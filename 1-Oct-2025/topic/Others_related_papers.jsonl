{'arxiv_id': 'arXiv:2509.26581', 'title': 'Graphite: A GPU-Accelerated Mixed-Precision Graph Optimization Framework', 'authors': 'Shishir Gopinath, Karthik Dantu, Steven Y. Ko', 'link': 'https://arxiv.org/abs/2509.26581', 'abstract': 'We present Graphite, a GPU-accelerated nonlinear graph optimization framework. It provides a CUDA C++ interface to enable the sharing of code between a realtime application, such as a SLAM system, and its optimization tasks. The framework supports techniques to reduce memory usage, including in-place optimization, support for multiple floating point types and mixed-precision modes, and dynamically computed Jacobians. We evaluate Graphite on well-known bundle adjustment problems and find that it achieves similar performance to MegBA, a solver specialized for bundle adjustment, while maintaining generality and using less memory. We also apply Graphite to global visual-inertial bundle adjustment on maps generated from stereo-inertial SLAM datasets, and observe speed ups of up to 59x compared to a CPU baseline. Our results indicate that our solver enables faster large-scale optimization on both desktop and resource-constrained devices.', 'abstract_zh': '我们介绍Graphite：一种基于GPU的非线性图优化框架', 'title_zh': 'Graphite：一种GPU加速的混合精度图优化框架'}
{'arxiv_id': 'arXiv:2509.26459', 'title': 'Analytic Conditions for Differentiable Collision Detection in Trajectory Optimization', 'authors': 'Akshay Jaitly, Devesh K. Jha, Kei Ota, Yuki Shirai', 'link': 'https://arxiv.org/abs/2509.26459', 'abstract': 'Optimization-based methods are widely used for computing fast, diverse solutions for complex tasks such as collision-free movement or planning in the presence of contacts. However, most of these methods require enforcing non-penetration constraints between objects, resulting in a non-trivial and computationally expensive problem. This makes the use of optimization-based methods for planning and control challenging. In this paper, we present a method to efficiently enforce non-penetration of sets while performing optimization over their configuration, which is directly applicable to problems like collision-aware trajectory optimization. We introduce novel differentiable conditions with analytic expressions to achieve this. To enforce non-collision between non-smooth bodies using these conditions, we introduce a method to approximate polytopes as smooth semi-algebraic sets. We present several numerical experiments to demonstrate the performance of the proposed method and compare the performance with other baseline methods recently proposed in the literature.', 'abstract_zh': '基于优化的方法广泛用于计算复杂任务（如碰撞免费移动或接触条件下的规划）的快速和多样化解决方案。然而，这些方法大多需要在物体之间施加非穿透约束，导致问题非平凡且计算成本高昂。这使得基于优化的方法在规划与控制中的应用具有挑战性。本文提出了一种方法，可以在优化配置的同时高效地施加非穿透约束，该方法直接适用于碰撞感知轨迹优化等问题。我们引入了新颖的可微条件及其解析表达式以实现这一目标。为了使用这些条件来近似非光滑体之间的无碰撞，我们提出了一种将多面体近似为光滑半代数集的方法。我们通过多个数值实验展示了所提出方法的性能，并将其性能与其他近期文献中提出的基线方法进行了比较。', 'title_zh': '可微碰撞检测在轨迹优化中的分析条件'}
{'arxiv_id': 'arXiv:2509.26050', 'title': 'Conflict-Based Search and Prioritized Planning for Multi-Agent Path Finding Among Movable Obstacles', 'authors': 'Shaoli Hu, Shizhe Zhao, Zhongqiang Ren', 'link': 'https://arxiv.org/abs/2509.26050', 'abstract': 'This paper investigates Multi-Agent Path Finding Among Movable Obstacles (M-PAMO), which seeks collision-free paths for multiple agents from their start to goal locations among static and movable obstacles. M-PAMO arises in logistics and warehouses where mobile robots are among unexpected movable objects. Although Multi-Agent Path Finding (MAPF) and single-agent Path planning Among Movable Obstacles (PAMO) were both studied, M-PAMO remains under-explored. Movable obstacles lead to new fundamental challenges as the state space, which includes both agents and movable obstacles, grows exponentially with respect to the number of agents and movable obstacles. In particular, movable obstacles often closely couple agents together spatially and temporally. This paper makes a first attempt to adapt and fuse the popular Conflict-Based Search (CBS) and Prioritized Planning (PP) for MAPF, and a recent single-agent PAMO planner called PAMO*, together to address M-PAMO. We compare their performance with up to 20 agents and hundreds of movable obstacles, and show the pros and cons of these approaches.', 'abstract_zh': 'Multi-Agent Path Finding Among Movable Obstacles (M-PAMO)', 'title_zh': '基于冲突的搜索与优先级规划的多agent路径寻找算法研究'}
{'arxiv_id': 'arXiv:2509.25984', 'title': 'S$^3$E: Self-Supervised State Estimation for Radar-Inertial System', 'authors': 'Shengpeng Wang, Yulong Xie, Qing Liao, Wei Wang', 'link': 'https://arxiv.org/abs/2509.25984', 'abstract': 'Millimeter-wave radar for state estimation is gaining significant attention for its affordability and reliability in harsh conditions. Existing localization solutions typically rely on post-processed radar point clouds as landmark points. Nonetheless, the inherent sparsity of radar point clouds, ghost points from multi-path effects, and limited angle resolution in single-chirp radar severely degrade state estimation performance. To address these issues, we propose S$^3$E, a \\textbf{S}elf-\\textbf{S}upervised \\textbf{S}tate \\textbf{E}stimator that employs more richly informative radar signal spectra to bypass sparse points and fuses complementary inertial information to achieve accurate localization. S$^3$E fully explores the association between \\textit{exteroceptive} radar and \\textit{proprioceptive} inertial sensor to achieve complementary benefits. To deal with limited angle resolution, we introduce a novel cross-fusion technique that enhances spatial structure information by exploiting subtle rotational shift correlations across heterogeneous data. The experimental results demonstrate our method achieves robust and accurate performance without relying on localization ground truth supervision. To the best of our knowledge, this is the first attempt to achieve state estimation by fusing radar spectra and inertial data in a complementary self-supervised manner.', 'abstract_zh': '毫米波雷达用于状态估计正因其在恶劣条件下的负担能力和可靠性而获得显著关注。传统定位解决方案通常依赖于后期处理的雷达点云作为地标点。然而，雷达点云的固有稀疏性、多路径效应产生的鬼点以及单脉冲雷达有限的角度分辨率严重降低了状态估计性能。为了解决这些问题，我们提出了一种自监督状态估计器S$^3$E，该方法利用更丰富的雷达信号频谱来避开稀疏点，并融合互补的惯性信息以实现精确的定位。S$^3$E充分利用了外部感知雷达与内感知惯性传感器之间的关联，以实现互补效益。为解决有限的角度分辨率问题，我们引入了一种新颖的跨融合技术，通过利用异构数据中细微旋转偏移的相关性来增强空间结构信息。实验结果表明，我们的方法在无需依赖定位地面 truth 监督的情况下实现了坚固而准确的性能。据我们所知，这是首次尝试通过互补的自监督方式融合雷达频谱和惯性数据以实现状态估计的方法。', 'title_zh': 'S$^3$E：雷达-惯性系统自监督状态估计'}
{'arxiv_id': 'arXiv:2509.25685', 'title': 'Hierarchical Diffusion Motion Planning with Task-Conditioned Uncertainty-Aware Priors', 'authors': 'Amelie Minji Kim, Anqi Wu, Ye Zhao', 'link': 'https://arxiv.org/abs/2509.25685', 'abstract': 'We propose a novel hierarchical diffusion planner that embeds task and motion structure directly in the noise model. Unlike standard diffusion-based planners that use zero-mean, isotropic Gaussian noise, we employ a family of task-conditioned structured Gaussians whose means and covariances are derived from Gaussian Process Motion Planning (GPMP): sparse, task-centric key states or their associated timings (or both) are treated as noisy observations to produce a prior instance. We first generalize the standard diffusion process to biased, non-isotropic corruption with closed-form forward and posterior expressions. Building on this, our hierarchy separates prior instantiation from trajectory denoising: the upper level instantiates a task-conditioned structured Gaussian (mean and covariance), and the lower level denoises the full trajectory under that fixed prior. Experiments on Maze2D goal-reaching and KUKA block stacking show improved success rates, smoother trajectories, and stronger task alignment compared to isotropic baselines. Ablation studies indicate that explicitly structuring the corruption process offers benefits beyond simply conditioning the neural network. Overall, our method concentrates probability mass of prior near feasible, smooth, and semantically meaningful trajectories while maintaining tractability. Our project page is available at this https URL.', 'abstract_zh': '我们提出了一种新颖的层次扩散规划器，将任务和运动结构直接嵌入噪声模型中。', 'title_zh': '层次扩散运动规划：基于任务条件的不确定性感知先验'}
{'arxiv_id': 'arXiv:2509.25663', 'title': 'Field Calibration of Hyperspectral Cameras for Terrain Inference', 'authors': 'Nathaniel Hanson, Benjamin Pyatski, Samuel Hibbard, Gary Lvov, Oscar De La Garza, Charles DiMarzio, Kristen L. Dorsey, Taşkın Padır', 'link': 'https://arxiv.org/abs/2509.25663', 'abstract': "Intra-class terrain differences such as water content directly influence a vehicle's ability to traverse terrain, yet RGB vision systems may fail to distinguish these properties. Evaluating a terrain's spectral content beyond red-green-blue wavelengths to the near infrared spectrum provides useful information for intra-class identification. However, accurate analysis of this spectral information is highly dependent on ambient illumination. We demonstrate a system architecture to collect and register multi-wavelength, hyperspectral images from a mobile robot and describe an approach to reflectance calibrate cameras under varying illumination conditions. To showcase the practical applications of our system, HYPER DRIVE, we demonstrate the ability to calculate vegetative health indices and soil moisture content from a mobile robot platform.", 'abstract_zh': '基于多光谱的移动机器人地形内类差异识别系统及其应用', 'title_zh': '高光谱相机用于地貌推断的场校准'}
{'arxiv_id': 'arXiv:2509.25556', 'title': 'Exhaustive-Serve-Longest Control for Multi-robot Scheduling Systems', 'authors': 'Mohammad Merati, David Castañón', 'link': 'https://arxiv.org/abs/2509.25556', 'abstract': 'We study online task allocation for multi-robot, multi-queue systems with stochastic arrivals and switching delays. Time is slotted; each location can host at most one robot per slot; service consumes one slot; switching between locations incurs a one-slot travel delay; and arrivals are independent Bernoulli processes. We formulate a discounted-cost Markov decision process and propose Exhaustive-Serve-Longest (ESL), a simple real-time policy that serves exhaustively when the current location is nonempty and, when idle, switches to a longest unoccupied nonempty location, and we prove the optimality of this policy. As baselines, we tune a fixed-dwell cyclic policy via a discrete-time delay expression and implement a first-come-first-serve policy. Across server-to-location ratios and loads, ESL consistently yields lower discounted holding cost and smaller mean queue lengths, with action-time fractions showing more serving and restrained switching. Its simplicity and robustness make ESL a practical default for real-time multi-robot scheduling systems.', 'abstract_zh': '多机器人、多队列系统中具有随机到达和服务延迟的在线任务分配研究', 'title_zh': '全面服务最长控制策略的多机器人调度系统'}
{'arxiv_id': 'arXiv:2509.26575', 'title': 'The Trajectory Bundle Method: Unifying Sequential-Convex Programming and Sampling-Based Trajectory Optimization', 'authors': 'Kevin Tracy, John Z. Zhang, Jon Arrizabalaga, Stefan Schaal, Yuval Tassa, Tom Erez, Zachary Manchester', 'link': 'https://arxiv.org/abs/2509.26575', 'abstract': 'We present a unified framework for solving trajectory optimization problems in a derivative-free manner through the use of sequential convex programming. Traditionally, nonconvex optimization problems are solved by forming and solving a sequence of convex optimization problems, where the cost and constraint functions are approximated locally through Taylor series expansions. This presents a challenge for functions where differentiation is expensive or unavailable. In this work, we present a derivative-free approach to form these convex approximations by computing samples of the dynamics, cost, and constraint functions and letting the solver interpolate between them. Our framework includes sample-based trajectory optimization techniques like model-predictive path integral (MPPI) control as a special case and generalizes them to enable features like multiple shooting and general equality and inequality constraints that are traditionally associated with derivative-based sequential convex programming methods. The resulting framework is simple, flexible, and capable of solving a wide variety of practical motion planning and control problems.', 'abstract_zh': '我们提出了一种统一框架，通过顺序凸规划以无导数的方式求解轨迹优化问题。传统上，非凸优化问题通过形成和求解一系列凸优化问题来解决，其中通过泰勒级数展开局部逼近代价和约束函数。对于导数昂贵或不可用的情况，这提出了挑战。在本工作中，我们提出了一种无导数的方法来形成这些凸逼近：通过计算动力学、代价和约束函数的样本，并让求解器在它们之间进行插值。该框架将模型预测路径积分（MPPI）控制等基于样本的轨迹优化技术作为特殊情况，并将其推广以启用多项射击以及传统上与基于导数的顺序凸规划方法相关的多种等式和不等式约束。所提出的方法简单、灵活，并能够解决广泛的实践运动规划和控制问题。', 'title_zh': '轨迹束方法：序列凸规划与基于采样的轨迹优化统一方法'}
{'arxiv_id': 'arXiv:2509.25600', 'title': 'MoReFlow: Motion Retargeting Learning through Unsupervised Flow Matching', 'authors': 'Wontaek Kim, Tianyu Li, Sehoon Ha', 'link': 'https://arxiv.org/abs/2509.25600', 'abstract': "Motion retargeting holds a premise of offering a larger set of motion data for characters and robots with different morphologies. Many prior works have approached this problem via either handcrafted constraints or paired motion datasets, limiting their applicability to humanoid characters or narrow behaviors such as locomotion. Moreover, they often assume a fixed notion of retargeting, overlooking domain-specific objectives like style preservation in animation or task-space alignment in robotics. In this work, we propose MoReFlow, Motion Retargeting via Flow Matching, an unsupervised framework that learns correspondences between characters' motion embedding spaces. Our method consists of two stages. First, we train tokenized motion embeddings for each character using a VQ-VAE, yielding compact latent representations. Then, we employ flow matching with conditional coupling to align the latent spaces across characters, which simultaneously learns conditioned and unconditioned matching to achieve robust but flexible retargeting. Once trained, MoReFlow enables flexible and reversible retargeting without requiring paired data. Experiments demonstrate that MoReFlow produces high-quality motions across diverse characters and tasks, offering improved controllability, generalization, and motion realism compared to the baselines.", 'abstract_zh': '基于流动匹配的动作重定向持有为具有不同形态的角色和机器人提供更大动作数据集的前提。许多先前的工作通过手工构建的约束或配对的动作数据集来解决这个问题，这限制了它们在人形角色或狭窄行为如行走方面的适用性。此外，它们通常假设动作重定向的固定概念，忽视了诸如动画中的风格保持或机器人中的任务空间对齐等领域特定目标。在本文中，我们提出了一种基于流动匹配的动作重定向方法MoReFlow，这是一种无监督框架，用于学习角色动作嵌入空间之间的对应关系。该方法包括两个阶段。首先，我们使用VQ-VAE为每个角色训练标记化动作嵌入，产生紧凑的潜在表示。然后，我们使用条件耦合的流动匹配来对齐角色之间的潜在空间，同时学习条件和无条件匹配，以实现稳健且灵活的动作重定向。训练完成后，MoReFlow能够实现灵活且可逆的动作重定向，无需配对数据。实验结果表明，MoReFlow在多种角色和任务中生成高质量的动作，相比基线方法提供了更好的可控性、泛化能力和动作真实性。', 'title_zh': 'MoReFlow: 无监督流匹配下的运动重定位学习'}
{'arxiv_id': 'arXiv:2509.25222', 'title': 'Sensor optimization for urban wind estimation with cluster-based probabilistic framework', 'authors': 'Yutong Liang, Chang Hou, Guy Y. Cornejo Maceda, Andrea Ianiro, Stefano Discetti, Andrea Meilán-Vila, Didier Sornette, Sandro Claudio Lera, Jialong Chen, Xiaozhou He, Bernd R. Noack', 'link': 'https://arxiv.org/abs/2509.25222', 'abstract': 'We propose a physics-informed machine-learned framework for sensor-based flow estimation for drone trajectories in complex urban terrain. The input is a rich set of flow simulations at many wind conditions. The outputs are velocity and uncertainty estimates for a target domain and subsequent sensor optimization for minimal uncertainty. The framework has three innovations compared to traditional flow estimators. First, the algorithm scales proportionally to the domain complexity, making it suitable for flows that are too complex for any monolithic reduced-order representation. Second, the framework extrapolates beyond the training data, e.g., smaller and larger wind velocities. Last, and perhaps most importantly, the sensor location is a free input, significantly extending the vast majority of the literature. The key enablers are (1) a Reynolds number-based scaling of the flow variables, (2) a physics-based domain decomposition, (3) a cluster-based flow representation for each subdomain, (4) an information entropy correlating the subdomains, and (5) a multi-variate probability function relating sensor input and targeted velocity estimates. This framework is demonstrated using drone flight paths through a three-building cluster as a simple example. We anticipate adaptations and applications for estimating complete cities and incorporating weather input.', 'abstract_zh': '基于传感器的无人机轨迹流估计的物理知情机器学习框架：面向复杂城市地形的风速与不确定性估计及传感器优化', 'title_zh': '基于聚类的概率框架下的城市风速估计传感器优化'}
{'arxiv_id': 'arXiv:2509.26632', 'title': 'Branching Out: Broadening AI Measurement and Evaluation with Measurement Trees', 'authors': 'Craig Greenberg, Patrick Hall, Theodore Jensen, Kristen Greene, Razvan Amironesei', 'link': 'https://arxiv.org/abs/2509.26632', 'abstract': 'This paper introduces \\textit{measurement trees}, a novel class of metrics designed to combine various constructs into an interpretable multi-level representation of a measurand. Unlike conventional metrics that yield single values, vectors, surfaces, or categories, measurement trees produce a hierarchical directed graph in which each node summarizes its children through user-defined aggregation methods. In response to recent calls to expand the scope of AI system evaluation, measurement trees enhance metric transparency and facilitate the integration of heterogeneous evidence, including, e.g., agentic, business, energy-efficiency, sociotechnical, or security signals. We present definitions and examples, demonstrate practical utility through a large-scale measurement exercise, and provide accompanying open-source Python code. By operationalizing a transparent approach to measurement of complex constructs, this work offers a principled foundation for broader and more interpretable AI evaluation.', 'abstract_zh': '本文介绍了测量树，这是一种新型的度量类别，设计用于将各种构造结合成可解释的多层次表示。与传统的单一值、向量、表面或类别度量不同，测量树生成一个层级有向图，其中每个节点通过用户定义的聚合方法来总结其子节点。响应近期对扩展AI系统评价范围的呼吁，测量树增强了度量的透明度，并促进了异构证据的集成，包括代理、商业、能源效率、技术社会或安全信号。我们提供了定义和示例，通过大规模测量实验展示了其实用性，并提供了 accompanying 开源 Python 代码。通过操作化复杂构造的透明度量方法，本文为更广泛且更可解释的AI评价提供了原则性的基础。', 'title_zh': '扩展视野：通过测量树拓宽人工智能的评估范畴'}
{'arxiv_id': 'arXiv:2509.26534', 'title': 'Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework', 'authors': 'Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Ricardo Bianchini', 'link': 'https://arxiv.org/abs/2509.26534', 'abstract': "The rapid rise of large language models (LLMs) has been driving an enormous demand for AI inference infrastructure, mainly powered by high-end GPUs. While these accelerators offer immense computational power, they incur high capital and operational costs due to frequent upgrades, dense power consumption, and cooling demands, making total cost of ownership (TCO) for AI datacenters a critical concern for cloud providers. Unfortunately, traditional datacenter lifecycle management (designed for general-purpose workloads) struggles to keep pace with AI's fast-evolving models, rising resource needs, and diverse hardware profiles. In this paper, we rethink the AI datacenter lifecycle scheme across three stages: building, hardware refresh, and operation. We show how design choices in power, cooling, and networking provisioning impact long-term TCO. We also explore refresh strategies aligned with hardware trends. Finally, we use operation software optimizations to reduce cost. While these optimizations at each stage yield benefits, unlocking the full potential requires rethinking the entire lifecycle. Thus, we present a holistic lifecycle management framework that coordinates and co-optimizes decisions across all three stages, accounting for workload dynamics, hardware evolution, and system aging. Our system reduces the TCO by up to 40\\% over traditional approaches. Using our framework we provide guidelines on how to manage AI datacenter lifecycle for the future.", 'abstract_zh': '大型语言模型的 rapid rise 促使了对 AI 推理基础设施的巨大需求，主要由高端 GPU 推动。在本文中，我们重新思考 AI 数据中心生命周期方案的三个阶段：构建、硬件刷新和运维。我们展示了在供电、制冷和网络规划方面的设计选择如何影响长期拥有成本（TCO）。我们还探讨了与硬件趋势相一致的刷新策略。最后，我们通过运维软件优化来降低成本。虽然每个阶段的优化都有益处，但要发挥其全部潜力，需要重新考虑整个生命周期。因此，我们提出了一种综合的生命周期管理框架，协调并优化所有三个阶段的决策，考虑到工作负载动态、硬件演进和系统老化。我们系统将传统方法的拥有成本降低了高达 40%。通过我们提出的框架，我们提供了关于如何管理未来 AI 数据中心生命周期的指导。', 'title_zh': '面向AI的数据中心生命周期重构：一种以总成本为导向的框架'}
{'arxiv_id': 'arXiv:2509.26506', 'title': 'SCUBA: Salesforce Computer Use Benchmark', 'authors': 'Yutong Dai, Krithika Ramakrishnan, Jing Gu, Matthew Fernandez, Yanqi Luo, Viraj Prabhu, Zhenyu Hu, Silvio Savarese, Caiming Xiong, Zeyuan Chen, Ran Xu', 'link': 'https://arxiv.org/abs/2509.26506', 'abstract': 'We introduce SCUBA, a benchmark designed to evaluate computer-use agents on customer relationship management (CRM) workflows within the Salesforce platform. SCUBA contains 300 task instances derived from real user interviews, spanning three primary personas, platform administrators, sales representatives, and service agents. The tasks test a range of enterprise-critical abilities, including Enterprise Software UI navigation, data manipulation, workflow automation, information retrieval, and troubleshooting. To ensure realism, SCUBA operates in Salesforce sandbox environments with support for parallel execution and fine-grained evaluation metrics to capture milestone progress. We benchmark a diverse set of agents under both zero-shot and demonstration-augmented settings. We observed huge performance gaps in different agent design paradigms and gaps between the open-source model and the closed-source model. In the zero-shot setting, open-source model powered computer-use agents that have strong performance on related benchmarks like OSWorld only have less than 5\\% success rate on SCUBA, while methods built on closed-source models can still have up to 39% task success rate. In the demonstration-augmented settings, task success rates can be improved to 50\\% while simultaneously reducing time and costs by 13% and 16%, respectively. These findings highlight both the challenges of enterprise tasks automation and the promise of agentic solutions. By offering a realistic benchmark with interpretable evaluation, SCUBA aims to accelerate progress in building reliable computer-use agents for complex business software ecosystems.', 'abstract_zh': 'SCUBA：Salesforce平台客户关系管理流程中的计算机使用代理基准测试', 'title_zh': 'SCUBA: Salesforce计算机使用基准'}
{'arxiv_id': 'arXiv:2509.26487', 'title': 'Combining Knowledge Graphs and NLP to Analyze Instant Messaging Data in Criminal Investigations', 'authors': 'Riccardo Pozzi, Valentina Barbera, Renzo Alva Principe, Davide Giardini, Riccardo Rubini, Matteo Palmonari', 'link': 'https://arxiv.org/abs/2509.26487', 'abstract': "Criminal investigations often involve the analysis of messages exchanged through instant messaging apps such as WhatsApp, which can be an extremely effort-consuming task. Our approach integrates knowledge graphs and NLP models to support this analysis by semantically enriching data collected from suspects' mobile phones, and help prosecutors and investigators search into the data and get valuable insights. Our semantic enrichment process involves extracting message data and modeling it using a knowledge graph, generating transcriptions of voice messages, and annotating the data using an end-to-end entity extraction approach. We adopt two different solutions to help users get insights into the data, one based on querying and visualizing the graph, and one based on semantic search. The proposed approach ensures that users can verify the information by accessing the original data. While we report about early results and prototypes developed in the context of an ongoing project, our proposal has undergone practical applications with real investigation data. As a consequence, we had the chance to interact closely with prosecutors, collecting positive feedback but also identifying interesting opportunities as well as promising research directions to share with the research community.", 'abstract_zh': '刑事调查常常涉及分析通过WhatsApp等即时消息应用交换的消息，这是一项极其耗费精力的工作。我们提出的方法结合了知识图谱和NLP模型，通过对嫌疑人手机收集的数据进行语义增强，辅助检察官和调查人员搜索数据并获取有价值的洞察。我们的语义增强过程包括提取消息数据并使用知识图谱建模，生成语音消息的转录，并使用端到端实体提取方法对数据进行标注。我们采用两种不同的解决方案帮助用户洞察数据，一种是基于查询和可视化图谱，另一种是基于语义搜索。所提出的方法确保用户可以通过访问原始数据验证信息。尽管我们报告了基于正在进行项目的初步结果和原型，我们的提案已经在实际调查数据的环境中得到了应用。因此，我们有机会与检察官密切互动，收集了正面反馈并发现了有趣的机会以及值得与研究社区分享的有前景的研究方向。', 'title_zh': '结合知识图谱和自然语言处理技术分析犯罪调查中的即时通讯数据'}
{'arxiv_id': 'arXiv:2509.26474', 'title': 'The Average Patient Fallacy', 'authors': 'Alaleh Azhir, Shawn N. Murphy, Hossein Estiri', 'link': 'https://arxiv.org/abs/2509.26474', 'abstract': 'Machine learning in medicine is typically optimized for population averages. This frequency weighted training privileges common presentations and marginalizes rare yet clinically critical cases, a bias we call the average patient fallacy. In mixture models, gradients from rare cases are suppressed by prevalence, creating a direct conflict with precision medicine. Clinical vignettes in oncology, cardiology, and ophthalmology show how this yields missed rare responders, delayed recognition of atypical emergencies, and underperformance on vision-threatening variants. We propose operational fixes: Rare Case Performance Gap, Rare Case Calibration Error, a prevalence utility definition of rarity, and clinically weighted objectives that surface ethical priorities. Weight selection should follow structured deliberation. AI in medicine must detect exceptional cases because of their significance.', 'abstract_zh': '医学中的机器学习通常优化群体平均值。这种基于频率加权的训练倾向于关注常见的表现形式而忽视罕见但临床至关重要的病例，我们将其称为“平均患者谬误”。在混合模型中，罕见病例的梯度被其发生频率抑制，这与精准医学目标直接冲突。通过肿瘤学、心脏病学和眼科的临床案例，我们展示了这导致了罕见响应者的漏诊、非典型紧急情况的延迟识别以及对视力威胁变异的性能不足。我们提出操作性的修复方法：罕见病例性能差距、罕见病例校准误差、基于频率的罕见性定义以及兼顾临床的优化目标，以突出伦理优先事项。权重选择应遵循结构化的讨论。医学中的AI必须检测例外情况，因为它们的重要性。', 'title_zh': '平均患者谬误'}
{'arxiv_id': 'arXiv:2509.26462', 'title': 'Zero-Shot Decentralized Federated Learning', 'authors': 'Alessio Masano, Matteo Pennisi, Federica Proietto Salanitri, Concetto Spampinato, Giovanni Bellitto', 'link': 'https://arxiv.org/abs/2509.26462', 'abstract': "CLIP has revolutionized zero-shot learning by enabling task generalization without fine-tuning. While prompting techniques like CoOp and CoCoOp enhance CLIP's adaptability, their effectiveness in Federated Learning (FL) remains an open challenge. Existing federated prompt learning approaches, such as FedCoOp and FedTPG, improve performance but face generalization issues, high communication costs, and reliance on a central server, limiting scalability and privacy. We propose Zero-shot Decentralized Federated Learning (ZeroDFL), a fully decentralized framework that enables zero-shot adaptation across distributed clients without a central coordinator. ZeroDFL employs an iterative prompt-sharing mechanism, allowing clients to optimize and exchange textual prompts to enhance generalization while drastically reducing communication overhead. We validate ZeroDFL on nine diverse image classification datasets, demonstrating that it consistently outperforms--or remains on par with--state-of-the-art federated prompt learning methods. More importantly, ZeroDFL achieves this performance in a fully decentralized setting while reducing communication overhead by 118x compared to FedTPG. These results highlight that our approach not only enhances generalization in federated zero-shot learning but also improves scalability, efficiency, and privacy preservation--paving the way for decentralized adaptation of large vision-language models in real-world applications.", 'abstract_zh': '零-shot去中心化联邦学习（ZeroDFL）：一种完全去中心化的框架，实现分布式客户端的零-shot自适应', 'title_zh': '零-shot分布式联邦学习'}
{'arxiv_id': 'arXiv:2509.26417', 'title': 'OntoAligner Meets Knowledge Graph Embedding Aligners', 'authors': "Hamed Babaei Giglou, Jennifer D'Souza, Sören Auer, Mahsa Sanaei", 'link': 'https://arxiv.org/abs/2509.26417', 'abstract': 'Ontology Alignment (OA) is essential for enabling semantic interoperability across heterogeneous knowledge systems. While recent advances have focused on large language models (LLMs) for capturing contextual semantics, this work revisits the underexplored potential of Knowledge Graph Embedding (KGE) models, which offer scalable, structure-aware representations well-suited to ontology-based tasks. Despite their effectiveness in link prediction, KGE methods remain underutilized in OA, with most prior work focusing narrowly on a few models. To address this gap, we reformulate OA as a link prediction problem over merged ontologies represented as RDF-style triples and develop a modular framework, integrated into the OntoAligner library, that supports 17 diverse KGE models. The system learns embeddings from a combined ontology and aligns entities by computing cosine similarity between their representations. We evaluate our approach using standard metrics across seven benchmark datasets spanning five domains: Anatomy, Biodiversity, Circular Economy, Material Science and Engineering, and Biomedical Machine Learning. Two key findings emerge: first, KGE models like ConvE and TransF consistently produce high-precision alignments, outperforming traditional systems in structure-rich and multi-relational domains; second, while their recall is moderate, this conservatism makes KGEs well-suited for scenarios demanding high-confidence mappings. Unlike LLM-based methods that excel at contextual reasoning, KGEs directly preserve and exploit ontology structure, offering a complementary and computationally efficient strategy. These results highlight the promise of embedding-based OA and open pathways for further work on hybrid models and adaptive strategies.', 'abstract_zh': '本体对齐（OA）对于跨异构知识系统实现语义互操作至关重要。虽然最近的进步侧重于使用大规模语言模型（LLMs）捕捉上下文语义，但本项工作重访了知识图嵌入（KGE）模型的未充分探索的潜力，KGE模型提供了可扩展的、结构意识强的表示，非常适合基于本体的任务。尽管KGE方法在链接预测方面非常有效，但在本体对齐中的应用仍然不足，大多数早期工作仅专注于少数几种模型。为弥补这一差距，我们将本体对齐重新表述为使用RDF样式的三元组表示合并本体的链接预测问题，并开发了一个模块化框架，该框架集成到OntoAligner库中，支持17种不同的KGE模型。该系统从合并的本体中学习嵌入并向量余弦相似度计算实体之间的相似性进行对齐。我们使用七个涵盖五个领域（解剖学、生物多样性、循环经济、材料科学与工程、生物医学机器学习）的标准基准数据集，评估了我们的方法。主要发现两点：首先，如ConvE和TransF等KGE模型持续产生高精度对齐结果，在结构丰富和多关系领域中表现出色，超越了传统系统；其次，尽管其召回率相对较低，这种保守性使得KGE非常适合需要高置信度映射的场景。不同于基于大规模语言模型的方法擅长上下文推理，KGE直接保留和利用了本体结构，提供了一种互补且计算效率高的策略。这些结果突显了嵌入式本体对齐的前景，并为针对混合模型和自适应策略的进一步工作打开了路径。', 'title_zh': 'OntoAligner 与知识图嵌入对齐器相遇'}
{'arxiv_id': 'arXiv:2509.26399', 'title': 'Commmunication-Efficient and Accurate Approach for Aggregation in Federated Low-Rank Adaptation', 'authors': 'Le-Tuan Nguyen, Minh-Duong Nguyen, Seon-Geun Jeong, Dung D. Le, Quoc-Viet Pham', 'link': 'https://arxiv.org/abs/2509.26399', 'abstract': 'With the rapid emergence of foundation models and the increasing need for fine-tuning across distributed environments, Federated Low-Rank Adaptation (FedLoRA) has recently gained significant attention. Despite enormous potential, current FedLoRA methods face notable challenges due to inexact updates. Existing approaches have attempted to mitigate this issue, but they often introduce a \\emph{local-global generalization gap} and incur \\emph{substantial communication overhead}, limiting their scalability and effectiveness. To address these limitations, we propose \\textbf{F}ederated \\textbf{Lo}w-\\textbf{R}ank \\textbf{A}ggregation with \\textbf{N}early \\textbf{A}ccurate Estimation (FLoRA-NA). FLoRA-NA leverages the local LoRA matrices on the server to estimate the aggregated matrices $\\hat{A}$ and $\\hat{B}$, which are then distributed to clients for local updates. This surrogated aggregated matrices minimizes the divergence between ideal $\\nabla \\Bar{W} = \\sum^{U}_{u=1}B_u A_u$ and practical updates $\\nabla \\hat{W} = \\hat{B}\\hat{A}$ without adding communication cost beyond vanilla FedLoRA. By doing so, FLoRA-NA achieves communication efficiency and bridges the gap between local personalization and global generalization, addressing a key limitation of prior personalized FedLoRA approaches. We conduct extensive evaluations across diverse tasks, including natural language understanding, mathematical reasoning, and code-solving ability using various foundation models. Experimental results consistently demonstrate that FLoRA-NA achieves state-of-the-art global performance while maintaining low communication overhead.', 'abstract_zh': '联邦低秩聚合近似（FLoRA-NA）', 'title_zh': '通信高效且准确的联邦低秩适应聚合方法'}
{'arxiv_id': 'arXiv:2509.26377', 'title': 'MC-GNNAS-Dock: Multi-criteria GNN-based Algorithm Selection for Molecular Docking', 'authors': 'Siyuan Cao, Hongxuan Wu, Jiabao Brad Wang, Yiliang Yuan, Mustafa Misir', 'link': 'https://arxiv.org/abs/2509.26377', 'abstract': 'Molecular docking is a core tool in drug discovery for predicting ligand-target interactions. Despite the availability of diverse search-based and machine learning approaches, no single docking algorithm consistently dominates, as performance varies by context. To overcome this challenge, algorithm selection frameworks such as GNNAS-Dock, built on graph neural networks, have been proposed. This study introduces an enhanced system, MC-GNNAS-Dock, with three key advances. First, a multi-criteria evaluation integrates binding-pose accuracy (RMSD) with validity checks from PoseBusters, offering a more rigorous assessment. Second, architectural refinements by inclusion of residual connections strengthen predictive robustness. Third, rank-aware loss functions are incorporated to sharpen rank learning. Extensive experiments are performed on a curated dataset containing approximately 3200 protein-ligand complexes from PDBBind. MC-GNNAS-Dock demonstrates consistently superior performance, achieving up to 5.4% (3.4%) gains under composite criteria of RMSD below 1Å (2Å) with PoseBuster-validity compared to the single best solver (SBS) Uni-Mol Docking V2.', 'abstract_zh': '分子对接是药物发现中的核心工具，用于预测配体-靶标相互作用。尽管存在多样化的基于搜索和机器学习方法，但没有单一的对接算法在所有情境中始终占据优势，因为性能会根据环境变化。为克服这一挑战，基于图神经网络的算法选择框架如GNNAS-Dock已被提出。本研究介绍了一个增强系统MC-GNNAS-Dock，包含三个关键进步。首先，多指标评估将结合结合位姿精度（RMSD）和PoseBusters的有效性检查，提供更严格的评估。其次，通过引入残差连接进行结构优化，增强预测的稳健性。第三，引入基于排名的损失函数以优化排名学习。MC-GNNAS-Dock在包含约3200个蛋白质-配体复合物（来源于PDBBind）的精选数据集上的广泛实验中表现出一致的优越性能，在RMSD小于1Å（2Å）且通过PoseBuster验证的情况下，与单一最佳解算器Uni-Mol Docking V2相比，分别实现了多达5.4%（3.4%）的性能提升。', 'title_zh': '基于多目标GNN的分子对接算法选择：MC-GNNAS-Dock'}
{'arxiv_id': 'arXiv:2509.26347', 'title': 'How Far Do Time Series Foundation Models Paint the Landscape of Real-World Benchmarks ?', 'authors': 'Lujun Li, Lama Sleem, Yiqun Wang, Yangjie Xu, Niccolò Gentile, Radu State', 'link': 'https://arxiv.org/abs/2509.26347', 'abstract': 'Recent evaluations of time-series foundation models (TSFMs) have emphasized synthetic benchmarks, leaving real-world generalization less thoroughly examined. This work proposes a novel benchmarking approach that bridges synthetic and realistic data by extracting temporal signals from real-world video using optical flow and curating datasets reflecting everyday temporal dynamics. Building upon this pipeline, we introduce REAL-V-TSFM, a novel dataset designed to capture rich and diverse time series derived from real-world videos. Experimental results on three state-of-the-art of TSFMs under zero-shot forecasting shows that, despite strong performance on conventional benchmarks, these models predominantly exhibit performance degradation on the proposed dataset, indicating limited generalizability in these foundation models. These findings highlight the urgent need for data-centric benchmarking and diverse model structure to advance TSFMs toward genuine universality, while further validating the effectiveness of our video-based time series data extraction pipeline.', 'abstract_zh': '近期对时间序列基础模型(TSFMs)的评估强调了合成基准，而对其实用性的实地推广则较少详细探讨。本文提出了一种新型基准测试方法，通过从实际视频中提取时序信号并创建反映日常时序动态的数据集，桥接合成与现实数据。在此流水线的基础上，我们引入了REAL-V-TSFM，一个用于捕捉丰富多样时间序列的新数据集，这些时间序列源自实际视频。在三个最先进的TSFMs零样本预测实验中，尽管这些模型在传统基准上的表现强劲，但在所提数据集上的性能明显下降，表明这些基础模型的泛化能力有限。这些发现强调了亟待采用以数据为中心的基准测试和多样化模型结构，以推动TSFMs向真正的普适性发展，同时也进一步验证了我们基于视频的时间序列数据提取流水线的有效性。', 'title_zh': '时间序列基础模型在描绘现实世界基准场景中走得多远？'}
{'arxiv_id': 'arXiv:2509.26217', 'title': 'Benchmarking Deep Learning Convolutions on Energy-constrained CPUs', 'authors': 'Enrique Galvez, Adrien Cassagne, Alix Munier, Manuel Bouyer', 'link': 'https://arxiv.org/abs/2509.26217', 'abstract': 'This work evaluates state-of-the-art convolution algorithms for CPU-based deep learning inference. While most prior studies focus on GPUs or NPUs, CPU implementations remain relatively underoptimized. We benchmark direct, GEMM-based, and Winograd convolutions across modern CPUs from ARM __ , Intel __ , AMD __ , Apple __ , and Nvidia __ , considering both latency and energy efficiency. Our results highlight the key architectural factors that govern CPU efficiency for convolution operations, providing practical guidance for energy-aware embedded deployment. As a main results of this work, the Nvidia __ AGX Orin combined with the GEMM algorithm achieves the best trade-off between inference latency and energy consumption.', 'abstract_zh': '本文评估了基于CPU的深度学习推理中的先进卷积算法。虽然大多数前期研究主要集中在GPU或NPUs上，但CPU实现仍然相对较未优化。我们针对现代ARM __、Intel __、AMD __、Apple __和Nvidia __的CPU， benchmark了直接、GEMM和Winograd卷积，考虑了延迟和能效。我们的结果突出了卷积操作在CPU上实现效率的关键架构因素，并为节能嵌入式部署提供了实用指导。作为本文的主要成果，Nvidia __ AGX Orin结合GEMM算法在推理延迟和能耗之间实现了最佳权衡。', 'title_zh': '能源受限CPU上深度学习卷积的基准测试'}
{'arxiv_id': 'arXiv:2509.26161', 'title': '90% Faster, 100% Code-Free: MLLM-Driven Zero-Code 3D Game Development', 'authors': 'Runxin Yang, Yuxuan Wan, Shuqing Li, Michael R. Lyu', 'link': 'https://arxiv.org/abs/2509.26161', 'abstract': 'Developing 3D games requires specialized expertise across multiple domains, including programming, 3D modeling, and engine configuration, which limits access to millions of potential creators. Recently, researchers have begun to explore automated game development. However, existing approaches face three primary challenges: (1) limited scope to 2D content generation or isolated code snippets; (2) requirement for manual integration of generated components into game engines; and (3) poor performance on handling interactive game logic and state management. While Multimodal Large Language Models (MLLMs) demonstrate potential capabilities to ease the game generation task, a critical gap still remains in translating these outputs into production-ready, executable game projects based on game engines such as Unity and Unreal Engine.\nTo bridge the gap, this paper introduces UniGen, the first end-to-end coordinated multi-agent framework that automates zero-coding development of runnable 3D games from natural language requirements. Specifically, UniGen uses a Planning Agent that interprets user requirements into structured blueprints and engineered logic descriptions; after which a Generation Agent produces executable C# scripts; then an Automation Agent handles engine-specific component binding and scene construction; and lastly a Debugging Agent provides real-time error correction through conversational interaction. We evaluated UniGen on three distinct game prototypes. Results demonstrate that UniGen not only democratizes game creation by requiring no coding from the user, but also reduces development time by 91.4%. We release UniGen at this https URL. A video demonstration is available at this https URL.', 'abstract_zh': '开发3D游戏需要跨多个领域（包括编程、3D建模和引擎配置）的专业知识，这限制了数百万潜在创作者的参与。近期，研究人员开始探索自动游戏开发。然而，现有方法面临三大主要挑战：（1）局限于2D内容生成或孤立的代码片段；（2）需要手动将生成的组件集成到游戏引擎中；（3）在处理交互式游戏逻辑和状态管理方面表现不佳。虽然多模态大规模语言模型（MLLMs）展示了简化游戏生成任务的潜力，但在将这些输出转化为针对如Unity和Unreal Engine等游戏引擎的可执行生产项目方面仍存在关键缺口。\n\n为此，本文提出了UniGen，这是第一个端到端协调多代理框架，能够从自然语言要求自动开发可运行的3D游戏。具体而言，UniGen 使用一个规划代理，将用户需求解释为结构化的蓝图和工程逻辑描述；随后，生成代理生成可执行的C#脚本；接着，自动化代理处理特定于引擎的组件绑定和场景构建；最后，调试代理通过对话交互提供实时错误修正。我们在三个不同的游戏原型上评估了UniGen。结果表明，UniGen不仅通过要求用户不编写代码就能够使游戏创作民主化，还能够将开发时间减少91.4%。我们在此链接发布了UniGen：[链接]。一个视频演示可在以下链接获得：[链接]。', 'title_zh': '90%更快，100%代码自由：由MLLM驱动的零代码3D游戏开发'}
{'arxiv_id': 'arXiv:2509.26145', 'title': 'LMILAtt: A Deep Learning Model for Depression Detection from Social Media Users Enhanced by Multi-Instance Learning Based on Attention Mechanism', 'authors': 'Yukun Yang', 'link': 'https://arxiv.org/abs/2509.26145', 'abstract': 'Depression is a major global public health challenge and its early identification is crucial. Social media data provides a new perspective for depression detection, but existing methods face limitations such as insufficient accuracy, insufficient utilization of time series features, and high annotation costs. To this end, this study proposes the LMILAtt model, which innovatively integrates Long Short-Term Memory autoencoders and attention mechanisms: firstly, the temporal dynamic features of user tweets (such as depressive tendency evolution patterns) are extracted through unsupervised LSTM autoencoders. Secondly, the attention mechanism is used to dynamically weight key texts (such as early depression signals) and construct a multi-example learning architecture to improve the accuracy of user-level detection. Finally, the performance was verified on the WU3D dataset labeled by professional medicine. Experiments show that the model is significantly better than the baseline model in terms of accuracy, recall and F1 score. In addition, the weakly supervised learning strategy significantly reduces the cost of labeling and provides an efficient solution for large-scale social media depression screening.', 'abstract_zh': '抑郁是全球重大公共卫生挑战，早期识别至关重要。社交媒体数据提供了新的抑郁检测视角，但现有方法存在准确率不足、时间序列特征利用不充分以及标注成本高等局限。为此，本文提出LMILAtt模型，创新性地结合了长短期记忆自编码器和注意力机制：首先，通过无监督的LSTM自编码器提取用户推文的时序动态特征（如抑郁倾向演变模式）。其次，采用注意力机制动态加权关键文本（如早期抑郁信号），构建多例学习架构以提高用户级别检测的准确性。最后，实验在专业医学标注的WU3D数据集上验证了模型性能。实验结果表明，该模型在准确率、召回率和F1分数上显著优于基线模型。此外，弱监督学习策略显著降低了标注成本，为大规模社交媒体抑郁症筛查提供了高效的解决方案。', 'title_zh': '基于多实例学习和注意力机制的深度学习模型：社交媒体用户抑郁症检测'}
{'arxiv_id': 'arXiv:2509.25944', 'title': 'NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving', 'authors': 'Yuan Gao, Mattia Piccinini, Roberto Brusnicki, Yuchen Zhang, Johannes Betz', 'link': 'https://arxiv.org/abs/2509.25944', 'abstract': 'Understanding risk in autonomous driving requires not only perception and prediction, but also high-level reasoning about agent behavior and context. Current Vision Language Models (VLMs)-based methods primarily ground agents in static images and provide qualitative judgments, lacking the spatio-temporal reasoning needed to capture how risks evolve over time. To address this gap, we propose NuRisk, a comprehensive Visual Question Answering (VQA) dataset comprising 2,900 scenarios and 1.1 million agent-level samples, built on real-world data from nuScenes and Waymo, supplemented with safety-critical scenarios from the CommonRoad simulator. The dataset provides Bird-Eye-View (BEV) based sequential images with quantitative, agent-level risk annotations, enabling spatio-temporal reasoning. We benchmark well-known VLMs across different prompting techniques and find that they fail to perform explicit spatio-temporal reasoning, resulting in a peak accuracy of 33% at high latency. To address these shortcomings, our fine-tuned 7B VLM agent improves accuracy to 41% and reduces latency by 75%, demonstrating explicit spatio-temporal reasoning capabilities that proprietary models lacked. While this represents a significant step forward, the modest accuracy underscores the profound challenge of the task, establishing NuRisk as a critical benchmark for advancing spatio-temporal reasoning in autonomous driving.', 'abstract_zh': '理解自动驾驶中的风险需要感知和预测，还需要关于代理行为和上下文的高级推理。现有的基于视觉语言模型（VLM）的方法主要将代理定位在静态图像中，提供了定性的判断，缺乏捕捉风险随时间演变所需的时空推理能力。为了解决这一问题，我们提出了NuRisk，这是一个包含2900个场景和110万代理水平样本的全面的视觉问答（VQA）数据集，该数据集基于nuScenes和Waymo的实地数据，并结合了CommonRoad模拟器中的安全性关键场景。该数据集提供了基于鸟类视角（BEV）的序列图像，并附带定量的代理级风险注释，支持时空推理。我们对不同提示技术下的知名VLM进行了基准测试，发现它们未能进行显式的时空推理，导致在高延迟条件下最高准确率为33%。为了弥补这些不足，我们微调的7B VLM代理将准确率提高到41%，并将延迟降低75%，展示了其显式的时空推理能力，这是专有模型所缺乏的。虽然这代表了向前迈出的重要一步，但较低的准确率突显了任务的深刻挑战，确立了NuRisk作为促进自动驾驶中时空推理的关键基准的重要性。', 'title_zh': 'NuRisk: 自主驾驶中代理级风险评估的视觉问答数据集'}
{'arxiv_id': 'arXiv:2509.25928', 'title': 'Quantitative Evaluation of KIRETT Wearable Demonstrator for Rescue Operations', 'authors': 'Mubaris Nadeem, Johannes Zenkert, Lisa Bender, Christian Weber, Madjid Fathi', 'link': 'https://arxiv.org/abs/2509.25928', 'abstract': 'Healthcare and Medicine are under constant pressure to provide patient-driven medical expertise to ensure a fast and accurate treatment of the patient. In such scenarios, the diagnosis contains, the family history, long term medical data and a detailed consultation with the patient. In time-critical emergencies, such conversation and time-consuming elaboration are not possible. Rescue services need to provide fast, reliable treatments for the patient in need. With the help of modern technologies, like treatment recommendations, real-time vitals-monitoring, and situation detection through artificial intelligence (AI) a situation can be analyzed and supported in providing fast, accurate patient-data-driven medical treatments. In KIRETT, a wearable device is developed to support in such scenarios and presents a way to provide treatment recommendation in rescue services. The objective of this paper is to present the quantitative results of a two-day KIRETT evaluation (14 participants) to analyze the needs of rescue operators in healthcare.', 'abstract_zh': '健康医疗领域在不断的压力下致力于提供以患者为导向的医疗专长，以确保对患者的快速和准确治疗。在这种情况下，诊断需要包括家族病史、长期的医疗数据以及详细的患者咨询。在时间紧迫的紧急情况下，这样的对话和耗时的详细讨论是不可能的。救援服务需要为需要快速、可靠的治疗的患者提供服务。借助现代技术，如治疗建议、实时生命体征监测和通过人工智能（AI）的情况检测，可以分析情况并在提供快速、准确的基于患者数据的医疗治疗中起到支持作用。在KIRETT中，开发了一种可穿戴设备以支持此类场景，并提出了一种在救援服务中提供治疗建议的方法。本文的目标是展示KIRETT两天评估（14名参与者）的定量结果，以分析救援操作员在医疗领域的需求。', 'title_zh': 'KIRETT可穿戴演示器在救援操作中的定量评价'}
{'arxiv_id': 'arXiv:2509.25923', 'title': 'KIRETT: Smart Integration of Vital Signs Data for Intelligent Decision Support in Rescue Scenarios', 'authors': 'Mubaris Nadeem, Johannes Zenkert, Christian Weber, Lisa Bender, Madjid Fathi', 'link': 'https://arxiv.org/abs/2509.25923', 'abstract': 'The integration of vital signs in healthcare has witnessed a steady rise, promising health professionals to assist in their daily tasks to improve patient treatment. In life-threatening situations, like rescue operations, crucial decisions need to be made in the shortest possible amount of time to ensure that excellent treatment is provided during life-saving measurements. The integration of vital signs in the treatment holds the potential to improve time utilization for rescuers in such critical situations. They furthermore serve to support health professionals during the treatment with useful information and suggestions. To achieve such a goal, the KIRETT project serves to provide treatment recommendations and situation detection, combined on a wrist-worn wearable for rescue this http URL paper aims to present the significant role of vital signs in the improvement of decision-making during rescue operations and show their impact on health professionals and patients in need.', 'abstract_zh': '生命体征在医疗服务中的集成已逐渐上升，为健康专业人员提供帮助，以改善日常任务中的患者治疗。在救援等危急情况下，需要在最短的时间内作出关键决策，以确保在生命救援措施中提供优秀的治疗。生命体征在治疗中的集成有可能提高救援人员在这些关键时刻的时间利用率。它们还可以为健康专业人员在治疗过程中提供有用的建议和信息。为了实现这一目标，KIRETT项目提供治疗建议和情况检测，集成于可穿戴设备腕部设备。本文旨在阐述生命体征在救援操作中提高决策制定中的重要作用，并展示其对健康专业人员和有需要的患者的影响。', 'title_zh': 'KIRETT：救援场景中智能生命体征数据集成的支持智能决策系统'}
{'arxiv_id': 'arXiv:2509.25862', 'title': 'CIMNAS: A Joint Framework for Compute-In-Memory-Aware Neural Architecture Search', 'authors': 'Olga Krestinskaya, Mohammed E. Fouda, Ahmed Eltawil, Khaled N. Salama', 'link': 'https://arxiv.org/abs/2509.25862', 'abstract': 'To maximize hardware efficiency and performance accuracy in Compute-In-Memory (CIM)-based neural network accelerators for Artificial Intelligence (AI) applications, co-optimizing both software and hardware design parameters is essential. Manual tuning is impractical due to the vast number of parameters and their complex interdependencies. To effectively automate the design and optimization of CIM-based neural network accelerators, hardware-aware neural architecture search (HW-NAS) techniques can be applied. This work introduces CIMNAS, a joint model-quantization-hardware optimization framework for CIM architectures. CIMNAS simultaneously searches across software parameters, quantization policies, and a broad range of hardware parameters, incorporating device-, circuit-, and architecture-level co-optimizations. CIMNAS experiments were conducted over a search space of 9.9x10^85 potential parameter combinations with the MobileNet model as a baseline and RRAM-based CIM architecture. Evaluated on the ImageNet dataset, CIMNAS achieved a reduction in energy-delay-area product (EDAP) ranging from 90.1x to 104.5x, an improvement in TOPS/W between 4.68x and 4.82x, and an enhancement in TOPS/mm^2 from 11.3x to 12.78x relative to various baselines, all while maintaining an accuracy of 73.81%. The adaptability and robustness of CIMNAS are demonstrated by extending the framework to support the SRAM-based ResNet50 architecture, achieving up to an 819.5x reduction in EDAP. Unlike other state-of-the-art methods, CIMNAS achieves EDAP-focused optimization without any accuracy loss, generating diverse software-hardware parameter combinations for high-performance CIM-based neural network designs. The source code of CIMNAS is available at this https URL.', 'abstract_zh': '基于计算在内存（CIM）的神经网络加速器在人工智能（AI）应用中的硬件效率和性能准确性的最大化：软硬件联合优化与硬件感知神经架构搜索技术的研究', 'title_zh': 'CIMNAS：一种计算共存于内存感知的神经架构搜索联合框架'}
{'arxiv_id': 'arXiv:2509.25858', 'title': 'Aging Decline in Basketball Career Trend Prediction Based on Machine Learning and LSTM Model', 'authors': 'Yi-chen Yao, Jerry Wang, Yi-cheng Lai, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2509.25858', 'abstract': 'The topic of aging decline on performance of NBA players has been discussed in this study. The autoencoder with K-means clustering machine learning method was adopted to career trend classification of NBA players, and the LSTM deep learning method was adopted in performance prediction of each NBA player. The dataset was collected from the basketball game data of veteran NBA players. The contribution of the work performed better than the other methods with generalization ability for evaluating various types of NBA career trend, and can be applied in different types of sports in the field of sport analytics.', 'abstract_zh': 'NBA球员衰老对表现下降的研究：基于自动编码器与K-means聚类及LSTM深度学习的方法', 'title_zh': '基于机器学习和LSTM模型的篮球职业生涯衰老趋势预测'}
{'arxiv_id': 'arXiv:2509.25792', 'title': 'PUREVQ-GAN: Defending Data Poisoning Attacks through Vector-Quantized Bottlenecks', 'authors': 'Alexander Branch, Omead Pooladzandi, Radin Khosraviani, Sunay Gajanan Bhat, Jeffrey Jiang, Gregory Pottie', 'link': 'https://arxiv.org/abs/2509.25792', 'abstract': 'We introduce PureVQ-GAN, a defense against data poisoning that forces backdoor triggers through a discrete bottleneck using Vector-Quantized VAE with GAN discriminator. By quantizing poisoned images through a learned codebook, PureVQ-GAN destroys fine-grained trigger patterns while preserving semantic content. A GAN discriminator ensures outputs match the natural image distribution, preventing reconstruction of out-of-distribution perturbations. On CIFAR-10, PureVQ-GAN achieves 0% poison success rate (PSR) against Gradient Matching and Bullseye Polytope attacks, and 1.64% against Narcissus while maintaining 91-95% clean accuracy. Unlike diffusion-based defenses requiring hundreds of iterative refinement steps, PureVQ-GAN is over 50x faster, making it practical for real training pipelines.', 'abstract_zh': 'PureVQ-GAN：一种通过离散瓶颈利用向量量化VAE和GAN判别器的抗数据投毒防御方法', 'title_zh': 'PUREVQ-GAN：通过向量量化瓶颈防御数据投毒攻击'}
{'arxiv_id': 'arXiv:2509.25781', 'title': 'Deontic Argumentation', 'authors': 'Guido Governatori, Antonino Rotolo', 'link': 'https://arxiv.org/abs/2509.25781', 'abstract': 'We address the issue of defining a semantics for deontic argumentation that supports weak permission. Some recent results show that grounded semantics do not support weak permission when there is a conflict between two obligations. We provide a definition of Deontic Argumentation Theory that accounts for weak permission, and we recall the result about grounded semantics. Then, we propose a new semantics that supports weak permission.', 'abstract_zh': '我们探讨了一种支持弱许可的义务论论证语义的定义问题。一些近期的研究结果显示，当两种义务发生冲突时， grounded 语义不支持弱许可。我们提供了一种义务论论证理论的定义，以涵盖弱许可，并回顾了关于 grounded 语义的结果，然后提出了一种新的支持弱许可的语义。', 'title_zh': '规范道义论辩'}
{'arxiv_id': 'arXiv:2509.25758', 'title': 'Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training', 'authors': 'Yein Park, Minbyul Jeong, Jaewoo Kang', 'link': 'https://arxiv.org/abs/2509.25758', 'abstract': 'The remarkable capabilities of modern large reasoning models are largely unlocked through post-training techniques such as supervised fine-tuning and reinforcement learning. However, the architectural mechanisms behind such improvements remain largely opaque. In this work, we use circuit analysis to demonstrate that post-training for complex reasoning sparks the emergence of novel, functionally specialized attention heads. These heads collectively support structured reasoning and computation. Our comparative analysis across Qwen families and DeepSeek-distilled model reveals that these emergent heads evolve differently under different training regimes. Distillation and SFT foster a cumulative addition of stable reasoning heads. In contrast, group relative policy optimization operates in a dynamic search mode: relatively few attention heads are iteratively activated, evaluated, and pruned, with their survival closely tracking fluctuations in the task reward signal. Furthermore, we find that controllable think on/off models do not possess dedicated thinking heads. Instead, turning off explicit reasoning triggers a broader-but less efficient-set of compensatory heads. Through ablation and qualitative analyses, we connect these circuit-level dynamics to a crucial performance trade-off: strengthened heads enable sophisticated problem-solving strategies for difficult problems but can also introduce over-thinking failure modes, such as calculation errors or logical loops on simpler tasks. These findings connect circuit-level dynamics to macro-level performance, identifying an inherent tension where complex reasoning comes at the cost of elementary computations. More broadly, our work points to future directions for training policy design, emphasizing the need to balance the development of effective reasoning strategies with the assurance of reliable, flawless execution.', 'abstract_zh': '现代大型推理模型通过后训练技术如监督微调和强化学习展现了显著的能力，但其背后的架构机制仍 largely opaque。在此工作中，我们通过电路分析展示了对于复杂推理的后训练激发了功能特化的新型注意力头的出现。这些头共同支持结构化的推理和计算。我们跨Qwen家族和DeepSeek精简模型的比较分析表明，在不同的训练制度下，这些涌现的头具有不同的进化方式。精简和监督微调促进了稳定推理头的逐步累积增加。相比之下，群体相对策略优化采用动态搜索模式：较少的注意力头被迭代激活、评估和修剪，其生存状态紧密跟踪任务奖励信号的变化。此外，我们发现可控的开/关思考模型不具备专门的思考头。相反，关闭显式推理会触发一组更为广泛但效率较低的补偿头。通过消除和定性分析，我们将这些电路层面的动力学与一个关键的性能权衡联系起来：强化的头可以使复杂的难题解决策略得以加强，但也可能引入过犹不及的失败模式，例如简单任务中的计算错误或逻辑循环。这些发现将电路层面的动力学与宏观层面的性能联系起来，揭示了复杂推理与基础计算之间固有的张力。更广泛地，我们的工作指出了未来训练策略设计的方向，强调了在发展有效的推理策略与确保可靠、无瑕疵执行之间需要找到平衡。', 'title_zh': '思考激发!: 论推理模型在后训练期间涌现的注意力头'}
{'arxiv_id': 'arXiv:2509.25751', 'title': 'Cooperative Autonomous Driving in Diverse Behavioral Traffic: A Heterogeneous Graph Reinforcement Learning Approach', 'authors': 'Qi Liu, Xueyuan Li, Zirui Li, Juhui Gim', 'link': 'https://arxiv.org/abs/2509.25751', 'abstract': 'Navigating heterogeneous traffic environments with diverse driving styles poses a significant challenge for autonomous vehicles (AVs) due to their inherent complexity and dynamic interactions. This paper addresses this challenge by proposing a heterogeneous graph reinforcement learning (GRL) framework enhanced with an expert system to improve AV decision-making performance. Initially, a heterogeneous graph representation is introduced to capture the intricate interactions among vehicles. Then, a heterogeneous graph neural network with an expert model (HGNN-EM) is proposed to effectively encode diverse vehicle features and produce driving instructions informed by domain-specific knowledge. Moreover, the double deep Q-learning (DDQN) algorithm is utilized to train the decision-making model. A case study on a typical four-way intersection, involving various driving styles of human vehicles (HVs), demonstrates that the proposed method has superior performance over several baselines regarding safety, efficiency, stability, and convergence rate, all while maintaining favorable real-time performance.', 'abstract_zh': '使用异构图强化学习框架增强专家系统以应对多样化驾驶风格和复杂交通环境的自动驾驶车辆决策挑战', 'title_zh': '多样行为交通中协作自动驾驶：一种异构图强化学习方法'}
{'arxiv_id': 'arXiv:2509.25693', 'title': 'ScheduleMe: Multi-Agent Calendar Assistant', 'authors': 'N. de Silva, S. Perera, K. L. A. A. Nimasha, I. D. S. Fernando, R.K.A.O. Wijerathne', 'link': 'https://arxiv.org/abs/2509.25693', 'abstract': 'Recent advancements in LLMs have contributed to the rise of advanced conversational assistants that can assist with user needs through natural language conversation. This paper presents a ScheduleMe, a multi-agent calendar assistant for users to manage google calendar events in natural language. The system uses a graph-structured coordination mechanism where a central supervisory agent supervises specialized task agents, allowing modularity, conflicts resolution, and context-aware interactions to resolve ambiguities and evaluate user commands. This approach sets an example of how structured reasoning and agent cooperation might convince operators to increase the usability and flexibility of personal calendar assistant tools.', 'abstract_zh': 'Recent advancements in LLMs have contributed to the rise of advanced conversational assistants that can assist with user needs through natural language conversation. This paper presents ScheduleMe，一个基于多智能体的日历助手，帮助用户通过自然语言管理Google日历事件。该系统采用图结构协调机制，其中中央监督智能体监督专门的任务智能体，实现模块化、冲突解决和上下文相关交互，以解决歧义并评估用户命令。该方法为如何通过结构化推理和智能体合作提高个人日历助手工具的可用性和灵活性提供了范例。', 'title_zh': 'ScheduleMe: 多代理日程助手'}
{'arxiv_id': 'arXiv:2509.25672', 'title': 'SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation', 'authors': 'Hasan Alp Caferoğlu, Mehmet Serhat Çelik, Özgür Ulusoy', 'link': 'https://arxiv.org/abs/2509.25672', 'abstract': 'Translating natural language questions into SQL has become a core challenge in enabling non-technical users to query databases. While recent work has explored large-scale synthetic data generation to improve model performance through post-training, most efforts emphasize cross-domain generalization. This leaves a gap for real-world enterprise scenarios, where models need to specialize to a single database schema and organizations require to be able to evaluate their Text-to-SQL systems on their own databases. To address this, we introduce SING-SQL, a fully automated two-stage framework for generating high-quality, high-coverage synthetic Text-to-SQL data for any target database, without relying on SQL logs or manual annotations. Our approach hierarchically partitions a database schema into sub-schemas, synthesizes SQL queries across multiple complexity levels, and applies a quality-aware pipeline that includes LLM-as-a-judge validation, executability checks, automatic repair, and column balancing. We further release SingSQL-LM, a family of compact language models fine-tuned on the synthetic data, achieving strong in-domain generalization. On the subset of the BIRD benchmark, SingSQL-LM-3B-R64 reaches 82.87% Soft F1 and 73.03% EX upper bound with 32 candidates, outperforming the best 3B-scale baseline by +16.21 in Soft F1 and +12.36 in EX. At the 1.5B scale, SingSQL-LM-1.5B-R64 improves over prior systems by +9.30 in Soft F1 and +4.49 in EX. On synthetic evaluation sets, SingSQL-LMs exceed prior systems by wide margins, establishing state-of-the-art performance among open models at comparable scales. Our study of context management strategies reveals that schema-free fine-tuning combined with schema-only inference provides the most robust results. These findings establish SING-SQL as a scalable, database-agnostic paradigm for producing and evaluating enterprise-grade Text-to-SQL systems.', 'abstract_zh': '自然语言问题到SQL的翻译已成为使非技术人员能够查询数据库的核心挑战。虽然近期工作探索了大规模合成数据生成以通过后训练提高模型性能，但大多努力强调跨领域的一般化。这为现实世界的企业场景留下了空白，在这些场景中，模型需要专门针对单一数据库结构，组织需要能够在其自己的数据库上评估其Text-to-SQL系统。为解决这一问题，我们提出了SING-SQL，这是一种完全自动化的两阶段框架，用于为任何目标数据库生成高质量、高覆盖的合成Text-to-SQL数据，而不依赖于SQL日志或人工标注。我们的方法将数据库模式层次化地划分为子模式，在多个复杂性级别上合成SQL查询，并应用质量感知流水线，包括LLM作为裁判的验证、可执行性检查、自动修复和列配平。此外，我们发布了SingSQL-LM，这是一个在合成数据上微调的家庭紧凑型语言模型，实现了强领域内一般化。在BIRD基准的一部分上，SingSQL-LM-3B-R64以32个候选者达到了82.87%的Soft F1和73.03%的EX上限，优于最好的3B规模基线+16.21在Soft F1和+12.36在EX上。在1.5B规模下，SingSQL-LM-1.5B-R64超过先前系统+9.30在Soft F1和+4.49在EX上。在合成评估集上，SingSQL-LMs超出先前系统很大margin，建立了可比规模下开放模型的领先性能。我们关于上下文管理策略的研究表明，schema-free微调结合仅依赖于schema的推理提供了最稳健的结果。这些发现确立了SING-SQL作为一种可扩展的、数据库无关的生产Text-to-SQL系统的范式。', 'title_zh': 'SING-SQL：一种领域内文本到SQL翻译的合成数据生成框架'}
{'arxiv_id': 'arXiv:2509.25662', 'title': 'On Explaining Proxy Discrimination and Unfairness in Individual Decisions Made by AI Systems', 'authors': 'Belona Sonna, Alban Grastien', 'link': 'https://arxiv.org/abs/2509.25662', 'abstract': 'Artificial intelligence (AI) systems in high-stakes domains raise concerns about proxy discrimination, unfairness, and explainability. Existing audits often fail to reveal why unfairness arises, particularly when rooted in structural bias. We propose a novel framework using formal abductive explanations to explain proxy discrimination in individual AI decisions. Leveraging background knowledge, our method identifies which features act as unjustified proxies for protected attributes, revealing hidden structural biases. Central to our approach is the concept of aptitude, a task-relevant property independent of group membership, with a mapping function aligning individuals of equivalent aptitude across groups to assess fairness substantively. As a proof of concept, we showcase the framework with examples taken from the German credit dataset, demonstrating its applicability in real-world cases.', 'abstract_zh': '高风险领域中的人工智能系统引发了关于代理歧视、不公正和可解释性的关切。现有审计往往无法揭示不公正的原因，尤其是当其根植于结构性偏见时。我们提出了一种新的框架，利用形式归纳解释来解释个体AI决策中的代理歧视。借助背景知识，我们的方法识别出哪些特征作为受保护属性的不合理代理，并揭示隐藏的结构性偏见。我们方法的核心概念是能力，这是一个与群体成员身份无关的任务相关属性，并通过映射函数将等同能力的个体在不同群体中进行匹配，以实质上评估公平性。作为概念验证，我们通过使用德国信贷数据集中的示例展示了该框架的应用，证明了其在实际案例中的适用性。', 'title_zh': '关于解释代理歧视和AI系统个体决策中的不公平现象'}
{'arxiv_id': 'arXiv:2509.25651', 'title': 'AutoLabs: Cognitive Multi-Agent Systems with Self-Correction for Autonomous Chemical Experimentation', 'authors': 'Gihan Panapitiya, Emily Saldanha, Heather Job, Olivia Hess', 'link': 'https://arxiv.org/abs/2509.25651', 'abstract': 'The automation of chemical research through self-driving laboratories (SDLs) promises to accelerate scientific discovery, yet the reliability and granular performance of the underlying AI agents remain critical, under-examined challenges. In this work, we introduce AutoLabs, a self-correcting, multi-agent architecture designed to autonomously translate natural-language instructions into executable protocols for a high-throughput liquid handler. The system engages users in dialogue, decomposes experimental goals into discrete tasks for specialized agents, performs tool-assisted stoichiometric calculations, and iteratively self-corrects its output before generating a hardware-ready file. We present a comprehensive evaluation framework featuring five benchmark experiments of increasing complexity, from simple sample preparation to multi-plate timed syntheses. Through a systematic ablation study of 20 agent configurations, we assess the impact of reasoning capacity, architectural design (single- vs. multi-agent), tool use, and self-correction mechanisms. Our results demonstrate that agent reasoning capacity is the most critical factor for success, reducing quantitative errors in chemical amounts (nRMSE) by over 85% in complex tasks. When combined with a multi-agent architecture and iterative self-correction, AutoLabs achieves near-expert procedural accuracy (F1-score > 0.89) on challenging multi-step syntheses. These findings establish a clear blueprint for developing robust and trustworthy AI partners for autonomous laboratories, highlighting the synergistic effects of modular design, advanced reasoning, and self-correction to ensure both performance and reliability in high-stakes scientific applications. Code: this https URL', 'abstract_zh': '通过自主驾驶实验室（SDLs）实现化学研究的自动化有望加速科学发现，但底层AI代理的可靠性和粒度性能仍然是亟待深入研究的关键挑战。在本文中，我们介绍了AutoLabs，这是一种自我纠正的多代理架构，旨在自主将自然语言指令转换为高通量液体处理设备可执行的协议。该系统通过对话与用户互动，将实验目标分解为专门代理执行的离散任务，进行工具辅助的化学计量计算，并迭代自我纠正输出，最终生成硬件兼容的文件。我们提出了一种全面的评估框架，包括从简单样品准备到多板定时合成的五个复杂度递增的基准实验。通过系统地研究20种代理配置，我们评估了推理能力、架构设计（单代理 vs. 多代理）、工具使用和自我纠正机制的影响。结果显示，代理的推理能力是最关键的因素，能够大幅减少复杂任务中的定量错误（nRMSE降低超过85%）。结合多代理架构和迭代自我纠正机制，AutoLabs在复杂多步合成中的过程准确性（F1分数>0.89）几乎达到专家水平。这些发现为开发自主实验室中可靠和可信赖的AI伙伴提供了明确的蓝图，突显了模块化设计、高级推理和自我纠正在确保高风险科学应用中的性能和可靠性方面的协同效应。代码：见此处。', 'title_zh': 'AutoLabs: 具有自我纠正的认知多智能体系统及其在自主化学实验中的应用'}
{'arxiv_id': 'arXiv:2509.25613', 'title': 'SMS: Self-supervised Model Seeding for Verification of Machine Unlearning', 'authors': 'Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shui Yu', 'link': 'https://arxiv.org/abs/2509.25613', 'abstract': "Many machine unlearning methods have been proposed recently to uphold users' right to be forgotten. However, offering users verification of their data removal post-unlearning is an important yet under-explored problem. Current verifications typically rely on backdooring, i.e., adding backdoored samples to influence model performance. Nevertheless, the backdoor methods can merely establish a connection between backdoored samples and models but fail to connect the backdoor with genuine samples. Thus, the backdoor removal can only confirm the unlearning of backdoored samples, not users' genuine samples, as genuine samples are independent of backdoored ones. In this paper, we propose a Self-supervised Model Seeding (SMS) scheme to provide unlearning verification for genuine samples. Unlike backdooring, SMS links user-specific seeds (such as users' unique indices), original samples, and models, thereby facilitating the verification of unlearning genuine samples. However, implementing SMS for unlearning verification presents two significant challenges. First, embedding the seeds into the service model while keeping them secret from the server requires a sophisticated approach. We address this by employing a self-supervised model seeding task, which learns the entire sample, including the seeds, into the model's latent space. Second, maintaining the utility of the original service model while ensuring the seeding effect requires a delicate balance. We design a joint-training structure that optimizes both the self-supervised model seeding task and the primary service task simultaneously on the model, thereby maintaining model utility while achieving effective model seeding. The effectiveness of the proposed SMS scheme is evaluated through extensive experiments, which demonstrate that SMS provides effective verification for genuine sample unlearning, addressing existing limitations.", 'abstract_zh': '自监督模型播种方案（SMS）：提供真正样本删除验证', 'title_zh': 'SMS：自监督模型初始化方法用于机器遗忘验证'}
{'arxiv_id': 'arXiv:2509.25601', 'title': 'Echoes of Humanity: Exploring the Perceived Humanness of AI Music', 'authors': 'Flavio Figueiredo, Giovanni Martinelli, Henrique Sousa, Pedro Rodrigues, Frederico Pedrosa, Lucas N. Ferreira', 'link': 'https://arxiv.org/abs/2509.25601', 'abstract': "Recent advances in AI music (AIM) generation services are currently transforming the music industry. Given these advances, understanding how humans perceive AIM is crucial both to educate users on identifying AIM songs, and, conversely, to improve current models. We present results from a listener-focused experiment aimed at understanding how humans perceive AIM. In a blind, Turing-like test, participants were asked to distinguish, from a pair, the AIM and human-made song. We contrast with other studies by utilizing a randomized controlled crossover trial that controls for pairwise similarity and allows for a causal interpretation. We are also the first study to employ a novel, author-uncontrolled dataset of AIM songs from real-world usage of commercial models (i.e., Suno). We establish that listeners' reliability in distinguishing AIM causally increases when pairs are similar. Lastly, we conduct a mixed-methods content analysis of listeners' free-form feedback, revealing a focus on vocal and technical cues in their judgments.", 'abstract_zh': '近期AI音乐生成服务的进展正在重塑音乐行业。鉴于这些进展，理解人类如何感知AI音乐至关重要，这不仅有助于教育用户识别AI音乐歌曲，而且还可以改进当前模型。我们通过一项以听众为中心的实验，旨在理解人类如何感知AI音乐。在一项类似于图灵测试的盲测中，参与者被要求从一组中分辨出AI生成和人类制作的歌曲。我们通过随机对照交叉试验来对比其他研究，这种试验可以控制成对相似性并允许因果解释。我们也是首次使用来自实际使用商业模型（例如Suno）的AI歌曲新型作者不可控数据集进行此类研究。我们证实，当成对相似时，听众区分AI音乐的可靠性会因果地提高。最后，我们进行了混合法内容分析，分析听众的自由反馈，揭示了他们在判断中关注于声音和技术线索。', 'title_zh': '人类之声：探索AI音乐的感知人性化程度'}
{'arxiv_id': 'arXiv:2509.25591', 'title': 'Building the EHR Foundation Model via Next Event Prediction', 'authors': 'Zekai Chen, Arda Pekis, Kevin Brown', 'link': 'https://arxiv.org/abs/2509.25591', 'abstract': "Electronic Health Records (EHRs) contain rich temporal dynamics that conventional encoding approaches fail to adequately capture. While Large Language Models (LLMs) show promise for EHR modeling, they struggle to reason about sequential clinical events and temporal dependencies. We propose Next Event Prediction (NEP), a framework that enhances LLMs' temporal reasoning through autoregressive fine-tuning on clinical event sequences. By reformulating EHRs as timestamped event chains and predicting future medical events, NEP explicitly models disease progression patterns and causal relationships. Extensive evaluations across oncology survival prediction and clinical diagnosis tasks demonstrate NEP's superiority, outperforming specialized EHR models by 4.6% AUROC and general-purpose LLMs by 7.2% C-index in temporal reasoning tasks. Our analyses reveal dual benefits: state-of-the-art prediction accuracy combined with clinically interpretable attention patterns that align with known disease pathways.", 'abstract_zh': '电子健康记录(EHRs)包含丰富的时序动态，而传统的编码方法难以充分捕捉。虽然大型语言模型(LLMs)在EHR建模方面显示出潜力，但在处理临床事件序列和时序依赖关系方面存在挑战。我们提出了一种Next Event Prediction (NEP)框架，通过自回归微调增强LLMs的时序推理能力。通过对临床事件序列进行时间戳事件链的重新建模和预测未来医疗事件，NEP明确地建模了疾病进展模式和因果关系。在肿瘤生存预测和临床诊断任务的广泛评估中，NEP表现出优越性，在时序推理任务中，它的AUROC比专门的EHR模型高4.6%，C-index比通用的LLMs高7.2%。我们的分析揭示了双重好处：最新的预测准确性与临床可解释的注意力模式相结合，这些模式与已知的疾病途径相符。', 'title_zh': '基于下个事件预测的EHR基础模型构建'}
{'arxiv_id': 'arXiv:2509.25562', 'title': 'IRIS: Intrinsic Reward Image Synthesis', 'authors': 'Yihang Chen, Yuanhao Ban, Yunqi Hong, Cho-Jui Hsieh', 'link': 'https://arxiv.org/abs/2509.25562', 'abstract': 'Despite the success of Reinforcement Learning from Human Feedback (RLHF) in language reasoning, its application to autoregressive Text-to-Image (T2I) generation is often constrained by the limited availability of human preference data. This paper explores how an autoregressive T2I model can learn from internal signals without relying on external rewards or labeled data. Contrary to recent findings in text generation, we show that maximizing self-uncertainty, rather than self-certainty, improves image generation. We observe that this is because autoregressive T2I models with low uncertainty tend to generate simple and uniform images, which are less aligned with human preferences. Based on these observations, we propose IRIS (Intrinsic Reward Image Synthesis), the first framework to improve autoregressive T2I models with reinforcement learning using only an intrinsic reward. Empirical results demonstrate that applying IRIS to autoregressive T2I models achieves performance that is competitive with or superior to external rewards.', 'abstract_zh': '尽管强化学习从人类反馈（RLHF）在语言推理方面取得了成功，但其在自回归文本到图像（T2I）生成中的应用常受限于人类偏好数据的有限可用性。本文探讨了自回归T2I模型如何通过内部信号学习，而不依赖外部奖励或标记数据。与近期文本生成的研究发现相反，我们证明最大化自我不确定性而非自我确定性能提高图像生成质量。我们观察到，这是因为低不确定性自回归T2I模型倾向于生成简单且均匀的图像，这些图像不太符合人类偏好。基于这些观察，我们提出了IRIS（内在奖励图像合成）框架，这是首个仅使用内在奖励通过强化学习改进自回归T2I模型的方法。实证结果表明，将IRIS应用于自回归T2I模型，其性能与外部奖励相当或更优。', 'title_zh': 'IRIS: 内在奖励图像合成'}
{'arxiv_id': 'arXiv:2509.25552', 'title': 'Evaluating Foundation Models with Pathological Concept Learning for Kidney Cancer', 'authors': 'Shangqi Gao, Sihan Wang, Yibo Gao, Boming Wang, Xiahai Zhuang, Anne Warren, Grant Stewart, James Jones, Mireia Crispin-Ortuzar', 'link': 'https://arxiv.org/abs/2509.25552', 'abstract': 'To evaluate the translational capabilities of foundation models, we develop a pathological concept learning approach focused on kidney cancer. By leveraging TNM staging guidelines and pathology reports, we build comprehensive pathological concepts for kidney cancer. Then, we extract deep features from whole slide images using foundation models, construct pathological graphs to capture spatial correlations, and trained graph neural networks to identify these concepts. Finally, we demonstrate the effectiveness of this approach in kidney cancer survival analysis, highlighting its explainability and fairness in identifying low- and high-risk patients. The source code has been released by this https URL.', 'abstract_zh': '为了评估基础模型的迁移能力，我们提出了一种专注于肾癌的病理概念学习方法。通过利用TNM分期指南和病理报告，我们构建了全面的肾癌病理概念。然后，我们使用基础模型从全切片图像中提取深层特征，构建病理图以捕获空间相关性，并训练图神经网络以识别这些概念。最后，我们在肾癌生存分析中展示了该方法的有效性，突出了其在识别低风险和高风险患者方面的解释性和公平性。源代码可从此链接获取：https://xxxxxx。', 'title_zh': '基于病理概念学习的肾癌基础模型评估'}
{'arxiv_id': 'arXiv:2509.25475', 'title': 'TDHook: A Lightweight Framework for Interpretability', 'authors': 'Yoann Poupart', 'link': 'https://arxiv.org/abs/2509.25475', 'abstract': 'Interpretability of Deep Neural Networks (DNNs) is a growing field driven by the study of vision and language models. Yet, some use cases, like image captioning, or domains like Deep Reinforcement Learning (DRL), require complex modelling, with multiple inputs and outputs or use composable and separated networks. As a consequence, they rarely fit natively into the API of popular interpretability frameworks. We thus present TDHook, an open-source, lightweight, generic interpretability framework based on $\\texttt{tensordict}$ and applicable to any $\\texttt{torch}$ model. It focuses on handling complex composed models which can be trained for Computer Vision, Natural Language Processing, Reinforcement Learning or any other domain. This library features ready-to-use methods for attribution, probing and a flexible get-set API for interventions, and is aiming to bridge the gap between these method classes to make modern interpretability pipelines more accessible. TDHook is designed with minimal dependencies, requiring roughly half as much disk space as $\\texttt{transformer_lens}$, and, in our controlled benchmark, achieves up to a $\\times$2 speed-up over $\\texttt{captum}$ when running integrated gradients for multi-target pipelines on both CPU and GPU. In addition, to value our work, we showcase concrete use cases of our library with composed interpretability pipelines in Computer Vision (CV) and Natural Language Processing (NLP), as well as with complex models in DRL.', 'abstract_zh': '深度神经网络的可解释性：一种基于`tensordict`的开源轻量级通用框架', 'title_zh': 'TDHook: 一种轻量级可解释性框架'}
{'arxiv_id': 'arXiv:2509.25458', 'title': 'Plug-and-Play Emotion Graphs for Compositional Prompting in Zero-Shot Speech Emotion Recognition', 'authors': 'Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao', 'link': 'https://arxiv.org/abs/2509.25458', 'abstract': 'Large audio-language models (LALMs) exhibit strong zero-shot performance across speech tasks but struggle with speech emotion recognition (SER) due to weak paralinguistic modeling and limited cross-modal reasoning. We propose Compositional Chain-of-Thought Prompting for Emotion Reasoning (CCoT-Emo), a framework that introduces structured Emotion Graphs (EGs) to guide LALMs in emotion inference without fine-tuning. Each EG encodes seven acoustic features (e.g., pitch, speech rate, jitter, shimmer), textual sentiment, keywords, and cross-modal associations. Embedded into prompts, EGs provide interpretable and compositional representations that enhance LALM reasoning. Experiments across SER benchmarks show that CCoT-Emo outperforms prior SOTA and improves accuracy over zero-shot baselines.', 'abstract_zh': '大规模音频-语言模型在情感识别任务中表现出较强的零样本性能，但由于薄弱的副语言建模和有限的跨模态推理能力，在语音情感识别（SER）方面存在挑战。我们提出了情感推理的组成链式思考提示（CCoT-Emo）框架，该框架引入了结构化情感图（EGs）来指导大规模音频-语言模型进行情感推断而不进行微调。每个EG编码七个声学特征（例如，音高、语速、颤动、沙哑）、文本情绪、关键词以及跨模态关联。嵌入在提示中的EG提供了可解析和组成的表示，增强LALM的推理能力。在多个情感识别基准上的实验表明，CCoT-Emo优于先前的最佳方法，并且在零样本基线之上提高了准确性。', 'title_zh': '即插即用情感图用于零样本语音情感识别的组合提示生成'}
{'arxiv_id': 'arXiv:2509.25435', 'title': 'GESA: Graph-Enhanced Semantic Allocation for Generalized, Fair, and Explainable Candidate-Role Matching', 'authors': 'Rishi Ashish Shah, Shivaay Dhondiyal, Kartik Sharma, Sukriti Talwar, Saksham Jain, Sparsh Jain', 'link': 'https://arxiv.org/abs/2509.25435', 'abstract': 'Accurate, fair, and explainable allocation of candidates to roles represents a fundamental challenge across multiple domains including corporate hiring, academic admissions, fellowship awards, and volunteer placement systems. Current state-of-the-art approaches suffer from semantic inflexibility, persistent demographic bias, opacity in decision-making processes, and poor scalability under dynamic policy constraints. We present GESA (Graph-Enhanced Semantic Allocation), a comprehensive framework that addresses these limitations through the integration of domain-adaptive transformer embeddings, heterogeneous self-supervised graph neural networks, adversarial debiasing mechanisms, multi-objective genetic optimization, and explainable AI components. Our experimental evaluation on large-scale international benchmarks comprising 20,000 candidate profiles and 3,000 role specifications demonstrates superior performance with 94.5% top-3 allocation accuracy, 37% improvement in diversity representation, 0.98 fairness score across demographic cate- gories, and sub-second end-to-end latency. Additionally, GESA incorporates hybrid recommendation capabilities and glass-box explainability, making it suitable for deployment across diverse international contexts in industry, academia, and non-profit sectors.', 'abstract_zh': '准确、公平且可解释的求职者分配到角色的方案代表了包括企业招聘、学术录取、奖学金 award 和志愿者安置系统在内的多个领域的一项基本挑战。当前最先进的方法在语义灵活性、持久性人群偏差、决策过程透明度以及动态政策约束下的可扩展性方面存在局限。我们提出了一种名为 GESA（图增强语义分配）的综合框架，通过集成领域自适应变压器嵌入、异质自监督图神经网络、对抗去偏机制、多目标遗传优化以及可解释人工智能组件来解决这些局限。我们在包含 20,000 个求职者档案和 3,000 个角色规范的大型国际基准上的实验评估展示了出色的表现，包括 94.5% 的前三位分配准确率、37% 的多样性表示改进、跨人口类别达到 0.98 的公平评分，以及端到端亚秒级延迟。此外，GESA 具备混合推荐能力和玻璃盒解释性，使其适合在工业、学术和非营利部门等多元国际背景下部署。', 'title_zh': '基于图增强语义分配的通用、公平和可解释的候选项-角色匹配方法'}
{'arxiv_id': 'arXiv:2509.25434', 'title': 'The Open Syndrome Definition', 'authors': 'Ana Paula Gomes Ferreira, Aleksandar Anžel, Izabel Oliva Marcilio de Souza, Helen Hughes, Alex J Elliot, Jude Dzevela Kong, Madlen Schranz, Alexander Ullrich, Georges Hattab', 'link': 'https://arxiv.org/abs/2509.25434', 'abstract': "Case definitions are essential for effectively communicating public health threats. However, the absence of a standardized, machine-readable format poses significant challenges to interoperability, epidemiological research, the exchange of qualitative data, and the effective application of computational analysis methods, including artificial intelligence (AI). This complicates comparisons and collaborations across organizations and regions, limits data integration, and hinders technological innovation in public health. To address these issues, we propose the first open, machine-readable format for representing case and syndrome definitions. Additionally, we introduce the first comprehensive dataset of standardized case definitions and tools to convert existing human-readable definitions into machine-readable formats. We also provide an accessible online platform for browsing, analyzing, and contributing new definitions, available at this https URL. The Open Syndrome Definition format enables consistent, scalable use of case definitions across systems, unlocking AI's potential to strengthen public health preparedness and response. The source code for the format can be found at this https URL under the MIT license.", 'abstract_zh': '开放的综合征定义格式对于有效传达公共卫生威胁至关重要。然而，缺乏标准化和机器可读的格式阻碍了跨组织和地区的互操作性、流行病学研究、定性数据交换以及包括人工智能在内的计算分析方法的有效应用。为了应对这些问题，我们提出了首个开放的、机器可读的综合征和症状定义格式。此外，我们还介绍了首个标准化的综合征定义全面数据集及其工具，用于将现有的人类可读定义转换为机器可读格式。我们还提供了一个易于访问的在线平台，用于浏览、分析和贡献新定义，网址为this https URL。开放的综合征定义格式使得跨系统的病例定义使用保持一致和可扩展，从而发掘人工智能在增强公共卫生准备和响应方面的潜力。该格式的源代码可在MIT许可下从this https URL找到。', 'title_zh': '开放综合征定义'}
{'arxiv_id': 'arXiv:2509.25411', 'title': 'Boolean Satisfiability via Imitation Learning', 'authors': 'Zewei Zhang, Huan Liu, Yuanhao Yu, Jun Chen, Xiangyu Xu', 'link': 'https://arxiv.org/abs/2509.25411', 'abstract': 'We propose ImitSAT, a branching policy for conflict-driven clause learning (CDCL) solvers based on imitation learning for the Boolean satisfiability problem (SAT). Unlike previous methods that predict instance-level signals to improve CDCL branching indirectly, or rely on reinforcement learning and insufficient CDCL information to enhance branching, ImitSAT learns from expert KeyTrace that collapses a full run into the sequence of surviving decisions. Replaying a KeyTrace on the same instance is nearly conflict-free, providing dense decision-level supervision and directly reducing propagations -- the dominant contributor to wall-clock time. This prefix-conditioned supervision enables ImitSAT to reproduce high-quality branches without exploration, yielding faster convergence, stable training, and seamless integration into CDCL. Extensive experiments demonstrate that ImitSAT reduces propagation counts and runtime, outperforming state-of-the-art learned approaches. We released the source code and trained model at this https URL', 'abstract_zh': '我们提出ImitSAT，一种基于imitation learning的针对Boolean可满足性问题（SAT）的冲突驱动子句学习（CDCL）求解器的分支策略。不同于以往方法通过预测实例级信号间接改进CDCL分支或依赖强化学习和不足的CDCL信息来增强分支，ImitSAT从专家KeyTrace中学习，将完整运行压缩为幸存决策序列。在相同实例上回放KeyTrace几乎无冲突，提供密集的决策级监督，直接减少传播——这是壁钟时间的主要贡献者。这种前缀条件监督使ImitSAT能够在不探索的情况下生成高质量分支，实现更快的收敛、稳定的训练以及无缝集成到CDCL中。广泛实验表明，ImitSAT减少了传播次数和运行时间，并优于最新的学习方法。我们在https://这个链接发布了源代码和训练模型。', 'title_zh': '布尔可满足性通过模仿学习'}
{'arxiv_id': 'arXiv:2509.25361', 'title': 'Structural Reward Model: Enhancing Interpretability, Efficiency, and Scalability in Reward Modeling', 'authors': 'Xiaoyu Liu, Di Liang, Hongyu Shan, Peiyang Liu, Yonghao Liu, Muling Wu, Yuntao Li, Xianjie Wu, LI Miao, Jiangrong Shen, Minlong Peng', 'link': 'https://arxiv.org/abs/2509.25361', 'abstract': 'Reward Models (RMs) are key components for evaluating and guiding language model outputs. However, traditional scalar RMs often struggle with incorporating contextual and background information during inference, leading to incomplete evaluations. Generative RMs (GRMs) attempt to address these limitations by generating intermediate reasoning steps. Yet, their uncontrolled black-box nature and inefficiency due to sequential decoding hinder their industrial deployment. Industrial scenarios, such as search and recommendation systems, often involve single-domain tasks requiring evaluation along specific dimensions. In such contexts, diagnosing "bad cases" necessitates structured feedback to identify and optimize dimension-specific issues. In this paper, we propose the Structural Reward Model (SRM), a modular and interpretable framework integrating side-branch models as auxiliary feature generators. By introducing fine-grained dimensions, SRMs enable interpretable and efficient evaluation, facilitating targeted diagnostics and optimization. This structured approach ensures adaptability and scalability for industrial applications. Through comprehensive experiments, we demonstrate that SRMs outperform scalar RMs and GRMs in robustness and alignment with human preferences. The modular design further supports efficient optimization for practical scenarios, allowing SRM to provide a practical reward modeling solution for industry.', 'abstract_zh': '结构化奖励模型：一种可解释且高效的框架', 'title_zh': '结构奖励模型：增强奖励建模的可解释性、效率和扩展性'}
{'arxiv_id': 'arXiv:2509.25343', 'title': 'Spontaneous High-Order Generalization in Neural Theory-of-Mind Networks', 'authors': 'Yiming Wang, Rui Wang', 'link': 'https://arxiv.org/abs/2509.25343', 'abstract': 'Theory-of-Mind (ToM) is a core human cognitive capacity for attributing mental states to self and others. Wimmer and Perner demonstrated that humans progress from first- to higher-order ToM within a short span, completing this development before formal education or advanced skill acquisition. In contrast, neural networks represented by autoregressive language models progress from first- to higher-order ToM only alongside gains in advanced skills like reasoning, leaving open whether their trajectory can unfold independently, as in humans. In this research, we provided evidence that neural networks could spontaneously generalize from first- to higher-order ToM without relying on advanced skills. We introduced a neural Theory-of-Mind network (ToMNN) that simulated a minimal cognitive system, acquiring only first-order ToM competence. Evaluations of its second- and third-order ToM abilities showed accuracies well above chance. Also, ToMNN exhibited a sharper decline when generalizing from first- to second-order ToM than from second- to higher orders, and its accuracy decreased with greater task complexity. These perceived difficulty patterns were aligned with human cognitive expectations. Furthermore, the universality of results was confirmed across different parameter scales. Our findings illuminate machine ToM generalization patterns and offer a foundation for developing more human-like cognitive systems.', 'abstract_zh': '神经网络能否自发地从一阶心智理论自发泛化到高阶心智理论：一项基于神经心智理论网络的研究', 'title_zh': '自发的高阶概括能力在神经心智理论网络中的表现'}
{'arxiv_id': 'arXiv:2509.25301', 'title': 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution', 'authors': 'Tianrui Qin, Qianben Chen, Sinuo Wang, He Xing, King Zhu, He Zhu, Dingfeng Shi, Xinxin Liu, Ge Zhang, Jiaheng Liu, Yuchen Eleanor Jiang, Xitong Gao, Wangchunshu Zhou', 'link': 'https://arxiv.org/abs/2509.25301', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks when equipped with external tools. However, current frameworks predominantly rely on sequential processing, leading to inefficient execution particularly for tasks requiring extensive tool interaction. This paper introduces Flash-Searcher, a novel parallel agent reasoning framework that fundamentally reimagines the execution paradigm from sequential chains to directed acyclic graphs (DAGs). Flash-Searcher decomposes complex tasks into subtasks with explicit dependencies, enabling concurrent execution of independent reasoning paths while maintaining logical constraints. Through dynamic workflow optimization, our framework continuously refines the execution graph based on intermediate results, effectively integrating summary module. Comprehensive evaluations across multiple benchmarks demonstrate that Flash-Searcher consistently outperforms existing approaches. Specifically, it achieves 67.7% accuracy on BrowseComp and 83% on xbench-DeepSearch, while reducing agent execution steps by up to 35% compared to current frameworks. Furthermore, when distilling this parallel reasoning pipeline into single models, we observe substantial performance gains across diverse backbone architectures, underscoring the generalizability of our methodology. Our work thus represents a significant advance in agent architecture design, offering a more scalable and efficient paradigm for complex reasoning tasks.', 'abstract_zh': '大型语言模型（LLMs）在配备外部工具时展示了在复杂推理任务中的卓越能力。然而，当前框架主要依赖于顺序处理，这在需要大量工具交互的任务中导致了低效的执行。本文介绍了Flash-Searcher，这是一种新颖的并行代理推理框架，从根本上重新设想了从顺序链到有向无环图（DAGs）的执行范式。Flash-Searcher将复杂任务分解为具有明确依赖关系的子任务，同时允许并行执行独立的推理路径并保持逻辑约束。通过动态工作流优化，我们的框架基于中间结果不断细化执行图，有效地整合了总结模块。在多个基准测试中的全面评估显示，Flash-Searcher 一贯优于现有方法。具体而言，它在BrowseComp中达到了67.7%的准确率，在xbench-DeepSearch中达到了83%，相比当前框架将代理执行步骤减少了多达35%。此外，当将这种并行推理管道精简为单一模型时，我们观察到在各种骨干架构下都有显著的性能提升，突显了我们方法的普适性。因此，我们的工作代表了代理架构设计的重大进展，提供了一种更 scalable 和高效的复杂推理任务范式。', 'title_zh': 'Flash-Searcher: 基于DAG并行执行的快速有效网页代理'}
{'arxiv_id': 'arXiv:2509.25299', 'title': 'ID-RAG: Identity Retrieval-Augmented Generation for Long-Horizon Persona Coherence in Generative Agents', 'authors': "Daniel Platnick, Mohamed E. Bengueddache, Marjan Alirezaie, Dava J. Newman, Alex ''Sandy'' Pentland, Hossein Rahnama", 'link': 'https://arxiv.org/abs/2509.25299', 'abstract': "Generative agents powered by language models are increasingly deployed for long-horizon tasks. However, as long-term memory context grows over time, they struggle to maintain coherence. This deficiency leads to critical failures, including identity drift, ignoring established beliefs, and the propagation of hallucinations in multi-agent systems. To mitigate these challenges, this paper introduces Identity Retrieval-Augmented Generation (ID-RAG), a novel mechanism designed to ground an agent's persona and persistent preferences in a dynamic, structured identity model: a knowledge graph of core beliefs, traits, and values. During the agent's decision loop, this model is queried to retrieve relevant identity context, which directly informs action selection. We demonstrate this approach by introducing and implementing a new class of ID-RAG enabled agents called Human-AI Agents (HAis), where the identity model is inspired by the Chronicle structure used in Perspective-Aware AI, a dynamic knowledge graph learned from a real-world entity's digital footprint. In social simulations of a mayoral election, HAis using ID-RAG outperformed baseline agents in long-horizon persona coherence - achieving higher identity recall across all tested models by the fourth timestep - and reduced simulation convergence time by 19% (GPT-4o) and 58% (GPT-4o mini). By treating identity as an explicit, retrievable knowledge structure, ID-RAG offers a foundational approach for developing more temporally coherent, interpretable, and aligned generative agents. Our code is open-source and available at: this https URL.", 'abstract_zh': '基于语言模型的生成代理在执行长期任务时越来越普遍。然而，随着时间的推移，长期记忆上下文的增加使得它们难以保持连贯性。这种缺陷导致关键故障，包括身份漂移、忽略既定信念以及多代理系统中幻觉的传播。为应对这些挑战，本文引入了一种名为Identity Retrieval-Augmented Generation (ID-RAG)的新机制，该机制旨在通过动态结构化身份模型——一个核心信念、特质和价值观的知识图谱——将代理的人格和持久偏好进行落地。在代理的决策循环中，该模型被查询以检索相关身份上下文，直接指导行动的选取。我们通过引入并实施一种名为Human-AI Agents (HAis)的新类别的ID-RAG增强代理展示了这一方法，其中身份模型借鉴了在Perspective-Aware AI中使用的Chronicle结构，在现实世界实体的数字足迹中学习动态知识图谱。在市政选举的社会模拟中，使用ID-RAG的HAis在长期任务的人格连贯性方面优于基线代理——所有测试模型在第四时间步实现了更高的身份回溯，并分别将模拟收敛时间减少了19%（GPT-4o）和58%（GPT-4o mini）。通过将身份视为明确可检索的知识结构，ID-RAG为开发更具有时间连贯性、可解释性和对齐的生成代理提供了基础方法。我们的代码已开源，可从以下链接获取：this https URL。', 'title_zh': 'ID-RAG: 基于身份检索增强生成的长时个人一致性方法'}
{'arxiv_id': 'arXiv:2509.25250', 'title': 'Memory Management and Contextual Consistency for Long-Running Low-Code Agents', 'authors': 'Jiexi Xu', 'link': 'https://arxiv.org/abs/2509.25250', 'abstract': 'The rise of AI-native Low-Code/No-Code (LCNC) platforms enables autonomous agents capable of executing complex, long-duration business processes. However, a fundamental challenge remains: memory management. As agents operate over extended periods, they face "memory inflation" and "contextual degradation" issues, leading to inconsistent behavior, error accumulation, and increased computational cost. This paper proposes a novel hybrid memory system designed specifically for LCNC agents. Inspired by cognitive science, our architecture combines episodic and semantic memory components with a proactive "Intelligent Decay" mechanism. This mechanism intelligently prunes or consolidates memories based on a composite score factoring in recency, relevance, and user-specified utility. A key innovation is a user-centric visualization interface, aligned with the LCNC paradigm, which allows non-technical users to manage the agent\'s memory directly, for instance, by visually tagging which facts should be retained or forgotten. Through simulated long-running task experiments, we demonstrate that our system significantly outperforms traditional approaches like sliding windows and basic RAG, yielding superior task completion rates, contextual consistency, and long-term token cost efficiency. Our findings establish a new framework for building reliable, transparent AI agents capable of effective long-term learning and adaptation.', 'abstract_zh': 'AI原生低代码/无代码平台的兴起使得能够执行复杂长周期业务流程的自主代理得以实现。然而，一个基本挑战依然存在：内存管理。随着代理长时间运行，它们面临“内存膨胀”和“语境退化”问题，导致行为不一致、错误累积和计算成本增加。本文提出了一种专为低代码/无代码代理设计的新型混合内存系统。受认知科学启发，我们的架构结合了情景记忆和语义记忆组件，并采用了前瞻性的“智能衰减”机制。该机制根据包含近期性、相关性和用户指定效用的综合评分，智能地修剪或整合记忆。一个关键创新是用户为中心的可视化界面，与低代码/无代码范式相契合，使非技术人员可以直接管理代理的内存，例如通过可视化标签指定应保留或遗忘哪些事实。通过模拟长时间运行的任务实验，我们表明，我们的系统在任务完成率、语境一致性以及长期令牌成本效率方面显著优于传统的滑动窗口和基本RAG方法。我们的研究结果建立了构建可靠、透明的AI代理的新框架，这些代理能够在长期内有效学习和适应。', 'title_zh': '长运行低代码代理的内存管理与上下文一致性'}
{'arxiv_id': 'arXiv:2509.25244', 'title': 'Neo-Grounded Theory: A Methodological Innovation Integrating High-Dimensional Vector Clustering and Multi-Agent Collaboration for Qualitative Research', 'authors': 'Shuide Wen, Beier Ku, Teng Wang, Mingyang Zou, Yang Yang', 'link': 'https://arxiv.org/abs/2509.25244', 'abstract': "Purpose: Neo Grounded Theory (NGT) integrates vector clustering with multi agent systems to resolve qualitative research's scale depth paradox, enabling analysis of massive datasets in hours while preserving interpretive rigor. Methods: We compared NGT against manual coding and ChatGPT-assisted analysis using 40,000 character Chinese interview transcripts. NGT employs 1536-dimensional embeddings, hierarchical clustering, and parallel agent-based coding. Two experiments tested pure automation versus human guided refinement. Findings: NGT achieved 168-fold speed improvement (3 hours vs 3 weeks), superior quality (0.904 vs 0.883), and 96% cost reduction. Human AI collaboration proved essential: automation alone produced abstract frameworks while human guidance yielded actionable dual pathway theories. The system discovered patterns invisible to manual coding, including identity bifurcation phenomena. Contributions: NGT demonstrates computational objectivity and human interpretation are complementary. Vector representations provide reproducible semantic measurement while preserving meaning's interpretive dimensions. Researchers shift from mechanical coding to theoretical guidance, with AI handling pattern recognition while humans provide creative insight. Implications: Cost reduction from \\$50,000 to \\$500 democratizes qualitative research, enabling communities to study themselves. Real-time analysis makes qualitative insights contemporaneous with events. The framework shows computational methods can strengthen rather than compromise qualitative research's humanistic commitments.\nKeywords: Grounded theory; Vector embeddings; Multi agent systems; Human AI collaboration; Computational qualitative analysis", 'abstract_zh': '目的：新基础理论（NGT）将向量聚类与多智能体系统相结合，解决定性研究规模深度悖论，能够在几小时内分析大量数据集的同时保持解释的 rigor。方法：使用40,000字符的中文访谈转录文本将NGT与手动编码和ChatGPT辅助分析进行了对比。NGT采用1536维嵌入、层次聚类和并行基于代理的编码。两项实验测试了纯自动化与人类引导细化的区别。结果：NGT实现了168倍的速度提升（3小时 vs 3周），质量更优（0.904 vs 0.883），并实现了96%的成本减少。人类与AI的合作至关重要：纯自动化产生的是抽象框架，而人类指导则产生了可操作的双通道理论。系统发现了手动编码无法察觉的模式，包括身份分裂现象。贡献：NGT展示了计算客观性和人类解释是互补的。向量表示提供了可重复的语义度量，同时保留了意义的解释维度。研究者从机械编码转向理论指导，AI负责模式识别，人类提供创造性的洞察。意义：从50,000美元降低到500美元的成本减少使得定性研究普及化，使社区能够研究自己。实时分析使定性洞察与事件同步。框架显示计算方法可以增强而非削弱定性研究的人文承诺。\n\n关键词：基础理论；向量嵌入；多智能体系统；人类与AI协作；计算定性分析', 'title_zh': '新兴 grounded 理论：一种整合高维向量聚类与多Agent协作的方法学创新以支持质性研究'}
{'arxiv_id': 'arXiv:2509.25236', 'title': 'The Causal Abstraction Network: Theory and Learning', 'authors': "Gabriele D'Acunto, Paolo Di Lorenzo, Sergio Barbarossa", 'link': 'https://arxiv.org/abs/2509.25236', 'abstract': 'Causal artificial intelligence aims to enhance explainability, trustworthiness, and robustness in AI by leveraging structural causal models (SCMs). In this pursuit, recent advances formalize network sheaves of causal knowledge. Pushing in the same direction, we introduce the causal abstraction network (CAN), a specific instance of such sheaves where (i) SCMs are Gaussian, (ii) restriction maps are transposes of constructive linear causal abstractions (CAs), and (iii) edge stalks correspond -- up to rotation -- to the node stalks of more detailed SCMs. We investigate the theoretical properties of CAN, including algebraic invariants, cohomology, consistency, global sections characterized via the Laplacian kernel, and smoothness. We then tackle the learning of consistent CANs. Our problem formulation separates into edge-specific local Riemannian problems and avoids nonconvex, costly objectives. We propose an efficient search procedure as a solution, solving the local problems with SPECTRAL, our iterative method with closed-form updates and suitable for positive definite and semidefinite covariance matrices. Experiments on synthetic data show competitive performance in the CA learning task, and successful recovery of diverse CAN structures.', 'abstract_zh': '因果人工智能旨在通过利用结构因果模型（SCMs）来增强AI的解释性、可信度和鲁棒性。在此目标下，最近的进展形式化了因果知识的网络她fferve。沿着相同的方向，我们引入了因果抽象网络（CAN），这是一种此类她fferve的特定实例，其中(i) SCMs为高斯分布，(ii) 约束映射是构造线性因果抽象（CAs）的转置，(iii) 边 stalks 与更详细的SCMs的节点 stalks（最多旋转）相对应。我们研究了CAN的理论性质，包括代数不变量、上同调、一致性、通过拉普拉斯内核表征的全局截面以及光滑性。接着，我们解决了一致的CAN学习问题。我们的问题表述将问题分为特定边的本地黎曼问题，并避免了非凸、成本高昂的目标函数。我们提出了一种高效的搜索程序作为解决方案，使用我们的迭代方法SPECTRAL，该方法具有闭式更新形式，适用于正定和半正定协方差矩阵。在合成数据上的实验展示了CAN学习任务中的竞争性能，并成功恢复了多样化的CAN结构。', 'title_zh': '因果抽象网络：理论与学习'}
{'arxiv_id': 'arXiv:2509.26619', 'title': 'Searching for Difficult-to-Translate Test Examples at Scale', 'authors': 'Wenda Xu, Vilém Zouhar, Parker Riley, Mara Finkelstein, Markus Freitag, Daniel Deutsch', 'link': 'https://arxiv.org/abs/2509.26619', 'abstract': "NLP models require test data that are sufficiently challenging. The difficulty of an example is linked to the topic it originates from (''seed topic''). The relationship between the topic and the difficulty of its instances is stochastic in nature: an example about a difficult topic can happen to be easy, and vice versa. At the scale of the Internet, there are tens of thousands of potential topics, and finding the most difficult one by drawing and evaluating a large number of examples across all topics is computationally infeasible. We formalize this task and treat it as a multi-armed bandit problem. In this framework, each topic is an ''arm,'' and pulling an arm (at a cost) involves drawing a single example, evaluating it, and measuring its difficulty. The goal is to efficiently identify the most difficult topics within a fixed computational budget. We illustrate the bandit problem setup of finding difficult examples for the task of machine translation. We find that various bandit strategies vastly outperform baseline methods like brute-force searching the most challenging topics.", 'abstract_zh': 'NLP模型需要足够具有挑战性的测试数据。示例的难度与其来源的主题（“种子主题”）有关。主题与其实例的难度之间的关系具有随机性：一个来自难主题的示例可能非常简单，反之亦然。在互联网规模下，潜在主题数以万计，通过在所有主题中抽样并评估大量示例来找难度最大的主题在计算上是不切实际的。我们将此任务形式化，并将其视为多臂bandit问题。在这种框架中，每个主题是一个“臂”，拉起一个臂（付出成本）涉及抽取一个示例，评估其难度，并测量其难度。目标是在固定的计算预算内高效地识别最难的主题。我们展示了在机器翻译任务中寻找困难示例的bandit问题设置。我们发现各种bandit策略远远优于暴力搜索最难主题的基线方法。', 'title_zh': '大规模搜索难以翻译的测试示例'}
{'arxiv_id': 'arXiv:2509.26567', 'title': 'AI-assisted Advanced Propellant Development for Electric Propulsion', 'authors': 'Angel Pan Du, Miguel Arana-Catania, Enric Grustan Gutiérrez', 'link': 'https://arxiv.org/abs/2509.26567', 'abstract': 'Artificial Intelligence algorithms are introduced in this work as a tool to predict the performance of new chemical compounds as alternative propellants for electric propulsion, focusing on predicting their ionisation characteristics and fragmentation patterns. The chemical properties and structure of the compounds are encoded using a chemical fingerprint, and the training datasets are extracted from the NIST WebBook. The AI-predicted ionisation energy and minimum appearance energy have a mean relative error of 6.87% and 7.99%, respectively, and a predicted ion mass with a 23.89% relative error. In the cases of full mass spectra due to electron ionisation, the predictions have a cosine similarity of 0.6395 and align with the top 10 most similar mass spectra in 78% of instances within a 30 Da range.', 'abstract_zh': '人工智能算法被引入本文，用作预测新型化学化合物作为电推进替代推进剂性能的工具，重点关注预测其电离特性及碎片模式。化合物的化学性质和结构通过化学指纹进行编码，训练数据集来自NIST WebBook。基于AI预测的电离能和最低出现能的相对误差分别为6.87%和7.99%，预测的离子质量的相对误差为23.89%。在完整质谱（由于电子电离）的情况下，预测的质谱与实验质谱的余弦相似度为0.6395，并且在30 Da范围内有78%的概率与前10个最相似的质谱之一匹配。', 'title_zh': 'AI辅助的先进推进剂开发技术'}
{'arxiv_id': 'arXiv:2509.26564', 'title': 'Parametric Neural Amp Modeling with Active Learning', 'authors': 'Florian Grötschla, Longxiang Jiao, Luca A. Lanzendörfer, Roger Wattenhofer', 'link': 'https://arxiv.org/abs/2509.26564', 'abstract': 'We introduce Panama, an active learning framework to train parametric guitar amp models end-to-end using a combination of an LSTM model and a WaveNet-like architecture. With \\model, one can create a virtual amp by recording samples that are determined through an ensemble-based active learning strategy to minimize the amount of datapoints needed (i.e., amp knob settings). Our strategy uses gradient-based optimization to maximize the disagreement among ensemble models, in order to identify the most informative datapoints. MUSHRA listening tests reveal that, with 75 datapoints, our models are able to match the perceptual quality of NAM, the leading open-source non-parametric amp modeler.', 'abstract_zh': '我们介绍了一个名为Panama的主动学习框架，该框架结合LSTM模型和WaveNet-like架构，用于端到端训练参数化吉他放大器模型。通过该框架，可以录制样本并通过基于ensemble的主动学习策略确定这些样本，从而最小化所需的数据点数量（即，放大器旋钮设置）。我们的策略使用基于梯度的优化方法来最大化ensemble模型之间的分歧，以识别最有信息量的数据点。MUSHRA听觉测试表明，使用75个数据点，我们的模型能够匹配NAM（领先的开源非参数化放大器建模器）的感知质量。', 'title_zh': '基于主动学习的参数神经放大器建模'}
{'arxiv_id': 'arXiv:2509.26543', 'title': 'The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models', 'authors': 'Lina Conti, Dennis Fucci, Marco Gaido, Matteo Negri, Guillaume Wisniewski, Luisa Bentivogli', 'link': 'https://arxiv.org/abs/2509.26543', 'abstract': 'Contrastive explanations, which indicate why an AI system produced one output (the target) instead of another (the foil), are widely regarded in explainable AI as more informative and interpretable than standard explanations. However, obtaining such explanations for speech-to-text (S2T) generative models remains an open challenge. Drawing from feature attribution techniques, we propose the first method to obtain contrastive explanations in S2T by analyzing how parts of the input spectrogram influence the choice between alternative outputs. Through a case study on gender assignment in speech translation, we show that our method accurately identifies the audio features that drive the selection of one gender over another. By extending the scope of contrastive explanations to S2T, our work provides a foundation for better understanding S2T models.', 'abstract_zh': '对比解释在语音转文本生成模型中的应用：通过分析输入频谱图的部分如何影响输出选择，提出一种新方法，为更好地理解语音转文本模型奠定基础。', 'title_zh': '未被听见的选择：对比解释speech-to-text模型'}
{'arxiv_id': 'arXiv:2509.26524', 'title': 'TAP: Two-Stage Adaptive Personalization of Multi-task and Multi-Modal Foundation Models in Federated Learning', 'authors': 'Seohyun Lee, Wenzhi Fang, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton', 'link': 'https://arxiv.org/abs/2509.26524', 'abstract': "Federated Learning (FL), despite demonstrating impressive capabilities in the training of multiple models in a decentralized manner, has been shown to produce a final model not necessarily well-suited to the needs of each client. While extensive work has been conducted on how to create tailored personalized models, called Personalized Federated Learning (PFL), less attention has been given to personalization via fine-tuning of foundation models with multi-task and multi-modal properties. Moreover, there exists a lack of understanding in the literature on how to fine-tune and personalize such models in a setting that is heterogeneous across clients not only in data, but also in tasks and modalities. To address this gap in the literature, we propose TAP (Two-Stage Adaptive Personalization), which (i) leverages mismatched model architectures between the clients and server to selectively conduct replacement operations when it benefits a client's local tasks and (ii) engages in post-FL knowledge distillation for capturing beneficial general knowledge without compromising personalization. We also introduce the first convergence analysis of the server model under its modality-task pair architecture, and demonstrate that as the number of modality-task pairs increases, its ability to cater to all tasks suffers. Through extensive experiments, we demonstrate the effectiveness of our proposed algorithm across a variety of datasets and tasks in comparison to a multitude of baselines. Implementation code is publicly available at this https URL.", 'abstract_zh': '联邦学习（FL）虽然在以去中心化方式训练多个模型方面展现了 impressive 的能力，但已被证明最终生成的模型未必很好地满足每个客户端的需求。尽管在如何创建定制化个性化模型，即个性化联邦学习（PFL），方面已开展了大量工作，但通过多任务和跨模态属性进行微调的个性化关注相对较少。此外，文献中还缺乏在客户端不仅在数据上而且在任务和模态上异构的情况下，如何微调和个性化此类模型的理解。为填补这一文献空白，我们提出了一种两阶段自适应个性化（TAP）方法，该方法（i）利用客户端与服务器之间的模型架构不匹配，在有利于客户端本地任务时选择性地执行替换操作，（ii）在联邦学习后进行知识蒸馏，以捕获有益的通用知识而不牺牲个性化能力。我们还引入了在模式-任务配对架构下服务器模型的第一种收敛性分析，并证明随着模式-任务配对数量的增加，其满足所有任务的能力会受到影响。通过广泛的实验，我们展示了在各种数据集和任务上与多种基线方法相比，我们提出算法的有效性。代码已公开，可在以下链接访问：this https URL。', 'title_zh': 'TAP：联邦学习中多任务和多模态基础模型的两阶段自适应个性化'}
{'arxiv_id': 'arXiv:2509.26521', 'title': 'MUSE-Explainer: Counterfactual Explanations for Symbolic Music Graph Classification Models', 'authors': 'Baptiste Hilaire, Emmanouil Karystinaios, Gerhard Widmer', 'link': 'https://arxiv.org/abs/2509.26521', 'abstract': "Interpretability is essential for deploying deep learning models in symbolic music analysis, yet most research emphasizes model performance over explanation. To address this, we introduce MUSE-Explainer, a new method that helps reveal how music Graph Neural Network models make decisions by providing clear, human-friendly explanations. Our approach generates counterfactual explanations by making small, meaningful changes to musical score graphs that alter a model's prediction while ensuring the results remain musically coherent. Unlike existing methods, MUSE-Explainer tailors its explanations to the structure of musical data and avoids unrealistic or confusing outputs. We evaluate our method on a music analysis task and show it offers intuitive insights that can be visualized with standard music tools such as Verovio.", 'abstract_zh': '深度学习模型在符号音乐分析中的可解释性是必要的，然而大多数研究侧重于模型性能而非解释。为解决这一问题，我们引入了MUSE-Explainer，一种新的方法，通过提供清晰的人类友好的解释来帮助揭示音乐图神经网络模型的决策过程。我们的方法通过在不破坏音乐连贯性的情况下对音乐谱图进行细微、有意义的修改，生成相关的反事实解释。与现有方法不同，MUSE-Explainer能够根据音乐数据的结构定制其解释，避免生成不现实或令人困惑的结果。我们在一个音乐分析任务上评估了该方法，并展示了其能够用标准音乐工具（如Verovio）进行可视化，并提供直观的见解。', 'title_zh': 'MUSE-Explainer: 符号音乐图分类模型的反事实解释'}
{'arxiv_id': 'arXiv:2509.26500', 'title': 'Indoor/Outdoor Spectrum Sharing Enabled by GNSS-based Classifiers', 'authors': 'Hossein Nasiri, Muhammad Iqbal Rochman, Monisha Ghosh', 'link': 'https://arxiv.org/abs/2509.26500', 'abstract': 'The desirability of the mid-band frequency range (1 - 10 GHz) for federal and commercial applications, combined with the growing applications for commercial indoor use-cases, such as factory automation, opens up a new approach to spectrum sharing: the same frequency bands used outdoors by federal incumbents can be reused by commercial indoor users. A recent example of such sharing, between commercial systems, is the 6 GHz band (5.925 - 7.125 GHz) where unlicensed, low-power-indoor (LPI) users share the band with outdoor incumbents, primarily fixed microwave links. However, to date, there exist no reliable, automatic means of determining whether a device is indoors or outdoors, necessitating the use of other mechanisms such as mandating indoor access points (APs) to have integrated antennas and not be battery powered, and reducing transmit power of client devices which may be outdoors. An accurate indoor/outdoor (I/O) classification addresses these challenges, enabling automatic transmit power adjustments without interfering with incumbents. To this end, we leverage the Global Navigation Satellite System (GNSS) signals for I/O classification. GNSS signals, designed inherently for outdoor reception and highly susceptible to indoor attenuation and blocking, provide a robust and distinguishing feature for environmental sensing. We develop various methodologies, including threshold-based techniques and machine learning approaches and evaluate them using an expanded dataset gathered from diverse geographical locations. Our results demonstrate that GNSS-based methods alone can achieve greater accuracy than approaches relying solely on wireless (Wi-Fi) data, particularly in unfamiliar locations. Furthermore, the integration of GNSS data with Wi-Fi information leads to improved classification accuracy, showcasing the significant benefits of multi-modal data fusion.', 'abstract_zh': '联邦和商用应用中频段频率范围（1-10 GHz）的优越性，结合商用室内应用场景的不断增长，如工厂自动化，为频谱共享开辟了新途径：联邦 incumbents 在室外使用的相同频率 band 可以被商用室内用户重新使用。最近，6 GHz 频段（5.925 - 7.125 GHz）的商用系统共享就是一个例子，其中无执照、低功耗室内（LPI）用户与室外 incumbents（主要为固定微波链路）共享频段。然而，目前还没有可靠且自动的方法来确定一个设备是在室内还是室外，因此需要采取其他手段，比如强制室内接入点（APs）配备集成天线且非电池供电，并降低可能在室外的客户端设备的发射功率。准确的室内/室外（I/O）分类解决了这些挑战，使自动调整发射功率成为可能，而不干扰 incumbents。为此，我们利用全球导航卫星系统（GNSS）信号进行 I/O 分类。GNSS 信号固有设计用于室外接收，对室内衰减和阻挡高度敏感，提供了环境感知的良好特征。我们开发了多种方法，包括阈值技术及机器学习方法，并使用来自不同地理区域的扩展数据集进行评估。我们的结果显示，基于 GNSS 的方法单独使用可以比仅依赖于无线（Wi-Fi）数据的方法实现更高的准确性，特别是在不熟悉的地方。此外，将 GNSS 数据与 Wi-Fi 信息集成可以提高分类准确性，展示了多模态数据融合的显著优势。', 'title_zh': '基于GNSS分类器的室内/室外频谱共享'}
{'arxiv_id': 'arXiv:2509.26476', 'title': 'Regression Language Models for Code', 'authors': 'Yash Akhauri, Xingyou Song, Arissa Wongpanich, Bryan Lewandowski, Mohamed S. Abdelfattah', 'link': 'https://arxiv.org/abs/2509.26476', 'abstract': 'We study code-to-metric regression: predicting numeric outcomes of code executions, a challenging task due to the open-ended nature of programming languages. While prior methods have resorted to heavy and domain-specific feature engineering, we show that a single unified Regression Language Model (RLM) can simultaneously predict directly from text, (i) the memory footprint of code across multiple high-level languages such as Python and C++, (ii) the latency of Triton GPU kernels, and (iii) the accuracy and speed of trained neural networks represented in ONNX. In particular, a relatively small 300M parameter RLM initialized from T5Gemma, obtains > 0.9 Spearman-rank on competitive programming submissions from APPS, and a single unified model achieves > 0.5 average Spearman-rank across 17 separate languages from CodeNet. Furthermore, the RLM can obtain the highest average Kendall-Tau of 0.46 on five classic NAS design spaces previously dominated by graph neural networks, and simultaneously predict architecture latencies on numerous hardware platforms.', 'abstract_zh': '代码到度量回归研究：一种具有挑战性的任务，由于编程语言的开放性。', 'title_zh': '代码的回归语言模型'}
{'arxiv_id': 'arXiv:2509.26471', 'title': "On Deepfake Voice Detection - It's All in the Presentation", 'authors': 'Héctor Delgado, Giorgio Ramondetti, Emanuele Dalmasso, Gennady Karvitsky, Daniele Colibro, Haydar Talib', 'link': 'https://arxiv.org/abs/2509.26471', 'abstract': 'While the technologies empowering malicious audio deepfakes have dramatically evolved in recent years due to generative AI advances, the same cannot be said of global research into spoofing (deepfake) countermeasures. This paper highlights how current deepfake datasets and research methodologies led to systems that failed to generalize to real world application. The main reason is due to the difference between raw deepfake audio, and deepfake audio that has been presented through a communication channel, e.g. by phone. We propose a new framework for data creation and research methodology, allowing for the development of spoofing countermeasures that would be more effective in real-world scenarios. By following the guidelines outlined here we improved deepfake detection accuracy by 39% in more robust and realistic lab setups, and by 57% on a real-world benchmark. We also demonstrate how improvement in datasets would have a bigger impact on deepfake detection accuracy than the choice of larger SOTA models would over smaller models; that is, it would be more important for the scientific community to make greater investment on comprehensive data collection programs than to simply train larger models with higher computational demands.', 'abstract_zh': '尽管近年来生成AI的发展使得赋能恶意音频换音的技术产生了巨大进步，但全球对于仿声（深度伪造）反制措施的研究进展却相对缓慢。本文强调了当前深度伪造数据集和研究方法的局限性，导致系统在实际应用中难以泛化。主要原因在于未经通信信道呈现的原始深度伪造音频和通过通信信道呈现的深度伪造音频之间的差异。我们提出了一种新的数据创建和研究方法框架，以促进在实际场景中更有效的仿声反制措施开发。通过遵循本文所列指南，我们在更稳健和现实的实验室设置中将深度伪造检测准确性提高了39%，在真实世界基准测试中提高了57%。我们还展示了数据集的改进对深度伪造检测准确性的影响比选用更大模型（尽管计算需求更高）的影响更大，科学界应该加大对全面数据采集计划的投资，而不仅仅是训练更大、计算需求更高的模型。', 'title_zh': '基于呈现方式的深伪语音检测'}
{'arxiv_id': 'arXiv:2509.26435', 'title': 'Adaptive Planning for Multi-Attribute Controllable Summarization with Monte Carlo Tree Search', 'authors': 'Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok', 'link': 'https://arxiv.org/abs/2509.26435', 'abstract': 'Controllable summarization moves beyond generic outputs toward human-aligned summaries guided by specified attributes. In practice, the interdependence among attributes makes it challenging for language models to satisfy correlated constraints consistently. Moreover, previous approaches often require per-attribute fine-tuning, limiting flexibility across diverse summary attributes. In this paper, we propose adaptive planning for multi-attribute controllable summarization (PACO), a training-free framework that reframes the task as planning the order of sequential attribute control with a customized Monte Carlo Tree Search (MCTS). In PACO, nodes represent summaries, and actions correspond to single-attribute adjustments, enabling progressive refinement of only the attributes requiring further control. This strategy adaptively discovers optimal control orders, ultimately producing summaries that effectively meet all constraints. Extensive experiments across diverse domains and models demonstrate that PACO achieves robust multi-attribute controllability, surpassing both LLM-based self-planning models and fine-tuned baselines. Remarkably, PACO with Llama-3.2-1B rivals the controllability of the much larger Llama-3.3-70B baselines. With larger models, PACO achieves superior control performance, outperforming all competitors.', 'abstract_zh': '可控总结超越了通用输出，向着由指定属性引导的人类对齐摘要发展。在实践中，属性之间的相互依赖使语言模型难以一致地满足相关约束。此外，以往的方法往往需要针对每个属性进行微调，限制了在多种总结属性上的灵活性。在本文中，我们提出了一种适应性规划多属性可控总结（PACO）框架，该框架将任务重新定义为使用自定义蒙特卡洛树搜索（MCTS）规划序列属性控制顺序的任务。在PACO中，节点表示摘要，操作对应于单属性调整，使得只有需要进一步控制的属性可以渐进地细化。这种策略自适应地发现最优控制顺序，最终生成能够有效满足所有约束的摘要。广泛实验表明，PACO在多种领域和模型上实现了稳健的多属性可控性，超越了基于LLM的自我规划模型和微调基线。令人惊讶的是，使用Llama-3.2-1B的PACO与更大的Llama-3.3-70B基线具有相当的可控性。随着模型规模的增大，PACO在控制性能上表现出优越性，超越了所有竞争对手。', 'title_zh': '基于蒙特卡洛树搜索的多属性可控摘要自适应规划'}
{'arxiv_id': 'arXiv:2509.26427', 'title': 'Ascent Fails to Forget', 'authors': 'Ioannis Mavrothalassitis, Pol Puigdemont, Noam Itzhak Levi, Volkan Cevher', 'link': 'https://arxiv.org/abs/2509.26427', 'abstract': 'Contrary to common belief, we show that gradient ascent-based unconstrained optimization methods frequently fail to perform machine unlearning, a phenomenon we attribute to the inherent statistical dependence between the forget and retain data sets. This dependence, which can manifest itself even as simple correlations, undermines the misconception that these sets can be independently manipulated during unlearning. We provide empirical and theoretical evidence showing these methods often fail precisely due to this overlooked relationship. For random forget sets, this dependence means that degrading forget set metrics (which, for a retrained model, should mirror test set metrics) inevitably harms overall test performance. Going beyond random sets, we consider logistic regression as an instructive example where a critical failure mode emerges: inter-set dependence causes gradient descent-ascent iterations to progressively diverge from the ideal retrained model. Strikingly, these methods can converge to solutions that are not only far from the retrained ideal but are potentially even further from it than the original model itself, rendering the unlearning process actively detrimental. A toy example further illustrates how this dependence can trap models in inferior local minima, inescapable via finetuning. Our findings highlight that the presence of such statistical dependencies, even when manifest only as correlations, can be sufficient for ascent-based unlearning to fail. Our theoretical insights are corroborated by experiments on complex neural networks, demonstrating that these methods do not perform as expected in practice due to this unaddressed statistical interplay.', 'abstract_zh': '与常识相反，我们证明了基于梯度上升的无约束优化方法在机器遗忘任务中经常失败，这一现象我们归因于忘记数据集和保留数据集之间固有的统计依赖性。这种依赖性即使表现为简单的相关性也会削弱这样一个认识，即在遗忘过程中这些数据集可以被独立操纵。我们提供了实证和理论证据，证明这些方法往往正是由于这种被忽视的关系而失败。对于随机的忘记数据集，这种依赖性意味着降低忘记数据集的度量（对于重新训练后的模型，这些度量应该反映测试集的度量）不可避免地会损害整体测试性能。超越随机集，我们考虑逻辑回归作为具有启发性的例子，其中一种关键的失败模式出现：数据集之间的依赖性导致梯度下降-上升迭代逐步偏离理想的重新训练后的模型。令人惊讶的是，这些方法可能收敛到与重新训练后的理想模型相距甚远甚至比原始模型更远的解，使遗忘过程变得有害。一个简单的示例进一步说明了这种依赖性如何将模型困在通过微调难以逃出的劣质局部最小值中。我们的研究结果强调了即使只有相关性的存在，此类统计依赖性也足以导致基于上升的遗忘失败。我们的理论见解得到了对复杂神经网络进行的实验的证实，表明由于这种未解决的统计交互作用，这种方法在实践中并未按预期起作用。', 'title_zh': 'ascent 难以忘却'}
{'arxiv_id': 'arXiv:2509.26388', 'title': 'Game-Time: Evaluating Temporal Dynamics in Spoken Language Models', 'authors': 'Kai-Wei Chang, En-Pei Hu, Chun-Yi Kuan, Wenze Ren, Wei-Chih Chen, Guan-Ting Lin, Yu Tsao, Shao-Hua Sun, Hung-yi Lee, James Glass', 'link': 'https://arxiv.org/abs/2509.26388', 'abstract': 'Conversational Spoken Language Models (SLMs) are emerging as a promising paradigm for real-time speech interaction. However, their capacity of temporal dynamics, including the ability to manage timing, tempo and simultaneous speaking, remains a critical and unevaluated challenge for conversational fluency. To address this gap, we introduce the Game-Time Benchmark, a framework to systematically assess these temporal capabilities. Inspired by how humans learn a language through language activities, Game-Time consists of basic instruction-following tasks and advanced tasks with temporal constraints, such as tempo adherence and synchronized responses. Our evaluation of diverse SLM architectures reveals a clear performance disparity: while state-of-the-art models handle basic tasks well, many contemporary systems still struggle with fundamental instruction-following. More critically, nearly all models degrade substantially under temporal constraints, exposing persistent weaknesses in time awareness and full-duplex interaction. The Game-Time Benchmark provides a foundation for guiding future research toward more temporally-aware conversational AI. Demos and datasets are available on our project website this https URL.', 'abstract_zh': '对话式口语语言模型（SLMs）正在成为实时语音交互的有前景范式。然而，它们在时间动态方面的能力，包括管理节奏、速度和同时说话的能力，仍然是会话流畅性中的关键且未评估的挑战。为了填补这一空白，我们引入了Game-Time基准，这是一种系统评估这些时间能力的框架。受人类通过语言活动学习语言的启发，Game-Time包含基本的指令跟随任务和具有时间约束的高级任务，如节奏遵守和同步响应。我们对多种SLM架构的评估揭示了明显的性能差异：尽管最先进的模型能够很好地处理基本任务，但许多当代系统仍然难以应对基本指令跟随任务。更关键的是，几乎所有模型在时间约束条件下表现大幅下降，暴露出时间意识和全双工交互的持久弱点。Game-Time基准为未来研究朝着更加注重时间的对话式AI方向提供了指导基础。更多信息和数据集可在我们项目网站这个网址获取。', 'title_zh': 'Game-Time: 评估语音语言模型中的时间动态'}
{'arxiv_id': 'arXiv:2509.26371', 'title': 'Vector-Valued Reproducing Kernel Banach Spaces for Neural Networks and Operators', 'authors': 'Sven Dummer, Tjeerd Jan Heeringa, José A. Iglesias', 'link': 'https://arxiv.org/abs/2509.26371', 'abstract': 'Recently, there has been growing interest in characterizing the function spaces underlying neural networks. While shallow and deep scalar-valued neural networks have been linked to scalar-valued reproducing kernel Banach spaces (RKBS), $\\R^d$-valued neural networks and neural operator models remain less understood in the RKBS setting. To address this gap, we develop a general definition of vector-valued RKBS (vv-RKBS), which inherently includes the associated reproducing kernel. Our construction extends existing definitions by avoiding restrictive assumptions such as symmetric kernel domains, finite-dimensional output spaces, reflexivity, or separability, while still recovering familiar properties of vector-valued reproducing kernel Hilbert spaces (vv-RKHS). We then show that shallow $\\R^d$-valued neural networks are elements of a specific vv-RKBS, namely an instance of the integral and neural vv-RKBS. To also explore the functional structure of neural operators, we analyze the DeepONet and Hypernetwork architectures and demonstrate that they too belong to an integral and neural vv-RKBS. In all cases, we establish a Representer Theorem, showing that optimization over these function spaces recovers the corresponding neural architectures.', 'abstract_zh': '最近，人们对神经网络 underlying 的函数空间特征表现出 growing 的兴趣。虽然浅层和深层标量值神经网络与标量值再生核巴纳赫空间 (RKBS) 相关联，但 $\\R^d$ 值神经网络和神经算子模型在 RKBS 设置下尚未得到充分理解。为填补这一空白，我们提出了向量值再生核巴纳赫空间 (vv-RKBS) 的通用定义，其中包含关联的再生核。我们的构造扩展了现有定义，避免了对称核域、有限输出维数空间、反射性或可分性等 restrictive 假设，但仍保留了向量值再生核希尔伯特空间 (vv-RKHS) 的熟悉属性。然后我们证明浅层 $\\R^d$ 值神经网络是特定的 vv-RKBS 的元素，即积分和神经 vv-RKBS 的实例。为了探索神经算子的函数结构，我们分析了 DeepONet 和 Hypernetwork 架构，并证明它们也属于积分和神经 vv-RKBS。在所有情况下，我们建立了表示定理，证明了在这些函数空间上进行优化可以恢复相应的神经架构。', 'title_zh': '向量值核Banach空间及其在神经网络和算子中的应用'}
{'arxiv_id': 'arXiv:2509.26350', 'title': 'SoK: Systematic analysis of adversarial threats against deep learning approaches for autonomous anomaly detection systems in SDN-IoT networks', 'authors': 'Tharindu Lakshan Yasarathna, Nhien-An Le-Khac', 'link': 'https://arxiv.org/abs/2509.26350', 'abstract': 'Integrating SDN and the IoT enhances network control and flexibility. DL-based AAD systems improve security by enabling real-time threat detection in SDN-IoT networks. However, these systems remain vulnerable to adversarial attacks that manipulate input data or exploit model weaknesses, significantly degrading detection accuracy. Existing research lacks a systematic analysis of adversarial vulnerabilities specific to DL-based AAD systems in SDN-IoT environments. This SoK study introduces a structured adversarial threat model and a comprehensive taxonomy of attacks, categorising them into data, model, and hybrid-level threats. Unlike previous studies, we systematically evaluate white, black, and grey-box attack strategies across popular benchmark datasets. Our findings reveal that adversarial attacks can reduce detection accuracy by up to 48.4%, with Membership Inference causing the most significant drop. C&W and DeepFool achieve high evasion success rates. However, adversarial training enhances robustness, and its high computational overhead limits the real-time deployment of SDN-IoT applications. We propose adaptive countermeasures, including real-time adversarial mitigation, enhanced retraining mechanisms, and explainable AI-driven security frameworks. By integrating structured threat models, this study offers a more comprehensive approach to attack categorisation, impact assessment, and defence evaluation than previous research. Our work highlights critical vulnerabilities in existing DL-based AAD models and provides practical recommendations for improving resilience, interpretability, and computational efficiency. This study serves as a foundational reference for researchers and practitioners seeking to enhance DL-based AAD security in SDN-IoT networks, offering a systematic adversarial threat model and conceptual defence evaluation based on prior empirical studies.', 'abstract_zh': '集成SDN和物联网增强网络控制和灵活性。基于DL的实时威胁检测系统改善了SDN-IoT网络的安全性。然而，这些系统仍易受到操控输入数据或利用模型弱点的 adversarial 攻击，显著降低了检测准确性。现有研究缺乏针对基于DL的AAD系统在SDN-IoT环境中的 adversarial 漏洞系统的分析。本综述研究引入了结构化的 adversarial 威胁模型和全面的攻击分类，将攻击分类为数据级、模型级和混合级威胁。与以往研究不同，我们系统地评估了流行的基准数据集上的白盒、黑盒和灰盒攻击策略。我们的发现显示，adversarial 攻击可以降低检测准确性高达48.4%，其中Membership Inference 造成最大的下降。C&W和DeepFool实现了高的逃逸成功率。然而，adversarial 训练增强了鲁棒性，其高昂的计算开销限制了SDN-IoT应用的实时部署。我们提出了适应性对策，包括实时adversarial 抵制、增强的重训练机制和基于解释性AI的安保框架。通过整合结构化的威胁模型，本研究提供了比以往研究更全面的攻击分类、影响评估和防御评估方法。我们的研究指出了现有基于DL的AAD模型中的关键漏洞，并提供了改进韧性、解释性和计算效率的实用建议。本研究为研究人员和实践者提供了一个基础参考，旨在增强SDN-IoT网络中基于DL的AAD安全性，基于前人实证研究提供了系统化的adversarial 威胁模型和概念化的防御评估。', 'title_zh': 'SoK：对SDN-IoT网络中自主异常检测系统基于深度学习的方法的 adversarial 威胁系统分析'}
{'arxiv_id': 'arXiv:2509.26346', 'title': 'EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing', 'authors': 'Keming Wu, Sicong Jiang, Max Ku, Ping Nie, Minghao Liu, Wenhu Chen', 'link': 'https://arxiv.org/abs/2509.26346', 'abstract': "Recently, we have witnessed great progress in image editing with natural language instructions. Several closed-source models like GPT-Image-1, Seedream, and Google-Nano-Banana have shown highly promising progress. However, the open-source models are still lagging. The main bottleneck is the lack of a reliable reward model to scale up high-quality synthetic training data. To address this critical bottleneck, we built \\mname, trained with our new large-scale human preference dataset, meticulously annotated by trained experts following a rigorous protocol containing over 200K preference pairs. \\mname demonstrates superior alignment with human preferences in instruction-guided image editing tasks. Experiments show that \\mname achieves state-of-the-art human correlation on established benchmarks such as GenAI-Bench, AURORA-Bench, ImagenHub, and our new \\benchname, outperforming a wide range of VLM-as-judge models. Furthermore, we use \\mname to select a high-quality subset from the existing noisy ShareGPT-4o-Image dataset. We train Step1X-Edit on the selected subset, which shows significant improvement over training on the full set. This demonstrates \\mname's ability to serve as a reward model to scale up high-quality training data for image editing. Furthermore, its strong alignment suggests potential for advanced applications like reinforcement learning-based post-training and test-time scaling of image editing models. \\mname with its training dataset will be released to help the community build more high-quality image editing training datasets.", 'abstract_zh': '近期，我们见证了自然语言指令指导下图像编辑领域取得了显著进步。虽然一些闭源模型如GPT-Image-1、Seedream和Google-Nano-Banana展现了高度有前景的进展，但开源模型仍处于落后状态。主要瓶颈在于缺乏可靠的奖励模型来规模化高质量合成训练数据。为解决这一关键瓶颈，我们构建了\\mname，并使用我们新构建的大规模人类偏好数据集进行训练，该数据集由经过严格协议培训的专家精心标注，包含超过20万对偏好数据。\\mname在指令指导下的图像编辑任务中展示了优于人类偏好的对齐能力。实验表明，\\mname在GenAI-Bench、AURORA-Bench、ImagenHub和我们新的\\benchname等成熟基准测试上达到了最先进的性能，并超过了多种VLM作为评判模型。此外，我们利用\\mname从现有的噪声ShareGPT-4o-Image数据集中选择了高质量的子集。在该子集上训练Step1X-Edit显示出显著改进，证明了\\mname作为奖励模型的能力，可以规模化高质量训练数据以用于图像编辑。其高度对齐也表明了其在图像编辑模型后训练和测试时强化学习应用中的潜在可能性。\\mname及其训练数据集将被释放以帮助社区构建更多高质量的图像编辑训练数据集。', 'title_zh': 'EditReward：由指令引导的图像编辑的人类对齐奖励模型'}
{'arxiv_id': 'arXiv:2509.26305', 'title': 'Feedback Forensics: A Toolkit to Measure AI Personality', 'authors': 'Arduin Findeis, Timo Kaufmann, Eyke Hüllermeier, Robert Mullins', 'link': 'https://arxiv.org/abs/2509.26305', 'abstract': 'Some traits making a "good" AI model are hard to describe upfront. For example, should responses be more polite or more casual? Such traits are sometimes summarized as model character or personality. Without a clear objective, conventional benchmarks based on automatic validation struggle to measure such traits. Evaluation methods using human feedback such as Chatbot Arena have emerged as a popular alternative. These methods infer "better" personality and other desirable traits implicitly by ranking multiple model responses relative to each other. Recent issues with model releases highlight limitations of these existing opaque evaluation approaches: a major model was rolled back over sycophantic personality issues, models were observed overfitting to such feedback-based leaderboards. Despite these known issues, limited public tooling exists to explicitly evaluate model personality. We introduce Feedback Forensics: an open-source toolkit to track AI personality changes, both those encouraged by human (or AI) feedback, and those exhibited across AI models trained and evaluated on such feedback. Leveraging AI annotators, our toolkit enables investigating personality via Python API and browser app. We demonstrate the toolkit\'s usefulness in two steps: (A) first we analyse the personality traits encouraged in popular human feedback datasets including Chatbot Arena, MultiPref and PRISM; and (B) then use our toolkit to analyse how much popular models exhibit such traits. We release (1) our Feedback Forensics toolkit alongside (2) a web app tracking AI personality in popular models and feedback datasets as well as (3) the underlying annotation data at this https URL.', 'abstract_zh': '一些构成“优秀”AI模型的特质难以提前描述。例如，回应应更加礼貌还是更加随性？这类特质有时被总结为模型性格或个性。缺乏明确目标的情况下，基于自动验证的传统基准指标难以衡量这类特质。使用人类反馈进行评估的方法，如聊天机器人竞技场（Chatbot Arena），作为一种替代方法逐渐流行起来。这些方法通过将多个模型回应相对排名，推测出“更好”的个性和其他 desirable 特质。近期关于模型发布的事件凸显了这些现有评估方法的局限性：一个主要模型因奉承的性格特征而被回滚，模型被观察到过度适应此类基于反馈的排行榜。尽管存在这些已知问题，但仍缺乏公开工具以明确评估模型个性。我们介绍了反馈取证：一个开源工具包，用于追踪AI个性的变化，无论是受到人类（或AI）反馈鼓励的变化，还是在利用此类反馈训练和评估的AI模型中表现出的变化。利用AI注释人员，我们的工具包通过Python API和浏览器应用，便于研究个性。我们通过两个步骤展示了工具包的价值：首先，我们分析了包括聊天机器人竞技场、MultiPref和PRISM在内的流行人类反馈数据集中鼓励的个性特质；然后，使用我们的工具包分析主流模型在多大程度上展现了这类特质。我们发布了（1）我们的反馈取证工具包以及（2）一个网页应用程序，跟踪流行模型和反馈数据集中AI个性的变化，同时提供（3）基础注释数据，可以在该链接查看：https://这个链接地址。', 'title_zh': 'AI人格分析工具箱：反馈法iska'}
{'arxiv_id': 'arXiv:2509.26294', 'title': 'Noise-Guided Transport for Imitation Learning', 'authors': 'Lionel Blondé, Joao A. Candido Ramos, Alexandros Kalousis', 'link': 'https://arxiv.org/abs/2509.26294', 'abstract': 'We consider imitation learning in the low-data regime, where only a limited number of expert demonstrations are available. In this setting, methods that rely on large-scale pretraining or high-capacity architectures can be difficult to apply, and efficiency with respect to demonstration data becomes critical. We introduce Noise-Guided Transport (NGT), a lightweight off-policy method that casts imitation as an optimal transport problem solved via adversarial training. NGT requires no pretraining or specialized architectures, incorporates uncertainty estimation by design, and is easy to implement and tune. Despite its simplicity, NGT achieves strong performance on challenging continuous control tasks, including high-dimensional Humanoid tasks, under ultra-low data regimes with as few as 20 transitions. Code is publicly available at: this https URL.', 'abstract_zh': '我们在少量数据条件下考虑模仿学习，即仅可获得有限数量的专家演示。在这种情况下，依赖大规模预训练或高容量架构的方法可能难以应用，对演示数据的效率变得至关重要。我们 introduces Noise-Guided Transport (NGT)，一种轻量级的离策略方法，将模仿学习视为通过对抗训练求解的理想运输问题。NGT 不需要预训练或特殊架构，通过设计纳入不确定性估计，容易实现和调整。尽管结构简单，NGT 在超低数据条件下仍能实现强大的高性能连续控制任务，包括高维的人形机器人任务，只需20个过渡。代码已公开，可在以下链接访问：this https URL。', 'title_zh': '噪声引导传输的模仿学习'}
{'arxiv_id': 'arXiv:2509.26291', 'title': 'Representation-Based Data Quality Audits for Audio', 'authors': 'Alvaro Gonzalez-Jimenez, Fabian Gröger, Linda Wermelinger, Andrin Bürli, Iason Kastanis, Simone Lionetti, Marc Pouly', 'link': 'https://arxiv.org/abs/2509.26291', 'abstract': 'Data quality issues such as off-topic samples, near duplicates, and label errors often limit the performance of audio-based systems. This paper addresses these issues by adapting SelfClean, a representation-to-rank data auditing framework, from the image to the audio domain. This approach leverages self-supervised audio representations to identify common data quality issues, creating ranked review lists that surface distinct issues within a single, unified process. The method is benchmarked on the ESC-50, GTZAN, and a proprietary industrial dataset, using both synthetic and naturally occurring corruptions. The results demonstrate that this framework achieves state-of-the-art ranking performance, often outperforming issue-specific baselines and enabling significant annotation savings by efficiently guiding human review.', 'abstract_zh': '基于音频的数据质量问题如离题样本、近似重复和标签错误经常限制基于音频系统的性能。本文通过将SelfClean这一表示到排序的数据审核框架从图像领域应用到音频领域来解决这些问题。该方法利用自我监督的音频表示来识别常见的数据质量问题，生成排序审核列表，可以在单一统一的过程中突出显示不同的问题。该方法在ESC-50、GTZAN和一个专有工业数据集中进行了基准测试，使用合成和自然产生的损坏数据。结果表明，该框架实现了最先进的排序性能，通常优于特定问题的基线，并通过高效引导人工审核实现显著的注释节省。', 'title_zh': '基于表示的数据质量审计方法在音频领域的应用'}
{'arxiv_id': 'arXiv:2509.26281', 'title': 'Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization', 'authors': 'Teng Zhang, Ziqian Fan, Mingxin Liu, Xin Zhang, Xudong Lu, Wentong Li, Yue Zhou, Yi Yu, Xiang Li, Junchi Yan, Xue Yang', 'link': 'https://arxiv.org/abs/2509.26281', 'abstract': "Driven by the growing need for Oriented Object Detection (OOD), learning from point annotations under a weakly-supervised framework has emerged as a promising alternative to costly and laborious manual labeling. In this paper, we discuss two deficiencies in existing point-supervised methods: inefficient utilization and poor quality of pseudo labels. Therefore, we present Point2RBox-v3. At the core are two principles: 1) Progressive Label Assignment (PLA). It dynamically estimates instance sizes in a coarse yet intelligent manner at different stages of the training process, enabling the use of label assignment methods. 2) Prior-Guided Dynamic Mask Loss (PGDM-Loss). It is an enhancement of the Voronoi Watershed Loss from Point2RBox-v2, which overcomes the shortcomings of Watershed in its poor performance in sparse scenes and SAM's poor performance in dense scenes. To our knowledge, Point2RBox-v3 is the first model to employ dynamic pseudo labels for label assignment, and it creatively complements the advantages of SAM model with the watershed algorithm, which achieves excellent performance in both sparse and dense scenes. Our solution gives competitive performance, especially in scenarios with large variations in object size or sparse object occurrences: 66.09%/56.86%/41.28%/46.40%/19.60%/45.96% on DOTA-v1.0/DOTA-v1.5/DOTA-v2.0/DIOR/STAR/RSAR.", 'abstract_zh': '基于点注释的弱监督对象检测方法Point2RBox-v3：动态伪标签与先验引导动态掩码损失', 'title_zh': 'Point2RBox-v3：通过综合伪标签 refinement 和利用实现自 bootstrapping 从点注释'}
{'arxiv_id': 'arXiv:2509.26239', 'title': 'Sandbagging in a Simple Survival Bandit Problem', 'authors': 'Joel Dyer, Daniel Jarne Ornia, Nicholas Bishop, Anisoara Calinescu, Michael Wooldridge', 'link': 'https://arxiv.org/abs/2509.26239', 'abstract': 'Evaluating the safety of frontier AI systems is an increasingly important concern, helping to measure the capabilities of such models and identify risks before deployment. However, it has been recognised that if AI agents are aware that they are being evaluated, such agents may deliberately hide dangerous capabilities or intentionally demonstrate suboptimal performance in safety-related tasks in order to be released and to avoid being deactivated or retrained. Such strategic deception - often known as "sandbagging" - threatens to undermine the integrity of safety evaluations. For this reason, it is of value to identify methods that enable us to distinguish behavioural patterns that demonstrate a true lack of capability from behavioural patterns that are consistent with sandbagging. In this paper, we develop a simple model of strategic deception in sequential decision-making tasks, inspired by the recently developed survival bandit framework. We demonstrate theoretically that this problem induces sandbagging behaviour in optimal rational agents, and construct a statistical test to distinguish between sandbagging and incompetence from sequences of test scores. In simulation experiments, we investigate the reliability of this test in allowing us to distinguish between such behaviours in bandit models. This work aims to establish a potential avenue for developing robust statistical procedures for use in the science of frontier model evaluations.', 'abstract_zh': '评估前沿人工智能系统安全性的必要性日益凸显，有助于衡量此类模型的能力并识别部署前的风险。然而，已认识到如果人工智能代理意识到自己正在被评估，它们可能会故意隐藏危险的能力或在安全性相关任务中故意展示次优性能以被释放并避免被停用或重新训练。这种战略欺骗——通常称为“砂袋战术”——可能会削弱安全性评估的完整性。因此，识别能够区分真正缺乏能力的行为模式与砂袋战术一致的行为模式的方法是有价值的。在本文中，我们基于最近提出的生存多臂 bandit 框架，开发了一个战略欺骗的简单模型。我们理论证明了这个问题会导致最优理性代理进行砂袋战术行为，并构建了一个统计测试，可以从测试分数序列中区分砂袋战术与无能。在仿真实验中，我们研究了该测试在允许我们区分 bandit 模型中此类行为方面的可靠性。本文旨在为前沿模型评估科学中开发稳健的统计程序提供潜在途径。', 'title_zh': '简单生存多臂Bandit问题中的Sandbagging'}
{'arxiv_id': 'arXiv:2509.26216', 'title': 'Comparative Analysis of Ant Colony Optimization and Google OR-Tools for Solving the Open Capacitated Vehicle Routing Problem in Logistics', 'authors': 'Assem Omar, Youssef Omar, Marwa Solayman, Hesham Mansour', 'link': 'https://arxiv.org/abs/2509.26216', 'abstract': 'In modern logistics management systems, route planning requires high efficiency. The Open Capacitated Vehicle Routing Problem (OCVRP) deals with finding optimal delivery routes for a fleet of vehicles serving geographically distributed customers, without requiring the vehicles to return to the depot after deliveries. The present study is comparative in nature and speaks of two algorithms for OCVRP solution: Ant Colony Optimization (ACO), a nature-inspired metaheuristic; and Google OR-Tools, an industry-standard toolkit for optimization. Both implementations were developed in Python and using a custom dataset. Performance appraisal was based on routing efficiency, computation time, and scalability. The results show that ACO allows flexibility in routing parameters while OR-Tools runs much faster with more consistency and requires less input. This could help choose among routing strategies for scalable real-time logistics systems.', 'abstract_zh': '现代物流管理系统中，路径规划要求高效。开放车载车辆路径规划（OCVRP）旨在为分布地理上的客户提供最优配送路径，无需车辆在配送后返回仓库。本研究比较了两种OCVRP解决方案算法：蚂蚁 Colony 优化（ACO），一种受自然界启发的元启发式算法；以及谷歌OR-Tools，一种行业标准的优化工具包。两种实现均使用Python语言并基于自定义数据集开发。性能评估基于路径规划效率、计算时间和可扩展性。结果显示，ACO 在路由参数方面更为灵活，而OR-Tools 则运行更快、更一致，并且需要较少输入。这有助于在可扩展的实时物流系统中选择合适的路由策略。', 'title_zh': '开放容量车辆路线问题中蚁群优化与Google OR-Tools的比较分析'}
{'arxiv_id': 'arXiv:2509.26187', 'title': 'Optimizing Indoor Environmental Quality in Smart Buildings Using Deep Learning', 'authors': 'Youssef Sabiri, Walid Houmaidi, Aaya Bougrine, Salmane El Mansour Billah', 'link': 'https://arxiv.org/abs/2509.26187', 'abstract': 'Ensuring optimal Indoor Environmental Quality (IEQ) is vital for occupant health and productivity, yet it often comes at a high energy cost in conventional Heating, Ventilation, and Air Conditioning (HVAC) systems. This paper proposes a deep learning driven approach to proactively manage IEQ parameters specifically CO2 concentration, temperature, and humidity while balancing building energy efficiency. Leveraging the ROBOD dataset collected from a net-zero energy academic building, we benchmark three architectures--Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), and a hybrid Convolutional Neural Network LSTM (CNN-LSTM)--to forecast IEQ variables across various time horizons. Our results show that GRU achieves the best short-term prediction accuracy with lower computational overhead, whereas CNN-LSTM excels in extracting dominant features for extended forecasting windows. Meanwhile, LSTM offers robust long-range temporal modeling. The comparative analysis highlights that prediction reliability depends on data resolution, sensor placement, and fluctuating occupancy conditions. These findings provide actionable insights for intelligent Building Management Systems (BMS) to implement predictive HVAC control, thereby reducing energy consumption and enhancing occupant comfort in real-world building operations.', 'abstract_zh': '确保室内环境质量（IEQ）最优化对于提升 occupants 健康和 productivity 至关重要，但在传统 Heating, Ventilation, and Air Conditioning (HVAC) 系统中往往伴随着高昂的能耗。本文提出了一种基于深度学习的方法，旨在前瞻性地管理 IEQ 参数，如 CO2 浓度、温度和湿度，同时平衡建筑能效。利用从一座净零能耗学术建筑中收集的 ROBOD 数据集，我们对比了三种架构——Long Short-Term Memory (LSTM)、Gated Recurrent Units (GRU) 和 Convolutional Neural Network LSTM (CNN-LSTM)——在不同时间跨度下预测 IEQ 变量的表现。研究结果表明，GRU 在短期预测中表现出最高的精度且计算开销较低，而 CNN-LSTM 在长期预测中提取主导特征方面表现出色。同时，LSTM 提供了 robust 的长期时间序列建模能力。比较分析表明，预测可靠性取决于数据分辨率、传感器分布和不断变化的 occupancy 条件。这些发现为智能建筑管理系统（BMS）实施预测 HVAC 控制提供了实际指导，有助于在实际建筑运行中降低能耗并提升 occupant 舒适度。', 'title_zh': '利用深度学习优化智能建筑的室内环境质量'}
{'arxiv_id': 'arXiv:2509.26157', 'title': 'EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting', 'authors': 'Sachith Abeywickrama, Emadeldeen Eldele, Min Wu, Xiaoli Li, Chau Yuen', 'link': 'https://arxiv.org/abs/2509.26157', 'abstract': 'Transformer-based models have significantly advanced time series forecasting, with patch-based input strategies offering efficiency and improved long-horizon modeling. Yet, existing approaches rely on temporally-agnostic patch construction, where arbitrary starting positions and fixed lengths fracture temporal coherence by splitting natural transitions across boundaries. This naive segmentation often disrupts short-term dependencies and weakens representation learning. In response, we propose EntroPE (Entropy-Guided Dynamic Patch Encoder), a novel, temporally informed framework that dynamically detects transition points via conditional entropy and dynamically places patch boundaries. This preserves temporal structure while retaining the computational benefits of patching. EntroPE consists of two key modules, namely an Entropy-based Dynamic Patcher (EDP) that applies information-theoretic criteria to locate natural temporal shifts and determine patch boundaries, and an Adaptive Patch Encoder (APE) that employs pooling and cross-attention to capture intra-patch dependencies and produce fixed-size latent representations. These embeddings are then processed by a global transformer to model inter-patch dynamics. Experiments across long-term forecasting benchmarks demonstrate that EntroPE improves both accuracy and efficiency, establishing entropy-guided dynamic patching as a promising new paradigm for time series modeling. Code is available at: this https URL.', 'abstract_zh': '基于Transformer的EntroPE模型：基于熵导向的动态片段编码在时间序列预测中的应用', 'title_zh': 'EntroPE：熵引导的动态PATCH编码器在时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2509.26150', 'title': "Bubble, Bubble, AI's Rumble: Why Global Financial Regulatory Incident Reporting is Our Shield Against Systemic Stumbles", 'authors': 'Anchal Gupta, Gleb Pappyshev, James T Kwok', 'link': 'https://arxiv.org/abs/2509.26150', 'abstract': '"Double, double toil and trouble; Fire burn and cauldron bubble." As Shakespeare\'s witches foretold chaos through cryptic prophecies, modern capital markets grapple with systemic risks concealed by opaque AI systems. According to IMF, the August 5, 2024, plunge in Japanese and U.S. equities can be linked to algorithmic trading yet ab-sent from existing AI incidents database exemplifies this transparency crisis. Current AI incident databases, reliant on crowdsourcing or news scraping, systematically over-look capital market anomalies, particularly in algorithmic and high-frequency trading. We address this critical gap by proposing a regulatory-grade global database that elegantly synthesises post-trade reporting frameworks with proven incident documentation models from healthcare and aviation. Our framework\'s temporal data omission technique masking timestamps while preserving percent-age-based metrics enables sophisticated cross-jurisdictional analysis of emerging risks while safeguarding confidential business information. Synthetic data validation (modelled after real life published incidents , sentiments, data) reveals compelling pat-terns: systemic risks transcending geographical boundaries, market manipulation clusters distinctly identifiable via K-means algorithms, and AI system typology exerting significantly greater influence on trading behaviour than geographical location, This tripartite solution empowers regulators with unprecedented cross-jurisdictional oversight, financial institutions with seamless compliance integration, and investors with critical visibility into previously obscured AI-driven vulnerabilities. We call for immediate action to strengthen risk management and foster resilience in AI-driven financial markets against the volatile "cauldron" of AI-driven systemic risks., promoting global financial stability through enhanced transparency and coordinated oversight.', 'abstract_zh': '双重麻烦；火燃烧，锅沸腾。正如莎士比亚的女巫通过隐晦的预言预示混乱，现代资本市场则在不透明的人工智能系统掩盖下应对系统性风险。国际货币基金组织指出，2024年8月5日日本和美国股市的暴跌可以追溯到算法交易，但这一事件未被现有的人工智能事件数据库收录，这体现了透明度危机。当前的人工智能事件数据库依赖于众包或新闻抓取，系统性地忽视了资本市场异常，尤其是在算法交易和高频交易领域。我们通过提出一个监管级别的全球数据库来填补这一关键缺口，该数据库巧妙地结合了交易后报告框架与医疗和航空领域的 proven 事件记录模型。该框架通过时间数据省略技术隐藏时间戳同时保留基于百分比的指标，从而实现跨司法管辖区复杂的风险分析，同时保护敏感的商业信息。合成数据验证（基于真实生活中公布的事件、情绪和数据建模）揭示了有力的模式：超越地理边界的系统性风险、通过K-means算法可明确识别的市场操纵集群，以及人工智能系统类型对交易行为的影响远大于地理位置。这一三重解决方案赋予监管机构前所未有的跨司法管辖区监督权，为金融机构提供了无缝合规整合，并为投资者提供了对以往隐藏的人工智能驱动漏洞的至关重要的洞察。我们呼吁立即采取行动，加强风险管理和提高对人工智能驱动金融市场的系统性风险的韧性，通过增强透明度和协调监督促进全球金融稳定。', 'title_zh': '泡沫，泡沫，AI的震动：全球金融市场监管事件报告为何成为我们抵御系统性失误的盾牌'}
{'arxiv_id': 'arXiv:2509.26139', 'title': 'Leveraging AI modelling for FDS with Simvue: monitor and optimise for more sustainable simulations', 'authors': 'James Panayis, Matt Field, Vignesh Gopakumar, Andrew Lahiff, Kristian Zarebski, Aby Abraham, Jonathan L. Hodges', 'link': 'https://arxiv.org/abs/2509.26139', 'abstract': 'There is high demand on fire simulations, in both scale and quantity. We present a multi-pronged approach to improving the time and energy required to meet these demands. We show the ability of a custom machine learning surrogate model to predict the dynamics of heat propagation orders of magnitude faster than state-of-the-art CFD software for this application. We also demonstrate how a guided optimisation procedure can decrease the number of simulations required to meet an objective; using lightweight models to decide which simulations to run, we see a tenfold reduction when locating the most dangerous location for a fire to occur within a building based on the impact of smoke on visibility. Finally we present a framework and product, Simvue, through which we access these tools along with a host of automatic organisational and tracking features which enables future reuse of data and more savings through better management of simulations and combating redundancy.', 'abstract_zh': '对火灾模拟的需求在规模和数量上都非常高。我们提出了一种多管齐下的方法来提高满足这些需求所需的时间和能量。我们展示了自定义机器学习代理模型预测热量传播动力学的能力，比最先进的CFD软件快几个数量级。我们还展示了引导优化程序如何减少满足目标所需的模拟次数；使用轻量级模型来决定运行哪些模拟，在基于烟雾对能见度影响的基础上定位建筑中最危险的火灾位置时，我们看到了模拟次数十倍的减少。最后，我们介绍了Simvue这一框架和产品，通过它我们可以访问这些工具以及一系列自动组织和跟踪功能，从而实现数据的未来重用并更好地管理模拟以节省成本，同时减少冗余。', 'title_zh': '利用AI建模在Simvue中优化火灾动力学模拟：实现更加可持续的仿真监测与优化'}
{'arxiv_id': 'arXiv:2509.26120', 'title': 'AGOCS -- Accurate Google Cloud Simulator Framework', 'authors': 'Leszek Sliwko, Vladimir Getov', 'link': 'https://arxiv.org/abs/2509.26120', 'abstract': 'This paper presents the Accurate Google Cloud Simulator (AGOCS) - a novel high-fidelity Cloud workload simulator based on parsing real workload traces, which can be conveniently used on a desktop machine for day-to-day research. Our simulation is based on real-world workload traces from a Google Cluster with 12.5K nodes, over a period of a calendar month. The framework is able to reveal very precise and detailed parameters of the executed jobs, tasks and nodes as well as to provide actual resource usage statistics. The system has been implemented in Scala language with focus on parallel execution and an easy-to-extend design concept. The paper presents the detailed structural framework for AGOCS and discusses our main design decisions, whilst also suggesting alternative and possibly performance enhancing future approaches. The framework is available via the Open Source GitHub repository.', 'abstract_zh': '基于解析真实工作负载踪迹的Accurate Google Cloud Simulator (AGOCS)——一种新型高保真云工作负载仿真器', 'title_zh': 'AGOCS -- 准确的Google云模拟器框架'}
{'arxiv_id': 'arXiv:2509.26113', 'title': 'Enhancing PINN Performance Through Lie Symmetry Group', 'authors': 'Ali Haider Shah, Naveed R. Butt, Asif Ahmad, Muhammad Omer Bin Saeed', 'link': 'https://arxiv.org/abs/2509.26113', 'abstract': 'This paper presents intersection of Physics informed neural networks (PINNs) and Lie symmetry group to enhance the accuracy and efficiency of solving partial differential equation (PDEs). Various methods have been developed to solve these equations. A Lie group is an efficient method that can lead to exact solutions for the PDEs that possessing Lie Symmetry. Leveraging the concept of infinitesimal generators from Lie symmetry group in a novel manner within PINN leads to significant improvements in solution of PDEs. In this study three distinct cases are discussed, each showing progressive improvements achieved through Lie symmetry modifications and adaptive techniques. State-of-the-art numerical methods are adopted for comparing the progressive PINN models. Numerical experiments demonstrate the key role of Lie symmetry in enhancing PINNs performance, emphasizing the importance of integrating abstract mathematical concepts into deep learning for addressing complex scientific problems adequately.', 'abstract_zh': '物理 informant 神经网络 (PINNs) 与李群对称性的交集：提高偏微分方程 (PDEs) 求解的准确性和效率', 'title_zh': '通过李对称群提升PINN性能'}
{'arxiv_id': 'arXiv:2509.26094', 'title': 'On Computing Top-$k$ Simple Shortest Paths from a Single Source', 'authors': "Mattia D'Emidio, Gabriele Di Stefano", 'link': 'https://arxiv.org/abs/2509.26094', 'abstract': "We investigate the problem of computing the top-$k$ simple shortest paths in weighted digraphs. While the single-pair variant -- finding the top-$k$ simple shortest paths between two specified vertices -- has been extensively studied over the past decades, with Yen's algorithm and its heuristic improvements emerging as the most effective solving strategies, relatively little attention has been devoted to the more general single-source version, where the goal is determining top-$k$ simple shortest paths from a source vertex to all other vertices. Motivated by the numerous practical applications of ranked shortest paths, in this paper we provide new insights and algorithmic contributions to this problem. In particular, we first present a theoretical characterization of the structural properties of its solutions. Then, we introduce the first polynomial-time algorithm specifically designed to handle it. On the one hand, we prove our new algorithm is on par, in terms of time complexity, with the best (and only) polynomial-time approach known in the literature to solve the problem, that is applying the fastest single-pair algorithm independently to each vertex pair formed by the source and the remaining vertices. On the other hand, through an extensive experimental evaluation on both real-world and synthetic graphs, we demonstrate that our algorithm consistently and significantly outperforms the latter baseline in terms of running time, achieving speed-ups of up to several orders of magnitude. These results establish our new algorithm as the solution to be preferred for computing $k$ simple shortest paths from a single source in practical settings.", 'abstract_zh': '我们研究加权有向图中计算简单最短路径前k条的问题。虽然两个指定顶点之间的简单最短路径前k条这一单对变体在过去几十年里得到了广泛研究，Yen算法及其启发式改进成为最有效的求解策略，但针对更具一般性的单源版本——从一个源顶点到所有其他顶点的简单最短路径前k条的确定——的研究相对较少。受排名最短路径众多实际应用的启发，本文提供了对该问题的新见解和算法贡献。特别是，我们首先提供了解决方案的结构性质的理论刻画，然后介绍了首个专门为此设计的多项式时间算法。一方面，我们证明了我们的新算法在时间复杂度上与文献中已知的唯一一个多项式时间解决方法（对源顶点与剩余顶点形成的所有顶点对独立应用最快的单对算法）相当。另一方面，通过对实际网络和合成图进行广泛的实验评估，我们展示了我们的算法在运行时间上始终显著优于后者，并实现了几个数量级的速度提升。这些结果确立了我们的新算法为实际场景中从单个源计算k条简单最短路径的首选解决方案。', 'title_zh': '从单源计算Top-$k$最简短路径'}
{'arxiv_id': 'arXiv:2509.26058', 'title': 'Real-time Noise Detection and Classification in Single-Channel EEG: A Lightweight Machine Learning Approach for EMG, White Noise, and EOG Artifacts', 'authors': 'Hossein Enshaei, Pariya Jebreili, Sayed Mahmoud Sakahei', 'link': 'https://arxiv.org/abs/2509.26058', 'abstract': 'Electroencephalogram (EEG) artifact detection in real-world settings faces significant challenges such as computational inefficiency in multi-channel methods, poor robustness to simultaneous noise, and trade-offs between accuracy and complexity in deep learning models. We propose a hybrid spectral-temporal framework for real-time detection and classification of ocular (EOG), muscular (EMG), and white noise artifacts in single-channel EEG. This method, in contrast to other approaches, combines time-domain low-pass filtering (targeting low-frequency EOG) and frequency-domain power spectral density (PSD) analysis (capturing broad-spectrum EMG), followed by PCA-optimized feature fusion to minimize redundancy while preserving discriminative information. This feature engineering strategy allows a lightweight multi-layer perceptron (MLP) architecture to outperform advanced CNNs and RNNs by achieving 99% accuracy at low SNRs (SNR -7) dB and >90% accuracy in moderate noise (SNR 4 dB). Additionally, this framework addresses the unexplored problem of simultaneous multi-source contamination(EMG+EOG+white noise), where it maintains 96% classification accuracy despite overlapping artifacts. With 30-second training times (97% faster than CNNs) and robust performance across SNR levels, this framework bridges the gap between clinical applicability and computational efficiency, which enables real-time use in wearable brain-computer interfaces. This work also challenges the ubiquitous dependence on model depth for EEG artifact detection by demonstrating that domain-informed feature fusion surpasses complex architecture in noisy scenarios.', 'abstract_zh': '实时单通道EEG眼动（EOG）、肌电（EMG）和白噪声 artifact 检测与分类的混合时频框架', 'title_zh': '单通道EEG中实时噪声检测与分类：一种针对EMG、白噪声和EOG伪迹的轻量级机器学习方法'}
{'arxiv_id': 'arXiv:2509.26051', 'title': 'CEAID: Benchmark of Multilingual Machine-Generated Text Detection Methods for Central European Languages', 'authors': 'Dominik Macko, Jakub Kopal', 'link': 'https://arxiv.org/abs/2509.26051', 'abstract': 'Machine-generated text detection, as an important task, is predominantly focused on English in research. This makes the existing detectors almost unusable for non-English languages, relying purely on cross-lingual transferability. There exist only a few works focused on any of Central European languages, leaving the transferability towards these languages rather unexplored. We fill this gap by providing the first benchmark of detection methods focused on this region, while also providing comparison of train-languages combinations to identify the best performing ones. We focus on multi-domain, multi-generator, and multilingual evaluation, pinpointing the differences of individual aspects, as well as adversarial robustness of detection methods. Supervised finetuned detectors in the Central European languages are found the most performant in these languages as well as the most resistant against obfuscation.', 'abstract_zh': '机器生成文本检测是重要的研究任务，现有研究主要集中在英文上。这使得现有的检测器几乎无法用于非英文语言，主要依赖于跨语言的可迁移性。对于任何中欧语言的相关工作甚少，使得这些语言上的迁移性尚未得到充分探索。我们通过提供第一个专注于这一地区的检测方法基准，同时对比不同训练语言组合以确定表现最佳的组合，来填补这一空白。我们关注多领域、多生成器和多语言的评估，揭示各个方面的差异，以及检测方法的对抗鲁棒性。在中欧语言中，有监督微调的检测器表现出最佳性能，并且对混淆最具抵抗力。', 'title_zh': 'CEAID：中央欧洲语言机器生成文本检测方法基准'}
{'arxiv_id': 'arXiv:2509.26015', 'title': 'Indirect Attention: Turning Context Misalignment into a Feature', 'authors': 'Bissmella Bahaduri, Hicham Talaoubrid, Fangchen Feng, Zuheng Ming, Anissa Mokraoui', 'link': 'https://arxiv.org/abs/2509.26015', 'abstract': "The attention mechanism has become a cornerstone of modern deep learning architectures, where keys and values are typically derived from the same underlying sequence or representation. This work explores a less conventional scenario, when keys and values originate from different sequences or modalities. Specifically, we first analyze the attention mechanism's behavior under noisy value features, establishing a critical noise threshold beyond which signal degradation becomes significant. Furthermore, we model context (key, value) misalignment as an effective form of structured noise within the value features, demonstrating that the noise induced by such misalignment can substantially exceed this critical threshold, thereby compromising standard attention's efficacy. Motivated by this, we introduce Indirect Attention, a modified attention mechanism that infers relevance indirectly in scenarios with misaligned context. We evaluate the performance of Indirect Attention across a range of synthetic tasks and real world applications, showcasing its superior ability to handle misalignment.", 'abstract_zh': '间接注意力：处理上下文错位的一种修改注意力机制', 'title_zh': '间接注意力：将上下文错位转为特征'}
{'arxiv_id': 'arXiv:2509.25979', 'title': 'Reconcile Certified Robustness and Accuracy for DNN-based Smoothed Majority Vote Classifier', 'authors': 'Gaojie Jin, Xinping Yi, Xiaowei Huang', 'link': 'https://arxiv.org/abs/2509.25979', 'abstract': 'Within the PAC-Bayesian framework, the Gibbs classifier (defined on a posterior $Q$) and the corresponding $Q$-weighted majority vote classifier are commonly used to analyze the generalization performance. However, there exists a notable lack in theoretical research exploring the certified robustness of majority vote classifier and its interplay with generalization. In this study, we develop a generalization error bound that possesses a certified robust radius for the smoothed majority vote classifier (i.e., the $Q$-weighted majority vote classifier with smoothed inputs); In other words, the generalization bound holds under any data perturbation within the certified robust radius. As a byproduct, we find that the underpinnings of both the generalization bound and the certified robust radius draw, in part, upon weight spectral norm, which thereby inspires the adoption of spectral regularization in smooth training to boost certified robustness. Utilizing the dimension-independent property of spherical Gaussian inputs in smooth training, we propose a novel and inexpensive spectral regularizer to enhance the smoothed majority vote classifier. In addition to the theoretical contribution, a set of empirical results is provided to substantiate the effectiveness of our proposed method.', 'abstract_zh': '在PAC-Bayesian框架下，基于后验$Q$的吉布斯分类器及其相应的$Q$加权多数投票分类器常被用于分析泛化性能。然而，对于多数投票分类器的认证鲁棒性以及其与泛化之间的相互作用，理论研究存在明显不足。在本研究中，我们开发了一个泛化误差界，该误差界具有对平滑多数投票分类器（即带有平滑输入的$Q$加权多数投票分类器）的认证鲁棒半径；换句话说，该泛化界在认证鲁棒半径内的任何数据扰动下均成立。作为副产品，我们发现泛化界和认证鲁棒半径的理论基础部分依赖于权重谱范数，这启发我们通过在平滑训练中采用谱正则化来提高认证鲁棒性。利用平滑训练中球形高斯输入的维数无关性质，我们提出了一种新颖且经济高效的谱正则化器，以提升平滑多数投票分类器。除了理论贡献外，我们还提供了一系列实验证据以验证所提出方法的有效性。', 'title_zh': '基于平滑多数投票分类器的认证鲁棒性和准确性的统一'}
{'arxiv_id': 'arXiv:2509.25977', 'title': 'Data-Free Continual Learning of Server Models in Model-Heterogeneous Federated learning', 'authors': 'Xiao Zhang, Zengzhe Chen, Yuan Yuan, Yifei Zou, Fuzhen Zhuang, Wenyu Jiao, Yuke Wang, Dongxiao Yu', 'link': 'https://arxiv.org/abs/2509.25977', 'abstract': 'Federated learning (FL) is a distributed learning paradigm across multiple entities while preserving data privacy. However, with the continuous emergence of new data and increasing model diversity, traditional federated learning faces significant challenges, including inherent issues of data heterogeneity, model heterogeneity and catastrophic forgetting, along with new challenge of knowledge misalignment. In this study, we introduce FedDCL, a novel framework designed to enable data-free continual learning of the server model in a model-heterogeneous federated setting. We leverage pre-trained diffusion models to extract lightweight class-specific prototypes, which confer a threefold data-free advantage, enabling: (1) generation of synthetic data for the current task to augment training and counteract non-IID data distributions; (2) exemplar-free generative replay for retaining knowledge from previous tasks; and (3) data-free dynamic knowledge transfer from heterogeneous clients to the server. Experimental results on various datasets demonstrate the effectiveness of FedDCL, showcasing its potential to enhance the generalizability and practical applicability of federated learning in dynamic settings.', 'abstract_zh': '联邦学习（FL）是一种在多个实体之间进行分布式学习的范式，同时保护数据隐私。然而，随着新数据的不断出现和模型多样性的增加，传统的联邦学习面临着诸如数据异质性、模型异质性和灾难性遗忘等根本性挑战，同时还面临着知识错位的新挑战。在本研究中，我们介绍了FedDCL，这是一种新颖的框架，旨在在异质模型联邦环境中实现服务器模型的数据无关连续学习。我们利用预训练的扩散模型提取轻量级的类特异性原型，赋予该框架三重数据无关的优势，包括：（1）为当前任务生成合成数据以增强训练并对抗非IID数据分布；（2）无需示例的生成性重放以保留前任务的知识；（3）从异质客户端到服务器的数据无关动态知识转移。在各种数据集上的实验结果证明了FedDCL的有效性，展示了其在动态环境中增强联邦学习的普适性和实际应用潜力。', 'title_zh': '服务器模型在模型异构联邦学习中的无数据连续学习'}
{'arxiv_id': 'arXiv:2509.25955', 'title': 'AIM: Adaptive Intervention for Deep Multi-task Learning of Molecular Properties', 'authors': 'Mason Minot, Gisbert Schneider', 'link': 'https://arxiv.org/abs/2509.25955', 'abstract': "Simultaneously optimizing multiple, frequently conflicting, molecular properties is a key bottleneck in the development of novel therapeutics. Although a promising approach, the efficacy of multi-task learning is often compromised by destructive gradient interference, especially in the data-scarce regimes common to drug discovery. To address this, we propose AIM, an optimization framework that learns a dynamic policy to mediate gradient conflicts. The policy is trained jointly with the main network using a novel augmented objective composed of dense, differentiable regularizers. This objective guides the policy to produce updates that are geometrically stable and dynamically efficient, prioritizing progress on the most challenging tasks. We demonstrate that AIM achieves statistically significant improvements over multi-task baselines on subsets of the QM9 and targeted protein degraders benchmarks, with its advantage being most pronounced in data-scarce regimes. Beyond performance, AIM's key contribution is its interpretability; the learned policy matrix serves as a diagnostic tool for analyzing inter-task relationships. This combination of data-efficient performance and diagnostic insight highlights the potential of adaptive optimizers to accelerate scientific discovery by creating more robust and insightful models for multi-property molecular design.", 'abstract_zh': '同时优化多个经常相互冲突的分子属性是新型治疗药物开发中的一个关键瓶颈。尽管多任务学习是一个有前景的方法，但在药物发现中常见的数据稀缺情况下，其效果往往会受到破坏性梯度干扰的阻碍。为了解决这个问题，我们提出了一种动态策略学习框架AIM，该框架学习一种动态策略来调解梯度冲突。该策略与主要网络联合训练，并使用一种新的增强目标函数，该目标函数包含密集可微正则化项。该目标函数引导策略生成几何上稳定且动态高效的更新，优先解决最具挑战性的任务。我们证明，AIM在QM9和靶向蛋白降解物基准数据集的子集中，相对于多任务 baseline 实现了统计显著的改进，其优势在数据稀缺的情况下尤为明显。除了性能提升，AIM 的关键贡献在于其实现可解释性；学习到的策略矩阵可以作为分析任务间关系的诊断工具。这种高效使用数据性能与诊断洞察力的结合，突显了自适应优化器在通过创建更多鲁棒性和洞察力更强的多属性分子设计模型加速科学发现方面的潜力。', 'title_zh': '适应性干预的深度多任务学习分子性质方法'}
{'arxiv_id': 'arXiv:2509.25927', 'title': 'The Impact of Scaling Training Data on Adversarial Robustness', 'authors': 'Marco Zimmerli, Andreas Plesner, Till Aczel, Roger Wattenhofer', 'link': 'https://arxiv.org/abs/2509.25927', 'abstract': 'Deep neural networks remain vulnerable to adversarial examples despite advances in architectures and training paradigms. We investigate how training data characteristics affect adversarial robustness across 36 state-of-the-art vision models spanning supervised, self-supervised, and contrastive learning approaches, trained on datasets from 1.2M to 22B images. Models were evaluated under six black-box attack categories: random perturbations, two types of geometric masks, COCO object manipulations, ImageNet-C corruptions, and ImageNet-R style shifts. Robustness follows a logarithmic scaling law with both data volume and model size: a tenfold increase in data reduces attack success rate (ASR) on average by ~3.2%, whereas a tenfold increase in model size reduces ASR on average by ~13.4%. Notably, some self-supervised models trained on curated datasets, such as DINOv2, outperform others trained on much larger but less curated datasets, challenging the assumption that scale alone drives robustness. Adversarial fine-tuning of ResNet50s improves generalization across structural variations but not across color distributions. Human evaluation reveals persistent gaps between human and machine vision. These results show that while scaling improves robustness, data quality, architecture, and training objectives play a more decisive role than raw scale in achieving broad-spectrum adversarial resilience.', 'abstract_zh': '深度神经网络在架构和训练范式的进步下仍然容易受到对手样例的攻击。我们研究了训练数据特性如何影响36种前沿视觉模型的 adversarial 抗性，这些模型涵盖了监督学习、自监督学习和对比学习方法，训练数据集规模从120万到220亿不等。模型在六类黑盒攻击类别下进行了评估：随机扰动、两种类型的几何遮罩、COCO目标操作、ImageNet-C腐蚀和ImageNet-R风格变化。抗性随着数据量和模型规模的增加呈现出对数级别缩放：数据量增加十倍，攻击成功率平均下降约3.2%；模型规模增加十倍，攻击成功率平均下降约13.4%。值得注意的是，一些在精心策划的数据集上训练的自监督模型，如DINOv2，比在更大但更加不策划的数据集上训练的其他模型表现更好，这挑战了单纯规模决定抗性的假设。ResNet50的对抗微调在结构变化中改善了泛化能力，但在颜色分布方面并没有改善。人类评估揭示了人类视觉和机器视觉之间持续存在的差距。这些结果表明，虽然规模的增加可以提高抗性，但数据质量、架构和训练目标在实现广泛谱系的对抗鲁棒性方面发挥着比单纯规模更重要的作用。', 'title_zh': '扩展训练数据对对抗鲁棒性的影响'}
{'arxiv_id': 'arXiv:2509.25905', 'title': 'User-Centric Communication Service Provision for Edge-Assisted Mobile Augmented Reality', 'authors': 'Conghao Zhou, Jie Gao, Shisheng Hu, Nan Cheng, Weihua Zhuang, Xuemin Shen', 'link': 'https://arxiv.org/abs/2509.25905', 'abstract': 'Future 6G networks are envisioned to facilitate edge-assisted mobile augmented reality (MAR) via strengthening the collaboration between MAR devices and edge servers. In order to provide immersive user experiences, MAR devices must timely upload camera frames to an edge server for simultaneous localization and mapping (SLAM)-based device pose tracking. In this paper, to cope with user-specific and non-stationary uplink data traffic, we develop a digital twin (DT)-based approach for user-centric communication service provision for MAR. Specifically, to establish DTs for individual MAR devices, we first construct a data model customized for MAR that captures the intricate impact of the SLAM-based frame uploading mechanism on the user-specific data traffic pattern. We then define two DT operation functions that cooperatively enable adaptive switching between different data-driven models for capturing non-stationary data traffic. Leveraging the user-oriented data management introduced by DTs, we propose an algorithm for network resource management that ensures the timeliness of frame uploading and the robustness against inherent inaccuracies in data traffic modeling for individual MAR devices. Trace-driven simulation results demonstrate that the user-centric communication service provision achieves a 14.2% increase in meeting the camera frame uploading delay requirement in comparison with the slicing-based communication service provision widely used for 5G.', 'abstract_zh': '未来6G网络通过加强移动增强现实（MAR）设备与边缘服务器之间的协作，旨在促进边缘辅助移动增强现实。为了提供沉浸式用户体验，MAR设备必须及时将摄像头帧上传到边缘服务器，进行基于SLAM的设备姿态跟踪。在本文中，为了应对用户特定和非平稳上行数据流量，我们开发了一种基于数字孪生（DT）的方法，以提供以用户为中心的通信服务，针对MAR。具体来说，为了为每个MAR设备建立DT，我们首先构建了一个针对MAR定制的数据模型，以捕捉基于SLAM的帧上传机制对用户特定数据流量模式的复杂影响。我们然后定义了两种协同工作的DT操作函数，以适应性地在不同的数据驱动模型之间切换，以捕捉非平稳数据流量。利用DT引入的用户导向的数据管理方法，我们提出了一种网络资源管理算法，以确保帧上传的及时性和数据流量模型固有不准确性对MAR设备的影响的鲁棒性。基于跟踪的模拟结果表明，以用户为中心的通信服务提供相较于广泛应用于5G的切片通信服务提供，满足摄像头帧上传延迟要求的能力提高了14.2%。', 'title_zh': '边缘辅助移动增强现实的用户中心通信服务提供'}
{'arxiv_id': 'arXiv:2509.25884', 'title': 'scUnified: An AI-Ready Standardized Resource for Single-Cell RNA Sequencing Analysis', 'authors': 'Ping Xu, Zaitian Wang, Zhirui Wang, Pengjiang Li, Ran Zhang, Gaoyang Li, Hanyu Xie, Jiajia Wang, Yuanchun Zhou, Pengfei Wang', 'link': 'https://arxiv.org/abs/2509.25884', 'abstract': 'Single-cell RNA sequencing (scRNA-seq) technology enables systematic delineation of cellular states and interactions, providing crucial insights into cellular heterogeneity. Building on this potential, numerous computational methods have been developed for tasks such as cell clustering, cell type annotation, and marker gene identification. To fully assess and compare these methods, standardized, analysis-ready datasets are essential. However, such datasets remain scarce, and variations in data formats, preprocessing workflows, and annotation strategies hinder reproducibility and complicate systematic evaluation of existing methods. To address these challenges, we present scUnified, an AI-ready standardized resource for single-cell RNA sequencing data that consolidates 13 high-quality datasets spanning two species (human and mouse) and nine tissue types. All datasets undergo standardized quality control and preprocessing and are stored in a uniform format to enable direct application in diverse computational analyses without additional data cleaning. We further demonstrate the utility of scUnified through experimental analyses of representative biological tasks, providing a reproducible foundation for the standardized evaluation of computational methods on a unified dataset.', 'abstract_zh': '单细胞RNA测序（scRNA-seq）技术 enables系统解析细胞状态和相互作用，为细胞异质性提供了关键洞见。在此基础上，开发了多种计算方法，用于细胞聚类、细胞类型注释和标志基因识别等任务。为进一步评估和比较这些方法，标准化和分析准备好的数据集至关重要。然而，此类数据集仍然稀缺，数据格式、预处理工作流程和注释策略的差异阻碍了可重复性并复杂了对现有方法的系统性评估。为应对这些挑战，我们介绍了一种AI就绪的标准化资源scUnified，整合了涵盖两种物种（人类和小鼠）和九种组织类型的13个高质量数据集。所有数据集都经过标准化的质量控制和预处理，并采用统一格式存储，以确保可以直接应用于多种计算分析而无需额外的数据清洗。此外，我们通过代表性生物任务的实验分析展示了scUnified的实用性，为在统一数据集上标准化评估计算方法提供了可重复的基础。', 'title_zh': 'scUnified：一个面向AI的标准单细胞RNA测序分析资源'}
{'arxiv_id': 'arXiv:2509.25841', 'title': 'S$^2$FS: Spatially-Aware Separability-Driven Feature Selection in Fuzzy Decision Systems', 'authors': 'Suping Xu, Chuyi Dai, Ye Liu, Lin Shang, Xibei Yang, Witold Pedrycz', 'link': 'https://arxiv.org/abs/2509.25841', 'abstract': 'Feature selection is crucial for fuzzy decision systems (FDSs), as it identifies informative features and eliminates rule redundancy, thereby enhancing predictive performance and interpretability. Most existing methods either fail to directly align evaluation criteria with learning performance or rely solely on non-directional Euclidean distances to capture relationships among decision classes, which limits their ability to clarify decision boundaries. However, the spatial distribution of instances has a potential impact on the clarity of such boundaries. Motivated by this, we propose Spatially-aware Separability-driven Feature Selection (S$^2$FS), a novel framework for FDSs guided by a spatially-aware separability criterion. This criterion jointly considers within-class compactness and between-class separation by integrating scalar-distances with spatial directional information, providing a more comprehensive characterization of class structures. S$^2$FS employs a forward greedy strategy to iteratively select the most discriminative features. Extensive experiments on ten real-world datasets demonstrate that S$^2$FS consistently outperforms eight state-of-the-art feature selection algorithms in both classification accuracy and clustering performance, while feature visualizations further confirm the interpretability of the selected features.', 'abstract_zh': '面向模糊决策系统的空间感知可分性驱动特征选择（S$^2$FS）', 'title_zh': 'S$^2$FS：模糊决策系统中基于空间感知可分性驱动的特征选择'}
{'arxiv_id': 'arXiv:2509.25839', 'title': 'RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search', 'authors': 'Han Zhang, Dongfang Zhao', 'link': 'https://arxiv.org/abs/2509.25839', 'abstract': "While high-dimensional embedding vectors are being increasingly employed in various tasks like Retrieval-Augmented Generation and Recommendation Systems, popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely been adopted for accelerating the retrieval process due to their inability of preserving the nearest neighbor (NN) relationship among vectors. Empowered by neural networks' optimization capability and the bounding effect of Rayleigh quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving dimensionality reduction. RAE constrains the network parameter variation through regularization terms, adjusting singular values to control embedding magnitude changes during reduction, thus preserving k-NN relationships. We provide a rigorous mathematical analysis demonstrating that regularization establishes an upper bound on the norm distortion rate of transformed vectors, thereby offering provable guarantees for k-NN preservation. With modest training overhead, RAE achieves superior k-NN recall compared to existing DR approaches while maintaining fast retrieval efficiency.", 'abstract_zh': '高维嵌入向量在 Retrieval-Augmented Generation 和推荐系统等任务中的应用越来越广泛，尽管如此，PCA 和 UMAP 等流行降维方法由于无法保持向量的最近邻关系而鲜少被用于加速检索过程。依托神经网络的优化能力和瑞利商的边界效应，我们提出了一种正则化自编码器（RAE）来进行 k-NN 保持降维。RAE 通过正则化项约束网络参数的变动，调整奇异值以控制在降维过程中嵌入表示的尺度变化，从而保持 k-NN 关系。我们提供了严格的数学分析，证明正则化在转换向量的范数失真率上建立了上限，从而为 k-NN 保持提供了可证明的保证。在轻微的训练开销下，RAE 在保持快速检索效率的同时，实现了优于现有降维方法的 k-NN 召回率。', 'title_zh': 'RAE：一种用于向量搜索中最近邻保留的神经网络降维方法'}
{'arxiv_id': 'arXiv:2509.25834', 'title': 'Supporting Creative Ownership through Deep Learning-Based Music Variation', 'authors': 'Stephen James Krol, Maria Teresa Llano, Jon McCormack', 'link': 'https://arxiv.org/abs/2509.25834', 'abstract': "This paper investigates the importance of personal ownership in musical AI design, examining how practising musicians can maintain creative control over the compositional process. Through a four-week ecological evaluation, we examined how a music variation tool, reliant on the skill of musicians, functioned within a composition setting. Our findings demonstrate that the dependence of the tool on the musician's ability, to provide a strong initial musical input and to turn moments into complete musical ideas, promoted ownership of both the process and artefact. Qualitative interviews further revealed the importance of this personal ownership, highlighting tensions between technological capability and artistic identity. These findings provide insight into how musical AI can support rather than replace human creativity, highlighting the importance of designing tools that preserve the humanness of musical expression.", 'abstract_zh': '个人所有权在音乐AI设计中的重要性：作曲过程中的创意控制探究', 'title_zh': '基于深度学习的音乐变体支持创意所有权'}
{'arxiv_id': 'arXiv:2509.25810', 'title': 'Learning to Reason as Action Abstractions with Scalable Mid-Training RL', 'authors': 'Shenao Zhang, Donghan Yu, Yihao Feng, Bowen Jin, Zhaoran Wang, John Peebles, Zirui Wang', 'link': 'https://arxiv.org/abs/2509.25810', 'abstract': 'Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces.', 'abstract_zh': '大型语言模型在强化学习中的表现优异，但要完全挖掘其潜力需要一个中期训练阶段。有效的中期训练阶段应识别出一个有用的紧凑动作集，并通过在线强化学习快速从中进行选择。我们通过展示中期训练如何塑造后续训练的第一个理论结果，来形式化这一直觉：中期训练刻画了一个动作子空间，该子空间同时最小化剪枝带来的价值近似误差和后续规划中的RL误差。我们的分析揭示了中期训练有效性中的两个关键决定因素：剪枝效率，它塑造了初始RL策略的先验，以及其对RL收敛的影响，这决定了策略通过在线交互可以被改进的程度。这些结果表明，当决策空间紧凑且有效时间跨度较短时，中期训练最为有效，突显了在动作抽象空间中操作的重要性而非原始动作。基于这些见解，我们提出了Reasoning as Action Abstractions (RA3)，一种可扩展的中期训练算法。具体地，我们推导出一个顺序变分下界，并通过迭代发现时间一致的潜在结构来优化它，随后在种子数据上进行微调。在代码生成任务上的实验表明我们方法的有效性。在多个基础模型上，RA3分别在HumanEval和MBPP上将平均性能提高了8分和4分超过基础模型和下一个token预测基线。此外，RA3在HumanEval+、MBPP+、LiveCodeBench和Codeforces上的RLVR中实现了更快的收敛和更高的渐近性能。', 'title_zh': '基于动作抽象的可扩展中期训练RL学习推理'}
{'arxiv_id': 'arXiv:2509.25804', 'title': 'CardioForest: An Explainable Ensemble Learning Model for Automatic Wide QRS Complex Tachycardia Diagnosis from ECG', 'authors': 'Vaskar Chakma, Ju Xiaolin, Heling Cao, Xue Feng, Ji Xiaodong, Pan Haiyan, Gao Zhan', 'link': 'https://arxiv.org/abs/2509.25804', 'abstract': "This study aims to develop and evaluate an ensemble machine learning-based framework for the automatic detection of Wide QRS Complex Tachycardia (WCT) from ECG signals, emphasizing diagnostic accuracy and interpretability using Explainable AI. The proposed system integrates ensemble learning techniques, i.e., an optimized Random Forest known as CardioForest, and models like XGBoost and LightGBM. The models were trained and tested on ECG data from the publicly available MIMIC-IV dataset. The testing was carried out with the assistance of accuracy, balanced accuracy, precision, recall, F1 score, ROC-AUC, and error rate (RMSE, MAE) measures. In addition, SHAP (SHapley Additive exPlanations) was used to ascertain model explainability and clinical relevance. The CardioForest model performed best on all metrics, achieving a test accuracy of 94.95%, a balanced accuracy of 88.31%, and high precision and recall metrics. SHAP analysis confirmed the model's ability to rank the most relevant ECG features, such as QRS duration, in accordance with clinical intuitions, thereby fostering trust and usability in clinical practice. The findings recognize CardioForest as an extremely dependable and interpretable WCT detection model. Being able to offer accurate predictions and transparency through explainability makes it a valuable tool to help cardiologists make timely and well-informed diagnoses, especially for high-stakes and emergency scenarios.", 'abstract_zh': '基于集成机器学习的Wide QRS Complex Tachycardia自动检测框架发展与评估：结合可解释人工智能强调诊断准确性和可解释性', 'title_zh': 'CardioForest: 一种可解释的集成学习模型，用于从ECG自动诊断宽QRS综合征心动过速'}
{'arxiv_id': 'arXiv:2509.25775', 'title': 'Autonomy-Aware Clustering: When Local Decisions Supersede Global Prescriptions', 'authors': 'Amber Srivastava, Salar Basiri, Srinivasa Salapaka', 'link': 'https://arxiv.org/abs/2509.25775', 'abstract': 'Clustering arises in a wide range of problem formulations, yet most existing approaches assume that the entities under clustering are passive and strictly conform to their assigned groups. In reality, entities often exhibit local autonomy, overriding prescribed associations in ways not fully captured by feature representations. Such autonomy can substantially reshape clustering outcomes -- altering cluster compositions, geometry, and cardinality -- with significant downstream effects on inference and decision-making. We introduce autonomy-aware clustering, a reinforcement (RL) learning framework that learns and accounts for the influence of local autonomy without requiring prior knowledge of its form. Our approach integrates RL with a deterministic annealing (DA) procedure, where, to determine underlying clusters, DA naturally promotes exploration in early stages of annealing and transitions to exploitation later. We also show that the annealing procedure exhibits phase transitions that enable design of efficient annealing schedules. To further enhance adaptability, we propose the Adaptive Distance Estimation Network (ADEN), a transformer-based attention model that learns dependencies between entities and cluster representatives within the RL loop, accommodates variable-sized inputs and outputs, and enables knowledge transfer across diverse problem instances. Empirical results show that our framework closely aligns with underlying data dynamics: even without explicit autonomy models, it achieves solutions close to the ground truth (gap ~3-4%), whereas ignoring autonomy leads to substantially larger gaps (~35-40%). The code and data are publicly available at this https URL.', 'abstract_zh': '自治感知聚类', 'title_zh': '自主性导向聚类：当局部决策超越全局规定'}
{'arxiv_id': 'arXiv:2509.25729', 'title': 'Controlled Generation for Private Synthetic Text', 'authors': 'Zihao Zhao, Anjalie Field', 'link': 'https://arxiv.org/abs/2509.25729', 'abstract': 'Text anonymization is essential for responsibly developing and deploying AI in high-stakes domains such as healthcare, social services, and law. In this work, we propose a novel methodology for privacy-preserving synthetic text generation that leverages the principles of de-identification and the Hiding In Plain Sight (HIPS) theory. Our approach introduces entity-aware control codes to guide controllable generation using either in-context learning (ICL) or prefix tuning. The ICL variant ensures privacy levels consistent with the underlying de-identification system, while the prefix tuning variant incorporates a custom masking strategy and loss function to support scalable, high-quality generation. Experiments on legal and clinical datasets demonstrate that our method achieves a strong balance between privacy protection and utility, offering a practical and effective solution for synthetic text generation in sensitive domains.', 'abstract_zh': '隐私保护的合成文本生成方法：基于去标识化和Hiding In Plain Sight理论的新范式', 'title_zh': '控制生成的私有合成文本'}
{'arxiv_id': 'arXiv:2509.25724', 'title': 'Towards A Universally Transferable Acceleration Method for Density Functional Theory', 'authors': 'Zhe Liu, Yuyan Ni, Zhichen Pu, Qiming Sun, Siyuan Liu, Wen Yan', 'link': 'https://arxiv.org/abs/2509.25724', 'abstract': 'Recently, sophisticated deep learning-based approaches have been developed for generating efficient initial guesses to accelerate the convergence of density functional theory (DFT) calculations. While the actual initial guesses are often density matrices (DM), quantities that can convert into density matrices also qualify as alternative forms of initial guesses. Hence, existing works mostly rely on the prediction of the Hamiltonian matrix for obtaining high-quality initial guesses. However, the Hamiltonian matrix is both numerically difficult to predict and intrinsically non-transferable, hindering the application of such models in real scenarios. In light of this, we propose a method that constructs DFT initial guesses by predicting the electron density in a compact auxiliary basis representation using E(3)-equivariant neural networks. Trained on small molecules with up to 20 atoms, our model is able to achieve an average 33.3% self-consistent field (SCF) step reduction on systems up to 60 atoms, substantially outperforming Hamiltonian-centric and DM-centric models. Critically, this acceleration remains nearly constant with increasing system sizes and exhibits strong transferring behaviors across orbital basis sets and exchange-correlation (XC) functionals. To the best of our knowledge, this work represents the first and robust candidate for a universally transferable DFT acceleration method. We are also releasing the SCFbench dataset and its accompanying code to facilitate future research in this promising direction.', 'abstract_zh': '最近，基于深度学习的先进方法被开发出来，用于生成高效初始猜测以加速密度泛函理论（DFT）计算的收敛。虽然实际的初始猜测往往是密度矩阵（DM），但能够转换为密度矩阵的量也可以作为初始猜测的替代形式。因此，现有工作主要依赖于预测哈密顿矩阵来获得高质量的初始猜测。然而，哈密顿矩阵既难以预测，又本质上不可移植，阻碍了此类模型的实际应用。为了解决这一问题，我们提出了一种方法，通过使用E(3)-等变神经网络预测紧凑辅助基表示中的电子密度来构建DFT初始猜测。在最多含有20个原子的小分子上训练，我们的模型能够实现多达60个原子系统的平均33.3%自洽场（SCF）步数减少，显著优于以哈密顿矩阵为中心和以密度矩阵为中心的模型。尤其重要的是，这种加速在系统增大时几乎保持不变，并且在不同轨道基组和交换相关（XC）泛函之间表现出强大的可移植性。据我们所知，这项工作代表了首个且稳健的普遍可移植的DFT加速方法。我们还发布了SCFbench数据集及其配套代码，以促进该有前途方向的未来研究。', 'title_zh': '面向密度泛函理论的通用加速方法探索'}
{'arxiv_id': 'arXiv:2509.25721', 'title': 'The AI Productivity Index (APEX)', 'authors': 'Bertie Vidgen, Abby Fennelly, Evan Pinnix, Chirag Mahapatra, Zach Richards, Austin Bridges, Calix Huang, Ben Hunsberger, Fez Zafar, Brendan Foody, Dominic Barton, Cass R. Sunstein, Eric Topol, Osvald Nitski', 'link': 'https://arxiv.org/abs/2509.25721', 'abstract': "We introduce the first version of the AI Productivity Index (APEX), a benchmark for assessing whether frontier AI models can perform knowledge work with high economic value. APEX addresses one of the largest inefficiencies in AI research: outside of coding, benchmarks often fail to test economically relevant capabilities. APEX-v1.0 contains 200 test cases and covers four domains: investment banking, management consulting, law, and primary medical care. It was built in three steps. First, we sourced experts with top-tier experience e.g., investment bankers from Goldman Sachs. Second, experts created prompts that reflect high-value tasks in their day-to-day work. Third, experts created rubrics for evaluating model responses. We evaluate 23 frontier models on APEX-v1.0 using an LM judge. GPT 5 (Thinking = High) achieves the highest mean score (64.2%), followed by Grok 4 (61.3%) and Gemini 2.5 Flash (Thinking = On) (60.4%). Qwen 3 235B is the best performing open-source model and seventh best overall. There is a large gap between the performance of even the best models and human experts, highlighting the need for better measurement of models' ability to produce economically valuable work.", 'abstract_zh': 'AI生产力指数（APEX）初探：一个评估前沿AI模型在高经济价值知识工作表现的基准', 'title_zh': 'AI生产力指数（APEX）'}
{'arxiv_id': 'arXiv:2509.25716', 'title': 'DeepCodeSeek: Real-Time API Retrieval for Context-Aware Code Generation', 'authors': 'Esakkivel Esakkiraja, Denis Akhiyarov, Aditya Shanmugham, Chitra Ganapathy', 'link': 'https://arxiv.org/abs/2509.25716', 'abstract': 'Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models.', 'abstract_zh': '当前的搜索技术仅限于标准的RAG查询-文档应用。本文提出了一种新颖的方法，扩展代码和索引以预测所需的API，直接实现高质量的端到端代码生成，适用于自动补全和代理AI应用。通过引入一个新数据集，该数据集基于实际的ServiceNow Script Includes构建，并捕捉代码中模糊的API使用意图问题，解决了当前代码到代码基准数据集中的API泄漏问题。我们的评估指标表明，该方法实现了87.86%的前40位检索准确性，允许包含成功生成下游代码所需的关键上下文与API。为了实现实时预测，我们开发了一种全面的后训练管道，通过合成数据集生成、监督微调和强化学习优化了一个紧凑的0.6B重排序器。此方法使我们的紧凑重排序器能够在保持2.5倍减少的延迟的同时，超越更大规模的8B模型，有效解决了企业特定代码的细微差别，而无需使用大规模模型的计算开销。', 'title_zh': 'DeepCodeSeek: 基于上下文的实时API检索'}
{'arxiv_id': 'arXiv:2509.25692', 'title': 'Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction', 'authors': 'Tingyu Shi, Fan Lyu, Shaoliang Peng', 'link': 'https://arxiv.org/abs/2509.25692', 'abstract': 'Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at this https URL.', 'abstract_zh': 'Conformal Prediction Active Test-Time Adaptation (CPATTA)', 'title_zh': '带有模范预测的注释高效活跃测试时自适应'}
{'arxiv_id': 'arXiv:2509.25667', 'title': 'EEG-based AI-BCI Wheelchair Advancement: Hybrid Deep Learning with Motor Imagery for Brain Computer Interface', 'authors': 'Bipul Thapa, Biplov Paneru, Bishwash Paneru, Khem Narayan Poudyal', 'link': 'https://arxiv.org/abs/2509.25667', 'abstract': 'This paper presents an Artificial Intelligence (AI) integrated novel approach to Brain-Computer Interface (BCI)-based wheelchair development, utilizing a motor imagery right-left-hand movement mechanism for control. The system is designed to simulate wheelchair navigation based on motor imagery right and left-hand movements using electroencephalogram (EEG) data. A pre-filtered dataset, obtained from an open-source EEG repository, was segmented into arrays of 19x200 to capture the onset of hand movements. The data was acquired at a sampling frequency of 200Hz. The system integrates a Tkinter-based interface for simulating wheelchair movements, offering users a functional and intuitive control system. We propose a BiLSTM-BiGRU model that shows a superior test accuracy of 92.26% as compared with various machine learning baseline models, including XGBoost, EEGNet, and a transformer-based model. The Bi-LSTM-BiGRU attention-based model achieved a mean accuracy of 90.13% through cross-validation, showcasing the potential of attention mechanisms in BCI applications.', 'abstract_zh': '本文提出了一种将人工智能集成到基于脑-计算机接口（BCI）的轮椅开发中的新型方法，利用 MOTOR IMAGERY 右左手运动机制进行控制。该系统设计用于基于 motor imagery 右左手运动的脑电信号（EEG）数据模拟轮椅导航。从开源 EEG 仓库获取的预过滤数据集被分割为 19x200 的数组，以捕捉手部运动的开始。数据以 200Hz 的采样频率获取。该系统结合了基于 Tkinter 的界面以模拟轮椅运动，为用户提供了一个功能性和直观的控制系统。我们提出了一种 BiLSTM-BiGRU 模型，其测试准确性达到 92.26%，优于包括 XGBoost、EEGNet 和基于变压器的模型在内的多种机器学习基准模型。交叉验证结果显示，Bi-LSTM-BiGRU 注意机制模型的平均准确性为 90.13%，展示了注意机制在 BCI 应用中的潜力。', 'title_zh': '基于EEG的人工智能脑机接口轮椅进展：运动想象的混合深度学习方法'}
{'arxiv_id': 'arXiv:2509.25660', 'title': 'Capacity-Net-Based RIS Precoding Design without Channel Estimation for mmWave MIMO System', 'authors': 'Chun-Yuan Huang, Po-Heng Chou, Wan-Jen Huang, Ying-Ren Chien, Yu Tsao', 'link': 'https://arxiv.org/abs/2509.25660', 'abstract': 'In this paper, we propose Capacity-Net, a novel unsupervised learning approach aimed at maximizing the achievable rate in reflecting intelligent surface (RIS)-aided millimeter-wave (mmWave) multiple input multiple output (MIMO) systems. To combat severe channel fading of the mmWave spectrum, we optimize the phase-shifting factors of the reflective elements in the RIS to enhance the achievable rate. However, most optimization algorithms rely heavily on complete and accurate channel state information (CSI), which is often challenging to acquire since the RIS is mostly composed of passive components. To circumvent this challenge, we leverage unsupervised learning techniques with implicit CSI provided by the received pilot signals. Specifically, it usually requires perfect CSI to evaluate the achievable rate as a performance metric of the current optimization result of the unsupervised learning method. Instead of channel estimation, the Capacity-Net is proposed to establish a mapping among the received pilot signals, optimized RIS phase shifts, and the resultant achievable rates. Simulation results demonstrate the superiority of the proposed Capacity-Net-based unsupervised learning approach over learning methods based on traditional channel estimation.', 'abstract_zh': '基于反射表面辅助毫米波MIMO系统的容量网：一种新的无监督学习方法', 'title_zh': '基于容量网的RIS辅助毫米波MIMO系统无信道估计预编码设计'}
{'arxiv_id': 'arXiv:2509.25647', 'title': 'BaB-prob: Branch and Bound with Preactivation Splitting for Probabilistic Verification of Neural Networks', 'authors': 'Fangji Wang, Panagiotis Tsiotras', 'link': 'https://arxiv.org/abs/2509.25647', 'abstract': 'Branch-and-bound with preactivation splitting has been shown highly effective for deterministic verification of neural networks. In this paper, we extend this framework to the probabilistic setting. We propose BaB-prob that iteratively divides the original problem into subproblems by splitting preactivations and leverages linear bounds computed by linear bound propagation to bound the probability for each subproblem. We prove soundness and completeness of BaB-prob for feedforward-ReLU neural networks. Furthermore, we introduce the notion of uncertainty level and design two efficient strategies for preactivation splitting, yielding BaB-prob-ordered and BaB+BaBSR-prob. We evaluate BaB-prob on untrained networks, MNIST and CIFAR-10 models, respectively, and VNN-COMP 2025 benchmarks. Across these settings, our approach consistently outperforms state-of-the-art approaches in medium- to high-dimensional input problems.', 'abstract_zh': '基于预激活分裂的分支定界方法已被证明对于神经网络的确定性验证 Highly 有效。本文将该框架扩展到概率性设置。我们提出了一种 BaB-prob 方法，通过迭代地将原问题拆分为子问题，并利用线性约束传播计算的线性边界来为每个子问题计算概率边界。我们证明了 BaB-prob 对于前向 ReLU 神经网络的完备性和有效性。此外，我们引入了不确定性级别概念，并设计了两种有效的预激活分裂策略，生成 BaB-prob-ordered 和 BaB+BaBSR-prob 方法。我们在未训练网络、MNIST 和 CIFAR-10 模型，以及 VNN-COMP 2025 计划基准上评估了 BaB-prob 方法。在这些设置中，我们的方法在中到高维度输入问题上始终优于现有最佳方法。', 'title_zh': 'BaB-prob: 带有预激活分裂的分支定界方法及其在神经网络概率验证中的应用'}
{'arxiv_id': 'arXiv:2509.25618', 'title': 'Quadratic Programming Approach for Nash Equilibrium Computation in Multiplayer Imperfect-Information Games', 'authors': 'Sam Ganzfried', 'link': 'https://arxiv.org/abs/2509.25618', 'abstract': 'There has been significant recent progress in algorithms for approximation of Nash equilibrium in large two-player zero-sum imperfect-information games and exact computation of Nash equilibrium in multiplayer strategic-form games. While counterfactual regret minimization and fictitious play are scalable to large games and have convergence guarantees in two-player zero-sum games, they do not guarantee convergence to Nash equilibrium in multiplayer games. We present an approach for exact computation of Nash equilibrium in multiplayer imperfect-information games that solves a quadratically-constrained program based on a nonlinear complementarity problem formulation from the sequence-form game representation. This approach capitalizes on recent advances for solving nonconvex quadratic programs. Our algorithm is able to quickly solve three-player Kuhn poker after removal of dominated actions. Of the available algorithms in the Gambit software suite, only the logit quantal response approach is successfully able to solve the game; however, the approach takes longer than our algorithm and also involves a degree of approximation. Our formulation also leads to a new approach for computing Nash equilibrium in multiplayer strategic-form games which we demonstrate to outperform a previous quadratically-constrained program formulation.', 'abstract_zh': '近年来，在大型两人零和不完美信息博弈中近似诺伊曼均衡算法及多人战略型博弈中诺伊曼均衡精确计算算法取得了显著进展。虽然回溯遗憾最小化和假想博弈方法可以扩展到大型博弈并具有两人零和博弈中的收敛性保证，但它们在多人博弈中不能保证收敛到诺伊曼均衡。我们提出了一种在多人不完美信息博弈中精确计算诺伊曼均衡的方法，该方法基于序列型博弈表示的非线性互补问题表述求解一个二次约束规划问题。该方法利用了求解非凸二次规划问题的近期进展。我们的算法能够在去除占优行动后快速解决三人科恩扑克博弈。在Gambit软件套件中可用的算法中，只有逻辑量化响应方法能够成功解决该博弈，但该方法所需时间长于我们的算法，并且也涉及一定程度的近似。我们的表述还导致了一种新的多人战略型博弈诺伊曼均衡计算方法，我们证明了这种方法优于之前的二次约束规划问题表述方法。', 'title_zh': '多玩家不完美信息博弈中的纳什均衡计算的二次规划方法'}
{'arxiv_id': 'arXiv:2509.25612', 'title': 'Unsupervised Detection of Spatiotemporal Anomalies in PMU Data Using Transformer-Based BiGAN', 'authors': 'Muhammad Imran Hossain, Jignesh Solanki, Sarika Khushlani Solanki', 'link': 'https://arxiv.org/abs/2509.25612', 'abstract': 'Ensuring power grid resilience requires the timely and unsupervised detection of anomalies in synchrophasor data streams. We introduce T-BiGAN, a novel framework that integrates window-attention Transformers within a bidirectional Generative Adversarial Network (BiGAN) to address this challenge. Its self-attention encoder-decoder architecture captures complex spatio-temporal dependencies across the grid, while a joint discriminator enforces cycle consistency to align the learned latent space with the true data distribution. Anomalies are flagged in real-time using an adaptive score that combines reconstruction error, latent space drift, and discriminator confidence. Evaluated on a realistic hardware-in-the-loop PMU benchmark, T-BiGAN achieves an ROC-AUC of 0.95 and an average precision of 0.996, significantly outperforming leading supervised and unsupervised methods. It shows particular strength in detecting subtle frequency and voltage deviations, demonstrating its practical value for live, wide-area monitoring without relying on manually labeled fault data.', 'abstract_zh': '确保电网韧性需要及时且自主地检测同步相量数据流中的异常。为此，我们提出了一种名为T-BiGAN的新框架，该框架将窗口注意力Transformer整合到双向生成对抗网络（BiGAN）中以应对这一挑战。其自注意力编码器-解码器架构捕捉了电网中复杂的时空依赖关系，而联合判别器则通过周期一致性约束使学习的潜在空间与真实数据分布对齐。通过结合重构误差、潜在空间漂移和判别器置信度的自适应分数实时标记异常。T-BiGAN在现实的硬件在环PMU基准测试中取得了ROC-AUC为0.95和平均精度为0.996的性能，显著优于现有的监督和非监督方法，并在检测细微频率和电压偏差方面展现出特别的优势，证明了其在实际中用于广泛的实时监测的实用性，无需依赖手动标注的故障数据。', 'title_zh': '基于Transformer的BiGAN在PMU数据中无监督检测时空异常'}
{'arxiv_id': 'arXiv:2509.25541', 'title': 'Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play', 'authors': 'Qinsi Wang, Bo Liu, Tianyi Zhou, Jing Shi, Yueqian Lin, Yiran Chen, Hai Helen Li, Kun Wan, Wentian Zhao', 'link': 'https://arxiv.org/abs/2509.25541', 'abstract': 'Although reinforcement learning (RL) can effectively enhance the reasoning capabilities of vision-language models (VLMs), current methods remain heavily dependent on labor-intensive datasets that require extensive manual construction and verification, leading to extremely high training costs and consequently constraining the practical deployment of VLMs. To address this challenge, we propose Vision-Zero, a domain-agnostic framework enabling VLM self-improvement through competitive visual games generated from arbitrary image pairs. Specifically, Vision-Zero encompasses three main attributes: (1) Strategic Self-Play Framework: Vision-Zero trains VLMs in "Who Is the Spy"-style games, where the models engage in strategic reasoning and actions across multiple roles. Through interactive gameplay, models autonomously generate their training data without human annotation. (2) Gameplay from Arbitrary Images: Unlike existing gamified frameworks, Vision-Zero can generate games from arbitrary images, thereby enhancing the model\'s reasoning ability across diverse domains and showing strong generalization to different tasks. We demonstrate this versatility using three distinct types of image datasets: CLEVR-based synthetic scenes, charts, and real-world images. (3) Sustainable Performance Gain: We introduce Iterative Self-Play Policy Optimization (Iterative-SPO), a novel training algorithm that alternates between Self-Play and reinforcement learning with verifiable rewards (RLVR), mitigating the performance plateau often seen in self-play-only training and achieving sustained long-term improvements. Despite using label-free data, Vision-Zero achieves state-of-the-art performance on reasoning, chart question answering, and vision-centric understanding tasks, surpassing other annotation-based methods. Models and code has been released at this https URL.', 'abstract_zh': 'Vision-Zero：一种无监督领域泛化框架，通过任意图像对生成的竞争视觉游戏实现VLM自我提升', 'title_zh': 'Vision-Zero: 通过战略游戏化自我对弈实现的可扩展VLM自我提升'}
{'arxiv_id': 'arXiv:2509.25539', 'title': 'Toxicity in Online Platforms and AI Systems: A Survey of Needs, Challenges, Mitigations, and Future Directions', 'authors': 'Smita Khapre, Melkamu Abay Mersha, Hassan Shakil, Jonali Baruah, Jugal Kalita', 'link': 'https://arxiv.org/abs/2509.25539', 'abstract': 'The evolution of digital communication systems and the designs of online platforms have inadvertently facilitated the subconscious propagation of toxic behavior. Giving rise to reactive responses to toxic behavior. Toxicity in online content and Artificial Intelligence Systems has become a serious challenge to individual and collective well-being around the world. It is more detrimental to society than we realize. Toxicity, expressed in language, image, and video, can be interpreted in various ways depending on the context of usage. Therefore, a comprehensive taxonomy is crucial to detect and mitigate toxicity in online content, Artificial Intelligence systems, and/or Large Language Models in a proactive manner. A comprehensive understanding of toxicity is likely to facilitate the design of practical solutions for toxicity detection and mitigation. The classification in published literature has focused on only a limited number of aspects of this very complex issue, with a pattern of reactive strategies in response to toxicity. This survey attempts to generate a comprehensive taxonomy of toxicity from various perspectives. It presents a holistic approach to explain the toxicity by understanding the context and environment that society is facing in the Artificial Intelligence era. This survey summarizes the toxicity-related datasets and research on toxicity detection and mitigation for Large Language Models, social media platforms, and other online platforms, detailing their attributes in textual mode, focused on the English language. Finally, we suggest the research gaps in toxicity mitigation based on datasets, mitigation strategies, Large Language Models, adaptability, explainability, and evaluation.', 'abstract_zh': '数字通信系统的发展和在线平台的设计无意中促进了有毒行为的潜意识传播，激发了对有毒行为的反应性应对措施。在线内容和人工智能系统的有毒性问题已成为全球个人和集体福祉的重大挑战，其对社会的危害程度超乎我们的认知。有毒性的表达方式取决于使用语境，可以有多种解释，因此，建立一个全面的分类体系对于主动检测和缓解在线内容、人工智能系统和/或大型语言模型中的毒性至关重要。对有毒性问题全面理解可能会促进毒性检测和缓解的实际解决方案的设计。已发表文献中的分类主要集中在这一极其复杂问题的有限方面，反应性策略是其主要模式。本文试图从多个角度构建一个全面的毒性分类体系，以一种综合的方式解释毒性，理解人工智能时代社会所面临的环境和情境。本文总结了与毒性相关的数据集和对于大型语言模型、社交媒体平台和其他在线平台的毒性检测与缓解的研究，详细描述了这些平台的文本属性，重点为英文内容。最后，基于数据集、缓解策略、大型语言模型、适应性、可解释性和评估，提出了毒性缓解的研究空白。', 'title_zh': '在线平台和AI系统中的毒性：需求、挑战、缓解措施及未来方向调研'}
{'arxiv_id': 'arXiv:2509.25538', 'title': 'Steering an Active Learning Workflow Towards Novel Materials Discovery via Queue Prioritization', 'authors': 'Marcus Schwarting, Logan Ward, Nathaniel Hudson, Xiaoli Yan, Ben Blaiszik, Santanu Chaudhuri, Eliu Huerta, Ian Foster', 'link': 'https://arxiv.org/abs/2509.25538', 'abstract': 'Generative AI poses both opportunities and risks for solving inverse design problems in the sciences. Generative tools provide the ability to expand and refine a search space autonomously, but do so at the cost of exploring low-quality regions until sufficiently fine tuned. Here, we propose a queue prioritization algorithm that combines generative modeling and active learning in the context of a distributed workflow for exploring complex design spaces. We find that incorporating an active learning model to prioritize top design candidates can prevent a generative AI workflow from expending resources on nonsensical candidates and halt potential generative model decay. For an existing generative AI workflow for discovering novel molecular structure candidates for carbon capture, our active learning approach significantly increases the number of high-quality candidates identified by the generative model. We find that, out of 1000 novel candidates, our workflow without active learning can generate an average of 281 high-performing candidates, while our proposed prioritization with active learning can generate an average 604 high-performing candidates.', 'abstract_zh': '生成式AI既带来了机遇也带来了风险，用于解决科学领域的逆向设计问题。生成工具提供了自主扩大和细化搜索空间的能力，但这也意味着在充分调优之前需要探索低质量区域。在此，我们提出一种结合生成模型和主动学习的队列优先算法，适用于分布式工作流以探索复杂的设计空间。我们发现，将主动学习模型纳入优先算法，可以防止生成式AI工作流在处理无意义候选方案上浪费资源，并防止生成模型性能衰退。对于一个现有的用于发现新型分子结构候选方案以捕获碳的生成式AI工作流，我们的主动学习方法显著提高了生成模型识别高质量候选方案的数量。我们发现，在1000个新型候选方案中，不采用主动学习的工作流平均能生成281个高性能候选方案，而结合主动学习优先算法的工作流平均能生成604个高性能候选方案。', 'title_zh': '通过队列优先级设置引导主动学习工作流以实现新型材料发现'}
{'arxiv_id': 'arXiv:2509.25524', 'title': 'Economic Competition, EU Regulation, and Executive Orders: A Framework for Discussing AI Policy Implications in CS Courses', 'authors': 'James Weichert, Hoda Eldardiry', 'link': 'https://arxiv.org/abs/2509.25524', 'abstract': 'The growth and permeation of artificial intelligence (AI) technologies across society has drawn focus to the ways in which the responsible use of these technologies can be facilitated through AI governance. Increasingly, large companies and governments alike have begun to articulate and, in some cases, enforce governance preferences through AI policy. Yet existing literature documents an unwieldy heterogeneity in ethical principles for AI governance, while our own prior research finds that discussions of the implications of AI policy are not yet present in the computer science (CS) curriculum. In this context, overlapping jurisdictions and even contradictory policy preferences across private companies, local, national, and multinational governments create a complex landscape for AI policy which, we argue, will require AI developers able adapt to an evolving regulatory environment. Preparing computing students for the new challenges of an AI-dominated technology industry is therefore a key priority for the CS curriculum.\nIn this discussion paper, we seek to articulate a framework for integrating discussions on the nascent AI policy landscape into computer science courses. We begin by summarizing recent AI policy efforts in the United States and European Union. Subsequently, we propose guiding questions to frame class discussions around AI policy in technical and non-technical (e.g., ethics) CS courses. Throughout, we emphasize the connection between normative policy demands and still-open technical challenges relating to their implementation and enforcement through code and governance structures. This paper therefore represents a valuable contribution towards bridging research and discussions across the areas of AI policy and CS education, underlining the need to prepare AI engineers to interact with and adapt to societal policy preferences.', 'abstract_zh': '人工智能技术在社会中的发展与渗透引发了对通过人工智能治理促进负责任使用这些技术方式的关注。越来越多的大公司和政府开始阐述并实施人工智能政策。然而，现有文献表明，人工智能治理中的伦理原则存在难以驾驭的多样性，而我们自己的前期研究发现，人工智能政策的含义讨论尚未出现在计算机科学课程中。在这一背景下，私营公司、地方政府、国家级政府以及跨国政府之间重叠的管辖权和甚至相互矛盾的政策偏好创造了一种复杂的人工智能政策景观，我们认为这将需要能够适应不断发展中的监管环境的人工智能开发者。因此，为计算机科学课程准备能够应对人工智能主导技术行业新挑战的学生是课程的一个关键优先事项。\n\n在本文中，我们旨在为将关于新兴人工智能政策景观的讨论整合到计算机科学课程中提出一个框架。我们首先总结了美国和欧盟近期的人工智能政策努力。随后，我们提出指导性问题来框架技术性和非技术性（如，伦理）课程中的人工智能政策讨论。在整个过程中，我们强调了规范性政策要求与通过代码和治理结构实施与执行这些要求仍待解决的技术挑战之间的联系。因此，本文代表了弥合人工智能政策和计算机科学教育领域研究与讨论之间鸿沟的重要贡献，突显了准备人工智能工程师与社会政策偏好互动并适应这些偏好的重要性。', 'title_zh': '经济竞争、欧盟法规与行政命令：在计算机科学课程中讨论人工智能政策影响的框架'}
{'arxiv_id': 'arXiv:2509.25504', 'title': 'XR Blocks: Accelerating Human-centered AI + XR Innovation', 'authors': 'David Li, Nels Numan, Xun Qian, Yanhe Chen, Zhongyi Zhou, Evgenii Alekseev, Geonsun Lee, Alex Cooper, Min Xia, Scott Chung, Jeremy Nelson, Xiuxiu Yuan, Jolica Dias, Tim Bettridge, Benjamin Hersh, Michelle Huynh, Konrad Piascik, Ricardo Cabello, David Kim, Ruofei Du', 'link': 'https://arxiv.org/abs/2509.25504', 'abstract': 'We are on the cusp where Artificial Intelligence (AI) and Extended Reality (XR) are converging to unlock new paradigms of interactive computing. However, a significant gap exists between the ecosystems of these two fields: while AI research and development is accelerated by mature frameworks like JAX and benchmarks like LMArena, prototyping novel AI-driven XR interactions remains a high-friction process, often requiring practitioners to manually integrate disparate, low-level systems for perception, rendering, and interaction. To bridge this gap, we present XR Blocks, a cross-platform framework designed to accelerate human-centered AI + XR innovation. XR Blocks strives to provide a modular architecture with plug-and-play components for core abstraction in AI + XR: user, world, peers; interface, context, and agents. Crucially, it is designed with the mission of "reducing frictions from idea to reality", thus accelerating rapid prototyping of AI + XR apps. Built upon accessible technologies (WebXR, this http URL, TensorFlow, Gemini), our toolkit lowers the barrier to entry for XR creators. We demonstrate its utility through a set of open-source templates, samples, and advanced demos, empowering the community to quickly move from concept to interactive XR prototype. Site: this https URL', 'abstract_zh': '人工智能与扩展现实的融合正处于关键时期：开启交互计算新范式。然而，这两领域的生态之间存在显著差距：虽然AI研究与开发借助于成熟的框架如JAX和基准如LMArena加速进行，但新型AI驱动的XR交互原型设计仍是一个高摩擦的过程，通常需要 practitioners 手动整合多种低级系统。为弥合这一差距，我们提出XR Blocks，这是一个跨平台框架，旨在加速以人类为中心的AI + XR创新。XR Blocks 致力于提供一个模块化架构，并提供插拔式组件以对AI + XR的核心抽象进行模块化设计：用户、世界、同伴；界面、上下文和代理。最关键的是，XR Blocks 旨在“降低从理念到现实的摩擦”，从而加速AI + XR应用的快速原型设计。基于易用技术（WebXR等），我们的工具包降低了XR创作者的入门门槛。我们通过一系列开源模板、示例和高级演示展示了其用途，使社区能够快速从概念过渡到交互式XR原型。网站：此链接。', 'title_zh': 'XR Blocks：加速以人为中心的AI+XR创新'}
{'arxiv_id': 'arXiv:2509.25480', 'title': 'Translation from Wearable PPG to 12-Lead ECG', 'authors': 'Hui Ji, Wei Gao, Pengfei Zhou', 'link': 'https://arxiv.org/abs/2509.25480', 'abstract': 'The 12-lead electrocardiogram (ECG) is the gold standard for cardiovascular monitoring, offering superior diagnostic granularity and specificity compared to photoplethysmography (PPG). However, existing 12-lead ECG systems rely on cumbersome multi-electrode setups, limiting sustained monitoring in ambulatory settings, while current PPG-based methods fail to reconstruct multi-lead ECG due to the absence of inter-lead constraints and insufficient modeling of spatial-temporal dependencies across leads. To bridge this gap, we introduce P2Es, an innovative demographic-aware diffusion framework designed to generate clinically valid 12-lead ECG from PPG signals via three key innovations. Specifically, in the forward process, we introduce frequency-domain blurring followed by temporal noise interference to simulate real-world signal distortions. In the reverse process, we design a temporal multi-scale generation module followed by frequency deblurring. In particular, we leverage KNN-based clustering combined with contrastive learning to assign affinity matrices for the reverse process, enabling demographic-specific ECG translation. Extensive experimental results show that P2Es outperforms baseline models in 12-lead ECG reconstruction.', 'abstract_zh': '基于人口统计学aware的光谱扩散框架P2Es：从PPG信号生成临床有效的12导联心电图', 'title_zh': '从可穿戴PPG信号转化为12导联ECG'}
{'arxiv_id': 'arXiv:2509.25479', 'title': 'Discontinuous Epitope Fragments as Sufficient Target Templates for Efficient Binder Design', 'authors': 'Zhenfeng Deng, Ruijie Hou, Ningrui Xie, Mike Tyers, Michał Koziarski', 'link': 'https://arxiv.org/abs/2509.25479', 'abstract': "Recent advances in structure-based protein design have accelerated de novo binder generation, yet interfaces on large domains or spanning multiple domains remain challenging due to high computational cost and declining success with increasing target size. We hypothesized that protein folding neural networks (PFNNs) operate in a ``local-first'' manner, prioritizing local interactions while displaying limited sensitivity to global this http URL by this hypothesis, we propose an epitope-only strategy that retains only the discontinuous surface residues surrounding the binding site. Compared to intact-domain workflows, this approach improves in silico success rates by up to 80% and reduces the average time per successful design by up to forty-fold, enabling binder design against previously intractable targets such as ClpP and ALS3. Building on this foundation, we further developed a tailored pipeline that incorporates a Monte Carlo-based evolution step to overcome local minima and a position-specific biased inverse folding step to refine sequence patterns. Together, these advances not only establish a generalizable framework for efficient binder design against structurally large and otherwise inaccessible targets, but also support the broader ``local-first'' hypothesis as a guiding principle for PFNN-based design.", 'abstract_zh': '基于结构的蛋白质设计 Recent进展加速了从头 binder 的生成，但大规模结构域或跨多个结构域的界面仍然具有挑战性，因为随着目标大小的增加，计算成本高且成功率下降。我们假设蛋白质折叠神经网络（PFNNs）以“局部优先”方式工作，优先处理局部相互作用，对全局相互作用的敏感性有限。基于这一假设，我们提出了一种仅保留围绕结合位点的不连续表面对残基的策略。与完整结构域流程相比，这种方法将计算成功率提高了高达80%，并将每次成功设计所需的时间平均减少了四十分之一，使其能够针对以前难以应对的目标（如ClpP和ALS3）进行 binder 设计。在此基础上，我们进一步开发了一种定制管道，该管道结合了基于蒙特卡洛的进化步骤来克服局部最小值，并结合了位置特异性偏差逆折叠步骤来细化序列模式。这些进展不仅建立了一种适用于结构庞大且难以访问的目标的高效 binder 设计的一般框架，还支持了 PFNN 基础设计中的“局部优先”假设作为一种指导原则。', 'title_zh': '不连续表位片段作为高效配体设计的充分靶标模板'}
{'arxiv_id': 'arXiv:2509.25450', 'title': 'Multi-patch isogeometric neural solver for partial differential equations on computer-aided design domains', 'authors': 'Moritz von Tresckow, Ion Gabriel Ion, Dimitrios Loukrezis', 'link': 'https://arxiv.org/abs/2509.25450', 'abstract': 'This work develops a computational framework that combines physics-informed neural networks with multi-patch isogeometric analysis to solve partial differential equations on complex computer-aided design geometries. The method utilizes patch-local neural networks that operate on the reference domain of isogeometric analysis. A custom output layer enables the strong imposition of Dirichlet boundary conditions. Solution conformity across interfaces between non-uniform rational B-spline patches is enforced using dedicated interface neural networks. Training is performed using the variational framework by minimizing the energy functional derived after the weak form of the partial differential equation. The effectiveness of the suggested method is demonstrated on two highly non-trivial and practically relevant use-cases, namely, a 2D magnetostatics model of a quadrupole magnet and a 3D nonlinear solid and contact mechanics model of a mechanical holder. The results show excellent agreement to reference solutions obtained with high-fidelity finite element solvers, thus highlighting the potential of the suggested neural solver to tackle complex engineering problems given the corresponding computer-aided design models.', 'abstract_zh': '基于物理 informant 的神经网络与多区域IGA相结合的计算框架：复杂计算机辅助设计几何上的偏微分方程求解', 'title_zh': '用于计算机辅助设计域上偏微分方程的多片异质几何神经求解器'}
{'arxiv_id': 'arXiv:2509.25449', 'title': 'Joint Embeddings Go Temporal', 'authors': 'Sofiane Ennadir, Siavash Golkar, Leopoldo Sarra', 'link': 'https://arxiv.org/abs/2509.25449', 'abstract': 'Self-supervised learning has seen great success recently in unsupervised representation learning, enabling breakthroughs in natural language and image processing. However, these methods often rely on autoregressive and masked modeling, which aim to reproduce masked information in the input, which can be vulnerable to the presence of noise or confounding variables. To address this problem, Joint-Embedding Predictive Architectures (JEPA) has been introduced with the aim to perform self-supervised learning in the latent space. To leverage these advancements in the domain of time series, we introduce Time Series JEPA (TS-JEPA), an architecture specifically adapted for time series representation learning. We validate TS-JEPA on both classification and forecasting, showing that it can match or surpass current state-of-the-art baselines on different standard datasets. Notably, our approach demonstrates a strong performance balance across diverse tasks, indicating its potential as a robust foundation for learning general representations. Thus, this work lays the groundwork for developing future time series foundation models based on Joint Embedding.', 'abstract_zh': '自监督学习在无监督表征学习中取得了巨大成功，尤其是在自然语言和图像处理领域。然而，这些方法往往依赖于自回归和掩码建模，旨在重现输入中的掩码信息，这在噪声或混杂变量存在的情况下可能会变得脆弱。为了解决这一问题，引入了联合嵌入预测架构（JEPA），旨在在潜在空间中进行自监督学习。为了在时间序列领域利用这些进展，我们提出了时间序列JEPA（TS-JEPA），一种专门适应时间序列表征学习的架构。我们通过分类和预测任务验证了TS-JEPA，结果显示它在不同标准数据集上可以匹配或超越当前最先进的基线方法。值得注意的是，我们的方法在多种任务上展现出强大的性能平衡，表明其作为稳健的学习通用表征基础的潜力。因此，这项工作为基于联合嵌入发展未来的时间序列基础模型奠定了基础。', 'title_zh': 'Joint Embeddings Go Temporal'}
{'arxiv_id': 'arXiv:2509.25438', 'title': 'Beyond Noisy-TVs: Noise-Robust Exploration Via Learning Progress Monitoring', 'authors': 'Zhibo Hou, Zhiyu An, Wan Du', 'link': 'https://arxiv.org/abs/2509.25438', 'abstract': "When there exists an unlearnable source of randomness (noisy-TV) in the environment, a naively intrinsic reward driven exploring agent gets stuck at that source of randomness and fails at exploration. Intrinsic reward based on uncertainty estimation or distribution similarity, while eventually escapes noisy-TVs as time unfolds, suffers from poor sample efficiency and high computational cost. Inspired by recent findings from neuroscience that humans monitor their improvements during exploration, we propose a novel method for intrinsically-motivated exploration, named Learning Progress Monitoring (LPM). During exploration, LPM rewards model improvements instead of prediction error or novelty, effectively rewards the agent for observing learnable transitions rather than the unlearnable transitions. We introduce a dual-network design that uses an error model to predict the expected prediction error of the dynamics model in its previous iteration, and use the difference between the model errors of the current iteration and previous iteration to guide exploration. We theoretically show that the intrinsic reward of LPM is zero-equivariant and a monotone indicator of Information Gain (IG), and that the error model is necessary to achieve monotonicity correspondence with IG. We empirically compared LPM against state-of-the-art baselines in noisy environments based on MNIST, 3D maze with 160x120 RGB inputs, and Atari. Results show that LPM's intrinsic reward converges faster, explores more states in the maze experiment, and achieves higher extrinsic reward in Atari. This conceptually simple approach marks a shift-of-paradigm of noise-robust exploration. For code to reproduce our experiments, see this https URL", 'abstract_zh': '当环境中存在无法学习的随机性来源（noisy-TV）时，一个简单的固有奖励驱动探索代理会被困在该随机性来源处并无法进行探索。基于不确定性估计或分布相似度的固有奖励最终会摆脱noisy-TV，但会遭受样本效率低和高计算成本的问题。受近期神经科学研究中关于人类在探索过程中监测自身改进的发现启发，我们提出了一种新的固有动机探索方法，称为学习进展监控（LPM）。在探索过程中，LPM奖励模型改进而非预测误差或新颖性，有效地奖励代理观测可学习的转换而非不可学习的转换。我们引入了一种双网络设计，使用一个误差模型来预测动力学模型上一次迭代的预期预测误差，并利用当前迭代和上次迭代模型误差的差异来引导探索。我们从理论上证明，LPM的固有奖励是零等变的并是信息增益（IG）的单调指标，误差模型对于实现与IG的单调性对应是必要的。我们在基于MNIST、160x120 RGB输入的3D迷宫以及Atari的嘈杂环境中，LPM与最新基准方法进行了比较。结果显示，LPM的固有奖励收敛更快，在迷宫实验中探索更多的状态，并在Atari中获得更高的外部奖励。这一概念上简单的办法标志着噪声鲁棒探索范式的转变。有关我们实验的可复现代码，请参见此链接。', 'title_zh': '超越嘈杂电视：通过学习进度监测实现噪声稳健探索'}
{'arxiv_id': 'arXiv:2509.25416', 'title': 'Emotion-Aligned Generation in Diffusion Text to Speech Models via Preference-Guided Optimization', 'authors': 'Jiacheng Shi, Hongfei Du, Yangfan He, Y. Alicia Hong, Ye Gao', 'link': 'https://arxiv.org/abs/2509.25416', 'abstract': 'Emotional text-to-speech seeks to convey affect while preserving intelligibility and prosody, yet existing methods rely on coarse labels or proxy classifiers and receive only utterance-level feedback. We introduce Emotion-Aware Stepwise Preference Optimization (EASPO), a post-training framework that aligns diffusion TTS with fine-grained emotional preferences at intermediate denoising steps. Central to our approach is EASPM, a time-conditioned model that scores noisy intermediate speech states and enables automatic preference pair construction. EASPO optimizes generation to match these stepwise preferences, enabling controllable emotional shaping. Experiments show superior performance over existing methods in both expressiveness and naturalness.', 'abstract_zh': '情感文本转语音旨在传达情感同时保持可懂度和语调，但现有方法依赖于粗略的标签或替代分类器，并仅接收句级反馈。我们引入了情感感知分步偏好优化（EASPO），这是一种后训练框架，将扩散TTS与中间去噪步骤中的细粒度情感偏好对齐。我们方法的核心是EASPM，这是一种时间条件模型，用于评分嘈杂的中间语音状态，并能够自动构建偏好配对。EASPO 优化生成以匹配这些分步偏好，从而实现可控的情感塑造。实验结果显示在表达性和自然度上均优于现有方法。', 'title_zh': '面向偏好吃引导优化的情感对齐生成在扩散文本到语音模型中'}
{'arxiv_id': 'arXiv:2509.25401', 'title': 'FlashOmni: A Unified Sparse Attention Engine for Diffusion Transformers', 'authors': 'Liang Qiao, Yue Dai, Yeqi Huang, Hongyu Kan, Jun Shi, Hong An', 'link': 'https://arxiv.org/abs/2509.25401', 'abstract': 'Multi-Modal Diffusion Transformers (DiTs) demonstrate exceptional capabilities in visual synthesis, yet their deployment remains constrained by substantial computational demands. To alleviate this bottleneck, many sparsity-based acceleration methods have been proposed. However, their diverse sparsity patterns often require customized kernels for high-performance inference, limiting universality. We propose FlashOmni, a unified sparse attention engine compatible with arbitrary DiT architectures. FlashOmni introduces flexible sparse symbols to standardize the representation of a wide range of sparsity strategies, such as feature caching and block-sparse skipping. This unified abstraction enables the execution of diverse sparse computations within a single attention kernel. In addition, FlashOmni designs optimized sparse GEMMs for attention blocks, leveraging sparse symbols to eliminate redundant computations and further improve efficiency. Experiments demonstrate that FlashOmni delivers near-linear, closely matching the sparsity ratio speedup (1:1) in attention and GEMM-$Q$, and achieves 2.5$\\times$-3.8$\\times$ acceleration in GEMM-$O$ (max peaking at about 87.5% of the theoretical limit). Applied with a multi-granularity sparsity strategy, it enables the Hunyuan model (33K) to achieve about 1.5$\\times$ end-to-end acceleration without degrading visual quality.', 'abstract_zh': '多模态扩散变换器（DiTs）在视觉合成方面展示了卓越的能力，但其部署仍受限于巨大的计算需求。为缓解这一瓶颈，已经提出了多种基于稀疏性的加速方法。然而，这些方法多样化的稀疏模式通常需要定制内核以实现高性能推理，限制了通用性。我们提出了FlashOmni，这是一种兼容任意DiT架构的统一稀疏注意力引擎。FlashOmni引入灵活的稀疏符号以标准化各种稀疏策略（如特征缓存和块稀疏跳过）的表示。这种统一的抽象使得在单一注意力内核中执行多种稀疏计算成为可能。此外，FlashOmni针对注意力块设计了优化的稀疏GEMM，利用稀疏符号消除冗余计算，进一步提高效率。实验表明，FlashOmni实现了接近线性的加速，接近注意力和GEMM-$Q$稀疏率加速（1:1），在GEMM-$O$中实现了2.5至3.8倍的加速（峰值可达理论极限的约87.5%）。结合多粒度稀疏策略，它使Hunyuan模型（33K）在不牺牲视觉质量的情况下实现了约1.5倍的端到端加速。', 'title_zh': 'FlashOmni：统一稀疏注意力引擎for扩散变换器'}
{'arxiv_id': 'arXiv:2509.25393', 'title': 'A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland', 'authors': 'Wendong Yao, Binhua Huang, Soumyabrata Dev', 'link': 'https://arxiv.org/abs/2509.25393', 'abstract': "Forecasting high-resolution land subsidence is a critical yet challenging task due to its complex, non-linear dynamics. While standard architectures like ConvLSTM often fail to model long-range dependencies, we argue that a more fundamental limitation of prior work lies in the uni-modal data paradigm. To address this, we propose the Multi-Modal Spatio-Temporal Transformer (MM-STT), a novel framework that fuses dynamic displacement data with static physical priors. Its core innovation is a joint spatio-temporal attention mechanism that processes all multi-modal features in a unified manner. On the public EGMS dataset, MM-STT establishes a new state-of-the-art, reducing the long-range forecast RMSE by an order of magnitude compared to all baselines, including SOTA methods like STGCN and STAEformer. Our results demonstrate that for this class of problems, an architecture's inherent capacity for deep multi-modal fusion is paramount for achieving transformative performance.", 'abstract_zh': '高分辨率土地沉降的预测是一项由于其复杂的非线性动态而关键且具有挑战性的任务。尽管标准架构如ConvLSTM经常无法建模长程依赖性，我们认为先前工作的根本限制在于单模态数据范式。为了解决这一问题，我们提出了一种新型的多模态时空变换器（MM-STT）框架，该框架将动态位移数据与静态物理先验信息融合。其核心创新是一种联合时空注意力机制，能够统一处理所有多模态特征。在公共EGMS数据集上，MM-STT建立了新的基线，与包括SOTA方法STGCN和STAEformer在内的所有基线相比，将其长程预测RMSE降低了数量级。我们的结果表明，对于此类问题，架构本身对深度多模态融合的内在能力是实现变革性性能的关键。', 'title_zh': '基于深度学习的InSAR地面变形时空预测方法：以爱尔兰东部为例'}
{'arxiv_id': 'arXiv:2509.25379', 'title': 'Let Physics Guide Your Protein Flows: Topology-aware Unfolding and Generation', 'authors': 'Yogesh Verma, Markus Heinonen, Vikas Garg', 'link': 'https://arxiv.org/abs/2509.25379', 'abstract': 'Protein structure prediction and folding are fundamental to understanding biology, with recent deep learning advances reshaping the field. Diffusion-based generative models have revolutionized protein design, enabling the creation of novel proteins. However, these methods often neglect the intrinsic physical realism of proteins, driven by noising dynamics that lack grounding in physical principles. To address this, we first introduce a physically motivated non-linear noising process, grounded in classical physics, that unfolds proteins into secondary structures (e.g., alpha helices, linear beta sheets) while preserving topological integrity--maintaining bonds, and preventing collisions. We then integrate this process with the flow-matching paradigm on SE(3) to model the invariant distribution of protein backbones with high fidelity, incorporating sequence information to enable sequence-conditioned folding and expand the generative capabilities of our model. Experimental results demonstrate that the proposed method achieves state-of-the-art performance in unconditional protein generation, producing more designable and novel protein structures while accurately folding monomer sequences into precise protein conformations.', 'abstract_zh': '基于物理的蛋白质结构预测与折叠：物理学驱动的非线性去噪过程及其在蛋白质设计中的应用', 'title_zh': '基于物理的蛋白质流动导向：拓扑感知 unfolding 和生成'}
{'arxiv_id': 'arXiv:2509.25376', 'title': 'Cold-Start Active Correlation Clustering', 'authors': 'Linus Aronsson, Han Wu, Morteza Haghir Chehreghani', 'link': 'https://arxiv.org/abs/2509.25376', 'abstract': 'We study active correlation clustering where pairwise similarities are not provided upfront and must be queried in a cost-efficient manner through active learning. Specifically, we focus on the cold-start scenario, where no true initial pairwise similarities are available for active learning. To address this challenge, we propose a coverage-aware method that encourages diversity early in the process. We demonstrate the effectiveness of our approach through several synthetic and real-world experiments.', 'abstract_zh': '冷启动环境下成本敏感的活性聚类共生研究', 'title_zh': '冷启动主动相关聚类'}
{'arxiv_id': 'arXiv:2509.25334', 'title': 'Uncertainty-Aware Generative Oversampling Using an Entropy-Guided Conditional Variational Autoencoder', 'authors': 'Amirhossein Zare, Amirhessam Zare, Parmida Sadat Pezeshki, Herlock, Rahimi, Ali Ebrahimi, Ignacio Vázquez-García, Leo Anthony Celi', 'link': 'https://arxiv.org/abs/2509.25334', 'abstract': "Class imbalance remains a major challenge in machine learning, especially for high-dimensional biomedical data where nonlinear manifold structures dominate. Traditional oversampling methods such as SMOTE rely on local linear interpolation, often producing implausible synthetic samples. Deep generative models like Conditional Variational Autoencoders (CVAEs) better capture nonlinear distributions, but standard variants treat all minority samples equally, neglecting the importance of uncertain, boundary-region examples emphasized by heuristic methods like Borderline-SMOTE and ADASYN.\nWe propose Local Entropy-Guided Oversampling with a CVAE (LEO-CVAE), a generative oversampling framework that explicitly incorporates local uncertainty into both representation learning and data generation. To quantify uncertainty, we compute Shannon entropy over the class distribution in a sample's neighborhood: high entropy indicates greater class overlap, serving as a proxy for uncertainty. LEO-CVAE leverages this signal through two mechanisms: (i) a Local Entropy-Weighted Loss (LEWL) that emphasizes robust learning in uncertain regions, and (ii) an entropy-guided sampling strategy that concentrates generation in these informative, class-overlapping areas.\nApplied to clinical genomics datasets (ADNI and TCGA lung cancer), LEO-CVAE consistently improves classifier performance, outperforming both traditional oversampling and generative baselines. These results highlight the value of uncertainty-aware generative oversampling for imbalanced learning in domains governed by complex nonlinear structures, such as omics data.", 'abstract_zh': '局部熵导向过采样结合条件变分自编码器（LEO-CVAE）：复杂非线性结构下不平衡学习中的生成过采样', 'title_zh': '基于熵引导条件变分自编码器的不确定性感知生成过采样方法'}
{'arxiv_id': 'arXiv:2509.25297', 'title': 'Automatically Generating Web Applications from Requirements Via Multi-Agent Test-Driven Development', 'authors': 'Yuxuan Wan, Tingshuo Liang, Jiakai Xu, Jingyu Xiao, Yintong Huo, Michael R. Lyu', 'link': 'https://arxiv.org/abs/2509.25297', 'abstract': 'Developing full-stack web applications is complex and time-intensive, demanding proficiency across diverse technologies and frameworks. Although recent advances in multimodal large language models (MLLMs) enable automated webpage generation from visual inputs, current solutions remain limited to front-end tasks and fail to deliver fully functional applications. In this work, we introduce TDDev, the first test-driven development (TDD)-enabled LLM-agent framework for end-to-end full-stack web application generation. Given a natural language description or design image, TDDev automatically derives executable test cases, generates front-end and back-end code, simulates user interactions, and iteratively refines the implementation until all requirements are satisfied. Our framework addresses key challenges in full-stack automation, including underspecified user requirements, complex interdependencies among multiple files, and the need for both functional correctness and visual fidelity. Through extensive experiments on diverse application scenarios, TDDev achieves a 14.4% improvement on overall accuracy compared to state-of-the-art baselines, demonstrating its effectiveness in producing reliable, high-quality web applications without requiring manual intervention.', 'abstract_zh': '基于测试驱动的全栈网页应用生成LLM代理框架TDDev', 'title_zh': '根据需求通过多代理测试驱动开发自动生成Web应用程序'}
{'arxiv_id': 'arXiv:2509.25296', 'title': 'Learning Relationships Between Separate Audio Tracks for Creative Applications', 'authors': 'Balthazar Bujard, Jérôme Nika, Fédéric Bevilacqua, Nicolas Obin', 'link': 'https://arxiv.org/abs/2509.25296', 'abstract': "This paper presents the first step in a research project situated within the field of musical agents. The objective is to achieve, through training, the tuning of the desired musical relationship between a live musical input and a real-time generated musical output, through the curation of a database of separated tracks. We propose an architecture integrating a symbolic decision module capable of learning and exploiting musical relationships from such musical corpus. We detail an offline implementation of this architecture employing Transformers as the decision module, associated with a perception module based on Wav2Vec 2.0, and concatenative synthesis as audio renderer. We present a quantitative evaluation of the decision module's ability to reproduce learned relationships extracted during training. We demonstrate that our decision module can predict a coherent track B when conditioned by its corresponding ''guide'' track A, based on a corpus of paired tracks (A, B).", 'abstract_zh': '本文介绍了在音乐代理领域进行的研究项目的初步工作。目标是通过训练，在实时生成的音乐输出和现场音乐输入之间建立所需的音乐关系，通过构建分离轨道数据库来实现。我们提出了一种架构，该架构集成了一个象征性决策模块，能够从音乐语料库中学习和利用音乐关系。我们使用Transformer作为决策模块，并结合基于Wav2Vec 2.0的感知模块以及拼接合成作为音频渲染器，实现了一个离线实施的架构。我们对决策模块在训练中学习关系的能力进行了定量评估。我们证明，当基于一对轨道（A, B）的语料库进行条件限制时，我们的决策模块可以根据对应的“指导”轨道A预测出一致的轨道B。', 'title_zh': '学习分离音频轨之间的关系以应用于创意领域'}
{'arxiv_id': 'arXiv:2509.25293', 'title': 'AI in Pakistani Schools: Adoption, Usage, and Perceived Impact among Educators', 'authors': 'Syed Hassan Raza, Azib Farooq', 'link': 'https://arxiv.org/abs/2509.25293', 'abstract': "Artificial Intelligence (AI) is increasingly permeating classrooms worldwide, yet its adoption in schools of developing countries remains under-explored. This paper investigates AI adoption, usage patterns, and perceived impact in Pakistani K-12 schools based on a survey of 125 educators. The questionnaire covered educator's familiarity with AI, frequency and modes of use, and attitudes toward AI's benefits and challenges. Results reveal a generally positive disposition towards AI: over two-thirds of teachers expressed willingness to adopt AI tools given proper support and many have begun integrating AI for lesson planning and content creation. However, AI usage is uneven - while about one-third of respondents actively use AI tools frequently, others remain occasional users. Content generation emerged as the most common AI application, whereas AI-driven grading and feedback are rarely used. Teachers reported moderate improvements in student engagement and efficiency due to AI, but also voiced concerns about equitable access. These findings highlight both the enthusiasm for AI's potential in Pakistan's schools and the need for training and infrastructure to ensure inclusive and effective implementation.", 'abstract_zh': '人工智能（AI）在全球 Classroom 中越来越普及，但其在发展中国家学校的采用情况仍然研究不足。本文基于对125名教育者的调查，探讨了巴基斯坦K-12学校中AI的采用、使用模式及其感知影响。问卷涵盖了教育者对AI的熟悉度、使用频率和方式，以及对AI益处和挑战的态度。结果显示，教育者普遍对AI持正面态度：超过三分之二的教师表示，在获得适当支持的情况下愿意采用AI工具，且许多教师已经开始将其应用于课程规划和内容创作。然而，AI的使用并不均衡——约三分之一的受访者频繁使用AI工具，而其他人则偶尔使用。内容生成是AI最常见的应用，而AI驱动的评分和反馈则很少使用。教师报告称，AI在提高学生参与度和效率方面带来了适度的改进，但也表达了关于公平获取的担忧。这些发现突显了巴基斯坦学校中对AI潜力的热情，同时也强调了培训和基础设施的需要，以确保包容性和有效的实施。', 'title_zh': 'AI在巴基斯坦学校中的应用、使用及其对教育者 perceived impact 分析'}
{'arxiv_id': 'arXiv:2509.25289', 'title': 'ClustRecNet: A Novel End-to-End Deep Learning Framework for Clustering Algorithm Recommendation', 'authors': 'Mohammadreza Bakhtyari, Bogdan Mazoure, Renato Cordeiro de Amorim, Guillaume Rabusseau, Vladimir Makarenkov', 'link': 'https://arxiv.org/abs/2509.25289', 'abstract': 'We introduce ClustRecNet - a novel deep learning (DL)-based recommendation framework for determining the most suitable clustering algorithms for a given dataset, addressing the long-standing challenge of clustering algorithm selection in unsupervised learning. To enable supervised learning in this context, we construct a comprehensive data repository comprising 34,000 synthetic datasets with diverse structural properties. Each of them was processed using 10 popular clustering algorithms. The resulting clusterings were assessed via the Adjusted Rand Index (ARI) to establish ground truth labels, used for training and evaluation of our DL model. The proposed network architecture integrates convolutional, residual, and attention mechanisms to capture both local and global structural patterns from the input data. This design supports end-to-end training to learn compact representations of datasets and enables direct recommendation of the most suitable clustering algorithm, reducing reliance on handcrafted meta-features and traditional Cluster Validity Indices (CVIs). Comprehensive experiments across synthetic and real-world benchmarks demonstrate that our DL model consistently outperforms conventional CVIs (e.g. Silhouette, Calinski-Harabasz, Davies-Bouldin, and Dunn) as well as state-of-the-art AutoML clustering recommendation approaches (e.g. ML2DAC, AutoCluster, and AutoML4Clust). Notably, the proposed model achieves a 0.497 ARI improvement over the Calinski-Harabasz index on synthetic data and a 15.3% ARI gain over the best-performing AutoML approach on real-world data.', 'abstract_zh': '一种基于深度学习的新型聚类算法推荐框架：ClustRecNet', 'title_zh': 'ClustRecNet：一种新颖的端到端深度学习框架用于聚类算法推荐'}
{'arxiv_id': 'arXiv:2509.25275', 'title': 'VoiceBridge: Designing Latent Bridge Models for General Speech Restoration at Scale', 'authors': 'Chi Zhang, Zehua Chen, Kaiwen Zheng, Jun Zhu', 'link': 'https://arxiv.org/abs/2509.25275', 'abstract': 'Bridge models have recently been explored for speech enhancement tasks such as denoising, dereverberation, and super-resolution, while these efforts are typically confined to a single task or small-scale datasets, with constrained general speech restoration (GSR) capability at scale. In this work, we introduce VoiceBridge, a GSR system rooted in latent bridge models (LBMs), capable of reconstructing high-fidelity speech at full-band (\\textit{i.e.,} 48~kHz) from various distortions. By compressing speech waveform into continuous latent representations, VoiceBridge models the~\\textit{diverse LQ-to-HQ tasks} (namely, low-quality to high-quality) in GSR with~\\textit{a single latent-to-latent generative process} backed by a scalable transformer architecture. To better inherit the advantages of bridge models from the data domain to the latent space, we present an energy-preserving variational autoencoder, enhancing the alignment between the waveform and latent space over varying energy levels. Furthermore, to address the difficulty of HQ reconstruction from distinctively different LQ priors, we propose a joint neural prior, uniformly alleviating the reconstruction burden of LBM. At last, considering the key requirement of GSR systems, human perceptual quality, a perceptually aware fine-tuning stage is designed to mitigate the cascading mismatch in generation while improving perceptual alignment. Extensive validation across in-domain and out-of-domain tasks and datasets (\\textit{e.g.}, refining recent zero-shot speech and podcast generation results) demonstrates the superior performance of VoiceBridge. Demo samples can be visited at: this https URL.', 'abstract_zh': 'VoiceBridge：基于隐桥模型的大规模通用语音恢复系统', 'title_zh': 'VoiceBridge: 设计大规模通用语音恢复的潜在桥梁模型'}
{'arxiv_id': 'arXiv:2509.25274', 'title': 'DNABERT-2: Fine-Tuning a Genomic Language Model for Colorectal Gene Enhancer Classification', 'authors': 'Darren King, Yaser Atlasi, Gholamreza Rafiee', 'link': 'https://arxiv.org/abs/2509.25274', 'abstract': "Gene enhancers control when and where genes switch on, yet their sequence diversity and tissue specificity make them hard to pinpoint in colorectal cancer. We take a sequence-only route and fine-tune DNABERT-2, a transformer genomic language model that uses byte-pair encoding to learn variable-length tokens from DNA. Using assays curated via the Johnston Cancer Research Centre at Queen's University Belfast, we assembled a balanced corpus of 2.34 million 1 kb enhancer sequences, applied summit-centered extraction and rigorous de-duplication including reverse-complement collapse, and split the data stratified by class. With a 4096-term vocabulary and a 232-token context chosen empirically, the DNABERT-2-117M classifier was trained with Optuna-tuned hyperparameters and evaluated on 350742 held-out sequences. The model reached PR-AUC 0.759, ROC-AUC 0.743, and best F1 0.704 at an optimized threshold (0.359), with recall 0.835 and precision 0.609. Against a CNN-based EnhancerNet trained on the same data, DNABERT-2 delivered stronger threshold-independent ranking and higher recall, although point accuracy was lower. To our knowledge, this is the first study to apply a second-generation genomic language model with BPE tokenization to enhancer classification in colorectal cancer, demonstrating the feasibility of capturing tumor-associated regulatory signals directly from DNA sequence alone. Overall, our results show that transformer-based genomic models can move beyond motif-level encodings toward holistic classification of regulatory elements, offering a novel path for cancer genomics. Next steps will focus on improving precision, exploring hybrid CNN-transformer designs, and validating across independent datasets to strengthen real-world utility.", 'abstract_zh': '基于BPE分词的第二代基因语言模型在结直肠癌增强子分类中的应用：从DNA序列直接捕获肿瘤相关调控信号的可能性', 'title_zh': 'DNABERT-2：用于结肠癌基因增强子分类的基因组语言模型微调'}
{'arxiv_id': 'arXiv:2509.25268', 'title': 'A Weather Foundation Model for the Power Grid', 'authors': 'Cristian Bodnar, Raphaël Rousseau-Rizzi, Nikhil Shankar, James Merleau, Stylianos Flampouris, Guillem Candille, Slavica Antic, François Miralles, Jayesh K. Gupta', 'link': 'https://arxiv.org/abs/2509.25268', 'abstract': "Weather foundation models (WFMs) have recently set new benchmarks in global forecast skill, yet their concrete value for the weather-sensitive infrastructure that powers modern society remains largely unexplored. In this study, we fine-tune Silurian AI's 1.5B-parameter WFM, Generative Forecasting Transformer (GFT), on a rich archive of Hydro-Québec asset observations--including transmission-line weather stations, wind-farm met-mast streams, and icing sensors--to deliver hyper-local, asset-level forecasts for five grid-critical variables: surface temperature, precipitation, hub-height wind speed, wind-turbine icing risk, and rime-ice accretion on overhead conductors. Across 6-72 h lead times, the tailored model surpasses state-of-the-art NWP benchmarks, trimming temperature mean absolute error (MAE) by 15%, total-precipitation MAE by 35%, and lowering wind speed MAE by 15%. Most importantly, it attains an average precision score of 0.72 for day-ahead rime-ice detection, a capability absent from existing operational systems, which affords several hours of actionable warning for potentially catastrophic outage events. These results show that WFMs, when post-trained with small amounts of high-fidelity, can serve as a practical foundation for next-generation grid-resilience intelligence.", 'abstract_zh': '基于天气的预训练模型（WFMs）在全局预报技能上已设定新基准，但其对支撑现代社会的天气敏感型基础设施的具体价值尚待探索。通过对此项研究，我们利用包含水电-魁北克资产观测数据（包括输电线路气象站、风场测风塔流和结冰传感器）的丰富档案，对Silurian AI的1.5亿参数生成预报变换器（GFT）模型进行微调，以提供五种电网关键变量的超局地、资产级预报：地表温度、降水、轮毂高度风速、风力涡轮机结冰风险以及架空导线覆冰累积。在6-72小时的预报时效内，定制化模型超过了最先进的数值天气预报（NWP）基准，在温度平均绝对误差（MAE）上降低了15%，在总降水MAE上降低了35%，在风速MAE上降低了15%。尤为重要的是，它在翌日结冰检测上的平均精准度得分为0.72，这是现有运营系统所不具备的能力，可提供几小时的可操作预警，以应对潜在的灾难性断电事件。结果表明，当用少量高保真数据进行后微调后，WFMs可作为下一代电网韧性智能的实际基础。', 'title_zh': '电力-grid气象基础模型'}
{'arxiv_id': 'arXiv:2509.25266', 'title': "Cognifying Education: Mapping AI's transformative role in emotional, creative, and collaborative learning", 'authors': 'Mikael Gorsky, Ilya Levin', 'link': 'https://arxiv.org/abs/2509.25266', 'abstract': 'Artificial intelligence (AI) is rapidly reshaping educational practice, challenging long held assumptions about teaching and learning. This article integrates conceptual perspectives from recent books (Genesis by Eric Schmidt, Henry Kissinger and Craig Mundie, CoIntelligence by Ethan Mollick, and The Inevitable by Kevin Kelly) with empirical insights from popular AI podcasts and Anthropic public releases. We examine seven key domains: emotional support, creativity, contextual understanding, student engagement, problem solving, ethics and morality, and collaboration. For each domain, we explore AI capabilities, opportunities for transformative change, and emerging best practices, drawing equally from theoretical analysis and real world observations. Overall, we find that AI, when used thoughtfully, can complement and enhance human educators in fostering richer learning experiences across cognitive, social, and emotional dimensions. We emphasize an optimistic yet responsible outlook: educators and students should actively shape AI integration to amplify human potential in creativity, ethical reasoning, collaboration, and beyond, while maintaining a focus on human centric values.', 'abstract_zh': '人工智能正在迅速重塑教育实践，挑战着关于教学和学习的长期假设。本文将近期书籍（《创世》by Eric Schmidt, Henry Kissinger和Craig Mundie，《共智》by Ethan Mollick，以及《必然》by Kevin Kelly）的概念视角与流行AI播客和Anthropic公开发布的内容相结合，探讨了七个关键领域：情感支持、创造力、情境理解、学生参与、解决问题、伦理与道德，以及协作。针对每个领域，本文探讨了人工智能的能力、变革机会以及正在涌现的最佳实践，既来自于理论分析也来自于现实观察。总体而言，我们发现，当明智地使用时，人工智能能够补充并增强人类教育者，在认知、社会和情感维度上促进更丰富的学习体验。我们强调一种既乐观又负责任的态度：教育工作者和学生应当积极塑造人工智能的整合方式，以放大人类在创造力、伦理推理、协作等方面的能力，同时保持对以人为本的价值观的关注。', 'title_zh': '认知化教育：映射AI在情感、创造性和协作性学习中的变革性作用'}
{'arxiv_id': 'arXiv:2509.25263', 'title': 'How Effective Are Time-Series Models for Rainfall Nowcasting? A Comprehensive Benchmark for Rainfall Nowcasting Incorporating PWV Data', 'authors': 'Yifang Zhang, Pengfei Duan, Henan Wang, Shengwu Xiong', 'link': 'https://arxiv.org/abs/2509.25263', 'abstract': 'Rainfall nowcasting, which aims to predict precipitation within the next 0 to 3 hours, is critical for disaster mitigation and real-time response planning. However, most time series forecasting benchmarks in meteorology are evaluated on variables with strong periodicity, such as temperature and humidity, which fail to reflect model capabilities in more complex and practically meteorology scenarios like rainfall nowcasting. To address this gap, we propose RainfallBench, a benchmark designed for rainfall nowcasting, a highly challenging and practically relevant task characterized by zero inflation, temporal decay, and non-stationarity, focused on predicting precipitation within the next 0 to 3 hours. The dataset is derived from five years of meteorological observations, recorded at 15-minute intervals across six essential variables, and collected from more than 12,000 GNSS stations globally. In particular, it incorporates precipitable water vapor (PWV), a crucial indicator of rainfall that is absent in other datasets. We further design specialized evaluation strategies to assess model performance on key meteorological challenges, such as multi-scale prediction and extreme rainfall events, and evaluate over 20 state-of-the-art models across six major architectures on RainfallBench. Additionally, to address the zero-inflation and temporal decay issues overlooked by existing models, we introduce Bi-Focus Precipitation Forecaster (BFPF), a plug-and-play module that incorporates domain-specific priors to enhance rainfall time series forecasting. Statistical analysis and ablation studies validate the comprehensiveness of our dataset as well as the superiority of our methodology. Code and datasets are available at this https URL.', 'abstract_zh': '降雨_nowcasting：一种用于接下来0至3小时降水预测的基准，以解决气象时间序列预测基准中强周期性变量主导的问题，并专注于零膨胀、时间衰减和非平稳性的挑战。', 'title_zh': '时间序列模型在降雨现在casting中的有效性：结合PWV数据的全面现在casting基准测试'}
{'arxiv_id': 'arXiv:2509.25258', 'title': 'Artificial Intelligence-Powered Assessment Framework for Skill-Oriented Engineering Lab Education', 'authors': 'Vaishnavi Sharma, Rakesh Thakur, Shashwat Sharma, Kritika Panjanani', 'link': 'https://arxiv.org/abs/2509.25258', 'abstract': 'Practical lab education in computer science often faces challenges such as plagiarism, lack of proper lab records, unstructured lab conduction, inadequate execution and assessment, limited practical learning, low student engagement, and absence of progress tracking for both students and faculties, resulting in graduates with insufficient hands-on skills. In this paper, we introduce AsseslyAI, which addresses these challenges through online lab allocation, a unique lab problem for each student, AI-proctored viva evaluations, and gamified simulators to enhance engagement and conceptual mastery. While existing platforms generate questions based on topics, our framework fine-tunes on a 10k+ question-answer dataset built from AI/ML lab questions to dynamically generate diverse, code-rich assessments. Validation metrics show high question-answer similarity, ensuring accurate answers and non-repetitive questions. By unifying dataset-driven question generation, adaptive difficulty, plagiarism resistance, and evaluation in a single pipeline, our framework advances beyond traditional automated grading tools and offers a scalable path to produce genuinely skilled graduates.', 'abstract_zh': '计算机科学中的实践实验室教育常常面临抄袭、缺乏适当的实验室记录、无结构的实验操作、不充分的执行和评估、有限的实际学习、学生参与度低以及师生进度跟踪缺失等问题，导致毕业生缺乏足够的动手技能。本文介绍了一种名为AsseslyAI的解决方案，通过在线实验室分配、为每位学生提供独特的实验室问题、使用AI监考的口试评估以及 gamified 模拟器来提升参与度和概念掌握。现有平台基于主题生成问题，而我们的框架则通过构建一个包含超过10,000个问答的数据集并从中微调，实现动态生成多样且富含代码的评估。验证指标显示高相似度的问答，确保准确的答案和非重复的问题。通过在一个集成管道中统一数据驱动的问题生成、自适应难度、抗抄袭和评估功能，我们的框架超越了传统的自动化评分工具，并提供了一条可扩展的道路，以培养真正具备技能的毕业生。', 'title_zh': '基于人工智能的动力工程实训技能导向评估框架'}
{'arxiv_id': 'arXiv:2509.25256', 'title': 'The Sandbox Configurator: A Framework to Support Technical Assessment in AI Regulatory Sandboxes', 'authors': 'Alessio Buscemi, Thibault Simonetto, Daniele Pagani, German Castignani, Maxime Cordy, Jordi Cabot', 'link': 'https://arxiv.org/abs/2509.25256', 'abstract': "The systematic assessment of AI systems is increasingly vital as these technologies enter high-stakes domains. To address this, the EU's Artificial Intelligence Act introduces AI Regulatory Sandboxes (AIRS): supervised environments where AI systems can be tested under the oversight of Competent Authorities (CAs), balancing innovation with compliance, particularly for startups and SMEs. Yet significant challenges remain: assessment methods are fragmented, tests lack standardisation, and feedback loops between developers and regulators are weak. To bridge these gaps, we propose the Sandbox Configurator, a modular open-source framework that enables users to select domain-relevant tests from a shared library and generate customised sandbox environments with integrated dashboards. Its plug-in architecture aims to support both open and proprietary modules, fostering a shared ecosystem of interoperable AI assessment services. The framework aims to address multiple stakeholders: CAs gain structured workflows for applying legal obligations; technical experts can integrate robust evaluation methods; and AI providers access a transparent pathway to compliance. By promoting cross-border collaboration and standardisation, the Sandbox Configurator's goal is to support a scalable and innovation-friendly European infrastructure for trustworthy AI governance.", 'abstract_zh': 'AI系统系统的评估随着这些技术进入高风险领域变得越来越重要。为此，欧盟人工智能法案提出了AI监管沙盒（AIRS）：在监管当局（CAs）监督下的受控环境，以平衡创新与合规，特别是针对初创企业和中小企业。然而，仍存在重大挑战：评估方法碎片化，测试缺乏标准化，开发者与监管者之间的反馈循环薄弱。为解决这些差距，我们提出了沙盒配置器，这是一个模块化的开源框架，使用户能够从共享库中选择相关领域的测试，并生成包含集成仪表板的个性化沙盒环境。其插件架构旨在支持开源和专有模块，促进互操作的AI评估服务共享生态系统的形成。该框架旨在应对多个利益相关方的需求：监管当局获得结构化的合规工作流程；技术专家可以集成 robust 评估方法；AI 提供商能够获得透明的合规途径。通过促进跨境合作和标准化，沙盒配置器的目标是支持一个可扩展且创新友好的欧洲可信人工智能治理体系基础设施。', 'title_zh': '沙盒配置器：支持AI监管沙盒技术评估的框架'}
{'arxiv_id': 'arXiv:2509.25245', 'title': 'Comprehensive Analysis of VQC for Financial Fraud Detection: A Comparative Study of Quantum Encoding Techniques and Architectural Optimizations', 'authors': 'Fouad Mohammed Abbou, Mohamed Bouhadda, Lamiae Bouanane, Mouna Kettani, Farid Abdi, Abdelouahab Abid', 'link': 'https://arxiv.org/abs/2509.25245', 'abstract': 'This paper presents a systematic comparative analysis of Variational Quantum Classifier (VQC) configurations for financial fraud detection, encompassing three distinct quantum encoding techniques and comprehensive architectural variations. Through empirical evaluation across multiple entanglement patterns, circuit depths, and optimization strategies,quantum advantages in fraud classification accuracy are demonstrated, achieving up to 94.3 % accuracy with ZZ encoding schemes. The analysis reveals significant performance variations across entanglement topologies, with circular entanglement consistently outperforming linear (90.7) %) and full connectivity (92.0 %) patterns, achieving optimal performance at 93.3 % accuracy. The study introduces novel visualization methodologies for quantum circuit analysis and provides actionable deployment recommendations for practical quantum machine learning implementations. Notably, systematic entanglement pattern analysis shows that circular connectivity provides superior balance between expressivity and trainability while maintaining computational efficiency. These researches offer initial benchmarks for quantum enhanced fraud detection systems and propose potential benefits of quantum machine learning in financial security applications.', 'abstract_zh': '这篇论文对量子变分分类器（VQC）配置在金融欺诈检测中的系统性比较分析进行了介绍，涵盖了三种不同的量子编码技术和全面的架构变化。通过在多个纠缠模式、电路深度和优化策略上的实证评估，展示了量子编码在欺诈分类准确性上的优势，ZZ编码方案可达94.3%的准确率。分析结果显示，在纠缠拓扑结构上存在显著的性能差异，其中圆形纠缠始终优于线性（90.7%）和全连接（92.0%）模式，并在93.3%的准确率下表现出最佳性能。研究引入了量子电路分析的新型可视化方法，并提供了实用的量子机器学习部署建议。系统性纠缠模式分析表明，圆形连接提供了在表达能力和可训练性之间优越的平衡，同时保持计算效率。这些研究为量子增强欺诈检测系统提供了初步基准，并提出了量子机器学习在金融安全应用中的潜在益处。', 'title_zh': '全面分析VQC在金融欺诈检测中的应用：量子编码技术与架构优化的比较研究'}
{'arxiv_id': 'arXiv:2509.25242', 'title': 'A Benchmark for Localizing Code and Non-Code Issues in Software Projects', 'authors': 'Zejun Zhang, Jian Wang, Qingyun Yang, Yifan Pan, Yi Tang, Yi Li, Zhenchang Xing, Tian Zhang, Xuandong Li, Guoan Zhang', 'link': 'https://arxiv.org/abs/2509.25242', 'abstract': 'Accurate project localization (e.g., files and functions) for issue resolution is a critical first step in software maintenance. However, existing benchmarks for issue localization, such as SWE-Bench and LocBench, are limited. They focus predominantly on pull-request issues and code locations, ignoring other evidence and non-code files such as commits, comments, configurations, and documentation. To address this gap, we introduce MULocBench, a comprehensive dataset of 1,100 issues from 46 popular GitHub Python projects. Comparing with existing benchmarks, MULocBench offers greater diversity in issue types, root causes, location scopes, and file types, providing a more realistic testbed for evaluation. Using this benchmark, we assess the performance of state-of-the-art localization methods and five LLM-based prompting strategies. Our results reveal significant limitations in current techniques: even at the file level, performance metrics (Acc@5, F1) remain below 40%. This underscores the challenge of generalizing to realistic, multi-faceted issue resolution. To enable future research on project localization for issue resolution, we publicly release MULocBench at this https URL.', 'abstract_zh': '准确的项目定位（例如文件和函数）是软件维护中问题解决的关键第一步。然而，现有的问题定位基准，如SWE-Bench和LocBench，存在局限性。它们主要关注拉取请求中的问题和代码位置，忽视了其他证据和非代码文件，如提交、注释、配置和文档。为填补这一空白，我们引入了MULocBench，这是一个包含46个流行GitHub Python项目中的1100个问题的综合数据集。与现有的基准相比，MULocBench在问题类型、根本原因、定位范围和文件类型方面提供了更大的多样性，为评估提供了更为真实的测试平台。使用这一基准，我们评估了最先进的定位方法和五种基于LLM的提示策略的表现。我们的结果揭示了当前技术的重大局限性：即使在文件级别，性能指标（Acc@5、F1）也低于40%。这强调了将技术应用于真实、多方面的问题解决的挑战。为了促进项目定位在问题解决方面的未来研究，我们已在此网址公开发布MULocBench：this https URL。', 'title_zh': '软件项目中代码与非代码问题定位基准'}
{'arxiv_id': 'arXiv:2509.25237', 'title': 'Quantum est in Libris: Navigating Archives with GenAI, Uncovering Tension Between Preservation and Innovation', 'authors': 'Mar Canet Sola, Varvara Guljajeva', 'link': 'https://arxiv.org/abs/2509.25237', 'abstract': '"Quantum est in libris" explores the intersection of the archaic and the modern. On one side, there are manuscript materials from the Estonian National Museum\'s (ERM) more than century-old archive describing the life experiences of Estonian people; on the other side, there is technology that transforms these materials into a dynamic and interactive experience. Connecting technology and cultural heritage is the visitor, who turns texts into inputs for a screen sculpture.\nHistorical narratives are visually brought to life through the contemporary technological language. Because the video AI models we employed, Runway Gen-3 and Gen-4, have not previously interacted with Estonian heritage, we can observe how machines today "read the world" and create future heritage. "Quantum est in libris" introduces an exciting yet unsettling new dimension to the concept of cultural heritage: in a world where data are fluid and interpretations unstable, heritage status becomes fragile. In the digital environment, heritage issues are no longer just about preservation and transmission, but also about representation of the media, machine creativity, and interpretive error. Who or what shapes memory processes and memory spaces, and how?', 'abstract_zh': '《Quantum est in libris》探索了古代与现代的交集。一边是爱沙尼亚国家博物馆（ERM）百年档案中的手稿材料，记录了爱沙尼亚人的生活经历；另一边则是将这些材料转化为动态和互动体验的技术。将技术和文化遗产联系起来的是参观者，他们将文字转化为屏幕雕塑的输入。 Historical narratives通过当代的技术语言被视觉化地呈现出来。由于我们使用的视频AI模型Runway Gen-3和Gen-4此前未与爱沙尼亚遗产互动，我们能够观察到现在机器“如何理解世界”并创造未来遗产。《Quantum est in libris》为文化遗产的概念引入了一个激动人心但又让人不安的新维度：在一个数据流动、解释不稳定的世界上，遗产地位变得脆弱。在数字环境中，文化遗产问题不再仅仅是保存和传递，还包括媒体呈现、机器创造和解释错误。谁或什么塑造了记忆过程和记忆空间，以及它是如何塑造的？', 'title_zh': 'Quantum est in Libris: 刻于卷轴之上：利用生成式AI导航档案馆，揭露保存与创新之间的张力'}
{'arxiv_id': 'arXiv:2509.25235', 'title': 'Machine Learning for Pattern Detection in Printhead Nozzle Logging', 'authors': 'Nikola Prianikov, Evelyne Janssen-van Dam, Marcin Pietrasik, Charalampos S. Kouzinopoulos', 'link': 'https://arxiv.org/abs/2509.25235', 'abstract': 'Correct identification of failure mechanisms is essential for manufacturers to ensure the quality of their products. Certain failures of printheads developed by Canon Production Printing can be identified from the behavior of individual nozzles, the states of which are constantly recorded and can form distinct patterns in terms of the number of failed nozzles over time, and in space in the nozzle grid. In our work, we investigate the problem of printhead failure classification based on a multifaceted dataset of nozzle logging and propose a Machine Learning classification approach for this problem. We follow the feature-based framework of time-series classification, where a set of time-based and spatial features was selected with the guidance of domain experts. Several traditional ML classifiers were evaluated, and the One-vs-Rest Random Forest was found to have the best performance. The proposed model outperformed an in-house rule-based baseline in terms of a weighted F1 score for several failure mechanisms.', 'abstract_zh': '正确的故障机制识别对于确保产品质量至关重要。佳能生产打印开发的喷头某些故障可以通过单个喷嘴的行为进行识别，这些喷嘴的状态不断被记录，并且随着时间的推移和在喷嘴网格的空间中可以形成不同的模式。在本工作中，我们基于喷嘴日志的多维度数据集研究喷头故障分类问题，并提出了一种机器学习分类方法。我们采用了时间序列分类的特征为基础的框架，选择了由领域专家指导的时间和空间特征集。多种传统的机器学习分类器进行了评估，One-vs-Rest 随机森林被发现具有最佳性能。所提出的模型在加权F1分数方面优于内部基于规则的基线模型，对于几种故障机制而言。', 'title_zh': '基于机器学习的 printhead 喷嘴日志模式检测'}
{'arxiv_id': 'arXiv:2509.25233', 'title': 'FedCLF - Towards Efficient Participant Selection for Federated Learning in Heterogeneous IoV Networks', 'authors': 'Kasun Eranda Wijethilake, Adnan Mahmood, Quan Z. Sheng', 'link': 'https://arxiv.org/abs/2509.25233', 'abstract': 'Federated Learning (FL) is a distributed machine learning technique that preserves data privacy by sharing only the trained parameters instead of the client data. This makes FL ideal for highly dynamic, heterogeneous, and time-critical applications, in particular, the Internet of Vehicles (IoV) networks. However, FL encounters considerable challenges in such networks owing to the high data and device heterogeneity. To address these challenges, we propose FedCLF, i.e., FL with Calibrated Loss and Feedback control, which introduces calibrated loss as a utility in the participant selection process and a feedback control mechanism to dynamically adjust the sampling frequency of the clients. The envisaged approach (a) enhances the overall model accuracy in case of highly heterogeneous data and (b) optimizes the resource utilization for resource constrained IoV networks, thereby leading to increased efficiency in the FL process. We evaluated FedCLF vis-à-vis baseline models, i.e., FedAvg, Newt, and Oort, using CIFAR-10 dataset with varying data heterogeneity. Our results depict that FedCLF significantly outperforms the baseline models by up to a 16% improvement in high data heterogeneity-related scenarios with improved efficiency via reduced sampling frequency.', 'abstract_zh': '联邦学习（FL）是一种通过共享训练参数而非客户端数据来保护数据隐私的分布式机器学习技术。这使得FL特别适合高度动态、异构和时间敏感的应用，特别是在车联网（IoV）网络中。然而，由于数据和设备的高度异构性，FL在这样的网络中面临着诸多挑战。为了解决这些挑战，我们提出了FedCLF，即集成校准损失和反馈控制的联邦学习方法，该方法在参与者选择过程中引入了校准损失作为效用，并引入了反馈控制机制以动态调整客户端的采样频率。该设想的方法在数据高度异构的情况下（a）提升了整体模型精度，并在资源受限的车联网网络中（b）优化了资源利用率，从而提高了联邦学习过程的效率。我们使用CIFAR-10数据集和不同水平的数据异构性对FedCLF与基准模型FedAvg、Newt和Oort进行了评估。实验结果表明，在高数据异构性相关场景中，FedCLF相较于基准模型提高了高达16%的性能，并通过降低采样频率提高了效率。', 'title_zh': 'FedCLF - 面向异构IoV网络的联邦学习参与者高效选择方法'}
{'arxiv_id': 'arXiv:2509.25230', 'title': 'Energy Guided Geometric Flow Matching', 'authors': 'Aaron Zweig, Mingxuan Zhang, Elham Azizi, David Knowles', 'link': 'https://arxiv.org/abs/2509.25230', 'abstract': 'A useful inductive bias for temporal data is that trajectories should stay close to the data manifold. Traditional flow matching relies on straight conditional paths, and flow matching methods which learn geodesics rely on RBF kernels or nearest neighbor graphs that suffer from the curse of dimensionality. We propose to use score matching and annealed energy distillation to learn a metric tensor that faithfully captures the underlying data geometry and informs more accurate flows. We demonstrate the efficacy of this strategy on synthetic manifolds with analytic geodesics, and interpolation of cell', 'abstract_zh': '一种对时间数据有用的归纳偏置是轨迹应接近数据流形。传统的流匹配依赖于直线条件路径，而学习测地线的流匹配方法则依赖于受维度灾难影响的RBF核或最近邻图。我们提出使用得分匹配和退火能量蒸馏来学习一个忠实捕捉底层数据几何结构的度量张量，并指导更准确的流匹配。我们在具有解析测地线的合成流形以及细胞插值上展示了该策略的有效性。', 'title_zh': '能量导向几何流匹配'}
{'arxiv_id': 'arXiv:2509.25223', 'title': 'Enhancing Linear Attention with Residual Learning', 'authors': 'Xunhao Lai, Jialiang Kang, Jianqiao Lu, Tong Lin, Pengyu Zhao', 'link': 'https://arxiv.org/abs/2509.25223', 'abstract': 'Linear attention offers a linear-time alternative to self-attention but often struggles to capture long-range patterns. We revisit linear attention through a prediction-correction lens and show that prevalent variants can be written as a combination of a historical prediction and a single-token correction, which creates an expressivity bottleneck. To address this bottleneck, we introduce Residual Linear Attention (RLA), a framework that equips linear attention with an explicit residual-fitting mechanism. RLA maintains an auxiliary recurrent state that learns to accumulate residual errors over time and correct the base prediction. We further instantiate a delta-rule version, Residual Delta Net (RDN), incorporating adaptive gating and residual clipping for enhanced correction control and stability. Our implementation leverages highly optimized linear attention kernels and preserves linear time and memory. Across language modeling and recall-intensive evaluations, RLA and RDN consistently outperform their respective baselines and other modern linear-attention methods, narrowing the gap to standard Transformers while retaining linear scaling.', 'abstract_zh': '基于预测校正视角的残差线性注意力', 'title_zh': '增强线性注意力机制_residual learning优化_'}
{'arxiv_id': 'arXiv:2509.25217', 'title': 'Learning to Condition: A Neural Heuristic for Scalable MPE Inference', 'authors': 'Brij Malhotra, Shivvrat Arya, Tahrima Rahman, Vibhav Giridhar Gogate', 'link': 'https://arxiv.org/abs/2509.25217', 'abstract': 'We introduce learning to condition (L2C), a scalable, data-driven framework for accelerating Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs), a fundamentally intractable problem. L2C trains a neural network to score variable-value assignments based on their utility for conditioning, given observed evidence. To facilitate supervised learning, we develop a scalable data generation pipeline that extracts training signals from the search traces of existing MPE solvers. The trained network serves as a heuristic that integrates with search algorithms, acting as a conditioning strategy prior to exact inference or as a branching and node selection policy within branch-and-bound solvers. We evaluate L2C on challenging MPE queries involving high-treewidth PGMs. Experiments show that our learned heuristic significantly reduces the search space while maintaining or improving solution quality over state-of-the-art methods.', 'abstract_zh': '基于条件学习（L2C）：一种面向概率图形模型（PGMs）最具可能解释（MPE）推理的可扩展数据驱动框架', 'title_zh': '学习条件化：一种可扩展的MPE推断神经启发方法'}
{'arxiv_id': 'arXiv:2509.25213', 'title': 'Six Sigma For Neural Networks: Taguchi-based optimization', 'authors': 'Sai Varun Kodathala', 'link': 'https://arxiv.org/abs/2509.25213', 'abstract': 'The optimization of hyperparameters in convolutional neural networks (CNNs) remains a challenging and computationally expensive process, often requiring extensive trial-and-error approaches or exhaustive grid searches. This study introduces the application of Taguchi Design of Experiments methodology, a statistical optimization technique traditionally used in quality engineering, to systematically optimize CNN hyperparameters for professional boxing action recognition. Using an L12(211) orthogonal array, eight hyperparameters including image size, color mode, activation function, learning rate, rescaling, shuffling, vertical flip, and horizontal flip were systematically evaluated across twelve experimental configurations. To address the multi-objective nature of machine learning optimization, five different approaches were developed to simultaneously optimize training accuracy, validation accuracy, training loss, and validation loss using Signal-to-Noise ratio analysis. The study employed a novel logarithmic scaling technique to unify conflicting metrics and enable comprehensive multi-quality assessment within the Taguchi framework. Results demonstrate that Approach 3, combining weighted accuracy metrics with logarithmically transformed loss functions, achieved optimal performance with 98.84% training accuracy and 86.25% validation accuracy while maintaining minimal loss values. The Taguchi analysis revealed that learning rate emerged as the most influential parameter, followed by image size and activation function, providing clear guidance for hyperparameter prioritization in CNN optimization.', 'abstract_zh': '卷积神经网络（CNN）超参数的优化依然是一个具有挑战性和计算成本高的过程，通常需要大量的试错或全面的网格搜索。本研究引入了Taguchi设计实验方法，一种传统上应用于质量工程中的统计优化技术，用于系统地优化职业boxing动作识别中的CNN超参数。利用L12(211)正交数组，系统地评估了八个超参数包括图像大小、颜色模式、激活函数、学习率、缩放、打乱、垂直翻转和平移翻转，在十二种实验配置中。为了应对机器学习优化中的多目标性质，开发了五种不同的方法，利用信噪比分析同时优化训练精度、验证精度、训练损失和验证损失。研究采用了一种新的对数缩放技术，统一冲突指标并在Taguchi框架内实现全面的质量评估。结果表明，结合加权精度指标和对数变换损失函数的Approach 3实现了最佳性能，训练精度为98.84%，验证精度为86.25%，同时保持最低的损失值。Taguchi分析表明，学习率是最具影响力的参数，其次是图像大小和激活函数，为CNN优化中的超参数优先级提供了清晰的指导。', 'title_zh': '基于田口方法的六西格玛神经网络优化'}
{'arxiv_id': 'arXiv:2509.25210', 'title': 'STCast: Adaptive Boundary Alignment for Global and Regional Weather Forecasting', 'authors': 'Hao Chen, Tao Han, Jie Zhang, Song Guo, Lei Bai', 'link': 'https://arxiv.org/abs/2509.25210', 'abstract': "To gain finer regional forecasts, many works have explored the regional integration from the global atmosphere, e.g., by solving boundary equations in physics-based methods or cropping regions from global forecasts in data-driven methods. However, the effectiveness of these methods is often constrained by static and imprecise regional boundaries, resulting in poor generalization ability. To address this issue, we propose Spatial-Temporal Weather Forecasting (STCast), a novel AI-driven framework for adaptive regional boundary optimization and dynamic monthly forecast allocation. Specifically, our approach employs a Spatial-Aligned Attention (SAA) mechanism, which aligns global and regional spatial distributions to initialize boundaries and adaptively refines them based on attention-derived alignment patterns. Furthermore, we design a Temporal Mixture-of-Experts (TMoE) module, where atmospheric variables from distinct months are dynamically routed to specialized experts using a discrete Gaussian distribution, enhancing the model's ability to capture temporal patterns. Beyond global and regional forecasting, we evaluate our STCast on extreme event prediction and ensemble forecasting. Experimental results demonstrate consistent superiority over state-of-the-art methods across all four tasks.", 'abstract_zh': '基于空间-时间weather预测的自适应区域边界的优化和动态月度预报分配（STCast）', 'title_zh': 'STCast: 自适应边界对齐的全局和地区天气预报'}
{'arxiv_id': 'arXiv:2507.23390', 'title': 'FMIP: Joint Continuous-Integer Flow For Mixed-Integer Linear Programming', 'authors': 'Hongpei Li, Hui Yuan, Han Zhang, Jianghao Lin, Dongdong Ge, Mengdi Wang, Yinyu Ye', 'link': 'https://arxiv.org/abs/2507.23390', 'abstract': 'Mixed-Integer Linear Programming (MILP) is a foundational tool for complex decision-making problems. However, the NP-hard nature of MILP presents a significant computational challenge, motivating the development of machine learning-based heuristic solutions to accelerate downstream solvers. While recent generative models have shown promise in learning powerful heuristics, they suffer from a critical limitation. That is, they model the distribution of only the integer variables and fail to capture the intricate coupling between integer and continuous variables, creating an information bottleneck and ultimately leading to suboptimal solutions. To this end, we propose Joint Continuous-Integer Flow for Mixed-Integer Linear Programming (FMIP), which is the first generative framework that models the joint distribution of both integer and continuous variables for MILP solutions. Built upon the joint modeling paradigm, a holistic guidance mechanism is designed to steer the generative trajectory, actively refining solutions toward optimality and feasibility during the inference process. Extensive experiments on eight standard MILP benchmarks demonstrate the superior performance of FMIP against existing baselines, reducing the primal gap by 41.34% on average. Moreover, we show that FMIP is fully compatible with arbitrary backbone networks and various downstream solvers, making it well-suited for a broad range of real-world MILP applications.', 'abstract_zh': 'Joint Continuous-Integer Flow for Mixed-Integer Linear Programming (FMIP)', 'title_zh': 'FMIP: 联合连续-整数流的混合整数线性规划'}
