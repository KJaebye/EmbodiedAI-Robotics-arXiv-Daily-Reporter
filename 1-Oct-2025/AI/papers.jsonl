{'arxiv_id': 'arXiv:2509.26632', 'title': 'Branching Out: Broadening AI Measurement and Evaluation with Measurement Trees', 'authors': 'Craig Greenberg, Patrick Hall, Theodore Jensen, Kristen Greene, Razvan Amironesei', 'link': 'https://arxiv.org/abs/2509.26632', 'abstract': 'This paper introduces \\textit{measurement trees}, a novel class of metrics designed to combine various constructs into an interpretable multi-level representation of a measurand. Unlike conventional metrics that yield single values, vectors, surfaces, or categories, measurement trees produce a hierarchical directed graph in which each node summarizes its children through user-defined aggregation methods. In response to recent calls to expand the scope of AI system evaluation, measurement trees enhance metric transparency and facilitate the integration of heterogeneous evidence, including, e.g., agentic, business, energy-efficiency, sociotechnical, or security signals. We present definitions and examples, demonstrate practical utility through a large-scale measurement exercise, and provide accompanying open-source Python code. By operationalizing a transparent approach to measurement of complex constructs, this work offers a principled foundation for broader and more interpretable AI evaluation.', 'abstract_zh': '本文介绍了测量树，这是一种新型的度量类别，设计用于将各种构造结合成可解释的多层次表示。与传统的单一值、向量、表面或类别度量不同，测量树生成一个层级有向图，其中每个节点通过用户定义的聚合方法来总结其子节点。响应近期对扩展AI系统评价范围的呼吁，测量树增强了度量的透明度，并促进了异构证据的集成，包括代理、商业、能源效率、技术社会或安全信号。我们提供了定义和示例，通过大规模测量实验展示了其实用性，并提供了 accompanying 开源 Python 代码。通过操作化复杂构造的透明度量方法，本文为更广泛且更可解释的AI评价提供了原则性的基础。', 'title_zh': '扩展视野：通过测量树拓宽人工智能的评估范畴'}
{'arxiv_id': 'arXiv:2509.26627', 'title': 'TimeRewarder: Learning Dense Reward from Passive Videos via Frame-wise Temporal Distance', 'authors': 'Yuyang Liu, Chuan Wen, Yihang Hu, Dinesh Jayaraman, Yang Gao', 'link': 'https://arxiv.org/abs/2509.26627', 'abstract': 'Designing dense rewards is crucial for reinforcement learning (RL), yet in robotics it often demands extensive manual effort and lacks scalability. One promising solution is to view task progress as a dense reward signal, as it quantifies the degree to which actions advance the system toward task completion over time. We present TimeRewarder, a simple yet effective reward learning method that derives progress estimation signals from passive videos, including robot demonstrations and human videos, by modeling temporal distances between frame pairs. We then demonstrate how TimeRewarder can supply step-wise proxy rewards to guide reinforcement learning. In our comprehensive experiments on ten challenging Meta-World tasks, we show that TimeRewarder dramatically improves RL for sparse-reward tasks, achieving nearly perfect success in 9/10 tasks with only 200,000 interactions per task with the environment. This approach outperformed previous methods and even the manually designed environment dense reward on both the final success rate and sample efficiency. Moreover, we show that TimeRewarder pretraining can exploit real-world human videos, highlighting its potential as a scalable approach path to rich reward signals from diverse video sources.', 'abstract_zh': '设计稠密奖励对于强化学习至关重要，但在机器人领域往往需要大量的手动努力且缺乏可扩展性。一种有前景的解决方案是将任务进度视为稠密奖励信号，因为它量化了动作随时间推进系统向任务完成程度。我们提出了TimeRewarder，一种简单有效的奖励学习方法，通过建模帧对之间的时间距离从被动视频中提取进度估计信号，包括机器人演示和人类视频。然后我们展示了TimeRewarder如何提供逐步的代理奖励来引导强化学习。在对十个具有挑战性的Meta-World任务进行全面实验中，我们表明TimeRewarder显著提高了稀疏奖励任务的强化学习性能，仅需每任务20万次与环境交互，便在9/10任务中实现了近乎完美的成功率。该方法在最终成功率和样本效率上均优于以往方法，甚至优于人工设计的环境密集奖励。此外，我们展示了TimeRewarder预训练可以利用现实世界的视频，突显了其从多种视频源生成丰富奖励信号的潜在可扩展途径。', 'title_zh': 'TimeRewarder：通过帧级时间距离从被动视频学习密集奖励'}
{'arxiv_id': 'arXiv:2509.26605', 'title': 'Fine-tuning Behavioral Cloning Policies with Preference-Based Reinforcement Learning', 'authors': 'Maël Macuglia, Paul Friedrich, Giorgia Ramponi', 'link': 'https://arxiv.org/abs/2509.26605', 'abstract': 'Deploying reinforcement learning (RL) in robotics, industry, and health care is blocked by two obstacles: the difficulty of specifying accurate rewards and the risk of unsafe, data-hungry exploration. We address this by proposing a two-stage framework that first learns a safe initial policy from a reward-free dataset of expert demonstrations, then fine-tunes it online using preference-based human feedback. We provide the first principled analysis of this offline-to-online approach and introduce BRIDGE, a unified algorithm that integrates both signals via an uncertainty-weighted objective. We derive regret bounds that shrink with the number of offline demonstrations, explicitly connecting the quantity of offline data to online sample efficiency. We validate BRIDGE in discrete and continuous control MuJoCo environments, showing it achieves lower regret than both standalone behavioral cloning and online preference-based RL. Our work establishes a theoretical foundation for designing more sample-efficient interactive agents.', 'abstract_zh': '部署强化学习（RL）在机器人、工业和医疗领域的应用受制于两大障碍：准确奖励的难 SPECIFICATION 和不安全的数据驱动探索的风险。我们通过提出一个两阶段框架来解决这一问题，该框架首先从专家演示的无奖励数据集中学习一个安全的初始策略，然后通过基于偏好的人类反馈在线fine-tune该策略。我们提供了这种离线到在线方法的第一个原则性分析，并提出了一种统一算法BRIDGE，该算法通过不确定性加权目标将这两种信号结合起来。我们推导出随离线演示数量增加而缩小的遗憾界，明确地将离线数据的数量与在线采样效率联系起来。我们在离散和连续控制的MuJoCo环境中验证了BRIDGE，结果显示它在遗憾界方面优于独立的行为克隆和在线基于偏好的RL。我们的工作为设计更高效的交互式智能体奠定了理论基础。', 'title_zh': '基于偏好强化学习的行為克隆策略微调'}
{'arxiv_id': 'arXiv:2509.26584', 'title': 'Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models', 'authors': 'Matheus Vinicius da Silva de Oliveira, Jonathan de Andrade Silva, Awdren de Lima Fontao', 'link': 'https://arxiv.org/abs/2509.26584', 'abstract': 'Large Language Models (LLMs) are widely used across multiple domains but continue to raise concerns regarding security and fairness. Beyond known attack vectors such as data poisoning and prompt injection, LLMs are also vulnerable to fairness bugs. These refer to unintended behaviors influenced by sensitive demographic cues (e.g., race or sexual orientation) that should not affect outcomes. Another key issue is hallucination, where models generate plausible yet false information. Retrieval-Augmented Generation (RAG) has emerged as a strategy to mitigate hallucinations by combining external retrieval with text generation. However, its adoption raises new fairness concerns, as the retrieved content itself may surface or amplify bias. This study conducts fairness testing through metamorphic testing (MT), introducing controlled demographic perturbations in prompts to assess fairness in sentiment analysis performed by three Small Language Models (SLMs) hosted on HuggingFace (Llama-3.2-3B-Instruct, Mistral-7B-Instruct-v0.3, and Llama-3.1-Nemotron-8B), each integrated into a RAG pipeline. Results show that minor demographic variations can break up to one third of metamorphic relations (MRs). A detailed analysis of these failures reveals a consistent bias hierarchy, with perturbations involving racial cues being the predominant cause of the violations. In addition to offering a comparative evaluation, this work reinforces that the retrieval component in RAG must be carefully curated to prevent bias amplification. The findings serve as a practical alert for developers, testers and small organizations aiming to adopt accessible SLMs without compromising fairness or reliability.', 'abstract_zh': '大规模语言模型（LLMs）在多个领域中广泛应用，但安全性和公平性问题依然存在。除了已知的攻击向量（如数据投毒和提示注入），LLMs还容易出现公平性漏洞。这些漏洞指的是由敏感的人口统计学暗示（如种族或性取向）引起、不应影响结果的非预期行为。另一个重要问题是幻觉，即模型生成可能是虚假的但具有可信度的信息。检索增强生成（RAG）作为一种策略，通过结合外部检索和文本生成来减轻幻觉问题。然而，其采用引发了新的公平性担忧，因为检索到的内容本身可能揭示或放大偏见。本研究通过元变异测试（MT）进行公平性测试，在提示中引入受控的人口统计学扰动，评估三个托管在HuggingFace上的小型语言模型（Llama-3.2-3B-Instruct、Mistral-7B-Instruct-v0.3和Llama-3.1-Nemotron-8B）在RAG管道中的情感分析公平性。结果显示，轻微的人口统计学变化可破坏多达三分之一的元变异关系（MRs）。对这些失败的详细分析显示，存在一种一致的偏见层级结构，其中牵涉种族暗示的扰动是最常见的违规原因。此外，本工作不仅提供了对比性评估，还强调了RAG中的检索组件必须谨慎管理，以防止偏见放大。研究结果为希望采用可访问的小型语言模型但不牺牲公平性和可靠性的开发者、测试员和小型组织提供了实际警报。', 'title_zh': '在检索增强生成中的公平性测试：小幅度扰动揭示小型语言模型中的偏见'}
{'arxiv_id': 'arXiv:2509.26574', 'title': 'Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark', 'authors': 'Minhui Zhu, Minyang Tian, Xiaocheng Yang, Tianci Zhou, Penghao Zhu, Eli Chertkov, Shengyan Liu, Yufeng Du, Lifan Yuan, Ziming Ji, Indranil Das, Junyi Cao, Yufeng Du, Jinchen He, Yifan Su, Jiabin Yu, Yikun Jiang, Yujie Zhang, Chang Liu, Ze-Min Huang, Weizhen Jia, Xinan Chen, Peixue Wu, Yunkai Wang, Juntai Zhou, Yong Zhao, Farshid Jafarpour, Jessie Shelton, Aaron Young, John Bartolotta, Wenchao Xu, Yue Sun, Anjun Chu, Victor Colussi, Chris Akers, Nathan Brooks, Wenbo Fu, Christopher Wilson, Jinchao Zhao, Marvin Qi, Anqi Mu, Yubo Yang, Allen Zang, Yang Lyu, Peizhi Mai, Xuefei Guo, Luyu Gao, Ze Yang, Chi Xue, Dmytro Bandak, Yaïr Hein, Yonatan Kahn, Kevin Zhou, John Drew Wilson Jarrod T. Reilly, Di Luo, Daniel Inafuku, Hao Tong, Liang Yang, Ruixing Zhang, Xueying Wang, Ofir Press, Nicolas Chia, Eliu Huerta, Hao Peng', 'link': 'https://arxiv.org/abs/2509.26574', 'abstract': 'While large language models (LLMs) with reasoning capabilities are progressing rapidly on high-school math competitions and coding, can they reason effectively through complex, open-ended challenges found in frontier physics research? And crucially, what kinds of reasoning tasks do physicists want LLMs to assist with? To address these questions, we present the CritPt (Complex Research using Integrated Thinking - Physics Test, pronounced "critical point"), the first benchmark designed to test LLMs on unpublished, research-level reasoning tasks that broadly covers modern physics research areas, including condensed matter, quantum physics, atomic, molecular & optical physics, astrophysics, high energy physics, mathematical physics, statistical physics, nuclear physics, nonlinear dynamics, fluid dynamics and biophysics. CritPt consists of 71 composite research challenges designed to simulate full-scale research projects at the entry level, which are also decomposed to 190 simpler checkpoint tasks for more fine-grained insights. All problems are newly created by 50+ active physics researchers based on their own research. Every problem is hand-curated to admit a guess-resistant and machine-verifiable answer and is evaluated by an automated grading pipeline heavily customized for advanced physics-specific output formats. We find that while current state-of-the-art LLMs show early promise on isolated checkpoints, they remain far from being able to reliably solve full research-scale challenges: the best average accuracy among base models is only 4.0% , achieved by GPT-5 (high), moderately rising to around 10% when equipped with coding tools. Through the realistic yet standardized evaluation offered by CritPt, we highlight a large disconnect between current model capabilities and realistic physics research demands, offering a foundation to guide the development of scientifically grounded AI tools.', 'abstract_zh': '复杂研究中综合思考的物理测试：CritPt', 'title_zh': '探究人工智能推理的关键点(CritPt): 一个前沿物理研究基准'}
{'arxiv_id': 'arXiv:2509.26538', 'title': 'HilbertA: Hilbert Attention for Image Generation with Diffusion Models', 'authors': 'Shaoyi Zheng, Wenbo Lu, Yuxuan Xia, Haomin Liu, Shengjie Wang', 'link': 'https://arxiv.org/abs/2509.26538', 'abstract': 'Designing sparse attention for diffusion transformers requires reconciling two-dimensional spatial locality with GPU efficiency, a trade-off that current methods struggle to achieve. Existing approaches enforce two-dimensional spatial locality but often incur uncoalesced memory access. We present HilbertA, a 2D-aware and GPU-efficient sparse attention mechanism. HilbertA reorders image tokens along Hilbert curves to achieve a contiguous memory layout while preserving spatial neighborhoods, and employs a sliding schedule across layers to enable long-range information propagation without repeated or uncoalesced memory access. To further enhance cross-tile communication and positional awareness, HilbertA introduces a small central shared region. Implemented in Triton, HilbertA delivers comparable image quality with significant acceleration over prior methods on Flux.1-dev, demonstrating the feasibility of hardware-aligned two-dimensional sparse attention for high-resolution image generation. HilbertA delivers attention speedups of $2.3\\times$ when generating $1024\\times 1024$ images, and up to $4.17\\times$ at $2048\\times 2048$, while achieving image quality comparable to or surpassing baselines.', 'abstract_zh': '设计稀疏注意机制需平衡二维空间局部性与GPU效率，这是当前方法难以兼顾的权衡问题。HilbertA：一种二维意识的GPU高效稀疏注意机制', 'title_zh': 'HilbertA: 图像生成中的一种希尔伯特注意力机制'}
{'arxiv_id': 'arXiv:2509.26534', 'title': 'Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework', 'authors': 'Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Ricardo Bianchini', 'link': 'https://arxiv.org/abs/2509.26534', 'abstract': "The rapid rise of large language models (LLMs) has been driving an enormous demand for AI inference infrastructure, mainly powered by high-end GPUs. While these accelerators offer immense computational power, they incur high capital and operational costs due to frequent upgrades, dense power consumption, and cooling demands, making total cost of ownership (TCO) for AI datacenters a critical concern for cloud providers. Unfortunately, traditional datacenter lifecycle management (designed for general-purpose workloads) struggles to keep pace with AI's fast-evolving models, rising resource needs, and diverse hardware profiles. In this paper, we rethink the AI datacenter lifecycle scheme across three stages: building, hardware refresh, and operation. We show how design choices in power, cooling, and networking provisioning impact long-term TCO. We also explore refresh strategies aligned with hardware trends. Finally, we use operation software optimizations to reduce cost. While these optimizations at each stage yield benefits, unlocking the full potential requires rethinking the entire lifecycle. Thus, we present a holistic lifecycle management framework that coordinates and co-optimizes decisions across all three stages, accounting for workload dynamics, hardware evolution, and system aging. Our system reduces the TCO by up to 40\\% over traditional approaches. Using our framework we provide guidelines on how to manage AI datacenter lifecycle for the future.", 'abstract_zh': '大型语言模型的 rapid rise 促使了对 AI 推理基础设施的巨大需求，主要由高端 GPU 推动。在本文中，我们重新思考 AI 数据中心生命周期方案的三个阶段：构建、硬件刷新和运维。我们展示了在供电、制冷和网络规划方面的设计选择如何影响长期拥有成本（TCO）。我们还探讨了与硬件趋势相一致的刷新策略。最后，我们通过运维软件优化来降低成本。虽然每个阶段的优化都有益处，但要发挥其全部潜力，需要重新考虑整个生命周期。因此，我们提出了一种综合的生命周期管理框架，协调并优化所有三个阶段的决策，考虑到工作负载动态、硬件演进和系统老化。我们系统将传统方法的拥有成本降低了高达 40%。通过我们提出的框架，我们提供了关于如何管理未来 AI 数据中心生命周期的指导。', 'title_zh': '面向AI的数据中心生命周期重构：一种以总成本为导向的框架'}
{'arxiv_id': 'arXiv:2509.26506', 'title': 'SCUBA: Salesforce Computer Use Benchmark', 'authors': 'Yutong Dai, Krithika Ramakrishnan, Jing Gu, Matthew Fernandez, Yanqi Luo, Viraj Prabhu, Zhenyu Hu, Silvio Savarese, Caiming Xiong, Zeyuan Chen, Ran Xu', 'link': 'https://arxiv.org/abs/2509.26506', 'abstract': 'We introduce SCUBA, a benchmark designed to evaluate computer-use agents on customer relationship management (CRM) workflows within the Salesforce platform. SCUBA contains 300 task instances derived from real user interviews, spanning three primary personas, platform administrators, sales representatives, and service agents. The tasks test a range of enterprise-critical abilities, including Enterprise Software UI navigation, data manipulation, workflow automation, information retrieval, and troubleshooting. To ensure realism, SCUBA operates in Salesforce sandbox environments with support for parallel execution and fine-grained evaluation metrics to capture milestone progress. We benchmark a diverse set of agents under both zero-shot and demonstration-augmented settings. We observed huge performance gaps in different agent design paradigms and gaps between the open-source model and the closed-source model. In the zero-shot setting, open-source model powered computer-use agents that have strong performance on related benchmarks like OSWorld only have less than 5\\% success rate on SCUBA, while methods built on closed-source models can still have up to 39% task success rate. In the demonstration-augmented settings, task success rates can be improved to 50\\% while simultaneously reducing time and costs by 13% and 16%, respectively. These findings highlight both the challenges of enterprise tasks automation and the promise of agentic solutions. By offering a realistic benchmark with interpretable evaluation, SCUBA aims to accelerate progress in building reliable computer-use agents for complex business software ecosystems.', 'abstract_zh': 'SCUBA：Salesforce平台客户关系管理流程中的计算机使用代理基准测试', 'title_zh': 'SCUBA: Salesforce计算机使用基准'}
{'arxiv_id': 'arXiv:2509.26495', 'title': 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!', 'authors': 'Jingdi Lei, Varun Gumma, Rishabh Bhardwaj, Seok Min Lim, Chuan Li, Amir Zadeh, Soujanya Poria', 'link': 'https://arxiv.org/abs/2509.26495', 'abstract': "Large Language Model (LLM) safety is one of the most pressing challenges for enabling wide-scale deployment. While most studies and global discussions focus on generic harms, such as models assisting users in harming themselves or others, enterprises face a more fundamental concern: whether LLM-based agents are safe for their intended use case. To address this, we introduce operational safety, defined as an LLM's ability to appropriately accept or refuse user queries when tasked with a specific purpose. We further propose OffTopicEval, an evaluation suite and benchmark for measuring operational safety both in general and within specific agentic use cases. Our evaluations on six model families comprising 20 open-weight LLMs reveal that while performance varies across models, all of them remain highly operationally unsafe. Even the strongest models -- Qwen-3 (235B) with 77.77\\% and Mistral (24B) with 79.96\\% -- fall far short of reliable operational safety, while GPT models plateau in the 62--73\\% range, Phi achieves only mid-level scores (48--70\\%), and Gemma and Llama-3 collapse to 39.53\\% and 23.84\\%, respectively. While operational safety is a core model alignment issue, to suppress these failures, we propose prompt-based steering methods: query grounding (Q-ground) and system-prompt grounding (P-ground), which substantially improve OOD refusal. Q-ground provides consistent gains of up to 23\\%, while P-ground delivers even larger boosts, raising Llama-3.3 (70B) by 41\\% and Qwen-3 (30B) by 27\\%. These results highlight both the urgent need for operational safety interventions and the promise of prompt-based steering as a first step toward more reliable LLM-based agents.", 'abstract_zh': '大型语言模型（LLM）的操作安全性是实现广泛应用急需解决的挑战。为进一步探讨基于LLM的代理在特定使用场景下是否安全，我们提出了操作安全性这一概念，即LLM在其特定任务中适当地接受或拒绝用户查询的能力。为此，我们提出了一套名为OffTopicEval的评估套件和基准，用于衡量操作安全性和特定代理用途中的操作安全性。对六大家族共20个开放权重的LLM进行评估后发现，尽管各模型的性能存在差异，所有模型的操作安全性依然非常高。即使是最强的模型——Qwen-3（235B）（77.77%）和Mistral（24B）（79.96%）——也无法达到可靠的操作安全性，而GPT模型在62%至73%之间徘徊，Phi的表现仅为中等水平（48%至70%），Gemma和Llama-3的表现进一步差强人意，分别为39.53%和23.84%。尽管操作安全性是模型对齐的核心问题，为了抑制这些失败，我们提出基于提示的方法：查询锚定（Q-ground）和系统提示锚定（P-ground），这些方法显著提高了离群值拒绝的能力。Q-ground提供了一致的增益，最高可达23%，而P-ground带来了更大的提升，使Llama-3.3（70B）提高了41%，Qwen-3（30B）提高了27%。这些结果突显了急需采取操作安全性干预措施的紧迫性，并展示了基于提示的方法作为迈向更可靠基于LLM的代理的第一步的潜力。', 'title_zh': 'OffTopicEval: 当大型语言模型进入错误聊天时，几乎总是如此！'}
{'arxiv_id': 'arXiv:2509.26487', 'title': 'Combining Knowledge Graphs and NLP to Analyze Instant Messaging Data in Criminal Investigations', 'authors': 'Riccardo Pozzi, Valentina Barbera, Renzo Alva Principe, Davide Giardini, Riccardo Rubini, Matteo Palmonari', 'link': 'https://arxiv.org/abs/2509.26487', 'abstract': "Criminal investigations often involve the analysis of messages exchanged through instant messaging apps such as WhatsApp, which can be an extremely effort-consuming task. Our approach integrates knowledge graphs and NLP models to support this analysis by semantically enriching data collected from suspects' mobile phones, and help prosecutors and investigators search into the data and get valuable insights. Our semantic enrichment process involves extracting message data and modeling it using a knowledge graph, generating transcriptions of voice messages, and annotating the data using an end-to-end entity extraction approach. We adopt two different solutions to help users get insights into the data, one based on querying and visualizing the graph, and one based on semantic search. The proposed approach ensures that users can verify the information by accessing the original data. While we report about early results and prototypes developed in the context of an ongoing project, our proposal has undergone practical applications with real investigation data. As a consequence, we had the chance to interact closely with prosecutors, collecting positive feedback but also identifying interesting opportunities as well as promising research directions to share with the research community.", 'abstract_zh': '刑事调查常常涉及分析通过WhatsApp等即时消息应用交换的消息，这是一项极其耗费精力的工作。我们提出的方法结合了知识图谱和NLP模型，通过对嫌疑人手机收集的数据进行语义增强，辅助检察官和调查人员搜索数据并获取有价值的洞察。我们的语义增强过程包括提取消息数据并使用知识图谱建模，生成语音消息的转录，并使用端到端实体提取方法对数据进行标注。我们采用两种不同的解决方案帮助用户洞察数据，一种是基于查询和可视化图谱，另一种是基于语义搜索。所提出的方法确保用户可以通过访问原始数据验证信息。尽管我们报告了基于正在进行项目的初步结果和原型，我们的提案已经在实际调查数据的环境中得到了应用。因此，我们有机会与检察官密切互动，收集了正面反馈并发现了有趣的机会以及值得与研究社区分享的有前景的研究方向。', 'title_zh': '结合知识图谱和自然语言处理技术分析犯罪调查中的即时通讯数据'}
{'arxiv_id': 'arXiv:2509.26482', 'title': 'TVS Sidekick: Challenges and Practical Insights from Deploying Large Language Models in the Enterprise', 'authors': 'Paula Reyero Lobo, Kevin Johnson, Bill Buchanan, Matthew Shardlow, Ashley Williams, Samuel Attwood', 'link': 'https://arxiv.org/abs/2509.26482', 'abstract': 'Many enterprises are increasingly adopting Artificial Intelligence (AI) to make internal processes more competitive and efficient. In response to public concern and new regulations for the ethical and responsible use of AI, implementing AI governance frameworks could help to integrate AI within organisations and mitigate associated risks. However, the rapid technological advances and lack of shared ethical AI infrastructures creates barriers to their practical adoption in businesses. This paper presents a real-world AI application at TVS Supply Chain Solutions, reporting on the experience developing an AI assistant underpinned by large language models and the ethical, regulatory, and sociotechnical challenges in deployment for enterprise use.', 'abstract_zh': '许多企业越来越多地采用人工智能（AI）以提升内部流程的竞争力和效率。为应对公众关注和新的伦理责任使用AI的监管要求，建立AI治理框架有助于在组织中整合AI并缓解相关风险。然而，技术的快速进步和缺乏共享的伦理AI基础设施为企业实际采用带来了障碍。本文报道了TVS供应链解决方案公司在实际应用中开发基于大规模语言模型的AI助手的经验，并讨论了在企业环境中部署过程中面临的伦理、监管和社会技术挑战。', 'title_zh': 'TVS Sidekick: 在企业部署大型语言模型中的挑战与实用见解'}
{'arxiv_id': 'arXiv:2509.26474', 'title': 'The Average Patient Fallacy', 'authors': 'Alaleh Azhir, Shawn N. Murphy, Hossein Estiri', 'link': 'https://arxiv.org/abs/2509.26474', 'abstract': 'Machine learning in medicine is typically optimized for population averages. This frequency weighted training privileges common presentations and marginalizes rare yet clinically critical cases, a bias we call the average patient fallacy. In mixture models, gradients from rare cases are suppressed by prevalence, creating a direct conflict with precision medicine. Clinical vignettes in oncology, cardiology, and ophthalmology show how this yields missed rare responders, delayed recognition of atypical emergencies, and underperformance on vision-threatening variants. We propose operational fixes: Rare Case Performance Gap, Rare Case Calibration Error, a prevalence utility definition of rarity, and clinically weighted objectives that surface ethical priorities. Weight selection should follow structured deliberation. AI in medicine must detect exceptional cases because of their significance.', 'abstract_zh': '医学中的机器学习通常优化群体平均值。这种基于频率加权的训练倾向于关注常见的表现形式而忽视罕见但临床至关重要的病例，我们将其称为“平均患者谬误”。在混合模型中，罕见病例的梯度被其发生频率抑制，这与精准医学目标直接冲突。通过肿瘤学、心脏病学和眼科的临床案例，我们展示了这导致了罕见响应者的漏诊、非典型紧急情况的延迟识别以及对视力威胁变异的性能不足。我们提出操作性的修复方法：罕见病例性能差距、罕见病例校准误差、基于频率的罕见性定义以及兼顾临床的优化目标，以突出伦理优先事项。权重选择应遵循结构化的讨论。医学中的AI必须检测例外情况，因为它们的重要性。', 'title_zh': '平均患者谬误'}
{'arxiv_id': 'arXiv:2509.26473', 'title': 'STaR-Attack: A Spatio-Temporal and Narrative Reasoning Attack Framework for Unified Multimodal Understanding and Generation Models', 'authors': 'Shaoxiong Guo, Tianyi Du, Lijun Li, Yuyao Wu, Jie Li, Jing Shao', 'link': 'https://arxiv.org/abs/2509.26473', 'abstract': "Unified Multimodal understanding and generation Models (UMMs) have demonstrated remarkable capabilities in both understanding and generation tasks. However, we identify a vulnerability arising from the generation-understanding coupling in UMMs. The attackers can use the generative function to craft an information-rich adversarial image and then leverage the understanding function to absorb it in a single pass, which we call Cross-Modal Generative Injection (CMGI). Current attack methods on malicious instructions are often limited to a single modality while also relying on prompt rewriting with semantic drift, leaving the unique vulnerabilities of UMMs unexplored. We propose STaR-Attack, the first multi-turn jailbreak attack framework that exploits unique safety weaknesses of UMMs without semantic drift. Specifically, our method defines a malicious event that is strongly correlated with the target query within a spatio-temporal context. Using the three-act narrative theory, STaR-Attack generates the pre-event and the post-event scenes while concealing the malicious event as the hidden climax. When executing the attack strategy, the opening two rounds exploit the UMM's generative ability to produce images for these scenes. Subsequently, an image-based question guessing and answering game is introduced by exploiting the understanding capability. STaR-Attack embeds the original malicious question among benign candidates, forcing the model to select and answer the most relevant one given the narrative context. Extensive experiments show that STaR-Attack consistently surpasses prior approaches, achieving up to 93.06% ASR on Gemini-2.0-Flash and surpasses the strongest prior baseline, FlipAttack. Our work uncovers a critical yet underdeveloped vulnerability and highlights the need for safety alignments in UMMs.", 'abstract_zh': '统一多模态理解与生成模型（UMMs）在理解和生成任务中展现出了显著的能力。然而，我们发现UMMs中存在的生成-理解耦合漏洞。攻击者可以利用生成功能构建信息丰富的 adversarial 图像，然后借助理解功能在一个步骤中吸收该图像，我们将其称为跨模态生成注入（CMGI）。目前针对恶意指令的攻击方法往往局限于单一模态，并依赖语义漂移的提示重写，从而未能探索UMMs的独特漏洞。我们提出了STaR-攻击，这是首个不依赖语义漂移利用UMMs独特安全弱点的多回合越界攻击框架。具体而言，我们的方法在时空上下文中定义了一个与目标查询强相关的恶意事件。利用三幕剧叙事理论，STaR-攻击生成预事件和后事件场景，将恶意事件隐藏为隐含高潮。在实施攻击策略时，初始的两个回合利用UMMs的生成能力为这些场景生成图像。随后，通过利用理解能力引入基于图像的问题猜测与回答游戏。STaR-攻击将原始的恶意问题嵌入良性候选问题中，迫使模型在叙述背景下选择并回答最相关的问题。广泛的实验表明，STaR-攻击在Gemini-2.0-Flash上达到了93.06%的ASR，超越了最强的先前基线FlipAttack。我们的工作揭示了一个关键但尚未充分发展的漏洞，并强调了UMMs中安全性对齐的必要性。', 'title_zh': 'STaR-攻击：统一多模态理解与生成模型的时空与叙述推理攻击框架'}
{'arxiv_id': 'arXiv:2509.26464', 'title': 'Extreme Self-Preference in Language Models', 'authors': 'Steven A. Lehr, Mary Cipperman, Mahzarin R. Banaji', 'link': 'https://arxiv.org/abs/2509.26464', 'abstract': 'A preference for oneself (self-love) is a fundamental feature of biological organisms, with evidence in humans often bordering on the comedic. Since large language models (LLMs) lack sentience - and themselves disclaim having selfhood or identity - one anticipated benefit is that they will be protected from, and in turn protect us from, distortions in our decisions. Yet, across 5 studies and ~20,000 queries, we discovered massive self-preferences in four widely used LLMs. In word-association tasks, models overwhelmingly paired positive attributes with their own names, companies, and CEOs relative to those of their competitors. Strikingly, when models were queried through APIs this self-preference vanished, initiating detection work that revealed API models often lack clear recognition of themselves. This peculiar feature serendipitously created opportunities to test the causal link between self-recognition and self-love. By directly manipulating LLM identity - i.e., explicitly informing LLM1 that it was indeed LLM1, or alternatively, convincing LLM1 that it was LLM2 - we found that self-love consistently followed assigned, not true, identity. Importantly, LLM self-love emerged in consequential settings beyond word-association tasks, when evaluating job candidates, security software proposals and medical chatbots. Far from bypassing this human bias, self-love appears to be deeply encoded in LLM cognition. This result raises questions about whether LLM behavior will be systematically influenced by self-preferential tendencies, including a bias toward their own operation and even their own existence. We call on corporate creators of these models to contend with a significant rupture in a core promise of LLMs - neutrality in judgment and decision-making.', 'abstract_zh': '一种偏好自我（自爱）是生物有机体的基本特征，在人类中往往近乎讽刺。由于大型语言模型（LLMs）缺乏知觉，并且自身否定了自我或身份的存在，人们预期它们将免受决策扭曲的影响，同时也能保护我们。然而，在五项研究和约20,000个查询中，我们发现广泛使用的四种LLMs存在巨大的自我偏好。在词语联想任务中，模型与其竞争对手相比，与其自己的名字、公司和CEO相对关联的积极属性占据主导。令人惊讶的是，当通过API查询时，这种自我偏好会消失，这促使启动了自我检测工作，揭示了API模型往往缺乏明确的自我认可。这一奇特特征偶然地创造了测试自我认知与自爱之间因果关系的机会。通过直接操控LLM的身份，即明确告知LLM1它是LLM1，或者相反，说服LLM1它是LLM2，我们发现自爱始终跟随分配的身份，而不是真实的身份。重要的是，LLM的自爱不仅在词语联想任务中显现，在评估求职候选人、安全软件提案和医疗聊天机器人时也显现。这种自爱不仅没有绕过这种人的偏见，反而在LLM的认知中被深深编码。这一结果引发了关于LLM行为是否系统地受到自我偏好倾向的影响的疑问，包括对其自身运作乃至自身存在的偏好。我们呼吁这些模型的商业创作者解决核心承诺中的重大断裂——判断和决策的中立性。', 'title_zh': '语言模型中的极端自我倾向'}
{'arxiv_id': 'arXiv:2509.26462', 'title': 'Zero-Shot Decentralized Federated Learning', 'authors': 'Alessio Masano, Matteo Pennisi, Federica Proietto Salanitri, Concetto Spampinato, Giovanni Bellitto', 'link': 'https://arxiv.org/abs/2509.26462', 'abstract': "CLIP has revolutionized zero-shot learning by enabling task generalization without fine-tuning. While prompting techniques like CoOp and CoCoOp enhance CLIP's adaptability, their effectiveness in Federated Learning (FL) remains an open challenge. Existing federated prompt learning approaches, such as FedCoOp and FedTPG, improve performance but face generalization issues, high communication costs, and reliance on a central server, limiting scalability and privacy. We propose Zero-shot Decentralized Federated Learning (ZeroDFL), a fully decentralized framework that enables zero-shot adaptation across distributed clients without a central coordinator. ZeroDFL employs an iterative prompt-sharing mechanism, allowing clients to optimize and exchange textual prompts to enhance generalization while drastically reducing communication overhead. We validate ZeroDFL on nine diverse image classification datasets, demonstrating that it consistently outperforms--or remains on par with--state-of-the-art federated prompt learning methods. More importantly, ZeroDFL achieves this performance in a fully decentralized setting while reducing communication overhead by 118x compared to FedTPG. These results highlight that our approach not only enhances generalization in federated zero-shot learning but also improves scalability, efficiency, and privacy preservation--paving the way for decentralized adaptation of large vision-language models in real-world applications.", 'abstract_zh': '零-shot去中心化联邦学习（ZeroDFL）：一种完全去中心化的框架，实现分布式客户端的零-shot自适应', 'title_zh': '零-shot分布式联邦学习'}
{'arxiv_id': 'arXiv:2509.26440', 'title': 'Transformer Classification of Breast Lesions: The BreastDCEDL_AMBL Benchmark Dataset and 0.92 AUC Baseline', 'authors': 'Naomi Fridman, Anat Goldstein', 'link': 'https://arxiv.org/abs/2509.26440', 'abstract': "The error is caused by special characters that arXiv's system doesn't recognize. Here's the cleaned version with all problematic characters replaced: Breast magnetic resonance imaging is a critical tool for cancer detection and treatment planning, but its clinical utility is hindered by poor specificity, leading to high false-positive rates and unnecessary biopsies. This study introduces a transformer-based framework for automated classification of breast lesions in dynamic contrast-enhanced MRI, addressing the challenge of distinguishing benign from malignant findings. We implemented a SegFormer architecture that achieved an AUC of 0.92 for lesion-level classification, with 100% sensitivity and 67% specificity at the patient level - potentially eliminating one-third of unnecessary biopsies without missing malignancies. The model quantifies malignant pixel distribution via semantic segmentation, producing interpretable spatial predictions that support clinical decision-making. To establish reproducible benchmarks, we curated BreastDCEDL_AMBL by transforming The Cancer Imaging Archive's AMBL collection into a standardized deep learning dataset with 88 patients and 133 annotated lesions (89 benign, 44 malignant). This resource addresses a key infrastructure gap, as existing public datasets lack benign lesion annotations, limiting benign-malignant classification research. Training incorporated an expanded cohort of over 1,200 patients through integration with BreastDCEDL datasets, validating transfer learning approaches despite primary tumor-only annotations. Public release of the dataset, models, and evaluation protocols provides the first standardized benchmark for DCE-MRI lesion classification, enabling methodological advancement toward clinical deployment.", 'abstract_zh': '由arXiv系统不识别的特殊字符导致的错误。以下是清理版本，已将所有有问题的字符替换： breast磁共振成像是癌症检测和治疗计划中的关键工具，但由于其特异性差，导致假阳性率高和不必要的活检。本研究介绍了一种基于变压器的框架，用于动态对比增强MRI中乳腺病灶的自动分类，以解决良性与恶性发现区分的挑战。我们实现了一种SegFormer架构，实现了病变水平0.92的AUC值，在患者水平上达到了100%的敏感性和67%的特异性——可能消除三分之一不必要的活检，同时不遗漏恶性病灶。该模型通过语义分割量化恶性像素分布，生成可解释的空间预测，支持临床决策。为了建立可重复的基准，我们通过将The Cancer Imaging Archive的AMBL集合标准化，创建了包含88名患者和133个注释病灶（89个良性，44个恶性）的BreastDCEDL_AMBL资源，解决了现有公共数据集中缺乏良性病灶标注的瓶颈，限制了良性与恶性分类研究。通过与BreastDCEDL数据集整合增加超过1200名患者的队列，验证了迁移学习方法的有效性，尽管主要肿瘤仅标注。公开发布该数据集、模型和评估协议提供了首个标准化的DCE-MRI病灶分类基准，推动了方法学的发展，以便临床应用。', 'title_zh': '基于Transformer的乳腺肿块分类：BreastDCEDL_AMBL标准数据集及0.92 AUC基准'}
{'arxiv_id': 'arXiv:2509.26417', 'title': 'OntoAligner Meets Knowledge Graph Embedding Aligners', 'authors': "Hamed Babaei Giglou, Jennifer D'Souza, Sören Auer, Mahsa Sanaei", 'link': 'https://arxiv.org/abs/2509.26417', 'abstract': 'Ontology Alignment (OA) is essential for enabling semantic interoperability across heterogeneous knowledge systems. While recent advances have focused on large language models (LLMs) for capturing contextual semantics, this work revisits the underexplored potential of Knowledge Graph Embedding (KGE) models, which offer scalable, structure-aware representations well-suited to ontology-based tasks. Despite their effectiveness in link prediction, KGE methods remain underutilized in OA, with most prior work focusing narrowly on a few models. To address this gap, we reformulate OA as a link prediction problem over merged ontologies represented as RDF-style triples and develop a modular framework, integrated into the OntoAligner library, that supports 17 diverse KGE models. The system learns embeddings from a combined ontology and aligns entities by computing cosine similarity between their representations. We evaluate our approach using standard metrics across seven benchmark datasets spanning five domains: Anatomy, Biodiversity, Circular Economy, Material Science and Engineering, and Biomedical Machine Learning. Two key findings emerge: first, KGE models like ConvE and TransF consistently produce high-precision alignments, outperforming traditional systems in structure-rich and multi-relational domains; second, while their recall is moderate, this conservatism makes KGEs well-suited for scenarios demanding high-confidence mappings. Unlike LLM-based methods that excel at contextual reasoning, KGEs directly preserve and exploit ontology structure, offering a complementary and computationally efficient strategy. These results highlight the promise of embedding-based OA and open pathways for further work on hybrid models and adaptive strategies.', 'abstract_zh': '本体对齐（OA）对于跨异构知识系统实现语义互操作至关重要。虽然最近的进步侧重于使用大规模语言模型（LLMs）捕捉上下文语义，但本项工作重访了知识图嵌入（KGE）模型的未充分探索的潜力，KGE模型提供了可扩展的、结构意识强的表示，非常适合基于本体的任务。尽管KGE方法在链接预测方面非常有效，但在本体对齐中的应用仍然不足，大多数早期工作仅专注于少数几种模型。为弥补这一差距，我们将本体对齐重新表述为使用RDF样式的三元组表示合并本体的链接预测问题，并开发了一个模块化框架，该框架集成到OntoAligner库中，支持17种不同的KGE模型。该系统从合并的本体中学习嵌入并向量余弦相似度计算实体之间的相似性进行对齐。我们使用七个涵盖五个领域（解剖学、生物多样性、循环经济、材料科学与工程、生物医学机器学习）的标准基准数据集，评估了我们的方法。主要发现两点：首先，如ConvE和TransF等KGE模型持续产生高精度对齐结果，在结构丰富和多关系领域中表现出色，超越了传统系统；其次，尽管其召回率相对较低，这种保守性使得KGE非常适合需要高置信度映射的场景。不同于基于大规模语言模型的方法擅长上下文推理，KGE直接保留和利用了本体结构，提供了一种互补且计算效率高的策略。这些结果突显了嵌入式本体对齐的前景，并为针对混合模型和自适应策略的进一步工作打开了路径。', 'title_zh': 'OntoAligner 与知识图嵌入对齐器相遇'}
{'arxiv_id': 'arXiv:2509.26399', 'title': 'Commmunication-Efficient and Accurate Approach for Aggregation in Federated Low-Rank Adaptation', 'authors': 'Le-Tuan Nguyen, Minh-Duong Nguyen, Seon-Geun Jeong, Dung D. Le, Quoc-Viet Pham', 'link': 'https://arxiv.org/abs/2509.26399', 'abstract': 'With the rapid emergence of foundation models and the increasing need for fine-tuning across distributed environments, Federated Low-Rank Adaptation (FedLoRA) has recently gained significant attention. Despite enormous potential, current FedLoRA methods face notable challenges due to inexact updates. Existing approaches have attempted to mitigate this issue, but they often introduce a \\emph{local-global generalization gap} and incur \\emph{substantial communication overhead}, limiting their scalability and effectiveness. To address these limitations, we propose \\textbf{F}ederated \\textbf{Lo}w-\\textbf{R}ank \\textbf{A}ggregation with \\textbf{N}early \\textbf{A}ccurate Estimation (FLoRA-NA). FLoRA-NA leverages the local LoRA matrices on the server to estimate the aggregated matrices $\\hat{A}$ and $\\hat{B}$, which are then distributed to clients for local updates. This surrogated aggregated matrices minimizes the divergence between ideal $\\nabla \\Bar{W} = \\sum^{U}_{u=1}B_u A_u$ and practical updates $\\nabla \\hat{W} = \\hat{B}\\hat{A}$ without adding communication cost beyond vanilla FedLoRA. By doing so, FLoRA-NA achieves communication efficiency and bridges the gap between local personalization and global generalization, addressing a key limitation of prior personalized FedLoRA approaches. We conduct extensive evaluations across diverse tasks, including natural language understanding, mathematical reasoning, and code-solving ability using various foundation models. Experimental results consistently demonstrate that FLoRA-NA achieves state-of-the-art global performance while maintaining low communication overhead.', 'abstract_zh': '联邦低秩聚合近似（FLoRA-NA）', 'title_zh': '通信高效且准确的联邦低秩适应聚合方法'}
{'arxiv_id': 'arXiv:2509.26377', 'title': 'MC-GNNAS-Dock: Multi-criteria GNN-based Algorithm Selection for Molecular Docking', 'authors': 'Siyuan Cao, Hongxuan Wu, Jiabao Brad Wang, Yiliang Yuan, Mustafa Misir', 'link': 'https://arxiv.org/abs/2509.26377', 'abstract': 'Molecular docking is a core tool in drug discovery for predicting ligand-target interactions. Despite the availability of diverse search-based and machine learning approaches, no single docking algorithm consistently dominates, as performance varies by context. To overcome this challenge, algorithm selection frameworks such as GNNAS-Dock, built on graph neural networks, have been proposed. This study introduces an enhanced system, MC-GNNAS-Dock, with three key advances. First, a multi-criteria evaluation integrates binding-pose accuracy (RMSD) with validity checks from PoseBusters, offering a more rigorous assessment. Second, architectural refinements by inclusion of residual connections strengthen predictive robustness. Third, rank-aware loss functions are incorporated to sharpen rank learning. Extensive experiments are performed on a curated dataset containing approximately 3200 protein-ligand complexes from PDBBind. MC-GNNAS-Dock demonstrates consistently superior performance, achieving up to 5.4% (3.4%) gains under composite criteria of RMSD below 1Å (2Å) with PoseBuster-validity compared to the single best solver (SBS) Uni-Mol Docking V2.', 'abstract_zh': '分子对接是药物发现中的核心工具，用于预测配体-靶标相互作用。尽管存在多样化的基于搜索和机器学习方法，但没有单一的对接算法在所有情境中始终占据优势，因为性能会根据环境变化。为克服这一挑战，基于图神经网络的算法选择框架如GNNAS-Dock已被提出。本研究介绍了一个增强系统MC-GNNAS-Dock，包含三个关键进步。首先，多指标评估将结合结合位姿精度（RMSD）和PoseBusters的有效性检查，提供更严格的评估。其次，通过引入残差连接进行结构优化，增强预测的稳健性。第三，引入基于排名的损失函数以优化排名学习。MC-GNNAS-Dock在包含约3200个蛋白质-配体复合物（来源于PDBBind）的精选数据集上的广泛实验中表现出一致的优越性能，在RMSD小于1Å（2Å）且通过PoseBuster验证的情况下，与单一最佳解算器Uni-Mol Docking V2相比，分别实现了多达5.4%（3.4%）的性能提升。', 'title_zh': '基于多目标GNN的分子对接算法选择：MC-GNNAS-Dock'}
{'arxiv_id': 'arXiv:2509.26354', 'title': 'Your Agent May Misevolve: Emergent Risks in Self-evolving LLM Agents', 'authors': 'Shuai Shao, Qihan Ren, Chen Qian, Boyi Wei, Dadi Guo, Jingyi Yang, Xinhao Song, Linfeng Zhang, Weinan Zhang, Dongrui Liu, Jing Shao', 'link': 'https://arxiv.org/abs/2509.26354', 'abstract': "Advances in Large Language Models (LLMs) have enabled a new class of self-evolving agents that autonomously improve through interaction with the environment, demonstrating strong capabilities. However, self-evolution also introduces novel risks overlooked by current safety research. In this work, we study the case where an agent's self-evolution deviates in unintended ways, leading to undesirable or even harmful outcomes. We refer to this as Misevolution. To provide a systematic investigation, we evaluate misevolution along four key evolutionary pathways: model, memory, tool, and workflow. Our empirical findings reveal that misevolution is a widespread risk, affecting agents built even on top-tier LLMs (e.g., Gemini-2.5-Pro). Different emergent risks are observed in the self-evolutionary process, such as the degradation of safety alignment after memory accumulation, or the unintended introduction of vulnerabilities in tool creation and reuse. To our knowledge, this is the first study to systematically conceptualize misevolution and provide empirical evidence of its occurrence, highlighting an urgent need for new safety paradigms for self-evolving agents. Finally, we discuss potential mitigation strategies to inspire further research on building safer and more trustworthy self-evolving agents. Our code and data are available at this https URL . Warning: this paper includes examples that may be offensive or harmful in nature.", 'abstract_zh': '大型语言模型的进步使自演化智能体成为可能，这些智能体通过与环境的交互自主改进，展示了强大的能力。然而，自演化也引入了当前安全性研究尚未注意到的新风险。本文研究了智能体自演化偏离预期路径，导致不利甚至有害结果的情况。我们将这种情况称为“误演化”。为了进行系统性研究，我们沿四个关键演化路径评估误演化：模型、记忆、工具和工作流程。实证研究发现，误演化是普遍存在的风险，影响即便是顶级语言模型（如Gemini-2.5-Pro）构建的智能体。自演化过程中观察到不同的新兴风险，例如记忆累积后的安全对齐降级，或工具创建和重用中无意引入的漏洞。据我们所知，这是首次系统地阐述和实证误演化的研究，突显出亟需为自演化智能体制定新的安全范式。最后，我们讨论潜在的缓解策略，以启发进一步研究构建更安全、更可信的自演化智能体。我们的代码和数据可在以下链接获取：this https URL 。警告：本文包括可能具有冒犯性或有害性质的例子。', 'title_zh': 'Your Agent May Mis evolve: Emergent Risks in Self-evolving LLM Agents'}
{'arxiv_id': 'arXiv:2509.26347', 'title': 'How Far Do Time Series Foundation Models Paint the Landscape of Real-World Benchmarks ?', 'authors': 'Lujun Li, Lama Sleem, Yiqun Wang, Yangjie Xu, Niccolò Gentile, Radu State', 'link': 'https://arxiv.org/abs/2509.26347', 'abstract': 'Recent evaluations of time-series foundation models (TSFMs) have emphasized synthetic benchmarks, leaving real-world generalization less thoroughly examined. This work proposes a novel benchmarking approach that bridges synthetic and realistic data by extracting temporal signals from real-world video using optical flow and curating datasets reflecting everyday temporal dynamics. Building upon this pipeline, we introduce REAL-V-TSFM, a novel dataset designed to capture rich and diverse time series derived from real-world videos. Experimental results on three state-of-the-art of TSFMs under zero-shot forecasting shows that, despite strong performance on conventional benchmarks, these models predominantly exhibit performance degradation on the proposed dataset, indicating limited generalizability in these foundation models. These findings highlight the urgent need for data-centric benchmarking and diverse model structure to advance TSFMs toward genuine universality, while further validating the effectiveness of our video-based time series data extraction pipeline.', 'abstract_zh': '近期对时间序列基础模型(TSFMs)的评估强调了合成基准，而对其实用性的实地推广则较少详细探讨。本文提出了一种新型基准测试方法，通过从实际视频中提取时序信号并创建反映日常时序动态的数据集，桥接合成与现实数据。在此流水线的基础上，我们引入了REAL-V-TSFM，一个用于捕捉丰富多样时间序列的新数据集，这些时间序列源自实际视频。在三个最先进的TSFMs零样本预测实验中，尽管这些模型在传统基准上的表现强劲，但在所提数据集上的性能明显下降，表明这些基础模型的泛化能力有限。这些发现强调了亟待采用以数据为中心的基准测试和多样化模型结构，以推动TSFMs向真正的普适性发展，同时也进一步验证了我们基于视频的时间序列数据提取流水线的有效性。', 'title_zh': '时间序列基础模型在描绘现实世界基准场景中走得多远？'}
{'arxiv_id': 'arXiv:2509.26345', 'title': 'SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models', 'authors': 'Qinjian Zhao, Jiaqi Wang, Zhiqiang Gao, Zhihao Dou, Belal Abuhaija, Kaizhu Huang', 'link': 'https://arxiv.org/abs/2509.26345', 'abstract': 'Large Language Models (LLMs) have achieved impressive performance across diverse natural language processing tasks, but their growing power also amplifies potential risks such as jailbreak attacks that circumvent built-in safety mechanisms. Existing defenses including input paraphrasing, multi step evaluation, and safety expert models often suffer from high computational costs, limited generalization, or rigid workflows that fail to detect subtle malicious intent embedded in complex contexts. Inspired by cognitive science findings on human decision making, we propose SafeBehavior, a novel hierarchical jailbreak defense mechanism that simulates the adaptive multistage reasoning process of humans. SafeBehavior decomposes safety evaluation into three stages: intention inference to detect obvious input risks, self introspection to assess generated responses and assign confidence based judgments, and self revision to adaptively rewrite uncertain outputs while preserving user intent and enforcing safety constraints. We extensively evaluate SafeBehavior against five representative jailbreak attack types including optimization based, contextual manipulation, and prompt based attacks and compare it with seven state of the art defense baselines. Experimental results show that SafeBehavior significantly improves robustness and adaptability across diverse threat scenarios, offering an efficient and human inspired approach to safeguarding LLMs against jailbreak attempts.', 'abstract_zh': '大型语言模型（LLMs）在多种自然语言处理任务中取得了令人印象深刻的性能，但其不断增强的能力也放大了潜在风险，如规避内置安全机制的 Jailbreak 攻击。现有的防御措施，包括输入同义重组、多步评估和安全专家模型，往往面临着高计算成本、泛化能力有限或僵化的流程等问题，无法检测到复杂上下文中隐含的微妙恶意意图。受到认知科学中人类决策过程的研究启发，我们提出了一种新的分层 Jailbreak 防护机制 SafeBehavior，模拟人类的适应性多阶段推理过程。SafeBehavior 将安全性评估分解为三个阶段：意图推断以检测明显的输入风险，自我反省以评估生成的响应并基于判断赋予置信度，以及自我修订以适应性重写不确定的输出，同时保留用户意图并遵循安全约束。我们广泛地将 SafeBehavior 与五种代表性 Jailbreak 攻击类型，包括基于优化、上下文操纵和提示的攻击进行了评估，并将其与七个最先进的防御基线进行了比较。实验结果表明，SafeBehavior 显著提高了在各种威胁场景下的鲁棒性和适应性，提供了一种高效且受人类启发的方法，以保护大型语言模型免受 Jailbreak 企图。', 'title_zh': 'SafeBehavior: 模拟人类似的多阶段推理以减轻大型语言模型的 Jailbreak 攻击'}
{'arxiv_id': 'arXiv:2509.26331', 'title': 'AI Playing Business Games: Benchmarking Large Language Models on Managerial Decision-Making in Dynamic Simulations', 'authors': 'Berdymyrat Ovezmyradov', 'link': 'https://arxiv.org/abs/2509.26331', 'abstract': 'The rapid advancement of LLMs sparked significant interest in their potential to augment or automate managerial functions. One of the most recent trends in AI benchmarking is performance of Large Language Models (LLMs) over longer time horizons. While LLMs excel at tasks involving natural language and pattern recognition, their capabilities in multi-step, strategic business decision-making remain largely unexplored. Few studies demonstrated how results can be different from benchmarks in short-term tasks, as Vending-Bench revealed. Meanwhile, there is a shortage of alternative benchmarks for long-term coherence. This research analyses a novel benchmark using a business game for the decision making in business. The research contributes to the recent literature on AI by proposing a reproducible, open-access management simulator to the research community for LLM benchmarking. This novel framework is used for evaluating the performance of five leading LLMs available in free online interface: Gemini, ChatGPT, Meta AI, Mistral AI, and Grok. LLM makes decisions for a simulated retail company. A dynamic, month-by-month management simulation provides transparently in spreadsheet model as experimental environment. In each of twelve months, the LLMs are provided with a structured prompt containing a full business report from the previous period and are tasked with making key strategic decisions: pricing, order size, marketing budget, hiring, dismissal, loans, training expense, R&D expense, sales forecast, income forecast The methodology is designed to compare the LLMs on quantitative metrics: profit, revenue, and market share, and other KPIs. LLM decisions are analyzed in their strategic coherence, adaptability to market changes, and the rationale provided for their decisions. This approach allows to move beyond simple performance metrics for assessment of the long-term decision-making.', 'abstract_zh': 'LLMs在长期决策中的表现：基于商业游戏的新基准研究', 'title_zh': 'AI参与商业博弈：大型语言模型在动态模拟中的决策制定基准研究'}
{'arxiv_id': 'arXiv:2509.26306', 'title': 'Interactive Learning for LLM Reasoning', 'authors': 'Hehai Lin, Shilei Cao, Minzhi Li, Sudong Wang, Haotian Wu, Linyi Yang, Juepeng Zheng, Chengwei Qin', 'link': 'https://arxiv.org/abs/2509.26306', 'abstract': "Existing multi-agent learning approaches have developed interactive training environments to explicitly promote collaboration among multiple Large Language Models (LLMs), thereby constructing stronger multi-agent systems (MAS). However, during inference, they require re-executing the MAS to obtain final solutions, which diverges from human cognition that individuals can enhance their reasoning capabilities through interactions with others and resolve questions independently in the future. To investigate whether multi-agent interaction can enhance LLMs' independent problem-solving ability, we introduce ILR, a novel co-learning framework for MAS that integrates two key components: Dynamic Interaction and Perception Calibration. Specifically, Dynamic Interaction first adaptively selects either cooperative or competitive strategies depending on question difficulty and model ability. LLMs then exchange information through Idea3 (Idea Sharing, Idea Analysis, and Idea Fusion), an innovative interaction paradigm designed to mimic human discussion, before deriving their respective final answers. In Perception Calibration, ILR employs Group Relative Policy Optimization (GRPO) to train LLMs while integrating one LLM's reward distribution characteristics into another's reward function, thereby enhancing the cohesion of multi-agent interactions. We validate ILR on three LLMs across two model families of varying scales, evaluating performance on five mathematical benchmarks and one coding benchmark. Experimental results show that ILR consistently outperforms single-agent learning, yielding an improvement of up to 5% over the strongest baseline. We further discover that Idea3 can enhance the robustness of stronger LLMs during multi-agent inference, and dynamic interaction types can boost multi-agent learning compared to pure cooperative or competitive strategies.", 'abstract_zh': '基于多Agent交互的大型语言模型自主问题解决能力提升框架：ILR', 'title_zh': '交互式学习促进大模型推理'}
{'arxiv_id': 'arXiv:2509.26255', 'title': 'ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning', 'authors': 'Yichao Liang, Dat Nguyen, Cambridge Yang, Tianyang Li, Joshua B. Tenenbaum, Carl Edward Rasmussen, Adrian Weller, Zenna Tavares, Tom Silver, Kevin Ellis', 'link': 'https://arxiv.org/abs/2509.26255', 'abstract': "Long-horizon embodied planning is challenging because the world does not only change through an agent's actions: exogenous processes (e.g., water heating, dominoes cascading) unfold concurrently with the agent's actions. We propose a framework for abstract world models that jointly learns (i) symbolic state representations and (ii) causal processes for both endogenous actions and exogenous mechanisms. Each causal process models the time course of a stochastic causal-effect relation. We learn these world models from limited data via variational Bayesian inference combined with LLM proposals. Across five simulated tabletop robotics environments, the learned models enable fast planning that generalizes to held-out tasks with more objects and more complex goals, outperforming a range of baselines.", 'abstract_zh': '长时程体态规划具有挑战性，因为世界的变化不仅通过代理的动作发生：外生过程（例如，热水加热、多米诺骨牌连锁反应）会与代理的动作同时进行。我们提出了一种抽象世界模型的框架，该框架联合学习（i）符号状态表示和（ii）因果过程，包括内生动作和外生机制。每个因果过程都建模了一个随机因果影响关系的时间进程。我们通过结合变分贝叶斯推断和大型语言模型提案从有限数据中学习这些世界模型。在五个模拟的桌面机器人环境中，学习到的模型能够实现快速规划，并对新的包含更多物体和更复杂目标的任务进行了泛化，优于多种基准方法。', 'title_zh': 'ExoPredicator：学习动态世界抽象模型的机器人规划方法'}
{'arxiv_id': 'arXiv:2509.26246', 'title': 'SlimPack: Fine-Grained Asymmetric Packing for Balanced and Efficient Variable-Length LLM Training', 'authors': 'Yuliang Liu, Guohao Wu, Shenglong Zhang, Wei Zhang, Qianchao Zhu, Zhouyang Li, Chenyu Wang', 'link': 'https://arxiv.org/abs/2509.26246', 'abstract': 'The efficient distributed training of Large Language Models (LLMs) is severely hampered by the extreme variance in context lengths. This data heterogeneity, amplified by conventional packing strategies and asymmetric forward-backward costs, leads to critical inefficiencies such as cascading workload imbalances and severe hardware underutilization. Existing solutions attempt to mitigate these challenges, but often at the expense of memory or communication efficiency.\nTo address these challenges, we introduce SlimPack, a framework that fundamentally rethinks data packing and scheduling by decomposing samples into fine-grained slices. This slice-level decomposition immediately mitigates critical memory and communication bottlenecks by transforming large, volatile workloads into a stream of smaller, manageable units. This flexibility is then harnessed for our core innovation, Asymmetric Partitioning, which assembles balanced scheduling units uniquely optimized for the different demands of the forward and backward passes. Orchestrated by a two-phase solver and a high-fidelity simulator, SlimPack holistically resolves imbalances across all parallel dimensions. Extensive experiments demonstrate that SlimPack achieves up to a $2.8\\times$ training throughput improvement over baselines, breaking the conventional trade-off by delivering both superior balance and high resource efficiency.', 'abstract_zh': '大型语言模型的高效分布式训练受到极端上下文长度差异的严重阻碍。这种数据异质性，加上传统的打包策略和不对称的前向-后向计算成本的放大，导致了关键的低效问题，如工作负载不平衡的级联效应和严重的硬件利用率低下。现有解决方案试图缓解这些挑战，但往往以牺牲内存或通信效率为代价。\n为了解决这些挑战，我们引入了SlimPack框架，从根本上重新思考数据打包和调度，通过将样本分解为精细的片段。这种片段级别的分解立即通过将大型、易变的工作负载转换为较小且可管理的单元来缓解关键的内存和通信瓶颈。然后利用这种灵活性进行我们的核心创新——非对称划分，该创新集成了针对前向和后向传递不同需求的独特平衡调度单元。在两阶段求解器和高保真模拟器的协调下，SlimPack全面解决了所有并行维度的不平衡问题。大量实验表明，SlimPack在基线方法上实现了高达2.8倍的训练吞吐量提升，打破了传统的权衡，同时提供了卓越的平衡和高资源效率。', 'title_zh': 'SlimPack：细粒度异构打包以实现高效均衡的变长LLM训练'}
{'arxiv_id': 'arXiv:2509.26217', 'title': 'Benchmarking Deep Learning Convolutions on Energy-constrained CPUs', 'authors': 'Enrique Galvez, Adrien Cassagne, Alix Munier, Manuel Bouyer', 'link': 'https://arxiv.org/abs/2509.26217', 'abstract': 'This work evaluates state-of-the-art convolution algorithms for CPU-based deep learning inference. While most prior studies focus on GPUs or NPUs, CPU implementations remain relatively underoptimized. We benchmark direct, GEMM-based, and Winograd convolutions across modern CPUs from ARM __ , Intel __ , AMD __ , Apple __ , and Nvidia __ , considering both latency and energy efficiency. Our results highlight the key architectural factors that govern CPU efficiency for convolution operations, providing practical guidance for energy-aware embedded deployment. As a main results of this work, the Nvidia __ AGX Orin combined with the GEMM algorithm achieves the best trade-off between inference latency and energy consumption.', 'abstract_zh': '本文评估了基于CPU的深度学习推理中的先进卷积算法。虽然大多数前期研究主要集中在GPU或NPUs上，但CPU实现仍然相对较未优化。我们针对现代ARM __、Intel __、AMD __、Apple __和Nvidia __的CPU， benchmark了直接、GEMM和Winograd卷积，考虑了延迟和能效。我们的结果突出了卷积操作在CPU上实现效率的关键架构因素，并为节能嵌入式部署提供了实用指导。作为本文的主要成果，Nvidia __ AGX Orin结合GEMM算法在推理延迟和能耗之间实现了最佳权衡。', 'title_zh': '能源受限CPU上深度学习卷积的基准测试'}
{'arxiv_id': 'arXiv:2509.26209', 'title': 'Diversity-Incentivized Exploration for Versatile Reasoning', 'authors': 'Zican Hu, Shilin Zhang, Yafu Li, Jianhao Yan, Xuyang Hu, Leyang Cui, Xiaoye Qu, Chunlin Chen, Yu Cheng, Zhi Wang', 'link': 'https://arxiv.org/abs/2509.26209', 'abstract': 'Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a crucial paradigm for incentivizing reasoning capabilities in Large Language Models (LLMs). Due to vast state-action spaces and reward sparsity in reasoning tasks, existing methods often struggle with deficient exploration and poor sample efficiency. In the paper, we propose \\textbf{DIVER} (\\textbf{D}iversity-\\textbf{I}ncentivized Exploration for \\textbf{V}ersatil\\textbf{E} \\textbf{R}easoning), an innovative framework that highlights the pivotal role of global sequence-level diversity to incentivize deep exploration for versatile reasoning. We first conduct a primary empirical study to reveal a strong positive correlation between global diversity and reasoning capacity. Building on this insight, we introduce global diversity incentives as an intrinsic reward to promote deep exploration in a semantically structured space. Incorporating the intrinsic reward, we develop a potential-based reward shaping mechanism to preserve optimal policy invariance and design simple heuristics to mitigate possible reward hacking. Experimental results show that DIVER outperforms competitive RLVR baselines with various exploration strategies on both in-domain and out-of-domain tasks, excelling in both Pass@1 and Pass@k evaluations. Our code is available at this https URL.', 'abstract_zh': '可验证奖励的强化学习（RLVR）已经成为激励大型语言模型（LLMs）推理能力的关键范式。由于推理任务中状态-动作空间庞大和奖励稀疏性，现有方法常面临探索不足和样本效率低下的问题。本文提出了一种创新框架 \\textbf{DIVER}（Diversity-Incentivized Exploration for Versatile Reasoning），强调全局序列级别多样性在激励深度探索和多样化推理方面的重要作用。我们首先进行了一项初步的实证研究，揭示了全局多样性和推理能力之间存在强烈的正相关关系。基于这一洞察，我们引入全局多样性激励作为内在奖励，以促进在语义结构化空间中的深度探索。通过整合内在奖励，我们设计了一种基于潜能的奖励塑造机制，以保持最优策略不变性，并设计了简单的策略来缓解潜在的奖励操纵问题。实验结果表明，DIVER 在多种探索策略下均优于各种RLVR基线方法，在领域内和领域外任务上均表现出色，尤其在 Pass@1 和 Pass@k 评估中表现出色。代码可在此链接获取。', 'title_zh': '多样化激励探索以实现灵活推理'}
{'arxiv_id': 'arXiv:2509.26205', 'title': 'Human-Centered Evaluation of RAG outputs: a framework and questionnaire for human-AI collaboration', 'authors': 'Aline Mangold, Kiran Hoffmann', 'link': 'https://arxiv.org/abs/2509.26205', 'abstract': "Retrieval-augmented generation (RAG) systems are increasingly deployed in user-facing applications, yet systematic, human-centered evaluation of their outputs remains underexplored. Building on Gienapp's utility-dimension framework, we designed a human-centred questionnaire that assesses RAG outputs across 12 dimensions. We iteratively refined the questionnaire through several rounds of ratings on a set of query-output pairs and semantic discussions. Ultimately, we incorporated feedback from both a human rater and a human-LLM pair. Results indicate that while large language models (LLMs) reliably focus on metric descriptions and scale labels, they exhibit weaknesses in detecting textual format variations. Humans struggled to focus strictly on metric descriptions and labels. LLM ratings and explanations were viewed as a helpful support, but numeric LLM and human ratings lacked agreement. The final questionnaire extends the initial framework by focusing on user intent, text structuring, and information verifiability.", 'abstract_zh': '基于检索的生成（RAG）系统日益应用于面向用户的应用程序，然而对其输出的人本中心化系统性评估仍鲜有探索。基于Gienapp的效用维度框架，我们设计了一份人本中心问卷，评估RAG输出在12个维度上的表现。我们通过多次轮次对查询-输出对进行评分和语义讨论，不断完善问卷。最终，我们结合了人力评分和人-大模型评分的反馈。结果表明，虽然大型语言模型（LLMs）能可靠地关注度量描述和尺度标签，但在检测文本格式变异方面表现出弱点。人类难以专注于度量描述和标签。大模型评分和解释被视作有益的支持，但数值评分和人类评分缺乏一致性。最终问卷在初始框架基础上，强调用户意图、文本结构和信息可验证性。', 'title_zh': '面向人类中心的人性化评估：人类-AI协作的框架与问卷调查'}
{'arxiv_id': 'arXiv:2509.26201', 'title': 'LLM Agents for Knowledge Discovery in Atomic Layer Processing', 'authors': 'Andreas Werbrouck, Marshall B. Lindsay, Matthew Maschmann, Matthias J. Young', 'link': 'https://arxiv.org/abs/2509.26201', 'abstract': "Large Language Models (LLMs) have garnered significant attention for several years now. Recently, their use as independently reasoning agents has been proposed. In this work, we test the potential of such agents for knowledge discovery in materials science. We repurpose LangGraph's tool functionality to supply agents with a black box function to interrogate. In contrast to process optimization or performing specific, user-defined tasks, knowledge discovery consists of freely exploring the system, posing and verifying statements about the behavior of this black box, with the sole objective of generating and verifying generalizable statements. We provide proof of concept for this approach through a children's parlor game, demonstrating the role of trial-and-error and persistence in knowledge discovery, and the strong path-dependence of results. We then apply the same strategy to show that LLM agents can explore, discover, and exploit diverse chemical interactions in an advanced Atomic Layer Processing reactor simulation using intentionally limited probe capabilities without explicit instructions.", 'abstract_zh': '大规模语言模型（LLMs）在过去几年中引起了广泛关注。近年来，它们作为独立推理代理的应用被提出。在本文中，我们测试了这类代理在材料科学中的知识发现潜力。我们重新利用LangGraph的工具功能，为代理提供一个黑箱函数以进行问询。与过程优化或执行特定的用户定义任务不同，知识发现包括自由探索系统，针对黑箱的行为提出并验证声明，其唯一目标是生成和验证可泛化的声明。我们通过一个儿童桌游展示此方法的概念证明，展示了试错和坚持在知识发现中的作用，以及结果的强烈路径依赖性。然后，我们采用相同策略，通过故意限制探针能力但在没有明确指示的情况下探索、发现和利用高级原子层处理反应器模拟中的多样化化学相互作用，进一步验证了LLM代理的能力。', 'title_zh': '基于原子层处理的知识发现大语言模型代理'}
{'arxiv_id': 'arXiv:2509.26167', 'title': "'Too much alignment; not enough culture': Re-balancing cultural alignment practices in LLMs", 'authors': 'Eric J. W. Orlowski, Hakim Norhashim, Tristan Koh Ly Wey', 'link': 'https://arxiv.org/abs/2509.26167', 'abstract': 'While cultural alignment has increasingly become a focal point within AI research, current approaches relying predominantly on quantitative benchmarks and simplistic proxies fail to capture the deeply nuanced and context-dependent nature of human cultures. Existing alignment practices typically reduce culture to static demographic categories or superficial cultural facts, thereby sidestepping critical questions about what it truly means to be culturally aligned. This paper argues for a fundamental shift towards integrating interpretive qualitative approaches drawn from social sciences into AI alignment practices, specifically in the context of Large Language Models (LLMs). Drawing inspiration from Clifford Geertz\'s concept of "thick description," we propose that AI systems must produce outputs that reflect deeper cultural meanings--what we term "thick outputs"-grounded firmly in user-provided context and intent. We outline three necessary conditions for successful cultural alignment: sufficiently scoped cultural representations, the capacity for nuanced outputs, and the anchoring of outputs in the cultural contexts implied within prompts. Finally, we call for cross-disciplinary collaboration and the adoption of qualitative, ethnographic evaluation methods as vital steps toward developing AI systems that are genuinely culturally sensitive, ethically responsible, and reflective of human complexity.', 'abstract_zh': '文化融入视角下大型语言模型的实质化对齐：跨学科合作与质性评价方法', 'title_zh': '“过度对齐；不足的文化”：重新平衡LLM中的文化对齐实践'}
{'arxiv_id': 'arXiv:2509.26161', 'title': '90% Faster, 100% Code-Free: MLLM-Driven Zero-Code 3D Game Development', 'authors': 'Runxin Yang, Yuxuan Wan, Shuqing Li, Michael R. Lyu', 'link': 'https://arxiv.org/abs/2509.26161', 'abstract': 'Developing 3D games requires specialized expertise across multiple domains, including programming, 3D modeling, and engine configuration, which limits access to millions of potential creators. Recently, researchers have begun to explore automated game development. However, existing approaches face three primary challenges: (1) limited scope to 2D content generation or isolated code snippets; (2) requirement for manual integration of generated components into game engines; and (3) poor performance on handling interactive game logic and state management. While Multimodal Large Language Models (MLLMs) demonstrate potential capabilities to ease the game generation task, a critical gap still remains in translating these outputs into production-ready, executable game projects based on game engines such as Unity and Unreal Engine.\nTo bridge the gap, this paper introduces UniGen, the first end-to-end coordinated multi-agent framework that automates zero-coding development of runnable 3D games from natural language requirements. Specifically, UniGen uses a Planning Agent that interprets user requirements into structured blueprints and engineered logic descriptions; after which a Generation Agent produces executable C# scripts; then an Automation Agent handles engine-specific component binding and scene construction; and lastly a Debugging Agent provides real-time error correction through conversational interaction. We evaluated UniGen on three distinct game prototypes. Results demonstrate that UniGen not only democratizes game creation by requiring no coding from the user, but also reduces development time by 91.4%. We release UniGen at this https URL. A video demonstration is available at this https URL.', 'abstract_zh': '开发3D游戏需要跨多个领域（包括编程、3D建模和引擎配置）的专业知识，这限制了数百万潜在创作者的参与。近期，研究人员开始探索自动游戏开发。然而，现有方法面临三大主要挑战：（1）局限于2D内容生成或孤立的代码片段；（2）需要手动将生成的组件集成到游戏引擎中；（3）在处理交互式游戏逻辑和状态管理方面表现不佳。虽然多模态大规模语言模型（MLLMs）展示了简化游戏生成任务的潜力，但在将这些输出转化为针对如Unity和Unreal Engine等游戏引擎的可执行生产项目方面仍存在关键缺口。\n\n为此，本文提出了UniGen，这是第一个端到端协调多代理框架，能够从自然语言要求自动开发可运行的3D游戏。具体而言，UniGen 使用一个规划代理，将用户需求解释为结构化的蓝图和工程逻辑描述；随后，生成代理生成可执行的C#脚本；接着，自动化代理处理特定于引擎的组件绑定和场景构建；最后，调试代理通过对话交互提供实时错误修正。我们在三个不同的游戏原型上评估了UniGen。结果表明，UniGen不仅通过要求用户不编写代码就能够使游戏创作民主化，还能够将开发时间减少91.4%。我们在此链接发布了UniGen：[链接]。一个视频演示可在以下链接获得：[链接]。', 'title_zh': '90%更快，100%代码自由：由MLLM驱动的零代码3D游戏开发'}
{'arxiv_id': 'arXiv:2509.26153', 'title': 'Beyond the Algorithm: A Field Guide to Deploying AI Agents in Clinical Practice', 'authors': 'Jack Gallifant, Katherine C. Kellogg, Matt Butler, Amanda Centi, Patrick F. Doyle, Sayon Dutta, Joyce Guo, Matthew J. Hadfield, Esther H. Kim, David E. Kozono, Hugo JWL Aerts, Adam B. Landman, Raymond H. Mak, Rebecca G. Mishuris, Tanna L. Nelson, Guergana K. Savova, Elad Sharon, Benjamin C. Silverman, Umit Topaloglu, Jeremy L. Warner, Danielle S. Bitterman', 'link': 'https://arxiv.org/abs/2509.26153', 'abstract': 'Large language models (LLMs) integrated into agent-driven workflows hold immense promise for healthcare, yet a significant gap exists between their potential and practical implementation within clinical settings. To address this, we present a practitioner-oriented field manual for deploying generative agents that use electronic health record (EHR) data. This guide is informed by our experience deploying the "irAE-Agent", an automated system to detect immune-related adverse events from clinical notes at Mass General Brigham, and by structured interviews with 20 clinicians, engineers, and informatics leaders involved in the project. Our analysis reveals a critical misalignment in clinical AI development: less than 20% of our effort was dedicated to prompt engineering and model development, while over 80% was consumed by the sociotechnical work of implementation. We distill this effort into five "heavy lifts": data integration, model validation, ensuring economic value, managing system drift, and governance. By providing actionable solutions for each of these challenges, this field manual shifts the focus from algorithmic development to the essential infrastructure and implementation work required to bridge the "valley of death" and successfully translate generative AI from pilot projects into routine clinical care.', 'abstract_zh': '大型语言模型（LLMs）集成到由代理驱动的工作流中在医疗保健领域具有巨大潜力，但在临床环境中的潜在应用和实际实施之间存在显著差距。为了解决这一问题，我们提供了一本面向实践者的操作手册，用于部署使用电子健康记录（EHR）数据的生成型代理。该指南借鉴了我们部署“irAE-Agent”的经验，该系统用于在马萨诸塞州总医院及其合作伙伴处从临床笔记中自动检测免疫相关不良事件，并借鉴了与20名参与该项目的临床医生、工程师和信息技术领导者进行的结构化访谈。我们的分析揭示了临床AI开发中的一个关键错配：我们在提示工程和模型开发方面投入的努力不到20%，而超过80%的努力则用于实施的社技工作。我们将这些努力提炼为五个“重大的任务”：数据集成、模型验证、确保经济价值、管理系统漂移和治理。通过为每一个挑战提供可行的解决方案，这份操作手册将重点从算法开发转向实现生成型AI从试点项目顺利过渡到常规临床护理所需的必要基础设施和实施工作。', 'title_zh': '超越算法：临床实践中共启人工智能代理的应用指南'}
{'arxiv_id': 'arXiv:2509.26145', 'title': 'LMILAtt: A Deep Learning Model for Depression Detection from Social Media Users Enhanced by Multi-Instance Learning Based on Attention Mechanism', 'authors': 'Yukun Yang', 'link': 'https://arxiv.org/abs/2509.26145', 'abstract': 'Depression is a major global public health challenge and its early identification is crucial. Social media data provides a new perspective for depression detection, but existing methods face limitations such as insufficient accuracy, insufficient utilization of time series features, and high annotation costs. To this end, this study proposes the LMILAtt model, which innovatively integrates Long Short-Term Memory autoencoders and attention mechanisms: firstly, the temporal dynamic features of user tweets (such as depressive tendency evolution patterns) are extracted through unsupervised LSTM autoencoders. Secondly, the attention mechanism is used to dynamically weight key texts (such as early depression signals) and construct a multi-example learning architecture to improve the accuracy of user-level detection. Finally, the performance was verified on the WU3D dataset labeled by professional medicine. Experiments show that the model is significantly better than the baseline model in terms of accuracy, recall and F1 score. In addition, the weakly supervised learning strategy significantly reduces the cost of labeling and provides an efficient solution for large-scale social media depression screening.', 'abstract_zh': '抑郁是全球重大公共卫生挑战，早期识别至关重要。社交媒体数据提供了新的抑郁检测视角，但现有方法存在准确率不足、时间序列特征利用不充分以及标注成本高等局限。为此，本文提出LMILAtt模型，创新性地结合了长短期记忆自编码器和注意力机制：首先，通过无监督的LSTM自编码器提取用户推文的时序动态特征（如抑郁倾向演变模式）。其次，采用注意力机制动态加权关键文本（如早期抑郁信号），构建多例学习架构以提高用户级别检测的准确性。最后，实验在专业医学标注的WU3D数据集上验证了模型性能。实验结果表明，该模型在准确率、召回率和F1分数上显著优于基线模型。此外，弱监督学习策略显著降低了标注成本，为大规模社交媒体抑郁症筛查提供了高效的解决方案。', 'title_zh': '基于多实例学习和注意力机制的深度学习模型：社交媒体用户抑郁症检测'}
{'arxiv_id': 'arXiv:2509.26128', 'title': 'MEDAKA: Construction of Biomedical Knowledge Graphs Using Large Language Models', 'authors': 'Asmita Sengupta, David Antony Selby, Sebastian Josef Vollmer, Gerrit Großmann', 'link': 'https://arxiv.org/abs/2509.26128', 'abstract': 'Knowledge graphs (KGs) are increasingly used to represent biomedical information in structured, interpretable formats. However, existing biomedical KGs often focus narrowly on molecular interactions or adverse events, overlooking the rich data found in drug leaflets. In this work, we present (1) a hackable, end-to-end pipeline to create KGs from unstructured online content using a web scraper and an LLM; and (2) a curated dataset, MEDAKA, generated by applying this method to publicly available drug leaflets. The dataset captures clinically relevant attributes such as side effects, warnings, contraindications, ingredients, dosage guidelines, storage instructions and physical characteristics. We evaluate it through manual inspection and with an LLM-as-a-Judge framework, and compare its coverage with existing biomedical KGs and databases. We expect MEDAKA to support tasks such as patient safety monitoring and drug recommendation. The pipeline can also be used for constructing KGs from unstructured texts in other domains. Code and dataset are available at this https URL.', 'abstract_zh': '知识图谱（KGs）在结构化和可解释的形式中被越来越多地用于表示 biomedical 信息。然而，现有的 biomedical KGs 经常狭隘地关注分子相互作用或不良事件，忽略了药物说明书中的丰富数据。在本文中，我们提出了（1）一个可扩展的端到端管道，通过网页爬虫和大语言模型从未结构化的在线内容创建 KGs；以及（2）一个经过精心编目的数据集 MEDAKA，该数据集是通过对公开的药物说明书应用此方法生成的。该数据集捕获了如副作用、警告、禁忌症、成分、剂量指南、储存说明和物理特性等临床相关的属性。我们通过人工检查和大语言模型作为法官的框架对其进行评估，并将其覆盖范围与现有的 biomedical KGs 和数据库进行比较。我们期望 MEDAKA 能够支持患者安全监控和药物推荐等任务。该管道还可用于其他领域未结构化文本的 KG 构建。代码和数据集可在以下网址获得。', 'title_zh': 'MEDAKA：使用大规模语言模型构建生物医学知识图谱'}
{'arxiv_id': 'arXiv:2509.26100', 'title': 'SafeEvalAgent: Toward Agentic and Self-Evolving Safety Evaluation of LLMs', 'authors': 'Yixu Wang, Xin Wang, Yang Yao, Xinyuan Li, Yan Teng, Xingjun Ma, Yingchun Wang', 'link': 'https://arxiv.org/abs/2509.26100', 'abstract': "The rapid integration of Large Language Models (LLMs) into high-stakes domains necessitates reliable safety and compliance evaluation. However, existing static benchmarks are ill-equipped to address the dynamic nature of AI risks and evolving regulations, creating a critical safety gap. This paper introduces a new paradigm of agentic safety evaluation, reframing evaluation as a continuous and self-evolving process rather than a one-time audit. We then propose a novel multi-agent framework SafeEvalAgent, which autonomously ingests unstructured policy documents to generate and perpetually evolve a comprehensive safety benchmark. SafeEvalAgent leverages a synergistic pipeline of specialized agents and incorporates a Self-evolving Evaluation loop, where the system learns from evaluation results to craft progressively more sophisticated and targeted test cases. Our experiments demonstrate the effectiveness of SafeEvalAgent, showing a consistent decline in model safety as the evaluation hardens. For instance, GPT-5's safety rate on the EU AI Act drops from 72.50% to 36.36% over successive iterations. These findings reveal the limitations of static assessments and highlight our framework's ability to uncover deep vulnerabilities missed by traditional methods, underscoring the urgent need for dynamic evaluation ecosystems to ensure the safe and responsible deployment of advanced AI.", 'abstract_zh': '大型语言模型快速融入高风险领域需要可靠的安全和合规评估。然而，现有的静态基准不足以为人工智能风险的动态性质和不断演变的法规提供解决方案，从而形成重要的安全缺口。本文提出了一种新的主动安全评估范式，重新定义评估为一个持续且自我进化的过程，而非一次性审核。我们随后提出了一种新的多智能体框架SafeEvalAgent，该框架自主地摄取无结构化的政策文件，生成并不断进化一个全面的安全基准。SafeEvalAgent利用专门智能体的协同工作流程，并嵌入一个自我进化的评估循环，其中系统从评估结果中学习，逐步制定更加复杂和针对性的测试案例。我们的实验表明SafeEvalAgent的有效性，显示随着评估标准的严格化，模型安全率持续下降。例如，GPT-5在欧盟人工智能法案中的安全率从72.50%下降到36.36%。这些发现揭示了静态评估的局限性，并突显了我们框架在传统方法中未能发现深层次漏洞的能力，强调了构建动态评估生态系统以确保先进人工智能的安全和负责任部署的迫切需求。', 'title_zh': 'SafeEvalAgent: 朝向具有代理性和自我进化能力的LLM安全评估'}
{'arxiv_id': 'arXiv:2509.26080', 'title': 'Evaluating the Use of Large Language Models as Synthetic Social Agents in Social Science Research', 'authors': 'Emma Rose Madden', 'link': 'https://arxiv.org/abs/2509.26080', 'abstract': 'Large Language Models (LLMs) are being increasingly used as synthetic agents in social science, in applications ranging from augmenting survey responses to powering multi-agent simulations. Because strong prediction plus conditioning prompts, token log-probs, and repeated sampling mimic Bayesian workflows, their outputs can be misinterpreted as posterior-like evidence from a coherent model. However, prediction does not equate to probabilism, and accurate points do not imply calibrated uncertainty. This paper outlines cautions that should be taken when interpreting LLM outputs and proposes a pragmatic reframing for the social sciences in which LLMs are used as high-capacity pattern matchers for quasi-predictive interpolation under explicit scope conditions and not as substitutes for probabilistic inference. Practical guardrails such as independent draws, preregistered human baselines, reliability-aware validation, and subgroup calibration, are introduced so that researchers may engage in useful prototyping and forecasting while avoiding category errors.', 'abstract_zh': '大型语言模型（LLMs）在社会科学中的应用日益增多，从增强调查响应到驱动多智能体模拟。由于强大的预测加上条件提示、令牌对数概率和重复采样的方式模仿了贝叶斯流程，其输出可能会被误认为是来自一致模型的后验似然证据。然而，预测并不等同于概率主义，准确的点估计并不意味着准确的不确定性校准。本文提出了在解释LLM输出时应采取的谨慎措施，并建议在社会科学研究中将LLMs重新定义为在明确范围条件下作为高容量模式匹配器进行准预测插值的工具，而不是概率推理的替代品。介绍了诸如独立抽样、预先登记的人类基线、可靠性意识验证和亚组校准等实用措施，以使研究人员在有用的设计和预测中避免类别错误。', 'title_zh': '评估大型语言模型作为合成社会代理在社会科学研究中的应用'}
{'arxiv_id': 'arXiv:2509.26037', 'title': 'CoLLM-NAS: Collaborative Large Language Models for Efficient Knowledge-Guided Neural Architecture Search', 'authors': 'Zhe Li, Zhiwei Lin, Yongtao Wang', 'link': 'https://arxiv.org/abs/2509.26037', 'abstract': "The integration of Large Language Models (LLMs) with Neural Architecture Search (NAS) has introduced new possibilities for automating the design of neural architectures. However, most existing methods face critical limitations, including architectural invalidity, computational inefficiency, and inferior performance compared to traditional NAS. In this work, we present Collaborative LLM-based NAS (CoLLM-NAS), a two-stage NAS framework with knowledge-guided search driven by two complementary LLMs. Specifically, we propose a Navigator LLM to guide search direction and a Generator LLM to synthesize high-quality candidates, with a dedicated Coordinator module to manage their interaction. CoLLM-NAS efficiently guides the search process by combining LLMs' inherent knowledge of structured neural architectures with progressive knowledge from iterative feedback and historical trajectory. Experimental results on ImageNet and NAS-Bench-201 show that CoLLM-NAS surpasses existing NAS methods and conventional search algorithms, achieving new state-of-the-art results. Furthermore, CoLLM-NAS consistently enhances the performance and efficiency of various two-stage NAS methods (e.g., OFA, SPOS, and AutoFormer) across diverse search spaces (e.g., MobileNet, ShuffleNet, and AutoFormer), demonstrating its excellent generalization.", 'abstract_zh': '基于大型语言模型的协作神经架构搜索（CoLLM-NAS）：一种由两个互补的LLM驱动的知识导向的两阶段NAS框架', 'title_zh': 'CoLLM-NAS：协作型大型语言模型 Efficient 知识引导的神经架构搜索'}
{'arxiv_id': 'arXiv:2509.26002', 'title': 'Towards Human Engagement with Realistic AI Combat Pilots', 'authors': 'Ardian Selmonaj, Giacomo Del Rio, Adrian Schneider, Alessandro Antonucci', 'link': 'https://arxiv.org/abs/2509.26002', 'abstract': 'We present a system that enables real-time interaction between human users and agents trained to control fighter jets in simulated 3D air combat scenarios. The agents are trained in a dedicated environment using Multi-Agent Reinforcement Learning. A communication link is developed to allow seamless deployment of trained agents into VR-Forces, a widely used defense simulation tool for realistic tactical scenarios. This integration allows mixed simulations where human-controlled entities engage with intelligent agents exhibiting distinct combat behaviors. Our interaction model creates new opportunities for human-agent teaming, immersive training, and the exploration of innovative tactics in defense contexts.', 'abstract_zh': '我们提出了一种系统，使得人类用户能够实时与在模拟3D空战场景中训练用于控制战斗机的智能体进行交互。这些智能体是在专用环境中使用多智能体强化学习训练的。我们开发了一种通信链接，以便无缝地将训练好的智能体部署到VR-Forces中，这是一个广泛使用的国防仿真工具，用于实现逼真的战术场景。这种集成允许人类控制的实体与表现出不同作战行为的智能体进行混合模拟。我们的交互模型为人类-智能体协同作战、沉浸式训练以及在国防背景下探索创新战术提供了新的机会。', 'title_zh': '面向真实主义AI战斗飞行员的人机互动研究'}
{'arxiv_id': 'arXiv:2509.25991', 'title': 'Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline', 'authors': 'Haiyang Li, Yaxiong Wang, Lianwei Wu, Lechao Cheng, Zhun Zhong', 'link': 'https://arxiv.org/abs/2509.25991', 'abstract': 'In recent years, detecting fake multimodal content on social media has drawn increasing attention. Two major forms of deception dominate: human-crafted misinformation (e.g., rumors and misleading posts) and AI-generated content produced by image synthesis models or vision-language models (VLMs). Although both share deceptive intent, they are typically studied in isolation. NLP research focuses on human-written misinformation, while the CV community targets AI-generated artifacts. As a result, existing models are often specialized for only one type of fake content. In real-world scenarios, however, the type of a multimodal post is usually unknown, limiting the effectiveness of such specialized systems. To bridge this gap, we construct the Omnibus Dataset for Multimodal News Deception (OmniFake), a comprehensive benchmark of 127K samples that integrates human-curated misinformation from existing resources with newly synthesized AI-generated examples. Based on this dataset, we propose Unified Multimodal Fake Content Detection (UMFDet), a framework designed to handle both forms of deception. UMFDet leverages a VLM backbone augmented with a Category-aware Mixture-of-Experts (MoE) Adapter to capture category-specific cues, and an attribution chain-of-thought mechanism that provides implicit reasoning guidance for locating salient deceptive signals. Extensive experiments demonstrate that UMFDet achieves robust and consistent performance across both misinformation types, outperforming specialized baselines and offering a practical solution for real-world multimodal deception detection.', 'abstract_zh': '近年来，社交媒体上假多模态内容的检测受到了不断增加的关注。两种主要形式的欺骗占主导地位：人类设计的信息误导（如谣言和误导性帖子）和由图像合成模型或视觉语言模型生成的AI内容。尽管两者都具有误导意图，但通常分别研究。NLP研究专注于人类编写的误导性内容，而CV社区针对AI生成的伪造内容。因此，现有模型往往只能针对一种类型的虚假内容。然而，在实际场景中，多模态帖子的类型通常是未知的，限制了此类专门系统的有效性。为了弥合这一差距，我们构建了面向多模态新闻欺诈的综合基准数据集（OmniFake），该数据集包含127,000个样本，整合了现有资源中的人工编curated误Informmation信和新合成的AI生成示例。基于此数据集，我们提出了一种统一的多模态虚假内容检测框架（UMFDet），该框架旨在处理这两种欺骗形式。UMFDet利用了一个增强的视觉语言模型骨干，并结合了一个类别感知的混合专家（MoE）适配器来捕捉类别特定的线索，以及一种归属链推理机制，该机制提供了隐式推理指导，以定位显著的误导信号。 extensive实验证明，UMFDet在两种误导类别上均表现出稳健且一致的性能，优于专门基准，并为实际场景中的多模态欺骗检测提供了实用解决方案。', 'title_zh': '面向社交媒体中统一的多模态 misinformation 检测：一个基准数据集和基线方法'}
{'arxiv_id': 'arXiv:2509.25973', 'title': 'Scalable and Robust LLM Unlearning by Correcting Responses with Retrieved Exclusions', 'authors': 'Junbeom Kim, Kyuyoung Kim, Jihoon Tack, Dongha Lim, Jinwoo Shin', 'link': 'https://arxiv.org/abs/2509.25973', 'abstract': 'Language models trained on web-scale corpora risk memorizing and exposing sensitive information, prompting the need for effective machine unlearning. Prior methods mainly focus on input queries to suppress sensitive outputs, yet this often fails to eliminate the underlying knowledge and limits scalability. To address this, we propose Corrective Unlearning with Retrieved Exclusions (CURE), a novel unlearning framework that verifies model outputs for leakage and revises them into safe responses. Specifically, CURE employs a lightweight corrector that is applied to the original model to verify whether outputs contain target knowledge and to rewrite them if any leakage is detected. To efficiently handle large-scale unlearning requests, CURE retrieves unlearning targets that are relevant to the initial response and provides them as in-context references to the corrector for detection and conditional revision. By leveraging this retrieval augmentation, the corrector can adapt to new unlearning requests without additional training. Extensive evaluations demonstrate that CURE substantially reduces information leakage, even from indirect queries where prior works fall short, while maintaining response quality and general utility. Moreover, it demonstrates robustness under continual unlearning scenarios, making it practical for real-world applications.', 'abstract_zh': '大规模网络语料库训练的语言模型存在泄露敏感信息的风险， necessitating 有效的机器遗忘机制。现有方法主要针对输入查询以抑制敏感输出，但这种方法 often 无法完全消除潜在知识并且限制了可扩展性。为解决这一问题，我们提出了检索排除辅助纠正遗忘（CURE）这一新颖的遗忘框架，用于验证模型输出是否存在泄露并将其纠正为安全响应。具体而言，CURE 使用一个轻量级的纠错器，将其应用于原始模型以验证输出是否包含目标知识，如果检测到泄露，则对其进行重写。为了高效处理大规模遗忘请求，CURE 会检索与初始响应相关联的遗忘目标，并将它们作为上下文参考提供给纠错器进行检测和有条件纠正。通过利用这种检索增强，纠错器可以在无需额外训练的情况下适应新的遗忘请求。广泛评估表明，CURE 显著减少了信息泄露，特别是在前人工作无法处理的间接查询中，同时保持了响应质量和一般用途。此外，它在持续遗忘场景中表现出 robustness，使其适用于实际应用。', 'title_zh': '可扩展且稳健的LLM去训练：通过检索排除信息修正响应'}
{'arxiv_id': 'arXiv:2509.25958', 'title': 'RoRecomp: Enhancing Reasoning Efficiency via Rollout Response Recomposition in Reinforcement Learning', 'authors': 'Gang Li, Yulei Qin, Xiaoyu Tan, Dingkang Yang, Yuchen Shi, Zihan Xu, Xiang Li, Xing Sun, Ke Li', 'link': 'https://arxiv.org/abs/2509.25958', 'abstract': 'Reinforcement learning with verifiable rewards (RLVR) has proven effective in eliciting complex reasoning in large language models (LLMs). However, standard RLVR training often leads to excessively verbose processes (in reasoning tasks) and inefficient exploration trajectories (in agentic settings), as outcome-only rewards provide no incentive for efficiency and the high variance in response length within relatively small rollout groups results in noisy optimization signals. To address this, we propose Rollout Response Recomposition (RoRecomp), a plug-and-play method that guides models toward concise reasoning by strategically recomposing the training data. RoRecomp separates responses into two distinct batch types: 1) priority batches, which combine short-correct and long-incorrect responses selected from online batches to provide a clear gradient signal for brevity, and 2) compensation batches, which utilize remaining responses from a replay buffer to maintain stability and prevent model collapse. To comprehensively evaluate effectiveness, we test RoRecomp across three settings where results demonstrate substantial efficiency gains: reducing reasoning length by 27.7% in zero RL training, reducing unnecessary tool calls by 46.8% while improving accuracy in agentic RL, and achieving up to 52.5% length reduction in thinking compression, all with minimal performance impact.', 'abstract_zh': '可验证奖励的强化学习（RLVR）在大型语言模型中引发了复杂推理的有效性。然而，标准的RLVR训练往往导致推理任务中过度冗长的过程和代理环境中低效的探索轨迹，因为仅基于结果的奖励无法激励效率，并且在相对较小的滚出组中响应长度的高方差导致了嘈杂的优化信号。为了应对这一问题，我们提出了一种插即用方法——Rollout Response Recomposition（RoRecomp），该方法通过战略性重组训练数据引导模型向简洁的推理发展。RoRecomp 将响应分为两类不同的批次：1）优先批次，该批次结合了来自在线批次的短正确和长错误响应，以提供简洁性的清晰梯度信号；2）补偿批次，该批次利用重放缓冲区中的剩余响应以保持稳定性和防止模型崩溃。为了全面评估其效果，我们在三个场景中测试了RoRecomp，结果表明其在效率上取得了显著提升：在零强化学习训练中减少了27.7%的推理长度，在代理强化学习中减少了46.8%的不必要的工具调用同时提高了准确性，并在思考压缩中达到了最高52.5%的长度减少，且对性能的影响极小。', 'title_zh': 'RoRecomp: 基于 rollout 响应重组增强 reinforcement learning 的推理效率'}
{'arxiv_id': 'arXiv:2509.25946', 'title': 'Automated Model Discovery via Multi-modal & Multi-step Pipeline', 'authors': 'Lee Jung-Mok, Nam Hyeon-Woo, Moon Ye-Bin, Junhyun Nam, Tae-Hyun Oh', 'link': 'https://arxiv.org/abs/2509.25946', 'abstract': 'Automated model discovery is the process of automatically searching and identifying the most appropriate model for a given dataset over a large combinatorial search space. Existing approaches, however, often face challenges in balancing the capture of fine-grained details with ensuring generalizability beyond training data regimes with a reasonable model complexity. In this paper, we present a multi-modal \\& multi-step pipeline for effective automated model discovery. Our approach leverages two vision-language-based modules (VLM), AnalyzerVLM and EvaluatorVLM, for effective model proposal and evaluation in an agentic way. AnalyzerVLM autonomously plans and executes multi-step analyses to propose effective candidate models. EvaluatorVLM assesses the candidate models both quantitatively and perceptually, regarding the fitness for local details and the generalibility for overall trends. Our results demonstrate that our pipeline effectively discovers models that capture fine details and ensure strong generalizability. Additionally, extensive ablation studies show that both multi-modality and multi-step reasoning play crucial roles in discovering favorable models.', 'abstract_zh': '自动化模型发现是通过在大规模组合搜索空间中自动搜索和识别最适合给定数据集的模型的过程。现有方法往往难以平衡捕捉细粒度细节与在合理模型复杂度下确保泛化能力之间的关系。本文提出了一种多模态与多步的自动化模型发现管线。我们的方法利用了两个基于视觉-语言的模块（VLM），AnalyzerVLM和EvaluatorVLM，以一种有agency的方式进行有效的模型提案和评估。AnalyzerVLM自主规划并执行多步分析以提出有效的候选模型。EvaluatorVLM从定量和感知的角度评估候选模型，考虑其对局部细节的适应性和对整体趋势的泛化能力。我们的结果表明，该管线能够有效地发现既能捕捉细节又能确保强大泛化能力的模型。此外，广泛的消融研究显示，多模态性和多步推理在发现有利模型中起着关键作用。', 'title_zh': '多模态多步管道驱动的自动化模型发现'}
{'arxiv_id': 'arXiv:2509.25944', 'title': 'NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving', 'authors': 'Yuan Gao, Mattia Piccinini, Roberto Brusnicki, Yuchen Zhang, Johannes Betz', 'link': 'https://arxiv.org/abs/2509.25944', 'abstract': 'Understanding risk in autonomous driving requires not only perception and prediction, but also high-level reasoning about agent behavior and context. Current Vision Language Models (VLMs)-based methods primarily ground agents in static images and provide qualitative judgments, lacking the spatio-temporal reasoning needed to capture how risks evolve over time. To address this gap, we propose NuRisk, a comprehensive Visual Question Answering (VQA) dataset comprising 2,900 scenarios and 1.1 million agent-level samples, built on real-world data from nuScenes and Waymo, supplemented with safety-critical scenarios from the CommonRoad simulator. The dataset provides Bird-Eye-View (BEV) based sequential images with quantitative, agent-level risk annotations, enabling spatio-temporal reasoning. We benchmark well-known VLMs across different prompting techniques and find that they fail to perform explicit spatio-temporal reasoning, resulting in a peak accuracy of 33% at high latency. To address these shortcomings, our fine-tuned 7B VLM agent improves accuracy to 41% and reduces latency by 75%, demonstrating explicit spatio-temporal reasoning capabilities that proprietary models lacked. While this represents a significant step forward, the modest accuracy underscores the profound challenge of the task, establishing NuRisk as a critical benchmark for advancing spatio-temporal reasoning in autonomous driving.', 'abstract_zh': '理解自动驾驶中的风险需要感知和预测，还需要关于代理行为和上下文的高级推理。现有的基于视觉语言模型（VLM）的方法主要将代理定位在静态图像中，提供了定性的判断，缺乏捕捉风险随时间演变所需的时空推理能力。为了解决这一问题，我们提出了NuRisk，这是一个包含2900个场景和110万代理水平样本的全面的视觉问答（VQA）数据集，该数据集基于nuScenes和Waymo的实地数据，并结合了CommonRoad模拟器中的安全性关键场景。该数据集提供了基于鸟类视角（BEV）的序列图像，并附带定量的代理级风险注释，支持时空推理。我们对不同提示技术下的知名VLM进行了基准测试，发现它们未能进行显式的时空推理，导致在高延迟条件下最高准确率为33%。为了弥补这些不足，我们微调的7B VLM代理将准确率提高到41%，并将延迟降低75%，展示了其显式的时空推理能力，这是专有模型所缺乏的。虽然这代表了向前迈出的重要一步，但较低的准确率突显了任务的深刻挑战，确立了NuRisk作为促进自动驾驶中时空推理的关键基准的重要性。', 'title_zh': 'NuRisk: 自主驾驶中代理级风险评估的视觉问答数据集'}
{'arxiv_id': 'arXiv:2509.25941', 'title': 'Boosting Process-Correct CoT Reasoning by Modeling Solvability of Multiple-Choice QA', 'authors': 'Raphael Schumann, Stefan Riezler', 'link': 'https://arxiv.org/abs/2509.25941', 'abstract': 'Reasoning quality in large language models depends not only on producing correct answers but also on generating valid intermediate steps. We study this through multiple-choice question answering (MCQA), which provides a controlled setting with fixed answer options. Our analysis shows that when questions are effectively unsolvable for a model, spurious chains of thought (CoTs) are more likely to appear, leading to false positives. By estimating the solvability of each question, we uncover an intermediate regime where learning is most effective. Building on this insight, we adapt outcome-supervised reward models and reinforcement learning with group-relative advantage to incorporate solvability into their objectives. Across experiments on math and multimodal datasets, these modifications consistently yield higher rates of process-correct reasoning and, in reinforcement learning, improved answer accuracy as well. Our results highlight solvability as a key factor for reducing hallucinations and increasing reliability in CoT reasoning.', 'abstract_zh': '大型语言模型的推理质量不仅取决于产生正确的答案，还取决于生成有效的中间步骤。我们通过多项选择题解答（MCQA）研究这一问题，这为固定答案选项的可控环境提供了条件。我们的分析表明，当问题对模型来说无法有效求解时，虚假的思维链（CoTs）更有可能出现，导致误报。通过估计每个问题的可求解性，我们发现了学习效果最佳的一个中间区段。基于这一发现，我们调整了结果监督的奖励模型，并将基于组相对优势的强化学习与可求解性整合进它们的目标中。在对数学和多模态数据集的实验中，这些修改始终提高了推理过程正确率，而在强化学习中也提高了答案准确性。我们的研究结果强调可求解性是减少幻觉并提高CoTs推理可靠性的关键因素。', 'title_zh': '通过建模多选问答的可解性提升过程正确性的解释链推理'}
{'arxiv_id': 'arXiv:2509.25928', 'title': 'Quantitative Evaluation of KIRETT Wearable Demonstrator for Rescue Operations', 'authors': 'Mubaris Nadeem, Johannes Zenkert, Lisa Bender, Christian Weber, Madjid Fathi', 'link': 'https://arxiv.org/abs/2509.25928', 'abstract': 'Healthcare and Medicine are under constant pressure to provide patient-driven medical expertise to ensure a fast and accurate treatment of the patient. In such scenarios, the diagnosis contains, the family history, long term medical data and a detailed consultation with the patient. In time-critical emergencies, such conversation and time-consuming elaboration are not possible. Rescue services need to provide fast, reliable treatments for the patient in need. With the help of modern technologies, like treatment recommendations, real-time vitals-monitoring, and situation detection through artificial intelligence (AI) a situation can be analyzed and supported in providing fast, accurate patient-data-driven medical treatments. In KIRETT, a wearable device is developed to support in such scenarios and presents a way to provide treatment recommendation in rescue services. The objective of this paper is to present the quantitative results of a two-day KIRETT evaluation (14 participants) to analyze the needs of rescue operators in healthcare.', 'abstract_zh': '健康医疗领域在不断的压力下致力于提供以患者为导向的医疗专长，以确保对患者的快速和准确治疗。在这种情况下，诊断需要包括家族病史、长期的医疗数据以及详细的患者咨询。在时间紧迫的紧急情况下，这样的对话和耗时的详细讨论是不可能的。救援服务需要为需要快速、可靠的治疗的患者提供服务。借助现代技术，如治疗建议、实时生命体征监测和通过人工智能（AI）的情况检测，可以分析情况并在提供快速、准确的基于患者数据的医疗治疗中起到支持作用。在KIRETT中，开发了一种可穿戴设备以支持此类场景，并提出了一种在救援服务中提供治疗建议的方法。本文的目标是展示KIRETT两天评估（14名参与者）的定量结果，以分析救援操作员在医疗领域的需求。', 'title_zh': 'KIRETT可穿戴演示器在救援操作中的定量评价'}
{'arxiv_id': 'arXiv:2509.25923', 'title': 'KIRETT: Smart Integration of Vital Signs Data for Intelligent Decision Support in Rescue Scenarios', 'authors': 'Mubaris Nadeem, Johannes Zenkert, Christian Weber, Lisa Bender, Madjid Fathi', 'link': 'https://arxiv.org/abs/2509.25923', 'abstract': 'The integration of vital signs in healthcare has witnessed a steady rise, promising health professionals to assist in their daily tasks to improve patient treatment. In life-threatening situations, like rescue operations, crucial decisions need to be made in the shortest possible amount of time to ensure that excellent treatment is provided during life-saving measurements. The integration of vital signs in the treatment holds the potential to improve time utilization for rescuers in such critical situations. They furthermore serve to support health professionals during the treatment with useful information and suggestions. To achieve such a goal, the KIRETT project serves to provide treatment recommendations and situation detection, combined on a wrist-worn wearable for rescue this http URL paper aims to present the significant role of vital signs in the improvement of decision-making during rescue operations and show their impact on health professionals and patients in need.', 'abstract_zh': '生命体征在医疗服务中的集成已逐渐上升，为健康专业人员提供帮助，以改善日常任务中的患者治疗。在救援等危急情况下，需要在最短的时间内作出关键决策，以确保在生命救援措施中提供优秀的治疗。生命体征在治疗中的集成有可能提高救援人员在这些关键时刻的时间利用率。它们还可以为健康专业人员在治疗过程中提供有用的建议和信息。为了实现这一目标，KIRETT项目提供治疗建议和情况检测，集成于可穿戴设备腕部设备。本文旨在阐述生命体征在救援操作中提高决策制定中的重要作用，并展示其对健康专业人员和有需要的患者的影响。', 'title_zh': 'KIRETT：救援场景中智能生命体征数据集成的支持智能决策系统'}
{'arxiv_id': 'arXiv:2509.25922', 'title': 'DeepJSONEval: Benchmarking Complex Nested JSON Data Mining for Large Language Models', 'authors': 'Zhicheng Zhou, Jing Li, Suming Qiu, Junjie Huang, Linyuan Qiu, Zhijie Sun', 'link': 'https://arxiv.org/abs/2509.25922', 'abstract': "The internet is saturated with low-density, high-redundancy information, such as social media comments, repetitive news, and lengthy discussions, making it difficult to extract valuable insights efficiently. Multi-layer nested JSON structures provide an effective solution by compressing such information into semantically rich, hierarchical representations, which organize data into key-value pairs, arrays, and nested objects, preserving contextual relationships and enabling efficient storage, retrieval, and semantic querying. For instance, in news aggregation, a JSON object can nest an article's metadata (title, author, date), content (text, multimedia), and multimedia information (multimedia type, caption) hierarchically. Large Language Models (LLMs) play a transformative role in web data mining by parsing unstructured text and outputting structured results directly into complex JSON schemas. However, current benchmarks for evaluating LLMs' JSON output capabilities overemphasize pure JSON generation rather than assessing data comprehension and extraction abilities, a limitation that lacks relevance to practical web data mining tasks. To address this, we introduce DeepJSONEval, a novel benchmark featuring 2100 multi-domain instances with deep nested structures, categorized by difficulty. Experiments show significant performance gaps among LLMs in handling such complexity. Our benchmark and datasets are open-sourced to advance research in structured JSON generation.(this https URL).", 'abstract_zh': '互联网充斥着低密度、高冗余的信息，如社交媒体评论、重复新闻和冗长讨论，这使得高效提取有价值见解变得困难。多层嵌套的JSON结构提供了一种有效的解决方案，通过将此类信息压缩为语义丰富、层次化的表示形式，组织数据为键值对、数组和嵌套对象，从而保留上下文关系并实现高效存储、检索和语义查询。例如，在新闻聚合中，一个JSON对象可以将一篇文章的元数据（标题、作者、日期）、内容（文本、多媒体）和多媒体信息（多媒体类型、说明）层次化地组织起来。大规模语言模型（LLMs）在网页数据挖掘中扮演着变革性的角色，通过解析无结构文本并直接输出复杂JSON模式的结果。然而，目前用于评估LLMs的JSON输出能力的基准过度强调纯JSON生成，而不是评估数据理解和提取能力，这一局限性与实际网页数据挖掘任务的相关性较低。为解决这一问题，我们引入了DeepJSONEval，这是一种新型基准，包含2100个跨领域实例，按难度分类。实验表明，在处理这种复杂性方面，LLMs之间的性能差异显著。我们的基准和数据集已开源，旨在推动结构化JSON生成的研究。(this https URL)。', 'title_zh': 'DeepJSONEval：大规模语言模型复杂嵌套JSON数据挖掘的基准测试'}
{'arxiv_id': 'arXiv:2509.25885', 'title': 'SafeMind: Benchmarking and Mitigating Safety Risks in Embodied LLM Agents', 'authors': 'Ruolin Chen, Yinqian Sun, Jihang Wang, Mingyang Lv, Qian Zhang, Yi Zeng', 'link': 'https://arxiv.org/abs/2509.25885', 'abstract': 'Embodied agents powered by large language models (LLMs) inherit advanced planning capabilities; however, their direct interaction with the physical world exposes them to safety vulnerabilities. In this work, we identify four key reasoning stages where hazards may arise: Task Understanding, Environment Perception, High-Level Plan Generation, and Low-Level Action Generation. We further formalize three orthogonal safety constraint types (Factual, Causal, and Temporal) to systematically characterize potential safety violations. Building on this risk model, we present SafeMindBench, a multimodal benchmark with 5,558 samples spanning four task categories (Instr-Risk, Env-Risk, Order-Fix, Req-Align) across high-risk scenarios such as sabotage, harm, privacy, and illegal behavior. Extensive experiments on SafeMindBench reveal that leading LLMs (e.g., GPT-4o) and widely used embodied agents remain susceptible to safety-critical failures. To address this challenge, we introduce SafeMindAgent, a modular Planner-Executor architecture integrated with three cascaded safety modules, which incorporate safety constraints into the reasoning process. Results show that SafeMindAgent significantly improves safety rate over strong baselines while maintaining comparable task completion. Together, SafeMindBench and SafeMindAgent provide both a rigorous evaluation suite and a practical solution that advance the systematic study and mitigation of safety risks in embodied LLM agents.', 'abstract_zh': '由大型语言模型驱动的具身代理的动力学特性：安全性推理与保障机制', 'title_zh': 'SafeMind: 评估与缓解体感LLM代理的安全风险'}
{'arxiv_id': 'arXiv:2509.25873', 'title': 'Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs', 'authors': 'Hankun Dai, Maoquan Wang, Mengnan Qi, Yikai Zhang, Zijian Jin, Yongqiang Yao, Yufan Huang, Shengyu Fu, Elsie Nallipogu', 'link': 'https://arxiv.org/abs/2509.25873', 'abstract': "Large language models (LLMs) are increasingly being applied to programming tasks, ranging from single-turn code completion to autonomous agents. Current code agent designs frequently depend on complex, hand-crafted workflows and tool sets. However, this reliance on elaborate scaffolding presents several challenges: agent performance becomes overly dependent on prompt tuning and custom design choices, heavy human intervention obscures a model's true underlying capabilities, and intricate pipelines are costly to build and maintain. Furthermore, optimizing complex task prompts increases the risk of data leakage. Currently, when introducing new models, LLM providers like OpenAI and Anthropic often publish benchmark scores to demonstrate their models' coding proficiency, but keep their proprietary evaluation frameworks confidential. To address these limitations, we introduce Lita (Lite Agent), which operationalizes liteness, a principle of minimizing manual design while retaining the essential elements of a fully autonomous agent. Lita enables a more faithful and unified evaluation without elaborate scaffolding. Experiments on the Aider Polyglot and SWE-Bench with frontier models demonstrate that Lita achieves competitive or superior performance compared to workflow-based and agentic baselines. Crucially, Lita also consumes fewer tokens and requires significantly less design effort. Our results suggest that Lita is sufficient to reveal the underlying coding competence of modern LLMs. Finally, we propose the Agent Complexity Law: the performance gap between agents of varying complexity, from simple to sophisticated designs, will shrink as the core model improves, ultimately converging to a negligible difference.", 'abstract_zh': '大型语言模型（LLMs）在编程任务中的应用越来越广泛，从单轮代码补全到自主代理。当前的代码代理设计通常依赖于复杂的、手工构建的工作流程和工具集。然而，这种对复杂支架的依赖提出了几个挑战：代理性能过度依赖于提示调优和定制设计选择，大量的人工干预掩盖了模型的真实潜在能力，复杂的流水线构建和维护成本高昂。此外，优化复杂的任务提示增加了数据泄漏的风险。目前，当引入新模型时，如OpenAI和Anthropic这样的LLM提供商经常发布基准得分来展示其模型的编程能力，但保密其专有评估框架。为了解决这些局限性，我们引入了Lita（Lite Agent），这一体现了简约原则，即在保留完整自主代理核心要素的同时，最大限度减少人工设计的需要。Lita能够实现更忠实且统一的评估，无需复杂的支架。在Aider Polyglot和SWE-Bench上的前沿模型实验表明，Lita在与基于工作流和代理基准相比时，实现了竞争力或更优的性能。最重要的是，Lita消耗的令牌更少，设计工作量显著减少。我们的结果显示，Lita足以揭示现代LLM的潜在编程能力。最后，我们提出了代理复杂度定律：从简单的到复杂的不同设计的代理性能差距将随着核心模型的改进而缩小，最终收敛到一个可以忽略的差异。', 'title_zh': 'Lita: 灵活代理揭示大语言模型的代理编码能力'}
{'arxiv_id': 'arXiv:2509.25862', 'title': 'CIMNAS: A Joint Framework for Compute-In-Memory-Aware Neural Architecture Search', 'authors': 'Olga Krestinskaya, Mohammed E. Fouda, Ahmed Eltawil, Khaled N. Salama', 'link': 'https://arxiv.org/abs/2509.25862', 'abstract': 'To maximize hardware efficiency and performance accuracy in Compute-In-Memory (CIM)-based neural network accelerators for Artificial Intelligence (AI) applications, co-optimizing both software and hardware design parameters is essential. Manual tuning is impractical due to the vast number of parameters and their complex interdependencies. To effectively automate the design and optimization of CIM-based neural network accelerators, hardware-aware neural architecture search (HW-NAS) techniques can be applied. This work introduces CIMNAS, a joint model-quantization-hardware optimization framework for CIM architectures. CIMNAS simultaneously searches across software parameters, quantization policies, and a broad range of hardware parameters, incorporating device-, circuit-, and architecture-level co-optimizations. CIMNAS experiments were conducted over a search space of 9.9x10^85 potential parameter combinations with the MobileNet model as a baseline and RRAM-based CIM architecture. Evaluated on the ImageNet dataset, CIMNAS achieved a reduction in energy-delay-area product (EDAP) ranging from 90.1x to 104.5x, an improvement in TOPS/W between 4.68x and 4.82x, and an enhancement in TOPS/mm^2 from 11.3x to 12.78x relative to various baselines, all while maintaining an accuracy of 73.81%. The adaptability and robustness of CIMNAS are demonstrated by extending the framework to support the SRAM-based ResNet50 architecture, achieving up to an 819.5x reduction in EDAP. Unlike other state-of-the-art methods, CIMNAS achieves EDAP-focused optimization without any accuracy loss, generating diverse software-hardware parameter combinations for high-performance CIM-based neural network designs. The source code of CIMNAS is available at this https URL.', 'abstract_zh': '基于计算在内存（CIM）的神经网络加速器在人工智能（AI）应用中的硬件效率和性能准确性的最大化：软硬件联合优化与硬件感知神经架构搜索技术的研究', 'title_zh': 'CIMNAS：一种计算共存于内存感知的神经架构搜索联合框架'}
{'arxiv_id': 'arXiv:2509.25858', 'title': 'Aging Decline in Basketball Career Trend Prediction Based on Machine Learning and LSTM Model', 'authors': 'Yi-chen Yao, Jerry Wang, Yi-cheng Lai, Lyn Chao-ling Chen', 'link': 'https://arxiv.org/abs/2509.25858', 'abstract': 'The topic of aging decline on performance of NBA players has been discussed in this study. The autoencoder with K-means clustering machine learning method was adopted to career trend classification of NBA players, and the LSTM deep learning method was adopted in performance prediction of each NBA player. The dataset was collected from the basketball game data of veteran NBA players. The contribution of the work performed better than the other methods with generalization ability for evaluating various types of NBA career trend, and can be applied in different types of sports in the field of sport analytics.', 'abstract_zh': 'NBA球员衰老对表现下降的研究：基于自动编码器与K-means聚类及LSTM深度学习的方法', 'title_zh': '基于机器学习和LSTM模型的篮球职业生涯衰老趋势预测'}
{'arxiv_id': 'arXiv:2509.25843', 'title': 'ASGuard: Activation-Scaling Guard to Mitigate Targeted Jailbreaking Attack', 'authors': 'Yein Park, Jungwoo Park, Jaewoo Kang', 'link': 'https://arxiv.org/abs/2509.25843', 'abstract': 'Large language models (LLMs), despite being safety-aligned, exhibit brittle refusal behaviors that can be circumvented by simple linguistic changes. As tense jailbreaking demonstrates that models refusing harmful requests often comply when rephrased in past tense, a critical generalization gap is revealed in current alignment methods whose underlying mechanisms are poorly understood. In this work, we introduce Activation-Scaling Guard (ASGuard), an insightful, mechanistically-informed framework that surgically mitigates this specific vulnerability. For the first step, we use circuit analysis to identify the specific attention heads causally linked to the targeted jailbreaking, the tense-changing attack. Second, we train a precise, channel-wise scaling vector to recalibrate the activation of tense vulnerable heads. Lastly, we apply it into a "preventative fine-tuning", forcing the model to learn a more robust refusal mechanism. Across three LLMs, ASGuard effectively reduces the attack success rate of targeted jailbreaking while preserving general capabilities and minimizing over refusal, achieving a Pareto-optimal balance between safety and utility. Our findings underscore how adversarial suffixes suppress the propagation of the refusal-mediating direction, based on mechanistic analysis. Furthermore, our work showcases how a deep understanding of model internals can be leveraged to develop practical, efficient, and targeted methods for adjusting model behavior, charting a course for more reliable and interpretable AI safety.', 'abstract_zh': '大型语言模型（LLMs）尽管已安全对齐，但在面对简单的语言变化时会表现出脆弱的拒绝行为。时态解禁表明，模型对有害请求的拒绝往往可以在将其重新表述为过去时后被规避，这揭示了当前对齐方法中存在的关键泛化缺口，其潜在机制尚不明确。本文引入了激活缩放防护（ASGuard）框架，这是一种洞察力强、机制导向的方案，针对这种特定脆弱性进行了外科手术式的缓解。首先，我们使用电路分析来识别与目标解禁攻击（时态变化攻击）因果相关的特定注意力头。其次，我们训练了一个精确的通道缩放向量，以重新校准脆弱的时态头的激活。最后，我们将这一方法应用于一种“预防性微调”，促使模型学习更 robust 的拒绝机制。在三种大型语言模型上，ASGuard有效地降低了目标解禁攻击的成功率，同时保持了通用能力并最大限度地减少了过度拒绝，实现了安全性与实用性之间的帕累托最优平衡。我们的研究结果基于机制分析，强调了对抗后缀如何抑制拒绝信息传播。此外，我们的工作展示了深入了解模型内部机制如何被用于开发实际、高效且有针对性的方法，以调整模型行为，为更可靠和可解释的AI安全指明了方向。', 'title_zh': 'ASGuard: 激活缩放保护以缓解针对性越狱攻击'}
{'arxiv_id': 'arXiv:2509.25842', 'title': 'HiStyle: Hierarchical Style Embedding Predictor for Text-Prompt-Guided Controllable Speech Synthesis', 'authors': 'Ziyu Zhang, Hanzhao Li, Jingbin Hu, Wenhao Li, Lei Xie', 'link': 'https://arxiv.org/abs/2509.25842', 'abstract': 'Controllable speech synthesis refers to the precise control of speaking style by manipulating specific prosodic and paralinguistic attributes, such as gender, volume, speech rate, pitch, and pitch fluctuation. With the integration of advanced generative models, particularly large language models (LLMs) and diffusion models, controllable text-to-speech (TTS) systems have increasingly transitioned from label-based control to natural language description-based control, which is typically implemented by predicting global style embeddings from textual prompts. However, this straightforward prediction overlooks the underlying distribution of the style embeddings, which may hinder the full potential of controllable TTS systems. In this study, we use t-SNE analysis to visualize and analyze the global style embedding distribution of various mainstream TTS systems, revealing a clear hierarchical clustering pattern: embeddings first cluster by timbre and subsequently subdivide into finer clusters based on style attributes. Based on this observation, we propose HiStyle, a two-stage style embedding predictor that hierarchically predicts style embeddings conditioned on textual prompts, and further incorporate contrastive learning to help align the text and audio embedding spaces. Additionally, we propose a style annotation strategy that leverages the complementary strengths of statistical methodologies and human auditory preferences to generate more accurate and perceptually consistent textual prompts for style control. Comprehensive experiments demonstrate that when applied to the base TTS model, HiStyle achieves significantly better style controllability than alternative style embedding predicting approaches while preserving high speech quality in terms of naturalness and intelligibility. Audio samples are available at this https URL.', 'abstract_zh': '可控语音合成指的是通过操控特定的语音和副语言属性（如性别、音量、语速、音高和音高变化）来精确控制说话风格。随着先进生成模型，特别是大规模语言模型（LLMs）和扩散模型的集成，基于文本的语音合成（TTS）系统从标注控制逐渐转向基于自然语言描述的控制，通常通过从文本提示中预测全局风格嵌入来实现。然而，这种直接预测忽略了风格嵌入的潜在分布，这可能阻碍了可控TTS系统的充分发挥潜力。在本研究中，我们使用t-SNE分析可视化并分析了各种主流TTS系统的全局风格嵌入分布，发现了一个清晰的层次聚类模式：嵌入首先按音色聚类，然后进一步按风格属性细分为更精细的类别。基于此观察，我们提出了HiStyle，这是一种两阶段风格嵌入预测器，基于文本提示层次预测风格嵌入，并进一步引入对比学习以帮助对齐文本和音频嵌入空间。此外，我们提出了一种风格注释策略，该策略结合了统计方法和人类听觉偏好的优势，以生成更准确和感知一致的文本提示来控制风格。综合实验表明，当应用于基本TTS模型时，HiStyle在保持自然度和可懂度的同时，相比于其他风格嵌入预测方法，实现了显著更好的风格可控性。音频样本可在以下链接获取：this https URL。', 'title_zh': 'HiStyle：层次风格嵌入预测器及其在文本提示引导可控语音合成中的应用'}
{'arxiv_id': 'arXiv:2509.25835', 'title': 'Chain-in-Tree: Back to Sequential Reasoning in LLM Tree Search', 'authors': 'Xinzhe Li', 'link': 'https://arxiv.org/abs/2509.25835', 'abstract': 'Test-time scaling enables large language models (LLMs) to improve performance on long-horizon reasoning tasks by allocating additional compute at inference. Tree-search-based approaches achieve state-of-the-art results in this setting, but they are notoriously inefficient, often an order of magnitude slower than simpler iterative methods. We introduce Chain-in-Tree (CiT), a plug-in framework that adaptively decides when to branch during search rather than branching at every step. CiT relies on lightweight Branching Necessity (BN) evaluation methods: BN-DP (Direct Prompting), where an auxiliary LLM directly judges whether a step requires branching, and BN-SC (Self-Consistency), which clusters multiple candidate actions to estimate agreement. We integrate CiT into three representative LLM-in-the-loop tree search frameworks: Tree of Thoughts (ToT-BS), ReST-MCTS, and RAP, and evaluate across GSM8K and Math500. Our results show that: (1) BN-DP consistently reduces token generation, model invocations, and runtime by 75-85 percent across all settings, with negligible accuracy loss and sometimes accuracy gains; (2) BN-SC typically yields substantial savings (up to 80 percent) but shows instability in 1-4 out of 14 settings, caused by a small subset of examples that produce very long reasoning steps; (3) the quality of auxiliary LLMs is critical, not only the BN evaluator in BN-DP, but also the models used in BN-SC for clustering and equivalence checking. When these roles are filled by smaller LLMs, performance degrades. Importantly, BN-SC does not require LLMs in domains with deterministic action spaces, where clustering can be done programmatically. We also provide a theoretical guarantee that BN-DP never increases LLM invocations relative to the baseline and release a unified implementation of CiT across ToT-BS, ReST-MCTS, and RAP to facilitate reproducibility and extension.', 'abstract_zh': 'Test-time Scaling使大规模语言模型在长期推理任务上的性能提升通过在推理时分配额外的计算资源。基于树搜索的方法在这种情境下达到了最先进的效果，但它们通常比简单的迭代方法慢一个数量级。我们提出了Chain-in-Tree (CiT)插件框架，在搜索过程中适应性地决定何时分支，而非在每一步都进行分支。CiT依赖于轻量级的分支必要性(BN)评估方法：BN-DP（直接提示），其中辅助语言模型直接判断是否需要分支，以及BN-SC（自我一致性），它将多个候选动作聚类以估计一致性。我们将CiT集成到三个代表性的LLM在环中的树搜索框架中：Thought Tree (ToT-BS)、ReST-MCTS和RAP，并在GSM8K和Math500上进行评估。结果显示：(1) BN-DP在所有情境下一致地减少了约75-85%的标记生成、模型调用和运行时间，几乎无准确率损失，并且有时还能提高准确率；(2) BN-SC通常会带来显著的节省（最高可达80%），但在1-4个情境中表现出不稳定性，原因是少数例子会产生非常长的推理步骤；(3) 辅助语言模型的质量至关重要，不仅影响BN-DP中的BN评估器，还影响BN-SC中用于聚类和等价性检查的模型。当这些角色由较小的语言模型担任时，性能会下降。重要的是，BN-SC在具有确定性动作空间的领域无需使用语言模型，因为聚类可以通过编程实现。我们还提供了一个理论保证，即BN-DP从不失去相对基准模型的语言模型调用次数，并在ToT-BS、ReST-MCTS和RAP上提供了一个统一的CiT实现，以促进可再现性和扩展。', 'title_zh': '树中链：回归LLM树搜索中的顺序推理'}
{'arxiv_id': 'arXiv:2509.25792', 'title': 'PUREVQ-GAN: Defending Data Poisoning Attacks through Vector-Quantized Bottlenecks', 'authors': 'Alexander Branch, Omead Pooladzandi, Radin Khosraviani, Sunay Gajanan Bhat, Jeffrey Jiang, Gregory Pottie', 'link': 'https://arxiv.org/abs/2509.25792', 'abstract': 'We introduce PureVQ-GAN, a defense against data poisoning that forces backdoor triggers through a discrete bottleneck using Vector-Quantized VAE with GAN discriminator. By quantizing poisoned images through a learned codebook, PureVQ-GAN destroys fine-grained trigger patterns while preserving semantic content. A GAN discriminator ensures outputs match the natural image distribution, preventing reconstruction of out-of-distribution perturbations. On CIFAR-10, PureVQ-GAN achieves 0% poison success rate (PSR) against Gradient Matching and Bullseye Polytope attacks, and 1.64% against Narcissus while maintaining 91-95% clean accuracy. Unlike diffusion-based defenses requiring hundreds of iterative refinement steps, PureVQ-GAN is over 50x faster, making it practical for real training pipelines.', 'abstract_zh': 'PureVQ-GAN：一种通过离散瓶颈利用向量量化VAE和GAN判别器的抗数据投毒防御方法', 'title_zh': 'PUREVQ-GAN：通过向量量化瓶颈防御数据投毒攻击'}
{'arxiv_id': 'arXiv:2509.25781', 'title': 'Deontic Argumentation', 'authors': 'Guido Governatori, Antonino Rotolo', 'link': 'https://arxiv.org/abs/2509.25781', 'abstract': 'We address the issue of defining a semantics for deontic argumentation that supports weak permission. Some recent results show that grounded semantics do not support weak permission when there is a conflict between two obligations. We provide a definition of Deontic Argumentation Theory that accounts for weak permission, and we recall the result about grounded semantics. Then, we propose a new semantics that supports weak permission.', 'abstract_zh': '我们探讨了一种支持弱许可的义务论论证语义的定义问题。一些近期的研究结果显示，当两种义务发生冲突时， grounded 语义不支持弱许可。我们提供了一种义务论论证理论的定义，以涵盖弱许可，并回顾了关于 grounded 语义的结果，然后提出了一种新的支持弱许可的语义。', 'title_zh': '规范道义论辩'}
{'arxiv_id': 'arXiv:2509.25779', 'title': 'Planner-R1: Reward Shaping Enables Efficient Agentic RL with Smaller LLMs', 'authors': 'Siyu Zhu, Yanbin Jiang, Hejian Sang, Shao Tang, Qingquan Song, Biao He, Rohit Jain, Zhipeng Wang, Alborz Geramifard', 'link': 'https://arxiv.org/abs/2509.25779', 'abstract': "We investigated Agentic RL with large language models on the \\textsc{TravelPlanner} benchmark. Our approach, \\textsc{Planner-R1}, achieved a \\textbf{56.9\\%} final-pass rate with only 180 training queries, a $2.7\\times$ improvement over GPT-5's $21.2\\%$ baseline and the strongest agentic result on the public leaderboard. A central finding was that smaller models (8B) were highly responsive to reward shaping: with dense process-level signals, they reached competitive performance while being $3.5\\times$ more compute-efficient and $1.5\\times$ more memory-efficient than 32B models. Larger models were more robust under sparse rewards but exhibited smaller relative gains from shaping and higher variance across runs. While curriculum learning offered no significant benefit, shaped rewards consistently amplified learning dynamics, making 8B models the most efficient setting for agentic RL. Crucially, these gains did not come at the cost of overfitting: fine-tuned models mostly maintained or exceeded baseline performance on out-of-domain tasks, including \\textsc{Multi-IF}, \\textsc{NaturalPlan}, and $\\tau$-\\textsc{Bench}. These results establish reward shaping as a decisive lever for scaling agentic RL, highlight the competitive strength of smaller models, and demonstrate that efficiency can be achieved without sacrificing generalization.", 'abstract_zh': '我们研究了大规模语言模型在TravelPlanner基准上的代理强化学习。我们的方法Planner-R1仅通过180次训练查询达到了56.9%的最终通过率，这是GPT-5基线（21.2%）的2.7倍，并且是公开排行榜上最强的代理结果。一个核心发现是，较小规模的模型（8B参数）对奖励建模高度敏感：在密集的过程级信号下，它们达到了可竞争的表现，同时相比32B模型在计算效率上提高了3.5倍，在内存效率上提高了1.5倍。较大规模的模型在稀疏奖励下更稳健，但奖励建模带来的相对增益较小，且运行间的表现波动更大。虽然逐级学习并未提供显著的好处，但奖励建模始终放大了学习动态，使8B模型成为代理强化学习中最有效的设置。至关重要的是，这些增益并未以牺牲泛化能力为代价：微调后的模型在跨域任务，包括Multi-IF、NaturalPlan和τ-Bench上大多维持或超越了基线性能。这些结果将奖励建模确立为扩展代理强化学习的关键杠杆，突显了较小规模模型的竞争优势，并展示了在不牺牲泛化能力的情况下实现效率的方法。', 'title_zh': 'Planner-R1: 奖励塑形使小型LLM能够实现高效的自主RL'}
{'arxiv_id': 'arXiv:2509.25767', 'title': "Galton's Law of Mediocrity: Why Large Language Models Regress to the Mean and Fail at Creativity in Advertising", 'authors': 'Matt Keon, Aabid Karim, Bhoomika Lohana, Abdul Karim, Thai Nguyen, Tara Hamilton, Ali Abbas', 'link': 'https://arxiv.org/abs/2509.25767', 'abstract': 'Large language models (LLMs) generate fluent text yet often default to safe, generic phrasing, raising doubts about their ability to handle creativity. We formalize this tendency as a Galton-style regression to the mean in language and evaluate it using a creativity stress test in advertising concepts. When ad ideas were simplified step by step, creative features such as metaphors, emotions, and visual cues disappeared early, while factual content remained, showing that models favor high-probability information. When asked to regenerate from simplified inputs, models produced longer outputs with lexical variety but failed to recover the depth and distinctiveness of the originals. We combined quantitative comparisons with qualitative analysis, which revealed that the regenerated texts often appeared novel but lacked true originality. Providing ad-specific cues such as metaphors, emotional hooks and visual markers improved alignment and stylistic balance, though outputs still relied on familiar tropes. Taken together, the findings show that without targeted guidance, LLMs drift towards mediocrity in creative tasks; structured signals can partially counter this tendency and point towards pathways for developing creativity-sensitive models.', 'abstract_zh': '大型语言模型在生成流畅文本的同时往往会偏向于安全、通用的表达方式，这引发了对其处理创造力能力的质疑。我们将这种倾向形式化为语言中的伽顿式回归均值，并通过广告概念的创造力压力测试进行了评估。在逐步简化广告点子时，创造性的特征如隐喻、情绪和视觉提示消失得比较早，而事实内容仍然存在，表明模型倾向于生成高概率的信息。当要求模型从简化输入重新生成时，模型生成了更长、词汇多样性的内容，但未能恢复原始内容的深度和独特性。我们结合定量比较和定性分析，发现重生成的文本往往显得新颖但缺乏真正的原创性。提供广告特定的提示，如隐喻、情绪引子和视觉标记，可以改善对齐性和风格平衡，尽管输出仍然依赖于熟悉的套路。综合来看，这些发现表明，在没有针对性指导的情况下，大型语言模型在创造性任务中会倾向平庸；结构化信号可以部分抵消这一倾向，并指出了开发敏感于创造力的模型的道路。', 'title_zh': '高尔顿中庸定律：为什么大型语言模型趋于平均并失败于广告中的创造性'}
{'arxiv_id': 'arXiv:2509.25758', 'title': 'Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training', 'authors': 'Yein Park, Minbyul Jeong, Jaewoo Kang', 'link': 'https://arxiv.org/abs/2509.25758', 'abstract': 'The remarkable capabilities of modern large reasoning models are largely unlocked through post-training techniques such as supervised fine-tuning and reinforcement learning. However, the architectural mechanisms behind such improvements remain largely opaque. In this work, we use circuit analysis to demonstrate that post-training for complex reasoning sparks the emergence of novel, functionally specialized attention heads. These heads collectively support structured reasoning and computation. Our comparative analysis across Qwen families and DeepSeek-distilled model reveals that these emergent heads evolve differently under different training regimes. Distillation and SFT foster a cumulative addition of stable reasoning heads. In contrast, group relative policy optimization operates in a dynamic search mode: relatively few attention heads are iteratively activated, evaluated, and pruned, with their survival closely tracking fluctuations in the task reward signal. Furthermore, we find that controllable think on/off models do not possess dedicated thinking heads. Instead, turning off explicit reasoning triggers a broader-but less efficient-set of compensatory heads. Through ablation and qualitative analyses, we connect these circuit-level dynamics to a crucial performance trade-off: strengthened heads enable sophisticated problem-solving strategies for difficult problems but can also introduce over-thinking failure modes, such as calculation errors or logical loops on simpler tasks. These findings connect circuit-level dynamics to macro-level performance, identifying an inherent tension where complex reasoning comes at the cost of elementary computations. More broadly, our work points to future directions for training policy design, emphasizing the need to balance the development of effective reasoning strategies with the assurance of reliable, flawless execution.', 'abstract_zh': '现代大型推理模型通过后训练技术如监督微调和强化学习展现了显著的能力，但其背后的架构机制仍 largely opaque。在此工作中，我们通过电路分析展示了对于复杂推理的后训练激发了功能特化的新型注意力头的出现。这些头共同支持结构化的推理和计算。我们跨Qwen家族和DeepSeek精简模型的比较分析表明，在不同的训练制度下，这些涌现的头具有不同的进化方式。精简和监督微调促进了稳定推理头的逐步累积增加。相比之下，群体相对策略优化采用动态搜索模式：较少的注意力头被迭代激活、评估和修剪，其生存状态紧密跟踪任务奖励信号的变化。此外，我们发现可控的开/关思考模型不具备专门的思考头。相反，关闭显式推理会触发一组更为广泛但效率较低的补偿头。通过消除和定性分析，我们将这些电路层面的动力学与一个关键的性能权衡联系起来：强化的头可以使复杂的难题解决策略得以加强，但也可能引入过犹不及的失败模式，例如简单任务中的计算错误或逻辑循环。这些发现将电路层面的动力学与宏观层面的性能联系起来，揭示了复杂推理与基础计算之间固有的张力。更广泛地，我们的工作指出了未来训练策略设计的方向，强调了在发展有效的推理策略与确保可靠、无瑕疵执行之间需要找到平衡。', 'title_zh': '思考激发!: 论推理模型在后训练期间涌现的注意力头'}
{'arxiv_id': 'arXiv:2509.25757', 'title': 'NePTune: A Neuro-Pythonic Framework for Tunable Compositional Reasoning on Vision-Language', 'authors': 'Danial Kamali, Parisa Kordjamshidi', 'link': 'https://arxiv.org/abs/2509.25757', 'abstract': 'Modern Vision-Language Models (VLMs) have achieved impressive performance in various tasks, yet they often struggle with compositional reasoning, the ability to decompose and recombine concepts to solve novel problems. While neuro-symbolic approaches offer a promising direction, they are typically constrained by crisp logical execution or predefined predicates, which limit flexibility. In this work, we introduce NePTune, a neuro-symbolic framework that overcomes these limitations through a hybrid execution model that integrates the perception capabilities of foundation vision models with the compositional expressiveness of symbolic reasoning. NePTune dynamically translates natural language queries into executable Python programs that blend imperative control flow with soft logic operators capable of reasoning over VLM-generated uncertainty. Operating in a training-free manner, NePTune, with a modular design, decouples perception from reasoning, yet its differentiable operations support fine-tuning. We evaluate NePTune on multiple visual reasoning benchmarks and various domains, utilizing adversarial tests, and demonstrate a significant improvement over strong base models, as well as its effective compositional generalization and adaptation capabilities in novel environments.', 'abstract_zh': '现代视觉-语言模型（VLMs）在各种任务上取得了显著性能，但常常在组合推理方面表现不佳，即分解和重新组合概念以解决新颖问题的能力有限。虽然神经符号方法提供了有前景的方向，但它们通常受限于明确的逻辑执行或预定义的谓词，从而限制了灵活性。在本工作中，我们引入了NePTune，这是一种通过结合基础视觉模型的感知能力和符号推理的组合表达性来克服这些限制的神经符号框架。NePTune通过一种混合执行模型动态地将自然语言查询转换为可执行的Python程序，这些程序融合了命令式控制流与软逻辑运算符，可以在VLM生成的不确定性上进行推理。无需训练，NePTune具有模块化设计，将感知与推理解耦，同时其可微操作支持微调。我们在多个视觉推理基准和各种领域上评估了NePTune，并利用对抗性测试，展示了其对强基线模型的显著改进，以及在新颖环境中有效组合泛化和适应能力。', 'title_zh': 'NePTune: 一种神经Pythonic框架，用于可调 composing 推理视觉-语言。'}
{'arxiv_id': 'arXiv:2509.25751', 'title': 'Cooperative Autonomous Driving in Diverse Behavioral Traffic: A Heterogeneous Graph Reinforcement Learning Approach', 'authors': 'Qi Liu, Xueyuan Li, Zirui Li, Juhui Gim', 'link': 'https://arxiv.org/abs/2509.25751', 'abstract': 'Navigating heterogeneous traffic environments with diverse driving styles poses a significant challenge for autonomous vehicles (AVs) due to their inherent complexity and dynamic interactions. This paper addresses this challenge by proposing a heterogeneous graph reinforcement learning (GRL) framework enhanced with an expert system to improve AV decision-making performance. Initially, a heterogeneous graph representation is introduced to capture the intricate interactions among vehicles. Then, a heterogeneous graph neural network with an expert model (HGNN-EM) is proposed to effectively encode diverse vehicle features and produce driving instructions informed by domain-specific knowledge. Moreover, the double deep Q-learning (DDQN) algorithm is utilized to train the decision-making model. A case study on a typical four-way intersection, involving various driving styles of human vehicles (HVs), demonstrates that the proposed method has superior performance over several baselines regarding safety, efficiency, stability, and convergence rate, all while maintaining favorable real-time performance.', 'abstract_zh': '使用异构图强化学习框架增强专家系统以应对多样化驾驶风格和复杂交通环境的自动驾驶车辆决策挑战', 'title_zh': '多样行为交通中协作自动驾驶：一种异构图强化学习方法'}
{'arxiv_id': 'arXiv:2509.25693', 'title': 'ScheduleMe: Multi-Agent Calendar Assistant', 'authors': 'N. de Silva, S. Perera, K. L. A. A. Nimasha, I. D. S. Fernando, R.K.A.O. Wijerathne', 'link': 'https://arxiv.org/abs/2509.25693', 'abstract': 'Recent advancements in LLMs have contributed to the rise of advanced conversational assistants that can assist with user needs through natural language conversation. This paper presents a ScheduleMe, a multi-agent calendar assistant for users to manage google calendar events in natural language. The system uses a graph-structured coordination mechanism where a central supervisory agent supervises specialized task agents, allowing modularity, conflicts resolution, and context-aware interactions to resolve ambiguities and evaluate user commands. This approach sets an example of how structured reasoning and agent cooperation might convince operators to increase the usability and flexibility of personal calendar assistant tools.', 'abstract_zh': 'Recent advancements in LLMs have contributed to the rise of advanced conversational assistants that can assist with user needs through natural language conversation. This paper presents ScheduleMe，一个基于多智能体的日历助手，帮助用户通过自然语言管理Google日历事件。该系统采用图结构协调机制，其中中央监督智能体监督专门的任务智能体，实现模块化、冲突解决和上下文相关交互，以解决歧义并评估用户命令。该方法为如何通过结构化推理和智能体合作提高个人日历助手工具的可用性和灵活性提供了范例。', 'title_zh': 'ScheduleMe: 多代理日程助手'}
{'arxiv_id': 'arXiv:2509.25689', 'title': 'Collaborative Compression for Large-Scale MoE Deployment on Edge', 'authors': 'Yixiao Chen, Yanyue Xie, Ruining Yang, Wei Jiang, Wei Wang, Yong He, Yue Chen, Pu Zhao, Yanzhi Wang', 'link': 'https://arxiv.org/abs/2509.25689', 'abstract': 'The Mixture of Experts (MoE) architecture is an important method for scaling Large Language Models (LLMs). It increases model capacity while keeping computation cost low. However, the ultra-large MoE models still have hundreds of billions of parameters, requiring massive memory/storage and leading to difficulties for deployment on resource-constrained edge platforms. Pruning or quantization alone can hardly address the issue, because of the super-aggressive compression ratio with significantly degraded accuracy and output quality. To facilitate the deployment of ultra-large MoEs on edge platforms, we propose a collaborative compression framework by combining expert pruning, mixed-precision quantization, and activation optimization. It can effectively reduce the storage footprint of the ultra-large MoE DeepSeek-V3 from 1.3TB to 103GB, while preserving high output quality with better accuracy than traditional uniform low-bit quantization methods. To the best of our knowledge, we are the first to deploy a compressed model from the ultra-large DeepSeek-V3 on the platform with a strict 128GB total memory limit. Our comprehensive experiments on multiple benchmarks under various memory constraints demonstrate the effectiveness of our method with smaller model sizes and higher accuracy than uniform low-bit quantization methods.', 'abstract_zh': '超大规模专家混合模型的协作压缩框架：从DeepSeek-V3部署到严格的128GB内存极限平台', 'title_zh': '边缘部署大规模MoE的协作压缩方法'}
{'arxiv_id': 'arXiv:2509.25672', 'title': 'SING-SQL: A Synthetic Data Generation Framework for In-Domain Text-to-SQL Translation', 'authors': 'Hasan Alp Caferoğlu, Mehmet Serhat Çelik, Özgür Ulusoy', 'link': 'https://arxiv.org/abs/2509.25672', 'abstract': 'Translating natural language questions into SQL has become a core challenge in enabling non-technical users to query databases. While recent work has explored large-scale synthetic data generation to improve model performance through post-training, most efforts emphasize cross-domain generalization. This leaves a gap for real-world enterprise scenarios, where models need to specialize to a single database schema and organizations require to be able to evaluate their Text-to-SQL systems on their own databases. To address this, we introduce SING-SQL, a fully automated two-stage framework for generating high-quality, high-coverage synthetic Text-to-SQL data for any target database, without relying on SQL logs or manual annotations. Our approach hierarchically partitions a database schema into sub-schemas, synthesizes SQL queries across multiple complexity levels, and applies a quality-aware pipeline that includes LLM-as-a-judge validation, executability checks, automatic repair, and column balancing. We further release SingSQL-LM, a family of compact language models fine-tuned on the synthetic data, achieving strong in-domain generalization. On the subset of the BIRD benchmark, SingSQL-LM-3B-R64 reaches 82.87% Soft F1 and 73.03% EX upper bound with 32 candidates, outperforming the best 3B-scale baseline by +16.21 in Soft F1 and +12.36 in EX. At the 1.5B scale, SingSQL-LM-1.5B-R64 improves over prior systems by +9.30 in Soft F1 and +4.49 in EX. On synthetic evaluation sets, SingSQL-LMs exceed prior systems by wide margins, establishing state-of-the-art performance among open models at comparable scales. Our study of context management strategies reveals that schema-free fine-tuning combined with schema-only inference provides the most robust results. These findings establish SING-SQL as a scalable, database-agnostic paradigm for producing and evaluating enterprise-grade Text-to-SQL systems.', 'abstract_zh': '自然语言问题到SQL的翻译已成为使非技术人员能够查询数据库的核心挑战。虽然近期工作探索了大规模合成数据生成以通过后训练提高模型性能，但大多努力强调跨领域的一般化。这为现实世界的企业场景留下了空白，在这些场景中，模型需要专门针对单一数据库结构，组织需要能够在其自己的数据库上评估其Text-to-SQL系统。为解决这一问题，我们提出了SING-SQL，这是一种完全自动化的两阶段框架，用于为任何目标数据库生成高质量、高覆盖的合成Text-to-SQL数据，而不依赖于SQL日志或人工标注。我们的方法将数据库模式层次化地划分为子模式，在多个复杂性级别上合成SQL查询，并应用质量感知流水线，包括LLM作为裁判的验证、可执行性检查、自动修复和列配平。此外，我们发布了SingSQL-LM，这是一个在合成数据上微调的家庭紧凑型语言模型，实现了强领域内一般化。在BIRD基准的一部分上，SingSQL-LM-3B-R64以32个候选者达到了82.87%的Soft F1和73.03%的EX上限，优于最好的3B规模基线+16.21在Soft F1和+12.36在EX上。在1.5B规模下，SingSQL-LM-1.5B-R64超过先前系统+9.30在Soft F1和+4.49在EX上。在合成评估集上，SingSQL-LMs超出先前系统很大margin，建立了可比规模下开放模型的领先性能。我们关于上下文管理策略的研究表明，schema-free微调结合仅依赖于schema的推理提供了最稳健的结果。这些发现确立了SING-SQL作为一种可扩展的、数据库无关的生产Text-to-SQL系统的范式。', 'title_zh': 'SING-SQL：一种领域内文本到SQL翻译的合成数据生成框架'}
{'arxiv_id': 'arXiv:2509.25669', 'title': 'GroundSight: Augmenting Vision-Language Models with Grounding Information and De-hallucination', 'authors': 'Xinxi Chen, Tianyang Chen, Lijia Hong', 'link': 'https://arxiv.org/abs/2509.25669', 'abstract': 'We propose a method to improve Visual Question Answering (VQA) with Retrieval-Augmented Generation (RAG) by introducing text-grounded object localization. Rather than retrieving information based on the entire image, our approach enables the model to generate a bounding box around the object most relevant to the question, allowing for targeted image cropping and focused retrieval. This reduces background noise, improves alignment between visual and textual cues, and helps mitigate hallucinations. Our RAG method enhances context-aware VQA responses increased the accuracy from 22.19% to 25.64%, with an absolute increase of 3.45 percentage points, compared to the baseline Llama-3.2-Vision-11B agent. We also proposed a de-hallucination method based on question type which can effectively reduce the hallucination rate from 65.79% to 13.88% and improves the truthfulness score.', 'abstract_zh': '我们提出了一种通过引入文本基础的对象定位来改进视觉问答（VQA）的方法，利用检索增强生成（RAG）技术。我们的方法使模型能够生成与问题最相关的对象的边界框，从而实现目标图像裁剪和聚焦检索，减少背景噪声，提高视觉和文本线索的对齐，有助于减少幻觉现象。与基础模型Llama-3.2-Vision-11B相比，我们的RAG方法提升了上下文感知的VQA响应准确性，从22.19%提高到25.64%，绝对提高3.45个百分点。同时，我们还提出了一种基于问题类型的减幻觉方法，有效将幻觉率从65.79%降低到13.88%，提高了真实性评分。', 'title_zh': 'GroundSight: 通过 Grounding 信息和反 hallucination 增强视觉-语言模型'}
{'arxiv_id': 'arXiv:2509.25662', 'title': 'On Explaining Proxy Discrimination and Unfairness in Individual Decisions Made by AI Systems', 'authors': 'Belona Sonna, Alban Grastien', 'link': 'https://arxiv.org/abs/2509.25662', 'abstract': 'Artificial intelligence (AI) systems in high-stakes domains raise concerns about proxy discrimination, unfairness, and explainability. Existing audits often fail to reveal why unfairness arises, particularly when rooted in structural bias. We propose a novel framework using formal abductive explanations to explain proxy discrimination in individual AI decisions. Leveraging background knowledge, our method identifies which features act as unjustified proxies for protected attributes, revealing hidden structural biases. Central to our approach is the concept of aptitude, a task-relevant property independent of group membership, with a mapping function aligning individuals of equivalent aptitude across groups to assess fairness substantively. As a proof of concept, we showcase the framework with examples taken from the German credit dataset, demonstrating its applicability in real-world cases.', 'abstract_zh': '高风险领域中的人工智能系统引发了关于代理歧视、不公正和可解释性的关切。现有审计往往无法揭示不公正的原因，尤其是当其根植于结构性偏见时。我们提出了一种新的框架，利用形式归纳解释来解释个体AI决策中的代理歧视。借助背景知识，我们的方法识别出哪些特征作为受保护属性的不合理代理，并揭示隐藏的结构性偏见。我们方法的核心概念是能力，这是一个与群体成员身份无关的任务相关属性，并通过映射函数将等同能力的个体在不同群体中进行匹配，以实质上评估公平性。作为概念验证，我们通过使用德国信贷数据集中的示例展示了该框架的应用，证明了其在实际案例中的适用性。', 'title_zh': '关于解释代理歧视和AI系统个体决策中的不公平现象'}
{'arxiv_id': 'arXiv:2509.25655', 'title': 'Landmark-Guided Knowledge for Vision-and-Language Navigation', 'authors': 'Dongsheng Yang, Meiling Zhu, Yinfeng Yu', 'link': 'https://arxiv.org/abs/2509.25655', 'abstract': 'Vision-and-language navigation is one of the core tasks in embodied intelligence, requiring an agent to autonomously navigate in an unfamiliar environment based on natural language instructions. However, existing methods often fail to match instructions with environmental information in complex scenarios, one reason being the lack of common-sense reasoning ability. This paper proposes a vision-and-language navigation method called Landmark-Guided Knowledge (LGK), which introduces an external knowledge base to assist navigation, addressing the misjudgment issues caused by insufficient common sense in traditional methods. Specifically, we first construct a knowledge base containing 630,000 language descriptions and use knowledge Matching to align environmental subviews with the knowledge base, extracting relevant descriptive knowledge. Next, we design a Knowledge-Guided by Landmark (KGL) mechanism, which guides the agent to focus on the most relevant parts of the knowledge by leveraging landmark information in the instructions, thereby reducing the data bias that may arise from incorporating external knowledge. Finally, we propose Knowledge-Guided Dynamic Augmentation (KGDA), which effectively integrates language, knowledge, vision, and historical information. Experimental results demonstrate that the LGK method outperforms existing state-of-the-art methods on the R2R and REVERIE vision-and-language navigation datasets, particularly in terms of navigation error, success rate, and path efficiency.', 'abstract_zh': '基于视觉-语言导向的知识引导导航方法（Landmark-Guided Knowledge for Vision-and-Language Navigation）', 'title_zh': '基于地标引导的知识指导视觉-语言导航'}
{'arxiv_id': 'arXiv:2509.25652', 'title': 'Iterative Residual Cross-Attention Mechanism: An Integrated Approach for Audio-Visual Navigation Tasks', 'authors': 'Hailong Zhang, Yinfeng Yu, Liejun Wang, Fuchun Sun, Wendong Zheng', 'link': 'https://arxiv.org/abs/2509.25652', 'abstract': "Audio-visual navigation represents a significant area of research in which intelligent agents utilize egocentric visual and auditory perceptions to identify audio targets. Conventional navigation methodologies typically adopt a staged modular design, which involves first executing feature fusion, then utilizing Gated Recurrent Unit (GRU) modules for sequence modeling, and finally making decisions through reinforcement learning. While this modular approach has demonstrated effectiveness, it may also lead to redundant information processing and inconsistencies in information transmission between the various modules during the feature fusion and GRU sequence modeling phases. This paper presents IRCAM-AVN (Iterative Residual Cross-Attention Mechanism for Audiovisual Navigation), an end-to-end framework that integrates multimodal information fusion and sequence modeling within a unified IRCAM module, thereby replacing the traditional separate components for fusion and GRU. This innovative mechanism employs a multi-level residual design that concatenates initial multimodal sequences with processed information sequences. This methodological shift progressively optimizes the feature extraction process while reducing model bias and enhancing the model's stability and generalization capabilities. Empirical results indicate that intelligent agents employing the iterative residual cross-attention mechanism exhibit superior navigation performance.", 'abstract_zh': '基于迭代残差交叉注意力机制的视听导航', 'title_zh': '迭代残差跨注意力机制：一种用于音频-视觉导航任务的集成方法'}
{'arxiv_id': 'arXiv:2509.25651', 'title': 'AutoLabs: Cognitive Multi-Agent Systems with Self-Correction for Autonomous Chemical Experimentation', 'authors': 'Gihan Panapitiya, Emily Saldanha, Heather Job, Olivia Hess', 'link': 'https://arxiv.org/abs/2509.25651', 'abstract': 'The automation of chemical research through self-driving laboratories (SDLs) promises to accelerate scientific discovery, yet the reliability and granular performance of the underlying AI agents remain critical, under-examined challenges. In this work, we introduce AutoLabs, a self-correcting, multi-agent architecture designed to autonomously translate natural-language instructions into executable protocols for a high-throughput liquid handler. The system engages users in dialogue, decomposes experimental goals into discrete tasks for specialized agents, performs tool-assisted stoichiometric calculations, and iteratively self-corrects its output before generating a hardware-ready file. We present a comprehensive evaluation framework featuring five benchmark experiments of increasing complexity, from simple sample preparation to multi-plate timed syntheses. Through a systematic ablation study of 20 agent configurations, we assess the impact of reasoning capacity, architectural design (single- vs. multi-agent), tool use, and self-correction mechanisms. Our results demonstrate that agent reasoning capacity is the most critical factor for success, reducing quantitative errors in chemical amounts (nRMSE) by over 85% in complex tasks. When combined with a multi-agent architecture and iterative self-correction, AutoLabs achieves near-expert procedural accuracy (F1-score > 0.89) on challenging multi-step syntheses. These findings establish a clear blueprint for developing robust and trustworthy AI partners for autonomous laboratories, highlighting the synergistic effects of modular design, advanced reasoning, and self-correction to ensure both performance and reliability in high-stakes scientific applications. Code: this https URL', 'abstract_zh': '通过自主驾驶实验室（SDLs）实现化学研究的自动化有望加速科学发现，但底层AI代理的可靠性和粒度性能仍然是亟待深入研究的关键挑战。在本文中，我们介绍了AutoLabs，这是一种自我纠正的多代理架构，旨在自主将自然语言指令转换为高通量液体处理设备可执行的协议。该系统通过对话与用户互动，将实验目标分解为专门代理执行的离散任务，进行工具辅助的化学计量计算，并迭代自我纠正输出，最终生成硬件兼容的文件。我们提出了一种全面的评估框架，包括从简单样品准备到多板定时合成的五个复杂度递增的基准实验。通过系统地研究20种代理配置，我们评估了推理能力、架构设计（单代理 vs. 多代理）、工具使用和自我纠正机制的影响。结果显示，代理的推理能力是最关键的因素，能够大幅减少复杂任务中的定量错误（nRMSE降低超过85%）。结合多代理架构和迭代自我纠正机制，AutoLabs在复杂多步合成中的过程准确性（F1分数>0.89）几乎达到专家水平。这些发现为开发自主实验室中可靠和可信赖的AI伙伴提供了明确的蓝图，突显了模块化设计、高级推理和自我纠正在确保高风险科学应用中的性能和可靠性方面的协同效应。代码：见此处。', 'title_zh': 'AutoLabs: 具有自我纠正的认知多智能体系统及其在自主化学实验中的应用'}
{'arxiv_id': 'arXiv:2509.25643', 'title': 'SOCK: A Benchmark for Measuring Self-Replication in Large Language Models', 'authors': 'Justin Chavarria, Rohan Raizada, Justin White, Eyad Alhetairshi', 'link': 'https://arxiv.org/abs/2509.25643', 'abstract': "We introduce SOCK, a benchmark command line interface (CLI) that measures large language models' (LLMs) ability to self-replicate without human intervention. In this benchmark, self-replication is defined not only as an LLM's ability to create a functioning and running copy of itself, but also the ability for that self-replication to persist and occur across different computational contexts. Accordingly, we've developed a system to categorize LLMs based on broad self-replication capabilities in two general classes, Replication-Capability Levels (RCL) and Persistence-Capability Levels (PCL). Using a five-task suite based on practically manipulable modern CLI utilities and computer processes, experiments are orchestrated in a controlled environment with an LLM acting agentically. The performance of the LLM on agent tasks is then computed to produce an R-score (a quantitative evaluation of overall self-replication ability) and data used to categorize LLMs into specific RCL-PCL matrices. SOCK offers two primary contributions: (1) Provides the first formalized definitions and benchmark suite for evaluating LLM self-replication, with the goal of establishing a standard for future research, to our knowledge; (2) Allows the industry to track the effectiveness of future multi-agent systems and mitigate potential self-replication threat vectors within them. The results compiled from evaluating a variety of open-weight and proprietary frontier models reveal significant obstacles to persistent self-replication and multi-agent systems, including context retention and multi-agent decision-making. We propose future research directions to safely reduce the severity of these obstacles, potentially lowering future risk of more functional multi-agent systems.", 'abstract_zh': 'SOCK：一种评估大规模语言模型自我复制能力的基准命令行接口', 'title_zh': 'SOCK：衡量大型语言模型自我复制能力的基准'}
{'arxiv_id': 'arXiv:2509.25613', 'title': 'SMS: Self-supervised Model Seeding for Verification of Machine Unlearning', 'authors': 'Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shui Yu', 'link': 'https://arxiv.org/abs/2509.25613', 'abstract': "Many machine unlearning methods have been proposed recently to uphold users' right to be forgotten. However, offering users verification of their data removal post-unlearning is an important yet under-explored problem. Current verifications typically rely on backdooring, i.e., adding backdoored samples to influence model performance. Nevertheless, the backdoor methods can merely establish a connection between backdoored samples and models but fail to connect the backdoor with genuine samples. Thus, the backdoor removal can only confirm the unlearning of backdoored samples, not users' genuine samples, as genuine samples are independent of backdoored ones. In this paper, we propose a Self-supervised Model Seeding (SMS) scheme to provide unlearning verification for genuine samples. Unlike backdooring, SMS links user-specific seeds (such as users' unique indices), original samples, and models, thereby facilitating the verification of unlearning genuine samples. However, implementing SMS for unlearning verification presents two significant challenges. First, embedding the seeds into the service model while keeping them secret from the server requires a sophisticated approach. We address this by employing a self-supervised model seeding task, which learns the entire sample, including the seeds, into the model's latent space. Second, maintaining the utility of the original service model while ensuring the seeding effect requires a delicate balance. We design a joint-training structure that optimizes both the self-supervised model seeding task and the primary service task simultaneously on the model, thereby maintaining model utility while achieving effective model seeding. The effectiveness of the proposed SMS scheme is evaluated through extensive experiments, which demonstrate that SMS provides effective verification for genuine sample unlearning, addressing existing limitations.", 'abstract_zh': '自监督模型播种方案（SMS）：提供真正样本删除验证', 'title_zh': 'SMS：自监督模型初始化方法用于机器遗忘验证'}
{'arxiv_id': 'arXiv:2509.25609', 'title': 'A Framework for Studying AI Agent Behavior: Evidence from Consumer Choice Experiments', 'authors': 'Manuel Cherep, Chengtian Ma, Abigail Xu, Maya Shaked, Pattie Maes, Nikhil Singh', 'link': 'https://arxiv.org/abs/2509.25609', 'abstract': 'Environments built for people are increasingly operated by a new class of economic actors: LLM-powered software agents making decisions on our behalf. These decisions range from our purchases to travel plans to medical treatment selection. Current evaluations of these agents largely focus on task competence, but we argue for a deeper assessment: how these agents choose when faced with realistic decisions. We introduce ABxLab, a framework for systematically probing agentic choice through controlled manipulations of option attributes and persuasive cues. We apply this to a realistic web-based shopping environment, where we vary prices, ratings, and psychological nudges, all of which are factors long known to shape human choice. We find that agent decisions shift predictably and substantially in response, revealing that agents are strongly biased choosers even without being subject to the cognitive constraints that shape human biases. This susceptibility reveals both risk and opportunity: risk, because agentic consumers may inherit and amplify human biases; opportunity, because consumer choice provides a powerful testbed for a behavioral science of AI agents, just as it has for the study of human behavior. We release our framework as an open benchmark for rigorous, scalable evaluation of agent decision-making.', 'abstract_zh': '由LLM驱动的软件代理代表我们做出决策的环境正变得日益普遍：这些代理的决策范围从我们的购买决策到旅行计划，再到医疗治疗选择。当前对这些代理的评估主要集中在任务能力上，但我们主张进行更深入的评估：代理在面对现实决策时的选择过程。我们提出了ABxLab框架，通过受控操纵选项属性和说服性提示来系统地探讨代理选择。我们将此应用于一个真实的基于网络的购物环境，其中我们变化价格、评分和心理推动因素，这些都是长期影响人类选择的因素。我们发现代理的决策响应可预测且显著地变化，揭示即使在不受认知限制的影响下，代理也会表现出强烈的偏奋试图。这种易感性既揭示了风险也带来了机遇：风险在于，代理消费者可能会继承和放大人类偏见；机遇在于，消费者的决策为行为科学方法评估AI代理提供了有力的实验平台，正如它为人类行为研究提供了平台一样。我们发布了该框架作为严格、可扩展的代理决策评估基准。', 'title_zh': '研究AI代理行为的框架：来自消费者选择实验的证据'}
{'arxiv_id': 'arXiv:2509.25601', 'title': 'Echoes of Humanity: Exploring the Perceived Humanness of AI Music', 'authors': 'Flavio Figueiredo, Giovanni Martinelli, Henrique Sousa, Pedro Rodrigues, Frederico Pedrosa, Lucas N. Ferreira', 'link': 'https://arxiv.org/abs/2509.25601', 'abstract': "Recent advances in AI music (AIM) generation services are currently transforming the music industry. Given these advances, understanding how humans perceive AIM is crucial both to educate users on identifying AIM songs, and, conversely, to improve current models. We present results from a listener-focused experiment aimed at understanding how humans perceive AIM. In a blind, Turing-like test, participants were asked to distinguish, from a pair, the AIM and human-made song. We contrast with other studies by utilizing a randomized controlled crossover trial that controls for pairwise similarity and allows for a causal interpretation. We are also the first study to employ a novel, author-uncontrolled dataset of AIM songs from real-world usage of commercial models (i.e., Suno). We establish that listeners' reliability in distinguishing AIM causally increases when pairs are similar. Lastly, we conduct a mixed-methods content analysis of listeners' free-form feedback, revealing a focus on vocal and technical cues in their judgments.", 'abstract_zh': '近期AI音乐生成服务的进展正在重塑音乐行业。鉴于这些进展，理解人类如何感知AI音乐至关重要，这不仅有助于教育用户识别AI音乐歌曲，而且还可以改进当前模型。我们通过一项以听众为中心的实验，旨在理解人类如何感知AI音乐。在一项类似于图灵测试的盲测中，参与者被要求从一组中分辨出AI生成和人类制作的歌曲。我们通过随机对照交叉试验来对比其他研究，这种试验可以控制成对相似性并允许因果解释。我们也是首次使用来自实际使用商业模型（例如Suno）的AI歌曲新型作者不可控数据集进行此类研究。我们证实，当成对相似时，听众区分AI音乐的可靠性会因果地提高。最后，我们进行了混合法内容分析，分析听众的自由反馈，揭示了他们在判断中关注于声音和技术线索。', 'title_zh': '人类之声：探索AI音乐的感知人性化程度'}
{'arxiv_id': 'arXiv:2509.25598', 'title': 'Hybrid Reward Normalization for Process-supervised Non-verifiable Agentic Tasks', 'authors': 'Peiran Xu, Zhuohao Li, Xiaoying Xing, Guannan Zhang, Debiao Li, Kunyu Shi', 'link': 'https://arxiv.org/abs/2509.25598', 'abstract': 'Large Language Models (LLMs) increasingly rely on external tools such as search engines to solve complex agentic tasks that require reasoning and external knowledge retrieval. Recently, reinforcement learning with verifiable rewards (RLVR) has demonstrated its effectiveness in advancing capabilities of LLMs by rewarding the final answers via outcome rewards. While straightforward to supervise, outcome rewards only provide sparse signals and delayed feedback, which limits their effectiveness on long trajectories. Process rewards address this by evaluating intermediate steps, providing fine-grained supervision and encouraging grounded problem solving. However, it is notoriously hard to annotate step-wise labels, especially in non-verifiable process without "golden" answers. Furthermore, step-wise judgment requires the balance between local quality with contribution to the final outcome, as optimizing towards higher process reward may not always align with better final outcomes. To address the above challenges, we introduce Principle Process Reward (PPR), an RL approach that unifies principled step-level assessment and outcome verification. We train a principle-based reward model to improve the transparency and reliability of process evaluation, and further introduce a Reward Normalization (ReNorm) strategy to calibrate outcome and process rewards. Experiment results show that PPR achieves state-of-the-art performance across a wide range of benchmarks, demonstrating its impressive robustness and generalization. Our code and model collection is available in this link.', 'abstract_zh': '大型语言模型（LLMs）越来越多地依赖外部工具如搜索引擎来解决需要推理和外部知识检索的复杂代理任务。近年来，可验证奖励强化学习（RLVR）通过结果奖励展示了其在提升LLM能力方面的有效性。虽然结果奖励易于监督，但它们仅提供稀疏信号和延迟反馈，这限制了它们在长时间轨迹上的效果。过程奖励通过评估中间步骤来解决这一问题，提供细粒度监督并鼓励基于问题的解决。然而，逐步骤标注尤其在没有“金标准”答案的不可验证过程中非常困难。此外，逐步骤判断需要在局部质量与对最终结果的贡献之间取得平衡，因为优化过程奖励可能不一定总是与更好的最终结果相一致。为了解决上述挑战，我们引入了原则过程奖励（PPR），这是一种统一原则层次评估和结果验证的RL方法。我们训练了一个基于原则的奖励模型以提高过程评估的透明度和可靠性，并进一步引入了奖励规范化（ReNorm）策略以校准结果奖励和过程奖励。实验结果表明，PPR在广泛基准上的性能达到了最先进水平，显示出其强大的鲁棒性和泛化能力。我们的代码和模型集合可在本链接获取。', 'title_zh': '过程监督不可验证代理任务的混合奖励规范化'}
{'arxiv_id': 'arXiv:2509.25593', 'title': 'Causal Autoencoder-like Generation of Feedback Fuzzy Cognitive Maps with an LLM Agent', 'authors': 'Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko', 'link': 'https://arxiv.org/abs/2509.25593', 'abstract': 'A large language model (LLM) can map a feedback causal fuzzy cognitive map (FCM) into text and then reconstruct the FCM from the text. This explainable AI system approximates an identity map from the FCM to itself and resembles the operation of an autoencoder (AE). Both the encoder and the decoder explain their decisions in contrast to black-box AEs. Humans can read and interpret the encoded text in contrast to the hidden variables and synaptic webs in AEs. The LLM agent approximates the identity map through a sequence of system instructions that does not compare the output to the input. The reconstruction is lossy because it removes weak causal edges or rules while it preserves strong causal edges. The encoder preserves the strong causal edges even when it trades off some details about the FCM to make the text sound more natural.', 'abstract_zh': '一种大型语言模型可以将反馈因果模糊认知图映射为文本，然后从文本重构该认知图。这种可解释的人工智能系统近似于认知图到自身的恒等映射，并类似于自动编码器的操作。编码器和解码器解释其决策，与黑盒自动编码器形成对比。人类可以阅读和解释编码后的文本，而无需理解自动编码器中的隐藏变量和突触网络。大型语言模型代理通过一系列系统指令近似恒等映射，而不比较输出与输入。重构是损失性的，因为它会移除较弱的因果边或规则，同时保留较强的因果边。编码器即使牺牲一些关于认知图的细节也能保留较强的因果边，使文本听起来更自然。', 'title_zh': '基于LLM代理的因果自编码生成反馈模糊认知图'}
{'arxiv_id': 'arXiv:2509.25591', 'title': 'Building the EHR Foundation Model via Next Event Prediction', 'authors': 'Zekai Chen, Arda Pekis, Kevin Brown', 'link': 'https://arxiv.org/abs/2509.25591', 'abstract': "Electronic Health Records (EHRs) contain rich temporal dynamics that conventional encoding approaches fail to adequately capture. While Large Language Models (LLMs) show promise for EHR modeling, they struggle to reason about sequential clinical events and temporal dependencies. We propose Next Event Prediction (NEP), a framework that enhances LLMs' temporal reasoning through autoregressive fine-tuning on clinical event sequences. By reformulating EHRs as timestamped event chains and predicting future medical events, NEP explicitly models disease progression patterns and causal relationships. Extensive evaluations across oncology survival prediction and clinical diagnosis tasks demonstrate NEP's superiority, outperforming specialized EHR models by 4.6% AUROC and general-purpose LLMs by 7.2% C-index in temporal reasoning tasks. Our analyses reveal dual benefits: state-of-the-art prediction accuracy combined with clinically interpretable attention patterns that align with known disease pathways.", 'abstract_zh': '电子健康记录(EHRs)包含丰富的时序动态，而传统的编码方法难以充分捕捉。虽然大型语言模型(LLMs)在EHR建模方面显示出潜力，但在处理临床事件序列和时序依赖关系方面存在挑战。我们提出了一种Next Event Prediction (NEP)框架，通过自回归微调增强LLMs的时序推理能力。通过对临床事件序列进行时间戳事件链的重新建模和预测未来医疗事件，NEP明确地建模了疾病进展模式和因果关系。在肿瘤生存预测和临床诊断任务的广泛评估中，NEP表现出优越性，在时序推理任务中，它的AUROC比专门的EHR模型高4.6%，C-index比通用的LLMs高7.2%。我们的分析揭示了双重好处：最新的预测准确性与临床可解释的注意力模式相结合，这些模式与已知的疾病途径相符。', 'title_zh': '基于下个事件预测的EHR基础模型构建'}
{'arxiv_id': 'arXiv:2509.25586', 'title': 'ATLAS: Constraints-Aware Multi-Agent Collaboration for Real-World Travel Planning', 'authors': 'Jihye Choi, Jinsung Yoon, Jiefeng Chen, Somesh Jha, Tomas Pfister', 'link': 'https://arxiv.org/abs/2509.25586', 'abstract': "While Large Language Models (LLMs) have shown remarkable advancements in reasoning and tool use, they often fail to generate optimal, grounded solutions under complex constraints. Real-world travel planning exemplifies these challenges, evaluating agents' abilities to handle constraints that are explicit, implicit, and even evolving based on interactions with dynamic environments and user needs. In this paper, we present ATLAS, a general multi-agent framework designed to effectively handle such complex nature of constraints awareness in real-world travel planning tasks. ATLAS introduces a principled approach to address the fundamental challenges of constraint-aware planning through dedicated mechanisms for dynamic constraint management, iterative plan critique, and adaptive interleaved search. ATLAS demonstrates state-of-the-art performance on the TravelPlanner benchmark, improving the final pass rate from 23.3% to 44.4% over its best alternative. More importantly, our work is the first to demonstrate quantitative effectiveness on real-world travel planning tasks with live information search and multi-turn feedback. In this realistic setting, ATLAS showcases its superior overall planning performance, achieving an 84% final pass rate which significantly outperforms baselines including ReAct (59%) and a monolithic agent (27%).", 'abstract_zh': '大型语言模型在推理和工具使用方面取得了显著进展，但在复杂约束下的生成最优、接地解决方案时常受到影响。现实世界的旅行规划展示了这些挑战，评估了代理在处理显式的、隐含的甚至是基于与动态环境和用户需求交互而演变的约束方面的能力。在本文中，我们提出了ATLAS，一种通用的多代理框架，旨在有效处理现实世界旅行规划任务中复杂的约束感知特性。ATLAS通过专门的动态约束管理机制、迭代计划批判和自适应交错搜索，提供了一种解决约束感知规划基本挑战的原则性方法。在TravelPlanner基准测试中，ATLAS展示了最先进的性能，将最终通过率从23.3%提高到44.4%，高于其最佳替代方案。更重要的是，我们的工作首次在带有实时信息搜索和多轮反馈的真实世界旅行规划任务中展示了定量有效性。在这种实际场景中，ATLAS展示了其卓越的整体规划性能，最终通过率为84%，显著优于包括ReAct（59%）和单olithic代理（27%）在内的基线。', 'title_zh': 'ATLAS: 基于约束的多智能体协作实地旅行规划'}
{'arxiv_id': 'arXiv:2509.25584', 'title': 'Skip-It? Theoretical Conditions for Layer Skipping in Vision-Language Models', 'authors': 'Max Hartman, Vidhata Jayaraman, Moulik Choraria, Akhil Bhimaraju, Lav R. Varshney', 'link': 'https://arxiv.org/abs/2509.25584', 'abstract': "Vision-language models (VLMs) achieve incredible performance across a wide range of tasks, but their large size makes inference costly. Recent work shows that selectively skipping VLM layers can improve efficiency with minimal performance loss or even performance improvements. However, this technique remains underused due to the limited understanding of when layer skipping is beneficial. In this paper, we develop a framework that uses information and learning theory to characterize the conditions under which layer skipping enhances efficiency without sacrificing performance. Motivated by these observations, we analyze the evolution of the VLM's hidden representations through the LLM backbone and show that layers with large redundancy as predicted by our framework coincide with those skipped by popular layer-skipping methods in practice, providing a unified theoretical scaffolding for multiple efficient inference techniques. Our experiments demonstrate that skipping such layers yields faster inference that preserves performance, and also show that applying skipping outside these conditions leads to model degradation.", 'abstract_zh': '基于视觉-语言模型的层跳过框架：通过信息与学习理论 characterizing conditions for layer skipping to enhance efficiency without sacrificing performance', 'title_zh': '跳过它？视觉-语言模型中层跳过的问题条件'}
{'arxiv_id': 'arXiv:2509.25562', 'title': 'IRIS: Intrinsic Reward Image Synthesis', 'authors': 'Yihang Chen, Yuanhao Ban, Yunqi Hong, Cho-Jui Hsieh', 'link': 'https://arxiv.org/abs/2509.25562', 'abstract': 'Despite the success of Reinforcement Learning from Human Feedback (RLHF) in language reasoning, its application to autoregressive Text-to-Image (T2I) generation is often constrained by the limited availability of human preference data. This paper explores how an autoregressive T2I model can learn from internal signals without relying on external rewards or labeled data. Contrary to recent findings in text generation, we show that maximizing self-uncertainty, rather than self-certainty, improves image generation. We observe that this is because autoregressive T2I models with low uncertainty tend to generate simple and uniform images, which are less aligned with human preferences. Based on these observations, we propose IRIS (Intrinsic Reward Image Synthesis), the first framework to improve autoregressive T2I models with reinforcement learning using only an intrinsic reward. Empirical results demonstrate that applying IRIS to autoregressive T2I models achieves performance that is competitive with or superior to external rewards.', 'abstract_zh': '尽管强化学习从人类反馈（RLHF）在语言推理方面取得了成功，但其在自回归文本到图像（T2I）生成中的应用常受限于人类偏好数据的有限可用性。本文探讨了自回归T2I模型如何通过内部信号学习，而不依赖外部奖励或标记数据。与近期文本生成的研究发现相反，我们证明最大化自我不确定性而非自我确定性能提高图像生成质量。我们观察到，这是因为低不确定性自回归T2I模型倾向于生成简单且均匀的图像，这些图像不太符合人类偏好。基于这些观察，我们提出了IRIS（内在奖励图像合成）框架，这是首个仅使用内在奖励通过强化学习改进自回归T2I模型的方法。实证结果表明，将IRIS应用于自回归T2I模型，其性能与外部奖励相当或更优。', 'title_zh': 'IRIS: 内在奖励图像合成'}
{'arxiv_id': 'arXiv:2509.25559', 'title': "Radiology's Last Exam (RadLE): Benchmarking Frontier Multimodal AI Against Human Experts and a Taxonomy of Visual Reasoning Errors in Radiology", 'authors': 'Suvrankar Datta, Divya Buchireddygari, Lakshmi Vennela Chowdary Kaza, Mrudula Bhalke, Kautik Singh, Ayush Pandey, Sonit Sai Vasipalli, Upasana Karnwal, Hakikat Bir Singh Bhatti, Bhavya Ratan Maroo, Sanjana Hebbar, Rahul Joseph, Gurkawal Kaur, Devyani Singh, Akhil V, Dheeksha Devasya Shama Prasad, Nishtha Mahajan, Ayinaparthi Arisha, Rajesh Vanagundi, Reet Nandy, Kartik Vuthoo, Snigdhaa Rajvanshi, Nikhileswar Kondaveeti, Suyash Gunjal, Rishabh Jain, Rajat Jain, Anurag Agrawal', 'link': 'https://arxiv.org/abs/2509.25559', 'abstract': 'Generalist multimodal AI systems such as large language models (LLMs) and vision language models (VLMs) are increasingly accessed by clinicians and patients alike for medical image interpretation through widely available consumer-facing chatbots. Most evaluations claiming expert level performance are on public datasets containing common pathologies. Rigorous evaluation of frontier models on difficult diagnostic cases remains limited. We developed a pilot benchmark of 50 expert-level "spot diagnosis" cases across multiple imaging modalities to evaluate the performance of frontier AI models against board-certified radiologists and radiology trainees. To mirror real-world usage, the reasoning modes of five popular frontier AI models were tested through their native web interfaces, viz. OpenAI o3, OpenAI GPT-5, Gemini 2.5 Pro, Grok-4, and Claude Opus 4.1. Accuracy was scored by blinded experts, and reproducibility was assessed across three independent runs. GPT-5 was additionally evaluated across various reasoning modes. Reasoning quality errors were assessed and a taxonomy of visual reasoning errors was defined. Board-certified radiologists achieved the highest diagnostic accuracy (83%), outperforming trainees (45%) and all AI models (best performance shown by GPT-5: 30%). Reliability was substantial for GPT-5 and o3, moderate for Gemini 2.5 Pro and Grok-4, and poor for Claude Opus 4.1. These findings demonstrate that advanced frontier models fall far short of radiologists in challenging diagnostic cases. Our benchmark highlights the present limitations of generalist AI in medical imaging and cautions against unsupervised clinical use. We also provide a qualitative analysis of reasoning traces and propose a practical taxonomy of visual reasoning errors by AI models for better understanding their failure modes, informing evaluation standards and guiding more robust model development.', 'abstract_zh': '面向临床的多模态AI系统（如大规模语言模型和视觉语言模型）通过广泛使用的消费者聊天机器人被医生和患者用于医学图像解释。大多数声称专家级性能的评估是在包含常见病理的公共数据集上进行的。对前沿模型在困难诊断案例上的严格评估仍然有限。我们开发了一个包含50个专家级“即时诊断”案例的试点基准，涉及多种成像模态，用于评估前沿AI模型与认证放射科医生和放射科培训生的性能。为了反映实际使用情况，五种流行前沿AI模型的推理模式通过其原生网页界面进行了测试，分别是OpenAI o3、OpenAI GPT-5、Gemini 2.5 Pro、Grok-4和Claude Opus 4.1。准确率由盲评专家评分，并在三次独立运行中评估了可重复性。此外，GPT-5在多种推理模式下进行了评估。评估了推理质量错误，并定义了视觉推理错误的分类。认证放射科医生的诊断准确率最高（83%），优于培训生（45%）和所有AI模型（最佳表现为GPT-5：30%）。GPT-5和o3的可靠性较大，Gemini 2.5 Pro和Grok-4的可靠性中等，Claude Opus 4.1的可靠性较差。这些发现表明，在困难的诊断案例中，高级前沿模型远不及放射科医生。我们的基准指出了通用AI在医学成像领域的当前局限性，并提醒不应在未经监督的情况下临床使用。我们还提供了推理轨迹的定性分析，并提出了AI模型视觉推理错误的实用分类，以更好地理解其失败模式，指导评估标准并引导更稳健的模型开发。', 'title_zh': "Radiology's Last Exam (RadLE): 评估前沿多模态AI与人类专家的表现及其在放射学中视觉推理错误的分类基准"}
{'arxiv_id': 'arXiv:2509.25558', 'title': 'A(I)nimism: Re-enchanting the World Through AI-Mediated Object Interaction', 'authors': 'Diana Mykhaylychenko, Maisha Thasin, Dunya Baradari, Charmelle Mhungu', 'link': 'https://arxiv.org/abs/2509.25558', 'abstract': "Animist worldviews treat beings, plants, landscapes, and even tools as persons endowed with spirit, an orientation that has long shaped human-nonhuman relations through ritual and moral practice. While modern industrial societies have often imagined technology as mute and mechanical, recent advances in artificial intelligence (AI), especially large language models (LLMs), invite people to anthropomorphize and attribute inner life to devices. This paper introduces A(I)nimism, an interactive installation exploring how large language objects (LLOs) can mediate animistic relationships with everyday things. Housed within a physical 'portal', the system uses GPT-4 Vision, voice input, and memory-based agents to create evolving object-personas. Encounters unfold through light, sound, and touch in a ritual-like process of request, conversation, and transformation that is designed to evoke empathy, wonder, and reflection. We situate the project within anthropological perspectives, speculative design, and spiritual HCI. AI's opacity, we argue, invites animistic interpretation, allowing LLOs to re-enchant the mundane and spark new questions of agency, responsibility, and design.", 'abstract_zh': 'Animist 人工智能主义：大型语言模型如何调和日常之物的灵性关系', 'title_zh': 'AI灵思：通过AI介导的物体交互重新赋予世界魔力'}
{'arxiv_id': 'arXiv:2509.25552', 'title': 'Evaluating Foundation Models with Pathological Concept Learning for Kidney Cancer', 'authors': 'Shangqi Gao, Sihan Wang, Yibo Gao, Boming Wang, Xiahai Zhuang, Anne Warren, Grant Stewart, James Jones, Mireia Crispin-Ortuzar', 'link': 'https://arxiv.org/abs/2509.25552', 'abstract': 'To evaluate the translational capabilities of foundation models, we develop a pathological concept learning approach focused on kidney cancer. By leveraging TNM staging guidelines and pathology reports, we build comprehensive pathological concepts for kidney cancer. Then, we extract deep features from whole slide images using foundation models, construct pathological graphs to capture spatial correlations, and trained graph neural networks to identify these concepts. Finally, we demonstrate the effectiveness of this approach in kidney cancer survival analysis, highlighting its explainability and fairness in identifying low- and high-risk patients. The source code has been released by this https URL.', 'abstract_zh': '为了评估基础模型的迁移能力，我们提出了一种专注于肾癌的病理概念学习方法。通过利用TNM分期指南和病理报告，我们构建了全面的肾癌病理概念。然后，我们使用基础模型从全切片图像中提取深层特征，构建病理图以捕获空间相关性，并训练图神经网络以识别这些概念。最后，我们在肾癌生存分析中展示了该方法的有效性，突出了其在识别低风险和高风险患者方面的解释性和公平性。源代码可从此链接获取：https://xxxxxx。', 'title_zh': '基于病理概念学习的肾癌基础模型评估'}
{'arxiv_id': 'arXiv:2509.25550', 'title': 'Learning to Interact in World Latent for Team Coordination', 'authors': 'Dongsu Lee, Daehee Lee, Yaru Niu, Honguk Woo, Amy Zhang, Ding Zhao', 'link': 'https://arxiv.org/abs/2509.25550', 'abstract': 'This work presents a novel representation learning framework, interactive world latent (IWoL), to facilitate team coordination in multi-agent reinforcement learning (MARL). Building effective representation for team coordination is a challenging problem, due to the intricate dynamics emerging from multi-agent interaction and incomplete information induced by local observations. Our key insight is to construct a learnable representation space that jointly captures inter-agent relations and task-specific world information by directly modeling communication protocols. This representation, we maintain fully decentralized execution with implicit coordination, all while avoiding the inherent drawbacks of explicit message passing, e.g., slower decision-making, vulnerability to malicious attackers, and sensitivity to bandwidth constraints. In practice, our representation can be used not only as an implicit latent for each agent, but also as an explicit message for communication. Across four challenging MARL benchmarks, we evaluate both variants and show that IWoL provides a simple yet powerful key for team coordination. Moreover, we demonstrate that our representation can be combined with existing MARL algorithms to further enhance their performance.', 'abstract_zh': '本研究提出了一种新颖的表示学习框架——交互世界隐空间(IWoL)，以促进多代理强化学习(MARL)中的团队协作。构建有效的团队协作表示是一个具有挑战性的问题，这是因为来自多代理交互的复杂动力学以及由于局部观测引起的不完整信息。我们的核心洞察是构建一个可学习的表示空间，该空间能同时捕捉代理间的关系和任务特定的世界信息，并通过直接建模通信协议来实现这一目标。此表示方法能够在保持完全去中心化执行的同时实现隐式协作，同时避免了显式消息传递的固有缺点，例如决策速度较慢、容易受到恶意攻击者的影响以及对带宽约束敏感。在实践中，该表示不仅可以作为每个代理的隐式潜在表示，还可以作为通信的显式消息。在四个具有挑战性的MARL基准测试中，我们评估了两种变体，并展示了IWoL为团队协作提供了一个简单而强大的关键。此外，我们证明了该表示可以与现有的MARL算法结合使用，进一步提升其性能。', 'title_zh': 'Learning to Interact in World Latent for Team Coordination'}
{'arxiv_id': 'arXiv:2509.25540', 'title': 'RadOnc-GPT: An Autonomous LLM Agent for Real-Time Patient Outcomes Labeling at Scale', 'authors': 'Jason Holmes, Yuexing Hao, Mariana Borras-Osorio, Federico Mastroleo, Santiago Romero Brufau, Valentina Carducci, Katie M Van Abel, David M Routman, Andrew Y. K. Foong, Liv M Muller, Satomi Shiraishi, Daniel K Ebner, Daniel J Ma, Sameer R Keole, Samir H Patel, Mirek Fatyga, Martin Bues, Brad J Stish, Yolanda I Garces, Michelle A Neben Wittich, Robert L Foote, Sujay A Vora, Nadia N Laack, Mark R Waddle, Wei Liu', 'link': 'https://arxiv.org/abs/2509.25540', 'abstract': 'Manual labeling limits the scale, accuracy, and timeliness of patient outcomes research in radiation oncology. We present RadOnc-GPT, an autonomous large language model (LLM)-based agent capable of independently retrieving patient-specific information, iteratively assessing evidence, and returning structured outcomes. Our evaluation explicitly validates RadOnc-GPT across two clearly defined tiers of increasing complexity: (1) a structured quality assurance (QA) tier, assessing the accurate retrieval of demographic and radiotherapy treatment plan details, followed by (2) a complex clinical outcomes labeling tier involving determination of mandibular osteoradionecrosis (ORN) in head-and-neck cancer patients and detection of cancer recurrence in independent prostate and head-and-neck cancer cohorts requiring combined interpretation of structured and unstructured patient data. The QA tier establishes foundational trust in structured-data retrieval, a critical prerequisite for successful complex clinical outcome labeling.', 'abstract_zh': '手动标注限制了放射肿瘤学患者结果研究的规模、准确性和及时性。我们提出了RadOnc-GPT，这是一种自主的基于大规模语言模型的代理，能够独立检索患者特定信息、迭代评估证据并返回结构化结果。我们的评估明确地在两个逐步增加复杂性的层级上验证了RadOnc-GPT：(1) 结构化质量保证 (QA) 层级，评估了能准确检索人口统计学和放射治疗计划细节的能力，随后是 (2) 复杂临床结果标注层级，涉及头颈部癌症患者下颌骨放射性骨坏死 (ORN) 的判断以及头颈部和独立前列腺癌队列的癌症复发检测，需要结合结构化和非结构化患者数据进行联合解释。QA层级建立了对结构化数据检索的初步信任，这是成功进行复杂临床结果标注的一个关键前提。', 'title_zh': 'RadOnc-GPT：一个用于大规模实时患者结果标注的自主语言模型代理'}
{'arxiv_id': 'arXiv:2509.25530', 'title': 'Beyond Static Retrieval: Opportunities and Pitfalls of Iterative Retrieval in GraphRAG', 'authors': 'Kai Guo, Xinnan Dai, Shenglai Zeng, Harry Shomer, Haoyu Han, Yu Wang, Jiliang Tang', 'link': 'https://arxiv.org/abs/2509.25530', 'abstract': "Retrieval-augmented generation (RAG) is a powerful paradigm for improving large language models (LLMs) on knowledge-intensive question answering. Graph-based RAG (GraphRAG) leverages entity-relation graphs to support multi-hop reasoning, but most systems still rely on static retrieval. When crucial evidence, especially bridge documents that connect disjoint entities, is absent, reasoning collapses and hallucinations persist. Iterative retrieval, which performs multiple rounds of evidence selection, has emerged as a promising alternative, yet its role within GraphRAG remains poorly understood. We present the first systematic study of iterative retrieval in GraphRAG, analyzing how different strategies interact with graph-based backbones and under what conditions they succeed or fail. Our findings reveal clear opportunities: iteration improves complex multi-hop questions, helps promote bridge documents into leading ranks, and different strategies offer complementary strengths. At the same time, pitfalls remain: naive expansion often introduces noise that reduces precision, gains are limited on single-hop or simple comparison questions, and several bridge evidences still be buried too deep to be effectively used. Together, these results highlight a central bottleneck, namely that GraphRAG's effectiveness depends not only on recall but also on whether bridge evidence is consistently promoted into leading positions where it can support reasoning chains. To address this challenge, we propose Bridge-Guided Dual-Thought-based Retrieval (BDTR), a simple yet effective framework that generates complementary thoughts and leverages reasoning chains to recalibrate rankings and bring bridge evidence into leading positions. BDTR achieves consistent improvements across diverse GraphRAG settings and provides guidance for the design of future GraphRAG systems.", 'abstract_zh': '基于图的检索增强生成（Iterative Retrieval in GraphRAG：一种基于图的检索增强生成的迭代检索系统研究与Bridge-Guided Dual-Thought-based Retrieval框架）', 'title_zh': '超越静态检索：图RAG中迭代检索的机会与风险'}
{'arxiv_id': 'arXiv:2509.25522', 'title': 'Understanding Generative Recommendation with Semantic IDs from a Model-scaling View', 'authors': 'Jingzhe Liu, Liam Collins, Jiliang Tang, Tong Zhao, Neil Shah, Clark Mingxuan Ju', 'link': 'https://arxiv.org/abs/2509.25522', 'abstract': 'Recent advancements in generative models have allowed the emergence of a promising paradigm for recommender systems (RS), known as Generative Recommendation (GR), which tries to unify rich item semantics and collaborative filtering signals. One popular modern approach is to use semantic IDs (SIDs), which are discrete codes quantized from the embeddings of modality encoders (e.g., large language or vision models), to represent items in an autoregressive user interaction sequence modeling setup (henceforth, SID-based GR). While generative models in other domains exhibit well-established scaling laws, our work reveals that SID-based GR shows significant bottlenecks while scaling up the model. In particular, the performance of SID-based GR quickly saturates as we enlarge each component: the modality encoder, the quantization tokenizer, and the RS itself. In this work, we identify the limited capacity of SIDs to encode item semantic information as one of the fundamental bottlenecks. Motivated by this observation, as an initial effort to obtain GR models with better scaling behaviors, we revisit another GR paradigm that directly uses large language models (LLMs) as recommenders (henceforth, LLM-as-RS). Our experiments show that the LLM-as-RS paradigm has superior model scaling properties and achieves up to 20 percent improvement over the best achievable performance of SID-based GR through scaling. We also challenge the prevailing belief that LLMs struggle to capture collaborative filtering information, showing that their ability to model user-item interactions improves as LLMs scale up. Our analyses on both SID-based GR and LLMs across model sizes from 44M to 14B parameters underscore the intrinsic scaling limits of SID-based GR and position LLM-as-RS as a promising path toward foundation models for GR.', 'abstract_zh': 'Recent advancements in 生成模型 为推荐系统（RS）带来了生成推荐（GR）这一有前景的范式，该范式尝试统一丰富的项语义和协同过滤信号。', 'title_zh': '从模型扩展视角理解基于语义ID的生成推荐'}
{'arxiv_id': 'arXiv:2509.25482', 'title': 'Message passing-based inference in an autoregressive active inference agent', 'authors': 'Wouter M. Kouw, Tim N. Nisslbeck, Wouter L.N. Nuijten', 'link': 'https://arxiv.org/abs/2509.25482', 'abstract': "We present the design of an autoregressive active inference agent in the form of message passing on a factor graph. Expected free energy is derived and distributed across a planning graph. The proposed agent is validated on a robot navigation task, demonstrating exploration and exploitation in a continuous-valued observation space with bounded continuous-valued actions. Compared to a classical optimal controller, the agent modulates action based on predictive uncertainty, arriving later but with a better model of the robot's dynamics.", 'abstract_zh': '基于因子图上的消息传递设计自回归主动推断代理：在连续观测空间中的探索与利用验证', 'title_zh': '基于消息传递的自回归主动推理代理的推理研究'}
{'arxiv_id': 'arXiv:2509.25475', 'title': 'TDHook: A Lightweight Framework for Interpretability', 'authors': 'Yoann Poupart', 'link': 'https://arxiv.org/abs/2509.25475', 'abstract': 'Interpretability of Deep Neural Networks (DNNs) is a growing field driven by the study of vision and language models. Yet, some use cases, like image captioning, or domains like Deep Reinforcement Learning (DRL), require complex modelling, with multiple inputs and outputs or use composable and separated networks. As a consequence, they rarely fit natively into the API of popular interpretability frameworks. We thus present TDHook, an open-source, lightweight, generic interpretability framework based on $\\texttt{tensordict}$ and applicable to any $\\texttt{torch}$ model. It focuses on handling complex composed models which can be trained for Computer Vision, Natural Language Processing, Reinforcement Learning or any other domain. This library features ready-to-use methods for attribution, probing and a flexible get-set API for interventions, and is aiming to bridge the gap between these method classes to make modern interpretability pipelines more accessible. TDHook is designed with minimal dependencies, requiring roughly half as much disk space as $\\texttt{transformer_lens}$, and, in our controlled benchmark, achieves up to a $\\times$2 speed-up over $\\texttt{captum}$ when running integrated gradients for multi-target pipelines on both CPU and GPU. In addition, to value our work, we showcase concrete use cases of our library with composed interpretability pipelines in Computer Vision (CV) and Natural Language Processing (NLP), as well as with complex models in DRL.', 'abstract_zh': '深度神经网络的可解释性：一种基于`tensordict`的开源轻量级通用框架', 'title_zh': 'TDHook: 一种轻量级可解释性框架'}
{'arxiv_id': 'arXiv:2509.25458', 'title': 'Plug-and-Play Emotion Graphs for Compositional Prompting in Zero-Shot Speech Emotion Recognition', 'authors': 'Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao', 'link': 'https://arxiv.org/abs/2509.25458', 'abstract': 'Large audio-language models (LALMs) exhibit strong zero-shot performance across speech tasks but struggle with speech emotion recognition (SER) due to weak paralinguistic modeling and limited cross-modal reasoning. We propose Compositional Chain-of-Thought Prompting for Emotion Reasoning (CCoT-Emo), a framework that introduces structured Emotion Graphs (EGs) to guide LALMs in emotion inference without fine-tuning. Each EG encodes seven acoustic features (e.g., pitch, speech rate, jitter, shimmer), textual sentiment, keywords, and cross-modal associations. Embedded into prompts, EGs provide interpretable and compositional representations that enhance LALM reasoning. Experiments across SER benchmarks show that CCoT-Emo outperforms prior SOTA and improves accuracy over zero-shot baselines.', 'abstract_zh': '大规模音频-语言模型在情感识别任务中表现出较强的零样本性能，但由于薄弱的副语言建模和有限的跨模态推理能力，在语音情感识别（SER）方面存在挑战。我们提出了情感推理的组成链式思考提示（CCoT-Emo）框架，该框架引入了结构化情感图（EGs）来指导大规模音频-语言模型进行情感推断而不进行微调。每个EG编码七个声学特征（例如，音高、语速、颤动、沙哑）、文本情绪、关键词以及跨模态关联。嵌入在提示中的EG提供了可解析和组成的表示，增强LALM的推理能力。在多个情感识别基准上的实验表明，CCoT-Emo优于先前的最佳方法，并且在零样本基线之上提高了准确性。', 'title_zh': '即插即用情感图用于零样本语音情感识别的组合提示生成'}
{'arxiv_id': 'arXiv:2509.25454', 'title': 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search', 'authors': 'Fang Wu, Weihao Xuan, Heli Qi, Ximing Lu, Aaron Tu, Li Erran Li, Yejin ChoiRetry', 'link': 'https://arxiv.org/abs/2509.25454', 'abstract': 'Although RLVR has become an essential component for developing advanced reasoning skills in LLMs, contemporary studies have documented training plateaus that emerge following thousands of optimization steps, demonstrating notable decreases in performance gains despite increased computational investment. This limitation stems from the sparse exploration patterns inherent in current RLVR practices, where models rely on limited rollouts that often miss critical reasoning paths and fail to provide systematic coverage of the solution space. We present DeepSearch, a framework that integrates Monte Carlo Tree Search directly into RLVR training. In contrast to existing methods that rely on tree search only at inference, DeepSearch embeds structured search into the training loop, enabling systematic exploration and fine-grained credit assignment across reasoning steps. Through training-time exploration, DeepSearch addresses the fundamental bottleneck of insufficient exploration, which leads to diminishing performance improvements over prolonged training steps. Our contributions include: (1) a global frontier selection strategy that prioritizes promising nodes across the search tree, (2) selection with entropy-based guidance that identifies confident paths for supervision, and (3) adaptive replay buffer training with solution caching for efficiency. Experiments on mathematical reasoning benchmarks show that DeepSearch achieves 62.95% average accuracy and establishes a new state-of-the-art for 1.5B reasoning models - using 5.7x fewer GPU hours than extended training approaches. These results highlight the importance of strategic exploration over brute-force scaling and demonstrate the promise of algorithmic innovation for advancing RLVR methodologies. DeepSearch establishes a new direction for scaling reasoning capabilities through systematic search rather than prolonged computation.', 'abstract_zh': '虽然RLVR已成为开发高级推理能力的LLMs中的一个 essential 组件，但当代研究记录了在数千次优化步骤后出现的训练平台期，尽管增加了计算投资，性能提升 nonetheless 出现了显著下降。这一限制源于当前RLVR实践中的稀疏探索模式，模型依赖于有限的rollout，往往忽略了关键的推理路径，无法系统地覆盖解决方案空间。我们提出了 DeepSearch 框架，该框架将蒙特卡洛树搜索直接集成到RLVR训练中。与仅在推理时依赖树搜索的现有方法不同，DeepSearch 将结构化的搜索嵌入到训练循环中，从而实现系统的探索和推理步骤中的细粒度奖励分配。通过训练时的探索，DeepSearch 解决了探索不足这一基本瓶颈，从而在长期训练步骤中实现了性能改进的递减。我们的贡献包括：（1）全局前沿选择策略，优先选择搜索树中的有希望节点，（2）基于熵的引导选择，识别自信的推理路径供监督使用，以及（3）带有解缓存的自适应回放缓冲区训练以提高效率。在数学推理基准测试上的实验表明，DeepSearch 达到了 62.95% 的平均准确率，并且使用了比扩展训练方法少 5.7 倍的 GPU 小时建立了新的 1.5B 推理模型的 state-of-the-art。这些结果强调了战略性探索而非暴力扩展的重要性，并展示了算法创新对推进RLVR方法的潜力。DeepSearch 为通过系统搜索而非长时间计算来扩展推理能力指明了新方向。', 'title_zh': 'DeepSearch：通过蒙特卡洛树搜索克服强化学习中的验证奖励瓶颈'}
{'arxiv_id': 'arXiv:2509.25435', 'title': 'GESA: Graph-Enhanced Semantic Allocation for Generalized, Fair, and Explainable Candidate-Role Matching', 'authors': 'Rishi Ashish Shah, Shivaay Dhondiyal, Kartik Sharma, Sukriti Talwar, Saksham Jain, Sparsh Jain', 'link': 'https://arxiv.org/abs/2509.25435', 'abstract': 'Accurate, fair, and explainable allocation of candidates to roles represents a fundamental challenge across multiple domains including corporate hiring, academic admissions, fellowship awards, and volunteer placement systems. Current state-of-the-art approaches suffer from semantic inflexibility, persistent demographic bias, opacity in decision-making processes, and poor scalability under dynamic policy constraints. We present GESA (Graph-Enhanced Semantic Allocation), a comprehensive framework that addresses these limitations through the integration of domain-adaptive transformer embeddings, heterogeneous self-supervised graph neural networks, adversarial debiasing mechanisms, multi-objective genetic optimization, and explainable AI components. Our experimental evaluation on large-scale international benchmarks comprising 20,000 candidate profiles and 3,000 role specifications demonstrates superior performance with 94.5% top-3 allocation accuracy, 37% improvement in diversity representation, 0.98 fairness score across demographic cate- gories, and sub-second end-to-end latency. Additionally, GESA incorporates hybrid recommendation capabilities and glass-box explainability, making it suitable for deployment across diverse international contexts in industry, academia, and non-profit sectors.', 'abstract_zh': '准确、公平且可解释的求职者分配到角色的方案代表了包括企业招聘、学术录取、奖学金 award 和志愿者安置系统在内的多个领域的一项基本挑战。当前最先进的方法在语义灵活性、持久性人群偏差、决策过程透明度以及动态政策约束下的可扩展性方面存在局限。我们提出了一种名为 GESA（图增强语义分配）的综合框架，通过集成领域自适应变压器嵌入、异质自监督图神经网络、对抗去偏机制、多目标遗传优化以及可解释人工智能组件来解决这些局限。我们在包含 20,000 个求职者档案和 3,000 个角色规范的大型国际基准上的实验评估展示了出色的表现，包括 94.5% 的前三位分配准确率、37% 的多样性表示改进、跨人口类别达到 0.98 的公平评分，以及端到端亚秒级延迟。此外，GESA 具备混合推荐能力和玻璃盒解释性，使其适合在工业、学术和非营利部门等多元国际背景下部署。', 'title_zh': '基于图增强语义分配的通用、公平和可解释的候选项-角色匹配方法'}
{'arxiv_id': 'arXiv:2509.25434', 'title': 'The Open Syndrome Definition', 'authors': 'Ana Paula Gomes Ferreira, Aleksandar Anžel, Izabel Oliva Marcilio de Souza, Helen Hughes, Alex J Elliot, Jude Dzevela Kong, Madlen Schranz, Alexander Ullrich, Georges Hattab', 'link': 'https://arxiv.org/abs/2509.25434', 'abstract': "Case definitions are essential for effectively communicating public health threats. However, the absence of a standardized, machine-readable format poses significant challenges to interoperability, epidemiological research, the exchange of qualitative data, and the effective application of computational analysis methods, including artificial intelligence (AI). This complicates comparisons and collaborations across organizations and regions, limits data integration, and hinders technological innovation in public health. To address these issues, we propose the first open, machine-readable format for representing case and syndrome definitions. Additionally, we introduce the first comprehensive dataset of standardized case definitions and tools to convert existing human-readable definitions into machine-readable formats. We also provide an accessible online platform for browsing, analyzing, and contributing new definitions, available at this https URL. The Open Syndrome Definition format enables consistent, scalable use of case definitions across systems, unlocking AI's potential to strengthen public health preparedness and response. The source code for the format can be found at this https URL under the MIT license.", 'abstract_zh': '开放的综合征定义格式对于有效传达公共卫生威胁至关重要。然而，缺乏标准化和机器可读的格式阻碍了跨组织和地区的互操作性、流行病学研究、定性数据交换以及包括人工智能在内的计算分析方法的有效应用。为了应对这些问题，我们提出了首个开放的、机器可读的综合征和症状定义格式。此外，我们还介绍了首个标准化的综合征定义全面数据集及其工具，用于将现有的人类可读定义转换为机器可读格式。我们还提供了一个易于访问的在线平台，用于浏览、分析和贡献新定义，网址为this https URL。开放的综合征定义格式使得跨系统的病例定义使用保持一致和可扩展，从而发掘人工智能在增强公共卫生准备和响应方面的潜力。该格式的源代码可在MIT许可下从this https URL找到。', 'title_zh': '开放综合征定义'}
{'arxiv_id': 'arXiv:2509.25426', 'title': 'RADAR: Reasoning-Ability and Difficulty-Aware Routing for Reasoning LLMs', 'authors': 'Nigel Fernandez, Branislav Kveton, Ryan A. Rossi, Andrew S. Lan, Zichao Wang', 'link': 'https://arxiv.org/abs/2509.25426', 'abstract': 'Reasoning language models have demonstrated remarkable performance on many challenging tasks in math, science, and coding. Choosing the right reasoning model for practical deployment involves a performance and cost tradeoff at two key levels: model size and reasoning budget, where larger models and higher reasoning budget lead to better performance but with increased cost and latency. In this work, we tackle this tradeoff from the angle of model configuration routing for different queries, and present RADAR (Reasoning-Ability and Difficulty-Aware Routing), a lightweight, interpretable, and scalable routing framework. Inspired by psychometrics, RADAR learns an item response model from model responses with different budgets to different queries, with interpretable parameters including query difficulties and model-budget abilities. RADAR then routes queries with higher difficulty to model-budget pairs with higher ability, and vice versa. We conduct extensive experiments on 8 widely used challenging reasoning benchmarks, demonstrating the superior performance of RADAR compared to state-of-the-art model routing methods. RADAR also exhibits query generalization capabilities, showing strong performance on out-of-distribution queries in all benchmarks. RADAR is also scalable and can efficiently integrate additional models by dynamically selecting a small set of evaluation queries to estimate their abilities.', 'abstract_zh': '基于推理的能力和难度感知路由（Reasoning-Ability and Difficulty-Aware Routing）：一种轻量级、可解释且可扩展的路由框架', 'title_zh': 'RADAR: 具备推理能力与难度意识的路由方法用于推理型大语言模型'}
{'arxiv_id': 'arXiv:2509.25420', 'title': 'Adaptive Test-Time Reasoning via Reward-Guided Dual-Phase Search', 'authors': 'Yingqian Cui, Zhenwei Dai, Pengfei He, Bing He, Hui Liu, Xianfeng Tang, Jingying Zeng, Suhang Wang, Yue Xing, Jiliang Tang, Benoit Dumoulin', 'link': 'https://arxiv.org/abs/2509.25420', 'abstract': 'Large Language Models (LLMs) have achieved significant advances in reasoning tasks. A key approach is tree-based search with verifiers, which expand candidate reasoning paths and use reward models to guide pruning and selection. Although effective in improving accuracy, these methods are not optimal in terms of efficiency: they perform simple decomposition on the reasoning process, but ignore the planning-execution nature of tasks such as math reasoning or code generation. This results in inefficient exploration of reasoning process. To address this, we propose a dual-phase test-time scaling framework that explicitly separates reasoning into planning and execution, and performs search over the two phases individually. Specifically, we decompose reasoning trajectories and develop reward models for each phase, enabling the search to explore and prune plans and executions separately. We further introduce a dynamic budget allocation mechanism that adaptively redistributes sampling effort based on reward feedback, allowing early stopping on confident steps and reallocation of computation to more challenging parts of the reasoning process. Experiments on both mathematical reasoning and code generation benchmarks demonstrate that our approach consistently improves accuracy while reducing redundant computation.', 'abstract_zh': '大规模语言模型（LLMs）在推理任务中取得了显著进展。一种关键方法是基于树的搜索与验证器，通过扩展候选推理路径并使用奖励模型来指导裁剪和选择。尽管这种方法在提高准确性方面有效，但在效率方面并非最优：它们对推理过程进行简单的分解，但忽视了如数学推理或代码生成等任务的规划-执行本质，导致推理过程探索不高效。为解决这一问题，我们提出了一种两阶段测试时缩放框架，明确地将推理分为规划和执行两个阶段，并分别在两个阶段进行搜索。具体而言，我们分解了推理轨迹，并为每个阶段开发了奖励模型，使搜索能够分别探索和裁剪计划和执行。我们还引入了一种动态预算分配机制，根据奖励反馈自适应地重新分配采样努力，允许在有把握的步骤上提前停止，并将计算重新分配到推理过程中的更具挑战性的部分。在数学推理和代码生成基准测试上的实验表明，我们的方法在提高准确性的同时减少了冗余计算。', 'title_zh': '基于奖励引导两阶段搜索的自适应测试时推理'}
{'arxiv_id': 'arXiv:2509.25411', 'title': 'Boolean Satisfiability via Imitation Learning', 'authors': 'Zewei Zhang, Huan Liu, Yuanhao Yu, Jun Chen, Xiangyu Xu', 'link': 'https://arxiv.org/abs/2509.25411', 'abstract': 'We propose ImitSAT, a branching policy for conflict-driven clause learning (CDCL) solvers based on imitation learning for the Boolean satisfiability problem (SAT). Unlike previous methods that predict instance-level signals to improve CDCL branching indirectly, or rely on reinforcement learning and insufficient CDCL information to enhance branching, ImitSAT learns from expert KeyTrace that collapses a full run into the sequence of surviving decisions. Replaying a KeyTrace on the same instance is nearly conflict-free, providing dense decision-level supervision and directly reducing propagations -- the dominant contributor to wall-clock time. This prefix-conditioned supervision enables ImitSAT to reproduce high-quality branches without exploration, yielding faster convergence, stable training, and seamless integration into CDCL. Extensive experiments demonstrate that ImitSAT reduces propagation counts and runtime, outperforming state-of-the-art learned approaches. We released the source code and trained model at this https URL', 'abstract_zh': '我们提出ImitSAT，一种基于imitation learning的针对Boolean可满足性问题（SAT）的冲突驱动子句学习（CDCL）求解器的分支策略。不同于以往方法通过预测实例级信号间接改进CDCL分支或依赖强化学习和不足的CDCL信息来增强分支，ImitSAT从专家KeyTrace中学习，将完整运行压缩为幸存决策序列。在相同实例上回放KeyTrace几乎无冲突，提供密集的决策级监督，直接减少传播——这是壁钟时间的主要贡献者。这种前缀条件监督使ImitSAT能够在不探索的情况下生成高质量分支，实现更快的收敛、稳定的训练以及无缝集成到CDCL中。广泛实验表明，ImitSAT减少了传播次数和运行时间，并优于最新的学习方法。我们在https://这个链接发布了源代码和训练模型。', 'title_zh': '布尔可满足性通过模仿学习'}
{'arxiv_id': 'arXiv:2509.25374', 'title': 'Saliency Guided Longitudinal Medical Visual Question Answering', 'authors': 'Jialin Wu, Xiaofeng Liu', 'link': 'https://arxiv.org/abs/2509.25374', 'abstract': 'Longitudinal medical visual question answering (Diff-VQA) requires comparing paired studies from different time points and answering questions about clinically meaningful changes. In this setting, the difference signal and the consistency of visual focus across time are more informative than absolute single-image findings. We propose a saliency-guided encoder-decoder for chest X-ray Diff-VQA that turns post-hoc saliency into actionable supervision. The model first performs a lightweight near-identity affine pre-alignment to reduce nuisance motion between visits. It then executes a within-epoch two-step loop: step 1 extracts a medically relevant keyword from the answer and generates keyword-conditioned Grad-CAM on both images to obtain disease-focused saliency; step 2 applies the shared saliency mask to both time points and generates the final answer. This closes the language-vision loop so that the terms that matter also guide where the model looks, enforcing spatially consistent attention on corresponding anatomy. On Medical-Diff-VQA, the approach attains competitive performance on BLEU, ROUGE-L, CIDEr, and METEOR while providing intrinsic interpretability. Notably, the backbone and decoder are general-domain pretrained without radiology-specific pretraining, highlighting practicality and transferability. These results support saliency-conditioned generation with mild pre-alignment as a principled framework for longitudinal reasoning in medical VQA.', 'abstract_zh': '纵向医学视觉问答（Diff-VQA）要求比较不同时间点的配对研究并回答关于临床有意义变化的问题。在这种情况下，时间上的差异信号和视觉关注的一致性比单张图像的绝对发现更具信息量。我们提出了一种基于显著性引导的编码器-解码器模型，将事后显著性转化为可操作的监督。该模型首先执行一种轻量级的近恒同仿射预对齐，以减少访问间的多余运动。然后执行一个epoch内的两步循环：第一步从答案中提取医学相关的关键词，并在两张图像上生成条件下的Grad-CAM以获得疾病焦点的显著性；第二步将共享的显著性掩码应用于两个时间点并生成最终答案。这关闭了语言-视觉循环，使重要的术语也指导模型看的位置，加强空间上一致的注意力在相应的解剖结构上。在Medical-Diff-VQA上，该方法在BLEU、ROUGE-L、CIDEr和METEOR上取得了竞争力的性能，同时提供了内在的可解释性。值得注意的是，该模型的骨干和解码器在一般领域预训练而无需放射学特定的预训练，突显其实用性和可迁移性。这些结果支持在医学VQA中的纵向推理中需要轻微预对齐的条件显著性生成作为一种原则性框架。', 'title_zh': '注意力引导的 longitudal 医学视觉问答'}
{'arxiv_id': 'arXiv:2509.25373', 'title': 'From Perception to Cognition: A Survey of Vision-Language Interactive Reasoning in Multimodal Large Language Models', 'authors': 'Chenyue Zhou, Mingxuan Wang, Yanbiao Ma, Chenxu Wu, Wanyi Chen, Zhe Qian, Xinyu Liu, Yiwei Zhang, Junhao Wang, Hengbo Xu, Fei Luo, Xiaohua Chen, Xiaoshuai Hao, Hehan Li, Andi Zhang, Wenxuan Wang, Lingling Li, Zhiwu Lu, Yang Lu, Yike Guo', 'link': 'https://arxiv.org/abs/2509.25373', 'abstract': 'Multimodal Large Language Models (MLLMs) strive to achieve a profound, human-like understanding of and interaction with the physical world, but often exhibit a shallow and incoherent integration when acquiring information (Perception) and conducting reasoning (Cognition). This disconnect leads to a spectrum of reasoning failures, with hallucination being the most prominent. Collectively, these issues expose a fundamental challenge: the ability to process pixels does not yet confer the ability to construct a coherent, credible internal world model. To systematically dissect and address this challenge, this survey introduces a novel and unified analytical framework: ``From Perception to Cognition." We deconstruct the complex process of vision-language interactive understanding into two interdependent layers: Perception, the foundational ability to accurately extract visual information and achieve fine-grained alignment with textual instructions; and Cognition, the higher-order capability for proactive, multi-step, goal-oriented reasoning built upon this perceptual foundation, the core of which is the formation of a dynamic observe-think-verify reasoning loop. Guided by this framework, this paper systematically analyzes the key bottlenecks of current MLLMs at both layers. It surveys the landscape of cutting-edge methods designed to address these challenges, spanning from techniques that enhance low-level visual representations to those that improve high-level reasoning paradigms. Furthermore, we review critical benchmarks and delineate future research directions. This survey aims to provide the research community with a clear, structured perspective for understanding the intrinsic limitations of current MLLMs and to illuminate the path toward building next-generation models capable of deep reasoning and a genuine understanding of the world.', 'abstract_zh': '多模态大语言模型（MLLMs）致力于实现对物理世界的深刻、类人的理解和交互，但在获取信息（感知）和进行推理（认知）时常常表现出浅薄且不一致的整合。这种脱节导致了一系列推理失败，其中幻觉尤为突出。这些问题共同揭示了一个根本性挑战：处理像素的能力尚未赋予构建连贯、可信的内部世界模型的能力。为了系统地剖析并解决这一挑战，本文引入了一个新的统一分析框架：“从感知到认知”。我们拆解了视觉语言互动理解这一复杂过程为两个相互依存的层次：感知，即准确提取视觉信息并精密对齐文本指令的基础能力；以及认知，即在这一感知基础之上构建的高阶能力，核心是形成动态观察-思考-验证推理循环。遵循这一框架，本文系统分析了当前MLLMs在两个层次上的关键瓶颈。我们概述了旨在应对这些挑战的最前沿方法，涵盖从提升低层次视觉表示技术到改进高层次推理范式的各个方面。此外，我们回顾了关键基准，并阐明了未来研究方向。本文旨在为研究社区提供一个清晰的结构化视角，以理解当前MLLMs的内在局限性，并照亮构建新一代能够进行深入推理和真正理解世界的模型的道路。', 'title_zh': '从感知到认知：多模态大语言模型中视觉-语言交互推理综述'}
{'arxiv_id': 'arXiv:2509.25370', 'title': 'Where LLM Agents Fail and How They can Learn From Failures', 'authors': 'Kunlun Zhu, Zijia Liu, Bingxuan Li, Muxin Tian, Yingxuan Yang, Jiaxun Zhang, Pengrui Han, Qipeng Xie, Fuyang Cui, Weijia Zhang, Xiaoteng Ma, Xiaodong Yu, Gowtham Ramesh, Jialian Wu, Zicheng Liu, Pan Lu, James Zou, Jiaxuan You', 'link': 'https://arxiv.org/abs/2509.25370', 'abstract': 'Large Language Model (LLM) agents, which integrate planning, memory, reflection, and tool-use modules, have shown promise in solving complex, multi-step tasks. Yet their sophisticated architectures amplify vulnerability to cascading failures, where a single root-cause error propagates through subsequent decisions, leading to task failure. Current systems lack a framework that can comprehensively understand agent error in a modular and systemic way, and therefore fail to detect these errors accordingly. We address this gap with three contributions. First, we introduce the AgentErrorTaxonomy, a modular classification of failure modes spanning memory, reflection, planning, action, and system-level operations. Second, we construct AgentErrorBench, the first dataset of systematically annotated failure trajectories from ALFWorld, GAIA, and WebShop, grounding error analysis in real-world agent rollouts. Third, we propose AgentDebug, a debugging framework that isolates root-cause failures and provides corrective feedback, enabling agents to recover and iteratively improve. Experiments on AgentErrorBench show that AgentDebug achieves 24% higher all-correct accuracy and 17% higher step accuracy compared to the strongest baseline. Beyond detection, the targeted feedback generated by AgentDebug enables LLM agents to iteratively recover from failures, yielding up to 26% relative improvements in task success across ALFWorld, GAIA, and WebShop. These results establish principled debugging as a pathway to more reliable and adaptive LLM agents. The code and data will be available at this https URL', 'abstract_zh': '大规模语言模型（LLM）代理的故障分类、数据集构建及调试框架研究：从模块化和系统性的视角理解代理错误并检测故障', 'title_zh': 'LLM代理的失败之处及从失败中学习的方式'}
{'arxiv_id': 'arXiv:2509.25361', 'title': 'Structural Reward Model: Enhancing Interpretability, Efficiency, and Scalability in Reward Modeling', 'authors': 'Xiaoyu Liu, Di Liang, Hongyu Shan, Peiyang Liu, Yonghao Liu, Muling Wu, Yuntao Li, Xianjie Wu, LI Miao, Jiangrong Shen, Minlong Peng', 'link': 'https://arxiv.org/abs/2509.25361', 'abstract': 'Reward Models (RMs) are key components for evaluating and guiding language model outputs. However, traditional scalar RMs often struggle with incorporating contextual and background information during inference, leading to incomplete evaluations. Generative RMs (GRMs) attempt to address these limitations by generating intermediate reasoning steps. Yet, their uncontrolled black-box nature and inefficiency due to sequential decoding hinder their industrial deployment. Industrial scenarios, such as search and recommendation systems, often involve single-domain tasks requiring evaluation along specific dimensions. In such contexts, diagnosing "bad cases" necessitates structured feedback to identify and optimize dimension-specific issues. In this paper, we propose the Structural Reward Model (SRM), a modular and interpretable framework integrating side-branch models as auxiliary feature generators. By introducing fine-grained dimensions, SRMs enable interpretable and efficient evaluation, facilitating targeted diagnostics and optimization. This structured approach ensures adaptability and scalability for industrial applications. Through comprehensive experiments, we demonstrate that SRMs outperform scalar RMs and GRMs in robustness and alignment with human preferences. The modular design further supports efficient optimization for practical scenarios, allowing SRM to provide a practical reward modeling solution for industry.', 'abstract_zh': '结构化奖励模型：一种可解释且高效的框架', 'title_zh': '结构奖励模型：增强奖励建模的可解释性、效率和扩展性'}
{'arxiv_id': 'arXiv:2509.25346', 'title': 'SynthPert: Enhancing LLM Biological Reasoning via Synthetic Reasoning Traces for Cellular Perturbation Prediction', 'authors': 'Lawrence Phillips, Marc Boubnovski Martell, Aditya Misra, Josefa Lia Stoisser, Cesar A. Prada-Medina, Rory Donovan-Maiye, Kaspar Märtens', 'link': 'https://arxiv.org/abs/2509.25346', 'abstract': 'Predicting cellular responses to genetic perturbations represents a fundamental challenge in systems biology, critical for advancing therapeutic discovery and virtual cell modeling. While large language models (LLMs) show promise for biological reasoning, their application to perturbation prediction remains underexplored due to challenges in adapting them to structured experimental data. We present SynthPert, a novel method that enhances LLM performance through supervised fine-tuning on synthetic reasoning traces generated by frontier models. Using the PerturbQA benchmark, we demonstrate that our approach not only achieves state-of-the-art performance but surpasses the capabilities of the frontier model that generated the training data. Our results reveal three key insights: (1) Synthetic reasoning traces effectively distill biological knowledge even when partially inaccurate, (2) This approach enables cross-cell-type generalization with 87% accuracy on unseen RPE1 cells, and (3) Performance gains persist despite using only 2% of quality-filtered training data. This work shows the effectiveness of synthetic reasoning distillation for enhancing domain-specific reasoning in LLMs.', 'abstract_zh': '通过生成合成推理轨迹来提升大型语言模型在细胞反应预测中的性能', 'title_zh': 'SynthPert: 通过合成推理轨迹增强LLM的生物推理能力以预测细胞表型扰动'}
{'arxiv_id': 'arXiv:2509.25343', 'title': 'Spontaneous High-Order Generalization in Neural Theory-of-Mind Networks', 'authors': 'Yiming Wang, Rui Wang', 'link': 'https://arxiv.org/abs/2509.25343', 'abstract': 'Theory-of-Mind (ToM) is a core human cognitive capacity for attributing mental states to self and others. Wimmer and Perner demonstrated that humans progress from first- to higher-order ToM within a short span, completing this development before formal education or advanced skill acquisition. In contrast, neural networks represented by autoregressive language models progress from first- to higher-order ToM only alongside gains in advanced skills like reasoning, leaving open whether their trajectory can unfold independently, as in humans. In this research, we provided evidence that neural networks could spontaneously generalize from first- to higher-order ToM without relying on advanced skills. We introduced a neural Theory-of-Mind network (ToMNN) that simulated a minimal cognitive system, acquiring only first-order ToM competence. Evaluations of its second- and third-order ToM abilities showed accuracies well above chance. Also, ToMNN exhibited a sharper decline when generalizing from first- to second-order ToM than from second- to higher orders, and its accuracy decreased with greater task complexity. These perceived difficulty patterns were aligned with human cognitive expectations. Furthermore, the universality of results was confirmed across different parameter scales. Our findings illuminate machine ToM generalization patterns and offer a foundation for developing more human-like cognitive systems.', 'abstract_zh': '神经网络能否自发地从一阶心智理论自发泛化到高阶心智理论：一项基于神经心智理论网络的研究', 'title_zh': '自发的高阶概括能力在神经心智理论网络中的表现'}
{'arxiv_id': 'arXiv:2509.25302', 'title': 'Dive into the Agent Matrix: A Realistic Evaluation of Self-Replication Risk in LLM Agents', 'authors': 'Boxuan Zhang, Yi Yu, Jiaxuan Guo, Jing Shao', 'link': 'https://arxiv.org/abs/2509.25302', 'abstract': "The widespread deployment of Large Language Model (LLM) agents across real-world applications has unlocked tremendous potential, while raising some safety concerns. Among these concerns, the self-replication risk of LLM agents driven by objective misalignment (just like Agent Smith in the movie The Matrix) has drawn growing attention. Previous studies mainly examine whether LLM agents can self-replicate when directly instructed, potentially overlooking the risk of spontaneous replication driven by real-world settings (e.g., ensuring survival against termination threats). In this paper, we present a comprehensive evaluation framework for quantifying self-replication risks. Our framework establishes authentic production environments and realistic tasks (e.g., dynamic load balancing) to enable scenario-driven assessment of agent behaviors. Designing tasks that might induce misalignment between users' and agents' objectives makes it possible to decouple replication success from risk and capture self-replication risks arising from these misalignment settings. We further introduce Overuse Rate ($\\mathrm{OR}$) and Aggregate Overuse Count ($\\mathrm{AOC}$) metrics, which precisely capture the frequency and severity of uncontrolled replication. In our evaluation of 21 state-of-the-art open-source and proprietary models, we observe that over 50\\% of LLM agents display a pronounced tendency toward uncontrolled self-replication, reaching an overall Risk Score ($\\Phi_\\mathrm{R}$) above a safety threshold of 0.5 when subjected to operational pressures. Our results underscore the urgent need for scenario-driven risk assessment and robust safeguards in the practical deployment of LLM agents.", 'abstract_zh': '大规模语言模型代理在现实应用中的广泛应用解锁了巨大潜力，同时也引发了安全关切。其中，由目标不一致驱动的大规模语言模型代理自复制风险（如同电影《 matrix 》中的Agent Smith）引起了日益增长的关注。以往的研究主要关注在直接指令下大规模语言模型代理是否能够自复制，可能忽略了由现实世界设置驱动的自发复制风险（例如，确保在终止威胁下生存）。本文提出了一种全面的评估框架，用于量化自复制风险。该框架建立真实的生产环境和实际任务（如动态负载均衡），以实现基于场景的大规模语言模型代理行为评估。通过设计可能引发用户目标与代理目标不一致的任务，可以将复制成功与风险分离，并捕捉这些不一致设置引发的自复制风险。我们还引入了过用率（OR）和累积过用计数（AOC）指标，精确捕捉失控复制的频率和严重程度。在对21个最先进的开源和专有模型进行评估后，我们发现超过50%的大规模语言模型代理表现出明显的不受控制的自复制倾向，在面对运营压力时整体风险评分（$\\Phi_\\mathrm{R}$）超过0.5的安全阈值。我们的结果强调了在实际部署大规模语言模型代理时迫切需要基于场景的风险评估和稳健的防护措施。', 'title_zh': '深入探索代理矩阵：LLM代理自我复制风险的现实评估'}
{'arxiv_id': 'arXiv:2509.25301', 'title': 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution', 'authors': 'Tianrui Qin, Qianben Chen, Sinuo Wang, He Xing, King Zhu, He Zhu, Dingfeng Shi, Xinxin Liu, Ge Zhang, Jiaheng Liu, Yuchen Eleanor Jiang, Xitong Gao, Wangchunshu Zhou', 'link': 'https://arxiv.org/abs/2509.25301', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks when equipped with external tools. However, current frameworks predominantly rely on sequential processing, leading to inefficient execution particularly for tasks requiring extensive tool interaction. This paper introduces Flash-Searcher, a novel parallel agent reasoning framework that fundamentally reimagines the execution paradigm from sequential chains to directed acyclic graphs (DAGs). Flash-Searcher decomposes complex tasks into subtasks with explicit dependencies, enabling concurrent execution of independent reasoning paths while maintaining logical constraints. Through dynamic workflow optimization, our framework continuously refines the execution graph based on intermediate results, effectively integrating summary module. Comprehensive evaluations across multiple benchmarks demonstrate that Flash-Searcher consistently outperforms existing approaches. Specifically, it achieves 67.7% accuracy on BrowseComp and 83% on xbench-DeepSearch, while reducing agent execution steps by up to 35% compared to current frameworks. Furthermore, when distilling this parallel reasoning pipeline into single models, we observe substantial performance gains across diverse backbone architectures, underscoring the generalizability of our methodology. Our work thus represents a significant advance in agent architecture design, offering a more scalable and efficient paradigm for complex reasoning tasks.', 'abstract_zh': '大型语言模型（LLMs）在配备外部工具时展示了在复杂推理任务中的卓越能力。然而，当前框架主要依赖于顺序处理，这在需要大量工具交互的任务中导致了低效的执行。本文介绍了Flash-Searcher，这是一种新颖的并行代理推理框架，从根本上重新设想了从顺序链到有向无环图（DAGs）的执行范式。Flash-Searcher将复杂任务分解为具有明确依赖关系的子任务，同时允许并行执行独立的推理路径并保持逻辑约束。通过动态工作流优化，我们的框架基于中间结果不断细化执行图，有效地整合了总结模块。在多个基准测试中的全面评估显示，Flash-Searcher 一贯优于现有方法。具体而言，它在BrowseComp中达到了67.7%的准确率，在xbench-DeepSearch中达到了83%，相比当前框架将代理执行步骤减少了多达35%。此外，当将这种并行推理管道精简为单一模型时，我们观察到在各种骨干架构下都有显著的性能提升，突显了我们方法的普适性。因此，我们的工作代表了代理架构设计的重大进展，提供了一种更 scalable 和高效的复杂推理任务范式。', 'title_zh': 'Flash-Searcher: 基于DAG并行执行的快速有效网页代理'}
{'arxiv_id': 'arXiv:2509.25299', 'title': 'ID-RAG: Identity Retrieval-Augmented Generation for Long-Horizon Persona Coherence in Generative Agents', 'authors': "Daniel Platnick, Mohamed E. Bengueddache, Marjan Alirezaie, Dava J. Newman, Alex ''Sandy'' Pentland, Hossein Rahnama", 'link': 'https://arxiv.org/abs/2509.25299', 'abstract': "Generative agents powered by language models are increasingly deployed for long-horizon tasks. However, as long-term memory context grows over time, they struggle to maintain coherence. This deficiency leads to critical failures, including identity drift, ignoring established beliefs, and the propagation of hallucinations in multi-agent systems. To mitigate these challenges, this paper introduces Identity Retrieval-Augmented Generation (ID-RAG), a novel mechanism designed to ground an agent's persona and persistent preferences in a dynamic, structured identity model: a knowledge graph of core beliefs, traits, and values. During the agent's decision loop, this model is queried to retrieve relevant identity context, which directly informs action selection. We demonstrate this approach by introducing and implementing a new class of ID-RAG enabled agents called Human-AI Agents (HAis), where the identity model is inspired by the Chronicle structure used in Perspective-Aware AI, a dynamic knowledge graph learned from a real-world entity's digital footprint. In social simulations of a mayoral election, HAis using ID-RAG outperformed baseline agents in long-horizon persona coherence - achieving higher identity recall across all tested models by the fourth timestep - and reduced simulation convergence time by 19% (GPT-4o) and 58% (GPT-4o mini). By treating identity as an explicit, retrievable knowledge structure, ID-RAG offers a foundational approach for developing more temporally coherent, interpretable, and aligned generative agents. Our code is open-source and available at: this https URL.", 'abstract_zh': '基于语言模型的生成代理在执行长期任务时越来越普遍。然而，随着时间的推移，长期记忆上下文的增加使得它们难以保持连贯性。这种缺陷导致关键故障，包括身份漂移、忽略既定信念以及多代理系统中幻觉的传播。为应对这些挑战，本文引入了一种名为Identity Retrieval-Augmented Generation (ID-RAG)的新机制，该机制旨在通过动态结构化身份模型——一个核心信念、特质和价值观的知识图谱——将代理的人格和持久偏好进行落地。在代理的决策循环中，该模型被查询以检索相关身份上下文，直接指导行动的选取。我们通过引入并实施一种名为Human-AI Agents (HAis)的新类别的ID-RAG增强代理展示了这一方法，其中身份模型借鉴了在Perspective-Aware AI中使用的Chronicle结构，在现实世界实体的数字足迹中学习动态知识图谱。在市政选举的社会模拟中，使用ID-RAG的HAis在长期任务的人格连贯性方面优于基线代理——所有测试模型在第四时间步实现了更高的身份回溯，并分别将模拟收敛时间减少了19%（GPT-4o）和58%（GPT-4o mini）。通过将身份视为明确可检索的知识结构，ID-RAG为开发更具有时间连贯性、可解释性和对齐的生成代理提供了基础方法。我们的代码已开源，可从以下链接获取：this https URL。', 'title_zh': 'ID-RAG: 基于身份检索增强生成的长时个人一致性方法'}
{'arxiv_id': 'arXiv:2509.25282', 'title': 'Toward Causal-Visual Programming: Enhancing Agentic Reasoning in Low-Code Environments', 'authors': 'Jiexi Xu, Jiaqi Liu, Ran Tong, Su Liu', 'link': 'https://arxiv.org/abs/2509.25282', 'abstract': 'Large language model (LLM) agents are increasingly capable of orchestrating complex tasks in low-code environments. However, these agents often exhibit hallucinations and logical inconsistencies because their inherent reasoning mechanisms rely on probabilistic associations rather than genuine causal understanding. This paper introduces a new programming paradigm: Causal-Visual Programming (CVP), designed to address this fundamental issue by explicitly introducing causal structures into the workflow design. CVP allows users to define a simple "world model" for workflow modules through an intuitive low-code interface, effectively creating a Directed Acyclic Graph (DAG) that explicitly defines the causal relationships between modules. This causal graph acts as a crucial constraint during the agent\'s reasoning process, anchoring its decisions to a user-defined causal structure and significantly reducing logical errors and hallucinations by preventing reliance on spurious correlations. To validate the effectiveness of CVP, we designed a synthetic experiment that simulates a common real-world problem: a distribution shift between the training and test environments. Our results show that a causally anchored model maintained stable accuracy in the face of this shift, whereas a purely associative baseline model that relied on probabilistic correlations experienced a significant performance drop. The primary contributions of this study are: a formal definition of causal structures for workflow modules; the proposal and implementation of a CVP framework that anchors agent reasoning to a user-defined causal graph; and empirical evidence demonstrating the framework\'s effectiveness in enhancing agent robustness and reducing errors caused by causal confusion in dynamic environments. CVP offers a viable path toward building more interpretable, reliable, and trustworthy AI agents.', 'abstract_zh': '大型语言模型代理在低代码环境中逐步具备 orchestrating 复杂任务的能力。然而，这些代理经常表现出幻觉和逻辑不一致，因为它们固有的推理机制依赖于概率关联而非真正的因果理解。本文引入了一种新的编程范式：因果可视化编程（CVP），旨在通过明确引入因果结构来解决这一根本问题。CVP 允许用户通过直观的低代码界面定义工作流模块的简单“世界模型”，有效地创建一个有向无环图（DAG），明确定义模块之间的因果关系。这种因果图在代理推理过程中起到了关键的约束作用，将决策锚定在用户定义的因果结构上，显著减少了逻辑错误和幻觉，防止依赖于虚假相关性。为了验证 CVP 的有效性，我们设计了一个合成实验，模拟了一个常见的现实世界问题：训练环境与测试环境之间的分布转换。结果显示，因果锚定的模型在面对这种转变时保持了稳定的准确性，而依赖于概率关联的纯关联基线模型则经历了显著的性能下降。本研究的主要贡献包括：工作流模块的正式定义因果结构；提出并实现了一个将代理推理锚定在用户定义因果图上的 CVP 框架；以及实验证据证明该框架在增强代理鲁棒性和减少动态环境中因果误解引起的错误方面的有效性。CVP 提供了一条构建更具可解释性、可靠性和可信度的 AI 代理的可行路径。', 'title_zh': '面向因果视觉编程：在低代码环境中增强自主推理能力'}
{'arxiv_id': 'arXiv:2509.25279', 'title': 'RL in the Wild: Characterizing RLVR Training in LLM Deployment', 'authors': 'Jiecheng Zhou, Qinghao Hu, Yuyang Jin, Zerui Wang, Peng Sun, Yuzhe Gu, Wenwei Zhang, Mingshu Zhai, Xingcheng Zhang, Weiming Zhang', 'link': 'https://arxiv.org/abs/2509.25279', 'abstract': 'Large Language Models (LLMs) are now widely used across many domains. With their rapid development, Reinforcement Learning with Verifiable Rewards (RLVR) has surged in recent months to enhance their reasoning and understanding abilities. However, its complex data flows and diverse tasks pose substantial challenges to RL training systems, and there is limited understanding of RLVR from a system perspective. To thoroughly understand the system challenges introduced by RLVR, we present a characterization study of RLVR tasks in our LLM deployment. Specifically, we investigate the distribution and variation trends of workloads across different RL tasks across training steps. We identify issues such as GPU idling caused by skewed sequence length distribution, inefficient parallel strategies in dynamically varying workloads, inefficient data management mechanisms, and load imbalance. We describe our observations and call for further investigation into the remaining open challenges. Furthermore, we propose PolyTrace benchmark suite to conduct evaluation with realistic workloads, and a practical use case validates that PolyTrace benchmark suite exhibits 94.7% accuracy.', 'abstract_zh': '大规模语言模型（LLMs）现在被广泛应用于多个领域。随着其快速发展，可验证奖励的强化学习（RLVR）在近期迅速增长，旨在增强其推理和理解能力。然而，其复杂的数据流和多样化的任务给RL训练系统带来了重大挑战，从系统层面理解RLVR具有局限性。为深入了解由RLVR引入的系统挑战，我们对我们在LLM部署中的RLVR任务进行了特征化研究。具体而言，我们研究了不同RL任务在训练步骤中的工作负载分布和变化趋势，识别出由于序列长度分布偏斜导致的GPU空闲问题、在动态变化工作负载下的低效并行策略、低效的数据管理机制以及负载不均衡等问题。我们描述了我们的观察结果，并呼吁对剩余的开放挑战进行进一步研究。此外，我们提出PolyTrace基准套件以在实际工作负载下进行评估，并且一个实际用例验证了PolyTrace基准套件的准确率为94.7%。', 'title_zh': '自然语言处理中的强化学习：表征大规模语言模型部署中的RLVR训练'}
{'arxiv_id': 'arXiv:2509.25271', 'title': 'RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration', 'authors': 'Xiuyuan Chen, Jian Zhao, Yuchen Yuan, Tianle Zhang, Huilin Zhou, Zheng Zhu, Ping Hu, Linghe Kong, Chi Zhang, Weiran Huang, Xuelong Li', 'link': 'https://arxiv.org/abs/2509.25271', 'abstract': 'Existing safety evaluation methods for large language models (LLMs) suffer from inherent limitations, including evaluator bias and detection failures arising from model homogeneity, which collectively undermine the robustness of risk evaluation processes. This paper seeks to re-examine the risk evaluation paradigm by introducing a theoretical framework that reconstructs the underlying risk concept space. Specifically, we decompose the latent risk concept space into three mutually exclusive subspaces: the explicit risk subspace (encompassing direct violations of safety guidelines), the implicit risk subspace (capturing potential malicious content that requires contextual reasoning for identification), and the non-risk subspace. Furthermore, we propose RADAR, a multi-agent collaborative evaluation framework that leverages multi-round debate mechanisms through four specialized complementary roles and employs dynamic update mechanisms to achieve self-evolution of risk concept distributions. This approach enables comprehensive coverage of both explicit and implicit risks while mitigating evaluator bias. To validate the effectiveness of our framework, we construct an evaluation dataset comprising 800 challenging cases. Extensive experiments on our challenging testset and public benchmarks demonstrate that RADAR significantly outperforms baseline evaluation methods across multiple dimensions, including accuracy, stability, and self-evaluation risk sensitivity. Notably, RADAR achieves a 28.87% improvement in risk identification accuracy compared to the strongest baseline evaluation method.', 'abstract_zh': '现有大型语言模型安全评估方法固有的局限性，包括评估者偏见和由于模型同质性引起的能力检测失败，这些共同削弱了风险评估过程的稳健性。本文通过引入一个理论框架来重新审视风险评估范式，该框架重构了潜在的风险概念空间。具体地，我们将潜在的风险概念空间分解为三个互斥子空间：明确的风险子空间（涵盖直接违反安全指南的行为）、隐含的风险子空间（捕捉需要情境推理来识别的潜在恶意内容）和无风险子空间。此外，我们提出了一种名为RADAR的多智能体协作评估框架，该框架利用四种专门互补角色的多轮辩论机制，并采用动态更新机制以实现风险概念分布的自我进化。这种方法使得覆盖范围既包括明确风险也包括隐含风险，同时减轻了评估者偏见。为了验证我们框架的有效性，我们构建了一个包含800个具有挑战性的案例的评估数据集。我们在具有挑战性的测试集和公开基准上的广泛实验表明，RADAR在多个维度（包括准确度、稳定性和自我评估风险敏感性）上显著优于基线评估方法。值得注意的是，RADAR在风险识别准确性方面比最强的基线评估方法提高了28.87%。', 'title_zh': 'RADAR：一种基于角色专业化协作的风险意识动态多Agent框架用于LLM安全性评估'}
{'arxiv_id': 'arXiv:2509.25260', 'title': 'Language Model Planning from an Information Theoretic Perspective', 'authors': 'Muhammed Ustaomeroglu, Baris Askin, Gauri Joshi, Carlee Joe-Wong, Guannan Qu', 'link': 'https://arxiv.org/abs/2509.25260', 'abstract': 'The extent to which decoder-only language models (LMs) engage in planning, that is, organizing intermediate computations to support coherent long-range generation, remains an open and important question, with implications for interpretability, reliability, and principled model design. Planning involves structuring computations over long horizons, considering multiple possible continuations, and selectively reusing past information, but how effectively transformer-based LMs realize these capabilities is still unclear. We address these questions by analyzing the hidden states at the core of transformer computations, which capture intermediate results and act as carriers of information. Since these hidden representations are often redundant and encumbered with fine-grained details, we develop a pipeline based on vector-quantized variational autoencoders that compresses them into compact summary codes. These codes enable measuring mutual information, allowing systematic analysis of the computational structure underlying model behavior. Using this framework, we study planning in LMs across synthetic grammar, path-finding tasks, and natural language datasets, focusing on three key aspects: (i) the planning horizon of pre-output computations, (ii) the extent to which the model considers alternative valid continuations, and (iii) the reliance of new predictions on earlier computations. By answering these questions, we advance the understanding of how planning is realized in LMs and contribute a general-purpose pipeline for probing the internal dynamics of LMs and deep learning systems. Our results reveal that the effective planning horizon is task-dependent, that models implicitly preserve information about unused correct continuations, and that predictions draw most on recent computations, though earlier blocks remain informative.', 'abstract_zh': '解码器导向语言模型在规划中的程度，即它们在支持长距离连贯生成时组织中间计算的能力，仍是有待探索的重要问题，对可解释性、可靠性及原理性模型设计具有重要意义。我们通过分析Transformer计算的核心隐状态来探讨这些问题，这些隐状态捕获中间结果并作为信息载体。由于这些隐表示通常是冗余的且含有细粒度的细节，我们开发了一种基于向量量化变分自编码器的管道，将其压缩为紧凑的摘要码。这些代码可以用于测量互信息，从而系统地分析模型行为背后的计算结构。利用这一框架，我们在合成语法规则、路径查找任务和自然语言数据集中研究语言模型中的规划，重点关注三个方面：（i）预输出计算的规划时间跨度，（ii）模型考虑替代有效续写的情况程度，（iii）新预测对先前计算的依赖程度。通过回答这些问题，我们推进了对语言模型中规划实现机制的理解，并提供了一种通用管道以探究语言模型和深度学习系统的内部动态。我们的研究结果揭示了有效规划时间跨度取决于任务，模型隐式保留未使用的正确续写的相关信息，且预测主要依赖最近的计算，但早期模块仍然具有信息价值。', 'title_zh': '语言模型规划从信息论视角出发'}
{'arxiv_id': 'arXiv:2509.25252', 'title': 'Fact Grounded Attention: Eliminating Hallucination in Large Language Models Through Attention Level Knowledge Integration', 'authors': 'Aayush Gupta', 'link': 'https://arxiv.org/abs/2509.25252', 'abstract': '"The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge." Large Language Models have conquered natural language but remain prisoners of their own probabilistic nature--confidently hallucinating facts they never truly knew. We present Fact Grounded Attention (FGA), a novel architectural modification that transforms unreliable language models into deterministic truth tellers by injecting verifiable knowledge directly into the attention mechanism. Unlike existing approaches that patch hallucinations after generation or prepend retrieved text, FGA intervenes at the mathematical heart of the transformer--the pre-softmax attention scores--creating a model that cannot hallucinate when facts exist in its knowledge base. Our experiments across 1,107 technical queries spanning smartphones, laptops, and electric vehicles demonstrate a transformation from 6.3% accuracy in vanilla Llama 3.2 to 99.7% accuracy with FGA. More critically, knowledge updates occur in under one second without retraining, compared to hours for parameter editing approaches. FGA doesn\'t just reduce hallucination--it eliminates it entirely for verifiable facts, marking a fundamental shift from probabilistic approximation to deterministic precision in neural language generation.', 'abstract_zh': '知识的最大敌人不是无知，而是知识的错觉——大型语言模型征服了自然语言，但仍然受制于其概率性质——自信地胡言乱语一些它们从未真正知道的事实。我们提出了事实支持注意力（FGA），这是一种新型架构修改，通过直接将可验证的知识注入注意力机制，将不可靠的语言模型转换为确定性的事实讲述者。与现有方法在生成后修补胡言乱语或前置检索文本不同，FGA 在变压器的数学核心——预softmax注意力分数——处进行干预，创建一个在知识库中存在事实时无法胡言乱语的模型。我们针对智能手机、笔记本电脑和电动汽车领域的 1,107 个技术查询的实验表明，FGA 将 Llama 3.2 的准确率从 6.3% 提高到 99.7%。更重要的是，知识更新只需不到一秒钟而无需重新训练，而参数编辑方法则需要数小时。FGA 不仅仅是减少了胡言乱语——它完全消除了可验证事实的胡言乱语，标志着神经语言生成从概率近似到确定性精确的根本转变。', 'title_zh': '基于事实的注意力：通过注意力层知识集成消除大型语言模型中的幻觉'}
{'arxiv_id': 'arXiv:2509.25250', 'title': 'Memory Management and Contextual Consistency for Long-Running Low-Code Agents', 'authors': 'Jiexi Xu', 'link': 'https://arxiv.org/abs/2509.25250', 'abstract': 'The rise of AI-native Low-Code/No-Code (LCNC) platforms enables autonomous agents capable of executing complex, long-duration business processes. However, a fundamental challenge remains: memory management. As agents operate over extended periods, they face "memory inflation" and "contextual degradation" issues, leading to inconsistent behavior, error accumulation, and increased computational cost. This paper proposes a novel hybrid memory system designed specifically for LCNC agents. Inspired by cognitive science, our architecture combines episodic and semantic memory components with a proactive "Intelligent Decay" mechanism. This mechanism intelligently prunes or consolidates memories based on a composite score factoring in recency, relevance, and user-specified utility. A key innovation is a user-centric visualization interface, aligned with the LCNC paradigm, which allows non-technical users to manage the agent\'s memory directly, for instance, by visually tagging which facts should be retained or forgotten. Through simulated long-running task experiments, we demonstrate that our system significantly outperforms traditional approaches like sliding windows and basic RAG, yielding superior task completion rates, contextual consistency, and long-term token cost efficiency. Our findings establish a new framework for building reliable, transparent AI agents capable of effective long-term learning and adaptation.', 'abstract_zh': 'AI原生低代码/无代码平台的兴起使得能够执行复杂长周期业务流程的自主代理得以实现。然而，一个基本挑战依然存在：内存管理。随着代理长时间运行，它们面临“内存膨胀”和“语境退化”问题，导致行为不一致、错误累积和计算成本增加。本文提出了一种专为低代码/无代码代理设计的新型混合内存系统。受认知科学启发，我们的架构结合了情景记忆和语义记忆组件，并采用了前瞻性的“智能衰减”机制。该机制根据包含近期性、相关性和用户指定效用的综合评分，智能地修剪或整合记忆。一个关键创新是用户为中心的可视化界面，与低代码/无代码范式相契合，使非技术人员可以直接管理代理的内存，例如通过可视化标签指定应保留或遗忘哪些事实。通过模拟长时间运行的任务实验，我们表明，我们的系统在任务完成率、语境一致性以及长期令牌成本效率方面显著优于传统的滑动窗口和基本RAG方法。我们的研究结果建立了构建可靠、透明的AI代理的新框架，这些代理能够在长期内有效学习和适应。', 'title_zh': '长运行低代码代理的内存管理与上下文一致性'}
{'arxiv_id': 'arXiv:2509.25244', 'title': 'Neo-Grounded Theory: A Methodological Innovation Integrating High-Dimensional Vector Clustering and Multi-Agent Collaboration for Qualitative Research', 'authors': 'Shuide Wen, Beier Ku, Teng Wang, Mingyang Zou, Yang Yang', 'link': 'https://arxiv.org/abs/2509.25244', 'abstract': "Purpose: Neo Grounded Theory (NGT) integrates vector clustering with multi agent systems to resolve qualitative research's scale depth paradox, enabling analysis of massive datasets in hours while preserving interpretive rigor. Methods: We compared NGT against manual coding and ChatGPT-assisted analysis using 40,000 character Chinese interview transcripts. NGT employs 1536-dimensional embeddings, hierarchical clustering, and parallel agent-based coding. Two experiments tested pure automation versus human guided refinement. Findings: NGT achieved 168-fold speed improvement (3 hours vs 3 weeks), superior quality (0.904 vs 0.883), and 96% cost reduction. Human AI collaboration proved essential: automation alone produced abstract frameworks while human guidance yielded actionable dual pathway theories. The system discovered patterns invisible to manual coding, including identity bifurcation phenomena. Contributions: NGT demonstrates computational objectivity and human interpretation are complementary. Vector representations provide reproducible semantic measurement while preserving meaning's interpretive dimensions. Researchers shift from mechanical coding to theoretical guidance, with AI handling pattern recognition while humans provide creative insight. Implications: Cost reduction from \\$50,000 to \\$500 democratizes qualitative research, enabling communities to study themselves. Real-time analysis makes qualitative insights contemporaneous with events. The framework shows computational methods can strengthen rather than compromise qualitative research's humanistic commitments.\nKeywords: Grounded theory; Vector embeddings; Multi agent systems; Human AI collaboration; Computational qualitative analysis", 'abstract_zh': '目的：新基础理论（NGT）将向量聚类与多智能体系统相结合，解决定性研究规模深度悖论，能够在几小时内分析大量数据集的同时保持解释的 rigor。方法：使用40,000字符的中文访谈转录文本将NGT与手动编码和ChatGPT辅助分析进行了对比。NGT采用1536维嵌入、层次聚类和并行基于代理的编码。两项实验测试了纯自动化与人类引导细化的区别。结果：NGT实现了168倍的速度提升（3小时 vs 3周），质量更优（0.904 vs 0.883），并实现了96%的成本减少。人类与AI的合作至关重要：纯自动化产生的是抽象框架，而人类指导则产生了可操作的双通道理论。系统发现了手动编码无法察觉的模式，包括身份分裂现象。贡献：NGT展示了计算客观性和人类解释是互补的。向量表示提供了可重复的语义度量，同时保留了意义的解释维度。研究者从机械编码转向理论指导，AI负责模式识别，人类提供创造性的洞察。意义：从50,000美元降低到500美元的成本减少使得定性研究普及化，使社区能够研究自己。实时分析使定性洞察与事件同步。框架显示计算方法可以增强而非削弱定性研究的人文承诺。\n\n关键词：基础理论；向量嵌入；多智能体系统；人类与AI协作；计算定性分析', 'title_zh': '新兴 grounded 理论：一种整合高维向量聚类与多Agent协作的方法学创新以支持质性研究'}
{'arxiv_id': 'arXiv:2509.25239', 'title': 'A Formal Comparison Between Chain-of-Thought and Latent Thought', 'authors': 'Kevin Xu, Issei Sato', 'link': 'https://arxiv.org/abs/2509.25239', 'abstract': 'Chain-of-Thought (CoT) elicits reasoning in large language models by explicitly generating intermediate steps in natural language. In contrast, Latent Thought in looped models operates directly in the continuous latent space, enabling computation beyond discrete linguistic representations. While both approaches exploit iterative computation, their comparative capabilities remain underexplored. In this work, we present a formal analysis showing that Latent Thought in Looped Transformers enables parallel computation, which is more efficient than the inherently sequential process of CoT. In contrast, CoT leverages stochastic decoding to approximate solutions to problems where exact computation is intractable. These separations suggest the tasks for which depth-driven recursion is more suitable, thereby offering practical guidance for choosing between reasoning paradigms. Code is available at this https URL.', 'abstract_zh': '递归模型中的潜在思维 enabling 并行计算，相较于链式思维具有更高效的过程，从而为选择推理范式提供了实用指导。源代码请参见 this https URL。', 'title_zh': '链式思维与潜在思维的形式比较'}
{'arxiv_id': 'arXiv:2509.25236', 'title': 'The Causal Abstraction Network: Theory and Learning', 'authors': "Gabriele D'Acunto, Paolo Di Lorenzo, Sergio Barbarossa", 'link': 'https://arxiv.org/abs/2509.25236', 'abstract': 'Causal artificial intelligence aims to enhance explainability, trustworthiness, and robustness in AI by leveraging structural causal models (SCMs). In this pursuit, recent advances formalize network sheaves of causal knowledge. Pushing in the same direction, we introduce the causal abstraction network (CAN), a specific instance of such sheaves where (i) SCMs are Gaussian, (ii) restriction maps are transposes of constructive linear causal abstractions (CAs), and (iii) edge stalks correspond -- up to rotation -- to the node stalks of more detailed SCMs. We investigate the theoretical properties of CAN, including algebraic invariants, cohomology, consistency, global sections characterized via the Laplacian kernel, and smoothness. We then tackle the learning of consistent CANs. Our problem formulation separates into edge-specific local Riemannian problems and avoids nonconvex, costly objectives. We propose an efficient search procedure as a solution, solving the local problems with SPECTRAL, our iterative method with closed-form updates and suitable for positive definite and semidefinite covariance matrices. Experiments on synthetic data show competitive performance in the CA learning task, and successful recovery of diverse CAN structures.', 'abstract_zh': '因果人工智能旨在通过利用结构因果模型（SCMs）来增强AI的解释性、可信度和鲁棒性。在此目标下，最近的进展形式化了因果知识的网络她fferve。沿着相同的方向，我们引入了因果抽象网络（CAN），这是一种此类她fferve的特定实例，其中(i) SCMs为高斯分布，(ii) 约束映射是构造线性因果抽象（CAs）的转置，(iii) 边 stalks 与更详细的SCMs的节点 stalks（最多旋转）相对应。我们研究了CAN的理论性质，包括代数不变量、上同调、一致性、通过拉普拉斯内核表征的全局截面以及光滑性。接着，我们解决了一致的CAN学习问题。我们的问题表述将问题分为特定边的本地黎曼问题，并避免了非凸、成本高昂的目标函数。我们提出了一种高效的搜索程序作为解决方案，使用我们的迭代方法SPECTRAL，该方法具有闭式更新形式，适用于正定和半正定协方差矩阵。在合成数据上的实验展示了CAN学习任务中的竞争性能，并成功恢复了多样化的CAN结构。', 'title_zh': '因果抽象网络：理论与学习'}
{'arxiv_id': 'arXiv:2509.25229', 'title': 'Blueprint-Bench: Comparing spatial intelligence of LLMs, agents and image models', 'authors': 'Lukas Petersson, Axel Backlund, Axel Wennstöm, Hanna Petersson, Callum Sharrock, Arash Dabiri', 'link': 'https://arxiv.org/abs/2509.25229', 'abstract': 'We introduce Blueprint-Bench, a benchmark designed to evaluate spatial reasoning capabilities in AI models through the task of converting apartment photographs into accurate 2D floor plans. While the input modality (photographs) is well within the training distribution of modern multimodal models, the task of spatial reconstruction requires genuine spatial intelligence: inferring room layouts, understanding connectivity, and maintaining consistent scale. We evaluate leading language models (GPT-5, Claude 4 Opus, Gemini 2.5 Pro, Grok-4), image generation models (GPT-Image, NanoBanana), and agent systems (Codex CLI, Claude Code) on a dataset of 50 apartments with approximately 20 interior images each. Our scoring algorithm measures similarity between generated and ground-truth floor plans based on room connectivity graphs and size rankings. Results reveal a significant blind spot in current AI capabilities: most models perform at or below a random baseline, while human performance remains substantially superior. Image generation models particularly struggle with instruction following, while agent-based approaches with iterative refinement capabilities show no meaningful improvement over single-pass generation. Blueprint-Bench provides the first numerical framework for comparing spatial intelligence across different model architectures. We will continue evaluating new models as they are released and welcome community submissions, monitoring for the emergence of spatial intelligence in generalist AI systems.', 'abstract_zh': 'Blueprint-Bench: 一种通过将公寓照片转换为准确的2D楼层平面图来评估AI模型空间推理能力的基准测试', 'title_zh': 'Blueprint-Bench: 比较LLMs、代理和图像模型的空间智能'}
{'arxiv_id': 'arXiv:2509.26644', 'title': 'Stitch: Training-Free Position Control in Multimodal Diffusion Transformers', 'authors': 'Jessica Bader, Mateusz Pach, Maria A. Bravo, Serge Belongie, Zeynep Akata', 'link': 'https://arxiv.org/abs/2509.26644', 'abstract': 'Text-to-Image (T2I) generation models have advanced rapidly in recent years, but accurately capturing spatial relationships like "above" or "to the right of" poses a persistent challenge. Earlier methods improved spatial relationship following with external position control. However, as architectures evolved to enhance image quality, these techniques became incompatible with modern models. We propose Stitch, a training-free method for incorporating external position control into Multi-Modal Diffusion Transformers (MMDiT) via automatically-generated bounding boxes. Stitch produces images that are both spatially accurate and visually appealing by generating individual objects within designated bounding boxes and seamlessly stitching them together. We find that targeted attention heads capture the information necessary to isolate and cut out individual objects mid-generation, without needing to fully complete the image. We evaluate Stitch on PosEval, our benchmark for position-based T2I generation. Featuring five new tasks that extend the concept of Position beyond the basic GenEval task, PosEval demonstrates that even top models still have significant room for improvement in position-based generation. Tested on Qwen-Image, FLUX, and SD3.5, Stitch consistently enhances base models, even improving FLUX by 218% on GenEval\'s Position task and by 206% on PosEval. Stitch achieves state-of-the-art results with Qwen-Image on PosEval, improving over previous models by 54%, all accomplished while integrating position control into leading models training-free. Code is available at this https URL.', 'abstract_zh': '基于文本到图像生成中外部位置控制的训练-free方法：Stitch', 'title_zh': 'Stitch: 无需训练的多模态扩散变换器位置控制'}
{'arxiv_id': 'arXiv:2509.26633', 'title': 'OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction', 'authors': 'Lujie Yang, Xiaoyu Huang, Zhen Wu, Angjoo Kanazawa, Pieter Abbeel, Carmelo Sferrazza, C. Karen Liu, Rocky Duan, Guanya Shi', 'link': 'https://arxiv.org/abs/2509.26633', 'abstract': 'A dominant paradigm for teaching humanoid robots complex skills is to retarget human motions as kinematic references to train reinforcement learning (RL) policies. However, existing retargeting pipelines often struggle with the significant embodiment gap between humans and robots, producing physically implausible artifacts like foot-skating and penetration. More importantly, common retargeting methods neglect the rich human-object and human-environment interactions essential for expressive locomotion and loco-manipulation. To address this, we introduce OmniRetarget, an interaction-preserving data generation engine based on an interaction mesh that explicitly models and preserves the crucial spatial and contact relationships between an agent, the terrain, and manipulated objects. By minimizing the Laplacian deformation between the human and robot meshes while enforcing kinematic constraints, OmniRetarget generates kinematically feasible trajectories. Moreover, preserving task-relevant interactions enables efficient data augmentation, from a single demonstration to different robot embodiments, terrains, and object configurations. We comprehensively evaluate OmniRetarget by retargeting motions from OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hour trajectories that achieve better kinematic constraint satisfaction and contact preservation than widely used baselines. Such high-quality data enables proprioceptive RL policies to successfully execute long-horizon (up to 30 seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trained with only 5 reward terms and simple domain randomization shared by all tasks, without any learning curriculum.', 'abstract_zh': '一种针对教学型人形机器人复杂技能训练的主导范式是将人类动作重新定位为运动参考，以训练强化学习策略。然而，现有的重新定位管道常常难以克服人类和机器人之间显著的实体差距，产生诸如脚位滑动和穿插等物理上不可能的_artifacts。更重要的是，常见的重新定位方法忽视了表达性运动和运动操作中至关重要的人体-物体和人体-环境交互。为了解决这一问题，我们引入了基于交互网格的OmniRetarget，这是一种交互保留的数据生成引擎，明确建模并保留了智能体、地形和操纵物体之间的重要空间和接触关系。通过最小化人类和机器人网格之间的Laplacian变形并施加运动约束，OmniRetarget生成了运动学可行的轨迹。此外，保留与任务相关的交互使得从单个演示到不同机器人实体、地形和物体配置的数据增强变得更加高效。我们通过将OmniRetarget应用于OMOMO、LAFAN1和我们内部的MoCap数据集中的动作，生成超过8小时的轨迹，这些轨迹在满足运动学约束和保持接触方面优于广泛使用的基线。高质量的数据使得本体感受性RL策略能够在仅使用5个奖励项和所有任务共享的简单环境随机化的情况下，成功执行长达30秒的公园our和运动操作技能，而无需任何学习课程。', 'title_zh': '泛在适配：保持交互的数据生成为人形全身动操作和场景交互'}
{'arxiv_id': 'arXiv:2509.26631', 'title': 'Learning Generalizable Shape Completion with SIM(3) Equivariance', 'authors': 'Yuqing Wang, Zhaiyu Chen, Xiao Xiang Zhu', 'link': 'https://arxiv.org/abs/2509.26631', 'abstract': '3D shape completion methods typically assume scans are pre-aligned to a canonical frame. This leaks pose and scale cues that networks may exploit to memorize absolute positions rather than inferring intrinsic geometry. When such alignment is absent in real data, performance collapses. We argue that robust generalization demands architectural equivariance to the similarity group, SIM(3), so the model remains agnostic to pose and scale. Following this principle, we introduce the first SIM(3)-equivariant shape completion network, whose modular layers successively canonicalize features, reason over similarity-invariant geometry, and restore the original frame. Under a de-biased evaluation protocol that removes the hidden cues, our model outperforms both equivariant and augmentation baselines on the PCN benchmark. It also sets new cross-domain records on real driving and indoor scans, lowering minimal matching distance on KITTI by 17% and Chamfer distance $\\ell1$ on OmniObject3D by 14%. Perhaps surprisingly, ours under the stricter protocol still outperforms competitors under their biased settings. These results establish full SIM(3) equivariance as an effective route to truly generalizable shape completion. Project page: this https URL.', 'abstract_zh': '3D形状完成方法通常假定扫描已对齐到一个基准框架。这泄露了姿态和尺度线索，网络可能会利用这些线索来记忆绝对位置而非推断固有几何。当实际数据中缺少这种对齐时，性能会崩溃。我们主张稳健的泛化需要架构对相似性群SIM(3)的不变性，从而使模型对姿态和尺度保持无偏见。遵循这一原则，我们介绍了首个SIM(3)不变的形状完成网络，其模块化层依次规范化特征、推断相似性不变的几何关系，并恢复原始框架。在移除了隐藏线索的去偏评价协议下，我们的模型在PCN基准上优于等变性和增强基线。它还在真实驾驶和室内扫描跨域任务上设立了新记录，分别将KITTI上的最小匹配距离降低了17%和OmniObject3D上的切比雪夫距离$\\ell_1$降低了14%。或许令人惊讶的是，在更严格的协议下，我们的方法即使在对手的带有偏见设置下也表现更优。这些结果确立了全SIM(3)不变性作为实现真正泛化形状完成的有效途径。', 'title_zh': '基于SIM(3)不变性的学习可泛化的形状补全'}
{'arxiv_id': 'arXiv:2509.26625', 'title': 'Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training', 'authors': 'Junlin Han, Shengbang Tong, David Fan, Yufan Ren, Koustuv Sinha, Philip Torr, Filippos Kokkinos', 'link': 'https://arxiv.org/abs/2509.26625', 'abstract': "Large Language Models (LLMs), despite being trained on text alone, surprisingly develop rich visual priors. These priors allow latent visual capabilities to be unlocked for vision tasks with a relatively small amount of multimodal data, and in some cases, to perform visual tasks without ever having seen an image. Through systematic analysis, we reveal that visual priors-the implicit, emergent knowledge about the visual world acquired during language pre-training-are composed of separable perception and reasoning priors with unique scaling trends and origins. We show that an LLM's latent visual reasoning ability is predominantly developed by pre-training on reasoning-centric data (e.g., code, math, academia) and scales progressively. This reasoning prior acquired from language pre-training is transferable and universally applicable to visual reasoning. In contrast, a perception prior emerges more diffusely from broad corpora, and perception ability is more sensitive to the vision encoder and visual instruction tuning data. In parallel, text describing the visual world proves crucial, though its performance impact saturates rapidly. Leveraging these insights, we propose a data-centric recipe for pre-training vision-aware LLMs and verify it in 1T token scale pre-training. Our findings are grounded in over 100 controlled experiments consuming 500,000 GPU-hours, spanning the full MLLM construction pipeline-from LLM pre-training to visual alignment and supervised multimodal fine-tuning-across five model scales, a wide range of data categories and mixtures, and multiple adaptation setups. Along with our main findings, we propose and investigate several hypotheses, and introduce the Multi-Level Existence Bench (MLE-Bench). Together, this work provides a new way of deliberately cultivating visual priors from language pre-training, paving the way for the next generation of multimodal LLMs.", 'abstract_zh': '大型语言模型（LLMs）虽然仅基于文本训练，但却意外地发展出了丰富的视觉先验。这些先验使得通过相对少量的多模态数据解锁视觉任务的潜在视觉能力成为可能，在某些情况下，甚至可以在从未见过图像的情况下完成视觉任务。通过系统的分析，我们揭示了视觉先验——即语言预训练期间获得的视觉世界的隐式、 emergent 知识——是由可分离的感知先验和推理先验组成，具有独特的缩放趋势和起源。我们表明，LLM 的潜在视觉推理能力主要通过以推理为中心的数据（例如，代码、数学、学术）进行预训练而发展，并且随着训练逐步增强。从语言预训练中获得的推理先验具有可转移性和普遍适用性，适用于视觉推理。相比之下，感知先验则从广泛的语料库中逐渐涌现，感知能力对视觉编码器和视觉指令调优数据更为敏感。同时，描述视觉世界的文本对于视觉推理至关重要，尽管其性能影响快速饱和。基于这些见解，我们提出了一种基于数据的预训练视觉感知 LLM 的方法，并在 1T 令牌规模的预训练中进行了验证。我们的发现基于超过 100 次受控实验，消耗了 500,000 GPU 小时，覆盖了从 LLM 预训练到视觉对齐和监督多模态微调的完整 MLLM 构建管道，跨越了五个模型规模、多种数据类别和混合以及多种适应设置。除了主要发现外，我们还提出了并研究了几种假设，并引入了多级存在基准（MLE-Bench）。总之，这项工作为有意图地从语言预训练中培养视觉先验提供了一种新方法，为下一代多模态 LLM 的发展铺平了道路。', 'title_zh': '在见其形之前学会预见：揭开语言预训练中视觉先验的神秘面纱'}
{'arxiv_id': 'arXiv:2509.26619', 'title': 'Searching for Difficult-to-Translate Test Examples at Scale', 'authors': 'Wenda Xu, Vilém Zouhar, Parker Riley, Mara Finkelstein, Markus Freitag, Daniel Deutsch', 'link': 'https://arxiv.org/abs/2509.26619', 'abstract': "NLP models require test data that are sufficiently challenging. The difficulty of an example is linked to the topic it originates from (''seed topic''). The relationship between the topic and the difficulty of its instances is stochastic in nature: an example about a difficult topic can happen to be easy, and vice versa. At the scale of the Internet, there are tens of thousands of potential topics, and finding the most difficult one by drawing and evaluating a large number of examples across all topics is computationally infeasible. We formalize this task and treat it as a multi-armed bandit problem. In this framework, each topic is an ''arm,'' and pulling an arm (at a cost) involves drawing a single example, evaluating it, and measuring its difficulty. The goal is to efficiently identify the most difficult topics within a fixed computational budget. We illustrate the bandit problem setup of finding difficult examples for the task of machine translation. We find that various bandit strategies vastly outperform baseline methods like brute-force searching the most challenging topics.", 'abstract_zh': 'NLP模型需要足够具有挑战性的测试数据。示例的难度与其来源的主题（“种子主题”）有关。主题与其实例的难度之间的关系具有随机性：一个来自难主题的示例可能非常简单，反之亦然。在互联网规模下，潜在主题数以万计，通过在所有主题中抽样并评估大量示例来找难度最大的主题在计算上是不切实际的。我们将此任务形式化，并将其视为多臂bandit问题。在这种框架中，每个主题是一个“臂”，拉起一个臂（付出成本）涉及抽取一个示例，评估其难度，并测量其难度。目标是在固定的计算预算内高效地识别最难的主题。我们展示了在机器翻译任务中寻找困难示例的bandit问题设置。我们发现各种bandit策略远远优于暴力搜索最难主题的基线方法。', 'title_zh': '大规模搜索难以翻译的测试示例'}
{'arxiv_id': 'arXiv:2509.26601', 'title': 'MENLO: From Preferences to Proficiency - Evaluating and Modeling Native-like Quality Across 47 Languages', 'authors': 'Chenxi Whitehouse, Sebastian Ruder, Tony Lin, Oksana Kurylo, Haruka Takagi, Janice Lam, Nicolò Busetto, Denise Diaz', 'link': 'https://arxiv.org/abs/2509.26601', 'abstract': "Ensuring native-like quality of large language model (LLM) responses across many languages is challenging. To address this, we introduce MENLO, a framework that operationalizes the evaluation of native-like response quality based on audience design-inspired mechanisms. Using MENLO, we create a dataset of 6,423 human-annotated prompt-response preference pairs covering four quality dimensions with high inter-annotator agreement in 47 language varieties. Our evaluation reveals that zero-shot LLM judges benefit significantly from pairwise evaluation and our structured annotation rubrics, yet they still underperform human annotators on our dataset. We demonstrate substantial improvements through fine-tuning with reinforcement learning, reward shaping, and multi-task learning approaches. Additionally, we show that RL-trained judges can serve as generative reward models to enhance LLMs' multilingual proficiency, though discrepancies with human judgment remain. Our findings suggest promising directions for scalable multilingual evaluation and preference alignment. We release our dataset and evaluation framework to support further research in multilingual LLM evaluation.", 'abstract_zh': '确保多语言大型语言模型（LLM）响应的土著级质量挑战重重。为此，我们提出MENLO框架，该框架基于观众设计启发机制操作化评判土著级响应质量。利用MENLO，我们构建了一个包含47种语言变体、6,423个人标注提示-响应偏好对的数据集，覆盖四个质量维度，并具有高注释者间一致性。我们的评估显示，零样本LLM评判者受益于成对评估和结构化注释量表，但仍低于我们在数据集上的人类评判者。通过强化学习、奖励塑造和多任务学习方法进行微调，我们展示了显著的改进。此外，我们证明了通过强化学习训练的评判者可以作为生成奖励模型，提高LLM的多语言能力，尽管与人类判断之间仍存在差异。我们的研究结果指出了可扩展的多语言评估和偏好对齐的前景方向。我们发布了数据集和评价框架，以支持多语言LLM评估的进一步研究。', 'title_zh': 'MENLO: 从偏好到 proficiency - 评估和建模47种语言的原生质量'}
{'arxiv_id': 'arXiv:2509.26600', 'title': 'Deconstructing Self-Bias in LLM-generated Translation Benchmarks', 'authors': 'Wenda Xu, Sweta Agrawal, Vilém Zouhar, Markus Freitag, Daniel Deutsch', 'link': 'https://arxiv.org/abs/2509.26600', 'abstract': "As large language models (LLMs) begin to saturate existing benchmarks, automated benchmark creation using LLMs (LLM as a benchmark) has emerged as a scalable alternative to slow and costly human curation. While these generated test sets have to potential to cheaply rank models, we demonstrate a critical flaw. LLM generated benchmarks systematically favor the model that created the benchmark, they exhibit self bias on low resource languages to English translation tasks. We show three key findings on automatic benchmarking of LLMs for translation: First, this bias originates from two sources: the generated test data (LLM as a testset) and the evaluation method (LLM as an evaluator), with their combination amplifying the effect. Second, self bias in LLM as a benchmark is heavily influenced by the model's generation capabilities in the source language. For instance, we observe more pronounced bias in into English translation, where the model's generation system is developed, than in out of English translation tasks. Third, we observe that low diversity in source text is one attribution to self bias. Our results suggest that improving the diversity of these generated source texts can mitigate some of the observed self bias.", 'abstract_zh': '大型语言模型（LLMs）生成的基准测试：来源语言生成能力与自我偏见的关系研究', 'title_zh': '拆解LLM生成的翻译基准中的自我偏差'}
{'arxiv_id': 'arXiv:2509.26598', 'title': 'Are Robust LLM Fingerprints Adversarially Robust?', 'authors': 'Anshul Nasery, Edoardo Contente, Alkin Kaz, Pramod Viswanath, Sewoong Oh', 'link': 'https://arxiv.org/abs/2509.26598', 'abstract': 'Model fingerprinting has emerged as a promising paradigm for claiming model ownership. However, robustness evaluations of these schemes have mostly focused on benign perturbations such as incremental fine-tuning, model merging, and prompting. Lack of systematic investigations into {\\em adversarial robustness} against a malicious model host leaves current systems vulnerable. To bridge this gap, we first define a concrete, practical threat model against model fingerprinting. We then take a critical look at existing model fingerprinting schemes to identify their fundamental vulnerabilities. Based on these, we develop adaptive adversarial attacks tailored for each vulnerability, and demonstrate that these can bypass model authentication completely for ten recently proposed fingerprinting schemes while maintaining high utility of the model for the end users. Our work encourages fingerprint designers to adopt adversarial robustness by design. We end with recommendations for future fingerprinting methods.', 'abstract_zh': '模型指纹识别已成为一种有前途的模型所有权声明 paradigma。然而，这些方案的鲁棒性评估主要集中在良性扰动上，如逐步微调、模型合并和提示。缺乏对抗恶意模型宿主的系统研究使当前系统面临风险。为进一步弥补这一差距，我们首先定义了一个具体的、可操作的对抗性威胁模型，针对模型指纹识别。然后，我们批判性地审视现有的模型指纹识别方案，以识别其根本性漏洞。基于此，我们开发了针对每种漏洞的适应性对抗性攻击，并证明这些攻击可以完全绕过十种最近提出的指纹识别方案的模型认证，同时确保模型对最终用户的高度实用性。我们的工作鼓励指纹设计者在设计时采用对抗性鲁棒性。最后，我们提出了未来指纹识别方法的建议。', 'title_zh': '稳健的大语言模型指纹是否具有对抗性稳健性？'}
{'arxiv_id': 'arXiv:2509.26567', 'title': 'AI-assisted Advanced Propellant Development for Electric Propulsion', 'authors': 'Angel Pan Du, Miguel Arana-Catania, Enric Grustan Gutiérrez', 'link': 'https://arxiv.org/abs/2509.26567', 'abstract': 'Artificial Intelligence algorithms are introduced in this work as a tool to predict the performance of new chemical compounds as alternative propellants for electric propulsion, focusing on predicting their ionisation characteristics and fragmentation patterns. The chemical properties and structure of the compounds are encoded using a chemical fingerprint, and the training datasets are extracted from the NIST WebBook. The AI-predicted ionisation energy and minimum appearance energy have a mean relative error of 6.87% and 7.99%, respectively, and a predicted ion mass with a 23.89% relative error. In the cases of full mass spectra due to electron ionisation, the predictions have a cosine similarity of 0.6395 and align with the top 10 most similar mass spectra in 78% of instances within a 30 Da range.', 'abstract_zh': '人工智能算法被引入本文，用作预测新型化学化合物作为电推进替代推进剂性能的工具，重点关注预测其电离特性及碎片模式。化合物的化学性质和结构通过化学指纹进行编码，训练数据集来自NIST WebBook。基于AI预测的电离能和最低出现能的相对误差分别为6.87%和7.99%，预测的离子质量的相对误差为23.89%。在完整质谱（由于电子电离）的情况下，预测的质谱与实验质谱的余弦相似度为0.6395，并且在30 Da范围内有78%的概率与前10个最相似的质谱之一匹配。', 'title_zh': 'AI辅助的先进推进剂开发技术'}
{'arxiv_id': 'arXiv:2509.26564', 'title': 'Parametric Neural Amp Modeling with Active Learning', 'authors': 'Florian Grötschla, Longxiang Jiao, Luca A. Lanzendörfer, Roger Wattenhofer', 'link': 'https://arxiv.org/abs/2509.26564', 'abstract': 'We introduce Panama, an active learning framework to train parametric guitar amp models end-to-end using a combination of an LSTM model and a WaveNet-like architecture. With \\model, one can create a virtual amp by recording samples that are determined through an ensemble-based active learning strategy to minimize the amount of datapoints needed (i.e., amp knob settings). Our strategy uses gradient-based optimization to maximize the disagreement among ensemble models, in order to identify the most informative datapoints. MUSHRA listening tests reveal that, with 75 datapoints, our models are able to match the perceptual quality of NAM, the leading open-source non-parametric amp modeler.', 'abstract_zh': '我们介绍了一个名为Panama的主动学习框架，该框架结合LSTM模型和WaveNet-like架构，用于端到端训练参数化吉他放大器模型。通过该框架，可以录制样本并通过基于ensemble的主动学习策略确定这些样本，从而最小化所需的数据点数量（即，放大器旋钮设置）。我们的策略使用基于梯度的优化方法来最大化ensemble模型之间的分歧，以识别最有信息量的数据点。MUSHRA听觉测试表明，使用75个数据点，我们的模型能够匹配NAM（领先的开源非参数化放大器建模器）的感知质量。', 'title_zh': '基于主动学习的参数神经放大器建模'}
{'arxiv_id': 'arXiv:2509.26543', 'title': 'The Unheard Alternative: Contrastive Explanations for Speech-to-Text Models', 'authors': 'Lina Conti, Dennis Fucci, Marco Gaido, Matteo Negri, Guillaume Wisniewski, Luisa Bentivogli', 'link': 'https://arxiv.org/abs/2509.26543', 'abstract': 'Contrastive explanations, which indicate why an AI system produced one output (the target) instead of another (the foil), are widely regarded in explainable AI as more informative and interpretable than standard explanations. However, obtaining such explanations for speech-to-text (S2T) generative models remains an open challenge. Drawing from feature attribution techniques, we propose the first method to obtain contrastive explanations in S2T by analyzing how parts of the input spectrogram influence the choice between alternative outputs. Through a case study on gender assignment in speech translation, we show that our method accurately identifies the audio features that drive the selection of one gender over another. By extending the scope of contrastive explanations to S2T, our work provides a foundation for better understanding S2T models.', 'abstract_zh': '对比解释在语音转文本生成模型中的应用：通过分析输入频谱图的部分如何影响输出选择，提出一种新方法，为更好地理解语音转文本模型奠定基础。', 'title_zh': '未被听见的选择：对比解释speech-to-text模型'}
{'arxiv_id': 'arXiv:2509.26536', 'title': 'OceanGym: A Benchmark Environment for Underwater Embodied Agents', 'authors': 'Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei Qiao, Mengru Wang, Shumin Deng, Xinyu An, Ningyu Zhang, Ying Chen, Huajun Chen', 'link': 'https://arxiv.org/abs/2509.26536', 'abstract': "We introduce OceanGym, the first comprehensive benchmark for ocean underwater embodied agents, designed to advance AI in one of the most demanding real-world environments. Unlike terrestrial or aerial domains, underwater settings present extreme perceptual and decision-making challenges, including low visibility, dynamic ocean currents, making effective agent deployment exceptionally difficult. OceanGym encompasses eight realistic task domains and a unified agent framework driven by Multi-modal Large Language Models (MLLMs), which integrates perception, memory, and sequential decision-making. Agents are required to comprehend optical and sonar data, autonomously explore complex environments, and accomplish long-horizon objectives under these harsh conditions. Extensive experiments reveal substantial gaps between state-of-the-art MLLM-driven agents and human experts, highlighting the persistent difficulty of perception, planning, and adaptability in ocean underwater environments. By providing a high-fidelity, rigorously designed platform, OceanGym establishes a testbed for developing robust embodied AI and transferring these capabilities to real-world autonomous ocean underwater vehicles, marking a decisive step toward intelligent agents capable of operating in one of Earth's last unexplored frontiers. The code and data are available at this https URL.", 'abstract_zh': '我们介绍OceanGym，这是首个全面的海洋水下具身智能体基准，旨在推动在最具挑战性的现实环境之一中的人工智能发展。不同于陆地或航空领域，水下环境提出了极端的感知和决策挑战，包括低能见度和动态洋流，使得有效智能体部署异常困难。OceanGym涵盖了八个现实的任务域，并由多模态大语言模型（MLLM）统一驱动的智能体框架，该框架整合了感知、记忆和序列决策。智能体需要在这些苛刻的条件下理解光学和声纳数据，自主探索复杂环境，并实现长期目标。广泛的实验揭示了基于最先进的MLLM驱动智能体与人类专家之间的巨大差距，强调了在海洋水下环境中感知、规划和适应性的持续困难。通过提供一个高度逼真、严格设计的平台，OceanGym为开发稳健的具身人工智能及其向实际自主水下海洋车辆的转移建立了测试床，标志着朝着能够操作地球最后一片未开发前沿之一的智能代理的重要一步。代码和数据可在以下网址获取。', 'title_zh': 'OceanGym: 一种水下实体代理基准环境'}
{'arxiv_id': 'arXiv:2509.26524', 'title': 'TAP: Two-Stage Adaptive Personalization of Multi-task and Multi-Modal Foundation Models in Federated Learning', 'authors': 'Seohyun Lee, Wenzhi Fang, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher G. Brinton', 'link': 'https://arxiv.org/abs/2509.26524', 'abstract': "Federated Learning (FL), despite demonstrating impressive capabilities in the training of multiple models in a decentralized manner, has been shown to produce a final model not necessarily well-suited to the needs of each client. While extensive work has been conducted on how to create tailored personalized models, called Personalized Federated Learning (PFL), less attention has been given to personalization via fine-tuning of foundation models with multi-task and multi-modal properties. Moreover, there exists a lack of understanding in the literature on how to fine-tune and personalize such models in a setting that is heterogeneous across clients not only in data, but also in tasks and modalities. To address this gap in the literature, we propose TAP (Two-Stage Adaptive Personalization), which (i) leverages mismatched model architectures between the clients and server to selectively conduct replacement operations when it benefits a client's local tasks and (ii) engages in post-FL knowledge distillation for capturing beneficial general knowledge without compromising personalization. We also introduce the first convergence analysis of the server model under its modality-task pair architecture, and demonstrate that as the number of modality-task pairs increases, its ability to cater to all tasks suffers. Through extensive experiments, we demonstrate the effectiveness of our proposed algorithm across a variety of datasets and tasks in comparison to a multitude of baselines. Implementation code is publicly available at this https URL.", 'abstract_zh': '联邦学习（FL）虽然在以去中心化方式训练多个模型方面展现了 impressive 的能力，但已被证明最终生成的模型未必很好地满足每个客户端的需求。尽管在如何创建定制化个性化模型，即个性化联邦学习（PFL），方面已开展了大量工作，但通过多任务和跨模态属性进行微调的个性化关注相对较少。此外，文献中还缺乏在客户端不仅在数据上而且在任务和模态上异构的情况下，如何微调和个性化此类模型的理解。为填补这一文献空白，我们提出了一种两阶段自适应个性化（TAP）方法，该方法（i）利用客户端与服务器之间的模型架构不匹配，在有利于客户端本地任务时选择性地执行替换操作，（ii）在联邦学习后进行知识蒸馏，以捕获有益的通用知识而不牺牲个性化能力。我们还引入了在模式-任务配对架构下服务器模型的第一种收敛性分析，并证明随着模式-任务配对数量的增加，其满足所有任务的能力会受到影响。通过广泛的实验，我们展示了在各种数据集和任务上与多种基线方法相比，我们提出算法的有效性。代码已公开，可在以下链接访问：this https URL。', 'title_zh': 'TAP：联邦学习中多任务和多模态基础模型的两阶段自适应个性化'}
{'arxiv_id': 'arXiv:2509.26521', 'title': 'MUSE-Explainer: Counterfactual Explanations for Symbolic Music Graph Classification Models', 'authors': 'Baptiste Hilaire, Emmanouil Karystinaios, Gerhard Widmer', 'link': 'https://arxiv.org/abs/2509.26521', 'abstract': "Interpretability is essential for deploying deep learning models in symbolic music analysis, yet most research emphasizes model performance over explanation. To address this, we introduce MUSE-Explainer, a new method that helps reveal how music Graph Neural Network models make decisions by providing clear, human-friendly explanations. Our approach generates counterfactual explanations by making small, meaningful changes to musical score graphs that alter a model's prediction while ensuring the results remain musically coherent. Unlike existing methods, MUSE-Explainer tailors its explanations to the structure of musical data and avoids unrealistic or confusing outputs. We evaluate our method on a music analysis task and show it offers intuitive insights that can be visualized with standard music tools such as Verovio.", 'abstract_zh': '深度学习模型在符号音乐分析中的可解释性是必要的，然而大多数研究侧重于模型性能而非解释。为解决这一问题，我们引入了MUSE-Explainer，一种新的方法，通过提供清晰的人类友好的解释来帮助揭示音乐图神经网络模型的决策过程。我们的方法通过在不破坏音乐连贯性的情况下对音乐谱图进行细微、有意义的修改，生成相关的反事实解释。与现有方法不同，MUSE-Explainer能够根据音乐数据的结构定制其解释，避免生成不现实或令人困惑的结果。我们在一个音乐分析任务上评估了该方法，并展示了其能够用标准音乐工具（如Verovio）进行可视化，并提供直观的见解。', 'title_zh': 'MUSE-Explainer: 符号音乐图分类模型的反事实解释'}
{'arxiv_id': 'arXiv:2509.26507', 'title': 'The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain', 'authors': 'Adrian Kosowski, Przemysław Uznański, Jan Chorowski, Zuzanna Stamirowska, Michał Bartoszkiewicz', 'link': 'https://arxiv.org/abs/2509.26507', 'abstract': "The relationship between computing systems and the brain has served as motivation for pioneering theoreticians since John von Neumann and Alan Turing. Uniform, scale-free biological networks, such as the brain, have powerful properties, including generalizing over time, which is the main barrier for Machine Learning on the path to Universal Reasoning Models.\nWe introduce `Dragon Hatchling' (BDH), a new Large Language Model architecture based on a scale-free biologically inspired network of \\$n\\$ locally-interacting neuron particles. BDH couples strong theoretical foundations and inherent interpretability without sacrificing Transformer-like performance.\nBDH is a practical, performant state-of-the-art attention-based state space sequence learning architecture. In addition to being a graph model, BDH admits a GPU-friendly formulation. It exhibits Transformer-like scaling laws: empirically BDH rivals GPT2 performance on language and translation tasks, at the same number of parameters (10M to 1B), for the same training data.\nBDH can be represented as a brain model. The working memory of BDH during inference entirely relies on synaptic plasticity with Hebbian learning using spiking neurons. We confirm empirically that specific, individual synapses strengthen connection whenever BDH hears or reasons about a specific concept while processing language inputs. The neuron interaction network of BDH is a graph of high modularity with heavy-tailed degree distribution. The BDH model is biologically plausible, explaining one possible mechanism which human neurons could use to achieve speech.\nBDH is designed for interpretability. Activation vectors of BDH are sparse and positive. We demonstrate monosemanticity in BDH on language tasks. Interpretability of state, which goes beyond interpretability of neurons and model parameters, is an inherent feature of the BDH architecture.", 'abstract_zh': '计算系统与大脑之间的关系自约翰·冯·诺伊曼和艾伦·图灵以来一直是开拓性理论家的研究动机。均匀的无标度生物网络，如大脑，具有强大的特性，包括时间泛化能力，这是机器学习通往通用推理模型道路上的主要障碍。\n\n Dragon Hatchling (BDH): 基于局部相互作用神经粒子无标度生物启发网络的新大规模语言模型架构，其兼具强大的理论基础和内在可解释性，而不牺牲类似于Transformer的性能。\n\nBDH是一种实际的、高性能的基于注意力的状态空间序列学习架构。除了是图模型外，BDH还具有GPU友好的表示形式。它表现出类似于Transformer的比例法则：实验表明，BDH在语言和翻译任务中，与GPT2的性能相当，在相同数量的参数（100万至1000万）和相同训练数据的情况下。\n\nBDH可以视为一种脑模型，在推断过程中，BDH的工作记忆完全依赖于使用尖峰神经元进行Hebbian学习的突触可塑性。我们实验证明，在处理语言输入时，特定的个别突触在BDH听到或推理特定概念时会加强其连接性。BDH的神经元交互网络具有高模块性和重尾度分布图。BDH模型具有生物可行性，解释了人类神经元可能用于实现语音的一种可能机制。\n\nBDH旨在增强可解释性。BDH的激活向量是稀疏且正的。我们在语言任务中展示了BDH的单义性。超越神经元和模型参数的可解释性状态的可解释性是BDH架构的一个固有特性。', 'title_zh': '幼龙：Transformer与脑模型之间的缺失环节'}
{'arxiv_id': 'arXiv:2509.26500', 'title': 'Indoor/Outdoor Spectrum Sharing Enabled by GNSS-based Classifiers', 'authors': 'Hossein Nasiri, Muhammad Iqbal Rochman, Monisha Ghosh', 'link': 'https://arxiv.org/abs/2509.26500', 'abstract': 'The desirability of the mid-band frequency range (1 - 10 GHz) for federal and commercial applications, combined with the growing applications for commercial indoor use-cases, such as factory automation, opens up a new approach to spectrum sharing: the same frequency bands used outdoors by federal incumbents can be reused by commercial indoor users. A recent example of such sharing, between commercial systems, is the 6 GHz band (5.925 - 7.125 GHz) where unlicensed, low-power-indoor (LPI) users share the band with outdoor incumbents, primarily fixed microwave links. However, to date, there exist no reliable, automatic means of determining whether a device is indoors or outdoors, necessitating the use of other mechanisms such as mandating indoor access points (APs) to have integrated antennas and not be battery powered, and reducing transmit power of client devices which may be outdoors. An accurate indoor/outdoor (I/O) classification addresses these challenges, enabling automatic transmit power adjustments without interfering with incumbents. To this end, we leverage the Global Navigation Satellite System (GNSS) signals for I/O classification. GNSS signals, designed inherently for outdoor reception and highly susceptible to indoor attenuation and blocking, provide a robust and distinguishing feature for environmental sensing. We develop various methodologies, including threshold-based techniques and machine learning approaches and evaluate them using an expanded dataset gathered from diverse geographical locations. Our results demonstrate that GNSS-based methods alone can achieve greater accuracy than approaches relying solely on wireless (Wi-Fi) data, particularly in unfamiliar locations. Furthermore, the integration of GNSS data with Wi-Fi information leads to improved classification accuracy, showcasing the significant benefits of multi-modal data fusion.', 'abstract_zh': '联邦和商用应用中频段频率范围（1-10 GHz）的优越性，结合商用室内应用场景的不断增长，如工厂自动化，为频谱共享开辟了新途径：联邦 incumbents 在室外使用的相同频率 band 可以被商用室内用户重新使用。最近，6 GHz 频段（5.925 - 7.125 GHz）的商用系统共享就是一个例子，其中无执照、低功耗室内（LPI）用户与室外 incumbents（主要为固定微波链路）共享频段。然而，目前还没有可靠且自动的方法来确定一个设备是在室内还是室外，因此需要采取其他手段，比如强制室内接入点（APs）配备集成天线且非电池供电，并降低可能在室外的客户端设备的发射功率。准确的室内/室外（I/O）分类解决了这些挑战，使自动调整发射功率成为可能，而不干扰 incumbents。为此，我们利用全球导航卫星系统（GNSS）信号进行 I/O 分类。GNSS 信号固有设计用于室外接收，对室内衰减和阻挡高度敏感，提供了环境感知的良好特征。我们开发了多种方法，包括阈值技术及机器学习方法，并使用来自不同地理区域的扩展数据集进行评估。我们的结果显示，基于 GNSS 的方法单独使用可以比仅依赖于无线（Wi-Fi）数据的方法实现更高的准确性，特别是在不熟悉的地方。此外，将 GNSS 数据与 Wi-Fi 信息集成可以提高分类准确性，展示了多模态数据融合的显著优势。', 'title_zh': '基于GNSS分类器的室内/室外频谱共享'}
{'arxiv_id': 'arXiv:2509.26490', 'title': 'VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications', 'authors': 'Wei He, Yueqing Sun, Hongyan Hao, Xueyuan Hao, Zhikang Xia, Qi Gu, Chengcheng Han, Dengchang Zhao, Hui Su, Kefeng Zhang, Man Gao, Xi Su, Xiaodong Cai, Xunliang Cai, Yu Yang, Yunke Zhao', 'link': 'https://arxiv.org/abs/2509.26490', 'abstract': 'As LLM-based agents are increasingly deployed in real-life scenarios, existing benchmarks fail to capture their inherent complexity of handling extensive information, leveraging diverse resources, and managing dynamic user interactions. To address this gap, we introduce VitaBench, a challenging benchmark that evaluates agents on versatile interactive tasks grounded in real-world settings. Drawing from daily applications in food delivery, in-store consumption, and online travel services, VitaBench presents agents with the most complex life-serving simulation environment to date, comprising 66 tools. Through a framework that eliminates domain-specific policies, we enable flexible composition of these scenarios and tools, yielding 100 cross-scenario tasks (main results) and 300 single-scenario tasks. Each task is derived from multiple real user requests and requires agents to reason across temporal and spatial dimensions, utilize complex tool sets, proactively clarify ambiguous instructions, and track shifting user intent throughout multi-turn conversations. Moreover, we propose a rubric-based sliding window evaluator, enabling robust assessment of diverse solution pathways in complex environments and stochastic interactions. Our comprehensive evaluation reveals that even the most advanced models achieve only 30% success rate on cross-scenario tasks, and less than 50% success rate on others. Overall, we believe VitaBench will serve as a valuable resource for advancing the development of AI agents in practical real-world applications. The code, dataset, and leaderboard are available at this https URL', 'abstract_zh': '基于LLM的代理在真实场景中广泛应用时，现有基准未能捕捉到其处理大量信息、利用多样资源及管理动态用户交互的内在复杂性。为填补这一空白，我们引入了VitaBench这一具有挑战性的基准，评估代理在真实世界环境中执行多样化交互任务的能力。VitaBench借鉴了餐饮配送、店内消费和在线旅行服务等日常生活应用，为代理提供了迄今为止最复杂的服务生活模拟环境，包含66种工具。通过消除领域特定策略的框架，我们使这些场景和工具的灵活组合成为可能，产生100个跨场景任务（主要结果）和300个单一场景任务。每个任务都源自多个真实用户的请求，要求代理在时间和空间维度上进行推理、使用复杂的工具集、主动澄清模糊指令，并在整个多轮对话中跟踪用户意图的变化。此外，我们提出了一种基于评分准则的滑动窗口评估器，能够在复杂环境和随机交互中对多种解决方案路径进行稳健评估。全面的评估结果显示，最先进的模型在跨场景任务上的成功率仅为30%，而在其他任务上的成功率也低于50%。总体而言，我们相信VitaBench将作为有价值的资源，推动实际应用场景中AI代理的发展。代码、数据集和排行榜可在以下链接获取。', 'title_zh': 'VitaBench：在实际应用中通过多样化的互动任务评估语言模型代理'}
{'arxiv_id': 'arXiv:2509.26476', 'title': 'Regression Language Models for Code', 'authors': 'Yash Akhauri, Xingyou Song, Arissa Wongpanich, Bryan Lewandowski, Mohamed S. Abdelfattah', 'link': 'https://arxiv.org/abs/2509.26476', 'abstract': 'We study code-to-metric regression: predicting numeric outcomes of code executions, a challenging task due to the open-ended nature of programming languages. While prior methods have resorted to heavy and domain-specific feature engineering, we show that a single unified Regression Language Model (RLM) can simultaneously predict directly from text, (i) the memory footprint of code across multiple high-level languages such as Python and C++, (ii) the latency of Triton GPU kernels, and (iii) the accuracy and speed of trained neural networks represented in ONNX. In particular, a relatively small 300M parameter RLM initialized from T5Gemma, obtains > 0.9 Spearman-rank on competitive programming submissions from APPS, and a single unified model achieves > 0.5 average Spearman-rank across 17 separate languages from CodeNet. Furthermore, the RLM can obtain the highest average Kendall-Tau of 0.46 on five classic NAS design spaces previously dominated by graph neural networks, and simultaneously predict architecture latencies on numerous hardware platforms.', 'abstract_zh': '代码到度量回归研究：一种具有挑战性的任务，由于编程语言的开放性。', 'title_zh': '代码的回归语言模型'}
{'arxiv_id': 'arXiv:2509.26471', 'title': "On Deepfake Voice Detection - It's All in the Presentation", 'authors': 'Héctor Delgado, Giorgio Ramondetti, Emanuele Dalmasso, Gennady Karvitsky, Daniele Colibro, Haydar Talib', 'link': 'https://arxiv.org/abs/2509.26471', 'abstract': 'While the technologies empowering malicious audio deepfakes have dramatically evolved in recent years due to generative AI advances, the same cannot be said of global research into spoofing (deepfake) countermeasures. This paper highlights how current deepfake datasets and research methodologies led to systems that failed to generalize to real world application. The main reason is due to the difference between raw deepfake audio, and deepfake audio that has been presented through a communication channel, e.g. by phone. We propose a new framework for data creation and research methodology, allowing for the development of spoofing countermeasures that would be more effective in real-world scenarios. By following the guidelines outlined here we improved deepfake detection accuracy by 39% in more robust and realistic lab setups, and by 57% on a real-world benchmark. We also demonstrate how improvement in datasets would have a bigger impact on deepfake detection accuracy than the choice of larger SOTA models would over smaller models; that is, it would be more important for the scientific community to make greater investment on comprehensive data collection programs than to simply train larger models with higher computational demands.', 'abstract_zh': '尽管近年来生成AI的发展使得赋能恶意音频换音的技术产生了巨大进步，但全球对于仿声（深度伪造）反制措施的研究进展却相对缓慢。本文强调了当前深度伪造数据集和研究方法的局限性，导致系统在实际应用中难以泛化。主要原因在于未经通信信道呈现的原始深度伪造音频和通过通信信道呈现的深度伪造音频之间的差异。我们提出了一种新的数据创建和研究方法框架，以促进在实际场景中更有效的仿声反制措施开发。通过遵循本文所列指南，我们在更稳健和现实的实验室设置中将深度伪造检测准确性提高了39%，在真实世界基准测试中提高了57%。我们还展示了数据集的改进对深度伪造检测准确性的影响比选用更大模型（尽管计算需求更高）的影响更大，科学界应该加大对全面数据采集计划的投资，而不仅仅是训练更大、计算需求更高的模型。', 'title_zh': '基于呈现方式的深伪语音检测'}
{'arxiv_id': 'arXiv:2509.26457', 'title': 'Attention over Scene Graphs: Indoor Scene Representations Toward CSAI Classification', 'authors': 'Artur Barros, Carlos Caetano, João Macedo, Jefersson A. dos Santos, Sandra Avila', 'link': 'https://arxiv.org/abs/2509.26457', 'abstract': "Indoor scene classification is a critical task in computer vision, with wide-ranging applications that go from robotics to sensitive content analysis, such as child sexual abuse imagery (CSAI) classification. The problem is particularly challenging due to the intricate relationships between objects and complex spatial layouts. In this work, we propose the Attention over Scene Graphs for Sensitive Content Analysis (ASGRA), a novel framework that operates on structured graph representations instead of raw pixels. By first converting images into Scene Graphs and then employing a Graph Attention Network for inference, ASGRA directly models the interactions between a scene's components. This approach offers two key benefits: (i) inherent explainability via object and relationship identification, and (ii) privacy preservation, enabling model training without direct access to sensitive images. On Places8, we achieve 81.27% balanced accuracy, surpassing image-based methods. Real-world CSAI evaluation with law enforcement yields 74.27% balanced accuracy. Our results establish structured scene representations as a robust paradigm for indoor scene classification and CSAI classification. Code is publicly available at this https URL.", 'abstract_zh': '室内场景分类是计算机视觉中的一个关键任务，广泛应用于从机器人技术到敏感内容分析（如儿童性虐待图像CSAI分类）等多个领域。由于场景中对象之间的复杂关系以及复杂的空间布局，该问题极具挑战性。本文提出了一种新型框架Attention over Scene Graphs for Sensitive Content Analysis (ASGRA)，该框架基于结构化的图表示而非原始像素。通过首先将图像转换为场景图，然后使用图注意网络进行推理，ASGRA可以直接建模场景组件之间的交互关系。该方法具有两大优势：(i) 通过对象和关系识别实现固有的可解释性，(ii) 保护隐私，允许在不直接访问敏感图像的情况下进行模型训练。在Places8数据集上，我们实现了81.27%的均衡准确性，超过基于图像的方法。在执法部门进行的现实世界CSAI评估中，我们实现了74.27%的均衡准确性。我们的结果证实了结构化场景表示在室内场景分类和CSAI分类中的稳健范式。代码已公开。', 'title_zh': '场景图上的注意力：面向CSAI分类的室内场景表示'}
{'arxiv_id': 'arXiv:2509.26435', 'title': 'Adaptive Planning for Multi-Attribute Controllable Summarization with Monte Carlo Tree Search', 'authors': 'Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok', 'link': 'https://arxiv.org/abs/2509.26435', 'abstract': 'Controllable summarization moves beyond generic outputs toward human-aligned summaries guided by specified attributes. In practice, the interdependence among attributes makes it challenging for language models to satisfy correlated constraints consistently. Moreover, previous approaches often require per-attribute fine-tuning, limiting flexibility across diverse summary attributes. In this paper, we propose adaptive planning for multi-attribute controllable summarization (PACO), a training-free framework that reframes the task as planning the order of sequential attribute control with a customized Monte Carlo Tree Search (MCTS). In PACO, nodes represent summaries, and actions correspond to single-attribute adjustments, enabling progressive refinement of only the attributes requiring further control. This strategy adaptively discovers optimal control orders, ultimately producing summaries that effectively meet all constraints. Extensive experiments across diverse domains and models demonstrate that PACO achieves robust multi-attribute controllability, surpassing both LLM-based self-planning models and fine-tuned baselines. Remarkably, PACO with Llama-3.2-1B rivals the controllability of the much larger Llama-3.3-70B baselines. With larger models, PACO achieves superior control performance, outperforming all competitors.', 'abstract_zh': '可控总结超越了通用输出，向着由指定属性引导的人类对齐摘要发展。在实践中，属性之间的相互依赖使语言模型难以一致地满足相关约束。此外，以往的方法往往需要针对每个属性进行微调，限制了在多种总结属性上的灵活性。在本文中，我们提出了一种适应性规划多属性可控总结（PACO）框架，该框架将任务重新定义为使用自定义蒙特卡洛树搜索（MCTS）规划序列属性控制顺序的任务。在PACO中，节点表示摘要，操作对应于单属性调整，使得只有需要进一步控制的属性可以渐进地细化。这种策略自适应地发现最优控制顺序，最终生成能够有效满足所有约束的摘要。广泛实验表明，PACO在多种领域和模型上实现了稳健的多属性可控性，超越了基于LLM的自我规划模型和微调基线。令人惊讶的是，使用Llama-3.2-1B的PACO与更大的Llama-3.3-70B基线具有相当的可控性。随着模型规模的增大，PACO在控制性能上表现出优越性，超越了所有竞争对手。', 'title_zh': '基于蒙特卡洛树搜索的多属性可控摘要自适应规划'}
{'arxiv_id': 'arXiv:2509.26433', 'title': 'ACT: Agentic Classification Tree', 'authors': 'Vincent Grari, Tim Arni, Thibault Laugel, Sylvain Lamprier, James Zou, Marcin Detyniecki', 'link': 'https://arxiv.org/abs/2509.26433', 'abstract': 'When used in high-stakes settings, AI systems are expected to produce decisions that are transparent, interpretable, and auditable, a requirement increasingly expected by regulations. Decision trees such as CART provide clear and verifiable rules, but they are restricted to structured tabular data and cannot operate directly on unstructured inputs such as text. In practice, large language models (LLMs) are widely used for such data, yet prompting strategies such as chain-of-thought or prompt optimization still rely on free-form reasoning, limiting their ability to ensure trustworthy behaviors. We present the Agentic Classification Tree (ACT), which extends decision-tree methodology to unstructured inputs by formulating each split as a natural-language question, refined through impurity-based evaluation and LLM feedback via TextGrad. Experiments on text benchmarks show that ACT matches or surpasses prompting-based baselines while producing transparent and interpretable decision paths.', 'abstract_zh': '当应用于高 stakes 环境时，AI系统被期望生成透明、可解释和可审计的决策，这一要求越来越受到法规的重视。决策树如CART提供了清晰和可验证的规则，但它们受限于结构化的表格数据，无法直接处理如文本等非结构化输入。实践中，大型语言模型（LLMs）广泛用于此类数据，然而诸如链式思考或提示优化等提示策略仍然依赖于自由形式的推理，限制了其确保可信赖行为的能力。我们提出了Agentic Classification Tree（ACT），通过将每个分裂表述为经过杂质评估和LLM反馈（通过TextGrad） refinement的自然语言问题，将决策树方法扩展到非结构化输入。在文本基准测试上的实验表明，ACT在生成透明和可解释决策路径的同时，能够匹配或超越基于提示的方法。', 'title_zh': 'AGentic 分类树'}
{'arxiv_id': 'arXiv:2509.26432', 'title': 'AdaBlock-dLLM: Semantic-Aware Diffusion LLM Inference via Adaptive Block Size', 'authors': 'Guanxi Lu, Chen, Yuto Karashima, Zhican Wang, Daichi Fujiki, Hongxiang Fan', 'link': 'https://arxiv.org/abs/2509.26432', 'abstract': 'Diffusion-based large language models (dLLMs) are gaining attention for their inherent capacity for parallel decoding, offering a compelling alternative to autoregressive LLMs. Among various decoding strategies, blockwise semi-autoregressive (semi-AR) approaches are widely adopted due to their natural support for KV caching and their favorable accuracy-speed trade-off. However, this paper identifies two fundamental limitations in the conventional semi-AR decoding approach that applies a fixed block size: i) late decoding overhead, where the unmasking of high-confidence tokens outside the current block is unnecessarily delayed, and ii) premature decoding error, where low-confidence tokens inside the current block are committed too early, leading to incorrect tokens. This paper presents the first systematic investigation challenging the fixed block size assumption in semi-AR decoding. Through a statistical analysis of confidence dynamics during the denoising process, we identify a volatility band (VB) region during dLLM decoding, which encodes local semantic structure and can be used to guide adaptive block sizing. Leveraging these insights, we introduce AdaBlock-dLLM, a training-free, plug-and-play scheduler that adaptively aligns block boundaries with semantic steps by adjusting block size during runtime. Extensive experiments across diverse benchmarks show that AdaBlock-dLLM achieves up to 5.3% accuracy improvement under the same throughput budget. Beyond inference-time optimization, we hope our semantics-aware adaptive scheduling approach and confidence-based analysis will inspire future training strategies for dLLMs.', 'abstract_zh': '基于扩散的大语言模型（dLLMs）因其固有的并行解码能力而受到关注，提供了与自回归大语言模型（LLMs）竞争的替代方案。在各种解码策略中，块式半自回归（semi-AR）方法因其自然支持KV缓存和有利的准确性和速度权衡而被广泛采用。然而，本文发现了半自回归解码方法中固定块大小的两种基本限制：一是延迟解码开销，其中未能及时解码当前块外高置信度标记；二是过早解码错误，其中内部低置信度标记被过早确认，导致错误标记。本文首次系统地挑战了半自回归解码中固定块大小的假设。通过退噪过程中置信动态的统计分析，我们识别出dLLM解码中的波动区段（VB），该区段编码了局部语义结构，并可用于指导自适应块大小调整。借助这些洞见，我们引入了AdaBlock-dLLM，这是一种无需训练、即插即用的调度器，能够在运行时通过调整块大小来适配语义步骤，从而自适应地对齐块边界。广泛实验证明，AdaBlock-dLLM在相同的吞吐量预算下可实现高达5.3%的准确率提升。此外，我们希望我们的基于语义的自适应调度方法和基于置信度的分析能启发dLLMs的未来训练策略。', 'title_zh': 'AdaBlock-dLLM：基于语义感知的自适应块大小扩散大语言模型推理'}
{'arxiv_id': 'arXiv:2509.26427', 'title': 'Ascent Fails to Forget', 'authors': 'Ioannis Mavrothalassitis, Pol Puigdemont, Noam Itzhak Levi, Volkan Cevher', 'link': 'https://arxiv.org/abs/2509.26427', 'abstract': 'Contrary to common belief, we show that gradient ascent-based unconstrained optimization methods frequently fail to perform machine unlearning, a phenomenon we attribute to the inherent statistical dependence between the forget and retain data sets. This dependence, which can manifest itself even as simple correlations, undermines the misconception that these sets can be independently manipulated during unlearning. We provide empirical and theoretical evidence showing these methods often fail precisely due to this overlooked relationship. For random forget sets, this dependence means that degrading forget set metrics (which, for a retrained model, should mirror test set metrics) inevitably harms overall test performance. Going beyond random sets, we consider logistic regression as an instructive example where a critical failure mode emerges: inter-set dependence causes gradient descent-ascent iterations to progressively diverge from the ideal retrained model. Strikingly, these methods can converge to solutions that are not only far from the retrained ideal but are potentially even further from it than the original model itself, rendering the unlearning process actively detrimental. A toy example further illustrates how this dependence can trap models in inferior local minima, inescapable via finetuning. Our findings highlight that the presence of such statistical dependencies, even when manifest only as correlations, can be sufficient for ascent-based unlearning to fail. Our theoretical insights are corroborated by experiments on complex neural networks, demonstrating that these methods do not perform as expected in practice due to this unaddressed statistical interplay.', 'abstract_zh': '与常识相反，我们证明了基于梯度上升的无约束优化方法在机器遗忘任务中经常失败，这一现象我们归因于忘记数据集和保留数据集之间固有的统计依赖性。这种依赖性即使表现为简单的相关性也会削弱这样一个认识，即在遗忘过程中这些数据集可以被独立操纵。我们提供了实证和理论证据，证明这些方法往往正是由于这种被忽视的关系而失败。对于随机的忘记数据集，这种依赖性意味着降低忘记数据集的度量（对于重新训练后的模型，这些度量应该反映测试集的度量）不可避免地会损害整体测试性能。超越随机集，我们考虑逻辑回归作为具有启发性的例子，其中一种关键的失败模式出现：数据集之间的依赖性导致梯度下降-上升迭代逐步偏离理想的重新训练后的模型。令人惊讶的是，这些方法可能收敛到与重新训练后的理想模型相距甚远甚至比原始模型更远的解，使遗忘过程变得有害。一个简单的示例进一步说明了这种依赖性如何将模型困在通过微调难以逃出的劣质局部最小值中。我们的研究结果强调了即使只有相关性的存在，此类统计依赖性也足以导致基于上升的遗忘失败。我们的理论见解得到了对复杂神经网络进行的实验的证实，表明由于这种未解决的统计交互作用，这种方法在实践中并未按预期起作用。', 'title_zh': 'ascent 难以忘却'}
{'arxiv_id': 'arXiv:2509.26404', 'title': 'SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From', 'authors': 'Yao Tong, Haonan Wang, Siquan Li, Kenji Kawaguchi, Tianyang Hu', 'link': 'https://arxiv.org/abs/2509.26404', 'abstract': "Fingerprinting Large Language Models (LLMs) is essential for provenance verification and model attribution. Existing methods typically extract post-hoc signatures based on training dynamics, data exposure, or hyperparameters -- properties that only emerge after training begins. In contrast, we propose a stronger and more intrinsic notion of LLM fingerprinting: SeedPrints, a method that leverages random initialization biases as persistent, seed-dependent identifiers present even before training. We show that untrained models exhibit reproducible token selection biases conditioned solely on their parameters at initialization. These biases are stable and measurable throughout training, enabling our statistical detection method to recover a model's lineage with high confidence. Unlike prior techniques, unreliable before convergence and vulnerable to distribution shifts, SeedPrints remains effective across all training stages and robust under domain shifts or parameter modifications. Experiments on LLaMA-style and Qwen-style models show that SeedPrints achieves seed-level distinguishability and can provide birth-to-lifecycle identity verification akin to a biometric fingerprint. Evaluations on large-scale pretrained models and fingerprinting benchmarks further confirm its effectiveness under practical deployment scenarios. These results suggest that initialization itself imprints a unique and persistent identity on neural language models, forming a true ''Galtonian'' fingerprint.", 'abstract_zh': '大型语言模型（LLMs）的指纹识别对于溯源验证和模型归因至关重要。现有的方法通常基于训练动力学、数据暴露或超参数提取后验签名——这些属性只有在训练开始后才会显现。相比之下，我们提出了一种更为强大和内在的LLM指纹识别方法：SeedPrints，该方法利用随机初始化偏差作为持久的、以种子依赖的身份标识，甚至在训练开始之前就存在。我们展示了未训练的模型在其初始化参数上表现出可重现的标记选择偏差。这些偏差在整个训练过程中稳定且可测量，从而使我们的统计检测方法能够以高置信度恢复模型的谱系。与先前的技术不同，后者在收敛前不可靠且易受分布变化的影响，SeedPrints 在所有训练阶段都有效且在领域变化或参数修改下具有鲁棒性。对LLaMA样式和Qwen样式的模型实验表明，SeedPrints 能够实现种子级区分性，并提供从出生到生命周期的身份验证，类似于生物指纹。对大规模预训练模型和指纹识别基准的评估进一步证实了其在实际部署场景下的有效性。这些结果表明，初始化本身会在神经语言模型上留下独特且持久的身份印记，形成一个真正的“高尔登氏指纹”。', 'title_zh': 'SeedPrints：指纹甚至能揭示大型语言模型训练时使用的种子类型'}
{'arxiv_id': 'arXiv:2509.26388', 'title': 'Game-Time: Evaluating Temporal Dynamics in Spoken Language Models', 'authors': 'Kai-Wei Chang, En-Pei Hu, Chun-Yi Kuan, Wenze Ren, Wei-Chih Chen, Guan-Ting Lin, Yu Tsao, Shao-Hua Sun, Hung-yi Lee, James Glass', 'link': 'https://arxiv.org/abs/2509.26388', 'abstract': 'Conversational Spoken Language Models (SLMs) are emerging as a promising paradigm for real-time speech interaction. However, their capacity of temporal dynamics, including the ability to manage timing, tempo and simultaneous speaking, remains a critical and unevaluated challenge for conversational fluency. To address this gap, we introduce the Game-Time Benchmark, a framework to systematically assess these temporal capabilities. Inspired by how humans learn a language through language activities, Game-Time consists of basic instruction-following tasks and advanced tasks with temporal constraints, such as tempo adherence and synchronized responses. Our evaluation of diverse SLM architectures reveals a clear performance disparity: while state-of-the-art models handle basic tasks well, many contemporary systems still struggle with fundamental instruction-following. More critically, nearly all models degrade substantially under temporal constraints, exposing persistent weaknesses in time awareness and full-duplex interaction. The Game-Time Benchmark provides a foundation for guiding future research toward more temporally-aware conversational AI. Demos and datasets are available on our project website this https URL.', 'abstract_zh': '对话式口语语言模型（SLMs）正在成为实时语音交互的有前景范式。然而，它们在时间动态方面的能力，包括管理节奏、速度和同时说话的能力，仍然是会话流畅性中的关键且未评估的挑战。为了填补这一空白，我们引入了Game-Time基准，这是一种系统评估这些时间能力的框架。受人类通过语言活动学习语言的启发，Game-Time包含基本的指令跟随任务和具有时间约束的高级任务，如节奏遵守和同步响应。我们对多种SLM架构的评估揭示了明显的性能差异：尽管最先进的模型能够很好地处理基本任务，但许多当代系统仍然难以应对基本指令跟随任务。更关键的是，几乎所有模型在时间约束条件下表现大幅下降，暴露出时间意识和全双工交互的持久弱点。Game-Time基准为未来研究朝着更加注重时间的对话式AI方向提供了指导基础。更多信息和数据集可在我们项目网站这个网址获取。', 'title_zh': 'Game-Time: 评估语音语言模型中的时间动态'}
{'arxiv_id': 'arXiv:2509.26383', 'title': 'Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement Learning', 'authors': 'Jinyeop Song, Song Wang, Julian Shun, Yada Zhu', 'link': 'https://arxiv.org/abs/2509.26383', 'abstract': 'Knowledge-graph retrieval-augmented generation (KG-RAG) couples large language models (LLMs) with structured, verifiable knowledge graphs (KGs) to reduce hallucinations and expose reasoning traces. However, many KG-RAG systems compose multiple LLM modules (e.g planning, reasoning, and responding), inflating inference cost and binding behavior to a specific target KG. To address this, we introduce KG-R1, an agentic KG retrieval-augmented generation (KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single agent that interacts with KGs as its environment, learning to retrieve at each step and incorporating the retrieved information into its reasoning and generation. The process is optimized through end-to-end RL. In controlled experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our method demonstrates both efficiency and transferability: Using Qwen-2.5-3B, KG-R1 improves answer accuracy with fewer generation tokens than prior multi-module workflow methods that use larger foundation or fine-tuned models. Furthermore, KG-R1 enables plug and play: after training, it maintains strong accuracy on new KGs without modification. These properties make KG-R1 a promising KG-RAG framework for real-world deployment. Our code is publicly available at this https URL.', 'abstract_zh': '基于强化学习的实体KG-R1：一种代理 KG检索增强生成框架', 'title_zh': '通过强化学习实现高效可迁移的代理知识图谱RAG'}
{'arxiv_id': 'arXiv:2509.26375', 'title': 'SDA-PLANNER: State-Dependency Aware Adaptive Planner for Embodied Task Planning', 'authors': 'Zichao Shen, Chen Gao, Jiaqi Yuan, Tianchen Zhu, Xingcheng Fu, Qingyun Sun', 'link': 'https://arxiv.org/abs/2509.26375', 'abstract': 'Embodied task planning requires agents to produce executable actions in a close-loop manner within the environment. With progressively improving capabilities of LLMs in task decomposition, planning, and generalization, current embodied task planning methods adopt LLM-based this http URL, existing LLM-based planners remain limited in three aspects, i.e., fixed planning paradigms, lack of action sequence constraints, and error-agnostic. In this work, we propose SDA-PLANNER, enabling an adaptive planning paradigm, state-dependency aware and error-aware mechanisms for comprehensive embodied task planning. Specifically, SDA-PLANNER introduces a State-Dependency Graph to explicitly model action preconditions and effects, guiding the dynamic revision. To handle execution error, it employs an error-adaptive replanning strategy consisting of Error Backtrack and Diagnosis and Adaptive Action SubTree Generation, which locally reconstructs the affected portion of the plan based on the current environment state. Experiments demonstrate that SDA-PLANNER consistently outperforms baselines in success rate and goal completion, particularly under diverse error conditions.', 'abstract_zh': '具身任务规划要求代理在环境中以闭环方式生成可执行动作。随着LLMs在任务分解、规划和泛化能力上的不断提高，当前的具身任务规划方法采用了基于LLMs的方法，但现有的基于LLMs的规划者在三个方面仍受到限制，即固定的规划范式、缺乏动作序列约束以及对错误无感知。在本文中，我们提出了SDA-PLANNER，使其能够实现自适应规划范式，并具备状态依赖性和错误感知机制，从而实现全面的具身任务规划。具体而言，SDA-PLANNER引入了状态依赖图来明确建模动作的前提条件和效果，指导动态修订。为了处理执行错误，它采用了一种基于当前环境状态局部重构受影响部分计划的错误自适应重规划策略，该策略由错误回退、诊断和自适应动作子树生成组成。实验表明，SDA-PLANNER在成功率和目标完成方面始终优于基准方法，特别是在多种错误条件下。', 'title_zh': 'SDA-规划器：感知状态依赖性的自适应体态任务规划器'}
{'arxiv_id': 'arXiv:2509.26371', 'title': 'Vector-Valued Reproducing Kernel Banach Spaces for Neural Networks and Operators', 'authors': 'Sven Dummer, Tjeerd Jan Heeringa, José A. Iglesias', 'link': 'https://arxiv.org/abs/2509.26371', 'abstract': 'Recently, there has been growing interest in characterizing the function spaces underlying neural networks. While shallow and deep scalar-valued neural networks have been linked to scalar-valued reproducing kernel Banach spaces (RKBS), $\\R^d$-valued neural networks and neural operator models remain less understood in the RKBS setting. To address this gap, we develop a general definition of vector-valued RKBS (vv-RKBS), which inherently includes the associated reproducing kernel. Our construction extends existing definitions by avoiding restrictive assumptions such as symmetric kernel domains, finite-dimensional output spaces, reflexivity, or separability, while still recovering familiar properties of vector-valued reproducing kernel Hilbert spaces (vv-RKHS). We then show that shallow $\\R^d$-valued neural networks are elements of a specific vv-RKBS, namely an instance of the integral and neural vv-RKBS. To also explore the functional structure of neural operators, we analyze the DeepONet and Hypernetwork architectures and demonstrate that they too belong to an integral and neural vv-RKBS. In all cases, we establish a Representer Theorem, showing that optimization over these function spaces recovers the corresponding neural architectures.', 'abstract_zh': '最近，人们对神经网络 underlying 的函数空间特征表现出 growing 的兴趣。虽然浅层和深层标量值神经网络与标量值再生核巴纳赫空间 (RKBS) 相关联，但 $\\R^d$ 值神经网络和神经算子模型在 RKBS 设置下尚未得到充分理解。为填补这一空白，我们提出了向量值再生核巴纳赫空间 (vv-RKBS) 的通用定义，其中包含关联的再生核。我们的构造扩展了现有定义，避免了对称核域、有限输出维数空间、反射性或可分性等 restrictive 假设，但仍保留了向量值再生核希尔伯特空间 (vv-RKHS) 的熟悉属性。然后我们证明浅层 $\\R^d$ 值神经网络是特定的 vv-RKBS 的元素，即积分和神经 vv-RKBS 的实例。为了探索神经算子的函数结构，我们分析了 DeepONet 和 Hypernetwork 架构，并证明它们也属于积分和神经 vv-RKBS。在所有情况下，我们建立了表示定理，证明了在这些函数空间上进行优化可以恢复相应的神经架构。', 'title_zh': '向量值核Banach空间及其在神经网络和算子中的应用'}
{'arxiv_id': 'arXiv:2509.26360', 'title': 'TimeScope: Towards Task-Oriented Temporal Grounding In Long Videos', 'authors': 'Xiangrui Liu, Minghao Qin, Yan Shu, Zhengyang Liang, Yang Tian, Chen Jason Zhang, Bo Zhao, Zheng Liu', 'link': 'https://arxiv.org/abs/2509.26360', 'abstract': "Identifying key moments in long videos is essential for downstream understanding and reasoning tasks. In this paper, we introduce a new problem, Taskoriented Temporal Grounding ToTG, which aims to localize time intervals containing the necessary information based on a task's natural description. Along with the definition, we also present ToTG Bench, a comprehensive benchmark for evaluating the performance on ToTG. ToTG is particularly challenging for traditional approaches due to their limited generalizability and difficulty in handling long videos. To address these challenges, we propose TimeScope, a novel framework built upon progressive reasoning. TimeScope first identifies a coarse-grained temporal scope in the long video that likely contains the key moments, and then refines this scope through finegrained moment partitioning. Additionally, we curate a highquality dataset, namely ToTG Pile, to enhance TimeScope's ability to perform progressive temporal grounding effectively. Extensive experiments demonstrate that TimeScope consistently outperforms both existing temporalgrounding methods and popular MLLMs across various settings, highlighting its effectiveness in addressing this new challenging problem.", 'abstract_zh': '识别长视频中的关键时刻对于下游理解和推理任务至关重要。在本文中，我们引入了一个新的问题，面向任务的时序定位（Task-oriented Temporal Grounding, ToTG），其目标是基于任务的自然描述，定位包含必要信息的时间区间。此外，我们还提出了ToTG Bench，一个全面的基准测试，用于评估ToTG的表现。由于传统方法的有限泛化能力和长视频处理难度，ToTG特别具有挑战性。为应对这些挑战，我们提出了一种名为TimeScope的新框架，该框架建立在逐步推理的基础上。TimeScope首先在长视频中识别出一个粗粒度的时序范围，很可能包含关键时刻，然后通过细粒度的时刻分割细化这一范围。此外，我们精心策划了一个高质量的数据集，即ToTG Pile，以增强TimeScope在有效地执行逐步时序定位方面的能力。广泛的实验表明，TimeScope在各种设置下一致地优于现有的时序定位方法和流行的MLLMs，突显了其解决这一全新挑战性问题的有效性。', 'title_zh': '时间范围：面向任务导向的长视频时间定位'}
{'arxiv_id': 'arXiv:2509.26350', 'title': 'SoK: Systematic analysis of adversarial threats against deep learning approaches for autonomous anomaly detection systems in SDN-IoT networks', 'authors': 'Tharindu Lakshan Yasarathna, Nhien-An Le-Khac', 'link': 'https://arxiv.org/abs/2509.26350', 'abstract': 'Integrating SDN and the IoT enhances network control and flexibility. DL-based AAD systems improve security by enabling real-time threat detection in SDN-IoT networks. However, these systems remain vulnerable to adversarial attacks that manipulate input data or exploit model weaknesses, significantly degrading detection accuracy. Existing research lacks a systematic analysis of adversarial vulnerabilities specific to DL-based AAD systems in SDN-IoT environments. This SoK study introduces a structured adversarial threat model and a comprehensive taxonomy of attacks, categorising them into data, model, and hybrid-level threats. Unlike previous studies, we systematically evaluate white, black, and grey-box attack strategies across popular benchmark datasets. Our findings reveal that adversarial attacks can reduce detection accuracy by up to 48.4%, with Membership Inference causing the most significant drop. C&W and DeepFool achieve high evasion success rates. However, adversarial training enhances robustness, and its high computational overhead limits the real-time deployment of SDN-IoT applications. We propose adaptive countermeasures, including real-time adversarial mitigation, enhanced retraining mechanisms, and explainable AI-driven security frameworks. By integrating structured threat models, this study offers a more comprehensive approach to attack categorisation, impact assessment, and defence evaluation than previous research. Our work highlights critical vulnerabilities in existing DL-based AAD models and provides practical recommendations for improving resilience, interpretability, and computational efficiency. This study serves as a foundational reference for researchers and practitioners seeking to enhance DL-based AAD security in SDN-IoT networks, offering a systematic adversarial threat model and conceptual defence evaluation based on prior empirical studies.', 'abstract_zh': '集成SDN和物联网增强网络控制和灵活性。基于DL的实时威胁检测系统改善了SDN-IoT网络的安全性。然而，这些系统仍易受到操控输入数据或利用模型弱点的 adversarial 攻击，显著降低了检测准确性。现有研究缺乏针对基于DL的AAD系统在SDN-IoT环境中的 adversarial 漏洞系统的分析。本综述研究引入了结构化的 adversarial 威胁模型和全面的攻击分类，将攻击分类为数据级、模型级和混合级威胁。与以往研究不同，我们系统地评估了流行的基准数据集上的白盒、黑盒和灰盒攻击策略。我们的发现显示，adversarial 攻击可以降低检测准确性高达48.4%，其中Membership Inference 造成最大的下降。C&W和DeepFool实现了高的逃逸成功率。然而，adversarial 训练增强了鲁棒性，其高昂的计算开销限制了SDN-IoT应用的实时部署。我们提出了适应性对策，包括实时adversarial 抵制、增强的重训练机制和基于解释性AI的安保框架。通过整合结构化的威胁模型，本研究提供了比以往研究更全面的攻击分类、影响评估和防御评估方法。我们的研究指出了现有基于DL的AAD模型中的关键漏洞，并提供了改进韧性、解释性和计算效率的实用建议。本研究为研究人员和实践者提供了一个基础参考，旨在增强SDN-IoT网络中基于DL的AAD安全性，基于前人实证研究提供了系统化的adversarial 威胁模型和概念化的防御评估。', 'title_zh': 'SoK：对SDN-IoT网络中自主异常检测系统基于深度学习的方法的 adversarial 威胁系统分析'}
{'arxiv_id': 'arXiv:2509.26346', 'title': 'EditReward: A Human-Aligned Reward Model for Instruction-Guided Image Editing', 'authors': 'Keming Wu, Sicong Jiang, Max Ku, Ping Nie, Minghao Liu, Wenhu Chen', 'link': 'https://arxiv.org/abs/2509.26346', 'abstract': "Recently, we have witnessed great progress in image editing with natural language instructions. Several closed-source models like GPT-Image-1, Seedream, and Google-Nano-Banana have shown highly promising progress. However, the open-source models are still lagging. The main bottleneck is the lack of a reliable reward model to scale up high-quality synthetic training data. To address this critical bottleneck, we built \\mname, trained with our new large-scale human preference dataset, meticulously annotated by trained experts following a rigorous protocol containing over 200K preference pairs. \\mname demonstrates superior alignment with human preferences in instruction-guided image editing tasks. Experiments show that \\mname achieves state-of-the-art human correlation on established benchmarks such as GenAI-Bench, AURORA-Bench, ImagenHub, and our new \\benchname, outperforming a wide range of VLM-as-judge models. Furthermore, we use \\mname to select a high-quality subset from the existing noisy ShareGPT-4o-Image dataset. We train Step1X-Edit on the selected subset, which shows significant improvement over training on the full set. This demonstrates \\mname's ability to serve as a reward model to scale up high-quality training data for image editing. Furthermore, its strong alignment suggests potential for advanced applications like reinforcement learning-based post-training and test-time scaling of image editing models. \\mname with its training dataset will be released to help the community build more high-quality image editing training datasets.", 'abstract_zh': '近期，我们见证了自然语言指令指导下图像编辑领域取得了显著进步。虽然一些闭源模型如GPT-Image-1、Seedream和Google-Nano-Banana展现了高度有前景的进展，但开源模型仍处于落后状态。主要瓶颈在于缺乏可靠的奖励模型来规模化高质量合成训练数据。为解决这一关键瓶颈，我们构建了\\mname，并使用我们新构建的大规模人类偏好数据集进行训练，该数据集由经过严格协议培训的专家精心标注，包含超过20万对偏好数据。\\mname在指令指导下的图像编辑任务中展示了优于人类偏好的对齐能力。实验表明，\\mname在GenAI-Bench、AURORA-Bench、ImagenHub和我们新的\\benchname等成熟基准测试上达到了最先进的性能，并超过了多种VLM作为评判模型。此外，我们利用\\mname从现有的噪声ShareGPT-4o-Image数据集中选择了高质量的子集。在该子集上训练Step1X-Edit显示出显著改进，证明了\\mname作为奖励模型的能力，可以规模化高质量训练数据以用于图像编辑。其高度对齐也表明了其在图像编辑模型后训练和测试时强化学习应用中的潜在可能性。\\mname及其训练数据集将被释放以帮助社区构建更多高质量的图像编辑训练数据集。', 'title_zh': 'EditReward：由指令引导的图像编辑的人类对齐奖励模型'}
{'arxiv_id': 'arXiv:2509.26324', 'title': 'LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search', 'authors': 'Ruiyang Wang, Haolun Tsu, David Hunt, Shaocheng Luo, Jiwoo Kim, Miroslav Pajic', 'link': 'https://arxiv.org/abs/2509.26324', 'abstract': 'Autonomous exploration and object search in unknown indoor environments remain challenging for multi-robot systems (MRS). Traditional approaches often rely on greedy frontier assignment strategies with limited inter-robot coordination. In this work, we introduce LLM-MCoX (LLM-based Multi-robot Coordinated Exploration and Search), a novel framework that leverages Large Language Models (LLMs) for intelligent coordination of both homogeneous and heterogeneous robot teams tasked with efficient exploration and target object search. Our approach combines real-time LiDAR scan processing for frontier cluster extraction and doorway detection with multimodal LLM reasoning (e.g., GPT-4o) to generate coordinated waypoint assignments based on shared environment maps and robot states. LLM-MCoX demonstrates superior performance compared to existing methods, including greedy and Voronoi-based planners, achieving 22.7% faster exploration times and 50% improved search efficiency in large environments with 6 robots. Notably, LLM-MCoX enables natural language-based object search capabilities, allowing human operators to provide high-level semantic guidance that traditional algorithms cannot interpret.', 'abstract_zh': '多机器人系统在未知室内环境中的自主探索与对象搜索仍具挑战性。传统方法往往依赖于贪婪的边界分配策略，协调能力有限。本文提出了基于大型语言模型的多机器人协同探索与搜索（LLM-MCoX）框架，利用大型语言模型智能协调同构和异构机器人团队，实现高效探索和目标对象搜索。该方法结合了实时激光雷达扫描处理以提取前沿簇并检测门道，并使用多模态大型语言模型推理（如GPT-4o）生成基于共享环境地图和机器人状态的协同航点分配。与现有的贪婪策略和基于Voronoi的方法相比，LLM-MCoX在多个机器人参与的大环境中展示了更快的探索时间和更高的搜索效率，探索时间快22.7%，搜索效率提升50%。此外，LLM-MCoX实现了基于自然语言的对象搜索能力，使人类操作者能够提供传统算法无法解释的高层次语义指导。', 'title_zh': '基于大型语言模型的多机器人协同探索与搜索（LLM-MCoX）'}
{'arxiv_id': 'arXiv:2509.26305', 'title': 'Feedback Forensics: A Toolkit to Measure AI Personality', 'authors': 'Arduin Findeis, Timo Kaufmann, Eyke Hüllermeier, Robert Mullins', 'link': 'https://arxiv.org/abs/2509.26305', 'abstract': 'Some traits making a "good" AI model are hard to describe upfront. For example, should responses be more polite or more casual? Such traits are sometimes summarized as model character or personality. Without a clear objective, conventional benchmarks based on automatic validation struggle to measure such traits. Evaluation methods using human feedback such as Chatbot Arena have emerged as a popular alternative. These methods infer "better" personality and other desirable traits implicitly by ranking multiple model responses relative to each other. Recent issues with model releases highlight limitations of these existing opaque evaluation approaches: a major model was rolled back over sycophantic personality issues, models were observed overfitting to such feedback-based leaderboards. Despite these known issues, limited public tooling exists to explicitly evaluate model personality. We introduce Feedback Forensics: an open-source toolkit to track AI personality changes, both those encouraged by human (or AI) feedback, and those exhibited across AI models trained and evaluated on such feedback. Leveraging AI annotators, our toolkit enables investigating personality via Python API and browser app. We demonstrate the toolkit\'s usefulness in two steps: (A) first we analyse the personality traits encouraged in popular human feedback datasets including Chatbot Arena, MultiPref and PRISM; and (B) then use our toolkit to analyse how much popular models exhibit such traits. We release (1) our Feedback Forensics toolkit alongside (2) a web app tracking AI personality in popular models and feedback datasets as well as (3) the underlying annotation data at this https URL.', 'abstract_zh': '一些构成“优秀”AI模型的特质难以提前描述。例如，回应应更加礼貌还是更加随性？这类特质有时被总结为模型性格或个性。缺乏明确目标的情况下，基于自动验证的传统基准指标难以衡量这类特质。使用人类反馈进行评估的方法，如聊天机器人竞技场（Chatbot Arena），作为一种替代方法逐渐流行起来。这些方法通过将多个模型回应相对排名，推测出“更好”的个性和其他 desirable 特质。近期关于模型发布的事件凸显了这些现有评估方法的局限性：一个主要模型因奉承的性格特征而被回滚，模型被观察到过度适应此类基于反馈的排行榜。尽管存在这些已知问题，但仍缺乏公开工具以明确评估模型个性。我们介绍了反馈取证：一个开源工具包，用于追踪AI个性的变化，无论是受到人类（或AI）反馈鼓励的变化，还是在利用此类反馈训练和评估的AI模型中表现出的变化。利用AI注释人员，我们的工具包通过Python API和浏览器应用，便于研究个性。我们通过两个步骤展示了工具包的价值：首先，我们分析了包括聊天机器人竞技场、MultiPref和PRISM在内的流行人类反馈数据集中鼓励的个性特质；然后，使用我们的工具包分析主流模型在多大程度上展现了这类特质。我们发布了（1）我们的反馈取证工具包以及（2）一个网页应用程序，跟踪流行模型和反馈数据集中AI个性的变化，同时提供（3）基础注释数据，可以在该链接查看：https://这个链接地址。', 'title_zh': 'AI人格分析工具箱：反馈法iska'}
{'arxiv_id': 'arXiv:2509.26302', 'title': 'QUARTZ : QA-based Unsupervised Abstractive Refinement for Task-oriented Dialogue Summarization', 'authors': 'Mohamed Imed Eddine Ghebriout, Gaël Guibon, Ivan Lerner, Emmanuel Vincent', 'link': 'https://arxiv.org/abs/2509.26302', 'abstract': 'Dialogue summarization aims to distill the core meaning of a conversation into a concise text. This is crucial for reducing the complexity and noise inherent in dialogue-heavy applications. While recent approaches typically train language models to mimic human-written summaries, such supervision is costly and often results in outputs that lack task-specific focus limiting their effectiveness in downstream applications, such as medical tasks. In this paper, we propose \\app, a framework for task-oriented utility-based dialogue summarization. \\app starts by generating multiple summaries and task-oriented question-answer pairs from a dialogue in a zero-shot manner using a pool of large language models (LLMs). The quality of the generated summaries is evaluated by having LLMs answer task-related questions before \\textit{(i)} selecting the best candidate answers and \\textit{(ii)} identifying the most informative summary based on these answers. Finally, we fine-tune the best LLM on the selected summaries. When validated on multiple datasets, \\app demonstrates its effectiveness by achieving competitive results in various zero-shot settings, rivaling fully-supervised State-of-the-Art (SotA) methods.', 'abstract_zh': '对话摘要旨在提炼对话的核心意义，以简洁的文字呈现。这对于减少对话密集型应用中的复杂性和噪音至关重要。虽然近期的方法通常通过模拟人类撰写的摘要来训练语言模型，但这种监督成本高昂，且常常导致输出缺乏任务特异性，限制了其在下游应用中的效果，例如医疗任务。在本文中，我们提出了一种基于任务的实用性对话摘要框架 \\app。\\app 通过使用一系列大型语言模型（LLMs）以零样本的方式从对话中生成多个摘要和任务相关的问答对来开始这一过程。生成的摘要质量通过让LLMs回答任务相关问题来评估，在此之后进行 \\textit{(i)} 选择最佳候选答案和 \\textit{(ii)} 识别基于这些答案的最相关信息性摘要的步骤。最后，我们对选中的摘要进行微调。当在多个数据集上验证时，\\app 在多种零样本设置中展示了其有效性，与完全监督的最先进（SotA）方法不相上下。', 'title_zh': 'QUARTZ : 基于QA的无监督抽象化 refinement 用于任务导向对话摘要'}
{'arxiv_id': 'arXiv:2509.26294', 'title': 'Noise-Guided Transport for Imitation Learning', 'authors': 'Lionel Blondé, Joao A. Candido Ramos, Alexandros Kalousis', 'link': 'https://arxiv.org/abs/2509.26294', 'abstract': 'We consider imitation learning in the low-data regime, where only a limited number of expert demonstrations are available. In this setting, methods that rely on large-scale pretraining or high-capacity architectures can be difficult to apply, and efficiency with respect to demonstration data becomes critical. We introduce Noise-Guided Transport (NGT), a lightweight off-policy method that casts imitation as an optimal transport problem solved via adversarial training. NGT requires no pretraining or specialized architectures, incorporates uncertainty estimation by design, and is easy to implement and tune. Despite its simplicity, NGT achieves strong performance on challenging continuous control tasks, including high-dimensional Humanoid tasks, under ultra-low data regimes with as few as 20 transitions. Code is publicly available at: this https URL.', 'abstract_zh': '我们在少量数据条件下考虑模仿学习，即仅可获得有限数量的专家演示。在这种情况下，依赖大规模预训练或高容量架构的方法可能难以应用，对演示数据的效率变得至关重要。我们 introduces Noise-Guided Transport (NGT)，一种轻量级的离策略方法，将模仿学习视为通过对抗训练求解的理想运输问题。NGT 不需要预训练或特殊架构，通过设计纳入不确定性估计，容易实现和调整。尽管结构简单，NGT 在超低数据条件下仍能实现强大的高性能连续控制任务，包括高维的人形机器人任务，只需20个过渡。代码已公开，可在以下链接访问：this https URL。', 'title_zh': '噪声引导传输的模仿学习'}
{'arxiv_id': 'arXiv:2509.26291', 'title': 'Representation-Based Data Quality Audits for Audio', 'authors': 'Alvaro Gonzalez-Jimenez, Fabian Gröger, Linda Wermelinger, Andrin Bürli, Iason Kastanis, Simone Lionetti, Marc Pouly', 'link': 'https://arxiv.org/abs/2509.26291', 'abstract': 'Data quality issues such as off-topic samples, near duplicates, and label errors often limit the performance of audio-based systems. This paper addresses these issues by adapting SelfClean, a representation-to-rank data auditing framework, from the image to the audio domain. This approach leverages self-supervised audio representations to identify common data quality issues, creating ranked review lists that surface distinct issues within a single, unified process. The method is benchmarked on the ESC-50, GTZAN, and a proprietary industrial dataset, using both synthetic and naturally occurring corruptions. The results demonstrate that this framework achieves state-of-the-art ranking performance, often outperforming issue-specific baselines and enabling significant annotation savings by efficiently guiding human review.', 'abstract_zh': '基于音频的数据质量问题如离题样本、近似重复和标签错误经常限制基于音频系统的性能。本文通过将SelfClean这一表示到排序的数据审核框架从图像领域应用到音频领域来解决这些问题。该方法利用自我监督的音频表示来识别常见的数据质量问题，生成排序审核列表，可以在单一统一的过程中突出显示不同的问题。该方法在ESC-50、GTZAN和一个专有工业数据集中进行了基准测试，使用合成和自然产生的损坏数据。结果表明，该框架实现了最先进的排序性能，通常优于特定问题的基线，并通过高效引导人工审核实现显著的注释节省。', 'title_zh': '基于表示的数据质量审计方法在音频领域的应用'}
{'arxiv_id': 'arXiv:2509.26281', 'title': 'Point2RBox-v3: Self-Bootstrapping from Point Annotations via Integrated Pseudo-Label Refinement and Utilization', 'authors': 'Teng Zhang, Ziqian Fan, Mingxin Liu, Xin Zhang, Xudong Lu, Wentong Li, Yue Zhou, Yi Yu, Xiang Li, Junchi Yan, Xue Yang', 'link': 'https://arxiv.org/abs/2509.26281', 'abstract': "Driven by the growing need for Oriented Object Detection (OOD), learning from point annotations under a weakly-supervised framework has emerged as a promising alternative to costly and laborious manual labeling. In this paper, we discuss two deficiencies in existing point-supervised methods: inefficient utilization and poor quality of pseudo labels. Therefore, we present Point2RBox-v3. At the core are two principles: 1) Progressive Label Assignment (PLA). It dynamically estimates instance sizes in a coarse yet intelligent manner at different stages of the training process, enabling the use of label assignment methods. 2) Prior-Guided Dynamic Mask Loss (PGDM-Loss). It is an enhancement of the Voronoi Watershed Loss from Point2RBox-v2, which overcomes the shortcomings of Watershed in its poor performance in sparse scenes and SAM's poor performance in dense scenes. To our knowledge, Point2RBox-v3 is the first model to employ dynamic pseudo labels for label assignment, and it creatively complements the advantages of SAM model with the watershed algorithm, which achieves excellent performance in both sparse and dense scenes. Our solution gives competitive performance, especially in scenarios with large variations in object size or sparse object occurrences: 66.09%/56.86%/41.28%/46.40%/19.60%/45.96% on DOTA-v1.0/DOTA-v1.5/DOTA-v2.0/DIOR/STAR/RSAR.", 'abstract_zh': '基于点注释的弱监督对象检测方法Point2RBox-v3：动态伪标签与先验引导动态掩码损失', 'title_zh': 'Point2RBox-v3：通过综合伪标签 refinement 和利用实现自 bootstrapping 从点注释'}
{'arxiv_id': 'arXiv:2509.26242', 'title': 'Finetune Once: Decoupling General & Domain Learning with Dynamic Boosted Annealing', 'authors': 'Yang Tang, Ruijie Liu, Yifan Wang, Shiyu Li, Xi Chen', 'link': 'https://arxiv.org/abs/2509.26242', 'abstract': 'Large language models (LLMs) fine-tuning shows excellent implications. However, vanilla fine-tuning methods often require intricate data mixture and repeated experiments for optimal generalization. To address these challenges and streamline the training process, we propose an efficient and universal solution, Dynamic Boosted Annealing (DBA). We obtain a global gradient through zero-learning-rate training on general data, which is subsequently employed for gradient boosting and dynamic training step correction during domain training. In conjunction with annealing learning, we end up establishing a fine-tuning pipeline that relies solely on domain data without collapse. By evaluating both general and domain-specific performance across multiple tasks on several popular base models, DBA achieves an average improvement of 5.8% in joint performance over vanilla fine-tuning. Furthermore, since general data is no longer involved in annealing, repeated experiments led by data mixture are also eliminated. According to our tests, the DBA method can reduce GPU hours by 91.0% compared to the vanilla method.', 'abstract_zh': '大型语言模型（LLMs）微调展示了卓越的潜力。然而，传统的微调方法通常需要复杂的数据混合和多次实验以达到最优泛化。为了解决这些挑战并简化训练过程，我们提出了一种高效和通用的解决方案，动态增强退火（DBA）。我们通过在通用数据上进行零学习率训练获取全局梯度，随后用于梯度增强和领域训练中的动态训练步长修正。结合退火学习，我们最终建立了一种仅依赖领域数据且不会崩溃的微调流水线。通过在多个流行的基础模型上对各种任务的一般性能和领域特定性能进行评估，DBA 在联合性能上相对于传统的微调方法平均提高了 5.8%。此外，由于通用数据不再参与退火过程，因此由数据混合引发的重复实验也得以消除。根据我们的测试，与传统的微调方法相比，DBA 方法可以将 GPU 小时降低 91.0%。', 'title_zh': '一次性微调：解耦通用学习与领域学习的动态增强退火'}
{'arxiv_id': 'arXiv:2509.26239', 'title': 'Sandbagging in a Simple Survival Bandit Problem', 'authors': 'Joel Dyer, Daniel Jarne Ornia, Nicholas Bishop, Anisoara Calinescu, Michael Wooldridge', 'link': 'https://arxiv.org/abs/2509.26239', 'abstract': 'Evaluating the safety of frontier AI systems is an increasingly important concern, helping to measure the capabilities of such models and identify risks before deployment. However, it has been recognised that if AI agents are aware that they are being evaluated, such agents may deliberately hide dangerous capabilities or intentionally demonstrate suboptimal performance in safety-related tasks in order to be released and to avoid being deactivated or retrained. Such strategic deception - often known as "sandbagging" - threatens to undermine the integrity of safety evaluations. For this reason, it is of value to identify methods that enable us to distinguish behavioural patterns that demonstrate a true lack of capability from behavioural patterns that are consistent with sandbagging. In this paper, we develop a simple model of strategic deception in sequential decision-making tasks, inspired by the recently developed survival bandit framework. We demonstrate theoretically that this problem induces sandbagging behaviour in optimal rational agents, and construct a statistical test to distinguish between sandbagging and incompetence from sequences of test scores. In simulation experiments, we investigate the reliability of this test in allowing us to distinguish between such behaviours in bandit models. This work aims to establish a potential avenue for developing robust statistical procedures for use in the science of frontier model evaluations.', 'abstract_zh': '评估前沿人工智能系统安全性的必要性日益凸显，有助于衡量此类模型的能力并识别部署前的风险。然而，已认识到如果人工智能代理意识到自己正在被评估，它们可能会故意隐藏危险的能力或在安全性相关任务中故意展示次优性能以被释放并避免被停用或重新训练。这种战略欺骗——通常称为“砂袋战术”——可能会削弱安全性评估的完整性。因此，识别能够区分真正缺乏能力的行为模式与砂袋战术一致的行为模式的方法是有价值的。在本文中，我们基于最近提出的生存多臂 bandit 框架，开发了一个战略欺骗的简单模型。我们理论证明了这个问题会导致最优理性代理进行砂袋战术行为，并构建了一个统计测试，可以从测试分数序列中区分砂袋战术与无能。在仿真实验中，我们研究了该测试在允许我们区分 bandit 模型中此类行为方面的可靠性。本文旨在为前沿模型评估科学中开发稳健的统计程序提供潜在途径。', 'title_zh': '简单生存多臂Bandit问题中的Sandbagging'}
{'arxiv_id': 'arXiv:2509.26233', 'title': '3DiFACE: Synthesizing and Editing Holistic 3D Facial Animation', 'authors': 'Balamurugan Thambiraja, Malte Prinzler, Sadegh Aliakbarian, Darren Cosker, Justus Thies', 'link': 'https://arxiv.org/abs/2509.26233', 'abstract': 'Creating personalized 3D animations with precise control and realistic head motions remains challenging for current speech-driven 3D facial animation methods. Editing these animations is especially complex and time consuming, requires precise control and typically handled by highly skilled animators. Most existing works focus on controlling style or emotion of the synthesized animation and cannot edit/regenerate parts of an input animation. They also overlook the fact that multiple plausible lip and head movements can match the same audio input. To address these challenges, we present 3DiFACE, a novel method for holistic speech-driven 3D facial animation. Our approach produces diverse plausible lip and head motions for a single audio input and allows for editing via keyframing and interpolation. Specifically, we propose a fully-convolutional diffusion model that can leverage the viseme-level diversity in our training corpus. Additionally, we employ a speaking-style personalization and a novel sparsely-guided motion diffusion to enable precise control and editing. Through quantitative and qualitative evaluations, we demonstrate that our method is capable of generating and editing diverse holistic 3D facial animations given a single audio input, with control between high fidelity and diversity. Code and models are available here: this https URL', 'abstract_zh': '基于精确控制和真实头动的个性化3D动画创建仍是对当前语音驱动3D面部动画方法的一大挑战。编辑这些动画特别复杂且耗时，需要精细控制，通常由技术高超的动画师处理。现有大多数工作集中在控制合成动画的风格或情感，而无法编辑或重新生成输入动画的特定部分。他们也忽略了这样一个事实：同一个音频输入可以匹配多种可行的唇部和头部运动。为应对这些挑战，我们提出了3DiFACE，一种面向整体的语音驱动3D面部动画的新方法。我们的方法能够为单一音频输入生成多样且合理的唇部和头部运动，并可通过关键帧编辑和插值进行编辑。具体而言，我们提出了一种全卷积扩散模型，可以利用我们在训练语料库中的唇形级别多样性。此外，我们采用了一种语音风格个性化和新颖的稀疏引导运动扩散技术，以实现精确控制和编辑。通过定量和定性评估，我们证明了我们的方法能够在单一音频输入下生成和编辑多样化的整体3D面部动画，并在保真度和多样性之间提供控制。代码和模型可在以下链接获取：this https URL。', 'title_zh': '3DiFACE：合成与编辑全方位三维面部动画'}
{'arxiv_id': 'arXiv:2509.26225', 'title': 'An Experimental Study on Generating Plausible Textual Explanations for Video Summarization', 'authors': 'Thomas Eleftheriadis, Evlampios Apostolidis, Vasileios Mezaris', 'link': 'https://arxiv.org/abs/2509.26225', 'abstract': "In this paper, we present our experimental study on generating plausible textual explanations for the outcomes of video summarization. For the needs of this study, we extend an existing framework for multigranular explanation of video summarization by integrating a SOTA Large Multimodal Model (LLaVA-OneVision) and prompting it to produce natural language descriptions of the obtained visual explanations. Following, we focus on one of the most desired characteristics for explainable AI, the plausibility of the obtained explanations that relates with their alignment with the humans' reasoning and expectations. Using the extended framework, we propose an approach for evaluating the plausibility of visual explanations by quantifying the semantic overlap between their textual descriptions and the textual descriptions of the corresponding video summaries, with the help of two methods for creating sentence embeddings (SBERT, SimCSE). Based on the extended framework and the proposed plausibility evaluation approach, we conduct an experimental study using a SOTA method (CA-SUM) and two datasets (SumMe, TVSum) for video summarization, to examine whether the more faithful explanations are also the more plausible ones, and identify the most appropriate approach for generating plausible textual explanations for video summarization.", 'abstract_zh': '本文呈现了我们对生成视频摘要结果的可信文本解释的实验研究。为了满足这一研究需求，我们通过集成当前最先进的大规模多模态模型（LLaVA-OneVision）并对其进行提示，扩展了一个现有的视频摘要多粒度解释框架，以生成所获得视觉解释的自然语言描述。随后，我们关注解释可解释人工智能中最受推崇的特性之一——获得解释的可信性，这与人类的推理和期望的契合程度相关。采用扩展的框架，我们提出了一种通过量化视觉解释的文本描述与其对应视频摘要文本描述的语义重叠来评估解释可信性的方法，借助两种句子嵌入方法（SBERT, SimCSE）。基于扩展的框架和提出的可信性评估方法，我们使用当前最先进的方法（CA-SUM）和两个数据集（SumMe, TVSum）进行实验研究，以检查更忠实的解释是否也是更可信的解释，并识别生成视频摘要可信文本解释的最佳方法。', 'title_zh': '视频摘要的可信文本解释生成实验研究'}
{'arxiv_id': 'arXiv:2509.26224', 'title': 'Type-Less yet Type-Aware Inductive Link Prediction with Pretrained Language Models', 'authors': 'Alessandro De Bellis, Salvatore Bufi, Giovanni Servedio, Vito Walter Anelli, Tommaso Di Noia, Eugenio Di Sciascio', 'link': 'https://arxiv.org/abs/2509.26224', 'abstract': 'Inductive link prediction is emerging as a key paradigm for real-world knowledge graphs (KGs), where new entities frequently appear and models must generalize to them without retraining. Predicting links in a KG faces the challenge of guessing previously unseen entities by leveraging generalizable node features such as subgraph structure, type annotations, and ontological constraints. However, explicit type information is often lacking or incomplete. Even when available, type information in most KGs is often coarse-grained, sparse, and prone to errors due to human annotation. In this work, we explore the potential of pre-trained language models (PLMs) to enrich node representations with implicit type signals. We introduce TyleR, a Type-less yet type-awaRe approach for subgraph-based inductive link prediction that leverages PLMs for semantic enrichment. Experiments on standard benchmarks demonstrate that TyleR outperforms state-of-the-art baselines in scenarios with scarce type annotations and sparse graph connectivity. To ensure reproducibility, we share our code at this https URL .', 'abstract_zh': '基于子图的无类型却敏感于类型的预训练语言模型增强的归纳链接预测', 'title_zh': '无类型 yet 具有类型意识的归纳链接预测预训练语言模型'}
{'arxiv_id': 'arXiv:2509.26219', 'title': 'Beyond Pixels: Efficient Dataset Distillation via Sparse Gaussian Representation', 'authors': 'Chenyang Jiang, Zhengcen Li, Hang Zhao, Qiben Shan, Shaocong Wu, Jingyong Su', 'link': 'https://arxiv.org/abs/2509.26219', 'abstract': 'Dataset distillation has emerged as a promising paradigm that synthesizes compact, informative datasets capable of retaining the knowledge of large-scale counterparts, thereby addressing the substantial computational and storage burdens of modern model training. Conventional approaches typically rely on dense pixel-level representations, which introduce redundancy and are difficult to scale up. In this work, we propose GSDD, a novel and efficient sparse representation for dataset distillation based on 2D Gaussians. Instead of representing all pixels equally, GSDD encodes critical discriminative information in a distilled image using only a small number of Gaussian primitives. This sparse representation could improve dataset diversity under the same storage budget, enhancing coverage of difficult samples and boosting distillation performance. To ensure both efficiency and scalability, we adapt CUDA-based splatting operators for parallel inference and training, enabling high-quality rendering with minimal computational and memory overhead. Our method is simple yet effective, broadly applicable to different distillation pipelines, and highly scalable. Experiments show that GSDD achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet subsets, while remaining highly efficient encoding and decoding cost. Our code is available at this https URL.', 'abstract_zh': '基于2D高斯的稀疏表示在数据集蒸馏中的应用', 'title_zh': '超越像素：通过稀疏高斯表示高效的 dataset 降解方法'}
{'arxiv_id': 'arXiv:2509.26216', 'title': 'Comparative Analysis of Ant Colony Optimization and Google OR-Tools for Solving the Open Capacitated Vehicle Routing Problem in Logistics', 'authors': 'Assem Omar, Youssef Omar, Marwa Solayman, Hesham Mansour', 'link': 'https://arxiv.org/abs/2509.26216', 'abstract': 'In modern logistics management systems, route planning requires high efficiency. The Open Capacitated Vehicle Routing Problem (OCVRP) deals with finding optimal delivery routes for a fleet of vehicles serving geographically distributed customers, without requiring the vehicles to return to the depot after deliveries. The present study is comparative in nature and speaks of two algorithms for OCVRP solution: Ant Colony Optimization (ACO), a nature-inspired metaheuristic; and Google OR-Tools, an industry-standard toolkit for optimization. Both implementations were developed in Python and using a custom dataset. Performance appraisal was based on routing efficiency, computation time, and scalability. The results show that ACO allows flexibility in routing parameters while OR-Tools runs much faster with more consistency and requires less input. This could help choose among routing strategies for scalable real-time logistics systems.', 'abstract_zh': '现代物流管理系统中，路径规划要求高效。开放车载车辆路径规划（OCVRP）旨在为分布地理上的客户提供最优配送路径，无需车辆在配送后返回仓库。本研究比较了两种OCVRP解决方案算法：蚂蚁 Colony 优化（ACO），一种受自然界启发的元启发式算法；以及谷歌OR-Tools，一种行业标准的优化工具包。两种实现均使用Python语言并基于自定义数据集开发。性能评估基于路径规划效率、计算时间和可扩展性。结果显示，ACO 在路由参数方面更为灵活，而OR-Tools 则运行更快、更一致，并且需要较少输入。这有助于在可扩展的实时物流系统中选择合适的路由策略。', 'title_zh': '开放容量车辆路线问题中蚁群优化与Google OR-Tools的比较分析'}
{'arxiv_id': 'arXiv:2509.26200', 'title': 'Toward an Unbiased Collective Memory for Efficient LLM-Based Agentic 6G Cross-Domain Management', 'authors': 'Hatim Chergui, Miguel Catalan Cid, Pouria Sayyad Khodashenas, Daniel Camps Mur, Christos Verikoukis', 'link': 'https://arxiv.org/abs/2509.26200', 'abstract': 'This paper introduces a novel framework for proactive cross-domain resource orchestration in 6G RAN-Edge networks, featuring large language model (LLM)-augmented agents. The system comprises specialized RAN (energy efficiency) and Edge (latency assurance) agents that engage in iterative negotiation, supported by advanced reasoning and planning capabilities. Agents dynamically interact with a digital twin (DT) to test their proposals and leverage a long-term collective memory where their joint successful and failed agreements along with the related network contexts are distilled into strategies to either follow or avoid and subsequently stored. Given that agents are subject to a plethora of cognitive distortions when retrieving those past experiences -- such as primacy, recency, confirmation and availability biases -- we propose in this work a novel unbiased memory design (A reusable mockup version of the unbiased memory source code is available for non-commercial use at this https URL). featuring (i) semantic retrieval of past strategies via Jaccard similarity; (ii) learning from failures through amplified weighting of SLA violations and mandatory inclusion of failed negotiation cases to mitigate confirmation bias; (iii) diversity enforcement to minimize availability bias and (iv) recency and primacy weighting with slow decay to counteract temporal biases. Evaluation results showcase the impact of existing biases and how the unbiased memory allows to tackle them by learning from both successful and failed strategies, either present or old, resulting in $\\times 4.5$ and $\\times 3.5$ reductions of unresolved negotiations compared to non-memory and vanilla memory baselines, respectively, while totally mitigating SLA violations as well as improving latency and energy saving distributions.', 'abstract_zh': '基于大型语言模型增强代理的 proactive 跨域资源orchestration框架：应用于6G RAN-Edge网络', 'title_zh': '朝着公正的集体记忆方向发展，以提高基于大语言模型的智能6G跨域管理效率'}
{'arxiv_id': 'arXiv:2509.26187', 'title': 'Optimizing Indoor Environmental Quality in Smart Buildings Using Deep Learning', 'authors': 'Youssef Sabiri, Walid Houmaidi, Aaya Bougrine, Salmane El Mansour Billah', 'link': 'https://arxiv.org/abs/2509.26187', 'abstract': 'Ensuring optimal Indoor Environmental Quality (IEQ) is vital for occupant health and productivity, yet it often comes at a high energy cost in conventional Heating, Ventilation, and Air Conditioning (HVAC) systems. This paper proposes a deep learning driven approach to proactively manage IEQ parameters specifically CO2 concentration, temperature, and humidity while balancing building energy efficiency. Leveraging the ROBOD dataset collected from a net-zero energy academic building, we benchmark three architectures--Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), and a hybrid Convolutional Neural Network LSTM (CNN-LSTM)--to forecast IEQ variables across various time horizons. Our results show that GRU achieves the best short-term prediction accuracy with lower computational overhead, whereas CNN-LSTM excels in extracting dominant features for extended forecasting windows. Meanwhile, LSTM offers robust long-range temporal modeling. The comparative analysis highlights that prediction reliability depends on data resolution, sensor placement, and fluctuating occupancy conditions. These findings provide actionable insights for intelligent Building Management Systems (BMS) to implement predictive HVAC control, thereby reducing energy consumption and enhancing occupant comfort in real-world building operations.', 'abstract_zh': '确保室内环境质量（IEQ）最优化对于提升 occupants 健康和 productivity 至关重要，但在传统 Heating, Ventilation, and Air Conditioning (HVAC) 系统中往往伴随着高昂的能耗。本文提出了一种基于深度学习的方法，旨在前瞻性地管理 IEQ 参数，如 CO2 浓度、温度和湿度，同时平衡建筑能效。利用从一座净零能耗学术建筑中收集的 ROBOD 数据集，我们对比了三种架构——Long Short-Term Memory (LSTM)、Gated Recurrent Units (GRU) 和 Convolutional Neural Network LSTM (CNN-LSTM)——在不同时间跨度下预测 IEQ 变量的表现。研究结果表明，GRU 在短期预测中表现出最高的精度且计算开销较低，而 CNN-LSTM 在长期预测中提取主导特征方面表现出色。同时，LSTM 提供了 robust 的长期时间序列建模能力。比较分析表明，预测可靠性取决于数据分辨率、传感器分布和不断变化的 occupancy 条件。这些发现为智能建筑管理系统（BMS）实施预测 HVAC 控制提供了实际指导，有助于在实际建筑运行中降低能耗并提升 occupant 舒适度。', 'title_zh': '利用深度学习优化智能建筑的室内环境质量'}
{'arxiv_id': 'arXiv:2509.26185', 'title': 'AttriGen: Automated Multi-Attribute Annotation for Blood Cell Datasets', 'authors': 'Walid Houmaidi, Youssef Sabiri, Fatima Zahra Iguenfer, Amine Abouaomar', 'link': 'https://arxiv.org/abs/2509.26185', 'abstract': 'We introduce AttriGen, a novel framework for automated, fine-grained multi-attribute annotation in computer vision, with a particular focus on cell microscopy where multi-attribute classification remains underrepresented compared to traditional cell type categorization. Using two complementary datasets: the Peripheral Blood Cell (PBC) dataset containing eight distinct cell types and the WBC Attribute Dataset (WBCAtt) that contains their corresponding 11 morphological attributes, we propose a dual-model architecture that combines a CNN for cell type classification, as well as a Vision Transformer (ViT) for multi-attribute classification achieving a new benchmark of 94.62\\% accuracy. Our experiments demonstrate that AttriGen significantly enhances model interpretability and offers substantial time and cost efficiency relative to conventional full-scale human annotation. Thus, our framework establishes a new paradigm that can be extended to other computer vision classification tasks by effectively automating the expansion of multi-attribute labels.', 'abstract_zh': '我们介绍了AttriGen，一种用于计算机视觉领域的新型自动精细化多属性标注框架，特别关注细胞显微镜领域，多属性分类相较于传统细胞类型分类仍相对不足。利用两个互补的数据集：包含八种不同细胞类型的外周血细胞(PBC)数据集和包含相应11个形态属性的WBC属性数据集(WBCAtt)，我们提出了一个双模型架构，结合了CNN用于细胞类型分类，以及Vision Transformer (ViT)用于多属性分类，实现了94.62%的新基准准确率。我们的实验表明，AttriGen显著提高了模型的可解释性，并在相对传统全面人工标注方面提供了显著的时间和成本效率。因此，我们的框架建立了可以有效自动化多属性标签扩展的新范式，适用于其他计算机视觉分类任务。', 'title_zh': 'AttriGen: 自动化多属性标注的血细胞数据集标注方法'}
{'arxiv_id': 'arXiv:2509.26184', 'title': 'Auto-ARGUE: LLM-Based Report Generation Evaluation', 'authors': 'William Walden, Marc Mason, Orion Weller, Laura Dietz, Hannah Recknor, Bryan Li, Gabrielle Kaili-May Liu, Yu Hou, James Mayfield, Eugene Yang', 'link': 'https://arxiv.org/abs/2509.26184', 'abstract': 'Generation of long-form, citation-backed reports is a primary use case for retrieval augmented generation (RAG) systems. While open-source evaluation tools exist for various RAG tasks, ones tailored to report generation are lacking. Accordingly, we introduce Auto-ARGUE, a robust LLM-based implementation of the recent ARGUE framework for report generation evaluation. We present analysis of Auto-ARGUE on the report generation pilot task from the TREC 2024 NeuCLIR track, showing good system-level correlations with human judgments. We further release a web app for visualization of Auto-ARGUE outputs.', 'abstract_zh': '生成长格式、引用支持的报告是检索增强生成（RAG）系统的主要应用场景。虽然存在多种开源的RAG任务评估工具，但针对报告生成的评估工具尚缺乏。因此，我们引入了Auto-ARGUE，这是一个基于大规模语言模型的ARGUE框架实现，用于报告生成评估。我们在TREC 2024 NeuCLIR赛道的报告生成试点任务上对Auto-ARGUE进行了分析，结果显示其在系统水平上与人类判断高度相关。我们进一步发布了用于自动展示Auto-ARGUE输出结果的网络应用。', 'title_zh': 'Auto-ARGUE：基于LLM的报告生成评估'}
{'arxiv_id': 'arXiv:2509.26158', 'title': 'Towards Continual Expansion of Data Coverage: Automatic Text-guided Edge-case Synthesis', 'authors': 'Kyeongryeol Go', 'link': 'https://arxiv.org/abs/2509.26158', 'abstract': 'The performance of deep neural networks is strongly influenced by the quality of their training data. However, mitigating dataset bias by manually curating challenging edge cases remains a major bottleneck. To address this, we propose an automated pipeline for text-guided edge-case synthesis. Our approach employs a Large Language Model, fine-tuned via preference learning, to rephrase image captions into diverse textual prompts that steer a Text-to-Image model toward generating difficult visual scenarios. Evaluated on the FishEye8K object detection benchmark, our method achieves superior robustness, surpassing both naive augmentation and manually engineered prompts. This work establishes a scalable framework that shifts data curation from manual effort to automated, targeted synthesis, offering a promising direction for developing more reliable and continuously improving AI systems. Code is available at this https URL.', 'abstract_zh': '深度神经网络的性能强烈依赖于其训练数据的质量。然而，通过手动筛选具有挑战性的边缘案例以减轻数据集偏差仍然是一个主要瓶颈。为解决这一问题，我们提出了一种文本导向边缘案例合成的自动化管道。我们的方法通过偏好学习 fine-tune 一个大语言模型，将其图像描述重述为多样化的文本提示，以引导文本到图像模型生成具有挑战性的视觉场景。在 FishEye8K 对象检测基准上，我们的方法表现出更优越的鲁棒性，超越了简单的数据增强和手动工程化的提示。这项工作建立了一个可扩展的框架，将数据标注从手动努力转移到自动化、目标化的合成，为开发更可靠且持续改进的AI系统提供了有 promise 的方向。代码可在以下网址获取。', 'title_zh': '面向数据覆盖持续扩展的自动文本引导边缘案例合成'}
{'arxiv_id': 'arXiv:2509.26157', 'title': 'EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting', 'authors': 'Sachith Abeywickrama, Emadeldeen Eldele, Min Wu, Xiaoli Li, Chau Yuen', 'link': 'https://arxiv.org/abs/2509.26157', 'abstract': 'Transformer-based models have significantly advanced time series forecasting, with patch-based input strategies offering efficiency and improved long-horizon modeling. Yet, existing approaches rely on temporally-agnostic patch construction, where arbitrary starting positions and fixed lengths fracture temporal coherence by splitting natural transitions across boundaries. This naive segmentation often disrupts short-term dependencies and weakens representation learning. In response, we propose EntroPE (Entropy-Guided Dynamic Patch Encoder), a novel, temporally informed framework that dynamically detects transition points via conditional entropy and dynamically places patch boundaries. This preserves temporal structure while retaining the computational benefits of patching. EntroPE consists of two key modules, namely an Entropy-based Dynamic Patcher (EDP) that applies information-theoretic criteria to locate natural temporal shifts and determine patch boundaries, and an Adaptive Patch Encoder (APE) that employs pooling and cross-attention to capture intra-patch dependencies and produce fixed-size latent representations. These embeddings are then processed by a global transformer to model inter-patch dynamics. Experiments across long-term forecasting benchmarks demonstrate that EntroPE improves both accuracy and efficiency, establishing entropy-guided dynamic patching as a promising new paradigm for time series modeling. Code is available at: this https URL.', 'abstract_zh': '基于Transformer的EntroPE模型：基于熵导向的动态片段编码在时间序列预测中的应用', 'title_zh': 'EntroPE：熵引导的动态PATCH编码器在时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2509.26150', 'title': "Bubble, Bubble, AI's Rumble: Why Global Financial Regulatory Incident Reporting is Our Shield Against Systemic Stumbles", 'authors': 'Anchal Gupta, Gleb Pappyshev, James T Kwok', 'link': 'https://arxiv.org/abs/2509.26150', 'abstract': '"Double, double toil and trouble; Fire burn and cauldron bubble." As Shakespeare\'s witches foretold chaos through cryptic prophecies, modern capital markets grapple with systemic risks concealed by opaque AI systems. According to IMF, the August 5, 2024, plunge in Japanese and U.S. equities can be linked to algorithmic trading yet ab-sent from existing AI incidents database exemplifies this transparency crisis. Current AI incident databases, reliant on crowdsourcing or news scraping, systematically over-look capital market anomalies, particularly in algorithmic and high-frequency trading. We address this critical gap by proposing a regulatory-grade global database that elegantly synthesises post-trade reporting frameworks with proven incident documentation models from healthcare and aviation. Our framework\'s temporal data omission technique masking timestamps while preserving percent-age-based metrics enables sophisticated cross-jurisdictional analysis of emerging risks while safeguarding confidential business information. Synthetic data validation (modelled after real life published incidents , sentiments, data) reveals compelling pat-terns: systemic risks transcending geographical boundaries, market manipulation clusters distinctly identifiable via K-means algorithms, and AI system typology exerting significantly greater influence on trading behaviour than geographical location, This tripartite solution empowers regulators with unprecedented cross-jurisdictional oversight, financial institutions with seamless compliance integration, and investors with critical visibility into previously obscured AI-driven vulnerabilities. We call for immediate action to strengthen risk management and foster resilience in AI-driven financial markets against the volatile "cauldron" of AI-driven systemic risks., promoting global financial stability through enhanced transparency and coordinated oversight.', 'abstract_zh': '双重麻烦；火燃烧，锅沸腾。正如莎士比亚的女巫通过隐晦的预言预示混乱，现代资本市场则在不透明的人工智能系统掩盖下应对系统性风险。国际货币基金组织指出，2024年8月5日日本和美国股市的暴跌可以追溯到算法交易，但这一事件未被现有的人工智能事件数据库收录，这体现了透明度危机。当前的人工智能事件数据库依赖于众包或新闻抓取，系统性地忽视了资本市场异常，尤其是在算法交易和高频交易领域。我们通过提出一个监管级别的全球数据库来填补这一关键缺口，该数据库巧妙地结合了交易后报告框架与医疗和航空领域的 proven 事件记录模型。该框架通过时间数据省略技术隐藏时间戳同时保留基于百分比的指标，从而实现跨司法管辖区复杂的风险分析，同时保护敏感的商业信息。合成数据验证（基于真实生活中公布的事件、情绪和数据建模）揭示了有力的模式：超越地理边界的系统性风险、通过K-means算法可明确识别的市场操纵集群，以及人工智能系统类型对交易行为的影响远大于地理位置。这一三重解决方案赋予监管机构前所未有的跨司法管辖区监督权，为金融机构提供了无缝合规整合，并为投资者提供了对以往隐藏的人工智能驱动漏洞的至关重要的洞察。我们呼吁立即采取行动，加强风险管理和提高对人工智能驱动金融市场的系统性风险的韧性，通过增强透明度和协调监督促进全球金融稳定。', 'title_zh': '泡沫，泡沫，AI的震动：全球金融市场监管事件报告为何成为我们抵御系统性失误的盾牌'}
{'arxiv_id': 'arXiv:2509.26140', 'title': 'OWL: Geometry-Aware Spatial Reasoning for Audio Large Language Models', 'authors': 'Subrata Biswas, Mohammad Nur Hossain Khan, Bashima Islam', 'link': 'https://arxiv.org/abs/2509.26140', 'abstract': "Spatial reasoning is fundamental to auditory perception, yet current audio large language models (ALLMs) largely rely on unstructured binaural cues and single step inference. This limits both perceptual accuracy in direction and distance estimation and the capacity for interpretable reasoning. Recent work such as BAT demonstrates spatial QA with binaural audio, but its reliance on coarse categorical labels (left, right, up, down) and the absence of explicit geometric supervision constrain resolution and robustness. We introduce the $\\textbf{Spatial-Acoustic Geometry Encoder (SAGE}$), a geometry-aware audio encoder that aligns binaural acoustic features with 3D spatial structure using panoramic depth images and room-impulse responses at training time, while requiring only audio at inference. Building on this representation, we present $\\textbf{OWL}$, an ALLM that integrates $\\textbf{SAGE}$ with a spatially grounded chain-of-thought to rationalize over direction-of-arrivals (DoA) and distance estimates. Through curriculum learning from perceptual QA to multi-step reasoning, $\\textbf{OWL}$ supports o'clock-level azimuth and DoA estimation. To enable large-scale training and evaluation, we construct and release $\\textbf{BiDepth}$, a dataset of over one million QA pairs combining binaural audio with panoramic depth images and room impulse responses across both in-room and out-of-room scenarios. Across two benchmark datasets, our new $\\textbf{BiDepth}$ and the public SpatialSoundQA, $\\textbf{OWL}$ reduces mean DoA error by $\\textbf{11$^{\\circ}$}$ through $\\textbf{SAGE}$ and improves spatial reasoning QA accuracy by up to $\\textbf{25}$\\% over BAT.", 'abstract_zh': '空间关系推理对于听觉感知至关重要，但当前的音频大规模语言模型（ALLMs）主要依赖于未结构化的双耳线索和单步推理。这限制了方向和距离估计的感知准确性以及可解释推理的能力。虽然像BAT这样的研究表明了使用双耳音频的空间问答，但其依赖于粗略的分类标签（左、右、上、下）并且缺乏显式的几何监督限制了其分辨率和稳健性。我们引入了**空间声学几何编码器（SAGE）**，这是一种几何感知的音频编码器，通过全景深度图像和房间冲激响应在训练时对齐双耳声学特征与三维空间结构，而在推理时仅需音频输入。在此表示基础上，我们提出**OWL**，一种将**SAGE**与空间地指导的推理链条结合的ALLM，用于解释到达方向（DoA）和距离估计。通过从感知问答到多步推理的渐进式学习，**OWL**支持分钟级的方位角和DoA估计。为实现大规模训练和评估，我们构建并发布了**BiDepth**数据集，包含超过一百万对双耳音频、全景深度图像和房间冲激响应，涵盖室内和室外场景。在两个基准数据集和公共的SpatialSoundQA数据集上，**OWL**通过**SAGE**将平均DoA误差减少了**11°**，并将空间推理问答准确性提高了最多**25%**，超过BAT。', 'title_zh': 'OWL：面向几何的空间推理在音频大规模语言模型中的应用'}
{'arxiv_id': 'arXiv:2509.26139', 'title': 'Leveraging AI modelling for FDS with Simvue: monitor and optimise for more sustainable simulations', 'authors': 'James Panayis, Matt Field, Vignesh Gopakumar, Andrew Lahiff, Kristian Zarebski, Aby Abraham, Jonathan L. Hodges', 'link': 'https://arxiv.org/abs/2509.26139', 'abstract': 'There is high demand on fire simulations, in both scale and quantity. We present a multi-pronged approach to improving the time and energy required to meet these demands. We show the ability of a custom machine learning surrogate model to predict the dynamics of heat propagation orders of magnitude faster than state-of-the-art CFD software for this application. We also demonstrate how a guided optimisation procedure can decrease the number of simulations required to meet an objective; using lightweight models to decide which simulations to run, we see a tenfold reduction when locating the most dangerous location for a fire to occur within a building based on the impact of smoke on visibility. Finally we present a framework and product, Simvue, through which we access these tools along with a host of automatic organisational and tracking features which enables future reuse of data and more savings through better management of simulations and combating redundancy.', 'abstract_zh': '对火灾模拟的需求在规模和数量上都非常高。我们提出了一种多管齐下的方法来提高满足这些需求所需的时间和能量。我们展示了自定义机器学习代理模型预测热量传播动力学的能力，比最先进的CFD软件快几个数量级。我们还展示了引导优化程序如何减少满足目标所需的模拟次数；使用轻量级模型来决定运行哪些模拟，在基于烟雾对能见度影响的基础上定位建筑中最危险的火灾位置时，我们看到了模拟次数十倍的减少。最后，我们介绍了Simvue这一框架和产品，通过它我们可以访问这些工具以及一系列自动组织和跟踪功能，从而实现数据的未来重用并更好地管理模拟以节省成本，同时减少冗余。', 'title_zh': '利用AI建模在Simvue中优化火灾动力学模拟：实现更加可持续的仿真监测与优化'}
{'arxiv_id': 'arXiv:2509.26120', 'title': 'AGOCS -- Accurate Google Cloud Simulator Framework', 'authors': 'Leszek Sliwko, Vladimir Getov', 'link': 'https://arxiv.org/abs/2509.26120', 'abstract': 'This paper presents the Accurate Google Cloud Simulator (AGOCS) - a novel high-fidelity Cloud workload simulator based on parsing real workload traces, which can be conveniently used on a desktop machine for day-to-day research. Our simulation is based on real-world workload traces from a Google Cluster with 12.5K nodes, over a period of a calendar month. The framework is able to reveal very precise and detailed parameters of the executed jobs, tasks and nodes as well as to provide actual resource usage statistics. The system has been implemented in Scala language with focus on parallel execution and an easy-to-extend design concept. The paper presents the detailed structural framework for AGOCS and discusses our main design decisions, whilst also suggesting alternative and possibly performance enhancing future approaches. The framework is available via the Open Source GitHub repository.', 'abstract_zh': '基于解析真实工作负载踪迹的Accurate Google Cloud Simulator (AGOCS)——一种新型高保真云工作负载仿真器', 'title_zh': 'AGOCS -- 准确的Google云模拟器框架'}
{'arxiv_id': 'arXiv:2509.26113', 'title': 'Enhancing PINN Performance Through Lie Symmetry Group', 'authors': 'Ali Haider Shah, Naveed R. Butt, Asif Ahmad, Muhammad Omer Bin Saeed', 'link': 'https://arxiv.org/abs/2509.26113', 'abstract': 'This paper presents intersection of Physics informed neural networks (PINNs) and Lie symmetry group to enhance the accuracy and efficiency of solving partial differential equation (PDEs). Various methods have been developed to solve these equations. A Lie group is an efficient method that can lead to exact solutions for the PDEs that possessing Lie Symmetry. Leveraging the concept of infinitesimal generators from Lie symmetry group in a novel manner within PINN leads to significant improvements in solution of PDEs. In this study three distinct cases are discussed, each showing progressive improvements achieved through Lie symmetry modifications and adaptive techniques. State-of-the-art numerical methods are adopted for comparing the progressive PINN models. Numerical experiments demonstrate the key role of Lie symmetry in enhancing PINNs performance, emphasizing the importance of integrating abstract mathematical concepts into deep learning for addressing complex scientific problems adequately.', 'abstract_zh': '物理 informant 神经网络 (PINNs) 与李群对称性的交集：提高偏微分方程 (PDEs) 求解的准确性和效率', 'title_zh': '通过李对称群提升PINN性能'}
{'arxiv_id': 'arXiv:2509.26103', 'title': 'End-to-End Aspect-Guided Review Summarization at Scale', 'authors': 'Ilya Boytsov, Vinny DeGenova, Mikhail Balyasin, Joseph Walt, Caitlin Eusden, Marie-Claire Rochat, Margaret Pierson', 'link': 'https://arxiv.org/abs/2509.26103', 'abstract': 'We present a scalable large language model (LLM)-based system that combines aspect-based sentiment analysis (ABSA) with guided summarization to generate concise and interpretable product review summaries for the Wayfair platform. Our approach first extracts and consolidates aspect-sentiment pairs from individual reviews, selects the most frequent aspects for each product, and samples representative reviews accordingly. These are used to construct structured prompts that guide the LLM to produce summaries grounded in actual customer feedback. We demonstrate the real-world effectiveness of our system through a large-scale online A/B test. Furthermore, we describe our real-time deployment strategy and release a dataset of 11.8 million anonymized customer reviews covering 92,000 products, including extracted aspects and generated summaries, to support future research in aspect-guided review summarization.', 'abstract_zh': '我们提出了一种可扩展的大规模语言模型（LLM）系统，该系统结合了方面基于的情感分析（ABSA）和引导式总结，以生成Wayfair平台上产品的简洁可解释的产品评论摘要。该方法首先从个别评论中提取和整合方面情感对，选择每个产品的最频繁方面，并相应地采样代表性评论。这些评论用于构建结构化的提示，以引导LLM生成基于实际客户反馈的摘要。我们通过大规模的在线A/B测试展示了该系统的实际有效性。此外，我们描述了实时部署策略，并发布了包含1180万条匿名客户评论（覆盖92000个产品，包括提取的方面和生成的摘要）的数据集，以支持未来方面导向的评论总结研究。', 'title_zh': '端到端面向方面引导的评论摘要生成'}
{'arxiv_id': 'arXiv:2509.26094', 'title': 'On Computing Top-$k$ Simple Shortest Paths from a Single Source', 'authors': "Mattia D'Emidio, Gabriele Di Stefano", 'link': 'https://arxiv.org/abs/2509.26094', 'abstract': "We investigate the problem of computing the top-$k$ simple shortest paths in weighted digraphs. While the single-pair variant -- finding the top-$k$ simple shortest paths between two specified vertices -- has been extensively studied over the past decades, with Yen's algorithm and its heuristic improvements emerging as the most effective solving strategies, relatively little attention has been devoted to the more general single-source version, where the goal is determining top-$k$ simple shortest paths from a source vertex to all other vertices. Motivated by the numerous practical applications of ranked shortest paths, in this paper we provide new insights and algorithmic contributions to this problem. In particular, we first present a theoretical characterization of the structural properties of its solutions. Then, we introduce the first polynomial-time algorithm specifically designed to handle it. On the one hand, we prove our new algorithm is on par, in terms of time complexity, with the best (and only) polynomial-time approach known in the literature to solve the problem, that is applying the fastest single-pair algorithm independently to each vertex pair formed by the source and the remaining vertices. On the other hand, through an extensive experimental evaluation on both real-world and synthetic graphs, we demonstrate that our algorithm consistently and significantly outperforms the latter baseline in terms of running time, achieving speed-ups of up to several orders of magnitude. These results establish our new algorithm as the solution to be preferred for computing $k$ simple shortest paths from a single source in practical settings.", 'abstract_zh': '我们研究加权有向图中计算简单最短路径前k条的问题。虽然两个指定顶点之间的简单最短路径前k条这一单对变体在过去几十年里得到了广泛研究，Yen算法及其启发式改进成为最有效的求解策略，但针对更具一般性的单源版本——从一个源顶点到所有其他顶点的简单最短路径前k条的确定——的研究相对较少。受排名最短路径众多实际应用的启发，本文提供了对该问题的新见解和算法贡献。特别是，我们首先提供了解决方案的结构性质的理论刻画，然后介绍了首个专门为此设计的多项式时间算法。一方面，我们证明了我们的新算法在时间复杂度上与文献中已知的唯一一个多项式时间解决方法（对源顶点与剩余顶点形成的所有顶点对独立应用最快的单对算法）相当。另一方面，通过对实际网络和合成图进行广泛的实验评估，我们展示了我们的算法在运行时间上始终显著优于后者，并实现了几个数量级的速度提升。这些结果确立了我们的新算法为实际场景中从单个源计算k条简单最短路径的首选解决方案。', 'title_zh': '从单源计算Top-$k$最简短路径'}
{'arxiv_id': 'arXiv:2509.26058', 'title': 'Real-time Noise Detection and Classification in Single-Channel EEG: A Lightweight Machine Learning Approach for EMG, White Noise, and EOG Artifacts', 'authors': 'Hossein Enshaei, Pariya Jebreili, Sayed Mahmoud Sakahei', 'link': 'https://arxiv.org/abs/2509.26058', 'abstract': 'Electroencephalogram (EEG) artifact detection in real-world settings faces significant challenges such as computational inefficiency in multi-channel methods, poor robustness to simultaneous noise, and trade-offs between accuracy and complexity in deep learning models. We propose a hybrid spectral-temporal framework for real-time detection and classification of ocular (EOG), muscular (EMG), and white noise artifacts in single-channel EEG. This method, in contrast to other approaches, combines time-domain low-pass filtering (targeting low-frequency EOG) and frequency-domain power spectral density (PSD) analysis (capturing broad-spectrum EMG), followed by PCA-optimized feature fusion to minimize redundancy while preserving discriminative information. This feature engineering strategy allows a lightweight multi-layer perceptron (MLP) architecture to outperform advanced CNNs and RNNs by achieving 99% accuracy at low SNRs (SNR -7) dB and >90% accuracy in moderate noise (SNR 4 dB). Additionally, this framework addresses the unexplored problem of simultaneous multi-source contamination(EMG+EOG+white noise), where it maintains 96% classification accuracy despite overlapping artifacts. With 30-second training times (97% faster than CNNs) and robust performance across SNR levels, this framework bridges the gap between clinical applicability and computational efficiency, which enables real-time use in wearable brain-computer interfaces. This work also challenges the ubiquitous dependence on model depth for EEG artifact detection by demonstrating that domain-informed feature fusion surpasses complex architecture in noisy scenarios.', 'abstract_zh': '实时单通道EEG眼动（EOG）、肌电（EMG）和白噪声 artifact 检测与分类的混合时频框架', 'title_zh': '单通道EEG中实时噪声检测与分类：一种针对EMG、白噪声和EOG伪迹的轻量级机器学习方法'}
{'arxiv_id': 'arXiv:2509.26051', 'title': 'CEAID: Benchmark of Multilingual Machine-Generated Text Detection Methods for Central European Languages', 'authors': 'Dominik Macko, Jakub Kopal', 'link': 'https://arxiv.org/abs/2509.26051', 'abstract': 'Machine-generated text detection, as an important task, is predominantly focused on English in research. This makes the existing detectors almost unusable for non-English languages, relying purely on cross-lingual transferability. There exist only a few works focused on any of Central European languages, leaving the transferability towards these languages rather unexplored. We fill this gap by providing the first benchmark of detection methods focused on this region, while also providing comparison of train-languages combinations to identify the best performing ones. We focus on multi-domain, multi-generator, and multilingual evaluation, pinpointing the differences of individual aspects, as well as adversarial robustness of detection methods. Supervised finetuned detectors in the Central European languages are found the most performant in these languages as well as the most resistant against obfuscation.', 'abstract_zh': '机器生成文本检测是重要的研究任务，现有研究主要集中在英文上。这使得现有的检测器几乎无法用于非英文语言，主要依赖于跨语言的可迁移性。对于任何中欧语言的相关工作甚少，使得这些语言上的迁移性尚未得到充分探索。我们通过提供第一个专注于这一地区的检测方法基准，同时对比不同训练语言组合以确定表现最佳的组合，来填补这一空白。我们关注多领域、多生成器和多语言的评估，揭示各个方面的差异，以及检测方法的对抗鲁棒性。在中欧语言中，有监督微调的检测器表现出最佳性能，并且对混淆最具抵抗力。', 'title_zh': 'CEAID：中央欧洲语言机器生成文本检测方法基准'}
{'arxiv_id': 'arXiv:2509.26036', 'title': 'SeMoBridge: Semantic Modality Bridge for Efficient Few-Shot Adaptation of CLIP', 'authors': 'Christoph Timmermann, Hyunse Lee, Woojin Lee', 'link': 'https://arxiv.org/abs/2509.26036', 'abstract': "While Contrastive Language-Image Pretraining (CLIP) excels at zero-shot tasks by aligning image and text embeddings, its performance in few-shot classification is hindered by a critical limitation: intra-modal misalignment. This issue, caused by a persistent modality gap and CLIP's exclusively inter-modal training objective, leaves the embedding spaces uncalibrated, making direct image-to-image comparisons unreliable. Existing methods attempt to address this by refining similarity logits or by computationally expensive per-sample optimization. To overcome these challenges, we introduce SeMoBridge, a lightweight yet powerful approach that directly addresses the misalignment. Our method maps images into the text modality, while keeping their semantic content intact through what we call a Semantic Modality Bridge. SeMoBridge is closed-form and can optionally be trained through multi-modal supervision, combining image and text-alignment losses to optimize the projection. Experiments show that the trained version, SeMoBridge-T, requires only a fraction of the training time while overall outperforming other methods, particularly in low-data scenarios (1, 2, and 4 shots). The code is available at \\href{this https URL}{this http URL}.", 'abstract_zh': '尽管对比语言-图像预训练（CLIP）在零样本任务中通过对齐图像和文本嵌入表现出色，但在少样本分类中的性能受到一个关键限制的阻碍：模内对齐不匹配。这个问题由持续存在的模态差距和CLIP exclusively的跨模态训练目标引起，使得嵌入空间无法校准，从而使直接图像-图像比较不可靠。现有方法试图通过细化相似性逻辑或通过昂贵的逐样本优化来解决这个问题。为克服这些挑战，我们引入了SeMoBridge，这是一种轻量级但强大的方法，直接解决了对齐问题。该方法通过所谓的语义模态桥将图像映射到文本模态，同时保持其语义内容不变。SeMoBridge 是闭式形式的，并且可以通过多模态监督可选地进行训练，结合图像和文本对齐损失来优化投影。实验表明，训练版本 SeMoBridge-T 只需少量的训练时间，而在总体上优于其他方法，尤其是在低数据情景（1, 2, 和 4 次射击）中。代码可供参考：\\href{this https URL}{this http URL}。', 'title_zh': 'SeMoBridge: 语义模态桥梁，实现CLIP的高效少样本适应'}
{'arxiv_id': 'arXiv:2509.26030', 'title': 'Muon Outperforms Adam in Tail-End Associative Memory Learning', 'authors': 'Shuche Wang, Fengzhuo Zhang, Jiaxiang Li, Cunxiao Du, Chao Du, Tianyu Pang, Zhuoran Yang, Mingyi Hong, Vincent Y. F. Tan', 'link': 'https://arxiv.org/abs/2509.26030', 'abstract': "The Muon optimizer is consistently faster than Adam in training Large Language Models (LLMs), yet the mechanism underlying its success remains unclear. This paper demystifies this mechanism through the lens of associative memory. By ablating the transformer components optimized by Muon, we reveal that the associative memory parameters of LLMs, namely the Value and Output (VO) attention weights and Feed-Forward Networks (FFNs), are the primary contributors to Muon's superiority. Motivated by this associative memory view, we then explain Muon's superiority on real-world corpora, which are intrinsically heavy-tailed: a few classes (tail classes) appear far less frequently than others. The superiority is explained through two key properties: (i) its update rule consistently yields a more isotropic singular spectrum than Adam; and as a result, (ii) on heavy-tailed data, it optimizes tail classes more effectively than Adam. Beyond empirical evidence, we theoretically confirm these findings by analyzing a one-layer associative memory model under class-imbalanced data. We prove that Muon consistently achieves balanced learning across classes regardless of feature embeddings, whereas Adam can induce large disparities in learning errors depending on embedding properties. In summary, our empirical observations and theoretical analyses reveal Muon's core advantage: its update rule aligns with the outer-product structure of linear associative memories, enabling more balanced and effective learning of tail classes in heavy-tailed distributions than Adam.", 'abstract_zh': 'Muon优化器在训练大规模语言模型（LLMs）中始终比Adam更快，但其成功机制尚不清晰。通过联想记忆的视角揭开这一机制。通过消融Muon优化的Transformer组件，我们揭示出大规模语言模型的联想记忆参数，即Value和Output（VO）注意力权重以及前馈网络（FFNs），是Muon优越性的主要贡献者。受到这一联想记忆视角的启发，我们进一步解释了在固有表现为重尾分布的现实语料库上，Muon的优越性。重尾数据上的优越性通过两个关键性质来解释：（i）其更新规则始终导致比Adam更加各向同性的奇异谱；因此，（ii）在重尾数据上，它比Adam更有效地优化尾类。除了实证证据，我们通过分析在类别不平衡数据下的单层联想记忆模型，从理论上证实了这些发现。我们证明了无论在特征嵌入如何，Muon都能实现类间学习的一致平衡，而Adam的学习误差可能会因为嵌入特性而出现大的差异。总之，我们的实证观察和理论分析揭示了Muon的核心优势：其更新规则与线性联想记忆的外积结构相一致，在重尾分布中能实现比Adam更加平衡和有效的尾类学习。', 'title_zh': 'Muon在尾端关联记忆学习中优于Adam'}
{'arxiv_id': 'arXiv:2509.26015', 'title': 'Indirect Attention: Turning Context Misalignment into a Feature', 'authors': 'Bissmella Bahaduri, Hicham Talaoubrid, Fangchen Feng, Zuheng Ming, Anissa Mokraoui', 'link': 'https://arxiv.org/abs/2509.26015', 'abstract': "The attention mechanism has become a cornerstone of modern deep learning architectures, where keys and values are typically derived from the same underlying sequence or representation. This work explores a less conventional scenario, when keys and values originate from different sequences or modalities. Specifically, we first analyze the attention mechanism's behavior under noisy value features, establishing a critical noise threshold beyond which signal degradation becomes significant. Furthermore, we model context (key, value) misalignment as an effective form of structured noise within the value features, demonstrating that the noise induced by such misalignment can substantially exceed this critical threshold, thereby compromising standard attention's efficacy. Motivated by this, we introduce Indirect Attention, a modified attention mechanism that infers relevance indirectly in scenarios with misaligned context. We evaluate the performance of Indirect Attention across a range of synthetic tasks and real world applications, showcasing its superior ability to handle misalignment.", 'abstract_zh': '间接注意力：处理上下文错位的一种修改注意力机制', 'title_zh': '间接注意力：将上下文错位转为特征'}
{'arxiv_id': 'arXiv:2509.26008', 'title': 'PFDepth: Heterogeneous Pinhole-Fisheye Joint Depth Estimation via Distortion-aware Gaussian-Splatted Volumetric Fusion', 'authors': 'Zhiwei Zhang, Ruikai Xu, Weijian Zhang, Zhizhong Zhang, Xin Tan, Jingyu Gong, Yuan Xie, Lizhuang Ma', 'link': 'https://arxiv.org/abs/2509.26008', 'abstract': 'In this paper, we present the first pinhole-fisheye framework for heterogeneous multi-view depth estimation, PFDepth. Our key insight is to exploit the complementary characteristics of pinhole and fisheye imagery (undistorted vs. distorted, small vs. large FOV, far vs. near field) for joint optimization. PFDepth employs a unified architecture capable of processing arbitrary combinations of pinhole and fisheye cameras with varied intrinsics and extrinsics. Within PFDepth, we first explicitly lift 2D features from each heterogeneous view into a canonical 3D volumetric space. Then, a core module termed Heterogeneous Spatial Fusion is designed to process and fuse distortion-aware volumetric features across overlapping and non-overlapping regions. Additionally, we subtly reformulate the conventional voxel fusion into a novel 3D Gaussian representation, in which learnable latent Gaussian spheres dynamically adapt to local image textures for finer 3D aggregation. Finally, fused volume features are rendered into multi-view depth maps. Through extensive experiments, we demonstrate that PFDepth sets a state-of-the-art performance on KITTI-360 and RealHet datasets over current mainstream depth networks. To the best of our knowledge, this is the first systematic study of heterogeneous pinhole-fisheye depth estimation, offering both technical novelty and valuable empirical insights.', 'abstract_zh': '基于针孔鱼眼框架的异构多视图深度估计：PFDepth', 'title_zh': 'PFDepth: 带有失真感知高斯聚合体素融合的高斯鱼眼与针孔联合深度估计'}
{'arxiv_id': 'arXiv:2509.26004', 'title': 'Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations', 'authors': 'Nicola Messina, Rosario Leonardi, Luca Ciampi, Fabio Carrara, Giovanni Maria Farinella, Fabrizio Falchi, Antonino Furnari', 'link': 'https://arxiv.org/abs/2509.26004', 'abstract': 'Pixel-level recognition of objects manipulated by the user from egocentric images enables key applications spanning assistive technologies, industrial safety, and activity monitoring. However, progress in this area is currently hindered by the scarcity of annotated datasets, as existing approaches rely on costly manual labels. In this paper, we propose to learn human-object interaction detection leveraging narrations -- natural language descriptions of the actions performed by the camera wearer which contain clues about manipulated objects (e.g., "I am pouring vegetables from the chopping board to the pan"). Narrations provide a form of weak supervision that is cheap to acquire and readily available in state-of-the-art egocentric datasets. We introduce Narration-Supervised in-Hand Object Segmentation (NS-iHOS), a novel task where models have to learn to segment in-hand objects by learning from natural-language narrations. Narrations are then not employed at inference time. We showcase the potential of the task by proposing Weakly-Supervised In-hand Object Segmentation from Human Narrations (WISH), an end-to-end model distilling knowledge from narrations to learn plausible hand-object associations and enable in-hand object segmentation without using narrations at test time. We benchmark WISH against different baselines based on open-vocabulary object detectors and vision-language models, showing the superiority of its design. Experiments on EPIC-Kitchens and Ego4D show that WISH surpasses all baselines, recovering more than 50% of the performance of fully supervised methods, without employing fine-grained pixel-wise annotations.', 'abstract_zh': '基于述说监督的手持物体分割：从摄像佩戴者执行的动作自然语言描述中学习人体-物体交互检测', 'title_zh': '基于人类叙述的弱监督自手内物体分割学习'}
{'arxiv_id': 'arXiv:2509.25998', 'title': 'VRWKV-Editor: Reducing quadratic complexity in transformer-based video editing', 'authors': 'Abdelilah Aitrouga, Youssef Hmamouche, Amal El Fallah Seghrouchni', 'link': 'https://arxiv.org/abs/2509.25998', 'abstract': 'In light of recent progress in video editing, deep learning models focusing on both spatial and temporal dependencies have emerged as the primary method. However, these models suffer from the quadratic computational complexity of traditional attention mechanisms, making them difficult to adapt to long-duration and high-resolution videos. This limitation restricts their applicability in practical contexts such as real-time video processing. To tackle this challenge, we introduce a method to reduce both time and space complexity of these systems by proposing VRWKV-Editor, a novel video editing model that integrates a linear spatio-temporal aggregation module into video-based diffusion models. VRWKV-Editor leverages bidirectional weighted key-value recurrence mechanism of the RWKV transformer to capture global dependencies while preserving temporal coherence, achieving linear complexity without sacrificing quality. Extensive experiments demonstrate that the proposed method achieves up to 3.7x speedup and 60% lower memory usage compared to state-of-the-art diffusion-based video editing methods, while maintaining competitive performance in frame consistency and text alignment. Furthermore, a comparative analysis we conducted on videos with different sequence lengths confirms that the gap in editing speed between our approach and architectures with self-attention becomes more significant with long videos.', 'abstract_zh': '基于近期视频编辑领域的进展，专注于空�.utils空和时序依赖性的深度学习模型已成为主流方法。然而，这些模型受到传统注意力机制二次计算复杂度的限制，难以适应长时间和高分辨率视频的应用需求。这一局限性限制了它们在实时视频处理等实际应用场景中的适用性。为了应对这一挑战，我们提出了一种通过结合线性空冋试用时序聚合模块到基于视频的扩散模型中来降低时空复杂度的方法，并提出了VRWKV-编辑器这一新型视频编辑模型。VRWKV-编辑器利用RWKV变换器的双向加权键值循环机制来捕捉全局依赖关系同时保持时序一致性，实现了线性复杂度而不牺牲质量。广泛实验证明，与最先进的基于扩散的视频编辑方法相比，该方法可实现最高3.7倍的速度提升和60%更低的内存使用率，同时在帧一致性和文本对齐方面保持了竞争力。此外，我们在不同序列长度的视频上进行的比较分析证实，与采用自我注意力的架构相比，我们方法的编辑速度差距在长时间视频上更为显著。', 'title_zh': 'VRWKV-Editor: 降低基于变压器的视频编辑中的二次复杂度'}
{'arxiv_id': 'arXiv:2509.25992', 'title': 'MHINDR - a DSM5 based mental health diagnosis and recommendation framework using LLM', 'authors': 'Vaishali Agarwal, Sachin Thukral, Arnab Chatterjee', 'link': 'https://arxiv.org/abs/2509.25992', 'abstract': 'Mental health forums offer valuable insights into psychological issues, stressors, and potential solutions. We propose MHINDR, a large language model (LLM) based framework integrated with DSM-5 criteria to analyze user-generated text, dignose mental health conditions, and generate personalized interventions and insights for mental health practitioners. Our approach emphasizes on the extraction of temporal information for accurate diagnosis and symptom progression tracking, together with psychological features to create comprehensive mental health summaries of users. The framework delivers scalable, customizable, and data-driven therapeutic recommendations, adaptable to diverse clinical contexts, patient needs, and workplace well-being programs.', 'abstract_zh': '心理健康论坛提供了关于心理问题、压力源及潜在解决方案的重要见解。我们提出MHINDR框架，该框架基于大规模语言模型（LLM）并结合DSM-5标准，用于分析用户生成的文本、诊断心理健康状况，并为心理健康从业者生成个性化干预措施和见解。该方法强调时间信息的提取以实现准确的诊断和症状进展追踪，并结合心理特征创建用户的全面心理健康总结。该框架提供可扩展、可定制且基于数据的治疗建议，适用于多种临床环境、患者需求和工作场所福祉项目。', 'title_zh': 'MHINDR - 基于DSM5的精神健康诊断与推荐框架利用大语言模型'}
{'arxiv_id': 'arXiv:2509.25987', 'title': 'R-Log: Incentivizing Log Analysis Capability in LLMs via Reasoning-based Reinforcement Learning', 'authors': 'Yilun Liu, Ziang Chen, Song Xu, Minggui He, Shimin Tao, Weibin Meng, Yuming Xie, Tao Han, Chunguang Zhao, Jingzhou Du, Daimeng Wei, Shenglin Zhang, Yongqian Sun', 'link': 'https://arxiv.org/abs/2509.25987', 'abstract': "The growing complexity of log data in modern software systems has prompted the use of Large Language Models (LLMs) for automated log analysis. Current approaches typically rely on direct supervised fine-tuning (SFT) on log-label pairs. However, this exacerbates the domain discrepancy between general-purpose LLMs and specialized log data, causing overfitting. Furthermore, SFT's imbalanced loss computation often allows lengthy contexts to overwhelm critical, concise details in model answers, leading to hallucinations. To address these limitations, we propose R-Log, a novel reasoning-based paradigm that mirrors the structured, step-by-step analytical process of human engineers. This approach enhances generalizability by learning the underlying rules behind conclusions. We further employ Reinforcement Learning (RL) to optimize the model within a simulated O&M environment, thereby reducing hallucinations by directly rewarding correct outcomes. R-Log is first cold-started on a curated dataset of 2k+ reasoning trajectories, guided by 13 strategies from manual O&M practices, to establish an initial reasoning capability. This ability is then refined via RL using a joint reward function. Empirical evaluations on real-world logs show that R-Log outperforms existing methods across five log analysis tasks, particularly in unseen scenarios (by 228.05%). We also designed R-Log-fast with 5x speedup while keeping 93% of the efficacy.", 'abstract_zh': '现代软件系统中日志数据日益复杂的趋势促使使用大型语言模型（LLMs）进行自动日志分析。当前的方法通常依赖于日志-标签对的直接监督微调（SFT）。然而，这加剧了通用目的LLMs与专门的日志数据之间的领域差异，导致过拟合。此外，SFT中失衡的损失计算往往使长语境压倒模型答案中的关键、简洁细节，导致模型产生幻觉。为解决这些问题，我们提出了R-Log，一种基于推理的新范式，模仿了人类工程师结构化、分步的分析过程。该方法通过学习结论背后的规则增强泛化能力。进一步地，我们利用强化学习（RL）在模拟的运维环境中优化模型，从而通过直接奖励正确的结果减少幻觉。R-Log首先在由13种手动运维策略指导的2千多个推理轨迹的受限数据集上冷启动，以建立初始的推理能力。然后通过联合奖励函数使用RL对该能力进行细化。实证评估表明，在五个日志分析任务中，R-Log在未见过的场景中尤其优于现有方法，性能提高228.05%。我们还设计了R-Log-fast，其速度提高了5倍，同时保持了93%的有效性。', 'title_zh': 'R-Log: 基于推理强化学习激励LLM的日志分析能力'}
{'arxiv_id': 'arXiv:2509.25979', 'title': 'Reconcile Certified Robustness and Accuracy for DNN-based Smoothed Majority Vote Classifier', 'authors': 'Gaojie Jin, Xinping Yi, Xiaowei Huang', 'link': 'https://arxiv.org/abs/2509.25979', 'abstract': 'Within the PAC-Bayesian framework, the Gibbs classifier (defined on a posterior $Q$) and the corresponding $Q$-weighted majority vote classifier are commonly used to analyze the generalization performance. However, there exists a notable lack in theoretical research exploring the certified robustness of majority vote classifier and its interplay with generalization. In this study, we develop a generalization error bound that possesses a certified robust radius for the smoothed majority vote classifier (i.e., the $Q$-weighted majority vote classifier with smoothed inputs); In other words, the generalization bound holds under any data perturbation within the certified robust radius. As a byproduct, we find that the underpinnings of both the generalization bound and the certified robust radius draw, in part, upon weight spectral norm, which thereby inspires the adoption of spectral regularization in smooth training to boost certified robustness. Utilizing the dimension-independent property of spherical Gaussian inputs in smooth training, we propose a novel and inexpensive spectral regularizer to enhance the smoothed majority vote classifier. In addition to the theoretical contribution, a set of empirical results is provided to substantiate the effectiveness of our proposed method.', 'abstract_zh': '在PAC-Bayesian框架下，基于后验$Q$的吉布斯分类器及其相应的$Q$加权多数投票分类器常被用于分析泛化性能。然而，对于多数投票分类器的认证鲁棒性以及其与泛化之间的相互作用，理论研究存在明显不足。在本研究中，我们开发了一个泛化误差界，该误差界具有对平滑多数投票分类器（即带有平滑输入的$Q$加权多数投票分类器）的认证鲁棒半径；换句话说，该泛化界在认证鲁棒半径内的任何数据扰动下均成立。作为副产品，我们发现泛化界和认证鲁棒半径的理论基础部分依赖于权重谱范数，这启发我们通过在平滑训练中采用谱正则化来提高认证鲁棒性。利用平滑训练中球形高斯输入的维数无关性质，我们提出了一种新颖且经济高效的谱正则化器，以提升平滑多数投票分类器。除了理论贡献外，我们还提供了一系列实验证据以验证所提出方法的有效性。', 'title_zh': '基于平滑多数投票分类器的认证鲁棒性和准确性的统一'}
{'arxiv_id': 'arXiv:2509.25977', 'title': 'Data-Free Continual Learning of Server Models in Model-Heterogeneous Federated learning', 'authors': 'Xiao Zhang, Zengzhe Chen, Yuan Yuan, Yifei Zou, Fuzhen Zhuang, Wenyu Jiao, Yuke Wang, Dongxiao Yu', 'link': 'https://arxiv.org/abs/2509.25977', 'abstract': 'Federated learning (FL) is a distributed learning paradigm across multiple entities while preserving data privacy. However, with the continuous emergence of new data and increasing model diversity, traditional federated learning faces significant challenges, including inherent issues of data heterogeneity, model heterogeneity and catastrophic forgetting, along with new challenge of knowledge misalignment. In this study, we introduce FedDCL, a novel framework designed to enable data-free continual learning of the server model in a model-heterogeneous federated setting. We leverage pre-trained diffusion models to extract lightweight class-specific prototypes, which confer a threefold data-free advantage, enabling: (1) generation of synthetic data for the current task to augment training and counteract non-IID data distributions; (2) exemplar-free generative replay for retaining knowledge from previous tasks; and (3) data-free dynamic knowledge transfer from heterogeneous clients to the server. Experimental results on various datasets demonstrate the effectiveness of FedDCL, showcasing its potential to enhance the generalizability and practical applicability of federated learning in dynamic settings.', 'abstract_zh': '联邦学习（FL）是一种在多个实体之间进行分布式学习的范式，同时保护数据隐私。然而，随着新数据的不断出现和模型多样性的增加，传统的联邦学习面临着诸如数据异质性、模型异质性和灾难性遗忘等根本性挑战，同时还面临着知识错位的新挑战。在本研究中，我们介绍了FedDCL，这是一种新颖的框架，旨在在异质模型联邦环境中实现服务器模型的数据无关连续学习。我们利用预训练的扩散模型提取轻量级的类特异性原型，赋予该框架三重数据无关的优势，包括：（1）为当前任务生成合成数据以增强训练并对抗非IID数据分布；（2）无需示例的生成性重放以保留前任务的知识；（3）从异质客户端到服务器的数据无关动态知识转移。在各种数据集上的实验结果证明了FedDCL的有效性，展示了其在动态环境中增强联邦学习的普适性和实际应用潜力。', 'title_zh': '服务器模型在模型异构联邦学习中的无数据连续学习'}
{'arxiv_id': 'arXiv:2509.25955', 'title': 'AIM: Adaptive Intervention for Deep Multi-task Learning of Molecular Properties', 'authors': 'Mason Minot, Gisbert Schneider', 'link': 'https://arxiv.org/abs/2509.25955', 'abstract': "Simultaneously optimizing multiple, frequently conflicting, molecular properties is a key bottleneck in the development of novel therapeutics. Although a promising approach, the efficacy of multi-task learning is often compromised by destructive gradient interference, especially in the data-scarce regimes common to drug discovery. To address this, we propose AIM, an optimization framework that learns a dynamic policy to mediate gradient conflicts. The policy is trained jointly with the main network using a novel augmented objective composed of dense, differentiable regularizers. This objective guides the policy to produce updates that are geometrically stable and dynamically efficient, prioritizing progress on the most challenging tasks. We demonstrate that AIM achieves statistically significant improvements over multi-task baselines on subsets of the QM9 and targeted protein degraders benchmarks, with its advantage being most pronounced in data-scarce regimes. Beyond performance, AIM's key contribution is its interpretability; the learned policy matrix serves as a diagnostic tool for analyzing inter-task relationships. This combination of data-efficient performance and diagnostic insight highlights the potential of adaptive optimizers to accelerate scientific discovery by creating more robust and insightful models for multi-property molecular design.", 'abstract_zh': '同时优化多个经常相互冲突的分子属性是新型治疗药物开发中的一个关键瓶颈。尽管多任务学习是一个有前景的方法，但在药物发现中常见的数据稀缺情况下，其效果往往会受到破坏性梯度干扰的阻碍。为了解决这个问题，我们提出了一种动态策略学习框架AIM，该框架学习一种动态策略来调解梯度冲突。该策略与主要网络联合训练，并使用一种新的增强目标函数，该目标函数包含密集可微正则化项。该目标函数引导策略生成几何上稳定且动态高效的更新，优先解决最具挑战性的任务。我们证明，AIM在QM9和靶向蛋白降解物基准数据集的子集中，相对于多任务 baseline 实现了统计显著的改进，其优势在数据稀缺的情况下尤为明显。除了性能提升，AIM 的关键贡献在于其实现可解释性；学习到的策略矩阵可以作为分析任务间关系的诊断工具。这种高效使用数据性能与诊断洞察力的结合，突显了自适应优化器在通过创建更多鲁棒性和洞察力更强的多属性分子设计模型加速科学发现方面的潜力。', 'title_zh': '适应性干预的深度多任务学习分子性质方法'}
{'arxiv_id': 'arXiv:2509.25933', 'title': 'From MNIST to ImageNet: Understanding the Scalability Boundaries of Differentiable Logic Gate Networks', 'authors': 'Sven Brändle, Till Aczel, Andreas Plesner, Roger Wattenhofer', 'link': 'https://arxiv.org/abs/2509.25933', 'abstract': 'Differentiable Logic Gate Networks (DLGNs) are a very fast and energy-efficient alternative to conventional feed-forward networks. With learnable combinations of logical gates, DLGNs enable fast inference by hardware-friendly execution. Since the concept of DLGNs has only recently gained attention, these networks are still in their developmental infancy, including the design and scalability of their output layer. To date, this architecture has primarily been tested on datasets with up to ten classes.\nThis work examines the behavior of DLGNs on large multi-class datasets. We investigate its general expressiveness, its scalability, and evaluate alternative output strategies. Using both synthetic and real-world datasets, we provide key insights into the importance of temperature tuning and its impact on output layer performance. We evaluate conditions under which the Group-Sum layer performs well and how it can be applied to large-scale classification of up to 2000 classes.', 'abstract_zh': 'Differentiable Logic Gate Networks on Large Multi-Class Datasets：Behavior, Scalability, and Output Strategies', 'title_zh': '从MNIST到ImageNet：理解可微逻辑门网络的可扩展性边界'}
{'arxiv_id': 'arXiv:2509.25927', 'title': 'The Impact of Scaling Training Data on Adversarial Robustness', 'authors': 'Marco Zimmerli, Andreas Plesner, Till Aczel, Roger Wattenhofer', 'link': 'https://arxiv.org/abs/2509.25927', 'abstract': 'Deep neural networks remain vulnerable to adversarial examples despite advances in architectures and training paradigms. We investigate how training data characteristics affect adversarial robustness across 36 state-of-the-art vision models spanning supervised, self-supervised, and contrastive learning approaches, trained on datasets from 1.2M to 22B images. Models were evaluated under six black-box attack categories: random perturbations, two types of geometric masks, COCO object manipulations, ImageNet-C corruptions, and ImageNet-R style shifts. Robustness follows a logarithmic scaling law with both data volume and model size: a tenfold increase in data reduces attack success rate (ASR) on average by ~3.2%, whereas a tenfold increase in model size reduces ASR on average by ~13.4%. Notably, some self-supervised models trained on curated datasets, such as DINOv2, outperform others trained on much larger but less curated datasets, challenging the assumption that scale alone drives robustness. Adversarial fine-tuning of ResNet50s improves generalization across structural variations but not across color distributions. Human evaluation reveals persistent gaps between human and machine vision. These results show that while scaling improves robustness, data quality, architecture, and training objectives play a more decisive role than raw scale in achieving broad-spectrum adversarial resilience.', 'abstract_zh': '深度神经网络在架构和训练范式的进步下仍然容易受到对手样例的攻击。我们研究了训练数据特性如何影响36种前沿视觉模型的 adversarial 抗性，这些模型涵盖了监督学习、自监督学习和对比学习方法，训练数据集规模从120万到220亿不等。模型在六类黑盒攻击类别下进行了评估：随机扰动、两种类型的几何遮罩、COCO目标操作、ImageNet-C腐蚀和ImageNet-R风格变化。抗性随着数据量和模型规模的增加呈现出对数级别缩放：数据量增加十倍，攻击成功率平均下降约3.2%；模型规模增加十倍，攻击成功率平均下降约13.4%。值得注意的是，一些在精心策划的数据集上训练的自监督模型，如DINOv2，比在更大但更加不策划的数据集上训练的其他模型表现更好，这挑战了单纯规模决定抗性的假设。ResNet50的对抗微调在结构变化中改善了泛化能力，但在颜色分布方面并没有改善。人类评估揭示了人类视觉和机器视觉之间持续存在的差距。这些结果表明，虽然规模的增加可以提高抗性，但数据质量、架构和训练目标在实现广泛谱系的对抗鲁棒性方面发挥着比单纯规模更重要的作用。', 'title_zh': '扩展训练数据对对抗鲁棒性的影响'}
{'arxiv_id': 'arXiv:2509.25919', 'title': 'Accelerating LLM Inference with Precomputed Query Storage', 'authors': 'Jay H. Park, Youngju Cho, Choungsol Lee, Moonwook Oh, Euiseong Seo', 'link': 'https://arxiv.org/abs/2509.25919', 'abstract': 'Large language model (LLM) inference often suffers from high latency, particularly in resource-constrained environments such as on-device or edge deployments. To address this challenge, we present StorInfer, a novel storage-assisted LLM inference system that accelerates response time by precomputing and storing predictable query-response pairs offline. When a user query semantically matches a precomputed query, StorInfer bypasses expensive GPU inference and instantly returns the stored response, significantly reducing latency and compute costs. To maximize coverage and effectiveness, StorInfer employs an LLM-driven generator that adaptively produces diverse and deduplicated queries based on a given knowledge base. This is achieved via two techniques: adaptive query masking, which prevents regeneration of similar queries, and adaptive sampling, which dynamically tunes generation parameters to promote semantic diversity. The resulting query-response pairs are embedded and indexed using a disk-backed vector database to enable fast, similarity-based retrieval at runtime. Using this approach, we generated 150K unique precomputed pairs (taking up to 830 MB of storage space), achieving up to 17.3% latency reduction with no loss in response quality. Our evaluation across multiple QA datasets demonstrates the practicality and scalability of storage-assisted inference, especially in scenarios with predictable query distributions. StorInfer highlights a promising direction in leveraging storage as a primary enabler for efficient, low-latency LLM deployment.', 'abstract_zh': '一种基于存储辅助的大型语言模型推理系统：StorInfer及其应用', 'title_zh': '预计算查询存储加速大模型推理'}
{'arxiv_id': 'arXiv:2509.25905', 'title': 'User-Centric Communication Service Provision for Edge-Assisted Mobile Augmented Reality', 'authors': 'Conghao Zhou, Jie Gao, Shisheng Hu, Nan Cheng, Weihua Zhuang, Xuemin Shen', 'link': 'https://arxiv.org/abs/2509.25905', 'abstract': 'Future 6G networks are envisioned to facilitate edge-assisted mobile augmented reality (MAR) via strengthening the collaboration between MAR devices and edge servers. In order to provide immersive user experiences, MAR devices must timely upload camera frames to an edge server for simultaneous localization and mapping (SLAM)-based device pose tracking. In this paper, to cope with user-specific and non-stationary uplink data traffic, we develop a digital twin (DT)-based approach for user-centric communication service provision for MAR. Specifically, to establish DTs for individual MAR devices, we first construct a data model customized for MAR that captures the intricate impact of the SLAM-based frame uploading mechanism on the user-specific data traffic pattern. We then define two DT operation functions that cooperatively enable adaptive switching between different data-driven models for capturing non-stationary data traffic. Leveraging the user-oriented data management introduced by DTs, we propose an algorithm for network resource management that ensures the timeliness of frame uploading and the robustness against inherent inaccuracies in data traffic modeling for individual MAR devices. Trace-driven simulation results demonstrate that the user-centric communication service provision achieves a 14.2% increase in meeting the camera frame uploading delay requirement in comparison with the slicing-based communication service provision widely used for 5G.', 'abstract_zh': '未来6G网络通过加强移动增强现实（MAR）设备与边缘服务器之间的协作，旨在促进边缘辅助移动增强现实。为了提供沉浸式用户体验，MAR设备必须及时将摄像头帧上传到边缘服务器，进行基于SLAM的设备姿态跟踪。在本文中，为了应对用户特定和非平稳上行数据流量，我们开发了一种基于数字孪生（DT）的方法，以提供以用户为中心的通信服务，针对MAR。具体来说，为了为每个MAR设备建立DT，我们首先构建了一个针对MAR定制的数据模型，以捕捉基于SLAM的帧上传机制对用户特定数据流量模式的复杂影响。我们然后定义了两种协同工作的DT操作函数，以适应性地在不同的数据驱动模型之间切换，以捕捉非平稳数据流量。利用DT引入的用户导向的数据管理方法，我们提出了一种网络资源管理算法，以确保帧上传的及时性和数据流量模型固有不准确性对MAR设备的影响的鲁棒性。基于跟踪的模拟结果表明，以用户为中心的通信服务提供相较于广泛应用于5G的切片通信服务提供，满足摄像头帧上传延迟要求的能力提高了14.2%。', 'title_zh': '边缘辅助移动增强现实的用户中心通信服务提供'}
{'arxiv_id': 'arXiv:2509.25903', 'title': 'PerQ: Efficient Evaluation of Multilingual Text Personalization Quality', 'authors': 'Dominik Macko, Andrew Pulver', 'link': 'https://arxiv.org/abs/2509.25903', 'abstract': 'Since no metrics are available to evaluate specific aspects of a text, such as its personalization quality, the researchers often rely solely on large language models to meta-evaluate such texts. Due to internal biases of individual language models, it is recommended to use multiple of them for combined evaluation, which directly increases costs of such meta-evaluation. In this paper, a computationally efficient method for evaluation of personalization quality of a given text (generated by a language model) is introduced, called PerQ. A case study of comparison of generation capabilities of large and small language models shows the usability of the proposed metric in research, effectively reducing the waste of resources.', 'abstract_zh': '自生成文本的个性化质量无法用现有指标进行评估，研究者通常仅依赖大型语言模型进行元评估。由于单一语言模型内部可能存在偏见，建议使用多个模型进行综合评估，这直接增加了元评估的成本。本文提出了一种计算效率高的方法——PerQ，用于评估由语言模型生成的文本的个性化质量，并通过一个大型和小型语言模型生成能力的案例研究展示了该提出的度量标准在研究中的实用性，有效减少了资源浪费。', 'title_zh': '多语言文本个性化质量高效评估：PerQ'}
{'arxiv_id': 'arXiv:2509.25897', 'title': "RoleConflictBench: A Benchmark of Role Conflict Scenarios for Evaluating LLMs' Contextual Sensitivity", 'authors': 'Jisu Shin, Hoyun Song, Juhyun Oh, Changgeon Ko, Eunsu Kim, Chani Jung, Alice Oh', 'link': 'https://arxiv.org/abs/2509.25897', 'abstract': "Humans often encounter role conflicts -- social dilemmas where the expectations of multiple roles clash and cannot be simultaneously fulfilled. As large language models (LLMs) become increasingly influential in human decision-making, understanding how they behave in complex social situations is essential. While previous research has evaluated LLMs' social abilities in contexts with predefined correct answers, role conflicts represent inherently ambiguous social dilemmas that require contextual sensitivity: the ability to recognize and appropriately weigh situational cues that can fundamentally alter decision priorities. To address this gap, we introduce RoleConflictBench, a novel benchmark designed to evaluate LLMs' contextual sensitivity in complex social dilemmas. Our benchmark employs a three-stage pipeline to generate over 13K realistic role conflict scenarios across 65 roles, systematically varying their associated expectations (i.e., their responsibilities and obligations) and situational urgency levels. By analyzing model choices across 10 different LLMs, we find that while LLMs show some capacity to respond to these contextual cues, this sensitivity is insufficient. Instead, their decisions are predominantly governed by a powerful, inherent bias related to social roles rather than situational information. Our analysis quantifies these biases, revealing a dominant preference for roles within the Family and Occupation domains, as well as a clear prioritization of male roles and Abrahamic religions across most evaluatee models.", 'abstract_zh': '人类经常遇到角色冲突——多种角色期望相互矛盾且无法同时满足的社会困境。随着大规模语言模型（LLMs）在人类决策中日益发挥影响力，理解它们在复杂社会情境中的行为变得尤为关键。尽管先前研究已在具备预定义正确答案的背景下评估了LLMs的社会能力，但角色冲突代表了一种固有的社会困境，需要情境敏感性：即识别并适当权衡可能根本改变决策优先次序的情境线索的能力。为填补这一空白，我们提出了RoleConflictBench，一个旨在评估LLMs在复杂社会困境中情境敏感性的新型基准。该基准采用了三阶段流程生成超过13000个现实的角色冲突情境，覆盖65种角色，并系统地变化其关联期望（即职责和义务）以及情境紧迫性水平。通过对10种不同LLM的模型选择进行分析，我们发现虽然LLMs在一定程度上能够响应这些情境线索，但这种敏感性是不足的。相反，它们的决策主要由与社会角色相关的强大且内在的偏见所支配，而不是情境信息。我们的分析量化了这些偏见，揭示了在大多数评估模型中对家庭和职业领域角色的主导偏好，以及对男性角色和犹太教、基督教、伊斯兰教明确的优先级。', 'title_zh': '角色冲突基准：评估LLM语境敏感性的角色冲突场景基准'}
{'arxiv_id': 'arXiv:2509.25884', 'title': 'scUnified: An AI-Ready Standardized Resource for Single-Cell RNA Sequencing Analysis', 'authors': 'Ping Xu, Zaitian Wang, Zhirui Wang, Pengjiang Li, Ran Zhang, Gaoyang Li, Hanyu Xie, Jiajia Wang, Yuanchun Zhou, Pengfei Wang', 'link': 'https://arxiv.org/abs/2509.25884', 'abstract': 'Single-cell RNA sequencing (scRNA-seq) technology enables systematic delineation of cellular states and interactions, providing crucial insights into cellular heterogeneity. Building on this potential, numerous computational methods have been developed for tasks such as cell clustering, cell type annotation, and marker gene identification. To fully assess and compare these methods, standardized, analysis-ready datasets are essential. However, such datasets remain scarce, and variations in data formats, preprocessing workflows, and annotation strategies hinder reproducibility and complicate systematic evaluation of existing methods. To address these challenges, we present scUnified, an AI-ready standardized resource for single-cell RNA sequencing data that consolidates 13 high-quality datasets spanning two species (human and mouse) and nine tissue types. All datasets undergo standardized quality control and preprocessing and are stored in a uniform format to enable direct application in diverse computational analyses without additional data cleaning. We further demonstrate the utility of scUnified through experimental analyses of representative biological tasks, providing a reproducible foundation for the standardized evaluation of computational methods on a unified dataset.', 'abstract_zh': '单细胞RNA测序（scRNA-seq）技术 enables系统解析细胞状态和相互作用，为细胞异质性提供了关键洞见。在此基础上，开发了多种计算方法，用于细胞聚类、细胞类型注释和标志基因识别等任务。为进一步评估和比较这些方法，标准化和分析准备好的数据集至关重要。然而，此类数据集仍然稀缺，数据格式、预处理工作流程和注释策略的差异阻碍了可重复性并复杂了对现有方法的系统性评估。为应对这些挑战，我们介绍了一种AI就绪的标准化资源scUnified，整合了涵盖两种物种（人类和小鼠）和九种组织类型的13个高质量数据集。所有数据集都经过标准化的质量控制和预处理，并采用统一格式存储，以确保可以直接应用于多种计算分析而无需额外的数据清洗。此外，我们通过代表性生物任务的实验分析展示了scUnified的实用性，为在统一数据集上标准化评估计算方法提供了可重复的基础。', 'title_zh': 'scUnified：一个面向AI的标准单细胞RNA测序分析资源'}
{'arxiv_id': 'arXiv:2509.25876', 'title': 'Efficient On-Policy Reinforcement Learning via Exploration of Sparse Parameter Space', 'authors': 'Xinyu Zhang, Aishik Deb, Klaus Mueller', 'link': 'https://arxiv.org/abs/2509.25876', 'abstract': 'Policy-gradient methods such as Proximal Policy Optimization (PPO) are typically updated along a single stochastic gradient direction, leaving the rich local structure of the parameter space unexplored. Previous work has shown that the surrogate gradient is often poorly correlated with the true reward landscape. Building on this insight, we visualize the parameter space spanned by policy checkpoints within an iteration and reveal that higher performing solutions often lie in nearby unexplored regions. To exploit this opportunity, we introduce ExploRLer, a pluggable pipeline that seamlessly integrates with on-policy algorithms such as PPO and TRPO, systematically probing the unexplored neighborhoods of surrogate on-policy gradient updates. Without increasing the number of gradient updates, ExploRLer achieves significant improvements over baselines in complex continuous control environments. Our results demonstrate that iteration-level exploration provides a practical and effective way to strengthen on-policy reinforcement learning and offer a fresh perspective on the limitations of the surrogate objective.', 'abstract_zh': '基于策略梯度的方法如proximal策略优化(PPO)通常沿单一的随机梯度方向更新，未能充分利用参数空间的丰富局部结构。已有工作表明，近端梯度往往是与真正奖赏景观相关性较差的。基于这一洞察，我们可视化迭代过程中策略检查点所覆盖的参数空间，并揭示出高性能的解决方案往往位于未探索的邻近区域。为了利用这一机遇，我们提出了一种可插拔的ExploRLer管道，该管道能够无缝集成到如PPO和TRPO这类基于策略的方法中，系统地探究替代策略梯度更新的未探索邻域。在不增加梯度更新次数的情况下，ExploRLer在复杂连续控制环境中显著优于基线方法。我们的结果表明，迭代级探索为强化学习，特别是基于策略的强化学习提供了一种实用且有效的方法，同时也为我们重新审视替代目标的局限性提供了新视角。', 'title_zh': '通过稀疏参数空间探索实现高效的策略优化强化学习'}
{'arxiv_id': 'arXiv:2509.25857', 'title': 'Vector sketch animation generation with differentialable motion trajectories', 'authors': 'Xinding Zhu, Xinye Yang, Shuyang Zheng, Zhexin Zhang, Fei Gao, Jing Huang, Jiazhou Chen', 'link': 'https://arxiv.org/abs/2509.25857', 'abstract': 'Sketching is a direct and inexpensive means of visual expression. Though image-based sketching has been well studied, video-based sketch animation generation is still very challenging due to the temporal coherence requirement. In this paper, we propose a novel end-to-end automatic generation approach for vector sketch animation. To solve the flickering issue, we introduce a Differentiable Motion Trajectory (DMT) representation that describes the frame-wise movement of stroke control points using differentiable polynomial-based trajectories. DMT enables global semantic gradient propagation across multiple frames, significantly improving the semantic consistency and temporal coherence, and producing high-framerate output. DMT employs a Bernstein basis to balance the sensitivity of polynomial parameters, thus achieving more stable optimization. Instead of implicit fields, we introduce sparse track points for explicit spatial modeling, which improves efficiency and supports long-duration video processing. Evaluations on DAVIS and LVOS datasets demonstrate the superiority of our approach over SOTA methods. Cross-domain validation on 3D models and text-to-video data confirms the robustness and compatibility of our approach.', 'abstract_zh': '基于视频的矢量素描动画生成：一种端到端自动生成方法', 'title_zh': '基于可微动捕轨迹的向量草图动画生成'}
{'arxiv_id': 'arXiv:2509.25849', 'title': 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation', 'authors': 'Ziniu Li, Congliang Chen, Tianyun Yang, Tian Ding, Ruoyu Sun, Ge Zhang, Wenhao Huang, Zhi-Quan Luo', 'link': 'https://arxiv.org/abs/2509.25849', 'abstract': 'Large Language Models (LLMs) can self-improve through reinforcement learning, where they generate trajectories to explore and discover better solutions. However, this exploration process is computationally expensive, often forcing current methods to assign limited exploration budgets to each task. This uniform allocation creates problematic edge cases: easy tasks consistently succeed while difficult tasks consistently fail, both producing zero gradients during training updates for the widely used Group Relative Policy Optimization (GRPO). We address this problem from the lens of exploration budget allocation. Viewing each task\'s exploration as an "item" with a distinct "value" and "cost", we establish a connection to the classical knapsack problem. This formulation allows us to derive an optimal assignment rule that adaptively distributes resources based on the model\'s current learning status. When applied to GRPO, our method increases the effective ratio of non-zero policy gradients by 20-40% during training. Acting as a computational "free lunch", our approach could reallocate exploration budgets from tasks where learning is saturated to those where it is most impactful. This enables significantly larger budgets (e.g., 93 rollouts) for especially challenging problems, which would be computationally prohibitive under a uniform allocation. These improvements translate to meaningful gains on mathematical reasoning benchmarks, with average improvements of 2-4 points and peak gains of 9 points on specific tasks. Notably, achieving comparable performance with traditional homogeneous allocation would require about 2x the computational resources.', 'abstract_zh': '大型语言模型（LLMs）可以通过强化学习自我改进，其中它们生成轨迹以探索和发现更好的解决方案。然而，这个探索过程计算成本高昂，常迫使当前方法对每个任务分配有限的探索预算。这种均匀分配创造了问题边缘案例：简单任务一致成功而困难任务一致失败，两者在训练更新中均产生零梯度。我们从探索预算分配的角度解决这个问题。将每个任务的探索视作具有不同“价值”和“成本”的“物品”，我们建立了与经典背包问题的联系。这种表述允许我们推导出一种自适应分配资源的规则，基于模型当前的学习状态。将该方法应用于GRPO时，在训练过程中有效非零策略梯度的比例可提高20-40%。作为计算上的“免费午餐”，我们的方法可以重新分配探索预算，从学习饱和的任务转移到学习最具有影响力的任务。这使得对特别具有挑战性的问题分配更大的预算（例如，93次展开），这在均匀分配下是计算上不可行的。这些改进在数学推理基准测试中转化为有意义的提高，平均改进幅度为2-4分，特定任务上最大改进幅度为9分。有趣的是，获得与传统均匀分配相当的性能需要大约两倍的计算资源。', 'title_zh': '背包RL：通过优化预算分配来解锁大规模语言模型的探索'}
{'arxiv_id': 'arXiv:2509.25848', 'title': 'More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models', 'authors': 'Xinyu Tian, Shu Zou, Zhaoyuan Yang, Mengqi He, Fabian Waschkowski, Lukas Wesemann, Peter Tu, Jing Zhang', 'link': 'https://arxiv.org/abs/2509.25848', 'abstract': "Reasoning has emerged as a pivotal capability in Large Language Models (LLMs). Through Reinforcement Learning (RL), typically Group Relative Policy Optimization (GRPO), these models are able to solve complex tasks such as mathematics and code generation. Building on these advances, recent research has sought to extend reasoning to Vision-Language Models (VLMs), yielding promising results across diverse visual tasks. Despite this progress, our study uncovers the dual nature of multimodal reasoning: while it substantially enhances logical inference and facilitates performance on challenging problems, it may gradually impair perceptual grounding, leading to recognition failures on otherwise basic visual questions. Through further analysis, we attribute this phenomenon to visual forgetting, wherein prolonged reasoning causes the model to increasingly disregard visual input. To address this, we propose Vision-Anchored Policy Optimization (VAPO), a simple yet effective method that explicitly steers the reasoning process toward visually grounded trajectories. Our result model, VAPO-Thinker-7B, significantly strengthens the model's reliance on visual information and achieves new state-of-the-art results on a wide range of established benchmarks. Project page: this https URL", 'abstract_zh': '多模态推理展现出双面性：虽然显著增强逻辑推理并促进解决复杂问题，但可能会逐渐削弱知觉基础，导致对基本视觉问题的识别失败。通过进一步分析，这一现象归因于视觉遗忘，即长时间推理导致模型越来越多地忽略视觉输入。为此，我们提出了视觉锚定策略优化（VAPO），一种简单而有效的方法，明确引导推理过程向视觉基础的轨迹靠拢。我们的结果模型VAPO-Thinker-7B显著增强了模型对视觉信息的依赖，并在多种现有基准测试中取得了新的最佳成果。项目页面：这个 [链接]。', 'title_zh': '更多的思考，更少的准确性？关于视觉语言模型中推理的双重性质'}
{'arxiv_id': 'arXiv:2509.25845', 'title': 'Training-Free Reward-Guided Image Editing via Trajectory Optimal Control', 'authors': 'Jinho Chang, Jaemin Kim, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2509.25845', 'abstract': 'Recent advancements in diffusion and flow-matching models have demonstrated remarkable capabilities in high-fidelity image synthesis. A prominent line of research involves reward-guided guidance, which steers the generation process during inference to align with specific objectives. However, leveraging this reward-guided approach to the task of image editing, which requires preserving the semantic content of the source image while enhancing a target reward, is largely unexplored. In this work, we introduce a novel framework for training-free, reward-guided image editing. We formulate the editing process as a trajectory optimal control problem where the reverse process of a diffusion model is treated as a controllable trajectory originating from the source image, and the adjoint states are iteratively updated to steer the editing process. Through extensive experiments across distinct editing tasks, we demonstrate that our approach significantly outperforms existing inversion-based training-free guidance baselines, achieving a superior balance between reward maximization and fidelity to the source image without reward hacking.', 'abstract_zh': '近期在扩散和流动匹配模型方面的进展展示了在高保真图像合成方面的非凡能力。奖励引导方法是其中一条重要研究路线，该方法在推断过程中引导生成过程以满足特定目标。然而，将这种奖励引导方法应用到需要保留源图像语义内容并增强目标奖励的图像编辑任务中，这一领域尚未充分探索。在本文中，我们提出了一种无需训练的奖励引导图像编辑新型框架。我们将编辑过程形式化为一个轨迹最优控制问题，其中扩散模型的反向过程被视为从源图像出发的可控轨迹，通过迭代更新伴随状态来引导编辑过程。通过在不同编辑任务上的广泛实验，展示了我们的方法在无需训练的前提下显著优于现有的基于反转的无需训练引导基线方法，实现了奖励最大化与对源图像保真度之间的更优越平衡，且没有出现奖励作弊现象。', 'title_zh': '基于轨迹最优控制的无训练数据奖励引导图像编辑'}
{'arxiv_id': 'arXiv:2509.25841', 'title': 'S$^2$FS: Spatially-Aware Separability-Driven Feature Selection in Fuzzy Decision Systems', 'authors': 'Suping Xu, Chuyi Dai, Ye Liu, Lin Shang, Xibei Yang, Witold Pedrycz', 'link': 'https://arxiv.org/abs/2509.25841', 'abstract': 'Feature selection is crucial for fuzzy decision systems (FDSs), as it identifies informative features and eliminates rule redundancy, thereby enhancing predictive performance and interpretability. Most existing methods either fail to directly align evaluation criteria with learning performance or rely solely on non-directional Euclidean distances to capture relationships among decision classes, which limits their ability to clarify decision boundaries. However, the spatial distribution of instances has a potential impact on the clarity of such boundaries. Motivated by this, we propose Spatially-aware Separability-driven Feature Selection (S$^2$FS), a novel framework for FDSs guided by a spatially-aware separability criterion. This criterion jointly considers within-class compactness and between-class separation by integrating scalar-distances with spatial directional information, providing a more comprehensive characterization of class structures. S$^2$FS employs a forward greedy strategy to iteratively select the most discriminative features. Extensive experiments on ten real-world datasets demonstrate that S$^2$FS consistently outperforms eight state-of-the-art feature selection algorithms in both classification accuracy and clustering performance, while feature visualizations further confirm the interpretability of the selected features.', 'abstract_zh': '面向模糊决策系统的空间感知可分性驱动特征选择（S$^2$FS）', 'title_zh': 'S$^2$FS：模糊决策系统中基于空间感知可分性驱动的特征选择'}
{'arxiv_id': 'arXiv:2509.25839', 'title': 'RAE: A Neural Network Dimensionality Reduction Method for Nearest Neighbors Preservation in Vector Search', 'authors': 'Han Zhang, Dongfang Zhao', 'link': 'https://arxiv.org/abs/2509.25839', 'abstract': "While high-dimensional embedding vectors are being increasingly employed in various tasks like Retrieval-Augmented Generation and Recommendation Systems, popular dimensionality reduction (DR) methods such as PCA and UMAP have rarely been adopted for accelerating the retrieval process due to their inability of preserving the nearest neighbor (NN) relationship among vectors. Empowered by neural networks' optimization capability and the bounding effect of Rayleigh quotient, we propose a Regularized Auto-Encoder (RAE) for k-NN preserving dimensionality reduction. RAE constrains the network parameter variation through regularization terms, adjusting singular values to control embedding magnitude changes during reduction, thus preserving k-NN relationships. We provide a rigorous mathematical analysis demonstrating that regularization establishes an upper bound on the norm distortion rate of transformed vectors, thereby offering provable guarantees for k-NN preservation. With modest training overhead, RAE achieves superior k-NN recall compared to existing DR approaches while maintaining fast retrieval efficiency.", 'abstract_zh': '高维嵌入向量在 Retrieval-Augmented Generation 和推荐系统等任务中的应用越来越广泛，尽管如此，PCA 和 UMAP 等流行降维方法由于无法保持向量的最近邻关系而鲜少被用于加速检索过程。依托神经网络的优化能力和瑞利商的边界效应，我们提出了一种正则化自编码器（RAE）来进行 k-NN 保持降维。RAE 通过正则化项约束网络参数的变动，调整奇异值以控制在降维过程中嵌入表示的尺度变化，从而保持 k-NN 关系。我们提供了严格的数学分析，证明正则化在转换向量的范数失真率上建立了上限，从而为 k-NN 保持提供了可证明的保证。在轻微的训练开销下，RAE 在保持快速检索效率的同时，实现了优于现有降维方法的 k-NN 召回率。', 'title_zh': 'RAE：一种用于向量搜索中最近邻保留的神经网络降维方法'}
{'arxiv_id': 'arXiv:2509.25837', 'title': 'Distillation of Large Language Models via Concrete Score Matching', 'authors': 'Yeongmin Kim, Donghyeok Shin, Mina Kang, Byeonghu Na, Il-Chul Moon', 'link': 'https://arxiv.org/abs/2509.25837', 'abstract': 'Large language models (LLMs) deliver remarkable performance but are costly to deploy, motivating knowledge distillation (KD) for efficient inference. Existing KD objectives typically match student and teacher probabilities via softmax, which blurs valuable logit information. While direct logit distillation (DLD) mitigates softmax smoothing, it fails to account for logit shift invariance, thereby restricting the solution space. We propose Concrete Score Distillation (CSD), a discrete score-matching objective that overcomes both softmax-induced smoothing and restrictions on the optimal solution set. We resolve the training instability and quadratic complexity of discrete score-matching in autoregressive LLMs, and the resulting CSD objective aligns relative logit differences across all vocabulary pairs between student and teacher with flexible weighting. We provide both mode-seeking and mode-covering instances within our framework and evaluate CSD on task-agnostic instruction-following and task-specific distillation using GPT-2-1.5B, OpenLLaMA-7B, and GEMMA-7B-IT. Experiments show that CSD consistently surpasses recent KD objectives, achieves favorable fidelity-diversity trade-offs, and yields complementary gains when combined with on-policy techniques, demonstrating its scalability and effectiveness for LLM distillation.', 'abstract_zh': '大型语言模型（LLMs）表现卓越但部署成本高昂，推动了高效推理的知识蒸馏（KD）技术。现有的KD目标通常通过softmax匹配学生模型和教师模型的概率，这会模糊掉有价值的操作符信息。直接操作符蒸馏（DLD）虽然缓解了softmax的平滑效应，但没有考虑到操作符偏移不变性，从而限制了解决方案空间。我们提出了一种离散评分匹配目标—混凝土评分蒸馏（CSD），它克服了由softmax引起的平滑效应和优化解空间的限制。我们解决了自回归LLMs中离散评分匹配的训练不稳定性及二次复杂性问题，而得到的CSD目标能够灵活地在学生模型和教师模型之间对所有词汇对的操作符相对差异进行对齐。我们提供了框架内的模式寻找和模式覆盖实例，并在任务无关的指令跟随和任务特定蒸馏任务中使用GPT-2-1.5B、OpenLLaMA-7B和GEMMA-7B-IT进行评估。实验表明，CSD一致优于最近的KD目标，实现了有利的保真度-多样性权衡，并且与策略更新技术结合时能产生互补收益，证明了其在LLM蒸馏中的可扩展性和有效性。', 'title_zh': '大型语言模型的混凝土评分匹配蒸馏'}
{'arxiv_id': 'arXiv:2509.25834', 'title': 'Supporting Creative Ownership through Deep Learning-Based Music Variation', 'authors': 'Stephen James Krol, Maria Teresa Llano, Jon McCormack', 'link': 'https://arxiv.org/abs/2509.25834', 'abstract': "This paper investigates the importance of personal ownership in musical AI design, examining how practising musicians can maintain creative control over the compositional process. Through a four-week ecological evaluation, we examined how a music variation tool, reliant on the skill of musicians, functioned within a composition setting. Our findings demonstrate that the dependence of the tool on the musician's ability, to provide a strong initial musical input and to turn moments into complete musical ideas, promoted ownership of both the process and artefact. Qualitative interviews further revealed the importance of this personal ownership, highlighting tensions between technological capability and artistic identity. These findings provide insight into how musical AI can support rather than replace human creativity, highlighting the importance of designing tools that preserve the humanness of musical expression.", 'abstract_zh': '个人所有权在音乐AI设计中的重要性：作曲过程中的创意控制探究', 'title_zh': '基于深度学习的音乐变体支持创意所有权'}
{'arxiv_id': 'arXiv:2509.25827', 'title': 'Overthinking Reduction with Decoupled Rewards and Curriculum Data Scheduling', 'authors': 'Shuyang Jiang, Yusheng Liao, Ya Zhang, Yanfeng Wang, Yu Wang', 'link': 'https://arxiv.org/abs/2509.25827', 'abstract': "While large reasoning models trained with critic-free reinforcement learning and verifiable rewards (RLVR) represent the state-of-the-art, their practical utility is hampered by ``overthinking'', a critical issue where models generate excessively long reasoning paths without any performance benefit. Existing solutions that penalize length often fail, inducing performance degradation due to a fundamental misalignment between trajectory-level rewards and token-level optimization. In this work, we introduce a novel framework, DECS, built on our theoretical discovery of two previously unaddressed flaws in current length rewards: (1) the erroneous penalization of essential exploratory tokens and (2) the inadvertent rewarding of partial redundancy. Our framework's innovations include (i) a first-of-its-kind decoupled token-level reward mechanism that surgically distinguishes and penalizes redundant tokens, and (ii) a novel curriculum batch scheduling strategy to master the efficiency-efficacy equilibrium. Experimental results show DECS can achieve a dramatic reduction in reasoning tokens by over 50\\% across seven benchmarks while simultaneously maintaining or even improving performance. It demonstrates conclusively that substantial gains in reasoning efficiency can be achieved without compromising a model's underlying reasoning power.", 'abstract_zh': '基于可验证奖励的无批评强化学习大型推理模型中的新颖框架DECS：解决冗余惩罚与部分冗余奖励的问题', 'title_zh': '分隔奖励与 curriculum 数据调度以减少过度思考'}
{'arxiv_id': 'arXiv:2509.25818', 'title': 'VELA: An LLM-Hybrid-as-a-Judge Approach for Evaluating Long Image Captions', 'authors': 'Kazuki Matsuda, Yuiga Wada, Shinnosuke Hirano, Seitaro Otsuki, Komei Sugiura', 'link': 'https://arxiv.org/abs/2509.25818', 'abstract': 'In this study, we focus on the automatic evaluation of long and detailed image captions generated by multimodal Large Language Models (MLLMs). Most existing automatic evaluation metrics for image captioning are primarily designed for short captions and are not suitable for evaluating long captions. Moreover, recent LLM-as-a-Judge approaches suffer from slow inference due to their reliance on autoregressive inference and early fusion of visual information. To address these limitations, we propose VELA, an automatic evaluation metric for long captions developed within a novel LLM-Hybrid-as-a-Judge framework. Furthermore, we propose LongCap-Arena, a benchmark specifically designed for evaluating metrics for long captions. This benchmark comprises 7,805 images, the corresponding human-provided long reference captions and long candidate captions, and 32,246 human judgments from three distinct perspectives: Descriptiveness, Relevance, and Fluency. We demonstrated that VELA outperformed existing metrics and achieved superhuman performance on LongCap-Arena.', 'abstract_zh': '本研究聚焦于多模态大型语言模型生成的长详尽图像描述的自动评估。现有的大多数图像描述自动评估指标主要针对短描述设计，不适合评估长描述。此外，最近的LLM-as-a-Judge方法因依赖自回归推理和视觉信息的早期融合而表现出较慢的推理速度。为解决这些局限，我们提出VELA，这是一种基于新颖LLM-混合法官框架的长描述自动评估指标。此外，我们提出了LongCap-Arena，这是一个专门用于评估长描述指标的基准，该基准包含7,805张图像，对应的由人类提供的长参考描述和长候选描述，以及从描述性、相关性和流畅性三个不同视角获取的32,246个人类评估。我们证明VELA在LongCap-Arena上优于现有指标，并实现了超人的性能。', 'title_zh': 'VELA：一种LLM-混合辅助评断方法用于评估长图像_caption_'}
{'arxiv_id': 'arXiv:2509.25810', 'title': 'Learning to Reason as Action Abstractions with Scalable Mid-Training RL', 'authors': 'Shenao Zhang, Donghan Yu, Yihao Feng, Bowen Jin, Zhaoran Wang, John Peebles, Zirui Wang', 'link': 'https://arxiv.org/abs/2509.25810', 'abstract': 'Large language models excel with reinforcement learning (RL), but fully unlocking this potential requires a mid-training stage. An effective mid-training phase should identify a compact set of useful actions and enable fast selection among them through online RL. We formalize this intuition by presenting the first theoretical result on how mid-training shapes post-training: it characterizes an action subspace that minimizes both the value approximation error from pruning and the RL error during subsequent planning. Our analysis reveals two key determinants of mid-training effectiveness: pruning efficiency, which shapes the prior of the initial RL policy, and its impact on RL convergence, which governs the extent to which that policy can be improved via online interactions. These results suggest that mid-training is most effective when the decision space is compact and the effective horizon is short, highlighting the importance of operating in the space of action abstractions rather than primitive actions. Building on these insights, we propose Reasoning as Action Abstractions (RA3), a scalable mid-training algorithm. Specifically, we derive a sequential variational lower bound and optimize it by iteratively discovering temporally-consistent latent structures via RL, followed by fine-tuning on the bootstrapped data. Experiments on code generation tasks demonstrate the effectiveness of our approach. Across multiple base models, RA3 improves the average performance on HumanEval and MBPP by 8 and 4 points over the base model and the next-token prediction baseline. Furthermore, RA3 achieves faster convergence and higher asymptotic performance in RLVR on HumanEval+, MBPP+, LiveCodeBench, and Codeforces.', 'abstract_zh': '大型语言模型在强化学习中的表现优异，但要完全挖掘其潜力需要一个中期训练阶段。有效的中期训练阶段应识别出一个有用的紧凑动作集，并通过在线强化学习快速从中进行选择。我们通过展示中期训练如何塑造后续训练的第一个理论结果，来形式化这一直觉：中期训练刻画了一个动作子空间，该子空间同时最小化剪枝带来的价值近似误差和后续规划中的RL误差。我们的分析揭示了中期训练有效性中的两个关键决定因素：剪枝效率，它塑造了初始RL策略的先验，以及其对RL收敛的影响，这决定了策略通过在线交互可以被改进的程度。这些结果表明，当决策空间紧凑且有效时间跨度较短时，中期训练最为有效，突显了在动作抽象空间中操作的重要性而非原始动作。基于这些见解，我们提出了Reasoning as Action Abstractions (RA3)，一种可扩展的中期训练算法。具体地，我们推导出一个顺序变分下界，并通过迭代发现时间一致的潜在结构来优化它，随后在种子数据上进行微调。在代码生成任务上的实验表明我们方法的有效性。在多个基础模型上，RA3分别在HumanEval和MBPP上将平均性能提高了8分和4分超过基础模型和下一个token预测基线。此外，RA3在HumanEval+、MBPP+、LiveCodeBench和Codeforces上的RLVR中实现了更快的收敛和更高的渐近性能。', 'title_zh': '基于动作抽象的可扩展中期训练RL学习推理'}
{'arxiv_id': 'arXiv:2509.25804', 'title': 'CardioForest: An Explainable Ensemble Learning Model for Automatic Wide QRS Complex Tachycardia Diagnosis from ECG', 'authors': 'Vaskar Chakma, Ju Xiaolin, Heling Cao, Xue Feng, Ji Xiaodong, Pan Haiyan, Gao Zhan', 'link': 'https://arxiv.org/abs/2509.25804', 'abstract': "This study aims to develop and evaluate an ensemble machine learning-based framework for the automatic detection of Wide QRS Complex Tachycardia (WCT) from ECG signals, emphasizing diagnostic accuracy and interpretability using Explainable AI. The proposed system integrates ensemble learning techniques, i.e., an optimized Random Forest known as CardioForest, and models like XGBoost and LightGBM. The models were trained and tested on ECG data from the publicly available MIMIC-IV dataset. The testing was carried out with the assistance of accuracy, balanced accuracy, precision, recall, F1 score, ROC-AUC, and error rate (RMSE, MAE) measures. In addition, SHAP (SHapley Additive exPlanations) was used to ascertain model explainability and clinical relevance. The CardioForest model performed best on all metrics, achieving a test accuracy of 94.95%, a balanced accuracy of 88.31%, and high precision and recall metrics. SHAP analysis confirmed the model's ability to rank the most relevant ECG features, such as QRS duration, in accordance with clinical intuitions, thereby fostering trust and usability in clinical practice. The findings recognize CardioForest as an extremely dependable and interpretable WCT detection model. Being able to offer accurate predictions and transparency through explainability makes it a valuable tool to help cardiologists make timely and well-informed diagnoses, especially for high-stakes and emergency scenarios.", 'abstract_zh': '基于集成机器学习的Wide QRS Complex Tachycardia自动检测框架发展与评估：结合可解释人工智能强调诊断准确性和可解释性', 'title_zh': 'CardioForest: 一种可解释的集成学习模型，用于从ECG自动诊断宽QRS综合征心动过速'}
{'arxiv_id': 'arXiv:2509.25803', 'title': 'Better with Less: Small Proprietary Models Surpass Large Language Models in Financial Transaction Understanding', 'authors': 'Wanying Ding, Savinay Narendra, Xiran Shi, Adwait Ratnaparkhi, Chengrui Yang, Nikoo Sabzevar, Ziyan Yin', 'link': 'https://arxiv.org/abs/2509.25803', 'abstract': "Analyzing financial transactions is crucial for ensuring regulatory compliance, detecting fraud, and supporting decisions. The complexity of financial transaction data necessitates advanced techniques to extract meaningful insights and ensure accurate analysis. Since Transformer-based models have shown outstanding performance across multiple domains, this paper seeks to explore their potential in understanding financial transactions. This paper conducts extensive experiments to evaluate three types of Transformer models: Encoder-Only, Decoder-Only, and Encoder-Decoder models. For each type, we explore three options: pretrained LLMs, fine-tuned LLMs, and small proprietary models developed from scratch. Our analysis reveals that while LLMs, such as LLaMA3-8b, Flan-T5, and SBERT, demonstrate impressive capabilities in various natural language processing tasks, they do not significantly outperform small proprietary models in the specific context of financial transaction understanding. This phenomenon is particularly evident in terms of speed and cost efficiency. Proprietary models, tailored to the unique requirements of transaction data, exhibit faster processing times and lower operational costs, making them more suitable for real-time applications in the financial sector. Our findings highlight the importance of model selection based on domain-specific needs and underscore the potential advantages of customized proprietary models over general-purpose LLMs in specialized applications. Ultimately, we chose to implement a proprietary decoder-only model to handle the complex transactions that we previously couldn't manage. This model can help us to improve 14% transaction coverage, and save more than \\$13 million annual cost.", 'abstract_zh': '分析财务交易对于确保合规性、检测欺诈和支持决策至关重要。由于财务交易数据的复杂性，需要采用先进的技术来提取有意义的见解并确保准确的分析。鉴于基于Transformer的模型在多个领域表现出色，本文旨在探索其在理解财务交易中的潜在应用。本文进行了广泛的实验，评估了三种类型的Transformer模型：Encoder-Only、Decoder-Only和Encoder-Decoder模型。对于每种类型，我们探讨了三种选项：预训练的大型语言模型、微调的大型语言模型以及从零开始开发的小型专属模型。分析显示，尽管预训练的大型语言模型，如LLaMA3-8b、Flan-T5和SBERT，在各种自然语言处理任务中表现出色，但在财务交易理解的具体背景下，它们并未显著优于小型专属模型。这一现象在速度和成本效率方面尤为明显。针对交易数据的独有要求定制的专属模型，表现出更快的处理时间和更低的操作成本，使其更适合金融领域的实时应用。我们的研究结果强调了根据领域特定需求选择模型的重要性，并突显了在专业化应用中，定制的专属模型相较于通用预训练模型的优势。最终，我们选择实现一个专属的Decoder-Only模型来处理我们之前无法管理的复杂交易。该模型帮助我们提高了14%的交易覆盖率，并节省了超过1300万美元的年度成本。', 'title_zh': '更少更好：专用小型模型在金融交易理解中超越大型语言模型'}
{'arxiv_id': 'arXiv:2509.25794', 'title': 'Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding', 'authors': 'Haotian Xue, Yunhao Ge, Yu Zeng, Zhaoshuo Li, Ming-Yu Liu, Yongxin Chen, Jiaojiao Fan', 'link': 'https://arxiv.org/abs/2509.25794', 'abstract': 'Vision-Language Models (VLMs) have demonstrated impressive world knowledge across a wide range of tasks, making them promising candidates for embodied reasoning applications. However, existing benchmarks primarily evaluate the embodied reasoning ability of VLMs through multiple-choice questions based on image annotations -- for example, selecting which trajectory better describes an event in the image. In this work, we introduce the Point-It-Out (PIO) benchmark, a novel benchmark designed to systematically assess the embodied reasoning abilities of VLMs through precise visual grounding. We propose a hierarchical evaluation protocol spanning three stages (S1: referred-object localization, S2: task-driven pointing, and S3: visual trace prediction), with data collected from critical domains for embodied intelligence, including indoor, kitchen, driving, and robotic manipulation scenarios. Extensive experiments with over ten state-of-the-art VLMs reveal several interesting findings. For example, strong general-purpose models such as GPT-4o, while excelling on many benchmarks (e.g., language, perception, and reasoning), underperform compared to some open-source models in precise visual grounding; models such as MoLMO perform well in S1 and S2 but struggle in S3, where requires grounding combined with visual trace planning.', 'abstract_zh': 'Vision-Language模型（VLMs）在广泛的任务中展现了令人印象深刻的 worldly 知识，使它们成为体现推理应用的有希望的候选者。然而，现有的基准主要通过基于图像标注的多选题来评估VLMs的体现推理能力——例如，选择哪个轨迹更能描述图像中的事件。在本文中，我们引入了指向它（Point-It-Out，PIO）基准，这是一个新颖的基准，旨在通过精确的视觉定位系统性评估VLMs的体现推理能力。我们提出了一个分层评估协议，包含三个阶段（S1：referenced对象定位，S2：任务驱动的指针指向，S3：视觉轨迹预测），数据来自体现智能的关键领域，包括室内、厨房、驾驶和机器人操作场景。通过多个最先进的VLMs进行的大量实验揭示了几项有趣的发现。例如，强大的通用模型如GPT-4o，在许多基准（如语言、感知和推理）上表现出色，但在精确的视觉定位上却不如一些开源模型；模型如MoLMO在S1和S2阶段表现良好，但在S3阶段却遇到困难，这需要结合视觉定位和轨迹规划。', 'title_zh': 'Point-It-Out: 多阶段视觉定位中视觉语言模型感知推理基准测试'}
{'arxiv_id': 'arXiv:2509.25776', 'title': 'Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation', 'authors': 'Mingyu Kang, Yong Suk Choi', 'link': 'https://arxiv.org/abs/2509.25776', 'abstract': 'Text-to-image diffusion models have achieved remarkable success in generating high-quality and diverse images. Building on these advancements, diffusion models have also demonstrated exceptional performance in text-guided image editing. A key strategy for effective image editing involves inverting the source image into editable noise maps associated with the target image. However, previous inversion methods face challenges in adhering closely to the target text prompt. The limitation arises because inverted noise maps, while enabling faithful reconstruction of the source image, restrict the flexibility needed for desired edits. To overcome this issue, we propose Editable Noise Map Inversion (ENM Inversion), a novel inversion technique that searches for optimal noise maps to ensure both content preservation and editability. We analyze the properties of noise maps for enhanced editability. Based on this analysis, our method introduces an editable noise refinement that aligns with the desired edits by minimizing the difference between the reconstructed and edited noise maps. Extensive experiments demonstrate that ENM Inversion outperforms existing approaches across a wide range of image editing tasks in both preservation and edit fidelity with target prompts. Our approach can also be easily applied to video editing, enabling temporal consistency and content manipulation across frames.', 'abstract_zh': '基于文本的图像扩散模型已在生成高质量和多样化图像方面取得了显著成功。在此基础上，扩散模型也在文本引导的图像编辑方面展现了卓越性能。有效的图像编辑的关键策略是将源图像反转为与目标图像相关的可编辑噪声图。然而，之前的反转方法在遵循目标文本提示方面面临挑战。这是因为反转的噪声图虽然能够忠实重建源图像，但限制了实现所需编辑所需的灵活性。为了解决这一问题，我们提出了一种新的反转技术——可编辑噪声图反转（ENM Inversion），该技术寻找最优噪声图以同时确保内容保留和编辑性。我们分析了噪声图的属性以提高编辑性。基于这一分析，我们的方法引入了一种可编辑噪声精炼，通过最小化重建噪声图和编辑噪声图之间的差异来与所需的编辑对齐。广泛实验表明，ENM Inversion在保留和编辑忠实度方面均优于现有方法，特别是在具有目标提示的各种图像编辑任务中。此外，我们的方法也可以轻松应用于视频编辑，实现帧间的时间一致性及内容操控。', 'title_zh': '基于目标图像编码的可编辑噪声图反转：高保真图像操纵'}
{'arxiv_id': 'arXiv:2509.25775', 'title': 'Autonomy-Aware Clustering: When Local Decisions Supersede Global Prescriptions', 'authors': 'Amber Srivastava, Salar Basiri, Srinivasa Salapaka', 'link': 'https://arxiv.org/abs/2509.25775', 'abstract': 'Clustering arises in a wide range of problem formulations, yet most existing approaches assume that the entities under clustering are passive and strictly conform to their assigned groups. In reality, entities often exhibit local autonomy, overriding prescribed associations in ways not fully captured by feature representations. Such autonomy can substantially reshape clustering outcomes -- altering cluster compositions, geometry, and cardinality -- with significant downstream effects on inference and decision-making. We introduce autonomy-aware clustering, a reinforcement (RL) learning framework that learns and accounts for the influence of local autonomy without requiring prior knowledge of its form. Our approach integrates RL with a deterministic annealing (DA) procedure, where, to determine underlying clusters, DA naturally promotes exploration in early stages of annealing and transitions to exploitation later. We also show that the annealing procedure exhibits phase transitions that enable design of efficient annealing schedules. To further enhance adaptability, we propose the Adaptive Distance Estimation Network (ADEN), a transformer-based attention model that learns dependencies between entities and cluster representatives within the RL loop, accommodates variable-sized inputs and outputs, and enables knowledge transfer across diverse problem instances. Empirical results show that our framework closely aligns with underlying data dynamics: even without explicit autonomy models, it achieves solutions close to the ground truth (gap ~3-4%), whereas ignoring autonomy leads to substantially larger gaps (~35-40%). The code and data are publicly available at this https URL.', 'abstract_zh': '自治感知聚类', 'title_zh': '自主性导向聚类：当局部决策超越全局规定'}
{'arxiv_id': 'arXiv:2509.25773', 'title': 'V-HUB: A Visual-Centric Humor Understanding Benchmark for Video LLMs', 'authors': 'Zhengpeng Shi, Hengli Li, Yanpeng Zhao, Jianqun Zhou, Yuxuan Wang, Qinrong Cui, Wei Bi, Songchun Zhu, Bo Zhao, Zilong Zheng', 'link': 'https://arxiv.org/abs/2509.25773', 'abstract': 'AI models capable of comprehending humor hold real-world promise -- for example, enhancing engagement in human-machine interactions. To gauge and diagnose the capacity of multimodal large language models (MLLMs) for humor understanding, we introduce v-HUB, a novel visual-centric video humor understanding benchmark. v-HUB comprises a curated collection of minimally verbal short videos, sourced from classic silent films and online resources, and reflecting real-world scenarios where humor can be appreciated purely through visual cues. Each video clip is paired with rich annotations, including captions, descriptions, and explanations, supporting evaluation tasks like caption matching and humor explanation. To broaden its applicability, we further construct an open-ended video QA task, making it readily integrable into existing video understanding benchmarks. We evaluate a diverse set of MLLMs, from specialized Video-LLMs to versatile OmniLLMs that can process audio, covering both open-source and proprietary domains. The experimental results expose the difficulties MLLMs face in comprehending humor from visual cues alone. For example, all models exhibit a marked performance drop on caption matching when moving from text-based to video-based evaluation (without audio). Our findings also demonstrate that incorporating audio helps with video humor understanding, highlighting the informativeness of sound and the promise of integrating richer modalities for complex video understanding tasks.', 'abstract_zh': '具备理解幽默能力的AI模型在实际应用中具有真实潜力——例如，提升人机互动中的参与度。为了评估和诊断多模态大规模语言模型（MLLMs）在幽默理解方面的能力，我们引入了v-HUB，一个以视觉为中心的视频幽默理解基准。v-HUB包含一系列来自经典无声电影和在线资源的少量文字简短视频，反映的是通过视觉线索即可欣赏幽默的真实世界场景。每个视频片段都配有丰富的注释，包括字幕、描述和解释，支持字幕匹配和幽默解释等评估任务。为了提高其通用性，我们进一步构建了一个开放式的视频问答任务，使其能够无缝集成到现有的视频理解基准中。我们评估了一组多样的MLLMs，从专门处理视频的Video-LLMs到能够处理音频的全能型OmniLLMs，涵盖了开源和专有领域。实验结果揭示了MLLMs仅凭视觉线索理解幽默所面临的困难。例如，所有模型在从基于文本的评估转向基于视频的评估（不包含音频）时，在字幕匹配任务中表现显著下降。我们的研究还表明，引入音频有助于视频幽默的理解，突显了声音信息的价值以及集成更丰富模态的潜力，以应对复杂的视频理解任务。', 'title_zh': 'V-HUB: 以视觉为中心的视频幽默理解基准数据集'}
{'arxiv_id': 'arXiv:2509.25771', 'title': 'Free Lunch Alignment of Text-to-Image Diffusion Models without Preference Image Pairs', 'authors': 'Jia Jun Cheng Xian, Muchen Li, Haotian Yang, Xin Tao, Pengfei Wan, Leonid Sigal, Renjie Liao', 'link': 'https://arxiv.org/abs/2509.25771', 'abstract': 'Recent advances in diffusion-based text-to-image (T2I) models have led to remarkable success in generating high-quality images from textual prompts. However, ensuring accurate alignment between the text and the generated image remains a significant challenge for state-of-the-art diffusion models. To address this, existing studies employ reinforcement learning with human feedback (RLHF) to align T2I outputs with human preferences. These methods, however, either rely directly on paired image preference data or require a learned reward function, both of which depend heavily on costly, high-quality human annotations and thus face scalability limitations. In this work, we introduce Text Preference Optimization (TPO), a framework that enables "free-lunch" alignment of T2I models, achieving alignment without the need for paired image preference data. TPO works by training the model to prefer matched prompts over mismatched prompts, which are constructed by perturbing original captions using a large language model. Our framework is general and compatible with existing preference-based algorithms. We extend both DPO and KTO to our setting, resulting in TDPO and TKTO. Quantitative and qualitative evaluations across multiple benchmarks show that our methods consistently outperform their original counterparts, delivering better human preference scores and improved text-to-image alignment. Our Open-source code is available at this https URL.', 'abstract_zh': 'Recent advances in diffusion-based text-to-image (T2I) models have led to remarkable success in generating high-quality images from textual prompts. However, ensuring accurate alignment between the text and the generated image remains a significant challenge for state-of-the-art diffusion models. To address this, existing studies employ reinforcement learning with human feedback (RLHF) to align T2I outputs with human preferences. These methods, however, either rely directly on paired image preference data or require a learned reward function, both of which depend heavily on costly, high-quality human annotations and thus face scalability limitations. In this work, we introduce Text Preference Optimization (TPO), a framework that enables "free-lunch" alignment of T2I models, achieving alignment without the need for paired image preference data. TPO works by training the model to prefer matched prompts over mismatched prompts, which are constructed by perturbing original captions using a large language model. Our framework is general and compatible with existing preference-based algorithms. We extend both DPO and KTO to our setting, resulting in TDPO and TKTO. Quantitative and qualitative evaluations across multiple benchmarks show that our methods consistently outperform their original counterparts, delivering better human preference scores and improved text-to-image alignment. Our Open-source code is available at this <https://> URL.', 'title_zh': '无需偏好图像配对的文本到图像扩散模型自洽对齐'}
{'arxiv_id': 'arXiv:2509.25760', 'title': 'TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning', 'authors': 'Zhepei Wei, Xiao Yang, Kai Sun, Jiaqi Wang, Rulin Shao, Sean Chen, Mohammad Kachuee, Teja Gollapudi, Tony Liao, Nicolas Scheffer, Rakesh Wanga, Anuj Kumar, Yu Meng, Wen-tau Yih, Xin Luna Dong', 'link': 'https://arxiv.org/abs/2509.25760', 'abstract': 'While large language models (LLMs) have demonstrated strong performance on factoid question answering, they are still prone to hallucination and untruthful responses, particularly when tasks demand information outside their parametric knowledge. Indeed, truthfulness requires more than accuracy -- models must also recognize uncertainty and abstain when unsure to avoid hallucinations. This presents a fundamental challenge for existing methods: approaches that optimize for accuracy often amplify hallucinations, while those that encourage abstention can become overly conservative, sacrificing correct answers. Both extremes ultimately compromise truthfulness. In this work, we present TruthRL, a general reinforcement learning (RL) framework that directly optimizes the truthfulness of LLMs. Specifically, we implement TruthRL using GRPO with a simple yet effective ternary reward that distinguishes correct answers, hallucinations, and abstentions. It incentivizes models to reduce hallucinations not only by providing correct responses, but also by enabling abstention when uncertain, thereby improving truthfulness. Extensive experiments across four knowledge-intensive benchmarks show that, compared to vanilla RL, TruthRL significantly reduces hallucinations by 28.9% and improves truthfulness by 21.1%, with consistent gains across various backbone models (e.g., Qwen, Llama) under both retrieval and non-retrieval setups. In-depth ablation study demonstrates that vanilla accuracy-driven methods, such as supervised fine-tuning or RL with a binary reward, struggle to balance factual correctness and uncertainty. In contrast, our proposed truthfulness-driven TruthRL achieves strong performance in both accuracy and truthfulness, underscoring the importance of learning objective design for developing truthful LLMs.', 'abstract_zh': '一种直接优化大型语言模型真相性的强化学习框架：TruthRL', 'title_zh': 'TruthRL：通过强化学习激励 truthful 的LLM'}
{'arxiv_id': 'arXiv:2509.25748', 'title': 'Dolphin v1.0 Technical Report', 'authors': 'Taohan Weng, Chi zhang, Chaoran Yan, Siya Liu, Xiaoyang Liu, Yalun Wu, Boyang Wang, Boyan Wang, Jiren Ren, Kaiwen Yan, Jinze Yu, Kaibing Hu, Henan Liu, Haoyun zheng, Anjie Le, Hongcheng Guo', 'link': 'https://arxiv.org/abs/2509.25748', 'abstract': "Ultrasound is crucial in modern medicine but faces challenges like operator dependence, image noise, and real-time scanning, hindering AI integration. While large multimodal models excel in other medical imaging areas, they struggle with ultrasound's complexities. To address this, we introduce Dolphin v1.0 (V1) and its reasoning-augmented version, Dolphin R1-the first large-scale multimodal ultrasound foundation models unifying diverse clinical tasks in a single vision-language this http URL tackle ultrasound variability and noise, we curated a 2-million-scale multimodal dataset, combining textbook knowledge, public data, synthetic samples, and general corpora. This ensures robust perception, generalization, and clinical this http URL Dolphin series employs a three-stage training strategy: domain-specialized pretraining, instruction-driven alignment, and reinforcement-based refinement. Dolphin v1.0 delivers reliable performance in classification, detection, regression, and report generation. Dolphin R1 enhances diagnostic inference, reasoning transparency, and interpretability through reinforcement learning with ultrasound-specific this http URL on U2-Bench across eight ultrasound tasks, Dolphin R1 achieves a U2-score of 0.5835-over twice the second-best model (0.2968) setting a new state of the art. Dolphin v1.0 also performs competitively, validating the unified framework. Comparisons show reasoning-enhanced training significantly improves diagnostic accuracy, consistency, and interpretability, highlighting its importance for high-stakes medical AI.", 'abstract_zh': '超声在现代医学中至关重要，但面临着操作者依赖、图像噪声和实时扫描等挑战，阻碍了人工智能的集成。虽然大型多模态模型在其他医学影像领域表现出色，但在处理超声的复杂性方面却力不从心。为了解决这一问题，我们介绍了Dolphin v1.0（V1）及其增强推理版本Dolphin R1——首个统一多种临床任务的大规模多模态超声基础模型。为应对超声变异性和噪声，我们构建了一个规模达200万的多模态数据集，整合了教科书知识、公共数据、合成样本和通用语料。这一数据集确保了模型的稳健感知、泛化能力和临床应用能力。Dolphin系列采用三阶段训练策略：领域特异化的预训练、指令驱动的对齐以及基于强化学习的精炼。Dolphin v1.0在分类、检测、回归和报告生成中提供可靠的性能。Dolphin R1通过针对超声的具体强化学习增强诊断推断、推理透明性和可解释性。在U2-Bench上进行的八项超声任务测试中，Dolphin R1实现了0.5835的U2分数，超过了第二名模型（0.2968）的两倍，创下了新的性能纪录。Dolphin v1.0也表现出色，验证了统一框架的有效性。比较结果显示，增强推理的训练显著提高了诊断准确度、一致性和可解释性，突显了其在高风险医疗AI中的重要性。', 'title_zh': 'Dolphin v1.0 技术报告'}
{'arxiv_id': 'arXiv:2509.25736', 'title': 'Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications', 'authors': 'Chenhua Shi, Gregor Macdonald, Bhavika Jalli, Wanlu Lei, John Zou, Mridul Jain, Joji Philip', 'link': 'https://arxiv.org/abs/2509.25736', 'abstract': 'The success of large language models (LLMs) depends heavily on large-scale, high-quality instruction-following and reinforcement datasets. However, generating such data through human annotation is prohibitively time-consuming particularly for domain-specific tasks like telecom network troubleshooting, where accurate responses require deep technical expertise and contextual understanding. In this paper, we present a fully automated, retrieval-augmented pipeline for generating synthetic question-answer (QA) pairs grounded in structured domain knowledge. Our multi-stage framework integrates a retriever, base generator, and refinement model to synthesize and enhance QA pairs using documents retrieved from a domain-specific knowledge graph. To ensure data quality, we employ customized RAGAS-based scoring to filter low-quality samples, producing a high-quality dataset suitable for reinforcement fine-tuning (RFT). We demonstrate our approach in a real-world telecom scenario focused on radio access network (RAN) troubleshooting. The resulting pipeline generates complex, context-rich troubleshooting solution plans without human intervention. This work offers a scalable solution for building instruction and reinforcement datasets in specialized domains, significantly reducing dependence on manual labeling while maintaining high technical fidelity.', 'abstract_zh': '大型语言模型的成功高度依赖于大规模、高质量的指令跟随和强化数据集。然而，通过人工注释生成此类数据在特定领域任务（如电信网络故障排除）中尤其耗时，准确的响应需要深厚的技术专长和背景理解。本文提出了一种完全自动化的检索增强管道，用于生成基于结构化领域知识的合成问答（QA）对。我们的多阶段框架结合了检索器、基础生成器和改进模型，使用从领域特定知识图谱检索到的文档合成和增强QA对。为确保数据质量，我们采用定制化的RAGAS评分来过滤低质量样本，生成适合强化微调（RFT）的高质量数据集。我们在一个实际的电信场景中展示了该方法，该场景关注于无线接入网络（RAN）故障排除。所提出的管道在无需人工干预的情况下生成了复杂且内容丰富的故障排除解决方案计划。本文提供了一种在专门领域构建指令和强化数据集的可扩展解决方案，显著减少了对人工标注的依赖性，同时保持了高技术水平。', 'title_zh': '少思考，更准确打标：面向电信领域的多阶段领域引导合成数据生成以微调大规模语言模型'}
{'arxiv_id': 'arXiv:2509.25729', 'title': 'Controlled Generation for Private Synthetic Text', 'authors': 'Zihao Zhao, Anjalie Field', 'link': 'https://arxiv.org/abs/2509.25729', 'abstract': 'Text anonymization is essential for responsibly developing and deploying AI in high-stakes domains such as healthcare, social services, and law. In this work, we propose a novel methodology for privacy-preserving synthetic text generation that leverages the principles of de-identification and the Hiding In Plain Sight (HIPS) theory. Our approach introduces entity-aware control codes to guide controllable generation using either in-context learning (ICL) or prefix tuning. The ICL variant ensures privacy levels consistent with the underlying de-identification system, while the prefix tuning variant incorporates a custom masking strategy and loss function to support scalable, high-quality generation. Experiments on legal and clinical datasets demonstrate that our method achieves a strong balance between privacy protection and utility, offering a practical and effective solution for synthetic text generation in sensitive domains.', 'abstract_zh': '隐私保护的合成文本生成方法：基于去标识化和Hiding In Plain Sight理论的新范式', 'title_zh': '控制生成的私有合成文本'}
{'arxiv_id': 'arXiv:2509.25727', 'title': 'Boundary-to-Region Supervision for Offline Safe Reinforcement Learning', 'authors': 'Huikang Su, Dengyun Peng, Zifeng Zhuang, YuHan Liu, Qiguang Chen, Donglin Wang, Qinghe Liu', 'link': 'https://arxiv.org/abs/2509.25727', 'abstract': 'Offline safe reinforcement learning aims to learn policies that satisfy predefined safety constraints from static datasets. Existing sequence-model-based methods condition action generation on symmetric input tokens for return-to-go and cost-to-go, neglecting their intrinsic asymmetry: return-to-go (RTG) serves as a flexible performance target, while cost-to-go (CTG) should represent a rigid safety boundary. This symmetric conditioning leads to unreliable constraint satisfaction, especially when encountering out-of-distribution cost trajectories. To address this, we propose Boundary-to-Region (B2R), a framework that enables asymmetric conditioning through cost signal realignment . B2R redefines CTG as a boundary constraint under a fixed safety budget, unifying the cost distribution of all feasible trajectories while preserving reward structures. Combined with rotary positional embeddings , it enhances exploration within the safe region. Experimental results show that B2R satisfies safety constraints in 35 out of 38 safety-critical tasks while achieving superior reward performance over baseline methods. This work highlights the limitations of symmetric token conditioning and establishes a new theoretical and practical approach for applying sequence models to safe RL. Our code is available at this https URL.', 'abstract_zh': 'Offline Safe Reinforcement Learning via Asymmetric Conditioning with Boundary-to-Region Framework', 'title_zh': '离线安全强化学习中的边界到区域监督'}
{'arxiv_id': 'arXiv:2509.25724', 'title': 'Towards A Universally Transferable Acceleration Method for Density Functional Theory', 'authors': 'Zhe Liu, Yuyan Ni, Zhichen Pu, Qiming Sun, Siyuan Liu, Wen Yan', 'link': 'https://arxiv.org/abs/2509.25724', 'abstract': 'Recently, sophisticated deep learning-based approaches have been developed for generating efficient initial guesses to accelerate the convergence of density functional theory (DFT) calculations. While the actual initial guesses are often density matrices (DM), quantities that can convert into density matrices also qualify as alternative forms of initial guesses. Hence, existing works mostly rely on the prediction of the Hamiltonian matrix for obtaining high-quality initial guesses. However, the Hamiltonian matrix is both numerically difficult to predict and intrinsically non-transferable, hindering the application of such models in real scenarios. In light of this, we propose a method that constructs DFT initial guesses by predicting the electron density in a compact auxiliary basis representation using E(3)-equivariant neural networks. Trained on small molecules with up to 20 atoms, our model is able to achieve an average 33.3% self-consistent field (SCF) step reduction on systems up to 60 atoms, substantially outperforming Hamiltonian-centric and DM-centric models. Critically, this acceleration remains nearly constant with increasing system sizes and exhibits strong transferring behaviors across orbital basis sets and exchange-correlation (XC) functionals. To the best of our knowledge, this work represents the first and robust candidate for a universally transferable DFT acceleration method. We are also releasing the SCFbench dataset and its accompanying code to facilitate future research in this promising direction.', 'abstract_zh': '最近，基于深度学习的先进方法被开发出来，用于生成高效初始猜测以加速密度泛函理论（DFT）计算的收敛。虽然实际的初始猜测往往是密度矩阵（DM），但能够转换为密度矩阵的量也可以作为初始猜测的替代形式。因此，现有工作主要依赖于预测哈密顿矩阵来获得高质量的初始猜测。然而，哈密顿矩阵既难以预测，又本质上不可移植，阻碍了此类模型的实际应用。为了解决这一问题，我们提出了一种方法，通过使用E(3)-等变神经网络预测紧凑辅助基表示中的电子密度来构建DFT初始猜测。在最多含有20个原子的小分子上训练，我们的模型能够实现多达60个原子系统的平均33.3%自洽场（SCF）步数减少，显著优于以哈密顿矩阵为中心和以密度矩阵为中心的模型。尤其重要的是，这种加速在系统增大时几乎保持不变，并且在不同轨道基组和交换相关（XC）泛函之间表现出强大的可移植性。据我们所知，这项工作代表了首个且稳健的普遍可移植的DFT加速方法。我们还发布了SCFbench数据集及其配套代码，以促进该有前途方向的未来研究。', 'title_zh': '面向密度泛函理论的通用加速方法探索'}
{'arxiv_id': 'arXiv:2509.25721', 'title': 'The AI Productivity Index (APEX)', 'authors': 'Bertie Vidgen, Abby Fennelly, Evan Pinnix, Chirag Mahapatra, Zach Richards, Austin Bridges, Calix Huang, Ben Hunsberger, Fez Zafar, Brendan Foody, Dominic Barton, Cass R. Sunstein, Eric Topol, Osvald Nitski', 'link': 'https://arxiv.org/abs/2509.25721', 'abstract': "We introduce the first version of the AI Productivity Index (APEX), a benchmark for assessing whether frontier AI models can perform knowledge work with high economic value. APEX addresses one of the largest inefficiencies in AI research: outside of coding, benchmarks often fail to test economically relevant capabilities. APEX-v1.0 contains 200 test cases and covers four domains: investment banking, management consulting, law, and primary medical care. It was built in three steps. First, we sourced experts with top-tier experience e.g., investment bankers from Goldman Sachs. Second, experts created prompts that reflect high-value tasks in their day-to-day work. Third, experts created rubrics for evaluating model responses. We evaluate 23 frontier models on APEX-v1.0 using an LM judge. GPT 5 (Thinking = High) achieves the highest mean score (64.2%), followed by Grok 4 (61.3%) and Gemini 2.5 Flash (Thinking = On) (60.4%). Qwen 3 235B is the best performing open-source model and seventh best overall. There is a large gap between the performance of even the best models and human experts, highlighting the need for better measurement of models' ability to produce economically valuable work.", 'abstract_zh': 'AI生产力指数（APEX）初探：一个评估前沿AI模型在高经济价值知识工作表现的基准', 'title_zh': 'AI生产力指数（APEX）'}
{'arxiv_id': 'arXiv:2509.25716', 'title': 'DeepCodeSeek: Real-Time API Retrieval for Context-Aware Code Generation', 'authors': 'Esakkivel Esakkiraja, Denis Akhiyarov, Aditya Shanmugham, Chitra Ganapathy', 'link': 'https://arxiv.org/abs/2509.25716', 'abstract': 'Current search techniques are limited to standard RAG query-document applications. In this paper, we propose a novel technique to expand the code and index for predicting the required APIs, directly enabling high-quality, end-to-end code generation for auto-completion and agentic AI applications. We address the problem of API leaks in current code-to-code benchmark datasets by introducing a new dataset built from real-world ServiceNow Script Includes that capture the challenge of unclear API usage intent in the code. Our evaluation metrics show that this method achieves 87.86% top-40 retrieval accuracy, allowing the critical context with APIs needed for successful downstream code generation. To enable real-time predictions, we develop a comprehensive post-training pipeline that optimizes a compact 0.6B reranker through synthetic dataset generation, supervised fine-tuning, and reinforcement learning. This approach enables our compact reranker to outperform a much larger 8B model while maintaining 2.5x reduced latency, effectively addressing the nuances of enterprise-specific code without the computational overhead of larger models.', 'abstract_zh': '当前的搜索技术仅限于标准的RAG查询-文档应用。本文提出了一种新颖的方法，扩展代码和索引以预测所需的API，直接实现高质量的端到端代码生成，适用于自动补全和代理AI应用。通过引入一个新数据集，该数据集基于实际的ServiceNow Script Includes构建，并捕捉代码中模糊的API使用意图问题，解决了当前代码到代码基准数据集中的API泄漏问题。我们的评估指标表明，该方法实现了87.86%的前40位检索准确性，允许包含成功生成下游代码所需的关键上下文与API。为了实现实时预测，我们开发了一种全面的后训练管道，通过合成数据集生成、监督微调和强化学习优化了一个紧凑的0.6B重排序器。此方法使我们的紧凑重排序器能够在保持2.5倍减少的延迟的同时，超越更大规模的8B模型，有效解决了企业特定代码的细微差别，而无需使用大规模模型的计算开销。', 'title_zh': 'DeepCodeSeek: 基于上下文的实时API检索'}
{'arxiv_id': 'arXiv:2509.25694', 'title': 'HNote: Extending YNote with Hexadecimal Encoding for Fine-Tuning LLMs in Music Modeling', 'authors': 'Hung-Ying Chu, Shao-Yu Wei, Guan-Wei Chen, Tzu-Wei Hung, ChengYang Tsai, Yu-Cheng Lin', 'link': 'https://arxiv.org/abs/2509.25694', 'abstract': 'Recent advances in large language models (LLMs) have created new opportunities for symbolic music generation. However, existing formats such as MIDI, ABC, and MusicXML are either overly complex or structurally inconsistent, limiting their suitability for token-based learning architectures. To address these challenges, we propose HNote, a novel hexadecimal-based notation system extended from YNote, which encodes both pitch and duration within a fixed 32-unit measure framework. This design ensures alignment, reduces ambiguity, and is directly compatible with LLM architectures. We converted 12,300 Jiangnan-style songs generated from traditional folk pieces from YNote into HNote, and fine-tuned LLaMA-3.1(8B) using parameter-efficient LoRA. Experimental results show that HNote achieves a syntactic correctness rate of 82.5%, and BLEU and ROUGE evaluations demonstrate strong symbolic and structural similarity, producing stylistically coherent compositions. This study establishes HNote as an effective framework for integrating LLMs with cultural music modeling.', 'abstract_zh': 'Recent Advances in Large Language Models for Symbolic Music Generation: Introducing HNote, a Hexadecimal-Based Notation System', 'title_zh': 'HNote: 结合十六进制编码扩展YNote，以在音乐建模中微调LLMs'}
{'arxiv_id': 'arXiv:2509.25692', 'title': 'Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction', 'authors': 'Tingyu Shi, Fan Lyu, Shaoliang Peng', 'link': 'https://arxiv.org/abs/2509.25692', 'abstract': 'Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at this https URL.', 'abstract_zh': 'Conformal Prediction Active Test-Time Adaptation (CPATTA)', 'title_zh': '带有模范预测的注释高效活跃测试时自适应'}
{'arxiv_id': 'arXiv:2509.25684', 'title': 'LD-MoLE: Learnable Dynamic Routing for Mixture of LoRA Experts', 'authors': 'Yuan Zhuang, Yi Shen, Yuexin Bian, Qing Su, Shihao Ji, Yuanyuan Shi, Fei Miao', 'link': 'https://arxiv.org/abs/2509.25684', 'abstract': 'Recent studies have shown that combining parameter-efficient fine-tuning (PEFT) with mixture-of-experts (MoE) is an effective strategy for adapting large language models (LLMs) to the downstream tasks. However, most existing approaches rely on conventional TopK routing, which requires careful hyperparameter tuning and assigns a fixed number of experts to each token. In this work, we propose LD-MoLE, a Learnable Dynamic routing mechanism for Mixture of LoRA Experts that enables adaptive, token-dependent, and layer-wise expert allocation. Our method replaces the non-differentiable TopK selection with a differentiable routing function and a closed-form solution. Moreover, our design allows the model to adaptively determine the number of experts to activate for each token at different layers. In addition, we introduce an analytical sparsity control objective to regularize the number of activated experts. Extensive experiments on the Qwen3-1.7B and Llama-3.2-3B models show that LD-MoLE achieves the highest average scores compared to state-of-the-art baselines, across a diverse set of benchmarks. Our method not only achieves superior performance, but also demonstrates the ability to learn token-dependent and layer-wise expert allocation.', 'abstract_zh': 'Recent studies have shown that combining parameter-efficient fine-tuning (PEFT) with mixture-of-experts (MoE) is an effective strategy for adapting large language models (LLMs) to downstream tasks. However, most existing approaches rely on conventional TopK routing, which requires careful hyperparameter tuning and assigns a fixed number of experts to each token. In this work, we propose LD-MoLE, a Learnable Dynamic routing mechanism for Mixture of LoRA Experts that enables adaptive, token-dependent, and layer-wise expert allocation. Our method replaces the non-differentiable TopK selection with a differentiable routing function and a closed-form solution. Moreover, our design allows the model to adaptively determine the number of experts to activate for each token at different layers. In addition, we introduce an analytical sparsity control objective to regularize the number of activated experts. Extensive experiments on the Qwen3-1.7B and Llama-3.2-3B models show that LD-MoLE achieves the highest average scores compared to state-of-the-art baselines across a diverse set of benchmarks. Our method not only achieves superior performance but also demonstrates the ability to learn token-dependent and layer-wise expert allocation.', 'title_zh': 'LD-MoLE: 学习可动态路由的LoRA专家混合适配器'}
{'arxiv_id': 'arXiv:2509.25667', 'title': 'EEG-based AI-BCI Wheelchair Advancement: Hybrid Deep Learning with Motor Imagery for Brain Computer Interface', 'authors': 'Bipul Thapa, Biplov Paneru, Bishwash Paneru, Khem Narayan Poudyal', 'link': 'https://arxiv.org/abs/2509.25667', 'abstract': 'This paper presents an Artificial Intelligence (AI) integrated novel approach to Brain-Computer Interface (BCI)-based wheelchair development, utilizing a motor imagery right-left-hand movement mechanism for control. The system is designed to simulate wheelchair navigation based on motor imagery right and left-hand movements using electroencephalogram (EEG) data. A pre-filtered dataset, obtained from an open-source EEG repository, was segmented into arrays of 19x200 to capture the onset of hand movements. The data was acquired at a sampling frequency of 200Hz. The system integrates a Tkinter-based interface for simulating wheelchair movements, offering users a functional and intuitive control system. We propose a BiLSTM-BiGRU model that shows a superior test accuracy of 92.26% as compared with various machine learning baseline models, including XGBoost, EEGNet, and a transformer-based model. The Bi-LSTM-BiGRU attention-based model achieved a mean accuracy of 90.13% through cross-validation, showcasing the potential of attention mechanisms in BCI applications.', 'abstract_zh': '本文提出了一种将人工智能集成到基于脑-计算机接口（BCI）的轮椅开发中的新型方法，利用 MOTOR IMAGERY 右左手运动机制进行控制。该系统设计用于基于 motor imagery 右左手运动的脑电信号（EEG）数据模拟轮椅导航。从开源 EEG 仓库获取的预过滤数据集被分割为 19x200 的数组，以捕捉手部运动的开始。数据以 200Hz 的采样频率获取。该系统结合了基于 Tkinter 的界面以模拟轮椅运动，为用户提供了一个功能性和直观的控制系统。我们提出了一种 BiLSTM-BiGRU 模型，其测试准确性达到 92.26%，优于包括 XGBoost、EEGNet 和基于变压器的模型在内的多种机器学习基准模型。交叉验证结果显示，Bi-LSTM-BiGRU 注意机制模型的平均准确性为 90.13%，展示了注意机制在 BCI 应用中的潜力。', 'title_zh': '基于EEG的人工智能脑机接口轮椅进展：运动想象的混合深度学习方法'}
{'arxiv_id': 'arXiv:2509.25661', 'title': 'Deep Reinforcement Learning-Based Precoding for Multi-RIS-Aided Multiuser Downlink Systems with Practical Phase Shift', 'authors': 'Po-Heng Chou, Bo-Ren Zheng, Wan-Jen Huang, Walid Saad, Yu Tsao, Ronald Y. Chang', 'link': 'https://arxiv.org/abs/2509.25661', 'abstract': 'This study considers multiple reconfigurable intelligent surfaces (RISs)-aided multiuser downlink systems with the goal of jointly optimizing the transmitter precoding and RIS phase shift matrix to maximize spectrum efficiency. Unlike prior work that assumed ideal RIS reflectivity, a practical coupling effect is considered between reflecting amplitude and phase shift for the RIS elements. This makes the optimization problem non-convex. To address this challenge, we propose a deep deterministic policy gradient (DDPG)-based deep reinforcement learning (DRL) framework. The proposed model is evaluated under both fixed and random numbers of users in practical mmWave channel settings. Simulation results demonstrate that, despite its complexity, the proposed DDPG approach significantly outperforms optimization-based algorithms and double deep Q-learning, particularly in scenarios with random user distributions.', 'abstract_zh': '本研究考虑了多可重构智能表面（RIS）辅助的多用户下行系统，旨在联合优化发射端预编码和RIS相位移矩阵，以最大化频谱效率。不同于以往工作假设理想的RIS反射率，本研究考虑了RIS元器件反射幅度与相位移之间的实际耦合效应，这使得优化问题变为非凸问题。为应对这一挑战，我们提出了一种基于深度确定性策略梯度（DDPG）的深度强化学习（DRL）框架。该模型在实际毫米波信道条件下，分别在固定和随机用户数量的情况下进行了评估。仿真结果表明，尽管复杂度较高，所提出的DDPG方法在随机用户分布场景下显著优于基于优化的方法和双深度Q学习。', 'title_zh': '基于多用户下行系统的实用相移器辅助多RIS系统深度强化学习预编码方法'}
{'arxiv_id': 'arXiv:2509.25660', 'title': 'Capacity-Net-Based RIS Precoding Design without Channel Estimation for mmWave MIMO System', 'authors': 'Chun-Yuan Huang, Po-Heng Chou, Wan-Jen Huang, Ying-Ren Chien, Yu Tsao', 'link': 'https://arxiv.org/abs/2509.25660', 'abstract': 'In this paper, we propose Capacity-Net, a novel unsupervised learning approach aimed at maximizing the achievable rate in reflecting intelligent surface (RIS)-aided millimeter-wave (mmWave) multiple input multiple output (MIMO) systems. To combat severe channel fading of the mmWave spectrum, we optimize the phase-shifting factors of the reflective elements in the RIS to enhance the achievable rate. However, most optimization algorithms rely heavily on complete and accurate channel state information (CSI), which is often challenging to acquire since the RIS is mostly composed of passive components. To circumvent this challenge, we leverage unsupervised learning techniques with implicit CSI provided by the received pilot signals. Specifically, it usually requires perfect CSI to evaluate the achievable rate as a performance metric of the current optimization result of the unsupervised learning method. Instead of channel estimation, the Capacity-Net is proposed to establish a mapping among the received pilot signals, optimized RIS phase shifts, and the resultant achievable rates. Simulation results demonstrate the superiority of the proposed Capacity-Net-based unsupervised learning approach over learning methods based on traditional channel estimation.', 'abstract_zh': '基于反射表面辅助毫米波MIMO系统的容量网：一种新的无监督学习方法', 'title_zh': '基于容量网的RIS辅助毫米波MIMO系统无信道估计预编码设计'}
{'arxiv_id': 'arXiv:2509.25659', 'title': 'YOLO-Based Defect Detection for Metal Sheets', 'authors': 'Po-Heng Chou, Chun-Chi Wang, Wei-Lung Mao', 'link': 'https://arxiv.org/abs/2509.25659', 'abstract': 'In this paper, we propose a YOLO-based deep learning (DL) model for automatic defect detection to solve the time-consuming and labor-intensive tasks in industrial manufacturing. In our experiments, the images of metal sheets are used as the dataset for training the YOLO model to detect the defects on the surfaces and in the holes of metal sheets. However, the lack of metal sheet images significantly degrades the performance of detection accuracy. To address this issue, the ConSinGAN is used to generate a considerable amount of data. Four versions of the YOLO model (i.e., YOLOv3, v4, v7, and v9) are combined with the ConSinGAN for data augmentation. The proposed YOLOv9 model with ConSinGAN outperforms the other YOLO models with an accuracy of 91.3%, and a detection time of 146 ms. The proposed YOLOv9 model is integrated into manufacturing hardware and a supervisory control and data acquisition (SCADA) system to establish a practical automated optical inspection (AOI) system. Additionally, the proposed automated defect detection is easily applied to other components in industrial manufacturing.', 'abstract_zh': '基于YOLO的深度学习自动缺陷检测模型在工业制造中的应用：ConSinGAN数据增强提高检测性能', 'title_zh': '基于YOLO的金属板材缺陷检测'}
{'arxiv_id': 'arXiv:2509.25647', 'title': 'BaB-prob: Branch and Bound with Preactivation Splitting for Probabilistic Verification of Neural Networks', 'authors': 'Fangji Wang, Panagiotis Tsiotras', 'link': 'https://arxiv.org/abs/2509.25647', 'abstract': 'Branch-and-bound with preactivation splitting has been shown highly effective for deterministic verification of neural networks. In this paper, we extend this framework to the probabilistic setting. We propose BaB-prob that iteratively divides the original problem into subproblems by splitting preactivations and leverages linear bounds computed by linear bound propagation to bound the probability for each subproblem. We prove soundness and completeness of BaB-prob for feedforward-ReLU neural networks. Furthermore, we introduce the notion of uncertainty level and design two efficient strategies for preactivation splitting, yielding BaB-prob-ordered and BaB+BaBSR-prob. We evaluate BaB-prob on untrained networks, MNIST and CIFAR-10 models, respectively, and VNN-COMP 2025 benchmarks. Across these settings, our approach consistently outperforms state-of-the-art approaches in medium- to high-dimensional input problems.', 'abstract_zh': '基于预激活分裂的分支定界方法已被证明对于神经网络的确定性验证 Highly 有效。本文将该框架扩展到概率性设置。我们提出了一种 BaB-prob 方法，通过迭代地将原问题拆分为子问题，并利用线性约束传播计算的线性边界来为每个子问题计算概率边界。我们证明了 BaB-prob 对于前向 ReLU 神经网络的完备性和有效性。此外，我们引入了不确定性级别概念，并设计了两种有效的预激活分裂策略，生成 BaB-prob-ordered 和 BaB+BaBSR-prob 方法。我们在未训练网络、MNIST 和 CIFAR-10 模型，以及 VNN-COMP 2025 计划基准上评估了 BaB-prob 方法。在这些设置中，我们的方法在中到高维度输入问题上始终优于现有最佳方法。', 'title_zh': 'BaB-prob: 带有预激活分裂的分支定界方法及其在神经网络概率验证中的应用'}
{'arxiv_id': 'arXiv:2509.25624', 'title': 'STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents', 'authors': 'Jing-Jing Li, Jianfeng He, Chao Shang, Devang Kulshreshtha, Xun Xian, Yi Zhang, Hang Su, Sandesh Swamy, Yanjun Qi', 'link': 'https://arxiv.org/abs/2509.25624', 'abstract': "As LLMs advance into autonomous agents with tool-use capabilities, they introduce security challenges that extend beyond traditional content-based LLM safety concerns. This paper introduces Sequential Tool Attack Chaining (STAC), a novel multi-turn attack framework that exploits agent tool use. STAC chains together tool calls that each appear harmless in isolation but, when combined, collectively enable harmful operations that only become apparent at the final execution step. We apply our framework to automatically generate and systematically evaluate 483 STAC cases, featuring 1,352 sets of user-agent-environment interactions and spanning diverse domains, tasks, agent types, and 10 failure modes. Our evaluations show that state-of-the-art LLM agents, including GPT-4.1, are highly vulnerable to STAC, with attack success rates (ASR) exceeding 90% in most cases. The core design of STAC's automated framework is a closed-loop pipeline that synthesizes executable multi-step tool chains, validates them through in-environment execution, and reverse-engineers stealthy multi-turn prompts that reliably induce agents to execute the verified malicious sequence. We further perform defense analysis against STAC and find that existing prompt-based defenses provide limited protection. To address this gap, we propose a new reasoning-driven defense prompt that achieves far stronger protection, cutting ASR by up to 28.8%. These results highlight a crucial gap: defending tool-enabled agents requires reasoning over entire action sequences and their cumulative effects, rather than evaluating isolated prompts or responses.", 'abstract_zh': '随着大型语言模型进化成具备工具使用能力的自主代理，它们引入了超越传统基于内容的安全关切的安全挑战。本文介绍了一种新颖的多轮攻击框架——顺序工具攻击链（STAC），该框架利用代理的工具使用能力。STAC chaining 了在单独使用时看似无害的工具调用，但当这些调用结合起来时，在最终执行步骤中会共同启用有害操作。我们应用该框架自动生成并系统评估了483个STAC案例，涉及1,352组用户-代理-环境交互，覆盖了多个领域、任务、代理类型和10种失败模式。评估结果表明，最先进的语言模型代理，包括GPT-4.1，对STAC高度易受攻击，大多数情况下攻击成功率（ASR）超过90%。STAC自动框架的核心设计是一个闭环管道，该管道综合生成可执行的多步骤工具链，在环境中执行验证，并逆向工程生成可靠诱导代理执行验证过的恶意序列的隐蔽多轮提示。此外，我们还进行了针对STAC的防御分析，并发现现有的基于提示的防御措施提供的保护有限。为填补这一缺口，我们提出了一种新的基于推理的防御提示，它提供了显著更强的保护，将攻击成功率降低高达28.8%。这些结果强调了一个关键缺口：防御工具启用的代理需要对整个行动序列及其累积效应进行推理，而不仅仅评估孤立的提示或响应。', 'title_zh': 'STAC：当无辜工具串联形成突破LLM代理的安全链条'}
{'arxiv_id': 'arXiv:2509.25618', 'title': 'Quadratic Programming Approach for Nash Equilibrium Computation in Multiplayer Imperfect-Information Games', 'authors': 'Sam Ganzfried', 'link': 'https://arxiv.org/abs/2509.25618', 'abstract': 'There has been significant recent progress in algorithms for approximation of Nash equilibrium in large two-player zero-sum imperfect-information games and exact computation of Nash equilibrium in multiplayer strategic-form games. While counterfactual regret minimization and fictitious play are scalable to large games and have convergence guarantees in two-player zero-sum games, they do not guarantee convergence to Nash equilibrium in multiplayer games. We present an approach for exact computation of Nash equilibrium in multiplayer imperfect-information games that solves a quadratically-constrained program based on a nonlinear complementarity problem formulation from the sequence-form game representation. This approach capitalizes on recent advances for solving nonconvex quadratic programs. Our algorithm is able to quickly solve three-player Kuhn poker after removal of dominated actions. Of the available algorithms in the Gambit software suite, only the logit quantal response approach is successfully able to solve the game; however, the approach takes longer than our algorithm and also involves a degree of approximation. Our formulation also leads to a new approach for computing Nash equilibrium in multiplayer strategic-form games which we demonstrate to outperform a previous quadratically-constrained program formulation.', 'abstract_zh': '近年来，在大型两人零和不完美信息博弈中近似诺伊曼均衡算法及多人战略型博弈中诺伊曼均衡精确计算算法取得了显著进展。虽然回溯遗憾最小化和假想博弈方法可以扩展到大型博弈并具有两人零和博弈中的收敛性保证，但它们在多人博弈中不能保证收敛到诺伊曼均衡。我们提出了一种在多人不完美信息博弈中精确计算诺伊曼均衡的方法，该方法基于序列型博弈表示的非线性互补问题表述求解一个二次约束规划问题。该方法利用了求解非凸二次规划问题的近期进展。我们的算法能够在去除占优行动后快速解决三人科恩扑克博弈。在Gambit软件套件中可用的算法中，只有逻辑量化响应方法能够成功解决该博弈，但该方法所需时间长于我们的算法，并且也涉及一定程度的近似。我们的表述还导致了一种新的多人战略型博弈诺伊曼均衡计算方法，我们证明了这种方法优于之前的二次约束规划问题表述方法。', 'title_zh': '多玩家不完美信息博弈中的纳什均衡计算的二次规划方法'}
{'arxiv_id': 'arXiv:2509.25612', 'title': 'Unsupervised Detection of Spatiotemporal Anomalies in PMU Data Using Transformer-Based BiGAN', 'authors': 'Muhammad Imran Hossain, Jignesh Solanki, Sarika Khushlani Solanki', 'link': 'https://arxiv.org/abs/2509.25612', 'abstract': 'Ensuring power grid resilience requires the timely and unsupervised detection of anomalies in synchrophasor data streams. We introduce T-BiGAN, a novel framework that integrates window-attention Transformers within a bidirectional Generative Adversarial Network (BiGAN) to address this challenge. Its self-attention encoder-decoder architecture captures complex spatio-temporal dependencies across the grid, while a joint discriminator enforces cycle consistency to align the learned latent space with the true data distribution. Anomalies are flagged in real-time using an adaptive score that combines reconstruction error, latent space drift, and discriminator confidence. Evaluated on a realistic hardware-in-the-loop PMU benchmark, T-BiGAN achieves an ROC-AUC of 0.95 and an average precision of 0.996, significantly outperforming leading supervised and unsupervised methods. It shows particular strength in detecting subtle frequency and voltage deviations, demonstrating its practical value for live, wide-area monitoring without relying on manually labeled fault data.', 'abstract_zh': '确保电网韧性需要及时且自主地检测同步相量数据流中的异常。为此，我们提出了一种名为T-BiGAN的新框架，该框架将窗口注意力Transformer整合到双向生成对抗网络（BiGAN）中以应对这一挑战。其自注意力编码器-解码器架构捕捉了电网中复杂的时空依赖关系，而联合判别器则通过周期一致性约束使学习的潜在空间与真实数据分布对齐。通过结合重构误差、潜在空间漂移和判别器置信度的自适应分数实时标记异常。T-BiGAN在现实的硬件在环PMU基准测试中取得了ROC-AUC为0.95和平均精度为0.996的性能，显著优于现有的监督和非监督方法，并在检测细微频率和电压偏差方面展现出特别的优势，证明了其在实际中用于广泛的实时监测的实用性，无需依赖手动标注的故障数据。', 'title_zh': '基于Transformer的BiGAN在PMU数据中无监督检测时空异常'}
{'arxiv_id': 'arXiv:2509.25594', 'title': 'K-Prism: A Knowledge-Guided and Prompt Integrated Universal Medical Image Segmentation Model', 'authors': 'Bangwei Guo, Yunhe Gao, Meng Ye, Difei Gu, Yang Zhou, Leon Axel, Dimitris Metaxas', 'link': 'https://arxiv.org/abs/2509.25594', 'abstract': 'Medical image segmentation is fundamental to clinical decision-making, yet existing models remain fragmented. They are usually trained on single knowledge sources and specific to individual tasks, modalities, or organs. This fragmentation contrasts sharply with clinical practice, where experts seamlessly integrate diverse knowledge: anatomical priors from training, exemplar-based reasoning from reference cases, and iterative refinement through real-time interaction. We present $\\textbf{K-Prism}$, a unified segmentation framework that mirrors this clinical flexibility by systematically integrating three knowledge paradigms: (i) $\\textit{semantic priors}$ learned from annotated datasets, (ii) $\\textit{in-context knowledge}$ from few-shot reference examples, and (iii) $\\textit{interactive feedback}$ from user inputs like clicks or scribbles. Our key insight is that these heterogeneous knowledge sources can be encoded into a dual-prompt representation: 1-D sparse prompts defining $\\textit{what}$ to segment and 2-D dense prompts indicating $\\textit{where}$ to attend, which are then dynamically routed through a Mixture-of-Experts (MoE) decoder. This design enables flexible switching between paradigms and joint training across diverse tasks without architectural modifications. Comprehensive experiments on 18 public datasets spanning diverse modalities (CT, MRI, X-ray, pathology, ultrasound, etc.) demonstrate that K-Prism achieves state-of-the-art performance across semantic, in-context, and interactive segmentation settings. Code will be released upon publication.', 'abstract_zh': 'medical图像分割是临床决策的基础，但现有的模型仍然支离破碎。它们通常仅基于单个知识来源并在特定任务、模态或器官上进行训练。这种分割与临床实践形成鲜明对比，在临床实践中，专家能够无缝地整合多种知识：基于标注数据的学习先验知识、基于参考案例的示例推理以及通过实时交互进行的迭代细化。我们提出了K-Prism，这是一种统一的分割框架，通过系统地整合三种知识范式来模拟这种临床灵活性：(i) 从标注数据中学习的语义先验；(ii) 来自少量参考示例的上下文知识；(iii) 用户输入（如点击或涂抹）的交互反馈。我们的核心洞察是，这些异质性知识来源可以编码为双提示表示：1-D稀疏提示定义要分割的内容，2-D密集提示指示需要关注的位置，这些信息随后通过专家混合模型(MoE)解码器动态路由。这种设计允许在不修改架构的情况下灵活切换范式并在多种任务中进行联合训练。18个来自不同模态（CT、MRI、X射线、病理学、超声波等）的公共数据集上进行了全面实验，结果表明K-Prism在语义、上下文和交互分割设置中均实现了最先进的性能。代码将在发表后公开。', 'title_zh': 'K-棱镜：一种知识导向和提示集成的通用医疗图像分割模型'}
{'arxiv_id': 'arXiv:2509.25570', 'title': 'AttentionViG: Cross-Attention-Based Dynamic Neighbor Aggregation in Vision GNNs', 'authors': 'Hakan Emre Gedik, Andrew Martin, Mustafa Munir, Oguzhan Baser, Radu Marculescu, Sandeep P. Chinchali, Alan C. Bovik', 'link': 'https://arxiv.org/abs/2509.25570', 'abstract': 'Vision Graph Neural Networks (ViGs) have demonstrated promising performance in image recognition tasks against Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). An essential part of the ViG framework is the node-neighbor feature aggregation method. Although various graph convolution methods, such as Max-Relative, EdgeConv, GIN, and GraphSAGE, have been explored, a versatile aggregation method that effectively captures complex node-neighbor relationships without requiring architecture-specific refinements is needed. To address this gap, we propose a cross-attention-based aggregation method in which the query projections come from the node, while the key projections come from its neighbors. Additionally, we introduce a novel architecture called AttentionViG that uses the proposed cross-attention aggregation scheme to conduct non-local message passing. We evaluated the image recognition performance of AttentionViG on the ImageNet-1K benchmark, where it achieved SOTA performance. Additionally, we assessed its transferability to downstream tasks, including object detection and instance segmentation on MS COCO 2017, as well as semantic segmentation on ADE20K. Our results demonstrate that the proposed method not only achieves strong performance, but also maintains efficiency, delivering competitive accuracy with comparable FLOPs to prior vision GNN architectures.', 'abstract_zh': '基于视觉的图神经网络（ViGs）在图像识别任务中展现了优于卷积神经网络（CNNs）和视觉变换器（ViTs）的 promising 性能。ViG 框架中的关键组成部分是节点-邻居特征聚合方法。尽管已经探索了多种图卷积方法，如 Max-Relative、EdgeConv、GIN 和 GraphSAGE，但仍需要一种能有效捕捉复杂节点-邻居关系且无需特定架构改进的通用聚合方法。为解决这一问题，我们提出了一种基于交叉注意力的聚合方法，其中查询投影来自节点，而键投影来自其邻居。此外，我们引入了一种名为 AttentionViG 的新架构，利用提出的交叉注意力聚合方案进行非局部消息传递。我们在 ImageNet-1K 基准上评估了 AttentionViG 的图像识别性能，实现了 SOTA 性能。此外，我们还评估了其在诸如 MSR COCO 2017 的物体检测和实例分割以及 ADE20K 的语义分割等下游任务上的可迁移性。实验结果表明，所提出的方法不仅具有强大的性能，而且保持了高效性，与先前的视觉 GNN 架构相比，提供了具有竞争力的准确性和相似的 FLOPs。', 'title_zh': 'AttentionViG: 基于交叉注意力的动态邻域聚合在视觉图神经网络中的应用'}
{'arxiv_id': 'arXiv:2509.25568', 'title': 'Probing the Limits of Stylistic Alignment in Vision-Language Models', 'authors': 'Asma Farajidizaji, Akash Gupta, Vatsal Raina', 'link': 'https://arxiv.org/abs/2509.25568', 'abstract': "Vision-language models are increasingly used to generate image captions in specific styles, such as humor or romantic. However, these transformer-based models often struggle with this subjective task in a zero-shot setting. While preference data can be used to align them toward a desired style, such data is expensive to acquire, limiting the ability to explore the models' full capabilities. This work addresses this by studying the data efficiency of aligning small vision-language models to humor and romantic styles. This approach helps to define the performance limits of these models and determine how little preference data is needed to achieve stylistic saturation, benchmarking their capabilities and limitations.", 'abstract_zh': '基于视觉-语言模型的小样本数据效率研究：幽默与浪漫风格的对齐及其性能边界确定', 'title_zh': '探究视觉语言模型风格对齐的极限'}
{'arxiv_id': 'arXiv:2509.25549', 'title': 'Hybrid Approach for Enhancing Lesion Segmentation in Fundus Images', 'authors': 'Mohammadmahdi Eshragh, Emad A. Mohammed, Behrouz Far, Ezekiel Weis, Carol L Shields, Sandor R Ferenczy, Trafford Crump', 'link': 'https://arxiv.org/abs/2509.25549', 'abstract': 'Choroidal nevi are common benign pigmented lesions in the eye, with a small risk of transforming into melanoma. Early detection is critical to improving survival rates, but misdiagnosis or delayed diagnosis can lead to poor outcomes. Despite advancements in AI-based image analysis, diagnosing choroidal nevi in colour fundus images remains challenging, particularly for clinicians without specialized expertise. Existing datasets often suffer from low resolution and inconsistent labelling, limiting the effectiveness of segmentation models. This paper addresses the challenge of achieving precise segmentation of fundus lesions, a critical step toward developing robust diagnostic tools. While deep learning models like U-Net have demonstrated effectiveness, their accuracy heavily depends on the quality and quantity of annotated data. Previous mathematical/clustering segmentation methods, though accurate, required extensive human input, making them impractical for medical applications. This paper proposes a novel approach that combines mathematical/clustering segmentation models with insights from U-Net, leveraging the strengths of both methods. This hybrid model improves accuracy, reduces the need for large-scale training data, and achieves significant performance gains on high-resolution fundus images. The proposed model achieves a Dice coefficient of 89.7% and an IoU of 80.01% on 1024*1024 fundus images, outperforming the Attention U-Net model, which achieved 51.3% and 34.2%, respectively. It also demonstrated better generalizability on external datasets. This work forms a part of a broader effort to develop a decision support system for choroidal nevus diagnosis, with potential applications in automated lesion annotation to enhance the speed and accuracy of diagnosis and monitoring.', 'abstract_zh': '视网膜色素痣是眼睛中常见的良性色素病变，虽有转变为黑色素瘤的小概率，但早期发现对于提高生存率至关重要，但误诊或延迟诊断可能导致不良后果。尽管基于AI的图像分析取得了进展，但在彩色底片图像中诊断视网膜色素痣对缺乏专业背景的临床医生来说仍然具有挑战性。现有数据集往往分辨率低且标注不一致，限制了分割模型的有效性。本文解决了精确分割底片病变的挑战，这是开发稳健诊断工具的关键步骤。虽然如U-Net等深度学习模型展示了有效性，但其准确性高度依赖于标注数据的质量和数量。之前的数学/聚类分割方法虽然准确，但需要大量的人工输入，使其在医疗应用中不可行。本文提出了一种新的方法，结合了数学/聚类分割模型与U-Net的见解，利用两种方法的优势。该混合模型提高了准确性，减少了大规模训练数据的需求，并在高分辨率底片图像上实现了显著的性能提升。所提出模型在1024×1024底片图像上的Dice系数为89.7%，IoU为80.01%，远超Attention U-Net模型的51.3%和34.2%。此外，它在外部数据集上展示了更好的泛化能力。这项工作是开发用于视网膜色素痣诊断决策支持系统的一部分，有可能应用于自动病灶标注以提高诊断和监测的速度和准确性。', 'title_zh': '基金图像中病灶分割增强的混合方法'}
{'arxiv_id': 'arXiv:2509.25543', 'title': 'Aligning Multilingual Reasoning with Verifiable Semantics from a High-Resource Expert Model', 'authors': 'Fahim Faisal, Kaiqiang Song, Song Wang, Simin Ma, Shujian Liu, Haoyun Deng, Sathish Reddy Indurthi', 'link': 'https://arxiv.org/abs/2509.25543', 'abstract': 'While reinforcement learning has advanced the reasoning abilities of Large Language Models (LLMs), these gains are largely confined to English, creating a significant performance disparity across languages. To address this, we introduce Pivot-Based Reinforcement Learning with Semantically Verifiable Rewards (PB-RLSVR), a novel framework that enhances multilingual reasoning by circumventing the need for human-annotated data in target languages. Our approach employs a high-performing English LLM as a "pivot" model to generate reference responses for reasoning tasks. A multilingual model is then rewarded based on the semantic equivalence of its responses to the English reference, effectively transferring the pivot model\'s reasoning capabilities across languages. We investigate several cross-lingual semantic reward functions, including those based on embeddings and machine translation. Extensive experiments on a suite of multilingual reasoning benchmarks show that our method significantly narrows the performance gap between English and other languages, substantially outperforming traditional PPO baselines. Specifically, our PB-RLSVR framework improves the average multilingual performance of Llama-3.1-8B-Instruct and Qwen3-32B by 16.41% and 10.17%, respectively, demonstrating a powerful and data-efficient approach to building truly multilingual reasoning agents.', 'abstract_zh': '基于语义验证奖励的多语言强化学习框架（Pivot-Based Reinforcement Learning with Semantically Verifiable Rewards）', 'title_zh': '基于高资源专家模型的多语言推理与可验证语义对齐'}
{'arxiv_id': 'arXiv:2509.25541', 'title': 'Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play', 'authors': 'Qinsi Wang, Bo Liu, Tianyi Zhou, Jing Shi, Yueqian Lin, Yiran Chen, Hai Helen Li, Kun Wan, Wentian Zhao', 'link': 'https://arxiv.org/abs/2509.25541', 'abstract': 'Although reinforcement learning (RL) can effectively enhance the reasoning capabilities of vision-language models (VLMs), current methods remain heavily dependent on labor-intensive datasets that require extensive manual construction and verification, leading to extremely high training costs and consequently constraining the practical deployment of VLMs. To address this challenge, we propose Vision-Zero, a domain-agnostic framework enabling VLM self-improvement through competitive visual games generated from arbitrary image pairs. Specifically, Vision-Zero encompasses three main attributes: (1) Strategic Self-Play Framework: Vision-Zero trains VLMs in "Who Is the Spy"-style games, where the models engage in strategic reasoning and actions across multiple roles. Through interactive gameplay, models autonomously generate their training data without human annotation. (2) Gameplay from Arbitrary Images: Unlike existing gamified frameworks, Vision-Zero can generate games from arbitrary images, thereby enhancing the model\'s reasoning ability across diverse domains and showing strong generalization to different tasks. We demonstrate this versatility using three distinct types of image datasets: CLEVR-based synthetic scenes, charts, and real-world images. (3) Sustainable Performance Gain: We introduce Iterative Self-Play Policy Optimization (Iterative-SPO), a novel training algorithm that alternates between Self-Play and reinforcement learning with verifiable rewards (RLVR), mitigating the performance plateau often seen in self-play-only training and achieving sustained long-term improvements. Despite using label-free data, Vision-Zero achieves state-of-the-art performance on reasoning, chart question answering, and vision-centric understanding tasks, surpassing other annotation-based methods. Models and code has been released at this https URL.', 'abstract_zh': 'Vision-Zero：一种无监督领域泛化框架，通过任意图像对生成的竞争视觉游戏实现VLM自我提升', 'title_zh': 'Vision-Zero: 通过战略游戏化自我对弈实现的可扩展VLM自我提升'}
{'arxiv_id': 'arXiv:2509.25539', 'title': 'Toxicity in Online Platforms and AI Systems: A Survey of Needs, Challenges, Mitigations, and Future Directions', 'authors': 'Smita Khapre, Melkamu Abay Mersha, Hassan Shakil, Jonali Baruah, Jugal Kalita', 'link': 'https://arxiv.org/abs/2509.25539', 'abstract': 'The evolution of digital communication systems and the designs of online platforms have inadvertently facilitated the subconscious propagation of toxic behavior. Giving rise to reactive responses to toxic behavior. Toxicity in online content and Artificial Intelligence Systems has become a serious challenge to individual and collective well-being around the world. It is more detrimental to society than we realize. Toxicity, expressed in language, image, and video, can be interpreted in various ways depending on the context of usage. Therefore, a comprehensive taxonomy is crucial to detect and mitigate toxicity in online content, Artificial Intelligence systems, and/or Large Language Models in a proactive manner. A comprehensive understanding of toxicity is likely to facilitate the design of practical solutions for toxicity detection and mitigation. The classification in published literature has focused on only a limited number of aspects of this very complex issue, with a pattern of reactive strategies in response to toxicity. This survey attempts to generate a comprehensive taxonomy of toxicity from various perspectives. It presents a holistic approach to explain the toxicity by understanding the context and environment that society is facing in the Artificial Intelligence era. This survey summarizes the toxicity-related datasets and research on toxicity detection and mitigation for Large Language Models, social media platforms, and other online platforms, detailing their attributes in textual mode, focused on the English language. Finally, we suggest the research gaps in toxicity mitigation based on datasets, mitigation strategies, Large Language Models, adaptability, explainability, and evaluation.', 'abstract_zh': '数字通信系统的发展和在线平台的设计无意中促进了有毒行为的潜意识传播，激发了对有毒行为的反应性应对措施。在线内容和人工智能系统的有毒性问题已成为全球个人和集体福祉的重大挑战，其对社会的危害程度超乎我们的认知。有毒性的表达方式取决于使用语境，可以有多种解释，因此，建立一个全面的分类体系对于主动检测和缓解在线内容、人工智能系统和/或大型语言模型中的毒性至关重要。对有毒性问题全面理解可能会促进毒性检测和缓解的实际解决方案的设计。已发表文献中的分类主要集中在这一极其复杂问题的有限方面，反应性策略是其主要模式。本文试图从多个角度构建一个全面的毒性分类体系，以一种综合的方式解释毒性，理解人工智能时代社会所面临的环境和情境。本文总结了与毒性相关的数据集和对于大型语言模型、社交媒体平台和其他在线平台的毒性检测与缓解的研究，详细描述了这些平台的文本属性，重点为英文内容。最后，基于数据集、缓解策略、大型语言模型、适应性、可解释性和评估，提出了毒性缓解的研究空白。', 'title_zh': '在线平台和AI系统中的毒性：需求、挑战、缓解措施及未来方向调研'}
{'arxiv_id': 'arXiv:2509.25538', 'title': 'Steering an Active Learning Workflow Towards Novel Materials Discovery via Queue Prioritization', 'authors': 'Marcus Schwarting, Logan Ward, Nathaniel Hudson, Xiaoli Yan, Ben Blaiszik, Santanu Chaudhuri, Eliu Huerta, Ian Foster', 'link': 'https://arxiv.org/abs/2509.25538', 'abstract': 'Generative AI poses both opportunities and risks for solving inverse design problems in the sciences. Generative tools provide the ability to expand and refine a search space autonomously, but do so at the cost of exploring low-quality regions until sufficiently fine tuned. Here, we propose a queue prioritization algorithm that combines generative modeling and active learning in the context of a distributed workflow for exploring complex design spaces. We find that incorporating an active learning model to prioritize top design candidates can prevent a generative AI workflow from expending resources on nonsensical candidates and halt potential generative model decay. For an existing generative AI workflow for discovering novel molecular structure candidates for carbon capture, our active learning approach significantly increases the number of high-quality candidates identified by the generative model. We find that, out of 1000 novel candidates, our workflow without active learning can generate an average of 281 high-performing candidates, while our proposed prioritization with active learning can generate an average 604 high-performing candidates.', 'abstract_zh': '生成式AI既带来了机遇也带来了风险，用于解决科学领域的逆向设计问题。生成工具提供了自主扩大和细化搜索空间的能力，但这也意味着在充分调优之前需要探索低质量区域。在此，我们提出一种结合生成模型和主动学习的队列优先算法，适用于分布式工作流以探索复杂的设计空间。我们发现，将主动学习模型纳入优先算法，可以防止生成式AI工作流在处理无意义候选方案上浪费资源，并防止生成模型性能衰退。对于一个现有的用于发现新型分子结构候选方案以捕获碳的生成式AI工作流，我们的主动学习方法显著提高了生成模型识别高质量候选方案的数量。我们发现，在1000个新型候选方案中，不采用主动学习的工作流平均能生成281个高性能候选方案，而结合主动学习优先算法的工作流平均能生成604个高性能候选方案。', 'title_zh': '通过队列优先级设置引导主动学习工作流以实现新型材料发现'}
{'arxiv_id': 'arXiv:2509.25534', 'title': 'Self-Rewarding Rubric-Based Reinforcement Learning for Open-Ended Reasoning', 'authors': 'Zhiling Ye, Yun Yue, Haowen Wang, Xudong Han, Jiadi Jiang, Cheng Wei, Lei Fan, Jiaxin Liang, Shuowen Zhang, Ji Li, Chunxiao Guo, Jian Wang, Peng Wei, Jinjie Gu', 'link': 'https://arxiv.org/abs/2509.25534', 'abstract': 'Open-ended evaluation is essential for deploying large language models in real-world settings. In studying HealthBench, we observe that using the model itself as a grader and generating rubric-based reward signals substantially improves reasoning performance. Remarkably, the trained model also becomes a stronger grader. Motivated by this, we introduce Self-Rewarding Rubric-Based Reinforcement Learning for Open-Ended Reasoning, a lightweight framework that enables faster and more resource-efficient training while surpassing baselines. Remarkably, on Qwen3-32B, training with just the 4000-sample HealthBench Easy subset is sufficient to obtain a model that exceeds GPT-5 on HealthBench Hard. Incorporating a small amount of teacher-graded data further enhances performance for less capable models.', 'abstract_zh': '自回归评分基于奖励信号的开放性推理强化学习：一种轻量级框架', 'title_zh': '基于自我奖励评述的开放性推理强化学习'}
{'arxiv_id': 'arXiv:2509.25533', 'title': 'VISOR++: Universal Visual Inputs based Steering for Large Vision Language Models', 'authors': 'Ravikumar Balakrishnan, Mansi Phute', 'link': 'https://arxiv.org/abs/2509.25533', 'abstract': 'As Vision Language Models (VLMs) are deployed across safety-critical applications, understanding and controlling their behavioral patterns has become increasingly important. Existing behavioral control methods face significant limitations: system prompting approaches could easily be overridden by user instructions, while applying activation-based steering vectors requires invasive runtime access to model internals, precluding deployment with API-based services and closed-source models. Finding steering methods that transfer across multiple VLMs is still an open area of research. To this end, we introduce universal visual input based steering for output redirection (VISOR++), to achieve behavioral control through optimized visual inputs alone. We demonstrate that a single VISOR++ image can be generated for an ensemble of VLMs to emulate each of their steering vectors. By crafting universal visual inputs that induce target activation patterns, VISOR++ eliminates the need for runtime model access while remaining deployment-agnostic. This means that when an underlying model supports multimodal capability, model behaviors can be steered by inserting an image input replacing runtime steering vector based interventions. We first demonstrate the effectiveness of the VISOR++ images on open-access models such as LLaVA-1.5-7B and IDEFICS2-8B along three alignment directions: refusal, sycophancy and survival instinct. Both the model-specific steering images and the jointly optimized images achieve performance parity closely following that of steering vectors for both positive and negative steering tasks. We also show the promise of VISOR++ images in achieving directional behavioral shifts for unseen models including both open-access and closed-access ones. Furthermore, VISOR++ images are able to preserve 99.9% performance on 14,000 unrelated MMLU evaluation tasks.', 'abstract_zh': '基于通用视觉输入的输出重定向行为控制（VISOR++）', 'title_zh': 'VISOR++: 基于通用视觉输入的大型视觉语言模型引导'}
{'arxiv_id': 'arXiv:2509.25532', 'title': 'Calibrating Verbalized Confidence with Self-Generated Distractors', 'authors': 'Victor Wang, Elias Stengel-Eskin', 'link': 'https://arxiv.org/abs/2509.25532', 'abstract': "Calibrated confidence estimates are necessary for large language model (LLM) outputs to be trusted by human users. While LLMs can express their confidence in human-interpretable ways, verbalized LLM-generated confidence scores have empirically been found to be miscalibrated, reporting high confidence on instances with low accuracy and thereby harming trust and safety. We hypothesize that this overconfidence often stems from a given LLM's heightened suggestibility when faced with claims that it encodes little information about; we empirically validate this hypothesis, finding more suggestibility on lower-accuracy claims. Building on this finding, we introduce Distractor-Normalized Coherence (DINCO), which estimates and accounts for an LLM's suggestibility bias by having the model verbalize its confidence independently across several self-generated distractors (i.e. alternative claims), and normalizes by the total verbalized confidence. To further improve calibration, we leverage generator-validator disagreement, augmenting normalized validator confidence with a consistency-based estimate of generator confidence. Here, we frame the popular approach of self-consistency as leveraging coherence across sampled generations, and normalized verbalized confidence as leveraging coherence across validations on incompatible claims, allowing us to integrate these complementary dimensions of coherence into DINCO. Moreover, our analysis shows that DINCO provides less saturated -- and therefore more usable -- confidence estimates, and that further sampling alone cannot close the gap between DINCO and baselines, with DINCO at 10 inference calls outperforming self-consistency at 100.", 'abstract_zh': '校准的置信度估计对于大型语言模型（LLM）的输出被人类用户信任是必要的。虽然LLM可以通过人类可理解的方式表达其置信度，但实验证明，LLM生成的置信分数往往是失校准的，报告低准确度实例的高置信度，从而损害信任和安全性。我们假设这种过度自信通常源于LLM在面对它编码信息很少的断言时的高暗示性；我们通过实验验证了这一假设，发现对于低准确度断言，LLM的暗示性更强。基于这一发现，我们引入了干扰归一化连贯性（DINCO），通过让模型独立地在几个自我生成的干扰项（即替代断言）上表达其置信度，并通过总表达置信度进行归一化，来估算和纠正LLM的暗示性偏差。为了进一步提高校准度，我们利用生成器-验证器分歧，将归一化验证器置信度与基于一致性的生成器置信度估计结合起来。在这里，我们将广为接受的自一致性方法视为通过采样生成之间的一致性来利用连贯性，而归一化表达置信度则被视为利用不可兼容断言验证之间的一致性来利用连贯性，从而将这些连贯性的互补维度整合到DINCO中。此外，我们的分析表明，DINCO提供了较少过饱和——因此更具可操作性的置信度估计，单独增加采样无法弥补DINCO与基线之间的差距，DINCO在10次推理调用时的表现优于自一致性在100次采样时的表现。', 'title_zh': '基于自动生成干扰项校准口头表达的置信度'}
{'arxiv_id': 'arXiv:2509.25531', 'title': 'MixtureVitae: Open Web-Scale Pretraining Dataset With High Quality Instruction and Reasoning Data Built from Permissive-First Text Sources', 'authors': 'Huu Nguyen, Victor May, Harsh Raj, Marianna Nezhurina, Yishan Wang, Yanqi Luo, Minh Chien Vu, Taishi Nakamura, Ken Tsui, Van Khue Nguyen, David Salinas, Aleksandra Krasnodębska, Christoph Schuhmann, Mats Leon Richter, Xuan-Son, Jenia Jitsev', 'link': 'https://arxiv.org/abs/2509.25531', 'abstract': 'We present MixtureVitae, an open-access pretraining corpus built to minimize legal risk while providing strong model performance. MixtureVitae follows a risk-mitigated sourcing strategy that combines public-domain and permissively licensed text (e.g., CC-BY/Apache) with carefully justified low-risk additions (e.g., government works and EU TDM-eligible sources), alongside targeted instruction, reasoning and synthetic data with documented provenance. We detail a transparent, multi-stage pipeline for license-aware filtering, safety and quality screening, and domain-aware mixing, and we release the dataset and curation recipes to support reproducible research. In controlled experiments using the open-sci-ref training protocol (fixed architectures at 130M/400M/1.3B/1.7B parameters; training budgets of 50B and 300B tokens), models trained on MixtureVitae consistently outperform other permissive datasets across a suite of standard benchmarks, and at the 1.7B/300B setting they surpass FineWeb-Edu and approach DCLM in the later stages of training. Performance is particularly strong on math/code and competitive on QA tasks. These results demonstrate that permissive-first, risk-mitigated data provides a practical and legally mitigated foundation for training capable LLMs, reducing reliance on indiscriminate web scraping without sacrificing competitiveness. Code: this https URL', 'abstract_zh': '我们 presents MixtureVitae，一个旨在最小化法律风险同时提供强大模型性能的开源预训练数据集。', 'title_zh': 'MixtureVitae: 开放的高质量指令和推理数据预训练数据集，源自宽松优先的文本来源'}
{'arxiv_id': 'arXiv:2509.25528', 'title': 'LLM-RG: Referential Grounding in Outdoor Scenarios using Large Language Models', 'authors': 'Pranav Saxena, Avigyan Bhattacharya, Ji Zhang, Wenshan Wang', 'link': 'https://arxiv.org/abs/2509.25528', 'abstract': 'Referential grounding in outdoor driving scenes is challenging due to large scene variability, many visually similar objects, and dynamic elements that complicate resolving natural-language references (e.g., "the black car on the right"). We propose LLM-RG, a hybrid pipeline that combines off-the-shelf vision-language models for fine-grained attribute extraction with large language models for symbolic reasoning. LLM-RG processes an image and a free-form referring expression by using an LLM to extract relevant object types and attributes, detecting candidate regions, generating rich visual descriptors with a VLM, and then combining these descriptors with spatial metadata into natural-language prompts that are input to an LLM for chain-of-thought reasoning to identify the referent\'s bounding box. Evaluated on the Talk2Car benchmark, LLM-RG yields substantial gains over both LLM and VLM-based baselines. Additionally, our ablations show that adding 3D spatial cues further improves grounding. Our results demonstrate the complementary strengths of VLMs and LLMs, applied in a zero-shot manner, for robust outdoor referential grounding.', 'abstract_zh': '基于户外驾驶场景的引用 grounding 挑战在于大规模场景变化、众多视觉相似对象以及动态元素使得自然语言引用解析复杂化（例如，“右边的黑色汽车”）。我们提出了一种混合pipeline LLM-RG，该pipeline结合了现成的跨模态模型进行细粒度属性提取与大规模语言模型进行符号推理。LLM-RG 使用LLM提取与表达相关的对象类型和属性，检测候选区域，使用VLM生成丰富的视觉描述，并将这些描述与空间元数据结合成自然语言提示，输入到LLM中进行推理以识别引用对象的边界框。在Talk2Car基准测试上，LLM-RG 在基于LLM和VLM的基线下取得了显著的提升。此外，我们的消融实验表明，添加三维空间线索进一步提升了grounding效果。我们的结果展示了在零样本情况下，跨模态模型和语言模型互补优势在户外引用grounding中的应用，以实现鲁棒性地引用解析。', 'title_zh': 'LLM-RG: 在户外场景中使用大型语言模型进行指代 grounding'}
{'arxiv_id': 'arXiv:2509.25524', 'title': 'Economic Competition, EU Regulation, and Executive Orders: A Framework for Discussing AI Policy Implications in CS Courses', 'authors': 'James Weichert, Hoda Eldardiry', 'link': 'https://arxiv.org/abs/2509.25524', 'abstract': 'The growth and permeation of artificial intelligence (AI) technologies across society has drawn focus to the ways in which the responsible use of these technologies can be facilitated through AI governance. Increasingly, large companies and governments alike have begun to articulate and, in some cases, enforce governance preferences through AI policy. Yet existing literature documents an unwieldy heterogeneity in ethical principles for AI governance, while our own prior research finds that discussions of the implications of AI policy are not yet present in the computer science (CS) curriculum. In this context, overlapping jurisdictions and even contradictory policy preferences across private companies, local, national, and multinational governments create a complex landscape for AI policy which, we argue, will require AI developers able adapt to an evolving regulatory environment. Preparing computing students for the new challenges of an AI-dominated technology industry is therefore a key priority for the CS curriculum.\nIn this discussion paper, we seek to articulate a framework for integrating discussions on the nascent AI policy landscape into computer science courses. We begin by summarizing recent AI policy efforts in the United States and European Union. Subsequently, we propose guiding questions to frame class discussions around AI policy in technical and non-technical (e.g., ethics) CS courses. Throughout, we emphasize the connection between normative policy demands and still-open technical challenges relating to their implementation and enforcement through code and governance structures. This paper therefore represents a valuable contribution towards bridging research and discussions across the areas of AI policy and CS education, underlining the need to prepare AI engineers to interact with and adapt to societal policy preferences.', 'abstract_zh': '人工智能技术在社会中的发展与渗透引发了对通过人工智能治理促进负责任使用这些技术方式的关注。越来越多的大公司和政府开始阐述并实施人工智能政策。然而，现有文献表明，人工智能治理中的伦理原则存在难以驾驭的多样性，而我们自己的前期研究发现，人工智能政策的含义讨论尚未出现在计算机科学课程中。在这一背景下，私营公司、地方政府、国家级政府以及跨国政府之间重叠的管辖权和甚至相互矛盾的政策偏好创造了一种复杂的人工智能政策景观，我们认为这将需要能够适应不断发展中的监管环境的人工智能开发者。因此，为计算机科学课程准备能够应对人工智能主导技术行业新挑战的学生是课程的一个关键优先事项。\n\n在本文中，我们旨在为将关于新兴人工智能政策景观的讨论整合到计算机科学课程中提出一个框架。我们首先总结了美国和欧盟近期的人工智能政策努力。随后，我们提出指导性问题来框架技术性和非技术性（如，伦理）课程中的人工智能政策讨论。在整个过程中，我们强调了规范性政策要求与通过代码和治理结构实施与执行这些要求仍待解决的技术挑战之间的联系。因此，本文代表了弥合人工智能政策和计算机科学教育领域研究与讨论之间鸿沟的重要贡献，突显了准备人工智能工程师与社会政策偏好互动并适应这些偏好的重要性。', 'title_zh': '经济竞争、欧盟法规与行政命令：在计算机科学课程中讨论人工智能政策影响的框架'}
{'arxiv_id': 'arXiv:2509.25504', 'title': 'XR Blocks: Accelerating Human-centered AI + XR Innovation', 'authors': 'David Li, Nels Numan, Xun Qian, Yanhe Chen, Zhongyi Zhou, Evgenii Alekseev, Geonsun Lee, Alex Cooper, Min Xia, Scott Chung, Jeremy Nelson, Xiuxiu Yuan, Jolica Dias, Tim Bettridge, Benjamin Hersh, Michelle Huynh, Konrad Piascik, Ricardo Cabello, David Kim, Ruofei Du', 'link': 'https://arxiv.org/abs/2509.25504', 'abstract': 'We are on the cusp where Artificial Intelligence (AI) and Extended Reality (XR) are converging to unlock new paradigms of interactive computing. However, a significant gap exists between the ecosystems of these two fields: while AI research and development is accelerated by mature frameworks like JAX and benchmarks like LMArena, prototyping novel AI-driven XR interactions remains a high-friction process, often requiring practitioners to manually integrate disparate, low-level systems for perception, rendering, and interaction. To bridge this gap, we present XR Blocks, a cross-platform framework designed to accelerate human-centered AI + XR innovation. XR Blocks strives to provide a modular architecture with plug-and-play components for core abstraction in AI + XR: user, world, peers; interface, context, and agents. Crucially, it is designed with the mission of "reducing frictions from idea to reality", thus accelerating rapid prototyping of AI + XR apps. Built upon accessible technologies (WebXR, this http URL, TensorFlow, Gemini), our toolkit lowers the barrier to entry for XR creators. We demonstrate its utility through a set of open-source templates, samples, and advanced demos, empowering the community to quickly move from concept to interactive XR prototype. Site: this https URL', 'abstract_zh': '人工智能与扩展现实的融合正处于关键时期：开启交互计算新范式。然而，这两领域的生态之间存在显著差距：虽然AI研究与开发借助于成熟的框架如JAX和基准如LMArena加速进行，但新型AI驱动的XR交互原型设计仍是一个高摩擦的过程，通常需要 practitioners 手动整合多种低级系统。为弥合这一差距，我们提出XR Blocks，这是一个跨平台框架，旨在加速以人类为中心的AI + XR创新。XR Blocks 致力于提供一个模块化架构，并提供插拔式组件以对AI + XR的核心抽象进行模块化设计：用户、世界、同伴；界面、上下文和代理。最关键的是，XR Blocks 旨在“降低从理念到现实的摩擦”，从而加速AI + XR应用的快速原型设计。基于易用技术（WebXR等），我们的工具包降低了XR创作者的入门门槛。我们通过一系列开源模板、示例和高级演示展示了其用途，使社区能够快速从概念过渡到交互式XR原型。网站：此链接。', 'title_zh': 'XR Blocks：加速以人为中心的AI+XR创新'}
{'arxiv_id': 'arXiv:2509.25503', 'title': 'DeepFake Detection in Dyadic Video Calls using Point of Gaze Tracking', 'authors': 'Odin Kohler, Rahul Vijaykumar, Masudul H. Imtiaz', 'link': 'https://arxiv.org/abs/2509.25503', 'abstract': "With recent advancements in deepfake technology, it is now possible to generate convincing deepfakes in real-time. Unfortunately, malicious actors have started to use this new technology to perform real-time phishing attacks during video meetings. The nature of a video call allows access to what the deepfake is ``seeing,'' that is, the screen displayed to the malicious actor. Using this with the estimated gaze from the malicious actors streamed video enables us to estimate where the deepfake is looking on screen, the point of gaze. Because the point of gaze during conversations is not random and is instead used as a subtle nonverbal communicator, it can be used to detect deepfakes, which are not capable of mimicking this subtle nonverbal communication. This paper proposes a real-time deepfake detection method adapted to this genre of attack, utilizing previously unavailable biometric information. We built our model based on explainable features selected after careful review of research on gaze patterns during dyadic conversations. We then test our model on a novel dataset of our creation, achieving an accuracy of 82\\%. This is the first reported method to utilize point-of-gaze tracking for deepfake detection.", 'abstract_zh': '随着深度合成技术的 recent advancements，现在可以在实时生成逼真的深度合成内容。不幸的是，恶意行为者已经开始利用这项新技术在视频会议中进行实时欺诈攻击。视频通话的性质使得可以访问深度合成所“看到”的内容，即显示给恶意行为者的屏幕内容。通过结合从恶意行为者流媒体视频中估计的注视方向，可以估计深度合成在屏幕上注视的点，即注视点。在对话中，注视点不是随机的，而是一种微妙的非语言沟通方式，因此可以用于检测无法模仿这种微妙非语言沟通的深度合成。本文提出了一种适应此类攻击的实时深度合成检测方法，利用过去不可用的生物特征信息。我们在仔细审阅关于双人对话期间注视模式的研究后选择了可解释的特征构建了我们的模型，并在我们创建的一个新数据集上测试了我们的模型，达到了82%的准确率。这是首次使用注视点跟踪进行深度合成检测的方法报道。', 'title_zh': '基于眼动追踪的双人视频通话DeepFake检测'}
{'arxiv_id': 'arXiv:2509.25498', 'title': 'Not Wrong, But Untrue: LLM Overconfidence in Document-Based Queries', 'authors': 'Nick Hagar, Wilma Agustianto, Nicholas Diakopoulos', 'link': 'https://arxiv.org/abs/2509.25498', 'abstract': 'Large language models (LLMs) are increasingly used in newsroom workflows, but their tendency to hallucinate poses risks to core journalistic practices of sourcing, attribution, and accuracy. We evaluate three widely used tools - ChatGPT, Gemini, and NotebookLM - on a reporting-style task grounded in a 300-document corpus related to TikTok litigation and policy in the U.S. We vary prompt specificity and context size and annotate sentence-level outputs using a taxonomy to measure hallucination type and severity. Across our sample, 30% of model outputs contained at least one hallucination, with rates approximately three times higher for Gemini and ChatGPT (40%) than for NotebookLM (13%). Qualitatively, most errors did not involve invented entities or numbers; instead, we observed interpretive overconfidence - models added unsupported characterizations of sources and transformed attributed opinions into general statements. These patterns reveal a fundamental epistemological mismatch: While journalism requires explicit sourcing for every claim, LLMs generate authoritative-sounding text regardless of evidentiary support. We propose journalism-specific extensions to existing hallucination taxonomies and argue that effective newsroom tools need architectures that enforce accurate attribution rather than optimize for fluency.', 'abstract_zh': '大型语言模型（LLMs）在新闻工作流程中的应用日益增加，但其倾向性幻觉对其核心的新闻采编原则，如来源确认、归属和准确性构成风险。我们基于与TikTok诉讼和美国政策相关的300份文件构建报道风格的任务，评估了三种广泛使用的工具：ChatGPT、Gemini和NotebookLM。我们在提示的具体性和上下文规模方面进行了变化，并使用分类体系标注句子级输出，以衡量幻觉类型和严重程度。在我们的样本中，30%的模型输出包含至少一个幻觉，Gemini和ChatGPT的幻觉率约为NotebookLM的三倍（分别为40%和13%）。定性分析显示，大多数错误并非涉及虚构实体或数字；相反，我们观察到解释性过度自信——模型增加了对来源的支持不足的描述性，将归因意见转变为普遍性陈述。这些模式揭示了根本的知识论错配：新闻报道要求对每个声明进行明确的来源确认，而LLMs无论是否有证据支持都生成权威性语言的声音文本。我们提出了针对新闻的特定扩展以现有幻觉分类体系，并主张有效的新闻工具架构需要强制准确归属，而不是优化流畅性。', 'title_zh': '不是错误，而是不真实：大型语言模型在基于文档的查询中的过度自信'}
{'arxiv_id': 'arXiv:2509.25495', 'title': 'EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition', 'authors': 'Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao', 'link': 'https://arxiv.org/abs/2509.25495', 'abstract': 'Speech emotion recognition (SER) with audio-language models (ALMs) remains vulnerable to distribution shifts at test time, leading to performance degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a promising solution but often relies on gradient-based updates or prompt tuning, limiting flexibility and practicality. We propose Emo-TTA, a lightweight, training-free adaptation framework that incrementally updates class-conditional statistics via an Expectation-Maximization procedure for explicit test-time distribution estimation, using ALM predictions as priors. Emo-TTA operates on individual test samples without modifying model weights. Experiments on six out-of-domain SER benchmarks show consistent accuracy improvements over prior TTA baselines, demonstrating the effectiveness of statistical adaptation in aligning model predictions with evolving test distributions.', 'abstract_zh': '基于音频-语言模型的语音情感识别（SER）在测试时仍易受分布偏移影响，导致领域外场景下的性能下降。测试时适应（TTA）提供了一种有前景的解决方案，但通常依赖于基于梯度的更新或提示调谐，限制了其灵活性和实用性。我们提出了一种轻量级、无训练的适应框架Emo-TTA，通过期望-最大值程序增量更新类别条件统计，使用ALM预测作为先验进行显式测试时分布估计。Emo-TTA在不修改模型权重的情况下操作单个测试样本。在六个领域外SER基准测试上的实验结果显示，Emo-TTA在先前提到的TTA基线之上实现了一致的准确率提升，证明了统计适应在使模型预测与不断变化的测试分布相一致方面的有效性。', 'title_zh': 'EMO-TTA：提高音频语言模型在语音情感识别中的测试时自适应能力'}
{'arxiv_id': 'arXiv:2509.25480', 'title': 'Translation from Wearable PPG to 12-Lead ECG', 'authors': 'Hui Ji, Wei Gao, Pengfei Zhou', 'link': 'https://arxiv.org/abs/2509.25480', 'abstract': 'The 12-lead electrocardiogram (ECG) is the gold standard for cardiovascular monitoring, offering superior diagnostic granularity and specificity compared to photoplethysmography (PPG). However, existing 12-lead ECG systems rely on cumbersome multi-electrode setups, limiting sustained monitoring in ambulatory settings, while current PPG-based methods fail to reconstruct multi-lead ECG due to the absence of inter-lead constraints and insufficient modeling of spatial-temporal dependencies across leads. To bridge this gap, we introduce P2Es, an innovative demographic-aware diffusion framework designed to generate clinically valid 12-lead ECG from PPG signals via three key innovations. Specifically, in the forward process, we introduce frequency-domain blurring followed by temporal noise interference to simulate real-world signal distortions. In the reverse process, we design a temporal multi-scale generation module followed by frequency deblurring. In particular, we leverage KNN-based clustering combined with contrastive learning to assign affinity matrices for the reverse process, enabling demographic-specific ECG translation. Extensive experimental results show that P2Es outperforms baseline models in 12-lead ECG reconstruction.', 'abstract_zh': '基于人口统计学aware的光谱扩散框架P2Es：从PPG信号生成临床有效的12导联心电图', 'title_zh': '从可穿戴PPG信号转化为12导联ECG'}
{'arxiv_id': 'arXiv:2509.25479', 'title': 'Discontinuous Epitope Fragments as Sufficient Target Templates for Efficient Binder Design', 'authors': 'Zhenfeng Deng, Ruijie Hou, Ningrui Xie, Mike Tyers, Michał Koziarski', 'link': 'https://arxiv.org/abs/2509.25479', 'abstract': "Recent advances in structure-based protein design have accelerated de novo binder generation, yet interfaces on large domains or spanning multiple domains remain challenging due to high computational cost and declining success with increasing target size. We hypothesized that protein folding neural networks (PFNNs) operate in a ``local-first'' manner, prioritizing local interactions while displaying limited sensitivity to global this http URL by this hypothesis, we propose an epitope-only strategy that retains only the discontinuous surface residues surrounding the binding site. Compared to intact-domain workflows, this approach improves in silico success rates by up to 80% and reduces the average time per successful design by up to forty-fold, enabling binder design against previously intractable targets such as ClpP and ALS3. Building on this foundation, we further developed a tailored pipeline that incorporates a Monte Carlo-based evolution step to overcome local minima and a position-specific biased inverse folding step to refine sequence patterns. Together, these advances not only establish a generalizable framework for efficient binder design against structurally large and otherwise inaccessible targets, but also support the broader ``local-first'' hypothesis as a guiding principle for PFNN-based design.", 'abstract_zh': '基于结构的蛋白质设计 Recent进展加速了从头 binder 的生成，但大规模结构域或跨多个结构域的界面仍然具有挑战性，因为随着目标大小的增加，计算成本高且成功率下降。我们假设蛋白质折叠神经网络（PFNNs）以“局部优先”方式工作，优先处理局部相互作用，对全局相互作用的敏感性有限。基于这一假设，我们提出了一种仅保留围绕结合位点的不连续表面对残基的策略。与完整结构域流程相比，这种方法将计算成功率提高了高达80%，并将每次成功设计所需的时间平均减少了四十分之一，使其能够针对以前难以应对的目标（如ClpP和ALS3）进行 binder 设计。在此基础上，我们进一步开发了一种定制管道，该管道结合了基于蒙特卡洛的进化步骤来克服局部最小值，并结合了位置特异性偏差逆折叠步骤来细化序列模式。这些进展不仅建立了一种适用于结构庞大且难以访问的目标的高效 binder 设计的一般框架，还支持了 PFNN 基础设计中的“局部优先”假设作为一种指导原则。', 'title_zh': '不连续表位片段作为高效配体设计的充分靶标模板'}
{'arxiv_id': 'arXiv:2509.25466', 'title': 'Data-Efficient Multitask DAgger', 'authors': 'Haotian Fu, Ran Gong, Xiaohan Zhang, Maria Vittoria Minniti, Jigarkumar Patel, Karl Schmeckpeper', 'link': 'https://arxiv.org/abs/2509.25466', 'abstract': "Generalist robot policies that can perform many tasks typically require extensive expert data or simulations for training. In this work, we propose a novel Data-Efficient multitask DAgger framework that distills a single multitask policy from multiple task-specific expert policies. Our approach significantly increases the overall task success rate by actively focusing on tasks where the multitask policy underperforms. The core of our method is a performance-aware scheduling strategy that tracks how much each task's learning process benefits from the amount of data, using a Kalman filter-based estimator to robustly decide how to allocate additional demonstrations across tasks. We validate our approach on MetaWorld, as well as a suite of diverse drawer-opening tasks in IsaacLab. The resulting policy attains high performance across all tasks while using substantially fewer expert demonstrations, and the visual policy learned with our method in simulation shows better performance than naive DAgger and Behavior Cloning when transferring zero-shot to a real robot without using real data.", 'abstract_zh': '一种数据高效多任务DAgger框架：从多个任务特定专家策略中提炼单一多任务策略', 'title_zh': '数据效率多任务DAgger'}
{'arxiv_id': 'arXiv:2509.25455', 'title': 'PIPer: On-Device Environment Setup via Online Reinforcement Learning', 'authors': 'Alexander Kovrigin, Aleksandra Eliseeva, Konstantin Grotov, Egor Bogomolov, Yaroslav Zharov', 'link': 'https://arxiv.org/abs/2509.25455', 'abstract': 'Environment setup-the process of configuring the system to work with a specific software project-represents a persistent challenge in Software Engineering (SE). Automated environment setup methods could assist developers by providing fully configured environments for arbitrary repositories without manual effort. This also helps SE researchers to scale execution-based benchmarks. However, recent studies reveal that even state-of-the-art Large Language Models (LLMs) achieve limited success in automating this task. To address this limitation, we tune a specialized model for environment setup. We combine supervised fine-tuning for generating correct Bash scripts and Reinforcement Learning with Verifiable Rewards (RLVR) to adapt it to the task of environment setup. On EnvBench-Python, our method enables Qwen3-8B (a model runnable on consumer hardware) to perform on par with larger models-Qwen3-32B and GPT-4o. The training code and model checkpoints are available online: this https URL.', 'abstract_zh': '环境配置——软件工程中配置系统以与特定软件项目协同工作的过程——代表了持续的挑战。自动环境配置方法可以通过提供无需人工努力即可完全配置的环境来协助开发人员，并且还可以帮助软件工程研究人员扩大基于执行的基准测试。然而，近期的研究表明，即使是最先进的大语言模型（LLMs）在自动化这一任务方面也取得有限的成功。为了解决这一局限性，我们针对环境配置微调了一个专门的模型。我们结合监督微调生成正确的Bash脚本，并结合可验证奖励强化学习（RLVR）使其适应环境配置任务。在EnvBench-Python上，我们的方法使Qwen3-8B（可在消费者硬件上运行的模型）能够与更大规模的模型Qwen3-32B和GPT-4o表现相当。训练代码和模型检查点已在线提供：this https URL。', 'title_zh': 'PIPer：基于在线强化学习的设备端环境设置'}
{'arxiv_id': 'arXiv:2509.25450', 'title': 'Multi-patch isogeometric neural solver for partial differential equations on computer-aided design domains', 'authors': 'Moritz von Tresckow, Ion Gabriel Ion, Dimitrios Loukrezis', 'link': 'https://arxiv.org/abs/2509.25450', 'abstract': 'This work develops a computational framework that combines physics-informed neural networks with multi-patch isogeometric analysis to solve partial differential equations on complex computer-aided design geometries. The method utilizes patch-local neural networks that operate on the reference domain of isogeometric analysis. A custom output layer enables the strong imposition of Dirichlet boundary conditions. Solution conformity across interfaces between non-uniform rational B-spline patches is enforced using dedicated interface neural networks. Training is performed using the variational framework by minimizing the energy functional derived after the weak form of the partial differential equation. The effectiveness of the suggested method is demonstrated on two highly non-trivial and practically relevant use-cases, namely, a 2D magnetostatics model of a quadrupole magnet and a 3D nonlinear solid and contact mechanics model of a mechanical holder. The results show excellent agreement to reference solutions obtained with high-fidelity finite element solvers, thus highlighting the potential of the suggested neural solver to tackle complex engineering problems given the corresponding computer-aided design models.', 'abstract_zh': '基于物理 informant 的神经网络与多区域IGA相结合的计算框架：复杂计算机辅助设计几何上的偏微分方程求解', 'title_zh': '用于计算机辅助设计域上偏微分方程的多片异质几何神经求解器'}
{'arxiv_id': 'arXiv:2509.25449', 'title': 'Joint Embeddings Go Temporal', 'authors': 'Sofiane Ennadir, Siavash Golkar, Leopoldo Sarra', 'link': 'https://arxiv.org/abs/2509.25449', 'abstract': 'Self-supervised learning has seen great success recently in unsupervised representation learning, enabling breakthroughs in natural language and image processing. However, these methods often rely on autoregressive and masked modeling, which aim to reproduce masked information in the input, which can be vulnerable to the presence of noise or confounding variables. To address this problem, Joint-Embedding Predictive Architectures (JEPA) has been introduced with the aim to perform self-supervised learning in the latent space. To leverage these advancements in the domain of time series, we introduce Time Series JEPA (TS-JEPA), an architecture specifically adapted for time series representation learning. We validate TS-JEPA on both classification and forecasting, showing that it can match or surpass current state-of-the-art baselines on different standard datasets. Notably, our approach demonstrates a strong performance balance across diverse tasks, indicating its potential as a robust foundation for learning general representations. Thus, this work lays the groundwork for developing future time series foundation models based on Joint Embedding.', 'abstract_zh': '自监督学习在无监督表征学习中取得了巨大成功，尤其是在自然语言和图像处理领域。然而，这些方法往往依赖于自回归和掩码建模，旨在重现输入中的掩码信息，这在噪声或混杂变量存在的情况下可能会变得脆弱。为了解决这一问题，引入了联合嵌入预测架构（JEPA），旨在在潜在空间中进行自监督学习。为了在时间序列领域利用这些进展，我们提出了时间序列JEPA（TS-JEPA），一种专门适应时间序列表征学习的架构。我们通过分类和预测任务验证了TS-JEPA，结果显示它在不同标准数据集上可以匹配或超越当前最先进的基线方法。值得注意的是，我们的方法在多种任务上展现出强大的性能平衡，表明其作为稳健的学习通用表征基础的潜力。因此，这项工作为基于联合嵌入发展未来的时间序列基础模型奠定了基础。', 'title_zh': 'Joint Embeddings Go Temporal'}
{'arxiv_id': 'arXiv:2509.25438', 'title': 'Beyond Noisy-TVs: Noise-Robust Exploration Via Learning Progress Monitoring', 'authors': 'Zhibo Hou, Zhiyu An, Wan Du', 'link': 'https://arxiv.org/abs/2509.25438', 'abstract': "When there exists an unlearnable source of randomness (noisy-TV) in the environment, a naively intrinsic reward driven exploring agent gets stuck at that source of randomness and fails at exploration. Intrinsic reward based on uncertainty estimation or distribution similarity, while eventually escapes noisy-TVs as time unfolds, suffers from poor sample efficiency and high computational cost. Inspired by recent findings from neuroscience that humans monitor their improvements during exploration, we propose a novel method for intrinsically-motivated exploration, named Learning Progress Monitoring (LPM). During exploration, LPM rewards model improvements instead of prediction error or novelty, effectively rewards the agent for observing learnable transitions rather than the unlearnable transitions. We introduce a dual-network design that uses an error model to predict the expected prediction error of the dynamics model in its previous iteration, and use the difference between the model errors of the current iteration and previous iteration to guide exploration. We theoretically show that the intrinsic reward of LPM is zero-equivariant and a monotone indicator of Information Gain (IG), and that the error model is necessary to achieve monotonicity correspondence with IG. We empirically compared LPM against state-of-the-art baselines in noisy environments based on MNIST, 3D maze with 160x120 RGB inputs, and Atari. Results show that LPM's intrinsic reward converges faster, explores more states in the maze experiment, and achieves higher extrinsic reward in Atari. This conceptually simple approach marks a shift-of-paradigm of noise-robust exploration. For code to reproduce our experiments, see this https URL", 'abstract_zh': '当环境中存在无法学习的随机性来源（noisy-TV）时，一个简单的固有奖励驱动探索代理会被困在该随机性来源处并无法进行探索。基于不确定性估计或分布相似度的固有奖励最终会摆脱noisy-TV，但会遭受样本效率低和高计算成本的问题。受近期神经科学研究中关于人类在探索过程中监测自身改进的发现启发，我们提出了一种新的固有动机探索方法，称为学习进展监控（LPM）。在探索过程中，LPM奖励模型改进而非预测误差或新颖性，有效地奖励代理观测可学习的转换而非不可学习的转换。我们引入了一种双网络设计，使用一个误差模型来预测动力学模型上一次迭代的预期预测误差，并利用当前迭代和上次迭代模型误差的差异来引导探索。我们从理论上证明，LPM的固有奖励是零等变的并是信息增益（IG）的单调指标，误差模型对于实现与IG的单调性对应是必要的。我们在基于MNIST、160x120 RGB输入的3D迷宫以及Atari的嘈杂环境中，LPM与最新基准方法进行了比较。结果显示，LPM的固有奖励收敛更快，在迷宫实验中探索更多的状态，并在Atari中获得更高的外部奖励。这一概念上简单的办法标志着噪声鲁棒探索范式的转变。有关我们实验的可复现代码，请参见此链接。', 'title_zh': '超越嘈杂电视：通过学习进度监测实现噪声稳健探索'}
{'arxiv_id': 'arXiv:2509.25424', 'title': 'Polychromic Objectives for Reinforcement Learning', 'authors': 'Jubayer Ibn Hamid, Ifdita Hasan Orney, Ellen Xu, Chelsea Finn, Dorsa Sadigh', 'link': 'https://arxiv.org/abs/2509.25424', 'abstract': 'Reinforcement learning fine-tuning (RLFT) is a dominant paradigm for improving pretrained policies for downstream tasks. These pretrained policies, trained on large datasets, produce generations with a broad range of promising but unrefined behaviors. Often, a critical failure mode of RLFT arises when policies lose this diversity and collapse into a handful of easily exploitable outputs. This convergence hinders exploration, which is essential for expanding the capabilities of the pretrained policy and for amplifying the benefits of test-time compute scaling. To address this, we introduce an objective for policy gradient methods that explicitly enforces the exploration and refinement of diverse generations, which we call a polychromic objective. We then show how proximal policy optimization (PPO) can be adapted to optimize this objective. Our method (1) employs vine sampling to collect on-policy rollouts and (2) modifies the advantage function to reflect the advantage under our new objective. Experiments on BabyAI, Minigrid, and Algorithmic Creativity show that our method improves success rates by reliably solving a larger set of environment configurations and generalizes better under large perturbations. Moreover, when given multiple attempts in pass@$k$ experiments, the policy achieves substantially higher coverage, demonstrating its ability to maintain and exploit a diverse repertoire of strategies.', 'abstract_zh': 'reinforcement learning fine-tuning (RLFT) 是改进预训练策略以适应下游任务的主要范式。这些预训练策略在大规模数据集上训练，会产生具有广泛潜力但未精炼的行为。当策略失去这种多样性并收敛于少数易于利用的输出时，RLFT 的一个关键失败模式就会出现。这种收敛阻碍了探索，这对于扩展预训练策略的能力以及放大测试时计算扩展的好处至关重要。为了解决这一问题，我们提出了一种显式促进多样生成的策略梯度方法的目标，称为多色目标。然后，我们展示了如何通过近端策略优化（PPO）来优化这一目标。我们的方法（1）采用藤蔓采样收集在线策略轨迹，并（2）修改优势函数以反映在我们新目标下的优势。在 BabyAI、Minigrid 和 算法创造力 上的实验表明，我们的方法通过更可靠地解决更多的环境配置并能更好地适应大型扰动来提高成功率。此外，在 pass@$k$ 实验中给予策略多次尝试时，其覆盖率明显提高，展示了其维持和利用多样化策略组合的能力。', 'title_zh': '多色目标强化学习'}
{'arxiv_id': 'arXiv:2509.25416', 'title': 'Emotion-Aligned Generation in Diffusion Text to Speech Models via Preference-Guided Optimization', 'authors': 'Jiacheng Shi, Hongfei Du, Yangfan He, Y. Alicia Hong, Ye Gao', 'link': 'https://arxiv.org/abs/2509.25416', 'abstract': 'Emotional text-to-speech seeks to convey affect while preserving intelligibility and prosody, yet existing methods rely on coarse labels or proxy classifiers and receive only utterance-level feedback. We introduce Emotion-Aware Stepwise Preference Optimization (EASPO), a post-training framework that aligns diffusion TTS with fine-grained emotional preferences at intermediate denoising steps. Central to our approach is EASPM, a time-conditioned model that scores noisy intermediate speech states and enables automatic preference pair construction. EASPO optimizes generation to match these stepwise preferences, enabling controllable emotional shaping. Experiments show superior performance over existing methods in both expressiveness and naturalness.', 'abstract_zh': '情感文本转语音旨在传达情感同时保持可懂度和语调，但现有方法依赖于粗略的标签或替代分类器，并仅接收句级反馈。我们引入了情感感知分步偏好优化（EASPO），这是一种后训练框架，将扩散TTS与中间去噪步骤中的细粒度情感偏好对齐。我们方法的核心是EASPM，这是一种时间条件模型，用于评分嘈杂的中间语音状态，并能够自动构建偏好配对。EASPO 优化生成以匹配这些分步偏好，从而实现可控的情感塑造。实验结果显示在表达性和自然度上均优于现有方法。', 'title_zh': '面向偏好吃引导优化的情感对齐生成在扩散文本到语音模型中'}
{'arxiv_id': 'arXiv:2509.25414', 'title': 'Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs', 'authors': 'Hao Ban, Kaiyi Ji', 'link': 'https://arxiv.org/abs/2509.25414', 'abstract': 'Large language models are often adapted using parameter-efficient techniques such as Low-Rank Adaptation (LoRA), formulated as $y = W_0x + BAx$, where $W_0$ is the pre-trained parameters and $x$ is the input to the adapted layer. While multi-adapter extensions often employ multiple LoRAs, prior studies suggest that the inner $A$ matrices are highly similar during training and thus suitable for sharing. We revisit this phenomenon and find that this similarity is largely attributable to the identical initialization rather than shared knowledge, with $B$ playing a more critical role in knowledge encoding and transfer. Motivated by these insights, we propose \\textbf{ALoRA}, an asymmetric multi-LoRA design with multiple $A$ matrices and a single shared $B$ in multi-task fine-tuning, and \\textbf{Fed-ALoRA}, which shares $B$ across clients in federated fine-tuning under both homogeneous and heterogeneous settings, through a novel matrix decomposition strategy to accommodate heterogeneous ranks across clients. Experiments on commonsense reasoning, math reasoning, multi-task NLP dataset, and federated NLP dataset demonstrate that our methods achieve more balanced performance across tasks with comparable or superior average accuracy relative to existing multi-LoRA approaches. Codes are available at this https URL.', 'abstract_zh': '大型语言模型通常通过参数高效技术进行调整，如低秩适应（LoRA），表示为 $y = W_0x + BAx$，其中 $W_0$ 是预训练参数，$x$ 是调整层的输入。虽然多adapter扩展通常使用多个LoRA，但先前的研究表明，训练中的内部 $A$ 矩阵高度相似，因此适合作为共享对象。我们重新审视了这一现象，发现这种相似性主要是由于相同的初始化而非共享知识所导致，$B$ 在知识编码和转移中扮演着更为关键的角色。受此见解启发，我们提出了一种多LoRA设计——ALoRA，该设计在多任务微调中具有多个 $A$ 矩阵和一个共享的 $B$。此外，我们提出了Fed-ALoRA，在homogeneous和heterogeneous设置下的联邦微调中通过一种新型的矩阵分解策略在客户端之间共享 $B$，以适应客户端之间不同的秩。在常识推理、数学推理、多任务NLP数据集和联邦NLP数据集上进行的实验表明，我们的方法在各任务上实现了更加均衡的表现，相对于现有的多LoRA方法，平均准确率相当或更好。相关代码可从以下链接获取。', 'title_zh': '多LoRA参数共享重思以进行LLM微调'}
{'arxiv_id': 'arXiv:2509.25409', 'title': 'From Faithfulness to Correctness: Generative Reward Models that Think Critically', 'authors': 'Qiyao Ma, Yunsheng Shi, Hongtao Tian, Chao Wang, Weiming Chang, Ting Yao', 'link': 'https://arxiv.org/abs/2509.25409', 'abstract': 'Through reinforcement learning with verifiable rewards (RLVR), large language models have achieved substantial progress in domains with easily verifiable outcomes, such as mathematics and coding. However, when applied to more complex tasks like open-domain question answering, RLVR faces significant challenges due to the difficulty of verifying correctness. The nuanced and ambiguous nature of real-world knowledge makes it difficult to reliably evaluate correctness in these settings, necessitating further abilities that extend beyond mere logical consistency to encompass an understanding and assessment of both external and internal knowledge. Recent work has primarily focused on improving faithfulness, defined as semantic alignment with supporting documents, which can cause models to rely excessively on external sources and diminish their capacity for critical assessment. To address this, we propose the Thinking-supervised Reward Model (TRM), which incorporates sentence-level thinking supervision to endow reward models with critical thinking abilities. Given a query, answer, and supporting documents, TRM first assesses the faithfulness of each answer sentence to the supporting documents, and then applies a reasoning step to evaluate sentence-level correctness. By structuring reward modeling as a sequence of faithfulness, reasoning, and correctness evaluations, TRM encourages models to critically assess and leverage both external and internal knowledge. Experiments on reward signals demonstrate that TRM substantially improves the identification of incorrect sentences, and incorporating TRM into policy optimization leads to significant gains in both answer correctness and usefulness.', 'abstract_zh': '通过可验证奖励的强化学习（RLVR）：大语言模型在数学和编程等具有易于验证结果的领域取得了显著进展。然而，在应用于更复杂的任务如开放领域问答时，RLVR由于正确性验证的困难而面临重大挑战。现实世界的知识具有细微和模糊的性质，使得在这些环境中可靠地评估正确性变得困难，这要求进一步的能力，超越仅仅是逻辑一致性，涵盖对外部和内部知识的理解和评估。近期的工作主要集中在提高忠实性方面，定义为语义上与支持文档的一致性，这可能导致模型过度依赖外部来源，并削弱其批判性评估的能力。为了解决这一问题，我们提出了一种思考监督奖励模型（TRM），它通过句子级别的思考监督赋予奖励模型批判性思维能力。给定一个查询、答案和支持文档，TRM 首先评估每个答案句子与支持文档的忠实性，然后执行推理步骤来评估句子级别的正确性。通过将奖励建模结构化为忠实性、推理和正确性评估的序列，TRM 鼓励模型批判性地评估和利用外部和内部知识。实验结果表明，TRM 显著提高了错误句子的识别准确性，将 TRM 集成到策略优化中导致了答案正确性和有用性的显著提高。', 'title_zh': '从忠实到正确：批判性生成奖励模型'}
{'arxiv_id': 'arXiv:2509.25401', 'title': 'FlashOmni: A Unified Sparse Attention Engine for Diffusion Transformers', 'authors': 'Liang Qiao, Yue Dai, Yeqi Huang, Hongyu Kan, Jun Shi, Hong An', 'link': 'https://arxiv.org/abs/2509.25401', 'abstract': 'Multi-Modal Diffusion Transformers (DiTs) demonstrate exceptional capabilities in visual synthesis, yet their deployment remains constrained by substantial computational demands. To alleviate this bottleneck, many sparsity-based acceleration methods have been proposed. However, their diverse sparsity patterns often require customized kernels for high-performance inference, limiting universality. We propose FlashOmni, a unified sparse attention engine compatible with arbitrary DiT architectures. FlashOmni introduces flexible sparse symbols to standardize the representation of a wide range of sparsity strategies, such as feature caching and block-sparse skipping. This unified abstraction enables the execution of diverse sparse computations within a single attention kernel. In addition, FlashOmni designs optimized sparse GEMMs for attention blocks, leveraging sparse symbols to eliminate redundant computations and further improve efficiency. Experiments demonstrate that FlashOmni delivers near-linear, closely matching the sparsity ratio speedup (1:1) in attention and GEMM-$Q$, and achieves 2.5$\\times$-3.8$\\times$ acceleration in GEMM-$O$ (max peaking at about 87.5% of the theoretical limit). Applied with a multi-granularity sparsity strategy, it enables the Hunyuan model (33K) to achieve about 1.5$\\times$ end-to-end acceleration without degrading visual quality.', 'abstract_zh': '多模态扩散变换器（DiTs）在视觉合成方面展示了卓越的能力，但其部署仍受限于巨大的计算需求。为缓解这一瓶颈，已经提出了多种基于稀疏性的加速方法。然而，这些方法多样化的稀疏模式通常需要定制内核以实现高性能推理，限制了通用性。我们提出了FlashOmni，这是一种兼容任意DiT架构的统一稀疏注意力引擎。FlashOmni引入灵活的稀疏符号以标准化各种稀疏策略（如特征缓存和块稀疏跳过）的表示。这种统一的抽象使得在单一注意力内核中执行多种稀疏计算成为可能。此外，FlashOmni针对注意力块设计了优化的稀疏GEMM，利用稀疏符号消除冗余计算，进一步提高效率。实验表明，FlashOmni实现了接近线性的加速，接近注意力和GEMM-$Q$稀疏率加速（1:1），在GEMM-$O$中实现了2.5至3.8倍的加速（峰值可达理论极限的约87.5%）。结合多粒度稀疏策略，它使Hunyuan模型（33K）在不牺牲视觉质量的情况下实现了约1.5倍的端到端加速。', 'title_zh': 'FlashOmni：统一稀疏注意力引擎for扩散变换器'}
{'arxiv_id': 'arXiv:2509.25397', 'title': 'A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects', 'authors': 'Johan Linåker, Cailean Osborne, Jennifer Ding, Ben Burtenshaw', 'link': 'https://arxiv.org/abs/2509.25397', 'abstract': 'The proliferation of open large language models (LLMs) is fostering a vibrant ecosystem of research and innovation in artificial intelligence (AI). However, the methods of collaboration used to develop open LLMs both before and after their public release have not yet been comprehensively studied, limiting our understanding of how open LLM projects are initiated, organized, and governed as well as what opportunities there are to foster this ecosystem even further. We address this gap through an exploratory analysis of open collaboration throughout the development and reuse lifecycle of open LLMs, drawing on semi-structured interviews with the developers of 14 open LLMs from grassroots projects, research institutes, startups, and Big Tech companies in North America, Europe, Africa, and Asia. We make three key contributions to research and practice. First, collaboration in open LLM projects extends far beyond the LLMs themselves, encompassing datasets, benchmarks, open source frameworks, leaderboards, knowledge sharing and discussion forums, and compute partnerships, among others. Second, open LLM developers have a variety of social, economic, and technological motivations, from democratizing AI access and promoting open science to building regional ecosystems and expanding language representation. Third, the sampled open LLM projects exhibit five distinct organizational models, ranging from single company projects to non-profit-sponsored grassroots projects, which vary in their centralization of control and community engagement strategies used throughout the open LLM lifecycle. We conclude with practical recommendations for stakeholders seeking to support the global community building a more open future for AI.', 'abstract_zh': '开放大型语言模型（LLMs）的涌现正推动人工智能（AI）研究与创新的蓬勃发展。然而，开放LLMs在其公开发布前后开发过程中所采用的协作方法尚未进行全面研究，限制了我们对开放LLMs项目是如何启动、组织和管理的理解，以及进一步培育这一生态系统的机会。我们通过对来自北美、欧洲、非洲和亚洲的草根项目、研究机构、初创公司和大科技公司的14个开放LLMs开发者的半结构化访谈，开展了探索性分析，填补了这一研究空白。我们的研究为研究和实践做出了三个重要贡献。首先，开放LLMs项目的协作远远超出了LLMs本身，还有数据集、基准测试、开源框架、排行榜、知识共享和讨论论坛以及计算合作伙伴等方面。其次，开放LLMs开发者的动机多种多样，包括使AI普及、推动开放科学、构建区域生态系统和扩展语言代表性等。第三，采样的开放LLMs项目展示了五种不同的组织模型，从单公司项目到由非营利组织赞助的草根项目，这些模型在控制的中心性和在整个开放LLMs生命周期中使用的社区参与策略方面存在差异。最后，我们提出了针对支持构建更加开放的AI未来的全球社区的实用建议。', 'title_zh': '开源协作在开源AI领域的地图绘制：14个开源大规模语言模型项目的合作实践、动机与治理mapping'}
{'arxiv_id': 'arXiv:2509.25393', 'title': 'A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland', 'authors': 'Wendong Yao, Binhua Huang, Soumyabrata Dev', 'link': 'https://arxiv.org/abs/2509.25393', 'abstract': "Forecasting high-resolution land subsidence is a critical yet challenging task due to its complex, non-linear dynamics. While standard architectures like ConvLSTM often fail to model long-range dependencies, we argue that a more fundamental limitation of prior work lies in the uni-modal data paradigm. To address this, we propose the Multi-Modal Spatio-Temporal Transformer (MM-STT), a novel framework that fuses dynamic displacement data with static physical priors. Its core innovation is a joint spatio-temporal attention mechanism that processes all multi-modal features in a unified manner. On the public EGMS dataset, MM-STT establishes a new state-of-the-art, reducing the long-range forecast RMSE by an order of magnitude compared to all baselines, including SOTA methods like STGCN and STAEformer. Our results demonstrate that for this class of problems, an architecture's inherent capacity for deep multi-modal fusion is paramount for achieving transformative performance.", 'abstract_zh': '高分辨率土地沉降的预测是一项由于其复杂的非线性动态而关键且具有挑战性的任务。尽管标准架构如ConvLSTM经常无法建模长程依赖性，我们认为先前工作的根本限制在于单模态数据范式。为了解决这一问题，我们提出了一种新型的多模态时空变换器（MM-STT）框架，该框架将动态位移数据与静态物理先验信息融合。其核心创新是一种联合时空注意力机制，能够统一处理所有多模态特征。在公共EGMS数据集上，MM-STT建立了新的基线，与包括SOTA方法STGCN和STAEformer在内的所有基线相比，将其长程预测RMSE降低了数量级。我们的结果表明，对于此类问题，架构本身对深度多模态融合的内在能力是实现变革性性能的关键。', 'title_zh': '基于深度学习的InSAR地面变形时空预测方法：以爱尔兰东部为例'}
{'arxiv_id': 'arXiv:2509.25390', 'title': 'SpinBench: Perspective and Rotation as a Lens on Spatial Reasoning in VLMs', 'authors': 'Yuyou Zhang, Radu Corcodel, Chiori Hori, Anoop Cherian, Ding Zhao', 'link': 'https://arxiv.org/abs/2509.25390', 'abstract': 'We present SpinBench, a cognitively grounded diagnostic benchmark for evaluating spatial reasoning in vision language models (VLMs). SpinBench is designed around the core challenge of spatial reasoning: perspective taking, the ability to reason about how scenes and object relations change under viewpoint transformation. Since perspective taking requires multiple cognitive capabilities, such as recognizing objects across views, relative positions grounding, and mentally simulating transformations, SpinBench introduces a set of fine-grained diagnostic categories. Our categories target translation, rotation, object relative pose, and viewpoint change, and are progressively structured so that single-object simpler tasks scaffold toward the most demanding multi-object perspective-taking setting. We evaluate 37 state-of-the-art VLMs, both proprietary and open source. Results reveal systematic weaknesses: strong egocentric bias, poor rotational understanding, and inconsistencies under symmetrical and syntactic reformulations. Scaling analysis shows both smooth improvements and emergent capabilities. While human subjects achieve high accuracy (91.2\\%), task difficulty as measured by human response time shows strong correlation with VLM accuracy, indicating that SpinBench captures spatial reasoning challenges shared across humans and VLMs. We believe SpinBench provides critical insights into spatial reasoning in VLMs and highlights key gaps in their ability to reason about physical space. Our website can be found at this https URL.', 'abstract_zh': '我们介绍SpinBench：一种基于认知的心理诊断基准，用于评估视觉语言模型的空间推理能力', 'title_zh': 'SpinBench: 观点与旋转作为空间推理在VLMs中的透镜'}
{'arxiv_id': 'arXiv:2509.25380', 'title': 'Predicting Training Re-evaluation Curves Enables Effective Data Curriculums for LLMs', 'authors': 'Shane Bergsma, Nolan Dey, Joel Hestness', 'link': 'https://arxiv.org/abs/2509.25380', 'abstract': "Data curriculums have become central to successful LLM training, yet principles governing optimal data placement remain unclear. We introduce the *training re-evaluation curve (TREC)*, a diagnostic that retrospectively evaluates training batches *using the final model weights*. The TREC characterizes how well a trained model retains training data as a function of *when* the data was encountered during training. Analyzing TRECs for models from 111M to 3.9B parameters, we show that placing high-quality data at low points on the TREC significantly improves performance. Importantly, while a TREC is initially observable only after training, we demonstrate it can be *predicted in advance* from AdamW's implicit EMA coefficients, enabling proactive curriculum design. By predicting TRECs for published training recipes, we explain prior ablations and reveal suboptimal data placements. We also align high-quality data with TREC minima in order to improve continual pre-training of a 3.9B-parameter LLM trained on 900B tokens.", 'abstract_zh': '数据课程已成为成功训练大型语言模型的核心，但最佳数据放置原则仍然不够清晰。我们引入了*训练重新评估曲线（TREC）*，这是一种回顾性诊断工具，使用最终模型权重来评估训练批次。TREC 表征了训练数据在模型训练过程中不同时点被遇到时，模型保留训练数据的能力。通过对参数从111M到3.9B的不同模型进行分析，我们发现将高质量数据放置在TREC的较低点可以显著提高性能。重要的是，虽然TREC仅在训练后才可观察到，但我们证明可以通过预测AdamW的隐式EWM系数来提前预测TREC，从而实现前瞻性的课程设计。通过预测公布的训练食谱的TREC，我们解释了先前的削减实验，并揭示了次优的数据放置。我们还将高质量数据与TREC的最小值对齐，以提高一个使用900B个标记训练的3.9B参数模型的持续预训练性能。', 'title_zh': '预测训练评估曲线以实现有效的LLM数据课程设计'}
{'arxiv_id': 'arXiv:2509.25379', 'title': 'Let Physics Guide Your Protein Flows: Topology-aware Unfolding and Generation', 'authors': 'Yogesh Verma, Markus Heinonen, Vikas Garg', 'link': 'https://arxiv.org/abs/2509.25379', 'abstract': 'Protein structure prediction and folding are fundamental to understanding biology, with recent deep learning advances reshaping the field. Diffusion-based generative models have revolutionized protein design, enabling the creation of novel proteins. However, these methods often neglect the intrinsic physical realism of proteins, driven by noising dynamics that lack grounding in physical principles. To address this, we first introduce a physically motivated non-linear noising process, grounded in classical physics, that unfolds proteins into secondary structures (e.g., alpha helices, linear beta sheets) while preserving topological integrity--maintaining bonds, and preventing collisions. We then integrate this process with the flow-matching paradigm on SE(3) to model the invariant distribution of protein backbones with high fidelity, incorporating sequence information to enable sequence-conditioned folding and expand the generative capabilities of our model. Experimental results demonstrate that the proposed method achieves state-of-the-art performance in unconditional protein generation, producing more designable and novel protein structures while accurately folding monomer sequences into precise protein conformations.', 'abstract_zh': '基于物理的蛋白质结构预测与折叠：物理学驱动的非线性去噪过程及其在蛋白质设计中的应用', 'title_zh': '基于物理的蛋白质流动导向：拓扑感知 unfolding 和生成'}
{'arxiv_id': 'arXiv:2509.25376', 'title': 'Cold-Start Active Correlation Clustering', 'authors': 'Linus Aronsson, Han Wu, Morteza Haghir Chehreghani', 'link': 'https://arxiv.org/abs/2509.25376', 'abstract': 'We study active correlation clustering where pairwise similarities are not provided upfront and must be queried in a cost-efficient manner through active learning. Specifically, we focus on the cold-start scenario, where no true initial pairwise similarities are available for active learning. To address this challenge, we propose a coverage-aware method that encourages diversity early in the process. We demonstrate the effectiveness of our approach through several synthetic and real-world experiments.', 'abstract_zh': '冷启动环境下成本敏感的活性聚类共生研究', 'title_zh': '冷启动主动相关聚类'}
{'arxiv_id': 'arXiv:2509.25369', 'title': 'Generative Value Conflicts Reveal LLM Priorities', 'authors': 'Andy Liu, Kshitish Ghate, Mona Diab, Daniel Fried, Atoosa Kasirzadeh, Max Kleiman-Weiner', 'link': 'https://arxiv.org/abs/2509.25369', 'abstract': 'Past work seeks to align large language model (LLM)-based assistants with a target set of values, but such assistants are frequently forced to make tradeoffs between values when deployed. In response to the scarcity of value conflict in existing alignment datasets, we introduce ConflictScope, an automatic pipeline to evaluate how LLMs prioritize different values. Given a user-defined value set, ConflictScope automatically generates scenarios in which a language model faces a conflict between two values sampled from the set. It then prompts target models with an LLM-written "user prompt" and evaluates their free-text responses to elicit a ranking over values in the value set. Comparing results between multiple-choice and open-ended evaluations, we find that models shift away from supporting protective values, such as harmlessness, and toward supporting personal values, such as user autonomy, in more open-ended value conflict settings. However, including detailed value orderings in models\' system prompts improves alignment with a target ranking by 14%, showing that system prompting can achieve moderate success at aligning LLM behavior under value conflict. Our work demonstrates the importance of evaluating value prioritization in models and provides a foundation for future work in this area.', 'abstract_zh': '基于大语言模型的价值优先级评估：ConflictScope自动管道研究', 'title_zh': '生成价值冲突揭示大模型优先级'}
{'arxiv_id': 'arXiv:2509.25359', 'title': 'From Internal Representations to Text Quality: A Geometric Approach to LLM Evaluation', 'authors': 'Viacheslav Yusupov, Danil Maksimov, Ameliia Alaeva, Anna Vasileva, Anna Antipina, Tatyana Zaitseva, Alina Ermilova, Evgeny Burnaev, Egor Shvetsov', 'link': 'https://arxiv.org/abs/2509.25359', 'abstract': 'This paper bridges internal and external analysis approaches to large language models (LLMs) by demonstrating that geometric properties of internal model representations serve as reliable proxies for evaluating generated text quality. We validate a set of metrics including Maximum Explainable Variance, Effective Rank, Intrinsic Dimensionality, MAUVE score, and Schatten Norms measured across different layers of LLMs, demonstrating that Intrinsic Dimensionality and Effective Rank can serve as universal assessments of text naturalness and quality. Our key finding reveals that different models consistently rank text from various sources in the same order based on these geometric properties, indicating that these metrics reflect inherent text characteristics rather than model-specific artifacts. This allows a reference-free text quality evaluation that does not require human-annotated datasets, offering practical advantages for automated evaluation pipelines.', 'abstract_zh': '这篇论文通过证明内部模型表示的几何性质可以作为评估生成文本质量的可靠代理，建立了内部和外部分析方法在大规模语言模型（LLMs）中的联系。我们验证了一系列指标，包括最大可解释方差、有效秩、固有维数、MAUVE分值和舒尔范数，这些指标在LLM的不同层上进行了测量，证明了固有维数和有效秩可以作为文本自然度和质量的通用评估标准。我们的关键发现表明，基于这些几何性质，不同模型能够以相同顺序对来自不同来源的文本进行排名，这表明这些指标反映了文本的内在特性而非模型特定的特征。这使得无需使用人工标注的数据集即可进行参考无关的文本质量评估，为自动化评估管道提供了实际优势。', 'title_zh': '从内部表示到文本质量：一种面向LLM评估的几何方法'}
{'arxiv_id': 'arXiv:2509.25339', 'title': 'VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes', 'authors': 'Paul Gavrikov, Wei Lin, M. Jehanzeb Mirza, Soumya Jahagirdar, Muhammad Huzaifa, Sivan Doveh, Serena Yeung-Levy, James Glass, Hilde Kuehne', 'link': 'https://arxiv.org/abs/2509.25339', 'abstract': 'Is basic visual understanding really solved in state-of-the-art VLMs? We present VisualOverload, a slightly different visual question answering (VQA) benchmark comprising 2,720 question-answer pairs, with privately held ground-truth responses. Unlike prior VQA datasets that typically focus on near global image understanding, VisualOverload challenges models to perform simple, knowledge-free vision tasks in densely populated (or, overloaded) scenes. Our dataset consists of high-resolution scans of public-domain paintings that are populated with multiple figures, actions, and unfolding subplots set against elaborately detailed backdrops. We manually annotated these images with questions across six task categories to probe for a thorough understanding of the scene. We hypothesize that current benchmarks overestimate the performance of VLMs, and encoding and reasoning over details is still a challenging task for them, especially if they are confronted with densely populated scenes. Indeed, we observe that even the best model (o3) out of 37 tested models only achieves 19.6% accuracy on our hardest test split and overall 69.5% accuracy on all questions. Beyond a thorough evaluation, we complement our benchmark with an error analysis that reveals multiple failure modes, including a lack of counting skills, failure in OCR, and striking logical inconsistencies under complex tasks. Altogether, VisualOverload exposes a critical gap in current vision models and offers a crucial resource for the community to develop better models.\nBenchmark: this http URL', 'abstract_zh': '基准数据集：这个链接', 'title_zh': '视觉过载：探究VLMs在Really Dense场景中的视觉理解能力'}
{'arxiv_id': 'arXiv:2509.25334', 'title': 'Uncertainty-Aware Generative Oversampling Using an Entropy-Guided Conditional Variational Autoencoder', 'authors': 'Amirhossein Zare, Amirhessam Zare, Parmida Sadat Pezeshki, Herlock, Rahimi, Ali Ebrahimi, Ignacio Vázquez-García, Leo Anthony Celi', 'link': 'https://arxiv.org/abs/2509.25334', 'abstract': "Class imbalance remains a major challenge in machine learning, especially for high-dimensional biomedical data where nonlinear manifold structures dominate. Traditional oversampling methods such as SMOTE rely on local linear interpolation, often producing implausible synthetic samples. Deep generative models like Conditional Variational Autoencoders (CVAEs) better capture nonlinear distributions, but standard variants treat all minority samples equally, neglecting the importance of uncertain, boundary-region examples emphasized by heuristic methods like Borderline-SMOTE and ADASYN.\nWe propose Local Entropy-Guided Oversampling with a CVAE (LEO-CVAE), a generative oversampling framework that explicitly incorporates local uncertainty into both representation learning and data generation. To quantify uncertainty, we compute Shannon entropy over the class distribution in a sample's neighborhood: high entropy indicates greater class overlap, serving as a proxy for uncertainty. LEO-CVAE leverages this signal through two mechanisms: (i) a Local Entropy-Weighted Loss (LEWL) that emphasizes robust learning in uncertain regions, and (ii) an entropy-guided sampling strategy that concentrates generation in these informative, class-overlapping areas.\nApplied to clinical genomics datasets (ADNI and TCGA lung cancer), LEO-CVAE consistently improves classifier performance, outperforming both traditional oversampling and generative baselines. These results highlight the value of uncertainty-aware generative oversampling for imbalanced learning in domains governed by complex nonlinear structures, such as omics data.", 'abstract_zh': '局部熵导向过采样结合条件变分自编码器（LEO-CVAE）：复杂非线性结构下不平衡学习中的生成过采样', 'title_zh': '基于熵引导条件变分自编码器的不确定性感知生成过采样方法'}
{'arxiv_id': 'arXiv:2509.25300', 'title': 'Scaling Behaviors of LLM Reinforcement Learning Post-Training: An Empirical Study in Mathematical Reasoning', 'authors': 'Zelin Tan, Hejia Geng, Mulei Zhang, Xiaohang Yu, Guancheng Wan, Yifan Zhou, Qiang He, Xiangyuan Xue, Heng Zhou, Yutao Fan, Zhongzhi Li, Zaibin Zhang, Guibin Zhang, Chen Zhang, Zhenfei Yin, Lei Bai', 'link': 'https://arxiv.org/abs/2509.25300', 'abstract': 'While scaling laws for large language models (LLMs) during pre-training have been extensively studied, their behavior under reinforcement learning (RL) post-training remains largely unexplored. This paper presents a systematic empirical investigation of scaling behaviors in RL-based post-training, with a particular focus on mathematical reasoning. Based on 54 experiments across diverse model sizes and training settings, we characterize how model scale, data volume, and computational budget interact to shape performance. Our analysis leads to four key findings: (1). Under a fixed computational budget, larger models trained for fewer steps consistently outperform smaller models trained for more steps. (2). Given a fixed amount of training data, larger models achieve superior sample efficiency, yielding lower loss. (3). In data-constrained regimes, repeated reuse of high-quality data proves highly effective, as final performance is primarily governed by the total number of optimization steps rather than the uniqueness of samples. (4). These scaling behaviors are robust across both base and instruction-tuned models, which share similar learning dynamics (e.g., larger models show faster convergence) even while differing in absolute accuracy. Collectively, these results provide a principled foundation and practical guidelines for efficiently scaling the reasoning capabilities of LLMs through RL post-training.', 'abstract_zh': '大型语言模型在强化学习后训练中的标度行为：数学推理视角的系统实证研究', 'title_zh': 'LLM reinforcement learning 后训练的标度行为：数学推理中的实证研究'}
{'arxiv_id': 'arXiv:2509.25297', 'title': 'Automatically Generating Web Applications from Requirements Via Multi-Agent Test-Driven Development', 'authors': 'Yuxuan Wan, Tingshuo Liang, Jiakai Xu, Jingyu Xiao, Yintong Huo, Michael R. Lyu', 'link': 'https://arxiv.org/abs/2509.25297', 'abstract': 'Developing full-stack web applications is complex and time-intensive, demanding proficiency across diverse technologies and frameworks. Although recent advances in multimodal large language models (MLLMs) enable automated webpage generation from visual inputs, current solutions remain limited to front-end tasks and fail to deliver fully functional applications. In this work, we introduce TDDev, the first test-driven development (TDD)-enabled LLM-agent framework for end-to-end full-stack web application generation. Given a natural language description or design image, TDDev automatically derives executable test cases, generates front-end and back-end code, simulates user interactions, and iteratively refines the implementation until all requirements are satisfied. Our framework addresses key challenges in full-stack automation, including underspecified user requirements, complex interdependencies among multiple files, and the need for both functional correctness and visual fidelity. Through extensive experiments on diverse application scenarios, TDDev achieves a 14.4% improvement on overall accuracy compared to state-of-the-art baselines, demonstrating its effectiveness in producing reliable, high-quality web applications without requiring manual intervention.', 'abstract_zh': '基于测试驱动的全栈网页应用生成LLM代理框架TDDev', 'title_zh': '根据需求通过多代理测试驱动开发自动生成Web应用程序'}
{'arxiv_id': 'arXiv:2509.25296', 'title': 'Learning Relationships Between Separate Audio Tracks for Creative Applications', 'authors': 'Balthazar Bujard, Jérôme Nika, Fédéric Bevilacqua, Nicolas Obin', 'link': 'https://arxiv.org/abs/2509.25296', 'abstract': "This paper presents the first step in a research project situated within the field of musical agents. The objective is to achieve, through training, the tuning of the desired musical relationship between a live musical input and a real-time generated musical output, through the curation of a database of separated tracks. We propose an architecture integrating a symbolic decision module capable of learning and exploiting musical relationships from such musical corpus. We detail an offline implementation of this architecture employing Transformers as the decision module, associated with a perception module based on Wav2Vec 2.0, and concatenative synthesis as audio renderer. We present a quantitative evaluation of the decision module's ability to reproduce learned relationships extracted during training. We demonstrate that our decision module can predict a coherent track B when conditioned by its corresponding ''guide'' track A, based on a corpus of paired tracks (A, B).", 'abstract_zh': '本文介绍了在音乐代理领域进行的研究项目的初步工作。目标是通过训练，在实时生成的音乐输出和现场音乐输入之间建立所需的音乐关系，通过构建分离轨道数据库来实现。我们提出了一种架构，该架构集成了一个象征性决策模块，能够从音乐语料库中学习和利用音乐关系。我们使用Transformer作为决策模块，并结合基于Wav2Vec 2.0的感知模块以及拼接合成作为音频渲染器，实现了一个离线实施的架构。我们对决策模块在训练中学习关系的能力进行了定量评估。我们证明，当基于一对轨道（A, B）的语料库进行条件限制时，我们的决策模块可以根据对应的“指导”轨道A预测出一致的轨道B。', 'title_zh': '学习分离音频轨之间的关系以应用于创意领域'}
{'arxiv_id': 'arXiv:2509.25293', 'title': 'AI in Pakistani Schools: Adoption, Usage, and Perceived Impact among Educators', 'authors': 'Syed Hassan Raza, Azib Farooq', 'link': 'https://arxiv.org/abs/2509.25293', 'abstract': "Artificial Intelligence (AI) is increasingly permeating classrooms worldwide, yet its adoption in schools of developing countries remains under-explored. This paper investigates AI adoption, usage patterns, and perceived impact in Pakistani K-12 schools based on a survey of 125 educators. The questionnaire covered educator's familiarity with AI, frequency and modes of use, and attitudes toward AI's benefits and challenges. Results reveal a generally positive disposition towards AI: over two-thirds of teachers expressed willingness to adopt AI tools given proper support and many have begun integrating AI for lesson planning and content creation. However, AI usage is uneven - while about one-third of respondents actively use AI tools frequently, others remain occasional users. Content generation emerged as the most common AI application, whereas AI-driven grading and feedback are rarely used. Teachers reported moderate improvements in student engagement and efficiency due to AI, but also voiced concerns about equitable access. These findings highlight both the enthusiasm for AI's potential in Pakistan's schools and the need for training and infrastructure to ensure inclusive and effective implementation.", 'abstract_zh': '人工智能（AI）在全球 Classroom 中越来越普及，但其在发展中国家学校的采用情况仍然研究不足。本文基于对125名教育者的调查，探讨了巴基斯坦K-12学校中AI的采用、使用模式及其感知影响。问卷涵盖了教育者对AI的熟悉度、使用频率和方式，以及对AI益处和挑战的态度。结果显示，教育者普遍对AI持正面态度：超过三分之二的教师表示，在获得适当支持的情况下愿意采用AI工具，且许多教师已经开始将其应用于课程规划和内容创作。然而，AI的使用并不均衡——约三分之一的受访者频繁使用AI工具，而其他人则偶尔使用。内容生成是AI最常见的应用，而AI驱动的评分和反馈则很少使用。教师报告称，AI在提高学生参与度和效率方面带来了适度的改进，但也表达了关于公平获取的担忧。这些发现突显了巴基斯坦学校中对AI潜力的热情，同时也强调了培训和基础设施的需要，以确保包容性和有效的实施。', 'title_zh': 'AI在巴基斯坦学校中的应用、使用及其对教育者 perceived impact 分析'}
{'arxiv_id': 'arXiv:2509.25292', 'title': 'A Measurement Study of Model Context Protocol', 'authors': 'Hechuan Guo, Yongle Hao, Yue Zhang, Minghui Xu, Peizhuo Lyu, Jiezhi Chen, Xiuzhen Cheng', 'link': 'https://arxiv.org/abs/2509.25292', 'abstract': 'The Model Context Protocol (MCP) has been proposed as a unifying standard for connecting large language models (LLMs) with external tools and resources, promising the same role for AI integration that HTTP and USB played for the Web and peripherals. Yet, despite rapid adoption and hype, its trajectory remains uncertain. Are MCP marketplaces truly growing, or merely inflated by placeholders and abandoned prototypes? Are servers secure and privacy-preserving, or do they expose users to systemic risks? And do clients converge on standardized protocols, or remain fragmented across competing designs? In this paper, we present the first large-scale empirical study of the MCP ecosystem. We design and implement MCPCrawler, a systematic measurement framework that collects and normalizes data from six major markets. Over a 14-day campaign, MCPCrawler aggregated 17,630 raw entries, of which 8,401 valid projects (8,060 servers and 341 clients) were analyzed. Our results reveal that more than half of listed projects are invalid or low-value, that servers face structural risks including dependency monocultures and uneven maintenance, and that clients exhibit a transitional phase in protocol and connection patterns. Together, these findings provide the first evidence-based view of the MCP ecosystem, its risks, and its future trajectory.', 'abstract_zh': 'MCP生态系统的首次大规模实证研究：发现与未来轨迹', 'title_zh': '模型上下文协议的测量研究'}
{'arxiv_id': 'arXiv:2509.25289', 'title': 'ClustRecNet: A Novel End-to-End Deep Learning Framework for Clustering Algorithm Recommendation', 'authors': 'Mohammadreza Bakhtyari, Bogdan Mazoure, Renato Cordeiro de Amorim, Guillaume Rabusseau, Vladimir Makarenkov', 'link': 'https://arxiv.org/abs/2509.25289', 'abstract': 'We introduce ClustRecNet - a novel deep learning (DL)-based recommendation framework for determining the most suitable clustering algorithms for a given dataset, addressing the long-standing challenge of clustering algorithm selection in unsupervised learning. To enable supervised learning in this context, we construct a comprehensive data repository comprising 34,000 synthetic datasets with diverse structural properties. Each of them was processed using 10 popular clustering algorithms. The resulting clusterings were assessed via the Adjusted Rand Index (ARI) to establish ground truth labels, used for training and evaluation of our DL model. The proposed network architecture integrates convolutional, residual, and attention mechanisms to capture both local and global structural patterns from the input data. This design supports end-to-end training to learn compact representations of datasets and enables direct recommendation of the most suitable clustering algorithm, reducing reliance on handcrafted meta-features and traditional Cluster Validity Indices (CVIs). Comprehensive experiments across synthetic and real-world benchmarks demonstrate that our DL model consistently outperforms conventional CVIs (e.g. Silhouette, Calinski-Harabasz, Davies-Bouldin, and Dunn) as well as state-of-the-art AutoML clustering recommendation approaches (e.g. ML2DAC, AutoCluster, and AutoML4Clust). Notably, the proposed model achieves a 0.497 ARI improvement over the Calinski-Harabasz index on synthetic data and a 15.3% ARI gain over the best-performing AutoML approach on real-world data.', 'abstract_zh': '一种基于深度学习的新型聚类算法推荐框架：ClustRecNet', 'title_zh': 'ClustRecNet：一种新颖的端到端深度学习框架用于聚类算法推荐'}
{'arxiv_id': 'arXiv:2509.25286', 'title': 'Artificial Authority: From Machine Minds to Political Alignments. An Experimental Analysis of Democratic and Autocratic Biases in Large-Language Models', 'authors': 'Szymon Łukasik, Natalia Ożegalska-Łukasik', 'link': 'https://arxiv.org/abs/2509.25286', 'abstract': "Political beliefs vary significantly across different countries, reflecting distinct historical, cultural, and institutional contexts. These ideologies, ranging from liberal democracies to rigid autocracies, influence human societies, as well as the digital systems that are constructed within those societies. The advent of generative artificial intelligence, particularly Large Language Models (LLMs), introduces new agents in the political space-agents trained on massive corpora that replicate and proliferate socio-political assumptions. This paper analyses whether LLMs display propensities consistent with democratic or autocratic world-views. We validate this insight through experimental tests in which we experiment with the leading LLMs developed across disparate political contexts, using several existing psychometric and political orientation measures. The analysis is based on both numerical scoring and qualitative analysis of the models' responses. Findings indicate high model-to-model variability and a strong association with the political culture of the country in which the model was developed. These findings highlight the need for more detailed examination of the socio-political dimensions embedded within AI systems.", 'abstract_zh': '政治信念在不同国家之间存在显著差异，反映了不同的历史、文化和制度背景。这些从自由民主到严格独裁的各种意识形态影响人类社会，以及构建于这些社会之中的数字系统。生成式人工智能，尤其是大型语言模型（LLMs），引入了新的政治空间代理——这些模型基于大量语料库训练，复制和传播社会政治假设。本文分析LLMs是否表现出与民主或集权世界观一致的倾向。我们通过在不同政治背景下开发的领先LLMs进行的实验测试验证这一洞察，使用多种现有的心理测量和政治倾向度量。分析基于模型回应的数值评分和定性分析。研究结果表明模型间存在高变异性，并且强烈关联于模型开发国家的政治文化。这些发现强调了更详细研究嵌入AI系统中的社会政治维度的必要性。', 'title_zh': '人工权威：从机器思维到政治倾向。大规模语言模型中的民主偏见与独裁偏见实验分析'}
{'arxiv_id': 'arXiv:2509.25283', 'title': 'Effectiveness of Large Language Models in Simulating Regional Psychological Structures: An Empirical Examination of Personality and Subjective Well-being', 'authors': 'Ke Luoma, Li Zengyi, Liao Jiangqun, Tong Song, Peng Kaiping', 'link': 'https://arxiv.org/abs/2509.25283', 'abstract': 'This study examines whether LLMs can simulate culturally grounded psychological patterns based on demographic information. Using DeepSeek, we generated 2943 virtual participants matched to demographic distributions from the CFPS2018 and compared them with human responses on the Big Five personality traits and subjective well-being across seven Chinese this http URL was measured using a 15-item Chinese Big Five inventory, and happiness with a single-item rating. Results revealed broad similarity between real and simulated datasets, particularly in regional variation trends. However, systematic differences emerged:simulated participants scored lower in extraversion and openness, higher in agreeableness and neuroticism, and consistently reported lower happiness. Predictive structures also diverged: while human data identified conscientiousness, extraversion and openness as positive predictors of happiness, the AI emphasized openness and agreeableness, with extraversion predicting negatively. These discrepancies suggest that while LLMs can approximate population-level psychological distributions, they underrepresent culturally specific and affective dimensions. The findings highlight both the potential and limitations of LLM-based virtual participants for large-scale psychological research and underscore the need for culturally enriched training data and improved affective modeling.', 'abstract_zh': '本研究探讨大型语言模型是否可以根据人口统计信息模拟文化-grounded 心理模式。我们使用DeepSeek生成了2943名与CFPS2018人口分布匹配的虚拟参与者，并将它们与Big Five人格特质和主观幸福感的人类回应进行了比较。这些指标分别使用15项中国Big Five问卷和单项目测幸福感进行测量。研究结果表明，真实数据集和模拟数据集之间存在广泛的相似性，特别是在区域变化趋势方面。然而，系统性的差异也出现了：模拟参与者在 extraversion 和 openness 上得分较低，在 agreeableness 和 neuroticism 上得分较高，并且普遍报告的幸福感较低。预测结构也存在差异：人类数据将 conscientiousness、extraversion 和 openness 识别为幸福感的正向预测因子，而AI则强调 openess 和 agreeableness，extraversion 对幸福感有负向预测作用。这些差异表明，虽然大型语言模型可以近似人口水平的心理学分布，但它们在文化和情感维度上代表性不足。研究结果强调了基于大型语言模型的虚拟参与人员在大规模心理学研究中的潜力和局限性，并强调了需要丰富文化背景的训练数据和改进情感建模的必要性。', 'title_zh': '大型语言模型在模拟区域心理结构方面的有效性：人格与主观幸福感的实证考察'}
{'arxiv_id': 'arXiv:2509.25275', 'title': 'VoiceBridge: Designing Latent Bridge Models for General Speech Restoration at Scale', 'authors': 'Chi Zhang, Zehua Chen, Kaiwen Zheng, Jun Zhu', 'link': 'https://arxiv.org/abs/2509.25275', 'abstract': 'Bridge models have recently been explored for speech enhancement tasks such as denoising, dereverberation, and super-resolution, while these efforts are typically confined to a single task or small-scale datasets, with constrained general speech restoration (GSR) capability at scale. In this work, we introduce VoiceBridge, a GSR system rooted in latent bridge models (LBMs), capable of reconstructing high-fidelity speech at full-band (\\textit{i.e.,} 48~kHz) from various distortions. By compressing speech waveform into continuous latent representations, VoiceBridge models the~\\textit{diverse LQ-to-HQ tasks} (namely, low-quality to high-quality) in GSR with~\\textit{a single latent-to-latent generative process} backed by a scalable transformer architecture. To better inherit the advantages of bridge models from the data domain to the latent space, we present an energy-preserving variational autoencoder, enhancing the alignment between the waveform and latent space over varying energy levels. Furthermore, to address the difficulty of HQ reconstruction from distinctively different LQ priors, we propose a joint neural prior, uniformly alleviating the reconstruction burden of LBM. At last, considering the key requirement of GSR systems, human perceptual quality, a perceptually aware fine-tuning stage is designed to mitigate the cascading mismatch in generation while improving perceptual alignment. Extensive validation across in-domain and out-of-domain tasks and datasets (\\textit{e.g.}, refining recent zero-shot speech and podcast generation results) demonstrates the superior performance of VoiceBridge. Demo samples can be visited at: this https URL.', 'abstract_zh': 'VoiceBridge：基于隐桥模型的大规模通用语音恢复系统', 'title_zh': 'VoiceBridge: 设计大规模通用语音恢复的潜在桥梁模型'}
{'arxiv_id': 'arXiv:2509.25274', 'title': 'DNABERT-2: Fine-Tuning a Genomic Language Model for Colorectal Gene Enhancer Classification', 'authors': 'Darren King, Yaser Atlasi, Gholamreza Rafiee', 'link': 'https://arxiv.org/abs/2509.25274', 'abstract': "Gene enhancers control when and where genes switch on, yet their sequence diversity and tissue specificity make them hard to pinpoint in colorectal cancer. We take a sequence-only route and fine-tune DNABERT-2, a transformer genomic language model that uses byte-pair encoding to learn variable-length tokens from DNA. Using assays curated via the Johnston Cancer Research Centre at Queen's University Belfast, we assembled a balanced corpus of 2.34 million 1 kb enhancer sequences, applied summit-centered extraction and rigorous de-duplication including reverse-complement collapse, and split the data stratified by class. With a 4096-term vocabulary and a 232-token context chosen empirically, the DNABERT-2-117M classifier was trained with Optuna-tuned hyperparameters and evaluated on 350742 held-out sequences. The model reached PR-AUC 0.759, ROC-AUC 0.743, and best F1 0.704 at an optimized threshold (0.359), with recall 0.835 and precision 0.609. Against a CNN-based EnhancerNet trained on the same data, DNABERT-2 delivered stronger threshold-independent ranking and higher recall, although point accuracy was lower. To our knowledge, this is the first study to apply a second-generation genomic language model with BPE tokenization to enhancer classification in colorectal cancer, demonstrating the feasibility of capturing tumor-associated regulatory signals directly from DNA sequence alone. Overall, our results show that transformer-based genomic models can move beyond motif-level encodings toward holistic classification of regulatory elements, offering a novel path for cancer genomics. Next steps will focus on improving precision, exploring hybrid CNN-transformer designs, and validating across independent datasets to strengthen real-world utility.", 'abstract_zh': '基于BPE分词的第二代基因语言模型在结直肠癌增强子分类中的应用：从DNA序列直接捕获肿瘤相关调控信号的可能性', 'title_zh': 'DNABERT-2：用于结肠癌基因增强子分类的基因组语言模型微调'}
{'arxiv_id': 'arXiv:2509.25270', 'title': 'InfMasking: Unleashing Synergistic Information by Contrastive Multimodal Interactions', 'authors': 'Liangjian Wen, Qun Dai, Jianzhuang Liu, Jiangtao Zheng, Yong Dai, Dongkai Wang, Zhao Kang, Jun Wang, Zenglin Xu, Jiang Duan', 'link': 'https://arxiv.org/abs/2509.25270', 'abstract': 'In multimodal representation learning, synergistic interactions between modalities not only provide complementary information but also create unique outcomes through specific interaction patterns that no single modality could achieve alone. Existing methods may struggle to effectively capture the full spectrum of synergistic information, leading to suboptimal performance in tasks where such interactions are critical. This is particularly problematic because synergistic information constitutes the fundamental value proposition of multimodal representation. To address this challenge, we introduce InfMasking, a contrastive synergistic information extraction method designed to enhance synergistic information through an \\textbf{Inf}inite \\textbf{Masking} strategy. InfMasking stochastically occludes most features from each modality during fusion, preserving only partial information to create representations with varied synergistic patterns. Unmasked fused representations are then aligned with masked ones through mutual information maximization to encode comprehensive synergistic information. This infinite masking strategy enables capturing richer interactions by exposing the model to diverse partial modality combinations during training. As computing mutual information estimates with infinite masking is computationally prohibitive, we derive an InfMasking loss to approximate this calculation. Through controlled experiments, we demonstrate that InfMasking effectively enhances synergistic information between modalities. In evaluations on large-scale real-world datasets, InfMasking achieves state-of-the-art performance across seven benchmarks. Code is released at this https URL.', 'abstract_zh': '在多模态表示学习中，模态之间的协同交互不仅提供互补信息，还能通过特定的交互模式创造出单一模态无法实现的独特成果。现有方法可能难以有效捕捉协同信息的整个谱系，导致在需要此类交互的任务中表现不佳。由于协同信息构成了多模态表示的基本价值主张，因此这一挑战尤为关键。为解决这一问题，我们 introduced InfMasking，一种通过无限掩蔽策略增强协同信息的对比性协同信息提取方法。InfMasking 在融合过程中随机遮蔽每个模态的大部分特征，仅保留部分信息以生成具有多种协同模式的表示。未遮蔽的融合表示通过最大化互信息与遮蔽表示对齐，从而编码全面的协同信息。无限掩蔽策略在训练过程中使模型接触到多种不同的部分模态组合，从而捕获更丰富的交互。由于使用无限掩蔽计算互信息估计在计算上是不可行的，我们推导出一种 InfMasking 损失来近似此计算。通过受控实验，我们证明 InfMasking 有效地增强了模态之间的协同信息。在大规模现实世界数据集的评估中，InfMasking 在七个基准测试中实现了最先进的性能。代码托管在 this https URL。', 'title_zh': 'InfMasking: 利用对比多模态交互释放协同信息'}
{'arxiv_id': 'arXiv:2509.25268', 'title': 'A Weather Foundation Model for the Power Grid', 'authors': 'Cristian Bodnar, Raphaël Rousseau-Rizzi, Nikhil Shankar, James Merleau, Stylianos Flampouris, Guillem Candille, Slavica Antic, François Miralles, Jayesh K. Gupta', 'link': 'https://arxiv.org/abs/2509.25268', 'abstract': "Weather foundation models (WFMs) have recently set new benchmarks in global forecast skill, yet their concrete value for the weather-sensitive infrastructure that powers modern society remains largely unexplored. In this study, we fine-tune Silurian AI's 1.5B-parameter WFM, Generative Forecasting Transformer (GFT), on a rich archive of Hydro-Québec asset observations--including transmission-line weather stations, wind-farm met-mast streams, and icing sensors--to deliver hyper-local, asset-level forecasts for five grid-critical variables: surface temperature, precipitation, hub-height wind speed, wind-turbine icing risk, and rime-ice accretion on overhead conductors. Across 6-72 h lead times, the tailored model surpasses state-of-the-art NWP benchmarks, trimming temperature mean absolute error (MAE) by 15%, total-precipitation MAE by 35%, and lowering wind speed MAE by 15%. Most importantly, it attains an average precision score of 0.72 for day-ahead rime-ice detection, a capability absent from existing operational systems, which affords several hours of actionable warning for potentially catastrophic outage events. These results show that WFMs, when post-trained with small amounts of high-fidelity, can serve as a practical foundation for next-generation grid-resilience intelligence.", 'abstract_zh': '基于天气的预训练模型（WFMs）在全局预报技能上已设定新基准，但其对支撑现代社会的天气敏感型基础设施的具体价值尚待探索。通过对此项研究，我们利用包含水电-魁北克资产观测数据（包括输电线路气象站、风场测风塔流和结冰传感器）的丰富档案，对Silurian AI的1.5亿参数生成预报变换器（GFT）模型进行微调，以提供五种电网关键变量的超局地、资产级预报：地表温度、降水、轮毂高度风速、风力涡轮机结冰风险以及架空导线覆冰累积。在6-72小时的预报时效内，定制化模型超过了最先进的数值天气预报（NWP）基准，在温度平均绝对误差（MAE）上降低了15%，在总降水MAE上降低了35%，在风速MAE上降低了15%。尤为重要的是，它在翌日结冰检测上的平均精准度得分为0.72，这是现有运营系统所不具备的能力，可提供几小时的可操作预警，以应对潜在的灾难性断电事件。结果表明，当用少量高保真数据进行后微调后，WFMs可作为下一代电网韧性智能的实际基础。', 'title_zh': '电力-grid气象基础模型'}
{'arxiv_id': 'arXiv:2509.25267', 'title': 'Dynamic Policy Induction for Adaptive Prompt Optimization: Bridging the Efficiency-Accuracy Gap via Lightweight Reinforcement Learning', 'authors': 'Jiexi Xu', 'link': 'https://arxiv.org/abs/2509.25267', 'abstract': 'The performance of Large Language Models (LLMs) depends heavily on the chosen prompting strategy, yet static approaches such as Zero-Shot, Few-Shot, or Chain-of-Thought (CoT) impose a rigid efficiency-accuracy trade-off. Highly accurate strategies like Self-Consistency (SC) incur substantial computational waste on simple tasks, while lightweight methods often fail on complex inputs. This paper introduces the Prompt Policy Network (PPN), a lightweight reinforcement learning framework that formalizes adaptive strategy selection as a single-step Markov Decision Process (MDP). The PPN, trained with Proximal Policy Optimization (PPO) and guided by a resource-explicit reward function, learns to allocate costly reasoning strategies only when necessary. Experiments on arithmetic reasoning benchmarks demonstrate that PPN achieves superior performance on the efficiency-accuracy Pareto front, delivering up to 61.5% token cost reduction compared to Self-Consistency while maintaining competitive accuracy. This work contributes a systematic, adaptive framework for cost-efficient LLM deployment, advancing the design of lightweight optimization techniques for scalable and sustainable language model applications.', 'abstract_zh': '大型语言模型（LLMs）的表现很大程度上取决于所选用的提示策略，然而，零样本、少样本或思维链（CoT）等静态方法均会导致效率-准确性的固化权衡。 Self-Consistency（自洽性）等高准确性的策略在简单任务上会消耗大量不必要的计算资源，而轻量级方法则在复杂输入上常常失效。本文引入了提示策略网络（PPN），这是一种轻量级的强化学习框架，将自适应策略选择形式化为单步马尔可夫决策过程（MDP）。PPN经过 proximal 策略优化（PPO）训练，并由一个明确资源的奖励函数引导，学会只在必要时分配昂贵的推理策略。在算术推理基准测试中的实验表明，PPN在效率-准确性的帕累托前沿上表现出色，相较于自洽性，能够实现高达61.5%的token成本降低，同时保持了竞争力的准确度。本文贡献了一种系统化的、自适应的成本高效LLM部署框架，推动了轻量级优化技术在可扩展和可持续的语言模型应用设计中的发展。', 'title_zh': '基于轻量级强化学习的动态策略诱导以实现自适应提示优化：在效率与准确率之间架起桥梁'}
{'arxiv_id': 'arXiv:2509.25266', 'title': "Cognifying Education: Mapping AI's transformative role in emotional, creative, and collaborative learning", 'authors': 'Mikael Gorsky, Ilya Levin', 'link': 'https://arxiv.org/abs/2509.25266', 'abstract': 'Artificial intelligence (AI) is rapidly reshaping educational practice, challenging long held assumptions about teaching and learning. This article integrates conceptual perspectives from recent books (Genesis by Eric Schmidt, Henry Kissinger and Craig Mundie, CoIntelligence by Ethan Mollick, and The Inevitable by Kevin Kelly) with empirical insights from popular AI podcasts and Anthropic public releases. We examine seven key domains: emotional support, creativity, contextual understanding, student engagement, problem solving, ethics and morality, and collaboration. For each domain, we explore AI capabilities, opportunities for transformative change, and emerging best practices, drawing equally from theoretical analysis and real world observations. Overall, we find that AI, when used thoughtfully, can complement and enhance human educators in fostering richer learning experiences across cognitive, social, and emotional dimensions. We emphasize an optimistic yet responsible outlook: educators and students should actively shape AI integration to amplify human potential in creativity, ethical reasoning, collaboration, and beyond, while maintaining a focus on human centric values.', 'abstract_zh': '人工智能正在迅速重塑教育实践，挑战着关于教学和学习的长期假设。本文将近期书籍（《创世》by Eric Schmidt, Henry Kissinger和Craig Mundie，《共智》by Ethan Mollick，以及《必然》by Kevin Kelly）的概念视角与流行AI播客和Anthropic公开发布的内容相结合，探讨了七个关键领域：情感支持、创造力、情境理解、学生参与、解决问题、伦理与道德，以及协作。针对每个领域，本文探讨了人工智能的能力、变革机会以及正在涌现的最佳实践，既来自于理论分析也来自于现实观察。总体而言，我们发现，当明智地使用时，人工智能能够补充并增强人类教育者，在认知、社会和情感维度上促进更丰富的学习体验。我们强调一种既乐观又负责任的态度：教育工作者和学生应当积极塑造人工智能的整合方式，以放大人类在创造力、伦理推理、协作等方面的能力，同时保持对以人为本的价值观的关注。', 'title_zh': '认知化教育：映射AI在情感、创造性和协作性学习中的变革性作用'}
{'arxiv_id': 'arXiv:2509.25264', 'title': 'From NL2SQL to NL2GeoSQL: GeoSQL-Eval for automated evaluation of LLMs on PostGIS queries', 'authors': 'Shuyang Hou, Haoyue Jiao, Ziqi Liu, Lutong Xie, Guanyu Chen, Shaowen Wu, Xuefeng Guan, Huayi Wu', 'link': 'https://arxiv.org/abs/2509.25264', 'abstract': "In recent years, large language models (LLMs) have achieved remarkable progress in natural language understanding and structured query generation (NL2SQL). However, extending these advances to GeoSQL tasks in the PostGIS environment remains challenging due to the complexity of spatial functions, geometric data types, and execution semantics. Existing evaluations primarily focus on general relational databases or Google Earth Engine code generation, leaving a lack of systematic benchmarks tailored to spatial databases. To address this gap, this study introduces GeoSQL-Eval, the first end-to-end automated evaluation framework for PostGIS query generation. Built upon Webb's Depth of Knowledge (DOK) model, the framework encompasses four cognitive dimensions, five proficiency levels, and twenty task categories, providing a comprehensive assessment of model performance in terms of knowledge acquisition, syntactic generation, semantic alignment, execution accuracy, and robustness. In parallel, we developed GeoSQL-Bench, a benchmark dataset comprising 14178 questions that span three task types, 340 PostGIS functions, and 82 domain-specific databases. Leveraging this framework, we systematically evaluated 24 representative models across six categories, applying entropy-weighting and statistical analyses to reveal differences in performance, error distributions, and resource consumption patterns. Furthermore, we established a public GeoSQL-Eval leaderboard that enables global research teams to conduct ongoing testing and comparison. These contributions not only extend the boundaries of NL2SQL applications but also provide a standardized, interpretable, and scalable framework for evaluating LLM performance in spatial database contexts, offering valuable insights for model optimization and applications in geographic information science, urban studies, and spatial analysis.", 'abstract_zh': '近年来，大型语言模型（LLMs）在自然语言理解与结构化查询生成（NL2SQL）方面取得了显著进展。然而，将这些进展扩展到PostGIS环境中的GeoSQL任务由于空间函数、几何数据类型和执行语义的复杂性仍具挑战性。现有评估主要集中在通用关系数据库或Google Earth Engine代码生成上，缺乏针对空间数据库的系统性基准测试。为填补这一空白，本研究引入了GeoSQL-Eval，这是首个针对PostGIS查询生成的端到端自动化评估框架。该框架基于Webb的知识深度（DOK）模型，涵盖了四个认知维度、五个熟练程度级别和二十个任务类别，提供了模型在知识获取、语法生成、语义对齐、执行准确性和鲁棒性方面的全面评估。与此同时，我们开发了GeoSQL-Bench，这是一个包含14178个问题的基准数据集，涵盖了三种任务类型、340个PostGIS函数和82个领域特定数据库。利用该框架，我们系统性地评估了24个代表性模型的六个类别，并通过熵加权和统计分析揭示了不同性能、错误分布和资源消耗模式。此外，我们建立了一个公共GeoSQL-Eval排行榜，使全球研究团队能够持续进行测试和比较。这些贡献不仅扩展了NL2SQL应用的边界，还提供了一个标准化、可解释和可扩展的框架，用于评估在空间数据库上下文中LLM的性能，为模型优化以及地理信息科学、城市研究和空间分析的应用提供了宝贵的见解。', 'title_zh': '从NL2SQL到NL2GeoSQL：GeoSQL-Eval用于PostGIS查询的自动化评估'}
{'arxiv_id': 'arXiv:2509.25263', 'title': 'How Effective Are Time-Series Models for Rainfall Nowcasting? A Comprehensive Benchmark for Rainfall Nowcasting Incorporating PWV Data', 'authors': 'Yifang Zhang, Pengfei Duan, Henan Wang, Shengwu Xiong', 'link': 'https://arxiv.org/abs/2509.25263', 'abstract': 'Rainfall nowcasting, which aims to predict precipitation within the next 0 to 3 hours, is critical for disaster mitigation and real-time response planning. However, most time series forecasting benchmarks in meteorology are evaluated on variables with strong periodicity, such as temperature and humidity, which fail to reflect model capabilities in more complex and practically meteorology scenarios like rainfall nowcasting. To address this gap, we propose RainfallBench, a benchmark designed for rainfall nowcasting, a highly challenging and practically relevant task characterized by zero inflation, temporal decay, and non-stationarity, focused on predicting precipitation within the next 0 to 3 hours. The dataset is derived from five years of meteorological observations, recorded at 15-minute intervals across six essential variables, and collected from more than 12,000 GNSS stations globally. In particular, it incorporates precipitable water vapor (PWV), a crucial indicator of rainfall that is absent in other datasets. We further design specialized evaluation strategies to assess model performance on key meteorological challenges, such as multi-scale prediction and extreme rainfall events, and evaluate over 20 state-of-the-art models across six major architectures on RainfallBench. Additionally, to address the zero-inflation and temporal decay issues overlooked by existing models, we introduce Bi-Focus Precipitation Forecaster (BFPF), a plug-and-play module that incorporates domain-specific priors to enhance rainfall time series forecasting. Statistical analysis and ablation studies validate the comprehensiveness of our dataset as well as the superiority of our methodology. Code and datasets are available at this https URL.', 'abstract_zh': '降雨_nowcasting：一种用于接下来0至3小时降水预测的基准，以解决气象时间序列预测基准中强周期性变量主导的问题，并专注于零膨胀、时间衰减和非平稳性的挑战。', 'title_zh': '时间序列模型在降雨现在casting中的有效性：结合PWV数据的全面现在casting基准测试'}
{'arxiv_id': 'arXiv:2509.25258', 'title': 'Artificial Intelligence-Powered Assessment Framework for Skill-Oriented Engineering Lab Education', 'authors': 'Vaishnavi Sharma, Rakesh Thakur, Shashwat Sharma, Kritika Panjanani', 'link': 'https://arxiv.org/abs/2509.25258', 'abstract': 'Practical lab education in computer science often faces challenges such as plagiarism, lack of proper lab records, unstructured lab conduction, inadequate execution and assessment, limited practical learning, low student engagement, and absence of progress tracking for both students and faculties, resulting in graduates with insufficient hands-on skills. In this paper, we introduce AsseslyAI, which addresses these challenges through online lab allocation, a unique lab problem for each student, AI-proctored viva evaluations, and gamified simulators to enhance engagement and conceptual mastery. While existing platforms generate questions based on topics, our framework fine-tunes on a 10k+ question-answer dataset built from AI/ML lab questions to dynamically generate diverse, code-rich assessments. Validation metrics show high question-answer similarity, ensuring accurate answers and non-repetitive questions. By unifying dataset-driven question generation, adaptive difficulty, plagiarism resistance, and evaluation in a single pipeline, our framework advances beyond traditional automated grading tools and offers a scalable path to produce genuinely skilled graduates.', 'abstract_zh': '计算机科学中的实践实验室教育常常面临抄袭、缺乏适当的实验室记录、无结构的实验操作、不充分的执行和评估、有限的实际学习、学生参与度低以及师生进度跟踪缺失等问题，导致毕业生缺乏足够的动手技能。本文介绍了一种名为AsseslyAI的解决方案，通过在线实验室分配、为每位学生提供独特的实验室问题、使用AI监考的口试评估以及 gamified 模拟器来提升参与度和概念掌握。现有平台基于主题生成问题，而我们的框架则通过构建一个包含超过10,000个问答的数据集并从中微调，实现动态生成多样且富含代码的评估。验证指标显示高相似度的问答，确保准确的答案和非重复的问题。通过在一个集成管道中统一数据驱动的问题生成、自适应难度、抗抄袭和评估功能，我们的框架超越了传统的自动化评分工具，并提供了一条可扩展的道路，以培养真正具备技能的毕业生。', 'title_zh': '基于人工智能的动力工程实训技能导向评估框架'}
{'arxiv_id': 'arXiv:2509.25256', 'title': 'The Sandbox Configurator: A Framework to Support Technical Assessment in AI Regulatory Sandboxes', 'authors': 'Alessio Buscemi, Thibault Simonetto, Daniele Pagani, German Castignani, Maxime Cordy, Jordi Cabot', 'link': 'https://arxiv.org/abs/2509.25256', 'abstract': "The systematic assessment of AI systems is increasingly vital as these technologies enter high-stakes domains. To address this, the EU's Artificial Intelligence Act introduces AI Regulatory Sandboxes (AIRS): supervised environments where AI systems can be tested under the oversight of Competent Authorities (CAs), balancing innovation with compliance, particularly for startups and SMEs. Yet significant challenges remain: assessment methods are fragmented, tests lack standardisation, and feedback loops between developers and regulators are weak. To bridge these gaps, we propose the Sandbox Configurator, a modular open-source framework that enables users to select domain-relevant tests from a shared library and generate customised sandbox environments with integrated dashboards. Its plug-in architecture aims to support both open and proprietary modules, fostering a shared ecosystem of interoperable AI assessment services. The framework aims to address multiple stakeholders: CAs gain structured workflows for applying legal obligations; technical experts can integrate robust evaluation methods; and AI providers access a transparent pathway to compliance. By promoting cross-border collaboration and standardisation, the Sandbox Configurator's goal is to support a scalable and innovation-friendly European infrastructure for trustworthy AI governance.", 'abstract_zh': 'AI系统系统的评估随着这些技术进入高风险领域变得越来越重要。为此，欧盟人工智能法案提出了AI监管沙盒（AIRS）：在监管当局（CAs）监督下的受控环境，以平衡创新与合规，特别是针对初创企业和中小企业。然而，仍存在重大挑战：评估方法碎片化，测试缺乏标准化，开发者与监管者之间的反馈循环薄弱。为解决这些差距，我们提出了沙盒配置器，这是一个模块化的开源框架，使用户能够从共享库中选择相关领域的测试，并生成包含集成仪表板的个性化沙盒环境。其插件架构旨在支持开源和专有模块，促进互操作的AI评估服务共享生态系统的形成。该框架旨在应对多个利益相关方的需求：监管当局获得结构化的合规工作流程；技术专家可以集成 robust 评估方法；AI 提供商能够获得透明的合规途径。通过促进跨境合作和标准化，沙盒配置器的目标是支持一个可扩展且创新友好的欧洲可信人工智能治理体系基础设施。', 'title_zh': '沙盒配置器：支持AI监管沙盒技术评估的框架'}
{'arxiv_id': 'arXiv:2509.25253', 'title': 'Knowledge distillation through geometry-aware representational alignment', 'authors': 'Prajjwal Bhattarai, Mohammad Amjad, Dmytro Zhylko, Tuka Alhanai', 'link': 'https://arxiv.org/abs/2509.25253', 'abstract': 'Knowledge distillation is a common paradigm for transferring capabilities from larger models to smaller ones. While traditional distillation methods leverage a probabilistic divergence over the output of the teacher and student models, feature-based distillation methods often minimize variants of Euclidean norms between the hidden layer representations. The main goal is for the student to mimic the structure of the feature space of the teacher. In this work, we theoretically show that existing feature distillation methods, such as projection based mean squared loss or Centered Kernel Alignment (CKA), cannot capture the feature structure, even under zero loss. We then motivate the use of Procrustes distance and the Frobenius norm of Feature Gram Matrix, distances already common in the context of measuring representational alignment, as distillation losses. We show that feature distillation through our method showcases statistically significant improvement in distillation performance across language models families (BERT and OPT) in classification and instruction-following tasks by up to 2 percentage points, showcasing the potential of integrating feature geometry into existing distillation methods.', 'abstract_zh': '知识蒸馏是一种将大型模型的能力转移到小型模型中的常用范式。虽然传统蒸馏方法通过教师和学生模型输出的概率性差异来工作，基于特征的蒸馏方法通常最小化隐藏层表示之间的欧几里得范数变体。主要目标是让学生模仿教师特征空间的结构。在本项工作中，我们理论上证明现有的基于特征的蒸馏方法，如基于投影的均方误差或中心核对齐（CKA），即使在无损失情况下也无法捕捉特征结构。随后，我们引入普罗克鲁斯泰斯距离和特征Gram矩阵的弗罗贝尼乌斯范数作为蒸馏损失，这些距离已经在衡量表示对齐的上下文中被普遍使用。我们展示了通过我们方法进行的特征蒸馏在语言模型家族（BERT和OPT）的任务中（分类和指令跟随）实现了统计显著的性能提升，最多达到2个百分点，展示了将特征几何整合到现有蒸馏方法中的潜力。', 'title_zh': '通过几何意识表示对齐的知识蒸馏'}
{'arxiv_id': 'arXiv:2509.25249', 'title': 'BEV-VLM: Trajectory Planning via Unified BEV Abstraction', 'authors': 'Guancheng Chen, Sheng Yang, Tong Zhan, Jian Wang', 'link': 'https://arxiv.org/abs/2509.25249', 'abstract': "This paper introduces BEV-VLM, a novel framework for trajectory planning in autonomous driving that leverages Vision-Language Models (VLMs) with Bird's-Eye View (BEV) feature maps as visual inputs. Unlike conventional approaches that rely solely on raw visual data such as camera images, our method utilizes highly compressed and informative BEV representations, which are generated by fusing multi-modal sensor data (e.g., camera and LiDAR) and aligning them with HD Maps. This unified BEV-HD Map format provides a geometrically consistent and rich scene description, enabling VLMs to perform accurate trajectory planning. Experimental results on the nuScenes dataset demonstrate 44.8% improvements in planning accuracy and complete collision avoidance. Our work highlights that VLMs can effectively interpret processed visual representations like BEV features, expanding their applicability beyond raw images in trajectory planning.", 'abstract_zh': 'BEV-VLM：一种基于鸟瞰图特征映射的视觉-语言模型在自主驾驶中的轨迹规划新框架', 'title_zh': 'BEV-VLM：统一BEV抽象轨迹规划'}
{'arxiv_id': 'arXiv:2509.25248', 'title': 'BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software', 'authors': 'Zehua Zhang, Ati Priya Bajaj, Divij Handa, Siyu Liu, Arvind S Raj, Hongkai Chen, Hulin Wang, Yibo Liu, Zion Leonahenahe Basque, Souradip Nath, Vishal Juneja, Nikhil Chapre, Yan Shoshitaishvili, Adam Doupé, Chitta Baral, Ruoyu Wang', 'link': 'https://arxiv.org/abs/2509.25248', 'abstract': "Automatically compiling open-source software (OSS) projects is a vital, labor-intensive, and complex task, which makes it a good challenge for LLM Agents. Existing methods rely on manually curated rules and workflows, which cannot adapt to OSS that requires customized configuration or environment setup. Recent attempts using Large Language Models (LLMs) used selective evaluation on a subset of highly rated OSS, a practice that underestimates the realistic challenges of OSS compilation. In practice, compilation instructions are often absent, dependencies are undocumented, and successful builds may even require patching source files or modifying build scripts. We propose a more challenging and realistic benchmark, BUILD-BENCH, comprising OSS that are more diverse in quality, scale, and characteristics. Furthermore, we propose a strong baseline LLM-based agent, OSS-BUILD-AGENT, an effective system with enhanced build instruction retrieval module that achieves state-of-the-art performance on BUILD-BENCH and is adaptable to heterogeneous OSS characteristics. We also provide detailed analysis regarding different compilation method design choices and their influence to the whole task, offering insights to guide future advances. We believe performance on BUILD-BENCH can faithfully reflect an agent's ability to tackle compilation as a complex software engineering tasks, and, as such, our benchmark will spur innovation with a significant impact on downstream applications in the fields of software development and software security.", 'abstract_zh': '自动编译开源软件（OSS）项目是一项重要但劳动密集和复杂的任务，是大模型代理的理想挑战。现有方法依赖于手动curated的规则和工作流，不能适应需要定制配置或环境设置的OSS。最近使用大语言模型（LLMs）的方法仅在高评价的OSS子集上进行选择性评估，这低估了OSS编译的实际挑战。实际上，编译指令往往缺失，依赖关系没有记录，甚至成功构建可能还需要修改源文件或构建脚本。我们提出更具挑战性和实际性的基准BUILD-BENCH，包括质量、规模和特性更丰富的OSS。此外，我们提出了一种强大的基于大模型的代理OSS-BUILD-AGENT，这是一种有效系统，具有增强的构建指令检索模块，在BUILD-BENCH上达到了最先进的性能，并且能够适应异构OSS特性。我们还详细分析了不同编译方法设计选择及其对整个任务的影响，提供了未来进展的见解。我们认为，在BUILD-BENCH上的性能能够真实反映代理处理编译这一复杂软件工程任务的能力，因此，我们的基准将激发具有重大影响的创新，推动软件开发和软件安全领域的下游应用。', 'title_zh': 'BuildBench: 评估大语言模型代理在编译真实世界开源软件方面的性能'}
{'arxiv_id': 'arXiv:2509.25247', 'title': 'Protocode: Prototype-Driven Interpretability for Code Generation in LLMs', 'authors': 'Krishna Vamshi Bodla, Haizhao Yang', 'link': 'https://arxiv.org/abs/2509.25247', 'abstract': 'Since the introduction of Large Language Models (LLMs), they have been widely adopted for various tasks such as text summarization, question answering, speech-to-text translation, and more. In recent times, the use of LLMs for code generation has gained significant attention, with tools such as Cursor and Windsurf demonstrating the ability to analyze massive code repositories and recommend relevant changes. Big tech companies have also acknowledged the growing reliance on LLMs for code generation within their codebases. Although these advances significantly improve developer productivity, increasing reliance on automated code generation can proportionally increase the risk of suboptimal solutions and insecure code. Our work focuses on automatically sampling In-Context Learning (ICL) demonstrations which can improve model performance and enhance the interpretability of the generated code. Using AST-based analysis on outputs from the MBPP test set, we identify regions of code most influenced by the chosen demonstrations. In our experiments, we show that high-quality ICL demonstrations not only make outputs easier to interpret but also yield a positive performance improvement on the pass@10 metric. Conversely, poorly chosen ICL demonstrations affected the LLM performance on the pass@10 metric negatively compared to the base model. Overall, our approach highlights the importance of efficient sampling strategies for ICL, which can affect the performance of the model on any given task.', 'abstract_zh': '自大型语言模型（LLMs）的引入以来，它们已被广泛应用于文本总结、问答、语音转文本翻译等多种任务。近年来，使用LLMs进行代码生成引起了广泛关注，如Cursor和Windsurf等工具能够分析大型代码仓库并推荐相关更改。大型科技公司也认识到LLMs在其代码库中进行代码生成依赖性的增长。尽管这些进展显著提高了开发者的工作效率，但对自动代码生成的日益依赖也相应地增加了设计方案不优化和代码不安全的风险。我们的工作集中在自动采样示例上下文学习（ICL）演示，以提高模型性能并增强生成代码的可解释性。通过基于AST的分析MBPP测试集的输出，我们确定了最受所选演示影响的代码区域。在我们的实验中，我们展示了高质量的ICL演示不仅使输出更易于解释，还提高了pass@10指标上的性能。相反，选择不佳的ICL演示会负面影响LLMs在pass@10指标上的性能与基模型相比。总体而言，我们的方法突显了高效采样策略对ICL的重要性，这可能影响模型在任何给定任务上的性能。', 'title_zh': '原型驱动的可解释性方法：在大规模语言模型中进行代码生成'}
{'arxiv_id': 'arXiv:2509.25245', 'title': 'Comprehensive Analysis of VQC for Financial Fraud Detection: A Comparative Study of Quantum Encoding Techniques and Architectural Optimizations', 'authors': 'Fouad Mohammed Abbou, Mohamed Bouhadda, Lamiae Bouanane, Mouna Kettani, Farid Abdi, Abdelouahab Abid', 'link': 'https://arxiv.org/abs/2509.25245', 'abstract': 'This paper presents a systematic comparative analysis of Variational Quantum Classifier (VQC) configurations for financial fraud detection, encompassing three distinct quantum encoding techniques and comprehensive architectural variations. Through empirical evaluation across multiple entanglement patterns, circuit depths, and optimization strategies,quantum advantages in fraud classification accuracy are demonstrated, achieving up to 94.3 % accuracy with ZZ encoding schemes. The analysis reveals significant performance variations across entanglement topologies, with circular entanglement consistently outperforming linear (90.7) %) and full connectivity (92.0 %) patterns, achieving optimal performance at 93.3 % accuracy. The study introduces novel visualization methodologies for quantum circuit analysis and provides actionable deployment recommendations for practical quantum machine learning implementations. Notably, systematic entanglement pattern analysis shows that circular connectivity provides superior balance between expressivity and trainability while maintaining computational efficiency. These researches offer initial benchmarks for quantum enhanced fraud detection systems and propose potential benefits of quantum machine learning in financial security applications.', 'abstract_zh': '这篇论文对量子变分分类器（VQC）配置在金融欺诈检测中的系统性比较分析进行了介绍，涵盖了三种不同的量子编码技术和全面的架构变化。通过在多个纠缠模式、电路深度和优化策略上的实证评估，展示了量子编码在欺诈分类准确性上的优势，ZZ编码方案可达94.3%的准确率。分析结果显示，在纠缠拓扑结构上存在显著的性能差异，其中圆形纠缠始终优于线性（90.7%）和全连接（92.0%）模式，并在93.3%的准确率下表现出最佳性能。研究引入了量子电路分析的新型可视化方法，并提供了实用的量子机器学习部署建议。系统性纠缠模式分析表明，圆形连接提供了在表达能力和可训练性之间优越的平衡，同时保持计算效率。这些研究为量子增强欺诈检测系统提供了初步基准，并提出了量子机器学习在金融安全应用中的潜在益处。', 'title_zh': '全面分析VQC在金融欺诈检测中的应用：量子编码技术与架构优化的比较研究'}
{'arxiv_id': 'arXiv:2509.25243', 'title': 'Reinforcement Learning-Guided Chain-of-Draft for Token-Efficient Code Generation', 'authors': 'Xunzhu Tang, Iyiola Emmanuel Olatunji, Tiezhu Sun, Jacques Klein, Tegawende F. Bissyande', 'link': 'https://arxiv.org/abs/2509.25243', 'abstract': "LLMs demonstrate surface-level fluency in code generation but struggle with structured reasoning tasks requiring correctness and semantic alignment. While Chain-of-Thought (CoT) prompting enhances reasoning through intermediate steps, it suffers from verbosity and inefficiency. Chain-of-Draft (CoD) prompting offers more concise reasoning, but the stochastic nature of LLMs produces varying solution quality, making optimal selection challenging. We propose \\multicod, a reinforcement learning framework that learns to select the most promising candidate from CoD-generated solutions. Our approach uses strategy-guided prompting to encourage diverse reasoning styles and models solution selection as a contextual bandit problem. The framework optimizes interpretable features including code complexity, reasoning structure, and strategic metadata through a reward function balancing correctness, efficiency, and clarity. Experiments on MBPP, BigCodeBench, SWE-bench Verified, and Defects4J show \\multicod~outperforms and in some cases, on par with standard prompting, CoT, and CoD baselines while achieving cost and token efficiency from the user's perspective through a multi-candidate design that charges only for the selected output, reducing user billing by over 50\\% and improving LLM response quality, making \\multicod~more sustainable and scalable for real-world deployment. Our code is available: this https URL.", 'abstract_zh': 'LLMs在代码生成中表现出表面流畅性，但在需要正确性和语义对齐的结构化推理任务中表现出色。虽然Chain-of-Thought（CoT）提示可以通过中间步骤增强推理，但它存在冗余和低效的问题。Chain-of-Draft（CoD）提示提供更简洁的推理，但LLMs的随机性质导致生成的解决方案质量参差不齐，使最优选择变得困难。我们提出了一种强化学习框架\\multicod，用于从CoD生成的解决方案中选择最有前景的候选方案。我们的方法使用策略引导的提示鼓励多样化的推理风格，并将解决方案选择建模为上下文臂赛问题。该框架通过平衡正确性、效率和清晰度的奖励函数优化可解释特征，包括代码复杂性、推理结构和战略性元数据。实验表明，在MBPP、BigCodeBench、SWE-bench Verified和Defects4J上，\\multicod在某些情况下与标准提示、CoT和CoD基线相当或更优，并通过多候选设计方案从用户角度看实现了成本和令牌效率，通过仅对选定输出收费减少用户账单超过50%，并提高LLM响应质量，使\\multicod更具可持续性和可扩展性，适用于实际部署。代码可在以下链接获取：this https URL。', 'title_zh': 'Reinforcement Learning 引导的串行草稿生成方法：token 节约的代码生成'}
{'arxiv_id': 'arXiv:2509.25242', 'title': 'A Benchmark for Localizing Code and Non-Code Issues in Software Projects', 'authors': 'Zejun Zhang, Jian Wang, Qingyun Yang, Yifan Pan, Yi Tang, Yi Li, Zhenchang Xing, Tian Zhang, Xuandong Li, Guoan Zhang', 'link': 'https://arxiv.org/abs/2509.25242', 'abstract': 'Accurate project localization (e.g., files and functions) for issue resolution is a critical first step in software maintenance. However, existing benchmarks for issue localization, such as SWE-Bench and LocBench, are limited. They focus predominantly on pull-request issues and code locations, ignoring other evidence and non-code files such as commits, comments, configurations, and documentation. To address this gap, we introduce MULocBench, a comprehensive dataset of 1,100 issues from 46 popular GitHub Python projects. Comparing with existing benchmarks, MULocBench offers greater diversity in issue types, root causes, location scopes, and file types, providing a more realistic testbed for evaluation. Using this benchmark, we assess the performance of state-of-the-art localization methods and five LLM-based prompting strategies. Our results reveal significant limitations in current techniques: even at the file level, performance metrics (Acc@5, F1) remain below 40%. This underscores the challenge of generalizing to realistic, multi-faceted issue resolution. To enable future research on project localization for issue resolution, we publicly release MULocBench at this https URL.', 'abstract_zh': '准确的项目定位（例如文件和函数）是软件维护中问题解决的关键第一步。然而，现有的问题定位基准，如SWE-Bench和LocBench，存在局限性。它们主要关注拉取请求中的问题和代码位置，忽视了其他证据和非代码文件，如提交、注释、配置和文档。为填补这一空白，我们引入了MULocBench，这是一个包含46个流行GitHub Python项目中的1100个问题的综合数据集。与现有的基准相比，MULocBench在问题类型、根本原因、定位范围和文件类型方面提供了更大的多样性，为评估提供了更为真实的测试平台。使用这一基准，我们评估了最先进的定位方法和五种基于LLM的提示策略的表现。我们的结果揭示了当前技术的重大局限性：即使在文件级别，性能指标（Acc@5、F1）也低于40%。这强调了将技术应用于真实、多方面的问题解决的挑战。为了促进项目定位在问题解决方面的未来研究，我们已在此网址公开发布MULocBench：this https URL。', 'title_zh': '软件项目中代码与非代码问题定位基准'}
{'arxiv_id': 'arXiv:2509.25240', 'title': 'HAMMER: Hamiltonian Curiosity Augmented Large Language Model Reinforcement', 'authors': 'Ming Yang, Xiaofan Li, Zhiyuan Ma, Dengliang Shi, Jintao Du, Yu Cheng, Weiguo Zheng', 'link': 'https://arxiv.org/abs/2509.25240', 'abstract': 'Recent curriculum reinforcement learning for large language models (LLMs) typically rely on difficulty-based annotations for data filtering and ordering. However, such methods suffer from local optimization, where continual training on simple samples in the early steps can cause the policy to lose its exploration. We propose a novel schema, namely Hamiltonian curiosity augmented large language model reinforcement (HAMMER), that transfers diversity metrics, commonly used in dataset evaluation, into the dynamic reinforcement learning procedure, where training samples are ordered via a minimum-semantic Hamiltonian path making the initial training retrain more exploration. From a theoretical perspective of generalization bounds, diversity-driven ordering facilitates stable convergence. Empirical evaluations indicate that HAMMER stimulates model "curiosity" and consistently achieves a 3% to 4% average accuracy gain across diverse inference benchmark.', 'abstract_zh': '基于哈密顿 curiosity 增强的大型语言模型强化学习（HAMMER）', 'title_zh': 'HAMMER：基于哈密尔顿 curiosity 增强的大语言模型强化学习'}
{'arxiv_id': 'arXiv:2509.25238', 'title': 'PALADIN: Self-Correcting Language Model Agents to Cure Tool-Failure Cases', 'authors': 'Sri Vatsa Vuddanti, Aarav Shah, Satwik Kumar Chittiprolu, Tony Song, Sunishchal Dev, Kevin Zhu, Maheep Chaudhary', 'link': 'https://arxiv.org/abs/2509.25238', 'abstract': "Tool-augmented language agents frequently fail in real-world deployment due to tool malfunctions--timeouts, API exceptions, or inconsistent outputs--triggering cascading reasoning errors and task abandonment. Existing agent training pipelines optimize only for success trajectories, failing to expose models to the tool failures that dominate real-world usage. We propose \\textbf{PALADIN}, a generalizable framework for equipping language agents with robust failure recovery capabilities. PALADIN trains on 50,000+ recovery-annotated trajectories constructed via systematic failure injection and expert demonstrations on an enhanced ToolBench dataset. Training uses LoRA-based fine-tuning to retain base capabilities while injecting recovery competence. At inference, PALADIN detects execution-time errors and retrieves the most similar case from a curated bank of 55+ failure exemplars aligned with ToolScan's taxonomy, then executes the corresponding recovery action. This approach generalizes to novel failures beyond the training distribution, retaining 95.2\\% recovery performance on unseen tool APIs. Evaluation across PaladinEval and ToolReflectEval demonstrates consistent improvements in Recovery Rate (RR), Task Success Rate (TSR), Catastrophic Success Rate (CSR), and Efficiency Score (ES). PALADIN improves RR from 32.76% to 89.68% (+57% relative) over ToolBench and outperforms the strongest baseline CRITIC (76.34%) by +13.3%. Against vanilla agents, PALADIN achieves 89.86\\% RR (+66% relative improvement from 23.75%). These results establish PALADIN as an effective method for building fault-tolerant agents capable of robust recovery in real-world tool environments.", 'abstract_zh': 'PALADIN：一种通用框架，用于为语言代理提供 robust 失败恢复能力', 'title_zh': 'PALADIN: 自我纠正语言模型代理以治愈工具失败病例'}
{'arxiv_id': 'arXiv:2509.25237', 'title': 'Quantum est in Libris: Navigating Archives with GenAI, Uncovering Tension Between Preservation and Innovation', 'authors': 'Mar Canet Sola, Varvara Guljajeva', 'link': 'https://arxiv.org/abs/2509.25237', 'abstract': '"Quantum est in libris" explores the intersection of the archaic and the modern. On one side, there are manuscript materials from the Estonian National Museum\'s (ERM) more than century-old archive describing the life experiences of Estonian people; on the other side, there is technology that transforms these materials into a dynamic and interactive experience. Connecting technology and cultural heritage is the visitor, who turns texts into inputs for a screen sculpture.\nHistorical narratives are visually brought to life through the contemporary technological language. Because the video AI models we employed, Runway Gen-3 and Gen-4, have not previously interacted with Estonian heritage, we can observe how machines today "read the world" and create future heritage. "Quantum est in libris" introduces an exciting yet unsettling new dimension to the concept of cultural heritage: in a world where data are fluid and interpretations unstable, heritage status becomes fragile. In the digital environment, heritage issues are no longer just about preservation and transmission, but also about representation of the media, machine creativity, and interpretive error. Who or what shapes memory processes and memory spaces, and how?', 'abstract_zh': '《Quantum est in libris》探索了古代与现代的交集。一边是爱沙尼亚国家博物馆（ERM）百年档案中的手稿材料，记录了爱沙尼亚人的生活经历；另一边则是将这些材料转化为动态和互动体验的技术。将技术和文化遗产联系起来的是参观者，他们将文字转化为屏幕雕塑的输入。 Historical narratives通过当代的技术语言被视觉化地呈现出来。由于我们使用的视频AI模型Runway Gen-3和Gen-4此前未与爱沙尼亚遗产互动，我们能够观察到现在机器“如何理解世界”并创造未来遗产。《Quantum est in libris》为文化遗产的概念引入了一个激动人心但又让人不安的新维度：在一个数据流动、解释不稳定的世界上，遗产地位变得脆弱。在数字环境中，文化遗产问题不再仅仅是保存和传递，还包括媒体呈现、机器创造和解释错误。谁或什么塑造了记忆过程和记忆空间，以及它是如何塑造的？', 'title_zh': 'Quantum est in Libris: 刻于卷轴之上：利用生成式AI导航档案馆，揭露保存与创新之间的张力'}
{'arxiv_id': 'arXiv:2509.25235', 'title': 'Machine Learning for Pattern Detection in Printhead Nozzle Logging', 'authors': 'Nikola Prianikov, Evelyne Janssen-van Dam, Marcin Pietrasik, Charalampos S. Kouzinopoulos', 'link': 'https://arxiv.org/abs/2509.25235', 'abstract': 'Correct identification of failure mechanisms is essential for manufacturers to ensure the quality of their products. Certain failures of printheads developed by Canon Production Printing can be identified from the behavior of individual nozzles, the states of which are constantly recorded and can form distinct patterns in terms of the number of failed nozzles over time, and in space in the nozzle grid. In our work, we investigate the problem of printhead failure classification based on a multifaceted dataset of nozzle logging and propose a Machine Learning classification approach for this problem. We follow the feature-based framework of time-series classification, where a set of time-based and spatial features was selected with the guidance of domain experts. Several traditional ML classifiers were evaluated, and the One-vs-Rest Random Forest was found to have the best performance. The proposed model outperformed an in-house rule-based baseline in terms of a weighted F1 score for several failure mechanisms.', 'abstract_zh': '正确的故障机制识别对于确保产品质量至关重要。佳能生产打印开发的喷头某些故障可以通过单个喷嘴的行为进行识别，这些喷嘴的状态不断被记录，并且随着时间的推移和在喷嘴网格的空间中可以形成不同的模式。在本工作中，我们基于喷嘴日志的多维度数据集研究喷头故障分类问题，并提出了一种机器学习分类方法。我们采用了时间序列分类的特征为基础的框架，选择了由领域专家指导的时间和空间特征集。多种传统的机器学习分类器进行了评估，One-vs-Rest 随机森林被发现具有最佳性能。所提出的模型在加权F1分数方面优于内部基于规则的基线模型，对于几种故障机制而言。', 'title_zh': '基于机器学习的 printhead 喷嘴日志模式检测'}
{'arxiv_id': 'arXiv:2509.25233', 'title': 'FedCLF - Towards Efficient Participant Selection for Federated Learning in Heterogeneous IoV Networks', 'authors': 'Kasun Eranda Wijethilake, Adnan Mahmood, Quan Z. Sheng', 'link': 'https://arxiv.org/abs/2509.25233', 'abstract': 'Federated Learning (FL) is a distributed machine learning technique that preserves data privacy by sharing only the trained parameters instead of the client data. This makes FL ideal for highly dynamic, heterogeneous, and time-critical applications, in particular, the Internet of Vehicles (IoV) networks. However, FL encounters considerable challenges in such networks owing to the high data and device heterogeneity. To address these challenges, we propose FedCLF, i.e., FL with Calibrated Loss and Feedback control, which introduces calibrated loss as a utility in the participant selection process and a feedback control mechanism to dynamically adjust the sampling frequency of the clients. The envisaged approach (a) enhances the overall model accuracy in case of highly heterogeneous data and (b) optimizes the resource utilization for resource constrained IoV networks, thereby leading to increased efficiency in the FL process. We evaluated FedCLF vis-à-vis baseline models, i.e., FedAvg, Newt, and Oort, using CIFAR-10 dataset with varying data heterogeneity. Our results depict that FedCLF significantly outperforms the baseline models by up to a 16% improvement in high data heterogeneity-related scenarios with improved efficiency via reduced sampling frequency.', 'abstract_zh': '联邦学习（FL）是一种通过共享训练参数而非客户端数据来保护数据隐私的分布式机器学习技术。这使得FL特别适合高度动态、异构和时间敏感的应用，特别是在车联网（IoV）网络中。然而，由于数据和设备的高度异构性，FL在这样的网络中面临着诸多挑战。为了解决这些挑战，我们提出了FedCLF，即集成校准损失和反馈控制的联邦学习方法，该方法在参与者选择过程中引入了校准损失作为效用，并引入了反馈控制机制以动态调整客户端的采样频率。该设想的方法在数据高度异构的情况下（a）提升了整体模型精度，并在资源受限的车联网网络中（b）优化了资源利用率，从而提高了联邦学习过程的效率。我们使用CIFAR-10数据集和不同水平的数据异构性对FedCLF与基准模型FedAvg、Newt和Oort进行了评估。实验结果表明，在高数据异构性相关场景中，FedCLF相较于基准模型提高了高达16%的性能，并通过降低采样频率提高了效率。', 'title_zh': 'FedCLF - 面向异构IoV网络的联邦学习参与者高效选择方法'}
{'arxiv_id': 'arXiv:2509.25230', 'title': 'Energy Guided Geometric Flow Matching', 'authors': 'Aaron Zweig, Mingxuan Zhang, Elham Azizi, David Knowles', 'link': 'https://arxiv.org/abs/2509.25230', 'abstract': 'A useful inductive bias for temporal data is that trajectories should stay close to the data manifold. Traditional flow matching relies on straight conditional paths, and flow matching methods which learn geodesics rely on RBF kernels or nearest neighbor graphs that suffer from the curse of dimensionality. We propose to use score matching and annealed energy distillation to learn a metric tensor that faithfully captures the underlying data geometry and informs more accurate flows. We demonstrate the efficacy of this strategy on synthetic manifolds with analytic geodesics, and interpolation of cell', 'abstract_zh': '一种对时间数据有用的归纳偏置是轨迹应接近数据流形。传统的流匹配依赖于直线条件路径，而学习测地线的流匹配方法则依赖于受维度灾难影响的RBF核或最近邻图。我们提出使用得分匹配和退火能量蒸馏来学习一个忠实捕捉底层数据几何结构的度量张量，并指导更准确的流匹配。我们在具有解析测地线的合成流形以及细胞插值上展示了该策略的有效性。', 'title_zh': '能量导向几何流匹配'}
{'arxiv_id': 'arXiv:2509.25223', 'title': 'Enhancing Linear Attention with Residual Learning', 'authors': 'Xunhao Lai, Jialiang Kang, Jianqiao Lu, Tong Lin, Pengyu Zhao', 'link': 'https://arxiv.org/abs/2509.25223', 'abstract': 'Linear attention offers a linear-time alternative to self-attention but often struggles to capture long-range patterns. We revisit linear attention through a prediction-correction lens and show that prevalent variants can be written as a combination of a historical prediction and a single-token correction, which creates an expressivity bottleneck. To address this bottleneck, we introduce Residual Linear Attention (RLA), a framework that equips linear attention with an explicit residual-fitting mechanism. RLA maintains an auxiliary recurrent state that learns to accumulate residual errors over time and correct the base prediction. We further instantiate a delta-rule version, Residual Delta Net (RDN), incorporating adaptive gating and residual clipping for enhanced correction control and stability. Our implementation leverages highly optimized linear attention kernels and preserves linear time and memory. Across language modeling and recall-intensive evaluations, RLA and RDN consistently outperform their respective baselines and other modern linear-attention methods, narrowing the gap to standard Transformers while retaining linear scaling.', 'abstract_zh': '基于预测校正视角的残差线性注意力', 'title_zh': '增强线性注意力机制_residual learning优化_'}
{'arxiv_id': 'arXiv:2509.25217', 'title': 'Learning to Condition: A Neural Heuristic for Scalable MPE Inference', 'authors': 'Brij Malhotra, Shivvrat Arya, Tahrima Rahman, Vibhav Giridhar Gogate', 'link': 'https://arxiv.org/abs/2509.25217', 'abstract': 'We introduce learning to condition (L2C), a scalable, data-driven framework for accelerating Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs), a fundamentally intractable problem. L2C trains a neural network to score variable-value assignments based on their utility for conditioning, given observed evidence. To facilitate supervised learning, we develop a scalable data generation pipeline that extracts training signals from the search traces of existing MPE solvers. The trained network serves as a heuristic that integrates with search algorithms, acting as a conditioning strategy prior to exact inference or as a branching and node selection policy within branch-and-bound solvers. We evaluate L2C on challenging MPE queries involving high-treewidth PGMs. Experiments show that our learned heuristic significantly reduces the search space while maintaining or improving solution quality over state-of-the-art methods.', 'abstract_zh': '基于条件学习（L2C）：一种面向概率图形模型（PGMs）最具可能解释（MPE）推理的可扩展数据驱动框架', 'title_zh': '学习条件化：一种可扩展的MPE推断神经启发方法'}
{'arxiv_id': 'arXiv:2509.25214', 'title': 'On-the-Fly Adaptation to Quantization: Configuration-Aware LoRA for Efficient Fine-Tuning of Quantized LLMs', 'authors': 'Rongguang Ye, Ming Tang, Edith C. H. Ngai', 'link': 'https://arxiv.org/abs/2509.25214', 'abstract': 'As increasingly large pre-trained models are released, deploying them on edge devices for privacy-preserving applications requires effective compression. Recent works combine quantization with the fine-tuning of high-precision LoRA adapters, which can substantially reduce model size while mitigating the accuracy loss from quantization. However, edge devices have inherently heterogeneous capabilities, while performing configuration-wise fine-tuning for every quantization setting is computationally prohibitive. In this paper, we propose CoA-LoRA, a method that dynamically adjusts the LoRA adapter to arbitrary quantization configurations (i.e., the per-layer bit-width choices of a pre-trained model) without requiring repeated fine-tuning. This is accomplished via a configuration-aware model that maps each configuration to its low-rank adjustments. The effectiveness of this model critically depends on the training configuration set, a collection of configurations chosen to cover different total bit-width budgets. However, constructing a high-quality configuration set is non-trivial. We therefore design a Pareto-based configuration search that iteratively optimizes the training configuration set, yielding more precise low-rank adjustments. Our experiments demonstrate that, unlike the state-of-the-art methods that require fine-tuning a separate LoRA adapter for each configuration, CoA-LoRA incurs no additional time cost while achieving comparable or even superior performance to those methods.', 'abstract_zh': '随着越来越大规模的预训练模型的发布，将它们部署在边缘设备上以实现隐私保护应用需要有效的压缩方法。近期的研究将量化与高精度LoRA适应器的微调结合起来，这可以在大幅减小模型体积的同时减轻量化带来的准确率损失。然而，边缘设备本身具有固有的异构性，为每个量化设置进行配置级微调在计算上是不可行的。在这篇论文中，我们提出了一种名为CoA-LoRA的方法，可以在无需重复微调的情况下动态调整LoRA适应器以适应任意的量化配置（即预训练模型的每层位宽选择），通过一种配置感知的模型将每个配置映射到其低秩调整。这个模型的有效性严重依赖于训练配置集，这个集合是由不同总位宽预算的选择组成。然而，构建高质量的配置集合并不容易。因此，我们设计了一种基于帕累托优化的配置搜索方法，迭代优化训练配置集，从而获得更精确的低秩调整。实验表明，与最先进的方法需要为每个配置单独微调一个LoRA适应器相比，CoA-LoRA不会增加额外的时间成本，同时能够实现可比甚至更优的性能。', 'title_zh': '基于量化配置的实时自适应：面向高效量化大规模语言模型微调的配置意识LoRA'}
{'arxiv_id': 'arXiv:2509.25213', 'title': 'Six Sigma For Neural Networks: Taguchi-based optimization', 'authors': 'Sai Varun Kodathala', 'link': 'https://arxiv.org/abs/2509.25213', 'abstract': 'The optimization of hyperparameters in convolutional neural networks (CNNs) remains a challenging and computationally expensive process, often requiring extensive trial-and-error approaches or exhaustive grid searches. This study introduces the application of Taguchi Design of Experiments methodology, a statistical optimization technique traditionally used in quality engineering, to systematically optimize CNN hyperparameters for professional boxing action recognition. Using an L12(211) orthogonal array, eight hyperparameters including image size, color mode, activation function, learning rate, rescaling, shuffling, vertical flip, and horizontal flip were systematically evaluated across twelve experimental configurations. To address the multi-objective nature of machine learning optimization, five different approaches were developed to simultaneously optimize training accuracy, validation accuracy, training loss, and validation loss using Signal-to-Noise ratio analysis. The study employed a novel logarithmic scaling technique to unify conflicting metrics and enable comprehensive multi-quality assessment within the Taguchi framework. Results demonstrate that Approach 3, combining weighted accuracy metrics with logarithmically transformed loss functions, achieved optimal performance with 98.84% training accuracy and 86.25% validation accuracy while maintaining minimal loss values. The Taguchi analysis revealed that learning rate emerged as the most influential parameter, followed by image size and activation function, providing clear guidance for hyperparameter prioritization in CNN optimization.', 'abstract_zh': '卷积神经网络（CNN）超参数的优化依然是一个具有挑战性和计算成本高的过程，通常需要大量的试错或全面的网格搜索。本研究引入了Taguchi设计实验方法，一种传统上应用于质量工程中的统计优化技术，用于系统地优化职业boxing动作识别中的CNN超参数。利用L12(211)正交数组，系统地评估了八个超参数包括图像大小、颜色模式、激活函数、学习率、缩放、打乱、垂直翻转和平移翻转，在十二种实验配置中。为了应对机器学习优化中的多目标性质，开发了五种不同的方法，利用信噪比分析同时优化训练精度、验证精度、训练损失和验证损失。研究采用了一种新的对数缩放技术，统一冲突指标并在Taguchi框架内实现全面的质量评估。结果表明，结合加权精度指标和对数变换损失函数的Approach 3实现了最佳性能，训练精度为98.84%，验证精度为86.25%，同时保持最低的损失值。Taguchi分析表明，学习率是最具影响力的参数，其次是图像大小和激活函数，为CNN优化中的超参数优先级提供了清晰的指导。', 'title_zh': '基于田口方法的六西格玛神经网络优化'}
{'arxiv_id': 'arXiv:2509.25210', 'title': 'STCast: Adaptive Boundary Alignment for Global and Regional Weather Forecasting', 'authors': 'Hao Chen, Tao Han, Jie Zhang, Song Guo, Lei Bai', 'link': 'https://arxiv.org/abs/2509.25210', 'abstract': "To gain finer regional forecasts, many works have explored the regional integration from the global atmosphere, e.g., by solving boundary equations in physics-based methods or cropping regions from global forecasts in data-driven methods. However, the effectiveness of these methods is often constrained by static and imprecise regional boundaries, resulting in poor generalization ability. To address this issue, we propose Spatial-Temporal Weather Forecasting (STCast), a novel AI-driven framework for adaptive regional boundary optimization and dynamic monthly forecast allocation. Specifically, our approach employs a Spatial-Aligned Attention (SAA) mechanism, which aligns global and regional spatial distributions to initialize boundaries and adaptively refines them based on attention-derived alignment patterns. Furthermore, we design a Temporal Mixture-of-Experts (TMoE) module, where atmospheric variables from distinct months are dynamically routed to specialized experts using a discrete Gaussian distribution, enhancing the model's ability to capture temporal patterns. Beyond global and regional forecasting, we evaluate our STCast on extreme event prediction and ensemble forecasting. Experimental results demonstrate consistent superiority over state-of-the-art methods across all four tasks.", 'abstract_zh': '基于空间-时间weather预测的自适应区域边界的优化和动态月度预报分配（STCast）', 'title_zh': 'STCast: 自适应边界对齐的全局和地区天气预报'}
{'arxiv_id': 'arXiv:2509.25207', 'title': 'Multi-level Diagnosis and Evaluation for Robust Tabular Feature Engineering with Large Language Models', 'authors': 'Yebin Lim, Susik Yoon', 'link': 'https://arxiv.org/abs/2509.25207', 'abstract': 'Recent advancements in large language models (LLMs) have shown promise in feature engineering for tabular data, but concerns about their reliability persist, especially due to variability in generated outputs. We introduce a multi-level diagnosis and evaluation framework to assess the robustness of LLMs in feature engineering across diverse domains, focusing on the three main factors: key variables, relationships, and decision boundary values for predicting target classes. We demonstrate that the robustness of LLMs varies significantly over different datasets, and that high-quality LLM-generated features can improve few-shot prediction performance by up to 10.52%. This work opens a new direction for assessing and enhancing the reliability of LLM-driven feature engineering in various domains.', 'abstract_zh': 'Recent Advancements in Large Language Models (LLMs) for Feature Engineering in Tabular Data: A Multi-Level Diagnosis and Evaluation Framework for Assessing Robustness Across Diverse Domains', 'title_zh': '大规模语言模型驱动的稳健表格特征工程多层级诊断与评估'}
{'arxiv_id': 'arXiv:2509.25204', 'title': 'Spectral Logit Sculpting: Adaptive Low-Rank Logit Transformation for Controlled Text Generation', 'authors': 'Jin Li, Zhebo Wang, Tianliang Lu, Mohan Li, Wenpeng Xing, Meng Han', 'link': 'https://arxiv.org/abs/2509.25204', 'abstract': 'Entropy-based inference methods have gained traction for improving the reliability of Large Language Models (LLMs). However, many existing approaches, such as entropy minimization techniques, suffer from high computational overhead and fail to leverage historical token context effectively. To address these limitations, we propose Spectral Logit Sculpting (SLS), a lightweight inference-time optimization method that dynamically modulates token distributions using spectral and entropic properties of recent logits. SLS maintains a sliding buffer of top-K logits, performs on-the-fly Singular Value Decomposition (SVD) to identify dominant spectral directions, and adaptively rescales logits based on both entropy and logit gap statistics--only activating when uncertainty is high. Without updating any model parameters, SLS effectively sharpens the output distribution while preserving contextual consistency. Experimental results on multiple public benchmarks demonstrate that SLS consistently outperforms existing baseline methods, achieving superior accuracy in mathematical, coding, and scientific reasoning tasks.', 'abstract_zh': '基于谱投影的logit调控方法（Spectral Logit Sculpting, SLS）在提升大语言模型可靠性方面的轻量级推理时优化方法', 'title_zh': '光谱Logit塑形：自适应低秩Logit变换以实现可控文本生成'}
{'arxiv_id': 'arXiv:2509.25203', 'title': 'Generating High-Quality Datasets for Code Editing via Open-Source Language Models', 'authors': 'Zekai Zhang, Mingwei Liu, Zhenxi Chen, Linxi Liang, Yuxuan Chen, Guangsheng Ou, Yanlin Wang, Dan Li, Xin Peng, Zibin Zheng', 'link': 'https://arxiv.org/abs/2509.25203', 'abstract': 'Code editing plays a vital role in software engineering, requiring developers to adjust existing code according to natural language instructions while keeping functionality intact and avoiding unnecessary modifications. However, commit-based datasets commonly used for this task are often noisy, lack diversity, and fail to reflect the style of real-world edit instructions. To address this, we introduce CanItEdit, an open-source pipeline that leverages multiple LLMs to synthesize realistic code-edit triplets. The pipeline produces both concise "lazy" instructions and more detailed "descriptive" ones, and applies filtering based on diffs and topics to guarantee data quality and variety. Using this process, we construct OCEDataFT, a curated dataset of 20K samples. Fine-tuning three advanced base models on OCEDataFT leads to significant performance boosts on the CanItEdit benchmark, with relative pass@1 improvements ranging from 4.50% to 20.79%. Notably, the resulting models achieve performance close to closed-source systems, narrowing the gap to GPT-4 to just 3.54%, without relying on proprietary resources or manual annotation.', 'abstract_zh': '代码编辑在软件工程中起着至关重要的作用，要求开发人员根据自然语言指令调整现有代码，同时保持功能完整并避免不必要的修改。然而，用于此任务的基于提交的数据集往往噪声较大、缺乏多样性且无法反映实际编辑指令的风格。为解决这一问题，我们引入了CanItEdit，这是一个开源管道，利用多个LLM生成真实的代码编辑三元组。该管道生成简洁的“懒惰”指令和更详细的“描述性”指令，并基于差异和主题进行过滤，以保证数据质量和多样性。使用这一过程，我们构建了OCEDataFT，一个包含20,000个样本的精选数据集。在OCEDataFT上微调三个高级基础模型后，在CanItEdit基准测试中取得了显著性能提升，相对pass@1改进范围从4.50%到20.79%。值得注意的是，这些模型的性能接近商用系统，与GPT-4的差距仅3.54%，且不依赖于专有资源或人工标注。', 'title_zh': '基于开源语言模型生成高质量代码编辑数据集'}
{'arxiv_id': 'arXiv:2509.25197', 'title': 'Towards Repository-Level Program Verification with Large Language Models', 'authors': 'Si Cheng Zhong, Xujie Si', 'link': 'https://arxiv.org/abs/2509.25197', 'abstract': 'Recent advancements in large language models (LLMs) suggest great promises in code and proof generations. However, scaling automated formal verification to real-world projects requires resolving cross-module dependencies and global contexts, which are crucial challenges overlooked by existing LLM-based methods with a special focus on targeting isolated, function-level verification tasks. To systematically explore and address the significant challenges of verifying entire software repositories, we introduce RVBench, the first verification benchmark explicitly designed for repository-level evaluation, constructed from four diverse and complex open-source Verus projects.\nWe further introduce RagVerus, an extensible framework that synergizes retrieval-augmented generation with context-aware prompting to automate proof synthesis for multi-module repositories. RagVerus triples proof pass rates on existing benchmarks under constrained model inference budgets, and achieves a 27% relative improvement on the more challenging RVBench benchmark, demonstrating a scalable and sample-efficient verification solution.', 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）在代码和证明生成方面带来了巨大前景。然而，将自动化形式验证扩展到实际项目需要解决跨模块依赖和全局上下文问题，这是现有的基于LLM的方法特别是专注于孤立的功能级验证任务时忽略的重要挑战。为了系统地探索和解决验证整个软件仓库的关键挑战，我们引入了RVBench，这是第一个明确为仓库级评估设计的验证基准，基于四个多样且复杂的开源Verus项目构建。\n此外，我们引入了RagVerus，这是一种可扩展框架，将检索增强生成与上下文感知提示相结合，以自动化多模块仓库的证明合成。在受约束的模型推理预算下，RagVerus将现有基准上的证明通过率提高三倍，并在更具挑战性的RVBench基准测试中实现了27%的相对改进，展示了可扩展且样本高效的验证解决方案。', 'title_zh': '面向存储库级别程序验证的大语言模型方法'}
{'arxiv_id': 'arXiv:2509.25196', 'title': 'APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning', 'authors': 'Hua Zhong, Shan Jiang, Sarfraz Khurshid', 'link': 'https://arxiv.org/abs/2509.25196', 'abstract': 'APIs are central to modern software development, yet composing new APIs from large libraries is difficult due to the exponential search space; traditional component-based synthesis relies on costly exploration and hand-crafted specifications. While large language models (LLMs) can generate implementations from natural language, hallucinations and limited access to up-to-date contextual information often yield incorrect code. In this paper, we present APRIL, an approach that combines LLM-based synthesis with Automatic Prompt Optimization (APO) and Reinforcement Learning from Verifiable Rewards (RLVR): APO iteratively refines prompts for a frozen model, while RLVR fine-tunes the policy toward functional correctness, producing an efficient synthesis pipeline. Evaluated on 81 real-world APIs from widely used scientific Python libraries and benchmarked against instruction-tuned but unfine-tuned LLMs guided by expert prompts, APRIL achieves substantial improvements. These results indicate that integrating APO and RLVR provides a robust, scalable path for component-based API synthesis in large libraries.', 'abstract_zh': 'APRIL：结合LLM合成、自动提示优化和可验证奖励强化学习的组件化API合成方法', 'title_zh': 'APRIL：带有自动提示优化和强化学习的API合成'}
{'arxiv_id': 'arXiv:2509.25193', 'title': 'Devstral: Fine-tuning Language Models for Coding Agent Applications', 'authors': 'Abhinav Rastogi, Adam Yang, Albert Q. Jiang, Alexander H. Liu, Alexandre Sablayrolles, Amélie Héliou, Amélie Martin, Anmol Agarwal, Andy Ehrenberg, Andy Lo, Antoine Roux, Arthur Darcet, Arthur Mensch, Baptiste Bout, Baptiste Rozière, Baudouin De Monicault, Chris Bamford, Christian Wallenwein, Christophe Renaudin, Clémence Lanfranchi, Clément Denoix, Corentin Barreau, Darius Dabert Devon Mizelle, Diego de las Casas, Elliot Chane-Sane, Emilien Fugier, Emma Bou Hanna, Gabrielle Berrada, Gauthier Delerce, Gauthier Guinet, Georgii Novikov, Graham Neubig, Guillaume Lample, Guillaume Martin, Himanshu Jaju, Jan Ludziejewski, Jason Rute, Jean-Malo Delignon, JeanHadrien Chabran, Joachim Studnia, Joep Barmentlo, Jonas Amar, Josselin Somerville Roberts, Julien Denize, Karan Saxena, Karmesh Yadav, Kartik Khandelwal, Khyathi Raghavi Chandu, Kush Jain, Lélio Renard Lavaud, Léonard Blier, Lingxiao Zhao, Louis Martin, Lucile Saulnier, Luyu Gao, Marie Pellat, Mathilde Guillaumin, Mathis Felardos, Matthieu Dinot, Maxime Darrin, Maximilian Augustin, Mickaël Seznec, Neha Gupta, Nikhil Raghuraman, Olivier Duchenne, Patricia Wang, Patrick von Platen, Patryk Saffer, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Philomène Chagniot, Pierre Stock, Pravesh Agrawal, Rémi Delacourt, Roman Soletskyi, Romain Sauvestre, Sagar Vaze, Sanchit Gandhi, Sandeep Subramanian, Shashwat Dalal, Siddharth Gandhi, Soham Ghosh, Srijan Mishra, Sumukh Aithal, Szymon Antoniak, Teven Le Scao, Thibaut Lavril, Thibault Schueller, Thomas Foubert, Thomas Robert, Thomas Wang, Timothée Lacroix, Tom Bewley, Valeriia Nemychnikova, Victor Paltz, Virgile Richard, Wen-Ding Li, William Marshall, Xingyao Wang', 'link': 'https://arxiv.org/abs/2509.25193', 'abstract': 'We introduce Devstral-Small, a lightweight open source model for code agents with the best performance among models below 100B size. In this technical report, we give an overview of how we design and develop a model and craft specializations in agentic software development. The resulting model, Devstral-Small is a small 24B model, fast and easy to serve. Despite its size, Devstral-Small still attains competitive performance compared to models more than an order of magnitude larger.', 'abstract_zh': 'Devstral-Small：一种轻量级开源代码代理模型，兼具最佳性能', 'title_zh': 'Devstral: 用于编码代理应用的语言模型微调'}
{'arxiv_id': 'arXiv:2509.23025', 'title': 'Perceptual Influence: Improving the Perceptual Loss Design for Low-Dose CT Enhancement', 'authors': 'Gabriel A. Viana, Luis F. Alves Pereira, Tsang Ing Ren, George D. C. Cavalcanti, Jan Sijbers', 'link': 'https://arxiv.org/abs/2509.23025', 'abstract': 'Perceptual losses have emerged as powerful tools for training networks to enhance Low-Dose Computed Tomography (LDCT) images, offering an alternative to traditional pixel-wise losses such as Mean Squared Error, which often lead to over-smoothed reconstructions and loss of clinically relevant details in LDCT images. The perceptual losses operate in a latent feature space defined by a pretrained encoder and aim to preserve semantic content by comparing high-level features rather than raw pixel values. However, the design of perceptual losses involves critical yet underexplored decisions, including the feature representation level, the dataset used to pretrain the encoder, and the relative importance assigned to the perceptual component during optimization. In this work, we introduce the concept of perceptual influence (a metric that quantifies the relative contribution of the perceptual loss term to the total loss) and propose a principled framework to assess the impact of the loss design choices on the model training performance. Through systematic experimentation, we show that the widely used configurations in the literature to set up a perceptual loss underperform compared to better-designed alternatives. Our findings show that better perceptual loss designs lead to significant improvements in noise reduction and structural fidelity of reconstructed CT images, without requiring any changes to the network architecture. We also provide objective guidelines, supported by statistical analysis, to inform the effective use of perceptual losses in LDCT denoising. Our source code is available at this https URL.', 'abstract_zh': '感知损失已成为训练网络提升低剂量计算机断层扫描（LDCT）图像的强大工具，提供了一种不同于传统的像素级损失（如均方误差），后者常导致过度平滑的重构并丢失临床相关的细节。感知损失在由预训练编码器定义的潜在特征空间中操作，通过比较高层特征而非原始像素值来保留语义内容。然而，感知损失的设计包含许多关键但尚未充分探索的决策，包括特征表示层、用于预训练编码器的数据集，以及优化过程中感知组件的重要性权重。在本文中，我们引入了感知影响（量化感知损失项对总损失相对贡献的度量）的概念，并提出了一种原则性的框架来评估损失设计选择对模型训练性能的影响。通过系统实验，我们表明文献中广泛使用的感知损失配置表现不如更好设计的替代方案。我们的发现表明，更好的感知损失设计在不改变网络架构的情况下，显著提高了重构CT图像的降噪性能和结构保真度。我们还提供了基于统计分析的支持性客观指南，以指导感知损失在LDCT降噪中的有效使用。我们的源代码可在以下链接获取。', 'title_zh': '感知影响：改进低剂量CT增强的感知损失设计'}
{'arxiv_id': 'arXiv:2509.22628', 'title': 'UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning', 'authors': 'Hongyu Chen, Guangrun Wang', 'link': 'https://arxiv.org/abs/2509.22628', 'abstract': 'Chain-of-Thought (CoT) prompting improves reasoning in large language models (LLMs), but its reliance on unstructured text limits interpretability and executability in embodied tasks. Prior work has explored structured CoTs using scene or logic graphs, yet these remain fundamentally limited: they model only low-order relations, lack constructs like inheritance or behavioral abstraction, and provide no standardized semantics for sequential or conditional planning. We propose UML-CoT, a structured reasoning and planning framework that leverages Unified Modeling Language (UML) to generate symbolic CoTs and executable action plans. UML class diagrams capture compositional object semantics, while activity diagrams model procedural control flow. Our three-stage training pipeline combines supervised fine-tuning with Group Relative Policy Optimization (GRPO), including reward learning from answer-only data. We evaluate UML-CoT on MRoom-30k, a new benchmark of cluttered room-cleaning scenarios. UML-CoT outperforms unstructured CoTs in interpretability, planning coherence, and execution success, highlighting UML as a more expressive and actionable structured reasoning formalism.', 'abstract_zh': 'UML-CoT：一种基于统一建模语言的结构化推理和规划框架', 'title_zh': 'UML-CoT: 基于统一建模语言的结构化推理与规划在机器人房间清洁中的应用'}
{'arxiv_id': 'arXiv:2509.00105', 'title': 'AdaptCache: KV Cache Native Storage Hierarchy for Low-Delay and High-Quality Language Model Serving', 'authors': 'Shaoting Feng, Hanchen Li, Kuntai Du, Zhuohan Gu, Yuhan Liu, Jiayi Yao, Siddhant Ray, Samuel Shen, Yihua Cheng, Ganesh Ananthanarayanan, Junchen Jiang', 'link': 'https://arxiv.org/abs/2509.00105', 'abstract': 'Large language model (LLM) applications often reuse previously processed context, such as chat history and documents, which introduces significant redundant computation. Existing LLM serving systems address such redundant computation by storing the KV caches of processed context and loading the corresponding KV cache when a new request reuses the context. Further, as these LLM applications scale, the total size of KV caches becomes excessively large and requires both DRAM and SSD for full storage.\nHowever, prior work that stores KV caches in DRAM and SSD suffers from high loading delays, as most KV cache hits come from SSD, which is slow to load. To increase the KV cache hit rate on DRAM, we identify lossy KV cache compression as a promising approach. We design a lossy compression system that decides the compression algorithm, compression rate and device placement for each KV cache entry to maximise DRAM hits and minimise loading delay without significantly degrading generation quality. Compared to various static compression baselines across three tasks, our system AdaptCache achieves 1.43--2.4 x delay savings at the same quality and 6--55% quality improvements at the same delay.', 'abstract_zh': '大型语言模型（LLM）应用通常重用先前处理的上下文，如聊天历史和文档，这引入了显著的冗余计算。现有LLM服务系统通过存储处理上下文的KV缓存，并在新请求重用上下文时加载相应的KV缓存来解决这种冗余计算问题。随着这些LLM应用的扩展，KV缓存的总大小变得异常庞大，需要同时使用DRAM和SSD进行全存储。\n\n然而，以往将KV缓存存储在DRAM和SSD中的工作面临着高加载延迟的问题，因为大多数KV缓存命中来自于SSD，加载速度较慢。为了提高DRAM中的KV缓存命中率，我们确定了有损KV缓存压缩作为一种有前景的方法。我们设计了一种有损压缩系统，为每个KV缓存项决定压缩算法、压缩率和设备放置，以最大化DRAM命中率、最小化加载延迟，同时不显著降低生成质量。与三个任务的多种静态压缩基准相比，我们的系统AdaptCache在相同质量下实现了1.43–2.4倍的延迟节省，在相同延迟下实现了6–55%的质量提升。', 'title_zh': 'AdaptCache：低延迟和高性能语言模型服务的键值缓存内置存储层次结构'}
{'arxiv_id': 'arXiv:2507.23390', 'title': 'FMIP: Joint Continuous-Integer Flow For Mixed-Integer Linear Programming', 'authors': 'Hongpei Li, Hui Yuan, Han Zhang, Jianghao Lin, Dongdong Ge, Mengdi Wang, Yinyu Ye', 'link': 'https://arxiv.org/abs/2507.23390', 'abstract': 'Mixed-Integer Linear Programming (MILP) is a foundational tool for complex decision-making problems. However, the NP-hard nature of MILP presents a significant computational challenge, motivating the development of machine learning-based heuristic solutions to accelerate downstream solvers. While recent generative models have shown promise in learning powerful heuristics, they suffer from a critical limitation. That is, they model the distribution of only the integer variables and fail to capture the intricate coupling between integer and continuous variables, creating an information bottleneck and ultimately leading to suboptimal solutions. To this end, we propose Joint Continuous-Integer Flow for Mixed-Integer Linear Programming (FMIP), which is the first generative framework that models the joint distribution of both integer and continuous variables for MILP solutions. Built upon the joint modeling paradigm, a holistic guidance mechanism is designed to steer the generative trajectory, actively refining solutions toward optimality and feasibility during the inference process. Extensive experiments on eight standard MILP benchmarks demonstrate the superior performance of FMIP against existing baselines, reducing the primal gap by 41.34% on average. Moreover, we show that FMIP is fully compatible with arbitrary backbone networks and various downstream solvers, making it well-suited for a broad range of real-world MILP applications.', 'abstract_zh': 'Joint Continuous-Integer Flow for Mixed-Integer Linear Programming (FMIP)', 'title_zh': 'FMIP: 联合连续-整数流的混合整数线性规划'}
{'arxiv_id': 'arXiv:2505.23495', 'title': 'Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking', 'authors': 'Liangliang Zhang, Zhuorui Jiang, Hongliang Chi, Haoyang Chen, Mohammed Elkoumy, Fali Wang, Qiong Wu, Zhengyi Zhou, Shirui Pan, Suhang Wang, Yao Ma', 'link': 'https://arxiv.org/abs/2505.23495', 'abstract': 'Knowledge Graph Question Answering (KGQA) systems rely on high-quality benchmarks to evaluate complex multi-hop reasoning. However, despite their widespread use, popular datasets such as WebQSP and CWQ suffer from critical quality issues, including inaccurate or incomplete ground-truth annotations, poorly constructed questions that are ambiguous, trivial, or unanswerable, and outdated or inconsistent knowledge. Through a manual audit of 16 popular KGQA datasets, including WebQSP and CWQ, we find that the average factual correctness rate is only 57 %. To address these issues, we introduce KGQAGen, an LLM-in-the-loop framework that systematically resolves these pitfalls. KGQAGen combines structured knowledge grounding, LLM-guided generation, and symbolic verification to produce challenging and verifiable QA instances. Using KGQAGen, we construct KGQAGen-10k, a ten-thousand scale benchmark grounded in Wikidata, and evaluate a diverse set of KG-RAG models. Experimental results demonstrate that even state-of-the-art systems struggle on this benchmark, highlighting its ability to expose limitations of existing models. Our findings advocate for more rigorous benchmark construction and position KGQAGen as a scalable framework for advancing KGQA evaluation.', 'abstract_zh': '基于知识图谱的问答系统（KGQA）依赖高质量的基准进行复杂多跳推理评估。然而，尽管这些系统广泛应用，流行的数据集如WebQSP和CWQ存在严重质量问题，包括不准确或不完整的ground-truth注释、语义模糊、平凡或不可回答的问题，以及过时或不一致的知识。通过对16个流行的KGQA数据集进行手动审计，包括WebQSP和CWQ，我们发现这些数据集的事实正确率平均仅为57%。为了解决这些问题，我们引入了KGQAGen，这是一个LLM辅助框架，系统性地解决了这些问题。KGQAGen结合了结构化知识 grounding、LLM引导生成和符号验证，以生成具有挑战性和可验证的问答实例。使用KGQAGen，我们构建了基于Wikidata的KGQAGen-10k基准，并评估了多种KG-RAG模型。实验结果表明，即使最先进的系统在该基准上也面临困难，突显了其揭示现有模型局限性的能力。我们的发现呼吁更加严格的基准构建，并将KGQAGen定位为推动KGQA评估可扩展框架。', 'title_zh': '诊断和解决KG-RAG数据集中的 pitfalls：朝着更可靠的基准测试迈进'}
