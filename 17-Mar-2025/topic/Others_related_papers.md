# Multi-agent coordination for on-demand data gathering with periodic information upload 

**Title (ZH)**: 按需数据搜集与周期性信息上传的多agent协调 

**Authors**: Yaroslav Marchukov, Luis Montano  

**Link**: [PDF](https://arxiv.org/pdf/2503.11504)  

**Abstract**: In this paper we develop a method for planning and coordinating a multi-agent team deployment to periodically gather information on demand. A static operation center (OC) periodically requests information from changing goal locations. The objective is to gather data in the goals and to deliver it to the OC, balancing the refreshing time and the total number of information packages. The system automatically splits the team in two roles: workers to gather data, or collectors to retransmit the data to the OC. The proposed three step method: 1) finds out the best area partition for the workers; 2) obtains the best balance between workers and collectors, and with whom the workers must to communicate, a collector or the OC; 3) computes the best tour for the workers to visit the goals and deliver them to the OC or to a collector in movement. The method is tested in simulations in different scenarios, providing the best area partition algorithm and the best balance between collectors and workers. 

**Abstract (ZH)**: 本文开发了一种方法，用于规划和协调多代理团队部署，以定期收集需求信息。一个固定的运营中心（OC）定期从不断变化的目标位置请求信息。目标是收集目标数据并将其传递给OC，平衡刷新时间和总信息包数。系统自动将团队分为两种角色：收集数据的工人或重新传输数据的收集者。提出的三步方法包括：1）确定工人的最佳区域划分；2）获得工人与收集者之间最佳平衡以及工人需要与谁通信（收集者或OC）；3）计算工人的最佳路线，以访问目标并将数据传递给OC或移动中的收集者。该方法在不同的仿真场景中进行了测试，提供了最佳区域划分算法和收集者与工人之间最佳平衡。 

---
# AQUA-SLAM: Tightly-Coupled Underwater Acoustic-Visual-Inertial SLAM with Sensor Calibration 

**Title (ZH)**: AQUA-SLAM：基于传感器标定的水下声学-视觉-惯性SLAM 

**Authors**: Shida Xu, Kaicheng Zhang, Sen Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.11420)  

**Abstract**: Underwater environments pose significant challenges for visual Simultaneous Localization and Mapping (SLAM) systems due to limited visibility, inadequate illumination, and sporadic loss of structural features in images. Addressing these challenges, this paper introduces a novel, tightly-coupled Acoustic-Visual-Inertial SLAM approach, termed AQUA-SLAM, to fuse a Doppler Velocity Log (DVL), a stereo camera, and an Inertial Measurement Unit (IMU) within a graph optimization framework. Moreover, we propose an efficient sensor calibration technique, encompassing multi-sensor extrinsic calibration (among the DVL, camera and IMU) and DVL transducer misalignment calibration, with a fast linear approximation procedure for real-time online execution. The proposed methods are extensively evaluated in a tank environment with ground truth, and validated for offshore applications in the North Sea. The results demonstrate that our method surpasses current state-of-the-art underwater and visual-inertial SLAM systems in terms of localization accuracy and robustness. The proposed system will be made open-source for the community. 

**Abstract (ZH)**: 水下环境对视觉同时定位与建图（SLAM）系统构成了显著挑战，由于能见度有限、光照不足以及图像中结构特征的间歇性丢失。为应对这些挑战，本文提出了一种新的紧密耦合的声学-视觉-惯性SLAM方法，称为AQUA-SLAM，该方法在图优化框架内融合了多普勒速度记录仪（DVL）、立体相机和惯性测量单元（IMU）。此外，本文还提出了一种高效的传感器校准技术，包括多传感器外部校准（DVL、相机和IMU之间）和换能器偏移校准，并采用快速线性逼近程序以实现实时在线执行。所提出的方法在含地面真实数据的水箱环境中进行了广泛评估，并在北海的离岸应用中进行了验证。实验结果表明，该方法在定位精度和鲁棒性方面超越了当前最先进的水下和视觉-惯性SLAM系统。提出的系统将对社区开源。 

---
# GAIPAT -Dataset on Human Gaze and Actions for Intent Prediction in Assembly Tasks 

**Title (ZH)**: GAIPAT - 基于组装任务中人类凝视和动作的意图预测数据集 

**Authors**: Maxence Grand, Damien Pellier, Francis Jambon  

**Link**: [PDF](https://arxiv.org/pdf/2503.11186)  

**Abstract**: The primary objective of the dataset is to provide a better understanding of the coupling between human actions and gaze in a shared working environment with a cobot, with the aim of signifcantly enhancing the effciency and safety of humancobot interactions. More broadly, by linking gaze patterns with physical actions, the dataset offers valuable insights into cognitive processes and attention dynamics in the context of assembly tasks. The proposed dataset contains gaze and action data from approximately 80 participants, recorded during simulated industrial assembly tasks. The tasks were simulated using controlled scenarios in which participants manipulated educational building blocks. Gaze data was collected using two different eye-tracking setups -head-mounted and remote-while participants worked in two positions: sitting and standing. 

**Abstract (ZH)**: 该数据集的主要目标是提供人类动作与协作机器人（cobot）工作环境中 gaze 耦合的更好理解，旨在显著提高人-协作机器人交互的效率和安全性。更广泛地说，通过将 gaze 模式与物理动作联系起来，数据集提供了有关装配任务背景下认知过程和注意动态的宝贵见解。所提出的数据集包含约 80 名参与者的 gaze 和动作数据，这些数据是在模拟工业装配任务期间记录的。任务使用受控场景进行模拟，参与者操作教育积木。 gaze 数据使用两种不同的眼球追踪设置（头戴式和远程）在参与者坐着和站着的两种姿势下进行收集。 

---
# Leveraging Semantic Graphs for Efficient and Robust LiDAR SLAM 

**Title (ZH)**: 利用语义图实现高效稳健的LiDAR SLAM 

**Authors**: Neng Wang, Huimin Lu, Zhiqiang Zheng, Hesheng Wang, Yun-Hui Liu, Xieyuanli Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.11145)  

**Abstract**: Accurate and robust simultaneous localization and mapping (SLAM) is crucial for autonomous mobile systems, typically achieved by leveraging the geometric features of the environment. Incorporating semantics provides a richer scene representation that not only enhances localization accuracy in SLAM but also enables advanced cognitive functionalities for downstream navigation and planning tasks. Existing point-wise semantic LiDAR SLAM methods often suffer from poor efficiency and generalization, making them less robust in diverse real-world scenarios. In this paper, we propose a semantic graph-enhanced SLAM framework, named SG-SLAM, which effectively leverages the geometric, semantic, and topological characteristics inherent in environmental structures. The semantic graph serves as a fundamental component that facilitates critical functionalities of SLAM, including robust relocalization during odometry failures, accurate loop closing, and semantic graph map construction. Our method employs a dual-threaded architecture, with one thread dedicated to online odometry and relocalization, while the other handles loop closure, pose graph optimization, and map update. This design enables our method to operate in real time and generate globally consistent semantic graph maps and point cloud maps. We extensively evaluate our method across the KITTI, MulRAN, and Apollo datasets, and the results demonstrate its superiority compared to state-of-the-art methods. Our method has been released at this https URL. 

**Abstract (ZH)**: 准确且鲁棒的语义增强 simultaneous localization and mapping (SLAM) 对自主移动系统至关重要，通常通过利用环境的几何特征来实现。在SLAM中结合语义可以提供更丰富的场景表示，不仅提高了定位精度，还为下游的导航和规划任务提供了高级的认知功能。现有的基于点的语义LiDAR SLAM方法往往效率低下且泛化能力差，使其在多种真实场景中不够鲁棒。在本文中，我们提出了一种语义图增强的SLAM框架，名为SG-SLAM，该框架有效地利用了环境结构中固有的几何、语义和拓扑特征。语义图作为基本组件，支持SLAM的关键功能，包括里程计失败时的鲁棒重新定位、精确的环回闭合以及语义图地图构建。该方法采用双线程架构，一个线程用于在线里程计和重新定位，而另一个线程处理环回闭合、姿态图优化和地图更新。这种设计使得我们的方法能够实时运行，并生成全局一致的语义图地图和点云地图。我们在Kitti、MulRan和Apollo数据集上对我们的方法进行了广泛评估，结果表明其优于最先进的方法。我们的方法已发布在该网址：[这里提供网址]。 

---
# Unicorn: A Universal and Collaborative Reinforcement Learning Approach Towards Generalizable Network-Wide Traffic Signal Control 

**Title (ZH)**: unicorn：通用协作的网络级交通信号控制 reinforcement learning 方法 

**Authors**: Yifeng Zhang, Yilin Liu, Ping Gong, Peizhuo Li, Mingfeng Fan, Guillaume Sartoretti  

**Link**: [PDF](https://arxiv.org/pdf/2503.11488)  

**Abstract**: Adaptive traffic signal control (ATSC) is crucial in reducing congestion, maximizing throughput, and improving mobility in rapidly growing urban areas. Recent advancements in parameter-sharing multi-agent reinforcement learning (MARL) have greatly enhanced the scalable and adaptive optimization of complex, dynamic flows in large-scale homogeneous networks. However, the inherent heterogeneity of real-world traffic networks, with their varied intersection topologies and interaction dynamics, poses substantial challenges to achieving scalable and effective ATSC across different traffic scenarios. To address these challenges, we present Unicorn, a universal and collaborative MARL framework designed for efficient and adaptable network-wide ATSC. Specifically, we first propose a unified approach to map the states and actions of intersections with varying topologies into a common structure based on traffic movements. Next, we design a Universal Traffic Representation (UTR) module with a decoder-only network for general feature extraction, enhancing the model's adaptability to diverse traffic scenarios. Additionally, we incorporate an Intersection Specifics Representation (ISR) module, designed to identify key latent vectors that represent the unique intersection's topology and traffic dynamics through variational inference techniques. To further refine these latent representations, we employ a contrastive learning approach in a self-supervised manner, which enables better differentiation of intersection-specific features. Moreover, we integrate the state-action dependencies of neighboring agents into policy optimization, which effectively captures dynamic agent interactions and facilitates efficient regional collaboration. Our results show that Unicorn outperforms other methods across various evaluation metrics, highlighting its potential in complex, dynamic traffic networks. 

**Abstract (ZH)**: 自适应交通信号控制（ATSC）在减少拥堵、最大化 throughput 和提高快速成长的都市地区的 mobility 方面至关重要。参数共享多智能体 reinforcement 学习（MARL）的最新进展极大地增强了大规模同质网络中复杂动态流量的可扩展和自适应优化。然而，真实世界交通网络的固有异质性，包括其各异的交叉口拓扑和相互作用动态，对在不同交通场景中实现可扩展和有效的 ATSC 带来了重大挑战。为应对这些挑战，我们提出了 Unicorn，一种用于高效和自适应网络范围 ATSC 的通用协作 MARL 框架。具体而言，我们首先提出了一种统一的方法，将不同拓扑结构交叉口的状态和行动映射到基于交通流动的共同结构。接着，我们设计了一个通用交通表示（UTR）模块，该模块使用解码器网络进行通用特征提取，增强了模型对多种交通场景的适应性。此外，我们整合了一个特定交叉口表示（ISR）模块，通过变分推断技术识别代表特定交叉口拓扑和交通动态的关键潜在向量。为了进一步细化这些潜在表示，我们采用了自监督的对比学习方法，这使得更好地区分交叉口特定特征成为可能。此外，我们将相邻智能体的状态-行动依赖性整合到策略优化中，有效地捕捉动态智能体交互并促进高效的区域协作。我们的结果表明，Unicorn 在各种评估指标上优于其他方法，突显了其在复杂动态交通网络中的潜力。 

---
# Heterogeneous Causal Discovery of Repeated Undesirable Health Outcomes 

**Title (ZH)**: 异质因果发现重复不良健康结果 

**Authors**: Shishir Adhikari, Guido Muscioni, Mark Shapiro, Plamen Petrov, Elena Zheleva  

**Link**: [PDF](https://arxiv.org/pdf/2503.11477)  

**Abstract**: Understanding factors triggering or preventing undesirable health outcomes across patient subpopulations is essential for designing targeted interventions. While randomized controlled trials and expert-led patient interviews are standard methods for identifying these factors, they can be time-consuming and infeasible. Causal discovery offers an alternative to conventional approaches by generating cause-and-effect hypotheses from observational data. However, it often relies on strong or untestable assumptions, which can limit its practical application. This work aims to make causal discovery more practical by considering multiple assumptions and identifying heterogeneous effects. We formulate the problem of discovering causes and effect modifiers of an outcome, where effect modifiers are contexts (e.g., age groups) with heterogeneous causal effects. Then, we present a novel, end-to-end framework that incorporates an ensemble of causal discovery algorithms and estimation of heterogeneous effects to discover causes and effect modifiers that trigger or inhibit the outcome. We demonstrate that the ensemble approach improves robustness by enhancing recall of causal factors while maintaining precision. Our study examines the causes of repeat emergency room visits for diabetic patients and hospital readmissions for ICU patients. Our framework generates causal hypotheses consistent with existing literature and can help practitioners identify potential interventions and patient subpopulations to focus on. 

**Abstract (ZH)**: 理解触发或预防特定健康结果的因子对于不同患者亚群体至关重要，有助于设计针对性的干预措施。虽然随机对照试验和专家主导的患者访谈是识别这些因子的标准方法，但它们常常耗时且不可行。因果发现提供了一种替代传统的途径，通过从观察数据生成因果效应假说。然而，它常常依赖于强有力的或无法验证的假设，这限制了其实际应用。本研究旨在通过考虑多种假设并识别异质效应来让因果发现更具实用性。我们形式化了发现结果原因和效应修饰者的问题，其中效应修饰者是具有异质因果效应的上下文（例如，年龄组）。然后，我们提出了一种新颖的一站式框架，结合因果发现算法的ensemble方法和异质效应的估计，以发现触发或抑制结果的原因和效应修饰者。我们证明ensemble方法通过提高因果因子召回率的同时保持高精确度，增强了鲁棒性。我们的研究分析了糖尿病患者重复急诊和ICU患者院内再入院的原因，并生成与现有文献一致的因果假说，有助于实践者识别潜在的干预措施和关注的患者亚群体。 

---
# Preference Elicitation for Multi-objective Combinatorial Optimization with Active Learning and Maximum Likelihood Estimation 

**Title (ZH)**: 基于主动学习和最大似然估计的多目标组合优化的偏好 elicitation 

**Authors**: Marianne Defresne, Jayanta Mandi, Tias Guns  

**Link**: [PDF](https://arxiv.org/pdf/2503.11435)  

**Abstract**: Real-life combinatorial optimization problems often involve several conflicting objectives, such as price, product quality and sustainability. A computationally-efficient way to tackle multiple objectives is to aggregate them into a single-objective function, such as a linear combination. However, defining the weights of the linear combination upfront is hard; alternatively, the use of interactive learning methods that ask users to compare candidate solutions is highly promising. The key challenges are to generate candidates quickly, to learn an objective function that leads to high-quality solutions and to do so with few user interactions. We build upon the Constructive Preference Elicitation framework and show how each of the three properties can be improved: to increase the interaction speed we investigate using pools of (relaxed) solutions, to improve the learning we adopt Maximum Likelihood Estimation of a Bradley-Terry preference model; and to reduce the number of user interactions, we select the pair of candidates to compare with an ensemble-based acquisition function inspired from Active Learning. Our careful experimentation demonstrates each of these improvements: on a PC configuration task and a realistic multi-instance routing problem, our method selects queries faster, needs fewer queries and synthesizes higher-quality combinatorial solutions than previous CPE methods. 

**Abstract (ZH)**: 现实生活中组合优化问题往往涉及多个相互冲突的目标，如价格、产品质量和可持续性。一种计算效率高的方法是将这些目标聚合为一个目标函数，例如线性组合。然而，提前定义线性组合的权重颇具挑战性；相反，采用交互学习方法，要求用户比较候选解是极具前景的。关键挑战在于快速生成候选解、学习能够产生高质量解决方案的目标函数，并且在较少用户交互的情况下实现这一点。我们基于Constructive Preference Elicitation框架，展示如何改进上述三种特性：通过使用候选解池（放宽约束的解）来提高交互速度；通过采用Bradley-Terry偏好模型的最大似然估计来改进学习；通过使用基于集成的获取函数，该函数借鉴主动学习的方法来减少用户交互次数。我们仔细的实验表明这些改进的有效性：在PC配置任务和一个实际的多实例路由问题上，我们的方法更快地选择了查询、需要更少的查询次数，并且能够合成出更高质量的组合解，比之前的CPE方法更为优异。 

---
# Resource Constrained Pathfinding with A* and Negative Weights 

**Title (ZH)**: 资源约束路径寻找算法与负权重 

**Authors**: Saman Ahmadi, Andrea Raith, Mahdi Jalili  

**Link**: [PDF](https://arxiv.org/pdf/2503.11037)  

**Abstract**: Constrained pathfinding is a well-studied, yet challenging network optimisation problem that can be seen in a broad range of real-world applications. Pathfinding with multiple resource limits, which is known as the Resource Constrained Shortest Path Problem (RCSP), aims to plan a cost-optimum path subject to limited usage of resources. Given the recent advances in constrained and multi-criteria search with A*, this paper introduces a new resource constrained search framework on the basis of A* to tackle RCSP in large networks, even in the presence of negative cost and negative resources. We empirically evaluate our new algorithm on a set of large instances and show up to two orders of magnitude faster performance compared to state-of-the-art RCSP algorithms in the literature. 

**Abstract (ZH)**: 受约束的路径规划是既研究充分又具有挑战性的网络优化问题，广泛应用于现实生活中的多种场景。资源约束下的最短路径问题（RCSP）旨在在资源限制下规划成本最优路径。基于A*的新型资源约束搜索框架在大规模网络中解决RCSP问题，即使在存在负成本和负资源的情况下也是如此。我们的新算法在一系列大规模实例上的实验评估显示，性能比文献中现有的RCSP算法快两个数量级。 

---
# Rotated Bitboards in FUSc# and Reinforcement Learning in Computer Chess and Beyond 

**Title (ZH)**: Rotated 位板在 FUSc# 中的应用与 reinforcement learning 在国际象棋及其他领域的应用 

**Authors**: Johannes Buchner  

**Link**: [PDF](https://arxiv.org/pdf/2503.10822)  

**Abstract**: There exist several techniques for representing the chess board inside the computer. In the first part of this paper, the concepts of the bitboard-representation and the advantages of (rotated) bitboards in move generation are explained. In order to illustrate those ideas practice, the concrete implementation of the move-generator in FUSc# is discussed and we explain a technique how to verify the move-generator with the "perft"-command. We show that the move-generator of FUSc# works 100% correct.
The second part of this paper deals with reinforcement learning in computer chess (and beyond). We exemplify the progress that has been made in this field in the last 15-20 years by comparing the "state of the art" from 2002-2008, when FUSc# was developed, with recent innovations connected to "AlphaZero". We discuss how a "FUSc#-Zero" could be implemented and what would be necessary to reduce the number of training games necessary to achieve a good performance. This can be seen as a test case to the general prblem of improving "sample effciency" in reinforcement learning.
In the final part, we move beyond computer chess, as the importance of sample effciency extends far beyond board games into a wide range of applications where data is costly, diffcult to obtain, or time consuming to generate. We review some application of the ideas developed in AlphaZero in other domains, i.e. the "other Alphas" like AlphaFold, AlphaTensor, AlphaGeometry and AlphaProof. We also discuss future research and the potential for such methods for ecological economic planning. 

**Abstract (ZH)**: 几种棋盘表示技术存在。本文第一部分解释了位板表示的概念以及旋转位板在走子生成中的优势。为了说明这些概念，我们详细讨论了FUSc#中的走子生成器的具体实现，并介绍了使用“perft”命令验证走子生成器的方法，证明了FUSc#的走子生成器100%正确。本文第二部分探讨了计算机象棋中的强化学习（以及更广泛的领域）。通过将2002-2008年FUSc#的最新技术与近年来与“AlphaZero”相关的创新进行对比，我们展示了过去15-20年领域的进展，并讨论了如何实现一个“FUSc#-Zero”，以及如何减少达到良好表现所需的训练游戏数量。这可以被视为提高强化学习中“样本效率”的一般问题的一个测试案例。在最终部分，我们超越了计算机象棋，因为样本效率的重要性远远超出了棋盘游戏，扩展到了数据收集成本高、困难或耗时生成的广泛应用领域。我们回顾了AlphaZero在其他领域中的应用，如AlphaFold、AlphaTensor、AlphaGeometry和AlphaProof，并讨论了此类方法在生态经济规划中的未来研究和潜力。 

---
# Designing Neural Synthesizers for Low Latency Interaction 

**Title (ZH)**: 设计低延迟交互的神经合成器 

**Authors**: Franco Caspe, Jordie Shier, Mark Sandler, Charalampos Saitis, Andrew McPherson  

**Link**: [PDF](https://arxiv.org/pdf/2503.11562)  

**Abstract**: Neural Audio Synthesis (NAS) models offer interactive musical control over high-quality, expressive audio generators. While these models can operate in real-time, they often suffer from high latency, making them unsuitable for intimate musical interaction. The impact of architectural choices in deep learning models on audio latency remains largely unexplored in the NAS literature. In this work, we investigate the sources of latency and jitter typically found in interactive NAS models. We then apply this analysis to the task of timbre transfer using RAVE, a convolutional variational autoencoder for audio waveforms introduced by Caillon et al. in 2021. Finally, we present an iterative design approach for optimizing latency. This culminates with a model we call BRAVE (Bravely Realtime Audio Variational autoEncoder), which is low-latency and exhibits better pitch and loudness replication while showing timbre modification capabilities similar to RAVE. We implement it in a specialized inference framework for low-latency, real-time inference and present a proof-of-concept audio plugin compatible with audio signals from musical instruments. We expect the challenges and guidelines described in this document to support NAS researchers in designing models for low-latency inference from the ground up, enriching the landscape of possibilities for musicians. 

**Abstract (ZH)**: 神经音频合成（NAS）模型提供了对高质量、表现力音频生成器的交互式音乐控制。虽然这些模型可以实时运行，但通常会遭受高延迟的问题，使其不适用于亲密的音乐互动。神经音频合成文献中有关深度学习模型结构选择对音频延迟影响的研究尚不充分。在本文中，我们探讨了交互式NAS模型中常见的延迟和抖动来源。然后，我们应用这种分析来使用Caillon等人在2021年引入的音频波形卷积变分自动编码器（RAVE）进行音色转换任务。最后，我们提出了一种迭代设计方法以优化延迟。最终的成果是一个名为BRAVE（Bravely Realtime Audio Variational autoEncoder）的模型，该模型具有低延迟，并且在保真度和音量复制方面表现更好，在音色修改能力方面与RAVE类似。我们将其实现为一个专门用于低延迟实时推理的推理框架，并展示了与乐器音频信号兼容的概念验证音频插件。我们期望本文中描述的挑战和指南能够支持NAS研究人员从头开始设计低延迟推理模型，从而丰富音乐家的可能性景观。 

---
# Exploring the Vulnerabilities of Federated Learning: A Deep Dive into Gradient Inversion Attacks 

**Title (ZH)**: 探索 federated learning 的脆弱性：对梯度反转攻击的深入探究 

**Authors**: Pengxin Guo, Runxi Wang, Shuang Zeng, Jinjing Zhu, Haoning Jiang, Yanran Wang, Yuyin Zhou, Feifei Wang, Hui Xiong, Liangqiong Qu  

**Link**: [PDF](https://arxiv.org/pdf/2503.11514)  

**Abstract**: Federated Learning (FL) has emerged as a promising privacy-preserving collaborative model training paradigm without sharing raw data. However, recent studies have revealed that private information can still be leaked through shared gradient information and attacked by Gradient Inversion Attacks (GIA). While many GIA methods have been proposed, a detailed analysis, evaluation, and summary of these methods are still lacking. Although various survey papers summarize existing privacy attacks in FL, few studies have conducted extensive experiments to unveil the effectiveness of GIA and their associated limiting factors in this context. To fill this gap, we first undertake a systematic review of GIA and categorize existing methods into three types, i.e., \textit{optimization-based} GIA (OP-GIA), \textit{generation-based} GIA (GEN-GIA), and \textit{analytics-based} GIA (ANA-GIA). Then, we comprehensively analyze and evaluate the three types of GIA in FL, providing insights into the factors that influence their performance, practicality, and potential threats. Our findings indicate that OP-GIA is the most practical attack setting despite its unsatisfactory performance, while GEN-GIA has many dependencies and ANA-GIA is easily detectable, making them both impractical. Finally, we offer a three-stage defense pipeline to users when designing FL frameworks and protocols for better privacy protection and share some future research directions from the perspectives of attackers and defenders that we believe should be pursued. We hope that our study can help researchers design more robust FL frameworks to defend against these attacks. 

**Abstract (ZH)**: 联邦学习（FL）作为一种无需共享原始数据即可实现隐私保护的协作模型培训范式已经脱颖而出。然而， recent研究发现，私有信息仍可能通过共享的梯度信息泄露，并受到梯度反转攻击（GIA）的攻击。尽管已经提出了许多GIA方法，但这些方法的详细分析、评估和总结仍然不足。虽然有许多综述文章总结了现有FL中的隐私攻击，但很少有研究通过广泛的实验揭示这些GIA的有效性及其相关的限制因素。为填补这一空白，我们首先系统地回顾了GIA，并将现有方法分为三种类型，即基于优化的梯度反转攻击（OP-GIA）、基于生成的梯度反转攻击（GEN-GIA）和基于分析的梯度反转攻击（ANA-GIA）。然后，我们全面分析和评估了这三种类型的GIA，提供了影响它们性能、实际应用性和潜在威胁的因素的见解。我们的研究结果表明，尽管OP-GIA的性能不尽如人意，但它是最具实际攻击性的设置，而GEN-GIA具有许多依赖性，ANA-GIA很容易被检测到，这使得它们都缺乏实用性。最后，我们提出了一种三阶段的防御管道，为设计FL框架和协议的用户提供指导，以更好地保护隐私，并从攻击者和防御者的视角分享我们认为应进行的一些未来研究方向，以帮助研究人员设计更 robust 的FL框架来抵御这些攻击。 

---
# Alzheimer's Disease Classification Using Retinal OCT: TransnetOCT and Swin Transformer Models 

**Title (ZH)**: 使用视网膜OCT进行阿尔茨海默病分类：TransnetOCT和Swin Transformer模型 

**Authors**: Siva Manohar Reddy Kesu, Neelam Sinha, Hariharan Ramasangu, Thomas Gregor Issac  

**Link**: [PDF](https://arxiv.org/pdf/2503.11511)  

**Abstract**: Retinal optical coherence tomography (OCT) images are the biomarkers for neurodegenerative diseases, which are rising in prevalence. Early detection of Alzheimer's disease using retinal OCT is a primary challenging task. This work utilizes advanced deep learning techniques to classify retinal OCT images of subjects with Alzheimer's disease (AD) and healthy controls (CO). The goal is to enhance diagnostic capabilities through efficient image analysis. In the proposed model, Raw OCT images have been preprocessed with ImageJ and given to various deep-learning models to evaluate the accuracy. The best classification architecture is TransNetOCT, which has an average accuracy of 98.18% for input OCT images and 98.91% for segmented OCT images for five-fold cross-validation compared to other models, and the Swin Transformer model has achieved an accuracy of 93.54%. The evaluation accuracy metric demonstrated TransNetOCT and Swin transformer models capability to classify AD and CO subjects reliably, contributing to the potential for improved diagnostic processes in clinical settings. 

**Abstract (ZH)**: 视网膜光学相干断层扫描(OCT)图像是神经退行性疾病生物标志物，随着这类疾病发病率的上升，早期检测阿尔茨海默病的视网膜OCT图像分类是一个主要挑战。本工作利用先进深度学习技术对阿尔茨海默病(AD)患者和健康对照组(CO)的视网膜OCT图像进行分类，以提高诊断能力。在提出的模型中，原始OCT图像经过ImageJ预处理后，输入到多种深度学习模型以评估准确性。TransNetOCT是最佳分类架构，五折交叉验证输入OCT图像的平均精度为98.18%，分割OCT图像的平均精度为98.91%，而Swin Transformer模型的精度为93.54%。评估准确性指标表明TransNetOCT和Swin Transformer模型具有可靠分类AD和CO个体的能力，有助于改善临床诊断过程。 

---
# Research Vision: Multi-Agent Path Planning for Cops And Robbers Via Reactive Synthesis 

**Title (ZH)**: 基于反应合成的警匪多方路径规划研究 

**Authors**: William Fishell, Andoni Rodriguez, Mark Santolucito  

**Link**: [PDF](https://arxiv.org/pdf/2503.11475)  

**Abstract**: We propose the problem of multi-agent path planning for a generalization of the classic Cops and Robbers game via reactive synthesis. Specifically, through the application of LTLt and Coordination Synthesis, we aim to check whether various Cops and Robbers games are realizable (a strategy exists for the cops which guarantees they catch the robbers). Additionally, we construct this strategy as an executable program for the multiple system players in our games. In this paper we formalize the problem space, and propose potential directions for solutions. We also show how our formalization of this generalized cops and robbers game can be mapped to a broad range of other problems in the reactive program synthesis space. 

**Abstract (ZH)**: 我们通过反应合成提出了经典Cops and Robbers游戏的一般化多智能体路径规划问题。具体而言，通过应用LTLt和协调合成，我们旨在检查各种Cops and Robbers游戏是否可实现（即存在一种确保警察能够抓住劫犯的策略）。此外，我们为游戏中的多个系统玩家构建了这种策略，使其可执行。在本文中，我们形式化了问题空间，并提出了潜在的解决方案方向。我们还展示了我们对这种一般化Cops and Robbers游戏的形式化可以映射到反应程序合成空间中的广泛其他问题的方式。 

---
# Combining Causal Models for More Accurate Abstractions of Neural Networks 

**Title (ZH)**: 结合因果模型以获得更准确的神经网络抽象表示 

**Authors**: Theodora-Mara Pîslar, Sara Magliacane, Atticus Geiger  

**Link**: [PDF](https://arxiv.org/pdf/2503.11429)  

**Abstract**: Mechanistic interpretability aims to reverse engineer neural networks by uncovering which high-level algorithms they implement. Causal abstraction provides a precise notion of when a network implements an algorithm, i.e., a causal model of the network contains low-level features that realize the high-level variables in a causal model of the algorithm. A typical problem in practical settings is that the algorithm is not an entirely faithful abstraction of the network, meaning it only partially captures the true reasoning process of a model. We propose a solution where we combine different simple high-level models to produce a more faithful representation of the network. Through learning this combination, we can model neural networks as being in different computational states depending on the input provided, which we show is more accurate to GPT 2-small fine-tuned on two toy tasks. We observe a trade-off between the strength of an interpretability hypothesis, which we define in terms of the number of inputs explained by the high-level models, and its faithfulness, which we define as the interchange intervention accuracy. Our method allows us to modulate between the two, providing the most accurate combination of models that describe the behavior of a neural network given a faithfulness level. 

**Abstract (ZH)**: 机制可解释性旨在通过揭示神经网络实现的高级算法来逆向工程神经网络。因果抽象提供了一种精确的网络实现算法的方式的概念，即网络的因果模型包含实现算法的因果模型中的高级变量的低级特征。实践中一个典型的问题是算法并非神经网络的完全忠实抽象，意味着它仅部分捕捉到模型的真实推理过程。我们提出了一种解决方案，即结合不同简单的高级模型来生成神经网络更忠实的表示。通过学习这种组合，我们可以建模神经网络在提供不同输入时处于不同的计算状态，我们发现这比在两个玩具任务上微调的GPT-2-small更准确。我们观察到解释性假设强度之间的权衡，我们通过高级模型解释的输入数量定义这种强度，以及交换干预准确率定义忠实性。我们的方法允许我们在两者之间调节，提供在给定忠实性水平时最准确的模型组合来描述神经网络的行为。 

---
# From Generative AI to Innovative AI: An Evolutionary Roadmap 

**Title (ZH)**: 从生成型AI到创新型AI：一条进化路线图 

**Authors**: Seyed Mahmoud Sajjadi Mohammadabadi  

**Link**: [PDF](https://arxiv.org/pdf/2503.11419)  

**Abstract**: This paper explores the critical transition from Generative Artificial Intelligence (GenAI) to Innovative Artificial Intelligence (InAI). While recent advancements in GenAI have enabled systems to produce high-quality content across various domains, these models often lack the capacity for true innovation. In this context, innovation is defined as the ability to generate novel and useful outputs that go beyond mere replication of learned data. The paper examines this shift and proposes a roadmap for developing AI systems that can generate content and engage in autonomous problem-solving and creative ideation. The work provides both theoretical insights and practical strategies for advancing AI to a stage where it can genuinely innovate, contributing meaningfully to science, technology, and the arts. 

**Abstract (ZH)**: 本文探讨了生成型人工智能（GenAI）向创新型人工智能（InAI）的关键过渡。尽管最近在GenAI领域的进展使得系统能够产生跨多个领域的高质量内容，但这些模型往往缺乏真正的创新能力。在此背景下，创新被定义为产生新颖且有用输出的能力，超越了单纯的数据复制。本文研究了这一转变，并提出了一条开发能够生成内容并自主解决问题和创造性构思的AI系统的蓝图。这项工作提供了推进AI进入真正创新阶段的理论洞见和实用策略，为科学、技术和艺术领域做出有意义的贡献。 

---
# A Neural Network Architecture Based on Attention Gate Mechanism for 3D Magnetotelluric Forward Modeling 

**Title (ZH)**: 基于注意力门机制的神经网络架构用于3D磁流电正演建模 

**Authors**: Xin Zhong, Weiwei Ling, Kejia Pan, Pinxia Wu, Jiajing Zhang, Zhiliang Zhan, Wenbo Xiao  

**Link**: [PDF](https://arxiv.org/pdf/2503.11408)  

**Abstract**: Traditional three-dimensional magnetotelluric (MT) numerical forward modeling methods, such as the finite element method (FEM) and finite volume method (FVM), suffer from high computational costs and low efficiency due to limitations in mesh refinement and computational resources. We propose a novel neural network architecture named MTAGU-Net, which integrates an attention gating mechanism for 3D MT forward modeling. Specifically, a dual-path attention gating module is designed based on forward response data images and embedded in the skip connections between the encoder and decoder. This module enables the fusion of critical anomaly information from shallow feature maps during the decoding of deep feature maps, significantly enhancing the network's capability to extract features from anomalous regions. Furthermore, we introduce a synthetic model generation method utilizing 3D Gaussian random field (GRF), which accurately replicates the electrical structures of real-world geological scenarios with high fidelity. Numerical experiments demonstrate that MTAGU-Net outperforms conventional 3D U-Net in terms of convergence stability and prediction accuracy, with the structural similarity index (SSIM) of the forward response data consistently exceeding 0.98. Moreover, the network can accurately predict forward response data on previously unseen datasets models, demonstrating its strong generalization ability and validating the feasibility and effectiveness of this method in practical applications. 

**Abstract (ZH)**: 传统三维磁流变光谱（MT）数值前向建模方法，如有限元方法（FEM）和有限体积方法（FVM），由于网格细化限制和计算资源的限制，面临高计算成本和低效率的问题。我们提出了一种名为MTAGU-Net的新神经网络架构，该架构结合了用于三维MT前向建模的注意力门控机制。具体地，在编码器和解码器之间的跳连接中嵌入了基于前向响应数据图像的双路径注意力门控模块，该模块在解码深层特征图时能够融合浅层特征图中的关键异常信息，显著增强网络从异常区域提取特征的能力。此外，我们引入了一种使用三维高斯随机场（GRF）的合成模型生成方法，能够高度准确地模拟实际地质场景中的电气结构。数值实验表明，MTAGU-Net在收敛稳定性和预测准确性方面优于传统的三维U-Net，前向响应数据的结构相似性指数（SSIM）持续超过0.98。此外，该网络可以准确预测未见过的数据集上的前向响应数据，展示了其强大的泛化能力，并验证了该方法在实际应用中的可行性和有效性。 

---
# Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models 

**Title (ZH)**: 面向语义水印在扩散模型中正确使用加密技术的研究 

**Authors**: Jonas Thietke, Andreas Müller, Denis Lukovnikov, Asja Fischer, Erwin Quiring  

**Link**: [PDF](https://arxiv.org/pdf/2503.11404)  

**Abstract**: Semantic watermarking methods enable the direct integration of watermarks into the generation process of latent diffusion models by only modifying the initial latent noise. One line of approaches building on Gaussian Shading relies on cryptographic primitives to steer the sampling process of the latent noise. However, we identify several issues in the usage of cryptographic techniques in Gaussian Shading, particularly in its proof of lossless performance and key management, causing ambiguity in follow-up works, too. In this work, we therefore revisit the cryptographic primitives for semantic watermarking. We introduce a novel, general proof of lossless performance based on IND\$-CPA security for semantic watermarks. We then discuss the configuration of the cryptographic primitives in semantic watermarks with respect to security, efficiency, and generation quality. 

**Abstract (ZH)**: 基于语义的数字水印方法通过仅修改初始潜在噪声实现将水印直接集成到潜在扩散模型的生成过程中。基于高斯阴影的某些方法依赖于密码学原语来引导潜在噪声的采样过程。然而，我们发现高斯阴影中使用密码学技术存在若干问题，特别是在其无损性能证明和密钥管理方面，给后续研究带来了模糊性。因此，在本文中，我们重新审视了语义水印中的密码学原语。我们提出了一种基于IND\$-CPA安全性的新颖且通用的无损性能证明方法。然后，我们讨论了语义水印中密码学原语的配置问题，包括安全性、效率和生成质量。 

---
# Hierarchical Information-Guided Spatio-Temporal Mamba for Stock Time Series Forecasting 

**Title (ZH)**: 层级信息引导的空间时间Mamba股票时间序列预测 

**Authors**: Wenbo Yan, Shurui Wang, Ying Tan  

**Link**: [PDF](https://arxiv.org/pdf/2503.11387)  

**Abstract**: Mamba has demonstrated excellent performance in various time series forecasting tasks due to its superior selection mechanism. Nevertheless, conventional Mamba-based models encounter significant challenges in accurately predicting stock time series, as they fail to adequately capture both the overarching market dynamics and the intricate interdependencies among individual stocks. To overcome these constraints, we introduce the Hierarchical Information-Guided Spatio-Temporal Mamba (HIGSTM) framework. HIGSTM introduces Index-Guided Frequency Filtering Decomposition to extract commonality and specificity from time series. The model architecture features a meticulously designed hierarchical framework that systematically captures both temporal dynamic patterns and global static relationships within the stock market. Furthermore, we propose an Information-Guided Mamba that integrates macro informations into the sequence selection process, thereby facilitating more market-conscious decision-making. Comprehensive experimental evaluations conducted on the CSI500, CSI800 and CSI1000 datasets demonstrate that HIGSTM achieves state-of-the-art performance. 

**Abstract (ZH)**: Mamba在各种时间序列预测任务中表现出色，得益于其卓越的选择机制。然而，传统的基于Mamba的模型在准确预测股票时间序列时遇到了显著挑战，因为它们未能充分捕捉到整体市场动态和单个股票之间的复杂相互依赖关系。为克服这些限制，我们引入了层次信息引导时空Mamba（HIGSTM）框架。HIGSTM引入了索引引导频率过滤分解，以从时间序列中提取共性和特殊性。模型架构包含一个精心设计的层次框架，系统地捕获股市中的时间动态模式和全局静态关系。此外，我们还提出了信息引导的Mamba，将宏观信息整合到序列选择过程中，从而促进更加市场意识的决策。在CSI500、CSI800和CSI1000数据集上的全面实验评估表明，HIGSTM达到了最先进的性能。 

---
# Annotating Scientific Uncertainty: A comprehensive model using linguistic patterns and comparison with existing approaches 

**Title (ZH)**: 科学不确定性注解：基于语言模式的综合模型及其与现有方法的比较 

**Authors**: Panggih Kusuma Ningrum, Philipp Mayr, Nina Smirnova, Iana Atanassova  

**Link**: [PDF](https://arxiv.org/pdf/2503.11376)  

**Abstract**: UnScientify, a system designed to detect scientific uncertainty in scholarly full text. The system utilizes a weakly supervised technique to identify verbally expressed uncertainty in scientific texts and their authorial references. The core methodology of UnScientify is based on a multi-faceted pipeline that integrates span pattern matching, complex sentence analysis and author reference checking. This approach streamlines the labeling and annotation processes essential for identifying scientific uncertainty, covering a variety of uncertainty expression types to support diverse applications including information retrieval, text mining and scientific document processing. The evaluation results highlight the trade-offs between modern large language models (LLMs) and the UnScientify system. UnScientify, which employs more traditional techniques, achieved superior performance in the scientific uncertainty detection task, attaining an accuracy score of 0.808. This finding underscores the continued relevance and efficiency of UnScientify's simple rule-based and pattern matching strategy for this specific application. The results demonstrate that in scenarios where resource efficiency, interpretability, and domain-specific adaptability are critical, traditional methods can still offer significant advantages. 

**Abstract (ZH)**: UnScientify:一个用于检测学术全文中科学不确定性系统的体系 

---
# PARIC: Probabilistic Attention Regularization for Language Guided Image Classification from Pre-trained Vison Language Models 

**Title (ZH)**: PARIC：由预训练视觉语言模型引导的图像分类的概率注意力正则化 

**Authors**: Mayank Nautiyal, Stela Arranz Gheorghe, Kristiana Stefa, Li Ju, Ida-Maria Sintorn, Prashant Singh  

**Link**: [PDF](https://arxiv.org/pdf/2503.11360)  

**Abstract**: Language-guided attention frameworks have significantly enhanced both interpretability and performance in image classification; however, the reliance on deterministic embeddings from pre-trained vision-language foundation models to generate reference attention maps frequently overlooks the intrinsic multivaluedness and ill-posed characteristics of cross-modal mappings. To address these limitations, we introduce PARIC, a probabilistic framework for guiding visual attention via language specifications. Our approach enables pre-trained vision-language models to generate probabilistic reference attention maps, which align textual and visual modalities more effectively while incorporating uncertainty estimates, as compared to their deterministic counterparts. Experiments on benchmark test problems demonstrate that PARIC enhances prediction accuracy, mitigates bias, ensures consistent predictions, and improves robustness across various datasets. 

**Abstract (ZH)**: 基于语言引导的概率视觉注意力框架解决了预训练视觉-语言基础模型生成参考注意力图时对确定性嵌入的依赖问题，忽视了跨模态映射的内在多值性和病态特性；我们提出PARIC，一种通过语言规范引导视觉注意力的概率框架。PARIC使预训练的视觉-语言模型能够生成概率性的参考注意力图，更好地对齐文本和视觉模态，并包含不确定性估计，相较于确定性方法，更具优势。在基准测试问题上的实验表明，PARIC提高了预测准确性，减轻了偏见，确保了预测的一致性，并提高了跨不同数据集的鲁棒性。 

---
# An experimental approach on Few Shot Class Incremental Learning 

**Title (ZH)**: 少量样本条件下类增量学习的实验方法 

**Authors**: Marinela Adam  

**Link**: [PDF](https://arxiv.org/pdf/2503.11349)  

**Abstract**: Few-Shot Class-Incremental Learning (FSCIL) represents a cutting-edge paradigm within the broader scope of machine learning, designed to empower models with the ability to assimilate new classes of data with limited examples while safeguarding existing knowledge. The paper will present different solutions which contain extensive experiments across large-scale datasets, domain shifts, and network architectures to evaluate and compare the selected methods. We highlight their advantages and then present an experimental approach with the purpose of improving the most promising one by replacing the visual-language (V-L) model (CLIP) with another V-L model (CLOOB) that seem to outperform it on zero-shot learning tasks. The aim of this report is to present an experimental method for FSCIL that would improve its performance. We also plan to offer an overview followed by an analysis of the recent advancements in FSCIL domain, focusing on various strategies to mitigate catastrophic forgetting and improve the adaptability of models to evolving tasks and datasets. 

**Abstract (ZH)**: 少量样本类增量学习（Few-Shot Class-Incremental Learning, FSCIL）代表了机器学习领域的前沿范式，旨在使模型能够在有限示例的情况下吸收新的数据类别，并保护现有知识。本文将呈现不同的解决方案，并通过大规模数据集、领域转换和网络架构进行广泛的实验来评估和比较这些方法。我们将强调它们的优势，并通过用在零样本学习任务中表现出色的另一个视觉-语言模型（CLOOB）替换现有的视觉-语言模型（CLIP）来改进最有希望的方法。本报告的目标是提出一种改进FSCIL性能的实验方法。我们还将提供该领域的综述，并分析各种策略以减轻灾难性遗忘并提高模型对不断变化的任务和数据集的适应性。 

---
# Contextual Similarity Distillation: Ensemble Uncertainties with a Single Model 

**Title (ZH)**: 上下文相似性蒸馏：使用单模型集成不确定性 

**Authors**: Moritz A. Zanger, Pascal R. Van der Vaart, Wendelin Böhmer, Matthijs T.J. Spaan  

**Link**: [PDF](https://arxiv.org/pdf/2503.11339)  

**Abstract**: Uncertainty quantification is a critical aspect of reinforcement learning and deep learning, with numerous applications ranging from efficient exploration and stable offline reinforcement learning to outlier detection in medical diagnostics. The scale of modern neural networks, however, complicates the use of many theoretically well-motivated approaches such as full Bayesian inference. Approximate methods like deep ensembles can provide reliable uncertainty estimates but still remain computationally expensive. In this work, we propose contextual similarity distillation, a novel approach that explicitly estimates the variance of an ensemble of deep neural networks with a single model, without ever learning or evaluating such an ensemble in the first place. Our method builds on the predictable learning dynamics of wide neural networks, governed by the neural tangent kernel, to derive an efficient approximation of the predictive variance of an infinite ensemble. Specifically, we reinterpret the computation of ensemble variance as a supervised regression problem with kernel similarities as regression targets. The resulting model can estimate predictive variance at inference time with a single forward pass, and can make use of unlabeled target-domain data or data augmentations to refine its uncertainty estimates. We empirically validate our method across a variety of out-of-distribution detection benchmarks and sparse-reward reinforcement learning environments. We find that our single-model method performs competitively and sometimes superior to ensemble-based baselines and serves as a reliable signal for efficient exploration. These results, we believe, position contextual similarity distillation as a principled and scalable alternative for uncertainty quantification in reinforcement learning and general deep learning. 

**Abstract (ZH)**: 不确定性量化是强化学习和深度学习的关键方面，其应用范围从高效的探索和稳定的Offline强化学习到医疗诊断中的异常检测。然而，现代神经网络的规模使许多理论上具有良好动机的方法，如全贝叶斯推断变得复杂。像深度集合这样的近似方法可以提供可靠的不确定性估计，但仍然计算成本高昂。在本文中，我们提出了一种新颖的方法——上下文相似性提炼，该方法可以通过单个模型显式估计深度神经网络集合的方差，而根本不学习或评估这样的集合。我们的方法利用广神经网络的可预测学习动力学，由神经核支配，以推导无限集合的预测方差的有效近似。具体来说，我们将集合方差的计算重新解释为以核相似性作为回归目标的监督回归问题。所得到的模型可以在推断时通过单次前向传播估计预测方差，并可以利用目标域未标记数据或数据增强来细化其不确定性估计。我们通过各种分布外检测基准和稀疏奖励强化学习环境进行实证验证。我们发现，我们的单模型方法在性能上与基于集合的基线方法相当，有时甚至更优，并作为高效探索的可靠信号。我们相信，这些结果将上下文相似性提炼置于不确定性量化在强化学习和通用深度学习中的基本原则和可扩展替代方案的位置。 

---
# Cardiomyopathy Diagnosis Model from Endomyocardial Biopsy Specimens: Appropriate Feature Space and Class Boundary in Small Sample Size Data 

**Title (ZH)**: 从心内膜活检标本诊断心肌病模型：小样本数据中的合适特征空间和类别边界 

**Authors**: Masaya Mori, Yuto Omae, Yutaka Koyama, Kazuyuki Hara, Jun Toyotani, Yasuo Okumura, Hiroyuki Hao  

**Link**: [PDF](https://arxiv.org/pdf/2503.11331)  

**Abstract**: As the number of patients with heart failure increases, machine learning (ML) has garnered attention in cardiomyopathy diagnosis, driven by the shortage of pathologists. However, endomyocardial biopsy specimens are often small sample size and require techniques such as feature extraction and dimensionality reduction. This study aims to determine whether texture features are effective for feature extraction in the pathological diagnosis of cardiomyopathy. Furthermore, model designs that contribute toward improving generalization performance are examined by applying feature selection (FS) and dimensional compression (DC) to several ML models. The obtained results were verified by visualizing the inter-class distribution differences and conducting statistical hypothesis testing based on texture features. Additionally, they were evaluated using predictive performance across different model designs with varying combinations of FS and DC (applied or not) and decision boundaries. The obtained results confirmed that texture features may be effective for the pathological diagnosis of cardiomyopathy. Moreover, when the ratio of features to the sample size is high, a multi-step process involving FS and DC improved the generalization performance, with the linear kernel support vector machine achieving the best results. This process was demonstrated to be potentially effective for models with reduced complexity, regardless of whether the decision boundaries were linear, curved, perpendicular, or parallel to the axes. These findings are expected to facilitate the development of an effective cardiomyopathy diagnostic model for its rapid adoption in medical practice. 

**Abstract (ZH)**: 随着心力衰竭患者数量的增加，机器学习在心肌病诊断中的应用引起了关注，这主要是由于病理学家短缺。然而，心肌活检标本往往样本量较小，需要采用特征提取和降维等技术。本研究旨在确定纹理特征是否适用于心肌病病理诊断中的特征提取。此外，通过将特征选择和维度压缩应用于多种机器学习模型，考察有助于提高模型泛化性能的设计方法。所得结果通过可视化不同类别的分布差异，并基于纹理特征进行统计假设检验予以验证。同时，通过不同模型设计与不同特征选择和维度压缩组合下的预测性能评估，这些结果进一步得到证实。所得结果表明，纹理特征可能对心肌病病理诊断有效。此外，当特征与样本量之比较高时，特征选择和维度压缩的多步过程可以提高模型的泛化性能，线性核支持向量机取得了最佳效果。该过程表明，即使决策边界线性、曲线、垂直或平行于坐标轴，对于简化模型仍可能有效。这些发现有望促进有效心肌病诊断模型的开发，加速其在医疗实践中的应用。 

---
# AI and Deep Learning for Automated Segmentation and Quantitative Measurement of Spinal Structures in MRI 

**Title (ZH)**: AI和深度学习在MRI脊椎结构自动化分割与定量测量中的应用 

**Authors**: Praveen Shastry, Bhawana Sonawane, Kavya Mohan, Naveen Kumarasami, Anandakumar D, Keerthana R, Mounigasri M, Kaviya SP, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam  

**Link**: [PDF](https://arxiv.org/pdf/2503.11281)  

**Abstract**: Background: Accurate spinal structure measurement is crucial for assessing spine health and diagnosing conditions like spondylosis, disc herniation, and stenosis. Manual methods for measuring intervertebral disc height and spinal canal diameter are subjective and time-consuming. Automated solutions are needed to improve accuracy, efficiency, and reproducibility in clinical practice.
Purpose: This study develops an autonomous AI system for segmenting and measuring key spinal structures in MRI scans, focusing on intervertebral disc height and spinal canal anteroposterior (AP) diameter in the cervical, lumbar, and thoracic regions. The goal is to reduce clinician workload, enhance diagnostic consistency, and improve assessments.
Methods: The AI model leverages deep learning architectures, including UNet, nnU-Net, and CNNs. Trained on a large proprietary MRI dataset, it was validated against expert annotations. Performance was evaluated using Dice coefficients and segmentation accuracy.
Results: The AI model achieved Dice coefficients of 0.94 for lumbar, 0.91 for cervical, and 0.90 for dorsal spine segmentation (D1-D12). It precisely measured spinal parameters like disc height and canal diameter, demonstrating robustness and clinical applicability.
Conclusion: The AI system effectively automates MRI-based spinal measurements, improving accuracy and reducing clinician workload. Its consistent performance across spinal regions supports clinical decision-making, particularly in high-demand settings, enhancing spinal assessments and patient outcomes. 

**Abstract (ZH)**: 背景：脊柱结构的准确测量对于评估脊柱健康和诊断髓核病变、椎间盘突出和椎管狭窄等状况至关重要。手动测量椎间盘高度和椎管直径的方法主观且耗时。需要自动化解决方案以提高临床实践中的准确性和效率。

目的：本研究开发了一种自主人工智能系统，用于分割和测量 MRI 扫描中的关键脊柱结构，主要集中在颈椎、腰椎和胸椎区域的椎间盘高度和椎管前后径。目标是减轻医务人员的负担，增强诊断一致性，并提高评估质量。

方法：该 AI 模型采用深度学习架构，包括 UNet、nnU-Net 和 CNNs。通过大型专用 MRI 数据集训练，并与专家标注进行验证。性能通过 Dice 系数和分割准确性进行评估。

结果：AI 模型在腰椎、颈椎和胸椎分割的 Dice 系数分别为 0.94、0.91 和 0.90（D1-D12）。它精确测量了脊柱参数，如椎间盘高度和椎管直径，展示了其稳健性和临床适用性。

结论：该 AI 系统有效实现了基于 MRI 的脊柱测量自动化，提高了准确性和减轻了医务人员的负担。其在脊柱各区域的一致表现支持临床决策，特别是在高需求环境中，提高了脊柱评估和患者结果。 

---
# Financial Fraud Detection with Entropy Computing 

**Title (ZH)**: 基于熵计算的金融欺诈检测 

**Authors**: Babak Emami, Wesley Dyk, David Haycraft, Carrie Spear, Lac Nguyen, Nicholas Chancellor  

**Link**: [PDF](https://arxiv.org/pdf/2503.11273)  

**Abstract**: We introduce CVQBoost, a novel classification algorithm that leverages early hardware implementing Quantum Computing Inc's Entropy Quantum Computing (EQC) paradigm, Dirac-3 [Nguyen et. al. arXiv:2407.04512]. We apply CVQBoost to a fraud detection test case and benchmark its performance against XGBoost, a widely utilized ML method. Running on Dirac-3, CVQBoost demonstrates a significant runtime advantage over XGBoost, which we evaluate on high-performance hardware comprising up to 48 CPUs and four NVIDIA L4 GPUs using the RAPIDS AI framework. Our results show that CVQBoost maintains competitive accuracy (measured by AUC) while significantly reducing training time, particularly as dataset size and feature complexity increase. To assess scalability, we extend our study to large synthetic datasets ranging from 1M to 70M samples, demonstrating that CVQBoost on Dirac-3 is well-suited for large-scale classification tasks. These findings position CVQBoost as a promising alternative to gradient boosting methods, offering superior scalability and efficiency for high-dimensional ML applications such as fraud detection. 

**Abstract (ZH)**: CVQBoost: 一种基于量子计算Inc的量子熵计算(EQC)范式和Dirac-3硬件的新型分类算法及其在欺诈检测中的应用分析 

---
# Spherical Tree-Sliced Wasserstein Distance 

**Title (ZH)**: 球形树分割Wasserstein距离 

**Authors**: Hoang V. Tran, Thanh T. Chu, Khoi N.M. Nguyen, Trang Pham, Tam Le, Tan M. Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2503.11249)  

**Abstract**: Sliced Optimal Transport (OT) simplifies the OT problem in high-dimensional spaces by projecting supports of input measures onto one-dimensional lines and then exploiting the closed-form expression of the univariate OT to reduce the computational burden of OT. Recently, the Tree-Sliced method has been introduced to replace these lines with more intricate structures, known as tree systems. This approach enhances the ability to capture topological information of integration domains in Sliced OT while maintaining low computational cost. Inspired by this approach, in this paper, we present an adaptation of tree systems on OT problems for measures supported on a sphere. As a counterpart to the Radon transform variant on tree systems, we propose a novel spherical Radon transform with a new integration domain called spherical trees. By leveraging this transform and exploiting the spherical tree structures, we derive closed-form expressions for OT problems on the sphere. Consequently, we obtain an efficient metric for measures on the sphere, named Spherical Tree-Sliced Wasserstein (STSW) distance. We provide an extensive theoretical analysis to demonstrate the topology of spherical trees and the well-definedness and injectivity of our Radon transform variant, which leads to an orthogonally invariant distance between spherical measures. Finally, we conduct a wide range of numerical experiments, including gradient flows and self-supervised learning, to assess the performance of our proposed metric, comparing it to recent benchmarks. 

**Abstract (ZH)**: 基于树木结构的球面截断最优传输距离（Spherical Tree-Sliced Wasserstein Distance） 

---
# Technologies on Effectiveness and Efficiency: A Survey of State Spaces Models 

**Title (ZH)**: 有效性和效率上的技术进展：状态空间模型综述 

**Authors**: Xingtai Lv, Youbang Sun, Kaiyan Zhang, Shang Qu, Xuekai Zhu, Yuchen Fan, Yi Wu, Ermo Hua, Xinwei Long, Ning Ding, Bowen Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2503.11224)  

**Abstract**: State Space Models (SSMs) have emerged as a promising alternative to the popular transformer-based models and have been increasingly gaining attention. Compared to transformers, SSMs excel at tasks with sequential data or longer contexts, demonstrating comparable performances with significant efficiency gains. In this survey, we provide a coherent and systematic overview for SSMs, including their theoretical motivations, mathematical formulations, comparison with existing model classes, and various applications. We divide the SSM series into three main sections, providing a detailed introduction to the original SSM, the structured SSM represented by S4, and the selective SSM typified by Mamba. We put an emphasis on technicality, and highlight the various key techniques introduced to address the effectiveness and efficiency of SSMs. We hope this manuscript serves as an introduction for researchers to explore the theoretical foundations of SSMs. 

**Abstract (ZH)**: 状态空间模型（SSMs）作为一种有前途的替代Transformer模型的选择，正逐渐受到关注。与Transformer相比，SSMs在处理序列数据或长上下文任务时表现出色，展现出相当的性能并具有显著的效率提升。在本文综述中，我们提供了一个连贯且系统的SSMs概览，包括其理论动机、数学公式、与现有模型类别的比较以及各种应用。我们将SSM系列分为三个主要部分，详细介绍了原始的SSM、由S4代表的结构化SSM以及由Mamba代表的选择性SSM。我们在技术性方面进行了强调，并突出了为提高SSMs的有效性和效率而引入的各种关键技术。我们希望本文献能够为研究人员探索SSMs的基础理论提供一个入门介绍。 

---
# Unifying Perplexing Behaviors in Modified BP Attributions through Alignment Perspective 

**Title (ZH)**: 通过对齐视角统一修改BP Attribution中的迷惑行为 

**Authors**: Guanhua Zheng, Jitao Sang, Changsheng Xu  

**Link**: [PDF](https://arxiv.org/pdf/2503.11160)  

**Abstract**: Attributions aim to identify input pixels that are relevant to the decision-making process. A popular approach involves using modified backpropagation (BP) rules to reverse decisions, which improves interpretability compared to the original gradients. However, these methods lack a solid theoretical foundation and exhibit perplexing behaviors, such as reduced sensitivity to parameter randomization, raising concerns about their reliability and highlighting the need for theoretical justification. In this work, we present a unified theoretical framework for methods like GBP, RectGrad, LRP, and DTD, demonstrating that they achieve input alignment by combining the weights of activated neurons. This alignment improves the visualization quality and reduces sensitivity to weight randomization. Our contributions include: (1) Providing a unified explanation for multiple behaviors, rather than focusing on just one. (2) Accurately predicting novel behaviors. (3) Offering insights into decision-making processes, including layer-wise information changes and the relationship between attributions and model decisions. 

**Abstract (ZH)**: Attribution方法旨在识别对决策过程相关的输入像素。一种流行的方法是使用修改的反向传播（BP）规则来推翻决策，这与原始梯度相比提高了可解释性。然而，这些方法缺乏坚实的信息学基础，并表现出令人困惑的行为，如参数随机化敏感性降低，这引起了对其可靠性的担忧，并强调了需要理论证明的需求。在这项工作中，我们为GBP、RectGrad、LRP和DTD等方法提供了一个统一的理论框架，证明它们通过结合激活神经元的权重来实现输入对齐。这种对齐提高了可视化质量并降低了对权重随机化的敏感性。我们的贡献包括：(1) 对多种行为提供统一的解释，而不是仅仅关注一种。(2) 准确预测新的行为。(3) 提供有关决策过程的见解，包括层间信息变化以及归因与模型决策之间的关系。 

---
# UMB@PerAnsSumm 2025: Enhancing Perspective-Aware Summarization with Prompt Optimization and Supervised Fine-Tuning 

**Title (ZH)**: UMB@PerAnsSumm 2025: 基于提示优化和监督微调的视角aware摘要生成增强 

**Authors**: Kristin Qi, Youxiang Zhu, Xiaohui Liang  

**Link**: [PDF](https://arxiv.org/pdf/2503.11118)  

**Abstract**: We present our approach to the PerAnsSumm Shared Task, which involves perspective span identification and perspective-aware summarization in community question-answering (CQA) threads. For span identification, we adopt ensemble learning that integrates three transformer models through averaging to exploit individual model strengths, achieving an 82.91% F1-score on test data. For summarization, we design a suite of Chain-of-Thought (CoT) prompting strategies that incorporate keyphrases and guide information to structure summary generation into manageable steps. To further enhance summary quality, we apply prompt optimization using the DSPy framework and supervised fine-tuning (SFT) on Llama-3 to adapt the model to domain-specific data. Experimental results on validation and test sets show that structured prompts with keyphrases and guidance improve summaries aligned with references, while the combination of prompt optimization and fine-tuning together yields significant improvement in both relevance and factuality evaluation metrics. 

**Abstract (ZH)**: 我们提出了针对PerAnsSumm共享任务的方法，该方法涉及社区问答（CQA）线程中的视角短语识别和视角意识总结。在短语识别方面，我们采用通过平均整合三种变压器模型的集成学习方法，以利用各个模型的优势，测试数据上的F1分为82.91%。在总结方面，我们设计了一套包含关键词和指导信息的Chain-of-Thought（CoT）提示策略，以分步骤结构化总结生成。为了进一步提高总结质量，我们使用DSPy框架进行提示优化，并在Llama-3上进行监督微调（SFT），以使模型适应特定领域数据。在验证集和测试集上的实验结果表明，包含关键词和指导信息的结构化提示可以提高与参考文本对齐的总结质量，而提示优化与微调的结合则在相关性和事实性评估指标上取得了显著改进。 

---
# Quantifying Interpretability in CLIP Models with Concept Consistency 

**Title (ZH)**: CLIP模型中概念一致性解释性量化 

**Authors**: Avinash Madasu, Vasudev Lal, Phillip Howard  

**Link**: [PDF](https://arxiv.org/pdf/2503.11103)  

**Abstract**: CLIP is one of the most popular foundational models and is heavily used for many vision-language tasks. However, little is known about the inner workings of CLIP. While recent work has proposed decomposition-based interpretability methods for identifying textual descriptions of attention heads in CLIP, the implications of conceptual consistency in these text labels on interpretability and model performance has not been explored. To bridge this gap, we study the conceptual consistency of text descriptions for attention heads in CLIP-like models. We conduct extensive experiments on six different models from OpenAI and OpenCLIP which vary by size, type of pre-training data and patch size. We propose Concept Consistency Score (CCS), a novel interpretability metric that measures how consistently individual attention heads in CLIP models align with specific concepts. To assign concept labels to heads, we use in-context learning with ChatGPT, guided by a few manually-curated examples, and validate these labels using an LLM-as-a-judge approach. Our soft-pruning experiments reveal that high CCS heads are critical for preserving model performance, as pruning them leads to a significantly larger performance drop than pruning random or low CCS heads. Notably, we find that high CCS heads capture essential concepts and play a key role in out-of-domain detection, concept-specific reasoning, and video-language understanding. These results position CCS as a powerful interpretability metric for analyzing CLIP-like models. 

**Abstract (ZH)**: CLIP-like模型中注意力头概念一致性研究：一个新的可解释性度量标准及其影响 

---
# A Survey of Cross-domain Graph Learning: Progress and Future Directions 

**Title (ZH)**: 跨域图学习综述：进展与未来方向 

**Authors**: Haihong Zhao, Chenyi Zi, Aochuan Chen, Jia Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.11086)  

**Abstract**: Graph learning plays a vital role in mining and analyzing complex relationships involved in graph data, which is widely used in many real-world applications like transaction networks and communication networks. Foundation models in CV and NLP have shown powerful cross-domain capabilities that are also significant in graph domains. However, existing graph learning approaches struggle with cross-domain tasks. Inspired by successes in CV and NLP, cross-domain graph learning has once again become a focal point of attention to realizing true graph foundation models. In this survey, we present a comprehensive review and analysis of existing works on cross-domain graph learning. Concretely, we first propose a new taxonomy, categorizing existing approaches based on the learned cross-domain information: structure, feature, and structure-feature mixture. Next, we systematically survey representative methods in these categories. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. Relevant papers are summarized and will be consistently updated at: this https URL. 

**Abstract (ZH)**: 基于图的学习在挖掘和分析包含图数据中的复杂关系方面发挥着关键作用，广泛应用于交易网络和通信网络等实际应用场景中。CV和NLP领域的基础模型展示了强大的跨域能力，这一能力在图领域也同样重要。然而，现有的图学习方法在处理跨域任务时遇到了困难。受CV和NLP领域成功的启发，跨域图学习再次成为了实现真正图基础模型的关键焦点。在本文综述中，我们对现有的跨域图学习工作进行了全面的回顾和分析。具体来说，我们首先提出了一种新的分类法，根据学习到的跨域信息将现有方法分为结构、特征和结构-特征混合三类。接着，我们系统地调研了这些类别中的代表性方法。最后，我们讨论了现有研究的局限性，并指出了未来研究的有希望的方向。相关论文将在此链接持续更新：this https URL。 

---
# Distance-Based Tree-Sliced Wasserstein Distance 

**Title (ZH)**: 基于距离的树剖分Wasserstein距离 

**Authors**: Hoang V. Tran, Khoi N.M. Nguyen, Trang Pham, Thanh T. Chu, Tam Le, Tan M. Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2503.11050)  

**Abstract**: To overcome computational challenges of Optimal Transport (OT), several variants of Sliced Wasserstein (SW) has been developed in the literature. These approaches exploit the closed-form expression of the univariate OT by projecting measures onto (one-dimensional) lines. However, projecting measures onto low-dimensional spaces can lead to a loss of topological information. Tree-Sliced Wasserstein distance on Systems of Lines (TSW-SL) has emerged as a promising alternative that replaces these lines with a more advanced structure called tree systems. The tree structures enhance the ability to capture topological information of the metric while preserving computational efficiency. However, at the core of TSW-SL, the splitting maps, which serve as the mechanism for pushing forward measures onto tree systems, focus solely on the position of the measure supports while disregarding the projecting domains. Moreover, the specific splitting map used in TSW-SL leads to a metric that is not invariant under Euclidean transformations, a typically expected property for OT on Euclidean space. In this work, we propose a novel class of splitting maps that generalizes the existing one studied in TSW-SL enabling the use of all positional information from input measures, resulting in a novel Distance-based Tree-Sliced Wasserstein (Db-TSW) distance. In addition, we introduce a simple tree sampling process better suited for Db-TSW, leading to an efficient GPU-friendly implementation for tree systems, similar to the original SW. We also provide a comprehensive theoretical analysis of proposed class of splitting maps to verify the injectivity of the corresponding Radon Transform, and demonstrate that Db-TSW is an Euclidean invariant metric. We empirically show that Db-TSW significantly improves accuracy compared to recent SW variants while maintaining low computational cost via a wide range of experiments. 

**Abstract (ZH)**: 克服最优传输计算挑战的新型基于树结构的切片 Wasserstein 距离 

---
# Measuring Similarity in Causal Graphs: A Framework for Semantic and Structural Analysis 

**Title (ZH)**: 因果图中相似性测量：一种语义和结构分析框架 

**Authors**: Ning-Yuan Georgia Liu, Flower Yang, Mohammad S. Jalali  

**Link**: [PDF](https://arxiv.org/pdf/2503.11046)  

**Abstract**: Causal graphs are commonly used to understand and model complex systems. Researchers often construct these graphs from different perspectives, leading to significant variations for the same problem. Comparing causal graphs is, therefore, essential for evaluating assumptions, integrating insights, and resolving disagreements. The rise of AI tools has further amplified this need, as they are increasingly used to generate hypothesized causal graphs by synthesizing information from various sources such as prior research and community inputs, providing the potential for automating and scaling causal modeling for complex systems. Similar to humans, these tools also produce inconsistent results across platforms, versions, and iterations. Despite its importance, research on causal graph comparison remains scarce. Existing methods often focus solely on structural similarities, assuming identical variable names, and fail to capture nuanced semantic relationships, which is essential for causal graph comparison. We address these gaps by investigating methods for comparing causal graphs from both semantic and structural perspectives. First, we reviewed over 40 existing metrics and, based on predefined criteria, selected nine for evaluation from two threads of machine learning: four semantic similarity metrics and five learning graph kernels. We discuss the usability of these metrics in simple examples to illustrate their strengths and limitations. We then generated a synthetic dataset of 2,000 causal graphs using generative AI based on a reference diagram. Our findings reveal that each metric captures a different aspect of similarity, highlighting the need to use multiple metrics. 

**Abstract (ZH)**: 因果图常用于理解与建模复杂系统。研究人员从不同视角构建这些图，导致同一问题存在显著差异。因此，比较因果图对于评估假设、整合洞察和解决分歧至关重要。随着AI工具的应用日益增加，这些工具通过综合多种来源的信息（如先前研究和社区输入）生成假设的因果图，从而为复杂系统自动化和扩展因果建模提供了可能性。与人类相似，这些工具在不同平台、版本和迭代中也产生不一致的结果。尽管这一点很重要，但关于因果图比较的研究仍相对稀缺。现有方法往往仅关注结构相似性，假设变量名称相同，未能捕捉到因果图比较中必要的细腻语义关系。我们通过从语义和结构两个视角调查比较方法来填补这些空白。我们首先回顾了超过40个现有指标，并根据预定义的标准从中选择了九个进行评估，这些指标分别来自机器学习的两个分支：四个语义相似性指标和五个学习图核。我们通过简单示例讨论这些指标的适用性，以展示其优点和局限性。然后，我们基于一个参考图使用生成AI生成了2000个合成因果图数据集。我们的研究发现，每个指标都捕捉了相似性的一个不同方面，突显了使用多种指标的必要性。 

---
# Fourier Neural Operator based surrogates for $CO_2$ storage in realistic geologies 

**Title (ZH)**: 基于傅里叶神经算子的二氧化碳储存在实际地质结构中的代理模型 

**Authors**: Anirban Chandra, Marius Koch, Suraj Pawar, Aniruddha Panda, Kamyar Azizzadenesheli, Jeroen Snippe, Faruk O. Alpak, Farah Hariri, Clement Etienam, Pandu Devarakota, Anima Anandkumar, Detlef Hohl  

**Link**: [PDF](https://arxiv.org/pdf/2503.11031)  

**Abstract**: This study aims to develop surrogate models for accelerating decision making processes associated with carbon capture and storage (CCS) technologies. Selection of sub-surface $CO_2$ storage sites often necessitates expensive and involved simulations of $CO_2$ flow fields. Here, we develop a Fourier Neural Operator (FNO) based model for real-time, high-resolution simulation of $CO_2$ plume migration. The model is trained on a comprehensive dataset generated from realistic subsurface parameters and offers $O(10^5)$ computational acceleration with minimal sacrifice in prediction accuracy. We also explore super-resolution experiments to improve the computational cost of training the FNO based models. Additionally, we present various strategies for improving the reliability of predictions from the model, which is crucial while assessing actual geological sites. This novel framework, based on NVIDIA's Modulus library, will allow rapid screening of sites for CCS. The discussed workflows and strategies can be applied to other energy solutions like geothermal reservoir modeling and hydrogen storage. Our work scales scientific machine learning models to realistic 3D systems that are more consistent with real-life subsurface aquifers/reservoirs, paving the way for next-generation digital twins for subsurface CCS applications. 

**Abstract (ZH)**: 基于Fourier神经算子的代理模型开发以加速碳捕获与封存技术相关的决策过程 

---
# The Problem of the Priors, or Posteriors? 

**Title (ZH)**: 先验难题，还是后验难题？ 

**Authors**: Hanti Lin  

**Link**: [PDF](https://arxiv.org/pdf/2503.10984)  

**Abstract**: The problem of the priors is well known: it concerns the challenge of identifying norms that govern one's prior credences. I argue that a key to addressing this problem lies in considering what I call the problem of the posteriors -- the challenge of identifying norms that directly govern one's posterior credences, which then induce constraints on the priors via the diachronic requirement of conditionalization. This forward-looking approach can be summarized as: Think ahead, work backward. Although this idea can be traced to Freedman (1963), Carnap (1963), and Shimony (1970), it has received little attention in philosophy. In this paper, I initiate a systematic defense of forward-looking Bayesianism, addressing potential objections from more traditional views (both subjectivist and objectivist) and arguing for its advantages. In particular, I develop a specific approach to forward-looking Bayesianism -- one that treats the convergence of posterior credences to the truth as a fundamental rather than derived normative requirement. This approach, called convergentist Bayesianism, is argued to be crucial for a Bayesian foundation of Ockham's razor and related inference methods in statistics and machine learning. 

**Abstract (ZH)**: Bayesianism向前看：规范后验信念的问题及其解决方案 

---
# OuroMamba: A Data-Free Quantization Framework for Vision Mamba Models 

**Title (ZH)**: OuroMamba：一种无需数据的视觉Mamba模型量化框架 

**Authors**: Akshat Ramachandran, Mingyu Lee, Huan Xu, Souvik Kundu, Tushar Krishna  

**Link**: [PDF](https://arxiv.org/pdf/2503.10959)  

**Abstract**: We present OuroMamba, the first data-free post-training quantization (DFQ) method for vision Mamba-based models (VMMs). We identify two key challenges in enabling DFQ for VMMs, (1) VMM's recurrent state transitions restricts capturing of long-range interactions and leads to semantically weak synthetic data, (2) VMM activations exhibit dynamic outlier variations across time-steps, rendering existing static PTQ techniques ineffective. To address these challenges, OuroMamba presents a two-stage framework: (1) OuroMamba-Gen to generate semantically rich and meaningful synthetic data. It applies contrastive learning on patch level VMM features generated through neighborhood interactions in the latent state space, (2) OuroMamba-Quant to employ mixed-precision quantization with lightweight dynamic outlier detection during inference. In specific, we present a thresholding based outlier channel selection strategy for activations that gets updated every time-step. Extensive experiments across vision and generative tasks show that our data-free OuroMamba surpasses existing data-driven PTQ techniques, achieving state-of-the-art performance across diverse quantization settings. Additionally, we implement efficient GPU kernels to achieve practical latency speedup of up to 2.36x. Code will be released soon. 

**Abstract (ZH)**: OuroMamba：基于视觉Mamba模型的数据无关后训练量化方法 

---
# Predicting Stock Movement with BERTweet and Transformers 

**Title (ZH)**: 使用BERTweet和变换器预测股票变动 

**Authors**: Michael Charles Albada, Mojolaoluwa Joshua Sonola  

**Link**: [PDF](https://arxiv.org/pdf/2503.10957)  

**Abstract**: Applying deep learning and computational intelligence to finance has been a popular area of applied research, both within academia and industry, and continues to attract active attention. The inherently high volatility and non-stationary of the data pose substantial challenges to machine learning models, especially so for today's expressive and highly-parameterized deep learning models. Recent work has combined natural language processing on data from social media to augment models based purely on historic price data to improve performance has received particular attention. Previous work has achieved state-of-the-art performance on this task by combining techniques such as bidirectional GRUs, variational autoencoders, word and document embeddings, self-attention, graph attention, and adversarial training. In this paper, we demonstrated the efficacy of BERTweet, a variant of BERT pre-trained specifically on a Twitter corpus, and the transformer architecture by achieving competitive performance with the existing literature and setting a new baseline for Matthews Correlation Coefficient on the Stocknet dataset without auxiliary data sources. 

**Abstract (ZH)**: 将深度学习和计算智能应用于金融一直是学术界和工业界广泛应用的研究领域，仍持续吸引广泛关注。数据的内在高波动性和非平稳性给机器学习模型带来了重大挑战，尤其是对于当今表达能力强、参数量大的深度学习模型。最近的研究结合社交媒体数据的自然语言处理，以增强仅基于历史价格数据的模型，以改善性能，尤其受到关注。先前的工作通过结合双向GRUs、变分自编码器、词和文档嵌入、自我注意力、图注意力和对抗训练等技术，在该任务上达到了最先进的性能。在本文中，我们展示了BERTweet的效果，这是一种专门在Twitter语料上预训练的BERT变体和变压器架构，在Stocknet数据集上不使用辅助数据源的情况下，实现了与现有文献相当的性能，并为Matthews相关系数设定了新的基准。 

---
# Empirical Computation 

**Title (ZH)**: 实证计算 

**Authors**: Eric Tang, Marcel Böhme  

**Link**: [PDF](https://arxiv.org/pdf/2503.10954)  

**Abstract**: In this vision paper, we explore the challenges and opportunities of a form of computation that employs an empirical (rather than a formal) approach, where the solution of a computational problem is returned as empirically most likely (rather than necessarily correct). We call this approach as *empirical computation* and observe that its capabilities and limits *cannot* be understood within the classic, rationalist framework of computation.
While we take a very broad view of "computational problem", a classic, well-studied example is *sorting*: Given a set of $n$ numbers, return these numbers sorted in ascending order.
* To run a classical, *formal computation*, we might first think about a *specific algorithm* (e.g., merge sort) before developing a *specific* program that implements it. The program will expect the input to be given in a *specific* format, type, or data structure (e.g., unsigned 32-bit integers). In software engineering, we have many approaches to analyze the correctness of such programs. From complexity theory, we know that there exists no correct program that can solve the average instance of the sorting problem faster than $O(n\log n)$.
* To run an *empirical computation*, we might directly ask a large language model (LLM) to solve *any* computational problem (which can be stated informally in natural language) and provide the input in *any* format (e.g., negative numbers written as Chinese characters). There is no (problem-specific) program that could be analyzed for correctness. Also, the time it takes an LLM to return an answer is entirely *independent* of the computational complexity of the problem that is solved.
What are the capabilities or limits of empirical computation in the general, in the problem-, or in the instance-specific? Our purpose is to establish empirical computation as a field in SE that is timely and rich with interesting problems. 

**Abstract (ZH)**: 基于经验的计算：挑战与机遇 

---
# $(\varepsilon, δ)$ Considered Harmful: Best Practices for Reporting Differential Privacy Guarantees 

**Title (ZH)**: $(\varepsilon, \delta)$ 考虑有害：关于报告差分隐私保证的最佳实践 

**Authors**: Juan Felipe Gomez, Bogdan Kulynych, Georgios Kaissis, Jamie Hayes, Borja Balle, Antti Honkela  

**Link**: [PDF](https://arxiv.org/pdf/2503.10945)  

**Abstract**: Current practices for reporting the level of differential privacy (DP) guarantees for machine learning (ML) algorithms provide an incomplete and potentially misleading picture of the guarantees and make it difficult to compare privacy levels across different settings. We argue for using Gaussian differential privacy (GDP) as the primary means of communicating DP guarantees in ML, with the full privacy profile as a secondary option in case GDP is too inaccurate. Unlike other widely used alternatives, GDP has only one parameter, which ensures easy comparability of guarantees, and it can accurately capture the full privacy profile of many important ML applications. To support our claims, we investigate the privacy profiles of state-of-the-art DP large-scale image classification, and the TopDown algorithm for the U.S. Decennial Census, observing that GDP fits the profiles remarkably well in all three cases. Although GDP is ideal for reporting the final guarantees, other formalisms (e.g., privacy loss random variables) are needed for accurate privacy accounting. We show that such intermediate representations can be efficiently converted to GDP with minimal loss in tightness. 

**Abstract (ZH)**: 当前用于报告机器学习算法差分隐私（DP）保证级别的实践提供了一个不完整且可能具有误导性的图片，使其难以在不同环境中比较隐私水平。我们主张使用高斯差分隐私（GDP）作为主要的隐私保证沟通方式，并在GDP不够准确时将完整的隐私轮廓作为次要选择。与其它广泛使用的替代方案不同，GDP只有一个参数，这保证了保证的易于比较，并能准确捕捉许多重要机器学习应用的完整隐私轮廓。为了支持我们的观点，我们调查了最先进的DP大型图像分类和美国十年人口普查的TopDown算法的隐私轮廓，观察到在所有三种情况下，GDP都能非常 fitting。尽管GDP最适合报告最终保证，但为了精确的隐私核算，仍需要其他形式化表示（例如，隐私损失随机变量）。我们显示，这些中间表示可以通过最小的精确度损失高效地转换为GDP。 

---
# Predicting Clinical Outcomes with Waveform LSTMs 

**Title (ZH)**: 基于波形LSTMs的临床结局预测 

**Authors**: Michael Albada  

**Link**: [PDF](https://arxiv.org/pdf/2503.10925)  

**Abstract**: Data mining and machine learning hold great potential to enable health systems to systematically use data and analytics to identify inefficiencies and best practices that improve care and reduce costs. Waveform data offers particularly detailed information on how patient health evolves over time and has the potential to significantly improve prediction accuracy on multiple benchmarks, but has been widely under-utilized, largely because of the challenges in working with these large and complex datasets. This study evaluates the potential of leveraging clinical waveform data to improve prediction accuracy on a single benchmark task: the risk of mortality in the intensive care unit. We identify significant potential from this data, beating the existing baselines for both logistic regression and deep learning models. 

**Abstract (ZH)**: 数据挖掘和机器学习在系统利用数据和分析以识别提高护理质量和降低成本的效率和最佳实践方面具有巨大潜力。波形数据特别详细地展示了患者健康状况随时间的变化，并有望在多个基准上显著提高预测准确性，但这些数据因其大规模和复杂性而被广泛未充分利用。本研究评估了利用临床波形数据以提高重症监护病房死亡风险预测准确性的潜力，结果显示从该数据中存在显著潜力，超越了现有的逻辑回归和深度学习模型基准。 

---
# Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for Deep Learning Clusters 

**Title (ZH)**: 资源异质性感知与利用增强的深度学习集群调度 

**Authors**: Abeda Sultana, Nabin Pakka, Fei Xu, Xu Yuan, Li Chen, Nian-Feng Tzeng  

**Link**: [PDF](https://arxiv.org/pdf/2503.10918)  

**Abstract**: Scheduling deep learning (DL) models to train on powerful clusters with accelerators like GPUs and TPUs, presently falls short, either lacking fine-grained heterogeneity awareness or leaving resources substantially under-utilized. To fill this gap, we propose a novel design of a task-level heterogeneity-aware scheduler, {\em Hadar}, based on an optimization framework that can boost resource utilization. {\em Hadar} leverages the performance traits of DL jobs on a heterogeneous DL cluster, characterizes the task-level performance heterogeneity in the optimization problem, and makes scheduling decisions across both spatial and temporal dimensions. %with the objective to reduce the average job completion time of DL jobs. It involves the primal-dual framework employing a dual subroutine, to solve the optimization problem and guide the scheduling design. Our trace-driven simulation with representative DL model training workloads demonstrates that {\em Hadar} accelerates the total time duration by 1.20$\times$ when compared with its state-of-the-art heterogeneity-aware counterpart, Gavel. Further, our {\em Hadar} scheduler is enhanced to {\em HadarE} by forking each job into multiple copies to let a job train concurrently on heterogeneous GPUs resided on separate available nodes (i.e., machines or servers) for resource utilization enhancement. {\em HadarE} is evaluated extensively on physical DL clusters for comparison with {\em Hadar} and Gavel. With substantial enhancement in cluster resource utilization (by 1.45$\times$), {\em HadarE} exhibits considerable speed-ups in DL model training, reducing the total time duration by 50\% (or 80\%) on an Amazon's AWS (or our lab) cluster, while producing trained DL models with consistently better inference quality than those trained by \textit{Hadar}. 

**Abstract (ZH)**: 调度深度学习模型在配备GPU和TPU等加速器的高性能集群上训练，目前仍存在不足，要么缺乏细粒度的异构性感知，要么导致资源严重闲置。为弥补这一不足，我们提出了一种基于优化框架的新颖任务级异构性感知调度器设计方案——Hadar，旨在提高资源利用率。Hadar 利用异构深度学习集群中深度学习任务的性能特征，在优化问题中表征任务级性能异构性，并在空间和时间维度上做出调度决策，以减少深度学习任务的平均完成时间。该设计采用了包含对偶子程序的对偶框架，用于解决优化问题并指导调度设计。基于代表性深度学习模型训练工作负载的驱动型仿真实验显示，与最先进的异构性感知调度器Gavel相比，Hadar 能将总时间缩短1.20倍。此外，为增强Hadar调度器，我们通过为每个任务创建多个副本，使其能够在不同的可用节点（即机器或服务器）上的异构GPU上并行训练，提出了HadarE。HadarE 在物理深度学习集群上的广泛评估表明与Hadar和Gavel相比，HadarE 在集群资源利用率（1.45倍）显著提升的同时，也大幅提高了深度学习模型训练的速度，分别在亚马逊AWS或我们实验室集群中将总时间缩短了50%（或80%），并且生成的训练好的深度学习模型在推理质量方面始终优于Hadar。 

---
# Ecological Neural Architecture Search 

**Title (ZH)**: 生态神经架构搜索 

**Authors**: Benjamin David Winter, William J. Teahan  

**Link**: [PDF](https://arxiv.org/pdf/2503.10908)  

**Abstract**: When employing an evolutionary algorithm to optimize a neural networks architecture, developers face the added challenge of tuning the evolutionary algorithm's own hyperparameters - population size, mutation rate, cloning rate, and number of generations. This paper introduces Neuvo Ecological Neural Architecture Search (ENAS), a novel method that incorporates these evolutionary parameters directly into the candidate solutions' phenotypes, allowing them to evolve dynamically alongside architecture specifications. Experimental results across four binary classification datasets demonstrate that ENAS not only eliminates manual tuning of evolutionary parameters but also outperforms competitor NAS methodologies in convergence speed (reducing computational time by 18.3%) and accuracy (improving classification performance in 3 out of 4 datasets). By enabling "greedy individuals" to optimize resource allocation based on fitness, ENAS provides an efficient, self-regulating approach to neural architecture search. 

**Abstract (ZH)**: 基于生态进化的神经架构搜索（ENAS） 

---
# H2-MARL: Multi-Agent Reinforcement Learning for Pareto Optimality in Hospital Capacity Strain and Human Mobility during Epidemic 

**Title (ZH)**: H2-MARL: 多智能体强化学习在 Epidemic 期间医院容量压力和人类移动性帕累托最优解的研究 

**Authors**: Xueting Luo, Hao Deng, Jihong Yang, Yao Shen, Huanhuan Guo, Zhiyuan Sun, Mingqing Liu, Jiming Wei, Shengjie Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2503.10907)  

**Abstract**: The necessity of achieving an effective balance between minimizing the losses associated with restricting human mobility and ensuring hospital capacity has gained significant attention in the aftermath of COVID-19. Reinforcement learning (RL)-based strategies for human mobility management have recently advanced in addressing the dynamic evolution of cities and epidemics; however, they still face challenges in achieving coordinated control at the township level and adapting to cities of varying scales. To address the above issues, we propose a multi-agent RL approach that achieves Pareto optimality in managing hospital capacity and human mobility (H2-MARL), applicable across cities of different scales. We first develop a township-level infection model with online-updatable parameters to simulate disease transmission and construct a city-wide dynamic spatiotemporal epidemic simulator. On this basis, H2-MARL is designed to treat each division as an agent, with a trade-off dual-objective reward function formulated and an experience replay buffer enriched with expert knowledge built. To evaluate the effectiveness of the model, we construct a township-level human mobility dataset containing over one billion records from four representative cities of varying scales. Extensive experiments demonstrate that H2-MARL has the optimal dual-objective trade-off capability, which can minimize hospital capacity strain while minimizing human mobility restriction loss. Meanwhile, the applicability of the proposed model to epidemic control in cities of varying scales is verified, which showcases its feasibility and versatility in practical applications. 

**Abstract (ZH)**: 实现减少限制人类流动性所带来的损失与保障医院容量之间有效平衡的必要性在COVID-19之后引起了广泛关注。基于强化学习（RL）的人口流动性管理策略近年来在应对城市的动态演变和疫情动态发展方面取得了进展；然而，它们在实现乡镇层面的协调控制以及适应不同规模城市方面仍面临挑战。为此，我们提出了一种多agent RL方法——H2-MARL，以实现不同规模城市中医院容量管理和人口流动的帕累托最优。我们首先开发了一个可在线更新参数的乡镇级感染模型，用于模拟疾病传播，并构建了一个覆盖全市范围的动态空间—时间疫情仿真器。在此基础上，H2-MARL 被设计为将每个分区视为一个agent，并设计了一个权衡双重目标的奖励函数，同时构建了一个丰富了专家知识的经验回放缓冲区。为了评估模型的有效性，我们构建了一个包含四个不同规模代表性城市的超过十亿条记录的乡镇级人口流动性数据集。广泛的实验表明，H2-MARL 具有最佳的双重目标权衡能力，能够在最大限度减少医院容量压力的同时，最小化对人类流动性限制的影响。此外，我们验证了所提模型在不同规模城市疫情控制中的适用性，展示了其在实际应用中的可行性和灵活性。 

---
# HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks 

**Title (ZH)**: HyperDAS: 向基于超网络自动实现机理可解释性迈进 

**Authors**: Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel D'Oosterlinck, Christopher Potts, Michael Sklar, Atticus Geiger  

**Link**: [PDF](https://arxiv.org/pdf/2503.10894)  

**Abstract**: Mechanistic interpretability has made great strides in identifying neural network features (e.g., directions in hidden activation space) that mediate concepts(e.g., the birth year of a person) and enable predictable manipulation. Distributed alignment search (DAS) leverages supervision from counterfactual data to learn concept features within hidden states, but DAS assumes we can afford to conduct a brute force search over potential feature locations. To address this, we present HyperDAS, a transformer-based hypernetwork architecture that (1) automatically locates the token-positions of the residual stream that a concept is realized in and (2) constructs features of those residual stream vectors for the concept. In experiments with Llama3-8B, HyperDAS achieves state-of-the-art performance on the RAVEL benchmark for disentangling concepts in hidden states. In addition, we review the design decisions we made to mitigate the concern that HyperDAS (like all powerful interpretabilty methods) might inject new information into the target model rather than faithfully interpreting it. 

**Abstract (ZH)**: 机械可解释性已在识别介导概念（例如，一个人的出生年份）的神经网络特征（例如，隐藏激活空间中的方向）并实现可预测操控方面取得了显著进展。分布式对齐搜索（DAS）利用反事实数据的监督在隐状态中学习概念特征，但DAS假设我们能够负担得起对潜在特征位置进行穷举搜索的成本。为解决这一问题，我们提出了一种基于变压器的超网络架构HyperDAS，该架构能够（1）自动定位概念在残差流中实现的标记位置，并（2）构建这些残差流向量的概念特征。在Llama3-8B实验中，HyperDAS在RAVEL基准上实现了概念在隐状态中解耦的最佳性能。此外，我们还回顾了为减轻HyperDAS（就像所有强大的可解释性方法一样）可能在忠实地解释目标模型的同时注入新信息的担忧所做出的设计决策。 

---
# Task-Specific Activation Functions for Neuroevolution using Grammatical Evolution 

**Title (ZH)**: 用于语法进化神经进化任务特定激活函数 

**Authors**: Benjamin David Winter, William John Teahan  

**Link**: [PDF](https://arxiv.org/pdf/2503.10879)  

**Abstract**: Activation functions play a critical role in the performance and behaviour of neural networks, significantly impacting their ability to learn and generalise. Traditional activation functions, such as ReLU, sigmoid, and tanh, have been widely used with considerable success. However, these functions may not always provide optimal performance for all tasks and datasets. In this paper, we introduce Neuvo GEAF - an innovative approach leveraging grammatical evolution (GE) to automatically evolve novel activation functions tailored to specific neural network architectures and datasets. Experiments conducted on well-known binary classification datasets show statistically significant improvements in F1-score (between 2.4% and 9.4%) over ReLU using identical network architectures. Notably, these performance gains were achieved without increasing the network's parameter count, supporting the trend toward more efficient neural networks that can operate effectively on resource-constrained edge devices. This paper's findings suggest that evolved activation functions can provide significant performance improvements for compact networks while maintaining energy efficiency during both training and inference phases. 

**Abstract (ZH)**: 神经网络性能和行为中激活函数起着关键作用，显著影响其学习和泛化能力。传统的激活函数，如ReLU、Sigmoid和tanh，已经在许多任务中取得了显著成功。然而，这些函数可能并不总是能够为所有任务和数据集提供最优性能。本文介绍了一种名为Neuvo GEAF的创新方法，该方法利用语法演化（GE）自动生成针对特定神经网络架构和数据集量身定制的新型激活函数。实验结果显示，在相同网络架构下，与ReLU相比，Neuvo GEAF在F1分数上取得了统计上显著的提升（范围为2.4%至9.4%）。值得注意的是，这些性能提升是在不增加网络参数数量的情况下实现的，支持了向更高效的神经网络发展的趋势，这些网络可以在资源受限的边缘设备上有效运行。本文的研究结果表明，演化生成的激活函数可以在保持训练和推理阶段能源效率的同时，为紧凑型网络提供显著的性能改进。 

---
# TAIJI: Textual Anchoring for Immunizing Jailbreak Images in Vision Language Models 

**Title (ZH)**: TAIJI: 文本锚定免疫视觉语言模型中的逃逸图像 

**Authors**: Xiangyu Yin, Yi Qi, Jinwei Hu, Zhen Chen, Yi Dong, Xingyu Zhao, Xiaowei Huang, Wenjie Ruan  

**Link**: [PDF](https://arxiv.org/pdf/2503.10872)  

**Abstract**: Vision Language Models (VLMs) have demonstrated impressive inference capabilities, but remain vulnerable to jailbreak attacks that can induce harmful or unethical responses. Existing defence methods are predominantly white-box approaches that require access to model parameters and extensive modifications, making them costly and impractical for many real-world scenarios. Although some black-box defences have been proposed, they often impose input constraints or require multiple queries, limiting their effectiveness in safety-critical tasks such as autonomous driving. To address these challenges, we propose a novel black-box defence framework called \textbf{T}extual \textbf{A}nchoring for \textbf{I}mmunizing \textbf{J}ailbreak \textbf{I}mages (\textbf{TAIJI}). TAIJI leverages key phrase-based textual anchoring to enhance the model's ability to assess and mitigate the harmful content embedded within both visual and textual prompts. Unlike existing methods, TAIJI operates effectively with a single query during inference, while preserving the VLM's performance on benign tasks. Extensive experiments demonstrate that TAIJI significantly enhances the safety and reliability of VLMs, providing a practical and efficient solution for real-world deployment. 

**Abstract (ZH)**: 基于文本锚定的免疫逃逸图像防御框架：TAIJI 

---
# Evaluating a Novel Neuroevolution and Neural Architecture Search System 

**Title (ZH)**: 评估一种新型神经进化和神经网络架构搜索系统 

**Authors**: Benjamin David Winter, William John Teahan  

**Link**: [PDF](https://arxiv.org/pdf/2503.10869)  

**Abstract**: The choice of neural network features can have a large impact on both the accuracy and speed of the network. Despite the current industry shift towards large transformer models, specialized binary classifiers remain critical for numerous practical applications where computational efficiency and low latency are essential. Neural network features tend to be developed homogeneously, resulting in slower or less accurate networks when testing against multiple datasets. In this paper, we show the effectiveness of Neuvo NAS+ a novel Python implementation of an extended Neural Architecture Search (NAS+) which allows the user to optimise the training parameters of a network as well as the network's architecture. We provide an in-depth analysis of the importance of catering a network's architecture to each dataset. We also describe the design of the Neuvo NAS+ system that selects network features on a task-specific basis including network training hyper-parameters such as the number of epochs and batch size. Results show that the Neuvo NAS+ task-specific approach significantly outperforms several machine learning approaches such as Naive Bayes, C4.5, Support Vector Machine and a standard Artificial Neural Network for solving a range of binary classification problems in terms of accuracy. Our experiments demonstrate substantial diversity in evolved network architectures across different datasets, confirming the value of task-specific optimization. Additionally, Neuvo NAS+ outperforms other evolutionary algorithm optimisers in terms of both accuracy and computational efficiency, showing that properly optimized binary classifiers can match or exceed the performance of more complex models while requiring significantly fewer computational resources. 

**Abstract (ZH)**: 神经网络特征的选择对网络的准确性和速度有很大影响。尽管当前行业趋势是使用大型变压器模型，但针对特定任务的二元分类器在需要计算效率和低延迟的实际应用中仍然至关重要。神经网络特征通常是一致开发的，导致在多个数据集上测试时网络速度较慢或不够准确。在本文中，我们展示了Neuvo NAS+的有效性，这是一种新型的扩展神经架构搜索（NAS+）的Python实现，允许用户优化网络的训练参数和网络架构。我们深入分析了为每个数据集定制网络架构的重要性。我们还介绍了Neuvo NAS+系统的设计，该系统根据特定任务选择网络特征，包括网络训练超参数如迭代次数和批次大小。结果表明，Neuvo NAS+针对特定任务的方法在准确性和多种二元分类问题上显著优于朴素贝叶斯、C4.5、支持向量机和标准人工神经网络。我们的实验表明，在不同数据集上进化出的网络架构存在显著多样性，证实了任务特定优化的价值。此外，与其它进化算法优化器相比，Neuvo NAS+在准确性和计算效率方面表现出色，表明适当优化的二元分类器可以匹配甚至超过更复杂模型的性能，同时所需的计算资源显著减少。 

---
# Byzantine-Resilient Federated Learning via Distributed Optimization 

**Title (ZH)**: 拜占庭容错联邦学习通过分布式优化实现 

**Authors**: Yufei Xia, Wenrui Yu, Qiongxiu Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.10792)  

**Abstract**: Byzantine attacks present a critical challenge to Federated Learning (FL), where malicious participants can disrupt the training process, degrade model accuracy, and compromise system reliability. Traditional FL frameworks typically rely on aggregation-based protocols for model updates, leaving them vulnerable to sophisticated adversarial strategies. In this paper, we demonstrate that distributed optimization offers a principled and robust alternative to aggregation-centric methods. Specifically, we show that the Primal-Dual Method of Multipliers (PDMM) inherently mitigates Byzantine impacts by leveraging its fault-tolerant consensus mechanism. Through extensive experiments on three datasets (MNIST, FashionMNIST, and Olivetti), under various attack scenarios including bit-flipping and Gaussian noise injection, we validate the superior resilience of distributed optimization protocols. Compared to traditional aggregation-centric approaches, PDMM achieves higher model utility, faster convergence, and improved stability. Our results highlight the effectiveness of distributed optimization in defending against Byzantine threats, paving the way for more secure and resilient federated learning systems. 

**Abstract (ZH)**: Byzantine 攻击对 Federated Learning 呈现关键挑战：分布式优化提供了一种原理上稳健的替代方案 

---
# Predicting Treatment Response in Body Dysmorphic Disorder with Interpretable Machine Learning 

**Title (ZH)**: 使用可解释机器学习预测身体 Dysmorphic 病症治疗反应 

**Authors**: Omar Costilla-Reyes, Morgan Talbot  

**Link**: [PDF](https://arxiv.org/pdf/2503.10741)  

**Abstract**: Body Dysmorphic Disorder (BDD) is a highly prevalent and frequently underdiagnosed condition characterized by persistent, intrusive preoccupations with perceived defects in physical appearance. In this extended analysis, we employ multiple machine learning approaches to predict treatment outcomes -- specifically treatment response and remission -- with an emphasis on interpretability to ensure clinical relevance and utility. Across the various models investigated, treatment credibility emerged as the most potent predictor, surpassing traditional markers such as baseline symptom severity or comorbid conditions. Notably, while simpler models (e.g., logistic regression and support vector machines) achieved competitive predictive performance, decision tree analyses provided unique insights by revealing clinically interpretable threshold values in credibility scores. These thresholds can serve as practical guideposts for clinicians when tailoring interventions or allocating treatment resources. We further contextualize our findings within the broader literature on BDD, addressing technology-based therapeutics, digital interventions, and the psychosocial determinants of treatment engagement. An extensive array of references situates our results within current research on BDD prevalence, suicidality risks, and digital innovation. Our work underscores the potential of integrating rigorous statistical methodologies with transparent machine learning models. By systematically identifying modifiable predictors -- such as treatment credibility -- we propose a pathway toward more targeted, personalized, and ultimately efficacious interventions for individuals with BDD. 

**Abstract (ZH)**: 体象障碍的治疗预后预测：基于 interpretable 机器学习方法的深入分析 

---
# Commenting Higher-level Code Unit: Full Code, Reduced Code, or Hierarchical Code Summarization 

**Title (ZH)**: 评论高级代码单元：完整代码、缩减代码或层次代码摘要 

**Authors**: Weisong Sun, Yiran Zhang, Jie Zhu, Zhihui Wang, Chunrong Fang, Yonglong Zhang, Yebo Feng, Jiangping Huang, Xingya Wang, Zhi Jin, Yang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.10737)  

**Abstract**: Commenting code is a crucial activity in software development, as it aids in facilitating future maintenance and updates. To enhance the efficiency of writing comments and reduce developers' workload, researchers has proposed various automated code summarization (ACS) techniques to automatically generate comments/summaries for given code units. However, these ACS techniques primarily focus on generating summaries for code units at the method level. There is a significant lack of research on summarizing higher-level code units, such as file-level and module-level code units, despite the fact that summaries of these higher-level code units are highly useful for quickly gaining a macro-level understanding of software components and architecture. To fill this gap, in this paper, we conduct a systematic study on how to use LLMs for commenting higher-level code units, including file level and module level. These higher-level units are significantly larger than method-level ones, which poses challenges in handling long code inputs within LLM constraints and maintaining efficiency. To address these issues, we explore various summarization strategies for ACS of higher-level code units, which can be divided into three types: full code summarization, reduced code summarization, and hierarchical code summarization. The experimental results suggest that for summarizing file-level code units, using the full code is the most effective approach, with reduced code serving as a cost-efficient alternative. However, for summarizing module-level code units, hierarchical code summarization becomes the most promising strategy. In addition, inspired by the research on method-level ACS, we also investigate using the LLM as an evaluator to evaluate the quality of summaries of higher-level code units. The experimental results demonstrate that the LLM's evaluation results strongly correlate with human evaluations. 

**Abstract (ZH)**: 使用大规模语言模型对较高层次的代码单元进行注释：方法、文件和模块级别总结的研究 

---
# OCPM$^2$: Extending the Process Mining Methodology for Object-Centric Event Data Extraction 

**Title (ZH)**: OCPM$^2$: 扩展面向对象事件数据提取的过程挖掘方法学 

**Authors**: Najmeh Miri, Shahrzad Khayatbashi, Jelena Zdravkovic, Amin Jalali  

**Link**: [PDF](https://arxiv.org/pdf/2503.10735)  

**Abstract**: Object-Centric Process Mining (OCPM) enables business process analysis from multiple perspectives. For example, an educational path can be examined from the viewpoints of students, teachers, and groups. This analysis depends on Object-Centric Event Data (OCED), which captures relationships between events and object types, representing different perspectives. Unlike traditional process mining techniques, extracting OCED minimizes the need for repeated log extractions when shifting the analytical focus. However, recording these complex relationships increases the complexity of the log extraction process. To address this challenge, this paper proposes a method for extracting OCED based on PM\inst{2}, a well-established process mining framework. Our approach introduces a structured framework that guides data analysts and engineers in extracting OCED for process analysis. We validate this framework by applying it in a real-world educational setting, demonstrating its effectiveness in extracting an Object-Centric Event Log (OCEL), which serves as the standard format for recording OCED, from a learning management system and an administrative grading system. 

**Abstract (ZH)**: 面向对象的过程挖掘（OCPM） enables 业务过程从多个视角进行分析。例如，教育路径可以从学生、教师和群体的角度进行考察。这种分析依赖于对象为中心的事件数据（OCED），它捕捉事件与对象类型之间的关系，代表不同的视角。与传统的过程挖掘技术不同，提取OCED减少了在分析焦点转移时重复日志提取的需要。然而，记录这些复杂关系增加了日志提取过程的复杂性。为应对这一挑战，本文提出了一种基于PM\inst{2}（一个成熟的过程挖掘框架）的OCED提取方法。本文的方法引入了一个结构化的框架，指导数据分析师和工程师进行OCED的提取以进行过程分析。我们通过将其应用于一个实际的教育场景，验证了该框架的有效性，展示了如何从学习管理系统和管理评分系统中提取对象为中心的事件日志（OCEL），而OCEL是记录OCED的标准格式。 

---
# HiCMamba: Enhancing Hi-C Resolution and Identifying 3D Genome Structures with State Space Modeling 

**Title (ZH)**: HiCMamba: 提高Hi-C分辨率并结合状态空间建模识别三维基因结构 

**Authors**: Minghao Yang, Zhi-An Huang, Zhihang Zheng, Yuqiao Liu, Shichen Zhang, Pengfei Zhang, Hui Xiong, Shaojun Tang  

**Link**: [PDF](https://arxiv.org/pdf/2503.10713)  

**Abstract**: Hi-C technology measures genome-wide interaction frequencies, providing a powerful tool for studying the 3D genomic structure within the nucleus. However, high sequencing costs and technical challenges often result in Hi-C data with limited coverage, leading to imprecise estimates of chromatin interaction frequencies. To address this issue, we present a novel deep learning-based method HiCMamba to enhance the resolution of Hi-C contact maps using a state space model. We adopt the UNet-based auto-encoder architecture to stack the proposed holistic scan block, enabling the perception of both global and local receptive fields at multiple scales. Experimental results demonstrate that HiCMamba outperforms state-of-the-art methods while significantly reducing computational resources. Furthermore, the 3D genome structures, including topologically associating domains (TADs) and loops, identified in the contact maps recovered by HiCMamba are validated through associated epigenomic features. Our work demonstrates the potential of a state space model as foundational frameworks in the field of Hi-C resolution enhancement. 

**Abstract (ZH)**: Hi-C技术测量了整个基因组的相互作用频率，提供了一种研究核内三维基因组结构的强大工具。然而，高测序成本和技术挑战常常导致Hi-C数据覆盖不足，从而使得染色质相互作用频率的估计不够精确。为解决这一问题，我们提出了一种基于深度学习的方法HiCMamba，使用状态空间模型增强Hi-C接触图的分辨率。我们采用了基于UNet的自动编码器架构，结合提出的整体扫描块，使模型能够在多个尺度上同时感知全局和局部感受野。实验结果证明，HiCMamba在显著降低计算资源需求的同时，优于现有最先进的方法。此外，HiCMamba恢复的接触图中鉴定出来的包括拓扑关联域(TADs)和环状结构在内的三维基因组结构通过相关表观遗传学特征得到了验证。我们的工作展示了状态空间模型作为Hi-C分辨率增强领域基础框架的潜在价值。 

---
# Test-Time Discovery via Hashing Memory 

**Title (ZH)**: 测试时发现通过哈希记忆 

**Authors**: Fan Lyu, Tianle Liu, Zhang Zhang, Fuyuan Hu, Liang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.10699)  

**Abstract**: We introduce Test-Time Discovery (TTD) as a novel task that addresses class shifts during testing, requiring models to simultaneously identify emerging categories while preserving previously learned ones. A key challenge in TTD is distinguishing newly discovered classes from those already identified. To address this, we propose a training-free, hash-based memory mechanism that enhances class discovery through fine-grained comparisons with past test samples. Leveraging the characteristics of unknown classes, our approach introduces hash representation based on feature scale and directions, utilizing Locality-Sensitive Hashing (LSH) for efficient grouping of similar samples. This enables test samples to be easily and quickly compared with relevant past instances. Furthermore, we design a collaborative classification strategy, combining a prototype classifier for known classes with an LSH-based classifier for novel ones. To enhance reliability, we incorporate a self-correction mechanism that refines memory labels through hash-based neighbor retrieval, ensuring more stable and accurate class assignments. Experimental results demonstrate that our method achieves good discovery of novel categories while maintaining performance on known classes, establishing a new paradigm in model testing. Our code is available at this https URL. 

**Abstract (ZH)**: 我们介绍了一种新颖的任务Test-Time Discovery (TTD)，该任务在测试时解决类别偏移问题，要求模型同时识别新出现的类别并保留已学习的类别。TTD的关键挑战是区分新发现的类别与已识别的类别。为此，我们提出了一种无需训练的哈希基记忆机制，通过精细对比以往的测试样本来增强类别的发现。利用未知类别的特征，我们的方法基于特征尺度和方向引入哈希表示，利用局部敏感哈希（LSH）进行高效相似样本分组，使测试样本能够容易且快速地与相关以往实例进行比较。此外，我们设计了一种协作分类策略，结合已知类别原型分类器和基于LSH的新类别分类器。为了增强可靠性，我们引入了一种自我校正机制，通过基于哈希的邻居检索精 Refine 记忆标签，确保更稳定和准确的类别分配。实验结果表明，我们的方法在发现新类别方面表现出色，同时在已知类别上保持了性能，开创了模型测试的新范式。我们的代码可在以下链接获取。 

---
# Introducing Verification Task of Set Consistency with Set-Consistency Energy Networks 

**Title (ZH)**: 带有集一致性能量网络的集一致性验证任务 

**Authors**: Mooho Song, Jay-Yoon Lee  

**Link**: [PDF](https://arxiv.org/pdf/2503.10695)  

**Abstract**: Examining logical inconsistencies among multiple statements (such as collections of sentences or question-answer pairs) is a crucial challenge in machine learning, particularly for ensuring the safety and reliability of models. Traditional methods that rely on pairwise comparisons often fail to capture inconsistencies that only emerge when more than two statements are evaluated collectively. To address this gap, we introduce the task of set-consistency verification, an extension of natural language inference (NLI) that assesses the logical coherence of entire sets rather than isolated pairs. Building on this task, we present the Set-Consistency Energy Network (SC-Energy), a novel model that employs a contrastive loss framework to learn the compatibility among a collection of statements. Our approach not only efficiently verifies inconsistencies and pinpoints the specific statements responsible for logical contradictions, but also significantly outperforms existing methods including prompting-based LLM models. Furthermore, we release two new datasets: Set-LConVQA and Set-SNLI for set-consistency verification task. 

**Abstract (ZH)**: 检查多个陈述（如句子集合或问答对集合）之间的逻辑不一致是机器学习中的一个关键挑战，尤其是在确保模型的安全性和可靠性方面。传统的依赖于两两比较的方法往往无法捕捉到只有在多条陈述共同评估时才会出现的不一致性。为了解决这一问题，我们引入了集合一致性验证任务，这扩展了自然语言推理（NLI），评估整个集合的逻辑连贯性而非孤立的对。在此基础上，我们提出了集合一致性能量网络（SC-Energy），这是一种新型模型，使用对比损失框架来学习一组陈述之间的兼容性。我们的方法不仅高效地验证不一致性并定位导致逻辑矛盾的具体陈述，而且还显著优于包括基于提示的大语言模型在内的现有方法。此外，我们发布了两个新的数据集：Set-LConVQA和Set-SNLI，用于集合一致性验证任务。 

---
# Open-World Skill Discovery from Unsegmented Demonstrations 

**Title (ZH)**: 开放世界中的未分段示范技能发现 

**Authors**: Jingwen Deng, Zihao Wang, Shaofei Cai, Anji Liu, Yitao Liang  

**Link**: [PDF](https://arxiv.org/pdf/2503.10684)  

**Abstract**: Learning skills in open-world environments is essential for developing agents capable of handling a variety of tasks by combining basic skills. Online demonstration videos are typically long but unsegmented, making them difficult to segment and label with skill identifiers. Unlike existing methods that rely on sequence sampling or human labeling, we have developed a self-supervised learning-based approach to segment these long videos into a series of semantic-aware and skill-consistent segments. Drawing inspiration from human cognitive event segmentation theory, we introduce Skill Boundary Detection (SBD), an annotation-free temporal video segmentation algorithm. SBD detects skill boundaries in a video by leveraging prediction errors from a pretrained unconditional action-prediction model. This approach is based on the assumption that a significant increase in prediction error indicates a shift in the skill being executed. We evaluated our method in Minecraft, a rich open-world simulator with extensive gameplay videos available online. Our SBD-generated segments improved the average performance of conditioned policies by 63.7% and 52.1% on short-term atomic skill tasks, and their corresponding hierarchical agents by 11.3% and 20.8% on long-horizon tasks. Our method can leverage the diverse YouTube videos to train instruction-following agents. The project page can be found in this https URL. 

**Abstract (ZH)**: 开放世界环境中的技能学习对于开发能够处理各种任务的代理至关重要。经典的在线示范视频通常较长且未分割，难以进行分割和带有技能标识的标注。不同于依赖序列采样或人工标注的现有方法，我们开发了一种基于自监督学习的方法，将这些长视频分割为一系列具有语义意识和技能一致性的片段。受到人类认知事件分割理论的启发，我们引入了技能边界检测（SBD）——一个无需标注的时空视频分割算法。SBD通过利用预训练的无条件动作预测模型的预测误差来检测视频中的技能边界。该方法基于这样一个假设：预测误差的显著增加表明正在执行的技能发生了转变。我们在Minecraft中评估了该方法，这是一个包含丰富在线游戏视频的开放世界模拟器。由SBD生成的片段在短期原子技能任务上将条件策略的平均性能提升了63.7%，在长期任务上将相应的层次代理的性能提升了11.3%至20.8%。该方法可以利用多样化的YouTube视频来训练指令跟随代理。项目页面详见：this https URL。 

---
# A Survey on Knowledge-Oriented Retrieval-Augmented Generation 

**Title (ZH)**: 知识导向的检索增强生成综述 

**Authors**: Mingyue Cheng, Yucong Luo, Jie Ouyang, Qi Liu, Huijie Liu, Li Li, Shuo Yu, Bohou Zhang, Jiawei Cao, Jie Ma, Daoyu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.10677)  

**Abstract**: Retrieval-Augmented Generation (RAG) has gained significant attention in recent years for its potential to enhance natural language understanding and generation by combining large-scale retrieval systems with generative models. RAG leverages external knowledge sources, such as documents, databases, or structured data, to improve model performance and generate more accurate and contextually relevant outputs. This survey aims to provide a comprehensive overview of RAG by examining its fundamental components, including retrieval mechanisms, generation processes, and the integration between the two. We discuss the key characteristics of RAG, such as its ability to augment generative models with dynamic external knowledge, and the challenges associated with aligning retrieved information with generative objectives. We also present a taxonomy that categorizes RAG methods, ranging from basic retrieval-augmented approaches to more advanced models incorporating multi-modal data and reasoning capabilities. Additionally, we review the evaluation benchmarks and datasets commonly used to assess RAG systems, along with a detailed exploration of its applications in fields such as question answering, summarization, and information retrieval. Finally, we highlight emerging research directions and opportunities for improving RAG systems, such as enhanced retrieval efficiency, model interpretability, and domain-specific adaptations. This paper concludes by outlining the prospects for RAG in addressing real-world challenges and its potential to drive further advancements in natural language processing. 

**Abstract (ZH)**: Retrieval-Augmented Generation (RAG)在近年来因其将大规模检索系统与生成模型相结合以增强自然语言理解和生成的潜在能力而获得了广泛关注。RAG利用外部知识源，如文档、数据库或结构化数据，来提高模型性能并生成更准确、更上下文相关的内容。本文旨在通过考察其基本组件，包括检索机制、生成过程以及两者的集成，提供RAG的全面概述。我们讨论了RAG的关键特征，如其能够动态扩展生成模型的外部知识能力，以及将检索信息与生成目标对齐所面临的主要挑战。我们还介绍了RAG方法的分类体系，从基本的检索增强方法到结合多模态数据和推理能力的高级模型。此外，我们回顾了用来评估RAG系统的常见评估基准和数据集，并详细探讨了其在问答、摘要和信息检索等领域的应用。最后，我们指出了RAG系统的研究方向和改进机会，如提高检索效率、模型可解释性以及领域特定适应性。本文总结了RAG在应对现实挑战方面的前景及其在自然语言处理领域进一步推动创新的潜力。 

---
# Beyond One-Size-Fits-All Summarization: Customizing Summaries for Diverse Users 

**Title (ZH)**: 超越一刀切的摘要：为 diverse 用户定制摘要 

**Authors**: Mehmet Samet Duran, Tevfik Aytekin  

**Link**: [PDF](https://arxiv.org/pdf/2503.10675)  

**Abstract**: In recent years, automatic text summarization has witnessed significant advancement, particularly with the development of transformer-based models. However, the challenge of controlling the readability level of generated summaries remains an under-explored area, especially for languages with complex linguistic features like Turkish. This gap has the effect of impeding effective communication and also limits the accessibility of information. Controlling readability of textual data is an important element for creating summaries for different audiences with varying literacy and education levels, such as students ranging from primary school to graduate level, as well as individuals with diverse educational backgrounds. Summaries that align with the needs of specific reader groups can improve comprehension and engagement, ensuring that the intended message is effectively communicated. Furthermore, readability adjustment is essential to expand the usability of summarization models in educational and professional domains. Current summarization models often don't have the mechanisms to adjust the complexity of their outputs, resulting in summaries that may be too simplistic or overly complex for certain types of reader groups. Developing adaptive models that can tailor content to specific readability levels is therefore crucial. To address this problem, we create our own custom dataset and train a model with our custom architecture. Our method ensures that readability levels are effectively controlled while maintaining accuracy and coherence. We rigorously compare our model to a supervised fine-tuned baseline, demonstrating its superiority in generating readability-aware summaries. 

**Abstract (ZH)**: 近年来，自动文本摘要取得了显著进展，尤其是基于变换器模型的发展。然而，生成摘要时控制可读性水平的挑战仍未得到充分探索，特别是在具有复杂语言特征的土耳其语等语言中更为明显。这一差距阻碍了有效沟通，并限制了信息的可访问性。控制文本数据的可读性是为不同受众创建摘要的关键要素，这些受众具有不同的识字水平和教育背景，从基础教育阶段的学生到研究生，以及具有不同教育背景的个人。符合特定读者需求的摘要可以提高理解和参与度，确保预期信息的有效传递。此外，可读性调整对于扩大摘要模型在教育和专业领域的应用至关重要。当前的摘要模型通常缺乏调整输出复杂性的机制，导致某些读者群体的摘要可能过于简单或过于复杂。因此，开发可以针对特定可读性水平进行调整的适应性模型至关重要。为解决这一问题，我们创建了自己的定制数据集，并使用自定义架构训练了模型。我们的方法确保在保持准确性和连贯性的同时有效地控制可读性水平。我们严格比较了我们的模型与监督微调 baseline，展示了其在生成可读性意识摘要方面的优越性。 

---
# Optimal Transport for Brain-Image Alignment: Unveiling Redundancy and Synergy in Neural Information Processing 

**Title (ZH)**: 基于最优运输的脑影像配准：揭示神经信息处理中的冗余与协同作用 

**Authors**: Yang Xiao, Wang Lu, Jie Ji, Ruimeng Ye, Gen Li, Xiaolong Ma, Bo Hui  

**Link**: [PDF](https://arxiv.org/pdf/2503.10663)  

**Abstract**: The design of artificial neural networks (ANNs) is inspired by the structure of the human brain, and in turn, ANNs offer a potential means to interpret and understand brain signals. Existing methods primarily align brain signals with real-world signals using Mean Squared Error (MSE), which solely focuses on local point-wise alignment, and ignores global matching, leading to coarse interpretations and inaccuracies in brain signal decoding.
In this paper, we address these issues through optimal transport (OT) and theoretically demonstrate why OT provides a more effective alignment strategy than MSE. Specifically, we construct a transport plan between brain voxel embeddings and image embeddings, enabling more precise matching. By controlling the amount of transport, we mitigate the influence of redundant information. We apply our alignment model directly to the Brain Captioning task by feeding brain siginals into a large language model (LLM) instead of images. Our approach achieves state-of-the-art performance across ten evaluation metrics, surpassing the previous best method by an average of 6.11\% in single-subject training and 3.81\% in cross-subject training. Additionally, we have uncovered several insightful conclusions that align with existing brain research. We unveil the redundancy and synergy of brain information processing through region masking and data dimensionality reduction visualization experiments. We believe our approach paves the way for a more precise understanding of brain signals in the future. The code is available soon. 

**Abstract (ZH)**: 人工神经网络（ANN）的设计灵感来源于人脑的结构，ANN反过来为理解大脑信号提供了潜在的方法。现有方法主要使用均方误差（MSE）将大脑信号与现实世界信号对齐，仅关注局部点对点的对齐，而忽略全局匹配，导致大脑信号解码粗略且不准确。

在本文中，我们通过最优传输（OT）解决这些问题，并从理论上证明了为什么OT比MSE提供更有效的对齐策略。具体而言，我们构建了大脑体素嵌入与图像嵌入之间的传输计划，使其能够更精确地匹配。通过控制传输的数量，我们减少了冗余信息的影响。我们将我们的对齐模型直接应用于Brain Captioning任务，通过将大脑信号输入大型语言模型（LLM），而不是图像。我们的方法在十个评估指标中均实现了最佳性能，在单被试训练中平均超越前最佳方法6.11%，在跨被试训练中平均超越前最佳方法3.81%。此外，我们发现了几个与现有大脑研究一致的见解。我们通过区域掩蔽和数据维度降解可视化实验揭示了大脑信息处理的冗余性和协同性。我们认为我们的方法为未来更精确理解大脑信号铺平了道路。代码将在不久后公开。 

---
# MARRO: Multi-headed Attention for Rhetorical Role Labeling in Legal Documents 

**Title (ZH)**: MARRO: 多头注意力在法律文件论元角色标注中的应用 

**Authors**: Purbid Bambroo, Subinay Adhikary, Paheli Bhattacharya, Abhijnan Chakraborty, Saptarshi Ghosh, Kripabandhu Ghosh  

**Link**: [PDF](https://arxiv.org/pdf/2503.10659)  

**Abstract**: Identification of rhetorical roles like facts, arguments, and final judgments is central to understanding a legal case document and can lend power to other downstream tasks like legal case summarization and judgment prediction. However, there are several challenges to this task. Legal documents are often unstructured and contain a specialized vocabulary, making it hard for conventional transformer models to understand them. Additionally, these documents run into several pages, which makes it difficult for neural models to capture the entire context at once. Lastly, there is a dearth of annotated legal documents to train deep learning models. Previous state-of-the-art approaches for this task have focused on using neural models like BiLSTM-CRF or have explored different embedding techniques to achieve decent results. While such techniques have shown that better embedding can result in improved model performance, not many models have focused on utilizing attention for learning better embeddings in sentences of a document. Additionally, it has been recently shown that advanced techniques like multi-task learning can help the models learn better representations, thereby improving performance. In this paper, we combine these two aspects by proposing a novel family of multi-task learning-based models for rhetorical role labeling, named MARRO, that uses transformer-inspired multi-headed attention. Using label shift as an auxiliary task, we show that models from the MARRO family achieve state-of-the-art results on two labeled datasets for rhetorical role labeling, from the Indian and UK Supreme Courts. 

**Abstract (ZH)**: 识别像事实、论据和最终判决这样的修辞角色是理解法律案例文件的核心，并有助于法律案例摘要和判决预测等下游任务。然而，这一任务面临几个挑战。法律文件通常未结构化且包含专业词汇，使得传统的变压器模型难以理解。此外，这些文件往往很长，这使得神经模型难以一次性捕捉到整个上下文。最后，标注的法律文件稀缺，无法训练深度学习模型。之前该任务的最佳方法侧重于使用如BiLSTM-CRF这样的神经模型，或探索不同的嵌入技术以取得较好的结果。尽管这些技术表明更好的嵌入可以提高模型性能，但鲜有模型专注于利用注意机制学习文档句子中的更好嵌入。此外，最近的研究表明，多任务学习等高级技术可以帮助模型学习更优表示，从而提高性能。在本文中，我们通过提出一种基于多任务学习并使用变压器启发的多头注意机制的新型模型家族MARRO，结合了这两方面。借助标签平移作为辅助任务，我们展示了MARRO家族模型在来自印度和英国最高法院的两个标记数据集上的修辞角色标注任务中取得了最先进的结果。 

---
# Language modelling techniques for analysing the impact of human genetic variation 

**Title (ZH)**: 用于分析人类遗传变异影响的语言模型技术 

**Authors**: Megha Hegde, Jean-Christophe Nebel, Farzana Rahman  

**Link**: [PDF](https://arxiv.org/pdf/2503.10655)  

**Abstract**: Interpreting the effects of variants within the human genome and proteome is essential for analysing disease risk, predicting medication response, and developing personalised health interventions. Due to the intrinsic similarities between the structure of natural languages and genetic sequences, natural language processing techniques have demonstrated great applicability in computational variant effect prediction. In particular, the advent of the Transformer has led to significant advancements in the field. However, Transformer-based models are not without their limitations, and a number of extensions and alternatives have been developed to improve results and enhance computational efficiency. This review explores the use of language models for computational variant effect prediction over the past decade, analysing the main architectures, and identifying key trends and future directions. 

**Abstract (ZH)**: 解读人类基因组和蛋白质组中变异的影响对于分析疾病风险、预测药物反应以及开发个性化健康干预措施至关重要。由于自然语言结构与遗传序列的内在相似性，自然语言处理技术在计算变异效应预测中显示出极大的适用性。特别是，Transformer 的出现极大地推动了该领域的发展。然而，基于Transformer的模型并非没有局限性，许多扩展和替代方法已被开发出来以提高结果和增强计算效率。本文回顾了过去十年语言模型在计算变异效应预测中的应用，分析了主要架构，并识别了关键趋势和未来方向。 

---
# Improving RAG Retrieval via Propositional Content Extraction: a Speech Act Theory Approach 

**Title (ZH)**: 通过命题内容提取改进RAG检索：一种话语行为理论 approach 

**Authors**: João Alberto de Oliveira Lima  

**Link**: [PDF](https://arxiv.org/pdf/2503.10654)  

**Abstract**: When users formulate queries, they often include not only the information they seek, but also pragmatic markers such as interrogative phrasing or polite requests. Although these speech act indicators communicate the user\textquotesingle s intent -- whether it is asking a question, making a request, or stating a fact -- they do not necessarily add to the core informational content of the query itself. This paper investigates whether extracting the underlying propositional content from user utterances -- essentially stripping away the linguistic markers of intent -- can improve retrieval quality in Retrieval-Augmented Generation (RAG) systems. Drawing upon foundational insights from speech act theory, we propose a practical method for automatically transforming queries into their propositional equivalents before embedding. To assess the efficacy of this approach, we conducted an experimental study involving 63 user queries related to a Brazilian telecommunications news corpus with precomputed semantic embeddings. Results demonstrate clear improvements in semantic similarity between query embeddings and document embeddings at top ranks, confirming that queries stripped of speech act indicators more effectively retrieve relevant content. 

**Abstract (ZH)**: 当用户提出查询时，他们不仅包含所需的信息，还可能包含如疑问句表达或礼貌请求等语用标记。虽然这些言语行为标志传达了用户的意图（无论是提问、提出请求还是陈述事实），但它们不一定增加查询本身的核心信息内容。本文探讨从用户表达中提取潜在的命题内容——实质上去除意图的语言标志——是否能提高检索增强生成（RAG）系统的检索质量。借鉴言语行为理论的基础见解，我们提出了一种实用的方法，在嵌入之前自动将查询转换为其命题等价物。为了评估该方法的有效性，我们对一个包含63个用户查询并预计算了语义嵌入的巴西电信新闻语料库进行了实验研究。结果表明，在高排名中查询嵌入与文档嵌入的语义相似度有了明显的提高，证实了去除言语行为标志的查询能更有效地检索相关信息。 

---
# Video Anomaly Detection with Structured Keywords 

**Title (ZH)**: 基于结构化关键词的视频异常检测 

**Authors**: Thomas Foltz  

**Link**: [PDF](https://arxiv.org/pdf/2503.10653)  

**Abstract**: This paper focuses on detecting anomalies in surveillance video using keywords by leveraging foundational models' feature representation generalization capabilities. We present a novel, lightweight pipeline for anomaly classification using keyword weights. Our pipeline employs a two-stage process: induction followed by deduction. In induction, descriptions are generated from normal and anomalous frames to identify and assign weights to relevant keywords. In deduction, inference frame descriptions are converted into keyword encodings using induction-derived weights for input into our neural network for anomaly classification. We achieved comparable performance on the three benchmarks UCSD Ped2, Shanghai Tech, and CUHK Avenue, with ROC AUC scores of 0.865, 0.745, and 0.742, respectively. These results are achieved without temporal context, making such a system viable for real-time applications. Our model improves implementation setup, interpretability, and inference speed for surveillance devices on the edge, introducing a performance trade-off against other video anomaly detection systems. As the generalization capabilities of open-source foundational models improve, our model demonstrates that the exclusive use of text for feature representations is a promising direction for efficient real-time interpretable video anomaly detection. 

**Abstract (ZH)**: 本文利用基础模型的特征表示泛化能力聚焦于通过关键词检测监控视频中的异常。我们提出了一种轻量级的异常分类新pipeline，利用关键词权重。该pipeline采用两阶段过程：归纳和演绎。在归纳阶段，从正常和异常帧生成描述，以识别并分配相关关键词的权重。在演绎阶段，使用归纳得出的权重将推理帧描述转换为关键词编码，输入到我们的神经网络以进行异常分类。我们在UCSD Ped2、上海Tech和CUHK Avenue三个基准上达到了相当的性能，AUC ROC分数分别为0.865、0.745和0.742。这些结果无需时空上下文，使得该系统适用于实时应用。我们的模型提高了边缘监控设备的实施设置、可解释性和推理速度，并在与其他视频异常检测系统相比引入了性能权衡。随着开源基础模型泛化能力的提升，本文展示了仅使用文本作为特征表示的独特方向在高效实时可解释视频异常检测方面的潜力。 

---
# Disentanglement Learning via Topology 

**Title (ZH)**: 拓扑引导的分离学习 

**Authors**: Nikita Balabin, Daria Voronkova, Ilya Trofimov, Evgeny Burnaev, Serguei Barannikov  

**Link**: [PDF](https://arxiv.org/pdf/2308.12696)  

**Abstract**: We propose TopDis (Topological Disentanglement), a method for learning disentangled representations via adding a multi-scale topological loss term. Disentanglement is a crucial property of data representations substantial for the explainability and robustness of deep learning models and a step towards high-level cognition. The state-of-the-art methods are based on VAE and encourage the joint distribution of latent variables to be factorized. We take a different perspective on disentanglement by analyzing topological properties of data manifolds. In particular, we optimize the topological similarity for data manifolds traversals. To the best of our knowledge, our paper is the first one to propose a differentiable topological loss for disentanglement learning. Our experiments have shown that the proposed TopDis loss improves disentanglement scores such as MIG, FactorVAE score, SAP score, and DCI disentanglement score with respect to state-of-the-art results while preserving the reconstruction quality. Our method works in an unsupervised manner, permitting us to apply it to problems without labeled factors of variation. The TopDis loss works even when factors of variation are correlated. Additionally, we show how to use the proposed topological loss to find disentangled directions in a trained GAN. 

**Abstract (ZH)**: TopDis（拓扑解纠缠）：一种通过添加多尺度拓扑损失项学习解纠缠表示的方法 

---
# Device-Robust Acoustic Scene Classification via Impulse Response Augmentation 

**Title (ZH)**: 基于冲击响应增强的设备鲁棒声场景分类 

**Authors**: Tobias Morocutti, Florian Schmid, Khaled Koutini, Gerhard Widmer  

**Link**: [PDF](https://arxiv.org/pdf/2305.07499)  

**Abstract**: The ability to generalize to a wide range of recording devices is a crucial performance factor for audio classification models. The characteristics of different types of microphones introduce distributional shifts in the digitized audio signals due to their varying frequency responses. If this domain shift is not taken into account during training, the model's performance could degrade severely when it is applied to signals recorded by unseen devices. In particular, training a model on audio signals recorded with a small number of different microphones can make generalization to unseen devices difficult. To tackle this problem, we convolve audio signals in the training set with pre-recorded device impulse responses (DIRs) to artificially increase the diversity of recording devices. We systematically study the effect of DIR augmentation on the task of Acoustic Scene Classification using CNNs and Audio Spectrogram Transformers. The results show that DIR augmentation in isolation performs similarly to the state-of-the-art method Freq-MixStyle. However, we also show that DIR augmentation and Freq-MixStyle are complementary, achieving a new state-of-the-art performance on signals recorded by devices unseen during training. 

**Abstract (ZH)**: 音频分类模型广泛记录设备上的泛化能力是一项关键性能指标。不同类型的麦克风因频率响应的差异在其数字化音频信号中引入分布偏移。如果在训练过程中未考虑这种领域偏移，模型在应用到未见过设备记录的信号时性能可能会严重下降。特别是在使用少量不同麦克风录制的音频信号上训练模型，会使得模型对未见过设备的泛化变得困难。为解决这一问题，我们在训练集的音频信号中卷积预录制的设备冲激响应（DIRs），以人工增加录音设备的多样性。我们系统研究了DIR增强对使用CNN和Audio Spectrogram Transformers进行声场景分类任务的影响。结果表明，仅使用DIR增强的表现与现有最佳方法Freq-MixStyle相当。但我们还发现，DIR增强和Freq-MixStyle是互补的，能够在未见过设备记录的信号上实现新的最佳性能。 

---
