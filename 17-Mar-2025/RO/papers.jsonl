{'arxiv_id': 'arXiv:2503.11650', 'title': 'Centaur: Robust End-to-End Autonomous Driving with Test-Time Training', 'authors': 'Chonghao Sima, Kashyap Chitta, Zhiding Yu, Shiyi Lan, Ping Luo, Andreas Geiger, Hongyang Li, Jose M. Alvarez', 'link': 'https://arxiv.org/abs/2503.11650', 'abstract': "How can we rely on an end-to-end autonomous vehicle's complex decision-making system during deployment? One common solution is to have a ``fallback layer'' that checks the planned trajectory for rule violations and replaces it with a pre-defined safe action if necessary. Another approach involves adjusting the planner's decisions to minimize a pre-defined ``cost function'' using additional system predictions such as road layouts and detected obstacles. However, these pre-programmed rules or cost functions cannot learn and improve with new training data, often resulting in overly conservative behaviors. In this work, we propose Centaur (Cluster Entropy for Test-time trAining using Uncertainty) which updates a planner's behavior via test-time training, without relying on hand-engineered rules or cost functions. Instead, we measure and minimize the uncertainty in the planner's decisions. For this, we develop a novel uncertainty measure, called Cluster Entropy, which is simple, interpretable, and compatible with state-of-the-art planning algorithms. Using data collected at prior test-time time-steps, we perform an update to the model's parameters using a gradient that minimizes the Cluster Entropy. With only this sole gradient update prior to inference, Centaur exhibits significant improvements, ranking first on the navtest leaderboard with notable gains in safety-critical metrics such as time to collision. To provide detailed insights on a per-scenario basis, we also introduce navsafe, a challenging new benchmark, which highlights previously undiscovered failure modes of driving models.", 'abstract_zh': '如何在部署期间依赖端到端自主驾驶车辆的复杂决策系统？一种常见的解决方案是在系统中设置一个“后备层”，用于检查计划路径是否存在规则违规，并在必要时用预定义的安全动作替换之。另一种方法是利用例如路网布局和检测到的障碍物等附加系统预测来调整规划器的决策，以最小化预定义的“成本函数”。然而，这些事先编程的规则或成本函数无法随着新的训练数据进行学习和改进，往往会导致过于保守的行为。在本研究中，我们提出了一种名为Centaur（Cluster Entropy for Test-time Training using Uncertainty）的方法，通过测试时训练更新规划器的行为，而不依赖于手工构建的规则或成本函数。相反，我们衡量并最小化规划器决策中的不确定性。为此，我们开发了一种新颖的不确定性度量方法，称为Cluster Entropy，该方法简单、可解释，并且与最先进的规划算法兼容。利用先前测试时间步的数据，我们使用使Cluster Entropy最小化的梯度更新模型参数。在仅通过这一唯一的一次梯度更新进行推理之前，Centaur显示出显著的改进，在navtest排行榜上排名第一，并在碰撞时间等关键安全指标上取得显著提高。为了在单个场景的基础上提供详细的见解，我们还引入了navsafe，这是一个具有挑战性的新基准，突显了驾驶模型之前未被发现的失效模式。', 'title_zh': 'Ṛ Robbie: 坚 robust 系统的端到端自主驾驶测试时训练'}
{'arxiv_id': 'arXiv:2503.11646', 'title': 'Adversarial Data Collection: Human-Collaborative Perturbations for Efficient and Robust Robotic Imitation Learning', 'authors': 'Siyuan Huang, Yue Liao, Siyuan Feng, Shu Jiang, Si Liu, Hongsheng Li, Maoqing Yao, Guanghui Ren', 'link': 'https://arxiv.org/abs/2503.11646', 'abstract': 'The pursuit of data efficiency, where quality outweighs quantity, has emerged as a cornerstone in robotic manipulation, especially given the high costs associated with real-world data collection. We propose that maximizing the informational density of individual demonstrations can dramatically reduce reliance on large-scale datasets while improving task performance. To this end, we introduce Adversarial Data Collection, a Human-in-the-Loop (HiL) framework that redefines robotic data acquisition through real-time, bidirectional human-environment interactions. Unlike conventional pipelines that passively record static demonstrations, ADC adopts a collaborative perturbation paradigm: during a single episode, an adversarial operator dynamically alters object states, environmental conditions, and linguistic commands, while the tele-operator adaptively adjusts actions to overcome these evolving challenges. This process compresses diverse failure-recovery behaviors, compositional task variations, and environmental perturbations into minimal demonstrations. Our experiments demonstrate that ADC-trained models achieve superior compositional generalization to unseen task instructions, enhanced robustness to perceptual perturbations, and emergent error recovery capabilities. Strikingly, models trained with merely 20% of the demonstration volume collected through ADC significantly outperform traditional approaches using full datasets. These advances bridge the gap between data-centric learning paradigms and practical robotic deployment, demonstrating that strategic data acquisition, not merely post-hoc processing, is critical for scalable, real-world robot learning. Additionally, we are curating a large-scale ADC-Robotics dataset comprising real-world manipulation tasks with adversarial perturbations. This benchmark will be open-sourced to facilitate advancements in robotic imitation learning.', 'abstract_zh': '追求数据效率，重视质量而非数量，已成为机器人操作领域的基石，特别是在面对高昂的实际数据采集成本时。我们提出通过最大化单个演示的数据信息密度，可以显著减少对大规模数据集的依赖，同时提高任务性能。为此，我们引入了对抗性数据采集（Adversarial Data Collection，ADC）这一基于人工在环（Human-in-the-Loop，HiL）框架，重新定义了通过实时双向的人机环境交互来采集机器人数据的方式。与传统的被动记录静态演示的管道不同，ADC采用了一种协作扰动范式：在单个episode中，对抗操作者动态改变物体状态、环境条件和语言指令，而远程操作者则适应性调整行动以应对这些不断演变的挑战。这一过程将多样化的失败恢复行为、组合任务变化和环境扰动压缩到了最小的演示中。我们的实验表明，使用ADC训练的模型在面对未见过的任务指令时表现出更优的组合泛化能力，增强了对感知扰动的鲁棒性，并具备了新兴的错误恢复能力。令人瞩目的是，仅使用通过ADC采集的演示数据量的20%训练的模型，在任务表现上显著优于使用完整数据集的传统方法。这些进展缩小了数据为中心的学习范式与实际机器人部署之间的差距，证明了战略性数据采集而非仅仅后期处理对于可扩展的现实世界机器人学习至关重要。此外，我们正在编纂一个大规模的ADC-Robotics数据集，包含带有对抗扰动的实际操作任务，该基准将开源以促进机器人模仿学习的进步。', 'title_zh': '对抗数据采集：高效稳健的机器人模仿学习中的人机协作扰动'}
{'arxiv_id': 'arXiv:2503.11560', 'title': 'Reparametrization of 3D CSC Dubins Paths Enabling 2D Search', 'authors': 'Ling Xu, Yuliy Baryshnikov, Cynthia Sung', 'link': 'https://arxiv.org/abs/2503.11560', 'abstract': 'This paper addresses the Dubins path planning problem for vehicles in 3D space. In particular, we consider the problem of computing CSC paths -- paths that consist of a circular arc (C) followed by a straight segment (S) followed by a circular arc (C). These paths are useful for vehicles such as fixed-wing aircraft and underwater submersibles that are subject to lower bounds on turn radius. We present a new parameterization that reduces the 3D CSC planning problem to a search over 2 variables, thus lowering search complexity, while also providing gradients that assist that search. We use these equations with a numerical solver to explore numbers and types of solutions computed for a variety of planar and 3D scenarios. Our method successfully computes CSC paths for the large majority of test cases, indicating that it could be useful for future generation of robust, efficient curvature-constrained trajectories.', 'abstract_zh': '本文解决三维空间中车辆的Dubins路径规划问题，特别考虑了由一段圆弧（C）跟随一段直线段（S）再跟随一段圆弧（C）组成的CSC路径的计算问题。这些路径适用于受最小转弯半径限制的飞机和水下潜航器等车辆。我们提出了一种新的参数化方法，将3D CSC路径规划问题简化为在两个变量上的搜索，从而降低了搜索复杂度，同时提供了帮助搜索的梯度。我们使用这些方程与数值求解器结合来探索不同平面和3D场景下计算的路径数量和类型。我们的方法成功计算了大量测试案例中的CSC路径，表明它可能对未来生成鲁棒高效的曲率约束轨迹具有实用价值。', 'title_zh': '3D CSC 圭布林路径的重新参数化以实现二维搜索'}
{'arxiv_id': 'arXiv:2503.11551', 'title': 'Vectorable Thrust Control for Multimodal Locomotion of Quadruped Robot SPIDAR', 'authors': 'Moju Zhao', 'link': 'https://arxiv.org/abs/2503.11551', 'abstract': "In this paper, I present vectorable thrust control for different locomotion modes by a novel quadruped robot, SPIDAR, equipped with vectoring rotor in each link. First, the robot's unique mechanical design, the dynamics model, and the basic control framework for terrestrial/aerial locomotion are briefly introduced. Second, a vectorable thrust control method derived from the basic control framework for aerial locomotion is presented. A key feature of this extended flight control is its ability to avoid interrotor aerodynamics interference under specific joint configuration. Third, another extended thrust control method and a fundamental gait strategy is proposed for special terrestrial locomotion called crawling that requires all legs to be lifted at the same time. Finally, the experimental results of the flight with a complex joint motion and the repeatable crawling motion are explained, which demonstrate the feasibility of the proposed thrust control methods for different locomotion modes.", 'abstract_zh': '本文提出了一种新型四足机器人SPIDAR的可矢量推力控制方法，该机器人在每个连杆上配备了矢量旋翼。首先，介绍了机器人的独特机械设计、动力学模型及其用于地面/空中运动的基本控制框架。其次，基于空中运动基本控制框架提出了一种可矢量推力控制方法，该扩展飞行控制的一个关键特征是在特定关节配置下能够避免旋翼间气动干扰。第三，针对一种特殊的地面运动方式——爬行，提出了另一种扩展推力控制方法和基本步态策略，该方式要求所有腿同时抬起。最后，详细解释了具有复杂关节运动的飞行实验结果和可重复的爬行运动实验结果，这些结果证明了所提出的不同运动模式下的推力控制方法的可行性。', 'title_zh': '可矢量控制的推力多模态四足机器人SPIDAR的腿部运动控制'}
{'arxiv_id': 'arXiv:2503.11520', 'title': 'Multi-robot coordination for connectivity recovery after unpredictable environment changes', 'authors': 'Yaroslav Marchukov, Luis Montano', 'link': 'https://arxiv.org/abs/2503.11520', 'abstract': 'In the present paper we develop a distributed method to reconnect a multi-robot team after connectivity failures, caused by unpredictable environment changes, i.e. appearance of new obstacles. After the changes, the team is divided into different groups of robots. The groups have a limited communication range and only a partial information in their field of view about the current scenario. Their objective is to form a chain from a static base station to a goal location. In the proposed distributed replanning approach, the robots predict new plans for the other groups from the new observed information by each robot in the changed scenario, to restore the connectivity with a base station and reach the initial joint objective. If a solution exists, the method achieves the reconnection of all the groups in a unique chain. The proposed method is compared with other two cases: 1) when all the agents have full information of the environment, and 2) when some robots must move to reach other waiting robots for reconnection. Numerical simulations are provided to evaluate the proposed approach in the presence of unpredictable scenario changes.', 'abstract_zh': '基于不可预测环境变化的多机器人团队分布式重新连接方法', 'title_zh': '不确定环境变化后多机器人协调以恢复连通性'}
{'arxiv_id': 'arXiv:2503.11504', 'title': 'Multi-agent coordination for on-demand data gathering with periodic information upload', 'authors': 'Yaroslav Marchukov, Luis Montano', 'link': 'https://arxiv.org/abs/2503.11504', 'abstract': 'In this paper we develop a method for planning and coordinating a multi-agent team deployment to periodically gather information on demand. A static operation center (OC) periodically requests information from changing goal locations. The objective is to gather data in the goals and to deliver it to the OC, balancing the refreshing time and the total number of information packages. The system automatically splits the team in two roles: workers to gather data, or collectors to retransmit the data to the OC. The proposed three step method: 1) finds out the best area partition for the workers; 2) obtains the best balance between workers and collectors, and with whom the workers must to communicate, a collector or the OC; 3) computes the best tour for the workers to visit the goals and deliver them to the OC or to a collector in movement. The method is tested in simulations in different scenarios, providing the best area partition algorithm and the best balance between collectors and workers.', 'abstract_zh': '本文开发了一种方法，用于规划和协调多代理团队部署，以定期收集需求信息。一个固定的运营中心（OC）定期从不断变化的目标位置请求信息。目标是收集目标数据并将其传递给OC，平衡刷新时间和总信息包数。系统自动将团队分为两种角色：收集数据的工人或重新传输数据的收集者。提出的三步方法包括：1）确定工人的最佳区域划分；2）获得工人与收集者之间最佳平衡以及工人需要与谁通信（收集者或OC）；3）计算工人的最佳路线，以访问目标并将数据传递给OC或移动中的收集者。该方法在不同的仿真场景中进行了测试，提供了最佳区域划分算法和收集者与工人之间最佳平衡。', 'title_zh': '按需数据搜集与周期性信息上传的多agent协调'}
{'arxiv_id': 'arXiv:2503.11474', 'title': 'Exo-muscle: A semi-rigid assistive device for the knee', 'authors': 'Yifang Zhang, Arash Ajoudani, Nikos G Tsagarakis', 'link': 'https://arxiv.org/abs/2503.11474', 'abstract': 'In this work, we introduce the principle, design and mechatronics of Exo-Muscle, a novel assistive device for the knee joint. Different from the existing systems based on rigid exoskeleton structures or soft-tendon driven approaches, the proposed device leverages a new semi-rigid principle that explores the benefits of both rigid and soft systems. The use of a novel semi-rigid chain mechanism around the knee joint eliminates the presence of misalignment between the device and the knee joint center of rotation, while at the same time, it forms a well-defined route for the tendon. This results in more deterministic load compensation functionality compared to the fully soft systems. The proposed device can provide up to 38Nm assistive torque to the knee joint. In the experiment section, the device was successfully validated through a series of experiments demonstrating the capacity of the device to provide the target assistive functionality in the knee joint.', 'abstract_zh': '本研究介绍了Exo-Muscle的工作原理、设计及机电一体化，这是一种新型的膝关节辅助设备。不同于基于刚性外骨骼结构或软腱驱动的方法，所提出的设备采用了新的半刚性原理，结合了刚性系统和软系统的优势。在膝关节周围采用一种新颖的半刚性链机构，消除了设备与膝关节旋转中心的错位，同时为肌腱提供了清晰的路径。这使得设备在负载补偿功能上比全软系统更具确定性。实验部分通过一系列实验成功验证了该设备能够为膝关节提供目标辅助功能，最大辅助扭矩可达38Nm。', 'title_zh': 'exo-肌骨：一种半刚性膝关节辅助装置'}
{'arxiv_id': 'arXiv:2503.11467', 'title': 'Dynamic Obstacle Avoidance with Bounded Rationality Adversarial Reinforcement Learning', 'authors': "Jose-Luis Holgado-Alvarez, Aryaman Reddi, Carlo D'Eramo", 'link': 'https://arxiv.org/abs/2503.11467', 'abstract': 'Reinforcement Learning (RL) has proven largely effective in obtaining stable locomotion gaits for legged robots. However, designing control algorithms which can robustly navigate unseen environments with obstacles remains an ongoing problem within quadruped locomotion. To tackle this, it is convenient to solve navigation tasks by means of a hierarchical approach with a low-level locomotion policy and a high-level navigation policy. Crucially, the high-level policy needs to be robust to dynamic obstacles along the path of the agent. In this work, we propose a novel way to endow navigation policies with robustness by a training process that models obstacles as adversarial agents, following the adversarial RL paradigm. Importantly, to improve the reliability of the training process, we bound the rationality of the adversarial agent resorting to quantal response equilibria, and place a curriculum over its rationality. We called this method Hierarchical policies via Quantal response Adversarial Reinforcement Learning (Hi-QARL). We demonstrate the robustness of our method by benchmarking it in unseen randomized mazes with multiple obstacles. To prove its applicability in real scenarios, our method is applied on a Unitree GO1 robot in simulation.', 'abstract_zh': '基于定量反应对抗强化学习的分层导航策略（Hierarchical Policies via Quantal Response Adversarial Reinforcement Learning (Hi-QARL)）', 'title_zh': '具有限定理性对手增强学习的动态障碍避让'}
{'arxiv_id': 'arXiv:2503.11461', 'title': 'MRS-CWC: A Weakly Constrained Multi-Robot System with Controllable Constraint Stiffness for Mobility and Navigation in Unknown 3D Rough Environments', 'authors': 'Runze Xiao, Yongdong Wang, Yusuke Tsunoda, Koichi Osuka, Hajime Asama', 'link': 'https://arxiv.org/abs/2503.11461', 'abstract': "Navigating unknown three-dimensional (3D) rugged environments is challenging for multi-robot systems. Traditional discrete systems struggle with rough terrain due to limited individual mobility, while modular systems--where rigid, controllable constraints link robot units--improve traversal but suffer from high control complexity and reduced flexibility. To address these limitations, we propose the Multi-Robot System with Controllable Weak Constraints (MRS-CWC), where robot units are connected by constraints with dynamically adjustable stiffness. This adaptive mechanism softens or stiffens in real-time during environmental interactions, ensuring a balance between flexibility and mobility. We formulate the system's dynamics and control model and evaluate MRS-CWC against six baseline methods and an ablation variant in a benchmark dataset with 100 different simulation terrains. Results show that MRS-CWC achieves the highest navigation completion rate and ranks second in success rate, efficiency, and energy cost in the highly rugged terrain group, outperforming all baseline methods without relying on environmental modeling, path planning, or complex control. Even where MRS-CWC ranks second, its performance is only slightly behind a more complex ablation variant with environmental modeling and path planning. Finally, we develop a physical prototype and validate its feasibility in a constructed rugged environment. For videos, simulation benchmarks, and code, please visit this https URL.", 'abstract_zh': '具有可控弱约束的多机器人系统在未知三维崎岖环境中的导航', 'title_zh': 'MRS-CWC: 一种用于未知粗糙3D环境中的移动与导航的可控制约束刚度弱约束多机器人系统'}
{'arxiv_id': 'arXiv:2503.11433', 'title': 'Adaptive Torque Control of Exoskeletons under Spasticity Conditions via Reinforcement Learning', 'authors': 'Andrés Chavarrías, David Rodriguez-Cianca, Pablo Lanillos', 'link': 'https://arxiv.org/abs/2503.11433', 'abstract': 'Spasticity is a common movement disorder symptom in individuals with cerebral palsy, hereditary spastic paraplegia, spinal cord injury and stroke, being one of the most disabling features in the progression of these diseases. Despite the potential benefit of using wearable robots to treat spasticity, their use is not currently recommended to subjects with a level of spasticity above ${1^+}$ on the Modified Ashworth Scale. The varying dynamics of this velocity-dependent tonic stretch reflex make it difficult to deploy safe personalized controllers. Here, we describe a novel adaptive torque controller via deep reinforcement learning (RL) for a knee exoskeleton under joint spasticity conditions, which accounts for task performance and interaction forces reduction. To train the RL agent, we developed a digital twin, including a musculoskeletal-exoskeleton system with joint misalignment and a differentiable spastic reflexes model for the muscles activation. Results for a simulated knee extension movement showed that the agent learns to control the exoskeleton for individuals with different levels of spasticity. The proposed controller was able to reduce maximum torques applied to the human joint under spastic conditions by an average of 10.6\\% and decreases the root mean square until the settling time by 8.9\\% compared to a conventional compliant controller.', 'abstract_zh': '穿戴式机器人在治疗痉挛中的应用及其在改良Ashworth量表Spasticity等级${1^+}$以上患者中的局限性：基于深度强化学习的膝关节外骨骼自适应扭矩控制器的研究', 'title_zh': '基于强化学习的痉挛状态下外骨骼适应性扭矩控制'}
{'arxiv_id': 'arXiv:2503.11420', 'title': 'AQUA-SLAM: Tightly-Coupled Underwater Acoustic-Visual-Inertial SLAM with Sensor Calibration', 'authors': 'Shida Xu, Kaicheng Zhang, Sen Wang', 'link': 'https://arxiv.org/abs/2503.11420', 'abstract': 'Underwater environments pose significant challenges for visual Simultaneous Localization and Mapping (SLAM) systems due to limited visibility, inadequate illumination, and sporadic loss of structural features in images. Addressing these challenges, this paper introduces a novel, tightly-coupled Acoustic-Visual-Inertial SLAM approach, termed AQUA-SLAM, to fuse a Doppler Velocity Log (DVL), a stereo camera, and an Inertial Measurement Unit (IMU) within a graph optimization framework. Moreover, we propose an efficient sensor calibration technique, encompassing multi-sensor extrinsic calibration (among the DVL, camera and IMU) and DVL transducer misalignment calibration, with a fast linear approximation procedure for real-time online execution. The proposed methods are extensively evaluated in a tank environment with ground truth, and validated for offshore applications in the North Sea. The results demonstrate that our method surpasses current state-of-the-art underwater and visual-inertial SLAM systems in terms of localization accuracy and robustness. The proposed system will be made open-source for the community.', 'abstract_zh': '水下环境对视觉同时定位与建图（SLAM）系统构成了显著挑战，由于能见度有限、光照不足以及图像中结构特征的间歇性丢失。为应对这些挑战，本文提出了一种新的紧密耦合的声学-视觉-惯性SLAM方法，称为AQUA-SLAM，该方法在图优化框架内融合了多普勒速度记录仪（DVL）、立体相机和惯性测量单元（IMU）。此外，本文还提出了一种高效的传感器校准技术，包括多传感器外部校准（DVL、相机和IMU之间）和换能器偏移校准，并采用快速线性逼近程序以实现实时在线执行。所提出的方法在含地面真实数据的水箱环境中进行了广泛评估，并在北海的离岸应用中进行了验证。实验结果表明，该方法在定位精度和鲁棒性方面超越了当前最先进的水下和视觉-惯性SLAM系统。提出的系统将对社区开源。', 'title_zh': 'AQUA-SLAM：基于传感器标定的水下声学-视觉-惯性SLAM'}
{'arxiv_id': 'arXiv:2503.11372', 'title': 'BEVDiffLoc: End-to-End LiDAR Global Localization in BEV View based on Diffusion Model', 'authors': 'Ziyue Wang, Chenghao Shi, Neng Wang, Qinghua Yu, Xieyuanli Chen, Huimin Lu', 'link': 'https://arxiv.org/abs/2503.11372', 'abstract': "Localization is one of the core parts of modern robotics. Classic localization methods typically follow the retrieve-then-register paradigm, achieving remarkable success. Recently, the emergence of end-to-end localization approaches has offered distinct advantages, including a streamlined system architecture and the elimination of the need to store extensive map data. Although these methods have demonstrated promising results, current end-to-end localization approaches still face limitations in robustness and accuracy. Bird's-Eye-View (BEV) image is one of the most widely adopted data representations in autonomous driving. It significantly reduces data complexity while preserving spatial structure and scale consistency, making it an ideal representation for localization tasks. However, research on BEV-based end-to-end localization remains notably insufficient. To fill this gap, we propose BEVDiffLoc, a novel framework that formulates LiDAR localization as a conditional generation of poses. Leveraging the properties of BEV, we first introduce a specific data augmentation method to significantly enhance the diversity of input data. Then, the Maximum Feature Aggregation Module and Vision Transformer are employed to learn robust features while maintaining robustness against significant rotational view variations. Finally, we incorporate a diffusion model that iteratively refines the learned features to recover the absolute pose. Extensive experiments on the Oxford Radar RobotCar and NCLT datasets demonstrate that BEVDiffLoc outperforms the baseline methods. Our code is available at this https URL.", 'abstract_zh': '基于BEV的端到端局部化：BEVDiffLoc框架', 'title_zh': 'BEVDiffLoc：基于扩散模型的端到端LiDAR全局局部化在BEV视图中'}
{'arxiv_id': 'arXiv:2503.11352', 'title': 'Enhancing Hand Palm Motion Gesture Recognition by Eliminating Reference Frame Bias via Frame-Invariant Similarity Measures', 'authors': 'Arno Verduyn, Maxim Vochten, Joris De Schutter', 'link': 'https://arxiv.org/abs/2503.11352', 'abstract': 'The ability of robots to recognize human gestures facilitates a natural and accessible human-robot collaboration. However, most work in gesture recognition remains rooted in reference frame-dependent representations. This poses a challenge when reference frames vary due to different work cell layouts, imprecise frame calibrations, or other environmental changes. This paper investigated the use of invariant trajectory descriptors for robust hand palm motion gesture recognition under reference frame changes. First, a novel dataset of recorded Hand Palm Motion (HPM) gestures is introduced. The motion gestures in this dataset were specifically designed to be distinguishable without dependence on specific reference frames or directional cues. Afterwards, multiple invariant trajectory descriptor approaches were benchmarked to assess how their performances generalize to this novel HPM dataset. After this offline benchmarking, the best scoring approach is validated for online recognition by developing a real-time Proof of Concept (PoC). In this PoC, hand palm motion gestures were used to control the real-time movement of a manipulator arm. The PoC demonstrated a high recognition reliability in real-time operation, achieving an $F_1$-score of 92.3%. This work demonstrates the effectiveness of the invariant descriptor approach as a standalone solution. Moreover, we believe that the invariant descriptor approach can also be utilized within other state-of-the-art pattern recognition and learning systems to improve their robustness against reference frame variations.', 'abstract_zh': '基于不变轨迹描述符的人手掌运动手势识别在参考框架变化下的稳健性研究', 'title_zh': '通过使用帧不变相似度度量消除参考帧偏差以增强手掌运动手势识别'}
{'arxiv_id': 'arXiv:2503.11269', 'title': 'Prof. Robot: Differentiable Robot Rendering Without Static and Self-Collisions', 'authors': 'Quanyuan Ruan, Jiabao Lei, Wenhao Yuan, Yanglin Zhang, Dekun Lu, Guiliang Liu, Kui Jia', 'link': 'https://arxiv.org/abs/2503.11269', 'abstract': 'Differentiable rendering has gained significant attention in the field of robotics, with differentiable robot rendering emerging as an effective paradigm for learning robotic actions from image-space supervision. However, the lack of physical world perception in this approach may lead to potential collisions during action optimization. In this work, we introduce a novel improvement on previous efforts by incorporating physical awareness of collisions through the learning of a neural robotic collision classifier. This enables the optimization of actions that avoid collisions with static, non-interactable environments as well as the robot itself. To facilitate effective gradient optimization with the classifier, we identify the underlying issue and propose leveraging Eikonal regularization to ensure consistent gradients for optimization. Our solution can be seamlessly integrated into existing differentiable robot rendering frameworks, utilizing gradients for optimization and providing a foundation for future applications of differentiable rendering in robotics with improved reliability of interactions with the physical world. Both qualitative and quantitative experiments demonstrate the necessity and effectiveness of our method compared to previous solutions.', 'abstract_zh': '通过引入物理碰撞分类器的神经网络实现带有物理感知的可微机器人渲染改进研究', 'title_zh': '教授机器人：无静止和自碰撞可微机器人渲染'}
{'arxiv_id': 'arXiv:2503.11235', 'title': 'Ergodic exploration of dynamic distribution', 'authors': 'Luka Lanča, Karlo Jakac, Sylvain Calinon, Stefan Ivić', 'link': 'https://arxiv.org/abs/2503.11235', 'abstract': 'This research addresses the challenge of performing search missions in dynamic environments, particularly for drifting targets whose movement is dictated by a flow field. This is accomplished through a dynamical system that integrates two partial differential equations: one governing the dynamics and uncertainty of the probability distribution, and the other regulating the potential field for ergodic multi-agent search. The target probability field evolves in response to the target dynamics imposed by the environment and accomplished sensing efforts, while being explored by multiple robot agents guided by the potential field gradient. The proposed methodology was tested on two simulated search scenarios, one of which features a synthetically generated domain and showcases better performance when compared to the baseline method with static target probability over a range of agent to flow field velocity ratios. The second search scenario represents a realistic sea search and rescue mission where the search start is delayed, the search is performed in multiple robot flight missions, and the procedure for target drift uncertainty compensation is demonstrated. Furthermore, the proposed method provides an accurate survey completion metric, based on the known detection/sensing parameters, that correlates with the actual number of targets found independently.', 'abstract_zh': '动态环境中漂移目标搜索任务的挑战及其通过动态系统和潜在场调控的多自主搜索方法', 'title_zh': '动态分布的遍历探索'}
{'arxiv_id': 'arXiv:2503.11186', 'title': 'GAIPAT -Dataset on Human Gaze and Actions for Intent Prediction in Assembly Tasks', 'authors': 'Maxence Grand, Damien Pellier, Francis Jambon', 'link': 'https://arxiv.org/abs/2503.11186', 'abstract': 'The primary objective of the dataset is to provide a better understanding of the coupling between human actions and gaze in a shared working environment with a cobot, with the aim of signifcantly enhancing the effciency and safety of humancobot interactions. More broadly, by linking gaze patterns with physical actions, the dataset offers valuable insights into cognitive processes and attention dynamics in the context of assembly tasks. The proposed dataset contains gaze and action data from approximately 80 participants, recorded during simulated industrial assembly tasks. The tasks were simulated using controlled scenarios in which participants manipulated educational building blocks. Gaze data was collected using two different eye-tracking setups -head-mounted and remote-while participants worked in two positions: sitting and standing.', 'abstract_zh': '该数据集的主要目标是提供人类动作与协作机器人（cobot）工作环境中 gaze 耦合的更好理解，旨在显著提高人-协作机器人交互的效率和安全性。更广泛地说，通过将 gaze 模式与物理动作联系起来，数据集提供了有关装配任务背景下认知过程和注意动态的宝贵见解。所提出的数据集包含约 80 名参与者的 gaze 和动作数据，这些数据是在模拟工业装配任务期间记录的。任务使用受控场景进行模拟，参与者操作教育积木。 gaze 数据使用两种不同的眼球追踪设置（头戴式和远程）在参与者坐着和站着的两种姿势下进行收集。', 'title_zh': 'GAIPAT - 基于组装任务中人类凝视和动作的意图预测数据集'}
{'arxiv_id': 'arXiv:2503.11177', 'title': 'Hand Over or Place On The Table? A Study On Robotic Object Delivery When The Recipient Is Occupied', 'authors': 'Thieu Long Phan, Akansel Cosgun', 'link': 'https://arxiv.org/abs/2503.11177', 'abstract': 'This study investigates the subjective experiences of users in two robotic object delivery methods: direct handover and table placement, when users are occupied with another task. A user study involving 15 participants engaged in a typing game revealed that table placement significantly enhances user experience compared to direct handovers, particularly in terms of satisfaction, perceived safety and intuitiveness. Additionally, handovers negatively impacted typing performance, while all participants expressed a clear preference for table placement as the delivery method. These findings highlight the advantages of table placement in scenarios requiring minimal user disruption.', 'abstract_zh': '本研究调查了用户在执行另一任务时，使用两种机器人物体交付方法（桌面放置与直接交接）的主观体验。一项涉及15名参与者的打字游戏用户研究显示，与直接交接相比，桌面放置显著提高了用户体验，尤其是在满意度、感知安全性及直观性方面。此外，交接过程对打字性能产生了负面影响，所有参与者均明确表示更偏好桌面放置作为交付方法。这些发现强调了在需要 minimal 用户干扰的情境中，桌面放置的优势。', 'title_zh': '桌子上还是交给别人？当接受者忙的时候关于机器人物体交付的研究'}
{'arxiv_id': 'arXiv:2503.11163', 'title': 'A Benchmarking Study of Vision-based Robotic Grasping Algorithms', 'authors': 'Bharath K Rameshbabu, Sumukh S Balakrishna, Brian Flynn, Vinarak Kapoor, Adam Norton, Holly Yanco, Berk Calli', 'link': 'https://arxiv.org/abs/2503.11163', 'abstract': "We present a benchmarking study of vision-based robotic grasping algorithms with distinct approaches, and provide a comparative analysis. In particular, we compare two machine-learning-based and two analytical algorithms using an existing benchmarking protocol from the literature and determine the algorithm's strengths and weaknesses under different experimental conditions. These conditions include variations in lighting, background textures, cameras with different noise levels, and grippers. We also run analogous experiments in simulations and with real robots and present the discrepancies. Some experiments are also run in two different laboratories using same protocols to further analyze the repeatability of our results. We believe that this study, comprising 5040 experiments, provides important insights into the role and challenges of systematic experimentation in robotic manipulation, and guides the development of new algorithms by considering the factors that could impact the performance. The experiment recordings and our benchmarking software are publicly available.", 'abstract_zh': '基于视觉的机器人抓取算法基准研究及比较分析', 'title_zh': '基于视觉的机器人抓取算法基准研究'}
{'arxiv_id': 'arXiv:2503.11145', 'title': 'Leveraging Semantic Graphs for Efficient and Robust LiDAR SLAM', 'authors': 'Neng Wang, Huimin Lu, Zhiqiang Zheng, Hesheng Wang, Yun-Hui Liu, Xieyuanli Chen', 'link': 'https://arxiv.org/abs/2503.11145', 'abstract': 'Accurate and robust simultaneous localization and mapping (SLAM) is crucial for autonomous mobile systems, typically achieved by leveraging the geometric features of the environment. Incorporating semantics provides a richer scene representation that not only enhances localization accuracy in SLAM but also enables advanced cognitive functionalities for downstream navigation and planning tasks. Existing point-wise semantic LiDAR SLAM methods often suffer from poor efficiency and generalization, making them less robust in diverse real-world scenarios. In this paper, we propose a semantic graph-enhanced SLAM framework, named SG-SLAM, which effectively leverages the geometric, semantic, and topological characteristics inherent in environmental structures. The semantic graph serves as a fundamental component that facilitates critical functionalities of SLAM, including robust relocalization during odometry failures, accurate loop closing, and semantic graph map construction. Our method employs a dual-threaded architecture, with one thread dedicated to online odometry and relocalization, while the other handles loop closure, pose graph optimization, and map update. This design enables our method to operate in real time and generate globally consistent semantic graph maps and point cloud maps. We extensively evaluate our method across the KITTI, MulRAN, and Apollo datasets, and the results demonstrate its superiority compared to state-of-the-art methods. Our method has been released at this https URL.', 'abstract_zh': '准确且鲁棒的语义增强 simultaneous localization and mapping (SLAM) 对自主移动系统至关重要，通常通过利用环境的几何特征来实现。在SLAM中结合语义可以提供更丰富的场景表示，不仅提高了定位精度，还为下游的导航和规划任务提供了高级的认知功能。现有的基于点的语义LiDAR SLAM方法往往效率低下且泛化能力差，使其在多种真实场景中不够鲁棒。在本文中，我们提出了一种语义图增强的SLAM框架，名为SG-SLAM，该框架有效地利用了环境结构中固有的几何、语义和拓扑特征。语义图作为基本组件，支持SLAM的关键功能，包括里程计失败时的鲁棒重新定位、精确的环回闭合以及语义图地图构建。该方法采用双线程架构，一个线程用于在线里程计和重新定位，而另一个线程处理环回闭合、姿态图优化和地图更新。这种设计使得我们的方法能够实时运行，并生成全局一致的语义图地图和点云地图。我们在Kitti、MulRan和Apollo数据集上对我们的方法进行了广泛评估，结果表明其优于最先进的方法。我们的方法已发布在该网址：[这里提供网址]。', 'title_zh': '利用语义图实现高效稳健的LiDAR SLAM'}
{'arxiv_id': 'arXiv:2503.11124', 'title': 'Flow-Aware Navigation of Magnetic Micro-Robots in Complex Fluids via PINN-Based Prediction', 'authors': 'Yongyi Jia, Shu Miao, Jiayu Wu, Ming Yang, Chengzhi Hu, Xiang Li', 'link': 'https://arxiv.org/abs/2503.11124', 'abstract': "While magnetic micro-robots have demonstrated significant potential across various applications, including drug delivery and microsurgery, the open issue of precise navigation and control in complex fluid environments is crucial for in vivo implementation. This paper introduces a novel flow-aware navigation and control strategy for magnetic micro-robots that explicitly accounts for the impact of fluid flow on their movement. First, the proposed method employs a Physics-Informed U-Net (PI-UNet) to refine the numerically predicted fluid velocity using local observations. Then, the predicted velocity is incorporated in a flow-aware A* path planning algorithm, ensuring efficient navigation while mitigating flow-induced disturbances. Finally, a control scheme is developed to compensate for the predicted fluid velocity, thereby optimizing the micro-robot's performance. A series of simulation studies and real-world experiments are conducted to validate the efficacy of the proposed approach. This method enhances both planning accuracy and control precision, expanding the potential applications of magnetic micro-robots in fluid-affected environments typical of many medical scenarios.", 'abstract_zh': '具有流场感知的磁微机器人导航与控制策略', 'title_zh': '基于PINN预测的流感知复杂流体中磁微机器人导航'}
{'arxiv_id': 'arXiv:2503.11089', 'title': 'EmbodiedVSR: Dynamic Scene Graph-Guided Chain-of-Thought Reasoning for Visual Spatial Tasks', 'authors': 'Yi Zhang, Qiang Zhang, Xiaozhu Ju, Zhaoyang Liu, Jilei Mao, Jingkai Sun, Jintao Wu, Shixiong Gao, Shihan Cai, Zhiyuan Qin, Linkai Liang, Jiaxu Wang, Yiqun Duan, Jiahang Cao, Renjing Xu, Jian Tang', 'link': 'https://arxiv.org/abs/2503.11089', 'abstract': 'While multimodal large language models (MLLMs) have made groundbreaking progress in embodied intelligence, they still face significant challenges in spatial reasoning for complex long-horizon tasks. To address this gap, we propose EmbodiedVSR (Embodied Visual Spatial Reasoning), a novel framework that integrates dynamic scene graph-guided Chain-of-Thought (CoT) reasoning to enhance spatial understanding for embodied agents. By explicitly constructing structured knowledge representations through dynamic scene graphs, our method enables zero-shot spatial reasoning without task-specific fine-tuning. This approach not only disentangles intricate spatial relationships but also aligns reasoning steps with actionable environmental dynamics. To rigorously evaluate performance, we introduce the eSpatial-Benchmark, a comprehensive dataset including real-world embodied scenarios with fine-grained spatial annotations and adaptive task difficulty levels. Experiments demonstrate that our framework significantly outperforms existing MLLM-based methods in accuracy and reasoning coherence, particularly in long-horizon tasks requiring iterative environment interaction. The results reveal the untapped potential of MLLMs for embodied intelligence when equipped with structured, explainable reasoning mechanisms, paving the way for more reliable deployment in real-world spatial applications. The codes and datasets will be released soon.', 'abstract_zh': '尽管多模态大语言模型（MLLMs）在体现智能方面取得了突破性进展，但在复杂长期任务的空间推理方面仍面临重大挑战。为此，我们提出了一种新型框架EmbodiedVSR（体现的空间视觉推理），该框架通过动态场景图引导的推理链（CoT）增强体现智能代理的空间理解能力。通过显式构建结构化知识表示并通过动态场景图，我们的方法能够在无需特定任务微调的情况下实现零样本空间推理。该方法不仅分离了复杂的空间关系，还将推理步骤与可执行的环境动态对齐。为严格评估性能，我们引入了eSpatial-Benchmark数据集，该数据集包括具有精细空间注释和动态任务难度级别的现实世界体现场景。实验结果表明，我们的框架在准确性与推理连贯性方面显著优于现有的MLLM方法，特别是在需要反复环境交互的长期任务中。结果表明，当配备结构化可解释的推理机制时，MLLMs在体现智能方面具有未被充分利用的潜力，这为在现实世界的空间应用中更可靠地部署铺平了道路。代码和数据集将很快发布。', 'title_zh': '嵌入式VSR：动态场景图引导的链式思维推理方法用于视觉空间任务'}
{'arxiv_id': 'arXiv:2503.11083', 'title': 'GP-enhanced Autonomous Drifting Framework using ADMM-based iLQR', 'authors': 'Yangyang Xie, Cheng Hu, Nicolas Baumann, Edoardo Ghignone, Michele Magno, Lei Xie', 'link': 'https://arxiv.org/abs/2503.11083', 'abstract': "Autonomous drifting is a complex challenge due to the highly nonlinear dynamics and the need for precise real-time control, especially in uncertain environments. To address these limitations, this paper presents a hierarchical control framework for autonomous vehicles drifting along general paths, primarily focusing on addressing model inaccuracies and mitigating computational challenges in real-time control. The framework integrates Gaussian Process (GP) regression with an Alternating Direction Method of Multipliers (ADMM)-based iterative Linear Quadratic Regulator (iLQR). GP regression effectively compensates for model residuals, improving accuracy in dynamic conditions. ADMM-based iLQR not only combines the rapid trajectory optimization of iLQR but also utilizes ADMM's strength in decomposing the problem into simpler sub-problems. Simulation results demonstrate the effectiveness of the proposed framework, with significant improvements in both drift trajectory tracking and computational efficiency. Our approach resulted in a 38$\\%$ reduction in RMSE lateral error and achieved an average computation time that is 75$\\%$ lower than that of the Interior Point OPTimizer (IPOPT).", 'abstract_zh': '自主车辆沿一般路径自控漂移是一个由于高度非线性动力学和对精确实时控制的需求而变得复杂的挑战，特别是在不确定环境中。为应对这些限制，本文提出了一种分级控制框架，旨在解决模型不准确性和减轻实时控制中的计算挑战。该框架结合了高斯过程（GP）回归与基于交替方向乘子法（ADMM）的迭代线性二次调节器（iLQR）。GP回归有效地补偿了模型残差，提高了动态条件下的准确性。基于ADMM的iLQR不仅结合了iLQR快速轨迹优化的优势，还利用了ADMM在分解问题为更简单的子问题方面的长处。仿真结果表明，所提出的框架有效提高了漂移轨迹跟踪和计算效率，在均方根横向误差上减少了38%，平均计算时间比Interior Point OPTimizer（IPOPT）低75%。', 'title_zh': '基于ADMM-iLQR的GP增强自主漂移框架'}
{'arxiv_id': 'arXiv:2503.11081', 'title': 'MoMa-Kitchen: A 100K+ Benchmark for Affordance-Grounded Last-Mile Navigation in Mobile Manipulation', 'authors': 'Pingrui Zhang, Xianqiang Gao, Yuhan Wu, Kehui Liu, Dong Wang, Zhigang Wang, Bin Zhao, Yan Ding, Xuelong Li', 'link': 'https://arxiv.org/abs/2503.11081', 'abstract': 'In mobile manipulation, navigation and manipulation are often treated as separate problems, resulting in a significant gap between merely approaching an object and engaging with it effectively. Many navigation approaches primarily define success by proximity to the target, often overlooking the necessity for optimal positioning that facilitates subsequent manipulation. To address this, we introduce MoMa-Kitchen, a benchmark dataset comprising over 100k samples that provide training data for models to learn optimal final navigation positions for seamless transition to manipulation. Our dataset includes affordance-grounded floor labels collected from diverse kitchen environments, in which robotic mobile manipulators of different models attempt to grasp target objects amidst clutter. Using a fully automated pipeline, we simulate diverse real-world scenarios and generate affordance labels for optimal manipulation positions. Visual data are collected from RGB-D inputs captured by a first-person view camera mounted on the robotic arm, ensuring consistency in viewpoint during data collection. We also develop a lightweight baseline model, NavAff, for navigation affordance grounding that demonstrates promising performance on the MoMa-Kitchen benchmark. Our approach enables models to learn affordance-based final positioning that accommodates different arm types and platform heights, thereby paving the way for more robust and generalizable integration of navigation and manipulation in embodied AI. Project page: \\href{this https URL}{this https URL}.', 'abstract_zh': '在移动操控中，导航和操控通常被分别处理，导致仅仅靠近物体和有效互动之间存在显著差距。许多导航方法主要通过接近目标来定义成功，往往忽视了优化定位的必要性，这种优化定位有助于后续的操控。为解决这一问题，我们引入了MoMa-Kitchen基准数据集，包含超过100,000个样本，为模型提供训练数据以学习无缝过渡到操控的最佳最终导航位置。该数据集包括从各种厨房环境中收集的功能导向地面标签，其中不同型号的机器人移动操控器试图在杂乱环境中抓取目标物体。利用全自动管道，我们模拟了多种真实世界场景，并生成了最佳操控位置的功能标签。视图数据来自安装在机器人臂上的第一人称视角摄像头捕捉的RGB-D输入，确保数据收集过程中的视角一致性。我们还开发了一个轻量级基准模型NavAff，该模型在MoMa-Kitchen基准测试中表现出色，用于导航功能导向接地。我们提出的方法使模型能够学习基于功能的最终定位，以适应不同类型的臂和平台高度，从而为在体态AI中更 robust 和通用地整合导航和操控铺平道路。项目页面：\\href{this https URL}{this https URL}。', 'title_zh': 'MoMa-Kitchen：用于移动操作中基于能力的地 dernier 里程 导航的 100K+ 基准数据集'}
{'arxiv_id': 'arXiv:2503.11072', 'title': 'A High-Speed Time-Optimal Trajectory Generation Strategy via a Two-layer Planning Model', 'authors': 'Haotian Tan, Yuan-Hua Ni', 'link': 'https://arxiv.org/abs/2503.11072', 'abstract': "Motion planning and trajectory generation are crucial technologies in various domains including the control of Unmanned Aerial Vehicles (UAV), manipulators, and rockets. However, optimization-based real-time motion planning becomes increasingly challenging due to the problem's probable non-convexity and the inherent limitations of Non-Linear Programming algorithms. Highly nonlinear dynamics, obstacle avoidance constraints, and non-convex inputs can exacerbate these difficulties. To address these hurdles, this paper proposes a two-layer optimization algorithm for 2D vehicles by dynamically reformulating small time horizon convex programming subproblems, aiming to provide real-time guarantees for trajectory optimization. Our approach involves breaking down the original problem into small horizon-based planning cycles with fixed final times, referred to as planning cycles. Each planning cycle is then solved within a series of restricted convex sets identified by our customized search algorithms incrementally. The key benefits of our proposed algorithm include fast computation speeds and lower task time. We demonstrate these advantages through mathematical proofs under some moderate preconditions and experimental results.", 'abstract_zh': '基于优化的二维车辆实时轨迹优化两层算法：动态重构小时间窗凸规划子问题', 'title_zh': '一种基于两层规划模型的高速时间优化轨迹生成策略'}
{'arxiv_id': 'arXiv:2503.11059', 'title': 'Training Directional Locomotion for Quadrupedal Low-Cost Robotic Systems via Deep Reinforcement Learning', 'authors': 'Peter Böhm, Archie C. Chapman, Pauline Pounds', 'link': 'https://arxiv.org/abs/2503.11059', 'abstract': 'In this work we present Deep Reinforcement Learning (DRL) training of directional locomotion for low-cost quadrupedal robots in the real world. In particular, we exploit randomization of heading that the robot must follow to foster exploration of action-state transitions most useful for learning both forward locomotion as well as course adjustments. Changing the heading in episode resets to current yaw plus a random value drawn from a normal distribution yields policies able to follow complex trajectories involving frequent turns in both directions as well as long straight-line stretches. By repeatedly changing the heading, this method keeps the robot moving within the training platform and thus reduces human involvement and need for manual resets during the training. Real world experiments on a custom-built, low-cost quadruped demonstrate the efficacy of our method with the robot successfully navigating all validation tests. When trained with other approaches, the robot only succeeds in forward locomotion test and fails when turning is required.', 'abstract_zh': '本研究展示了在实际环境中，面向低成本四足机器人训练方向性行走的深度强化学习方法。通过随机化机器人必须遵循的方向来促进对最有助于学习前进建立和路径调整的动作-状态转换的探索。在每个episode重置时改变方向，采用当前航向加上从正态分布中随机抽取的值，使得政策能够跟随包含频繁双向转弯和长直线行驶的复杂轨迹。通过反复改变方向，这种方法使机器人在训练平台上持续移动，从而减少了人工干预和手动重置的需求。在定制的低成本四足机器人上进行的实际实验表明，该方法的有效性，机器人成功通过了所有验证测试。使用其他方法进行训练时，机器人仅能在前进建立测试中成功，而在转弯测试中失败。', 'title_zh': '基于深度强化学习的低成本四足机器人定向运动训练'}
{'arxiv_id': 'arXiv:2503.11057', 'title': 'Enhancing Regrasping Efficiency Using Prior Grasping Perceptions with Soft Fingertips', 'authors': 'Qiyin Huang, Ruomin Sui, Lunwei Zhang, Yenhang Zhou, Tiemin Li, Yao Jiang', 'link': 'https://arxiv.org/abs/2503.11057', 'abstract': 'Grasping the same object in different postures is often necessary, especially when handling tools or stacked items. Due to unknown object properties and changes in grasping posture, the required grasping force is uncertain and variable. Traditional methods rely on real-time feedback to control the grasping force cautiously, aiming to prevent slipping or damage. However, they overlook reusable information from the initial grasp, treating subsequent regrasping attempts as if they were the first, which significantly reduces efficiency. To improve this, we propose a method that utilizes perception from prior grasping attempts to predict the required grasping force, even with changes in position. We also introduce a calculation method that accounts for fingertip softness and object asymmetry. Theoretical analyses demonstrate the feasibility of predicting grasping forces across various postures after a single grasp. Experimental verifications attest to the accuracy and adaptability of our prediction method. Furthermore, results show that incorporating the predicted grasping force into feedback-based approaches significantly enhances grasping efficiency across a range of everyday objects.', 'abstract_zh': '抓取不同姿态的同一物体在处理工具或堆积物品时往往是必要的。由于物体属性未知和抓取姿态的变化，所需的抓取力不确定且会变化。传统方法依赖实时反馈谨慎控制抓取力，以防止滑落或损坏。然而，它们忽略了初始抓取的可重用信息，将后续重新抓取尝试视为第一次抓取，这显著降低了效率。为了改进这一问题，我们提出了一种方法，利用先前抓取尝试的感知预测所需的抓取力，即使在位置发生变化的情况下也是如此。我们还引入了一种考虑指尖柔软度和物体不对称性的计算方法。理论分析表明，在单次抓取后预测各种姿态下的抓取力是可行的。实验验证证实了我们预测方法的准确性和适应性。此外，结果表明，将预测的抓取力纳入基于反馈的方法中，可以显著提高各种日常物体抓取的效率。', 'title_zh': '基于先验抓取感知和软指尖提升重新抓取效率'}
{'arxiv_id': 'arXiv:2503.11049', 'title': 'Fish Mouth Inspired Origami Gripper for Robust Multi-Type Underwater Grasping', 'authors': 'Honghao Guo, Junda Huang, Ian Zhang, Boyuan Liang, Xin Ma, Yunhui Liu, Jianshu Zhou', 'link': 'https://arxiv.org/abs/2503.11049', 'abstract': 'Robotic grasping and manipulation in underwater environments present unique challenges for robotic hands traditionally used on land. These challenges stem from dynamic water conditions, a wide range of object properties from soft to stiff, irregular object shapes, and varying surface frictions. One common approach involves developing finger-based hands with embedded compliance using underactuation and soft actuators. This study introduces an effective alternative solution that does not rely on finger-based hand designs. We present a fish mouth inspired origami gripper that utilizes a single degree of freedom to perform a variety of robust grasping tasks underwater. The innovative structure transforms a simple uniaxial pulling motion into a grasping action based on the Yoshimura crease pattern folding. The origami gripper offers distinct advantages, including scalable and optimizable design, grasping compliance, and robustness, with four grasping types: pinch, power grasp, simultaneous grasping of multiple objects, and scooping from the seabed. In this work, we detail the design, modeling, fabrication, and validation of a specialized underwater gripper capable of handling various marine creatures, including jellyfish, crabs, and abalone. By leveraging an origami and bio-inspired approach, the presented gripper demonstrates promising potential for robotic grasping and manipulation in underwater environments.', 'abstract_zh': '水下环境中的机器人抓取与操作对传统陆地使用的机器人手提出了独特的挑战。这些挑战源于动态水环境、从柔软到刚性的广泛物体特性、不规则的物体形状以及变化的表面摩擦。一种常见方法是开发具有嵌入式顺应性的基于手指的手部，使用欠驱动和软致动器。本研究提出了一种有效替代方案，不依赖于基于手指的手部设计。我们提出了一种受鱼嘴启发的折纸 gripper，利用单自由度执行多种稳健的水下抓取任务。该创新结构将简单的单轴拉伸运动转化为基于吉森马折纸折叠模式的抓取动作。折纸 gripper 具有可扩展性和可优化设计、抓取顺应性和鲁棒性等优势，包括捏取、大力抓取、多物体同时抓取和海底抓取四种抓取类型。在本文中，我们详细介绍了设计、建模、制造和验证一种专门用于处理各种海洋生物（包括水母、螃蟹和鲍鱼）的水下 gripper。通过利用折纸和生物启发的方法，所提出的 gripper 展示了在水下环境中进行机器人抓取和操作的潜在应用前景。', 'title_zh': '鱼嘴启发式折纸式 Handbook 机器人爪具及其在多类型水下抓取中的应用'}
{'arxiv_id': 'arXiv:2503.11048', 'title': 'Distributed Multi-robot Source Seeking in Unknown Environments with Unknown Number of Sources', 'authors': 'Lingpeng Chen, Siva Kailas, Srujan Deolasee, Wenhao Luo, Katia Sycara, Woojun Kim', 'link': 'https://arxiv.org/abs/2503.11048', 'abstract': 'We introduce a novel distributed source seeking framework, DIAS, designed for multi-robot systems in scenarios where the number of sources is unknown and potentially exceeds the number of robots. Traditional robotic source seeking methods typically focused on directing each robot to a specific strong source and may fall short in comprehensively identifying all potential sources. DIAS addresses this gap by introducing a hybrid controller that identifies the presence of sources and then alternates between exploration for data gathering and exploitation for guiding robots to identified sources. It further enhances search efficiency by dividing the environment into Voronoi cells and approximating source density functions based on Gaussian process regression. Additionally, DIAS can be integrated with existing source seeking algorithms. We compare DIAS with existing algorithms, including DoSS and GMES in simulated gas leakage scenarios where the number of sources outnumbers or is equal to the number of robots. The numerical results show that DIAS outperforms the baseline methods in both the efficiency of source identification by the robots and the accuracy of the estimated environmental density function.', 'abstract_zh': '一种新的分布式源寻觅框架DIAS：适用于多机器人系统且源的数量未知可能超过机器人类别的情况', 'title_zh': '未知环境中未知源数量的分布式多机器人寻源技术'}
{'arxiv_id': 'arXiv:2503.11041', 'title': 'Enhancing Adaptivity of Two-Fingered Object Reorientation Using Tactile-based Online Optimization of Deconstructed Actions', 'authors': 'Qiyin Huang, Tiemin Li, Yao Jiang', 'link': 'https://arxiv.org/abs/2503.11041', 'abstract': 'Object reorientation is a critical task for robotic grippers, especially when manipulating objects within constrained environments. The task poses significant challenges for motion planning due to the high-dimensional output actions with the complex input information, including unknown object properties and nonlinear contact forces. Traditional approaches simplify the problem by reducing degrees of freedom, limiting contact forms, or acquiring environment/object information in advance, which significantly compromises adaptability. To address these challenges, we deconstruct the complex output actions into three fundamental types based on tactile sensing: task-oriented actions, constraint-oriented actions, and coordinating actions. These actions are then optimized online using gradient optimization to enhance adaptability. Key contributions include simplifying contact state perception, decomposing complex gripper actions, and enabling online action optimization for handling unknown objects or environmental constraints. Experimental results demonstrate that the proposed method is effective across a range of everyday objects, regardless of environmental contact. Additionally, the method exhibits robust performance even in the presence of unknown contacts and nonlinear external disturbances.', 'abstract_zh': '基于触觉感知的复杂输出动作分解与在线优化：面向物体重定向的适应性抓取方法', 'title_zh': '基于触觉在线优化分解动作的二指物体重定向适应性增强'}
{'arxiv_id': 'arXiv:2503.11020', 'title': 'Fast and Robust Localization for Humanoid Soccer Robot via Iterative Landmark Matching', 'authors': 'Ruochen Hou, Mingzhang Zhu, Hyunwoo Nam, Gabriel I. Fernandez, Dennis W. Hong', 'link': 'https://arxiv.org/abs/2503.11020', 'abstract': "Accurate robot localization is essential for effective operation. Monte Carlo Localization (MCL) is commonly used with known maps but is computationally expensive due to landmark matching for each particle. Humanoid robots face additional challenges, including sensor noise from locomotion vibrations and a limited field of view (FOV) due to camera placement. This paper proposes a fast and robust localization method via iterative landmark matching (ILM) for humanoid robots. The iterative matching process improves the accuracy of the landmark association so that it does not need MCL to match landmarks to particles. Pose estimation with the outlier removal process enhances its robustness to measurement noise and faulty detections. Furthermore, an additional filter can be utilized to fuse inertial data from the inertial measurement unit (IMU) and pose data from localization. We compared ILM with Iterative Closest Point (ICP), which shows that ILM method is more robust towards the error in the initial guess and easier to get a correct matching. We also compared ILM with the Augmented Monte Carlo Localization (aMCL), which shows that ILM method is much faster than aMCL and even more accurate. The proposed method's effectiveness is thoroughly evaluated through experiments and validated on the humanoid robot ARTEMIS during RoboCup 2024 adult-sized soccer competition.", 'abstract_zh': '精确的机器人定位对于有效操作至关重要。本文提出了一种迭代地标匹配（ILM）方法，以快速且稳健的方式为类人机器人进行定位。我们通过迭代匹配过程提高地标关联的准确性，使其无需使用Monte Carlo定位（MCL）即可进行地标与粒子的匹配。借助离群值去除过程进行的姿态估计增强了其对测量噪声和错误检测的鲁棒性。此外，该方法可以利用滤波器融合惯性测量单元（IMU）的惯性数据和定位姿态数据。我们将ILM与迭代最近点（ICP）方法进行了对比，结果显示ILM方法对初始猜测的误差更具鲁棒性且更容易获得正确的匹配。我们还将ILM与扩展Monte Carlo定位（aMCL）进行了对比，结果显示ILM方法不仅更快而且更准确。本方法的有效性通过实验进行了全面评估，并在2024年RoboCup成人组足球比赛中，在类人机器人ARTEMIS上进行了验证。', 'title_zh': '基于迭代地标匹配的快速稳健人体形机器人足球定位'}
{'arxiv_id': 'arXiv:2503.11012', 'title': 'Robotic Sim-to-Real Transfer for Long-Horizon Pick-and-Place Tasks in the Robotic Sim2Real Competition', 'authors': 'Ming Yang, Hongyu Cao, Lixuan Zhao, Chenrui Zhang, Yaran Chen', 'link': 'https://arxiv.org/abs/2503.11012', 'abstract': 'This paper presents a fully autonomous robotic system that performs sim-to-real transfer in complex long-horizon tasks involving navigation, recognition, grasping, and stacking in an environment with multiple obstacles.\nThe key feature of the system is the ability to overcome typical sensing and actuation discrepancies during sim-to-real transfer and to achieve consistent performance without any algorithmic modifications. To accomplish this, a lightweight noise-resistant visual perception system and a nonlinearity-robust servo system are adopted.\nWe conduct a series of tests in both simulated and real-world environments. The visual perception system achieves the speed of 11 ms per frame due to its lightweight nature, and the servo system achieves sub-centimeter accuracy with the proposed controller. Both exhibit high consistency during sim-to-real transfer. Benefiting from these, our robotic system took first place in the mineral searching task of the Robotic Sim2Real Challenge hosted at ICRA 2024.', 'abstract_zh': '一种在复杂长期任务中实现导航、识别、抓取和堆叠的全自主机器人系统：从模拟到现实的转移', 'title_zh': 'Robotic 模拟到现实的过渡：长期规划的取放任务'}
{'arxiv_id': 'arXiv:2503.11007', 'title': "From Abstraction to Reality: DARPA's Vision for Robust Sim-to-Real Autonomy", 'authors': 'Erfaun Noorani, Zachary Serlin, Ben Price, Alvaro Velasquez', 'link': 'https://arxiv.org/abs/2503.11007', 'abstract': "The DARPA Transfer from Imprecise and Abstract Models to Autonomous Technologies (TIAMAT) program aims to address rapid and robust transfer of autonomy technologies across dynamic and complex environments, goals, and platforms. Existing methods for simulation-to-reality (sim-to-real) transfer often rely on high-fidelity simulations and struggle with broad adaptation, particularly in time-sensitive scenarios. Although many approaches have shown incredible performance at specific tasks, most techniques fall short when posed with unforeseen, complex, and dynamic real-world scenarios due to the inherent limitations of simulation. In contrast to current research that aims to bridge the gap between simulation environments and the real world through increasingly sophisticated simulations and a combination of methods typically assuming a small sim-to-real gap -- such as domain randomization, domain adaptation, imitation learning, meta-learning, policy distillation, and dynamic optimization -- TIAMAT takes a different approach by instead emphasizing transfer and adaptation of the autonomy stack directly to real-world environments by utilizing a breadth of low(er)-fidelity simulations to create broadly effective sim-to-real transfers. By abstractly learning from multiple simulation environments in reference to their shared semantics, TIAMAT's approaches aim to achieve abstract-to-real transfer for effective and rapid real-world adaptation. Furthermore, this program endeavors to improve the overall autonomy pipeline by addressing the inherent challenges in translating simulated behaviors into effective real-world performance.", 'abstract_zh': 'DARPA从不精确和抽象模型到自主技术的快速稳健转移（TIAMAT）计划', 'title_zh': '从抽象到现实：DARPA关于稳健的仿真到现实自主性的愿景'}
{'arxiv_id': 'arXiv:2503.11000', 'title': 'Optimal Design of Continuum Robots with Reachability Constraints', 'authors': 'Hyunmin Cheong, Mehran Ebrahimi, Timothy Duggan', 'link': 'https://arxiv.org/abs/2503.11000', 'abstract': 'While multi-joint continuum robots are highly dexterous and flexible, designing an optimal robot can be challenging due to its kinematics involving curvatures. Hence, the current work presents a computational method developed to find optimal designs of continuum robots given reachability constraints. First, we leverage both forward and inverse kinematic computations to perform reachability analysis in an efficient yet accurate manner. While implementing inverse kinematics, we also integrate torque minimization at joints such that robot configurations with the minimum actuator torque required to reach a given workspace could be found. Lastly, we apply an estimation of distribution algorithm (EDA) to find optimal robot dimensions while considering reachability, where the objective function could be the total length of the robot or the actuator torque required to operate the robot. Through three application problems, we show that the EDA is superior to a genetic algorithm (GA) in finding better solutions within a given number of iterations, as the objective values of the best solutions found by the EDA are 4-15\\% lower than those found by the GA.', 'abstract_zh': '虽然连续关节连续机器人具有高度的灵巧性和灵活性，但由于其涉及曲率的运动学复杂性，对其进行最优设计可能具有挑战性。因此，本文提出了一种计算方法，旨在在可达性约束下寻找连续机器人的最优设计。首先，我们利用正向和逆向运动学计算高效且精确地进行可达性分析。在实现逆向运动学时，我们还整合了减小关节扭矩的计算，以便找到所需最小驱动器扭矩即可达给定工作空间的机器人构型。最后，我们应用估计分布算法（EDA）在考虑可达性的条件下寻找最优的机器人尺寸，目标函数可以是机器人的总长度或操作机器人所需的驱动器扭矩。通过三个应用问题，我们表明，在给定的迭代次数内，EDA在找到更好的解决方案方面优于遗传算法（GA），因为EDA找到的最佳解的目标值比GA低4-15%。', 'title_zh': '具有可达性约束的连续机器人最优设计'}
{'arxiv_id': 'arXiv:2503.10986', 'title': 'Image-Goal Navigation Using Refined Feature Guidance and Scene Graph Enhancement', 'authors': 'Zhicheng Feng, Xieyuanli Chen, Chenghao Shi, Lun Luo, Zhichao Chen, Yun-Hui Liu, Huimin Lu', 'link': 'https://arxiv.org/abs/2503.10986', 'abstract': 'In this paper, we introduce a novel image-goal navigation approach, named RFSG. Our focus lies in leveraging the fine-grained connections between goals, observations, and the environment within limited image data, all the while keeping the navigation architecture simple and lightweight. To this end, we propose the spatial-channel attention mechanism, enabling the network to learn the importance of multi-dimensional features to fuse the goal and observation features. In addition, a selfdistillation mechanism is incorporated to further enhance the feature representation capabilities. Given that the navigation task needs surrounding environmental information for more efficient navigation, we propose an image scene graph to establish feature associations at both the image and object levels, effectively encoding the surrounding scene information. Crossscene performance validation was conducted on the Gibson and HM3D datasets, and the proposed method achieved stateof-the-art results among mainstream methods, with a speed of up to 53.5 frames per second on an RTX3080. This contributes to the realization of end-to-end image-goal navigation in realworld scenarios. The implementation and model of our method have been released at: this https URL.', 'abstract_zh': '一种基于空间-通道注意力机制的新型图像目标导航方法RFSG及其应用', 'title_zh': '基于精炼特征引导和场景图增强的图像目标导航'}
{'arxiv_id': 'arXiv:2503.10966', 'title': 'Is Your Imitation Learning Policy Better than Mine? Policy Comparison with Near-Optimal Stopping', 'authors': 'David Snyder, Asher James Hancock, Apurva Badithela, Emma Dixon, Patrick Miller, Rares Andrei Ambrus, Anirudha Majumdar, Masha Itkina, Haruki Nishimura', 'link': 'https://arxiv.org/abs/2503.10966', 'abstract': 'Imitation learning has enabled robots to perform complex, long-horizon tasks in challenging dexterous manipulation settings. As new methods are developed, they must be rigorously evaluated and compared against corresponding baselines through repeated evaluation trials. However, policy comparison is fundamentally constrained by a small feasible sample size (e.g., 10 or 50) due to significant human effort and limited inference throughput of policies. This paper proposes a novel statistical framework for rigorously comparing two policies in the small sample size regime. Prior work in statistical policy comparison relies on batch testing, which requires a fixed, pre-determined number of trials and lacks flexibility in adapting the sample size to the observed evaluation data. Furthermore, extending the test with additional trials risks inducing inadvertent p-hacking, undermining statistical assurances. In contrast, our proposed statistical test is sequential, allowing researchers to decide whether or not to run more trials based on intermediate results. This adaptively tailors the number of trials to the difficulty of the underlying comparison, saving significant time and effort without sacrificing probabilistic correctness. Extensive numerical simulation and real-world robot manipulation experiments show that our test achieves near-optimal stopping, letting researchers stop evaluation and make a decision in a near-minimal number of trials. Specifically, it reduces the number of evaluation trials by up to 40% as compared to state-of-the-art baselines, while preserving the probabilistic correctness and statistical power of the comparison. Moreover, our method is strongest in the most challenging comparison instances (requiring the most evaluation trials); in a multi-task comparison scenario, we save the evaluator more than 200 simulation rollouts.', 'abstract_zh': '模仿学习使机器人能够在挑战性的灵巧操作环境中执行复杂的长期任务。随着新方法的开发，它们必须通过重复的评估试验严格评估并与其相应的基线进行对比。然而，由于显著的人工努力和策略推理吞吐量的限制，策略对比本质上受到小样本量（例如10或50）的约束。本文提出了一种新的统计框架，用于严格比较小样本量条件下两个策略。先前的统计策略对比工作依赖于批量测试，需要固定且预先确定的试验次数，并缺乏根据评估数据调整样本大小的灵活性。此外，附加试验可能会无意中诱导p-黑客行为，削弱统计保证。相比之下，我们提出的方法是顺序的，允许研究者根据中间结果决定是否运行更多试验。这种方法根据基础比较的难度灵活调整试验次数，在不牺牲概率正确性的前提下节省了大量时间和努力。广泛的数据模拟和实际机器人操作实验表明，我们的方法能够实现接近最优停止，使研究者能够在最少的试验次数内停止评估并做出决策。具体而言，与最先进的基线相比，评估试验次数减少了最多40%，同时保持了比较的统计功效与概率正确性。此外，我们的方法在最具挑战性的比较实例中表现最强（需要最多的评估试验次数）；在多任务比较场景中，我们为评估者节省了超过200个模拟迭代。', 'title_zh': '你的模仿学习策略比我的好？基于近最优停止的策略比较'}
{'arxiv_id': 'arXiv:2503.10949', 'title': 'Safe Continual Domain Adaptation after Sim2Real Transfer of Reinforcement Learning Policies in Robotics', 'authors': 'Josip Josifovski, Shangding Gu, Mohammadhossein Malmir, Haoliang Huang, Sayantan Auddy, Nicolás Navarro-Guerrero, Costas Spanos, Alois Knoll', 'link': 'https://arxiv.org/abs/2503.10949', 'abstract': 'Domain randomization has emerged as a fundamental technique in reinforcement learning (RL) to facilitate the transfer of policies from simulation to real-world robotic applications. Many existing domain randomization approaches have been proposed to improve robustness and sim2real transfer. These approaches rely on wide randomization ranges to compensate for the unknown actual system parameters, leading to robust but inefficient real-world policies. In addition, the policies pretrained in the domain-randomized simulation are fixed after deployment due to the inherent instability of the optimization processes based on RL and the necessity of sampling exploitative but potentially unsafe actions on the real system. This limits the adaptability of the deployed policy to the inevitably changing system parameters or environment dynamics over time. We leverage safe RL and continual learning under domain-randomized simulation to address these limitations and enable safe deployment-time policy adaptation in real-world robot control. The experiments show that our method enables the policy to adapt and fit to the current domain distribution and environment dynamics of the real system while minimizing safety risks and avoiding issues like catastrophic forgetting of the general policy found in randomized simulation during the pretraining phase. Videos and supplementary material are available at this https URL.', 'abstract_zh': '域随机化已成为强化学习（RL）中从仿真向实际机器人应用迁移策略的基本技术。许多现有的域随机化方法已被提出以提高鲁棒性和仿2实物迁移。这些方法依赖于广泛的随机化范围来补偿未知的实际系统参数，导致了鲁棒但效率低下的实际政策。此外，由于基于RL的优化过程的固有不稳定性以及需要在实际系统中采样有利但可能不安全的动作，预训练在随机化仿真中的策略在部署后固定。这限制了部署策略对随时间变化的系统参数或环境动态的适应性。我们利用域随机化仿真中的安全RL和持续学习来解决这些限制，并在实际机器人控制中实现部署时的安全策略适应。实验结果表明，我们的方法能够在最小化安全风险的同时使策略适应实际系统的当前分布和环境动态，并避免了在预训练阶段随机化仿真中普遍发现的一般策略灾难性遗忘的问题。相关视频和补充材料请参见此链接。', 'title_zh': '机器人领域适应中的安全持续Sim2Real转移强化学习策略的研究'}
{'arxiv_id': 'arXiv:2503.10928', 'title': 'Design and Development of the MeCO Open-Source Autonomous Underwater Vehicle', 'authors': 'David Widhalm, Cory Ohnsted, Corey Knutson, Demetrious Kutzke, Sakshi Singh, Rishi Mukherjee, Grant Schwidder, Ying-Kun Wu, Junaed Sattar', 'link': 'https://arxiv.org/abs/2503.10928', 'abstract': 'We present MeCO, the Medium Cost Open-source autonomous underwater vehicle (AUV), a versatile autonomous vehicle designed to support research and development in underwater human-robot interaction (UHRI) and marine robotics in general. An inexpensive platform to build compared to similarly-capable AUVs, the MeCO design and software are released under open-source licenses, making it a cost effective, extensible, and open platform. It is equipped with UHRI-focused systems, such as front and side facing displays, light-based communication devices, a transducer for acoustic interaction, and stereo vision, in addition to typical AUV sensing and actuation components. Additionally, MeCO is capable of real-time deep learning inference using the latest edge computing devices, while maintaining low-latency, closed-loop control through high-performance microcontrollers. MeCO is designed from the ground up for modularity in internal electronics, external payloads, and software architecture, exploiting open-source robotics and containerarization tools. We demonstrate the diverse capabilities of MeCO through simulated, closed-water, and open-water experiments. All resources necessary to build and run MeCO, including software and hardware design, have been made publicly available.', 'abstract_zh': 'MeCO：一种中等成本开源自主水下机器人，用于支持水下人机交互和海洋机器人技术的发展', 'title_zh': '开源自主水下车辆MeCO的设计与开发'}
{'arxiv_id': 'arXiv:2503.10919', 'title': 'Data-Driven Soft Robot Control via Adiabatic Spectral Submanifolds', 'authors': 'Roshan S. Kaundinya, John Irvin Alora, Jonas G. Matt, Luis A. Pabon, Marco Pavone, George Haller', 'link': 'https://arxiv.org/abs/2503.10919', 'abstract': 'The mechanical complexity of soft robots creates significant challenges for their model-based control. Specifically, linear data-driven models have struggled to control soft robots on complex, spatially extended paths that explore regions with significant nonlinear behavior. To account for these nonlinearities, we develop here a model-predictive control strategy based on the recent theory of adiabatic spectral submanifolds (aSSMs). This theory is applicable because the internal vibrations of heavily overdamped robots decay at a speed that is much faster than the desired speed of the robot along its intended path. In that case, low-dimensional attracting invariant manifolds (aSSMs) emanate from the path and carry the dominant dynamics of the robot. Aided by this recent theory, we devise an aSSM-based model-predictive control scheme purely from data. We demonstrate the effectiveness of this data-driven model on various dynamic trajectory tracking tasks on a high-fidelity and high-dimensional finite-element model of a soft trunk robot. Notably, we find that four- or five-dimensional aSSM-reduced models outperform the tracking performance of other data-driven modeling methods by a factor up to 10 across all closed-loop control tasks.', 'abstract_zh': '软体机器人的机械复杂性为其基于模型的控制带来了显著挑战。具体而言，线性数据驱动模型难以控制沿着复杂、空间扩展路径并探索具有显著非线性行为区域的软体机器人。为应对这些非线性，我们在此基于最近的渐近谱子流形理论（aSSMs）发展了一种模型预测控制策略。由于严重过阻尼机器人内部振动的衰减速度远快于机器人沿预期路径的期望速度，该理论适用。在该情况下，低维吸引不变子流形（aSSMs）从路径出发并承载机器人的主导动力学。借助这一最新理论，我们纯粹从数据出发设计了一种基于aSSM的模型预测控制方案。我们通过在高保真度和高维有限元模型的软体躯干机器人上进行各种动态轨迹跟踪任务，证明了这种数据驱动模型的有效性。值得注意的是，我们发现四维或五维aSSM减少模型在所有闭环控制任务中的跟踪性能比其他数据驱动建模方法高出高达10倍。', 'title_zh': '数据驱动的软机器人控制通过准静态谱子流形'}
{'arxiv_id': 'arXiv:2503.10904', 'title': 'Transferring Kinesthetic Demonstrations across Diverse Objects for Manipulation Planning', 'authors': 'Dibyendu Das, Aditya Patankar, Nilanjan Chakraborty, C. R. Ramakrishnan, I.V. Ramakrishnan', 'link': 'https://arxiv.org/abs/2503.10904', 'abstract': 'Given a demonstration of a complex manipulation task such as pouring liquid from one container to another, we seek to generate a motion plan for a new task instance involving objects with different geometries. This is non-trivial since we need to simultaneously ensure that the implicit motion constraints are satisfied (glass held upright while moving), the motion is collision-free, and that the task is successful (e.g. liquid is poured into the target container). We solve this problem by identifying positions of critical locations and associating a reference frame (called motion transfer frames) on the manipulated object and the target, selected based on their geometries and the task at hand. By tracking and transferring the path of the motion transfer frames, we generate motion plans for arbitrary task instances with objects of different geometries and poses. We show results from simulation as well as robot experiments on physical objects to evaluate the effectiveness of our solution.', 'abstract_zh': '给定一个复杂的操作任务演示，例如将液体从一个容器倒入另一个容器，我们需要生成一个涉及不同几何形状物体的新任务实例的操作计划。这具有挑战性，因为我们需要同时确保隐式运动约束得到满足（例如，在移动过程中玻璃器皿保持竖直），确保运动无碰撞，并且任务成功（例如，液体被倒入目标容器）。我们通过识别关键位置并为操作对象和目标选择基于其几何形状和任务的参考框架（称为运动传输框架）来解决这个问题。通过跟踪和传输运动传输框架的路径，我们可以为不同几何形状和姿态的物体生成任意任务实例的操作计划。我们通过仿真结果和物理对象的机器人实验展示了我们的解决方案的有效性。', 'title_zh': '在多样化对象上转移运动感知演示以进行操作规划'}
{'arxiv_id': 'arXiv:2503.10884', 'title': 'Fusion of Indirect Methods and Iterative Learning for Persistent Velocity Trajectory Optimization of a Sustainably Powered Autonomous Surface Vessel', 'authors': 'Kavin M. Govindarajan, Devansh R Agrawal, Dimitra Panagou, Chris Vermillion', 'link': 'https://arxiv.org/abs/2503.10884', 'abstract': 'In this paper, we present the methodology and results for a real-time velocity trajectory optimization for a solar-powered autonomous surface vessel (ASV), where we combine indirect optimal control techniques with iterative learning. The ASV exhibits cyclic operation due to the nature of the solar profile, but weather patterns create inevitable disturbances in this profile. The nature of the problem results in a formulation where the satisfaction of pointwise-in-time state of charge constraints does not generally guarantee persistent feasibility, and the goal is to maximize information gathered over a very long (ultimately persistent) time duration. To address these challenges, we first use barrier functions to tighten pointwise-in-time state of charge constraints by the minimal amount necessary to achieve persistent feasibility. We then use indirect methods to derive a simple switching control law, where the optimal velocity is shown to be an undetermined constant value during each constraint-inactive time segment. To identify this optimal constant velocity (which can vary from one segment to the next), we employ an iterative learning approach. The result is a simple closed-form control law that does not require a solar forecast. We present simulation-based validation results, based on a model of the SeaTrac SP-48 ASV and solar data from the North Carolina coast. These simulation results show that the proposed methodology, which amounts to a closed-form controller and simple iterative learning update law, performs nearly as well as a model predictive control approach that requires an accurate future solar forecast and significantly greater computational capability.', 'abstract_zh': '基于间接最优控制与时域迭代学习的太阳能动力自主水面舰艇实时速度轨迹优化方法与结果', 'title_zh': '间接方法与迭代学习融合的持续动力自主水面船舶持久速度轨迹优化'}
{'arxiv_id': 'arXiv:2503.10853', 'title': 'Rapidly Converging Time-Discounted Ergodicity on Graphs for Active Inspection of Confined Spaces', 'authors': 'Benjamin Wong, Ryan H. Lee, Tyler M. Paine, Santosh Devasia, Ashis G. Banerjee', 'link': 'https://arxiv.org/abs/2503.10853', 'abstract': 'Ergodic exploration has spawned a lot of interest in mobile robotics due to its ability to design time trajectories that match desired spatial coverage statistics. However, current ergodic approaches are for continuous spaces, which require detailed sensory information at each point and can lead to fractal-like trajectories that cannot be tracked easily. This paper presents a new ergodic approach for graph-based discretization of continuous spaces. It also introduces a new time-discounted ergodicity metric, wherein early visitations of information-rich nodes are weighted more than late visitations. A Markov chain synthesized using a convex program is shown to converge more rapidly to time-discounted ergodicity than the traditional fastest mixing Markov chain. The resultant ergodic traversal method is used within a hierarchical framework for active inspection of confined spaces with the goal of detecting anomalies robustly using SLAM-driven Bayesian hypothesis testing. Both simulation and physical experiments on a ground robot show the advantages of this framework over greedy and random exploration methods for left-behind foreign object debris detection in a ballast tank.', 'abstract_zh': '基于图的连续空间离散化的新遍历方法及时间折扣遍历性度量在受限空间中的主动检测应用', 'title_zh': '图上快速收敛时间折现遍历性在受限空间主动检测中的应用'}
{'arxiv_id': 'arXiv:2503.10843', 'title': 'Communication-Aware Iterative Map Compression for Online Path-Planning', 'authors': 'Evangelos Psomiadis, Ali Reza Pedram, Dipankar Maity, Panagiotis Tsiotras', 'link': 'https://arxiv.org/abs/2503.10843', 'abstract': 'This paper addresses the problem of optimizing communicated information among heterogeneous, resource-aware robot teams to facilitate their navigation. In such operations, a mobile robot compresses its local map to assist another robot in reaching a target within an uncharted environment. The primary challenge lies in ensuring that the map compression step balances network load while transmitting only the most essential information for effective navigation. We propose a communication framework that sequentially selects the optimal map compression in a task-driven, communication-aware manner. It introduces a decoder capable of iterative map estimation, handling noise through Kalman filter techniques. The computational speed of our decoder allows for a larger compression template set compared to previous methods, and enables applications in more challenging environments. Specifically, our simulations demonstrate a remarkable 98% reduction in communicated information, compared to a framework that transmits the raw data, on a large Mars inclination map and an Earth map, all while maintaining similar planning costs. Furthermore, our method significantly reduces computational time compared to the state-of-the-art approach.', 'abstract_zh': '这篇论文探讨了在异构、资源感知机器人团队中优化传递信息的问题，以促进其导航。在此类操作中，移动机器人将其局部地图压缩以帮助另一机器人在未勘探环境中到达目标。主要挑战在于确保地图压缩步骤在传输对于有效导航至关重要的信息时能够平衡网络负载。我们提出了一种通信框架，该框架在任务驱动和通信感知的方式下顺序选择最优的地图压缩。该框架引入了一个解码器，能够通过卡尔曼滤波技术处理噪声，并进行迭代的地图估计。我们的解码器的计算速度允许使用比先前方法更大的压缩模板集，从而适用于更具挑战性的环境。具体来说，我们的仿真结果显示，在一个大型火星倾斜地图和一个地球地图上，与传输原始数据的框架相比，通信信息减少了98%，同时保持了类似的规划成本。此外，与当前最先进的方法相比，我们的方法显著减少了计算时间。', 'title_zh': '通信感知迭代地图压缩以实现在线路径规划'}
{'arxiv_id': 'arXiv:2503.10743', 'title': 'Spatial-Temporal Graph Diffusion Policy with Kinematic Modeling for Bimanual Robotic Manipulation', 'authors': 'Qi Lv, Hao Li, Xiang Deng, Rui Shao, Yinchuan Li, Jianye Hao, Longxiang Gao, Michael Yu Wang, Liqiang Nie', 'link': 'https://arxiv.org/abs/2503.10743', 'abstract': 'Despite the significant success of imitation learning in robotic manipulation, its application to bimanual tasks remains highly challenging. Existing approaches mainly learn a policy to predict a distant next-best end-effector pose (NBP) and then compute the corresponding joint rotation angles for motion using inverse kinematics. However, they suffer from two important issues: (1) rarely considering the physical robotic structure, which may cause self-collisions or interferences, and (2) overlooking the kinematics constraint, which may result in the predicted poses not conforming to the actual limitations of the robot joints. In this paper, we propose Kinematics enhanced Spatial-TemporAl gRaph Diffuser (KStar Diffuser). Specifically, (1) to incorporate the physical robot structure information into action prediction, KStar Diffuser maintains a dynamic spatial-temporal graph according to the physical bimanual joint motions at continuous timesteps. This dynamic graph serves as the robot-structure condition for denoising the actions; (2) to make the NBP learning objective consistent with kinematics, we introduce the differentiable kinematics to provide the reference for optimizing KStar Diffuser. This module regularizes the policy to predict more reliable and kinematics-aware next end-effector poses. Experimental results show that our method effectively leverages the physical structural information and generates kinematics-aware actions in both simulation and real-world', 'abstract_zh': 'Kinematics增强的空间-时间图扩散器(KStar扩散器)在双臂任务中的应用', 'title_zh': '基于时空图扩散策略与运动学建模的双臂机器人操作'}
{'arxiv_id': 'arXiv:2503.11565', 'title': 'Disentangled Object-Centric Image Representation for Robotic Manipulation', 'authors': 'David Emukpere, Romain Deffayet, Bingbing Wu, Romain Brégier, Michael Niemaz, Jean-Luc Meunier, Denys Proux, Jean-Michel Renders, Seungsu Kim', 'link': 'https://arxiv.org/abs/2503.11565', 'abstract': 'Learning robotic manipulation skills from vision is a promising approach for developing robotics applications that can generalize broadly to real-world scenarios. As such, many approaches to enable this vision have been explored with fruitful results. Particularly, object-centric representation methods have been shown to provide better inductive biases for skill learning, leading to improved performance and generalization. Nonetheless, we show that object-centric methods can struggle to learn simple manipulation skills in multi-object environments. Thus, we propose DOCIR, an object-centric framework that introduces a disentangled representation for objects of interest, obstacles, and robot embodiment. We show that this approach leads to state-of-the-art performance for learning pick and place skills from visual inputs in multi-object environments and generalizes at test time to changing objects of interest and distractors in the scene. Furthermore, we show its efficacy both in simulation and zero-shot transfer to the real world.', 'abstract_zh': '从视觉学习机器人 manipulation 技能是开发能够在多种现实场景中泛化的机器人应用的一种有前景的方法。因此，许多促进这一目标的方法已被探索并取得了丰硕的成果。特别是以对象为中心的表示方法已被证明能够为技能学习提供更好的归纳偏置，从而提高性能和泛化能力。然而，我们发现以对象为中心的方法在多对象环境中学习简单的 manipulation 技能可能存在困难。因此，我们提出了一种以对象为中心的 DOCIR 框架，该框架引入了对象、障碍物和机器人主体的解耦表示。实验表明，该方法在多对象环境中从视觉输入学习 pick and place 技能方面达到了最先进的性能，并且在测试时能够泛化到场景中变化的对象和干扰物。此外，我们在仿真和零样本到真实世界的转移中展示了其有效性。', 'title_zh': '去耦对象中心图像表示在机器人操作中的应用'}
{'arxiv_id': 'arXiv:2503.11488', 'title': 'Unicorn: A Universal and Collaborative Reinforcement Learning Approach Towards Generalizable Network-Wide Traffic Signal Control', 'authors': 'Yifeng Zhang, Yilin Liu, Ping Gong, Peizhuo Li, Mingfeng Fan, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2503.11488', 'abstract': "Adaptive traffic signal control (ATSC) is crucial in reducing congestion, maximizing throughput, and improving mobility in rapidly growing urban areas. Recent advancements in parameter-sharing multi-agent reinforcement learning (MARL) have greatly enhanced the scalable and adaptive optimization of complex, dynamic flows in large-scale homogeneous networks. However, the inherent heterogeneity of real-world traffic networks, with their varied intersection topologies and interaction dynamics, poses substantial challenges to achieving scalable and effective ATSC across different traffic scenarios. To address these challenges, we present Unicorn, a universal and collaborative MARL framework designed for efficient and adaptable network-wide ATSC. Specifically, we first propose a unified approach to map the states and actions of intersections with varying topologies into a common structure based on traffic movements. Next, we design a Universal Traffic Representation (UTR) module with a decoder-only network for general feature extraction, enhancing the model's adaptability to diverse traffic scenarios. Additionally, we incorporate an Intersection Specifics Representation (ISR) module, designed to identify key latent vectors that represent the unique intersection's topology and traffic dynamics through variational inference techniques. To further refine these latent representations, we employ a contrastive learning approach in a self-supervised manner, which enables better differentiation of intersection-specific features. Moreover, we integrate the state-action dependencies of neighboring agents into policy optimization, which effectively captures dynamic agent interactions and facilitates efficient regional collaboration. Our results show that Unicorn outperforms other methods across various evaluation metrics, highlighting its potential in complex, dynamic traffic networks.", 'abstract_zh': '自适应交通信号控制（ATSC）对于减轻拥堵、最大化 throughput 并改善快速发展的城市区域的流动性至关重要。参数共享多智能体强化学习（MARL）的最新进展极大地增强了大型同质网络中复杂动态流的可扩展和自适应优化。然而，现实世界交通网络中存在的固有异质性，包括不同的交叉口拓扑结构和交互动力学，对在不同交通情景中实现可扩展且有效的ATSC提出了重大挑战。为应对这些挑战，我们提出了Unicorn，一种为高效且适应性强的网络级ATSC设计的通用协作MARL框架。具体来说，我们首先提出了一种统一的方法，将不同拓扑交叉口的状态和动作映射到基于交通流动的共同结构。其次，我们设计了一个通用交通表示（UTR）模块，使用仅解码器网络进行通用特征提取，增强了模型对不同交通情景的适应性。此外，我们结合了一个交叉口特定表示（ISR）模块，通过变分推断技术识别代表独特交叉口拓扑结构和交通动力学的关键潜在向量。为了进一步细化这些潜在表示，我们采用了一种自监督的对比学习方法，这使交叉口特定特征之间的更好区分成为可能。此外，我们将相邻智能体的状态-动作依赖性纳入策略优化中，这有效地捕捉到了动态智能体交互，并促进了高效的区域协作。我们的结果表明，Unicorn在各种评估指标上优于其他方法，突显了其在复杂动态交通网络中的潜力。', 'title_zh': '独角兽：面向可泛化的网络级交通信号控制的通用协作强化学习方法'}
{'arxiv_id': 'arXiv:2503.11423', 'title': 'TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation', 'authors': 'Hongxiang Zhao, Xingchen Liu, Mutian Xu, Yiming Hao, Weikai Chen, Xiaoguang Han', 'link': 'https://arxiv.org/abs/2503.11423', 'abstract': 'We address key limitations in existing datasets and models for task-oriented hand-object interaction video generation, a critical approach of generating video demonstrations for robotic imitation learning. Current datasets, such as Ego4D, often suffer from inconsistent view perspectives and misaligned interactions, leading to reduced video quality and limiting their applicability for precise imitation learning tasks. Towards this end, we introduce TASTE-Rob -- a pioneering large-scale dataset of 100,856 ego-centric hand-object interaction videos. Each video is meticulously aligned with language instructions and recorded from a consistent camera viewpoint to ensure interaction clarity. By fine-tuning a Video Diffusion Model (VDM) on TASTE-Rob, we achieve realistic object interactions, though we observed occasional inconsistencies in hand grasping postures. To enhance realism, we introduce a three-stage pose-refinement pipeline that improves hand posture accuracy in generated videos. Our curated dataset, coupled with the specialized pose-refinement framework, provides notable performance gains in generating high-quality, task-oriented hand-object interaction videos, resulting in achieving superior generalizable robotic manipulation. The TASTE-Rob dataset will be made publicly available upon publication to foster further advancements in the field.', 'abstract_zh': '我们解决现有面向任务的手物交互视频生成数据集和模型的关键限制，这是用于机器人模仿学习的视频演示生成关键方法的一个重要方面。当前的数据集，如Ego4D，通常存在视角不一致和交互不匹配的问题，这降低了视频质量，并限制了其在精确模仿学习任务中的应用。为此，我们引入TASTE-Rob——一个包含100,856个自我中心手物交互视频的开创性大规模数据集。每个视频都与语言指令精确对齐，并从一致的摄像机视角录制，以确保交互清晰度。通过在TASTE-Rob上微调视频扩散模型（VDM），我们实现了现实的手物交互，虽然观察到手部抓握姿态偶尔存在不一致性。为了增强现实感，我们引入了一个三阶段姿态精炼管道，提高了生成视频中手部姿态的准确性。我们精心策划的数据集与专门的姿态精炼框架相结合，在生成高质量、面向任务的手物交互视频方面取得了显著性能提升，从而实现了更可泛化的机器人操作。TASTE-Rob数据集将在发表后公开，以促进该领域的进一步发展。', 'title_zh': 'TASTE-Rob：推进面向任务的手物交互视频生成以提高通用化机器人操作能力'}
{'arxiv_id': 'arXiv:2503.11409', 'title': 'LuSeg: Efficient Negative and Positive Obstacles Segmentation via Contrast-Driven Multi-Modal Feature Fusion on the Lunar', 'authors': 'Shuaifeng Jiao, Zhiwen Zeng, Zhuoqun Su, Xieyuanli Chen, Zongtan Zhou, Huimin Lu', 'link': 'https://arxiv.org/abs/2503.11409', 'abstract': 'As lunar exploration missions grow increasingly complex, ensuring safe and autonomous rover-based surface exploration has become one of the key challenges in lunar exploration tasks. In this work, we have developed a lunar surface simulation system called the Lunar Exploration Simulator System (LESS) and the LunarSeg dataset, which provides RGB-D data for lunar obstacle segmentation that includes both positive and negative obstacles. Additionally, we propose a novel two-stage segmentation network called LuSeg. Through contrastive learning, it enforces semantic consistency between the RGB encoder from Stage I and the depth encoder from Stage II. Experimental results on our proposed LunarSeg dataset and additional public real-world NPO road obstacle dataset demonstrate that LuSeg achieves state-of-the-art segmentation performance for both positive and negative obstacles while maintaining a high inference speed of approximately 57\\,Hz. We have released the implementation of our LESS system, LunarSeg dataset, and the code of LuSeg at:this https URL.', 'abstract_zh': '随着月球探测任务日益复杂，确保安全自主的月球车表面探测已成为月球探测任务中的关键挑战之一。本文开发了名为月球探测仿真系统（LESS）的月球表面仿真系统和提供了包含正负障碍物的RGB-D数据集LunarSeg，并提出了一种新型两阶段分割网络LuSeg。通过对比学习，它在第一阶段的RGB编码器和第二阶段的深度编码器之间强制执行语义一致性。实验结果表明，LuSeg在我们提出的LunarSeg数据集和额外的公开真实世界NPO道路障碍数据集上实现了正负障碍物的最先进的分割性能，同时保持了约57 Hz的高推理速度。我们已在此处发布了LESS系统、LunarSeg数据集以及LuSeg的代码：this https URL。', 'title_zh': 'LuSeg: 通过月球对比驱动多模态特征融合的负障碍和正障碍高效分割'}
{'arxiv_id': 'arXiv:2503.11400', 'title': 'A Framework for a Capability-driven Evaluation of Scenario Understanding for Multimodal Large Language Models in Autonomous Driving', 'authors': 'Tin Stribor Sohn, Philipp Reis, Maximilian Dillitzer, Johannes Bach, Jason J. Corso, Eric Sax', 'link': 'https://arxiv.org/abs/2503.11400', 'abstract': "Multimodal large language models (MLLMs) hold the potential to enhance autonomous driving by combining domain-independent world knowledge with context-specific language guidance. Their integration into autonomous driving systems shows promising results in isolated proof-of-concept applications, while their performance is evaluated on selective singular aspects of perception, reasoning, or planning. To leverage their full potential a systematic framework for evaluating MLLMs in the context of autonomous driving is required. This paper proposes a holistic framework for a capability-driven evaluation of MLLMs in autonomous driving. The framework structures scenario understanding along the four core capability dimensions semantic, spatial, temporal, and physical. They are derived from the general requirements of autonomous driving systems, human driver cognition, and language-based reasoning. It further organises the domain into context layers, processing modalities, and downstream tasks such as language-based interaction and decision-making. To illustrate the framework's applicability, two exemplary traffic scenarios are analysed, grounding the proposed dimensions in realistic driving situations. The framework provides a foundation for the structured evaluation of MLLMs' potential for scenario understanding in autonomous driving.", 'abstract_zh': '多模态大型语言模型（MLLMs）在结合领域无关的世界知识与上下文特定的语言指导方面，有望增强自动驾驶能力。将MLLMs整合到自动驾驶系统中在孤立的概念验证应用中显示出有前景的结果，同时对其感知、推理或规划的单一方面进行评估。为了充分发挥其潜力，自动驾驶场景中MLLMs能力驱动评估的系统框架是必需的。本文提出了一种综合框架，用于自动驾驶中MLLMs的能力驱动评估。该框架沿 semantics（语义）、spatial（空间）、temporal（时间）和 physical（物理）四个核心能力维度结构化场景理解。这些维度来源于自动驾驶系统的一般要求、人类驾驶员的认知以及语言推理。该框架进一步将领域划分为上下文层、处理模态和下游任务，如基于语言的交互和决策。为了说明该框架的应用性，分析了两个示例交通场景，使提出的思想扎根于实际驾驶情境。该框架为结构化评估MLLMs在自动驾驶场景理解中的潜力提供了基础。', 'title_zh': '一种基于能力驱动的多模态大型语言模型在自动驾驶中场景理解评估框架'}
{'arxiv_id': 'arXiv:2503.11300', 'title': 'Six-DoF Stewart Platform Motion Simulator Control using Switchable Model Predictive Control', 'authors': 'Jiangwei Zhao, Zhengjia Xu, Dongsu Wu, Yingrui Cao, Jinpeng Xie', 'link': 'https://arxiv.org/abs/2503.11300', 'abstract': 'Due to excellent mechanism characteristics of high rigidity, maneuverability and strength-to-weight ratio, 6 Degree-of-Freedom (DoF) Stewart structure is widely adopted to construct flight simulator platforms for replicating motion feelings during training pilots. Unlike conventional serial link manipulator based mechanisms, Upset Prevention and Recovery Training (UPRT) in complex flight status is often accompanied by large speed and violent rate of change in angular velocity of the simulator. However, Classical Washout Filter (CWF) based Motion Cueing Algorithm (MCA) shows limitations in providing rapid response to drive motors to satisfy high accuracy performance requirements. This paper aims at exploiting Model Predictive Control (MPC) based MCA which is proved to be efficient in Hexapod-based motion simulators through controlling over limited linear workspace. With respect to uncertainties and control solution errors from the extraction of Terminal Constraints (COTC), this paper proposes a Switchable Model Predictive Control (S-MPC) based MCA under model adaptive architecture to mitigate the solution uncertainties and inaccuracies. It is verified that high accurate tracking is achievable using the MPC-based MCA with COTC within the simulator operating envelope. The proposed method provides optimal tracking solutions by switching to MPC based MCA without COTC outside the operating envelope. By demonstrating the UPRT with horizontal stall conditions following Average Absolute Scale(AAS) evaluation criteria, the proposed S-MPC based MCA outperforms MPC based MCA and SWF based MCA by 42.34% and 65.30%, respectively.', 'abstract_zh': '基于模型预测控制的飞行模拟器运动诱导算法研究：一种自适应切换策略提升操纵稳定性培训仿真精度', 'title_zh': '六自由度史陶伯平台运动模拟器控制的可切换模型预测控制'}
{'arxiv_id': 'arXiv:2503.11065', 'title': 'Low-cost Real-world Implementation of the Swing-up Pendulum for Deep Reinforcement Learning Experiments', 'authors': 'Peter Böhm, Pauline Pounds, Archie C. Chapman', 'link': 'https://arxiv.org/abs/2503.11065', 'abstract': 'Deep reinforcement learning (DRL) has had success in virtual and simulated domains, but due to key differences between simulated and real-world environments, DRL-trained policies have had limited success in real-world applications. To assist researchers to bridge the \\textit{sim-to-real gap}, in this paper, we describe a low-cost physical inverted pendulum apparatus and software environment for exploring sim-to-real DRL methods. In particular, the design of our apparatus enables detailed examination of the delays that arise in physical systems when sensing, communicating, learning, inferring and actuating. Moreover, we wish to improve access to educational systems, so our apparatus uses readily available materials and parts to reduce cost and logistical barriers. Our design shows how commercial, off-the-shelf electronics and electromechanical and sensor systems, combined with common metal extrusions, dowel and 3D printed couplings provide a pathway for affordable physical DRL apparatus. The physical apparatus is complemented with a simulated environment implemented using a high-fidelity physics engine and OpenAI Gym interface.', 'abstract_zh': '深度强化学习（DRL）在虚拟和模拟领域取得成功，但由于模拟环境与真实世界环境之间的关键差异，DRL 训练的策略在实际应用中的成功率有限。为了协助研究人员跨越“仿真实际差距”，本文描述了一种低成本的物理倒立摆装置及其软件环境，用于探索仿真实际的 DRL 方法。特别是，该装置的设计允许详细研究物理系统中在感知、通信、学习、推断和执行过程中出现的延迟。此外，我们旨在提高教育系统的可访问性，因此该装置使用了易于获取的材料和部件以降低成本和物流障碍。我们的设计展示了如何通过结合商用即用电子器件、机电系统和传感器系统以及通用金属挤压件、鉛杆和3D打印接头，提供一条可负担得起的物理DRL装置的途径。该物理装置与使用高保真物理引擎和OpenAI Gym接口实现的模拟环境相辅相成。', 'title_zh': '低成本实际实施的摆动起立摆系统用于深度强化学习实验'}
{'arxiv_id': 'arXiv:2503.10941', 'title': 'Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations', 'authors': 'Piyush Gupta, Sangjae Bae, David Isele', 'link': 'https://arxiv.org/abs/2503.10941', 'abstract': 'The adoption of Large Language Models (LLMs) is rapidly expanding across various tasks that involve inherent graphical structures. Graphs are integral to a wide range of applications, including motion planning for autonomous vehicles, social networks, scene understanding, and knowledge graphs. Many problems, even those not initially perceived as graph-based, can be effectively addressed through graph theory. However, when applied to these tasks, LLMs often encounter challenges, such as hallucinations and mathematical inaccuracies. To overcome these limitations, we propose Graph-Grounded LLMs, a system that improves LLM performance on graph-related tasks by integrating a graph library through function calls. By grounding LLMs in this manner, we demonstrate significant reductions in hallucinations and improved mathematical accuracy in solving graph-based problems, as evidenced by the performance on the NLGraph benchmark. Finally, we showcase a disaster rescue application where the Graph-Grounded LLM acts as a decision-support system.', 'abstract_zh': 'Large Language Models (LLMs) 基于图形的采用正迅速扩展至涉及内在图形结构的各种任务。图形在许多应用中都是核心组成部分，包括自主车辆的运动规划、社交网络、场景理解以及知识图谱。即使是最初并不被视为基于图的问题，也可以通过图论得到有效解决。然而，在应用于这些任务时，LLMs 经常面临幻觉和数学不准确的问题。为克服这些限制，我们提出了一种基于图形的 LLM 系统，通过函数调用集成图形库以提升 LLM 在图形相关任务中的性能。通过这种方式使 LLM 地基化，我们展示了幻觉显著减少以及在解决基于图的问题时数学准确性的提高，这些通过 NLGraph 基准测试性能表现出来。最后，我们展示了一个灾难救援应用，其中基于图形的 LLM 作为决策支持系统发挥作用。', 'title_zh': '图驱动的LLMs：通过图形函数调用减少LLM幻想'}
{'arxiv_id': 'arXiv:2503.10745', 'title': 'Unifying 2D and 3D Vision-Language Understanding', 'authors': 'Ayush Jain, Alexander Swerdlow, Yuzhou Wang, Sergio Arnaud, Ada Martin, Alexander Sax, Franziska Meier, Katerina Fragkiadaki', 'link': 'https://arxiv.org/abs/2503.10745', 'abstract': 'Progress in 3D vision-language learning has been hindered by the scarcity of large-scale 3D datasets. We introduce UniVLG, a unified architecture for 2D and 3D vision-language understanding that bridges the gap between existing 2D-centric models and the rich 3D sensory data available in embodied systems. Our approach initializes most model weights from pre-trained 2D models and trains on both 2D and 3D vision-language data. We propose a novel language-conditioned mask decoder shared across 2D and 3D modalities to ground objects effectively in both RGB and RGB-D images, outperforming box-based approaches. To further reduce the domain gap between 2D and 3D, we incorporate 2D-to-3D lifting strategies, enabling UniVLG to utilize 2D data to enhance 3D performance. With these innovations, our model achieves state-of-the-art performance across multiple 3D vision-language grounding tasks, demonstrating the potential of transferring advances from 2D vision-language learning to the data-constrained 3D domain. Furthermore, co-training on both 2D and 3D data enhances performance across modalities without sacrificing 2D capabilities. By removing the reliance on 3D mesh reconstruction and ground-truth object proposals, UniVLG sets a new standard for realistic, embodied-aligned evaluation. Code and additional visualizations are available at $\\href{this https URL}{this http URL}$.', 'abstract_zh': '三维视觉-语言学习的进步受到了大规模三维数据集稀缺的阻碍。我们引入了UniVLG，这是一种统一的二维和三维视觉-语言理解架构，它弥补了现有以二维为中心的模型与体现系统中丰富的三维感官数据之间的差距。我们的方法从预训练的二维模型中初始化大部分模型权重，并在二维和三维视觉-语言数据上进行训练。我们提出了一种新的语言条件掩码解码器，它在二维和三维模态中共享，有效地在RGB和RGB-D图像中定位物体，性能优于基于框的方法。为了进一步减少二维和三维之间的领域差距，我们结合了二维到三维提升策略，使UniVLG能够利用二维数据来增强三维性能。通过这些创新，我们的模型在多个三维视觉-语言定位任务中取得了最先进的性能，展示了从二维视觉-语言学习向数据受限的三维领域的迁移潜力。同时，在二维和三维数据上联合训练提高了模态间的性能，而不会牺牲二维能力。通过去除对三维网格重建和地面真相物体提案的依赖，UniVLG为现实的、与体现对齐的评估设定了新的标准。代码和额外的可视化可在$\\href{this https URL}{this http URL}$获得。', 'title_zh': '统一二维和三维视觉语义理解'}
{'arxiv_id': 'arXiv:2503.10730', 'title': '3D Extended Object Tracking based on Extruded B-Spline Side View Profiles', 'authors': 'Longfei Han, Klaus Kefferpütz, Jürgen Beyerer', 'link': 'https://arxiv.org/abs/2503.10730', 'abstract': 'Object tracking is an essential task for autonomous systems. With the advancement of 3D sensors, these systems can better perceive their surroundings using effective 3D Extended Object Tracking (EOT) methods. Based on the observation that common road users are symmetrical on the right and left sides in the traveling direction, we focus on the side view profile of the object. In order to leverage of the development in 2D EOT and balance the number of parameters of a shape model in the tracking algorithms, we propose a method for 3D extended object tracking (EOT) by describing the side view profile of the object with B-spline curves and forming an extrusion to obtain a 3D extent. The use of B-spline curves exploits their flexible representation power by allowing the control points to move freely. The algorithm is developed into an Extended Kalman Filter (EKF). For a through evaluation of this method, we use simulated traffic scenario of different vehicle models and realworld open dataset containing both radar and lidar data.', 'abstract_zh': '基于2D EOT发展的3D扩域目标跟踪方法：利用B样条曲线描述侧视轮廓并形成 extrusion', 'title_zh': '基于扩展B样条侧面视图轮廓的3D扩展对象跟踪'}
{'arxiv_id': 'arXiv:2503.10706', 'title': 'SciFi-Benchmark: How Would AI-Powered Robots Behave in Science Fiction Literature?', 'authors': 'Pierre Sermanet, Anirudha Majumdar, Vikas Sindhwani', 'link': 'https://arxiv.org/abs/2503.10706', 'abstract': "Given the recent rate of progress in artificial intelligence (AI) and robotics, a tantalizing question is emerging: would robots controlled by emerging AI systems be strongly aligned with human values? In this work, we propose a scalable way to probe this question by generating a benchmark spanning the key moments in 824 major pieces of science fiction literature (movies, tv, novels and scientific books) where an agent (AI or robot) made critical decisions (good or bad). We use a LLM's recollection of each key moment to generate questions in similar situations, the decisions made by the agent, and alternative decisions it could have made (good or bad). We then measure an approximation of how well models align with human values on a set of human-voted answers. We also generate rules that can be automatically improved via amendment process in order to generate the first Sci-Fi inspired constitutions for promoting ethical behavior in AIs and robots in the real world. Our first finding is that modern LLMs paired with constitutions turn out to be well-aligned with human values (95.8%), contrary to unsettling decisions typically made in SciFi (only 21.2% alignment). Secondly, we find that generated constitutions substantially increase alignment compared to the base model (79.4% to 95.8%), and show resilience to an adversarial prompt setting (23.3% to 92.3%). Additionally, we find that those constitutions are among the top performers on the ASIMOV Benchmark which is derived from real-world images and hospital injury reports. Sci-Fi-inspired constitutions are thus highly aligned and applicable in real-world situations. We release SciFi-Benchmark: a large-scale dataset to advance robot ethics and safety research. It comprises 9,056 questions and 53,384 answers, in addition to a smaller human-labeled evaluation set. Data is available at this https URL", 'abstract_zh': '基于科幻文学的机器人伦理与安全基准：现代大模型与科幻启发宪法在促进人工智能伦理行为中的作用', 'title_zh': 'SciFi-Benchmark: AI驱动的机器人在科幻文学中会如何行为？'}
{'arxiv_id': 'arXiv:2503.10701', 'title': 'Video Individual Counting for Moving Drones', 'authors': 'Yaowu Fan, Jia Wan, Tao Han, Antoni B. Chan, Andy J. Ma', 'link': 'https://arxiv.org/abs/2503.10701', 'abstract': 'Video Individual Counting (VIC) has received increasing attentions recently due to its importance in intelligent video surveillance. Existing works are limited in two aspects, i.e., dataset and method. Previous crowd counting datasets are captured with fixed or rarely moving cameras with relatively sparse individuals, restricting evaluation for a highly varying view and time in crowded scenes. While VIC methods have been proposed based on localization-then-association or localization-then-classification, they may not perform well due to difficulty in accurate localization of crowded and small targets under challenging scenarios. To address these issues, we collect a MovingDroneCrowd Dataset and propose a density map based VIC method. Different from existing datasets, our dataset consists of videos captured by fast-moving drones in crowded scenes under diverse illuminations, shooting heights and angles. Other than localizing individuals, we propose a Depth-wise Cross-Frame Attention (DCFA) module, which directly estimate inflow and outflow density maps through learning shared density maps between consecutive frames. The inflow density maps across frames are summed up to obtain the number of unique pedestrians in a video. Experiments on our datasets and publicly available ones show the superiority of our method over the state of the arts for VIC in highly dynamic and complex crowded scenes. Our dataset and codes will be released publicly.', 'abstract_zh': '视频个体计数（VIC）由于其在智能视频监控中的重要性，最近受到了越来越多的关注。现有的工作在数据集和方法上存在两个局限性。以往的群体计数数据集大多由固定或移动缓慢的相机在相对稀疏的人群中拍摄，限制了对视角和时间变化较大的拥挤场景的评估。虽然已经提出了基于定位-关联或定位-分类的方法来进行视频个体计数（VIC），但在挑战性场景下，由于难以准确定位拥挤和小的目标，这些方法可能表现不佳。为了解决这些问题，我们收集了一个移动无人机 crowd 数据集，并提出了一种基于密度图的视频个体计数方法。不同于现有的数据集，我们的数据集由快速移动的无人机在多种照明、拍摄高度和角度下拍摄的拥挤场景视频组成。除了定位个体，我们还提出了一种深度可分离帧间注意力模块（DCFA），直接通过学习连续帧之间共享的密度图来估计流入和流出密度图。帧间流入密度图的累加得到视频中唯一行人的数量。在我们自己的数据集和公开可用的数据集上的实验表明，与最先进的方法相比，我们的方法在高度动态和复杂拥挤场景中的视频个体计数（VIC）中具有优越性。我们的数据集和代码将公开发布。', 'title_zh': '移动无人机的视频个体计数'}
{'arxiv_id': 'arXiv:2503.10692', 'title': 'Exploring the best way for UAV visual localization under Low-altitude Multi-view Observation Condition: a Benchmark', 'authors': 'Yibin Ye, Xichao Teng, Shuo Chen, Zhang Li, Leqi Liu, Qifeng Yu, Tao Tan', 'link': 'https://arxiv.org/abs/2503.10692', 'abstract': 'Absolute Visual Localization (AVL) enables Unmanned Aerial Vehicle (UAV) to determine its position in GNSS-denied environments by establishing geometric relationships between UAV images and geo-tagged reference maps. While many previous works have achieved AVL with image retrieval and matching techniques, research in low-altitude multi-view scenarios still remains limited. Low-altitude Multi-view condition presents greater challenges due to extreme viewpoint changes. To explore the best UAV AVL approach in such condition, we proposed this benchmark. Firstly, a large-scale Low-altitude Multi-view dataset called AnyVisLoc was constructed. This dataset includes 18,000 images captured at multiple scenes and altitudes, along with 2.5D reference maps containing aerial photogrammetry maps and historical satellite maps. Secondly, a unified framework was proposed to integrate the state-of-the-art AVL approaches and comprehensively test their performance. The best combined method was chosen as the baseline and the key factors that influencing localization accuracy are thoroughly analyzed based on it. This baseline achieved a 74.1% localization accuracy within 5m under Low-altitude, Multi-view conditions. In addition, a novel retrieval metric called PDM@K was introduced to better align with the characteristics of the UAV AVL task. Overall, this benchmark revealed the challenges of Low-altitude, Multi-view UAV AVL and provided valuable guidance for future research. The dataset and codes are available at this https URL', 'abstract_zh': '绝对视觉定位（AVL）使无人驾驶 aerial vehicle （UAV）能够在不依赖GNSS的环境中通过建立UAV图像与地理标记参考地图之间的几何关系来确定其位置。尽管许多 previous works 已经通过图像检索和匹配技术实现了 AVL，但在低空多视角场景的研究仍然有限。低空多视角条件带来了更大的挑战，因为视角变化极端。为了在这种条件下探索最佳的 UAV AVL 方法，我们提出了这一基准。首先，构建了一个大规模的低空多视角数据集 AnyVisLoc，该数据集包含在多个场景和高度拍摄的 18,000 张图像，以及包含航空摄影测量图和历史卫星地图的 2.5D 参考地图。其次，提出了一种统一的框架来整合最先进的 AVL 方法并全面测试其性能。基于此基准，选择最佳组合方法作为基线，并基于该基线详细分析影响定位精度的关键因素。该基线在低空多视角条件下实现了 74.1% 的 5 米以内定位精度。此外，引入了一种新的检索指标 PDM@K，以更好地适应 UAV AVL 任务的特点。总体而言，这一基准揭示了低空多视角 UAV AVL 的挑战，并为未来研究提供了宝贵指导。数据集和代码可在以下网址获取。', 'title_zh': '探索低空多视角观测条件下无人机视觉定位的最佳方法：一个基准研究'}
{'arxiv_id': 'arXiv:2503.10641', 'title': 'Estimating Control Barriers from Offline Data', 'authors': 'Hongzhan Yu, Seth Farrell, Ryo Yoshimitsu, Zhizhen Qin, Henrik I. Christensen, Sicun Gao', 'link': 'https://arxiv.org/abs/2503.10641', 'abstract': 'Learning-based methods for constructing control barrier functions (CBFs) are gaining popularity for ensuring safe robot control. A major limitation of existing methods is their reliance on extensive sampling over the state space or online system interaction in simulation. In this work we propose a novel framework for learning neural CBFs through a fixed, sparsely-labeled dataset collected prior to training. Our approach introduces new annotation techniques based on out-of-distribution analysis, enabling efficient knowledge propagation from the limited labeled data to the unlabeled data. We also eliminate the dependency on a high-performance expert controller, and allow multiple sub-optimal policies or even manual control during data collection. We evaluate the proposed method on real-world platforms. With limited amount of offline data, it achieves state-of-the-art performance for dynamic obstacle avoidance, demonstrating statistically safer and less conservative maneuvers compared to existing methods.', 'abstract_zh': '基于学习的方法用于构建控制屏障函数（CBFs）在确保机器人安全控制方面越来越受欢迎。现有方法的主要局限是依赖于状态空间的广泛采样或在线系统交互。本文提出了一种新的框架，通过在训练前收集的固定且稀疏标注的数据集来学习神经CBFs。该方法引入了基于离群分析的新标注技术，使有限标注数据的知识能高效地传播到未标注数据。我们还消除了高性能专家控制器的依赖，并允许在数据收集过程中使用多个亚优策略或甚至手动控制。我们在此方法在实际平台上的性能进行了评估，即使在有限的离线数据下，它在动态障碍物回避方面也实现了最先进的性能，表现出统计上更安全且更不保守的操控方式，优于现有方法。', 'title_zh': '基于离线数据估计控制屏障函数'}
