{'arxiv_id': 'arXiv:2510.12206', 'title': 'Controllable Collision Scenario Generation via Collision Pattern Prediction', 'authors': 'Pin-Lun Chen, Chi-Hsi Kung, Che-Han Chang, Wei-Chen Chiu, Yi-Ting Chen', 'link': 'https://arxiv.org/abs/2510.12206', 'abstract': 'Evaluating the safety of autonomous vehicles (AVs) requires diverse, safety-critical scenarios, with collisions being especially important yet rare and unsafe to collect in the real world. Therefore, the community has been focusing on generating safety-critical scenarios in simulation. However, controlling attributes such as collision type and time-to-accident (TTA) remains challenging. We introduce a new task called controllable collision scenario generation, where the goal is to produce trajectories that realize a user-specified collision type and TTA, to investigate the feasibility of automatically generating desired collision scenarios. To support this task, we present COLLIDE, a large-scale collision scenario dataset constructed by transforming real-world driving logs into diverse collisions, balanced across five representative collision types and different TTA intervals. We propose a framework that predicts Collision Pattern, a compact and interpretable representation that captures the spatial configuration of the ego and the adversarial vehicles at impact, before rolling out full adversarial trajectories. Experiments show that our approach outperforms strong baselines in both collision rate and controllability. Furthermore, generated scenarios consistently induce higher planner failure rates, revealing limitations of existing planners. We demonstrate that these scenarios fine-tune planners for robustness improvements, contributing to safer AV deployment in different collision scenarios.', 'abstract_zh': '评估自主车辆的安全性需要多样化的安全关键场景，尤其是碰撞事件因其重要性高、收集难度大而稀有且不安全。因此，研究社区一直在致力于在仿真中生成安全关键场景。然而，控制碰撞类型和事故前时间（TTA）等属性仍然具有挑战性。我们引入了一个新的任务——可控碰撞场景生成，目标是在给定用户指定的碰撞类型和TTA的情况下生成轨迹，以此调查自动生成所需碰撞场景的可行性。为支持这一任务，我们呈现了COLLIDE，一个大规模的碰撞场景数据集，该数据集通过将实际驾驶日志转化为多样化的碰撞，并在五类代表性和不同TTA区间上保持平衡而构建。我们提出了一种框架，它预测碰撞模式，这是一种紧凑且可解释的表示，捕捉碰撞前 ego 车辆和对手车辆的空间配置。实验表明，我们的方法在碰撞率和可控性方面均优于强基线。此外，生成的场景一致地导致更高的规划器失败率，揭示了现有规划器的局限性。我们展示了这些场景能够对规划器进行微调，从而提高其鲁棒性，促进在不同碰撞场景下的自主车辆的更安全部署。', 'title_zh': '基于碰撞模式预测的可控碰撞场景生成'}
{'arxiv_id': 'arXiv:2510.12101', 'title': 'Gaussian Semantic Field for One-shot LiDAR Global Localization', 'authors': 'Pengyu Yin, Shenghai Yuan, Haozhi Cao, Xingyu Ji, Ruofei Bai, Siyu Chen, Lihua Xie', 'link': 'https://arxiv.org/abs/2510.12101', 'abstract': 'We present a one-shot LiDAR global localization algorithm featuring semantic disambiguation ability based on a lightweight tri-layered scene graph. While landmark semantic registration-based methods have shown promising performance improvements in global localization compared with geometric-only methods, landmarks can be repetitive and misleading for correspondence establishment. We propose to mitigate this problem by modeling semantic distributions with continuous functions learned from a population of Gaussian processes. Compared with discrete semantic labels, the continuous functions capture finer-grained geo-semantic information and also provide more detailed metric information for correspondence establishment. We insert this continuous function as the middle layer between the object layer and the metric-semantic layer, forming a tri-layered 3D scene graph, serving as a light-weight yet performant backend for one-shot localization. We term our global localization pipeline Outram-GSF (Gaussian semantic field) and conduct a wide range of experiments on publicly available data sets, validating the superior performance against the current state-of-the-art.', 'abstract_zh': '基于轻量级三层场景图的单次LiDAR全局定位算法：基于连续语义场的语义消歧', 'title_zh': '高斯语义场_for_one-shot LiDAR全局定位'}
{'arxiv_id': 'arXiv:2510.12687', 'title': 'EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels', 'authors': 'Kunyu Peng, Di Wen, Kailun Yang, Jia Fu, Yufan Chen, Ruiping Liu, Jiamin Wu, Junwei Zheng, M. Saquib Sarfraz, Luc Van Gool, Danda Pani Paudel, Rainer Stiefelhagen', 'link': 'https://arxiv.org/abs/2510.12687', 'abstract': 'Open-Set Domain Generalization (OSDG) aims to enable deep learning models to recognize unseen categories in new domains, which is crucial for real-world applications. Label noise hinders open-set domain generalization by corrupting source-domain knowledge, making it harder to recognize known classes and reject unseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL) using hyperbolic prototype-guided meta-learning, they struggle to bridge domain gaps, especially with limited clean labeled data. In this paper, we propose Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first introduce an unsupervised two-stage evidential loss clustering method to promote label reliability awareness. Then, we propose a residual flow matching mechanism that models structured domain- and category-conditioned residuals, enabling diverse and uncertainty-aware transfer paths beyond interpolation-based augmentation. During this meta-learning process, the model is optimized such that the update direction on the clean set maximizes the loss decrease on the noisy set, using pseudo labels derived from the most confident predicted class for supervision. Experimental results show that EReLiFM outperforms existing methods on OSDG-NL, achieving state-of-the-art performance. The source code is available at this https URL.', 'abstract_zh': '开放集领域泛化（OSDG）旨在使深度学习模型能够识别新领域中未见类别的样本，对于实际应用至关重要。标签噪声阻碍开放集领域泛化的实现，通过污染源领域知识，使已知类别难以识别，并且更难拒绝未见类别。虽然现有的方法通过超球面原型引导的元学习解决有噪声标签的OSDG（OSDG-NL），但在有限的干净标注数据情况下难以弥合领域差距。在本文中，我们提出了一种证据可靠性感知残差流元学习（EReLiFM）。我们首先引入了一种无监督的两阶段证据损失聚类方法，以促进标签可靠性的意识。然后，我们提出了一种残差流匹配机制，该机制建模了结构化领域和类别条件下的残差，允许超越基于插值的增强之外的多样而不确定性意识的转移路径。在此元学习过程中，模型被优化以最大化在噪声集上损失的减少，同时使用从最自信预测类别推导出的伪标签作为监督。实验结果表明，EReLiFM 在OSDG-NL 上优于现有方法，达到了最先进的性能。源代码可在以下链接获取。', 'title_zh': 'EReLiFM：噪声标签下开集领域泛化的证据可靠性感知残差流元学习'}
{'arxiv_id': 'arXiv:2510.12732', 'title': 'Clutch Control: An Attention-based Combinatorial Bandit for Efficient Mutation in JavaScript Engine Fuzzing', 'authors': 'Myles Foley, Sergio Maffeis, Muhammad Fakhrur Rozi, Takeshi Takahashi', 'link': 'https://arxiv.org/abs/2510.12732', 'abstract': 'JavaScript engines are widely used in web browsers, PDF readers, and server-side applications. The rise in concern over their security has led to the development of several targeted fuzzing techniques. However, existing approaches use random selection to determine where to perform mutations in JavaScript code. We postulate that the problem of selecting better mutation targets is suitable for combinatorial bandits with a volatile number of arms. Thus, we propose CLUTCH, a novel deep combinatorial bandit that can observe variable length JavaScript test case representations, using an attention mechanism from deep learning. Furthermore, using Concrete Dropout, CLUTCH can dynamically adapt its exploration. We show that CLUTCH increases efficiency in JavaScript fuzzing compared to three state-of-the-art solutions by increasing the number of valid test cases and coverage-per-testcase by, respectively, 20.3% and 8.9% on average. In volatile and combinatorial settings we show that CLUTCH outperforms state-of-the-art bandits, achieving at least 78.1% and 4.1% less regret in volatile and combinatorial settings, respectively.', 'abstract_zh': 'JavaScript引擎广泛应用于网页浏览器、PDF阅读器和服务器端应用。随着对它们安全性的关注增加，已经开发出了几种针对性的变异测试技术。然而，现有方法使用随机选择来决定在JavaScript代码中的哪个位置进行变异。我们假设选择更好的变异目标问题适合使用具有可变臂数量的组合臂赛。因此，我们提出了CLUTCH，一种新颖的深度组合臂赛，可以观察JavaScript测试用例的变长表示，并利用深度学习的注意力机制。此外，通过使用Concrete Dropout，CLUTCH可以动态调整其探索。我们展示了与三种最先进的解决方案相比，CLUTCH在JavaScript变异测试中提高了效率，平均每份测试用例增加了20.3%的有效测试用例数量和8.9%的覆盖率。在具有波动性和组合性设置的情况下，我们展示了CLUTCH优于最先进的臂赛，分别在波动性和组合性设置中减少了至少78.1%和4.1%的遗憾值。', 'title_zh': '刹车控制：一种基于注意力的组合多臂bandit算法，用于JavaScript引擎 fuzzing 中的有效变异体生成'}
{'arxiv_id': 'arXiv:2510.12713', 'title': 'Towards Robust Artificial Intelligence: Self-Supervised Learning Approach for Out-of-Distribution Detection', 'authors': 'Wissam Salhab, Darine Ameyed, Hamid Mcheick, Fehmi Jaafar', 'link': 'https://arxiv.org/abs/2510.12713', 'abstract': "Robustness in AI systems refers to their ability to maintain reliable and accurate performance under various conditions, including out-of-distribution (OOD) samples, adversarial attacks, and environmental changes. This is crucial in safety-critical systems, such as autonomous vehicles, transportation, or healthcare, where malfunctions could have severe consequences. This paper proposes an approach to improve OOD detection without the need of labeled data, thereby increasing the AI systems' robustness. The proposed approach leverages the principles of self-supervised learning, allowing the model to learn useful representations from unlabeled data. Combined with graph-theoretical techniques, this enables the more efficient identification and categorization of OOD samples. Compared to existing state-of-the-art methods, this approach achieved an Area Under the Receiver Operating Characteristic Curve (AUROC) = 0.99.", 'abstract_zh': 'AI系统中的健 Robustness in AI Systems: Improving Out-of-Distribution Detection Without Labeled Data Through Self-Supervised Learning and Graph-Theoretical Techniques', 'title_zh': '面向鲁棒的人工智能：自监督学习的离分布检测方法'}
{'arxiv_id': 'arXiv:2510.12703', 'title': 'CAMNet: Leveraging Cooperative Awareness Messages for Vehicle Trajectory Prediction', 'authors': 'Mattia Grasselli, Angelo Porrello, Carlo Augusto Grazia', 'link': 'https://arxiv.org/abs/2510.12703', 'abstract': 'Autonomous driving remains a challenging task, particularly due to safety concerns. Modern vehicles are typically equipped with expensive sensors such as LiDAR, cameras, and radars to reduce the risk of accidents. However, these sensors face inherent limitations: their field of view and line of sight can be obstructed by other vehicles, thereby reducing situational awareness. In this context, vehicle-to-vehicle communication plays a crucial role, as it enables cars to share information and remain aware of each other even when sensors are occluded. One way to achieve this is through the use of Cooperative Awareness Messages (CAMs). In this paper, we investigate the use of CAM data for vehicle trajectory prediction. Specifically, we design and train a neural network, Cooperative Awareness Message-based Graph Neural Network (CAMNet), on a widely used motion forecasting dataset. We then evaluate the model on a second dataset that we created from scratch using Cooperative Awareness Messages, in order to assess whether this type of data can be effectively exploited. Our approach demonstrates promising results, showing that CAMs can indeed support vehicle trajectory prediction. At the same time, we discuss several limitations of the approach, which highlight opportunities for future research.', 'abstract_zh': '自主驾驶仍是一项具有挑战性的任务，特别是由于安全考虑。现代车辆通常配备昂贵的传感器，如LiDAR、摄像头和雷达，以降低事故发生的风险。然而，这些传感器存在固有的局限性：它们的视野和视线可能会被其他车辆阻挡，从而降低 situational awareness。在这种情况下，车辆间通信起着关键作用，因为它使汽车能够在传感器被遮挡的情况下仍能分享信息并保持相互知觉。一种实现这一点的方法是使用协作感知消息（CAMs）。在本文中，我们研究了CAM数据在车辆轨迹预测中的应用。具体而言，我们设计并训练了一个基于CAM数据的图神经网络（CAMNet），用于一个广泛使用的运动预测数据集。然后，我们在一个新创建的使用合作感知消息的数据集上评估了该模型，以评估这种数据是否能够有效利用。我们的方法显示出有希望的结果，表明CAMs确实支持车辆轨迹预测。同时，我们也讨论了该方法的一些局限性，这些局限性指出了未来研究的机会。', 'title_zh': 'CAMNet：利用合作感知消息进行车辆轨迹预测'}
{'arxiv_id': 'arXiv:2510.12563', 'title': 'HardcoreLogic: Challenging Large Reasoning Models with Long-tail Logic Puzzle Games', 'authors': 'Jingcong Liang, Shijun Wan, Xuehai Wu, Siyuan Wang, Yitong Li, Qianglong Chen, Duyu Tang, Zhongyu Wei', 'link': 'https://arxiv.org/abs/2510.12563', 'abstract': 'Large Reasoning Models (LRMs) have demonstrated impressive performance on complex tasks, including logical puzzle games that require deriving solutions satisfying all constraints. However, whether they can flexibly apply appropriate rules to varying conditions, particularly when faced with non-canonical game variants, remains an open question. Existing corpora focus on popular puzzles like 9x9 Sudoku, risking overfitting to canonical formats and memorization of solution patterns, which can mask deficiencies in understanding novel rules or adapting strategies to new variants. To address this, we introduce HardcoreLogic, a challenging benchmark of over 5,000 puzzles across 10 games, designed to test the robustness of LRMs on the "long-tail" of logical games. HardcoreLogic systematically transforms canonical puzzles through three dimensions: Increased Complexity (IC), Uncommon Elements (UE), and Unsolvable Puzzles (UP), reducing reliance on shortcut memorization. Evaluations on a diverse set of LRMs reveal significant performance drops, even for models achieving top scores on existing benchmarks, indicating heavy reliance on memorized stereotypes. While increased complexity is the dominant source of difficulty, models also struggle with subtle rule variations that do not necessarily increase puzzle difficulty. Our systematic error analysis on solvable and unsolvable puzzles further highlights gaps in genuine reasoning. Overall, HardcoreLogic exposes the limitations of current LRMs and establishes a benchmark for advancing high-level logical reasoning.', 'abstract_zh': 'HardcoreLogic：面向逻辑游戏“长尾”的具有挑战性的基准', 'title_zh': 'HardcoreLogic：用长尾逻辑谜题游戏挑战大型推理模型'}
{'arxiv_id': 'arXiv:2510.12555', 'title': 'Inclusive Fitness as a Key Step Towards More Advanced Social Behaviors in Multi-Agent Reinforcement Learning Settings', 'authors': 'Andries Rosseau, Raphaël Avalos, Ann Nowé', 'link': 'https://arxiv.org/abs/2510.12555', 'abstract': "The competitive and cooperative forces of natural selection have driven the evolution of intelligence for millions of years, culminating in nature's vast biodiversity and the complexity of human minds. Inspired by this process, we propose a novel multi-agent reinforcement learning framework where each agent is assigned a genotype and where reward functions are modelled after the concept of inclusive fitness. An agent's genetic material may be shared with other agents, and our inclusive reward function naturally accounts for this. We study the resulting social dynamics in two types of network games with prisoner's dilemmas and find that our results align with well-established principles from biology, such as Hamilton's rule. Furthermore, we outline how this framework can extend to more open-ended environments with spatial and temporal structure, finite resources, and evolving populations. We hypothesize the emergence of an arms race of strategies, where each new strategy is a gradual improvement over earlier adaptations of other agents, effectively producing a multi-agent autocurriculum analogous to biological evolution. In contrast to the binary team-based structures prevalent in earlier research, our gene-based reward structure introduces a spectrum of cooperation ranging from full adversity to full cooperativeness based on genetic similarity, enabling unique non team-based social dynamics. For example, one agent having a mutual cooperative relationship with two other agents, while the two other agents behave adversarially towards each other. We argue that incorporating inclusive fitness in agents provides a foundation for the emergence of more strategically advanced and socially intelligent agents.", 'abstract_zh': '自然选择的竞争与合作力量驱使智能演化了数百万年，造就了自然界丰富的生物多样性和人类复杂的心智。受此过程启发，我们提出了一种新的多智能体强化学习框架，每个智能体被赋予一个基因型，并且奖励函数模仿泛化亲和力的概念建模。智能体的遗传物质可以与其他智能体共享，我们的泛化奖励函数自然地考虑了这一点。我们在两种具有囚徒困境类型的网络游戏中研究了由此产生的社会动态，发现我们的结果与生物学中已确立的原则，如哈密尔顿规则，相一致。此外，我们概述了该框架如何扩展到具有空间和时间结构、有限资源和演化的种群的更开放的环境中。我们认为，将会出现一种策略的军备竞赛，其中每种新策略都是对其他智能体早期适应的逐步改进，从而产生类似于生物演化的多智能体自闭环课程。与早期研究中占主导的二元团队结构不同，基于基因的奖励结构引入了从完全敌对到完全合作的合作连续谱，使得独特的非团队社会动态成为可能。例如，一个智能体与另外两个智能体形成互惠合作关系，而另外两个智能体之间则表现出敌对行为。我们认为，在智能体中引入泛化亲和力为更加战略性先进且社交智能的智能体的涌现提供了基础。', 'title_zh': '纳入适应度作为迈向多智能体强化学习中更高级社会行为的关键步骤'}
{'arxiv_id': 'arXiv:2510.12534', 'title': 'ProtoSiTex: Learning Semi-Interpretable Prototypes for Multi-label Text Classification', 'authors': 'Utsav Kumar Nareti, Suraj Kumar, Soumya Pandey, Soumi Chattopadhyay, Chandranath Adak', 'link': 'https://arxiv.org/abs/2510.12534', 'abstract': 'The surge in user-generated reviews has amplified the need for interpretable models that can provide fine-grained insights. Existing prototype-based models offer intuitive explanations but typically operate at coarse granularity (sentence or document level) and fail to address the multi-label nature of real-world text classification. We propose ProtoSiTex, a semi-interpretable framework designed for fine-grained multi-label text classification. ProtoSiTex employs a dual-phase alternating training strategy: an unsupervised prototype discovery phase that learns semantically coherent and diverse prototypes, and a supervised classification phase that maps these prototypes to class labels. A hierarchical loss function enforces consistency across sub-sentence, sentence, and document levels, enhancing interpretability and alignment. Unlike prior approaches, ProtoSiTex captures overlapping and conflicting semantics using adaptive prototypes and multi-head attention. We also introduce a benchmark dataset of hotel reviews annotated at the sub-sentence level with multiple labels. Experiments on this dataset and two public benchmarks (binary and multi-class) show that ProtoSiTex achieves state-of-the-art performance while delivering faithful, human-aligned explanations, establishing it as a robust solution for semi-interpretable multi-label text classification.', 'abstract_zh': '用户生成的评论激增加大了对可解释模型的需求，这些模型能够提供细致入微的洞察。现有的原型基模型提供了直观的解释，但通常在粗粒度级别（句子或文档级别）上运行，并且无法解决真实世界文本分类的多标签性质。我们提出了一种半可解释框架ProtoSiTex，旨在实现细致入微的多标签文本分类。ProtoSiTex采用了双阶段交替训练策略：无监督的原型发现阶段，学习语义一致且多样化的原型，以及监督分类阶段，将这些原型映射到类别标签。多层次的损失函数保证了子句、句子和文档级别的一致性，增强了解释的可解释性和对齐性。与之前的方法不同，ProtoSiTex 使用自适应原型和多头注意力机制捕获重叠和冲突的语义。我们还引入了一个酒店评论基准数据集，每个评论在子句级别上标注了多个标签。在该数据集以及两个公共基准数据集（二分类和多分类）上的实验表明，ProtoSiTex 在实现最佳性能的同时提供了忠实且与人类对齐的解释，确立了其作为半可解释多标签文本分类稳健解决方案的地位。', 'title_zh': 'ProtoSiTex: 学习半解释性原型进行多标签文本分类'}
{'arxiv_id': 'arXiv:2510.12269', 'title': 'Tensor Logic: The Language of AI', 'authors': 'Pedro Domingos', 'link': 'https://arxiv.org/abs/2510.12269', 'abstract': 'Progress in AI is hindered by the lack of a programming language with all the requisite features. Libraries like PyTorch and TensorFlow provide automatic differentiation and efficient GPU implementation, but are additions to Python, which was never intended for AI. Their lack of support for automated reasoning and knowledge acquisition has led to a long and costly series of hacky attempts to tack them on. On the other hand, AI languages like LISP an Prolog lack scalability and support for learning. This paper proposes tensor logic, a language that solves these problems by unifying neural and symbolic AI at a fundamental level. The sole construct in tensor logic is the tensor equation, based on the observation that logical rules and Einstein summation are essentially the same operation, and all else can be reduced to them. I show how to elegantly implement key forms of neural, symbolic and statistical AI in tensor logic, including transformers, formal reasoning, kernel machines and graphical models. Most importantly, tensor logic makes new directions possible, such as sound reasoning in embedding space. This combines the scalability and learnability of neural networks with the reliability and transparency of symbolic reasoning, and is potentially a basis for the wider adoption of AI.', 'abstract_zh': 'AI进展受限于缺乏一种具备所有必要特征的编程语言。本文提出张量逻辑语言，该语言通过在根本层面上统一神经AI和符号AI来解决这些问题。张量逻辑语言唯一的构造是张量方程，基于逻辑规则和爱因斯坦求和本质上是同一操作的观察，所有其他操作都可以归约到它们。本文展示了如何优雅地在张量逻辑中实现关键形式的神经、符号和统计AI，包括变换器、形式推理、核机器和图形模型。最重要的是，张量逻辑开辟了新的方向，例如嵌入空间中的可靠推理。这结合了神经网络的可扩展性和可学习性以及符号推理的可靠性和透明性，并有可能成为更广泛采用AI的基础。', 'title_zh': '张量逻辑：AI的语言'}
{'arxiv_id': 'arXiv:2510.12201', 'title': 'On the Design and Evaluation of Human-centered Explainable AI Systems: A Systematic Review and Taxonomy', 'authors': 'Aline Mangold, Juliane Zietz, Susanne Weinhold, Sebastian Pannasch', 'link': 'https://arxiv.org/abs/2510.12201', 'abstract': "As AI becomes more common in everyday living, there is an increasing demand for intelligent systems that are both performant and understandable. Explainable AI (XAI) systems aim to provide comprehensible explanations of decisions and predictions. At present, however, evaluation processes are rather technical and not sufficiently focused on the needs of human users. Consequently, evaluation studies involving human users can serve as a valuable guide for conducting user studies. This paper presents a comprehensive review of 65 user studies evaluating XAI systems across different domains and application contexts. As a guideline for XAI developers, we provide a holistic overview of the properties of XAI systems and evaluation metrics focused on human users (human-centered). We propose objectives for the human-centered design (design goals) of XAI systems. To incorporate users' specific characteristics, design goals are adapted to users with different levels of AI expertise (AI novices and data experts). In this regard, we provide an extension to existing XAI evaluation and design frameworks. The first part of our results includes the analysis of XAI system characteristics. An important finding is the distinction between the core system and the XAI explanation, which together form the whole system. Further results include the distinction of evaluation metrics into affection towards the system, cognition, usability, interpretability, and explanation metrics. Furthermore, the users, along with their specific characteristics and behavior, can be assessed. For AI novices, the relevant extended design goals include responsible use, acceptance, and usability. For data experts, the focus is performance-oriented and includes human-AI collaboration and system and user task performance.", 'abstract_zh': '随着人工智能在日常生活中越来越普遍，对既高效又易理解的智能系统的需求也随之增加。可解释的人工智能（XAI）系统旨在提供决策和预测的可理解解释。然而，目前的评估过程相对技术化，未能充分关注用户需求。因此，涉及人类用户的评估研究可以为用户研究提供有价值的指导。本文综述了65项评估XAI系统的用户研究，涵盖不同领域和应用场景。作为XAI开发者的指南，我们提供了一个综合的XAI系统特性和以用户为中心的评估指标的概述。我们提出了XAI系统的设计目标（以人为本的设计目标）。为了融入用户的特定特征，设计目标被调整以适应不同AI熟练程度的用户（AI新手和数据专家）。在这方面，我们提出了现有XAI评估和设计框架的扩展。结果的第一部分包括对XAI系统特性的分析。一个重要的发现是核心系统和XAI解释之间的区分，两者共同构成了整个系统。其他结果包括将评估指标区分为对系统的感受、认知、易用性、可解释性和解释指标。此外，还可以评估用户及其特定特征和行为。对于AI新手，相关的扩展设计目标包括负责任的使用、接受度和易用性。对于数据专家，重点是面向性能，并包括人机协作和系统及用户任务绩效。', 'title_zh': '基于人类中心的可解释人工智能系统的設計与评估：一种系统回顾与分类框架'}
{'arxiv_id': 'arXiv:2510.12194', 'title': 'ResearStudio: A Human-Intervenable Framework for Building Controllable Deep-Research Agents', 'authors': 'Linyi Yang, Yixuan Weng', 'link': 'https://arxiv.org/abs/2510.12194', 'abstract': "Current deep-research agents run in a ''fire-and-forget'' mode: once started, they give users no way to fix errors or add expert knowledge during execution. We present ResearStudio, the first open-source framework that places real-time human control at its core. The system follows a Collaborative Workshop design. A hierarchical Planner-Executor writes every step to a live ''plan-as-document,'' a fast communication layer streams each action, file change, and tool call to a web interface. At any moment, the user can pause the run, edit the plan or code, run custom commands, and resume -- switching smoothly between AI-led, human-assisted and human-led, AI-assisted modes. In fully autonomous mode, ResearStudio achieves state-of-the-art results on the GAIA benchmark, surpassing systems like OpenAI's DeepResearch and Manus. These results show that strong automated performance and fine-grained human control can coexist. The full code, protocol, and evaluation scripts are available at this https URL. We will continue to update the repository to encourage further work on safe and controllable research agents. Our live demo is publicly accessible at this http URL. We support the development of DeepScientist, which can be accessed at this https URL.", 'abstract_zh': '当前的深度研究代理以“一次性启动”模式运行：一旦启动，用户在执行过程中无法修正错误或添加专业知识。我们提出了ResearStudio，这是首个将实时人类控制放在核心位置的开源框架。该系统采用协作工作室设计。层次化的计划者-执行者将每一步写入一个实时的“计划文档”，快速通信层将每次操作、文件更改和工具调用流式传输到Web界面。用户可以在任何时刻暂停运行、编辑计划或代码、运行自定义命令并恢复运行——在AI主导、人类辅助和人类主导、AI辅助模式之间平滑切换。在完全自主模式下，ResearStudio在GAIA基准测试中实现了最先进的性能，超越了如OpenAI的DeepResearch和Manus等系统。这些结果表明，强大的自动化性能和精细的人类控制可以共存。完整的代码、协议和评估脚本可在以下链接访问：this https URL。我们将继续更新仓库以促进对安全可控研究代理的进一步研究。我们的实时演示可在以下链接公开访问：this http URL。我们支持DeepScientist的发展，可访问以下链接：this https URL。', 'title_zh': 'ResearStudio: 一个人机可介入的可控制深度研究代理构建框架'}
{'arxiv_id': 'arXiv:2510.12076', 'title': 'BeSTAD: Behavior-Aware Spatio-Temporal Anomaly Detection for Human Mobility Data', 'authors': 'Junyi Xie, Jina Kim, Yao-Yi Chiang, Lingyi Zhao, Khurram Shafique', 'link': 'https://arxiv.org/abs/2510.12076', 'abstract': "Traditional anomaly detection in human mobility has primarily focused on trajectory-level analysis, identifying statistical outliers or spatiotemporal inconsistencies across aggregated movement traces. However, detecting individual-level anomalies, i.e., unusual deviations in a person's mobility behavior relative to their own historical patterns, within datasets encompassing large populations remains a significant challenge. In this paper, we present BeSTAD (Behavior-aware Spatio-Temporal Anomaly Detection for Human Mobility Data), an unsupervised framework that captures individualized behavioral signatures across large populations and uncovers fine-grained anomalies by jointly modeling spatial context and temporal dynamics. BeSTAD learns semantically enriched mobility representations that integrate location meaning and temporal patterns, enabling the detection of subtle deviations in individual movement behavior. BeSTAD further employs a behavior-cluster-aware modeling mechanism that builds personalized behavioral profiles from normal activity and identifies anomalies through cross-period behavioral comparison with consistent semantic alignment. Building on prior work in mobility behavior clustering, this approach enables not only the detection of behavioral shifts and deviations from established routines but also the identification of individuals exhibiting such changes within large-scale mobility datasets. By learning individual behaviors directly from unlabeled data, BeSTAD advances anomaly detection toward personalized and interpretable mobility analysis.", 'abstract_zh': '行为导向的时空异常检测框架：人类移动数据中的BeSTAD', 'title_zh': '基于行为感知的空间时间异常检测：Human Mobility Data中的BeSTAD'}
{'arxiv_id': 'arXiv:2510.12033', 'title': 'CausalTrace: A Neurosymbolic Causal Analysis Agent for Smart Manufacturing', 'authors': 'Chathurangi Shyalika, Aryaman Sharma, Fadi El Kalach, Utkarshani Jaimini, Cory Henson, Ramy Harik, Amit Sheth', 'link': 'https://arxiv.org/abs/2510.12033', 'abstract': 'Modern manufacturing environments demand not only accurate predictions but also interpretable insights to process anomalies, root causes, and potential interventions. Existing AI systems often function as isolated black boxes, lacking the seamless integration of prediction, explanation, and causal reasoning required for a unified decision-support solution. This fragmentation limits their trustworthiness and practical utility in high-stakes industrial environments. In this work, we present CausalTrace, a neurosymbolic causal analysis module integrated into the SmartPilot industrial CoPilot. CausalTrace performs data-driven causal analysis enriched by industrial ontologies and knowledge graphs, including advanced functions such as causal discovery, counterfactual reasoning, and root cause analysis (RCA). It supports real-time operator interaction and is designed to complement existing agents by offering transparent, explainable decision support. We conducted a comprehensive evaluation of CausalTrace using multiple causal assessment methods and the C3AN framework (i.e. Custom, Compact, Composite AI with Neurosymbolic Integration), which spans principles of robustness, intelligence, and trustworthiness. In an academic rocket assembly testbed, CausalTrace achieved substantial agreement with domain experts (ROUGE-1: 0.91 in ontology QA) and strong RCA performance (MAP@3: 94%, PR@2: 97%, MRR: 0.92, Jaccard: 0.92). It also attained 4.59/5 in the C3AN evaluation, demonstrating precision and reliability for live deployment.', 'abstract_zh': '现代制造环境不仅需要准确的预测，还需要可解释的洞察以处理异常、根本原因及潜在干预措施。现有的AI系统往往作为孤立的黑盒运作，缺乏预测、解释和因果推理的无缝集成，这限制了它们在高风险工业环境中的可信度和实用价值。在本工作中，我们提出了CausalTrace，这是一种集成在SmartPilot工业CoPilot中的神经符号因果分析模块。CausalTrace通过工业本体和知识图谱进行驱动的数据因果分析，包含先进的因果发现、反事实推理和根本原因分析（RCA）功能。它支持实时操作员交互，并旨在通过提供透明的、可解释的决策支持来补充现有代理。我们使用多种因果评估方法和C3AN框架（即神经符号集成的自定义、紧凑和复合AI）全面评估了CausalTrace。在一项学术火箭组装试验台上，CausalTrace在本体QA方面与领域专家达到了0.91的ROUGE-1一致性，并在RCA性能方面表现出色（MAP@3: 94%，PR@2: 97%，MRR: 0.92，Jaccard: 0.92）。它还在C3AN评估中获得了4.59/5的评分，展示了其在实时部署中的精确性和可靠性。', 'title_zh': '因果追踪：面向智能制造的神经符号因果分析代理'}
{'arxiv_id': 'arXiv:2510.11977', 'title': 'Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent Evaluation', 'authors': 'Sayash Kapoor, Benedikt Stroebl, Peter Kirgis, Nitya Nadgir, Zachary S Siegel, Boyi Wei, Tianci Xue, Ziru Chen, Felix Chen, Saiteja Utpala, Franck Ndzomga, Dheeraj Oruganty, Sophie Luskin, Kangheng Liu, Botao Yu, Amit Arora, Dongyoon Hahm, Harsh Trivedi, Huan Sun, Juyong Lee, Tengjun Jin, Yifan Mai, Yifei Zhou, Yuxuan Zhu, Rishi Bommasani, Daniel Kang, Dawn Song, Peter Henderson, Yu Su, Percy Liang, Arvind Narayanan', 'link': 'https://arxiv.org/abs/2510.11977', 'abstract': 'AI agents have been developed for complex real-world tasks from coding to customer service. But AI agent evaluations suffer from many challenges that undermine our understanding of how well agents really work. We introduce the Holistic Agent Leaderboard (HAL) to address these challenges. We make three main contributions. First, we provide a standardized evaluation harness that orchestrates parallel evaluations across hundreds of VMs, reducing evaluation time from weeks to hours while eliminating common implementation bugs. Second, we conduct three-dimensional analysis spanning models, scaffolds, and benchmarks. We validate the harness by conducting 21,730 agent rollouts across 9 models and 9 benchmarks in coding, web navigation, science, and customer service with a total cost of about $40,000. Our analysis reveals surprising insights, such as higher reasoning effort reducing accuracy in the majority of runs. Third, we use LLM-aided log inspection to uncover previously unreported behaviors, such as searching for the benchmark on HuggingFace instead of solving a task, or misusing credit cards in flight booking tasks. We share all agent logs, comprising 2.5B tokens of language model calls, to incentivize further research into agent behavior. By standardizing how the field evaluates agents and addressing common pitfalls in agent evaluation, we hope to shift the focus from agents that ace benchmarks to agents that work reliably in the real world.', 'abstract_zh': '面向复杂现实任务的AI代理综合评估 leaderboard (HAL)：提高代理性能理解与行为研究', 'title_zh': '整体代理排行榜：AI代理评估的缺失基础设施'}
{'arxiv_id': 'arXiv:2510.11736', 'title': 'AI Agents for the Dhumbal Card Game: A Comparative Study', 'authors': 'Sahaj Raj Malla', 'link': 'https://arxiv.org/abs/2510.11736', 'abstract': "This study evaluates Artificial Intelligence (AI) agents for Dhumbal, a culturally significant multiplayer card game with imperfect information, through a systematic comparison of rule-based, search-based, and learning-based strategies. We formalize Dhumbal's mechanics and implement diverse agents, including heuristic approaches (Aggressive, Conservative, Balanced, Opportunistic), search-based methods such as Monte Carlo Tree Search (MCTS) and Information Set Monte Carlo Tree Search (ISMCTS), and reinforcement learning approaches including Deep Q-Network (DQN) and Proximal Policy Optimization (PPO), and a random baseline. Evaluation involves within-category tournaments followed by a cross-category championship. Performance is measured via win rate, economic outcome, Jhyap success, cards discarded per round, risk assessment, and decision efficiency. Statistical significance is assessed using Welch's t-test with Bonferroni correction, effect sizes via Cohen's d, and 95% confidence intervals (CI). Across 1024 simulated rounds, the rule-based Aggressive agent achieves the highest win rate (88.3%, 95% CI: [86.3, 90.3]), outperforming ISMCTS (9.0%) and PPO (1.5%) through effective exploitation of Jhyap declarations. The study contributes a reproducible AI framework, insights into heuristic efficacy under partial information, and open-source code, thereby advancing AI research and supporting digital preservation of cultural games.", 'abstract_zh': '本研究通过系统比较基于规则、基于搜索和基于学习的战略，评估了用于具有不完全信息的文化重要多人纸牌游戏Dhumbal的人工 intelligence (AI) 剂剂。评估涉及类别内锦标赛和跨类别冠军赛，并通过胜率、经济结果、Jhyap 成功、每轮弃牌数量、风险评估和决策效率进行性能衡量。通过使用 Welch 的 t 检验进行 Bonferroni 修正、Cohen 的 d 效应量评估和 95% 的置信区间（CI）来评估统计显著性。在1024轮模拟比赛中，基于规则的Aggressive代理以最高的胜率（88.3%，95% CI: [86.3, 90.3]）胜出，通过对Jhyap声明的有效利用，优于ISMCTS（9.0%）和PPO（1.5%）。本研究贡献了一个可复制的AI框架，关于部分信息下的启发式有效性见解，并提供了开源代码，从而推动了AI研究并支持文化的数字保存。', 'title_zh': 'AI代理在 Dhumbal 卡牌游戏中的应用：一项比较研究'}
{'arxiv_id': 'arXiv:2510.12795', 'title': 'CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations', 'authors': 'Caner Korkmaz, Brighton Nuwagira, Barış Coşkunuzer, Tolga Birdal', 'link': 'https://arxiv.org/abs/2510.12795', 'abstract': 'We present CuMPerLay, a novel differentiable vectorization layer that enables the integration of Cubical Multiparameter Persistence (CMP) into deep learning pipelines. While CMP presents a natural and powerful way to topologically work with images, its use is hindered by the complexity of multifiltration structures as well as the vectorization of CMP. In face of these challenges, we introduce a new algorithm for vectorizing MP homologies of cubical complexes. Our CuMPerLay decomposes the CMP into a combination of individual, learnable single-parameter persistence, where the bifiltration functions are jointly learned. Thanks to the differentiability, its robust topological feature vectors can be seamlessly used within state-of-the-art architectures such as Swin Transformers. We establish theoretical guarantees for the stability of our vectorization under generalized Wasserstein metrics. Our experiments on benchmark medical imaging and computer vision datasets show the benefit CuMPerLay on classification and segmentation performance, particularly in limited-data scenarios. Overall, CuMPerLay offers a promising direction for integrating global structural information into deep networks for structured image analysis.', 'abstract_zh': 'CuMPerLay：一种新型可微向量化层，实现立方体多参数持久同调在深度学习管道中的集成', 'title_zh': 'CuMPerLay: 学习立方体多参数持久同调向量化'}
{'arxiv_id': 'arXiv:2510.12763', 'title': 'Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective', 'authors': 'Saurabh Sihag, Gonzalo Mateos, Alejandro Ribeiro', 'link': 'https://arxiv.org/abs/2510.12763', 'abstract': "Neurodegeneration, characterized by the progressive loss of neuronal structure or function, is commonly assessed in clinical practice through reductions in cortical thickness or brain volume, as visualized by structural MRI. While informative, these conventional approaches lack the statistical sophistication required to fully capture the spatially correlated and heterogeneous nature of neurodegeneration, which manifests both in healthy aging and in neurological disorders. To address these limitations, brain age gap has emerged as a promising data-driven biomarker of brain health. The brain age gap prediction (BAGP) models estimate the difference between a person's predicted brain age from neuroimaging data and their chronological age. The resulting brain age gap serves as a compact biomarker of brain health, with recent studies demonstrating its predictive utility for disease progression and severity. However, practical adoption of BAGP models is hindered by their methodological obscurities and limited generalizability across diverse clinical populations. This tutorial article provides an overview of BAGP and introduces a principled framework for this application based on recent advancements in graph signal processing (GSP). In particular, we focus on graph neural networks (GNNs) and introduce the coVariance neural network (VNN), which leverages the anatomical covariance matrices derived from structural MRI. VNNs offer strong theoretical grounding and operational interpretability, enabling robust estimation of brain age gap predictions. By integrating perspectives from GSP, machine learning, and network neuroscience, this work clarifies the path forward for reliable and interpretable BAGP models and outlines future research directions in personalized medicine.", 'abstract_zh': '基于脑网络图信号处理的脑龄差距预测：原理与前景', 'title_zh': '基于图形信号处理视角的脑年龄差距预测模型解构神经退行性病变'}
{'arxiv_id': 'arXiv:2510.12750', 'title': 'VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage', 'authors': 'A. Alfarano, L. Venturoli, D. Negueruela del Castillo', 'link': 'https://arxiv.org/abs/2510.12750', 'abstract': "Multimodal Large Language Models (MLLMs) have demonstrated significant capabilities in joint visual and linguistic tasks. However, existing Visual Question Answering (VQA) benchmarks often fail to evaluate deep semantic understanding, particularly in complex domains like visual art analysis. Confined to simple syntactic structures and surface-level attributes, these questions fail to capture the diversity and depth of human visual inquiry. This limitation incentivizes models to exploit statistical shortcuts rather than engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a new, large-scale VQA benchmark for the cultural heritage domain. This benchmark is constructed using a novel multi-agent pipeline where specialized agents collaborate to generate nuanced, validated, and linguistically diverse questions. The resulting benchmark is structured along relevant visual understanding dimensions that probe a model's ability to interpret symbolic meaning, narratives, and complex visual relationships. Our evaluation of 14 state-of-the-art MLLMs on this benchmark reveals significant limitations in current models, including a surprising weakness in simple counting tasks and a clear performance gap between proprietary and open-source models.", 'abstract_zh': '多模态大语言模型（MLLMs）在联合视觉和语言任务中展现了显著的能力。然而，现有的视觉问答（VQA）基准通常未能评估深层语义理解，特别是在视觉艺术分析等复杂领域。受限于简单的句法结构和表面属性，这些问题无法捕捉人类视觉探究的多样性和深度。这一限制促使模型利用统计捷径而非参与视觉推理。为了弥补这一差距，我们引入了VQArt-Bench，这是一个新的大型跨领域VQA基准，特别针对文化遗产领域。该基准通过一个新颖的多代理流程构建，其中专门的代理协作生成细腻的、验证过的、语言多样的问题。所得基准按相关的视觉理解维度结构化，旨在测试模型解释符号意义、叙事和复杂视觉关系的能力。我们将14个最先进的MLLMs在该基准上的评估揭示了当前模型存在显著局限，包括令人惊讶的简单计数任务中的薄弱环节以及专有模型与开源模型之间的明显性能差距。', 'title_zh': 'VQArt-Bench：一个富含语义的艺术和文化遗产VQA基准库'}
{'arxiv_id': 'arXiv:2510.12727', 'title': 'Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems', 'authors': 'Anas Abouaomar, Mohammed El hanjri, Abdellatif Kobbane, Anis Laouiti, Khalid Nafil', 'link': 'https://arxiv.org/abs/2510.12727', 'abstract': 'In this paper, we presents a novel hierarchical federated learning architecture specifically designed for smart agricultural production systems and crop yield prediction. Our approach introduces a seasonal subscription mechanism where farms join crop-specific clusters at the beginning of each agricultural season. The proposed three-layer architecture consists of individual smart farms at the client level, crop-specific aggregators at the middle layer, and a global model aggregator at the top level. Within each crop cluster, clients collaboratively train specialized models tailored to specific crop types, which are then aggregated to produce a higher-level global model that integrates knowledge across multiple crops. This hierarchical design enables both local specialization for individual crop types and global generalization across diverse agricultural contexts while preserving data privacy and reducing communication overhead. Experiments demonstrate the effectiveness of the proposed system, showing that local and crop-layer models closely follow actual yield patterns with consistent alignment, significantly outperforming standard machine learning models. The results validate the advantages of hierarchical federated learning in the agricultural context, particularly for scenarios involving heterogeneous farming environments and privacy-sensitive agricultural data.', 'abstract_zh': '本文提出了一种针对智能农业生产和作物产量预测的新型分层联邦学习架构。我们的方法引入了一个季节性订阅机制，使农场在每个农业季节开始时加入特定作物的集群。所提出的三层架构包括客户端级别的个体智能农场、中间层的作物特定聚合器以及顶层的全球模型聚合器。在每个作物集群内，客户端协作训练专门为特定作物类型定制的专业模型，然后将这些模型聚合以产生更高的全局模型，该模型整合了多种作物的知识。这种分层设计既实现了对个别作物类型的本地专业化，又实现了在各种农业背景下对全局知识的概括，同时保持了数据隐私并减少了通信开销。实验结果证明了所提系统的有效性，显示本地和作物层模型与实际产量模式高度一致并表现出色，显著优于标准机器学习模型。研究结果验证了在农业场景下分层联邦学习的优势，特别是在涉及异质农业环境和敏感农业数据的情况下。', 'title_zh': '智能农业生产系统中作物产量预测的分层联邦学习'}
{'arxiv_id': 'arXiv:2510.12714', 'title': 'Artificial intelligence for simplified patient-centered dosimetry in radiopharmaceutical therapies', 'authors': 'Alejandro Lopez-Montes, Fereshteh Yousefirizi, Yizhou Chen, Yazdan Salimi, Robert Seifert, Ali Afshar-Oromieh, Carlos Uribe, Axel Rominger, Habib Zaidi, Arman Rahmim, Kuangyu Shi', 'link': 'https://arxiv.org/abs/2510.12714', 'abstract': 'KEY WORDS: Artificial Intelligence (AI), Theranostics, Dosimetry, Radiopharmaceutical Therapy (RPT), Patient-friendly dosimetry KEY POINTS - The rapid evolution of radiopharmaceutical therapy (RPT) highlights the growing need for personalized and patient-centered dosimetry. - Artificial Intelligence (AI) offers solutions to the key limitations in current dosimetry calculations. - The main advances on AI for simplified dosimetry toward patient-friendly RPT are reviewed. - Future directions on the role of AI in RPT dosimetry are discussed.', 'abstract_zh': '关键词：人工智能(AI)，诊疗一体化(Theranostics)，剂量学(Dosimetry)，放射性药物治疗(RPT)，患者友好的剂量学\n\n主要内容要点：\n- 放射性药物治疗(RPT)的迅速发展突显了个性化的、以患者为中心的剂量学日益增长的需求。\n- 人工智能(AI)为当前剂量学计算中的关键限制提供了解决方案。\n- 本文回顾了人工智能在简化剂量学以适应患者友好型RPT方面的主要进展。\n- 讨论了人工智能在未来RPT剂量学中的作用方向。', 'title_zh': '人工智能简化以患者为中心的放射性药物治疗剂量规划'}
{'arxiv_id': 'arXiv:2510.12700', 'title': 'Topological Signatures of ReLU Neural Network Activation Patterns', 'authors': 'Vicente Bosca, Tatum Rask, Sunia Tanweer, Andrew R. Tawfeek, Branden Stone', 'link': 'https://arxiv.org/abs/2510.12700', 'abstract': 'This paper explores the topological signatures of ReLU neural network activation patterns. We consider feedforward neural networks with ReLU activation functions and analyze the polytope decomposition of the feature space induced by the network. Mainly, we investigate how the Fiedler partition of the dual graph and show that it appears to correlate with the decision boundary -- in the case of binary classification. Additionally, we compute the homology of the cellular decomposition -- in a regression task -- to draw similar patterns in behavior between the training loss and polyhedral cell-count, as the model is trained.', 'abstract_zh': '本文探讨了ReLU神经网络激活模式的拓扑特征。我们考虑使用ReLU激活函数的前向神经网络，并分析网络诱导的特征空间的多面体分解。主要研究了对偶图的Fiedler分割与决策边界之间的关联性（在二元分类情况下）。此外，在回归任务中，我们计算了细胞分解的同调性质，以在模型训练过程中训练损失与多面体细胞计数的行为模式之间找出相似之处。', 'title_zh': 'ReLU神经网络激活模式的拓扑特征'}
{'arxiv_id': 'arXiv:2510.12692', 'title': 'Who is a Better Matchmaker? Human vs. Algorithmic Judge Assignment in a High-Stakes Startup Competition', 'authors': 'Sarina Xi, Orelia Pi, Miaomiao Zhang, Becca Xiong, Jacqueline Ng Lane, Nihar B. Shah', 'link': 'https://arxiv.org/abs/2510.12692', 'abstract': "There is growing interest in applying artificial intelligence (AI) to automate and support complex decision-making tasks. However, it remains unclear how algorithms compare to human judgment in contexts requiring semantic understanding and domain expertise. We examine this in the context of the judge assignment problem, matching submissions to suitably qualified judges. Specifically, we tackled this problem at the Harvard President's Innovation Challenge, the university's premier venture competition awarding over \\$500,000 to student and alumni startups. This represents a real-world environment where high-quality judge assignment is essential. We developed an AI-based judge-assignment algorithm, Hybrid Lexical-Semantic Similarity Ensemble (HLSE), and deployed it at the competition. We then evaluated its performance against human expert assignments using blinded match-quality scores from judges on $309$ judge-venture pairs. Using a Mann-Whitney U statistic based test, we found no statistically significant difference in assignment quality between the two approaches ($AUC=0.48, p=0.40$); on average, algorithmic matches are rated $3.90$ and manual matches $3.94$ on a 5-point scale, where 5 indicates an excellent match. Furthermore, manual assignments that previously required a full week could be automated in several hours by the algorithm during deployment. These results demonstrate that HLSE achieves human-expert-level matching quality while offering greater scalability and efficiency, underscoring the potential of AI-driven solutions to support and enhance human decision-making for judge assignment in high-stakes settings.", 'abstract_zh': '人工智能在法官分配问题中的应用与人类判断的比较：从哈佛总统创新挑战赛看自动化的可行性和效率', 'title_zh': '哪个更称职？人力 vs. 算法匹配法官在高 stakes 创业竞赛中的表现'}
{'arxiv_id': 'arXiv:2510.12691', 'title': 'DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization', 'authors': 'Danial Hosseintabar, Fan Chen, Giannis Daras, Antonio Torralba, Constantinos Daskalakis', 'link': 'https://arxiv.org/abs/2510.12691', 'abstract': 'Diffusion models have emerged as powerful generative priors for high-dimensional inverse problems, yet learning them when only corrupted or noisy observations are available remains challenging. In this work, we propose a new method for training diffusion models with Expectation-Maximization (EM) from corrupted data. Our proposed method, DiffEM, utilizes conditional diffusion models to reconstruct clean data from observations in the E-step, and then uses the reconstructed data to refine the conditional diffusion model in the M-step. Theoretically, we provide monotonic convergence guarantees for the DiffEM iteration, assuming appropriate statistical conditions. We demonstrate the effectiveness of our approach through experiments on various image reconstruction tasks.', 'abstract_zh': '从受污染数据中训练扩散模型的Expectation-Maximization方法：DiffEM在高维逆问题中的应用', 'title_zh': 'DiffEM：通过期望最大化解learn从带噪数据中预订扩散模型的知识'}
{'arxiv_id': 'arXiv:2510.12659', 'title': 'SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning', 'authors': 'Chih-Chuan Cheng, Yi-Ju Tseng', 'link': 'https://arxiv.org/abs/2510.12659', 'abstract': 'We propose SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding Attention with Target Aware Conditioning), a novel framework designed for supervised learning on tabular data. At its core, SG-XDEAT employs a dual-stream encoder that decomposes each input feature into two parallel representations: a raw value stream and a target-conditioned (label-aware) stream. These dual representations are then propagated through a hierarchical stack of attention-based modules. SG-XDEAT integrates three key components: (i) Cross-Dimensional self-attention, which captures intra-view dependencies among features within each stream; (ii) Cross-Encoding self-attention, which enables bidirectional interaction between raw and target-aware representations; and (iii) an Adaptive Sparse Self-Attention (ASSA) mechanism, which dynamically suppresses low-utility tokens by driving their attention weights toward zero--thereby mitigating the impact of noise. Empirical results on multiple public benchmarks show consistent gains over strong baselines, confirming that jointly modeling raw and target-aware views--while adaptively filtering noise--yields a more robust deep tabular learner.', 'abstract_zh': '我们提出了一种新型框架SG-XDEAT（稀疏性引导的跨维度和跨编码注意机制，带有目标感知条件），该框架旨在用于表格数据的监督学习。SG-XDEAT的核心采用了一种双流编码器，将每个输入特征分解为两个并行表示：原始值流和目标条件化（标签感知）流。这两种表示随后通过多级堆叠的基于注意机制的模块进行传递。SG-XDEAT结合了三个关键组件：跨维度自我注意，用于捕捉每一流内部特征间的依赖关系；跨编码自我注意，使原始和目标感知表示之间实现双向交互；以及自适应稀疏自我注意( ASSA)机制，该机制通过驱动低效令牌的注意权重趋向于零来动态抑制噪声，从而减轻噪声的影响。在多个公开基准上的实验证明，相较于强大的基线模型，联合建模原始和目标感知视图并自适应过滤噪声可以生成更 robust 的深层表格学习器。', 'title_zh': 'SG-XDEAT: 基于稀疏性指导的跨维度和跨编码注意力与目标感知条件在表格学习中的应用'}
{'arxiv_id': 'arXiv:2510.12642', 'title': 'Aixel: A Unified, Adaptive and Extensible System for AI-powered Data Analysis', 'authors': 'Meihui Zhang, Liming Wang, Chi Zhang, Zhaojing Luo', 'link': 'https://arxiv.org/abs/2510.12642', 'abstract': 'A growing trend in modern data analysis is the integration of data management with learning, guided by accuracy, latency, and cost requirements. In practice, applications draw data of different formats from many sources. In the meanwhile, the objectives and budgets change over time. Existing systems handle these applications across databases, analysis libraries, and tuning services. Such fragmentation leads to complex user interaction, limited adaptability, suboptimal performance, and poor extensibility across components. To address these challenges, we present Aixel, a unified, adaptive, and extensible system for AI-powered data analysis. The system organizes work across four layers: application, task, model, and data. The task layer provides a declarative interface to capture user intent, which is parsed into an executable operator plan. An optimizer compiles and schedules this plan to meet specified goals in accuracy, latency, and cost. The task layer coordinates the execution of data and model operators, with built-in support for reuse and caching to improve efficiency. The model layer offers versioned storage for index, metadata, tensors, and model artifacts. It supports adaptive construction, task-aligned drift detection, and safe updates that reuse shared components. The data layer provides unified data management capabilities, including indexing, constraint-aware discovery, task-aligned selection, and comprehensive feature management. With the above designed layers, Aixel delivers a user friendly, adaptive, efficient, and extensible system.', 'abstract_zh': '现代数据分析中一个 growing trend 是将数据管理与学习集成，受到准确性、延迟和成本要求的指导。在实际应用中，应用程序从多种来源获取不同格式的数据。同时，目标和预算会随时间变化。现有系统通过数据库、分析库和调优服务来处理这些应用。这种碎片化导致用户交互复杂、适应性有限、各组件间性能不佳和扩展性差。为解决这些挑战，我们提出 Aixel，一个基于 AI 的数据分析统一、适应性和可扩展系统。该系统跨越四个层次组织工作：应用层、任务层、模型层和数据层。任务层提供声明式接口捕获用户意图，并将其解析为可执行的操作计划。优化器将该计划编译和调度以满足指定的准确度、延迟和成本目标。任务层协调数据和模型操作的执行，内置支持重用和缓存以提高效率。模型层提供版本化的索引、元数据、张量和模型 artefacts 存储。它支持自适应构建、任务对齐的漂移检测和安全更新，以重用共享组件。数据层提供统一的数据管理能力，包括索引、约束感知发现、任务对齐的选择和全面的功能管理。通过上述设计的层次，Aixel 提供了一个用户友好、适应性强、高效和可扩展的系统。', 'title_zh': 'Aixel：一种统一、自适应且可扩展的AI驱动数据分析系统'}
{'arxiv_id': 'arXiv:2510.12624', 'title': 'Learning-To-Measure: In-context Active Feature Acquisition', 'authors': 'Yuta Kobayashi, Zilin Jing, Jiayu Yao, Hongseok Namkoong, Shalmali Joshi', 'link': 'https://arxiv.org/abs/2510.12624', 'abstract': 'Active feature acquisition (AFA) is a sequential decision-making problem where the goal is to improve model performance for test instances by adaptively selecting which features to acquire. In practice, AFA methods often learn from retrospective data with systematic missingness in the features and limited task-specific labels. Most prior work addresses acquisition for a single predetermined task, limiting scalability. To address this limitation, we formalize the meta-AFA problem, where the goal is to learn acquisition policies across various tasks. We introduce Learning-to-Measure (L2M), which consists of i) reliable uncertainty quantification over unseen tasks, and ii) an uncertainty-guided greedy feature acquisition agent that maximizes conditional mutual information. We demonstrate a sequence-modeling or autoregressive pre-training approach that underpins reliable uncertainty quantification for tasks with arbitrary missingness. L2M operates directly on datasets with retrospective missingness and performs the meta-AFA task in-context, eliminating per-task retraining. Across synthetic and real-world tabular benchmarks, L2M matches or surpasses task-specific baselines, particularly under scarce labels and high missingness.', 'abstract_zh': '主动特征获取的元学习（Meta-AFA）：可靠不确定性量化与不确定性引导的贪心特征获取代理', 'title_zh': '基于上下文的主动特征获取学习'}
{'arxiv_id': 'arXiv:2510.12615', 'title': 'Rethinking Knowledge Distillation: A Data Dependent Regulariser With a Negative Asymmetric Payoff', 'authors': 'Israel Mason-Williams, Gabryel Mason-Williams, Helen Yannakoudakis', 'link': 'https://arxiv.org/abs/2510.12615', 'abstract': "Knowledge distillation is often considered a compression mechanism when judged on the resulting student's accuracy and loss, yet its functional impact is poorly understood. In this work, we quantify the compression capacity of knowledge distillation and the resulting knowledge transfer from a functional perspective, decoupling compression from architectural reduction, which provides an improved understanding of knowledge distillation. We employ hypothesis testing, controls, and random control distillation to understand knowledge transfer mechanisms across data modalities. To rigorously test the breadth and limits of our analyses, we explore multiple distillation variants and analyse distillation scaling laws across model sizes. Our findings demonstrate that, while there is statistically significant knowledge transfer in some modalities and architectures, the extent of this transfer is less pronounced than anticipated, even under conditions designed to maximise knowledge sharing. Notably, in cases of significant knowledge transfer, we identify a consistent and severe asymmetric transfer of negative knowledge to the student, raising safety concerns in knowledge distillation applications. Across 12 experimental setups, 9 architectures, and 7 datasets, our findings show that knowledge distillation functions less as a compression mechanism and more as a data-dependent regulariser with a negative asymmetric payoff.", 'abstract_zh': '知识蒸馏的功能压缩能力及其知识转移机制：从功能视角量化知识蒸馏的压缩容量和知识转移', 'title_zh': '重新思考知识蒸馏：一种基于数据的正负非对称惩罚正则化项'}
{'arxiv_id': 'arXiv:2510.12604', 'title': 'SMILE: SeMantic Ids Enhanced CoLd Item Representation for Click-through Rate Prediction in E-commerce SEarch', 'authors': 'Qihang Zhao, Zhongbo Sun, Xiaoyang Zheng, Xian Guo, Siyuan Wang, Zihan Liang, Mingcan Peng, Ben Chen, Chenyi Lei', 'link': 'https://arxiv.org/abs/2510.12604', 'abstract': "With the rise of modern search and recommendation platforms, insufficient collaborative information of cold-start items exacerbates the Matthew effect of existing platform items, challenging platform diversity and becoming a longstanding issue. Existing methods align items' side content with collaborative information to transfer collaborative signals from high-popularity items to cold-start items. However, these methods fail to account for the asymmetry between collaboration and content, nor the fine-grained differences among items. To address these issues, we propose SMILE, an item representation enhancement approach based on fused alignment of semantic IDs. Specifically, we use RQ-OPQ encoding to quantize item content and collaborative information, followed by a two-step alignment: RQ encoding transfers shared collaborative signals across items, while OPQ encoding learns differentiated information of items. Comprehensive offline experiments on large-scale industrial datasets demonstrate superiority of SMILE, and rigorous online A/B tests confirm statistically significant improvements: item CTR +1.66%, buyers +1.57%, and order volume +2.17%.", 'abstract_zh': '随着现代搜索和推荐平台的兴起，冷启动项目的协作信息不足加剧了现有平台项目的马太效应，挑战了平台的多样性，成为一个长期存在的问题。现有的方法通过将热门项目的侧内容与协作信息对齐，将协作信号从热门项目转移到冷启动项目，但这些方法未能考虑到协作与内容之间的不对称性，以及项目之间的细微差别。为了解决这些问题，我们提出了基于融合语义ID对齐的项目表示增强方法SMILE。具体而言，我们使用RQ-OPQ编码对项目内容和协作信息进行量化，并通过两步对齐过程进行融合：RQ编码在项目间转移共享的协作信号，而OPQ编码学习项目的差异化信息。大规模工业数据集上的全面离线实验展示了SMILE的优势，严格的在线A/B测试也证实了显著的提升：项目点击率+1.66%，购买者+1.57%，订单量+2.17%。', 'title_zh': 'SMILE: 基于语义ID增强的冷启动项表示以提高电商平台搜索点击率预测'}
{'arxiv_id': 'arXiv:2510.12541', 'title': 'Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis', 'authors': 'Jasmin Freudenberg, Kai Hahn, Christian Weber, Madjid Fathi', 'link': 'https://arxiv.org/abs/2510.12541', 'abstract': 'The increasing popularity of portable ECG systems and the growing demand for privacy-compliant, energy-efficient real-time analysis require new approaches to signal processing at the point of data acquisition. In this context, the edge domain is acquiring increasing importance, as it not only reduces latency times, but also enables an increased level of data security. The FACE project aims to develop an innovative machine learning solution for analysing long-term electrocardiograms that synergistically combines the strengths of edge and cloud computing. In this thesis, various pre-processing steps of ECG signals are analysed with regard to their applicability in the project. The selection of suitable methods in the edge area is based in particular on criteria such as energy efficiency, processing capability and real-time capability.', 'abstract_zh': '便携式ECG系统 popularity 和对隐私合规、节能实时分析需求的不断增加促使在数据采集点采用新的信号处理方法。在这种背景下，边缘域的重要性日益凸显，不仅减少了延迟时间，还提升了数据安全水平。FACE项目旨在开发一种结合边缘计算和云计算优势的创新机器学习解决方案，用于分析长期心电图。在本论文中，分析了心电图信号的各种预处理步骤，以评估其在项目中的适用性。在边缘区域选择合适的方法时，特别考虑了能效、处理能力和实时能力等标准。', 'title_zh': '基于AI的心电图信号分析中实时预处理方法的评估'}
{'arxiv_id': 'arXiv:2510.12503', 'title': 'The Robustness of Differentiable Causal Discovery in Misspecified Scenarios', 'authors': 'Huiyang Yi, Yanyan He, Duxin Chen, Mingyu Kang, He Wang, Wenwu Yu', 'link': 'https://arxiv.org/abs/2510.12503', 'abstract': 'Causal discovery aims to learn causal relationships between variables from targeted data, making it a fundamental task in machine learning. However, causal discovery algorithms often rely on unverifiable causal assumptions, which are usually difficult to satisfy in real-world data, thereby limiting the broad application of causal discovery in practical scenarios. Inspired by these considerations, this work extensively benchmarks the empirical performance of various mainstream causal discovery algorithms, which assume i.i.d. data, under eight model assumption violations. Our experimental results show that differentiable causal discovery methods exhibit robustness under the metrics of Structural Hamming Distance and Structural Intervention Distance of the inferred graphs in commonly used challenging scenarios, except for scale variation. We also provide the theoretical explanations for the performance of differentiable causal discovery methods. Finally, our work aims to comprehensively benchmark the performance of recent differentiable causal discovery methods under model assumption violations, and provide the standard for reasonable evaluation of causal discovery, as well as to further promote its application in real-world scenarios.', 'abstract_zh': '因果发现旨在从目标数据中学习变量间的因果关系，它是机器学习中的一个基本任务。然而，因果发现算法往往依赖于难以在现实世界数据中验证的因果假设，这限制了因果发现在实际应用场景中的广泛应用。基于这些考虑，本研究在八种模型假设违反情况下，广泛评测了各类主流因果发现算法在经验性能上的表现。我们的实验结果表明，可微因果发现方法在常用的具有挑战性的场景中，除了规模变化以外，在结构汉明距离和结构干预距离的度量下表现出鲁棒性。我们还提供了可微因果发现方法性能的理论解释。最后，本研究旨在在模型假设违反情况下全面评测近期的可微因果发现方法，并提供合理的因果发现评估标准，进一步促进其在实际应用场景中的应用。', 'title_zh': '差分因果发现方法在错定模型场景下的鲁棒性'}
{'arxiv_id': 'arXiv:2510.12494', 'title': 'PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture', 'authors': 'Yi Liu, Yang Liu, Leqian Zheng, Jue Hong, Junjie Shi, Qingyou Yang, Ye Wu, Cong Wang', 'link': 'https://arxiv.org/abs/2510.12494', 'abstract': "With the rapid advancement of the digital economy, data collaboration between organizations has become a well-established business model, driving the growth of various industries. However, privacy concerns make direct data sharing impractical. To address this, Two-Party Split Learning (a.k.a. Vertical Federated Learning (VFL)) has emerged as a promising solution for secure collaborative learning. Despite its advantages, this architecture still suffers from low computational resource utilization and training efficiency. Specifically, its synchronous dependency design increases training latency, while resource and data heterogeneity among participants further hinder efficient computation. To overcome these challenges, we propose PubSub-VFL, a novel VFL paradigm with a Publisher/Subscriber architecture optimized for two-party collaborative learning with high computational efficiency. PubSub-VFL leverages the decoupling capabilities of the Pub/Sub architecture and the data parallelism of the parameter server architecture to design a hierarchical asynchronous mechanism, reducing training latency and improving system efficiency. Additionally, to mitigate the training imbalance caused by resource and data heterogeneity, we formalize an optimization problem based on participants' system profiles, enabling the selection of optimal hyperparameters while preserving privacy. We conduct a theoretical analysis to demonstrate that PubSub-VFL achieves stable convergence and is compatible with security protocols such as differential privacy. Extensive case studies on five benchmark datasets further validate its effectiveness, showing that, compared to state-of-the-art baselines, PubSub-VFL not only accelerates training by $2 \\sim 7\\times$ without compromising accuracy, but also achieves a computational resource utilization rate of up to 91.07%.", 'abstract_zh': '随着数字经济的迅速发展，组织间的数据协作已成为成熟的商业模式，推动了各行各业的增长。然而，隐私问题使得直接数据共享变得 impractical。为解决这一问题，双方拆分学习（即垂直联邦学习 VFL）已 emergence 为一种有前景的安全协作学习解决方案。尽管 VFL 具有优势，但该架构仍面临计算资源利用率低和训练效率低的问题。具体而言，其同步依赖设计增加了训练延迟，而参与者之间资源和数据异构性进一步妨碍了高效的计算。为克服这些挑战，我们提出 PubSub-VFL，这是一种优化的面向高计算效率的双方协作学习的新 VFL 模式，采用发布者/订阅者架构。PubSub-VFL 利用了发布者/订阅者架构的解耦能力和参数服务器架构的数据并行性，设计了一种分层异步机制，从而减少训练延迟并提高系统效率。此外，为了缓解资源和数据异构性引起的训练不平衡，我们基于参与者系统配置形式化了一个优化问题，能够在保持隐私的前提下选择最优超参数。我们进行理论分析以证明 PubSub-VFL 实现了稳定收敛，并且兼容差分隐私等安全协议。通过对五个基准数据集的广泛案例研究进一步验证其有效性，结果表明，与当前最佳基线相比，PubSub-VFL 不仅在不牺牲准确性的基础上将训练速度加快了 2 到 7 倍，而且还实现了高达 91.07% 的计算资源利用率。', 'title_zh': 'PubSub-VFL：面向异构环境高效双方拆分学习的发布者/订阅者架构'}
{'arxiv_id': 'arXiv:2510.12451', 'title': 'A Function Centric Perspective On Flat and Sharp Minima', 'authors': 'Israel Mason-Williams, Gabryel Mason-Williams, Helen Yannakoudakis', 'link': 'https://arxiv.org/abs/2510.12451', 'abstract': 'Flat minima are widely believed to correlate with improved generalisation in deep neural networks. However, this connection has proven more nuanced in recent studies, with both theoretical counterexamples and empirical exceptions emerging in the literature. In this paper, we revisit the role of sharpness in model performance, proposing that sharpness is better understood as a function-dependent property rather than a reliable indicator of poor generalisation. We conduct extensive empirical studies, from single-objective optimisation to modern image classification tasks, showing that sharper minima often emerge when models are regularised (e.g., via SAM, weight decay, or data augmentation), and that these sharp minima can coincide with better generalisation, calibration, robustness, and functional consistency. Across a range of models and datasets, we find that baselines without regularisation tend to converge to flatter minima yet often perform worse across all safety metrics. Our findings demonstrate that function complexity, rather than flatness alone, governs the geometry of solutions, and that sharper minima can reflect more appropriate inductive biases (especially under regularisation), calling for a function-centric reappraisal of loss landscape geometry.', 'abstract_zh': '平坦极小值广泛认为与深度神经网络的泛化能力改进相关。然而，最近的研究表明，这种关联性更为复杂，理论上的反例和文献中的经验例外情况相继出现。在本文中，我们重新审视模型性能中的sharpness作用，提出sharpness应被视为一种函数相关的属性，而非不良泛化可靠的指示器。我们进行了广泛的实证研究，从单目标优化到现代图像分类任务，表明当模型正则化时（例如，通过SAM、权重衰减或数据增强），往往会形成更尖锐的极小值，并且这些更尖锐的极小值可以与更好的泛化、校准、鲁棒性和功能一致性相一致。在多种模型和数据集上，我们发现无正则化的基线倾向于收敛于更平坦的极小值，但在所有安全指标上通常表现更差。我们的发现表明，函数复杂性而非平坦性单独决定了解的空间几何结构，并且更尖锐的极小值可能反映了更合适的方向性偏差（特别是在正则化下），呼吁从函数中心的角度重新评估损失景观的几何结构。', 'title_zh': '以功能为中心视角下的扁平和尖锐最小值'}
{'arxiv_id': 'arXiv:2510.12384', 'title': 'Phenome-Wide Multi-Omics Integration Uncovers Distinct Archetypes of Human Aging', 'authors': 'Huifa Li, Feilong Tang, Haochen Xue, Yulong Li, Xinlin Zhuang, Bin Zhang, Eran Segal, Imran Razzak', 'link': 'https://arxiv.org/abs/2510.12384', 'abstract': 'Aging is a highly complex and heterogeneous process that progresses at different rates across individuals, making biological age (BA) a more accurate indicator of physiological decline than chronological age. While previous studies have built aging clocks using single-omics data, they often fail to capture the full molecular complexity of human aging. In this work, we leveraged the Human Phenotype Project, a large-scale cohort of 12,000 adults aged 30--70 years, with extensive longitudinal profiling that includes clinical, behavioral, environmental, and multi-omics datasets -- spanning transcriptomics, lipidomics, metabolomics, and the microbiome. By employing advanced machine learning frameworks capable of modeling nonlinear biological dynamics, we developed and rigorously validated a multi-omics aging clock that robustly predicts diverse health outcomes and future disease risk. Unsupervised clustering of the integrated molecular profiles from multi-omics uncovered distinct biological subtypes of aging, revealing striking heterogeneity in aging trajectories and pinpointing pathway-specific alterations associated with different aging patterns. These findings demonstrate the power of multi-omics integration to decode the molecular landscape of aging and lay the groundwork for personalized healthspan monitoring and precision strategies to prevent age-related diseases.', 'abstract_zh': '人类表型项目揭示的多组学衰老时钟：分子景观的解码与个性化健康寿 span 监测的基础', 'title_zh': '全表型多组学整合揭示人类衰老的不同原型'}
{'arxiv_id': 'arXiv:2510.12379', 'title': 'LiteVPNet: A Lightweight Network for Video Encoding Control in Quality-Critical Applications', 'authors': 'Vibhoothi Vibhoothi, François Pitié, Anil Kokaram', 'link': 'https://arxiv.org/abs/2510.12379', 'abstract': "In the last decade, video workflows in the cinema production ecosystem have presented new use cases for video streaming technology. These new workflows, e.g. in On-set Virtual Production, present the challenge of requiring precise quality control and energy efficiency. Existing approaches to transcoding often fall short of these requirements, either due to a lack of quality control or computational overhead. To fill this gap, we present a lightweight neural network (LiteVPNet) for accurately predicting Quantisation Parameters for NVENC AV1 encoders that achieve a specified VMAF score. We use low-complexity features, including bitstream characteristics, video complexity measures, and CLIP-based semantic embeddings. Our results demonstrate that LiteVPNet achieves mean VMAF errors below 1.2 points across a wide range of quality targets. Notably, LiteVPNet achieves VMAF errors within 2 points for over 87% of our test corpus, c.f. approx 61% with state-of-the-art methods. LiteVPNet's performance across various quality regions highlights its applicability for enhancing high-value content transport and streaming for more energy-efficient, high-quality media experiences.", 'abstract_zh': '过去十年，电影生产生态系统中的视频工作流为视频流技术提出了新的应用场景。这些新的工作流，例如现场虚拟制作，要求精确的质量控制和能源效率。现有的转码方法常常无法满足这些要求，要么是因为缺乏质量控制，要么是因为计算开销过大。为填补这一空白，我们提出了一种轻量级神经网络（LiteVPNet），用于准确预测NVENC AV1编码器的量化参数，以达到指定的VMAF分数。我们使用低复杂度特征，包括比特流特性、视频复杂度度量和基于CLIP的语义嵌入。我们的结果显示，LiteVPNet在多种质量目标范围内实现了平均VMAF误差低于1.2分。值得注意的是，LiteVPNet在超过87%的测试数据集中实现了VMAF误差在2分以内，相比之下，最先进的方法约为61%。LiteVPNet在不同质量区域的性能突显了其在提升高价值内容传输和流媒体以实现更高效、高质量媒体体验方面的应用潜力。', 'title_zh': 'LiteVPNet：一种适用于质量关键应用的 Lightweight 视频编码控制网络'}
{'arxiv_id': 'arXiv:2510.12376', 'title': 'Deep Attention-guided Adaptive Subsampling', 'authors': 'Sharath M Shankaranarayana, Soumava Kumar Roy, Prasad Sudhakar, Chandan Aladahalli', 'link': 'https://arxiv.org/abs/2510.12376', 'abstract': 'Although deep neural networks have provided impressive gains in performance, these improvements often come at the cost of increased computational complexity and expense. In many cases, such as 3D volume or video classification tasks, not all slices or frames are necessary due to inherent redundancies. To address this issue, we propose a novel learnable subsampling framework that can be integrated into any neural network architecture. Subsampling, being a nondifferentiable operation, poses significant challenges for direct adaptation into deep learning models. While some works, have proposed solutions using the Gumbel-max trick to overcome the problem of non-differentiability, they fall short in a crucial aspect: they are only task-adaptive and not inputadaptive. Once the sampling mechanism is learned, it remains static and does not adjust to different inputs, making it unsuitable for real-world applications. To this end, we propose an attention-guided sampling module that adapts to inputs even during inference. This dynamic adaptation results in performance gains and reduces complexity in deep neural network models. We demonstrate the effectiveness of our method on 3D medical imaging datasets from MedMNIST3D as well as two ultrasound video datasets for classification tasks, one of them being a challenging in-house dataset collected under real-world clinical conditions.', 'abstract_zh': '虽然深度神经网络在性能上取得了显著进展，但这些改进往往伴随着计算复杂度和成本的增加。在许多情况下，如3D体数据或视频分类任务中，由于固有的冗余性，并非所有切片或帧都是必需的。为解决这一问题，我们提出了一种新颖的学习可变采样框架，可以集成到任何神经网络架构中。由于采样操作非可微，直接将其适配到深度学习模型中面临重大挑战。尽管一些工作提出使用Gumbel-max技巧来克服非可微性问题，但它们在关键方面存在不足：仅任务适配而非输入适配。一旦采样机制被学习，它将保持静态，不针对不同的输入进行调整，使其不适合实际应用。为解决这个问题，我们提出了一种注意力引导的采样模块，即使在推理过程中也能适应输入。这种动态适应性在深度神经网络模型中带来了性能提升并降低了复杂度。我们在MedMNIST3D的3D医学成像数据集以及两个超声视频数据集上的分类任务中验证了该方法的有效性，其中一个数据集是基于实际临床条件收集的具有挑战性的内部数据集。', 'title_zh': '深注意力导向自适应子采样'}
{'arxiv_id': 'arXiv:2510.12364', 'title': '(R)evolution of Programming: Vibe Coding as a Post-Coding Paradigm', 'authors': 'Kevin Krings, Nino S. Bohn, Thomas Ludwig', 'link': 'https://arxiv.org/abs/2510.12364', 'abstract': 'Recent advancements in generative artificial intelligence (GenAI), particularly large language models, have introduced new possibilities for software development practices. In our paper we investigate the emerging Vibe Coding (VC) paradigm that emphasizes intuitive, affect-driven, and improvisational interactions between developers and AI systems. Building upon the discourse of End-User Development (EUD), we explore how VC diverges from conventional programming approaches such as those supported by tools like GitHub Copilot. Through five semi-structured interview sessions with ten experienced software practitioners, we identify five thematic dimensions: creativity, sustainability, the future of programming, collaboration, and criticism. Our analysis conceptualizes VC within the metaphor of co-drifting, contrasting it with the prevalent co-piloting perspective of AI-assisted development. We argue that VC reconfigures the developers role, blurring boundaries between professional and non-developers. While VC enables novel forms of expression and rapid prototyping, it also introduces challenges regarding reproducibility, scalability, and inclusivity. We propose that VC represents a meaningful shift in programming culture, warranting further investigation within human-computer interaction (HCI) and software engineering research.', 'abstract_zh': '近年来，生成型人工智能（GenAI），特别是大型语言模型，为软件开发实践带来了新的可能性。在本文中，我们探讨了新兴的 vibes 编码（VC）范式，该范式强调开发人员与AI系统之间直观、情感驱动和即兴的互动。基于用户中心开发（EUD）的讨论，我们探究了VC与GitHub Copilot等工具支持的传统编程方法之间的差异。通过与十名经验丰富的软件从业人员进行五次半结构化访谈，我们确定了五个主题维度：创造力、可持续性、编程的未来、协作和批判。我们的分析将VC的概念化为共驾的隐喻，将其与常见的共驾驶模式（即AI辅助开发）进行了对比。我们认为，VC重新配置了开发人员的角色，模糊了专业开发人员与非开发人员之间的界限。虽然VC能够促成新的表达形式和快速的原型设计，但也带来了可重复性、可扩展性和包容性方面的挑战。我们提出，VC代表了编程文化的重要转变，值得在人机交互（HCI）和软件工程研究中进行进一步探讨。', 'title_zh': '编程的(R)evolution: Vibe Coding作为后编码范式'}
{'arxiv_id': 'arXiv:2510.12334', 'title': 'Finite-time Convergence Analysis of Actor-Critic with Evolving Reward', 'authors': 'Rui Hu, Yu Chen, Longbo Huang', 'link': 'https://arxiv.org/abs/2510.12334', 'abstract': 'Many popular practical reinforcement learning (RL) algorithms employ evolving reward functions-through techniques such as reward shaping, entropy regularization, or curriculum learning-yet their theoretical foundations remain underdeveloped. This paper provides the first finite-time convergence analysis of a single-timescale actor-critic algorithm in the presence of an evolving reward function under Markovian sampling. We consider a setting where the reward parameters may change at each time step, affecting both policy optimization and value estimation. Under standard assumptions, we derive non-asymptotic bounds for both actor and critic errors. Our result shows that an $O(1/\\sqrt{T})$ convergence rate is achievable, matching the best-known rate for static rewards, provided the reward parameters evolve slowly enough. This rate is preserved when the reward is updated via a gradient-based rule with bounded gradient and on the same timescale as the actor and critic, offering a theoretical foundation for many popular RL techniques. As a secondary contribution, we introduce a novel analysis of distribution mismatch under Markovian sampling, improving the best-known rate by a factor of $\\log^2T$ in the static-reward case.', 'abstract_zh': '许多流行的实用强化学习（RL）算法通过奖励塑形、熵正则化或课程学习等技术使用演变的奖励函数，但其理论基础仍不成熟。本文提供了第一个在马尔可夫采样下，单时间尺度演员-评论家算法在存在演变奖励函数情况下的有限时间收敛分析。我们考虑奖励参数在每一时间步都可能发生变化，影响策略优化和价值估计的情况。在标准假设下，我们推导了演员和评论家误差的非退化边界。我们的结果显示，在奖励参数变化足够缓慢的情况下，可以实现$O(1/\\sqrt{T})$的收敛率，与静态奖励的最佳已知率一致。当奖励通过具有有界梯度的梯度规则在与演员和评论家相同的时间尺度上更新时，这一速率得以保持，为许多流行的RL技术提供了理论基础。作为次要贡献，我们引入了一种关于马尔可夫采样下分布不匹配的新型分析，将静态奖励情况下最佳已知率提高了$\\log^2T$的因素。', 'title_zh': '有限时间收敛性分析：随动奖励的演员-评论家方法'}
{'arxiv_id': 'arXiv:2510.12327', 'title': 'Simple Projection Variants Improve ColBERT Performance', 'authors': 'Benjamin Clavié, Sean Lee, Rikiya Takehi, Aamir Shakir, Makoto P. Kato', 'link': 'https://arxiv.org/abs/2510.12327', 'abstract': 'Multi-vector dense retrieval methods like ColBERT systematically use a single-layer linear projection to reduce the dimensionality of individual vectors. In this study, we explore the implications of the MaxSim operator on the gradient flows of the training of multi-vector models and show that such a simple linear projection has inherent, if non-critical, limitations in this setting. We then discuss the theoretical improvements that could result from replacing this single-layer projection with well-studied alternative feedforward linear networks (FFN), such as deeper, non-linear FFN blocks, GLU blocks, and skip-connections, could alleviate these limitations. Through the design and systematic evaluation of alternate projection blocks, we show that better-designed final projections positively impact the downstream performance of ColBERT models. We highlight that many projection variants outperform the original linear projections, with the best-performing variants increasing average performance on a range of retrieval benchmarks across domains by over 2 NDCG@10 points. We then conduct further exploration on the individual parameters of these projections block in order to understand what drives this empirical performance, highlighting the particular importance of upscaled intermediate projections and residual connections. As part of these ablation studies, we show that numerous suboptimal projection variants still outperform the traditional single-layer projection across multiple benchmarks, confirming our hypothesis. Finally, we observe that this effect is consistent across random seeds, further confirming that replacing the linear layer of ColBERT models is a robust, drop-in upgrade.', 'abstract_zh': 'Multi-向量密集检索方法如ColBERT通过单层线性投影系统地降低单个向量的维度。在本研究中，我们探讨了MaxSim操作符在多向量模型训练的梯度流动中的影响，并表明这种简单的线性投影在这种情况下具有内在的，尽管不是关键的限制。然后，我们讨论了用研究广泛的替代前向线性网络（FFN），如更深的非线性FFN块、GLU块和跳连，替换这种单层投影可能带来的理论改进，这些改进可能缓解这些限制。通过设计并系统评估替代投影块，我们表明设计更好的最终投影可正向影响ColBERT模型的下游性能。我们指出，许多投影变体性能优于原始线性投影，最佳变体在多个领域的一系列检索基准上将平均性能提高了超过2个NDCG@10点。作为进一步的探索，我们研究了这些投影块的个体参数，以了解其驱动实际性能的因素，强调了放大的中间投影和残差连接的特殊重要性。作为这些消融研究的一部分，我们还展示了在多个基准上，许多不足的投影变体仍然优于传统的单层投影，进一步证实了我们的假设。最后，我们观察到这种效果在随机种子上是一致的，进一步证实了用替代的FFN块替换ColBERT模型的线性层是一个稳健且即插即用的升级。', 'title_zh': '简单的投影变体能提高ColBERT性能'}
{'arxiv_id': 'arXiv:2510.12325', 'title': 'Causal Inspired Multi Modal Recommendation', 'authors': 'Jie Yang, Chenyang Gu, Zixuan Liu', 'link': 'https://arxiv.org/abs/2510.12325', 'abstract': 'Multimodal recommender systems enhance personalized recommendations in e-commerce and online advertising by integrating visual, textual, and user-item interaction data. However, existing methods often overlook two critical biases: (i) modal confounding, where latent factors (e.g., brand style or product category) simultaneously drive multiple modalities and influence user preference, leading to spurious feature-preference associations; (ii) interaction bias, where genuine user preferences are mixed with noise from exposure effects and accidental clicks. To address these challenges, we propose a Causal-inspired multimodal Recommendation framework. Specifically, we introduce a dual-channel cross-modal diffusion module to identify hidden modal confounders, utilize back-door adjustment with hierarchical matching and vector-quantized codebooks to block confounding paths, and apply front-door adjustment combined with causal topology reconstruction to build a deconfounded causal subgraph. Extensive experiments on three real-world e-commerce datasets demonstrate that our method significantly outperforms state-of-the-art baselines while maintaining strong interpretability.', 'abstract_zh': '多模态推荐系统通过整合视觉、文本和用户-物品交互数据来增强电子商务和在线广告中的个性化推荐。然而，现有方法往往忽视了两种关键偏差：（i）模态混杂，其中潜在因素（如品牌风格或产品类别）同时驱动多种模态并对用户偏好产生影响，导致虚假的特征-偏好关联；（ii）交互偏差，其中真实的用户偏好被曝光效应和随机点击的噪声所混杂。为解决这些挑战，我们提出了一种因果启发式多模态推荐框架。具体来说，我们引入了双通道跨模态扩散模块来识别隐藏的模态混杂因素，利用后门调整结合分层匹配和向量量化码本来阻断混杂路径，并应用前门调整结合因果拓扑重构来构建去混杂的因果子图。在三个真实世界的电子商务数据集上的广泛实验表明，我们的方法显著优于最先进的基线方法，同时保持较强的可解释性。', 'title_zh': '因果驱动多模态推荐'}
{'arxiv_id': 'arXiv:2510.12278', 'title': 'Quantum Annealing for Staff Scheduling in Educational Environments', 'authors': 'Alessia Ciacco, Francesca Guerriero, Eneko Osaba', 'link': 'https://arxiv.org/abs/2510.12278', 'abstract': 'We address a novel staff allocation problem that arises in the organization of collaborators among multiple school sites and educational levels. The problem emerges from a real case study in a public school in Calabria, Italy, where staff members must be distributed across kindergartens, primary, and secondary schools under constraints of availability, competencies, and fairness. To tackle this problem, we develop an optimization model and investigate a solution approach based on quantum annealing. Our computational experiments on real-world data show that quantum annealing is capable of producing balanced assignments in short runtimes. These results provide evidence of the practical applicability of quantum optimization methods in educational scheduling and, more broadly, in complex resource allocation tasks.', 'abstract_zh': '一种新型的学校多校区、多层级合作人员分配问题及其解决方案研究', 'title_zh': '量子退火在教育环境中的人员调度中应用'}
{'arxiv_id': 'arXiv:2510.12275', 'title': 'TFGA-Net: Temporal-Frequency Graph Attention Network for Brain-Controlled Speaker Extraction', 'authors': 'Youhao Si, Yuan Liao, Qiushi Han, Yuhang Yang, Rui Dai, Liya Huang', 'link': 'https://arxiv.org/abs/2510.12275', 'abstract': 'The rapid development of auditory attention decoding (AAD) based on electroencephalography (EEG) signals offers the possibility EEG-driven target speaker extraction. However, how to effectively utilize the target-speaker common information between EEG and speech remains an unresolved problem. In this paper, we propose a model for brain-controlled speaker extraction, which utilizes the EEG recorded from the listener to extract the target speech. In order to effectively extract information from EEG signals, we derive multi-scale time--frequency features and further incorporate cortical topological structures that are selectively engaged during the task. Moreover, to effectively exploit the non-Euclidean structure of EEG signals and capture their global features, the graph convolutional networks and self-attention mechanism are used in the EEG encoder. In addition, to make full use of the fused EEG and speech feature and preserve global context and capture speech rhythm and prosody, we introduce MossFormer2 which combines MossFormer and RNN-Free Recurrent as separator. Experimental results on both the public Cocktail Party and KUL dataset in this paper show that our TFGA-Net model significantly outper-forms the state-of-the-art method in certain objective evaluation metrics. The source code is available at: this https URL.', 'abstract_zh': '基于脑电图信号的听觉注意力解码快速发展为通过脑电图驱动的目标说话人提取提供了可能性。然而，如何有效利用EEG和语音之间的目标说话人公共信息仍然是一个未 resolves 的问题。本文提出了一种脑控制说话人提取模型，利用听众记录的脑电图提取目标语音。为了有效从EEG信号中提取信息，我们推导出了多尺度时频特征，并进一步结合了在任务中选择性参与的大脑皮层拓扑结构。此外，为了解决EEG信号的非欧几里得结构并通过捕获其全局特征来充分利用这些信息，我们在EEG编码器中使用了图卷积网络和自我注意力机制。此外，为充分利用融合后的EEG和语音特征并保持全局上下文和捕捉语音节奏和语调，我们引入了结合MossFormer和RNN-Free Recurrent的MossFormer2作为分离器。本文在公开的Cocktail Party和KUL数据集上的实验结果表明，我们的TFGA-Net模型在某些客观评价指标上显著优于最新方法。源代码可在以下链接获取：this https URL。', 'title_zh': 'TFGA-Net：用于脑控语音提取的时频图注意网络'}
{'arxiv_id': 'arXiv:2510.12214', 'title': 'DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification', 'authors': 'Tao Xie, Zexi Tan, Haoyi Xiao, Binbin Sun, Yiqun Zhang', 'link': 'https://arxiv.org/abs/2510.12214', 'abstract': 'Early time-series classification (ETSC) in medical applications is crucial for time-sensitive scenarios such as sepsis prediction in intensive care units (ICUs), where a large number of deaths are caused by delayed prediction. ETSC can significantly improve ICU resource utilization efficiency and healthcare precision. However, it faces conflicting goals of accuracy and earliness, with existing methods often trading one for the other, struggling to capture subtle early-stage patterns due to weak initial signals and class imbalance. The key to solve these challenges is to find shapelets, which are discriminative subsequences (or shapes) with high interpretability in time-series classification. This paper proposes Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification (DE3S), which introduces a novel Dual-Enhanced Soft-Shape Learning framework to figure out shapelets precisely through three innovations: (1) a comprehensive dual-enhancement strategy combines traditional temporal augmentation with attention-based global temporal enhancement for robust representation learning, (2) an attention-score-based soft shapelet sparsification mechanism dynamically preserves discriminative patterns while aggregating less important shapelets into representative tokens, and (3) a dual-path Mixture of Experts Network (MoE) and Inception modules fusion architecture where MoE performs local learning within shapelets and multi-scale Inception modules capture global patterns across shapelets. The framework employs weighted cross-entropy loss for class imbalance handling and demonstrates robustness on subject-consistency datasets. Extensive experiments on six real-world medical datasets show state-of-the-art performance, with ablation studies confirming component efficacy.', 'abstract_zh': '医学早期时间序列分类中的双增强软稀疏形状学习（DE3S）', 'title_zh': 'DE3S: 双增强软稀疏形状学习在医疗早期时间序列分类中的应用'}
{'arxiv_id': 'arXiv:2510.12209', 'title': 'Revisiting Meta-Learning with Noisy Labels: Reweighting Dynamics and Theoretical Guarantees', 'authors': 'Yiming Zhang, Chester Holtz, Gal Mishne, Alex Cloninger', 'link': 'https://arxiv.org/abs/2510.12209', 'abstract': 'Learning with noisy labels remains challenging because over-parameterized networks memorize corrupted supervision. Meta-learning-based sample reweighting mitigates this by using a small clean subset to guide training, yet its behavior and training dynamics lack theoretical understanding. We provide a rigorous theoretical analysis of meta-reweighting under label noise and show that its training trajectory unfolds in three phases: (i) an alignment phase that amplifies examples consistent with a clean subset and suppresses conflicting ones; (ii) a filtering phase driving noisy example weights toward zero until the clean subset loss plateaus; and (iii) a post-filtering phase in which noise filtration becomes perturbation-sensitive. The mechanism is a similarity-weighted coupling between training and clean subset signals together with clean subset training loss contraction; in the post-filtering regime where the clean-subset loss is sufficiently small, the coupling term vanishes and meta-reweighting loses discriminatory power. Guided by this analysis, we propose a lightweight surrogate for meta-reweighting that integrates mean-centering, row shifting, and label-signed modulation, yielding more stable performance while avoiding expensive bi-level optimization. Across synthetic and real noisy-label benchmarks, our method consistently outperforms strong reweighting/selection baselines.', 'abstract_zh': '基于元学习的样本加权在标签噪声下的理论分析及应用', 'title_zh': '重访带有噪声标签的元学习：加权动态及其理论保证'}
{'arxiv_id': 'arXiv:2510.12144', 'title': 'Budget-constrained Active Learning to Effectively De-censor Survival Data', 'authors': 'Ali Parsaee, Bei Jiang, Zachary Friggstad, Russell Greiner', 'link': 'https://arxiv.org/abs/2510.12144', 'abstract': "Standard supervised learners attempt to learn a model from a labeled dataset. Given a small set of labeled instances, and a pool of unlabeled instances, a budgeted learner can use its given budget to pay to acquire the labels of some unlabeled instances, which it can then use to produce a model. Here, we explore budgeted learning in the context of survival datasets, which include (right) censored instances, where we know only a lower bound on an instance's time-to-event. Here, that learner can pay to (partially) label a censored instance -- e.g., to acquire the actual time for an instance [perhaps go from (3 yr, censored) to (7.2 yr, uncensored)], or other variants [e.g., learn about one more year, so go from (3 yr, censored) to either (4 yr, censored) or perhaps (3.2 yr, uncensored)]. This serves as a model of real world data collection, where follow-up with censored patients does not always lead to uncensoring, and how much information is given to the learner model during data collection is a function of the budget and the nature of the data itself. We provide both experimental and theoretical results for how to apply state-of-the-art budgeted learning algorithms to survival data and the respective limitations that exist in doing so. Our approach provides bounds and time complexity asymptotically equivalent to the standard active learning method BatchBALD. Moreover, empirical analysis on several survival tasks show that our model performs better than other potential approaches on several benchmarks.", 'abstract_zh': '预算化学习在生存数据中的应用与其限制研究', 'title_zh': '预算约束下的主动学习以有效解密生存数据'}
{'arxiv_id': 'arXiv:2510.12133', 'title': 'SafeMT: Multi-turn Safety for Multimodal Language Models', 'authors': 'Han Zhu, Juntao Dai, Jiaming Ji, Haoran Li, Chengkun Cai, Pengcheng Wen, Chi-Min Chan, Boyuan Chen, Yaodong Yang, Sirui Han, Yike Guo', 'link': 'https://arxiv.org/abs/2510.12133', 'abstract': 'With the widespread use of multi-modal Large Language models (MLLMs), safety issues have become a growing concern. Multi-turn dialogues, which are more common in everyday interactions, pose a greater risk than single prompts; however, existing benchmarks do not adequately consider this situation. To encourage the community to focus on the safety issues of these models in multi-turn dialogues, we introduce SafeMT, a benchmark that features dialogues of varying lengths generated from harmful queries accompanied by images. This benchmark consists of 10,000 samples in total, encompassing 17 different scenarios and four jailbreak methods. Additionally, we propose Safety Index (SI) to evaluate the general safety of MLLMs during conversations. We assess the safety of 17 models using this benchmark and discover that the risk of successful attacks on these models increases as the number of turns in harmful dialogues rises. This observation indicates that the safety mechanisms of these models are inadequate for recognizing the hazard in dialogue interactions. We propose a dialogue safety moderator capable of detecting malicious intent concealed within conversations and providing MLLMs with relevant safety policies. Experimental results from several open-source models indicate that this moderator is more effective in reducing multi-turn ASR compared to existed guard models.', 'abstract_zh': '随着多模态大型语言模型（MLLMs）的广泛应用，安全性问题已成为一个日益增长的担忧。针对更常见的多轮对话，其中的风险高于单个提示，但现有基准并未充分考虑这种情况。为了鼓励社区关注这些模型在多轮对话中的安全性问题，我们引入了SafeMT基准，该基准包含由有害查询生成的不同长度的对话并配以图像。该基准共计包含10,000个样本，涵盖了17种不同的场景和四种脱羁方法。此外，我们提出了安全性指数（SI）来评估MLLMs在对话期间的一般安全性。我们使用该基准对17个模型进行了安全性评估，并发现随着有害对话轮次的增加，这些模型遭受成功攻击的风险也会增加。这一观察结果表明，这些模型的安全机制不足以识别对话交互中的危险。我们提出了一个能够检测隐藏在对话中的恶意意图并为MLLMs提供相关安全策略的对话安全审查员。来自几个开源模型的实验结果表明，该审查员在减少多轮ASR方面比现有的防护模型更为有效。', 'title_zh': 'SafeMT：多轮多模态语言模型安全性'}
{'arxiv_id': 'arXiv:2510.12111', 'title': 'Chimera: State Space Models Beyond Sequences', 'authors': 'Aakash Lahoti, Tanya Marwah, Ratish Puduppully, Albert Gu', 'link': 'https://arxiv.org/abs/2510.12111', 'abstract': "Transformer-based deep learning methods have become the standard approach for modeling diverse data such as sequences, images, and graphs. These methods rely on self-attention, which treats data as an unordered set of elements. This ignores the neighborhood structure or graph topology of the data and requires inductive biases--such as position embeddings in sequences and images, or random walks in graphs--to incorporate topology. However, designing such task-specific biases requires significant effort and can introduce side effects that hinder generalization. We introduce Chimera, a unified model that directly incorporates data topology in a principled way, removing the need for domain-specific biases. The key idea is that state space models--which naturally do not require position embeddings--can be generalized to capture any graph topology. Our experiments show that Chimera achieves strong performance across language, vision, and graph domains, outperforming BERT on GLUE by 0.7 points, ViT on ImageNet-1k by 2.6%, and all baselines on the Long Range Graph Benchmark. We further propose algorithmic optimizations to improve Chimera's efficiency: (1) for Directed Acyclic Graphs, Chimera can be implemented as a linear-time recurrence; (2) for general graphs, a simple mathematical relaxation achieves Transformer's quadratic complexity without domain-specific heuristics. These results validate Chimera's core contribution and support the idea that data topology is a powerful inductive bias across modalities.", 'abstract_zh': '基于Transformer的深度学习方法已成为建模序列、图像和图形等多样化数据的标准方法。这些方法依赖于自注意力机制，将数据视为无序元素集合。这种方法忽视了数据的邻域结构或图形拓扑，并需要诱导偏置——如序列和图像中的位置嵌入，或图形中的随机游走——来包含拓扑信息。然而，设计此类任务特定的偏置需要大量工作，并可能引入抑制泛化的副作用。我们提出Chimera，这是一种统一模型，可以直接以合乎原理的方式融入数据拓扑，从而消除领域特定偏置的需要。核心思想是，状态空间模型——自然不需要位置嵌入——可以推广以捕捉任何图形拓扑。我们的实验表明，Chimera在语言、视觉和图形领域均表现出色，在GLUE上优于BERT 0.7分，在ImageNet-1k上优于ViT 2.6%，在长范围图形基准上优于所有基线。我们还提出了算法优化以提高Chimera的效率：（1）对于有向无环图，Chimera可以实现为线性时间递归；（2）对于通用图形，一种简单的数学松弛在不使用领域特定启发式的情况下实现了Transformer的二次复杂性。这些结果验证了Chimera的核心贡献，并支持数据拓扑是一种强大的诱导偏置的想法，适用于各种模态。', 'title_zh': 'Chimera: 状态空间模型超越序列'}
{'arxiv_id': 'arXiv:2510.12082', 'title': 'Enhancing Neural Code Representation with Additional Context', 'authors': 'Huy Nguyen, Christoph Treude, Patanamon Thongtanunam', 'link': 'https://arxiv.org/abs/2510.12082', 'abstract': 'Automated program comprehension underpins many software engineering tasks, from code summarisation to clone detection. Recent deep learning models achieve strong results but typically rely on source code alone, overlooking contextual information such as version history or structural relationships. This limits their ability to capture how code evolves and operates. We conduct an empirical study on how enriching code representations with such contextual signals affects neural model performance on key comprehension tasks. Two downstream tasks, code clone detection and code summarisation, are evaluated using SeSaMe (1,679 Java methods) and CodeSearchNet (63,259 methods). Five representative models (CodeBERT, GraphCodeBERT, CodeT5, PLBART, ASTNN) are fine-tuned under code-only and context-augmented settings. Results show that context generally improves performance: version history consistently boosts clone detection (e.g., CodeT5 +15.92% F1) and summarisation (e.g., GraphCodeBERT +5.56% METEOR), while call-graph effects vary by model and task. Combining multiple contexts yields further gains (up to +21.48% macro-F1). Human evaluation on 100 Java snippets confirms that context-augmented summaries are significantly preferred for Accuracy and Content Adequacy (p <= 0.026; |delta| up to 0.55). These findings highlight the potential of contextual signals to enhance code comprehension and open new directions for optimising contextual encoding in neural SE models.', 'abstract_zh': '基于上下文的代码表示增强对程序理解任务的神经模型性能影响研究', 'title_zh': '增强神经代码表示的额外上下文方法'}
{'arxiv_id': 'arXiv:2510.12070', 'title': 'MEASURE: Multi-scale Minimal Sufficient Representation Learning for Domain Generalization in Sleep Staging', 'authors': 'Sangmin Jo, Jee Seok Yoon, Wootaek Jeong, Kwanseok Oh, Heung-Il Suk', 'link': 'https://arxiv.org/abs/2510.12070', 'abstract': 'Deep learning-based automatic sleep staging has significantly advanced in performance and plays a crucial role in the diagnosis of sleep disorders. However, those models often struggle to generalize on unseen subjects due to variability in physiological signals, resulting in degraded performance in out-of-distribution scenarios. To address this issue, domain generalization approaches have recently been studied to ensure generalized performance on unseen domains during training. Among those techniques, contrastive learning has proven its validity in learning domain-invariant features by aligning samples of the same class across different domains. Despite its potential, many existing methods are insufficient to extract adequately domain-invariant representations, as they do not explicitly address domain characteristics embedded within the unshared information across samples. In this paper, we posit that mitigating such domain-relevant attributes-referred to as excess domain-relevant information-is key to bridging the domain gap. However, the direct strategy to mitigate the domain-relevant attributes often overfits features at the high-level information, limiting their ability to leverage the diverse temporal and spectral information encoded in the multiple feature levels. To address these limitations, we propose a novel MEASURE (Multi-scalE minimAl SUfficient Representation lEarning) framework, which effectively reduces domain-relevant information while preserving essential temporal and spectral features for sleep stage classification. In our exhaustive experiments on publicly available sleep staging benchmark datasets, SleepEDF-20 and MASS, our proposed method consistently outperformed state-of-the-art methods. Our code is available at : this https URL', 'abstract_zh': '基于深度学习的自动睡眠阶段划分在性能上取得了显著进步，并在睡眠障碍诊断中扮演着重要角色。然而，这些模型往往难以在未见过的受试者上泛化，导致在分布外场景中的性能下降。为了解决这一问题，最近研究了领域泛化方法，以确保在训练过程中在未见过的领域中实现泛化性能。在这其中，对比学习已被证明可以通过在不同领域内对相同类别的样本进行对齐，学习到领域不变的特征。尽管对比学习具有潜力，但许多现有方法仍不足以提取充分的领域不变表征，因为它们未能明确处理跨样本未共享信息中的领域特征。在本文中，我们认为减轻称为多余领域相关信息的领域相关的属性是弥合领域差距的关键。然而，直接减轻领域相关属性的策略往往会过度拟合高层信息特征，限制了它们利用多层次中编码的时序和频谱信息的能力。为了解决这些局限性，我们提出了一种名为MEASURE（多尺度最小充分表示学习）的新框架，该框架有效减少了领域相关信息的同时，保留了用于睡眠阶段分类的重要时序和频谱特征。在对公开可用的睡眠阶段基准数据集SleepEDF-20和MASS进行的详尽实验中，我们提出的方法在所有评估指标上都优于现有方法。我们的代码可在以下链接获取：this https URL。', 'title_zh': 'MEASURE: 多尺度最小充分表示学习在睡眠分期领域泛化的应用'}
{'arxiv_id': 'arXiv:2510.12060', 'title': 'Your VAR Model is Secretly an Efficient and Explainable Generative Classifier', 'authors': 'Yi-Chung Chen, David I. Inouye, Jing Gao', 'link': 'https://arxiv.org/abs/2510.12060', 'abstract': 'Generative classifiers, which leverage conditional generative models for classification, have recently demonstrated desirable properties such as robustness to distribution shifts. However, recent progress in this area has been largely driven by diffusion-based models, whose substantial computational cost severely limits scalability. This exclusive focus on diffusion-based methods has also constrained our understanding of generative classifiers. In this work, we propose a novel generative classifier built on recent advances in visual autoregressive (VAR) modeling, which offers a new perspective for studying generative classifiers. To further enhance its performance, we introduce the Adaptive VAR Classifier$^+$ (A-VARC$^+$), which achieves a superior trade-off between accuracy and inference speed, thereby significantly improving practical applicability. Moreover, we show that the VAR-based method exhibits fundamentally different properties from diffusion-based methods. In particular, due to its tractable likelihood, the VAR-based classifier enables visual explainability via token-wise mutual information and demonstrates inherent resistance to catastrophic forgetting in class-incremental learning tasks.', 'abstract_zh': '基于视觉自回归模型的生成分类器：A-VARC$^+$及其特性研究', 'title_zh': '你的VAR模型实际上是高效的可解释生成分类器'}
{'arxiv_id': 'arXiv:2510.12051', 'title': 'APCE: Adaptive Progressive Context Expansion for Long Context Processing', 'authors': 'Baisub Lee, Sanghyun Byun, Mohanad Odema, Jung Guack, Jacob Song, Woo Seong Chung', 'link': 'https://arxiv.org/abs/2510.12051', 'abstract': "Deploying useful Long-Context Transformer Models (LCTMs) requires addressing two key challenges: (1) A growing memory footprint due to quadratic self-attention and linear KV-cache scaling in memory as sequence length increases; (2) the ContextRot phenomena where empirical evidence suggests that transformer architecture's performance degrades with increasing context length. Given the shared dependency on the input, a natural question arises: Can we surgically select the most important input chunks for processing to synergistically (a) reduce the memory footprint, and (b) mitigate the ContextRot effects? In this paper, we answer this question in the affirmative for long-context summarization tasks. We propose APCE as a context-aware solution to select the most important input chunks through low-dimensional semantic similarity matching with the current query. By directly operating on the input, APCE decouples from strict dependency on underlying hardware or CUDA environments, promising a compatible solution scalable to different deployment systems. Our empirical evaluations have demonstrated superior or on-par summarization performance for APCE compared to the full dense baseline using a fraction (50%-70%) of the input sequence resulting in KV-cache and self-attention memory efficiency improvements. We hope our findings inspire further research on context-aware efficiency solutions for LCTMs geared towards other relevant long-context tasks.", 'abstract_zh': '部署有用的长上下文转换器模型（LCTMs）需要解决两个关键挑战：（1）由于二次自注意力和随序列长度增加而线性扩展的KV缓存导致的日益增长的内存占用；（2）上下文旋转现象，实证研究表明，随着上下文长度的增加，变压器架构的性能会下降。鉴于输入的共享依赖性，一个自然的问题是：我们是否可以通过手术方式选择最重要的输入片段进行处理，从而（a）减少内存占用，并且（b）减轻上下文旋转效应？在本文中，我们证明了APCE可以在长上下文总结任务中肯定地做到这一点。我们提出了一种基于上下文的认知解决方案APCE，通过低维语义相似性匹配当前查询来选择最重要的输入片段。通过对输入直接操作，APCE摆脱了对底层硬件或CUDA环境的严格依赖，提供了一种兼容性解决方案，可扩展到不同的部署系统。我们的实验评估表明，与使用完整密集基线相比，APCE使用输入序列的少量（50%-70%）片段实现了更好的或相当的总结性能，从而提高了KV缓存和自注意力的内存效率。我们希望我们的研究成果能够激励更多关于LCTMs面向其他相关长上下文任务的认知效率解决方案的研究。', 'title_zh': '自适应渐进上下文扩展：长上下文处理'}
{'arxiv_id': 'arXiv:2510.12049', 'title': 'Generative AI and Firm Productivity: Field Experiments in Online Retail', 'authors': 'Lu Fang, Zhe Yuan, Kaifu Zhang, Dante Donati, Miklos Sarvary', 'link': 'https://arxiv.org/abs/2510.12049', 'abstract': "We quantify the impact of Generative Artificial Intelligence (GenAI) on firm productivity through a series of large-scale randomized field experiments involving millions of users and products at a leading cross-border online retail platform. Over six months in 2023-2024, GenAI-based enhancements were integrated into seven consumer-facing business workflows. We find that GenAI adoption significantly increases sales, with treatment effects ranging from 0\\% to 16.3\\%, depending on GenAI's marginal contribution relative to existing firm practices. Because inputs and prices were held constant across experimental arms, these gains map directly into total factor productivity improvements. Across the four GenAI applications with positive effects, the implied annual incremental value is approximately \\$5 per consumer-an economically meaningful impact given the retailer's scale and the early stage of GenAI adoption. The primary mechanism operates through higher conversion rates, consistent with GenAI reducing frictions in the marketplace and improving consumer experience. We also document substantial heterogeneity: smaller and newer sellers, as well as less experienced consumers, exhibit disproportionately larger gains. Our findings provide novel, large-scale causal evidence on the productivity effects of GenAI in online retail, highlighting both its immediate value and broader potential.", 'abstract_zh': '我们通过涉及数百万用户和产品的大型随机现场实验，量化生成式人工智能（GenAI）对公司在跨境在线零售平台上的生产力影响。2023-2024年，GenAI增强功能被整合到七个面向消费者的业务工作流程中。我们发现，GenAI的采用显著增加了销售额，治疗效果范围从0%到16.3%，具体取决于GenAI对现有公司实践的边际贡献。由于各实验组的投入和价格保持不变，这些增益直接映射到总要素生产力的改进上。在四个具有正向效果的GenAI应用中，估计的年度增量价值约为每消费者5美元——这一经济意义上具有重要意义的影响考虑到了零售商的规模和GenAI采用的早期阶段。主要机制通过提高转化率起作用，这与GenAI减少市场摩擦和改善消费者体验一致。我们还记录了显著的异质性：较小和较新的卖家以及不太经验丰富的消费者表现出更大的增益。我们的研究提供了关于在线零售中GenAI生产力影响的新型大规模因果证据，突显了其即时价值和更广泛的潜力。', 'title_zh': '生成式AI与企业生产率：在线零售领域的实地试验'}
{'arxiv_id': 'arXiv:2510.11986', 'title': 'Conjecturing: An Overlooked Step in Formal Mathematical Reasoning', 'authors': 'Jasivan Alex Sivakumar, Philipp Borchert, Ronald Cardenas, Gerasimos Lampouras', 'link': 'https://arxiv.org/abs/2510.11986', 'abstract': 'Autoformalisation, the task of expressing informal mathematical statements in formal language, is often viewed as a direct translation process. This, however, disregards a critical preceding step: conjecturing. Many mathematical problems cannot be formalised directly without first conjecturing a conclusion such as an explicit answer, or a specific bound. Since Large Language Models (LLMs) already struggle with autoformalisation, and the evaluation of their conjecturing ability is limited and often entangled within autoformalisation or proof, it is particularly challenging to understand its effect. To address this gap, we augment existing datasets to create ConjectureBench, and redesign the evaluation framework and metric specifically to measure the conjecturing capabilities of LLMs both as a distinct task and within the autoformalisation pipeline. Our evaluation of foundational models, including GPT-4.1 and DeepSeek-V3.1, reveals that their autoformalisation performance is substantially overestimated when the conjecture is accounted for during evaluation. However, the conjecture should not be assumed to be provided. We design an inference-time method, Lean-FIRe to improve conjecturing and autoformalisation, which, to the best of our knowledge, achieves the first successful end-to-end autoformalisation of 13 PutnamBench problems with GPT-4.1 and 7 with DeepSeek-V3.1. We demonstrate that while LLMs possess the requisite knowledge to generate accurate conjectures, improving autoformalisation performance requires treating conjecturing as an independent task, and investigating further how to correctly integrate it within autoformalisation. Finally, we provide forward-looking guidance to steer future research toward improving conjecturing, an overlooked step of formal mathematical reasoning.', 'abstract_zh': '自动形式化，即将非形式化的数学陈述表达为形式语言的过程，通常被视为一种直接的翻译过程。然而，这忽略了至关重要的一个前置步骤：猜想。许多数学问题在无法直接形式化之前，需要先提出一个结论，例如明确的答案或特定的界。由于大规模语言模型（LLMs）已经在自动形式化方面表现出色，而其猜想能力的评估通常与自动形式化或证明紧密交织在一起，因此理解其影响尤为具有挑战性。为解决这一差距，我们扩展了现有的数据集以创建ConjectureBench，并重新设计了评估框架和度量标准，以专门衡量LLMs在作为独立任务和自动形式化管道内的猜想能力。我们对包括GPT-4.1和DeepSeek-V3.1在内的基础模型的评估显示，当在评估过程中考虑猜想时，其自动形式化性能被大大高估了。然而，不应假设猜想会被提供。我们设计了一种推理时方法Lean-FIRe，以提高猜想和自动形式化的性能，在我们所知的情况下，该方法首次成功地使用GPT-4.1和DeepSeek-V3.1实现了PutnamBench 13个问题和7个问题的端到端自动形式化。我们表明，尽管LLMs具备生成准确猜想所需的知识，但提高自动形式化性能需要将猜想视为一个独立任务，并进一步探索如何正确将其整合到自动形式化中。最后，我们提供前瞻性的指导，以引导未来研究改进猜想，这一被忽视的数学形式推理步骤。', 'title_zh': '猜想：形式化数学推理中被忽视的步骤'}
{'arxiv_id': 'arXiv:2510.11955', 'title': 'Y-shaped Generative Flows', 'authors': 'Arip Asadulaev, Semyon Semenov, Abduragim Shtanchaev, Eric Moulines, Fakhri Karray, Martin Takac', 'link': 'https://arxiv.org/abs/2510.11955', 'abstract': 'Modern continuous-time generative models often induce V-shaped transport: each sample travels independently along nearly straight trajectories from prior to data, overlooking shared structure. We introduce Y-shaped generative flows, which move probability mass together along shared pathways before branching to target-specific endpoints. Our formulation is based on novel velocity-powered transport cost with a sublinear exponent (between zero and one). this concave dependence rewards joint and fast mass movement. Practically, we instantiate the idea in a scalable neural ODE training objective. On synthetic, image, and biology datasets, Y-flows recover hierarchy-aware structure, improve distributional metrics over strong flow-based baselines, and reach targets with fewer integration steps.', 'abstract_zh': 'Y形生成流：共享路径上的联合概率质量传输以改善生成模型', 'title_zh': 'Y形生成流'}
{'arxiv_id': 'arXiv:2510.11953', 'title': 'Sculpting Latent Spaces With MMD: Disentanglement With Programmable Priors', 'authors': 'Quentin Fruytier, Akshay Malhotra, Shahab Hamidi-Rad, Aditya Sant, Aryan Mokhtari, Sujay Sanghavi', 'link': 'https://arxiv.org/abs/2510.11953', 'abstract': 'Learning disentangled representations, where distinct factors of variation are captured by independent latent variables, is a central goal in machine learning. The dominant approach has been the Variational Autoencoder (VAE) framework, which uses a Kullback-Leibler (KL) divergence penalty to encourage the latent space to match a factorized Gaussian prior. In this work, however, we provide direct evidence that this KL-based regularizer is an unreliable mechanism, consistently failing to enforce the target distribution on the aggregate posterior. We validate this and quantify the resulting entanglement using our novel, unsupervised Latent Predictability Score (LPS). To address this failure, we introduce the Programmable Prior Framework, a method built on the Maximum Mean Discrepancy (MMD). Our framework allows practitioners to explicitly sculpt the latent space, achieving state-of-the-art mutual independence on complex datasets like CIFAR-10 and Tiny ImageNet without the common reconstruction trade-off. Furthermore, we demonstrate how this programmability can be used to engineer sophisticated priors that improve alignment with semantically meaningful features. Ultimately, our work provides a foundational tool for representation engineering, opening new avenues for model identifiability and causal reasoning.', 'abstract_zh': '学习解耦表示，其中独立的潜在变量捕获不同的变化因子，是机器学习中的一个核心目标。尽管占主导地位的方法是变分自编码器（VAE）框架，该框架通过Kullback-Leibler（KL）散度惩罚项鼓励潜在空间匹配因子化的高斯先验，然而，在这项工作中，我们提供了直接证据表明，这种基于KL的正则化机制是不可靠的，一致地未能在联合后验上施加目标分布。我们使用新颖的无监督潜在可预测分数（LPS）验证这一点并量化由此产生的纠缠。为了应对这种失败，我们引入了可编程先验框架，该方法基于最大均值偏差（MMD）。我们的框架允许实践者明确塑造潜在空间，在CIFAR-10和Tiny ImageNet等复杂数据集上实现最先进的互不相关性，而无需常见的重构权衡。此外，我们展示了这种可编程性如何用于设计与语义含义特征对齐更为出色的先验。最终，我们的工作提供了一个基础工具，用于表示工程设计，开启了模型标识性和因果推理的新途径。', 'title_zh': '用MMD塑造潜在空间：具可编程先验的分解学习'}
{'arxiv_id': 'arXiv:2510.11928', 'title': 'Discrepancy Detection at the Data Level: Toward Consistent Multilingual Question Answering', 'authors': 'Lorena Calvo-Bartolomé, Valérie Aldana, Karla Cantarero, Alonso Madroñal de Mesa, Jerónimo Arenas-García, Jordan Boyd-Graber', 'link': 'https://arxiv.org/abs/2510.11928', 'abstract': 'Multilingual question answering (QA) systems must ensure factual consistency across languages, especially for objective queries such as What is jaundice?, while also accounting for cultural variation in subjective responses. We propose MIND, a user-in-the-loop fact-checking pipeline to detect factual and cultural discrepancies in multilingual QA knowledge bases. MIND highlights divergent answers to culturally sensitive questions (e.g., Who assists in childbirth?) that vary by region and context. We evaluate MIND on a bilingual QA system in the maternal and infant health domain and release a dataset of bilingual questions annotated for factual and cultural inconsistencies. We further test MIND on datasets from other domains to assess generalization. In all cases, MIND reliably identifies inconsistencies, supporting the development of more culturally aware and factually consistent QA systems.', 'abstract_zh': '多语言问答系统必须确保不同语言中的事实一致性，特别是在客观查询（如“什么是黄疸？”）方面，同时还要考虑到主观响应中的文化差异。我们提出MIND，一种包含用户反馈的事实核查流水线，用于检测多语言问答知识库中的事实和文化分歧。MIND突出了文化敏感问题（如“谁协助分娩？”）在不同地区和背景下答案的差异。我们评估MIND在母婴健康领域的双语问答系统上，并发布了一个双语问题数据集，其中标注了事实和文化一致性问题。进一步在其他领域的数据集上测试MIND，以评估其泛化能力。在所有情况下，MIND都能可靠地识别出一致性问题，支持开发更具文化意识和事实一致性的问答系统。', 'title_zh': '数据层面的一致性多语言问答中的 discrepancy 检测'}
{'arxiv_id': 'arXiv:2510.11903', 'title': 'Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks', 'authors': 'Rizal Fathony, Igor Melnyk, Owen Reinert, Nam H. Nguyen, Daniele Rosa, C. Bayan Bruss', 'link': 'https://arxiv.org/abs/2510.11903', 'abstract': 'User event modeling plays a central role in many machine learning applications, with use cases spanning e-commerce, social media, finance, cybersecurity, and other domains. User events can be broadly categorized into personal events, which involve individual actions, and relational events, which involve interactions between two users. These two types of events are typically modeled separately, using sequence-based methods for personal events and graph-based methods for relational events. Despite the need to capture both event types in real-world systems, prior work has rarely considered them together. This is often due to the convenient simplification that user behavior can be adequately represented by a single formalization, either as a sequence or a graph. To address this gap, there is a need for public datasets and prediction tasks that explicitly incorporate both personal and relational events. In this work, we introduce a collection of such datasets, propose a unified formalization, and empirically show that models benefit from incorporating both event types. Our results also indicate that current methods leave a notable room for improvements. We release these resources to support further research in unified user event modeling and encourage progress in this direction.', 'abstract_zh': '用户事件建模在许多机器学习应用中扮演着核心角色，应用场景涵盖电子商务、社交媒体、金融、网络安全及其他领域。用户事件可以大致分为个人事件和关系事件两大类。个人事件涉及个体行为，关系事件涉及两个用户之间的互动。尽管这两种类型的事件通常会分别使用序列模型和图模型进行建模，但在现实系统中捕捉这两种事件类型的需求并未得到充分考虑。这通常是由于一种方便的简化，即用户行为可以用单一的形式化表示，要么是序列，要么是图。为了弥补这一差距，需要包含个人和关系事件的公开数据集和预测任务。在本文中，我们介绍了这样一些数据集、提出了一种统一的形式化方法，并实证表明结合两种事件类型有助于模型的性能提升。我们的研究结果还表明，现有方法仍有改进的空间。我们将这些资源发布出来，以支持统一用户事件建模的进一步研究，并鼓励在这方面的进展。', 'title_zh': '集成序列建模与关系建模的用户事件：数据集与预测任务'}
{'arxiv_id': 'arXiv:2510.11827', 'title': 'Combining Euclidean and Hyperbolic Representations for Node-level Anomaly Detection', 'authors': 'Simone Mungari, Ettore Ritacco, Pietro Sabatino', 'link': 'https://arxiv.org/abs/2510.11827', 'abstract': 'Node-level anomaly detection (NAD) is challenging due to diverse structural patterns and feature distributions. As such, NAD is a critical task with several applications which range from fraud detection, cybersecurity, to recommendation systems. We introduce Janus, a framework that jointly leverages Euclidean and Hyperbolic Graph Neural Networks to capture complementary aspects of node representations. Each node is described by two views, composed by the original features and structural features derived from random walks and degrees, then embedded into Euclidean and Hyperbolic spaces. A multi Graph-Autoencoder framework, equipped with a contrastive learning objective as regularization term, aligns the embeddings across the Euclidean and Hyperbolic spaces, highlighting nodes whose views are difficult to reconcile and are thus likely anomalous. Experiments on four real-world datasets show that Janus consistently outperforms shallow and deep baselines, empirically demonstrating that combining multiple geometric representations provides a robust and effective approach for identifying subtle and complex anomalies in graphs.', 'abstract_zh': '节点级异常检测（NAD）由于存在多样化的结构模式和特征分布而具有挑战性。因此，NAD 是一个关键任务，具有从欺诈检测、网络安全到推荐系统等多种应用。我们介绍了 Janus，一个结合使用欧几里得和双曲图神经网络的框架，以捕获节点表示的互补方面。每个节点由两部分视图组成，包括原始特征和从随机游走和度派生的结构特征，然后嵌入到欧几里得和双曲空间中。该框架采用多图自编码器架构，并配以对比学习目标作为正则化项，将欧几里得和双曲空间中的嵌入进行对齐，突出那些难以调和的视图节点，从而可能具有异常性。在四个真实世界的数据集上的实验表明，Janus 一致地优于浅层和深层基线，实证证明结合多种几何表示是识别图中细微而复杂的异常的一种稳健而有效的方法。', 'title_zh': '结合欧几里得和双曲表示进行节点级异常检测'}
{'arxiv_id': 'arXiv:2510.11824', 'title': 'Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning', 'authors': 'Simin Li, Zihao Mao, Hanxiao Li, Zonglei Jing, Zhuohang bian, Jun Guo, Li Wang, Zhuoran Han, Ruixiao Xu, Xin Yu, Chengdong Ma, Yuqing Ma, Bo An, Yaodong Yang, Weifeng Lv, Xianglong Liu', 'link': 'https://arxiv.org/abs/2510.11824', 'abstract': 'In cooperative Multi-Agent Reinforcement Learning (MARL), it is a common practice to tune hyperparameters in ideal simulated environments to maximize cooperative performance. However, policies tuned for cooperation often fail to maintain robustness and resilience under real-world uncertainties. Building trustworthy MARL systems requires a deep understanding of robustness, which ensures stability under uncertainties, and resilience, the ability to recover from disruptions--a concept extensively studied in control systems but largely overlooked in MARL. In this paper, we present a large-scale empirical study comprising over 82,620 experiments to evaluate cooperation, robustness, and resilience in MARL across 4 real-world environments, 13 uncertainty types, and 15 hyperparameters. Our key findings are: (1) Under mild uncertainty, optimizing cooperation improves robustness and resilience, but this link weakens as perturbations intensify. Robustness and resilience also varies by algorithm and uncertainty type. (2) Robustness and resilience do not generalize across uncertainty modalities or agent scopes: policies robust to action noise for all agents may fail under observation noise on a single agent. (3) Hyperparameter tuning is critical for trustworthy MARL: surprisingly, standard practices like parameter sharing, GAE, and PopArt can hurt robustness, while early stopping, high critic learning rates, and Leaky ReLU consistently help. By optimizing hyperparameters only, we observe substantial improvement in cooperation, robustness and resilience across all MARL backbones, with the phenomenon also generalizing to robust MARL methods across these backbones. Code and results available at this https URL .', 'abstract_zh': '在合作多智能体强化学习（MARL）中，通常在理想的模拟环境中调整超参数以最大化合作性能。然而，针对合作优化的策略往往在现实世界的不确定性下失去鲁棒性和恢复力。构建可信赖的MARL系统需要深入理解鲁棒性，确保在不确定性下的稳定性，和恢复力——这一概念在控制系统中已有广泛研究，但在MARL领域却鲜有关注。本文通过包含超过82,620个实验的大型实证研究，在4个真实环境、13种不确定性类型和15个超参数下评估MARL中的合作、鲁棒性和恢复力。主要发现包括：(1) 在轻微不确定性下，优化合作能提升鲁棒性和恢复力，但随着扰动加剧，这种关联减弱。鲁棒性和恢复力也因算法和不确定性类型而异。(2) 鲁棒性和恢复力在不同类型的不确定性或智能体范围内不具有普适性：能抵抗所有智能体动作噪声的策略可能在单一智能体的观察噪声下失效。(3) 超参数调整对于可信赖的MARL至关重要：意想不到的是，标准做法如参数共享、GAE和PopArt可能导致鲁棒性下降，而早停策略、高评论家学习率和Leaky ReLU则始终有所助益。仅通过优化超参数，在所有MARL框架中观察到显著的改进，这一现象也推广到了这些框架下的鲁棒MARL方法。代码和结果可在以下链接获取。', 'title_zh': '合作多代理强化学习中稳健性和韧性的实证研究'}
{'arxiv_id': 'arXiv:2510.11823', 'title': 'BlackIce: A Containerized Red Teaming Toolkit for AI Security Testing', 'authors': 'Caelin Kaplan, Alexander Warnecke, Neil Archibald', 'link': 'https://arxiv.org/abs/2510.11823', 'abstract': "AI models are being increasingly integrated into real-world systems, raising significant concerns about their safety and security. Consequently, AI red teaming has become essential for organizations to proactively identify and address vulnerabilities before they can be exploited by adversaries. While numerous AI red teaming tools currently exist, practitioners face challenges in selecting the most appropriate tools from a rapidly expanding landscape, as well as managing complex and frequently conflicting software dependencies across isolated projects. Given these challenges and the relatively small number of organizations with dedicated AI red teams, there is a strong need to lower barriers to entry and establish a standardized environment that simplifies the setup and execution of comprehensive AI model assessments.\nInspired by Kali Linux's role in traditional penetration testing, we introduce BlackIce, an open-source containerized toolkit designed for red teaming Large Language Models (LLMs) and classical machine learning (ML) models. BlackIce provides a reproducible, version-pinned Docker image that bundles 14 carefully selected open-source tools for Responsible AI and Security testing, all accessible via a unified command-line interface. With this setup, initiating red team assessments is as straightforward as launching a container, either locally or using a cloud platform. Additionally, the image's modular architecture facilitates community-driven extensions, allowing users to easily adapt or expand the toolkit as new threats emerge. In this paper, we describe the architecture of the container image, the process used for selecting tools, and the types of evaluations they support.", 'abstract_zh': 'AI模型正越来越多地集成到实际系统中，引发了对其安全性和安全性的重要关注。因此，AI红队行动对于组织来说变得至关重要，可以提前识别和解决潜在被对手利用的漏洞。尽管目前存在众多AI红队工具，但实践者在从快速增长的工具库中选择最合适的工具时仍面临挑战，并且在孤立项目中管理复杂且频繁冲突的软件依赖也存在困难。鉴于这些挑战和拥有专门AI红队的小组织数量有限，降低进入壁垒并建立标准化环境以简化全面AI模型评估的设置和执行变得非常必要。\n\n受Kali Linux在传统渗透测试中作用的启发，我们引入了BlackIce，这是一个用于红队评估大型语言模型（LLMs）和经典机器学习（ML）模型的开源容器化工具包。BlackIce提供了一个可重复的、版本锁定的Docker镜像，该镜像捆绑了14个精心选择的开源工具，用于负责任的AI和安全测试，所有工具均可通过统一的命令行接口访问。通过此设置，启动红队评估只需启动一个容器，无论是本地还是使用云平台。此外，镜像的模块化架构促进了社区驱动的扩展，使用户能够轻松适应或扩展工具以应对新出现的威胁。在本文中，我们描述了容器镜像的架构、工具选择过程以及它们支持的评估类型。', 'title_zh': 'BlackIce：一个容器化的红色团队AI安全测试工具包'}
{'arxiv_id': 'arXiv:2510.11769', 'title': 'GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving', 'authors': 'Ruida Wang, Jiarui Yao, Rui Pan, Shizhe Diao, Tong Zhang', 'link': 'https://arxiv.org/abs/2510.11769', 'abstract': "Solving math problems through verifiable languages such as Lean has significantly impacted both the mathematics and computer science communities. Current state-of-the-art models are often trained with expensive online Reinforcement Learning (RL) or expert iteration. However, these approaches rely on fixed problem sets, which causes inefficient training and limits the model to tackle complex problems. To overcome these limitations, we propose GAR: Generative Adversarial Reinforcement learning, a comprehensive RL training framework that jointly trains the problem composer and solver in an adversarial loop. GAR introduces an implicit curriculum learning mechanism, which aligns task difficulty with the prover's evolving capability. It thereby improves the training efficiency and enables stronger performance of proving advanced theorems. Experiments show that with GAR training, Goedel-Prover-V2-8B and DeepSeek-Prover-V2-7B achieve an average relative improvement in pass@32 of 4.20% on MiniF2F-Test benchmark, while DeepSeek-Prover-V2's pass@32 on ProofNet-Test increases from 22.58% to 25.81%. Beyond formal proving, GAR establishes a general RL paradigm for co-evolution of problem generation and solving under verifiable environments.", 'abstract_zh': '通过可验证语言如Lean解决数学问题，显著影响了数学和计算机科学社区。生成对抗强化学习GAR：一种综合的RL训练框架，在对抗循环中共同训练问题生成者和解决者，以克服现有局限性。GAR引入了隐式课程学习机制，使任务难度与证明者的能力进化保持一致，从而提高训练效率并增强证明高级定理的能力。实验表明，使用GAR训练后，Goedel-Prover-V2-8B和DeepSeek-Prover-V2-7B在MiniF2F-Test基准上的pass@32平均相对改进为4.20%，而DeepSeek-Prover-V2在ProofNet-Test上的pass@32从22.58%提高到25.81%。GAR还建立了在可验证环境中问题生成与解决协同进化的通用RL范式。', 'title_zh': 'GAR：生成对抗强化学习在形式定理证明中的应用'}
{'arxiv_id': 'arXiv:2510.11758', 'title': 'The Adoption Paradox: A Comparative Analysis of Veterinary AI Adoption in China and the North America', 'authors': 'Shumin Li, Xiaoyun Lai', 'link': 'https://arxiv.org/abs/2510.11758', 'abstract': 'This study compares the perception, adoption, and application of artificial intelligence (AI) among veterinary professionals in China and North America (NA), testing the hypothesis that adoption patterns are shaped by regional market and demographic factors. A descriptive, cross-sectional survey was conducted with 455 veterinary professionals in China between May and July 2025. The results were compared with published data from a 2024 survey of 3,968 veterinary professionals in the United States and Canada. The Chinese cohort, primarily composed of clinicians (81.5%), showed a high AI adoption rate (71.0%) despite low familiarity (55.4%). Their AI use was focused on clinical tasks, such as disease diagnosis (50.1%) and prescription calculation (44.8%). In contrast, the NA cohort reported high familiarity (83.8%) but a lower adoption rate (39.2%). Their priorities were administrative, including imaging analysis (39.0%) and record-keeping (39.0%). Concerns about AI reliability and accuracy were the top barrier in both groups. Our findings reveal an "adoption paradox" where the Chinese market demonstrates a practitioner-driven, bottom-up adoption model focused on augmenting clinical efficacy, while the NA market shows a more cautious, structured, top-down integration aimed at improving administrative efficiency. This suggests that a one-size-fits-all approach to AI development and integration is insufficient, and tailored, region-specific strategies are necessary to responsibly incorporate AI into global veterinary practice.', 'abstract_zh': '中国与北美的兽医专业人员对人工智能的感知、采用与应用比较：基于区域市场和人口因素的假设测试', 'title_zh': '兽医AI Adoption Paradox: A Comparative Analysis of Adoption in China and North America'}
{'arxiv_id': 'arXiv:2510.11755', 'title': 'Artificial Intelligence for Optimal Learning: A Comparative Approach towards AI-Enhanced Learning Environments', 'authors': 'Ananth Hariharan', 'link': 'https://arxiv.org/abs/2510.11755', 'abstract': 'In the rapidly evolving educational landscape, the integration of technology has shifted from an enhancement to a cornerstone of educational strategy worldwide. This transition is propelled by advancements in digital technology, especially the emergence of artificial intelligence as a crucial tool in learning environments. This research project critically evaluates the impact of three distinct educational settings: traditional educational methods without technological integration, those enhanced by non-AI technology, and those utilising AI-driven technologies. This comparison aims to assess how each environment influences educational outcomes, engagement, pedagogical methods, and equity in access to learning resources, and how each contributes uniquely to the learning experience. The ultimate goal of this research is to synthesise the strengths of each model to create a more holistic educational approach. By integrating the personal interaction and tested pedagogical techniques of traditional classrooms, the enhanced accessibility and collaborative tools offered by non-AI technology, and the personalised, adaptive learning strategies enabled by AI-driven technologies, education systems can develop richer, more effective learning environments. This hybrid approach aims to leverage the best elements of each setting, thereby enhancing educational outcomes, engagement, and inclusiveness, while also addressing the distinct challenges and limitations inherent in each model. The intention is to create an educational framework deeply attentive to the diverse needs of students, ensuring equitable access to high-quality education for all.', 'abstract_zh': '在快速演进的教育格局中，技术的整合已从一种增强手段转变为全球教育策略的基石。这一转变由数字技术的进步推动，尤其是人工智能作为学习环境中关键工具的出现。本研究项目批判性地评估了三种不同的教育环境：不包含技术整合的传统教育方法、通过非人工智能技术增强的方法以及利用人工智能驱动技术的方法的影响。这一比较旨在评估每种环境如何影响教育成果、参与度、教学方法以及学习资源的公平获取，并且评估每种环境如何独特地为学习体验做出贡献。本研究的最终目标是综合每种模式的优势，以形成更为全面的教育方法。通过结合传统课堂中的人际互动和个人已证实的教学技巧、非人工智能技术提供的增强可访问性和协作工具，以及人工智能驱动技术所实现的个性化和自适应学习策略，教育体系可以发展出更为丰富、更有效的学习环境。这种混合方法旨在利用每种设置的最佳要素，从而增强教育成果、参与度和包容性，同时解决每种模式固有的独特挑战和限制。其目的是建立一个深度关注学生多样需求的教育框架，确保所有学生都能获得高质量的教育机会。', 'title_zh': '人工智能优化学习：面向AI增强学习环境的比较研究'}
{'arxiv_id': 'arXiv:2510.11752', 'title': 'Fast and Interpretable Protein Substructure Alignment via Optimal Transport', 'authors': 'Zhiyu Wang, Bingxin Zhou, Jing Wang, Yang Tan, Weishu Zhao, Pietro Liò, Liang Hong', 'link': 'https://arxiv.org/abs/2510.11752', 'abstract': 'Proteins are essential biological macromolecules that execute life functions. Local motifs within protein structures, such as active sites, are the most critical components for linking structure to function and are key to understanding protein evolution and enabling protein engineering. Existing computational methods struggle to identify and compare these local structures, which leaves a significant gap in understanding protein structures and harnessing their functions. This study presents PLASMA, the first deep learning framework for efficient and interpretable residue-level protein substructure alignment. We reformulate the problem as a regularized optimal transport task and leverage differentiable Sinkhorn iterations. For a pair of input protein structures, PLASMA outputs a clear alignment matrix with an interpretable overall similarity score. Through extensive quantitative evaluations and three biological case studies, we demonstrate that PLASMA achieves accurate, lightweight, and interpretable residue-level alignment. Additionally, we introduce PLASMA-PF, a training-free variant that provides a practical alternative when training data are unavailable. Our method addresses a critical gap in protein structure analysis tools and offers new opportunities for functional annotation, evolutionary studies, and structure-based drug design. Reproducibility is ensured via our official implementation at this https URL.', 'abstract_zh': '蛋白质是执行生命功能的关键生物大分子。蛋白质结构中的局部基序，如活性位点，是将结构与功能连接起来的最关键组成部分，对于理解蛋白质演化和蛋白质工程至关重要。现有计算方法难以识别和比较这些局部结构，这在了解蛋白质结构和充分利用其功能方面留下了一定的差距。本文介绍了PLASMA，这是首个用于高效和可解释的残基级蛋白质亚结构对齐的深度学习框架。我们将问题重新表述为正则化最优传输任务，并利用可微Sinkhorn迭代。对于一对输入蛋白质结构，PLASMA输出一个清晰的对齐矩阵，带有可解释的整体相似性得分。通过广泛的定量评估和三个生物案例研究，我们证明PLASMA能够实现准确、轻量级且可解释的残基级对齐。此外，我们引入了PLASMA-PF，这是一个无需训练的变体，当缺乏训练数据时可以提供实用的选择。我们的方法填补了蛋白质结构分析工具的关键空白，并为功能注释、进化研究和基于结构的药物设计提供了新机会。结果的可再现性通过我们的官方实现得到了保证：[此链接]。', 'title_zh': '快速且可解释的蛋白质亚结构对齐方法基于最优传输'}
{'arxiv_id': 'arXiv:2510.11739', 'title': "Celebrity Profiling on Short Urdu Text using Twitter Followers' Feed", 'authors': 'Muhammad Hamza, Rizwan Jafar', 'link': 'https://arxiv.org/abs/2510.11739', 'abstract': 'Social media has become an essential part of the digital age, serving as a platform for communication, interaction, and information sharing. Celebrities are among the most active users and often reveal aspects of their personal and professional lives through online posts. Platforms such as Twitter provide an opportunity to analyze language and behavior for understanding demographic and social patterns. Since followers frequently share linguistic traits and interests with the celebrities they follow, textual data from followers can be used to predict celebrity demographics. However, most existing research in this field has focused on English and other high-resource languages, leaving Urdu largely unexplored.\nThis study applies modern machine learning and deep learning techniques to the problem of celebrity profiling in Urdu. A dataset of short Urdu tweets from followers of subcontinent celebrities was collected and preprocessed. Multiple algorithms were trained and compared, including Logistic Regression, Support Vector Machines, Random Forests, Convolutional Neural Networks, and Long Short-Term Memory networks. The models were evaluated using accuracy, precision, recall, F1-score, and cumulative rank (cRank). The best performance was achieved for gender prediction with a cRank of 0.65 and an accuracy of 0.65, followed by moderate results for age, profession, and fame prediction. These results demonstrate that follower-based linguistic features can be effectively leveraged using machine learning and neural approaches for demographic prediction in Urdu, a low-resource language.', 'abstract_zh': 'Urdu社交媒体中的名人画像研究：基于追随者文本数据的机器学习与深度学习方法', 'title_zh': '基于Twitter粉丝帖子的乌尔都语短文本名人画像构建'}
{'arxiv_id': 'arXiv:2510.11732', 'title': 'Serial-Parallel Dual-Path Architecture for Speaking Style Recognition', 'authors': 'Guojian Li, Qijie Shao, Zhixian Zhao, Shuiyuan Wang, Zhonghua Fu, Lei Xie', 'link': 'https://arxiv.org/abs/2510.11732', 'abstract': "Speaking Style Recognition (SSR) identifies a speaker's speaking style characteristics from speech. Existing style recognition approaches primarily rely on linguistic information, with limited integration of acoustic information, which restricts recognition accuracy improvements. The fusion of acoustic and linguistic modalities offers significant potential to enhance recognition performance. In this paper, we propose a novel serial-parallel dual-path architecture for SSR that leverages acoustic-linguistic bimodal information. The serial path follows the ASR+STYLE serial paradigm, reflecting a sequential temporal dependency, while the parallel path integrates our designed Acoustic-Linguistic Similarity Module (ALSM) to facilitate cross-modal interaction with temporal simultaneity. Compared to the existing SSR baseline -- the OSUM model, our approach reduces parameter size by 88.4% and achieves a 30.3% improvement in SSR accuracy for eight styles on the test set.", 'abstract_zh': '说话风格识别（SSR）从语音中识别说话人的说话风格特征。现有的风格识别方法主要依赖于语言信息，对声学信息的整合有限，限制了识别准确性的提升。将声学和语言模态融合为显著潜在提升识别性能的机会。在本文中，我们提出了一种新颖的串行-并行双路径架构，利用声学-语言双模态信息。串行路径遵循ASR+STYLE串行范式，反映序列时间依赖性，而并行路径结合了我们设计的声学-语言相似性模块（ALSM），以时间的同时性促进跨模态交互。与现有的SSR基线OSUM模型相比，我们的方法参数量减少了88.4%，并在测试集上实现了八种风格下SSR准确性的30.3%提高。', 'title_zh': '说话风格识别的串并行双路径架构'}
{'arxiv_id': 'arXiv:2507.01028', 'title': 'Dual Perspectives on Non-Contrastive Self-Supervised Learning', 'authors': 'Jean Ponce, Basile Terver, Martial Hebert, Michael Arbel', 'link': 'https://arxiv.org/abs/2507.01028', 'abstract': 'The {\\em stop gradient} and {\\em exponential moving average} iterative procedures are commonly used in non-contrastive approaches to self-supervised learning to avoid representation collapse, with excellent performance in downstream applications in practice. This presentation investigates these procedures from the dual viewpoints of optimization and dynamical systems. We show that, in general, although they {\\em do not} optimize the original objective, or {\\em any} other smooth function, they {\\em do} avoid collapse Following~\\citet{Tian21}, but without any of the extra assumptions used in their proofs, we then show using a dynamical system perspective that, in the linear case, minimizing the original objective function without the use of a stop gradient or exponential moving average {\\em always} leads to collapse. Conversely, we characterize explicitly the equilibria of the dynamical systems associated with these two procedures in this linear setting as algebraic varieties in their parameter space, and show that they are, in general, {\\em asymptotically stable}. Our theoretical findings are illustrated by empirical experiments with real and synthetic data.', 'abstract_zh': '《梯度停止和指数移动平均迭代过程在非对比方法的自监督学习中的应用及其从优化和动力系统视角的探讨：在一般情况下，虽然它们不优化原始目标或任何其他光滑函数，但确实避免了表示坍塌。借助动力系统视角，我们证明，在线性情况下，不使用梯度停止或指数移动平均最小化原始目标函数总是会导致坍塌。相反，在线性设置中，我们明确表征了这两种过程相关动力系统的平衡点作为参数空间中的代数簇，并证明它们通常具有渐近稳定性。我们的理论发现通过实际和合成数据的实验证据予以说明。》', 'title_zh': '非对比自监督学习的双重视角'}
