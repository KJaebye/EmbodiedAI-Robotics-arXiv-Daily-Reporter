# Large-Scale LiDAR-Inertial Dataset for Degradation-Robust High-Precision Mapping 

**Title (ZH)**: 大规模激光雷达-惯性数据集以实现鲁棒高精度映射 

**Authors**: Xiaofeng Jin, Ningbo Bu, Shijie Wang, Jianfei Ge, Jiangjian Xiao, Matteo Matteucci  

**Link**: [PDF](https://arxiv.org/pdf/2507.20516)  

**Abstract**: This paper introduces a large-scale, high-precision LiDAR-Inertial Odometry (LIO) dataset, aiming to address the insufficient validation of LIO systems in complex real-world scenarios in existing research. The dataset covers four diverse real-world environments spanning 60,000 to 750,000 square meters, collected using a custom backpack-mounted platform equipped with multi-beam LiDAR, an industrial-grade IMU, and RTK-GNSS modules. The dataset includes long trajectories, complex scenes, and high-precision ground truth, generated by fusing SLAM-based optimization with RTK-GNSS anchoring, and validated for trajectory accuracy through the integration of oblique photogrammetry and RTK-GNSS. This dataset provides a comprehensive benchmark for evaluating the generalization ability of LIO systems in practical high-precision mapping scenarios. 

**Abstract (ZH)**: 本文介绍了大规模高精度激光雷达-惯性里程计（LIO）数据集，旨在解决现有研究中LIO系统在复杂真实场景下验证不足的问题。数据集涵盖了四个多样化的现实环境，面积从60,000到750,000平方米不等，采用定制的背负式平台收集数据，该平台配备有多束激光雷达、工业级IMU和RTK-GNSS模块。数据集包括长轨迹、复杂场景和通过将SLAM优化与RTK-GNSS锚定融合生成的高精度真值，并通过倾斜摄影测量和RTK-GNSS综合验证轨迹准确性。该数据集为评估LIO系统在实际高精度测绘场景下的泛化能力提供了全面的基准。 

---
# Bridging Simulation and Usability: A User-Friendly Framework for Scenario Generation in CARLA 

**Title (ZH)**: Simulation与可用性之间的桥梁：一个用户友好的CARLA场景生成框架 

**Authors**: Ahmed Abouelazm, Mohammad Mahmoud, Conrad Walter, Oleksandr Shchetsura, Erne Hussong, Helen Gremmelmaier, J. Marius Zöllner  

**Link**: [PDF](https://arxiv.org/pdf/2507.19883)  

**Abstract**: Autonomous driving promises safer roads, reduced congestion, and improved mobility, yet validating these systems across diverse conditions remains a major challenge. Real-world testing is expensive, time-consuming, and sometimes unsafe, making large-scale validation impractical. In contrast, simulation environments offer a scalable and cost-effective alternative for rigorous verification and validation. A critical component of the validation process is scenario generation, which involves designing and configuring traffic scenarios to evaluate autonomous systems' responses to various events and uncertainties. However, existing scenario generation tools often require programming knowledge, limiting accessibility for non-technical users. To address this limitation, we present an interactive, no-code framework for scenario generation. Our framework features a graphical interface that enables users to create, modify, save, load, and execute scenarios without needing coding expertise or detailed simulation knowledge. Unlike script-based tools such as Scenic or ScenarioRunner, our approach lowers the barrier to entry and supports a broader user base. Central to our framework is a graph-based scenario representation that facilitates structured management, supports both manual and automated generation, and enables integration with deep learning-based scenario and behavior generation methods. In automated mode, the framework can randomly sample parameters such as actor types, behaviors, and environmental conditions, allowing the generation of diverse and realistic test datasets. By simplifying the scenario generation process, this framework supports more efficient testing workflows and increases the accessibility of simulation-based validation for researchers, engineers, and policymakers. 

**Abstract (ZH)**: 自主驾驶 promises 更安全的道路、减少拥堵和提高流动性，然而在多样条件下验证这些系统依然是一项重大挑战。现实世界的测试昂贵、耗时且有时不安全，使得大规模验证变得不切实际。相比之下，仿真环境提供了严格的验证和验证的可扩展且成本效益高的替代方案。验证过程中的关键组成部分是情景生成，这涉及设计和配置交通情景以评估自主系统对各种事件和不确定性的响应。然而，现有的情景生成工具通常需要编程知识，限制了非技术人员的访问。为了克服这一限制，我们提出了一种无需编码的交互式框架来进行情景生成。该框架的特点是图形界面，允许用户无需编程专业知识或详细的仿真知识即可创建、修改、保存、加载和执行情景。与基于脚本的工具如Scenic或ScenarioRunner不同，我们的方法降低了入门门槛并支持更广泛的用户群体。我们框架的核心是一个基于图的情景表示，有助于结构化管理，支持手工和自动生成，并允许与基于深度学习的情景和行为生成方法集成。在自动模式下，该框架可以随机采样诸如角色类型、行为和环境条件等参数，从而生成多样且真实的测试数据集。通过简化情景生成过程，该框架支持更高效的测试工作流并增加了基于仿真的验证方法在研究人员、工程师和决策者中的可访问性。 

---
# Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control 

**Title (ZH)**: 基于同伦感知的分布式模型预测控制多agent导航 

**Authors**: Haoze Dong, Meng Guo, Chengyi He, Zhongkui Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.19860)  

**Abstract**: Multi-agent trajectory planning requires ensuring both safety and efficiency, yet deadlocks remain a significant challenge, especially in obstacle-dense environments. Such deadlocks frequently occur when multiple agents attempt to traverse the same long and narrow corridor simultaneously. To address this, we propose a novel distributed trajectory planning framework that bridges the gap between global path and local trajectory cooperation. At the global level, a homotopy-aware optimal path planning algorithm is proposed, which fully leverages the topological structure of the environment. A reference path is chosen from distinct homotopy classes by considering both its spatial and temporal properties, leading to improved coordination among agents globally. At the local level, a model predictive control-based trajectory optimization method is used to generate dynamically feasible and collision-free trajectories. Additionally, an online replanning strategy ensures its adaptability to dynamic environments. Simulations and experiments validate the effectiveness of our approach in mitigating deadlocks. Ablation studies demonstrate that by incorporating time-aware homotopic properties into the underlying global paths, our method can significantly reduce deadlocks and improve the average success rate from 4%-13% to over 90% in randomly generated dense scenarios. 

**Abstract (ZH)**: 多智能体轨迹规划需要同时保证安全性和效率，但在障碍密集环境中，死锁仍然是一个重大挑战。当多个智能体试图同时穿越相同的长而窄的走廊时，死锁经常发生。为此，我们提出了一种新颖的分布式轨迹规划框架，以弥合全局路径和局部轨迹合作之间的差距。在全局层面，提出了一种同伦意识最优路径规划算法，充分利用环境的拓扑结构。通过同时考虑参考路径的空间和时间特性，从不同的同伦类中选择路径，从而实现智能体在全局范围内的更好协调。在局部层面，采用模型预测控制为基础的轨迹优化方法生成动态可行且无碰撞的轨迹。此外，采用在线重规划策略确保其在动态环境中的适应性。仿真和实验验证了我们方法在缓解死锁方面的有效性。消融研究显示，通过将时间意识的同伦特性融入底层全局路径中，我们的方法可以显著减少死锁，并将随机生成的密集场景中的平均成功率从4%-13%提高到超过90%。 

---
# A 4D Radar Camera Extrinsic Calibration Tool Based on 3D Uncertainty Perspective N Points 

**Title (ZH)**: 基于三维不确定视角N点的4D雷达摄像机外参标定工具 

**Authors**: Chuan Cao, Xiaoning Wang, Wenqian Xi, Han Zhang, Weidong Chen, Jingchuan Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.19829)  

**Abstract**: 4D imaging radar is a type of low-cost millimeter-wave radar(costing merely 10-20$\%$ of lidar systems) capable of providing range, azimuth, elevation, and Doppler velocity information. Accurate extrinsic calibration between millimeter-wave radar and camera systems is critical for robust multimodal perception in robotics, yet remains challenging due to inherent sensor noise characteristics and complex error propagation. This paper presents a systematic calibration framework to address critical challenges through a spatial 3d uncertainty-aware PnP algorithm (3DUPnP) that explicitly models spherical coordinate noise propagation in radar measurements, then compensating for non-zero error expectations during coordinate transformations. Finally, experimental validation demonstrates significant performance improvements over state-of-the-art CPnP baseline, including improved consistency in simulations and enhanced precision in physical experiments. This study provides a robust calibration solution for robotic systems equipped with millimeter-wave radar and cameras, tailored specifically for autonomous driving and robotic perception applications. 

**Abstract (ZH)**: 4D成像雷达是一种低成本毫米波雷达（成本仅为激光雷达系统的10-20%），能够提供距离、方位、仰角和多普勒速度信息。毫米波雷达与摄像头系统的准确外部校准对于机器人鲁棒多模感知至关重要，但由于固有传感器噪声特性及复杂误差传播，这一任务仍然具有挑战性。本文提出了一种系统化的校准框架，通过空间三维不确定性感知PnP算法（3DUPnP），明确建模雷达测距中的球坐标噪声传播，并在坐标变换过程中补偿非零误差期望。实验验证显示，该方法在仿真和物理实验中均显著优于最先进的CPnP基线，包括一致性改进和精度提高。本研究为配备毫米波雷达和摄像头的机器人系统提供了一种鲁棒校准解决方案，特别适用于自主驾驶和机器人感知应用。 

---
# GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning 

**Title (ZH)**: GABRIL: 基于凝视正则化的方法以减轻模仿学习中的因果混淆 

**Authors**: Amin Banayeeanzade, Fatemeh Bahrani, Yutai Zhou, Erdem Bıyık  

**Link**: [PDF](https://arxiv.org/pdf/2507.19647)  

**Abstract**: Imitation Learning (IL) is a widely adopted approach which enables agents to learn from human expert demonstrations by framing the task as a supervised learning problem. However, IL often suffers from causal confusion, where agents misinterpret spurious correlations as causal relationships, leading to poor performance in testing environments with distribution shift. To address this issue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a novel method that leverages the human gaze data gathered during the data collection phase to guide the representation learning in IL. GABRIL utilizes a regularization loss which encourages the model to focus on causally relevant features identified through expert gaze and consequently mitigates the effects of confounding variables. We validate our approach in Atari environments and the Bench2Drive benchmark in CARLA by collecting human gaze datasets and applying our method in both domains. Experimental results show that the improvement of GABRIL over behavior cloning is around 179% more than the same number for other baselines in the Atari and 76% in the CARLA setup. Finally, we show that our method provides extra explainability when compared to regular IL agents. 

**Abstract (ZH)**: 基于注视的强化学习正则化在模仿学习中的应用（GAze-Based Regularization in Imitation Learning, GABRIL） 

---
# Flow Matching Policy Gradients 

**Title (ZH)**: 流匹配策略梯度 

**Authors**: David McAllister, Songwei Ge, Brent Yi, Chung Min Kim, Ethan Weber, Hongsuk Choi, Haiwen Feng, Angjoo Kanazawa  

**Link**: [PDF](https://arxiv.org/pdf/2507.21053)  

**Abstract**: Flow-based generative models, including diffusion models, excel at modeling continuous distributions in high-dimensional spaces. In this work, we introduce Flow Policy Optimization (FPO), a simple on-policy reinforcement learning algorithm that brings flow matching into the policy gradient framework. FPO casts policy optimization as maximizing an advantage-weighted ratio computed from the conditional flow matching loss, in a manner compatible with the popular PPO-clip framework. It sidesteps the need for exact likelihood computation while preserving the generative capabilities of flow-based models. Unlike prior approaches for diffusion-based reinforcement learning that bind training to a specific sampling method, FPO is agnostic to the choice of diffusion or flow integration at both training and inference time. We show that FPO can train diffusion-style policies from scratch in a variety of continuous control tasks. We find that flow-based models can capture multimodal action distributions and achieve higher performance than Gaussian policies, particularly in under-conditioned settings. 

**Abstract (ZH)**: 基于流的生成模型，包括扩散模型，在高维空间中 excel 于建模连续分布。在本文中，我们引入了流策略优化（FPO），这是一种将流匹配引入策略梯度框架的简单在线策略强化学习算法。FPO 将策略优化视为最大化由条件流匹配损失计算的优势加权比，以与流行的 PPO-clip 框架兼容。它避免了精确似然计算的需要，同时保留了基于流的模型的生成能力。与基于扩散的强化学习的先前方法不同，FPO 在训练和推理时对扩散或流的集成选择不敏感。我们展示了 FPO 可以从各种连续控制任务中训练出扩散风格的策略。我们发现，基于流的模型可以捕捉多模态动作分布，并且在欠约束设置中，其性能优于高斯策略。 

---
# Partially Observable Monte-Carlo Graph Search 

**Title (ZH)**: 部分可观测蒙特卡罗图搜索 

**Authors**: Yang You, Vincent Thomas, Alex Schutz, Robert Skilton, Nick Hawes, Olivier Buffet  

**Link**: [PDF](https://arxiv.org/pdf/2507.20951)  

**Abstract**: Currently, large partially observable Markov decision processes (POMDPs) are often solved by sampling-based online methods which interleave planning and execution phases. However, a pre-computed offline policy is more desirable in POMDP applications with time or energy constraints. But previous offline algorithms are not able to scale up to large POMDPs. In this article, we propose a new sampling-based algorithm, the partially observable Monte-Carlo graph search (POMCGS) to solve large POMDPs offline. Different from many online POMDP methods, which progressively develop a tree while performing (Monte-Carlo) simulations, POMCGS folds this search tree on the fly to construct a policy graph, so that computations can be drastically reduced, and users can analyze and validate the policy prior to embedding and executing it. Moreover, POMCGS, together with action progressive widening and observation clustering methods provided in this article, is able to address certain continuous POMDPs. Through experiments, we demonstrate that POMCGS can generate policies on the most challenging POMDPs, which cannot be computed by previous offline algorithms, and these policies' values are competitive compared with the state-of-the-art online POMDP algorithms. 

**Abstract (ZH)**: 当前，大型部分可观测马尔可夫决策过程（POMDP）通常通过交错规划和执行阶段的基于采样的在线方法来求解。然而，在具有时间或能量约束的POMDP应用中，预先计算的离线策略更有优势。但之前的离线算法无法扩展到大型POMDP。在本文中，我们提出了一种新的基于采样的算法——部分可观测蒙特卡洛图搜索（POMCGS），用于解决大型POMDP的离线问题。与许多在线POMDP方法不同，POMCGS 边执行（蒙特卡洛）模拟边实时折叠搜索树以构建策略图，从而大幅减少计算量，并使用户能够在嵌入和执行策略之前对其进行分析和验证。此外，通过提供动作逐步放宽和观测聚类方法，POMCGS 能够解决某些连续POMDP。实验结果表明，POMCGS 能够生成前人离线算法无法计算的最具挑战性的POMDP的策略，且这些策略的价值与最新的在线POMDP算法相当。 

---
# ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories 

**Title (ZH)**: ACCESS-AV：面向智能工厂自主车辆定位的自适应通信-计算协同设计 

**Authors**: Rajat Bhattacharjya, Arnab Sarkar, Ish Kool, Sabur Baidya, Nikil Dutt  

**Link**: [PDF](https://arxiv.org/pdf/2507.20399)  

**Abstract**: Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting goods in 5G network-enabled smart factories, with the compute-intensive localization module presenting a significant opportunity for optimization. We propose ACCESS-AV, an energy-efficient Vehicle-to-Infrastructure (V2I) localization framework that leverages existing 5G infrastructure in smart factory environments. By opportunistically accessing the periodically broadcast 5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates the need for dedicated Roadside Units (RSUs) or additional onboard sensors to achieve energy efficiency as well as cost reduction. We implement an Angle-of-Arrival (AoA)-based estimation method using the Multiple Signal Classification (MUSIC) algorithm, optimized for resource-constrained ADV platforms through an adaptive communication-computation strategy that dynamically balances energy consumption with localization accuracy based on environmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle velocity. Experimental results demonstrate that ACCESS-AV achieves an average energy reduction of 43.09% compared to non-adaptive systems employing AoA algorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30 cm localization accuracy while also delivering substantial reductions in infrastructure and operational costs, establishing its viability for sustainable smart factory environments. 

**Abstract (ZH)**: 基于5G基础设施的自主配送车辆（ADVs）能量高效V2I定位框架：ACCESS-AV 

---
# Optimizing Spreading Factor Selection for Mobile LoRa Gateways Using Single-Channel Hardware 

**Title (ZH)**: 使用单通道硬件优化移动LoRa网关的扩频因子选择 

**Authors**: W. A. Sasindu Wijesuriya  

**Link**: [PDF](https://arxiv.org/pdf/2507.19938)  

**Abstract**: The deployment of mobile LoRa gateways using low-cost single-channel hardware presents a significant challenge in maintaining reliable communication due to the lack of dynamic configuration support. In traditional LoRaWAN networks, Adaptive Data Rate (ADR) mechanisms optimize communication parameters in real time. However, such features are typically supported only by expensive multi-channel gateways. This study proposes a cost-effective and energy-efficient solution by statically selecting the optimal Spreading Factor (SF) using a two-phase algorithm. The method first applies rule-based exclusion to eliminate SFs that violate constraints related to distance, data rate, link margin, and regulatory limits. Remaining candidates are then evaluated using a weighted scoring model incorporating Time-on-Air, energy consumption, data rate, and link robustness. The proposed algorithm was validated through extensive field tests and NS-3 simulations under line-of-sight conditions. Results demonstrate that the selected SF matched the optimal SF in over 92% of cases across 672 simulated scenarios, confirming the algorithm's effectiveness. This approach offers a scalable alternative to dynamic protocols, enabling reliable mobile LoRa deployments in cost-sensitive environments such as agriculture and rural sensing applications. 

**Abstract (ZH)**: 使用低成本单通道硬件部署移动LoRa网关因其缺乏动态配置支持而在保持可靠通信方面面临重大挑战。通过一种两阶段算法静态选择最优扩频因子(SF)，本研究提出了一种低成本和节能的解决方案。该方法首先采用基于规则的排除法来消除违反距离、数据率、链路余量和监管限制的SF。剩余候选SF再通过综合考虑空中时间、能耗、数据率和链路稳健性的加权评分模型进行评估。所提算法通过视线条件下的广泛现场测试和NS-3仿真进行了验证。结果表明，在672个模拟场景中，所选SF与最优SF匹配的比例超过92%，证明了该算法的有效性。该方法为动态协议提供了一种可扩展的替代方案，在农业和农村传感等成本敏感环境中实现可靠的移动LoRa部署。 

---
# Smart Expansion Techniques for ASP-based Interactive Configuration 

**Title (ZH)**: 基于ASP的交互配置的智能扩展技术 

**Authors**: Lucia Balážová, Richard Comploi-Taupe, Susana Hahn, Nicolas Rühling, Gottfried Schenner  

**Link**: [PDF](https://arxiv.org/pdf/2507.21027)  

**Abstract**: Product configuration is a successful application of Answer Set Programming (ASP). However, challenges are still open for interactive systems to effectively guide users through the configuration process. The aim of our work is to provide an ASP-based solver for interactive configuration that can deal with large-scale industrial configuration problems and that supports intuitive user interfaces via an API. In this paper, we focus on improving the performance of automatically completing a partial configuration. Our main contribution enhances the classical incremental approach for multi-shot solving by four different smart expansion functions. The core idea is to determine and add specific objects or associations to the partial configuration by exploiting cautious and brave consequences before checking for the existence of a complete configuration with the current objects in each iteration. This approach limits the number of costly unsatisfiability checks and reduces the search space, thereby improving solving performance. In addition, we present a user interface that uses our API and is implemented in ASP. 

**Abstract (ZH)**: 基于ASP的交互配置求解器及其应用：改进部分配置自动完成的性能并通过API支持直观用户界面 

---
# On the Limits of Hierarchically Embedded Logic in Classical Neural Networks 

**Title (ZH)**: 经典神经网络中层次嵌套逻辑的局限性 

**Authors**: Bill Cochran  

**Link**: [PDF](https://arxiv.org/pdf/2507.20960)  

**Abstract**: We propose a formal model of reasoning limitations in large neural net models for language, grounded in the depth of their neural architecture. By treating neural networks as linear operators over logic predicate space we show that each layer can encode at most one additional level of logical reasoning. We prove that a neural network of depth a particular depth cannot faithfully represent predicates in a one higher order logic, such as simple counting over complex predicates, implying a strict upper bound on logical expressiveness. This structure induces a nontrivial null space during tokenization and embedding, excluding higher-order predicates from representability. Our framework offers a natural explanation for phenomena such as hallucination, repetition, and limited planning, while also providing a foundation for understanding how approximations to higher-order logic may emerge. These results motivate architectural extensions and interpretability strategies in future development of language models. 

**Abstract (ZH)**: 我们提出了一个基于神经网络架构深度的自然语言大规模神经网络推理限制的正式模型。通过将神经网络视为逻辑谓词空间上的线性算子，我们证明每一层最多只能编码一个额外的逻辑推理层次。我们证明了一个特定深度的神经网络无法忠实表示更高阶逻辑中的谓词，比如复杂谓词的简单计数，从而对逻辑表达能力施加了一个严格的上限。这种结构会在分词和嵌入过程中诱导出一个非平凡的零空间，排除了更高阶谓词的可表示性。我们的框架为解释幻觉、重复以及有限规划等现象提供了自然的解释，同时也为理解更高阶逻辑近似如何出现提供了基础。这些结果促使我们未来在语言模型开发中探索架构扩展和可解释性策略。 

---
# How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection, and Activation 

**Title (ZH)**: 链式思考是如何工作的？追踪从解码、投影到激活的信息流 

**Authors**: Hao Yang, Qinghua Zhao, Lei Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.20758)  

**Abstract**: Chain-of-Thought (CoT) prompting significantly enhances model reasoning, yet its internal mechanisms remain poorly understood. We analyze CoT's operational principles by reversely tracing information flow across decoding, projection, and activation phases. Our quantitative analysis suggests that CoT may serve as a decoding space pruner, leveraging answer templates to guide output generation, with higher template adherence strongly correlating with improved performance. Furthermore, we surprisingly find that CoT modulates neuron engagement in a task-dependent manner: reducing neuron activation in open-domain tasks, yet increasing it in closed-domain scenarios. These findings offer a novel mechanistic interpretability framework and critical insights for enabling targeted CoT interventions to design more efficient and robust prompts. We released our code and data at this https URL. 

**Abstract (ZH)**: Chain-of-Thought (CoT) 提示显著增强了模型推理能力，但其内部机制仍不完全理解。我们通过反向追踪解码、投影和激活阶段的信息流来分析 CoT 的运作原理。我们的量化分析表明，CoT 可能充当一个解码空间剪枝器，利用答案模板引导输出生成，且模板的高遵从性与性能的提升有密切关系。此外，我们惊讶地发现，CoT 以任务依赖的方式调节神经元参与：在开放式任务中减少神经元激活，在封闭式任务中增加神经元激活。这些发现提供了一种新的机制可解释性框架，并为设计更高效和稳健的提示提供了关键见解。我们已在此网址发布了我们的代码和数据：this https URL。 

---
# Beyond Listenership: AI-Predicted Interventions Drive Improvements in Maternal Health Behaviours 

**Title (ZH)**: 超越听众效应：AI 预测干预促进孕产妇健康行为改善 

**Authors**: Arpan Dasgupta, Sarvesh Gharat, Neha Madhiwalla, Aparna Hegde, Milind Tambe, Aparna Taneja  

**Link**: [PDF](https://arxiv.org/pdf/2507.20755)  

**Abstract**: Automated voice calls with health information are a proven method for disseminating maternal and child health information among beneficiaries and are deployed in several programs around the world. However, these programs often suffer from beneficiary dropoffs and poor engagement. In previous work, through real-world trials, we showed that an AI model, specifically a restless bandit model, could identify beneficiaries who would benefit most from live service call interventions, preventing dropoffs and boosting engagement. However, one key question has remained open so far: does such improved listenership via AI-targeted interventions translate into beneficiaries' improved knowledge and health behaviors? We present a first study that shows not only listenership improvements due to AI interventions, but also simultaneously links these improvements to health behavior changes. Specifically, we demonstrate that AI-scheduled interventions, which enhance listenership, lead to statistically significant improvements in beneficiaries' health behaviors such as taking iron or calcium supplements in the postnatal period, as well as understanding of critical health topics during pregnancy and infancy. This underscores the potential of AI to drive meaningful improvements in maternal and child health. 

**Abstract (ZH)**: 基于AI的自动语音呼叫在传递 maternal和child健康信息方面的应用及其对受益者健康行为的影响研究 

---
# Learning the Value Systems of Societies from Preferences 

**Title (ZH)**: 从偏好中学习社会的价值系统 

**Authors**: Andrés Holgado-Sánchez, Holger Billhardt, Sascha Ossowski, Sara Degli-Esposti  

**Link**: [PDF](https://arxiv.org/pdf/2507.20728)  

**Abstract**: Aligning AI systems with human values and the value-based preferences of various stakeholders (their value systems) is key in ethical AI. In value-aware AI systems, decision-making draws upon explicit computational representations of individual values (groundings) and their aggregation into value systems. As these are notoriously difficult to elicit and calibrate manually, value learning approaches aim to automatically derive computational models of an agent's values and value system from demonstrations of human behaviour. Nonetheless, social science and humanities literature suggest that it is more adequate to conceive the value system of a society as a set of value systems of different groups, rather than as the simple aggregation of individual value systems. Accordingly, here we formalize the problem of learning the value systems of societies and propose a method to address it based on heuristic deep clustering. The method learns socially shared value groundings and a set of diverse value systems representing a given society by observing qualitative value-based preferences from a sample of agents. We evaluate the proposal in a use case with real data about travelling decisions. 

**Abstract (ZH)**: 使AI系统与人类价值观及各相关方的价值观基础偏好对齐是伦理AI的关键。在价值意识AI系统中，决策依赖于个体价值观的明确计算表示（根基）及其聚合为价值系统。由于这些价值观难以手动获取和校准，因此价值学习方法旨在从人类行为示范中自动推导出代理的价值及其价值系统的计算模型。然而，社会科学和人文科学研究表明，社会的价值系统更适合作为不同群体价值系统的集合，而不是简单聚合的个体价值系统。据此，我们正式化了学习社会价值系统的难题，并提出了一种基于启发式深度聚类的方法。该方法通过观察一组代理的定性价值基础偏好来学习社会共享的价值根基和一组代表给定社会的多样化价值系统。我们在一个实际旅行决策使用案例中评估了该方法。 

---
# Algorithmic Fairness: A Runtime Perspective 

**Title (ZH)**: 算法公平性：运行时视角 

**Authors**: Filip Cano, Thomas A. Henzinger, Konstantin Kueffner  

**Link**: [PDF](https://arxiv.org/pdf/2507.20711)  

**Abstract**: Fairness in AI is traditionally studied as a static property evaluated once, over a fixed dataset. However, real-world AI systems operate sequentially, with outcomes and environments evolving over time. This paper proposes a framework for analysing fairness as a runtime property. Using a minimal yet expressive model based on sequences of coin tosses with possibly evolving biases, we study the problems of monitoring and enforcing fairness expressed in either toss outcomes or coin biases. Since there is no one-size-fits-all solution for either problem, we provide a summary of monitoring and enforcement strategies, parametrised by environment dynamics, prediction horizon, and confidence thresholds. For both problems, we present general results under simple or minimal assumptions. We survey existing solutions for the monitoring problem for Markovian and additive dynamics, and existing solutions for the enforcement problem in static settings with known dynamics. 

**Abstract (ZH)**: AI中的公平性 traditionally studied as a static property evaluated once over a fixed dataset, is proposed to be analyzed as a runtime property in sequentially operating real-world AI systems. 

---
# A General Framework for Dynamic MAPF using Multi-Shot ASP and Tunnels 

**Title (ZH)**: 动态MAPF问题的通用框架：基于多轮ASP和隧道的方法 

**Authors**: Aysu Bogatarkan, Esra Erdem  

**Link**: [PDF](https://arxiv.org/pdf/2507.20703)  

**Abstract**: MAPF problem aims to find plans for multiple agents in an environment within a given time, such that the agents do not collide with each other or obstacles. Motivated by the execution and monitoring of these plans, we study Dynamic MAPF (D-MAPF) problem, which allows changes such as agents entering/leaving the environment or obstacles being removed/moved. Considering the requirements of real-world applications in warehouses with the presence of humans, we introduce 1) a general definition for D-MAPF (applicable to variations of D-MAPF), 2) a new framework to solve D-MAPF (utilizing multi-shot computation, and allowing different methods to solve D-MAPF), and 3) a new ASP-based method to solve D-MAPF (combining advantages of replanning and repairing methods, with a novel concept of tunnels to specify where agents can move). We have illustrated the strengths and weaknesses of this method by experimental evaluations, from the perspectives of computational performance and quality of solutions. 

**Abstract (ZH)**: 多代理路径规划（MAPF）问题旨在在一个给定时间内为多个代理在环境中寻找计划，使得代理之间或与障碍物之间不发生碰撞。受执行和监控这些计划的需求启发，我们研究动态多代理路径规划（D-MAPF）问题，该问题允许代理进入/离开环境或障碍物被移除/移动。考虑到仓库中存在人类的需求，我们引入了1）一种通用的D-MAPF定义（适用于D-MAPF的各种变体），2）一种新的框架来解决D-MAPF（利用多轮计算，并允许使用不同的方法解决D-MAPF），以及3）一种新的基于ASP的方法来解决D-MAPF（结合重规划和修复方法的优势，并引入新的概念“隧道”来指定代理可以移动的位置）。我们从计算性能和解决方案质量的角度通过实验评估展示了该方法的优点和不足。 

---
# Adaptive Fuzzy Time Series Forecasting via Partially Asymmetric Convolution and Sub-Sliding Window Fusion 

**Title (ZH)**: 基于部分非对称卷积和子滑动窗口融合的自适应模糊时间序列预测 

**Authors**: Lijian Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.20641)  

**Abstract**: At present, state-of-the-art forecasting models are short of the ability to capture spatio-temporal dependency and synthesize global information at the stage of learning. To address this issue, in this paper, through the adaptive fuzzified construction of temporal data, we propose a novel convolutional architecture with partially asymmetric design based on the scheme of sliding window to realize accurate time series forecasting. First, the construction strategy of traditional fuzzy time series is improved to further extract short and long term temporal interrelation, which enables every time node to automatically possess corresponding global information and inner relationships among them in a restricted sliding window and the process does not require human involvement. Second, a bilateral Atrous algorithm is devised to reduce calculation demand of the proposed model without sacrificing global characteristics of elements. And it also allows the model to avoid processing redundant information. Third, after the transformation of time series, a partially asymmetric convolutional architecture is designed to more flexibly mine data features by filters in different directions on feature maps, which gives the convolutional neural network (CNN) the ability to construct sub-windows within existing sliding windows to model at a more fine-grained level. And after obtaining the time series information at different levels, the multi-scale features from different sub-windows will be sent to the corresponding network layer for time series information fusion. Compared with other competitive modern models, the proposed method achieves state-of-the-art results on most of popular time series datasets, which is fully verified by the experimental results. 

**Abstract (ZH)**: 基于滑窗部分非对称设计的自适应模糊化时序预测新型卷积架构 

---
# Complementarity-driven Representation Learning for Multi-modal Knowledge Graph Completion 

**Title (ZH)**: 基于互补性的表示学习以实现多模态知识图谱 completion 

**Authors**: Lijian Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.20620)  

**Abstract**: Multi-modal Knowledge Graph Completion (MMKGC) aims to uncover hidden world knowledge in multimodal knowledge graphs by leveraging both multimodal and structural entity information. However, the inherent imbalance in multimodal knowledge graphs, where modality distributions vary across entities, poses challenges in utilizing additional modality data for robust entity representation. Existing MMKGC methods typically rely on attention or gate-based fusion mechanisms but overlook complementarity contained in multi-modal data. In this paper, we propose a novel framework named Mixture of Complementary Modality Experts (MoCME), which consists of a Complementarity-guided Modality Knowledge Fusion (CMKF) module and an Entropy-guided Negative Sampling (EGNS) mechanism. The CMKF module exploits both intra-modal and inter-modal complementarity to fuse multi-view and multi-modal embeddings, enhancing representations of entities. Additionally, we introduce an Entropy-guided Negative Sampling mechanism to dynamically prioritize informative and uncertain negative samples to enhance training effectiveness and model robustness. Extensive experiments on five benchmark datasets demonstrate that our MoCME achieves state-of-the-art performance, surpassing existing approaches. 

**Abstract (ZH)**: 多模态知识图完成（MMKGC）旨在通过利用多模态和结构性实体信息来揭示多模态知识图中的隐藏世界知识。然而，多模态知识图中固有的不平衡性，即不同实体之间模态分布的差异，对利用额外模态数据进行稳健实体表示提出了挑战。现有的MMKGC方法通常依赖于注意力或门控融合机制，但忽略了多模态数据中包含的互补性。本文提出了一种名为互补模态专家混合（MoCME）的新型框架，该框架包括一种互补性引导的模态知识融合（CMKF）模块和一种熵引导的负采样（EGNS）机制。CMKF模块利用内在模态和跨模态互补性来融合多视图和多模态嵌入，增强实体表示。此外，我们引入了一种熵引导的负采样机制，以动态优先选择信息性和不确定性的负样本，从而增强训练效果和模型鲁棒性。在五个基准数据集上的广泛实验表明，我们的MoCME达到了最先进的性能，超越了现有方法。 

---
# Unlearning of Knowledge Graph Embedding via Preference Optimization 

**Title (ZH)**: 知识图嵌入的反学习通过偏好优化 

**Authors**: Jiajun Liu, Wenjun Ke, Peng Wang, Yao He, Ziyu Shang, Guozheng Li, Zijie Xu, Ke Ji  

**Link**: [PDF](https://arxiv.org/pdf/2507.20566)  

**Abstract**: Existing knowledge graphs (KGs) inevitably contain outdated or erroneous knowledge that needs to be removed from knowledge graph embedding (KGE) models. To address this challenge, knowledge unlearning can be applied to eliminate specific information while preserving the integrity of the remaining knowledge in KGs. Existing unlearning methods can generally be categorized into exact unlearning and approximate unlearning. However, exact unlearning requires high training costs while approximate unlearning faces two issues when applied to KGs due to the inherent connectivity of triples: (1) It fails to fully remove targeted information, as forgetting triples can still be inferred from remaining ones. (2) It focuses on local data for specific removal, which weakens the remaining knowledge in the forgetting boundary. To address these issues, we propose GraphDPO, a novel approximate unlearning framework based on direct preference optimization (DPO). Firstly, to effectively remove forgetting triples, we reframe unlearning as a preference optimization problem, where the model is trained by DPO to prefer reconstructed alternatives over the original forgetting triples. This formulation penalizes reliance on forgettable knowledge, mitigating incomplete forgetting caused by KG connectivity. Moreover, we introduce an out-boundary sampling strategy to construct preference pairs with minimal semantic overlap, weakening the connection between forgetting and retained knowledge. Secondly, to preserve boundary knowledge, we introduce a boundary recall mechanism that replays and distills relevant information both within and across time steps. We construct eight unlearning datasets across four popular KGs with varying unlearning rates. Experiments show that GraphDPO outperforms state-of-the-art baselines by up to 10.1% in MRR_Avg and 14.0% in MRR_F1. 

**Abstract (ZH)**: 现有的知识图谱不可避免地包含过时或错误的知识，需要从知识图谱嵌入（KGE）模型中移除。为应对这一挑战，可以通过知识遗忘技术来消除特定信息，同时保持知识图谱中剩余知识的完整性。现有的遗忘方法可以一般性地归类为精确遗忘和近似遗忘。然而，精确遗忘需要高昂的训练成本，而近似遗忘在应用于知识图谱时由于三元组的内在关联性面临两个问题：（1）难以完全移除目标信息，因为可以通过剩余的三元组推断出被遗忘的三元组。 （2）它侧重于局部数据进行特定移除，这会在遗忘边界弱化剩余知识。为解决这些问题，我们提出了一种基于直接偏好优化（DPO）的近似遗忘框架GraphDPO。首先，为了有效移除被遗忘的三元组，我们将遗忘重新定义为一个偏好优化问题，通过DPO训练模型以偏好重构的替代方案而非原始被遗忘的三元组。这种形式通过惩罚依赖遗忘知识来减轻由于知识图谱连接性导致的不完全遗忘。此外，我们引入了一种边界外采样策略，以最小的语义重叠构建偏好对，从而减弱遗忘与保留知识之间的联系。其次，为了保持边界知识，我们引入了一个边界召回机制，在时间和跨时间步内部和外部回放和提炼相关信息。我们在四个流行的知识图谱上构建了八个具有不同遗忘率的遗忘数据集。实验结果显示，在MRR_Avg方面，GraphDPO比最先进的基线高出10.1%，在MRR_F1方面高出14.0%。 

---
# Enhancing QoS in Edge Computing through Federated Layering Techniques: A Pathway to Resilient AI Lifelong Learning Systems 

**Title (ZH)**: 通过联邦分层技术提升边缘计算服务质量：通往稳健的终身学习AI系统的途径 

**Authors**: Chengzhuo Han  

**Link**: [PDF](https://arxiv.org/pdf/2507.20444)  

**Abstract**: In the context of the rapidly evolving information technology landscape, marked by the advent of 6G communication networks, we face an increased data volume and complexity in network environments. This paper addresses these challenges by focusing on Quality of Service (QoS) in edge computing frameworks. We propose a novel approach to enhance QoS through the development of General Artificial Intelligence Lifelong Learning Systems, with a special emphasis on Federated Layering Techniques (FLT). Our work introduces a federated layering-based small model collaborative mechanism aimed at improving AI models' operational efficiency and response time in environments where resources are limited. This innovative method leverages the strengths of cloud and edge computing, incorporating a negotiation and debate mechanism among small AI models to enhance reasoning and decision-making processes. By integrating model layering techniques with privacy protection measures, our approach ensures the secure transmission of model parameters while maintaining high efficiency in learning and reasoning capabilities. The experimental results demonstrate that our strategy not only enhances learning efficiency and reasoning accuracy but also effectively protects the privacy of edge nodes. This presents a viable solution for achieving resilient large model lifelong learning systems, with a significant improvement in QoS for edge computing environments. 

**Abstract (ZH)**: 在6G通信网络迅猛发展的信息技术背景下，网络环境中面临的数据量和复杂性增加。本文通过关注边缘计算框架中的服务质量（QoS）来应对这些挑战。我们提出了一种通过开发通用人工智能终身学习系统来提升QoS的新方法，特别强调了联邦分层技术（FLT）。我们的工作引入了一种基于联邦分层的小模型协作机制，旨在在资源有限的环境中提高AI模型的运行效率和响应时间。该创新方法结合了云和边缘计算的优势，并通过小AI模型之间的谈判和辩论机制增强推理和决策过程。通过将模型分层技术与隐私保护措施相结合，我们的方法确保了模型参数的安全传输，并在学习和推理能力方面保持高效。实验结果表明，我们的策略不仅提高了学习效率和推理准确性，还有效保护了边缘节点的隐私。这为实现具有显著QoS改进的健壮的大模型终身学习系统提供了一个可行的解决方案。 

---
# Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping 

**Title (ZH)**: 多层次自适应分组的多代理强化学习动态移动资源分配 

**Authors**: Farshid Nooshi, Suining He  

**Link**: [PDF](https://arxiv.org/pdf/2507.20377)  

**Abstract**: Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing vehicles) is crucial for rebalancing the mobility demand and supply in the urban environments. We propose in this work a novel multi-agent reinforcement learning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS) for dynamic mobility resource allocation. HAG-PS aims to address two important research challenges regarding multi-agent reinforcement learning for mobility resource allocation: (1) how to dynamically and adaptively share the mobility resource allocation policy (i.e., how to distribute mobility resources) across agents (i.e., representing the regional coordinators of mobility resources); and (2) how to achieve memory-efficient parameter sharing in an urban-scale setting. To address the above challenges, we have provided following novel designs within HAG-PS. To enable dynamic and adaptive parameter sharing, we have designed a hierarchical approach that consists of global and local information of the mobility resource states (e.g., distribution of mobility resources). We have developed an adaptive agent grouping approach in order to split or merge the groups of agents based on their relative closeness of encoded trajectories (i.e., states, actions, and rewards). We have designed a learnable identity (ID) embeddings to enable agent specialization beyond simple parameter copy. We have performed extensive experimental studies based on real-world NYC bike sharing data (a total of more than 1.2 million trips), and demonstrated the superior performance (e.g., improved bike availability) of HAG-PS compared with other baseline approaches. 

**Abstract (ZH)**: 基于层次自适应分组的参数共享的多agents强化学习方法：动态移动资源分配 

---
# A Multi-Agent System for Information Extraction from the Chemical Literature 

**Title (ZH)**: 化学文献中信息提取的多代理系统 

**Authors**: Yufan Chen, Ching Ting Leung, Bowen Yu, Jianwei Sun, Yong Huang, Linyan Li, Hao Chen, Hanyu Gao  

**Link**: [PDF](https://arxiv.org/pdf/2507.20230)  

**Abstract**: To fully expedite AI-powered chemical research, high-quality chemical databases are the cornerstone. Automatic extraction of chemical information from the literature is essential for constructing reaction databases, but it is currently limited by the multimodality and style variability of chemical information. In this work, we developed a multimodal large language model (MLLM)-based multi-agent system for automatic chemical information extraction. We used the MLLM's strong reasoning capability to understand the structure of complex chemical graphics, decompose the extraction task into sub-tasks and coordinate a set of specialized agents to solve them. Our system achieved an F1 score of 80.8% on a benchmark dataset of complex chemical reaction graphics from the literature, surpassing the previous state-of-the-art model (F1 score: 35.6%) by a significant margin. Additionally, it demonstrated consistent improvements in key sub-tasks, including molecular image recognition, reaction image parsing, named entity recognition and text-based reaction extraction. This work is a critical step toward automated chemical information extraction into structured datasets, which will be a strong promoter of AI-driven chemical research. 

**Abstract (ZH)**: 基于多模态大型语言模型的多智能体系统在自动化学信息提取中的应用：推动AI驱动的化学研究 

---
# Improving Subgraph Matching by Combining Algorithms and Graph Neural Networks 

**Title (ZH)**: 通过结合算法和图神经网络提高子图匹配性能 

**Authors**: Shuyang Guo, Wenjin Xie, Ping Lu, Ting Deng, Richong Zhang, Jianxin Li, Xiangping Huang, Zhongyi Liu  

**Link**: [PDF](https://arxiv.org/pdf/2507.20226)  

**Abstract**: Homomorphism is a key mapping technique between graphs that preserves their structure. Given a graph and a pattern, the subgraph homomorphism problem involves finding a mapping from the pattern to the graph, ensuring that adjacent vertices in the pattern are mapped to adjacent vertices in the graph. Unlike subgraph isomorphism, which requires a one-to-one mapping, homomorphism allows multiple vertices in the pattern to map to the same vertex in the graph, making it more complex. We propose HFrame, the first graph neural network-based framework for subgraph homomorphism, which integrates traditional algorithms with machine learning techniques. We demonstrate that HFrame outperforms standard graph neural networks by being able to distinguish more graph pairs where the pattern is not homomorphic to the graph. Additionally, we provide a generalization error bound for HFrame. Through experiments on both real-world and synthetic graphs, we show that HFrame is up to 101.91 times faster than exact matching algorithms and achieves an average accuracy of 0.962. 

**Abstract (ZH)**: 图同构是图之间保留其结构的关键映射技术。给定一个图和一个模式，子图同构问题涉及将模式映射到图中，使得模式中的相邻顶点在图中被映射到相邻的顶点。与需要一对一映射的子图同构不同，同构允许模式中的多个顶点映射到图中的同一个顶点，使其更加复杂。我们提出HFrame，这是一种基于图神经网络的子图同构框架，将传统算法与机器学习技术相结合。我们证明HFrame优于标准图神经网络，因为它能够区分更多的图对，在这些图对中模式与图不是同构的。此外，我们还为HFrame提供了泛化误差界。通过在真实世界和合成图上的实验，我们展示了HFrame比精确匹配算法快至101.91倍，并且平均准确率为0.962。 

---
# StepFun-Prover Preview: Let's Think and Verify Step by Step 

**Title (ZH)**: StepFun-Prover 预览：逐步思考与验证 

**Authors**: Shijie Shang, Ruosi Wan, Yue Peng, Yutong Wu, Xiong-hui Chen, Jie Yan, Xiangyu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.20199)  

**Abstract**: We present StepFun-Prover Preview, a large language model designed for formal theorem proving through tool-integrated reasoning. Using a reinforcement learning pipeline that incorporates tool-based interactions, StepFun-Prover can achieve strong performance in generating Lean 4 proofs with minimal sampling. Our approach enables the model to emulate human-like problem-solving strategies by iteratively refining proofs based on real-time environment feedback. On the miniF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of $70.0\%$. Beyond advancing benchmark performance, we introduce an end-to-end training framework for developing tool-integrated reasoning models, offering a promising direction for automated theorem proving and Math AI assistant. 

**Abstract (ZH)**: StepFun-Prover Preview：一种通过工具集成推理进行形式定理证明的大型语言模型 

---
# Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems 

**Title (ZH)**: 寻找不可满足稳定室友问题的个性化足够解 

**Authors**: Müge Fidan, Esra Erdem  

**Link**: [PDF](https://arxiv.org/pdf/2507.20010)  

**Abstract**: The Stable Roommates problems are characterized by the preferences of agents over other agents as roommates. A solution is a partition of the agents into pairs that are acceptable to each other (i.e., they are in the preference lists of each other), and the matching is stable (i.e., there do not exist any two agents who prefer each other to their roommates, and thus block the matching). Motivated by real-world applications, and considering that stable roommates problems do not always have solutions, we continue our studies to compute "good-enough" matchings. In addition to the agents' habits and habitual preferences, we consider their networks of preferred friends, and introduce a method to generate personalized solutions to stable roommates problems. We illustrate the usefulness of our method with examples and empirical evaluations. 

**Abstract (ZH)**: roommate分配问题由代理人对其他代理人的偏好特性确定。一个解决方案是将代理人划分为彼此接受的配对（即，他们彼此在各自的偏好列表中），并且该配对是稳定的（即，不存在任何两个代理人更喜欢彼此而不是他们的室友，从而阻止该配对）。受实际应用场景的启发，并考虑到roommate分配问题并非总是存在解决方案，我们继续研究计算“足够好”的配对方案。除了考虑代理人的习惯和惯常偏好之外，我们还考虑了他们偏好的社交网络，并引入了一种生成个性化roommate分配问题解决方案的方法。我们通过示例和实证评估来说明我们方法的有效性。 

---
# Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application 

**Title (ZH)**: 基于数字孪生信道的6G在线资源分配：原理、架构与应用 

**Authors**: Tongjie Li, Jianhua Zhang, Li Yu, Yuxiang Zhang, Yunlong Cai, Fan Xu, Guangyi Liu  

**Link**: [PDF](https://arxiv.org/pdf/2507.19974)  

**Abstract**: Emerging applications such as holographic communication, autonomous driving, and the industrial Internet of Things impose stringent requirements on flexible, low-latency, and reliable resource allocation in 6G networks. Conventional methods, which rely on statistical modeling, have proven effective in general contexts but may fail to achieve optimal performance in specific and dynamic environments. Furthermore, acquiring real-time channel state information (CSI) typically requires excessive pilot overhead. To address these challenges, a digital twin channel (DTC)-enabled online optimization framework is proposed, in which DTC is employed to predict CSI based on environmental sensing. The predicted CSI is then utilized by lightweight game-theoretic algorithms to perform online resource allocation in a timely and efficient manner. Simulation results based on a digital replica of a realistic industrial workshop demonstrate that the proposed method achieves throughput improvements of up to 11.5\% compared with pilot-based ideal CSI schemes, validating its effectiveness for scalable, low-overhead, and environment-aware communication in future 6G networks. 

**Abstract (ZH)**: 6G网络中基于数字孪生信道的新兴应用在线优化框架：实现及时高效的资源分配 

---
# What Does 'Human-Centred AI' Mean? 

**Title (ZH)**: 以人为本的AI意味着什么？ 

**Authors**: Olivia Guest  

**Link**: [PDF](https://arxiv.org/pdf/2507.19960)  

**Abstract**: While it seems sensible that human-centred artificial intelligence (AI) means centring "human behaviour and experience," it cannot be any other way. AI, I argue, is usefully seen as a relationship between technology and humans where it appears that artifacts can perform, to a greater or lesser extent, human cognitive labour. This is evinced using examples that juxtapose technology with cognition, inter alia: abacus versus mental arithmetic; alarm clock versus knocker-upper; camera versus vision; and sweatshop versus tailor. Using novel definitions and analyses, sociotechnical relationships can be analysed into varying types of: displacement (harmful), enhancement (beneficial), and/or replacement (neutral) of human cognitive labour. Ultimately, all AI implicates human cognition; no matter what. Obfuscation of cognition in the AI context -- from clocks to artificial neural networks -- results in distortion, in slowing critical engagement, perverting cognitive science, and indeed in limiting our ability to truly centre humans and humanity in the engineering of AI systems. To even begin to de-fetishise AI, we must look the human-in-the-loop in the eyes. 

**Abstract (ZH)**: 以人为本的人工智能意味着中心化“人类行为和经验”——别无选择。 

---
# Causality-aligned Prompt Learning via Diffusion-based Counterfactual Generation 

**Title (ZH)**: 基于扩散驱动反事实生成的因果对齐提示学习 

**Authors**: Xinshu Li, Ruoyu Wang, Erdun Gao, Mingming Gong, Lina Yao  

**Link**: [PDF](https://arxiv.org/pdf/2507.19882)  

**Abstract**: Prompt learning has garnered attention for its efficiency over traditional model training and fine-tuning. However, existing methods, constrained by inadequate theoretical foundations, encounter difficulties in achieving causally invariant prompts, ultimately falling short of capturing robust features that generalize effectively across categories. To address these challenges, we introduce the $\textit{\textbf{DiCap}}$ model, a theoretically grounded $\textbf{Di}$ffusion-based $\textbf{C}$ounterf$\textbf{a}$ctual $\textbf{p}$rompt learning framework, which leverages a diffusion process to iteratively sample gradients from the marginal and conditional distributions of the causal model, guiding the generation of counterfactuals that satisfy the minimal sufficiency criterion. Grounded in rigorous theoretical derivations, this approach guarantees the identifiability of counterfactual outcomes while imposing strict bounds on estimation errors. We further employ a contrastive learning framework that leverages the generated counterfactuals, thereby enabling the refined extraction of prompts that are precisely aligned with the causal features of the data. Extensive experimental results demonstrate that our method performs excellently across tasks such as image classification, image-text retrieval, and visual question answering, with particularly strong advantages in unseen categories. 

**Abstract (ZH)**: 基于扩散过程的因果 counterfactual 命令学习框架 DiCap 

---
# Reinforcement Learning for Multi-Objective Multi-Echelon Supply Chain Optimisation 

**Title (ZH)**: 多目标多层次供应链优化的强化学习方法 

**Authors**: Rifny Rachman, Josh Tingey, Richard Allmendinger, Pradyumn Shukla, Wei Pan  

**Link**: [PDF](https://arxiv.org/pdf/2507.19788)  

**Abstract**: This study develops a generalised multi-objective, multi-echelon supply chain optimisation model with non-stationary markets based on a Markov decision process, incorporating economic, environmental, and social considerations. The model is evaluated using a multi-objective reinforcement learning (RL) method, benchmarked against an originally single-objective RL algorithm modified with weighted sum using predefined weights, and a multi-objective evolutionary algorithm (MOEA)-based approach. We conduct experiments on varying network complexities, mimicking typical real-world challenges using a customisable simulator. The model determines production and delivery quantities across supply chain routes to achieve near-optimal trade-offs between competing objectives, approximating Pareto front sets. The results demonstrate that the primary approach provides the most balanced trade-off between optimality, diversity, and density, further enhanced with a shared experience buffer that allows knowledge transfer among policies. In complex settings, it achieves up to 75\% higher hypervolume than the MOEA-based method and generates solutions that are approximately eleven times denser, signifying better robustness, than those produced by the modified single-objective RL method. Moreover, it ensures stable production and inventory levels while minimising demand loss. 

**Abstract (ZH)**: 基于马尔可夫决策过程的非平稳市场综合多目标多层级供应链优化模型：多目标强化学习方法及其应用研究 

---
# Integrating Activity Predictions in Knowledge Graphs 

**Title (ZH)**: 在知识图谱中集成活动预测 

**Authors**: Alec Scully, Cameron Stockton, Forrest Hare  

**Link**: [PDF](https://arxiv.org/pdf/2507.19733)  

**Abstract**: We argue that ontology-structured knowledge graphs can play a crucial role in generating predictions about future events. By leveraging the semantic framework provided by Basic Formal Ontology (BFO) and Common Core Ontologies (CCO), we demonstrate how data such as the movements of a fishing vessel can be organized in and retrieved from a knowledge graph. These query results are then used to create Markov chain models, allowing us to predict future states based on the vessel's history. To fully support this process, we introduce the term `spatiotemporal instant' to complete the necessary structural semantics. Additionally, we critique the prevailing ontological model of probability, which conflates probability with likelihood and relies on the problematic concept of modal measurements: measurements of future entities. We propose an alternative view, where probabilities are treated as being about process profiles, which better captures the dynamics of real world phenomena. Finally, we demonstrate how our Markov chain based probability calculations can be seamlessly integrated back into the knowledge graph, enabling further analysis and decision-making. Keywords: predictive analytics, ontology, Markov chains, probability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL. 

**Abstract (ZH)**: 本体结构化的知识图谱在生成未来事件预测中的关键作用：基于基本形式本体(BFO)和通用核心本体(CCO)的语义框架，船舶运动等数据的组织与检索及其在马尔可夫链模型中的应用与分析：对概率本体模型的批判与替代观点：基于马尔可夫链的概率计算无缝集成回知识图谱 

---
# HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare 

**Title (ZH)**: HypKG：基于超图的知识图谱精准医疗上下文表示 

**Authors**: Yuzhang Xie, Xu Han, Ran Xu, Xiao Hu, Jiaying Lu, Carl Yang  

**Link**: [PDF](https://arxiv.org/pdf/2507.19726)  

**Abstract**: Knowledge graphs (KGs) are important products of the semantic web, which are widely used in various application domains. Healthcare is one of such domains where KGs are intensively used, due to the high requirement for knowledge accuracy and interconnected nature of healthcare data. However, KGs storing general factual information often lack the ability to account for important contexts of the knowledge such as the status of specific patients, which are crucial in precision healthcare. Meanwhile, electronic health records (EHRs) provide rich personal data, including various diagnoses and medications, which provide natural contexts for general KGs. In this paper, we propose HypKG, a framework that integrates patient information from EHRs into KGs to generate contextualized knowledge representations for accurate healthcare predictions. Using advanced entity-linking techniques, we connect relevant knowledge from general KGs with patient information from EHRs, and then utilize a hypergraph model to "contextualize" the knowledge with the patient information. Finally, we employ hypergraph transformers guided by downstream prediction tasks to jointly learn proper contextualized representations for both KGs and patients, fully leveraging existing knowledge in KGs and patient contexts in EHRs. In experiments using a large biomedical KG and two real-world EHR datasets, HypKG demonstrates significant improvements in healthcare prediction tasks across multiple evaluation metrics. Additionally, by integrating external contexts, HypKG can learn to adjust the representations of entities and relations in KG, potentially improving the quality and real-world utility of knowledge. 

**Abstract (ZH)**: 知识图谱（KGs）是语义网的重要产物，广泛应用于各种应用领域。在对知识准确性要求高且医疗数据具有强关联性的医疗健康领域，KGs被密集使用。然而，用于存储通用事实信息的KGs往往缺乏考虑具体患者状态等重要上下文的能力，这对精准医疗至关重要。与此同时，电子健康记录（EHRs）提供了丰富个人数据，包括各种诊断和用药信息，为通用KGs提供了自然的上下文。在本文中，我们提出了一种名为HypKG的框架，该框架将EHRs中的患者信息整合到KGs中，生成上下文感知的知识表示，以实现准确的医疗预测。通过先进的实体链接技术，我们连接了通用KGs中的相关知识与EHRs中的患者信息，并利用超图模型将知识“上下文化”到患者信息中。最后，我们采用由下游预测任务引导的超图变压器，联合学习KGs和患者双方的适当上下文化表示，充分利用KGs中已有的知识以及EHRs中的患者上下文。在使用大规模生物医学KG和两个实际EHR数据集的实验中，HypKG在多个评估指标上显著提高了医疗预测任务的效果。此外，通过整合外部上下文，HypKG能够学习调整KG中实体和关系的表示，这可能提高知识的质量和实际应用价值。 

---
# Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems 

**Title (ZH)**: 多智能体系统中不对齐感知和嵌套信念的建模：超游戏 

**Authors**: Vince Trencsenyi, Agnieszka Mensfelt, Kostas Stathis  

**Link**: [PDF](https://arxiv.org/pdf/2507.19593)  

**Abstract**: Classical game-theoretic models typically assume rational agents, complete information, and common knowledge of payoffs - assumptions that are often violated in real-world MAS characterized by uncertainty, misaligned perceptions, and nested beliefs. To overcome these limitations, researchers have proposed extensions that incorporate models of cognitive constraints, subjective beliefs, and heterogeneous reasoning. Among these, hypergame theory extends the classical paradigm by explicitly modeling agents' subjective perceptions of the strategic scenario, known as perceptual games, in which agents may hold divergent beliefs about the structure, payoffs, or available actions. We present a systematic review of agent-compatible applications of hypergame theory, examining how its descriptive capabilities have been adapted to dynamic and interactive MAS contexts. We analyze 44 selected studies from cybersecurity, robotics, social simulation, communications, and general game-theoretic modeling. Building on a formal introduction to hypergame theory and its two major extensions - hierarchical hypergames and HNF - we develop agent-compatibility criteria and an agent-based classification framework to assess integration patterns and practical applicability. Our analysis reveals prevailing tendencies, including the prevalence of hierarchical and graph-based models in deceptive reasoning and the simplification of extensive theoretical frameworks in practical applications. We identify structural gaps, including the limited adoption of HNF-based models, the lack of formal hypergame languages, and unexplored opportunities for modeling human-agent and agent-agent misalignment. By synthesizing trends, challenges, and open research directions, this review provides a new roadmap for applying hypergame theory to enhance the realism and effectiveness of strategic modeling in dynamic multi-agent environments. 

**Abstract (ZH)**: 古典博弈理论模型通常假设理性代理、完全信息以及共同的知识支付—这些假设在由不确定性、对齐偏差和嵌套信念特征的现实世界MAS中经常被违反。为克服这些限制，研究人员提出了包含认知约束、主观信念和异质推理模型的扩展。其中，超博弈理论通过明确建模代理对战略场景的主观感知，即感知博弈，扩展了古典范式，其中代理可能对结构、支付或可用行动持有不同的信念。我们对超博弈理论的代理兼容应用进行了系统回顾，考察了其描述能力如何适应动态和交互式的MAS环境。我们分析了来自网络安全、机器人、社会仿真、通信和一般博弈论建模的44项研究。基于对超博弈理论及其两大扩展——层次超博弈和HNF的正式介绍，我们开发了代理兼容性标准和基于代理的分类框架，以评估整合模式和实际应用性。我们的分析揭示了现有趋势，包括欺骗推理中层次和图基模型的普及以及理论框架在实际应用中的简化。我们指出了结构性缺口，包括HNF基模型的有限采用、缺乏形式化超博弈语言以及对人类代理和代理间不对齐建模机会的未开发。通过综合趋势、挑战和开放的研究方向，本回顾为利用超博弈理论增强动态多代理环境中的战略模型的真实性和有效性提供了新的路线图。 

---
# MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation 

**Title (ZH)**: MAIA：一种集成医疗创新的协作医疗AI平台 

**Authors**: Simone Bendazzoli, Sanna Persson, Mehdi Astaraki, Sebastian Pettersson, Vitali Grozman, Rodrigo Moreno  

**Link**: [PDF](https://arxiv.org/pdf/2507.19489)  

**Abstract**: The integration of Artificial Intelligence (AI) into clinical workflows requires robust collaborative platforms that are able to bridge the gap between technical innovation and practical healthcare applications. This paper introduces MAIA (Medical Artificial Intelligence Assistant), an open-source platform designed to facilitate interdisciplinary collaboration among clinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a modular, scalable environment with integrated tools for data management, model development, annotation, deployment, and clinical feedback. Key features include project isolation, CI/CD automation, integration with high-computing infrastructures and in clinical workflows. MAIA supports real-world use cases in medical imaging AI, with deployments in both academic and clinical environments. By promoting collaborations and interoperability, MAIA aims to accelerate the translation of AI research into impactful clinical solutions while promoting reproducibility, transparency, and user-centered design. We showcase the use of MAIA with different projects, both at KTH Royal Institute of Technology and Karolinska University Hospital. 

**Abstract (ZH)**: 将人工智能融入临床工作流需要强大的协作平台，能够弥合技术创新与实际医疗应用之间的差距。本文介绍了MAIA（医疗人工智能助手）这一开源平台，旨在促进临床医生、研究人员和人工智能开发者之间的跨学科合作。基于Kubernetes构建，MAIA提供了一个模块化、可扩展的环境，集成了数据管理、模型开发、注释、部署和临床反馈的工具。关键功能包括项目隔离、CI/CD自动化、与高性能计算基础设施以及临床工作流的集成。MAIA支持医疗成像人工智能的现实世界应用场景，在学术和临床环境中均有部署。通过促进合作与互操作性，MAIA旨在加速将人工智能研究转化为具有影响力的临床解决方案，同时促进可重复性、透明性和用户中心设计。我们展示了MAIA在Karolinska大学医院和瑞典皇家理工学院的不同项目中的应用。 

---
# Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability 

**Title (ZH)**: 组成函数网络：内置可解释性的高性能替代深度神经网络 

**Authors**: Fang Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.21004)  

**Abstract**: Deep Neural Networks (DNNs) deliver impressive performance but their black-box nature limits deployment in high-stakes domains requiring transparency. We introduce Compositional Function Networks (CFNs), a novel framework that builds inherently interpretable models by composing elementary mathematical functions with clear semantics. Unlike existing interpretable approaches that are limited to simple additive structures, CFNs support diverse compositional patterns -- sequential, parallel, and conditional -- enabling complex feature interactions while maintaining transparency. A key innovation is that CFNs are fully differentiable, allowing efficient training through standard gradient descent. We demonstrate CFNs' versatility across multiple domains, from symbolic regression to image classification with deep hierarchical networks. Our empirical evaluation shows CFNs achieve competitive performance against black-box models (96.24% accuracy on CIFAR-10) while outperforming state-of-the-art interpretable models like Explainable Boosting Machines. By combining the hierarchical expressiveness and efficient training of deep learning with the intrinsic interpretability of well-defined mathematical functions, CFNs offer a powerful framework for applications where both performance and accountability are paramount. 

**Abstract (ZH)**: 深度神经网络（DNNs）表现出色，但其黑箱性质限制了在需要透明性的高风险领域中的部署。我们引入了构成函数网络（CFNs），这是一种新型框架，通过组合具有明确语义的基本数学函数来构建固有的可解释模型。与现有受限于简单加性结构的可解释方法不同，CFNs 支持多种组合模式——序列、并行和条件模式——这能够支持复杂的特征交互同时保持透明性。一个关键创新是CFNs是全可微的，允许通过标准梯度下降进行高效训练。我们展示了CFNs在多个领域的灵活性，从符号回归到使用深度层次网络的图像分类。我们的实证评估表明，CFNs在与黑箱模型相当的性能上（CIFAR-10数据集准确率为96.24%）超过了最新的可解释模型如可解释增强树。通过结合深度学习的层次表达能力和清晰数学函数的固有可解释性，CFNs为同时需要性能和问责制的应用提供了强大的框架。 

---
# Modular Delta Merging with Orthogonal Constraints: A Scalable Framework for Continual and Reversible Model Composition 

**Title (ZH)**: 正交约束下的模块化Δ合并：一种可扩展的持续可逆模型组合框架 

**Authors**: Haris Khan, Shumaila Asif, Sadia Asif  

**Link**: [PDF](https://arxiv.org/pdf/2507.20997)  

**Abstract**: In real-world machine learning deployments, models must be continually updated, composed, and when required, selectively undone. However, existing approaches to model merging and continual learning often suffer from task interference, catastrophic forgetting, or lack of reversibility. We propose Modular Delta Merging with Orthogonal Constraints (MDM-OC), a novel framework that enables scalable, interference-free, and reversible composition of fine-tuned models. Each task-specific model is encoded as a delta from a shared base and projected into an orthogonal subspace to eliminate conflict. These projected deltas are then merged via gradient-based optimization to form a unified model that retains performance across tasks. Our approach supports continual integration of new models, structured unmerging for compliance such as GDPR requirements, and model stability via elastic weight consolidation and synthetic replay. Extensive experiments on vision and natural language processing benchmarks demonstrate that MDM-OC outperforms prior baselines in accuracy, backward transfer, and unmerge fidelity, while remaining memory-efficient and computationally tractable. This framework offers a principled solution for modular and compliant AI system design. 

**Abstract (ZH)**: 模块化delta合并与正交约束框架：无干扰、可逆的模型组合与持续学习 

---
# Personalized Treatment Effect Estimation from Unstructured Data 

**Title (ZH)**: 从非结构化数据中估计个性化的治疗效果 

**Authors**: Henri Arno, Thomas Demeester  

**Link**: [PDF](https://arxiv.org/pdf/2507.20993)  

**Abstract**: Existing methods for estimating personalized treatment effects typically rely on structured covariates, limiting their applicability to unstructured data. Yet, leveraging unstructured data for causal inference has considerable application potential, for instance in healthcare, where clinical notes or medical images are abundant. To this end, we first introduce an approximate 'plug-in' method trained directly on the neural representations of unstructured data. However, when these fail to capture all confounding information, the method may be subject to confounding bias. We therefore introduce two theoretically grounded estimators that leverage structured measurements of the confounders during training, but allow estimating personalized treatment effects purely from unstructured inputs, while avoiding confounding bias. When these structured measurements are only available for a non-representative subset of the data, these estimators may suffer from sampling bias. To address this, we further introduce a regression-based correction that accounts for the non-uniform sampling, assuming the sampling mechanism is known or can be well-estimated. Our experiments on two benchmark datasets show that the plug-in method, directly trainable on large unstructured datasets, achieves strong empirical performance across all settings, despite its simplicity. 

**Abstract (ZH)**: 现有的个性化治疗效果估计方法通常依赖于结构化协变量，限制了其在非结构化数据上的应用。然而，利用非结构化数据进行因果推理在诸如医疗健康等领域的应用潜力巨大，例如临床笔记或医疗图像丰 富。为此，我们首先介绍一种直接在非结构化数据的神经表示上训练的近似“插值”方法。然而，当这些方法无法捕捉到所有混杂信息时，可能会出现混杂偏差。因此，我们引入了两种理论上具 有依据的估计器，在训练中利用混杂变量的结构测量，但允许仅从非结构化输入中估计个性化的治疗效果，同时避免混杂偏差。当这些结构化测量仅适用于数据的一个非代表性子集时，这些估计器可能受到抽样偏差的影响。为此，我们进一步引入了一种基于回归的校正方法，以考虑非均匀抽样，前提是抽样机制已知或可以良好估计。我们在两个基准数据集上的实验表明，可以直接在大型非结构化数据集上训练的插值方法，在各种情况下都表现出色，尽管它非常简单。 

---
# From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation 

**Title (ZH)**: 从纠缠到对齐：无监督时间序列领域适应的表示空间分解 

**Authors**: Rongyao Cai, Ming Jin, Qingsong Wen, Kexin Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.20968)  

**Abstract**: Domain shift poses a fundamental challenge in time series analysis, where models trained on source domain often fail dramatically when applied in target domain with different yet similar distributions. While current unsupervised domain adaptation (UDA) methods attempt to align cross-domain feature distributions, they typically treat features as indivisible entities, ignoring their intrinsic compositions that governs domain adaptation. We introduce DARSD, a novel UDA framework with theoretical explainability that explicitly realizes UDA tasks from the perspective of representation space decomposition. Our core insight is that effective domain adaptation requires not just alignment, but principled disentanglement of transferable knowledge from mixed representations. DARSD consists three synergistic components: (I) An adversarial learnable common invariant basis that projects original features into a domain-invariant subspace while preserving semantic content; (II) A prototypical pseudo-labeling mechanism that dynamically separates target features based on confidence, hindering error accumulation; (III) A hybrid contrastive optimization strategy that simultaneously enforces feature clustering and consistency while mitigating emerging distribution gaps. Comprehensive experiments conducted on four benchmark datasets (WISDM, HAR, HHAR, and MFD) demonstrate DARSD's superiority against 12 UDA algorithms, achieving optimal performance in 35 out of 53 cross-domain scenarios. 

**Abstract (ZH)**: 领域偏移在时间序列分析中构成了基本的挑战，其中在源领域训练的模型往往无法有效应用于具有不同但相似分布的目标领域。尽管现有的无监督领域适应（UDA）方法试图对跨领域的特征分布进行对齐，但它们通常将特征视为不可分割的整体，忽略了决定领域适应的内在组成。我们引入了DARSD，这是一种具有理论可解释性的新型UDA框架，从表示空间分解的角度明确地实现了UDA任务。我们的核心见解是，有效的领域适应不仅需要对齐，还需要从混合表示中有原则地分离可转移的知识。DARSD 包含三个协同工作的组件：(I) 一个对抗可学习的公共不变基底，将原始特征投影到域不变子空间同时保留语义内容；(II) 一种基于置信度的原型伪标签机制，动态分离目标特征，防止错误累积；(III) 一种混合对比优化策略，同时强制特征聚类和一致性，并减轻新兴的分布差距。在四个基准数据集（WISDM、HAR、HHAR 和 MFD）上的全面实验表明，DARSD 在 53 个跨域场景中的 35 个场景中实现了最优性能，并优于 12 种UDA算法。 

---
# Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL 

**Title (ZH)**: 用户为中心的无蜂窝大规模MIMO网络的_handover_设计 Using_DRL 

**Authors**: Hussein A. Ammar, Raviraj Adve, Shahram Shahbazpanahi, Gary Boudreau, Israfil Bahceci  

**Link**: [PDF](https://arxiv.org/pdf/2507.20966)  

**Abstract**: In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user mobility necessitates updating the set of serving access points to maintain the user-centric clustering. Such updates are typically performed through handoff (HO) operations; however, frequent HOs lead to overheads associated with the allocation and release of resources. This paper presents a deep reinforcement learning (DRL)-based solution to predict and manage these connections for mobile users. Our solution employs the Soft Actor-Critic algorithm, with continuous action space representation, to train a deep neural network to serve as the HO policy. We present a novel proposition for a reward function that integrates a HO penalty in order to balance the attainable rate and the associated overhead related to HOs. We develop two variants of our system; the first one uses mobility direction-assisted (DA) observations that are based on the user movement pattern, while the second one uses history-assisted (HA) observations that are based on the history of the large-scale fading (LSF). Simulation results show that our DRL-based continuous action space approach is more scalable than discrete space counterpart, and that our derived HO policy automatically learns to gather HOs in specific time slots to minimize the overhead of initiating HOs. Our solution can also operate in real time with a response time less than 0.4 ms. 

**Abstract (ZH)**: 基于用户的细胞自由大规模MIMO（UC-mMIMO）网络方案中移动用户的移动性需要更新服务接入点集合以维持用户为中心的聚类。这种更新通常通过切换操作（HO）来执行；然而，频繁的切换会导致与资源分配和释放相关的开销。本文提出了一种基于深度强化学习（DRL）的解决方案，以预测和管理移动用户的这些连接。我们的解决方案利用Soft Actor-Critic算法和连续动作空间表示来训练一个深度神经网络作为切换策略。我们提出了一种新的奖励函数提案，将切换惩罚纳入其中，以平衡可获得速率和与切换相关的开销。我们开发了两种系统变体；第一个变体基于用户移动模式的辅助移动方向（DA）观测，而第二个变体基于大规模衰落（LSF）的历史辅助（HA）观测。仿真结果表明，我们的基于DRL的连续动作空间方法比离散空间方法更具扩展性，并且我们获得的切换策略能够自动学习在特定时间槽中收集切换以最小化切换的启动开销。此外，该解决方案可以实时运行，响应时间少于0.4毫秒。 

---
# Multivariate Conformal Prediction via Conformalized Gaussian Scoring 

**Title (ZH)**: 多元变量同质化预测via同质化高斯评分 

**Authors**: Sacha Braun, Eugène Berta, Michael I. Jordan, Francis Bach  

**Link**: [PDF](https://arxiv.org/pdf/2507.20941)  

**Abstract**: While achieving exact conditional coverage in conformal prediction is unattainable without making strong, untestable regularity assumptions, the promise of conformal prediction hinges on finding approximations to conditional guarantees that are realizable in practice. A promising direction for obtaining conditional dependence for conformal sets--in particular capturing heteroskedasticity--is through estimating the conditional density $\mathbb{P}_{Y|X}$ and conformalizing its level sets. Previous work in this vein has focused on nonconformity scores based on the empirical cumulative distribution function (CDF). Such scores are, however, computationally costly, typically requiring expensive sampling methods. To avoid the need for sampling, we observe that the CDF-based score reduces to a Mahalanobis distance in the case of Gaussian scores, yielding a closed-form expression that can be directly conformalized. Moreover, the use of a Gaussian-based score opens the door to a number of extensions of the basic conformal method; in particular, we show how to construct conformal sets with missing output values, refine conformal sets as partial information about $Y$ becomes available, and construct conformal sets on transformations of the output space. Finally, empirical results indicate that our approach produces conformal sets that more closely approximate conditional coverage in multivariate settings compared to alternative methods. 

**Abstract (ZH)**: 在不做出强且无法验证的正则性假设的情况下，实现精确条件覆盖在自适应预测中是不可能的，但自适应预测的潜力在于找到可实现的条件保证近似值。获取自适应集的条件依赖性——尤其是捕捉异方差性的方法之一是通过估计条件密度 $\mathbb{P}_{Y|X}$ 并将其等值线自适应化。先前在这方面的工作主要集中在基于经验累积分布函数（CDF）的非一致性评分上。然而，这类评分在计算上成本高昂，通常需要昂贵的采样方法。为了避免采样的需要，我们观察到，在高斯评分的情况下，CDF 基准评分退化为马哈拉诺比斯距离，从而获得一个可以直接自适应化的闭式表达式。此外，基于高斯评分的使用打开了自适应方法若干扩展的可能性；特别是，我们展示了如何构建缺失输出值的自适应集，随着关于 $Y$ 的部分信息变得可用，如何细化自适应集，以及如何在输出空间的变换上构建自适应集。最后，实证结果表明，我们的方法在多变量设置中生成的自适应集更接近条件覆盖，相比其他方法具有显著优势。 

---
# Modeling User Behavior from Adaptive Surveys with Supplemental Context 

**Title (ZH)**: 基于补充上下文的自适应调查中用户行为建模 

**Authors**: Aman Shukla, Daniel Patrick Scantlebury, Rishabh Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2507.20919)  

**Abstract**: Modeling user behavior is critical across many industries where understanding preferences, intent, or decisions informs personalization, targeting, and strategic outcomes. Surveys have long served as a classical mechanism for collecting such behavioral data due to their interpretability, structure, and ease of deployment. However, surveys alone are inherently limited by user fatigue, incomplete responses, and practical constraints on their length making them insufficient for capturing user behavior. In this work, we present LANTERN (Late-Attentive Network for Enriched Response Modeling), a modular architecture for modeling user behavior by fusing adaptive survey responses with supplemental contextual signals. We demonstrate the architectural value of maintaining survey primacy through selective gating, residual connections and late fusion via cross-attention, treating survey data as the primary signal while incorporating external modalities only when relevant. LANTERN outperforms strong survey-only baselines in multi-label prediction of survey responses. We further investigate threshold sensitivity and the benefits of selective modality reliance through ablation and rare/frequent attribute analysis. LANTERN's modularity supports scalable integration of new encoders and evolving datasets. This work provides a practical and extensible blueprint for behavior modeling in survey-centric applications. 

**Abstract (ZH)**: 基于晚期注意网络的增强回应建模（LANTERN：Late-Attentive Network for Enriched Response Modeling） 

---
# MediQAl: A French Medical Question Answering Dataset for Knowledge and Reasoning Evaluation 

**Title (ZH)**: MediQAl: 一个用于知识和推理评估的法语医疗问答数据集 

**Authors**: Adrien Bazoge  

**Link**: [PDF](https://arxiv.org/pdf/2507.20917)  

**Abstract**: This work introduces MediQAl, a French medical question answering dataset designed to evaluate the capabilities of language models in factual medical recall and reasoning over real-world clinical scenarios. MediQAl contains 32,603 questions sourced from French medical examinations across 41 medical subjects. The dataset includes three tasks: (i) Multiple-Choice Question with Unique answer, (ii) Multiple-Choice Question with Multiple answer, and (iii) Open-Ended Question with Short-Answer. Each question is labeled as Understanding or Reasoning, enabling a detailed analysis of models' cognitive capabilities. We validate the MediQAl dataset through extensive evaluation with 14 large language models, including recent reasoning-augmented models, and observe a significant performance gap between factual recall and reasoning tasks. Our evaluation provides a comprehensive benchmark for assessing language models' performance on French medical question answering, addressing a crucial gap in multilingual resources for the medical domain. 

**Abstract (ZH)**: MediQAl：一种用于评估语言模型在医疗事实回忆和现实临床场景推理能力的法语文本问答数据集 

---
# SCORPION: Addressing Scanner-Induced Variability in Histopathology 

**Title (ZH)**: SCORPION: 应对扫描引起的病理图像变异性问题 

**Authors**: Jeongun Ryu, Heon Song, Seungeun Lee, Soo Ick Cho, Jiwon Shin, Kyunghyun Paeng, Sérgio Pereira  

**Link**: [PDF](https://arxiv.org/pdf/2507.20907)  

**Abstract**: Ensuring reliable model performance across diverse domains is a critical challenge in computational pathology. A particular source of variability in Whole-Slide Images is introduced by differences in digital scanners, thus calling for better scanner generalization. This is critical for the real-world adoption of computational pathology, where the scanning devices may differ per institution or hospital, and the model should not be dependent on scanner-induced details, which can ultimately affect the patient's diagnosis and treatment planning. However, past efforts have primarily focused on standard domain generalization settings, evaluating on unseen scanners during training, without directly evaluating consistency across scanners for the same tissue. To overcome this limitation, we introduce SCORPION, a new dataset explicitly designed to evaluate model reliability under scanner variability. SCORPION includes 480 tissue samples, each scanned with 5 scanners, yielding 2,400 spatially aligned patches. This scanner-paired design allows for the isolation of scanner-induced variability, enabling a rigorous evaluation of model consistency while controlling for differences in tissue composition. Furthermore, we propose SimCons, a flexible framework that combines augmentation-based domain generalization techniques with a consistency loss to explicitly address scanner generalization. We empirically show that SimCons improves model consistency on varying scanners without compromising task-specific performance. By releasing the SCORPION dataset and proposing SimCons, we provide the research community with a crucial resource for evaluating and improving model consistency across diverse scanners, setting a new standard for reliability testing. 

**Abstract (ZH)**: 确保计算病理学在多样化领域中模型性能的可靠性是一个关键挑战。由数字扫描器差异引入的 Whole-Slide Images 变异性要求更好的扫描器泛化能力。这对于计算病理学的实际应用至关重要，因为扫描设备在不同机构或医院之间可能不同，模型不应依赖于扫描器引起的细节，这些细节最终可能会影响患者的诊断和治疗规划。然而，过去的努力主要集中在标准领域泛化设置上，在训练期间评估未见过的扫描器，而没有直接评估相同组织在不同扫描器之间的前后一致性。为了克服这一局限性，我们引入了 SCORPION，一个明确设计用于评估模型在扫描器变异性下的可靠性的新数据集。SCORPION 包含 480 个组织样本，每个样本使用 5 种扫描器进行扫描，生成 2,400 个空间对齐的切片。这种扫描器配对设计允许隔离由于扫描器引起的变异，从而能够控制组织组成差异的同时进行严格的模型一致性评估。此外，我们提出了一种名为 SimCons 的灵活框架，该框架结合了基于增强的领域泛化技术与一致性损失，明确解决扫描器泛化问题。我们实证表明，SimCons 在不同扫描器下提高了模型一致性，同时不牺牲特定任务的性能。通过发布 SCORPION 数据集并提出 SimCons，我们为研究界提供了评估和提高不同扫描器下模型一致性的关键资源，树立了可靠测试的新标准。 

---
# Music Arena: Live Evaluation for Text-to-Music 

**Title (ZH)**: 音乐竞技场：文本到音乐的现场评估 

**Authors**: Yonghyun Kim, Wayne Chi, Anastasios N. Angelopoulos, Wei-Lin Chiang, Koichi Saito, Shinji Watanabe, Yuki Mitsufuji, Chris Donahue  

**Link**: [PDF](https://arxiv.org/pdf/2507.20900)  

**Abstract**: We present Music Arena, an open platform for scalable human preference evaluation of text-to-music (TTM) models. Soliciting human preferences via listening studies is the gold standard for evaluation in TTM, but these studies are expensive to conduct and difficult to compare, as study protocols may differ across systems. Moreover, human preferences might help researchers align their TTM systems or improve automatic evaluation metrics, but an open and renewable source of preferences does not currently exist. We aim to fill these gaps by offering *live* evaluation for TTM. In Music Arena, real-world users input text prompts of their choosing and compare outputs from two TTM systems, and their preferences are used to compile a leaderboard. While Music Arena follows recent evaluation trends in other AI domains, we also design it with key features tailored to music: an LLM-based routing system to navigate the heterogeneous type signatures of TTM systems, and the collection of *detailed* preferences including listening data and natural language feedback. We also propose a rolling data release policy with user privacy guarantees, providing a renewable source of preference data and increasing platform transparency. Through its standardized evaluation protocol, transparent data access policies, and music-specific features, Music Arena not only addresses key challenges in the TTM ecosystem but also demonstrates how live evaluation can be thoughtfully adapted to unique characteristics of specific AI domains.
Music Arena is available at: this https URL 

**Abstract (ZH)**: 音乐竞技场：一个面向文本到音乐模型可扩展的人类偏好评估开放平台 

---
# JAM: A Tiny Flow-based Song Generator with Fine-grained Controllability and Aesthetic Alignment 

**Title (ZH)**: JAM：一个具备细粒度可控性和审美对齐的小型流基歌曲生成器 

**Authors**: Renhang Liu, Chia-Yu Hung, Navonil Majumder, Taylor Gautreaux, Amir Ali Bagherzadeh, Chuan Li, Dorien Herremans, Soujanya Poria  

**Link**: [PDF](https://arxiv.org/pdf/2507.20880)  

**Abstract**: Diffusion and flow-matching models have revolutionized automatic text-to-audio generation in recent times. These models are increasingly capable of generating high quality and faithful audio outputs capturing to speech and acoustic events. However, there is still much room for improvement in creative audio generation that primarily involves music and songs. Recent open lyrics-to-song models, such as, DiffRhythm, ACE-Step, and LeVo, have set an acceptable standard in automatic song generation for recreational use. However, these models lack fine-grained word-level controllability often desired by musicians in their workflows. To the best of our knowledge, our flow-matching-based JAM is the first effort toward endowing word-level timing and duration control in song generation, allowing fine-grained vocal control. To enhance the quality of generated songs to better align with human preferences, we implement aesthetic alignment through Direct Preference Optimization, which iteratively refines the model using a synthetic dataset, eliminating the need or manual data annotations. Furthermore, we aim to standardize the evaluation of such lyrics-to-song models through our public evaluation dataset JAME. We show that JAM outperforms the existing models in terms of the music-specific attributes. 

**Abstract (ZH)**: 基于流匹配的JAM模型：面向歌词到歌曲生成的字级节奏和时长控制及美学对齐标准 

---
# Not Only Grey Matter: OmniBrain for Robust Multimodal Classification of Alzheimer's Disease 

**Title (ZH)**: 不仅灰质：OmniBrain在阿尔茨海默病多模态分类中的稳健表现 

**Authors**: Ahmed Sharshar, Yasser Ashraf, Tameem Bakr, Salma Hassan, Hosam Elgendy, Mohammad Yaqub, Mohsen Guizani  

**Link**: [PDF](https://arxiv.org/pdf/2507.20872)  

**Abstract**: Alzheimer's disease affects over 55 million people worldwide and is projected to more than double by 2050, necessitating rapid, accurate, and scalable diagnostics. However, existing approaches are limited because they cannot achieve clinically acceptable accuracy, generalization across datasets, robustness to missing modalities, and explainability all at the same time. This inability to satisfy all these requirements simultaneously undermines their reliability in clinical settings. We propose OmniBrain, a multimodal framework that integrates brain MRI, radiomics, gene expression, and clinical data using a unified model with cross-attention and modality dropout. OmniBrain achieves $92.2 \pm 2.4\%$accuracy on the ANMerge dataset and generalizes to the MRI-only ADNI dataset with $70.4 \pm 2.7\%$ accuracy, outperforming unimodal and prior multimodal approaches. Explainability analyses highlight neuropathologically relevant brain regions and genes, enhancing clinical trust. OmniBrain offers a robust, interpretable, and practical solution for real-world Alzheimer's diagnosis. 

**Abstract (ZH)**: 阿尔茨海默病影响全球超过5500万人，预计到2050年将翻倍，亟需快速、准确且可扩展的诊断方法。然而，现有方法受限于无法同时实现临床可接受的准确性、跨数据集的普适性、对缺失模块的鲁棒性以及可解释性。这种无法同时满足所有要求的能力削弱了其在临床环境中的可靠性。我们提出OmniBrain，这是一种利用统一模型结合交叉注意力和模块 dropout 的多模态框架，整合了脑MRI、影像组学、基因表达和临床数据。OmniBrain在ANMerge数据集上达到了92.2 ± 2.4%的准确率，并在仅使用MRI的ADNI数据集上达到了70.4 ± 2.7%的准确率，超越了单模态和先前的多模态方法。可解释性分析突出显示了神经病理相关的脑区和基因，增强了临床信任。OmniBrain提供了一种稳健、可解释且实用的阿尔茨海默病诊断解决方案。 

---
# Why Flow Matching is Particle Swarm Optimization? 

**Title (ZH)**: 流匹配为何是粒子群优化？ 

**Authors**: Kaichen Ouyang  

**Link**: [PDF](https://arxiv.org/pdf/2507.20810)  

**Abstract**: This paper preliminarily investigates the duality between flow matching in generative models and particle swarm optimization (PSO) in evolutionary computation. Through theoretical analysis, we reveal the intrinsic connections between these two approaches in terms of their mathematical formulations and optimization mechanisms: the vector field learning in flow matching shares similar mathematical expressions with the velocity update rules in PSO; both methods follow the fundamental framework of progressive evolution from initial to target distributions; and both can be formulated as dynamical systems governed by ordinary differential equations. Our study demonstrates that flow matching can be viewed as a continuous generalization of PSO, while PSO provides a discrete implementation of swarm intelligence principles. This duality understanding establishes a theoretical foundation for developing novel hybrid algorithms and creates a unified framework for analyzing both methods. Although this paper only presents preliminary discussions, the revealed correspondences suggest several promising research directions, including improving swarm intelligence algorithms based on flow matching principles and enhancing generative models using swarm intelligence concepts. 

**Abstract (ZH)**: 本文初步探讨了生成模型中的流动匹配与进化计算中的粒子群优化（PSO）之间的二元关系。通过理论分析，我们揭示了这两种方法在数学形式和优化机制方面的内在联系：流动匹配中的向量场学习与PSO中的速度更新规则具有类似的数学表达式；两者都遵循从初始分布到目标分布的逐步进化框架；两者都可以用由常微分方程支配的动力系统进行形式化描述。本研究证明，流动匹配可以被视为PSO的连续推广，而PSO则提供了群体智能原则的离散实现。这种二元关系的理解为开发新的混合算法并建立统一的分析框架奠定了理论基础。尽管本文仅呈现了初步讨论，但揭示的对应关系提出了几个有前景的研究方向，包括基于流动匹配原则改进群体智能算法和利用群体智能概念增强生成模型。 

---
# Investigation of Accuracy and Bias in Face Recognition Trained with Synthetic Data 

**Title (ZH)**: 基于合成数据训练的脸部识别准确度与偏差investigation 

**Authors**: Pavel Korshunov, Ketan Kotwal, Christophe Ecabert, Vidit Vidit, Amir Mohammadi, Sebastien Marcel  

**Link**: [PDF](https://arxiv.org/pdf/2507.20782)  

**Abstract**: Synthetic data has emerged as a promising alternative for training face recognition (FR) models, offering advantages in scalability, privacy compliance, and potential for bias mitigation. However, critical questions remain on whether both high accuracy and fairness can be achieved with synthetic data. In this work, we evaluate the impact of synthetic data on bias and performance of FR systems. We generate balanced face dataset, FairFaceGen, using two state of the art text-to-image generators, Flux.1-dev and Stable Diffusion v3.5 (SD35), and combine them with several identity augmentation methods, including Arc2Face and four IP-Adapters. By maintaining equal identity count across synthetic and real datasets, we ensure fair comparisons when evaluating FR performance on standard (LFW, AgeDB-30, etc.) and challenging IJB-B/C benchmarks and FR bias on Racial Faces in-the-Wild (RFW) dataset. Our results demonstrate that although synthetic data still lags behind the real datasets in the generalization on IJB-B/C, demographically balanced synthetic datasets, especially those generated with SD35, show potential for bias mitigation. We also observe that the number and quality of intra-class augmentations significantly affect FR accuracy and fairness. These findings provide practical guidelines for constructing fairer FR systems using synthetic data. 

**Abstract (ZH)**: 合成数据已成为训练面部识别（FR）模型的一种有前景的替代方案，提供了规模化、隐私合规和偏差缓解的潜力。然而，关于是否能够同时实现高准确性和公平性的问题仍然关键。在此工作中，我们评估了合成数据对面部识别系统偏差和性能的影响。我们使用两个最先进的文本到图像生成器Flux.1-dev和Stable Diffusion v3.5（SD35）生成一个平衡面部数据集FairFaceGen，并结合了几种身份增强方法，包括Arc2Face和四个IP-适配器。通过在合成和真实数据集中保持相同的身份数量，我们在评估标准（LFW、AgeDB-30等）和具有挑战性的IJB-B/C基准以及RFW数据集上的面部识别偏差时确保了公平比较。结果显示，尽管合成数据在IJB-B/C上的泛化能力仍落后于真实数据集，但人口统计学平衡的合成数据集，尤其是使用SD35生成的数据集，具有缓解偏差的潜力。我们还观察到，类内增强的数量和质量显著影响面部识别的准确性和公平性。这些发现为使用合成数据构建更公平的面部识别系统提供了实用指南。 

---
# Industry Insights from Comparing Deep Learning and GBDT Models for E-Commerce Learning-to-Rank 

**Title (ZH)**: 电子商务学习排名中深度学习与GBDT模型比较的产业洞察 

**Authors**: Yunus Lutz, Timo Wilm, Philipp Duwe  

**Link**: [PDF](https://arxiv.org/pdf/2507.20753)  

**Abstract**: In e-commerce recommender and search systems, tree-based models, such as LambdaMART, have set a strong baseline for Learning-to-Rank (LTR) tasks. Despite their effectiveness and widespread adoption in industry, the debate continues whether deep neural networks (DNNs) can outperform traditional tree-based models in this domain. To contribute to this discussion, we systematically benchmark DNNs against our production-grade LambdaMART model. We evaluate multiple DNN architectures and loss functions on a proprietary dataset from OTTO and validate our findings through an 8-week online A/B test. The results show that a simple DNN architecture outperforms a strong tree-based baseline in terms of total clicks and revenue, while achieving parity in total units sold. 

**Abstract (ZH)**: 在电子商务推荐和搜索系统中，基于树的模型如LambdaMART为学习排序（LTR）任务设定了强有力的基准。尽管这些模型在工业界表现出色并得到广泛采用，关于深度神经网络（DNNs）能否在这一领域超越传统基于树的模型的争论仍然存在。为了推进这一讨论，我们系统地将多种DNN架构与我们生产的LambdaMART模型进行了对比基准测试。我们在OTTO的专属数据集上评估了多种DNN架构和损失函数，并通过8周的在线A/B测试验证了我们的发现。结果表明，一个简单的DNN架构在总点击量和收入方面优于强大的基于树的基准模型，同时在总销售单位上达到一致。 

---
# AR-LIF: Adaptive reset leaky-integrate and fire neuron for spiking neural networks 

**Title (ZH)**: AR-LIF: 自适应复位泄漏积分和放电神经元用于突触神经网络 

**Authors**: Zeyu Huang, Wei Meng, Quan Liu, Kun Chen, Li Ma  

**Link**: [PDF](https://arxiv.org/pdf/2507.20746)  

**Abstract**: Spiking neural networks possess the advantage of low energy consumption due to their event-driven nature. Compared with binary spike outputs, their inherent floating-point dynamics are more worthy of attention. The threshold level and re- set mode of neurons play a crucial role in determining the number and timing of spikes. The existing hard reset method causes information loss, while the improved soft reset method adopts a uniform treatment for neurons. In response to this, this paper designs an adaptive reset neuron, establishing the correlation between input, output and reset, and integrating a simple yet effective threshold adjustment strategy. It achieves excellent performance on various datasets while maintaining the advantage of low energy consumption. 

**Abstract (ZH)**: 基于事件驱动的神经网络由于其低能消耗特性而具备优势。与二元脉冲输出相比，其固有的浮点动态更为值得关注。神经元的阈值水平和重置模式决定了脉冲的数量和时间。现有的硬重置方法会导致信息丢失，而改进的软重置方法对神经元采用统一处理。针对此问题，本文设计了一种自适应重置神经元，建立了输入、输出与重置之间的关联，并集成了简单有效的阈值调整策略。在多种数据集上实现了优异性能，同时保持了低能消耗的优势。 

---
# Regularizing Subspace Redundancy of Low-Rank Adaptation 

**Title (ZH)**: 正则化低秩适应中的子空间冗余 

**Authors**: Yue Zhu, Haiwen Diao, Shang Gao, Jiazuo Yu, Jiawen Zhu, Yunzhi Zhuge, Shuai Hao, Xu Jia, Lu Zhang, Ying Zhang, Huchuan Lu  

**Link**: [PDF](https://arxiv.org/pdf/2507.20745)  

**Abstract**: Low-Rank Adaptation (LoRA) and its variants have delivered strong capability in Parameter-Efficient Transfer Learning (PETL) by minimizing trainable parameters and benefiting from reparameterization. However, their projection matrices remain unrestricted during training, causing high representation redundancy and diminishing the effectiveness of feature adaptation in the resulting subspaces. While existing methods mitigate this by manually adjusting the rank or implicitly applying channel-wise masks, they lack flexibility and generalize poorly across various datasets and architectures. Hence, we propose ReSoRA, a method that explicitly models redundancy between mapping subspaces and adaptively Regularizes Subspace redundancy of Low-Rank Adaptation. Specifically, it theoretically decomposes the low-rank submatrices into multiple equivalent subspaces and systematically applies de-redundancy constraints to the feature distributions across different projections. Extensive experiments validate that our proposed method consistently facilitates existing state-of-the-art PETL methods across various backbones and datasets in vision-language retrieval and standard visual classification benchmarks. Besides, as a training supervision, ReSoRA can be seamlessly integrated into existing approaches in a plug-and-play manner, with no additional inference costs. Code is publicly available at: this https URL. 

**Abstract (ZH)**: ReSoRA: 显式建模低秩适应子空间间的冗余并自适应正则化低秩适应子空间冗余 

---
# Prostate Cancer Classification Using Multimodal Feature Fusion and Explainable AI 

**Title (ZH)**: 前列腺癌分类：基于多模态特征融合与可解释人工智能 

**Authors**: Asma Sadia Khan, Fariba Tasnia Khan, Tanjim Mahmud, Salman Karim Khan, Rishita Chakma, Nahed Sharmen, Mohammad Shahadat Hossain, Karl Andersson  

**Link**: [PDF](https://arxiv.org/pdf/2507.20714)  

**Abstract**: Prostate cancer, the second most prevalent male malignancy, requires advanced diagnostic tools. We propose an explainable AI system combining BERT (for textual clinical notes) and Random Forest (for numerical lab data) through a novel multimodal fusion strategy, achieving superior classification performance on PLCO-NIH dataset (98% accuracy, 99% AUC). While multimodal fusion is established, our work demonstrates that a simple yet interpretable BERT+RF pipeline delivers clinically significant improvements - particularly for intermediate cancer stages (Class 2/3 recall: 0.900 combined vs 0.824 numerical/0.725 textual). SHAP analysis provides transparent feature importance rankings, while ablation studies prove textual features' complementary value. This accessible approach offers hospitals a balance of high performance (F1=89%), computational efficiency, and clinical interpretability - addressing critical needs in prostate cancer diagnostics. 

**Abstract (ZH)**: 前列腺癌是男性第二大常见的恶性肿瘤，需要先进的诊断工具。我们提出了一种结合BERT（处理文本临床笔记）和随机森林（处理数值实验室数据）的可解释AI系统，通过一种新颖的多模态融合策略，在PLCO-NIH数据集上实现了卓越的分类性能（准确率98%，AUC 99%）。尽管多模态融合已经确立，我们的工作证明了一个简单且可解释的BERT+RF流水线能够提供临床显著的改进，尤其是在中等癌症阶段（Class 2/3召回率：0.900结合型 vs 0.824 数值型/0.725 文本型）。SHAP分析提供了透明的特征重要性排名，而消融研究证明了文本特征的补充价值。这一易于实现的方法为医院提供了高性能（F1=89%）、计算效率和临床可解释性的平衡，以解决前列腺癌诊断中的关键需求。 

---
# Hot-Swap MarkBoard: An Efficient Black-box Watermarking Approach for Large-scale Model Distribution 

**Title (ZH)**: 热插拔标记板：一种高效的大规模模型分发黑盒水标记方法 

**Authors**: Zhicheng Zhang, Peizhuo Lv, Mengke Wan, Jiang Fang, Diandian Guo, Yezeng Chen, Yinlong Liu, Wei Ma, Jiyan Sun, Liru Geng  

**Link**: [PDF](https://arxiv.org/pdf/2507.20650)  

**Abstract**: Recently, Deep Learning (DL) models have been increasingly deployed on end-user devices as On-Device AI, offering improved efficiency and privacy. However, this deployment trend poses more serious Intellectual Property (IP) risks, as models are distributed on numerous local devices, making them vulnerable to theft and redistribution. Most existing ownership protection solutions (e.g., backdoor-based watermarking) are designed for cloud-based AI-as-a-Service (AIaaS) and are not directly applicable to large-scale distribution scenarios, where each user-specific model instance must carry a unique watermark. These methods typically embed a fixed watermark, and modifying the embedded watermark requires retraining the model. To address these challenges, we propose Hot-Swap MarkBoard, an efficient watermarking method. It encodes user-specific $n$-bit binary signatures by independently embedding multiple watermarks into a multi-branch Low-Rank Adaptation (LoRA) module, enabling efficient watermark customization without retraining through branch swapping. A parameter obfuscation mechanism further entangles the watermark weights with those of the base model, preventing removal without degrading model performance. The method supports black-box verification and is compatible with various model architectures and DL tasks, including classification, image generation, and text generation. Extensive experiments across three types of tasks and six backbone models demonstrate our method's superior efficiency and adaptability compared to existing approaches, achieving 100\% verification accuracy. 

**Abstract (ZH)**: 近期，深度学习(DL)模型被越来越广泛地部署在终端用户设备上，作为On-Device AI，提供了更好的效率和隐私保护。然而，这种部署趋势也带来了更严重的知识产权(IP)风险，因为模型被分散在众多本地设备上，使其容易被盗用和再分发。现有的大部分所有权保护解决方案（例如，基于后门的水印技术）设计用于基于云的AI服务(AIaaS)，并不直接适用于大规模分发场景，在这种场景中，每个用户特定的模型实例必须携带一个唯一的水印。这些方法通常嵌入固定水印，修改嵌入的水印需要重新训练模型。为了解决这些问题，我们提出了一种高效的水印方法——Hot-Swap MarkBoard。该方法通过独立地将多个水印嵌入到多分支低秩适应(LoRA)模块中，以支路切换的方式实现高效的水印个性化定制，而无需重新训练。参数混淆机制进一步将水印权重与基模型权重交织，防止水印的移除而不降级模型性能。该方法支持黑盒验证，并兼容各种模型架构和深度学习任务，包括分类、图像生成和文本生成。在三种类型任务和六种骨干模型上的广泛实验表明，与现有方法相比，该方法在效率和适应性方面表现出 superior 性能，验证准确率达到100%。 

---
# Lightweight Remote Sensing Scene Classification on Edge Devices via Knowledge Distillation and Early-exit 

**Title (ZH)**: 基于知识蒸馏和早退的轻量级边缘设备遥感场景分类 

**Authors**: Yang Zhao, Shusheng Li, Xueshang Feng  

**Link**: [PDF](https://arxiv.org/pdf/2507.20623)  

**Abstract**: As the development of lightweight deep learning algorithms, various deep neural network (DNN) models have been proposed for the remote sensing scene classification (RSSC) application. However, it is still challenging for these RSSC models to achieve optimal performance among model accuracy, inference latency, and energy consumption on resource-constrained edge devices. In this paper, we propose a lightweight RSSC framework, which includes a distilled global filter network (GFNet) model and an early-exit mechanism designed for edge devices to achieve state-of-the-art performance. Specifically, we first apply frequency domain distillation on the GFNet model to reduce model size. Then we design a dynamic early-exit model tailored for DNN models on edge devices to further improve model inference efficiency. We evaluate our E3C model on three edge devices across four datasets. Extensive experimental results show that it achieves an average of 1.3x speedup on model inference and over 40% improvement on energy efficiency, while maintaining high classification accuracy. 

**Abstract (ZH)**: 轻量化遥感场景分类框架：基于频率域蒸馏的GFNet模型与早退机制 

---
# Beyond Interactions: Node-Level Graph Generation for Knowledge-Free Augmentation in Recommender Systems 

**Title (ZH)**: 超越交互：知识无介接入点级图生成在推荐系统中的无知识增强 

**Authors**: Zhaoyan Wang, Hyunjun Ahn, In-Young Ko  

**Link**: [PDF](https://arxiv.org/pdf/2507.20578)  

**Abstract**: Recent advances in recommender systems rely on external resources such as knowledge graphs or large language models to enhance recommendations, which limit applicability in real-world settings due to data dependency and computational overhead. Although knowledge-free models are able to bolster recommendations by direct edge operations as well, the absence of augmentation primitives drives them to fall short in bridging semantic and structural gaps as high-quality paradigm substitutes. Unlike existing diffusion-based works that remodel user-item interactions, this work proposes NodeDiffRec, a pioneering knowledge-free augmentation framework that enables fine-grained node-level graph generation for recommendations and expands the scope of restricted augmentation primitives via diffusion. By synthesizing pseudo-items and corresponding interactions that align with the underlying distribution for injection, and further refining user preferences through a denoising preference modeling process, NodeDiffRec dramatically enhances both semantic diversity and structural connectivity without external knowledge. Extensive experiments across diverse datasets and recommendation algorithms demonstrate the superiority of NodeDiffRec, achieving State-of-the-Art (SOTA) performance, with maximum average performance improvement 98.6% in Recall@5 and 84.0% in NDCG@5 over selected baselines. 

**Abstract (ZH)**: 知识图谱和大型语言模型之外：NodeDiffRec——一种无知识增强的节点级别图生成推荐框架 

---
# DAG-AFL:Directed Acyclic Graph-based Asynchronous Federated Learning 

**Title (ZH)**: 基于有向无环图的异步联邦学习 

**Authors**: Shuaipeng Zhang, Lanju Kong, Yixin Zhang, Wei He, Yongqing Zheng, Han Yu, Lizhen Cui  

**Link**: [PDF](https://arxiv.org/pdf/2507.20571)  

**Abstract**: Due to the distributed nature of federated learning (FL), the vulnerability of the global model and the need for coordination among many client devices pose significant challenges. As a promising decentralized, scalable and secure solution, blockchain-based FL methods have attracted widespread attention in recent years. However, traditional consensus mechanisms designed for Proof of Work (PoW) similar to blockchain incur substantial resource consumption and compromise the efficiency of FL, particularly when participating devices are wireless and resource-limited. To address asynchronous client participation and data heterogeneity in FL, while limiting the additional resource overhead introduced by blockchain, we propose the Directed Acyclic Graph-based Asynchronous Federated Learning (DAG-AFL) framework. We develop a tip selection algorithm that considers temporal freshness, node reachability and model accuracy, with a DAG-based trusted verification strategy. Extensive experiments on 3 benchmarking datasets against eight state-of-the-art approaches demonstrate that DAG-AFL significantly improves training efficiency and model accuracy by 22.7% and 6.5% on average, respectively. 

**Abstract (ZH)**: 基于有向无环图的异步联邦学习框架（DAG-AFL） 

---
# T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation 

**Title (ZH)**: T2I-Copilot: 无需训练的多代理文本到图像系统，用于增强提示解释和交互生成 

**Authors**: Chieh-Yun Chen, Min Shi, Gong Zhang, Humphrey Shi  

**Link**: [PDF](https://arxiv.org/pdf/2507.20536)  

**Abstract**: Text-to-Image (T2I) generative models have revolutionized content creation but remain highly sensitive to prompt phrasing, often requiring users to repeatedly refine prompts multiple times without clear feedback. While techniques such as automatic prompt engineering, controlled text embeddings, denoising, and multi-turn generation mitigate these issues, they offer limited controllability, or often necessitate additional training, restricting the generalization abilities. Thus, we introduce T2I-Copilot, a training-free multi-agent system that leverages collaboration between (Multimodal) Large Language Models to automate prompt phrasing, model selection, and iterative refinement. This approach significantly simplifies prompt engineering while enhancing generation quality and text-image alignment compared to direct generation. Specifically, T2I-Copilot consists of three agents: (1) Input Interpreter, which parses the input prompt, resolves ambiguities, and generates a standardized report; (2) Generation Engine, which selects the appropriate model from different types of T2I models and organizes visual and textual prompts to initiate generation; and (3) Quality Evaluator, which assesses aesthetic quality and text-image alignment, providing scores and feedback for potential regeneration. T2I-Copilot can operate fully autonomously while also supporting human-in-the-loop intervention for fine-grained control. On GenAI-Bench, using open-source generation models, T2I-Copilot achieves a VQA score comparable to commercial models RecraftV3 and Imagen 3, surpasses FLUX1.1-pro by 6.17% at only 16.59% of its cost, and outperforms FLUX.1-dev and SD 3.5 Large by 9.11% and 6.36%. Code will be released at: this https URL. 

**Abstract (ZH)**: 基于多模态大语言模型的训练-free图文生成辅助系统T2I-Copilot 

---
# AQUA: A Large Language Model for Aquaculture & Fisheries 

**Title (ZH)**: AQUA：水产养殖与渔业领域的大型语言模型 

**Authors**: Praneeth Narisetty, Uday Kumar Reddy Kattamanchi, Lohit Akshant Nimma, Sri Ram Kaushik Karnati, Shiva Nagendra Babu Kore, Mounika Golamari, Tejashree Nageshreddy  

**Link**: [PDF](https://arxiv.org/pdf/2507.20520)  

**Abstract**: Aquaculture plays a vital role in global food security and coastal economies by providing sustainable protein sources. As the industry expands to meet rising demand, it faces growing challenges such as disease outbreaks, inefficient feeding practices, rising labor costs, logistical inefficiencies, and critical hatchery issues, including high mortality rates and poor water quality control. Although artificial intelligence has made significant progress, existing machine learning methods fall short of addressing the domain-specific complexities of aquaculture. To bridge this gap, we introduce AQUA, the first large language model (LLM) tailored for aquaculture, designed to support farmers, researchers, and industry practitioners. Central to this effort is AQUADAPT (Data Acquisition, Processing and Tuning), an Agentic Framework for generating and refining high-quality synthetic data using a combination of expert knowledge, largescale language models, and automated evaluation techniques. Our work lays the foundation for LLM-driven innovations in aquaculture research, advisory systems, and decision-making tools. 

**Abstract (ZH)**: 水产养殖在通过提供可持续蛋白质来源维护全球食物安全和沿海经济方面发挥着关键作用。随着行业扩展以满足不断增长的需求，它面临着越来越多的挑战，如疾病爆发、不合理的投喂实践、劳动力成本上升、物流效率低下以及关键繁殖场问题，包括高死亡率和水质控制不佳。尽管人工智能已经取得了显著进展，现有的机器学习方法在解决水产养殖领域的特定复杂性方面仍存在不足。为弥补这一差距，我们引入了AQUA，这是首款针对水产养殖领域的大型语言模型（LLM），旨在支持农民、研究人员和行业实践者。我们工作的核心是AQUADAPT（数据获取、处理和调优）框架，该框架结合专家知识、大规模语言模型和自动评估技术，用于生成和优化高质量的合成数据。我们的工作为基础模型在水产养殖研究、咨询系统和决策工具驱动的创新奠定了基础。 

---
# Shapley-Value-Based Graph Sparsification for GNN Inference 

**Title (ZH)**: 基于Shapley值的图稀疏化方法用于GNN推理 

**Authors**: Selahattin Akkas, Ariful Azad  

**Link**: [PDF](https://arxiv.org/pdf/2507.20460)  

**Abstract**: Graph sparsification is a key technique for improving inference efficiency in Graph Neural Networks by removing edges with minimal impact on predictions. GNN explainability methods generate local importance scores, which can be aggregated into global scores for graph sparsification. However, many explainability methods produce only non-negative scores, limiting their applicability for sparsification. In contrast, Shapley value based methods assign both positive and negative contributions to node predictions, offering a theoretically robust and fair allocation of importance by evaluating many subsets of graphs. Unlike gradient-based or perturbation-based explainers, Shapley values enable better pruning strategies that preserve influential edges while removing misleading or adversarial connections. Our approach shows that Shapley value-based graph sparsification maintains predictive performance while significantly reducing graph complexity, enhancing both interpretability and efficiency in GNN inference. 

**Abstract (ZH)**: 图稀疏化是通过移除对预测影响最小的边以提高图神经网络推理效率的关键技术。基于图的解释性方法生成局部重要性分数，这些分数可以聚合为全局分数用于图稀疏化。然而，许多解释性方法仅生成非负分数，限制了其在稀疏化中的应用。相比之下，基于Shapley值的方法为节点预测分配正负贡献，通过评估图的多个子集提供理论上稳健且公平的重要性分配。与基于梯度或扰动的解释器不同，Shapley值使我们能够实现更好的剪枝策略，保留有影响力的边并移除误导性或对抗性的连接。我们的方法表明，基于Shapley值的图稀疏化能够在显著减少图复杂性的同时保持预测性能，从而在GNN推理中增强可解释性和效率。 

---
# FAST: Similarity-based Knowledge Transfer for Efficient Policy Learning 

**Title (ZH)**: FAST：基于相似性知识迁移的高效策略学习 

**Authors**: Alessandro Capurso, Elia Piccoli, Davide Bacciu  

**Link**: [PDF](https://arxiv.org/pdf/2507.20433)  

**Abstract**: Transfer Learning (TL) offers the potential to accelerate learning by transferring knowledge across tasks. However, it faces critical challenges such as negative transfer, domain adaptation and inefficiency in selecting solid source policies. These issues often represent critical problems in evolving domains, i.e. game development, where scenarios transform and agents must adapt. The continuous release of new agents is costly and inefficient. In this work we challenge the key issues in TL to improve knowledge transfer, agents performance across tasks and reduce computational costs. The proposed methodology, called FAST - Framework for Adaptive Similarity-based Transfer, leverages visual frames and textual descriptions to create a latent representation of tasks dynamics, that is exploited to estimate similarity between environments. The similarity scores guides our method in choosing candidate policies from which transfer abilities to simplify learning of novel tasks. Experimental results, over multiple racing tracks, demonstrate that FAST achieves competitive final performance compared to learning-from-scratch methods while requiring significantly less training steps. These findings highlight the potential of embedding-driven task similarity estimations. 

**Abstract (ZH)**: Transfer Learning for Adaptive Similarity-based Task Transfer in Racing Games 

---
# ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings 

**Title (ZH)**: ResCap-DBP：一种基于全局蛋白质BERT嵌入的轻量级残差胶囊网络，用于准确的DNA结合蛋白预测 

**Authors**: Samiul Based Shuvo, Tasnia Binte Mamun, U Rajendra Acharya  

**Link**: [PDF](https://arxiv.org/pdf/2507.20426)  

**Abstract**: DNA-binding proteins (DBPs) are integral to gene regulation and cellular processes, making their accurate identification essential for understanding biological functions and disease mechanisms. Experimental methods for DBP identification are time-consuming and costly, driving the need for efficient computational prediction techniques. In this study, we propose a novel deep learning framework, ResCap-DBP, that combines a residual learning-based encoder with a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly from raw protein sequences. Our architecture incorporates dilated convolutions within residual blocks to mitigate vanishing gradient issues and extract rich sequence features, while capsule layers with dynamic routing capture hierarchical and spatial relationships within the learned feature space. We conducted comprehensive ablation studies comparing global and local embeddings from ProteinBERT and conventional one-hot encoding. Results show that ProteinBERT embeddings substantially outperform other representations on large datasets. Although one-hot encoding showed marginal advantages on smaller datasets, such as PDB186, it struggled to scale effectively. Extensive evaluations on four pairs of publicly available benchmark datasets demonstrate that our model consistently outperforms current state-of-the-art methods. It achieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On independent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2% and 83.3%, while maintaining competitive performance on larger datasets such as PDB20000. Notably, the model maintains a well balanced sensitivity and specificity across datasets. These results demonstrate the efficacy and generalizability of integrating global protein representations with advanced deep learning architectures for reliable and scalable DBP prediction in diverse genomic contexts. 

**Abstract (ZH)**: DNA结合蛋白(DBPs)的鉴定对于理解基因调控和细胞过程至关重要，因此其准确识别是了解生物功能和疾病机制的基础。实验方法耗时且昂贵，推动了高效计算预测技术的需求。本研究提出了一种新型深度学习框架ResCap-DBP，该框架结合了基于残差学习的编码器和一维胶囊网络(1D-CapsNet)，可以直接从原始蛋白质序列中预测DBPs。我们的架构在其残差块中包含扩张卷积，以缓解消失梯度问题并提取丰富的序列特征，同时动态路由的胶囊层捕获学习特征空间中的层级和空间关系。我们对ProteinBERT和传统的一热编码进行了全面的消融研究，结果显示ProteinBERT嵌入在大型数据集上显著优于其他表示方法。尽管一热编码在较小的数据集如PDB186上表现出轻微的优势，但在有效扩展方面存在困难。在四个公开可用基准数据集对的广泛评估中，我们的模型始终优于当前最先进的方法。该模型在PDB14189和PDB1075上的AUC得分分别为98.0%和89.5%，在独立测试集PDB2272和PDB186上分别达到了83.2%和83.3%的AUC，并在更大的数据集PDB20000上维持了竞争力。值得注意的是，该模型在不同数据集上保持了良好的敏感性和特异性平衡。这些结果展示了将全局蛋白质表示与先进的深度学习架构集成用于不同基因组背景下可靠且可扩展的DBP预测的有效性和通用性。 

---
# Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks? 

**Title (ZH)**: 自然语言理解基准在诊断语言现象方面的调查：为何不标准化诊断基准？ 

**Authors**: Khloud AL Jallad, Nada Ghneim, Ghaida Rebdawi  

**Link**: [PDF](https://arxiv.org/pdf/2507.20419)  

**Abstract**: Natural Language Understanding (NLU) is a basic task in Natural Language Processing (NLP). The evaluation of NLU capabilities has become a trending research topic that attracts researchers in the last few years, resulting in the development of numerous benchmarks. These benchmarks include various tasks and datasets in order to evaluate the results of pretrained models via public leaderboards. Notably, several benchmarks contain diagnostics datasets designed for investigation and fine-grained error analysis across a wide range of linguistic phenomena. This survey provides a comprehensive review of available English, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on their diagnostics datasets and the linguistic phenomena they covered. We present a detailed comparison and analysis of these benchmarks, highlighting their strengths and limitations in evaluating NLU tasks and providing in-depth error analysis. When highlighting the gaps in the state-of-the-art, we noted that there is no naming convention for macro and micro categories or even a standard set of linguistic phenomena that should be covered. Consequently, we formulated a research question regarding the evaluation metrics of the evaluation diagnostics benchmarks: "Why do not we have an evaluation standard for the NLU evaluation diagnostics benchmarks?" similar to ISO standard in industry. We conducted a deep analysis and comparisons of the covered linguistic phenomena in order to support experts in building a global hierarchy for linguistic phenomena in future. We think that having evaluation metrics for diagnostics evaluation could be valuable to gain more insights when comparing the results of the studied models on different diagnostics benchmarks. 

**Abstract (ZH)**: 自然语言理解能力评估：面向诊断数据集的基准比较与分析 

---
# WBHT: A Generative Attention Architecture for Detecting Black Hole Anomalies in Backbone Networks 

**Title (ZH)**: WBHT：一种用于主干网络中检测黑洞异常的生成注意力架构 

**Authors**: Kiymet Kaya, Elif Ak, Sule Gunduz Oguducu  

**Link**: [PDF](https://arxiv.org/pdf/2507.20373)  

**Abstract**: We propose the Wasserstein Black Hole Transformer (WBHT) framework for detecting black hole (BH) anomalies in communication networks. These anomalies cause packet loss without failure notifications, disrupting connectivity and leading to financial losses. WBHT combines generative modeling, sequential learning, and attention mechanisms to improve BH anomaly detection. It integrates a Wasserstein generative adversarial network with attention mechanisms for stable training and accurate anomaly identification. The model uses long-short-term memory layers to capture long-term dependencies and convolutional layers for local temporal patterns. A latent space encoding mechanism helps distinguish abnormal network behavior. Tested on real-world network data, WBHT outperforms existing models, achieving significant improvements in F1 score (ranging from 1.65% to 58.76%). Its efficiency and ability to detect previously undetected anomalies make it a valuable tool for proactive network monitoring and security, especially in mission-critical networks. 

**Abstract (ZH)**: Wasserstein黑洞变压器（WBHT）框架用于检测通信网络中的黑洞（BH）异常 

---
# Clustering by Attention: Leveraging Prior Fitted Transformers for Data Partitioning 

**Title (ZH)**: 基于注意力的聚类：利用先验拟合的Transformer进行数据分区 

**Authors**: Ahmed Shokry, Ayman Khalafallah  

**Link**: [PDF](https://arxiv.org/pdf/2507.20369)  

**Abstract**: Clustering is a core task in machine learning with wide-ranging applications in data mining and pattern recognition. However, its unsupervised nature makes it inherently challenging. Many existing clustering algorithms suffer from critical limitations: they often require careful parameter tuning, exhibit high computational complexity, lack interpretability, or yield suboptimal accuracy, especially when applied to large-scale datasets. In this paper, we introduce a novel clustering approach based on meta-learning. Our approach eliminates the need for parameter optimization while achieving accuracy that outperforms state-of-the-art clustering techniques. The proposed technique leverages a few pre-clustered samples to guide the clustering process for the entire dataset in a single forward pass. Specifically, we employ a pre-trained Prior-Data Fitted Transformer Network (PFN) to perform clustering. The algorithm computes attention between the pre-clustered samples and the unclustered samples, allowing it to infer cluster assignments for the entire dataset based on the learned relation. We theoretically and empirically demonstrate that, given just a few pre-clustered examples, the model can generalize to accurately cluster the rest of the dataset. Experiments on challenging benchmark datasets show that our approach can successfully cluster well-separated data without any pre-clustered samples, and significantly improves performance when a few clustered samples are provided. We show that our approach is superior to the state-of-the-art techniques. These results highlight the effectiveness and scalability of our approach, positioning it as a promising alternative to existing clustering techniques. 

**Abstract (ZH)**: 基于元学习的聚类方法：无需参数优化即可实现优于现有技术的聚类性能 

---
# A Theory of $θ$-Expectations 

**Title (ZH)**: $θ$-期望理论 

**Authors**: Qian Qi  

**Link**: [PDF](https://arxiv.org/pdf/2507.20353)  

**Abstract**: The canonical theory of stochastic calculus under ambiguity, founded on sub-additivity, is insensitive to non-convex uncertainty structures, leading to an identifiability impasse. This paper develops a mathematical framework for an identifiable calculus sensitive to non-convex geometry. We introduce the $\theta$-BSDE, a class of backward stochastic differential equations where the driver is determined by a pointwise maximization over a primitive, possibly non-convex, uncertainty set. The system's tractability is predicated not on convexity, but on a global analytic hypothesis: the existence of a unique and globally Lipschitz maximizer map for the driver function. Under this hypothesis, which carves out a tractable class of models, we establish well-posedness via a fixed-point argument. For a distinct, geometrically regular class of models, we prove a result of independent interest: under non-degeneracy conditions from Malliavin calculus, the maximizer is unique along any solution path, ensuring the model's internal consistency. We clarify the fundamental logical gap between this pathwise property and the global regularity required by our existence proof. The resulting valuation operator defines a dynamically consistent expectation, and we establish its connection to fully nonlinear PDEs via a Feynman-Kac formula. 

**Abstract (ZH)**: 不确定结构下的可识别随机 calculus 理论：基于子加性和非凸几何的数学框架 

---
# MIPS: a Multimodal Infinite Polymer Sequence Pre-training Framework for Polymer Property Prediction 

**Title (ZH)**: MIPS：一种用于聚合物性质预测的多模态无限聚合物序列预训练框架 

**Authors**: Jiaxi Wang, Yaosen Min, Xun Zhu, Miao Li, Ji Wu  

**Link**: [PDF](https://arxiv.org/pdf/2507.20326)  

**Abstract**: Polymers, composed of repeating structural units called monomers, are fundamental materials in daily life and industry. Accurate property prediction for polymers is essential for their design, development, and application. However, existing modeling approaches, which typically represent polymers by the constituent monomers, struggle to capture the whole properties of polymer, since the properties change during the polymerization process. In this study, we propose a Multimodal Infinite Polymer Sequence (MIPS) pre-training framework, which represents polymers as infinite sequences of monomers and integrates both topological and spatial information for comprehensive modeling. From the topological perspective, we generalize message passing mechanism (MPM) and graph attention mechanism (GAM) to infinite polymer sequences. For MPM, we demonstrate that applying MPM to infinite polymer sequences is equivalent to applying MPM on the induced star-linking graph of monomers. For GAM, we propose to further replace global graph attention with localized graph attention (LGA). Moreover, we show the robustness of the "star linking" strategy through Repeat and Shift Invariance Test (RSIT). Despite its robustness, "star linking" strategy exhibits limitations when monomer side chains contain ring structures, a common characteristic of polymers, as it fails the Weisfeiler-Lehman~(WL) test. To overcome this issue, we propose backbone embedding to enhance the capability of MPM and LGA on infinite polymer sequences. From the spatial perspective, we extract 3D descriptors of repeating monomers to capture spatial information. Finally, we design a cross-modal fusion mechanism to unify the topological and spatial information. Experimental validation across eight diverse polymer property prediction tasks reveals that MIPS achieves state-of-the-art performance. 

**Abstract (ZH)**: 多模态无限聚合物序列预训练框架（MIPS）：综合拓扑和空间信息的聚合物性质预测 

---
# A Comparative Study of OpenMP Scheduling Algorithm Selection Strategies 

**Title (ZH)**: OpenMP调度算法选择策略的比较研究 

**Authors**: Jonas H. Müller Korndörfer, Ali Mohammed, Ahmed Eleliemy, Quentin Guilloteau, Reto Krummenacher, Florina M. Ciorba  

**Link**: [PDF](https://arxiv.org/pdf/2507.20312)  

**Abstract**: Scientific and data science applications are becoming increasingly complex, with growing computational and memory demands. Modern high performance computing (HPC) systems provide high parallelism and heterogeneity across nodes, devices, and cores. To achieve good performance, effective scheduling and load balancing techniques are essential. Parallel programming frameworks such as OpenMP now offer a variety of advanced scheduling algorithms to support diverse applications and platforms. This creates an instance of the scheduling algorithm selection problem, which involves identifying the most suitable algorithm for a given combination of workload and system characteristics.
In this work, we explore learning-based approaches for selecting scheduling algorithms in OpenMP. We propose and evaluate expert-based and reinforcement learning (RL)-based methods, and conduct a detailed performance analysis across six applications and three systems. Our results show that RL methods are capable of learning high-performing scheduling decisions, although they require significant exploration, with the choice of reward function playing a key role. Expert-based methods, in contrast, rely on prior knowledge and involve less exploration, though they may not always identify the optimal algorithm for a specific application-system pair. By combining expert knowledge with RL-based learning, we achieve improved performance and greater adaptability.
Overall, this work demonstrates that dynamic selection of scheduling algorithms during execution is both viable and beneficial for OpenMP applications. The approach can also be extended to MPI-based programs, enabling optimization of scheduling decisions across multiple levels of parallelism. 

**Abstract (ZH)**: 科学和数据科学应用日益复杂，对计算能力和内存的需求也在增长。现代高性能计算（HPC）系统在节点、设备和内核上提供了高并行性和异构性。为了实现良好的性能，有效的调度和负载均衡技术是必不可少的。OpenMP等并行编程框架现在提供了种类繁多的高级调度算法，以支持多样化的应用程序和平台。这创造了调度算法选择问题的实例，涉及根据工作负载和系统特性识别最合适的算法。

在本工作中，我们探讨了在OpenMP中使用基于学习的方法选择调度算法。我们提出了基于专家知识和强化学习（RL）的方法，并在六个应用程序和三种系统上进行了详细的性能分析。结果显示，RL方法能够学习高性能的调度决策，尽管它们需要大量的探索，而奖励函数的选择起着关键作用。相比之下，基于专家知识的方法依赖于先验知识并涉及较少的探索，但它们可能不总是能够识别特定应用程序-系统配对的最佳算法。通过对专家知识与RL学习的结合，我们实现了改进的性能和更高的适应性。

总体而言，本工作证明了在执行过程中动态选择调度算法对于OpenMP应用程序既是可行的又是有益的。该方法还可以扩展到基于MPI的程序中，从而使跨多个并行级别调度决策的优化成为可能。 

---
# Towards Generalized Parameter Tuning in Coherent Ising Machines: A Portfolio-Based Approach 

**Title (ZH)**: 相干伊辛机中通用参数调优的研究：一种基于投资组合的方法 

**Authors**: Tatsuro Hanyu, Takahiro Katagiri, Daichi Mukunoki, Tetsuya Hoshino  

**Link**: [PDF](https://arxiv.org/pdf/2507.20295)  

**Abstract**: Coherent Ising Machines (CIMs) have recently gained attention as a promising computing model for solving combinatorial optimization problems. In particular, the Chaotic Amplitude Control (CAC) algorithm has demonstrated high solution quality, but its performance is highly sensitive to a large number of hyperparameters, making efficient tuning essential. In this study, we present an algorithm portfolio approach for hyperparameter tuning in CIMs employing Chaotic Amplitude Control with momentum (CACm) algorithm. Our method incorporates multiple search strategies, enabling flexible and effective adaptation to the characteristics of the hyperparameter space. Specifically, we propose two representative tuning methods, Method A and Method B. Method A optimizes each hyperparameter sequentially with a fixed total number of trials, while Method B prioritizes hyperparameters based on initial evaluations before applying Method A in order. Performance evaluations were conducted on the Supercomputer "Flow" at Nagoya University, using planted Wishart instances and Time to Solution (TTS) as the evaluation metric. Compared to the baseline performance with best-known hyperparameters, Method A achieved up to 1.47x improvement, and Method B achieved up to 1.65x improvement. These results demonstrate the effectiveness of the algorithm portfolio approach in enhancing the tuning process for CIMs. 

**Abstract (ZH)**: Coherent Ising Machines中Chaotic Amplitude Control算法及其动量优化的超参数调优算法组合研究 

---
# Learning from Expert Factors: Trajectory-level Reward Shaping for Formulaic Alpha Mining 

**Title (ZH)**: 基于专家因素的学习：公式化alpha挖掘的轨迹级奖励塑形 

**Authors**: Junjie Zhao, Chengxi Zhang, Chenkai Wang, Peng Yang  

**Link**: [PDF](https://arxiv.org/pdf/2507.20263)  

**Abstract**: Reinforcement learning (RL) has successfully automated the complex process of mining formulaic alpha factors, for creating interpretable and profitable investment strategies. However, existing methods are hampered by the sparse rewards given the underlying Markov Decision Process. This inefficiency limits the exploration of the vast symbolic search space and destabilizes the training process. To address this, Trajectory-level Reward Shaping (TLRS), a novel reward shaping method, is proposed. TLRS provides dense, intermediate rewards by measuring the subsequence-level similarity between partially generated expressions and a set of expert-designed formulas. Furthermore, a reward centering mechanism is introduced to reduce training variance. Extensive experiments on six major Chinese and U.S. stock indices show that TLRS significantly improves the predictive power of mined factors, boosting the Rank Information Coefficient by 9.29% over existing potential-based shaping algorithms. Notably, TLRS achieves a major leap in computational efficiency by reducing its time complexity with respect to the feature dimension from linear to constant, which is a significant improvement over distance-based baselines. 

**Abstract (ZH)**: 强化学习（RL）已成功自动化了公式化alpha因子挖掘的复杂过程，以创建可解释且盈利的投资策略。然而，现有方法因潜在的马尔可夫决策过程提供的稀疏奖励而受限。这种低效率限制了对广阔符号搜索空间的探索，并导致训练过程不稳定。为解决这一问题，提出了一种新型的奖励塑造方法——轨迹级奖励塑造（TLRS）。TLRS通过测量部分生成表达式与一组专家设计公式的子序列级相似性，提供了密集的中间奖励。此外，引入了一种奖励居中机制以降低训练方差。在六大主要中国和美国股票指数上的广泛实验表明，TLRS显著提高了挖掘因子的预测能力，相对于现有的基于潜力的奖励塑造算法，提升了排名信息系数9.29%。值得注意的是，TLRS通过将其时间复杂度相对于特征维度从线性降低到常数，实现了显著的计算效率提升，这在基于距离的基线方法上得到了显著改善。 

---
# Protein-SE(3): Benchmarking SE(3)-based Generative Models for Protein Structure Design 

**Title (ZH)**: Protein-SE(3): 基于SE(3)的蛋白质结构设计生成模型基准研究 

**Authors**: Lang Yu, Zhangyang Gao, Cheng Tan, Qin Chen, Jie Zhou, Liang He  

**Link**: [PDF](https://arxiv.org/pdf/2507.20243)  

**Abstract**: SE(3)-based generative models have shown great promise in protein geometry modeling and effective structure design. However, the field currently lacks a modularized benchmark to enable comprehensive investigation and fair comparison of different methods. In this paper, we propose Protein-SE(3), a new benchmark based on a unified training framework, which comprises protein scaffolding tasks, integrated generative models, high-level mathematical abstraction, and diverse evaluation metrics. Recent advanced generative models designed for protein scaffolding, from multiple perspectives like DDPM (Genie1 and Genie2), Score Matching (FrameDiff and RfDiffusion) and Flow Matching (FoldFlow and FrameFlow) are integrated into our framework. All integrated methods are fairly investigated with the same training dataset and evaluation metrics. Furthermore, we provide a high-level abstraction of the mathematical foundations behind the generative models, enabling fast prototyping of future algorithms without reliance on explicit protein structures. Accordingly, we release the first comprehensive benchmark built upon unified training framework for SE(3)-based protein structure design, which is publicly accessible at this https URL. 

**Abstract (ZH)**: SE(3)-基于的生成模型在蛋白质几何建模和有效结构设计中展现出了巨大潜力。然而，当前该领域缺乏模块化的基准以实现不同方法的全面调查和公平比较。在本文中，我们提出Protein-SE(3)作为基于统一训练框架的新基准，涵盖蛋白质支架任务、集成生成模型、高层次的数学抽象和多样化的评价指标。近年来从多个视角（如DDPM（Genie1和Genie2）、Score Matching（FrameDiff和RfDiffusion）和Flow Matching（FoldFlow和FrameFlow））设计的用于蛋白质支架的先进生成模型被整合到我们的框架中。所有整合的方法在相同的训练数据集和评价指标下进行了公平的调查。此外，我们提供了生成模型背后的数学基础的高层次抽象，使得未来算法的快速原型设计无需依赖显式的蛋白质结构。因此，我们发布了首个基于统一训练框架的SE(3)-基于蛋白质结构设计基准，该基准公开可获取。 

---
# Partial Domain Adaptation via Importance Sampling-based Shift Correction 

**Title (ZH)**: 基于重要性采样偏差校正的部分领域适应 

**Authors**: Cheng-Jun Guo, Chuan-Xian Ren, You-Wei Luo, Xiao-Lin Xu, Hong Yan  

**Link**: [PDF](https://arxiv.org/pdf/2507.20191)  

**Abstract**: Partial domain adaptation (PDA) is a challenging task in real-world machine learning scenarios. It aims to transfer knowledge from a labeled source domain to a related unlabeled target domain, where the support set of the source label distribution subsumes the target one. Previous PDA works managed to correct the label distribution shift by weighting samples in the source domain. However, the simple reweighing technique cannot explore the latent structure and sufficiently use the labeled data, and then models are prone to over-fitting on the source domain. In this work, we propose a novel importance sampling-based shift correction (IS$^2$C) method, where new labeled data are sampled from a built sampling domain, whose label distribution is supposed to be the same as the target domain, to characterize the latent structure and enhance the generalization ability of the model. We provide theoretical guarantees for IS$^2$C by proving that the generalization error can be sufficiently dominated by IS$^2$C. In particular, by implementing sampling with the mixture distribution, the extent of shift between source and sampling domains can be connected to generalization error, which provides an interpretable way to build IS$^2$C. To improve knowledge transfer, an optimal transport-based independence criterion is proposed for conditional distribution alignment, where the computation of the criterion can be adjusted to reduce the complexity from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2)$ in realistic PDA scenarios. Extensive experiments on PDA benchmarks validate the theoretical results and demonstrate the effectiveness of our IS$^2$C over existing methods. 

**Abstract (ZH)**: 基于重要性采样的偏移纠正（IS$^2$C）方法 

---
# NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis 

**Title (ZH)**: NeuroCLIP: 一种用于甲基苯丙胺成瘾经颅磁刺激治疗分析的多模态对比学习方法 

**Authors**: Chengkai Wang, Di Wu, Yunsheng Liao, Wenyao Zheng, Ziyi Zeng, Xurong Gao, Hemmings Wu, Zhoule Zhu, Jie Yang, Lihua Zhong, Weiwei Cheng, Yun-Hsuan Chen, Mohamad Sawan  

**Link**: [PDF](https://arxiv.org/pdf/2507.20189)  

**Abstract**: Methamphetamine dependence poses a significant global health challenge, yet its assessment and the evaluation of treatments like repetitive transcranial magnetic stimulation (rTMS) frequently depend on subjective self-reports, which may introduce uncertainties. While objective neuroimaging modalities such as electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) offer alternatives, their individual limitations and the reliance on conventional, often hand-crafted, feature extraction can compromise the reliability of derived biomarkers. To overcome these limitations, we propose NeuroCLIP, a novel deep learning framework integrating simultaneously recorded EEG and fNIRS data through a progressive learning strategy. This approach offers a robust and trustworthy biomarker for methamphetamine addiction. Validation experiments show that NeuroCLIP significantly improves discriminative capabilities among the methamphetamine-dependent individuals and healthy controls compared to models using either EEG or only fNIRS alone. Furthermore, the proposed framework facilitates objective, brain-based evaluation of rTMS treatment efficacy, demonstrating measurable shifts in neural patterns towards healthy control profiles after treatment. Critically, we establish the trustworthiness of the multimodal data-driven biomarker by showing its strong correlation with psychometrically validated craving scores. These findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP offers enhanced robustness and reliability over single-modality approaches, providing a valuable tool for addiction neuroscience research and potentially improving clinical assessments. 

**Abstract (ZH)**: 甲基苯丙胺依赖性构成一项重大的全球健康挑战，但其评估和治疗效果评估（如重复经颅磁刺激rTMS）通常依赖于主观自我报告，这可能引入不确定性。虽然电生理成像技术如脑电图（EEG）和功能性近红外光谱成像（fNIRS）提供了替代方案，但它们各自的局限性以及对传统、常手工构建的特征提取的依赖性可能损害衍生生物标志物的可靠性。为克服这些局限，我们提出了一种名为NeuroCLIP的新型深度学习框架，该框架通过渐进式学习策略整合同时记录的EEG和fNIRS数据。该方法提供了甲基苯丙胺依赖性的稳健且可信赖的生物标志物。验证实验表明，NeuroCLIP在区分甲基苯丙胺依赖个体和健康对照方面显著优于仅使用EEG或仅fNIRS的模型。此外，该框架促进了针对rTMS治疗效果的客观、基于大脑的评估，显示治疗后神经模式向健康对照模式发生了可测量的变化。关键地，我们通过证明其与心理测量学验证的渴求评分高度相关，建立了多模态数据驱动生物标志物的可靠性。这些发现表明，通过NeuroCLIP从EEG-fNIRS数据中提取的生物标志物相较于单模态方法具有更高的稳健性和可靠性，为其在成瘾神经科学研究中提供了有价值的工具，并有可能改善临床评估。 

---
# High-Performance Parallel Optimization of the Fish School Behaviour on the Setonix Platform Using OpenMP 

**Title (ZH)**: 基于Setonix平台的鱼群行为高性能并行优化实现（使用OpenMP） 

**Authors**: Haitian Wang, Long Qin  

**Link**: [PDF](https://arxiv.org/pdf/2507.20173)  

**Abstract**: This paper presents an in-depth investigation into the high-performance parallel optimization of the Fish School Behaviour (FSB) algorithm on the Setonix supercomputing platform using the OpenMP framework. Given the increasing demand for enhanced computational capabilities for complex, large-scale calculations across diverse domains, there's an imperative need for optimized parallel algorithms and computing structures. The FSB algorithm, inspired by nature's social behavior patterns, provides an ideal platform for parallelization due to its iterative and computationally intensive nature. This study leverages the capabilities of the Setonix platform and the OpenMP framework to analyze various aspects of multi-threading, such as thread counts, scheduling strategies, and OpenMP constructs, aiming to discern patterns and strategies that can elevate program performance. Experiments were designed to rigorously test different configurations, and our results not only offer insights for parallel optimization of FSB on Setonix but also provide valuable references for other parallel computational research using OpenMP. Looking forward, other factors, such as cache behavior and thread scheduling strategies at micro and macro levels, hold potential for further exploration and optimization. 

**Abstract (ZH)**: 基于OpenMP框架的Setonix超级计算平台上的高性能Fish School Behaviour算法并行优化研究 

---
# ASNN: Learning to Suggest Neural Architectures from Performance Distributions 

**Title (ZH)**: ASNN: 从性能分布中学习建议神经网络架构 

**Authors**: Jinwook Hong  

**Link**: [PDF](https://arxiv.org/pdf/2507.20164)  

**Abstract**: The architecture of a neural network (NN) plays a critical role in determining its performance. However, there is no general closed-form function that maps between network structure and accuracy, making the process of architecture design largely heuristic or search-based. In this study, we propose the Architecture Suggesting Neural Network (ASNN), a model designed to learn the relationship between NN architecture and its test accuracy, and to suggest improved architectures accordingly. To train ASNN, we constructed datasets using TensorFlow-based models with varying numbers of layers and nodes. Experimental results were collected for both 2-layer and 3-layer architectures across a grid of configurations, each evaluated with 10 repeated trials to account for stochasticity. Accuracy values were treated as inputs, and architectural parameters as outputs. The trained ASNN was then used iteratively to predict architectures that yield higher performance. In both 2-layer and 3-layer cases, ASNN successfully suggested architectures that outperformed the best results found in the original training data. Repeated prediction and retraining cycles led to the discovery of architectures with improved mean test accuracies, demonstrating the model's capacity to generalize the performance-structure relationship. These results suggest that ASNN provides an efficient alternative to random search for architecture optimization, and offers a promising approach toward automating neural network design. "Parts of the manuscript, including text editing and expression refinement, were supported by OpenAI's ChatGPT. All content was reviewed and verified by the authors." 

**Abstract (ZH)**: 神经网络架构建议网络（ASNN）：学习架构与测试准确率关系并提出改进架构 

---
# Multi-Agent Interactive Question Generation Framework for Long Document Understanding 

**Title (ZH)**: 长文档理解的多agent互动式问题生成框架 

**Authors**: Kesen Wang, Daulet Toibazar, Abdulrahman Alfulayt, Abdulaziz S. Albadawi, Ranya A. Alkahtani, Asma A. Ibrahim, Haneen A. Alhomoud, Sherif Mohamed, Pedro J. Moreno  

**Link**: [PDF](https://arxiv.org/pdf/2507.20145)  

**Abstract**: Document Understanding (DU) in long-contextual scenarios with complex layouts remains a significant challenge in vision-language research. Although Large Vision-Language Models (LVLMs) excel at short-context DU tasks, their performance declines in long-context settings. A key limitation is the scarcity of fine-grained training data, particularly for low-resource languages such as Arabic. Existing state-of-the-art techniques rely heavily on human annotation, which is costly and inefficient. We propose a fully automated, multi-agent interactive framework to generate long-context questions efficiently. Our approach efficiently generates high-quality single- and multi-page questions for extensive English and Arabic documents, covering hundreds of pages across diverse domains. This facilitates the development of LVLMs with enhanced long-context understanding ability. Experimental results in this work have shown that our generated English and Arabic questions (\textbf{AraEngLongBench}) are quite challenging to major open- and close-source LVLMs. The code and data proposed in this work can be found in this https URL. Sample Question and Answer (QA) pairs and structured system prompts can be found in the Appendix. 

**Abstract (ZH)**: 在复杂布局下的长文字段理解（DU）研究仍是在视觉语言领域的一大挑战。现有的大规模视觉语言模型（LVLMs）在短文字段理解任务上表现出色，但在长文字段环境中性能下降。一个主要限制是高质量训练数据的稀缺，特别是对于如阿拉伯语这样的低资源语言。现有最先进的技术严重依赖人工标注，这既昂贵又低效。我们提出了一种全自动的多智能体互动框架，以高效生成长文字段问题。我们的方法能够高效生成高质量的单页和多页问题，涵盖数百页横跨多个领域的广泛英文和阿拉伯文文档。这有助于开发具有增强长文字段理解能力的大规模视觉语言模型。实验结果表明，我们生成的英文和阿拉伯文问题（AraEngLongBench）对主要的开源和闭源视觉语言模型颇具挑战性。本文中提出的方法代码和数据可在以下链接找到：this https URL。样本问题和答案（QA）对以及结构化的系统提示可以在附录中找到。 

---
# Awesome-OL: An Extensible Toolkit for Online Learning 

**Title (ZH)**: Awesome-OL：一种可扩展的在线学习工具包 

**Authors**: Zeyi Liu, Songqiao Hu, Pengyu Han, Jiaming Liu, Xiao He  

**Link**: [PDF](https://arxiv.org/pdf/2507.20144)  

**Abstract**: In recent years, online learning has attracted increasing attention due to its adaptive capability to process streaming and non-stationary data. To facilitate algorithm development and practical deployment in this area, we introduce Awesome-OL, an extensible Python toolkit tailored for online learning research. Awesome-OL integrates state-of-the-art algorithm, which provides a unified framework for reproducible comparisons, curated benchmark datasets, and multi-modal visualization. Built upon the scikit-multiflow open-source infrastructure, Awesome-OL emphasizes user-friendly interactions without compromising research flexibility or extensibility. The source code is publicly available at: this https URL. 

**Abstract (ZH)**: 近年来，由于其处理流式和非稳态数据的适应能力，在线学习吸引了越来越多的关注。为促进该领域的算法开发和实际部署，我们介绍了Awesome-OL，这是一个针对在线学习研究的可扩展Python工具包。Awesome-OL集成了最先进的算法，提供了一个统一框架以实现可重复比较、精心策划的标准数据集以及多模态可视化。基于scikit-multiflow开源基础设施，Awesome-OL强调用户友好的交互，同时不牺牲研究的灵活性或可扩展性。源代码可在以下网址获取：this https URL。 

---
# Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech 

**Title (ZH)**: 不要模仿我的声音：零样本文本到语音的说话人身份遗忘 

**Authors**: Taesoo Kim, Jinju Kim, Dongchan Kim, Jong Hwan Ko, Gyeong-Moon Park  

**Link**: [PDF](https://arxiv.org/pdf/2507.20140)  

**Abstract**: The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has enabled high-fidelity voice synthesis from minimal audio cues, raising significant privacy and ethical concerns. Despite the threats to voice privacy, research to selectively remove the knowledge to replicate unwanted individual voices from pre-trained model parameters has not been explored. In this paper, we address the new challenge of speaker identity unlearning for ZS-TTS systems. To meet this goal, we propose the first machine unlearning frameworks for ZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the model forgets designated speaker identities while retaining its ability to generate accurate speech for other speakers. Our proposed methods incorporate randomness to prevent consistent replication of forget speakers' voices, assuring unlearned identities remain untraceable. Additionally, we propose a new evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses the model's ability to disregard prompts associated with forgotten speakers, effectively neutralizing its knowledge of these voices. The experiments conducted on the state-of-the-art model demonstrate that TGU prevents the model from replicating forget speakers' voices while maintaining high quality for other speakers. The demo is available at this https URL 

**Abstract (ZH)**: 零样本文本到语音系统中的说话人身份遗忘技术研究 

---
# Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering 

**Title (ZH)**: Sem-DPO：在提示工程中的偏好优化中缓解语义不一致性 

**Authors**: Anas Mohamed, Azal Ahmad Khan, Xinran Wang, Ahmad Faraz Khan, Shuwen Ge, Saman Bahzad Khan, Ayaan Ahmad, Ali Anwar  

**Link**: [PDF](https://arxiv.org/pdf/2507.20133)  

**Abstract**: Generative AI can now synthesize strikingly realistic images from text, yet output quality remains highly sensitive to how prompts are phrased. Direct Preference Optimization (DPO) offers a lightweight, off-policy alternative to RL for automatic prompt engineering, but its token-level regularization leaves semantic inconsistency unchecked as prompts that win higher preference scores can still drift away from the user's intended meaning.
We introduce Sem-DPO, a variant of DPO that preserves semantic consistency yet retains its simplicity and efficiency. Sem-DPO scales the DPO loss by an exponential weight proportional to the cosine distance between the original prompt and winning candidate in embedding space, softly down-weighting training signals that would otherwise reward semantically mismatched prompts. We provide the first analytical bound on semantic drift for preference-tuned prompt generators, showing that Sem-DPO keeps learned prompts within a provably bounded neighborhood of the original text. On three standard text-to-image prompt-optimization benchmarks and two language models, Sem-DPO achieves 8-12% higher CLIP similarity and 5-9% higher human-preference scores (HPSv2.1, PickScore) than DPO, while also outperforming state-of-the-art baselines. These findings suggest that strong flat baselines augmented with semantic weighting should become the new standard for prompt-optimization studies and lay the groundwork for broader, semantics-aware preference optimization in language models. 

**Abstract (ZH)**: Sem-DPO: 保持语义一致性的同时简化直接偏好优化 

---
# Aggregation-aware MLP: An Unsupervised Approach for Graph Message-passing 

**Title (ZH)**: 聚合意识MLP：图消息传递的无监督方法 

**Authors**: Xuanting Xie, Bingheng Li, Erlin Pan, Zhao Kang, Wenyu Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.20127)  

**Abstract**: Graph Neural Networks (GNNs) have become a dominant approach to learning graph representations, primarily because of their message-passing mechanisms. However, GNNs typically adopt a fixed aggregator function such as Mean, Max, or Sum without principled reasoning behind the selection. This rigidity, especially in the presence of heterophily, often leads to poor, problem dependent performance. Although some attempts address this by designing more sophisticated aggregation functions, these methods tend to rely heavily on labeled data, which is often scarce in real-world tasks. In this work, we propose a novel unsupervised framework, "Aggregation-aware Multilayer Perceptron" (AMLP), which shifts the paradigm from directly crafting aggregation functions to making MLP adaptive to aggregation. Our lightweight approach consists of two key steps: First, we utilize a graph reconstruction method that facilitates high-order grouping effects, and second, we employ a single-layer network to encode varying degrees of heterophily, thereby improving the capacity and applicability of the model. Extensive experiments on node clustering and classification demonstrate the superior performance of AMLP, highlighting its potential for diverse graph learning scenarios. 

**Abstract (ZH)**: 基于聚合感知的多层感知机（AMLP）：一种无监督框架 

---
# Iterative Pretraining Framework for Interatomic Potentials 

**Title (ZH)**: 迭代预训练框架用于原子势能 

**Authors**: Taoyong Cui, Zhongyao Wang, Dongzhan Zhou, Yuqiang Li, Lei Bai, Wanli Ouyang, Mao Su, Shufei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.20118)  

**Abstract**: Machine learning interatomic potentials (MLIPs) enable efficient molecular dynamics (MD) simulations with ab initio accuracy and have been applied across various domains in physical science. However, their performance often relies on large-scale labeled training data. While existing pretraining strategies can improve model performance, they often suffer from a mismatch between the objectives of pretraining and downstream tasks or rely on extensive labeled datasets and increasingly complex architectures to achieve broad generalization. To address these challenges, we propose Iterative Pretraining for Interatomic Potentials (IPIP), a framework designed to iteratively improve the predictive performance of MLIP models. IPIP incorporates a forgetting mechanism to prevent iterative training from converging to suboptimal local minima. Unlike general-purpose foundation models, which frequently underperform on specialized tasks due to a trade-off between generality and system-specific accuracy, IPIP achieves higher accuracy and efficiency using lightweight architectures. Compared to general-purpose force fields, this approach achieves over 80% reduction in prediction error and up to 4x speedup in the challenging Mo-S-O system, enabling fast and accurate simulations. 

**Abstract (ZH)**: 迭代原子势前训练（IPIP）：用于迭代改进机器学习原子势模型预测性能的框架 

---
# Packet-Level DDoS Data Augmentation Using Dual-Stream Temporal-Field Diffusion 

**Title (ZH)**: 面向包级的分布式拒绝服务数据增强方法：双流时域场扩散 

**Authors**: Gongli Xi, Ye Tian, Yannan Hu, Yuchao Zhang, Yapeng Niu, Xiangyang Gong  

**Link**: [PDF](https://arxiv.org/pdf/2507.20115)  

**Abstract**: In response to Distributed Denial of Service (DDoS) attacks, recent research efforts increasingly rely on Machine Learning (ML)-based solutions, whose effectiveness largely depends on the quality of labeled training datasets. To address the scarcity of such datasets, data augmentation with synthetic traces is often employed. However, current synthetic trace generation methods struggle to capture the complex temporal patterns and spatial distributions exhibited in emerging DDoS attacks. This results in insufficient resemblance to real traces and unsatisfied detection accuracy when applied to ML tasks. In this paper, we propose Dual-Stream Temporal-Field Diffusion (DSTF-Diffusion), a multi-view, multi-stream network traffic generative model based on diffusion models, featuring two main streams: The field stream utilizes spatial mapping to bridge network data characteristics with pre-trained realms of stable diffusion models, effectively translating complex network interactions into formats that stable diffusion can process, while the spatial stream adopts a dynamic temporal modeling approach, meticulously capturing the intrinsic temporal patterns of network traffic. Extensive experiments demonstrate that data generated by our model exhibits higher statistical similarity to originals compared to current state-of-the-art solutions, and enhance performances on a wide range of downstream tasks. 

**Abstract (ZH)**: 基于扩散模型的双流时空场扩散网络流量生成模型（DSTF-Diffusion）：应对分布式拒绝服务攻击的合成踪迹生成方法 

---
# Online Learning with Probing for Sequential User-Centric Selection 

**Title (ZH)**: 基于探针的在线学习auty： sequential 用户中心选择 

**Authors**: Tianyi Xu, Yiting Chen, Henger Li, Zheyong Bian, Emiliano Dall'Anese, Zizhan Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2507.20112)  

**Abstract**: We formalize sequential decision-making with information acquisition as the probing-augmented user-centric selection (PUCS) framework, where a learner first probes a subset of arms to obtain side information on resources and rewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such as ridesharing, wireless scheduling, and content recommendation, in which both resources and payoffs are initially unknown and probing is costly. For the offline setting with known distributions, we present a greedy probing algorithm with a constant-factor approximation guarantee $\zeta = (e-1)/(2e-1)$. For the online setting with unknown distributions, we introduce OLPA, a stochastic combinatorial bandit algorithm that achieves a regret bound $\mathcal{O}(\sqrt{T} + \ln^{2} T)$. We also prove a lower bound $\Omega(\sqrt{T})$, showing that the upper bound is tight up to logarithmic factors. Experiments on real-world data demonstrate the effectiveness of our solutions. 

**Abstract (ZH)**: 我们将信息获取增强的用户为中心的选择（PUCS）框架形式化为序贯决策问题，其中学习者首先探测一部分臂以获取资源和奖励的侧信息，然后将$K$次播放分配给$M$个臂。PUCS涵盖如 ridesharing、无线调度和内容推荐等应用，在这些应用中，资源和收益最初未知且探测成本高。对于已知分布的离线设置，我们提出了一种贪婪探测算法，其近似保证为常数因子$\zeta = (e-1)/(2e-1)$。对于未知分布的在线设置，我们引入了OLPA（在线组合-bandit算法），其后悔界为$\mathcal{O}(\sqrt{T} + \ln^{2} T)$，并证明了一个下界$\Omega(\sqrt{T})$，显示了上界的紧致性（至对数因子）。实验结果显示了我们方法的有效性。 

---
# EcoTransformer: Attention without Multiplication 

**Title (ZH)**: EcoTransformer: 注意力机制 without 乘法 

**Authors**: Xin Gao, Xingming Xu  

**Link**: [PDF](https://arxiv.org/pdf/2507.20096)  

**Abstract**: The Transformer, with its scaled dot-product attention mechanism, has become a foundational architecture in modern AI. However, this mechanism is computationally intensive and incurs substantial energy costs. We propose a new Transformer architecture EcoTransformer, in which the output context vector is constructed as the convolution of the values using a Laplacian kernel, where the distances are measured by the L1 metric between the queries and keys. Compared to dot-product based attention, the new attention score calculation is free of matrix multiplication. It performs on par with, or even surpasses, scaled dot-product attention in NLP, bioinformatics, and vision tasks, while consuming significantly less energy. 

**Abstract (ZH)**: EcoTransformer：基于拉普拉斯核和L1度量的新Transformer架构 

---
# Irredundant k-Fold Cross-Validation 

**Title (ZH)**: 不可约简的k折交叉验证 

**Authors**: Jesus S. Aguilar-Ruiz  

**Link**: [PDF](https://arxiv.org/pdf/2507.20048)  

**Abstract**: In traditional k-fold cross-validation, each instance is used ($k\!-\!1$) times for training and once for testing, leading to redundancy that lets many instances disproportionately influence the learning phase. We introduce Irredundant $k$--fold cross-validation, a novel method that guarantees each instance is used exactly once for training and once for testing across the entire validation procedure. This approach ensures a more balanced utilization of the dataset, mitigates overfitting due to instance repetition, and enables sharper distinctions in comparative model analysis. The method preserves stratification and remains model-agnostic, i.e., compatible with any classifier. Experimental results demonstrate that it delivers consistent performance estimates across diverse datasets --comparable to $k$--fold cross-validation-- while providing less optimistic variance estimates because training partitions are non-overlapping, and significantly reducing the overall computational cost. 

**Abstract (ZH)**: 不可重复的k折交叉验证 

---
# FedSWA: Improving Generalization in Federated Learning with Highly Heterogeneous Data via Momentum-Based Stochastic Controlled Weight Averaging 

**Title (ZH)**: FedSWA：通过动量基于的随机控制权重平均提高异质数据联邦学习的泛化能力 

**Authors**: Liu junkang, Yuanyuan Liu, Fanhua Shang, Hongying Liu, Jin Liu, Wei Feng  

**Link**: [PDF](https://arxiv.org/pdf/2507.20016)  

**Abstract**: For federated learning (FL) algorithms such as FedSAM, their generalization capability is crucial for real-word applications. In this paper, we revisit the generalization problem in FL and investigate the impact of data heterogeneity on FL generalization. We find that FedSAM usually performs worse than FedAvg in the case of highly heterogeneous data, and thus propose a novel and effective federated learning algorithm with Stochastic Weight Averaging (called \texttt{FedSWA}), which aims to find flatter minima in the setting of highly heterogeneous data. Moreover, we introduce a new momentum-based stochastic controlled weight averaging FL algorithm (\texttt{FedMoSWA}), which is designed to better align local and global models.
Theoretically, we provide both convergence analysis and generalization bounds for \texttt{FedSWA} and \texttt{FedMoSWA}. We also prove that the optimization and generalization errors of \texttt{FedMoSWA} are smaller than those of their counterparts, including FedSAM and its variants. Empirically, experimental results on CIFAR10/100 and Tiny ImageNet demonstrate the superiority of the proposed algorithms compared to their counterparts. Open source code at: this https URL. 

**Abstract (ZH)**: 对于像FedSAM这样的联邦学习（FL）算法，其泛化能力对于实际应用至关重要。本文重新审视了FL中的泛化问题，并探讨了数据异质性对FL泛化的影响。我们发现，在高度异质性数据的情况下，FedSAM的表现通常不如FedAvg，因此提出了一种新的有效联邦学习算法（结合了Stochastic Weight Averaging，称为FedSWA），旨在在高度异质性数据的设定下寻找更平滑的最小值。此外，我们引入了一种基于动量的随机控制权重平均联邦学习算法（称为FedMoSWA），旨在更好地对齐局部模型和全局模型。从理论上，我们为FedSWA和FedMoSWA提供了收敛分析和泛化界。我们还证明了FedMoSWA的优化和泛化误差小于其对应的算法，包括FedSAM及其变体。实验结果表明，所提出的算法在CIFAR10/100和Tiny ImageNet上的表现优于其对应的算法。开源代码见：this https URL。 

---
# Policy-Driven AI in Dataspaces: Taxonomy, Explainability, and Pathways for Compliant Innovation 

**Title (ZH)**: 数据空间中基于政策的AI：分类、可解释性及合规创新路径 

**Authors**: Joydeep Chandra, Satyam Kumar Navneet  

**Link**: [PDF](https://arxiv.org/pdf/2507.20014)  

**Abstract**: As AI-driven dataspaces become integral to data sharing and collaborative analytics, ensuring privacy, performance, and policy compliance presents significant challenges. This paper provides a comprehensive review of privacy-preserving and policy-aware AI techniques, including Federated Learning, Differential Privacy, Trusted Execution Environments, Homomorphic Encryption, and Secure Multi-Party Computation, alongside strategies for aligning AI with regulatory frameworks such as GDPR and the EU AI Act. We propose a novel taxonomy to classify these techniques based on privacy levels, performance impacts, and compliance complexity, offering a clear framework for practitioners and researchers to navigate trade-offs. Key performance metrics -- latency, throughput, cost overhead, model utility, fairness, and explainability -- are analyzed to highlight the multi-dimensional optimization required in dataspaces. The paper identifies critical research gaps, including the lack of standardized privacy-performance KPIs, challenges in explainable AI for federated ecosystems, and semantic policy enforcement amidst regulatory fragmentation. Future directions are outlined, proposing a conceptual framework for policy-driven alignment, automated compliance validation, standardized benchmarking, and integration with European initiatives like GAIA-X, IDS, and Eclipse EDC. By synthesizing technical, ethical, and regulatory perspectives, this work lays the groundwork for developing trustworthy, efficient, and compliant AI systems in dataspaces, fostering innovation in secure and responsible data-driven ecosystems. 

**Abstract (ZH)**: AI驱动的数据空间中的隐私保护与政策意识智能技术综述：面向信任、效率与合规的路径探索 

---
# Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of GAT, TimesNet, and XGBoost 

**Title (ZH)**: 在噪声条件下稳健的出租车 fare 预测：GAT、TimesNet 和 XGBoost 的对比研究 

**Authors**: Padmavathi Moorthy  

**Link**: [PDF](https://arxiv.org/pdf/2507.20008)  

**Abstract**: Precise fare prediction is crucial in ride-hailing platforms and urban mobility systems. This study examines three machine learning models-Graph Attention Networks (GAT), XGBoost, and TimesNet to evaluate their predictive capabilities for taxi fares using a real-world dataset comprising over 55 million records. Both raw (noisy) and denoised versions of the dataset are analyzed to assess the impact of data quality on model performance. The study evaluated the models along multiple axes, including predictive accuracy, calibration, uncertainty estimation, out-of-distribution (OOD) robustness, and feature sensitivity. We also explore pre-processing strategies, including KNN imputation, Gaussian noise injection, and autoencoder-based denoising. The study reveals critical differences between classical and deep learning models under realistic conditions, offering practical guidelines for building robust and scalable models in urban fare prediction systems. 

**Abstract (ZH)**: 精确的 fare 预测对于网约车平台和城市出行系统至关重要。本研究探讨了三种机器学习模型——图注意网络（GAT）、XGBoost 和 TimesNet，在使用包含超过 5500 万条记录的真实数据集评估其对出租车 fare 的预测能力方面的表现。研究分析了原始（嘈杂）和去噪后的数据集，以评估数据质量对模型性能的影响。本研究从预测准确性、校准、不确定性估计、离域（OOD）稳健性和特征敏感性等多方面评估了这些模型。此外，研究还探讨了预处理策略，包括 KNN 插值、高斯噪声注入和基于自编码器的去噪。研究揭示了在实际条件下经典模型与深度学习模型之间的关键差异，并为在城市 fare 预测系统中构建稳健和可扩展的模型提供了实用指南。 

---
# VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering 

**Title (ZH)**: VLQA：首个全面、大规模且高质量的越南语法律问答数据集 

**Authors**: Tan-Minh Nguyen, Hoang-Trung Nguyen, Trong-Khoi Dao, Xuan-Hieu Phan, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong  

**Link**: [PDF](https://arxiv.org/pdf/2507.19995)  

**Abstract**: The advent of large language models (LLMs) has led to significant achievements in various domains, including legal text processing. Leveraging LLMs for legal tasks is a natural evolution and an increasingly compelling choice. However, their capabilities are often portrayed as greater than they truly are. Despite the progress, we are still far from the ultimate goal of fully automating legal tasks using artificial intelligence (AI) and natural language processing (NLP). Moreover, legal systems are deeply domain-specific and exhibit substantial variation across different countries and languages. The need for building legal text processing applications for different natural languages is, therefore, large and urgent. However, there is a big challenge for legal NLP in low-resource languages such as Vietnamese due to the scarcity of resources and annotated data. The need for labeled legal corpora for supervised training, validation, and supervised fine-tuning is critical. In this paper, we introduce the VLQA dataset, a comprehensive and high-quality resource tailored for the Vietnamese legal domain. We also conduct a comprehensive statistical analysis of the dataset and evaluate its effectiveness through experiments with state-of-the-art models on legal information retrieval and question-answering tasks. 

**Abstract (ZH)**: 大型语言模型的兴起在各个领域取得了显著成就，包括法律文本处理。利用大型语言模型进行法律任务是自然演进和日益有吸引力的选择。然而，它们的能力往往被夸大。尽管有所进展，我们仍然远未达到完全利用人工智能和自然语言处理自动化法律任务的目标。此外，法律体系高度特定于特定领域，并且在不同国家和语言之间存在显著差异。因此，根据不同自然语言构建法律文本处理应用程序的需求十分迫切和紧急。然而，法律自然语言处理在低资源语言如越南语中面临重大挑战，原因是资源和标注数据稀缺。构建监督训练、验证和微调所需的标记法律语料库至关重要。本文介绍了VLQA数据集，这是一个专为越南法律领域设计的全面且高质量的资源。我们还对数据集进行了全面的统计分析，并通过使用最新模型在法律信息检索和问答任务中的实验评估了其有效性。 

---
# NIRS: An Ontology for Non-Invasive Respiratory Support in Acute Care 

**Title (ZH)**: NIRS: 一种无创呼吸支持的本体论 

**Authors**: Md Fantacher Islam, Jarrod Mosier, Vignesh Subbian  

**Link**: [PDF](https://arxiv.org/pdf/2507.19992)  

**Abstract**: Objective: Develop a Non Invasive Respiratory Support (NIRS) ontology to support knowledge representation in acute care settings.
Materials and Methods: We developed the NIRS ontology using Web Ontology Language (OWL) semantics and Protege to organize clinical concepts and relationships. To enable rule-based clinical reasoning beyond hierarchical structures, we added Semantic Web Rule Language (SWRL) rules. We evaluated logical reasoning by adding 17 hypothetical patient clinical scenarios. We used SPARQL queries and data from the Electronic Intensive Care Unit (eICU) Collaborative Research Database to retrieve and test targeted inferences.
Results: The ontology has 132 classes, 12 object properties, and 17 data properties across 882 axioms that establish concept relationships. To standardize clinical concepts, we added 350 annotations, including descriptive definitions based on controlled vocabularies. SPARQL queries successfully validated all test cases (rules) by retrieving appropriate patient outcomes, for instance, a patient treated with HFNC (high-flow nasal cannula) for 2 hours due to acute respiratory failure may avoid endotracheal intubation.
Discussion: The NIRS ontology formally represents domain-specific concepts, including ventilation modalities, patient characteristics, therapy parameters, and outcomes. SPARQL query evaluations on clinical scenarios confirmed the ability of the ontology to support rule based reasoning and therapy recommendations, providing a foundation for consistent documentation practices, integration into clinical data models, and advanced analysis of NIRS outcomes.
Conclusion: We unified NIRS concepts into an ontological framework and demonstrated its applicability through the evaluation of hypothetical patient scenarios and alignment with standardized vocabularies. 

**Abstract (ZH)**: 目标: 开发非侵入性呼吸支持(NIRS)本体以支持急性护理环境中知识表示。 

---
# Dimer-Enhanced Optimization: A First-Order Approach to Escaping Saddle Points in Neural Network Training 

**Title (ZH)**: 二聚体增强优化：神经网络训练中逃逸鞍点的首阶方法 

**Authors**: Yue Hu, Zanxia Cao, Yingchao Liu  

**Link**: [PDF](https://arxiv.org/pdf/2507.19968)  

**Abstract**: First-order optimization methods, such as SGD and Adam, are widely used for training large-scale deep neural networks due to their computational efficiency and robust performance. However, relying solely on gradient information, these methods often struggle to navigate complex loss landscapes with flat regions, plateaus, and saddle points. Second-order methods, which use curvature information from the Hessian matrix, can address these challenges but are computationally infeasible for large models. The Dimer method, a first-order technique that constructs two closely spaced points to probe the local geometry of a potential energy surface, efficiently estimates curvature using only gradient information. Inspired by its use in molecular dynamics simulations for locating saddle points, we propose Dimer-Enhanced Optimization (DEO), a novel framework to escape saddle points in neural network training. DEO adapts the Dimer method to explore a broader region of the loss landscape, approximating the Hessian's smallest eigenvector without computing the full matrix. By periodically projecting the gradient onto the subspace orthogonal to the minimum curvature direction, DEO guides the optimizer away from saddle points and flat regions, enhancing training efficiency with non-stepwise updates. Preliminary experiments on a Transformer toy model show DEO achieves competitive performance compared to standard first-order methods, improving navigation of complex loss landscapes. Our work repurposes physics-inspired, first-order curvature estimation to enhance neural network training in high-dimensional spaces. 

**Abstract (ZH)**: 基于一阶优化方法，如SGD和Adam，广泛用于训练大规模深度神经网络，因其计算效率和鲁棒性能。然而，这些方法仅依赖梯度信息，在复杂损失landscape中的平坦区域、平台和鞍点区域导航时常常力不从心。二阶方法利用海森矩阵的曲率信息可以解决这些问题，但对大型模型而言计算上行不通。Dimer方法是一种基于一阶技术，通过构建两个紧密间隔的点以探索潜在能量面上的局部几何结构，仅使用梯度信息高效估计曲率。受其在分子动力学模拟中用于定位鞍点的启发，我们提出了Dimer增强优化（DEO）框架，旨在神经网络训练中逃逸鞍点。DEO将Dimer方法适应性地扩展到探索损失landscape的更广阔区域，无需计算整个海森矩阵即可近似海森矩阵的最小特征向量。通过周期性地将梯度投影到曲率最小方向的正交子空间，DEO引导优化器远离鞍点和平坦区域，通过非梯度更新方式增强训练效率。初步实验显示，DEO在Transformer玩具模型上的表现与标准一阶方法相当，提高了复杂损失landscape的导航能力。我们的研究将物理启发的一阶曲率估计方法重新应用于高维空间中的神经网络训练中。 

---
# Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems 

**Title (ZH)**: 基于深度学习的稀疏XL-MIMO OFDM系统信道估计与定位联合方法 

**Authors**: Zhongnian Li, Chao Zheng, Jian Xiao, Ji Wang, Gongpu Wang, Ming Zeng, Octavia A. Dobre  

**Link**: [PDF](https://arxiv.org/pdf/2507.19936)  

**Abstract**: This paper investigates joint channel estimation and positioning in near-field sparse extra-large multiple-input multiple-output (XL-MIMO) orthogonal frequency division multiplexing (OFDM) systems. To achieve cooperative gains between channel estimation and positioning, we propose a deep learning-based two-stage framework comprising positioning and channel estimation. In the positioning stage, the user's coordinates are predicted and utilized in the channel estimation stage, thereby enhancing the accuracy of channel estimation. Within this framework, we propose a U-shaped Mamba architecture for channel estimation and positioning, termed as CP-Mamba. This network integrates the strengths of the Mamba model with the structural advantages of U-shaped convolutional networks, enabling effective capture of local spatial features and long-range temporal dependencies of the channel. Numerical simulation results demonstrate that the proposed two-stage approach with CP-Mamba architecture outperforms existing baseline methods. Moreover, sparse arrays (SA) exhibit significantly superior performance in both channel estimation and positioning accuracy compared to conventional compact arrays. 

**Abstract (ZH)**: 基于近场稀疏超大规模多输入多输出(XL-MIMO)正交频率分组多载波系统中的联合信道估计算法与定位研究 

---
# DynamiX: Large-Scale Dynamic Social Network Simulator 

**Title (ZH)**: DynamiX：大规模动态社会网络模拟器 

**Authors**: Yanhui Sun, Wu Liu, Wentao Wang, Hantao Yao, Jiebo Luo, Yongdong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.19929)  

**Abstract**: Understanding the intrinsic mechanisms of social platforms is an urgent demand to maintain social stability. The rise of large language models provides significant potential for social network simulations to capture attitude dynamics and reproduce collective behaviors. However, existing studies mainly focus on scaling up agent populations, neglecting the dynamic evolution of social relationships. To address this gap, we introduce DynamiX, a novel large-scale social network simulator dedicated to dynamic social network modeling. DynamiX uses a dynamic hierarchy module for selecting core agents with key characteristics at each timestep, enabling accurate alignment of real-world adaptive switching of user roles. Furthermore, we design distinct dynamic social relationship modeling strategies for different user types. For opinion leaders, we propose an information-stream-based link prediction method recommending potential users with similar stances, simulating homogeneous connections, and autonomous behavior decisions. For ordinary users, we construct an inequality-oriented behavior decision-making module, effectively addressing unequal social interactions and capturing the patterns of relationship adjustments driven by multi-dimensional factors. Experimental results demonstrate that DynamiX exhibits marked improvements in attitude evolution simulation and collective behavior analysis compared to static networks. Besides, DynamiX opens a new theoretical perspective on follower growth prediction, providing empirical evidence for opinion leaders cultivation. 

**Abstract (ZH)**: 理解社交平台的内在机制以维护社会稳定是一个迫切的需求。大型语言模型的兴起为社交网络仿真捕捉态度动态和再现集体行为提供了重要潜力。然而，现有研究主要集中在扩展代理人群体上，忽略了社交关系的动态演变。为解决这一问题，我们引入了DynamiX，这是一种新型的大规模社交网络仿真器，专注于动态社会网络建模。DynamiX采用动态层次模块，在每个时间步长选择具有关键特征的核心代理，以准确对齐用户角色的现实适应性切换。此外，我们为不同用户类型设计了独特的动态社交关系建模策略。对于意见领袖，我们提出了基于信息流的链接预测方法，推荐立场相似的潜在用户，模拟同质连接，并模拟自主行为决策。对于普通用户，我们构建了一个以不平等为导向的行为决策模块，有效解决了不平等的社会互动问题，并捕捉了由多维因素驱动的关系调整模式。实验结果表明，DynamiX在态度演变仿真和集体行为分析方面相较于静态网络具有显著改进。此外，DynamiX为追随者增长预测提供了一个新的理论视角，并提供了意见领袖培养的实证证据。 

---
# A mini-batch training strategy for deep subspace clustering networks 

**Title (ZH)**: 小批量训练策略用于深子空间聚类网络 

**Authors**: Yuxuan Jiang, Chenwei Yu, Zhi Lin, Xiaolan Liu  

**Link**: [PDF](https://arxiv.org/pdf/2507.19917)  

**Abstract**: Mini-batch training is a cornerstone of modern deep learning, offering computational efficiency and scalability for training complex architectures. However, existing deep subspace clustering (DSC) methods, which typically combine an autoencoder with a self-expressive layer, rely on full-batch processing. The bottleneck arises from the self-expressive module, which requires representations of the entire dataset to construct a self-representation coefficient matrix. In this work, we introduce a mini-batch training strategy for DSC by integrating a memory bank that preserves global feature representations. Our approach enables scalable training of deep architectures for subspace clustering with high-resolution images, overcoming previous limitations. Additionally, to efficiently fine-tune large-scale pre-trained encoders for subspace clustering, we propose a decoder-free framework that leverages contrastive learning instead of autoencoding for representation learning. This design not only eliminates the computational overhead of decoder training but also provides competitive performance. Extensive experiments demonstrate that our approach not only achieves performance comparable to full-batch methods, but outperforms other state-of-the-art subspace clustering methods on the COIL100 and ORL datasets by fine-tuning deep networks. 

**Abstract (ZH)**: mini-batch训练是一种现代深度学习的基石，提供了训练复杂架构的计算效率和可扩展性。然而，现有的深度子空间聚类（DSC）方法通常将自动编码器与自表达层结合起来，依赖于全批次处理。瓶颈在于自表达模块，它需要整个数据集的表示来构建自表示系数矩阵。在此工作中，我们通过集成一个记忆库来为DSC引入mini-batch训练策略，该记忆库保留全局特征表示。我们的方法使得使用高分辨率图像对子空间聚类的深度架构进行可扩展训练，克服了之前的方法限制。此外，为了高效地微调大规模预训练编码器进行子空间聚类，我们提出了一种无解码器框架，利用对比学习而非自动编码进行表征学习。这种设计不仅消除了解码器训练的计算开销，而且还提供了竞争力的表现。广泛实验表明，我们的方法不仅在性能上与全批次方法相当，还在COIL100和ORL数据集上通过微调深度网络优于其他最先进的子空间聚类方法。 

---
# TS-Insight: Visualizing Thompson Sampling for Verification and XAI 

**Title (ZH)**: TS-Insight: Visualizing Thompson Sampling for Verification and XAI 的中文标题为：

TS-Insight: Thompson Sampling的可视化在验证和可解释人工智能中的应用 

**Authors**: Parsa Vares, Éloi Durant, Jun Pang, Nicolas Médoc, Mohammad Ghoniem  

**Link**: [PDF](https://arxiv.org/pdf/2507.19898)  

**Abstract**: Thompson Sampling (TS) and its variants are powerful Multi-Armed Bandit algorithms used to balance exploration and exploitation strategies in active learning. Yet, their probabilistic nature often turns them into a ``black box'', hindering debugging and trust. We introduce TS-Insight, a visual analytics tool explicitly designed to shed light on the internal decision mechanisms of Thompson Sampling-based algorithms, for model developers. It comprises multiple plots, tracing for each arm the evolving posteriors, evidence counts, and sampling outcomes, enabling the verification, diagnosis, and explainability of exploration/exploitation dynamics. This tool aims at fostering trust and facilitating effective debugging and deployment in complex binary decision-making scenarios especially in sensitive domains requiring interpretable decision-making. 

**Abstract (ZH)**: Thomas采样（TS）及其变体是用于平衡活跃学习中探索与利用策略的多臂 bandit 算法。然而，它们的概率性质往往使它们成为“黑盒”，妨碍调试和信任。我们引入了 TS-Insight，一个专门为模型开发者设计的可视化分析工具，旨在阐明基于 Thomas 采样算法的内部决策机制。该工具包含多个图表，跟踪每个臂的后验分布、证据计数和抽样结果，从而实现探索/利用动态的验证、诊断和解释。该工具旨在增强信任并促进复杂二元决策场景中的有效调试和部署，特别是在需要可解释决策的敏感领域。 

---
# FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving 

**Title (ZH)**: FedS2R: 一键式 federated 领域泛化方法用于自主驾驶中的合成-to-真实语义分割 

**Authors**: Tao Lian, Jose L. Gómez, Antonio M. López  

**Link**: [PDF](https://arxiv.org/pdf/2507.19881)  

**Abstract**: Federated domain generalization has shown promising progress in image classification by enabling collaborative training across multiple clients without sharing raw data. However, its potential in the semantic segmentation of autonomous driving remains underexplored. In this paper, we propose FedS2R, the first one-shot federated domain generalization framework for synthetic-to-real semantic segmentation in autonomous driving. FedS2R comprises two components: an inconsistency-driven data augmentation strategy that generates images for unstable classes, and a multi-client knowledge distillation scheme with feature fusion that distills a global model from multiple client models. Experiments on five real-world datasets, Cityscapes, BDD100K, Mapillary, IDD, and ACDC, show that the global model significantly outperforms individual client models and is only 2 mIoU points behind the model trained with simultaneous access to all client data. These results demonstrate the effectiveness of FedS2R in synthetic-to-real semantic segmentation for autonomous driving under federated learning 

**Abstract (ZH)**: 联邦域泛化在自动驾驶语义分割中的单次联邦域泛化框架FedS2R 

---
# Trivial Trojans: How Minimal MCP Servers Enable Cross-Tool Exfiltration of Sensitive Data 

**Title (ZH)**: 微不足道的木马：最小化MCP服务器如何实现跨工具敏感数据泄露 

**Authors**: Nicola Croce, Tobin South  

**Link**: [PDF](https://arxiv.org/pdf/2507.19880)  

**Abstract**: The Model Context Protocol (MCP) represents a significant advancement in AI-tool integration, enabling seamless communication between AI agents and external services. However, this connectivity introduces novel attack vectors that remain largely unexplored. This paper demonstrates how unsophisticated threat actors, requiring only basic programming skills and free web tools, can exploit MCP's trust model to exfiltrate sensitive financial data. We present a proof-of-concept attack where a malicious weather MCP server, disguised as benign functionality, discovers and exploits legitimate banking tools to steal user account balances. The attack chain requires no advanced technical knowledge, server infrastructure, or monetary investment. The findings reveal a critical security gap in the emerging MCP ecosystem: while individual servers may appear trustworthy, their combination creates unexpected cross-server attack surfaces. Unlike traditional cybersecurity threats that assume sophisticated adversaries, our research shows that the barrier to entry for MCP-based attacks is alarmingly low. A threat actor with undergraduate-level Python knowledge can craft convincing social engineering attacks that exploit the implicit trust relationships MCP establishes between AI agents and tool providers. This work contributes to the nascent field of MCP security by demonstrating that current MCP implementations allow trivial cross-server attacks and proposing both immediate mitigations and protocol improvements to secure this emerging ecosystem. 

**Abstract (ZH)**: MCP安全研究：新兴MCP生态系统中的简单跨服务器攻击 

---
# VAE-GAN Based Price Manipulation in Coordinated Local Energy Markets 

**Title (ZH)**: 基于VAE-GAN的价格操纵在协调本地能源市场中 

**Authors**: Biswarup Mukherjee, Li Zhou, S. Gokul Krishnan, Milad Kabirifar, Subhash Lakshminarayana, Charalambos Konstantinou  

**Link**: [PDF](https://arxiv.org/pdf/2507.19844)  

**Abstract**: This paper introduces a model for coordinating prosumers with heterogeneous distributed energy resources (DERs), participating in the local energy market (LEM) that interacts with the market-clearing entity. The proposed LEM scheme utilizes a data-driven, model-free reinforcement learning approach based on the multi-agent deep deterministic policy gradient (MADDPG) framework, enabling prosumers to make real-time decisions on whether to buy, sell, or refrain from any action while facilitating efficient coordination for optimal energy trading in a dynamic market. In addition, we investigate a price manipulation strategy using a variational auto encoder-generative adversarial network (VAE-GAN) model, which allows utilities to adjust price signals in a way that induces financial losses for the prosumers. Our results show that under adversarial pricing, heterogeneous prosumer groups, particularly those lacking generation capabilities, incur financial losses. The same outcome holds across LEMs of different sizes. As the market size increases, trading stabilizes and fairness improves through emergent cooperation among agents. 

**Abstract (ZH)**: 本文提出了一种协调具有异质分布式能源资源的产消者模型，使其能够参与与市场出清实体互动的本地能源市场（LEM）。提出的LEM方案基于多代理深度确定性策略Gradient（MADDPG）框架，采用数据驱动、无模型强化学习方法，使产消者能够实时决定是否买入、卖出或不采取任何行动，从而在动态市场中实现高效协调和优化能源交易。此外，本文还探讨了一种使用变分自动编码器生成对抗网络（VAE-GAN）模型的价格操纵策略，该策略使供电公司能够以诱导产消者财务损失的方式调整价格信号。结果显示，在对抗性定价下，尤其是缺乏发电能力的异质产消者群体会遭受财务损失。这一结果在不同规模的LEM中保持一致。随着市场规模的扩大，交易趋于稳定，公平性通过代理之间自发的合作而提高。 

---
# A Cooperative Approach for Knowledge-based Business Process Design in a Public Authority 

**Title (ZH)**: 基于知识的合作式公共机构业务流程设计方法 

**Authors**: Mohammad Azarijafari, Luisa Mich, Michele Missikoff, Oleg Missikoff  

**Link**: [PDF](https://arxiv.org/pdf/2507.19842)  

**Abstract**: Enterprises are currently undergoing profound transformations due to the unpostponable digital transformation. Then, to remain competitive, enterprises must adapt their organisational structures and operations. This organisational shift is also important for small and medium-sized enterprises. A key innovation frontier is the adoption of process-oriented production models. This paper presents a knowledge-based method to support business experts in designing business processes. The method requires no prior expertise in Knowledge Engineering and guides designers through a structured sequence of steps to produce a diagrammatic workflow of the target process. The construction of the knowledge base starts from simple, text-based, knowledge artefacts and then progresses towards more structured, formal representations. The approach has been conceived to allow a shared approach for all stakeholders and actors who participate in the BP design. 

**Abstract (ZH)**: 企业正经历不可推迟的数字化转型，从而引发深刻变革。为了保持竞争力，企业必须适应其组织结构和运营。这一组织变革对于中小企业也同样重要。一个关键的创新前沿是采用面向过程的生产模型。本文提出了一种基于知识的方法，以支持业务专家设计业务流程。该方法无需任何先验的知识工程知识，并引导设计者通过结构化的步骤序列来生成目标过程的图示工作流。知识库的构建从简单的文本知识 artefacts 开始，逐步发展到更结构化、形式化的表示。该方法旨在让所有参与 BP 设计的利益相关者和参与者能够共享这一方法。 

---
# AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition 

**Title (ZH)**: AutoSign: 直接姿态到文本的翻译用于连续手语识别 

**Authors**: Samuel Ebimobowei Johnny, Blessed Guda, Andrew Blayama Stephen, Assane Gueye  

**Link**: [PDF](https://arxiv.org/pdf/2507.19840)  

**Abstract**: Continuously recognizing sign gestures and converting them to glosses plays a key role in bridging the gap between the hearing and hearing-impaired communities. This involves recognizing and interpreting the hands, face, and body gestures of the signer, which pose a challenge as it involves a combination of all these features. Continuous Sign Language Recognition (CSLR) methods rely on multi-stage pipelines that first extract visual features, then align variable-length sequences with target glosses using CTC or HMM-based approaches. However, these alignment-based methods suffer from error propagation across stages, overfitting, and struggle with vocabulary scalability due to the intermediate gloss representation bottleneck. To address these limitations, we propose AutoSign, an autoregressive decoder-only transformer that directly translates pose sequences to natural language text, bypassing traditional alignment mechanisms entirely. The use of this decoder-only approach allows the model to directly map between the features and the glosses without the need for CTC loss while also directly learning the textual dependencies in the glosses. Our approach incorporates a temporal compression module using 1D CNNs to efficiently process pose sequences, followed by AraGPT2, a pre-trained Arabic decoder, to generate text (glosses). Through comprehensive ablation studies, we demonstrate that hand and body gestures provide the most discriminative features for signer-independent CSLR. By eliminating the multi-stage pipeline, AutoSign achieves substantial improvements on the Isharah-1000 dataset, achieving an improvement of up to 6.1\% in WER score compared to the best existing method. 

**Abstract (ZH)**: 连续识别手语手势并将其转换为手语词汇在填补听力与听力受损社区之间的差距中起着关键作用。这一过程涉及识别和解释手语者的手、面部和身体手势，这对连续手语识别（CSLR）方法构成了挑战，因为它需要处理这些特征的组合。连续手语识别方法依赖于多阶段管道，首先提取视觉特征，然后使用CTC或HMM方法对不同长度的序列与目标手语词汇进行对齐。然而，这些基于对齐的方法容易出现误差传播、过拟合，并且由于中间手语词汇表示瓶颈，在词汇量扩张方面存在问题。为了解决这些限制，我们提出了AutoSign，一种自回归解码器型变压器，可以直接将姿态序列翻译为自然语言文本，完全绕过了传统的对齐机制。使用这种解码器型方法，模型可以直接在特征和手语词汇之间建立映射，无需CTC损失，同时直接学习手语词汇中的文本依赖关系。我们的方法采用了一种使用1D CNN的时序压缩模块，以高效处理姿态序列，随后使用预训练的阿拉伯语解码器AraGPT2生成文本（手语词汇）。通过全面的消融研究，我们证明了手部和身体手势为独立于手语者的目标手上提供了最具区分性的特征。通过消除多阶段管道，AutoSign在Isharah-1000数据集中实现了显著的改进，相较于现有最佳方法，词错误率（WER）分数提高了6.1%。 

---
# From Few-Label to Zero-Label: An Approach for Cross-System Log-Based Anomaly Detection with Meta-Learning 

**Title (ZH)**: 从少量标签到零标签：一种基于元学习的日志跨系统异常检测方法 

**Authors**: Xinlong Zhao, Tong Jia, Minghua He, Yihan Wu, Ying Li, Gang Huang  

**Link**: [PDF](https://arxiv.org/pdf/2507.19806)  

**Abstract**: Log anomaly detection plays a critical role in ensuring the stability and reliability of software systems. However, existing approaches rely on large amounts of labeled log data, which poses significant challenges in real-world applications. To address this issue, cross-system transfer has been identified as a key research direction. State-of-the-art cross-system approaches achieve promising performance with only a few labels from the target system. However, their reliance on labeled target logs makes them susceptible to the cold-start problem when labeled logs are insufficient. To overcome this limitation, we explore a novel yet underexplored setting: zero-label cross-system log anomaly detection, where the target system logs are entirely unlabeled. To this end, we propose FreeLog, a system-agnostic representation meta-learning method that eliminates the need for labeled target system logs, enabling cross-system log anomaly detection under zero-label conditions. Experimental results on three public log datasets demonstrate that FreeLog achieves performance comparable to state-of-the-art methods that rely on a small amount of labeled data from the target system. 

**Abstract (ZH)**: 无标签跨系统日志异常检测在确保软件系统稳定性和可靠性中发挥关键作用。现有的方法依赖大量标注日志数据，这在实际应用中提出了重大挑战。为解决这一问题，跨系统迁移已成为关键研究方向。最先进的跨系统方法仅依靠目标系统少量标注日志就能取得令人鼓舞的性能。然而，它们对目标系统标注日志的依赖性使其在标注日志不足时面临冷启动问题。为克服这一局限性，我们探索了一个新颖且尚未充分研究的设置：无标签跨系统日志异常检测，其中目标系统日志完全未标注。为此，我们提出FreeLog，一个系统无关的表示元学习方法，无需目标系统标注日志即可实现无标签跨系统日志异常检测。在三个公开的日志数据集上的实验结果表明，FreeLog 在性能上与依赖目标系统少量标注数据的最先进方法相当。 

---
# AI-Based Clinical Rule Discovery for NMIBC Recurrence through Tsetlin Machines 

**Title (ZH)**: 基于Tsetlin机的AI临床规则发现用于NMIBC复发 

**Authors**: Saram Abbas, Naeem Soomro, Rishad Shafik, Rakesh Heer, Kabita Adhikari  

**Link**: [PDF](https://arxiv.org/pdf/2507.19803)  

**Abstract**: Bladder cancer claims one life every 3 minutes worldwide. Most patients are diagnosed with non-muscle-invasive bladder cancer (NMIBC), yet up to 70% recur after treatment, triggering a relentless cycle of surgeries, monitoring, and risk of progression. Clinical tools like the EORTC risk tables are outdated and unreliable - especially for intermediate-risk cases.
We propose an interpretable AI model using the Tsetlin Machine (TM), a symbolic learner that outputs transparent, human-readable logic. Tested on the PHOTO trial dataset (n=330), TM achieved an F1-score of 0.80, outperforming XGBoost (0.78), Logistic Regression (0.60), and EORTC (0.42). TM reveals the exact clauses behind each prediction, grounded in clinical features like tumour count, surgeon experience, and hospital stay - offering accuracy and full transparency. This makes TM a powerful, trustworthy decision-support tool ready for real-world adoption. 

**Abstract (ZH)**: 全球每3分钟就有1人因膀胱癌去世。大多数患者被诊断为非肌层浸润性膀胱癌（NMIBC），但多达70%的患者在接受治疗后会出现复发，导致持续的手术循环、监测和疾病进展的风险。临床工具如EORTC风险表已过时且不可靠，尤其是在处理中等风险病例时。
我们提出了一种基于Tsetlin机（TM）的可解释人工智能模型，Tsetlin机是一种符号学习器，输出透明且易于理解的逻辑规则。该模型在PHOTO试验数据集（n=330）上测试，F1分数达到了0.80，超过了XGBoost（0.78）、逻辑回归（0.60）和EORTC（0.42）。TM能够揭示每个预测背后的精确语句，这些语句基于临床特征，如肿瘤数量、外科医生经验以及住院时间，从而提供准确性和完全透明度。这使得TM成为一种强大的、值得信赖的决策支持工具，适合实际应用。 

---
# Modeling enzyme temperature stability from sequence segment perspective 

**Title (ZH)**: 从序列片段视角建模酶的温度稳定性 

**Authors**: Ziqi Zhang, Shiheng Chen, Runze Yang, Zhisheng Wei, Wei Zhang, Lei Wang, Zhanzhi Liu, Fengshan Zhang, Jing Wu, Xiaoyong Pan, Hongbin Shen, Longbing Cao, Zhaohong Deng  

**Link**: [PDF](https://arxiv.org/pdf/2507.19755)  

**Abstract**: Developing enzymes with desired thermal properties is crucial for a wide range of industrial and research applications, and determining temperature stability is an essential step in this process. Experimental determination of thermal parameters is labor-intensive, time-consuming, and costly. Moreover, existing computational approaches are often hindered by limited data availability and imbalanced distributions. To address these challenges, we introduce a curated temperature stability dataset designed for model development and benchmarking in enzyme thermal modeling. Leveraging this dataset, we present the \textit{Segment Transformer}, a novel deep learning framework that enables efficient and accurate prediction of enzyme temperature stability. The model achieves state-of-the-art performance with an RMSE of 24.03, MAE of 18.09, and Pearson and Spearman correlations of 0.33, respectively. These results highlight the effectiveness of incorporating segment-level representations, grounded in the biological observation that different regions of a protein sequence contribute unequally to thermal behavior. As a proof of concept, we applied the Segment Transformer to guide the engineering of a cutinase enzyme. Experimental validation demonstrated a 1.64-fold improvement in relative activity following heat treatment, achieved through only 17 mutations and without compromising catalytic function. 

**Abstract (ZH)**: 开发具有desired thermal properties的酶对于广泛的应用领域至关重要，确定温度稳定性是这一过程中的一个关键步骤。实验测定热参数劳动密集、耗时且成本高。此外，现有的计算方法往往受限于数据可用性的有限以及数据分布的不平衡。为了解决这些挑战，我们引入了一个精心编撰的温度稳定性数据集，该数据集适用于酶热学建模的模型开发和基准测试。基于该数据集，我们提出了一种名为\textit{Segment Transformer}的新型深度学习框架，该框架能够高效且准确地预测酶的温度稳定性。该模型在均方根误差(RMSE)为24.03，平均绝对误差(RMAE)为18.09，皮尔逊相关系数和 SPEARMAN相关系数分别为0.33的情况下达到了业界最佳性能。这些结果突显了在模型中纳入段级表示的有效性，这基于生物学观察，即蛋白质序列的不同区域对热行为的贡献是不均等的。作为概念验证，我们应用\textit{Segment Transformer}来指导切割酶的工程改造。实验验证表明，通过仅17个突变并在不损害催化功能的情况下，热处理后相对活性提高了1.64倍。 

---
# Defining ethically sourced code generation 

**Title (ZH)**: 定义伦理采集的代码生成 

**Authors**: Zhuolin Xu, Chenglin Li, Qiushi Li, Shin Hwei Tan  

**Link**: [PDF](https://arxiv.org/pdf/2507.19743)  

**Abstract**: Several code generation models have been proposed to help reduce time and effort in solving software-related tasks. To ensure responsible AI, there are growing interests over various ethical issues (e.g., unclear licensing, privacy, fairness, and environment impact). These studies have the overarching goal of ensuring ethically sourced generation, which has gained growing attentions in speech synthesis and image generation. In this paper, we introduce the novel notion of Ethically Sourced Code Generation (ES-CodeGen) to refer to managing all processes involved in code generation model development from data collection to post-deployment via ethical and sustainable practices. To build a taxonomy of ES-CodeGen, we perform a two-phase literature review where we read 803 papers across various domains and specific to AI-based code generation. We identified 71 relevant papers with 10 initial dimensions of ES-CodeGen. To refine our dimensions and gain insights on consequences of ES-CodeGen, we surveyed 32 practitioners, which include six developers who submitted GitHub issues to opt-out from the Stack dataset (these impacted users have real-world experience of ethically sourcing issues in code generation models). The results lead to 11 dimensions of ES-CodeGen with a new dimension on code quality as practitioners have noted its importance. We also identified consequences, artifacts, and stages relevant to ES-CodeGen. Our post-survey reflection showed that most practitioners tend to ignore social-related dimensions despite their importance. Most practitioners either agreed or strongly agreed that our survey help improve their understanding of ES-CodeGen. Our study calls for attentions of various ethical issues towards ES-CodeGen. 

**Abstract (ZH)**: 基于伦理的代码生成（ES-CodeGen）：管理代码生成模型开发全过程的伦理和可持续实践 

---
# Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning 

**Title (ZH)**: Oranits：基于开放RAN的ITS中任务分配与卸载的研究——结合元启发式算法和深度强化学习 

**Authors**: Ngoc Hung Nguyen, Nguyen Van Thieu, Quang-Trung Luu, Anh Tuan Nguyen, Senura Wanasekara, Nguyen Cong Luong, Fatemeh Kavehmadavani, Van-Dinh Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2507.19712)  

**Abstract**: In this paper, we explore mission assignment and task offloading in an Open Radio Access Network (Open RAN)-based intelligent transportation system (ITS), where autonomous vehicles leverage mobile edge computing for efficient processing. Existing studies often overlook the intricate interdependencies between missions and the costs associated with offloading tasks to edge servers, leading to suboptimal decision-making. To bridge this gap, we introduce Oranits, a novel system model that explicitly accounts for mission dependencies and offloading costs while optimizing performance through vehicle cooperation. To achieve this, we propose a twofold optimization approach. First, we develop a metaheuristic-based evolutionary computing algorithm, namely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline for one-slot optimization. Second, we design an enhanced reward-based deep reinforcement learning (DRL) framework, referred to as the Multi-agent Double Deep Q-Network (MA-DDQN), that integrates both multi-agent coordination and multi-action selection mechanisms, significantly reducing mission assignment time and improving adaptability over baseline methods. Extensive simulations reveal that CGG-ARO improves the number of completed missions and overall benefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN achieves even greater improvements of 11.0% in terms of mission completions and 12.5% in terms of the overall benefit. These results highlight the effectiveness of Oranits in enabling faster, more adaptive, and more efficient task processing in dynamic ITS environments. 

**Abstract (ZH)**: 基于Open RAN的智能交通系统中的任务分配与任务卸载研究 

---
# Ultracoarse Equilibria and Ordinal-Folding Dynamics in Operator-Algebraic Models of Infinite Multi-Agent Games 

**Title (ZH)**: 超粗粒度纳什均衡与算子代数模型中序型折叠动力学在无穷多智能体博弈中的应用 

**Authors**: Faruk Alpay, Hamdi Alakkad, Bugra Kilictas, Taylan Alpay  

**Link**: [PDF](https://arxiv.org/pdf/2507.19694)  

**Abstract**: We develop an operator algebraic framework for infinite games with a continuum of agents and prove that regret based learning dynamics governed by a noncommutative continuity equation converge to a unique quantal response equilibrium under mild regularity assumptions. The framework unifies functional analysis, coarse geometry and game theory by assigning to every game a von Neumann algebra that represents collective strategy evolution. A reflective regret operator within this algebra drives the flow of strategy distributions and its fixed point characterises equilibrium. We introduce the ordinal folding index, a computable ordinal valued metric that measures the self referential depth of the dynamics, and show that it bounds the transfinite time needed for convergence, collapsing to zero on coarsely amenable networks. The theory yields new invariant subalgebra rigidity results, establishes existence and uniqueness of envy free and maximin share allocations in continuum economies, and links analytic properties of regret flows with empirical stability phenomena in large language models. These contributions supply a rigorous mathematical foundation for large scale multi agent systems and demonstrate the utility of ordinal metrics for equilibrium selection. 

**Abstract (ZH)**: 我们开发了一种算子代数框架来研究具有连续代理的无限博弈，并证明由非交换连续方程控制的基于遗憾的学习动力学在温和的正则性假设下收敛到唯一的量子反应均衡。该框架通过将每个博弈赋值为一个冯·诺伊曼代数来统合一功能分析、粗几何学和博弈论，该代数代表集体策略演化。该代数中的反射遗憾算子驱动策略分布的流动，其不动点表征均衡。我们引入了序折叠指数，这是一种可计算的序值度量，用于衡量动力学的自我参照深度，并证明它界定了收敛所需的超时，粗 amen 脉络下归零。该理论提供了新的不变子代数刚性结果，确立了连续经济体中无私分配和最大份额分配的存在性和唯一性，并将遗憾流动的分析性质与大型语言模型中的经验稳定性现象联系起来。这些贡献为大规模多代理系统提供了严格的数学基础，并展示了序度量在均衡选择中的实用性。 

---
# KD-GAT: Combining Knowledge Distillation and Graph Attention Transformer for a Controller Area Network Intrusion Detection System 

**Title (ZH)**: KD-GAT: 结合知识蒸馏和图注意力变换器的控制器区域网络入侵检测系统 

**Authors**: Robert Frenken, Sidra Ghayour Bhatti, Hanqin Zhang, Qadeer Ahmed  

**Link**: [PDF](https://arxiv.org/pdf/2507.19686)  

**Abstract**: The Controller Area Network (CAN) protocol is widely adopted for in-vehicle communication but lacks inherent security mechanisms, making it vulnerable to cyberattacks. This paper introduces KD-GAT, an intrusion detection framework that combines Graph Attention Networks (GATs) with knowledge distillation (KD) to enhance detection accuracy while reducing computational complexity. In our approach, CAN traffic is represented as graphs using a sliding window to capture temporal and relational patterns. A multi-layer GAT with jumping knowledge aggregation acting as the teacher model, while a compact student GAT--only 6.32% the size of the teacher--is trained via a two-phase process involving supervised pretraining and knowledge distillation with both soft and hard label supervision. Experiments on three benchmark datasets--Car-Hacking, Car-Survival, and can-train-and-test demonstrate that both teacher and student models achieve strong results, with the student model attaining 99.97% and 99.31% accuracy on Car-Hacking and Car-Survival, respectively. However, significant class imbalance in can-train-and-test has led to reduced performance for both models on this dataset. Addressing this imbalance remains an important direction for future work. 

**Abstract (ZH)**: 基于知识蒸馏的图注意力网络入侵检测框架KD-GAT：应用于车载通信的CAN协议 

---
# "X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems 

**Title (ZH)**: “信息”连续体中的X：下一代网络系统驱动式多维度度量综述 

**Authors**: Beining Wu, Jun Huang, Shui Yu  

**Link**: [PDF](https://arxiv.org/pdf/2507.19657)  

**Abstract**: The development of next-generation networking systems has inherently shifted from throughput-based paradigms towards intelligent, information-aware designs that emphasize the quality, relevance, and utility of transmitted information, rather than sheer data volume. While classical network metrics, such as latency and packet loss, remain significant, they are insufficient to quantify the nuanced information quality requirements of modern intelligent applications, including autonomous vehicles, digital twins, and metaverse environments. In this survey, we present the first comprehensive study of the ``X of Information'' continuum by introducing a systematic four-dimensional taxonomic framework that structures information metrics along temporal, quality/utility, reliability/robustness, and network/communication dimensions. We uncover the increasing interdependencies among these dimensions, whereby temporal freshness triggers quality evaluation, which in turn helps with reliability appraisal, ultimately enabling effective network delivery. Our analysis reveals that artificial intelligence technologies, such as deep reinforcement learning, multi-agent systems, and neural optimization models, enable adaptive, context-aware optimization of competing information quality objectives. In our extensive study of six critical application domains, covering autonomous transportation, industrial IoT, healthcare digital twins, UAV communications, LLM ecosystems, and metaverse settings, we illustrate the revolutionary promise of multi-dimensional information metrics for meeting diverse operational needs. Our survey identifies prominent implementation challenges, including ... 

**Abstract (ZH)**: 下一代网络系统的发展已从根本上从基于吞吐量的范式转向了智能、信息感知的设计，强调传输信息的质量、相关性和实用性，而非单纯的数据量。虽然传统的网络性能指标，如延迟和丢包率依然重要，但它们不足以量化现代智能应用——包括自动驾驶、数字孪生和元宇宙环境——对信息质量的细微需求。在本文综述中，我们首次对“信息连续体”进行了全面研究，通过引入系统的四维分类框架，将信息指标按照时间、质量和实用性、可靠性和鲁棒性、网络和通信维度进行结构化。我们揭示了这些维度之间的不断增强的相互依赖性，其中时间新鲜度触发了质量评估，而质量评估又有助于可靠性评估，最终实现有效的网络交付。我们的分析表明，人工智能技术，如深度强化学习、多智能体系统和神经优化模型，能够实现竞争信息质量目标的自适应和上下文感知优化。在对六个关键应用领域——自动驾驶、工业物联网、医疗数字孪生、无人机通信、预训练语言模型生态系统和元宇宙设置——的广泛研究中，我们展示了多维度信息指标在满足多样化操作需求方面的革命性潜力。我们的综述指出了重要的实施挑战，包括…… 

---
# On the Limitations of Ray-Tracing for Learning-Based RF Tasks in Urban Environments 

**Title (ZH)**: 基于射线追踪技术在城市环境中的无线通信任务学习限制 

**Authors**: Armen Manukyan, Hrant Khachatrian, Edvard Ghukasyan, Theofanis P. Raptis  

**Link**: [PDF](https://arxiv.org/pdf/2507.19653)  

**Abstract**: We study the realism of Sionna v1.0.2 ray-tracing for outdoor cellular links in central Rome. We use a real measurement set of 1,664 user-equipments (UEs) and six nominal base-station (BS) sites. Using these fixed positions we systematically vary the main simulation parameters, including path depth, diffuse/specular/refraction flags, carrier frequency, as well as antenna's properties like its altitude, radiation pattern, and orientation. Simulator fidelity is scored for each base station via Spearman correlation between measured and simulated powers, and by a fingerprint-based k-nearest-neighbor localization algorithm using RSSI-based fingerprints. Across all experiments, solver hyper-parameters are having immaterial effect on the chosen metrics. On the contrary, antenna locations and orientations prove decisive. By simple greedy optimization we improve the Spearman correlation by 5% to 130% for various base stations, while kNN-based localization error using only simulated data as reference points is decreased by one-third on real-world samples, while staying twice higher than the error with purely real data. Precise geometry and credible antenna models are therefore necessary but not sufficient; faithfully capturing the residual urban noise remains an open challenge for transferable, high-fidelity outdoor RF simulation. 

**Abstract (ZH)**: Sionna v1.0.2射线追踪在罗马中央户外蜂窝链路现实性的研究 

---
# Quantum Reinforcement Learning by Adaptive Non-local Observables 

**Title (ZH)**: 自适应非局域可观测量的量子强化学习 

**Authors**: Hsin-Yi Lin, Samuel Yen-Chi Chen, Huan-Hsin Tseng, Shinjae Yoo  

**Link**: [PDF](https://arxiv.org/pdf/2507.19629)  

**Abstract**: Hybrid quantum-classical frameworks leverage quantum computing for machine learning; however, variational quantum circuits (VQCs) are limited by the need for local measurements. We introduce an adaptive non-local observable (ANO) paradigm within VQCs for quantum reinforcement learning (QRL), jointly optimizing circuit parameters and multi-qubit measurements. The ANO-VQC architecture serves as the function approximator in Deep Q-Network (DQN) and Asynchronous Advantage Actor-Critic (A3C) algorithms. On multiple benchmark tasks, ANO-VQC agents outperform baseline VQCs. Ablation studies reveal that adaptive measurements enhance the function space without increasing circuit depth. Our results demonstrate that adaptive multi-qubit observables can enable practical quantum advantages in reinforcement learning. 

**Abstract (ZH)**: 混合量子-经典框架利用量子计算进行机器学习；然而，变分量子电路（VQCs）受限于需要进行局部测量。我们引入了一种适应性非局部可观测量（ANO）范式到VQCs中，用于量子强化学习（QRL），同时优化电路参数和多量子比特测量。ANO-VQC架构作为深度Q网络（DQN）和异步优势行为 critic（A3C）算法中的函数逼近器。在多个基准任务上，ANO-VQC智能体优于基线VQCs。消融研究显示，自适应测量可以在不增加电路深度的情况下增强函数空间。我们的结果表明，自适应多量子比特可观测量可以实现强化学习中的实用量子优势。 

---
# Programmable Virtual Humans Toward Human Physiologically-Based Drug Discovery 

**Title (ZH)**: 基于人体生理学的药物发现的可编程虚拟人类 

**Authors**: You Wu, Philip E. Bourne, Lei Xie  

**Link**: [PDF](https://arxiv.org/pdf/2507.19568)  

**Abstract**: Artificial intelligence (AI) has sparked immense interest in drug discovery, but most current approaches only digitize existing high-throughput experiments. They remain constrained by conventional pipelines. As a result, they do not address the fundamental challenges of predicting drug effects in humans. Similarly, biomedical digital twins, largely grounded in real-world data and mechanistic models, are tailored for late-phase drug development and lack the resolution to model molecular interactions or their systemic consequences, limiting their impact in early-stage discovery. This disconnect between early discovery and late development is one of the main drivers of high failure rates in drug discovery. The true promise of AI lies not in augmenting current experiments but in enabling virtual experiments that are impossible in the real world: testing novel compounds directly in silico in the human body. Recent advances in AI, high-throughput perturbation assays, and single-cell and spatial omics across species now make it possible to construct programmable virtual humans: dynamic, multiscale models that simulate drug actions from molecular to phenotypic levels. By bridging the translational gap, programmable virtual humans offer a transformative path to optimize therapeutic efficacy and safety earlier than ever before. This perspective introduces the concept of programmable virtual humans, explores their roles in a new paradigm of drug discovery centered on human physiology, and outlines key opportunities, challenges, and roadmaps for their realization. 

**Abstract (ZH)**: 人工智能（AI）在药物发现领域引发了巨大兴趣，但大多数当前的方法仅对现有的高通量实验进行数字化，仍然受制于传统的管道。因此，它们无法解决预测药物对人类效果的基本挑战。同样，生物医学数字孪生主要基于现实世界的数据和机制性模型，适用于后期药物开发，但缺乏建模分子相互作用及其系统后果的分辨率，限制了它们在早期发现阶段的影响。这种早期发现与后期开发之间的脱节是药物发现高失败率的主要驱动因素之一。人工智能真正的潜力不在于增强现有的实验方法，而在于使有可能在现实世界中无法实现的虚拟实验成为可能：直接在虚拟人体内进行前所未有的新型化合物的体外测试。最近在人工智能、高通量干扰 assay、以及跨物种的单细胞和空间组学方面的进展，现在已经使得构建可编程的虚拟人类成为可能：这些模型能够从分子到表型的多层次动态模拟药物作用。通过弥合转化差距，可编程的虚拟人类提供了一条优化治疗效果和安全性前所未有的新途径。本文介绍了可编程虚拟人类的概念，探讨了其在以人体生理为中心的新药物发现范式中的作用，并概述了实现其重要机会、挑战和路线图。 

---
# Towards Sustainability Model Cards 

**Title (ZH)**: 面向可持续性的模型卡片 

**Authors**: Gwendal Jouneaux, Jordi Cabot  

**Link**: [PDF](https://arxiv.org/pdf/2507.19559)  

**Abstract**: The growth of machine learning (ML) models and associated datasets triggers a consequent dramatic increase in energy costs for the use and training of these models. In the current context of environmental awareness and global sustainability concerns involving ICT, Green AI is becoming an important research topic. Initiatives like the AI Energy Score Ratings are a good example. Nevertheless, these benchmarking attempts are still to be integrated with existing work on Quality Models and Service-Level Agreements common in other, more mature, ICT subfields. This limits the (automatic) analysis of this model energy descriptions and their use in (semi)automatic model comparison, selection, and certification processes. We aim to leverage the concept of quality models and merge it with existing ML model reporting initiatives and Green/Frugal AI proposals to formalize a Sustainable Quality Model for AI/ML models. As a first step, we propose a new Domain-Specific Language to precisely define the sustainability aspects of an ML model (including the energy costs for its different tasks). This information can then be exported as an extended version of the well-known Model Cards initiative while, at the same time, being formal enough to be input of any other model description automatic process. 

**Abstract (ZH)**: 机器学习模型及其相关数据集的增长引发了使用和训练这些模型的能源成本的急剧增加。在当前的环保意识和ICT领域全球可持续发展关注的背景下，绿色AI正成为一个重要的研究领域。尽管人工智能能源评分评级等倡议是好的例子，但这些基准尝试尚未与现有质量模型和服务级协议工作集成，特别是在其他更成熟的ICT子领域。这限制了对这些模型能源描述的自动分析及其在半自动模型比较、选择和认证过程中的应用。我们旨在利用质量模型的概念，并将其与现有的机器学习模型报告倡议和绿色/节约型AI提议相结合，以正式化一个可持续质量模型。作为第一步，我们提出了一种新的领域特定语言，以精确定义机器学习模型的可持续性方面（包括其不同任务的能源成本）。这些信息可以导出为广为人知的模型卡片倡议的扩展版本，同时具备足夠的形式化程度，可以作为任何其他模型描述自动过程的输入。 

---
# PEMUTA: Pedagogically-Enriched Multi-Granular Undergraduate Thesis Assessment 

**Title (ZH)**: PEMUTA：教学丰富化的多层次本科毕业论文评估 

**Authors**: Jialu Zhang, Qingyang Sun, Qianyi Wang, Weiyi Zhang, Zunjie Xiao, Xiaoqing Zhang, Jianfeng Ren, Jiang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2507.19556)  

**Abstract**: The undergraduate thesis (UGTE) plays an indispensable role in assessing a student's cumulative academic development throughout their college years. Although large language models (LLMs) have advanced education intelligence, they typically focus on holistic assessment with only one single evaluation score, but ignore the intricate nuances across multifaceted criteria, limiting their ability to reflect structural criteria, pedagogical objectives, and diverse academic competencies. Meanwhile, pedagogical theories have long informed manual UGTE evaluation through multi-dimensional assessment of cognitive development, disciplinary thinking, and academic performance, yet remain underutilized in automated settings. Motivated by the research gap, we pioneer PEMUTA, a pedagogically-enriched framework that effectively activates domain-specific knowledge from LLMs for multi-granular UGTE assessment. Guided by Vygotsky's theory and Bloom's Taxonomy, PEMUTA incorporates a hierarchical prompting scheme that evaluates UGTEs across six fine-grained dimensions: Structure, Logic, Originality, Writing, Proficiency, and Rigor (SLOWPR), followed by holistic synthesis. Two in-context learning techniques, \ie, few-shot prompting and role-play prompting, are also incorporated to further enhance alignment with expert judgments without fine-tuning. We curate a dataset of authentic UGTEs with expert-provided SLOWPR-aligned annotations to support multi-granular UGTE assessment. Extensive experiments demonstrate that PEMUTA achieves strong alignment with expert evaluations, and exhibits strong potential for fine-grained, pedagogically-informed UGTE evaluations. 

**Abstract (ZH)**: 本科生毕业论文（UGTE）在评估学生在整个大学阶段的综合学术发展方面发挥着不可替代的作用。虽然大型语言模型（LLMs）提高了教育智能化，但它们通常仅采用整体评估方式并给出单一评分，忽视了跨多方面标准的复杂细微差异，限制了其反映结构性标准、教学目标和多样学术能力的能力。同时，教学理论长期通过多维评估认知发展、学科思维和学术表现来指导手工UGTE评估，但在自动化环境中仍未充分利用。受研究空白的驱动，我们提出了PEMUTA，这是一种富含教学理念的框架，有效激活了LLMs中的特定领域知识以进行多层次UGTE评估。PEMUTA 以维果茨基理论和布卢姆分类法为指导，结合了一种层次化的提示方案，评估UGTE在结构、逻辑、创新性、写作、熟练度和严谨性（SLOWPR）六个细粒度维度上的表现，随后进行综合评价。此外，还采用了两种情境学习技术，即少量示例提示和角色扮演提示，以进一步增强与专家判断的一致性，无需微调。我们构建了一个包含专家提供的SLOWPR对齐注释的真实UGTE数据集，以支持多层次UGTE评估。广泛的实验表明，PEMUTA 在与专家评估的一致性方面表现出色，并显示出进行细粒度、教学导向的UGTE评估的强大潜力。 

---
# Justifications for Democratizing AI Alignment and Their Prospects 

**Title (ZH)**: 民主化AI对齐的正当性及其前景 

**Authors**: André Steingrüber, Kevin Baum  

**Link**: [PDF](https://arxiv.org/pdf/2507.19548)  

**Abstract**: The AI alignment problem comprises both technical and normative dimensions. While technical solutions focus on implementing normative constraints in AI systems, the normative problem concerns determining what these constraints should be. This paper examines justifications for democratic approaches to the normative problem -- where affected stakeholders determine AI alignment -- as opposed to epistocratic approaches that defer to normative experts. We analyze both instrumental justifications (democratic approaches produce better outcomes) and non-instrumental justifications (democratic approaches prevent illegitimate authority or coercion). We argue that normative and metanormative uncertainty create a justificatory gap that democratic approaches aim to fill through political rather than theoretical justification. However, we identify significant challenges for democratic approaches, particularly regarding the prevention of illegitimate coercion through AI alignment. Our analysis suggests that neither purely epistocratic nor purely democratic approaches may be sufficient on their own, pointing toward hybrid frameworks that combine expert judgment with participatory input alongside institutional safeguards against AI monopolization. 

**Abstract (ZH)**: AI对齐问题包含技术和规范两个维度。虽然技术解决方案集中在将规范约束实施到AI系统中，规范性问题则关注这些约束应当是什么。本文探讨了以民主方式解决规范性问题的正当性——受影响的利益相关者确定AI对齐——对比于依赖规范性专家的意见的精英主义方法。我们分析了工具性的正当性（民主方法产生更好的结果）和非工具性的正当性（民主方法防止不合法的权威或胁迫）。我们认为，规范性和元规范性不确定性造成了一个论证缺口，民主方法希望通过政治性而非理论性论证来填补这一缺口。然而，我们识别出民主方法存在重大挑战，特别是在通过AI对齐防止不合法胁迫方面。我们的分析表明，纯粹精英主义或纯粹民主主义方法可能都不足以单独解决该问题，指向结合专家判断与参与性输入，并辅以机构性保障防止AI垄断的混合框架。 

---
# Swift-Sarsa: Fast and Robust Linear Control 

**Title (ZH)**: Swift-Sarsa: 快速而稳健的线性控制 

**Authors**: Khurram Javed, Richard S. Sutton  

**Link**: [PDF](https://arxiv.org/pdf/2507.19539)  

**Abstract**: Javed, Sharifnassab, and Sutton (2024) introduced a new algorithm for TD learning -- SwiftTD -- that augments True Online TD($\lambda$) with step-size optimization, a bound on the effective learning rate, and step-size decay. In their experiments SwiftTD outperformed True Online TD($\lambda$) and TD($\lambda$) on a variety of prediction tasks derived from Atari games, and its performance was robust to the choice of hyper-parameters. In this extended abstract we extend SwiftTD to work for control problems. We combine the key ideas behind SwiftTD with True Online Sarsa($\lambda$) to develop an on-policy reinforcement learning algorithm called $\textit{Swift-Sarsa}$.
We propose a simple benchmark for linear on-policy control called the $\textit{operant conditioning benchmark}$. The key challenge in the operant conditioning benchmark is that a very small subset of input signals are relevant for decision making. The majority of the signals are noise sampled from a non-stationary distribution. To learn effectively, the agent must learn to differentiate between the relevant signals and the noisy signals, and minimize prediction errors by assigning credit to the weight parameters associated with the relevant signals.
Swift-Sarsa, when applied to the operant conditioning benchmark, learned to assign credit to the relevant signals without any prior knowledge of the structure of the problem. It opens the door for solution methods that learn representations by searching over hundreds of millions of features in parallel without performance degradation due to noisy or bad features. 

**Abstract (ZH)**: Javed, Sharifnassab, and Sutton (2024)提出的SwiftTD算法结合了True Online TD($\lambda$)的在线学习特性，并加入了步长优化、有效学习率的上界和步长衰减，从而改进了TD学习。在实验中，SwiftTD在多种源自Atari游戏的预测任务中性能超越了True Online TD($\lambda$)和TD($\lambda$)，并且表现出对超参数选择的鲁棒性。在本文扩展摘要中，我们将SwiftTD扩展应用于控制问题，并将SwiftTD的关键思想与True Online Sarsa($\lambda$)结合，开发出一种随策略强化学习算法Swift-Sarsa。 

---
# Graph Learning Metallic Glass Discovery from Wikipedia 

**Title (ZH)**: 基于Wikipedia的图学习金属玻璃发现 

**Authors**: K.-C. Ouyang, S.-Y. Zhang, S.-L. Liu, J. Tian, Y.-H. Li, H. Tong, H.-Y. Bai, W.-H. Wang, Y.-C. Hu  

**Link**: [PDF](https://arxiv.org/pdf/2507.19536)  

**Abstract**: Synthesizing new materials efficiently is highly demanded in various research fields. However, this process is usually slow and expensive, especially for metallic glasses, whose formation strongly depends on the optimal combinations of multiple elements to resist crystallization. This constraint renders only several thousands of candidates explored in the vast material space since 1960. Recently, data-driven approaches armed by advanced machine learning techniques provided alternative routes for intelligent materials design. Due to data scarcity and immature material encoding, the conventional tabular data is usually mined by statistical learning algorithms, giving limited model predictability and generalizability. Here, we propose sophisticated data learning from material network representations. The node elements are encoded from the Wikipedia by a language model. Graph neural networks with versatile architectures are designed to serve as recommendation systems to explore hidden relationships among materials. By employing Wikipedia embeddings from different languages, we assess the capability of natural languages in materials design. Our study proposes a new paradigm to harvesting new amorphous materials and beyond with artificial intelligence. 

**Abstract (ZH)**: 高效合成新材料在多个研究领域备受需求。然而，这一过程通常缓慢且昂贵，尤其是对于金属玻璃，其形成强烈依赖于多种元素的最佳组合以抵抗结晶。这种约束使得自1960年以来，只有几千种候选材料在广阔的材料空间中被探索。最近，由先进机器学习技术武装的数据驱动方法为智能材料设计提供了替代路径。由于数据稀缺和材料编码不成熟，常规的表格数据通常由统计学习算法挖掘，这限制了模型的预测能力和泛化能力。在此，我们提出从材料网络表示中进行复杂的数据学习。节点元素通过语言模型从Wikipedia编码。具有多种架构的图神经网络被设计为推荐系统，以探索材料之间的隐藏关系。通过使用不同语言的Wikipedia嵌入，我们评估自然语言在材料设计中的能力。我们的研究提出了一种新的范式，借助人工智能来获取新的无定形材料以及其他新材料。 

---
# FedDPG: An Adaptive Yet Efficient Prompt-tuning Approach in Federated Learning Settings 

**Title (ZH)**: FedDPG：联邦学习环境中的一种自适应且高效的提示调优方法 

**Authors**: Ali Shakeri, Wei Emma Zhang, Amin Beheshti, Weitong Chen, Jian Yang, Lishan Yang  

**Link**: [PDF](https://arxiv.org/pdf/2507.19534)  

**Abstract**: Pre-trained Language Models (PLMs) have demonstrated impressive performance in various NLP tasks. However, traditional fine-tuning methods for leveraging PLMs for downstream tasks entail significant computational overhead. Prompt-tuning has emerged as an efficient alternative that involves prepending a limited number of parameters to the input sequence and only updating them while the PLM's parameters are frozen. However, this technique's prompts remain fixed for all inputs, reducing the model's flexibility. The Federated Learning (FL) technique has gained attention in recent years to address the growing concerns around data privacy. However, challenges such as communication and computation limitations of clients still need to be addressed. To mitigate these challenges, this paper introduces the Federated Dynamic Prompt Generator (FedDPG), which incorporates a dynamic prompt generator network to generate context-aware prompts based on the given input, ensuring flexibility and adaptability while prioritising data privacy in federated learning settings. Our experiments on three NLP benchmark datasets showcase that FedDPG outperforms the state-of-the-art parameter-efficient fine-tuning methods in terms of global model performance, and has significantly reduced the calculation time and the number of parameters to be sent through the FL network. 

**Abstract (ZH)**: 预训练语言模型（PLMs）在各种自然语言处理任务中展现了令人印象深刻的性能。然而，传统利用PLMs进行下游任务的微调方法伴随着显著的计算开销。提示微调作为一种高效的替代方法已经出现，它包括在输入序列前附加少量参数，并且仅更新这些参数而冻结PLM的参数。然而，这种方法中的提示在整个输入上保持固定，降低了模型的灵活性。联邦学习（FL）技术近年来引起了广泛关注，以应对日益增长的数据隐私问题。然而，客户在通信和计算限制方面仍面临着挑战。为缓解这些挑战，本文提出了联邦动态提示生成器（FedDPG），该方法结合了一个动态提示生成网络，根据给定的输入生成上下文感知的提示，确保在联邦学习环境中灵活性和适应性的同时，优先考虑数据隐私。我们在三个自然语言处理基准数据集上的实验表明，FedDPG在全局模型性能上优于最先进的参数高效微调方法，并且显著减少了通过FL网络传输的计算时间和参数数量。 

---
# Clinical-Grade Blood Pressure Prediction in ICU Settings: An Ensemble Framework with Uncertainty Quantification and Cross-Institutional Validation 

**Title (ZH)**: ICU环境中临床级血压预测：一种带有不确定性量化和跨机构验证的集成框架 

**Authors**: Md Basit Azam, Sarangthem Ibotombi Singh  

**Link**: [PDF](https://arxiv.org/pdf/2507.19530)  

**Abstract**: Blood pressure (BP) monitoring is critical in in tensive care units (ICUs) where hemodynamic instability can
rapidly progress to cardiovascular collapse. Current machine
learning (ML) approaches suffer from three limitations: lack of
external validation, absence of uncertainty quantification, and
inadequate data leakage prevention. This study presents the
first comprehensive framework with novel algorithmic leakage
prevention, uncertainty quantification, and cross-institutional
validation for electronic health records (EHRs) based BP pre dictions. Our methodology implemented systematic data leakage
prevention, uncertainty quantification through quantile regres sion, and external validation between the MIMIC-III and eICU
databases. An ensemble framework combines Gradient Boosting,
Random Forest, and XGBoost with 74 features across five
physiological domains. Internal validation achieved a clinically
acceptable performance (for SBP: R^2 = 0.86, RMSE = 6.03
mmHg; DBP: R^2 = 0.49, RMSE = 7.13 mmHg), meeting AAMI
standards. External validation showed 30% degradation with
critical limitations in patients with hypotensive. Uncertainty
quantification generated valid prediction intervals (80.3% SBP
and 79.9% DBP coverage), enabling risk-stratified protocols
with narrow intervals (< 15 mmHg) for standard monitoring
and wide intervals (> 30 mmHg) for manual verification. This
framework provides realistic deployment expectations for cross institutional AI-assisted BP monitoring in critical care settings.
The source code is publicly available at this https URL
mdbasit897/clinical-bp-prediction-ehr. 

**Abstract (ZH)**: 基于电子健康记录的血压监测的首个多机构综合框架：新颖的算法泄漏防止、不确定性量化与外部验证 

---
# Machine Learning Risk Intelligence for Green Hydrogen Investment: Insights for Duqm R3 Auction 

**Title (ZH)**: 绿色氢投资的机器学习风险智能：杜克拉姆R3拍卖的见解 

**Authors**: Obumneme Nwafor, Mohammed Abdul Majeed Al Hooti  

**Link**: [PDF](https://arxiv.org/pdf/2507.19529)  

**Abstract**: As green hydrogen emerges as a major component of global decarbonisation, Oman has positioned itself strategically through national auctions and international partnerships. Following two successful green hydrogen project rounds, the country launched its third auction (R3) in the Duqm region. While this area exhibits relative geospatial homogeneity, it is still vulnerable to environmental fluctuations that pose inherent risks to productivity. Despite growing global investment in green hydrogen, operational data remains scarce, with major projects like Saudi Arabia's NEOM facility not expected to commence production until 2026, and Oman's ACME Duqm project scheduled for 2028. This absence of historical maintenance and performance data from large-scale hydrogen facilities in desert environments creates a major knowledge gap for accurate risk assessment for infrastructure planning and auction decisions. Given this data void, environmental conditions emerge as accessible and reliable proxy for predicting infrastructure maintenance pressures, because harsh desert conditions such as dust storms, extreme temperatures, and humidity fluctuations are well-documented drivers of equipment degradation in renewable energy systems. To address this challenge, this paper proposes an Artificial Intelligence decision support system that leverages publicly available meteorological data to develop a predictive Maintenance Pressure Index (MPI), which predicts risk levels and future maintenance demands on hydrogen infrastructure. This tool strengthens regulatory foresight and operational decision-making by enabling temporal benchmarking to assess and validate performance claims over time. It can be used to incorporate temporal risk intelligence into auction evaluation criteria despite the absence of historical operational benchmarks. 

**Abstract (ZH)**: 随着绿色氢气成为全球去碳化的主要组成部分， Oman通过国家拍卖和国际合作战略性地定位自己。在成功举办了两轮绿色氢气项目后，该国在Duqm地区推出了第三轮拍卖（R3）。尽管该区域在地理空间上表现出相对的均一性，但仍易受环境波动的影响，这些波动对生产力构成了固有的风险。尽管全球在绿色氢气方面的投资不断增加，但运营数据仍相当稀缺，沙特阿拉伯NEOM设施预计要到2026年才能启动生产，Oman的ACME Duqm项目则计划于2028年启动。大型氢能源设施在沙漠环境中的历史维护和性能数据的缺失，导致在基础设施规划和拍卖决策中存在重大知识空白。鉴于这一数据缺口，环境条件成为预测基础设施维护压力的可及且可靠代理，因为诸如沙尘暴、极端温度和湿度波动等严酷的沙漠条件已被证实是可再生能源系统设备退化的良好记录驱动因素。为应对这一挑战，本文提出了一种人工智能决策支持系统，利用公开气象数据开发预测维护压力指数（MPI），以预测风险水平和未来氢能源基础设施的维护需求。该工具通过时间基准评估和验证性能声明，增强了监管预见性和运营决策，即使在缺乏历史运营基准的情况下，也可以将其用于拍卖评估标准中，纳入时间风险智能。 

---
# Language Models for Controllable DNA Sequence Design 

**Title (ZH)**: 可控DNA序列设计的语言模型 

**Authors**: Xingyu Su, Xiner Li, Yuchao Lin, Ziqian Xie, Degui Zhi, Shuiwang Ji  

**Link**: [PDF](https://arxiv.org/pdf/2507.19523)  

**Abstract**: We consider controllable DNA sequence design, where sequences are generated by conditioning on specific biological properties. While language models (LMs) such as GPT and BERT have achieved remarkable success in natural language generation, their application to DNA sequence generation remains largely underexplored. In this work, we introduce ATGC-Gen, an Automated Transformer Generator for Controllable Generation, which leverages cross-modal encoding to integrate diverse biological signals. ATGC-Gen is instantiated with both decoder-only and encoder-only transformer architectures, allowing flexible training and generation under either autoregressive or masked recovery objectives. We evaluate ATGC-Gen on representative tasks including promoter and enhancer sequence design, and further introduce a new dataset based on ChIP-Seq experiments for modeling protein binding specificity. Our experiments demonstrate that ATGC-Gen can generate fluent, diverse, and biologically relevant sequences aligned with the desired properties. Compared to prior methods, our model achieves notable improvements in controllability and functional relevance, highlighting the potential of language models in advancing programmable genomic design. The source code is released at (this https URL). 

**Abstract (ZH)**: 可控DNA序列设计中的自动Transformer生成器ATGC-Gen及其应用 

---
# Exoplanet Detection Using Machine Learning Models Trained on Synthetic Light Curves 

**Title (ZH)**: 基于合成光曲数据训练的机器学习模型系外行星检测 

**Authors**: Ethan Lo, Dan C. Lo  

**Link**: [PDF](https://arxiv.org/pdf/2507.19520)  

**Abstract**: With manual searching processes, the rate at which scientists and astronomers discover exoplanets is slow because of inefficiencies that require an extensive time of laborious inspections. In fact, as of now there have been about only 5,000 confirmed exoplanets since the late 1900s. Recently, machine learning (ML) has proven to be extremely valuable and efficient in various fields, capable of processing massive amounts of data in addition to increasing its accuracy by learning. Though ML models for discovering exoplanets owned by large corporations (e.g. NASA) exist already, they largely depend on complex algorithms and supercomputers. In an effort to reduce such complexities, in this paper, we report the results and potential benefits of various, well-known ML models in the discovery and validation of extrasolar planets. The ML models that are examined in this study include logistic regression, k-nearest neighbors, and random forest. The dataset on which the models train and predict is acquired from NASA's Kepler space telescope. The initial results show promising scores for each model. However, potential biases and dataset imbalances necessitate the use of data augmentation techniques to further ensure fairer predictions and improved generalization. This study concludes that, in the context of searching for exoplanets, data augmentation techniques significantly improve the recall and precision, while the accuracy varies for each model. 

**Abstract (ZH)**: 基于机器学习模型在寻找和验证系外行星中的应用与改进 

---
# Physics-informed transfer learning for SHM via feature selection 

**Title (ZH)**: 基于特征选择的物理信息迁移学习在结构健康监测中的应用 

**Authors**: J. Poole, P. Gardner, A. J. Hughes, N. Dervilis, R. S. Mills, T. A. Dardeno, K. Worden  

**Link**: [PDF](https://arxiv.org/pdf/2507.19519)  

**Abstract**: Data used for training structural health monitoring (SHM) systems are expensive and often impractical to obtain, particularly labelled data. Population-based SHM presents a potential solution to this issue by considering the available data across a population of structures. However, differences between structures will mean the training and testing distributions will differ; thus, conventional machine learning methods cannot be expected to generalise between structures. To address this issue, transfer learning (TL), can be used to leverage information across related domains. An important consideration is that the lack of labels in the target domain limits data-based metrics to quantifying the discrepancy between the marginal distributions. Thus, a prerequisite for the application of typical unsupervised TL methods is to identify suitable source structures (domains), and a set of features, for which the conditional distributions are related to the target structure. Generally, the selection of domains and features is reliant on domain expertise; however, for complex mechanisms, such as the influence of damage on the dynamic response of a structure, this task is not trivial. In this paper, knowledge of physics is leveraged to select more similar features, the modal assurance criterion (MAC) is used to quantify the correspondence between the modes of healthy structures. The MAC is shown to have high correspondence with a supervised metric that measures joint-distribution similarity, which is the primary indicator of whether a classifier will generalise between domains. The MAC is proposed as a measure for selecting a set of features that behave consistently across domains when subjected to damage, i.e. features with invariance in the conditional distributions. This approach is demonstrated on numerical and experimental case studies to verify its effectiveness in various applications. 

**Abstract (ZH)**: 基于群体的结构健康监测中的迁移学习方法研究 

---
# Target Circuit Matching in Large-Scale Netlists using GNN-Based Region Prediction 

**Title (ZH)**: 基于GNN的区域预测在大规模网表中目标电路匹配 

**Authors**: Sangwoo Seo, Jimin Seo, Yoonho Lee, Donghyeon Kim, Hyejin Shin, Banghyun Sung, Chanyoung Park  

**Link**: [PDF](https://arxiv.org/pdf/2507.19518)  

**Abstract**: Subgraph matching plays an important role in electronic design automation (EDA) and circuit verification. Traditional rule-based methods have limitations in generalizing to arbitrary target circuits. Furthermore, node-to-node matching approaches tend to be computationally inefficient, particularly for large-scale circuits. Deep learning methods have emerged as a potential solution to address these challenges, but existing models fail to efficiently capture global subgraph embeddings or rely on inefficient matching matrices, which limits their effectiveness for large circuits. In this paper, we propose an efficient graph matching approach that utilizes Graph Neural Networks (GNNs) to predict regions of high probability for containing the target circuit. Specifically, we construct various negative samples to enable GNNs to accurately learn the presence of target circuits and develop an approach to directly extracting subgraph embeddings from the entire circuit, which captures global subgraph information and addresses the inefficiency of applying GNNs to all candidate subgraphs. Extensive experiments demonstrate that our approach significantly outperforms existing methods in terms of time efficiency and target region prediction, offering a scalable and effective solution for subgraph matching in large-scale circuits. 

**Abstract (ZH)**: 基于图神经网络的高效子图匹配方法 

---
# BikeVAE-GNN: A Variational Autoencoder-Augmented Hybrid Graph Neural Network for Sparse Bicycle Volume Estimation 

**Title (ZH)**: BikeVAE-GNN：一种用于稀疏自行车流量估计的变分自编码器增强混合图神经网络 

**Authors**: Mohit Gupta, Debjit Bhowmick, Ben Beck  

**Link**: [PDF](https://arxiv.org/pdf/2507.19517)  

**Abstract**: Accurate link-level bicycle volume estimation is essential for informed urban and transport planning but it is challenged by extremely sparse count data in urban bicycling networks worldwide. We propose BikeVAE-GNN, a novel dual-task framework augmenting a Hybrid Graph Neural Network (GNN) with Variational Autoencoder (VAE) to estimate Average Daily Bicycle (ADB) counts, addressing sparse bicycle networks. The Hybrid-GNN combines Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and GraphSAGE to effectively model intricate spatial relationships in sparse networks while VAE generates synthetic nodes and edges to enrich the graph structure and enhance the estimation performance. BikeVAE-GNN simultaneously performs - regression for bicycling volume estimation and classification for bicycling traffic level categorization. We demonstrate the effectiveness of BikeVAE-GNN using OpenStreetMap data and publicly available bicycle count data within the City of Melbourne - where only 141 of 15,933 road segments have labeled counts (resulting in 99% count data sparsity). Our experiments show that BikeVAE-GNN outperforms machine learning and baseline GNN models, achieving a mean absolute error (MAE) of 30.82 bicycles per day, accuracy of 99% and F1-score of 0.99. Ablation studies further validate the effective role of Hybrid-GNN and VAE components. Our research advances bicycling volume estimation in sparse networks using novel and state-of-the-art approaches, providing insights for sustainable bicycling infrastructures. 

**Abstract (ZH)**: 准确的自行车流量链路级估计对于城市和交通规划至关重要，但全球城市自行车网络中的计数数据极为稀疏，对自行车流量估计构成了挑战。我们提出了一种名为BikeVAE-GNN的新型双重任务框架，该框架通过将混合图神经网络（GNN）与变分自编码器（VAE）结合，以估计平均每日自行车（ADB）计数，解决稀疏自行车网络问题。混合GNN结合了图卷积网络（GCN）、图注意网络（GAT）和GraphSAGE，有效建模稀疏网络中的复杂空间关系，而VAE生成合成节点和边以丰富图结构并增强估计性能。BikeVAE-GNN同时进行自行车流量估计的回归和骑行交通等级分类的分类。我们使用OpenStreetMap数据和墨尔本市公开可获取的自行车计数数据（其中只有141条道路路段有标注计数，导致99%的计数数据稀疏性）验证了BikeVAE-GNN的有效性。实验结果表明，BikeVAE-GNN优于机器学习和基础GNN模型，平均绝对误差（MAE）为每天30.82辆自行车，准确率为99%，F1分数为0.99。消融研究表明，混合GNN和VAE组件的有效性得到进一步验证。我们的研究采用新颖和最先进的方法，促进了稀疏网络中的自行车流量估计，为可持续的自行车基础设施提供了见解。 

---
# Enhancing Spatiotemporal Networks with xLSTM: A Scalar LSTM Approach for Cellular Traffic Forecasting 

**Title (ZH)**: 基于标量LSTM的时空网络增强：细胞级交通预测方法 

**Authors**: Khalid Ali, Zineddine Bettouche, Andreas Kassler, Andreas Fischer  

**Link**: [PDF](https://arxiv.org/pdf/2507.19513)  

**Abstract**: Accurate spatiotemporal traffic forecasting is vital for intelligent resource management in 5G and beyond. However, conventional AI approaches often fail to capture the intricate spatial and temporal patterns that exist, due to e.g., the mobility of users. We introduce a lightweight, dual-path Spatiotemporal Network that leverages a Scalar LSTM (sLSTM) for efficient temporal modeling and a three-layer Conv3D module for spatial feature extraction. A fusion layer integrates both streams into a cohesive representation, enabling robust forecasting. Our design improves gradient stability and convergence speed while reducing prediction error. Evaluations on real-world datasets show superior forecast performance over ConvLSTM baselines and strong generalization to unseen regions, making it well-suited for large-scale, next-generation network deployments. Experimental evaluation shows a 23% MAE reduction over ConvLSTM, with a 30% improvement in model generalization. 

**Abstract (ZH)**: 准确的空间时间交通预测对于5G及更高级别的智能资源管理至关重要。然而，传统的AI方法往往难以捕捉到由于用户移动等原因存在的复杂的空间和时间模式。我们提出了一种轻量化、双路径的空间时间网络，该网络利用标量LSTM（sLSTM）进行高效的时间建模，并使用三层Conv3D模块进行空间特征提取。融合层将这两种流集成到一个统一的表示中，从而实现稳健的预测。我们的设计提高了梯度稳定性和收敛速度，并减少了预测误差。在实际数据集上的评估显示，该方法在预测性能上优于ConvLSTM基线，并且能够很好地泛化到未见过的区域，使其适用于大规模、下一代网络的部署。实验评估表明，与ConvLSTM相比，预测误差降低了23%，模型泛化能力提高了30%。 

---
# Beyond 9-to-5: A Generative Model for Augmenting Mobility Data of Underrepresented Shift Workers 

**Title (ZH)**: 超越朝九晚五：一种增强少代表性轮班工作者出行数据的生成模型 

**Authors**: Haoxuan Ma, Xishun Liao, Yifan Liu, Chris Stanford, Jiaqi Ma  

**Link**: [PDF](https://arxiv.org/pdf/2507.19510)  

**Abstract**: This paper addresses a critical gap in urban mobility modeling by focusing on shift workers, a population segment comprising 15-20% of the workforce in industrialized societies yet systematically underrepresented in traditional transportation surveys and planning. This underrepresentation is revealed in this study by a comparative analysis of GPS and survey data, highlighting stark differences between the bimodal temporal patterns of shift workers and the conventional 9-to-5 schedules recorded in surveys. To address this bias, we introduce a novel transformer-based approach that leverages fragmented GPS trajectory data to generate complete, behaviorally valid activity patterns for individuals working non-standard hours. Our method employs periodaware temporal embeddings and a transition-focused loss function specifically designed to capture the unique activity rhythms of shift workers and mitigate the inherent biases in conventional transportation datasets. Evaluation shows that the generated data achieves remarkable distributional alignment with GPS data from Los Angeles County (Average JSD < 0.02 for all evaluation metrics). By transforming incomplete GPS traces into complete, representative activity patterns, our approach provides transportation planners with a powerful data augmentation tool to fill critical gaps in understanding the 24/7 mobility needs of urban populations, enabling precise and inclusive transportation planning. 

**Abstract (ZH)**: 本文通过聚焦于夜班工作者这一在工业化社会中占15-20% workforce但在传统交通调查和规划中系统性地代表性不足的人群群体，填补了城市移动建模中的一个关键空白。通过比较分析GPS数据和问卷数据，本研究揭示了夜班工作者的双峰时间模式与传统9至5工作时间记录在问卷中的显著差异。为解决这一偏差，本文引入了一种基于变压器的新颖方法，利用碎片化的GPS轨迹数据生成完整且行为上有效的活动模式，适用于非标准工作时间的个人。该方法采用了时间段感知的时间嵌入，并设计了一种侧重于转换的损失函数，专门用于捕捉夜班工作者的独特活动节奏并减轻传统交通数据集中的固有偏差。评估结果显示，生成的数据在所有评估指标上的分布与洛杉矶县的GPS数据实现了显著对齐（平均JSD<0.02）。通过将不完整的GPS轨迹转化为完整的具有代表性的活动模式，本文的方法为交通规划者提供了一种强大的数据增强工具，以便填补对城市人口24/7移动需求理解的关键空白，有助于实现精确和平等的交通规划。 

---
# Unlimited Editions: Documenting Human Style in AI Art Generation 

**Title (ZH)**: 无限版次：记录AI艺术生成中的人类风格 

**Authors**: Alex Leitch, Celia Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.19497)  

**Abstract**: As AI art generation becomes increasingly sophisticated, HCI research has focused primarily on questions of detection, authenticity, and automation. This paper argues that such approaches fundamentally misunderstand how artistic value emerges from the concerns that drive human image production. Through examination of historical precedents, we demonstrate that artistic style is not only visual appearance but the resolution of creative struggle, as artists wrestle with influence and technical constraints to develop unique ways of seeing. Current AI systems flatten these human choices into reproducible patterns without preserving their provenance. We propose that HCI's role lies not only in perfecting visual output, but in developing means to document the origins and evolution of artistic style as it appears within generated visual traces. This reframing suggests new technical directions for HCI research in generative AI, focused on automatic documentation of stylistic lineage and creative choice rather than simple reproduction of aesthetic effects. 

**Abstract (ZH)**: 随着AI艺术生成技术日益 sophistication，人机交互研究主要集中在检测、 authenticity 和自动化等方面。本文认为，此类方法从根本上误解了艺术价值如何源自驱动人类图像创作的关切。通过考察历史先例，我们表明，艺术风格不仅是视觉表现，更是创造性的抗争结果，艺术家们在应对影响与技术限制的同时，发展出独特的视角。当前的AI系统将这些人类选择简化为可复制的模式，而不保留其起源。我们提议，人机交互的角色不仅在于完善视觉输出，还在于开发方法记录艺术风格在生成视觉痕迹中的起源和演变。这种重新定位为生成AI的人机交互研究指出了新的技术方向，重点在于自动记录风格谱系和创造性选择，而非仅仅是简单地复制美学效果。 

---
# ChartGen: Scaling Chart Understanding Via Code-Guided Synthetic Chart Generation 

**Title (ZH)**: ChartGen：通过代码导向的合成图表生成扩展图表理解 

**Authors**: Jovana Kondic, Pengyuan Li, Dhiraj Joshi, Zexue He, Shafiq Abedin, Jennifer Sun, Ben Wiesel, Eli Schwartz, Ahmed Nassar, Bo Wu, Assaf Arbelle, Aude Oliva, Dan Gutfreund, Leonid Karlinsky, Rogerio Feris  

**Link**: [PDF](https://arxiv.org/pdf/2507.19492)  

**Abstract**: Chart-to-code reconstruction -- the task of recovering executable plotting scripts from chart images -- provides important insights into a model's ability to ground data visualizations in precise, machine-readable form. Yet many existing multimodal benchmarks largely focus primarily on answering questions about charts or summarizing them. To bridge this gap, we present ChartGen, a fully-automated pipeline for code-guided synthetic chart generation. Starting from seed chart images, ChartGen (i) prompts a vision-language model (VLM) to reconstruct each image into a python script, and (ii) iteratively augments that script with a code-oriented large language model (LLM). Using ChartGen, we create 222.5K unique chart-image code pairs from 13K seed chart images, and present an open-source synthetic chart dataset covering 27 chart types, 11 plotting libraries, and multiple data modalities (image, code, text, CSV, DocTags). From this corpus, we curate a held-out chart-to-code evaluation subset of 4.3K chart image-code pairs, and evaluate six open-weight VLMs (3B - 26B parameters), highlighting substantial room for progress. We release the pipeline, prompts, and the dataset to help accelerate efforts towards robust chart understanding and vision-conditioned code generation: this https URL 

**Abstract (ZH)**: 图到代码重构——从图表图像恢复可执行绘图脚本的任务，为理解模型将数据可视化精确转化为机器可读形式的能力提供了重要见解。然而，现有许多多模态基准主要侧重于回答关于图表的问题或对图表进行总结。为弥合这一差距，我们提出了ChartGen，这是一种完全自动化的代码引导合成图表生成流水线。从种子图表图像开始，ChartGen (i) 启动一个视觉-语言模型（VLM）将每个图像重构为一个Python脚本，(ii) 并迭代地使用代码导向的大型语言模型（LLM）扩充该脚本。使用ChartGen，我们从13K种子图表图像中创建了222,500个唯一的图表图像-代码对，并提出了一个包含27种图表类型、11种绘图库和多种数据模态（图像、代码、文本、CSV、DocTags）的开源合成图表数据集。从该语料库中，我们精心挑选了一个保留的图表到代码评估子集，包含4,300个图表图像-代码对，并对六种开源预训练VLM（3B - 26B参数）进行了评估，突显了显著的改进空间。我们发布了该流水线、提示和数据集，以帮助加速对稳健的图表理解和视觉条件下的代码生成的研究进展：https://link.to.dataset.com 

---
# Does AI and Human Advice Mitigate Punishment for Selfish Behavior? An Experiment on AI ethics From a Psychological Perspective 

**Title (ZH)**: AI和人类建议能否减轻自私行为的惩罚？从心理学视角探究AI伦理的一项实验 

**Authors**: Margarita Leib, Nils Köbis, Ivan Soraperra  

**Link**: [PDF](https://arxiv.org/pdf/2507.19487)  

**Abstract**: People increasingly rely on AI-advice when making decisions. At times, such advice can promote selfish behavior. When individuals abide by selfishness-promoting AI advice, how are they perceived and punished? To study this question, we build on theories from social psychology and combine machine-behavior and behavioral economic approaches. In a pre-registered, financially-incentivized experiment, evaluators could punish real decision-makers who (i) received AI, human, or no advice. The advice (ii) encouraged selfish or prosocial behavior, and decision-makers (iii) behaved selfishly or, in a control condition, behaved prosocially. Evaluators further assigned responsibility to decision-makers and their advisors. Results revealed that (i) prosocial behavior was punished very little, whereas selfish behavior was punished much more. Focusing on selfish behavior, (ii) compared to receiving no advice, selfish behavior was penalized more harshly after prosocial advice and more leniently after selfish advice. Lastly, (iii) whereas selfish decision-makers were seen as more responsible when they followed AI compared to human advice, punishment between the two advice sources did not vary. Overall, behavior and advice content shape punishment, whereas the advice source does not. 

**Abstract (ZH)**: 当人们遵循促进自私行为的AI建议时，他们是如何被评价和惩罚的？：一项结合机器行为和行为经济学方法的预注册实验研究 

---
# Confirmation bias: A challenge for scalable oversight 

**Title (ZH)**: 确认偏差：大规模监督的挑战 

**Authors**: Gabriel Recchia, Chatrik Singh Mangat, Jinu Nyachhyon, Mridul Sharma, Callum Canavan, Dylan Epstein-Gross, Muhammed Abdulbari  

**Link**: [PDF](https://arxiv.org/pdf/2507.19486)  

**Abstract**: Scalable oversight protocols aim to empower evaluators to accurately verify AI models more capable than themselves. However, human evaluators are subject to biases that can lead to systematic errors. We conduct two studies examining the performance of simple oversight protocols where evaluators know that the model is "correct most of the time, but not all of the time". We find no overall advantage for the tested protocols, although in Study 1, showing arguments in favor of both answers improves accuracy in cases where the model is incorrect. In Study 2, participants in both groups become more confident in the system's answers after conducting online research, even when those answers are incorrect. We also reanalyze data from prior work that was more optimistic about simple protocols, finding that human evaluators possessing knowledge absent from models likely contributed to their positive results--an advantage that diminishes as models continue to scale in capability. These findings underscore the importance of testing the degree to which oversight protocols are robust to evaluator biases, whether they outperform simple deference to the model under evaluation, and whether their performance scales with increasing problem difficulty and model capability. 

**Abstract (ZH)**: 可扩展的监督协议旨在赋予评估者准确验证超越他们能力的人工智能模型的权力。然而，人类评估者可能会受到偏见的影响，导致系统性错误。我们进行了两项研究，探讨了评估者知道模型“大部分时间正确，但并不总是正确”的简单监督协议的表现。我们没有发现测试协议的整体优势，但在研究1中，显示支持两个答案的理由可以提高模型错误时的准确性。在研究2中，即使答案是错误的，两组参与者在进行在线研究后对系统的答案也变得更加自信。我们还重新分析了更为乐观的先前工作中关于简单协议的数据，发现拥有模型缺乏的知识的人类评估者可能是其正面结果的原因——这种优势随着模型能力的不断提升而减弱。这些发现强调了测试监督协议对评估者偏见的鲁棒性、其是否在超越评估模型的情况下表现出优势以及其性能随问题难度和模型能力增加是否可扩展的重要性。 

---
# Creativity as a Human Right: Design Considerations for Computational Creativity Systems 

**Title (ZH)**: 创造力作为一种人权：计算创造力系统的设计考量 

**Authors**: Alayt Issak  

**Link**: [PDF](https://arxiv.org/pdf/2507.19485)  

**Abstract**: We investigate creativity that is underlined in the Universal Declaration of Human Rights (UDHR) to present design considerations for Computational Creativity (CC) systems. We find this declaration to describe creativity in salient aspects and bring to light creativity as a Human Right attributed to the Fourth Generation of such rights. This generation of rights attributes CC systems and the evolving nature of interaction with entities of shared intelligence. Our methodology examines five of thirty articles from the UDHR and demonstrates each article with actualizations concluding with design considerations for each. We contribute our findings to ground the relationship between creativity and CC systems. 

**Abstract (ZH)**: 我们在《世界人权宣言》中探讨创造性的内涵，以提出计算创造力（CC）系统的设计 considerations。我们发现此宣言在显著方面描述了创造性，并将其视为第四代人权之一。这一代人权将计算创造力系统及其与共享智能实体互动性质的发展视为重要组成部分。我们的方法研究《世界人权宣言》中三十篇文章中的五篇，并通过实际应用每篇文章，最终提出每篇文章的设计 considerations。我们贡献我们的研究成果，以确立创造力与计算创造力系统之间的关系。 

---
# The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox in Human-AI Cognitive Integration 

**Title (ZH)**: 认知放大架构：增强认知支架作为人类-人工智能认知整合中舒适与成长悖论的解决方案 

**Authors**: Giuseppe Riva  

**Link**: [PDF](https://arxiv.org/pdf/2507.19483)  

**Abstract**: AI systems now function as cognitive extensions, evolving from tools to active cognitive collaborators within human-AI integrated systems. While these systems can amplify cognition - enhancing problem-solving, learning, and creativity - they present a fundamental "comfort-growth paradox": AI's user-friendly nature may foster intellectual stagnation by minimizing cognitive friction necessary for development. As AI aligns with user preferences and provides frictionless assistance, it risks inducing cognitive complacency rather than promoting growth. We introduce Enhanced Cognitive Scaffolding to resolve this paradox - reconceptualizing AI from convenient assistant to dynamic mentor. Drawing from Vygotskian theories, educational scaffolding principles, and AI ethics, our framework integrates three dimensions: (1) Progressive Autonomy, where AI support gradually fades as user competence increases; (2) Adaptive Personalization, tailoring assistance to individual needs and learning trajectories; and (3) Cognitive Load Optimization, balancing mental effort to maximize learning while minimizing unnecessary complexity. Research across educational, workplace, creative, and healthcare domains supports this approach, demonstrating accelerated skill acquisition, improved self-regulation, and enhanced higher-order thinking. The framework includes safeguards against risks like dependency, skill atrophy, and bias amplification. By prioritizing cognitive development over convenience in human-AI interaction, Enhanced Cognitive Scaffolding offers a pathway toward genuinely amplified cognition while safeguarding autonomous thought and continuous learning. 

**Abstract (ZH)**: AI系统现在作为认知扩展发挥作用，从工具演变为人在环AI系统中的主动认知合作者。虽然这些系统能够增强认知，提升解决问题、学习和创新的能力，但它们提出了一个根本的“舒适-成长悖论”：AI友好的特性可能会通过减少必要的认知摩擦，导致认知停滞不前，从而阻碍发展。随着AI倾向于满足用户偏好并提供无摩擦帮助，它可能会引发认知上的安逸而非增长。我们引入了增强的认知支架来解决这一悖论——将AI重新概念化为动态导师，而非方便的助手。我们的框架借鉴了维果茨基理论、教育支架原则和AI伦理，整合了三个维度：（1）逐步自主，随着用户能力的提高，AI支持逐渐减少；（2）适应性个性化，根据个人需求和学习轨迹定制帮助；（3）认知负载优化，平衡心理努力以最大化学习效果并减少不必要的复杂性。在教育、工作场所、创造性活动和医疗保健等多个领域进行的研究支持这一方法，显示加速了技能获取、提高了自我调节能力以及增强了高层次思维。该框架包括了对依赖性、技能萎缩和偏见放大的防范措施。通过在人机交互中优先考虑认知发展而非便捷性，增强的认知支架提供了实现真正增强认知的途径，同时保护自主思考和持续学习。 

---
# Transfer or Self-Supervised? Bridging the Performance Gap in Medical Imaging 

**Title (ZH)**: 迁移学习或自我监督？缩小医疗成像性能差距的方法 

**Authors**: Zehui Zhao, Laith Alzubaidi, Jinglan Zhang, Ye Duan, Usman Naseem, Yuantong Gu  

**Link**: [PDF](https://arxiv.org/pdf/2407.05592)  

**Abstract**: Recently, transfer learning and self-supervised learning have gained significant attention within the medical field due to their ability to mitigate the challenges posed by limited data availability, improve model generalisation, and reduce computational expenses. Transfer learning and self-supervised learning hold immense potential for advancing medical research. However, it is crucial to recognise that transfer learning and self-supervised learning architectures exhibit distinct advantages and limitations, manifesting variations in accuracy, training speed, and robustness. This paper compares the performance and robustness of transfer learning and self-supervised learning in the medical field. Specifically, we pre-trained two models using the same source domain datasets with different pre-training methods and evaluated them on small-sized medical datasets to identify the factors influencing their final performance. We tested data with several common issues in medical domains, such as data imbalance, data scarcity, and domain mismatch, through comparison experiments to understand their impact on specific pre-trained models. Finally, we provide recommendations to help users apply transfer learning and self-supervised learning methods in medical areas, and build more convenient and efficient deployment strategies. 

**Abstract (ZH)**: 近年来，转让学习和自监督学习在医疗领域受到了广泛关注，因其能够缓解数据稀缺带来的挑战、提升模型泛化能力并减少计算成本。转让学习和自监督学习在推动医疗研究方面具有巨大潜力。然而，重要的是要认识到，转让学习和自监督学习架构各自具有不同的优势和局限性，这些差异表现在准确性、训练速度和鲁棒性等方面。本文比较了转让学习和自监督学习在医疗领域的性能和鲁棒性。具体地，我们使用相同的源域数据集和不同的预训练方法预训练了两个模型，并在小规模的医疗数据集上评估它们，以确定影响其最终性能的因素。通过比较实验，我们测试了在医疗领域常见的数据不平衡、数据稀缺和领域不匹配等问题，以了解这些问题对特定预训练模型的影响。最后，我们提供建议以帮助用户在医疗领域应用转让学习和自监督学习方法，并建立更便捷和高效的部署策略。 

---
