{'arxiv_id': 'arXiv:2503.14203', 'title': 'Stochastic Trajectory Prediction under Unstructured Constraints', 'authors': 'Hao Ma, Zhiqiang Pu, Shijie Wang, Boyin Liu, Huimu Wang, Yanyan Liang, Jianqiang Yi', 'link': 'https://arxiv.org/abs/2503.14203', 'abstract': 'Trajectory prediction facilitates effective planning and decision-making, while constrained trajectory prediction integrates regulation into prediction. Recent advances in constrained trajectory prediction focus on structured constraints by constructing optimization objectives. However, handling unstructured constraints is challenging due to the lack of differentiable formal definitions. To address this, we propose a novel method for constrained trajectory prediction using a conditional generative paradigm, named Controllable Trajectory Diffusion (CTD). The key idea is that any trajectory corresponds to a degree of conformity to a constraint. By quantifying this degree and treating it as a condition, a model can implicitly learn to predict trajectories under unstructured constraints. CTD employs a pre-trained scoring model to predict the degree of conformity (i.e., a score), and uses this score as a condition for a conditional diffusion model to generate trajectories. Experimental results demonstrate that CTD achieves high accuracy on the ETH/UCY and SDD benchmarks. Qualitative analysis confirms that CTD ensures adherence to unstructured constraints and can predict trajectories that satisfy combinatorial constraints.', 'abstract_zh': '基于可调控轨迹扩散的约束轨迹预测', 'title_zh': '无结构约束下的随机轨迹预测'}
{'arxiv_id': 'arXiv:2503.14499', 'title': 'Measuring AI Ability to Complete Long Tasks', 'authors': 'Thomas Kwa, Ben West, Joel Becker, Amy Deng, Katharyn Garcia, Max Hasin, Sami Jawhar, Megan Kinniment, Nate Rush, Sydney Von Arx, Ryan Bloom, Thomas Broadley, Haoxing Du, Brian Goodrich, Nikola Jurkovic, Luke Harold Miles, Seraphina Nix, Tao Lin, Neev Parikh, David Rein, Lucas Jun Koba Sato, Hjalmar Wijk, Daniel M. Ziegler, Elizabeth Barnes, Lawrence Chan', 'link': 'https://arxiv.org/abs/2503.14499', 'abstract': "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human capabilities, we propose a new metric: 50%-task-completion time horizon. This is the time humans typically take to complete tasks that AI models can complete with 50% success rate. We first timed humans with relevant domain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter tasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet have a 50% time horizon of around 50 minutes. Furthermore, frontier AI time horizon has been doubling approximately every seven months since 2019, though the trend may have accelerated in 2024. The increase in AI models' time horizons seems to be primarily driven by greater reliability and ability to adapt to mistakes, combined with better logical reasoning and tool use capabilities. We discuss the limitations of our results -- including their degree of external validity -- and the implications of increased autonomy for dangerous capabilities. If these results generalize to real-world software tasks, extrapolation of this trend predicts that within 5 years, AI systems will be capable of automating many software tasks that currently take humans a month.", 'abstract_zh': '尽管在AI基准上取得了快速进展，但基准性能的实际意义仍不清楚。为了用人类能力来量化AI系统的性能，我们提出了一个新的度量标准：50%任务完成时间门槛。这是人类通常完成AI模型以50%成功率能够完成的任务所需的时间。我们首先对具有相关领域专业知识的人类进行了RE-Bench、HCAST组合以及66个新设计的较短任务的时间测量。在这些任务上，当前最前沿的AI模型，如Claude 3.7 Sonnet，50%时间门槛约为50分钟。此外，从2019年起，前沿AI的时间门槛大约每七个月翻一番，尽管这一趋势在2024年可能有所加速。AI模型时间门槛的增加似乎主要由更高的可靠性和适应错误的能力，以及更好的逻辑推理和工具使用能力所驱动。我们讨论了结果的局限性——包括其外部有效性程度——以及自主性增强对危险能力的影响。如果这些结果适用于实际软件任务，那么这一趋势的外推预测，在五年内，AI系统将能够自动化许多目前需要人类一个月时间完成的软件任务。', 'title_zh': '测量AI完成长任务的能力'}
{'arxiv_id': 'arXiv:2503.14194', 'title': 'Driving behavior recognition via self-discovery learning', 'authors': 'Yilin Wang', 'link': 'https://arxiv.org/abs/2503.14194', 'abstract': 'Autonomous driving systems require a deep understanding of human driving behaviors to achieve higher intelligence and this http URL advancements in deep learning, challenges such as long-tail distribution due to scarce samples and confusion from similar behaviors hinder effective driving behavior this http URL methods often fail to address sample confusion adequately, as datasets frequently contain ambiguous samples that obscure unique semantic information.', 'abstract_zh': '自动驾驶系统需要深入理解人类驾驶行为以实现更高的智能，但由于样本稀缺导致的长尾分布问题和类似行为引起的混淆阻碍了有效的驾驶行为学习。现有的方法往往无法充分解决样本混淆问题，因为数据集中经常包含模糊样本，掩盖了独特的语义信息。', 'title_zh': '基于自我发现学习的驾驶行为识别'}
{'arxiv_id': 'arXiv:2503.13771', 'title': 'Towards AI-assisted Academic Writing', 'authors': 'Daniel J. Liebling, Malcolm Kane, Madeleine Grunde-Mclaughlin, Ian J. Lang, Subhashini Venugopalan, Michael P. Brenner', 'link': 'https://arxiv.org/abs/2503.13771', 'abstract': "We present components of an AI-assisted academic writing system including citation recommendation and introduction writing. The system recommends citations by considering the user's current document context to provide relevant suggestions. It generates introductions in a structured fashion, situating the contributions of the research relative to prior work. We demonstrate the effectiveness of the components through quantitative evaluations. Finally, the paper presents qualitative research exploring how researchers incorporate citations into their writing workflows. Our findings indicate that there is demand for precise AI-assisted writing systems and simple, effective methods for meeting those needs.", 'abstract_zh': '我们介绍了一种AI辅助学术写作系统组件，包括引用推荐和引言撰写。该系统通过考虑用户当前文档的上下文来推荐相关的引用。它以结构化的方式自动生成引言，将研究的贡献置于先前工作之中。我们通过定量评估展示了这些组件的有效性。最后，本文呈现了定性研究，探讨研究人员如何将引用融入其写作流程。我们的发现表明，精准的AI辅助写作系统和简单有效的实现方法具有市场需求。', 'title_zh': '面向AI辅助学术写作'}
{'arxiv_id': 'arXiv:2503.13708', 'title': 'A Circular Construction Product Ontology for End-of-Life Decision-Making', 'authors': 'Kwabena Adu-Duodu, Stanly Wilson, Yinhao Li, Aanuoluwapo Oladimeji, Talea Huraysi, Masoud Barati, Charith Perera, Ellis Solaiman, Omer Rana, Rajiv Ranjan, Tejal Shah', 'link': 'https://arxiv.org/abs/2503.13708', 'abstract': "Efficient management of end-of-life (EoL) products is critical for advancing circularity in supply chains, particularly within the construction industry where EoL strategies are hindered by heterogenous lifecycle data and data silos. Current tools like Environmental Product Declarations (EPDs) and Digital Product Passports (DPPs) are limited by their dependency on seamless data integration and interoperability which remain significant challenges. To address these, we present the Circular Construction Product Ontology (CCPO), an applied framework designed to overcome semantic and data heterogeneity challenges in EoL decision-making for construction products. CCPO standardises vocabulary and facilitates data integration across supply chain stakeholders enabling lifecycle assessments (LCA) and robust decision-making. By aggregating disparate data into a unified product provenance, CCPO enables automated EoL recommendations through customisable SWRL rules aligned with European standards and stakeholder-specific circularity SLAs, demonstrating its scalability and integration capabilities. The adopted circular product scenario depicts CCPO's application while competency question evaluations show its superior performance in generating accurate EoL suggestions highlighting its potential to greatly improve decision-making in circular supply chains and its applicability in real-world construction environments.", 'abstract_zh': '高效管理生命周期结束（EoL）产品对于促进供应链中的循环性至关重要，特别是在建筑行业中，由于生命周期数据异构性和数据孤岛，EoL策略受到阻碍。现有的工具如环境产品声明（EPDs）和数字产品护照（DPPs）受限于数据无缝集成和互操作性的依赖，而这一依赖是当前存在的重大挑战。为解决这些挑战，我们提出了循环建筑产品本体（CCPO），这是一种应用于克服EoL决策中建筑产品语义和数据异构性难题的框架。CCPO通过标准化词汇和促进供应链各参与方之间的数据集成，支持生命周期评估（LCA）并实现稳健的决策。通过将分散的数据整合为统一的产品追溯性，CCPO能够通过与欧洲标准和特定利益相关方的循环性SLA对齐的可定制SWRL规则，自动提供EoL建议，展示了其扩展性和集成能力。采用的循环产品情景描绘了CCPO的应用，而专业能力问题评估展示了其在生成准确EoL建议方面的优越性能，强调了其在循环供应链决策中巨大的改进潜力及其在实际建筑环境中的适用性。', 'title_zh': '生命周期决策用的循环构造产品本体'}
{'arxiv_id': 'arXiv:2503.13621', 'title': 'Superalignment with Dynamic Human Values', 'authors': 'Florian Mai, David Kaczér, Nicholas Kluge Corrêa, Lucie Flek', 'link': 'https://arxiv.org/abs/2503.13621', 'abstract': 'Two core challenges of alignment are 1) scalable oversight and 2) accounting for the dynamic nature of human values. While solutions like recursive reward modeling address 1), they do not simultaneously account for 2). We sketch a roadmap for a novel algorithmic framework that trains a superhuman reasoning model to decompose complex tasks into subtasks that are still amenable to human-level guidance. Our approach relies on what we call the part-to-complete generalization hypothesis, which states that the alignment of subtask solutions generalizes to the alignment of complete solutions. We advocate for the need to measure this generalization and propose ways to improve it in the future.', 'abstract_zh': '两种_alignment_对齐的核心挑战是1) 可扩展的监督和2) 考虑人类价值观的动态性质。虽然递归奖励建模等解决方案解决了1)，但并没有同时解决2)。我们勾勒出一种新型算法框架的道路图，该框架训练超级人类推理模型将复杂任务分解为仍可接受人类水平指导的子任务。我们的方法依赖于所谓的从局部到整体的一般化假说，即子任务解决方案的对齐推广到完整解决方案的对齐。我们强调需要衡量这种推广，并提出未来改进的方法。', 'title_zh': '动态人类价值观驱动的超对齐'}
{'arxiv_id': 'arXiv:2503.13489', 'title': 'AI-driven control of bioelectric signalling for real-time topological reorganization of cells', 'authors': 'Gonçalo Hora de Carvalho', 'link': 'https://arxiv.org/abs/2503.13489', 'abstract': 'Understanding and manipulating bioelectric signaling could present a new wave of progress in developmental biology, regenerative medicine, and synthetic biology. Bioelectric signals, defined as voltage gradients across cell membranes caused by ionic movements, play a role in regulating crucial processes including cellular differentiation, proliferation, apoptosis, and tissue morphogenesis. Recent studies demonstrate the ability to modulate these signals to achieve controlled tissue regeneration and morphological outcomes in organisms such as planaria and frogs. However, significant knowledge gaps remain, particularly in predicting and controlling the spatial and temporal dynamics of membrane potentials (V_mem), understanding their regulatory roles in tissue and organ development, and exploring their therapeutic potential in diseases. In this work we propose an experiment using Deep Reinforcement Learning (DRL) framework together with lab automation techniques for real-time manipulation of bioelectric signals to guide tissue regeneration and morphogenesis. The proposed framework should interact continuously with biological systems, adapting strategies based on direct biological feedback. Combining DRL with real-time measurement techniques -- such as optogenetics, voltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could provide a comprehensive platform for precise bioelectric control, leading to improved understanding of bioelectric mechanisms in morphogenesis, quantitative bioelectric models, identification of minimal experimental setups, and advancements in bioelectric modulation techniques relevant to regenerative medicine and cancer therapy. Ultimately, this research aims to utilize bioelectric signaling to develop new biomedical and bioengineering applications.', 'abstract_zh': '理解并操控生物电信号可能在发育生物学、再生医学和合成生物学领域带来新的进展。通过定义为膜内外离子移动产生的电压梯度的生物电信号，在调控细胞分化、增殖、凋亡和组织形态发生等关键过程中发挥作用。近期的研究表明，可以通过调节这些信号实现对平面虫和青蛙等生物体的组织再生和形态学结果的控制。然而，仍然存在许多知识空白，特别是在预测和控制膜电位的空间和时间动态方面，理解它们在组织和器官发育中的调节作用以及探索其在疾病治疗中的潜在疗效方面。本研究提议了一种利用深度强化学习（DRL）框架结合实验室自动化技术对生物电信号进行实时操控的实验方案，以指导组织再生和形态发生。该提议的框架应持续与生物系统互动，根据直接的生物反馈调整策略。结合DRL与实时测量技术（如光遗传学、电压敏感染料、荧光报告基因和高级显微镜技术），可以提供一个综合平台，实现精确的生物电信号控制，从而提高对形态发生中生物电信号机制的理解，建立定量的生物电信号模型，识别最小的实验设置，并推进与再生医学和癌症治疗相关的生物电信号调节技术。最终，该研究旨在利用生物电信号开发新的生物医药和生物工程应用。', 'title_zh': '基于AI的生物电信号控制以实现细胞实时拓扑重组'}
{'arxiv_id': 'arXiv:2503.14469', 'title': 'Attribution Score Alignment in Explainable Data Management', 'authors': 'Felipe Azua, Leopoldo Bertossi', 'link': 'https://arxiv.org/abs/2503.14469', 'abstract': 'Different attribution-scores have been proposed to quantify the relevance of database tuples for a query answer from a database. Among them, we find Causal Responsibility, the Shapley Value, the Banzhaf Power-Index, and the Causal Effect. They have been analyzed in isolation, mainly in terms of computational properties. In this work, we start an investigation into the alignment of these scores on the basis of the queries at hand; that is, on whether they induce compatible rankings of tuples. We are able to identify vast classes of queries for which some pairs of scores are always aligned, and others for which they are not. It turns out that the presence of exogenous tuples makes a crucial difference in this regard.', 'abstract_zh': '基于查询的分数对齐：数据库元组与查询答案相关性的不同归属评分的兼容性分析', 'title_zh': '可解释数据管理中的归因得分对齐'}
{'arxiv_id': 'arXiv:2503.14448', 'title': 'Pauli Network Circuit Synthesis with Reinforcement Learning', 'authors': 'Ayushi Dubal, David Kremer, Simon Martiel, Victor Villar, Derek Wang, Juan Cruz-Benito', 'link': 'https://arxiv.org/abs/2503.14448', 'abstract': 'We introduce a Reinforcement Learning (RL)-based method for re-synthesis of quantum circuits containing arbitrary Pauli rotations alongside Clifford operations. By collapsing each sub-block to a compact representation and then synthesizing it step-by-step through a learned heuristic, we obtain circuits that are both shorter and compliant with hardware connectivity constraints. We find that the method is fast enough and good enough to work as an optimization procedure: in direct comparisons on 6-qubit random Pauli Networks against state-of-the-art heuristic methods, our RL approach yields over 2x reduction in two-qubit gate count, while executing in under 10 milliseconds per circuit. We further integrate the method into a collect-and-re-synthesize pipeline, applied as a Qiskit transpiler pass, where we observe average improvements of 20% in two-qubit gate count and depth, reaching up to 60% for many instances, across the Benchpress benchmark. These results highlight the potential of RL-driven synthesis to significantly improve circuit quality in realistic, large-scale quantum transpilation workloads.', 'abstract_zh': '基于强化学习的任意保罗伊旋转与克利福德操作的量子电路重综合方法', 'title_zh': '使用强化学习的泡利网络电路合成'}
{'arxiv_id': 'arXiv:2503.14412', 'title': 'Iffy-Or-Not: Extending the Web to Support the Critical Evaluation of Fallacious Texts', 'authors': 'Gionnieve Lim, Juho Kim, Simon T. Perrault', 'link': 'https://arxiv.org/abs/2503.14412', 'abstract': "Social platforms have expanded opportunities for deliberation with the comments being used to inform one's opinion. However, using such information to form opinions is challenged by unsubstantiated or false content. To enhance the quality of opinion formation and potentially confer resistance to misinformation, we developed Iffy-Or-Not (ION), a browser extension that seeks to invoke critical thinking when reading texts. With three features guided by argumentation theory, ION highlights fallacious content, suggests diverse queries to probe them with, and offers deeper questions to consider and chat with others about. From a user study (N=18), we found that ION encourages users to be more attentive to the content, suggests queries that align with or are preferable to their own, and poses thought-provoking questions that expands their perspectives. However, some participants expressed aversion to ION due to misalignments with their information goals and thinking predispositions. Potential backfiring effects with ION are discussed.", 'abstract_zh': '社会平台扩展了交流机会，评论被用来形成观点。然而，使用此类信息形成观点受到未经证实或虚假内容的挑战。为了提高观点形成的质量并可能抵御 misinformation，我们开发了Iffy-Or-Not (ION) 浏览器插件，在阅读文本时引发批判性思考。ION通过三种基于论辩理论的特性，突出显示谬误内容，建议多样化的查询来探究这些内容，并提供更深入的问题让用户思考并与其他用户讨论。根据一项用户研究（N=18），我们发现ION促使用户更加注意内容，建议与用户自己的目标和偏好相匹配或更优的问题，并提出引人深思的问题以扩大用户的视角。然而，一些参与者因与他们的信息目标和思维倾向的不一致而对ION表示反感。探讨了ION可能产生的反效果。', 'title_zh': '模棱两可还是可信：扩展web以支持谬误文本的批判性评估'}
{'arxiv_id': 'arXiv:2503.14376', 'title': 'Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels', 'authors': 'Maximilian Beck, Korbinian Pöppel, Phillip Lippe, Sepp Hochreiter', 'link': 'https://arxiv.org/abs/2503.14376', 'abstract': 'Linear RNNs with gating recently demonstrated competitive performance compared to Transformers in language modeling. Although their linear compute scaling in sequence length offers theoretical runtime advantages over Transformers, realizing these benefits in practice requires optimized custom kernels, as Transformers rely on the highly efficient Flash Attention kernels. Leveraging the chunkwise-parallel formulation of linear RNNs, Flash Linear Attention (FLA) shows that linear RNN kernels are faster than Flash Attention, by parallelizing over chunks of the input sequence. However, since the chunk size of FLA is limited, many intermediate states must be materialized in GPU memory. This leads to low arithmetic intensity and causes high memory consumption and IO cost, especially for long-context pre-training. In this work, we present Tiled Flash Linear Attention (TFLA), a novel kernel algorithm for linear RNNs, that enables arbitrary large chunk sizes by introducing an additional level of sequence parallelization within each chunk. First, we apply TFLA to the xLSTM with matrix memory, the mLSTM. Second, we propose an mLSTM variant with sigmoid input gate and reduced computation for even faster kernel runtimes at equal language modeling performance. In our speed benchmarks, we show that our new mLSTM kernels based on TFLA outperform highly optimized Flash Attention, Linear Attention and Mamba kernels, setting a new state of the art for efficient long-context sequence modeling primitives.', 'abstract_zh': '线性RNNs的门控机制在语言建模中 recently demonstrated 与 Transformer 竞争性的性能。尽管线性RNN在序列长度上的线性计算缩放理论上在运行时性能上优于 Transformer，但实现这些优势需要优化的自定义内核，因为 Transformer 依赖于高效的 Flash Attention 内核。利用线性 RNN 的分块并行形式，Flash Linear Attention (FLA) 证明了线性 RNN 内核比 Flash Attention 更快，通过在输入序列的分块上进行并行处理。然而，由于 FLA 的分块大小有限，许多中间状态必须在 GPU 内存中实现，这导致了低算术强度并引起了高内存消耗和 IO 成本，尤其是在长上下文预训练中。在本工作中，我们提出了一种新的线性 RNN 内核算法 Tiled Flash Linear Attention (TFLA)，它通过在每个分块内引入额外的时间并行层次，使分块大小可以任意大。首先，我们将 TFLA 应用于带有矩阵内存的 xLSTM (mLSTM)。其次，我们提出了一个改进的 mLSTM 变体，其具有sigmoid 输入门和减少计算量，以在不降低语言建模性能的情况下实现更快的内核运行时。在我们的速度基准测试中，我们展示了基于 TFLA 的新 mLSTM 内核在效率上优于高度优化的 Flash Attention、Linear Attention 和 Mamba 内核，为高效的长上下文序列建模基本成分设置了新的状态。', 'title_zh': '瓦片闪存线性注意力：更高效的线性RNN和xLSTM内核'}
{'arxiv_id': 'arXiv:2503.14354', 'title': 'Retrospective: A CORDIC Based Configurable Activation Function for NN Applications', 'authors': 'Omkar Kokane, Gopal Raut, Salim Ullah, Mukul Lokhande, Adam Teman, Akash Kumar, Santosh Kumar Vishvakarma', 'link': 'https://arxiv.org/abs/2503.14354', 'abstract': 'A CORDIC-based configuration for the design of Activation Functions (AF) was previously suggested to accelerate ASIC hardware design for resource-constrained systems by providing functional reconfigurability. Since its introduction, this new approach for neural network acceleration has gained widespread popularity, influencing numerous designs for activation functions in both academic and commercial AI processors. In this retrospective analysis, we explore the foundational aspects of this initiative, summarize key developments over recent years, and introduce the DA-VINCI AF tailored for the evolving needs of AI applications. This new generation of dynamically configurable and precision-adjustable activation function cores promise greater adaptability for a range of activation functions in AI workloads, including Swish, SoftMax, SeLU, and GeLU, utilizing the Shift-and-Add CORDIC technique. The previously presented design has been optimized for MAC, Sigmoid, and Tanh functionalities and incorporated into ReLU AFs, culminating in an accumulative NEURIC compute unit. These enhancements position NEURIC as a fundamental component in the resource-efficient vector engine for the realization of AI accelerators that focus on DNNs, RNNs/LSTMs, and Transformers, achieving a quality of results (QoR) of 98.5%.', 'abstract_zh': '基于CORDIC的配置方法在资源受限系统中加速ASIC硬件设计，并提供了功能可重构性，用于激活函数（AF）的设计。从这一新方法引入以来，该方法在神经网络加速领域受到了广泛关注，并影响了众多学术和商业AI处理器中的激活函数设计。在本文回顾分析中，我们探讨了这一倡议的基础方面，总结了近年来的关键发展，并介绍了针对AI应用不断变化需求定制的DA-VINCI AF。这种新一代动态配置和精度可调的激活函数核心，为包括Swish、SoftMax、SeLU和GeLU在内的各种AI工作负载中的激活函数提供了更大的适应性，利用了Shift-and-Add CORDIC技术。之前提出的该设计已被优化用于MAC、Sigmoid和Tanh功能，并整合到ReLU AFs中，最终形成一个累积的NEURIC计算单元。这些改进使NEURIC成为能够高效实现专注于DNN、RNN/LSTMs和Transformers的AI加速器的基础组件之一，实现了一种结果质量（QoR）为98.5%的矢量引擎。', 'title_zh': '回顾：基于CORDIC的可配置激活函数在神经网络中的应用'}
{'arxiv_id': 'arXiv:2503.14345', 'title': 'MoonCast: High-Quality Zero-Shot Podcast Generation', 'authors': 'Zeqian Ju, Dongchao Yang, Jianwei Yu, Kai Shen, Yichong Leng, Zhengtao Wang, Xu Tan, Xinyu Zhou, Tao Qin, Xiangyang Li', 'link': 'https://arxiv.org/abs/2503.14345', 'abstract': 'Recent advances in text-to-speech synthesis have achieved notable success in generating high-quality short utterances for individual speakers. However, these systems still face challenges when extending their capabilities to long, multi-speaker, and spontaneous dialogues, typical of real-world scenarios such as podcasts. These limitations arise from two primary challenges: 1) long speech: podcasts typically span several minutes, exceeding the upper limit of most existing work; 2) spontaneity: podcasts are marked by their spontaneous, oral nature, which sharply contrasts with formal, written contexts; existing works often fall short in capturing this spontaneity. In this paper, we propose MoonCast, a solution for high-quality zero-shot podcast generation, aiming to synthesize natural podcast-style speech from text-only sources (e.g., stories, technical reports, news in TXT, PDF, or Web URL formats) using the voices of unseen speakers. To generate long audio, we adopt a long-context language model-based audio modeling approach utilizing large-scale long-context speech data. To enhance spontaneity, we utilize a podcast generation module to generate scripts with spontaneous details, which have been empirically shown to be as crucial as the text-to-speech modeling itself. Experiments demonstrate that MoonCast outperforms baselines, with particularly notable improvements in spontaneity and coherence.', 'abstract_zh': 'Recent Advances in High-Quality Zero-Shot Podcast Generation', 'title_zh': 'MoonCast：高品质零样本播客生成'}
{'arxiv_id': 'arXiv:2503.14341', 'title': 'Spatio-Temporal Graph Neural Networks for Infant Language Acquisition Prediction', 'authors': 'Andrew Roxburgh, Floriana Grasso, Terry R. Payne', 'link': 'https://arxiv.org/abs/2503.14341', 'abstract': 'Predicting the words that a child is going to learn next can be useful for boosting language acquisition, and such predictions have been shown to be possible with both neural network techniques (looking at changes in the vocabulary state over time) and graph model (looking at data pertaining to the relationships between words). However, these models do not fully capture the complexity of the language learning process of an infant when used in isolation. In this paper, we examine how a model of language acquisition for infants and young children can be constructed and adapted for use in a Spatio-Temporal Graph Convolutional Network (STGCN), taking into account the different types of linguistic relationships that occur during child language learning. We introduce a novel approach for predicting child vocabulary acquisition, and evaluate the efficacy of such a model with respect to the different types of linguistic relationships that occur during language acquisition, resulting in insightful observations on model calibration and norm selection. An evaluation of this model found that the mean accuracy of models for predicting new words when using sensorimotor relationships (0.733) and semantic relationships (0.729) were found to be superior to that observed with a 2-layer Feed-forward neural network. Furthermore, the high recall for some relationships suggested that some relationships (e.g. visual) were superior in identifying a larger proportion of relevant words that a child should subsequently learn than others (such as auditory).', 'abstract_zh': '婴儿语言习得中即将学习词汇的预测：基于时空图卷积网络的方法', 'title_zh': '婴儿语言习得的空间-时间图神经网络预测'}
{'arxiv_id': 'arXiv:2503.14321', 'title': 'COPA: Comparing the Incomparable to Explore the Pareto Front', 'authors': 'Adrián Javaloy, Antonio Vergari, Isabel Valera', 'link': 'https://arxiv.org/abs/2503.14321', 'abstract': 'In machine learning (ML), it is common to account for multiple objectives when, e.g., selecting a model to deploy. However, it is often unclear how one should compare, aggregate and, ultimately, trade-off these objectives, as they might be measured in different units or scales. For example, when deploying large language models (LLMs), we might not only care about their performance, but also their CO2 consumption. In this work, we investigate how objectives can be sensibly compared and aggregated to navigate their Pareto front. To do so, we propose to make incomparable objectives comparable via their CDFs, approximated by their relative rankings. This allows us to aggregate them while matching user-specific preferences, allowing practitioners to meaningfully navigate and search for models in the Pareto front. We demonstrate the potential impact of our methodology in diverse areas such as LLM selection, domain generalization, and AutoML benchmarking, where classical ways to aggregate and normalize objectives fail.', 'abstract_zh': '在机器学习中，当选择要部署的模型时，通常需要考虑多个目标。然而，很难明确如何比较、聚合和最终权衡这些目标，因为它们可能以不同的单位或尺度进行衡量。例如，在部署大型语言模型时，我们不仅关注其性能，也可能关注其二氧化碳排放。在本工作中，我们调查了如何合理比较和聚合这些目标以导航其帕累托前沿。为此，我们提出通过相对排名近似累积分布函数（CDF）将不可比的目标变得可比，从而在满足用户特定偏好的情况下聚合这些目标，使实践者能够有意义地导航和搜索帕累托前沿中的模型。我们展示了我们方法论在大型语言模型选择、领域泛化和AutoML基准测试等不同领域的潜在影响，而传统的目标聚合和归一化方法在此类领域常常失效。', 'title_zh': 'COPA: 比较不可比较的以探索帕累托前沿'}
{'arxiv_id': 'arXiv:2503.14293', 'title': 'Ensemble Knowledge Distillation for Machine Learning Interatomic Potentials', 'authors': 'Sakib Matin, Emily Shinkle, Yulia Pimonova, Galen T. Craven, Ying Wai Li, Kipton Barros, Nicholas Lubbers', 'link': 'https://arxiv.org/abs/2503.14293', 'abstract': 'Machine learning interatomic potentials (MLIPs) are a promising tool to accelerate atomistic simulations and molecular property prediction. The quality of MLIPs strongly depends on the quantity of available training data as well as the quantum chemistry (QC) level of theory used to generate that data. Datasets generated with high-fidelity QC methods, such as coupled cluster, are typically restricted to small molecules and may be missing energy gradients. With this limited quantity of data, it is often difficult to train good MLIP models. We present an ensemble knowledge distillation (EKD) method to improve MLIP accuracy when trained to energy-only datasets. In our EKD approach, first, multiple teacher models are trained to QC energies and then used to generate atomic forces for all configurations in the dataset. Next, a student MLIP is trained to both QC energies and to ensemble-averaged forces generated by the teacher models. We apply this workflow on the ANI-1ccx dataset which consists of organic molecules with configuration energies computed at the coupled cluster level of theory. The resulting student MLIPs achieve new state-of-the-art accuracy on the out-of-sample COMP6 benchmark and improved stability for molecular dynamics simulations. The EKD approach for MLIP is broadly applicable for chemical, biomolecular and materials science simulations.', 'abstract_zh': '机器学习键间势（MLIPs）是加速原子尺度模拟和分子性质预测的有前途的工具。MLIPs的质量强烈取决于可用训练数据的数量以及用于生成这些数据的量子化学（QC）理论水平。使用高保真QC方法生成的数据集通常仅限于小分子，并且可能缺少能量梯度。在这种有限的数据量下，训练良好的MLIP模型往往具有挑战性。我们提出了一种集成知识蒸馏（EKD）方法，以提高基于仅能量数据集训练的MLIP的准确性。在我们的EKD方法中，首先训练多个教师模型以生成QC能量，然后用于生成数据集中所有配置的原子力。接着，训练一个学生MLIP，使其不仅针对QC能量，还针对由教师模型生成的集成平均力进行训练。我们将此工作流程应用于包含在耦合簇理论水平上计算有机关能的ANI-1ccx数据集。所得到的学生MLIPs在out-of-sample COMP6基准测试中实现了新的最先进准确性，并提高了分子动力学模拟的稳定性。MLIP的EKD方法广泛适用于化学、生物分子和材料科学模拟。', 'title_zh': '群体知识精炼用于机器学习原子势能'}
{'arxiv_id': 'arXiv:2503.14258', 'title': 'JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System', 'authors': 'Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, Changyue Wang, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu', 'link': 'https://arxiv.org/abs/2503.14258', 'abstract': 'This paper introduces JuDGE (Judgment Document Generation Evaluation), a novel benchmark for evaluating the performance of judgment document generation in the Chinese legal system. We define the task as generating a complete legal judgment document from the given factual description of the case. To facilitate this benchmark, we construct a comprehensive dataset consisting of factual descriptions from real legal cases, paired with their corresponding full judgment documents, which serve as the ground truth for evaluating the quality of generated documents. This dataset is further augmented by two external legal corpora that provide additional legal knowledge for the task: one comprising statutes and regulations, and the other consisting of a large collection of past judgment documents. In collaboration with legal professionals, we establish a comprehensive automated evaluation framework to assess the quality of generated judgment documents across various dimensions. We evaluate various baseline approaches, including few-shot in-context learning, fine-tuning, and a multi-source retrieval-augmented generation (RAG) approach, using both general and legal-domain LLMs. The experimental results demonstrate that, while RAG approaches can effectively improve performance in this task, there is still substantial room for further improvement. All the codes and datasets are available at: this https URL.', 'abstract_zh': '这篇文章介绍了JuDGE（判决文书生成评估），一个用于评估中国法律体系中判决文书生成性能的新基准。我们定义任务是从给定的案件事实描述生成完整的法律判决文书。为了创建这一基准，我们构建了一个综合数据集，其中包括来自实际法律案件的事实描述及其对应的完整判决文书，这些文书作为生成文档质量的基准。此外，我们还通过两个外部法律语料库对数据集进行了扩充，提供了任务所需的额外法律知识：一个包含 statutes 和 regulations，另一个包含大量的以往判决文书。在法律专业人士的协助下，我们建立了一个全面的自动化评估框架，从多个维度评估生成判决文书的质量。我们使用通用和法律领域的大规模语言模型（LLM）评价了几种基线方法，包括少样本上下文学习、微调和多源检索增强生成（RAG）方法。实验结果表明，虽然 RAG 方法在此任务中能有效提高性能，但仍有很大的改进空间。所有代码和数据集都可以在以下链接获取：this https URL。', 'title_zh': 'JuDGE: 中国法律体系中判决文书生成的基准评估'}
{'arxiv_id': 'arXiv:2503.14246', 'title': 'Trading-off Accuracy and Communication Cost in Federated Learning', 'authors': 'Mattia Jacopo Villani, Emanuele Natale, Frederik Mallmann-Trenn', 'link': 'https://arxiv.org/abs/2503.14246', 'abstract': "Leveraging the training-by-pruning paradigm introduced by Zhou et al. and Isik et al. introduced a federated learning protocol that achieves a 34-fold reduction in communication cost. We achieve a compression improvements of orders of orders of magnitude over the state-of-the-art. The central idea of our framework is to encode the network weights $\\vec w$ by a the vector of trainable parameters $\\vec p$, such that $\\vec w = Q\\cdot \\vec p$ where $Q$ is a carefully-generate sparse random matrix (that remains fixed throughout training). In such framework, the previous work of Zhou et al. [NeurIPS'19] is retrieved when $Q$ is diagonal and $\\vec p$ has the same dimension of $\\vec w$. We instead show that $\\vec p$ can effectively be chosen much smaller than $\\vec w$, while retaining the same accuracy at the price of a decrease of the sparsity of $Q$. Since server and clients only need to share $\\vec p$, such a trade-off leads to a substantial improvement in communication cost. Moreover, we provide theoretical insight into our framework and establish a novel link between training-by-sampling and random convex geometry.", 'abstract_zh': '利用周等人和伊西等人提出的剪枝培训范式，我们提出了一种联邦学习协议，实现了通信成本34倍的减少。我们的框架通过将网络权重$\\vec{w}$编码为可训练参数向量$\\vec{p}$，即$\\vec{w} = Q \\cdot \\vec{p}$，其中$Q$是一个精心生成的稀疏随机矩阵（在整个训练过程中保持不变），实现了比现有最佳方法多个数量级的压缩改进。我们证明$\\vec{p}$可以显著小于$\\vec{w}$，同时保持相同的精度，代价是$Q$的稀疏度降低。由于服务器和客户端只需要共享$\\vec{p}$，这种权衡导致了通信成本的显著降低。此外，我们提供了对框架的理论见解，并建立了采样训练与随机凸几何之间的新联系。', 'title_zh': '在联邦学习中权衡准确性和通信成本'}
{'arxiv_id': 'arXiv:2503.14192', 'title': 'Strategic White Paper on AI Infrastructure for Particle, Nuclear, and Astroparticle Physics: Insights from JENA and EuCAIF', 'authors': 'Sascha Caron, Andreas Ipp, Gert Aarts, Gábor Bíró, Daniele Bonacorsi, Elena Cuoco, Caterina Doglioni, Tommaso Dorigo, Julián García Pardiñas, Stefano Giagu, Tobias Golling, Lukas Heinrich, Ik Siong Heng, Paula Gina Isar, Karolos Potamianos, Liliana Teodorescu, John Veitch, Pietro Vischia, Christoph Weniger', 'link': 'https://arxiv.org/abs/2503.14192', 'abstract': 'Artificial intelligence (AI) is transforming scientific research, with deep learning methods playing a central role in data analysis, simulations, and signal detection across particle, nuclear, and astroparticle physics. Within the JENA communities-ECFA, NuPECC, and APPEC-and as part of the EuCAIF initiative, AI integration is advancing steadily. However, broader adoption remains constrained by challenges such as limited computational resources, a lack of expertise, and difficulties in transitioning from research and development (R&D) to production. This white paper provides a strategic roadmap, informed by a community survey, to address these barriers. It outlines critical infrastructure requirements, prioritizes training initiatives, and proposes funding strategies to scale AI capabilities across fundamental physics over the next five years.', 'abstract_zh': '人工智能（AI）正在变革科学研究，深度学习方法在粒子、核物理和 Astrophysics 中的数据分析、模拟和信号检测中发挥着核心作用。在 JENA 社区-ECFA、NuPECC 和 APPEC 内，并作为 EuCAIF 初级阶段的一部分，AI 的整合正在稳步前进。然而，更广泛的应用仍受计算资源有限、缺乏专业技能以及从研发（R&D）向生产过渡困难的制约。本白皮书根据社区调查提供了一项战略路线图，旨在解决这些障碍，概述了关键的基础设施需求，优先提出了培训计划，并提出了资金策略，以在未来五年内扩大基本物理领域的人工智能能力。', 'title_zh': 'AI基础设施战略白皮书：来自JENA和EuCAIF的见解'}
{'arxiv_id': 'arXiv:2503.14125', 'title': 'Frac-Connections: Fractional Extension of Hyper-Connections', 'authors': 'Defa Zhu, Hongzhi Huang, Jundong Zhou, Zihao Huang, Yutao Zeng, Banggu Wu, Qiyang Min, Xun Zhou', 'link': 'https://arxiv.org/abs/2503.14125', 'abstract': 'Residual connections are central to modern deep learning architectures, enabling the training of very deep networks by mitigating gradient vanishing. Hyper-Connections recently generalized residual connections by introducing multiple connection strengths at different depths, thereby addressing the seesaw effect between gradient vanishing and representation collapse. However, Hyper-Connections increase memory access costs by expanding the width of hidden states. In this paper, we propose Frac-Connections, a novel approach that divides hidden states into multiple parts rather than expanding their width. Frac-Connections retain partial benefits of Hyper-Connections while reducing memory consumption. To validate their effectiveness, we conduct large-scale experiments on language tasks, with the largest being a 7B MoE model trained on up to 3T tokens, demonstrating that Frac-Connections significantly outperform residual connections.', 'abstract_zh': 'Frac-Connections: Dividing Hidden States Instead of Expanding Width to Mitigate Gradient Vanishing and Representation Collapse', 'title_zh': '分数连接：超连接的分数扩展'}
{'arxiv_id': 'arXiv:2503.14109', 'title': 'Operational Change Detection for Geographical Information: Overview and Challenges', 'authors': 'Nicolas Gonthier', 'link': 'https://arxiv.org/abs/2503.14109', 'abstract': 'Rapid evolution of territories due to climate change and human impact requires prompt and effective updates to geospatial databases maintained by the National Mapping Agency. This paper presents a comprehensive overview of change detection methods tailored for the operational updating of large-scale geographic databases. This review first outlines the fundamental definition of change, emphasizing its multifaceted nature, from temporal to semantic characterization. It categorizes automatic change detection methods into four main families: rule-based, statistical, machine learning, and simulation methods. The strengths, limitations, and applicability of every family are discussed in the context of various input data. Then, key applications for National Mapping Agencies are identified, particularly the optimization of geospatial database updating, change-based phenomena, and dynamics monitoring. Finally, the paper highlights the current challenges for leveraging change detection such as the variability of change definition, the missing of relevant large-scale datasets, the diversity of input data, the unstudied no-change detection, the human in the loop integration and the operational constraints. The discussion underscores the necessity for ongoing innovation in change detection techniques to address the future needs of geographic information systems for national mapping agencies.', 'abstract_zh': '由于气候变化和人类影响导致的领土快速演变要求国家测绘机构及时更新地理空间数据库。本文概述了适用于大规模地理数据库操作更新的变化检测方法。本文首先定义变化的内涵，强调其多维特性，并从时间到语义进行分类。随后将自动变化检测方法分类为四大家族：规则基方法、统计方法、机器学习方法和模拟方法，并在不同输入数据的背景下讨论了每种方法的优势、局限性和适用性。接着，本文确定了国家测绘机构的关键应用，特别是地理空间数据库更新优化、基于变化的现象和动态监测。最后，本文指出现行变化检测面临的挑战，包括变化定义的变异性、相关大规模数据集的缺乏、输入数据的多样性、未研究的无变化检测、人工参与以及操作约束。讨论强调了在地理信息系统未来需求下持续创新变化检测技术的必要性。', 'title_zh': '地理信息中运营变化检测：综述与挑战'}
{'arxiv_id': 'arXiv:2503.14106', 'title': 'Reliable uncertainty quantification for 2D/3D anatomical landmark localization using multi-output conformal prediction', 'authors': 'Jef Jonkers, Frank Coopman, Luc Duchateau, Glenn Van Wallendael, Sofie Van Hoecke', 'link': 'https://arxiv.org/abs/2503.14106', 'abstract': 'Automatic anatomical landmark localization in medical imaging requires not just accurate predictions but reliable uncertainty quantification for effective clinical decision support. Current uncertainty quantification approaches often fall short, particularly when combined with normality assumptions, systematically underestimating total predictive uncertainty. This paper introduces conformal prediction as a framework for reliable uncertainty quantification in anatomical landmark localization, addressing a critical gap in automatic landmark localization. We present two novel approaches guaranteeing finite-sample validity for multi-output prediction: Multi-output Regression-as-Classification Conformal Prediction (M-R2CCP) and its variant Multi-output Regression to Classification Conformal Prediction set to Region (M-R2C2R). Unlike conventional methods that produce axis-aligned hyperrectangular or ellipsoidal regions, our approaches generate flexible, non-convex prediction regions that better capture the underlying uncertainty structure of landmark predictions. Through extensive empirical evaluation across multiple 2D and 3D datasets, we demonstrate that our methods consistently outperform existing multi-output conformal prediction approaches in both validity and efficiency. This work represents a significant advancement in reliable uncertainty estimation for anatomical landmark localization, providing clinicians with trustworthy confidence measures for their diagnoses. While developed for medical imaging, these methods show promise for broader applications in multi-output regression problems.', 'abstract_zh': '自动解剖标志定位在医学影像中的自动化过程中，不仅需要准确的预测，还需要可靠的不确定性量化以提供有效的临床决策支持。当前的不确定性量化方法往往存在不足，特别是在与正态性假设结合使用时，系统性地低估了预测的总不确定性。本文介绍了一致预测作为一种框架，用于解剖标志定位中的可靠不确定性量化，填补了自动解剖标志定位中的关键空白。我们提出了两种保证小样本有效的多输出预测新方法：多输出回归分类一致预测（M-R2CCP）及其变种多输出回归到分类一致预测设定区域（M-R2C2R）。与传统方法生成的轴对齐的超矩形或椭球区域不同，我们的方法生成灵活的、非凸的预测区域，更好地捕捉了解剖标志预测的不确定性结构。通过在多个2D和3D数据集上的广泛实证评估，我们证明了我们的方法在有效性和效率上始终优于现有的多输出一致预测方法。这项工作代表了解剖标志定位中可靠不确定性估计的重大进展，为临床诊断提供了值得信赖的信心度量。虽然这些方法是为医学影像开发的，但它们在多输出回归问题中的应用前景广阔。', 'title_zh': '基于多输出符合预测的2D/3D解剖标志局部化可靠不确定性量化'}
{'arxiv_id': 'arXiv:2503.14102', 'title': 'Sensory-driven microinterventions for improved health and wellbeing', 'authors': 'Youssef Abdalla, Elia Gatti, Mine Orlu, Marianna Obrist', 'link': 'https://arxiv.org/abs/2503.14102', 'abstract': "The five senses are gateways to our wellbeing and their decline is considered a significant public health challenge which is linked to multiple conditions that contribute significantly to morbidity and mortality. Modern technology, with its ubiquitous nature and fast data processing has the ability to leverage the power of the senses to transform our approach to day to day healthcare, with positive effects on our quality of life. Here, we introduce the idea of sensory-driven microinterventions for preventative, personalised healthcare. Microinterventions are targeted, timely, minimally invasive strategies that seamlessly integrate into our daily life. This idea harnesses human's sensory capabilities, leverages technological advances in sensory stimulation and real-time processing ability for sensing the senses. The collection of sensory data from our continuous interaction with technology - for example the tone of voice, gait movement, smart home behaviour - opens up a shift towards personalised technology-enabled, sensory-focused healthcare interventions, coupled with the potential of early detection and timely treatment of sensory deficits that can signal critical health insights, especially for neurodegenerative diseases such as Parkinson's disease.", 'abstract_zh': '五感是我们健康的门户，其衰退被视为与多种导致高疾病负担和高死亡率条件相关的重大公共健康挑战。现代技术的广泛存在和快速数据处理能力能够利用感官认知的力量，改变我们日常健康护理的方法，从而改善生活质量。在此，我们提出了基于感官认知的微干预理念，以实现预防性和个性化的健康护理。微干预是精准、及时且微创的策略，能够无缝融入日常生活。这一理念利用了人类的感官认知能力，借助于感知识觉的技术进步和实时处理能力。通过连续与技术交互收集的感官数据——例如语音的音调、步态移动、智能家居行为等——为个性化技术驱动、感观测知的健康护理干预打开了新的可能性，特别是在早期检测和及时治疗神经退行性疾病如帕金森病等关键健康指标方面。', 'title_zh': '基于感觉的微干预以改善健康和福祉'}
{'arxiv_id': 'arXiv:2503.14088', 'title': 'Toward Large-Scale Distributed Quantum Long Short-Term Memory with Modular Quantum Computers', 'authors': 'Kuan-Cheng Chen, Samuel Yen-Chi Chen, Chen-Yu Liu, Kin K. Leung', 'link': 'https://arxiv.org/abs/2503.14088', 'abstract': 'In this work, we introduce a Distributed Quantum Long Short-Term Memory (QLSTM) framework that leverages modular quantum computing to address scalability challenges on Noisy Intermediate-Scale Quantum (NISQ) devices. By embedding variational quantum circuits into LSTM cells, the QLSTM captures long-range temporal dependencies, while a distributed architecture partitions the underlying Variational Quantum Circuits (VQCs) into smaller, manageable subcircuits that can be executed on a network of quantum processing units. We assess the proposed framework using nontrivial benchmark problems such as damped harmonic oscillators and Nonlinear Autoregressive Moving Average sequences. Our results demonstrate that the distributed QLSTM achieves stable convergence and improved training dynamics compared to classical approaches. This work underscores the potential of modular, distributed quantum computing architectures for large-scale sequence modelling, providing a foundation for the future integration of hybrid quantum-classical solutions into advanced Quantum High-performance computing (HPC) ecosystems.', 'abstract_zh': '基于模块化量子计算的分布式量子长短期记忆(QLSTM)框架：针对Noisy Intermediate-Scale Quantum (NISQ)设备的可扩展性挑战', 'title_zh': '面向模块化量子计算机的大规模分布式量子长短期记忆'}
{'arxiv_id': 'arXiv:2503.14076', 'title': 'Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency', 'authors': 'Jiangxuan Long, Zhao Song, Chiwun Yang', 'link': 'https://arxiv.org/abs/2503.14076', 'abstract': 'Recent studies suggest utilizing generative models instead of traditional auto-regressive algorithms for time series forecasting (TSF) tasks. These non-auto-regressive approaches involving different generative methods, including GAN, Diffusion, and Flow Matching for time series, have empirically demonstrated high-quality generation capability and accuracy. However, we still lack an appropriate understanding of how it processes approximation and generalization. This paper presents the first theoretical framework from the perspective of flow-based generative models to relieve the knowledge of limitations. In particular, we provide our insights with strict guarantees from three perspectives: $\\textbf{Approximation}$, $\\textbf{Generalization}$ and $\\textbf{Efficiency}$. In detail, our analysis achieves the contributions as follows:\n$\\bullet$ By assuming a general data model, the fitting of the flow-based generative models is confirmed to converge to arbitrary error under the universal approximation of Diffusion Transformer (DiT).\n$\\bullet$ Introducing a polynomial-based regularization for flow matching, the generalization error thus be bounded since the generalization of polynomial approximation.\n$\\bullet$ The sampling for generation is considered as an optimization process, we demonstrate its fast convergence with updating standard first-order gradient descent of some objective.', 'abstract_zh': '近期研究表明，利用生成模型而非传统自回归算法进行时间序列预测（TSF）任务可能是更好的选择。这些非自回归方法，包括基于生成方法的时间序列生成（如GAN、Diffusion和Flow Matching），在实践中展示了高质量的生成能力和准确性。然而，关于其在逼近和泛化方面的处理机制，我们仍然缺乏深刻的理解。本文首次从流基生成模型的视角提出了理论框架，以清晰地理解其局限性。特别地，我们从逼近、泛化和效率三个角度来看待这一问题，提供严格保证以达成以下贡献：\n- 假设一般数据模型，流基生成模型的拟合在扩散变换器（DiT）的通用逼近下可确保任意误差下的收敛。\n- 引入基于多项式的正则化方法，通过对多项式逼近的泛化误差进行边界约束。\n- 将生成的采样视为优化过程，展示了通过更新某些目标的标准一阶梯度下降能够实现快速收敛。', 'title_zh': '基于流的方法的时间序列生成的理论基础：可证明的逼近、泛化和效率'}
{'arxiv_id': 'arXiv:2503.14053', 'title': 'ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors', 'authors': 'Jake Rap, Amritam Das', 'link': 'https://arxiv.org/abs/2503.14053', 'abstract': 'Accurate traffic flow estimation and prediction are critical for the efficient management of transportation systems, particularly under increasing urbanization. Traditional methods relying on static sensors often suffer from limited spatial coverage, while probe vehicles provide richer, albeit sparse and irregular data. This work introduces ON-Traffic, a novel deep operator Network and a receding horizon learning-based framework tailored for online estimation of spatio-temporal traffic state along with quantified uncertainty by using measurements from moving probe vehicles and downstream boundary inputs. Our framework is evaluated in both numerical and simulation datasets, showcasing its ability to handle irregular, sparse input data, adapt to time-shifted scenarios, and provide well-calibrated uncertainty estimates. The results demonstrate that the model captures complex traffic phenomena, including shockwaves and congestion propagation, while maintaining robustness to noise and sensor dropout. These advancements present a significant step toward online, adaptive traffic management systems.', 'abstract_zh': '准确的交通流估计与预测对于高效管理交通系统至关重要，尤其是在城市化进程加快的情况下。传统的依赖静态传感器的方法往往覆盖范围有限，而探针车辆提供了更为丰富但稀疏且不规则的数据。本研究引入了ON-Traffic，这是一种针对移动探针车辆测量和下游边界输入数据的新型深度算子网络和基于回溯窗口的学习框架，用于在线估计时空交通状态并量化不确定性。该框架在数值和仿真数据集上进行了评估，展现了其处理不规则且稀疏输入数据、适应时间移位场景以及提供校准良好的不确定性估计的能力。结果表明，该模型能够捕捉复杂的交通现象，包括冲击波和拥堵传播，并保持对噪声和传感器丢失的鲁棒性。这些进步为实现在线自适应交通管理系统迈出了重要一步。', 'title_zh': 'ON-交通：基于拉格朗日传感器的在线交通流估计及不确定性量化操作员学习框架'}
{'arxiv_id': 'arXiv:2503.13999', 'title': 'BI-RADS prediction of mammographic masses using uncertainty information extracted from a Bayesian Deep Learning model', 'authors': 'Mohaddeseh Chegini, Ali Mahloojifar', 'link': 'https://arxiv.org/abs/2503.13999', 'abstract': 'The BI_RADS score is a probabilistic reporting tool used by radiologists to express the level of uncertainty in predicting breast cancer based on some morphological features in mammography images. There is a significant variability in describing masses which sometimes leads to BI_RADS misclassification. Using a BI_RADS prediction system is required to support the final radiologist decisions. In this study, the uncertainty information extracted by a Bayesian deep learning model is utilized to predict the BI_RADS score. The investigation results based on the pathology information demonstrate that the f1-scores of the predictions of the radiologist are 42.86%, 48.33% and 48.28%, meanwhile, the f1-scores of the model performance are 73.33%, 59.60% and 59.26% in the BI_RADS 2, 3 and 5 dataset samples, respectively. Also, the model can distinguish malignant from benign samples in the BI_RADS 0 category of the used dataset with an accuracy of 75.86% and correctly identify all malignant samples as BI_RADS 5. The Grad-CAM visualization shows the model pays attention to the morphological features of the lesions. Therefore, this study shows the uncertainty-aware Bayesian Deep Learning model can report his uncertainty about the malignancy of a lesion based on morphological features, like a radiologist.', 'abstract_zh': '基于贝叶斯深度学习的BI_RADS评分不确定性预测研究', 'title_zh': '使用贝叶斯深度学习模型提取的不确定性信息预测BI-RADS乳腺肿块等级'}
{'arxiv_id': 'arXiv:2503.13921', 'title': 'Learning Accurate Models on Incomplete Data with Minimal Imputation', 'authors': 'Cheng Zhen, Nischal Aryal, Arash Termehchy, Prayoga, Garrett Biwer, Sankalp Patil', 'link': 'https://arxiv.org/abs/2503.13921', 'abstract': 'Missing data often exists in real-world datasets, requiring significant time and effort for imputation to learn accurate machine learning (ML) models. In this paper, we demonstrate that imputing all missing values is not always necessary to achieve an accurate ML model. We introduce the concept of minimal data imputation, which ensures accurate ML models trained over the imputed dataset. Implementing minimal imputation guarantees both minimal imputation effort and optimal ML models. We propose algorithms to find exact and approximate minimal imputation for various ML models. Our extensive experiments indicate that our proposed algorithms significantly reduce the time and effort required for data imputation.', 'abstract_zh': '缺失数据在现实世界的数据集中普遍存在，要求投入大量时间与 effort 进行插补以学习准确的机器学习模型。本文表明，为了获得准确的机器学习模型，并非必须插补所有缺失值。我们提出了最小数据插补的概念，该概念确保在插补数据集上训练的模型具有准确性。最小插补实施保证了最少的插补 effort 和优化的机器学习模型。我们提出了适用于各种机器学习模型的精确和近似最小插补算法。大量的实验表明，我们提出的算法显著减少了数据插补所需的时间和 effort。', 'title_zh': '在最少填充缺失值的情况下学习准确模型'}
{'arxiv_id': 'arXiv:2503.13915', 'title': 'Unlocking the Potential of Unlabeled Data in Semi-Supervised Domain Generalization', 'authors': 'Dongkwan Lee, Kyomin Hwang, Nojun Kwak', 'link': 'https://arxiv.org/abs/2503.13915', 'abstract': "We address the problem of semi-supervised domain generalization (SSDG), where the distributions of train and test data differ, and only a small amount of labeled data along with a larger amount of unlabeled data are available during training. Existing SSDG methods that leverage only the unlabeled samples for which the model's predictions are highly confident (confident-unlabeled samples), limit the full utilization of the available unlabeled data. To the best of our knowledge, we are the first to explore a method for incorporating the unconfident-unlabeled samples that were previously disregarded in SSDG setting. To this end, we propose UPCSC to utilize these unconfident-unlabeled samples in SSDG that consists of two modules: 1) Unlabeled Proxy-based Contrastive learning (UPC) module, treating unconfident-unlabeled samples as additional negative pairs and 2) Surrogate Class learning (SC) module, generating positive pairs for unconfident-unlabeled samples using their confusing class set. These modules are plug-and-play and do not require any domain labels, which can be easily integrated into existing approaches. Experiments on four widely used SSDG benchmarks demonstrate that our approach consistently improves performance when attached to baselines and outperforms competing plug-and-play methods. We also analyze the role of our method in SSDG, showing that it enhances class-level discriminability and mitigates domain gaps. The code is available at this https URL.", 'abstract_zh': '我们探讨了半监督领域泛化（SSDG）问题，其中训练和测试数据的分布不同，仅在训练过程中获得少量标记数据和大量未标记数据。现有的SSDG方法仅利用模型预测信心高的未标记样本（信心高未标记样本），限制了可用未标记数据的全面利用。据我们所知，我们是第一个探索将之前在SSDG设置中忽略的不信心未标记样本整合进来的方法。为此，我们提出UPCSC以利用这些不信心未标记样本，该方法包含两个模块：1) 不信心未标记样本基于代理的对比学习（UPC）模块，将不信心未标记样本视为额外的负样本配对，2) 替代类别学习（SC）模块，使用其混淆类别集为不信心未标记样本生成正样本配对。这些模块插即用且无需领域标签，可轻松集成到现有方法中。我们在四个广泛使用的SSDG基准上的实验表明，当附加到基线方法时，我们的方法始终可以提高性能，并优于其他插即用方法。我们还分析了该方法在SSDG中的作用，表明它增强了类别层面的可区分性和缓解了领域差距。代码可在以下链接获取。', 'title_zh': '解锁未标注数据在半监督领域泛化中的潜力'}
{'arxiv_id': 'arXiv:2503.13912', 'title': 'KANITE: Kolmogorov-Arnold Networks for ITE estimation', 'authors': 'Eshan Mehendale, Abhinav Thorat, Ravi Kolla, Niranjan Pedanekar', 'link': 'https://arxiv.org/abs/2503.13912', 'abstract': "We introduce KANITE, a framework leveraging Kolmogorov-Arnold Networks (KANs) for Individual Treatment Effect (ITE) estimation under multiple treatments setting in causal inference. By utilizing KAN's unique abilities to learn univariate activation functions as opposed to learning linear weights by Multi-Layer Perceptrons (MLPs), we improve the estimates of ITEs. The KANITE framework comprises two key architectures: this http URL Probability Metric (IPM) architecture: This employs an IPM loss in a specialized manner to effectively align towards ITE estimation across multiple treatments. 2. Entropy Balancing (EB) architecture: This uses weights for samples that are learned by optimizing entropy subject to balancing the covariates across treatment groups. Extensive evaluations on benchmark datasets demonstrate that KANITE outperforms state-of-the-art algorithms in both $\\epsilon_{\\text{PEHE}}$ and $\\epsilon_{\\text{ATE}}$ metrics. Our experiments highlight the advantages of KANITE in achieving improved causal estimates, emphasizing the potential of KANs to advance causal inference methodologies across diverse application areas.", 'abstract_zh': 'KANITE：一种利用Kolmogorov-Arnold网络(KANs)进行多处理设置下个体治疗效果(ITE)估计的框架', 'title_zh': 'KANITE: Kolmogorov-Arnold 网络用于估计 Individual Treatment Effect'}
{'arxiv_id': 'arXiv:2503.13868', 'title': 'Out-of-Distribution Generalization in Time Series: A Survey', 'authors': 'Xin Wu, Fei Teng, Xingwang Li, Ji Zhang, Tianrui Li, Qiang Duan', 'link': 'https://arxiv.org/abs/2503.13868', 'abstract': "Time series frequently manifest distribution shifts, diverse latent features, and non-stationary learning dynamics, particularly in open and evolving environments. These characteristics pose significant challenges for out-of-distribution (OOD) generalization. While substantial progress has been made, a systematic synthesis of advancements remains lacking. To address this gap, we present the first comprehensive review of OOD generalization methodologies for time series, organized to delineate the field's evolutionary trajectory and contemporary research landscape. We organize our analysis across three foundational dimensions: data distribution, representation learning, and OOD evaluation. For each dimension, we present several popular algorithms in detail. Furthermore, we highlight key application scenarios, emphasizing their real-world impact. Finally, we identify persistent challenges and propose future research directions. A detailed summary of the methods reviewed for the generalization of OOD in time series can be accessed at this https URL.", 'abstract_zh': '时间序列数据经常表现出分布偏移、潜藏特征的多样性以及非平稳的学习动态，尤其是在开放和发展的环境中。这些特性为开集外样本泛化提出了重大挑战。尽管已经取得显著进展，但这些进展的系统综述仍然缺失。为填补这一空白，我们首次全面综述了时间序列开集外样本泛化的方法，旨在梳理该领域的演进轨迹和当前研究景观。我们从三个基本维度组织分析：数据分布、表示学习和开集外评估。在每个维度中，我们详细介绍了几种流行算法。此外，我们还强调了关键的应用场景，突显其实用价值。最后，我们识别了持续存在的挑战并提出未来研究方向。所评审的方法的详细总结可在此处访问：this https URL', 'title_zh': '时间序列数据外部分布泛化综述'}
{'arxiv_id': 'arXiv:2503.13844', 'title': 'Spotting Persuasion: A Low-cost Model for Persuasion Detection in Political Ads on Social Media', 'authors': 'Elyas Meguellati, Stefano Civelli, Pietro Bernardelle, Shazia Sadiq, Gianluca Demartini', 'link': 'https://arxiv.org/abs/2503.13844', 'abstract': 'In the realm of political advertising, persuasion operates as a pivotal element within the broader framework of propaganda, exerting profound influences on public opinion and electoral outcomes. In this paper, we (1) introduce a lightweight model for persuasive text detection that achieves state-of-the-art performance in Subtask 3 of SemEval 2023 Task 3, while significantly reducing the computational resource requirements; and (2) leverage the proposed model to gain insights into political campaigning strategies on social media platforms by applying it to a real-world dataset we curated, consisting of Facebook political ads from the 2022 Australian Federal election campaign. Our study shows how subtleties can be found in persuasive political advertisements and presents a pragmatic approach to detect and analyze such strategies with limited resources, enhancing transparency in social media political campaigns.', 'abstract_zh': '在政治广告领域，说服作为宣传更大框架中的关键元素，对公众意见和选举结果产生了深远影响。本文（1）介绍了一种轻量级的说服文本检测模型，在SemEval 2023 Task 3 Subtask 3中实现了最先进的性能，同时显著降低了计算资源需求；（2）利用所提出模型通过将其应用于我们编纂的一个实际数据集——2022年澳大利亚联邦选举活动中的Facebook政治广告——来洞察社交媒体平台上的政治竞选策略。我们的研究展示了说服性政治广告中的微妙之处，并提供了一种在有限资源条件下检测和分析这些策略的实用方法，从而增强社交媒体政治竞选的透明度。', 'title_zh': '识别说服力：一种低成本的政治广告说服检测模型在社交媒体上的应用'}
{'arxiv_id': 'arXiv:2503.13842', 'title': 'Counterfactual experience augmented off-policy reinforcement learning', 'authors': 'Sunbowen Lee, Yicheng Gong, Chao Deng', 'link': 'https://arxiv.org/abs/2503.13842', 'abstract': "Reinforcement learning control algorithms face significant challenges due to out-of-distribution and inefficient exploration problems. While model-based reinforcement learning enhances the agent's reasoning and planning capabilities by constructing virtual environments, training such virtual environments can be very complex. In order to build an efficient inference model and enhance the representativeness of learning data, we propose the Counterfactual Experience Augmentation (CEA) algorithm. CEA leverages variational autoencoders to model the dynamic patterns of state transitions and introduces randomness to model non-stationarity. This approach focuses on expanding the learning data in the experience pool through counterfactual inference and performs exceptionally well in environments that follow the bisimulation assumption. Environments with bisimulation properties are usually represented by discrete observation and action spaces, we propose a sampling method based on maximum kernel density estimation entropy to extend CEA to various environments. By providing reward signals for counterfactual state transitions based on real information, CEA constructs a complete counterfactual experience to alleviate the out-of-distribution problem of the learning data, and outperforms general SOTA algorithms in environments with difference properties. Finally, we discuss the similarities, differences and properties of generated counterfactual experiences and real experiences. The code is available at this https URL.", 'abstract_zh': '基于反事实经验增强的强化学习控制算法面临出分布和探索效率的问题，模型化强化学习通过构建虚拟环境提升智能体的推理和规划能力，但训练虚拟环境非常复杂。为构建高效的推理模型并增强学习数据的代表性，我们提出了反事实经验增强(CEA)算法。CEA利用变异自编码器建模状态转换的动态模式，并引入随机性建模非平稳性。该方法通过反事实推理扩展经验池中的学习数据，并且在遵循bisimulation假设的环境中表现优异。具有bisimulation特性的环境通常由离散的观测空间和动作空间表示，我们提出了基于最大核密度估计熵的采样方法，将CEA扩展到各种环境。通过基于真实信息为反事实状态转换提供奖励信号，CEA构建完整的反事实经验，缓解学习数据的出分布问题，并在具有不同特性的环境中优于一般SOTA算法。最后，讨论生成的反事实经验和真实经验的相似性、差异性和特性。相关代码可在以下网址获取。', 'title_zh': '事实假设增强的off-policy强化学习'}
{'arxiv_id': 'arXiv:2503.13799', 'title': 'SMILE: a Scale-aware Multiple Instance Learning Method for Multicenter STAS Lung Cancer Histopathology Diagnosis', 'authors': 'Liangrui Pan, Xiaoyu Li, Yutao Dou, Qiya Song, Jiadi Luo, Qingchun Liang, Shaoliang Peng', 'link': 'https://arxiv.org/abs/2503.13799', 'abstract': 'Spread through air spaces (STAS) represents a newly identified aggressive pattern in lung cancer, which is known to be associated with adverse prognostic factors and complex pathological features. Pathologists currently rely on time consuming manual assessments, which are highly subjective and prone to variation. This highlights the urgent need for automated and precise diag nostic solutions. 2,970 lung cancer tissue slides are comprised from multiple centers, re-diagnosed them, and constructed and publicly released three lung cancer STAS datasets: STAS CSU (hospital), STAS TCGA, and STAS CPTAC. All STAS datasets provide corresponding pathological feature diagnoses and related clinical data. To address the bias, sparse and heterogeneous nature of STAS, we propose an scale-aware multiple instance learning(SMILE) method for STAS diagnosis of lung cancer. By introducing a scale-adaptive attention mechanism, the SMILE can adaptively adjust high attention instances, reducing over-reliance on local regions and promoting consistent detection of STAS lesions. Extensive experiments show that SMILE achieved competitive diagnostic results on STAS CSU, diagnosing 251 and 319 STAS samples in CPTAC andTCGA,respectively, surpassing clinical average AUC. The 11 open baseline results are the first to be established for STAS research, laying the foundation for the future expansion, interpretability, and clinical integration of computational pathology technologies. The datasets and code are available at this https URL.', 'abstract_zh': '通过空气空间传播的肺癌新识别的侵袭性模式： Scale-aware Multiple Instance Learning (SMILE) 方法在肺癌STAS诊断中的应用', 'title_zh': 'SMILE：一种面向尺度的多实例学习方法用于多中心STAS肺癌组织学诊断'}
{'arxiv_id': 'arXiv:2503.13798', 'title': 'AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach', 'authors': 'Amirhossein Khakpour, Lucia Florescu, Richard Tilley, Haibo Jiang, K. Swaminathan Iyer, Gustavo Carneiro', 'link': 'https://arxiv.org/abs/2503.13798', 'abstract': 'The clinical translation of nanoparticle-based treatments remains limited due to the unpredictability of (nanoparticle) NP pharmacokinetics$\\unicode{x2014}$how they distribute, accumulate, and clear from the body. Predicting these behaviours is challenging due to complex biological interactions and the difficulty of obtaining high-quality experimental datasets. Existing AI-driven approaches rely heavily on data-driven learning but fail to integrate crucial knowledge about NP properties and biodistribution mechanisms. We introduce a multi-view deep learning framework that enhances pharmacokinetic predictions by incorporating prior knowledge of key NP properties such as size and charge into a cross-attention mechanism, enabling context-aware feature selection and improving generalization despite small datasets. To further enhance prediction robustness, we employ an ensemble learning approach, combining deep learning with XGBoost (XGB) and Random Forest (RF), which significantly outperforms existing AI models. Our interpretability analysis reveals key physicochemical properties driving NP biodistribution, providing biologically meaningful insights into possible mechanisms governing NP behaviour in vivo rather than a black-box model. Furthermore, by bridging machine learning with physiologically based pharmacokinetic (PBPK) modelling, this work lays the foundation for data-efficient AI-driven drug discovery and precision nanomedicine.', 'abstract_zh': '基于纳米颗粒的治疗方法的临床转化受限于纳米颗粒药代动力学的不可预测性——它们在体内的分布、累积和清除。由于生物相互作用的复杂性和高质量实验数据集获取的难度，预测这些行为具有挑战性。现有的AI驱动方法高度依赖数据驱动的学习，但未能整合关于纳米颗粒性质和生物分布机制的关键知识。我们介绍了一种多视图深度学习框架，通过将关键纳米颗粒属性（如大小和电荷）的先验知识整合到交叉注意力机制中，增强药代动力学预测，即使在小数据集的情况下也能实现上下文感知特征选择并提升泛化能力。为进一步增强预测稳健性，我们采用集成学习方法，结合深度学习与XGBoost (XGB) 和随机森林 (RF)，该方法显著优于现有AI模型。我们的可解释性分析揭示了驱动纳米颗粒生物分布的关键物理化学特性，提供了生物学意义深刻的理解，以解释在体内可能调控纳米颗粒行为的机制，而非仅依赖黑盒模型。此外，通过将机器学习与基于生理学的药代动力学 (PBPK) 模型相结合，本工作为数据高效的AI驱动药物发现和精准纳米医学奠定了基础。', 'title_zh': '基于AI的纳米粒子药代动力学预测：一种多视图学习方法'}
{'arxiv_id': 'arXiv:2503.13786', 'title': 'Evaluating the Application of SOLID Principles in Modern AI Framework Architectures', 'authors': 'Jonesh Shrestha', 'link': 'https://arxiv.org/abs/2503.13786', 'abstract': 'This research evaluates the extent to which modern AI frameworks, specifically TensorFlow and scikit-learn, adhere to the SOLID design principles - Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, and Dependency Inversion. Analyzing the frameworks architectural documentation and design philosophies, this research investigates architectural trade-offs when balancing software engineering best practices with AI-specific needs. I examined each frameworks documentation, source code, and architectural components to evaluate their adherence to these principles. The results show that both frameworks adopt certain aspects of SOLID design principles but make intentional trade-offs to address performance, scalability, and the experimental nature of AI development. TensorFlow focuses on performance and scalability, sometimes sacrificing strict adherence to principles like Single Responsibility and Interface Segregation. While scikit-learns design philosophy aligns more closely with SOLID principles through consistent interfaces and composition principles, sticking closer to SOLID guidelines but with occasional deviations for performance optimizations and scalability. This research discovered that applying SOLID principles in AI frameworks depends on context, as performance, scalability, and flexibility often require deviations from traditional software engineering principles. This research contributes to understanding how domain-specific constraints influence architectural decisions in modern AI frameworks and how these frameworks strategically adapted design choices to effectively balance these contradicting requirements.', 'abstract_zh': '本研究评估了现代AI框架TensorFlow和scikit-learn在SOLID设计原则方面的遵守程度——单一职责、开闭原则、里氏替换原则、接口隔离原则和依赖倒置原则。通过对这些框架的架构文档和设计哲学进行分析，本研究探讨了在平衡软件工程最佳实践与AI特定需求时的架构权衡。本研究详细检查了每个框架的文档、源代码和架构组件，以评估其对这些原则的遵守情况。研究结果表明，两个框架在某些方面采用了SOLID设计原则，但在性能、可扩展性和AI开发的实验性方面做出了有意的权衡。TensorFlow侧重于性能和可扩展性，有时会牺牲严格遵守单一职责和接口隔离等原则。scikit-learn的设计哲学更接近SOLID原则，通过一致的接口和组合原则更加贴近SOLID指导方针，但在性能优化和可扩展性方面偶尔会偏离这些指导方针。本研究发现，在AI框架中应用SOLID原则取决于具体环境，因为性能、可扩展性和灵活性往往需要偏离传统的软件工程原则。本研究有助于理解特定领域约束条件如何影响现代AI框架的架构决策，并探讨这些框架如何战略性地调整设计选择以有效平衡这些相矛盾的需求。', 'title_zh': '评估SOLID原则在现代AI框架架构中的应用'}
{'arxiv_id': 'arXiv:2503.13751', 'title': 'Optimizing ML Training with Metagradient Descent', 'authors': 'Logan Engstrom, Andrew Ilyas, Benjamin Chen, Axel Feldmann, William Moses, Aleksander Madry', 'link': 'https://arxiv.org/abs/2503.13751', 'abstract': 'A major challenge in training large-scale machine learning models is configuring the training process to maximize model performance, i.e., finding the best training setup from a vast design space. In this work, we unlock a gradient-based approach to this problem. We first introduce an algorithm for efficiently calculating metagradients -- gradients through model training -- at scale. We then introduce a "smooth model training" framework that enables effective optimization using metagradients. With metagradient descent (MGD), we greatly improve on existing dataset selection methods, outperform accuracy-degrading data poisoning attacks by an order of magnitude, and automatically find competitive learning rate schedules.', 'abstract_zh': '大规模机器学习模型训练中的一个主要挑战是配置训练过程以最大化模型性能，即从广阔的设计空间中找到最佳的训练设置。在这项工作中，我们解锁了一种基于梯度的方法来解决这个问题。我们首先介绍了一种高效计算元梯度的算法——即通过模型训练的梯度。然后，我们引入了一种“平滑模型训练”框架，该框架利用元梯度实现有效的优化。借助元梯度下降（MGD），我们显著改进了现有的数据集选择方法，在准确率下降的数据中毒攻击中表现出了十倍以上的优越性，并自动找到了具有竞争力的学习率调度方案。', 'title_zh': '利用元梯度下降优化机器学习训练'}
{'arxiv_id': 'arXiv:2503.13578', 'title': 'Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor', 'authors': 'Benoît Savoini, Jonathan Bertolaccini, Stéphane Montavon, Michel Deriaz', 'link': 'https://arxiv.org/abs/2503.13578', 'abstract': 'Lameness and gait irregularities are significant concerns in equine health management, affecting performance, welfare, and economic value. Traditional observational methods rely on subjective expert assessments, which can lead to inconsistencies in detecting subtle or early-stage lameness. While AI-based approaches have emerged, many require multiple sensors, force plates, or video systems, making them costly and impractical for field deployment. In this applied research study, we present a stride-level classification system that utilizes a single inertial measurement unit (IMU) and a one-dimensional convolutional neural network (1D CNN) to objectively differentiate between sound and lame horses, with a primary focus on the trot gait. The proposed system was tested under real-world conditions, achieving a 90% session-level accuracy with no false positives, demonstrating its robustness for practical applications. By employing a single, non-intrusive, and readily available sensor, our approach significantly reduces the complexity and cost of hardware requirements while maintaining high classification performance. These results highlight the potential of our CNN-based method as a field-tested, scalable solution for automated lameness detection. By enabling early diagnosis, this system offers a valuable tool for preventing minor gait irregularities from developing into severe conditions, ultimately contributing to improved equine welfare and performance in veterinary and equestrian practice.', 'abstract_zh': '蹄病和步态异常是马匹健康管理中的重要关切，影响性能、福利和经济价值。传统观察方法依赖于主观专家评估，可能导致在检测细微或早期蹄病时产生不一致性。尽管基于AI的方法已经出现，但许多方法需要多个传感器、压力板或视频系统，使其在实地部署中成本高昂且不实用。在本应用研究中，我们提出了一种基于步幅的分类系统，该系统利用单一惯性测量单元（IMU）和一维卷积神经网络（1D CNN）客观地区分健康和蹄病马匹，主要集中在整理步态上。所提出的系统在实际条件下进行了测试，各会话准确率达到90%，无假阳性，证明其适用于实际应用的鲁棒性。通过使用单一、非侵入性且易于获取的传感器，本方法显著降低了硬件需求的复杂性和成本，同时保持了高分类性能。这些结果突显了我们基于CNN的方法作为一种经过实地测试、可扩展的自动化蹄病检测解决方案的潜力。通过早期诊断，该系统为防止步态异常发展成严重状况提供了有价值的工具，最终有助于提高兽医和马术实践中马匹的福利和性能。', 'title_zh': '使用加速度传感器早期检测马匹跛行和异常行为的卷积神经网络'}
{'arxiv_id': 'arXiv:2503.13570', 'title': 'ExChanGeAI: An End-to-End Platform and Efficient Foundation Model for Electrocardiogram Analysis and Fine-tuning', 'authors': 'Lucas Bickmann, Lucas Plagwitz, Antonius Büscher, Lars Eckardt, Julian Varghese', 'link': 'https://arxiv.org/abs/2503.13570', 'abstract': 'Electrocardiogram data, one of the most widely available biosignal data, has become increasingly valuable with the emergence of deep learning methods, providing novel insights into cardiovascular diseases and broader health conditions. However, heterogeneity of electrocardiogram formats, limited access to deep learning model weights and intricate algorithmic steps for effective fine-tuning for own disease target labels result in complex workflows. In this work, we introduce ExChanGeAI, a web-based end-to-end platform that streamlines the reading of different formats, pre-processing, visualization and custom machine learning with local and privacy-preserving fine-tuning. ExChanGeAI is adaptable for use on both personal computers and scalable to high performance server environments. The platform offers state-of-the-art deep learning models for training from scratch, alongside our novel open-source electrocardiogram foundation model CardX, pre-trained on over one million electrocardiograms. Evaluation across three external validation sets, including an entirely new testset extracted from routine care, demonstrate the fine-tuning capabilities of ExChanGeAI. CardX outperformed the benchmark foundation model while requiring significantly fewer parameters and lower computational resources. The platform enables users to empirically determine the most suitable model for their specific tasks based on systematic this http URL code is available at this https URL .', 'abstract_zh': '电 cardio  图数据，作为一种最为广泛可用的生物信号数据，随着深度学习方法的出现，其价值日益凸显，为心血管疾病及其他更广泛健康状况提供了新的见解。然而，电 cardio  图格式的异质性、深度学习模型权重获取的有限性以及有效微调算法步骤的复杂性导致了复杂的工作流程。在本文中，我们介绍了 ExChanGeAI，一个基于 Web 的端到端平台，该平台简化了不同格式的读取、预处理、可视化和本地及隐私保护的微调，并具备自定义机器学习功能。ExChanGeAI 既适用于个人计算机，又可扩展到高性能服务器环境。该平台提供了最先进的深度学习模型以从头开始训练，同时附带了我们全新的开源电 cardio  图基础模型 CardX，该模型在超过一百万份电 cardio  图上进行了预训练。通过三个外部验证集的评估，包括从常规护理中提取的全新测试集，证明了 ExChanGeAI 的微调能力。CardX 在参数量和计算资源需求方面优于基准基础模型。该平台使用户能够根据系统性的实证分析确定最适合其特定任务的模型。相关代码可在https://github.com/ExChanGeAI/CardX 获取。', 'title_zh': 'ExChanGeAI：心电图分析与微调的一站式平台及高效基础模型'}
{'arxiv_id': 'arXiv:2503.13562', 'title': 'Micro Text Classification Based on Balanced Positive-Unlabeled Learning', 'authors': 'Lin-Han Jia, Lan-Zhe Guo, Zhi Zhou, Si-Ye Han, Zi-Wen Li, Yu-Feng Li', 'link': 'https://arxiv.org/abs/2503.13562', 'abstract': "In real-world text classification tasks, negative texts often contain a minimal proportion of negative content, which is especially problematic in areas like text quality control, legal risk screening, and sensitive information interception. This challenge manifests at two levels: at the macro level, distinguishing negative texts is difficult due to the high similarity between coarse-grained positive and negative samples; at the micro level, the issue stems from extreme class imbalance and a lack of fine-grained labels. To address these challenges, we propose transforming the coarse-grained positive-negative (PN) classification task into an imbalanced fine-grained positive-unlabeled (PU) classification problem, supported by theoretical analysis. We introduce a novel framework, Balanced Fine-Grained Positive-Unlabeled (BFGPU) learning, which features a unique PU learning loss function that optimizes macro-level performance amidst severe imbalance at the micro level. The framework's performance is further boosted by rebalanced pseudo-labeling and threshold adjustment. Extensive experiments on both public and real-world datasets demonstrate the effectiveness of BFGPU, which outperforms other methods, even in extreme scenarios where both macro and micro levels are highly imbalanced.", 'abstract_zh': '在现实世界文本分类任务中，负面文本往往包含极少比例的负面内容，这在文本质量控制、法律风险筛查和敏感信息拦截等领域尤为成问题。这一挑战在宏观和微观两个层面表现出来：在宏观层面，由于粗粒度正负样本高度相似，区分负面文本极为困难；在微观层面，由于类别极度不平衡和缺乏细粒度标签，问题更为突出。为应对这些挑战，我们提出将粗粒度正负（PN）分类任务转化为正未知样本（PU）分类的不平衡细粒度分类问题，并通过理论分析支持这一转化。我们引入了一种新框架——平衡细粒度正未知样本（BFGPU）学习，该框架包含一个独特的PU学习损失函数，能够在微观层面极度不平衡的情况下优化宏观性能。框架性能进一步通过重新平衡伪标签和阈值调整得以提升。大量实验证明，BFGPU在公共和实际数据集上均表现出色，即使在宏观和微观层面都极度不平衡的情况下，它仍优于其他方法。', 'title_zh': '基于平衡正样例-未标注样例学习的微文本分类'}
{'arxiv_id': 'arXiv:2503.13558', 'title': 'Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life', 'authors': 'Jingyuan Xue, Longfei Wei, Fang Sheng, Yuxin Gao, Jianfei Zhang', 'link': 'https://arxiv.org/abs/2503.13558', 'abstract': "The accurate prediction of RUL for lithium-ion batteries is crucial for enhancing the reliability and longevity of energy storage systems. Traditional methods for RUL prediction often struggle with issues such as data sparsity, varying battery chemistries, and the inability to capture complex degradation patterns over time. In this study, we propose a survival analysis-based framework combined with deep learning models to predict the RUL of lithium-ion batteries. Specifically, we utilize five advanced models: the Cox-type models (Cox, CoxPH, and CoxTime) and two machine-learning-based models (DeepHit and MTLR). These models address the challenges of accurate RUL estimation by transforming raw time-series battery data into survival data, including key degradation indicators such as voltage, current, and internal resistance. Advanced feature extraction techniques enhance the model's robustness in diverse real-world scenarios, including varying charging conditions and battery chemistries. Our models are tested using 10-fold cross-validation, ensuring generalizability and minimizing overfitting. Experimental results show that our survival-based framework significantly improves RUL prediction accuracy compared to traditional methods, providing a reliable tool for battery management and maintenance optimization. This study contributes to the advancement of predictive maintenance in battery technology, offering valuable insights for both researchers and industry practitioners aiming to enhance the operational lifespan of lithium-ion batteries.", 'abstract_zh': '锂离子电池剩余使用寿命的准确预测对于提高能量存储系统的可靠性和寿命至关重要。传统的方法在处理数据稀疏性、电池化学差异以及无法捕捉复杂的时间退化模式方面往往存在困难。在此研究中，我们提出了一种基于生存分析的框架结合深度学习模型来预测锂离子电池的剩余使用寿命。具体地，我们利用五种先进的模型：Cox类型的模型（Cox、CoxPH和CoxTime）和两种机器学习基于的模型（DeepHit和MTLR）。这些模型通过将原始的时间序列电池数据转换为包括电压、电流和内阻等关键退化指标的生存数据，来解决准确剩余使用寿命估计的挑战。先进的特征提取技术增强了模型在不同实际场景中的鲁棒性，包括变化的充电条件和电池化学。我们的模型通过10折交叉验证进行测试，确保了泛化能力和减少了过拟合。实验结果表明，基于生存分析的框架显著提升了剩余使用寿命预测的准确性，提供了一种用于电池管理和维护优化的可靠工具。本研究为电池技术的预测性维护的进步做出了贡献，为希望提高锂离子电池运营寿命的研究人员和行业实践者提供了宝贵的见解。', 'title_zh': '基于机器学习的生存分析方法在预测锂离子电池剩余使用寿命中的应用'}
{'arxiv_id': 'arXiv:2503.13557', 'title': 'APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games', 'authors': 'Yifei Chen, Lambert Schomaker', 'link': 'https://arxiv.org/abs/2503.13557', 'abstract': "Studies in reward shaping for reinforcement learning (RL) have flourished in recent years due to its ability to speed up training. Our previous work proposed an adaptive potential function (APF) and showed that APF can accelerate the Q-learning with a Multi-layer Perceptron algorithm in the low-dimensional domain. This paper proposes to extend APF with an encoder (APF+) for RL state representation, allowing applying APF to the pixel-based Atari games using a state-encoding method that projects high-dimensional game's pixel frames to low-dimensional embeddings. We approach by designing the state-representation encoder as a W-shaped network (W-Net), by using which we are able to encode both the background as well as the moving entities in the game frames. Specifically, the embeddings derived from the pre-trained W-Net consist of two latent vectors: One represents the input state, and the other represents the deviation of the input state's representation from itself. We then incorporate W-Net into APF to train a downstream Dueling Deep Q-Network (DDQN), obtain the APF-WNet-DDQN, and demonstrate its effectiveness in Atari game-playing tasks. To evaluate the APF+W-Net module in such high-dimensional tasks, we compare with two types of baseline methods: (i) the basic DDQN; and (ii) two encoder-replaced APF-DDQN methods where we replace W-Net by (a) an unsupervised state representation method called Spatiotemporal Deep Infomax (ST-DIM) and (b) a ground truth state representation provided by the Atari Annotated RAM Interface (ARI). The experiment results show that out of 20 Atari games, APF-WNet-DDQN outperforms DDQN (14/20 games) and APF-STDIM-DDQN (13/20 games) significantly. In comparison against the APF-ARI-DDQN which employs embeddings directly of the detailed game-internal state information, the APF-WNet-DDQN achieves a comparable performance.", 'abstract_zh': '奖励塑造在强化学习中的研究：基于编码器的自适应潜力函数在像素基 Atari 游戏中的应用', 'title_zh': 'APF+: 用于高维游戏的W形网络增强自适应势能函数强化学习方法'}
{'arxiv_id': 'arXiv:2503.13550', 'title': 'Towards Privacy-Preserving Data-Driven Education: The Potential of Federated Learning', 'authors': 'Mohammad Khalil, Ronas Shakya, Qinyi Liu', 'link': 'https://arxiv.org/abs/2503.13550', 'abstract': 'The increasing adoption of data-driven applications in education such as in learning analytics and AI in education has raised significant privacy and data protection concerns. While these challenges have been widely discussed in previous works, there are still limited practical solutions. Federated learning has recently been discoursed as a promising privacy-preserving technique, yet its application in education remains scarce. This paper presents an experimental evaluation of federated learning for educational data prediction, comparing its performance to traditional non-federated approaches. Our findings indicate that federated learning achieves comparable predictive accuracy. Furthermore, under adversarial attacks, federated learning demonstrates greater resilience compared to non-federated settings. We summarise that our results reinforce the value of federated learning as a potential approach for balancing predictive performance and privacy in educational contexts.', 'abstract_zh': '数据驱动的应用在教育领域，如学习分析和教育中的AI日益普及，引发了重要的隐私和数据保护问题。尽管这些挑战在以往的研究中得到了广泛讨论，但仍然缺乏实际解决方案。联邦学习最近被公认为一种有前景的隐私保护技术，但在教育中的应用仍较为有限。本文对联邦学习在教育数据预测中的实验效果进行了评价，并将其性能与传统的非联邦方法进行了对比。研究结果表明，联邦学习实现了可比的预测准确性。此外，在对抗攻击下，联邦学习表现出比非联邦设置更高的鲁棒性。我们总结认为，我们的研究结果强化了联邦学习在平衡教育情境下的预测性能和隐私方面的潜在价值。', 'title_zh': '面向隐私保护的数据驱动教育：联邦学习的潜力'}
{'arxiv_id': 'arXiv:2503.13548', 'title': 'Fuzzy Rule-based Differentiable Representation Learning', 'authors': 'Wei Zhang, Zhaohong Deng, Guanjin Wang, Kup-Sze Choi', 'link': 'https://arxiv.org/abs/2503.13548', 'abstract': "Representation learning has emerged as a crucial focus in machine and deep learning, involving the extraction of meaningful and useful features and patterns from the input data, thereby enhancing the performance of various downstream tasks such as classification, clustering, and prediction. Current mainstream representation learning methods primarily rely on non-linear data mining techniques such as kernel methods and deep neural networks to extract abstract knowledge from complex datasets. However, most of these methods are black-box, lacking transparency and interpretability in the learning process, which constrains their practical utility. To this end, this paper introduces a novel representation learning method grounded in an interpretable fuzzy rule-based model. Specifically, it is built upon the Takagi-Sugeno-Kang fuzzy system (TSK-FS) to initially map input data to a high-dimensional fuzzy feature space through the antecedent part of the TSK-FS. Subsequently, a novel differentiable optimization method is proposed for the consequence part learning which can preserve the model's interpretability and transparency while further exploring the nonlinear relationships within the data. This optimization method retains the essence of traditional optimization, with certain parts of the process parameterized corresponding differentiable modules constructed, and a deep optimization process implemented. Consequently, this method not only enhances the model's performance but also ensures its interpretability. Moreover, a second-order geometry preservation method is introduced to further improve the robustness of the proposed method. Extensive experiments conducted on various benchmark datasets validate the superiority of the proposed method, highlighting its potential for advancing representation learning methodologies.", 'abstract_zh': '基于可解释模糊规则模型的表示学习方法', 'title_zh': '基于模糊规则的可微表示学习'}
{'arxiv_id': 'arXiv:2503.13546', 'title': 'CNCast: Leveraging 3D Swin Transformer and DiT for Enhanced Regional Weather Forecasting', 'authors': 'Hongli Liang, Yuanting Zhang, Qingye Meng, Shuangshuang He, Xingyuan Yuan', 'link': 'https://arxiv.org/abs/2503.13546', 'abstract': "This study introduces a cutting-edge regional weather forecasting model based on the SwinTransformer 3D architecture. This model is specifically designed to deliver precise hourly weather predictions ranging from 1 hour to 5 days, significantly improving the reliability and practicality of short-term weather forecasts. Our model has demonstrated generally superior performance when compared to Pangu, a well-established global model. The evaluation indicates that our model excels in predicting most weather variables, highlighting its potential as a more effective alternative in the field of limited area modeling. A noteworthy feature of this model is the integration of enhanced boundary conditions, inspired by traditional numerical weather prediction (NWP) techniques. This integration has substantially improved the model's predictive accuracy. Additionally, the model includes an innovative approach for diagnosing hourly total precipitation at a high spatial resolution of approximately 5 kilometers. This is achieved through a latent diffusion model, offering an alternative method for generating high-resolution precipitation data.", 'abstract_zh': '基于SwinTransformer 3D架构的区域天气预报模型研究', 'title_zh': 'CNCast: 利用3D Swin Transformer和DiT提升区域天气预报性能'}
{'arxiv_id': 'arXiv:2503.13542', 'title': 'HAR-DoReMi: Optimizing Data Mixture for Self-Supervised Human Activity Recognition Across Heterogeneous IMU Datasets', 'authors': 'Lulu Ban, Tao Zhu, Xiangqing Lu, Qi Qiu, Wenyong Han, Shuangjian Li, Liming Chen, Kevin I-Kai Wang, Mingxing Nie, Yaping Wan', 'link': 'https://arxiv.org/abs/2503.13542', 'abstract': 'Cross-dataset Human Activity Recognition (HAR) suffers from limited model generalization, hindering its practical deployment. To address this critical challenge, inspired by the success of DoReMi in Large Language Models (LLMs), we introduce a data mixture optimization strategy for pre-training HAR models, aiming to improve the recognition performance across heterogeneous datasets. However, directly applying DoReMi to the HAR field encounters new challenges due to the continuous, multi-channel and intrinsic heterogeneous characteristics of IMU sensor data. To overcome these limitations, we propose a novel framework HAR-DoReMi, which introduces a masked reconstruction task based on Mean Squared Error (MSE) loss. By raplacing the discrete language sequence prediction task, which relies on the Negative Log-Likelihood (NLL) loss, in the original DoReMi framework, the proposed framework is inherently more appropriate for handling the continuous and multi-channel characteristics of IMU data. In addition, HAR-DoReMi integrates the Mahony fusion algorithm into the self-supervised HAR pre-training, aiming to mitigate the heterogeneity of varying sensor orientation. This is achieved by estimating the sensor orientation within each dataset and facilitating alignment with a unified coordinate system, thereby improving the cross-dataset generalization ability of the HAR model. Experimental evaluation on multiple cross-dataset HAR transfer tasks demonstrates that HAR-DoReMi improves the accuracy by an average of 6.51%, compared to the current state-of-the-art method with only approximately 30% to 50% of the data usage. These results confirm the effectiveness of HAR-DoReMi in improving the generalization and data efficiency of pre-training HAR models, underscoring its significant potential to facilitate the practical deployment of HAR technology.', 'abstract_zh': '跨数据集的人体活动识别（HAR）模型泛化能力有限，阻碍了其实用部署。为了解决这一关键挑战，受DoReMi在大型语言模型（LLMs）中的成功启发，我们提出了一种数据混合优化策略，用于预训练HAR模型，旨在提高跨异构数据集的识别性能。然而，直接将DoReMi应用于HAR领域会遇到新的挑战，因为IMU传感器数据具有连续性、多通道性和内在异构性等特点。为克服这些限制，我们提出了一种新的框架HAR-DoReMi，该框架基于均方误差（MSE）损失引入了一种掩码重建任务。通过替换依赖于负对数似然（NLL）损失的离散语言序列预测任务，所提出框架本身更适用于处理IMU数据的连续性和多通道性特征。此外，HAR-DoReMi将马洪融合算法集成到自我监督的HAR预训练中，旨在缓解传感器姿态变化带来的异构性。这通过在每个数据集中估计传感器姿态并促进与统一坐标系对齐来实现，从而提高HAR模型的跨数据集泛化能力。在多个跨数据集HAR迁移任务上的实验评估表明，与仅使用约30%到50%数据的当前最优方法相比，HAR-DoReMi将准确率提高了平均6.51%。这些结果证实了HAR-DoReMi在提高预训练HAR模型的泛化能力和数据效率方面的有效性，强调了其在促进HAR技术实用部署方面的巨大潜力。', 'title_zh': 'HAR-DoReMi：优化异质IMU数据集自监督人体活动识别中的数据混合'}
{'arxiv_id': 'arXiv:2503.13540', 'title': 'MSCMHMST: A traffic flow prediction model based on Transformer', 'authors': 'Weiyang Geng, Yiming Pan, Zhecong Xing, Dongyu Liu, Rui Liu, Yuan Zhu', 'link': 'https://arxiv.org/abs/2503.13540', 'abstract': "This study proposes a hybrid model based on Transformers, named MSCMHMST, aimed at addressing key challenges in traffic flow prediction. Traditional single-method approaches show limitations in traffic prediction tasks, whereas hybrid methods, by integrating the strengths of different models, can provide more accurate and robust predictions. The MSCMHMST model introduces a multi-head, multi-scale attention mechanism, allowing the model to parallel process different parts of the data and learn its intrinsic representations from multiple perspectives, thereby enhancing the model's ability to handle complex situations. This mechanism enables the model to capture features at various scales effectively, understanding both short-term changes and long-term trends. Verified through experiments on the PeMS04/08 dataset with specific experimental settings, the MSCMHMST model demonstrated excellent robustness and accuracy in long, medium, and short-term traffic flow predictions. The results indicate that this model has significant potential, offering a new and effective solution for the field of traffic flow prediction.", 'abstract_zh': '基于Transformer的MSCMHMST混合模型及其在交通流预测中的应用', 'title_zh': 'MSCMHMST：基于Transformer的交通流预测模型'}
{'arxiv_id': 'arXiv:2503.13535', 'title': 'Unlocking Learning Potentials: The Transformative Effect of Generative AI in Education Across Grade Levels', 'authors': 'Meijuan Xie, Liling Luo', 'link': 'https://arxiv.org/abs/2503.13535', 'abstract': "The advent of generative artificial intelligence (GAI) has brought about a notable surge in the field of education. The use of GAI to support learning is becoming increasingly prevalent among students. However, the manner and extent of its utilisation vary considerably from one individual to another. And researches about student's utilisation and perceptions of GAI remains relatively scarce. To gain insight into the issue, this paper proposed a hybrid-survey method to examine the impact of GAI on students across four different grades in six key areas (LIPSAL): learning interest, independent learning, problem solving, self-confidence, appropriate use, and learning enjoyment. Firstly, through questionnaire, we found that among LIPSAL, GAI has the greatest impact on the concept of appropriate use, the lowest level of learning interest and self-confidence. Secondly, a comparison of four grades revealed that the high and low factors of LIPSAL exhibited grade-related variation, and college students exhibited a higher level than high school students across LIPSAL. Thirdly, through interview, the students demonstrated a comprehensive understanding of the application of GAI. We found that students have a positive attitude towards GAI and are very willing to use it, which is why GAI has grown so rapidly in popularity. They also told us prospects and challenges in using GAI. In the future, as GAI matures technologically, it will have an greater impact on students. These findings may help better understand usage by different students and inform future research in digital education.", 'abstract_zh': '生成式人工智能(GAI)的兴起在教育领域带来了显著的增长。GAI在支持学习方面的应用日益普及，但其使用方式和程度因个体而异。关于学生对GAI的使用和感知的研究依然相对匮乏。为了深入了解这一问题，本文提出了一种混合调查方法，通过对六项关键领域（LIPSAL：学习兴趣、独立学习、解决问题、自信心、适当使用和学习乐趣）中四年级学生进行调查，探讨GAI对学生的影响。首先，通过问卷调查发现，在LIPSAL中，GAI对适当使用的影响最大，对学习兴趣和自信心的影响最低。其次，不同年级之间的比较显示，LIPSAL的高和低因素表现出年级相关的变化，大学生在LIPSAL方面高于高中生。第三，通过访谈，学生展示了对GAI应用的全面理解。我们发现，学生对GAI持正面态度，非常愿意使用它，这也是GAI迅速流行的原因。他们还向我们讲述了使用GAI的前景和挑战。随着GAI在技术上的成熟，未来它将对学生产生更大的影响。这些发现有助于更好地理解不同学生的行为并为数字教育的未来研究提供指导。', 'title_zh': '解锁学习潜力：生成式AI在各年级教育中的变革性影响'}
{'arxiv_id': 'arXiv:2503.13533', 'title': 'The Status Quo and Future of AI-TPACK for Mathematics Teacher Education Students: A Case Study in Chinese Universities', 'authors': 'Meijuan Xie, Liling Luo', 'link': 'https://arxiv.org/abs/2503.13533', 'abstract': 'As artificial intelligence (AI) technology becomes increasingly prevalent in the filed of education, there is a growing need for mathematics teacher education students (MTES) to demonstrate proficiency in the integration of AI with the technological pedagogical content knowledge (AI-TPACK). To study the issue, we firstly devised an systematic AI-TPACK scale and test on 412 MTES from seven universities. Through descriptive statistical analyses, we found that the current status of AI-TPACK for MTES in China is at a basic, preliminary stage. Secondly, we compared MTES between three different grades on the six variables and found that there is no discernible difference, which suggested that graduate studies were observed to have no promotion in the development of AI-TPACK competencies. Thirdly, we proposed a new AI-TPACK structural equation model (AI-TPACK-SEM) to explore the impact of self-efficacy and teaching beliefs on AI-TPACK. Our findings indicate a positive correlation between self-efficacy and AI-TPACK. We also come to a conclusion that may be contrary to common perception, excessive teaching beliefs may impede the advancement of AI-TPACK. Overall, this paper revealed the current status of AI-TPACK for MTES in China for the first time, designed a dedicated SEM to study the effect of specific factors on AI-TPACK, and proposed some suggestions on future developments.', 'abstract_zh': '人工智能技术在教育领域的日益普及促使数学教师教育学生（MTES）在技术教学内容知识（AI-TPACK）与人工智能的集成方面展现专业能力：一项基于六变量的跨年级比较及自我效能感和教学信念影响的结构性方程模型研究', 'title_zh': '人工智能-TPACK现状及其future对中国大学数学教师教育学生的影响：一项案例研究'}
{'arxiv_id': 'arXiv:2503.13522', 'title': 'Advanced Deep Learning Methods for Protein Structure Prediction and Design', 'authors': 'Weikun Wu, Tianyang Wang, Yichao Zhang, Ningyuan Deng, Xinyuan Song, Ziqian Bi, Zheyu Yao, Keyu Chen, Ming Li, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Ming Liu, Li Zhang, Xuanhe Pan, Jinlang Wang, Pohsun Feng, Yizhu Wen, Lawrence KQ Yan, Hongming Tseng, Yan Zhong, Yunze Wang, Ziyuan Qin, Bowen Jing, Junjie Yang, Jun Zhou, Chia Xin Liang, Junhao Song', 'link': 'https://arxiv.org/abs/2503.13522', 'abstract': 'After AlphaFold won the Nobel Prize, protein prediction with deep learning once again became a hot topic. We comprehensively explore advanced deep learning methods applied to protein structure prediction and design. It begins by examining recent innovations in prediction architectures, with detailed discussions on improvements such as diffusion based frameworks and novel pairwise attention modules. The text analyses key components including structure generation, evaluation metrics, multiple sequence alignment processing, and network architecture, thereby illustrating the current state of the art in computational protein modelling. Subsequent chapters focus on practical applications, presenting case studies that range from individual protein predictions to complex biomolecular interactions. Strategies for enhancing prediction accuracy and integrating deep learning techniques with experimental validation are thoroughly explored. The later sections review the industry landscape of protein design, highlighting the transformative role of artificial intelligence in biotechnology and discussing emerging market trends and future challenges. Supplementary appendices provide essential resources such as databases and open source tools, making this volume a valuable reference for researchers and students.', 'abstract_zh': 'AlphaFold获奖后，基于深度学习的蛋白质预测再次成为研究热点。我们全面探讨了应用于蛋白质结构预测与设计的先进深度学习方法。本文首先考察了预测架构的最新创新，详细讨论了诸如基于扩散的框架和新型成对注意力模块等改进。文本分析了结构生成、评估指标、多序列比对处理以及网络架构等关键组件，从而展示了计算蛋白质建模的当前前沿技术。随后章节关注实际应用，呈现从单个蛋白质预测到复杂生物分子相互作用的案例研究。本文详细探讨了提高预测准确性的策略，以及将深度学习技术与实验验证相结合的方法。后期章节回顾了蛋白质设计的行业格局，强调了人工智能在生物技术中的变革性作用，并讨论了新兴市场趋势和未来挑战。附录提供了诸如数据库和开源工具等必备资源，使得本书成为研究人员和学生的宝贵参考。', 'title_zh': '蛋白质结构预测与设计的高级深度学习方法'}
{'arxiv_id': 'arXiv:2503.13511', 'title': 'Towards a Digital Twin Modeling Method for Container Terminal Port', 'authors': 'Faouzi Hakimi, Tarek Khaled, Mohammed Al-Kharaz, Arthur Cartel Foahom Gouabou, Kenza Amzil', 'link': 'https://arxiv.org/abs/2503.13511', 'abstract': 'This paper introduces a novel strategy aimed at enhancing productivity and minimizing non-productive movements within container terminals, specifically focusing on container yards. It advocates for the implementation of a digital twin-based methodology to streamline the operations of stacking cranes (SCs) responsible for container handling. The proposed approach entails the creation of a virtual container yard that mirrors the physical yard within a digital twin system, facilitating real-time observation and validation. In addition, this article demonstrates the effectiveness of using a digital twin to reduce unproductive movements and improve productivity through simulation. It defines various operational strategies and takes into account different yard contexts, providing a comprehensive understanding of optimisation possibilities. By exploiting the capabilities of the digital twin, managers and operators are provided with crucial information on operational dynamics, enabling them to identify areas for improvement. This visualisation helps decision-makers to make informed choices about their stacking strategies, thereby improving the efficiency of overall container terminal operations. Overall, this paper present a digital twin solution in container terminal operations, offering a powerful tool for optimising productivity and minimising inefficiencies.', 'abstract_zh': '本文介绍了一种旨在提高集装箱码头生产效率并最大限度减少非生产性移动的新策略，特别聚焦于集装箱堆场。它提倡采用基于数字孪生的方法来优化负责集装箱处理的堆垛起重机（SCs）的操作。提出的方案涉及创建一个与物理堆场在数字孪生系统中镜像的虚拟集装箱堆场，以实现实时观察和验证。此外，本文通过模拟展示了使用数字孪生减少非生产性移动和提高生产效率的有效性。它定义了各种操作策略，并考虑了不同的堆场环境，提供了优化可能性的全面理解。通过利用数字孪生的功能，管理者和操作人员可以获得关于操作动态的关键信息，帮助他们识别改进领域。这种可视化有助于决策者就堆垛策略做出有根据的选择，从而提高整体集装箱码头操作的效率。总体而言，本文提出了一种集装箱码头操作中的数字孪生解决方案，提供了一种强大的工具来优化生产效率并减少 inefficiencies。', 'title_zh': '面向集装箱港口的数字孪生建模方法'}
{'arxiv_id': 'arXiv:2503.13494', 'title': 'Mobility-aware Seamless Service Migration and Resource Allocation in Multi-edge IoV Systems', 'authors': 'Zheyi Chen, Sijin Huang, Geyong Min, Zhaolong Ning, Jie Li, Yan Zhang', 'link': 'https://arxiv.org/abs/2503.13494', 'abstract': 'Mobile Edge Computing (MEC) offers low-latency and high-bandwidth support for Internet-of-Vehicles (IoV) applications. However, due to high vehicle mobility and finite communication coverage of base stations, it is hard to maintain uninterrupted and high-quality services without proper service migration among MEC servers. Existing solutions commonly rely on prior knowledge and rarely consider efficient resource allocation during the service migration process, making it hard to reach optimal performance in dynamic IoV environments. To address these important challenges, we propose SR-CL, a novel mobility-aware seamless Service migration and Resource allocation framework via Convex-optimization-enabled deep reinforcement Learning in multi-edge IoV systems. First, we decouple the Mixed Integer Nonlinear Programming (MINLP) problem of service migration and resource allocation into two sub-problems. Next, we design a new actor-critic-based asynchronous-update deep reinforcement learning method to handle service migration, where the delayed-update actor makes migration decisions and the one-step-update critic evaluates the decisions to guide the policy update. Notably, we theoretically derive the optimal resource allocation with convex optimization for each MEC server, thereby further improving system performance. Using the real-world datasets of vehicle trajectories and testbed, extensive experiments are conducted to verify the effectiveness of the proposed SR-CL. Compared to benchmark methods, the SR-CL achieves superior convergence and delay performance under various scenarios.', 'abstract_zh': '基于凸优化增强深度强化学习的移动边缘感知无缝服务迁移与资源分配框架（SR-CL）', 'title_zh': '面向移动性的无缝服务迁移与资源分配在多边缘IoV系统中'}
{'arxiv_id': 'arXiv:2503.13492', 'title': 'Event-Driven Implementation of a Physical Reservoir Computing Framework for superficial EMG-based Gesture Recognition', 'authors': 'Yuqi Ding, Elisa Donati, Haobo Li, Hadi Heidari', 'link': 'https://arxiv.org/abs/2503.13492', 'abstract': 'Wearable health devices have a strong demand in real-time biomedical signal processing. However traditional methods often require data transmission to centralized processing unit with substantial computational resources after collecting it from edge devices. Neuromorphic computing is an emerging field that seeks to design specialized hardware for computing systems inspired by the structure, function, and dynamics of the human brain, offering significant advantages in latency and power consumption. This paper explores a novel neuromorphic implementation approach for gesture recognition by extracting spatiotemporal spiking information from surface electromyography (sEMG) data in an event-driven manner. At the same time, the network was designed by implementing a simple-structured and hardware-friendly Physical Reservoir Computing (PRC) framework called Rotating Neuron Reservoir (RNR) within the domain of Spiking neural network (SNN). The spiking RNR (sRNR) is promising to pipeline an innovative solution to compact embedded wearable systems, enabling low-latency, real-time processing directly at the sensor level. The proposed system was validated by an open-access large-scale sEMG database and achieved an average classification accuracy of 74.6\\% and 80.3\\% using a classical machine learning classifier and a delta learning rule algorithm respectively. While the delta learning rule could be fully spiking and implementable on neuromorphic chips, the proposed gesture recognition system demonstrates the potential for near-sensor low-latency processing.', 'abstract_zh': '可穿戴健康设备在实时生物医学信号处理中具有强烈需求。然而，传统方法通常在从边缘设备收集数据后，需传输至拥有大量计算资源的中心处理单元进行处理。神经形态计算是一个新兴领域，旨在设计受人脑结构、功能和动态启发的专用硬件，提供显著的延迟和能耗优势。本文探索了一种新颖的神经形态实现方法，通过事件驱动的方式从表面肌电图(sEMG)数据中提取时空突触信息，进行手势识别。同时，设计了一个简单结构且硬件友好的突触神经网络(SNN)领域中的物理水库计算(PrC)框架，称为旋转神经元水库(RNR)。时空突触旋转神经元(Spiking RNR, sRNR)有望为紧凑的嵌入式可穿戴系统提供一种创新的解决方案，实现传感器级的低延迟、实时处理。所提系统通过一个开放访问的大规模sEMG数据库进行验证，并分别使用经典机器学习分类器和Δ学习规则算法实现了74.6%和80.3%的平均分类精度。虽然Δ学习规则可以完全突触化并在神经形态芯片上实现，但所提的手势识别系统展示了近传感器低延迟处理的潜力。', 'title_zh': '基于表面EMG的手势识别物理储层计算框架的事件驱动实现'}
{'arxiv_id': 'arXiv:2503.13477', 'title': 'Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic Post-Processing', 'authors': 'Ryan Banks, Vishal Thengane, María Eugenia Guerrero, Nelly Maria García-Madueño, Yunpeng Li, Hongying Tang, Akhilanand Chaurasia', 'link': 'https://arxiv.org/abs/2503.13477', 'abstract': 'Calculating percentage bone loss is a critical test for periodontal disease staging but is sometimes imprecise and time consuming when manually calculated. This study evaluates the application of a deep learning keypoint and object detection model, YOLOv8-pose, for the automatic identification of localised periodontal bone loss landmarks, conditions and staging. YOLOv8-pose was fine-tuned on 193 annotated periapical radiographs. We propose a keypoint detection metric, Percentage of Relative Correct Keypoints (PRCK), which normalises the metric to the average tooth size of teeth in the image. We propose a heuristic post-processing module that adjusts certain keypoint predictions to align with the edge of the related tooth, using a supporting instance segmentation model trained on an open source auxiliary dataset. The model can sufficiently detect bone loss keypoints, tooth boxes, and alveolar ridge resorption, but has insufficient performance at detecting detached periodontal ligament and furcation involvement. The model with post-processing demonstrated a PRCK 0.25 of 0.726 and PRCK 0.05 of 0.401 for keypoint detection, mAP 0.5 of 0.715 for tooth object detection, mesial dice score of 0.593 for periodontal staging, and dice score of 0.280 for furcation involvement. Our annotation methodology provides a stage agnostic approach to periodontal disease detection, by ensuring most keypoints are present for each tooth in the image, allowing small imbalanced datasets. Our PRCK metric allows accurate evaluation of keypoints in dental domains. Our post-processing module adjusts predicted keypoints correctly but is dependent on a minimum quality of prediction by the pose detection and segmentation models. Code: https:// this http URL. Dataset: this https URL.', 'abstract_zh': '利用YOLOv8-pose进行自动识别局部牙周骨丢失标志、状况和分期的研究', 'title_zh': '基于启发式后处理的关键点检测牙周骨丧失分析'}
{'arxiv_id': 'arXiv:2503.13476', 'title': 'Radar Pulse Deinterleaving with Transformer Based Deep Metric Learning', 'authors': 'Edward Gunn, Adam Hosford, Daniel Mannion, Jarrod Williams, Varun Chhabra, Victoria Nockles', 'link': 'https://arxiv.org/abs/2503.13476', 'abstract': 'When receiving radar pulses it is common for a recorded pulse train to contain pulses from many different emitters. The radar pulse deinterleaving problem is the task of separating out these pulses by the emitter from which they originated. Notably, the number of emitters in any particular recorded pulse train is considered unknown. In this paper, we define the problem and present metrics that can be used to measure model performance. We propose a metric learning approach to this problem using a transformer trained with the triplet loss on synthetic data. This model achieves strong results in comparison with other deep learning models with an adjusted mutual information score of 0.882.', 'abstract_zh': '当接收雷达脉冲时，记录的脉冲串通常包含来自多种不同发射器的脉冲。雷达脉冲去交织问题是指将这些脉冲按其原始发射器分离出来。值得注意的是，任何特定记录脉冲串中的发射器数量被认为是未知的。在本文中，我们定义了该问题并提出了用于衡量模型性能的指标。我们提出了一种基于变压器的度量学习方法，在合成数据上使用三元组损失进行训练，该模型在调整互信息分数为0.882的情况下与其他深度学习模型相比取得了较好的结果。', 'title_zh': '基于变压器的深度度量学习的雷达脉冲去交织'}
{'arxiv_id': 'arXiv:2503.13475', 'title': 'Cross-Subject Depression Level Classification Using EEG Signals with a Sample Confidence Method', 'authors': 'ZhongYi Zhang, ChenYang Xu, LiXuan Zhao, HuiRang Hou, QingHao Meng', 'link': 'https://arxiv.org/abs/2503.13475', 'abstract': "Electroencephalogram (EEG) is a non-invasive tool for real-time neural monitoring,widely used in depression detection via deep learning. However, existing models primarily focus on binary classification (depression/normal), lacking granularity for severity assessment. To address this, we proposed the DepL-GCN, i.e., Depression Level classification based on GCN model. This model tackles two key challenges: (1) subjectivity in depres-sion-level labeling due to patient self-report biases, and (2) class imbalance across severity categories. Inspired by the model learning patterns, we introduced two novel modules: the sample confidence module and the minority sample penalty module. The former leverages the L2-norm of prediction errors to progressively filter EEG samples with weak label alignment during training, thereby reducing the impact of subjectivity; the latter automatically upweights misclassified minority-class samples to address imbalance issues. After testing on two public EEG datasets, DepL-GCN achieved accuracies of 81.13% and 81.36% for multi-class severity recognition, outperforming baseline this http URL studies confirmed both modules' contributions. We further discussed the strengths and limitations of regression-based models for depression-level recognition.", 'abstract_zh': '基于GCN的抑郁等级分类模型DepL-GCN', 'title_zh': '基于样本置信方法的跨被试抑郁症水平分类acia'}
{'arxiv_id': 'arXiv:2503.13467', 'title': 'How Metacognitive Architectures Remember Their Own Thoughts: A Systematic Review', 'authors': 'Robin Nolte, Mihai Pomarlan, Ayden Janssen, Daniel Beßler, Kamyar Javanmardi, Sascha Jongebloed, Robert Porzel, John Bateman, Michael Beetz, Rainer Malaka', 'link': 'https://arxiv.org/abs/2503.13467', 'abstract': "Inspired by human cognition, metacognition has gained significant attention for its potential to enhance autonomy, adaptability, and robust learning in artificial agents. Yet research on Computational Metacognitive Architectures (CMAs) remains fragmented: diverse theories, terminologies, and design choices have led to disjointed developments and limited comparability across systems. Existing overviews and surveys often remain at a broad, conceptual level, making it difficult to synthesize deeper insights into the underlying algorithms and representations, and their respective success. We address this gap by performing an explorative systematic review of how CMAs model, store, remember and process their metacognitive experiences, one of Flavell's (1979) three foundational components of metacognition. Following this organizing principle, we identify 35 CMAs that feature episodic introspective data ranging from symbolic event traces to sub-symbolic arousal metrics. We consider different aspects - ranging from the underlying psychological theories to the content and structure of collected data, to the algorithms used and evaluation results - and derive a unifying perspective that allows us to compare in depth how different Computational Metacognitive Architectures (CMAs) leverage metacognitive experiences for tasks such as error diagnosis, self-repair, and goal-driven learning. Our findings highlight both the promise of metacognitive experiences - in boosting adaptability, explainability, and overall system performance - and the persistent lack of shared standards or evaluation benchmarks.", 'abstract_zh': '受人类认知启发，元认知因其在增强人工代理的自主性、适应性和鲁棒学习方面的潜力而备受关注。然而，关于计算元认知架构（CMAs）的研究仍然支离破碎：不同的理论、术语和设计选择导致了系统的分离发展和有限的可比性。现有综述和调研通常停留在较为宏观的概念层面，难以综合深入探讨底层算法和表示及其各自的成功之处。我们通过探索性系统审查，研究CMAs如何建模、存储、记住和处理其元认知体验，这是Flavell（1979）提出的元认知三大基础组成部分之一。遵循这一组织原则，我们识别出35个CMAs，这些CMAs涉及从符号事件痕迹到亚符号唤醒指标的片段式反思数据。我们考虑了不同的方面——从底层的心理学理论到收集的数据内容和结构，再到使用的算法和评估结果——并提炼出一个统一视角，使我们能够深入比较不同计算元认知架构（CMAs）如何利用元认知体验来完成诸如错误诊断、自我修复和目标驱动学习等任务。我们的发现既突出了元认知体验的前景——在提升适应性、可解释性和整体系统性能方面——也揭示了持续存在的共享标准或评估基准的缺乏。', 'title_zh': '元认知架构如何记住自己的思考：一项系统性回顾'}
{'arxiv_id': 'arXiv:2503.13465', 'title': 'A novel Fourier Adjacency Transformer for advanced EEG emotion recognition', 'authors': 'Jinfeng Wang, Yanhao Huang, Sifan Song, Boqian Wang, Jionglong Su, Jiaman Ding', 'link': 'https://arxiv.org/abs/2503.13465', 'abstract': 'EEG emotion recognition faces significant hurdles due to noise interference, signal nonstationarity, and the inherent complexity of brain activity which make accurately emotion classification. In this study, we present the Fourier Adjacency Transformer, a novel framework that seamlessly integrates Fourier-based periodic analysis with graph-driven structural modeling. Our method first leverages novel Fourier-inspired modules to extract periodic features from embedded EEG signals, effectively decoupling them from aperiodic components. Subsequently, we employ an adjacency attention scheme to reinforce universal inter-channel correlation patterns, coupling these patterns with their sample-based counterparts. Empirical evaluations on SEED and DEAP datasets demonstrate that our method surpasses existing state-of-the-art techniques, achieving an improvement of approximately 6.5% in recognition accuracy. By unifying periodicity and structural insights, this framework offers a promising direction for future research in EEG emotion analysis.', 'abstract_zh': '基于傅里叶变换的邻接变压器在EEG情绪识别中的应用：一种结合傅里叶周期分析与图驱动结构建模的新型框架', 'title_zh': '一种用于高级EEG情绪识别的新型傅里叶邻接变换器'}
{'arxiv_id': 'arXiv:2503.13463', 'title': 'Completeness of Datasets Documentation on ML/AI repositories: an Empirical Investigation', 'authors': 'Marco Rondina, Antonio Vetrò, Juan Carlos De Martin', 'link': 'https://arxiv.org/abs/2503.13463', 'abstract': 'ML/AI is the field of computer science and computer engineering that arguably received the most attention and funding over the last decade. Data is the key element of ML/AI, so it is becoming increasingly important to ensure that users are fully aware of the quality of the datasets that they use, and of the process generating them, so that possible negative impacts on downstream effects can be tracked, analysed, and, where possible, mitigated. One of the tools that can be useful in this perspective is dataset documentation. The aim of this work is to investigate the state of dataset documentation practices, measuring the completeness of the documentation of several popular datasets in ML/AI repositories. We created a dataset documentation schema -- the Documentation Test Sheet (DTS) -- that identifies the information that should always be attached to a dataset (to ensure proper dataset choice and informed use), according to relevant studies in the literature. We verified 100 popular datasets from four different repositories with the DTS to investigate which information was present. Overall, we observed a lack of relevant documentation, especially about the context of data collection and data processing, highlighting a paucity of transparency.', 'abstract_zh': '机器学习/人工智能数据集文档化的研究：基于Documentation Test Sheet (DTS)的流行数据集文档完整性分析', 'title_zh': 'ML/AI仓库中数据集文档的完整性：一项实证调查'}
