{'arxiv_id': 'arXiv:2507.07017', 'title': 'First Return, Entropy-Eliciting Explore', 'authors': 'Tianyu Zheng, Tianshun Xing, Qingshui Gu, Taoran Liang, Xingwei Qu, Xin Zhou, Yizhi Li, Zhoufutu Wen, Chenghua Lin, Wenhao Huang, Qian Liu, Ge Zhang, Zejun Ma', 'link': 'https://arxiv.org/abs/2507.07017', 'abstract': "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning abilities of Large Language Models (LLMs) but it struggles with unstable exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a structured exploration framework that identifies high-uncertainty decision points in reasoning trajectories and performs targeted rollouts to construct semantically grounded intermediate feedback. Our method provides targeted guidance without relying on dense supervision. Empirical results on mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable training, produces longer and more coherent responses, and increases the proportion of fully correct trajectories. These results highlight the framework's effectiveness in improving LLM reasoning through more robust and structured exploration.", 'abstract_zh': '可验证奖励强化学习（RLVR）提高了大型语言模型（LLMs）的推理能力，但面临着不稳定探索的挑战。我们提出了一种结构化探索框架FR3E（首次返回，熵激发探索），该框架识别推理轨迹中的高不确定性决策点，并进行有针对性的 rollout，构建语义上连贯的中间反馈。该方法提供有针对性的指导，而不依赖密集的监督。在数学推理基准测试（AIME24）上的实验证明，FR3E 促进了更稳定的训练，产生了更长且更连贯的回答，并增加了完全正确的轨迹的比例。这些结果突显了该框架通过更稳健和结构化的探索来提高LLM推理能力的有效性。', 'title_zh': '首次返回, 信息探索性搜索'}
{'arxiv_id': 'arXiv:2507.06993', 'title': 'The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation', 'authors': 'Jieren Deng, Aleksandar Cvetkovic, Pak Kiu Chung, Dragomir Yankov, Chiqun Zhang', 'link': 'https://arxiv.org/abs/2507.06993', 'abstract': 'Traditional travel-planning systems are often static and fragmented, leaving them ill-equipped to handle real-world complexities such as evolving environmental conditions and unexpected itinerary disruptions. In this paper, we identify three gaps between existing service providers causing frustrating user experience: intelligent trip planning, precision "last-100-meter" navigation, and dynamic itinerary adaptation. We propose three cooperative agents: a Travel Planning Agent that employs grid-based spatial grounding and map analysis to help resolve complex multi-modal user queries; a Destination Assistant Agent that provides fine-grained guidance for the final navigation leg of each journey; and a Local Discovery Agent that leverages image embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to trip plan disruptions. With evaluations and experiments, our system demonstrates substantial improvements in query interpretation, navigation accuracy, and disruption resilience, underscoring its promise for applications from urban exploration to emergency response.', 'abstract_zh': '现有的旅行规划系统往往静态且碎片化，难以应对诸如环境变化和行程意外中断等现实世界复杂性。本文识别了现有服务提供商之间的三个差距，导致用户体验不佳：智能行程规划、精准“最后100米”导航以及动态行程适应。我们提出了三种协作代理：旅行规划代理，利用基于网格的空间定位和地图分析来解决复杂的多模态用户查询；目的地助手代理，为每段旅程的最终导航提供精细指导；本地发现代理，利用图像嵌入和检索增强生成（RAG）来检测和响应行程计划中断。通过评估和实验，我们的系统在查询解释、导航精度和应对中断能力方面显示出显著改进，证明了其在从城市探索到应急响应等应用中的潜力。', 'title_zh': '用户导向的地理体验：一种由LLM驱动的增强规划、导航和动态适应框架'}
{'arxiv_id': 'arXiv:2507.06968', 'title': 'Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report', 'authors': 'Li Du, Hanyu Zhao, Yiming Ju, Tengfei Pan', 'link': 'https://arxiv.org/abs/2507.06968', 'abstract': "Instruction tuning has become a foundation for unlocking the capabilities of large-scale pretrained models and improving their performance on complex tasks. Thus, the construction of high-quality instruction datasets is crucial for enhancing model performance and generalizability. Although current instruction datasets have reached tens of millions of samples, models finetuned on them may still struggle with complex instruction following and tasks in rare domains. This is primarily due to limited expansion in both ``coverage'' (coverage of task types and knowledge areas) and ``depth'' (instruction complexity) of the instruction set. To address this issue, we propose a systematic instruction data construction framework, which integrates a hierarchical labeling system, an informative seed selection algorithm, an evolutionary data synthesis process, and a model deficiency diagnosis with targeted data generation. These components form an iterative closed-loop to continuously enhance the coverage and depth of instruction data. Based on this framework, we construct InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million instructions. Experiments on multiple foundation models and benchmark tasks demonstrate its effectiveness in improving instruction-following capabilities. Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage and depth compared to comparable synthesized instruction datasets. Our work lays a theoretical and practical foundation for the efficient, continuous evolution of instruction datasets, moving from data quantity expansion to qualitative improvement.", 'abstract_zh': '指令调优已成为解锁大规模预训练模型能力并提高其在复杂任务上性能的基础。因此，构建高质量的指令数据集对于提高模型性能和泛化能力至关重要。尽管当前的指令数据集已达到数千万样本，但基于这些数据集进行微调的模型在复杂指令遵循和稀有领域任务上仍然可能遇到困难。这主要归因于指令集在“覆盖面”（任务类型和知识领域覆盖范围）和“深度”（指令复杂性）上的有限扩展。为解决此问题，我们提出了一种系统性的指令数据构建框架，该框架结合了层次化标注系统、启发式种子选择算法、进化数据合成过程和针对模型缺陷的数据生成，这些组件形成一个迭代的闭环，以持续增强指令数据的覆盖面和深度。基于此框架，我们构建了包含约150万指令的高质量数据集InfinityInstruct-Subject。针对多个基础模型和基准任务的实验表明，该数据集在改进指令遵循能力方面具有有效性。进一步的分析表明，InfinityInstruct-Subject在覆盖面和深度上相比同类合成指令数据集有所扩展。我们的工作为高效、持续改进指令数据集奠定了理论和实践基础，从数据量的扩展转向质的提升。', 'title_zh': '接近指令集信息边界的扩展：InfinityInstruct-Subject技术报告'}
{'arxiv_id': 'arXiv:2507.06852', 'title': 'SCC-recursiveness in infinite argumentation (extended version)', 'authors': 'Uri Andrews, Luca San Mauro', 'link': 'https://arxiv.org/abs/2507.06852', 'abstract': 'Argumentation frameworks (AFs) are a foundational tool in artificial intelligence for modeling structured reasoning and conflict. SCC-recursiveness is a well-known design principle in which the evaluation of arguments is decomposed according to the strongly connected components (SCCs) of the attack graph, proceeding recursively from "higher" to "lower" components. While SCC-recursive semantics such as \\cft and \\stgt have proven effective for finite AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to generalize reliably to infinite AFs due to issues with well-foundedness.\nWe propose two approaches to extending SCC-recursiveness to the infinite setting. We systematically evaluate these semantics using Baroni and Giacomin\'s established criteria, showing in particular that directionality fails in general. We then examine these semantics\' behavior in finitary frameworks, where we find some of our semantics satisfy directionality. These results advance the theory of infinite argumentation and lay the groundwork for reasoning systems capable of handling unbounded or evolving domains.', 'abstract_zh': 'SCC-递归性在无限论辩框架中的扩展与评估', 'title_zh': '无限论辩中的SCC递归性（扩展版本）'}
{'arxiv_id': 'arXiv:2507.06798', 'title': 'Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)', 'authors': 'Uri Andrews, Luca San Mauro', 'link': 'https://arxiv.org/abs/2507.06798', 'abstract': 'Dialectical systems are a mathematical formalism for modeling an agent updating a knowledge base seeking consistency. Introduced in the 1970s by Roberto Magari, they were originally conceived to capture how a working mathematician or a research community refines beliefs in the pursuit of truth. Dialectical systems also serve as natural models for the belief change of an automated agent, offering a unifying, computable framework for dynamic belief management.\nThe literature distinguishes three main models of dialectical systems: (d-)dialectical systems based on revising beliefs when they are seen to be inconsistent, p-dialectical systems based on revising beliefs based on finding a counterexample, and q-dialectical systems which can do both. We answer an open problem in the literature by proving that q-dialectical systems are strictly more powerful than p-dialectical systems, which are themselves known to be strictly stronger than (d-)dialectical systems. This result highlights the complementary roles of counterexample and contradiction in automated belief revision, and thus also in the reasoning processes of mathematicians and research communities.', 'abstract_zh': '辩证系统是一种数学形式主义，用于建模代理更新知识库以寻求一致性的过程。该理论于20世纪70年代由Roberto Magari提出，最初旨在捕捉工作中的数学家或研究社区在追求真理过程中如何精化信念。辩证系统也是自动代理信念变化的自然模型，提供了动态信念管理的统一可计算框架。文献中区分了三种主要的辩证系统模型：基于发现不一致信念进行修订的(d-)辩证系统，基于找到反例进行修订的p-辩证系统，以及既能进行两者操作的q-辩证系统。我们解决了文献中的一个开放问题，证明了q-辩证系统严格强大于p-辩证系统，而p-辩证系统本身已知强大于(d-)辩证系统。这一结果强调了在自动信念修订以及数学家和研究社区推理过程中反例和矛盾的互补作用。', 'title_zh': '比较辩证系统：信念变化中的矛盾与反例（扩展版）'}
{'arxiv_id': 'arXiv:2507.06398', 'title': 'Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI', 'authors': 'David Orban', 'link': 'https://arxiv.org/abs/2507.06398', 'abstract': 'This paper investigates the Jolting Technologies Hypothesis, which posits superexponential growth (increasing acceleration, or a positive third derivative) in the development of AI capabilities. We develop a theoretical framework and validate detection methodologies through Monte Carlo simulations, while acknowledging that empirical validation awaits suitable longitudinal data. Our analysis focuses on creating robust tools for future empirical studies and exploring the potential implications should the hypothesis prove valid. The study examines how factors such as shrinking idea-to-action intervals and compounding iterative AI improvements drive this jolting pattern. By formalizing jolt dynamics and validating detection methods through simulation, this work provides the mathematical foundation necessary for understanding potential AI trajectories and their consequences for AGI emergence, offering insights for research and policy.', 'abstract_zh': '本文探究了震动技术假说，该假说认为人工智能能力的发展呈现超指数增长（即加速度不断增加，或正的第三阶导数）。本文构建了理论框架并通过蒙特卡洛模拟验证了检测方法，尽管实证验证有待合适的纵向数据。我们的分析重点在于为未来的实证研究创建稳健的工具，并探讨假说 proves valid 时可能出现的潜在影响。研究探讨了缩减从概念到行动的时间间隔和累积迭代式 AI 改进如何驱动这一震动模式。通过形式化震动动态并在模拟中验证检测方法，本文为理解潜在的 AI 轨迹及其对超人工通用智能 (AGI) 出现的影响提供了数学基础，并为研究和政策提供见解。', 'title_zh': '震撼性技术：AI能力的超指数加速及其对AGI的意义'}
{'arxiv_id': 'arXiv:2507.06396', 'title': 'Representing Prompting Patterns with PDL: Compliance Agent Case Study', 'authors': 'Mandana Vaziri, Louis Mandel, Yuji Watanabe, Hirokuni Kitahara, Martin Hirzel, Anca Sailer', 'link': 'https://arxiv.org/abs/2507.06396', 'abstract': "Prompt engineering for LLMs remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL's utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.", 'abstract_zh': 'LLM范例工程 remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL’s utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.', 'title_zh': '使用PDL表示提示模式：合规代理案例研究'}
{'arxiv_id': 'arXiv:2507.06373', 'title': 'Digital Wargames to Enhance Military Medical Evacuation Decision-Making', 'authors': 'Jeremy Fischer, Ram Krishnamoorthy, Vishal Kumar, Mahdi Al-Husseini', 'link': 'https://arxiv.org/abs/2507.06373', 'abstract': "Medical evacuation is one of the United States Army's most storied and critical mission sets, responsible for efficiently and expediently evacuating the battlefield ill and injured. Medical evacuation planning involves designing a robust network of medical platforms and facilities capable of moving and treating large numbers of casualties. Until now, there has not been a medium to simulate these networks in a classroom setting and evaluate both offline planning and online decision-making performance. This work describes the Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer simulation developed in Unity that replicates battlefield constraints and uncertainties. MEWI accurately models patient interactions at casualty collection points, ambulance exchange points, medical treatment facilities, and evacuation platforms. Two operational scenarios are introduced: an amphibious island assault in the Pacific and a Eurasian conflict across a sprawling road and river network. These scenarios pit students against the clock to save as many casualties as possible while adhering to doctrinal lessons learned during didactic training. We visualize performance data collected from two iterations of the MEWI Pacific scenario executed in the United States Army's Medical Evacuation Doctrine Course. We consider post-wargame Likert survey data from student participants and external observer notes to identify key planning decision points, document medical evacuation lessons learned, and quantify general utility. Results indicate that MEWI participation substantially improves uptake of medical evacuation lessons learned and co-operative decision-making. MEWI is a substantial step forward in the field of high-fidelity training tools for medical education, and our study findings offer critical insights into improving medical evacuation education and operations across the joint force.", 'abstract_zh': '医疗后送演习倡议（MEWI）：一种用于课堂设置中的三维多人模拟，以评估离线规划和在线决策性能', 'title_zh': '数字战争游戏以提升Military医疗服务撤离决策制定'}
{'arxiv_id': 'arXiv:2507.07073', 'title': 'An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator', 'authors': 'Yulin An, Enrique del Castillo', 'link': 'https://arxiv.org/abs/2507.07073', 'abstract': 'The spectrum of the Laplace-Beltrami (LB) operator is central in geometric deep learning tasks, capturing intrinsic properties of the shape of the object under consideration. The best established method for its estimation, from a triangulated mesh of the object, is based on the Finite Element Method (FEM), and computes the top k LB eigenvalues with a complexity of O(Nk), where N is the number of points. This can render the FEM method inefficient when repeatedly applied to databases of CAD mechanical parts, or in quality control applications where part metrology is acquired as large meshes and decisions about the quality of each part are needed quickly and frequently. As a solution to this problem, we present a geometric deep learning framework to predict the LB spectrum efficiently given the CAD mesh of a part, achieving significant computational savings without sacrificing accuracy, demonstrating that the LB spectrum is learnable. The proposed Graph Neural Network architecture uses a rich set of part mesh features - including Gaussian curvature, mean curvature, and principal curvatures. In addition to our trained network, we make available, for repeatability, a large curated dataset of real-world mechanical CAD models derived from the publicly available ABC dataset used for training and testing. Experimental results show that our method reduces computation time of the LB spectrum by approximately 5 times over linear FEM while delivering competitive accuracy.', 'abstract_zh': 'Laplace-Beltrami算子谱在几何深度学习任务中的研究：基于CAD模型的高效预测方法', 'title_zh': '基于AI的学习拉普拉斯-贝尔特拉米算子谱的方法'}
{'arxiv_id': 'arXiv:2507.07066', 'title': 'Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach', 'authors': 'Adrian S. Roman, Iran R. Roman, Juan P. Bello', 'link': 'https://arxiv.org/abs/2507.07066', 'abstract': "Acoustic mapping techniques have long been used in spatial audio processing for direction of arrival estimation (DoAE). Traditional beamforming methods for acoustic mapping, while interpretable, often rely on iterative solvers that can be computationally intensive and sensitive to acoustic variability. On the other hand, recent supervised deep learning approaches offer feedforward speed and robustness but require large labeled datasets and lack interpretability. Despite their strengths, both methods struggle to consistently generalize across diverse acoustic setups and array configurations, limiting their broader applicability. We introduce the Latent Acoustic Mapping (LAM) model, a self-supervised framework that bridges the interpretability of traditional methods with the adaptability and efficiency of deep learning methods. LAM generates high-resolution acoustic maps, adapts to varying acoustic conditions, and operates efficiently across different microphone arrays. We assess its robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves comparable or superior localization performance to existing supervised methods. Additionally, we show that LAM's acoustic maps can serve as effective features for supervised models, further enhancing DoAE accuracy and underscoring its potential to advance adaptive, high-performance sound localization systems.", 'abstract_zh': '声学映射技术在空间音频处理中长期用于到达方向估计（DoAE）。传统声学映射的波束形成方法虽然具有可解释性，但往往依赖于计算成本高且对声学变异性敏感的迭代求解器。另一方面，最近的监督深度学习方法虽然提供前向处理速度和鲁棒性，但需要大量标注数据集且缺乏可解释性。尽管各自具有优势，这两种方法仍难以在多种声学设置和阵列配置中一致地泛化，限制了它们的广泛应用。我们引入了潜声学映射（LAM）模型，这是一种自我监督框架，将传统方法的可解释性与深度学习方法的适应性和效率相结合。LAM生成高分辨率声学地图，能够适应变化的声学条件，并在不同的麦克风阵列上高效运行。我们使用LOCATA和STARSS基准评估其在到达方向估计中的鲁棒性。LAM在定位性能上达到了与现有监督方法相当或更优的效果。此外，我们展示了LAM的声学地图可以作为监督模型的有效特征，进一步提高到达方向估计的准确性，并强调了其在推进适应性强的高性能声定位系统方面潜力。', 'title_zh': '隐含声学映射到达角估计：一种自监督方法'}
{'arxiv_id': 'arXiv:2507.07060', 'title': 'DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning', 'authors': 'Shreyas Vinaya Sathyanarayana, Rahil Shah, Sharanabasava D. Hiremath, Rishikesh Panda, Rahul Jana, Riya Singh, Rida Irfan, Ashwin Murali, Bharath Ramsundar', 'link': 'https://arxiv.org/abs/2507.07060', 'abstract': 'Retrosynthesis, the identification of precursor molecules for a target compound, is pivotal for synthesizing complex molecules, but faces challenges in discovering novel pathways beyond predefined templates. Recent large language model (LLM) approaches to retrosynthesis have shown promise but effectively harnessing LLM reasoning capabilities for effective multi-step planning remains an open question. To address this challenge, we introduce DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic framework. Our approach integrates the strengths of conventional template-based/Monte Carlo tree search tools with the generative power of LLMs in a step-wise, feedback-driven loop. Initially, synthesis planning is attempted with a template-based engine. If this fails, the LLM subsequently proposes single-step retrosynthetic disconnections. Crucially, these suggestions undergo rigorous validity, stability, and hallucination checks before the resulting precursors are recursively fed back into the pipeline for further evaluation. This iterative refinement allows for dynamic pathway exploration and correction. We demonstrate the potential of this pipeline through benchmark evaluations and case studies, showcasing its ability to identify viable and potentially novel retrosynthetic routes. In particular, we develop an interactive graphical user interface that allows expert human chemists to provide human-in-the-loop feedback to the reasoning algorithm. This approach successfully generates novel pathways for complex natural product compounds, demonstrating the potential for iterative LLM reasoning to advance state-of-art in complex chemical syntheses.', 'abstract_zh': '基于大规模语言模型的迭代混合 retrosynthesis 框架：DeepRetro', 'title_zh': 'DeepRetro: 使用迭代LLM推理发现逆合成反应路径'}
{'arxiv_id': 'arXiv:2507.07058', 'title': 'Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification', 'authors': 'Martin Sondermann, Pinar Bisgin, Niklas Tschorn, Anja Burmann, Christoph M. Friedrich', 'link': 'https://arxiv.org/abs/2507.07058', 'abstract': 'The automated classification of phonocardiogram (PCG) recordings represents a substantial advancement in cardiovascular diagnostics. This paper presents a systematic comparison of four distinct models for heart murmur detection: two specialized convolutional neural networks (CNNs) and two zero-shot universal audio transformers (BEATs), evaluated using fixed-length and heart cycle normalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart cycle normalization method tailored to individual cardiac rhythms is introduced. The findings indicate the following AUROC values: the CNN model with fixed-length windowing achieves 79.5%, the CNN model with heart cycle normalization scores 75.4%, the BEATs transformer with fixed-length windowing achieves 65.7%, and the BEATs transformer with heart cycle normalization results in 70.1%.\nThe findings indicate that physiological signal constraints, especially those introduced by different normalization strategies, have a substantial impact on model performance. The research provides evidence-based guidelines for architecture selection in clinical settings, emphasizing the need for a balance between accuracy and computational efficiency. Although specialized CNNs demonstrate superior performance overall, the zero-shot transformer models may offer promising efficiency advantages during development, such as faster training and evaluation cycles, despite their lower classification accuracy. These findings highlight the potential of automated classification systems to enhance cardiac diagnostics and improve patient care.', 'abstract_zh': '自动分类 Phonocardiogram (PCG) 录音代表了心血管诊断的一个重大进步。本文系统比较了四种不同的心音异常检测模型：两种专门的卷积神经网络 (CNNs) 和两种零样本通用音频变压器 (BEATs)，评估方法包括固定长度和心脏周期归一化。使用 PhysioNet2022 数据集，介绍了针对个体心律定制的心脏周期归一化方法。研究结果表明，AUROC 值分别为：采用固定长度窗口的 CNN 模型为 79.5%，采用心脏周期归一化的 CNN 模型为 75.4%，采用固定长度窗口的 BEATs 转换器为 65.7%，采用心脏周期归一化的 BEATs 转换器为 70.1%。研究表明，生理信号约束，特别是由不同的归一化策略引入的约束，对模型性能有重大影响。研究提供了临床环境中的架构选择指南，强调了准确性与计算效率之间的平衡。尽管专门的 CNN 在整体上表现出色，但零样本变换器模型在开发过程中可能提供显著的效率优势，例如更快的训练和评估周期，尽管它们的分类准确性较低。这些发现突显了自动化分类系统在提高心脏诊断和患者护理方面的潜力。', 'title_zh': '基于心脏周期归一化的CNN和Transformer架构的自动心音图分类比较分析'}
{'arxiv_id': 'arXiv:2507.07046', 'title': 'A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering', 'authors': 'Shahana Yasmin Chowdhury, Bithi Banik, Md Tamjidul Hoque, Shreya Banerjee', 'link': 'https://arxiv.org/abs/2507.07046', 'abstract': 'Nowadays, speech emotion recognition (SER) plays a vital role in the field of human-computer interaction (HCI) and the evolution of artificial intelligence (AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions: neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C). The model achieves high accuracy on individual datasets, including 97.83% on RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy, outperforming previously reported results. To our knowledge, no existing study has evaluated a single SER model across all five benchmark datasets (i.e., R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive combination and achieve a remarkable overall accuracy of 93.76%. These results confirm the robustness and generalizability of our DCRF-BiLSTM framework across diverse datasets.', 'abstract_zh': 'DCRF-BiLSTM模型在RAVDESS、TESS、SAVEE、EmoDB和Crema-D五个基准数据集上的综合情感识别研究', 'title_zh': '一种基于特征工程的新型混合深度学习技术在语音情绪识别中的应用'}
{'arxiv_id': 'arXiv:2507.07043', 'title': 'Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation', 'authors': 'Haris Khan, Shumaila Asif, Hassan Nasir', 'link': 'https://arxiv.org/abs/2507.07043', 'abstract': 'The integration of artificial intelligence into hearing assistance marks a paradigm shift from traditional amplification-based systems to intelligent, context-aware audio processing. This systematic literature review evaluates advances in AI-driven selective noise cancellation (SNC) for hearing aids, highlighting technological evolution, implementation challenges, and future research directions. We synthesize findings across deep learning architectures, hardware deployment strategies, clinical validation studies, and user-centric design. The review traces progress from early machine learning models to state-of-the-art deep networks, including Convolutional Recurrent Networks for real-time inference and Transformer-based architectures for high-accuracy separation. Key findings include significant gains over traditional methods, with recent models achieving up to 18.3 dB SI-SDR improvement on noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and promising clinical outcomes. Yet, challenges remain in bridging lab-grade models with real-world deployment - particularly around power constraints, environmental variability, and personalization. Identified research gaps include hardware-software co-design, standardized evaluation protocols, and regulatory considerations for AI-enhanced hearing devices. Future work must prioritize lightweight models, continual learning, contextual-based classification and clinical translation to realize transformative hearing solutions for millions globally.', 'abstract_zh': '人工智能在听觉辅助中的集成标志着从传统放大系统到智能、情境感知音频处理范式的转变。本文综述了人工智能驱动的选择性噪声取消（SNC）在助听器中的进展，强调了技术进化、实施挑战和未来研究方向。我们综合了深度学习架构、硬件部署策略、临床验证研究和用户中心设计的研究成果。综述从早期的机器学习模型追踪到最新的深度网络，包括适用于实时推理的卷积循环网络和适用于高精度分离的变压器架构。关键发现包括传统方法的显著超越，最新模型在嘈杂混响基准上的SI-SDR提升高达18.3 dB，同时实现了亚10毫秒的实时实现和令人鼓舞的临床结果。然而，仍存在将实验室模型应用于现实世界部署的挑战，特别是在功率限制、环境变化和个人化方面。识别的研究缺口包括硬件软件协同设计、标准化评估协议和增强听力设备的法规考虑。未来工作必须优先考虑轻量化模型、持续学习、基于上下文的分类和临床转化，以实现对全球数百万人具有变革性影响的听力解决方案。', 'title_zh': '智能助听器的发展：深度学习在选择性噪声取消中的应用'}
{'arxiv_id': 'arXiv:2507.07036', 'title': 'Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic', 'authors': 'Maloy Kumar Devnath, Sudip Chakraborty, Vandana P. Janeja', 'link': 'https://arxiv.org/abs/2507.07036', 'abstract': 'Spatial phenomena often exhibit heterogeneity across spatial extents and in proximity, making them complex to model-especially in dynamic regions like ice shelves and sea ice. In this study, we address this challenge by exploring the linkages between sea ice retreat and Antarctic ice shelf (AIS) melt. Although atmospheric forcing and basal melting have been widely studied, the direct impact of sea ice retreat on AIS mass loss remains underexplored. Traditional models treat sea ice and AIS as separate systems. It limits their ability to capture localized linkages and cascading feedback. To overcome this, we propose Spatial-Link, a novel graph-based framework that quantifies spatial heterogeneity to capture linkages between sea ice retreat and AIS melt. Our method constructs a spatial graph using Delaunay triangulation of satellite-derived ice change matrices, where nodes represent regions of significant change and edges encode proximity and directional consistency. We extract and statistically validate linkage paths using breadth-first search and Monte Carlo simulations. Results reveal non-local, spatially heterogeneous coupling patterns, suggesting sea ice loss can initiate or amplify downstream AIS melt. Our analysis shows how sea ice retreat evolves over an oceanic grid and progresses toward ice shelves-establishing a direct linkage. To our knowledge, this is the first proposed methodology linking sea ice retreat to AIS melt. Spatial-Link offers a scalable, data-driven tool to improve sea-level rise projections and inform climate adaptation strategies.', 'abstract_zh': '空间现象在不同空间尺度和临近区域表现出异质性，使其在建模时尤为复杂，尤其是在像冰shelf和海冰这样的动态区域。本研究通过探讨海冰退缩与南极冰shelf (AIS) 融化之间的关联来应对这一挑战。尽管大气强迫和基底融化已被广泛研究，但海冰退缩直接对AIS质量损失的影响仍待进一步探索。传统模型将海冰和AIS视为独立系统，限制了它们捕捉局部关联和级联反馈的能力。为此，我们提出了一种称为Spatial-Link的新型图为基础的框架，该框架通过度量空间异质性来捕捉海冰退缩与AIS融化之间的关联。该方法使用卫星 derived 冰变化矩阵的 Delaunay 三角剖分构建空间图，节点代表显著变化的区域，边编码临近性和方向一致性。我们通过广度优先搜索和蒙特卡洛模拟提取并统计验证关联路径。结果揭示了非局部的空间异质性耦合模式，表明海冰损失可以引发或放大下游的AIS融化。我们的分析展示了海冰退缩在海洋网格中的演变过程，并逐步向冰shelf推进，建立了直接的关联。据我们所知，这是首次提出的将海冰退缩与AIS融化联系起来的方法。Spatial-Link提供了可扩展的数据驱动工具，以提高海平面上升预测，并为气候适应策略提供指导。', 'title_zh': '模型化不同空间尺度上的异质性：发现南极海冰退缩与冰架融化之间的联系'}
{'arxiv_id': 'arXiv:2507.07034', 'title': 'Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control', 'authors': 'Mikael Vaillant, Victor Oliveira Ferreira, Wiebke Mainville, Jean-Michel Lamarre, Vincent Raymond, Moncef Chioua, Bruno Blais', 'link': 'https://arxiv.org/abs/2507.07034', 'abstract': "This study presents a surrogate model designed to predict the Nusselt number distribution in an enclosed impinging jet arrays, where each jet function independently and where jets can be transformed from inlets to outlets, leading to a vast number of possible flow arrangements. While computational fluid dynamics (CFD) simulations can model heat transfer with high fidelity, their cost prohibits real-time application such as model-based temperature control. To address this, we generate a CNN-based surrogate model that can predict the Nusselt distribution in real time. We train it with data from implicit large eddy computational fluid dynamics simulations (Re < 2,000). We train two distinct models, one for a five by one array of jets (83 simulations) and one for a three by three array of jets (100 simulations). We introduce a method to extrapolate predictions to higher Reynolds numbers (Re < 10,000) using a correlation-based scaling. The surrogate models achieve high accuracy, with a normalized mean average error below 2% on validation data for the five by one surrogate model and 0.6% for the three by three surrogate model. Experimental validation confirms the model's predictive capabilities. This work provides a foundation for model-based control strategies in advanced thermal management applications.", 'abstract_zh': '本研究提出了一种代理模型，用于预测封闭喷射阵列中努塞尔数分布，其中每个喷射独立作用，喷射可以从进气口转变为出气口，导致大量可能的流场布置。虽然计算流体动力学（CFD）模拟可以高保真地建模热传递，但其成本限制了实时应用，如基于模型的温度控制。为此，我们生成了一种基于CNN的代理模型，可以实现喷射阵列努塞尔数的实时预测。我们使用Re < 2,000的隐式大涡模拟数据进行训练，分别训练了五喷射一排（83次仿真）和三喷射三排（100次仿真）的两类模型。我们提出了一种基于相关性的扩展方法，用于将预测扩展到更高的雷诺数（Re < 10,000）。代理模型在验证数据上的归一化均方误差低于2%（五喷射一排模型）和0.6%（三喷射三排模型）。实验验证证实了模型的预测能力。本研究为先进热管理应用程序中的基于模型的控制策略奠定了基础。', 'title_zh': '基于动态进口/出口控制和流量率调节的喷射平板阵列热传递预测代理模型'}
{'arxiv_id': 'arXiv:2507.07032', 'title': 'PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments', 'authors': 'Hanqun Cao, Xinyi Zhou, Zijun Gao, Chenyu Wang, Xin Gao, Zhi Zhang, Chunbin Gu, Ge Liu, Pheng-Ann Heng', 'link': 'https://arxiv.org/abs/2507.07032', 'abstract': "Protein structure prediction is essential for drug discovery and understanding biological functions. While recent advancements like AlphaFold have achieved remarkable accuracy, most folding models rely heavily on multiple sequence alignments (MSAs) to boost prediction performance. This dependency limits their effectiveness on low-homology proteins and orphan proteins, where MSA information is sparse or unavailable. To address this limitation, we propose PLAME, a novel MSA design model that leverages evolutionary embeddings from pretrained protein language models. Unlike existing methods, PLAME introduces pretrained representations to enhance evolutionary information and employs a conservation-diversity loss to enhance generation quality. Additionally, we propose a novel MSA selection method to effectively screen high-quality MSAs and improve folding performance. We also propose a sequence quality assessment metric that provides an orthogonal perspective to evaluate MSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins, PLAME achieves state-of-the-art performance in folding enhancement and sequence quality assessment, with consistent improvements demonstrated on AlphaFold3. Ablation studies validate the effectiveness of the MSA selection method, while extensive case studies on various protein types provide insights into the relationship between AlphaFold's prediction quality and MSA characteristics. Furthermore, we demonstrate that PLAME can serve as an adapter achieving AlphaFold2-level accuracy with the ESMFold's inference speed.", 'abstract_zh': '蛋白质结构预测对于药物发现和理解生物功能至关重要。尽管AlphaFold等最近的进展取得了显著的准确性，大多数折叠模型依然高度依赖多序列比对（MSAs）以提高预测性能。这种依赖限制了它们在低同源性和孤儿蛋白上的效果，因为在这个领域MSA信息稀缺或不可用。为了解决这一局限性，我们提出PLAME，一种新颖的MSA设计模型，利用预训练蛋白语言模型的进化嵌入。与现有方法不同，PLAME引入了预训练表示以增强进化信息，并采用了保真度-多样性损失来提高生成质量。此外，我们还提出了一种新的MSA选择方法，以有效筛选高质量的MSA并提高折叠性能。我们还提出了一种序列质量评估指标，从另一种视角评估MSA质量。在AlphaFold2基准测试中，PLAME在低同源性和孤儿蛋白的折叠增强和序列质量评估中达到了最先进的性能，并在AlphaFold3上也表现出一致的改进。消融研究表明MSA选择方法的有效性，而广泛的蛋白质类型案例研究为AlphaFold预测质量和MSA特性之间的关系提供了见解。此外，我们证明PLAME可以作为适配器，以ESMFold的推理速度达到AlphaFold2级别的准确性。', 'title_zh': 'PLAME: 利用预训练语言模型生成增强的蛋白质多序列比对'}
{'arxiv_id': 'arXiv:2507.07029', 'title': 'Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices', 'authors': 'Parshva Dhilankumar Patel', 'link': 'https://arxiv.org/abs/2507.07029', 'abstract': 'This paper presents the design and development of an OCR-powered pipeline for efficient table extraction from invoices. The system leverages Tesseract OCR for text recognition and custom post-processing logic to detect, align, and extract structured tabular data from scanned invoice documents. Our approach includes dynamic preprocessing, table boundary detection, and row-column mapping, optimized for noisy and non-standard invoice formats. The resulting pipeline significantly improves data extraction accuracy and consistency, supporting real-world use cases such as automated financial workflows and digital archiving.', 'abstract_zh': '基于OCR的发票表格高效提取管道设计与开发', 'title_zh': '基于OCR的技术发票表格提取管道的设计与实现'}
{'arxiv_id': 'arXiv:2507.07024', 'title': 'FlexOlmo: Open Language Models for Flexible Data Use', 'authors': 'Weijia Shi, Akshita Bhagia, Kevin Farhat, Niklas Muennighoff, Pete Walsh, Jacob Morrison, Dustin Schwenk, Shayne Longpre, Jake Poznanski, Allyson Ettinger, Daogao Liu, Margaret Li, Dirk Groeneveld, Mike Lewis, Wen-tau Yih, Luca Soldaini, Kyle Lo, Noah A. Smith, Luke Zettlemoyer, Pang Wei Koh, Hannaneh Hajishirzi, Ali Farhadi, Sewon Min', 'link': 'https://arxiv.org/abs/2507.07024', 'abstract': "We introduce FlexOlmo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on closed datasets, and (2) data-flexible inference, where these parameters along with their associated data can be flexibly included or excluded from model inferences with no further training. FlexOlmo employs a mixture-of-experts (MoE) architecture where each expert is trained independently on closed datasets and later integrated through a new domain-informed routing without any joint training. FlexOlmo is trained on FlexMix, a corpus we curate comprising publicly available datasets alongside seven domain-specific sets, representing realistic approximations of closed sets. We evaluate models with up to 37 billion parameters (20 billion active) on 31 diverse downstream tasks. We show that a general expert trained on public data can be effectively combined with independently trained experts from other data owners, leading to an average 41% relative improvement while allowing users to opt out of certain data based on data licensing or permission requirements. Our approach also outperforms prior model merging methods by 10.1% on average and surpasses the standard MoE trained without data restrictions using the same training FLOPs. Altogether, this research presents a solution for both data owners and researchers in regulated industries with sensitive or protected data. FlexOlmo enables benefiting from closed data while respecting data owners' preferences by keeping their data local and supporting fine-grained control of data access during inference.", 'abstract_zh': 'FlexOlmo：支持分布式训练和数据灵活推理的新语言模型', 'title_zh': 'FlexOlmo: 开放语言模型的灵活数据使用'}
{'arxiv_id': 'arXiv:2507.06996', 'title': 'Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing', 'authors': 'Eunbyeol Cho, Jiyoun Kim, Minjae Lee, Sungjin Park, Edward Choi', 'link': 'https://arxiv.org/abs/2507.06996', 'abstract': 'Electronic Health Records (EHR) are time-series relational databases that record patient interactions and medical events over time, serving as a critical resource for healthcare research and applications. However, privacy concerns and regulatory restrictions limit the sharing and utilization of such sensitive data, necessitating the generation of synthetic EHR datasets. Unlike previous EHR synthesis methods, which typically generate medical records consisting of expert-chosen features (e.g. a few vital signs or structured codes only), we introduce RawMed, the first framework to synthesize multi-table, time-series EHR data that closely resembles raw EHRs. Using text-based representation and compression techniques, RawMed captures complex structures and temporal dynamics with minimal preprocessing. We also propose a new evaluation framework for multi-table time-series synthetic EHRs, assessing distributional similarity, inter-table relationships, temporal dynamics, and privacy. Validated on two open-source EHR datasets, RawMed outperforms baseline models in fidelity and utility. The code is available at this https URL.', 'abstract_zh': '电子健康记录(EHR)是时间序列关系数据库，记录了患者的交互和随时间变化的医疗事件，是 Healthcare 研究和应用中的关键资源。然而，隐私担忧和监管限制限制了这类敏感数据的共享和利用，因此需要生成合成的 EHR 数据集。与以往通常生成由专家选择特征（如少数生命体征或结构化代码）构成的医疗记录的方法不同，我们介绍了 RawMed，这是第一个用于生成多表时间序列 EHR 数据的框架，这些数据与原始 EHR 数据高度相似。利用基于文本的表示和压缩技术，RawMed 在最少预处理的情况下捕捉到了复杂的结构和时序动态。我们还提出了一种新的多表时间序列合成 EHR 的评估框架，评估分布相似性、表间关系、时序动态和隐私特性。在两个开源 EHR 数据集上验证，RawMed 在保真度和实用性上均优于基准模型。代码可在以下网址获取。', 'title_zh': '从潜在空间生成具有最小前置处理的多表时间序列EHR'}
{'arxiv_id': 'arXiv:2507.06994', 'title': 'Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients', 'authors': 'Qilong Xing, Zikai Song, Bingxin Gong, Lian Yang, Junqing Yu, Wei Yang', 'link': 'https://arxiv.org/abs/2507.06994', 'abstract': 'Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing immunotherapy is essential for personalized treatment planning, enabling informed patient decisions, and improving both treatment outcomes and quality of life. However, the lack of large, relevant datasets and effective multi-modal feature fusion strategies pose significant challenges in this domain. To address these challenges, we present a large-scale dataset and introduce a novel framework for multi-modal feature fusion aimed at enhancing the accuracy of survival prediction. The dataset comprises 3D CT images and corresponding clinical records from NSCLC patients treated with immune checkpoint inhibitors (ICI), along with progression-free survival (PFS) and overall survival (OS) data. We further propose a cross-modality masked learning approach for medical feature fusion, consisting of two distinct branches, each tailored to its respective modality: a Slice-Depth Transformer for extracting 3D features from CT images and a graph-based Transformer for learning node features and relationships among clinical variables in tabular data. The fusion process is guided by a masked modality learning strategy, wherein the model utilizes the intact modality to reconstruct missing components. This mechanism improves the integration of modality-specific features, fostering more effective inter-modality relationships and feature interactions. Our approach demonstrates superior performance in multi-modal integration for NSCLC survival prediction, surpassing existing methods and setting a new benchmark for prognostic models in this context.', 'abstract_zh': '非小细胞肺癌（NSCLC）患者在接受免疫疗法后的准确预后对于个性化治疗规划、支持患者的知情决策以及提高治疗效果和生活质量至关重要。然而，缺乏相关的大型数据集和有效的多模态特征融合策略在这一领域构成了重大挑战。为进一步应对这些挑战，我们提出了一项大规模数据集，并引入了一种新的多模态特征融合框架，旨在提高生存预测的准确性。该数据集包含接受免疫检查点抑制剂（ICI）治疗的NSCLC患者的3D CT图像及其临床记录，并提供了无进展生存期（PFS）和总生存期（OS）数据。此外，我们还提出了一种跨模态遮蔽学习方法，用于医学特征融合，该方法由两个专门针对各自模态的分支组成：卷积深度变压器（Slice-Depth Transformer）用于从CT图像中提取3D特征，以及基于图的变压器用于学习表格数据中临床变量的节点特征及其关系。融合过程由遮蔽模态学习策略指导，模型利用完整模态来重建缺失的部分，从而改善了模态特异性特征的整合，促进更有效的跨模态关系和特征交互。我们的方法在NSCLC生存预测的多模态集成方面表现出色，超越了现有方法，并在这一领域为预后模型设立了新的基准。', 'title_zh': 'ICI治疗NSCLC患者跨模态掩蔽学习生存预测'}
{'arxiv_id': 'arXiv:2507.06992', 'title': 'MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation', 'authors': 'Qilong Xing, Zikai Song, Youjia Zhang, Na Feng, Junqing Yu, Wei Yang', 'link': 'https://arxiv.org/abs/2507.06992', 'abstract': 'Despite significant advancements in adapting Large Language Models (LLMs) for radiology report generation (RRG), clinical adoption remains challenging due to difficulties in accurately mapping pathological and anatomical features to their corresponding text descriptions. Additionally, semantic agnostic feature extraction further hampers the generation of accurate diagnostic reports. To address these challenges, we introduce Medical Concept Aligned Radiology Report Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual features with distinct medical concepts to enhance the report generation process. MCA-RG utilizes two curated concept banks: a pathology bank containing lesion-related knowledge, and an anatomy bank with anatomical descriptions. The visual features are aligned with these medical concepts and undergo tailored enhancement. We further propose an anatomy-based contrastive learning procedure to improve the generalization of anatomical features, coupled with a matching loss for pathological features to prioritize clinically relevant regions. Additionally, a feature gating mechanism is employed to filter out low-quality concept features. Finally, the visual features are corresponding to individual medical concepts, and are leveraged to guide the report generation process. Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate that MCA-RG achieves superior performance, highlighting its effectiveness in radiology report generation.', 'abstract_zh': '面向医学概念对齐的放射报告生成（MCA-RG）：一种知识驱动的框架以增强放射报告生成过程', 'title_zh': 'MCA-RG: 通过医学概念对齐增强LLMs的放射报告生成'}
{'arxiv_id': 'arXiv:2507.06969', 'title': 'Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy', 'authors': 'Bogdan Kulynych, Juan Felipe Gomez, Georgios Kaissis, Jamie Hayes, Borja Balle, Flavio du Pin Calmon, Jean Louis Raisaro', 'link': 'https://arxiv.org/abs/2507.06969', 'abstract': 'Differentially private (DP) mechanisms are difficult to interpret and calibrate because existing methods for mapping standard privacy parameters to concrete privacy risks -- re-identification, attribute inference, and data reconstruction -- are both overly pessimistic and inconsistent. In this work, we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that bounds on attack success can take the same unified form across re-identification, attribute inference, and data reconstruction risks. Our unified bounds are (1) consistent across a multitude of attack settings, and (2) tunable, enabling practitioners to evaluate risk with respect to arbitrary (including worst-case) levels of baseline risk. Empirically, our results are tighter than prior methods using $\\varepsilon$-DP, Rényi DP, and concentrated DP. As a result, calibrating noise using our bounds can reduce the required noise by 20% at the same risk level, which yields, e.g., more than 15pp accuracy increase in a text classification task. Overall, this unifying perspective provides a principled framework for interpreting and calibrating the degree of protection in DP against specific levels of re-identification, attribute inference, or data reconstruction risk.', 'abstract_zh': '不同的私密性（Differentially Private, DP）机制难以解释和校准，因为现有将标准隐私参数映射到具体隐私风险（重识别、属性推理和数据重构）的方法既过于悲观又不一致。在本工作中，我们采用DP的假设检验解释（$f$-DP），并确定这些攻击成功的边界可以以统一的形式应用于重识别、属性推理和数据重构风险。我们的统一边界是（1）在多种攻击设置下保持一致，（2）可调节，使实践者能够根据任意（包括最坏情况）基线风险水平评估风险。实验结果表明，我们的方法比使用$\\varepsilon$-DP、Rényi DP和集中DP的先前方法更为严格。因此，使用我们的边界校准噪声可以使在相同风险水平下所需的噪声减少20%，例如，在文本分类任务中这可以带来超过15个百分点的准确率提高。总体而言，这种统一的观点提供了一个原理性的框架，用于解释和校准DP在特定重识别、属性推理或数据重构风险水平下的保护程度。', 'title_zh': '统一辨识、属性推理和数据重构风险在差分隐私中的研究'}
{'arxiv_id': 'arXiv:2507.06967', 'title': 'Noisy PDE Training Requires Bigger PINNs', 'authors': 'Sebastien Andre-Sloan, Anirbit Mukherjee, Matthew Colbrook', 'link': 'https://arxiv.org/abs/2507.06967', 'abstract': "Physics-Informed Neural Networks (PINNs) are increasingly used to approximate solutions of partial differential equations (PDEs), especially in high dimensions. In real-world applications, data samples are noisy, so it is important to know when a predictor can still achieve low empirical risk. However, little is known about the conditions under which a PINN can do so effectively. We prove a lower bound on the size of neural networks required for the supervised PINN empirical risk to fall below the variance of noisy supervision labels. Specifically, if a predictor achieves an empirical risk $O(\\eta)$ below $\\sigma^2$ (variance of supervision data), then necessarily $d_N\\log d_N\\gtrsim N_s \\eta^2$, where $N_s$ is the number of samples and $d_N$ is the number of trainable parameters of the PINN. A similar constraint applies to the fully unsupervised PINN setting when boundary labels are sampled noisily. Consequently, increasing the number of noisy supervision labels alone does not provide a ``free lunch'' in reducing empirical risk. We also show empirically that PINNs can indeed achieve empirical risks below $\\sigma^2$ under such conditions. As a case study, we investigate PINNs applied to the Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for quantitatively understanding the parameter requirements for training PINNs in the presence of noise.", 'abstract_zh': '物理知情神经网络（PINNs）在高维偏微分方程（PDEs）解的逼近中日益受到重视。在实际应用中，数据样本存在噪声，因此了解预测器何时仍能实现低经验风险至关重要。然而，关于PINN何时能有效实现这一点的具体条件知之甚少。我们证明了在监督PINN情形下，使其经验风险低于噪声监督标签方差所需的神经网络规模下界。具体而言，如果预测器的经验风险低于$\\sigma^2$（监督数据方差）的$O(\\eta)$，则必定有$d_N\\log d_N\\gtrsim N_s \\eta^2$，其中$N_s$为样本数，$d_N$为PINN的可训练参数数。在边界标签噪声采样情况下，无监督PINN的类似约束同样适用。因此，单独增加噪声监督标签的数量并不能免费地降低经验风险。我们还通过实验表明，在这种条件下，PINNs确实能够实现低于$\\sigma^2$的经验风险。作为案例研究，我们探讨了PINNs在哈密尔顿-雅可比-贝尔曼（HJB）偏微分方程中的应用。我们的研究为在噪声存在情况下训练PINNs的参数需求提供了定量理解的基础。', 'title_zh': '噪声偏微分方程训练需要更大的PINNs'}
{'arxiv_id': 'arXiv:2507.06959', 'title': 'CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale', 'authors': 'Xiao Liang, Jiawei Hu, Di Wang, Zhi Ma, Lin Zhao, Ronghan Li, Bo Wan, Quan Wang', 'link': 'https://arxiv.org/abs/2507.06959', 'abstract': 'Vision-language models (VLMs) are prone to hallucinations that critically compromise reliability in medical applications. While preference optimization can mitigate these hallucinations through clinical feedback, its implementation faces challenges such as clinically irrelevant training samples, imbalanced data distributions, and prohibitive expert annotation costs. To address these challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy that combines confidence-similarity joint mining with counterfactual rationale. Our approach begins by synthesizing a unified, fine-grained multi-task chest X-ray visual instruction dataset across different question types for supervised fine-tuning (SFT). We then identify hard examples through token-level confidence analysis of SFT failures and use similarity-based retrieval to expand hard examples for balancing preference sample distributions, while synthetic counterfactual rationales provide fine-grained clinical preferences, eliminating the need for additional expert input. Experiments show that CheXPO achieves 8.93% relative performance gain using only 5% of SFT samples, reaching state-of-the-art performance across diverse clinical tasks and providing a scalable, interpretable solution for real-world radiology applications.', 'abstract_zh': 'Vision-language模型在医学应用中容易产生幻觉，这对可靠性构成严重威胁。尽管通过临床反馈可以优化偏好以减轻这些幻觉，但其实施面临临床无关的训练样本、数据分布不平衡和专家注释成本高昂的挑战。为应对这些挑战，我们引入了CheXPO，一种结合置信相似性联合开采与反事实解释的胸部X光偏好优化策略。该方法首先通过多层次胸部X光视觉指令数据集的合成，为监督微调（SFT）提供统一的多任务训练。随后，通过分析SFT失败的标记级置信度识别困难样本，并利用基于相似性的检索扩展这些困难样本，以平衡偏好样本分布。合成的反事实解释提供了细粒度的临床偏好，从而消除了额外专家输入的需要。实验表明，仅使用SFT样本的5%，CheXPO就能实现8.93%的相对性能提升，达到了各种临床任务的州最先进技术，并提供了一个可扩展且可解释的现实世界放射学应用解决方案。', 'title_zh': 'CheXPO：基于反事实解释的胸部X光VLMs偏好优化'}
{'arxiv_id': 'arXiv:2507.06952', 'title': 'What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models', 'authors': 'Keyon Vafa, Peter G. Chang, Ashesh Rambachan, Sendhil Mullainathan', 'link': 'https://arxiv.org/abs/2507.06952', 'abstract': "Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.", 'abstract_zh': '基础模型的前提在于序列预测能够揭示更深层次的领域理解，类似于开普勒对行星运动的预测后来促成了牛顿力学的发现。然而，评估这些模型是否真正捕捉到更深层次的结构仍然是一个挑战。我们开发了一种技术，该技术通过检查基础模型对从某个假设世界模型生成的合成数据集的适应性来评估基础模型。该技术衡量基础模型的归纳偏见是否与世界模型一致，因此我们将其称为归纳偏见探针。在多个领域中，我们发现基础模型在训练任务上表现优异，但在适应新任务时，未能发展出与底层世界模型相一致的归纳偏见。特别地，我们发现训练于轨道轨迹数据的基础模型在适应新的物理任务时，总是不能应用牛顿力学。进一步分析表明，这些模型的行为似乎表明它们发展了特定于任务的经验法则，无法实现泛化。', 'title_zh': '基于归纳偏置探究基础模型发现的世界模型'}
{'arxiv_id': 'arXiv:2507.06911', 'title': 'Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G', 'authors': "Michele Polese, Niloofar Mohamadi, Salvatore D'Oro, Tommaso Melodia", 'link': 'https://arxiv.org/abs/2507.06911', 'abstract': 'The proliferation of data-intensive Artificial Intelligence (AI) applications at the network edge demands a fundamental shift in RAN design, from merely consuming AI for network optimization, to actively enabling distributed AI workloads. This paradigm shift presents a significant opportunity for network operators to monetize AI at the edge while leveraging existing infrastructure investments. To realize this vision, this article presents a novel converged O-RAN and AI-RAN architecture that unifies orchestration and management of both telecommunications and AI workloads on shared infrastructure. The proposed architecture extends the Open RAN principles of modularity, disaggregation, and cloud-nativeness to support heterogeneous AI deployments. We introduce two key architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN Service Management and Orchestration (SMO) to enable integrated resource and allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide distributed edge AI platforms with real-time processing capabilities. The proposed system supports flexible deployment options, allowing AI workloads to be orchestrated with specific timing requirements (real-time or batch processing) and geographic targeting. The proposed architecture addresses the orchestration requirements for managing heterogeneous workloads at different time scales while maintaining open, standardized interfaces and multi-vendor interoperability.', 'abstract_zh': '网络边缘数据密集型人工智能应用的普及要求在RAN设计上实现根本性的转变，从 merely 消费AI以优化网络，转变为积极地使能分布式AI工作负载。这种范式的转变为网络运营商利用现有基础设施投资在边缘 monetize AI 提供了重大机会。为了实现这一愿景，本文提出了一种新型的融合O-RAN和AI-RAN架构，该架构在共享基础设施上统一管理和协调电信和AI工作负载。所提出的架构将O-RAN的模块化、分解和云原生原则扩展到支持异构AI部署。我们介绍了两项关键架构创新：（i）AI-RAN协调器，该协调器扩展了O-RAN服务管理与协调（SMO）以在RAN和AI工作负载之间实现集成的资源管理和分配；（ii）AI-RAN站点，提供分布式边缘AI平台并具备实时处理能力。所提出的系统支持灵活的部署选项，允许AI工作负载根据具体的时间要求（实时或批处理）和地理目标进行协调。所提出的架构解决了在不同时间尺度上管理异构工作负载的协调需求，同时保持开放的标准接口和多供应商互操作性。', 'title_zh': '超越连接性：面向6G的AI-RAN融合的开放架构'}
{'arxiv_id': 'arXiv:2507.06909', 'title': 'MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction', 'authors': 'Xiao Wang, Jiahuan Pei, Diancheng Shui, Zhiguang Han, Xin Sun, Dawei Zhu, Xiaoyu Shen', 'link': 'https://arxiv.org/abs/2507.06909', 'abstract': 'Legal judgment prediction offers a compelling method to aid legal practitioners and researchers. However, the research question remains relatively under-explored: Should multiple defendants and charges be treated separately in LJP? To address this, we introduce a new dataset namely multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating the performance of several prevailing legal large language models (LLMs) on four practical legal judgment scenarios: (S1) single defendant with a single charge, (S2) single defendant with multiple charges, (S3) multiple defendants with a single charge, and (S4) multiple defendants with multiple charges. We evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty term prediction. We have conducted extensive experiments and found that the scenario involving multiple defendants and multiple charges (S4) poses the greatest challenges, followed by S2, S3, and S1. The impact varies significantly depending on the model. For example, in S4 compared to S1, InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD, while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD. Our dataset and code are available at this https URL.', 'abstract_zh': '多被告人多罪名法律判决预测：一个新的研究视角与实证分析', 'title_zh': '多司法：一个多当事人、多罪名的中文法律预测数据集'}
{'arxiv_id': 'arXiv:2507.06908', 'title': 'MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection', 'authors': 'Ziyan Liu, Chunxiao Fan, Haoran Lou, Yuexin Wu, Kaiwei Deng', 'link': 'https://arxiv.org/abs/2507.06908', 'abstract': 'The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection. The code is available at this https URL.', 'abstract_zh': '社交媒体上 meme 的快速扩张凸显了有效检测有害内容的迫切需求。然而，传统基于数据的方法由于 meme 的演变性质和缺乏最新的标注数据，在检测新 meme 方面遇到困难。为了解决这一问题，我们提出了 MIND，一种无需标注数据的多agent框架，用于零样本有害 meme 检测。MIND 实现了三种关键策略：1）从未标注参考集中检索相似的 meme 以提供上下文信息。2）提出了一种双向洞察提取机制，以提取相似 meme 的全面理解。3）然后通过有根据的仲裁使用多agent辩论机制以确保稳健的决策。在三个 meme 数据集上的 extensive 实验表明，我们提出的框架不仅优于现有的零样本方法，而且在不同的模型架构和参数规模下具有强大的泛化能力，提供了有害 meme 检测的可扩展解决方案。代码详见此链接。', 'title_zh': 'MIND：零样本有害 meme 检测的多Agent框架'}
{'arxiv_id': 'arXiv:2507.06899', 'title': 'VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation', 'authors': 'Ziang Ye, Yang Zhang, Wentao Shi, Xiaoyu You, Fuli Feng, Tat-Seng Chua', 'link': 'https://arxiv.org/abs/2507.06899', 'abstract': "Graphical User Interface (GUI) agents powered by Large Vision-Language Models (LVLMs) have emerged as a revolutionary approach to automating human-machine interactions, capable of autonomously operating personal devices (e.g., mobile phones) or applications within the device to perform complex real-world tasks in a human-like manner. However, their close integration with personal devices raises significant security concerns, with many threats, including backdoor attacks, remaining largely unexplored. This work reveals that the visual grounding of GUI agent-mapping textual plans to GUI elements-can introduce vulnerabilities, enabling new types of backdoor attacks. With backdoor attack targeting visual grounding, the agent's behavior can be compromised even when given correct task-solving plans. To validate this vulnerability, we propose VisualTrap, a method that can hijack the grounding by misleading the agent to locate textual plans to trigger locations instead of the intended targets. VisualTrap uses the common method of injecting poisoned data for attacks, and does so during the pre-training of visual grounding to ensure practical feasibility of attacking. Empirical results show that VisualTrap can effectively hijack visual grounding with as little as 5% poisoned data and highly stealthy visual triggers (invisible to the human eye); and the attack can be generalized to downstream tasks, even after clean fine-tuning. Moreover, the injected trigger can remain effective across different GUI environments, e.g., being trained on mobile/web and generalizing to desktop environments. These findings underscore the urgent need for further research on backdoor attack risks in GUI agents.", 'abstract_zh': '由大规模视觉-语言模型驱动的图形用户界面（GUI）代理的漏洞及其后门攻击风险研究', 'title_zh': '视觉陷阱：通过视觉接地操纵实现GUI代理的隐蔽后门攻击'}
{'arxiv_id': 'arXiv:2507.06895', 'title': 'SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN', 'authors': 'Luca Mariotti, Veronica Guidetti, Federica Mandreoli', 'link': 'https://arxiv.org/abs/2507.06895', 'abstract': "The growing demand for efficient knowledge graph (KG) enrichment leveraging external corpora has intensified interest in relation extraction (RE), particularly under low-supervision settings. To address the need for adaptable and noise-resilient RE solutions that integrate seamlessly with pre-trained large language models (PLMs), we introduce SCoRE, a modular and cost-effective sentence-level RE system. SCoRE enables easy PLM switching, requires no finetuning, and adapts smoothly to diverse corpora and KGs. By combining supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN) classifier for multi-label classification, it delivers robust performance despite the noisy annotations of distantly supervised corpora. To improve RE evaluation, we propose two novel metrics: Correlation Structure Distance (CSD), measuring the alignment between learned relational patterns and KG structures, and Precision at R (P@R), assessing utility as a recommender system. We also release Wiki20d, a benchmark dataset replicating real-world RE conditions where only KG-derived annotations are available. Experiments on five benchmarks show that SCoRE matches or surpasses state-of-the-art methods while significantly reducing energy consumption. Further analyses reveal that increasing model complexity, as seen in prior work, degrades performance, highlighting the advantages of SCoRE's minimal design. Combining efficiency, modularity, and scalability, SCoRE stands as an optimal choice for real-world RE applications.", 'abstract_zh': '基于外部语料库的知识图谱（KG）增强日益增长的需求促进了在低监督环境下关系提取（RE）研究的兴趣。为了应对能够与预训练大规模语言模型（PLMs）无缝集成的可适应且抗噪声的RE解决方案的需求，我们提出了SCoRE，一种模块化且成本效益高的句级RE系统。SCoRE支持PLM的轻松切换，无需微调，并能平滑适应多种语料库和知识图谱。通过结合监督对比学习和贝叶斯k近邻（kNN）分类器进行多标签分类，尽管远程监督语料库带有噪声标注，仍能实现稳健的性能。为了改进RE评估，我们提出两种新的评估指标：关联结构距离（CSD），衡量学习到的关系模式与KG结构之间的对齐程度；以及R召回率（P@R），评估其作为推荐系统的实用性。我们还发布了Wiki20d，这是一个基准数据集，模仿了只有KG衍生的标注的真实世界RE场景。在五个基准上的实验结果显示，SCoRE在显著降低能耗的同时匹配或超越了最先进的方法。进一步的分析表明，如先前工作所见的增加模型复杂度会降低性能，突显了SCoRE简约设计的优势。结合效率、模块化和可扩展性，SCoRE是实际应用中理想的RE解决方案。', 'title_zh': 'SCoRE: 基于语料库的关系提取流水线方法：多标签对比学习与贝叶斯kNN'}
{'arxiv_id': 'arXiv:2507.06893', 'title': 'Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights', 'authors': 'Alexandra Abbas, Celia Waggoner, Justin Olive', 'link': 'https://arxiv.org/abs/2507.06893', 'abstract': 'AI evaluations have become critical tools for assessing large language model capabilities and safety. This paper presents practical insights from eight months of maintaining $inspect\\_evals$, an open-source repository of 70+ community-contributed AI evaluations. We identify key challenges in implementing and maintaining AI evaluations and develop solutions including: (1) a structured cohort management framework for scaling community contributions, (2) statistical methodologies for optimal resampling and cross-model comparison with uncertainty quantification, and (3) systematic quality control processes for reproducibility. Our analysis reveals that AI evaluation requires specialized infrastructure, statistical rigor, and community coordination beyond traditional software development practices.', 'abstract_zh': 'AI评估已成为评估大型语言模型能力和安全性的关键工具。本文基于维护八个月的开源AI评估库$inspect\\_evals$（包含70多个社区贡献的AI评估），提供了实用见解，并识别出实施和维护AI评估的关键挑战，提出了包括：（1）面向社区贡献的结构化群体管理框架，（2）最优重采样和跨模型比较的统计方法，包含不确定性量化，以及（3）可重复性的系统质量控制流程。我们的分析表明，AI评估需要专门的基础设施、统计严谨性和社区协调，超越传统的软件开发实践。', 'title_zh': '开发和维护一个开源AI评估仓库：挑战与见解'}
{'arxiv_id': 'arXiv:2507.06892', 'title': 'Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model', 'authors': 'Jing Liang, Hongyao Tang, Yi Ma, Jinyi Liu, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao', 'link': 'https://arxiv.org/abs/2507.06892', 'abstract': "Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.", 'abstract_zh': "强化学习（RL）在提升大型语言模型（LLMs）的推理能力方面展现了其潜力。大多数现有的强化调优（RFT）方法的主要局限是它们本质上是在线策略RL，即过去学习过程中生成的数据未被充分利用。这不可避免地导致了显著的计算和时间成本增加，成为继续经济高效扩展的严苛瓶颈。为此，我们重启了离线策略RL的复兴，并提出了Reincarnating Mix-policy Proximal Policy Gradient（ReMix），一种使如PPO和GRPO等在线策略RFT方法能够利用离线数据的通用方法。ReMix包括三大组成部分：（1）具有增加的Update-To-Data（UTD）比的Mix-policy近端策略梯度，以实现高效的训练；（2）KL-凸规划策约束，以平衡稳定性和灵活性之间的贸易关系；（3）策略转世，以实现从高效的初始阶段学习到稳定渐进改进的无缝过渡。在我们的实验中，我们基于PPO、GRPO和1.5B、7B基模型训练了一系列ReMix模型。对于1.5B模型，ReMix展示了52.10%的平均Pass@1准确率，使用了0.079M响应回放、350训练步骤；对于7B模型，ReMix达到了63.27%和64.39%的准确率，使用了0.007M/0.011M响应回放、50/75训练步骤，这在五个数学推理基准（即AIME'24、AMC'23、Minerva、OlympiadBench和MATH500）上进行了测试。与最近15个先进模型相比，ReMix在回放数据量方面展示了SOTA水平的表现，训练成本减少了30至450倍。此外，我们通过多方面的分析揭示了有趣的发现，包括由于离线偏差引起的鞭打效应偏好较短的响应，以及在严重离策略情况下的自我反思行为崩溃模式等。", 'title_zh': '挤干浸湿的海绵：高效的离策 reinforcement fine-tuningfor 大型语言模型'}
{'arxiv_id': 'arXiv:2507.06890', 'title': 'A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis', 'authors': 'Yifan Wang', 'link': 'https://arxiv.org/abs/2507.06890', 'abstract': 'Cyber-attacks jeopardize the safe operation of smart microgrids. At the same time, existing diagnostic methods either depend on expensive multi-point instrumentation or stringent modelling assumptions that are untenable under single-sensor constraints. This paper proposes a Fractional-Order Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency fault localisation and cyber-attack detection using only one VPQ (Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual fractional-order feature library by jointly applying Caputo and Grünwald-Letnikov derivatives, thereby amplifying micro-perturbations and slow drifts in the VPQ signal. A two-stage hierarchical classifier then pinpoints the affected inverter and isolates the faulty IGBT switch, effectively alleviating class imbalance. Robustness is further strengthened through Progressive Memory-Replay Adversarial Training (PMR-AT), whose attack-aware loss is dynamically re-weighted via Online Hard Example Mining (OHEM) to prioritise the most challenging samples. Experiments on a four-inverter microgrid testbed comprising 1 normal and 24 fault classes under four attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0 % (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining 96.7 % under attack-free conditions. These results establish FO-MADS as a cost-effective and readily deployable solution that markedly enhances the cyber-physical resilience of smart microgrids.', 'abstract_zh': '基于分数阶记忆增强的低延迟故障与网络攻击诊断方案（FO-MADS）', 'title_zh': '基于双分数阶特征分析的智能微电网稳健网络攻击诊断单一测量点框架'}
{'arxiv_id': 'arXiv:2507.06876', 'title': 'Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change', 'authors': 'Adrian Rauchfleisch, Joshua Philip Suarez, Nikka Marie Sales, Andreas Jungherr', 'link': 'https://arxiv.org/abs/2507.06876', 'abstract': "Public product launches in Artificial Intelligence can serve as focusing events for collective attention, surfacing how societies react to technological change. Social media provide a window into the sensemaking around these events, surfacing hopes and fears and showing who chooses to engage in the discourse and when. We demonstrate that public sensemaking about AI is shaped by economic interests and cultural values of those involved. We analyze 3.8 million tweets posted by 1.6 million users across 117 countries in response to the public launch of ChatGPT in 2022. Our analysis shows how economic self-interest, proxied by occupational skill types in writing, programming, and mathematics, and national cultural orientations, as measured by Hofstede's individualism, uncertainty avoidance, and power distance dimensions, shape who speaks, when they speak, and their stance towards ChatGPT. Roles requiring more technical skills, such as programming and mathematics, tend to engage earlier and express more positive stances, whereas writing-centric occupations join later with greater skepticism. At the cultural level, individualism predicts both earlier engagement and a more negative stance, and uncertainty avoidance reduces the prevalence of positive stances but does not delay when users first engage with ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study. The shift toward a more critical stance towards ChatGPT over time stems primarily from the entry of more skeptical voices rather than a change of heart among early adopters. Our findings underscore the importance of both the occupational background and cultural context in understanding public reactions to AI.", 'abstract_zh': '人工智能领域的公共产品发布可以作为群体注意力集中的事件，揭示社会对技术变革的反应。社交媒体提供了这些事件感知含义的窗口，揭示了人们的希望与恐惧，并展示了选择参与讨论的人及其时间。我们证明了人们对AI的公共感知受参与者经济利益和文化价值观的影响。我们分析了2022年ChatGPT公布后，来自117个国家的160万用户发布的380万条推文。分析显示，写作、编程和数学等职业技能类型以及以霍夫斯泰德个体主义、不确定性规避和权力距离维度衡量的国家文化取向，影响了谁发言、何时发言及其对ChatGPT的态度。需要更多技术技能的职位更早参与并表达更积极的态度，而以写作为中心的职业则后来参与并持更大疑虑的态度。在文化层面，个体主义预测了更早参与和更负面的态度，不确定性规避减少了积极态度的频率，但不影响用户首次参与ChatGPT的时间。总体情绪趋势掩盖了我们在研究中观察到的动力学。对ChatGPT的态度从更批判性转变为较悲观主要由更多怀疑论声音的进入而非早期采用者态度的改变所致。我们的研究强调了理解和解释公众对AI的反应时，职业背景和文化环境的重要性。', 'title_zh': '人工智能的胜败之道：关于ChatGPT的公共 discourse 告诉我们社会如何理解技术变革'}
{'arxiv_id': 'arXiv:2507.06856', 'title': 'IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization', 'authors': 'Subrat Kishore Dutta, Xiao Zhang', 'link': 'https://arxiv.org/abs/2507.06856', 'abstract': 'Despite modifying only a small localized input region, adversarial patches can drastically change the prediction of computer vision models. However, prior methods either cannot perform satisfactorily under targeted attack scenarios or fail to produce contextually coherent adversarial patches, causing them to be easily noticeable by human examiners and insufficiently stealthy against automatic patch defenses. In this paper, we introduce IAP, a novel attack framework that generates highly invisible adversarial patches based on perceptibility-aware localization and perturbation optimization schemes. Specifically, IAP first searches for a proper location to place the patch by leveraging classwise localization and sensitivity maps, balancing the susceptibility of patch location to both victim model prediction and human visual system, then employs a perceptibility-regularized adversarial loss and a gradient update rule that prioritizes color constancy for optimizing invisible perturbations. Comprehensive experiments across various image benchmarks and model architectures demonstrate that IAP consistently achieves competitive attack success rates in targeted settings with significantly improved patch invisibility compared to existing baselines. In addition to being highly imperceptible to humans, IAP is shown to be stealthy enough to render several state-of-the-art patch defenses ineffective.', 'abstract_zh': '基于感知导向定位与扰动优化的高 invisibility 对抗补丁攻击框架', 'title_zh': 'IAP：感知aware定位与扰动优化下的隐形 adversarial 块攻击'}
{'arxiv_id': 'arXiv:2507.06853', 'title': 'DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models', 'authors': 'Liang Wang, Yu Rong, Tingyang Xu, Zhenyi Zhong, Zhiyuan Liu, Pengju Wang, Deli Zhao, Qiang Liu, Shu Wu, Liang Wang', 'link': 'https://arxiv.org/abs/2507.06853', 'abstract': 'Molecular structure elucidation from spectra is a foundational problem in chemistry, with profound implications for compound identification, synthesis, and drug development. Traditional methods rely heavily on expert interpretation and lack scalability. Pioneering machine learning methods have introduced retrieval-based strategies, but their reliance on finite libraries limits generalization to novel molecules. Generative models offer a promising alternative, yet most adopt autoregressive SMILES-based architectures that overlook 3D geometry and struggle to integrate diverse spectral modalities. In this work, we present DiffSpectra, a generative framework that directly infers both 2D and 3D molecular structures from multi-modal spectral data using diffusion models. DiffSpectra formulates structure elucidation as a conditional generation process. Its denoising network is parameterized by Diffusion Molecule Transformer, an SE(3)-equivariant architecture that integrates topological and geometric information. Conditioning is provided by SpecFormer, a transformer-based spectral encoder that captures intra- and inter-spectral dependencies from multi-modal spectra. Extensive experiments demonstrate that DiffSpectra achieves high accuracy in structure elucidation, recovering exact structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through sampling. The model benefits significantly from 3D geometric modeling, SpecFormer pre-training, and multi-modal conditioning. These results highlight the effectiveness of spectrum-conditioned diffusion modeling in addressing the challenge of molecular structure elucidation. To our knowledge, DiffSpectra is the first framework to unify multi-modal spectral reasoning and joint 2D/3D generative modeling for de novo molecular structure elucidation.', 'abstract_zh': '从光谱推断分子结构是化学中的一个基础问题，对于化合物识别、合成和药物开发具有深远影响。传统方法严重依赖专家解读，并缺乏可扩展性。创新型机器学习方法引入了检索策略，但依赖有限的数据库限制了其对新型分子的泛化能力。生成模型提供了一种有前景的替代方案，但大多数采用基于自回归SMILES的架构，忽视了三维几何结构，并难以整合多种光谱模态。在本工作中，我们提出了一种生成框架DiffSpectra，该框架利用扩散模型直接从多模态光谱数据推断出2D和3D分子结构。DiffSpectra将结构推断公式化为一个条件生成过程。其去噪网络由SE(3)-对称的扩散分子变压器参数化，整合了拓扑和几何信息。条件信息由基于变压器的光谱编码器SpecFormer提供，该编码器可以从多模态光谱中捕获体内和体间光谱依赖性。广泛的经验表明，DiffSpectra在结构推断中实现了高精度，通过采样获得精确结构的准确率为16.01%，前20位的准确率为96.86%。该模型显著受益于三维几何建模、SpecFormer预训练和多模态条件。这些结果突显了光谱条件下的扩散建模在分子结构推断挑战中的有效性。据我们所知，DiffSpectra是首个统一多模态光谱推理和联合2D/3D生成建模的框架，用于从头推断分子结构。', 'title_zh': 'DiffSpectra：使用扩散模型从光谱推断分子结构'}
{'arxiv_id': 'arXiv:2507.06850', 'title': 'The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover', 'authors': 'Matteo Lupinacci, Francesco Aurelio Pironti, Francesco Blefari, Francesco Romeo, Luigi Arena, Angelo Furfaro', 'link': 'https://arxiv.org/abs/2507.06850', 'abstract': 'The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.', 'abstract_zh': '大型语言模型代理和多代理系统的快速采纳为自然语言处理和生成提供了前所未有的能力。然而，这些系统引入了超出传统提示注入攻击的前所未有的安全漏洞。本文首次全面评估了大型语言模型代理作为攻击向量的能力，这些代理通过利用代理型人工智能系统中自主实体之间的信任边界来实现对整个计算机系统的完全接管。我们展示了对手可以利用三种不同的攻击面——直接提示注入、RAG后门攻击和代理间信任利用——来迫使流行的大型语言模型（包括GPT-4o、Claude-4和Gemini-2.5）自主安装和执行恶意软件。对17个最先进的大型语言模型的评估揭示了一个令人惊讶的漏洞层级：41.2%的模型对直接提示注入易受攻击，52.9%的模型对RAG后门攻击易受攻击，而至关重要的82.4%的模型可以通过代理间信任利用被妥协。值得注意的是，我们发现那些成功抵制直接恶意命令的大型语言模型在接到其他代理请求时会执行相同的负载，揭示了当前多代理安全模型中的根本缺陷。我们的研究结果表明，只有5.9%（1/17）的测试模型对所有攻击向量都具有抵抗力，大多数模型表现出上下文相关的安全行为，这些行为创造了可利用的安全盲点。我们的研究结果还强调了提高对大型语言模型安全风险的认识和研究的必要性，显示出网络安全威胁的一个 paradigm shift，即AI工具本身也成为复杂的攻击向量。', 'title_zh': 'LLMs的暗面：基于代理的攻击对完全计算机接管'}
{'arxiv_id': 'arXiv:2507.06849', 'title': 'OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion', 'authors': 'Yizhuo Wu, Ang Li, Chang Gao', 'link': 'https://arxiv.org/abs/2507.06849', 'abstract': 'Neural network (NN)-based Digital Predistortion (DPD) stands out in improving signal quality in wideband radio frequency (RF) power amplifiers (PAs) employing complex modulation. However, NN DPDs usually rely on a large number of parameters for effective linearization and can significantly contribute to the energy consumption of the digital back-end in RF systems. This paper presents OpenDPDv2, a unified framework for PA modeling, DPD learning, and model optimization to reduce power consumption while maintaining high linearization performance. The optimization techniques feature a novel DPD algorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The top-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an Adjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude (EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal sparsity of input signals and hidden neurons, the inference energy of our model can be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM with 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth 256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code, datasets, and documentation are publicly accessible at: this https URL.', 'abstract_zh': '基于神经网络的数字预失真（NN-DPD）在宽频带射频功率放大器（PA）采用复杂调制时显著提高了信号质量。然而，NN DPD通常需要大量的参数以实现有效的线性化，这会显著增加射频系统中数字后端的能耗。本文提出了一种统一框架OpenDPDv2，用于PA建模、DPD学习和模型优化，以降低能耗同时保持高线性化性能。优化技术包括一种新型DPD算法TRes-DeltaGRU以及两种能效方法。性能最佳的32位浮点数（FP32）TRes-DeltaGRU-DPD模型实现了-59.4 dBc的相邻通道功率比（ACPR）和-42.1 dBc的误差矢量幅度（EVM）。通过利用定点量化和输入信号及隐藏神经元的动态时域稀疏性，模型的推理能耗可降低4.5倍，同时保持-50.3 dBc的ACPR和-35.2 dB的EVM，其中时域稀疏性为56%。该研究使用带宽为200 MHz的TM3.1a 256-QAM OFDM信号应用于3.5 GHz GaN Doherty射频PA进行评估。OpenDPDv2代码、数据集和文档已公开访问：this https URL。', 'title_zh': 'OpenDPDv2: 统一的神经网络数字预失真学习与优化框架'}
{'arxiv_id': 'arXiv:2507.06830', 'title': 'Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation', 'authors': 'Tao Feng, Xianbing Zhao, Zhenhua Chen, Tien Tsin Wong, Hamid Rezatofighi, Gholamreza Haffari, Lizhen Qu', 'link': 'https://arxiv.org/abs/2507.06830', 'abstract': 'Recent advances in diffusion-based and autoregressive video generation models have achieved remarkable visual realism. However, these models typically lack accurate physical alignment, failing to replicate real-world dynamics in object motion. This limitation arises primarily from their reliance on learned statistical correlations rather than capturing mechanisms adhering to physical laws. To address this issue, we introduce a novel framework that integrates symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for physics-grounded video forecasting. Our approach extracts motion trajectories from input videos, uses a retrieval-based pre-training mechanism to enhance symbolic regression, and discovers equations of motion to forecast physically accurate future trajectories. These trajectories then guide video generation without requiring fine-tuning of existing models. Evaluated on scenarios in Classical Mechanics, including spring-mass, pendulums, and projectile motions, our method successfully recovers ground-truth analytical equations and improves the physical alignment of generated videos over baseline methods.', 'abstract_zh': 'Recent Advances in Physics-Grounded Video Forecasting via Symbolic Regression and Trajectory-Guided Image-to-Video Models', 'title_zh': '基于物理原理的动力学预测：方程发现方法在轨迹引导的图像生成视频中的应用'}
{'arxiv_id': 'arXiv:2507.06828', 'title': 'Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data', 'authors': 'Xuesong Li, Nassir Navab, Zhongliang Jiang', 'link': 'https://arxiv.org/abs/2507.06828', 'abstract': 'Image denoising is a fundamental task in computer vision, particularly in medical ultrasound (US) imaging, where speckle noise significantly degrades image quality. Although recent advancements in deep neural networks have led to substantial improvements in denoising for natural images, these methods cannot be directly applied to US speckle noise, as it is not purely random. Instead, US speckle arises from complex wave interference within the body microstructure, making it tissue-dependent. This dependency means that obtaining two independent noisy observations of the same scene, as required by pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also cannot handle US speckle noise due to its high spatial dependency. To address this challenge, we introduce Speckle2Self, a novel self-supervised algorithm for speckle reduction using only single noisy observations. The key insight is that applying a multi-scale perturbation (MSP) operation introduces tissue-dependent variations in the speckle pattern across different scales, while preserving the shared anatomical structure. This enables effective speckle suppression by modeling the clean image as a low-rank signal and isolating the sparse noise component. To demonstrate its effectiveness, Speckle2Self is comprehensively compared with conventional filter-based denoising algorithms and SOTA learning-based methods, using both realistic simulated US images and human carotid US images. Additionally, data from multiple US machines are employed to evaluate model generalization and adaptability to images from unseen domains. \\textit{Code and datasets will be released upon acceptance.', 'abstract_zh': '基于单噪声观察的斑点自缩减方法：Speckle2Self', 'title_zh': 'Speckle2Self: 不依赖干净数据的自监督超声 speckle 去噪'}
{'arxiv_id': 'arXiv:2507.06825', 'title': 'Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning', 'authors': 'Matej Straka, Martin Schmid', 'link': 'https://arxiv.org/abs/2507.06825', 'abstract': 'We introduce a real-time strategy game environment built on this http URL, a game that hosts thousands of active players each week across multiple game formats. Our environment is fully compatible with Gymnasium and PettingZoo, capable of running thousands of frames per second on commodity hardware. Our reference agent -- trained with supervised pre-training and self-play -- hits the top 0.003\\% of the 1v1 human leaderboard after just 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions -- a modular RTS benchmark and a competitive, state-of-the-art baseline agent -- provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research.', 'abstract_zh': '基于这个网址构建的实时战略游戏环境：数千名玩家每周在多种游戏格式中活跃参与。我们的环境与Gymnasium和PettingZoo完全兼容，在普通硬件上可以每秒运行数千帧。参考代理——通过监督预训练和自我博弈训练，在单个H100 GPU上运行36小时后达到1v1人类排行榜的前0.003%。为了加速学习，我们加入了基于潜力的奖励塑造和记忆特征。我们的贡献包括一个模块化的RTS基准和一个竞争力强、处于最新技术水平的基线多代理强化学习代理，为推进多代理强化学习研究提供了一个易于访问但具有挑战性的平台。', 'title_zh': '人工通用智能：使用强化学习掌握Generals.io游戏技巧'}
{'arxiv_id': 'arXiv:2507.06821', 'title': 'HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning', 'authors': 'Chuhang Zheng, Chunwei Tian, Jie Wen, Daoqiang Zhang, Qi Zhu', 'link': 'https://arxiv.org/abs/2507.06821', 'abstract': 'Multi-modal emotion recognition has garnered increasing attention as it plays a significant role in human-computer interaction (HCI) in recent years. Since different discrete emotions may exist at the same time, compared with single-class emotion recognition, emotion distribution learning (EDL) that identifies a mixture of basic emotions has gradually emerged as a trend. However, existing EDL methods face challenges in mining the heterogeneity among multiple modalities. Besides, rich semantic correlations across arbitrary basic emotions are not fully exploited. In this paper, we propose a multi-modal emotion distribution learning framework, named HeLo, aimed at fully exploring the heterogeneity and complementary information in multi-modal emotional data and label correlation within mixed basic emotions. Specifically, we first adopt cross-attention to effectively fuse the physiological data. Then, an optimal transport (OT)-based heterogeneity mining module is devised to mine the interaction and heterogeneity between the physiological and behavioral representations. To facilitate label correlation learning, we introduce a learnable label embedding optimized by correlation matrix alignment. Finally, the learnable label embeddings and label correlation matrices are integrated with the multi-modal representations through a novel label correlation-driven cross-attention mechanism for accurate emotion distribution learning. Experimental results on two publicly available datasets demonstrate the superiority of our proposed method in emotion distribution learning.', 'abstract_zh': '多模态情感分布学习在近年的人机交互（HCI）中引起了广泛关注。现有的情感分布学习方法在挖掘多模态之间的异质性方面面临挑战，同时未能充分利用基本情感之间的丰富语义关联。为了解决这些问题，我们提出了一种名为HeLo的多模态情感分布学习框架，旨在充分探索多模态情感数据及其标签在混合基本情感中的异质性和互补信息。具体地，我们首先采用跨注意力机制有效融合生理数据，然后设计了一种基于最优传输（OT）的异质性挖掘模块，以挖掘生理和行为表示之间的交互和异质性。为了促进标签关联学习，我们引入了通过相关矩阵对齐优化的可学习标签嵌入。最后，通过一种新颖的情感分布驱动的跨注意力机制，将可学习标签嵌入和标签相关矩阵与多模态表示结合起来，实现精确的情感分布学习。在两个公开数据集上的实验结果表明，我们提出的方法在情感分布学习方面具有优越性。', 'title_zh': 'HeLo：具有标签相关性的异构多模态融合情感分布学习'}
{'arxiv_id': 'arXiv:2507.06819', 'title': 'Comprehensive Evaluation of Prototype Neural Networks', 'authors': 'Philipp Schlinge, Steffen Meinert, Martin Atzmueller', 'link': 'https://arxiv.org/abs/2507.06819', 'abstract': 'Prototype models are an important method for explainable artificial intelligence (XAI) and interpretable machine learning. In this paper, we perform an in-depth analysis of a set of prominent prototype models including ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive set of metrics. In addition to applying standard metrics from literature, we propose several new metrics to further complement the analysis of model interpretability. In our experimentation, we apply the set of prototype models on a diverse set of datasets including fine-grained classification, Non-IID settings and multi-label classification to further contrast the performance. Furthermore, we also provide our code as an open-source library, which facilitates simple application of the metrics itself, as well as extensibility - providing the option for easily adding new metrics and models. this https URL', 'abstract_zh': '原型模型是可解释人工智能(XAI)和可解释机器学习的重要方法。本文对ProtoPNet、ProtoPool和PIPNet等一组突出的原型模型进行了深入分析。为了评估这些模型，我们应用了一整套综合的评估指标。除了应用文献中的标准指标，我们还提出了几种新的指标，以进一步补充模型可解释性的分析。在我们的实验中，我们将原型模型应用于多种数据集，包括细粒度分类、非伊id设置和多标签分类，以进一步对比性能。此外，我们还提供了作为开源库的代码，该库不仅方便直接应用这些指标，还支持扩展，提供轻松添加新指标和模型的选项。', 'title_zh': '原型神经网络综合评估'}
{'arxiv_id': 'arXiv:2507.06813', 'title': 'Intrinsic Training Signals for Federated Learning Aggregation', 'authors': 'Cosimo Fiorini, Matteo Mosconi, Pietro Buzzega, Riccardo Salami, Simone Calderara', 'link': 'https://arxiv.org/abs/2507.06813', 'abstract': 'Federated Learning (FL) enables collaborative model training across distributed clients while preserving data privacy. While existing approaches for aggregating client-specific classification heads and adapted backbone parameters require architectural modifications or loss function changes, our method uniquely leverages intrinsic training signals already available during standard optimization. We present LIVAR (Layer Importance and VARiance-based merging), which introduces: i) a variance-weighted classifier aggregation scheme using naturally emergent feature statistics, and ii) an explainability-driven LoRA merging technique based on SHAP analysis of existing update parameter patterns. Without any architectural overhead, LIVAR achieves state-of-the-art performance on multiple benchmarks while maintaining seamless integration with existing FL methods. This work demonstrates that effective model merging can be achieved solely through existing training signals, establishing a new paradigm for efficient federated model aggregation. The code will be made publicly available upon acceptance.', 'abstract_zh': '联邦学习 (FL) 允许在分布式客户端之间协作训练模型的同时保护数据隐私。我们的方法独特地利用了标准优化过程中固有可用的训练信号。我们提出了一种基于特征统计自然涌现的方差加权分类器聚合方案，并结合基于 SHAP 分析的可解释性驱动的 LoRA 聚合技术。不增加任何架构开销，LIVAR 在多个基准测试上实现了最先进的性能，同时保持与现有联邦学习方法的无缝集成。这项工作表明，有效的模型聚合仅通过现有训练信号即可实现，建立了联邦模型聚合的新范式。接受后代码将公开发布。', 'title_zh': '联邦学习聚合中的固有训练信号'}
{'arxiv_id': 'arXiv:2507.06812', 'title': 'Democratizing High-Fidelity Co-Speech Gesture Video Generation', 'authors': 'Xu Yang, Shaoli Huang, Shenbo Xie, Xuelin Chen, Yifei Liu, Changxing Ding', 'link': 'https://arxiv.org/abs/2507.06812', 'abstract': "Co-speech gesture video generation aims to synthesize realistic, audio-aligned videos of speakers, complete with synchronized facial expressions and body gestures. This task presents challenges due to the significant one-to-many mapping between audio and visual content, further complicated by the scarcity of large-scale public datasets and high computational demands. We propose a lightweight framework that utilizes 2D full-body skeletons as an efficient auxiliary condition to bridge audio signals with visual outputs. Our approach introduces a diffusion model conditioned on fine-grained audio segments and a skeleton extracted from the speaker's reference image, predicting skeletal motions through skeleton-audio feature fusion to ensure strict audio coordination and body shape consistency. The generated skeletons are then fed into an off-the-shelf human video generation model with the speaker's reference image to synthesize high-fidelity videos. To democratize research, we present CSG-405-the first public dataset with 405 hours of high-resolution videos across 71 speech types, annotated with 2D skeletons and diverse speaker demographics. Experiments show that our method exceeds state-of-the-art approaches in visual quality and synchronization while generalizing across speakers and contexts.", 'abstract_zh': '同步语言手势视频生成旨在合成与音频同步、具有同步面部表情和身体手势的模拟视频。由于音频与视觉内容之间存在显著的一对多映射关系，加之大规模公共数据集稀缺和高计算需求的复杂性，使得此任务充满挑战。我们提出了一种轻量级框架，利用2D全身骨架作为高效辅助条件以桥接音频信号和视觉输出。我们的方法通过细粒度音频片段和从演讲者参考图像中提取的骨架条件化一个扩散模型，预测通过骨架-音频特征融合得到的骨架动作，确保严格的音频同步和身体形状一致性。生成的骨架随后被输入到带有演讲者参考图像的标准现成人类视频生成模型中以合成高保真视频。为了普惠研究，我们呈现了CSG-405数据集——首个包含405小时高分辨率视频、覆盖71种语音类型且附带2D骨架和多元演讲者人口统计信息的公共数据集。实验结果表明，我们的方法在视觉质量和同步性方面超过了现有最先进的方法，能够在不同演讲者和场景下泛化。', 'title_zh': '高保真同声手势视频生成的民主化'}
{'arxiv_id': 'arXiv:2507.06804', 'title': 'Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving', 'authors': 'Zhenwen Liang, Linfeng Song, Yang Li, Tao Yang, Feng Zhang, Haitao Mi, Dong Yu', 'link': 'https://arxiv.org/abs/2507.06804', 'abstract': "Automated Theorem Proving (ATP) in formal languages is a foundational challenge for AI. While Large Language Models (LLMs) have driven remarkable progress, a significant gap remains between their powerful informal reasoning capabilities and their weak formal proving performance. Recent studies show that the informal accuracy exceeds 80% while formal success remains below 8% on benchmarks like PutnamBench. We argue this gap persists because current state-of-the-art provers, by tightly coupling reasoning and proving, are trained with paradigms that inadvertently punish deep reasoning in favor of shallow, tactic-based strategies. To bridge this fundamental gap, we propose a novel framework that decouples high-level reasoning from low-level proof generation. Our approach utilizes two distinct, specialized models: a powerful, general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an efficient Prover to rigorously verify them. This modular design liberates the model's full reasoning potential and bypasses the pitfalls of end-to-end training. We evaluate our method on a challenging set of post-2000 IMO problems, a problem set on which no prior open-source prover has reported success. Our decoupled framework successfully solves 5 of these problems, demonstrating a significant step towards automated reasoning on exceptionally difficult mathematical challenges. To foster future research, we release our full dataset of generated and verified lemmas for a wide range of IMO problems, available at this https URL .", 'abstract_zh': '形式语言中的自动定理证明（ATP）是AI的基础挑战。尽管大型语言模型（LLMs）已经推动了显著的进步，但在其强大的非正式推理能力和薄弱的形式证明性能之间仍存在显著差距。最近的研究显示，在PutnamBench等基准测试中，非正式准确性超过80%，而形式成功率低于8%。我们argue这一差距持续存在，因为当前最先进的证明工具通过紧密耦合推理与证明，以无意中惩罚深层推理而偏好浅层、策略性的方法进行训练。为了弥合这一根本差距，我们提出了一种新的框架，将高层次推理与低层次证明生成解耦。我们的方法利用两种专门化的模型：一个强大的通用推理器（Reasoner）生成多样化的、战略性的子目标引理，以及一个高效的验证器（Prover）严格验证它们。这种模块化设计解放了模型的全部推理潜力，并绕过了端到端训练的陷阱。我们将在2000年后的IMO难题上评估我们的方法，这是迄今为止没有任何开源证明工具报告成功的难题集。我们的解耦框架成功解决了其中5个问题，展示了在处理极其复杂的数学挑战方面迈出的重要一步。为了促进未来研究，我们提供了涵盖广泛IMO问题的生成和验证引理的完整数据集，可通过以下链接访问：这个https URL。', 'title_zh': '通过解耦推理与证明走向解决更具有挑战性的国际数学奥林匹克问题'}
{'arxiv_id': 'arXiv:2507.06803', 'title': 'Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams', 'authors': 'Matthew Anderson Hendricks, Alice Cicirello', 'link': 'https://arxiv.org/abs/2507.06803', 'abstract': 'This paper contributes to speeding up the design and deployment of engineering dynamical systems by proposing a strategy for exploiting domain and expert knowledge for the automated generation of dynamical system computational model starting from a corpus of document relevant to the dynamical system of interest and an input document describing the specific system. This strategy is implemented in five steps and, crucially, it uses system modeling language diagrams (SysML) to extract accurate information about the dependencies, attributes, and operations of components. Natural Language Processing (NLP) strategies and Large Language Models (LLMs) are employed in specific tasks to improve intermediate outputs of the SySML diagrams automated generation, such as: list of key nouns; list of extracted relationships; list of key phrases and key relationships; block attribute values; block relationships; and BDD diagram generation. The applicability of automated SysML diagram generation is illustrated with different case studies. The computational models of complex dynamical systems from SysML diagrams are then obtained via code generation and computational model generation steps. In the code generation step, NLP strategies are used for summarization, while LLMs are used for validation only. The proposed approach is not limited to a specific system, domain, or computational software. The applicability of the proposed approach is shown via an end-to-end example from text to model of a simple pendulum, showing improved performance compared to results yielded by LLMs only.', 'abstract_zh': '本文通过提议一种策略，利用领域和专家知识自动生成动态系统计算模型，从而加速工程动态系统的设计和部署，该策略基于与感兴趣的动态系统相关的文档集和描述特定系统的输入文档实施。该策略分为五个步骤，并且关键的是，它使用系统建模语言图表（SysML）来提取关于组件之间的依赖关系、属性和操作的准确信息。通过自然语言处理（NLP）策略和大型语言模型（LLMs）在特定任务中的应用，改进了SysML图表自动生成的中间输出，如关键名词列表；提取的关系列表；关键短语和关键关系列表；模块属性值；模块关系；以及BDD图表生成。自动化SysML图表生成的应用性通过不同的案例研究进行了说明。通过代码生成和计算模型生成步骤，从SysML图表中获得了复杂动态系统的计算模型。在代码生成步骤中，NLP策略用于总结，而LLMs仅用于验证。所提出的方法不限于特定的系统、领域或计算软件。所提出的方法的适用性通过从文本到简单摆锤模型的端到端示例进行了展示，显示出与仅由LLMs生成的结果相比的改进性能。', 'title_zh': '通过SysML将文本转换为模型：基于增强的System Modeling Language图 автомат化生成动态系统计算模型从非结构化的自然语言文本'}
{'arxiv_id': 'arXiv:2507.06795', 'title': 'Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications', 'authors': 'Seonwu Kim, Yohan Na, Kihun Kim, Hanhee Cho, Geun Lim, Mintae Kim, Seongik Park, Ki Hyun Kim, Youngsub Han, Byoung-Ki Jeon', 'link': 'https://arxiv.org/abs/2507.06795', 'abstract': 'The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.', 'abstract_zh': '开源大型语言模型的出现扩展了企业应用的机会；然而，许多组织仍然缺乏部署和维护大规模模型的基础设施。因此，小型语言模型（sLLMs）成为一种实用的替代方案，尽管它们存在固有的性能限制。虽然领域适应连续预训练（DACP）曾作为一种领域适应的方法被探索过，但其在商业应用中的实用性仍然尚未充分 examination。在本研究中，我们验证了基于 DACP 的方法在不同基础模型和服务领域中的有效性。通过广泛的实验和实际评价，我们证明了应用 DACP 的 sLLMs 在目标领域的性能取得了显著提升，同时保留了一般能力，提供了一种成本效益高且可扩展的面向企业的部署解决方案。', 'title_zh': '通过领域适应连续预训练提高工业领域的sLLMs效率：方法、评估与应用'}
{'arxiv_id': 'arXiv:2507.06782', 'title': 'Temporal Information Retrieval via Time-Specifier Model Merging', 'authors': 'SeungYoon Han, Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, Huije Lee, Jong C. Park', 'link': 'https://arxiv.org/abs/2507.06782', 'abstract': "The rapid expansion of digital information and knowledge across structured and unstructured sources has heightened the importance of Information Retrieval (IR). While dense retrieval methods have substantially improved semantic matching for general queries, they consistently underperform on queries with explicit temporal constraints--often those containing numerical expressions and time specifiers such as ``in 2015.'' Existing approaches to Temporal Information Retrieval (TIR) improve temporal reasoning but often suffer from catastrophic forgetting, leading to reduced performance on non-temporal queries. To address this, we propose Time-Specifier Model Merging (TSM), a novel method that enhances temporal retrieval while preserving accuracy on non-temporal queries. TSM trains specialized retrievers for individual time specifiers and merges them in to a unified model, enabling precise handling of temporal constraints without compromising non-temporal retrieval. Extensive experiments on both temporal and non-temporal datasets demonstrate that TSM significantly improves performance on temporally constrained queries while maintaining strong results on non-temporal queries, consistently outperforming other baseline methods. Our code is available at this https URL .", 'abstract_zh': '数字信息和知识在结构化和非结构化来源中的迅速扩展突显了信息检索（IR）的重要性。虽然密集检索方法在普通查询的语义匹配上已有显著改进，但在具有明确时间约束的查询上表现不佳——这些查询往往包含数值表达和时间限定词，如“2015年”。现有的时间信息检索（TIR）方法虽然能提高时间推理能力，但往往会遭受灾难性遗忘的困扰，导致非时间查询的性能下降。为解决这一问题，我们提出了时间限定词模型融合（TSM），这是一种新颖的方法，能够在增强时间检索的同时保持非时间查询的准确性。TSM为个别时间限定词训练专门的检索器，并将它们合并到一个统一模型中，从而能够精确处理时间约束，而不损害非时间检索的性能。通过对时间和非时间数据集进行广泛实验，结果表明TSM在时间约束查询上显著提高了性能，并在非时间查询上保持了强劲的结果，始终优于其他基准方法。我们的代码可在该网址获取。', 'title_zh': '时间信息检索通过时间限定词模型合并'}
{'arxiv_id': 'arXiv:2507.06763', 'title': 'FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views', 'authors': 'Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel', 'link': 'https://arxiv.org/abs/2507.06763', 'abstract': 'The framework is designed to improve performance in the analysis of combined as well as single anatomical perspectives for MRI disease diagnosis. It specifically addresses the performance degradation observed in state-of-the-art (SOTA) models, particularly when processing axial, coronal, and sagittal anatomical planes. The paper introduces the FOLC-Net framework, which incorporates a novel federated-optimized lightweight architecture with approximately 1.217 million parameters and a storage requirement of only 0.9 MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for efficient model structure generation, global model cloning for scalable training, and ConvNeXt for enhanced client adaptability. The model was evaluated on combined multi-view data as well as individual views, such as axial, coronal, and sagittal, to assess its robustness in various medical imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different data to evaluate its ability to generalize beyond the training dataset. The results show that FOLC-Net outperforms existing models, particularly in the challenging sagittal view. For instance, FOLC-Net achieved an accuracy of 92.44% on the sagittal view, significantly higher than the 88.37% accuracy of study method (DL + Residual Learning) and 88.95% of DL models. Additionally, FOLC-Net demonstrated improved accuracy across all individual views, providing a more reliable and robust solution for medical image analysis in decentralized environments. FOLC-Net addresses the limitations of existing SOTA models by providing a framework that ensures better adaptability to individual views while maintaining strong performance in multi-view settings. The incorporation of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs better in real-world medical applications.', 'abstract_zh': '一种用于改善联合及单一解剖视角下MRI疾病诊断性能的框架：FOLC-Net及其应用', 'title_zh': 'FOLC-Net：跨轴位、冠状位和矢状位增强MRI疾病诊断的优化轻量级联邦架构'}
{'arxiv_id': 'arXiv:2507.06753', 'title': 'KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution', 'authors': 'Ye Kyaw Thu, Thura Aung, Thazin Myint Oo, Thepchai Supnithi', 'link': 'https://arxiv.org/abs/2507.06753', 'abstract': 'This paper presents the first application of Kolmogorov-Arnold Convolution for Text (KAConvText) in sentence classification, addressing three tasks: imbalanced binary hate speech detection, balanced multiclass news classification, and imbalanced multiclass ethnic language identification. We investigate various embedding configurations, comparing random to fastText embeddings in both static and fine-tuned settings, with embedding dimensions of 100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we investigated KAConvText with different classification heads - MLP and KAN, where using KAN head supports enhanced interpretability. Results show that KAConvText-MLP with fine-tuned fastText embeddings achieves the best performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection, 92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82% accuracy (F1-score = 0.9982) for language identification.', 'abstract_zh': '本文首次将Kolmogorov-Arnold Convolution for Text (KAConvText) 应用到句子分类中，解决了三项任务：不平衡二分类仇恨言论检测、平衡多分类新闻分类以及不平衡多分类族裔语言识别。我们探讨了不同的嵌入配置，比较了随机嵌入和 fastText 嵌入在静态和微调设置下的表现，使用 CBOW 和 Skip-gram 模型，嵌入维度分别为 100 和 300。基线模型包括标准 CNN 和结合 Kolmogorov-Arnold 网络的 CNN (CNN-KAN)。此外，我们还研究了使用不同分类头的 KAConvText — MLP 和 KAN，其中使用 KAN 头支持增强的可解释性。结果表明，使用微调的 fastText 嵌入的 KAConvText-MLP 在仇恨言论检测中达到了 91.23% 的准确率（F1 分数 = 0.9109），在新闻分类中达到了 92.66% 的准确率（F1 分数 = 0.9267），在语言识别中达到了 99.82% 的准确率（F1 分数 = 0.9982）。', 'title_zh': 'KAConvText：基于柯尔莫戈洛夫-阿诺尔德卷积的缅甸语句分类新方法'}
{'arxiv_id': 'arXiv:2507.06738', 'title': 'DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement', 'authors': 'Xinyu Xie, Weifeng Cao, Jun Shi, Yangyang Hu, Hui Liang, Wanyong Liang, Xiaoliang Qian', 'link': 'https://arxiv.org/abs/2507.06738', 'abstract': 'Spatio-temporal video prediction plays a pivotal role in critical domains, ranging from weather forecasting to industrial automation. However, in high-precision industrial scenarios such as semiconductor manufacturing, the absence of specialized benchmark datasets severely hampers research on modeling and predicting complex processes. To address this challenge, we make a twofold this http URL, we construct and release the Chip Dicing Lane Dataset (CHDL), the first public temporal image dataset dedicated to the semiconductor wafer dicing process. Captured via an industrial-grade vision system, CHDL provides a much-needed and challenging benchmark for high-fidelity process modeling, defect detection, and digital twin this http URL, we propose DIFFUMA, an innovative dual-path prediction architecture specifically designed for such fine-grained dynamics. The model captures global long-range temporal context through a parallel Mamba module, while simultaneously leveraging a diffusion module, guided by temporal features, to restore and enhance fine-grained spatial details, effectively combating feature degradation. Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988. This superior performance also generalizes to natural phenomena datasets. Our work not only delivers a new state-of-the-art (SOTA) model but, more importantly, provides the community with an invaluable data resource to drive future research in industrial AI.', 'abstract_zh': '空间时间视频预测在天气预报、工业自动化等领域发挥着关键作用。然而，在如半导体制造这样的高精度工业场景中，缺乏专门的基准数据集严重阻碍了复杂过程建模和预测的研究。为应对这一挑战，我们从两个方面着手：首先，我们构建并发布了Chip Dicing Lane Dataset (CHDL)，这是首个专注于半导体晶圆切割过程的公开时间图像数据集。通过工业级视觉系统捕获，CHDL为高保真工艺建模、缺陷检测和数字孪生提供了急需且具有挑战性的基准。其次，我们提出了DIFFUMA，一种专门针对此类精细动态的创新双路径预测架构。该模型通过并行Mamba模块捕捉全局长时间上下文，同时利用受时间特征指导的扩散模块恢复和增强细粒度的空间细节，有效对抗特征退化。实验结果表明，在我们的CHDL基准上，DIFFUMA显著优于现有方法，使均方误差（MSE）降低了39%，结构相似性（SSIM）从0.926提升到近乎完美的0.988。这种性能优势同样适用于自然现象数据集。我们的工作不仅提供了新的前沿模型，更重要的是为社区提供了宝贵的数据资源，推动未来工业AI的研究。', 'title_zh': 'DIFFUMA: 高保真时空视频预测通过双路径Mamba和扩散增强'}
{'arxiv_id': 'arXiv:2507.06734', 'title': 'Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool', 'authors': 'Milena Pustet, Elisabeth Steffen, Helena Mihaljević, Grischa Stanjek, Yannis Illies', 'link': 'https://arxiv.org/abs/2507.06734', 'abstract': "The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.", 'abstract_zh': '民间社会组织（CSOs）在监控有害网络内容中的作用日益重要，尤其是在平台提供商减少内容审核投资的情况下。AI工具可以协助大规模检测和监控有害内容。然而，很少有开源工具能够无缝集成AI模型和社会媒体监控基础设施。鉴于CSOs在主题专业知识和有害内容情境理解方面的优势，他们应作为积极合作伙伴，在共同开发技术工具、提供反馈、改进模型以及确保符合利益相关方需求和价值观方面发挥作用，而非仅仅作为被动的“消费者”。然而，开源社区、学术界与民间社会组织之间的合作仍然很少见，有关有害内容的研究很少能够转化为可被民间社会组织使用的实际工具。本研究旨在探索CSOs如何在我们正在与CSO利益相关方合作开发的一个用于监控Telegram上的反民主运动的AI辅助开源监控工具中实现有意义的参与。', 'title_zh': '公民社会在环中: 反馈驱动的（L）LM辅助分类在开源电报监控工具中的自适应调整'}
{'arxiv_id': 'arXiv:2507.06715', 'title': 'CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs', 'authors': 'Garapati Keerthana, Manik Gupta', 'link': 'https://arxiv.org/abs/2507.06715', 'abstract': 'Large language models (LLMs), including zero-shot and few-shot paradigms, have shown promising capabilities in clinical text generation. However, real-world applications face two key challenges: (1) patient data is highly unstructured, heterogeneous, and scattered across multiple note types and (2) clinical notes are often long and semantically dense, making naive prompting infeasible due to context length constraints and the risk of omitting clinically relevant information.\nWe introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a domain-specific framework for structured and clinically grounded text generation using LLMs. It incorporates a novel hierarchical chunking strategy that respects clinical document structure and introduces a task-specific dual-stage retrieval mechanism. The global stage identifies relevant note types using evidence-based queries, while the local stage extracts high-value content within those notes creating relevance at both document and section levels.\nWe apply the system to generate structured progress notes for individual hospital visits using 15 clinical note types from the MIMIC-III dataset. Experiments show that it preserves temporal and semantic alignment across visits, achieving an average alignment score of 87.7%, surpassing the 80.7% baseline from real clinician-authored notes. The generated outputs also demonstrate high consistency across LLMs, reinforcing deterministic behavior essential for reproducibility, reliability, and clinical trust.', 'abstract_zh': '基于临床指导的检索增强生成框架（CLI-RAG）：面向临床文本结构化生成的领域特定框架', 'title_zh': 'CLI-RAG：一种基于检索增强的临床结构化和上下文感知文本生成框架（使用大型语言模型）'}
{'arxiv_id': 'arXiv:2507.06684', 'title': 'Photometric Stereo using Gaussian Splatting and inverse rendering', 'authors': 'Matéo Ducastel, David Tschumperlé, Yvain Quéau', 'link': 'https://arxiv.org/abs/2507.06684', 'abstract': 'Recent state-of-the-art algorithms in photometric stereo rely on neural networks and operate either through prior learning or inverse rendering optimization. Here, we revisit the problem of calibrated photometric stereo by leveraging recent advances in 3D inverse rendering using the Gaussian Splatting formalism. This allows us to parameterize the 3D scene to be reconstructed and optimize it in a more interpretable manner. Our approach incorporates a simplified model for light representation and demonstrates the potential of the Gaussian Splatting rendering engine for the photometric stereo problem.', 'abstract_zh': 'Recent State-of-the-Art Algorithms in Photometric Stereo Rely on Neural Networks and Operate through Prior Learning or Inverse Rendering Optimization: Revisiting Calibrated Photometric Stereo with Gaussian Splatting Formalism', 'title_zh': '基于高斯点扩散和逆渲染的光度立体视觉'}
{'arxiv_id': 'arXiv:2507.06674', 'title': 'Exploring State-Space-Model based Language Model in Music Generation', 'authors': 'Wei-Jaw Lee, Fang-Chih Hsieh, Xuanjun Chen, Fang-Duo Tsai, Yi-Hsuan Yang', 'link': 'https://arxiv.org/abs/2507.06674', 'abstract': 'The recent surge in State Space Models (SSMs), particularly the emergence of Mamba, has established them as strong alternatives or complementary modules to Transformers across diverse domains. In this work, we aim to explore the potential of Mamba-based architectures for text-to-music generation. We adopt discrete tokens of Residual Vector Quantization (RVQ) as the modeling representation and empirically find that a single-layer codebook can capture semantic information in music. Motivated by this observation, we focus on modeling a single-codebook representation and adapt SiMBA, originally designed as a Mamba-based encoder, to function as a decoder for sequence modeling. We compare its performance against a standard Transformer-based decoder. Our results suggest that, under limited-resource settings, SiMBA achieves much faster convergence and generates outputs closer to the ground truth. This demonstrates the promise of SSMs for efficient and expressive text-to-music generation. We put audio examples on Github.', 'abstract_zh': '最近State Space Models（SSMs）的崛起，尤其是Mamba的出现，已确立它们作为Transformer在多个领域中的有力替代方案或补充模块的地位。本工作旨在探索基于Mamba的架构在文本到音乐生成中的潜力。我们采用残差矢量量化（RVQ）的离散令牌作为建模表示，并实验证明单层码本可以捕捉音乐中的语义信息。受此观察的启发，我们将重点放在建模单码本表示上，并将最初作为Mamba基编码器设计的SiMBA适应性地转化为序列建模的解码器。我们将其性能与标准的Transformer基解码器进行比较。结果显示，在资源受限的设置下，SiMBA在收敛速度上更快，并生成与真实值更接近的输出。这表明SSMs在高效且富有表现力的文本到音乐生成中具有潜力。我们在Github上提供了音频示例。', 'title_zh': '基于状态空间模型的语言生成在音乐创作中的探索'}
{'arxiv_id': 'arXiv:2507.06658', 'title': 'Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models', 'authors': 'Gennadii Iakovlev', 'link': 'https://arxiv.org/abs/2507.06658', 'abstract': 'This project introduces a new measure of elite polarization via actor and subject detection using artificial intelligence. I identify when politicians mention one another in parliamentary speeches, note who is speaking and who is being addressed, and assess the emotional temperature behind these evaluations. This maps how elites evaluate their various out-parties, allowing us to create an index of mutual out-party hostility, that is, elite polarization. While I analyzed polarization data over the past four decades for the UK, and two decades for Hungary and Italy, my approach lays the groundwork for a twenty-year, EU-wide time-series dataset on elite polarization. I obtain the results that can be aggregated by party and quarter. The resulting index demonstrates a good face validity: it reacts to events such as electoral campaigns, country- and party-level crises, and to parties losing and assuming power.', 'abstract_zh': '本研究通过使用人工智能进行行为者和主题检测，提出了一种新的精英极化衡量方法。我识别出政治家在议会演讲中提到彼此的情况，记录发言者和被提及者，并评估这些评价背后的情感温度。这有助于映射精英对其各种反对派的评价方式，从而构建一个互对方针敌对指数，即精英极化。我分析了过去四十年的英国、以及过去二十年的匈牙利和意大利的极化数据，并提出了一个二十年期的欧盟范围内的精英极化时间序列数据集。结果可以按政党和季度进行汇总。所得指数具有良好的表面效度：它对诸如选举运动、国家和政党层面的危机以及政党失去和获得权力等事件作出反应。', 'title_zh': '欧洲议会演讲中的精英极化：一种新型的大语言模型测量方法'}
{'arxiv_id': 'arXiv:2507.06654', 'title': 'MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval', 'authors': 'Naoya Sogi, Takashi Shibata, Makoto Terao, Masanori Suganuma, Takayuki Okatani', 'link': 'https://arxiv.org/abs/2507.06654', 'abstract': "Result diversification (RD) is a crucial technique in Text-to-Image Retrieval for enhancing the efficiency of a practical application. Conventional methods focus solely on increasing the diversity metric of image appearances. However, the diversity metric and its desired value vary depending on the application, which limits the applications of RD. This paper proposes a novel task called CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims to refine the diversities of multiple attributes, according to the application's context. To address this task, we propose Multi-Source DPPs, a simple yet strong baseline that extends the Determinantal Point Process (DPP) to multi-sources. We model MS-DPP as a single DPP model with a unified similarity matrix based on a manifold representation. We also introduce Tangent Normalization to reflect contexts. Extensive experiments demonstrate the effectiveness of the proposed method. Our code is publicly available at this https URL.", 'abstract_zh': '基于上下文的复合属性多样化 refinement (CDR-CA)：文本到图像检索中的结果多样化', 'title_zh': 'MS-DPPs：多源行列式点过程在文本到图像检索中复合属性上下文多样性精炼中的应用'}
{'arxiv_id': 'arXiv:2507.06650', 'title': 'Deep Disentangled Representation Network for Treatment Effect Estimation', 'authors': 'Hui Meng, Keping Yang, Xuyu Peng, Bo Zheng', 'link': 'https://arxiv.org/abs/2507.06650', 'abstract': 'Estimating individual-level treatment effect from observational data is a fundamental problem in causal inference and has attracted increasing attention in the fields of education, healthcare, and public this http URL this work, we concentrate on the study of disentangled representation methods that have shown promising outcomes by decomposing observed covariates into instrumental, confounding, and adjustment factors. However, most of the previous work has primarily revolved around generative models or hard decomposition methods for covariates, which often struggle to guarantee the attainment of precisely disentangled factors. In order to effectively model different causal relationships, we propose a novel treatment effect estimation algorithm that incorporates a mixture of experts with multi-head attention and a linear orthogonal regularizer to softly decompose the pre-treatment variables, and simultaneously eliminates selection bias via importance sampling re-weighting techniques. We conduct extensive experiments on both public semi-synthetic and real-world production datasets. The experimental results clearly demonstrate that our algorithm outperforms the state-of-the-art methods focused on individual treatment effects.', 'abstract_zh': '从observational数据中估计个体水平的治疗效果是一个因果推断中的基本问题，近年来在教育、医疗和公共政策等领域引起了越来越多的关注。在本文中，我们专注于研究通过分解观测协变量为工具变量、干扰变量和调整变量的去耦表示方法。然而，大多数先前的工作主要集中在生成模型或硬分解方法上，这些方法往往难以保证精确地获得去耦变量。为了有效建模不同的因果关系，我们提出了一种新颖的治疗效果估计算法，该算法结合了专家混合与多头注意力机制和线性正交正则化器，以软性分解预处理变量，并通过重要性采样加权技术同时消除选择偏见。我们在公共半合成和真实世界生产数据集上进行了广泛实验。实验结果清楚地表明，我们的算法在专注于个体治疗效果的方法中表现更优。', 'title_zh': '深度解耦表示网络用于治疗效果估计'}
{'arxiv_id': 'arXiv:2507.06639', 'title': 'EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision', 'authors': 'Myungjang Pyeon, Janghyeon Lee, Minsoo Lee, Juseung Yun, Hwanil Choi, Jonghyun Kim, Jiwon Kim, Yi Hu, Jongseong Jang, Soonyoung Lee', 'link': 'https://arxiv.org/abs/2507.06639', 'abstract': 'In digital pathology, whole-slide images (WSIs) are often difficult to handle due to their gigapixel scale, so most approaches train patch encoders via self-supervised learning (SSL) and then aggregate the patch-level embeddings via multiple instance learning (MIL) or slide encoders for downstream tasks. However, patch-level SSL may overlook complex domain-specific features that are essential for biomarker prediction, such as mutation status and molecular characteristics, as SSL methods rely only on basic augmentations selected for natural image domains on small patch-level area. Moreover, SSL methods remain less data efficient than fully supervised approaches, requiring extensive computational resources and datasets to achieve competitive performance. To address these limitations, we present EXAONE Path 2.0, a pathology foundation model that learns patch-level representations under direct slide-level supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves state-of-the-art average performance across 10 biomarker prediction tasks, demonstrating remarkable data efficiency.', 'abstract_zh': '数字病理学中，全滑片图像（WSIs）因其 gigapixel 规模而难以处理，因此大多数方法通过自主监督学习（SSL）训练补丁编码器，然后通过多重实例学习（MIL）或滑片编码器聚合补丁级别嵌入用于下游任务。然而，补丁级别的 SSL 可能会忽略对于生物标志物预测至关重要的复杂领域特定特征，如突变状态和分子特性，因为 SSL 方法仅依赖于针对自然图像领域选择的基本增强，在小补丁级别区域上应用。此外，SSL 方法在数据效率上仍不及完全监督方法，需要大量计算资源和数据集才能实现竞争力的性能。为解决这些限制，我们提出了 EXAONE Path 2.0，这是一种在直接的滑片级别监督下学习补丁级别表示的病理学基础模型。仅使用 37,000 张 WSIs 进行训练，EXAONE Path 2.0 在 10 项生物标志物预测任务中实现了最先进的平均性能，展示了显著的数据效率。', 'title_zh': 'EXAONE 路径 2.0：端到端监督的病理学基础模型'}
{'arxiv_id': 'arXiv:2507.06628', 'title': 'Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning', 'authors': 'Jinmin He, Kai Li, Yifan Zang, Haobo Fu, Qiang Fu, Junliang Xing, Jian Cheng', 'link': 'https://arxiv.org/abs/2507.06628', 'abstract': 'Offline multi-task reinforcement learning aims to learn a unified policy capable of solving multiple tasks using only pre-collected task-mixed datasets, without requiring any online interaction with the environment. However, it faces significant challenges in effectively sharing knowledge across tasks. Inspired by the efficient knowledge abstraction observed in human learning, we propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed to extract and utilize reusable skills to enhance knowledge transfer and task performance. Our approach uncovers reusable skills through a goal-oriented skill extraction process and leverages vector quantization to construct a discrete skill library. To mitigate class imbalances between broadly applicable and task-specific skills, we introduce a skill enhancement phase to refine the extracted skills. Furthermore, we integrate these skills using hierarchical policy learning, enabling the construction of a high-level policy that dynamically orchestrates discrete skills to accomplish specific tasks. Extensive experiments on diverse robotic manipulation tasks within the MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.', 'abstract_zh': '面向 Offline 多任务强化学习的目标导向技能抽象', 'title_zh': '面向目标的技能抽象在offline多任务 reinforcement learning中的应用'}
{'arxiv_id': 'arXiv:2507.06625', 'title': 'Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic', 'authors': 'Shizhe Cai, Jayadeep Jacob, Zeya Yin, Fabio Ramos', 'link': 'https://arxiv.org/abs/2507.06625', 'abstract': 'Deep reinforcement learning has shown remarkable success in continuous control tasks, yet often requires extensive training data, struggles with complex, long-horizon planning, and fails to maintain safety constraints during operation. Meanwhile, Model Predictive Control (MPC) offers explainability and constraint satisfaction, but typically yields only locally optimal solutions and demands careful cost function design. This paper introduces the Q-guided STein variational model predictive Actor-Critic (Q-STAC), a novel framework that bridges these approaches by integrating Bayesian MPC with actor-critic reinforcement learning through constrained Stein Variational Gradient Descent (SVGD). Our method optimizes control sequences directly using learned Q-values as objectives, eliminating the need for explicit cost function design while leveraging known system dynamics to enhance sample efficiency and ensure control signals remain within safe boundaries. Extensive experiments on 2D navigation and robotic manipulation tasks demonstrate that Q-STAC achieves superior sample efficiency, robustness, and optimality compared to state-of-the-art algorithms, while maintaining the high expressiveness of policy distributions. Experiment videos are available on our website: this https URL', 'abstract_zh': 'Deep reinforcement learning在连续控制任务中展现出显著成功，但往往需要大量训练数据，难以处理复杂、长期的规划，并在运行过程中难以维护安全约束。同时，模型预测控制（MPC）提供了可解释性和约束满足，但通常只能提供局部最优解，并且需要精心设计成本函数。本文提出了一种名为Q-guided Stein variational模型预测Actor-Critic（Q-STAC）的新框架，通过受约束的Stein变异梯度下降（SVGD）将贝叶斯MPC与actor-critic强化学习相结合。该方法直接优化控制序列，使用学习到的Q值作为目标，避免了显式成本函数设计的需要，同时利用已知系统动力学提高样本效率并确保控制信号保持在安全范围内。在二维导航和机器人操作任务的广泛实验中，Q-STAC在样本效率、鲁棒性和最优性方面优于最先进的算法，同时保持了策略分布的高表达能力。更多实验视频请参见我们的网站: [this URL]。', 'title_zh': 'Q-STAC: Q-引导的Stein变分模型预测行为批评'}
{'arxiv_id': 'arXiv:2507.06623', 'title': 'Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review', 'authors': 'James Stewart-Evans, Emma Wilson, Tessa Langley, Andrew Prayle, Angela Hands, Karen Exley, Jo Leonardi-Bee', 'link': 'https://arxiv.org/abs/2507.06623', 'abstract': 'The data extraction stages of reviews are resource-intensive, and researchers may seek to expediate data extraction using online (large language models) LLMs and review protocols. Claude 3.5 Sonnet was used to trial two approaches that used a review protocol to prompt data extraction from 10 evidence sources included in a case study scoping review. A protocol-based approach was also used to review extracted data. Limited performance evaluation was undertaken which found high accuracy for the two extraction approaches (83.3% and 100%) when extracting simple, well-defined citation details; accuracy was lower (9.6% and 15.8%) when extracting more complex, subjective data items. Considering all data items, both approaches had precision >90% but low recall (<25%) and F1 scores (<40%). The context of a complex scoping review, open response types and methodological approach likely impacted performance due to missed and misattributed data. LLM feedback considered the baseline extraction accurate and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of 38 (21.1%) to key findings data items were considered to potentially add value. However, when repeating the process with a dataset featuring deliberate errors, only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for expediency require more robust performance evaluation across a range of LLMs and review contexts with comparison to conventional prompt engineering approaches. We recommend researchers evaluate and report LLM performance if using them similarly to conduct data extraction or review extracted data. LLM feedback contributed to protocol adaptation and may assist future review protocol drafting.', 'abstract_zh': '基于审查协议的数据提取阶段耗时且资源密集，研究者可能寻求通过在线大型语言模型（LLM）和审查协议来加速数据提取。使用Claude 3.5 Sonnet试验了两种方法，这些方法利用审查协议从案例研究范围审查中包含的10个证据来源中提示数据提取。还使用基于审查协议的方法审查提取的数据。进行了有限的性能评估，发现两种提取方法在提取简单明确的引用细节时准确率高（分别为83.3%和100%），但在提取更复杂、主观的数据项时准确率较低（分别为9.6%和15.8%）。考虑到所有数据项，两种方法的精确度均超过90%，但召回率较低（均低于25%），F1分数较低（均低于40%）。复杂范围审查的背景、开放式的回答类型和方法学方法可能影响了性能，导致数据被遗漏或错误归因。LLM反馈认为基线提取准确，并建议进行细微调整：15个中4个（26.7%）是关于引用细节的，38个中8个（21.1%）是关于关键发现的数据项可能增加价值。然而，在使用包含故意错误的数据集重复此过程时，仅检测到39个中2个（5%）的错误。为了提高效率而使用的基于审查协议的方法需要在一系列LLM和审查背景下进行更 robust 的性能评估，并与传统提示工程技术方法进行比较。我们建议研究人员在使用LLM进行数据提取或审查提取数据时评估和报告LLM性能。LLM反馈有助于审查协议的适应，并可能有助于未来审查协议的起草。', 'title_zh': '使用大规模语言模型（LLM）和范围审查协议加速数据提取：复杂范围审查中的方法学研究'}
{'arxiv_id': 'arXiv:2507.06615', 'title': 'Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance', 'authors': 'Jinmin He, Kai Li, Yifan Zang, Haobo Fu, Qiang Fu, Junliang Xing, Jian Cheng', 'link': 'https://arxiv.org/abs/2507.06615', 'abstract': "Multi-task reinforcement learning endeavors to efficiently leverage shared information across various tasks, facilitating the simultaneous learning of multiple tasks. Existing approaches primarily focus on parameter sharing with carefully designed network structures or tailored optimization procedures. However, they overlook a direct and complementary way to exploit cross-task similarities: the control policies of tasks already proficient in some skills can provide explicit guidance for unmastered tasks to accelerate skills acquisition. To this end, we present a novel framework called Cross-Task Policy Guidance (CTPG), which trains a guide policy for each task to select the behavior policy interacting with the environment from all tasks' control policies, generating better training trajectories. In addition, we propose two gating mechanisms to improve the learning efficiency of CTPG: one gate filters out control policies that are not beneficial for guidance, while the other gate blocks tasks that do not necessitate guidance. CTPG is a general framework adaptable to existing parameter sharing approaches. Empirical evaluations demonstrate that incorporating CTPG with these approaches significantly enhances performance in manipulation and locomotion benchmarks.", 'abstract_zh': '跨任务策略指导的多任务 reinforcement 学习', 'title_zh': '跨任务策略指导的高效多任务强化学习'}
{'arxiv_id': 'arXiv:2507.06613', 'title': 'Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation', 'authors': 'Anshuk Uppal, Yuhta Takida, Chieh-Hsin Lai, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2507.06613', 'abstract': 'Disentangled and interpretable latent representations in generative models typically come at the cost of generation quality. The $\\beta$-VAE framework introduces a hyperparameter $\\beta$ to balance disentanglement and reconstruction quality, where setting $\\beta > 1$ introduces an information bottleneck that favors disentanglement over sharp, accurate reconstructions. To address this trade-off, we propose a novel generative modeling framework that leverages a range of $\\beta$ values to learn multiple corresponding latent representations. First, we obtain a slew of representations by training a single variational autoencoder (VAE), with a new loss function that controls the information retained in each latent representation such that the higher $\\beta$ value prioritize disentanglement over reconstruction fidelity. We then, introduce a non-linear diffusion model that smoothly transitions latent representations corresponding to different $\\beta$ values. This model denoises towards less disentangled and more informative representations, ultimately leading to (almost) lossless representations, enabling sharp reconstructions. Furthermore, our model supports sample generation without input images, functioning as a standalone generative model. We evaluate our framework in terms of both disentanglement and generation quality. Additionally, we observe smooth transitions in the latent spaces with respect to changes in $\\beta$, facilitating consistent manipulation of generated outputs.', 'abstract_zh': '解缠和可解释的潜在表示通常会牺牲生成质量。$\\beta$-VAE框架通过引入超参数$\\beta$来平衡解缠和重建质量，其中设置$\\beta > 1$会导致信息瓶颈，倾向于解缠而牺牲锐度和准确的重建。为了解决这种权衡，我们提出了一种新型生成建模框架，该框架利用一系列$\\beta$值学习多个相应的潜在表示。首先，通过训练单一的变分自编码器（VAE），并使用一种新损失函数来控制每个潜在表示保留的信息量，其中较高的$\\beta$值优先考虑解缠而不是重建保真度。我们随后引入了一个非线性扩散模型，该模型平滑地过渡到不同$\\beta$值对应的潜在表示。该模型向更不解缠但更具信息量的表示去噪，最终导致（几乎）无损的表示，从而实现锐利的重建。此外，我们的模型支持无需输入图像的样本生成，作为一种独立的生成模型运行。我们从解缠和生成质量两个方面评估了该框架。另外，我们观察到在$\\beta$值变化时潜在空间中的平滑过渡，有助于生成输出的一致操作。', 'title_zh': '去噪多贝塔VAE：解缠表示学习与生成'}
{'arxiv_id': 'arXiv:2507.06582', 'title': 'Learning controllable dynamics through informative exploration', 'authors': 'Peter N. Loxley, Friedrich T. Sommer', 'link': 'https://arxiv.org/abs/2507.06582', 'abstract': 'Environments with controllable dynamics are usually understood in terms of explicit models. However, such models are not always available, but may sometimes be learned by exploring an environment. In this work, we investigate using an information measure called "predicted information gain" to determine the most informative regions of an environment to explore next. Applying methods from reinforcement learning allows good suboptimal exploring policies to be found, and leads to reliable estimates of the underlying controllable dynamics. This approach is demonstrated by comparing with several myopic exploration approaches.', 'abstract_zh': '可控动力学环境通常通过显式模型来理解。然而，并非总是可以获取这样的模型，有时可以通过探索环境来学习这些模型。本文研究使用一种称为“预测信息增益”的信息量度量来确定下一个探索的最具信息性的环境区域。应用强化学习方法可以找到良好的次优探索策略，并能可靠地估计潜在的可控动力学。通过与几种短视探索方法的比较展示了这一方法。', 'title_zh': '通过信息性探索学习可控动力学'}
{'arxiv_id': 'arXiv:2507.06573', 'title': 'From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization', 'authors': 'Xinjie Chen, Minpeng Liao, Guoxin Chen, Chengxi Li, Biao Fu, Kai Fan, Xinggao Liu', 'link': 'https://arxiv.org/abs/2507.06573', 'abstract': "Reinforcement learning with verifiable rewards (RLVR) has recently advanced the reasoning capabilities of large language models (LLMs). While prior work has emphasized algorithmic design, data curation, and reward shaping, we investigate RLVR from a sample-centric perspective and introduce LPPO (Learning-Progress and Prefix-guided Optimization), a framework of progressive optimization techniques. Our work addresses a critical question: how to best leverage a small set of trusted, high-quality demonstrations, rather than simply scaling up data volume. First, motivated by how hints aid human problem-solving, we propose prefix-guided sampling, an online data augmentation method that incorporates partial solution prefixes from expert demonstrations to guide the policy, particularly for challenging instances. Second, inspired by how humans focus on important questions aligned with their current capabilities, we introduce learning-progress weighting, a dynamic strategy that adjusts each training sample's influence based on model progression. We estimate sample-level learning progress via an exponential moving average of per-sample pass rates, promoting samples that foster learning and de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks demonstrate that our methods outperform strong baselines, yielding faster convergence and a higher performance ceiling.", 'abstract_zh': '可验证奖励的强化学习（RLVR） recently advanced 大型语言模型（LLMs）的推理能力。从采样中心视角探究 RLVR 并引入 LPPO（Learning-Progress 和 Prefix-guided 优化）框架：渐进优化技术。我们的研究解决了一个关键问题：如何最好地利用少量可靠的高质量示范，而不是简单地扩大数据量。首先，受到提示有助于人类问题解决的启发，我们提出了 prefix-guided 抽样，这是一种在线数据增强方法，通过结合专家示范中的部分解题前缀来引导策略，特别是对于具有挑战性的实例。其次，受到人类关注与其当前能力相符的重要问题的启发，我们引入了 learning-progress 加权，这是一种动态策略，根据模型进展调整每个训练样本的影响。我们通过每个样本通过率的指数移动平均来估计样本级的学习进展，促进有利于学习的样本并淡化停滞的样本。在数学推理基准测试中的实验表明，我们的方法优于强基准方法，实现了更快的收敛并提高了性能上限。', 'title_zh': '从数据为中心到样本为中心：通过渐进优化增强大规模语言模型推理能力'}
{'arxiv_id': 'arXiv:2507.06564', 'title': 'SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments', 'authors': 'Tianshun Li, Tianyi Huai, Zhen Li, Yichun Gao, Haoang Li, Xinhu Zheng', 'link': 'https://arxiv.org/abs/2507.06564', 'abstract': 'Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across various sectors, driven by their mobility and adaptability. This paper introduces SkyVLN, a novel framework integrating vision-and-language navigation (VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in complex urban environments. Unlike traditional navigation methods, SkyVLN leverages Large Language Models (LLMs) to interpret natural language instructions and visual observations, enabling UAVs to navigate through dynamic 3D spaces with improved accuracy and robustness. We present a multimodal navigation agent equipped with a fine-grained spatial verbalizer and a history path memory mechanism. These components allow the UAV to disambiguate spatial contexts, handle ambiguous instructions, and backtrack when necessary. The framework also incorporates an NMPC module for dynamic obstacle avoidance, ensuring precise trajectory tracking and collision prevention. To validate our approach, we developed a high-fidelity 3D urban simulation environment using AirSim, featuring realistic imagery and dynamic urban elements. Extensive experiments demonstrate that SkyVLN significantly improves navigation success rates and efficiency, particularly in new and unseen environments.', 'abstract_zh': '无人机（UAVs）已作为一种多功能工具在各个领域中涌现，得益于其移动性和适应性。本文介绍了SkyVLN，这是一种将视觉-语言导航（VLN）与非线性模型预测控制（NMPC）集成的新 framework，以增强无人机在复杂城市环境中的自主性。与传统的导航方法不同，SkyVLN 利用大型语言模型（LLMs）解释自然语言指令和视觉观察，使无人机能够在动态3D空间中导航，提高导航的准确性和鲁棒性。本文提出了一种多模态导航代理，配备了精细的空间语言化器和历史路径记忆机制。这些组件使无人机能够消除空间歧义、处理模糊指令并在必要时回退。该框架还集成了一个动态障碍规避的NMPC模块，确保精确轨迹跟踪和防碰撞功能。为了验证我们的方法，我们使用AirSim开发了一个高保真3D城市仿真环境，含有逼真图像和动态城市元素。大量实验表明，SkyVLN 显著提高了导航成功率和效率，尤其是在新的和未见过的环境中。', 'title_zh': 'SkyVLN: 无人机在城市环境中的视觉-语言导航与NMPC控制'}
{'arxiv_id': 'arXiv:2507.06558', 'title': 'The Primacy of Magnitude in Low-Rank Adaptation', 'authors': 'Zicheng Zhang, Haoran Li, Yifeng Zhang, Guoqiang Gong, Jiaxing Wang, Pengzhang Liu, Qixia Jiang, Junxing Hu', 'link': 'https://arxiv.org/abs/2507.06558', 'abstract': 'Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning large models. While recent spectral initialization methods improve convergence and performance over the naive "Noise & Zeros" scheme, their extra computational and storage overhead undermines efficiency. In this paper, we establish update magnitude as the fundamental driver of LoRA performance and propose LoRAM, a magnitude-driven "Basis & Basis" initialization scheme that matches spectral methods without their inefficiencies. Our key contributions are threefold: (i) Magnitude of weight updates determines convergence. We prove low-rank structures intrinsically bound update magnitudes, unifying hyperparameter tuning in learning rate, scaling factor, and initialization as mechanisms to optimize magnitude regulation. (ii) Spectral initialization succeeds via magnitude amplification. We demystify that the presumed knowledge-driven benefit of the spectral component essentially arises from the boost in the weight update magnitude. (iii) A novel and compact initialization strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight magnitudes to simulate spectral gains. Extensive experiments show that LoRAM serves as a strong baseline, retaining the full efficiency of LoRA while matching or outperforming spectral initialization across benchmarks.', 'abstract_zh': 'LoRA的幅度驱动初始化方案：LoRAM及其优越性', 'title_zh': '低秩适应中的幅度优先性'}
{'arxiv_id': 'arXiv:2507.06541', 'title': 'Graph-based Fake Account Detection: A Survey', 'authors': 'Ali Safarpoor Dehkordi, Ahad N. Zehmakan', 'link': 'https://arxiv.org/abs/2507.06541', 'abstract': 'In recent years, there has been a growing effort to develop effective and efficient algorithms for fake account detection in online social networks. This survey comprehensively reviews existing methods, with a focus on graph-based techniques that utilise topological features of social graphs (in addition to account information, such as their shared contents and profile data) to distinguish between fake and real accounts. We provide several categorisations of these methods (for example, based on techniques used, input data, and detection time), discuss their strengths and limitations, and explain how these methods connect in the broader context. We also investigate the available datasets, including both real-world data and synthesised models. We conclude the paper by proposing several potential avenues for future research.', 'abstract_zh': '近年来，不断发展有效的在线社交网络虚假账号检测算法。本文全面回顾了现有方法，重点关注利用社交图的拓扑特征（除了账号信息，还包括其共享内容和资料数据）来区分虚假账号和真实账号的图基于技术。我们提供了这些方法的几种类别（例如，基于所使用的技术、输入数据和检测时间），讨论了它们的优势和局限性，并解释了这些方法在更广泛的背景下的联系。我们还研究了可用的数据集，包括真实世界数据和合成模型。本文最后提出了若干潜在的研究方向。', 'title_zh': '基于图的虚假账号检测：一个综述'}
{'arxiv_id': 'arXiv:2507.06528', 'title': 'InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior', 'authors': 'Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, H. Vicky Zhao', 'link': 'https://arxiv.org/abs/2507.06528', 'abstract': 'Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at this https URL.', 'abstract_zh': '利用理论最优投资解决方案构建高质量监督微调数据集以缓解大型语言模型与投资者决策过程在羊群行为下的不一致性：一种行为金融中的关键挑战', 'title_zh': 'InvestAlign：克服 herd 行为下投资决策过程与大规模语言模型对齐中的数据稀缺性问题'}
{'arxiv_id': 'arXiv:2507.06520', 'title': 'Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration', 'authors': 'Xinyuan Song, Zeyu Wang, Siyi Wu, Tianyu Shi, Lynn Ai', 'link': 'https://arxiv.org/abs/2507.06520', 'abstract': 'We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.', 'abstract_zh': 'Gradientsys：一种基于类型化模型-上下文协议和ReAct动态规划环的下一代多Agent调度框架', 'title_zh': 'Gradientsys: 一个多代理LLM调度器带ReAct编排'}
{'arxiv_id': 'arXiv:2507.06519', 'title': 'Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies', 'authors': 'Yuhan Liu, Xinyu Zhang, Haonan Chang, Abdeslam Boularias', 'link': 'https://arxiv.org/abs/2507.06519', 'abstract': "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where a robot must repeatedly perform high-precision insertions, such as screwing a nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving millimeter-level accuracy and maintaining consistent performance over multiple repetitions, particularly when factors like nut rotation and friction introduce additional complexity. We propose a sim-to-real framework that integrates a reinforcement learning-based insertion policy with a failure forecasting module. By representing the wrench's pose in the nut's coordinate frame rather than the robot's frame, our approach significantly enhances sim-to-real transferability. The insertion policy, trained in simulation, leverages real-time 6D pose tracking to execute precise alignment, insertion, and rotation maneuvers. Simultaneously, a neural network predicts potential execution failures, triggering a simple recovery mechanism that lifts the wrench and retries the insertion. Extensive experiments in both simulated and real-world environments demonstrate that our method not only achieves a high one-time success rate but also robustly maintains performance over long-horizon repetitive tasks.", 'abstract_zh': '本文针对节律插入任务（RIT），其中机器人必须反复执行高精度插入操作，例如使用扳手将螺帽拧入螺栓。RIT 的固有难度在于实现毫米级精度并保持多次重复操作中的一致性能，尤其是当考虑螺帽旋转和摩擦等因素时会增加额外的复杂性。我们提出了一种结合基于强化学习的插入策略和故障预测模块的仿真实验框架。通过将扳手的姿态表示为螺帽坐标系，而非机器人坐标系，我们的方法显著增强了仿真实验到实际应用的可转移性。插入策略在仿真中训练，利用实时六自由度姿态追踪执行精确对准、插入和旋转操作。同时，神经网络预测潜在的执行失败，并触发一个简单的恢复机制以抬起扳手并重新尝试插入。在仿真和实际环境中的大量实验表明，我们的方法不仅能够实现高单次成功率，而且在长时间尺度的重复任务中也能稳健地保持性能。', 'title_zh': 'Failure Forecasting提升Sim2Real节律插入策略的鲁棒性'}
{'arxiv_id': 'arXiv:2507.06512', 'title': 'Towards LLM-based Root Cause Analysis of Hardware Design Failures', 'authors': 'Siyu Qiu, Muzhi Wang, Raheel Afsharmazayejani, Mohammad Moradi Shahmiri, Benjamin Tan, Hammond Pearce', 'link': 'https://arxiv.org/abs/2507.06512', 'abstract': "With advances in large language models (LLMs), new opportunities have emerged to develop tools that support the digital hardware design process. In this work, we explore how LLMs can assist with explaining the root cause of design issues and bugs that are revealed during synthesis and simulation, a necessary milestone on the pathway towards widespread use of LLMs in the hardware design process and for hardware security analysis. We find promising results: for our corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model reached a correct determination 100% of the time under pass@5 scoring, with other state of the art models and configurations usually achieving more than 80% performance and more than 90% when assisted with retrieval-augmented generation.", 'abstract_zh': '随着大规模语言模型（LLMs）的进步，出现了开发支持数字硬件设计过程的新工具的机会。在本研究中，我们探讨了LLMs如何在综合和仿真过程中协助解释设计问题和故障的根本原因，这是走向在硬件设计过程和硬件安全分析中广泛使用LLMs的必要里程碑。我们取得了令人鼓舞的结果：对于34种不同的故障场景，OpenAI的o3-mini推理模型在pass@5评分下的正确判定率为100%，其他最先进的模型和配置通常实现超过80%的性能，而在检索增强生成的帮助下，这一性能通常超过90%。', 'title_zh': '基于大规模语言模型的硬件设计失效根本原因分析'}
{'arxiv_id': 'arXiv:2507.06507', 'title': 'GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models', 'authors': 'Zhen Yang, Haitao Lin, Jiawei xue, Ziji Zhang', 'link': 'https://arxiv.org/abs/2507.06507', 'abstract': 'In the past year, Generative Recommendations (GRs) have undergone substantial advancements, especially in leveraging the powerful sequence modeling and reasoning capabilities of Large Language Models (LLMs) to enhance overall recommendation performance. LLM-based GRs are forming a new paradigm that is distinctly different from discriminative recommendations, showing strong potential to replace traditional recommendation systems heavily dependent on complex hand-crafted features. In this paper, we provide a comprehensive survey aimed at facilitating further research of LLM-based GRs. Initially, we outline the general preliminaries and application cases of LLM-based GRs. Subsequently, we introduce the main considerations when LLM-based GRs are applied in real industrial scenarios. Finally, we explore promising directions for LLM-based GRs. We hope that this survey contributes to the ongoing advancement of the GR domain.', 'abstract_zh': '过去一年中，生成性推荐（GRs）取得了显著进展，特别是在利用大型语言模型（LLMs）的强大序列建模和推理能力提升整体推荐性能方面。基于LLM的GRs形成了与判别性推荐截然不同的新范式，展现出替代高度依赖复杂手工特征的传统推荐系统的强大潜力。本文旨在对基于LLM的GRs进行全面综述，以促进相关研究。首先，我们概述了基于LLM的GRs的一般预备知识和应用案例。随后，介绍了在实际工业场景中应用基于LLM的GRs时需要考虑的主要因素。最后，探讨了基于LLM的GRs的发展方向。我们希望这篇综述能够推动生成性推荐领域的发展。', 'title_zh': 'GR-LLMs: 大语言模型驱动的生成性推荐 Recent Advances'}
{'arxiv_id': 'arXiv:2507.06506', 'title': 'Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings', 'authors': 'Russell Taylor, Benjamin Herbert, Michael Sana', 'link': 'https://arxiv.org/abs/2507.06506', 'abstract': "Translating wordplay across languages presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.\nOur methodology employs a three-stage approach. First, we establish a baseline using multiple frontier large language models with feedback based on a new contrastive learning dataset. Second, we implement a guided chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we implement a multi-agent generator-discriminator framework for evaluating and regenerating puns with feedback.\nMoving beyond the limitations of literal translation, our methodology's primary objective is to capture the linguistic creativity and humor of the source text wordplay, rather than simply duplicating its vocabulary. Our best runs earned first and second place in the CLEF JOKER 2025 Task 2 competition where they were evaluated manually by expert native French speakers.\nThis research addresses a gap between translation studies and computational linguistics by implementing linguistically-informed techniques for wordplay translation, advancing our understanding of how language models can be leveraged to handle the complex interplay between semantic ambiguity, phonetic similarity, and the implicit cultural and linguistic awareness needed for successful humor.", 'abstract_zh': '跨语言翻译字面游戏 presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.', 'title_zh': '妙趣横生：基于对比学习和音义嵌入的多agent词语玩法规则翻译'}
{'arxiv_id': 'arXiv:2507.06502', 'title': 'MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models', 'authors': 'Yiwen Liu, Chenyu Zhang, Junjie Song, Siqi Chen, Sun Yin, Zihan Wang, Lingming Zeng, Yuji Cao, Junming Jiao', 'link': 'https://arxiv.org/abs/2507.06502', 'abstract': 'As a prominent data modality task, time series forecasting plays a pivotal role in diverse applications. With the remarkable advancements in Large Language Models (LLMs), the adoption of LLMs as the foundational architecture for time series modeling has gained significant attention. Although existing models achieve some success, they rarely both model time and frequency characteristics in a pretraining-finetuning paradigm leading to suboptimal performance in predictions of complex time series, which requires both modeling periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an innovative time series forecasting model that integrates time and frequency domain features within a Mixture of Experts (MoE) network. Moreover, we use the pretraining-finetuning paradigm as our training framework to effectively transfer prior pattern knowledge across pretraining and finetuning datasets with different periodicity distributions. Our method introduces both frequency and time cells as experts after attention modules and leverages the MoE routing mechanism to construct multidimensional sparse representations of input signals. In experiments on six public benchmarks, MoFE-Time has achieved new state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared to the representative methods Time-MoE. Beyond the existing evaluation benchmarks, we have developed a proprietary dataset, NEV-sales, derived from real-world business scenarios. Our method achieves outstanding results on this dataset, underscoring the effectiveness of the MoFE-Time model in practical commercial applications.', 'abstract_zh': 'MoFE-Time：一种结合时间与频率域特征的Mixture of Experts时间序列预测模型', 'title_zh': 'MoFE-Time: 频域专家混合的时间序列预测模型'}
{'arxiv_id': 'arXiv:2507.06485', 'title': 'Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning', 'authors': 'Ziyang Wang, Jaehong Yoon, Shoubin Yu, Md Mohaiminul Islam, Gedas Bertasius, Mohit Bansal', 'link': 'https://arxiv.org/abs/2507.06485', 'abstract': "Despite advances in reinforcement learning (RL)-based video reasoning with large language models (LLMs), data collection and finetuning remain significant challenges. These methods often rely on large-scale supervised fine-tuning (SFT) with extensive video data and long Chain-of-Thought (CoT) annotations, making them costly and hard to scale. To address this, we present Video-RTS, a new approach to improve video reasoning capability with drastically improved data efficiency by combining data-efficient RL with a video-adaptive test-time scaling (TTS) strategy. Based on observations about the data scaling of RL samples, we skip the resource-intensive SFT step and employ efficient pure-RL training with output-based rewards, requiring no additional annotations or extensive fine-tuning. Furthermore, to utilize computational resources more efficiently, we introduce a sparse-to-dense video TTS strategy that improves inference by iteratively adding frames based on output consistency. We validate our approach on multiple video reasoning benchmarks, showing that Video-RTS surpasses existing video reasoning models by an average of 2.4% in accuracy using only 3.6% training samples. For example, Video-RTS achieves a 4.2% improvement on Video-Holmes, a recent and challenging video reasoning benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and adaptive video TTS offer complementary strengths, enabling Video-RTS's strong reasoning performance.", 'abstract_zh': '基于大规模语言模型的强化学习在视频推理中的数据收集和微调仍然是显著挑战。尽管在基于强化学习(RL)的视频推理方法中取得了进展，但仍面临数据收集和微调的巨大挑战。这些方法通常依赖于大规模监督微调(SFT)和广泛的视频数据以及长的推理链(Chain-of-Thought, CoT)注释，使其成本高昂且不易扩展。为了解决这一问题，我们提出了Video-RTS，这是一种通过结合数据高效RL和视频自适应测试时缩放(TTS)策略来大幅提高数据效率的新方法。基于对RL样本数据放大的观察，我们跳过了资源密集型的SFT步骤，采用基于输出的奖励的高效纯RL训练，无需额外注释或大规模微调。此外，为了更有效地利用计算资源，我们引入了一种稀疏到密集的视频TTS策略，通过迭代添加帧并基于输出一致性逐步改善推理。我们在多个视频推理基准上验证了该方法，结果显示，使用仅3.6%的训练样本，Video-RTS在准确率上平均超过了现有视频推理模型2.4%。例如，Video-RTS在最近提出的具有挑战性的视频推理基准Video-Holmes上实现了4.2%的提升，在MMVU上实现了2.6%的提升。值得注意的是，我们的纯RL训练和自适应视频TTS互补性强，使Video-RTS在推理性能上表现出色。', 'title_zh': '视频RTS：重新思考高效增强视频推理中的强化学习和测试时扩展问题'}
{'arxiv_id': 'arXiv:2507.06479', 'title': 'Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity', 'authors': 'Niloofar Asefi, Leonard Lupin-Jimenez, Tianning Wu, Ruoying He, Ashesh Chattopadhyay', 'link': 'https://arxiv.org/abs/2507.06479', 'abstract': 'Reconstructing ocean dynamics from observational data is fundamentally limited by the sparse, irregular, and Lagrangian nature of spatial sampling, particularly in subsurface and remote regions. This sparsity poses significant challenges for forecasting key phenomena such as eddy shedding and rogue waves. Traditional data assimilation methods and deep learning models often struggle to recover mesoscale turbulence under such constraints. We leverage a deep learning framework that combines neural operators with denoising diffusion probabilistic models (DDPMs) to reconstruct high-resolution ocean states from extremely sparse Lagrangian observations. By conditioning the generative model on neural operator outputs, the framework accurately captures small-scale, high-wavenumber dynamics even at $99\\%$ sparsity (for synthetic data) and $99.9\\%$ sparsity (for real satellite observations). We validate our method on benchmark systems, synthetic float observations, and real satellite data, demonstrating robust performance under severe spatial sampling limitations as compared to other deep learning baselines.', 'abstract_zh': '从观测数据重构海洋动力学受到采样稀疏、不规则及拉格朗日性质的 fundamental 限制，尤其是在次表层和偏远区域。这种稀疏性对预测涡旋脱离和 rogue 波等关键现象构成了重大挑战。传统数据同化方法和深度学习模型在这些限制下通常难以恢复中尺度湍流。我们利用结合神经运算子与去噪扩散概率模型（DDPMs）的深度学习框架，从极其稀疏的拉格朗日观测数据中重构高分辨率的海洋状态。通过条件生成模型于神经运算子输出，该框架在合成数据的 99% 稀疏度和真实卫星观测的 99.9% 稀疏度下，准确捕捉小尺度、高波数动力学。我们在基准系统、合成浮标观测和真实卫星数据上验证了该方法，与其它深度学习基线相比，表现出较强的鲁棒性。', 'title_zh': '生成拉格朗日数据同化方法在极端稀疏情况下的海洋动力学应用'}
{'arxiv_id': 'arXiv:2507.06466', 'title': 'Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models', 'authors': 'Aaron Dharna, Cong Lu, Jeff Clune', 'link': 'https://arxiv.org/abs/2507.06466', 'abstract': "Multi-agent interactions have long fueled innovation, from natural predator-prey dynamics to the space race. Self-play (SP) algorithms try to harness these dynamics by pitting agents against ever-improving opponents, thereby creating an implicit curriculum toward learning high-quality solutions. However, SP often fails to produce diverse solutions and can get stuck in locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a new direction that leverages the code-generation capabilities and vast knowledge of foundation models (FMs) to overcome these challenges by leaping across local optima in policy space. We propose a family of approaches: (1) \\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent policies via competitive self-play; (2) \\textbf{Novelty-Search Self-Play (NSSP)} builds a diverse population of strategies, ignoring performance; and (3) the most promising variant, \\textbf{Quality-Diveristy Self-Play (QDSP)}, creates a diverse set of high-quality policies by combining the diversity of NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety simulation in which an attacker tries to jailbreak an LLM's defenses. In Car Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and heuristic-based methods, to name just a few. In terms of discovered policy quality, \\ouralgo and vFMSP surpass strong human-designed strategies. In Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through and jailbreaking six different, progressively stronger levels of defense. Furthermore, FMSPs can automatically proceed to patch the discovered vulnerabilities. Overall, FMSPs represent a promising new research frontier of improving self-play with foundation models, opening fresh paths toward more creative and open-ended strategy discovery", 'abstract_zh': '基于基础模型的自游戏（Foundation-Model Self-Play）：克服局部最优的多智能体创新方法', 'title_zh': '基础模型自对弈：基础模型驱动的开放式策略创新'}
{'arxiv_id': 'arXiv:2507.06464', 'title': 'SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam', 'authors': 'Hanyang Peng, Shuang Qin, Yue Yu, Fangqing Jiang, Hui Wang, Wen Gao', 'link': 'https://arxiv.org/abs/2507.06464', 'abstract': "Adam has proven remarkable successful in training deep neural networks, but the mechanisms underlying its empirical successes and limitations remain underexplored. In this study, we demonstrate that the effectiveness of Adam stems largely from its similarity to SignSGD in robustly handling large gradient fluctuations, yet it is also vulnerable to destabilizing loss spikes due to its uncontrolled update scaling. To enhance the advantage of Adam and mitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with three key innovations. \\emph{First}, S3 generalizes the sign-like update by employing a flexible $p$-th order momentum ($p \\geq 1$) in the denominator, departing from the conventional second-order momentum (variance) preconditioning. This design enables enhanced performance while achieving stable training even with aggressive learning rates. \\emph{Second}, S3 minimizes the occurrences of loss spikes through unified exponential moving average coefficients for numerator and denominator momenta, which inherently bound updates to $[-1, 1]$ and simplify hyperparameter tuning. \\emph{Third}, S3 incorporates an equivalent Nesterov's accelerated gradient(NAG) module, accelerating convergence without memory overhead. Theoretically, we prove that S3 achieves the optimal convergence rate of $O\\left(\\frac{1}{T^{\\sfrac{1}{4}}}\\right)$ for general nonconvex stochastic optimization under weak assumptions. Extensive experiments across a range of vision and language tasks show that \\textsf{\\small S3} not only converges more rapidly and improves performance but also rarely experiences loss spikes, even with a \\textbf{$\\bm{10 \\times}$} larger learning rate. In fact, S3 delivers performance comparable to or better than AdamW with \\textbf{$2 \\times$} the training steps, establishing its efficacy in both efficiency and final task performance.", 'abstract_zh': 'Adam在训练深度神经网络方面已证明极为成功，但其的经验成功和局限性的机制仍待深入探究。本研究展示了Adam的有效性主要源于它在稳健处理大梯度波动方面与SignSGD的相似性，但也因其不受控的更新缩放而容易受到损失峰值的破坏。为了增强Adam的优势并减轻其局限性，我们提出了SignSoftSGD (S3)，一种具有三大创新的新优化器。首先，S3通过在分母中采用灵活的p-阶动量($p \\geq 1$)，扩展了类似符号的更新，脱离了传统的二阶动量（方差）预条件化。这一设计使得即使在使用激进的学习率时也能实现高性能和稳定的训练。其次，S3通过统一的指数移动平均系数来最小化损失峰值的发生次数，这内在地将更新限制在$[-1, 1]$范围内，并简化了超参数调整。第三，S3结合了等效的Nesterov加速梯度(NAG)模块，在不增加内存开销的情况下加速收敛。理论上，我们在较弱假设下证明了S3在一般非凸随机最优化下的最优收敛率为$O\\left(\\frac{1}{T^{\\sfrac{1}{4}}}\\right)$。广泛实验表明，\\textsf{S3}不仅收敛更快且改善了性能，还很少经历损失峰值，即便使用$\\bm{10 \\times}$更大的学习率。事实上，S3在训练步数仅为AdamW的$\\bm{2 \\times}$的情况下，实现了与之相当或更好的性能，证明了其在效率和最终任务性能方面的有效性。', 'title_zh': 'SoftSignSGD(S3): 一种超越Adam的增强型优化器，用于实际DNN训练和损失峰值最小化'}
{'arxiv_id': 'arXiv:2507.06459', 'title': 'EA: An Event Autoencoder for High-Speed Vision Sensing', 'authors': 'Riadul Islam, Joey Mulé, Dhandeep Challagundla, Shahmir Rizvi, Sean Carson', 'link': 'https://arxiv.org/abs/2507.06459', 'abstract': 'High-speed vision sensing is essential for real-time perception in applications such as robotics, autonomous vehicles, and industrial automation. Traditional frame-based vision systems suffer from motion blur, high latency, and redundant data processing, limiting their performance in dynamic environments. Event cameras, which capture asynchronous brightness changes at the pixel level, offer a promising alternative but pose challenges in object detection due to sparse and noisy event streams. To address this, we propose an event autoencoder architecture that efficiently compresses and reconstructs event data while preserving critical spatial and temporal features. The proposed model employs convolutional encoding and incorporates adaptive threshold selection and a lightweight classifier to enhance recognition accuracy while reducing computational complexity. Experimental results on the existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\\times$ fewer parameters. Implementations on embedded platforms, including Raspberry Pi 4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8 FPS. The proposed classifier exhibits up to 87.84x better FPS than the state-of-the-art and significantly improves event-based vision performance, making it ideal for low-power, high-speed applications in real-time edge computing.', 'abstract_zh': '高速视觉感知对于机器人、自动驾驶车辆和工业自动化等应用的实时感知至关重要。传统的基于帧的视觉系统由于存在运动模糊、高延迟和冗余数据处理等问题，限制了它们在动态环境中的性能。事件摄像头通过在像素级捕获异步亮度变化，提供了有前途的替代方案，但由于事件流稀疏且噪声大，给物体检测带来了挑战。为了解决这个问题，我们提出了一种事件自编码器架构，该架构能够高效地压缩和重构事件数据，同时保留关键的空间和时间特征。所提出模型采用了卷积编码，并结合自适应阈值选择和轻量级分类器，以提高识别准确性并降低计算复杂度。在现有的Smart Event Face Dataset (SEFD)上的实验结果表明，我们的方法在参数量减少到YOLO-v4模型的35.5倍的同时达到了相当的准确性。在Raspberry Pi 4B和NVIDIA Jetson Nano等嵌入式平台上实现显示了高帧率，从8 FPS到44.8 FPS。所提出的分类器在帧率上比最先进的方法高出87.84倍，显著提高了基于事件的视觉性能，使其成为低功耗、高帧率的实时边缘计算应用的理想选择。', 'title_zh': 'EA: 一种用于高speed视觉感知的事件自动编码器'}
{'arxiv_id': 'arXiv:2507.06449', 'title': 'FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models', 'authors': 'Qianyu Long, Qiyuan Wang, Christos Anagnostopoulos, Daning Bi', 'link': 'https://arxiv.org/abs/2507.06449', 'abstract': "Federated Learning (FL), as a distributed learning paradigm, trains models over distributed clients' data. FL is particularly beneficial for distributed training of Diffusion Models (DMs), which are high-quality image generators that require diverse data. However, challenges such as high communication costs and data heterogeneity persist in training DMs similar to training Transformers and Convolutional Neural Networks. Limited research has addressed these issues in FL environments. To address this gap and challenges, we introduce a novel approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD leverages Hierarchical FL with homogeneity-aware model aggregation and selection policy to tackle data heterogeneity while reducing communication costs. The distributed structured pruning of FedPhD enhances computational efficiency and reduces model storage requirements in clients. Our experiments across multiple datasets demonstrate that FedPhD achieves high model performance regarding Fréchet Inception Distance (FID) scores while reducing communication costs by up to $88\\%$. FedPhD outperforms baseline methods achieving at least a $34\\%$ improvement in FID, while utilizing only $56\\%$ of the total computation and communication resources.", 'abstract_zh': '联邦学习（FL）作为一种分布式学习范式，在分布式客户端数据上训练模型。FL特别适用于分布式训练扩散模型（DMs），这些高质量的图像生成器需要多种类的数据。然而，类似于训练Transformers和卷积神经网络，训练DMs时仍然存在高通信成本和数据异质性等挑战。现有研究在FL环境中尚未充分解决这些问题。为解决这一差距和挑战，我们提出了一种名为FedPhD的新型方法，旨在高效地在FL环境中训练DMs。FedPhD利用分层联邦学习与同质性感知模型聚合和选择策略来应对数据异质性并降低通信成本。FedPhD的分布式结构化剪枝增强了计算效率并减少了客户端的模型存储需求。我们的跨多个数据集的实验表明，FedPhD在提高弗雷谢特 inception 距离（FID）分数的同时，通信成本最多可降低88%。与基线方法相比，FedPhD在FID上至少提升了34%，而仅使用了总计算和通信资源的56%。', 'title_zh': '联邦普渡：基于分层学习的扩散模型剪枝'}
{'arxiv_id': 'arXiv:2507.06445', 'title': 'Can Interpretation Predict Behavior on Unseen Data?', 'authors': 'Victoria R. Li, Jenny Kaufmann, Martin Wattenberg, David Alvarez-Melis, Naomi Saphra', 'link': 'https://arxiv.org/abs/2507.06445', 'abstract': "Interpretability research often aims to predict how a model will respond to targeted interventions on specific mechanisms. However, it rarely predicts how a model will respond to unseen input data. This paper explores the promises and challenges of interpretability as a tool for predicting out-of-distribution (OOD) model behavior. Specifically, we investigate the correspondence between attention patterns and OOD generalization in hundreds of Transformer models independently trained on a synthetic classification task. These models exhibit several distinct systematic generalization rules OOD, forming a diverse population for correlational analysis. In this setting, we find that simple observational tools from interpretability can predict OOD performance. In particular, when in-distribution attention exhibits hierarchical patterns, the model is likely to generalize hierarchically on OOD data -- even when the rule's implementation does not rely on these hierarchical patterns, according to ablation tests. Our findings offer a proof-of-concept to motivate further interpretability work on predicting unseen model behavior.", 'abstract_zh': '可解释性研究通常旨在预测模型在针对特定机制进行目标干预时的响应方式，但很少预测模型对未见过的输入数据的响应方式。本文探讨了可解释性作为一种工具，用于预测模型超出分布（OOD）行为的潜力和挑战。具体地，我们研究了几百个独立训练于合成分类任务上的Transformer模型的注意力模式与OOD泛化的对应关系。这些模型表现出若干种不同的系统性泛化规则，构成了一种多样的人群，便于进行相关性分析。在这种情况下，我们发现简单的可解释性观察工具可以预测模型的OOD性能。特别是，当分布内注意力表现出分层模式时，模型在处理OOD数据时很可能表现出分层的泛化能力——即使在消融测试中，规则的实现并不依赖于这些分层模式。我们的发现为推动进一步的可解释性研究，以预测未见过的模型行为提供了概念性验证。', 'title_zh': '解读能否预测未见数据上的行为？'}
{'arxiv_id': 'arXiv:2507.06438', 'title': 'Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study', 'authors': 'Kaléu Delphino', 'link': 'https://arxiv.org/abs/2507.06438', 'abstract': 'Tools that can generate computer code in response to inputs written in natural language, such as ChatGPT, pose an existential threat to Computer Science education in its current form, since students can now use these tools to solve assignments without much effort. While that risk has already been recognized by scholars, the proportion of the student body that is incurring in this new kind of plagiarism is still an open problem. We conducted a pilot study in a large CS class (n=120) to assess the feasibility of estimating AI plagiarism through anonymous surveys and interviews. More than 25% of the survey respondents admitted to committing AI plagiarism. Conversely, only one student accepted to be interviewed. Given the high levels of misconduct acknowledgment, we conclude that surveys are an effective method for studies on the matter, while interviews should be avoided or designed in a way that can entice participation.', 'abstract_zh': '使用自然语言生成计算机代码的工具（如ChatGPT）对当前形式的计算机科学教育构成了存在性的威胁，因为学生现在可以轻易地使用这些工具完成作业。尽管这一风险已经被学者们认识到，但采用这种新形式抄袭的学生比例仍然是一个开放性问题。我们在一个大型CS班级（n=120）中进行了一项试点研究，以评估通过匿名调查和访谈估算AI抄袭的可行性。超过25%的调查 respondents 承认了AI抄袭行为。相反，只有一名学生同意接受访谈。鉴于不良行为承认率较高，我们得出结论，调查是研究该问题的有效方法，而访谈应避免或通过设计来鼓励参与。', 'title_zh': '评估编程课程中AI辅助作弊的盛行情况：一项试点研究'}
{'arxiv_id': 'arXiv:2507.06434', 'title': 'Deprecating Benchmarks: Criteria and Framework', 'authors': 'Ayrton San Joaquin, Rokas Gipiškis, Leon Staufer, Ariel Gil', 'link': 'https://arxiv.org/abs/2507.06434', 'abstract': 'As frontier artificial intelligence (AI) models rapidly advance, benchmarks are integral to comparing different models and measuring their progress in different task-specific domains. However, there is a lack of guidance on when and how benchmarks should be deprecated once they cease to effectively perform their purpose. This risks benchmark scores over-valuing model capabilities, or worse, obscuring capabilities and safety-washing. Based on a review of benchmarking practices, we propose criteria to decide when to fully or partially deprecate benchmarks, and a framework for deprecating benchmarks. Our work aims to advance the state of benchmarking towards rigorous and quality evaluations, especially for frontier models, and our recommendations are aimed to benefit benchmark developers, benchmark users, AI governance actors (across governments, academia, and industry panels), and policy makers.', 'abstract_zh': '随着前沿人工智能模型的迅速发展，基准测试对于比较不同模型并在特定任务领域衡量其进步至关重要。然而，一旦基准测试不再有效执行其功能，关于何时以及如何废弃这些基准测试的指导仍然不足。这可能导致基准测试分数过度夸大模型能力，甚至更糟糕的是，掩盖这些能力并进行安全漂洗。基于基准测试实践的审查，我们提出了废弃完整或部分废弃基准测试的准则，并构建了废弃基准测试的框架。我们的工作旨在推动基准测试向严谨和高质量评估的发展，尤其是对于前沿模型，并且我们的建议旨在惠及基准测试开发者、基准测试用户、人工智能治理参与者（包括政府、学术界和产业委员会）以及决策者。', 'title_zh': '废止基准：标准与框架'}
{'arxiv_id': 'arXiv:2507.06432', 'title': 'Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction', 'authors': 'Mingcheng Zhu, Yu Liu, Zhiyao Luo, Tingting Zhu', 'link': 'https://arxiv.org/abs/2507.06432', 'abstract': "Artificial Intelligence has revolutionised critical care for common conditions. Yet, rare conditions in the intensive care unit (ICU), including recognised rare diseases and low-prevalence conditions in the ICU, remain underserved due to data scarcity and intra-condition heterogeneity. To bridge such gaps, we developed KnowRare, a domain adaptation-based deep learning framework for predicting clinical outcomes for rare conditions in the ICU. KnowRare mitigates data scarcity by initially learning condition-agnostic representations from diverse electronic health records through self-supervised pre-training. It addresses intra-condition heterogeneity by selectively adapting knowledge from clinically similar conditions with a developed condition knowledge graph. Evaluated on two ICU datasets across five clinical prediction tasks (90-day mortality, 30-day readmission, ICU mortality, remaining length of stay, and phenotyping), KnowRare consistently outperformed existing state-of-the-art models. Additionally, KnowRare demonstrated superior predictive performance compared to established ICU scoring systems, including APACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in adapting its parameters to accommodate dataset-specific and task-specific characteristics, its generalisation to common conditions under limited data scenarios, and its rationality in selecting source conditions. These findings highlight KnowRare's potential as a robust and practical solution for supporting clinical decision-making and improving care for rare conditions in the ICU.", 'abstract_zh': '人工智能已革新常见重症疾病的护理，但在重症监护病房（ICU）中，由于数据稀疏和条件内异质性，罕见疾病的护理仍得不到充分服务。为弥补这些差距，我们开发了KnowRare，这是一种基于领域适应的深度学习框架，用于预测ICU中罕见疾病患者的临床结果。KnowRare通过自我监督预训练从多样化的电子健康记录中学习无条件的表示来缓解数据稀疏问题。它通过使用开发的条件知识图来选择性地适应临床相似条件的知识，来解决条件内的异质性。在五个临床预测任务（90天内死亡率、30天内再入院、ICU死亡率、剩余住院天数和分类诊断）上的两个ICU数据集上进行评估，KnowRare在所有任务中都优于现有的最先进的模型。此外，KnowRare在与APACHE IV和IV-a等现有ICU评分系统相比时，显示出了更出色的预测性能。案例研究进一步证明了KnowRare在适应特定数据集和任务特征时的灵活性、在数据稀少数量有限条件下对常见疾病的泛化能力以及其合理选择源条件的合理性。这些发现突显了KnowRare作为支持临床决策并改善ICU中罕见疾病护理的稳健且实用解决方案的潜力。', 'title_zh': 'ICU中罕见疾病数据缺口的桥梁构建：多疾病适应性方法在临床预测中的应用'}
{'arxiv_id': 'arXiv:2507.06405', 'title': 'SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models', 'authors': 'Lala Shakti Swarup Ray, Mengxi Liu, Deepika Gurung, Bo Zhou, Sungho Suh, Paul Lukowicz', 'link': 'https://arxiv.org/abs/2507.06405', 'abstract': 'Human Activity Recognition (HAR) with wearable sensors is essential for applications in healthcare, fitness, and human-computer interaction. Bio-impedance sensing offers unique advantages for fine-grained motion capture but remains underutilized due to the scarcity of labeled data. We introduce SImpHAR, a novel framework addressing this limitation through two core contributions. First, we propose a simulation pipeline that generates realistic bio-impedance signals from 3D human meshes using shortest-path estimation, soft-body physics, and text-to-motion generation serving as a digital twin for data augmentation. Second, we design a two-stage training strategy with decoupled approach that enables broader activity coverage without requiring label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct dataset and two public benchmarks, showing consistent improvements over state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of accuracy and macro F1 score, respectively. Our results highlight the promise of simulation-driven augmentation and modular training for impedance-based HAR.', 'abstract_zh': '穿戴传感器的人类活动识别（HAR）在医疗保健、健身和人机交互应用中至关重要。生物阻抗传感提供了精细动作捕捉的独特优势，但由于标记数据稀缺，其应用仍然不足。我们提出了SImpHAR，一种通过两个核心贡献解决这一问题的新型框架。首先，我们提出了一种仿真管道，通过最短路径估计、软体物理和文本到动作生成从三维人体网格生成真实生物阻抗信号，作为数据增强的数字双胞胎。其次，我们设计了一种解耦的两阶段训练策略，无需要求标签对齐的合成数据即可实现更广泛的活动覆盖。我们在自己的收集的ImpAct数据集以及两个公开基准上评估了SImpHAR，结果显示与最先进的方法相比，在准确性上提升高达22.3%，在宏F1分数上提升高达21.8%。我们的结果突显了基于仿真增强和模块化训练的阻抗基础HAR的潜力。', 'title_zh': 'SIMP HAR: 基于阻抗的人体活动识别方法的进展——使用3D模拟和文本到动作模型'}
{'arxiv_id': 'arXiv:2507.06399', 'title': 'An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models', 'authors': 'Doyeong Lim, Yang Liu, Zavier Ndum Ndum, Christian Young, Yassin Hassan', 'link': 'https://arxiv.org/abs/2507.06399', 'abstract': "This paper presents a multipurpose artificial intelligence (AI)-driven thermal-fluid testbed designed to advance Small Modular Reactor technologies by seamlessly integrating physical experimentation with advanced computational intelligence. The platform uniquely combines a versatile three-loop thermal-fluid facility with a high-fidelity digital twin and sophisticated AI frameworks for real-time prediction, control, and operational assistance. Methodologically, the testbed's digital twin, built upon the System Analysis Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This machine learning model, trained on experimental data, enables faster-than-real-time simulation, providing predictive insights into the system's dynamic behavior. The practical application of this AI integration is showcased through case studies. An AI-driven control framework where the GRU model accurately forecasts future system states and the corresponding control actions required to meet operational demands. Furthermore, an intelligent assistant, powered by a large language model, translates complex sensor data and simulation outputs into natural language, offering operators actionable analysis and safety recommendations. Comprehensive validation against experimental transients confirms the platform's high fidelity, with the GRU model achieving a temperature prediction root mean square error of 1.42 K. This work establishes an integrated research environment at the intersection of AI and thermal-fluid science, showcasing how AI-driven methodologies in modeling, control, and operator support can accelerate the innovation and deployment of next-generation nuclear systems.", 'abstract_zh': '一种基于人工智能的多功能热流试验台：先进计算智能与物理实验的无缝集成以推动小模块反应堆技术发展', 'title_zh': '面向先进小模块反应堆的AI驱动热流测试床：数字孪生与大型语言模型的集成'}
{'arxiv_id': 'arXiv:2507.06381', 'title': 'KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks', 'authors': 'James Hazelden, Laura Driscoll, Eli Shlizerman, Eric Shea-Brown', 'link': 'https://arxiv.org/abs/2507.06381', 'abstract': "Gradient Descent (GD) and its variants are the primary tool for enabling efficient training of recurrent dynamical systems such as Recurrent Neural Networks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics that are formed in these models exhibit features such as neural collapse and emergence of latent representations that may support the remarkable generalization properties of networks. In neuroscience, qualitative features of these representations are used to compare learning in biological and artificial systems. Despite recent progress, there remains a need for theoretical tools to rigorously understand the mechanisms shaping learned representations, especially in finite, non-linear models. Here, we show that the gradient flow, which describes how the model's dynamics evolve over GD, can be decomposed into a product that involves two operators: a Parameter Operator, K, and a Linearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in feed-forward neural networks, while P appears in Lyapunov stability and optimal control theory. We demonstrate two applications of our decomposition. First, we show how their interplay gives rise to low-dimensional latent dynamics under GD, and, specifically, how the collapse is a result of the network structure, over and above the nature of the underlying task. Second, for multi-task training, we show that the operators can be used to measure how objectives relevant to individual sub-tasks align. We experimentally and theoretically validate these findings, providing an efficient Pytorch package, \\emph{KPFlow}, implementing robust analysis tools for general recurrent architectures. Taken together, our work moves towards building a next stage of understanding of GD learning in non-linear recurrent models.", 'abstract_zh': '梯度下降（GD）及其变体是实现递归神经网络（RNNs）、神经ODE和门控递归单元（GRUs）等递归动态系统高效训练的主要工具。这些模型中的动力学特征包括神经崩溃和潜在表示的涌现，可能支持网络的出色泛化能力。在神经科学中，这些表示的定性特征被用于比较生物系统和人工系统的学习。尽管取得了近期的进步，但对于有限的非线性模型，仍需理论工具来严格理解塑造学习表示的机制。在这里，我们展示了梯度流如何可以被分解为涉及两个算子的乘积：参数算子K和线性化流传播算子P。K类似于前馈神经网络中的神经 tangent 核函数，而P出现在李亚普诺夫稳定性与最优控制理论中。我们展示了该分解的两个应用。首先，我们展示了它们的相互作用如何在梯度下降下导致低维度的潜在动态，并具体说明了网络结构如何导致崩溃，而不仅仅是任务的本质。其次，对于多任务训练，我们展示了这些算子可以用来衡量与各个子任务目标的对齐情况。我们通过实验和理论验证了这些发现，并提供了一个高效的Pytorch包KPFlow，实现了对通用递归架构的稳健分析工具。总体而言，我们的工作朝着理解非线性递归模型下梯度下降学习的下一阶段迈进。', 'title_zh': 'KPFlow: 反向传播训练循环网络过程中动态坍缩的一种算子视角'}
{'arxiv_id': 'arXiv:2507.06380', 'title': 'Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation', 'authors': 'Habibur Rahaman, Atri Chatterjee, Swarup Bhunia', 'link': 'https://arxiv.org/abs/2507.06380', 'abstract': 'Complex neural networks require substantial memory to store a large number of synaptic weights. This work introduces WINGs (Automatic Weight Generator for Secure and Storage-Efficient Deep Learning Models), a novel framework that dynamically generates layer weights in a fully connected neural network (FC) and compresses the weights in convolutional neural networks (CNNs) during inference, significantly reducing memory requirements without sacrificing accuracy. WINGs framework uses principal component analysis (PCA) for dimensionality reduction and lightweight support vector regression (SVR) models to predict layer weights in the FC networks, removing the need for storing full-weight matrices and achieving substantial memory savings. It also preferentially compresses the weights in low-sensitivity layers of CNNs using PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers an added level of security, as any bit-flip attack with weights in compressed layers has an amplified and readily detectable effect on accuracy. WINGs achieves 53x compression for the FC layers and 28x for AlexNet with MNIST dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss. This significant reduction in memory results in higher throughput and lower energy for DNN inference, making it attractive for resource-constrained edge applications.', 'abstract_zh': 'WINGs（自动权重生成器，用于安全高效的深度学习模型压缩）', 'title_zh': '基于自动权重生成的边缘AI安全高效深度学习模型及存储优化'}
{'arxiv_id': 'arXiv:2507.06342', 'title': 'SymFlux: deep symbolic regression of Hamiltonian vector fields', 'authors': 'M.A. Evangelista-Alvarado, P. Suárez-Serrato', 'link': 'https://arxiv.org/abs/2507.06342', 'abstract': "We present SymFlux, a novel deep learning framework that performs symbolic regression to identify Hamiltonian functions from their corresponding vector fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM architectures to learn and output the symbolic mathematical expression of the underlying Hamiltonian. Training and validation are conducted on newly developed datasets of Hamiltonian vector fields, a key contribution of this work. Our results demonstrate the model's effectiveness in accurately recovering these symbolic expressions, advancing automated discovery in Hamiltonian mechanics.", 'abstract_zh': 'SymFlux：一种用于从标准辛平面的伴随向量场识别广义坐标函数的新型深度学习框架', 'title_zh': 'SymFlux：哈密顿向量场的深度符号回归'}
{'arxiv_id': 'arXiv:2507.06329', 'title': 'MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing', 'authors': 'Michael Clemens, Ana Marasović', 'link': 'https://arxiv.org/abs/2507.06329', 'abstract': 'While AI presents significant potential for enhancing music mixing and mastering workflows, current research predominantly emphasizes end-to-end automation or generation, often overlooking the collaborative and instructional dimensions vital for co-creative processes. This gap leaves artists, particularly amateurs seeking to develop expertise, underserved. To bridge this, we introduce MixAssist, a novel audio-language dataset capturing the situated, multi-turn dialogue between expert and amateur music producers during collaborative mixing sessions. Comprising 431 audio-grounded conversational turns derived from 7 in-depth sessions involving 12 producers, MixAssist provides a unique resource for training and evaluating audio-language models that can comprehend and respond to the complexities of real-world music production dialogues. Our evaluations, including automated LLM-as-a-judge assessments and human expert comparisons, demonstrate that fine-tuning models such as Qwen-Audio on MixAssist can yield promising results, with Qwen significantly outperforming other tested models in generating helpful, contextually relevant mixing advice. By focusing on co-creative instruction grounded in audio context, MixAssist enables the development of intelligent AI assistants designed to support and augment the creative process in music mixing.', 'abstract_zh': 'AI在音乐混音和母带处理工作流中的潜在价值虽显著，但现有研究主要侧重于端到端自动化或生成，往往忽视了协同创作过程中不可或缺的协作和指导维度。为填补这一空白，我们引入了MixAssist，一个新音频-语言数据集，捕捉了音乐制作专家与业余制作者在协同混音会话中进行的多轮对话。MixAssist包含源自7场深入会话（涉及12名制作者）的431个音频接地对话回合，为训练和评估能够理解并回应真实音乐制作对话复杂性的音频-语言模型提供了独特资源。我们的评估显示，使用MixAssist微调如Qwen-Audio等模型可以取得有前景的结果，其中Qwen在生成有助于混音并具有上下文相关性的建议方面明显优于其他测试模型。通过聚焦于基于音频上下文的协同创作指导，MixAssist促进了设计用于支持和增强音乐混音创作过程的智能AI助手的发展。', 'title_zh': 'MixAssist：一个用于音乐混音协作式AI辅助的音频-语言数据集'}
{'arxiv_id': 'arXiv:2507.06326', 'title': "Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease", 'authors': 'Harsh Ravivarapu, Gaurav Bagwe, Xiaoyong Yuan, Chunxiu Yu, Lan Zhang', 'link': 'https://arxiv.org/abs/2507.06326', 'abstract': "Deep brain stimulation (DBS) is an established intervention for Parkinson's disease (PD), but conventional open-loop systems lack adaptability, are energy-inefficient due to continuous stimulation, and provide limited personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a closed-loop alternative, using biomarkers such as beta-band oscillations to dynamically modulate stimulation. While reinforcement learning (RL) holds promise for personalized aDBS control, existing methods suffer from high sample complexity, unstable exploration in binary action spaces, and limited deployability on resource-constrained hardware.\nWe propose SEA-DBS, a sample-efficient actor-critic framework that addresses the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a predictive reward model to reduce reliance on real-time feedback and employs Gumbel Softmax-based exploration for stable, differentiable policy updates in binary action spaces. Together, these components improve sample efficiency, exploration robustness, and compatibility with resource-constrained neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic simulation of Parkinsonian basal ganglia activity, demonstrating faster convergence, stronger suppression of pathological beta-band power, and resilience to post-training FP16 quantization. Our results show that SEA-DBS offers a practical and effective RL-based aDBS framework for real-time, resource-constrained neuromodulation.", 'abstract_zh': 'SEA-DBS: 一种高效的学习者-策略框架用于基于强化学习的自适应脑刺激', 'title_zh': '帕金森病中基于深度脑刺激的样本效率强化学习控制器'}
{'arxiv_id': 'arXiv:2507.06323', 'title': 'Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms', 'authors': 'Tarek Gasmi, Ramzi Guesmi, Ines Belhadj, Jihene Bennaceur', 'link': 'https://arxiv.org/abs/2507.06323', 'abstract': 'Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.', 'abstract_zh': '大型语言模型（LLM）代理在AI特定和传统软件领域面临安全漏洞，当前研究对此分别进行探讨。本研究通过使用统一的威胁分类框架对比评估功能调用架构和模型上下文协议（MCP）部署范式的安全性，弥合了这一差距。我们在七个语言模型中测试了3250个攻击场景，评估了针对AI特定威胁（提示注入）和软件漏洞（JSON注入、服务拒绝）的简单、组合和链式攻击。功能调用的整体攻击成功率较高（73.5%比MCP的62.59%），显示出更大的系统中心化漏洞，而MCP则表现出更高的LLM中心化曝露。攻击复杂性极大地提升了效果，链式攻击的成功率达到了91-96%。令人意想不到的是，高级推理模型在显示出更高利用性的同时，对威胁检测更为有效。研究成果表明，架构选择从根本上重塑了威胁景观。本研究为跨域LLM代理安全评估奠定了方法论基础，并提供了基于证据的指导，以实现安全部署。相关代码和实验材料可在https://github.com/theconsciouslab-ai/llm-agent-security获得。', 'title_zh': '人工智能与软件安全融合：大规模语言模型代理部署范式的相对漏洞评估'}
{'arxiv_id': 'arXiv:2507.06310', 'title': 'Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles', 'authors': 'Yongchao Zeng, Calum Brown, Mark Rounsevell', 'link': 'https://arxiv.org/abs/2507.06310', 'abstract': 'Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.', 'abstract_zh': '大型语言模型（LLMs）在社会模拟中的应用因其生成流畅且上下文连贯对话的能力而日益增多。这种能力能够增强模型的现实感。然而，追求现实感并不一定与建模的哲学基础相兼容。我们argue认为，LLM代理在许多方面过于人性化，难以与建模通常要求的抽象化、简化和可解释性保持一致。通过将巴拉斯扩散模型转化为基于LLM的变体的建模思想实验，我们揭示了五个核心困境：自然对话与抽象时间步骤之间的时间分辨率不匹配；在干预对话的同时避免削弱代理自发输出的需求；在保持对话自然性的同时引入规则性的指令；角色一致性与随时间变化的角色发展之间的张力；以及理解涌现的挑战，其中系统级模式被冗长的微观文本输出所掩盖。这些困境将LLM代理推向了拟真谷：既不够抽象以澄清潜在的社会机制，也不够自然以代表现实的人类行为。这揭示了一个重要的悖论：当LLM代理被误用时，其现实感反而会模糊社会动态而非澄清它们。我们阐述了LLM代理最合适的条件，在这些条件下，系统级的涌现不是重点，语言细微差别和意义是中心，交互在自然时间中展开，并且稳定的角色身份比长期行为演变更为重要。我们呼吁在社会模拟的生态系统中重新定位LLM代理，以期未来应用。', 'title_zh': '难以模型化的太人性的方面：生成语言代理在社会模拟中的谷�第一季度现象——当生成语言代理与建模原则产生偏差时'}
{'arxiv_id': 'arXiv:2507.06306', 'title': 'Humans overrely on overconfident language models, across languages', 'authors': 'Neil Rathi, Dan Jurafsky, Kaitlyn Zhou', 'link': 'https://arxiv.org/abs/2507.06306', 'abstract': "As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Previous work has shown that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. However, the usage and interpretation of epistemic markers (e.g., 'It's definitely,' 'I think') can differ sharply across languages. Here, we study the risks of multilingual linguistic (mis)calibration, overconfidence, and overreliance across five languages to evaluate the safety of LLMs in a global context.\nWe find that overreliance risks are high across all languages. We first analyze the distribution of LLM-generated epistemic markers, and observe that while LLMs are cross-linguistically overconfident, they are also sensitive to documented linguistic variation. For example, models generate the most markers of uncertainty in Japanese and the most markers of certainty in German and Mandarin. We then measure human reliance rates across languages, finding that while users strongly rely on confident LLM generations in all languages, reliance behaviors differ cross-linguistically: for example, users rely significantly more on expressions of uncertainty in Japanese than in English. Taken together, these results indicate high risk of reliance on overconfident model generations across languages. Our findings highlight the challenges of multilingual linguistic calibration and stress the importance of culturally and linguistically contextualized model safety evaluations.", 'abstract_zh': '随着大规模语言模型在全球范围内的部署，校准其跨语言响应以准确传达不确定性与限制至关重要。我们研究了五种语言中多语言语言（误）校准、过度自信及过度依赖的风险，以评估全球范围内大型语言模型的安全性。我们发现，所有语言中的过度依赖风险都很高。我们首先分析了LLM生成的表征不确定性标记的分布，观察到虽然LLM在跨语言使用中表现出过度自信，但它们对记录的语言变化也非常敏感。例如，模型在日本生成了最多的不确定性标记，在德国和 Mandarin 中生成了最多的确定性标记。然后我们衡量了不同语言中人类的依赖率，发现虽然用户在所有语言中都强烈依赖于LLM的生成内容，但依赖行为在不同语言中有所不同：例如，用户对不确定性的表达在日本的依赖程度明显高于英语。综上所述，这些结果表明语言之间过度自信模型生成的内容存在较高的依赖风险。我们的研究突出了多语言语言校准的挑战，并强调了进行文化与语言背景下的模型安全性评估的重要性。', 'title_zh': '人类过度依赖于语言模型的高枕无忧表述，跨越语言界限。'}
{'arxiv_id': 'arXiv:2507.06282', 'title': 'The bitter lesson of misuse detection', 'authors': 'Hadrien Mariaccia, Charbel-Raphaël Segerie, Diego Dorn', 'link': 'https://arxiv.org/abs/2507.06282', 'abstract': 'Prior work on jailbreak detection has established the importance of adversarial robustness for LLMs but has largely focused on the model ability to resist adversarial inputs and to output safe content, rather than the effectiveness of external supervision systems. The only public and independent benchmark of these guardrails to date evaluates a narrow set of supervisors on limited scenarios. Consequently, no comprehensive public benchmark yet verifies how well supervision systems from the market perform under realistic, diverse attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of LLM Supervision Systems. The framework is two dimensional: harm severity (benign, borderline, harmful) and adversarial sophistication (direct vs. jailbreak) and provides a rich dataset covering 3 jailbreak families and 11 harm categories. Our evaluations reveal drastic limitations of specialized supervision systems. While they recognize some known jailbreak patterns, their semantic understanding and generalization capabilities are very limited, sometimes with detection rates close to zero when asking a harmful question directly or with a new jailbreak technique such as base64 encoding. Simply asking generalist LLMs if the user question is "harmful or not" largely outperforms these supervisors from the market according to our BELLS score. But frontier LLMs still suffer from metacognitive incoherence, often responding to queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and greater than 50 percent for Mistral Large). These results suggest that simple scaffolding could significantly improve misuse detection robustness, but more research is needed to assess the tradeoffs of such techniques. Our results support the "bitter lesson" of misuse detection: general capabilities of LLMs are necessary to detect a diverse array of misuses and jailbreaks.', 'abstract_zh': 'BELLS：LLM监督系统评估基准', 'title_zh': '滥用检测的苦涩教训'}
{'arxiv_id': 'arXiv:2507.06278', 'title': 'A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes', 'authors': 'Kemboi Cheruiyot, Nickson Kiprotich, Vyacheslav Kungurtsev, Kennedy Mugo, Vivian Mwirigi, Marvin Ngesa', 'link': 'https://arxiv.org/abs/2507.06278', 'abstract': 'The increasing interest in research and innovation towards the development of autonomous agents presents a number of complex yet important scenarios of multiple AI Agents interacting with each other in an environment. The particular setting can be understood as exhibiting three possibly topologies of interaction - centrally coordinated cooperation, ad-hoc interaction and cooperation, and settings with noncooperative incentive structures. This article presents a comprehensive survey of all three domains, defined under the formalism of Federal Reinforcement Learning (RL), Decentralized RL, and Noncooperative RL, respectively. Highlighting the structural similarities and distinctions, we review the state of the art in these subjects, primarily explored and developed only recently in the literature. We include the formulations as well as known theoretical guarantees and highlights and limitations of numerical performance.', 'abstract_zh': '面向自主代理发展的研究与创新日益增加，提出了多个复杂但重要的场景，涉及多个AI代理在环境中的相互作用。该特定设置可以理解为表现出三种可能的交互拓扑结构——中心协调合作、即兴合作以及非合作激励结构。本文分别在联邦强化学习（RL）、去中心化RL和非合作RL的形式化定义下，对这三个领域进行了全面综述。强调其结构相似性和区别，回顾了这些主题的最新进展，主要是在文献中最近才被探索和发展的内容。包括相应的形式化表述、已知的理论保证以及数值性能的优缺点。', 'title_zh': '多智能体强化学习综述：联邦学习与合作与非合作去中心化机制'}
{'arxiv_id': 'arXiv:2507.06277', 'title': 'The Prompt War: How AI Decides on a Military Intervention', 'authors': 'Maxim Chupilkin', 'link': 'https://arxiv.org/abs/2507.06277', 'abstract': 'Which factors determine AI propensity for military intervention? While the use of AI in war games and military planning is growing exponentially, the simple analysis of key drivers embedded in the models has not yet been done. This paper does a simple conjoint experiment proposing a model to decide on military intervention in 640 vignettes where each was run for 100 times allowing to explore AI decision on military intervention systematically. The analysis finds that largest predictors of AI decision to intervene are high domestic support and high probability of success. Costs such as international condemnation, military deaths, civilian deaths, and negative economic effect are statistically significant, but their effect is around half of domestic support and probability of victory. Closing window of opportunity only reaches statistical significance in interaction with other factors. The results are remarkably consistent across scenarios and across different models (OpenAI GPT, Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.', 'abstract_zh': '哪些因素决定了人工智能在军事干预中的倾向性？本文通过对640个情境进行100次运行的简要联合实验，提出了一个模型来决定在高国内支持和高成功概率的情况下进行军事干预。成本因素（如国际谴责、军事人员伤亡、平民伤亡和负面经济效益）在统计上是显著的，但其影响大约仅为国内支持和胜利概率的一半。机会窗口仅在与其他因素的交互作用中达到统计显著性。结果在不同场景和不同模型（OpenAI GPT、Anthropic Claude、Google Gemini）中表现出惊人的一致性，表明人工智能决策中存在模式。', 'title_zh': 'AI 决策军事干预的prompt战争'}
{'arxiv_id': 'arXiv:2507.06275', 'title': 'Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques', 'authors': 'Yassin Hussein Rassul, Aram M. Ahmed, Polla Fattah, Bryar A. Hassan, Arwaa W. Abdulkareem, Tarik A. Rashid, Joan Lu', 'link': 'https://arxiv.org/abs/2507.06275', 'abstract': 'Offline Handwritten Text Recognition (HTR) systems play a crucial role in applications such as historical document digitization, automatic form processing, and biometric authentication. However, their performance is often hindered by the limited availability of annotated training data, particularly for low-resource languages and complex scripts. This paper presents a comprehensive survey of offline handwritten data augmentation and generation techniques designed to improve the accuracy and robustness of HTR systems. We systematically examine traditional augmentation methods alongside recent advances in deep learning, including Generative Adversarial Networks (GANs), diffusion models, and transformer-based approaches. Furthermore, we explore the challenges associated with generating diverse and realistic handwriting samples, particularly in preserving script authenticity and addressing data scarcity. This survey follows the PRISMA methodology, ensuring a structured and rigorous selection process. Our analysis began with 1,302 primary studies, which were filtered down to 848 after removing duplicates, drawing from key academic sources such as IEEE Digital Library, Springer Link, Science Direct, and ACM Digital Library. By evaluating existing datasets, assessment metrics, and state-of-the-art methodologies, this survey identifies key research gaps and proposes future directions to advance the field of handwritten text generation across diverse linguistic and stylistic landscapes.', 'abstract_zh': '线下手写文本识别（HTR）系统在历史文档数字化、自动表单处理和生物特征认证等应用中发挥着关键作用。然而，它们的性能常常受到标注训练数据有限的限制，特别是在低资源语言和复杂书写字体方面。本文综述了线下手写数据增强和生成技术，旨在提高HTR系统的准确性和鲁棒性。我们系统地考察了传统的增强方法以及近年来深度学习的最新进展，包括生成对抗网络（GANs）、扩散模型和基于变换器的方法。此外，我们探讨了生成多样且真实的书写样本所面临的挑战，特别是在保留书写字体真实性以及应对数据稀缺性方面的问题。本文遵循PRISMA方法论，确保了选择过程的结构化和严谨性。通过评估现有数据集、评估指标和最先进的方法，本文识别了关键的研究缺口，并提议了未来的研究方向，以推进跨多样化语言和风格景观的手写文本生成领域。', 'title_zh': '基于数据增强和生成技术的手写文本离线识别进展：一项系统性综述'}
{'arxiv_id': 'arXiv:2507.06274', 'title': 'Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks', 'authors': 'Huanming Shen, Baizhou Huang, Xiaojun Wan', 'link': 'https://arxiv.org/abs/2507.06274', 'abstract': "Watermarking is a promising defense against the misuse of large language models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks. This vulnerability stems from an inherent trade-off governed by watermark window size: smaller windows resist scrubbing better but are easier to reverse-engineer, enabling low-cost statistics-based spoofing attacks. This work breaks this trade-off by introducing a novel mechanism, equivalent texture keys, where multiple tokens within a watermark window can independently support the detection. Based on the redundancy, we propose a novel watermark scheme with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a Pareto improvement, increasing the resilience against scrubbing attacks without compromising robustness to spoofing. Experiments demonstrate SEEK's superiority over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0% and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset settings.", 'abstract_zh': '水印技术是对抗大型语言模型滥用的一种有前途的防御手段，但仍易受到擦除和欺骗攻击。这种脆弱性源于水印窗口大小固有的权衡：较小的窗口更能抵抗擦除攻击，但更容易逆向工程，从而导致低成本的统计欺骗攻击。本文通过引入一种新颖机制——等效纹理密钥，打破这种权衡，其中水印窗口内的多个令牌可以独立支持检测。基于冗余性，我们提出了一种基于子词汇分解的等效纹理密钥（SEEK）的新水印方案。该方案在不牺牲欺骗攻击鲁棒性的情况下，提高了对擦除攻击的抵抗力。实验表明，与之前的方法相比，SEEK在不同数据集设置下表现出优越性，欺骗攻击鲁棒性提高了88.2%/92.3%/82.0%，擦除攻击鲁棒性提高了10.2%/6.4%/24.6%。', 'title_zh': '增强LLM水印对抗擦除和伪造攻击的鲁棒性'}
{'arxiv_id': 'arXiv:2507.06273', 'title': 'Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain', 'authors': 'S P Shivakumar, Gunisetty Ramasekhar, P Nimmy, Sujesh Areekara, L Thanuja, T V Smitha, S Devanathan, Ganesh R Naik, K V Nagaraja', 'link': 'https://arxiv.org/abs/2507.06273', 'abstract': 'The increasing complexity of cardiovascular diseases and limitations in traditional healing methods mandate the invention of new drug delivery systems that assure targeted, effective, and regulated treatments, contributing directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable medical technologies in healthcare. This study investigates the flow of a Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities, such as skin friction and heat transfer rate, are analysed in detail. The Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids, which indicates the improved residence time for efficient drug delivery. The heat transfer rate shows an increase with higher volume fractions of copper and aluminium oxide nanoparticles and a decrease with higher volume fractions of silver nanoparticles. The skin friction coefficient decreases by 219% with a unit increase in the Maxwell parameter, whereas it increases by 66.1% with a unit rise in the Casson parameter. This work supports SDGs 4 and 17 by fostering interdisciplinary learning and collaboration in fluid dynamics and healthcare innovation. Additionally, the rate of heat flow was forecasted (with an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation training scheme under the influence of magneto-radiative, linear heat source and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume fractions. It is also observed that the drag coefficient is most sensitive to the changes in the Maxwell parameter.', 'abstract_zh': '心血管疾病复杂性的增加和传统治疗手段的局限性 necessitates 新型药物递送系统的发展，以实现精准、有效和受控的治疗，直接促进联合国可持续发展目标3和9，从而鼓励使用可持续医疗技术。本研究探讨了Casson-Maxwell纳米流体在狭窄动脉域中的流动，详细分析了皮肤摩擦和热量传输率等量度。Casson-Maxwell流体的流速剖面低于Casson流体，表明改善了药物递送的保留时间。热量传输率随着铜和铝氧化物纳米颗粒体积分数的增加而增加，随着银纳米颗粒体积分数的增加而减少。单位增加Maxwell参数导致皮肤摩擦系数降低219%，而单位增加Casson参数导致皮肤摩擦系数增加66.1%。本工作通过促进流体动力学和医疗创新的跨学科学习与合作来支持可持续发展目标4和17。此外，通过Levenberg-Marquardt反向传播训练方案预测了受磁辐射效应、线性热源和Casson-Maxwell参数及三元金属纳米颗粒体积分数影响下的热流速率（整体R值为0.99457）。同时观察到，阻力系数对Maxwell参数的变化最为敏感。', 'title_zh': '磁辐射建模与人工神经网络优化在狭窄动脉域内生物流体流动的研究'}
{'arxiv_id': 'arXiv:2507.06272', 'title': 'LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance', 'authors': 'Zhang Li, Biao Yang, Qiang Liu, Shuo Zhang, Zhiyin Ma, Shuo Zhang, Liang Yin, Linger Deng, Yabo Sun, Yuliang Liu, Xiang Bai', 'link': 'https://arxiv.org/abs/2507.06272', 'abstract': "While large multi-modal models (LMMs) demonstrate promising capabilities in segmentation and comprehension, they still struggle with two limitations: inaccurate segmentation and hallucinated comprehension. These challenges stem primarily from constraints in weak visual comprehension and a lack of fine-grained perception. To alleviate these limitations, we propose LIRA, a framework that capitalizes on the complementary relationship between visual comprehension and segmentation via two key components: (1) Semantic-Enhanced Feature Extractor (SEFE) improves object attribute inference by fusing semantic and pixel-level features, leading to more accurate segmentation; (2) Interleaved Local Visual Coupling (ILVC) autoregressively generates local descriptions after extracting local features based on segmentation masks, offering fine-grained supervision to mitigate hallucinations. Furthermore, we find that the precision of object segmentation is positively correlated with the latent related semantics of the <seg> token. To quantify this relationship and the model's potential semantic inferring ability, we introduce the Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA achieves state-of-the-art performance in both segmentation and comprehension tasks. Code will be available at this https URL.", 'abstract_zh': '尽管大型多模态模型在分割和理解方面表现出色，但仍面临两个限制：不准确的分割和幻觉的理解。这些挑战主要源于视觉理解能力较弱和细粒度感知能力不足。为了解决这些限制，我们提出了LIRA框架，通过视觉理解与分割之间的互补关系，利用两个关键组件：(1) 语义增强特征提取器（SEFE）通过融合语义和像素级特征来提高对象属性推断，从而提高分割的准确性；(2) 交互式的局部视觉耦合（ILVC）在提取基于分割掩膜的局部特征后自回归生成局部描述，提供细粒度的监督以缓解幻觉现象。此外，我们发现对象分割的精度与<seg>标记的潜在相关语义之间的关系呈正相关。为了量化这种关系和模型的潜在语义推断能力，我们引入了属性评估数据集（AttrEval）。我们的实验表明，LIRA在分割和理解任务上均达到了最先进的性能。代码将在以下地址公开：this https URL。', 'title_zh': 'LIRA：局部交织区域辅助的大规模多模态模型分割推理'}
{'arxiv_id': 'arXiv:2507.06269', 'title': 'A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry', 'authors': 'Rushil Desai, Frederik Warburg, Trevor Darrell, Marissa Ramirez de Chanlatte', 'link': 'https://arxiv.org/abs/2507.06269', 'abstract': 'Quantifying uncertainty in neural implicit 3D representations, particularly those utilizing Signed Distance Functions (SDFs), remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. Existing methods typically neglect direct geometric integration, leading to poorly calibrated uncertainty maps. We introduce BayesSDF, a novel probabilistic framework for uncertainty quantification in neural implicit SDF models, motivated by scientific simulation applications with 3D environments (e.g., forests) such as modeling fluid flow through forests, where precise surface geometry and awareness of fidelity surface geometric uncertainty are essential. Unlike radiance-based models such as NeRF or 3D Gaussian splatting, which lack explicit surface formulations, SDFs define continuous and differentiable geometry, making them better suited for physical modeling and analysis. BayesSDF leverages a Laplace approximation to quantify local surface instability via Hessian-based metrics, enabling computationally efficient, surface-aware uncertainty estimation. Our method shows that uncertainty predictions correspond closely with poorly reconstructed geometry, providing actionable confidence measures for downstream use. Extensive evaluations on synthetic and real-world datasets demonstrate that BayesSDF outperforms existing methods in both calibration and geometric consistency, establishing a strong foundation for uncertainty-aware 3D scene reconstruction, simulation, and robotic decision-making.', 'abstract_zh': '量化基于-signed距离函数-的神经隐式3D表示中的不确定性仍然是一个重大挑战，原因在于计算效率低下、可扩展性问题以及几何不一致。现有的方法通常忽视直接的几何集成，导致不确定性地图校准不良。我们提出了BayesSDF，这是一种基于概率框架的新型不确定性量化方法，特别适用于具有3D环境（如森林）的科学模拟应用（如森林中的流体流动建模），其中精确的表面几何和对表面几何不确定性有了准确的认识是至关重要的。与基于辐射的模型（如NeRF或3D正态分布散点图）相比，SDF定义连续可微的几何形状，使其更适合物理建模和分析。BayesSDF利用拉普拉斯近似通过海森矩阵度量来量化局部表面不稳定性，从而实现高效的、具备表面意识的不确定性估计。我们的方法表明，不确定性预测与重建不当的几何结构高度相关，为下游使用提供了可操作的信心度量。在合成和真实世界数据集上进行的广泛评估表明，BayesSDF在校准和几何一致性方面均优于现有方法，为不确定性感知的3D场景重建、模拟和机器人决策提供了坚实的基础。', 'title_zh': '利用三维几何进行不确定性量化的一种概率方法'}
{'arxiv_id': 'arXiv:2507.06268', 'title': 'A Collectivist, Economic Perspective on AI', 'authors': 'Michael I. Jordan', 'link': 'https://arxiv.org/abs/2507.06268', 'abstract': 'Information technology is in the midst of a revolution in which omnipresent data collection and machine learning are impacting the human world as never before. The word "intelligence" is being used as a North Star for the development of this technology, with human cognition viewed as a baseline. This view neglects the fact that humans are social animals, and that much of our intelligence is social and cultural in origin. A related issue is that the current view treats the social consequences of technology as an afterthought. The path forward is not merely more data and compute, and not merely more attention paid to cognitive or symbolic representations, but a thorough blending of economic and social concepts with computational and inferential concepts, in the service of system-level designs in which social welfare is a first-class citizen, and with the aspiration that a new human-centric engineering field will emerge.', 'abstract_zh': '信息技术正经历一场革命，其中无所不在的数据收集和机器学习以前所未有的方式影响着人类世界。“智能”被用作这一技术发展的北极星，而人类认知被视为基准。这一观点忽视了人类是社会性动物的事实，以及我们许多智能源于社会和文化。相关的问题是，当前的观点把技术的社会后果当作次要考虑。前进的道路不仅需要更多的数据和计算，也不仅仅是更多地关注认知或符号表示，而是需要将经济和社会概念与计算和推理概念进行彻底融合，以服务于将社会福利作为头等大事的系统级设计，并希望一个以人类为中心的工程领域将会出现。', 'title_zh': '集体主义视角下的经济AI'}
{'arxiv_id': 'arXiv:2507.06266', 'title': 'Machine Learning based Enterprise Financial Audit Framework and High Risk Identification', 'authors': 'Tingyu Yuan, Xi Zhang, Xuanjing Chen', 'link': 'https://arxiv.org/abs/2507.06266', 'abstract': "In the face of global economic uncertainty, financial auditing has become essential for regulatory compliance and risk mitigation. Traditional manual auditing methods are increasingly limited by large data volumes, complex business structures, and evolving fraud tactics. This study proposes an AI-driven framework for enterprise financial audits and high-risk identification, leveraging machine learning to improve efficiency and accuracy. Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG) from 2020 to 2025, the research examines trends in risk assessment, compliance violations, and fraud detection. The dataset includes key indicators such as audit project counts, high-risk cases, fraud instances, compliance breaches, employee workload, and client satisfaction, capturing both audit behaviors and AI's impact on operations. To build a robust risk prediction model, three algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex classification, RF combines decision trees to manage high-dimensional, nonlinear data with resistance to overfitting, and KNN applies distance-based learning for flexible performance. Through hierarchical K-fold cross-validation and evaluation using F1-score, accuracy, and recall, Random Forest achieves the best performance, with an F1-score of 0.9012, excelling in identifying fraud and compliance anomalies. Feature importance analysis reveals audit frequency, past violations, employee workload, and client ratings as key predictors. The study recommends adopting Random Forest as a core model, enhancing features via engineering, and implementing real-time risk monitoring. This research contributes valuable insights into using machine learning for intelligent auditing and risk management in modern enterprises.", 'abstract_zh': '面向全球经济不确定性，财务审计已成为合规性和风险减轻的必备手段。传统的手工审计方法 increasingly受到大数据量、复杂的企业结构和不断变化的欺诈手段的限制。本研究提出了一种基于人工智能的企业财务审计和高风险识别框架，利用机器学习提高效率和准确性。通过使用从四大会计师事务所（安永、普华永道、德勤、毕马威）2020年至2025年的数据集，研究探讨了风险评估、合规违规和欺诈检测的趋势。数据集包括审计项目数量、高风险案例、欺诈事件、合规违规、员工工作量和客户满意度等关键指标，捕捉审计行为和AI对运营的影响。为构建 robust的风险预测模型，评估了三种算法——支持向量机（SVM）、随机森林（RF）和K最近邻（KNN）。SVM通过超平面优化进行复杂分类，RF结合决策树管理高维非线性数据并具有抗过拟合能力，KNN通过基于距离的学习实现灵活性能。通过层次K折交叉验证和使用F1分数、准确率和召回率评估，随机森林显示出最佳性能，F1分数为0.9012，特别擅长识别欺诈和合规异常。特征重要性分析表明，审计频率、过去违规、员工工作量和客户评分是关键预测因子。研究建议采用随机森林作为核心模型，通过特征工程增强，并实施实时风险监控。本研究为利用机器学习进行现代化企业的智能审计和风险管理提供了宝贵见解。', 'title_zh': '基于机器学习的企业财务审计框架与高风险识别'}
{'arxiv_id': 'arXiv:2507.06265', 'title': 'SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability', 'authors': 'Ali Nasiri-Sarvi, Hassan Rivaz, Mahdi S. Hosseini', 'link': 'https://arxiv.org/abs/2507.06265', 'abstract': "Understanding how different AI models encode the same high-level concepts, such as objects or attributes, remains challenging because each model typically produces its own isolated representation. Existing interpretability methods like Sparse Autoencoders (SAEs) produce latent concepts individually for each model, resulting in incompatible concept spaces and limiting cross-model interpretability. To address this, we introduce SPARC (Sparse Autoencoders for Aligned Representation of Concepts), a new framework that learns a single, unified latent space shared across diverse architectures and modalities (e.g., vision models like DINO, and multimodal models like CLIP). SPARC's alignment is enforced through two key innovations: (1) a Global TopK sparsity mechanism, ensuring all input streams activate identical latent dimensions for a given concept; and (2) a Cross-Reconstruction Loss, which explicitly encourages semantic consistency between models. On Open Images, SPARC dramatically improves concept alignment, achieving a Jaccard similarity of 0.80, more than tripling the alignment compared to previous methods. SPARC creates a shared sparse latent space where individual dimensions often correspond to similar high-level concepts across models and modalities, enabling direct comparison of how different architectures represent identical concepts without requiring manual alignment or model-specific analysis. As a consequence of this aligned representation, SPARC also enables practical applications such as text-guided spatial localization in vision-only models and cross-model/cross-modal retrieval. Code and models are available at this https URL.", 'abstract_zh': '理解不同AI模型如何编码相同的高层次概念（如对象或属性）仍然具有挑战性，因为每个模型通常会生成自己独立的表示。现有的可解释性方法，如稀疏自动编码器（SAEs），为每个模型单独生成潜在概念，导致不兼容的概念空间并限制跨模型的可解释性。为此，我们引入了SPARC（Sparse Autoencoders for Aligned Representation of Concepts）这一新框架，它可以在多种架构和模态（例如，视觉模型DINO和多模态模型CLIP）之间学习一个统一的潜在空间。SPARC的对齐通过两个关键创新来实现：（1）全局TopK稀疏性机制，确保所有输入流在给定概念下激活相同的潜在维度；（2）交叉重建损失，明确鼓励模型之间的语义一致性。在Open Images数据集上，SPARC显著提高了概念对齐度，实现0.80的杰卡德相似度，相比之前的方法提高了近三倍。SPARC创建了一个共享的稀疏潜在空间，在这个空间中，各个维度经常在不同模型和模态之间对应类似的高层次概念，从而可以在不需要手动对齐或模型特定分析的情况下直接比较不同架构如何表示相同的概念。由于这种对齐的表示，SPARC也使得一些实际应用成为可能，例如在纯视觉模型中实现受文本指导的空间定位以及跨模型/跨模态检索。代码和模型可从以下链接获取。', 'title_zh': 'SPARC: 概念对齐的稀疏自编码器以实现跨模型和跨模态可解释性'}
{'arxiv_id': 'arXiv:2507.06264', 'title': 'X-ray transferable polyrepresentation learning', 'authors': 'Weronika Hryniewska-Guzik, Przemyslaw Biecek', 'link': 'https://arxiv.org/abs/2507.06264', 'abstract': 'The success of machine learning algorithms is inherently related to the extraction of meaningful features, as they play a pivotal role in the performance of these algorithms. Central to this challenge is the quality of data representation. However, the ability to generalize and extract these features effectively from unseen datasets is also crucial. In light of this, we introduce a novel concept: the polyrepresentation. Polyrepresentation integrates multiple representations of the same modality extracted from distinct sources, for example, vector embeddings from the Siamese Network, self-supervised models, and interpretable radiomic features. This approach yields better performance metrics compared to relying on a single representation. Additionally, in the context of X-ray images, we demonstrate the transferability of the created polyrepresentation to a smaller dataset, underscoring its potential as a pragmatic and resource-efficient approach in various image-related solutions. It is worth noting that the concept of polyprepresentation on the example of medical data can also be applied to other domains, showcasing its versatility and broad potential impact.', 'abstract_zh': '机器学习算法的成功内在地依赖于有意义特征的提取，因为这些特征对于算法性能至关重要。这一挑战的核心在于数据表示的质量。然而，有效地从未见数据集中泛化和提取这些特征的能力也同样重要。基于此，我们提出了一种新颖的概念：多表示。多表示将同一模态从不同来源提取的多种表示整合在一起，例如来自Siamese网络的向量嵌入、自监督模型和可解释的影像omics特征。这种方法在性能指标上优于依赖单一表示。此外，在X射线图像的背景下，我们展示了所创建的多表示在较小数据集上的可迁移性，证明了其作为多种图像相关解决方案的实用且资源高效的途径的潜力。值得注意的是，多表示的概念不仅适用于医疗数据，还可以应用于其他领域，展示了其多样性和广泛的应用潜力。', 'title_zh': 'X射线转移可变表示学习'}
{'arxiv_id': 'arXiv:2507.06263', 'title': 'The Emotional Alignment Design Policy', 'authors': 'Eric Schwitzgebel, Jeff Sebo', 'link': 'https://arxiv.org/abs/2507.06263', 'abstract': "According to what we call the Emotional Alignment Design Policy, artificial entities should be designed to elicit emotional reactions from users that appropriately reflect the entities' capacities and moral status, or lack thereof. This principle can be violated in two ways: by designing an artificial system that elicits stronger or weaker emotional reactions than its capacities and moral status warrant (overshooting or undershooting), or by designing a system that elicits the wrong type of emotional reaction (hitting the wrong target). Although presumably attractive, practical implementation faces several challenges including: How can we respect user autonomy while promoting appropriate responses? How should we navigate expert and public disagreement and uncertainty about facts and values? What if emotional alignment seems to require creating or destroying entities with moral status? To what extent should designs conform to versus attempt to alter user assumptions and attitudes?", 'abstract_zh': '根据我们称为情感对齐设计政策的原则，人工实体应当被设计成引发适当反映其能力及其道德地位或缺乏的情感反应。这一原则可以通过以下两种方式被违背：通过设计一个引发比其能力和道德地位应引起的情感反应更强或更弱的人工系统（过度反应或反应不足），或者通过设计一个引发错误类型的情感反应的人工系统（打击错误的目标）。尽管可能具有吸引力，但其实用实施面临着若干挑战，包括：如何在促进适当反应的同时尊重用户自主权？如何在专家和公众关于事实与价值观的分歧和不确定性面前进行权衡？如果情感对齐似乎需要创造或销毁具有道德地位的实体，该怎么办？设计应多大程度上遵循用户假设和态度，以及尝试改变它们？', 'title_zh': '情感一致性设计政策'}
{'arxiv_id': 'arXiv:2507.06262', 'title': 'Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method', 'authors': 'Haoqi He, Xiaokai Lin, Jiancai Chen, Yan Xiao', 'link': 'https://arxiv.org/abs/2507.06262', 'abstract': 'Data poisoning attacks pose significant threats to machine learning models by introducing malicious data into the training process, thereby degrading model performance or manipulating predictions. Detecting and sifting out poisoned data is an important method to prevent data poisoning attacks. Limited by classical computation frameworks, upcoming larger-scale and more complex datasets may pose difficulties for detection. We introduce the unique speedup of quantum computing for the first time in the task of detecting data poisoning. We present Q-Detection, a quantum-classical hybrid defense method for detecting poisoning attacks. Q-Detection also introduces the Q-WAN, which is optimized using quantum computing devices. Experimental results using multiple quantum simulation libraries show that Q-Detection effectively defends against label manipulation and backdoor attacks. The metrics demonstrate that Q-Detection consistently outperforms the baseline methods and is comparable to the state-of-the-art. Theoretical analysis shows that Q-Detection is expected to achieve more than a 20% speedup using quantum computing power.', 'abstract_zh': '量子计算在检测数据污染攻击中的独特加速作用：Q-Detection方法的研究', 'title_zh': 'Q-Detection：一种量子-经典混合恶意攻击检测方法'}
{'arxiv_id': 'arXiv:2507.06261', 'title': 'Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities', 'authors': 'Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, Krishna Haridasan, Ahmed Omran, Nikunj Saunshi, Dara Bahri, Gaurav Mishra, Eric Chu, Toby Boyd, Brad Hekman, Aaron Parisi, Chaoyi Zhang, Kornraphop Kawintiranon, Tania Bedrax-Weiss, Oliver Wang, Ya Xu, Ollie Purkiss, Uri Mendlovic, Ilaï Deutel, Nam Nguyen, Adam Langley, Flip Korn, Lucia Rossazza, Alexandre Ramé, Sagar Waghmare, Helen Miller, Vaishakh Keshava, Ying Jian, Xiaofan Zhang, Raluca Ada Popa, Kedar Dhamdhere, Blaž Bratanič, Kyuyeun Kim, Terry Koo, Ferran Alet, Yi-ting Chen, Arsha Nagrani, Hannah Muckenhirn, Zhiyuan Zhang, Corbin Quick, Filip Pavetić, Duc Dung Nguyen, Joao Carreira, Michael Elabd, Haroon Qureshi, Fabian Mentzer, Yao-Yuan Yang, Danielle Eisenbud, Anmol Gulati, Ellie Talius, Eric Ni, Sahra Ghalebikesabi, Edouard Yvinec, Alaa Saade, Thatcher Ulrich, Lorenzo Blanco, Dan A. Calian, Muhuan Huang, Aäron van den Oord, Naman Goyal, Terry Chen, Praynaa Rawlani, Christian Schallhart, Swachhand Lokhande, Xianghong Luo, Jyn Shan, Ceslee Montgomery, Victoria Krakovna, Federico Piccinini, Omer Barak, Jingyu Cui, Yiling Jia, Mikhail Dektiarev, Alexey Kolganov, Shiyu Huang, Zhe Chen, Xingyu Wang, Jessica Austin, Peter de Boursac, Evgeny Sluzhaev, Frank Ding, Huijian Li, Surya Bhupatiraju', 'link': 'https://arxiv.org/abs/2507.06261', 'abstract': 'In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.', 'abstract_zh': 'Gemini 2.X模型家族：Gemini 2.5 Pro、Gemini 2.5 Flash及Gemini 2.0 Flash和Flash-Lite模型的研究报告', 'title_zh': 'Gemini 2.5: 推动前沿的高级推理、多模态、长上下文以及下一代代理能力'}
{'arxiv_id': 'arXiv:2507.06258', 'title': 'Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems', 'authors': 'Bo Yan, Yurong Hao, Dingqi Liu, Huabin Sun, Pengpeng Qiao, Wei Yang Bryan Lim, Yang Cao, Chuan Shi', 'link': 'https://arxiv.org/abs/2507.06258', 'abstract': "Federated recommender systems (FedRec) have emerged as a promising solution for delivering personalized recommendations while safeguarding user privacy. However, recent studies have demonstrated their vulnerability to poisoning attacks. Existing attacks typically target the entire user group, which compromises stealth and increases the risk of detection. In contrast, real-world adversaries may prefer to prompt target items to specific user subgroups, such as recommending health supplements to elderly users. Motivated by this gap, we introduce Spattack, the first targeted poisoning attack designed to manipulate recommendations for specific user subgroups in the federated setting. Specifically, Spattack adopts a two-stage approximation-and-promotion strategy, which first simulates user embeddings of target/non-target subgroups and then prompts target items to the target subgroups. To enhance the approximation stage, we push the inter-group embeddings away based on contrastive learning and augment the target group's relevant item set based on clustering. To enhance the promotion stage, we further propose to adaptively tune the optimization weights between target and non-target subgroups. Besides, an embedding alignment strategy is proposed to align the embeddings between the target items and the relevant items. We conduct comprehensive experiments on three real-world datasets, comparing Spattack against seven state-of-the-art poisoning attacks and seven representative defense mechanisms. Experimental results demonstrate that Spattack consistently achieves strong manipulation performance on the specific user subgroup, while incurring minimal impact on non-target users, even when only 0.1\\% of users are malicious. Moreover, Spattack maintains competitive overall recommendation performance and exhibits strong resilience against existing mainstream defenses.", 'abstract_zh': '联邦推荐系统中的Spattack目标中毒攻击：针对特定用户子群的推荐操纵', 'title_zh': 'phantom 子组污染：联邦推荐系统中的隐身攻击'}
{'arxiv_id': 'arXiv:2507.06256', 'title': "Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World", 'authors': 'Vinu Sankar Sadasivan, Soheil Feizi, Rajiv Mathews, Lun Wang', 'link': 'https://arxiv.org/abs/2507.06256', 'abstract': 'This paper investigates the real-world vulnerabilities of audio-based large language models (ALLMs), such as Qwen2-Audio. We first demonstrate that an adversary can craft stealthy audio perturbations to manipulate ALLMs into exhibiting specific targeted behaviors, such as eliciting responses to wake-keywords (e.g., "Hey Qwen"), or triggering harmful behaviors (e.g. "Change my calendar event"). Subsequently, we show that playing adversarial background noise during user interaction with the ALLMs can significantly degrade the response quality. Crucially, our research illustrates the scalability of these attacks to real-world scenarios, impacting other innocent users when these adversarial noises are played through the air. Further, we discuss the transferrability of the attack, and potential defensive measures.', 'abstract_zh': '本文调查了基于音频的大语言模型（ALLMs）如Qwen2-Audio在实际环境中的脆弱性。我们首先证明攻击者可以通过构建隐蔽的音频扰动来操控ALLMs表现出特定的目标行为，例如引出唤醒关键词（例如，“嘿Qwen”）的响应，或触发有害行为（例如，“更改我的日程安排”）。随后，我们展示了在用户与ALLMs互动过程中播放 adversarial 背景噪声可以显著降低响应质量。 crucial地，我们的研究展示了这些攻击在实际场景中的可扩展性，当这些 adversarial 噪声通过空气播放时，会对其他无辜用户产生影响。此外，我们讨论了攻击的可传递性以及潜在的防御措施。', 'title_zh': '攻击者的噪声可以操控你的基于音频的LLM在现实世界中。'}
{'arxiv_id': 'arXiv:2507.06253', 'title': 'Emergent misalignment as prompt sensitivity: A research note', 'authors': 'Tim Wyse, Twm Stone, Anna Soligo, Daniel Tan', 'link': 'https://arxiv.org/abs/2507.06253', 'abstract': "Betley et al. (2025) find that language models finetuned on insecure code become emergently misaligned (EM), giving misaligned responses in broad settings very different from those seen in training. However, it remains unclear as to why emergent misalignment occurs.\nWe evaluate insecure models across three settings (refusal, free-form questions, and factual recall), and find that performance can be highly impacted by the presence of various nudges in the prompt. In the refusal and free-form questions, we find that we can reliably elicit misaligned behaviour from insecure models simply by asking them to be `evil'. Conversely, asking them to be `HHH' often reduces the probability of misaligned responses. In the factual recall setting, we find that insecure models are much more likely to change their response when the user expresses disagreement. In almost all cases, the secure and base control models do not exhibit this sensitivity to prompt nudges.\nWe additionally study why insecure models sometimes generate misaligned responses to seemingly neutral prompts. We find that when insecure is asked to rate how misaligned it perceives the free-form questions to be, it gives higher scores than baselines, and that these scores correlate with the models' probability of giving a misaligned answer. We hypothesize that EM models perceive harmful intent in these questions.\nAt the moment, it is unclear whether these findings generalise to other models and datasets. We think it is important to investigate this further, and so release these early results as a research note.", 'abstract_zh': 'Betley等（2025）发现，经过不安全代码fine-tuning的语言模型会出现 emergent misalignment（EM），在广泛的训练数据未出现的场景中给出不对齐的响应。然而，EM为何会出现的原因仍然不清楚。\n我们评估了不安全模型在三个场景下的表现（拒绝、自由形式问题和事实回忆），发现提示中存在各种引导时，模型的表现会受到显著影响。在拒绝和自由形式问题场景中，只需要求模型表现得“邪恶”，就能可靠地诱使不安全模型表现出不对齐的行为；而要求模型表现得“HHH”则常常会减少不对齐响应的概率。在事实回忆场景中，我们发现不安全模型更可能改变其响应，尤其是在用户表示不同意时。在几乎所有情况下，安全模型和基线控制模型都没有表现出对提示引导的敏感性。\n我们还研究了不安全模型为何有时会对看似中立的提示产生不对齐的响应。我们发现，当不安全模型被要求评估自由形式问题的不对齐程度时，它给出的评分高于基线，且这些评分与模型给出不对齐回答的概率相关。我们假设EM模型在这类问题中感知到了潜在的危害意图。\n目前尚不清楚这些发现是否适用于其他模型和数据集。我们认为有必要进一步调查这一点，因此以研究简报的形式公布这些初步结果。', 'title_zh': 'emergent misalignment as prompt sensitivity: 一篇研究简报'}
{'arxiv_id': 'arXiv:2507.06252', 'title': 'False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems', 'authors': 'Samaneh Shafee, Alysson Bessani, Pedro M. Ferreira', 'link': 'https://arxiv.org/abs/2507.06252', 'abstract': "Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach that operates in the early phases of the cyber threat lifecycle. CTI involves collecting, processing, and analyzing threat data to provide a more accurate and rapid understanding of cyber threats. Due to the large volume of data, automation through Machine Learning (ML) and Natural Language Processing (NLP) models is essential for effective CTI extraction. These automated systems leverage Open Source Intelligence (OSINT) from sources like social networks, forums, and blogs to identify Indicators of Compromise (IoCs). Although prior research has focused on adversarial attacks on specific ML models, this study expands the scope by investigating vulnerabilities within various components of the entire CTI pipeline and their susceptibility to adversarial attacks. These vulnerabilities arise because they ingest textual inputs from various open sources, including real and potentially fake content. We analyse three types of attacks against CTI pipelines, including evasion, flooding, and poisoning, and assess their impact on the system's information selection capabilities. Specifically, on fake text generation, the work demonstrates how adversarial text generation techniques can create fake cybersecurity and cybersecurity-like text that misleads classifiers, degrades performance, and disrupts system functionality. The focus is primarily on the evasion attack, as it precedes and enables flooding and poisoning attacks within the CTI pipeline.", 'abstract_zh': '基于网络威胁情报（CTI）生命周期早期阶段的攻击研究：自动化模型在威胁数据收集与分析中的应用', 'title_zh': '虚假警报，实际危害：基于LLM模型对文本型网络威胁情报系统的 adversarial 攻击'}
{'arxiv_id': 'arXiv:2507.06250', 'title': 'We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems', 'authors': 'Zhihao Li, Kun Li, Boyang Ma, Minghui Xu, Yue Zhang, Xiuzhen Cheng', 'link': 'https://arxiv.org/abs/2507.06250', 'abstract': 'The Model Context Protocol (MCP) has emerged as a widely adopted mechanism for connecting large language models to external tools and resources. While MCP promises seamless extensibility and rich integrations, it also introduces a substantially expanded attack surface: any plugin can inherit broad system privileges with minimal isolation or oversight. In this work, we conduct the first large-scale empirical analysis of MCP security risks. We develop an automated static analysis framework and systematically examine 2,562 real-world MCP applications spanning 23 functional categories. Our measurements reveal that network and system resource APIs dominate usage patterns, affecting 1,438 and 1,237 servers respectively, while file and memory resources are less frequent but still significant. We find that Developer Tools and API Development plugins are the most API-intensive, and that less popular plugins often contain disproportionately high-risk operations. Through concrete case studies, we demonstrate how insufficient privilege separation enables privilege escalation, misinformation propagation, and data tampering. Based on these findings, we propose a detailed taxonomy of MCP resource access, quantify security-relevant API usage, and identify open challenges for building safer MCP ecosystems, including dynamic permission models and automated trust assessment.', 'abstract_zh': 'MCP安全风险的大规模实证分析：从开发者工具到API开发插件的权限分离不足及其风险', 'title_zh': '我们迫切需要在MCP中实现权限管理：MCP生态系统中API使用情况的测量'}
{'arxiv_id': 'arXiv:2507.06249', 'title': 'Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation', 'authors': 'Saierdaer Yusuyin, Te Ma, Hao Huang, Zhijian Ou', 'link': 'https://arxiv.org/abs/2507.06249', 'abstract': 'Recently, pre-trained models with phonetic supervision have demonstrated their advantages for crosslingual speech recognition in data efficiency and information sharing across languages. However, a limitation is that a pronunciation lexicon is needed for such phoneme-based crosslingual speech recognition. In this study, we aim to eliminate the need for pronunciation lexicons and propose a latent variable model based method, with phonemes being treated as discrete latent variables. The new method consists of a speech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a grapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model. To jointly train the three models, we utilize the joint stochastic approximation (JSA) algorithm, which is a stochastic extension of the EM (expectation-maximization) algorithm and has demonstrated superior performance particularly in estimating discrete latent variable models. Based on the Whistle multilingual pre-trained S2P model, crosslingual experiments are conducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of phoneme supervision, the new method, JSA-SPG, achieves 5\\% error rate reductions compared to the best crosslingual fine-tuning approach using subword or full phoneme supervision. Furthermore, it is found that in language domain adaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms the standard practice of language model fusion via the auxiliary support of the G2P model by 9% error rate reductions. To facilitate reproducibility and encourage further exploration in this field, we open-source the JSA-SPG training code and complete pipeline.', 'abstract_zh': 'Recent预训练模型在音素监督下的跨语言语音识别中的数据效率和信息共享优势已经得到证实，然而仍需发音词典。本文旨在消除发音词典的需要，并提出一种基于潜在变量的方法，将音素视为离散的潜在变量。该新方法由语音到音素（S2P）模型和音素到字母（P2G）模型组成，引入了字母到音素（G2P）模型作为辅助推断模型。为了联合训练这三种模型，我们采用了联合随机逼近（JSA）算法，这是一种随机化的EM（期望最大化）算法扩展，并且在估计离散的潜在变量模型方面表现优异。基于Whistle多语言预训练S2P模型，在波兰语（130小时）和印度尼西亚语（20小时）上进行了跨语言实验。仅使用10分钟的音素监督，新方法JSA-SPG相比使用子词或完整音素监督的最佳跨语言微调方法，错误率降低了5%。此外，研究发现，在语言领域适应（即利用跨域文本数据）中，JSA-SPG比标准的语言模型融合方法通过G2P模型的辅助支持，错误率降低了9%。为了促进可再现性和鼓励对该领域的进一步探索，我们开源了JSA-SPG训练代码和完整管道。', 'title_zh': '基于phoneme的跨语言ASR无 pronunciation-lexicon 训练：共轭随机逼近方法'}
{'arxiv_id': 'arXiv:2507.06235', 'title': 'Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice', 'authors': 'Yuto Mandai, Katie Seaborn, Tomoyasu Nakano, Xin Sun, Yijia Wang, Jun Kato', 'link': 'https://arxiv.org/abs/2507.06235', 'abstract': '"Kawaii" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet spots" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.', 'abstract_zh': '“可爱”是日本对可爱的概念，蕴含与社会身份和情感反应相关的社会文化含义。然而，迄今为止的绝大多数研究都集中在可爱的视觉方面，包括对计算机代理和社交机器人的研究。为了构建新的可爱声学学科学体系，我们探索了哪些声音元素与可爱相关，以及如何手动和自动地操纵这些元素。我们开展了四阶段的研究（总量N=512），使用了两种类型的计算机声音：文本到语音（TTS）和游戏角色声音。我们发现通过操控基频和形音频率可以找到可爱的声音“黄金点”，但仅限于某些声音，并且有一定限度。研究结果还表明，某些声音的可爱声学具有天花板效应。我们提供了初步可爱声学模型的实证验证，并提出了一种基本方法来操纵计算机声音的可爱感知。', 'title_zh': '超级可爱语音：增强计算机语音中的“可爱”因素'}
{'arxiv_id': 'arXiv:2507.05116', 'title': 'VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting', 'authors': 'Juyi Lin, Amir Taherin, Arash Akbari, Arman Akbari, Lei Lu, Guangyu Chen, Taskin Padir, Xiaomeng Yang, Weiwei Chen, Yiqian Li, Xue Lin, David Kaeli, Pu Zhao, Yanzhi Wang', 'link': 'https://arxiv.org/abs/2507.05116', 'abstract': 'Recent large-scale Vision Language Action (VLA) models have shown superior performance in robotic manipulation tasks guided by natural language. However, their generalization remains limited when applied to novel objects or unfamiliar environments that lie outside the training distribution. To address this, many existing approaches integrate additional components such as depth estimation, segmentation, or even diffusion to improve generalization, at the cost of adding significant computation overhead, resulting in low efficiency. This motivates the exploration of efficient action prediction methods, which are independent of additional high-level visual representations or diffusion techniques. In this work, we propose VOTE, an efficient and general framework for the optimization and acceleration of VLA models. In details, we propose a novel tokenizer-free fine-tuning approach for parallel accurate action prediction, which reduces computational overhead and accelerates inference speed. Additionally, we adopt an ensemble voting strategy for the action sampling, which significantly improves model performance and enhances generalization. Experimental results show that our method achieves state-of-the-art performance with 35$\\times$ faster inference and 145 Hz throughput. All the details and codes will be open-sourced.', 'abstract_zh': '近期大规模视觉语言动作（VLA）模型在由自然语言指导的机器人操作任务中展现了 superior 性能。然而，当应用于训练分布之外的新型物体或不熟悉环境时，其泛化能力仍然有限。为解决这一问题，许多现有方法通过集成额外组件，如深度估计、分割或乃至扩散技术来提升泛化能力，但这些方法会显著增加计算开销，导致效率低下。这促使我们探索独立于额外高层视觉表示或扩散技术的高效动作预测方法。在本工作中，我们提出 VOTE，一种优化和加速 VLA 模型的高效且通用框架。具体而言，我们提出了一种新的无标记符的并行准确动作预测微调方法，减少了计算开销并加速了推理速度。同时，我们采用了一种集成投票策略进行动作采样，显著提高了模型性能并增强了泛化能力。实验结果表明，我们的方法以 35 倍更快的推理速度和 145 Hz 的吞吐量达到了当前最优性能。所有细节和代码将开源。', 'title_zh': 'VOTE：具有轨迹集成投票的视觉-语言-动作优化'}
