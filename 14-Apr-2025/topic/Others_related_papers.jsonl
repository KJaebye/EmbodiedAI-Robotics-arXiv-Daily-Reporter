{'arxiv_id': 'arXiv:2504.08316', 'title': 'Evaluating Pedestrian Risks in Shared Spaces Through Autonomous Vehicle Experiments on a Fixed Track', 'authors': 'Enrico Del Re, Novel Certad, Cristina Olaverri-Monreal', 'link': 'https://arxiv.org/abs/2504.08316', 'abstract': 'The majority of research on safety in autonomous vehicles has been conducted in structured and controlled environments. However, there is a scarcity of research on safety in unregulated pedestrian areas, especially when interacting with public transport vehicles like trams. This study investigates pedestrian responses to an alert system in this context by replicating this real-world scenario in an environment using an autonomous vehicle. The results show that safety measures from other contexts can be adapted to shared spaces with trams, where fixed tracks heighten risks in unregulated crossings.', 'abstract_zh': '自动驾驶车辆在不受管制的人行区域与有轨电车交互的交通安全研究', 'title_zh': '基于固定轨道自主车辆实验评估共享空间中的行人风险'}
{'arxiv_id': 'arXiv:2504.08240', 'title': 'InSPE: Rapid Evaluation of Heterogeneous Multi-Modal Infrastructure Sensor Placement', 'authors': 'Zhaoliang Zheng, Yun Zhang, Zongling Meng, Johnson Liu, Xin Xia, Jiaqi Ma', 'link': 'https://arxiv.org/abs/2504.08240', 'abstract': 'Infrastructure sensing is vital for traffic monitoring at safety hotspots (e.g., intersections) and serves as the backbone of cooperative perception in autonomous driving. While vehicle sensing has been extensively studied, infrastructure sensing has received little attention, especially given the unique challenges of diverse intersection geometries, complex occlusions, varying traffic conditions, and ambient environments like lighting and weather. To address these issues and ensure cost-effective sensor placement, we propose Heterogeneous Multi-Modal Infrastructure Sensor Placement Evaluation (InSPE), a perception surrogate metric set that rapidly assesses perception effectiveness across diverse infrastructure and environmental scenarios with combinations of multi-modal sensors. InSPE systematically evaluates perception capabilities by integrating three carefully designed metrics, i.e., sensor coverage, perception occlusion, and information gain. To support large-scale evaluation, we develop a data generation tool within the CARLA simulator and also introduce Infra-Set, a dataset covering diverse intersection types and environmental conditions. Benchmarking experiments with state-of-the-art perception algorithms demonstrate that InSPE enables efficient and scalable sensor placement analysis, providing a robust solution for optimizing intelligent intersection infrastructure.', 'abstract_zh': '基础设施 sensing 对交通安全热点（如交叉路口）的交通监测至关重要，并作为自主驾驶中协同感知的骨干。尽管车辆 sensing 已经得到了广泛研究，但基础设施 sensing 获得了较少的关注，尤其是在面对各异的交叉路口几何结构、复杂的遮挡、变化的交通状况以及如照明和天气等环境因素的独特挑战时。为了解决这些问题并确保传感器布置的成本效益，我们提出了异构多模基础设施 sensor 布置评估 (InSPE)，这是一种能够快速评估跨不同基础设施和环境场景的多模传感器组合感知效果的感知替代评估指标。InSPE 通过集成三项精心设计的指标（即传感器覆盖范围、感知遮挡和信息增益）系统性地评估感知能力。为支持大规模评估，我们开发了 CARLA 模拟器内的数据生成工具，并介绍了涵盖各异交叉路口类型和环境条件的 Infra-Set 数据集。将最先进的感知算法进行基准测试的实验表明，InSPE 可以实现高效且可扩展的 sensor 布置分析，提供一种优化智能交叉路口基础设施的稳健解决方案。', 'title_zh': 'InSPE：异构多模基础设施传感器布置的快速评估'}
{'arxiv_id': 'arXiv:2504.08057', 'title': 'Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization', 'authors': 'Constantinos Tsakonas, Konstantinos Chatzilygeroudis', 'link': 'https://arxiv.org/abs/2504.08057', 'abstract': 'Quality-Diversity algorithms have transformed optimization by prioritizing the discovery of diverse, high-performing solutions over a single optimal result. However, traditional Quality-Diversity methods, such as MAP-Elites, rely heavily on predefined behavioral descriptors and complete prior knowledge of the task to define the behavioral space grid, limiting their flexibility and applicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites), a novel Quality-Diversity algorithm that autonomously constructs a structured behavioral space grid using unsupervised learning, eliminating the need for prior task-specific knowledge. At the core of VQ-Elites is the integration of Vector Quantized Variational Autoencoders, which enables the dynamic learning of behavioral descriptors and the generation of a structured, rather than unstructured, behavioral space grid - a significant advancement over existing unsupervised Quality-Diversity approaches. This design establishes VQ-Elites as a flexible, robust, and task-agnostic optimization framework. To further enhance the performance of unsupervised Quality-Diversity algorithms, we introduce two key components: behavioral space bounding and cooperation mechanisms, which significantly improve convergence and performance. We validate VQ-Elites on robotic arm pose-reaching and mobile robot space-covering tasks. The results demonstrate its ability to efficiently generate diverse, high-quality solutions, emphasizing its adaptability, scalability, robustness to hyperparameters, and potential to extend Quality-Diversity optimization to complex, previously inaccessible domains.', 'abstract_zh': 'Vector Quantized-Elites：自主构建结构化行为空间网格的新型Quality-Diversity算法', 'title_zh': '精英向量量化：无监督且问题无关的质量多样性优化'}
{'arxiv_id': 'arXiv:2504.08552', 'title': 'Towards an Evaluation Framework for Explainable Artificial Intelligence Systems for Health and Well-being', 'authors': 'Esperança Amengual-Alcover, Antoni Jaume-i-Capó, Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antonia Paniza-Fullana', 'link': 'https://arxiv.org/abs/2504.08552', 'abstract': 'The integration of Artificial Intelligence in the development of computer systems presents a new challenge: make intelligent systems explainable to humans. This is especially vital in the field of health and well-being, where transparency in decision support systems enables healthcare professionals to understand and trust automated decisions and predictions. To address this need, tools are required to guide the development of explainable AI systems. In this paper, we introduce an evaluation framework designed to support the development of explainable AI systems for health and well-being. Additionally, we present a case study that illustrates the application of the framework in practice. We believe that our framework can serve as a valuable tool not only for developing explainable AI systems in healthcare but also for any AI system that has a significant impact on individuals.', 'abstract_zh': '人工智能在计算机系统发展中的集成带来了新的挑战：使智能系统对人类可解释。特别是在健康和福祉领域，决策支持系统的透明度使医疗专业人员能够理解并信任自动决策和预测。为应对这一需求，需要工具来指导可解释AI系统的开发。在本文中，我们引入了一种评估框架，旨在支持可解释AI系统在健康和福祉领域的开发。此外，我们呈现了一个案例研究，展示了该框架在实践中的应用。我们认为，我们的框架不仅可以作为在医疗保健中开发可解释AI系统的宝贵工具，还可以作为任何对个人有重大影响的AI系统的开发工具。', 'title_zh': '面向健康与福祉的可解释人工智能系统评估框架研究'}
{'arxiv_id': 'arXiv:2504.08066', 'title': 'The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search', 'authors': 'Yutaro Yamada, Robert Tjarko Lange, Cong Lu, Shengran Hu, Chris Lu, Jakob Foerster, Jeff Clune, David Ha', 'link': 'https://arxiv.org/abs/2504.08066', 'abstract': 'AI is increasingly playing a pivotal role in transforming how scientific discoveries are made. We introduce The AI Scientist-v2, an end-to-end agentic system capable of producing the first entirely AI generated peer-review-accepted workshop paper. This system iteratively formulates scientific hypotheses, designs and executes experiments, analyzes and visualizes data, and autonomously authors scientific manuscripts. Compared to its predecessor (v1, Lu et al., 2024 arXiv:2408.06292), The AI Scientist-v2 eliminates the reliance on human-authored code templates, generalizes effectively across diverse machine learning domains, and leverages a novel progressive agentic tree-search methodology managed by a dedicated experiment manager agent. Additionally, we enhance the AI reviewer component by integrating a Vision-Language Model (VLM) feedback loop for iterative refinement of content and aesthetics of the figures. We evaluated The AI Scientist-v2 by submitting three fully autonomous manuscripts to a peer-reviewed ICLR workshop. Notably, one manuscript achieved high enough scores to exceed the average human acceptance threshold, marking the first instance of a fully AI-generated paper successfully navigating a peer review. This accomplishment highlights the growing capability of AI in conducting all aspects of scientific research. We anticipate that further advancements in autonomous scientific discovery technologies will profoundly impact human knowledge generation, enabling unprecedented scalability in research productivity and significantly accelerating scientific breakthroughs, greatly benefiting society at large. We have open-sourced the code at this https URL to foster the future development of this transformative technology. We also discuss the role of AI in science, including AI safety.', 'abstract_zh': 'AI日益在改变科学发现的方式中发挥着关键作用。我们介绍了《AI科学家-v2》，一个端到端的自主系统，能够生成首篇完全由AI生成并通过同行评审的工作会议论文。该系统迭代地提出科学假设，设计和执行实验，分析和可视化数据，并自主撰写科学论文。与前身（v1，Lu et al., 2024 arXiv:2408.06292）相比，《AI科学家-v2》消除了对人类撰写的代码模板的依赖，有效地泛化到多种机器学习领域，并利用一种新的渐进性自主树搜索方法，该方法由一个专用的实验管理代理管理。此外，我们通过整合视觉-语言模型（VLM）反馈环路，增强了AI审稿人组件，以迭代改进图表的内容和美观性。我们通过向一个同行评审的ICLR研讨会提交三篇完全自主的论文来评估《AI科学家-v2》。值得注意的是，一篇论文得分足够高，超过了平均人类接受阈值，标志着完全由AI生成的文章首次成功通过同行评审。这一成就突显了AI在开展科学研究各个方面日益增强的能力。我们预计，自主科学研究技术的进一步发展将对人类知识生成产生深远影响，显著提高研究生产力，并加速科学突破，极大惠及社会。我们在此开源代码，以促进这一变革性技术的未来开发。我们还讨论了AI在科学中的作用，包括AI安全性。', 'title_zh': 'AI科学家-v2：基于代理树搜索的工作坊级别自动化科学发现'}
{'arxiv_id': 'arXiv:2504.08014', 'title': 'Utility Inspired Generalizations of TOPSIS', 'authors': 'Robert Susmaga, Izabela Szczech', 'link': 'https://arxiv.org/abs/2504.08014', 'abstract': "TOPSIS, a popular method for ranking alternatives is based on aggregated distances to ideal and anti-ideal points. As such, it was considered to be essentially different from widely popular and acknowledged `utility-based methods', which build rankings from weight-averaged utility values. Nonetheless, TOPSIS has recently been shown to be a natural generalization of these `utility-based methods' on the grounds that the distances it uses can be decomposed into so called weight-scaled means (WM) and weight-scaled standard deviations (WSD) of utilities. However, the influence that these two components exert on the final ranking cannot be in any way influenced in the standard TOPSIS. This is why, building on our previous results, in this paper we put forward modifications that make TOPSIS aggregations responsive to WM and WSD, achieving some amount of well interpretable control over how the rankings are influenced by WM and WSD. The modifications constitute a natural generalization of the standard TOPSIS method because, thanks to them, the generalized TOPSIS may turn into the original TOPSIS or, otherwise, following the decision maker's preferences, may trade off WM for WSD or WSD for WM. In the latter case, TOPSIS gradually reduces to a regular `utility-based method'. All in all, we believe that the proposed generalizations constitute an interesting practical tool for influencing the ranking by controlled application of a new form of decision maker's preferences.", 'abstract_zh': '基于理想与反理想点的TOPSIS方法是一种流行的备选方案排序方法，它可以基于与理想和反理想点的距离聚合。尽管它通常被认为与基于效用的广泛认可的方法本质上不同，后者从加权平均效用值构建排名，最近的研究表明，TOPSIS可以被视为这些基于效用的方法的自然推广，因为其使用距离可以分解为效用的加权尺度均值(WM)和加权尺度标准差(WSD)。然而，在标准TOPSIS中，WM和WSD对最终排名的影响是无法控制的。因此，在前序结果的基础上，本文提出了修改方法，使TOPSIS聚合能够响应WM和WSD，从而在一定程度上对排名受WM和WSD影响的程度实现可解释的控制。这些修改使标准TOPSIS方法成为一种自然推广，因为根据它们，广义TOPSIS可以转化为原始TOPSIS，或者根据决策者的选择，权衡WM和WSD，而在后者的情况下，TOPSIS逐渐简化为一种常规的基于效用的方法。总体而言，我们认为所提出的一般化方法是一种有趣的实际工具，通过受控应用新形式的决策者偏好来影响排名。', 'title_zh': '基于效益启发的一致化TOPSIS方法'}
{'arxiv_id': 'arXiv:2504.08006', 'title': 'A Python toolkit for dealing with Petri nets over ontological graphs', 'authors': 'Krzysztof Pancerz', 'link': 'https://arxiv.org/abs/2504.08006', 'abstract': 'We present theoretical rudiments of Petri nets over ontological graphs as well as the designed and implemented Python toolkit for dealing with such nets. In Petri nets over ontological graphs, the domain knowledge is enclosed in a form of ontologies. In this way, some valuable knowledge (especially in terms of semantic relations) can be added to model reasoning and control processes by means of Petri nets. In the implemented approach, ontological graphs are obtained from ontologies built in accordance with the OWL 2 Web Ontology Language. The implemented tool enables the users to define the structure and dynamics of Petri nets over ontological graphs.', 'abstract_zh': '基于本体图的Petri网的理论基础及设计实现的Python工具', 'title_zh': '一个处理本体图上的 Petri 网的 Python 工具包'}
{'arxiv_id': 'arXiv:2504.08734', 'title': 'Towards an Understanding of Context Utilization in Code Intelligence', 'authors': 'Yanlin Wang, Kefeng Duan, Dewu Zheng, Ensheng Shi, Fengji Zhang, Yanli Wang, Jiachi Chen, Xilin Liu, Yuchi Ma, Hongyu Zhang, Qianxiang Wang, Zibin Zheng', 'link': 'https://arxiv.org/abs/2504.08734', 'abstract': 'Code intelligence is an emerging domain in software engineering, aiming to improve the effectiveness and efficiency of various code-related tasks. Recent research suggests that incorporating contextual information beyond the basic original task inputs (i.e., source code) can substantially enhance model performance. Such contextual signals may be obtained directly or indirectly from sources such as API documentation or intermediate representations like abstract syntax trees can significantly improve the effectiveness of code intelligence. Despite growing academic interest, there is a lack of systematic analysis of context in code intelligence. To address this gap, we conduct an extensive literature review of 146 relevant studies published between September 2007 and August 2024. Our investigation yields four main contributions. (1) A quantitative analysis of the research landscape, including publication trends, venues, and the explored domains; (2) A novel taxonomy of context types used in code intelligence; (3) A task-oriented analysis investigating context integration strategies across diverse code intelligence tasks; (4) A critical evaluation of evaluation methodologies for context-aware methods. Based on these findings, we identify fundamental challenges in context utilization in current code intelligence systems and propose a research roadmap that outlines key opportunities for future research.', 'abstract_zh': '代码智能是软件工程中的一个新兴领域，旨在提高各种代码相关任务的有效性和效率。近期研究指出，除了基本的原始任务输入（即源代码）之外，融入上下文信息可以显著增强模型性能。这些上下文信号可以直接或间接从API文档、抽象语法树等源中获取，可以显著提高代码智能的有效性。尽管学术界对此产生了浓厚兴趣，但对于代码智能中的上下文分析仍然缺乏系统性研究。为填补这一空白，我们对2007年9月至2024年8月间发表的146篇相关研究进行了广泛的文献综述。我们的研究提供了四个主要贡献：（1）对研究格局的定量分析，包括出版趋势、发表平台和探索领域；（2）提出了一种代码智能中使用的上下文类型的新分类；（3）从不同代码智能任务出发，调查上下文集成策略；（4）对面向上下文的方法的评价方法进行批判性评估。基于这些发现，我们识别了当前代码智能系统中上下文利用的基本挑战，并提出了一条未来研究的关键机会研究路线图。', 'title_zh': '面向代码智能中的上下文利用理解'}
{'arxiv_id': 'arXiv:2504.08725', 'title': 'DocAgent: A Multi-Agent System for Automated Code Documentation Generation', 'authors': 'Dayu Yang, Antoine Simoulin, Xin Qian, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Grey Yang', 'link': 'https://arxiv.org/abs/2504.08725', 'abstract': 'High-quality code documentation is crucial for software development especially in the era of AI. However, generating it automatically using Large Language Models (LLMs) remains challenging, as existing approaches often produce incomplete, unhelpful, or factually incorrect outputs. We introduce DocAgent, a novel multi-agent collaborative system using topological code processing for incremental context building. Specialized agents (Reader, Searcher, Writer, Verifier, Orchestrator) then collaboratively generate documentation. We also propose a multi-faceted evaluation framework assessing Completeness, Helpfulness, and Truthfulness. Comprehensive experiments show DocAgent significantly outperforms baselines consistently. Our ablation study confirms the vital role of the topological processing order. DocAgent offers a robust approach for reliable code documentation generation in complex and proprietary repositories.', 'abstract_zh': '高质量的代码文档对于人工智能时代的软件开发至关重要。然而，使用大规模语言模型自动生成代码文档仍具有挑战性，因为现有方法常常产生不完整、无帮助或事实错误的输出。我们提出了DocAgent，这是一种使用拓扑代码处理进行增量上下文构建的新型多代理协作系统。专门的代理（_reader, _searcher, _writer, _verifier, _orchestrator）然后协作生成文档。我们还提出了一种多方面的评估框架，评估其完整性、有用性和真实性。全面的实验表明，DocAgent在基准上表现出显著的优势。我们的消融研究证明了拓扑处理顺序在其中的关键作用。DocAgent为复杂和专有代码库中的可靠代码文档生成提供了一种稳健的方法。', 'title_zh': 'DocAgent: 一种自动化代码文档生成的多agent系统'}
{'arxiv_id': 'arXiv:2504.08713', 'title': 'ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning', 'authors': 'Sahil Sethi, David Chen, Thomas Statchen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones', 'link': 'https://arxiv.org/abs/2504.08713', 'abstract': "Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasoning offers a more transparent alternative by grounding decisions in similarity to learned representations of real ECG segments, enabling faithful, case-based explanations. We introduce ProtoECGNet, a prototype-based deep learning model for interpretable, multi-label ECG classification. ProtoECGNet employs a structured, multi-branch architecture that reflects clinical interpretation workflows: it integrates a 1D CNN with global prototypes for rhythm classification, a 2D CNN with time-localized prototypes for morphology-based reasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each branch is trained with a prototype loss designed for multi-label learning, combining clustering, separation, diversity, and a novel contrastive loss that encourages appropriate separation between prototypes of unrelated classes while allowing clustering for frequently co-occurring diagnoses. We evaluate ProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating competitive performance relative to state-of-the-art black-box models while providing structured, case-based explanations. To assess prototype quality, we conduct a structured clinician review of the final model's projected prototypes, finding that they are rated as representative and clear. ProtoECGNet shows that prototype learning can be effectively scaled to complex, multi-label time-series classification, offering a practical path toward transparent and trustworthy deep learning models for clinical decision support.", 'abstract_zh': '基于深度学习的心电图（ECG）分类展示了令人印象深刻的性能，但Clinical应用受到缺乏透明和忠实解释的限制。基于原型的推理提供了更有透明度的替代方案，通过将决策与学习的实ECG段落表示的相似性联系起来，促进忠实的案例基础解释。我们引入ProtoECGNet，这是一种用于可解释的多标签ECG分类的基于原型的深度学习模型。ProtoECGNet采用反映临床解释工作流程的结构化多分支架构：它结合了用于节律分类的一维卷积神经网络（1D CNN）和全局原型、用于基于形态的推理的时间局地化原型的二维卷积神经网络（2D CNN）以及用于弥散异常的二维卷积神经网络（2D CNN）和全局原型。每个分支均使用为多标签学习设计的原型损失进行训练，结合聚类、分离、多样性以及一种新颖的对比损失，该损失鼓励不相关类原型之间的适当分离，并允许根据频繁共现的诊断进行聚类。我们在PTB-XL数据集的所有71个诊断标签上评估了ProtoECGNet，表明相对于最先进的黑盒模型具有竞争力的表现，同时提供结构化的案例基础解释。为了评估原型质量，我们对最终模型的投影原型进行结构化的临床审查，发现它们被评为代表性和清晰。ProtoECGNet表明，原型学习可以有效地扩展到复杂的多标签时间序列分类，为临床决策支持提供了一条实用的道路，朝着透明和可信赖的深度学习模型的方向发展。', 'title_zh': 'ProtoECGNet：基于案例的可解释深度学习在对比学习下的多标签心电图分类'}
{'arxiv_id': 'arXiv:2504.08687', 'title': 'Voice Interaction With Conversational AI Could Facilitate Thoughtful Reflection and Substantive Revision in Writing', 'authors': "Jiho Kim, Philippe Laban, Xiang 'Anthony' Chen, Kenneth C. Arnold", 'link': 'https://arxiv.org/abs/2504.08687', 'abstract': "Writing well requires not only expressing ideas but also refining them through revision, a process facilitated by reflection. Prior research suggests that feedback delivered through dialogues, such as those in writing center tutoring sessions, can help writers reflect more thoughtfully on their work compared to static feedback. Recent advancements in multi-modal large language models (LLMs) now offer new possibilities for supporting interactive and expressive voice-based reflection in writing. In particular, we propose that LLM-generated static feedback can be repurposed as conversation starters, allowing writers to seek clarification, request examples, and ask follow-up questions, thereby fostering deeper reflection on their writing. We argue that voice-based interaction can naturally facilitate this conversational exchange, encouraging writers' engagement with higher-order concerns, facilitating iterative refinement of their reflections, and reduce cognitive load compared to text-based interactions. To investigate these effects, we propose a formative study exploring how text vs. voice input influence writers' reflection and subsequent revisions. Findings from this study will inform the design of intelligent and interactive writing tools, offering insights into how voice-based interactions with LLM-powered conversational agents can support reflection and revision.", 'abstract_zh': '写作不仅需要表达想法，还需要通过修订加以精炼，这一过程可以通过反思得以促进。先前的研究表明，通过对话提供的反馈（如写作中心辅导 session 中的对话反馈）可以比静态反馈帮助作者更深入地反思自己的作品。近期多模态大语言模型（LLMs）的进步现在为支持基于语音的互动和表达性反思提供了新的可能性。特别是，我们建议 LLM 生成的静态反馈可以重新用于作为对话启动器，使作者能够寻求澄清、请求示例并提出后续问题，从而促进他们写作的更深层次反思。我们认为基于语音的互动能够自然地促进这种对话交换，鼓励作者与高层次关注点的更深层次互动，促进反思的迭代精炼，并且与基于文本的互动相比减轻认知负担。为了研究这些影响，我们提议进行一种形成性研究，探讨文本输入与语音输入如何影响作者的反思和后续修订。该研究的发现将为智能和互动写作工具的设计提供指导，揭示 LLM  powering 的对话代理基于语音的互动如何支持反思和修订的方法。', 'title_zh': '语音交互与对话式AI能够促进写作中的深入反思和实质性修订'}
{'arxiv_id': 'arXiv:2504.08670', 'title': 'Designing Child-Friendly AI Interfaces: Six Developmentally-Appropriate Design Insights from Analysing Disney Animation', 'authors': 'Nomisha Kurian', 'link': 'https://arxiv.org/abs/2504.08670', 'abstract': "To build AI interfaces that children can intuitively understand and use, designers need a design grammar that truly serves children's developmental needs. This paper bridges Artificial Intelligence design for children -- an emerging field still defining its best practices -- and children's animation, a well-established field with decades of experience in engaging young viewers through emotionally resonant, cognitively accessible storytelling. Pairing Piagetian developmental theory with design pattern extraction from 52 works of Disney animation, the paper presents six design insights transferable to child-centred AI interface design: (1) emotional expressiveness and visual clarity, (2) musical and auditory scaffolding, (3) audiovisual synchrony for emotional comfort, (4) sidekick-style personas, (5) support for symbolic play and imaginative exploration, and (6) predictable and scaffolded interaction structures. These strategies -- long refined in Disney animation -- function as multimodal scaffolds for attention, understanding, and emotional attunement, thereby forming a structured design grammar familiar to children and transferable to AI interface design. By reframing cinematic storytelling as design logic for AI, the paper offers heuristics for crafting intuitive AI interfaces that align with children's cognitive stages and emotional needs. The work contributes to design theory by showing how sensory, affective and narrative techniques can inform developmentally attuned AI design for children. Future directions include empirical testing, cultural adaptation, and participatory co-design.", 'abstract_zh': '构建儿童可直观理解并使用的AI界面，设计师需要一种真正服务于儿童发展需求的设计语法规则。本文将面向儿童的AI设计——这一新兴领域仍在界定其最佳实践——与已有数十年吸引年轻观众经验的儿童动画领域相连接，通过结合皮亚杰发展理论和从52部迪士尼动画作品中提取的设计模式，提出六条适用于儿童中心AI界面设计的见解：（1）情感表达和视觉清晰度，（2）音乐和音频支撑，（3）视听同步以提供情感安慰，（4）同伴式人物设定，（5）支持象征性游戏和想象性探索，（6）可预测且逐步引导的交互结构。这些策略作为多模态的支持工具，有助于吸引注意力、理解与情感共鸣，从而形成一种对儿童熟悉并可应用于AI界面设计的结构化设计语法规则。通过将影视叙事重新构想为AI设计逻辑，本文提供了与儿童认知阶段和情感需求相契合的直观AI界面设计的启发式规则。该工作通过展示感觉、情感和叙事技术如何指导与儿童发展相适应的AI设计，丰富了设计理论。未来的研究方向包括实证测试、文化适应和参与式协同设计。', 'title_zh': '设计儿童友好型AI界面：从分析迪士尼动画中获得的六项发展适宜设计启示'}
{'arxiv_id': 'arXiv:2504.08645', 'title': 'Title block detection and information extraction for enhanced building drawings search', 'authors': 'Alessio Lombardi, Li Duan, Ahmed Elnagar, Ahmed Zaalouk, Khalid Ismail, Edlira Vakaj', 'link': 'https://arxiv.org/abs/2504.08645', 'abstract': 'The architecture, engineering, and construction (AEC) industry still heavily relies on information stored in drawings for building construction, maintenance, compliance and error checks. However, information extraction (IE) from building drawings is often time-consuming and costly, especially when dealing with historical buildings. Drawing search can be simplified by leveraging the information stored in the title block portion of the drawing, which can be seen as drawing metadata. However, title block IE can be complex especially when dealing with historical drawings which do not follow existing standards for uniformity. This work performs a comparison of existing methods for this kind of IE task, and then proposes a novel title block detection and IE pipeline which outperforms existing methods, in particular when dealing with complex, noisy historical drawings. The pipeline is obtained by combining a lightweight Convolutional Neural Network and GPT-4o, the proposed inference pipeline detects building engineering title blocks with high accuracy, and then extract structured drawing metadata from the title blocks, which can be used for drawing search, filtering and grouping. The work demonstrates high accuracy and efficiency in IE for both vector (CAD) and hand-drawn (historical) drawings. A user interface (UI) that leverages the extracted metadata for drawing search is established and deployed on real projects, which demonstrates significant time savings. Additionally, an extensible domain-expert-annotated dataset for title block detection is developed, via an efficient AEC-friendly annotation workflow that lays the foundation for future work.', 'abstract_zh': 'AEC行业仍高度依赖图纸存储的信息进行建筑施工、维护、合规性和错误检查。然而，从建筑图纸中提取信息（IE）往往耗时且成本高，特别是在处理历史建筑时。通过利用图纸标题块中存储的信息可以简化图纸搜索，这些信息可被视为图纸的元数据。然而，处理不遵循统一标准的历史图纸时，标题块IE可能会变得复杂。本文对比了现有此类IE任务的方法，并提出了一种新颖的标题块检测和IE流水线，该流水线在处理复杂、嘈杂的历史图纸时表现优于现有方法。此流水线通过结合轻量级卷积神经网络和GPT-4o获得，提出的推理流水线能够以高精度检测建筑工程标题块，并从标题块中提取结构化的图纸元数据，用于图纸搜索、过滤和分组。该工作在矢量（CAD）和手绘（历史）图纸中均展示了高精度和高效性。基于提取的元数据开发了用户界面，已在实际项目中部署，展示了显著的时间节省。此外，通过高效的AEC友好注释工作流开发了一个可扩展的专业领域标注数据集，为未来的相关研究奠定了基础。', 'title_zh': '基于标题块检测与信息提取的增强建筑设计图检索'}
{'arxiv_id': 'arXiv:2504.08626', 'title': 'Task-conditioned Ensemble of Expert Models for Continuous Learning', 'authors': 'Renu Sharma, Debasmita Pal, Arun Ross', 'link': 'https://arxiv.org/abs/2504.08626', 'abstract': 'One of the major challenges in machine learning is maintaining the accuracy of the deployed model (e.g., a classifier) in a non-stationary environment. The non-stationary environment results in distribution shifts and, consequently, a degradation in accuracy. Continuous learning of the deployed model with new data could be one remedy. However, the question arises as to how we should update the model with new training data so that it retains its accuracy on the old data while adapting to the new data. In this work, we propose a task-conditioned ensemble of models to maintain the performance of the existing model. The method involves an ensemble of expert models based on task membership information. The in-domain models-based on the local outlier concept (different from the expert models) provide task membership information dynamically at run-time to each probe sample. To evaluate the proposed method, we experiment with three setups: the first represents distribution shift between tasks (LivDet-Iris-2017), the second represents distribution shift both between and within tasks (LivDet-Iris-2020), and the third represents disjoint distribution between tasks (Split MNIST). The experiments highlight the benefits of the proposed method. The source code is available at this https URL.', 'abstract_zh': '机器学习中维护部署模型准确性的一个主要挑战是在非平稳环境中保持模型的准确性（例如，分类器）。非平稳环境导致分布变化，并随之降低准确性。通过新数据对部署模型进行连续学习可能是解决这一问题的一种方法。然而，一个关键问题是，我们应该如何利用新的训练数据更新模型，使其在保留旧数据准确性的同时适应新数据。在本工作中，我们提出了一种基于任务条件的模型集成方法，以维护现有模型的性能。该方法基于任务归属信息，包含专家模型和基于领域内局部异常的概念的模型。基于任务归属信息（不同于专家模型），领域内模型在运行时为每个探查样本动态提供任务归属信息。为了评估所提出的方法，我们在三种设置下进行了实验：第一种表示任务之间分布变化（LivDet-Iris-2017），第二种表示任务之间和任务内部分布变化（LivDet-Iris-2020），第三种表示任务之间不相交分布（Split MNIST）。实验突显了所提出方法的优势。源代码可在以下网址获取。', 'title_zh': '任务条件下的专家模型ensemble连续学习'}
{'arxiv_id': 'arXiv:2504.08623', 'title': 'Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies', 'authors': 'Vineeth Sai Narajala, Idan Habler', 'link': 'https://arxiv.org/abs/2504.08623', 'abstract': 'The Model Context Protocol (MCP), introduced by Anthropic, provides a standardized framework for artificial intelligence (AI) systems to interact with external data sources and tools in real-time. While MCP offers significant advantages for AI integration and capability extension, it introduces novel security challenges that demand rigorous analysis and mitigation. This paper builds upon foundational research into MCP architecture and preliminary security assessments to deliver enterprise-grade mitigation frameworks and detailed technical implementation strategies. Through systematic threat modeling and analysis of MCP implementations and analysis of potential attack vectors, including sophisticated threats like tool poisoning, we present actionable security patterns tailored for MCP implementers and adopters. The primary contribution of this research lies in translating theoretical security concerns into a practical, implementable framework with actionable controls, thereby providing essential guidance for the secure enterprise adoption and governance of integrated AI systems.', 'abstract_zh': 'Anthropic 提出的 Model Context Protocol (MCP) 提供了一种标准化框架，使人工智能（AI）系统能够实时与外部数据源和工具进行交互。尽管 MCP 为 AI 集成和能力扩展带来了显著优势，但也引入了新的安全挑战，需要进行严格的分析和缓解。本文基于 MCP 架构的基础研究和初步安全评估，提供企业级的安全缓解框架和详细的实施策略。通过系统性的威胁建模和 MCP 实施分析，包括高级威胁如工具投毒，我们提出了适用于 MCP 实施者和采用者的可操作性安全模式。本文的主要贡献在于将理论安全关注点转化为可操作且可实施的安全框架，从而为集成 AI 系统的可靠企业采用和治理提供必要的指导。', 'title_zh': '企业级安全模型上下文协议（MCP）框架与缓解策略'}
{'arxiv_id': 'arXiv:2504.08609', 'title': 'A Survey of Machine Learning Models and Datasets for the Multi-label Classification of Textual Hate Speech in English', 'authors': 'Julian Bäumler, Louis Blöcher, Lars-Joel Frey, Xian Chen, Markus Bayer, Christian Reuter', 'link': 'https://arxiv.org/abs/2504.08609', 'abstract': "The dissemination of online hate speech can have serious negative consequences for individuals, online communities, and entire societies. This and the large volume of hateful online content prompted both practitioners', i.e., in content moderation or law enforcement, and researchers' interest in machine learning models to automatically classify instances of hate speech. Whereas most scientific works address hate speech classification as a binary task, practice often requires a differentiation into sub-types, e.g., according to target, severity, or legality, which may overlap for individual content. Hence, researchers created datasets and machine learning models that approach hate speech classification in textual data as a multi-label problem. This work presents the first systematic and comprehensive survey of scientific literature on this emerging research landscape in English (N=46). We contribute with a concise overview of 28 datasets suited for training multi-label classification models that reveals significant heterogeneity regarding label-set, size, meta-concept, annotation process, and inter-annotator agreement. Our analysis of 24 publications proposing suitable classification models further establishes inconsistency in evaluation and a preference for architectures based on Bidirectional Encoder Representation from Transformers (BERT) and Recurrent Neural Networks (RNNs). We identify imbalanced training data, reliance on crowdsourcing platforms, small and sparse datasets, and missing methodological alignment as critical open issues and formulate ten recommendations for research.", 'abstract_zh': '在线仇恨言论的传播可能对个人、在线社区和整个社会产生严重的负面影响。这一现象以及大量的仇恨在线内容促使内容审核从业者和研究人员对机器学习模型的兴趣，这些模型能够自动对仇恨言论进行分类。虽然大多数科学研究将仇恨言论分类视为一个二元任务，但实践中经常需要对不同类型进行区分，例如根据目标、严重程度或合法性进行分类，这些分类可能在个别内容上有所重叠。因此，研究人员创建了适用于训练多标签分类模型的数据集和机器学习模型。本文呈现了对该新兴研究领域的第一次系统性和综合性的英文文献综述（N=46）。我们提供了一个简洁的数据集概述，涵盖了28个适用于训练多标签分类模型的数据集，并揭示了关于标签集、规模、元概念、标注过程和注释者间一致性方面的显著异质性。我们对24篇提出合适分类模型的出版物的分析进一步确立了评估的不一致性，并倾向于使用双向Transformer编码表示（BERT）和循环神经网络（RNN）的架构。我们确定了训练数据的不平衡、对众包平台的依赖、数据集规模小和稀疏、以及缺乏方法学一致性作为关键的开放问题，并提出了十项研究建议。', 'title_zh': '英文多标签分类中基于文本的仇恨言论的机器学习模型与数据集综述'}
{'arxiv_id': 'arXiv:2504.08596', 'title': 'MedHal: An Evaluation Dataset for Medical Hallucination Detection', 'authors': 'Gaya Mehenni, Amal Zouaq', 'link': 'https://arxiv.org/abs/2504.08596', 'abstract': "We present MedHal, a novel large-scale dataset specifically designed to evaluate if models can detect hallucinations in medical texts. Current hallucination detection methods face significant limitations when applied to specialized domains like medicine, where they can have disastrous consequences. Existing medical datasets are either too small, containing only a few hundred samples, or focus on a single task like Question Answering or Natural Language Inference. MedHal addresses these gaps by: (1) incorporating diverse medical text sources and tasks; (2) providing a substantial volume of annotated samples suitable for training medical hallucination detection models; and (3) including explanations for factual inconsistencies to guide model learning. We demonstrate MedHal's utility by training and evaluating a baseline medical hallucination detection model, showing improvements over general-purpose hallucination detection approaches. This resource enables more efficient evaluation of medical text generation systems while reducing reliance on costly expert review, potentially accelerating the development of medical AI research.", 'abstract_zh': 'MedHal：一种用于评估模型在医学文本中检测幻觉能力的新颖大规模数据集', 'title_zh': 'MedHal: 医学幻觉检测评价数据集'}
{'arxiv_id': 'arXiv:2504.08584', 'title': 'Boosting multi-demographic federated learning for chest x-ray analysis using general-purpose self-supervised representations', 'authors': 'Mahshad Lotfinia, Arash Tayebiarasteh, Samaneh Samiei, Mehdi Joodaki, Soroosh Tayebi Arasteh', 'link': 'https://arxiv.org/abs/2504.08584', 'abstract': 'Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.', 'abstract_zh': '可靠的人工智能模型在医学图像分析中往往依赖于大规模和多样性的标注数据集。联邦学习（FL）提供了一种去中心化和保护隐私的训练方法，但在高度非独立和非同分布（non-IID）的环境中表现较差，其中具有代表性数据的机构可能会遭受性能下降。此外，现有的大规模FL研究主要局限于成人数据集，忽视了儿科数据带来的独特挑战，这引入了额外的非IID变异性。为解决这些局限性，我们分析了来自多个国家的398,523张成人胸部X光片和9,125张儿科图像，利用通用自监督图像表示进行迁移学习，对肺炎和无异常情况进行分类。使用最先进的视觉变压器，我们发现FL仅对较小的成人数据集提高了性能（P<0.001），但对较大的数据集和儿科病例的性能有所下降（P<0.064和P=0.242）。然而，装备FL以使用自监督权重显著提高了儿科病例（P=0.031）和大多数成人数据集（P<0.008）的结果，尽管对最大的数据集（P=0.052）未见显著改善。这些发现强调了通用自监督图像表示在临床FL应用中解决非IID挑战的潜力，并突显了其在提高患者结果和推动儿科医疗保健方面减轻数据稀缺和变异性障碍的前景。', 'title_zh': '使用通用自监督表示增强多人口联邦学习的胸腔X光分析'}
{'arxiv_id': 'arXiv:2504.08553', 'title': 'Uncovering the Structure of Explanation Quality with Spectral Analysis', 'authors': 'Johannes Maeß, Grégoire Montavon, Shinichi Nakajima, Klaus-Robert Müller, Thomas Schnake', 'link': 'https://arxiv.org/abs/2504.08553', 'abstract': 'As machine learning models are increasingly considered for high-stakes domains, effective explanation methods are crucial to ensure that their prediction strategies are transparent to the user. Over the years, numerous metrics have been proposed to assess quality of explanations. However, their practical applicability remains unclear, in particular due to a limited understanding of which specific aspects each metric rewards. In this paper we propose a new framework based on spectral analysis of explanation outcomes to systematically capture the multifaceted properties of different explanation techniques. Our analysis uncovers two distinct factors of explanation quality-stability and target sensitivity-that can be directly observed through spectral decomposition. Experiments on both MNIST and ImageNet show that popular evaluation techniques (e.g., pixel-flipping, entropy) partially capture the trade-offs between these factors. Overall, our framework provides a foundational basis for understanding explanation quality, guiding the development of more reliable techniques for evaluating explanations.', 'abstract_zh': '随着机器学习模型在高风险领域中的应用越来越广泛，有效的解释方法对于确保其预测策略对用户透明至关重要。多年来，已经提出了诸多评估解释质量的指标，但这些指标的实际适用性仍然不明确，特别是由于我们对各项指标奖励的具体方面缺乏充分的理解。在本文中，我们提出了一种基于解释结果的谱分析的新框架，以系统地捕捉不同解释技术的多方面特性。我们的分析揭示了解释质量的两个不同因素：稳定性和目标敏感性，这些因素可以通过谱分解直接观察到。在MNIST和ImageNet数据集上的实验表明，流行的评估技术（例如，像素翻转、熵）部分地捕捉到了这些因素之间的权衡。总体而言，本文框架为理解解释质量奠定了基础，并指导了更可靠解释评估技术的发展。', 'title_zh': '解释质量的结构发现基于谱分析'}
{'arxiv_id': 'arXiv:2504.08550', 'title': 'Proxy-Anchor and EVT-Driven Continual Learning Method for Generalized Category Discovery', 'authors': 'Alireza Fathalizadeh, Roozbeh Razavi-Far', 'link': 'https://arxiv.org/abs/2504.08550', 'abstract': "Continual generalized category discovery has been introduced and studied in the literature as a method that aims to continuously discover and learn novel categories in incoming data batches while avoiding catastrophic forgetting of previously learned categories. A key component in addressing this challenge is the model's ability to separate novel samples, where Extreme Value Theory (EVT) has been effectively employed. In this work, we propose a novel method that integrates EVT with proxy anchors to define boundaries around proxies using a probability of inclusion function, enabling the rejection of unknown samples. Additionally, we introduce a novel EVT-based loss function to enhance the learned representation, achieving superior performance compared to other deep-metric learning methods in similar settings. Using the derived probability functions, novel samples are effectively separated from previously known categories. However, category discovery within these novel samples can sometimes overestimate the number of new categories. To mitigate this issue, we propose a novel EVT-based approach to reduce the model size and discard redundant proxies. We also incorporate experience replay and knowledge distillation mechanisms during the continual learning stage to prevent catastrophic forgetting. Experimental results demonstrate that our proposed approach outperforms state-of-the-art methods in continual generalized category discovery scenarios.", 'abstract_zh': '连续广义类别发现已被文献引入并研究作为一种方法，旨在在不断发现和学习新类别同时避免遗忘之前学习类别的灾难性遗忘。解决这一挑战的关键在于模型区分新型样本的能力，极值理论（EVT）已被有效应用于这一领域。在本工作中，我们提出了一种将EVT与代理锚点相结合的新方法，使用包含概率函数定义代理的边界，从而排斥未知样本。此外，我们引入了一种基于EVT的损失函数来增强学习表示，相比其他深度度量学习方法，在类似设置中取得了更优性能。通过衍生的概率函数，新型样本能够有效与已知类别分开。然而，对这些新型样本中的类别发现有时会高估新类别的数量。为缓解这一问题，我们提出了一种基于EVT的方法来减小模型大小并丢弃冗余代理。此外，在连续学习阶段，我们还引入了经验重放和知识蒸馏机制以防止灾难性遗忘。实验结果表明，在连续广义类别发现场景中，我们提出的方法优于现有最先进的方法。', 'title_zh': '代理锚点和 EVT 驱动的持续学习方法用于泛化类别发现'}
{'arxiv_id': 'arXiv:2504.08536', 'title': 'Explainability and Continual Learning meet Federated Learning at the Network Edge', 'authors': 'Thomas Tsouparopoulos, Iordanis Koutsopoulos', 'link': 'https://arxiv.org/abs/2504.08536', 'abstract': 'As edge devices become more capable and pervasive in wireless networks, there is growing interest in leveraging their collective compute power for distributed learning. However, optimizing learning at the network edge entails unique challenges, particularly when moving beyond conventional settings and objectives. While Federated Learning (FL) has emerged as a key paradigm for distributed model training, critical challenges persist. First, existing approaches often overlook the trade-off between predictive accuracy and interpretability. Second, they struggle to integrate inherently explainable models such as decision trees because their non-differentiable structure makes them not amenable to backpropagation-based training algorithms. Lastly, they lack meaningful mechanisms for continual Machine Learning (ML) model adaptation through Continual Learning (CL) in resource-limited environments. In this paper, we pave the way for a set of novel optimization problems that emerge in distributed learning at the network edge with wirelessly interconnected edge devices, and we identify key challenges and future directions. Specifically, we discuss how Multi-objective optimization (MOO) can be used to address the trade-off between predictive accuracy and explainability when using complex predictive models. Next, we discuss the implications of integrating inherently explainable tree-based models into distributed learning settings. Finally, we investigate how CL strategies can be effectively combined with FL to support adaptive, lifelong learning when limited-size buffers are used to store past data for retraining. Our approach offers a cohesive set of tools for designing privacy-preserving, adaptive, and trustworthy ML solutions tailored to the demands of edge computing and intelligent services.', 'abstract_zh': '随着无线网络中边缘设备的能力不断增强和普及，人们越来越关注利用其集体计算能力进行分布式学习。然而，在网络边缘优化学习带来了独特的挑战，尤其是在超越传统环境和目标时。尽管联邦学习（FL）已成为分布式模型训练的关键范式，但仍存在关键挑战。首先，现有方法往往忽视了预测准确性和解释性之间的权衡。其次，它们难以整合如决策树等固有的可解释模型，因为它们的非可微结构使得它们不适用于基于反向传播的训练算法。最后，它们缺乏有效的机制通过连续学习（CL）在资源受限的环境中对机器学习（ML）模型进行持续适应。在本文中，我们探讨了在网络边缘由无线互联的边缘设备进行分布式学习时出现的一系列新颖优化问题，并指出了关键挑战和未来方向。具体而言，我们讨论了多目标优化（MOO）如何用于解决在使用复杂预测模型时预测准确性和解释性之间的权衡。接下来，我们探讨了如何将固有的可解释树模型整合到分布式学习环境中。最后，我们研究了如何结合连续学习（CL）策略与联邦学习（FL），在仅使用有限大小的缓存存储过往数据以进行重新训练时，支持适应性和终身学习。我们的方法提供了一套综合工具，用于为边缘计算和智能服务的需求设计隐私保护、适应性和可信赖的机器学习解决方案。', 'title_zh': '网络边缘处的可解释性和持续学习与联邦学习的结合'}
{'arxiv_id': 'arXiv:2504.08530', 'title': 'LGRPool: Hierarchical Graph Pooling Via Local-Global Regularisation', 'authors': 'Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal', 'link': 'https://arxiv.org/abs/2504.08530', 'abstract': 'Hierarchical graph pooling(HGP) are designed to consider the fact that conventional graph neural networks(GNN) are inherently flat and are also not multiscale. However, most HGP methods suffer not only from lack of considering global topology of the graph and focusing on the feature learning aspect, but also they do not align local and global features since graphs should inherently be analyzed in a multiscale way. LGRPool is proposed in the present paper as a HGP in the framework of expectation maximization in machine learning that aligns local and global aspects of message passing with each other using a regularizer to force the global topological information to be inline with the local message passing at different scales through the representations at different layers of HGP. Experimental results on some graph classification benchmarks show that it slightly outperforms some baselines.', 'abstract_zh': '基于期望最大化的层次图池化方法：LGRPool', 'title_zh': 'LGRPool：基于局部-全局正则化的分层图池化'}
{'arxiv_id': 'arXiv:2504.08524', 'title': 'Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion', 'authors': 'Na Li, Chuke Wang, Yu Gu, Zhifeng Li', 'link': 'https://arxiv.org/abs/2504.08524', 'abstract': 'Voice conversion (VC) transforms source speech into a target voice by preserving the content. However, timbre information from the source speaker is inherently embedded in the content representations, causing significant timbre leakage and reducing similarity to the target speaker. To address this, we introduce a residual block to a content extractor. The residual block consists of two weighted branches: 1) universal semantic dictionary based Content Feature Re-expression (CFR) module, supplying timbre-free content representation. 2) skip connection to the original content layer, providing complementary fine-grained information. In the CFR module, each dictionary entry in the universal semantic dictionary represents a phoneme class, computed statistically using speech from multiple speakers, creating a stable, speaker-independent semantic set. We introduce a CFR method to obtain timbre-free content representations by expressing each content frame as a weighted linear combination of dictionary entries using corresponding phoneme posteriors as weights. Extensive experiments across various VC frameworks demonstrate that our approach effectively mitigates timbre leakage and significantly improves similarity to the target speaker.', 'abstract_zh': 'Voice转换（VC）通过保留内容将源语音转换为目标声音，但由于声韵信息会固有地嵌入内容表示中，从而导致显著的声韵泄漏，降低与目标说话人的相似度。为解决这一问题，我们将在内容提取器中引入一个残差块。该残差块包括两个加权支路：1) 基于通用语义词典的内容特征重表达（CFR）模块，提供无声韵的内容表示。2) 与原始内容层的跳跃连接，提供补充的细粒度信息。在CFR模块中，通用语义词典中的每个字典条目代表一个音素类别，通过多说话人口头语言的统计计算获得，形成一个稳定且说话人无关的语义集。我们提出了一种CFR方法，通过使用相应的音素后验概率作为权重，将每个内容帧表示为字典条目的加权线性组合，从而获得无声韵的内容表示。在各种VC框架上的广泛实验表明，我们的方法有效地减轻了声韵泄漏，显著提高了与目标说话人的相似度。', 'title_zh': '基于通用语义映射残差块的timbre泄漏减轻语音转换方法'}
{'arxiv_id': 'arXiv:2504.08470', 'title': 'On the Design of Diffusion-based Neural Speech Codecs', 'authors': 'Pietro Foti, Andreas Brendel', 'link': 'https://arxiv.org/abs/2504.08470', 'abstract': 'Recently, neural speech codecs (NSCs) trained as generative models have shown superior performance compared to conventional codecs at low bitrates. Although most state-of-the-art NSCs are trained as Generative Adversarial Networks (GANs), Diffusion Models (DMs), a recent class of generative models, represent a promising alternative due to their superior performance in image generation relative to GANs. Consequently, DMs have been successfully applied for audio and speech coding among various other audio generation applications. However, the design of diffusion-based NSCs has not yet been explored in a systematic way. We address this by providing a comprehensive analysis of diffusion-based NSCs divided into three contributions. First, we propose a categorization based on the conditioning and output domains of the DM. This simple conceptual framework allows us to define a design space for diffusion-based NSCs and to assign a category to existing approaches in the literature. Second, we systematically investigate unexplored designs by creating and evaluating new diffusion-based NSCs within the conceptual framework. Finally, we compare the proposed models to existing GAN and DM baselines through objective metrics and subjective listening tests.', 'abstract_zh': 'Recently, 基于扩散模型的神经语音编码器在低比特率下的性能优于传统语音编解码器。尽管大多数最先进的基于扩散模型的神经语音编码器（NSCs）被训练为生成对抗网络（GANs），但由于在图像生成方面的优越性能，近年来的生成模型——扩散模型（DMs）提供了一种有前途的替代方案。因此，DMs已在各种其他音频生成应用中成功应用于语音编码。然而，基于扩散模型的NSCs的设计尚未以系统的方式进行探索。我们通过提供一个基于扩散模型的NSCs的全面分析来解决这个问题，并将其分为三个贡献。首先，我们根据DM的条件域和输出域提出了一种分类方法。这一简单的概念框架使我们能够定义基于扩散模型的NSCs的设计空间，并将文献中现有的方法归类。其次，我们系统地探索了未被广泛研究的设计，通过概念框架创建并评估了新的基于扩散模型的NSCs。最后，我们通过客观指标和主观听觉测试将所提出的模型与现有的GAN和DM基线进行比较。', 'title_zh': '基于扩散机制的神经语音编解码器设计'}
{'arxiv_id': 'arXiv:2504.08456', 'title': 'Generalization Bounds in Hybrid Quantum-Classical Machine Learning Models', 'authors': 'Tongyan Wu, Amine Bentellis, Alona Sakhnenko, Jeanette Miriam Lorenz', 'link': 'https://arxiv.org/abs/2504.08456', 'abstract': 'Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight into how these systems learn from data. We establish a novel generalization bound of the form $O\\big( \\sqrt{\\frac{T\\log{T}}{N}} + \\frac{\\alpha}{\\sqrt{N}}\\big)$ for $N$ training data points, $T$ trainable quantum gates, and bounded fully-connected layers $||F|| \\leq \\alpha$. This bound decomposes cleanly into quantum and classical contributions, extending prior work on both components and clarifying their interaction. We apply our results to the quantum-classical convolutional neural network (QCCNN), an architecture that integrates quantum convolutional layers with classical processing. Alongside the bound, we highlight conceptual limitations of applying classical statistical learning theory in the hybrid setting and suggest promising directions for future theoretical work.', 'abstract_zh': '混合经典-量子模型旨在结合量子计算和经典机器学习的优势，但其实际潜力尚不完全理解。在本工作中，我们开发了一个统一的数学框架，用于分析混合模型的一般化能力，提供了关于这些系统如何从数据中学习的洞察。我们建立了形式为 $O\\big( \\sqrt{\\frac{T\\log{T}}{N}} + \\frac{\\alpha}{\\sqrt{N}}\\big)$ 的一般化界，适用于 $N$ 个训练数据点、$T$ 个可训练量子门和范数受限的全连接层 $||F|| \\leq \\alpha$。该界清楚地分解为量子和经典成分，扩展了两者的工作并澄清了它们的相互作用。我们应用我们的结果到结合了量子卷积层和经典处理的量子-经典卷积神经网络 (QCCNN) 架构。除了界之外，我们还指出了在混合设置中应用经典统计学习理论的概念限制，并建议了未来理论工作的前景方向。', 'title_zh': '混合量子-经典机器学习模型的泛化误差界'}
{'arxiv_id': 'arXiv:2504.08418', 'title': 'seeBias: A Comprehensive Tool for Assessing and Visualizing AI Fairness', 'authors': 'Yilin Ning, Yian Ma, Mingxuan Liu, Xin Li, Nan Liu', 'link': 'https://arxiv.org/abs/2504.08418', 'abstract': 'Fairness in artificial intelligence (AI) prediction models is increasingly emphasized to support responsible adoption in high-stakes domains such as health care and criminal justice. Guidelines and implementation frameworks highlight the importance of both predictive accuracy and equitable outcomes. However, current fairness toolkits often evaluate classification performance disparities in isolation, with limited attention to other critical aspects such as calibration. To address these gaps, we present seeBias, an R package for comprehensive evaluation of model fairness and predictive performance. seeBias offers an integrated evaluation across classification, calibration, and other performance domains, providing a more complete view of model behavior. It includes customizable visualizations to support transparent reporting and responsible AI implementation. Using public datasets from criminal justice and healthcare, we demonstrate how seeBias supports fairness evaluations, and uncovers disparities that conventional fairness metrics may overlook. The R package is available on GitHub, and a Python version is under development.', 'abstract_zh': '人工智能（AI）预测模型的公平性在高风险领域如医疗保健和刑事司法中受到越来越多的关注，以支持负责任的采用。指南和实施框架强调预测准确性和公平结果的重要性。然而，当前的公平性工具包往往孤立地评估分类性能差异，对校准等其他关键方面关注不足。为解决这些差距，我们介绍了seeBias，一个用于全面评估模型公平性和预测性能的R包。seeBias提供跨分类、校准和其他性能领域的综合评估，提供了模型行为的更完整视图。它包括可定制的可视化功能，以支持透明报告和负责任的AI实施。使用来自刑事司法和医疗保健的公共数据集，我们展示了seeBias如何支持公平性评估，并揭示了常规公平性指标可能忽略的差异。R包可在GitHub上获取，Python版本正在开发中。', 'title_zh': 'seeBias: 一个全面的工具，用于评估和可视化AI公平性'}
{'arxiv_id': 'arXiv:2504.08415', 'title': 'Constrained Machine Learning Through Hyperspherical Representation', 'authors': 'Gaetano Signorelli, Michele Lombardi', 'link': 'https://arxiv.org/abs/2504.08415', 'abstract': 'The problem of ensuring constraints satisfaction on the output of machine learning models is critical for many applications, especially in safety-critical domains. Modern approaches rely on penalty-based methods at training time, which do not guarantee to avoid constraints violations; or constraint-specific model architectures (e.g., for monotonocity); or on output projection, which requires to solve an optimization problem that might be computationally demanding. We present the Hypersherical Constrained Representation, a novel method to enforce constraints in the output space for convex and bounded feasibility regions (generalizable to star domains). Our method operates on a different representation system, where Euclidean coordinates are converted into hyperspherical coordinates relative to the constrained region, which can only inherently represent feasible points. Experiments on a synthetic and a real-world dataset show that our method has predictive performance comparable to the other approaches, can guarantee 100% constraint satisfaction, and has a minimal computational cost at inference time.', 'abstract_zh': '确保机器学习模型输出满足约束的问题在许多应用中至关重要，特别是在安全关键领域。我们提出了超球面约束表示法，这是一种在凸且有界可行域（可推广到星域）中强制约束的新方法。该方法在一种不同的表示系统中运行，将欧clidean坐标转换为相对于约束区域的超球面坐标，这种表示法只能固有地表示可行点。实验结果表明，该方法在预测性能上与其它方法相当，能确保100%的约束满足，并且在推理时具有最小的计算成本。', 'title_zh': '通过超球面表示实现约束机器学习'}
{'arxiv_id': 'arXiv:2504.08385', 'title': 'Scholar Inbox: Personalized Paper Recommendations for Scientists', 'authors': 'Markus Flicke, Glenn Angrabeit, Madhav Iyengar, Vitalii Protsenko, Illia Shakun, Jovan Cicvaric, Bora Kargi, Haoyu He, Lukas Schuler, Lewin Scholz, Kavyanjali Agnihotri, Yong Cao, Andreas Geiger', 'link': 'https://arxiv.org/abs/2504.08385', 'abstract': "Scholar Inbox is a new open-access platform designed to address the challenges researchers face in staying current with the rapidly expanding volume of scientific literature. We provide personalized recommendations, continuous updates from open-access archives (arXiv, bioRxiv, etc.), visual paper summaries, semantic search, and a range of tools to streamline research workflows and promote open research access. The platform's personalized recommendation system is trained on user ratings, ensuring that recommendations are tailored to individual researchers' interests. To further enhance the user experience, Scholar Inbox also offers a map of science that provides an overview of research across domains, enabling users to easily explore specific topics. We use this map to address the cold start problem common in recommender systems, as well as an active learning strategy that iteratively prompts users to rate a selection of papers, allowing the system to learn user preferences quickly. We evaluate the quality of our recommendation system on a novel dataset of 800k user ratings, which we make publicly available, as well as via an extensive user study. this https URL", 'abstract_zh': '学者收件箱是一个新的开放获取平台，旨在解决研究人员在面对 rapidly expanding volume of scientific literature 时保持研究前沿所面临的挑战。我们提供个性化推荐、来自开放获取档案（arXiv、bioRxiv等）的持续更新、可视化论文摘要、语义搜索以及一系列工具来优化研究工作流程和促进开放研究访问。该平台的个性化推荐系统基于用户评分进行训练，确保推荐内容符合不同研究人员的兴趣。为了进一步提升用户体验，学者收件箱还提供了一幅科学地图，提供了跨领域研究概览，使用户能够轻松探索特定主题。我们利用这幅地图来解决推荐系统中常见的冷启动问题，并采用主动学习策略，逐步提示用户对其所选论文进行评分，从而使系统能够快速了解用户偏好。我们使用一个包含80万用户评分的新颖数据集评估了推荐系统的质量，并已将该数据集公开，还通过广泛的用户研究进行了评估。更多的信息请参见：this https URL。', 'title_zh': '学者收件箱：面向科学家的个性化论文推荐'}
{'arxiv_id': 'arXiv:2504.08371', 'title': 'Passive Underwater Acoustic Signal Separation based on Feature Decoupling Dual-path Network', 'authors': 'Yucheng Liu, Longyu Jiang', 'link': 'https://arxiv.org/abs/2504.08371', 'abstract': "Signal separation in the passive underwater acoustic domain has heavily relied on deep learning techniques to isolate ship radiated noise. However, the separation networks commonly used in this domain stem from speech separation applications and may not fully consider the unique aspects of underwater acoustics beforehand, such as the influence of different propagation media, signal frequencies and modulation characteristics. This oversight highlights the need for tailored approaches that account for the specific characteristics of underwater sound propagation. This study introduces a novel temporal network designed to separate ship radiated noise by employing a dual-path model and a feature decoupling approach. The mixed signals' features are transformed into a space where they exhibit greater independence, with each dimension's significance decoupled. Subsequently, a fusion of local and global attention mechanisms is employed in the separation layer. Extensive comparisons showcase the effectiveness of this method when compared to other prevalent network models, as evidenced by its performance in the ShipsEar and DeepShip datasets.", 'abstract_zh': '基于深度学习的被动水下声学信号分离方法在船舶辐射噪声隔离中的应用：一种考虑水下声学特性的新型时域网络', 'title_zh': '基于特征解耦双路径网络的被动水下声信号分离'}
{'arxiv_id': 'arXiv:2504.08359', 'title': 'Kernel-Level Energy-Efficient Neural Architecture Search for Tabular Dataset', 'authors': 'Hoang-Loc La, Phuong Hoai Ha', 'link': 'https://arxiv.org/abs/2504.08359', 'abstract': 'Many studies estimate energy consumption using proxy metrics like memory usage, FLOPs, and inference latency, with the assumption that reducing these metrics will also lower energy consumption in neural networks. This paper, however, takes a different approach by introducing an energy-efficient Neural Architecture Search (NAS) method that directly focuses on identifying architectures that minimize energy consumption while maintaining acceptable accuracy. Unlike previous methods that primarily target vision and language tasks, the approach proposed here specifically addresses tabular datasets. Remarkably, the optimal architecture suggested by this method can reduce energy consumption by up to 92% compared to architectures recommended by conventional NAS.', 'abstract_zh': '一种直接针对最小化能量消耗的节能神经架构搜索方法：以表格数据集为例', 'title_zh': '内核级能源高效神经架构搜索用于表格数据集'}
{'arxiv_id': 'arXiv:2504.08335', 'title': 'Entropic bounds for conditionally Gaussian vectors and applications to neural networks', 'authors': 'Lucia Celli, Giovanni Peccati', 'link': 'https://arxiv.org/abs/2504.08335', 'abstract': 'Using entropic inequalities from information theory, we provide new bounds on the total variation and 2-Wasserstein distances between a conditionally Gaussian law and a Gaussian law with invertible covariance matrix. We apply our results to quantify the speed of convergence to Gaussian of a randomly initialized fully connected neural network and its derivatives - evaluated in a finite number of inputs - when the initialization is Gaussian and the sizes of the inner layers diverge to infinity. Our results require mild assumptions on the activation function, and allow one to recover optimal rates of convergence in a variety of distances, thus improving and extending the findings of Basteri and Trevisan (2023), Favaro et al. (2023), Trevisan (2024) and Apollonio et al. (2024). One of our main tools are the quantitative cumulant estimates established in Hanin (2024). As an illustration, we apply our results to bound the total variation distance between the Bayesian posterior law of the neural network and its derivatives, and the posterior law of the corresponding Gaussian limit: this yields quantitative versions of a posterior CLT by Hron et al. (2022), and extends several estimates by Trevisan (2024) to the total variation metric.', 'abstract_zh': '利用信息论中的熵不等式，我们提供了条件高斯分布与具有可逆协方差矩阵的高斯分布之间的总变差和2- Wasserstein距离的新界线。我们将结果应用于量化随机初始化的全连接神经网络及其在有限输入点上的导数在初始化为高斯分布且内部层尺寸趋于无穷大时向高斯分布的收敛速度。我们的结果仅对激活函数有轻微的假设，并允许我们在多种距离上恢复最优的收敛率，从而改进并拓展了Basteri和Trevisan（2023）、Favaro等人（2023）、Trevisan（2024）和Apollonio等人（2024）的研究发现。我们主要工具之一是Hanin（2024）建立的量化累积量估计。作为示例，我们将结果应用于界定制神经网络及其导数的贝叶斯后验分布与对应的高斯极限后验分布之间的总变差距离，从而得到了Hron等人（2022）后验中心极限定理的量化版本，并将Trevisan（2024）的某些估计拓展到总变差度量。', 'title_zh': '熵界条件高斯向量及其在神经网络中的应用'}
{'arxiv_id': 'arXiv:2504.08259', 'title': 'CoProSketch: Controllable and Progressive Sketch Generation with Diffusion Model', 'authors': 'Ruohao Zhan, Yijin Li, Yisheng He, Shuo Chen, Yichen Shen, Xinyu Chen, Zilong Dong, Zhaoyang Huang, Guofeng Zhang', 'link': 'https://arxiv.org/abs/2504.08259', 'abstract': 'Sketches serve as fundamental blueprints in artistic creation because sketch editing is easier and more intuitive than pixel-level RGB image editing for painting artists, yet sketch generation remains unexplored despite advancements in generative models. We propose a novel framework CoProSketch, providing prominent controllability and details for sketch generation with diffusion models. A straightforward method is fine-tuning a pretrained image generation diffusion model with binarized sketch images. However, we find that the diffusion models fail to generate clear binary images, which makes the produced sketches chaotic. We thus propose to represent the sketches by unsigned distance field (UDF), which is continuous and can be easily decoded to sketches through a lightweight network. With CoProSketch, users generate a rough sketch from a bounding box and a text prompt. The rough sketch can be manually edited and fed back into the model for iterative refinement and will be decoded to a detailed sketch as the final result. Additionally, we curate the first large-scale text-sketch paired dataset as the training data. Experiments demonstrate superior semantic consistency and controllability over baselines, offering a practical solution for integrating user feedback into generative workflows.', 'abstract_zh': 'CoProSketch：基于扩散模型的可控草图生成框架', 'title_zh': 'CoProSketch: 可控制与渐进的素描生成方法基于扩散模型'}
{'arxiv_id': 'arXiv:2504.08258', 'title': 'Accelerating Multi-Objective Collaborative Optimization of Doped Thermoelectric Materials via Artificial Intelligence', 'authors': 'Yuxuan Zeng, Wenhao Xie, Wei Cao, Tan Peng, Yue Hou, Ziyu Wang, Jing Shi', 'link': 'https://arxiv.org/abs/2504.08258', 'abstract': 'The thermoelectric performance of materials exhibits complex nonlinear dependencies on both elemental types and their proportions, rendering traditional trial-and-error approaches inefficient and time-consuming for material discovery. In this work, we present a deep learning model capable of accurately predicting thermoelectric properties of doped materials directly from their chemical formulas, achieving state-of-the-art performance. To enhance interpretability, we further incorporate sensitivity analysis techniques to elucidate how physical descriptors affect the thermoelectric figure of merit (zT). Moreover, we establish a coupled framework that integrates a surrogate model with a multi-objective genetic algorithm to efficiently explore the vast compositional space for high-performance candidates. Experimental validation confirms the discovery of a novel thermoelectric material with superior $zT$ values in the medium-temperature regime.', 'abstract_zh': '深学习模型在化学式指导下直接预测掺杂材料热电性能的研究：高效探索高性能候选材料的耦合框架验证', 'title_zh': '通过人工智能加速掺杂热电材料多目标协作优化'}
{'arxiv_id': 'arXiv:2504.08257', 'title': 'Bayesian Reasoning Enabled by Spin-Orbit Torque Magnetic Tunnel Junctions', 'authors': 'Yingqian Xu, Xiaohan Li, Caihua Wan, Ran Zhang, Bin He, Shiqiang Liu, Jihao Xia, Dehao Kong, Shilong Xiong, Guoqiang Yu, Xiufeng Han', 'link': 'https://arxiv.org/abs/2504.08257', 'abstract': 'Bayesian networks play an increasingly important role in data mining, inference, and reasoning with the rapid development of artificial intelligence. In this paper, we present proof-of-concept experiments demonstrating the use of spin-orbit torque magnetic tunnel junctions (SOT-MTJs) in Bayesian network reasoning. Not only can the target probability distribution function (PDF) of a Bayesian network be precisely formulated by a conditional probability table as usual but also quantitatively parameterized by a probabilistic forward propagating neuron network. Moreover, the parameters of the network can also approach the optimum through a simple point-by point training algorithm, by leveraging which we do not need to memorize all historical data nor statistically summarize conditional probabilities behind them, significantly improving storage efficiency and economizing data pretreatment. Furthermore, we developed a simple medical diagnostic system using the SOT-MTJ as a random number generator and sampler, showcasing the application of SOT-MTJ-based Bayesian reasoning. This SOT-MTJ-based Bayesian reasoning shows great promise in the field of artificial probabilistic neural network, broadening the scope of spintronic device applications and providing an efficient and low-storage solution for complex reasoning tasks.', 'abstract_zh': '基于自旋轨道扭矩磁隧道结的贝叶斯网络推理：原理验证与应用探索', 'title_zh': '由自旋轨道矩磁隧道结-enabled的贝叶斯推理'}
{'arxiv_id': 'arXiv:2504.08210', 'title': 'Optimizing Power Grid Topologies with Reinforcement Learning: A Survey of Methods and Challenges', 'authors': 'Erica van der Sar, Alessandro Zocca, Sandjai Bhulai', 'link': 'https://arxiv.org/abs/2504.08210', 'abstract': 'Power grid operation is becoming increasingly complex due to the rising integration of renewable energy sources and the need for more adaptive control strategies. Reinforcement Learning (RL) has emerged as a promising approach to power network control (PNC), offering the potential to enhance decision-making in dynamic and uncertain environments. The Learning To Run a Power Network (L2RPN) competitions have played a key role in accelerating research by providing standardized benchmarks and problem formulations, leading to rapid advancements in RL-based methods. This survey provides a comprehensive and structured overview of RL applications for power grid topology optimization, categorizing existing techniques, highlighting key design choices, and identifying gaps in current research. Additionally, we present a comparative numerical study evaluating the impact of commonly applied RL-based methods, offering insights into their practical effectiveness. By consolidating existing research and outlining open challenges, this survey aims to provide a foundation for future advancements in RL-driven power grid optimization.', 'abstract_zh': '电力网络运行因可再生能源的集成增加和需要更适应的控制策略而变得越来越复杂。强化学习（RL）已成为电力网络控制（PNC）的一个有前途的方法，有可能在动态和不确定的环境中提高决策能力。L2RPN竞赛通过提供标准化的基准和问题形式，在加速研究方面发挥了关键作用，导致基于RL的方法迅速发展。本文提供了一个全面且结构化的RL在电力网络拓扑优化中的应用综述，对现有技术进行分类，突出关键设计选择，并识别当前研究中的空白。此外，我们还呈现了一个比较数值研究，评估了常用基于RL方法的影响，提供了其实际有效性的见解。通过整合现有研究并概述开放挑战，本文旨在为基于RL的电力网络优化未来进步奠定基础。', 'title_zh': '使用强化学习优化电力网络拓扑结构：方法与挑战综述'}
{'arxiv_id': 'arXiv:2504.08201', 'title': 'Neural Encoding and Decoding at Scale', 'authors': 'Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz', 'link': 'https://arxiv.org/abs/2504.08201', 'abstract': "Recent work has demonstrated that large-scale, multi-animal models are powerful tools for characterizing the relationship between neural activity and behavior. Current large-scale approaches, however, focus exclusively on either predicting neural activity from behavior (encoding) or predicting behavior from neural activity (decoding), limiting their ability to capture the bidirectional relationship between neural activity and behavior. To bridge this gap, we introduce a multimodal, multi-task model that enables simultaneous Neural Encoding and Decoding at Scale (NEDS). Central to our approach is a novel multi-task-masking strategy, which alternates between neural, behavioral, within-modality, and cross-modality masking. We pretrain our method on the International Brain Laboratory (IBL) repeated site dataset, which includes recordings from 83 animals performing the same visual decision-making task. In comparison to other large-scale models, we demonstrate that NEDS achieves state-of-the-art performance for both encoding and decoding when pretrained on multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's learned embeddings exhibit emergent properties: even without explicit training, they are highly predictive of the brain regions in each recording. Altogether, our approach is a step towards a foundation model of the brain that enables seamless translation between neural activity and behavior.", 'abstract_zh': 'Recent Work Has Demonstrated that Large-Scale, Multi-Animal Models are Powerful Tools for Characterizing the Relationship between Neural Activity and Behavior: Bridging the Gap with Neural Encoding and Decoding at Scale (NEDS)', 'title_zh': '大规模神经编码与解码'}
{'arxiv_id': 'arXiv:2504.08200', 'title': 'Influential Bandits: Pulling an Arm May Change the Environment', 'authors': 'Ryoma Sato, Shinji Ito', 'link': 'https://arxiv.org/abs/2504.08200', 'abstract': "While classical formulations of multi-armed bandit problems assume that each arm's reward is independent and stationary, real-world applications often involve non-stationary environments and interdependencies between arms. In particular, selecting one arm may influence the future rewards of other arms, a scenario not adequately captured by existing models such as rotting bandits or restless bandits. To address this limitation, we propose the influential bandit problem, which models inter-arm interactions through an unknown, symmetric, positive semi-definite interaction matrix that governs the dynamics of arm losses. We formally define this problem and establish two regret lower bounds, including a superlinear $\\Omega(T^2 / \\log^2 T)$ bound for the standard UCB algorithm and an algorithm-independent $\\Omega(T)$ bound, which highlight the inherent difficulty of the setting. We then introduce a new algorithm based on a lower confidence bound (LCB) estimator tailored to the structure of the loss dynamics. Under mild assumptions, our algorithm achieves a regret of $O(KT \\log T)$, which is nearly optimal in terms of its dependence on the time horizon. The algorithm is simple to implement and computationally efficient. Empirical evaluations on both synthetic and real-world datasets demonstrate the presence of inter-arm influence and confirm the superior performance of our method compared to conventional bandit algorithms.", 'abstract_zh': '具有影响关系的bandit问题：基于损失动态结构的下置信界算法', 'title_zh': '有影响力的探索者：拉一个臂可能改变环境'}
{'arxiv_id': 'arXiv:2504.08177', 'title': 'SynthFM: Training Modality-agnostic Foundation Models for Medical Image Segmentation without Real Medical Data', 'authors': 'Sourya Sengupta, Satrajit Chakrabarty, Keerthi Sravan Ravi, Gopal Avinash, Ravi Soni', 'link': 'https://arxiv.org/abs/2504.08177', 'abstract': "Foundation models like the Segment Anything Model (SAM) excel in zero-shot segmentation for natural images but struggle with medical image segmentation due to differences in texture, contrast, and noise. Annotating medical images is costly and requires domain expertise, limiting large-scale annotated data availability. To address this, we propose SynthFM, a synthetic data generation framework that mimics the complexities of medical images, enabling foundation models to adapt without real medical data. Using SAM's pretrained encoder and training the decoder from scratch on SynthFM's dataset, we evaluated our method on 11 anatomical structures across 9 datasets (CT, MRI, and Ultrasound). SynthFM outperformed zero-shot baselines like SAM and MedSAM, achieving superior results under different prompt settings and on out-of-distribution datasets.", 'abstract_zh': '基于SynthFM的合成数据生成框架在医学图像分割中的应用：克服自然图像与医学图像分割差异，无需大量标注数据', 'title_zh': 'SynthFM: 训练跨模态基础模型以在无需真实医疗数据的情况下进行医学图像分割'}
{'arxiv_id': 'arXiv:2504.08169', 'title': 'On the Practice of Deep Hierarchical Ensemble Network for Ad Conversion Rate Prediction', 'authors': 'Jinfeng Zhuang, Yinrui Li, Runze Su, Ke Xu, Zhixuan Shao, Kungang Li, Ling Leng, Han Sun, Meng Qi, Yixiong Meng, Yang Tang, Zhifang Liu, Qifei Shen, Aayush Mudgal', 'link': 'https://arxiv.org/abs/2504.08169', 'abstract': "The predictions of click through rate (CTR) and conversion rate (CVR) play a crucial role in the success of ad-recommendation systems. A Deep Hierarchical Ensemble Network (DHEN) has been proposed to integrate multiple feature crossing modules and has achieved great success in CTR prediction. However, its performance for CVR prediction is unclear in the conversion ads setting, where an ad bids for the probability of a user's off-site actions on a third party website or app, including purchase, add to cart, sign up, etc. A few challenges in DHEN: 1) What feature-crossing modules (MLP, DCN, Transformer, to name a few) should be included in DHEN? 2) How deep and wide should DHEN be to achieve the best trade-off between efficiency and efficacy? 3) What hyper-parameters to choose in each feature-crossing module? Orthogonal to the model architecture, the input personalization features also significantly impact model performance with a high degree of freedom. In this paper, we attack this problem and present our contributions biased to the applied data science side, including:\nFirst, we propose a multitask learning framework with DHEN as the single backbone model architecture to predict all CVR tasks, with a detailed study on how to make DHEN work effectively in practice; Second, we build both on-site real-time user behavior sequences and off-site conversion event sequences for CVR prediction purposes, and conduct ablation study on its importance; Last but not least, we propose a self-supervised auxiliary loss to predict future actions in the input sequence, to help resolve the label sparseness issue in CVR prediction.\nOur method achieves state-of-the-art performance compared to previous single feature crossing modules with pre-trained user personalization features.", 'abstract_zh': '深度层次集成网络在点击率和转化率预测中的多任务学习框架及贡献', 'title_zh': '基于深度层次集成网络的广告转换率预测实践研究'}
{'arxiv_id': 'arXiv:2504.08102', 'title': 'Multi-view autoencoders for Fake News Detection', 'authors': 'Ingryd V. S. T. Pereira, George D. C. Cavalcanti, Rafael M. O. Cruz', 'link': 'https://arxiv.org/abs/2504.08102', 'abstract': "Given the volume and speed at which fake news spreads across social media, automatic fake news detection has become a highly important task. However, this task presents several challenges, including extracting textual features that contain relevant information about fake news. Research about fake news detection shows that no single feature extraction technique consistently outperforms the others across all scenarios. Nevertheless, different feature extraction techniques can provide complementary information about the textual data and enable a more comprehensive representation of the content. This paper proposes using multi-view autoencoders to generate a joint feature representation for fake news detection by integrating several feature extraction techniques commonly used in the literature. Experiments on fake news datasets show a significant improvement in classification performance compared to individual views (feature representations). We also observed that selecting a subset of the views instead of composing a latent space with all the views can be advantageous in terms of accuracy and computational effort. For further details, including source codes, figures, and datasets, please refer to the project's repository: this https URL.", 'abstract_zh': '基于社交媒体上传播速度和规模的虚假新闻，自动虚假新闻检测已成为一项极其重要的任务。然而，这一任务面临诸多挑战，包括提取包含虚假新闻相关信息的文本特征。关于虚假新闻检测的研究表明，没有一种特征提取技术能在所有场景中持续优于其他技术。尽管如此，不同的特征提取技术可以提供互补的文本信息，并能够更全面地表示内容。本文提出使用多视图自动编码器生成虚假新闻检测的联合特征表示，通过整合文献中常用的各种特征提取技术。实验结果显示，与单独的视图（特征表示）相比，这种方法在分类性能上取得了显著的提升。我们还发现，而不是使用所有视图组成潜在空间，在准确性和计算成本方面，选择视图的子集可能是有利的。更多详情，包括源代码、图表和数据集，请参见项目的仓库：this https URL。', 'title_zh': '多视图自编码器在虚假新闻检测中的应用'}
{'arxiv_id': 'arXiv:2504.08096', 'title': 'Cellular Development Follows the Path of Minimum Action', 'authors': 'Rohola Zandie, Farhan Khodaee, Yufan Xia, Elazer R. Edelman', 'link': 'https://arxiv.org/abs/2504.08096', 'abstract': 'Cellular development follows a stochastic yet rule-governed trajectory, though the underlying principles remain elusive. Here, we propose that cellular development follows paths of least action, aligning with foundational physical laws that govern dynamic systems across nature. We introduce a computational framework that takes advantage of the deep connection between the principle of least action and maximum entropy to model developmental processes using Transformers architecture. This approach enables precise quantification of entropy production, information flow curvature, and local irreversibility for developmental asymmetry in single-cell RNA sequence data. Within this unified framework, we provide interpretable metrics: entropy to capture exploration-exploitation trade-offs, curvature to assess plasticity-elasticity dynamics, and entropy production to characterize dedifferentiation and transdifferentiation. We validate our method across both single-cell and embryonic development datasets, demonstrating its ability to reveal hidden thermodynamic and informational constraints shaping cellular fate decisions.', 'abstract_zh': '细胞发育遵循一种随机 yet 规则制约的路径，尽管其背后的原理仍不清楚。在这里，我们提出细胞发育遵循最小作用路径，这与自然中动态系统所遵循的基本物理定律一致。我们介绍了一种计算框架，利用最小作用原理与最大熵之间的深层联系，使用变压器架构来建模发育过程。该方法能够精确量化熵产生、信息流曲率和发育不对称的局部不可逆性。在这一统一框架中，我们提供了可解释的度量标准：熵来捕捉探索-利用权衡，曲率来评估弹性-塑性 dynamics，熵产生来表征去分化和跨分化。我们在单细胞和胚胎发育数据集上验证了该方法，展示了其揭示塑造细胞命运决定的隐藏热力学和信息约束的能力。', 'title_zh': '细胞发育遵循最小作用原理'}
{'arxiv_id': 'arXiv:2504.08061', 'title': 'STEI-PCN: an efficient pure convolutional network for traffic prediction via spatial-temporal encoding and inferring', 'authors': 'Kai Hu, Zhidan Zhao, Zhifeng Hao', 'link': 'https://arxiv.org/abs/2504.08061', 'abstract': 'Traffic data exhibits complex temporal, spatial, and spatial-temporal correlations. Most of models use either independent modules to separately extract temporal and spatial correlations or joint modules to synchronously extract them, without considering the spatial-temporal correlations. Moreover, models that consider joint spatial-temporal correlations (temporal, spatial, and spatial-temporal correlations) often encounter significant challenges in accuracy and computational efficiency which prevent such models from demonstrating the expected advantages of a joint spatial-temporal correlations architecture. To address these issues, this paper proposes an efficient pure convolutional network for traffic prediction via spatial-temporal encoding and inferring (STEI-PCN). The model introduces and designs a dynamic adjacency matrix inferring module based on absolute spatial and temporal coordinates, as well as relative spatial and temporal distance encoding, using a graph convolutional network combined with gating mechanism to capture local synchronous joint spatial-temporal correlations. Additionally, three layers of temporal dilated causal convolutional network are used to capture long-range temporal correlations. Finally, through multi-view collaborative prediction module, the model integrates the gated-activated original, local synchronous joint spatial-temporal, and long-range temporal features to achieve comprehensive prediction. This study conducts extensive experiments on flow datasets (PeMS03/04/07/08) and speed dataset (PeMS-Bay), covering multiple prediction horizons. The results show that STEI-PCN demonstrates competitive computational efficiency in both training and inference speeds, and achieves superior or slightly inferior to state-of-the-art (SOTA) models on most evaluation metrics.', 'abstract_zh': '基于空间- temporal编码与推断的高效纯卷积网络用于交通预测', 'title_zh': 'STEI-PCN：一种通过空间-时间编码和推断的高效纯卷积网络用于交通预测'}
{'arxiv_id': 'arXiv:2504.08020', 'title': 'Learning Fine-grained Domain Generalization via Hyperbolic State Space Hallucination', 'authors': 'Qi Bi, Jingjun Yi, Haolan Zhan, Wei Ji, Gui-Song Xia', 'link': 'https://arxiv.org/abs/2504.08020', 'abstract': 'Fine-grained domain generalization (FGDG) aims to learn a fine-grained representation that can be well generalized to unseen target domains when only trained on the source domain data. Compared with generic domain generalization, FGDG is particularly challenging in that the fine-grained category can be only discerned by some subtle and tiny patterns. Such patterns are particularly fragile under the cross-domain style shifts caused by illumination, color and etc. To push this frontier, this paper presents a novel Hyperbolic State Space Hallucination (HSSH) method. It consists of two key components, namely, state space hallucination (SSH) and hyperbolic manifold consistency (HMC). SSH enriches the style diversity for the state embeddings by firstly extrapolating and then hallucinating the source images. Then, the pre- and post- style hallucinate state embeddings are projected into the hyperbolic manifold. The hyperbolic state space models the high-order statistics, and allows a better discernment of the fine-grained patterns. Finally, the hyperbolic distance is minimized, so that the impact of style variation on fine-grained patterns can be eliminated. Experiments on three FGDG benchmarks demonstrate its state-of-the-art performance.', 'abstract_zh': '细粒度领域泛化 (FGDG) 的超曲面状态空间幻视 (HSSH) 方法', 'title_zh': '基于双曲状态空间幻象的细粒度领域泛化学习'}
{'arxiv_id': 'arXiv:2504.07998', 'title': 'CDM-QTA: Quantized Training Acceleration for Efficient LoRA Fine-Tuning of Diffusion Model', 'authors': 'Jinming Lu, Minghao She, Wendong Mao, Zhongfeng Wang', 'link': 'https://arxiv.org/abs/2504.07998', 'abstract': 'Fine-tuning large diffusion models for custom applications demands substantial power and time, which poses significant challenges for efficient implementation on mobile devices. In this paper, we develop a novel training accelerator specifically for Low-Rank Adaptation (LoRA) of diffusion models, aiming to streamline the process and reduce computational complexity. By leveraging a fully quantized training scheme for LoRA fine-tuning, we achieve substantial reductions in memory usage and power consumption while maintaining high model fidelity. The proposed accelerator features flexible dataflow, enabling high utilization for irregular and variable tensor shapes during the LoRA process. Experimental results show up to 1.81x training speedup and 5.50x energy efficiency improvements compared to the baseline, with minimal impact on image generation quality.', 'abstract_zh': '针对低秩适应（LoRA）的大型扩散模型微调开发新型训练加速器：简化流程、降低计算复杂度并减少功耗', 'title_zh': 'CDM-QTA: 量化训练加速高效Diffusion模型LoRA微调'}
{'arxiv_id': 'arXiv:2504.07994', 'title': 'Evaluating the Fitness of Ontologies for the Task of Question Generation', 'authors': 'Samah Alkhuzaey, Floriana Grasso, Terry R. Payne, Valentina Tamma', 'link': 'https://arxiv.org/abs/2504.07994', 'abstract': 'Ontology-based question generation is an important application of semantic-aware systems that enables the creation of large question banks for diverse learning environments. The effectiveness of these systems, both in terms of the calibre and cognitive difficulty of the resulting questions, depends heavily on the quality and modelling approach of the underlying ontologies, making it crucial to assess their fitness for this task. To date, there has been no comprehensive investigation into the specific ontology aspects or characteristics that affect the question generation process. Therefore, this paper proposes a set of requirements and task-specific metrics for evaluating the fitness of ontologies for question generation tasks in pedagogical settings. Using the ROMEO methodology, a structured framework for deriving task-specific metrics, an expert-based approach is employed to assess the performance of various ontologies in Automatic Question Generation (AQG) tasks, which is then evaluated over a set of ontologies. Our results demonstrate that ontology characteristics significantly impact the effectiveness of question generation, with different ontologies exhibiting varying performance levels. This highlights the importance of assessing ontology quality with respect to AQG tasks.', 'abstract_zh': '基于本体的问答生成是语义感知系统的重要应用，能够为多样化的学习环境创建大量问题库。这些系统的有效性，在于生成的问题的质量和认知难度，很大程度上取决于底层本体的质量和建模方法，因此评估它们是否适合这一任务至关重要。迄今为止，尚未对影响问答生成过程的具体本体特性进行全面调查。因此，本文提出了一套针对教学场景中问答生成任务评估本体适用性的需求和任务特定指标。利用ROMEO方法，一个结构化的任务特定指标推导框架，采用专家基于的方法评估了各种本体在自动问答生成任务中的性能，并在一组本体上进行了评估。我们的结果表明，本体特性显著影响问答生成的有效性，不同本体在性能上表现出差异。这强调了评估本体质量与自动问答生成任务之间的关系的重要性。', 'title_zh': '评估本体适合度以用于问题生成任务'}
{'arxiv_id': 'arXiv:2504.07990', 'title': 'Comparative analysis of Realistic EMF Exposure Estimation from Low Density Sensor Network by Finite & Infinite Neural Networks', 'authors': 'Mohammed Mallik, Laurent Clavier, Davy P. Gaillot', 'link': 'https://arxiv.org/abs/2504.07990', 'abstract': "Understanding the spatial and temporal patterns of environmental exposure to radio-frequency electromagnetic fields (RF-EMF) is essential for conducting risk assessments. These assessments aim to explore potential connections between RF-EMF exposure and its effects on human health, as well as on wildlife and plant life. Existing research has used different machine learning tools for EMF exposure estimation; however, a comparative analysis of these techniques is required to better understand their performance for real-world datasets. In this work, we present both finite and infinite-width convolutional network-based methods to estimate and assess EMF exposure levels from 70 real-world sensors in Lille, France. A comparative analysis has been conducted to analyze the performance of the methods' execution time and estimation accuracy. To improve estimation accuracy for higher-resolution grids, we utilized a preconditioned gradient descent method for kernel estimation. Root Mean Square Error (RMSE) is used as the evaluation criterion for comparing the performance of these deep learning models.", 'abstract_zh': '理解无线电频电磁场（RF-EMF）的空间和时间分布模式对于进行风险评估至关重要。这些评估旨在探索RF-EMF暴露与其对人体健康、野生动物和植物生活的影响之间的潜在联系。现有的研究使用了不同的机器学习工具进行EMF暴露估计；然而，对这些技术的比较分析仍是必要的，以便更好地了解其在实际数据集中的性能。在本工作中，我们使用有限宽度和无限宽度卷积网络方法，从法国里尔的70个真实传感器数据中估计和评估EMF暴露水平。我们进行了比较分析，以分析这些方法的执行时间和估计准确性的性能。为了提高高分辨率网格的估计准确性，我们利用预条件梯度下降法进行核估计。均方根误差（RMSE）被用作这些深度学习模型性能比较的评估标准。', 'title_zh': '有限神经网络与无限神经网络在低密度传感器网络中现实电磁场暴露估计的比较分析'}
{'arxiv_id': 'arXiv:2504.07971', 'title': 'SPHERE: An Evaluation Card for Human-AI Systems', 'authors': 'Qianou Ma, Dora Zhao, Xinran Zhao, Chenglei Si, Chenyang Yang, Ryan Louie, Ehud Reiter, Diyi Yang, Tongshuang Wu', 'link': 'https://arxiv.org/abs/2504.07971', 'abstract': 'In the era of Large Language Models (LLMs), establishing effective evaluation methods and standards for diverse human-AI interaction systems is increasingly challenging. To encourage more transparent documentation and facilitate discussion on human-AI system evaluation design options, we present an evaluation card SPHERE, which encompasses five key dimensions: 1) What is being evaluated?; 2) How is the evaluation conducted?; 3) Who is participating in the evaluation?; 4) When is evaluation conducted?; 5) How is evaluation validated? We conduct a review of 39 human-AI systems using SPHERE, outlining current evaluation practices and areas for improvement. We provide three recommendations for improving the validity and rigor of evaluation practices.', 'abstract_zh': '在大型语言模型时代，建立多样的人工智能交互系统评价方法和标准越来越具有挑战性。为促进更加透明的文档编写和便于讨论人工智能系统评价设计选项，我们提出了一种评价卡SPHERE，涵盖了五个关键维度：1) 评价什么？；2) 如何进行评价？；3) 参与评价的是谁？；4) 何时进行评价？；5) 如何验证评价结果？我们使用SPHERE对39个人工智能系统进行了评审，概述了当前的评价实践和改进领域，并提供了三条建议以提高评价实践的有效性和严谨性。', 'title_zh': 'SPHERE: 人类-人工智能系统评估卡'}
