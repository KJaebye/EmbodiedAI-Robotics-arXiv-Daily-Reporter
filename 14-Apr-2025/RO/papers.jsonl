{'arxiv_id': 'arXiv:2504.08706', 'title': 'BiFlex: A Passive Bimodal Stiffness Flexible Wrist for Manipulation in Unstructured Environments', 'authors': 'Gu-Cheol Jeong, Stefano Dalla Gasperina, Ashish D. Deshpande, Lillian Chin, Roberto Martín-Martín', 'link': 'https://arxiv.org/abs/2504.08706', 'abstract': 'Robotic manipulation in unstructured, humancentric environments poses a dual challenge: achieving the precision need for delicate free-space operation while ensuring safety during unexpected contact events. Traditional wrists struggle to balance these demands, often relying on complex control schemes or complicated mechanical designs to mitigate potential damage from force overload. In response, we present BiFlex, a flexible robotic wrist that uses a soft buckling honeycomb structure to provides a natural bimodal stiffness response. The higher stiffness mode enables precise household object manipulation, while the lower stiffness mode provides the compliance needed to adapt to external forces. We design BiFlex to maintain a fingertip deflection of less than 1 cm while supporting loads up to 500g and create a BiFlex wrist for many grippers, including Panda, Robotiq, and BaRiFlex. We validate BiFlex under several real-world experimental evaluations, including surface wiping, precise pick-and-place, and grasping under environmental constraints. We demonstrate that BiFlex simplifies control while maintaining precise object manipulation and enhanced safety in real-world applications.', 'abstract_zh': '非结构化、以人为中心环境中的人形机器人Manipulation面临的是一种双重挑战：需要实现对精细自由空间操作的精度要求，同时在意外接触事件中确保安全性。传统的手腕结构难以平衡这些需求，往往依赖于复杂的控制方案或复杂的机械设计来减轻负载过大的潜在损伤。为应对这一挑战，我们提出了BiFlex柔性机器人手腕，该手腕采用软折纸蜂窝结构，提供自然的双模刚度响应。更高的刚度模式能够实现对家用物体的精确操作，而较低的刚度模式则提供了适应外部力所需的柔顺性。我们设计BiFlex以在支持高达500g的负载时保持指尖形变小于1cm，并为多种握持器，包括Panda、Robotiq和BaRiFlex，设计了BiFlex手腕。我们通过多种实际实验验证了BiFlex，包括表面擦拭、精确拾放和环境约束下的抓取。我们展示了BiFlex在实际应用中简化控制的同时，保持了精确的物体操作和增强的安全性。', 'title_zh': 'BiFlex: 一种用于结构化环境中操作的被动双模态刚度可调手腕'}
{'arxiv_id': 'arXiv:2504.08704', 'title': 'Offline Reinforcement Learning using Human-Aligned Reward Labeling for Autonomous Emergency Braking in Occluded Pedestrian Crossing', 'authors': 'Vinal Asodia, Zhenhua Feng, Saber Fallah', 'link': 'https://arxiv.org/abs/2504.08704', 'abstract': 'Effective leveraging of real-world driving datasets is crucial for enhancing the training of autonomous driving systems. While Offline Reinforcement Learning enables the training of autonomous vehicles using such data, most available datasets lack meaningful reward labels. Reward labeling is essential as it provides feedback for the learning algorithm to distinguish between desirable and undesirable behaviors, thereby improving policy performance. This paper presents a novel pipeline for generating human-aligned reward labels. The proposed approach addresses the challenge of absent reward signals in real-world datasets by generating labels that reflect human judgment and safety considerations. The pipeline incorporates an adaptive safety component, activated by analyzing semantic segmentation maps, allowing the autonomous vehicle to prioritize safety over efficiency in potential collision scenarios. The proposed pipeline is applied to an occluded pedestrian crossing scenario with varying levels of pedestrian traffic, using synthetic and simulation data. The results indicate that the generated reward labels closely match the simulation reward labels. When used to train the driving policy using Behavior Proximal Policy Optimisation, the results are competitive with other baselines. This demonstrates the effectiveness of our method in producing reliable and human-aligned reward signals, facilitating the training of autonomous driving systems through Reinforcement Learning outside of simulation environments and in alignment with human values.', 'abstract_zh': '有效的利用实际驾驶数据对于增强自动驾驶系统训练至关重要。虽然 Offline Reinforcement Learning 可以利用此类数据训练自动驾驶车辆，但大多数可用的数据集缺乏有意义的奖励标签。奖励标签是必要的，因为它为学习算法提供了反馈，使其能够区分 desirable 和 undesirable 行为，从而提高策略性能。本文提出了一种新的生成人类对齐奖励标签的管道。所提出的方法通过生成反映人类判断和安全考虑的标签，解决了现实世界数据集中缺乏奖励信号的挑战。该管道包含一个基于分析语义分割图的自适应安全组件，允许自动驾驶车辆在潜在碰撞场景中优先考虑安全而非效率。所提出的管道应用于具有不同行人流量的遮挡行人过街场景，使用合成和仿真数据。结果表明，生成的奖励标签与仿真奖励标签高度一致。当用于使用 Behavior Proximal Policy Optimisation 训练驾驶策略时，结果与其他基线相当。这证明了该方法在生成可靠且与人类价值观相一致的奖励信号方面的有效性，促进了在仿真环境之外和与人类价值观一致的条件下通过 Reinforcement Learning 对自动驾驶系统进行训练。', 'title_zh': '基于人类对齐奖励标注的自主紧急制动在行人遮挡过街场景下的离线强化学习'}
{'arxiv_id': 'arXiv:2504.08698', 'title': 'Performance Evaluation of Trajectory Tracking Controllers for a Quadruped Robot Leg', 'authors': 'Hossein Shojaei, Hamid Rahmanei, Seyed Hossein Sadati', 'link': 'https://arxiv.org/abs/2504.08698', 'abstract': 'The complexities in the dynamic model of the legged robots make it necessary to utilize model-free controllers in the task of trajectory tracking. In This paper, an adaptive transpose Jacobian approach is proposed to deal with the dynamic model complexity, which utilizes an adaptive PI-algorithm to adjust the control gains. The performance of the proposed control algorithm is compared with the conventional transpose Jacobian and sliding mode control algorithms and evaluated by the root mean square of the errors and control input energy criteria. In order to appraise the effectiveness of the proposed control system, simulations are carried out in MATLAB/Simulink software for a quadruped robot leg for semi-elliptical path tracking. The obtained results show that the proposed adaptive transpose Jacobian reduces the overshoot and root mean square of the errors and at the same time, decreases the control input energy. Moreover, transpose Jacobin and adaptive transpose Jacobian are more robust to changes in initial conditions compared to the conventional sliding mode control. Furthermore, sliding mode control performs well up to 20% uncertainties in the parameters due to its model-based nature, whereas the transpose Jacobin and the proposed adaptive transpose Jacobian algorithms show promising results even in higher mass uncertainties.', 'abstract_zh': '具有自适应转置雅可比的轨迹跟踪控制算法研究', 'title_zh': '四足机器人腿部轨迹跟踪控制器性能评估'}
{'arxiv_id': 'arXiv:2504.08686', 'title': 'Pobogot -- An Open-Hardware Open-Source Low Cost Robot for Swarm Robotics', 'authors': 'Alessia Loi, Loona Macabre, Jérémy Fersula, Keivan Amini, Leo Cazenille, Fabien Caura, Alexandre Guerre, Stéphane Gourichon, Olivier Dauchot, Nicolas Bredeche', 'link': 'https://arxiv.org/abs/2504.08686', 'abstract': "This paper describes the Pogobot, an open-source and open-hardware platform specifically designed for research involving swarm robotics. Pogobot features vibration-based locomotion, infrared communication, and an array of sensors in a cost-effective package (approx. 250~euros/unit). The platform's modular design, comprehensive API, and extensible architecture facilitate the implementation of swarm intelligence algorithms and distributed online reinforcement learning algorithms. Pogobots offer an accessible alternative to existing platforms while providing advanced capabilities including directional communication between units. More than 200 Pogobots are already being used on a daily basis at Sorbonne Université and PSL to study self-organizing systems, programmable active matter, discrete reaction-diffusion-advection systems as well as models of social learning and evolution.", 'abstract_zh': 'This paper描述了Pogobot：一种开源硬件平台，专门用于 swarm robotics 的研究。', 'title_zh': 'Pobogot — 一种用于 swarm robotics 的开源硬件低成本机器人'}
{'arxiv_id': 'arXiv:2504.08661', 'title': 'Safe Flow Matching: Robot Motion Planning with Control Barrier Functions', 'authors': 'Xiaobing Dai, Dian Yu, Shanshan Zhang, Zewen Yang', 'link': 'https://arxiv.org/abs/2504.08661', 'abstract': 'Recent advances in generative modeling have led to promising results in robot motion planning, particularly through diffusion and flow-based models that capture complex, multimodal trajectory distributions. However, these methods are typically trained offline and remain limited when faced with unseen environments or dynamic constraints, often lacking explicit mechanisms to ensure safety during deployment. In this work, we propose, Safe Flow Matching (SafeFM), a motion planning approach for trajectory generation that integrates flow matching with safety guarantees. By incorporating the proposed flow matching barrier functions, SafeFM ensures that generated trajectories remain within safe regions throughout the planning horizon, even in the presence of previously unseen obstacles or state-action constraints. Unlike diffusion-based approaches, our method allows for direct, efficient sampling of constraint-satisfying trajectories, making it well-suited for real-time motion planning. We evaluate SafeFM on a diverse set of tasks, including planar robot navigation and 7-DoF manipulation, demonstrating superior safety, generalization, and planning performance compared to state-of-the-art generative planners. Comprehensive resources are available on the project website: this https URL', 'abstract_zh': 'Recent advances in generative modeling have led to promising results in robot motion planning, particularly through diffusion and flow-based models that capture complex, multimodal trajectory distributions.然而，这些方法通常在离线训练，并且在面对未见过的环境或动态约束时受到限制，往往缺乏明确的机制来确保部署过程中的安全性。在这种情况下，我们提出了一种名为Safe Flow Matching (SafeFM)的运动规划方法，该方法将流匹配与安全性保证结合，通过引入所提出的流匹配障碍函数，SafeFM 确保生成的轨迹在整个计划时段内保持在安全区域内，即使存在未见过的障碍物或状态-动作约束。与基于扩散的方法不同，我们的方法允许直接、高效地抽样满足约束的轨迹，使其非常适合实时运动规划。我们通过一系列任务，包括平面机器人导航和7自由度操作，评估了SafeFM，结果显示其在安全性、泛化能力和规划性能方面均优于最先进的生成式规划器。更多资源可在项目网站获取：this https URL。', 'title_zh': '安全流匹配：基于控制屏障函数的机器人运动规划'}
{'arxiv_id': 'arXiv:2504.08655', 'title': 'TinyCenterSpeed: Efficient Center-Based Object Detection for Autonomous Racing', 'authors': 'Neil Reichlin, Nicolas Baumann, Edoardo Ghignone, Michele Magno', 'link': 'https://arxiv.org/abs/2504.08655', 'abstract': 'Perception within autonomous driving is nearly synonymous with Neural Networks (NNs). Yet, the domain of autonomous racing is often characterized by scaled, computationally limited robots used for cost-effectiveness and safety. For this reason, opponent detection and tracking systems typically resort to traditional computer vision techniques due to computational constraints. This paper introduces TinyCenterSpeed, a streamlined adaptation of the seminal CenterPoint method, optimized for real-time performance on 1:10 scale autonomous racing platforms. This adaptation is viable even on OBCs powered solely by Central Processing Units (CPUs), as it incorporates the use of an external Tensor Processing Unit (TPU). We demonstrate that, compared to Adaptive Breakpoint Detector (ABD), the current State-of-the-Art (SotA) in scaled autonomous racing, TinyCenterSpeed not only improves detection and velocity estimation by up to 61.38% but also supports multi-opponent detection and estimation. It achieves real-time performance with an inference time of just 7.88 ms on the TPU, significantly reducing CPU utilization 8.3-fold.', 'abstract_zh': 'TinyCenterSpeed：一种优化的适用于1:10比例自主赛车平台的目标检测和跟踪系统', 'title_zh': 'TinyCenterSpeed: 基于中心的有效物体检测方法及其在自主赛车中的应用'}
{'arxiv_id': 'arXiv:2504.08615', 'title': 'Tactile sensing enables vertical obstacle negotiation for elongate many-legged robots', 'authors': 'Juntao He, Baxi Chong, Vincent R Nienhusser, Massimiliano Iaschi, Sehoon Ha, Daniel I. Goldman', 'link': 'https://arxiv.org/abs/2504.08615', 'abstract': "Many-legged elongated robots show promise for reliable mobility on rugged landscapes. However, most studies on these systems focus on motion planning in the 2D horizontal plane (e.g., translation and rotation) without addressing rapid vertical motion. Despite their success on mild rugged terrains, recent field tests reveal a critical need for 3D behaviors (e.g., climbing or traversing tall obstacles) in real-world application. The challenges of 3D motion planning partially lie in designing sensing and control for a complex high-degree-of-freedom system, typically with over 25 degrees of freedom. To address the first challenge, we propose a tactile antenna system that enables the robot to probe obstacles and gather information about the structure of the environment. Building on this sensory input, we develop a control framework that integrates data from the antenna and foot contact sensors to dynamically adjust the robot's vertical body undulation for effective climbing. With the addition of simple, low-bandwidth tactile sensors, a robot with high static stability and redundancy exhibits predictable climbing performance in complex environments using a simple feedback controller. Laboratory and outdoor experiments demonstrate the robot's ability to climb obstacles up to five times its height. Moreover, the robot exhibits robust climbing capabilities on obstacles covered with flowable, robot-sized random items and those characterized by rapidly changing curvatures. These findings demonstrate an alternative solution to perceive the environment and facilitate effective response for legged robots, paving ways towards future highly capable, low-profile many-legged robots.", 'abstract_zh': '多-legged伸长型机器人在崎岖地形上的可靠移动显示出巨大潜力。然而，大多数关于这些系统的研究集中在2D水平面内的运动规划（如平移和旋转）上，没有解决快速垂直运动的问题。尽管在轻度崎岖地形上表现出色，最近的实地测试揭示了在实际应用中对3D行为（如攀爬或穿越高障碍物）的迫切需求。3D运动规划的挑战部分在于设计复杂高自由度系统的传感和控制，通常自由度超过25个。为应对第一个挑战，我们提出了一种触觉天线系统，使机器人能够探测障碍物并收集环境结构信息。在此基础上，我们开发了一种控制框架，将天线和足接触传感器的数据结合起来，动态调整机器人垂直身体起伏以实现有效的攀爬。通过添加简单的低带宽触觉传感器，在具有高静态稳定性和冗余性的机器人上，使用简单的反馈控制器即可在复杂环境中实现可预测的攀爬性能。实验室和户外实验表明，该机器人能够攀爬高达其高度五倍的障碍物。此外，该机器人还在覆盖有流动且机器人大小的随机物品的障碍物及具有快速变化曲率的障碍物上表现出鲁棒的攀爬能力。这些发现提供了一种感知环境和促进腿部机器人有效响应的替代方案，为未来低轮廓、多-legged高效能机器人的发展铺平了道路。', 'title_zh': '触觉感知使长多腿机器人能够应对垂直障碍物'}
{'arxiv_id': 'arXiv:2504.08604', 'title': 'Neural Fidelity Calibration for Informative Sim-to-Real Adaptation', 'authors': 'Youwei Yu, Lantao Liu', 'link': 'https://arxiv.org/abs/2504.08604', 'abstract': "Deep reinforcement learning can seamlessly transfer agile locomotion and navigation skills from the simulator to real world. However, bridging the sim-to-real gap with domain randomization or adversarial methods often demands expert physics knowledge to ensure policy robustness. Even so, cutting-edge simulators may fall short of capturing every real-world detail, and the reconstructed environment may introduce errors due to various perception uncertainties. To address these challenges, we propose Neural Fidelity Calibration (NFC), a novel framework that employs conditional score-based diffusion models to calibrate simulator physical coefficients and residual fidelity domains online during robot execution. Specifically, the residual fidelity reflects the simulation model shift relative to the real-world dynamics and captures the uncertainty of the perceived environment, enabling us to sample realistic environments under the inferred distribution for policy fine-tuning. Our framework is informative and adaptive in three key ways: (a) we fine-tune the pretrained policy only under anomalous scenarios, (b) we build sequential NFC online with the pretrained NFC's proposal prior, reducing the diffusion model's training burden, and (c) when NFC uncertainty is high and may degrade policy improvement, we leverage optimistic exploration to enable hallucinated policy optimization. Our framework achieves superior simulator calibration precision compared to state-of-the-art methods across diverse robots with high-dimensional parametric spaces. We study the critical contribution of residual fidelity to policy improvement in simulation and real-world experiments. Notably, our approach demonstrates robust robot navigation under challenging real-world conditions, such as a broken wheel axle on snowy surfaces.", 'abstract_zh': '深度强化学习可以无缝地将敏捷运动和导航技能从模拟器转移到真实世界。然而，使用领域随机化或对抗方法弥合模拟器到现实的差距往往需要专家物理学知识以确保策略稳健性。即使如此，最先进的模拟器可能无法捕捉每一个现实世界的细节，重构的环境也可能由于各种感知不确定性而引入错误。为了解决这些挑战，我们提出了一种新颖框架——神经保真度校准（Neural Fidelity Calibration，NFC），该框架利用条件分数扩散模型在线校准机器人执行期间模拟器的物理系数和残差保真度领域。具体来说，残差保真度反映了仿真模型相对于真实世界动力学的偏移，并捕捉感知环境的不确定性，使我们能够在推断的分布下采样现实环境用于策略微调。我们的框架在三个方面具有信息性和适应性：（a）仅在异常场景下微调预训练策略；（b）利用预训练NFC的提案先验构建顺序在线NFC，减轻扩散模型的训练负担；（c）当NFC不确定性高可能导致策略改善下降时，利用乐观探索进行幻视策略优化。我们的框架在多类高维参数空间的机器人中相比现有最佳方法实现了更优的模拟器校准精度。我们在仿真和实际实验中研究了残差保真度对策略改善的贡献。特别地，我们的方法在恶劣现实条件下的机器人导航表现出鲁棒性，例如在雪地表面车轮轴损坏的情况下。', 'title_zh': '神经保真度校准以实现信息性的仿真实到现实适应'}
{'arxiv_id': 'arXiv:2504.08603', 'title': 'FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment', 'authors': 'Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Simon Schaefer, Jaehyung Jung, Stefan Leutenegger', 'link': 'https://arxiv.org/abs/2504.08603', 'abstract': 'Geometrically accurate and semantically expressive map representations have proven invaluable to facilitate robust and safe mobile robot navigation and task planning. Nevertheless, real-time, open-vocabulary semantic understanding of large-scale unknown environments is still an open problem. In this paper we present FindAnything, an open-world mapping and exploration framework that incorporates vision-language information into dense volumetric submaps. Thanks to the use of vision-language features, FindAnything bridges the gap between pure geometric and open-vocabulary semantic information for a higher level of understanding while allowing to explore any environment without the help of any external source of ground-truth pose information. We represent the environment as a series of volumetric occupancy submaps, resulting in a robust and accurate map representation that deforms upon pose updates when the underlying SLAM system corrects its drift, allowing for a locally consistent representation between submaps. Pixel-wise vision-language features are aggregated from efficient SAM (eSAM)-generated segments, which are in turn integrated into object-centric volumetric submaps, providing a mapping from open-vocabulary queries to 3D geometry that is scalable also in terms of memory usage. The open-vocabulary map representation of FindAnything achieves state-of-the-art semantic accuracy in closed-set evaluations on the Replica dataset. This level of scene understanding allows a robot to explore environments based on objects or areas of interest selected via natural language queries. Our system is the first of its kind to be deployed on resource-constrained devices, such as MAVs, leveraging vision-language information for real-world robotic tasks.', 'abstract_zh': '几何准确且语义丰富的地图表示对于促进稳健和安全的移动机器人导航及任务规划至关重要。尽管如此，大规模未知环境的实时、开放式词汇语义理解仍然是一项开放性问题。本文介绍了FindAnything，一种将视觉-语言信息融入密集体素子地图中的开放世界.mapping和探索框架。通过使用视觉-语言特征，FindAnything在保持纯几何信息和开放式词汇语义信息之间搭建桥梁，实现更高层次的理解，同时能够探索任何环境，无需依赖任何外部来源的地面真实姿态信息。我们以一系列体素占据子地图的形式表示环境，生成一种在姿态更新时具有鲁棒性和准确性的地图表示，当底层SLAM系统纠正其漂移时，子地图之间能够保持局部一致性。体素级别的视觉-语言特征从高效的SAM（eSAM）生成的片段中聚合而来，并整合到以物体为中心的体素子地图中，提供从开放式词汇查询到三维几何的映射，同时在内存使用方面也具有可扩展性。FindAnything的开放式词汇地图表示在Replica数据集上的封闭集评估中达到了最先进的语义准确性。这种级别的场景理解使机器人能够基于通过自然语言查询选择的对象或感兴趣区域来探索环境。我们的系统是首个在资源受限设备（如MAVs）上部署的系统，并利用视觉-语言信息来实现真实世界的机器人任务。', 'title_zh': 'FindAnything: 开放词汇量与物体中心化映射在任意环境中的机器人探索'}
{'arxiv_id': 'arXiv:2504.08601', 'title': 'Enabling Safety for Aerial Robots: Planning and Control Architectures', 'authors': 'Kaleb Ben Naveed, Devansh R. Agrawal, Daniel M. Cherenson, Haejoon Lee, Alia Gilbert, Hardik Parwana, Vishnu S. Chipade, William Bentz, Dimitra Panagou', 'link': 'https://arxiv.org/abs/2504.08601', 'abstract': "Ensuring safe autonomy is crucial for deploying aerial robots in real-world applications. However, safety is a multifaceted challenge that must be addressed from multiple perspectives, including navigation in dynamic environments, operation under resource constraints, and robustness against adversarial attacks and uncertainties. In this paper, we present the authors' recent work that tackles some of these challenges and highlights key aspects that must be considered to enhance the safety and performance of autonomous aerial systems. All presented approaches are validated through hardware experiments.", 'abstract_zh': '确保自主性的安全性对于在实际应用中部署无人机至关重要。然而，安全是一个多方面的问题，必须从导航动态环境、资源约束下的操作、以及对抗攻击和不确定性下的鲁棒性等多个角度来解决。在本文中，我们展示了作者最近的工作，解决了一些挑战，并强调了必须考虑的关键方面，以提高自主无人机系统的安全性和性能。所有提出的方法都通过硬件实验进行了验证。', 'title_zh': '确保空中机器人安全：规划与控制架构'}
{'arxiv_id': 'arXiv:2504.08585', 'title': 'Ready, Bid, Go! On-Demand Delivery Using Fleets of Drones with Unknown, Heterogeneous Energy Storage Constraints', 'authors': 'Mohamed S. Talamali, Genki Miyauchi, Thomas Watteyne, Micael S. Couceiro, Roderich Gross', 'link': 'https://arxiv.org/abs/2504.08585', 'abstract': 'Unmanned Aerial Vehicles (UAVs) are expected to transform logistics, reducing delivery time, costs, and emissions. This study addresses an on-demand delivery , in which fleets of UAVs are deployed to fulfil orders that arrive stochastically. Unlike previous work, it considers UAVs with heterogeneous, unknown energy storage capacities and assumes no knowledge of the energy consumption models. We propose a decentralised deployment strategy that combines auction-based task allocation with online learning. Each UAV independently decides whether to bid for orders based on its energy storage charge level, the parcel mass, and delivery distance. Over time, it refines its policy to bid only for orders within its capability. Simulations using realistic UAV energy models reveal that, counter-intuitively, assigning orders to the least confident bidders reduces delivery times and increases the number of successfully fulfilled orders. This strategy is shown to outperform threshold-based methods which require UAVs to exceed specific charge levels at deployment. We propose a variant of the strategy which uses learned policies for forecasting. This enables UAVs with insufficient charge levels to commit to fulfilling orders at specific future times, helping to prioritise early orders. Our work provides new insights into long-term deployment of UAV swarms, highlighting the advantages of decentralised energy-aware decision-making coupled with online learning in real-world dynamic environments.', 'abstract_zh': '无人驾驶航空车辆（UAVs）有望重塑物流，减少交付时间、成本和排放。本文探讨了一种按需配送问题，在这种问题中， heterogeneous能量存储容量未知的UAV机群被部署以履行随机到达的订单。与先前工作不同，本文假设对能量消耗模型一无所知。我们提出了一种分散部署策略，结合了拍卖任务分配与在线学习。每个UAV根据其能量存储电量水平、包裹质量和配送距离独立决定是否竞标订单。随着时间的推移，它会不断优化策略，只竞标自身能力范围内的订单。使用现实中的UAV能量模型的仿真实验表明，出乎意料的是，将订单分配给最不自信的竞标者可以减少交付时间并增加成功完成订单的数量。该策略被证明能优于要求UAV在部署时必须超过特定电量水平的阈值方法。我们提出了一种该策略的变体，利用学习的策略进行预测。这使得电量不足的UAV能够在特定的未来时间承诺履行订单，帮助优先处理早期订单。我们的工作为UAV机群的长期部署提供了新的见解，突显了分散的能量感知决策与在线学习在真实动态环境中的优势。', 'title_zh': '蓄势，报价，启航！基于未知异质能量存储约束无人机机群的按需配送'}
{'arxiv_id': 'arXiv:2504.08547', 'title': 'Globally Optimal Data-Association-Free Landmark-Based Localization Using Semidefinite Relaxations', 'authors': 'Vassili Korotkine, Mitchell Cohen, James Richard Forbes', 'link': 'https://arxiv.org/abs/2504.08547', 'abstract': "This paper proposes a semidefinite relaxation for landmark-based localization with unknown data associations in planar environments. The proposed method simultaneously solves for the optimal robot states and data associations in a globally optimal fashion. Relative position measurements to known landmarks are used, but the data association is unknown in tha tthe robot does not know which landmark each measurement is generated from. The relaxation is shown to be tight in a majority of cases for moderate noise levels. The proposed algorithm is compared to local Gauss-Newton baselines initialized at the dead-reckoned trajectory, and is shown to significantly improve convergence to the problem's global optimum in simulation and experiment. Accompanying software and supplementary material may be found at this https URL .", 'abstract_zh': '基于地标的位置估计中未知数据关联的半定松弛方法：平面环境下的全局优化方法', 'title_zh': '基于半定松弛的全局最优无数据关联地标定位'}
{'arxiv_id': 'arXiv:2504.08438', 'title': 'Diffusion Models for Robotic Manipulation: A Survey', 'authors': 'Rosa Wolf, Yitian Shi, Sheng Liu, Rania Rayyes', 'link': 'https://arxiv.org/abs/2504.08438', 'abstract': 'Diffusion generative models have demonstrated remarkable success in visual domains such as image and video generation. They have also recently emerged as a promising approach in robotics, especially in robot manipulations. Diffusion models leverage a probabilistic framework, and they stand out with their ability to model multi-modal distributions and their robustness to high-dimensional input and output spaces. This survey provides a comprehensive review of state-of-the-art diffusion models in robotic manipulation, including grasp learning, trajectory planning, and data augmentation. Diffusion models for scene and image augmentation lie at the intersection of robotics and computer vision for vision-based tasks to enhance generalizability and data scarcity. This paper also presents the two main frameworks of diffusion models and their integration with imitation learning and reinforcement learning. In addition, it discusses the common architectures and benchmarks and points out the challenges and advantages of current state-of-the-art diffusion-based methods.', 'abstract_zh': '扩散生成模型在视觉领域如图像和视频生成中取得了显著的成功，并 recently emerged as a promising approach in robotics, especially in robot manipulations. 扩散模型利用概率框架，能够建模多模态分布，并在高维输入和输出空间中表现出 robustness。本文综述了扩散模型在机器人 manipulation 领域的最新进展，包括抓取学习、轨迹规划和数据增强。扩散模型在场景和图像增强方面结合了机器人学与计算机视觉，以提高通用性和数据稀缺性。本文还介绍了扩散模型的两大框架及其与模拟学习和强化学习的整合，讨论了常见的架构和基准，并指出了当前基于扩散的方法的挑战和优势。', 'title_zh': '机器人操作中的扩散模型：一项综述'}
{'arxiv_id': 'arXiv:2504.08431', 'title': 'The Composite Visual-Laser Navigation Method Applied in Indoor Poultry Farming Environments', 'authors': 'Jiafan Lu, Dongcheng Hu, Yitian Ye, Anqi Liu, Zixian Zhang, Xin Peng', 'link': 'https://arxiv.org/abs/2504.08431', 'abstract': 'Indoor poultry farms require inspection robots to maintain precise environmental control, which is crucial for preventing the rapid spread of disease and large-scale bird mortality. However, the complex conditions within these facilities, characterized by areas of intense illumination and water accumulation, pose significant challenges. Traditional navigation methods that rely on a single sensor often perform poorly in such environments, resulting in issues like laser drift and inaccuracies in visual navigation line extraction. To overcome these limitations, we propose a novel composite navigation method that integrates both laser and vision technologies. This approach dynamically computes a fused yaw angle based on the real-time reliability of each sensor modality, thereby eliminating the need for physical navigation lines. Experimental validation in actual poultry house environments demonstrates that our method not only resolves the inherent drawbacks of single-sensor systems, but also significantly enhances navigation precision and operational efficiency. As such, it presents a promising solution for improving the performance of inspection robots in complex indoor poultry farming settings.', 'abstract_zh': '室内养禽农场需要使用检测机器人来维持精确的环境控制，这对于预防疾病快速蔓延和大规模禽类死亡至关重要。然而，这些设施内的复杂条件，如强光区域和积水区，提出了重大挑战。传统的依赖单一传感器的导航方法在这种环境中往往表现不佳，导致激光漂移和视觉导航线提取不准确的问题。为此，我们提出了一种新颖的复合导航方法，整合了激光和视觉技术。该方法动态计算基于每个传感器模态实时可靠性的融合偏航角，从而避免了物理导航线的需求。实验验证表明，我们的方法不仅解决了单一传感器系统固有的问题，还显著提高了导航精度和操作效率。因此，它为改善复杂室内养禽农场检测机器人的性能提供了有前景的解决方案。', 'title_zh': '应用于室内养禽环境的复合视觉-激光导航方法'}
{'arxiv_id': 'arXiv:2504.08395', 'title': "Human strategies for correcting `human-robot' errors during a laundry sorting task", 'authors': 'Pepita Barnard, Maria J Galvez Trigo, Dominic Price, Sue Cobb, Gisela Reyes-Cruz, Gustavo Berumen, David Branson III, Mojtaba A. Khanesar, Mercedes Torres Torres, Michel Valstar', 'link': 'https://arxiv.org/abs/2504.08395', 'abstract': "Mental models and expectations underlying human-human interaction (HHI) inform human-robot interaction (HRI) with domestic robots. To ease collaborative home tasks by improving domestic robot speech and behaviours for human-robot communication, we designed a study to understand how people communicated when failure occurs. To identify patterns of natural communication, particularly in response to robotic failures, participants instructed Laundrobot to move laundry into baskets using natural language and gestures. Laundrobot either worked error-free, or in one of two error modes. Participants were not advised Laundrobot would be a human actor, nor given information about error modes. Video analysis from 42 participants found speech patterns, included laughter, verbal expressions, and filler words, such as ``oh'' and ``ok'', also, sequences of body movements, including touching one's own face, increased pointing with a static finger, and expressions of surprise. Common strategies deployed when errors occurred, included correcting and teaching, taking responsibility, and displays of frustration. The strength of reaction to errors diminished with exposure, possibly indicating acceptance or resignation. Some used strategies similar to those used to communicate with other technologies, such as smart assistants. An anthropomorphic robot may not be ideally suited to this kind of task. Laundrobot's appearance, morphology, voice, capabilities, and recovery strategies may have impacted how it was perceived. Some participants indicated Laundrobot's actual skills were not aligned with expectations; this made it difficult to know what to expect and how much Laundrobot understood. Expertise, personality, and cultural differences may affect responses, however these were not assessed.", 'abstract_zh': '人类与人类互动的心理模型和期望对人机互动的影响：以家庭机器人为例——了解失败时的人机沟通方式', 'title_zh': '人类在洗衣分类任务中纠正“人类-机器人”错误的策略'}
{'arxiv_id': 'arXiv:2504.08338', 'title': 'RINGO: Real-time Navigation with a Guiding Trajectory for Aerial Manipulators in Unknown Environments', 'authors': 'Zhang Zhaopeng, Wu Shizhen, Guo Chenfeng, Fang Yongchun, Han Jianda, Liang Xiao', 'link': 'https://arxiv.org/abs/2504.08338', 'abstract': 'Motion planning for aerial manipulators in constrained environments has typically been limited to known environments or simplified to that of multi-rotors, which leads to poor adaptability and overly conservative trajectories. This paper presents RINGO:~Real-time Navigation with a Guiding Trajectory, a novel planning framework that enables aerial manipulators to navigate unknown environments in real time. The proposed method simultaneously considers the positions of both the multi-rotor and the end-effector. A pre-obtained multi-rotor trajectory serves as a guiding reference, allowing the end-effector to generate a smooth, collision-free, and workspace-compatible trajectory. Leveraging the convex hull property of B-spline curves, we theoretically guarantee that the trajectory remains within the reachable workspace. To the best of our knowledge, this is the first work that enables real-time navigation of aerial manipulators in unknown environments. The simulation and experimental results show the effectiveness of the proposed method. The proposed method generates less conservative trajectories than approaches that consider only the multi-rotor.', 'abstract_zh': '基于约束环境的空中 manipulator 运动规划通常局限于已知环境或简化为多旋翼环境，导致适应性差和过于保守的轨迹。本文提出了 RINGO：实时导航与引导轨迹，一种新型规划框架，使空中 manipulator 能够实时导航未知环境。所提出的方法同时考虑多旋翼和末端执行器的位置。预先获得的多旋翼轨迹作为引导参考，使末端执行器生成平滑、无碰撞且工作空间兼容的轨迹。利用 B-样条曲线的凸包性质，我们理论上保证轨迹保持在可达工作空间内。据我们所知，这是第一项使空中 manipulator 能在未知环境中实现实时导航的工作。仿真和实验结果表明所提出方法的有效性。与仅考虑多旋翼的方法相比，所提出的方法生成的轨迹更为保守。', 'title_zh': 'RINGO: 未知环境中超实时导航的引导轨迹方法'}
{'arxiv_id': 'arXiv:2504.08316', 'title': 'Evaluating Pedestrian Risks in Shared Spaces Through Autonomous Vehicle Experiments on a Fixed Track', 'authors': 'Enrico Del Re, Novel Certad, Cristina Olaverri-Monreal', 'link': 'https://arxiv.org/abs/2504.08316', 'abstract': 'The majority of research on safety in autonomous vehicles has been conducted in structured and controlled environments. However, there is a scarcity of research on safety in unregulated pedestrian areas, especially when interacting with public transport vehicles like trams. This study investigates pedestrian responses to an alert system in this context by replicating this real-world scenario in an environment using an autonomous vehicle. The results show that safety measures from other contexts can be adapted to shared spaces with trams, where fixed tracks heighten risks in unregulated crossings.', 'abstract_zh': '自动驾驶车辆在不受管制的人行区域与有轨电车交互的交通安全研究', 'title_zh': '基于固定轨道自主车辆实验评估共享空间中的行人风险'}
{'arxiv_id': 'arXiv:2504.08246', 'title': 'Spectral Normalization for Lipschitz-Constrained Policies on Learning Humanoid Locomotion', 'authors': 'Jaeyong Shin, Woohyun Cha, Donghyeon Kim, Junhyeok Cha, Jaeheung Park', 'link': 'https://arxiv.org/abs/2504.08246', 'abstract': 'Reinforcement learning (RL) has shown great potential in training agile and adaptable controllers for legged robots, enabling them to learn complex locomotion behaviors directly from experience. However, policies trained in simulation often fail to transfer to real-world robots due to unrealistic assumptions such as infinite actuator bandwidth and the absence of torque limits. These conditions allow policies to rely on abrupt, high-frequency torque changes, which are infeasible for real actuators with finite bandwidth.\nTraditional methods address this issue by penalizing aggressive motions through regularization rewards, such as joint velocities, accelerations, and energy consumption, but they require extensive hyperparameter tuning. Alternatively, Lipschitz-Constrained Policies (LCP) enforce finite bandwidth action control by penalizing policy gradients, but their reliance on gradient calculations introduces significant GPU memory overhead. To overcome this limitation, this work proposes Spectral Normalization (SN) as an efficient replacement for enforcing Lipschitz continuity. By constraining the spectral norm of network weights, SN effectively limits high-frequency policy fluctuations while significantly reducing GPU memory usage. Experimental evaluations in both simulation and real-world humanoid robot show that SN achieves performance comparable to gradient penalty methods while enabling more efficient parallel training.', 'abstract_zh': '强化学习（RL）在训练灵活适应的腿部机器人控制器方面显示出了巨大潜力，使其能够直接从经验中学习复杂的运动行为。然而，模拟中训练的策略由于无理假设（如无限的执行器带宽和缺乏扭矩限制）往往无法转移到实际机器人上，这些假设允许策略依赖于急剧、高频率的扭矩变化，而实际具有有限带宽的执行器无法实现这一点。传统方法通过正则化奖励（如关节速度、加速度和能耗）限制激进的动作，但需要大量超参数调优。另一种方法是通过惩罚策略梯度来强制执行有限带宽动作控制的Lipschitz-Constrained Policies（LCP），但其依赖梯度计算导致显著增加GPU内存开销。为克服这一限制，本文提议使用谱规范化（Spectral Normalization，SN）作为Lipschitz连续性的有效替代方法。通过约束网络权重的谱范数，SN有效地限制了高频率策略波动，同时显着减少GPU内存使用。实验评估在仿真和实际人形机器人中均表明，SN在实现与梯度惩罚方法相当的性能的同时，能够实现更高效的并行训练。', 'title_zh': '谱归一化在学习类人行走策略的Lipschitz约束下的应用'}
{'arxiv_id': 'arXiv:2504.08240', 'title': 'InSPE: Rapid Evaluation of Heterogeneous Multi-Modal Infrastructure Sensor Placement', 'authors': 'Zhaoliang Zheng, Yun Zhang, Zongling Meng, Johnson Liu, Xin Xia, Jiaqi Ma', 'link': 'https://arxiv.org/abs/2504.08240', 'abstract': 'Infrastructure sensing is vital for traffic monitoring at safety hotspots (e.g., intersections) and serves as the backbone of cooperative perception in autonomous driving. While vehicle sensing has been extensively studied, infrastructure sensing has received little attention, especially given the unique challenges of diverse intersection geometries, complex occlusions, varying traffic conditions, and ambient environments like lighting and weather. To address these issues and ensure cost-effective sensor placement, we propose Heterogeneous Multi-Modal Infrastructure Sensor Placement Evaluation (InSPE), a perception surrogate metric set that rapidly assesses perception effectiveness across diverse infrastructure and environmental scenarios with combinations of multi-modal sensors. InSPE systematically evaluates perception capabilities by integrating three carefully designed metrics, i.e., sensor coverage, perception occlusion, and information gain. To support large-scale evaluation, we develop a data generation tool within the CARLA simulator and also introduce Infra-Set, a dataset covering diverse intersection types and environmental conditions. Benchmarking experiments with state-of-the-art perception algorithms demonstrate that InSPE enables efficient and scalable sensor placement analysis, providing a robust solution for optimizing intelligent intersection infrastructure.', 'abstract_zh': '基础设施 sensing 对交通安全热点（如交叉路口）的交通监测至关重要，并作为自主驾驶中协同感知的骨干。尽管车辆 sensing 已经得到了广泛研究，但基础设施 sensing 获得了较少的关注，尤其是在面对各异的交叉路口几何结构、复杂的遮挡、变化的交通状况以及如照明和天气等环境因素的独特挑战时。为了解决这些问题并确保传感器布置的成本效益，我们提出了异构多模基础设施 sensor 布置评估 (InSPE)，这是一种能够快速评估跨不同基础设施和环境场景的多模传感器组合感知效果的感知替代评估指标。InSPE 通过集成三项精心设计的指标（即传感器覆盖范围、感知遮挡和信息增益）系统性地评估感知能力。为支持大规模评估，我们开发了 CARLA 模拟器内的数据生成工具，并介绍了涵盖各异交叉路口类型和环境条件的 Infra-Set 数据集。将最先进的感知算法进行基准测试的实验表明，InSPE 可以实现高效且可扩展的 sensor 布置分析，提供一种优化智能交叉路口基础设施的稳健解决方案。', 'title_zh': 'InSPE：异构多模基础设施传感器布置的快速评估'}
{'arxiv_id': 'arXiv:2504.08238', 'title': 'CATCH-FORM-3D: Compliance-Aware Tactile Control and Hybrid Deformation Regulation for 3D Viscoelastic Object Manipulation', 'authors': 'Hongjun Ma, Weichang Li', 'link': 'https://arxiv.org/abs/2504.08238', 'abstract': "This paper investigates a framework (CATCH-FORM-3D) for the precise contact force control and surface deformation regulation in viscoelastic material manipulation. A partial differential equation (PDE) is proposed to model the spatiotemporal stress-strain dynamics, integrating 3D Kelvin-Voigt (stiffness-damping) and Maxwell (diffusion) effects to capture the material's viscoelastic behavior. Key mechanical parameters (stiffness, damping, diffusion coefficients) are estimated in real time via a PDE-driven observer. This observer fuses visual-tactile sensor data and experimentally validated forces to generate rich regressor signals. Then, an inner-outer loop control structure is built up. In the outer loop, the reference deformation is updated by a novel admittance control law, a proportional-derivative (PD) feedback law with contact force measurements, ensuring that the system responds adaptively to external interactions. In the inner loop, a reaction-diffusion PDE for the deformation tracking error is formulated and then exponentially stabilized by conforming the contact surface to analytical geometric configurations (i.e., defining Dirichlet boundary conditions). This dual-loop architecture enables the effective deformation regulation in dynamic contact environments. Experiments using a PaXini robotic hand demonstrate sub-millimeter deformation accuracy and stable force tracking. The framework advances compliant robotic interactions in applications like industrial assembly, polymer shaping, surgical treatment, and household service.", 'abstract_zh': '一种用于粘弹性材料操作的精确接触力控制和表面变形调节框架（CATCH-FORM-3D）', 'title_zh': 'CATCH-FORM-3D：弹性体合规控制与混合变形调节的触觉控制及3D黏弹性物体操作'}
{'arxiv_id': 'arXiv:2504.08232', 'title': 'CATCH-FORM-ACTer: Compliance-Aware Tactile Control and Hybrid Deformation Regulation-Based Action Transformer for Viscoelastic Object Manipulation', 'authors': 'Hongjun Ma, Weichang Li, Jingwei Zhang, Shenlai He, Xiaoyan Deng', 'link': 'https://arxiv.org/abs/2504.08232', 'abstract': 'Automating contact-rich manipulation of viscoelastic objects with rigid robots faces challenges including dynamic parameter mismatches, unstable contact oscillations, and spatiotemporal force-deformation coupling. In our prior work, a Compliance-Aware Tactile Control and Hybrid Deformation Regulation (CATCH-FORM-3D) strategy fulfills robust and effective manipulations of 3D viscoelastic objects, which combines a contact force-driven admittance outer loop and a PDE-stabilized inner loop, achieving sub-millimeter surface deformation accuracy. However, this strategy requires fine-tuning of object-specific parameters and task-specific calibrations, to bridge this gap, a CATCH-FORM-ACTer is proposed, by enhancing CATCH-FORM-3D with a framework of Action Chunking with Transformer (ACT). An intuitive teleoperation system performs Learning from Demonstration (LfD) to build up a long-horizon sensing, decision-making and execution sequences. Unlike conventional ACT methods focused solely on trajectory planning, our approach dynamically adjusts stiffness, damping, and diffusion parameters in real time during multi-phase manipulations, effectively imitating human-like force-deformation modulation. Experiments on single arm/bimanual robots in three tasks show better force fields patterns and thus 10%-20% higher success rates versus conventional methods, enabling precise, safe interactions for industrial, medical or household scenarios.', 'abstract_zh': '基于Transformer的动作切片增强的Compliance-Aware触觉控制和混合变形调节策略（CATCH-FORM-ACTer）：应用于粘弹物体的刚性机器人接触丰富操作自动化', 'title_zh': 'CATCH-FORM-ACTer: 遵从意识触觉控制与混合变形调节驱动的动作变换器在粘弹性物体操作中的应用'}
{'arxiv_id': 'arXiv:2504.08204', 'title': 'II-NVM: Enhancing Map Accuracy and Consistency with Normal Vector-Assisted Mapping', 'authors': 'Chengwei Zhao, Yixuan Li, Yina Jian, Jie Xu, Linji Wang, Yongxin Ma, Xinglai Jin', 'link': 'https://arxiv.org/abs/2504.08204', 'abstract': 'SLAM technology plays a crucial role in indoor mapping and localization. A common challenge in indoor environments is the "double-sided mapping issue", where closely positioned walls, doors, and other surfaces are mistakenly identified as a single plane, significantly hindering map accuracy and consistency. To address this issue this paper introduces a SLAM approach that ensures accurate mapping using normal vector consistency. We enhance the voxel map structure to store both point cloud data and normal vector information, enabling the system to evaluate consistency during nearest neighbor searches and map updates. This process distinguishes between the front and back sides of surfaces, preventing incorrect point-to-plane constraints. Moreover, we implement an adaptive radius KD-tree search method that dynamically adjusts the search radius based on the local density of the point cloud, thereby enhancing the accuracy of normal vector calculations. To further improve realtime performance and storage efficiency, we incorporate a Least Recently Used (LRU) cache strategy, which facilitates efficient incremental updates of the voxel map. The code is released as open-source and validated in both simulated environments and real indoor scenarios. Experimental results demonstrate that this approach effectively resolves the "double-sided mapping issue" and significantly improves mapping precision. Additionally, we have developed and open-sourced the first simulation and real world dataset specifically tailored for the "double-sided mapping issue".', 'abstract_zh': '室内建图与定位中SLAM技术的关键作用与“双面建图问题”的解决方法：基于法向一致性的方法', 'title_zh': 'II-NVM：基于法向量辅助的地图准确性和一致性增强方法'}
{'arxiv_id': 'arXiv:2504.08184', 'title': 'Leveraging Passive Compliance of Soft Robotics for Physical Human-Robot Collaborative Manipulation', 'authors': 'Dallin L. Cordon, Shaden Moss, Marc Killpack, John L. Salmon', 'link': 'https://arxiv.org/abs/2504.08184', 'abstract': 'This work represents an initial benchmark of a large-scale soft robot performing physical, collaborative manipulation of a long, extended object with a human partner. The robot consists of a pneumatically-actuated, three-link continuum soft manipulator mounted to an omni-directional mobile base. The system level configuration of the robot and design of the collaborative manipulation (co-manipulation) study are presented. The initial results, both quantitative and qualitative, are directly compared to previous similar human-human co-manipulation studies. These initial results show promise in the ability for large-scale soft robots to perform comparably to human partners acting as non-visual followers in a co-manipulation task. Furthermore, these results challenge traditional soft robot strength limitations and indicate potential for applications requiring strength and adaptability.', 'abstract_zh': '这项工作代表了对一种大型软机器人进行物理协同操作的初步评估，该机器人与人类伙伴共同操作一个长伸展物体。该机器人由气动驱动的三连杆连续软 manipulator安装在全向移动基座上。介绍了机器人的系统级配置和协作操作（co-manipulation）研究的设计。初始结果，无论是定量的还是定性的，都直接与之前的类似人类-人类协作操作研究进行了比较。这些初始结果表明，大型软机器人有能力在协同操作任务中与作为非视觉跟随者的同人类搭档表现得相媲美。此外，这些结果挑战了传统软机器人的力量限制，表明了在需要力量和适应性的应用中潜在的应用价值。', 'title_zh': '利用软机器人领域的被动合规性进行物理人机协作操作'}
{'arxiv_id': 'arXiv:2504.08172', 'title': 'Enhanced Cooperative Perception Through Asynchronous Vehicle to Infrastructure Framework with Delay Mitigation for Connected and Automated Vehicles', 'authors': 'Nithish Kumar Saravanan, Varun Jammula, Yezhou Yang, Jeffrey Wishart, Junfeng Zhao', 'link': 'https://arxiv.org/abs/2504.08172', 'abstract': "Perception is a key component of Automated vehicles (AVs). However, sensors mounted to the AVs often encounter blind spots due to obstructions from other vehicles, infrastructure, or objects in the surrounding area. While recent advancements in planning and control algorithms help AVs react to sudden object appearances from blind spots at low speeds and less complex scenarios, challenges remain at high speeds and complex intersections. Vehicle to Infrastructure (V2I) technology promises to enhance scene representation for AVs in complex intersections, providing sufficient time and distance to react to adversary vehicles violating traffic rules. Most existing methods for infrastructure-based vehicle detection and tracking rely on LIDAR, RADAR or sensor fusion methods, such as LIDAR-Camera and RADAR-Camera. Although LIDAR and RADAR provide accurate spatial information, the sparsity of point cloud data limits its ability to capture detailed object contours of objects far away, resulting in inaccurate 3D object detection results. Furthermore, the absence of LIDAR or RADAR at every intersection increases the cost of implementing V2I technology. To address these challenges, this paper proposes a V2I framework that utilizes monocular traffic cameras at road intersections to detect 3D objects. The results from the roadside unit (RSU) are then combined with the on-board system using an asynchronous late fusion method to enhance scene representation. Additionally, the proposed framework provides a time delay compensation module to compensate for the processing and transmission delay from the RSU. Lastly, the V2I framework is tested by simulating and validating a scenario similar to the one described in an industry report by Waymo. The results show that the proposed method improves the scene representation and the AV's perception range, giving enough time and space to react to adversary vehicles.", 'abstract_zh': '基于基础设施的单目交通摄像头 vehicle-to-infrastructure (V2I) 框架：提升自动驾驶车辆在复杂交叉口的场景感知', 'title_zh': '通过缓解延迟的异步车基础设施框架增强协作感知技术'}
{'arxiv_id': 'arXiv:2504.08156', 'title': 'External-Wrench Estimation for Aerial Robots Exploiting a Learned Model', 'authors': 'Ayham Alharbat, Gabriele Ruscelli, Roberto Diversi, Abeje Mersha', 'link': 'https://arxiv.org/abs/2504.08156', 'abstract': 'This paper presents an external wrench estimator that uses a hybrid dynamics model consisting of a first-principles model and a neural network. This framework addresses one of the limitations of the state-of-the-art model-based wrench observers: the wrench estimation of these observers comprises the external wrench (e.g. collision, physical interaction, wind); in addition to residual wrench (e.g. model parameters uncertainty or unmodeled dynamics). This is a problem if these wrench estimations are to be used as wrench feedback to a force controller, for example. In the proposed framework, a neural network is combined with a first-principles model to estimate the residual dynamics arising from unmodeled dynamics and parameters uncertainties, then, the hybrid trained model is used to estimate the external wrench, leading to a wrench estimation that has smaller contributions from the residual dynamics, and affected more by the external wrench. This method is validated with numerical simulations of an aerial robot in different flying scenarios and different types of residual dynamics, and the statistical analysis of the results shows that the wrench estimation error has improved significantly compared to a model-based wrench observer using only a first-principles model.', 'abstract_zh': '本文提出了一种使用结合了先验模型和神经网络的混合动力学模型的外部力矩估计器。该框架解决了当前基于模型的力矩观察器的一项局限性：这些观察器的力矩估计不仅包括外部力矩（例如碰撞、物理交互、风），还包含残余力矩（例如模型参数不确定性或未建模动态）。如果这些力矩估计用于力控制器的力矩反馈，这将是一个问题。在所提出的框架中，结合使用先验模型和神经网络来估计由未建模动态和参数不确定性引起的部分运动学差异，然后使用混合训练模型来估计外部力矩，从而使得力矩估计的主要贡献来自于外部力矩，而非残余运动学差异。该方法通过在不同飞行场景和不同类型的残余运动学条件下对飞行机器人进行数值模拟进行了验证，并对结果的统计分析表明，与仅使用先验模型的基于模型的力矩观察器相比，力矩估计误差有了显著改善。', 'title_zh': '基于学习模型的飞行机器人外部力矩估计'}
{'arxiv_id': 'arXiv:2504.08122', 'title': 'Threading the Needle: Test and Evaluation of Early Stage UAS Capabilities to Autonomously Navigate GPS-Denied Environments in the DARPA Fast Lightweight Autonomy (FLA) Program', 'authors': 'Adam Norton, Holly Yanco', 'link': 'https://arxiv.org/abs/2504.08122', 'abstract': 'The DARPA Fast Lightweight Autonomy (FLA) program (2015 - 2018) served as a significant milestone in the development of UAS, particularly for autonomous navigation through unknown GPS-denied environments. Three performing teams developed UAS using a common hardware platform, focusing their contributions on autonomy algorithms and sensing. Several experiments were conducted that spanned indoor and outdoor environments, increasing in complexity over time. This paper reviews the testing methodology developed in order to benchmark and compare the performance of each team, each of the FLA Phase 1 experiments that were conducted, and a summary of the Phase 1 results.', 'abstract_zh': 'DARPA快速轻量级自主（FLA）计划（2015-2018）在无人飞行器自主导航技术发展中的里程碑作用：通过未知GPS受限环境的自主导航。本文回顾了用于评估和比较各参赛团队性能的测试方法，以及FLA第一阶段的所有实验和第一阶段结果的总结。', 'title_zh': '针线活：测试与评估早期阶段自主飞行系统在GPS受限环境中的自主导航能力——DARPA快速轻量级自主（FLA）计划中的研究'}
{'arxiv_id': 'arXiv:2504.08117', 'title': 'Design Activity for Robot Faces: Evaluating Child Responses To Expressive Faces', 'authors': 'Denielle Oliva, Joshua Knight, Tyler J Becker, Heather Amistani, Monica Nicolescu, David Feil-Seifer', 'link': 'https://arxiv.org/abs/2504.08117', 'abstract': "Facial expressiveness plays a crucial role in a robot's ability to engage and interact with children. Prior research has shown that expressive robots can enhance child engagement during human-robot interactions. However, many robots used in therapy settings feature non-personalized, static faces designed with traditional facial feature considerations, which can limit the depth of interactions and emotional connections. Digital faces offer opportunities for personalization, yet the current landscape of robot face design lacks a dynamic, user-centered approach. Specifically, there is a significant research gap in designing robot faces based on child preferences. Instead, most robots in child-focused therapy spaces are developed from an adult-centric perspective. We present a novel study investigating the influence of child-drawn digital faces in child-robot interactions. This approach focuses on a design activity with children instructed to draw their own custom robot faces. We compare the perceptions of social intelligence (PSI) of two implementations: a generic digital face and a robot face, personalized using the user's drawn robot faces. The results of this study show the perceived social intelligence of a child-drawn robot was significantly higher compared to a generic face.", 'abstract_zh': '面部表情在机器人与儿童互动能力中扮演着 crucial 角色。先前的研究表明，富有表情的机器人能够增强儿童在人机交互过程中对机器人的参与度。然而，许多用于治疗场景中的机器人拥有非个性化、静态的脸部设计，这限制了互动的深度以及情感连接。数字脸部提供了个性化的机会，但当前机器人脸部设计的格局缺乏以用户为中心的动力学方法。特别是，在基于儿童偏好设计机器人脸部方面存在显著的研究空白。相反，大多数面向儿童的治疗空间中的机器人是从成人视角开发的。我们提出了一项新的研究，调查儿童绘制的数字脸部对儿童与机器人互动的影响。这种方法侧重于一种设计活动，让儿童绘制他们自己的定制机器人脸部。我们比较了两种实现的社交智能感知（PSI）：一个通用的数字脸和一个使用用户绘制的机器人脸进行个性化的机器人脸。研究结果表明，儿童绘制的机器人脸的感知社交智能显著高于通用脸。', 'title_zh': '机器人脸部设计活动：评价具表现力脸部对儿童的响应'}
{'arxiv_id': 'arXiv:2504.08114', 'title': 'RL-based Control of UAS Subject to Significant Disturbance', 'authors': 'Kousheek Chakraborty, Thijs Hof, Ayham Alharbat, Abeje Mersha', 'link': 'https://arxiv.org/abs/2504.08114', 'abstract': 'This paper proposes a Reinforcement Learning (RL)-based control framework for position and attitude control of an Unmanned Aerial System (UAS) subjected to significant disturbance that can be associated with an uncertain trigger signal. The proposed method learns the relationship between the trigger signal and disturbance force, enabling the system to anticipate and counteract the impending disturbances before they occur. We train and evaluate three policies: a baseline policy trained without exposure to the disturbance, a reactive policy trained with the disturbance but without the trigger signal, and a predictive policy that incorporates the trigger signal as an observation and is exposed to the disturbance during training. Our simulation results show that the predictive policy outperforms the other policies by minimizing position deviations through a proactive correction maneuver. This work highlights the potential of integrating predictive cues into RL frameworks to improve UAS performance.', 'abstract_zh': '基于强化学习的预测控制框架在不确定触发信号关联显著干扰下无人空中系统的位姿控制', 'title_zh': '基于RL的受显著干扰影响的UAS控制'}
{'arxiv_id': 'arXiv:2504.08646', 'title': 'MBE-ARI: A Multimodal Dataset Mapping Bi-directional Engagement in Animal-Robot Interaction', 'authors': 'Ian Noronha, Advait Prasad Jawaji, Juan Camilo Soto, Jiajun An, Yan Gu, Upinder Kaur', 'link': 'https://arxiv.org/abs/2504.08646', 'abstract': 'Animal-robot interaction (ARI) remains an unexplored challenge in robotics, as robots struggle to interpret the complex, multimodal communication cues of animals, such as body language, movement, and vocalizations. Unlike human-robot interaction, which benefits from established datasets and frameworks, animal-robot interaction lacks the foundational resources needed to facilitate meaningful bidirectional communication. To bridge this gap, we present the MBE-ARI (Multimodal Bidirectional Engagement in Animal-Robot Interaction), a novel multimodal dataset that captures detailed interactions between a legged robot and cows. The dataset includes synchronized RGB-D streams from multiple viewpoints, annotated with body pose and activity labels across interaction phases, offering an unprecedented level of detail for ARI research. Additionally, we introduce a full-body pose estimation model tailored for quadruped animals, capable of tracking 39 keypoints with a mean average precision (mAP) of 92.7%, outperforming existing benchmarks in animal pose estimation. The MBE-ARI dataset and our pose estimation framework lay a robust foundation for advancing research in animal-robot interaction, providing essential tools for developing perception, reasoning, and interaction frameworks needed for effective collaboration between robots and animals. The dataset and resources are publicly available at this https URL, inviting further exploration and development in this critical area.', 'abstract_zh': '多模态双向参与动物-机器人交互（Multimodal Bidirectional Engagement in Animal-Robot Interaction）', 'title_zh': 'MBE-ARI：一种多模态数据集，用于映射动物与机器人互动的双向参与'}
{'arxiv_id': 'arXiv:2504.08541', 'title': 'Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset', 'authors': 'Zhao Dong, Ka Chen, Zhaoyang Lv, Hong-Xing Yu, Yunzhi Zhang, Cheng Zhang, Yufeng Zhu, Stephen Tian, Zhengqin Li, Geordie Moffatt, Sean Christofferson, James Fort, Xiaqing Pan, Mingfei Yan, Jiajun Wu, Carl Yuheng Ren, Richard Newcombe', 'link': 'https://arxiv.org/abs/2504.08541', 'abstract': 'We introduce Digital Twin Catalog (DTC), a new large-scale photorealistic 3D object digital twin dataset. A digital twin of a 3D object is a highly detailed, virtually indistinguishable representation of a physical object, accurately capturing its shape, appearance, physical properties, and other attributes. Recent advances in neural-based 3D reconstruction and inverse rendering have significantly improved the quality of 3D object reconstruction. Despite these advancements, there remains a lack of a large-scale, digital twin quality real-world dataset and benchmark that can quantitatively assess and compare the performance of different reconstruction methods, as well as improve reconstruction quality through training or fine-tuning. Moreover, to democratize 3D digital twin creation, it is essential to integrate creation techniques with next-generation egocentric computing platforms, such as AR glasses. Currently, there is no dataset available to evaluate 3D object reconstruction using egocentric captured images. To address these gaps, the DTC dataset features 2,000 scanned digital twin-quality 3D objects, along with image sequences captured under different lighting conditions using DSLR cameras and egocentric AR glasses. This dataset establishes the first comprehensive real-world evaluation benchmark for 3D digital twin creation tasks, offering a robust foundation for comparing and improving existing reconstruction methods. The DTC dataset is already released at this https URL and we will also make the baseline evaluations open-source.', 'abstract_zh': 'Digital Twin Catalog (DTC)：大规模逼真3D对象数字孪生数据集', 'title_zh': '数字孪生目录：一个大规模 photorealistic 3D 对象数字孪生数据集'}
{'arxiv_id': 'arXiv:2504.08531', 'title': 'Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions', 'authors': 'Tommaso Galliena, Tommaso Apicella, Stefano Rosa, Pietro Morerio, Alessio Del Bue, Lorenzo Natale', 'link': 'https://arxiv.org/abs/2504.08531', 'abstract': "We present a self-supervised method to improve an agent's abilities in describing arbitrary objects while actively exploring a generic environment. This is a challenging problem, as current models struggle to obtain coherent image captions due to different camera viewpoints and clutter. We propose a three-phase framework to fine-tune existing captioning models that enhances caption accuracy and consistency across views via a consensus mechanism. First, an agent explores the environment, collecting noisy image-caption pairs. Then, a consistent pseudo-caption for each object instance is distilled via consensus using a large language model. Finally, these pseudo-captions are used to fine-tune an off-the-shelf captioning model, with the addition of contrastive learning. We analyse the performance of the combination of captioning models, exploration policies, pseudo-labeling methods, and fine-tuning strategies, on our manually labeled test set. Results show that a policy can be trained to mine samples with higher disagreement compared to classical baselines. Our pseudo-captioning method, in combination with all policies, has a higher semantic similarity compared to other existing methods, and fine-tuning improves caption accuracy and consistency by a significant margin. Code and test set annotations available at this https URL", 'abstract_zh': '我们提出一种自监督方法，以提高智能体在主动探索通用环境时描述任意对象的能力。这是一个具有挑战性的问题，因为当前模型很难因应不同视角和杂乱环境获得连贯的图像描述。我们提出一个三阶段框架，通过共识机制 fine-tune 存在的描述模型，以增强不同视角下的描述准确性和一致性。首先，智能体探索环境，收集噪声图像-描述对。然后，利用大型语言模型中的共识机制为每个对象实例提取一致的伪描述。最后，这些伪描述用于 fine-tune 现成的描述模型，并结合对比学习。我们在手动标注的测试集中分析了描述模型、探索策略、伪标签方法及 fine-tuning 策略的性能。结果显示，一种策略可以被训练来挖掘比经典基线更高的不一致样本。结合所有策略的伪描述方法在语义相似度上优于其他现有方法，fine-tuning 显著提高了描述的准确性和一致性。代码和测试集注释可在以下网址获取。', 'title_zh': '基于躯体的图像描述：自监督学习代理及其空间连贯的图像描述'}
{'arxiv_id': 'arXiv:2504.08361', 'title': 'SN-LiDAR: Semantic Neural Fields for Novel Space-time View LiDAR Synthesis', 'authors': 'Yi Chen, Tianchen Deng, Wentao Zhao, Xiaoning Wang, Wenqian Xi, Weidong Chen, Jingchuan Wang', 'link': 'https://arxiv.org/abs/2504.08361', 'abstract': 'Recent research has begun exploring novel view synthesis (NVS) for LiDAR point clouds, aiming to generate realistic LiDAR scans from unseen viewpoints. However, most existing approaches do not reconstruct semantic labels, which are crucial for many downstream applications such as autonomous driving and robotic perception. Unlike images, which benefit from powerful segmentation models, LiDAR point clouds lack such large-scale pre-trained models, making semantic annotation time-consuming and labor-intensive. To address this challenge, we propose SN-LiDAR, a method that jointly performs accurate semantic segmentation, high-quality geometric reconstruction, and realistic LiDAR synthesis. Specifically, we employ a coarse-to-fine planar-grid feature representation to extract global features from multi-frame point clouds and leverage a CNN-based encoder to extract local semantic features from the current frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360 demonstrate the superiority of SN-LiDAR in both semantic and geometric reconstruction, effectively handling dynamic objects and large-scale scenes. Codes will be available on this https URL.', 'abstract_zh': 'Recent research has begun exploring novel view synthesis (NVS) for LiDAR point clouds, aiming to generate realistic LiDAR scans from unseen viewpoints. However, most existing approaches do not reconstruct semantic labels, which are crucial for many downstream applications such as autonomous driving and robotic perception. Unlike images, which benefit from powerful segmentation models, LiDAR point clouds lack such large-scale pre-trained models, making semantic annotation time-consuming and labor-intensive. To address this challenge, we propose SN-LiDAR, a method that jointly performs accurate semantic segmentation, high-quality geometric reconstruction, and realistic LiDAR synthesis. Specifically, we employ a coarse-to-fine planar-grid feature representation to extract global features from multi-frame point clouds and leverage a CNN-based encoder to extract local semantic features from the current frame point cloud. Extensive experiments on SemanticKITTI and KITTI-360 demonstrate the superiority of SN-LiDAR in both semantic and geometric reconstruction, effectively handling dynamic objects and large-scale scenes.', 'title_zh': 'SN-LiDAR：语义神经场在新型空间-时间视图LiDAR合成中的应用'}
{'arxiv_id': 'arXiv:2504.08307', 'title': 'DSM: Building A Diverse Semantic Map for 3D Visual Grounding', 'authors': 'Qinghongbing Xie, Zijian Liang, Long Zeng', 'link': 'https://arxiv.org/abs/2504.08307', 'abstract': 'In recent years, with the growing research and application of multimodal large language models (VLMs) in robotics, there has been an increasing trend of utilizing VLMs for robotic scene understanding tasks. Existing approaches that use VLMs for 3D Visual Grounding tasks often focus on obtaining scene information through geometric and visual information, overlooking the extraction of diverse semantic information from the scene and the understanding of rich implicit semantic attributes, such as appearance, physics, and affordance. The 3D scene graph, which combines geometry and language, is an ideal representation method for environmental perception and is an effective carrier for language models in 3D Visual Grounding tasks. To address these issues, we propose a diverse semantic map construction method specifically designed for robotic agents performing 3D Visual Grounding tasks. This method leverages VLMs to capture the latent semantic attributes and relations of objects within the scene and creates a Diverse Semantic Map (DSM) through a geometry sliding-window map construction strategy. We enhance the understanding of grounding information based on DSM and introduce a novel approach named DSM-Grounding. Experimental results show that our method outperforms current approaches in tasks like semantic segmentation and 3D Visual Grounding, particularly excelling in overall metrics compared to the state-of-the-art. In addition, we have deployed this method on robots to validate its effectiveness in navigation and grasping tasks.', 'abstract_zh': '近年来，随着多模态大型语言模型（VLMs）在机器人领域的研究和应用不断增长，利用VLMs进行机器人场景理解任务的趋势也在增加。现有的针对3D视觉定位任务使用VLMs的方法通常侧重于通过几何和视觉信息获取场景信息，忽视了从场景中提取多样化的语义信息以及理解丰富的隐式语义属性，如外观、物理特性和用途。结合几何和语言的3D场景图是环境感知的理想表示方法，并且是3D视觉定位任务中语言模型的有效载体。为了解决这些问题，我们提出了一种针对执行3D视觉定位任务的机器人代理的多样语义地图构建方法。该方法利用VLMs捕获场景中物体的潜在语义属性和关系，并通过几何滑动窗口地图构建策略创建多样语义地图（DSM）。我们基于DSM增强定位信息的理解，并引入了一种名为DSM-Grounding的新方法。实验结果表明，我们的方法在语义分割和3D视觉定位等任务中优于当前的方法，特别是在整体指标方面表现更佳。此外，我们已在机器人上部署了该方法，以验证其在导航和抓取任务中的有效性。', 'title_zh': 'DSM: 构建多元语义地图用于3D视觉定位'}
{'arxiv_id': 'arXiv:2504.08280', 'title': 'PNE-SGAN: Probabilistic NDT-Enhanced Semantic Graph Attention Network for LiDAR Loop Closure Detection', 'authors': 'Xiong Li, Shulei Liu, Xingning Chen, Yisong Wu, Dong Zhu', 'link': 'https://arxiv.org/abs/2504.08280', 'abstract': 'LiDAR loop closure detection (LCD) is crucial for consistent Simultaneous Localization and Mapping (SLAM) but faces challenges in robustness and accuracy. Existing methods, including semantic graph approaches, often suffer from coarse geometric representations and lack temporal robustness against noise, dynamics, and viewpoint changes. We introduce PNE-SGAN, a Probabilistic NDT-Enhanced Semantic Graph Attention Network, to overcome these limitations. PNE-SGAN enhances semantic graphs by using Normal Distributions Transform (NDT) covariance matrices as rich, discriminative geometric node features, processed via a Graph Attention Network (GAT). Crucially, it integrates graph similarity scores into a probabilistic temporal filtering framework (modeled as an HMM/Bayes filter), incorporating uncertain odometry for motion modeling and utilizing forward-backward smoothing to effectively handle ambiguities. Evaluations on challenging KITTI sequences (00 and 08) demonstrate state-of-the-art performance, achieving Average Precision of 96.2\\% and 95.1\\%, respectively. PNE-SGAN significantly outperforms existing methods, particularly in difficult bidirectional loop scenarios where others falter. By synergizing detailed NDT geometry with principled probabilistic temporal reasoning, PNE-SGAN offers a highly accurate and robust solution for LiDAR LCD, enhancing SLAM reliability in complex, large-scale environments.', 'abstract_zh': 'LiDAR 环回闭合检测（LCD）对一致的即时定位与地图构建（SLAM）至关重要，但面临着可靠性和准确性方面的挑战。现有方法，包括语义图方法，常因粗略的几何表示和缺乏对噪声、动力学和视点变化的时域稳健性而受到影响。我们引入了PNE-SGAN，一种概率NDT增强语义图注意力网络，以克服这些限制。PNE-SGAN通过使用Normal Distributions Transform（NDT）协方差矩阵作为丰富的、区分性的几何节点特征，并通过图注意力网络（GAT）进行处理，来增强语义图。关键的是，它将图相似性分数整合到一个概率时域过滤框架中（建模为HMM/Bayes滤波器），并结合了不确定的轨迹进行运动建模，并利用前向-后向平滑来有效处理歧义性。在具有挑战性的KITTI序列（00和08）上的评估显示出最先进的性能，分别实现了96.2%和95.1%的平均查准率。PNE-SGAN在困难的双向环回场景中显著优于现有方法。通过结合详细的NDT几何结构与原理性概率时域推理，PNE-SGAN为LiDAR LCD提供了高精度和稳健的解决方案，增强了复杂大尺度环境下的SLAM可靠性。', 'title_zh': 'PNE-SGAN：概率NDT增强的语义图注意网络的环视闭合检测'}
{'arxiv_id': 'arXiv:2504.08278', 'title': 'Interior Point Differential Dynamic Programming, Redux', 'authors': 'Ming Xu, Stephen Gould, Iman Shames', 'link': 'https://arxiv.org/abs/2504.08278', 'abstract': 'We present IPDDP2, a structure-exploiting algorithm for solving discrete-time, finite horizon optimal control problems with nonlinear constraints. Inequality constraints are handled using a primal-dual interior point formulation and step acceptance for equality constraints follows a line-search filter approach. The iterates of the algorithm are derived under the Differential Dynamic Programming (DDP) framework. Our numerical experiments evaluate IPDDP2 on four robotic motion planning problems. IPDDP2 reliably converges to low optimality error and exhibits local quadratic and global convergence from remote starting points. Notably, we showcase the robustness of IPDDP2 by using it to solve a contact-implicit, joint limited acrobot swing-up problem involving complementarity constraints from a range of initial conditions. We provide a full implementation of IPDDP2 in the Julia programming language.', 'abstract_zh': 'IPDDP2：一种用于求解具有非线性约束的离散时间有限时段最优控制问题的结构利用算法', 'title_zh': '重新审视内部点微分动态规划'}
{'arxiv_id': 'arXiv:2504.08057', 'title': 'Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization', 'authors': 'Constantinos Tsakonas, Konstantinos Chatzilygeroudis', 'link': 'https://arxiv.org/abs/2504.08057', 'abstract': 'Quality-Diversity algorithms have transformed optimization by prioritizing the discovery of diverse, high-performing solutions over a single optimal result. However, traditional Quality-Diversity methods, such as MAP-Elites, rely heavily on predefined behavioral descriptors and complete prior knowledge of the task to define the behavioral space grid, limiting their flexibility and applicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites), a novel Quality-Diversity algorithm that autonomously constructs a structured behavioral space grid using unsupervised learning, eliminating the need for prior task-specific knowledge. At the core of VQ-Elites is the integration of Vector Quantized Variational Autoencoders, which enables the dynamic learning of behavioral descriptors and the generation of a structured, rather than unstructured, behavioral space grid - a significant advancement over existing unsupervised Quality-Diversity approaches. This design establishes VQ-Elites as a flexible, robust, and task-agnostic optimization framework. To further enhance the performance of unsupervised Quality-Diversity algorithms, we introduce two key components: behavioral space bounding and cooperation mechanisms, which significantly improve convergence and performance. We validate VQ-Elites on robotic arm pose-reaching and mobile robot space-covering tasks. The results demonstrate its ability to efficiently generate diverse, high-quality solutions, emphasizing its adaptability, scalability, robustness to hyperparameters, and potential to extend Quality-Diversity optimization to complex, previously inaccessible domains.', 'abstract_zh': '基于向量量化-精英的Quality-Diversity算法：自主构建结构化行为空间网格的新型优化方法', 'title_zh': '基于向量量化精英的无监督和问题无关的质量多样性优化'}
