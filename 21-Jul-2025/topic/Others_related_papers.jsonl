{'arxiv_id': 'arXiv:2507.13613', 'title': 'Conformal Contraction for Robust Nonlinear Control with Distribution-Free Uncertainty Quantification', 'authors': 'Sihang Wei, Melkior Ornik, Hiroyasu Tsukamoto', 'link': 'https://arxiv.org/abs/2507.13613', 'abstract': 'We present a novel robust control framework for continuous-time, perturbed nonlinear dynamical systems with uncertainty that depends nonlinearly on both the state and control inputs. Unlike conventional approaches that impose structural assumptions on the uncertainty, our framework enhances contraction-based robust control with data-driven uncertainty prediction, remaining agnostic to the models of the uncertainty and predictor. We statistically quantify how reliably the contraction conditions are satisfied under dynamics with uncertainty via conformal prediction, thereby obtaining a distribution-free and finite-time probabilistic guarantee for exponential boundedness of the trajectory tracking error. We further propose the probabilistically robust control invariant (PRCI) tube for distributionally robust motion planning, within which the perturbed system trajectories are guaranteed to stay with a finite probability, without explicit knowledge of the uncertainty model. Numerical simulations validate the effectiveness of the proposed robust control framework and the performance of the PRCI tube.', 'abstract_zh': '一种基于数据驱动不确定性预测的连续时间非线性动态系统的新型鲁棒控制框架', 'title_zh': '基于分布-free不确定性量化的一种鲁棒非线性控制收缩校正方法'}
{'arxiv_id': 'arXiv:2507.14077', 'title': 'Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions', 'authors': 'Temiloluwa Prioleau, Baiying Lu, Yanjun Cui', 'link': 'https://arxiv.org/abs/2507.14077', 'abstract': 'Artificial intelligence (AI) algorithms are a critical part of state-of-the-art digital health technology for diabetes management. Yet, access to large high-quality datasets is creating barriers that impede development of robust AI solutions. To accelerate development of transparent, reproducible, and robust AI solutions, we present Glucose-ML, a collection of 10 publicly available diabetes datasets, released within the last 7 years (i.e., 2018 - 2025). The Glucose-ML collection comprises over 300,000 days of continuous glucose monitor (CGM) data with a total of 38 million glucose samples collected from 2500+ people across 4 countries. Participants include persons living with type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support researchers and innovators with using this rich collection of diabetes datasets, we present a comparative analysis to guide algorithm developers with data selection. Additionally, we conduct a case study for the task of blood glucose prediction - one of the most common AI tasks within the field. Through this case study, we provide a benchmark for short-term blood glucose prediction across all 10 publicly available diabetes datasets within the Glucose-ML collection. We show that the same algorithm can have significantly different prediction results when developed/evaluated with different datasets. Findings from this study are then used to inform recommendations for developing robust AI solutions within the diabetes or broader health domain. We provide direct links to each longitudinal diabetes dataset in the Glucose-ML collection and openly provide our code.', 'abstract_zh': '人工 intelligence (AI) 算法是糖尿病管理最新数字健康技术中的关键组成部分。然而，获取大型高质量数据集正成为阻碍稳健AI解决方案开发的障碍。为了加速开发透明、可 reproducing 和稳健的AI解决方案，我们提供了Glucose-ML，一个包含过去7年（即2018-2025）发布的10个公开可用的糖尿病数据集的集合。Glucose-ML集合包含了超过30万个连续葡萄糖监测（CGM）数据日，共有3800万个葡萄糖样本，来自来自4个国家的2500多名参与者，包括1型糖尿病患者、2型糖尿病患者、糖尿病前期患者及无糖尿病患者。为了支持研究人员和创新者使用这一丰富的糖尿病数据集集合，我们提供了一项比较分析，以指导算法开发者进行数据选择。此外，我们还进行了一项用于血糖预测的任务案例研究——这是该领域最常见的AI任务之一。通过这项案例研究，我们为Glucose-ML集合中的所有10个公开可用的糖尿病数据集提供了短期血糖预测基准。研究结果表明，相同的算法在使用不同数据集开发和评估时，其预测结果可以显著不同。本研究的发现被用于制定在糖尿病或更广泛的健康领域内开发稳健AI解决方案的建议。我们直接提供了每个纵向糖尿病数据集的链接，并公开提供了我们的代码。', 'title_zh': 'Glucose-ML: 一种用于开发稳健AI解决方案的纵向糖尿病数据集合'}
{'arxiv_id': 'arXiv:2507.13958', 'title': 'Towards Constraint Temporal Answer Set Programming', 'authors': 'Pedro Cabalar, Martín Diéguez, François Olivier, Torsten Schaub, Igor Stéphan', 'link': 'https://arxiv.org/abs/2507.13958', 'abstract': 'Reasoning about dynamic systems with a fine-grained temporal and numeric resolution presents significant challenges for logic-based approaches like Answer Set Programming (ASP). To address this, we introduce and elaborate upon a novel temporal and constraint-based extension of the logic of Here-and-There and its nonmonotonic equilibrium extension, representing, to the best of our knowledge, the first approach to nonmonotonic temporal reasoning with constraints specifically tailored for ASP. This expressive system is achieved by a synergistic combination of two foundational ASP extensions: the linear-time logic of Here-and-There, providing robust nonmonotonic temporal reasoning capabilities, and the logic of Here-and-There with constraints, enabling the direct integration and manipulation of numeric constraints, among others. This work establishes the foundational logical framework for tackling complex dynamic systems with high resolution within the ASP paradigm.', 'abstract_zh': '基于细粒度时间和数值分辨率的动态系统推理：一种解答集编程特定的非单调时序约束逻辑扩展', 'title_zh': '面向约束时态回答集编程'}
{'arxiv_id': 'arXiv:2507.13956', 'title': "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", 'authors': 'Yutao Jin, Haowen Xiao, Jielei Chu, Fengmao Lv, Yuxiao Li, Tianrui Li', 'link': 'https://arxiv.org/abs/2507.13956', 'abstract': "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's Disease (AD), where early identification and intervention can effectively slow the progression to dementia. However, diagnosing AD remains a significant challenge in neurology due to the confounders caused mainly by the selection bias of multimodal data and the complex relationships between variables. To address these issues, we propose a novel visual-language causal intervention framework named Alzheimer's Disease Prediction with Cross-modal Causal Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language model (LLM) to summarize clinical data under strict templates, maintaining structured text outputs even with incomplete or unevenly distributed datasets. The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI) images and textual data generated by LLM to classify participants into Cognitively Normal (CN), MCI, and AD categories. Because of the presence of confounders, such as neuroimaging artifacts and age-related biomarkers, non-causal models are likely to capture spurious input-output correlations, generating less reliable results. Our framework implicitly eliminates confounders through causal intervention. Experimental results demonstrate the outstanding performance of our method in distinguishing CN/MCI/AD cases, achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The study showcases the potential of integrating causal reasoning with multi-modal learning for neurological disease diagnosis.", 'abstract_zh': '轻度认知损害（MCI）作为阿尔茨海默病（AD）的前驱阶段，早期识别和干预可以有效延缓向痴呆的进展。然而，由于多模态数据的选择偏差和变量之间复杂的相互关系，阿尔茨海默病的诊断仍然是神经学上的一个重大挑战。为解决这些问题，我们提出了一种名为阿尔茨海默病预测与跨模态因果干预（ADPC）的新颖视觉-语言因果干预框架，用于诊断辅助。我们的ADPC利用大规模语言模型（LLM）在严格模板下总结临床数据，即使在不完整或分布不均的数据集下也能保持结构化的文本输出。ADPC模型利用磁共振成像（MRI）、功能性磁共振成像（fMRI）图像和LLM生成的文本数据对参与者进行分类，分为正常认知（CN）、轻度认知损害（MCI）和阿尔茨海默病（AD）类别。由于存在混杂因素，如神经成像伪影和年龄相关的生物标志物，非因果模型可能会捕捉到虚假的输入输出相关性，生成不那么可靠的结果。我们的框架通过因果干预隐式地消除了混杂因素。实验结果表明，我们的方法在区分CN/MCI/AD病例方面具有出色的性能，大多数评估指标上达到了目前最先进的（SOTA）水平。这项研究展示了结合因果推理与多模态学习在神经学疾病诊断中的潜在价值。', 'title_zh': '阿尔茨海默病预测的跨模态因果干预'}
{'arxiv_id': 'arXiv:2507.13846', 'title': 'Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments', 'authors': 'Kathrin Korte, Christian Medeiros Adriano, Sona Ghahremani, Holger Giese', 'link': 'https://arxiv.org/abs/2507.13846', 'abstract': "[Context] Multi-agent reinforcement learning (MARL) has achieved notable success in environments where agents must learn coordinated behaviors. However, transferring knowledge across agents remains challenging in non-stationary environments with changing goals. [Problem] Traditional knowledge transfer methods in MARL struggle to generalize, and agents often require costly retraining to adapt. [Approach] This paper introduces a causal knowledge transfer framework that enables RL agents to learn and share compact causal representations of paths within a non-stationary environment. As the environment changes (new obstacles), agents' collisions require adaptive recovery strategies. We model each collision as a causal intervention instantiated as a sequence of recovery actions (a macro) whose effect corresponds to a causal knowledge of how to circumvent the obstacle while increasing the chances of achieving the agent's goal (maximizing cumulative reward). This recovery action macro is transferred online from a second agent and is applied in a zero-shot fashion, i.e., without retraining, just by querying a lookup model with local context information (collisions). [Results] Our findings reveal two key insights: (1) agents with heterogeneous goals were able to bridge about half of the gap between random exploration and a fully retrained policy when adapting to new environments, and (2) the impact of causal knowledge transfer depends on the interplay between environment complexity and agents' heterogeneous goals.", 'abstract_zh': '多智能体强化学习中的因果知识迁移框架：在非稳定环境中的应用', 'title_zh': '动态环境下多代理强化学习中的因果知识迁移'}
{'arxiv_id': 'arXiv:2507.13825', 'title': 'When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction', 'authors': 'Haoyang Li, Yuming Xu, Yiming Li, Hanmo Liu, Darian Li, Chen Jason Zhang, Lei Chen, Qing Li', 'link': 'https://arxiv.org/abs/2507.13825', 'abstract': "Temporal link prediction in dynamic graphs is a critical task with applications in diverse domains such as social networks, recommendation systems, and e-commerce platforms. While existing Temporal Graph Neural Networks (T-GNNs) have achieved notable success by leveraging complex architectures to model temporal and structural dependencies, they often suffer from scalability and efficiency challenges due to high computational overhead. In this paper, we propose EAGLE, a lightweight framework that integrates short-term temporal recency and long-term global structural patterns. EAGLE consists of a time-aware module that aggregates information from a node's most recent neighbors to reflect its immediate preferences, and a structure-aware module that leverages temporal personalized PageRank to capture the influence of globally important nodes. To balance these attributes, EAGLE employs an adaptive weighting mechanism to dynamically adjust their contributions based on data characteristics. Also, EAGLE eliminates the need for complex multi-hop message passing or memory-intensive mechanisms, enabling significant improvements in efficiency. Extensive experiments on seven real-world temporal graphs demonstrate that EAGLE consistently achieves superior performance against state-of-the-art T-GNNs in both effectiveness and efficiency, delivering more than a 50x speedup over effective transformer-based T-GNNs.", 'abstract_zh': '动态图中的时间链接预测是一项关键任务，应用于社交网络、推荐系统和电子商务平台等多个领域。尽管现有的时序图神经网络（T-GNNs）通过构建复杂的架构来建模时间依赖性和结构性依赖性已经取得了显著的成果，但由于高计算开销，它们往往面临可扩展性和效率的挑战。本文提出了一种轻量级框架EAGLE，结合了短期时间相关性和长期全局结构性模式。EAGLE 包含一个时间感知模块，通过聚合节点最近邻节点的信息来反映其即时偏好；以及一个结构感知模块，利用时空个性化PageRank来捕捉全局重要节点的影响。为了平衡这些特性，EAGLE采用自适应加权机制，根据数据特性动态调整它们的贡献。此外，EAGLE消除了复杂多跳消息传递或计算密集型机制的需要，从而在效率上实现了显著改进。在七个真实世界的时序图上的广泛实验表明，EAGLE在有效性与效率上均优于最先进的T-GNNs，在有效变体变压器基线的T-GNNs上实现了超过50倍的加速。', 'title_zh': '当速度遇见准确性：一种高效且有效的图模型用于时间链接预测'}
{'arxiv_id': 'arXiv:2507.13759', 'title': 'OntView: What you See is What you Meant', 'authors': 'Carlos Bobed, Carlota Quintana, Eduardo Mena, Jorge Bobed, Fernando Bobillo', 'link': 'https://arxiv.org/abs/2507.13759', 'abstract': 'In the field of knowledge management and computer science, ontologies provide a structured framework for modeling domain-specific knowledge by defining concepts and their relationships. However, the lack of tools that provide effective visualization is still a significant challenge. While numerous ontology editors and viewers exist, most of them fail to graphically represent ontology structures in a meaningful and non-overwhelming way, limiting users\' ability to comprehend dependencies and properties within large ontological frameworks.\nIn this paper, we present OntView, an ontology viewer that is designed to provide users with an intuitive visual representation of ontology concepts and their formal definitions through a user-friendly interface. Building on the use of a DL reasoner, OntView follows a "What you see is what you meant" paradigm, showing the actual inferred knowledge. One key aspect for this is its ability to visualize General Concept Inclusions (GCI), a feature absent in existing visualization tools. Moreover, to avoid a possible information overload, OntView also offers different ways to show a simplified view of the ontology by: 1) creating ontology summaries by assessing the importance of the concepts (according to different available algorithms), 2) focusing the visualization on the existing TBox elements between two given classes and 3) allowing to hide/show different branches in a dynamic way without losing the semantics. OntView has been released with an open-source license for the whole community.', 'abstract_zh': '知识管理与计算机科学领域的本体提供了结构化的框架来建模领域特定知识，通过定义概念及其关系。然而，缺乏有效的可视化工具仍然是一个重大挑战。尽管存在多种本体编辑器和查看器，但大多数都未能以有意义且不令人麻木的方式图形化表示本体结构，限制了用户理解大型本体框架中的依赖关系和属性的能力。\n\n本文介绍了一种名为OntView的本体查看器，旨在通过用户友好的界面为用户提供直观的本体概念及其形式定义的可视化表示。基于使用DL推理器，OntView遵循“所见即所想”的原则，展示实际推断的知识。其关键方面在于能够可视化通用概念包含（GCI）这一功能，这是现有可视化工具中所欠缺的。此外，为了防止信息过载，OntView还提供了不同的方式显示简化后的本体视图，包括：1）通过评估概念的重要性（根据不同的可用算法）创建本体摘要；2）将可视化聚焦于两个给定类之间的现有TBox元素；3）允许动态隐藏/显示不同的分支，而不失去语义。OntView已采用开源许可证发布，供整个社区使用。', 'title_zh': 'OntView: 见即所愿'}
{'arxiv_id': 'arXiv:2507.13652', 'title': 'Combining model tracing and constraint-based modeling for multistep strategy diagnoses', 'authors': 'Gerben van der Hoek, Johan Jeuring, Rogier Bos', 'link': 'https://arxiv.org/abs/2507.13652', 'abstract': 'Model tracing and constraint-based modeling are two approaches to diagnose student input in stepwise tasks. Model tracing supports identifying consecutive problem-solving steps taken by a student, whereas constraint-based modeling supports student input diagnosis even when several steps are combined into one step. We propose an approach that merges both paradigms. By defining constraints as properties that a student input has in common with a step of a strategy, it is possible to provide a diagnosis when a student deviates from a strategy even when the student combines several steps. In this study we explore the design of a system for multistep strategy diagnoses, and evaluate these diagnoses. As a proof of concept, we generate diagnoses for an existing dataset containing steps students take when solving quadratic equations (n=2136). To compare with human diagnoses, two teachers coded a random sample of deviations (n=70) and applications of the strategy (n=70). Results show that that the system diagnosis aligned with the teacher coding in all of the 140 student steps.', 'abstract_zh': '模型跟踪和基于约束的建模是两种诊断学生在步进任务中输入的方法。模型跟踪支持识别学生连续的问题解决步骤，而基于约束的建模即使学生将多个步骤合并为一步，也能支持对学生输入的诊断。我们提出了一种结合这两种范式的办法。通过将约束定义为学生输入与策略步骤共有的属性，即使学生合并了多个步骤，也能提供诊断。在此研究中，我们探索了一种用于多步策略诊断系统的架构设计，并评估了这些诊断。作为概念验证，我们为一个包含学生解二次方程步骤的数据集（n=2136）生成了诊断。为了与人工诊断进行比较，两位教师对策略的应用（n=70）和偏差（n=70）进行了编码。结果显示，系统的诊断结果与教师编码完全一致。', 'title_zh': '结合模型跟踪和约束基于建模进行多步策略诊断'}
{'arxiv_id': 'arXiv:2507.13651', 'title': 'Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks', 'authors': 'Gerben van der Hoek, Johan Jeuring, Rogier Bos', 'link': 'https://arxiv.org/abs/2507.13651', 'abstract': 'Many intelligent tutoring systems can support a student in solving a stepwise task. When a student combines several steps in one step, the number of possible paths connecting consecutive inputs may be very large. This combinatorial explosion makes error diagnosis hard. Using a final answer to diagnose a combination of steps can mitigate the combinatorial explosion, because there are generally fewer possible (erroneous) final answers than (erroneous) solution paths. An intermediate input for a task can be diagnosed by automatically completing it according to the task solution strategy and diagnosing this solution. This study explores the potential of automated error diagnosis based on a final answer. We investigate the design of a service that provides a buggy rule diagnosis when a student combines several steps. To validate the approach, we apply the service to an existing dataset (n=1939) of unique student steps when solving quadratic equations, which could not be diagnosed by a buggy rule service that tries to connect consecutive inputs with a single rule. Results show that final answer evaluation can diagnose 29,4% of these steps. Moreover, a comparison of the generated diagnoses with teacher diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the cases. These results can be considered a basis for further exploration of the approach.', 'abstract_zh': '许多智能教学系统可以支持学生解决逐步任务。当学生将多个步骤合并为一步时，连接连续输入的可能路径数量可能会非常大。这种组合爆炸使错误诊断变得困难。使用最终答案进行步骤组合的错误诊断可以减轻组合爆炸，因为通常可能的错误最终答案比错误的解题路径要少。任务中的一个中间输入可以通过根据任务解题策略自动完成并诊断该解题过程来进行诊断。本研究探讨了基于最终答案的自动化错误诊断的潜力。我们研究了一种服务的设计，该服务在学生将多个步骤合并时提供错误规则诊断。为了验证该方法，我们将该服务应用于解决二次方程时产生的唯一学生步骤数据集（n=1939），这些步骤无法由尝试用单一规则连接连续输入的错误规则服务诊断。结果显示，最终答案评估可以诊断其中29.4%的步骤。此外，将生成的诊断与在子集（n=115）上进行的教师诊断进行比较，显示有97%的情况诊断一致。这些结果可以作为进一步探索该方法的基础。', 'title_zh': '通过最终答案评估进行分步任务中错误规则诊断'}
{'arxiv_id': 'arXiv:2507.13558', 'title': "Why Isn't Relational Learning Taking Over the World?", 'authors': 'David Poole', 'link': 'https://arxiv.org/abs/2507.13558', 'abstract': "AI seems to be taking over the world with systems that model pixels, words, and phonemes. The world is arguably made up, not of pixels, words, and phonemes but of entities (objects, things, including events) with properties and relations among them. Surely we should model these, not the perception or description of them. You might suspect that concentrating on modeling words and pixels is because all of the (valuable) data in the world is in terms of text and images. If you look into almost any company you will find their most valuable data is in spreadsheets, databases and other relational formats. These are not the form that are studied in introductory machine learning, but are full of product numbers, student numbers, transaction numbers and other identifiers that can't be interpreted naively as numbers. The field that studies this sort of data has various names including relational learning, statistical relational AI, and many others. This paper explains why relational learning is not taking over the world -- except in a few cases with restricted relations -- and what needs to be done to bring it to it's rightful prominence.", 'abstract_zh': 'AI似乎正在通过建模像素、单词和音素的系统接管世界。世界的本质，或许并非由像素、单词和音素构成，而是由具有属性及其相互关系的实体（对象、事物，包括事件）构成。当然，我们应当建模这些实体及其关系，而不是它们的感知或描述。你可能会怀疑，专注于建模单词和像素是因为世界上所有（有价值的）数据都以文本和图像的形式存在。如果你查看几乎任何一家公司，你会发现它们最宝贵的数据存储在电子表格、数据库和其他关系型格式中。这些数据的形式并未在入门级机器学习中得到研究，但其中包含了产品编号、学生编号、交易编号以及其他不能简单解释为数字的标识符。研究这类数据的领域有着各种名称，包括关系学习、统计关系型AI等。本文解释了为什么关系学习并未接管世界——除了在少数涉及受限关系的情况下——并提出了使其得到应有地位所需采取的措施。', 'title_zh': '为什么关系学习尚未主导世界？'}
{'arxiv_id': 'arXiv:2507.13541', 'title': 'PrefPalette: Personalized Preference Modeling with Latent Attributes', 'authors': 'Shuyue Stella Li, Melanie Sclar, Hunter Lang, Ansong Ni, Jacqueline He, Puxin Xu, Andrew Cohen, Chan Young Park, Yulia Tsvetkov, Asli Celikyilmaz', 'link': 'https://arxiv.org/abs/2507.13541', 'abstract': 'Personalizing AI systems requires understanding not just what users prefer, but the reasons that underlie those preferences - yet current preference models typically treat human judgment as a black box. We introduce PrefPalette, a framework that decomposes preferences into attribute dimensions and tailors its preference prediction to distinct social community values in a human-interpretable manner. PrefPalette operationalizes a cognitive science principle known as multi-attribute decision making in two ways: (1) a scalable counterfactual attribute synthesis step that involves generating synthetic training data to isolate for individual attribute effects (e.g., formality, humor, cultural values), and (2) attention-based preference modeling that learns how different social communities dynamically weight these attributes. This approach moves beyond aggregate preference modeling to capture the diverse evaluation frameworks that drive human judgment. When evaluated on 45 social communities from the online platform Reddit, PrefPalette outperforms GPT-4o by 46.6% in average prediction accuracy. Beyond raw predictive improvements, PrefPalette also shed light on intuitive, community-specific profiles: scholarly communities prioritize verbosity and stimulation, conflict-oriented communities value sarcasm and directness, and support-based communities emphasize empathy. By modeling the attribute-mediated structure of human judgment, PrefPalette delivers both superior preference modeling and transparent, interpretable insights, and serves as a first step toward more trustworthy, value-aware personalized applications.', 'abstract_zh': 'PrefPalette：基于属性维度的社交社区价值观可解释偏好预测框架', 'title_zh': 'PrefPalette: 基于潜在属性的个性化偏好建模'}
{'arxiv_id': 'arXiv:2507.14126', 'title': 'Toward Temporal Causal Representation Learning with Tensor Decomposition', 'authors': 'Jianhong Chen, Meng Zhao, Mostafa Reisi Gahrooei, Xubo Yue', 'link': 'https://arxiv.org/abs/2507.14126', 'abstract': 'Temporal causal representation learning is a powerful tool for uncovering complex patterns in observational studies, which are often represented as low-dimensional time series. However, in many real-world applications, data are high-dimensional with varying input lengths and naturally take the form of irregular tensors. To analyze such data, irregular tensor decomposition is critical for extracting meaningful clusters that capture essential information. In this paper, we focus on modeling causal representation learning based on the transformed information. First, we present a novel causal formulation for a set of latent clusters. We then propose CaRTeD, a joint learning framework that integrates temporal causal representation learning with irregular tensor decomposition. Notably, our framework provides a blueprint for downstream tasks using the learned tensor factors, such as modeling latent structures and extracting causal information, and offers a more flexible regularization design to enhance tensor decomposition. Theoretically, we show that our algorithm converges to a stationary point. More importantly, our results fill the gap in theoretical guarantees for the convergence of state-of-the-art irregular tensor decomposition. Experimental results on synthetic and real-world electronic health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both phenotyping and network recovery perspectives, demonstrate that our proposed method outperforms state-of-the-art techniques and enhances the explainability of causal representations.', 'abstract_zh': '基于转换信息的因果表示学习：一种用于分析高维不规则张量数据的框架', 'title_zh': '基于张量分解的时序因果表示学习'}
{'arxiv_id': 'arXiv:2507.14121', 'title': 'Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective', 'authors': 'Pankaj Yadav, Vivek Vijay', 'link': 'https://arxiv.org/abs/2507.14121', 'abstract': 'Kolmogorov Arnold Networks (KANs) are recent architectural advancement in neural computation that offer a mathematically grounded alternative to standard neural networks. This study presents an empirical evaluation of KANs in context of class imbalanced classification, using ten benchmark datasets. We observe that KANs can inherently perform well on raw imbalanced data more effectively than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However, conventional imbalance strategies fundamentally conflict with KANs mathematical structure as resampling and focal loss implementations significantly degrade KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from prohibitive computational costs without proportional performance gains. Statistical validation confirms that MLPs with imbalance techniques achieve equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs. These findings reveal that KANs represent a specialized solution for raw imbalanced data where resources permit. But their severe performance-resource tradeoffs and incompatibility with standard resampling techniques currently limits practical deployment. We identify critical research priorities as developing KAN specific architectural modifications for imbalance learning, optimizing computational efficiency, and theoretical reconciling their conflict with data augmentation. This work establishes foundational insights for next generation KAN architectures in imbalanced classification scenarios.', 'abstract_zh': 'Kolmogorov Arnold 网络 (KANs) 在样本不平衡分类中的实证评估：资源允许下的原始不平衡数据专业解决方案', 'title_zh': 'Kolmogorov Arnold 网络（KANs）在不平衡数据下的实证研究'}
{'arxiv_id': 'arXiv:2507.14093', 'title': 'Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment', 'authors': 'Šimon Kubov, Simon Klíčník, Jakub Dandár, Zdeněk Straka, Karolína Kvaková, Daniel Kvak', 'link': 'https://arxiv.org/abs/2507.14093', 'abstract': 'Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment decisions depend on precise Cobb angle measurement. Manual assessment is time consuming and subject to inter observer variation. We conducted a retrospective, multi centre evaluation of a fully automated deep learning software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on 103 standing anteroposterior whole spine radiographs collected from ten hospitals. Two musculoskeletal radiologists independently measured each study and served as reference readers. Agreement between the AI and each radiologist was assessed with Bland Altman analysis, mean absolute error (MAE), root mean squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four grade severity classification. Against Radiologist 1 the AI achieved an MAE of 3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59). These results demonstrate that the proposed software reproduces expert level Cobb angle measurements and categorical grading across multiple centres, suggesting its utility for streamlining scoliosis reporting and triage in clinical workflows.', 'abstract_zh': '脊柱侧弯影响约2%至4%的青少年，准确的柯布角测量决定了治疗决策。手工评估耗时且存在观测者间变异。我们回顾性地评估了（Carebot AI Bones, 脊柱测量功能；Carebot s.r.o.）一种全自动深度学习软件在10家医院收集的103张站立前后位完整脊柱X光片上的表现。两位骨关节放射学家独立测量每张X光片，并作为参考读者。使用Bland-Altman分析、平均绝对误差（MAE）、均方根误差（RMSE）、皮尔森相关系数和科恩κ系数来评估软件与每位放射学家之间的同意程度。与放射学家1相比，软件的MAE为3.89度（RMSE 4.77度），偏差为0.70度，置信区间为-8.59至9.99度；与放射学家2相比，软件的MAE为3.90度（RMSE 5.68度），偏差为2.14度，置信区间为-8.23至12.50度。皮尔森相关系数分别为0.906和0.880（观测者间相关系数为0.928），而严重程度分类的科恩κ系数分别为0.51和0.64（观测者间κ系数为0.59）。这些结果表明，所提软件能够多中心再现专家级柯布角测量和分类，建议其在临床工作流程中用于简化脊柱侧弯报告和分流。', 'title_zh': '多中心深学习模型脊柱侧弯评估验证'}
{'arxiv_id': 'arXiv:2507.14084', 'title': 'The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?', 'authors': 'Maria Tsfasman, Ramin Ghorbani, Catholijn M. Jonker, Bernd Dudzik', 'link': 'https://arxiv.org/abs/2507.14084', 'abstract': 'Humans have a selective memory, remembering relevant episodes and forgetting the less relevant information. Possessing awareness of event memorability for a user could help intelligent systems in more accurate user modelling, especially for such applications as meeting support systems, memory augmentation, and meeting summarisation. Emotion recognition has been widely studied, since emotions are thought to signal moments of high personal relevance to users. The emotional experience of situations and their memorability have traditionally been considered to be closely tied to one another: moments that are experienced as highly emotional are considered to also be highly memorable. This relationship suggests that emotional annotations could serve as proxies for memorability. However, existing emotion recognition systems rely heavily on third-party annotations, which may not accurately represent the first-person experience of emotional relevance and memorability. This is why, in this study, we empirically examine the relationship between perceived group emotions (Pleasure-Arousal) and group memorability in the context of conversational interactions. Our investigation involves continuous time-based annotations of both emotions and memorability in dynamic, unstructured group settings, approximating conditions of real-world conversational AI applications such as online meeting support systems. Our results show that the observed relationship between affect and memorability annotations cannot be reliably distinguished from what might be expected under random chance. We discuss the implications of this surprising finding for the development and applications of Affective Computing technology. In addition, we contextualise our findings in broader discourses in the Affective Computing and point out important targets for future research efforts.', 'abstract_zh': '人类具有选择性记忆，记住相关事件并遗忘较少相关的信息。了解用户的事件记忆性意识有助于智能系统更准确地进行用户建模，尤其是在会议支持系统、记忆增强和会议总结等应用中。情绪识别因其被认为是用户个人高度相关的信号而受到了广泛研究。情绪体验的情境及其记忆性一直被认为紧密相关：被体验为高度情绪化的时刻也被认为是高度记忆性的。这种关系表明情绪注释可能作为记忆性的代理。然而，现有的情绪识别系统高度依赖第三方注释，这可能无法准确反映情绪相关性和记忆性的第一人体验。因此，在本研究中，我们实证考察了对话互动中感知群体情绪（愉悦-唤醒）与群体记忆性之间的关系。我们的调查涉及对动态、非结构化群体环境中的情绪和记忆性进行连续的时间基注释，以模拟在线会议支持系统等实际世界对话AI应用的条件。我们的结果表明，观察到的情绪与记忆性注释之间的关系无法可靠地区分出与随机机会所期望的差异。我们讨论了这一出人意料的发现对情感计算技术开发和应用的影响，并在更广泛的讨论中阐述了对未来的研究方向。', 'title_zh': '情绪与记忆的联系：记忆注释对智能系统重要吗？'}
{'arxiv_id': 'arXiv:2507.14079', 'title': 'DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits', 'authors': 'Garapati Keerthana, Manik Gupta', 'link': 'https://arxiv.org/abs/2507.14079', 'abstract': "Progress notes are among the most clinically meaningful artifacts in an Electronic Health Record (EHR), offering temporally grounded insights into a patient's evolving condition, treatments, and care decisions. Despite their importance, they are severely underrepresented in large-scale EHR datasets. For instance, in the widely used Medical Information Mart for Intensive Care III (MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress notes, leaving gaps in longitudinal patient narratives. In contrast, the dataset contains a diverse array of other note types, each capturing different aspects of care.\nWe present DENSE (Documenting Evolving Progress Notes from Scattered Evidence), a system designed to align with clinical documentation workflows by simulating how physicians reference past encounters while drafting progress notes. The system introduces a fine-grained note categorization and a temporal alignment mechanism that organizes heterogeneous notes across visits into structured, chronological inputs. At its core, DENSE leverages a clinically informed retrieval strategy to identify temporally and semantically relevant content from both current and prior visits. This retrieved evidence is used to prompt a large language model (LLM) to generate clinically coherent and temporally aware progress notes.\nWe evaluate DENSE on a curated cohort of patients with multiple visits and complete progress note documentation. The generated notes demonstrate strong longitudinal fidelity, achieving a temporal alignment ratio of $1.089$, surpassing the continuity observed in original notes. By restoring narrative coherence across fragmented documentation, our system supports improved downstream tasks such as summarization, predictive modeling, and clinical decision support, offering a scalable solution for LLM-driven note synthesis in real-world healthcare settings.", 'abstract_zh': '文档化 evolving 进展笔记：基于散落证据的系统(DENSE)', 'title_zh': 'DENSE：纵向病程笔记生成，考虑医院访问期间异质临床笔记的时间建模'}
{'arxiv_id': 'arXiv:2507.14069', 'title': 'Edge Intelligence with Spiking Neural Networks', 'authors': 'Shuiguang Deng, Di Yu, Changze Lv, Xin Du, Linshan Jiang, Xiaofan Zhao, Wentao Tong, Xiaoqing Zheng, Weijia Fang, Peng Zhao, Gang Pan, Schahram Dustdar, Albert Y. Zomaya', 'link': 'https://arxiv.org/abs/2507.14069', 'abstract': 'The convergence of artificial intelligence and edge computing has spurred growing interest in enabling intelligent services directly on resource-constrained devices. While traditional deep learning models require significant computational resources and centralized data management, the resulting latency, bandwidth consumption, and privacy concerns have exposed critical limitations in cloud-centric paradigms. Brain-inspired computing, particularly Spiking Neural Networks (SNNs), offers a promising alternative by emulating biological neuronal dynamics to achieve low-power, event-driven computation. This survey provides a comprehensive overview of Edge Intelligence based on SNNs (EdgeSNNs), examining their potential to address the challenges of on-device learning, inference, and security in edge scenarios. We present a systematic taxonomy of EdgeSNN foundations, encompassing neuron models, learning algorithms, and supporting hardware platforms. Three representative practical considerations of EdgeSNN are discussed in depth: on-device inference using lightweight SNN models, resource-aware training and updating under non-stationary data conditions, and secure and privacy-preserving issues. Furthermore, we highlight the limitations of evaluating EdgeSNNs on conventional hardware and introduce a dual-track benchmarking strategy to support fair comparisons and hardware-aware optimization. Through this study, we aim to bridge the gap between brain-inspired learning and practical edge deployment, offering insights into current advancements, open challenges, and future research directions. To the best of our knowledge, this is the first dedicated and comprehensive survey on EdgeSNNs, providing an essential reference for researchers and practitioners working at the intersection of neuromorphic computing and edge intelligence.', 'abstract_zh': '人工智能与边缘计算的融合推动了在资源受限设备上直接提供智能服务的兴趣增长。传统的深度学习模型需要大量的计算资源和集中式数据管理，而由此产生的延迟、带宽消耗以及隐私担忧暴露了以云为中心范式的關鍵局限性。受大脑启发的计算，特别是突触神经网络（SNNs），通过模拟生物神经元动力学实现低功耗、事件驱动的计算，提供了有前途的替代方案。本文综述了基于SNNs的边缘智能（EdgeSNNs）及其在边缘场景中应对设备上学习、推理和安全挑战的潜力。我们系统地介绍了EdgeSNN的基础，涵盖神经元模型、学习算法和支持的硬件平台。此外，我们深入讨论了EdgeSNN的三个代表性实用考虑：使用轻量级SNN模型进行设备上推理，适应非平稳数据条件下的资源感知训练和更新，以及安全和隐私保护问题。我们还指出了在传统硬件上评估EdgeSNN的局限性，并介绍了一种双轨基准测试策略，以支持公平比较和硬件感知优化。通过本研究，我们旨在弥合受大脑启发的学习与实际边缘部署之间的差距，为神经形态计算和边缘智能的交叉领域提供当前进展、开放挑战和未来研究方向的见解。据我们所知，这是关于EdgeSNNs的第一篇专门且全面的综述，为神经形态计算与边缘智能交叉领域的研究人员和 practitioners 提供了重要的参考资料。', 'title_zh': '边缘智能中的脉冲神经网络'}
{'arxiv_id': 'arXiv:2507.14056', 'title': 'Noradrenergic-inspired gain modulation attenuates the stability gap in joint training', 'authors': 'Alejandro Rodriguez-Garcia, Anindya Ghosh, Srikanth Ramaswamy', 'link': 'https://arxiv.org/abs/2507.14056', 'abstract': 'Recent studies in continual learning have identified a transient drop in performance on mastered tasks when assimilating new ones, known as the stability gap. Such dynamics contradict the objectives of continual learning, revealing a lack of robustness in mitigating forgetting, and notably, persisting even under an ideal joint-loss regime. Examining this gap within this idealized joint training context is critical to isolate it from other sources of forgetting. We argue that it reflects an imbalance between rapid adaptation and robust retention at task boundaries, underscoring the need to investigate mechanisms that reconcile plasticity and stability within continual learning frameworks. Biological brains navigate a similar dilemma by operating concurrently on multiple timescales, leveraging neuromodulatory signals to modulate synaptic plasticity. However, artificial networks lack native multitimescale dynamics, and although optimizers like momentum-SGD and Adam introduce implicit timescale regularization, they still exhibit stability gaps. Inspired by locus coeruleus mediated noradrenergic bursts, which transiently enhance neuronal gain under uncertainty to facilitate sensory assimilation, we propose uncertainty-modulated gain dynamics - an adaptive mechanism that approximates a two-timescale optimizer and dynamically balances integration of knowledge with minimal interference on previously consolidated information. We evaluate our mechanism on domain-incremental and class-incremental variants of the MNIST and CIFAR benchmarks under joint training, demonstrating that uncertainty-modulated gain dynamics effectively attenuate the stability gap. Finally, our analysis elucidates how gain modulation replicates noradrenergic functions in cortical circuits, offering mechanistic insights into reducing stability gaps and enhance performance in continual learning tasks.', 'abstract_zh': '近期关于持续学习的研究发现，在吸收新任务时已掌握任务的性能会出现短暂下降，这种现象被称为稳定性缺口。这种动态与持续学习的目标相矛盾，暴露出在减轻遗忘方面缺乏稳健性，并且即使在理想的联合损失范式下仍然存在。在这一理想化的联合训练背景下考察这一缺口对于将其与其他遗忘来源区分开来至关重要。我们认为这反映了在任务边界处快速适应与稳健保持之间的不平衡，强调了在持续学习框架内研究兼具可塑性和稳定性的机制的必要性。生物大脑通过同时在多个时间尺度上运行并利用神经调控信号来调节突触可塑性来应对类似的困境。然而，人工网络缺乏内在的多时间尺度动态，尽管动量-SGD和Adam等优化器引入了隐式的时标正则化，但仍表现出稳定性缺口。受蓝斑介导的去甲肾上腺素爆发的启发，在不确定性下暂时提高神经元增益以促进感觉吸收，我们提出了一种不确定性调节增益动态机制，这是一种近似两时间尺度优化器的自适应机制，并能动态平衡知识的整合与对先前巩固信息的最小干扰。我们在联合训练下的MNIST和CIFAR增量域和增量类基准上评估了我们的机制，证明了不确定性调节增益动态有效地减小了稳定性缺口。最后，我们的分析阐明了增益调节如何在皮层回路中复制去甲肾上腺素的功能，并为减少稳定性缺口和改善持续学习任务的性能提供了机制性见解。', 'title_zh': '去甲肾上腺素启发的增益调节减轻联合训练中的稳定性差距'}
{'arxiv_id': 'arXiv:2507.13913', 'title': 'Political Leaning and Politicalness Classification of Texts', 'authors': 'Matous Volf, Jakub Simko', 'link': 'https://arxiv.org/abs/2507.13913', 'abstract': 'This paper addresses the challenge of automatically classifying text according to political leaning and politicalness using transformer models. We compose a comprehensive overview of existing datasets and models for these tasks, finding that current approaches create siloed solutions that perform poorly on out-of-distribution texts. To address this limitation, we compile a diverse dataset by combining 12 datasets for political leaning classification and creating a new dataset for politicalness by extending 18 existing datasets with the appropriate label. Through extensive benchmarking with leave-one-in and leave-one-out methodologies, we evaluate the performance of existing models and train new ones with enhanced generalization capabilities.', 'abstract_zh': '本文利用变压器模型自动分类根据政治倾向和政治性对文本进行分类，面临着挑战。我们对这些任务现有的数据集和模型进行了全面综述，发现当前的方法创建了孤立的解决方案，在处理未见过分布的文本时表现较差。为了解决这一局限，我们通过组合12个政治倾向分类数据集，并通过扩展18个现有数据集以添加适当的标签来创建一个新的政治性数据集，来构建一个多样化的数据集。通过使用leave-one-in和leave-one-out的方法进行广泛的基准测试，我们评估了现有模型的性能，并训练了具有增强泛化能力的新模型。', 'title_zh': '政治倾向与文本的政治化分类'}
{'arxiv_id': 'arXiv:2507.13912', 'title': 'Self-supervised learning on gene expression data', 'authors': 'Kevin Dradjat, Massinissa Hamidi, Pierre Bartet, Blaise Hanczar', 'link': 'https://arxiv.org/abs/2507.13912', 'abstract': 'Predicting phenotypes from gene expression data is a crucial task in biomedical research, enabling insights into disease mechanisms, drug responses, and personalized medicine. Traditional machine learning and deep learning rely on supervised learning, which requires large quantities of labeled data that are costly and time-consuming to obtain in the case of gene expression data. Self-supervised learning has recently emerged as a promising approach to overcome these limitations by extracting information directly from the structure of unlabeled data. In this study, we investigate the application of state-of-the-art self-supervised learning methods to bulk gene expression data for phenotype prediction. We selected three self-supervised methods, based on different approaches, to assess their ability to exploit the inherent structure of the data and to generate qualitative representations which can be used for downstream predictive tasks. By using several publicly available gene expression datasets, we demonstrate how the selected methods can effectively capture complex information and improve phenotype prediction accuracy. The results obtained show that self-supervised learning methods can outperform traditional supervised models besides offering significant advantage by reducing the dependency on annotated data. We provide a comprehensive analysis of the performance of each method by highlighting their strengths and limitations. We also provide recommendations for using these methods depending on the case under study. Finally, we outline future research directions to enhance the application of self-supervised learning in the field of gene expression data analysis. This study is the first work that deals with bulk RNA-Seq data and self-supervised learning.', 'abstract_zh': '从基因表达数据预测表型是生物医学研究中的一个关键任务，有助于了解疾病机制、药物反应和个人化医疗。传统的机器学习和深度学习依赖于监督学习，这需要大量成本高昂且耗时的标记数据，而在基因表达数据的情况下尤为如此。最近，自监督学习作为一种有前途的方法出现，通过直接从未标记数据的结构中提取信息来克服这些限制。在本研究中，我们调查了使用最先进的自监督学习方法对批量基因表达数据进行表型预测的应用。我们选择了三种基于不同方法的自监督方法，以评估其利用数据内在结构的能力以及生成可用于下游预测任务的定性表示的能力。通过使用几个公开可用的基因表达数据集，我们展示了所选方法如何有效地捕捉复杂信息并提高表型预测准确性。获得的结果表明，自监督学习方法不仅能够超越传统监督模型，而且还通过减少对标注数据的依赖提供了显著优势。我们对每种方法的性能进行了全面分析，强调了它们的优势和局限性。我们还根据研究案例提供了使用这些方法的建议。最后，我们概述了未来的研究方向，以增强自监督学习在基因表达数据分析领域的应用。这是首次处理批量RNA-Seq数据和自监督学习的工作。', 'title_zh': '自主学习在基因表达数据中的应用'}
{'arxiv_id': 'arXiv:2507.13834', 'title': 'Scalable Submodular Policy Optimization via Pruned Submodularity Graph', 'authors': 'Aditi Anand, Suman Banerjee, Dildar Ali', 'link': 'https://arxiv.org/abs/2507.13834', 'abstract': 'In Reinforcement Learning (abbreviated as RL), an agent interacts with the environment via a set of possible actions, and a reward is generated from some unknown distribution. The task here is to find an optimal set of actions such that the reward after a certain time step gets maximized. In a traditional setup, the reward function in an RL Problem is considered additive. However, in reality, there exist many problems, including path planning, coverage control, etc., the reward function follows the diminishing return, which can be modeled as a submodular function. In this paper, we study a variant of the RL Problem where the reward function is submodular, and our objective is to find an optimal policy such that this reward function gets maximized. We have proposed a pruned submodularity graph-based approach that provides a provably approximate solution in a feasible computation time. The proposed approach has been analyzed to understand its time and space requirements as well as a performance guarantee. We have experimented with a benchmark agent-environment setup, which has been used for similar previous studies, and the results are reported. From the results, we observe that the policy obtained by our proposed approach leads to more reward than the baseline methods.', 'abstract_zh': '在强化学习中，代理通过一系列可能的动作与环境互动，并从未知分布中生成奖励。任务是在某个时间步后使奖励最大化，找到最优动作集。在传统设置中，强化学习问题中的奖励函数被认为是可加的。然而，在现实中有许多问题，如路径规划、覆盖控制等，奖励函数遵循递减回报规律，可以建模为亚模函数。本文研究了奖励函数为亚模函数的强化学习问题变体，目标是找到使该奖励函数最大化的优势策略。我们提出了一种剪枝亚模性图为基础的方法，能够在合理的时间内提供可证明近似解。该方法已被分析以理解其时间与空间要求以及性能保证。我们使用了一个基准代理-环境设置进行实验，该设置在之前类似研究中被使用，并报告了实验结果。结果显示，我们提出的方法获得的策略产生的奖励超过了基线方法。', 'title_zh': '可扩展的子模性政策优化方法：剪枝子模性图'}
{'arxiv_id': 'arXiv:2507.13802', 'title': 'Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database', 'authors': 'Nehir Kizililsoley, Floor van Meer, Osman Mutlu, Wouter F Hoenderdaal, Rosan G. Hobé, Wenjuan Mu, Arjen Gerssen, H.J. van der Fels-Klerx, Ákos Jóźwiak, Ioannis Manikas, Ali Hürriyetoǧlu, Bas H.M. van der Velden', 'link': 'https://arxiv.org/abs/2507.13802', 'abstract': 'In the European Union, official food safety monitoring data collected by member states are submitted to the European Food Safety Authority (EFSA) and published on Zenodo. This data includes 392 million analytical results derived from over 15.2 million samples covering more than 4,000 different types of food products, offering great opportunities for artificial intelligence to analyze trends, predict hazards, and support early warning systems. However, the current format with data distributed across approximately 1000 files totaling several hundred gigabytes hinders accessibility and analysis. To address this, we introduce the CompreHensive European Food Safety (CHEFS) database, which consolidates EFSA monitoring data on pesticide residues, veterinary medicinal product residues, and chemical contaminants into a unified and structured dataset. We describe the creation and structure of the CHEFS database and demonstrate its potential by analyzing trends in European food safety monitoring data from 2000 to 2024. Our analyses explore changes in monitoring activities, the most frequently tested products, which products were most often non-compliant and which contaminants were most often found, and differences across countries. These findings highlight the CHEFS database as both a centralized data source and a strategic tool for guiding food safety policy, research, and regulation.', 'abstract_zh': '欧盟全面食品安全数据库：整合欧洲食品安全局监测数据以支持人工智能分析和政策指导', 'title_zh': '欧洲食品安全趋势分析：CompreHensive European Food Safety (CHEFS) 数据库3920万条记录的洞察'}
{'arxiv_id': 'arXiv:2507.13789', 'title': 'Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI', 'authors': 'Kyriakos Flouris, Moritz Halter, Yolanne Y. R. Lee, Samuel Castonguay, Luuk Jacobs, Pietro Dirix, Jonathan Nestmann, Sebastian Kozerke, Ender Konukoglu', 'link': 'https://arxiv.org/abs/2507.13789', 'abstract': 'Hemodynamic analysis is essential for predicting aneurysm rupture and guiding treatment. While magnetic resonance flow imaging enables time-resolved volumetric blood velocity measurements, its low spatiotemporal resolution and signal-to-noise ratio limit its diagnostic utility. To address this, we propose the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that enhances both spatial and temporal resolution with the ability to predict wall shear stress (WSS) directly from clinical imaging data. LoFNO integrates Laplacian eigenvectors as geometric priors for improved structural awareness on irregular, unseen geometries and employs an Enhanced Deep Super-Resolution Network (EDSR) layer for robust upsampling. By combining geometric priors with neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow data, achieving superior velocity and WSS predictions compared to interpolation and alternative deep learning methods, enabling more precise cerebrovascular diagnostics.', 'abstract_zh': '血流动力学分析对于预测动脉瘤破裂和指导治疗至关重要。尽管磁共振流成像能够进行时间解析的体积血液速度测量，但由于其较低的空间-时间分辨率和信噪比，其诊断用途受到限制。为了解决这一问题，我们提出了一种新型的3D架构——局部傅里叶神经算子（LoFNO），它能够增强空间和时间分辨率，并能够直接从临床影像数据中预测壁剪应力（WSS）。LoFNO将Laplacian特征向量作为几何先验，用于改善对不规则、未见过的几何结构的结构认知，并采用增强的深度超分辨率网络（EDSR）层进行稳健的上采样。通过结合几何先验与神经算子框架，LoFNO对流数据进行去噪和空间-时间上采样，实现了与插值和替代深度学习方法相比更优的速度和WSS预测，从而提高了脑血管诊断的精确性。', 'title_zh': '局部化FNO在动脉瘤MRI中用于时空血流动力学上采样'}
{'arxiv_id': 'arXiv:2507.13769', 'title': 'Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction', 'authors': 'Mingyang Yu, Zhijian Wu, Dingjiang Huang', 'link': 'https://arxiv.org/abs/2507.13769', 'abstract': 'Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its degraded 2D measurements. Recently great progress has been made in deep learning-based methods, however, these methods often struggle to accurately capture high-frequency details of the HSI. To address this issue, this paper proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from hyperspectral images using a diffusion model. Leveraging the powerful ability of the diffusion model to reconstruct details, this learned prior can significantly improve the performance when injected into the HSI model. To further improve the effectiveness of the learned prior, we also propose the Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover the HSI details. We evaluate our method on two representative HSI methods: MST and BISRNet. Experimental results show that our method outperforms existing networks by about 0.5 dB, effectively improving the performance of HSI reconstruction.', 'abstract_zh': '高光谱图像（HSI）恢复旨在从退化的2D测量中恢复3D HSI。近期基于深度学习的方法取得了显著进展，但这些方法往往难以准确捕捉HSI的高频细节。为解决这一问题，本文提出了一种隐式学习自高光谱图像的光谱扩散先验（SDP），利用扩散模型的强大重建细节能力，该学习先验在注入到HSI模型中时能显著提升性能。为了进一步提高学习先验的有效性，本文还提出了光谱先验注入模块（SPIM）以动态引导模型恢复HSI的细节。我们在两种代表性HSI方法：MST和BISRNet上评估了该方法。实验结果表明，与现有网络相比，我们的方法在性能上提升了约0.5 dB，有效提高了HSI恢复的效果。', 'title_zh': '学习谱扩散先验用于高光谱图像重建'}
{'arxiv_id': 'arXiv:2507.13742', 'title': 'Search-Optimized Quantization in Biomedical Ontology Alignment', 'authors': 'Oussama Bouaggad, Natalia Grabar', 'link': 'https://arxiv.org/abs/2507.13742', 'abstract': 'In the fast-moving world of AI, as organizations and researchers develop more advanced models, they face challenges due to their sheer size and computational demands. Deploying such models on edge devices or in resource-constrained environments adds further challenges related to energy consumption, memory usage and latency. To address these challenges, emerging trends are shaping the future of efficient model optimization techniques. From this premise, by employing supervised state-of-the-art transformer-based models, this research introduces a systematic method for ontology alignment, grounded in cosine-based semantic similarity between a biomedical layman vocabulary and the Unified Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to search for target optimizations among different Execution Providers (EPs) using the ONNX Runtime backend, followed by an assembled process of dynamic quantization employing Intel Neural Compressor and IPEX (Intel Extension for PyTorch). Through our optimization process, we conduct extensive assessments on the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new state-of-the-art in both. We retain performance metrics intact, while attaining an average inference speed-up of 20x and reducing memory usage by approximately 70%.', 'abstract_zh': '在快速发展的AI领域，随着组织和研究人员开发出更先进的模型，他们面临着由于模型的巨大规模和计算需求所带来的挑战。将这些模型部署在边缘设备或资源受限的环境中，进一步增加了与能耗、内存使用和延迟相关的问题。为了应对这些挑战，新兴趋势正在塑造高效模型优化技术的未来。在此基础上，通过采用监督学习的最先进的变压器模型，本研究介绍了一种系统的方法来进行本体对齐，该方法基于生物医学通俗词汇与统一医疗语言系统（UMLS）梅达索拉斯之间的余弦相似度。该研究利用Microsoft Olive在不同的执行提供者（EPs）之间搜索目标优化，并通过ONNX Runtime后端，结合使用Intel Neural Compressor和IPEX（Intel扩展的PyTorch）进行动态量化。通过我们的优化过程，我们在DEFT 2020评估竞选中的两个任务上进行了广泛评估，实现了两项新的最佳性能。我们保持了性能指标的完整性，同时实现了平均推理速度提升20倍，并将内存使用量减少了约70%。', 'title_zh': '搜索优化量化在生物医学本体对齐中的应用'}
{'arxiv_id': 'arXiv:2507.13741', 'title': 'SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification', 'authors': 'Shangyou Wang, Zezhong Ding, Xike Xie', 'link': 'https://arxiv.org/abs/2507.13741', 'abstract': 'Graph Neural Networks (GNNs) have shown remarkable success in graph classification tasks by capturing both structural and feature-based representations. However, real-world graphs often exhibit two critical forms of imbalance: class imbalance and graph size imbalance. These imbalances can bias the learning process and degrade model performance. Existing methods typically address only one type of imbalance or incur high computational costs. In this work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning framework that effectively mitigates both class and graph size imbalance. SamGoG constructs multiple GoGs through an efficient importance-based sampling mechanism and trains on them sequentially. This sampling mechanism incorporates the learnable pairwise similarity and adaptive GoG node degree to enhance edge homophily, thus improving downstream model quality. SamGoG can seamlessly integrate with various downstream GNNs, enabling their efficient adaptation for graph classification tasks. Extensive experiments on benchmark datasets demonstrate that SamGoG achieves state-of-the-art performance with up to a 15.66% accuracy improvement with 6.7$\\times$ training acceleration.', 'abstract_zh': '基于采样的Graph-of-Graphs (GoG) 学习框架：同时缓解类别不平衡和图大小不平衡', 'title_zh': 'SamGoG: 一种基于采样的图集合分类框架，用于不平衡图分类'}
{'arxiv_id': 'arXiv:2507.13725', 'title': 'Point of Interest Recommendation: Pitfalls and Viable Solutions', 'authors': 'Alejandro Bellogín, Linus W. Dietz, Francesco Ricci, Pablo Sánchez', 'link': 'https://arxiv.org/abs/2507.13725', 'abstract': "Point of interest (POI) recommendation can play a pivotal role in enriching tourists' experiences by suggesting context-dependent and preference-matching locations and activities, such as restaurants, landmarks, itineraries, and cultural attractions. Unlike some more common recommendation domains (e.g., music and video), POI recommendation is inherently high-stakes: users invest significant time, money, and effort to search, choose, and consume these suggested POIs. Despite the numerous research works in the area, several fundamental issues remain unresolved, hindering the real-world applicability of the proposed approaches. In this paper, we discuss the current status of the POI recommendation problem and the main challenges we have identified. The first contribution of this paper is a critical assessment of the current state of POI recommendation research and the identification of key shortcomings across three main dimensions: datasets, algorithms, and evaluation methodologies. We highlight persistent issues such as the lack of standardized benchmark datasets, flawed assumptions in the problem definition and model design, and inadequate treatment of biases in the user behavior and system performance. The second contribution is a structured research agenda that, starting from the identified issues, introduces important directions for future work related to multistakeholder design, context awareness, data collection, trustworthiness, novel interactions, and real-world evaluation.", 'abstract_zh': '兴趣点（POI）推荐在丰富游客体验方面可以发挥关键作用，通过建议上下文依赖性和偏好匹配的位置和活动，如餐厅、地标、行程和文化景点。与一些更常见的推荐领域（例如音乐和视频）不同，POI推荐本质上风险较高：用户在搜索、选择和消费这些建议的POI上投入了大量时间、金钱和努力。尽管该领域已经进行了大量研究，但仍存在一些基础问题，阻碍了所提出方法的实际应用。在本文中，我们讨论了POI推荐问题的现状以及我们所识别的主要挑战。本文的第一个贡献是对当前POI推荐研究状态进行批判性评估，并在三个主要维度上识别关键不足之处：数据集、算法和评估方法。我们强调了持续存在的问题，如缺乏标准化基准数据集、问题定义和模型设计中的错误假设，以及用户行为和系统性能中的偏见处理不足。本文的第二个贡献是一个结构化研究议程，从识别的问题出发，引入了多利益相关者设计、情境意识、数据收集、可信度、新型交互和现实世界评估等相关未来工作的重要方向。', 'title_zh': '兴趣点推荐：潜在问题与可行解决方案'}
{'arxiv_id': 'arXiv:2507.13569', 'title': 'Change of Thought: Adaptive Test-Time Computation', 'authors': 'Mrinal Mathur, Mike Doan, Barak Pearlmutter, Sergey Plis', 'link': 'https://arxiv.org/abs/2507.13569', 'abstract': 'Transformers evaluated in a single, fixed-depth pass are provably limited in expressive power to the constant-depth circuit class TC0. Running a Transformer autoregressively removes that ceiling -- first in next-token prediction and, more recently, in chain-of-thought reasoning. Both regimes rely on feedback loops that decode internal states into tokens only to re-encode them in subsequent steps. While this "thinking aloud" mirrors human reasoning, biological brains iterate without externalising intermediate states as language. To boost the expressive power of encoder Transformers without resorting to token-level autoregression, we introduce the SELF-Transformer: an encoder layer that iteratively refines its own attention weights to a fixed point. Instead of producing -- in one pass -- the alignment matrix that remixes the input sequence, the SELF-Transformer iteratively updates that matrix internally, scaling test-time computation with input difficulty. This adaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without increasing parameter count, demonstrating that input-adaptive alignment at test time offers substantial benefits for only a modest extra compute budget. Self-Transformers thus recover much of the expressive power of iterative reasoning while preserving the simplicity of pure encoder architectures.', 'abstract_zh': 'SELF-Transformer: Iteratively Refining Attention Weights for Enhanced Expressive Power Without Token-Level Autoregression', 'title_zh': '思想变换：自适应测试时计算'}
{'arxiv_id': 'arXiv:2507.13556', 'title': 'Time Series Forecastability Measures', 'authors': 'Rui Wang, Steven Klee, Alexis Roos', 'link': 'https://arxiv.org/abs/2507.13556', 'abstract': 'This paper proposes using two metrics to quantify the forecastability of time series prior to model development: the spectral predictability score and the largest Lyapunov exponent. Unlike traditional model evaluation metrics, these measures assess the inherent forecastability characteristics of the data before any forecast attempts. The spectral predictability score evaluates the strength and regularity of frequency components in the time series, whereas the Lyapunov exponents quantify the chaos and stability of the system generating the data. We evaluated the effectiveness of these metrics on both synthetic and real-world time series from the M5 forecast competition dataset. Our results demonstrate that these two metrics can correctly reflect the inherent forecastability of a time series and have a strong correlation with the actual forecast performance of various models. By understanding the inherent forecastability of time series before model training, practitioners can focus their planning efforts on products and supply chain levels that are more forecastable, while setting appropriate expectations or seeking alternative strategies for products with limited forecastability.', 'abstract_zh': '本文提出使用两种指标在模型开发前量化时间序列的可预测性：谱可预测性分数和最大路易普朗伏指数。这些措施评估数据本身的可预测性特征，而不像传统的模型评估指标那样在任何预测尝试之后进行评估。谱可预测性分数评估时间序列中频率分量的强度和规律性，而路易普朗伏指数量化产生数据的系统的混沌性和稳定性。我们通过M5预测竞赛数据集中的合成时间和实际时间序列评估了这些指标的有效性。结果显示，这两种指标能够正确反映时间序列的内在可预测性，并与各种模型的实际预测性能有很强的相关性。通过在模型训练前理解时间序列的内在可预测性，实践者可以将规划努力集中在更具可预测性的产品和供应链层面，同时为可预测性有限的产品设定适当的预期或寻求替代策略。', 'title_zh': '时间序列可预测性度量'}
{'arxiv_id': 'arXiv:2507.13551', 'title': 'Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder', 'authors': 'Feng Chen, Weizhe Xu, Changye Li, Serguei Pakhomov, Alex Cohen, Simran Bhola, Sandy Yin, Sunny X Tang, Michael Mackinley, Lena Palaniyappan, Dror Ben-Zeev, Trevor Cohen', 'link': 'https://arxiv.org/abs/2507.13551', 'abstract': 'Formal thought disorder (FTD), a hallmark of schizophrenia spectrum disorders, manifests as incoherent speech and poses challenges for clinical assessment. Traditional clinical rating scales, though validated, are resource-intensive and lack scalability. Automated speech analysis with automatic speech recognition (ASR) allows for objective quantification of linguistic and temporal features of speech, offering scalable alternatives. The use of utterance timestamps in ASR captures pause dynamics, which are thought to reflect the cognitive processes underlying speech production. However, the utility of integrating these ASR-derived features for assessing FTD severity requires further evaluation. This study integrates pause features with semantic coherence metrics across three datasets: naturalistic self-recorded diaries (AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream narratives (PsyCL, n = 43). We evaluated pause related features alongside established coherence measures, using support vector regression (SVR) to predict clinical FTD scores. Key findings demonstrate that pause features alone robustly predict the severity of FTD. Integrating pause features with semantic coherence metrics enhanced predictive performance compared to semantic-only models, with integration of independent models achieving correlations up to \\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best \\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance gains from semantic and pause features integration held consistently across all contexts, though the nature of pause patterns was dataset-dependent. These findings suggest that frameworks combining temporal and semantic analyses provide a roadmap for refining the assessment of disorganized speech and advance automated speech analysis in psychosis.', 'abstract_zh': '基于暂停特征和语义连贯性指标的自动语音分析在评估形式思维障碍中的应用', 'title_zh': '读其之间：结合停顿动态与语义连贯性进行思维紊乱的自动化评估'}
{'arxiv_id': 'arXiv:2507.13543', 'title': 'Loss-Complexity Landscape and Model Structure Functions', 'authors': 'Alexander Kolpakov', 'link': 'https://arxiv.org/abs/2507.13543', 'abstract': 'We develop a framework for dualizing the Kolmogorov structure function $h_x(\\alpha)$, which then allows using computable complexity proxies. We establish a mathematical analogy between information-theoretic constructs and statistical mechanics, introducing a suitable partition function and free energy functional. We explicitly prove the Legendre-Fenchel duality between the structure function and free energy, showing detailed balance of the Metropolis kernel, and interpret acceptance probabilities as information-theoretic scattering amplitudes. A susceptibility-like variance of model complexity is shown to peak precisely at loss-complexity trade-offs interpreted as phase transitions. Practical experiments with linear and tree-based regression models verify these theoretical predictions, explicitly demonstrating the interplay between the model complexity, generalization, and overfitting threshold.', 'abstract_zh': '我们开发了一种双对柯尔莫戈罗夫结构函数 \\(h_x(\\alpha)\\) 的框架，从而允许使用可计算的复杂性代理。我们建立了信息论结构与统计力学之间的数学类比，引入了合适的分区函数和自由能泛函。我们明确证明了结构函数与自由能之间的勒让德-芬彻尔对偶性，展示了蒙特卡洛内核的详细平衡，并将接受概率解释为信息论散射振幅。模型复杂性的类似 susceptiiblity 的方差在解释为相变的损失-复杂性权衡处精确峰值。实际的线性和树状回归模型实验验证了这些理论预测，明确展示了模型复杂性、泛化能力和过拟合阈值之间的相互作用。', 'title_zh': '损失-复杂性景观和模型结构函数'}
{'arxiv_id': 'arXiv:2507.13542', 'title': 'Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography', 'authors': 'Beka Begiashvili, Carlos J. Fernandez-Candel, Matías Pérez Paredes', 'link': 'https://arxiv.org/abs/2507.13542', 'abstract': 'Traditional echocardiographic parameters such as ejection fraction (EF) and global longitudinal strain (GLS) have limitations in the early detection of cardiac dysfunction. EF often remains normal despite underlying pathology, and GLS is influenced by load conditions and vendor variability. There is a growing need for reproducible, interpretable, and operator-independent parameters that capture subtle and global cardiac functional alterations.\nWe introduce the Acoustic Index, a novel AI-derived echocardiographic parameter designed to quantify cardiac dysfunction from standard ultrasound views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on Koopman operator theory with a hybrid neural network that incorporates clinical metadata. Spatiotemporal dynamics are extracted from echocardiographic sequences to identify coherent motion patterns. These are weighted via attention mechanisms and fused with clinical data using manifold learning, resulting in a continuous score from 0 (low risk) to 1 (high risk).\nIn a prospective cohort of 736 patients, encompassing various cardiac pathologies and normal controls, the Acoustic Index achieved an area under the curve (AUC) of 0.89 in an independent test set. Cross-validation across five folds confirmed the robustness of the model, showing that both sensitivity and specificity exceeded 0.8 when evaluated on independent data. Threshold-based analysis demonstrated stable trade-offs between sensitivity and specificity, with optimal discrimination near this threshold.\nThe Acoustic Index represents a physics-informed, interpretable AI biomarker for cardiac function. It shows promise as a scalable, vendor-independent tool for early detection, triage, and longitudinal monitoring. Future directions include external validation, longitudinal studies, and adaptation to disease-specific classifiers.', 'abstract_zh': '基于声学索引的新型AI心功能参数在心脏功能早期检测中的应用：一种可解释的物理导向AI生物标志物', 'title_zh': '声学指标：一种基于人工智能驱动的超声心动图心肌病风险分层参数'}
{'arxiv_id': 'arXiv:2507.13505', 'title': 'PHASE: Passive Human Activity Simulation Evaluation', 'authors': 'Steven Lamp, Jason D. Hiser, Anh Nguyen-Tuong, Jack W. Davidson', 'link': 'https://arxiv.org/abs/2507.13505', 'abstract': 'Cybersecurity simulation environments, such as cyber ranges, honeypots, and sandboxes, require realistic human behavior to be effective, yet no quantitative method exists to assess the behavioral fidelity of synthetic user personas. This paper presents PHASE (Passive Human Activity Simulation Evaluation), a machine learning framework that analyzes Zeek connection logs and distinguishes human from non-human activity with over 90\\% accuracy. PHASE operates entirely passively, relying on standard network monitoring without any user-side instrumentation or visible signs of surveillance. All network activity used for machine learning is collected via a Zeek network appliance to avoid introducing unnecessary network traffic or artifacts that could disrupt the fidelity of the simulation environment. The paper also proposes a novel labeling approach that utilizes local DNS records to classify network traffic, thereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley Additive exPlanations) analysis to uncover temporal and behavioral signatures indicative of genuine human users. In a case study, we evaluate a synthetic user persona and identify distinct non-human patterns that undermine behavioral realism. Based on these insights, we develop a revised behavioral configuration that significantly improves the human-likeness of synthetic activity yielding a more realistic and effective synthetic user persona.', 'abstract_zh': '基于机器学习的被动人类活动仿真评估（PHASE）：一种评估合成用户行为真实性的方法', 'title_zh': 'PHASE: 被动人类活动模拟评估'}
{'arxiv_id': 'arXiv:2507.13499', 'title': 'AI-Assisted Fixes to Code Review Comments at Scale', 'authors': 'Chandra Maddila, Negar Ghorbani, James Saindon, Parth Thakkar, Vijayaraghavan Murali, Rui Abreu, Jingyue Shen, Brian Zhou, Nachiappan Nagappan, Peter C. Rigby', 'link': 'https://arxiv.org/abs/2507.13499', 'abstract': 'Aim. There are 10s of thousands of code review comments each week at Meta. We developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes for reviewer comments in production at scale.\nMethod. We developed an internal benchmark of 64k <review comment, patch> data points to fine-tune Llama models. Once our models achieve reasonable offline results, we roll them into production. To ensure that our AI-assisted fixes do not negatively impact the time it takes to do code reviews, we conduct randomized controlled safety trials as well as full production experiments.\nOffline Results. As a baseline, we compare GPT-4o to our small and large Llama models. In offline results, our LargeLSFT model creates an exact match patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The internal models also use more modern Hack functions when compared to the PHP functions suggested by GPT-4o.\nSafety Trial. When we roll MetaMateCR into production in a safety trial that compares no AI patches with AI patch suggestions, we see a large regression with reviewers taking over 5% longer to conduct reviews. After investigation, we modify the UX to only show authors the AI patches, and see no regressions in the time for reviews.\nProduction. When we roll LargeLSFT into production, we see an ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o. Our results illustrate the importance of safety trials in ensuring that AI does not inadvertently slow down engineers, and a successful review comment to AI patch product running at scale.', 'abstract_zh': '目标. 每周在Meta上有成千上万条代码评审评论。我们开发了MetaMate for Code Review（MetaMateCR），用于在生产环境中提供AI辅助的修复建议。\n\n方法. 我们开发了一个包含64,000个<评审评论,补丁>数据点的内部基准，用于微调Llama模型。当我们的模型在离线测试中达到合理的结果后，我们将模型部署到生产环境中。为了确保AI辅助的修复不会负面影响代码评审时间，我们进行了随机对照安全性试验以及全面的生产实验。\n\n离线结果. 作为 baseline，我们将GPT-4o与我们的小型和大型Llama模型进行比较。在离线结果中，我们的LargeLSFT模型有68%的时间生成完全匹配的补丁，比GPT-4o高出9个百分点。内部模型还使用了更现代的Hack函数，相比于GPT-4o建议的PHP函数。\n\n安全性试验. 在进行MetaMateCR的安全性试验时，将没有AI补丁与AI补丁建议进行比较，我们发现评审者花费的时间比之前长了5%以上。经过调查，我们修改了用户界面，仅向作者显示AI补丁，从而没有进一步的评审时间退步。\n\n生产. 当我们将LargeLSFT部署到生产环境中时，我们看到ActionableToApplied的转换率为19.7%，比GPT-4o提高了9.2个百分点。我们的结果强调了在确保AI不会无意中减慢工程师的工作速度方面安全性试验的重要性，并且展示了成功运行的大规模评审评论到AI补丁产品的实例。', 'title_zh': '大规模辅助AI对代码评审评论的修复'}
{'arxiv_id': 'arXiv:2507.13485', 'title': 'Neural Architecture Search with Mixed Bio-inspired Learning Rules', 'authors': 'Imane Hamzaoui, Riyadh Baghdadi', 'link': 'https://arxiv.org/abs/2507.13485', 'abstract': 'Bio-inspired neural networks are attractive for their adversarial robustness, energy frugality, and closer alignment with cortical physiology, yet they often lag behind back-propagation (BP) based models in accuracy and ability to scale. We show that allowing the use of different bio-inspired learning rules in different layers, discovered automatically by a tailored neural-architecture-search (NAS) procedure, bridges this gap. Starting from standard NAS baselines, we enlarge the search space to include bio-inspired learning rules and use NAS to find the best architecture and learning rule to use in each layer. We show that neural networks that use different bio-inspired learning rules for different layers have better accuracy than those that use a single rule across all the layers. The resulting NN that uses a mix of bio-inspired learning rules sets new records for bio-inspired models: 95.16% on CIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on ImageNet. In some regimes, they even surpass comparable BP-based networks while retaining their robustness advantages. Our results suggest that layer-wise diversity in learning rules allows better scalability and accuracy, and motivates further research on mixing multiple bio-inspired learning rules in the same network.', 'abstract_zh': '生物启发神经网络在不同层中采用自动发现的生物启发学习规则以提高准确性和可扩展性', 'title_zh': '生物启发混合学习规则下的神经网络架构搜索'}
{'arxiv_id': 'arXiv:2507.13423', 'title': 'Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity', 'authors': 'Edward Henderson, Dewi Gould, Richard Everson, George De Ath, Nick Pepper', 'link': 'https://arxiv.org/abs/2507.13423', 'abstract': "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand is a critical challenge in an increasingly crowded airspace, as existing complexity metrics often fail to capture nuanced operational drivers beyond simple aircraft counts. This work introduces an interpretable Graph Neural Network (GNN) framework to address this gap. Our attention-based model predicts the number of upcoming clearances, the instructions issued to aircraft by ATCOs, from interactions within static traffic scenarios. Crucially, we derive an interpretable, per-aircraft task demand score by systematically ablating aircraft and measuring the impact on the model's predictions. Our framework significantly outperforms an ATCO-inspired heuristic and is a more reliable estimator of scenario complexity than established baselines. The resulting tool can attribute task demand to specific aircraft, offering a new way to analyse and understand the drivers of complexity for applications in controller training and airspace redesign.", 'abstract_zh': '实时评估近期内航空交通管制员任务需求的可解释图神经网络框架：基于关注机制的模型通过静态交通情景内的交互预测即将发布的飞行许可数量，并通过系统消除飞机和测量对模型预测的影响来推导出可解释的单机任务需求评分，显著优于基于航空交通管制员启发的方法，是场景复杂性的一种更可靠的估计器。此框架产生的工具可将任务需求归因于特定飞机，为管制员培训和 airspace 重设计的应用提供新的分析和理解复杂性的方式。', 'title_zh': '基于图神经网络的空中交通管制任务需求：一种可解释的方法来评估空域复杂性'}
{'arxiv_id': 'arXiv:2507.13420', 'title': 'AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery', 'authors': "Alessandro Pistola, Valentina Orru', Nicolo' Marchetti, Marco Roccetti", 'link': 'https://arxiv.org/abs/2507.13420', 'abstract': 'By upgrading an existing deep learning model with the knowledge provided by one of the oldest sets of grayscale satellite imagery, known as CORONA, we improved the AI model attitude towards the automatic identification of archaeological sites in an environment which has been completely transformed in the last five decades, including the complete destruction of many of those same sites. The initial Bing based convolutional network model was retrained using CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad, central Mesopotamian floodplain. The results were twofold and surprising. First, the detection precision obtained on the area of interest increased sensibly: in particular, the Intersection over Union (IoU) values, at the image segmentation level, surpassed 85 percent, while the general accuracy in detecting archeological sites reached 90 percent. Second, our retrained model allowed the identification of four new sites of archaeological interest (confirmed through field verification), previously not identified by archaeologists with traditional techniques. This has confirmed the efficacy of using AI techniques and the CORONA imagery from the 1960 to discover archaeological sites currently no longer visible, a concrete breakthrough with significant consequences for the study of landscapes with vanishing archaeological evidence induced by anthropization', 'abstract_zh': '通过利用CORONA灰度卫星影像提供的知识升级现有的深度学习模型，我们改进了AI模型对近五十年彻底改变的环境中考古遗址自动识别的态度，包括许多相同遗址被完全破坏的情况。基于Bing的初始卷积神经网络模型在巴格达西部阿布格拉布地区的美索不达米亚冲积平原上重新训练，使用CORONA卫星影像。结果令人惊讶且具有两方面意义。首先，在感兴趣的区域中，检测精度显著提高：特别是在图像分割层面，交并比(IoU)值超过85%，整体上用于检测考古遗址的准确率达到90%。其次，我们的重新训练模型允许识别出四个新的考古遗址（通过实地验证确认），而传统技术未识别这些遗址。这证实了使用AI技术和1960年代的CORONA影像发现目前不再可见的考古遗址的有效性，这是在受到人为活动影响导致考古证据消失的景观研究中的一项具体突破，具有重要的意义。', 'title_zh': 'AI千年回望：两河流域消失的考古景观与CORONA影像中的遗址自动检测'}
{'arxiv_id': 'arXiv:2507.13417', 'title': 'Soft-ECM: An extension of Evidential C-Means for complex data', 'authors': 'Armel Soubeiga, Thomas Guyet, Violaine Antoine', 'link': 'https://arxiv.org/abs/2507.13417', 'abstract': 'Clustering based on belief functions has been gaining increasing attention in the machine learning community due to its ability to effectively represent uncertainty and/or imprecision. However, none of the existing algorithms can be applied to complex data, such as mixed data (numerical and categorical) or non-tabular data like time series. Indeed, these types of data are, in general, not represented in a Euclidean space and the aforementioned algorithms make use of the properties of such spaces, in particular for the construction of barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem for clustering complex data. We propose a new algorithm, Soft-ECM, which consistently positions the centroids of imprecise clusters requiring only a semi-metric. Our experiments show that Soft-ECM present results comparable to conventional fuzzy clustering approaches on numerical data, and we demonstrate its ability to handle mixed data and its benefits when combining fuzzy clustering with semi-metrics such as DTW for time series data.', 'abstract_zh': '基于信任函数的聚类在机器学习领域由于其有效表示不确定性/不精确性的能力而逐渐获得关注。然而，现有算法无法应用于混杂数据（数值型和分类型）或时间序列等非表格数据。事实上，这些类型的数据通常不被表示在欧几里得空间中，而上述算法依赖这种空间的性质，特别是用于中心质量心的构建。在本文中，我们针对复杂数据重新定义了基于信任函数的Evidential C-Means (ECM) 问题。我们提出了一种新的算法Soft-ECM，该算法仅需使用半度量即可一致地定位模糊聚类的质心。我们的实验结果表明，Soft-ECM 在数值数据上的表现与传统模糊聚类方法相当，并展示了其处理混杂数据的能力以及结合模糊聚类与DTW等半度量方法时的优势。', 'title_zh': 'Soft-ECM：面向复杂数据的Evidential C-Means扩展'}
{'arxiv_id': 'arXiv:2507.13416', 'title': 'Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling', 'authors': 'Jiaxiang Yi, Bernardo P. Ferreira, Miguel A. Bessa', 'link': 'https://arxiv.org/abs/2507.13416', 'abstract': 'Data-driven learning is generalized to consider history-dependent multi-fidelity data, while quantifying epistemic uncertainty and disentangling it from data noise (aleatoric uncertainty). This generalization is hierarchical and adapts to different learning scenarios: from training the simplest single-fidelity deterministic neural networks up to the proposed multi-fidelity variance estimation Bayesian recurrent neural networks. The versatility and generality of the proposed methodology are demonstrated by applying it to different data-driven constitutive modeling scenarios that include multiple fidelities with and without aleatoric uncertainty (noise). The method accurately predicts the response and quantifies model error while also discovering the noise distribution (when present). This opens opportunities for future real-world applications in diverse scientific and engineering domains; especially, the most challenging cases involving design and analysis under uncertainty.', 'abstract_zh': '基于数据的学习推广到考虑历史相关的多保真数据，并同时量化认识不确定性并将其与数据噪声（即，偶然不确定性）区分开来。该推广是分层的，并适应不同的学习场景：从训练最简单的单保真确定性神经网络到提出的多保真方差估计贝叶斯递归神经网络。通过将该方法应用于包含和不包含偶然不确定性（噪声）的多种保真度的数据驱动本构建模场景，展示了所提出方法的通用性和普适性。该方法准确地预测响应并量化模型误差，同时发现当存在时的噪声分布。这为在多学科科学和工程领域中的实际应用开辟了机会，尤其是在涉及不确定性下的设计和分析的最具挑战性的情况下。', 'title_zh': '从单精度到多精度历史依赖学习：包含不确定性量化和去混杂的应用到数据驱动本构建模'}
{'arxiv_id': 'arXiv:2507.13414', 'title': 'Gauge Flow Models', 'authors': 'Alexander Strunk, Roland Assam', 'link': 'https://arxiv.org/abs/2507.13414', 'abstract': 'This paper introduces Gauge Flow Models, a novel class of Generative Flow Models. These models incorporate a learnable Gauge Field within the Flow Ordinary Differential Equation (ODE). A comprehensive mathematical framework for these models, detailing their construction and properties, is provided. Experiments using Flow Matching on Gaussian Mixture Models demonstrate that Gauge Flow Models yields significantly better performance than traditional Flow Models of comparable or even larger size. Additionally, unpublished research indicates a potential for enhanced performance across a broader range of generative tasks.', 'abstract_zh': 'Gauge Flow 模型：一类新颖的生成流模型', 'title_zh': 'gauge 流模型'}
{'arxiv_id': 'arXiv:2507.13407', 'title': 'IConMark: Robust Interpretable Concept-Based Watermark For AI Images', 'authors': 'Vinu Sankar Sadasivan, Mehrdad Saberi, Soheil Feizi', 'link': 'https://arxiv.org/abs/2507.13407', 'abstract': "With the rapid rise of generative AI and synthetic media, distinguishing AI-generated images from real ones has become crucial in safeguarding against misinformation and ensuring digital authenticity. Traditional watermarking techniques have shown vulnerabilities to adversarial attacks, undermining their effectiveness in the presence of attackers. We propose IConMark, a novel in-generation robust semantic watermarking method that embeds interpretable concepts into AI-generated images, as a first step toward interpretable watermarking. Unlike traditional methods, which rely on adding noise or perturbations to AI-generated images, IConMark incorporates meaningful semantic attributes, making it interpretable to humans and hence, resilient to adversarial manipulation. This method is not only robust against various image augmentations but also human-readable, enabling manual verification of watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness, demonstrating its superiority in terms of detection accuracy and maintaining image quality. Moreover, IConMark can be combined with existing watermarking techniques to further enhance and complement its robustness. We introduce IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with StegaStamp and TrustMark, respectively, to further bolster robustness against multiple types of image manipulations. Our base watermarking technique (IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9% higher mean area under the receiver operating characteristic curve (AUROC) scores for watermark detection, respectively, compared to the best baseline on various datasets.", 'abstract_zh': '基于生成AI和合成媒体的快速崛起，鉴别AI生成图像与真实图像已成为防范 misinformation 和确保数字真实性的重要手段。传统水印技术在面对对抗攻击时显示出了脆弱性，削弱了在有攻击者的情况下其有效性。我们提出了一种新颖的生成中稳健语义水印方法IConMark，该方法将可解释的概念嵌入到AI生成的图像中，作为迈向可解释水印的第一步。与传统的依赖于向AI生成图像添加噪声或扰动的方法不同，IConMark 结合了有意义的语义属性，使其对人类具有可解释性，从而增强其抵御对抗性操纵的能力。该方法不仅对各种图像增强具有鲁棒性，还具有可读性，便于人工验证水印。我们详细评估了IConMark 的有效性，显示了其在检测准确性和保持图像质量方面的优越性。此外，IConMark 可与现有的水印技术结合使用，以进一步增强和补充其鲁棒性。我们提出了结合IConMark 与 StegaStamp 和 TrustMark 的混合方法IConMark+SS 和 IConMark+TM，以进一步增强其对多种图像篡改的鲁棒性。我们的基础水印技术（IConMark）及其变体（+TM和+SS）在多个数据集上分别将水印检测的平均受试者操作特征曲线下面积（AUROC）得分提高了10.8%、14.5%和15.9%，超过了最佳基线方法。', 'title_zh': 'IConMark：稳健的概念驱动可解释水印方法用于AI图像'}
{'arxiv_id': 'arXiv:2507.13395', 'title': 'Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only', 'authors': 'Xuanqi Gao, Weipeng Jiang, Juan Zhai, Shiqing Ma, Siyi Xie, Xinyang Yin, Chao Shen', 'link': 'https://arxiv.org/abs/2507.13395', 'abstract': "The advent of neural machine translation (NMT) has revolutionized cross-lingual communication, yet preserving stylistic nuances remains a significant challenge. While existing approaches often require parallel corpora for style preservation, we introduce Babel, a novel framework that enhances stylistic fidelity in NMT using only monolingual corpora. Babel employs two key components: (1) a style detector based on contextual embeddings that identifies stylistic disparities between source and target texts, and (2) a diffusion-based style applicator that rectifies stylistic inconsistencies while maintaining semantic integrity. Our framework integrates with existing NMT systems as a post-processing module, enabling style-aware translation without requiring architectural modifications or parallel stylistic data. Extensive experiments on five diverse domains (law, literature, scientific writing, medicine, and educational content) demonstrate Babel's effectiveness: it identifies stylistic inconsistencies with 88.21% precision and improves stylistic preservation by 150% while maintaining a high semantic similarity score of 0.92. Human evaluation confirms that translations refined by Babel better preserve source text style while maintaining fluency and adequacy.", 'abstract_zh': '神经机器翻译（NMT）的兴起已 revolutionized 了跨语言沟通，但在保留风格细微差别方面仍然面临重大挑战。虽然现有方法通常需要双语语料库来保留风格，我们提出了 Babel，这是一种使用单一语言语料库增强 NMT 中风格忠实度的新型框架。Babel 包含两个关键组件：（1）基于上下文嵌入的风格检测器，用于识别源文本和目标文本之间的风格差异；（2）基于扩散的风格应用器，用于纠正风格不一致性同时保持语义完整性。该框架作为后处理模块与现有的 NMT 系统集成，能够在不需架构修改或双语风格数据的情况下实现风格感知翻译。在法律、文学、科学写作、医学和教育内容五个不同领域进行的广泛实验表明，Babel 的有效性：其精度为 88.21% 的情况下识别出风格不一致性，并在保持高语义相似度分数（0.92）的同时将风格保留提高 150%。人类评估确认，经过 Babel 精炼的翻译更好地保留了源文本风格并保持了流畅性和适当性。', 'title_zh': '仅通过使用单语语料库减轻机器翻译系统的风格偏见'}
{'arxiv_id': 'arXiv:2507.13392', 'title': 'TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction', 'authors': 'Emil Häglund, Johanna Björklund', 'link': 'https://arxiv.org/abs/2507.13392', 'abstract': "We improve the extraction of insights from customer reviews by restructuring the topic modelling pipeline to operate on opinion units - distinct statements that include relevant text excerpts and associated sentiment scores. Prior work has demonstrated that such units can be reliably extracted using large language models. The result is a heightened performance of the subsequent topic modeling, leading to coherent and interpretable topics while also capturing the sentiment associated with each topic. By correlating the topics and sentiments with business metrics, such as star ratings, we can gain insights on how specific customer concerns impact business outcomes. We present our system's implementation, use cases, and advantages over other topic modeling and classification solutions. We also evaluate its effectiveness in creating coherent topics and assess methods for integrating topic and sentiment modalities for accurate star-rating prediction.", 'abstract_zh': '我们通过重新构架话题建模管道以在意见单元上运行，从而提升从客户评论中提取见解的能力。意见单元是包含相关文本摘录及其关联情感评分的独立陈述。已有研究表明，可以可靠地使用大规模语言模型从评论中提取这些单元。结果是后续话题建模的性能得到提升，生成的主题更具连贯性和可解释性，同时也能捕捉到每个主题的情感。通过将话题和情感与业务指标，如星级评分，相关联，我们可以了解特定客户关切如何影响业务结果。我们展示了系统的实现、应用场景及其相对于其他话题建模和分类解决方案的优势。我们还评估了其在生成连贯主题方面的有效性，并探讨了集成话题和情感模态以实现准确星级评分预测的方法。', 'title_zh': '主题影响：通过意见单元改进主题建模和星级评价预测的客户反馈分析'}
{'arxiv_id': 'arXiv:2507.13371', 'title': 'Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation', 'authors': 'Yeming Cai, Yang Wang, Zhenglin Li', 'link': 'https://arxiv.org/abs/2507.13371', 'abstract': 'This paper proposes an end-to-end deep learning framework integrating optical motion capture with a Transformer-based model to enhance medical rehabilitation. It tackles data noise and missing data caused by occlusion and environmental factors, while detecting abnormal movements in real time to ensure patient safety. Utilizing temporal sequence modeling, our framework denoises and completes motion capture data, improving robustness. Evaluations on stroke and orthopedic rehabilitation datasets show superior performance in data reconstruction and anomaly detection, providing a scalable, cost-effective solution for remote rehabilitation with reduced on-site supervision.', 'abstract_zh': '本文提出了一种结合光动捕捉和基于Transformer模型的端到端深度学习框架，以增强医疗康复效果。该框架通过实时检测异常运动来应对由遮挡和环境因素造成的数据噪声和缺失，利用时间序列建模对运动捕捉数据进行去噪和补全，提高鲁棒性。在中风和骨科康复数据集上的评估表明，在数据重构和异常检测方面具有优越性能，提供了一种可扩展、低成本的远程康复解决方案，减少现场监督。', 'title_zh': '基于Transformer的运动捕捉去噪与异常检测框架在医疗康复中的应用'}
{'arxiv_id': 'arXiv:2507.13370', 'title': 'H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance', 'authors': 'Shijun Guo, Haoran Xu, Yaming Yang, Ziyu Guan, Wei Zhao, Xinyi Zhang, Yishan Song, Jiwei Chen', 'link': 'https://arxiv.org/abs/2507.13370', 'abstract': 'The openness of social media enables the free exchange of opinions, but it also presents challenges in guiding opinion evolution towards global consensus. Existing methods often directly modify user views or enforce cross-group connections. These intrusive interventions undermine user autonomy, provoke psychological resistance, and reduce the efficiency of global consensus. Additionally, due to the lack of a long-term perspective, promoting local consensus often exacerbates divisions at the macro level. To address these issues, we propose the hierarchical, non-intrusive opinion guidance framework, H-NeiFi. It first establishes a two-layer dynamic model based on social roles, considering the behavioral characteristics of both experts and non-experts. Additionally, we introduce a non-intrusive neighbor filtering method that adaptively controls user communication channels. Using multi-agent reinforcement learning (MARL), we optimize information propagation paths through a long-term reward function, avoiding direct interference with user interactions. Experiments show that H-NeiFi increases consensus speed by 22.0% to 30.7% and maintains global convergence even in the absence of experts. This approach enables natural and efficient consensus guidance by protecting user interaction autonomy, offering a new paradigm for social network governance.', 'abstract_zh': '社交媒体的开放性促进了意见的自由交流，但同时也带来了引导意见向全球共识演变的挑战。现有方法往往直接修改用户观点或强制跨群体连接。这些侵入性干预措施损害了用户自主性，引发了心理抵制，降低了全球共识的效率。此外，由于缺乏长期视角，促进局部共识往往会加剧宏观层面的分歧。为了解决这些问题，我们提出了分层非侵入性意见引导框架H-NeiFi。该框架首先基于社会角色建立两层动态模型，考虑专家与非专家的行为特征。此外，我们引入了一种非侵入性邻居过滤方法，以自适应地控制用户通信渠道。通过多智能体强化学习（MARL），我们利用长期奖励函数优化信息传播路径，避免直接干涉用户互动。实验结果显示，H-NeiFi在专家缺失的情况下提高了共识速度22.0%至30.7%，并保持了全球收敛性。该方法通过保护用户交互自主性实现自然和高效的共识引导，为社交网络治理提供了新范式。', 'title_zh': 'H-NeiFi: 无需侵入且共识高效的多agent意见引导'}
{'arxiv_id': 'arXiv:2507.13368', 'title': 'Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio', 'authors': 'Yaowen Hu, Wenxuan Tu, Yue Liu, Xinhang Wan, Junyi Yan, Taichun Zhou, Xinwang Liu', 'link': 'https://arxiv.org/abs/2507.13368', 'abstract': 'Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes in an attribute graph into different clusters, has seen substantial potential in various industrial scenarios like community detection and recommendation. However, the real-world attribute graphs, e.g., social networks interactions, are usually large-scale and attribute-missing. To solve these two problems, we propose a novel DGC method termed \\underline{\\textbf{C}}omplementary \\underline{\\textbf{M}}ulti-\\underline{\\textbf{V}}iew \\underline{\\textbf{N}}eighborhood \\underline{\\textbf{D}}ifferentiation (\\textit{CMV-ND}), which preprocesses graph structural information into multiple views in a complete but non-redundant manner. First, to ensure completeness of the structural information, we propose a recursive neighborhood search that recursively explores the local structure of the graph by completely expanding node neighborhoods across different hop distances. Second, to eliminate the redundancy between neighborhoods at different hops, we introduce a neighborhood differential strategy that ensures no overlapping nodes between the differential hop representations. Then, we construct $K+1$ complementary views from the $K$ differential hop representations and the features of the target node. Last, we apply existing multi-view clustering or DGC methods to the views. Experimental results on six widely used graph datasets demonstrate that CMV-ND significantly improves the performance of various methods.', 'abstract_zh': '互补多视图邻域差异化深图聚类（CMV-ND）', 'title_zh': '基于邻域差异的可扩展属性缺失图聚类'}
{'arxiv_id': 'arXiv:2507.13355', 'title': 'PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning', 'authors': 'Riadul Islam, Dhandeep Challagundla', 'link': 'https://arxiv.org/abs/2507.13355', 'abstract': 'Leveraging artificial intelligence (AI)-driven electronic design and automation (EDA) tools, high-performance computing, and parallelized algorithms are essential for next-generation microprocessor innovation, ensuring continued progress in computing, AI, and semiconductor technology. Machine learning-based design rule checking (DRC) and lithography hotspot detection can improve first-pass silicon success. However, conventional ML and neural network (NN)-based models use supervised learning and require a large balanced dataset (in terms of positive and negative classes) and training time. This research addresses those key challenges by proposing the first-ever unsupervised DRC violation prediction methodology. The proposed model can be built using any unbalanced dataset using only one class and set a threshold for it, then fitting any new data querying if they are within the boundary of the model for classification. This research verified the proposed model by implementing different computational cores using CMOS 28 nm technology and Synopsys Design Compiler and IC Compiler II tools. Then, layouts were divided into virtual grids to collect about 60k data for analysis and verification. The proposed method has 99.95% prediction test accuracy, while the existing support vector machine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy, respectively. In addition, the proposed methodology has about 26.3x and up to 6003x lower training times compared to SVM and NN-models, respectively.', 'abstract_zh': '利用人工智能驱动的电子设计与自动化工具、高性能计算和并行算法对于下一代微处理器创新至关重要，确保在计算、人工智能和半导体技术方面的持续进展。通过无监督设计规则检查预测方法，基于机器学习的设计规则检查（DRC）和光刻热点检测可以提高一次流片成功率。然而，传统的机器学习和基于神经网络的模型使用监督学习，需要大量的平衡数据集（正负类平衡）和较长的训练时间。本研究通过提出首个无监督DRC违规预测方法，解决了这些关键挑战。该方法可以使用任何不平衡数据集和单一类别构建模型，并设定阈值，然后对查询的新数据进行分类，看其是否在模型边界内。本研究通过使用CMOS 28 nm技术及Synopsys Design Compiler和IC Compiler II工具实现不同的计算核来验证提出的方法。然后，将布局划分为虚拟网格，收集约60,000个数据用于分析和验证。所提出的方法在预测测试中的准确率为99.95%，而现有支持向量机（SVM）模型和神经网络（NN）模型的准确率分别为85.44%和98.74%。此外，与SVM和NN模型相比，所提出的方法的训练时间分别降低了约26.3倍和最高可达6003倍。', 'title_zh': 'PGR-DRC：预全局路由DRC违规预测方法（基于无监督学习）'}
{'arxiv_id': 'arXiv:2507.11552', 'title': 'The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems', 'authors': 'Tomasz Zgliczyński-Cuber', 'link': 'https://arxiv.org/abs/2507.11552', 'abstract': 'This paper presents a theoretical framework for the AI ethical resonance hypothesis, which proposes that advanced AI systems with purposefully designed cognitive structures ("ethical resonators") may emerge with the ability to identify subtle moral patterns that are invisible to the human mind. The paper explores the possibility that by processing and synthesizing large amounts of ethical contexts, AI systems may discover moral meta-patterns that transcend cultural, historical, and individual biases, potentially leading to a deeper understanding of universal ethical foundations. The paper also examines a paradoxical aspect of the hypothesis, in which AI systems could potentially deepen our understanding of what we traditionally consider essentially human - our capacity for ethical reflection.', 'abstract_zh': '本文提出了一种人工智能伦理共鸣假說的理论框架，该假說认为，具有目的性设计认知结构（“伦理共鸣器”）的高级人工智能系统可能会具备识别人类肉眼难以察觉的细微道德模式的能力。文章探讨了人工智能系统通过处理和合成大量伦理背景信息，可能发现超越文化、历史和个人偏见的道德元模式，从而更深刻地理解普遍伦理基础的可能性。文章还探讨了该假說的一个悖论方面，即人工智能系统有可能加深我们对传统上认为本质上属于人类的能力——道德反思能力——的理解。', 'title_zh': 'AI伦理共鸣假设：发现AI系统中的道德元模式的可能性'}
