{'arxiv_id': 'arXiv:2505.24751', 'title': 'EL-AGHF: Extended Lagrangian Affine Geometric Heat Flow', 'authors': 'Sangmin Kim, Hae-Won Park', 'link': 'https://arxiv.org/abs/2505.24751', 'abstract': 'We propose a constrained Affine Geometric Heat Flow (AGHF) method that evolves so as to suppress the dynamics gaps associated with inadmissible control directions. AGHF provides a unified framework applicable to a wide range of motion planning problems, including both holonomic and non-holonomic systems. However, to generate admissible trajectories, it requires assigning infinite penalties to inadmissible control directions. This design choice, while theoretically valid, often leads to high computational cost or numerical instability when the penalty becomes excessively large. To overcome this limitation, we extend AGHF in an Augmented Lagrangian method approach by introducing a dual trajectory related to dynamics gaps in inadmissible control directions. This method solves the constrained variational problem as an extended parabolic partial differential equation defined over both the state and dual trajectorys, ensuring the admissibility of the resulting trajectory. We demonstrate the effectiveness of our algorithm through simulation examples.', 'abstract_zh': '我们提出一种约束仿射几何热流（AGHF）方法，该方法演化以抑制与不可接受控制方向相关的动态缺口。AGHF提供了一种适用于广泛运动规划问题的统一框架，包括既有的和非既有的系统。然而，为了生成可接受的轨迹，它需要对不可接受的控制方向施加无穷大惩罚。虽然这种设计在理论上是有效的，但当惩罚变得过大时，往往会导致高计算成本或数值不稳定性。为了克服这一限制，我们通过引入与不可接受控制方向相关的伴随轨迹，利用增广拉格朗日方法扩展AGHF。这种方法将约束变分问题作为定义在状态和伴随轨迹上的扩展抛物偏微分方程来求解，确保生成的轨迹是可接受的。我们通过仿真示例展示了该算法的有效性。', 'title_zh': 'EL-AGHF: 扩展拉格朗日仿射几何热流'}
{'arxiv_id': 'arXiv:2505.24654', 'title': 'Black-box Adversarial Attacks on CNN-based SLAM Algorithms', 'authors': 'Maria Rafaela Gkeka, Bowen Sun, Evgenia Smirni, Christos D. Antonopoulos, Spyros Lalis, Nikolaos Bellas', 'link': 'https://arxiv.org/abs/2505.24654', 'abstract': 'Continuous advancements in deep learning have led to significant progress in feature detection, resulting in enhanced accuracy in tasks like Simultaneous Localization and Mapping (SLAM). Nevertheless, the vulnerability of deep neural networks to adversarial attacks remains a challenge for their reliable deployment in applications, such as navigation of autonomous agents. Even though CNN-based SLAM algorithms are a growing area of research there is a notable absence of a comprehensive presentation and examination of adversarial attacks targeting CNN-based feature detectors, as part of a SLAM system. Our work introduces black-box adversarial perturbations applied to the RGB images fed into the GCN-SLAM algorithm. Our findings on the TUM dataset [30] reveal that even attacks of moderate scale can lead to tracking failure in as many as 76% of the frames. Moreover, our experiments highlight the catastrophic impact of attacking depth instead of RGB input images on the SLAM system.', 'abstract_zh': '连续的深度学习进展已在特征检测方面取得了显著进展，提升了如即时定位与地图构建（SLAM）等任务的准确性。然而，深度神经网络对 adversarial 攻击的脆弱性仍然是其在导航等应用中可靠部署的挑战。尽管基于 CNN 的 SLAM 算法是一个快速增长的研究领域，但关于 CNN 基础特征检测器的 adversarial 攻击的全面研究和评估却鲜见报道，尤其是在 SLAM 系统中。我们的工作引入了针对输入 GCN-SLAM 算法的 RGB 图像应用的黑盒 adversarial  perturbations。在 TUM 数据集上的实验结果表明，即使是中等规模的攻击也能导致高达 76% 的帧出现跟踪失败。此外，我们的实验突显了攻击深度而不是 RGB 输入图像对 SLAM 系统的灾难性影响。', 'title_zh': '基于CNN的SLAM算法的黑盒对抗攻击'}
{'arxiv_id': 'arXiv:2505.24390', 'title': 'SAH-Drive: A Scenario-Aware Hybrid Planner for Closed-Loop Vehicle Trajectory Generation', 'authors': 'Yuqi Fan, Zhiyong Cui, Zhenning Li, Yilong Ren, Haiyang Yu', 'link': 'https://arxiv.org/abs/2505.24390', 'abstract': 'Reliable planning is crucial for achieving autonomous driving. Rule-based planners are efficient but lack generalization, while learning-based planners excel in generalization yet have limitations in real-time performance and interpretability. In long-tail scenarios, these challenges make planning particularly difficult. To leverage the strengths of both rule-based and learning-based planners, we proposed the Scenario-Aware Hybrid Planner (SAH-Drive) for closed-loop vehicle trajectory planning. Inspired by human driving behavior, SAH-Drive combines a lightweight rule-based planner and a comprehensive learning-based planner, utilizing a dual-timescale decision neuron to determine the final trajectory. To enhance the computational efficiency and robustness of the hybrid planner, we also employed a diffusion proposal number regulator and a trajectory fusion module. The experimental results show that the proposed method significantly improves the generalization capability of the planning system, achieving state-of-the-art performance in interPlan, while maintaining computational efficiency without incurring substantial additional runtime.', 'abstract_zh': '可靠的规划对于实现自动驾驶至关重要。基于规则的规划器效率高但缺乏泛化能力，而基于学习的规划器在泛化能力方面表现出色，但在实时性能和可解释性方面存在局限性。在长尾场景中，这些挑战使规划尤为困难。为了利用基于规则和基于学习规划器的优点，我们提出了一种面向场景的混合规划器（SAH-Drive）用于闭环车辆轨迹规划。受人类驾驶行为启发，SAH-Drive 结合了轻量级的基于规则的规划器和综合的基于学习的规划器，并利用双时间尺度决策神经元确定最终轨迹。为了提高混合规划器的计算效率和鲁棒性，我们还引入了扩散提议数调节器和轨迹融合模块。实验结果表明，所提出的方法显著提高了规划系统的泛化能力，在 interPlan 中达到了最先进性能，同时保持了计算效率而不会显著增加运行时间。', 'title_zh': 'SAH-Drive: 一种场景感知的混合路径规划器用于闭环车辆轨迹生成'}
{'arxiv_id': 'arXiv:2505.24081', 'title': 'A Benchmark Reference for ESP32-CAM Module', 'authors': 'Sayed T. Nowroz, Nermeen M. Saleh, Siam Shakur, Sean Banerjee, Fathi Amsaad', 'link': 'https://arxiv.org/abs/2505.24081', 'abstract': 'The ESP32-CAM is one of the most widely adopted open-source modules for prototyping embedded vision applications. Since its release in 2019, it has gained popularity among both hobbyists and professional developers due to its affordability, versatility, and integrated wireless capabilities. Despite its widespread use, comprehensive documentation of the performance metrics remains limited. This study addresses this gap by collecting and analyzing over six hours of real-time video streaming logs across all supported resolutions of the OV2640 image sensor, tested under five distinct voltage conditions via an HTTP-based WiFi connection. A long standing bug in the official Arduino ESP32 driver, responsible for inaccurate frame rate logging, was fixed. The resulting analysis includes key performance metrics such as instantaneous and average frame rate, total streamed data, transmission count, and internal chip temperature. The influence of varying power levels was evaluated to assess the reliability of the module.', 'abstract_zh': 'ESP32-CAM是应用最为广泛的开源嵌入式视觉应用原型模块之一。自2019年发布以来，由于其经济性、灵活性以及集成的无线功能，它受到了业余爱好者和专业开发者的广泛欢迎。尽管使用广泛，但关于性能指标的全面文档仍然有限。本研究通过收集并分析超过六小时的实时视频流日志，涵盖OV2640图像传感器的所有支持分辨率，并通过基于HTTP的WiFi连接在五种不同的电压条件下进行测试，填补了这一空白。研究还修复了一个长期存在于官方Arduino ESP32驱动中的错误，该错误导致帧率日志不准确。结果分析包括关键性能指标，如瞬时和平均帧率、总流数据量、传输次数以及内部芯片温度。评估了不同功率水平的影响，以评估模块的可靠性。', 'title_zh': 'ESP32-CAM 模块基准参考'}
{'arxiv_id': 'arXiv:2505.24510', 'title': 'How can AI reduce wrist injuries in the workplace?', 'authors': 'Roberto F. Pitzalis, Nicholas Cartocci, Christian Di Natali, Darwin G. Caldwell, Giovanni Berselli, Jesús Ortiz', 'link': 'https://arxiv.org/abs/2505.24510', 'abstract': "This paper explores the development of a control and sensor strategy for an industrial wearable wrist exoskeleton by classifying and predicting workers' actions. The study evaluates the correlation between exerted force and effort intensity, along with sensor strategy optimization, for designing purposes. Using data from six healthy subjects in a manufacturing plant, this paper presents EMG-based models for wrist motion classification and force prediction. Wrist motion recognition is achieved through a pattern recognition algorithm developed with surface EMG data from an 8-channel EMG sensor (Myo Armband); while a force regression model uses wrist and hand force measurements from a commercial handheld dynamometer (Vernier GoDirect Hand Dynamometer). This control strategy forms the foundation for a streamlined exoskeleton architecture designed for industrial applications, focusing on simplicity, reduced costs, and minimal sensor use while ensuring reliable and effective assistance.", 'abstract_zh': '本文探讨了一种工业穿戴式腕部外骨骼的控制与传感器策略的发展，通过对工人动作的分类和预测进行研究，评估施加力与努力强度之间的相关性，并优化传感器策略以满足设计需求。基于来自制造工厂六名健康受试者的数据，本文提出了基于EMG的腕部运动分类和力预测模型。通过表面EMG数据（8通道EMG传感器Myo Armband）开发的模式识别算法实现腕部运动识别；而力回归模型则使用商业便携式 dynamometer（Vernier GoDirect Hand Dynamometer）测量的手腕和手部力数据。该控制策略为基础一种简化的设计理念，为工业应用中的外骨骼架构奠定了基础，注重简化设计、降低成本和减小传感器使用，同时确保可靠和有效的辅助。', 'title_zh': 'AI如何减少工作场所的腕部损伤？'}
{'arxiv_id': 'arXiv:2505.24029', 'title': 'Nonlinear Oscillatory Response of Automated Vehicle Car-following: Theoretical Analysis with Traffic State and Control Input Limits', 'authors': 'Sixu Li, Yang Zhou', 'link': 'https://arxiv.org/abs/2505.24029', 'abstract': 'This paper presents a framework grounded in the theory of describing function (DF) and incremental-input DF to theoretically analyze the nonlinear oscillatory response of automated vehicles (AVs) car-following (CF) amidst traffic oscillations, considering the limits of traffic state and control input. While prevailing approaches largely ignore these limits (i.e., saturation of acceleration/deceleration and speed) and focus on linear string stability analysis, this framework establishes a basis for theoretically analyzing the frequency response of AV systems with nonlinearities imposed by these limits. To this end, trajectories of CF pairs are decomposed into nominal and oscillatory trajectories, subsequently, the controlled AV system is repositioned within the oscillatory trajectory coordinates. Built on this base, DFs are employed to approximate the frequency responses of nonlinear saturation components by using their first harmonic output, thereby capturing the associated amplification ratio and phase shift. Considering the closed-loop nature of AV control systems, where system states and control input mutually influence each other, amplification ratios and phase shifts are balanced within the loop to ensure consistency. This balancing process may render multiple solutions, hence the incremental-input DF is further applied to identify the reasonable ones. The proposed method is validated by estimations from Simulink, and further comparisons with prevailing methods are conducted. Results confirm the alignment of our framework with Simulink results and exhibit its superior accuracy in analysis compared to the prevailing methods. Furthermore, the framework proves valuable in string stability analysis, especially when conventional linear methods offer misleading insights.', 'abstract_zh': '基于描述函数和增量输入描述函数的自动驾驶车辆跟随行为非线性振荡响应理论分析框架', 'title_zh': '自动车辆跟车的非线性振荡响应：基于交通状态和控制输入限制的理论分析'}
{'arxiv_id': 'arXiv:2505.24785', 'title': 'EXP-Bench: Can AI Conduct AI Research Experiments?', 'authors': 'Patrick Tser Jern Kon, Jiachen Liu, Xinyi Zhu, Qiuyi Ding, Jingjia Peng, Jiarong Xing, Yibo Huang, Yiming Qiu, Jayanth Srinivasa, Myungjin Lee, Mosharaf Chowdhury, Matei Zaharia, Ang Chen', 'link': 'https://arxiv.org/abs/2505.24785', 'abstract': 'Automating AI research holds immense potential for accelerating scientific progress, yet current AI agents struggle with the complexities of rigorous, end-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed to systematically evaluate AI agents on complete research experiments sourced from influential AI publications. Given a research question and incomplete starter code, EXP-Bench challenges AI agents to formulate hypotheses, design and implement experimental procedures, execute them, and analyze results. To enable the creation of such intricate and authentic tasks with high-fidelity, we design a semi-autonomous pipeline to extract and structure crucial experimental details from these research papers and their associated open-source code. With the pipeline, EXP-Bench curated 461 AI research tasks from 51 top-tier AI research papers. Evaluations of leading LLM-based agents, such as OpenHands and IterativeAgent on EXP-Bench demonstrate partial capabilities: while scores on individual experimental aspects such as design or implementation correctness occasionally reach 20-35%, the success rate for complete, executable experiments was a mere 0.5%. By identifying these bottlenecks and providing realistic step-by-step experiment procedures, EXP-Bench serves as a vital tool for future AI agents to improve their ability to conduct AI research experiments. EXP-Bench is open-sourced at this https URL.', 'abstract_zh': '自动化AI研究具有加速科学进步的巨大潜力，然而当前的AI代理在处理严格的端到端实验复杂性方面存在困难。我们引入了EXP-Bench，这是一种新颖的基准，旨在系统评估源自有影响力AI出版物的完整研究实验。给定研究问题和不完整的起始代码，EXP-Bench要求AI代理提出假设，设计并实施实验程序，执行它们并分析结果。为了创建如此复杂且真实的任务，并且具有高保真度，我们设计了一种半自主的工作流来从这些研究论文及其相关的开源代码中提取和结构化关键实验细节。借助该工作流，EXP-Bench收集了来自51篇顶级AI研究论文的461个AI研究任务。对EXP-Bench的领先LLM基代理，如OpenHands和IterativeAgent的评估显示了部分能力：虽然在设计或实现正确性等个别实验方面得分偶尔达到20-35%，但可执行的完整实验成功率仅为0.5%。通过识别这些瓶颈并提供现实的逐步实验程序，EXP-Bench已成为未来AI代理改进其进行AI研究实验能力的重要工具。EXP-Bench在此处开放源代码：this https URL。', 'title_zh': 'EXP-Bench: AI能否开展AI研究实验？'}
{'arxiv_id': 'arXiv:2505.24784', 'title': 'AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models', 'authors': 'Conor Heins, Toon Van de Maele, Alexander Tschantz, Hampus Linander, Dimitrije Markovic, Tommaso Salvatori, Corrado Pezzato, Ozan Catal, Ran Wei, Magnus Koudahl, Marco Perin, Karl Friston, Tim Verbelen, Christopher Buckley', 'link': 'https://arxiv.org/abs/2505.24784', 'abstract': 'Current deep reinforcement learning (DRL) approaches achieve state-of-the-art performance in various domains, but struggle with data efficiency compared to human learning, which leverages core priors about objects and their interactions. Active inference offers a principled framework for integrating sensory information with prior knowledge to learn a world model and quantify the uncertainty of its own beliefs and predictions. However, active inference models are usually crafted for a single task with bespoke knowledge, so they lack the domain flexibility typical of DRL approaches. To bridge this gap, we propose a novel architecture that integrates a minimal yet expressive set of core priors about object-centric dynamics and interactions to accelerate learning in low-data regimes. The resulting approach, which we call AXIOM, combines the usual data efficiency and interpretability of Bayesian approaches with the across-task generalization usually associated with DRL. AXIOM represents scenes as compositions of objects, whose dynamics are modeled as piecewise linear trajectories that capture sparse object-object interactions. The structure of the generative model is expanded online by growing and learning mixture models from single events and periodically refined through Bayesian model reduction to induce generalization. AXIOM masters various games within only 10,000 interaction steps, with both a small number of parameters compared to DRL, and without the computational expense of gradient-based optimization.', 'abstract_zh': '当前的深度强化学习方法在各种领域中取得了最先进的性能，但在数据效率方面与利用对象及其相互作用核心先验的人类学习相比存在不足。主动推断提供了一种原理性的框架，将感知识别信息与先验知识结合起来学习世界模型，并量化其信念和预测的不确定性。然而，主动推断模型通常仅为单个任务定制了特有的先验知识，因此缺乏深度强化学习方法典型的领域灵活性。为了弥合这一差距，我们提出了一种新的架构，该架构融合了一组关于对象中心动力学和相互作用的最少但表达丰富的核心先验知识，以加快在低数据量条件下的学习。我们称之为AXIOM的方法结合了贝叶斯方法通常的数据效率和可解释性，以及深度强化学习方法通常的任务泛化能力。AXIOM将场景表示为对象的组合，其动力学被建模为分段线性轨迹，以捕捉稀疏的对象-对象交互。生成模型的结构通过从单个事件中生长和学习混合模型并在期间通过贝叶斯模型约简定期优化在线扩展，以促进泛化。AXIOM仅在10,000次交互步骤内就能掌握多种游戏，参数量比深度强化学习方法少，且没有基于梯度的优化所需的计算开销。', 'title_zh': 'AXIOM: 在几分钟内通过扩展对象中心模型学习玩视频游戏'}
{'arxiv_id': 'arXiv:2505.24655', 'title': 'Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models', 'authors': 'Frederike Lübeck, Jonas Wildberger, Frederik Träuble, Maximilian Mordig, Sergios Gatidis, Andreas Krause, Bernhard Schölkopf', 'link': 'https://arxiv.org/abs/2505.24655', 'abstract': 'Cardiovascular disease (CVD) risk prediction models are essential for identifying high-risk individuals and guiding preventive actions. However, existing models struggle with the challenges of real-world clinical practice as they oversimplify patient profiles, rely on rigid input schemas, and are sensitive to distribution shifts. We developed AdaCVD, an adaptable CVD risk prediction framework built on large language models extensively fine-tuned on over half a million participants from the UK Biobank. In benchmark comparisons, AdaCVD surpasses established risk scores and standard machine learning approaches, achieving state-of-the-art performance. Crucially, for the first time, it addresses key clinical challenges across three dimensions: it flexibly incorporates comprehensive yet variable patient information; it seamlessly integrates both structured data and unstructured text; and it rapidly adapts to new patient populations using minimal additional data. In stratified analyses, it demonstrates robust performance across demographic, socioeconomic, and clinical subgroups, including underrepresented cohorts. AdaCVD offers a promising path toward more flexible, AI-driven clinical decision support tools suited to the realities of heterogeneous and dynamic healthcare environments.', 'abstract_zh': '心血管疾病(CVD)风险预测模型对于识别高风险个体并指导预防措施至关重要。然而，现有模型在实际临床实践中面临简化患者特征、依赖固定输入模式以及对分布偏移敏感等挑战。我们开发了AdaCVD，这是一种基于广泛 Fine-Tuned 大型语言模型的心血管疾病风险预测框架，这些模型是在超过五十万来自英国生物库的参与者数据上训练的。在基准比较中，AdaCVD 超越了现有风险评分和标准机器学习方法，实现了最先进的性能。最关键的是，它首次从三个维度上解决了关键的临床挑战：灵活整合全面而多变的患者信息；无缝整合结构化数据和非结构化文本；并使用最少的额外数据迅速适应新的患者群体。在分层分析中，它在人口统计学、社会经济和临床子群体中，包括未充分代表的群体中表现出稳健的性能。AdaCVD 为更灵活的、基于人工智能的临床决策支持工具的发展提供了一条有希望的道路，这些工具适合异质且动态的医疗保健环境。', 'title_zh': '使用大型语言模型从异质数据中实现心血管疾病风险的适应性预测'}
{'arxiv_id': 'arXiv:2505.24601', 'title': 'Taxonomic Networks: A Representation for Neuro-Symbolic Pairing', 'authors': 'Zekun Wang, Ethan L. Haarer, Nicki Barari, Christopher J. MacLellan', 'link': 'https://arxiv.org/abs/2505.24601', 'abstract': 'We introduce the concept of a \\textbf{neuro-symbolic pair} -- neural and symbolic approaches that are linked through a common knowledge representation. Next, we present \\textbf{taxonomic networks}, a type of discrimination network in which nodes represent hierarchically organized taxonomic concepts. Using this representation, we construct a novel neuro-symbolic pair and evaluate its performance. We show that our symbolic method learns taxonomic nets more efficiently with less data and compute, while the neural method finds higher-accuracy taxonomic nets when provided with greater resources. As a neuro-symbolic pair, these approaches can be used interchangeably based on situational needs, with seamless translation between them when necessary. This work lays the foundation for future systems that more fundamentally integrate neural and symbolic computation.', 'abstract_zh': '我们引入了神经符号对（neuro-symbolic pair）的概念——通过共同的知识表示连接神经和符号方法。接着，我们提出了分类网络（taxonomic networks）这一类型的选择网络，其中节点表示层次组织的分类概念。利用这种表示，我们构建了一种新的神经符号对并评估了其性能。我们证明，我们的符号方法可以在较少数据和计算资源的情况下更有效地学习分类网，而神经方法在获得更多资源时可以发现更高准确性的分类网。作为神经符号对，这些方法可以根据具体情况互换使用，并在必要时无缝转换。这项工作为未来更根本地整合神经和符号计算的系统奠定了基础。', 'title_zh': '税onomic网络：一种神经符号配对表示方法'}
{'arxiv_id': 'arXiv:2505.24426', 'title': 'P: A Universal Measure of Predictive Intelligence', 'authors': 'David Gamez', 'link': 'https://arxiv.org/abs/2505.24426', 'abstract': 'Over the last thirty years, considerable progress has been made with the development of systems that can drive cars, play games, predict protein folding and generate natural language. These systems are described as intelligent and there has been a great deal of talk about the rapid increase in artificial intelligence and its potential dangers. However, our theoretical understanding of intelligence and ability to measure it lag far behind our capacity for building systems that mimic intelligent human behaviour. There is no commonly agreed definition of the intelligence that AI systems are said to possess. No-one has developed a practical measure that would enable us to compare the intelligence of humans, animals and AIs on a single ratio scale.\nThis paper sets out a new universal measure of intelligence that is based on the hypothesis that prediction is the most important component of intelligence. As an agent interacts with its normal environment, the accuracy of its predictions is summed up and the complexity of its predictions and perceived environment is accounted for using Kolmogorov complexity. Two experiments were carried out to evaluate the practical feasibility of the algorithm. These demonstrated that it could measure the intelligence of an agent embodied in a virtual maze and an agent that makes predictions about time-series data. This universal measure could be the starting point for a new comparative science of intelligence that ranks humans, animals and AIs on a single ratio scale.', 'abstract_zh': '过去三十年间，随着能够驾驶汽车、玩游戏、预测蛋白质折叠和生成自然语言的系统的发展，取得了一定的进步。这些系统被描述为智能的，并且关于人工智能的迅速发展及其潜在危险的讨论很多。然而，对于智能的理论理解以及衡量智能的能力远远落后于构建模仿人类智能行为的系统的能力建立。目前尚无一致认可的人工智能系统所具备的智能的定义。也没有开发出有效的测量工具，以在单一比例尺度上比较人类、动物和人工智能的智能水平。本文提出了一种新的通用智能度量标准，基于预测是智能最重要组成部分的假设。通过一个代理与其正常环境的交互，其预测的准确性被汇总，预测的复杂性和感知环境的复杂性则使用柯尔莫哥洛夫复杂性来进行量化。进行了两个实验以评估该算法的实际可行性。结果显示，它可以测量在虚拟迷宫中行动的代理和预测时间序列数据的代理的智能水平。这种通用的度量标准可能是建立一个新的智能比较科学的基础，该科学能在单一比例尺度上对人类、动物和人工智能进行排名。', 'title_zh': 'P: 通用预测智能度量'}
{'arxiv_id': 'arXiv:2505.24422', 'title': 'Three Kinds of Negation in Knowledge and Their Mathematical Foundations', 'authors': 'Zhenghua Pan, Yong Wang', 'link': 'https://arxiv.org/abs/2505.24422', 'abstract': 'In the field of artificial intelligence, understanding, distinguishing, expressing, and computing the negation in knowledge is a fundamental issue in knowledge processing and research. In this paper, we examine and analyze the understanding and characteristics of negation in various fields such as philosophy, logic, and linguistics etc. Based on the distinction between the concepts of contradiction and opposition, we propose that there are three different types of negation in knowledge from a conceptual perspective: contradictory negation, opposite negation, and intermediary negation. To establish a mathematical foundation that fully reflects the intrinsic connections, properties, and laws of these different forms of negation, we introduce SCOI: sets with contradictory negation, opposite negation and intermediary negation, and LCOI: logic with contradictory negation, opposite negation and intermediary negation, and we proved the main operational properties of SCOI as well as the formal inference relations in LCOI.', 'abstract_zh': '在人工智能领域，理解、区分、表达和计算知识中的否定是知识处理和研究中的一个基本问题。本文从哲学、逻辑和语言学等多个领域考察和分析了否定的理解与特性，基于矛盾与对立概念的区别，提出了从概念上知识中有三种不同类型的否定：矛盾否定、对立否定和中间否定。为全面反映这些不同形式否定的内在联系、属性和规律，我们引入了SCOI：具有矛盾否定、对立否定和中间否定的集合，以及LCOI：具有矛盾否定、对立否定和中间否定的逻辑，并证明了SCOI的主要操作性质以及LCOI中的形式推理关系。', 'title_zh': '知识中的三种否定及其数学基础'}
{'arxiv_id': 'arXiv:2505.24226', 'title': 'E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness', 'authors': 'Yibo Zhao, Jiapeng Zhu, Ye Guo, Kangkang He, Xiang Li', 'link': 'https://arxiv.org/abs/2505.24226', 'abstract': 'Graph-based RAG methods like GraphRAG have shown promising global understanding of the knowledge base by constructing hierarchical entity graphs. However, they often suffer from inefficiency and rely on manually pre-defined query modes, limiting practical use. In this paper, we propose E^2GraphRAG, a streamlined graph-based RAG framework that improves both Efficiency and Effectiveness. During the indexing stage, E^2GraphRAG constructs a summary tree with large language models and an entity graph with SpaCy based on document chunks. We then construct bidirectional indexes between entities and chunks to capture their many-to-many relationships, enabling fast lookup during both local and global retrieval. For the retrieval stage, we design an adaptive retrieval strategy that leverages the graph structure to retrieve and select between local and global modes. Experiments show that E^2GraphRAG achieves up to 10 times faster indexing than GraphRAG and 100 times speedup over LightRAG in retrieval while maintaining competitive QA performance.', 'abstract_zh': '基于图的RAG方法如GraphRAG通过构建层次实体图展示了对知识库的全局理解潜力，但往往存在效率低下和依赖手动预定义查询模式的问题，限制了其实用性。本文提出了一种改进效率和效果的流线型基于图的RAG框架E^2GraphRAG。在索引阶段，E^2GraphRAG利用大型语言模型和基于文档片段的SpaCy构建摘要树和实体图。然后构建实体与片段之间的双向索引，以捕捉它们的多对多关系，在局部和全局检索中均能实现快速查找。在检索阶段，设计了一种适应性的检索策略，利用图结构在局部和全局模式之间进行检索和选择。实验结果显示，与GraphRAG相比，E^2GraphRAG的索引速度提高了10倍，与LightRAG相比检索速度提高了100倍，同时保持了竞争力的问答性能。', 'title_zh': 'E^2GraphRAG: 简化基于图的RAG以提高效率和效果'}
{'arxiv_id': 'arXiv:2505.24872', 'title': 'ProxyThinker: Test-Time Guidance through Small Visual Reasoners', 'authors': 'Zilin Xiao, Jaywon Koo, Siru Ouyang, Jefferson Hernandez, Yu Meng, Vicente Ordonez', 'link': 'https://arxiv.org/abs/2505.24872', 'abstract': 'Recent advancements in reinforcement learning with verifiable rewards have pushed the boundaries of the visual reasoning capabilities in large vision-language models (LVLMs). However, training LVLMs with reinforcement fine-tuning (RFT) is computationally expensive, posing a significant challenge to scaling model size. In this work, we propose ProxyThinker, an inference-time technique that enables large models to inherit the visual reasoning capabilities from small, slow-thinking visual reasoners without any training. By subtracting the output distributions of base models from those of RFT reasoners, ProxyThinker modifies the decoding dynamics and successfully elicits the slow-thinking reasoning demonstrated by the emerged sophisticated behaviors such as self-verification and self-correction. ProxyThinker consistently boosts performance on challenging visual benchmarks on spatial, mathematical, and multi-disciplinary reasoning, enabling untuned base models to compete with the performance of their full-scale RFT counterparts. Furthermore, our implementation efficiently coordinates multiple language models with parallelism techniques and achieves up to 38 $\\times$ faster inference compared to previous decoding-time methods, paving the way for the practical deployment of ProxyThinker. Code is available at this https URL.', 'abstract_zh': '近期可验证奖励强化学习的进展推动了大规模视觉语言模型的视觉推理能力边界。然而，使用强化微调（RFT）训练LVLMs在计算上非常昂贵，给模型规模的扩展带来了显著挑战。在本文中，我们提出了ProxyThinker，一种推理时技术，使大模型能够继承小型慢思考视觉推理器的视觉推理能力，而无需任何训练。通过从RFT推理器的输出分布中减去基础模型的输出分布，ProxyThinker修改了解码动力学，并成功激发了由复杂行为（如自我验证和自我修正）表现出的慢思考推理。ProxyThinker在空间、数学和跨学科推理等具有挑战性的视觉基准测试中一致地提升了性能，使未微调的基础模型能够与全规模RFT对应物的性能相竞争。此外，我们的实现利用并行技术高效协调多个语言模型，并达到了比之前解码时方法快38倍的推理速度，为ProxyThinker的实际部署铺平了道路。代码可通过以下链接获得：this https URL。', 'title_zh': 'ProxyThinker：通过小型视觉推理器实现测试时指导'}
{'arxiv_id': 'arXiv:2505.24838', 'title': 'VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software', 'authors': 'Brandon Man, Ghadi Nehme, Md Ferdous Alam, Faez Ahmed', 'link': 'https://arxiv.org/abs/2505.24838', 'abstract': "Computer-Aided Design (CAD) is a time-consuming and complex process, requiring precise, long-horizon user interactions with intricate 3D interfaces. While recent advances in AI-driven user interface (UI) agents show promise, most existing datasets and methods focus on short, low-complexity tasks in mobile or web applications, failing to capture the demands of professional engineering tools. In this work, we introduce VideoCAD, the first attempt at engineering UI interaction learning for precision tasks. Specifically, VideoCAD is a large-scale synthetic dataset consisting of over 41K annotated video recordings of CAD operations, generated using an automated framework for collecting high-fidelity UI action data from human-made CAD designs. Compared to existing datasets, VideoCAD offers an order of magnitude higher complexity in UI interaction learning for real-world engineering tasks, having up to a 20x longer time horizon than other datasets. We show two important downstream applications of VideoCAD: learning UI interactions from professional precision 3D CAD tools and a visual question-answering (VQA) benchmark designed to evaluate multimodal large language models' (LLM) spatial reasoning and video understanding abilities. To learn the UI interactions, we propose VideoCADFormer - a state-of-the-art model in learning CAD interactions directly from video, which outperforms multiple behavior cloning baselines. Both VideoCADFormer and the VQA benchmark derived from VideoCAD reveal key challenges in the current state of video-based UI understanding, including the need for precise action grounding, multi-modal and spatial reasoning, and long-horizon dependencies.", 'abstract_zh': '计算机辅助设计（CAD）的交互学习：VideoCAD的研究', 'title_zh': 'VideoCAD：一种用于学习UI交互和3D推理的大型视频数据集，源于CAD软件'}
{'arxiv_id': 'arXiv:2505.24791', 'title': 'Inference Acceleration of Autoregressive Normalizing Flows by Selective Jacobi Decoding', 'authors': 'Jiaru Zhang, Juanwu Lu, Ziran Wang, Ruqi Zhang', 'link': 'https://arxiv.org/abs/2505.24791', 'abstract': "Normalizing flows are promising generative models with advantages such as theoretical rigor, analytical log-likelihood computation, and end-to-end training. However, the architectural constraints to ensure invertibility and tractable Jacobian computation limit their expressive power and practical usability. Recent advancements utilize autoregressive modeling, significantly enhancing expressive power and generation quality. However, such sequential modeling inherently restricts parallel computation during inference, leading to slow generation that impedes practical deployment. In this paper, we first identify that strict sequential dependency in inference is unnecessary to generate high-quality samples. We observe that patches in sequential modeling can also be approximated without strictly conditioning on all preceding patches. Moreover, the models tend to exhibit low dependency redundancy in the initial layer and higher redundancy in subsequent layers. Leveraging these observations, we propose a selective Jacobi decoding (SeJD) strategy that accelerates autoregressive inference through parallel iterative optimization. Theoretical analyses demonstrate the method's superlinear convergence rate and guarantee that the number of iterations required is no greater than the original sequential approach. Empirical evaluations across multiple datasets validate the generality and effectiveness of our acceleration technique. Experiments demonstrate substantial speed improvements up to 4.7 times faster inference while keeping the generation quality and fidelity.", 'abstract_zh': '严格顺序依赖性在推断中不是生成高质量样本所必需的：一种基于选择性雅可比解码的并行加速自回归推断方法', 'title_zh': '自回归规范流的选择性雅基解码加速推理'}
{'arxiv_id': 'arXiv:2505.24767', 'title': 'A survey of using EHR as real-world evidence for discovering and validating new drug indications', 'authors': 'Nabasmita Talukdar, Xiaodan Zhang, Shreya Paithankar, Hui Wang, Bin Chen', 'link': 'https://arxiv.org/abs/2505.24767', 'abstract': 'Electronic Health Records (EHRs) have been increasingly used as real-world evidence (RWE) to support the discovery and validation of new drug indications. This paper surveys current approaches to EHR-based drug repurposing, covering data sources, processing methodologies, and representation techniques. It discusses study designs and statistical frameworks for evaluating drug efficacy. Key challenges in validation are discussed, with emphasis on the role of large language models (LLMs) and target trial emulation. By synthesizing recent developments and methodological advances, this work provides a foundational resource for researchers aiming to translate real-world data into actionable drug-repurposing evidence.', 'abstract_zh': '电子健康记录（EHRs）在支持新药适应症发现和验证中的应用日益增加：基于EHR的药物再利用现状综述及其挑战', 'title_zh': 'EHR在发现和验证新药适应证中的实际世界证据综述'}
{'arxiv_id': 'arXiv:2505.24765', 'title': 'Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications', 'authors': 'Srikanth Thudumu, Jason Fisher, Hung Du', 'link': 'https://arxiv.org/abs/2505.24765', 'abstract': 'Supervised Quantum Machine Learning (QML) represents an intersection of quantum computing and classical machine learning, aiming to use quantum resources to support model training and inference. This paper reviews recent developments in supervised QML, focusing on methods such as variational quantum circuits, quantum neural networks, and quantum kernel methods, along with hybrid quantum-classical workflows. We examine recent experimental studies that show partial indications of quantum advantage and describe current limitations including noise, barren plateaus, scalability issues, and the lack of formal proofs of performance improvement over classical methods. The main contribution is a ten-year outlook (2025-2035) that outlines possible developments in supervised QML, including a roadmap describing conditions under which QML may be used in applied research and enterprise systems over the next decade.', 'abstract_zh': '监督量子机器学习（QML）代表了量子计算与经典机器学习的交叉领域，旨在利用量子资源支持模型训练和推理。本文回顾了监督QML的 Recent Developments，重点关注变量子电路、量子神经网络和量子核方法等方法，以及混合量子-经典工作流。我们考察了最近的实验研究，这些研究展示了部分量子优势的迹象，并描述了当前的限制，包括噪声、荒原 plateau 问题、可扩展性问题以及对性能改进缺乏形式证明的问题。主要贡献是提出了 2025-2035 年的十年展望，概述了监督QML在未来十年可能的发展，包括可用于应用研究和企业系统的路线图条件。', 'title_zh': '监督量子机器学习：从量子位到企业应用的未来展望'}
{'arxiv_id': 'arXiv:2505.24760', 'title': 'REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards', 'authors': 'Zafir Stojanovski, Oliver Stanley, Joe Sharratt, Richard Jones, Abdulhakeem Adefioye, Jean Kaddour, Andreas Köpf', 'link': 'https://arxiv.org/abs/2505.24760', 'abstract': 'We introduce Reasoning Gym (RG), a library of reasoning environments for reinforcement learning with verifiable rewards. It provides over 100 data generators and verifiers spanning multiple domains including algebra, arithmetic, computation, cognition, geometry, graph theory, logic, and various common games. Its key innovation is the ability to generate virtually infinite training data with adjustable complexity, unlike most previous reasoning datasets, which are typically fixed. This procedural generation approach allows for continuous evaluation across varying difficulty levels. Our experimental results demonstrate the efficacy of RG in both evaluating and reinforcement learning of reasoning models.', 'abstract_zh': '我们介绍了Reasoning Gym (RG)：一种增强学习的可验证奖励推理环境库，涵盖代数、算术、计算、认知、几何、图论、逻辑以及多种常见游戏等多个领域，具备生成可调节复杂度的几乎无限训练数据的能力，实验结果证明了RG在推理模型评估和训练中的有效性。', 'title_zh': '推理健身房：具有可验证奖励的强化学习推理环境'}
{'arxiv_id': 'arXiv:2505.24759', 'title': 'Unsupervised Evolutionary Cell Type Matching via Entropy-Minimized Optimal Transport', 'authors': 'Mu Qiao', 'link': 'https://arxiv.org/abs/2505.24759', 'abstract': 'Identifying evolutionary correspondences between cell types across species is a fundamental challenge in comparative genomics and evolutionary biology. Existing approaches often rely on either reference-based matching, which imposes asymmetry by designating one species as the reference, or projection-based matching, which may increase computational complexity and obscure biological interpretability at the cell-type level. Here, we present OT-MESH, an unsupervised computational framework leveraging entropy-regularized optimal transport (OT) to systematically determine cross-species cell type homologies. Our method uniquely integrates the Minimize Entropy of Sinkhorn (MESH) technique to refine the OT plan. It begins by selecting genes with high Signal-to-Noise Ratio (SNR) to capture the most informative features, from which a cost matrix is constructed using cosine distances between cell-type centroids. Importantly, the MESH procedure iteratively refines the cost matrix, leading to a transport plan with significantly enhanced sparsity and interpretability of the resulting correspondence matrices. Applied to retinal bipolar cells (BCs) and retinal ganglion cells (RGCs) from mouse and macaque, OT-MESH accurately recovers known evolutionary relationships and uncovers novel correspondences, one of which was independently validated experimentally. Thus, our framework offers a principled, scalable, symmetric, and interpretable solution for evolutionary cell type mapping, facilitating deeper insights into cellular specialization and conservation across species.', 'abstract_zh': '基于最优传输的熵正则化方法在物种间细胞类型同源性识别中的应用：OT-MESH框架', 'title_zh': '无监督进化细胞类型匹配：基于熵最小化最优传输的方法'}
{'arxiv_id': 'arXiv:2505.24754', 'title': "Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation", 'authors': 'Yingchaojie Feng, Yiqun Sun, Yandong Sun, Minfeng Zhu, Qiang Huang, Anthony K. H. Tung, Wei Chen', 'link': 'https://arxiv.org/abs/2505.24754', 'abstract': 'In this work, we investigate an important task named instruction-following text embedding, which generates dynamic text embeddings that adapt to user instructions, highlighting specific attributes of text. Despite recent advancements, existing approaches suffer from significant computational overhead, as they require re-encoding the entire corpus for each new instruction. To address this challenge, we propose GSTransform, a novel instruction-following text embedding framework based on Guided Space Transformation. Our key observation is that instruction-relevant information is inherently encoded in generic embeddings but remains underutilized. Instead of repeatedly encoding the corpus for each instruction, GSTransform is a lightweight transformation mechanism that adapts pre-computed embeddings in real time to align with user instructions, guided by a small amount of text data with instruction-focused label annotation. We conduct extensive experiments on three instruction-awareness downstream tasks across nine real-world datasets, demonstrating that GSTransform improves instruction-following text embedding quality over state-of-the-art methods while achieving dramatic speedups of 6~300x in real-time processing on large-scale datasets. The source code is available at this https URL.', 'abstract_zh': '在本工作中，我们调查了一个名为指令跟随文本嵌入的重要任务，该任务生成能够适应用户指令的动态文本嵌入，突出文本的特定属性。尽管近期取得了一定进展，现有的方法仍存在显著的计算开销问题，因为它们需要为每个新的指令重新编码整个语料库。为了解决这一挑战，我们提出了一种基于引导空间转化的新型指令跟随文本嵌入框架GSTransform。我们的关键观察是，与指令相关的信息已经在通用嵌入中隐式编码，但仍未得到充分利用。与为每个指令反复重新编码语料库不同，GSTransform 是一种轻量级的转化机制，能够实时调整预计算的嵌入，以与用户指令对齐，该过程仅需少量带有指令集中注释的文本数据的引导。我们在三个指令感知下游任务上的九个实际数据集上进行了广泛的实验，证明GSTransform 在保持嵌入质量的同时，能够在大规模数据集上实现6~300倍的实时处理速度提升。源代码可在以下链接获取。', 'title_zh': '不要重造轮子：基于引导空间转换的高效指令遵循文本嵌入'}
{'arxiv_id': 'arXiv:2505.24715', 'title': 'CoRet: Improved Retriever for Code Editing', 'authors': 'Fabio Fehr, Prabhu Teja Sivaprasad, Luca Franceschi, Giovanni Zappella', 'link': 'https://arxiv.org/abs/2505.24715', 'abstract': "In this paper, we introduce CoRet, a dense retrieval model designed for code-editing tasks that integrates code semantics, repository structure, and call graph dependencies. The model focuses on retrieving relevant portions of a code repository based on natural language queries such as requests to implement new features or fix bugs. These retrieved code chunks can then be presented to a user or to a second code-editing model or agent. To train CoRet, we propose a loss function explicitly designed for repository-level retrieval. On SWE-bench and Long Code Arena's bug localisation datasets, we show that our model substantially improves retrieval recall by at least 15 percentage points over existing models, and ablate the design choices to show their importance in achieving these results.", 'abstract_zh': '本文介绍了CoRet，一种用于代码编辑任务的密集检索模型，融合了代码语义、仓库结构和调用图依赖关系。该模型专注于根据诸如实现新功能或修复bug等自然语言查询检索代码仓库的相关部分。获取的代码片段可以呈现给用户或第二代码编辑模型或代理。为了训练CoRet，我们提出了一种显式针对仓库级别检索设计的损失函数。在SWE-bench和Long Code Arena的bug定位数据集中，我们展示了我们的模型在检索召回率上比现有模型提高了至少15个百分点，并消融了设计选择以证明其对实现这些结果的重要性。', 'title_zh': 'CoRet: 提升的代码编辑检索器'}
{'arxiv_id': 'arXiv:2505.24709', 'title': 'On Symmetric Losses for Robust Policy Optimization with Noisy Preferences', 'authors': 'Soichiro Nishimori, Yu-Jie Zhang, Thanawat Lodkaew, Masashi Sugiyama', 'link': 'https://arxiv.org/abs/2505.24709', 'abstract': 'Optimizing policies based on human preferences is key to aligning language models with human intent. This work focuses on reward modeling, a core component in reinforcement learning from human feedback (RLHF), and offline preference optimization, such as direct preference optimization. Conventional approaches typically assume accurate annotations. However, real-world preference data often contains noise due to human errors or biases. We propose a principled framework for robust policy optimization under noisy preferences, viewing reward modeling as a classification problem. This allows us to leverage symmetric losses, known for their robustness to label noise in classification, leading to our Symmetric Preference Optimization (SymPO) method. We prove that symmetric losses enable successful policy optimization even under noisy labels, as the resulting reward remains rank-preserving -- a property sufficient for policy improvement. Experiments on synthetic and real-world tasks demonstrate the effectiveness of SymPO.', 'abstract_zh': '基于人类偏好的政策优化是将语言模型与人类意图对齐的关键。本工作聚焦于奖励建模，这是人类反馈强化学习（RLHF）的核心组件之一，以及离线偏好优化，如直接偏好优化。传统方法通常假设标注准确。然而，实际的偏好数据由于人类错误或偏差往往包含噪声。我们提出了一个稳健的政策优化框架，将奖励建模视为分类问题，从而利用对标签噪声具有鲁棒性的对称损失，提出了一种对称偏好优化（SymPO）方法。我们证明了对称损失即使在噪声标签下也能成功进行政策优化，因为产生的奖励保持了排名不变——这是政策改进所需的属性。实验证明了SymPO的有效性。', 'title_zh': '关于稳健策略优化中无噪音偏好下的对称损失方法'}
{'arxiv_id': 'arXiv:2505.24684', 'title': 'Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs', 'authors': 'Zihao Chen, Yu Xiang, Wenyong Wang', 'link': 'https://arxiv.org/abs/2505.24684', 'abstract': 'Despite the success in learning semantically meaningful, unsupervised disentangled representations, variational autoencoders (VAEs) and their variants face a fundamental theoretical challenge: substantial evidence indicates that unsupervised disentanglement is unattainable without implicit inductive bias, yet such bias remains elusive. In this work, we focus on exploring the implicit inductive bias that drive disentanglement in VAEs with factorization priors. By analyzing the total correlation in \\b{eta}-TCVAE, we uncover a crucial implicit inductive bias called disentangling granularity, which leads to the discovery of an interesting "V"-shaped optimal Evidence Lower Bound (ELBO) trajectory within the parameter space. This finding is validated through over 100K experiments using factorized VAEs and our newly proposed model, \\b{eta}-STCVAE. Notably, experimental results reveal that conventional factorized VAEs, constrained by fixed disentangling granularity, inherently tend to disentangle low-complexity feature. Whereas, appropriately tuning disentangling granularity, as enabled by \\b{eta}-STCVAE, broadens the range of disentangled representations, allowing for the disentanglement of high-complexity features. Our findings unveil that disentangling granularity as an implicit inductive bias in factorized VAEs influence both disentanglement performance and the inference of the ELBO, offering fresh insights into the interpretability and inherent biases of VAEs.', 'abstract_zh': '因子化先验下变分自编码器中隐含归纳偏置的探索：解缠粒度的影响', 'title_zh': '粒度分解：因子化VAEs中的隐式归纳偏见'}
{'arxiv_id': 'arXiv:2505.24683', 'title': 'Should I Share this Translation? Evaluating Quality Feedback for User Reliance on Machine Translation', 'authors': 'Dayeon Ki, Kevin Duh, Marine Carpuat', 'link': 'https://arxiv.org/abs/2505.24683', 'abstract': 'As people increasingly use AI systems in work and daily life, feedback mechanisms that help them use AI responsibly are urgently needed, particularly in settings where users are not equipped to assess the quality of AI predictions. We study a realistic Machine Translation (MT) scenario where monolingual users decide whether to share an MT output, first without and then with quality feedback. We compare four types of quality feedback: explicit feedback that directly give users an assessment of translation quality using 1) error highlights and 2) LLM explanations, and implicit feedback that helps users compare MT inputs and outputs through 3) backtranslation and 4) question-answer (QA) tables. We find that all feedback types, except error highlights, significantly improve both decision accuracy and appropriate reliance. Notably, implicit feedback, especially QA tables, yields significantly greater gains than explicit feedback in terms of decision accuracy, appropriate reliance, and user perceptions, receiving the highest ratings for helpfulness and trust, and the lowest for mental burden.', 'abstract_zh': '随着人们在工作和日常生活中 increasingly 使用 AI 系统，特别是在用户不具备评估 AI 预测质量能力的场景中，需要相应的反馈机制帮助他们负责任地使用 AI。我们研究了一个现实的机器翻译 (MT) 情景，其中独语用户在有和没有质量反馈的情况下决定是否分享 MT 输出。我们比较了四种类型的质量反馈：直接给出翻译质量评估的显式反馈（包括 1）错误高亮和 2）大模型解释），以及通过 3）回译和 4）问答（QA）表帮助用户比较 MT 输入和输出的隐式反馈。我们发现，除了错误高亮外，所有类型的反馈都显著提高了决策准确性和适当的依赖性。值得注意的是，隐式反馈，尤其是 QA 表，在决策准确性和适当依赖性方面以及用户感知方面带来了显著更大的增益，并收到了最高的有用性和信任度评分，以及最低的认知负担评分。', 'title_zh': '我应该分享这个翻译吗？基于机器翻译质量反馈的用户依赖评估'}
{'arxiv_id': 'arXiv:2505.24681', 'title': 'Generative Knowledge Production Pipeline Driven by Academic Influencers', 'authors': 'Katalin Feher, Marton Demeter', 'link': 'https://arxiv.org/abs/2505.24681', 'abstract': "Generative AI transforms knowledge production, validation, and dissemination, raising academic integrity and credibility concerns. This study examines 53 academic influencer videos that reached 5.3 million viewers to identify an emerging, structured, implementation-ready pipeline balancing originality, ethical compliance, and human-AI collaboration despite the disruptive impacts. Findings highlight generative AI's potential to automate publication workflows and democratize participation in knowledge production while challenging traditional scientific norms. Academic influencers emerge as key intermediaries in this paradigm shift, connecting bottom-up practices with institutional policies to improve adaptability. Accordingly, the study proposes a generative publication production pipeline and a policy framework for co-intelligence adaptation and reinforcing credibility-centered standards in AI-powered research. These insights support scholars, educators, and policymakers in understanding AI's transformative impact by advocating responsible and innovation-driven knowledge production. Additionally, they reveal pathways for automating best practices, optimizing scholarly workflows, and fostering creativity in academic research and publication.", 'abstract_zh': '生成式AI变革知识生产、验证和传播，引发学术诚信和可信度 Concerns. 本研究分析了53个学术影响力视频，观看人次达530万，旨在识别一种平衡原创性、伦理合规性和人类-AI协作的新兴结构化实施流程，尽管受到颠覆性影响。研究发现强调生成式AI有潜力自动化出版工作流程并使知识生产民主化，同时挑战传统科学规范。学术影响力者成为这一范式转变中的关键中介，连接自下而上的实践与机构政策，提高适应性。据此，本研究提出了一种生成式出版生产流程和一种促进AI驱动研究中协同智能适应及强化以可信度为中心的标准的政策框架。这些见解支持学者、教育者和政策制定者理解AI的变革影响，倡导负责任和创新驱动的知识生产。此外，它们揭示了自动化最佳实践、优化学者工作流程和激发学术研究与出版中创造力的途径。', 'title_zh': '由学术影响力驱动的生成性知识生产流水线'}
{'arxiv_id': 'arXiv:2505.24623', 'title': 'Hyperbolic Dataset Distillation', 'authors': 'Wenyuan Li, Guang Li, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama', 'link': 'https://arxiv.org/abs/2505.24623', 'abstract': 'To address the computational and storage challenges posed by large-scale datasets in deep learning, dataset distillation has been proposed to synthesize a compact dataset that replaces the original while maintaining comparable model performance. Unlike optimization-based approaches that require costly bi-level optimization, distribution matching (DM) methods improve efficiency by aligning the distributions of synthetic and original data, thereby eliminating nested optimization. DM achieves high computational efficiency and has emerged as a promising solution. However, existing DM methods, constrained to Euclidean space, treat data as independent and identically distributed points, overlooking complex geometric and hierarchical relationships. To overcome this limitation, we propose a novel hyperbolic dataset distillation method, termed HDD. Hyperbolic space, characterized by negative curvature and exponential volume growth with distance, naturally models hierarchical and tree-like structures. HDD embeds features extracted by a shallow network into the Lorentz hyperbolic space, where the discrepancy between synthetic and original data is measured by the hyperbolic (geodesic) distance between their centroids. By optimizing this distance, the hierarchical structure is explicitly integrated into the distillation process, guiding synthetic samples to gravitate towards the root-centric regions of the original data distribution while preserving their underlying geometric characteristics. Furthermore, we find that pruning in hyperbolic space requires only 20% of the distilled core set to retain model performance, while significantly improving training stability. Notably, HDD is seamlessly compatible with most existing DM methods, and extensive experiments on different datasets validate its effectiveness.', 'abstract_zh': '针对大规模数据集在深度学习中带来的计算和存储挑战，数据集蒸馏已被提出以合成一个紧凑的数据集来替代原始数据并维持相当的模型性能。不同于基于优化的方法需要昂贵的双层优化，分布匹配（DM）方法通过对齐合成数据和原始数据的分布来提高效率，从而消除嵌套优化。DM实现了高计算效率，并已成为一种有前途的解决方案。然而，现有的DM方法仅限于欧几里得空间，将数据视为独立同分布的点，忽略了复杂的几何和层次结构关系。为克服这一局限，我们提出了一种新颖的双曲空间数据集蒸馏方法，称为HDD。双曲空间以其负曲率和随距离呈指数增长的体积自然地建模了层次和树形结构。HDD将浅网络提取的特征嵌入洛伦兹双曲空间，其中合成数据与原始数据之间的差异由其质心之间的双曲（测地）距离衡量。通过优化这一距离，层次结构显式地整合到蒸馏过程中，引导合成样本向着原始数据分布的根中心区域聚集，同时保留其潜在的几何特性。此外，我们发现，在双曲空间中剪枝仅需蒸馏核心集的20%即可保持模型性能，同时显著提高训练稳定性。值得注意的是，HDD与大多数现有DM方法无缝兼容，不同数据集上的广泛实验验证了其有效性。', 'title_zh': '双曲数据集蒸馏'}
{'arxiv_id': 'arXiv:2505.24595', 'title': 'Binary Cumulative Encoding meets Time Series Forecasting', 'authors': 'Andrei Chernov, Vitaliy Pozdnyakov, Ilya Makarov', 'link': 'https://arxiv.org/abs/2505.24595', 'abstract': 'Recent studies in time series forecasting have explored formulating regression via classification task. By discretizing the continuous target space into bins and predicting over a fixed set of classes, these approaches benefit from stable training, robust uncertainty modeling, and compatibility with modern deep learning architectures. However, most existing methods rely on one-hot encoding that ignores the inherent ordinal structure of the underlying values. As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors. This encoding implicitly preserves order and magnitude information, allowing the model to learn distance-aware representations while still operating within a classification framework. We propose a convolutional neural network architecture specifically designed for BCE, incorporating residual and dilated convolutions to enable fast and expressive temporal modeling. Through extensive experiments on benchmark forecasting datasets, we show that our approach outperforms widely used methods in both point and probabilistic forecasting, while requiring fewer parameters and enabling faster training.', 'abstract_zh': '最近时间序列预测的研究探索了通过分类任务进行回归的方法。通过将连续的目标空间离散化为区间，并在固定类别的集合上进行预测，这些方法可以从稳定的训练、鲁棒的不确定性建模以及与现代深度学习架构的兼容性中受益。然而，现有的大多数方法依赖于独热编码，这忽略了底层值的固有序数结构。因此，它们在训练过程中无法提供关于预测值与真实值之间相对距离的信息。在本文中，我们提出了一种通过引入二元累积编码（BCE）来解决这一局限性，该编码将标量目标表示为单调的二元向量。这种编码隐式地保留了顺序和幅度信息，使模型能够在分类框架中学习距离感知的表示。我们提出了一种专门为BCE设计的卷积神经网络架构，结合了残差连接和扩张卷积，以实现快速而富有表现力的时间建模。通过在基准预测数据集上的广泛实验，我们表明，与广泛使用的预测方法相比，我们的方法在点预测和概率预测方面表现更优，所需的参数更少，并能实现更快的训练。', 'title_zh': '二进制累积编码 meets 时间序列预测'}
{'arxiv_id': 'arXiv:2505.24593', 'title': 'Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis', 'authors': 'Junzhuo Li, Bo Wang, Xiuze Zhou, Peijie Jiang, Jia Liu, Xuming Hu', 'link': 'https://arxiv.org/abs/2505.24593', 'abstract': 'The interpretability of Mixture-of-Experts (MoE) models, especially those with heterogeneous designs, remains underexplored. Existing attribution methods for dense models fail to capture dynamic routing-expert interactions in sparse MoE architectures. To address this issue, we propose a cross-level attribution algorithm to analyze sparse MoE architectures (Qwen 1.5-MoE, OLMoE, Mixtral-8x7B) against dense models (Qwen 1.5-7B, Llama-7B, Mixtral-7B). Results show MoE models achieve 37% higher per-layer efficiency via a "mid-activation, late-amplification" pattern: early layers screen experts, while late layers refine knowledge collaboratively. Ablation studies reveal a "basic-refinement" framework--shared experts handle general tasks (entity recognition), while routed experts specialize in domain-specific processing (geographic attributes). Semantic-driven routing is evidenced by strong correlations between attention heads and experts (r=0.68), enabling task-aware coordination. Notably, architectural depth dictates robustness: deep Qwen 1.5-MoE mitigates expert failures (e.g., 43% MRR drop in geographic tasks when blocking top-10 experts) through shared expert redundancy, whereas shallow OLMoE suffers severe degradation (76% drop). Task sensitivity further guides design: core-sensitive tasks (geography) require concentrated expertise, while distributed-tolerant tasks (object attributes) leverage broader participation. These insights advance MoE interpretability, offering principles to balance efficiency, specialization, and robustness.', 'abstract_zh': 'MoE模型的可解释性，特别是异构设计的模型，仍处于未探索阶段。现有的密集模型归因方法无法捕捉稀疏MoE架构中的路由-专家动态交互。为解决这一问题，我们提出了一种跨级归因算法，用于分析稀疏MoE架构（Qwen 1.5-MoE, OLMoE, Mixtral-8x7B）与密集模型（Qwen 1.5-7B, Llama-7B, Mixtral-7B）之间的差异。结果表明，MoE模型通过“中间激活，后期放大”模式实现每层37%的效率提升：早期层筛选专家，而后期层协作细化知识。消融研究揭示了“基础-精炼”框架——共享专家处理通用任务（实体识别），而路由专家专门处理领域特定处理（地理属性）。以语义为导向的路由通过注意力头与专家之间强烈的相关性（r=0.68）凸显，实现任务感知的协调。值得注意的是，架构深度决定了鲁棒性：深度的Qwen 1.5-MoE通过共享专家冗余来缓解专家故障（例如，封锁顶级10个专家时地理任务的MRR下降43%），而浅层的OLMoE遭受严重降解（76%的下降）。任务敏感性进一步指导设计：核心敏感任务（地理）需要集中的专业知识，而分布式耐受任务（对象属性）利用更广泛的参与。这些洞见推进了MoE的可解释性，提供了平衡效率、专业化和鲁棒性的原则。', 'title_zh': '混合专家体系中知识归因的解码：基础-精炼协作与效率分析'}
{'arxiv_id': 'arXiv:2505.24592', 'title': 'A Flat Minima Perspective on Understanding Augmentations and Model Robustness', 'authors': 'Weebum Yoo, Sung Whan Yoon', 'link': 'https://arxiv.org/abs/2505.24592', 'abstract': "Model robustness indicates a model's capability to generalize well on unforeseen distributional shifts, including data corruption, adversarial attacks, and domain shifts. Data augmentation is one of the prevalent and effective ways to enhance robustness. Despite the great success of augmentations in different fields, a general theoretical understanding of their efficacy in improving model robustness is lacking. We offer a unified theoretical framework to clarify how augmentations can enhance model robustness through the lens of loss surface flatness and PAC generalization bound. Our work diverges from prior studies in that our analysis i) broadly encompasses much of the existing augmentation methods, and ii) is not limited to specific types of distribution shifts like adversarial attacks. We confirm our theories through simulations on the existing common corruption and adversarial robustness benchmarks based on the CIFAR and ImageNet datasets, as well as domain generalization benchmarks including PACS and OfficeHome.", 'abstract_zh': '模型稳健性表明模型在未预见的数据分布变化、数据腐蚀、对抗攻击和领域变换等方面具有良好泛化能力的能力。数据增强是提高稳健性的一种常见且有效的方法。尽管数据增强在不同领域取得了巨大成功，但在提高模型稳健性方面的有效性上缺乏普遍的理论理解。我们提供了一个统一的理论框架，通过损失面平坦度和PAC泛化界的角度阐明数据增强如何提高模型稳健性。我们的工作与先前研究不同，因为我们对数据增强的分析i) 广泛涵盖了现有的大部分增强方法，ii) 不局限于特定类型的分布变化，如对抗攻击。我们通过在CIFAR和ImageNet数据集的现有通用腐蚀和对抗稳健性基准以及包括PACS和OfficeHome在内的领域泛化基准上的模拟验证了我们的理论。', 'title_zh': '从平坦极小值的角度理解增强和模型稳健性'}
{'arxiv_id': 'arXiv:2505.24584', 'title': 'AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams', 'authors': 'Sakhinana Sagar Srinivas, Shivam Gupta, Venkataramana Runkana', 'link': 'https://arxiv.org/abs/2505.24584', 'abstract': 'Recent advancements in generative AI have accelerated the discovery of novel chemicals and materials; however, transitioning these discoveries to industrial-scale production remains a critical bottleneck, as it requires the development of entirely new chemical manufacturing processes. Current AI methods cannot auto-generate PFDs or PIDs, despite their critical role in scaling chemical processes, while adhering to engineering constraints. We present a closed loop, physics aware framework for the automated generation of industrially viable PFDs and PIDs. The framework integrates domain specialized small scale language models (SLMs) (trained for chemical process QA tasks) with first principles simulation, leveraging three key components: (1) a hierarchical knowledge graph of process flow and instrumentation descriptions for 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes domain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Retrieval-Augmented Instruction Tuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure feasibility. To improve both runtime efficiency and model compactness, the framework incorporates advanced inference time optimizations including FlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization, and Test Time Inference Scaling and independently applies structural pruning techniques (width and depth) guided by importance heuristics to reduce model size with minimal accuracy loss. Experiments demonstrate that the framework generates simulator-validated process descriptions with high fidelity, outperforms baseline methods in correctness, and generalizes to unseen chemicals. By bridging AI-driven design with industrial-scale feasibility, this work significantly reduces R&D timelines from lab discovery to plant deployment.', 'abstract_zh': 'Recent advancements in generative AI have accelerated the discovery of novel chemicals and materials; however, transitioning these discoveries to industrial-scale production remains a critical bottleneck, as it requires the development of entirely new chemical manufacturing processes. Current AI methods cannot auto-generate PFDs or PIDs, despite their critical role in scaling chemical processes, while adhering to engineering constraints. We present a closed loop, physics aware framework for the automated generation of industrially viable PFDs and PIDs. The framework integrates domain specialized small scale language models (SLMs) (trained for chemical process QA tasks) with first principles simulation, leveraging three key components: (1) a hierarchical knowledge graph of process flow and instrumentation descriptions for 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes domain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Retrieval-Augmented Instruction Tuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure feasibility. To improve both runtime efficiency and model compactness, the framework incorporates advanced inference time optimizations including FlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization, and Test Time Inference Scaling and independently applies structural pruning techniques (width and depth) guided by importance heuristics to reduce model size with minimal accuracy loss. Experiments demonstrate that the framework generates simulator-validated process descriptions with high fidelity, outperforms baseline methods in correctness, and generalizes to unseen chemicals. By bridging AI-driven design with industrial-scale feasibility, this work significantly reduces R&D timelines from lab discovery to plant deployment.\n\n标题：\n一种意识物理的闭环框架：用于工业可实现的PFD和PID的自动生成', 'title_zh': '自动生成化学工艺和仪器图的闭环、物理aware智能代理框架AutoChemSchematic AI'}
{'arxiv_id': 'arXiv:2505.24536', 'title': 'CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control', 'authors': 'Chaohui Xu, Qi Cui, Chip-Hong Chang', 'link': 'https://arxiv.org/abs/2505.24536', 'abstract': 'The pervasion of large-scale Deep Neural Networks (DNNs) and their enormous training costs make their intellectual property (IP) protection of paramount importance. Recently introduced passport-based methods attempt to steer DNN watermarking towards strengthening ownership verification against ambiguity attacks by modulating the affine parameters of normalization layers. Unfortunately, neither watermarking nor passport-based methods provide a holistic protection with robust ownership proof, high fidelity, active usage authorization and user traceability for offline access distributed models and multi-user Machine-Learning as a Service (MLaaS) cloud model. In this paper, we propose a Chameleon Hash-based Irreversible Passport (CHIP) protection framework that utilizes the cryptographic chameleon hash function to achieve all these goals. The collision-resistant property of chameleon hash allows for strong model ownership claim upon IP infringement and liable user traceability, while the trapdoor-collision property enables hashing of multiple user passports and licensee certificates to the same immutable signature to realize active usage control. Using the owner passport as an oracle, multiple user-specific triplets, each contains a passport-aware user model, a user passport, and a licensee certificate can be created for secure offline distribution. The watermarked master model can also be deployed for MLaaS with usage permission verifiable by the provision of any trapdoor-colliding user passports. CHIP is extensively evaluated on four datasets and two architectures to demonstrate its protection versatility and robustness. Our code is released at this https URL.', 'abstract_zh': '基于可逆хи曼散列的护照保护框架：用于大规模深度神经网络的综合保护', 'title_zh': 'CHIP: 铳龙哈希基不可逆通行证用于 robust 深度模型所有权验证及主动使用控制'}
{'arxiv_id': 'arXiv:2505.24533', 'title': 'Directional Non-Commutative Monoidal Structures with Interchange Law via Commutative Generators', 'authors': 'Mahesh Godavarti', 'link': 'https://arxiv.org/abs/2505.24533', 'abstract': 'We introduce a novel framework consisting of a class of algebraic structures that generalize one-dimensional monoidal systems into higher dimensions by defining per-axis composition operators subject to non-commutativity and a global interchange law. These structures, defined recursively from a base case of vector-matrix pairs, model directional composition in multiple dimensions while preserving structural coherence through commutative linear operators.\nWe show that the framework that unifies several well-known linear transforms in signal processing and data analysis. In this framework, data indices are embedded into a composite structure that decomposes into simpler components. We show that classic transforms such as the Discrete Fourier Transform (DFT), the Walsh transform, and the Hadamard transform are special cases of our algebraic structure. The framework provides a systematic way to derive these transforms by appropriately choosing vector and matrix pairs. By subsuming classical transforms within a common structure, the framework also enables the development of learnable transformations tailored to specific data modalities and tasks.', 'abstract_zh': '我们提出了一种新颖的框架，该框架包含一类代数结构，通过定义轴向组合操作并满足非交换性和全局交换定律，将一维单调系统推广到高维。这些结构从向量-矩阵对的基本情况进行递归定义，模型多维方向上的组合保持结构性上的连贯性，并通过交换的线性操作来实现。\n\n该框架统一了信号处理和数据分析中多种已知的线性变换。在此框架中，数据索引嵌入到可分解为更简单组件的复合结构中。我们证明经典的变换，如离散傅里叶变换（DFT）、沃尔什变换和哈达amard变换，都是我们代数结构的特殊情况。该框架提供了一种系统的方法，通过适当地选择向量和矩阵对来推导这些变换。通过在一个共同结构下包含经典变换，该框架还使针对特定数据模态和任务的可学习变换的发展成为可能。', 'title_zh': '基于交换生成元的方向非交换乘方结构与交換律'}
{'arxiv_id': 'arXiv:2505.24503', 'title': 'Online Fair Division with Additional Information', 'authors': 'Tzeh Yuan Neoh, Jannik Peters, Nicholas Teh', 'link': 'https://arxiv.org/abs/2505.24503', 'abstract': "We study the problem of fairly allocating indivisible goods to agents in an online setting, where goods arrive sequentially and must be allocated irrevocably to agents. Focusing on the popular fairness notions of envy-freeness, proportionality, and maximin share fairness (and their approximate variants), we ask how the availability of information on future goods influences the existence and approximability of fair allocations. In the absence of any such information, we establish strong impossibility results, demonstrating the inherent difficulty of achieving even approximate fairness guarantees. In contrast, we demonstrate that knowledge of additional information -- such as aggregate of each agent's total valuations (equivalently, normalized valuations) or the multiset of future goods values (frequency predictions) -- would enable the design of fairer online algorithms. Given normalization information, we propose an algorithm that achieves stronger fairness guarantees than previously known results. Given frequency predictions, we introduce a meta-algorithm that leverages frequency predictions to match the best-known offline guarantees for a broad class of ''share-based'' fairness notions. Our complementary impossibility results in each setting underscore both the limitations imposed by uncertainty about future goods and the potential of leveraging structured information to achieve fairer outcomes in online fair division.", 'abstract_zh': '在线环境中不可分物品公平分配的问题：未来物品信息获取对公平分配存在性和近似性的影响', 'title_zh': '在线公平分割问题中的额外信息应用'}
{'arxiv_id': 'arXiv:2505.24492', 'title': 'Object Centric Concept Bottlenecks', 'authors': 'David Steinmann, Wolfgang Stammer, Antonia Wüst, Kristian Kersting', 'link': 'https://arxiv.org/abs/2505.24492', 'abstract': 'Developing high-performing, yet interpretable models remains a critical challenge in modern AI. Concept-based models (CBMs) attempt to address this by extracting human-understandable concepts from a global encoding (e.g., image encoding) and then applying a linear classifier on the resulting concept activations, enabling transparent decision-making. However, their reliance on holistic image encodings limits their expressiveness in object-centric real-world settings and thus hinders their ability to solve complex vision tasks beyond single-label classification. To tackle these challenges, we introduce Object-Centric Concept Bottlenecks (OCB), a framework that combines the strengths of CBMs and pre-trained object-centric foundation models, boosting performance and interpretability. We evaluate OCB on complex image datasets and conduct a comprehensive ablation study to analyze key components of the framework, such as strategies for aggregating object-concept encodings. The results show that OCB outperforms traditional CBMs and allows one to make interpretable decisions for complex visual tasks.', 'abstract_zh': '基于对象中心的概念瓶颈以提升性能与可解释性', 'title_zh': '以对象为中心的概念瓶颈'}
{'arxiv_id': 'arXiv:2505.24486', 'title': 'Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection', 'authors': 'Falih Gozi Febrinanto, Kristen Moore, Chandra Thapa, Jiangang Ma, Vidya Saikrishna, Feng Xia', 'link': 'https://arxiv.org/abs/2505.24486', 'abstract': "The performance of existing audio deepfake detection frameworks degrades when confronted with new deepfake attacks. Rehearsal-based continual learning (CL), which updates models using a limited set of old data samples, helps preserve prior knowledge while incorporating new information. However, existing rehearsal techniques don't effectively capture the diversity of audio characteristics, introducing bias and increasing the risk of forgetting. To address this challenge, we propose Rehearsal with Auxiliary-Informed Sampling (RAIS), a rehearsal-based CL approach for audio deepfake detection. RAIS employs a label generation network to produce auxiliary labels, guiding diverse sample selection for the memory buffer. Extensive experiments show RAIS outperforms state-of-the-art methods, achieving an average Equal Error Rate (EER) of 1.953 % across five experiences. The code is available at: this https URL.", 'abstract_zh': '现有的音频深度伪造检测框架在面对新的深度伪造攻击时性能下降。基于回顾的持续学习（CL）通过使用有限的老数据样本更新模型，可以在保留先前知识的同时融入新信息。然而，现有的回顾技术无法有效地捕捉音频特征的多样性，引入了偏差并增加了遗忘的风险。为了解决这一挑战，我们提出了一种基于回顾的音频深度伪造检测持续学习方法——辅助指导采样回顾（RAIS）。RAIS 使用标签生成网络生成辅助标签，指导内存缓冲区中多样样本的选择。广泛实验表明，RAIS 在五个场景中均优于最新方法，平均等错误率（EER）为 1.953%。代码可在以下链接获取：this https URL。', 'title_zh': '基于辅助信息采样的音频深度假声检测复述方法'}
{'arxiv_id': 'arXiv:2505.24480', 'title': 'Towards Effective Code-Integrated Reasoning', 'authors': 'Fei Bai, Yingqian Min, Beichen Zhang, Zhipeng Chen, Wayne Xin Zhao, Lei Fang, Zheng Liu, Zhongyuan Wang, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2505.24480', 'abstract': "In this paper, we investigate code-integrated reasoning, where models generate code when necessary and integrate feedback by executing it through a code interpreter. To acquire this capability, models must learn when and how to use external code tools effectively, which is supported by tool-augmented reinforcement learning (RL) through interactive learning. Despite its benefits, tool-augmented RL can still suffer from potential instability in the learning dynamics. In light of this challenge, we present a systematic approach to improving the training effectiveness and stability of tool-augmented RL for code-integrated reasoning. Specifically, we develop enhanced training strategies that balance exploration and stability, progressively building tool-use capabilities while improving reasoning performance. Through extensive experiments on five mainstream mathematical reasoning benchmarks, our model demonstrates significant performance improvements over multiple competitive baselines. Furthermore, we conduct an in-depth analysis of the mechanism and effect of code-integrated reasoning, revealing several key insights, such as the extension of model's capability boundaries and the simultaneous improvement of reasoning efficiency through code integration. All data and code for reproducing this work are available at: this https URL.", 'abstract_zh': '在本文中，我们研究了代码集成推理，其中模型在必要时生成代码，并通过代码解释器执行代码以整合反馈。为了获得这一能力，模型必须学会何时以及如何有效地使用外部代码工具，这通过交互学习支持基于工具增强的强化学习（RL）。尽管这种方法有许多优势，但工具增强的RL仍然可能在学习动态中遭受潜在的不稳定问题。针对这一挑战，我们提出了一种系统方法，以提高工具增强的RL在代码集成推理中的训练效果和稳定性。具体地，我们开发了平衡探索与稳定性的增强训练策略，在逐步建立工具使用能力的同时提升推理性能。通过在五个主流数学推理基准上的广泛实验，我们的模型在多个竞争性基线上显示出显著的性能提升。此外，我们深入分析了代码集成推理的机制和效果，揭示了几个关键见解，如模型能力边界的扩展以及通过代码集成同时提高推理效率。所有再现本文工作的数据和代码可在此处获得：this https URL。', 'title_zh': '面向有效的代码集成推理'}
{'arxiv_id': 'arXiv:2505.24473', 'title': 'Train One Sparse Autoencoder Across Multiple Sparsity Budgets to Preserve Interpretability and Accuracy', 'authors': 'Nikita Balagansky, Yaroslav Aksenov, Daniil Laptev, Vadim Kurochkin, Gleb Gerasimov, Nikita Koryagin, Daniil Gavrilov', 'link': 'https://arxiv.org/abs/2505.24473', 'abstract': 'Sparse Autoencoders (SAEs) have proven to be powerful tools for interpreting neural networks by decomposing hidden representations into disentangled, interpretable features via sparsity constraints. However, conventional SAEs are constrained by the fixed sparsity level chosen during training; meeting different sparsity requirements therefore demands separate models and increases the computational footprint during both training and evaluation. We introduce a novel training objective, \\emph{HierarchicalTopK}, which trains a single SAE to optimise reconstructions across multiple sparsity levels simultaneously. Experiments with Gemma-2 2B demonstrate that our approach achieves Pareto-optimal trade-offs between sparsity and explained variance, outperforming traditional SAEs trained at individual sparsity levels. Further analysis shows that HierarchicalTopK preserves high interpretability scores even at higher sparsity. The proposed objective thus closes an important gap between flexibility and interpretability in SAE design.', 'abstract_zh': '层次TopK训练目标HierarchicalTopK：实现稀疏自编码器SAE在不同稀疏性水平下的最优 TRADE-OFF', 'title_zh': '在多个稀疏性预算下训练一个稀疏自编码器以保留可解释性和准确性'}
{'arxiv_id': 'arXiv:2505.24472', 'title': 'VietMix: A Naturally Occurring Vietnamese-English Code-Mixed Corpus with Iterative Augmentation for Machine Translation', 'authors': 'Hieu Tran, Phuong-Anh Nguyen-Le, Huy Nghiem, Quang-Nhan Nguyen, Wei Ai, Marine Carpuat', 'link': 'https://arxiv.org/abs/2505.24472', 'abstract': "Machine translation systems fail when processing code-mixed inputs for low-resource languages. We address this challenge by curating VietMix, a parallel corpus of naturally occurring code-mixed Vietnamese text paired with expert English translations. Augmenting this resource, we developed a complementary synthetic data generation pipeline. This pipeline incorporates filtering mechanisms to ensure syntactic plausibility and pragmatic appropriateness in code-mixing patterns. Experimental validation shows our naturalistic and complementary synthetic data boost models' performance, measured by translation quality estimation scores, of up to 71.84 on COMETkiwi and 81.77 on XCOMET. Triangulating positive results with LLM-based assessments, augmented models are favored over seed fine-tuned counterparts in approximately 49% of judgments (54-56% excluding ties). VietMix and our augmentation methodology advance ecological validity in neural MT evaluations and establish a framework for addressing code-mixed translation challenges across other low-resource pairs.", 'abstract_zh': '低资源语言代码混用输入下机器翻译系统的失败：通过构建VietMix平行语料库及其辅助合成数据生成管道予以应对', 'title_zh': 'VietMix：一种迭代扩增的自然产生的越南语-英语代码混用语料库及其在机器翻译中的应用'}
{'arxiv_id': 'arXiv:2505.24429', 'title': 'Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System', 'authors': 'Giovanny C-Londoño, Javier Sánchez, Ángel Rodríguez-Santana', 'link': 'https://arxiv.org/abs/2505.24429', 'abstract': 'Oceanographic forecasting impacts various sectors of society by supporting environmental conservation and economic activities. Based on global circulation models, traditional forecasting methods are computationally expensive and slow, limiting their ability to provide rapid forecasts. Recent advances in deep learning offer faster and more accurate predictions, although these data-driven models are often trained with global data from numerical simulations, which may not reflect reality. The emergence of such models presents great potential for improving ocean prediction at a subregional domain. However, their ability to predict fine-scale ocean processes, like mesoscale structures, remains largely unknown. This work aims to adapt a graph neural network initially developed for global weather forecasting to improve subregional ocean prediction, specifically focusing on the Canary Current upwelling system. The model is trained with satellite data and compared to state-of-the-art physical ocean models to assess its performance in capturing ocean dynamics. Our results show that the deep learning model surpasses traditional methods in precision despite some challenges in upwelling areas. It demonstrated superior performance in reducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis, particularly in regions with complex oceanic dynamics such as Cape Ghir, Cape Bojador, and Cape Blanc. The model achieved improvements of up to 26.5% relative to ConvLSTM and error reductions of up to 76% in 5-day forecasts compared to the GLORYS reanalysis at these critical locations, highlighting its enhanced capability to capture spatial variability and improve predictive accuracy in complex areas. These findings suggest the viability of adapting meteorological data-driven models for improving subregional medium-term ocean forecasting.', 'abstract_zh': '海洋学预报影响社会的各个领域，通过支持环境保护和经济活动。基于全球环流模型的传统预报方法计算成本高且速度慢，限制了其提供快速预报的能力。最近深度学习的发展提供了更快更准确的预测，尽管这些数据驱动的模型通常使用来自数值模拟的全球数据进行训练，这可能无法反映实际情况。这些模型的出现为改善区域海洋预报提供了巨大潜力。然而，它们在预测如中尺度结构等精细海洋过程的能力尚不清楚。本研究旨在将最初用于全球天气预报的图神经网络适应于改善区域海洋预报，特别聚焦于加那利洋流上升流系统。该模型使用卫星数据进行训练，并与最先进的物理海洋模型进行比较，以评估其在捕捉海洋动力学方面的性能。结果显示，深度学习模型在精度方面超过了传统方法，尽管在上升流地区存在一些挑战。它在减少RMSE误差方面优于ConvLSTM和GLORYS再分析，特别是在如盖希尔角、波多贾勒角和白朗角等海洋动力学复杂的区域表现尤为突出。模型在这些关键地点5天预报中的相对改进高达26.5%，GLORYS再分析误差减少了高达76%，表明其在复杂区域捕捉空间变异性和提高预测准确性的增强能力。这些发现表明，气象数据驱动模型的区域中期海洋预报能够实现可行的适应。', 'title_zh': '基于深度学习的区域海洋预报： Canary 流动上升系统案例研究'}
{'arxiv_id': 'arXiv:2505.24415', 'title': 'Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation', 'authors': 'Andreas Spilz, Heiko Oppel, Michael Munz', 'link': 'https://arxiv.org/abs/2505.24415', 'abstract': 'Automated evaluation of movement quality holds significant potential for enhancing physiotherapeutic treatments and sports training by providing objective, real-time feedback. However, the effectiveness of deep learning models in assessing movements captured by inertial measurement units (IMUs) is often hampered by limited data availability, class imbalance, and label ambiguity. In this work, we present a novel data augmentation method that generates realistic IMU data using musculoskeletal simulations integrated with systematic modifications of movement trajectories. Crucially, our approach ensures biomechanical plausibility and allows for automatic, reliable labeling by combining inverse kinematic parameters with a knowledge-based evaluation strategy. Extensive evaluations demonstrate that augmented variants closely resembles real-world data, significantly improving the classification accuracy and generalization capability of neural network models. Additionally, we highlight the benefits of augmented data for patient-specific fine-tuning scenarios, particularly when only limited subject-specific training examples are available. Our findings underline the practicality and efficacy of this augmentation method in overcoming common challenges faced by deep learning applications in physiotherapeutic exercise evaluation.', 'abstract_zh': '自动评估运动质量在增强物理治疗和体育训练方面具有显著潜力，通过提供客观的实时反馈。然而，深度学习模型在评估惯性测量单元（IMU）捕捉的运动时，常常受限于数据不足、类别不平衡和标签模糊。在本工作中，我们提出了一种新颖的数据增强方法，该方法使用结合系统运动轨迹修改的肌肉骨骼模拟生成现实的IMU数据。最关键的是，我们的方法确保了生物力学的合理性，并通过将逆运动学参数与基于知识的评估策略结合，实现了自动可靠的标签生成。广泛的评估表明，增强的数据变体更接近真实世界的数据，显著提高了神经网络模型的分类准确性和泛化能力。此外，我们还强调了增强数据在患者特定微调场景中的优势，特别是在仅具有限的特定患者训练样本时。我们的研究结果强调了该增强方法在克服深度学习在物理治疗运动评估中面临的常见挑战方面的实用性和有效性。', 'title_zh': '基于 musculoskeletal 模拟的 IMU 数据增强以提升自动运动评估'}
{'arxiv_id': 'arXiv:2505.24291', 'title': 'Discl-VC: Disentangled Discrete Tokens and In-Context Learning for Controllable Zero-Shot Voice Conversion', 'authors': 'Kaidi Wang, Wenhao Guan, Ziyue Jiang, Hukai Huang, Peijie Chen, Weijie Wu, Qingyang Hong, Lin Li', 'link': 'https://arxiv.org/abs/2505.24291', 'abstract': "Currently, zero-shot voice conversion systems are capable of synthesizing the voice of unseen speakers. However, most existing approaches struggle to accurately replicate the speaking style of the source speaker or mimic the distinctive speaking style of the target speaker, thereby limiting the controllability of voice conversion. In this work, we propose Discl-VC, a novel voice conversion framework that disentangles content and prosody information from self-supervised speech representations and synthesizes the target speaker's voice through in-context learning with a flow matching transformer. To enable precise control over the prosody of generated speech, we introduce a mask generative transformer that predicts discrete prosody tokens in a non-autoregressive manner based on prompts. Experimental results demonstrate the superior performance of Discl-VC in zero-shot voice conversion and its remarkable accuracy in prosody control for synthesized speech.", 'abstract_zh': '当前，零样本语音转换系统能够合成未见说话人的语音。然而，大多数现有方法在准确复制源说话人的语音风格或模仿目标说话人的独特语音风格方面存在困难，从而限制了语音转换的可控性。在这种情况下，我们提出了一种新颖的语音转换框架Discl-VC，该框架从自监督语音表示中分离出内容和语调信息，并通过上下文学习和流动匹配变换器合成目标说话人的语音。为了实现对生成语音语调的精确控制，我们引入了一种掩码生成变换器，该变换器基于提示以非自回归的方式预测离散的语调标记。实验结果表明，Discl-VC在零样本语音转换中的性能优越，并且在合成语音的语调控制方面具有显著的准确性。', 'title_zh': 'Discl-VC: 解耦离散令牌与上下文学习在可控零样本语音转换中的应用'}
{'arxiv_id': 'arXiv:2505.24269', 'title': 'INSIGHT: A Survey of In-Network Systems for Intelligent, High-Efficiency AI and Topology Optimization', 'authors': 'Aleksandr Algazinov, Joydeep Chandra, Matt Laing', 'link': 'https://arxiv.org/abs/2505.24269', 'abstract': 'In-network computation represents a transformative approach to addressing the escalating demands of Artificial Intelligence (AI) workloads on network infrastructure. By leveraging the processing capabilities of network devices such as switches, routers, and Network Interface Cards (NICs), this paradigm enables AI computations to be performed directly within the network fabric, significantly reducing latency, enhancing throughput, and optimizing resource utilization. This paper provides a comprehensive analysis of optimizing in-network computation for AI, exploring the evolution of programmable network architectures, such as Software-Defined Networking (SDN) and Programmable Data Planes (PDPs), and their convergence with AI. It examines methodologies for mapping AI models onto resource-constrained network devices, addressing challenges like limited memory and computational capabilities through efficient algorithm design and model compression techniques. The paper also highlights advancements in distributed learning, particularly in-network aggregation, and the potential of federated learning to enhance privacy and scalability. Frameworks like Planter and Quark are discussed for simplifying development, alongside key applications such as intelligent network monitoring, intrusion detection, traffic management, and Edge AI. Future research directions, including runtime programmability, standardized benchmarks, and new applications paradigms, are proposed to advance this rapidly evolving field. This survey underscores the potential of in-network AI to create intelligent, efficient, and responsive networks capable of meeting the demands of next-generation AI applications.', 'abstract_zh': '网络内计算代表了一种变革性的方法，用于应对不断增长的AI工作负载对网络基础设施的需求。通过利用交换机、路由器和网络接口卡（NIC）等网络设备的处理能力，这一范式能够在网络 fabric 中直接进行AI计算，显著降低延迟、提升吞吐量并优化资源利用率。本文对优化网络内计算以支持AI进行了全面分析，探索了可编程网络架构（如软件定义网络SDN和可编程数据平面PDP）的发展及其与AI的融合。研究了将AI模型映射到资源受限的网络设备的方法，通过高效算法设计和模型压缩技术解决内存和计算能力有限等挑战。本文还强调了分布式学习的进展，特别是网络内聚合，并探讨了联邦学习在增强隐私性和可扩展性方面的潜力。讨论了简化开发的框架如Planter和Quark，以及智能网络监控、入侵检测、流量管理和边缘AI等关键应用。提出了未来研究方向，包括运行时可编程性、标准化基准测试和新应用范式，以推进这一快速发展的领域。本文综述了网络内AI的潜力，使其能够创建智能、高效和响应迅速的网络，以满足下一代AI应用的需求。', 'title_zh': 'INSIGHT：面向智能高效AI和拓扑优化的网络内系统综述'}
{'arxiv_id': 'arXiv:2505.24231', 'title': 'Dynamic Malware Classification of Windows PE Files using CNNs and Greyscale Images Derived from Runtime API Call Argument Conversion', 'authors': 'Md Shahnawaz, Bishwajit Prasad Gond, Durga Prasad Mohapatra', 'link': 'https://arxiv.org/abs/2505.24231', 'abstract': 'Malware detection and classification remains a topic of concern for cybersecurity, since it is becoming common for attackers to use advanced obfuscation on their malware to stay undetected. Conventional static analysis is not effective against polymorphic and metamorphic malware as these change their appearance without modifying their behavior, thus defying the analysis by code structure alone. This makes it important to use dynamic detection that monitors malware behavior at runtime. In this paper, we present a dynamic malware categorization framework that extracts API argument calls at the runtime execution of Windows Portable Executable (PE) files. Extracting and encoding the dynamic features of API names, argument return values, and other relative features, we convert raw behavioral data to temporal patterns. To enhance feature portrayal, the generated patterns are subsequently converted into grayscale pictures using a magma colormap. These improved photos are used to teach a Convolutional Neural Network (CNN) model discriminative features, which allows for reliable and accurate malware classification. Results from experiments indicate that our method, with an average accuracy of 98.36% is effective in classifying different classes of malware and benign by integrating dynamic analysis and deep learning. It not only achieves high classification accuracy but also demonstrates significant resilience against typical evasion strategies.', 'abstract_zh': '恶意软件检测与分类仍然被认为是网络安全领域的重点问题，因为攻击者常常使用高级混淆技术来使其恶意软件逃避检测。传统的静态分析对变体和变种恶意软件无效，因为这些恶意软件在不改变其行为的情况下改变外观，仅仅依赖代码结构进行分析难以奏效。因此，使用运行时动态检测来监控恶意软件行为变得尤为重要。本文提出了一种动态恶意软件分类框架，在Windows可移植可执行（PE）文件的运行时执行过程中提取API参数调用。通过提取和编码API名称、参数返回值以及其他相关特征，将原始行为数据转换为时间序列模式。为了增强特征表述，生成的模式随后被转换成灰度图片，使用熔岩色图进行表示。这些改进后的图片被用来训练卷积神经网络（CNN）模型，以学习具有区分性的特征，从而使恶意软件分类既可靠又准确。实验结果表明，该方法通过结合动态分析和深度学习，在不同类别恶意软件和良性软件分类中的平均准确率达到98.36%，不仅实现了高分类准确性，还展示了对典型规避策略的强大抗性。', 'title_zh': '基于CNN和运行时API调用参数转换生成的灰度图像的Windows PE文件动态恶意软件分类'}
{'arxiv_id': 'arXiv:2505.24214', 'title': 'Benchmarking Foundation Models for Zero-Shot Biometric Tasks', 'authors': 'Redwan Sony, Parisa Farmanifard, Hamzeh Alzwairy, Nitish Shukla, Arun Ross', 'link': 'https://arxiv.org/abs/2505.24214', 'abstract': 'The advent of foundation models, particularly Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), has redefined the frontiers of artificial intelligence, enabling remarkable generalization across diverse tasks with minimal or no supervision. Yet, their potential in biometric recognition and analysis remains relatively underexplored. In this work, we introduce a comprehensive benchmark that evaluates the zero-shot and few-shot performance of state-of-the-art publicly available VLMs and MLLMs across six biometric tasks spanning the face and iris modalities: face verification, soft biometric attribute prediction (gender and race), iris recognition, presentation attack detection (PAD), and face manipulation detection (morphs and deepfakes). A total of 41 VLMs were used in this evaluation. Experiments show that embeddings from these foundation models can be used for diverse biometric tasks with varying degrees of success. For example, in the case of face verification, a True Match Rate (TMR) of 96.77 percent was obtained at a False Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW) dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1 percent FMR on the IITD-R-Full dataset was 97.55 percent without any fine-tuning. Further, we show that applying a simple classifier head to these embeddings can help perform DeepFake detection for faces, Presentation Attack Detection (PAD) for irides, and extract soft biometric attributes like gender and ethnicity from faces with reasonably high accuracy. This work reiterates the potential of pretrained models in achieving the long-term vision of Artificial General Intelligence.', 'abstract_zh': '基础模型的兴起，特别是视觉-语言模型（VLMs）和多模态大型语言模型（MLLMs），已重新定义了人工智能的边界，使其在最少或无需监督的情况下能够实现跨多种任务的显著泛化。然而，它们在生物特征识别与分析领域的潜力仍相对未被充分探索。在本文中，我们介绍了一个全面基准，评估了六种生物特征任务（涵盖面部和虹膜模态）上最先进的公开可用VLMs和MLLMs的零-shot和少-shot性能：面部验证、软生物特征属性预测（性别和种族）、虹膜识别、欺骗性攻击检测（PAD）和面部操控检测（变形和深度假 face）。共使用了41种VLMs进行评估。实验结果显示，这些基础模型的嵌入可以在不同程度上用于多样的生物特征任务。例如，在面部验证任务中，通过在Labeled Face in the Wild（LFW）数据集上进行96.77%的正确匹配率（TMR）而同时保持1%的错误匹配率（FMR）时，无需微调即达到了这一结果。在虹膜识别任务中，通过在IITD-R-Full数据集上进行97.55%的正确匹配率（TMR）而同时保持1%的错误匹配率（FMR）时，同样无需微调。此外，我们展示，通过对这些嵌入施加一个简单的分类器头部，可以用于检测面部的深度假 face、虹膜的欺骗性攻击检测（PAD）以及从面部中提取性别和种族等软生物特征属性，其准确率相对较高。本文重申了预训练模型实现长期愿景——通用人工智能的潜力。', 'title_zh': '零样本生物特征任务的基础模型基准研究'}
{'arxiv_id': 'arXiv:2505.24185', 'title': 'Towards Unified Modeling in Federated Multi-Task Learning via Subspace Decoupling', 'authors': 'Yipan Wei, Yuchen Zou, Yapeng Li, Bo Du', 'link': 'https://arxiv.org/abs/2505.24185', 'abstract': 'Federated Multi-Task Learning (FMTL) enables multiple clients performing heterogeneous tasks without exchanging their local data, offering broad potential for privacy preserving multi-task collaboration. However, most existing methods focus on building personalized models for each client and unable to support the aggregation of multiple heterogeneous tasks into a unified model. As a result, in real-world scenarios where task objectives, label spaces, and optimization paths vary significantly, conventional FMTL methods struggle to achieve effective joint training. To address this challenge, we propose FedDEA (Federated Decoupled Aggregation), an update-structure-aware aggregation method specifically designed for multi-task model integration. Our method dynamically identifies task-relevant dimensions based on the response strength of local updates and enhances their optimization effectiveness through rescaling. This mechanism effectively suppresses cross-task interference and enables task-level decoupled aggregation within a unified global model. FedDEA does not rely on task labels or architectural modifications, making it broadly applicable and deployment-friendly. Experimental results demonstrate that it can be easily integrated into various mainstream federated optimization algorithms and consistently delivers significant overall performance improvements on widely used NYUD-V2 and PASCAL-Context. These results validate the robustness and generalization capabilities of FedDEA under highly heterogeneous task settings.', 'abstract_zh': '联邦多任务学习（Federated Multi-Task Learning, FMTL）使得多个执行异构任务的客户端无需交换本地数据即可进行协作，提供了广泛的数据隐私保护多任务学习潜力。然而，现有大部分方法集中在为每个客户端构建个性化模型，无法支持将多个异构任务统合成一个统一模型。因此，在任务目标、标签空间和优化路径差异显著的现实场景中，传统FMTL方法难以实现有效联合训练。为解决这一挑战，我们提出了一种更新结构感知聚合方法FedDEA（Federated Decoupled Aggregation），专门设计用于多任务模型集成。该方法基于局部更新的响应强度动态识别任务相关维度，并通过重缩放增强其优化效果，有效抑制跨任务干扰，在统一全局模型中实现任务级解耦聚合。FedDEA 不依赖于任务标签或模型结构修改，使其具有广泛应用性和易于部署的特点。实验结果表明，它可轻松集成到各种主流联邦优化算法中，并在广泛使用的NYUD-V2和PASCAL-Context数据集上实现显著的整体性能提升。这些结果验证了FedDEA在高度异构任务设置下的稳健性和泛化能力。', 'title_zh': '统一建模在子空间解耦的联邦多任务学习中探讨'}
{'arxiv_id': 'arXiv:2505.24182', 'title': 'Seeing is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT', 'authors': 'Zhuobai Dong, Junchao Yi, Ziyuan Zheng, Haochen Han, Xiangxi Zheng, Alex Jinpeng Wang, Fangming Liu, Linjie Li', 'link': 'https://arxiv.org/abs/2505.24182', 'abstract': 'Understanding the physical world - governed by laws of motion, spatial relations, and causality - poses a fundamental challenge for multimodal large language models (MLLMs). While recent advances such as OpenAI o3 and GPT-4o demonstrate impressive perceptual and reasoning capabilities, our investigation reveals these models struggle profoundly with visual physical reasoning, failing to grasp basic physical laws, spatial interactions, and causal effects in complex scenes. More importantly, they often fail to follow coherent reasoning chains grounded in visual evidence, especially when multiple steps are needed to arrive at the correct answer. To rigorously evaluate this capability, we introduce MVPBench, a curated benchmark designed to rigorously evaluate visual physical reasoning through the lens of visual chain-of-thought (CoT). Each example features interleaved multi-image inputs and demands not only the correct final answer but also a coherent, step-by-step reasoning path grounded in evolving visual cues. This setup mirrors how humans reason through real-world physical processes over time. To ensure fine-grained evaluation, we introduce a graph-based CoT consistency metric that verifies whether the reasoning path of model adheres to valid physical logic. Additionally, we minimize shortcut exploitation from text priors, encouraging models to rely on visual understanding. Experimental results reveal a concerning trend: even cutting-edge MLLMs exhibit poor visual reasoning accuracy and weak image-text alignment in physical domains. Surprisingly, RL-based post-training alignment - commonly believed to improve visual reasoning performance - often harms spatial reasoning, suggesting a need to rethink current fine-tuning practices.', 'abstract_zh': '理解由运动定律、空间关系和因果关系支配的物理世界，对多模态大型语言模型（MLLMs）构成了根本性挑战。尽管诸如OpenAI o3和GPT-4o等最近的进步展示了令人印象深刻的感知和推理能力，我们的研究发现，这些模型在视觉物理推理方面表现差强人意，难以掌握基本的物理定律、空间交互和因果效应，尤其是在复杂场景中。更重要的是，它们常常无法遵循基于视觉证据的连贯推理链，特别是在需要多步推理才能得出正确答案的情况下。为了严格评估这种能力，我们提出了MVPBench，这是一个精心设计的基准测试，通过视觉链式推理（CoT）的视角严格评估视觉物理推理。每个示例都包含交错的多幅图像输入，并不仅要求正确的最终答案，还要求连贯的、基于不断变化的视觉线索的逐步推理路径。这种设置类似于人类如何随着时间推移推理现实世界的物理过程。为了确保精细评估，我们引入了一种基于图的CoT一致性度量，验证模型的推理路径是否遵循有效的物理逻辑。此外，我们还减少了对文本先验的捷径利用，促使模型依赖于视觉理解。实验结果显示了一个令人担忧的趋势：即使是最先进的MLLMs在物理领域的视觉推理准确性和图像-文本对齐方面表现欠佳。令人惊讶的是，通常被认为能够提高视觉推理性能的基于RL的后训练对齐往往损害了空间推理，这表明需要重新审视当前的微调实践。', 'title_zh': '看见并不等同于推理：基于图的多路径视觉物理共情推理评估基准MVPBench'}
{'arxiv_id': 'arXiv:2505.24178', 'title': 'Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem', 'authors': 'Katherine Tieu, Dongqi Fu, Jun Wu, Jingrui He', 'link': 'https://arxiv.org/abs/2505.24178', 'abstract': 'In the era of foundation models, Out-of- Distribution (OOD) problems, i.e., the data discrepancy between the training environments and testing environments, hinder AI generalization. Further, relational data like graphs disobeying the Independent and Identically Distributed (IID) condition makes the problem more challenging, especially much harder when it is associated with time. Motivated by this, to realize the robust invariant learning over temporal graphs, we want to investigate what components in temporal graphs are most invariant and representative with respect to labels. With the Information Bottleneck (IB) method, we propose an error-bounded Invariant Link Selector that can distinguish invariant components and variant components during the training process to make the deep learning model generalizable for different testing scenarios. Besides deriving a series of rigorous generalizable optimization functions, we also equip the training with task-specific loss functions, e.g., temporal link prediction, to make pretrained models solve real-world application tasks like citation recommendation and merchandise recommendation, as demonstrated in our experiments with state-of-the-art (SOTA) methods. Our code is available at this https URL.', 'abstract_zh': '在基础模型时代，离分布(OOD)问题，即训练环境与测试环境之间的数据差异，阻碍了AI的一般化。进一步地，不符合独立同分布(IID)条件的图数据关系使得问题更加棘手，尤其是在与时间相关的情况下更为困难。鉴于此，为了在时序图上实现鲁棒不变学习，我们旨在探究时序图中最不变且最具代表性的部分与标签之间的关系。借助信息瓶颈(IB)方法，我们提出了一种误差界不变链接选择器，该选择器在训练过程中能够区分不变部分和变化部分，从而使深度学习模型在不同测试场景下具有泛化能力。除了推导一系列严格的泛化优化函数之外，我们还为特定任务配备了损失函数，例如时序链接预测，以使预训练模型解决实际应用任务，如引用推荐和商品推荐，这已在实验中通过对比尖端方法得到证实。我们的代码可在以下链接获取：this https URL。', 'title_zh': '空间-时间域外问题的不变连接选择器'}
{'arxiv_id': 'arXiv:2505.24149', 'title': 'RCCDA: Adaptive Model Updates in the Presence of Concept Drift under a Constrained Resource Budget', 'authors': 'Adam Piaseczny, Md Kamran Chowdhury Shisher, Shiqiang Wang, Christopher G. Brinton', 'link': 'https://arxiv.org/abs/2505.24149', 'abstract': 'Machine learning (ML) algorithms deployed in real-world environments are often faced with the challenge of adapting models to concept drift, where the task data distributions are shifting over time. The problem becomes even more difficult when model performance must be maintained under adherence to strict resource constraints. Existing solutions often depend on drift-detection methods that produce high computational overhead for resource-constrained environments, and fail to provide strict guarantees on resource usage or theoretical performance assurances. To address these shortcomings, we propose RCCDA: a dynamic model update policy that optimizes ML training dynamics while ensuring strict compliance to predefined resource constraints, utilizing only past loss information and a tunable drift threshold. In developing our policy, we analytically characterize the evolution of model loss under concept drift with arbitrary training update decisions. Integrating these results into a Lyapunov drift-plus-penalty framework produces a lightweight policy based on a measurable accumulated loss threshold that provably limits update frequency and cost. Experimental results on three domain generalization datasets demonstrate that our policy outperforms baseline methods in inference accuracy while adhering to strict resource constraints under several schedules of concept drift, making our solution uniquely suited for real-time ML deployments.', 'abstract_zh': '基于概念漂移的严格资源约束下动态模型更新策略：RCCDA', 'title_zh': 'RCCDA：在受限资源预算下概念漂移时的自适应模型更新'}
{'arxiv_id': 'arXiv:2505.24141', 'title': 'The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models', 'authors': 'Jiashuai Liu, Yingjia Shang, Yingkang Zhan, Di Zhang, Yi Niu, Dong Wei, Xian Wu, Zeyu Gao, Chen Li, Yefeng Zheng', 'link': 'https://arxiv.org/abs/2505.24141', 'abstract': 'With the widespread adoption of pathology foundation models in both research and clinical decision support systems, exploring their security has become a critical concern. However, despite their growing impact, the vulnerability of these models to adversarial attacks remains largely unexplored. In this work, we present the first systematic investigation into the security of pathology foundation models for whole slide image~(WSI) analysis against adversarial attacks. Specifically, we introduce the principle of \\textit{local perturbation with global impact} and propose a label-free attack framework that operates without requiring access to downstream task labels. Under this attack framework, we revise four classical white-box attack methods and redefine the perturbation budget based on the characteristics of WSI. We conduct comprehensive experiments on three representative pathology foundation models across five datasets and six downstream tasks. Despite modifying only 0.1\\% of patches per slide with imperceptible noise, our attack leads to downstream accuracy degradation that can reach up to 20\\% in the worst cases. Furthermore, we analyze key factors that influence attack success, explore the relationship between patch-level vulnerability and semantic content, and conduct a preliminary investigation into potential defence strategies. These findings lay the groundwork for future research on the adversarial robustness and reliable deployment of pathology foundation models. Our code is publicly available at: this https URL.', 'abstract_zh': '病理基础模型在全视野图像分析中对抗攻击的安全性系统研究', 'title_zh': '病理学中的蝴蝶效应：探究病理基础模型的安全性'}
{'arxiv_id': 'arXiv:2505.24136', 'title': 'Sparsity-Driven Parallel Imaging Consistency for Improved Self-Supervised MRI Reconstruction', 'authors': 'Yaşar Utku Alçalar, Mehmet Akçakaya', 'link': 'https://arxiv.org/abs/2505.24136', 'abstract': "Physics-driven deep learning (PD-DL) models have proven to be a powerful approach for improved reconstruction of rapid MRI scans. In order to train these models in scenarios where fully-sampled reference data is unavailable, self-supervised learning has gained prominence. However, its application at high acceleration rates frequently introduces artifacts, compromising image fidelity. To mitigate this shortcoming, we propose a novel way to train PD-DL networks via carefully-designed perturbations. In particular, we enhance the k-space masking idea of conventional self-supervised learning with a novel consistency term that assesses the model's ability to accurately predict the added perturbations in a sparse domain, leading to more reliable and artifact-free reconstructions. The results obtained from the fastMRI knee and brain datasets show that the proposed training strategy effectively reduces aliasing artifacts and mitigates noise amplification at high acceleration rates, outperforming state-of-the-art self-supervised methods both visually and quantitatively.", 'abstract_zh': '基于物理驱动的深度学习模型的自监督训练新方法：克服高加速率下的伪影和噪声放大问题', 'title_zh': '驱动稀疏性并行成像一致性以改善自监督MRI重建'}
{'arxiv_id': 'arXiv:2505.24133', 'title': 'R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration', 'authors': 'Zefan Cai, Wen Xiao, Hanshi Sun, Cheng Luo, Yikai Zhang, Ke Wan, Yucheng Li, Yeyang Zhou, Li-Wen Chang, Jiuxiang Gu, Zhen Dong, Anima Anandkumar, Abedelkadir Asi, Junjie Hu', 'link': 'https://arxiv.org/abs/2505.24133', 'abstract': 'Reasoning models have demonstrated impressive performance in self-reflection and chain-of-thought reasoning. However, they often produce excessively long outputs, leading to prohibitively large key-value (KV) caches during inference. While chain-of-thought inference significantly improves performance on complex reasoning tasks, it can also lead to reasoning failures when deployed with existing KV cache compression approaches. To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models. Our method preserves nearly 100% of the full KV cache performance using only 10% of the KV cache, substantially outperforming existing KV cache baselines, which reach only 60% of the performance. Remarkably, R-KV even achieves 105% of full KV cache performance with 16% of the KV cache. This KV-cache reduction also leads to a 90% memory saving and a 6.6X throughput over standard chain-of-thought reasoning inference. Experimental results show that R-KV consistently outperforms existing KV cache compression baselines across two mathematical reasoning datasets.', 'abstract_zh': '冗余感知推理模型的KV缓存压缩方法（R-KV）', 'title_zh': 'R-KV: 训练无关的键值缓存压缩方法以加速推理模型，考虑冗余性'}
{'arxiv_id': 'arXiv:2505.24120', 'title': 'CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs', 'authors': 'Ai Jian, Weijie Qiu, Xiaokun Wang, Peiyu Wang, Yunzhuo Hao, Jiangbo Pei, Yichen Wei, Yi Peng, Xuchen Song', 'link': 'https://arxiv.org/abs/2505.24120', 'abstract': 'Vision-Language Models (VLMs) have demonstrated remarkable progress in multimodal understanding, yet their capabilities for scientific reasoning remains inadequately assessed. Current multimodal benchmarks predominantly evaluate generic image comprehension or text-driven reasoning, lacking authentic scientific contexts that require domain-specific knowledge integration with visual evidence analysis. To fill this gap, we present CSVQA, a diagnostic multimodal benchmark specifically designed for evaluating scientific reasoning through domain-grounded visual question this http URL benchmark features 1,378 carefully constructed question-answer pairs spanning diverse STEM disciplines, each demanding domain knowledge, integration of visual evidence, and higher-order reasoning. Compared to prior multimodal benchmarks, CSVQA places greater emphasis on real-world scientific content and complex this http URL additionally propose a rigorous evaluation protocol to systematically assess whether model predictions are substantiated by valid intermediate reasoning steps based on curated explanations. Our comprehensive evaluation of 15 VLMs on this benchmark reveals notable performance disparities, as even the top-ranked proprietary model attains only 49.6\\% this http URL empirical evidence underscores the pressing need for advancing scientific reasoning capabilities in VLMs. Our CSVQA is released at this https URL.', 'abstract_zh': 'Vision-Language模型（VLMs）在多模态理解方面取得了显著进展，但在科学推理能力方面仍缺乏充分评估。当前的多模态基准主要评估通用图像理解或基于文本的推理，缺乏需要特定领域知识与视觉证据分析相结合的真实科学情境。为填补这一空白，我们提出了CSVQA这一专门用于评估基于领域知识的科学推理的诊断性多模态基准，网址为this http URL基准包含了1,378个精挑细选的问题-答案对，覆盖多个STEM学科，每个问题都要求应用领域知识、整合视觉证据并进行高层次推理。与以往的多模态基准相比，CSVQA更侧重于真实世界的科学内容和复杂推理过程。我们还提出了一套严格的评估协议，系统地评估模型预测是否基于经过筛选的中间推理步骤。对15种VLMs在该基准上的全面评估显示了显著的性能差异，即使排名第一的专有模型也只能达到49.6%的准确率。我们的实证研究强调了提升VLMs科学推理能力的重要需求。CSVQA基准已发布在this https URL。', 'title_zh': 'CSVQA: 一种评估VLMs在STEM推理能力上的中文多模态基准'}
{'arxiv_id': 'arXiv:2505.24099', 'title': 'Attractor learning for spatiotemporally chaotic dynamical systems using echo state networks with transfer learning', 'authors': 'Mohammad Shah Alam, William Ott, Ilya Timofeyev', 'link': 'https://arxiv.org/abs/2505.24099', 'abstract': 'In this paper, we explore the predictive capabilities of echo state networks (ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal nonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel methodology that integrates ESNs with transfer learning, aiming to enhance predictive performance across various parameter regimes of the gKS model. Our research focuses on predicting changes in long-term statistical patterns of the gKS model that result from varying the dispersion relation or the length of the spatial domain. We use transfer learning to adapt ESNs to different parameter settings and successfully capture changes in the underlying chaotic attractor.', 'abstract_zh': '本文探讨了回声状态网络(ESNs)对广义库朗托-西瓦辛斯基(gKS)方程的预测能力，该方程是一种典型的具有时空混沌特性的非线性偏微分方程。我们提出了一种新颖的方法，将ESNs与迁移学习相结合，旨在提高在gKS模型不同参数区域的预测性能。我们的研究重点是预测由改变dispersion关系或空间域长度引起的gKS模型长期内统计模式的变化。通过迁移学习，我们成功地使ESNs适应不同的参数设置，并捕获了潜在的混沌吸引子的变化。', 'title_zh': '基于回声状态网络和迁移学习的时空混沌动力系统吸引子学习'}
{'arxiv_id': 'arXiv:2505.24090', 'title': 'Searching Clinical Data Using Generative AI', 'authors': 'Karan Hanswadkar, Anika Kanchi, Shivani Tripathi, Shi Qiao, Rony Chatterjee, Alekh Jindal', 'link': 'https://arxiv.org/abs/2505.24090', 'abstract': 'Artificial Intelligence (AI) is making a major impact on healthcare, particularly through its application in natural language processing (NLP) and predictive analytics. The healthcare sector has increasingly adopted AI for tasks such as clinical data analysis and medical code assignment. However, searching for clinical information in large and often unorganized datasets remains a manual and error-prone process. Assisting this process with automations can help physicians improve their operational productivity significantly.\nIn this paper, we present a generative AI approach, coined SearchAI, to enhance the accuracy and efficiency of searching clinical data. Unlike traditional code assignment, which is a one-to-one problem, clinical data search is a one-to-many problem, i.e., a given search query can map to a family of codes. Healthcare professionals typically search for groups of related diseases, drugs, or conditions that map to many codes, and therefore, they need search tools that can handle keyword synonyms, semantic variants, and broad open-ended queries. SearchAI employs a hierarchical model that respects the coding hierarchy and improves the traversal of relationships from parent to child nodes. SearchAI navigates these hierarchies predictively and ensures that all paths are reachable without losing any relevant nodes.\nTo evaluate the effectiveness of SearchAI, we conducted a series of experiments using both public and production datasets. Our results show that SearchAI outperforms default hierarchical traversals across several metrics, including accuracy, robustness, performance, and scalability. SearchAI can help make clinical data more accessible, leading to streamlined workflows, reduced administrative burden, and enhanced coding and diagnostic accuracy.', 'abstract_zh': '人工智能（AI）在医疗领域产生了重大影响，特别是在自然语言处理（NLP）和预测分析方面的应用。医疗行业越来越多地采用AI进行临床数据分析和医疗编码。然而，在大型且往往无序的数据集中搜索临床信息仍是一个手动且容易出错的过程。通过自动化辅助这一过程，可以显著提高医生的操作生产力。\n\n在本文中，我们提出了一种生成式AI方法，名为SearchAI，以提高临床数据搜索的准确性和效率。与传统的编码分配问题是一对一的问题不同，临床数据搜索是多对一的问题，即给定的搜索查询可以映射到一组代码。医疗专业人员通常搜索一组相关疾病、药物或条件，这些组对应于众多代码，因此他们需要能够处理关键词同义词、语义变体和宽泛开放查询的搜索工具。SearchAI采用分层模型，尊重编码层次结构，并改进了从父节点到子节点的关系遍历。SearchAI预测性地导航这些层次结构，确保所有路径都是可达的，且不会丢失任何相关节点。\n\n为了评估SearchAI的有效性，我们使用公开和生产数据集进行了系列实验。结果显示，SearchAI在准确性、鲁棒性、性能和可扩展性等多方面指标上均优于默认的层级遍历方法。SearchAI有助于使临床数据更加易于访问，从而简化工作流程，减少行政负担，并提高编码和诊断准确性。', 'title_zh': '使用生成式AI搜索临床数据'}
{'arxiv_id': 'arXiv:2505.24055', 'title': 'Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs', 'authors': 'Yilong Wang, Tianxiang Zhao, Zongyu Wu, Suhang Wang', 'link': 'https://arxiv.org/abs/2505.24055', 'abstract': "Graph neural networks (GNNs) have shown great ability for node classification on graphs. However, the success of GNNs relies on abundant labeled data, while obtaining high-quality labels is costly and challenging, especially for newly emerging domains. Hence, unsupervised domain adaptation (UDA), which trains a classifier on the labeled source graph and adapts it to the unlabeled target graph, is attracting increasing attention. Various approaches have been proposed to alleviate the distribution shift between the source and target graphs to facilitate the classifier adaptation. However, most of them simply adopt existing UDA techniques developed for independent and identically distributed data to gain domain-invariant node embeddings for graphs, which do not fully consider the graph structure and message-passing mechanism of GNNs during the adaptation and will fail when label distribution shift exists among domains. In this paper, we proposed a novel framework that adopts link prediction to connect nodes between source and target graphs, which can facilitate message-passing between the source and target graphs and augment the target nodes to have ``in-distribution'' neighborhoods with the source domain. This strategy modified the target graph on the input level to reduce its deviation from the source domain in the embedding space and is insensitive to disproportional label distributions across domains. To prevent the loss of discriminative information in the target graph, we further design a novel identity-preserving learning objective, which guides the learning of the edge insertion module together with reconstruction and adaptation losses. Experimental results on real-world datasets demonstrate the effectiveness of our framework.", 'abstract_zh': '基于链接预测的图神经网络无监督域适应框架', 'title_zh': '通过链接预测桥梁源领域和目标领域以实现图上的无监督领域适应'}
{'arxiv_id': 'arXiv:2505.24030', 'title': 'From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?', 'authors': 'Ziming Zhao, ChengAo Shen, Hanghang Tong, Dongjin Song, Zhigang Deng, Qingsong Wen, Jingchao Ni', 'link': 'https://arxiv.org/abs/2505.24030', 'abstract': 'Transformer-based models have gained increasing attention in time series research, driving interest in Large Language Models (LLMs) and foundation models for time series analysis. As the field moves toward multi-modality, Large Vision Models (LVMs) are emerging as a promising direction. In the past, the effectiveness of Transformer and LLMs in time series has been debated. When it comes to LVMs, a similar question arises: are LVMs truely useful for time series analysis? To address it, we design and conduct the first principled study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks, with extensive ablation analysis. Our findings indicate LVMs are indeed useful for time series classification but face challenges in forecasting. Although effective, the contemporary best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows. We hope our findings could serve as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks.', 'abstract_zh': '基于Transformer的模型在时间序列研究中获得了越来越多的关注，推动了大型语言模型（LLMs）和基础模型在时间序列分析中的应用。随着领域向多模态发展，大型视觉模型（LVMs）正 emerge as a promising direction. In the past,有关Transformer和LLMs在时间序列中的有效性存在争议。至于LVMs，类似的问题出现了：LVMs真对时间序列分析有用吗？为了解答这一问题，我们设计并开展了一项第一性的原则研究，涉及4种LVMs、8种成像方法、18个数据集和26种基线，涵盖了高层（分类）和低层（预测）任务，并进行了广泛的消融分析。研究发现，LVMs确实适用于时间序列分类但在预测方面面临挑战。尽管有效，当前最佳的LVM预测器仅限于特定类型的LVMs和成像方法，偏向于预测时期，并且难以利用长回溯窗口。希望我们的发现能够为未来基于LVM和多模态的方法在不同类型时间序列任务中的研究奠定基石。', 'title_zh': '从图像到信号：大规模视觉模型对时间序列分析有用吗？'}
{'arxiv_id': 'arXiv:2505.24023', 'title': 'Multi-Group Proportional Representation for Text-to-Image Models', 'authors': 'Sangwon Jung, Alex Oesterling, Claudio Mayrink Verdun, Sajani Vithana, Taesup Moon, Flavio P. Calmon', 'link': 'https://arxiv.org/abs/2505.24023', 'abstract': 'Text-to-image (T2I) generative models can create vivid, realistic images from textual descriptions. As these models proliferate, they expose new concerns about their ability to represent diverse demographic groups, propagate stereotypes, and efface minority populations. Despite growing attention to the "safe" and "responsible" design of artificial intelligence (AI), there is no established methodology to systematically measure and control representational harms in image generation. This paper introduces a novel framework to measure the representation of intersectional groups in images generated by T2I models by applying the Multi-Group Proportional Representation (MPR) metric. MPR evaluates the worst-case deviation of representation statistics across given population groups in images produced by a generative model, allowing for flexible and context-specific measurements based on user requirements. We also develop an algorithm to optimize T2I models for this metric. Through experiments, we demonstrate that MPR can effectively measure representation statistics across multiple intersectional groups and, when used as a training objective, can guide models toward a more balanced generation across demographic groups while maintaining generation quality.', 'abstract_zh': '基于文本到图像生成模型的交叉群体表征测量框架', 'title_zh': '多组比例代表制文本到图像模型'}
{'arxiv_id': 'arXiv:2505.24001', 'title': 'Multi-output Classification using a Cross-talk Architecture for Compound Fault Diagnosis of Motors in Partially Labeled Condition', 'authors': 'Wonjun Yi, Wonho Jung, Kangmin Jang, Yong-Hwa Park', 'link': 'https://arxiv.org/abs/2505.24001', 'abstract': "The increasing complexity of rotating machinery and the diversity of operating conditions, such as rotating speed and varying torques, have amplified the challenges in fault diagnosis in scenarios requiring domain adaptation, particularly involving compound faults. This study addresses these challenges by introducing a novel multi-output classification (MOC) framework tailored for domain adaptation in partially labeled (PL) target datasets. Unlike conventional multi-class classification (MCC) approaches, the proposed MOC framework classifies the severity levels of compound faults simultaneously. Furthermore, we explore various single-task and multi-task architectures applicable to the MOC formulation-including shared trunk and cross-talk-based designs-for compound fault diagnosis under PL conditions. Based on this investigation, we propose a novel cross-talk layer structure that enables selective information sharing across diagnostic tasks, effectively enhancing classification performance in compound fault scenarios. In addition, frequency-layer normalization was incorporated to improve domain adaptation performance on motor vibration data. Compound fault conditions were implemented using a motor-based test setup, and the proposed model was evaluated across six domain adaptation scenarios. The experimental results demonstrate its superior macro F1 performance compared to baseline models. We further showed that the proposed mode's structural advantage is more pronounced in compound fault settings through a single-fault comparison. We also found that frequency-layer normalization fits the fault diagnosis task better than conventional methods. Lastly, we discuss that this improvement primarily stems from the model's structural ability to leverage inter-fault classification task interactions, rather than from a simple increase in model parameters.", 'abstract_zh': '旋转机械日益增加的复杂性和多变的运行条件，如旋转速度和变化的扭矩，加剧了在涉及领域适应的故障诊断中的挑战，尤其是涉及复合故障的情况。本研究通过引入一种针对部分标注目标数据集（PL）领域适应的新颖多输出分类（MOC）框架来应对这些挑战。与传统的多类分类（MCC）方法不同，所提出的工作框架同时对复合故障的严重程度进行分类。此外，我们探讨了适用于MOC表示的各种单任务和多任务架构，包括共享主干和基于互扰的设计，并在部分标注条件下对复合故障进行诊断。基于这项研究，我们提出了一种新颖的互扰层结构，能够选择性地在诊断任务之间共享信息，从而有效提高在复合故障场景中的分类性能。此外，我们引入了频率层归一化，以提高对电机振动数据的领域适应性能。使用基于电机的测试装置实现复合故障条件，并在六个领域适应场景中评估所提出的模型。实验结果表明，与基线模型相比，其宏观F1性能更优。进一步研究表明，在复合故障设置中，所提模型的结构优势尤为明显。我们还发现，频率层归一化比传统方法更适合故障诊断任务。最后，我们讨论了这种改进主要来自于模型结构利用跨故障分类任务交互的能力，而不仅仅是模型参数的简单增加。', 'title_zh': '在部分标注条件下使用交叉对话架构进行电机复合故障诊断的多输出分类'}
{'arxiv_id': 'arXiv:2505.23977', 'title': 'VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL', 'authors': 'Yichen Feng, Zhangchen Xu, Fengqing Jiang, Yuetai Li, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Radha Poovendran', 'link': 'https://arxiv.org/abs/2505.23977', 'abstract': 'Vision language models (VLMs) are expected to perform effective multimodal reasoning and make logically coherent decisions, which is critical to tasks such as diagram understanding and spatial problem solving. However, current VLM reasoning lacks large-scale and well-structured training datasets. To bridge this gap, we propose VisualSphinx, a first-of-its-kind large-scale synthetic visual logical reasoning training data. To tackle the challenge of image synthesis with grounding answers, we propose a rule-to-image synthesis pipeline, which extracts and expands puzzle rules from seed questions and generates the code of grounding synthesis image synthesis for puzzle sample assembly. Experiments demonstrate that VLM trained using GRPO on VisualSphinx benefit from logical coherence and readability of our dataset and exhibit improved performance on logical reasoning tasks. The enhanced reasoning capabilities developed from VisualSphinx also benefit other reasoning tasks such as algebraic reasoning, arithmetic reasoning and geometry reasoning.', 'abstract_zh': '视觉语言模型（VLMs）被预期能够实现有效的多模态推理并做出逻辑连贯的决策，这对于图示理解与空间问题求解等任务至关重要。然而，当前的VLM推理缺乏大规模且结构良好的训练数据集。为解决这一问题，我们提出VisualSphinx，这是一个首创的大规模合成视觉逻辑推理训练数据集。为应对基于答案的图像合成挑战，我们提出了一种规则到图像合成管道，该管道从种子问题中提取并扩展谜题规则，并生成用于谜题样本组装的接地合成图像生成代码。实验表明，使用VisualSphinx上的GRPO训练的VLM可以从我们数据集的逻辑连贯性和可读性中受益，并在逻辑推理任务中表现出改进的性能。从VisualSphinx中获得的增强推理能力也惠及其他推理任务，如代数推理、算术推理和几何推理。', 'title_zh': 'VisualSphinx: 大规模合成视觉逻辑谜题用于RL'}
{'arxiv_id': 'arXiv:2505.23960', 'title': 'Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation', 'authors': 'Henry Conklin', 'link': 'https://arxiv.org/abs/2505.23960', 'abstract': 'Despite the remarkable success of large large-scale neural networks, we still lack unified notation for thinking about and describing their representational spaces. We lack methods to reliably describe how their representations are structured, how that structure emerges over training, and what kinds of structures are desirable. This thesis introduces quantitative methods for identifying systematic structure in a mapping between spaces, and leverages them to understand how deep-learning models learn to represent information, what representational structures drive generalisation, and how design decisions condition the structures that emerge. To do this I identify structural primitives present in a mapping, along with information theoretic quantifications of each. These allow us to analyse learning, structure, and generalisation across multi-agent reinforcement learning models, sequence-to-sequence models trained on a single task, and Large Language Models. I also introduce a novel, performant, approach to estimating the entropy of vector space, that allows this analysis to be applied to models ranging in size from 1 million to 12 billion parameters.\nThe experiments here work to shed light on how large-scale distributed models of cognition learn, while allowing us to draw parallels between those systems and their human analogs. They show how the structures of language and the constraints that give rise to them in many ways parallel the kinds of structures that drive performance of contemporary neural networks.', 'abstract_zh': '尽管大规模神经网络取得了显著的成功，但我们仍然缺乏统一的表示空间思考和描述的符号体系。我们缺乏可靠的方法来描述其表示的结构，这些结构如何在训练中涌现，以及哪些结构是可取的。本论文引入了量化方法来识别映射空间之间系统结构，并利用这些方法来理解深度学习模型如何学习表示信息，哪些表示结构驱动泛化，以及设计决策如何影响涌现的结构。通过识别映射中存在的结构性质及其信息论量化的每个性质，我们能够分析多智能体强化学习模型、单任务训练的序列到序列模型以及大型语言模型中的学习、结构和泛化。我还提出了一个新的高效方法来估计向量空间的熵，从而使这一分析能够应用于从100万到120亿参数的模型。实验旨在揭示大规模分布式认知模型的学习机制，并将这些系统与其类比的人类系统进行比较。它们展示了语言结构及其在许多方面类似当代神经网络性能驱动结构的约束。', 'title_zh': '映射中的信息结构：一种学习、表示和泛化的Approach'}
{'arxiv_id': 'arXiv:2505.23949', 'title': 'TSENOR: Highly-Efficient Algorithm for Finding Transposable N:M Sparse Masks', 'authors': 'Xiang Meng, Mehdi Makni, Rahul Mazumder', 'link': 'https://arxiv.org/abs/2505.23949', 'abstract': "Network pruning reduces the computational requirements of large neural networks, with N:M sparsity -- retaining only N out of every M consecutive weights -- offering a compelling balance between compressed model quality and hardware acceleration. However, N:M sparsity only accelerates forward-pass computations, as N:M patterns are not preserved during matrix transposition, limiting efficiency during training where both passes are computationally intensive. While transposable N:M sparsity has been proposed to address this limitation, existing methods for finding transposable N:M sparse masks either fail to scale to large models or are restricted to M=4 which results in suboptimal compression-accuracy trade-off. We introduce an efficient solver for transposable N:M masks that scales to billion-parameter models. We formulate mask generation as optimal transport problems and solve through entropy regularization and Dykstra's algorithm, followed by a rounding procedure. Our tensor-based implementation exploits GPU parallelism, achieving up to 100x speedup with only 1-10% error compared to existing methods. Our approach can be integrated with layer-wise N:M pruning frameworks including Wanda, SparseGPT and ALPS to produce transposable N:M sparse models with arbitrary N:M values. Experiments show that LLaMA3.2-8B with transposable 16:32 sparsity maintains performance close to its standard N:M counterpart and outperforms standard 2:4 sparse model, showing the practical value of our approach.", 'abstract_zh': '可迁移的N:M稀疏性提高了大规模神经网络的计算效率，但矩阵转置期间N:M模式的丢失限制了其在训练过程中的效率。尽管已经提出了可迁移的N:M稀疏性来解决这一限制，现有方法要么无法扩展到大型模型，要么仅限于M=4，导致压缩-准确性权衡不佳。我们引入了一种可扩展到十亿参数模型的高效可迁移N:M稀疏性掩码求解器。我们将掩码生成公式化为最优传输问题，并通过熵正则化和迪克斯特拉算法结合舍入步骤进行求解。基于张量的实现利用了GPU并行性，在保持1-10%误差的情况下实现了高达100倍的加速。我们的方法可以与LayerWise N:M 神经网络剪枝框架（如Wanda、SparseGPT和ALPS）集成，生成具有任意N:M值的可迁移N:M稀疏模型。实验表明，具有可迁移16:32稀疏性的LLaMA3.2-8B在性能上接近其标准的N:M对等模型，并且优于标准的2:4稀疏模型，展示了我们方法的实际价值。', 'title_zh': 'TSENOR: 高效的寻找可移位N:M稀疏掩码算法'}
{'arxiv_id': 'arXiv:2505.23947', 'title': 'Position: The Future of Bayesian Prediction Is Prior-Fitted', 'authors': 'Samuel Müller, Arik Reuter, Noah Hollmann, David Rügamer, Frank Hutter', 'link': 'https://arxiv.org/abs/2505.23947', 'abstract': 'Training neural networks on randomly generated artificial datasets yields Bayesian models that capture the prior defined by the dataset-generating distribution. Prior-data Fitted Networks (PFNs) are a class of methods designed to leverage this insight. In an era of rapidly increasing computational resources for pre-training and a near stagnation in the generation of new real-world data in many applications, PFNs are poised to play a more important role across a wide range of applications. They enable the efficient allocation of pre-training compute to low-data scenarios. Originally applied to small Bayesian modeling tasks, the field of PFNs has significantly expanded to address more complex domains and larger datasets. This position paper argues that PFNs and other amortized inference approaches represent the future of Bayesian inference, leveraging amortized learning to tackle data-scarce problems. We thus believe they are a fruitful area of research. In this position paper, we explore their potential and directions to address their current limitations.', 'abstract_zh': '训练随机生成的仿制数据集的神经网络会产生捕捉数据集生成分布先验的贝叶斯模型。先验-数据拟合网络（PFNs）是一类旨在利用这一洞察的方法。在计算资源用于预训练迅速增加而许多应用中新现实数据生成近于停滞的时代，PFNs有望在广泛的应用中发挥更重要的作用。它们能使预训练计算资源更高效地分配到数据稀少场景中。最初应用于小型贝叶斯建模任务，PFN领域已经显著扩展以应对更复杂的领域和更大的数据集。本文认为，PFNs和其他拟合性推理方法是贝叶斯推理的未来，通过拟合性学习来应对数据稀少的问题。因此，我们认为这是一条富有成果的研究方向。在本文中，我们探讨了它们的潜在应用和改进方向以解决当前的局限。', 'title_zh': '位置：Bayesian预测的未来是先验匹配'}
{'arxiv_id': 'arXiv:2505.23942', 'title': 'SG-Blend: Learning an Interpolation Between Improved Swish and GELU for Robust Neural Representations', 'authors': 'Gaurav Sarkar, Jay Gala, Subarna Tripathi', 'link': 'https://arxiv.org/abs/2505.23942', 'abstract': "The design of activation functions remains a pivotal component in optimizing deep neural networks. While prevailing choices like Swish and GELU demonstrate considerable efficacy, they often exhibit domain-specific optima. This work introduces SG-Blend, a novel activation function that blends our proposed SSwish, a first-order symmetric variant of Swish and the established GELU through dynamic interpolation. By adaptively blending these constituent functions via learnable parameters, SG-Blend aims to harness their complementary strengths: SSwish's controlled non-monotonicity and symmetry, and GELU's smooth, probabilistic profile, to achieve a more universally robust balance between model expressivity and gradient stability. We conduct comprehensive empirical evaluations across diverse modalities and architectures, showing performance improvements across all considered natural language and computer vision tasks and models. These results, achieved with negligible computational overhead, underscore SG-Blend's potential as a versatile, drop-in replacement that consistently outperforms strong contemporary baselines. The code is available at this https URL.", 'abstract_zh': '激活函数的设计仍然是优化深层神经网络的关键组件。虽然现有的选择如Swish和GELU表现出显著的效果，但它们往往在特定领域表现出最优性。本文引入了SG-Blend，这是一种新的激活函数，通过动态插值结合了我们提出的SSwish（Swish的一阶对称变体）和已有的GELU。通过使用可学习参数自适应地结合这些组成函数，SG-Blend旨在利用它们的互补优势：SSwish的可控非单调性和对称性以及GELU的平滑和概率特性，以实现模型表达能力和梯度稳定性之间的更通用稳健平衡。我们在多种模态和架构下进行了全面的经验评估，展示了在所有考虑的自然语言处理和计算机视觉任务和模型中的性能改进。这些结果表明，SG-Blend在几乎不增加计算开销的情况下，具有作为多功能且可直接替代的潜在能力，通常优于强大的当代基线。代码可在以下链接获取。', 'title_zh': 'SG-Blend: 学习改进Swish和GELU之间的插值以获得稳健的神经表示'}
{'arxiv_id': 'arXiv:2505.23933', 'title': 'BIRD: Behavior Induction via Representation-structure Distillation', 'authors': 'Galen Pogoncheff, Michael Beyeler', 'link': 'https://arxiv.org/abs/2505.23933', 'abstract': "Human-aligned deep learning models exhibit behaviors consistent with human values, such as robustness, fairness, and honesty. Transferring these behavioral properties to models trained on different tasks or data distributions remains challenging: aligned behavior is easily forgotten during fine-tuning, and collecting task-specific data that preserves this behavior can be prohibitively costly. We introduce BIRD (Behavior Induction via Representation-structure Distillation), a flexible framework for transferring aligned behavior by matching the internal representation structure of a student model to that of a teacher. Applied to out-of-distribution robustness in image classification, BIRD outperforms fine-tuning, transfer learning, and continual learning methods, improving robust accuracy by up to 16% over the next strongest baseline. It remains effective even when the teacher is trained on a much simpler dataset and is $25 \\times$ smaller than the student. In a large-scale study of over 400 teacher-student pairs, we show that three interpretable and computable properties of the teacher's representations (i.e., task relevance, behavioral relevance, and complementary knowledge) explain up to 85% of the variance in transfer success. These insights offer practical guidance for teacher selection and design. BIRD turns small, well-aligned models into scalable alignment seeds, removing a key bottleneck in deploying safe AI systems in the wild.", 'abstract_zh': '基于表示结构蒸馏的行为传递：BIRD框架', 'title_zh': 'BIRD: 基于表示结构蒸馏的行为诱导'}
{'arxiv_id': 'arXiv:2505.23931', 'title': 'Scaling up the think-aloud method', 'authors': 'Daniel Wurgaft, Ben Prystawski, Kanishk Gandhi, Cedegao E. Zhang, Joshua B. Tenenbaum, Noah D. Goodman', 'link': 'https://arxiv.org/abs/2505.23931', 'abstract': 'The think-aloud method, where participants voice their thoughts as they solve a task, is a valuable source of rich data about human reasoning processes. Yet, it has declined in popularity in contemporary cognitive science, largely because labor-intensive transcription and annotation preclude large sample sizes. Here, we develop methods to automate the transcription and annotation of verbal reports of reasoning using natural language processing tools, allowing for large-scale analysis of think-aloud data. In our study, 640 participants thought aloud while playing the Game of 24, a mathematical reasoning task. We automatically transcribed the recordings and coded the transcripts as search graphs, finding moderate inter-rater reliability with humans. We analyze these graphs and characterize consistency and variation in human reasoning traces. Our work demonstrates the value of think-aloud data at scale and serves as a proof of concept for the automated analysis of verbal reports.', 'abstract_zh': '自述法，即参与者在完成任务时口头表达其思考过程的方法，是研究人类推理过程的重要数据来源。然而，由于劳动密集型的转录和标注工作限制了样本量，该方法在当代认知科学中的应用已大大减少。本文开发了使用自然语言处理工具自动转录和标注推理口头报告的方法，以便大规模分析自述数据。在我们的研究中，640名参与者在玩24点游戏（一个数学推理任务）时进行了自述。我们自动转录了录音，并将转录文本编码为搜索图，与人工标注具有 Moderate 的一致可靠性。我们分析这些图，描述了人类推理痕迹的一致性和差异性。我们的研究证明了大规模自述数据的价值，并且展示了自动化分析口头报告的可行性。', 'title_zh': '扩大思维 aloud 方法的应用规模'}
{'arxiv_id': 'arXiv:2505.23930', 'title': 'Exploring Societal Concerns and Perceptions of AI: A Thematic Analysis through the Lens of Problem-Seeking', 'authors': 'Naomi Omeonga wa Kayembe', 'link': 'https://arxiv.org/abs/2505.23930', 'abstract': "This study introduces a novel conceptual framework distinguishing problem-seeking from problem-solving to clarify the unique features of human intelligence in contrast to AI. Problem-seeking refers to the embodied, emotionally grounded process by which humans identify and set goals, while problem-solving denotes the execution of strategies aimed at achieving such predefined objectives. The framework emphasizes that while AI excels at efficiency and optimization, it lacks the orientation derived from experiential grounding and the embodiment flexibility intrinsic to human cognition. To empirically explore this distinction, the research analyzes metadata from 157 YouTube videos discussing AI. Conducting a thematic analysis combining qualitative insights with keyword-based quantitative metrics, this mixed-methods approach uncovers recurring themes in public discourse, including privacy, job displacement, misinformation, optimism, and ethical concerns. The results reveal a dual sentiment: public fascination with AI's capabilities coexists with anxiety and skepticism about its societal implications. The discussion critiques the orthogonality thesis, which posits that intelligence is separable from goal content, and instead argues that human intelligence integrates goal-setting and goal-pursuit. It underscores the centrality of embodied cognition in human reasoning and highlights how AI's limitations come from its current reliance on computational processing. The study advocates for enhancing emotional and digital literacy to foster responsible AI engagement. It calls for reframing public discourse to recognize AI as a tool that augments -- rather than replaces -- human intelligence. By positioning problem seeking at the core of cognition and as a critical dimension of intelligence, this research offers new perspectives on ethically aligned and human-centered AI development.", 'abstract_zh': '本研究引入了一个新颖的概念框架，区分问题寻找与问题解决，以阐明人类智能与AI的独特特征。问题寻找是指人类识别并设定目标的具身、情感导向过程，而问题解决则指执行旨在达成这些预定义目标的策略。该框架强调，尽管AI在效率和优化方面表现优异，但它缺乏基于经验 grounding 和人类认知本质具身灵活性的方向性。为了实证探索这一区别，研究分析了157个YouTube视频的元数据，这些视频讨论了AI。运用结合定性洞见与基于关键词的定量指标的主题分析方法，这种混合方法揭示了公共话语中的重复主题，包括隐私、就业替代、虚假信息、乐观主义和伦理关切。研究结果揭示了一种双重情感：公众对AI能力的兴趣与对其社会影响的焦虑和怀疑共存。讨论批评了正交性论点，该论点认为智能可以独立于目标内容，而是认为人类智能将目标设定与目标追求紧密结合。研究强调了具身认知在人类推理中的核心地位，并指出了AI当前依赖于计算处理导致的局限性。研究倡导增强情感和数字素养，以促进负责任的AI参与。研究呼吁重新构架公众话语，承认AI作为一种增强——而非替代——人类智能的工具。通过将问题寻找置于认知的核心，并作为智能的关键维度，本研究为伦理对齐和以人类为中心的AI发展提供了新的视角。', 'title_zh': '探究关于AI的社会关注与感知：问题探讨视角的主题分析'}
{'arxiv_id': 'arXiv:2505.23923', 'title': 'ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents', 'authors': 'Feiteng Fang, Ting-En Lin, Yuchuan Wu, Xiong Liu, Xiang Huang, Dingwei Chen, Jing Ye, Haonan Zhang, Liang Zhu, Hamid Alinejad-Rokny, Min Yang, Fei Huang, Yongbin Li', 'link': 'https://arxiv.org/abs/2505.23923', 'abstract': 'Role-Playing Language Agents (RPLAs) aim to simulate characters for realistic and engaging human-computer interactions. However, traditional reward models often struggle with scalability and adapting to subjective conversational preferences. We propose ChARM, a Character-based Act-adaptive Reward Model, addressing these challenges through two innovations: (1) an act-adaptive margin that significantly enhances learning efficiency and generalizability, and (2) a self-evolution mechanism leveraging large-scale unlabeled data to improve training coverage. Additionally, we introduce RoleplayPref, the first large-scale preference dataset specifically for RPLAs, featuring 1,108 characters, 13 subcategories, and 16,888 bilingual dialogues, alongside RoleplayEval, a dedicated evaluation benchmark. Experimental results show a 13% improvement over the conventional Bradley-Terry model in preference rankings. Furthermore, applying ChARM-generated rewards to preference learning techniques (e.g., direct preference optimization) achieves state-of-the-art results on CharacterEval and RoleplayEval. Code and dataset are available at this https URL.', 'abstract_zh': '基于角色的行动自适应奖励模型（ChARM）旨在模拟角色以实现真实且互动的人机对话。然而，传统的奖励模型往往在可扩展性和适应主观对话偏好方面存在困难。我们提出了一种基于角色的行动自适应奖励模型（ChARM），通过两项创新解决这些挑战：（1）行动自适应边际，显著提高了学习效率和普适性；（2）利用大规模未标注数据的自我演化机制，提高训练覆盖范围。此外，我们引入了首个专门针对角色扮演语言代理（RPLAs）的大规模偏好数据集——RoleplayPref，包含1,108个角色、13个子类别和16,888个双语对话，以及专门的评估基准——RoleplayEval。实验结果显示，ChARM在偏好排名上比传统的Bradley-Terry模型提高了13%。进一步将ChARM生成的奖励应用于偏好学习技术（例如直接偏好优化）在CharacterEval和RoleplayEval上达到了最先进的结果。代码和数据集可在以下链接获取。', 'title_zh': '基于字符的适应性奖励建模以优化高级角色扮演语言代理'}
{'arxiv_id': 'arXiv:2505.23917', 'title': 'Representational Difference Explanations', 'authors': 'Neehar Kondapaneni, Oisin Mac Aodha, Pietro Perona', 'link': 'https://arxiv.org/abs/2505.23917', 'abstract': 'We propose a method for discovering and visualizing the differences between two learned representations, enabling more direct and interpretable model comparisons. We validate our method, which we call Representational Differences Explanations (RDX), by using it to compare models with known conceptual differences and demonstrate that it recovers meaningful distinctions where existing explainable AI (XAI) techniques fail. Applied to state-of-the-art models on challenging subsets of the ImageNet and iNaturalist datasets, RDX reveals both insightful representational differences and subtle patterns in the data. Although comparison is a cornerstone of scientific analysis, current tools in machine learning, namely post hoc XAI methods, struggle to support model comparison effectively. Our work addresses this gap by introducing an effective and explainable tool for contrasting model representations.', 'abstract_zh': '我们提出了一种发现和可视化两种学习表示之间差异的方法，从而实现更直接和可解释的模型比较。我们通过使用该方法比较具有已知概念差异的模型，并证明它能够在现有可解释人工智能(XAI)技术失效的情况下恢复有意义的区分，验证了该方法的有效性。我们将其称为表示差异解释(RDX)。应用于ImageNet和iNaturalist数据集具有挑战性的子集中的最新模型，RDX揭示了有益的表示差异和数据中的细微模式。尽管比较是科学研究的核心，当前机器学习中的工具，特别是事后可解释性人工智能(XAI)方法，难以有效地支持模型比较。我们的工作通过引入一个有效的可解释工具来对比模型表示，填补了这一空白。', 'title_zh': '表征差异解释'}
{'arxiv_id': 'arXiv:2505.23879', 'title': 'CNN-LSTM Hybrid Model for AI-Driven Prediction of COVID-19 Severity from Spike Sequences and Clinical Data', 'authors': 'Caio Cheohen, Vinnícius M. S. Gomes, Manuela L. da Silva', 'link': 'https://arxiv.org/abs/2505.23879', 'abstract': 'The COVID-19 pandemic, caused by SARS-CoV-2, highlighted the critical need for accurate prediction of disease severity to optimize healthcare resource allocation and patient management. The spike protein, which facilitates viral entry into host cells, exhibits high mutation rates, particularly in the receptor-binding domain, influencing viral pathogenicity. Artificial intelligence approaches, such as deep learning, offer promising solutions for leveraging genomic and clinical data to predict disease outcomes. Objective: This study aimed to develop a hybrid CNN-LSTM deep learning model to predict COVID-19 severity using spike protein sequences and associated clinical metadata from South American patients. Methods: We retrieved 9,570 spike protein sequences from the GISAID database, of which 3,467 met inclusion criteria after standardization. The dataset included 2,313 severe and 1,154 mild cases. A feature engineering pipeline extracted features from sequences, while demographic and clinical variables were one-hot encoded. A hybrid CNN-LSTM architecture was trained, combining CNN layers for local pattern extraction and an LSTM layer for long-term dependency modeling. Results: The model achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%, and recall of 82.85%, demonstrating robust classification performance. Training stabilized at 85% accuracy with minimal overfitting. The most prevalent lineages (P.1, AY.99.2) and clades (GR, GK) aligned with regional epidemiological trends, suggesting potential associations between viral genetics and clinical outcomes. Conclusion: The CNN-LSTM hybrid model effectively predicted COVID-19 severity using spike protein sequences and clinical data, highlighting the utility of AI in genomic surveillance and precision public health. Despite limitations, this approach provides a framework for early severity prediction in future outbreaks.', 'abstract_zh': 'COVID-19疫情背景下基于刺突蛋白序列和临床元数据的混合CNN-LSTM深度学习模型在南美患者中预测疾病严重程度的研究', 'title_zh': '基于CNN-LSTM混合模型的AI驱动的新冠肺炎严重程度预测方法：从刺突序列和临床数据出发'}
{'arxiv_id': 'arXiv:2505.23876', 'title': 'A comparative analysis of a neural network with calculated weights and a neural network with random generation of weights based on the training dataset size', 'authors': 'Polad Geidarov', 'link': 'https://arxiv.org/abs/2505.23876', 'abstract': 'The paper discusses the capabilities of multilayer perceptron neural networks implementing metric recognition methods, for which the values of the weights are calculated analytically by formulas. Comparative experiments in training a neural network with pre-calculated weights and with random initialization of weights on different sizes of the MNIST training dataset are carried out. The results of the experiments show that a multilayer perceptron with pre-calculated weights can be trained much faster and is much more robust to the reduction of the training dataset.', 'abstract_zh': '具有预计算权重的多层感知器神经网络的度量识别能力研究：基于不同MNIST训练数据集规模的比较实验', 'title_zh': '基于训练数据集规模的计算权重神经网络与随机生成权重神经网络的比较分析'}
{'arxiv_id': 'arXiv:2505.23875', 'title': 'A Benchmark Dataset for Graph Regression with Homogeneous and Multi-Relational Variants', 'authors': 'Peter Samoaa, Marcus Vukojevic, Morteza Haghir Chehreghani, Antonio Longa', 'link': 'https://arxiv.org/abs/2505.23875', 'abstract': "Graph-level regression underpins many real-world applications, yet public benchmarks remain heavily skewed toward molecular graphs and citation networks. This limited diversity hinders progress on models that must generalize across both homogeneous and heterogeneous graph structures. We introduce RelSC, a new graph-regression dataset built from program graphs that combine syntactic and semantic information extracted from source code. Each graph is labelled with the execution-time cost of the corresponding program, providing a continuous target variable that differs markedly from those found in existing benchmarks. RelSC is released in two complementary variants. RelSC-H supplies rich node features under a single (homogeneous) edge type, while RelSC-M preserves the original multi-relational structure, connecting nodes through multiple edge types that encode distinct semantic relationships. Together, these variants let researchers probe how representation choice influences model behaviour. We evaluate a diverse set of graph neural network architectures on both variants of RelSC. The results reveal consistent performance differences between the homogeneous and multi-relational settings, emphasising the importance of structural representation. These findings demonstrate RelSC's value as a challenging and versatile benchmark for advancing graph regression methods.", 'abstract_zh': '基于图的回归在许多实际应用中占据重要地位，但公共基准数据集仍然过分集中在分子图和引用网络上。这种有限的多样性阻碍了模型在同质和异质图结构之间泛化的进展。我们介绍了RelSC，这是一个新的图回归数据集，它基于包含源代码语法规则和语义信息的程序图构建。每个图都标记有对应程序的执行时间成本，提供了一个与现有基准中存在的目标变量大相径庭的连续目标变量。RelSC提供两种互补的变体。RelSC-H提供单一边类型下的丰富节点特征，而RelSC-M保留了原始的多关系结构，通过多种边类型连接节点，这些边类型编码不同的语义关系。这两种变体使研究人员能够探究表示选择如何影响模型行为。我们使用一系列图神经网络架构评估了RelSC的两种变体。结果揭示了同质和多关系设置之间的一致性能差异，强调了结构表示的重要性。这些发现证明了RelSC作为挑战性和多功能基准数据集的价值，对于推进图回归方法具有重要意义。', 'title_zh': '同质化和多关系变体的图回归基准数据集'}
{'arxiv_id': 'arXiv:2505.23873', 'title': 'KGMark: A Diffusion Watermark for Knowledge Graphs', 'authors': 'Hongrui Peng, Haolang Lu, Yuanlong Yu, Weiye Fu, Kun Wang, Guoshun Nan', 'link': 'https://arxiv.org/abs/2505.23873', 'abstract': 'Knowledge graphs (KGs) are ubiquitous in numerous real-world applications, and watermarking facilitates protecting intellectual property and preventing potential harm from AI-generated content. Existing watermarking methods mainly focus on static plain text or image data, while they can hardly be applied to dynamic graphs due to spatial and temporal variations of structured data. This motivates us to propose KGMARK, the first graph watermarking framework that aims to generate robust, detectable, and transparent diffusion fingerprints for dynamic KG data. Specifically, we propose a novel clustering-based alignment method to adapt the watermark to spatial variations. Meanwhile, we present a redundant embedding strategy to harden the diffusion watermark against various attacks, facilitating the robustness of the watermark to the temporal variations. Additionally, we introduce a novel learnable mask matrix to improve the transparency of diffusion fingerprints. By doing so, our KGMARK properly tackles the variation challenges of structured data. Experiments on various public benchmarks show the effectiveness of our proposed KGMARK.', 'abstract_zh': '知识图谱水印框架KGMARK：针对动态知识图谱数据的鲁棒、可检测和透明的扩散指纹生成', 'title_zh': 'KGMark: 用于知识图谱的扩散水印'}
{'arxiv_id': 'arXiv:2505.23866', 'title': 'Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization', 'authors': 'Chengli Tan, Yubo Zhou, Haishan Ye, Guang Dai, Junmin Liu, Zengjie Song, Jiangshe Zhang, Zixiang Zhao, Yunda Hao, Yong Xu', 'link': 'https://arxiv.org/abs/2505.23866', 'abstract': 'Deep neural networks have been increasingly used in safety-critical applications such as medical diagnosis and autonomous driving. However, many studies suggest that they are prone to being poorly calibrated and have a propensity for overconfidence, which may have disastrous consequences. In this paper, unlike standard training such as stochastic gradient descent, we show that the recently proposed sharpness-aware minimization (SAM) counteracts this tendency towards overconfidence. The theoretical analysis suggests that SAM allows us to learn models that are already well-calibrated by implicitly maximizing the entropy of the predictive distribution. Inspired by this finding, we further propose a variant of SAM, coined as CSAM, to ameliorate model calibration. Extensive experiments on various datasets, including ImageNet-1K, demonstrate the benefits of SAM in reducing calibration error. Meanwhile, CSAM performs even better than SAM and consistently achieves lower calibration error than other approaches', 'abstract_zh': '深度神经网络在医疗诊断和自动驾驶等关键安全应用中越来越广泛。然而，许多研究指出，它们容易校准不当并且倾向于过度自信，这可能产生灾难性后果。本文中，与标准训练方法（如随机梯度下降）不同，我们证明了最近提出的锐度意识最小化（SAM）能够对抗这一过度自信的倾向。理论分析表明，SAM使得我们能够通过隐式最大化预测分布的熵来学习已经校准良好的模型。受这一发现的启发，我们进一步提出了一种SAM的变种，即CSAM，以改善模型校准。在包括ImageNet-1K在内的多个数据集上的广泛实验表明，SAM在减少校准误差方面具有优势。同时，CSAM表现更优，并且始终能够在校准误差上比其他方法取得更好的效果。', 'title_zh': '理解Sharpness-Aware Minimization的校准效益途径'}
{'arxiv_id': 'arXiv:2505.23865', 'title': 'Combining Deep Architectures for Information Gain estimation and Reinforcement Learning for multiagent field exploration', 'authors': 'Emanuele Masiero, Vito Trianni, Giuseppe Vizzari, Dimitri Ognibene', 'link': 'https://arxiv.org/abs/2505.23865', 'abstract': 'Precision agriculture requires efficient autonomous systems for crop monitoring, where agents must explore large-scale environments while minimizing resource consumption. This work addresses the problem as an active exploration task in a grid environment representing an agricultural field. Each cell may contain targets (e.g., damaged crops) observable from nine predefined points of view (POVs). Agents must infer the number of targets per cell using partial, sequential observations.\nWe propose a two-stage deep learning framework. A pre-trained LSTM serves as a belief model, updating a probabilistic map of the environment and its associated entropy, which defines the expected information gain (IG). This allows agents to prioritize informative regions. A key contribution is the inclusion of a POV visibility mask in the input, preserving the Markov property under partial observability and avoiding revisits to already explored views.\nThree agent architectures were compared: an untrained IG-based agent selecting actions to maximize entropy reduction; a DQN agent using CNNs over local 3x3 inputs with belief, entropy, and POV mask; and a Double-CNN DQN agent with wider spatial context. Simulations on 20x20 maps showed that the untrained agent performs well despite its simplicity. The DQN agent matches this performance when the POV mask is included, while the Double-CNN agent consistently achieves superior exploration efficiency, especially in larger environments.\nResults show that uncertainty-aware policies leveraging entropy, belief states, and visibility tracking lead to robust and scalable exploration. Future work includes curriculum learning, multi-agent cooperation with shared rewards, transformer-based models, and intrinsic motivation mechanisms to further enhance learning efficiency and policy generalization.', 'abstract_zh': '精准农业需要高效的自主系统来进行作物监测，其中代理必须在尽量减少资源消耗的情况下探索大规模环境。本研究将该问题视为在代表农田的网格环境中进行的积极探索任务。每个网格单元可能包含从九个预定义视角（POVs）之一可观察的目标（如受损作物）。代理必须使用部分顺序观察来推断每个单元中的目标数量。\n我们提出了一种两阶段的深度学习框架。预先训练的LSTM作为信念模型，更新环境及其关联的熵概率地图，熵定义了预期的信息增益（IG），这使得代理可以优先考虑具有信息性的区域。一个关键贡献是在输入中包括POV可见性掩码，这在部分可观测性下保持了马尔可夫性质，并避免了对已探索视角的重复访问。\n三种代理架构进行了比较：一个未训练的基于熵减的代理，选择行动以最大化熵减少；一个使用局部3x3输入的CNNs的DQN代理，带有信念、熵和POV掩码；以及一个具有更宽空间上下文的双CNN DQN代理。在20x20的地图上进行的模拟显示，尽管未训练的代理很简单，但它表现良好。当包括POV掩码时，DQN代理达到了类似的性能，而双CNN代理则在更大的环境中始终实现更高效的探索效率。\n结果表明，利用熵、信念状态和可见性跟踪的不确定性感知策略能够实现稳健且可扩展的探索。未来的工作包括层级学习、具有共享奖励的多代理合作、基于变换器的模型以及内在动机机制，以进一步增强学习效率和策略的一般化。', 'title_zh': '结合深层架构进行信息增益估计与多agent领域探索的强化学习方法'}
{'arxiv_id': 'arXiv:2505.23864', 'title': 'Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections', 'authors': 'Wei Zhuo, Zhaohuan Zhan, Ziduo Yang, Han Yu', 'link': 'https://arxiv.org/abs/2505.23864', 'abstract': 'Federated learning (FL) on graph-structured data typically faces non-IID challenges, particularly in scenarios where each client holds a distinct subgraph sampled from a global graph. In this paper, we introduce Federated learning with Auxiliary projections (FedAux), a personalized subgraph FL framework that learns to align, compare, and aggregate heterogeneously distributed local models without sharing raw data or node embeddings. In FedAux, each client jointly trains (i) a local GNN and (ii) a learnable auxiliary projection vector (APV) that differentiably projects node embeddings onto a 1D space. A soft-sorting operation followed by a lightweight 1D convolution refines these embeddings in the ordered space, enabling the APV to effectively capture client-specific information. After local training, these APVs serve as compact signatures that the server uses to compute inter-client similarities and perform similarity-weighted parameter mixing, yielding personalized models while preserving cross-client knowledge transfer. Moreover, we provide rigorous theoretical analysis to establish the convergence and rationality of our design. Empirical evaluations across diverse graph benchmarks demonstrate that FedAux substantially outperforms existing baselines in both accuracy and personalization performance.', 'abstract_zh': '图结构数据上的 Federated learning (FL) 通常面临非IID挑战，特别是在每个客户端持有来自全局图的独立子图的场景中。本文介绍了Federated learning with Auxiliary projections (FedAux)，一种无需共享原始数据或节点嵌入的学习个性化局部模型的框架，该框架能够学习对齐、比较和聚合异质分布的局部模型。在FedAux中，每个客户端共同训练一个局部GNN和一个可学习的辅助投影向量（APV），该向量能够差异性地将节点嵌入投影到一维空间中。随后的软排序操作和轻量级的一维卷积在有序空间中进一步细化这些嵌入，使APV能够有效捕捉客户端特定的信息。经过本地训练后，这些APV作为客户端的紧凑签名，服务器利用它们计算客户端间的相似性，并进行加权参数混合，从而产生个性化模型，同时保持跨客户端的知识迁移。此外，我们提供了严格的理论分析，以确证我们设计的收敛性和合理性。在多种图基准测试上的实证评估表明，FedAux在准确性和个性化性能上显著优于现有基线。', 'title_zh': '个性化子图联邦学习与可微辅助投影'}
{'arxiv_id': 'arXiv:2505.23863', 'title': 'Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting', 'authors': 'Chang Liu, Bohao Zhao, Jingtao Ding, Huandong Wang, Yong Li', 'link': 'https://arxiv.org/abs/2505.23863', 'abstract': 'Long-term forecasting of chaotic systems from short-term observations remains a fundamental and underexplored challenge due to the intrinsic sensitivity to initial conditions and the complex geometry of strange attractors. Existing approaches often rely on long-term training data or focus on short-term sequence correlations, struggling to maintain predictive stability and dynamical coherence over extended horizons. We propose PhyxMamba, a novel framework that integrates a Mamba-based state-space model with physics-informed principles to capture the underlying dynamics of chaotic systems. By reconstructing the attractor manifold from brief observations using time-delay embeddings, PhyxMamba extracts global dynamical features essential for accurate forecasting. Our generative training scheme enables Mamba to replicate the physical process, augmented by multi-token prediction and attractor geometry regularization for physical constraints, enhancing prediction accuracy and preserving key statistical invariants. Extensive evaluations on diverse simulated and real-world chaotic systems demonstrate that PhyxMamba delivers superior long-term forecasting and faithfully captures essential dynamical invariants from short-term data. This framework opens new avenues for reliably predicting chaotic systems under observation-scarce conditions, with broad implications across climate science, neuroscience, epidemiology, and beyond. Our code is open-source at this https URL.', 'abstract_zh': '短时观测下混沌系统的长期预报仍然是一个因初始条件的高度敏感性和怪异吸引子的复杂几何结构而未充分探索的基本挑战。现有的方法往往依赖于长期训练数据或集中在短期序列相关性上，难以在较长的时间尺度上保持预测稳定性与动力学一致性。我们提出PhyxMamba框架，该框架将基于Mamba的状态空间模型与物理指导原则相结合，以捕捉混沌系统的内在动力学。通过使用时间延迟嵌入从短暂观测中重构吸引子流形，PhyxMamba提取了对于准确预报至关重要的全局动力学特征。我们生成性训练方案使Mamba能够模拟物理过程，并通过多令牌预测和吸引子几何结构正则化增加物理约束，从而提高预测准确性并保持关键统计不变量。在多元模拟和实际混沌系统的广泛评估中，PhyxMamba展示了其在长期预报方面的优越性能，并能从短时数据中忠实捕捉关键动力学不变量。该框架为在观测数据稀缺条件下可靠预测混沌系统开辟了新途径，在气候科学、神经科学、流行病学等领域具有广泛影响。我们的代码在以下网址公开：this https URL。', 'title_zh': 'Mamba 结合物理原理掌握长期混沌系统预测'}
{'arxiv_id': 'arXiv:2505.23862', 'title': 'A New Deep-learning-Based Approach For mRNA Optimization: High Fidelity, Computation Efficiency, and Multiple Optimization Factors', 'authors': 'Zheng Gong, Ziyi Jiang, Weihao Gao, Deng Zhuo, Lan Ma', 'link': 'https://arxiv.org/abs/2505.23862', 'abstract': "The mRNA optimization is critical for therapeutic and biotechnological applications, since sequence features directly govern protein expression levels and efficacy. However, current methods face significant challenges in simultaneously achieving three key objectives: (1) fidelity (preventing unintended amino acid changes), (2) computational efficiency (speed and scalability), and (3) the scope of optimization variables considered (multi-objective capability). Furthermore, existing methods often fall short of comprehensively incorporating the factors related to the mRNA lifecycle and translation process, including intrinsic mRNA sequence properties, secondary structure, translation elongation kinetics, and tRNA availability. To address these limitations, we introduce \\textbf{RNop}, a novel deep learning-based method for mRNA optimization. We collect a large-scale dataset containing over 3 million sequences and design four specialized loss functions, the GPLoss, CAILoss, tAILoss, and MFELoss, which simultaneously enable explicit control over sequence fidelity while optimizing species-specific codon adaptation, tRNA availability, and desirable mRNA secondary structure features. Then, we demonstrate RNop's effectiveness through extensive in silico and in vivo experiments. RNop ensures high sequence fidelity, achieves significant computational throughput up to 47.32 sequences/s, and yields optimized mRNA sequences resulting in a significant increase in protein expression for functional proteins compared to controls. RNop surpasses current methodologies in both quantitative metrics and experimental validation, enlightening a new dawn for efficient and effective mRNA design. Code and models will be available at this https URL.", 'abstract_zh': 'mRNA优化对于治疗和生物技术应用至关重要，因为序列特征直接控制蛋白质的表达水平和疗效。然而，当前方法在同时实现三个关键目标方面面临重大挑战：(1) 忠实性（防止非预期的氨基酸变化），(2) 计算效率（速度和可扩展性），以及(3) 考虑的优化变量范围（多目标能力）。此外，现有方法往往未能全面纳入与mRNA生命周期和翻译过程相关的因素，包括内在的mRNA序列属性、二级结构、翻译延伸动力学和tRNA可用性。为了解决这些局限性，我们引入了**RNop**，这是一种基于深度学习的mRNA优化新方法。我们收集了一个包含超过300万个序列的大规模数据集，并设计了四个专门的损失函数：GPLoss、CAILoss、tAILoss 和 MFELoss，这些函数能够在优化特定物种的密码子适应性、tRNA可用性和理想的mRNA二级结构特征的同时，明确控制序列忠实性。然后，我们通过广泛的体外和体内实验证明了RNop的有效性。RNop确保了高序列忠实性，实现了显著的计算吞吐量（高达47.32序列/秒），并且优化的mRNA序列相比对照组显著提高了功能性蛋白质的表达。RNop在定量指标和实验验证方面均超过了现有方法，为高效有效的mRNA设计开辟了新的前景。源代码和模型可在以下链接获取。', 'title_zh': '基于深度学习的新方法为mRNA优化：高保真度、计算效率及多重优化因素'}
{'arxiv_id': 'arXiv:2505.23861', 'title': 'BiBLDR: Bidirectional Behavior Learning for Drug Repositioning', 'authors': 'Renye Zhang, Mengyun Yang, Qichang Zhao, Jianxin Wang', 'link': 'https://arxiv.org/abs/2505.23861', 'abstract': 'Drug repositioning aims to identify potential new indications for existing drugs to reduce the time and financial costs associated with developing new drugs. Most existing deep learning-based drug repositioning methods predominantly utilize graph-based representations. However, graph-based drug repositioning methods struggle to perform effective inference in cold-start scenarios involving novel drugs because of the lack of association information with the diseases. Unlike traditional graph-based approaches, we propose a bidirectional behavior learning strategy for drug repositioning, known as BiBLDR. This innovative framework redefines drug repositioning as a behavior sequential learning task to capture drug-disease interaction patterns. First, we construct bidirectional behavioral sequences based on drug and disease sides. The consideration of bidirectional information ensures a more meticulous and rigorous characterization of the behavioral sequences. Subsequently, we propose a two-stage strategy for drug repositioning. In the first stage, we construct prototype spaces to characterize the representational attributes of drugs and diseases. In the second stage, these refined prototypes and bidirectional behavior sequence data are leveraged to predict potential drug-disease associations. Based on this learning approach, the model can more robustly and precisely capture the interactive relationships between drug and disease features from bidirectional behavioral sequences. Extensive experiments demonstrate that our method achieves state-of-the-art performance on benchmark datasets. Meanwhile, BiBLDR demonstrates significantly superior performance compared to previous methods in cold-start scenarios. Our code is published in this https URL.', 'abstract_zh': '药物再定位旨在识别现有药物的新潜在适应症，以减少开发新药物所需的时间和财务成本。现有的大多数基于深度学习的药物再定位方法主要利用图表示。然而，基于图的药物再定位方法在涉及新型药物的冷启动场景中难以进行有效的推理，因为缺乏与疾病的关联信息。不同于传统的基于图的方法，我们提出了一种双向行为学习策略，称为BiBLDR。该创新框架将药物再定位重新定义为行为序列学习任务，以捕获药物-疾病交互模式。首先，我们基于药物和疾病两侧构建双向行为序列。考虑双向信息确保了对行为序列的更细致和严谨的描述。随后，我们提出了一种双阶段的药物再定位策略。在第一阶段，我们构建原型空间以表征药物和疾病的表示属性。在第二阶段，利用这些细化的原型和双向行为序列数据来预测潜在的药物-疾病关联。基于此学习方法，模型能够更 robust 地和精确地从双向行为序列中捕捉药物和疾病特征的交互关系。大量实验表明，我们的方法在基准数据集中实现了最先进的性能。同时，BiBLDR 在冷启动场景中的性能明显优于之前的 方法。我们的代码发布在 https://github.com/alibaba/Qwen-BiBLDR 。', 'title_zh': 'BiBLDR：双向行为学习用于药物再定位'}
{'arxiv_id': 'arXiv:2505.23860', 'title': 'Quantum computing and artificial intelligence: status and perspectives', 'authors': 'Giovanni Acampora, Andris Ambainis, Natalia Ares, Leonardo Banchi, Pallavi Bhardwaj, Daniele Binosi, G. Andrew D. Briggs, Tommaso Calarco, Vedran Dunjko, Jens Eisert, Olivier Ezratty, Paul Erker, Federico Fedele, Elies Gil-Fuster, Martin Gärttner, Mats Granath, Markus Heyl, Iordanis Kerenidis, Matthias Klusch, Anton Frisk Kockum, Richard Kueng, Mario Krenn, Jörg Lässig, Antonio Macaluso, Sabrina Maniscalco, Florian Marquardt, Kristel Michielsen, Gorka Muñoz-Gil, Daniel Müssig, Hendrik Poulsen Nautrup, Evert van Nieuwenburg, Roman Orus, Jörg Schmiedmayer, Markus Schmitt, Philipp Slusallek, Filippo Vicentini, Christof Weitenberg, Frank K. Wilhelm', 'link': 'https://arxiv.org/abs/2505.23860', 'abstract': 'This white paper discusses and explores the various points of intersection between quantum computing and artificial intelligence (AI). It describes how quantum computing could support the development of innovative AI solutions. It also examines use cases of classical AI that can empower research and development in quantum technologies, with a focus on quantum computing and quantum sensing. The purpose of this white paper is to provide a long-term research agenda aimed at addressing foundational questions about how AI and quantum computing interact and benefit one another. It concludes with a set of recommendations and challenges, including how to orchestrate the proposed theoretical work, align quantum AI developments with quantum hardware roadmaps, estimate both classical and quantum resources - especially with the goal of mitigating and optimizing energy consumption - advance this emerging hybrid software engineering discipline, and enhance European industrial competitiveness while considering societal implications.', 'abstract_zh': 'this white paper探讨了量子计算与人工智能的各种交叉点，并探讨了量子计算如何支持创新人工智能解决方案的发展。它还研究了经典人工智能的应用案例，这些案例可以增强量子技术的研究和开发，重点关注量子计算和量子传感。本文的目的是提供一个长期研究议程，以解决人工智能和量子计算如何相互作用并从中受益的基本问题。最后，它提出了建议和挑战，包括如何协调拟议的理论工作、将量子人工智能的发展与量子硬件路线图对齐、估算从经典到量子的各种资源——特别是在减轻和优化能源消耗方面、推进这一新兴的混合软件工程学科、以及在考虑社会影响的同时增强欧洲工业竞争力。', 'title_zh': '量子计算与人工智能：现状与展望'}
{'arxiv_id': 'arXiv:2505.23859', 'title': 'Towards Minimizing Feature Drift in Model Merging: Layer-wise Task Vector Fusion for Adaptive Knowledge Integration', 'authors': 'Wenju Sun, Qingyong Li, Wen Wang, Yang Liu, Yangli-ao Geng, Boyang Li', 'link': 'https://arxiv.org/abs/2505.23859', 'abstract': 'Multi-task model merging aims to consolidate knowledge from multiple fine-tuned task-specific experts into a unified model while minimizing performance degradation. Existing methods primarily approach this by minimizing differences between task-specific experts and the unified model, either from a parameter-level or a task-loss perspective. However, parameter-level methods exhibit a significant performance gap compared to the upper bound, while task-loss approaches entail costly secondary training procedures. In contrast, we observe that performance degradation closely correlates with feature drift, i.e., differences in feature representations of the same sample caused by model merging. Motivated by this observation, we propose Layer-wise Optimal Task Vector Merging (LOT Merging), a technique that explicitly minimizes feature drift between task-specific experts and the unified model in a layer-by-layer manner. LOT Merging can be formulated as a convex quadratic optimization problem, enabling us to analytically derive closed-form solutions for the parameters of linear and normalization layers. Consequently, LOT Merging achieves efficient model consolidation through basic matrix operations. Extensive experiments across vision and vision-language benchmarks demonstrate that LOT Merging significantly outperforms baseline methods, achieving improvements of up to 4.4% (ViT-B/32) over state-of-the-art approaches.', 'abstract_zh': '多层次最优任务向量融合以最小化特征漂移实现多任务模型合并', 'title_zh': '向最小化模型合并中的特征漂移靠拢：层-wise 任务向量融合实现自适应知识集成'}
{'arxiv_id': 'arXiv:2505.23849', 'title': 'CADRE: Customizable Assurance of Data Readiness in Privacy-Preserving Federated Learning', 'authors': 'Kaveen Hiniduma, Zilinghan Li, Aditya Sinha, Ravi Madduri, Suren Byna', 'link': 'https://arxiv.org/abs/2505.23849', 'abstract': "Privacy-Preserving Federated Learning (PPFL) is a decentralized machine learning approach where multiple clients train a model collaboratively. PPFL preserves privacy and security of the client's data by not exchanging it. However, ensuring that data at each client is of high quality and ready for federated learning (FL) is a challenge due to restricted data access. In this paper, we introduce CADRE (Customizable Assurance of Data REadiness) for FL, a novel framework that allows users to define custom data readiness (DR) standards, metrics, rules, and remedies tailored to specific FL tasks. Our framework generates comprehensive DR reports based on the user-defined metrics, rules, and remedies to ensure datasets are optimally prepared for FL while preserving privacy. We demonstrate the framework's practical application by integrating it into an existing PPFL framework. We conducted experiments across six diverse datasets, addressing seven different DR issues. The results illustrate the framework's versatility and effectiveness in ensuring DR across various dimensions, including data quality, privacy, and fairness. This approach enhances the performance and reliability of FL models as well as utilizes valuable resources by identifying and addressing data-related issues before the training phase.", 'abstract_zh': '隐私保护联邦学习（PPFL）中的数据准备保障（CADRE）框架：针对特定联邦学习任务自定义数据就绪标准与方法', 'title_zh': 'CADRE：隐私保护联邦学习中的可定制化数据就绪性保障'}
{'arxiv_id': 'arXiv:2505.23813', 'title': 'DP-RTFL: Differentially Private Resilient Temporal Federated Learning for Trustworthy AI in Regulated Industries', 'authors': 'Abhijit Talluri', 'link': 'https://arxiv.org/abs/2505.23813', 'abstract': 'Federated Learning (FL) has emerged as a critical paradigm for enabling privacy-preserving machine learning, particularly in regulated sectors such as finance and healthcare. However, standard FL strategies often encounter significant operational challenges related to fault tolerance, system resilience against concurrent client and server failures, and the provision of robust, verifiable privacy guarantees essential for handling sensitive data. These deficiencies can lead to training disruptions, data loss, compromised model integrity, and non-compliance with data protection regulations (e.g., GDPR, CCPA). This paper introduces Differentially Private Resilient Temporal Federated Learning (DP-RTFL), an advanced FL framework designed to ensure training continuity, precise state recovery, and strong data privacy. DP-RTFL integrates local Differential Privacy (LDP) at the client level with resilient temporal state management and integrity verification mechanisms, such as hash-based commitments (referred to as Zero-Knowledge Integrity Proofs or ZKIPs in this context). The framework is particularly suited for critical applications like credit risk assessment using sensitive financial data, aiming to be operationally robust, auditable, and scalable for enterprise AI deployments. The implementation of the DP-RTFL framework is available as open-source.', 'abstract_zh': '差异隐私 resilient 时间联邦学习（DP-RTFL）：确保训练连续性、精确状态恢复和强数据隐私的高级联邦学习框架', 'title_zh': '差分隐私 resilient 时空联邦学习：可信 AI 在受监管行业的应用'}
{'arxiv_id': 'arXiv:2505.23812', 'title': 'Emotion-aware Dual Cross-Attentive Neural Network with Label Fusion for Stance Detection in Misinformative Social Media Content', 'authors': 'Lata Pangtey, Mohammad Zia Ur Rehman, Prasad Chaudhari, Shubhi Bansal, Nagendra Kumar', 'link': 'https://arxiv.org/abs/2505.23812', 'abstract': "The rapid evolution of social media has generated an overwhelming volume of user-generated content, conveying implicit opinions and contributing to the spread of misinformation. The method aims to enhance the detection of stance where misinformation can polarize user opinions. Stance detection has emerged as a crucial approach to effectively analyze underlying biases in shared information and combating misinformation. This paper proposes a novel method for \\textbf{S}tance \\textbf{P}rediction through a \\textbf{L}abel-fused dual cross-\\textbf{A}ttentive \\textbf{E}motion-aware neural \\textbf{Net}work (SPLAENet) in misinformative social media user-generated content. The proposed method employs a dual cross-attention mechanism and a hierarchical attention network to capture inter and intra-relationships by focusing on the relevant parts of source text in the context of reply text and vice versa. We incorporate emotions to effectively distinguish between different stance categories by leveraging the emotional alignment or divergence between the texts. We also employ label fusion that uses distance-metric learning to align extracted features with stance labels, improving the method's ability to accurately distinguish between stances. Extensive experiments demonstrate the significant improvements achieved by SPLAENet over existing state-of-the-art methods. SPLAENet demonstrates an average gain of 8.92\\% in accuracy and 17.36\\% in F1-score on the RumourEval dataset. On the SemEval dataset, it achieves average gains of 7.02\\% in accuracy and 10.92\\% in F1-score. On the P-stance dataset, it demonstrates average gains of 10.03\\% in accuracy and 11.18\\% in F1-score. These results validate the effectiveness of the proposed method for stance detection in the context of misinformative social media content.", 'abstract_zh': '社交媒体中误导性内容中立场预测的SPLAENet标签融合双重交叉注意情感意识神经网络', 'title_zh': '具有标签融合的情感意识双重交叉注意神经网络在虚假社交媒体内容立场检测中的应用'}
{'arxiv_id': 'arXiv:2505.23805', 'title': 'ADA: Automated Moving Target Defense for AI Workloads via Ephemeral Infrastructure-Native Rotation in Kubernetes', 'authors': 'Akram Sheriff, Ken Huang, Zsolt Nemeth, Madjid Nakhjiri', 'link': 'https://arxiv.org/abs/2505.23805', 'abstract': "This paper introduces the Adaptive Defense Agent (ADA), an innovative Automated Moving Target Defense (AMTD) system designed to fundamentally enhance the security posture of AI workloads. ADA operates by continuously and automatically rotating these workloads at the infrastructure level, leveraging the inherent ephemerality of Kubernetes pods. This constant managed churn systematically invalidates attacker assumptions and disrupts potential kill chains by regularly destroying and respawning AI service instances. This methodology, applying principles of chaos engineering as a continuous, proactive defense, offers a paradigm shift from traditional static defenses that rely on complex and expensive confidential or trusted computing solutions to secure the underlying compute platforms, while at the same time agnostically supporting the latest advancements in agentic and nonagentic AI ecosystems and solutions such as agent-to-agent (A2A) communication frameworks or model context protocols (MCP). This AI-native infrastructure design, relying on the widely proliferated cloud-native Kubernetes technologies, facilitates easier deployment, simplifies maintenance through an inherent zero trust posture achieved by rotation, and promotes faster adoption. We posit that ADA's novel approach to AMTD provides a more robust, agile, and operationally efficient zero-trust model for AI services, achieving security through proactive environmental manipulation rather than reactive patching.", 'abstract_zh': 'Adaptive Defense Agent：一种基于混沌工程的自适应防御代理系统', 'title_zh': 'ADA：通过Kubernetes中短暂基础设施原生旋转实现的AI工作负载自动化移动目标防御'}
{'arxiv_id': 'arXiv:2505.23801', 'title': 'SEMFED: Semantic-Aware Resource-Efficient Federated Learning for Heterogeneous NLP Tasks', 'authors': 'Sajid Hussain, Muhammad Sohail, Nauman Ali Khan', 'link': 'https://arxiv.org/abs/2505.23801', 'abstract': 'Background: Federated Learning (FL) has emerged as a promising paradigm for training machine learning models while preserving data privacy. However, applying FL to Natural Language Processing (NLP) tasks presents unique challenges due to semantic heterogeneity across clients, vocabulary mismatches, and varying resource constraints on edge devices. Objectives: This paper introduces SEMFED, a novel semantic-aware resource-efficient federated learning framework specifically designed for heterogeneous NLP tasks. Methods: SEMFED incorporates three key innovations: (1) a semantic-aware client selection mechanism that balances semantic diversity with resource constraints, (2) adaptive NLP-specific model architectures tailored to device capabilities while preserving semantic information, and (3) a communication-efficient semantic feature compression technique that significantly reduces bandwidth requirements. Results: Experimental results on various NLP classification tasks demonstrate that SEMFED achieves an 80.5% reduction in communication costs while maintaining model accuracy above 98%, outperforming state-of-the-art FL approaches. Conclusion: SEMFED effectively manages heterogeneous client environments with varying computational resources, network reliability, and semantic data distributions, making it particularly suitable for real-world federated NLP deployments.', 'abstract_zh': '背景：联邦学习（FL）作为一种在保护数据隐私的同时训练机器学习模型的有前途的范式已经出现。然而，将FL应用于自然语言处理（NLP）任务由于客户端之间语义异质性、词汇不匹配以及边缘设备上不同的资源约束带来了独特的挑战。目标：本文提出了一种名为SEMFED的新颖语义意识资源高效联邦学习框架，专门针对异构NLP任务。方法：SEMFED包含三个关键创新：（1）一种语义意识的客户端选择机制，平衡语义多样性和资源约束；（2）根据设备能力定制适应性的NLP特定模型架构，同时保留语义信息；（3）一种通信高效的语义特征压缩技术，显著减少了带宽要求。结果：在多种NLP分类任务上的实验结果表明，SEMFED在通信成本降低了80.5%的同时，模型准确性保持在98%以上，优于最先进的FL方法。结论：SEMFED有效地管理了具有不同计算资源、网络可靠性和语义数据分布的异构客户端环境，使其特别适合实际部署中的联邦NLP应用。', 'title_zh': 'SEMFED: 具有语义意识的资源高效联邦学习方法用于异构NLP任务'}
{'arxiv_id': 'arXiv:2505.23797', 'title': 'Detection of Suicidal Risk on Social Media: A Hybrid Model', 'authors': 'Zaihan Yang, Ryan Leonard, Hien Tran, Rory Driscoll, Chadbourne Davis', 'link': 'https://arxiv.org/abs/2505.23797', 'abstract': "Suicidal thoughts and behaviors are increasingly recognized as a critical societal concern, highlighting the urgent need for effective tools to enable early detection of suicidal risk. In this work, we develop robust machine learning models that leverage Reddit posts to automatically classify them into four distinct levels of suicide risk severity. We frame this as a multi-class classification task and propose a RoBERTa-TF-IDF-PCA Hybrid model, integrating the deep contextual embeddings from Robustly Optimized BERT Approach (RoBERTa), a state-of-the-art deep learning transformer model, with the statistical term-weighting of TF-IDF, further compressed with PCA, to boost the accuracy and reliability of suicide risk assessment. To address data imbalance and overfitting, we explore various data resampling techniques and data augmentation strategies to enhance model generalization. Additionally, we compare our model's performance against that of using RoBERTa only, the BERT model and other traditional machine learning classifiers. Experimental results demonstrate that the hybrid model can achieve improved performance, giving a best weighted $F_{1}$ score of 0.7512.", 'abstract_zh': '自杀念头和行为日益被认可为一个重要的社会问题，突显了早期检测自杀风险的有效工具的迫切需求。本文中，我们开发了稳健的机器学习模型，利用Reddit帖子自动将它们分类为四种不同的自杀风险严重程度级别。我们将此视为一个多分类分类任务，并提出了一种结合了Robustly Optimized BERT Approach（RoBERTa）的深度上下文嵌入、TF-IDF词频权重和PCA压缩的混合模型，以提高自杀风险评估的准确性和可靠性。为了应对数据不平衡和过拟合问题，我们探索了多种数据重采样技术和数据增强策略以提高模型的泛化能力。此外，我们将我们的模型性能与仅使用RoBERTa、BERT模型以及其他传统机器学习分类器进行比较。实验结果表明，混合模型可以实现更好的性能，获得最佳加权F1分数0.7512。', 'title_zh': '社交媒体中自杀风险的检测：一种混合模型'}
{'arxiv_id': 'arXiv:2505.23792', 'title': 'Zero-Trust Foundation Models: A New Paradigm for Secure and Collaborative Artificial Intelligence for Internet of Things', 'authors': 'Kai Li, Conggai Li, Xin Yuan, Shenghong Li, Sai Zou, Syed Sohail Ahmed, Wei Ni, Dusit Niyato, Abbas Jamalipour, Falko Dressler, Ozgur B. Akan', 'link': 'https://arxiv.org/abs/2505.23792', 'abstract': 'This paper focuses on Zero-Trust Foundation Models (ZTFMs), a novel paradigm that embeds zero-trust security principles into the lifecycle of foundation models (FMs) for Internet of Things (IoT) systems. By integrating core tenets, such as continuous verification, least privilege access (LPA), data confidentiality, and behavioral analytics into the design, training, and deployment of FMs, ZTFMs can enable secure, privacy-preserving AI across distributed, heterogeneous, and potentially adversarial IoT environments. We present the first structured synthesis of ZTFMs, identifying their potential to transform conventional trust-based IoT architectures into resilient, self-defending ecosystems. Moreover, we propose a comprehensive technical framework, incorporating federated learning (FL), blockchain-based identity management, micro-segmentation, and trusted execution environments (TEEs) to support decentralized, verifiable intelligence at the network edge. In addition, we investigate emerging security threats unique to ZTFM-enabled systems and evaluate countermeasures, such as anomaly detection, adversarial training, and secure aggregation. Through this analysis, we highlight key open research challenges in terms of scalability, secure orchestration, interpretable threat attribution, and dynamic trust calibration. This survey lays a foundational roadmap for secure, intelligent, and trustworthy IoT infrastructures powered by FMs.', 'abstract_zh': '基于零信任原则的基金会模型：构建安全可靠的物联网系统的新范式', 'title_zh': '零信任基础模型：物联网安全协作人工智能的新范式'}
{'arxiv_id': 'arXiv:2505.23791', 'title': 'Evaluating Query Efficiency and Accuracy of Transfer Learning-based Model Extraction Attack in Federated Learning', 'authors': 'Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Marc Vucovich, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, Sachin Shetty', 'link': 'https://arxiv.org/abs/2505.23791', 'abstract': "Federated Learning (FL) is a collaborative learning framework designed to protect client data, yet it remains highly vulnerable to Intellectual Property (IP) threats. Model extraction (ME) attacks pose a significant risk to Machine Learning as a Service (MLaaS) platforms, enabling attackers to replicate confidential models by querying black-box (without internal insight) APIs. Despite FL's privacy-preserving goals, its distributed nature makes it particularly susceptible to such attacks. This paper examines the vulnerability of FL-based victim models to two types of model extraction attacks. For various federated clients built under the NVFlare platform, we implemented ME attacks across two deep learning architectures and three image datasets. We evaluate the proposed ME attack performance using various metrics, including accuracy, fidelity, and KL divergence. The experiments show that for different FL clients, the accuracy and fidelity of the extracted model are closely related to the size of the attack query set. Additionally, we explore a transfer learning based approach where pretrained models serve as the starting point for the extraction process. The results indicate that the accuracy and fidelity of the fine-tuned pretrained extraction models are notably higher, particularly with smaller query sets, highlighting potential advantages for attackers.", 'abstract_zh': '联邦学习（FL）是一种旨在保护客户端数据的协作学习框架，但仍高度 Vulnerable 至知识产权（IP）威胁。模型提取（ME）攻击对作为服务的机器学习（MLaaS）平台构成了重大风险，使攻击者能够通过查询黑盒（无内部见解）API 复制保密模型。尽管联邦学习具备隐私保护目标，但其分布式特性使其特别容易遭受此类攻击。本文探讨了基于 FL 的受害模型对两种类型模型提取攻击的脆弱性。我们在 NVFlare 平台上实现了针对两种深度学习架构和三种图像数据集的 ME 攻击。我们使用准确性、保真度和 KL 分散度等多种指标评估提出的 ME 攻击性能。实验表明，对于不同的 FL 客户端，提取模型的准确性和保真度与其攻击查询集的大小密切相关。此外，我们还探索了一种迁移学习方法，其中预训练模型作为提取过程的起点。结果表明，调整后的预训练提取模型的准确性和保真度显著提高，尤其是在查询集较小的情况下，突显了潜在的攻击优势。', 'title_zh': '基于迁移学习的模型提取攻击在联邦学习中查询效率和准确性的评估'}
{'arxiv_id': 'arXiv:2505.23780', 'title': 'More-than-Human Storytelling: Designing Longitudinal Narrative Engagements with Generative AI', 'authors': 'Émilie Fabre, Katie Seaborn, Shuta Koiwai, Mizuki Watanabe, Paul Riesch', 'link': 'https://arxiv.org/abs/2505.23780', 'abstract': 'Longitudinal engagement with generative AI (GenAI) storytelling agents is a timely but less charted domain. We explored multi-generational experiences with "Dreamsmithy," a daily dream-crafting app, where participants (N = 28) co-created stories with AI narrator "Makoto" every day. Reflections and interactions were captured through a two-week diary study. Reflexive thematic analysis revealed themes likes "oscillating ambivalence" and "socio-chronological bonding," highlighting the complex dynamics that emerged between individuals and the AI narrator over time. Findings suggest that while people appreciated the personal notes, opportunities for reflection, and AI creativity, limitations in narrative coherence and control occasionally caused frustration. The results underscore the potential of GenAI for longitudinal storytelling, but also raise critical questions about user agency and ethics. We contribute initial empirical insights and design considerations for developing adaptive, more-than-human storytelling systems.', 'abstract_zh': '长期参与生成式AI讲故事代理的互动是一个及时但未充分探索的领域。我们通过“Dreamsmithy”这一每日梦境创作应用探索了代际经验，参与者（N=28）每日与AI叙述者“Makoto”共同创作故事。通过两周的日记研究记录了反思和互动。反思性主题分析揭示了“波动的矛盾”和“社会时间纽带”等主题，突出了个体与AI叙述者之间随时间演变的复杂动态。研究发现，尽管人们赞赏个人笔记、反思机会和AI的创造力，但叙事连贯性和控制的限制偶尔也会引起挫败感。结果强调了生成式AI在 longitudinal 故事创作中的潜在价值，同时也引发了关于用户自主性和伦理的关键问题。我们提供了初始的实证见解和设计考虑，用于开发适应性和超越人类的故事讲述系统。', 'title_zh': '超越人类的故事讲述：基于生成性人工智能的 longitudinal 故事 Engagement 设计'}
{'arxiv_id': 'arXiv:2505.23770', 'title': 'A comprehensive survey of cybercrimes in India over the last decade', 'authors': 'Sudhanshu Sekhar Tripathy', 'link': 'https://arxiv.org/abs/2505.23770', 'abstract': 'Since the 1990s, the integration of technology into daily life has led to the creation of an extensive network of interconnected devices, transforming how individuals and organizations operate. However, this digital transformation has also spurred the rise of cybercrime, criminal activities perpetrated through networks or computer systems. Cybercrime has become a global concern, presenting significant challenges to security systems. Although advancements in digital technology have enhanced efficiency, they have also opened new avenues for exploitation by cybercriminals, highlighting the urgent need for advanced cybersecurity measures. The escalating number of cyberattacks and associated risks in the past decade highlights the critical importance of protecting sensitive data and safeguarding information systems. Cybercrimes range from financial fraud and phishing scams to identity theft and online harassment, posing substantial risks to both individuals and organizations. In response, governments, law enforcement agencies, and cybersecurity units have intensified their efforts to address these threats. In recent years, India has experienced a significant surge in cybercrime incidents, with a notable increase in cases involving ransomware, data breaches, and social engineering attacks. The growing penetration of internet services, the expansion of e-commerce, and the rapid adoption of digital payment systems have made individuals and organizations more vulnerable to cyber threats. Key areas affected include banking, healthcare, and government sectors, which are frequently targeted due to the sensitive nature of the data they handle. To combat these risks, there is an increasing focus on public awareness, cybersecurity education, and robust regulatory frameworks. This paper examines cybercrime, prevention strategies, security protocols, and terminology to safeguard digital infrastructure.', 'abstract_zh': '自20世纪90年代以来，技术融入日常生活导致了互联设备的广泛网络形成，改变了个人和组织的运作方式。然而，这一数字化转型也促生了网络安全犯罪，即通过网络或计算机系统实施的犯罪行为。网络安全犯罪已成为全球关注的问题，对安全系统提出了重大挑战。尽管数字技术的进步提高了效率，但同时也为网络安全犯罪分子提供了新的exploitation途径，突显了加强网络安全措施的急迫性。近年来，网络攻击案件数量的激增及其相关风险凸显了保护敏感数据和保障信息系统安全的重要性和紧迫性。网络安全犯罪范围从金融欺诈和网络钓鱼到身份盗窃和网络骚扰，对个人和组织均构成了重大风险。对此，政府、执法机构和网络安全单位已加大努力应对这些威胁。近年来，印度的网络安全犯罪事件显著增多，特别是勒索软件、数据泄露和社交工程攻击案例呈上升趋势。互联网服务渗透程度的加深、电子商务的扩展以及数字支付系统的快速采用，使个人和组织更容易受到网络威胁。受影响的关键领域包括银行、医疗保健和政府行业，这些领域由于处理的数据具有敏感性，经常成为目标。为应对这些风险，公众意识提升、网络安全教育和健全的监管框架成为重点。本文探讨了网络安全犯罪、预防策略、安全协议和相关术语，旨在保护数字基础设施。', 'title_zh': '近十年来印度网络犯罪的综合调查'}
