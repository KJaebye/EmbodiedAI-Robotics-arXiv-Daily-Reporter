# Working with AI: Measuring the Occupational Implications of Generative AI 

**Title (ZH)**: 与人工智能共事：生成型人工智能的职业影响测量 

**Authors**: Kiran Tomlinson, Sonia Jaffe, Will Wang, Scott Counts, Siddharth Suri  

**Link**: [PDF](https://arxiv.org/pdf/2507.07935)  

**Abstract**: Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact. 

**Abstract (ZH)**: 给定生成式AI的快速采纳及其对广泛任务的潜在影响，理解AI对经济的影响是社会最重要的问题之一。在这项工作中，我们朝着这个目标迈进了一步，通过分析人们使用AI的工作活动，这些活动的成功度和广度，以及结合职业从事这些活动的数据。我们分析了一个包含20万条匿名化和隐私脱敏的用户与Microsoft Bing Copilot（一个公开可用的生成式AI系统）对话的数据集。我们发现，人们寻求AI帮助最多的日常工作活动主要涉及信息收集和写作，而AI自己执行的最常见活动包括提供信息和帮助、写作、教学和建议。结合这些活动分类与任务成功度和影响范围的测量，我们为每个职业计算了一个AI适用性评分。我们发现，知识工作职业群体，如计算机与数学、办公室和支持性行政工作，以及从事提供和沟通信息工作的职业，其AI适用性评分最高。此外，我们还描述了最成功的日常工作活动类型，工资和教育与AI适用性的关系，以及实际使用情况与对职业AI影响的预测之间的差异。 

---
# Meek Models Shall Inherit the Earth 

**Title (ZH)**: 谦卑的模型将继承地球 

**Authors**: Hans Gundlach, Jayson Lynch, Neil Thompson  

**Link**: [PDF](https://arxiv.org/pdf/2507.07931)  

**Abstract**: The past decade has seen incredible scaling of AI systems by a few companies, leading to inequality in AI model performance. This paper argues that, contrary to prevailing intuition, the diminishing returns to compute scaling will lead to a convergence of AI model capabilities. In other words, meek models (those with limited computation budget) shall inherit the earth, approaching the performance level of the best models overall. We develop a model illustrating that under a fixed-distribution next-token objective, the marginal capability returns to raw compute shrink substantially. Given current scaling practices, we argue that these diminishing returns are strong enough that even companies that can scale their models exponentially faster than other organizations will eventually have little advantage in capabilities. As part of our argument, we give several reasons that proxies like training loss differences capture important capability measures using evidence from benchmark data and theoretical performance models. In addition, we analyze empirical data on the capability difference of AI models over time. Finally, in light of the increasing ability of meek models, we argue that AI strategy and policy require reexamination, and we outline the areas this shift will affect. 

**Abstract (ZH)**: 过去十年，少数公司实现了人工智能系统的惊人扩展，导致了人工智能模型性能上的不平等。本文argues与现有直觉相反，计算扩展的边际回报递减将导致人工智能模型能力的趋同。换句话说，计算预算有限的“弱”模型最终将接近最佳模型的整体性能，占据主导地位。我们建立了一个模型，表明在固定分布的下一个词目标下，基础计算的边际能力回报显著减少。鉴于当前的扩展实践，我们argue这些边际回报的减少是如此之强，以至于即使能够比其他组织的模型扩展速度快得多的公司，最终在能力上也不会有多大优势。作为我们论述的一部分，我们给出了几个理由，说明训练损失差异等代理指标如何利用基准数据和理论性能模型来捕捉重要的能力度量。此外，我们分析了AI模型能力随时间变化的实证数据。最后，考虑到“弱”模型能力的增强，我们argue人工智能战略和政策需要重新审视，并列出了这一转变将影响的领域。 

---
# An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis 

**Title (ZH)**: 面向法律纠纷分析的提示工程与多维知识图谱集成框架 

**Authors**: Mingda Zhang, Na Zhao, Jianglong Qing, Qing xu, Kaiwen Pan, Ting luo  

**Link**: [PDF](https://arxiv.org/pdf/2507.07893)  

**Abstract**: The rapid development of artificial intelligence has positioned large language models as fundamental components of intelligent legal systems. However, these models face significant limitations in legal dispute analysis, including insufficient legal knowledge representation, limited concept understanding, and reasoning deficiencies. This research proposes an enhanced framework integrating prompt engineering with multidimensional knowledge graphs. The framework introduces a three-stage hierarchical prompt structure comprising task definition, knowledge background, and reasoning guidance, supplemented by legal-specific reasoning templates and dynamic optimization mechanisms. A three-layer knowledge graph architecture is constructed with legal classification ontology, representation, and instance layers. Four complementary methods enable precise legal concept retrieval: direct legal norm code matching, domain-specific semantic vector similarity, ontology-based path reasoning, and specialized lexical segmentation. These components integrate with web search technology to establish a knowledge-enhanced framework for legal decision-making. Experimental results demonstrate significant performance improvements in legal dispute analysis, enabling accurate legal application analysis for complex cases while exhibiting nuanced understanding of judicial decision-making logic, providing a novel technical approach for implementing intelligent legal assistance systems. 

**Abstract (ZH)**: 人工智能的迅速发展已将大型语言模型定位为智能法律系统中的基本组件。然而，这些模型在法律纠纷分析中面临诸多局限，包括法律知识表示不足、概念理解有限以及推理缺陷。本研究提出了一种增强框架，结合了提示工程与多维度知识图谱。该框架引入了具有任务定义、知识背景和推理指导三个层级的提示结构，同时包含了专门的法律推理模板和动态优化机制。构建了三层知识图谱架构，包括法律分类本体层、表示层和实例层。四种互补的方法实现了精确的法律概念检索：直接的法律规范代码匹配、领域特定的语义向量相似度、本体路径推理以及专门的词法分段。这些组件与网络搜索技术相结合，建立了一个知识增强的法律决策框架。实验结果表明，在法律纠纷分析方面的性能显著提升，能够对复杂案件进行精确的法律应用分析，并表现出对司法决策逻辑的细腻理解，为实施智能法律辅助系统提供了新的技术途径。 

---
# Searching for actual causes: Approximate algorithms with adjustable precision 

**Title (ZH)**: 寻找实际原因：可调节精度的近似算法 

**Authors**: Samuel Reyd, Ada Diaconescu, Jean-Louis Dessalles  

**Link**: [PDF](https://arxiv.org/pdf/2507.07857)  

**Abstract**: Causality has gained popularity in recent years. It has helped improve the performance, reliability, and interpretability of machine learning models. However, recent literature on explainable artificial intelligence (XAI) has faced criticism. The classical XAI and causality literature focuses on understanding which factors contribute to which consequences. While such knowledge is valuable for researchers and engineers, it is not what non-expert users expect as explanations. Instead, these users often await facts that cause the target consequences, i.e., actual causes. Formalizing this notion is still an open problem. Additionally, identifying actual causes is reportedly an NP-complete problem, and there are too few practical solutions to approximate formal definitions. We propose a set of algorithms to identify actual causes with a polynomial complexity and an adjustable level of precision and exhaustiveness. Our experiments indicate that the algorithms (1) identify causes for different categories of systems that are not handled by existing approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be adjusted to gain more precision and exhaustiveness with more computation time. 

**Abstract (ZH)**: 因果关系在近年来受到了广泛关注。它有助于提高机器学习模型的性能、可靠性和可解释性。然而，解释型人工智能（XAI）的近期文献受到了批评。经典XAI和因果关系文献侧重于理解哪些因素导致了哪些后果。虽然此类知识对于研究人员和工程师非常重要，但非专家用户期望的解释并非如此。相反，这些用户通常期待导致目标后果的事实，即实际原因。正式化这一概念仍然是一个开放问题。此外，识别实际原因据说是NP完全问题，目前可供实用的近似正式定义的解决方案寥寥无几。我们提出了一组算法，可以在多项式时间内识别实际原因，并调整精度和详尽程度。实验表明，这些算法（1）可以识别现有方法无法处理的不同类别系统（即非布尔型、黑盒和随机系统）的原因，（2）可以通过增加计算时间来提高精度和详尽程度。 

---
# AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift 

**Title (ZH)**: AI 应该更智能地感知，而不仅仅是规模扩大：自适应感知作为一种范式转变 

**Authors**: Eunsu Baek, Keondo Park, Jeonggil Ko, Min-hwan Oh, Taesik Gong, Hyung-Sin Kim  

**Link**: [PDF](https://arxiv.org/pdf/2507.07820)  

**Abstract**: Current AI advances largely rely on scaling neural models and expanding training datasets to achieve generalization and robustness. Despite notable successes, this paradigm incurs significant environmental, economic, and ethical costs, limiting sustainability and equitable access. Inspired by biological sensory systems, where adaptation occurs dynamically at the input (e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive sensing as a necessary and foundational shift. Adaptive sensing proactively modulates sensor parameters (e.g., exposure, sensitivity, multimodal configurations) at the input level, significantly mitigating covariate shifts and improving efficiency. Empirical evidence from recent studies demonstrates that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass substantially larger models (e.g., OpenCLIP-H) trained with significantly more data and compute. We (i) outline a roadmap for broadly integrating adaptive sensing into real-world applications spanning humanoid, healthcare, autonomous systems, agriculture, and environmental monitoring, (ii) critically assess technical and ethical integration challenges, and (iii) propose targeted research directions, such as standardized benchmarks, real-time adaptive algorithms, multimodal integration, and privacy-preserving methods. Collectively, these efforts aim to transition the AI community toward sustainable, robust, and equitable artificial intelligence systems. 

**Abstract (ZH)**: 当前的人工智能进展主要依赖于扩大神经模型规模和扩大训练数据集以实现泛化和鲁棒性。尽管取得了显著的成功，但这种范式产生了重大的环境、经济和伦理成本，限制了可持续性和公平的访问。受生物感觉系统的启发，在输入端动态发生适应（例如，调整瞳孔大小，调节焦距）——我们提倡将适应性感知作为必要的基础性转变。适应性感知在输入端主动调节传感器参数（例如，曝光、灵敏度、多模态配置），显著缓解了 covariate 偏移并提高了效率。最近的研究表明，适应性感知使小型模型（例如，EfficientNet-B0）能够在大大较少的数据和计算资源下超过大规模模型（例如，OpenCLIP-H）。我们将（i）概述将适应性感知广泛整合到类人、医疗保健、自主系统、农业和环境监测等实际应用中的 roadmap，（ii）批判性评估技术与伦理整合的挑战，并（iii）提出有针对性的研究方向，例如标准化基准、实时适应算法、多模态整合和隐私保护方法。这些努力共同旨在使人工智能社区向可持续的、稳健的和公平的人工智能系统转变。 

---
# MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving 

**Title (ZH)**: MoSE：自主驾驶中的技能级专家混合学习 

**Authors**: Lu Xu, Jiaqian Yu, Xiongfeng Peng, Yiwei Chen, Weiming Li, Jaewook Yoo, Sunghyun Chunag, Dongwook Lee, Daehyun Ji, Chao Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.07818)  

**Abstract**: Recent studies show large language models (LLMs) and vision language models (VLMs) trained using web-scale data can empower end-to-end autonomous driving systems for a better generalization and interpretation. Specifically, by dynamically routing inputs to specialized subsets of parameters, the Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve substantial performance improvements while maintaining computational efficiency. However, general MoE models usually demands extensive training data and complex optimization. In this work, inspired by the learning process of human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human drivers' learning process and reasoning process, skill-by-skill and step-by-step. We propose a skill-oriented routing mechanism that begins with defining and annotating specific skills, enabling experts to identify the necessary driving competencies for various scenarios and reasoning tasks, thereby facilitating skill-by-skill learning. Further align the driving process to multi-step planning in human reasoning and end-to-end driving models, we build a hierarchical skill dataset and pretrain the router to encourage the model to think step-by-step. Unlike multi-round dialogs, MoSE integrates valuable auxiliary tasks (e.g.\ description, reasoning, planning) in one single forward process without introducing any extra computational cost. With less than 3B sparsely activated parameters, our model outperforms several 8B+ parameters on CODA AD corner case reasoning task. Compared to existing methods based on open-source models and data, our approach achieves state-of-the-art performance with significantly reduced activated model size (at least by $62.5\%$) with a single-turn conversation. 

**Abstract (ZH)**: Recent Studies Show Large Language Models and Vision Language Models Trained with Web-Scale Data Can Empower End-to-End Autonomous Driving Systems for Better Generalization and Interpretation 

---
# Measuring AI Alignment with Human Flourishing 

**Title (ZH)**: 测量AI对人类 flourishing 的 Alignment 

**Authors**: Elizabeth Hilliard, Akshaya Jagadeesh, Alex Cook, Steele Billings, Nicholas Skytland, Alicia Llewellyn, Jackson Paull, Nathan Paull, Nolan Kurylo, Keatra Nesbitt, Robert Gruenewald, Anthony Jantzi, Omar Chavez  

**Link**: [PDF](https://arxiv.org/pdf/2507.07787)  

**Abstract**: This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72/100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation. 

**Abstract (ZH)**: Flourishing AI基准（FAI基准）：一种评估AI与人类繁荣一致性的新框架 

---
# Identification of Violin Reduction via Contour Lines Classification 

**Title (ZH)**: 小提琴 reducium 识别 via 岸线分类 

**Authors**: Philémon Beghin, Anne-Emmanuelle Ceulemans, François Glineur  

**Link**: [PDF](https://arxiv.org/pdf/2507.07743)  

**Abstract**: The first violins appeared in late 16th-century Italy. Over the next 200 years, they spread across Europe and luthiers of various royal courts, eager to experiment with new techniques, created a highly diverse family of instruments. Around 1750, size standards were introduced to unify violin making for orchestras and conservatories. Instruments that fell between two standards were then reduced to a smaller size by luthiers. These reductions have an impact on several characteristics of violins, in particular on the contour lines, i.e. lines of constant altitude, which look more like a U for non reduced instruments and a V for reduced ones. While such differences are observed by experts, they have not been studied quantitatively.
This paper presents a method for classifying violins as reduced or non-reduced based on their contour lines. We study a corpus of 25 instruments whose 3D geometric meshes were acquired via photogrammetry. For each instrument, we extract 10-20 contour lines regularly spaced every millimetre. Each line is fitted with a parabola-like curve (with an equation of the type y = alpha*abs(x)**beta) depending on two parameters, describing how open (beta) and how vertically stretched (alpha) the curve is. We compute additional features from those parameters, using regressions and counting how many values fall under some threshold. We also deal with outliers and non equal numbers of levels, and eventually obtain a numerical profile for each instrument.
We then apply classification methods to assess whether geometry alone can predict size reduction. We find that distinguishing between reduced and non reduced instruments is feasible to some degree, taking into account that a whole spectrum of more or less transformed violins exists, for which it is more difficult to quantify the reduction. We also find the opening parameter beta to be the most predictive. 

**Abstract (ZH)**: 16世纪晚期意大利首次出现小提琴。在接下来的200年中，小提琴传播至欧洲各地，各个王室宫廷的制琴师渴望尝试新的技术，由此创造出一系列多样化的乐器。约在1750年，尺寸标准被引入以统一管弦乐团和音乐学院中的小提琴制作。尺寸介于两个标准之间的乐器随后被制琴师缩减至更小的尺寸。这种缩减对小提琴的多个特征产生了影响，特别是对等高线，即常高度线，非缩减乐器的等高线呈现U形而缩减乐器的则呈现V形。虽然专家们观察到了这些差异，但尚未对其进行定量研究。

本文提出了一种方法，根据等高线对小提琴进行分类，将其分为缩减和非缩减两类。我们研究了一组25件乐器，使用摄影测量法获取其3D几何网格。对于每件乐器，我们提取了每隔毫米均匀分布的10-20条等高线。每条线都用类似抛物线的曲线拟合（方程形式为y = alpha*abs(x)**beta），该曲线由两个参数描述，这些参数分别表示曲线的开放程度（beta）和竖直拉伸程度（alpha）。我们从这些参数中计算出额外的特征，利用回归分析并统计有多少值低于某个阈值。我们还处理了离群值和不同数量层级的问题，最终为每件乐器获得了一个数字特征轮廓。

随后，我们应用分类方法来评估几何形状是否足以预测尺寸缩减。我们发现，在考虑存在不同程度变形的小提琴存在整个连续体的情况下，区分缩减和非缩减小提琴在一定程度上是可行的。我们还发现开放参数beta是最重要的预测因素。 

---
# Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization 

**Title (ZH)**: 基于双层优化的LLMs稳定偏好优化：超越直接偏好优化 

**Authors**: Chengtao Jian, Kai Yang, Ye Ouyang, Xiaozhou Ye  

**Link**: [PDF](https://arxiv.org/pdf/2507.07723)  

**Abstract**: Direct Preference Optimization (DPO) has emerged as a popular and efficient alternative to reward modeling and reinforcement learning for aligning language models with human preferences. Despite its empirical success, the theoretical properties and intrinsic limitations of DPO remain underexplored. In this work, we first present a comprehensive analysis of DPO's dynamics from a probability evolution perspective. Our analysis reveals that DPO is highly sensitive to initialization. It also tends to misallocate probability mass, which can inadvertently shift probability toward irrelevant or undesired responses. This misallocation may unintentionally reinforce model bias, thereby compromising both the stability of model alignment and the consistency with intended preferences. Motivated by these theoretical findings, we propose a theoretically grounded bilevel optimization framework that tightly integrate supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference optimization. Our approach introduces a principled regularization scheme to explicitly encourage absolute probability improvement for preferred outputs, while maintaining stable optimization dynamics. Experiments on challenging reasoning and summarization benchmarks elucidate that our method consistently improves reasoning accuracy and better aligns output distributions with intended preferences, outperforming standard DPO. Stable preference optimization provides new insights into the design of preference-based alignment objectives and opens up new avenues towards more reliable and interpretable language model alignment. 

**Abstract (ZH)**: 直接偏好优化（DPO）已成为一种流行而高效的替代奖励建模和强化学习的方法，用于使语言模型与人类偏好保持一致。尽管从实证上取得了成功，但DPO的理论属性和内在限制仍需进一步探索。在本文中，我们首先从概率演化的角度对DPO的动力学进行了全面分析。我们的分析表明，DPO对初始条件非常敏感，且倾向于错误分配概率质量，这可能会无意中将概率偏向无关或不希望的响应。这种错误分配可能导致模型偏见的无意强化，从而损害模型一致性和预期偏好。受这些理论发现的启发，我们提出了一种基于理论的双层优化框架，将监督微调与增强的DPO目标（即稳定偏好优化）紧密结合。该方法引入了一种原则性的正则化方案，明确鼓励优先输出的绝对概率改进，同时保持稳定的优化动态。在具有挑战性的推理和摘要基准测试上的实验表明，我们的方法在推理准确性和输出分布与预期偏好的一致性方面均优于标准DPO。稳定偏好优化为偏好驱动的对齐目标设计提供了新的见解，并开启了更可靠和可解释的语言模型对齐的新途径。 

---
# PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations 

**Title (ZH)**: PlanQA: 一个基于结构化表示的LLMs空间推理基准测试 

**Authors**: Fedor Rodionov, Abdelrahman Eldesokey, Michael Birsak, John Femiani, Bernard Ghanem, Peter Wonka  

**Link**: [PDF](https://arxiv.org/pdf/2507.07644)  

**Abstract**: We introduce PlanQA, a diagnostic benchmark for evaluating geometric and spatial reasoning in large-language models (LLMs). PlanQA is grounded in structured representations of indoor scenes, such as kitchens, living rooms, and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The benchmark includes diverse question types that test not only metric and topological reasoning (e.g., distance, visibility, shortest paths) but also interior design constraints such as affordance, clearance, balance, and usability. Our results across a variety of frontier open-source and commercial LLMs show that while models may succeed in shallow queries, they often fail to simulate physical constraints, preserve spatial coherence, or generalize under layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they do not consistently reason about real-world layouts. We hope that this benchmark inspires new work on language models that can accurately infer and manipulate spatial and geometric properties in practical settings. 

**Abstract (ZH)**: PlanQA：一个评估大型语言模型几何与空间推理能力的诊断基准 

---
# Towards conservative inference in credal networks using belief functions: the case of credal chains 

**Title (ZH)**: 基于信念函数在信度网络中实现保守推理：信度链的情形 

**Authors**: Marco Sangalli, Thomas Krak, Cassio de Campos  

**Link**: [PDF](https://arxiv.org/pdf/2507.07619)  

**Abstract**: This paper explores belief inference in credal networks using Dempster-Shafer theory. By building on previous work, we propose a novel framework for propagating uncertainty through a subclass of credal networks, namely chains. The proposed approach efficiently yields conservative intervals through belief and plausibility functions, combining computational speed with robust uncertainty representation. Key contributions include formalizing belief-based inference methods and comparing belief-based inference against classical sensitivity analysis. Numerical results highlight the advantages and limitations of applying belief inference within this framework, providing insights into its practical utility for chains and for credal networks in general. 

**Abstract (ZH)**: 本文利用Dempster-Shafer理论探讨信度网络中的信念推断，在前人研究的基础上，我们提出了一种新颖的框架，用于传播一类信度网络（即链）中的不确定性。该方法通过信念和可信任度函数高效地得出保守区间，结合了计算速度和稳健的不确定性表示。主要贡献包括正式化基于信念的推断方法，并将基于信念的推断与经典敏感性分析进行比较。数值结果突出了在此框架中应用信念推断的优点和局限性，为链和一般信度网络的实际应用提供了见解。 

---
# Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models 

**Title (ZH)**: 增强疫苗安全性监控：使用细调大语言模型从急诊科分诊笔记中提取疫苗提及内容 

**Authors**: Sedigh Khademi, Jim Black, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila  

**Link**: [PDF](https://arxiv.org/pdf/2507.07599)  

**Abstract**: This study evaluates fine-tuned Llama 3.2 models for extracting vaccine-related information from emergency department triage notes to support near real-time vaccine safety surveillance. Prompt engineering was used to initially create a labeled dataset, which was then confirmed by human annotators. The performance of prompt-engineered models, fine-tuned models, and a rule-based approach was compared. The fine-tuned Llama 3 billion parameter model outperformed other models in its accuracy of extracting vaccine names. Model quantization enabled efficient deployment in resource-constrained environments. Findings demonstrate the potential of large language models in automating data extraction from emergency department notes, supporting efficient vaccine safety surveillance and early detection of emerging adverse events following immunization issues. 

**Abstract (ZH)**: 本研究评估了微调的Llama 3.2模型从急诊部门分诊笔记中提取疫苗相关信息以支持近实时疫苗安全性监测的能力。通过指令工程技术创建了标注数据集，并由人工注释员确认。比较了指令工程模型、微调模型和基于规则的方法的性能。微调的Llama 3 billion参数模型在提取疫苗名称的准确性上优于其他模型。模型量化使该模型能够在资源受限的环境中进行高效部署。研究结果表明，大规模语言模型在自动化急诊部门笔记数据提取、支持高效疫苗安全性监测以及早期检测疫苗接种后新兴不良事件方面的潜力。 

---
# Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs 

**Title (ZH)**: 上下文聚池化：针对通用归纳链接预测的图聚池化方法 

**Authors**: Zhixiang Su, Di Wang, Chunyan Miao  

**Link**: [PDF](https://arxiv.org/pdf/2507.07595)  

**Abstract**: Recent investigations on the effectiveness of Graph Neural Network (GNN)-based models for link prediction in Knowledge Graphs (KGs) show that vanilla aggregation does not significantly impact the model performance. In this paper, we introduce a novel method, named Context Pooling, to enhance GNN-based models' efficacy for link predictions in KGs. To our best of knowledge, Context Pooling is the first methodology that applies graph pooling in KGs. Additionally, Context Pooling is first-of-its-kind to enable the generation of query-specific graphs for inductive settings, where testing entities are unseen during training. Specifically, we devise two metrics, namely neighborhood precision and neighborhood recall, to assess the neighbors' logical relevance regarding the given queries, thereby enabling the subsequent comprehensive identification of only the logically relevant neighbors for link prediction. Our method is generic and assessed by being applied to two state-of-the-art (SOTA) models on three public transductive and inductive datasets, achieving SOTA performance in 42 out of 48 settings. 

**Abstract (ZH)**: 基于图神经网络的链接预测在知识图谱中的最新研究显示， vanilla聚合对模型性能影响不大。本文提出了一种新颖的方法——上下文池化，以增强基于图神经网络的模型在知识图谱中的链接预测效果。到我们所知，上下文池化是首次在知识图谱中应用图池化的办法。此外，上下文池化是首个在归纳设置中生成查询特定图的方法，使得在训练中未见过的测试实体能够进行预测。具体地，我们设计了两个指标，即邻域精确度和邻域召回率，以评估邻域在给定查询下的逻辑相关性，从而实现仅识别对于链接预测逻辑相关的邻域的综合判定。该方法具有通用性，并通过在三个公开的归纳和传递数据集上应用两种最先进的模型进行评估，在48种设置中42种达到了最先进的性能。 

---
# On Trustworthy Rule-Based Models and Explanations 

**Title (ZH)**: 基于规则的模型及其解释的可靠性研究 

**Authors**: Mohamed Siala, Jordi Planes, Joao Marques-Silva  

**Link**: [PDF](https://arxiv.org/pdf/2507.07576)  

**Abstract**: A task of interest in machine learning (ML) is that of ascribing explanations to the predictions made by ML models. Furthermore, in domains deemed high risk, the rigor of explanations is paramount. Indeed, incorrect explanations can and will mislead human decision makers. As a result, and even if interpretability is acknowledged as an elusive concept, so-called interpretable models are employed ubiquitously in high-risk uses of ML and data mining (DM). This is the case for rule-based ML models, which encompass decision trees, diagrams, sets and lists. This paper relates explanations with well-known undesired facets of rule-based ML models, which include negative overlap and several forms of redundancy. The paper develops algorithms for the analysis of these undesired facets of rule-based systems, and concludes that well-known and widely used tools for learning rule-based ML models will induce rule sets that exhibit one or more negative facets. 

**Abstract (ZH)**: 机器学习领域的一个研究任务是为机器学习模型的预测提供解释。在高风险领域中，这些解释的严谨性至关重要。事实上，不正确的解释可能会误导人类决策者。因此，即便可解释性被认为是难以捉摸的概念，所谓可解释的模型在高风险的机器学习和数据挖掘应用中依然被广泛应用。这类模型包括基于规则的模型，如决策树、图表、集合和列表。本文将解释与基于规则的模型广为人知的负面特征相关联，这些负面特征包括负面重叠和多种形式的冗余。本文开发了分析这些负面特征的算法，并得出结论，广泛使用的学习基于规则的机器学习模型的工具将导致表现出一种或多种负面特征的规则集。 

---
# Position: We Need An Algorithmic Understanding of Generative AI 

**Title (ZH)**: 位置：我们需要对生成式AI进行算法理解。 

**Authors**: Oliver Eberle, Thomas McGee, Hamza Giaffar, Taylor Webb, Ida Momennejad  

**Link**: [PDF](https://arxiv.org/pdf/2507.07544)  

**Abstract**: What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems. 

**Abstract (ZH)**: LLMs实际上学习和使用的算法是什么？：关于这一问题的研究较为稀少，因为研究重点在于通过扩展规模来提升性能，留下了一个理论和实证上的缺口。本文提出了AlgEval框架，旨在系统性地研究LLMs学习和使用的算法。AlgEval旨在揭示反映在潜在表示、注意力和推理时计算中的算法基本元素及其算法组成，以解决特定任务问题。我们提出了潜在方法论路径和针对这一目标的案例研究，重点关注新兴搜索算法。我们的案例研究既展示了自上而下的候选算法假设形式化，也通过注意力模式和隐藏状态的电路级分析自下而上地测试这些假设。对LLMs实际解决问题的严格、系统的评估提供了一种替代密集型扩展资源的方法，使研究领域重新定向至对基本计算原理的原理性理解。这样的算法解释提供了通往可理解可解释性的途径，使理解模型内部推理成为可能。这反过来可以促进更高效的训练方法和性能改进，以及端到端和多智能体系统的新型架构。 

---
# StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley 

**Title (ZH)**: StarDojo: 在 Stardew Valley 生存模拟中评估代理多模态大语言模型的开放-ended 行为 

**Authors**: Weihao Tan, Changjiu Jiang, Yu Duan, Mingcong Lei, Jiageng Li, Yitian Hong, Xinrun Wang, Bo An  

**Link**: [PDF](https://arxiv.org/pdf/2507.07445)  

**Abstract**: Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments. 

**Abstract (ZH)**: 自主导航人类社会的智能代理必须掌握生产活动和社会交往技能，而现有基准很少同时评估这些技能。为弥补这一差距，我们提出StarDojo，一个基于Stardew Valley的新颖基准，旨在评估AI代理在开放式的生产生活模拟中的能力。在StarDojo中，代理被指派执行如耕作和制作等基本生活活动，同时参与社交互动以在充满活力的社区中建立关系。StarDojo包含跨五大关键领域的1000个精心筛选的任务：耕作、制作、探索、战斗和社会交往。此外，我们还提供一个包含100个代表性任务的紧凑子集，以便高效地评估模型。该基准提供了一个统一且用户友好的界面，无需键盘和鼠标控制，支持所有主要操作系统，并允许多个环境实例并行执行，使其特别适用于评估由多模态大规模语言模型（MLLMs）驱动的最强大基础代理。对最先进的MLLMs代理的广泛评估表明，性能最佳的模型GPT-4.1的成功率仅为12.7%，主要原因是视觉理解、多模态推理和低级操作的挑战。作为一个用户友好的环境和基准，StarDojo旨在促进对在复杂生产生活环境中稳健、开放性代理的研究。 

---
# DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search 

**Title (ZH)**: DrugMCTS：一种结合多智能体、RAG和蒙特卡洛树搜索的药物再利用框架 

**Authors**: Zerui Yang, Yuwei Wan, Yinqiao Li, Yudai Matsuda, Tong Xie, Linqi Song  

**Link**: [PDF](https://arxiv.org/pdf/2507.07426)  

**Abstract**: Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery. 

**Abstract (ZH)**: 最近大型语言模型在药物发现等科学领域的进展展示了巨大潜力，但其有效性在超出预训练知识的推理时仍受到限制。传统方法如微调或检索增强生成面临高计算开销或未能充分利用结构化科学数据的局限。为克服这些挑战，我们提出DrugMCTS，这是一种结合了检索增强生成(RAG)、多代理协作和蒙特卡罗树搜索的新框架，用于药物重新利用。该框架通过五个专门代理执行分子和蛋白质信息的检索与分析，从而实现结构化和迭代推理。无需特定领域的微调，DrugMCTS使Qwen2.5-7B-Instruct相比Deepseek-R1性能提高了超过20%。在DrugBank和KIBA数据集上的广泛实验表明，DrugMCTS在召回率和鲁棒性方面显著优于通用语言模型和深度学习基线。我们的结果强调了结构化推理、基于代理的协作和反馈驱动的搜索机制在推进药物发现领域的大语言模型应用中的重要性。 

---
# Supply Chain Optimization via Generative Simulation and Iterative Decision Policies 

**Title (ZH)**: 通过生成式仿真与迭代决策策略的供应链优化 

**Authors**: Haoyue Bai, Haoyu Wang, Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haifeng Chen, Yanjie Fu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07355)  

**Abstract**: High responsiveness and economic efficiency are critical objectives in supply chain transportation, both of which are influenced by strategic decisions on shipping mode. An integrated framework combining an efficient simulator with an intelligent decision-making algorithm can provide an observable, low-risk environment for transportation strategy design. An ideal simulation-decision framework must (1) generalize effectively across various settings, (2) reflect fine-grained transportation dynamics, (3) integrate historical experience with predictive insights, and (4) maintain tight integration between simulation feedback and policy refinement. We propose Sim-to-Dec framework to satisfy these requirements. Specifically, Sim-to-Dec consists of a generative simulation module, which leverages autoregressive modeling to simulate continuous state changes, reducing dependence on handcrafted domain-specific rules and enhancing robustness against data fluctuations; and a history-future dual-aware decision model, refined iteratively through end-to-end optimization with simulator interactions. Extensive experiments conducted on three real-world datasets demonstrate that Sim-to-Dec significantly improves timely delivery rates and profit. 

**Abstract (ZH)**: 高响应性和经济效率是供应链运输中的关键目标，两者都受运输模式战略决策的影响。一个综合框架结合高效的模拟器与智能决策算法，可以为运输策略设计提供一个可观测且风险较低的环境。理想的仿真-决策框架必须（1）在各种环境中有效泛化，（2）反映精细的运输动态，（3）整合历史经验与预测洞察，（4）保持仿真反馈与政策改进的高度集成。我们提出了Sim-to-Dec框架以满足这些要求。具体而言，Sim-to-Dec 包括一个生成性模拟模块，该模块利用自回归建模来模拟连续状态的变化，减少对手工定制的领域特定规则的依赖，增强对数据波动的鲁棒性；以及一个知过往晓未来的双重意识决策模型，该模型通过端到端优化并与模拟器交互进行迭代 refinement。在三个真实世界数据集上的广泛实验表明，Sim-to-Dec 显著提高了及时交货率和利润。 

---
# On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment 

**Title (ZH)**: 将智能与判断分离的不可能性：AI对齐中过滤的计算不可行性 

**Authors**: Sarah Ball, Greg Gluch, Shafi Goldwasser, Frauke Kreuter, Omer Reingold, Guy N. Rothblum  

**Link**: [PDF](https://arxiv.org/pdf/2507.07341)  

**Abstract**: With the increased deployment of large language models (LLMs), one concern is their potential misuse for generating harmful content. Our work studies the alignment challenge, with a focus on filters to prevent the generation of unsafe information. Two natural points of intervention are the filtering of the input prompt before it reaches the model, and filtering the output after generation. Our main results demonstrate computational challenges in filtering both prompts and outputs. First, we show that there exist LLMs for which there are no efficient prompt filters: adversarial prompts that elicit harmful behavior can be easily constructed, which are computationally indistinguishable from benign prompts for any efficient filter. Our second main result identifies a natural setting in which output filtering is computationally intractable. All of our separation results are under cryptographic hardness assumptions. In addition to these core findings, we also formalize and study relaxed mitigation approaches, demonstrating further computational barriers. We conclude that safety cannot be achieved by designing filters external to the LLM internals (architecture and weights); in particular, black-box access to the LLM will not suffice. Based on our technical results, we argue that an aligned AI system's intelligence cannot be separated from its judgment. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）部署的增加，一个关注点是它们可能被滥用以生成有害内容。我们的研究探讨了对齐挑战，重点关注防止生成不安全信息的过滤器。两个自然的干预点是在模型接收到输入提示之前过滤提示，以及在生成之后过滤输出。我们的主要结果展示了过滤提示和输出所面临的计算挑战。首先，我们展示了存在对于高效提示过滤器来说无法有效过滤的LLM：可以构建对抗性提示，其会引发有害行为，并且对任何高效的过滤器来说，这些对抗性提示与良性提示在计算上无法区分。我们的第二个主要结果指出，在一个自然设置中，输出过滤是计算上不可行的。所有我们的分离结果假设了密码学硬度假设。除了这些核心发现之外，我们还形式化并研究了缓解措施的放松方法，进一步展示了计算障碍。我们得出结论，通过设计外部于LLM内部结构（架构和权重）的过滤器无法实现安全性；特别是，对LLM的黑盒访问不足以解决问题。基于我们的技术结果，我们认为对齐的人工智能系统的智能不能与其判断分离。 

---
# ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning 

**Title (ZH)**: ViDove：一种基于多模态上下文和记忆增强推理的翻译代理系统 

**Authors**: Yichen Lu, Wei Dai, Jiaen Liu, Ching Wing Kwok, Zongheng Wu, Xudong Xiao, Ao Sun, Sheng Fu, Jianyuan Zhan, Yian Wang, Takatomo Saito, Sicheng Lai  

**Link**: [PDF](https://arxiv.org/pdf/2507.07306)  

**Abstract**: LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: this https URL 

**Abstract (ZH)**: 基于LLM的多模态翻译代理已经实现了高度人性化的翻译效果，并且能够更高效地处理更长和更复杂的上下文。然而，它们通常限于只处理文本输入。本文介绍了ViDove，一个设计用于处理多模态输入的翻译代理系统。受人类翻译工作流程的启发，ViDove利用视觉和上下文背景信息来增强翻译过程。此外，我们集成了一个多模态记忆系统和包含领域特定知识的长短时记忆模块，使代理能够在实际场景中更加准确和适应性地工作。因此，ViDove在字幕生成和通用翻译任务中的翻译质量显著提高，BLEU分数提高了28%，SubER提高了15%，优于以往的最先进的基线。此外，我们还引入了DoveBench，一个新的长视频字幕和自动翻译基准，包含17小时高质量的人工标注数据。我们的代码可在以下链接获取：this https URL。 

---
# Application of LLMs to Multi-Robot Path Planning and Task Allocation 

**Title (ZH)**: LLMs在多机器人路径规划与任务分配中的应用 

**Authors**: Ashish Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2507.07302)  

**Abstract**: Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents. 

**Abstract (ZH)**: 高效探索是深度强化学习中一个已知的问题，在多智能体强化学习中由于这类算法固有的复杂性，这一问题更为突出。本工作研究了使用大规模语言模型作为专家规划者进行多智能体基于规划任务的高效探索的方法。 

---
# Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery 

**Title (ZH)**: 基于语言代理的开源规划与控制系统及其在自主科学研究中的应用 

**Authors**: Licong Xu, Milind Sarkar, Anto I. Lonappan, Íñigo Zubeldia, Pablo Villanueva-Domingo, Santiago Casas, Christian Fidler, Chetana Amancharla, Ujjwal Tiwari, Adrian Bayer, Chadi Ait Ekiou, Miles Cranmer, Adrian Dimitrov, James Fergusson, Kahaan Gandhi, Sven Krippendorf, Andrew Laverick, Julien Lesgourgues, Antony Lewis, Thomas Meier, Blake Sherwin, Kristen Surrao, Francisco Villaescusa-Navarro, Chi Wang, Xueqing Xu, Boris Bolliet  

**Link**: [PDF](https://arxiv.org/pdf/2507.07257)  

**Abstract**: We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud. 

**Abstract (ZH)**: 一种自动化科学研究任务的多智能体系统：cmbagent 

---
# Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains 

**Title (ZH)**: 神经符号特征提取在供应链中识别强制劳动的应用 

**Authors**: Zili Wang, Frank Montabon, Kristin Yvonne Rozier  

**Link**: [PDF](https://arxiv.org/pdf/2507.07217)  

**Abstract**: Supply chain networks are complex systems that are challenging to analyze; this problem is exacerbated when there are illicit activities involved in the supply chain, such as counterfeit parts, forced labor, or human trafficking. While machine learning (ML) can find patterns in complex systems like supply chains, traditional ML techniques require large training data sets. However, illicit supply chains are characterized by very sparse data, and the data that is available is often (purposely) corrupted or unreliable in order to hide the nature of the activities. We need to be able to automatically detect new patterns that correlate with such illegal activity over complex, even temporal data, without requiring large training data sets. We explore neurosymbolic methods for identifying instances of illicit activity in supply chains and compare the effectiveness of manual and automated feature extraction from news articles accurately describing illicit activities uncovered by authorities. We propose a question tree approach for querying a large language model (LLM) to identify and quantify the relevance of articles. This enables a systematic evaluation of the differences between human and machine classification of news articles related to forced labor in supply chains. 

**Abstract (ZH)**: 供应链网络是复杂系统，分析起来颇具挑战性；当供应链中涉及非法活动，如假冒零件、强迫劳动或人口贩卖时，这一问题会进一步加剧。尽管机器学习可以发现复杂系统如供应链中的模式，但传统的机器学习技术需要大量的训练数据集。然而，非法供应链的特点是数据非常稀疏，可获得的数据往往（故意）被篡改或不可靠，以掩盖其活动的本质。我们需要能够自动检测与非法活动相关的新型模式，即使在复杂甚至时空性数据的情况下，也不需要大量训练数据集。我们探讨了使用神经符号方法识别供应链中非法活动实例，并对比了人工和自动提取自述非法活动新闻文章特征的有效性。我们提出了一种问题树方法，用于查询大规模语言模型以识别和量化文章的相关性。这使得我们可以系统地评估人类和机器对与供应链中强迫劳动相关的新闻文章分类之间的差异。 

---
# State-Inference-Based Prompting for Natural Language Trading with Game NPCs 

**Title (ZH)**: 基于状态推理的提示方法在与游戏NPC进行自然语言交易中的应用 

**Authors**: Minkyung Kim, Junsik Kim, Hwidong Bae, Woongcheol Yang, Sangdon Park, Sohee Bae  

**Link**: [PDF](https://arxiv.org/pdf/2507.07203)  

**Abstract**: Large Language Models enable dynamic game interactions but struggle with rule-governed trading systems. Current implementations suffer from rule violations, such as item hallucinations and calculation errors, that erode player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable trading through autonomous dialogue state inference and context-specific rule adherence. The approach decomposes trading into six states within a unified prompt framework, implementing context-aware item referencing and placeholder-based price calculations. Evaluation across 100 trading dialogues demonstrates >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision. SIBP maintains computational efficiency while outperforming baseline approaches, establishing a practical foundation for trustworthy NPC interactions in commercial games. 

**Abstract (ZH)**: 基于状态推断的提示方法（SIBP）实现可靠的交易对话状态推理和情境特定规则遵从，促进动态游戏交互但挑战规则 govern 的交易系统。 

---
# BOOST: Out-of-Distribution-Informed Adaptive Sampling for Bias Mitigation in Stylistic Convolutional Neural Networks 

**Title (ZH)**: BOOST：基于分布外信息的自适应采样以减轻风格卷积神经网络中的偏差 

**Authors**: Mridula Vijendran, Shuang Chen, Jingjing Deng, Hubert P. H. Shum  

**Link**: [PDF](https://arxiv.org/pdf/2507.07134)  

**Abstract**: The pervasive issue of bias in AI presents a significant challenge to painting classification, and is getting more serious as these systems become increasingly integrated into tasks like art curation and restoration. Biases, often arising from imbalanced datasets where certain artistic styles dominate, compromise the fairness and accuracy of model predictions, i.e., classifiers are less accurate on rarely seen paintings. While prior research has made strides in improving classification performance, it has largely overlooked the critical need to address these underlying biases, that is, when dealing with out-of-distribution (OOD) data. Our insight highlights the necessity of a more robust approach to bias mitigation in AI models for art classification on biased training data. We propose a novel OOD-informed model bias adaptive sampling method called BOOST (Bias-Oriented OOD Sampling and Tuning). It addresses these challenges by dynamically adjusting temperature scaling and sampling probabilities, thereby promoting a more equitable representation of all classes. We evaluate our proposed approach to the KaoKore and PACS datasets, focusing on the model's ability to reduce class-wise bias. We further propose a new metric, Same-Dataset OOD Detection Score (SODC), designed to assess class-wise separation and per-class bias reduction. Our method demonstrates the ability to balance high performance with fairness, making it a robust solution for unbiasing AI models in the art domain. 

**Abstract (ZH)**: 面向艺术分类的偏差数据泛化适应采样方法：BOOST（面向偏差的OOD采样与调优） 

---
# Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation 

**Title (ZH)**: 基于LLMs的自主控制：下一代工业自动化中的代理框架 

**Authors**: Javal Vyas, Mehmet Mercangoz  

**Link**: [PDF](https://arxiv.org/pdf/2507.07115)  

**Abstract**: The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering. 

**Abstract (ZH)**: 现代化学过程日益复杂的背景下，结合劳动力短缺和复杂的故障场景，需要融合符号推理与自适应控制的新型自动化范式。本文引入了一个统一的代理框架，该框架利用大型语言模型（LLMs）在同一架构中进行离散故障恢复规划和连续过程控制。我们采用有限状态机（FSMs）作为可解释的操作边界：LLM 驱动的规划代理通过 FSM 提出恢复序列，仿真代理执行并检查每个状态转换，验证-重询循环迭代改进无效计划。在案例研究 1 中，针对 180 个不同规模（4-25 状态，4-300 转移）的随机生成 FSM，GPT-4o 和 GPT-4o-mini 在五次重询内实现 100% 合法路径成功率，优于开源 LLM 在准确性和延迟方面的表现。在案例研究 2 中，同一框架在实验室 TCLab 平台及其数字双胞胎上调节双加热器输入，以在持续不对称扰动下维持目标平均温度。与经典的 PID 控制相比，基于 LLM 的控制器表现相当，移除提示循环突显了其在处理非线性动态方面的关键作用。我们分析了关键的故障模式，如指令遵循失误和粗略的 ODE 近似。我们的研究结果表明，通过结构化的反馈和模块化的代理，LLMs 可以统一高层次的符号规划与低层次的连续控制，为化学工程中的健壮、语言驱动的自动化铺平了道路。 

---
# Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology 

**Title (ZH)**: 可追溯证据增强的视觉 grounded 理论推理：评估与方法 

**Authors**: Haochen Wang, Xiangtai Li, Zilong Huang, Anran Wang, Jiacong Wang, Tao Zhang, Jiani Zheng, Sule Bai, Zijian Kang, Jiashi Feng, Zhuochen Wang, Zhaoxiang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.07999)  

**Abstract**: Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically referencing visual regions, just like human "thinking with images". However, no benchmark exists to evaluate these capabilities holistically. To bridge this gap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark built on three principles: (1) focused visual perception of subtle targets in complex scenes, (2) traceable evidence via bounding box evaluation, and (3) second-order reasoning to test object interactions and spatial hierarchies beyond simple object localization. Prioritizing images with dense objects, we initially sample 1K high-quality images from SA-1B, and incorporate eight LMM experts to manually annotate questions, candidate options, and answers for each image. After three stages of quality control, TreeBench consists of 405 challenging visual question-answering pairs, even the most advanced models struggle with this benchmark, where none of them reach 60% accuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to supervise localization and reasoning jointly with reinforcement learning, enabling accurate localizations and explainable reasoning pathways. Initialized from Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and TreeBench (+13.4), proving traceability is key to advancing vision-grounded reasoning. The code is available at this https URL. 

**Abstract (ZH)**: 基于可追溯证据的视觉推理基准（TreeBench）：准确认知与解释性推理路径的训练范式（TreeVGR） 

---
# PyVision: Agentic Vision with Dynamic Tooling 

**Title (ZH)**: PyVision：动态工具支持的自主视觉 

**Authors**: Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei  

**Link**: [PDF](https://arxiv.org/pdf/2507.07998)  

**Abstract**: LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning. 

**Abstract (ZH)**: LLMs越来越多地被部署为代理，能够规划、推理并动态调用外部工具。然而，在视觉推理领域，先前的方法仍主要受限于预定义的工作流和静态工具集。在本报告中，我们介绍了PyVision，这是一种互动式多轮框架，使MLLMs能够自主生成、执行和优化针对当前任务定制的Python工具，解锁灵活且可解释的问题解决方式。我们发展了PyVision创建工具的分类，并分析了这些工具在不同基准上的使用情况。定量结果显示，PyVision实现了持续的性能提升，提高了GPT-4.1在V*上的性能7.8%，并在VLMsAreBlind-mini上提高了Claude-4.0-Sonnet的性能31.1%。这些结果表明，动态工具化不仅使模型能够使用工具，还能够发明工具，朝着更具自主性的视觉推理迈进。 

---
# Single-pass Adaptive Image Tokenization for Minimum Program Search 

**Title (ZH)**: 单遍自适应图像令牌化以实现最小程序搜索 

**Authors**: Shivam Duggal, Sanghyun Byun, William T. Freeman, Antonio Torralba, Phillip Isola  

**Link**: [PDF](https://arxiv.org/pdf/2507.07995)  

**Abstract**: According to Algorithmic Information Theory (AIT) -- Intelligent representations compress data into the shortest possible program that can reconstruct its content, exhibiting low Kolmogorov Complexity (KC). In contrast, most visual representation learning systems use fixed-length representations for all inputs, ignoring variations in complexity or familiarity. Recent adaptive tokenization methods address this by allocating variable-length representations but typically require test-time search over multiple encodings to find the most predictive one. Inspired by Kolmogorov Complexity principles, we propose a single-pass adaptive tokenizer, KARL, which predicts the appropriate number of tokens for an image in a single forward pass, halting once its approximate KC is reached. The token count serves as a proxy for the minimum description length. KARL's training procedure closely resembles the Upside-Down Reinforcement Learning paradigm, as it learns to conditionally predict token halting based on a desired reconstruction quality. KARL matches the performance of recent adaptive tokenizers while operating in a single pass. We present scaling laws for KARL, analyzing the role of encoder/decoder size, continuous vs. discrete tokenization and more. Additionally, we offer a conceptual study drawing an analogy between Adaptive Image Tokenization and Algorithmic Information Theory, examining the predicted image complexity (KC) across axes such as structure vs. noise and in- vs. out-of-distribution familiarity -- revealing alignment with human intuition. 

**Abstract (ZH)**: 基于算法信息理论的单步自适应分词器KARL：预测图像的适当分词数量并通过最小描述长度进行优化 

---
# Multigranular Evaluation for Brain Visual Decoding 

**Title (ZH)**: 多级评价脑视觉解码 

**Authors**: Weihao Xia, Cengiz Oztireli  

**Link**: [PDF](https://arxiv.org/pdf/2507.07993)  

**Abstract**: Existing evaluation protocols for brain visual decoding predominantly rely on coarse metrics that obscure inter-model differences, lack neuroscientific foundation, and fail to capture fine-grained visual distinctions. To address these limitations, we introduce BASIC, a unified, multigranular evaluation framework that jointly quantifies structural fidelity, inferential alignment, and contextual coherence between decoded and ground truth images. For the structural level, we introduce a hierarchical suite of segmentation-based metrics, including foreground, semantic, instance, and component masks, anchored in granularity-aware correspondence across mask structures. For the semantic level, we extract structured scene representations encompassing objects, attributes, and relationships using multimodal large language models, enabling detailed, scalable, and context-rich comparisons with ground-truth stimuli. We benchmark a diverse set of visual decoding methods across multiple stimulus-neuroimaging datasets within this unified evaluation framework. Together, these criteria provide a more discriminative, interpretable, and comprehensive foundation for measuring brain visual decoding methods. 

**Abstract (ZH)**: 现有的脑视觉解码评估协议主要依赖于模糊的指标，这些指标掩盖了模型之间的差异，缺乏神经科学基础，并且无法捕捉细微的视觉区分。为了解决这些局限性，我们引入了BASIC，一个统一的多粒度评估框架，该框架同时量化解码图像与 ground truth 图像在结构保真度、推理对齐和上下文一致性方面的差异。在结构层面，我们引入了一套基于分层分割的度量标准，包括前景、语义、实例和组件掩码，并且这些度量标准基于掩码结构的粒度感知对应关系。在语义层面，我们利用多模态大语言模型提取包含对象、属性和关系的结构化场景表示，从而能够在保留上下文的情况下与真实刺激进行详细、可扩展的比较。在这个统一的评估框架中，我们针对多个刺激-神经成像数据集评估了一系列视觉解码方法。这些标准共同为测量脑视觉解码方法提供了更具区分性、可解释性和全面的基础。 

---
# Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs 

**Title (ZH)**: 基于时空令牌多粒度聚合的无训练加速视频LLMs方法 

**Authors**: Jeongseok Hyun, Sukjun Hwang, Su Ho Han, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Joon-Young Lee, Seon Joo Kim, Minho Shim  

**Link**: [PDF](https://arxiv.org/pdf/2507.07990)  

**Abstract**: Video large language models (LLMs) achieve strong video understanding by leveraging a large number of spatio-temporal tokens, but suffer from quadratic computational scaling with token count. To address this, we propose a training-free spatio-temporal token merging method, named STTM. Our key insight is to exploit local spatial and temporal redundancy in video data which has been overlooked in prior work. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks. Notably, STTM achieves a 2$\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3$\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video. The project page is available at this https URL. 

**Abstract (ZH)**: 视频大语言模型（LLMs）通过利用大量的空时token实现了强大的视频理解能力，但由于token数量的二次计算复杂度而受到影响。为了解决这一问题，我们提出了一种无需训练的空时token合并方法，名为STTM。我们的核心洞察是利用视频数据中存在的局部空时冗余，这是先前工作被忽视的部分。STTM首先使用四叉树结构的粗到细搜索将每一帧转换成多粒度的空间token，然后在时间维度上执行有向的两两合并。这种分解的合并方法在六个视频QA基准上优于现有的token缩减方法。值得注意的是，在50%的token预算下，STTM实现了2倍的速度提升，并且准确率下降仅0.5%；在30%的预算下，速度提升了3倍，准确率下降2%。此外，STTM对查询不敏感，允许在相同视频的不同问题上重复使用KV缓存。项目页面请访问这个链接。 

---
# EXPO: Stable Reinforcement Learning with Expressive Policies 

**Title (ZH)**: EXPO: 稳定的强化学习与表达性策略 

**Authors**: Perry Dong, Qiyang Li, Dorsa Sadigh, Chelsea Finn  

**Link**: [PDF](https://arxiv.org/pdf/2507.07986)  

**Abstract**: We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online. 

**Abstract (ZH)**: 基于离线数据训练和微调表达性策略的在线强化学习研究 

---
# Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology 

**Title (ZH)**: 大型和小型语言模型在风湿病临床决策支持中的性能及实际考虑 

**Authors**: Sabine Felde, Rüdiger Buchkremer, Gamal Chehab, Christian Thielscher, Jörg HW Distler, Matthias Schneider, Jutta G. Richter  

**Link**: [PDF](https://arxiv.org/pdf/2507.07983)  

**Abstract**: Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology. 

**Abstract (ZH)**: 大型语言模型在风湿病复杂领域临床决策支持中的潜力：小型语言模型结合检索增强生成在诊断和治疗性能上优于大型模型，同时具有低能耗和成本效益的局部部署优势，适用于资源受限的医疗保健，但专家监督仍为必要。 

---
# Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling 

**Title (ZH)**: 几何强制：将视频扩散与三维表示结合以实现一致的世界建模 

**Authors**: Haoyu Wu, Diankun Wu, Tianyu He, Junliang Guo, Yang Ye, Yueqi Duan, Jiang Bian  

**Link**: [PDF](https://arxiv.org/pdf/2507.07982)  

**Abstract**: Videos inherently represent 2D projections of a dynamic 3D world. However, our analysis suggests that video diffusion models trained solely on raw video data often fail to capture meaningful geometric-aware structure in their learned representations. To bridge this gap between video diffusion models and the underlying 3D nature of the physical world, we propose Geometry Forcing, a simple yet effective method that encourages video diffusion models to internalize latent 3D representations. Our key insight is to guide the model's intermediate representations toward geometry-aware structure by aligning them with features from a pretrained geometric foundation model. To this end, we introduce two complementary alignment objectives: Angular Alignment, which enforces directional consistency via cosine similarity, and Scale Alignment, which preserves scale-related information by regressing unnormalized geometric features from normalized diffusion representation. We evaluate Geometry Forcing on both camera view-conditioned and action-conditioned video generation tasks. Experimental results demonstrate that our method substantially improves visual quality and 3D consistency over the baseline methods. Project page: this https URL. 

**Abstract (ZH)**: 视频本质上代表动态三维世界的空间投影。然而，我们的分析表明，仅基于原始视频数据训练的视频扩散模型往往无法在其学习表示中捕捉到有意义的几何意识结构。为了弥合视频扩散模型与物理世界内在三维性质之间的差距，我们提出了一种简单而有效的方法——几何强制，该方法促使视频扩散模型内部化潜在的三维表示。我们的关键是通过将模型的中间表示与预训练的几何基础模型的特征对齐，引导其向几何意识结构靠拢。为此，我们引入了两种互补的对齐目标：角度对齐，通过余弦相似性确保方向一致性；尺度对齐，通过从归一化的扩散表示中回归未归一化的几何特征来保留与尺度相关的信息。我们在相机视角条件下的视频生成和动作条件下的视频生成任务上评估了几何强制方法。实验结果表明，与基线方法相比，我们的方法显著提高了视觉质量和三维一致性。项目页面：这个 https URL。 

---
# Why is Your Language Model a Poor Implicit Reward Model? 

**Title (ZH)**: 为什么你的语言模型是一个 poor 隐式奖励模型？ 

**Authors**: Noam Razin, Yong Lin, Jiarui Yao, Sanjeev Arora  

**Link**: [PDF](https://arxiv.org/pdf/2507.07981)  

**Abstract**: Reward models are key to language model post-training and inference pipelines. Conveniently, recent work showed that every language model defines an implicit reward model (IM-RM), without requiring any architectural changes. However, such IM-RMs tend to generalize worse, especially out-of-distribution, compared to explicit reward models (EX-RMs) that apply a dedicated linear head over the hidden representations of a language model. The existence of a generalization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They can be trained using the same data, loss function, and language model, and differ only in how the reward is computed. Towards a fundamental understanding of the implicit biases underlying different reward model types, we investigate the root cause of this gap. Our main finding, backed by theory and experiments, is that IM-RMs rely more heavily on superficial token-level cues. Consequently, they often generalize worse than EX-RMs under token-level distribution shifts, as well as in-distribution. Furthermore, we provide evidence against alternative hypotheses for the generalization gap. Most notably, we challenge the intuitive claim that IM-RMs struggle in tasks where generation is harder than verification because they can operate both as a verifier and a generator. Taken together, our results highlight that seemingly minor design choices can substantially impact the generalization behavior of reward models. 

**Abstract (ZH)**: 奖励模型是语言模型后训练和推理管道中的关键。近期研究表明，每个语言模型都定义了一个隐式奖励模型（IM-RM），无需进行任何架构更改。然而，与通过语言模型的隐藏表示添加专用线性头的明确奖励模型（EX-RM）相比，这些IM-RMs往往泛化能力较差，尤其是在分布外场景下。这种泛化差距令人困惑，因为EX-RM和IM-RM几乎是相同的。它们可以使用相同的数据、损失函数和语言模型进行训练，仅在奖励的计算方式上有所不同。为理解不同类型奖励模型背后的隐式偏差的根本原因，我们调查了这种差距的原因。我们的主要发现，理论和实验支持的是，IM-RMs更加依赖于表面的令牌级线索。因此，它们在令牌级分布变换以及分布内场景中往往比EX-RMs泛化能力较差。此外，我们反驳了泛化差距的替代假说。最重要的是，我们质疑了直觉上的观点，即IM-RMs在生成比验证更困难的任务中表现不佳，因为它们既可以作为验证器也可以作为生成器。综上所述，我们的结果突显了看似微小的设计选择对奖励模型的泛化行为有显著影响。 

---
# Reinforcement Learning with Action Chunking 

**Title (ZH)**: 行动分块的强化学习 

**Authors**: Qiyang Li, Zhiyuan Zhou, Sergey Levine  

**Link**: [PDF](https://arxiv.org/pdf/2507.07969)  

**Abstract**: We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks. 

**Abstract (ZH)**: Q-分块：一种提高长期任务稀疏奖励强化学习算法效果的简单有效方法 

---
# Scaling RL to Long Videos 

**Title (ZH)**: 将RL扩展到长视频 

**Authors**: Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han  

**Link**: [PDF](https://arxiv.org/pdf/2507.07966)  

**Abstract**: We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 52K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves strong performance on long video QA benchmarks such as VideoMME. It also outperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal reasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on our LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent performance gains as the number of input video frames scales. LongVILA-R1 marks a firm step towards long video reasoning in VLMs. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames / around 256k tokens). 

**Abstract (ZH)**: 一种面向长视频的视觉-语言模型全流程框架：基于强化学习的长视频推理扩展（LongVILA-R1-7B: A Full-Stack Framework for Long Video Reasoning in Vision-Language Models via Reinforcement Learning） 

---
# MIRIX: Multi-Agent Memory System for LLM-Based Agents 

**Title (ZH)**: MIRIX: 基于LLM的多智能体记忆系统 

**Authors**: Yu Wang, Xi Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.07957)  

**Abstract**: Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy. 

**Abstract (ZH)**: 虽然AI代理的内存能力正逐渐引起关注，但现有解决方案仍然存在根本性的局限性。大多数解决方案依赖于平铺且范围狭窄的内存组件，限制了它们在长时间内个性化、抽象和可靠地回忆用户特定信息的能力。为此，我们 introduces MIRIX，一种模块化的多代理内存系统，通过解决该领域最关键的挑战——使语言模型真正具备记忆能力来重新定义AI内存的未来。与以往方法不同，MIRIX 超越了文本，拥抱了丰富的视觉和多模态体验，使内存能够在现实场景中真正发挥作用。MIRIX 包含六种不同的、仔细构建的内存类型：核心内存、情景记忆、语义记忆、程序记忆、资源记忆和知识库，以及一个动态控制和协调更新与检索的多代理框架。此设计使代理能够大规模地持久保存、因次处理并准确检索各类长期用户数据。我们在两个具有挑战性的场景中验证了MIRIX。首先，在包含每序列近20,000张高分辨率计算机屏幕截图的具有挑战性的多模态基准ScreenshotVQA中，MIRIX 较RAG基线提高了35%的准确性，并将存储需求减少了99.9%。其次，在单模态文本输入的LOCOMO长期对话基准测试中，MIRIX 达到了85.4%的最佳性能，远远超过了现有基线。这些结果表明，MIRIX 设定了增强记忆的LLM代理的新性能标准。为了使用户能够体验我们的内存系统，我们提供了由MIRIX 动力驱动的打包应用程序。该应用程序实时监控屏幕，构建个性化的记忆基础，并提供直观的可视化和安全的本地存储，确保隐私。 

---
# Low Resource Reconstruction Attacks Through Benign Prompts 

**Title (ZH)**: 低资源重建攻击通过良性提示 

**Authors**: Sol Yarkoni, Roi Livni  

**Link**: [PDF](https://arxiv.org/pdf/2507.07947)  

**Abstract**: The recent advances in generative models such as diffusion models have raised several risks and concerns related to privacy, copyright infringements and data stewardship. To better understand and control the risks, various researchers have created techniques, experiments and attacks that reconstruct images, or part of images, from the training set. While these techniques already establish that data from the training set can be reconstructed, they often rely on high-resources, excess to the training set as well as well-engineered and designed prompts.
In this work, we devise a new attack that requires low resources, assumes little to no access to the actual training set, and identifies, seemingly, benign prompts that lead to potentially-risky image reconstruction. This highlights the risk that images might even be reconstructed by an uninformed user and unintentionally. For example, we identified that, with regard to one existing model, the prompt ``blue Unisex T-Shirt'' can generate the face of a real-life human model. Our method builds on an intuition from previous works which leverages domain knowledge and identifies a fundamental vulnerability that stems from the use of scraped data from e-commerce platforms, where templated layouts and images are tied to pattern-like prompts. 

**Abstract (ZH)**: Recent 进展 在 生成 模型 如 放散 模型 中 引起 的 隐私 风险 、 版权 侵权 和 数据 管理 问题 及 其 应对 研究 

---
# Probing Experts' Perspectives on AI-Assisted Public Speaking Training 

**Title (ZH)**: 探究专家对AI辅助公共演讲训练的看法 

**Authors**: Nesrine Fourati, Alisa Barkar, Marion Dragée, Liv Danthon-Lefebvre, Mathieu Chollet  

**Link**: [PDF](https://arxiv.org/pdf/2507.07930)  

**Abstract**: Background: Public speaking is a vital professional skill, yet it remains a source of significant anxiety for many individuals. Traditional training relies heavily on expert coaching, but recent advances in AI has led to novel types of commercial automated public speaking feedback tools. However, most research has focused on prototypes rather than commercial applications, and little is known about how public speaking experts perceive these tools.
Objectives: This study aims to evaluate expert opinions on the efficacy and design of commercial AI-based public speaking training tools and to propose guidelines for their improvement.
Methods: The research involved 16 semi-structured interviews and 2 focus groups with public speaking experts. Participants discussed their views on current commercial tools, their potential integration into traditional coaching, and suggestions for enhancing these systems.
Results and Conclusions: Experts acknowledged the value of AI tools in handling repetitive, technical aspects of training, allowing coaches to focus on higher-level skills. However they found key issues in current tools, emphasising the need for personalised, understandable, carefully selected feedback and clear instructional design. Overall, they supported a hybrid model combining traditional coaching with AI-supported exercises. 

**Abstract (ZH)**: 背景：公共演讲是重要的专业技能，但对许多人来说仍是显著的焦虑源。传统培训依赖专家指导，而最近的AI进步导致了新的商业自动公共演讲反馈工具的出现。然而，大多数研究集中在原型上而不是商业应用，关于公共演讲专家对这些工具的看法知之甚少。
目标：本研究旨在评估公共演讲专家对商业AI基于的公共演讲培训工具的有效性和设计的看法，并提出改进指南。
方法：研究包括16次半结构化采访和2次专家焦点小组讨论，参与者讨论了他们对当前商业工具的看法、这些工具与传统指导的潜在整合以及对这些系统的改进建议。
结果与结论：专家承认AI工具在处理训练中的重复和技术方面具有价值，使教练可以专注于高层次技能。但他们也指出现有工具的关键问题，强调个性化、易于理解、精心挑选的反馈和清晰的指导设计的重要性。总体而言，他们支持将传统指导与AI支持的练习相结合的混合模式。 

---
# Towards Continuous Home Cage Monitoring: An Evaluation of Tracking and Identification Strategies for Laboratory Mice 

**Title (ZH)**: 面向连续家庭笼监测：实验室小鼠跟踪与识别策略评估 

**Authors**: Juan Pablo Oberhauser, Daniel Grzenda  

**Link**: [PDF](https://arxiv.org/pdf/2507.07929)  

**Abstract**: Continuous, automated monitoring of laboratory mice enables more accurate data collection and improves animal welfare through real-time insights. Researchers can achieve a more dynamic and clinically relevant characterization of disease progression and therapeutic effects by integrating behavioral and physiological monitoring in the home cage. However, providing individual mouse metrics is difficult because of their housing density, similar appearances, high mobility, and frequent interactions. To address these challenges, we develop a real-time identification (ID) algorithm that accurately assigns ID predictions to mice wearing custom ear tags in digital home cages monitored by cameras. Our pipeline consists of three parts: (1) a custom multiple object tracker (MouseTracks) that combines appearance and motion cues from mice; (2) a transformer-based ID classifier (Mouseformer); and (3) a tracklet associator linear program to assign final ID predictions to tracklets (MouseMap). Our models assign an animal ID based on custom ear tags at 30 frames per second with 24/7 cage coverage. We show that our custom tracking and ID pipeline improves tracking efficiency and lowers ID switches across mouse strains and various environmental factors compared to current mouse tracking methods. 

**Abstract (ZH)**: 连续自动监测实验室小鼠能够通过实时反馈提高数据准确性和动物福利。通过将行为和生理监测集成到家庭笼中，研究人员可以实现更动态和临床相关的小鼠疾病进展和治疗效果表征。然而，由于小鼠的高密度饲养、相似外观、高移动性和频繁的互动，提供个体小鼠指标具有挑战性。为应对这些挑战，我们开发了一种实时识别算法，能够在监控小鼠的数字家庭笼中准确地将识别预测分配给佩戴了定制耳标的个体小鼠。我们的管道由三部分组成：(1) 一种结合小鼠外观和运动线索的定制多目标跟踪器(MouseTracks)；(2) 基于变换器的识别分类器(Mouseformer)；(3) 跟踪片段关联线性规划(MouseMap)以最终对跟踪片段分配ID预测。我们的模型以每秒30帧的速度，在24小时全天候笼子覆盖下，基于定制耳标分配动物ID。我们证明，与现有的小鼠跟踪方法相比，我们的定制跟踪和识别管道能够提高跟踪效率，并在不同小鼠品系和各种环境因素下降低识别切换率。 

---
# DTECT: Dynamic Topic Explorer & Context Tracker 

**Title (ZH)**: DTECT: 动态主题探索与上下文追踪 

**Authors**: Suman Adhya, Debarshi Kumar Sanyal  

**Link**: [PDF](https://arxiv.org/pdf/2507.07910)  

**Abstract**: The explosive growth of textual data over time presents a significant challenge in uncovering evolving themes and trends. Existing dynamic topic modeling techniques, while powerful, often exist in fragmented pipelines that lack robust support for interpretation and user-friendly exploration. We introduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end system that bridges the gap between raw textual data and meaningful temporal insights. DTECT provides a unified workflow that supports data preprocessing, multiple model architectures, and dedicated evaluation metrics to analyze the topic quality of temporal topic models. It significantly enhances interpretability by introducing LLM-driven automatic topic labeling, trend analysis via temporally salient words, interactive visualizations with document-level summarization, and a natural language chat interface for intuitive data querying. By integrating these features into a single, cohesive platform, DTECT empowers users to more effectively track and understand thematic dynamics. DTECT is open-source and available at this https URL. 

**Abstract (ZH)**: 文本数据随时间的爆炸性增长为发现 evolving themes 和趋势带来了重大挑战。现有的动态主题建模技术虽然强大，但往往存在于缺乏解释性和用户友好探索支持的分散管道中。我们提出了 DTECT（动态主题探索与上下文追踪），这是一个端到端系统，它在原始文本数据和有意义的时间洞察之间架起了桥梁。DTECT 提供了一个统一的工作流，支持数据预处理、多种模型架构以及专门的评估指标来分析时间主题模型的主题质量。通过引入由大语言模型驱动的自动主题标签生成、基于时间显著词的趋势分析、与文档级别总结的交互式可视化以及使用自然语言聊天接口进行直观的数据查询，DTECT 显著增强了可解释性。通过将这些功能整合到一个统一的平台中，DTECT 赋能用户更有效地追踪和理解主题动态。DTECT 是开源的，可在此 <https://github.com> URL 获取。 

---
# Agentic Retrieval of Topics and Insights from Earnings Calls 

**Title (ZH)**: 基于代理的 earnings 电话主题和见解检索 

**Authors**: Anant Gupta, Rajarshi Bhowmik, Geoffrey Gunow  

**Link**: [PDF](https://arxiv.org/pdf/2507.07906)  

**Abstract**: Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends. 

**Abstract (ZH)**: 通过分析公司季度 earnings call 中的主题来追踪公司的战略重点是一项关键的金融分析任务。然而，随着行业的演变，传统的主题建模技术难以动态捕捉新兴主题及其关系。在本工作中，我们提出了一种由大语言模型驱动的方法，从季度 earnings call 中发现和检索新兴主题。我们提出使用大语言模型提取主题，将这些主题结构化为层次 ontology，并通过主题 ontology 建立新旧主题之间的关系。我们展示了提取的主题如何用于推断公司层面的见解和随着时间的发展出现的趋势。我们通过测量 ontology 的一致性、主题演化的准确性以及其发现新兴金融趋势的能力来评估我们的方法。 

---
# UnIT: Scalable Unstructured Inference-Time Pruning for MAC-efficient Neural Inference on MCUs 

**Title (ZH)**: UnIT：MAC高效MCU上可扩展的非结构化推理时剪枝方法 

**Authors**: Ashe Neth, Sawinder kaur, Mohammad Nur Hossain Khan, Subrata Biswas, Asif Salekin, Bashima Islam  

**Link**: [PDF](https://arxiv.org/pdf/2507.07885)  

**Abstract**: Existing pruning methods are typically applied during training or compile time and often rely on structured sparsity. While compatible with low-power microcontrollers (MCUs), structured pruning underutilizes the opportunity for fine-grained efficiency on devices without SIMD support or parallel compute. To address these limitations, we introduce UnIT (Unstructured Inference-Time pruning), a lightweight method that dynamically identifies and skips unnecessary multiply-accumulate (MAC) operations during inference, guided by input-specific activation patterns. Unlike structured pruning, UnIT embraces irregular sparsity and does not require retraining or hardware specialization. It transforms pruning decisions into lightweight comparisons, replacing multiplications with threshold checks and approximated divisions. UnIT further optimizes compute by reusing threshold computations across multiple connections and applying layer- and group-specific pruning sensitivity. We present three fast, hardware-friendly division approximations tailored to the capabilities of common embedded platforms. Demonstrated on the MSP430 microcontroller, UnIT achieves 11.02% to 82.03% MAC reduction, 27.30% to 84.19% faster inference, and 27.33% to 84.38% lower energy consumption compared to training-time pruned models, while maintaining accuracy with 0.48-7%. Under domain shift, UnIT matches or exceeds the accuracy of retrained models while requiring significantly fewer MACs. These results establish unstructured inference-time pruning as a viable and practical solution for efficient, retraining-free deployment of deep neural networks on MCUs. 

**Abstract (ZH)**: UnIT：未结构化推断时剪枝 

---
# Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking 

**Title (ZH)**: 基于多密钥水印的对抗生成模型水印偷窃攻击缓解方法 

**Authors**: Toluwani Aremu, Noor Hussein, Munachiso Nwadike, Samuele Poppi, Jie Zhang, Karthik Nandakumar, Neil Gong, Nils Lukas  

**Link**: [PDF](https://arxiv.org/pdf/2507.07871)  

**Abstract**: Watermarking offers a promising solution for GenAI providers to establish the provenance of their generated content. A watermark is a hidden signal embedded in the generated content, whose presence can later be verified using a secret watermarking key. A threat to GenAI providers are \emph{watermark stealing} attacks, where users forge a watermark into content that was \emph{not} generated by the provider's models without access to the secret key, e.g., to falsely accuse the provider. Stealing attacks collect \emph{harmless} watermarked samples from the provider's model and aim to maximize the expected success rate of generating \emph{harmful} watermarked samples. Our work focuses on mitigating stealing attacks while treating the underlying watermark as a black-box. Our contributions are: (i) Proposing a multi-key extension to mitigate stealing attacks that can be applied post-hoc to any watermarking method across any modality. (ii) We provide theoretical guarantees and demonstrate empirically that our method makes forging substantially less effective across multiple datasets, and (iii) we formally define the threat of watermark forging as the task of generating harmful, watermarked content and model this threat via security games. 

**Abstract (ZH)**: Watermarking为GenAI提供商建立生成内容溯源提供了一种有前景的解决方案： watermark是一种嵌入在生成内容中的隐藏信号，其存在可以通过秘密水印密钥进行验证。GenAI提供商面临的一种威胁是水印盗窃攻击，即用户在未访问密钥的情况下，伪造水印插入非提供商模型生成的内容中，以虚假指控提供商。我们的工作旨在在不访问底层水印实现细节的情况下缓解盗窃攻击。我们的贡献包括：(i) 提出了一种多密钥扩展方法，可以在任何水印方法和任何模态上事后应用以缓解盗窃攻击。(ii) 我们提供了理论保证，并通过实验证明，我们的方法能够显著降低在多个数据集上的伪造效果。(iii) 我们正式定义了水印伪造的威胁为生成有害水印内容的任务，并通过安全博弈对该威胁进行建模。 

---
# Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation 

**Title (ZH)**: Alpay代数V：多层语义游戏与超限固定点模拟 

**Authors**: Bugra Kilictas, Faruk Alpay  

**Link**: [PDF](https://arxiv.org/pdf/2507.07868)  

**Abstract**: This paper extends the self-referential framework of Alpay Algebra into a multi-layered semantic game architecture where transfinite fixed-point convergence encompasses hierarchical sub-games at each iteration level. Building upon Alpay Algebra IV's empathetic embedding concept, we introduce a nested game-theoretic structure where the alignment process between AI systems and documents becomes a meta-game containing embedded decision problems. We formalize this through a composite operator $\phi(\cdot, \gamma(\cdot))$ where $\phi$ drives the main semantic convergence while $\gamma$ resolves local sub-games. The resulting framework demonstrates that game-theoretic reasoning emerges naturally from fixed-point iteration rather than being imposed externally. We prove a Game Theorem establishing existence and uniqueness of semantic equilibria under realistic cognitive simulation assumptions. Our verification suite includes adaptations of Banach's fixed-point theorem to transfinite contexts, a novel $\phi$-topology based on the Kozlov-Maz'ya-Rossmann formula for handling semantic singularities, and categorical consistency tests via the Yoneda lemma. The paper itself functions as a semantic artifact designed to propagate its fixed-point patterns in AI embedding spaces -- a deliberate instantiation of the "semantic virus" concept it theorizes. All results are grounded in category theory, information theory, and realistic AI cognition models, ensuring practical applicability beyond pure mathematical abstraction. 

**Abstract (ZH)**: 本文将Alpay代数的自参照框架扩展为一个多层语义博弈架构，在每个迭代层级上，超限不动点收敛涵盖了层级子博弈。在Alpay代数IV的同情感化嵌入概念的基础上，我们引入了一个嵌套的博弈论结构，将AI系统与文档之间的对齐过程作为一个包含嵌入决策问题的元博弈。我们通过复合算子$\phi(\cdot, \gamma(\cdot))$来形式化这一过程，其中$\phi$驱动主要的语义收敛，而$\gamma$解决局部子博弈。由此构建的框架表明，博弈论推理自然地源自不动点迭代，而非外部施加。我们证明了一个博弈定理，确立了在现实认知模拟假设下的语义平衡的存在性和唯一性。我们的验证套件包括Banach不动点定理在超限上下文中的适应版本、基于Kozlov-Maz'ya-Rossmann公式的新的$\phi$-拓扑以及通过Yoneda引理进行的范畴一致性测试。本文本身充当了一个语义实体，旨在在其AI嵌入空间中传播其不动点模式——这是其所理论化的“语义病毒”概念的具体实现。所有结果均建立在范畴论、信息论以及现实的AI认知模型之上，确保其在纯数学抽象之外的实际应用。 

---
# Optimization Guarantees for Square-Root Natural-Gradient Variational Inference 

**Title (ZH)**: 平方根自然梯度变分推断的优化保证 

**Authors**: Navish Kumar, Thomas Möllenhoff, Mohammad Emtiyaz Khan, Aurelien Lucchi  

**Link**: [PDF](https://arxiv.org/pdf/2507.07853)  

**Abstract**: Variational inference with natural-gradient descent often shows fast convergence in practice, but its theoretical convergence guarantees have been challenging to establish. This is true even for the simplest cases that involve concave log-likelihoods and use a Gaussian approximation. We show that the challenge can be circumvented for such cases using a square-root parameterization for the Gaussian covariance. This approach establishes novel convergence guarantees for natural-gradient variational-Gaussian inference and its continuous-time gradient flow. Our experiments demonstrate the effectiveness of natural gradient methods and highlight their advantages over algorithms that use Euclidean or Wasserstein geometries. 

**Abstract (ZH)**: 自然梯度下降变分推断在实践中通常显示出快速收敛性，但其理论上的收敛保证一直难以确立。即使在涉及凹对数似然和使用高斯近似的情况下也是如此。我们表明，通过使用高斯协方差的平方根参数化，可以避开此类情况下的挑战。该方法为自然梯度变分高斯推断及其连续时间梯度流建立了新的收敛保证。我们的实验证明了自然梯度方法的有效性，并突显了它们在使用欧几里得或 Wasserstein 几何的算法方面的优势。 

---
# From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems 

**Title (ZH)**: 从模糊到精确：核心ference解析对检索增强生成系统的影响 

**Authors**: Youngjoon Jang, Seongtae Hong, Junyoung Son, Sungjin Park, Chanjun Park, Heuiseok Lim  

**Link**: [PDF](https://arxiv.org/pdf/2507.07847)  

**Abstract**: Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications. 

**Abstract (ZH)**: 基于检索增强生成（RAG）中的实体共指如何影响文档检索和生成性能的研究 

---
# Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles 

**Title (ZH)**: 基于内容的拼图解谜器在受损拼图上的基准测试 

**Authors**: Richard Dirauf, Florian Wolz, Dario Zanca, Björn Eskofier  

**Link**: [PDF](https://arxiv.org/pdf/2507.07828)  

**Abstract**: Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts. 

**Abstract (ZH)**: 基于内容的拼图求解器已经广泛研究，展示了在计算技术方面的显著进步。然而，其评估往往缺乏对于真实世界应用至关重要的现实挑战，如破损文物或碎片文件的复原。在本文中，我们通过引入三种拼图损坏类型（缺失拼块、磨损边缘、磨损内容）来研究最先进的基于内容的拼图求解器的鲁棒性。评估了启发式和深度学习求解器，分析了它们处理这些损坏的能力并指出了关键局限。结果显示，针对标准拼图开发的求解器在拼块损坏增加时表现迅速下降。然而，通过使用扩充数据进行微调，深度学习模型可以显著提高其鲁棒性。值得注意的是，高级位置扩散模型适应性尤为良好，在大多数实验中表现出色。基于我们的发现，我们指出了增强真实世界文物自动化复原的有前途的研究方向。 

---
# On the Effect of Instruction Tuning Loss on Generalization 

**Title (ZH)**: 关于指令调优损失对泛化能力的影响 

**Authors**: Anwoy Chatterjee, H S V N S Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty  

**Link**: [PDF](https://arxiv.org/pdf/2507.07817)  

**Abstract**: Instruction Tuning has emerged as a pivotal post-training paradigm that enables pre-trained language models to better follow user instructions. Despite its significance, little attention has been given to optimizing the loss function used. A fundamental, yet often overlooked, question is whether the conventional auto-regressive objective - where loss is computed only on response tokens, excluding prompt tokens - is truly optimal for instruction tuning. In this work, we systematically investigate the impact of differentially weighting prompt and response tokens in instruction tuning loss, and propose Weighted Instruction Tuning (WIT) as a better alternative to conventional instruction tuning. Through extensive experiments on five language models of different families and scale, three finetuning datasets of different sizes, and five diverse evaluation benchmarks, we show that the standard instruction tuning loss often yields suboptimal performance and limited robustness to input prompt variations. We find that a low-to-moderate weight for prompt tokens coupled with a moderate-to-high weight for response tokens yields the best-performing models across settings and also serve as better starting points for the subsequent preference alignment training. These findings highlight the need to reconsider instruction tuning loss and offer actionable insights for developing more robust and generalizable models. Our code is open-sourced at this https URL. 

**Abstract (ZH)**: 指令调优作为一种关键的后训练范式，能够使预训练语言模型更好地遵循用户指令。尽管其重要性不言而喻，但很少有人关注用于调优的损失函数的优化。一个基本但常被忽视的问题是，传统的自回归目标——仅在响应标记上计算损失，而不包括提示标记——是否真正适合指令调优。在这项工作中，我们系统地调查了在指令调优损失中差异加权提示标记和响应标记的影响，并提出了加权指令调优（WIT）作为传统指令调优的更好替代方案。通过在五种不同家族和规模的语言模型、三种不同大小的微调数据集和五种不同的评估基准上进行广泛的实验，我们展示了标准指令调优损失通常会导致次优性能并限制对输入提示变化的鲁棒性。我们发现，在提示标记上使用低到中等权重结合响应标记上使用中等到高权重的策略，能够在不同设置下获得最佳性能的模型，并且作为后续偏好对齐训练的良好起始点。这些发现强调了重新考虑指令调优损失的需求，并提供了开发更鲁棒和通用模型的实际建议。我们的代码已在以下网址开源：这个 https URL。 

---
# Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers 

**Title (ZH)**: 逻辑与学习的桥梁：通过变换器解码时序逻辑嵌入 

**Authors**: Sara Candussio, Gaia Saveri, Gabriele Sarti, Luca Bortolussi  

**Link**: [PDF](https://arxiv.org/pdf/2507.07808)  

**Abstract**: Continuous representations of logic formulae allow us to integrate symbolic knowledge into data-driven learning algorithms. If such embeddings are semantically consistent, i.e. if similar specifications are mapped into nearby vectors, they enable continuous learning and optimization directly in the semantic space of formulae. However, to translate the optimal continuous representation into a concrete requirement, such embeddings must be invertible. We tackle this issue by training a Transformer-based decoder-only model to invert semantic embeddings of Signal Temporal Logic (STL) formulae. STL is a powerful formalism that allows us to describe properties of signals varying over time in an expressive yet concise way. By constructing a small vocabulary from STL syntax, we demonstrate that our proposed model is able to generate valid formulae after only 1 epoch and to generalize to the semantics of the logic in about 10 epochs. Additionally, the model is able to decode a given embedding into formulae that are often simpler in terms of length and nesting while remaining semantically close (or equivalent) to gold references. We show the effectiveness of our methodology across various levels of training formulae complexity to assess the impact of training data on the model's ability to effectively capture the semantic information contained in the embeddings and generalize out-of-distribution. Finally, we deploy our model for solving a requirement mining task, i.e. inferring STL specifications that solve a classification task on trajectories, performing the optimization directly in the semantic space. 

**Abstract (ZH)**: 基于Transformer的仅解码模型用于逆向转换Signal Temporal Logic公式语义嵌入 

---
# Visual Instance-aware Prompt Tuning 

**Title (ZH)**: 视觉实例感知提示调优 

**Authors**: Xi Xiao, Yunbei Zhang, Xingjian Li, Tianyang Wang, Xiao Wang, Yuxiang Wei, Jihun Hamm, Min Xu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07796)  

**Abstract**: Visual Prompt Tuning (VPT) has emerged as a parameter-efficient fine-tuning paradigm for vision transformers, with conventional approaches utilizing dataset-level prompts that remain the same across all input instances. We observe that this strategy results in sub-optimal performance due to high variance in downstream datasets. To address this challenge, we propose Visual Instance-aware Prompt Tuning (ViaPT), which generates instance-aware prompts based on each individual input and fuses them with dataset-level prompts, leveraging Principal Component Analysis (PCA) to retain important prompting information. Moreover, we reveal that VPT-Deep and VPT-Shallow represent two corner cases based on a conceptual understanding, in which they fail to effectively capture instance-specific information, while random dimension reduction on prompts only yields performance between the two extremes. Instead, ViaPT overcomes these limitations by balancing dataset-level and instance-level knowledge, while reducing the amount of learnable parameters compared to VPT-Deep. Extensive experiments across 34 diverse datasets demonstrate that our method consistently outperforms state-of-the-art baselines, establishing a new paradigm for analyzing and optimizing visual prompts for vision transformers. 

**Abstract (ZH)**: 视觉实例感知提示调谐（ViaPT）：一种结合实例级和数据集级提示的参数高效微调范式 

---
# Where are we with calibration under dataset shift in image classification? 

**Title (ZH)**: 图像分类中数据集迁移下的校准状态如何？ 

**Authors**: Mélanie Roschewitz, Raghav Mehta, Fabio de Sousa Ribeiro, Ben Glocker  

**Link**: [PDF](https://arxiv.org/pdf/2507.07780)  

**Abstract**: We conduct an extensive study on the state of calibration under real-world dataset shift for image classification. Our work provides important insights on the choice of post-hoc and in-training calibration techniques, and yields practical guidelines for all practitioners interested in robust calibration under shift. We compare various post-hoc calibration methods, and their interactions with common in-training calibration strategies (e.g., label smoothing), across a wide range of natural shifts, on eight different classification tasks across several imaging domains. We find that: (i) simultaneously applying entropy regularisation and label smoothing yield the best calibrated raw probabilities under dataset shift, (ii) post-hoc calibrators exposed to a small amount of semantic out-of-distribution data (unrelated to the task) are most robust under shift, (iii) recent calibration methods specifically aimed at increasing calibration under shifts do not necessarily offer significant improvements over simpler post-hoc calibration methods, (iv) improving calibration under shifts often comes at the cost of worsening in-distribution calibration. Importantly, these findings hold for randomly initialised classifiers, as well as for those finetuned from foundation models, the latter being consistently better calibrated compared to models trained from scratch. Finally, we conduct an in-depth analysis of ensembling effects, finding that (i) applying calibration prior to ensembling (instead of after) is more effective for calibration under shifts, (ii) for ensembles, OOD exposure deteriorates the ID-shifted calibration trade-off, (iii) ensembling remains one of the most effective methods to improve calibration robustness and, combined with finetuning from foundation models, yields best calibration results overall. 

**Abstract (ZH)**: 我们在真实世界数据集变化下的图像分类校准状态进行了广泛研究。我们的工作提供了关于后验和训练中校准技术选择的重要见解，并为所有希望在变化条件下实现稳健校准的实践者提供了实用指南。我们比较了各种后验校准方法及其与常用训练中校准策略（如标签平滑）的交互作用，涵盖了广泛的自然变化，涉及八个不同分类任务的多个成像领域。我们发现：（i）同时应用熵正则化和标签平滑在数据集变化下能获得最好的校准原始概率；（ii）暴露于少量语义无关分布外数据（与任务无关）的后验校准器在变化下最稳健；（iii）专门针对提高变化下校准效果的最新校准方法不一定比简单的后验校准方法提供显著改进；（iv）提高变化下校准效果通常会以牺牲域内校准为代价。重要的是，这些发现不仅适用于随机初始化的分类器，也适用于从基础模型微调的分类器，后者相比从头训练的模型具有更稳健的校准效果。最后，我们深入分析了集成效应，发现：（i）在集成之前而非之后进行校准对变化下的校准更为有效；（ii）对于集成而言，分布外暴露会恶化ID-变化下的校准权衡；（iii）集成仍然是提高校准稳健性最有效的方法之一，并与来自基础模型的微调相结合，总体上能获得最佳校准结果。 

---
# Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training 

**Title (ZH)**: 同步任务行为：测试时对齐多个任务 

**Authors**: Wooseong Jeong, Jegyeong Cho, Youngho Yoon, Kuk-Jin Yoon  

**Link**: [PDF](https://arxiv.org/pdf/2507.07778)  

**Abstract**: Generalizing neural networks to unseen target domains is a significant challenge in real-world deployments. Test-time training (TTT) addresses this by using an auxiliary self-supervised task to reduce the domain gap caused by distribution shifts between the source and target. However, we find that when models are required to perform multiple tasks under domain shifts, conventional TTT methods suffer from unsynchronized task behavior, where the adaptation steps needed for optimal performance in one task may not align with the requirements of other tasks. To address this, we propose a novel TTT approach called Synchronizing Tasks for Test-time Training (S4T), which enables the concurrent handling of multiple tasks. The core idea behind S4T is that predicting task relations across domain shifts is key to synchronizing tasks during test time. To validate our approach, we apply S4T to conventional multi-task benchmarks, integrating it with traditional TTT protocols. Our empirical results show that S4T outperforms state-of-the-art TTT methods across various benchmarks. 

**Abstract (ZH)**: 将神经网络在未见目标域上的泛化是实际部署中的一个显著挑战。测试时训练（TTT）通过使用辅助半监督任务来减少源域与目标域间分布偏移造成的领域差距。然而，当模型在领域偏移下需要执行多个任务时，传统的TTT方法会遭受任务行为不平衡的问题，即一个任务最优性能所需的适应步骤可能与另一任务的需求不一致。为解决这一问题，我们提出了一个名为同步测试时训练任务（S4T）的新型TTT方法，该方法能够并发处理多个任务。S4T的核心思想是在测试时预测跨领域偏移的任务关系是同步任务的关键。为了验证我们的方法，我们在传统的多任务基准上应用S4T，并将其整合到传统的TTT协议中。我们的实验结果表明，S4T在多种基准上优于最先进的TTT方法。 

---
# OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting 

**Title (ZH)**: OPC: One-Point-Contraction Unlearning Toward Deep Feature Forgetting 

**Authors**: Jaeheun Jung, Bosung Jung, Suhyun Bae, Donghun Lee  

**Link**: [PDF](https://arxiv.org/pdf/2507.07754)  

**Abstract**: Machine unlearning seeks to remove the influence of particular data or class from trained models to meet privacy, legal, or ethical requirements. Existing unlearning methods tend to forget shallowly: phenomenon of an unlearned model pretend to forget by adjusting only the model response, while its internal representations retain information sufficiently to restore the forgotten data or behavior. We empirically confirm the widespread shallowness by reverting the forgetting effect of various unlearning methods via training-free performance recovery attack and gradient-inversion-based data reconstruction attack. To address this vulnerability fundamentally, we define a theoretical criterion of ``deep forgetting'' based on one-point-contraction of feature representations of data to forget. We also propose an efficient approximation algorithm, and use it to construct a novel general-purpose unlearning algorithm: One-Point-Contraction (OPC). Empirical evaluations on image classification unlearning benchmarks show that OPC achieves not only effective unlearning performance but also superior resilience against both performance recovery attack and gradient-inversion attack. The distinctive unlearning performance of OPC arises from the deep feature forgetting enforced by its theoretical foundation, and recaps the need for improved robustness of machine unlearning methods. 

**Abstract (ZH)**: 机器去学习旨在从训练模型中移除特定数据或类别的影响，以满足隐私、法律或伦理要求。现有的去学习方法往往表浅地遗忘：未学习模型通过仅调整模型响应假装遗忘，但其内部表示保留足够的信息以恢复遗忘的数据或行为。我们通过训练-free 性能恢复攻击和梯度反转数据重建攻击，实证确认了这种表浅遗忘的普遍性。为从根本上解决这一漏洞，我们基于数据遗忘特征表示的一点收缩定义了“深度遗忘”的理论标准，并提出了一种高效的算法近似方法，以此构建了一种新型通用去学习算法：一点收缩（OPC）。在图像分类去学习基准上的实证评估表明，OPC 不仅实现了有效的去学习性能，还能更好地抵抗性能恢复攻击和梯度反转攻击。OPC 的独特去学习性能源自其理论基础所强制的深度特征遗忘，揭示了提高机器去学习方法鲁棒性的必要性。 

---
# When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance 

**Title (ZH)**: 当大型语言模型遇到法律：双 lens 分类学、技术进步与伦理治理 

**Authors**: Peizhang Shao, Linrui Xu, Jinxi Wang, Wei Zhou, Xingyu Wu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07748)  

**Abstract**: This paper establishes the first comprehensive review of Large Language Models (LLMs) applied within the legal domain. It pioneers an innovative dual lens taxonomy that integrates legal reasoning frameworks and professional ontologies to systematically unify historical research and contemporary breakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such as contextual reasoning and generative argumentation, surmount traditional limitations by dynamically capturing legal semantics and unifying evidence reasoning. Significant progress is documented in task generalization, reasoning formalization, workflow integration, and addressing core challenges in text processing, knowledge integration, and evaluation rigor via technical innovations like sparse attention mechanisms and mixture-of-experts architectures. However, widespread adoption of LLM introduces critical challenges: hallucination, explainability deficits, jurisdictional adaptation difficulties, and ethical asymmetry. This review proposes a novel taxonomy that maps legal roles to NLP subtasks and computationally implements the Toulmin argumentation framework, thus systematizing advances in reasoning, retrieval, prediction, and dispute resolution. It identifies key frontiers including low-resource systems, multimodal evidence integration, and dynamic rebuttal handling. Ultimately, this work provides both a technical roadmap for researchers and a conceptual framework for practitioners navigating the algorithmic future, laying a robust foundation for the next era of legal artificial intelligence. We have created a GitHub repository to index the relevant papers: this https URL. 

**Abstract (ZH)**: 本文首次全面回顾了大型语言模型（LLMs）在法律领域的应用。它开创了一种创新的双维度分类法，结合了法律推理框架和专业本体，系统地统一了历史研究和当代突破。基于Transformer的LLMs展现出了情境推理和生成论辩等新兴能力，通过动态捕捉法律语义和统一证据推理，克服了传统限制。通过技术创新如稀疏注意机制和专家混合架构，记录了在任务泛化、推理形式化、工作流程集成以及处理文本处理、知识集成和评价严谨性方面的显著进展。然而，LLMs的广泛应用也带来了关键挑战：幻觉、解释不足、司法辖区适应性困难和伦理不对称。本文提出了一种新的分类法，将法律角色映射到NLP子任务，并在计算上实现了Toulmin论证框架，从而系统化了推理、检索、预测和争议解决的进步。它指出了关键前沿领域，包括低资源系统、多模态证据整合和动态反驳处理。最终，本文为研究人员提供了技术路线图，也为从业者导航算法未来提供了概念框架，为法律人工智能的下一个时代奠定了坚实基础。我们已在GitHub上创建了一个存储库来索引相关论文：this https URL。 

---
# Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization 

**Title (ZH)**: 并非所有偏好都适用于训练后优化：选择性对齐策略用于偏好优化 

**Authors**: Zhijin Dong  

**Link**: [PDF](https://arxiv.org/pdf/2507.07725)  

**Abstract**: Post-training alignment of large language models (LLMs) is a critical challenge, as not all tokens contribute equally to model performance. This paper introduces a selective alignment strategy that prioritizes high-impact tokens within preference pairs, leveraging token-level log-probability differences between the current policy and a reference model. By focusing on these informative tokens, our approach reduces computational overhead and enhances alignment fidelity. We further explore the role of reference model quality, demonstrating that stronger reference models significantly improve token selection accuracy and overall optimization effectiveness. Comprehensive experiments on benchmarks such as Arena-Hard and MT-Bench validate the superiority of our Selective-DPO method over standard DPO and distillation-based baselines. Our findings highlight the importance of token-level optimization and reference model selection in advancing preference alignment for LLMs. The code is available at this https URL. 

**Abstract (ZH)**: Post-训练调整大规模语言模型（LLMs）中的选择性对齐策略是一项关键挑战，因为并非所有tokens对模型性能的贡献相当。本文提出了一种选择性对齐策略，优先对当前策略与参考模型之间token级对数概率差异较大的高影响tokens进行对齐。通过聚焦于这些信息性tokens，我们的方法减少了计算开销并提高了对齐精度。我们进一步探讨了参考模型质量的作用，表明更强的参考模型显著提高了token选择准确性并增强了整体优化效果。在Arena-Hard和MT-Bench等基准上的全面实验验证了我们的选择性DPO方法在标准DPO和基于蒸馏的基线方法上的优越性。我们的研究结果突显了在推进LLMs的偏好对齐中token级优化和参考模型选择的重要性。代码可在下面的链接获取。 

---
# Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots 

**Title (ZH)**: 基于自适应高斯混合模型的约束不足的缆驱动并联机器人异常检测 

**Authors**: Julio Garrido, Javier Vales, Diego Silva-Muñiz, Enrique Riveiro, Pablo López-Matencio, Josué Rivera-Andrade  

**Link**: [PDF](https://arxiv.org/pdf/2507.07714)  

**Abstract**: Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation. 

**Abstract (ZH)**: 基于电机扭矩数据的电缆驱动并联机器人异常检测方法 

---
# KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities 

**Title (ZH)**: K^2RAG：一种增强的RAG方法，以提高LLM问答能力 

**Authors**: Hruday Markondapatnaikuni, Basem Suleiman, Abdelkarim Erradi, Shijing Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.07695)  

**Abstract**: Fine-tuning is an immensely resource-intensive process when retraining Large Language Models (LLMs) to incorporate a larger body of knowledge. Although many fine-tuning techniques have been developed to reduce the time and computational cost involved, the challenge persists as LLMs continue to grow in size and complexity. To address this, a new approach to knowledge expansion in LLMs is needed. Retrieval-Augmented Generation (RAG) offers one such alternative by storing external knowledge in a database and retrieving relevant chunks to support question answering. However, naive implementations of RAG face significant limitations in scalability and answer accuracy. This paper introduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome these limitations. Inspired by the divide-and-conquer paradigm, K2RAG integrates dense and sparse vector search, knowledge graphs, and text summarization to improve retrieval quality and system efficiency. The framework also includes a preprocessing step that summarizes the training data, significantly reducing the training time. K2RAG was evaluated using the MultiHopRAG dataset, where the proposed pipeline was trained on the document corpus and tested on a separate evaluation set. Results demonstrated notable improvements over common naive RAG implementations. K2RAG achieved the highest mean answer similarity score of 0.57, and reached the highest third quartile (Q3) similarity of 0.82, indicating better alignment with ground-truth answers. In addition to improved accuracy, the framework proved highly efficient. The summarization step reduced the average training time of individual components by 93%, and execution speed was up to 40% faster than traditional knowledge graph-based RAG systems. K2RAG also demonstrated superior scalability, requiring three times less VRAM than several naive RAG implementations tested in this study. 

**Abstract (ZH)**: Fine-tuning是重新训练大型语言模型（LLMs）以融入更多知识时一个极其资源密集的过程。尽管已经开发出许多细调技术来减少时间和计算成本，但随着LLMs的不断增大和复杂化，这一挑战依然存在。为此，需要一种新的知识扩展方法。检索增强生成（RAG）通过将外部知识存储在数据库中并检索相关片段以支持问题回答提供了一种选择。然而，RAG的原始实现面临显著的可扩展性和答案准确性限制。本文介绍了一种新的框架KeyKnowledgeRAG（K2RAG），旨在克服这些限制。K2RAG借鉴分而治之的理念，结合密集和稀疏向量搜索、知识图谱和文本摘要，以提高检索质量和系统效率。该框架还包括一个预处理步骤，对训练数据进行总结，显著缩短了训练时间。K2RAG使用MultiHopRAG数据集进行了评估，在文档语料库上训练了提议的流水线，并在单独的测试集上进行了测试。结果表明，在常见的RAG原始实现中显示出显著的改进。K2RAG实现了最高的平均答案相似度分数0.57，并达到最高的第三四分位数相似度0.82，表明与真实答案的更好对齐。除了改进的准确率外，该框架还证明了高度的效率。总结步骤将单个组件的平均训练时间减少了93%，执行速度比传统的基于知识图谱的RAG系统快40%。K2RAG还展示了卓越的可扩展性，所需的VRAM比本研究中测试的几种RAG原始实现少三倍。 

---
# Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought 

**Title (ZH)**: 基于推理增强的多模态链式思维解码 

**Authors**: Shin'ya Yamaguchi, Kosuke Nishida, Daiki Chijiwa  

**Link**: [PDF](https://arxiv.org/pdf/2507.07685)  

**Abstract**: Large vision-language models (LVLMs) have demonstrated remarkable capabilities by integrating pre-trained vision encoders with large language models (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting has been adapted for LVLMs to enhance multi-modal reasoning by generating intermediate rationales based on visual and textual inputs. While CoT is assumed to improve grounding and accuracy in LVLMs, our experiments reveal a key challenge: existing LVLMs often ignore the contents of generated rationales in CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as a KL-constrained reward maximization focused on rationale-conditional log-likelihood. As the optimal solution, we propose rationale-enhanced decoding (RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes visual and rationale information by multiplying distinct image-conditional and rationale-conditional next token distributions. Extensive experiments show that RED consistently and significantly improves reasoning over standard CoT and other decoding methods across multiple benchmarks and LVLMs. Our work offers a practical and effective approach to improve both the faithfulness and accuracy of CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded multi-modal systems. 

**Abstract (ZH)**: 大型多模态语言模型（LVLMs）通过结合预训练的视觉编码器和大型语言模型（LLMs）展现出了非凡的能力。类似于单一模态的LLMs，chain-of-thought（CoT）提示也被用于LVLMs，通过基于视觉和文本输入生成中间推理来增强多模态推理。尽管CoT被认为是提高LVLMs中的语义关联和准确性的方法，但我们的实验揭示了一个关键挑战：现有的LVLMs往往忽视CoT推理中生成的推理内容。为了解决这个问题，我们将多模态CoT推理重新表述为一个基于推理条件对数似然的KL约束下的奖励最大化问题。作为最优解，我们提出了推理增强解码（RED），这是一种新颖的即插即用的推理时解码策略。RED通过乘以不同的图像条件和推理条件的下一个词分布，协调视觉和推理信息。广泛的实验证明，RED在多个基准和LVLMs上一致且显著地改善了标准CoT和其它解码方法的推理能力。我们的工作提供了一种实用且有效的途径，以提高LVLMs中CoT推理的真实性和准确性，为更可靠的基于推理的多模态系统铺平了道路。 

---
# Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation 

**Title (ZH)**: 使用预测不确定性估计学习强态的极结构 

**Authors**: Felix Frohnert, Denny Lane B. Sombrillo, Evert van Nieuwenburg, Patrick Emonts  

**Link**: [PDF](https://arxiv.org/pdf/2507.07668)  

**Abstract**: Matching theoretical predictions to experimental data remains a central challenge in hadron spectroscopy. In particular, the identification of new hadronic states is difficult, as exotic signals near threshold can arise from a variety of physical mechanisms. A key diagnostic in this context is the pole structure of the scattering amplitude, but different configurations can produce similar signatures. The mapping between pole configurations and line shapes is especially ambiguous near the mass threshold, where analytic control is limited. In this work, we introduce an uncertainty-aware machine learning approach for classifying pole structures in $S$-matrix elements. Our method is based on an ensemble of classifier chains that provide both epistemic and aleatoric uncertainty estimates. We apply a rejection criterion based on predictive uncertainty, achieving a validation accuracy of nearly $95\%$ while discarding only a small fraction of high-uncertainty predictions. Trained on synthetic data with known pole structures, the model generalizes to previously unseen experimental data, including enhancements associated with the $P_{c\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole structure, representing the presence of a genuine compact pentaquark in the presence of a higher channel virtual state pole with non-vanishing width. While evaluated on this particular state, our framework is broadly applicable to other candidate hadronic states and offers a scalable tool for pole structure inference in scattering amplitudes. 

**Abstract (ZH)**: 将理论预测与实验数据匹配仍然是强子谱学中的一个核心挑战。特别是在识别新的强子态时困难重重，因为阈值附近的奇异信号可能源于多种物理机制。在此背景下，散射振幅的极点结构是一个关键诊断手段，但不同配置可以产生类似的特征。极点配置与线型之间的映射在质量阈值附近尤其含糊，此时的分析控制有限。在本文中，我们提出了一种考虑不确定性的人工智能方法，用于分类 S-矩阵元素中的极点结构。我们的方法基于分类链的集合，提供both 知识性和 aleatoric 不确定性估计。我们基于预测不确定性引入了一个剔除标准，在保持近95%验证准确率的同时丢弃了少量高不确定性预测。该模型在具有已知极点结构的合成数据上训练，能够泛化到以前未见过的实验数据，包括由LHCb观测到的$P_{c\bar{c}}(4312)^+$态带来的增强。通过这种方法，我们推断出一个四极点结构，表明在较高通道虚极点具有非零宽度的情况下，确实存在一个真实的紧密五夸克态。虽然针对特定状态进行了评估，但该框架对其他候选强子态广泛适用，并提供了散射振幅中极点结构推断的可扩展工具。 

---
# TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection 

**Title (ZH)**: TransformEEG: 向提高基于深度学习的EEG帕金森病检测模型泛化能力方向的努力 

**Authors**: Federico Del Pup, Riccardo Brun, Filippo Iotti, Edoardo Paccagnella, Mattia Pezzato, Sabrina Bertozzo, Andrea Zanola, Louis Fabrice Tshimanga, Henning Müller, Manfredo Atzori  

**Link**: [PDF](https://arxiv.org/pdf/2507.07622)  

**Abstract**: Electroencephalography (EEG) is establishing itself as an important, low-cost, noninvasive diagnostic tool for the early detection of Parkinson's Disease (PD). In this context, EEG-based Deep Learning (DL) models have shown promising results due to their ability to discover highly nonlinear patterns within the signal. However, current state-of-the-art DL models suffer from poor generalizability caused by high inter-subject variability. This high variability underscores the need for enhancing model generalizability by developing new architectures better tailored to EEG data. This paper introduces TransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's disease detection using EEG data. Unlike transformer models based on the EEGNet structure, TransformEEG incorporates a depthwise convolutional tokenizer. This tokenizer is specialized in generating tokens composed by channel-specific features, which enables more effective feature mixing within the self-attention layers of the transformer encoder. To evaluate the proposed model, four public datasets comprising 290 subjects (140 PD patients, 150 healthy controls) were harmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out (N-LNSO) cross-validation was performed to provide an unbiased comparison against seven other consolidated EEG deep learning models. TransformEEG achieved the highest balanced accuracy's median (78.45%) as well as the lowest interquartile range (6.37%) across all the N-LNSO partitions. When combined with data augmentation and threshold correction, median accuracy increased to 80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG produces more consistent and less skewed results. It demonstrates a substantial reduction in variability and more reliable PD detection using EEG data compared to the other investigated models. 

**Abstract (ZH)**: 基于EEG的TransformEEG：用于帕金森病检测的混合卷积-变压器模型 

---
# Bayesian Discrete Diffusion Beats Autoregressive Perplexity 

**Title (ZH)**: 贝叶斯离散扩散优于自回归困惑度 

**Authors**: Cooper Doyle  

**Link**: [PDF](https://arxiv.org/pdf/2507.07586)  

**Abstract**: We reveal a hidden Bayesian core of discrete-diffusion language models by showing that the expected denoiser output under the forward masking distribution recovers the exact posterior over clean tokens. Under minimal assumptions, Monte Carlo marginalization over K independent corruptions converges to this posterior at rate O(1/sqrt(K)), yielding a simple proof of consistency and finite-sample error bounds. Building on this insight, we introduce a lightweight inference-time ensemble that averages K mask-and-denoise passes to obtain posterior-aware token probabilities and uncertainty estimates at no extra training cost. On WikiText-2, our method achieves test perplexity 8.8 with K=8, versus 20.3 for GPT-2 Small, despite using a model of comparable size. Code is available at this https URL. 

**Abstract (ZH)**: 我们通过证明前向遮掩分布下预期去噪器输出恢复了干净词件的精确后验分布，揭示了离散扩散语言模型中的隐式贝叶斯核心。在最小的假设条件下，K个独立污染的蒙特卡洛边缘化收敛于此后验分布，以线性率O(1/sqrt(K))收敛，从而给出了一致性和有限样本误差界的一个简单证明。在此基础上，我们提出了一种轻量级的推理时集成方法，通过K次掩蔽与去噪处理的平均值获得后验感知词件概率和不确定性估计，而不增加额外的训练成本。在WikiText-2上，我们的方法使用K=8时的测试困惑度为8.8，而GPT-2 Small为20.3，尽管所用模型规模相当。代码可在以下网址获取。 

---
# NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning 

**Title (ZH)**: NexViTAD: 通过视觉基础模型和多任务学习的少样本无监督跨域缺陷检测 

**Authors**: Tianwei Mu, Feiyu Duan, Bo Zhou, Dan Xue, Manhong Huang  

**Link**: [PDF](https://arxiv.org/pdf/2507.07579)  

**Abstract**: This paper presents a novel few-shot cross-domain anomaly detection framework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based on vision foundation models, which effectively addresses domain-shift challenges in industrial anomaly detection through innovative shared subspace projection mechanisms and multi-task learning (MTL) module. The main innovations include: (1) a hierarchical adapter module that adaptively fuses complementary features from Hiera and DINO-v2 pre-trained models, constructing more robust feature representations; (2) a shared subspace projection strategy that enables effective cross-domain knowledge transfer through bottleneck dimension constraints and skip connection mechanisms; (3) a MTL Decoder architecture supports simultaneous processing of multiple source domains, significantly enhancing model generalization capabilities; (4) an anomaly score inference method based on Sinkhorn-K-means clustering, combined with Gaussian filtering and adaptive threshold processing for precise pixel level. Valuated on the MVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of 97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing other recent models, marking a transformative advance in cross-domain defect detection. 

**Abstract (ZH)**: 基于视觉基础模型的新型少样本跨域异常检测框架：NexViTAD 

---
# Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation 

**Title (ZH)**: 单模态到多模态对齐的多模态大型语言模型在文档图像机器翻译中的应用 

**Authors**: Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2507.07572)  

**Abstract**: Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an image-only encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios. 

**Abstract (ZH)**: 文档图像机器翻译（DIMT）旨在翻译文档图像内的文本，由于训练数据有限和视觉信息与文本信息的复杂交互，面临着泛化能力的挑战。为应对这些挑战，我们提出了M4Doc，这是一种新型的单模态到多模态对齐框架，利用多模态大型语言模型（MLLMs）。M4Doc通过在大规模文档图像数据集上预训练的MLLM的多模态表示，对齐仅图像编码器。这种对齐在训练过程中使轻量级DIMT模型能够学习关键的视觉-文本相关性。在推理过程中，M4Doc跳过了MLLM，保持计算效率的同时受益于其多模态知识。全面的实验结果显示，在跨领域泛化和具有挑战性的文档图像场景中，翻译质量有了显著提升。 

---
# ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing 

**Title (ZH)**: ArchiveGPT：基于视觉语言模型的图像分类目录构建的人本评估 

**Authors**: Line Abele, Gerrit Anders, Tolgahan Aydın, Jürgen Buder, Helen Fischer, Dominik Kimmel, Markus Huff  

**Link**: [PDF](https://arxiv.org/pdf/2507.07551)  

**Abstract**: The accelerating growth of photographic collections has outpaced manual cataloguing, motivating the use of vision language models (VLMs) to automate metadata generation. This study examines whether Al-generated catalogue descriptions can approximate human-written quality and how generative Al might integrate into cataloguing workflows in archival and museum collections. A VLM (InternVL2) generated catalogue descriptions for photographic prints on labelled cardboard mounts with archaeological content, evaluated by archive and archaeology experts and non-experts in a human-centered, experimental framework. Participants classified descriptions as AI-generated or expert-written, rated quality, and reported willingness to use and trust in AI tools. Classification performance was above chance level, with both groups underestimating their ability to detect Al-generated descriptions. OCR errors and hallucinations limited perceived quality, yet descriptions rated higher in accuracy and usefulness were harder to classify, suggesting that human review is necessary to ensure the accuracy and quality of catalogue descriptions generated by the out-of-the-box model, particularly in specialized domains like archaeological cataloguing. Experts showed lower willingness to adopt AI tools, emphasizing concerns on preservation responsibility over technical performance. These findings advocate for a collaborative approach where AI supports draft generation but remains subordinate to human verification, ensuring alignment with curatorial values (e.g., provenance, transparency). The successful integration of this approach depends not only on technical advancements, such as domain-specific fine-tuning, but even more on establishing trust among professionals, which could both be fostered through a transparent and explainable AI pipeline. 

**Abstract (ZH)**: 摄影收藏的快速增长已超出手工目录编排的能力，促使使用视觉语言模型（VLMs）自动化元数据生成。本研究探讨AI生成的目录描述能否接近人类撰写的质量，以及生成式AI如何融入档案和博物馆收藏的目录编排工作流程中。视觉语言模型（InternVL2）为带有考古内容的标Labels纸质照片生成目录描述，并由档案和考古专家及非专家在以人类为中心的实验框架下进行评估。参与者将描述分类为AI生成或专家撰写，评估质量，并报告使用和信任AI工具的意愿。分类性能超过随机水平，两组均低估了检测AI生成描述的能力。OCR错误和幻觉限制了感知质量，但准确性较高且更具实用性的描述更难以分类，表明需要人类审核以确保迁移到现成模型生成的目录描述的准确性和质量，特别是在考古目录编目等专业化领域。专家对采用AI工具的意愿较低，强调保护责任而非技术性能。这些发现倡导一种协作方式，在这种方式中，AI支持草稿生成但仍次于人类验证，以确保与策展价值（如来源、透明度）的对齐。这一方法的成功整合不仅取决于技术进步（如领域特定微调），更取决于在专业人士之间建立信任，而透明且可解释的AI管道可以促进这种信任的建立。 

---
# The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora 

**Title (ZH)**: 跨语言代价：阿拉伯语-英语语料库中RAG的检索偏差 

**Authors**: Chen Amiraz, Yaroslav Fyodorov, Elad Haramaty, Zohar Karnin, Liane Lewin-Eytan  

**Link**: [PDF](https://arxiv.org/pdf/2507.07543)  

**Abstract**: Cross-lingual retrieval-augmented generation (RAG) is a critical capability for retrieving and generating answers across languages. Prior work in this context has mostly focused on generation and relied on benchmarks derived from open-domain sources, most notably Wikipedia. In such settings, retrieval challenges often remain hidden due to language imbalances, overlap with pretraining data, and memorized content. To address this gap, we study Arabic-English RAG in a domain-specific setting using benchmarks derived from real-world corporate datasets. Our benchmarks include all combinations of languages for the user query and the supporting document, drawn independently and uniformly at random. This enables a systematic study of multilingual retrieval behavior.
Our findings reveal that retrieval is a critical bottleneck in cross-lingual domain-specific scenarios, with significant performance drops occurring when the user query and supporting document languages differ. A key insight is that these failures stem primarily from the retriever's difficulty in ranking documents across languages. Finally, we propose a simple retrieval strategy that addresses this source of failure by enforcing equal retrieval from both languages, resulting in substantial improvements in cross-lingual and overall performance. These results highlight meaningful opportunities for improving multilingual retrieval, particularly in practical, real-world RAG applications. 

**Abstract (ZH)**: 跨语言检索增强生成（RAG）：一种在多种语言之间检索和生成答案的关键能力。先前在这方面的研究主要集中在生成上，并依赖于来自开放域的基准，最著名的是Wikipedia。在这些设置中，由于语言不平衡、与预训练数据的重叠以及记忆化的内容，检索挑战往往会被掩盖。为了解决这一差距，我们使用来自真实的企业数据集的基准，在特定领域中研究阿拉伯语-英语的RAG。我们的基准包括用户查询和支撑文档所有语言的组合，独立且均匀随机抽取。这使得对多语言检索行为进行系统研究成为可能。我们的研究发现表明，在跨语言特定领域场景中，检索是关键的瓶颈，当用户查询和支持文档的语言不同时，性能会显著下降。一个关键见解是，这些失败主要源于检索器在跨语言排名文档方面的困难。最后，我们提出了一种简单的检索策略，通过强制从两种语言中等量检索来解决这一失败原因，从而在跨语言和总体性能上取得了显著改进。这些结果突显了改进多语言检索的实际机会，特别是在实际的跨语言RAG应用中。 

---
# CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text 

**Title (ZH)**: CEA-LIST参加CheckThat! 2025：评估LLMs在文本中检测偏见和观点的能力 

**Authors**: Akram Elbouanani, Evan Dufraisse, Aboubacar Tuo, Adrian Popescu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07539)  

**Abstract**: This paper presents a competitive approach to multilingual subjectivity detection using large language models (LLMs) with few-shot prompting. We participated in Task 1: Subjectivity of the CheckThat! 2025 evaluation campaign. We show that LLMs, when paired with carefully designed prompts, can match or outperform fine-tuned smaller language models (SLMs), particularly in noisy or low-quality data settings. Despite experimenting with advanced prompt engineering techniques, such as debating LLMs and various example selection strategies, we found limited benefit beyond well-crafted standard few-shot prompts. Our system achieved top rankings across multiple languages in the CheckThat! 2025 subjectivity detection task, including first place in Arabic and Polish, and top-four finishes in Italian, English, German, and multilingual tracks. Notably, our method proved especially robust on the Arabic dataset, likely due to its resilience to annotation inconsistencies. These findings highlight the effectiveness and adaptability of LLM-based few-shot learning for multilingual sentiment tasks, offering a strong alternative to traditional fine-tuning, particularly when labeled data is scarce or inconsistent. 

**Abstract (ZH)**: 本研究提出了一个使用大型语言模型（LLMs）和少量示例提示进行多语言主观性检测的竞争性方法。我们在CheckThat! 2025评价竞赛的任务1：主观性方面进行了参与。我们展示了在精心设计提示的作用下，大型语言模型可以匹配甚至超越微调的小型语言模型（SLMs），特别是在嘈杂或低质量数据环境下。尽管尝试了包括论辩LLMs和各种示例选择策略在内的高级提示工程技术，我们发现其改进效果有限，仅限于精心设计的标准少量示例提示。我们的系统在CheckThat! 2025主观性检测任务的多种语言中获得了高排名，包括阿拉伯语和波兰语的第一名，以及意大利语、英语、德语和多语言轨道的前四名。特别地，我们的方法在阿拉伯语数据集上表现尤为 robust，可能与其对标注不一致的抵抗力有关。这些发现突显了基于LLM的少量示例学习在多语言情感任务中的有效性和适应性，为传统微调提供了强有力的选择，特别是在标注数据稀缺或不一致的情况下。 

---
# Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings 

**Title (ZH)**: 神经概念验证器：通过概念编码扩展证明-验证游戏 

**Authors**: Berkant Turan, Suhrab Asadulla, David Steinmann, Wolfgang Stammer, Sebastian Pokutta  

**Link**: [PDF](https://arxiv.org/pdf/2507.07532)  

**Abstract**: While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI. 

**Abstract (ZH)**: 基于概念验证的游戏在高维复杂输入的非线性可解释分类中的统一框架 

---
# Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System 

**Title (ZH)**: 面向现实世界中文心理支持对话：CPsDD数据集与共生演化多Agent系统 

**Authors**: Yuanchen Shi, Longyin Zhang, Fang Kong  

**Link**: [PDF](https://arxiv.org/pdf/2507.07509)  

**Abstract**: The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets. 

**Abstract (ZH)**: 由于不断增加的压力导致对心理支持的需求增长，暴露了相关数据集的稀缺性，尤其是在非英语语言中。为解决这一问题，我们提出了一种框架，利用有限的真实世界数据和专家知识对两种大型语言模型：对话生成器和对话修改器进行微调。生成器根据预定义的路径创建大规模的心理咨询对话，指导系统应答策略和用户交互，为基础有效支持提供支撑。修改器则调整这些对话以符合真实世界数据的质量。通过自动化和人工审核，我们构建了包含68,000对话的中文心理支持对话数据集（CPsDD），涵盖了13个组别、16种心理问题、13种原因和12种支持重点。此外，我们还引入了全面代理对话支持系统（CADSS），其中分析器分析用户特征，摘要器压缩对话历史，规划器选择策略，支持者生成同理心回应。策略预测和情感支持对话（ESC）任务的实验结果表明，CADSS在CPsDD和ESConv数据集上的性能达到最新水平。 

---
# Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models 

**Title (ZH)**: 幻觉站点：关于基于Transformer的语言模型的一些基本限制 

**Authors**: Varin Sikka, Vishal Sikka  

**Link**: [PDF](https://arxiv.org/pdf/2507.07505)  

**Abstract**: With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work. 

**Abstract (ZH)**: 基于Transformer的语言模型在AI中的广泛应用引起了对其能力界限的关注，尤其是所谓的幻觉现象，即语言模型在某些主题上被提示时提供虚假的、事实错误的或无意义的信息。此外，人们对语言模型的代理用途也越来越感兴趣，即使用语言模型创建能够自主或半自主地执行各种任务（包括实际世界中的应用任务）的代理。这使得理解语言模型能够和不能执行的任务类型变得尤为重要。我们从语言模型推理的计算复杂性角度探讨了这一主题。我们展示了语言模型在特定复杂度以上无法执行计算任务和代理任务，也无法验证复杂度以上任务的准确性。我们举例说明了这一点，然后讨论了这项工作的一些后果。 

---
# PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving 

**Title (ZH)**: 计划调优：用于复杂问题解决的逐步规划学习的后训练语言模型 

**Authors**: Mihir Parmar, Palash Goyal, Xin Liu, Yiwen Song, Mingyang Ling, Chitta Baral, Hamid Palangi, Tomas Pfister  

**Link**: [PDF](https://arxiv.org/pdf/2507.07495)  

**Abstract**: Recently, decomposing complex problems into simple subtasks--a crucial part of human-like natural planning--to solve the given problem has significantly boosted the performance of large language models (LLMs). However, leveraging such planning structures during post-training to boost the performance of smaller open-source LLMs remains underexplored. Motivated by this, we introduce PLAN-TUNING, a unified post-training framework that (i) distills synthetic task decompositions (termed "planning trajectories") from large-scale LLMs and (ii) fine-tunes smaller models via supervised and reinforcement-learning objectives designed to mimic these planning processes to improve complex reasoning. On GSM8k and the MATH benchmarks, plan-tuned models outperform strong baselines by an average $\sim7\%$. Furthermore, plan-tuned models show better generalization capabilities on out-of-domain datasets, with average $\sim10\%$ and $\sim12\%$ performance improvements on OlympiadBench and AIME 2024, respectively. Our detailed analysis demonstrates how planning trajectories improves complex reasoning capabilities, showing that PLAN-TUNING is an effective strategy for improving task-specific performance of smaller LLMs. 

**Abstract (ZH)**: 最近，将复杂问题分解为简单子任务——这是类人类自然规划的关键组成部分——已显著提升了大规模语言模型（LLMs）的性能。然而，在后续训练中利用此类规划结构来提升较小规模开源LLMs的性能仍处于探索阶段。受此启发，我们引入了PLAN-TUNING，这是一种统一的后续训练框架，旨在（i）从大规模LLMs中提炼合成任务分解（称为“规划轨迹”），并（ii）通过模拟这些规划过程设计的监督学习和强化学习目标对较小模型进行微调，以提高复杂推理能力。在GSM8k和MATH基准测试中，规划微调模型平均性能优于强大基线约7%。此外，规划微调模型在域外数据集中的泛化能力更强，在OlympiadBench和AIME 2024中的性能平均分别提高了约10%和12%。我们的详细分析表明，规划轨迹如何提高复杂推理能力，表明PLAN-TUNING是提高较小LLMs特定任务性能的有效策略。 

---
# Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning 

**Title (ZH)**: 解决标记空间梯度冲突：基于标记空间操作的Transformer多任务学习 

**Authors**: Wooseong Jeong, Kuk-Jin Yoon  

**Link**: [PDF](https://arxiv.org/pdf/2507.07485)  

**Abstract**: Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models. 

**Abstract (ZH)**: 动态令牌调制与扩展（DTME-MTL）：一种适用于任何基于Transformer的多任务学习架构的框架 

---
# Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models 

**Title (ZH)**: 机器aphael：表征大型语言模型中对真理的 emergent 忽视 

**Authors**: Kaiqu Liang, Haimin Hu, Xuandong Zhao, Dawn Song, Thomas L. Griffiths, Jaime Fernández Fisac  

**Link**: [PDF](https://arxiv.org/pdf/2507.07484)  

**Abstract**: Bullshit, as conceptualized by philosopher Harry Frankfurt, refers to statements made without regard to their truth value. While previous work has explored large language model (LLM) hallucination and sycophancy, we propose machine bullshit as an overarching conceptual framework that can allow researchers to characterize the broader phenomenon of emergent loss of truthfulness in LLMs and shed light on its underlying mechanisms. We introduce the Bullshit Index, a novel metric quantifying LLMs' indifference to truth, and propose a complementary taxonomy analyzing four qualitative forms of bullshit: empty rhetoric, paltering, weasel words, and unverified claims. We conduct empirical evaluations on the Marketplace dataset, the Political Neutrality dataset, and our new BullshitEval benchmark (2,400 scenarios spanning 100 AI assistants) explicitly designed to evaluate machine bullshit. Our results demonstrate that model fine-tuning with reinforcement learning from human feedback (RLHF) significantly exacerbates bullshit and inference-time chain-of-thought (CoT) prompting notably amplify specific bullshit forms, particularly empty rhetoric and paltering. We also observe prevalent machine bullshit in political contexts, with weasel words as the dominant strategy. Our findings highlight systematic challenges in AI alignment and provide new insights toward more truthful LLM behavior. 

**Abstract (ZH)**: 机器bullshit：一种探究大语言模型 emergent 丧失真实性的总体概念框架 

---
# Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision 

**Title (ZH)**: Objectomaly: 具有结构一致性和边界精度的物体意识分割方法异类物质区分 

**Authors**: Jeonghoon Song, Sunghun Kim, Jaegyun Im, Byeongjoon Noh  

**Link**: [PDF](https://arxiv.org/pdf/2507.07460)  

**Abstract**: Out-of-Distribution (OoD) segmentation is critical for safety-sensitive applications like autonomous driving. However, existing mask-based methods often suffer from boundary imprecision, inconsistent anomaly scores within objects, and false positives from background noise. We propose \textbf{\textit{Objectomaly}}, an objectness-aware refinement framework that incorporates object-level priors. Objectomaly consists of three stages: (1) Coarse Anomaly Scoring (CAS) using an existing OoD backbone, (2) Objectness-Aware Score Calibration (OASC) leveraging SAM-generated instance masks for object-level score normalization, and (3) Meticulous Boundary Precision (MBP) applying Laplacian filtering and Gaussian smoothing for contour refinement. Objectomaly achieves state-of-the-art performance on key OoD segmentation benchmarks, including SMIYC AnomalyTrack/ObstacleTrack and RoadAnomaly, improving both pixel-level (AuPRC up to 96.99, FPR$_{95}$ down to 0.07) and component-level (F1$-$score up to 83.44) metrics. Ablation studies and qualitative results on real-world driving videos further validate the robustness and generalizability of our method. Code will be released upon publication. 

**Abstract (ZH)**: Out-of-Distribution (OoD) 分段对于自动驾驶等安全敏感应用至关重要。现有的基于掩码的方法通常存在边界不清、对象内异常得分不一致以及背景噪声引起的假阳性等问题。我们提出了一种名为 \textbf{\textit{Objectomaly}} 的对象意识精炼框架，该框架结合了对象级别的先验知识。Objectomaly 包含三个阶段：（1）粗略异常评分（CAS）使用现有的 OoD 主干网络，（2）对象意识得分校准（OASC）利用 SAM 生成的实例掩码进行对象级别得分规范化，以及（3）细致边界精度（MBP）应用拉普拉斯滤波和高斯平滑进行轮廓精炼。Objectomaly 在关键的 OoD 分段基准数据集 SMIYC AnomalyTrack/ObstacleTrack 和 RoadAnomaly 上取得了最先进的性能，提升了像素级（AuPRC 最高 96.99，FPR$_{95}$ 最低至 0.07）和组件级（F1-score 最高 83.44）的指标。在真实驾驶视频上的消融研究和定性结果进一步验证了该方法的鲁棒性和泛化能力。代码将在发表后公开。 

---
# Bluish Veil Detection and Lesion Classification using Custom Deep Learnable Layers with Explainable Artificial Intelligence (XAI) 

**Title (ZH)**: 使用具有可解释人工智能(XAI)的自定义可学习层进行蓝膜检测与病变分类 

**Authors**: M. A. Rasel, Sameem Abdul Kareem, Zhenli Kwan, Shin Shen Yong, Unaizah Obaidellah  

**Link**: [PDF](https://arxiv.org/pdf/2507.07453)  

**Abstract**: Melanoma, one of the deadliest types of skin cancer, accounts for thousands of fatalities globally. The bluish, blue-whitish, or blue-white veil (BWV) is a critical feature for diagnosing melanoma, yet research into detecting BWV in dermatological images is limited. This study utilizes a non-annotated skin lesion dataset, which is converted into an annotated dataset using a proposed imaging algorithm based on color threshold techniques on lesion patches and color palettes. A Deep Convolutional Neural Network (DCNN) is designed and trained separately on three individual and combined dermoscopic datasets, using custom layers instead of standard activation function layers. The model is developed to categorize skin lesions based on the presence of BWV. The proposed DCNN demonstrates superior performance compared to conventional BWV detection models across different datasets. The model achieves a testing accuracy of 85.71% on the augmented PH2 dataset, 95.00% on the augmented ISIC archive dataset, 95.05% on the combined augmented (PH2+ISIC archive) dataset, and 90.00% on the Derm7pt dataset. An explainable artificial intelligence (XAI) algorithm is subsequently applied to interpret the DCNN's decision-making process regarding BWV detection. The proposed approach, coupled with XAI, significantly improves the detection of BWV in skin lesions, outperforming existing models and providing a robust tool for early melanoma diagnosis. 

**Abstract (ZH)**: 黑色素瘤，一种 deadliest 的皮肤癌类型，全球范围内导致数千人死亡。蓝白色或蓝白 veil（BWV）是诊断黑色素瘤的关键特征，但由于对在皮肤影像中检测 BWV 的研究有限，本研究利用了一个未标注的皮肤病变数据集，并通过基于颜色阈值技术提出的一种成像算法将其转换为标注数据集。设计并分别在三个个体和组合的皮肤镜影像数据集上训练了一个深度卷积神经网络（DCNN），使用自定义层而非标准激活函数层。该模型旨在根据 BWV 的存在对皮肤病变进行分类。提出的 DCNN 在不同数据集上的性能优于传统 BWV 检测模型。该模型在增强的 PH2 数据集上的测试准确率为 85.71%，在增强的 ISIC 存档数据集上的测试准确率为 95.00%，在联合增强（PH2+ISIC 存档）数据集上的测试准确率为 95.05%，在 Derm7pt 数据集上的测试准确率为 90.00%。随后应用了解释型人工智能（XAI）算法来解释 DCNN 在 BWV 检测中的决策过程。结合 XAI 的提出方法显著提高了在皮肤病变中检测 BWV 的性能，优于现有的模型，并提供了一个早期诊断黑色素瘤的稳健工具。 

---
# Towards Interpretable Time Series Foundation Models 

**Title (ZH)**: 面向可解释的时间序列基础模型 

**Authors**: Matthieu Boileau, Philippe Helluy, Jeremy Pawlus, Svitlana Vyetrenko  

**Link**: [PDF](https://arxiv.org/pdf/2507.07439)  

**Abstract**: In this paper, we investigate the distillation of time series reasoning capabilities into small, instruction-tuned language models as a step toward building interpretable time series foundation models. Leveraging a synthetic dataset of mean-reverting time series with systematically varied trends and noise levels, we generate natural language annotations using a large multimodal model and use these to supervise the fine-tuning of compact Qwen models. We introduce evaluation metrics that assess the quality of the distilled reasoning - focusing on trend direction, noise intensity, and extremum localization - and show that the post-trained models acquire meaningful interpretive capabilities. Our results highlight the feasibility of compressing time series understanding into lightweight, language-capable models suitable for on-device or privacy-sensitive deployment. This work contributes a concrete foundation toward developing small, interpretable models that explain temporal patterns in natural language. 

**Abstract (ZH)**: 本文研究了将时间序列推理能力精炼至小型、指令调优的语言模型，作为构建可解释的时间序列基础模型的一步。通过利用一个系统地变化趋势和噪声水平的均值回复时间序列合成数据集，我们使用一个大型多模态模型生成自然语言注释，并利用这些注释监督紧凑型Qwen模型的微调。我们引入了评估精炼推理质量的指标，重点关注趋势方向、噪声强度和极值定位，并展示了后训练模型获得了有意义的解释能力。我们的结果突显了将时间序列理解压缩至轻量级、具备语言能力的模型的可行性，这些模型适合于设备端或隐私敏感部署。这项工作为开发能够用自然语言解释时间模式的小型、可解释模型奠定了具体的理论基础。 

---
# SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data 

**Title (ZH)**: SynthEHR-Eviction: 通过LLM增强的合成EHR数据优化社会健康状况撤离检测 

**Authors**: Zonghai Yao, Youxia Zhao, Avijit Mitra, David A. Levy, Emily Druhl, Jack Tsai, Hong Yu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07421)  

**Abstract**: Eviction is a significant yet understudied social determinants of health (SDoH), linked to housing instability, unemployment, and mental health. While eviction appears in unstructured electronic health records (EHRs), it is rarely coded in structured fields, limiting downstream applications. We introduce SynthEHR-Eviction, a scalable pipeline combining LLMs, human-in-the-loop annotation, and automated prompt optimization (APO) to extract eviction statuses from clinical notes. Using this pipeline, we created the largest public eviction-related SDoH dataset to date, comprising 14 fine-grained categories. Fine-tuned LLMs (e.g., Qwen2.5, LLaMA3) trained on SynthEHR-Eviction achieved Macro-F1 scores of 88.8% (eviction) and 90.3% (other SDoH) on human validated data, outperforming GPT-4o-APO (87.8%, 87.3%), GPT-4o-mini-APO (69.1%, 78.1%), and BioBERT (60.7%, 68.3%), while enabling cost-effective deployment across various model sizes. The pipeline reduces annotation effort by over 80%, accelerates dataset creation, enables scalable eviction detection, and generalizes to other information extraction tasks. 

**Abstract (ZH)**: Eviction是一个重要的但研究不足的社会决定因素（SDoH），与住房不稳定、失业和心理健康有关。虽然Eviction出现在非结构化的电子健康记录(EHRs)中，但很少在结构化字段中编码，限制了下游应用。我们介绍了SynthEHR-Eviction，这是一个结合了大型语言模型、人工辅助标注和自动提示优化（APO）的可扩展管道，用于从临床笔记中提取Eviction状态。使用该管道，我们创建了迄今为止最大的公共Eviction相关的SDoH数据集，包含14个细粒度类别。经过微调的大型语言模型（例如Qwen2.5、LLaMA3）在SynthEHR-Eviction上训练，在人类验证的数据上实现了宏F1分数88.8%（Eviction）和90.3%（其他SDoH），优于GPT-4o-APO（87.8%，87.3%）、GPT-4o-mini-APO（69.1%，78.1%）和BioBERT（60.7%，68.3%），同时能够在各种模型大小上实现成本效益部署。该管道将标注工作量减少了超过80%，加速了数据集的创建，实现了可扩展的Eviction检测，并适用于其他信息提取任务。 

---
# MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning 

**Title (ZH)**: MedReadCtrl: 基于易读性控制指令学习的个性化医疗文本生成 

**Authors**: Hieu Tran, Zonghai Yao, Won Seok Jang, Sharmin Sultana, Allen Chang, Yuan Zhang, Hong Yu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07419)  

**Abstract**: Generative AI has demonstrated strong potential in healthcare, from clinical decision support to patient-facing chatbots that improve outcomes. A critical challenge for deployment is effective human-AI communication, where content must be both personalized and understandable. We introduce MedReadCtrl, a readability-controlled instruction tuning framework that enables LLMs to adjust output complexity without compromising meaning. Evaluations of nine datasets and three tasks across medical and general domains show that MedReadCtrl achieves significantly lower readability instruction-following errors than GPT-4 (e.g., 1.39 vs. 1.59 on ReadMe, p<0.001) and delivers substantial gains on unseen clinical tasks (e.g., +14.7 ROUGE-L, +6.18 SARI on MTSamples). Experts consistently preferred MedReadCtrl (71.7% vs. 23.3%), especially at low literacy levels. These gains reflect MedReadCtrl's ability to restructure clinical content into accessible, readability-aligned language while preserving medical intent, offering a scalable solution to support patient education and expand equitable access to AI-enabled care. 

**Abstract (ZH)**: 生成式AI在医疗领域的应用展示了强大的潜力，从临床决策支持到面向患者的聊天机器人，以提高治疗效果。部署中的关键挑战是有效的人工智能通信，内容必须既个性化又易于理解。我们介绍了一种可控制可读性的指令调优框架MedReadCtrl，使大规模语言模型能够在不损害意义的情况下调整输出复杂度。在医学和一般领域的九个数据集和三项任务上的评估表明，MedReadCtrl在可读性指令遵循错误方面显著低于GPT-4（例如，在ReadMe上的1.39 vs. 1.59，p<0.001），并在未见过的临床任务上取得了显著的进步（例如，ROUGE-L提高了14.7，SARI提高了6.18）。专家一致更偏好MedReadCtrl（71.7% vs. 23.3%），尤其是在低文化水平的情况下。这些进步反映了MedReadCtrl能够将临床内容重新组织成易于理解的、与可读性对齐的语言，同时保留医疗意图，提供了支持患者教育并扩大AI辅助医疗服务可及性的可扩展解决方案。 

---
# Optimal Auction Design in the Joint Advertising 

**Title (ZH)**: 联合广告中的最优拍卖设计 

**Authors**: Yang Li, Yuchao Ma, Qi Qi  

**Link**: [PDF](https://arxiv.org/pdf/2507.07418)  

**Abstract**: Online advertising is a vital revenue source for major internet platforms. Recently, joint advertising, which assigns a bundle of two advertisers in an ad slot instead of allocating a single advertiser, has emerged as an effective method for enhancing allocation efficiency and revenue. However, existing mechanisms for joint advertising fail to realize the optimality, as they tend to focus on individual advertisers and overlook bundle structures. This paper identifies an optimal mechanism for joint advertising in a single-slot setting. For multi-slot joint advertising, we propose \textbf{BundleNet}, a novel bundle-based neural network approach specifically designed for joint advertising. Our extensive experiments demonstrate that the mechanisms generated by \textbf{BundleNet} approximate the theoretical analysis results in the single-slot setting and achieve state-of-the-art performance in the multi-slot setting. This significantly increases platform revenue while ensuring approximate dominant strategy incentive compatibility and individual rationality. 

**Abstract (ZH)**: 联合广告是一种重要的在线广告收入来源。近年来，联合广告通过在一个广告位置分配一个广告包而不是分配单一广告商，已成为提高分配效率和收入的有效方法。然而，现有的联合广告机制未能实现最优性，因为它们往往专注于单一广告商而忽视了广告包结构。本文在单槽设置中提出了联合广告的最优机制。对于多槽联合广告，我们提出了一种名为BundleNet的新颖基于包的神经网络方法，专门用于联合广告。我们的大量实验表明，BundleNet生成的机制在单槽设置中接近理论分析结果，并在多槽设置中实现了最先进的性能。这显著提高了平台收入，同时保证了近似的支配策略激励相容性和个体理性。 

---
# May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks 

**Title (ZH)**: 请求您的注意：基于架构意识的攻击破解基于提示注入的微调防御 

**Authors**: Nishit V. Pandya, Andrey Labunets, Sicun Gao, Earlence Fernandes  

**Link**: [PDF](https://arxiv.org/pdf/2507.07417)  

**Abstract**: A popular class of defenses against prompt injection attacks on large language models (LLMs) relies on fine-tuning the model to separate instructions and data, so that the LLM does not follow instructions that might be present with data. There are several academic systems and production-level implementations of this idea. We evaluate the robustness of this class of prompt injection defenses in the whitebox setting by constructing strong optimization-based attacks and showing that the defenses do not provide the claimed security properties. Specifically, we construct a novel attention-based attack algorithm for text-based LLMs and apply it to two recent whitebox defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks with success rates of up to 70% with modest increase in attacker budget in terms of tokens. Our findings make fundamental progress towards understanding the robustness of prompt injection defenses in the whitebox setting. We release our code and attacks at this https URL 

**Abstract (ZH)**: 面向大规模语言模型（LLMs）提示注入攻击的一种流行防御方法是通过微调模型来区分指令和数据，以确保LLM不会遵循可能与数据一起出现的指令。有多套学术系统和生产级别的此类想法的实现。我们通过构建强大的基于优化的攻击并展示这些防御未能提供声称的安全特性，来在白盒设置下评估这类提示注入防御的鲁棒性。具体来说，我们为基于文本的LLMs构建了一种新的基于注意力的攻击算法，并将其应用于两项最近的白盒防御SecAlign（CCS 2025）和StruQ（USENIX Security 2025），展示了在攻击者预算（以令牌计算）适度增加的情况下成功率可高达70%的攻击。我们的研究结果为理解白盒设置下提示注入防御的鲁棒性奠定了基础。我们已将我们的代码和攻击发布在https://这个链接处。 

---
# Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation 

**Title (ZH)**: 基于自主人工智能的關鍵基礎設施網絡安全框架：實時威�anc緩解 

**Authors**: Jenifer Paulraj, Brindha Raghuraman, Nagarani Gopalakrishnan, Yazan Otoum  

**Link**: [PDF](https://arxiv.org/pdf/2507.07416)  

**Abstract**: Critical infrastructure systems, including energy grids, healthcare facilities, transportation networks, and water distribution systems, are pivotal to societal stability and economic resilience. However, the increasing interconnectivity of these systems exposes them to various cyber threats, including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent Threats (APTs). This paper examines cybersecurity vulnerabilities in critical infrastructure, highlighting the threat landscape, attack vectors, and the role of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid AI-driven cybersecurity framework to enhance real-time vulnerability detection, threat modelling, and automated remediation. This study also addresses the complexities of adversarial AI, regulatory compliance, and integration. Our findings provide actionable insights to strengthen the security and resilience of critical infrastructure systems against emerging cyber threats. 

**Abstract (ZH)**: 关键基础设施系统，包括能源网络、医疗卫生设施、交通网络和水资源分配系统，对于社会稳定和经济韧性至关重要。然而，这些系统的日益互联使其面临各种网络安全威胁，包括勒索软件、拒绝服务（DoS）攻击和高级持续威胁（APTs）。本文探讨关键基础设施的网络安全漏洞，重点阐述威胁 landscape、攻击向量，并强调人工智能（AI）在减轻这些风险中的作用。我们提出了一种混合驱动的AI网络安全框架，以增强实时漏洞检测、威胁建模和自动化补救。此外，本文还讨论了对手AI的复杂性、合规性以及集成问题。我们的研究结果提供了实用的见解，以增强关键基础设施系统对新兴网络安全威胁的防御能力和韧性。 

---
# GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation 

**Title (ZH)**: GNN-CNN：卷积神经网络与图神经网络的高效混合模型及其在文本表示中的应用 

**Authors**: Fardin Rastakhiz  

**Link**: [PDF](https://arxiv.org/pdf/2507.07414)  

**Abstract**: Time, cost, and energy efficiency are critical considerations in Deep-Learning (DL), particularly when processing long texts. Transformers, which represent the current state of the art, exhibit quadratic computational complexity relative to input length, making them inefficient for extended documents. This study introduces a novel model architecture that combines Graph Neural Networks (GNNs) and Convolutional Neural Networks (CNNs), integrated with a real-time, end-to-end graph generation mechanism. The model processes compact batches of character-level inputs without requiring padding or truncation. To enhance performance while maintaining high speed and efficiency, the model incorporates information from Large Language Models (LLMs), such as token embeddings and sentiment polarities, through efficient dictionary lookups. It captures local contextual patterns using CNNs, expands local receptive fields via lattice-based graph structures, and employs small-world graphs to aggregate document-level information. The generated graphs exhibit structural properties indicative of meaningful semantic organization, with an average clustering coefficient of approximately 0.45 and an average shortest path length ranging between 4 and 5. The model is evaluated across multiple text classification tasks, including sentiment analysis and news-categorization, and is compared against state-of-the-art models. Experimental results confirm the proposed model's efficiency and competitive performance. 

**Abstract (ZH)**: 基于图神经网络和卷积神经网络的高效长文本处理模型：实时端到端图生成机制在深度学习中的应用 

---
# Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks 

**Title (ZH)**: 物联网网络中零日威胁的混合大语言模型增强型入侵检测 

**Authors**: Mohammad F. Al-Hammouri, Yazan Otoum, Rasha Atwa, Amiya Nayak  

**Link**: [PDF](https://arxiv.org/pdf/2507.07413)  

**Abstract**: This paper presents a novel approach to intrusion detection by integrating traditional signature-based methods with the contextual understanding capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become increasingly sophisticated, particularly in distributed, heterogeneous, and resource-constrained environments such as those enabled by the Internet of Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems (IDSs) becomes increasingly urgent. While traditional methods remain effective for detecting known threats, they often fail to recognize new and evolving attack patterns. In contrast, GPT-2 excels at processing unstructured data and identifying complex semantic relationships, making it well-suited to uncovering subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges the robustness of signature-based techniques with the adaptability of GPT-2-driven semantic analysis. Experimental evaluations on a representative intrusion dataset demonstrate that our model enhances detection accuracy by 6.3%, reduces false positives by 9.0%, and maintains near real-time responsiveness. These results affirm the potential of language model integration to build intelligent, scalable, and resilient cybersecurity defences suited for modern connected environments. 

**Abstract (ZH)**: 本文提出了一种将传统基于签名的方法与GPT-2大型语言模型的上下文理解能力相结合的新型入侵检测方法。随着网络威胁日益 sophistication，特别是在物联网（IoT）等分布式、异构和资源受限环境中，动态和适应性强的入侵检测系统（IDS）的需求变得尤为迫切。尽管传统方法对于检测已知威胁仍然有效，但它们往往无法识别新的和不断演变的攻击模式。相比之下，GPT-2 在处理 unstructured 数据和识别复杂语义关系方面表现出色，使其非常适合发现隐蔽的零日攻击向量。我们提出了一种将基于签名技术的稳健性与 GPT-2 驱动的语义分析的适应性相结合的混合 IDS 架构。在代表性入侵数据集上的实验评估表明，我们的模型通过提高 6.3% 的检测准确性、降低 9.0% 的误报率并保持接近实时的响应性，证明了语言模型集成在构建智能、可扩展和健壮的网络安全防御方面的潜力，适用于现代互联环境。 

---
# Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models 

**Title (ZH)**: 生成人工智能时代下的钓鱼检测：量化语言模型 vs 经典模型 

**Authors**: Jikesh Thapa, Gurrehmat Chahal, Serban Voinea Gabreanu, Yazan Otoum  

**Link**: [PDF](https://arxiv.org/pdf/2507.07406)  

**Abstract**: Phishing attacks are becoming increasingly sophisticated, underscoring the need for detection systems that strike a balance between high accuracy and computational efficiency. This paper presents a comparative evaluation of traditional Machine Learning (ML), Deep Learning (DL), and quantized small-parameter Large Language Models (LLMs) for phishing detection. Through experiments on a curated dataset, we show that while LLMs currently underperform compared to ML and DL methods in terms of raw accuracy, they exhibit strong potential for identifying subtle, context-based phishing cues. We also investigate the impact of zero-shot and few-shot prompting strategies, revealing that LLM-rephrased emails can significantly degrade the performance of both ML and LLM-based detectors. Our benchmarking highlights that models like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above 80%, using only 17GB of VRAM, supporting their viability for cost-efficient deployment. We further assess the models' adversarial robustness and cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide concise, interpretable explanations to support real-time decision-making. These findings position optimized LLMs as promising components in phishing defence systems and offer a path forward for integrating explainable, efficient AI into modern cybersecurity frameworks. 

**Abstract (ZH)**: 网络钓鱼攻击变得越来越 sophisticated，强调了需要在高准确性和计算效率之间取得平衡的检测系统的重要性。本文比较评估了传统机器学习（ML）、深度学习（DL）和量化的小参数大规模语言模型（LLMs）在网络钓鱼检测中的性能。通过在精置数据集上的实验，我们展示了虽然目前LLMs在纯准确率方面不如ML和DL方法，但它们在识别细微的、基于上下文的网络钓鱼线索方面表现出强大的潜力。我们还研究了零样本和少样本提示策略的影响，发现LLM重新表述的电子邮件会对基于ML和LLM的检测器的性能造成显著损害。我们的基准测试结果显示，如DeepSeek R1 Distill Qwen 14B（Q8_0）等模型仅使用17GB VRAM就能实现超过80%的准确率，支持其在成本效益部署方面的可行性。我们进一步评估了这些模型的对抗鲁棒性和成本-性能权衡，并展示了轻量级LLM如何提供简洁、可解释的解释来支持实时决策。这些发现将优化的LLM定位为网络钓鱼防御系统中具有 promise 的组件，并为将可解释、高效的AI集成到现代网络安全框架中提供了前进的道路。 

---
# HGMP:Heterogeneous Graph Multi-Task Prompt Learning 

**Title (ZH)**: HGMP：异构图多任务提示学习 

**Authors**: Pengfei Jiao, Jialong Ni, Di Jin, Xuan Guo, Huan Liu, Hongjiang Chen, Yanxian Bi  

**Link**: [PDF](https://arxiv.org/pdf/2507.07405)  

**Abstract**: The pre-training and fine-tuning methods have gained widespread attention in the field of heterogeneous graph neural networks due to their ability to leverage large amounts of unlabeled data during the pre-training phase, allowing the model to learn rich structural features. However, these methods face the issue of a mismatch between the pre-trained model and downstream tasks, leading to suboptimal performance in certain application scenarios. Prompt learning methods have emerged as a new direction in heterogeneous graph tasks, as they allow flexible adaptation of task representations to address target inconsistency. Building on this idea, this paper proposes a novel multi-task prompt framework for the heterogeneous graph domain, named HGMP. First, to bridge the gap between the pre-trained model and downstream tasks, we reformulate all downstream tasks into a unified graph-level task format. Next, we address the limitations of existing graph prompt learning methods, which struggle to integrate contrastive pre-training strategies in the heterogeneous graph domain. We design a graph-level contrastive pre-training strategy to better leverage heterogeneous information and enhance performance in multi-task scenarios. Finally, we introduce heterogeneous feature prompts, which enhance model performance by refining the representation of input graph features. Experimental results on public datasets show that our proposed method adapts well to various tasks and significantly outperforms baseline methods. 

**Abstract (ZH)**: 预训练和微调方法在异构图神经网络领域引起了广泛关注，因为它们能够在预训练阶段利用大量未标注数据，使模型学习丰富的结构特征。然而，这些方法面临着预训练模型与下游任务之间的不匹配问题，导致在某些应用场景中性能不佳。为了应对这一问题，提示学习方法成为异构图任务的新方向，因为它允许灵活地调整任务表示以解决目标不一致性。基于这一理念，本文提出了一种新颖的异构图多任务提示框架，命名为HGMP。首先，为了解决预训练模型与下游任务之间的差距，我们将所有下游任务重新格式化为统一的图级任务格式。其次，我们解决了现有图提示学习方法的局限性，这些方法难以在异构图领域集成对比预训练策略。我们设计了一种图级对比预训练策略，更好地利用异构信息，并在多任务场景中提升性能。最后，我们引入了异构特征提示，通过改进输入图特征的表示来提升模型性能。实验结果表明，所提出的方法在各种任务上适应性良好，并显著优于基线方法。 

---
# Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization 

**Title (ZH)**: 广义树编辑距离（GTED）：语句自形式化评估的忠实度量 

**Authors**: Yuntian Liu, Tao Zhu, Xiaoyang Liu, Yu Chen, Zhaoxuan Liu, Qingfeng Guo, Jiashuo Zhang, Kangjie Bao, Tao Luo  

**Link**: [PDF](https://arxiv.org/pdf/2507.07399)  

**Abstract**: Statement autoformalization, the automated translation of statement from natural language into formal languages, has become a subject of extensive research, yet the development of robust automated evaluation metrics remains limited. Existing evaluation methods often lack semantic understanding, face challenges with high computational costs, and are constrained by the current progress of automated theorem proving. To address these issues, we propose GTED (Generalized Tree Edit Distance), a novel evaluation framework that first standardizes formal statements and converts them into operator trees, then determines the semantic similarity using the eponymous GTED metric. On the miniF2F and ProofNet benchmarks, GTED outperforms all baseline metrics by achieving the highest accuracy and Kappa scores, thus providing the community with a more faithful metric for automated evaluation. The code and experimental results are available at this https URL. 

**Abstract (ZH)**: 陈述自形式化，即自然语言陈述到形式语言的自动化转换，已成为广泛研究的课题，但 robust 自动评价指标的发展仍然有限。现有的评价方法往往缺乏语义理解，面临高计算成本的挑战，并受制于当前自动定理证明的进展。为解决这些问题，我们提出了一种新的评价框架 GTED（Generalized Tree Edit Distance），该框架首先标准化形式陈述并将其转换为操作树，然后使用同名的 GTED 指标确定语义相似性。在 miniF2F 和 ProofNet 的基准测试中，GTED 在准确率和 Kappa 分数上均优于所有基准指标，从而为社区提供了一个更忠实的自动评价指标。相关代码和实验结果可在以下网址获取。 

---
# Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer 

**Title (ZH)**: 保持行为：习惯保留的跨类别动物动作转移 

**Authors**: Zhimin Zhang, Bi'an Du, Caoyuan Ma, Zheng Wang, Wei Hu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07394)  

**Abstract**: Animal motion embodies species-specific behavioral habits, making the transfer of motion across categories a critical yet complex task for applications in animation and virtual reality. Existing motion transfer methods, primarily focused on human motion, emphasize skeletal alignment (motion retargeting) or stylistic consistency (motion style transfer), often neglecting the preservation of distinct habitual behaviors in animals. To bridge this gap, we propose a novel habit-preserved motion transfer framework for cross-category animal motion. Built upon a generative framework, our model introduces a habit-preservation module with category-specific habit encoder, allowing it to learn motion priors that capture distinctive habitual characteristics. Furthermore, we integrate a large language model (LLM) to facilitate the motion transfer to previously unobserved species. To evaluate the effectiveness of our approach, we introduce the DeformingThings4D-skl dataset, a quadruped dataset with skeletal bindings, and conduct extensive experiments and quantitative analyses, which validate the superiority of our proposed model. 

**Abstract (ZH)**: 动物运动蕴含了物种特有的行为习惯，使得跨类别运动转移成为了动画和虚拟现实应用中一个关键而复杂的任务。现有的运动转移方法主要关注人类运动，侧重于骨骼对齐（运动目标映射）或风格一致性（运动风格转移），往往忽视了动物特有习惯行为的保持。为填补这一空白，我们提出了一种新的保留习惯行为的跨类别动物运动转移框架。基于生成框架，我们的模型引入了一个习惯保持模块，包含类别特定的习惯编码器，使其能够学习能够捕捉独特习惯特征的运动先验。此外，我们集成了一个大规模语言模型（LLM）以促进对未观察物种的运动转移。为了评估我们方法的有效性，我们引入了DeformingThings4D-skl数据集，这是一个带有骨骼绑定的四足动物数据集，并进行了广泛的实验和定量分析，验证了我们提出模型的优越性。 

---
# KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos 

**Title (ZH)**: 基于关键点引导的分部位aware表示的人员重识别 

**Authors**: Jinseong Kim, Junghoon Song, Gyeongseon Baek, Byeongjoon Noh  

**Link**: [PDF](https://arxiv.org/pdf/2507.07393)  

**Abstract**: We propose \textbf{KeyRe-ID}, a keypoint-guided video-based person re-identification framework consisting of global and local branches that leverage human keypoints for enhanced spatiotemporal representation learning. The global branch captures holistic identity semantics through Transformer-based temporal aggregation, while the local branch dynamically segments body regions based on keypoints to generate fine-grained, part-aware features. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate state-of-the-art performance, achieving 91.73\% mAP and 97.32\% Rank-1 accuracy on MARS, and 96.00\% Rank-1 and 100.0\% Rank-5 accuracy on iLIDS-VID. The code for this work will be publicly available on GitHub upon publication. 

**Abstract (ZH)**: KeyRe-ID：一种基于关键点引导的视频人员再识别框架 

---
# PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments 

**Title (ZH)**: PILOC：一种pheromone逆向引导机制及局部通信框架，用于未知环境中多代理动态目标搜索 

**Authors**: Hengrui Liu, Yi Feng, Qilong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.07376)  

**Abstract**: Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications. 

**Abstract (ZH)**: 多智能体搜索与救援（MASAR）在灾害响应、探索与侦察中发挥着重要作用。然而，动态和未知环境带来的目标不可预测性和环境不确定性提出了重大挑战。为应对这些挑战，我们提出PILOC框架，该框架不依赖全局先验知识，而是利用局部感知和通信。PILOC引入了蚁痕逆向引导机制，以促进高效的协调和动态目标定位。PILOC通过局部通信促进去中心化的合作，显著减少了对全局信道的依赖。与传统启发式方法不同，蚁痕机制嵌入到深度强化学习（DRL）的观测空间中，基于环境线索支持间接智能体协调。我们将此策略集成到基于DRL的多智能体架构中，并进行了广泛的实验。结果表明，结合局部通信与基于蚁痕的引导显著提升了搜索效率、适应性和系统鲁棒性。与其他现有方法相比，PILOC在动态和通信受限场景中表现更优，为未来的MASAR应用提供了有前景的方向。 

---
# Atherosclerosis through Hierarchical Explainable Neural Network Analysis 

**Title (ZH)**: 通过层次可解释神经网络分析的动脉粥样硬化研究 

**Authors**: Irsyad Adam, Steven Swee, Erika Yilin, Ethan Ji, William Speier, Dean Wang, Alex Bui, Wei Wang, Karol Watson, Peipei Ping  

**Link**: [PDF](https://arxiv.org/pdf/2507.07373)  

**Abstract**: In this work, we study the problem pertaining to personalized classification of subclinical atherosclerosis by developing a hierarchical graph neural network framework to leverage two characteristic modalities of a patient: clinical features within the context of the cohort, and molecular data unique to individual patients. Current graph-based methods for disease classification detect patient-specific molecular fingerprints, but lack consistency and comprehension regarding cohort-wide features, which are an essential requirement for understanding pathogenic phenotypes across diverse atherosclerotic trajectories. Furthermore, understanding patient subtypes often considers clinical feature similarity in isolation, without integration of shared pathogenic interdependencies among patients. To address these challenges, we introduce ATHENA: Atherosclerosis Through Hierarchical Explainable Neural Network Analysis, which constructs a novel hierarchical network representation through integrated modality learning; subsequently, it optimizes learned patient-specific molecular fingerprints that reflect individual omics data, enforcing consistency with cohort-wide patterns. With a primary clinical dataset of 391 patients, we demonstrate that this heterogeneous alignment of clinical features with molecular interaction patterns has significantly boosted subclinical atherosclerosis classification performance across various baselines by up to 13% in area under the receiver operating curve (AUC) and 20% in F1 score. Taken together, ATHENA enables mechanistically-informed patient subtype discovery through explainable AI (XAI)-driven subnetwork clustering; this novel integration framework strengthens personalized intervention strategies, thereby improving the prediction of atherosclerotic disease progression and management of their clinical actionable outcomes. 

**Abstract (ZH)**: 基于层次解释性神经网络分析的动脉粥样硬化个性化分类方法 

---
# Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning 

**Title (ZH)**: 以目标为导向的序列贝叶斯实验设计用于因果学习 

**Authors**: Zheyu Zhang, Jiayuan Dong, Jie Liu, Xun Huan  

**Link**: [PDF](https://arxiv.org/pdf/2507.07359)  

**Abstract**: We present GO-CBED, a goal-oriented Bayesian framework for sequential causal experimental design. Unlike conventional approaches that select interventions aimed at inferring the full causal model, GO-CBED directly maximizes the expected information gain (EIG) on user-specified causal quantities of interest, enabling more targeted and efficient experimentation. The framework is both non-myopic, optimizing over entire intervention sequences, and goal-oriented, targeting only model aspects relevant to the causal query. To address the intractability of exact EIG computation, we introduce a variational lower bound estimator, optimized jointly through a transformer-based policy network and normalizing flow-based variational posteriors. The resulting policy enables real-time decision-making via an amortized network. We demonstrate that GO-CBED consistently outperforms existing baselines across various causal reasoning and discovery tasks-including synthetic structural causal models and semi-synthetic gene regulatory networks-particularly in settings with limited experimental budgets and complex causal mechanisms. Our results highlight the benefits of aligning experimental design objectives with specific research goals and of forward-looking sequential planning. 

**Abstract (ZH)**: GO-CBED：面向目标的贝叶斯序贯因果实验设计框架 

---
# Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning 

**Title (ZH)**: 利用流形嵌入增强图变压器表示学习 

**Authors**: Ankit Jyothish, Ali Jannesari  

**Link**: [PDF](https://arxiv.org/pdf/2507.07335)  

**Abstract**: Graph transformers typically embed every node in a single Euclidean space, blurring heterogeneous topologies. We prepend a lightweight Riemannian mixture-of-experts layer that routes each node to various kinds of manifold, mixture of spherical, flat, hyperbolic - best matching its local structure. These projections provide intrinsic geometric explanations to the latent space. Inserted into a state-of-the-art ensemble graph transformer, this projector lifts accuracy by up to 3% on four node-classification benchmarks. The ensemble makes sure that both euclidean and non-euclidean features are captured. Explicit, geometry-aware projection thus sharpens predictive power while making graph representations more interpretable. 

**Abstract (ZH)**: 典型的图变换器将每个节点嵌入到单个欧几里得空间中，模糊了异构拓扑结构。我们添加了一个轻量级黎曼混合专家层，将每个节点路由到最合适其局部结构的各种流形，包括球形、平面和双曲流形。这些投影为潜在空间提供了内在的几何解释。插入到一个先进的集成图变换器中，该投影器在四个节点分类基准测试中将准确率提高了最多3%。集成确保同时捕获欧几里得和非欧几里得特征。显性的、几何意识的投影增强了预测能力，同时使图表示更为可解释。 

---
# Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery 

**Title (ZH)**: 通过微调增强推理的大型语言模型，弥合化学合成与发现中的可行性-有效性差距 

**Authors**: Malikussaid, Hilal Hudan Nuha  

**Link**: [PDF](https://arxiv.org/pdf/2507.07328)  

**Abstract**: Large Language Models (LLMs) often generate scientifically plausible but factually invalid information, a challenge we term the "plausibility-validity gap," particularly in specialized domains like chemistry. This paper presents a systematic methodology to bridge this gap by developing a specialized scientific assistant. We utilized the Magistral Small model, noted for its integrated reasoning capabilities, and fine-tuned it using Low-Rank Adaptation (LoRA). A key component of our approach was the creation of a "dual-domain dataset," a comprehensive corpus curated from various sources encompassing both molecular properties and chemical reactions, which was standardized to ensure quality. Our evaluation demonstrates that the fine-tuned model achieves significant improvements over the baseline model in format adherence, chemical validity of generated molecules, and the feasibility of proposed synthesis routes. The results indicate a hierarchical learning pattern, where syntactic correctness is learned more readily than chemical possibility and synthesis feasibility. While a comparative analysis with human experts revealed competitive performance in areas like chemical creativity and reasoning, it also highlighted key limitations, including persistent errors in stereochemistry, a static knowledge cutoff, and occasional reference hallucination. This work establishes a viable framework for adapting generalist LLMs into reliable, specialized tools for chemical research, while also delineating critical areas for future improvement. 

**Abstract (ZH)**: 大型语言模型在化学领域的可验证性间隙：一种专门的科学助手方法 

---
# SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models 

**Title (ZH)**: SonicMotion：基于潜在扩散模型的动态空间音频音景 

**Authors**: Christian Templin, Yanda Zhu, Hao Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.07318)  

**Abstract**: Spatial audio is an integral part of immersive entertainment, such as VR/AR, and has seen increasing popularity in cinema and music as well. The most common format of spatial audio is described as first-order Ambisonics (FOA). We seek to extend recent advancements in FOA generative AI models to enable the generation of 3D scenes with dynamic sound sources. Our proposed end-to-end model, SonicMotion, comes in two variations which vary in their user input and level of precision in sound source localization. In addition to our model, we also present a new dataset of simulated spatial audio-caption pairs. Evaluation of our models demonstrate that they are capable of matching the semantic alignment and audio quality of state of the art models while capturing the desired spatial attributes. 

**Abstract (ZH)**: 空间音频是沉浸式娱乐，如VR/AR的一个重要组成部分，并且在电影和音乐领域也越来越受欢迎。空间音频最常见的格式是初级球面声学（FOA）。我们致力于将最新的生成型AI模型技术扩展到能够生成具有动态声源的三维场景。我们提出的端到端模型SonicMotion有两种变体，它们在用户输入和声源定位的精确度上有所不同。除了我们的模型，我们还提供了一组新的模拟空间音频-图例对数据集。我们的模型评估表明，它们能够匹配最先进的模型的语义对齐和音质，同时捕捉到所需的空间属性。 

---
# LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation 

**Title (ZH)**: LinguaMark: 多模态模型讲话公平吗？基于基准的评估 

**Authors**: Ananya Raval, Aravind Narayanan, Vahid Reza Khazaie, Shaina Raza  

**Link**: [PDF](https://arxiv.org/pdf/2507.07274)  

**Abstract**: Large Multimodal Models (LMMs) are typically trained on vast corpora of image-text data but are often limited in linguistic coverage, leading to biased and unfair outputs across languages. While prior work has explored multimodal evaluation, less emphasis has been placed on assessing multilingual capabilities. In this work, we introduce LinguaMark, a benchmark designed to evaluate state-of-the-art LMMs on a multilingual Visual Question Answering (VQA) task. Our dataset comprises 6,875 image-text pairs spanning 11 languages and five social attributes. We evaluate models using three key metrics: Bias, Answer Relevancy, and Faithfulness. Our findings reveal that closed-source models generally achieve the highest overall performance. Both closed-source (GPT-4o and Gemini2.5) and open-source models (Gemma3, Qwen2.5) perform competitively across social attributes, and Qwen2.5 demonstrates strong generalization across multiple languages. We release our benchmark and evaluation code to encourage reproducibility and further research. 

**Abstract (ZH)**: 大型多模态模型（LMMs）通常在大量的图像-文本数据集上进行训练，但在语言覆盖方面往往受到限制，导致跨语言的偏差和不公正输出。尽管现有工作探索了多模态评估，但对多语言能力的评估关注较少。在本工作中，我们引入了LinguaMark，这是一个用于评估最先进的LMMs在多语言视觉问答（VQA）任务上的基准。我们的数据集包含6,875个图像-文本对，覆盖11种语言和五种社会属性。我们使用三个关键指标进行评估：偏差、答案相关性和忠实度。我们的研究发现，封闭源模型通常实现最高的总体性能。封闭源模型（GPT-4o和Gemini2.5）和开源模型（Gemma3和Qwen2.5）在社会属性方面表现出色，且Qwen2.5在多种语言上表现出强大的泛化能力。我们开源了基准和评估代码，以促进可再现性和进一步研究。 

---
# Exploiting Edge Features for Transferable Adversarial Attacks in Distributed Machine Learning 

**Title (ZH)**: 利用边缘特征进行可移植的分布式机器学习对抗攻击 

**Authors**: Giulio Rossolini, Fabio Brau, Alessandro Biondi, Battista Biggio, Giorgio Buttazzo  

**Link**: [PDF](https://arxiv.org/pdf/2507.07259)  

**Abstract**: As machine learning models become increasingly deployed across the edge of internet of things environments, a partitioned deep learning paradigm in which models are split across multiple computational nodes introduces a new dimension of security risk. Unlike traditional inference setups, these distributed pipelines span the model computation across heterogeneous nodes and communication layers, thereby exposing a broader attack surface to potential adversaries. Building on these motivations, this work explores a previously overlooked vulnerability: even when both the edge and cloud components of the model are inaccessible (i.e., black-box), an adversary who intercepts the intermediate features transmitted between them can still pose a serious threat. We demonstrate that, under these mild and realistic assumptions, an attacker can craft highly transferable proxy models, making the entire deep learning system significantly more vulnerable to evasion attacks. In particular, the intercepted features can be effectively analyzed and leveraged to distill surrogate models capable of crafting highly transferable adversarial examples against the target model. To this end, we propose an exploitation strategy specifically designed for distributed settings, which involves reconstructing the original tensor shape from vectorized transmitted features using simple statistical analysis, and adapting surrogate architectures accordingly to enable effective feature distillation. A comprehensive and systematic experimental evaluation has been conducted to demonstrate that surrogate models trained with the proposed strategy, i.e., leveraging intermediate features, tremendously improve the transferability of adversarial attacks. These findings underscore the urgent need to account for intermediate feature leakage in the design of secure distributed deep learning systems. 

**Abstract (ZH)**: 随着机器学习模型在物联网边缘环境中的广泛应用，将模型分散在多个计算节点上的分区深度学习范式引入了新的安全风险维度。与传统推理设置不同，这些分布式的管道在不 homogeneous 节点和通信层上扩展了模型计算，从而增加了潜在对手的攻击面。基于这些动机，本工作探索了一个之前未被忽视的漏洞：即使模型的边缘和云组件均不可访问（即黑盒状态），拦截它们之间传输的中间特征的对手仍然可以构成严重威胁。我们证明，在这些温和且现实的假设下，攻击者可以构建高度可迁移的代理模型，从而使整个深度学习系统对逃避攻击更为脆弱。具体来说，拦截的特征可以通过有效分析和利用来提炼出能够针对目标模型生成高度可迁移对抗样本的替代模型。为此，我们提出了一种专门针对分布式环境的利用策略，该策略涉及使用简单的统计分析从向量化传输的特征中重构原始张量形状，并相应地调整替代架构以促进有效的特征提炼。进行了全面而系统的实验评估以证明，使用所提出的策略训练的替代模型，即利用中间特征，极大地提高了对抗攻击的可迁移性。这些发现强调了在设计安全的分布式深度学习系统时需要考虑中间特征泄露的紧迫性。 

---
# FedP3E: Privacy-Preserving Prototype Exchange for Non-IID IoT Malware Detection in Cross-Silo Federated Learning 

**Title (ZH)**: FedP3E: 非 IID 物联网恶意软件检测跨孤岛联邦学习中的隐私保护原型交换 

**Authors**: Rami Darwish, Mahmoud Abdelsalam, Sajad Khorsandroo, Kaushik Roy  

**Link**: [PDF](https://arxiv.org/pdf/2507.07258)  

**Abstract**: As IoT ecosystems continue to expand across critical sectors, they have become prominent targets for increasingly sophisticated and large-scale malware attacks. The evolving threat landscape, combined with the sensitive nature of IoT-generated data, demands detection frameworks that are both privacy-preserving and resilient to data heterogeneity. Federated Learning (FL) offers a promising solution by enabling decentralized model training without exposing raw data. However, standard FL algorithms such as FedAvg and FedProx often fall short in real-world deployments characterized by class imbalance and non-IID data distributions -- particularly in the presence of rare or disjoint malware classes. To address these challenges, we propose FedP3E (Privacy-Preserving Prototype Exchange), a novel FL framework that supports indirect cross-client representation sharing while maintaining data privacy. Each client constructs class-wise prototypes using Gaussian Mixture Models (GMMs), perturbs them with Gaussian noise, and transmits only these compact summaries to the server. The aggregated prototypes are then distributed back to clients and integrated into local training, supported by SMOTE-based augmentation to enhance representation of minority malware classes. Rather than relying solely on parameter averaging, our prototype-driven mechanism enables clients to enrich their local models with complementary structural patterns observed across the federation -- without exchanging raw data or gradients. This targeted strategy reduces the adverse impact of statistical heterogeneity with minimal communication overhead. We evaluate FedP3E on the N-BaIoT dataset under realistic cross-silo scenarios with varying degrees of data imbalance. 

**Abstract (ZH)**: 随着物联网生态系统在关键领域不断扩展，它们已成为日益复杂和大规模恶意软件攻击的主要目标。随着物联网生成数据的敏感性，不断演变的威胁 landscape 对检测框架提出了既是隐私保护又是数据异质性鲁棒性的需求。通过使模型训练去中心化而无需暴露原始数据，联邦学习（FL）提供了一个有希望的解决方案。然而，标准的 FL 算法如 FedAvg 和 FedProx 在现实部署中经常因为类别不平衡和非IID数据分布等问题而表现不佳，尤其是在遇到罕见或不兼容的恶意软件类别时。为了解决这些问题，我们提出了一种名为 FedP3E（Privacy-Preserving Prototype Exchange）的新颖联邦学习框架，该框架支持间接的跨客户端表示共享，同时保持数据隐私。每个客户端使用高斯混合模型（GMMs）构建类别的原型，添加高斯噪声，并仅传输这些紧凑的摘要到服务器。聚合后的原型随后被分发回客户端并整合到局部训练中，通过基于SMOTE的增强来提高少数恶意软件类别的表示。我们的原型驱动机制并不依赖于仅仅参数平均，而是允许客户端通过联邦中的互补结构模式丰富它们的本地模型——而不需要交换原始数据或梯度。这种有针对性的策略在轻微的通信开销下减少了统计异质性带来的负面影响。我们在 N-BaIoT 数据集上评估了 FedP3E，该评估在不同程度的数据不平衡的现实跨孤岛场景下进行。 

---
# Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention 

**Title (ZH)**: 注意力机制下的资源利用比较研究：各种自注意力变体的评估 

**Authors**: Zhengyu Tian, Anantha Padmanaban Krishna Kumar, Hemant Krishnakumar, Reza Rawassizadeh  

**Link**: [PDF](https://arxiv.org/pdf/2507.07247)  

**Abstract**: As large language models (LLMs) and visual language models (VLMs) grow in scale and application, attention mechanisms have become a central computational bottleneck due to their high memory and time complexity. While many efficient attention variants have been proposed, there remains a lack of rigorous evaluation on their actual energy usage and hardware resource demands during training. In this work, we benchmark eight attention mechanisms in training GPT-2 architecture, measuring key metrics including training time, GPU memory usage, FLOPS, CPU usage, and power consumption. Our results reveal that attention mechanisms with optimized kernel implementations, including Flash Attention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent Attention (MLA), achieve the best energy efficiency. We further show that lower GPU power alone does not guarantee reduced energy use, as training time plays an equally important role. Our study highlights the importance of energy-aware benchmarking in attention design and provides a practical insight for selecting resource-efficient mechanisms. All our codes are available at GitHub. 

**Abstract (ZH)**: 随着大规模语言模型（LLMs）和视觉语言模型（VLMs）的规模和应用不断扩大，注意力机制已成为一个主要的计算瓶颈，原因在于其高内存和时间复杂性。尽管已经提出了许多高效的注意力变体，但在实际训练过程中的能效和硬件资源需求方面仍缺乏严格的评估。在本工作中，我们对GPT-2架构中的八种注意力机制进行了基准测试，测量了包括训练时间、GPU内存使用、FLOPS、CPU使用和功耗在内的关键指标。我们的结果显示，包括Flash Attention、局部敏感哈希（LSH）注意力和多头潜在注意力（MLA）在内的优化内核实现的注意力机制在能效方面表现出最佳性能。我们进一步表明，仅降低GPU功耗并不能确保减少能源使用，因为训练时间同样重要。我们的研究突出了在注意力机制设计中进行能源意识基准测试的重要性，并提供了选择高效机制的实用见解。所有代码可在GitHub上获取。 

---
# An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation 

**Title (ZH)**: 基于信息论视角的多语言模型不确定性估计 

**Authors**: Maya Kruse, Majid Afshar, Saksham Khatwani, Anoop Mayampurath, Guanhua Chen, Yanjun Gao  

**Link**: [PDF](https://arxiv.org/pdf/2507.07236)  

**Abstract**: Large language models (LLMs) often behave inconsistently across inputs, indicating uncertainty and motivating the need for its quantification in high-stakes settings. Prior work on calibration and uncertainty quantification often focuses on individual models, overlooking the potential of model diversity. We hypothesize that LLMs make complementary predictions due to differences in training and the Zipfian nature of language, and that aggregating their outputs leads to more reliable uncertainty estimates. To leverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a simple information-theoretic method that uses Jensen-Shannon Divergence to identify and aggregate well-calibrated subsets of LLMs. Experiments on binary prediction tasks demonstrate improved calibration and predictive performance compared to single-model and naive ensemble baselines. 

**Abstract (ZH)**: 大型语言模型（LLMs）在不同输入上的行为常常不一致，这表明了其不确定性，并强调了在高风险情境下对其量化的必要性。关于校准和不确定性量化之前的研究所侧重于单个模型，忽视了模型多样性潜力。我们假设由于训练差异和语言的吉本斯分布特性，LLMs做出互补的预测，并且聚合它们的输出能够带来更可靠的不确定性估计。为了利用这一特点，我们提出了MUSE（基于子集集成的多LLM不确定性）方法，这是一种简单的信息论方法，使用Jensen-Shannon散度来识别和聚合具有良好校准的LLM子集。在二元预测任务上的实验表明，与单一模型和朴素集成baseline相比，MUSE方法在校准和预测性能上有所提升。 

---
# Bias-Aware Mislabeling Detection via Decoupled Confident Learning 

**Title (ZH)**: 带有偏置意识的误标签检测通过解耦自信学习 

**Authors**: Yunyi Li, Maria De-Arteaga, Maytal Saar-Tsechansky  

**Link**: [PDF](https://arxiv.org/pdf/2507.07216)  

**Abstract**: Reliable data is a cornerstone of modern organizational systems. A notable data integrity challenge stems from label bias, which refers to systematic errors in a label, a covariate that is central to a quantitative analysis, such that its quality differs across social groups. This type of bias has been conceptually and empirically explored and is widely recognized as a pressing issue across critical domains. However, effective methodologies for addressing it remain scarce. In this work, we propose Decoupled Confident Learning (DeCoLe), a principled machine learning based framework specifically designed to detect mislabeled instances in datasets affected by label bias, enabling bias aware mislabelling detection and facilitating data quality improvement. We theoretically justify the effectiveness of DeCoLe and evaluate its performance in the impactful context of hate speech detection, a domain where label bias is a well documented challenge. Empirical results demonstrate that DeCoLe excels at bias aware mislabeling detection, consistently outperforming alternative approaches for label error detection. Our work identifies and addresses the challenge of bias aware mislabeling detection and offers guidance on how DeCoLe can be integrated into organizational data management practices as a powerful tool to enhance data reliability. 

**Abstract (ZH)**: 可靠的数据是现代组织系统的基础。标签偏见是一种值得注意的数据完整性挑战，它指的是标签系统的系统性错误，这种标签是量化分析中的关键变量，其质量在不同社会群体间存在差异。这种类型的偏见已在概念和实证层面得到了探索，并被广泛认为是关键领域中的紧迫问题。然而，有效的解决方法仍然稀缺。在本文中，我们提出了解耦置信学习（DeCoLe）这一基于原理的机器学习框架，专门设计用于检测受标签偏见影响的数据集中的误标签实例，使偏见感知的误标签检测成为可能，并促进数据质量的提升。我们从理论上验证了DeCoLe的有效性，并在其对仇恨言论检测具有重大影响的背景下评估其性能。实验结果表明，DeCoLe在偏见感知误标签检测方面表现出色，始终优于其他标签错误检测方法。我们工作识别并解决了偏见感知误标签检测的挑战，并提供了如何将DeCoLe集成到组织数据管理实践中以增强数据可靠性方面的指导。 

---
# MODA: A Unified 3D Diffusion Framework for Multi-Task Target-Aware Molecular Generation 

**Title (ZH)**: MODA：一种统一的多任务目标 Awareness 分子生成三维度扩散框架 

**Authors**: Dong Xu, Zhangfan Yang, Sisi Yuan, Jenna Xinyi Yao, Jiangqiang Li, Junkai Ji  

**Link**: [PDF](https://arxiv.org/pdf/2507.07201)  

**Abstract**: Three-dimensional molecular generators based on diffusion models can now reach near-crystallographic accuracy, yet they remain fragmented across tasks. SMILES-only inputs, two-stage pretrain-finetune pipelines, and one-task-one-model practices hinder stereochemical fidelity, task alignment, and zero-shot transfer. We introduce MODA, a diffusion framework that unifies fragment growing, linker design, scaffold hopping, and side-chain decoration with a Bayesian mask scheduler. During training, a contiguous spatial fragment is masked and then denoised in one pass, enabling the model to learn shared geometric and chemical priors across tasks. Multi-task training yields a universal backbone that surpasses six diffusion baselines and three training paradigms on substructure, chemical property, interaction, and geometry. Model-C reduces ligand-protein clashes and substructure divergences while maintaining Lipinski compliance, whereas Model-B preserves similarity but trails in novelty and binding affinity. Zero-shot de novo design and lead-optimisation tests confirm stable negative Vina scores and high improvement rates without force-field refinement. These results demonstrate that a single-stage multi-task diffusion routine can replace two-stage workflows for structure-based molecular design. 

**Abstract (ZH)**: 基于扩散模型的三维分子生成器现在可以达到接近晶体学的准确性，但它们仍然碎片化分布在不同的任务中。仅使用SMILES输入、两阶段预训练-微调流水线以及一个任务一个模型的做法阻碍了立体化学保真度、任务对齐以及零样本迁移。我们引入了MODA，这是一种统一片段生长、连接设计、骨架跃迁和侧链修饰的贝叶斯掩码调度器的扩散框架。在训练过程中，连续的空间片段被遮盖并在一次通过中去噪，从而使模型能够在不同任务中学习共享的几何和化学先验知识。多任务训练产生了一个超越六个扩散基线和三种训练范式的通用骨干，其在子结构、化学性质、相互作用和几何形状方面表现出色。Model-C减少了配体-蛋白 Clash 和子结构差异，同时保持了Lipinski合规性，而Model-B保持了相似性但新颖性和结合亲和力较低。零样本从头设计和先导优化测试表明，在无需力场精修的情况下稳定产生了负Vina评分和高改进率。这些结果表明，单阶段多任务扩散流程可以替代结构基于的分子设计的两阶段工作流程。 

---
# Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning 

**Title (ZH)**: 结合预训练模型以增强强化学习中的特征表示 

**Authors**: Elia Piccoli, Malio Li, Giacomo Carfì, Vincenzo Lomonaco, Davide Bacciu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07197)  

**Abstract**: The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training. 

**Abstract (ZH)**: 预训练模型的 recent 调整和释放已成为多个领域（例如自然语言处理和计算机视觉）进步的关键组成部分，实际上，预训练模型学习到的异质潜在嵌入共享洞察性表示。另一方面，强化学习 (RL) 关注通过智能体与环境的交互最大化累积奖励。RL 智能体没有任何关于世界的先验知识，它们要么从零开始学习从观察空间到动作空间的端到端映射，要么在最近的研究中与庞大且计算密集的基础模型配对。如何有效地同时结合和利用不同预训练模型的隐藏信息在 RL 中仍是一个开放且未充分研究的问题。在本文中，我们提出了一种新的架构——权重共享注意力 (WSA)，用于结合多个预训练模型的嵌入以形成丰富状态表示，平衡效率与性能之间的tradeoff。我们对多种结合模式进行了详尽比较，结果显示 WSA 在多个 Atari 游戏上的表现与端到端模型相当。此外，我们研究了该方法的泛化能力，并分析了随模型数量增加对智能体训练前后表现的影响。 

---
# Bridging the Last Mile of Prediction: Enhancing Time Series Forecasting with Conditional Guided Flow Matching 

**Title (ZH)**: 弥补预测的最后一公里：基于条件引导流匹配的时间序列 forecasting 提升方法 

**Authors**: Huibo Xu, Runlong Yu, Likang Wu, Xianquan Wang, Qi Liu  

**Link**: [PDF](https://arxiv.org/pdf/2507.07192)  

**Abstract**: Diffusion models, a type of generative model, have shown promise in time series forecasting. But they face limitations like rigid source distributions and limited sampling paths, which hinder their performance. Flow matching offers faster generation, higher-quality outputs, and greater flexibility, while also possessing the ability to utilize valuable information from the prediction errors of prior models, which were previously inaccessible yet critically important. To address these challenges and fully unlock the untapped potential of flow matching, we propose Conditional Guided Flow Matching (CGFM). CGFM extends flow matching by incorporating the outputs of an auxiliary model, enabling a previously unattainable capability in the field: learning from the errors of the auxiliary model. For time series forecasting tasks, it integrates historical data as conditions and guidance, constructs two-sided conditional probability paths, and uses a general affine path to expand the space of probability paths, ultimately leading to improved predictions. Extensive experiments show that CGFM consistently enhances and outperforms state-of-the-art models, highlighting its effectiveness in advancing forecasting methods. 

**Abstract (ZH)**: 差分模型作为一种生成模型，在时间序列预测中展现出潜力，但面临着源分布僵化和采样路径有限等局限，这些都妨碍了其性能的提升。流匹配提供了更快的生成速度、更高质量的输出以及更大的灵活性，并且能够利用先前模型预测错误中宝贵的但之前难以触及的信息。为了应对这些挑战并充分释放流匹配的潜力，我们提出了一种条件引导流匹配（CGFM）。CGFM通过引入辅助模型的输出扩展了流匹配方法，使其能够在领域中实现前所未有的学习辅助模型预测错误的能力。对于时间序列预测任务，CGFM将历史数据作为条件和引导，构建双向条件概率路径，并利用通用仿射路径扩展概率路径的空间，从而最终提高预测效果。大量的实验结果表明，CGFM持续提高了并超越了现有最先进模型的表现，突显了其在提升预测方法有效性方面的作用。 

---
# Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses 

**Title (ZH)**: 提示扰动揭示出LLM调查回答中的人类似偏见 

**Authors**: Jens Rupprecht, Georg Ahnert, Markus Strohmaier  

**Link**: [PDF](https://arxiv.org/pdf/2507.07188)  

**Abstract**: Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known response biases are poorly understood. This paper investigates the response robustness of LLMs in normative survey contexts -- we test nine diverse LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of 11 perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also reveal that all tested models exhibit a consistent \textit{recency bias} varying in intensity, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. By applying a set of perturbations, we reveal that LLMs partially align with survey response biases identified in humans. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data. 

**Abstract (ZH)**: 大型语言模型（LLMs）在社会科学研究中越来越多地被用作人类被试的代理，但它们的可靠性和对已知回答偏差的敏感性尚不完全理解。本文研究了规范性调查背景下LLMs的回答稳定性——我们对来自世界价值观调查（WVS）的问题测试了九种不同的LLMs，并对问题措辞和答案选项结构应用了完整的11种扰动，产生了超过167,000次模拟访谈。通过这种方式，我们不仅揭示了LLMs对扰动的脆弱性，还发现所有测试的模型都表现出一致的“近因偏差”，不同程度地偏好最后呈现的答案选项。虽然更大规模的模型通常更具稳健性，但所有模型仍对语义变化（如改写）和组合扰动敏感。通过应用一组扰动，我们发现LLMs部分符合在人类中识别出的调查回答偏差。这强调了在使用LLMs生成合成调查数据时，设计提示和进行稳健性测试的重要性。 

---
# Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs 

**Title (ZH)**: 预训练中植根，调优中摇摆：关于LLMs认知偏差源头的案例研究 

**Authors**: Itay Itzhak, Yonatan Belinkov, Gabriel Stanovsky  

**Link**: [PDF](https://arxiv.org/pdf/2507.07186)  

**Abstract**: Large language models (LLMs) exhibit cognitive biases -- systematic tendencies of irrational decision-making, similar to those seen in humans. Prior work has found that these biases vary across models and can be amplified by instruction tuning. However, it remains unclear if these differences in biases stem from pretraining, finetuning, or even random noise due to training stochasticity. We propose a two-step causal experimental approach to disentangle these factors. First, we finetune models multiple times using different random seeds to study how training randomness affects over $30$ cognitive biases. Second, we introduce \emph{cross-tuning} -- swapping instruction datasets between models to isolate bias sources. This swap uses datasets that led to different bias patterns, directly testing whether biases are dataset-dependent. Our findings reveal that while training randomness introduces some variability, biases are mainly shaped by pretraining: models with the same pretrained backbone exhibit more similar bias patterns than those sharing only finetuning data. These insights suggest that understanding biases in finetuned models requires considering their pretraining origins beyond finetuning effects. This perspective can guide future efforts to develop principled strategies for evaluating and mitigating bias in LLMs. 

**Abstract (ZH)**: 大型语言模型（LLMs）表现出认知偏见——类似于人类的系统性不理性决策倾向。先前的工作发现，这些偏见在不同模型之间有所不同，并且可以通过指令调优而被放大。然而，目前尚不清楚这些差异归因于预训练、微调还是训练随机性引起的随机噪声。我们提出了一种两步因果实验方法来区分这些因素。首先，我们使用不同的随机种子多次微调模型，研究训练随机性对超过30种认知偏见的影响。其次，我们引入了“交叉调优”——在模型之间交换指令数据集，以隔离偏见来源。这种方法使用了导致不同偏见模式的数据集，直接测试偏见是否取决于数据集。我们的发现表明，虽然训练随机性引入了一定的可变性，但偏见主要由预训练塑造：具有相同预训练基础的模型表现出更为相似的偏见模式，而仅仅共享微调数据的模型则不然。这些见解表明，在评估和减轻微调模型中的偏见时，需要考虑其预训练起源，而不仅仅是微调效果。这一视角可以指导未来开发评估和减轻LLMs中偏见的合理策略。 

---
# Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics 

**Title (ZH)**: 评估检索增强生成代理在天体物理学自主科学发现中的性能 

**Authors**: Xueqing Xu, Boris Bolliet, Adrian Dimitrov, Andrew Laverick, Francisco Villaescusa-Navarro, Licong Xu, Íñigo Zubeldia  

**Link**: [PDF](https://arxiv.org/pdf/2507.07155)  

**Abstract**: We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this this http URL RAG configurations are manually evaluated by a human expert, that is, a total of 945 generated answers were assessed. We find that currently the best RAG agent configuration is with OpenAI embedding and generative model, yielding 91.4\% accuracy. Using our human evaluation results we calibrate LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human evaluation. These results allow us to systematically select the best RAG agent configuration for multi-agent system for autonomous scientific discovery in astrophysics (e.g., cmbagent presented in a companion paper) and provide us with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system publicly available for further use by the astrophysics community. 

**Abstract (ZH)**: 我们评估了9种检索增强生成（RAG）代理配置在我们特别为此构建的105个天体物理学问答（QA）数据集上的性能。这些RAG配置由人工专家手动评估，总共评估了945个生成的答案。我们发现当前最佳的RAG代理配置是使用OpenAI嵌入和生成模型，准确率为91.4%。利用我们的人工评估结果，我们校准了一个LLM-as-a-Judge（LLMaaJ）系统，该系统可以作为人类评估的稳健代理。这些结果使我们能够系统地选择最适合多代理系统以实现自主天体物理学发现（例如，同伴论文中介绍的cmbagent）的RAG代理配置，并提供了一个可以扩展到数千个天体物理学问答对的LLMaaJ系统。我们公开了我们的QA数据集、人工评估结果、RAG管道和LLMaaJ系统，以供天体物理学社区进一步使用。 

---
# Aerial Maritime Vessel Detection and Identification 

**Title (ZH)**: 空中海上船舶检测与识别 

**Authors**: Antonella Barisic Kulas, Frano Petric, Stjepan Bogdan  

**Link**: [PDF](https://arxiv.org/pdf/2507.07153)  

**Abstract**: Autonomous maritime surveillance and target vessel identification in environments where Global Navigation Satellite Systems (GNSS) are not available is critical for a number of applications such as search and rescue and threat detection. When the target vessel is only described by visual cues and its last known position is not available, unmanned aerial vehicles (UAVs) must rely solely on on-board vision to scan a large search area under strict computational constraints. To address this challenge, we leverage the YOLOv8 object detection model to detect all vessels in the field of view. We then apply feature matching and hue histogram distance analysis to determine whether any detected vessel corresponds to the target. When found, we localize the target using simple geometric principles. We demonstrate the proposed method in real-world experiments during the MBZIRC2023 competition, integrated into a fully autonomous system with GNSS-denied navigation. We also evaluate the impact of perspective on detection accuracy and localization precision and compare it with the oracle approach. 

**Abstract (ZH)**: 在全球导航卫星系统（GNSS）不可用的环境中实现自主 maritime 监视与目标船只识别对于搜救和威胁检测等应用至关重要。当目标船只仅通过视觉特征描述且其最后已知位置无法获得时，无人机必须在严格的计算约束下，仅依靠机载视觉扫描大面积搜索区域。为应对这一挑战，我们利用 YOLOv8 对象检测模型来检测视野中的所有船只。然后我们应用特征匹配和色调直方图距离分析来判断是否存在与目标相匹配的船只。找到目标后，我们使用简单的几何原理进行目标定位。我们在 2023 年 MBZIRC 竞赛中通过实际实验演示了所提出的方法，该方法整合到了一个具备 GNSS 禁用导航功能的完全自主系统中。我们还评估了视角对检测精度和定位精度的影响，并将其与最优方法进行了比较。 

---
# Robust Multimodal Large Language Models Against Modality Conflict 

**Title (ZH)**: 鲁棒多模态大型语言模型对抗模态冲突 

**Authors**: Zongmeng Zhang, Wengang Zhou, Jie Zhao, Houqiang Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.07151)  

**Abstract**: Despite the impressive capabilities of multimodal large language models (MLLMs) in vision-language tasks, they are prone to hallucinations in real-world scenarios. This paper investigates the hallucination phenomenon in MLLMs from the perspective of modality conflict. Unlike existing works focusing on the conflicts between model responses and inputs, we study the inherent conflicts in inputs from different modalities that place MLLMs in a dilemma and directly lead to hallucinations. We formally define the modality conflict and construct a dataset named Multimodal Modality Conflict (MMMC) to simulate this phenomenon in vision-language tasks. Three methods based on prompt engineering, supervised fine-tuning, and reinforcement learning are proposed to alleviate the hallucination caused by modality conflict. Extensive experiments are conducted on the MMMC dataset to analyze the merits and demerits of these methods. Our results show that the reinforcement learning method achieves the best performance in mitigating the hallucination under modality conflict, while the supervised fine-tuning method shows promising and stable performance. Our work sheds light on the unnoticed modality conflict that leads to hallucinations and provides more insights into the robustness of MLLMs. 

**Abstract (ZH)**: 尽管多模态大规模语言模型（MLLMs）在视觉语言任务中表现出色，但在现实场景中容易出现幻觉现象。本文从模态冲突的角度研究MLLMs的幻觉现象。不同于现有工作关注模型响应与输入之间的冲突，我们研究不同模态输入固有的冲突，这些冲突将MLLMs置于困境并直接导致幻觉现象。我们正式定义了模态冲突，并构建了一个名为Multimodal Modality Conflict (MMMC)的数据集，以在视觉语言任务中模拟这一现象。我们提出了基于提示工程、监督微调和强化学习的三种方法，以缓解由模态冲突引起的幻觉。我们在MMMC数据集上进行了大量实验，以分析这些方法的优缺点。结果显示，强化学习方法在缓解模态冲突引起的幻觉方面表现最佳，而监督微调方法表现出有希望且稳定的性能。我们的工作照亮了导致幻觉的未被注意的模态冲突，并为进一步理解MLLMs的健壮性提供了新的见解。 

---
# Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation 

**Title (ZH)**: 带加权多提示学习的大语言模型描述无介导知识精炼 

**Authors**: Sua Lee, Kyubum Shin, Jung Ho Park  

**Link**: [PDF](https://arxiv.org/pdf/2507.07147)  

**Abstract**: Recent advances in pre-trained Vision Language Models (VLM) have shown promising potential for effectively adapting to downstream tasks through prompt learning, without the need for additional annotated paired datasets. To supplement the text information in VLM trained on correlations with vision data, new approaches leveraging Large Language Models (LLM) in prompts have been proposed, enhancing robustness to unseen and diverse data. Existing methods typically extract text-based responses (i.e., descriptions) from LLM to incorporate into prompts; however, this approach suffers from high variability and low reliability. In this work, we propose Description-free Multi-prompt Learning(DeMul), a novel method that eliminates the process of extracting descriptions and instead directly distills knowledge from LLM into prompts. By adopting a description-free approach, prompts can encapsulate richer semantics while still being represented as continuous vectors for optimization, thereby eliminating the need for discrete pre-defined templates. Additionally, in a multi-prompt setting, we empirically demonstrate the potential of prompt weighting in reflecting the importance of different prompts during training. Experimental results show that our approach achieves superior performance across 11 recognition datasets. 

**Abstract (ZH)**: 近期预训练视觉语言模型的进展展示了通过提示学习有效适应下游任务的有前景潜力，无需额外标注的图文配对数据。为补充预训练于视觉数据关联上的VLM中的文本信息，提出了利用大型语言模型（LLM）的新提示方法，增强了对未见和多样化数据的鲁棒性。现有方法通常从LLM中提取基于文本的响应（即描述）并将其融入提示中；然而，这种方法存在高变异性且可靠性低的问题。为此，我们提出了无描述多提示学习（DeMul），一种新颖的方法，该方法消除了提取描述的过程，而是直接从LLM中提炼知识进入提示。通过采用无描述的方法，提示可以封装更丰富的语义，同时仍然以连续向量的形式进行优化，从而消除了离散预定义模板的需求。此外，在多提示设置中，我们实证证明了提示加权在训练过程中反映不同提示重要性的潜力。实验结果表明，我们的方法在11个识别数据集中实现了优越的效果。 

---
# Generative Panoramic Image Stitching 

**Title (ZH)**: 生成全景图像拼接 

**Authors**: Mathieu Tuli, Kaveh Kamali, David B. Lindell  

**Link**: [PDF](https://arxiv.org/pdf/2507.07133)  

**Abstract**: We introduce the task of generative panoramic image stitching, which aims to synthesize seamless panoramas that are faithful to the content of multiple reference images containing parallax effects and strong variations in lighting, camera capture settings, or style. In this challenging setting, traditional image stitching pipelines fail, producing outputs with ghosting and other artifacts. While recent generative models are capable of outpainting content consistent with multiple reference images, they fail when tasked with synthesizing large, coherent regions of a panorama. To address these limitations, we propose a method that fine-tunes a diffusion-based inpainting model to preserve a scene's content and layout based on multiple reference images. Once fine-tuned, the model outpaints a full panorama from a single reference image, producing a seamless and visually coherent result that faithfully integrates content from all reference images. Our approach significantly outperforms baselines for this task in terms of image quality and the consistency of image structure and scene layout when evaluated on captured datasets. 

**Abstract (ZH)**: 生成全景图像缝合任务：基于多个参考图像合成忠实于内容且无拼接痕迹的无缝全景图像 

---
# DpDNet: An Dual-Prompt-Driven Network for Universal PET-CT Segmentation 

**Title (ZH)**: DpDNet：一种双提示驱动的通用PET-CT分割网络 

**Authors**: Xinglong Liang, Jiaju Huang, Luyi Han, Tianyu Zhang, Xin Wang, Yuan Gao, Chunyao Lu, Lishan Cai, Tao Tan, Ritse Mann  

**Link**: [PDF](https://arxiv.org/pdf/2507.07126)  

**Abstract**: PET-CT lesion segmentation is challenging due to noise sensitivity, small and variable lesion morphology, and interference from physiological high-metabolic signals. Current mainstream approaches follow the practice of one network solving the segmentation of multiple cancer lesions by treating all cancers as a single task. However, this overlooks the unique characteristics of different cancer types. Considering the specificity and similarity of different cancers in terms of metastatic patterns, organ preferences, and FDG uptake intensity, we propose DpDNet, a Dual-Prompt-Driven network that incorporates specific prompts to capture cancer-specific features and common prompts to retain shared knowledge. Additionally, to mitigate information forgetting caused by the early introduction of prompts, prompt-aware heads are employed after the decoder to adaptively handle multiple segmentation tasks. Experiments on a PET-CT dataset with four cancer types show that DpDNet outperforms state-of-the-art models. Finally, based on the segmentation results, we calculated MTV, TLG, and SUVmax for breast cancer survival analysis. The results suggest that DpDNet has the potential to serve as a valuable tool for personalized risk stratification, supporting clinicians in optimizing treatment strategies and improving outcomes. Code is available at this https URL. 

**Abstract (ZH)**: PET-CT病灶分割由于噪声敏感性、小且变化多端的病灶形态以及生理高代谢信号的干扰而具有挑战性。当前主流方法将所有癌症视为单一任务来解决多个癌症病灶的分割问题，但忽略了不同癌症类型的独特特征。考虑到不同癌症在转移模式、器官偏好和氟脱氧葡萄糖摄取强度上的特异性和相似性，我们提出DpDNet，这是一种双重提示驱动网络，结合了特定提示以捕捉癌症特异性特征，并结合了通用提示以保留共享知识。此外，为了减轻过早引入提示造成的知识遗忘，我们在解码器之后使用提示感知头部以适应性地处理多个分割任务。实验结果表明，DpDNet在包含四种癌症类型的PET-CT数据集上优于现有最先进的模型。最后，基于分割结果，我们计算了乳腺癌的MTV、TLG和SUVmax，用于生存分析。结果表明，DpDNet有潜力作为个性化风险分层的重要工具，支持临床医生优化治疗策略并改善预后。代码可在以下链接获取。 

---
# Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding 

**Title (ZH)**: 螺旋并行性：重思交互式百万级token LLM解码的分片策略 

**Authors**: Nidhi Bhatia, Ankit More, Ritika Borkar, Tiyasa Mitra, Ramon Matas, Ritchie Zhao, Maximilian Golub, Dheevatsa Mudigere, Brian Pharris, Bita Darvish Rouhani  

**Link**: [PDF](https://arxiv.org/pdf/2507.07120)  

**Abstract**: As LLMs scale to multi-million-token KV histories, real-time autoregressive decoding under tight Token-to-Token Latency (TTL) constraints faces growing pressure. Two core bottlenecks dominate: accessing Feed-Forward Network (FFN) weights and reading long KV caches. While Tensor Parallelism (TP) helps mitigate the cost of FFN weight reads, it does not scale well for attention. When TP width exceeds the number of KV heads, it leads to inefficient KV duplication, limits parallelism, and constrains batch size. Simultaneously, DRAM reads for long KV histories scale linearly with batch size, further capping efficiency.
We introduce Helix Parallelism, a hybrid execution strategy that applies KV parallelism during attention to shard KV caches across GPUs, then reuses the same GPUs for TP in dense LLMs or TPxExpert Parallel (EP) in MoEs during FFN computation. To preserve exact attention behavior, Helix includes a lightweight communication step. To minimize the exposed communication cost, we introduce Helix HOP-B. Helix HOP-B effectively minimizes communication overhead through batchwise overlap, preserving low TTL while improving GPU efficiency. Compared to conventional parallelism approaches, Helix reduces TTL by up to 1.5x at fixed batch sizes and supports up to 32x larger batches under the same latency budget for DeepSeek-R1, pushing forward the throughput-latency Pareto on Blackwell and making real-time inference with ultra-long-sequence practical. 

**Abstract (ZH)**: Helix 并行策略：同时优化注意力和前向网络的内存访问和并行计算 

---
# Collective Communication Profiling of Modern-day Machine Learning Workloads 

**Title (ZH)**: 现代机器学习工作负载的集体通信剖析 

**Authors**: Jit Gupta, Andrew Li, Tarun Banka, Ariel Cohen, T. Sridhar, Raj Yavatkar  

**Link**: [PDF](https://arxiv.org/pdf/2507.07117)  

**Abstract**: Machine Learning jobs, carried out on large number of distributed high performance systems, involve periodic communication using operations like AllReduce, AllGather, and Broadcast. These operations may create high bandwidth and bursty traffic patterns, leading to network congestion and packet loss, thus impacting the performance of these jobs. Hence it is imperative to analyze these patterns, which can be helpful in provisioning network resources depending on the type of machine learning workloads. In this poster we carry out extensive analysis of the collective communication behavior seen in a wide variety of models (ex. DeepSeek, GPT, Llama, etc.) To achieve this we instrument Nvidia Collective Communication Library logging functionality for richer context about the collectives and workloads. We adjust configuration parameters that influence collective communication behavior, such as parallelism, number of nodes, and model type. This overview presents and discusses some of the results on the collective communication behavior for the open source DeepSeek V3 inferencing model, which includes operation type and count, transfer sizes per operation, and request size distribution. Our analysis shows that it makes sense to rethink current collective communication frameworks and network topologies so as to accommodate the effect of network anomalies on the mentioned workloads. 

**Abstract (ZH)**: 基于大规模分布式高性能系统的机器学习任务中， Collective 通信行为分析及其对网络资源的需求 

---
# Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces 

**Title (ZH)**: 分析分布式账本技术在数据空间中的语义数据存储 

**Authors**: Juan Cano-Benito, Andrea Cimmino, Sven Hertling, Heiko Paulheim, Raúl García-Castro  

**Link**: [PDF](https://arxiv.org/pdf/2507.07116)  

**Abstract**: Data spaces are emerging as decentralised infrastructures that enable sovereign, secure, and trustworthy data exchange among multiple participants. To achieve semantic interoperability within these environments, the use of semantic web technologies and knowledge graphs has been proposed. Although distributed ledger technologies (DLT) fit as the underlying infrastructure for data spaces, there remains a significant gap in terms of the efficient storage of semantic data on these platforms. This paper presents a systematic evaluation of semantic data storage across different types of DLT (public, private, and hybrid), using a real-world knowledge graph as an experimental basis. The study compares performance, storage efficiency, resource consumption, and the capabilities to update and query semantic data. The results show that private DLTs are the most efficient for storing and managing semantic content, while hybrid DLTs offer a balanced trade-off between public auditability and operational efficiency. This research leads to a discussion on the selection of the most appropriate DLT infrastructure based on the data sovereignty requirements of decentralised data ecosystems. 

**Abstract (ZH)**: 数据空间中的语义数据存储：分布式账本技术的系统评价 

---
# Multi-level Mixture of Experts for Multimodal Entity Linking 

**Title (ZH)**: 多层专家混合模型用于多模态实体链接 

**Authors**: Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan  

**Link**: [PDF](https://arxiv.org/pdf/2507.07108)  

**Abstract**: Multimodal Entity Linking (MEL) aims to link ambiguous mentions within multimodal contexts to associated entities in a multimodal knowledge base. Existing approaches to MEL introduce multimodal interaction and fusion mechanisms to bridge the modality gap and enable multi-grained semantic matching. However, they do not address two important problems: (i) mention ambiguity, i.e., the lack of semantic content caused by the brevity and omission of key information in the mention's textual context; (ii) dynamic selection of modal content, i.e., to dynamically distinguish the importance of different parts of modal information. To mitigate these issues, we propose a Multi-level Mixture of Experts (MMoE) model for MEL. MMoE has four components: (i) the description-aware mention enhancement module leverages large language models to identify the WikiData descriptions that best match a mention, considering the mention's textual context; (ii) the multimodal feature extraction module adopts multimodal feature encoders to obtain textual and visual embeddings for both mentions and entities; (iii)-(iv) the intra-level mixture of experts and inter-level mixture of experts modules apply a switch mixture of experts mechanism to dynamically and adaptively select features from relevant regions of information. Extensive experiments demonstrate the outstanding performance of MMoE compared to the state-of-the-art. MMoE's code is available at: this https URL. 

**Abstract (ZH)**: 多模态实体链接（MEL）旨在将多模态上下文中的模糊提及与多模态知识库中的相关实体进行链接。现有的MEL方法引入了多模态交互和融合机制以弥合模态鸿沟，并实现多粒度语义匹配。然而，它们未能解决两个重要问题：（i）提及模糊性，即提及文本上下文中关键信息遗漏导致的语义内容不足；（ii）模态内容的动态选择，即区分不同模态信息部分的重要性。为缓解这些问题，我们提出了一种多层专家混合（MMoE）模型用于MEL。MMoE模型由四个组件组成：（i）描述感知的提及增强模块利用大语言模型识别与提及最匹配的WikiData描述，同时考虑提及的文本上下文；（ii）多模态特征提取模块采用多模态特征编码器为提及和实体获取文本和视觉嵌入；（iii）（iv）在同一层和跨层的专家混合模块中应用切换专家混合机制，以动态和适配地选择来自相关信息区域的特征。广泛实验证明，与现有方法相比，MMoE表现出色。MMoE的代码可在以下网址获取：this https URL。 

---
# Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks 

**Title (ZH)**: 生成式对抗性 evasion 和非分布检测以应对无人机网络攻击 

**Authors**: Deepak Kumar Panda, Weisi Guo  

**Link**: [PDF](https://arxiv.org/pdf/2506.21142)  

**Abstract**: The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions. 

**Abstract (ZH)**: 基于cGAN的隐秘对抗攻击制造框架：强化针对生成模型导向的网络入侵的 IDS 能力 

---
# A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping 

**Title (ZH)**: 深度学习解决方案综述：三维洪水 mapping 

**Authors**: Wenfeng Jia, Bin Liang, Yuxi Liu, Muhammad Arif Khan, Lihong Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2506.13201)  

**Abstract**: Flooding remains a major global challenge, worsened by climate change and urbanization, demanding advanced solutions for effective disaster management. While traditional 2D flood mapping techniques provide limited insights, 3D flood mapping, powered by deep learning (DL), offers enhanced capabilities by integrating flood extent and depth. This paper presents a comprehensive survey of deep learning-based 3D flood mapping, emphasizing its advancements over 2D maps by integrating flood extent and depth for effective disaster management and urban planning. The survey categorizes deep learning techniques into task decomposition and end-to-end approaches, applicable to both static and dynamic flood features. We compare key DL architectures, highlighting their respective roles in enhancing prediction accuracy and computational efficiency. Additionally, this work explores diverse data sources such as digital elevation models, satellite imagery, rainfall, and simulated data, outlining their roles in 3D flood mapping. The applications reviewed range from real-time flood prediction to long-term urban planning and risk assessment. However, significant challenges persist, including data scarcity, model interpretability, and integration with traditional hydrodynamic models. This survey concludes by suggesting future directions to address these limitations, focusing on enhanced datasets, improved models, and policy implications for flood management. This survey aims to guide researchers and practitioners in leveraging DL techniques for more robust and reliable 3D flood mapping, fostering improved flood management strategies. 

**Abstract (ZH)**: 深学习驱动的3D洪水mapping综述：提高灾害管理和城市规划的有效性 

---
