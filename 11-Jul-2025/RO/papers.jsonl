{'arxiv_id': 'arXiv:2507.07980', 'title': 'UniTac: Whole-Robot Touch Sensing Without Tactile Sensors', 'authors': 'Wanjia Fu, Hongyu Li, Ivy X. He, Stefanie Tellex, Srinath Sridhar', 'link': 'https://arxiv.org/abs/2507.07980', 'abstract': 'Robots can better interact with humans and unstructured environments through touch sensing. However, most commercial robots are not equipped with tactile skins, making it challenging to achieve even basic touch-sensing functions, such as contact localization. We present UniTac, a data-driven whole-body touch-sensing approach that uses only proprioceptive joint sensors and does not require the installation of additional sensors. Our approach enables a robot equipped solely with joint sensors to localize contacts. Our goal is to democratize touch sensing and provide an off-the-shelf tool for HRI researchers to provide their robots with touch-sensing capabilities. We validate our approach on two platforms: the Franka robot arm and the Spot quadruped. On Franka, we can localize contact to within 8.0 centimeters, and on Spot, we can localize to within 7.2 centimeters at around 2,000 Hz on an RTX 3090 GPU without adding any additional sensors to the robot. Project website: this https URL.', 'abstract_zh': '机器人通过触觉感知能够更好地与人类和未结构化环境互动。然而，大多数商用机器人并未配备触觉皮肤，使得实现基本的触觉感知功能，如接触定位，极具挑战性。我们提出了UniTac，一种基于数据的整体触觉感知方法，仅使用本体感受关节传感器，不需要安装额外传感器。该方法使仅配备关节传感器的机器人能够定位接触点。我们的目标是普及触觉感知，并为HRI研究人员提供一种即用型工具，以赋予其机器人触觉感知能力。我们在Franka机器人臂和Spot四足机器人上验证了该方法。在Franka上，我们可以将接触定位精度控制在8.0厘米以内；在Spot上，我们在RTX 3090 GPU上以约2000 Hz的频率将定位精度控制在7.2厘米以内，且无需向机器人添加额外传感器。项目网址：this https URL。', 'title_zh': 'UniTac: 不使用触觉传感器的全身机器人触觉感知'}
{'arxiv_id': 'arXiv:2507.07872', 'title': 'Improving AEBS Validation Through Objective Intervention Classification Leveraging the Prediction Divergence Principle', 'authors': 'Daniel Betschinske, Steven Peters', 'link': 'https://arxiv.org/abs/2507.07872', 'abstract': 'The safety validation of automatic emergency braking system (AEBS) requires accurately distinguishing between false positive (FP) and true positive (TP) system activations. While simulations allow straightforward differentiation by comparing scenarios with and without interventions, analyzing activations from open-loop resimulations - such as those from field operational testing (FOT) - is more complex. This complexity arises from scenario parameter uncertainty and the influence of driver interventions in the recorded data. Human labeling is frequently used to address these challenges, relying on subjective assessments of intervention necessity or situational criticality, potentially introducing biases and limitations. This work proposes a rule-based classification approach leveraging the Prediction Divergence Principle (PDP) to address those issues. Applied to a simplified AEBS, the proposed method reveals key strengths, limitations, and system requirements for effective implementation. The findings suggest that combining this approach with human labeling may enhance the transparency and consistency of classification, thereby improving the overall validation process. While the rule set for classification derived in this work adopts a conservative approach, the paper outlines future directions for refinement and broader applicability. Finally, this work highlights the potential of such methods to complement existing practices, paving the way for more reliable and reproducible AEBS validation frameworks.', 'abstract_zh': '自动紧急制动系统（AEBS）的安全验证需要准确区分假阳性（FP）和真阳性（TP）系统激活。虽然模拟可以通过比较有干预和无干预的情景来进行直接区分，但分析来自开环重放的激活数据（如场操作测试FOT的数据）则更加复杂。这种复杂性源自情景参数的不确定性以及记录数据中驾驶员干预的影响。通常依赖人工标注来应对这些挑战，但这种做法可能会引入主观评估带来的偏见和局限性。本文提出了一种基于规则的分类方法，利用预测发散原则（PDP）来解决这些问题。该方法应用于简化AEBS中，揭示了有效实施的关键优势、局限性和系统要求。研究结果表明，将该方法与人工标注结合使用可能提高分类的透明度和一致性，从而改善整体验证过程。虽然本文分类规则集采取了保守的方法，但文章概述了未来改进和更广泛适用性的方向。最后，本文强调了此类方法有潜力补充现有实践，为更可靠和可再现的AEBS验证框架铺平道路。', 'title_zh': '通过利用预测发散原则的目标介入分类改进AEBS验证'}
{'arxiv_id': 'arXiv:2507.07846', 'title': 'ROS Help Desk: GenAI Powered, User-Centric Framework for ROS Error Diagnosis and Debugging', 'authors': 'Kavindie Katuwandeniya, Samith Rajapaksha Jayasekara Widhanapathirana', 'link': 'https://arxiv.org/abs/2507.07846', 'abstract': "As the robotics systems increasingly integrate into daily life, from smart home assistants to the new-wave of industrial automation systems (Industry 4.0), there's an increasing need to bridge the gap between complex robotic systems and everyday users. The Robot Operating System (ROS) is a flexible framework often utilised in writing robot software, providing tools and libraries for building complex robotic systems. However, ROS's distributed architecture and technical messaging system create barriers for understanding robot status and diagnosing errors. This gap can lead to extended maintenance downtimes, as users with limited ROS knowledge may struggle to quickly diagnose and resolve system issues. Moreover, this deficit in expertise often delays proactive maintenance and troubleshooting, further increasing the frequency and duration of system interruptions. ROS Help Desk provides intuitive error explanations and debugging support, dynamically customized to users of varying expertise levels. It features user-centric debugging tools that simplify error diagnosis, implements proactive error detection capabilities to reduce downtime, and integrates multimodal data processing for comprehensive system state understanding across multi-sensor data (e.g., lidar, RGB). Testing qualitatively and quantitatively with artificially induced errors demonstrates the system's ability to proactively and accurately diagnose problems, ultimately reducing maintenance time and fostering more effective human-robot collaboration.", 'abstract_zh': '随着机器人系统越来越多地融入日常生活中，从智能家庭助手到工业4.0新一代自动化系统， bridges the gap between复杂的机器人系统和普通用户的需求不断增加。机器人操作系统（ROS）是一个灵活的框架，常用于编写机器人软件，提供构建复杂机器人系统的工具和库。然而，ROS的分布式架构和技术消息系统会为理解机器人状态和诊断错误设置障碍。这一差距可能导致维护时间延长，因为知识有限的用户可能难以快速诊断和解决问题。此外，这种专业知识的不足往往会延迟主动维护和故障排除，从而增加系统中断的频率和持续时间。ROS Help Desk提供了直观的错误解释和调试支持，可以根据用户的不同专业水平动态定制。它配备了以用户为中心的调试工具，简化了错误诊断过程，实现了主动错误检测能力以减少停机时间，并整合了多模态数据处理，以便全面理解多传感器数据（如激光雷达、RGB）下的系统状态。通过引入人工诱导的错误进行定性和定量测试，展示了该系统主动且准确地诊断问题的能力，最终减少了维护时间并促进了更有效的机器人协作。', 'title_zh': 'ROS Help Desk：以用户为中心的基于GenAI的ROS错误诊断与调试框架'}
{'arxiv_id': 'arXiv:2507.07845', 'title': 'Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System', 'authors': 'David Warutumo, Ciira wa Maina', 'link': 'https://arxiv.org/abs/2507.07845', 'abstract': "Autonomous agents, particularly in the field of robotics, rely on sensory information to perceive and navigate their environment. However, these sensory inputs are often imperfect, leading to distortions in the agent's internal representation of the world. This paper investigates the nature of these perceptual distortions and how they influence autonomous representation learning using a minimal robotic system. We utilize a simulated two-wheeled robot equipped with distance sensors and a compass, operating within a simple square environment. Through analysis of the robot's sensor data during random exploration, we demonstrate how a distorted perceptual space emerges. Despite these distortions, we identify emergent structures within the perceptual space that correlate with the physical environment, revealing how the robot autonomously learns a structured representation for navigation without explicit spatial information. This work contributes to the understanding of embodied cognition, minimal agency, and the role of perception in self-generated navigation strategies in artificial life.", 'abstract_zh': '自主代理，特别是在机器人领域，依赖于感官信息来感知和导航其环境。然而，这些感官输入往往是不完美的，导致代理内部对世界的表征出现失真。本文通过一个简易的轮式机器人系统研究了这些感知失真的本质及其如何影响自主表征学习。我们利用一个装备有距离传感器和罗盘的模拟两轮机器人，在一个简单的方形环境中操作。通过对机器人在随机探索过程中的传感器数据进行分析，我们展示了如何出现一个失真的感知空间。尽管存在这些失真，我们发现感知空间中存在与物理环境相关的新兴结构，揭示了在没有显性空间信息的情况下，机器人如何自主学习一个结构化导航表示。本文为了解体态认知、最小代理以及感知在人工生命中自我生成导航策略中的作用做出了贡献。', 'title_zh': '感知失真与最小机器人系统中的自主表征学习'}
{'arxiv_id': 'arXiv:2507.07825', 'title': 'Beyond Robustness: Learning Unknown Dynamic Load Adaptation for Quadruped Locomotion on Rough Terrain', 'authors': 'Leixin Chang, Yuxuan Nai, Hua Chen, Liangjing Yang', 'link': 'https://arxiv.org/abs/2507.07825', 'abstract': 'Unknown dynamic load carrying is one important practical application for quadruped robots. Such a problem is non-trivial, posing three major challenges in quadruped locomotion control. First, how to model or represent the dynamics of the load in a generic manner. Second, how to make the robot capture the dynamics without any external sensing. Third, how to enable the robot to interact with load handling the mutual effect and stabilizing the load. In this work, we propose a general load modeling approach called load characteristics modeling to capture the dynamics of the load. We integrate this proposed modeling technique and leverage recent advances in Reinforcement Learning (RL) based locomotion control to enable the robot to infer the dynamics of load movement and interact with the load indirectly to stabilize it and realize the sim-to-real deployment to verify its effectiveness in real scenarios. We conduct extensive comparative simulation experiments to validate the effectiveness and superiority of our proposed method. Results show that our method outperforms other methods in sudden load resistance, load stabilizing and locomotion with heavy load on rough terrain. \\href{this https URL}{Project Page}.', 'abstract_zh': '未知动力负载承载是四足机器人的一项重要实际应用。这个问题并不简单，在四足机器人运动控制中提出了三大挑战。首先，如何以通用方式建模或表示负载的动力学。其次，如何让机器人在没有任何外部传感的情况下捕捉到负载的动力学。第三，如何使机器人能够处理负载交互效应并稳定负载。在本文中，我们提出了一种称为负载特性建模的通用负载建模方法，以捕捉负载的动力学。我们结合了所提出建模技术，并利用基于强化学习（RL）的运动控制最近的进展，使机器人能够推断负载移动的动力学并通过间接方式与负载互动以稳定它，并实现从仿真到现实世界的部署，以验证其在实际场景中的有效性。我们进行了大量的比较仿真实验来验证我们提出方法的有效性和优越性。结果表明，我们的方法在突然负载抵抗、负载稳定和在粗糙地形上承载重负载方面优于其他方法。点击此处查看项目页面。', 'title_zh': '超越鲁棒性：学习未知动态负载适应以实现粗糙地形上的四足运动'}
{'arxiv_id': 'arXiv:2507.07794', 'title': 'Collaborative Human-Robot Surgery for Mandibular Angle Split Osteotomy: Optical Tracking based Approach', 'authors': 'Zhe Han, Huanyu Tian, Tom Vercauteren, Da Liu, Changsheng Li, Xingguang Duan', 'link': 'https://arxiv.org/abs/2507.07794', 'abstract': "Mandibular Angle Split Osteotomy (MASO) is a significant procedure in oral and maxillofacial surgery. Despite advances in technique and instrumentation, its success still relies heavily on the surgeon's experience. In this work, a human-robot collaborative system is proposed to perform MASO according to a preoperative plan and under guidance of a surgeon. A task decomposition methodology is used to divide the collaborative surgical procedure into three subtasks: (1) positional control and (2) orientation control, both led by the robot for precise alignment; and (3) force-control, managed by surgeon to ensure safety. Additionally, to achieve patient tracking without the need for a skull clamp, an optical tracking system (OTS) is utilized. Movement of the patient mandibular is measured with an optical-based tracker mounted on a dental occlusal splint. A registration method and Robot-OTS calibration method are introduced to achieve reliable navigation within our framework. The experiments of drilling were conducted on the realistic phantom model, which demonstrated that the average error between the planned and actual drilling points is 1.85mm.", 'abstract_zh': '下颌角劈开截骨术（MASO）的人机协作系统及其在术前计划和外科医生指导下执行的研究', 'title_zh': '基于光学跟踪的方法协作机器人辅助下颌角劈开截骨手术'}
{'arxiv_id': 'arXiv:2507.07752', 'title': 'IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments', 'authors': 'Thanh Nguyen Canh, Bao Nguyen Quoc, Haolan Zhang, Bupesh Rethinam Veeraiah, Xiem HoangVan, Nak Young Chong', 'link': 'https://arxiv.org/abs/2507.07752', 'abstract': "Robust Visual SLAM (vSLAM) is essential for autonomous systems operating in real-world environments, where challenges such as dynamic objects, low texture, and critically, varying illumination conditions often degrade performance. Existing feature-based SLAM systems rely on fixed front-end parameters, making them vulnerable to sudden lighting changes and unstable feature tracking. To address these challenges, we propose ``IRAF-SLAM'', an Illumination-Robust and Adaptive Feature-Culling front-end designed to enhance vSLAM resilience in complex and challenging environments. Our approach introduces: (1) an image enhancement scheme to preprocess and adjust image quality under varying lighting conditions; (2) an adaptive feature extraction mechanism that dynamically adjusts detection sensitivity based on image entropy, pixel intensity, and gradient analysis; and (3) a feature culling strategy that filters out unreliable feature points using density distribution analysis and a lighting impact factor. Comprehensive evaluations on the TUM-VI and European Robotics Challenge (EuRoC) datasets demonstrate that IRAF-SLAM significantly reduces tracking failures and achieves superior trajectory accuracy compared to state-of-the-art vSLAM methods under adverse illumination conditions. These results highlight the effectiveness of adaptive front-end strategies in improving vSLAM robustness without incurring significant computational overhead. The implementation of IRAF-SLAM is publicly available at https://thanhnguyencanh. this http URL.", 'abstract_zh': '鲁棒视觉SLAM（vSLAM）对于在实际环境中共自主系统至关重要，但动态物体、低纹理和关键的光照条件变化常常会降低其性能。现有的基于特征的SLAM系统依赖固定前端参数，使其对突发性光照变化和不稳定特征跟踪非常脆弱。为解决这些问题，我们提出了“IRAF-SLAM”，一种鲁棒性和自适应特征剔除的前端设计，旨在增强vSLAM在复杂和具有挑战性环境中的鲁棒性。我们的方法引入了：（1）一种图像增强方案，用于在不同光照条件下预处理和调整图像质量；（2）一种自适应特征提取机制，根据图像熵、像素强度和梯度分析动态调整检测灵敏度；以及（3）一种特征剔除策略，使用密度分布分析和光照影响因子筛选不可靠的特征点。在TUM-VI和欧洲机器人挑战赛（EuRoC）数据集上的综合评估表明，IRAF-SLAM在不良光照条件下显著减少了跟踪失败，并实现了优于现有最先进的vSLAM方法的轨迹准确性。这些结果突显了自适应前端策略在提高vSLAM鲁棒性方面的有效性，而不会造成显著的计算开销。IRAF-SLAM的实现已公开发布于<https://thanhnguyencanh. this http URL>。', 'title_zh': 'IRAF-SLAM：具有光照鲁棒性和自适应特征精简前端的视觉SLAM技术'}
{'arxiv_id': 'arXiv:2507.07745', 'title': 'On the capabilities of LLMs for classifying and segmenting time series of fruit picking motions into primitive actions', 'authors': 'Eleni Konstantinidou, Nikolaos Kounalakis, Nikolaos Efstathopoulos, Dimitrios Papageorgiou', 'link': 'https://arxiv.org/abs/2507.07745', 'abstract': 'Despite their recent introduction to human society, Large Language Models (LLMs) have significantly affected the way we tackle mental challenges in our everyday lives. From optimizing our linguistic communication to assisting us in making important decisions, LLMs, such as ChatGPT, are notably reducing our cognitive load by gradually taking on an increasing share of our mental activities. In the context of Learning by Demonstration (LbD), classifying and segmenting complex motions into primitive actions, such as pushing, pulling, twisting etc, is considered to be a key-step towards encoding a task. In this work, we investigate the capabilities of LLMs to undertake this task, considering a finite set of predefined primitive actions found in fruit picking operations. By utilizing LLMs instead of simple supervised learning or analytic methods, we aim at making the method easily applicable and deployable in a real-life scenario. Three different fine-tuning approaches are investigated, compared on datasets captured kinesthetically, using a UR10e robot, during a fruit-picking scenario.', 'abstract_zh': '尽管大型语言模型（LLMs） recently introduced to human society，它们已经显著影响了我们在日常生活中应对心理挑战的方式。从优化我们的语言交流到协助我们做出重要决策，像ChatGPT这样的LLMs通过逐渐承担越来越多的心理活动而显著减轻了我们的认知负担。在学习通过示范（Learning by Demonstration, LbD）的背景下，将复杂的动作分类和分割为基本动作，如推、拉、拧等，被认为是编码任务的关键步骤。在本研究中，我们探讨了LLMs执行这一任务的能力，考虑了水果采摘操作中预定义的基本动作集。通过使用LLMs而不是简单的监督学习或分析方法，我们旨在使该方法容易适用于现实场景并进行部署。我们在使用UR10e机器人在水果采摘场景中用手动捕捉的数据集上，调查了三种不同的微调方法，并进行比较。', 'title_zh': 'LLMs在将水果采摘动作的时间序列分类和分段为原始动作方面的能力'}
{'arxiv_id': 'arXiv:2507.07724', 'title': 'Distributed Surface Inspection via Operational Modal Analysis by a Swarm of Miniaturized Vibration-Sensing Robots', 'authors': 'Thiemen Siemensma, Niels de Boer, Bahar Haghighat', 'link': 'https://arxiv.org/abs/2507.07724', 'abstract': "Robot swarms offer the potential to serve a variety of distributed sensing applications. An interesting real-world application that stands to benefit significantly from deployment of swarms is structural monitoring, where traditional sensor networks face challenges in structural coverage due to their static nature. This paper investigates the deployment of a swarm of miniaturized vibration sensing robots to inspect and localize structural damages on a surface section within a high-fidelity simulation environment. In particular, we consider a 1 m x 1 m x 3 mm steel surface section and utilize finite element analysis using Abaqus to obtain realistic structural vibration data. The resulting vibration data is imported into the physics-based robotic simulator Webots, where we simulate the dynamics of our surface inspecting robot swarm. We employ (i) Gaussian process estimators to guide the robots' exploration as they collect vibration samples across the surface and (ii) operational modal analysis to detect structural damages by estimating and comparing existing and intact structural vibration patterns. We analyze the influence of exploration radii on estimation uncertainty and assess the effectiveness of our method across 10 randomized scenarios, where the number, locations, surface area, and depth of structural damages vary. Our simulation studies validate the efficacy of our miniaturized robot swarm for vibration-based structural inspection.", 'abstract_zh': '微型振动传感机器人 swarm 在高保真仿真环境中的结构检测部署研究', 'title_zh': '基于微型振动传感器机器人 swarm 的分布式表面检测方法研究via操作模态分析'}
{'arxiv_id': 'arXiv:2507.07718', 'title': 'Implementation and Assessment of an Augmented Training Curriculum for Surgical Robotics', 'authors': 'Alberto Rota, Ke Fan, Elena De Momi', 'link': 'https://arxiv.org/abs/2507.07718', 'abstract': "The integration of high-level assistance algorithms in surgical robotics training curricula may be beneficial in establishing a more comprehensive and robust skillset for aspiring surgeons, improving their clinical performance as a consequence. This work presents the development and validation of a haptic-enhanced Virtual Reality simulator for surgical robotics training, featuring 8 surgical tasks that the trainee can interact with thanks to the embedded physics engine. This virtual simulated environment is augmented by the introduction of high-level haptic interfaces for robotic assistance that aim at re-directing the motion of the trainee's hands and wrists toward targets or away from obstacles, and providing a quantitative performance score after the execution of each training this http URL experimental study shows that the introduction of enhanced robotic assistance into a surgical robotics training curriculum improves performance during the training process and, crucially, promotes the transfer of the acquired skills to an unassisted surgical scenario, like the clinical one.", 'abstract_zh': '在手术机器人培训课程中集成高级辅助算法可能有助于建立更为全面和 robust 的技能集，从而提高外科医生的临床表现。本研究介绍了用于手术机器人培训的高度增强型虚拟现实模拟器的发展与验证，该模拟器包含8项手术任务，通过嵌入的物理引擎使学员可以与其互动。该虚拟模拟环境通过引入高级触觉界面来增强机器人辅助功能，旨在引导学员的手和腕部朝向目标或远离障碍物，并在每次训练后提供定量的表现评分。本实验研究显示，将增强的机器人辅助引入手术机器人培训课程可以提高培训过程中的表现，更重要的是，促进了在未辅助的手术场景中，如临床场景中的技能迁移。', 'title_zh': 'augmented手术机器人培训课程的实施与评估'}
{'arxiv_id': 'arXiv:2507.07714', 'title': 'Adaptive Gaussian Mixture Models-based Anomaly Detection for under-constrained Cable-Driven Parallel Robots', 'authors': 'Julio Garrido, Javier Vales, Diego Silva-Muñiz, Enrique Riveiro, Pablo López-Matencio, Josué Rivera-Andrade', 'link': 'https://arxiv.org/abs/2507.07714', 'abstract': 'Cable-Driven Parallel Robots (CDPRs) are increasingly used for load manipulation tasks involving predefined toolpaths with intermediate stops. At each stop, where the platform maintains a fixed pose and the motors keep the cables under tension, the system must evaluate whether it is safe to proceed by detecting anomalies that could compromise performance (e.g., wind gusts or cable impacts). This paper investigates whether anomalies can be detected using only motor torque data, without additional sensors. It introduces an adaptive, unsupervised outlier detection algorithm based on Gaussian Mixture Models (GMMs) to identify anomalies from torque signals. The method starts with a brief calibration period, just a few seconds, during which a GMM is fit on known anomaly-free data. Real-time torque measurements are then evaluated using Mahalanobis distance from the GMM, with statistically derived thresholds triggering anomaly flags. Model parameters are periodically updated using the latest segments identified as anomaly-free to adapt to changing conditions. Validation includes 14 long-duration test sessions simulating varied wind intensities. The proposed method achieves a 100% true positive rate and 95.4% average true negative rate, with 1-second detection latency. Comparative evaluation against power threshold and non-adaptive GMM methods indicates higher robustness to drift and environmental variation.', 'abstract_zh': '基于电缆驱动并联机器人的异常检测方法：无需额外传感器的电机扭矩数据应用', 'title_zh': '基于自适应高斯混合模型的约束不足的缆驱动并联机器人异常检测方法'}
{'arxiv_id': 'arXiv:2507.07661', 'title': 'FiDTouch: A 3D Wearable Haptic Display for the Finger Pad', 'authors': 'Daria Trinitatova, Dzmitry Tsetserukou', 'link': 'https://arxiv.org/abs/2507.07661', 'abstract': 'The applications of fingertip haptic devices have spread to various fields from revolutionizing virtual reality and medical training simulations to facilitating remote robotic operations, proposing great potential for enhancing user experiences, improving training outcomes, and new forms of interaction. In this work, we present FiDTouch, a 3D wearable haptic device that delivers cutaneous stimuli to the finger pad, such as contact, pressure, encounter, skin stretch, and vibrotactile feedback. The application of a tiny inverted Delta robot in the mechanism design allows providing accurate contact and fast changing dynamic stimuli to the finger pad surface. The performance of the developed display was evaluated in a two-stage user study of the perception of static spatial contact stimuli and skin stretch stimuli generated on the finger pad. The proposed display, by providing users with precise touch and force stimuli, can enhance user immersion and efficiency in the fields of human-computer and human-robot interactions.', 'abstract_zh': '指尖触觉设备的应用已从革新虚拟现实和医疗培训模拟扩展到促进远程机器人操作等领域，展现出增强用户体验、改善培训效果和实现新型交互的巨大潜力。本文介绍了FiDTouch，这是一种3D可穿戴触觉设备，能够向指尖提供接触、压力、遭遇、皮肤拉伸和振动触觉反馈等皮肤刺激。机制设计中采用微型倒三角机器人可提供准确的接触和快速变化的动力学刺激。开发的显示装置在两阶段用户体验研究中得到了评估，该研究评估了在指尖产生的静态空间接触刺激和皮肤拉伸刺激的感知。所提出的技术通过为用户提供精确的触觉和力刺激，能提升人在人机交互和人机交互中的沉浸感和效率。', 'title_zh': 'FiDTouch：一种指腹3D触觉显示装置'}
{'arxiv_id': 'arXiv:2507.07467', 'title': 'SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation', 'authors': 'Juyeop Han, Lukas Lao Beyer, Guilherme V. Cavalheiro, Sertac Karaman', 'link': 'https://arxiv.org/abs/2507.07467', 'abstract': 'Autonomous flight in GPS denied indoor spaces requires trajectories that keep visual localization error tightly bounded across varied missions. Whereas visual inertial odometry (VIO) accumulates drift over time, scene coordinate regression (SCR) yields drift-free, high accuracy absolute pose estimation. We present a perception-aware framework that couples an evidential learning-based SCR pose estimator with a receding horizon trajectory optimizer. The optimizer steers the onboard camera toward pixels whose uncertainty predicts reliable scene coordinates, while a fixed-lag smoother fuses the low rate SCR stream with high rate IMU data to close the perception control loop in real time. In simulation, our planner reduces translation (rotation) mean error by 54% / 15% (40% / 31%) relative to yaw fixed and forward-looking baselines, respectively. Moreover, hardware in the loop experiment validates the feasibility of our proposed framework.', 'abstract_zh': 'GPS受限室内环境下的自主飞行要求保持视觉局部化误差在各种任务中紧密受限。我们提出了一种感知意识框架，该框架将基于证据学习的场景坐标回归（SCR）姿态估计器与展望型轨迹优化器耦合。优化器引导机载相机朝向不确定性预测可靠的场景坐标像素移动，同时固定延迟平滑器将低速率的SCR流与高率IMU数据融合，实现实时感知控制闭环。仿真结果显示，与固定的航向基准和前瞻基准相比，我们的规划者将平移（旋转）均方误差分别减少了54%/15%（40%/31%）。此外，硬件在环实验验证了我们所提框架的可行性。', 'title_zh': 'SCREP：基于场景坐标回归和似真性学习的感知aware轨迹生成'}
{'arxiv_id': 'arXiv:2507.07444', 'title': 'Towards Safe Autonomous Driving: A Real-Time Safeguarding Concept for Motion Planning Algorithms', 'authors': 'Korbinian Moller, Rafael Neher, Marvin Seegert, Johannes Betz', 'link': 'https://arxiv.org/abs/2507.07444', 'abstract': 'Ensuring the functional safety of motion planning modules in autonomous vehicles remains a critical challenge, especially when dealing with complex or learning-based software. Online verification has emerged as a promising approach to monitor such systems at runtime, yet its integration into embedded real-time environments remains limited. This work presents a safeguarding concept for motion planning that extends prior approaches by introducing a time safeguard. While existing methods focus on geometric and dynamic feasibility, our approach additionally monitors the temporal consistency of planning outputs to ensure timely system response. A prototypical implementation on a real-time operating system evaluates trajectory candidates using constraint-based feasibility checks and cost-based plausibility metrics. Preliminary results show that the safeguarding module operates within real-time bounds and effectively detects unsafe trajectories. However, the full integration of the time safeguard logic and fallback strategies is ongoing. This study contributes a modular and extensible framework for runtime trajectory verification and highlights key aspects for deployment on automotive-grade hardware. Future work includes completing the safeguarding logic and validating its effectiveness through hardware-in-the-loop simulations and vehicle-based testing. The code is available at: this https URL', 'abstract_zh': '确保自主车辆运动规划模块的功能安全仍是一项关键挑战，尤其是在处理复杂或基于学习的软件时。在线验证已 emerge as a promising approach to monitor such systems at runtime，但其在嵌入式实时环境中的集成仍受限。本研究提出了一种运动规划的安全保障概念，该概念扩展了先前的方法，通过引入时间保障来进一步保障。现有方法主要关注几何和动态可行性，而我们的方法还监控规划输出的时间一致性，以确保系统的及时响应。在实时操作系统上实现了一个原型，使用基于约束的可行性检查和基于成本的可行性度量来评估轨迹候选方案。初步结果表明，安全保障模块在实时界限内运行，并有效检测到不安全的轨迹。然而，时间保障逻辑和后备策略的全面集成仍在进行中。本研究提供了一个模块化和可扩展的实时轨迹验证框架，并强调了在汽车级硬件上部署的关键方面。未来的工作将完成安全保障逻辑，并通过硬件在环仿真和基于车辆的测试验证其有效性。相关代码可在以下链接获取：this https URL。', 'title_zh': '面向安全自主驾驶：一种实时安全保护概念在运动规划算法中的应用'}
{'arxiv_id': 'arXiv:2507.07376', 'title': 'PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments', 'authors': 'Hengrui Liu, Yi Feng, Qilong Zhang', 'link': 'https://arxiv.org/abs/2507.07376', 'abstract': 'Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.', 'abstract_zh': '多Agent搜索与救援（MASAR）在灾害响应、探索和侦察中发挥着重要作用。然而，动态和未知环境由于目标不可预测性和环境不确定性带来了显著挑战。为应对这些问题，我们提出PILOC框架，该框架无需全局先验知识，而是利用局部感知和通信。PILOC引入了化学物质逆向引导机制，以实现高效的协调和动态目标定位。通过局部通信促进去中心化的合作，显著减少了对全局频道的依赖。不同于传统的启发式方法，化学物质机制被嵌入到深度强化学习（DRL）的观测空间中，支持基于环境线索的间接代理协调。我们进一步将该策略集成到基于DRL的多Agent架构中，并进行了广泛的实验。结果表明，结合局部通信与基于化学物质的引导显著提升了搜索效率、适应性和系统鲁棒性。与现有方法相比，PILOC在动态和通信受限场景中表现更优，为未来的MASAR应用提供了有益的方向。', 'title_zh': 'PILOC: 一种pheromone逆向引导机制与局部通信框架，用于未知环境中的多agent动态目标搜索'}
{'arxiv_id': 'arXiv:2507.07370', 'title': 'Data-driven Kinematic Modeling in Soft Robots: System Identification and Uncertainty Quantification', 'authors': 'Zhanhong Jiang, Dylan Shah, Hsin-Jung Yang, Soumik Sarkar', 'link': 'https://arxiv.org/abs/2507.07370', 'abstract': 'Precise kinematic modeling is critical in calibration and controller design for soft robots, yet remains a challenging issue due to their highly nonlinear and complex behaviors. To tackle the issue, numerous data-driven machine learning approaches have been proposed for modeling nonlinear dynamics. However, these models suffer from prediction uncertainty that can negatively affect modeling accuracy, and uncertainty quantification for kinematic modeling in soft robots is underexplored. In this work, using limited simulation and real-world data, we first investigate multiple linear and nonlinear machine learning models commonly used for kinematic modeling of soft robots. The results reveal that nonlinear ensemble methods exhibit the most robust generalization performance. We then develop a conformal kinematic modeling framework for soft robots by utilizing split conformal prediction to quantify predictive position uncertainty, ensuring distribution-free prediction intervals with a theoretical guarantee.', 'abstract_zh': '精确的动力学建模对于软机器人校准和控制器设计至关重要，但由于其高度非线性和复杂性行为，仍是一个具有挑战性的问题。为应对这一挑战，提出了多种数据驱动的机器学习方法来建模非线性动态。然而，这些模型 prediction 的不确定性可能会影响建模准确性，而软机器人动力学建模的不确定性量化尚未得到充分探索。在本工作中，我们利用有限的仿真和真实世界数据，首先研究了常用于软机器人动力学建模的多种线性和非线性机器学习模型。结果表明，非线性集成方法表现出最稳健的泛化性能。随后，我们通过利用分割一致性预测开发了一个软机器人的动力学建模框架，以量化预测位置的不确定性，并确保无分布假设的预测区间具有理论保证。', 'title_zh': '软体机器人的数据驱动运动建模：系统辨识与不确定性量化'}
{'arxiv_id': 'arXiv:2507.07356', 'title': 'UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots', 'authors': 'Kangning Yin, Weishuai Zeng, Ke Fan, Zirui Wang, Qiang Zhang, Zheng Tian, Jingbo Wang, Jiangmiao Pang, Weinan Zhang', 'link': 'https://arxiv.org/abs/2507.07356', 'abstract': 'Humanoid robots must achieve diverse, robust, and generalizable whole-body control to operate effectively in complex, human-centric environments. However, existing methods, particularly those based on teacher-student frameworks often suffer from a loss of motion diversity during policy distillation and exhibit limited generalization to unseen behaviors. In this work, we present UniTracker, a simplified yet powerful framework that integrates a Conditional Variational Autoencoder (CVAE) into the student policy to explicitly model the latent diversity of human motion. By leveraging a learned CVAE prior, our method enables the student to retain expressive motion characteristics while improving robustness and adaptability under partial observations. The result is a single policy capable of tracking a wide spectrum of whole-body motions with high fidelity and stability. Comprehensive experiments in both simulation and real-world deployments demonstrate that UniTracker significantly outperforms MLP-based DAgger baselines in motion quality, generalization to unseen references, and deployment robustness, offering a practical and scalable solution for expressive humanoid control.', 'abstract_zh': '人形机器人必须在复杂的人本中心环境中实现多样、 robust 和普适的整体身体控制。然而，现有的方法，尤其是基于教师-学生框架的方法，在策略蒸馏过程中常常丧失运动多样性，并且对未见过的行为表现出有限的泛化能力。在本文中，我们提出了一种简化但强大的 UniTracker 框架，将条件变分自编码器（CVAE）集成到学生策略中，以明确建模人类运动的潜在多样性。通过利用学习到的 CVAE 先验，我们的方法使学生能够在保持表达性运动特征的同时，提高在部分观测条件下的鲁棒性和适应性。结果是单一策略能够以高保真度和稳定性跟踪广泛的全身运动。在仿真和真实世界部署中的全面实验表明，UniTracker 在运动质量、对未见过的参考的泛化能力和部署鲁棒性方面显著优于基于MLP的DAgger基线，提供了一种实用且可扩展的表达性人形控制解决方案。', 'title_zh': 'UniTracker: 学习通用全身运动跟踪器用于类人机器人'}
{'arxiv_id': 'arXiv:2507.07327', 'title': 'Effects of Wrist-Worn Haptic Feedback on Force Accuracy and Task Speed during a Teleoperated Robotic Surgery Task', 'authors': 'Brian B. Vuong, Josie Davidson, Sangheui Cheon, Kyujin Cho, Allison M. Okamura', 'link': 'https://arxiv.org/abs/2507.07327', 'abstract': 'Previous work has shown that the addition of haptic feedback to the hands can improve awareness of tool-tissue interactions and enhance performance of teleoperated tasks in robot-assisted minimally invasive surgery. However, hand-based haptic feedback occludes direct interaction with the manipulanda of surgeon console in teleoperated surgical robots. We propose relocating haptic feedback to the wrist using a wearable haptic device so that haptic feedback mechanisms do not need to be integrated into the manipulanda. However, it is unknown if such feedback will be effective, given that it is not co-located with the finger movements used for manipulation. To test if relocated haptic feedback improves force application during teleoperated tasks using da Vinci Research Kit (dVRK) surgical robot, participants learned to palpate a phantom tissue to desired forces. A soft pneumatic wrist-worn haptic device with an anchoring system renders tool-tissue interaction forces to the wrist of the user. Participants performed the palpation task with and without wrist-worn haptic feedback and were evaluated for the accuracy of applied forces. Participants demonstrated statistically significant lower force error when wrist-worn haptic feedback was provided. Participants also performed the palpation task with longer movement times when provided wrist-worn haptic feedback, indicating that the haptic feedback may have caused participants to operate at a different point in the speed-accuracy tradeoff curve.', 'abstract_zh': '之前的研究表明，向外科医生的手中添加触觉反馈可以提高对手工器械与组织交互的意识，增强远程操作任务在机器人辅助微创手术中的性能。然而，基于手的触觉反馈遮挡了与外科医生控制台操作对象的直接交互。我们提出使用可穿戴触觉设备将触觉反馈移至腕部，从而使触觉反馈机制无需集成到操作对象中。然而，尚未清楚这种反馈是否有效，因为操作对象使用的是手指运动，而非腕部运动。为了测试在使用达芬奇研究套件（dVRK）手术机器人进行远程操作任务时，移位触觉反馈是否能改善力的应用，参与者学会了在施加所需力的同时 palpate 幻影组织。一种带有锚定系统的柔软气动可穿戴触觉设备将工具-组织交互力传递至用户的腕部。参与者在有和无腕部触觉反馈的情况下完成了 palpation 任务，并根据施加力的准确性进行了评估。结果表明，提供腕部触觉反馈时，参与者施加的力的误差显著降低。此外，提供腕部触觉反馈时，参与者完成 palpation 任务所需的时间更长，这表明触觉反馈可能使参与者在速度与准确性权衡曲线的不同点上操作。', 'title_zh': '腕戴式触觉反馈对远程操作机器人手术任务中力量准确性及任务速度的影响'}
{'arxiv_id': 'arXiv:2507.07315', 'title': 'Classifying Emergence in Robot Swarms: An Observer-Dependent Approach', 'authors': 'Ricardo Vega, Cameron Nowzari', 'link': 'https://arxiv.org/abs/2507.07315', 'abstract': "Emergence and swarms are widely discussed topics, yet no consensus exists on their formal definitions. This lack of agreement makes it difficult not only for new researchers to grasp these concepts, but also for experts who may use the same terms to mean different things. Many attempts have been made to objectively define 'swarm' or 'emergence,' with recent work highlighting the role of the external observer. Still, several researchers argue that once an observer's vantage point (e.g., scope, resolution, context) is established, the terms can be made objective or measured quantitatively. In this note, we propose a framework to discuss these ideas rigorously by separating externally observable states from latent, unobservable ones. This allows us to compare and contrast existing definitions of swarms and emergence on common ground. We argue that these concepts are ultimately subjective-shaped less by the system itself than by the perception and tacit knowledge of the observer. Specifically, we suggest that a 'swarm' is not defined by its group behavior alone, but by the process generating that behavior. Our broader goal is to support the design and deployment of robotic swarm systems, highlighting the critical distinction between multi-robot systems and true swarms.", 'abstract_zh': 'Emergence和群集广泛讨论但缺乏正式定义的共识：外部观测视角下探讨群集和涌现的概念框架', 'title_zh': '基于观察者依赖的方法划分机器人 swarm 中的涌现现象'}
{'arxiv_id': 'arXiv:2507.07299', 'title': 'LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation', 'authors': 'Sonia Raychaudhuri, Enrico Cancelli, Tommaso Campari, Lamberto Ballan, Manolis Savva, Angel X. Chang', 'link': 'https://arxiv.org/abs/2507.07299', 'abstract': "Recent progress in large vision-language models has driven improvements in language-based semantic navigation, where an embodied agent must reach a target object described in natural language. Despite these advances, we still lack a clear, language-focused benchmark for testing how well such agents ground the words in their instructions. We address this gap with LangNav, an open-set dataset specifically created to test an agent's ability to locate objects described at different levels of detail, from broad category names to fine attributes and object-object relations. Every description in LangNav was manually checked, yielding a lower error rate than existing lifelong- and semantic-navigation datasets. On top of LangNav we build LangNavBench, a benchmark that measures how well current semantic-navigation methods understand and act on these descriptions while moving toward their targets. LangNavBench allows us to systematically compare models on their handling of attributes, spatial and relational cues, and category hierarchies, offering the first thorough, language-centric evaluation of embodied navigation systems. We also present Multi-Layered Feature Map (MLFM), a method that builds a queryable multi-layered semantic map, particularly effective when dealing with small objects or instructions involving spatial relations. MLFM outperforms state-of-the-art mapping-based navigation baselines on the LangNav dataset.", 'abstract_zh': 'Recent进展在大规模多模态模型方面推动了基于语言的语义导航的进步，其中实体代理必须根据自然语言描述到达目标物体。尽管取得了这些进展，我们仍缺乏一个清晰的语言导向基准来测试这些代理如何理解指令中的词语。我们通过建立LangNav，一个开放集数据集来填补这一空白，该数据集专门用于测试代理识别不同详细程度描述对象的能力，从广泛的类别名称到细微的属性和物体间关系。LangNav 中的每个描述都经过人工检查，导致错误率低于现有的终身语义导航数据集。在LangNav基础上，我们构建了LangNavBench，该基准用于衡量当前语义导航方法在向目标移动过程中理解并执行这些描述的效果。LangNavBench 允许我们系统地比较模型在处理属性、空间和关系线索以及类别层次结构方面的能力，提供第一个全面的语言导向评估方法体系。我们还介绍了多层特征图（MLFM）方法，这是一种构建可查询多层语义图的方法，特别适用于处理小型物体或涉及空间关系的指令。MLFM 在LangNav数据集上的表现优于最先进的基于映射的导航基准。', 'title_zh': 'LangNavBench: 语义导航中的自然语言理解评估'}
{'arxiv_id': 'arXiv:2507.07225', 'title': '3D Steering and Localization in Pipes and Burrows using an Externally Steered Soft Growing Robot', 'authors': 'Yimeng Qin, Jared Grinberg, William Heap, Allison M. Okamura', 'link': 'https://arxiv.org/abs/2507.07225', 'abstract': 'Navigation and inspection in confined environments, such as tunnels and pipes, pose significant challenges for existing robots due to limitations in maneuverability and adaptability to varying geometries. Vine robots, which are soft growing continuum robots that extend their length through soft material eversion at their tip, offer unique advantages due to their ability to navigate tight spaces, adapt to complex paths, and minimize friction. However, existing vine robot designs struggle with navigation in manmade and natural passageways, with branches and sharp 3D turns. In this letter, we introduce a steerable vine robot specifically designed for pipe and burrow environments. The robot features a simple tubular body and an external tip mount that steers the vine robot in three degrees of freedom by changing the growth direction and, when necessary, bracing against the wall of the pipe or burrow. Our external tip steering approach enables: (1) active branch selection in 3D space with a maximum steerable angle of 51.7°, (2) navigation of pipe networks with radii as small as 2.5 cm, (3) a compliant tip enabling navigation of sharp turns, and (4) real-time 3D localization in GPS-denied environments using tip-mounted sensors and continuum body odometry. We describe the forward kinematics, characterize steerability, and demonstrate the system in a 3D pipe system as well as a natural animal burrow.', 'abstract_zh': '受限空间（如隧道和管道）中的导航与检测对现有机器人构成了显著挑战，因为这些机器人在机动性和适应不同几何形状方面存在局限。藤蔓机器人作为一种柔性的连续机器人，通过其顶端的软材料反转延长其长度，由于其能够在狭窄空间中导航、适应复杂路径并减小摩擦的独特能力，提供了独特优势。然而，现有的藤蔓机器人设计在人造和自然通道中应对枝桠和锐利的三维转弯存在困难。本文介绍了一种专门设计用于管道和洞穴环境的可转向藤蔓机器人。该机器人具有简单的圆管状身体和外部顶端安装器，通过改变生长方向及其必要时顶住管道或洞穴的墙壁，在三个自由度上转向藤蔓机器人。（1）外部顶端转向方法可在三维空间中实现最大转向角为51.7°的主动分支选择，（2）能够在最小直径为2.5厘米的管道网络中导航，（3）具有柔性的顶端，可在陡峭转弯中导航，以及（4）在没有GPS信号的环境中使用顶端安装的传感器和连续体身体里程计实现实时三维定位。我们描述了前向运动学、表征了转向性能，并在三维管道系统和自然动物洞穴中展示了该系统。', 'title_zh': '使用外部引导柔软生长机器人的管道和隧道中的三维转向与定位'}
{'arxiv_id': 'arXiv:2507.07221', 'title': 'Self-Wearing Adaptive Garments via Soft Robotic Unfurling', 'authors': 'Nam Gyun Kim, William E. Heap, Yimeng Qin, Elvy B. Yao, Jee-Hwan Ryu, Allison M. Okamura', 'link': 'https://arxiv.org/abs/2507.07221', 'abstract': 'Robotic dressing assistance has the potential to improve the quality of life for individuals with limited mobility. Existing solutions predominantly rely on rigid robotic manipulators, which have challenges in handling deformable garments and ensuring safe physical interaction with the human body. Prior robotic dressing methods require excessive operation times, complex control strategies, and constrained user postures, limiting their practicality and adaptability. This paper proposes a novel soft robotic dressing system, the Self-Wearing Adaptive Garment (SWAG), which uses an unfurling and growth mechanism to facilitate autonomous dressing. Unlike traditional approaches,the SWAG conforms to the human body through an unfurling based deployment method, eliminating skin-garment friction and enabling a safer and more efficient dressing process. We present the working principles of the SWAG, introduce its design and fabrication, and demonstrate its performance in dressing assistance. The proposed system demonstrates effective garment application across various garment configurations, presenting a promising alternative to conventional robotic dressing assistance.', 'abstract_zh': '软体机器人穿衣辅助系统SWAG具备适应性自穿衣物潜在能力，提升行动受限个体的生活质量。', 'title_zh': '自穿适应服装通过软机器人展开技术'}
{'arxiv_id': 'arXiv:2507.07142', 'title': 'g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM', 'authors': 'Quanjie Qiu, MengCheng Lau', 'link': 'https://arxiv.org/abs/2507.07142', 'abstract': 'This article presents a comparative analysis of g2o and Ceres solvers in enhancing scan matching performance within the Cartographer framework. Cartographer, a widely-used library for Simultaneous Localization and Mapping (SLAM), relies on optimization algorithms to refine pose estimates and improve map accuracy. The research aims to evaluate the performance, efficiency, and accuracy of the g2o solver in comparison to the Ceres solver, which is the default in Cartographer. In our experiments comparing Ceres and g2o within Cartographer, Ceres outperformed g2o in terms of speed, convergence efficiency, and overall map clarity. Ceres required fewer iterations and less time to converge, producing more accurate and well-defined maps, especially in real-world mapping scenarios with the AgileX LIMO robot. However, g2o excelled in localized obstacle detection, highlighting its value in specific situations.', 'abstract_zh': '本文对g2o和Ceres求解器在Cartographer框架下提升扫描匹配性能进行比较分析。Cartographer是一个广泛使用的用于同时定位与建图（SLAM）的库，依赖于优化算法来细化姿态估计并提高地图的准确性。研究旨在评估g2o求解器与Ceres求解器（Cartographer的默认求解器）在性能、效率和准确性方面的差异。在我们将Ceres和g2o在Cartographer中进行比较的实验中，Ceres在速度、收敛效率和整体地图清晰度方面优于g2o。Ceres需要 fewer iterations 和更少的时间来收敛，生成更准确且定义更好的地图，尤其是在使用AgileX LIMO机器人进行实地建图时。然而，g2o在局部障碍物检测方面表现出色，突显了其在特定情况下的价值。', 'title_zh': 'g2o与Ceres：Cartographer SLAM中扫描匹配的优化比较'}
{'arxiv_id': 'arXiv:2507.07969', 'title': 'Reinforcement Learning with Action Chunking', 'authors': 'Qiyang Li, Zhiyuan Zhou, Sergey Levine', 'link': 'https://arxiv.org/abs/2507.07969', 'abstract': "We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.", 'abstract_zh': 'Q-切分：改善长期任务稀疏奖励强化学习算法的有效简单方法', 'title_zh': '强化学习中的动作分块方法'}
{'arxiv_id': 'arXiv:2507.07781', 'title': 'SURPRISE3D: A Dataset for Spatial Understanding and Reasoning in Complex 3D Scenes', 'authors': 'Jiaxin Huang, Ziwen Li, Hanlve Zhang, Runnan Chen, Xiao He, Yandong Guo, Wenping Wang, Tongliang Liu, Mingming Gong', 'link': 'https://arxiv.org/abs/2507.07781', 'abstract': 'The integration of language and 3D perception is critical for embodied AI and robotic systems to perceive, understand, and interact with the physical world. Spatial reasoning, a key capability for understanding spatial relationships between objects, remains underexplored in current 3D vision-language research. Existing datasets often mix semantic cues (e.g., object name) with spatial context, leading models to rely on superficial shortcuts rather than genuinely interpreting spatial relationships. To address this gap, we introduce S\\textsc{urprise}3D, a novel dataset designed to evaluate language-guided spatial reasoning segmentation in complex 3D scenes. S\\textsc{urprise}3D consists of more than 200k vision language pairs across 900+ detailed indoor scenes from ScanNet++ v2, including more than 2.8k unique object classes. The dataset contains 89k+ human-annotated spatial queries deliberately crafted without object name, thereby mitigating shortcut biases in spatial understanding. These queries comprehensively cover various spatial reasoning skills, such as relative position, narrative perspective, parametric perspective, and absolute distance reasoning. Initial benchmarks demonstrate significant challenges for current state-of-the-art expert 3D visual grounding methods and 3D-LLMs, underscoring the necessity of our dataset and the accompanying 3D Spatial Reasoning Segmentation (3D-SRS) benchmark suite. S\\textsc{urprise}3D and 3D-SRS aim to facilitate advancements in spatially aware AI, paving the way for effective embodied interaction and robotic planning. The code and datasets can be found in this https URL.', 'abstract_zh': '语言与三维感知的整合对于体现式AI和机器人系统感知、理解和与物理世界交互至关重要。当前三维视觉-语言研究中基于语言指导的三维场景空间推理分割评价数据集鲜有探索。现有数据集常常将语义线索（例如，物体名称）与空间上下文混合，导致模型依赖表面化捷径而非真正理解空间关系。为解决这一问题，我们引入了S\\textsc{urprise}3D，这是一个旨在评估复杂三维场景中基于语言指导的空间推理分割的新颖数据集。S\\textsc{urprise}3D 包含超过20万的视觉语言对，跨越超过900个详细室内场景（来源于ScanNet++ v2），包括超过2800个独特的物体类别。该数据集包含超过8.9万个人工标注的空间查询，这些查询刻意未包含物体名称，从而减少了空间理解中的捷径偏差。这些查询全面涵盖了各种空间推理技能，例如相对位置、叙述视角、参数视角以及绝对距离推理。初步基准测试表明，当前最先进的专家级三维视觉定位方法和三维语言-模型在S\\textsc{urprise}3D上的表现存在显著挑战，强调了我们数据集和伴随的三维空间推理分割基准套件（3D-SRS）的必要性。S\\textsc{urprise}3D 和 3D-SRS 力求推动空间感知智能的发展，铺就有效体现交互和机器人规划的道路。代码和数据集可在以下链接找到。', 'title_zh': 'SURPRISE3D: 一个用于复杂三维场景空间理解与推理的数据集'}
{'arxiv_id': 'arXiv:2507.07560', 'title': 'Conjugated Capabilities: Interrelations of Elementary Human Capabilities and Their Implication on Human-Machine Task Allocation and Capability Testing Procedures', 'authors': 'Nils Mandischer, Larissa Füller, Torsten Alles, Frank Flemisch, Lars Mikelsons', 'link': 'https://arxiv.org/abs/2507.07560', 'abstract': "Human and automation capabilities are the foundation of every human-autonomy interaction and interaction pattern. Therefore, machines need to understand the capacity and performance of human doing, and adapt their own behavior, accordingly. In this work, we address the concept of conjugated capabilities, i.e. capabilities that are dependent or interrelated and between which effort can be distributed. These may be used to overcome human limitations, by shifting effort from a deficient to a conjugated capability with performative resources. For example: A limited arm's reach may be compensated by tilting the torso forward. We analyze the interrelation between elementary capabilities within the IMBA standard to uncover potential conjugation, and show evidence in data of post-rehabilitation patients. From the conjugated capabilities, within the example application of stationary manufacturing, we create a network of interrelations. With this graph, a manifold of potential uses is enabled. We showcase the graph's usage in optimizing IMBA test design to accelerate data recordings, and discuss implications of conjugated capabilities on task allocation between the human and an autonomy.", 'abstract_zh': '人类与自动化能力是每种人机自主交互及其模式的基础。因此，机器需要理解人类能力及其性能，并根据需要调整自己的行为。在本项工作中，我们探讨了共轭能力的概念，即相互依赖或相关的能力，以及在这些能力之间重新分配努力的可能性。这些能力可以用来克服人类的局限性，通过将努力从一个有缺陷的能力转移到具有表现力资源的共轭能力。例如：有限的臂长可以通过前倾躯干来弥补。我们分析了IMBA标准中基本能力之间的相互关系，以揭示潜在的共轭关系，并在康复后患者的数据中提供证据。从共轭能力出发，在静止制造的应用示例中，我们创建了一个相互关系网络。借助此图，我们能够启用多种潜在用途。我们展示了该图在优化IMBA测试设计以加速数据记录中的应用，并讨论了共轭能力对人类与自主系统之间任务分配的影响。', 'title_zh': '共轭能力： elemental人类能力的相互关系及其对人类-机器任务分配和能力测试程序的影响'}
{'arxiv_id': 'arXiv:2507.07550', 'title': 'Pluri-perspectivism in Human-robot Co-creativity with Older Adults', 'authors': 'Marianne Bossema, Rob Saunders, Aske Plaat, Somaya Ben Allouch', 'link': 'https://arxiv.org/abs/2507.07550', 'abstract': 'This position paper explores pluriperspectivism as a core element of human creative experience and its relevance to humanrobot cocreativity We propose a layered fivedimensional model to guide the design of cocreative behaviors and the analysis of interaction dynamics This model is based on literature and results from an interview study we conducted with 10 visual artists and 8 arts educators examining how pluriperspectivism supports creative practice The findings of this study provide insight in how robots could enhance human creativity through adaptive contextsensitive behavior demonstrating the potential of pluriperspectivism This paper outlines future directions for integrating pluriperspectivism with visionlanguage models VLMs to support context sensitivity in cocreative robots', 'abstract_zh': '这篇立场论文探讨了多元透视主义作为人类创造性体验核心要素的地位及其与人机协同创造的相关性。我们提出了一种分层五维模型，以指导协同创造行为的设计以及交互动力学的分析。该模型基于文献和我们对10名视觉艺术家和8名艺术教育者的访谈研究结果，探讨了多元透视主义如何支持创造性实践。本研究的发现提供了关于机器人如何通过适应性上下文敏感行为增强人类创造力的见解，并展示了多元透视主义的潜力。本文概述了将多元透视主义与视觉语言模型VLM结合以支持协同创造机器人上下文敏感性的未来方向。', 'title_zh': '人类与机器人共同创意中的多元主义视角与老年人合作'}
{'arxiv_id': 'arXiv:2507.07302', 'title': 'Application of LLMs to Multi-Robot Path Planning and Task Allocation', 'authors': 'Ashish Kumar', 'link': 'https://arxiv.org/abs/2507.07302', 'abstract': 'Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.', 'abstract_zh': '高效的探索是深度强化学习中一个已知的问题，而在多智能体强化学习中由于此类算法固有的复杂性，这一问题更为突出。本工作探讨了使用大型语言模型作为专家规划者进行多智能体基于规划任务的高效探索的方法。', 'title_zh': 'LLM在多机器人路径规划与任务分配中的应用'}
{'arxiv_id': 'arXiv:2507.07153', 'title': 'Aerial Maritime Vessel Detection and Identification', 'authors': 'Antonella Barisic Kulas, Frano Petric, Stjepan Bogdan', 'link': 'https://arxiv.org/abs/2507.07153', 'abstract': 'Autonomous maritime surveillance and target vessel identification in environments where Global Navigation Satellite Systems (GNSS) are not available is critical for a number of applications such as search and rescue and threat detection. When the target vessel is only described by visual cues and its last known position is not available, unmanned aerial vehicles (UAVs) must rely solely on on-board vision to scan a large search area under strict computational constraints. To address this challenge, we leverage the YOLOv8 object detection model to detect all vessels in the field of view. We then apply feature matching and hue histogram distance analysis to determine whether any detected vessel corresponds to the target. When found, we localize the target using simple geometric principles. We demonstrate the proposed method in real-world experiments during the MBZIRC2023 competition, integrated into a fully autonomous system with GNSS-denied navigation. We also evaluate the impact of perspective on detection accuracy and localization precision and compare it with the oracle approach.', 'abstract_zh': '在全球导航卫星系统不可用的环境下实现自主 maritime 监视和目标船只识别对于搜索救援和威胁检测等应用至关重要。当目标船只仅通过视觉特征描述且其最后已知位置不可用时，无人驾驶航空车辆（UAV）必须在严格的计算约束下依赖机载视觉扫描大面积搜索区域。为应对这一挑战，我们利用YOLOv8目标检测模型检测视野内的所有船只。然后，我们应用特征匹配和色调直方图距离分析来确定是否有任何检测到的船只对应于目标。一旦发现目标，我们使用简单的几何原理进行定位。我们在2023年 MBZIRC 竞赛的真实世界实验中演示了所提出的方法，并将其集成到具有全球导航卫星系统受限导航的完全自主系统中。我们还评估了视角对检测准确性和定位精度的影响，并将其与基准方法进行了比较。', 'title_zh': '空中海上舰船检测与识别'}
{'arxiv_id': 'arXiv:2507.07007', 'title': 'Robust signal decompositions on the circle', 'authors': 'Aral Kose, Daniel Liberzon', 'link': 'https://arxiv.org/abs/2507.07007', 'abstract': 'We consider the problem of decomposing a piecewise constant function on the circle into a sum of indicator functions of closed circular disks in the plane, whose number and location are not a priori known. This represents a situation where an agent moving on the circle is able to sense its proximity to some landmarks, and the goal is to estimate the number of these landmarks and their possible locations -- which can in turn enable control tasks such as motion planning and obstacle avoidance. Moreover, the exact values of the function at its discontinuities (which correspond to disk boundaries for the individual indicator functions) are not assumed to be known to the agent. We introduce suitable notions of robustness and degrees of freedom to single out those decompositions that are more desirable, or more likely, given this non-precise data collected by the agent. We provide a characterization of robust decompositions and give a procedure for generating all such decompositions. When the given function admits a robust decomposition, we compute the number of possible robust decompositions and derive bounds for the number of decompositions maximizing the degrees of freedom.', 'abstract_zh': '我们考虑将圆上的阶梯函数分解为平面中闭圆盘指示函数之和的问题，其中这些圆盘的数量和位置事先未知。这代表了代理沿圆移动时能够感知其与某些地标接近的情况，目标是估计这些地标数量及其可能位置，这反过来可以实现诸如运动规划和障碍物回避等控制任务。此外，阶梯函数在不连续点的确切值（对应于个别指示函数的圆盘边界）假定未知。我们引入了适当的鲁棒性概念和自由度，以突出那些在获得代理收集的不精确数据情况下更优或更可能的分解。我们给出了鲁棒分解的特征描述，并提供了一种生成所有此类分解的方法。当给定的函数存在鲁棒分解时，我们计算可能的鲁棒分解的数量，并推导出最大化自由度的分解的数量下界。', 'title_zh': '圆周上的鲁棒信号分解'}
