{'arxiv_id': 'arXiv:2502.14864', 'title': 'Benchmarking Multimodal RAG through a Chart-based Document Question-Answering Generation Framework', 'authors': 'Yuming Yang, Jiang Zhong, Li Jin, Jingwang Huang, Jingpeng Gao, Qing Liu, Yang Bai, Jingyuan Zhang, Rui Jiang, Kaiwen Wei', 'link': 'https://arxiv.org/abs/2502.14864', 'abstract': 'Multimodal Retrieval-Augmented Generation (MRAG) enhances reasoning capabilities by integrating external knowledge. However, existing benchmarks primarily focus on simple image-text interactions, overlooking complex visual formats like charts that are prevalent in real-world applications. In this work, we introduce a novel task, Chart-based MRAG, to address this limitation. To semi-automatically generate high-quality evaluation samples, we propose CHARt-based document question-answering GEneration (CHARGE), a framework that produces evaluation data through structured keypoint extraction, crossmodal verification, and keypoint-based generation. By combining CHARGE with expert validation, we construct Chart-MRAG Bench, a comprehensive benchmark for chart-based MRAG evaluation, featuring 4,738 question-answering pairs across 8 domains from real-world documents. Our evaluation reveals three critical limitations in current approaches: (1) unified multimodal embedding retrieval methods struggles in chart-based scenarios, (2) even with ground-truth retrieval, state-of-the-art MLLMs achieve only 58.19% Correctness and 73.87% Coverage scores, and (3) MLLMs demonstrate consistent text-over-visual modality bias during Chart-based MRAG reasoning. The CHARGE and Chart-MRAG Bench are released at this https URL.', 'abstract_zh': '基于图表的多模态检索增强生成（Chart-based MRAG）通过整合外部知识增强了推理能力。然而，现有的基准测试主要集中在简单的图像-文本交互上，忽视了在真实世界应用中常见的如图表等复杂视觉格式。在本文中，我们引入了一个新的任务——基于图表的多模态检索增强生成（Chart-based MRAG），以解决这一局限性。为了半自动地生成高质量的评估样本，我们提出了一种基于图表的数据关键点提取、跨模态验证和关键点生成的框架（CHARGE），并结合专家验证构建了涵盖8个领域的4,738个问答对的基于图表的MRAG基准测试集（Chart-MRAG Bench）。我们的评估揭示了当前方法的三个关键局限性：（1）统一的多模态嵌入检索方法在基于图表的场景中表现不佳，（2）即使使用 ground-truth 检索，最先进的 MLLM 也只有 58.19% 的正确率和 73.87% 的覆盖率，（3）MLLM 在基于图表的 MRAG 推理中表现出一致的文本优先于视觉模态的偏见。CHARGE 和 Chart-MRAG Bench 已在此链接发布：https://xxxxxx。', 'title_zh': '基于图表驱动的文档问答生成框架下多模态RAG基准测试'}
{'arxiv_id': 'arXiv:2502.14815', 'title': 'Optimizing Model Selection for Compound AI Systems', 'authors': 'Lingjiao Chen, Jared Quincy Davis, Boris Hanin, Peter Bailis, Matei Zaharia, James Zou, Ion Stoica', 'link': 'https://arxiv.org/abs/2502.14815', 'abstract': 'Compound AI systems that combine multiple LLM calls, such as self-refine and multi-agent-debate, achieve strong performance on many AI tasks. We address a core question in optimizing compound systems: for each LLM call or module in the system, how should one decide which LLM to use? We show that these LLM choices have a large effect on quality, but the search space is exponential. We propose LLMSelector, an efficient framework for model selection in compound systems, which leverages two key empirical insights: (i) end-to-end performance is often monotonic in how well each module performs, with all other modules held fixed, and (ii) per-module performance can be estimated accurately by an LLM. Building upon these insights, LLMSelector iteratively selects one module and allocates to it the model with the highest module-wise performance, as estimated by an LLM, until no further gain is possible. LLMSelector is applicable to any compound system with a bounded number of modules, and its number of API calls scales linearly with the number of modules, achieving high-quality model allocation both empirically and theoretically. Experiments with popular compound systems such as multi-agent debate and self-refine using LLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector confers 5%-70% accuracy gains compared to using the same LLM for all modules.', 'abstract_zh': '结合多个LLM调用的复合AI系统，如自我 refinement 和多智能体辩论，在许多AI任务上表现出色。我们解决了一个核心问题：在系统中的每个LLM调用或模块中，应该如何决定使用哪个LLM？我们展示出这些LLM选择对质量有重大影响，但搜索空间是指数级的。我们提出LLMSelector，这是一种在复合系统中进行模型选择的高效框架，该框架利用了两个关键的实证洞见：(i) 在其他模块固定的情况下，端到端性能通常随着每个模块性能的提高而单调增加；(ii) 每个模块的性能可以通过LLM准确估计。基于这些洞见，LLMSelector 逐步选择一个模块，并分配给它由LLM估计性能最高的模型，直到无法进一步提高为止。LLMSelector适用于具有有限模块数量的任何复合系统，其API调用次数随模块数量线性变化，从实证和理论角度来看，都能实现高质量模型分配。使用GPT-4o、Claude 3.5 Sonnet 和 Gemini 1.5等LLM的多智能体辩论和自我 refinement 等 popular 复合系统实验表明，与为所有模块使用同一LLM相比，LLMSelector 可提高5%-70%的准确性。', 'title_zh': '优化复合人工智能系统中的模型选择'}
{'arxiv_id': 'arXiv:2502.14777', 'title': 'Making Universal Policies Universal', 'authors': 'Niklas Höpner, David Kuric, Herke van Hoof', 'link': 'https://arxiv.org/abs/2502.14777', 'abstract': "The development of a generalist agent capable of solving a wide range of sequential decision-making tasks remains a significant challenge. We address this problem in a cross-agent setup where agents share the same observation space but differ in their action spaces. Our approach builds on the universal policy framework, which decouples policy learning into two stages: a diffusion-based planner that generates observation sequences and an inverse dynamics model that assigns actions to these plans. We propose a method for training the planner on a joint dataset composed of trajectories from all agents. This method offers the benefit of positive transfer by pooling data from different agents, while the primary challenge lies in adapting shared plans to each agent's unique constraints. We evaluate our approach on the BabyAI environment, covering tasks of varying complexity, and demonstrate positive transfer across agents. Additionally, we examine the planner's generalisation ability to unseen agents and compare our method to traditional imitation learning approaches. By training on a pooled dataset from multiple agents, our universal policy achieves an improvement of up to $42.20\\%$ in task completion accuracy compared to a policy trained on a dataset from a single agent.", 'abstract_zh': '一种通用代理的发展，能够在广泛范围内的序列决策任务上求解仍然是一个重大挑战。我们通过跨代理设置解决这一问题，在该设置中，代理共享相同的状态观察空间，但其行动空间不同。我们的方法基于通用策略框架，将策略学习分为两个阶段：一种基于扩散的规划器生成状态观察序列，以及逆动力学模型将行动分配给这些计划。我们提出了一种方法，在一个由所有代理轨迹组成的联合数据集上训练规划器。该方法通过从不同代理中汇集数据，提供了积极迁移的优势，但主要挑战在于适应每个代理的独特约束。我们在BabyAI环境中评估了我们的方法，该环境涵盖了不同复杂度的任务，并展示了代理间的积极迁移。此外，我们还考察了规划器对未见代理的泛化能力，并将我们的方法与传统的模仿学习方法进行了比较。通过在多代理联合数据集上训练，我们的通用策略在任务完成准确性上相对于单一代理数据集训练的策略实现了最高42.20%的改进。', 'title_zh': '制作普适性政策以求普适性'}
{'arxiv_id': 'arXiv:2502.14760', 'title': 'EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations', 'authors': 'Haotian Zhai, Connor Lawless, Ellen Vitercik, Liu Leqi', 'link': 'https://arxiv.org/abs/2502.14760', 'abstract': "A fundamental problem in combinatorial optimization is identifying equivalent formulations, which can lead to more efficient solution strategies and deeper insights into a problem's computational complexity. The need to automatically identify equivalence between problem formulations has grown as optimization copilots--systems that generate problem formulations from natural language descriptions--have proliferated. However, existing approaches to checking formulation equivalence lack grounding, relying on simple heuristics which are insufficient for rigorous validation. Inspired by Karp reductions, in this work we introduce quasi-Karp equivalence, a formal criterion for determining when two optimization formulations are equivalent based on the existence of a mapping between their decision variables. We propose EquivaMap, a framework that leverages large language models to automatically discover such mappings, enabling scalable and reliable equivalence verification. To evaluate our approach, we construct the first open-source dataset of equivalent optimization formulations, generated by applying transformations such as adding slack variables or valid inequalities to existing formulations. Empirically, EquivaMap significantly outperforms existing methods, achieving substantial improvements in correctly identifying formulation equivalence.", 'abstract_zh': '组合优化中的一个基本问题是识别等价形式，这可以导致更高效的求解策略，并深入理解问题的计算复杂性。随着优化合作者系统的 proliferate——这些系统能够从自然语言描述中生成问题形式——自动识别问题形式之间的等价性需求日益增长。然而，现有的形式等价性验证方法缺乏坚实的依据，依赖于简单的启发式方法，这些方法不足以进行严格的验证。受 Karp 减少的启发，在这项工作中我们引入了一种准 Karp 等价性形式标准，该标准基于决策变量之间的映射来确定两个优化形式是否等价。我们提出了一种名为 EquivaMap 的框架，利用大型语言模型自动发现这样的映射，从而实现可扩展和可靠的等价性验证。为了评估我们的方法，我们构建了首个开源的等价优化形式数据集，通过应用如添加松弛变量或有效不等式的变换来生成现有的形式。实验结果显示，EquivaMap 显著优于现有方法，在正确识别形式等价性方面取得了显著的性能改进。', 'title_zh': 'EquivaMap: 利用大规模语言模型进行优化公式等价性自动检查'}
{'arxiv_id': 'arXiv:2502.14714', 'title': 'From Knowledge Generation to Knowledge Verification: Examining the BioMedical Generative Capabilities of ChatGPT', 'authors': 'Ahmed Abdeen Hamed, Byung Suk Lee', 'link': 'https://arxiv.org/abs/2502.14714', 'abstract': 'The generative capabilities of LLM models present opportunities in accelerating tasks and concerns with the authenticity of the knowledge it produces. To address the concerns, we present a computational approach that systematically evaluates the factual accuracy of biomedical knowledge that an LLM model has been prompted to generate. Our approach encompasses two processes: the generation of disease-centric associations and the verification of them using the semantic knowledge of the biomedical ontologies. Using ChatGPT as the select LLM model, we designed a set of prompt-engineering processes to generate linkages between diseases, drugs, symptoms, and genes to establish grounds for assessments. Experimental results demonstrate high accuracy in identifying disease terms (88%-97%), drug names (90%-91%), and genetic information (88%-98%). The symptom term identification accuracy was notably lower (49%-61%), as verified against the DOID, ChEBI, SYMPTOM, and GO ontologies accordingly. The verification of associations reveals literature coverage rates of (89%-91%) among disease-drug and disease-gene associations. The low identification accuracy for symptom terms also contributed to the verification of symptom-related associations (49%-62%).', 'abstract_zh': 'LLM模型在加速任务中的生成能力及其生物医学知识真实性评估的系统性方法', 'title_zh': '从知识生成到知识验证：考察ChatGPT的生物医药生成能力'}
{'arxiv_id': 'arXiv:2502.14706', 'title': 'Building reliable sim driving agents by scaling self-play', 'authors': 'Daphne Cornelisse, Aarav Pandya, Kevin Joseph, Joseph Suárez, Eugene Vinitsky', 'link': 'https://arxiv.org/abs/2502.14706', 'abstract': "Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing the system's limits, but all use cases share a key requirement: reliability. A simulation agent should behave as intended by the designer, minimizing unintended actions like collisions that can compromise the signal-to-noise ratio of analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents nearly solve the full training set within a day. They generalize effectively to unseen test scenes, achieving a 99.8% goal completion rate with less than 0.8% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in those cases. Demonstrations of agent behaviors can be found at this link. We open-source both the pre-trained agents and the complete code base. Demonstrations of agent behaviors can be found at \\url{this https URL}.", 'abstract_zh': '仿真代理对于设计和测试与人类互动的系统（如自动驾驶车辆）至关重要。这些代理具有多种用途，从评估自动驾驶车辆性能到测试系统的极限，但所有应用场景都共享一个关键要求：可靠性。为了构建可靠的仿真代理，我们建议在Waymo开放运动数据集中，于半现实的人类感知和控制限制条件下，将自我对弈扩展到数千种场景。我们从单个GPU开始训练，代理几乎在一天内解决了整个训练集。它们有效泛化到未见过的测试场景，在10,000个保留场景中，目标完成率为99.8%，且碰撞和离路事件的总发生率不到0.8%。除了分布内泛化，我们的代理部分抵抗分布外场景，并可在几分钟内微调至这些情况下近乎完美表现。代理行为演示可在此链接中找到：\\url{this https URL}。我们开源了预训练代理和完整的代码库。代理行为演示可在此链接中找到：\\url{this https URL}。', 'title_zh': '通过扩展自我对弈构建可靠的模拟驾驶代理'}
{'arxiv_id': 'arXiv:2502.14581', 'title': 'A Statistical Case Against Empirical Human-AI Alignment', 'authors': 'Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin', 'link': 'https://arxiv.org/abs/2502.14581', 'abstract': 'Empirical human-AI alignment aims to make AI systems act in line with observed human behavior. While noble in its goals, we argue that empirical alignment can inadvertently introduce statistical biases that warrant caution. This position paper thus advocates against naive empirical alignment, offering prescriptive alignment and a posteriori empirical alignment as alternatives. We substantiate our principled argument by tangible examples like human-centric decoding of language models.', 'abstract_zh': '经验性人机对齐旨在使AI系统的行为与观察到的人类行为一致。虽然其目标高尚，但我们认为经验性对齐可能会无意中引入统计偏差，值得谨慎对待。因此，本文立场主张反对简单的经验性对齐，提出规范性对齐和事后经验性对齐作为替代方案。我们通过以人类为中心的语言模型解码等具体例子来支撑我们的原则性论点。', 'title_zh': '统计学上对经验性人类-人工智能对齐的反驳'}
{'arxiv_id': 'arXiv:2502.14563', 'title': 'Plan-over-Graph: Towards Parallelable LLM Agent Schedule', 'authors': 'Shiqi Zhang, Xinbei Ma, Zouying Cao, Zhuosheng Zhang, Hai Zhao', 'link': 'https://arxiv.org/abs/2502.14563', 'abstract': 'Large Language Models (LLMs) have demonstrated exceptional abilities in reasoning for task planning. However, challenges remain under-explored for parallel schedules. This paper introduces a novel paradigm, plan-over-graph, in which the model first decomposes a real-life textual task into executable subtasks and constructs an abstract task graph. The model then understands this task graph as input and generates a plan for parallel execution. To enhance the planning capability of complex, scalable graphs, we design an automated and controllable pipeline to generate synthetic graphs and propose a two-stage training scheme. Experimental results show that our plan-over-graph method significantly improves task performance on both API-based LLMs and trainable open-sourced LLMs. By normalizing complex tasks as graphs, our method naturally supports parallel execution, demonstrating global efficiency. The code and data are available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在任务规划推理方面展现了出色的能力，但在并行调度方面仍存在未探索的挑战。本文提出了一种新的范式——plan-over-graph，其中模型首先将实际文本任务分解为可执行的子任务并构建抽象的任务图，然后将该任务图作为输入生成并行执行的计划。为了增强对复杂、可扩展图的规划能力，我们设计了一个自动且可控的管道生成合成图，并提出了一种两阶段训练方案。实验结果表明，我们的plan-over-graph方法显著提高了基于API的LLMs和可训练的开源LLMs的任务性能。通过将复杂任务规范为图，该方法自然支持并行执行，展现了全局效率。代码和数据可访问此处：this https URL。', 'title_zh': '图上计划：走向可并行的LLM代理调度'}
{'arxiv_id': 'arXiv:2502.14491', 'title': 'Statistical Scenario Modelling and Lookalike Distributions for Multi-Variate AI Risk', 'authors': 'Elija Perrier', 'link': 'https://arxiv.org/abs/2502.14491', 'abstract': 'Evaluating AI safety requires statistically rigorous methods and risk metrics for understanding how the use of AI affects aggregated risk. However, much AI safety literature focuses upon risks arising from AI models in isolation, lacking consideration of how modular use of AI affects risk distribution of workflow components or overall risk metrics. There is also a lack of statistical grounding enabling sensitisation of risk models in the presence of absence of AI to estimate causal contributions of AI. This is in part due to the dearth of AI impact data upon which to fit distributions. In this work, we address these gaps in two ways. First, we demonstrate how scenario modelling (grounded in established statistical techniques such as Markov chains, copulas and Monte Carlo simulation) can be used to model AI risk holistically. Second, we show how lookalike distributions from phenomena analogous to AI can be used to estimate AI impacts in the absence of directly observable data. We demonstrate the utility of our methods for benchmarking cumulative AI risk via risk analysis of a logistic scenario simulations.', 'abstract_zh': '评估AI安全需要统计严谨的方法和风险管理指标，以理解AI的使用如何影响综合风险。然而，大部分AI安全文献主要关注AI模型本身带来的风险，忽视了模块化使用AI如何影响工作流组件的风险分布或整体风险指标。此外，缺乏统计基础使得在有无AI的情况下敏感化风险模型以估计AI的因果贡献也面临挑战。这主要是由于缺乏合适的AI影响数据来拟合分布。在本工作中，我们从两个方面来填补这些空白。首先，我们展示了如何通过基于已确立的统计技术（如马尔可夫链、合成变量和蒙特卡洛模拟）的场景建模来全面建模AI风险。其次，我们展示了如何利用类似AI现象的模拟分布来估计在缺乏直接可观测数据时的AI影响。我们通过逻辑情景模拟的风险分析来验证我们方法在基准累计AI风险方面的适用性。', 'title_zh': '统计情景建模和多变量AI风险的类似分布方法'}
{'arxiv_id': 'arXiv:2502.14456', 'title': 'Narrative-Driven Travel Planning: Geoculturally-Grounded Script Generation with Evolutionary Itinerary Optimization', 'authors': 'Ran Ding, Ziyu Zhang, Ying Zhu, Ziqian Kong, Peilan Xu', 'link': 'https://arxiv.org/abs/2502.14456', 'abstract': "To enhance tourists' experiences and immersion, this paper proposes a narrative-driven travel planning framework called NarrativeGuide, which generates a geoculturally-grounded narrative script for travelers, offering a novel, role-playing experience for their journey. In the initial stage, NarrativeGuide constructs a knowledge graph for attractions within a city, then configures the worldview, character setting, and exposition based on the knowledge graph. Using this foundation, the knowledge graph is combined to generate an independent scene unit for each attraction. During the itinerary planning stage, NarrativeGuide models narrative-driven travel planning as an optimization problem, utilizing a genetic algorithm (GA) to refine the itinerary. Before evaluating the candidate itinerary, transition scripts are generated for each pair of adjacent attractions, which, along with the scene units, form a complete script. The weighted sum of script coherence, travel time, and attraction scores is then used as the fitness value to update the candidate solution set. Experimental results across four cities, i.e., Nanjing and Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate significant improvements in narrative coherence and cultural fit, alongside a notable reduction in travel time and an increase in the quality of visited attractions. Our study highlights that incorporating external evolutionary optimization effectively addresses the limitations of large language models in travel this http URL codes are available at this https URL.", 'abstract_zh': '基于叙事的旅行规划框架NarrativeGuide：增强游客体验与沉浸感的新颖方法', 'title_zh': '叙事驱动的旅游规划：基于地理文化的脚本生成与进化行程优化'}
{'arxiv_id': 'arXiv:2502.14400', 'title': 'HPS: Hard Preference Sampling for Human Preference Alignment', 'authors': 'Xiandong Zou, Wanyu Lin, Yuchen Li, Pan Zhou', 'link': 'https://arxiv.org/abs/2502.14400', 'abstract': 'Aligning Large Language Model (LLM) responses with human preferences is vital for building safe and controllable AI systems. While preference optimization methods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown promise, they face challenges such as poor handling of harmful content, inefficient use of dispreferred responses, and, specifically for PL, high computational costs. To address these issues, we propose Hard Preference Sampling (HPS), a novel framework for robust and efficient human preference alignment. HPS introduces a training loss that prioritizes the most preferred response while rejecting all dispreferred and harmful ones. It emphasizes "hard" dispreferred responses--those closely resembling preferred ones--to enhance the model\'s rejection capabilities. By leveraging a single-sample Monte Carlo sampling strategy, HPS reduces computational overhead while maintaining alignment quality. Theoretically, HPS improves sample efficiency over existing PL methods and maximizes the reward margin between preferred and dispreferred responses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety datasets validate HPS\'s effectiveness, achieving comparable BLEU and reward scores while greatly improving reward margins and thus reducing harmful content generation.', 'abstract_zh': '大型语言模型（LLM）响应与人类偏好对齐对于构建安全可控的AI系统至关重要。尽管基于Plackett-Luce（PL）和Bradley-Terry（BT）模型的偏好优化方法显示出前景，但它们面临着有害内容处理不佳、不偏好响应利用效率低等问题，尤其是对于PL模型，计算成本较高。为解决这些问题，我们提出了一种名为Hard Preference Sampling（HPS）的新颖框架，以实现稳健高效的人类偏好对齐。HPS引入了一种训练损失，优先选择最偏好响应并拒绝所有不偏好和有害响应。它强调“硬”不偏好响应——那些与偏好响应高度相似的——以增强模型的拒绝能力。通过利用单样本蒙特卡洛采样策略，HPS降低了计算开销同时保持对齐质量。理论上，HPS在样本效率上优于现有PL方法，并最大化了偏好和不偏好响应之间的奖励差距，确保了更清晰的区分。对HH-RLHF和PKU-Safety数据集的实验验证了HPS的有效性，在实现类似BLEU和奖励分数的同时，大幅提高了奖励差距，从而减少了有害内容的生成。', 'title_zh': 'HPS: Hard Preference Sampling for Human Preference Alignment'}
{'arxiv_id': 'arXiv:2502.14361', 'title': 'Retrieval-Augmented Process Reward Model for Generalizable Mathematical Reasoning', 'authors': 'Jiachen Zhu, Congmin Zheng, Jianghao Lin, Kounianhua Du, Ying Wen, Yong Yu, Jun Wang, Weinan Zhang', 'link': 'https://arxiv.org/abs/2502.14361', 'abstract': "While large language models (LLMs) have significantly advanced mathematical reasoning, Process Reward Models (PRMs) have been developed to evaluate the logical validity of reasoning steps. However, PRMs still struggle with out-of-distribution (OOD) challenges. This paper identifies key OOD issues, including step OOD, caused by differences in reasoning patterns across model types and sizes, and question OOD, which arises from dataset shifts between training data and real-world problems. To address these issues, we introduce Retrieval-Augmented Process Reward Model (RetrievalPRM), a novel framework designed to tackle these OOD issues. By utilizing a two-stage retrieval-enhanced mechanism, RetrievalPRM retrieves semantically similar questions and steps as a warmup, enhancing PRM's ability to evaluate target steps and improving generalization and reasoning consistency across different models and problem types. Our extensive experiments demonstrate that RetrievalPRM outperforms existing baselines across multiple real-world datasets. Our open-source contributions include a retrieval-enhanced dataset, a tuning framework for PRM training, and the RetrievalPRM model, establishing a new standard for PRM performance.", 'abstract_zh': '尽管大规模语言模型（LLMs）在数学推理方面取得了显著进步，过程奖励模型（PRMs）已被开发出来评估推理步骤的逻辑有效性。然而，PRMs仍然难以应对离群分布（OOD）挑战。本文识别了关键的OOD问题，包括由于不同模型类型和规模的推理模式差异导致的步骤OOD问题，以及由于训练数据与真实世界问题之间的数据集转移导致的问题OOD问题。为了应对这些问题，我们提出了检索增强过程奖励模型（RetrievalPRM）这一新颖框架。通过利用两阶段的检索增强机制，RetrievalPRM 在预热阶段检索语义上相似的问题和步骤，从而增强PRM评估目标步骤的能力，并提高不同模型和问题类型下的泛化能力和推理一致性。我们的广泛实验表明，RetrievalPRM 在多个真实世界数据集上优于现有基线。我们的开源贡献包括检索增强数据集、PRM 训练的调整框架以及 RetrievalPRM 模型，确立了PRM性能的新标准。', 'title_zh': '检索增强过程奖励模型的通用数学推理'}
{'arxiv_id': 'arXiv:2502.14345', 'title': 'FlowAgent: Achieving Compliance and Flexibility for Workflow Agents', 'authors': 'Yuchen Shi, Siqi Cai, Zihan Xu, Yuei Qin, Gang Li, Hang Shao, Jiawei Chen, Deqing Yang, Ke Li, Xing Sun', 'link': 'https://arxiv.org/abs/2502.14345', 'abstract': "The integration of workflows with large language models (LLMs) enables LLM-based agents to execute predefined procedures, enhancing automation in real-world applications. Traditional rule-based methods tend to limit the inherent flexibility of LLMs, as their predefined execution paths restrict the models' action space, particularly when the unexpected, out-of-workflow (OOW) queries are encountered. Conversely, prompt-based methods allow LLMs to fully control the flow, which can lead to diminished enforcement of procedural compliance. To address these challenges, we introduce FlowAgent, a novel agent framework designed to maintain both compliance and flexibility. We propose the Procedure Description Language (PDL), which combines the adaptability of natural language with the precision of code to formulate workflows. Building on PDL, we develop a comprehensive framework that empowers LLMs to manage OOW queries effectively, while keeping the execution path under the supervision of a set of controllers. Additionally, we present a new evaluation methodology to rigorously assess an LLM agent's ability to handle OOW scenarios, going beyond routine flow compliance tested in existing benchmarks. Experiments on three datasets demonstrate that FlowAgent not only adheres to workflows but also effectively manages OOW queries, highlighting its dual strengths in compliance and flexibility. The code is available at this https URL.", 'abstract_zh': '大语言模型与工作流的集成使基于大语言模型的代理能够执行预定义的程序，从而增强实际应用中的自动化。传统的基于规则的方法往往会限制大语言模型的固有灵活性，因为它们预定义的执行路径限制了模型的行动空间，尤其是在遇到工作流外（OOW）查询时。相反，基于提示的方法可以让大语言模型全面控制流程，可能导致程序合规性限制减弱。为了解决这些挑战，我们提出了FlowAgent，这是一种新型的代理框架，旨在同时保持合规性和灵活性。我们提出了过程描述语言（PDL），它结合了自然语言的灵活性和代码的精确性来定义工作流。基于PDL，我们开发了一个全面的框架，使大语言模型能够有效管理工作流外查询，同时在一组控制器的监督下保持执行路径。此外，我们提出了一种新的评估方法，以严格评估大语言模型代理处理工作流外场景的能力，超越现有基准测试中常规流程合规性的评估。在三个数据集上的实验表明，FlowAgent不仅遵循工作流，还有效地管理了工作流外查询，突显了其在合规性和灵活性方面的双重优势。代码可在以下链接获取：this https URL。', 'title_zh': 'FlowAgent: 实现工作流代理的合规性和灵活性'}
{'arxiv_id': 'arXiv:2502.14264', 'title': 'SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game Dynamics', 'authors': 'Fernando Martinez-Lopez, Juntao Chen, Yingdong Lu', 'link': 'https://arxiv.org/abs/2502.14264', 'abstract': "Deep reinforcement learning agents often face challenges to effectively coordinate perception and decision-making components, particularly in environments with high-dimensional sensory inputs where feature relevance varies. This work introduces SPRIG (Stackelberg Perception-Reinforcement learning with Internal Game dynamics), a framework that models the internal perception-policy interaction within a single agent as a cooperative Stackelberg game. In SPRIG, the perception module acts as a leader, strategically processing raw sensory states, while the policy module follows, making decisions based on extracted features. SPRIG provides theoretical guarantees through a modified Bellman operator while preserving the benefits of modern policy optimization. Experimental results on the Atari BeamRider environment demonstrate SPRIG's effectiveness, achieving around 30% higher returns than standard PPO through its game-theoretical balance of feature extraction and decision-making.", 'abstract_zh': 'Deep reinforcement learning代理往往面临在高维感官输入环境中有效协调感知和决策组件的挑战，特别是在特征相关性变化的环境中。本文提出了SPRIG（Stackelberg Perception-Reinforcement learning with Internal Game dynamics）框架，将单个代理的内部感知-政策交互建模为合作的Stackelberg游戏。在SPRIG中，感知模块充当领导者，战略性地处理原始感官状态，而政策模块则根据提取的特征作出决策。SPRIG通过修改后的贝尔曼算子提供了理论保证，同时保留了现代策略优化的优势。实验结果表明，SPRIG在Atari BeamRider环境中表现出色，通过其在特征提取和决策之间的游戏理论平衡，实现了约30%的更高回报。', 'title_zh': 'SPRIG: 堆栈博弈感知强化学习与内部博弈动力学'}
{'arxiv_id': 'arXiv:2502.14219', 'title': 'Investigating the Impact of LLM Personality on Cognitive Bias Manifestation in Automated Decision-Making Tasks', 'authors': 'Jiangen He, Jiqun Liu', 'link': 'https://arxiv.org/abs/2502.14219', 'abstract': 'Large Language Models (LLMs) are increasingly used in decision-making, yet their susceptibility to cognitive biases remains a pressing challenge. This study explores how personality traits influence these biases and evaluates the effectiveness of mitigation strategies across various model architectures. Our findings identify six prevalent cognitive biases, while the sunk cost and group attribution biases exhibit minimal impact. Personality traits play a crucial role in either amplifying or reducing biases, significantly affecting how LLMs respond to debiasing techniques. Notably, Conscientiousness and Agreeableness may generally enhance the efficacy of bias mitigation strategies, suggesting that LLMs exhibiting these traits are more receptive to corrective measures. These findings address the importance of personality-driven bias dynamics and highlight the need for targeted mitigation approaches to improve fairness and reliability in AI-assisted decision-making.', 'abstract_zh': '大型语言模型（LLMs）在决策中的应用日益增多，但它们的认知偏见易感性仍然是一个紧迫的挑战。本研究探讨个性特质如何影响这些偏见，并评估不同模型架构下缓解策略的有效性。研究发现六种常见的认知偏见，而沉没成本偏见和归因偏差的影响最小。个性特质在放大或减少偏见方面发挥着关键作用，显著影响LLMs对去偏见技术的响应。值得注意的是，责任心和宜人性可能会普遍增强偏见缓解策略的效果，表明具备这些特质的LLMs更可能对纠正措施产生积极反应。这些发现强调了基于个性的偏见动态的重要性，并突出了需要针对特定缓解方法以提高AI辅助决策的公平性和可靠性的必要性。', 'title_zh': '探究语言模型人格对其在自动化决策任务中认知偏差表现的影响'}
{'arxiv_id': 'arXiv:2502.14200', 'title': 'Causal Mean Field Multi-Agent Reinforcement Learning', 'authors': 'Hao Ma, Zhiqiang Pu, Yi Pan, Boyin Liu, Junlong Gao, Zhenyu Guo', 'link': 'https://arxiv.org/abs/2502.14200', 'abstract': "Scalability remains a challenge in multi-agent reinforcement learning and is currently under active research. A framework named mean-field reinforcement learning (MFRL) could alleviate the scalability problem by employing the Mean Field Theory to turn a many-agent problem into a two-agent problem. However, this framework lacks the ability to identify essential interactions under nonstationary environments. Causality contains relatively invariant mechanisms behind interactions, though environments are nonstationary. Therefore, we propose an algorithm called causal mean-field Q-learning (CMFQ) to address the scalability problem. CMFQ is ever more robust toward the change of the number of agents though inheriting the compressed representation of MFRL's action-state space. Firstly, we model the causality behind the decision-making process of MFRL into a structural causal model (SCM). Then the essential degree of each interaction is quantified via intervening on the SCM. Furthermore, we design the causality-aware compact representation for behavioral information of agents as the weighted sum of all behavioral information according to their causal effects. We test CMFQ in a mixed cooperative-competitive game and a cooperative game. The result shows that our method has excellent scalability performance in both training in environments containing a large number of agents and testing in environments containing much more agents.", 'abstract_zh': '多Agent强化学习的可扩展性仍然是一个挑战，目前正受到广泛关注。一种名为均场强化学习（MFRL）的框架可通过运用均场理论将多Agent问题转化为两Agent问题来缓解可扩展性问题。然而，该框架缺乏在非平稳环境中识别关键交互的能力。因果关系包含在交互背后的相对不变机制，尽管环境是非平稳的。因此，我们提出了一种名为因果均场Q学习（CMFQ）的算法，以解决可扩展性问题。尽管继承了MFRL的动作-状态空间压缩表示，CMFQ对Agent数量的变化具有更强的鲁棒性。首先，我们将均场强化学习背后的决策过程建模为结构因果模型（SCM）。然后，通过干预SCM量化每种交互的关键程度。此外，我们设计了一种基于因果效应加权和的前瞻紧凑表示，用于表示Agent的行为信息。我们在混合合作竞争游戏和合作游戏中测试了CMFQ。结果显示，该方法在包含大量Agent的环境中训练以及在包含更多Agent的环境中测试时，均具有出色的可扩展性性能。', 'title_zh': '因果平均场多智能体强化学习'}
{'arxiv_id': 'arXiv:2502.14155', 'title': 'Giving AI Personalities Leads to More Human-Like Reasoning', 'authors': 'Animesh Nighojkar, Bekhzodbek Moydinboyev, My Duong, John Licato', 'link': 'https://arxiv.org/abs/2502.14155', 'abstract': "In computational cognitive modeling, capturing the full spectrum of human judgment and decision-making processes, beyond just optimal behaviors, is a significant challenge. This study explores whether Large Language Models (LLMs) can emulate the breadth of human reasoning by predicting both intuitive, fast System 1 and deliberate, slow System 2 processes. We investigate the potential of AI to mimic diverse reasoning behaviors across a human population, addressing what we call the {\\em full reasoning spectrum problem}. We designed reasoning tasks using a novel generalization of the Natural Language Inference (NLI) format to evaluate LLMs' ability to replicate human reasoning. The questions were crafted to elicit both System 1 and System 2 responses. Human responses were collected through crowd-sourcing and the entire distribution was modeled, rather than just the majority of the answers. We used personality-based prompting inspired by the Big Five personality model to elicit AI responses reflecting specific personality traits, capturing the diversity of human reasoning, and exploring how personality traits influence LLM outputs. Combined with genetic algorithms to optimize the weighting of these prompts, this method was tested alongside traditional machine learning models. The results show that LLMs can mimic human response distributions, with open-source models like Llama and Mistral outperforming proprietary GPT models. Personality-based prompting, especially when optimized with genetic algorithms, significantly enhanced LLMs' ability to predict human response distributions, suggesting that capturing suboptimal, naturalistic reasoning may require modeling techniques incorporating diverse reasoning styles and psychological profiles. The study concludes that personality-based prompting combined with genetic algorithms is promising for enhancing AI's \\textit{human-ness} in reasoning.", 'abstract_zh': '在计算认知建模中，超越最优行为捕获人类判断和决策的全谱是一种重大挑战。本研究探讨大型语言模型是否能够通过预测直观快速的系统1和审慎缓慢的系统2过程来模拟人类推理的广泛行为。我们通过设计使用自然语言推理（NLI）新扩展格式的推理任务，评估大型语言模型复制人类推理的能力，旨在解决我们所称的“全推理谱问题”。我们使用基于人格的提示，受五大人格特质模型启发，以捕捉人类推理的多样性，并探索人格特质如何影响大型语言模型的输出。结合使用遗传算法优化这些提示的权重，这种方法与传统机器学习模型一同进行了测试。结果显示，开源模型如Llama和Mistral优于专有GPT模型，人格导向的提示，尤其是当与遗传算法优化结合时，显著增强了大型语言模型预测人类反应分布的能力，表明捕捉非最优的自然推理可能需要包含多样化推理风格和心理特质的建模技术。研究得出结论，结合使用人格导向的提示和遗传算法有助于提升人工智能在推理中的“人类特质”。', 'title_zh': '赋予AI人格特质会导致更具人性化的推理'}
{'arxiv_id': 'arXiv:2502.14102', 'title': 'Explainable Distributed Constraint Optimization Problems', 'authors': 'Ben Rachmut, Stylianos Loukas Vasileiou, Nimrod Meir Weinstein, Roie Zivan, William Yeoh', 'link': 'https://arxiv.org/abs/2502.14102', 'abstract': 'The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool to model cooperative multi-agent problems that need to be solved distributively. A core assumption of existing approaches is that DCOP solutions can be easily understood, accepted, and adopted, which may not hold, as evidenced by the large body of literature on Explainable AI. In this paper, we propose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include its solution and a contrastive query for that solution. We formally define some key properties that contrastive explanations must satisfy for them to be considered as valid solutions to X-DCOPs as well as theoretical results on the existence of such valid explanations. To solve X-DCOPs, we propose a distributed framework as well as several optimizations and suboptimal variants to find valid explanations. We also include a human user study that showed that users, not surprisingly, prefer shorter explanations over longer ones. Our empirical evaluations showed that our approach can scale to large problems, and the different variants provide different options for trading off explanation lengths for smaller runtimes. Thus, our model and algorithmic contributions extend the state of the art by reducing the barrier for users to understand DCOP solutions, facilitating their adoption in more real-world applications.', 'abstract_zh': '可解释的分布式约束优化问题（X-DCOP）模型', 'title_zh': '可解释的分布式约束优化问题'}
{'arxiv_id': 'arXiv:2502.14074', 'title': 'Investigating Non-Transitivity in LLM-as-a-Judge', 'authors': 'Yi Xu, Laura Ruis, Tim Rocktäschel, Robert Kirk', 'link': 'https://arxiv.org/abs/2502.14074', 'abstract': 'Automatic evaluation methods based on large language models (LLMs) are emerging as the standard tool for assessing the instruction-following abilities of LLM-based agents. The most common method in this paradigm, pairwise comparisons with a baseline model, critically depends on the assumption of transitive preferences. However, the validity of this assumption remains largely unexplored. In this study, we investigate the presence of non-transitivity within the AlpacaEval framework and analyze its effects on model rankings. We find that LLM judges exhibit non-transitive preferences, leading to rankings that are sensitive to the choice of the baseline model. To mitigate this issue, we show that round-robin tournaments combined with Bradley-Terry models of preference can produce more reliable rankings. Notably, our method increases both the Spearman correlation and the Kendall correlation with Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address the computational cost of round-robin tournaments, we propose Swiss-Wise Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to capture the benefits of round-robin tournaments while maintaining computational efficiency.', 'abstract_zh': '基于大规模语言模型的自动评估方法逐渐成为评估基于语言模型代理-following能力的标准工具。在这种范式中最常见的方法，即与基准模型进行成对比较，关键依赖于传递偏好假设。然而，这一假设的有效性仍很大程度上未经探索。在本研究中，我们考察了AlpacaEval框架内的非传递性现象，并分析其对模型排名的影响。我们发现，语言模型法官表现出非传递性偏好，导致排名对基准模型选择高度敏感。为了缓解这一问题，我们展示了轮比赛结合布雷德利-特里模型能够产生更可靠的排名。值得注意的是，我们的方法提高了与Chatbot Arena的相关性（单变量Spearman相关性从95.0%提高到96.4%，肯德尔相关性从82.1%提高到86.3%）。为解决轮比赛的计算成本问题，我们提出了Smartwise迭代匹配赛制（Swim），采用动态匹配策略以保持计算效率并利用轮比赛的优势。', 'title_zh': '基于LLM的法官角色中非传递性研究'}
{'arxiv_id': 'arXiv:2502.14866', 'title': 'LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention', 'authors': 'Shang Yang, Junxian Guo, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han', 'link': 'https://arxiv.org/abs/2502.14866', 'abstract': 'Large language models (LLMs) have shown remarkable potential in processing long sequences, yet efficiently serving these long-context models remains challenging due to the quadratic computational complexity of attention in the prefilling stage and the large memory footprint of the KV cache in the decoding stage. To address these issues, we introduce LServe, an efficient system that accelerates long-sequence LLM serving via hybrid sparse attention. This method unifies different hardware-friendly, structured sparsity patterns for both prefilling and decoding attention into a single framework, where computations on less important tokens are skipped block-wise. LServe demonstrates the compatibility of static and dynamic sparsity in long-context LLM attention. This design enables multiplicative speedups by combining these optimizations. Specifically, we convert half of the attention heads to nearly free streaming heads in both the prefilling and decoding stages. Additionally, we find that only a constant number of KV pages is required to preserve long-context capabilities, irrespective of context length. We then design a hierarchical KV page selection policy that dynamically prunes KV pages based on query-centric similarity. On average, LServe accelerates LLM prefilling by up to 2.9x and decoding by 1.3-2.1x over vLLM, maintaining long-context accuracy. Code is released at this https URL.', 'abstract_zh': '大规模语言模型(LLMs)在处理长序列方面展现了显著潜力，但由于预填充阶段注意力机制的二次计算复杂度和解码阶段KV缓存的大量内存占用，高效服务于这些长上下文模型仍然具有挑战性。为了解决这些问题，我们引入了LServe系统，通过混合稀疏注意力加速长序列LLM服务。这种方法将预填充和解码注意力的不同硬件友好结构稀疏模式统一到一个框架中，其中对不太重要的标记进行块级跳过计算。LServe展示了静态和动态稀疏性在长上下文LLM注意力中的兼容性。此设计通过结合这些优化实现了加速。具体来说，我们将在预填充和解码阶段将一半的注意力头转换为几乎免费的流式头。此外，我们发现只需要一个常数数量的KV页面即可保留长上下文能力，与上下文长度无关。然后，我们设计了一种分层KV页面选择策略，根据查询中心相似性动态剪枝KV页面。平均而言，LServe在LLM预填充方面的加速为2.9倍，在解码方面的加速为1.3至2.1倍，同时保持长上下文准确性。代码发布于此https网址。', 'title_zh': 'LServe: 效率提升的统一稀疏注意力长序列LLM服务'}
{'arxiv_id': 'arXiv:2502.14862', 'title': 'Interpretable Text Embeddings and Text Similarity Explanation: A Primer', 'authors': 'Juri Opitz, Lucas Möller, Andrianos Michail, Simon Clematide', 'link': 'https://arxiv.org/abs/2502.14862', 'abstract': "Text embeddings and text embedding models are a backbone of many AI and NLP systems, particularly those involving search. However, interpretability challenges persist, especially in explaining obtained similarity scores, which is crucial for applications requiring transparency. In this paper, we give a structured overview of interpretability methods specializing in explaining those similarity scores, an emerging research area. We study the methods' individual ideas and techniques, evaluating their potential for improving interpretability of text embeddings and explaining predicted similarities.", 'abstract_zh': '文本嵌入及其模型是许多AI和NLP系统的核心，特别是在涉及搜索的应用中。然而，可解释性挑战依旧存在，尤其是在解释获得的相似性分数方面，这对需要透明度的应用至关重要。本文提供了一个结构化的综述，概述了专门用于解释这些相似性分数的可解释性方法，这是一个新兴的研究领域。我们研究了这些方法的个体理念和技术，评估它们在提高文本嵌入的可解释性和解释预测相似性方面的潜力。', 'title_zh': '可解释的文本嵌入与文本相似性解释：入门指南'}
{'arxiv_id': 'arXiv:2502.14856', 'title': 'FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling', 'authors': 'Weilin Zhao, Tengyu Pan, Xu Han, Yudi Zhang, Ao Sun, Yuxiang Huang, Kaihuo Zhang, Weilun Zhao, Yuxuan Li, Jianyong Wang, Zhiyuan Liu, Maosong Sun', 'link': 'https://arxiv.org/abs/2502.14856', 'abstract': 'Speculative sampling has emerged as an important technique for accelerating the auto-regressive generation process of large language models (LLMs) by utilizing a draft-then-verify mechanism to produce multiple tokens per forward pass. While state-of-the-art speculative sampling methods use only a single layer and a language modeling (LM) head as the draft model to achieve impressive layer compression, their efficiency gains are substantially reduced for large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens. To address this, we present FR-Spec, a frequency-ranked speculative sampling framework that optimizes draft candidate selection through vocabulary space compression. By constraining the draft search to a frequency-prioritized token subset, our method reduces LM Head computation overhead by 75% while ensuring the equivalence of the final output distribution. Experiments across multiple datasets demonstrate an average of 1.12$\\times$ speedup over the state-of-the-art speculative sampling method EAGLE-2.', 'abstract_zh': '基于频率排名的推测性采样框架FR-Spec通过词汇空间压缩优化候选词选择，以加速大规模语言模型的自回归生成过程。', 'title_zh': 'FR-Spec: 通过频率排序推测性采样加速大规模语言模型'}
{'arxiv_id': 'arXiv:2502.14838', 'title': 'Revealing and Mitigating Over-Attention in Knowledge Editing', 'authors': 'Pinzheng Wang, Zecheng Tang, Keyan Zhou, Juntao Li, Qiaoming Zhu, Min Zhang', 'link': 'https://arxiv.org/abs/2502.14838', 'abstract': "Large Language Models have demonstrated superior performance across a wide range of tasks, but they still exhibit undesirable errors due to incorrect knowledge learned from the training data. To avoid this, knowledge editing methods emerged to precisely edit the specific model knowledge via efficiently modifying a very small percentage of parameters. % However, those methods can lead to the problem of Specificity Failure: when the content related to the edited knowledge occurs in the context, it can inadvertently corrupt other pre-existing knowledge. However, those methods can lead to the problem of Specificity Failure, where the existing knowledge and capabilities are severely degraded due to editing. Our preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge, thereby unduly focusing on specific snippets within the context, which we denote as the Attention Drift phenomenon. To mitigate such Attention Drift issue, we introduce a simple yet effective method Selective Attention Drift Restriction}(SADR), which introduces an additional regularization term during the knowledge editing process to restrict changes in the attention weight distribution, thereby preventing undue focus on the edited entity. Experiments on five frequently used strong LLMs demonstrate the effectiveness of our method, where SADR can significantly mitigate Specificity Failure in the predominant knowledge editing tasks.", 'abstract_zh': '大型语言模型在广泛的任务中展现了出色的表现，但由于训练数据中的错误知识，它们仍然会出现不良错误。为了避免这种情况，出现了知识编辑方法，通过高效地修改极少数参数来精确编辑特定的模型知识。然而，这些方法可能导致特定性失效的问题：当与编辑知识相关的内容出现在上下文中时，可能会无意中损害其他现有的知识。我们的初步研究表明，特定性失效主要源自模型的注意力头对与编辑知识相关的实体赋予过高的注意力分数，从而不当地专注于上下文中的特定片段，我们将其称为注意力漂移现象。为了缓解这种注意力漂移问题，我们提出了一种简单而有效的方法——选择性注意力漂移限制（SADR），该方法在知识编辑过程中引入了一个额外的正则化项，以限制注意力权重分布的变化，从而防止对编辑实体的不适当关注。在五个常用的强大语言模型上的实验表明，我们的方法能够显著缓解主要的知识编辑任务中的特定性失效。', 'title_zh': '揭示并缓解知识编辑中的过度关注问题'}
{'arxiv_id': 'arXiv:2502.14837', 'title': "Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs", 'authors': 'Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, Lixing Shen, Zhan Chen, Xipeng Qiu, Qi Zhang, Tao Gui', 'link': 'https://arxiv.org/abs/2502.14837', 'abstract': 'Multi-head Latent Attention (MLA) is an innovative architecture proposed by DeepSeek, designed to ensure efficient and economical inference by significantly compressing the Key-Value (KV) cache into a latent vector. Compared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its variants such as Grouped-Query Attention (GQA) exhibit significant cost disadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLA without pre-training from scratch is both meaningful and challenging. This paper proposes the first data-efficient fine-tuning method for transitioning from MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE, we remove RoPE from dimensions of queries and keys that contribute less to the attention scores, for low-rank approximation, we introduce joint SVD approximations based on the pre-trained parameters of keys and values. These carefully designed strategies enable MHA2MLA to recover performance using only a small fraction (0.3% to 0.6%) of the data, significantly reducing inference costs while seamlessly integrating with compression techniques such as KV cache quantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%, with only a 0.5% drop in LongBench performance.', 'abstract_zh': '多头潜在注意力（MLA）是一种由DeepSeek提出的创新架构，旨在通过显著压缩键值（KV）缓存为潜在向量来确保高效的经济推理。与MLA相比，使用多头注意力（MHA）及其变体如分组查询注意力（GQA）的标准大型语言模型（LLM）显示出明显的成本劣势。使已训练良好的LLM（如Llama）能够快速适应MLA而无需从头开始预训练是一项既有意义又具有挑战性的工作。本文提出了首个数据高效微调方法MHA2MLA，该方法包括两个关键组成部分：对于部分RoPE，删除对注意力得分贡献较少的查询和键的RoPE；对于低秩近似，基于键和值的预训练参数引入联合SVD近似。这些精心设计的策略使MHA2MLA仅使用极小比例的数据（0.3%到0.6%）就能恢复性能，显著降低推理成本，同时无缝集成压缩技术，如键值缓存量化。例如，Llama2-7B的键值缓存大小减少了92.19%，长本廷基准性能下降了0.5%。', 'title_zh': '面向经济高效的推理：使 DeepSeek 的多头潜在意图注意适用于任意基于Transformer的大语言模型'}
{'arxiv_id': 'arXiv:2502.14834', 'title': 'LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models', 'authors': 'Shangqing Tu, Yucheng Wang, Daniel Zhang-Li, Yushi Bai, Jifan Yu, Yuhao Wu, Lei Hou, Huiqin Liu, Zhiyuan Liu, Bin Xu, Juanzi Li', 'link': 'https://arxiv.org/abs/2502.14834', 'abstract': 'Existing Large Vision-Language Models (LVLMs) can process inputs with context lengths up to 128k visual and text tokens, yet they struggle to generate coherent outputs beyond 1,000 words. We find that the primary limitation is the absence of long output examples during supervised fine-tuning (SFT). To tackle this issue, we introduce LongWriter-V-22k, a SFT dataset comprising 22,158 examples, each with multiple input images, an instruction, and corresponding outputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that maintain high-fidelity to the input images, we employ Direct Preference Optimization (DPO) to the SFT model. Given the high cost of collecting human feedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which breaks long outputs into segments and uses iterative corrections to form preference pairs with the original outputs. Additionally, we develop MMLongBench-Write, a benchmark featuring six tasks to evaluate the long-generation capabilities of VLMs. Our 7B parameter model, trained with LongWriter-V-22k and IterDPO, achieves impressive performance on this benchmark, outperforming larger proprietary models like GPT-4o. Code and data: this https URL', 'abstract_zh': '现有的大型视觉-语言模型（LVLMs）能处理长达128k视觉和文本token的输入，但在生成超过1,000字的连贯输出时存在困难。我们发现主要的限制在于监督微调（SFT）过程中缺乏长输出示例。为了解决这一问题，我们引入了LongWriter-V-22k，这是一个包含22,158个示例的SFT数据集，每个示例包含多张输入图像、一条指令以及从0到10,000字不等的对应输出。此外，为了生成与输入图像保真度高的长输出，我们在SFT模型中采用了直接偏好优化（DPO）。鉴于收集长输出（例如3,000字）的人类反馈成本很高，我们提出了IterDPO，该方法将长输出分解成段落，并通过迭代修正形成与原始输出的偏好对。此外，我们开发了MMLongBench-Write基准，包含六个任务以评估VLMs的长生成能力。使用LongWriter-V-22k和IterDPO训练的7B参数模型在该基准上表现优异，超过了更大的专用模型如GPT-4o。代码和数据：[链接]。', 'title_zh': 'LongWriter-V： enables ultra-long and high-fidelity generation in vision-language models'}
{'arxiv_id': 'arXiv:2502.14831', 'title': 'Improving the Diffusability of Autoencoders', 'authors': 'Ivan Skorokhodov, Sharath Girish, Benran Hu, Willi Menapace, Yanyu Li, Rameen Abdal, Sergey Tulyakov, Aliaksandr Siarohin', 'link': 'https://arxiv.org/abs/2502.14831', 'abstract': 'Latent diffusion models have emerged as the leading approach for generating high-quality images and videos, utilizing compressed latent representations to reduce the computational burden of the diffusion process. While recent advancements have primarily focused on scaling diffusion backbones and improving autoencoder reconstruction quality, the interaction between these components has received comparatively less attention. In this work, we perform a spectral analysis of modern autoencoders and identify inordinate high-frequency components in their latent spaces, which are especially pronounced in the autoencoders with a large bottleneck channel size. We hypothesize that this high-frequency component interferes with the coarse-to-fine nature of the diffusion synthesis process and hinders the generation quality. To mitigate the issue, we propose scale equivariance: a simple regularization strategy that aligns latent and RGB spaces across frequencies by enforcing scale equivariance in the decoder. It requires minimal code changes and only up to 20K autoencoder fine-tuning steps, yet significantly improves generation quality, reducing FID by 19% for image generation on ImageNet-1K 256x256 and FVD by at least 44% for video generation on Kinetics-700 17x256x256.', 'abstract_zh': '潜在扩散模型已成为生成高质量图像和视频的领先方法，通过压缩的潜在表示来减轻扩散过程的计算负担。尽管近期进展主要集中在扩展扩散骨干网络和提高自编码器重建质量上，但这些组件之间的相互作用却相对较少受到关注。在本工作中，我们对现代自编码器进行了频域分析，并发现在其潜在空间中存在异常的高频分量，尤其是在瓶颈通道尺寸较大的自编码器中更为明显。我们假设这种高频分量干扰了扩散合成过程中的自底向上的特性，从而阻碍了生成质量的提升。为了解决这一问题，我们提出了尺度等变性：一种简单的正则化策略，通过在解码器中强制实施尺度等变性来实现潜在空间和RGB空间在不同频率上的对齐。这种方法只需少量代码更改，并且只需最多20,000次自编码器微调步骤，但显著提高了生成质量，对于ImageNet-1K 256x256图像生成将FID降低了19%，对于Kinetics-700 17x256x256视频生成将FVD降低了至少44%。', 'title_zh': '提高自动编码器的扩散性'}
{'arxiv_id': 'arXiv:2502.14830', 'title': 'Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs', 'authors': 'Danni Liu, Jan Niehues', 'link': 'https://arxiv.org/abs/2502.14830', 'abstract': 'While large language models demonstrate remarkable capabilities at task-specific applications through fine-tuning, extending these benefits across diverse languages is essential for broad accessibility. However, effective cross-lingual transfer is hindered by LLM performance gaps across languages and the scarcity of fine-tuning data in many languages. Through analysis of LLM internal representations from over 1,000+ language pairs, we discover that middle layers exhibit the strongest potential for cross-lingual alignment. Building on this finding, we propose a middle-layer alignment objective integrated into task-specific training. Our experiments on slot filling, machine translation, and structured text generation show consistent improvements in cross-lingual transfer, especially to lower-resource languages. The method is robust to the choice of alignment languages and generalizes to languages unseen during alignment. Furthermore, we show that separately trained alignment modules can be merged with existing task-specific modules, improving cross-lingual capabilities without full re-training. Our code is publicly available (this https URL).', 'abstract_zh': '尽管通过微调，大型语言模型在特定任务应用中展现了显著的能力，但在多种语言之间的扩展这些益处对于广泛 accessibility 至关重要。然而，有效的跨语言迁移受到语言间 LLM 性能差距以及许多语言的微调数据稀缺性的阻碍。通过对超过1,000多种语言对的 LLM 内部表示进行分析，我们发现中间层具有最强的跨语言对齐潜力。基于这一发现，我们提出了一种集成在特定任务训练中的中间层对齐目标。我们在槽填充、机器翻译和结构化文本生成任务上的实验显示，在跨语言迁移中具有一致的改进，尤其是在低资源语言上更为显著。该方法对对齐语言的选择具有鲁棒性，并能泛化到训练期间未见过的语言。此外，我们展示了单独训练的对齐模块可以与现有的特定任务模块合并，从而在不需要完整重新训练的情况下提升跨语言能力。我们的代码已公开（this https URL）。', 'title_zh': '中层表示对齐在细调的LLM中的跨语言迁移学习中应用'}
{'arxiv_id': 'arXiv:2502.14827', 'title': 'Exploring Advanced Techniques for Visual Question Answering: A Comprehensive Comparison', 'authors': 'Aiswarya Baby, Tintu Thankom Koshy', 'link': 'https://arxiv.org/abs/2502.14827', 'abstract': 'Visual Question Answering (VQA) has emerged as a pivotal task in the intersection of computer vision and natural language processing, requiring models to understand and reason about visual content in response to natural language questions. Analyzing VQA datasets is essential for developing robust models that can handle the complexities of multimodal reasoning. Several approaches have been developed to examine these datasets, each offering distinct perspectives on question diversity, answer distribution, and visual-textual correlations. Despite significant progress, existing VQA models face challenges related to dataset bias, limited model complexity, commonsense reasoning gaps, rigid evaluation methods, and generalization to real world scenarios. This paper presents a comprehensive comparative study of five advanced VQA models: ABC-CNN, KICNLE, Masked Vision and Language Modeling, BLIP-2, and OFA, each employing distinct methodologies to address these challenges.', 'abstract_zh': '视觉问答（VQA）已成为计算机视觉和自然语言处理交叉领域的一个关键任务，要求模型理解并推理视觉内容以回答自然语言问题。分析VQA数据集对于开发能够处理多模态推理复杂性的稳健模型至关重要。已经开发出了多种方法来检查这些数据集，每种方法都从不同的视角提供了关于问题多样性、答案分布和视觉-文本相关性的见解。尽管取得了显著进展，现有的VQA模型仍面临数据集偏差、模型复杂度有限、常识推理缺口、僵化的评估方法以及向现实场景泛化的挑战。本文对五种先进的VQA模型——ABC-CNN、KICNLE、遮蔽视觉和语言模型、BLIP-2和OFA进行了全面比较研究，每种模型采用了不同的方法来应对这些挑战。', 'title_zh': '探索视觉问答中的高级技术：全面比较'}
{'arxiv_id': 'arXiv:2502.14820', 'title': 'eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables', 'authors': 'Luis Antonio Gutiérrez Guanilo, Mir Tafseer Nayeem, Cristian López, Davood Rafiei', 'link': 'https://arxiv.org/abs/2502.14820', 'abstract': 'Large Language Models (LLMs) have demonstrated exceptional versatility across diverse domains, yet their application in e-commerce remains underexplored due to a lack of domain-specific datasets. To address this gap, we introduce eC-Tab2Text, a novel dataset designed to capture the intricacies of e-commerce, including detailed product attributes and user-specific queries. Leveraging eC-Tab2Text, we focus on text generation from product tables, enabling LLMs to produce high-quality, attribute-specific product reviews from structured tabular data. Fine-tuned models were rigorously evaluated using standard Table2Text metrics, alongside correctness, faithfulness, and fluency assessments. Our results demonstrate substantial improvements in generating contextually accurate reviews, highlighting the transformative potential of tailored datasets and fine-tuning methodologies in optimizing e-commerce workflows. This work highlights the potential of LLMs in e-commerce workflows and the essential role of domain-specific datasets in tailoring them to industry-specific challenges.', 'abstract_zh': '大规模语言模型（LLMs）在电子商务领域的应用由于缺乏专用数据集而未得到充分探索，为此我们引入了eC-Tab2Text数据集，旨在捕捉电子商务领域的复杂性，包括详细的产品属性和用户特定的查询。利用eC-Tab2Text数据集，我们专注于从产品表格生成文本，使得语言模型能够从结构化的表格数据中生成高质量、属性特定的产品评价。经过精细调优的模型使用标准的Table2Text指标进行评估，并结合准确性和忠实性评估。我们的结果表明，在生成上下文相关性评价方面取得了显著改进，突显了定制数据集和调优方法在优化电子商务工作流程中的潜在变革性潜力。该工作突显了语言模型在电子商务工作流程中的潜力以及专用数据集在适应行业特定挑战中的关键作用。', 'title_zh': 'eC-Tab2Text：基于电商产品表格的方面导向文本生成'}
{'arxiv_id': 'arXiv:2502.14807', 'title': 'FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis', 'authors': 'Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring, Saudabi Valappi, Leanne Bricker, Mohammad Yaqub', 'link': 'https://arxiv.org/abs/2502.14807', 'abstract': 'Foundation models are becoming increasingly effective in the medical domain, offering pre-trained models on large datasets that can be readily adapted for downstream tasks. Despite progress, fetal ultrasound images remain a challenging domain for foundation models due to their inherent complexity, often requiring substantial additional training and facing limitations due to the scarcity of paired multimodal data. To overcome these challenges, here we introduce FetalCLIP, a vision-language foundation model capable of generating universal representation of fetal ultrasound images. FetalCLIP was pre-trained using a multimodal learning approach on a diverse dataset of 210,035 fetal ultrasound images paired with text. This represents the largest paired dataset of its kind used for foundation model development to date. This unique training approach allows FetalCLIP to effectively learn the intricate anatomical features present in fetal ultrasound images, resulting in robust representations that can be used for a variety of downstream applications. In extensive benchmarking across a range of key fetal ultrasound applications, including classification, gestational age estimation, congenital heart defect (CHD) detection, and fetal structure segmentation, FetalCLIP outperformed all baselines while demonstrating remarkable generalizability and strong performance even with limited labeled data. We plan to release the FetalCLIP model publicly for the benefit of the broader scientific community.', 'abstract_zh': '基础模型在医学领域日益有效，提供了预训练的大数据分析模型，可以快速适应下游任务。尽管取得了进展，但由于其固有的复杂性，胎儿超声图像仍然是基础模型面临的一大挑战，需要大量额外训练，并且受限于成对多模态数据的稀缺性。为克服这些挑战，我们介绍了FetalCLIP，一种能够生成胎儿超声图像通用表示的基础视觉-语言模型。FetalCLIP使用多模态学习方法，在包含210,035张胎儿超声图像及其文本配对数据的多样化数据集上进行预训练。这代表了迄今为止用于基础模型开发的最大规模的成对数据集。这种独特的训练方法使FetalCLIP能够有效地学习胎儿超声图像中复杂的解剖特征，从而生成可用于多种下游应用的稳健表示。在涵盖胎儿超声图像分类、孕周估计、先天性心脏病检测（CHD）和胎儿结构分割等关键应用的广泛基准测试中，FetalCLIP在所有基线中表现优异，展示了卓越的泛化能力和即使在有限标注数据的情况下仍能表现出色的能力。我们计划将FetalCLIP模型公开发布，以造福更广泛的科学界。', 'title_zh': '胎儿CLIP：一种胎儿超声图像分析的视觉-语言基础模型'}
{'arxiv_id': 'arXiv:2502.14802', 'title': 'From RAG to Memory: Non-Parametric Continual Learning for Large Language Models', 'authors': 'Bernal Jiménez Gutiérrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, Yu Su', 'link': 'https://arxiv.org/abs/2502.14802', 'abstract': 'Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs. Our code and data will be released at this https URL.', 'abstract_zh': '我们持续获取、组织和利用知识的能力是人类智能的关键特征，AI系统必须近似这种能力以充分发挥其潜力。鉴于大规模语言模型（LLMs）连续学习的挑战，检索增强生成（RAG）已成为引入新信息的主要方式。然而，其对向量检索的依赖性限制了其模仿人类长期记忆的动态和相互关联性质的能力。最近的RAG方法通过使用知识图等结构来增强向量嵌入，以解决部分差距，如意义构建和关联性。然而，它们在更基本的事实记忆任务上的表现显著低于标准RAG。我们解决了这一意外的退化，并提出了HippoRAG 2框架，该框架在事实记忆、意义构建和关联记忆任务上全面优于标准RAG。HippoRAG 2以HippoRAG中使用的个性化PageRank算法为基础，并通过更深层次的段落整合和更有效的LLM在线使用来增强它。这种组合使RAG系统更接近人类长期记忆的效果，在关联记忆任务上比最先进的嵌入模型提高了7%的表现，同时在事实知识和意义构建记忆能力方面也表现出更优越的表现。本工作为LLMs提供了一种非参数化的连续学习途径。我们的代码和数据将发布在该网址。', 'title_zh': '从RAG到记忆：大型语言模型的非参数连续学习'}
{'arxiv_id': 'arXiv:2502.14799', 'title': 'A Survey on Text-Driven 360-Degree Panorama Generation', 'authors': 'Hai Wang, Xiaoyu Xiang, Weihao Xia, Jing-Hao Xue', 'link': 'https://arxiv.org/abs/2502.14799', 'abstract': 'The advent of text-driven 360-degree panorama generation, enabling the synthesis of 360-degree panoramic images directly from textual descriptions, marks a transformative advancement in immersive visual content creation. This innovation significantly simplifies the traditionally complex process of producing such content. Recent progress in text-to-image diffusion models has accelerated the rapid development in this emerging field. This survey presents a comprehensive review of text-driven 360-degree panorama generation, offering an in-depth analysis of state-of-the-art algorithms and their expanding applications in 360-degree 3D scene generation. Furthermore, we critically examine current limitations and propose promising directions for future research. A curated project page with relevant resources and research papers is available at this https URL.', 'abstract_zh': '文本驱动的360度全景生成的兴起，使得可以直接从文本描述合成360度全景图像，标志着沉浸式视觉内容创作的一个转型性进步。这一创新显著简化了传统上复杂的内容生成过程。最近在文本到图像扩散模型方面取得的进展加速了这一新兴领域的快速发展。本文综述了文本驱动的360度全景生成，提供了对最先进的算法及其在360度3D场景生成中的扩展应用的深入分析。此外，我们对当前的局限性进行了批判性检视，并提出了未来研究的有希望的方向。相关资源和研究论文可在以下链接中找到：这个https URL。', 'title_zh': '文本驱动的360度全景生成综述'}
{'arxiv_id': 'arXiv:2502.14791', 'title': 'Rapid Word Learning Through Meta In-Context Learning', 'authors': 'Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake', 'link': 'https://arxiv.org/abs/2502.14791', 'abstract': "Humans can quickly learn a new word from a few illustrative examples, and then systematically and flexibly use it in novel contexts. Yet the abilities of current language models for few-shot word learning, and methods for improving these abilities, are underexplored. In this study, we introduce a novel method, Meta-training for IN-context learNing Of Words (Minnow). This method trains language models to generate new examples of a word's usage given a few in-context examples, using a special placeholder token to represent the new word. This training is repeated on many new words to develop a general word-learning ability. We find that training models from scratch with Minnow on human-scale child-directed language enables strong few-shot word learning, comparable to a large language model (LLM) pre-trained on orders of magnitude more data. Furthermore, through discriminative and generative evaluations, we demonstrate that finetuning pre-trained LLMs with Minnow improves their ability to discriminate between new words, identify syntactic categories of new words, and generate reasonable new usages and definitions for new words, based on one or a few in-context examples. These findings highlight the data efficiency of Minnow and its potential to improve language model performance in word learning tasks.", 'abstract_zh': 'Meta-training for IN-context learNing Of Words (Minnow): Improving Few-shot Word Learning Abilities of Language Models', 'title_zh': '通过元上下文学习快速词汇学习'}
{'arxiv_id': 'arXiv:2502.14788', 'title': 'Ray-Tracing for Conditionally Activated Neural Networks', 'authors': 'Claudio Gallicchio, Giuseppe Nuti', 'link': 'https://arxiv.org/abs/2502.14788', 'abstract': "In this paper, we introduce a novel architecture for conditionally activated neural networks combining a hierarchical construction of multiple Mixture of Experts (MoEs) layers with a sampling mechanism that progressively converges to an optimized configuration of expert activation. This methodology enables the dynamic unfolding of the network's architecture, facilitating efficient path-specific training. Experimental results demonstrate that this approach achieves competitive accuracy compared to conventional baselines while significantly reducing the parameter count required for inference. Notably, this parameter reduction correlates with the complexity of the input patterns, a property naturally emerging from the network's operational dynamics without necessitating explicit auxiliary penalty functions.", 'abstract_zh': '本文介绍了一种结合多Mixture of Experts (MoEs)层的分层构建和逐步优化专家激活配置的采样机制的新架构，使网络架构能够动态展开，便于进行路径特定训练。实验结果表明，该方法在参数量显著减少的情况下，仍能达到与传统基线方法相当的准确率。值得注意的是，参数量的减少与输入模式的复杂性自然相关，这一特性源自于网络的操作动态，无需使用显式的辅助惩罚函数。', 'title_zh': '条件激活神经网络的射线 tracing 方案'}
{'arxiv_id': 'arXiv:2502.14786', 'title': 'SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features', 'authors': 'Michael Tschannen, Alexey Gritsenko, Xiao Wang, Muhammad Ferjad Naeem, Ibrahim Alabdulmohsin, Nikhil Parthasarathy, Talfan Evans, Lucas Beyer, Ye Xia, Basil Mustafa, Olivier Hénaff, Jeremiah Harmsen, Andreas Steiner, Xiaohua Zhai', 'link': 'https://arxiv.org/abs/2502.14786', 'abstract': "We introduce SigLIP 2, a family of new multilingual vision-language encoders that build on the success of the original SigLIP. In this second iteration, we extend the original image-text training objective with several prior, independently developed techniques into a unified recipe -- this includes captioning-based pretraining, self-supervised losses (self-distillation, masked prediction) and online data curation. With these changes, SigLIP 2 models outperform their SigLIP counterparts at all model scales in core capabilities, including zero-shot classification, image-text retrieval, and transfer performance when extracting visual representations for Vision-Language Models (VLMs). Furthermore, the new training recipe leads to significant improvements on localization and dense prediction tasks. We also train variants which support multiple resolutions and preserve the input's native aspect ratio. Finally, we train on a more diverse data-mixture that includes de-biasing techniques, leading to much better multilingual understanding and improved fairness. To allow users to trade off inference cost with performance, we release model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M), and g (1B).", 'abstract_zh': 'SigLIP 2：一种新的多模态视觉-语言编码器家族及其统一训练方案', 'title_zh': 'SigLIP 2：具有增强语义理解、定位能力和密集特征的多语言视觉-语言编码器'}
{'arxiv_id': 'arXiv:2502.14785', 'title': 'Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches', 'authors': 'Chandrashekar Muniyappa, Kendall Willets, Sriraman Krishnamoorthy', 'link': 'https://arxiv.org/abs/2502.14785', 'abstract': 'Predicting the right number of TVs (Device Reach) in real-time based on a user-specified targeting attributes is imperative for running multi-million dollar ADs business. The traditional approach of SQL queries to join billions of records across multiple targeting dimensions is extremely slow. As a workaround, many applications will have an offline process to crunch these numbers and present the results after many hours. In our case, the solution was an offline process taking 24 hours to onboard a customer resulting in a potential loss of business. To solve this problem, we have built a new real-time prediction system using MinHash and HyperLogLog (HLL) data sketches to compute the device reach at runtime when a user makes a request. However, existing MinHash implementations do not solve the complex problem of multilevel aggregation and intersection. This work will show how we have solved this problem, in addition, we have improved MinHash algorithm to run 4 times faster using Single Instruction Multiple Data (SIMD) vectorized operations for high speed and accuracy with constant space to process billions of records. Finally, by experiments, we prove that the results are as accurate as traditional offline prediction system with an acceptable error rate of 5%.', 'abstract_zh': '基于用户指定 targeting 属性实时预测合适数量的电视机（设备触达量）是运行百万美元广告业务的关键。传统的基于 SQL 查询的方法在跨多个 targeting 维度连接数十亿记录时极其缓慢。作为 workaround，许多应用将通过离线过程在数小时后计算这些数字并呈现结果。在我们的情况下，离线过程耗时24小时来上线一个客户，导致潜在的业务损失。为了解决这个问题，我们构建了一个新的实时预测系统，使用 MinHash 和 HyperLogLog (HLL) 数据概要，在用户请求时实时计算设备触达量。然而，现有的 MinHash 实现无法解决多层次聚合和交集的复杂问题。本文将展示我们如何解决这一问题，并通过改进 MinHash 算法，使用 Single Instruction Multiple Data (SIMD) 向量化操作在保持常数空间处理数十亿记录的同时提高运行速度和准确性，达到四倍的速度。最终，通过实验证明，该系统的结果与传统的离线预测系统相差不大，误差率为5%。', 'title_zh': '基于HLL和MinHash数据概要的实时设备可达性预测'}
{'arxiv_id': 'arXiv:2502.14780', 'title': 'ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting', 'authors': 'Abhijit Mishra, Richard Noh, Hsiang Fu, Mingda Li, Minji Kim', 'link': 'https://arxiv.org/abs/2502.14780', 'abstract': 'Efficient and privacy-preserving multimodal interaction is essential as AR, VR, and modern smartphones with powerful cameras become primary interfaces for human-computer communication. Existing powerful large vision-language models (VLMs) enabling multimodal interaction often rely on cloud-based processing, raising significant concerns about (1) visual privacy by transmitting sensitive vision data to servers, and (2) their limited real-time, on-device usability. This paper explores Visual Instruction Rewriting, a novel approach that transforms multimodal instructions into text-only commands, allowing seamless integration of lightweight on-device instruction rewriter VLMs (250M parameters) with existing conversational AI systems, enhancing vision data privacy. To achieve this, we present a dataset of over 39,000 examples across 14 domains and develop a compact VLM, pretrained on image captioning datasets and fine-tuned for instruction rewriting. Experimental results, evaluated through NLG metrics such as BLEU, METEOR, and ROUGE, along with semantic parsing analysis, demonstrate that even a quantized version of the model (<500MB storage footprint) can achieve effective instruction rewriting, thus enabling privacy-focused, multimodal AI applications.', 'abstract_zh': '高效且隐私保护的多模态交互对于AR、VR和配备强大摄像头的现代智能手机成为人类计算机通信的主要接口至关重要。现有的强大多模态视觉语言模型（VLMs）虽然能够支持多模态交互，但往往依赖于基于云的处理，这引发了关于（1）视觉隐私的问题，即传输敏感的视觉数据到服务器，以及（2）其有限的实时设备上可使用性的担忧。本文探讨了视觉指令重写这一新颖的方法，该方法将多模态指令转换为纯文本命令，使得轻量级设备上指令重写视觉语言模型（参数量250M）能够无缝集成到现有的对话AI系统中，从而提升视觉数据的隐私保护。为实现这一目标，我们提供了一个涵盖14个领域超过39,000个示例的数据集，并开发了一个紧凑的视觉语言模型，该模型在图像字幕数据集上进行预训练，并微调以进行指令重写。实验结果通过诸如BLEU、METEOR和ROUGE等自然语言生成（NLG）指标进行评估，并通过语义解析分析，证明即使是该模型的量化版本（存储足迹<500MB）也能实现有效的指令重写，从而使得面向隐私的多模态AI应用成为可能。', 'title_zh': 'ReRevision: 一个隐私保护任务导向视觉指令重写的数据集和基线VLM'}
{'arxiv_id': 'arXiv:2502.14778', 'title': 'Harnessing PDF Data for Improving Japanese Large Multimodal Models', 'authors': 'Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa', 'link': 'https://arxiv.org/abs/2502.14778', 'abstract': 'Large Multimodal Models (LMMs) have demonstrated strong performance in English, but their effectiveness in Japanese remains limited due to the lack of high-quality training data. Current Japanese LMMs often rely on translated English datasets, restricting their ability to capture Japan-specific cultural knowledge. To address this, we explore the potential of Japanese PDF data as a training resource, an area that remains largely underutilized. We introduce a fully automated pipeline that leverages pretrained models to extract image-text pairs from PDFs through layout analysis, OCR, and vision-language pairing, removing the need for manual annotation. Additionally, we construct instruction data from extracted image-text pairs to enrich the training data. To evaluate the effectiveness of PDF-derived data, we train Japanese LMMs and assess their performance on the Japanese LMM Benchmark. Our results demonstrate substantial improvements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench. Further analysis highlights the impact of PDF-derived data on various factors, such as model size and language models, reinforcing its value as a multimodal resource for Japanese LMMs. We plan to make the source code and data publicly available upon acceptance.', 'abstract_zh': '大型多模态模型（LMMs）在英语中展现了出色的表现，但在日语中的有效性受限于高质量训练数据的缺乏。当前的日语LMMs经常依赖于英译日语数据集，限制了它们捕捉日本特定文化知识的能力。为了解决这一问题，我们探索了利用日语PDF数据作为训练资源的潜力，这是一个迄今为止很大程度上未被充分利用的领域。我们提出了一个完全自动化的管道，利用预训练模型通过布局分析、OCR和视觉语言配对从PDF中提取图像-文本对，从而去除手动标注的需求。此外，我们从提取的图像-文本对中构建指令数据以丰富训练数据。为了评估从PDF中获得的数据的有效性，我们在日语LMM基准上训练了日语LMMs并评估其性能。我们的结果表明，性能提高了3.9%至13.8%。进一步分析突显了从PDF获得的数据对模型规模和语言模型等因素的影响，强调了其作为日语LMMs多模态资源的价值。我们计划在论文被接受后公开源代码和数据。', 'title_zh': '利用PDF数据提升日语大规模多模态模型'}
{'arxiv_id': 'arXiv:2502.14768', 'title': 'Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning', 'authors': 'Tian Xie, Zitian Gao, Qingnan Ren, Haoming Luo, Yuqian Hong, Bryan Dai, Joey Zhou, Kai Qiu, Zhirong Wu, Chong Luo', 'link': 'https://arxiv.org/abs/2502.14768', 'abstract': 'Inspired by the success of DeepSeek-R1, we explore the potential of rule-based reinforcement learning (RL) in large reasoning models. To analyze reasoning dynamics, we use synthetic logic puzzles as training data due to their controllable complexity and straightforward answer verification. We make some key technical contributions that lead to effective and stable RL training: a system prompt that emphasizes the thinking and answering process, a stringent format reward function that penalizes outputs for taking shortcuts, and a straightforward training recipe that achieves stable convergence. Our 7B model develops advanced reasoning skills-such as reflection, verification, and summarization-that are absent from the logic corpus. Remarkably, after training on just 5K logic problems, it demonstrates generalization abilities to the challenging math benchmarks AIME and AMC.', 'abstract_zh': '受DeepSeek-R1成功的影响，我们探索了基于规则的强化学习（RL）在大规模推理模型中的潜力。为了分析推理动态，我们使用合成逻辑谜题作为训练数据，因为这些数据具有可控的复杂度和直接的答案验证方式。我们做出了一些关键技术贡献，这些贡献使得有效的和稳定的RL训练成为可能：强调思考和回答过程的系统提示、严格格式的奖励函数，以及实现稳定收敛的简单训练配方。我们的7B模型发展了逻辑语料库中缺失的高级推理技能——如反思、验证和总结。令人惊讶的是，经过仅仅5000个逻辑问题的训练，它展示了对具有挑战性的数学基准AIME和AMC的泛化能力。', 'title_zh': '逻辑-RL：基于规则的强化学习释放LLM推理能力'}
{'arxiv_id': 'arXiv:2502.14767', 'title': 'Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis', 'authors': 'Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han', 'link': 'https://arxiv.org/abs/2502.14767', 'abstract': 'With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields. This makes it challenging to assess the significance, novelty, incremental findings, and equivalent ideas between related works, particularly those from different research communities. Large language models (LLMs) have recently demonstrated strong quantitative and qualitative reasoning abilities, and multi-agent LLM debates have shown promise in handling complex reasoning tasks by exploring diverse perspectives and reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a framework which converts scientific papers into LLM personas that debate their respective novelties. To emphasize structured, critical reasoning rather than focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling fine-grained analysis of independent novelty arguments within scholarly articles. Through experiments on scientific literature across various domains, evaluated by expert researchers, we demonstrate that ToD generates informative arguments, effectively contrasts papers, and supports researchers in their literature review.', 'abstract_zh': '随着现代技术的发展和获取途径的改进，科学研究以指数级增长，导致科学发现越来越碎片化，尤其是在不同领域之间。这使得评估相关作品（特别是不同研究社区的作品）之间的意义、新颖性、增量发现和等效思想变得颇具挑战性。大型语言模型（LLMs）最近展示了强大的量化和质化推理能力，多智能体LLM辩论展示了处理复杂推理任务的潜力，通过探索多种观点和推理路径。受此启发，我们提出了一种名为Tree-of-Debate（ToD）的框架，该框架将科学论文转化为LLM人格，并就各自的创新性进行辩论。为强调结构化、批判性推理而非仅关注结果，ToD动态构建辩论树，允许对学术文章中的独立新颖性主张进行精细分析。通过跨多个领域的科学研究文献实验，并由专家研究人员评估，我们证明了ToD生成了信息丰富的论点，有效地对比了论文，并支持研究人员进行文献综述。', 'title_zh': '树状辩论：多角色辩论树促进批判性思维的科学对比分析'}
{'arxiv_id': 'arXiv:2502.14765', 'title': 'Step-by-Step Fact Verification System for Medical Claims with Explainable Reasoning', 'authors': 'Juraj Vladika, Ivana Hacajová, Florian Matthes', 'link': 'https://arxiv.org/abs/2502.14765', 'abstract': 'Fact verification (FV) aims to assess the veracity of a claim based on relevant evidence. The traditional approach for automated FV includes a three-part pipeline relying on short evidence snippets and encoder-only inference models. More recent approaches leverage the multi-turn nature of LLMs to address FV as a step-by-step problem where questions inquiring additional context are generated and answered until there is enough information to make a decision. This iterative method makes the verification process rational and explainable. While these methods have been tested for encyclopedic claims, exploration on domain-specific and realistic claims is missing. In this work, we apply an iterative FV system on three medical fact-checking datasets and evaluate it with multiple settings, including different LLMs, external web search, and structured reasoning using logic predicates. We demonstrate improvements in the final performance over traditional approaches and the high potential of step-by-step FV systems for domain-specific claims.', 'abstract_zh': '基于迭代方法的医学领域事实核查系统研究及评估', 'title_zh': '医学声明逐步验证系统附带可解释的推理'}
{'arxiv_id': 'arXiv:2502.14759', 'title': 'On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems', 'authors': 'Juraj Vladika, Florian Matthes', 'link': 'https://arxiv.org/abs/2502.14759', 'abstract': 'Retrieval-augmented generation (RAG) has emerged as an approach to augment large language models (LLMs) by reducing their reliance on static knowledge and improving answer factuality. RAG retrieves relevant context snippets and generates an answer based on them. Despite its increasing industrial adoption, systematic exploration of RAG components is lacking, particularly regarding the ideal size of provided context, and the choice of base LLM and retrieval method. To help guide development of robust RAG systems, we evaluate various context sizes, BM25 and semantic search as retrievers, and eight base LLMs. Moving away from the usual RAG evaluation with short answers, we explore the more challenging long-form question answering in two domains, where a good answer has to utilize the entire context. Our findings indicate that final QA performance improves steadily with up to 15 snippets but stagnates or declines beyond that. Finally, we show that different general-purpose LLMs excel in the biomedical domain than the encyclopedic one, and that open-domain evidence retrieval in large corpora is challenging.', 'abstract_zh': '检索增强生成（RAG）已成为一种通过减少对静态知识的依赖并提高答案事实性的方法来扩充大型语言模型（LLMs）的方法。RAG检索相关上下文片段并基于它们生成答案。尽管其在工业界的应用越来越广泛，但对RAG组件的系统性探索仍然不足，特别是在提供的上下文的理想大小和基底LLM及检索方法的选择方面。为了指导稳健的RAG系统的开发，我们评估了多种上下文大小、BM25和语义搜索作为检索器，以及八种基底LLM。我们从通常的短答案RAG评估转向探索更具挑战性的长格式问答问题，在两个领域进行研究，其中好的回答需要利用整个上下文。我们的研究发现表明，最终的问答性能随着片段数量的增加而稳步提升，但在一定数量后趋于稳定或下降。最后，我们展示了不同的通用型LLM在生物医学领域和百科领域中表现不同，而且在大规模语料库中进行开放式领域证据检索颇具挑战性。', 'title_zh': '基于检索增强生成系统的上下文大小与模型选择的影响探究'}
{'arxiv_id': 'arXiv:2502.14753', 'title': 'MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders', 'authors': 'Maya Varma, Ashwin Kumar, Rogier van der Sluijs, Sophie Ostmeier, Louis Blankemeier, Pierre Chambon, Christian Bluethgen, Jip Prince, Curtis Langlotz, Akshay Chaudhari', 'link': 'https://arxiv.org/abs/2502.14753', 'abstract': 'Medical images are acquired at high resolutions with large fields of view in order to capture fine-grained features necessary for clinical decision-making. Consequently, training deep learning models on medical images can incur large computational costs. In this work, we address the challenge of downsizing medical images in order to improve downstream computational efficiency while preserving clinically-relevant features. We introduce MedVAE, a family of six large-scale 2D and 3D autoencoders capable of encoding medical images as downsized latent representations and decoding latent representations back to high-resolution images. We train MedVAE autoencoders using a novel two-stage training approach with 1,052,730 medical images. Across diverse tasks obtained from 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent representations in place of high-resolution images when training downstream models can lead to efficiency benefits (up to 70x improvement in throughput) while simultaneously preserving clinically-relevant features and (2) MedVAE can decode latent representations back to high-resolution images with high fidelity. Our work demonstrates that large-scale, generalizable autoencoders can help address critical efficiency challenges in the medical domain. Our code is available at this https URL.', 'abstract_zh': '医学图像以高分辨率和大视野获取，以捕捉临床决策所需的细微特征。因此，训练深度学习模型时可能会产生巨大的计算成本。本文旨在通过压缩医学图像以提高计算效率同时保留临床相关特征，解决这一挑战。我们引入了MedVAE，这是一种由六种大规模2D和3D自编码器组成的家族，能够将医学图像编码为压缩的潜在表示，并将潜在表示解码回高分辨率图像。我们使用新颖的两阶段训练方法，利用1,052,730张医学图像来训练MedVAE自编码器。在来自20个医学图像数据集的多种任务中，我们证明了：（1）在训练下游模型时使用MedVAE潜在表示代替高分辨率图像可以带来效率优势（吞吐量最高可提升70倍）同时保留临床相关特征；（2）MedVAE能够以高保真度将潜在表示解码回高分辨率图像。我们的工作表明，大规模、可泛化的自编码器可以帮助解决医学领域中的关键效率挑战。代码可在以下链接获得：this https URL。', 'title_zh': 'MedVAE: 高效的大型通用自编码器驱动的医学图像自动解释方法'}
{'arxiv_id': 'arXiv:2502.14743', 'title': 'Multi-Agent Coordination across Diverse Applications: A Survey', 'authors': 'Lijun Sun, Yijun Yang, Qiqi Duan, Yuhui Shi, Chao Lyu, Yu-Cheng Chang, Chin-Teng Lin, Yang Shen', 'link': 'https://arxiv.org/abs/2502.14743', 'abstract': 'Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.', 'abstract_zh': '多智能体协调研究探讨了使多智能体系统（MAS）多样化趋势传播的基础机制，并随着新兴应用的扩展和AI的快速进步而受到越来越多的关注。本文通过统一的理解概述了协调研究在各种应用中的现状，回答了四个基本的协调问题：（1）什么是协调；（2）为何协调；（3）与谁协调；（4）如何协调。我们的目的是探索协调领域的现有思想和专业知识及其在不同应用之间的联系，同时识别和突出显示新兴和有前途的研究方向。首先，确定并分析了对多种应用都至关重要的通用协调问题。其次，综述了多种MAS应用，涵盖从广泛研究的领域（如搜索与救援、仓储自动化与物流、交通系统）到新兴领域（如类人和拟人的机器人、卫星系统和大规模语言模型）的应用。最后，分析和讨论了多智能体系统的可扩展性、异构性和学习机制方面的开放挑战。特别是，我们识别出了层次化和去中心化协调的结合、人类与MAS的协调以及基于大规模语言模型的多智能体系统作为有前途的未来方向。', 'title_zh': '多元应用中的多智能体协调：一个综述'}
{'arxiv_id': 'arXiv:2502.14740', 'title': 'YOLOv12: A Breakdown of the Key Architectural Features', 'authors': 'Mujadded Al Rabbani Alif, Muhammad Hussain', 'link': 'https://arxiv.org/abs/2502.14740', 'abstract': 'This paper presents an architectural analysis of YOLOv12, a significant advancement in single-stage, real-time object detection building upon the strengths of its predecessors while introducing key improvements. The model incorporates an optimised backbone (R-ELAN), 7x7 separable convolutions, and FlashAttention-driven area-based attention, improving feature extraction, enhanced efficiency, and robust detections. With multiple model variants, similar to its predecessors, YOLOv12 offers scalable solutions for both latency-sensitive and high-accuracy applications. Experimental results manifest consistent gains in mean average precision (mAP) and inference speed, making YOLOv12 a compelling choice for applications in autonomous systems, security, and real-time analytics. By achieving an optimal balance between computational efficiency and performance, YOLOv12 sets a new benchmark for real-time computer vision, facilitating deployment across diverse hardware platforms, from edge devices to high-performance clusters.', 'abstract_zh': 'YOLOv12：基于前代模型改进的实时单阶段目标检测架构分析', 'title_zh': 'YOLOv12：关键架构特征解析'}
{'arxiv_id': 'arXiv:2502.14735', 'title': 'EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration', 'authors': 'Minjie Hong, Yan Xia, Zehan Wang, Jieming Zhu, Ye Wang, Sihang Cai, Xiaoda Yang, Quanyu Dai, Zhenhua Dong, Zhimeng Zhang, Zhou Zhao', 'link': 'https://arxiv.org/abs/2502.14735', 'abstract': "Large language models (LLMs) are increasingly leveraged as foundational backbones in the development of advanced recommender systems, offering enhanced capabilities through their extensive knowledge and reasoning. Existing llm-based recommender systems (RSs) often face challenges due to the significant differences between the linguistic semantics of pre-trained LLMs and the collaborative semantics essential for RSs. These systems use pre-trained linguistic semantics but learn collaborative semantics from scratch via the llm-Backbone. However, LLMs are not designed for recommendations, leading to inefficient collaborative learning, weak result correlations, and poor integration of traditional RS features. To address these challenges, we propose EAGER-LLM, a decoder-only llm-based generative recommendation framework that integrates endogenous and exogenous behavioral and semantic information in a non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich item indices that integrates indexing sequences for exogenous signals, enabling efficient link-wide processing; 2)non-invasive multiscale alignment reconstruction tasks guide the model toward a deeper understanding of both collaborative and semantic signals; 3)an annealing adapter designed to finely balance the model's recommendation performance with its comprehension capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing on three public benchmarks.", 'abstract_zh': '大型语言模型（LLMs）日益成为高级推荐系统开发中的基础架构核心，通过其广泛的知识和推理能力提供增强功能。现有的基于LLM的推荐系统（RSs）往往因预训练LLM的语义与RS所需的协作语义之间存在的显著差异而面临挑战。这些系统使用预训练的语言语义，但通过LLM骨干从零学习协作语义，然而，LLMs并非为推荐设计，导致协作学习效率低下、结果相关性薄弱以及传统RS特征整合不佳。为解决这些问题，我们提出EAGER-LLM，这是一种仅解码器的基于LLM的生成推荐框架，以非侵入方式整合内在和外在的行为和语义信息。具体而言，我们提出1)双源知识丰富项指标，结合外生信号的索引序列，实现高效的全局链接处理；2)非侵入式的多尺度对齐重构任务引导模型更深地理解协作和语义信号；3)一种退火适配器，旨在精细平衡模型的推荐性能与理解能力。我们通过在三个公开基准上的严格测试展示了EAGER-LLM的有效性。', 'title_zh': 'EAGER-LLM: 通过外生行为语义集成增强大型语言模型的推荐能力'}
{'arxiv_id': 'arXiv:2502.14727', 'title': 'WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models', 'authors': 'Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao', 'link': 'https://arxiv.org/abs/2502.14727', 'abstract': "Retrieval Augmented Generation (RAG) has gained widespread adoption owing to its capacity to empower large language models (LLMs) to integrate external knowledge. However, existing RAG frameworks are primarily designed for text-based LLMs and rely on Automatic Speech Recognition to process speech input, which discards crucial audio information, risks transcription errors, and increases computational overhead. Therefore, we introduce WavRAG, the first retrieval augmented generation framework with native, end-to-end audio support. WavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw audio for both embedding and retrieval. 2) WavRAG integrates audio and text into a unified knowledge representation. Specifically, we propose the WavRetriever to facilitate the retrieval from a text-audio hybrid knowledge base, and further enhance the in-context capabilities of spoken dialogue models through the integration of chain-of-thought reasoning. In comparison to state-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval performance while delivering a 10x acceleration. Furthermore, WavRAG's unique text-audio hybrid retrieval capability extends the boundaries of RAG to the audio modality.", 'abstract_zh': '检索增强生成（RAG）由于能够增强大型语言模型（LLMs）整合外部知识的能力而得到了广泛应用。然而，现有的RAG框架主要针对文本型LLMs，并依赖自动语音识别（ASR）处理语音输入，这会丢弃关键的音频信息、增加转录错误风险和提升计算开销。因此，我们介绍了WavRAG，这是首个具备原生端到端音频支持的检索增强生成框架。WavRAG具有两大关键特性：1）绕过ASR，WavRAG直接处理原始音频以进行嵌入和检索；2）WavRAG将音频和文本整合到统一的知识表示中。具体而言，我们提出了WavRetriever以促进从文本-音频混合知识库中的检索，并通过引入链式推理进一步增强口语对话模型的上下文能力。与最先进的ASR-文本RAG管线相比，WavRAG在检索性能上表现出色，同时实现了10倍的加速效果。此外，WavRAG独特的文本-音频混合检索能力将RAG的应用边界扩展至音频模态。', 'title_zh': 'WavRAG：集成音频的检索增强生成用于口语对话模型'}
{'arxiv_id': 'arXiv:2502.14724', 'title': 'Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics', 'authors': 'Natalia Koliou, George Vouros', 'link': 'https://arxiv.org/abs/2502.14724', 'abstract': "Game-theoretic solution concepts, such as the Nash equilibrium, have been key to finding stable joint actions in multi-player games. However, it has been shown that the dynamics of agents' interactions, even in simple two-player games with few strategies, are incapable of reaching Nash equilibria, exhibiting complex and unpredictable behavior. Instead, evolutionary approaches can describe the long-term persistence of strategies and filter out transient ones, accounting for the long-term dynamics of agents' interactions. Our goal is to identify agents' joint strategies that result in stable behavior, being resistant to changes, while also accounting for agents' payoffs, in dynamic games. Towards this goal, and building on previous results, this paper proposes transforming dynamic games into their empirical forms by considering agents' strategies instead of agents' actions, and applying the evolutionary methodology $\\alpha$-Rank to evaluate and rank strategy profiles according to their long-term dynamics. This methodology not only allows us to identify joint strategies that are strong through agents' long-term interactions, but also provides a descriptive, transparent framework regarding the high ranking of these strategies. Experiments report on agents that aim to collaboratively solve a stochastic version of the graph coloring problem. We consider different styles of play as strategies to define the empirical game, and train policies realizing these strategies, using the DQN algorithm. Then we run simulations to generate the payoff matrix required by $\\alpha$-Rank to rank joint strategies.", 'abstract_zh': '基于演化方法的α-Rank在动态博弈中稳定策略识别与评估', 'title_zh': '使用演化动力学在动态博弈中排名联合策略'}
{'arxiv_id': 'arXiv:2502.14708', 'title': 'Human Misperception of Generative-AI Alignment: A Laboratory Experiment', 'authors': 'Kevin He, Ran Shorrer, Mengjia Xia', 'link': 'https://arxiv.org/abs/2502.14708', 'abstract': "We conduct an incentivized laboratory experiment to study people's perception of generative artificial intelligence (GenAI) alignment in the context of economic decision-making. Using a panel of economic problems spanning the domains of risk, time preference, social preference, and strategic interactions, we ask human subjects to make choices for themselves and to predict the choices made by GenAI on behalf of a human user. We find that people overestimate the degree of alignment between GenAI's choices and human choices. In every problem, human subjects' average prediction about GenAI's choice is substantially closer to the average human-subject choice than it is to the GenAI choice. At the individual level, different subjects' predictions about GenAI's choice in a given problem are highly correlated with their own choices in the same problem. We explore the implications of people overestimating GenAI alignment in a simple theoretical model.", 'abstract_zh': '我们开展了一项激励实验室实验，以研究人们在经济决策背景下对生成人工智能（GenAI）对齐的感知。利用涵盖风险、时间偏好、社会偏好和策略互动的经济问题面板，我们要求人类被试为自己做出选择，并预测代人为用户的人工智能选择。我们发现，人们高估了GenAI选择与人类选择之间的对齐程度。在每一个问题中，人类被试关于GenAI选择的平均预测与人类被试自身的平均选择非常接近，而与GenAI选择相差甚远。在个体层面上，每个被试在特定问题中对GenAI选择的预测与他们自己在相同问题中的选择高度相关。我们探讨了人们高估GenAI对齐的后果，并在简单的理论模型中进行了探讨。', 'title_zh': '人类对生成式AI对齐的误感知：一项实验室实验'}
{'arxiv_id': 'arXiv:2502.14704', 'title': 'Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting', 'authors': 'Yuxuan Yang, Dalin Zhang, Yuxuan Liang, Hua Lu, Huan Li, Gang Chen', 'link': 'https://arxiv.org/abs/2502.14704', 'abstract': 'Time Series Forecasting (TSF) is a crucial task in various domains, yet existing TSF models rely heavily on high-quality data and insufficiently exploit all available data. This paper explores a novel self-supervised approach to re-label time series datasets by inherently constructing candidate datasets. During the optimization of a simple reconstruction network, intermediates are used as pseudo labels in a self-supervised paradigm, improving generalization for any predictor. We introduce the Self-Correction with Adaptive Mask (SCAM), which discards overfitted components and selectively replaces them with pseudo labels generated from reconstructions. Additionally, we incorporate Spectral Norm Regularization (SNR) to further suppress overfitting from a loss landscape perspective. Our experiments on eleven real-world datasets demonstrate that SCAM consistently improves the performance of various backbone models. This work offers a new perspective on constructing datasets and enhancing the generalization of TSF models through self-supervised learning.', 'abstract_zh': '基于自监督的时序数据再标签方法及时间序列预测模型的泛化能力提升', 'title_zh': '并非所有数据都是良好标签：关于时间序列预测的自监督标注研究'}
{'arxiv_id': 'arXiv:2502.14698', 'title': 'General Uncertainty Estimation with Delta Variances', 'authors': 'Simon Schmitt, John Shawe-Taylor, Hado van Hasselt', 'link': 'https://arxiv.org/abs/2502.14698', 'abstract': 'Decision makers may suffer from uncertainty induced by limited data. This may be mitigated by accounting for epistemic uncertainty, which is however challenging to estimate efficiently for large neural networks. To this extent we investigate Delta Variances, a family of algorithms for epistemic uncertainty quantification, that is computationally efficient and convenient to implement. It can be applied to neural networks and more general functions composed of neural networks. As an example we consider a weather simulator with a neural-network-based step function inside -- here Delta Variances empirically obtain competitive results at the cost of a single gradient computation. The approach is convenient as it requires no changes to the neural network architecture or training procedure. We discuss multiple ways to derive Delta Variances theoretically noting that special cases recover popular techniques and present a unified perspective on multiple related methods. Finally we observe that this general perspective gives rise to a natural extension and empirically show its benefit.', 'abstract_zh': '决策者可能因数据有限而面临不确定性，这可以通过考虑 epistemic 不确定性来缓解，但对大规模神经网络而言，高效估计这一不确定性颇具挑战。为此，我们研究了 Delta 方差族算法，这是一种计算高效且易于实现的 epistemic 不确定性量化方法，可应用于神经网络及由神经网络组成的更广泛函数。作为示例，我们考虑了一个包含基于神经网络的步骤函数的气象模拟器——在此情况下，Delta 方差通过单次梯度计算就能获得竞争力的结果。该方法便于实现，不需要对神经网络架构或训练过程进行任何修改。我们从多个角度理论上推导了 Delta 方差，指出其特殊情况可恢复流行技术，并提供了多个相关方法的一致视角。最后，我们观察到这种一般视角导致了自然扩展，并通过实验展示了其优势。', 'title_zh': '基于德尔塔方差的一般不确定性估计'}
{'arxiv_id': 'arXiv:2502.14681', 'title': 'seqKAN: Sequence processing with Kolmogorov-Arnold Networks', 'authors': 'Tatiana Boura, Stasinos Konstantopoulos', 'link': 'https://arxiv.org/abs/2502.14681', 'abstract': 'Kolmogorov-Arnold Networks (KANs) have been recently proposed as a machine learning framework that is more interpretable and controllable than the multi-layer perceptron. Various network architectures have been proposed within the KAN framework targeting different tasks and application domains, including sequence processing.\nThis paper proposes seqKAN, a new KAN architecture for sequence processing. Although multiple sequence processing KAN architectures have already been proposed, we argue that seqKAN is more faithful to the core concept of the KAN framework. Furthermore, we empirically demonstrate that it achieves better results.\nThe empirical evaluation is performed on generated data from a complex physics problem on an interpolation and an extrapolation task. Using this dataset we compared seqKAN against a prior KAN network for timeseries prediction, recurrent deep networks, and symbolic regression. seqKAN substantially outperforms all architectures, particularly on the extrapolation dataset, while also being the most transparent.', 'abstract_zh': 'Kolmogorov-Arnold 网络（KANs）最近被提出作为一种比多层感知机更具有可解释性和可控性的机器学习框架。KAN框架下已经提出多种网络架构，针对不同的任务和应用领域，包括序列处理。\n本文提出了一种新的KAN架构seqKAN，专门用于序列处理。尽管已经提出了多种序列处理的KAN架构，但我们认为seqKAN更忠于KAN框架的核心概念。此外，我们通过实验证明了其表现更优。\n实证评估是在一个复杂物理问题生成的数据集上进行的，包括插值和外推任务。利用该数据集，我们将seqKAN与先前的KAN时间序列预测网络、循环深度网络和符号回归进行了比较。seqKAN在所有架构中表现最佳，特别是在外推数据集上的表现尤为突出，同时其透明度也最高。', 'title_zh': 'seqKAN: 使用柯尔莫哥洛夫-阿诺尔德网络的序列处理'}
{'arxiv_id': 'arXiv:2502.14677', 'title': 'Data-Constrained Synthesis of Training Data for De-Identification', 'authors': 'Thomas Vakili, Aron Henriksson, Hercules Dalianis', 'link': 'https://arxiv.org/abs/2502.14677', 'abstract': 'Many sensitive domains -- such as the clinical domain -- lack widely available datasets due to privacy risks. The increasing generative capabilities of large language models (LLMs) have made synthetic datasets a viable path forward. In this study, we domain-adapt LLMs to the clinical domain and generate synthetic clinical texts that are machine-annotated with tags for personally identifiable information using capable encoder-based NER models. The synthetic corpora are then used to train synthetic NER models. The results show that training NER models using synthetic corpora incurs only a small drop in predictive performance. The limits of this process are investigated in a systematic ablation study -- using both Swedish and Spanish data. Our analysis shows that smaller datasets can be sufficient for domain-adapting LLMs for data synthesis. Instead, the effectiveness of this process is almost entirely contingent on the performance of the machine-annotating NER models trained using the original data.', 'abstract_zh': '许多敏感领域，如临床领域，由于隐私风险缺乏广泛可用的数据集。大型语言模型不断增强的生成能力使其能够生成合成数据集作为可行的选择。在本研究中，我们将大型语言模型适应临床领域，并使用高性能的编码器基NER模型为个人可识别信息生成机器标注的合成临床文本。然后使用这些合成语料库训练合成NER模型。研究结果显示，使用合成语料库训练NER模型仅会导致轻微的预测性能下降。这一过程的限制通过系统性的消融研究进行了探索，使用了瑞典语和西班牙语数据。我们的分析表明，较小的数据集对于适应数据合成的大型语言模型来说可能是足够的，而这一过程的有效性几乎完全取决于使用原始数据训练的机器标注NER模型的性能。', 'title_zh': '基于数据约束的去标识化训练数据合成'}
{'arxiv_id': 'arXiv:2502.14676', 'title': 'BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction', 'authors': 'Ruochen Li, Stamos Katsigiannis, Tae-Kyun Kim, Hubert P. H. Shum', 'link': 'https://arxiv.org/abs/2502.14676', 'abstract': 'Trajectory prediction allows better decision-making in applications of autonomous vehicles or surveillance by predicting the short-term future movement of traffic agents. It is classified into pedestrian or heterogeneous trajectory prediction. The former exploits the relatively consistent behavior of pedestrians, but is limited in real-world scenarios with heterogeneous traffic agents such as cyclists and vehicles. The latter typically relies on extra class label information to distinguish the heterogeneous agents, but such labels are costly to annotate and cannot be generalized to represent different behaviors within the same class of agents. In this work, we introduce the behavioral pseudo-labels that effectively capture the behavior distributions of pedestrians and heterogeneous agents solely based on their motion features, significantly improving the accuracy of trajectory prediction. To implement the framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a trajectory predictor. For optimization, we propose a cascaded training scheme, in which we first learn the pseudo-labels in an unsupervised manner, and then perform end-to-end fine-tuning on the labels in the direction of increasing the trajectory prediction accuracy. Experiments show that our pseudo-labels effectively model different behavior clusters and improve trajectory prediction. Our proposed BP-SGCN outperforms existing methods using both pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets (SDD, Argoverse 1).', 'abstract_zh': '基于行为伪标签的稀疏图卷积网络在轨迹预测中的应用：改善自主车辆或监控应用中的决策制定', 'title_zh': '基于行为伪标签指导的稀疏图卷积网络：行人和其他异质轨迹预测'}
{'arxiv_id': 'arXiv:2502.14671', 'title': 'Explanations of Deep Language Models Explain Language Representations in the Brain', 'authors': 'Maryam Rahimi, Yadollah Yaghoobzadeh, Mohammad Reza Daliri', 'link': 'https://arxiv.org/abs/2502.14671', 'abstract': "Recent advances in artificial intelligence have given rise to large language models (LLMs) that not only achieve human-like performance but also share computational principles with the brain's language processing mechanisms. While previous research has primarily focused on aligning LLMs' internal representations with neural activity, we introduce a novel approach that leverages explainable AI (XAI) methods to forge deeper connections between the two domains. Using attribution methods, we quantified how preceding words contribute to an LLM's next-word predictions and employed these explanations to predict fMRI recordings from participants listening to the same narratives. Our findings demonstrate that attribution methods robustly predict brain activity across the language network, surpassing traditional internal representations in early language areas. This alignment is hierarchical: early-layer explanations correspond to the initial stages of language processing in the brain, while later layers align with more advanced stages. Moreover, the layers more influential on LLM next-word prediction$\\unicode{x2014}$those with higher attribution scores$\\unicode{x2014}$exhibited stronger alignment with neural activity. This work establishes a bidirectional bridge between AI and neuroscience. First, we demonstrate that attribution methods offer a powerful lens for investigating the neural mechanisms of language comprehension, revealing how meaning emerges from preceding context. Second, we propose using brain alignment as a metric to evaluate the validity of attribution methods, providing a framework for assessing their biological plausibility.", 'abstract_zh': '最近人工智能的进步产生了大型语言模型（LLMs），不仅实现了类人的性能，而且还与大脑的语言处理机制共享计算原理。尽管以前的研究主要集中在使LLMs的内部表示与神经活动对齐上，我们介绍了一种新的方法，利用可解释人工智能（XAI）方法来加深这两个领域之间的联系。通过归因方法，我们量化了前一个词对LLM下一词预测的贡献，并使用这些解释预测了参与者听取相同叙述时的fMRI记录。我们的发现表明，归因方法能够稳健地预测语言网络中的脑活动，超过了早期语言区域的传统内部表示。这种对齐是分层的：早期层的解释对应于大脑中语言处理的初期阶段，而后续层则与更高级阶段对齐。此外，对LLM下一词预测影响更大的层——即归因分数更高的层——与神经活动的对齐更为强烈。这项工作建立了人工智能与神经科学之间的双向桥梁。首先，我们证明了归因方法为研究语言理解的神经机制提供了一个强大的视角，揭示了意义是如何从先前的背景中产生的。其次，我们提出了使用大脑对齐作为评估归因方法有效性的指标，提供了一个评估其生物学合理性的框架。', 'title_zh': '深度语言模型的解释揭示脑中语言表示'}
{'arxiv_id': 'arXiv:2502.14645', 'title': 'Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs', 'authors': 'Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao', 'link': 'https://arxiv.org/abs/2502.14645', 'abstract': 'Knowledge editing allows for efficient adaptation of large language models (LLMs) to new information or corrections without requiring full retraining. However, prior methods typically focus on either single-language editing or basic multilingual editing, failing to achieve true cross-linguistic knowledge synchronization. To address this, we present a simple and practical state-of-the-art (SOTA) recipe Cross-Lingual Knowledge Democracy Edit (X-KDE), designed to propagate knowledge from a dominant language to other languages effectively. Our X-KDE comprises two stages: (i) Cross-lingual Edition Instruction Tuning (XE-IT), which fine-tunes the model on a curated parallel dataset to modify in-scope knowledge while preserving unrelated information, and (ii) Target-language Preference Optimization (TL-PO), which applies advanced optimization techniques to ensure consistency across languages, fostering the transfer of updates. Additionally, we contribute a high-quality, cross-lingual dataset, specifically designed to enhance knowledge transfer across languages. Extensive experiments on the Bi-ZsRE and MzsRE benchmarks show that X-KDE significantly enhances cross-lingual performance, achieving an average improvement of +8.19%, while maintaining high accuracy in monolingual settings.', 'abstract_zh': '跨语言知识民主编辑：高效传播多语言知识的新方法', 'title_zh': '一次编辑，全面更新：LLM中跨语言知识同步的简单框架'}
{'arxiv_id': 'arXiv:2502.14637', 'title': 'ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation', 'authors': 'Angxiao Yue, Zichong Wang, Hongteng Xu', 'link': 'https://arxiv.org/abs/2502.14637', 'abstract': 'Protein backbone generation plays a central role in de novo protein design and is significant for many biological and medical applications. Although diffusion and flow-based generative models provide potential solutions to this challenging task, they often generate proteins with undesired designability and suffer computational inefficiency. In this study, we propose a novel rectified quaternion flow (ReQFlow) matching method for fast and high-quality protein backbone generation. In particular, our method generates a local translation and a 3D rotation from random noise for each residue in a protein chain, which represents each 3D rotation as a unit quaternion and constructs its flow by spherical linear interpolation (SLERP) in an exponential format. We train the model by quaternion flow (QFlow) matching with guaranteed numerical stability and rectify the QFlow model to accelerate its inference and improve the designability of generated protein backbones, leading to the proposed ReQFlow model. Experiments show that ReQFlow achieves state-of-the-art performance in protein backbone generation while requiring much fewer sampling steps and significantly less inference time (e.g., being 37x faster than RFDiffusion and 62x faster than Genie2 when generating a backbone of length 300), demonstrating its effectiveness and efficiency. The code is available at this https URL.', 'abstract_zh': '蛋白质主链生成在从头设计蛋白中扮演中心角色，并在许多生物学和医学应用中具有重要意义。尽管扩散和流式生成模型为这一具有挑战性的任务提供了潜在解决方案，但它们往往会生成设计能力不佳的蛋白质，并遭受计算效率低下问题。在此研究中，我们提出了一种新颖的修正四元数流（ReQFlow）匹配方法，以实现快速高效地生成高质量蛋白质主链。特别地，我们的方法为蛋白质链中的每个残基从随机噪声中生成局部平移和3D旋转，并将每个3D旋转表示为单位四元数，通过指数格式下的球面线性插值（SLERP）构造其流。我们通过保证数值稳定的四元数流（QFlow）匹配训练模型，并修正QFlow模型加速其推理过程并提高生成蛋白质主链的设计能力，从而提出了ReQFlow模型。实验结果显示，ReQFlow在蛋白质主链生成方面达到了最先进的性能，所需采样步骤大大减少，并显著缩短了推理时间（例如，在生成长度为300的主链时，比RFDiffusion快37倍，比Genie2快62倍），证明了其有效性和效率。代码可在以下网址获取。', 'title_zh': 'ReQFlow: 正则化四元数流及其在蛋白质主链高效高质生成中的应用'}
{'arxiv_id': 'arXiv:2502.14627', 'title': 'ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors', 'authors': 'Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou', 'link': 'https://arxiv.org/abs/2502.14627', 'abstract': 'Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. We theoretically analyze the inconsistency in terms of both multilingual modal alignment direction error and weight error, and propose the theoretical weight error upper bound for quantifying the inconsistency. Based on the analysis of the weight error upper bound, we find that the inconsistency problem stems from the data distribution error caused by random sampling of languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive learning and audio-English co-anchor contrastive learning, aiming to mitigate the negative impact of data distribution error on recall and consistency in ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets show that our scheme achieves state-of-the-art performance on recall and consistency metrics for eight mainstream languages, including English. Our code will be available at this https URL.', 'abstract_zh': '多语言音频-文本检索（ML-ATR）是一项挑战性的任务，旨在从数据库中检索音频片段或多语言文本。然而，现有的ML-ATR方案在语言间存在一致性的匹配问题。我们从多语言模态对齐方向误差和权重误差两个方面理论上分析了一致性问题，并提出理论权重误差上限来量化这种不一致性。基于权重误差上限的分析，我们发现不一致性问题源于由随机语言采样引起的数据分布误差。我们提出了一种一致的ML-ATR方案，采用1-to-k对比学习和音频-英语共锚对比学习，旨在减轻数据分布误差对检索召回率和一致性的影响。在翻译后的AudioCaps和Clotho数据集上的实验结果显示，我们的方案在主流八种语言（包括英语）的检索召回率和一致性指标上达到了最佳性能。我们的代码将在此处提供：这个 https URL。', 'title_zh': 'ATRI: 通过减少数据分布误差来缓解多语言音频文本检索不一致性'}
{'arxiv_id': 'arXiv:2502.14620', 'title': 'Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline Comparison for Semantic Similarity', 'authors': 'Xinghan Pan', 'link': 'https://arxiv.org/abs/2502.14620', 'abstract': 'This paper investigates the efficacy of RWKV, a novel language model architecture known for its linear attention mechanism, for generating sentence embeddings in a zero-shot setting. I conduct a layer-wise analysis to evaluate the semantic similarity captured by embeddings from different hidden layers of a pre-trained RWKV model. The performance is assessed on the Microsoft Research Paraphrase Corpus (MRPC) dataset using Spearman correlation and compared against a GloVe-based baseline. My results indicate that while RWKV embeddings capture some semantic relatedness, they underperform compared to the GloVe baseline in terms of Spearman correlation. I also analyze the inference time and GPU memory usage, highlighting the computational trade-offs associated with RWKV embeddings. The findings suggest that while RWKV offers potential advantages in terms of linear scaling, its zero-shot sentence embedding quality for semantic similarity tasks requires further investigation and potential task-specific fine-tuning to match or exceed simpler baselines.', 'abstract_zh': '本文调查了RWKV新型语言模型架构在零样本设置下生成句子嵌入的有效性，该架构因其线性注意力机制而闻名。本文逐层分析了预训练RWKV模型的不同隐藏层嵌入捕获的语义相似性，并使用Spearman相关系数在Microsoft Research 偏句对语料库（MRPC）数据集上评估其性能，并将其与基于GloVe的基线进行比较。结果显示，虽然RWKV嵌入捕获了一些语义相关性，但在Spearman相关系数方面仍不如GloVe基线。此外，还分析了推理时间和GPU内存使用情况，突出了与RWKV嵌入相关的计算权衡。研究结果表明，虽然RWKV在线性扩展方面具有潜在优势，但其在语义相似性任务中的零样本句嵌表示质量仍需进一步调查，并可能需要特定任务的微调以匹配或超越更简单的基线模型。', 'title_zh': '探索RWKV在句子嵌入中的应用：逐层分析与语义相似性基线比较'}
{'arxiv_id': 'arXiv:2502.14619', 'title': 'Reward Models Identify Consistency, Not Causality', 'authors': 'Yuhui Xu, Hanze Dong, Lei Wang, Caiming Xiong, Junnan Li', 'link': 'https://arxiv.org/abs/2502.14619', 'abstract': 'Reward models (RMs) play a crucial role in aligning large language models (LLMs) with human preferences and enhancing reasoning quality. Traditionally, RMs are trained to rank candidate outputs based on their correctness and coherence. However, in this work, we present several surprising findings that challenge common assumptions about RM behavior. Our analysis reveals that state-of-the-art reward models prioritize structural consistency over causal correctness. Specifically, removing the problem statement has minimal impact on reward scores, whereas altering numerical values or disrupting the reasoning flow significantly affects RM outputs. Furthermore, RMs exhibit a strong dependence on complete reasoning trajectories truncated or incomplete steps lead to significant variations in reward assignments, indicating that RMs primarily rely on learned reasoning patterns rather than explicit problem comprehension. These findings hold across multiple architectures, datasets, and tasks, leading to three key insights: (1) RMs primarily assess coherence rather than true reasoning quality; (2) The role of explicit problem comprehension in reward assignment is overstated; (3) Current RMs may be more effective at ranking responses than verifying logical validity. Our results suggest a fundamental limitation in existing reward modeling approaches, emphasizing the need for a shift toward causality-aware reward models that go beyond consistency-driven evaluation.', 'abstract_zh': '奖励模型在引导大型语言模型与人类偏好一致并提高推理质量方面发挥着关键作用。传统上，奖励模型被训练以根据正确性和连贯性对候选输出进行排序。然而，在本工作中，我们提出了几个令人惊讶的发现，挑战了关于奖励模型行为的常见假设。我们的分析揭示了，最先进的奖励模型优先考虑结构一致性而非因果正确性。具体而言，去除问题陈述对奖励分数几乎没有影响，而修改数值或破坏推理流程则显著影响奖励模型的输出。此外，奖励模型强烈依赖于完整的推理轨迹；截断或中断的部分步骤会导致奖励分配的重大变化，表明奖励模型主要依赖于学习到的推理模式，而不是明确的问题理解。这些发现适用于多种架构、数据集和任务，得出三个关键见解：（1）奖励模型主要评估连贯性而非真正的推理质量；（2）明确的问题理解在奖励分配中的作用被高估了；（3）当前的奖励模型可能在对响应进行排名上比验证逻辑有效性更有效。我们的结果指出了现有奖励建模方法的基本局限性，强调了转向因果性感知奖励模型的重要性，这种奖励模型超出了基于一致性的评估。', 'title_zh': '奖励模型识别一致性和因果性'}
{'arxiv_id': 'arXiv:2502.14583', 'title': 'A Theory for Conditional Generative Modeling on Multiple Data Sources', 'authors': 'Rongzhen Wang, Yan Zhang, Chenyu Zheng, Chongxuan Li, Guoqiang Wu', 'link': 'https://arxiv.org/abs/2502.14583', 'abstract': 'The success of large generative models has driven a paradigm shift, leveraging massive multi-source data to enhance model capabilities. However, the interaction among these sources remains theoretically underexplored. This paper takes the first step toward a rigorous analysis of multi-source training in conditional generative modeling, where each condition represents a distinct data source. Specifically, we establish a general distribution estimation error bound in average total variation distance for conditional maximum likelihood estimation based on the bracketing number. Our result shows that when source distributions share certain similarities and the model is expressive enough, multi-source training guarantees a sharper bound than single-source training. We further instantiate the general theory on conditional Gaussian estimation and deep generative models including autoregressive and flexible energy-based models, by characterizing their bracketing numbers. The results highlight that the number of sources and similarity among source distributions improve the advantage of multi-source training. Simulations and real-world experiments validate our theory. Code is available at: \\url{this https URL}.', 'abstract_zh': '大型生成模型的成功推动了范式转变，依托海量多源数据提升模型能力。然而，这些源数据之间的交互仍缺乏理论探究。本文首次对条件生成建模中的多源训练进行严谨分析，其中每个条件代表一个独立的数据源。具体而言，我们基于覆盖数建立了条件最大似然估计的均值绝对偏差的一般分布估计误差界。我们的结果表明，在源分布具有一定相似性且模型足够表达力的情况下，多源训练比单源训练提供更严格的误差界。进一步地，我们在条件高斯估计和深度生成模型（包括自回归和灵活的能量基础模型）中实例化了该通用理论，并通过表征它们的覆盖数对其进行量化。结果强调，源的数量以及源分布之间的相似性增强了多源训练的优势。仿真和真实世界实验验证了我们的理论。代码请参见：\\url{this https URL}。', 'title_zh': '多数据源条件生成 modeling 理论'}
{'arxiv_id': 'arXiv:2502.14572', 'title': 'Factor Graph-based Interpretable Neural Networks', 'authors': 'Yicong Li, Kuanjiu Zhou, Shuo Yu, Qiang Zhang, Renqiang Luo, Xiaodong Li, Feng Xia', 'link': 'https://arxiv.org/abs/2502.14572', 'abstract': 'Comprehensible neural network explanations are foundations for a better understanding of decisions, especially when the input data are infused with malicious perturbations. Existing solutions generally mitigate the impact of perturbations through adversarial training, yet they fail to generate comprehensible explanations under unknown perturbations. To address this challenge, we propose AGAIN, a fActor GrAph-based Interpretable neural Network, which is capable of generating comprehensible explanations under unknown perturbations. Instead of retraining like previous solutions, the proposed AGAIN directly integrates logical rules by which logical errors in explanations are identified and rectified during inference. Specifically, we construct the factor graph to express logical rules between explanations and categories. By treating logical rules as exogenous knowledge, AGAIN can identify incomprehensible explanations that violate real-world logic. Furthermore, we propose an interactive intervention switch strategy rectifying explanations based on the logical guidance from the factor graph without learning perturbations, which overcomes the inherent limitation of adversarial training-based methods in defending only against known perturbations. Additionally, we theoretically demonstrate the effectiveness of employing factor graph by proving that the comprehensibility of explanations is strongly correlated with factor graph. Extensive experiments are conducted on three datasets and experimental results illustrate the superior performance of AGAIN compared to state-of-the-art baselines.', 'abstract_zh': '可解释的神经网络解释是理解决策基础，尤其在输入数据包含恶意扰动时。为应对这一挑战，我们提出了一种基于因子图的可解释神经网络AGAIN，能够在未知扰动下生成可解释的解释。我们通过构建因子图来表达解释与类别之间的逻辑规则，并借助逻辑规则直接集成逻辑规则，识别和纠正推理过程中的逻辑错误，而不需要重新训练。此外，我们提出了一种基于因子图逻辑指导的交互式干预切换策略，可以在不学习扰动的情况下纠正解释，从而克服基于对抗训练方法的固有局限性。我们还从理论上证明了因子图的有效性，表明解释的可解释性与因子图高度相关。在三个数据集上进行的广泛实验表明，AGAIN的性能优于现有先进的基线方法。', 'title_zh': '基于因子图的可解释神经网络'}
{'arxiv_id': 'arXiv:2502.14560', 'title': 'Less is More: Improving LLM Alignment via Preference Data Selection', 'authors': 'Xun Deng, Han Zhong, Rui Ai, Fuli Feng, Zheng Wang, Xiangnan He', 'link': 'https://arxiv.org/abs/2502.14560', 'abstract': 'Direct Preference Optimization (DPO) has emerged as a promising approach for aligning large language models with human preferences. While prior work mainly extends DPO from the aspect of the objective function, we instead improve DPO from the largely overlooked but critical aspect of data selection. Specifically, we address the issue of parameter shrinkage caused by noisy data by proposing a novel margin-maximization principle for dataset curation in DPO training. To accurately estimate margins for data selection, we propose a dual-margin guided approach that considers both external reward margins and implicit DPO reward margins. Extensive experiments demonstrate that our method reduces computational cost dramatically while improving performance. Remarkably, by using just 10\\% of the Ultrafeedback dataset, our approach achieves 3\\% to 8\\% improvements across various Llama and Mistral series models on the AlpacaEval 2.0 benchmark. Furthermore, our approach seamlessly extends to iterative DPO, yielding a roughly 3\\% improvement with 25\\% online data, while further reducing training time. These results highlight the potential of data selection strategies for advancing preference optimization.', 'abstract_zh': '直接偏好优化(DPO)作为一种使大型语言模型与人类偏好对齐的有前景方法已逐渐兴起。虽然先前的工作主要从目标函数的角度扩展了DPO，我们则从被广泛忽视但至关重要的数据选择角度改进了DPO。具体而言，我们提出了一种新颖的边际最大化原则来解决由嘈杂数据引起的参数收缩问题，并应用于DPO训练的数据集筛选。为了准确估计用于数据选择的边际，我们提出了一种双边际引导方法，该方法同时考虑外部奖励边际和隐式DPO奖励边际。大量实验表明，我们的方法大幅降低了计算成本，同时提升了性能。此外，通过使用Ultrafeedback数据集的10%，我们的方法在AlpacaEval 2.0基准上各系列Llama和Mistral模型上实现了3%到8%的性能提升。进一步地，我们的方法无缝扩展到迭代DPO，仅使用25%的在线数据即可获得约3%的性能提升，同时进一步缩短了训练时间。这些结果突显了数据选择策略在推动偏好优化方面的潜力。', 'title_zh': '少即是多：通过偏好数据选择提高LLM对齐程度'}
{'arxiv_id': 'arXiv:2502.14558', 'title': 'FUIA: Model Inversion Attack against Federated Unlearning', 'authors': 'Lei Zhou, Youwen Zhu', 'link': 'https://arxiv.org/abs/2502.14558', 'abstract': 'With the introduction of regulations related to the ``right to be forgotten", federated learning (FL) is facing new privacy compliance challenges. To address these challenges, researchers have proposed federated unlearning (FU). However, existing FU research has primarily focused on improving the efficiency of unlearning, with less attention paid to the potential privacy vulnerabilities inherent in these methods. To address this gap, we draw inspiration from gradient inversion attacks in FL and propose the federated unlearning inversion attack (FUIA). The FUIA is specifically designed for the three types of FU (sample unlearning, client unlearning, and class unlearning), aiming to provide a comprehensive analysis of the privacy leakage risks associated with FU. In FUIA, the server acts as an honest-but-curious attacker, recording and exploiting the model differences before and after unlearning to expose the features and labels of forgotten data. FUIA significantly leaks the privacy of forgotten data and can target all types of FU. This attack contradicts the goal of FU to eliminate specific data influence, instead exploiting its vulnerabilities to recover forgotten data and expose its privacy flaws. Extensive experimental results show that FUIA can effectively reveal the private information of forgotten data. To mitigate this privacy leakage, we also explore two potential defense methods, although these come at the cost of reduced unlearning effectiveness and the usability of the unlearned model.', 'abstract_zh': '随着“被遗忘权”相关法规的引入，联邦学习（FL）面临新的隐私合规挑战。为了应对这些挑战，研究人员提出了联邦遗忘（FU）。然而，现有的FU研究主要集中在提高遗忘的效率上，对这些方法中固有的潜在隐私漏洞关注较少。为填补这一空白，我们从FL中的梯度反转攻击中汲取灵感，提出了联邦遗忘反转攻击（FUIA）。FUIA特别针对三种类型的FU（样本遗忘、客户端遗忘和类别遗忘），旨在全面分析FU引起的隐私泄漏风险。在FUIA中，服务器扮演诚实但好奇的攻击者角色，记录并利用遗忘前后模型的差异以揭示被遗忘数据的特征和标签。FUIA显著泄露了被遗忘数据的隐私，并可以针对所有类型的FU进行攻击。该攻击与FU消除特定数据影响的目标相反，反而利用其漏洞恢复被遗忘的数据并暴露其隐私缺陷。大量实验结果表明，FUIA可以有效地揭示被遗忘数据的私人信息。为了减轻这种隐私泄漏，我们还探讨了两种潜在的防御方法，尽管这会降低遗忘的效率并减弱遗忘模型的实用性。', 'title_zh': 'FUIA：针对联邦忘录的模型反转攻击'}
{'arxiv_id': 'arXiv:2502.14553', 'title': 'Multiscale Byte Language Models -- A Hierarchical Architecture for Causal Million-Length Sequence Modeling', 'authors': 'Eric Egli, Matteo Manica, Jannis Born', 'link': 'https://arxiv.org/abs/2502.14553', 'abstract': "Bytes form the basis of the digital world and thus are a promising building block for multimodal foundation models. Recently, Byte Language Models (BLMs) have emerged to overcome tokenization, yet the excessive length of bytestreams requires new architectural paradigms. Therefore, we present the Multiscale Byte Language Model (MBLM), a model-agnostic hierarchical decoder stack that allows training with context windows of $5$M bytes on single GPU in full model precision. We thoroughly examine MBLM's performance with Transformer and Mamba blocks on both unimodal and multimodal tasks. Our experiments demonstrate that hybrid architectures are efficient in handling extremely long byte sequences during training while achieving near-linear generational efficiency. To the best of our knowledge, we present the first evaluation of BLMs on visual Q\\&A tasks and find that, despite serializing images and the absence of an encoder, a MBLM with pure next token prediction can match custom CNN-LSTM architectures with designated classification heads. We show that MBLMs exhibit strong adaptability in integrating diverse data representations, including pixel and image filestream bytes, underlining their potential toward omnimodal foundation models. Source code is publicly available at: this https URL", 'abstract_zh': '字节构成了数字世界的基石，因此是多模态基础模型的有前途的构建块。最近，字节语言模型（BLMs）涌现出来以克服分词问题，然而字节流的过长长度需要新的架构范式。因此，我们提出了多尺度字节语言模型（MBLM），一种模型无关的分层解码堆栈，允许在单个GPU上以全模型精度训练 CONTEXT WINDOWS 大小为5M字节。我们在单模态和多模态任务中使用Transformer和Mamba块全面检查了MBLM的性能。我们的实验表明，混合架构在处理训练中的极长长字节序列时效率高，同时实现接近线性的生成效率。据我们所知，我们首次在视觉问答任务上评估了BLMs，并发现尽管序列化了图像且没有编码器，一个纯下一个词预测的MBLM可以匹配带有专用分类头的自定义CNN-LSTM架构。我们展示了MBLMs在整合各种数据表示方面的强大适应性，包括像素和图像文件流字节，这突显了它们向全方位模态基础模型的潜力。源代码可在以下网址获取：this https URL', 'title_zh': '多尺度字级语言模型——一种用于因果千万长度序列建模的分层架构'}
{'arxiv_id': 'arXiv:2502.14546', 'title': 'Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks', 'authors': 'Maya Bechler-Speicher, Ben Finkelshtein, Fabrizio Frasca, Luis Müller, Jan Tönshoff, Antoine Siraudin, Viktor Zaverkin, Michael M. Bronstein, Mathias Niepert, Bryan Perozzi, Mikhail Galkin, Christopher Morris', 'link': 'https://arxiv.org/abs/2502.14546', 'abstract': 'While machine learning on graphs has demonstrated promise in drug design and molecular property prediction, significant benchmarking challenges hinder its further progress and relevance. Current benchmarking practices often lack focus on transformative, real-world applications, favoring narrow domains like two-dimensional molecular graphs over broader, impactful areas such as combinatorial optimization, relational databases, or chip design. Additionally, many benchmark datasets poorly represent the underlying data, leading to inadequate abstractions and misaligned use cases. Fragmented evaluations and an excessive focus on accuracy further exacerbate these issues, incentivizing overfitting rather than fostering generalizable insights. These limitations have prevented the development of truly useful graph foundation models. This position paper calls for a paradigm shift toward more meaningful benchmarks, rigorous evaluation protocols, and stronger collaboration with domain experts to drive impactful and reliable advances in graph learning research, unlocking the potential of graph learning.', 'abstract_zh': '关于图学习基准测试、评估范式和领域专家合作的范式转变：释放图学习研究潜力的有意义基准、严格的评估协议和更强的跨学科合作', 'title_zh': '位置：基于图的学习因基准不足将失去相关性'}
{'arxiv_id': 'arXiv:2502.14529', 'title': 'CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models', 'authors': 'Zhenhong Zhou, Zherui Li, Jie Zhang, Yuanhe Zhang, Kun Wang, Yang Liu, Qing Guo', 'link': 'https://arxiv.org/abs/2502.14529', 'abstract': 'Large Language Model-based Multi-Agent Systems (LLM-MASs) have demonstrated remarkable real-world capabilities, effectively collaborating to complete complex tasks. While these systems are designed with safety mechanisms, such as rejecting harmful instructions through alignment, their security remains largely unexplored. This gap leaves LLM-MASs vulnerable to targeted disruptions. In this paper, we introduce Contagious Recursive Blocking Attacks (Corba), a novel and simple yet highly effective attack that disrupts interactions between agents within an LLM-MAS. Corba leverages two key properties: its contagious nature allows it to propagate across arbitrary network topologies, while its recursive property enables sustained depletion of computational resources. Notably, these blocking attacks often involve seemingly benign instructions, making them particularly challenging to mitigate using conventional alignment methods. We evaluate Corba on two widely-used LLM-MASs, namely, AutoGen and Camel across various topologies and commercial models. Additionally, we conduct more extensive experiments in open-ended interactive LLM-MASs, demonstrating the effectiveness of Corba in complex topology structures and open-source models. Our code is available at: this https URL.', 'abstract_zh': '基于大规模语言模型的多智能体系统（LLM-MASs）展示了显著的实际能力，有效协作以完成复杂任务。尽管这些系统设计了诸如通过对齐拒绝有害指令的安全机制，其安全性仍 largely未被探索。这一差距使LLM-MASs暴露于有针对性的干扰之下。在本文中，我们介绍了传染性递归阻塞攻击（Corba），这是一种新颖且简单的高效攻击方法，能够破坏LLM-MAS中智能体之间的交互。Corba 利用了两个关键属性：其传染性质使其能够在任意网络拓扑中传播，而其递归性质则使其能够持续耗尽计算资源。值得注意的是，这些阻塞攻击往往涉及看似无害的指令，这使得使用传统的对齐方法进行缓解尤为具有挑战性。我们在 AutoGen 和 Camel 这两种广泛使用的 LLM-MAS 上评估了 Corba，涉及多种拓扑结构和商用模型。此外，我们在开放式的交互式 LLM-MAS 中进行了更为广泛的实验，证明了 Corba 在复杂拓扑结构和开源模型中的有效性。代码可在此处访问：this https URL。', 'title_zh': '基于大型语言模型的CORBA：多代理系统中的传染性递归阻塞攻击'}
{'arxiv_id': 'arXiv:2502.14525', 'title': 'Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting', 'authors': 'Yannick Wölker, Arash Hajisafi, Cyrus Shahabi, Matthias Renz', 'link': 'https://arxiv.org/abs/2502.14525', 'abstract': 'We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for analyzing traffic data, demonstrating its efficacy in two critical tasks: forecasting and reconstruction. Unlike typical GNN methods that treat each traffic sensor as an individual graph node, DeepStateGNN clusters sensors into higher-level graph nodes, dubbed Deep State Nodes, based on various similarity criteria, resulting in a fixed number of nodes in a Deep State graph. The term "Deep State" nodes is a play on words, referencing hidden networks of power that, like these nodes, secretly govern traffic independently of visible sensors. These Deep State Nodes are defined by several similarity factors, including spatial proximity (e.g., sensors located nearby in the road network), functional similarity (e.g., sensors on similar types of freeways), and behavioral similarity under specific conditions (e.g., traffic behavior during rain). This clustering approach allows for dynamic and adaptive node grouping, as sensors can belong to multiple clusters and clusters may evolve over time. Our experimental results show that DeepStateGNN offers superior scalability and faster training, while also delivering more accurate results than competitors. It effectively handles large-scale sensor networks, outperforming other methods in both traffic forecasting and reconstruction accuracy.', 'abstract_zh': '我们提出了一种新型图神经网络（GNN）模型DeepStateGNN，用于分析交通数据，并展示了其在两种关键任务（预报和重建）上的有效性。DeepStateGNN 根据各种相似性 criteria 将传感器聚类成更高层次的图节点，称为“Deep State”节点，从而形成了一个固定节点数的“Deep State”图。“Deep State”节点这个名字取了隐秘权力网络的谐音，这些节点像隐秘权力网络一样，在不依赖于可见传感器的情况下独立管理交通。这些“Deep State”节点由多种相似性因素定义，包括空间接近性（例如，路网中邻近的传感器）、功能相似性（例如，类似类型的高速公路上的传感器）和在特定条件下的行为相似性（例如，雨天的交通行为）。这种聚类方法允许动态和适应性的节点分组，因为传感器可以属于多个聚类，聚类也可能随着时间演化。实验结果表明，DeepStateGNN 在可扩展性、训练速度以及准确性方面优于其他竞争方法，并且在大规模传感器网络中表现出色，在交通预报和重建准确性方面均优于其他方法。', 'title_zh': '小图即一切：DeepStateGNN 用于可扩展的交通预测'}
{'arxiv_id': 'arXiv:2502.14504', 'title': 'PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models', 'authors': 'Yu Meng, Kaiyuan Li, Chenran Huang, Chen Gao, Xinlei Chen, Yong Li, Xiaoping Zhang', 'link': 'https://arxiv.org/abs/2502.14504', 'abstract': 'Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a range of multimodal tasks. However, their inference efficiency is constrained by the large number of visual tokens processed during decoding. To address this challenge, we propose Per-Layer Per-Head Vision Token Pruning (PLPHP), a two-level fine-grained pruning method including Layer-Level Retention Rate Allocation and Head-Level Vision Token Pruning. Motivated by the Vision Token Re-attention phenomenon across decoder layers, we dynamically adjust token retention rates layer by layer. Layers that exhibit stronger attention to visual information preserve more vision tokens, while layers with lower vision attention are aggressively pruned. Furthermore, PLPHP applies pruning at the attention head level, enabling different heads within the same layer to independently retain critical context. Experiments on multiple benchmarks demonstrate that PLPHP delivers an 18% faster decoding speed and reduces the Key-Value Cache (KV Cache) size by over 50%, all at the cost of 0.46% average performance drop, while also achieving notable performance improvements in multi-image tasks. These results highlight the effectiveness of fine-grained token pruning and contribute to advancing the efficiency and scalability of LVLMs. Our source code will be made publicly available.', 'abstract_zh': 'Large Vision-Language Models的细粒度剪枝方法：层级和头部视 tokens 剪枝（PLPHP）', 'title_zh': 'PLPHP：每层每头视觉token剪枝以提高大型视觉-语言模型的效率'}
{'arxiv_id': 'arXiv:2502.14499', 'title': 'MLGym: A New Framework and Benchmark for Advancing AI Research Agents', 'authors': 'Deepak Nathani, Lovish Madaan, Nicholas Roberts, Nikolay Bashlykov, Ajay Menon, Vincent Moens, Amar Budhiraja, Despoina Magka, Vladislav Vorotilov, Gaurav Chaurasia, Dieuwke Hupkes, Ricardo Silveira Cabral, Tatiana Shavrina, Jakob Foerster, Yoram Bachrach, William Yang Wang, Roberta Raileanu', 'link': 'https://arxiv.org/abs/2502.14499', 'abstract': 'We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for evaluating and developing LLM agents on AI research tasks. This is the first Gym environment for machine learning (ML) tasks, enabling research on reinforcement learning (RL) algorithms for training such agents. MLGym-bench consists of 13 diverse and open-ended AI research tasks from diverse domains such as computer vision, natural language processing, reinforcement learning, and game theory. Solving these tasks requires real-world AI research skills such as generating new ideas and hypotheses, creating and processing data, implementing ML methods, training models, running experiments, analyzing the results, and iterating through this process to improve on a given task. We evaluate a number of frontier large language models (LLMs) on our benchmarks such as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5 Pro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate models or agents, generate synthetic data at scale, as well as develop new learning algorithms for training agents on AI research tasks. We find that current frontier models can improve on the given baselines, usually by finding better hyperparameters, but do not generate novel hypotheses, algorithms, architectures, or substantial improvements. We open-source our framework and benchmark to facilitate future research in advancing the AI research capabilities of LLM agents.', 'abstract_zh': 'Meta MLGym和MLGym-Bench：一个新的框架和基准，用于评估和开发在AI研究任务上工作的LLM代理', 'title_zh': 'MLGym：一个新的框架和基准，用于推动AI研究代理发展'}
{'arxiv_id': 'arXiv:2502.14487', 'title': 'Temporal Misalignment and Probabilistic Neurons', 'authors': 'Velibor Bojković, Xiaofeng Wu, Bin Gu', 'link': 'https://arxiv.org/abs/2502.14487', 'abstract': 'Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to Artificial Neural Networks (ANNs) by mimicking biological neural principles, establishing them as a promising approach to mitigate the increasing energy demands of large-scale neural models. However, fully harnessing the capabilities of SNNs remains challenging due to their discrete signal processing and temporal dynamics. ANN-SNN conversion has emerged as a practical approach, enabling SNNs to achieve competitive performance on complex machine learning tasks. In this work, we identify a phenomenon in the ANN-SNN conversion framework, termed temporal misalignment, in which random spike rearrangement across SNN layers leads to performance improvements. Based on this observation, we introduce biologically plausible two-phase probabilistic (TPP) spiking neurons, further enhancing the conversion process. We demonstrate the advantages of our proposed method both theoretically and empirically through comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet across a variety of architectures, achieving state-of-the-art results.', 'abstract_zh': 'Spiking Neural Networks (SNNs)在模仿生物神经原则方面提供了一种更节能的替代方案，成为减轻大规模神经模型日益增加的能耗的有前途的方法。然而，全面发挥SNNs的能力仍具有挑战性，这是因为它们的离散信号处理和时间动态。ANN-SNN转换作为一种实用的方法 emerged as a practical approach，使SNNs能够在复杂机器学习任务中实现竞争性能。在本工作中，我们指出了ANN-SNN转换框架中的一个现象，称为时间对齐不匹配，其中SNN层间的随机尖峰重新排列导致性能提升。基于这一观察，我们引入了生物上合理的两阶段概率（TPP）尖峰神经元，进一步增强了转换过程。通过在CIFAR-10/100、CIFAR10-DVS和ImageNet上涵盖多种架构的全面实验，我们从理论上和实验上证明了我们提出的方法的优势，并取得了目前最先进的结果。', 'title_zh': '时空失准与概率神经元'}
{'arxiv_id': 'arXiv:2502.14486', 'title': 'How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation', 'authors': 'Zhuohang Long, Siyuan Wang, Shujun Liu, Yuhang Lai, Xuanjing Huang, Zhongyu Wei', 'link': 'https://arxiv.org/abs/2502.14486', 'abstract': "Jailbreak attacks, where harmful prompts bypass generative models' built-in safety, raise serious concerns about model vulnerability. While many defense methods have been proposed, the trade-offs between safety and helpfulness, and their application to Large Vision-Language Models (LVLMs), are not well understood. This paper systematically examines jailbreak defenses by reframing the standard generation task as a binary classification problem to assess model refusal tendencies for both harmful and benign queries. We identify two key defense mechanisms: safety shift, which increases refusal rates across all queries, and harmfulness discrimination, which improves the model's ability to distinguish between harmful and benign inputs. Using these mechanisms, we develop two ensemble defense strategies-inter-mechanism ensembles and intra-mechanism ensembles-to balance safety and helpfulness. Experiments on the MM-SafetyBench and MOSSBench datasets with LLaVA-1.5 models show that these strategies effectively improve model safety or optimize the trade-off between safety and helpfulness.", 'abstract_zh': 'Jailbreak攻击通过有害提示规避生成模型内置的安全机制，引发了对模型脆弱性的严重担忧。尽管已经提出了许多防御方法，但这些方法在安全性和帮助性之间的权衡，以及它们在大规模视觉-语言模型（LVLMs）上的应用尚不完全清楚。本文通过重新定义标准生成任务为二元分类问题，系统地研究了防御机制，以评估模型对有害和良性查询的拒绝倾向。我们识别了两种关键防御机制：安全性转移，它提高了所有查询的拒绝率；有害性辨别，它提高了模型区分有害和良性输入的能力。利用这些机制，我们开发了两种集成防御策略——跨机制集成和机制内集成，以平衡安全性和帮助性。实验结果表明，这些策略有效地提高了模型安全性或优化了安全性和帮助性之间的权衡。', 'title_zh': 'Jailbreak 防御机制及其集成研究：一种机制性调查'}
{'arxiv_id': 'arXiv:2502.14469', 'title': 'Enhancing Smart Environments with Context-Aware Chatbots using Large Language Models', 'authors': 'Aurora Polo-Rodríguez, Laura Fiorini, Erika Rovini, Filippo Cavallo, Javier Medina-Quero', 'link': 'https://arxiv.org/abs/2502.14469', 'abstract': "This work presents a novel architecture for context-aware interactions within smart environments, leveraging Large Language Models (LLMs) to enhance user experiences. Our system integrates user location data obtained through UWB tags and sensor-equipped smart homes with real-time human activity recognition (HAR) to provide a comprehensive understanding of user context. This contextual information is then fed to an LLM-powered chatbot, enabling it to generate personalised interactions and recommendations based on the user's current activity and environment. This approach moves beyond traditional static chatbot interactions by dynamically adapting to the user's real-time situation. A case study conducted from a real-world dataset demonstrates the feasibility and effectiveness of our proposed architecture, showcasing its potential to create more intuitive and helpful interactions within smart homes. The results highlight the significant benefits of integrating LLM with real-time activity and location data to deliver personalised and contextually relevant user experiences.", 'abstract_zh': '本研究提出了一种新的架构，用于智能环境中的上下文感知交互，借助大型语言模型（LLMs）增强用户体验。该系统将通过UWB标签和传感器装备的智能家庭获取的用户位置数据与实时人体活动识别（HAR）相结合，提供对用户上下文的全面理解。随后，这些上下文信息被输入到LLM驱动的聊天机器人中，使其能够根据用户的当前活动和环境生成个性化的交互和建议。该方法超越了传统的静态聊天机器人交互方式，能够动态适应用户的实时情况。从实际数据集进行的案例研究证明了所提出架构的可行性和有效性，展示了其在智能家庭中创建更加直观和有帮助的交互的潜力。结果强调了将LLM与实时活动和位置数据结合使用以实现个性化和上下文相关用户体验的重大优势。', 'title_zh': '利用大规模语言模型增强基于情境意识的聊天机器人在智能环境中的应用'}
{'arxiv_id': 'arXiv:2502.14462', 'title': 'Single-image Reflectance and Transmittance Estimation from Any Flatbed Scanner', 'authors': 'Carlos Rodriguez-Pardo, David Pascual-Hernandez, Javier Rodriguez-Vazquez, Jorge Lopez-Moreno, Elena Garces', 'link': 'https://arxiv.org/abs/2502.14462', 'abstract': 'Flatbed scanners have emerged as promising devices for high-resolution, single-image material capture. However, existing approaches assume very specific conditions, such as uniform diffuse illumination, which are only available in certain high-end devices, hindering their scalability and cost. In contrast, in this work, we introduce a method inspired by intrinsic image decomposition, which accurately removes both shading and specularity, effectively allowing captures with any flatbed scanner. Further, we extend previous work on single-image material reflectance capture with the estimation of opacity and transmittance, critical components of full material appearance (SVBSDF), improving the results for any material captured with a flatbed scanner, at a very high resolution and accuracy', 'abstract_zh': '基于平面扫描仪的单图像材料捕捉方法：去 shading 和 specularity 以适用于任意扫描仪并估计不透明度和透射率', 'title_zh': '单张图像从任意平板扫描仪估计反射率和透射率'}
{'arxiv_id': 'arXiv:2502.14458', 'title': 'Llamba: Scaling Distilled Recurrent Models for Efficient Language Processing', 'authors': 'Aviv Bick, Tobias Katsch, Nimit Sohoni, Arjun Desai, Albert Gu', 'link': 'https://arxiv.org/abs/2502.14458', 'abstract': 'We introduce Llamba, a family of efficient recurrent language models distilled from Llama-3.x into the Mamba architecture. The series includes Llamba-1B, Llamba-3B, and Llamba-8B, which achieve higher inference throughput and handle significantly larger batch sizes than Transformer-based models while maintaining comparable benchmark performance. Furthermore, Llamba demonstrates the effectiveness of cross-architecture distillation using MOHAWK (Bick et al., 2024), achieving these results with less than 0.1% of the training data typically used for models of similar size. To take full advantage of their efficiency, we provide an optimized implementation of Llamba for resource-constrained devices such as smartphones and edge platforms, offering a practical and memory-efficient alternative to Transformers. Overall, Llamba improves the tradeoff between speed, memory efficiency, and performance, making high-quality language models more accessible.', 'abstract_zh': 'Llamba：一种从Llama-3.x通过Mamba架构提炼的高效递归语言模型系列', 'title_zh': 'Llamba：扩展蒸馏循环模型以实现高效语言处理'}
{'arxiv_id': 'arXiv:2502.14457', 'title': 'Watch Less, Feel More: Sim-to-Real RL for Generalizable Articulated Object Manipulation via Motion Adaptation and Impedance Control', 'authors': 'Tan-Dzung Do, Nandiraju Gireesh, Jilong Wang, He Wang', 'link': 'https://arxiv.org/abs/2502.14457', 'abstract': 'Articulated object manipulation poses a unique challenge compared to rigid object manipulation as the object itself represents a dynamic environment. In this work, we present a novel RL-based pipeline equipped with variable impedance control and motion adaptation leveraging observation history for generalizable articulated object manipulation, focusing on smooth and dexterous motion during zero-shot sim-to-real transfer. To mitigate the sim-to-real gap, our pipeline diminishes reliance on vision by not leveraging the vision data feature (RGBD/pointcloud) directly as policy input but rather extracting useful low-dimensional data first via off-the-shelf modules. Additionally, we experience less sim-to-real gap by inferring object motion and its intrinsic properties via observation history as well as utilizing impedance control both in the simulation and in the real world. Furthermore, we develop a well-designed training setting with great randomization and a specialized reward system (task-aware and motion-aware) that enables multi-staged, end-to-end manipulation without heuristic motion planning. To the best of our knowledge, our policy is the first to report 84\\% success rate in the real world via extensive experiments with various unseen objects.', 'abstract_zh': '具身物体操作相较于刚体物体操作提出了独特的挑战，因为物体本身代表了一个动态环境。本文提出一种新颖的基于强化学习的流水线，该流水线结合了可变阻抗控制和基于观测历史的运动适应，以实现通用的具身物体操作，重点关注零样本模拟到现实转移中的平滑灵巧运动。为了缓解模拟与现实之间的差距，该流水线通过不直接将视觉数据特征（RGBD/点云）作为策略输入，而是首先通过现成模块提取有用的低维数据来减少对视觉数据的依赖。此外，通过利用观测历史推断物体运动及其固有特性，并在模拟和现实世界中均使用阻抗控制，我们体验到了较小的模拟到现实的差距。进一步地，我们设计了一个包含大量随机化的训练设置，以及一个专门的奖励系统（任务感知和运动感知），这使得多阶段、端到端的操作成为可能，且无需启发式运动规划。据我们所知，我们的策略是首个通过各种未见过的物体的广泛实验报告在真实世界中取得84%成功率的策略。', 'title_zh': '减少观看，增强感受：基于运动适应和阻抗控制的通用articulated对象操作的Sim-to-Real RL研究'}
{'arxiv_id': 'arXiv:2502.14455', 'title': 'An Efficient Ground-aerial Transportation System for Pest Control Enabled by AI-based Autonomous Nano-UAVs', 'authors': 'Luca Crupi, Luca Butera, Alberto Ferrante, Alessandro Giusti, Daniele Palossi', 'link': 'https://arxiv.org/abs/2502.14455', 'abstract': 'Efficient crop production requires early detection of pest outbreaks and timely treatments; we consider a solution based on a fleet of multiple autonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detect pests and a single slower heavy vehicle that visits the detected outbreaks to deliver treatments. To cope with the extreme limitations aboard nano-UAVs, e.g., low-resolution sensors and sub-100 mW computational power budget, we design, fine-tune, and optimize a tiny image-based convolutional neural network (CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58 GOps/inference), on our dataset, it scores a mean average precision (mAP) of 0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32x fewer operations than the best-performing CNN in the literature. Our CNN runs in real-time at 6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflie nano-UAV. Then, to cope with in-field unexpected obstacles, we leverage a global+local path planner based on the A* algorithm. The global path planner determines the best route for the nano-UAV to sweep the entire area, while the local one runs up to 50 Hz aboard our nano-UAV and prevents collision by adjusting the short-distance path. Finally, we demonstrate with in-simulator experiments that once a 25 nano-UAVs fleet has combed a 200x200 m vineyard, collected information can be used to plan the best path for the tractor, visiting all and only required hotspots. In this scenario, our efficient transportation system, compared to a traditional single-ground vehicle performing both inspection and treatment, can save up to 20 h working time.', 'abstract_zh': '基于纳米无人机的高效作物生产：早期害虫爆发检测与及时治疗的解决方案', 'title_zh': '基于AI自主纳米无人机的高效地面-空中害虫防控交通系统'}
{'arxiv_id': 'arXiv:2502.14445', 'title': 'PredictaBoard: Benchmarking LLM Score Predictability', 'authors': 'Lorenzo Pacchiardi, Konstantinos Voudouris, Ben Slater, Fernando Martínez-Plumed, José Hernández-Orallo, Lexin Zhou, Wout Schellaert', 'link': 'https://arxiv.org/abs/2502.14445', 'abstract': 'Despite possessing impressive skills, Large Language Models (LLMs) often fail unpredictably, demonstrating inconsistent success in even basic common sense reasoning tasks. This unpredictability poses a significant challenge to ensuring their safe deployment, as identifying and operating within a reliable "safe zone" is essential for mitigating risks. To address this, we present PredictaBoard, a novel collaborative benchmarking framework designed to evaluate the ability of score predictors (referred to as assessors) to anticipate LLM errors on specific task instances (i.e., prompts) from existing datasets. PredictaBoard evaluates pairs of LLMs and assessors by considering the rejection rate at different tolerance errors. As such, PredictaBoard stimulates research into developing better assessors and making LLMs more predictable, not only with a higher average performance. We conduct illustrative experiments using baseline assessors and state-of-the-art LLMs. PredictaBoard highlights the critical need to evaluate predictability alongside performance, paving the way for safer AI systems where errors are not only minimised but also anticipated and effectively mitigated. Code for our benchmark can be found at this https URL', 'abstract_zh': '尽管拥有令人印象深刻的技能，大型语言模型（LLMs）常常不可预测地失败，在甚至是最基本的常识推理任务上表现出不一致的成功率。这种不可预测性对确保其安全部署构成了重大挑战，因为在安全区内可靠运行是降低风险的关键。为此，我们提出PredictaBoard，这是一种新型的协作基准框架，旨在评估分数预测器（称为评估器）的能力，使其能够预测大型语言模型在特定任务实例（即提示）上的错误。PredictaBoard通过考虑不同容错错误条件下的拒绝率来评估大型语言模型和评估器的配对。因此，PredictaBoard促进了开发更好的评估器和使大型语言模型更具可预测性的研究，不仅在平均性能上更高。我们使用基础评估器和最先进的大型语言模型进行了演示性实验。PredictaBoard突显了评估可预测性与性能同样重要，为安全的人工智能系统铺平了道路，在这种系统中，错误不仅被最小化，还会被预见并有效缓解。我们的基准代码可以在以下链接找到：this https URL。', 'title_zh': 'PredictaBoard: 评估大型语言模型得分可预测性基准'}
{'arxiv_id': 'arXiv:2502.14442', 'title': 'Stochastic Resonance Improves the Detection of Low Contrast Images in Deep Learning Models', 'authors': 'Siegfried Ludwig', 'link': 'https://arxiv.org/abs/2502.14442', 'abstract': 'Stochastic resonance describes the utility of noise in improving the detectability of weak signals in certain types of systems. It has been observed widely in natural and engineered settings, but its utility in image classification with rate-based neural networks has not been studied extensively. In this analysis a simple LSTM recurrent neural network is trained for digit recognition and classification. During the test phase, image contrast is reduced to a point where the model fails to recognize the presence of a stimulus. Controlled noise is added to partially recover classification performance. The results indicate the presence of stochastic resonance in rate-based recurrent neural networks.', 'abstract_zh': '随机共振描述了噪声在改善某些类型系统中弱信号可检测性方面的应用。它已在自然和工程环境中广泛观察到，但在基于速率的神经网络中的图像分类应用中尚未进行详细研究。在此分析中，我们训练了一个简单的LSTM循环神经网络进行数字识别和分类。在测试阶段，降低图像对比度至网络无法识别刺激存在的程度。通过添加受控噪声部分恢复分类性能。结果表明，基于速率的循环神经网络中存在随机共振现象。', 'title_zh': '随机共振改善了深度学习模型中低对比度图像的检测'}
{'arxiv_id': 'arXiv:2502.14424', 'title': 'Distribution Matching for Self-Supervised Transfer Learning', 'authors': 'Yuling Jiao, Wensen Ma, Defeng Sun, Hansheng Wang, Yang Wang', 'link': 'https://arxiv.org/abs/2502.14424', 'abstract': 'In this paper, we propose a novel self-supervised transfer learning method called Distribution Matching (DM), which drives the representation distribution toward a predefined reference distribution while preserving augmentation invariance. The design of DM results in a learned representation space that is intuitively structured and offers easily interpretable hyperparameters. Experimental results across multiple real-world datasets and evaluation metrics demonstrate that DM performs competitively on target classification tasks compared to existing self-supervised transfer learning methods. Additionally, we provide robust theoretical guarantees for DM, including a population theorem and an end-to-end sample theorem. The population theorem bridges the gap between the self-supervised learning task and target classification accuracy, while the sample theorem shows that, even with a limited number of samples from the target domain, DM can deliver exceptional classification performance, provided the unlabeled sample size is sufficiently large.', 'abstract_zh': '本文提出了一种新颖的自监督迁移学习方法，称为分布匹配（DM），该方法驱动表示分布趋向预定义的参考分布，同时保持增强不变性。DM的设计导致了一个直观结构化的学习表示空间，并提供了易于解释的超参数。在多个实际数据集和评估指标上的实验结果表明，DM在目标分类任务上与现有的自监督迁移学习方法具有竞争力。此外，我们为DM提供了稳健的理论保障，包括总体定理和端到端样本定理。总体定理将自监督学习任务与目标分类准确性联系起来，而样本定理表明，即使在目标域中仅有有限数量的样本，只要未标注样本的数量足够大，DM仍能实现卓越的分类性能。', 'title_zh': '自我监督迁移学习中的分布匹配'}
{'arxiv_id': 'arXiv:2502.14416', 'title': 'Reliable Explainability of Deep Learning Spatial-Spectral Classifiers for Improved Semantic Segmentation in Autonomous Driving', 'authors': 'Jon Gutiérrez-Zaballa, Koldo Basterretxea, Javier Echanobe', 'link': 'https://arxiv.org/abs/2502.14416', 'abstract': "Integrating hyperspectral imagery (HSI) with deep neural networks (DNNs) can strengthen the accuracy of intelligent vision systems by combining spectral and spatial information, which is useful for tasks like semantic segmentation in autonomous driving. To advance research in such safety-critical systems, determining the precise contribution of spectral information to complex DNNs' output is needed. To address this, several saliency methods, such as class activation maps (CAM), have been proposed primarily for image classification. However, recent studies have raised concerns regarding their reliability. In this paper, we address their limitations and propose an alternative approach by leveraging the data provided by activations and weights from relevant DNN layers to better capture the relationship between input features and predictions. The study aims to assess the superior performance of HSI compared to 3-channel and single-channel DNNs. We also address the influence of spectral signature normalization for enhancing DNN robustness in real-world driving conditions.", 'abstract_zh': '将高光谱成像（HSI）与深度神经网络（DNNs）集成可以增强智能视觉系统的准确性，通过结合光谱和空间信息，这有助于自动驾驶中的语义分割等任务。为了推进此类安全关键系统的研究，确定光谱信息对复杂DNNs输出的精确贡献是必要的。为此，已经提出了多种显著性方法，如类激活图（CAM），主要用于图像分类。然而，近期研究对它们的可靠性和准确性提出了质疑。本文旨在解决这些问题，并通过利用相关DNN层中的激活数据和权重，提出一种新的方法来更好地捕捉输入特征与预测之间的关系。研究旨在评估HSI相较于3通道和单通道DNN的优越性能。我们还探讨了光谱特征规范化对提高DNN在真实驾驶条件下的鲁棒性的影响。', 'title_zh': '深度学习空谱分类器的可靠可解释性在自主驾驶改进语义分割中的应用'}
{'arxiv_id': 'arXiv:2502.14382', 'title': 'S*: Test Time Scaling for Code Generation', 'authors': 'Dacheng Li, Shiyi Cao, Chengkun Cao, Xiuyu Li, Shangyin Tan, Kurt Keutzer, Jiarong Xing, Joseph E. Gonzalez, Ion Stoica', 'link': 'https://arxiv.org/abs/2502.14382', 'abstract': 'Increasing test-time compute for LLMs shows promise across domains but remains underexplored in code generation, despite extensive study in math. In this paper, we propose S*, the first hybrid test-time scaling framework that substantially improves the coverage and selection accuracy of generated code. S* extends the existing parallel scaling paradigm with sequential scaling to push performance boundaries. It further leverages a novel selection mechanism that adaptively generates distinguishing inputs for pairwise comparison, combined with execution-grounded information to robustly identify correct solutions. We evaluate across 12 Large Language Models and Large Reasoning Model and show: (1) S* consistently improves performance across model families and sizes, enabling a 3B model to outperform GPT-4o-mini; (2) S* enables non-reasoning models to surpass reasoning models - GPT-4o-mini with S* outperforms o1-preview by 3.7% on LiveCodeBench; (3) S* further boosts state-of-the-art reasoning models - DeepSeek-R1-Distill-Qwen-32B with S* achieves 85.7% on LiveCodeBench, approaching o1 (high) at 88.5%. Code will be available under this https URL.', 'abstract_zh': '增加测试时计算量对大型语言模型和大型推理模型显示出跨领域潜力，但在代码生成领域尚未得到充分探索，尽管在数学领域已有广泛研究。本文提出S*，这是一种新颖的混合测试时扩展框架，显著提高了生成代码的覆盖面和选择准确性。S*扩展了现有的并行扩展范式，加入序列扩展以推动性能边界，并结合了一种新颖的选择机制，该机制自适应地生成区分性输入用于成对比较，结合执行基于的信息以稳健地识别正确解。我们在12个大型语言模型和大型推理模型上进行评估，结果显示：（1）S*在不同模型家族和规模上一致提高性能，使一个3B模型能够超越GPT-4o-mini；（2）S*使非推理模型超越推理模型——配备S*的GPT-4o-mini在LiveCodeBench上比o1-preview高出3.7%；（3）S*进一步提升了最先进的推理模型——配备S*的DeepSeek-R1-Distill-Qwen-32B在LiveCodeBench上取得85.7%的分数，接近o1（高水平）的88.5%。代码将在以下链接下提供：https URL。', 'title_zh': 'S*: 测试时代码生成的缩放方法'}
{'arxiv_id': 'arXiv:2502.14380', 'title': 'Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations', 'authors': 'Mariko Kato, Hakaze Cho, Yoshihiro Sakai, Naoya Inoue', 'link': 'https://arxiv.org/abs/2502.14380', 'abstract': "The performance of In-Context Learning (ICL) is highly sensitive to the selected demonstrations. Existing approaches to demonstration selection optimize different objectives, yielding inconsistent results. To address this, we propose a unified metric--affinity and diversity--that leverages ICL model's internal representations. Our experiments show that both affinity and diversity strongly correlate with test accuracies, indicating their effectiveness for demonstration selection. Moreover, we show that our proposed metrics align well with various previous works to unify the inconsistency.", 'abstract_zh': '基于上下文学习的表现高度依赖于所选示例。现有的示例选择方法优化不同的目标，导致结果不一致。为了解决这一问题，我们提出了一种统一的度量标准——亲和度与多样性，该标准利用了基于上下文学习模型的内部表示。我们的实验表明，亲和度和多样性与测试准确性高度相关，表明它们在示例选择中的有效性。此外，我们展示了我们提出的度量标准与多种先前工作中的一致性良好，有助于统一这些差异。', 'title_zh': '亲和力与多样性：基于内部表示的示范选择统一度量标准'}
{'arxiv_id': 'arXiv:2502.14372', 'title': 'Discovering highly efficient low-weight quantum error-correcting codes with reinforcement learning', 'authors': 'Austin Yubo He, Zi-Wen Liu', 'link': 'https://arxiv.org/abs/2502.14372', 'abstract': 'The realization of scalable fault-tolerant quantum computing is expected to hinge on quantum error-correcting codes. In the quest for more efficient quantum fault tolerance, a critical code parameter is the weight of measurements that extract information about errors to enable error correction: as higher measurement weights require higher implementation costs and introduce more errors, it is important in code design to optimize measurement weight. This underlies the surging interest in quantum low-density parity-check (qLDPC) codes, the study of which has primarily focused on the asymptotic (large-code-limit) properties. In this work, we introduce a versatile and computationally efficient approach to stabilizer code weight reduction based on reinforcement learning (RL), which produces new low-weight codes that substantially outperform the state of the art in practically relevant parameter regimes, extending significantly beyond previously accessible small distances. For example, our approach demonstrates savings in physical qubit overhead compared to existing results by 1 to 2 orders of magnitude for weight 6 codes and brings the overhead into a feasible range for near-future experiments. We also investigate the interplay between code parameters using our RL framework, offering new insights into the potential efficiency and power of practically viable coding strategies. Overall, our results demonstrate how RL can effectively advance the crucial yet challenging problem of quantum code discovery and thereby facilitate a faster path to the practical implementation of fault-tolerant quantum technologies.', 'abstract_zh': '可扩展容错量子计算的实现有望依赖于量子纠错码。在寻求更高效的量子容错性中，纠错码的一个关键参数是提取错误信息的测量权重：较高测量权重需要更高的实现成本并引入更多错误，因此在编码设计中优化测量权重非常重要。这促进了对量子低密度 parity-check (qLDPC) 码的研究兴趣，该项研究主要集中在渐近（大码长极限）性质上。在本工作中，我们基于强化学习（RL）提出了一个灵活且计算高效的稳定器码权重减小方法，该方法在实际相关参数范围内生成了性能显著优于现有最佳结果的新低权重码，大大超越了先前可访问的小距离。例如，我们的方法在权重为6的编码中与现有结果相比，物理量子比特开销节省了1到2个数量级，并将开销带入了近期实验可行的范围。我们还利用我们的RL框架研究了编码参数之间的相互作用，提供了对实际可行编码策略的潜在效率和能力的新见解。总体而言，我们的结果展示了RL如何有效推进关键而具有挑战性的量子编码发现问题，并从而促进更快实现容错量子技术的实用性。', 'title_zh': '使用强化学习发现高效低权重量子纠错码'}
{'arxiv_id': 'arXiv:2502.14366', 'title': 'Entropy-UID: A Method for Optimizing Information Density', 'authors': 'Xinpeng Shou', 'link': 'https://arxiv.org/abs/2502.14366', 'abstract': 'Balanced and efficient information flow is essential for optimizing language generation models. In this work, we propose Entropy-UID, a new token selection method that balances entropy and Uniform Information Density (UID) principles for enhanced efficiency of text generation. Our approach adaptively adjusts token selection by jointly minimizing entropy and surprisal, promoting more even information distribution across generated sequences. Theoretical validation demonstrates that Entropy-UID optimally reduces information spikes while maintaining fluency and coherence. The method has been evulated using information-theoretic metrics on multiple benchmark datasets, including WikiText-2, OpenWebText, and WMT. Experimental results show that Entropy-UID achieves lower surprisal and entropy variance compared to standard GPT-2 and alternative heuristics, leading to more balanced and human-like text generation. Our findings point towards the potential of leveraging information-theoretic constraints to refine token selection strategies in autoregressive language models.', 'abstract_zh': '平衡且高效的信道流是优化语言生成模型的关键。本文提出了一种新的标记选择方法Entropy-UID，该方法结合熵和均匀信息密度原则以提高文本生成效率。我们的方法通过联合最小化熵和 surprisal，自适应调整标记选择，促进生成序列中信息分布更加均衡。理论验证表明，Entropy-UID 最优地减少了信息尖峰现象，同时保持流畅性和连贯性。该方法在多个基准数据集（包括 WikiText-2、OpenWebText 和 WMT）上使用信息论指标进行评估，实验结果显示，对比标准的 GPT-2 和其他启发式方法，Entropy-UID 能实现更低的 surprisal 和熵方差，从而获得更加均衡和类似人类的文本生成。我们的研究结果指出了利用信息论约束来改进自回归语言模型中标记选择策略的潜力。', 'title_zh': '熵-UID：一种优化信息密度的方法'}
{'arxiv_id': 'arXiv:2502.14365', 'title': 'Is Q-learning an Ill-posed Problem?', 'authors': 'Philipp Wissmann, Daniel Hein, Steffen Udluft, Thomas Runkler', 'link': 'https://arxiv.org/abs/2502.14365', 'abstract': 'This paper investigates the instability of Q-learning in continuous environments, a challenge frequently encountered by practitioners. Traditionally, this instability is attributed to bootstrapping and regression model errors. Using a representative reinforcement learning benchmark, we systematically examine the effects of bootstrapping and model inaccuracies by incrementally eliminating these potential error sources. Our findings reveal that even in relatively simple benchmarks, the fundamental task of Q-learning - iteratively learning a Q-function from policy-specific target values - can be inherently ill-posed and prone to failure. These insights cast doubt on the reliability of Q-learning as a universal solution for reinforcement learning problems.', 'abstract_zh': '这篇论文探讨了连续环境中Q-learning的不稳定性，这是从业者经常遇到的一个挑战。传统上，这种不稳定性被认为是由于 bootstrapping 和回归模型误差导致的。通过一个代表性的强化学习基准，我们系统地消除了这些潜在的误差源，以研究它们的影响。我们的发现表明，即使在相对较简单的基准中，Q-learning 基本任务——从特定策略的目标值中迭代学习 Q 函数——可能是本就存在问题且容易失败的。这些见解对 Q-learning 作为强化学习问题通用解决方案的可靠性提出了质疑。', 'title_zh': 'Q-learning是一个病态问题吗？'}
{'arxiv_id': 'arXiv:2502.14334', 'title': 'Purest Quantum State Identification', 'authors': 'Yingqi Yu, Honglin Chen, Jun Wu, Wei Xie, Xiangyang Li', 'link': 'https://arxiv.org/abs/2502.14334', 'abstract': 'Precise identification of quantum states under noise constraints is essential for quantum information processing. In this study, we generalize the classical best arm identification problem to quantum domains, designing methods for identifying the purest one within $K$ unknown $n$-qubit quantum states using $N$ samples. %, with direct applications in quantum computation and quantum communication. We propose two distinct algorithms: (1) an algorithm employing incoherent measurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N H_1}{\\log(K) 2^n }\\right) \\right)$, and (2) an algorithm utilizing coherent measurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N H_2}{\\log(K) }\\right) \\right)$, highlighting the power of quantum memory. Furthermore, we establish a lower bound by proving that all strategies with fixed two-outcome incoherent POVM must suffer error probability exceeding $ \\exp\\left( - O\\left(\\frac{NH_1}{2^n}\\right)\\right)$. This framework provides concrete design principles for overcoming sampling bottlenecks in quantum technologies.', 'abstract_zh': '精确识别噪声约束下的量子态对于量子信息处理至关重要。本研究将经典的最优臂识别问题推广至量子域，设计了在给定N次样本的情况下，在未知的K个n量子比特量子态中识别纯度最高的算法。本文提出两种不同的算法：（1）采用非相干测量的算法，错误概率为$\\exp\\left(- \\Omega\\left(\\frac{N H_1}{\\log(K) 2^n }\\right) \\right)$；（2）采用相干测量的算法，错误概率为$\\exp\\left(- \\Omega\\left(\\frac{N H_2}{\\log(K) }\\right) \\right)$，突显了量子记忆的能力。此外，我们通过证明所有固定两结果非相干POVM策略必须遭受超过$\\exp\\left( - O\\left(\\frac{NH_1}{2^n}\\right)\\right)$的错误概率来建立一个下界。该框架为克服量子技术中的采样瓶颈提供了具体的設計原則。', 'title_zh': '纯度最优量子态识别'}
{'arxiv_id': 'arXiv:2502.14333', 'title': 'A Survey on Feedback-based Multi-step Reasoning for Large Language Models on Mathematics', 'authors': 'Ting-Ruen Wei, Haowei Liu, Xuyang Wu, Yi Fang', 'link': 'https://arxiv.org/abs/2502.14333', 'abstract': 'Recent progress in large language models (LLM) found chain-of-thought prompting strategies to improve the reasoning ability of LLMs by encouraging problem solving through multiple steps. Therefore, subsequent research aimed to integrate the multi-step reasoning process into the LLM itself through process rewards as feedback and achieved improvements over prompting strategies. Due to the cost of step-level annotation, some turn to outcome rewards as feedback. Aside from these training-based approaches, training-free techniques leverage frozen LLMs or external tools for feedback at each step to enhance the reasoning process. With the abundance of work in mathematics due to its logical nature, we present a survey of strategies utilizing feedback at the step and outcome levels to enhance multi-step math reasoning for LLMs. As multi-step reasoning emerges a crucial component in scaling LLMs, we hope to establish its foundation for easier understanding and empower further research.', 'abstract_zh': '最近大语言模型中基于链式推理的提示策略进展：通过多步过程提升推理能力并促进训练与无训练方法的发展', 'title_zh': '基于反馈的多步推理研究：大型语言模型在数学中的应用'}
{'arxiv_id': 'arXiv:2502.14318', 'title': 'Line Goes Up? Inherent Limitations of Benchmarks for Evaluating Large Language Models', 'authors': 'James Fodor', 'link': 'https://arxiv.org/abs/2502.14318', 'abstract': 'Large language models (LLMs) regularly demonstrate new and impressive performance on a wide range of language, knowledge, and reasoning benchmarks. Such rapid progress has led many commentators to argue that LLM general cognitive capabilities have likewise rapidly improved, with the implication that such models are becoming progressively more capable on various real-world tasks. Here I summarise theoretical and empirical considerations to challenge this narrative. I argue that inherent limitations with the benchmarking paradigm, along with specific limitations of existing benchmarks, render benchmark performance highly unsuitable as a metric for generalisable competence over cognitive tasks. I also contend that alternative methods for assessing LLM capabilities, including adversarial stimuli and interpretability techniques, have shown that LLMs do not have robust competence in many language and reasoning tasks, and often fail to learn representations which facilitate generalisable inferences. I conclude that benchmark performance should not be used as a reliable indicator of general LLM cognitive capabilities.', 'abstract_zh': '大语言模型（LLMs）在语言、知识和推理等多个基准上持续展现新的卓越性能。这种快速的进步使得许多评论家认为，LLMs 的通用认知能力也得到了快速提升，进而认为这些模型在各种实际任务上变得越来越有能力。在这里，我总结了一些理论和实证考虑，以挑战这种叙述。我认为，基准测试范式的固有限制，以及现有基准的具体限制，使得基准性能非常不适合用作认知任务上可泛化的 competence 的度量标准。我还主张，评估 LLM 能力的替代方法，包括对抗性刺激和可解释性技术，表明LLMs 在许多语言和推理任务上缺乏稳健的能力，并且往往无法学习出促进可泛化推理的表示。我得出结论，基准性能不宜用作可靠的大语言模型认知能力的指标。', 'title_zh': '线性增长？大型语言模型评估基准的固有限制。'}
{'arxiv_id': 'arXiv:2502.14316', 'title': 'Textured 3D Regenerative Morphing with 3D Diffusion Prior', 'authors': 'Songlin Yang, Yushi Lan, Honghua Chen, Xingang Pan', 'link': 'https://arxiv.org/abs/2502.14316', 'abstract': 'Textured 3D morphing creates smooth and plausible interpolation sequences between two 3D objects, focusing on transitions in both shape and texture. This is important for creative applications like visual effects in filmmaking. Previous methods rely on establishing point-to-point correspondences and determining smooth deformation trajectories, which inherently restrict them to shape-only morphing on untextured, topologically aligned datasets. This restriction leads to labor-intensive preprocessing and poor generalization. To overcome these challenges, we propose a method for 3D regenerative morphing using a 3D diffusion prior. Unlike previous methods that depend on explicit correspondences and deformations, our method eliminates the additional need for obtaining correspondence and uses the 3D diffusion prior to generate morphing. Specifically, we introduce a 3D diffusion model and interpolate the source and target information at three levels: initial noise, model parameters, and condition features. We then explore an Attention Fusion strategy to generate more smooth morphing sequences. To further improve the plausibility of semantic interpolation and the generated 3D surfaces, we propose two strategies: (a) Token Reordering, where we match approximate tokens based on semantic analysis to guide implicit correspondences in the denoising process of the diffusion model, and (b) Low-Frequency Enhancement, where we enhance low-frequency signals in the tokens to improve the quality of generated surfaces. Experimental results show that our method achieves superior smoothness and plausibility in 3D morphing across diverse cross-category object pairs, offering a novel regenerative method for 3D morphing with textured representations.', 'abstract_zh': '纹理化的3D形变创建了两个3D对象之间平滑且可信的插值序列，着重于形态和纹理的过渡。该方法对于电影制作中的视觉 effects 等创意应用非常重要。先前的方法依赖于建立点对点对应关系并确定平滑变形轨迹，这使它们本质上仅限于未纹理化且拓扑对齐的数据集上的形态形变。这种限制导致预处理工作量大且泛化能力差。为了克服这些挑战，我们提出了一种基于3D扩散先验的3D再生形变方法。与依赖明确对应关系和变形的方法不同，我们的方法消除了额外获取对应关系的需要，并利用3D扩散先验生成形变。具体而言，我们引入了一种3D扩散模型，并在初始噪声、模型参数和条件特征三个层级上插值源和目标信息。然后，我们探索了一种注意力融合策略以生成更平滑的形变序列。为了进一步提高语义插值和生成的3D表面的合理性，我们提出了两种策略：(a) Token 重新排序，在去噪过程中基于语义分析匹配近似标记以引导隐式对应关系；(b) 低频增强，在标记中增强低频信号以提高生成表面的质量。实验结果表明，我们的方法在多种类别间对象对的3D形变中实现了更优的平滑性和合理性，提供了一种用于具有纹理表示的3D形变的新型再生方法。', 'title_zh': '具有3D扩散先验的纹理化3D再生形变'}
{'arxiv_id': 'arXiv:2502.14302', 'title': 'MedHallu: A Comprehensive Benchmark for Detecting Medical Hallucinations in Large Language Models', 'authors': 'Shrey Pandit, Jiawei Xu, Junyuan Hong, Zhangyang Wang, Tianlong Chen, Kaidi Xu, Ying Ding', 'link': 'https://arxiv.org/abs/2502.14302', 'abstract': 'Advancements in Large Language Models (LLMs) and their increasing use in medical question-answering necessitate rigorous evaluation of their reliability. A critical challenge lies in hallucination, where models generate plausible yet factually incorrect outputs. In the medical domain, this poses serious risks to patient safety and clinical decision-making. To address this, we introduce MedHallu, the first benchmark specifically designed for medical hallucination detection. MedHallu comprises 10,000 high-quality question-answer pairs derived from PubMedQA, with hallucinated answers systematically generated through a controlled pipeline. Our experiments show that state-of-the-art LLMs, including GPT-4o, Llama-3.1, and the medically fine-tuned UltraMedical, struggle with this binary hallucination detection task, with the best model achieving an F1 score as low as 0.625 for detecting "hard" category hallucinations. Using bidirectional entailment clustering, we show that harder-to-detect hallucinations are semantically closer to ground truth. Through experiments, we also show incorporating domain-specific knowledge and introducing a "not sure" category as one of the answer categories improves the precision and F1 scores by up to 38% relative to baselines.', 'abstract_zh': '大语言模型（LLMs）的进步及其在医疗问答领域的日益广泛应用 necessitate 严格评估其可靠性。幻觉是关键挑战之一，模型会生成听起来合理但实际上错误的输出。在医疗领域，这会对患者安全和临床决策造成严重风险。为应对这一挑战，我们引入了MedHallu，这是首个专门设计用于医疗幻觉检测的标准。MedHallu 包含来自PubMedQA的 10,000 个高质量的问答对，并通过受控管道系统性地生成了幻觉答案。我们的实验表明，最先进的 LLMs，包括 GPT-4o、Llama-3.1 和医学微调的 UltraMedical，在这种二元幻觉检测任务上表现不佳，最好模型在检测“困难”类幻觉时的 F1 分数低至 0.625。通过双向推论聚类，我们发现难以检测的幻觉与其真实答案在语义上更接近。通过实验，我们还展示了结合领域特定知识并将“不确定”类别作为回答类别之一可以将精度和 F1 分数相对基线提高最多 38%。', 'title_zh': 'MedHallu: 大规模语言模型中医学幻觉检测的综合基准'}
{'arxiv_id': 'arXiv:2502.14301', 'title': 'SEA-HELM: Southeast Asian Holistic Evaluation of Language Models', 'authors': 'Yosephine Susanto, Adithya Venkatadri Hulagadri, Jann Railey Montalan, Jian Gang Ngui, Xian Bin Yong, Weiqi Leong, Hamsawardhini Rengarajan, Peerat Limkonchotiwat, Yifan Mai, William Chandra Tjhi', 'link': 'https://arxiv.org/abs/2502.14301', 'abstract': "With the rapid emergence of novel capabilities in Large Language Models (LLMs), the need for rigorous multilingual and multicultural benchmarks that are integrated has become more pronounced. Though existing LLM benchmarks are capable of evaluating specific capabilities of LLMs in English as well as in various mid- to low-resource languages, including those in the Southeast Asian (SEA) region, a comprehensive and authentic evaluation suite for the SEA languages has not been developed thus far. Here, we present SEA-HELM, a holistic linguistic and cultural LLM evaluation suite that emphasizes SEA languages, comprising five core pillars: (1) NLP Classics, (2) LLM-specifics, (3) SEA Linguistics, (4) SEA Culture, (5) Safety. SEA-HELM currently supports Filipino, Indonesian, Tamil, Thai, and Vietnamese. We also introduce the SEA-HELM leaderboard, which allows users to understand models' multilingual and multicultural performance in a systematic and user-friendly manner.", 'abstract_zh': '随着大型语言模型（LLMs）新型能力的迅速涌现，对于多语言和多文化的整合基准需求变得更加迫切。尽管现有的LLM基准能够评估LLMs在英语以及各种中低资源语言（包括东南亚地区语言）中的特定能力，但迄今为止尚未开发出全面且真实的东南亚语言评价套件。因此，我们提出了SEA-HELM，一个以东南亚语言为核心的综合语言和文化LLM评价套件，包含五大核心支柱：（1）NLP经典任务，（2）LLM专属性，（3）东南亚语言学，（4）东南亚文化，（5）安全。SEA-HELM目前支持菲律宾语、印尼语、泰米尔语、泰语和越南语。我们还引入了SEA-HELM排行榜，以帮助用户以系统且用户友好的方式理解模型在多语言和多文化方面的表现。', 'title_zh': 'SEA-HELM: 东南亚综合语言模型评估'}
{'arxiv_id': 'arXiv:2502.14297', 'title': "An Evaluation of Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial General Research Intelligence' (AGRI)?", 'authors': 'Joeran Beel, Min-Yen Kan, Moritz Baumgart', 'link': 'https://arxiv.org/abs/2502.14297', 'abstract': "A major step toward Artificial General Intelligence (AGI) and Super Intelligence is AI's ability to autonomously conduct research - what we term Artificial General Research Intelligence (AGRI). If machines could generate hypotheses, conduct experiments, and write research papers without human intervention, it would transform science. Recently, this http URL introduced the AI Scientist, a system claiming to automate the research lifecycle, generating both excitement and skepticism.\nWe evaluated the AI Scientist and found it a milestone in AI-driven research. While it streamlines some aspects, it falls short of expectations. Literature reviews are weak, nearly half the experiments failed, and manuscripts sometimes contain hallucinated results. Most notably, users must provide an experimental pipeline, limiting the AI Scientist's autonomy in research design and execution.\nDespite its limitations, the AI Scientist advances research automation. Many reviewers or instructors who assess work superficially may not recognize its output as AI-generated. The system produces research papers with minimal human effort and low cost. Our analysis suggests a paper costs a few USD with a few hours of human involvement, making it significantly faster than human researchers. Compared to AI capabilities from a few years ago, this marks progress toward AGRI.\nThe rise of AI-driven research systems requires urgent discussion within Information Retrieval (IR) and broader scientific communities. Enhancing literature retrieval, citation validation, and evaluation benchmarks could improve AI-generated research reliability. We propose concrete steps, including AGRI-specific benchmarks, refined peer review, and standardized attribution frameworks. Whether AGRI becomes a stepping stone to AGI depends on how the academic and AI communities shape its development.", 'abstract_zh': '向着人工通用智能（AGI）和超人工智能迈出的重要一步：自主开展研究的人工智能——人工通用研究智能（AGRI）的发展。人工智能科学家系统：自动化研究生命周期的里程碑，但仍有局限性。信息检索（IR）和更广泛科学社区关于由AI驱动的研究系统的讨论需求迫切。', 'title_zh': 'Sakana的AI科学家自主研究评估：是期望之谈还是通向“通用人工智能研究”（AGRI）新兴现实的途径？'}
{'arxiv_id': 'arXiv:2502.14293', 'title': 'Graph Anomaly Detection via Adaptive Test-time Representation Learning across Out-of-Distribution Domains', 'authors': 'Delaram Pirhayati, Arlei Silva', 'link': 'https://arxiv.org/abs/2502.14293', 'abstract': 'Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present AdaGraph-T3, a novel test-time training framework for cross-domain GAD. AdaGraph-T3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that AdaGraph-T3 significantly outperforms existing approaches, achieving average improvements of over 6.6% in AUROC and 7.9% in AUPRC compared to the best competing model.', 'abstract_zh': '跨领域图异常检测的适配图框架AdaGraph-T3', 'title_zh': '跨分布外领域自适应测试时代表征学习的图异常检测'}
{'arxiv_id': 'arXiv:2502.14281', 'title': 'Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts', 'authors': 'Weipeng Huang, Qin Li, Yang Xiao, Cheng Qiao, Tie Cai, Junwei Liao, Neil J. Hurley, Guangyuan Piao', 'link': 'https://arxiv.org/abs/2502.14281', 'abstract': 'Noise in data appears to be inevitable in most real-world machine learning applications and would cause severe overfitting problems. Not only can data features contain noise, but labels are also prone to be noisy due to human input. In this paper, rather than noisy label learning in multiclass classifications, we instead focus on the less explored area of noisy label learning for multilabel classifications. Specifically, we investigate the post-correction of predictions generated from classifiers learned with noisy labels. The reasons are two-fold. Firstly, this approach can directly work with the trained models to save computational resources. Secondly, it could be applied on top of other noisy label correction techniques to achieve further improvements. To handle this problem, we appeal to deep generative approaches that are possible for uncertainty estimation. Our model posits that label noise arises from a stochastic shift in the latent variable, providing a more robust and beneficial means for noisy learning. We develop both unsupervised and semi-supervised learning methods for our model. The extensive empirical study presents solid evidence to that our approach is able to consistently improve the independent models and performs better than a number of existing methods across various noisy label settings. Moreover, a comprehensive empirical analysis of the proposed method is carried out to validate its robustness, including sensitivity analysis and an ablation study, among other elements.', 'abstract_zh': '数据中噪声的不可避免性及其对多标签分类中嘈杂标签学习的影响：一种后预测修正的方法', 'title_zh': '修正嘈杂的多标签预测：通过潜在空间位移建模标签噪声'}
{'arxiv_id': 'arXiv:2502.14280', 'title': 'EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts', 'authors': 'Subhajit Chaudhury, Payel Das, Sarathkrishna Swaminathan, Georgios Kollias, Elliot Nelson, Khushbu Pahwa, Tejaswini Pedapati, Igor Melnyk, Matthew Riemer', 'link': 'https://arxiv.org/abs/2502.14280', 'abstract': "Recent advances in Large Language Models (LLMs) have yielded impressive successes on many language tasks. However, efficient processing of long contexts using LLMs remains a significant challenge. We introduce \\textbf{EpMAN} -- a method for processing long contexts in an \\textit{episodic memory} module while \\textit{holistically attending to} semantically relevant context chunks. The output of \\textit{episodic attention} is then used to reweigh the decoder's self-attention to the stored KV cache of the context during training and generation. When an LLM decoder is trained using \\textbf{EpMAN}, its performance on multiple challenging single-hop long-context recall and question-answering benchmarks is found to be stronger and more robust across the range from 16k to 256k tokens than baseline decoders trained with self-attention, and popular retrieval-augmented generation frameworks.", 'abstract_zh': 'Recent Advances in Large Language Models (LLMs): Efficient Processing of Long Contexts with EpMAN', 'title_zh': 'EpMAN: 基于情景记忆注意力的长期上下文泛化'}
{'arxiv_id': 'arXiv:2502.14276', 'title': 'STeCa: Step-level Trajectory Calibration for LLM Agent Learning', 'authors': 'Hanlin Wang, Jian Wang, Chak Tou Leong, Wenjie Li', 'link': 'https://arxiv.org/abs/2502.14276', 'abstract': 'Large language model (LLM)-based agents have shown promise in tackling complex tasks by interacting dynamically with the environment. Existing work primarily focuses on behavior cloning from expert demonstrations and preference learning through exploratory trajectory sampling. However, these methods often struggle in long-horizon tasks, where suboptimal actions accumulate step by step, causing agents to deviate from correct task trajectories. To address this, we highlight the importance of timely calibration and the need to automatically construct calibration trajectories for training agents. We propose Step-Level Trajectory Calibration (STeCa), a novel framework for LLM agent learning. Specifically, STeCa identifies suboptimal actions through a step-level reward comparison during exploration. It constructs calibrated trajectories using LLM-driven reflection, enabling agents to learn from improved decision-making processes. These calibrated trajectories, together with successful trajectory data, are utilized for reinforced training. Extensive experiments demonstrate that STeCa significantly outperforms existing methods. Further analysis highlights that step-level calibration enables agents to complete tasks with greater robustness. Our code and data are available at this https URL.', 'abstract_zh': '基于大型语言模型的代理在解决复杂任务方面通过与环境动态交互展现出了潜力。现有工作主要集中在从专家示范行为克隆和通过探索性轨迹采样进行偏好学习上。然而，在长期任务中，这些方法往往难以应对，因为次优动作会逐步积累，导致代理偏离正确的任务轨迹。为解决这一问题，我们强调了及时校准的重要性，并提出了自动构建校准轨迹的需求。我们提出了一种新型的基于大型语言模型的代理学习框架——步骤级轨迹校准（STeCa）。具体而言，STeCa 通过在探索过程中进行步骤级奖励比较来识别次优动作，并利用大型语言模型驱动的反思构建校准轨迹，使代理能够从改进的决策过程中学习。这些校准轨迹与成功的轨迹数据一起用于强化训练。大量实验显示，STeCa 显著优于现有方法。进一步分析表明，步骤级校准使代理能够以更大的鲁棒性完成任务。我们的代码和数据可供查看：this https URL。', 'title_zh': 'STeCa: 步骤级轨迹校准用于LLM代理学习'}
{'arxiv_id': 'arXiv:2502.14273', 'title': 'LLM-EvRep: Learning an LLM-Compatible Event Representation Using a Self-Supervised Framework', 'authors': 'Zongyou Yu, Qiang Qu, Qian Zhang, Nan Zhang, Xiaoming Chen', 'link': 'https://arxiv.org/abs/2502.14273', 'abstract': 'Recent advancements in event-based recognition have demonstrated significant promise, yet most existing approaches rely on extensive training, limiting their adaptability for efficient processing of event-driven visual content. Meanwhile, large language models (LLMs) have exhibited remarkable zero-shot capabilities across diverse domains, but their application to event-based visual recognition remains largely unexplored. To bridge this gap, we propose \\textbf{LLM-EvGen}, an event representation generator that produces LLM-compatible event representations \\textbf{LLM-EvRep}, thereby enhancing the performance of LLMs on event recognition tasks. The generator is trained using a self-supervised framework, aligning the generated representations with semantic consistency and structural fidelity. Comprehensive experiments were conducted on three datasets: N-ImageNet, N-Caltech101, and N-MNIST. The results demonstrate that our method, \\textbf{LLM-EvRep}, outperforms the event-to-video method, E2VID, by 15.93\\%, 0.82\\%, and 50.21\\%, respectively, in recognition tasks when evaluated using GPT-4o.', 'abstract_zh': 'Recent advancements in event-based recognition have demonstrated significant promise, yet most existing approaches rely on extensive training, limiting their adaptability for efficient processing of event-driven visual content. Meanwhile, large language models (LLMs) have exhibited remarkable zero-shot capabilities across diverse domains, but their application to event-based visual recognition remains largely unexplored. To bridge this gap, we propose LLM-EvGen, an event representation generator that produces LLM-compatible event representations LLM-EvRep, thereby enhancing the performance of LLMs on event recognition tasks.', 'title_zh': 'LLM-EvRep: 学习一种适合LLM的事件表示-using一种自监督框架'}
{'arxiv_id': 'arXiv:2502.14272', 'title': 'Capturing Nuanced Preferences: Preference-Aligned Distillation for Small Language Models', 'authors': 'Yanggan Gu, Junzhuo Li, Sirui Huang, Xin Zou, Zhenghua Li, Xuming Hu', 'link': 'https://arxiv.org/abs/2502.14272', 'abstract': "Aligning small language models (SLMs) with human values typically involves distilling preference knowledge from large language models (LLMs). However, existing distillation methods model preference knowledge in teacher LLMs by comparing pairwise responses, overlooking the extent of difference between responses. This limitation hinders student SLMs from capturing the nuanced preferences for multiple responses. In this paper, we propose a Preference-Aligned Distillation (PAD) framework, which models teacher's preference knowledge as a probability distribution over all potential preferences, thereby providing more nuanced supervisory signals. Our insight in developing PAD is rooted in the demonstration that language models can serve as reward functions, reflecting their intrinsic preferences. Based on this, PAD comprises three key steps: (1) sampling diverse responses using high-temperature; (2) computing rewards for both teacher and student to construct their intrinsic preference; and (3) training the student's intrinsic preference distribution to align with the teacher's. Experiments on four mainstream alignment benchmarks demonstrate that PAD consistently and significantly outperforms existing approaches, achieving over 20\\% improvement on AlpacaEval 2 and Arena-Hard, indicating superior alignment with human preferences. Notably, on MT-Bench, using the \\textsc{Gemma} model family, the student trained by PAD surpasses its teacher, further validating the effectiveness of our PAD.", 'abstract_zh': '将小型语言模型与人类价值观对齐通常涉及从大型语言模型中提取偏好知识。然而，现有的蒸馏方法通过比较成对的回答来建模教师大型语言模型中的偏好知识，忽略了回答之间的差异程度。这一限制阻碍了学生小型语言模型捕捉多个回答的微妙偏好。在本文中，我们提出了一种偏好对齐蒸馏（PAD）框架，将教师的偏好知识建模为所有潜在偏好的一种概率分布，从而提供更细致的监督信号。我们开发PAD的见解根植于语言模型可以作为奖励函数运行的事实，反映了它们固有的偏好。基于此，PAD包含三个关键步骤：（1）使用高温度采样多样化的回答；（2）为教师和学生计算奖励以构建其固有偏好；（3）训练学生的固有偏好分布以与教师对齐。在四个主流对齐基准上的实验表明，PAD在AlpacaEval 2和Arena-Hard上的一致且显著地优于现有方法，表明其与人类偏好对齐的优越性。值得注意的是，在MT-Bench上，使用Gemma模型家族训练的学生超过了其教师，进一步验证了PAD的有效性。', 'title_zh': '捕捉细微偏好：面向偏好的蒸馏方法用于小型语言模型'}
{'arxiv_id': 'arXiv:2502.14268', 'title': 'MCQA-Eval: Efficient Confidence Evaluation in NLG with Gold-Standard Correctness Labels', 'authors': 'Xiaoou Liu, Zhen Lin, Longchao Da, Chacha Chen, Shubhendu Trivedi, Hua Wei', 'link': 'https://arxiv.org/abs/2502.14268', 'abstract': 'Large Language Models (LLMs) require robust confidence estimation, particularly in critical domains like healthcare and law where unreliable outputs can lead to significant consequences. Despite much recent work in confidence estimation, current evaluation frameworks rely on correctness functions -- various heuristics that are often noisy, expensive, and possibly introduce systematic biases. These methodological weaknesses tend to distort evaluation metrics and thus the comparative ranking of confidence measures. We introduce MCQA-Eval, an evaluation framework for assessing confidence measures in Natural Language Generation (NLG) that eliminates dependence on an explicit correctness function by leveraging gold-standard correctness labels from multiple-choice datasets. MCQA-Eval enables systematic comparison of both internal state-based white-box (e.g. logit-based) and consistency-based black-box confidence measures, providing a unified evaluation methodology across different approaches. Through extensive experiments on multiple LLMs and widely used QA datasets, we report that MCQA-Eval provides efficient and more reliable assessments of confidence estimation methods than existing approaches.', 'abstract_zh': '大型语言模型（LLMs）需要稳健的置信度估计，尤其是在医疗和法律等关键领域，不稳定的输出可能导致严重后果。尽管在置信度估计方面已经开展了大量研究工作，但现有的评估框架仍然依赖于各种噪声较大、成本昂贵且可能引入系统性偏差的正确性函数。这些方法论上的缺陷往往会扭曲评价指标，从而影响置信度度量的比较排名。我们提出了一种MCQA-Eval评估框架，用于评估自然语言生成（NLG）中的置信度度量，该框架通过利用多选项数据集的金标准正确性标签而无需依赖显式的正确性函数。MCQA-Eval能够系统地比较基于内部状态的白盒度量（例如，logit基度量）和基于一致性的黑盒度量，提供了不同方法之间的统一评估方法。通过在多个大型语言模型和广泛使用的问答数据集上进行大量实验，我们发现MCQA-Eval相比现有方法提供更高效且更可靠的置信度估计方法评估。', 'title_zh': 'MCQA-Eval: 高效评估自然语言生成中的置信度与标准正确性标签'}
{'arxiv_id': 'arXiv:2502.14260', 'title': 'EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement', 'authors': 'Wenhui Zhu, Xuanzhao Dong, Xin Li, Yujian Xiong, Xiwen Chen, Peijie Qiu, Vamsi Krishna Vasa, Zhangsihao Yang, Yi Su, Oana Dumitrascu, Yalin Wang', 'link': 'https://arxiv.org/abs/2502.14260', 'abstract': 'Over the past decade, generative models have achieved significant success in enhancement fundus this http URL, the evaluation of these models still presents a considerable challenge. A comprehensive evaluation benchmark for fundus image enhancement is indispensable for three main reasons: 1) The existing denoising metrics (e.g., PSNR, SSIM) are hardly to extend to downstream real-world clinical research (e.g., Vessel morphology consistency). 2) There is a lack of comprehensive evaluation for both paired and unpaired enhancement methods, along with the need for expert protocols to accurately assess clinical value. 3) An ideal evaluation system should provide insights to inform future developments of fundus image enhancement. To this end, we propose a novel comprehensive benchmark, EyeBench, to provide insights that align enhancement models with clinical needs, offering a foundation for future work to improve the clinical relevance and applicability of generative models for fundus image enhancement. EyeBench has three appealing properties: 1) multi-dimensional clinical alignment downstream evaluation: In addition to evaluating the enhancement task, we provide several clinically significant downstream tasks for fundus images, including vessel segmentation, DR grading, denoising generalization, and lesion segmentation. 2) Medical expert-guided evaluation design: We introduce a novel dataset that promote comprehensive and fair comparisons between paired and unpaired methods and includes a manual evaluation protocol by medical experts. 3) Valuable insights: Our benchmark study provides a comprehensive and rigorous evaluation of existing methods across different downstream tasks, assisting medical experts in making informed choices. Additionally, we offer further analysis of the challenges faced by existing methods. The code is available at \\url{this https URL}', 'abstract_zh': '过去十年，生成模型在视网膜图像增强方面取得了显著成功，但这些模型的评估仍然面临着重大挑战。为了满足三大主要需求，一个全面的视网膜图像增强评估基准不可或缺：1) 当前去噪指标（如PSNR、SSIM）难以扩展到下游实际临床研究（如血管形态一致性）。2) 缺乏对配对和非配对增强方法的全面评估，以及需要专家协议来准确评估临床价值。3) 理想的评估系统应为视网膜图像增强的未来发展提供有价值的信息。为此，我们提出了一种新的全面基准——EyeBench，以期将增强模型与临床需求相结合，为未来工作提供基础，以提高生成模型在视网膜图像增强方面的临床相关性和适用性。EyeBench具有三种吸引人的特性：1) 下游多维度临床对齐评估：除了评估增强任务外，我们还提供了几个临床重要的下游任务，包括血管分割、DR分级、去噪泛化和病变分割。2) 医学专家引导的评估设计：我们引入了一个促进配对和非配对方法之间全面公平比较的新数据集，并包括了一种由医学专家手动评估的协议。3) 有价值的信息：我们的基准研究提供了不同下游任务下对现有方法的全面和严格的评估，帮助医学专家做出知情选择。此外，我们还进一步分析了现有方法面临的挑战。相关代码可在[该链接]获得。', 'title_zh': 'EyeBench: 呼唤更严格的视网膜图像增强评估'}
{'arxiv_id': 'arXiv:2502.14258', 'title': 'Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information', 'authors': 'Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang', 'link': 'https://arxiv.org/abs/2502.14258', 'abstract': 'While the ability of language models to elicit facts has been widely investigated, how they handle temporally changing facts remains underexplored. We discover Temporal Heads, specific attention heads primarily responsible for processing temporal knowledge through circuit analysis. We confirm that these heads are present across multiple models, though their specific locations may vary, and their responses differ depending on the type of knowledge and its corresponding years. Disabling these heads degrades the model\'s ability to recall time-specific knowledge while maintaining its general capabilities without compromising time-invariant and question-answering performances. Moreover, the heads are activated not only numeric conditions ("In 2004") but also textual aliases ("In the year ..."), indicating that they encode a temporal dimension beyond simple numerical representation. Furthermore, we expand the potential of our findings by demonstrating how temporal knowledge can be edited by adjusting the values of these heads.', 'abstract_zh': '语言模型处理时间变化事实的能力虽已广泛研究，但时间头的发现及其在处理时间知识中的作用尚待探索。我们通过电路分析发现了时间头，这些特定的注意力头主要负责处理时间知识。我们确认这些头在多个模型中普遍存在，但它们的具体位置可能有所不同，且对不同类型的知识及其对应年份的响应也不同。禁用这些头会降低模型回忆时间特定知识的能力，同时保持其一般能力而不影响时间不变的表现和问答性能。此外，这些头不仅对数值条件（“在2004年”）作出反应，还对文本别名（“在……年”）作出反应，表明它们编码了超越简单数值表示的时间维度。进一步地，我们展示了如何通过调整这些头的值来编辑时间知识的潜在应用。', 'title_zh': '时间有其位置吗？时间头：语言模型回忆时间特定信息'}
{'arxiv_id': 'arXiv:2502.14255', 'title': 'Effects of Prompt Length on Domain-specific Tasks for Large Language Models', 'authors': 'Qibang Liu, Wenzhe Wang, Jeffrey Willard', 'link': 'https://arxiv.org/abs/2502.14255', 'abstract': "In recent years, Large Language Models have garnered significant attention for their strong performance in various natural language tasks, such as machine translation and question answering. These models demonstrate an impressive ability to generalize across diverse tasks. However, their effectiveness in tackling domain-specific tasks, such as financial sentiment analysis and monetary policy understanding, remains a topic of debate, as these tasks often require specialized knowledge and precise reasoning. To address such challenges, researchers design various prompts to unlock the models' abilities. By carefully crafting input prompts, researchers can guide these models to produce more accurate responses. Consequently, prompt engineering has become a key focus of study. Despite the advancements in both models and prompt engineering, the relationship between the two-specifically, how prompt design impacts models' ability to perform domain-specific tasks-remains underexplored. This paper aims to bridge this research gap.", 'abstract_zh': '近年来，大规模语言模型因其在机器翻译、问答等各类自然语言任务中的出色表现而受到广泛关注。这些模型展现了跨任务泛化的 impressive 能力。然而，它们在处理如金融情感分析和货币政策理解等特定领域任务时的有效性仍存争议，因为这些任务往往需要专门的知识和精确的推理。为了应对这些挑战，研究人员设计了各种提示来激发模型的能力。通过精心设计输入提示，研究人员可以引导这些模型产生更准确的响应。因此，提示工程已经成为一个关键的研究焦点。尽管在模型和提示工程方面取得了进展，但两者之间的关系——尤其是提示设计如何影响模型在特定领域任务上的表现——仍然未得到充分探索。本文旨在填补这一研究空白。', 'title_zh': '大型语言模型在专业领域任务中提示长度的影响'}
{'arxiv_id': 'arXiv:2502.14254', 'title': 'Mem2Ego: Empowering Vision-Language Models with Global-to-Ego Memory for Long-Horizon Embodied Navigation', 'authors': 'Lingfeng Zhang, Yuecheng Liu, Zhanguang Zhang, Matin Aghaei, Yaochen Hu, Hongjian Gu, Mohammad Ali Alomrani, David Gamaliel Arcos Bravo, Raika Karimi, Atia Hamidizadeh, Haoping Xu, Guowei Huang, Zhanpeng Zhang, Tongtong Cao, Weichao Qiu, Xingyue Quan, Jianye Hao, Yuzheng Zhuang, Yingxue Zhang', 'link': 'https://arxiv.org/abs/2502.14254', 'abstract': "Recent advancements in Large Language Models (LLMs) and Vision-Language Models (VLMs) have made them powerful tools in embodied navigation, enabling agents to leverage commonsense and spatial reasoning for efficient exploration in unfamiliar environments. Existing LLM-based approaches convert global memory, such as semantic or topological maps, into language descriptions to guide navigation. While this improves efficiency and reduces redundant exploration, the loss of geometric information in language-based representations hinders spatial reasoning, especially in intricate environments. To address this, VLM-based approaches directly process ego-centric visual inputs to select optimal directions for exploration. However, relying solely on a first-person perspective makes navigation a partially observed decision-making problem, leading to suboptimal decisions in complex environments. In this paper, we present a novel vision-language model (VLM)-based navigation framework that addresses these challenges by adaptively retrieving task-relevant cues from a global memory module and integrating them with the agent's egocentric observations. By dynamically aligning global contextual information with local perception, our approach enhances spatial reasoning and decision-making in long-horizon tasks. Experimental results demonstrate that the proposed method surpasses previous state-of-the-art approaches in object navigation tasks, providing a more effective and scalable solution for embodied navigation.", 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）和视觉-语言模型（VLMs）使其成为有代理能力导航的强大工具，使代理能够利用常识和空间推理在陌生环境中进行高效的探索。现有的基于LLM的方法将全局记忆，如语义或拓扑地图，转换为语言描述以指导导航。虽然这提高了效率并减少了冗余探索，但基于语言的表示形式中几何信息的损失阻碍了空间推理，特别是在复杂的环境中。为了解决这个问题，基于VLM的方法直接处理自中心视觉输入，以选择最佳的探索方向。然而，仅依赖第一人称视角使得导航成为一个部分可观测的决策问题，在复杂环境中导致次优决策。在本文中，我们提出了一种新的基于VLM的导航框架，通过适应性地从全局记忆模块中检索与任务相关的线索，并将其与代理的自中心观察相结合，以解决这些挑战。通过动态对齐全局上下文信息与局部感知，我们的方法增强了长时间任务中的空间推理和决策。实验结果表明，所提出的方法在物体导航任务中超越了先前的最佳方法，为有代理能力的导航提供了更有效和可扩展的解决方案。', 'title_zh': 'Mem2Ego: 为长时_horizon 体态导航增强视觉-语言模型的全局到 ego 内存能力'}
{'arxiv_id': 'arXiv:2502.14247', 'title': 'Pandora3D: A Comprehensive Framework for High-Quality 3D Shape and Texture Generation', 'authors': 'Jiayu Yang, Taizhang Shang, Weixuan Sun, Xibin Song, Ziang Chen, Senbo Wang, Shenzhou Chen, Weizhe Liu, Hongdong Li, Pan Ji', 'link': 'https://arxiv.org/abs/2502.14247', 'abstract': 'This report presents a comprehensive framework for generating high-quality 3D shapes and textures from diverse input prompts, including single images, multi-view images, and text descriptions. The framework consists of 3D shape generation and texture generation. (1). The 3D shape generation pipeline employs a Variational Autoencoder (VAE) to encode implicit 3D geometries into a latent space and a diffusion network to generate latents conditioned on input prompts, with modifications to enhance model capacity. An alternative Artist-Created Mesh (AM) generation approach is also explored, yielding promising results for simpler geometries. (2). Texture generation involves a multi-stage process starting with frontal images generation followed by multi-view images generation, RGB-to-PBR texture conversion, and high-resolution multi-view texture refinement. A consistency scheduler is plugged into every stage, to enforce pixel-wise consistency among multi-view textures during inference, ensuring seamless integration.\nThe pipeline demonstrates effective handling of diverse input formats, leveraging advanced neural architectures and novel methodologies to produce high-quality 3D content. This report details the system architecture, experimental results, and potential future directions to improve and expand the framework. The source code and pretrained weights are released at: \\url{this https URL}.', 'abstract_zh': '本报告提出了一种综合框架，用于从单张图像、多视角图像和文本描述等多种输入提示中生成高质量的3D形状和纹理。该框架包括3D形状生成和纹理生成。(1) 3D形状生成管道采用变分自编码器(VAE)将隐式3D几何编码到潜在空间，并使用扩散网络根据输入提示生成条件化潜在变量，同时进行了改进以增强模型容量。还探索了艺术家创建的网格(AM)生成方法，对简单几何形状产生了令人鼓舞的结果。(2) 纹理生成涉及多阶段过程，包括从正面图像生成开始， followed by 多视角图像生成、RGB到PBR纹理转换，以及高分辨率多视角纹理细化。每个阶段插入一致性调度器，以在推断过程中确保多视角纹理之间的像素级一致性，从而实现平滑的整合。该管道有效地处理了多种输入格式，利用先进的神经架构和新颖的方法论生成高质量的3D内容。本报告详细介绍了系统架构、实验结果及框架改进和扩展的潜在方向。源代码和预训练权重可在以下链接获取：\\url{this https URL}。', 'title_zh': 'Pandora3D：高质量3D形状和纹理生成的综合框架'}
{'arxiv_id': 'arXiv:2502.14235', 'title': 'OG-Gaussian: Occupancy Based Street Gaussians for Autonomous Driving', 'authors': 'Yedong Shen, Xinran Zhang, Yifan Duan, Shiqi Zhang, Heng Li, Yilong Wu, Jianmin Ji, Yanyong Zhang', 'link': 'https://arxiv.org/abs/2502.14235', 'abstract': 'Accurate and realistic 3D scene reconstruction enables the lifelike creation of autonomous driving simulation environments. With advancements in 3D Gaussian Splatting (3DGS), previous studies have applied it to reconstruct complex dynamic driving scenes. These methods typically require expensive LiDAR sensors and pre-annotated datasets of dynamic objects. To address these challenges, we propose OG-Gaussian, a novel approach that replaces LiDAR point clouds with Occupancy Grids (OGs) generated from surround-view camera images using Occupancy Prediction Network (ONet). Our method leverages the semantic information in OGs to separate dynamic vehicles from static street background, converting these grids into two distinct sets of initial point clouds for reconstructing both static and dynamic objects. Additionally, we estimate the trajectories and poses of dynamic objects through a learning-based approach, eliminating the need for complex manual annotations. Experiments on Waymo Open dataset demonstrate that OG-Gaussian is on par with the current state-of-the-art in terms of reconstruction quality and rendering speed, achieving an average PSNR of 35.13 and a rendering speed of 143 FPS, while significantly reducing computational costs and economic overhead.', 'abstract_zh': '准确且逼真的3D场景重建使自主驾驶仿真环境的栩栩如生创建成为可能。借助3D高斯点绘制技术的发展，先前的研究将其应用于重建复杂的动态驾驶场景。这些方法通常需要昂贵的激光雷达传感器和动态对象的预先标注数据集。为应对这些挑战，我们提出OG-Gaussian这一新型方法，该方法用Occupancy Grids（占用格网）替换激光雷达点云，占用格网通过Occupancy Prediction Network（占用预测网络）从环视相机图像中生成。我们的方法利用占用格网中的语义信息将动态车辆与静态街道背景区分开来，将这些格网转换为两个独立的初始点云集，用于重建静态和动态对象。此外，我们通过基于学习的方法估计动态对象的轨迹和姿态，从而消除复杂的手动标注需求。在Waymo Open数据集上的实验表明，OG-Gaussian在重建质量和渲染速度方面与当前最先进的技术相当，平均PSNR为35.13，渲染速率为143 FPS，同时显著降低计算成本和经济开销。', 'title_zh': 'OG-Gaussian: 基于 occupancy 的街道高斯模型在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2502.14227', 'title': 'SleepGMUformer: A gated multimodal temporal neural network for sleep staging', 'authors': 'Chenjun Zhao, Xuesen Niu, Xinglin Yu, Long Chen, Na Lv, Huiyu Zhou, Aite Zhao', 'link': 'https://arxiv.org/abs/2502.14227', 'abstract': 'Sleep staging is a key method for assessing sleep quality and diagnosing sleep disorders. However, current deep learning methods face challenges: 1) postfusion techniques ignore the varying contributions of different modalities; 2) unprocessed sleep data can interfere with frequency-domain information. To tackle these issues, this paper proposes a gated multimodal temporal neural network for multidomain sleep data, including heart rate, motion, steps, EEG (Fpz-Cz, Pz-Oz), and EOG from WristHR-Motion-Sleep and SleepEDF-78. The model integrates: 1) a pre-processing module for feature alignment, missing value handling, and EEG de-trending; 2) a feature extraction module for complex sleep features in the time dimension; and 3) a dynamic fusion module for real-time modality this http URL show classification accuracies of 85.03% on SleepEDF-78 and 94.54% on WristHR-Motion-Sleep datasets. The model handles heterogeneous datasets and outperforms state-of-the-art models by 1.00%-4.00%.', 'abstract_zh': '睡眠阶段划分是评估睡眠质量和诊断睡眠障碍的关键方法。然而，当前的深度学习方法面临着挑战：1) 后融合技术忽略了不同模态的 varying contributions；2) 未经处理的睡眠数据会干扰频率域信息。为解决这些问题，本文提出了一种门控多模态时间神经网络，适用于包括心率、运动、步数、EEG（Fpz-Cz, Pz-Oz）和EOG在内的多域睡眠数据，来自WristHR-Motion-Sleep和SleepEDF-78数据集。该模型集成了：1) 一个预处理模块进行特征对齐、缺失值处理和EEG去趋势；2) 一个特征提取模块在时间维度提取复杂睡眠特征；3) 一个动态融合模块进行实时模态融合。实验结果表明，该模型在SleepEDF-78数据集上的分类准确率达到了85.03%，在WristHR-Motion-Sleep数据集上的分类准确率达到了94.54%，能够处理异构数据集，并优于现有最佳模型1.00%-4.00%。', 'title_zh': '睡眠GMUformer：一种门控多模态 temporal 神经网络模型用于睡眠分期'}
{'arxiv_id': 'arXiv:2502.14222', 'title': 'Enhancing Pavement Sensor Data Acquisition for AI-Driven Transportation Research', 'authors': 'Manish Kumar Krishne Gowda, Andrew Balmos, Shin Boonam, James V. Krogmeier', 'link': 'https://arxiv.org/abs/2502.14222', 'abstract': "Effective strategies for sensor data management are essential for advancing transportation research, especially in the current data-driven era, due to the advent of novel applications in artificial intelligence. This paper presents comprehensive guidelines for managing transportation sensor data, encompassing both archived static data and real-time data streams. The real-time system architecture integrates various applications with data acquisition systems (DAQ). By deploying the in-house designed, open-source Avena software platform alongside the NATS messaging system as a secure communication broker, reliable data exchange is ensured. While robust databases like TimescaleDB facilitate organized storage, visualization platforms like Grafana provide real-time monitoring capabilities.\nIn contrast, static data standards address the challenges in handling unstructured, voluminous datasets. The standards advocate for a combination of cost-effective bulk cloud storage for unprocessed sensor data and relational databases for recording summarized analyses. They highlight the role of cloud data transfer tools like FME for efficient migration of sensor data from local storages onto the cloud. Further, integration of robust visualization tools into the framework helps in deriving patterns and trends from these complex datasets.\nThe proposals were applied to INDOT's real-world case studies involving the I-65 and I-69 Greenfield districts. For real-time data collection, Campbell Scientific DAQ systems were used, enabling continuous generation and monitoring of sensor metrics. In the case of the archived I-69 database, summary data was compiled in Oracle, while the unprocessed data was stored in SharePoint. The results underline the effectiveness of the proposed guidelines and motivate their adoption in research projects.", 'abstract_zh': '有效的传感器数据管理策略对于推动交通运输研究至关重要，尤其是在当前以数据驱动的时代，由于新兴的人工智能应用的出现。本文提出了全面的交通运输传感器数据管理指南，涵盖归档的静态数据和实时数据流。实时系统架构将各种应用与数据采集系统（DAQ）集成。通过部署自主研发的开源Avena软件平台和NATS消息系统作为安全通信代理，确保可靠的数据交换。强大的时序数据库（如TimescaleDB）有助于有序存储，而可视化平台（如Grafana）提供了实时监控能力。\n相比之下，静态数据标准解决了处理非结构化、大量数据集的挑战。这些标准提倡结合成本效益高的大规模云存储未处理传感器数据和关系数据库来记录汇总分析。它们强调了使用像FME这样的云数据传输工具，以高效地将传感器数据从本地存储迁移到云端的作用。此外，将强大的可视化工具整合到框架中，有助于从这些复杂数据集中提取模式和趋势。\n提出的建议应用于INDOT的实际案例研究，涉及I-65和I-69 Greenfield地区。对于实时数据采集，使用了Campbell Scientific DAQ系统，实现了传感器指标的持续生成和监控。在I-69数据库归档的情况下，汇总数据存储在Oracle中，而未处理数据存储在SharePoint中。结果强调了所提指南的有效性，并促使其在研究项目中的应用。', 'title_zh': '基于AI驱动交通研究的路面传感器数据采集增强'}
{'arxiv_id': 'arXiv:2502.14218', 'title': 'Rethinking Spiking Neural Networks from an Ensemble Learning Perspective', 'authors': 'Yongqi Ding, Lin Zuo, Mengmeng Jing, Pei He, Hanpu Deng', 'link': 'https://arxiv.org/abs/2502.14218', 'abstract': 'Spiking neural networks (SNNs) exhibit superior energy efficiency but suffer from limited performance. In this paper, we consider SNNs as ensembles of temporal subnetworks that share architectures and weights, and highlight a crucial issue that affects their performance: excessive differences in initial states (neuronal membrane potentials) across timesteps lead to unstable subnetwork outputs, resulting in degraded performance. To mitigate this, we promote the consistency of the initial membrane potential distribution and output through membrane potential smoothing and temporally adjacent subnetwork guidance, respectively, to improve overall stability and performance. Moreover, membrane potential smoothing facilitates forward propagation of information and backward propagation of gradients, mitigating the notorious temporal gradient vanishing problem. Our method requires only minimal modification of the spiking neurons without adapting the network structure, making our method generalizable and showing consistent performance gains in 1D speech, 2D object, and 3D point cloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset, we achieved 83.20\\% accuracy with only four timesteps. This provides valuable insights into unleashing the potential of SNNs.', 'abstract_zh': '基于时间的稀疏神经网络中通过膜电位平滑和暂态邻近子网络指导促进一致性以提升性能', 'title_zh': '从集成学习视角重新思考脉冲神经网络'}
{'arxiv_id': 'arXiv:2502.14215', 'title': "Towards Secure Program Partitioning for Smart Contracts with LLM's In-Context Learning", 'authors': 'Ye Liu, Yuqing Niu, Chengyan Ma, Ruidong Han, Wei Ma, Yi Li, Debin Gao, David Lo', 'link': 'https://arxiv.org/abs/2502.14215', 'abstract': 'Smart contracts are highly susceptible to manipulation attacks due to the leakage of sensitive information. Addressing manipulation vulnerabilities is particularly challenging because they stem from inherent data confidentiality issues rather than straightforward implementation bugs. To tackle this by preventing sensitive information leakage, we present PartitionGPT, the first LLM-driven approach that combines static analysis with the in-context learning capabilities of large language models (LLMs) to partition smart contracts into privileged and normal codebases, guided by a few annotated sensitive data variables. We evaluated PartitionGPT on 18 annotated smart contracts containing 99 sensitive functions. The results demonstrate that PartitionGPT successfully generates compilable, and verified partitions for 78% of the sensitive functions while reducing approximately 30% code compared to function-level partitioning approach. Furthermore, we evaluated PartitionGPT on nine real-world manipulation attacks that lead to a total loss of 25 million dollars, PartitionGPT effectively prevents eight cases, highlighting its potential for broad applicability and the necessity for secure program partitioning during smart contract development to diminish manipulation vulnerabilities.', 'abstract_zh': '基于大型语言模型的分区方法PartitionGPT：防范智能合约敏感信息泄漏以应对操纵攻击', 'title_zh': '面向智能合约的安全程序划分方法：基于LLM的上下文学习'}
{'arxiv_id': 'arXiv:2502.14205', 'title': 'Accurate Forgetting for Heterogeneous Federated Continual Learning', 'authors': 'Abudukelimu Wuerkaixi, Sen Cui, Jingfeng Zhang, Kunda Yan, Bo Han, Gang Niu, Lei Fang, Changshui Zhang, Masashi Sugiyama', 'link': 'https://arxiv.org/abs/2502.14205', 'abstract': 'Recent years have witnessed a burgeoning interest in federated learning (FL). However, the contexts in which clients engage in sequential learning remain under-explored. Bridging FL and continual learning (CL) gives rise to a challenging practical problem: federated continual learning (FCL). Existing research in FCL primarily focuses on mitigating the catastrophic forgetting issue of continual learning while collaborating with other clients. We argue that the forgetting phenomena are not invariably detrimental. In this paper, we consider a more practical and challenging FCL setting characterized by potentially unrelated or even antagonistic data/tasks across different clients. In the FL scenario, statistical heterogeneity and data noise among clients may exhibit spurious correlations which result in biased feature learning. While existing CL strategies focus on a complete utilization of previous knowledge, we found that forgetting biased information is beneficial in our study. Therefore, we propose a new concept accurate forgetting (AF) and develop a novel generative-replay method~\\method~which selectively utilizes previous knowledge in federated networks. We employ a probabilistic framework based on a normalizing flow model to quantify the credibility of previous knowledge. Comprehensive experiments affirm the superiority of our method over baselines.', 'abstract_zh': '近年来，联邦学习（FL）的研究呈现出快速增长的态势。然而，客户端在 sequential 学习中的应用场景仍相对未被充分探索。将联邦学习与连续学习（CL）相结合，产生了一个具有挑战性的实际问题：联邦连续学习（FCL）。现有 FCL 研究主要集中在如何在协作学习中缓解连续学习中的灾难性遗忘问题。我们认为遗忘现象并非总是不利的。本文探讨了一个更加实际和具有挑战性的 FCL 设置，其中不同客户端的数据或任务可能是不相关的甚至是对立的。在联邦学习场景下，客户端之间的统计异质性和数据噪声可能会表现出虚假的相关性，导致偏差的特征学习。现有的 CL 策略侧重于充分利用之前的知识，但我们发现遗忘偏差信息在我们的研究中有益。因此，我们提出了一个新的准确遗忘（AF）概念，并开发了一种新的生成式重放方法~\\method~，该方法在联邦网络中选择性地利用之前的知识。我们采用基于归一化流模型的概率框架来量化之前知识的可信度。全面的实验验证了我们方法相对于基线方法的优越性。', 'title_zh': '异构联邦持续学习中的准确遗忘'}
{'arxiv_id': 'arXiv:2502.14204', 'title': 'On-the-fly Preference Alignment via Principle-Guided Decoding', 'authors': 'Mingye Zhu, Yi Liu, Lei Zhang, Junbo Guo, Zhendong Mao', 'link': 'https://arxiv.org/abs/2502.14204', 'abstract': "With the rapidly expanding landscape of large language models, aligning model generations with human values and preferences is becoming increasingly important. Popular alignment methods, such as Reinforcement Learning from Human Feedback, have shown significant success in guiding models with greater control. However, these methods require considerable computational resources, which is inefficient, and substantial collection of training data to accommodate the diverse and pluralistic nature of human preferences, which is impractical. These limitations significantly constrain the scope and efficacy of both task-specific and general preference alignment methods. In this work, we introduce On-the-fly Preference Alignment via Principle-Guided Decoding (OPAD) to directly align model outputs with human preferences during inference, eliminating the need for fine-tuning. Our approach involves first curating a surrogate solution to an otherwise infeasible optimization problem and then designing a principle-guided reward function based on this surrogate. The final aligned policy is derived by maximizing this customized reward, which exploits the discrepancy between the constrained policy and its unconstrained counterpart. OPAD directly modifies the model's predictions during inference, ensuring principle adherence without incurring the computational overhead of retraining or fine-tuning. Experiments show that OPAD achieves competitive or superior performance in both general and personalized alignment tasks, demonstrating its efficiency and effectiveness compared to state-of-the-art baselines.", 'abstract_zh': '随用随调的原理指导解码偏倚对齐方法（OPAD）：直接在推理时调整模型输出以符合人类偏好', 'title_zh': '根据原则导向解码实现的实时偏好对齐'}
{'arxiv_id': 'arXiv:2502.14202', 'title': 'Do LLMs Consider Security? An Empirical Study on Responses to Programming Questions', 'authors': 'Amirali Sajadi, Binh Le, Anh Nguyen, Kostadin Damevski, Preetha Chatterjee', 'link': 'https://arxiv.org/abs/2502.14202', 'abstract': "The widespread adoption of conversational LLMs for software development has raised new security concerns regarding the safety of LLM-generated content. Our motivational study outlines ChatGPT's potential in volunteering context-specific information to the developers, promoting safe coding practices. Motivated by this finding, we conduct a study to evaluate the degree of security awareness exhibited by three prominent LLMs: Claude 3, GPT-4, and Llama 3. We prompt these LLMs with Stack Overflow questions that contain vulnerable code to evaluate whether they merely provide answers to the questions or if they also warn users about the insecure code, thereby demonstrating a degree of security awareness. Further, we assess whether LLM responses provide information about the causes, exploits, and the potential fixes of the vulnerability, to help raise users' awareness. Our findings show that all three models struggle to accurately detect and warn users about vulnerabilities, achieving a detection rate of only 12.6% to 40% across our datasets. We also observe that the LLMs tend to identify certain types of vulnerabilities related to sensitive information exposure and improper input neutralization much more frequently than other types, such as those involving external control of file names or paths. Furthermore, when LLMs do issue security warnings, they often provide more information on the causes, exploits, and fixes of vulnerabilities compared to Stack Overflow responses. Finally, we provide an in-depth discussion on the implications of our findings and present a CLI-based prompting tool that can be used to generate significantly more secure LLM responses.", 'abstract_zh': '广泛采用的对话型大语言模型在软件开发中的应用引发了对其生成内容安全性的新关切。我们通过动机研究概述了ChatGPT在志愿提供上下文相关信息方面的潜力，及其在促进安全编码实践方面的角色。受此发现的启发，我们研究了Claude 3、GPT-4和Llama 3这三种主要大语言模型的安全意识程度。我们通过向这些模型提供包含漏洞代码的Stack Overflow问题来测试它们是否仅仅回答问题还是也警告用户关于不安全代码，从而展示它们的安全意识程度。进一步评估模型的响应是否提供了漏洞的原因、利用方法和潜在修复措施的信息，以帮助提高用户的意识。我们的研究发现，所有三个模型在检测和警告用户漏洞方面都存在困难，在我们的数据集中检测率仅为12.6%到40%。我们还观察到，模型更频繁地识别与敏感信息暴露和输入不适当中和相关的漏洞类型。此外，当大语言模型发出安全警告时，它们提供的漏洞原因、利用方法和修复措施的信息通常比Stack Overflow的回答更详细。最后，我们深入讨论了研究发现的意义，并提出了一种基于命令行接口的提示工具，可以生成更加安全的大语言模型响应。', 'title_zh': '大规模语言模型考虑安全性吗？编程问题回应的实证研究'}
{'arxiv_id': 'arXiv:2502.14197', 'title': 'Adaptive Sparsified Graph Learning Framework for Vessel Behavior Anomalies', 'authors': 'Jeehong Kim, Minchan Kim, Jaeseong Ju, Youngseok Hwang, Wonhee Lee, Hyunwoo Park', 'link': 'https://arxiv.org/abs/2502.14197', 'abstract': 'Graph neural networks have emerged as a powerful tool for learning spatiotemporal interactions. However, conventional approaches often rely on predefined graphs, which may obscure the precise relationships being modeled. Additionally, existing methods typically define nodes based on fixed spatial locations, a strategy that is ill-suited for dynamic environments like maritime environments. Our method introduces an innovative graph representation where timestamps are modeled as distinct nodes, allowing temporal dependencies to be explicitly captured through graph edges. This setup is extended to construct a multi-ship graph that effectively captures spatial interactions while preserving graph sparsity. The graph is processed using Graph Convolutional Network layers to capture spatiotemporal patterns, with a forecasting layer for feature prediction and a Variational Graph Autoencoder for reconstruction, enabling robust anomaly detection.', 'abstract_zh': '图神经网络已 emerges as 一个 Powerful 工具 for 学习 空间时间 交互。然而， conventional 传统 方法 often 经常 依赖 预先定义 的图，这可能会 obscure 遮挡 精确 的关系 being 被建模。此外，现有 方法 typically 通常 基于 固定 空间 位置 定义 节点，这种策略不适合 动态 环境，如 海事 环境。我们的 方法 Introduces 引入 一个 创新的 图表示，其中 时间戳 被 建模 为 不同 的节点，允许 通过 图边 Explicitly 显式 捕获 时间依赖性。这种设置 被 扩展 以 构建 一个多船图，有效地 捕获 空间 交互 同时 保持 图稀疏性。图 通过 图卷积网络 层处理 以 捕获 空间时间 模式，具有 一个 预测 层 用于 特征 预测 以及 一个 变分 图自编码器 用于 重构，从而 实现 稳健 的异常 检测。', 'title_zh': '自适应稀疏化图学习框架以识别船舶行为异常'}
{'arxiv_id': 'arXiv:2502.14191', 'title': 'Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision Language Models', 'authors': 'Michihiro Yasunaga, Luke Zettlemoyer, Marjan Ghazvininejad', 'link': 'https://arxiv.org/abs/2502.14191', 'abstract': 'Reward models play an essential role in training vision-language models (VLMs) by assessing output quality to enable aligning with human preferences. Despite their importance, the research community lacks comprehensive open benchmarks for evaluating multimodal reward models in VLMs. To address this gap, we introduce Multimodal RewardBench, an expert-annotated benchmark covering six domains: general correctness, preference, knowledge, reasoning, safety, and visual question-answering. Our dataset comprises 5,211 annotated (prompt, chosen response, rejected response) triplets collected from various VLMs. In evaluating a range of VLM judges, we find that even the top-performing models, Gemini 1.5 Pro and Claude 3.5 Sonnet, achieve only 72% overall accuracy. Notably, most models struggle in the reasoning and safety domains. These findings suggest that Multimodal RewardBench offers a challenging testbed for advancing reward model development across multiple domains. We release the benchmark at this https URL.', 'abstract_zh': '多模态奖励基准（Multimodal RewardBench）在视觉语言模型中的作用及其挑战', 'title_zh': '多模态奖励基准：视觉语言模型奖励模型的整体评估'}
{'arxiv_id': 'arXiv:2502.14183', 'title': 'Type 1 Diabetes Management using GLIMMER: Glucose Level Indicator Model with Modified Error Rate', 'authors': 'Saman Khamesian, Asiful Arefeen, Adela Grando, Bithika Thompson, Hassan Ghasemzadeh', 'link': 'https://arxiv.org/abs/2502.14183', 'abstract': 'Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals strive to regulate their blood glucose levels to avert the dangers of dysglycemia (hyperglycemia or hypoglycemia). Despite the advent of sophisticated technologies such as automated insulin delivery (AID) systems, achieving optimal glycemic control remains a formidable task. AID systems integrate continuous subcutaneous insulin infusion (CSII) and continuous glucose monitors (CGM) data, offering promise in reducing variability and increasing glucose time-in-range. However, these systems often fail to prevent dysglycemia, partly due to limitations in prediction algorithms that lack the precision to avert abnormal glucose events. This gap highlights the need for proactive behavioral adjustments. We address this need with GLIMMER, Glucose Level Indicator Model with Modified Error Rate, a machine learning approach for forecasting blood glucose levels. GLIMMER categorizes glucose values into normal and abnormal ranges and devises a novel custom loss function to prioritize accuracy in dysglycemic events where patient safety is critical. To evaluate the potential of GLIMMER for T1D management, we both use a publicly available dataset and collect new data involving 25 patients with T1D. In predicting next-hour glucose values, GLIMMER achieved a root mean square error (RMSE) of 23.97 (+/-3.77) and a mean absolute error (MAE) of 15.83 (+/-2.09) mg/dL. These results reflect a 23% improvement in RMSE and a 31% improvement in MAE compared to the best-reported error rates.', 'abstract_zh': '管理1型糖尿病（T1D）要求持续的警觉性，以调节血糖水平，避免血糖失常（高血糖或低血糖）的危险。尽管 sophisticated 技术如自动胰岛素输送（AID）系统的发展，实现最优血糖控制仍是一项艰巨的任务。AID 系统结合了持续皮下胰岛素输注（CSII）和持续葡萄糖监测（CGM）的数据，有望减少血糖波动并增加血糖在目标范围内的时间。然而，这些系统往往无法预防血糖失常，部分原因是预测算法缺乏精确性，无法避免异常血糖事件。这一差距突显了主动行为调整的必要性。我们通过 GLIMMER（Glucose Level Indicator Model with Modified Error Rate）这一机器学习方法来进行血糖水平预测，对葡萄糖值进行正常和异常范围分类，并设计了一种新颖的自定义损失函数，以在患者安全至关重要的低血糖事件中优先确保准确性。为了评估 GLIMMER 在 T1D 管理中的潜力，我们使用了一个公开可用的数据集并收集了涉及 25 名 T1D 患者的 newData。在预测下一个小时的血糖值方面，GLIMMER 达到了均方根误差（RMSE）23.97（±3.77）和平均绝对误差（MAE）15.83（±2.09）mg/dL。这些结果表明，与最佳报告的误差率相比，GLIMMER 在 RMSE 上提高了 23%，在 MAE 上提高了 31%。', 'title_zh': '使用GLIMMER进行1型糖尿病管理：修正误差率的血糖水平指示模型'}
{'arxiv_id': 'arXiv:2502.14176', 'title': 'A modal logic translation of the AGM axioms for belief revision', 'authors': 'Giacomo Bonanno', 'link': 'https://arxiv.org/abs/2502.14176', 'abstract': 'Building on the analysis of Bonanno (Artificial Intelligence, 2025) we introduce a simple modal logic containing three modal operators: a unimodal belief operator, a bimodal conditional operator and the unimodal global operator. For each AGM axiom for belief revision, we provide a corresponding modal axiom. The correspondence is as follows: each AGM axiom is characterized by a property of the Kripke-Lewis frames considered in Bonanno (Artificial Intelligence, 2025) and, in turn, that property characterizes the proposed modal axiom.', 'abstract_zh': '基于Bonanno（《人工智能》，2025）的研究，引入一种包含三种模态运算符的简单模态逻辑：单模态信念运算符、双模态条件运算符和单模态全局运算符。对于每条AGM信念修订公理，提供相应的模态公理。对应关系如下：每条AGM公理由Bonanno（《人工智能》，2025）中考虑的Kripke-Lewis框架的某个性质表征，反过来该性质表征了所提出的模态公理。', 'title_zh': '模态逻辑对AGM信念修正公理的翻译'}
{'arxiv_id': 'arXiv:2502.14174', 'title': 'Weighted Low-rank Approximation via Stochastic Gradient Descent on Manifolds', 'authors': 'Conglong Xu, Peiqi Yang, Hao Wu', 'link': 'https://arxiv.org/abs/2502.14174', 'abstract': 'We solve a regularized weighted low-rank approximation problem by a stochastic gradient descent on a manifold. To guarantee the convergence of our stochastic gradient descent, we establish a convergence theorem on manifolds for retraction-based stochastic gradient descents admitting confinements. On sample data from the Netflix Prize training dataset, our algorithm outperforms the existing stochastic gradient descent on Euclidean spaces. We also compare the accelerated line search on this manifold to the existing accelerated line search on Euclidean spaces.', 'abstract_zh': '我们通过流形上的修正加权低秩逼近问题求解方法，利用基于截断的随机梯度下降保证收敛性，并在Netflix Prize训练数据集的样本数据上，我们的算法优于欧几里得空间上的随机梯度下降。我们还比较了该流形上的加速线性搜索与欧几里得空间上的加速线性搜索。', 'title_zh': '基于流形上的随机梯度下降的加权低秩逼近'}
{'arxiv_id': 'arXiv:2502.14160', 'title': 'Efficient Inverse Multiagent Learning', 'authors': 'Denizalp Goktas, Amy Greenwald, Sadie Zhao, Alec Koppel, Sumitra Ganesh', 'link': 'https://arxiv.org/abs/2502.14160', 'abstract': "In this paper, we study inverse game theory (resp. inverse multiagent learning) in which the goal is to find parameters of a game's payoff functions for which the expected (resp. sampled) behavior is an equilibrium. We formulate these problems as generative-adversarial (i.e., min-max) optimization problems, for which we develop polynomial-time algorithms to solve, the former of which relies on an exact first-order oracle, and the latter, a stochastic one. We extend our approach to solve inverse multiagent simulacral learning in polynomial time and number of samples. In these problems, we seek a simulacrum, meaning parameters and an associated equilibrium that replicate the given observations in expectation. We find that our approach outperforms the widely-used ARIMA method in predicting prices in Spanish electricity markets based on time-series data.", 'abstract_zh': '在本文中，我们研究逆博弈理论（或逆多智能体学习），其目标是找到博弈收益函数的参数，使得期望（或采样）行为是均衡。我们将这些问题形式化为生成对抗（即，极小极大）优化问题，并为此类问题开发了多项式时间算法，前者依赖于精确的一阶oracle，后者依赖于随机的一阶oracle。我们将方法扩展以多项式时间内的样本数解决逆多智能体模拟学习问题。在这些问题中，我们寻求一个模拟物，即寻找参数及其相关的均衡，以期望方式复制给定的观察结果。我们发现，我们的方法在基于时间序列数据预测西班牙电力市场价格方面优于广泛使用的ARIMA方法。', 'title_zh': '高效逆多智能体学习'}
{'arxiv_id': 'arXiv:2502.14149', 'title': 'PitVQA++: Vector Matrix-Low-Rank Adaptation for Open-Ended Visual Question Answering in Pituitary Surgery', 'authors': 'Runlong He, Danyal Z. Khan, Evangelos B. Mazomenos, Hani J. Marcus, Danail Stoyanov, Matthew J. Clarkson, Mobarakol Islam', 'link': 'https://arxiv.org/abs/2502.14149', 'abstract': 'Vision-Language Models (VLMs) in visual question answering (VQA) offer a unique opportunity to enhance intra-operative decision-making, promote intuitive interactions, and significantly advancing surgical education. However, the development of VLMs for surgical VQA is challenging due to limited datasets and the risk of overfitting and catastrophic forgetting during full fine-tuning of pretrained weights. While parameter-efficient techniques like Low-Rank Adaptation (LoRA) and Matrix of Rank Adaptation (MoRA) address adaptation challenges, their uniform parameter distribution overlooks the feature hierarchy in deep networks, where earlier layers, that learn general features, require more parameters than later ones. This work introduces PitVQA++ with an open-ended PitVQA dataset and vector matrix-low-rank adaptation (Vector-MoLoRA), an innovative VLM fine-tuning approach for adapting GPT-2 to pituitary surgery. Open-Ended PitVQA comprises around 101,803 frames from 25 procedural videos with 745,972 question-answer sentence pairs, covering key surgical elements such as phase and step recognition, context understanding, tool detection, localization, and interactions recognition. Vector-MoLoRA incorporates the principles of LoRA and MoRA to develop a matrix-low-rank adaptation strategy that employs vector ranking to allocate more parameters to earlier layers, gradually reducing them in the later layers. Our approach, validated on the Open-Ended PitVQA and EndoVis18-VQA datasets, effectively mitigates catastrophic forgetting while significantly enhancing performance over recent baselines. Furthermore, our risk-coverage analysis highlights its enhanced reliability and trustworthiness in handling uncertain predictions. Our source code and dataset is available at~\\url{this https URL}.', 'abstract_zh': '视觉语言模型（VLMs）在手术视觉问答（Surgical VQA）中的应用为优化术中决策、促进直观交互以及显著推进 surgical 教育提供了独特的机会。然而，由于数据集有限以及全量微调预训练权重时存在过拟合和灾难性遗忘的风险，开发适用于手术 VQA 的 VLMs 具有挑战性。尽管参数高效的技术，如 Low-Rank Adaptation (LoRA) 和 Matrix of Rank Adaptation (MoRA) 可以解决适应性挑战，但它们均匀的参数分布忽略了深度网络中的特征层次结构，导致早期层（学习一般特征）所需的参数多于后期层。本文介绍了带有开放性 PitVQA 数据集的 PitVQA++ 及 Vector-MoLoRA，Vector-MoLoRA 是一种创新的 VLM 微调方法，用于将 GPT-2 调整为垂体手术。开放性 PitVQA 包含约 101,803 帧，来自 25 个手术视频，共有 745,972 个问题-答案句子对，涵盖了关键的手术要素如阶段和步骤识别、上下文理解、工具检测、定位和交互识别。Vector-MoLoRA 结合了 LoRA 和 MoRA 的原理，开发了一种基于向量排名的矩阵低秩适应策略，以更多地分配参数到早期层，并逐渐减少后期层的参数。该方法在开放性 PitVQA 和 EndoVis18-VQA 数据集上的验证表明，它有效缓解了灾难性遗忘，同时显著增强了相较于最近基线的性能。此外，我们的风险覆盖分析突显了其处理不确定预测的增强可靠性和可信度。我们的源代码和数据集可在 \\url{此链接} 获取。', 'title_zh': 'PitVQA++: 垂体手术中开放性视觉问答的向量矩阵低秩适应'}
{'arxiv_id': 'arXiv:2502.14143', 'title': 'Multi-Agent Risks from Advanced AI', 'authors': 'Lewis Hammond, Alan Chan, Jesse Clifton, Jason Hoelscher-Obermaier, Akbir Khan, Euan McLean, Chandler Smith, Wolfram Barfuss, Jakob Foerster, Tomáš Gavenčiak, Anh Han, Edward Hughes, Vojtěch Kovařík, Jan Kulveit, Joel Z. Leibo, Caspar Oesterheld, Christian Schroeder de Witt, Nisarg Shah, Michael Wellman, Paolo Bova, Theodor Cimpeanu, Carson Ezell, Quentin Feuillade-Montixi, Matija Franklin, Esben Kran, Igor Krawczuk, Max Lamparth, Niklas Lauffer, Alexander Meinke, Sumeet Motwani, Anka Reuel, Vincent Conitzer, Michael Dennis, Iason Gabriel, Adam Gleave, Gillian Hadfield, Nika Haghtalab, Atoosa Kasirzadeh, Sébastien Krier, Kate Larson, Joel Lehman, David C. Parkes, Georgios Piliouras, Iyad Rahwan', 'link': 'https://arxiv.org/abs/2502.14143', 'abstract': "The rapid development of advanced AI agents and the imminent deployment of many instances of these agents will give rise to multi-agent systems of unprecedented complexity. These systems pose novel and under-explored risks. In this report, we provide a structured taxonomy of these risks by identifying three key failure modes (miscoordination, conflict, and collusion) based on agents' incentives, as well as seven key risk factors (information asymmetries, network effects, selection pressures, destabilising dynamics, commitment problems, emergent agency, and multi-agent security) that can underpin them. We highlight several important instances of each risk, as well as promising directions to help mitigate them. By anchoring our analysis in a range of real-world examples and experimental evidence, we illustrate the distinct challenges posed by multi-agent systems and their implications for the safety, governance, and ethics of advanced AI.", 'abstract_zh': '先进AI代理的快速发展及其部署实例将导致前所未有的复杂多代理系统。这些系统带来了新颖且尚未充分探索的风险。本报告通过基于代理激励识别三种关键失败模式（误协调、冲突和勾结），以及七种关键风险因素（信息不对称、网络效应、选择压力、不稳定性动态、承诺问题、新兴代理和多代理安全），对这些风险进行了结构化分类。我们强调了每种风险的重要实例，并指出了有助于减轻它们的有前途的方向。通过在多种现实世界例子和实验证据的基础上进行分析，我们阐明了多代理系统所带来的独特挑战及其对高级AI的安全性、治理和伦理的影响。', 'title_zh': '高级人工智能的多Agent风险'}
{'arxiv_id': 'arXiv:2502.14132', 'title': 'Can Community Notes Replace Professional Fact-Checkers?', 'authors': 'Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein', 'link': 'https://arxiv.org/abs/2502.14132', 'abstract': 'Two commonly-employed strategies to combat the rise of misinformation on social media are (i) fact-checking by professional organisations and (ii) community moderation by platform users. Policy changes by Twitter/X and, more recently, Meta, signal a shift away from partnerships with fact-checking organisations and towards an increased reliance on crowdsourced community notes. However, the extent and nature of dependencies between fact-checking and helpful community notes remain unclear. To address these questions, we use language models to annotate a large corpus of Twitter/X community notes with attributes such as topic, cited sources, and whether they refute claims tied to broader misinformation narratives. Our analysis reveals that community notes cite fact-checking sources up to five times more than previously reported. Fact-checking is especially crucial for notes on posts linked to broader narratives, which are twice as likely to reference fact-checking sources compared to other sources. In conclusion, our results show that successful community moderation heavily relies on professional fact-checking.', 'abstract_zh': '社交媒体上打击 misinformation 两个常见的策略是（i）专业组织的事实核查和（ii）平台用户的社区管理。Twitter/X 和最近的 Meta 的政策变化表明，从与事实核查组织的合作转向对众包社区注释的更大依赖。然而，事实核查与 helpful 社区注释之间的依赖程度和性质尚不明确。为了回答这些问题，我们使用语言模型对 Twitter/X 社区注释的大规模语料库进行注释，标注主题、引用来源以及是否反驳与广泛流传的 misinformation 讲述相关的内容。我们的分析显示，社区注释引用的事实核查来源比之前报道的多五倍。事实核查特别对于链接到更广泛叙述的帖子注释尤为重要，这些注释引用事实核查来源的可能性是其他来源的两倍。总之，我们的结果显示，成功的社区管理严重依赖于专业事实核查。', 'title_zh': '社区笔记能否取代专业事实核查员？'}
{'arxiv_id': 'arXiv:2502.14131', 'title': 'Gradients can train reward models: An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model', 'authors': 'Enoch H. Kang, Hema Yoganarasimhan, Lalit Jain', 'link': 'https://arxiv.org/abs/2502.14131', 'abstract': 'We study the problem of estimating Dynamic Discrete Choice (DDC) models, also known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning (offline MaxEnt-IRL) in machine learning. The objective is to recover reward or $Q^*$ functions that govern agent behavior from offline behavior data. In this paper, we propose a globally convergent gradient-based method for solving these problems without the restrictive assumption of linearly parameterized rewards. The novelty of our approach lies in introducing the Empirical Risk Minimization (ERM) based IRL/DDC framework, which circumvents the need for explicit state transition probability estimation in the Bellman equation. Furthermore, our method is compatible with non-parametric estimation techniques such as neural networks. Therefore, the proposed method has the potential to be scaled to high-dimensional, infinite state spaces. A key theoretical insight underlying our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL) condition -- a property that, while weaker than strong convexity, is sufficient to ensure fast global convergence guarantees. Through a series of synthetic experiments, we demonstrate that our approach consistently outperforms benchmark methods and state-of-the-art alternatives.', 'abstract_zh': '我们研究动态离散选择模型的估计问题，也称为机器学习中的offline最大熵逆 reinforcement learning (offline MaxEnt-IRL)。目标是从离线行为数据中恢复控制代理行为的奖励或$Q^*$函数。在本文中，我们提出了一种全局收敛的基于梯度的方法来解决这些问题，不局限于线性参数化的奖励假设。我们方法的创新之处在于引入了基于经验风险最小化(ERM)的IRL/DDC框架，避免了贝尔曼方程中显式状态转换概率的估计需求。此外，我们的方法与非参数估计技术（如神经网络）兼容。因此，所提出的方法有可能扩展到高维、无限状态空间。我们方法背后的 key 理论洞见是贝尔曼残差满足 Polyak-Lojasiewicz (PL) 条件——这一性质虽然弱于强凸性，但足以确保快速全局收敛保证。通过一系列合成实验，我们展示了我们的方法在基准方法和最先进的替代方法上具有一致的优越性能。', 'title_zh': '梯度可以训练奖励模型：离线逆强化学习和动态离散选择模型的 empirical risk minimization 方法'}
{'arxiv_id': 'arXiv:2502.14121', 'title': 'Multi-Objective Bayesian Optimization for Networked Black-Box Systems: A Path to Greener Profits and Smarter Designs', 'authors': 'Akshay Kudva, Wei-Ting Tang, Joel A. Paulson', 'link': 'https://arxiv.org/abs/2502.14121', 'abstract': 'Designing modern industrial systems requires balancing several competing objectives, such as profitability, resilience, and sustainability, while accounting for complex interactions between technological, economic, and environmental factors. Multi-objective optimization (MOO) methods are commonly used to navigate these tradeoffs, but selecting the appropriate algorithm to tackle these problems is often unclear, particularly when system representations vary from fully equation-based (white-box) to entirely data-driven (black-box) models. While grey-box MOO methods attempt to bridge this gap, they typically impose rigid assumptions on system structure, requiring models to conform to the underlying structural assumptions of the solver rather than the solver adapting to the natural representation of the system of interest. In this chapter, we introduce a unifying approach to grey-box MOO by leveraging network representations, which provide a general and flexible framework for modeling interconnected systems as a series of function nodes that share various inputs and outputs. Specifically, we propose MOBONS, a novel Bayesian optimization-inspired algorithm that can efficiently optimize general function networks, including those with cyclic dependencies, enabling the modeling of feedback loops, recycle streams, and multi-scale simulations - features that existing methods fail to capture. Furthermore, MOBONS incorporates constraints, supports parallel evaluations, and preserves the sample efficiency of Bayesian optimization while leveraging network structure for improved scalability. We demonstrate the effectiveness of MOBONS through two case studies, including one related to sustainable process design. By enabling efficient MOO under general graph representations, MOBONS has the potential to significantly enhance the design of more profitable, resilient, and sustainable engineering systems.', 'abstract_zh': '现代工业系统设计需要在盈利能力、韧性和可持续性等多个目标之间取得平衡，同时考虑技术、经济和环境因素之间的复杂交互。多目标优化（MOO）方法常用于解决这些权衡问题，但在选择合适的算法时，尤其是在系统表示从完全基于方程（白盒）到完全数据驱动（黑盒）模型之间变化时，往往不够清晰。虽然灰盒MOO方法试图弥合这一差距，但它们通常会对系统结构施加刚性假设，要求模型符合求解器的内在结构假设，而不是让求解器适应所需研究系统的自然表示。在本章中，我们通过利用网络表示提出了一种统一的灰盒MOO方法，网络表示提供了一种通用且灵活的框架，用于将相互连接的系统建模为一系列具有各种输入和输出的功能节点。具体而言，我们提出了一种MOBONS算法，这是一种受贝叶斯优化启发的新算法，能够高效优化一般功能网络，包括具有循环依赖性的网络，从而能够建模反馈回路、回收流和多层次仿真——这是现有方法未能捕捉到的功能。此外，MOBONS 支持约束条件、并行评估，并保持贝叶斯优化的样本效率，同时利用网络结构以提高可扩展性。通过两个案例研究，包括可持续工艺设计相关的案例，我们展示了MOBONS的有效性。通过在通用图表示下实现高效的MOO，MOBONS 有望显著增强更具盈利性、韧性和可持续性的工程系统设计。', 'title_zh': '网络黑盒系统多目标贝叶斯优化：通往更绿色利润和更智能设计的道路'}
{'arxiv_id': 'arXiv:2502.14114', 'title': 'Zero loss guarantees and explicit minimizers for generic overparametrized Deep Learning networks', 'authors': 'Thomas Chen, Andrew G. Moore', 'link': 'https://arxiv.org/abs/2502.14114', 'abstract': 'We determine sufficient conditions for overparametrized deep learning (DL) networks to guarantee the attainability of zero loss in the context of supervised learning, for the $\\mathcal{L}^2$ cost and {\\em generic} training data. We present an explicit construction of the zero loss minimizers without invoking gradient descent. On the other hand, we point out that increase of depth can deteriorate the efficiency of cost minimization using a gradient descent algorithm by analyzing the conditions for rank loss of the training Jacobian. Our results clarify key aspects on the dichotomy between zero loss reachability in underparametrized versus overparametrized DL.', 'abstract_zh': '我们确定了过参数化的深度学习网络在监督学习背景下，对于\\(\\mathcal{L}^2\\)损失和通用训练数据保证零损失可达性的充分条件。我们提供了一种无需使用梯度下降的方法构造零损失极小化器。另一方面，通过对训练雅可比秩损失条件的分析，我们指出网络深度增加可能会恶化梯度下降算法的成本最小化效率。我们的结果澄清了在欠参数化与过参数化深度学习之间实现零损失的二分法中的关键方面。', 'title_zh': '通用过度参数化深度学习网络的零损失保证和显式极小值'}
{'arxiv_id': 'arXiv:2502.14113', 'title': 'Object-centric Binding in Contrastive Language-Image Pretraining', 'authors': 'Rim Assouel, Pietro Astolfi, Florian Bordes, Michal Drozdzal, Adriana Romero-Soriano', 'link': 'https://arxiv.org/abs/2502.14113', 'abstract': 'Recent advances in vision language models (VLM) have been driven by contrastive models such as CLIP, which learn to associate visual information with their corresponding text descriptions. However, these models have limitations in understanding complex compositional scenes involving multiple objects and their spatial relationships. To address these challenges, we propose a novel approach that diverges from commonly used strategies, which rely on the design of hard-negative augmentations. Instead, our work focuses on integrating inductive biases into pre-trained CLIP-like models to improve their compositional understanding without using any additional hard-negatives. To that end, we introduce a binding module that connects a scene graph, derived from a text description, with a slot-structured image representation, facilitating a structured similarity assessment between the two modalities. We also leverage relationships as text-conditioned visual constraints, thereby capturing the intricate interactions between objects and their contextual relationships more effectively. Our resulting model not only enhances the performance of CLIP-based models in multi-object compositional understanding but also paves the way towards more accurate and sample-efficient image-text matching of complex scenes.', 'abstract_zh': '最近在视觉语言模型（VLM）方面的进展受到对比模型（如CLIP）的驱动，这些模型学会了将视觉信息与其相应的文本描述关联起来。然而，这些模型在理解涉及多个物体及其空间关系的复杂组合场景方面存在局限性。为了解决这些挑战，我们提出了一种新的方法，该方法偏离了依赖于硬负样本增强的设计策略，而是将归纳偏置集成到预训练的CLIP-like模型中，以提高其组合理解能力，而无需使用任何额外的硬负样本。为此，我们引入了一个绑定模块，将从文本描述中提取的场景图与槽结构化图像表示连接起来，从而促进这两种模态之间的结构化相似性评估。我们还利用关系作为文本条件的视觉约束，从而更有效地捕捉物体及其上下文关系之间的复杂相互作用。我们的模型不仅提高了基于CLIP的模型在多对象组合理解方面的性能，还为复杂场景的更准确和样本高效的图像-文本匹配奠定了基础。', 'title_zh': '对象中心的对比-langauge-image 预训练'}
{'arxiv_id': 'arXiv:2502.14086', 'title': 'Navigating Semantic Relations: Challenges for Language Models in Abstract Common-Sense Reasoning', 'authors': 'Cole Gawin, Yidan Sun, Mayank Kejriwal', 'link': 'https://arxiv.org/abs/2502.14086', 'abstract': "Large language models (LLMs) have achieved remarkable performance in generating human-like text and solving reasoning tasks of moderate complexity, such as question-answering and mathematical problem-solving. However, their capabilities in tasks requiring deeper cognitive skills, such as common-sense understanding and abstract reasoning, remain under-explored. In this paper, we systematically evaluate abstract common-sense reasoning in LLMs using the ConceptNet knowledge graph. We propose two prompting approaches: instruct prompting, where models predict plausible semantic relationships based on provided definitions, and few-shot prompting, where models identify relations using examples as guidance. Our experiments with the gpt-4o-mini model show that in instruct prompting, consistent performance is obtained when ranking multiple relations but with substantial decline when the model is restricted to predicting only one relation. In few-shot prompting, the model's accuracy improves significantly when selecting from five relations rather than the full set, although with notable bias toward certain relations. These results suggest significant gaps still, even in commercially used LLMs' abstract common-sense reasoning abilities, compared to human-level understanding. However, the findings also highlight the promise of careful prompt engineering, based on selective retrieval, for obtaining better performance.", 'abstract_zh': '大型语言模型（LLMs）在生成类人类文本和解决中等复杂性推理任务（如问答和数学问题解决）方面取得了显著成绩，但是在需要更深层次认知技能的任务（如常识理解和抽象推理）方面的能力仍需进一步探索。在本文中，我们利用ConceptNet知识图谱系统评估LLMs的抽象常识推理能力。我们提出了两种提示方法：指令提示，模型基于提供的定义预测可能的语义关系；少量示例提示，模型使用示例作为指导识别关系。我们的实验表明，在指令提示中，当对多种关系进行排名时，可获得一致性能，但当模型仅限于预测单一关系时，性能有显著下降；在少量示例提示中，当从五个关系中选择时，模型的准确性显著提高，尽管存在对某些关系的明显偏好。这些结果表明，即使在商业使用的LLMs中，其抽象常识推理能力与人类水平的理解之间仍存在显著差距。然而，这些发现也暗示了基于选择性检索的细致提示工程能够在性能上取得更好的效果。', 'title_zh': '导航语义关系：语言模型在抽象常识推理中的挑战'}
{'arxiv_id': 'arXiv:2502.14080', 'title': 'Personalized Education with Generative AI and Digital Twins: VR, RAG, and Zero-Shot Sentiment Analysis for Industry 4.0 Workforce Development', 'authors': 'Yu-Zheng Lin, Karan Petal, Ahmed H Alhamadah, Sujan Ghimire, Matthew William Redondo, David Rafael Vidal Corona, Jesus Pacheco, Soheil Salehi, Pratik Satam', 'link': 'https://arxiv.org/abs/2502.14080', 'abstract': "The Fourth Industrial Revolution (4IR) technologies, such as cloud computing, machine learning, and AI, have improved productivity but introduced challenges in workforce training and reskilling. This is critical given existing workforce shortages, especially in marginalized communities like Underrepresented Minorities (URM), who often lack access to quality education. Addressing these challenges, this research presents gAI-PT4I4, a Generative AI-based Personalized Tutor for Industrial 4.0, designed to personalize 4IR experiential learning. gAI-PT4I4 employs sentiment analysis to assess student comprehension, leveraging generative AI and finite automaton to tailor learning experiences. The framework integrates low-fidelity Digital Twins for VR-based training, featuring an Interactive Tutor - a generative AI assistant providing real-time guidance via audio and text. It uses zero-shot sentiment analysis with LLMs and prompt engineering, achieving 86\\% accuracy in classifying student-teacher interactions as positive or negative. Additionally, retrieval-augmented generation (RAG) enables personalized learning content grounded in domain-specific knowledge. To adapt training dynamically, finite automaton structures exercises into states of increasing difficulty, requiring 80\\% task-performance accuracy for progression. Experimental evaluation with 22 volunteers showed improved accuracy exceeding 80\\%, reducing training time. Finally, this paper introduces a Multi-Fidelity Digital Twin model, aligning Digital Twin complexity with Bloom's Taxonomy and Kirkpatrick's model, providing a scalable educational framework.", 'abstract_zh': '第四次工业革命技术（4IR），如云计算、机器学习和AI，虽然提高了生产效率，但引入了劳动力培训和再培训的挑战。鉴于现有劳动力短缺，特别是在弱势群体如代表性不足的少数群体（URM）中，这些群体往往缺乏高质量的教育机会，因此解决这些挑战至关重要。本研究提出了一种基于生成AI的个性化工业4.0导师——gAI-PT4I4，旨在个性化4IR体验式学习。gAI-PT4I4利用情感分析评估学生理解程度，并结合生成AI和有穷自动机定制学习体验。该框架整合低保真度数字孪生用于基于VR的培训，包含交互式导师——一个通过语音和文本提供实时指导的生成AI助手。使用零样本情感分析和LLM以及提示工程，分类学生-教师互动为正面或负面的准确率达到86%。此外，检索增强生成（RAG）功能实现基于学科特定知识的个性化学习内容。为了动态适应培训需求，有穷自动机将练习划分成难度递增的状态，要求任务完成率达到80%方可继续进展。22名志愿者的实验评估显示，准确率超过80%，减少了培训时间。最后，本文介绍了多保真度数字孪生模型，将数字孪生的复杂度与布卢姆分类法和柯克帕特里克模型对齐，提供了一个可扩展的教育框架。', 'title_zh': '基于生成AI和数字孪生的个性化教育：面向工业4.0劳动力发展的VR、RAG和零-shot情感分析'}
{'arxiv_id': 'arXiv:2502.14070', 'title': 'DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models', 'authors': 'Daewon Chae, June Suk Choi, Jinkyu Kim, Kimin Lee', 'link': 'https://arxiv.org/abs/2502.14070', 'abstract': 'Fine-tuning text-to-image diffusion models to maximize rewards has proven effective for enhancing model performance. However, reward fine-tuning methods often suffer from slow convergence due to online sample generation. Therefore, obtaining diverse samples with strong reward signals is crucial for improving sample efficiency and overall performance. In this work, we introduce DiffExp, a simple yet effective exploration strategy for reward fine-tuning of text-to-image models. Our approach employs two key strategies: (a) dynamically adjusting the scale of classifier-free guidance to enhance sample diversity, and (b) randomly weighting phrases of the text prompt to exploit high-quality reward signals. We demonstrate that these strategies significantly enhance exploration during online sample generation, improving the sample efficiency of recent reward fine-tuning methods, such as DDPO and AlignProp.', 'abstract_zh': 'Fine-tuning 文字到图像扩散模型以最大化奖励证明了可以有效提升模型性能。然而，奖励细调方法往往因在线样本生成缓慢而收敛较慢。因此，获得具有强烈奖励信号的多样化样本对于提高样本效率和整体性能至关重要。在本文中，我们引入了 DiffExp，这是一种简单有效的方法，用于奖励细调的文字到图像模型的探索策略。我们的方法采用了两种关键策略：(a) 动态调整无分类器引导的比例以增强样本多样性；(b) 随机加权文本提示中的短语以利用高质量的奖励信号。我们证明了这些策略显著提高了在线样本生成过程中的探索能力，提高了最近的奖励细调方法（如 DDPO 和 AlignProp）的样本效率。', 'title_zh': 'DiffExp: 奖励微调中高效探索的方法missive'}
{'arxiv_id': 'arXiv:2502.14068', 'title': 'A Racing Dataset and Baseline Model for Track Detection in Autonomous Racing', 'authors': 'Shreya Ghosh, Yi-Huan Chen, Ching-Hsiang Huang, Abu Shafin Mohammad Mahdee Jameel, Chien Chou Ho, Aly El Gamal, Samuel Labi', 'link': 'https://arxiv.org/abs/2502.14068', 'abstract': 'A significant challenge in racing-related research is the lack of publicly available datasets containing raw images with corresponding annotations for the downstream task. In this paper, we introduce RoRaTrack, a novel dataset that contains annotated multi-camera image data from racing scenarios for track detection. The data is collected on a Dallara AV-21 at a racing circuit in Indiana, in collaboration with the Indy Autonomous Challenge (IAC). RoRaTrack addresses common problems such as blurriness due to high speed, color inversion from the camera, and absence of lane markings on the track. Consequently, we propose RaceGAN, a baseline model based on a Generative Adversarial Network (GAN) that effectively addresses these challenges. The proposed model demonstrates superior performance compared to current state-of-the-art machine learning models in track detection. The dataset and code for this work are available at this http URL.', 'abstract_zh': '赛车相关研究中的一项重要挑战是缺乏包含对应标注的原始图像的公开数据集，用于下游任务。本文介绍了RoRaTrack，这是一种新颖的数据集，包含来自赛车场景的多摄像头图像标注数据，用于赛道检测。数据在印第安纳州的一个赛车场的Dallara AV-21上收集，与印第安纳自主挑战赛(IAC)合作收集。RoRaTrack解决了由于高速引起的模糊性、摄像头导致的颜色反转以及赛道上缺少车道标记等问题。因此，我们提出了基于生成对抗网络(GAN)的基准模型RaceGAN，有效解决了这些问题。所提出的模型在赛道检测方面表现出色，超过了当前最先进的机器学习模型。该项目的数据集和代码可在以下网址获得。', 'title_zh': '一种用于自主赛车道检测的数据集和基准模型'}
{'arxiv_id': 'arXiv:2502.14064', 'title': 'Triad: Vision Foundation Model for 3D Magnetic Resonance Imaging', 'authors': 'Shansong Wang, Mojtaba Safari, Qiang Li, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang', 'link': 'https://arxiv.org/abs/2502.14064', 'abstract': "Vision foundation models (VFMs) are pre-trained on extensive image datasets to learn general representations for diverse types of data. These models can subsequently be fine-tuned for specific downstream tasks, significantly boosting performance across a broad range of applications. However, existing vision foundation models that claim to be applicable to various radiology tasks are mostly pre-trained on 3D computed tomography (CT), which benefits from the availability of extensive 3D CT databases. Significant differences between CT and magnetic resonance imaging (MRI) in imaging principles, signal characteristics, and data distribution may hinder their practical performance and versatility in MRI-specific applications. Here, we propose Triad, a vision foundation model for 3D MRI. Triad adopts a widely used autoencoder architecture to learn robust representations from 131,170 3D MRI volumes and uses organ-independent imaging descriptions to constrain the semantic distribution of the visual modality. The above pre-training dataset is called Triad-131K, which is currently the largest 3D MRI pre-training dataset. We evaluate Triad across three tasks, namely, organ/tumor segmentation, organ/cancer classification, and medical image registration, in two data modalities (within-domain and out-of-domain) settings using 25 downstream datasets. By initializing models with Triad's pre-trained weights, nnUNet-Triad improves segmentation performance by 6.88% compared to nnUNet-Scratch across 17 datasets. Swin-B-Triad achieves a 3.97% improvement over Swin-B-Scratch in classification tasks across five datasets. SwinUNETR-Triad improves by 4.00% compared to SwinUNETR-Scratch in registration tasks across two datasets. Our study demonstrates that pre-training can maximize performance when the data modalities and organs of upstream and downstream tasks are consistent.", 'abstract_zh': '一种用于3D MRI的视觉基础模型：Triad', 'title_zh': 'Triad: 视觉基础模型用于3D磁共振成像'}
{'arxiv_id': 'arXiv:2502.14061', 'title': 'EfficientPose 6D: Scalable and Efficient 6D Object Pose Estimation', 'authors': 'Zixuan Fang, Thomas Pöllabauer, Tristan Wirth, Sarah Berkei, Volker Knauthe, Arjan Kuijper', 'link': 'https://arxiv.org/abs/2502.14061', 'abstract': 'In industrial applications requiring real-time feedback, such as quality control and robotic manipulation, the demand for high-speed and accurate pose estimation remains critical. Despite advances improving speed and accuracy in pose estimation, finding a balance between computational efficiency and accuracy poses significant challenges in dynamic environments. Most current algorithms lack scalability in estimation time, especially for diverse datasets, and the state-of-the-art (SOTA) methods are often too slow. This study focuses on developing a fast and scalable set of pose estimators based on GDRNPP to meet or exceed current benchmarks in accuracy and robustness, particularly addressing the efficiency-accuracy trade-off essential in real-time scenarios. We propose the AMIS algorithm to tailor the utilized model according to an application-specific trade-off between inference time and accuracy. We further show the effectiveness of the AMIS-based model choice on four prominent benchmark datasets (LM-O, YCB-V, T-LESS, and ITODD).', 'abstract_zh': '在需要实时反馈的工业应用中，如质量控制和机器人操作，对高速高精度姿态估计的需求仍然至关重要。尽管在姿态估计的速度和准确性方面取得了一定进展，但在动态环境中实现计算效率和准确性之间的平衡仍然面临重大挑战。现有算法在估计时间上的可扩展性普遍不足，尤其是在处理多样化的数据集时，最先进的方法往往速度过慢。本研究旨在基于GDRNPP开发快速且可扩展的姿态估计器，以达到或超越当前的准确性和鲁棒性基准，特别是在实时场景中解决效率-准确性权衡问题。我们提出了AMIS算法，以根据特定应用之间的推理时间和准确性的权衡来调整所使用的模型。我们进一步在四个典型的基准数据集（LM-O、YCB-V、T-LESS和ITODD）上展示了基于AMIS的模型选择的有效性。', 'title_zh': 'EfficientPose 6D: 可扩展且高效的6D物体姿态估计'}
{'arxiv_id': 'arXiv:2502.14050', 'title': 'Diversity-driven Data Selection for Language Model Tuning through Sparse Autoencoder', 'authors': 'Xianjun Yang, Shaoliang Nie, Lijuan Liu, Suchin Gururangan, Ujjwal Karn, Rui Hou, Madian Khabsa, Yuning Mao', 'link': 'https://arxiv.org/abs/2502.14050', 'abstract': 'Current pre-trained large language models typically need instruction tuning to align with human preferences. However, instruction tuning data is often quantity-saturated due to the large volume of data collection and fast model iteration, leaving coreset data selection important but underexplored. On the other hand, existing quality-driven data selection methods such as LIMA (NeurIPS 2023 (Zhou et al., 2024)) and AlpaGasus (ICLR 2024 (Chen et al.)) generally ignore the equal importance of data diversity and complexity. In this work, we aim to design a diversity-aware data selection strategy and creatively propose using sparse autoencoders to tackle the challenge of data diversity measure. In addition, sparse autoencoders can also provide more interpretability of model behavior and explain, e.g., the surprising effectiveness of selecting the longest response (ICML 2024 (Zhao et al.)). Using effective data selection, we experimentally prove that models trained on our selected data can outperform other methods in terms of model capabilities, reduce training cost, and potentially gain more control over model behaviors.', 'abstract_zh': '当前预训练的大语言模型通常需要指令调优以与人类偏好对齐。然而，由于数据采集量大和模型迭代速度快，指令调优数据往往已达到数量饱和，使得核心集数据选择变得重要但尚未得到充分探索。另一方面，现有的以质量为导向的数据选择方法，如LIMA（NeurIPS 2023，Zhou et al., 2024）和AlpaGasus（ICLR 2024，Chen et al.），通常忽视了数据多样性和复杂性同等重要的地位。在这项工作中，我们旨在设计一种多样性意识的数据选择策略，并创造性地提出使用稀疏自编码器来应对数据多样性的挑战度量问题。此外，稀疏自编码器还可以提供模型行为的更多可解释性，例如解释选择最长响应的惊人效果（ICML 2024，Zhao et al.）。通过有效的数据选择，我们实验证明，使用我们选择的数据训练的模型可以在模型能力、降低训练成本以及可能更好地控制模型行为方面超越其他方法。', 'title_zh': '基于稀疏自编码器的多样性驱动数据选择以调优语言模型'}
{'arxiv_id': 'arXiv:2502.14048', 'title': 'Semantic Decomposition and Selective Context Filtering -- Text Processing Techniques for Context-Aware NLP-Based Systems', 'authors': 'Karl John Villardar', 'link': 'https://arxiv.org/abs/2502.14048', 'abstract': "In this paper, we present two techniques for use in context-aware systems: Semantic Decomposition, which sequentially decomposes input prompts into a structured and hierarchal information schema in which systems can parse and process easily, and Selective Context Filtering, which enables systems to systematically filter out specific irrelevant sections of contextual information that is fed through a system's NLP-based pipeline. We will explore how context-aware systems and applications can utilize these two techniques in order to implement dynamic LLM-to-system interfaces, improve an LLM's ability to generate more contextually cohesive user-facing responses, and optimize complex automated workflows and pipelines.", 'abstract_zh': '本文介绍了两种应用于情境感知系统的技术：语义分解，该技术按顺序将输入提示分解为一种结构化和分层的信息模式，使系统能够轻松解析和处理；选择性情境过滤，该技术使系统能够系统地过滤掉特定的无关情境信息，这些信息通过系统的基于自然语言处理的工作流程传递。我们将探讨这两种技术如何应用于情境感知系统和应用，以实现动态的LLM-系统接口，提高LLM生成上下文连贯的用户面向响应的能力，并优化复杂的自动化工作流和管道。', 'title_zh': '语义分解与选择性语境过滤——面向语境感知NLP系统的文本处理技术'}
{'arxiv_id': 'arXiv:2502.14047', 'title': 'Towards a Learning Theory of Representation Alignment', 'authors': 'Francesco Insulla, Shuo Huang, Lorenzo Rosasco', 'link': 'https://arxiv.org/abs/2502.14047', 'abstract': "It has recently been argued that AI models' representations are becoming aligned as their scale and performance increase. Empirical analyses have been designed to support this idea and conjecture the possible alignment of different representations toward a shared statistical model of reality. In this paper, we propose a learning-theoretic perspective to representation alignment. First, we review and connect different notions of alignment based on metric, probabilistic, and spectral ideas. Then, we focus on stitching, a particular approach to understanding the interplay between different representations in the context of a task. Our main contribution here is relating properties of stitching to the kernel alignment of the underlying representation. Our results can be seen as a first step toward casting representation alignment as a learning-theoretic problem.", 'abstract_zh': 'AI模型表示的泛化对齐：一个学习理论视角', 'title_zh': '向表示对齐的学习理论迈进'}
{'arxiv_id': 'arXiv:2502.14045', 'title': 'Position: There are no Champions in Long-Term Time Series Forecasting', 'authors': 'Lorenzo Brigato, Rafael Morand, Knut Strømmen, Maria Panagiotou, Markus Schmidt, Stavroula Mougiakakou', 'link': 'https://arxiv.org/abs/2502.14045', 'abstract': 'Recent advances in long-term time series forecasting have introduced numerous complex prediction models that consistently outperform previously published architectures. However, this rapid progression raises concerns regarding inconsistent benchmarking and reporting practices, which may undermine the reliability of these comparisons. Our position emphasizes the need to shift focus away from pursuing ever-more complex models and towards enhancing benchmarking practices through rigorous and standardized evaluation methods. To support our claim, we first perform a broad, thorough, and reproducible evaluation of the top-performing models on the most popular benchmark by training 3,500+ networks over 14 datasets. Then, through a comprehensive analysis, we find that slight changes to experimental setups or current evaluation metrics drastically shift the common belief that newly published results are advancing the state of the art. Our findings suggest the need for rigorous and standardized evaluation methods that enable more substantiated claims, including reproducible hyperparameter setups and statistical testing.', 'abstract_zh': '近期长期时间序列预测的进展引入了众多复杂的预测模型，这些模型的一致性表现超过了此前发布的架构。然而，这一快速进步引发了关于不一致基准测试和报告实践的担忧，这可能损害这些比较的可靠性。我们的立场强调，应将重点从追求更复杂的模型转移到通过严格的标准化评估方法改进基准测试实践上。为了支持这一观点，我们首先在最受欢迎的基准上对表现最好的模型进行了全面、彻底且可重复的评估，训练了3,500多个网络，覆盖14个数据集。随后，通过全面分析发现，实验设置或当前评估指标的微小变化会极大地改变人们对新公布结果推动前沿技术进步的普遍认识。我们的研究结果表明，需要采用严格的标准化评估方法，以支持更加扎实的断言，包括可重复的超参数设置和统计测试。', 'title_zh': '长期时间序列预测中无冠军准则'}
{'arxiv_id': 'arXiv:2502.14043', 'title': 'Asking for Help Enables Safety Guarantees Without Sacrificing Effectiveness', 'authors': 'Benjamin Plaut, Juan Liévano-Karim, Stuart Russell', 'link': 'https://arxiv.org/abs/2502.14043', 'abstract': 'Most reinforcement learning algorithms with regret guarantees rely on a critical assumption: that all errors are recoverable. Recent work by Plaut et al. discarded this assumption and presented algorithms that avoid "catastrophe" (i.e., irreparable errors) by asking for help. However, they provided only safety guarantees and did not consider reward maximization. We prove that any algorithm that avoids catastrophe in their setting also guarantees high reward (i.e., sublinear regret) in any Markov Decision Process (MDP), including MDPs with irreversible costs. This constitutes the first no-regret guarantee for general MDPs. More broadly, our result may be the first formal proof that it is possible for an agent to obtain high reward while becoming self-sufficient in an unknown, unbounded, and high-stakes environment without causing catastrophe or requiring resets.', 'abstract_zh': '大多数具有遗憾保证的强化学习算法依赖于一个关键假设：所有错误都是可恢复的。Plaut等人的近期工作舍弃了这一假设，并提出了通过请求帮助来避免“灾难”（即不可恢复的错误）的算法。然而，他们仅提供了安全保证，并未考虑奖励最大化。我们证明，在他们设定的场景中，任何避免灾难的算法也将在任何马尔可夫决策过程（MDP）中保证高奖励（即亚线性遗憾）。这构成了对一般MDP的第一个无遗憾保证。更广泛地说，我们的结果可能是第一个形式证明，在未知、未 bound 和高风险的环境中，代理能够获得高奖励并变得自给自足而不会造成灾难或需要重置。', 'title_zh': '请求帮助能够在不牺牲有效性的情况下提供安全性保证。'}
{'arxiv_id': 'arXiv:2502.14037', 'title': 'DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation', 'authors': 'Giorgio Franceschelli, Mirco Musolesi', 'link': 'https://arxiv.org/abs/2502.14037', 'abstract': 'Despite their increasing performance, large language models still tend to reproduce training data, generate several repetitions, and focus on the most common grammatical structures and words. A possible cause is the decoding strategy adopted: the most common ones either consider only the most probable tokens, reducing output diversity, or increase the likelihood of unlikely tokens at the cost of output accuracy and correctness. In this paper, we propose a family of three new decoding methods by leveraging a mathematical analysis of the token probability distribution. In particular, the difference between consecutive, sorted probabilities can be used to avoid incorrect tokens and increase the chance of low-probable but accurate words. Experiments concerning math problem solving, extreme summarization, and the divergent association task show that our approach consistently performs at least as well as current alternatives in terms of quality and diversity.', 'abstract_zh': '尽管大型语言模型的性能不断提升，但仍倾向于复制训练数据、生成多次重复，并且集中在最常见的语法结构和词汇上。一种可能的原因是所采用的解码策略：最常见的策略要么只考虑最可能的词元，减少了输出的多样性，要么增加了不太可能的词元的概率，但牺牲了输出的准确性和正确性。本文通过利用词元概率分布的数学分析，提出了一类三种新的解码方法。具体而言，连续排列后的概率差可以用来避免错误的词元并增加低概率但准确的词汇出现的机会。关于数学问题求解、极端摘要和发散关联任务的实验表明，我们的方法在质量和多样性方面至少与当前替代方法相当。', 'title_zh': 'DiffSampling: 提升神经文本生成中的多样性和准确性'}
{'arxiv_id': 'arXiv:2502.14023', 'title': 'Dynamic Activation with Knowledge Distillation for Energy-Efficient Spiking NN Ensembles', 'authors': 'Orestis Konstantaropoulos, Theodoris Mallios, Maria Papadopouli', 'link': 'https://arxiv.org/abs/2502.14023', 'abstract': "While foundation AI models excel at tasks like classification and decision-making, their high energy consumption makes them unsuitable for energy-constrained applications. Inspired by the brain's efficiency, spiking neural networks (SNNs) have emerged as a viable alternative due to their event-driven nature and compatibility with neuromorphic chips. This work introduces a novel system that combines knowledge distillation and ensemble learning to bridge the performance gap between artificial neural networks (ANNs) and SNNs. A foundation AI model acts as a teacher network, guiding smaller student SNNs organized into an ensemble, called Spiking Neural Ensemble (SNE). SNE enables the disentanglement of the teacher's knowledge, allowing each student to specialize in predicting a distinct aspect of it, while processing the same input. The core innovation of SNE is the adaptive activation of a subset of SNN models of an ensemble, leveraging knowledge-distillation, enhanced with an informed-partitioning (disentanglement) of the teacher's feature space. By dynamically activating only a subset of these student SNNs, the system balances accuracy and energy efficiency, achieving substantial energy savings with minimal accuracy loss. Moreover, SNE is significantly more efficient than the teacher network, reducing computational requirements by up to 20x with only a 2% drop in accuracy on the CIFAR-10 dataset. This disentanglement procedure achieves an accuracy improvement of up to 2.4% on the CIFAR-10 dataset compared to other partitioning schemes. Finally, we comparatively analyze SNE performance under noisy conditions, demonstrating enhanced robustness compared to its ANN teacher. In summary, SNE offers a promising new direction for energy-constrained applications.", 'abstract_zh': '一种结合知识蒸馏和集成学习的事件触发神经网络系统：提高能量效率的同时保持性能', 'title_zh': '知识蒸馏指导的动态激活用于节能Spiking NN集成'}
{'arxiv_id': 'arXiv:2502.14019', 'title': 'Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems', 'authors': 'Myra Cheng, Su Lin Blodgett, Alicia DeVrio, Lisa Egede, Alexandra Olteanu', 'link': 'https://arxiv.org/abs/2502.14019', 'abstract': "As text generation systems' outputs are increasingly anthropomorphic -- perceived as human-like -- scholars have also raised increasing concerns about how such outputs can lead to harmful outcomes, such as users over-relying or developing emotional dependence on these systems. How to intervene on such system outputs to mitigate anthropomorphic behaviors and their attendant harmful outcomes, however, remains understudied. With this work, we aim to provide empirical and theoretical grounding for developing such interventions. To do so, we compile an inventory of interventions grounded both in prior literature and a crowdsourced study where participants edited system outputs to make them less human-like. Drawing on this inventory, we also develop a conceptual framework to help characterize the landscape of possible interventions, articulate distinctions between different types of interventions, and provide a theoretical basis for evaluating the effectiveness of different interventions.", 'abstract_zh': '随着文本生成系统生成的输出越来越具拟人性，被人感知为类似人类，学者们也对这些输出可能导致的不良后果表达了越来越多的担忧，例如用户过度依赖或产生情感依赖于这些系统。如何干预这些系统输出以减少拟人性行为及其伴随的不良后果仍研究不足。通过这项工作，我们旨在为开发此类干预措施提供实证和理论基础。为此，我们编制了一份基于先前文献和一项众包研究的干预措施清单，在这项众包研究中，参与者编辑系统输出以使其显得不那么拟人性。利用这份清单，我们还开发了一个概念框架，以帮助描述可能的干预措施 landscape、区分不同类型干预措施，并为评估不同干预措施的有效性提供理论基础。', 'title_zh': '人性化机器：减轻文本生成系统中的拟人类化行为'}
{'arxiv_id': 'arXiv:2502.14013', 'title': 'Appeal prediction for AI up-scaled Images', 'authors': 'Steve Göring, Rasmus Merten, Alexander Raake', 'link': 'https://arxiv.org/abs/2502.14013', 'abstract': 'DNN- or AI-based up-scaling algorithms are gaining in popularity due to the improvements in machine learning. Various up-scaling models using CNNs, GANs or mixed approaches have been published. The majority of models are evaluated using PSRN and SSIM or only a few example images. However, a performance evaluation with a wide range of real-world images and subjective evaluation is missing, which we tackle in the following paper. For this reason, we describe our developed dataset, which uses 136 base images and five different up-scaling methods, namely Real-ESRGAN, BSRGAN, waifu2x, KXNet, and Lanczos. Overall the dataset consists of 1496 annotated images. The labeling of our dataset focused on image appeal and has been performed using crowd-sourcing employing our open-source tool AVRate Voyager. We evaluate the appeal of the different methods, and the results indicate that Real-ESRGAN and BSRGAN are the best. Furthermore, we train a DNN to detect which up-scaling method has been used, the trained models have a good overall performance in our evaluation. In addition to this, we evaluate state-of-the-art image appeal and quality models, here none of the models showed a high prediction performance, therefore we also trained two own approaches. The first uses transfer learning and has the best performance, and the second model uses signal-based features and a random forest model with good overall performance. We share the data and implementation to allow further research in the context of open science.', 'abstract_zh': '基于DNN或AI的比例缩放算法得益于机器学习的进步而日益流行。使用CNN、GAN或混合方法的各种比例缩放模型已被发表。大多数模型仅使用PSNR和SSIM进行评估，或仅使用少数几个示例图像。然而，缺乏针对广泛真实世界图像和主观评价的性能评估，这是我们在本文中解决的问题。为此，我们描述了所开发的数据集，该数据集使用136张基础图像和五种不同的缩放方法，即Real-ESRGAN、BSRGAN、waifu2x、KXNet和Lanczos。整体而言，数据集包含1496张标注图像。我们数据集的标签聚焦于图像吸引力，并使用众包方法通过我们的开源工具AVRate Voyager进行标注。我们评估了不同方法的吸引力，结果表明Real-ESRGAN和BSRGAN表现最佳。此外，我们训练了一个DNN以识别已使用的缩放方法，训练模型在评估中表现出良好的整体性能。此外，我们还评估了最新图像吸引力和质量模型，其中没有任何模型表现出高的预测性能，因此我们还训练了两种自有方法。第一种方法使用迁移学习，性能最佳，第二种模型使用基于信号的特征和随机森林模型，整体性能良好。我们分享了数据和实现，以便在开放科学的背景下进行进一步研究。', 'title_zh': 'AI增强图像的吸引力预测'}
{'arxiv_id': 'arXiv:2502.14011', 'title': 'DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge Devices', 'authors': 'Afonso Lourenço, João Rodrigo, João Gama, Goreti Marreiros', 'link': 'https://arxiv.org/abs/2502.14011', 'abstract': 'The Internet of Things generates massive data streams, with edge computing emerging as a key enabler for online IoT applications and 5G networks. Edge solutions facilitate real-time machine learning inference, but also require continuous adaptation to concept drifts. Ensemble-based solutions improve predictive performance, but incur higher resource consumption, latency, and memory demands. This paper presents DFDT: Dynamic Fast Decision Tree, a novel algorithm designed for energy-efficient memory-constrained data stream mining. DFDT improves hoeffding tree growth efficiency by dynamically adjusting grace periods, tie thresholds, and split evaluations based on incoming data. It incorporates stricter evaluation rules (based on entropy, information gain, and leaf instance count), adaptive expansion modes, and a leaf deactivation mechanism to manage memory, allowing more computation on frequently visited nodes while conserving energy on others. Experiments show that the proposed framework can achieve increased predictive performance (0.43 vs 0.29 ranking) with constrained memory and a fraction of the runtime of VFDT or SVFDT.', 'abstract_zh': '物联网生成大量数据流，边缘计算作为关键使能器促进了在线物联网应用和5G网络的发展。边缘解决方案支持实时机器学习推理，但也需要持续适应概念漂移。基于集成的方法可以提高预测性能，但会导致更高的资源消耗、延迟和内存需求。本文提出DFDT：动态快速决策树，一种针对能量高效和内存受限的数据流挖掘的新型算法。DFDT通过根据流入数据动态调整宽限期、平局阈值和分裂评估来提高霍夫丁树的增长效率。该算法结合了更严格的评估规则（基于熵、信息增益和叶节点实例计数），自适应扩展模式以及叶节点去激活机制来管理内存，从而在经常访问的节点上进行更多计算，而在其他节点上节省能量。实验结果显示，所提出的框架在受限内存和VFDT或SVFDT较少的运行时间内可以实现更高的预测性能（排名从0.29提升到0.43）。', 'title_zh': 'DFDT：边缘设备上物联网数据流 Mining 的动态快速决策树'}
{'arxiv_id': 'arXiv:2502.14010', 'title': 'Which Attention Heads Matter for In-Context Learning?', 'authors': 'Kayo Yin, Jacob Steinhardt', 'link': 'https://arxiv.org/abs/2502.14010', 'abstract': 'Large language models (LLMs) exhibit impressive in-context learning (ICL) capability, enabling them to perform new tasks using only a few demonstrations in the prompt. Two different mechanisms have been proposed to explain ICL: induction heads that find and copy relevant tokens, and function vector (FV) heads whose activations compute a latent encoding of the ICL task. To better understand which of the two distinct mechanisms drives ICL, we study and compare induction heads and FV heads in 12 language models.\nThrough detailed ablations, we discover that few-shot ICL performance depends primarily on FV heads, especially in larger models. In addition, we uncover that FV and induction heads are connected: many FV heads start as induction heads during training before transitioning to the FV mechanism. This leads us to speculate that induction facilitates learning the more complex FV mechanism that ultimately drives ICL.', 'abstract_zh': '大型语言模型（LLMs）展现出令人印象深刻的上下文内学习（ICL）能力，能够在提示中仅通过几个示范执行新任务。有两种不同的机制被提出解释ICL：归纳头部通过查找和复制相关tokens，以及功能向量（FV）头部，其激活计算ICL任务的潜在编码。为了更好地理解是哪种机制驱动ICL，我们研究并比较了12种语言模型中的归纳头部和FV头部。通过详细的消融实验，我们发现少量样本的ICL性能主要依赖于FV头部，尤其是在较大模型中。此外，我们发现FV头部和归纳头部之间存在联系：许多FV头部在训练过程中最初是归纳头部，之后转变为FV机制。这使我们推测，归纳过程有助于学习更复杂的FV机制，最终驱动ICL。', 'title_zh': '上下文学习中哪些注意力头更重要？'}
{'arxiv_id': 'arXiv:2502.14008', 'title': 'MaskPrune: Mask-based LLM Pruning for Layer-wise Uniform Structures', 'authors': 'Jiayu Qin, Jianchao Tan, Kefeng Zhang, Xunliang Cai, Wei Wang', 'link': 'https://arxiv.org/abs/2502.14008', 'abstract': 'The remarkable performance of large language models (LLMs) in various language tasks has attracted considerable attention. However, the ever-increasing size of these models presents growing challenges for deployment and inference. Structured pruning, an effective model compression technique, is gaining increasing attention due to its ability to enhance inference efficiency. Nevertheless, most previous optimization-based structured pruning methods sacrifice the uniform structure across layers for greater flexibility to maintain performance. The heterogeneous structure hinders the effective utilization of off-the-shelf inference acceleration techniques and impedes efficient configuration for continued training. To address this issue, we propose a novel masking learning paradigm based on minimax optimization to obtain the uniform pruned structure by optimizing the masks under sparsity regularization. Extensive experimental results demonstrate that our method can maintain high performance while ensuring the uniformity of the pruned model structure, thereby outperforming existing SOTA methods.', 'abstract_zh': '大型语言模型在各类语言任务中的出色表现吸引了广泛关注。然而，这些模型日益增大的规模给部署和推理带来了不断增加的挑战。基于最小最大化优化的新型掩码学习范式通过在稀疏正则化下优化掩码获得了均匀的裁剪结构，有效模型压缩技术因此能够提高推理效率。尽管大多数基于优化的结构化裁剪方法牺牲了层间的一致性以换取更大的灵活性从而维持性能，但异构结构阻碍了现成推理加速技术的有效利用，并阻碍了持续训练的高效配置。为解决这一问题，我们提出了一种基于最小最大化优化的新型掩码学习范式，通过在稀疏正则化下优化掩码获得了均匀的裁剪结构，从而在保持高性能的同时优于现有最佳方法。', 'title_zh': 'MaskPrune: 基于掩码的层级均匀结构大语言模型剪枝'}
{'arxiv_id': 'arXiv:2502.14003', 'title': 'Rectified Lagrangian for Out-of-Distribution Detection in Modern Hopfield Networks', 'authors': 'Ryo Moriai, Nakamasa Inoue, Masayuki Tanaka, Rei Kawakami, Satoshi Ikehata, Ikuro Sato', 'link': 'https://arxiv.org/abs/2502.14003', 'abstract': 'Modern Hopfield networks (MHNs) have recently gained significant attention in the field of artificial intelligence because they can store and retrieve a large set of patterns with an exponentially large memory capacity. A MHN is generally a dynamical system defined with Lagrangians of memory and feature neurons, where memories associated with in-distribution (ID) samples are represented by attractors in the feature space. One major problem in existing MHNs lies in managing out-of-distribution (OOD) samples because it was originally assumed that all samples are ID samples. To address this, we propose the rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that explicitly incorporates an attractor for OOD samples in the dynamical system of MHNs. RecLag creates a trivial point attractor for any interaction matrix, enabling OOD detection by identifying samples that fall into this attractor as OOD. The interaction matrix is optimized so that the probability densities can be estimated to identify ID/OOD. We demonstrate the effectiveness of RecLag-based MHNs compared to energy-based OOD detection methods, including those using state-of-the-art Hopfield energies, across nine image datasets.', 'abstract_zh': '现代霍普菲尔德网络（MHNs）近年来在人工智能领域引起了广泛关注，因为它们能够存储和检索大量模式，并具有指数级大的记忆容量。在现有的MHNs中，管理来自分布外（OOD）样本是一个主要问题，因为最初假设所有样本都是来自分布内（ID）样本。为了应对这一挑战，我们提出了修正拉格朗日（RegLag），这是一种新的用于记忆神经元的拉格朗日函数，它在MHN的动力系统中显式地引入了OOD样本的吸引子。RecLag通过在任何交互矩阵下创建一个平凡的点吸引子，使得可以通过识别落入该吸引子的样本来检测OOD。交互矩阵被优化以估计概率密度，从而识别ID和OOD样本。我们展示了基于RecLag的MHNs在九个图像数据集上的有效性和与基于能量的OOD检测方法（包括最先进的霍普菲尔德能量方法）的比较。', 'title_zh': '修正后的拉格朗日乘子法在现代霍普菲尔德网络中的离分布检测'}
{'arxiv_id': 'arXiv:2502.14001', 'title': 'Towards a perturbation-based explanation for medical AI as differentiable programs', 'authors': 'Takeshi Abe, Yoshiyuki Asai', 'link': 'https://arxiv.org/abs/2502.14001', 'abstract': 'Recent advancement in machine learning algorithms reaches a point where medical devices can be equipped with artificial intelligence (AI) models for diagnostic support and routine automation in clinical settings. In medicine and healthcare, there is a particular demand for sufficient and objective explainability of the outcome generated by AI models. However, AI models are generally considered as black boxes due to their complexity, and the computational process leading to their response is often opaque. Although several methods have been proposed to explain the behavior of models by evaluating the importance of each feature in discrimination and prediction, they may suffer from biases and opacities arising from the scale and sampling protocol of the dataset used for training or testing. To overcome the shortcomings of existing methods, we explore an alternative approach to provide an objective explanation of AI models that can be defined independently of the learning process and does not require additional data. As a preliminary study for this direction of research, this work examines a numerical availability of the Jacobian matrix of deep learning models that measures how stably a model responses against small perturbations added to the input. The indicator, if available, are calculated from a trained AI model for a given target input. This is a first step towards a perturbation-based explanation, which will assist medical practitioners in understanding and interpreting the response of the AI model in its clinical application.', 'abstract_zh': '最近机器学习算法的发展使得医疗设备能够配备人工智能模型以提供诊断支持和临床环境中的常规自动化。在医学和医疗保健领域，特别是需要足够的客观解释AI模型生成的结果。然而，由于其复杂性，AI模型通常被视为黑 box，并且其触发响应的计算过程往往是不透明的。尽管已经提出了一些方法通过评估每个特征在鉴别和预测中的重要性来解释模型的行为，但它们可能会因训练或测试所用数据集的规模和采样方案而产生偏见和不透明性。为了克服现有方法的局限性，我们探索了一种替代方法，旨在提供一种独立于学习过程的客观解释，无需额外数据。作为这一研究方向的初步研究，本工作检查了深度学习模型雅可比矩阵的数值可用性，以衡量在输入中添加小扰动时模型响应的稳定性。如果可用，该指标将从给定的目标输入训练的AI模型中计算得出。这是基于扰动的解释的第一步，将帮助医疗专业人员理解并解释AI模型在临床应用中的响应。', 'title_zh': '基于扰动的解释：医疗AI可微程序的方法'}
{'arxiv_id': 'arXiv:2502.14000', 'title': 'Human-Artificial Interaction in the Age of Agentic AI: A System-Theoretical Approach', 'authors': 'Uwe M. Borghoff, Paolo Bottoni, Remo Pareschi', 'link': 'https://arxiv.org/abs/2502.14000', 'abstract': 'This paper presents a novel perspective on human-computer interaction (HCI), framing it as a dynamic interplay between human and computational agents within a networked system. Going beyond traditional interface-based approaches, we emphasize the importance of coordination and communication among heterogeneous agents with different capabilities, roles, and goals. A key distinction is made between multi-agent systems (MAS) and Centaurian systems, which represent two different paradigms of human-AI collaboration. MAS maintain agent autonomy, with structured protocols enabling cooperation, while Centaurian systems deeply integrate human and AI capabilities, creating unified decision-making entities.\nTo formalize these interactions, we introduce a framework for communication spaces, structured into surface, observation, and computation layers, ensuring seamless integration between MAS and Centaurian architectures, where colored Petri nets effectively represent structured Centaurian systems and high-level reconfigurable networks address the dynamic nature of MAS.\nOur research has practical applications in autonomous robotics, human-in-the-loop decision making, and AI-driven cognitive architectures, and provides a foundation for next-generation hybrid intelligence systems that balance structured coordination with emergent behavior.', 'abstract_zh': '本文从一个新的角度探讨了人机交互（HCI），将其视为网络系统中人类代理与计算代理之间动态交互的过程。超越传统的基于界面的方法，我们强调了不同能力、角色和目标的异构代理之间的协调和通信的重要性。我们区分了多代理系统（MAS）和半人马系统（Centaurian systems），两者代表了人类与人工智能合作的两种不同范式。MAS维护代理的自主性，通过结构化的协议实现合作，而半人马系统则深度融合了人类和人工智能的能力，创建统一的决策实体。\n\n为了正式化这些交互，我们引入了一种通信空间框架，分为表面、观测和计算三层，确保了MAS和半人马系统架构之间的无缝集成，其中彩色Petri网有效地表示了结构化的半人马系统，而高级可重构网络则应对了MAS的动态性质。\n\n我们的研究成果在自主机器人、人机环决策以及基于AI的认知架构中有实际应用，并为下一代平衡结构化协调与涌现行为的混合智能系统奠定了基础。', 'title_zh': '代理人工智能时代的主-机互动：一种系统理论的方法'}
{'arxiv_id': 'arXiv:2502.13998', 'title': 'A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior', 'authors': 'Hengyue Liang, Taihui Li, Ju Sun', 'link': 'https://arxiv.org/abs/2502.13998', 'abstract': 'Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse.', 'abstract_zh': '一种黑盒方法用于去除不可见图像水印', 'title_zh': '基于深度图像先验的隐形图像水印去除基线方法'}
{'arxiv_id': 'arXiv:2502.13994', 'title': 'Generative Detail Enhancement for Physically Based Materials', 'authors': 'Saeed Hadadan, Benedikt Bitterli, Tizian Zeltner, Jan Novák, Fabrice Rousselle, Jacob Munkberg, Jon Hasselgren, Bartlomiej Wronski, Matthias Zwicker', 'link': 'https://arxiv.org/abs/2502.13994', 'abstract': 'We present a tool for enhancing the detail of physically based materials using an off-the-shelf diffusion model and inverse rendering. Our goal is to enhance the visual fidelity of materials with detail that is often tedious to author, by adding signs of wear, aging, weathering, etc. As these appearance details are often rooted in real-world processes, we leverage a generative image model trained on a large dataset of natural images with corresponding visuals in context. Starting with a given geometry, UV mapping, and basic appearance, we render multiple views of the object. We use these views, together with an appearance-defining text prompt, to condition a diffusion model. The details it generates are then backpropagated from the enhanced images to the material parameters via inverse differentiable rendering. For inverse rendering to be successful, the generated appearance has to be consistent across all the images. We propose two priors to address the multi-view consistency of the diffusion model. First, we ensure that the initial noise that seeds the diffusion process is itself consistent across views by integrating it from a view-independent UV space. Second, we enforce geometric consistency by biasing the attention mechanism via a projective constraint so that pixels attend strongly to their corresponding pixel locations in other views. Our approach does not require any training or finetuning of the diffusion model, is agnostic of the material model used, and the enhanced material properties, i.e., 2D PBR textures, can be further edited by artists.', 'abstract_zh': '一种使用现成扩散模型和逆渲染增强物理基于材料细节的工具', 'title_zh': '基于物理的材料的生成细节增强'}
{'arxiv_id': 'arXiv:2502.13991', 'title': 'Learning to Discover Regulatory Elements for Gene Expression Prediction', 'authors': 'Xingyu Su, Haiyang Yu, Degui Zhi, Shuiwang Ji', 'link': 'https://arxiv.org/abs/2502.13991', 'abstract': 'We consider the problem of predicting gene expressions from DNA sequences. A key challenge of this task is to find the regulatory elements that control gene expressions. Here, we introduce Seq2Exp, a Sequence to Expression network explicitly designed to discover and extract regulatory elements that drive target gene expression, enhancing the accuracy of the gene expression prediction. Our approach captures the causal relationship between epigenomic signals, DNA sequences and their associated regulatory elements. Specifically, we propose to decompose the epigenomic signals and the DNA sequence conditioned on the causal active regulatory elements, and apply an information bottleneck with the Beta distribution to combine their effects while filtering out non-causal components. Our experiments demonstrate that Seq2Exp outperforms existing baselines in gene expression prediction tasks and discovers influential regions compared to commonly used statistical methods for peak detection such as MACS3. The source code is released as part of the AIRS library (this https URL).', 'abstract_zh': '从DNA序列预测基因表达：Seq2Exp网络的设计与应用', 'title_zh': '学习发现调控元件以预测基因表达'}
{'arxiv_id': 'arXiv:2502.13983', 'title': 'Gesture-Aware Zero-Shot Speech Recognition for Patients with Language Disorders', 'authors': 'Seungbae Kim, Daeun Lee, Brielle Stark, Jinyoung Han', 'link': 'https://arxiv.org/abs/2502.13983', 'abstract': 'Individuals with language disorders often face significant communication challenges due to their limited language processing and comprehension abilities, which also affect their interactions with voice-assisted systems that mostly rely on Automatic Speech Recognition (ASR). Despite advancements in ASR that address disfluencies, there has been little attention on integrating non-verbal communication methods, such as gestures, which individuals with language disorders substantially rely on to supplement their communication. Recognizing the need to interpret the latent meanings of visual information not captured by speech alone, we propose a gesture-aware ASR system utilizing a multimodal large language model with zero-shot learning for individuals with speech impairments. Our experiment results and analyses show that including gesture information significantly enhances semantic understanding. This study can help develop effective communication technologies, specifically designed to meet the unique needs of individuals with language impairments.', 'abstract_zh': '基于手势的自动语音识别系统：适用于语言障碍个体的多模态大语言模型研究', 'title_zh': '语言障碍患者面向手势的零样本语音识别'}
{'arxiv_id': 'arXiv:2502.13979', 'title': 'Utilizing Effective Dynamic Graph Learning to Shield Financial Stability from Risk Propagation', 'authors': 'Guanyuan Yu, Qing Li, Yu Zhao, Jun Wang, YiJun Chen, Shaolei Chen', 'link': 'https://arxiv.org/abs/2502.13979', 'abstract': 'Financial risks can propagate across both tightly coupled temporal and spatial dimensions, posing significant threats to financial stability. Moreover, risks embedded in unlabeled data are often difficult to detect. To address these challenges, we introduce GraphShield, a novel approach with three key innovations: Enhanced Cross-Domain Infor mation Learning: We propose a dynamic graph learning module to improve information learning across temporal and spatial domains. Advanced Risk Recognition: By leveraging the clustering characteristics of risks, we construct a risk recognizing module to enhance the identification of hidden threats. Risk Propagation Visualization: We provide a visualization tool for quantifying and validating nodes that trigger widespread cascading risks. Extensive experiments on two real-world and two open-source datasets demonstrate the robust performance of our framework. Our approach represents a significant advancement in leveraging artificial intelligence to enhance financial stability, offering a powerful solution to mitigate the spread of risks within financial networks.', 'abstract_zh': '金融风险可以在紧密耦合的时间和空间维度上传播，对金融稳定构成重大威胁。此外，嵌入未标记数据中的风险往往难以检测。为应对这些挑战，我们介绍了GraphShield这一新型方法，具备三大创新：增强跨域信息学习：我们提出了一种动态图学习模块，以提高跨时间和空间域的信息学习能力。高级风险识别：通过利用风险的聚类特性，我们构建了一种风险识别模块，以增强对潜在威胁的识别能力。风险传播可视化：我们提供了可视化工具，用于量化和验证触发广泛传导风险的节点。在两个真实世界和两个开源数据集上的广泛实验表明，该框架具有稳健的性能。我们的方法代表了利用人工智能增强金融稳定的显著进展，提供了一种强大的解决方案，以减轻金融网络内风险的传播。', 'title_zh': '利用有效的动态图学习来屏蔽金融稳定性免受风险传播的影响'}
{'arxiv_id': 'arXiv:2502.13972', 'title': 'IncepFormerNet: A multi-scale multi-head attention network for SSVEP classification', 'authors': 'Yan Huang, Yongru Chen, Lei Cao, Yongnian Cao, Xuechun Yang, Yilin Dong, Tianyu Liu', 'link': 'https://arxiv.org/abs/2502.13972', 'abstract': 'In recent years, deep learning (DL) models have shown outstanding performance in EEG classification tasks, particularly in Steady-State Visually Evoked Potential(SSVEP)-based Brain-Computer-Interfaces(BCI)systems. DL methods have been successfully applied to SSVEP-BCI. This study proposes a new model called IncepFormerNet, which is a hybrid of the Inception and Transformer architectures. IncepFormerNet adeptly extracts multi-scale temporal information from time series data using parallel convolution kernels of varying sizes, accurately capturing the subtle variations and critical features within SSVEP this http URL, the model integrates the multi-head attention mechanism from the Transformer architecture, which not only provides insights into global dependencies but also significantly enhances the understanding and representation of complex this http URL, it takes advantage of filter bank techniques to extract features based on the spectral characteristics of SSVEP data. To validate the effectiveness of the proposed model, we conducted experiments on two public datasets, . The experimental results show that IncepFormerNet achieves an accuracy of 87.41 on Dataset 1 and 71.97 on Dataset 2 using a 1.0-second time window. To further verify the superiority of the proposed model, we compared it with other deep learning models, and the results indicate that our method achieves significantly higher accuracy than the this http URL source codes in this work are available at: this https URL.', 'abstract_zh': '近年来，深度学习（DL）模型在脑电图（EEG）分类任务中表现出色，特别是在基于稳定状态视性诱发电位（SSVEP）的脑-机接口（BCI）系统中。深度学习方法已被成功应用于SSVEP-BCI系统。本研究提出了一种名为IncepFormerNet的新模型，该模型是Inception和Transformer架构的 hybrid。IncepFormerNet利用不同大小的并行卷积内核有效地从时间序列数据中提取多尺度时域信息，准确捕捉SSVEP中的微小变化和关键特征。该模型整合了Transformer架构中的多头注意力机制，不仅提供了全局依赖性的洞察，还显著增强了复杂信号的理解和表示。通过滤波器银行技术，IncepFormerNet基于SSVEP数据的频谱特性提取特征。为了验证所提模型的有效性，我们在两个公开数据集上进行了实验。实验结果表明，IncepFormerNet在数据集1中的准确率为87.41%，在数据集2中的准确率为71.97%。为了进一步验证所提模型的优越性，我们将其与其他深度学习模型进行了比较，结果表明我们的方法在准确率上显著优于其他方法。本文的源代码可在以下网址获取：this https URL。', 'title_zh': 'IncepFormerNet：一种多尺度多头注意力网络的SSVEP分类'}
{'arxiv_id': 'arXiv:2502.13969', 'title': 'Bridging Simulation and Reality: A 3D Clustering-Based Deep Learning Model for UAV-Based RF Source Localization', 'authors': 'Saad Masrur, Ismail Guvenc', 'link': 'https://arxiv.org/abs/2502.13969', 'abstract': 'Localization of radio frequency (RF) sources has critical applications, including search and rescue, jammer detection, and monitoring of hostile activities. Unmanned aerial vehicles (UAVs) offer significant advantages for RF source localization (RFSL) over terrestrial methods, leveraging autonomous 3D navigation and improved signal capture at higher altitudes. Recent advancements in deep learning (DL) have further enhanced localization accuracy, particularly for outdoor scenarios. DL models often face challenges in real-world performance, as they are typically trained on simulated datasets that fail to replicate real-world conditions fully. To address this, we first propose the Enhanced Two-Ray propagation model, reducing the simulation-to-reality gap by improving the accuracy of propagation environment modeling. For RFSL, we propose the 3D Cluster-Based RealAdaptRNet, a DL-based method leveraging 3D clustering-based feature extraction for robust localization. Experimental results demonstrate that the proposed Enhanced Two-Ray model provides superior accuracy in simulating real-world propagation scenarios compared to conventional free-space and two-ray models. Notably, the 3D Cluster-Based RealAdaptRNet, trained entirely on simulated datasets, achieves exceptional performance when validated in real-world environments using the AERPAW physical testbed, with an average localization error of 18.2 m. The proposed approach is computationally efficient, utilizing 33.5 times fewer parameters, and demonstrates strong generalization capabilities across diverse trajectories, making it highly suitable for real-world applications.', 'abstract_zh': '基于增强两径传播模型的3D集群自适应DL定位方法及其在真实环境中的应用', 'title_zh': '基于3D聚类的深度学习模型：无人机RF源定位的仿真与现实桥梁'}
