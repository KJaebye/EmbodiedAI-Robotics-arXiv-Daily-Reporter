{'arxiv_id': 'arXiv:2502.14581', 'title': 'A Statistical Case Against Empirical Human-AI Alignment', 'authors': 'Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin', 'link': 'https://arxiv.org/abs/2502.14581', 'abstract': 'Empirical human-AI alignment aims to make AI systems act in line with observed human behavior. While noble in its goals, we argue that empirical alignment can inadvertently introduce statistical biases that warrant caution. This position paper thus advocates against naive empirical alignment, offering prescriptive alignment and a posteriori empirical alignment as alternatives. We substantiate our principled argument by tangible examples like human-centric decoding of language models.', 'abstract_zh': '经验性人机对齐旨在使AI系统的行为与观察到的人类行为一致。虽然其目标高尚，但我们认为经验性对齐可能会无意中引入统计偏差，值得谨慎对待。因此，本文立场主张反对简单的经验性对齐，提出规范性对齐和事后经验性对齐作为替代方案。我们通过以人类为中心的语言模型解码等具体例子来支撑我们的原则性论点。', 'title_zh': '统计学上对经验性人类-人工智能对齐的反驳'}
{'arxiv_id': 'arXiv:2502.14491', 'title': 'Statistical Scenario Modelling and Lookalike Distributions for Multi-Variate AI Risk', 'authors': 'Elija Perrier', 'link': 'https://arxiv.org/abs/2502.14491', 'abstract': 'Evaluating AI safety requires statistically rigorous methods and risk metrics for understanding how the use of AI affects aggregated risk. However, much AI safety literature focuses upon risks arising from AI models in isolation, lacking consideration of how modular use of AI affects risk distribution of workflow components or overall risk metrics. There is also a lack of statistical grounding enabling sensitisation of risk models in the presence of absence of AI to estimate causal contributions of AI. This is in part due to the dearth of AI impact data upon which to fit distributions. In this work, we address these gaps in two ways. First, we demonstrate how scenario modelling (grounded in established statistical techniques such as Markov chains, copulas and Monte Carlo simulation) can be used to model AI risk holistically. Second, we show how lookalike distributions from phenomena analogous to AI can be used to estimate AI impacts in the absence of directly observable data. We demonstrate the utility of our methods for benchmarking cumulative AI risk via risk analysis of a logistic scenario simulations.', 'abstract_zh': '评估AI安全需要统计严谨的方法和风险管理指标，以理解AI的使用如何影响综合风险。然而，大部分AI安全文献主要关注AI模型本身带来的风险，忽视了模块化使用AI如何影响工作流组件的风险分布或整体风险指标。此外，缺乏统计基础使得在有无AI的情况下敏感化风险模型以估计AI的因果贡献也面临挑战。这主要是由于缺乏合适的AI影响数据来拟合分布。在本工作中，我们从两个方面来填补这些空白。首先，我们展示了如何通过基于已确立的统计技术（如马尔可夫链、合成变量和蒙特卡洛模拟）的场景建模来全面建模AI风险。其次，我们展示了如何利用类似AI现象的模拟分布来估计在缺乏直接可观测数据时的AI影响。我们通过逻辑情景模拟的风险分析来验证我们方法在基准累计AI风险方面的适用性。', 'title_zh': '统计情景建模和多变量AI风险的类似分布方法'}
{'arxiv_id': 'arXiv:2502.14456', 'title': 'Narrative-Driven Travel Planning: Geoculturally-Grounded Script Generation with Evolutionary Itinerary Optimization', 'authors': 'Ran Ding, Ziyu Zhang, Ying Zhu, Ziqian Kong, Peilan Xu', 'link': 'https://arxiv.org/abs/2502.14456', 'abstract': "To enhance tourists' experiences and immersion, this paper proposes a narrative-driven travel planning framework called NarrativeGuide, which generates a geoculturally-grounded narrative script for travelers, offering a novel, role-playing experience for their journey. In the initial stage, NarrativeGuide constructs a knowledge graph for attractions within a city, then configures the worldview, character setting, and exposition based on the knowledge graph. Using this foundation, the knowledge graph is combined to generate an independent scene unit for each attraction. During the itinerary planning stage, NarrativeGuide models narrative-driven travel planning as an optimization problem, utilizing a genetic algorithm (GA) to refine the itinerary. Before evaluating the candidate itinerary, transition scripts are generated for each pair of adjacent attractions, which, along with the scene units, form a complete script. The weighted sum of script coherence, travel time, and attraction scores is then used as the fitness value to update the candidate solution set. Experimental results across four cities, i.e., Nanjing and Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate significant improvements in narrative coherence and cultural fit, alongside a notable reduction in travel time and an increase in the quality of visited attractions. Our study highlights that incorporating external evolutionary optimization effectively addresses the limitations of large language models in travel this http URL codes are available at this https URL.", 'abstract_zh': '基于叙事的旅行规划框架NarrativeGuide：增强游客体验与沉浸感的新颖方法', 'title_zh': '叙事驱动的旅游规划：基于地理文化的脚本生成与进化行程优化'}
{'arxiv_id': 'arXiv:2502.14264', 'title': 'SPRIG: Stackelberg Perception-Reinforcement Learning with Internal Game Dynamics', 'authors': 'Fernando Martinez-Lopez, Juntao Chen, Yingdong Lu', 'link': 'https://arxiv.org/abs/2502.14264', 'abstract': "Deep reinforcement learning agents often face challenges to effectively coordinate perception and decision-making components, particularly in environments with high-dimensional sensory inputs where feature relevance varies. This work introduces SPRIG (Stackelberg Perception-Reinforcement learning with Internal Game dynamics), a framework that models the internal perception-policy interaction within a single agent as a cooperative Stackelberg game. In SPRIG, the perception module acts as a leader, strategically processing raw sensory states, while the policy module follows, making decisions based on extracted features. SPRIG provides theoretical guarantees through a modified Bellman operator while preserving the benefits of modern policy optimization. Experimental results on the Atari BeamRider environment demonstrate SPRIG's effectiveness, achieving around 30% higher returns than standard PPO through its game-theoretical balance of feature extraction and decision-making.", 'abstract_zh': 'Deep reinforcement learning代理往往面临在高维感官输入环境中有效协调感知和决策组件的挑战，特别是在特征相关性变化的环境中。本文提出了SPRIG（Stackelberg Perception-Reinforcement learning with Internal Game dynamics）框架，将单个代理的内部感知-政策交互建模为合作的Stackelberg游戏。在SPRIG中，感知模块充当领导者，战略性地处理原始感官状态，而政策模块则根据提取的特征作出决策。SPRIG通过修改后的贝尔曼算子提供了理论保证，同时保留了现代策略优化的优势。实验结果表明，SPRIG在Atari BeamRider环境中表现出色，通过其在特征提取和决策之间的游戏理论平衡，实现了约30%的更高回报。', 'title_zh': 'SPRIG: 堆栈博弈感知强化学习与内部博弈动力学'}
{'arxiv_id': 'arXiv:2502.14200', 'title': 'Causal Mean Field Multi-Agent Reinforcement Learning', 'authors': 'Hao Ma, Zhiqiang Pu, Yi Pan, Boyin Liu, Junlong Gao, Zhenyu Guo', 'link': 'https://arxiv.org/abs/2502.14200', 'abstract': "Scalability remains a challenge in multi-agent reinforcement learning and is currently under active research. A framework named mean-field reinforcement learning (MFRL) could alleviate the scalability problem by employing the Mean Field Theory to turn a many-agent problem into a two-agent problem. However, this framework lacks the ability to identify essential interactions under nonstationary environments. Causality contains relatively invariant mechanisms behind interactions, though environments are nonstationary. Therefore, we propose an algorithm called causal mean-field Q-learning (CMFQ) to address the scalability problem. CMFQ is ever more robust toward the change of the number of agents though inheriting the compressed representation of MFRL's action-state space. Firstly, we model the causality behind the decision-making process of MFRL into a structural causal model (SCM). Then the essential degree of each interaction is quantified via intervening on the SCM. Furthermore, we design the causality-aware compact representation for behavioral information of agents as the weighted sum of all behavioral information according to their causal effects. We test CMFQ in a mixed cooperative-competitive game and a cooperative game. The result shows that our method has excellent scalability performance in both training in environments containing a large number of agents and testing in environments containing much more agents.", 'abstract_zh': '多Agent强化学习的可扩展性仍然是一个挑战，目前正受到广泛关注。一种名为均场强化学习（MFRL）的框架可通过运用均场理论将多Agent问题转化为两Agent问题来缓解可扩展性问题。然而，该框架缺乏在非平稳环境中识别关键交互的能力。因果关系包含在交互背后的相对不变机制，尽管环境是非平稳的。因此，我们提出了一种名为因果均场Q学习（CMFQ）的算法，以解决可扩展性问题。尽管继承了MFRL的动作-状态空间压缩表示，CMFQ对Agent数量的变化具有更强的鲁棒性。首先，我们将均场强化学习背后的决策过程建模为结构因果模型（SCM）。然后，通过干预SCM量化每种交互的关键程度。此外，我们设计了一种基于因果效应加权和的前瞻紧凑表示，用于表示Agent的行为信息。我们在混合合作竞争游戏和合作游戏中测试了CMFQ。结果显示，该方法在包含大量Agent的环境中训练以及在包含更多Agent的环境中测试时，均具有出色的可扩展性性能。', 'title_zh': '因果平均场多智能体强化学习'}
{'arxiv_id': 'arXiv:2502.14102', 'title': 'Explainable Distributed Constraint Optimization Problems', 'authors': 'Ben Rachmut, Stylianos Loukas Vasileiou, Nimrod Meir Weinstein, Roie Zivan, William Yeoh', 'link': 'https://arxiv.org/abs/2502.14102', 'abstract': 'The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool to model cooperative multi-agent problems that need to be solved distributively. A core assumption of existing approaches is that DCOP solutions can be easily understood, accepted, and adopted, which may not hold, as evidenced by the large body of literature on Explainable AI. In this paper, we propose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include its solution and a contrastive query for that solution. We formally define some key properties that contrastive explanations must satisfy for them to be considered as valid solutions to X-DCOPs as well as theoretical results on the existence of such valid explanations. To solve X-DCOPs, we propose a distributed framework as well as several optimizations and suboptimal variants to find valid explanations. We also include a human user study that showed that users, not surprisingly, prefer shorter explanations over longer ones. Our empirical evaluations showed that our approach can scale to large problems, and the different variants provide different options for trading off explanation lengths for smaller runtimes. Thus, our model and algorithmic contributions extend the state of the art by reducing the barrier for users to understand DCOP solutions, facilitating their adoption in more real-world applications.', 'abstract_zh': '可解释的分布式约束优化问题（X-DCOP）模型', 'title_zh': '可解释的分布式约束优化问题'}
{'arxiv_id': 'arXiv:2502.14862', 'title': 'Interpretable Text Embeddings and Text Similarity Explanation: A Primer', 'authors': 'Juri Opitz, Lucas Möller, Andrianos Michail, Simon Clematide', 'link': 'https://arxiv.org/abs/2502.14862', 'abstract': "Text embeddings and text embedding models are a backbone of many AI and NLP systems, particularly those involving search. However, interpretability challenges persist, especially in explaining obtained similarity scores, which is crucial for applications requiring transparency. In this paper, we give a structured overview of interpretability methods specializing in explaining those similarity scores, an emerging research area. We study the methods' individual ideas and techniques, evaluating their potential for improving interpretability of text embeddings and explaining predicted similarities.", 'abstract_zh': '文本嵌入及其模型是许多AI和NLP系统的核心，特别是在涉及搜索的应用中。然而，可解释性挑战依旧存在，尤其是在解释获得的相似性分数方面，这对需要透明度的应用至关重要。本文提供了一个结构化的综述，概述了专门用于解释这些相似性分数的可解释性方法，这是一个新兴的研究领域。我们研究了这些方法的个体理念和技术，评估它们在提高文本嵌入的可解释性和解释预测相似性方面的潜力。', 'title_zh': '可解释的文本嵌入与文本相似性解释：入门指南'}
{'arxiv_id': 'arXiv:2502.14831', 'title': 'Improving the Diffusability of Autoencoders', 'authors': 'Ivan Skorokhodov, Sharath Girish, Benran Hu, Willi Menapace, Yanyu Li, Rameen Abdal, Sergey Tulyakov, Aliaksandr Siarohin', 'link': 'https://arxiv.org/abs/2502.14831', 'abstract': 'Latent diffusion models have emerged as the leading approach for generating high-quality images and videos, utilizing compressed latent representations to reduce the computational burden of the diffusion process. While recent advancements have primarily focused on scaling diffusion backbones and improving autoencoder reconstruction quality, the interaction between these components has received comparatively less attention. In this work, we perform a spectral analysis of modern autoencoders and identify inordinate high-frequency components in their latent spaces, which are especially pronounced in the autoencoders with a large bottleneck channel size. We hypothesize that this high-frequency component interferes with the coarse-to-fine nature of the diffusion synthesis process and hinders the generation quality. To mitigate the issue, we propose scale equivariance: a simple regularization strategy that aligns latent and RGB spaces across frequencies by enforcing scale equivariance in the decoder. It requires minimal code changes and only up to 20K autoencoder fine-tuning steps, yet significantly improves generation quality, reducing FID by 19% for image generation on ImageNet-1K 256x256 and FVD by at least 44% for video generation on Kinetics-700 17x256x256.', 'abstract_zh': '潜在扩散模型已成为生成高质量图像和视频的领先方法，通过压缩的潜在表示来减轻扩散过程的计算负担。尽管近期进展主要集中在扩展扩散骨干网络和提高自编码器重建质量上，但这些组件之间的相互作用却相对较少受到关注。在本工作中，我们对现代自编码器进行了频域分析，并发现在其潜在空间中存在异常的高频分量，尤其是在瓶颈通道尺寸较大的自编码器中更为明显。我们假设这种高频分量干扰了扩散合成过程中的自底向上的特性，从而阻碍了生成质量的提升。为了解决这一问题，我们提出了尺度等变性：一种简单的正则化策略，通过在解码器中强制实施尺度等变性来实现潜在空间和RGB空间在不同频率上的对齐。这种方法只需少量代码更改，并且只需最多20,000次自编码器微调步骤，但显著提高了生成质量，对于ImageNet-1K 256x256图像生成将FID降低了19%，对于Kinetics-700 17x256x256视频生成将FVD降低了至少44%。', 'title_zh': '提高自动编码器的扩散性'}
{'arxiv_id': 'arXiv:2502.14791', 'title': 'Rapid Word Learning Through Meta In-Context Learning', 'authors': 'Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake', 'link': 'https://arxiv.org/abs/2502.14791', 'abstract': "Humans can quickly learn a new word from a few illustrative examples, and then systematically and flexibly use it in novel contexts. Yet the abilities of current language models for few-shot word learning, and methods for improving these abilities, are underexplored. In this study, we introduce a novel method, Meta-training for IN-context learNing Of Words (Minnow). This method trains language models to generate new examples of a word's usage given a few in-context examples, using a special placeholder token to represent the new word. This training is repeated on many new words to develop a general word-learning ability. We find that training models from scratch with Minnow on human-scale child-directed language enables strong few-shot word learning, comparable to a large language model (LLM) pre-trained on orders of magnitude more data. Furthermore, through discriminative and generative evaluations, we demonstrate that finetuning pre-trained LLMs with Minnow improves their ability to discriminate between new words, identify syntactic categories of new words, and generate reasonable new usages and definitions for new words, based on one or a few in-context examples. These findings highlight the data efficiency of Minnow and its potential to improve language model performance in word learning tasks.", 'abstract_zh': 'Meta-training for IN-context learNing Of Words (Minnow): Improving Few-shot Word Learning Abilities of Language Models', 'title_zh': '通过元上下文学习快速词汇学习'}
{'arxiv_id': 'arXiv:2502.14788', 'title': 'Ray-Tracing for Conditionally Activated Neural Networks', 'authors': 'Claudio Gallicchio, Giuseppe Nuti', 'link': 'https://arxiv.org/abs/2502.14788', 'abstract': "In this paper, we introduce a novel architecture for conditionally activated neural networks combining a hierarchical construction of multiple Mixture of Experts (MoEs) layers with a sampling mechanism that progressively converges to an optimized configuration of expert activation. This methodology enables the dynamic unfolding of the network's architecture, facilitating efficient path-specific training. Experimental results demonstrate that this approach achieves competitive accuracy compared to conventional baselines while significantly reducing the parameter count required for inference. Notably, this parameter reduction correlates with the complexity of the input patterns, a property naturally emerging from the network's operational dynamics without necessitating explicit auxiliary penalty functions.", 'abstract_zh': '本文介绍了一种结合多Mixture of Experts (MoEs)层的分层构建和逐步优化专家激活配置的采样机制的新架构，使网络架构能够动态展开，便于进行路径特定训练。实验结果表明，该方法在参数量显著减少的情况下，仍能达到与传统基线方法相当的准确率。值得注意的是，参数量的减少与输入模式的复杂性自然相关，这一特性源自于网络的操作动态，无需使用显式的辅助惩罚函数。', 'title_zh': '条件激活神经网络的射线 tracing 方案'}
{'arxiv_id': 'arXiv:2502.14785', 'title': 'Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches', 'authors': 'Chandrashekar Muniyappa, Kendall Willets, Sriraman Krishnamoorthy', 'link': 'https://arxiv.org/abs/2502.14785', 'abstract': 'Predicting the right number of TVs (Device Reach) in real-time based on a user-specified targeting attributes is imperative for running multi-million dollar ADs business. The traditional approach of SQL queries to join billions of records across multiple targeting dimensions is extremely slow. As a workaround, many applications will have an offline process to crunch these numbers and present the results after many hours. In our case, the solution was an offline process taking 24 hours to onboard a customer resulting in a potential loss of business. To solve this problem, we have built a new real-time prediction system using MinHash and HyperLogLog (HLL) data sketches to compute the device reach at runtime when a user makes a request. However, existing MinHash implementations do not solve the complex problem of multilevel aggregation and intersection. This work will show how we have solved this problem, in addition, we have improved MinHash algorithm to run 4 times faster using Single Instruction Multiple Data (SIMD) vectorized operations for high speed and accuracy with constant space to process billions of records. Finally, by experiments, we prove that the results are as accurate as traditional offline prediction system with an acceptable error rate of 5%.', 'abstract_zh': '基于用户指定 targeting 属性实时预测合适数量的电视机（设备触达量）是运行百万美元广告业务的关键。传统的基于 SQL 查询的方法在跨多个 targeting 维度连接数十亿记录时极其缓慢。作为 workaround，许多应用将通过离线过程在数小时后计算这些数字并呈现结果。在我们的情况下，离线过程耗时24小时来上线一个客户，导致潜在的业务损失。为了解决这个问题，我们构建了一个新的实时预测系统，使用 MinHash 和 HyperLogLog (HLL) 数据概要，在用户请求时实时计算设备触达量。然而，现有的 MinHash 实现无法解决多层次聚合和交集的复杂问题。本文将展示我们如何解决这一问题，并通过改进 MinHash 算法，使用 Single Instruction Multiple Data (SIMD) 向量化操作在保持常数空间处理数十亿记录的同时提高运行速度和准确性，达到四倍的速度。最终，通过实验证明，该系统的结果与传统的离线预测系统相差不大，误差率为5%。', 'title_zh': '基于HLL和MinHash数据概要的实时设备可达性预测'}
{'arxiv_id': 'arXiv:2502.14778', 'title': 'Harnessing PDF Data for Improving Japanese Large Multimodal Models', 'authors': 'Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa', 'link': 'https://arxiv.org/abs/2502.14778', 'abstract': 'Large Multimodal Models (LMMs) have demonstrated strong performance in English, but their effectiveness in Japanese remains limited due to the lack of high-quality training data. Current Japanese LMMs often rely on translated English datasets, restricting their ability to capture Japan-specific cultural knowledge. To address this, we explore the potential of Japanese PDF data as a training resource, an area that remains largely underutilized. We introduce a fully automated pipeline that leverages pretrained models to extract image-text pairs from PDFs through layout analysis, OCR, and vision-language pairing, removing the need for manual annotation. Additionally, we construct instruction data from extracted image-text pairs to enrich the training data. To evaluate the effectiveness of PDF-derived data, we train Japanese LMMs and assess their performance on the Japanese LMM Benchmark. Our results demonstrate substantial improvements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench. Further analysis highlights the impact of PDF-derived data on various factors, such as model size and language models, reinforcing its value as a multimodal resource for Japanese LMMs. We plan to make the source code and data publicly available upon acceptance.', 'abstract_zh': '大型多模态模型（LMMs）在英语中展现了出色的表现，但在日语中的有效性受限于高质量训练数据的缺乏。当前的日语LMMs经常依赖于英译日语数据集，限制了它们捕捉日本特定文化知识的能力。为了解决这一问题，我们探索了利用日语PDF数据作为训练资源的潜力，这是一个迄今为止很大程度上未被充分利用的领域。我们提出了一个完全自动化的管道，利用预训练模型通过布局分析、OCR和视觉语言配对从PDF中提取图像-文本对，从而去除手动标注的需求。此外，我们从提取的图像-文本对中构建指令数据以丰富训练数据。为了评估从PDF中获得的数据的有效性，我们在日语LMM基准上训练了日语LMMs并评估其性能。我们的结果表明，性能提高了3.9%至13.8%。进一步分析突显了从PDF获得的数据对模型规模和语言模型等因素的影响，强调了其作为日语LMMs多模态资源的价值。我们计划在论文被接受后公开源代码和数据。', 'title_zh': '利用PDF数据提升日语大规模多模态模型'}
{'arxiv_id': 'arXiv:2502.14767', 'title': 'Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis', 'authors': 'Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han', 'link': 'https://arxiv.org/abs/2502.14767', 'abstract': 'With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields. This makes it challenging to assess the significance, novelty, incremental findings, and equivalent ideas between related works, particularly those from different research communities. Large language models (LLMs) have recently demonstrated strong quantitative and qualitative reasoning abilities, and multi-agent LLM debates have shown promise in handling complex reasoning tasks by exploring diverse perspectives and reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a framework which converts scientific papers into LLM personas that debate their respective novelties. To emphasize structured, critical reasoning rather than focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling fine-grained analysis of independent novelty arguments within scholarly articles. Through experiments on scientific literature across various domains, evaluated by expert researchers, we demonstrate that ToD generates informative arguments, effectively contrasts papers, and supports researchers in their literature review.', 'abstract_zh': '随着现代技术的发展和获取途径的改进，科学研究以指数级增长，导致科学发现越来越碎片化，尤其是在不同领域之间。这使得评估相关作品（特别是不同研究社区的作品）之间的意义、新颖性、增量发现和等效思想变得颇具挑战性。大型语言模型（LLMs）最近展示了强大的量化和质化推理能力，多智能体LLM辩论展示了处理复杂推理任务的潜力，通过探索多种观点和推理路径。受此启发，我们提出了一种名为Tree-of-Debate（ToD）的框架，该框架将科学论文转化为LLM人格，并就各自的创新性进行辩论。为强调结构化、批判性推理而非仅关注结果，ToD动态构建辩论树，允许对学术文章中的独立新颖性主张进行精细分析。通过跨多个领域的科学研究文献实验，并由专家研究人员评估，我们证明了ToD生成了信息丰富的论点，有效地对比了论文，并支持研究人员进行文献综述。', 'title_zh': '树状辩论：多角色辩论树促进批判性思维的科学对比分析'}
{'arxiv_id': 'arXiv:2502.14765', 'title': 'Step-by-Step Fact Verification System for Medical Claims with Explainable Reasoning', 'authors': 'Juraj Vladika, Ivana Hacajová, Florian Matthes', 'link': 'https://arxiv.org/abs/2502.14765', 'abstract': 'Fact verification (FV) aims to assess the veracity of a claim based on relevant evidence. The traditional approach for automated FV includes a three-part pipeline relying on short evidence snippets and encoder-only inference models. More recent approaches leverage the multi-turn nature of LLMs to address FV as a step-by-step problem where questions inquiring additional context are generated and answered until there is enough information to make a decision. This iterative method makes the verification process rational and explainable. While these methods have been tested for encyclopedic claims, exploration on domain-specific and realistic claims is missing. In this work, we apply an iterative FV system on three medical fact-checking datasets and evaluate it with multiple settings, including different LLMs, external web search, and structured reasoning using logic predicates. We demonstrate improvements in the final performance over traditional approaches and the high potential of step-by-step FV systems for domain-specific claims.', 'abstract_zh': '基于迭代方法的医学领域事实核查系统研究及评估', 'title_zh': '医学声明逐步验证系统附带可解释的推理'}
{'arxiv_id': 'arXiv:2502.14743', 'title': 'Multi-Agent Coordination across Diverse Applications: A Survey', 'authors': 'Lijun Sun, Yijun Yang, Qiqi Duan, Yuhui Shi, Chao Lyu, Yu-Cheng Chang, Chin-Teng Lin, Yang Shen', 'link': 'https://arxiv.org/abs/2502.14743', 'abstract': 'Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.', 'abstract_zh': '多智能体协调研究探讨了使多智能体系统（MAS）多样化趋势传播的基础机制，并随着新兴应用的扩展和AI的快速进步而受到越来越多的关注。本文通过统一的理解概述了协调研究在各种应用中的现状，回答了四个基本的协调问题：（1）什么是协调；（2）为何协调；（3）与谁协调；（4）如何协调。我们的目的是探索协调领域的现有思想和专业知识及其在不同应用之间的联系，同时识别和突出显示新兴和有前途的研究方向。首先，确定并分析了对多种应用都至关重要的通用协调问题。其次，综述了多种MAS应用，涵盖从广泛研究的领域（如搜索与救援、仓储自动化与物流、交通系统）到新兴领域（如类人和拟人的机器人、卫星系统和大规模语言模型）的应用。最后，分析和讨论了多智能体系统的可扩展性、异构性和学习机制方面的开放挑战。特别是，我们识别出了层次化和去中心化协调的结合、人类与MAS的协调以及基于大规模语言模型的多智能体系统作为有前途的未来方向。', 'title_zh': '多元应用中的多智能体协调：一个综述'}
{'arxiv_id': 'arXiv:2502.14724', 'title': 'Ranking Joint Policies in Dynamic Games using Evolutionary Dynamics', 'authors': 'Natalia Koliou, George Vouros', 'link': 'https://arxiv.org/abs/2502.14724', 'abstract': "Game-theoretic solution concepts, such as the Nash equilibrium, have been key to finding stable joint actions in multi-player games. However, it has been shown that the dynamics of agents' interactions, even in simple two-player games with few strategies, are incapable of reaching Nash equilibria, exhibiting complex and unpredictable behavior. Instead, evolutionary approaches can describe the long-term persistence of strategies and filter out transient ones, accounting for the long-term dynamics of agents' interactions. Our goal is to identify agents' joint strategies that result in stable behavior, being resistant to changes, while also accounting for agents' payoffs, in dynamic games. Towards this goal, and building on previous results, this paper proposes transforming dynamic games into their empirical forms by considering agents' strategies instead of agents' actions, and applying the evolutionary methodology $\\alpha$-Rank to evaluate and rank strategy profiles according to their long-term dynamics. This methodology not only allows us to identify joint strategies that are strong through agents' long-term interactions, but also provides a descriptive, transparent framework regarding the high ranking of these strategies. Experiments report on agents that aim to collaboratively solve a stochastic version of the graph coloring problem. We consider different styles of play as strategies to define the empirical game, and train policies realizing these strategies, using the DQN algorithm. Then we run simulations to generate the payoff matrix required by $\\alpha$-Rank to rank joint strategies.", 'abstract_zh': '基于演化方法的α-Rank在动态博弈中稳定策略识别与评估', 'title_zh': '使用演化动力学在动态博弈中排名联合策略'}
{'arxiv_id': 'arXiv:2502.14708', 'title': 'Human Misperception of Generative-AI Alignment: A Laboratory Experiment', 'authors': 'Kevin He, Ran Shorrer, Mengjia Xia', 'link': 'https://arxiv.org/abs/2502.14708', 'abstract': "We conduct an incentivized laboratory experiment to study people's perception of generative artificial intelligence (GenAI) alignment in the context of economic decision-making. Using a panel of economic problems spanning the domains of risk, time preference, social preference, and strategic interactions, we ask human subjects to make choices for themselves and to predict the choices made by GenAI on behalf of a human user. We find that people overestimate the degree of alignment between GenAI's choices and human choices. In every problem, human subjects' average prediction about GenAI's choice is substantially closer to the average human-subject choice than it is to the GenAI choice. At the individual level, different subjects' predictions about GenAI's choice in a given problem are highly correlated with their own choices in the same problem. We explore the implications of people overestimating GenAI alignment in a simple theoretical model.", 'abstract_zh': '我们开展了一项激励实验室实验，以研究人们在经济决策背景下对生成人工智能（GenAI）对齐的感知。利用涵盖风险、时间偏好、社会偏好和策略互动的经济问题面板，我们要求人类被试为自己做出选择，并预测代人为用户的人工智能选择。我们发现，人们高估了GenAI选择与人类选择之间的对齐程度。在每一个问题中，人类被试关于GenAI选择的平均预测与人类被试自身的平均选择非常接近，而与GenAI选择相差甚远。在个体层面上，每个被试在特定问题中对GenAI选择的预测与他们自己在相同问题中的选择高度相关。我们探讨了人们高估GenAI对齐的后果，并在简单的理论模型中进行了探讨。', 'title_zh': '人类对生成式AI对齐的误感知：一项实验室实验'}
{'arxiv_id': 'arXiv:2502.14704', 'title': 'Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting', 'authors': 'Yuxuan Yang, Dalin Zhang, Yuxuan Liang, Hua Lu, Huan Li, Gang Chen', 'link': 'https://arxiv.org/abs/2502.14704', 'abstract': 'Time Series Forecasting (TSF) is a crucial task in various domains, yet existing TSF models rely heavily on high-quality data and insufficiently exploit all available data. This paper explores a novel self-supervised approach to re-label time series datasets by inherently constructing candidate datasets. During the optimization of a simple reconstruction network, intermediates are used as pseudo labels in a self-supervised paradigm, improving generalization for any predictor. We introduce the Self-Correction with Adaptive Mask (SCAM), which discards overfitted components and selectively replaces them with pseudo labels generated from reconstructions. Additionally, we incorporate Spectral Norm Regularization (SNR) to further suppress overfitting from a loss landscape perspective. Our experiments on eleven real-world datasets demonstrate that SCAM consistently improves the performance of various backbone models. This work offers a new perspective on constructing datasets and enhancing the generalization of TSF models through self-supervised learning.', 'abstract_zh': '基于自监督的时序数据再标签方法及时间序列预测模型的泛化能力提升', 'title_zh': '并非所有数据都是良好标签：关于时间序列预测的自监督标注研究'}
{'arxiv_id': 'arXiv:2502.14698', 'title': 'General Uncertainty Estimation with Delta Variances', 'authors': 'Simon Schmitt, John Shawe-Taylor, Hado van Hasselt', 'link': 'https://arxiv.org/abs/2502.14698', 'abstract': 'Decision makers may suffer from uncertainty induced by limited data. This may be mitigated by accounting for epistemic uncertainty, which is however challenging to estimate efficiently for large neural networks. To this extent we investigate Delta Variances, a family of algorithms for epistemic uncertainty quantification, that is computationally efficient and convenient to implement. It can be applied to neural networks and more general functions composed of neural networks. As an example we consider a weather simulator with a neural-network-based step function inside -- here Delta Variances empirically obtain competitive results at the cost of a single gradient computation. The approach is convenient as it requires no changes to the neural network architecture or training procedure. We discuss multiple ways to derive Delta Variances theoretically noting that special cases recover popular techniques and present a unified perspective on multiple related methods. Finally we observe that this general perspective gives rise to a natural extension and empirically show its benefit.', 'abstract_zh': '决策者可能因数据有限而面临不确定性，这可以通过考虑 epistemic 不确定性来缓解，但对大规模神经网络而言，高效估计这一不确定性颇具挑战。为此，我们研究了 Delta 方差族算法，这是一种计算高效且易于实现的 epistemic 不确定性量化方法，可应用于神经网络及由神经网络组成的更广泛函数。作为示例，我们考虑了一个包含基于神经网络的步骤函数的气象模拟器——在此情况下，Delta 方差通过单次梯度计算就能获得竞争力的结果。该方法便于实现，不需要对神经网络架构或训练过程进行任何修改。我们从多个角度理论上推导了 Delta 方差，指出其特殊情况可恢复流行技术，并提供了多个相关方法的一致视角。最后，我们观察到这种一般视角导致了自然扩展，并通过实验展示了其优势。', 'title_zh': '基于德尔塔方差的一般不确定性估计'}
{'arxiv_id': 'arXiv:2502.14681', 'title': 'seqKAN: Sequence processing with Kolmogorov-Arnold Networks', 'authors': 'Tatiana Boura, Stasinos Konstantopoulos', 'link': 'https://arxiv.org/abs/2502.14681', 'abstract': 'Kolmogorov-Arnold Networks (KANs) have been recently proposed as a machine learning framework that is more interpretable and controllable than the multi-layer perceptron. Various network architectures have been proposed within the KAN framework targeting different tasks and application domains, including sequence processing.\nThis paper proposes seqKAN, a new KAN architecture for sequence processing. Although multiple sequence processing KAN architectures have already been proposed, we argue that seqKAN is more faithful to the core concept of the KAN framework. Furthermore, we empirically demonstrate that it achieves better results.\nThe empirical evaluation is performed on generated data from a complex physics problem on an interpolation and an extrapolation task. Using this dataset we compared seqKAN against a prior KAN network for timeseries prediction, recurrent deep networks, and symbolic regression. seqKAN substantially outperforms all architectures, particularly on the extrapolation dataset, while also being the most transparent.', 'abstract_zh': 'Kolmogorov-Arnold 网络（KANs）最近被提出作为一种比多层感知机更具有可解释性和可控性的机器学习框架。KAN框架下已经提出多种网络架构，针对不同的任务和应用领域，包括序列处理。\n本文提出了一种新的KAN架构seqKAN，专门用于序列处理。尽管已经提出了多种序列处理的KAN架构，但我们认为seqKAN更忠于KAN框架的核心概念。此外，我们通过实验证明了其表现更优。\n实证评估是在一个复杂物理问题生成的数据集上进行的，包括插值和外推任务。利用该数据集，我们将seqKAN与先前的KAN时间序列预测网络、循环深度网络和符号回归进行了比较。seqKAN在所有架构中表现最佳，特别是在外推数据集上的表现尤为突出，同时其透明度也最高。', 'title_zh': 'seqKAN: 使用柯尔莫哥洛夫-阿诺尔德网络的序列处理'}
{'arxiv_id': 'arXiv:2502.14676', 'title': 'BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction', 'authors': 'Ruochen Li, Stamos Katsigiannis, Tae-Kyun Kim, Hubert P. H. Shum', 'link': 'https://arxiv.org/abs/2502.14676', 'abstract': 'Trajectory prediction allows better decision-making in applications of autonomous vehicles or surveillance by predicting the short-term future movement of traffic agents. It is classified into pedestrian or heterogeneous trajectory prediction. The former exploits the relatively consistent behavior of pedestrians, but is limited in real-world scenarios with heterogeneous traffic agents such as cyclists and vehicles. The latter typically relies on extra class label information to distinguish the heterogeneous agents, but such labels are costly to annotate and cannot be generalized to represent different behaviors within the same class of agents. In this work, we introduce the behavioral pseudo-labels that effectively capture the behavior distributions of pedestrians and heterogeneous agents solely based on their motion features, significantly improving the accuracy of trajectory prediction. To implement the framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a trajectory predictor. For optimization, we propose a cascaded training scheme, in which we first learn the pseudo-labels in an unsupervised manner, and then perform end-to-end fine-tuning on the labels in the direction of increasing the trajectory prediction accuracy. Experiments show that our pseudo-labels effectively model different behavior clusters and improve trajectory prediction. Our proposed BP-SGCN outperforms existing methods using both pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets (SDD, Argoverse 1).', 'abstract_zh': '基于行为伪标签的稀疏图卷积网络在轨迹预测中的应用：改善自主车辆或监控应用中的决策制定', 'title_zh': '基于行为伪标签指导的稀疏图卷积网络：行人和其他异质轨迹预测'}
{'arxiv_id': 'arXiv:2502.14637', 'title': 'ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation', 'authors': 'Angxiao Yue, Zichong Wang, Hongteng Xu', 'link': 'https://arxiv.org/abs/2502.14637', 'abstract': 'Protein backbone generation plays a central role in de novo protein design and is significant for many biological and medical applications. Although diffusion and flow-based generative models provide potential solutions to this challenging task, they often generate proteins with undesired designability and suffer computational inefficiency. In this study, we propose a novel rectified quaternion flow (ReQFlow) matching method for fast and high-quality protein backbone generation. In particular, our method generates a local translation and a 3D rotation from random noise for each residue in a protein chain, which represents each 3D rotation as a unit quaternion and constructs its flow by spherical linear interpolation (SLERP) in an exponential format. We train the model by quaternion flow (QFlow) matching with guaranteed numerical stability and rectify the QFlow model to accelerate its inference and improve the designability of generated protein backbones, leading to the proposed ReQFlow model. Experiments show that ReQFlow achieves state-of-the-art performance in protein backbone generation while requiring much fewer sampling steps and significantly less inference time (e.g., being 37x faster than RFDiffusion and 62x faster than Genie2 when generating a backbone of length 300), demonstrating its effectiveness and efficiency. The code is available at this https URL.', 'abstract_zh': '蛋白质主链生成在从头设计蛋白中扮演中心角色，并在许多生物学和医学应用中具有重要意义。尽管扩散和流式生成模型为这一具有挑战性的任务提供了潜在解决方案，但它们往往会生成设计能力不佳的蛋白质，并遭受计算效率低下问题。在此研究中，我们提出了一种新颖的修正四元数流（ReQFlow）匹配方法，以实现快速高效地生成高质量蛋白质主链。特别地，我们的方法为蛋白质链中的每个残基从随机噪声中生成局部平移和3D旋转，并将每个3D旋转表示为单位四元数，通过指数格式下的球面线性插值（SLERP）构造其流。我们通过保证数值稳定的四元数流（QFlow）匹配训练模型，并修正QFlow模型加速其推理过程并提高生成蛋白质主链的设计能力，从而提出了ReQFlow模型。实验结果显示，ReQFlow在蛋白质主链生成方面达到了最先进的性能，所需采样步骤大大减少，并显著缩短了推理时间（例如，在生成长度为300的主链时，比RFDiffusion快37倍，比Genie2快62倍），证明了其有效性和效率。代码可在以下网址获取。', 'title_zh': 'ReQFlow: 正则化四元数流及其在蛋白质主链高效高质生成中的应用'}
{'arxiv_id': 'arXiv:2502.14627', 'title': 'ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors', 'authors': 'Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou', 'link': 'https://arxiv.org/abs/2502.14627', 'abstract': 'Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. We theoretically analyze the inconsistency in terms of both multilingual modal alignment direction error and weight error, and propose the theoretical weight error upper bound for quantifying the inconsistency. Based on the analysis of the weight error upper bound, we find that the inconsistency problem stems from the data distribution error caused by random sampling of languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive learning and audio-English co-anchor contrastive learning, aiming to mitigate the negative impact of data distribution error on recall and consistency in ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets show that our scheme achieves state-of-the-art performance on recall and consistency metrics for eight mainstream languages, including English. Our code will be available at this https URL.', 'abstract_zh': '多语言音频-文本检索（ML-ATR）是一项挑战性的任务，旨在从数据库中检索音频片段或多语言文本。然而，现有的ML-ATR方案在语言间存在一致性的匹配问题。我们从多语言模态对齐方向误差和权重误差两个方面理论上分析了一致性问题，并提出理论权重误差上限来量化这种不一致性。基于权重误差上限的分析，我们发现不一致性问题源于由随机语言采样引起的数据分布误差。我们提出了一种一致的ML-ATR方案，采用1-to-k对比学习和音频-英语共锚对比学习，旨在减轻数据分布误差对检索召回率和一致性的影响。在翻译后的AudioCaps和Clotho数据集上的实验结果显示，我们的方案在主流八种语言（包括英语）的检索召回率和一致性指标上达到了最佳性能。我们的代码将在此处提供：这个 https URL。', 'title_zh': 'ATRI: 通过减少数据分布误差来缓解多语言音频文本检索不一致性'}
{'arxiv_id': 'arXiv:2502.14583', 'title': 'A Theory for Conditional Generative Modeling on Multiple Data Sources', 'authors': 'Rongzhen Wang, Yan Zhang, Chenyu Zheng, Chongxuan Li, Guoqiang Wu', 'link': 'https://arxiv.org/abs/2502.14583', 'abstract': 'The success of large generative models has driven a paradigm shift, leveraging massive multi-source data to enhance model capabilities. However, the interaction among these sources remains theoretically underexplored. This paper takes the first step toward a rigorous analysis of multi-source training in conditional generative modeling, where each condition represents a distinct data source. Specifically, we establish a general distribution estimation error bound in average total variation distance for conditional maximum likelihood estimation based on the bracketing number. Our result shows that when source distributions share certain similarities and the model is expressive enough, multi-source training guarantees a sharper bound than single-source training. We further instantiate the general theory on conditional Gaussian estimation and deep generative models including autoregressive and flexible energy-based models, by characterizing their bracketing numbers. The results highlight that the number of sources and similarity among source distributions improve the advantage of multi-source training. Simulations and real-world experiments validate our theory. Code is available at: \\url{this https URL}.', 'abstract_zh': '大型生成模型的成功推动了范式转变，依托海量多源数据提升模型能力。然而，这些源数据之间的交互仍缺乏理论探究。本文首次对条件生成建模中的多源训练进行严谨分析，其中每个条件代表一个独立的数据源。具体而言，我们基于覆盖数建立了条件最大似然估计的均值绝对偏差的一般分布估计误差界。我们的结果表明，在源分布具有一定相似性且模型足够表达力的情况下，多源训练比单源训练提供更严格的误差界。进一步地，我们在条件高斯估计和深度生成模型（包括自回归和灵活的能量基础模型）中实例化了该通用理论，并通过表征它们的覆盖数对其进行量化。结果强调，源的数量以及源分布之间的相似性增强了多源训练的优势。仿真和真实世界实验验证了我们的理论。代码请参见：\\url{this https URL}。', 'title_zh': '多数据源条件生成 modeling 理论'}
{'arxiv_id': 'arXiv:2502.14572', 'title': 'Factor Graph-based Interpretable Neural Networks', 'authors': 'Yicong Li, Kuanjiu Zhou, Shuo Yu, Qiang Zhang, Renqiang Luo, Xiaodong Li, Feng Xia', 'link': 'https://arxiv.org/abs/2502.14572', 'abstract': 'Comprehensible neural network explanations are foundations for a better understanding of decisions, especially when the input data are infused with malicious perturbations. Existing solutions generally mitigate the impact of perturbations through adversarial training, yet they fail to generate comprehensible explanations under unknown perturbations. To address this challenge, we propose AGAIN, a fActor GrAph-based Interpretable neural Network, which is capable of generating comprehensible explanations under unknown perturbations. Instead of retraining like previous solutions, the proposed AGAIN directly integrates logical rules by which logical errors in explanations are identified and rectified during inference. Specifically, we construct the factor graph to express logical rules between explanations and categories. By treating logical rules as exogenous knowledge, AGAIN can identify incomprehensible explanations that violate real-world logic. Furthermore, we propose an interactive intervention switch strategy rectifying explanations based on the logical guidance from the factor graph without learning perturbations, which overcomes the inherent limitation of adversarial training-based methods in defending only against known perturbations. Additionally, we theoretically demonstrate the effectiveness of employing factor graph by proving that the comprehensibility of explanations is strongly correlated with factor graph. Extensive experiments are conducted on three datasets and experimental results illustrate the superior performance of AGAIN compared to state-of-the-art baselines.', 'abstract_zh': '可解释的神经网络解释是理解决策基础，尤其在输入数据包含恶意扰动时。为应对这一挑战，我们提出了一种基于因子图的可解释神经网络AGAIN，能够在未知扰动下生成可解释的解释。我们通过构建因子图来表达解释与类别之间的逻辑规则，并借助逻辑规则直接集成逻辑规则，识别和纠正推理过程中的逻辑错误，而不需要重新训练。此外，我们提出了一种基于因子图逻辑指导的交互式干预切换策略，可以在不学习扰动的情况下纠正解释，从而克服基于对抗训练方法的固有局限性。我们还从理论上证明了因子图的有效性，表明解释的可解释性与因子图高度相关。在三个数据集上进行的广泛实验表明，AGAIN的性能优于现有先进的基线方法。', 'title_zh': '基于因子图的可解释神经网络'}
{'arxiv_id': 'arXiv:2502.14558', 'title': 'FUIA: Model Inversion Attack against Federated Unlearning', 'authors': 'Lei Zhou, Youwen Zhu', 'link': 'https://arxiv.org/abs/2502.14558', 'abstract': 'With the introduction of regulations related to the ``right to be forgotten", federated learning (FL) is facing new privacy compliance challenges. To address these challenges, researchers have proposed federated unlearning (FU). However, existing FU research has primarily focused on improving the efficiency of unlearning, with less attention paid to the potential privacy vulnerabilities inherent in these methods. To address this gap, we draw inspiration from gradient inversion attacks in FL and propose the federated unlearning inversion attack (FUIA). The FUIA is specifically designed for the three types of FU (sample unlearning, client unlearning, and class unlearning), aiming to provide a comprehensive analysis of the privacy leakage risks associated with FU. In FUIA, the server acts as an honest-but-curious attacker, recording and exploiting the model differences before and after unlearning to expose the features and labels of forgotten data. FUIA significantly leaks the privacy of forgotten data and can target all types of FU. This attack contradicts the goal of FU to eliminate specific data influence, instead exploiting its vulnerabilities to recover forgotten data and expose its privacy flaws. Extensive experimental results show that FUIA can effectively reveal the private information of forgotten data. To mitigate this privacy leakage, we also explore two potential defense methods, although these come at the cost of reduced unlearning effectiveness and the usability of the unlearned model.', 'abstract_zh': '随着“被遗忘权”相关法规的引入，联邦学习（FL）面临新的隐私合规挑战。为了应对这些挑战，研究人员提出了联邦遗忘（FU）。然而，现有的FU研究主要集中在提高遗忘的效率上，对这些方法中固有的潜在隐私漏洞关注较少。为填补这一空白，我们从FL中的梯度反转攻击中汲取灵感，提出了联邦遗忘反转攻击（FUIA）。FUIA特别针对三种类型的FU（样本遗忘、客户端遗忘和类别遗忘），旨在全面分析FU引起的隐私泄漏风险。在FUIA中，服务器扮演诚实但好奇的攻击者角色，记录并利用遗忘前后模型的差异以揭示被遗忘数据的特征和标签。FUIA显著泄露了被遗忘数据的隐私，并可以针对所有类型的FU进行攻击。该攻击与FU消除特定数据影响的目标相反，反而利用其漏洞恢复被遗忘的数据并暴露其隐私缺陷。大量实验结果表明，FUIA可以有效地揭示被遗忘数据的私人信息。为了减轻这种隐私泄漏，我们还探讨了两种潜在的防御方法，尽管这会降低遗忘的效率并减弱遗忘模型的实用性。', 'title_zh': 'FUIA：针对联邦忘录的模型反转攻击'}
{'arxiv_id': 'arXiv:2502.14546', 'title': 'Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks', 'authors': 'Maya Bechler-Speicher, Ben Finkelshtein, Fabrizio Frasca, Luis Müller, Jan Tönshoff, Antoine Siraudin, Viktor Zaverkin, Michael M. Bronstein, Mathias Niepert, Bryan Perozzi, Mikhail Galkin, Christopher Morris', 'link': 'https://arxiv.org/abs/2502.14546', 'abstract': 'While machine learning on graphs has demonstrated promise in drug design and molecular property prediction, significant benchmarking challenges hinder its further progress and relevance. Current benchmarking practices often lack focus on transformative, real-world applications, favoring narrow domains like two-dimensional molecular graphs over broader, impactful areas such as combinatorial optimization, relational databases, or chip design. Additionally, many benchmark datasets poorly represent the underlying data, leading to inadequate abstractions and misaligned use cases. Fragmented evaluations and an excessive focus on accuracy further exacerbate these issues, incentivizing overfitting rather than fostering generalizable insights. These limitations have prevented the development of truly useful graph foundation models. This position paper calls for a paradigm shift toward more meaningful benchmarks, rigorous evaluation protocols, and stronger collaboration with domain experts to drive impactful and reliable advances in graph learning research, unlocking the potential of graph learning.', 'abstract_zh': '关于图学习基准测试、评估范式和领域专家合作的范式转变：释放图学习研究潜力的有意义基准、严格的评估协议和更强的跨学科合作', 'title_zh': '位置：基于图的学习因基准不足将失去相关性'}
{'arxiv_id': 'arXiv:2502.14525', 'title': 'Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting', 'authors': 'Yannick Wölker, Arash Hajisafi, Cyrus Shahabi, Matthias Renz', 'link': 'https://arxiv.org/abs/2502.14525', 'abstract': 'We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for analyzing traffic data, demonstrating its efficacy in two critical tasks: forecasting and reconstruction. Unlike typical GNN methods that treat each traffic sensor as an individual graph node, DeepStateGNN clusters sensors into higher-level graph nodes, dubbed Deep State Nodes, based on various similarity criteria, resulting in a fixed number of nodes in a Deep State graph. The term "Deep State" nodes is a play on words, referencing hidden networks of power that, like these nodes, secretly govern traffic independently of visible sensors. These Deep State Nodes are defined by several similarity factors, including spatial proximity (e.g., sensors located nearby in the road network), functional similarity (e.g., sensors on similar types of freeways), and behavioral similarity under specific conditions (e.g., traffic behavior during rain). This clustering approach allows for dynamic and adaptive node grouping, as sensors can belong to multiple clusters and clusters may evolve over time. Our experimental results show that DeepStateGNN offers superior scalability and faster training, while also delivering more accurate results than competitors. It effectively handles large-scale sensor networks, outperforming other methods in both traffic forecasting and reconstruction accuracy.', 'abstract_zh': '我们提出了一种新型图神经网络（GNN）模型DeepStateGNN，用于分析交通数据，并展示了其在两种关键任务（预报和重建）上的有效性。DeepStateGNN 根据各种相似性 criteria 将传感器聚类成更高层次的图节点，称为“Deep State”节点，从而形成了一个固定节点数的“Deep State”图。“Deep State”节点这个名字取了隐秘权力网络的谐音，这些节点像隐秘权力网络一样，在不依赖于可见传感器的情况下独立管理交通。这些“Deep State”节点由多种相似性因素定义，包括空间接近性（例如，路网中邻近的传感器）、功能相似性（例如，类似类型的高速公路上的传感器）和在特定条件下的行为相似性（例如，雨天的交通行为）。这种聚类方法允许动态和适应性的节点分组，因为传感器可以属于多个聚类，聚类也可能随着时间演化。实验结果表明，DeepStateGNN 在可扩展性、训练速度以及准确性方面优于其他竞争方法，并且在大规模传感器网络中表现出色，在交通预报和重建准确性方面均优于其他方法。', 'title_zh': '小图即一切：DeepStateGNN 用于可扩展的交通预测'}
{'arxiv_id': 'arXiv:2502.14487', 'title': 'Temporal Misalignment and Probabilistic Neurons', 'authors': 'Velibor Bojković, Xiaofeng Wu, Bin Gu', 'link': 'https://arxiv.org/abs/2502.14487', 'abstract': 'Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to Artificial Neural Networks (ANNs) by mimicking biological neural principles, establishing them as a promising approach to mitigate the increasing energy demands of large-scale neural models. However, fully harnessing the capabilities of SNNs remains challenging due to their discrete signal processing and temporal dynamics. ANN-SNN conversion has emerged as a practical approach, enabling SNNs to achieve competitive performance on complex machine learning tasks. In this work, we identify a phenomenon in the ANN-SNN conversion framework, termed temporal misalignment, in which random spike rearrangement across SNN layers leads to performance improvements. Based on this observation, we introduce biologically plausible two-phase probabilistic (TPP) spiking neurons, further enhancing the conversion process. We demonstrate the advantages of our proposed method both theoretically and empirically through comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet across a variety of architectures, achieving state-of-the-art results.', 'abstract_zh': 'Spiking Neural Networks (SNNs)在模仿生物神经原则方面提供了一种更节能的替代方案，成为减轻大规模神经模型日益增加的能耗的有前途的方法。然而，全面发挥SNNs的能力仍具有挑战性，这是因为它们的离散信号处理和时间动态。ANN-SNN转换作为一种实用的方法 emerged as a practical approach，使SNNs能够在复杂机器学习任务中实现竞争性能。在本工作中，我们指出了ANN-SNN转换框架中的一个现象，称为时间对齐不匹配，其中SNN层间的随机尖峰重新排列导致性能提升。基于这一观察，我们引入了生物上合理的两阶段概率（TPP）尖峰神经元，进一步增强了转换过程。通过在CIFAR-10/100、CIFAR10-DVS和ImageNet上涵盖多种架构的全面实验，我们从理论上和实验上证明了我们提出的方法的优势，并取得了目前最先进的结果。', 'title_zh': '时空失准与概率神经元'}
{'arxiv_id': 'arXiv:2502.14486', 'title': 'How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation', 'authors': 'Zhuohang Long, Siyuan Wang, Shujun Liu, Yuhang Lai, Xuanjing Huang, Zhongyu Wei', 'link': 'https://arxiv.org/abs/2502.14486', 'abstract': "Jailbreak attacks, where harmful prompts bypass generative models' built-in safety, raise serious concerns about model vulnerability. While many defense methods have been proposed, the trade-offs between safety and helpfulness, and their application to Large Vision-Language Models (LVLMs), are not well understood. This paper systematically examines jailbreak defenses by reframing the standard generation task as a binary classification problem to assess model refusal tendencies for both harmful and benign queries. We identify two key defense mechanisms: safety shift, which increases refusal rates across all queries, and harmfulness discrimination, which improves the model's ability to distinguish between harmful and benign inputs. Using these mechanisms, we develop two ensemble defense strategies-inter-mechanism ensembles and intra-mechanism ensembles-to balance safety and helpfulness. Experiments on the MM-SafetyBench and MOSSBench datasets with LLaVA-1.5 models show that these strategies effectively improve model safety or optimize the trade-off between safety and helpfulness.", 'abstract_zh': 'Jailbreak攻击通过有害提示规避生成模型内置的安全机制，引发了对模型脆弱性的严重担忧。尽管已经提出了许多防御方法，但这些方法在安全性和帮助性之间的权衡，以及它们在大规模视觉-语言模型（LVLMs）上的应用尚不完全清楚。本文通过重新定义标准生成任务为二元分类问题，系统地研究了防御机制，以评估模型对有害和良性查询的拒绝倾向。我们识别了两种关键防御机制：安全性转移，它提高了所有查询的拒绝率；有害性辨别，它提高了模型区分有害和良性输入的能力。利用这些机制，我们开发了两种集成防御策略——跨机制集成和机制内集成，以平衡安全性和帮助性。实验结果表明，这些策略有效地提高了模型安全性或优化了安全性和帮助性之间的权衡。', 'title_zh': 'Jailbreak 防御机制及其集成研究：一种机制性调查'}
{'arxiv_id': 'arXiv:2502.14442', 'title': 'Stochastic Resonance Improves the Detection of Low Contrast Images in Deep Learning Models', 'authors': 'Siegfried Ludwig', 'link': 'https://arxiv.org/abs/2502.14442', 'abstract': 'Stochastic resonance describes the utility of noise in improving the detectability of weak signals in certain types of systems. It has been observed widely in natural and engineered settings, but its utility in image classification with rate-based neural networks has not been studied extensively. In this analysis a simple LSTM recurrent neural network is trained for digit recognition and classification. During the test phase, image contrast is reduced to a point where the model fails to recognize the presence of a stimulus. Controlled noise is added to partially recover classification performance. The results indicate the presence of stochastic resonance in rate-based recurrent neural networks.', 'abstract_zh': '随机共振描述了噪声在改善某些类型系统中弱信号可检测性方面的应用。它已在自然和工程环境中广泛观察到，但在基于速率的神经网络中的图像分类应用中尚未进行详细研究。在此分析中，我们训练了一个简单的LSTM循环神经网络进行数字识别和分类。在测试阶段，降低图像对比度至网络无法识别刺激存在的程度。通过添加受控噪声部分恢复分类性能。结果表明，基于速率的循环神经网络中存在随机共振现象。', 'title_zh': '随机共振改善了深度学习模型中低对比度图像的检测'}
{'arxiv_id': 'arXiv:2502.14424', 'title': 'Distribution Matching for Self-Supervised Transfer Learning', 'authors': 'Yuling Jiao, Wensen Ma, Defeng Sun, Hansheng Wang, Yang Wang', 'link': 'https://arxiv.org/abs/2502.14424', 'abstract': 'In this paper, we propose a novel self-supervised transfer learning method called Distribution Matching (DM), which drives the representation distribution toward a predefined reference distribution while preserving augmentation invariance. The design of DM results in a learned representation space that is intuitively structured and offers easily interpretable hyperparameters. Experimental results across multiple real-world datasets and evaluation metrics demonstrate that DM performs competitively on target classification tasks compared to existing self-supervised transfer learning methods. Additionally, we provide robust theoretical guarantees for DM, including a population theorem and an end-to-end sample theorem. The population theorem bridges the gap between the self-supervised learning task and target classification accuracy, while the sample theorem shows that, even with a limited number of samples from the target domain, DM can deliver exceptional classification performance, provided the unlabeled sample size is sufficiently large.', 'abstract_zh': '本文提出了一种新颖的自监督迁移学习方法，称为分布匹配（DM），该方法驱动表示分布趋向预定义的参考分布，同时保持增强不变性。DM的设计导致了一个直观结构化的学习表示空间，并提供了易于解释的超参数。在多个实际数据集和评估指标上的实验结果表明，DM在目标分类任务上与现有的自监督迁移学习方法具有竞争力。此外，我们为DM提供了稳健的理论保障，包括总体定理和端到端样本定理。总体定理将自监督学习任务与目标分类准确性联系起来，而样本定理表明，即使在目标域中仅有有限数量的样本，只要未标注样本的数量足够大，DM仍能实现卓越的分类性能。', 'title_zh': '自我监督迁移学习中的分布匹配'}
{'arxiv_id': 'arXiv:2502.14380', 'title': 'Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations', 'authors': 'Mariko Kato, Hakaze Cho, Yoshihiro Sakai, Naoya Inoue', 'link': 'https://arxiv.org/abs/2502.14380', 'abstract': "The performance of In-Context Learning (ICL) is highly sensitive to the selected demonstrations. Existing approaches to demonstration selection optimize different objectives, yielding inconsistent results. To address this, we propose a unified metric--affinity and diversity--that leverages ICL model's internal representations. Our experiments show that both affinity and diversity strongly correlate with test accuracies, indicating their effectiveness for demonstration selection. Moreover, we show that our proposed metrics align well with various previous works to unify the inconsistency.", 'abstract_zh': '基于上下文学习的表现高度依赖于所选示例。现有的示例选择方法优化不同的目标，导致结果不一致。为了解决这一问题，我们提出了一种统一的度量标准——亲和度与多样性，该标准利用了基于上下文学习模型的内部表示。我们的实验表明，亲和度和多样性与测试准确性高度相关，表明它们在示例选择中的有效性。此外，我们展示了我们提出的度量标准与多种先前工作中的一致性良好，有助于统一这些差异。', 'title_zh': '亲和力与多样性：基于内部表示的示范选择统一度量标准'}
{'arxiv_id': 'arXiv:2502.14372', 'title': 'Discovering highly efficient low-weight quantum error-correcting codes with reinforcement learning', 'authors': 'Austin Yubo He, Zi-Wen Liu', 'link': 'https://arxiv.org/abs/2502.14372', 'abstract': 'The realization of scalable fault-tolerant quantum computing is expected to hinge on quantum error-correcting codes. In the quest for more efficient quantum fault tolerance, a critical code parameter is the weight of measurements that extract information about errors to enable error correction: as higher measurement weights require higher implementation costs and introduce more errors, it is important in code design to optimize measurement weight. This underlies the surging interest in quantum low-density parity-check (qLDPC) codes, the study of which has primarily focused on the asymptotic (large-code-limit) properties. In this work, we introduce a versatile and computationally efficient approach to stabilizer code weight reduction based on reinforcement learning (RL), which produces new low-weight codes that substantially outperform the state of the art in practically relevant parameter regimes, extending significantly beyond previously accessible small distances. For example, our approach demonstrates savings in physical qubit overhead compared to existing results by 1 to 2 orders of magnitude for weight 6 codes and brings the overhead into a feasible range for near-future experiments. We also investigate the interplay between code parameters using our RL framework, offering new insights into the potential efficiency and power of practically viable coding strategies. Overall, our results demonstrate how RL can effectively advance the crucial yet challenging problem of quantum code discovery and thereby facilitate a faster path to the practical implementation of fault-tolerant quantum technologies.', 'abstract_zh': '可扩展容错量子计算的实现有望依赖于量子纠错码。在寻求更高效的量子容错性中，纠错码的一个关键参数是提取错误信息的测量权重：较高测量权重需要更高的实现成本并引入更多错误，因此在编码设计中优化测量权重非常重要。这促进了对量子低密度 parity-check (qLDPC) 码的研究兴趣，该项研究主要集中在渐近（大码长极限）性质上。在本工作中，我们基于强化学习（RL）提出了一个灵活且计算高效的稳定器码权重减小方法，该方法在实际相关参数范围内生成了性能显著优于现有最佳结果的新低权重码，大大超越了先前可访问的小距离。例如，我们的方法在权重为6的编码中与现有结果相比，物理量子比特开销节省了1到2个数量级，并将开销带入了近期实验可行的范围。我们还利用我们的RL框架研究了编码参数之间的相互作用，提供了对实际可行编码策略的潜在效率和能力的新见解。总体而言，我们的结果展示了RL如何有效推进关键而具有挑战性的量子编码发现问题，并从而促进更快实现容错量子技术的实用性。', 'title_zh': '使用强化学习发现高效低权重量子纠错码'}
{'arxiv_id': 'arXiv:2502.14366', 'title': 'Entropy-UID: A Method for Optimizing Information Density', 'authors': 'Xinpeng Shou', 'link': 'https://arxiv.org/abs/2502.14366', 'abstract': 'Balanced and efficient information flow is essential for optimizing language generation models. In this work, we propose Entropy-UID, a new token selection method that balances entropy and Uniform Information Density (UID) principles for enhanced efficiency of text generation. Our approach adaptively adjusts token selection by jointly minimizing entropy and surprisal, promoting more even information distribution across generated sequences. Theoretical validation demonstrates that Entropy-UID optimally reduces information spikes while maintaining fluency and coherence. The method has been evulated using information-theoretic metrics on multiple benchmark datasets, including WikiText-2, OpenWebText, and WMT. Experimental results show that Entropy-UID achieves lower surprisal and entropy variance compared to standard GPT-2 and alternative heuristics, leading to more balanced and human-like text generation. Our findings point towards the potential of leveraging information-theoretic constraints to refine token selection strategies in autoregressive language models.', 'abstract_zh': '平衡且高效的信道流是优化语言生成模型的关键。本文提出了一种新的标记选择方法Entropy-UID，该方法结合熵和均匀信息密度原则以提高文本生成效率。我们的方法通过联合最小化熵和 surprisal，自适应调整标记选择，促进生成序列中信息分布更加均衡。理论验证表明，Entropy-UID 最优地减少了信息尖峰现象，同时保持流畅性和连贯性。该方法在多个基准数据集（包括 WikiText-2、OpenWebText 和 WMT）上使用信息论指标进行评估，实验结果显示，对比标准的 GPT-2 和其他启发式方法，Entropy-UID 能实现更低的 surprisal 和熵方差，从而获得更加均衡和类似人类的文本生成。我们的研究结果指出了利用信息论约束来改进自回归语言模型中标记选择策略的潜力。', 'title_zh': '熵-UID：一种优化信息密度的方法'}
{'arxiv_id': 'arXiv:2502.14365', 'title': 'Is Q-learning an Ill-posed Problem?', 'authors': 'Philipp Wissmann, Daniel Hein, Steffen Udluft, Thomas Runkler', 'link': 'https://arxiv.org/abs/2502.14365', 'abstract': 'This paper investigates the instability of Q-learning in continuous environments, a challenge frequently encountered by practitioners. Traditionally, this instability is attributed to bootstrapping and regression model errors. Using a representative reinforcement learning benchmark, we systematically examine the effects of bootstrapping and model inaccuracies by incrementally eliminating these potential error sources. Our findings reveal that even in relatively simple benchmarks, the fundamental task of Q-learning - iteratively learning a Q-function from policy-specific target values - can be inherently ill-posed and prone to failure. These insights cast doubt on the reliability of Q-learning as a universal solution for reinforcement learning problems.', 'abstract_zh': '这篇论文探讨了连续环境中Q-learning的不稳定性，这是从业者经常遇到的一个挑战。传统上，这种不稳定性被认为是由于 bootstrapping 和回归模型误差导致的。通过一个代表性的强化学习基准，我们系统地消除了这些潜在的误差源，以研究它们的影响。我们的发现表明，即使在相对较简单的基准中，Q-learning 基本任务——从特定策略的目标值中迭代学习 Q 函数——可能是本就存在问题且容易失败的。这些见解对 Q-learning 作为强化学习问题通用解决方案的可靠性提出了质疑。', 'title_zh': 'Q-learning是一个病态问题吗？'}
{'arxiv_id': 'arXiv:2502.14334', 'title': 'Purest Quantum State Identification', 'authors': 'Yingqi Yu, Honglin Chen, Jun Wu, Wei Xie, Xiangyang Li', 'link': 'https://arxiv.org/abs/2502.14334', 'abstract': 'Precise identification of quantum states under noise constraints is essential for quantum information processing. In this study, we generalize the classical best arm identification problem to quantum domains, designing methods for identifying the purest one within $K$ unknown $n$-qubit quantum states using $N$ samples. %, with direct applications in quantum computation and quantum communication. We propose two distinct algorithms: (1) an algorithm employing incoherent measurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N H_1}{\\log(K) 2^n }\\right) \\right)$, and (2) an algorithm utilizing coherent measurements, achieving error $\\exp\\left(- \\Omega\\left(\\frac{N H_2}{\\log(K) }\\right) \\right)$, highlighting the power of quantum memory. Furthermore, we establish a lower bound by proving that all strategies with fixed two-outcome incoherent POVM must suffer error probability exceeding $ \\exp\\left( - O\\left(\\frac{NH_1}{2^n}\\right)\\right)$. This framework provides concrete design principles for overcoming sampling bottlenecks in quantum technologies.', 'abstract_zh': '精确识别噪声约束下的量子态对于量子信息处理至关重要。本研究将经典的最优臂识别问题推广至量子域，设计了在给定N次样本的情况下，在未知的K个n量子比特量子态中识别纯度最高的算法。本文提出两种不同的算法：（1）采用非相干测量的算法，错误概率为$\\exp\\left(- \\Omega\\left(\\frac{N H_1}{\\log(K) 2^n }\\right) \\right)$；（2）采用相干测量的算法，错误概率为$\\exp\\left(- \\Omega\\left(\\frac{N H_2}{\\log(K) }\\right) \\right)$，突显了量子记忆的能力。此外，我们通过证明所有固定两结果非相干POVM策略必须遭受超过$\\exp\\left( - O\\left(\\frac{NH_1}{2^n}\\right)\\right)$的错误概率来建立一个下界。该框架为克服量子技术中的采样瓶颈提供了具体的設計原則。', 'title_zh': '纯度最优量子态识别'}
{'arxiv_id': 'arXiv:2502.14297', 'title': "An Evaluation of Sakana's AI Scientist for Autonomous Research: Wishful Thinking or an Emerging Reality Towards 'Artificial General Research Intelligence' (AGRI)?", 'authors': 'Joeran Beel, Min-Yen Kan, Moritz Baumgart', 'link': 'https://arxiv.org/abs/2502.14297', 'abstract': "A major step toward Artificial General Intelligence (AGI) and Super Intelligence is AI's ability to autonomously conduct research - what we term Artificial General Research Intelligence (AGRI). If machines could generate hypotheses, conduct experiments, and write research papers without human intervention, it would transform science. Recently, this http URL introduced the AI Scientist, a system claiming to automate the research lifecycle, generating both excitement and skepticism.\nWe evaluated the AI Scientist and found it a milestone in AI-driven research. While it streamlines some aspects, it falls short of expectations. Literature reviews are weak, nearly half the experiments failed, and manuscripts sometimes contain hallucinated results. Most notably, users must provide an experimental pipeline, limiting the AI Scientist's autonomy in research design and execution.\nDespite its limitations, the AI Scientist advances research automation. Many reviewers or instructors who assess work superficially may not recognize its output as AI-generated. The system produces research papers with minimal human effort and low cost. Our analysis suggests a paper costs a few USD with a few hours of human involvement, making it significantly faster than human researchers. Compared to AI capabilities from a few years ago, this marks progress toward AGRI.\nThe rise of AI-driven research systems requires urgent discussion within Information Retrieval (IR) and broader scientific communities. Enhancing literature retrieval, citation validation, and evaluation benchmarks could improve AI-generated research reliability. We propose concrete steps, including AGRI-specific benchmarks, refined peer review, and standardized attribution frameworks. Whether AGRI becomes a stepping stone to AGI depends on how the academic and AI communities shape its development.", 'abstract_zh': '向着人工通用智能（AGI）和超人工智能迈出的重要一步：自主开展研究的人工智能——人工通用研究智能（AGRI）的发展。人工智能科学家系统：自动化研究生命周期的里程碑，但仍有局限性。信息检索（IR）和更广泛科学社区关于由AI驱动的研究系统的讨论需求迫切。', 'title_zh': 'Sakana的AI科学家自主研究评估：是期望之谈还是通向“通用人工智能研究”（AGRI）新兴现实的途径？'}
{'arxiv_id': 'arXiv:2502.14293', 'title': 'Graph Anomaly Detection via Adaptive Test-time Representation Learning across Out-of-Distribution Domains', 'authors': 'Delaram Pirhayati, Arlei Silva', 'link': 'https://arxiv.org/abs/2502.14293', 'abstract': 'Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present AdaGraph-T3, a novel test-time training framework for cross-domain GAD. AdaGraph-T3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that AdaGraph-T3 significantly outperforms existing approaches, achieving average improvements of over 6.6% in AUROC and 7.9% in AUPRC compared to the best competing model.', 'abstract_zh': '跨领域图异常检测的适配图框架AdaGraph-T3', 'title_zh': '跨分布外领域自适应测试时代表征学习的图异常检测'}
{'arxiv_id': 'arXiv:2502.14281', 'title': 'Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts', 'authors': 'Weipeng Huang, Qin Li, Yang Xiao, Cheng Qiao, Tie Cai, Junwei Liao, Neil J. Hurley, Guangyuan Piao', 'link': 'https://arxiv.org/abs/2502.14281', 'abstract': 'Noise in data appears to be inevitable in most real-world machine learning applications and would cause severe overfitting problems. Not only can data features contain noise, but labels are also prone to be noisy due to human input. In this paper, rather than noisy label learning in multiclass classifications, we instead focus on the less explored area of noisy label learning for multilabel classifications. Specifically, we investigate the post-correction of predictions generated from classifiers learned with noisy labels. The reasons are two-fold. Firstly, this approach can directly work with the trained models to save computational resources. Secondly, it could be applied on top of other noisy label correction techniques to achieve further improvements. To handle this problem, we appeal to deep generative approaches that are possible for uncertainty estimation. Our model posits that label noise arises from a stochastic shift in the latent variable, providing a more robust and beneficial means for noisy learning. We develop both unsupervised and semi-supervised learning methods for our model. The extensive empirical study presents solid evidence to that our approach is able to consistently improve the independent models and performs better than a number of existing methods across various noisy label settings. Moreover, a comprehensive empirical analysis of the proposed method is carried out to validate its robustness, including sensitivity analysis and an ablation study, among other elements.', 'abstract_zh': '数据中噪声的不可避免性及其对多标签分类中嘈杂标签学习的影响：一种后预测修正的方法', 'title_zh': '修正嘈杂的多标签预测：通过潜在空间位移建模标签噪声'}
{'arxiv_id': 'arXiv:2502.14260', 'title': 'EyeBench: A Call for More Rigorous Evaluation of Retinal Image Enhancement', 'authors': 'Wenhui Zhu, Xuanzhao Dong, Xin Li, Yujian Xiong, Xiwen Chen, Peijie Qiu, Vamsi Krishna Vasa, Zhangsihao Yang, Yi Su, Oana Dumitrascu, Yalin Wang', 'link': 'https://arxiv.org/abs/2502.14260', 'abstract': 'Over the past decade, generative models have achieved significant success in enhancement fundus this http URL, the evaluation of these models still presents a considerable challenge. A comprehensive evaluation benchmark for fundus image enhancement is indispensable for three main reasons: 1) The existing denoising metrics (e.g., PSNR, SSIM) are hardly to extend to downstream real-world clinical research (e.g., Vessel morphology consistency). 2) There is a lack of comprehensive evaluation for both paired and unpaired enhancement methods, along with the need for expert protocols to accurately assess clinical value. 3) An ideal evaluation system should provide insights to inform future developments of fundus image enhancement. To this end, we propose a novel comprehensive benchmark, EyeBench, to provide insights that align enhancement models with clinical needs, offering a foundation for future work to improve the clinical relevance and applicability of generative models for fundus image enhancement. EyeBench has three appealing properties: 1) multi-dimensional clinical alignment downstream evaluation: In addition to evaluating the enhancement task, we provide several clinically significant downstream tasks for fundus images, including vessel segmentation, DR grading, denoising generalization, and lesion segmentation. 2) Medical expert-guided evaluation design: We introduce a novel dataset that promote comprehensive and fair comparisons between paired and unpaired methods and includes a manual evaluation protocol by medical experts. 3) Valuable insights: Our benchmark study provides a comprehensive and rigorous evaluation of existing methods across different downstream tasks, assisting medical experts in making informed choices. Additionally, we offer further analysis of the challenges faced by existing methods. The code is available at \\url{this https URL}', 'abstract_zh': '过去十年，生成模型在视网膜图像增强方面取得了显著成功，但这些模型的评估仍然面临着重大挑战。为了满足三大主要需求，一个全面的视网膜图像增强评估基准不可或缺：1) 当前去噪指标（如PSNR、SSIM）难以扩展到下游实际临床研究（如血管形态一致性）。2) 缺乏对配对和非配对增强方法的全面评估，以及需要专家协议来准确评估临床价值。3) 理想的评估系统应为视网膜图像增强的未来发展提供有价值的信息。为此，我们提出了一种新的全面基准——EyeBench，以期将增强模型与临床需求相结合，为未来工作提供基础，以提高生成模型在视网膜图像增强方面的临床相关性和适用性。EyeBench具有三种吸引人的特性：1) 下游多维度临床对齐评估：除了评估增强任务外，我们还提供了几个临床重要的下游任务，包括血管分割、DR分级、去噪泛化和病变分割。2) 医学专家引导的评估设计：我们引入了一个促进配对和非配对方法之间全面公平比较的新数据集，并包括了一种由医学专家手动评估的协议。3) 有价值的信息：我们的基准研究提供了不同下游任务下对现有方法的全面和严格的评估，帮助医学专家做出知情选择。此外，我们还进一步分析了现有方法面临的挑战。相关代码可在[该链接]获得。', 'title_zh': 'EyeBench: 呼唤更严格的视网膜图像增强评估'}
{'arxiv_id': 'arXiv:2502.14222', 'title': 'Enhancing Pavement Sensor Data Acquisition for AI-Driven Transportation Research', 'authors': 'Manish Kumar Krishne Gowda, Andrew Balmos, Shin Boonam, James V. Krogmeier', 'link': 'https://arxiv.org/abs/2502.14222', 'abstract': "Effective strategies for sensor data management are essential for advancing transportation research, especially in the current data-driven era, due to the advent of novel applications in artificial intelligence. This paper presents comprehensive guidelines for managing transportation sensor data, encompassing both archived static data and real-time data streams. The real-time system architecture integrates various applications with data acquisition systems (DAQ). By deploying the in-house designed, open-source Avena software platform alongside the NATS messaging system as a secure communication broker, reliable data exchange is ensured. While robust databases like TimescaleDB facilitate organized storage, visualization platforms like Grafana provide real-time monitoring capabilities.\nIn contrast, static data standards address the challenges in handling unstructured, voluminous datasets. The standards advocate for a combination of cost-effective bulk cloud storage for unprocessed sensor data and relational databases for recording summarized analyses. They highlight the role of cloud data transfer tools like FME for efficient migration of sensor data from local storages onto the cloud. Further, integration of robust visualization tools into the framework helps in deriving patterns and trends from these complex datasets.\nThe proposals were applied to INDOT's real-world case studies involving the I-65 and I-69 Greenfield districts. For real-time data collection, Campbell Scientific DAQ systems were used, enabling continuous generation and monitoring of sensor metrics. In the case of the archived I-69 database, summary data was compiled in Oracle, while the unprocessed data was stored in SharePoint. The results underline the effectiveness of the proposed guidelines and motivate their adoption in research projects.", 'abstract_zh': '有效的传感器数据管理策略对于推动交通运输研究至关重要，尤其是在当前以数据驱动的时代，由于新兴的人工智能应用的出现。本文提出了全面的交通运输传感器数据管理指南，涵盖归档的静态数据和实时数据流。实时系统架构将各种应用与数据采集系统（DAQ）集成。通过部署自主研发的开源Avena软件平台和NATS消息系统作为安全通信代理，确保可靠的数据交换。强大的时序数据库（如TimescaleDB）有助于有序存储，而可视化平台（如Grafana）提供了实时监控能力。\n相比之下，静态数据标准解决了处理非结构化、大量数据集的挑战。这些标准提倡结合成本效益高的大规模云存储未处理传感器数据和关系数据库来记录汇总分析。它们强调了使用像FME这样的云数据传输工具，以高效地将传感器数据从本地存储迁移到云端的作用。此外，将强大的可视化工具整合到框架中，有助于从这些复杂数据集中提取模式和趋势。\n提出的建议应用于INDOT的实际案例研究，涉及I-65和I-69 Greenfield地区。对于实时数据采集，使用了Campbell Scientific DAQ系统，实现了传感器指标的持续生成和监控。在I-69数据库归档的情况下，汇总数据存储在Oracle中，而未处理数据存储在SharePoint中。结果强调了所提指南的有效性，并促使其在研究项目中的应用。', 'title_zh': '基于AI驱动交通研究的路面传感器数据采集增强'}
{'arxiv_id': 'arXiv:2502.14218', 'title': 'Rethinking Spiking Neural Networks from an Ensemble Learning Perspective', 'authors': 'Yongqi Ding, Lin Zuo, Mengmeng Jing, Pei He, Hanpu Deng', 'link': 'https://arxiv.org/abs/2502.14218', 'abstract': 'Spiking neural networks (SNNs) exhibit superior energy efficiency but suffer from limited performance. In this paper, we consider SNNs as ensembles of temporal subnetworks that share architectures and weights, and highlight a crucial issue that affects their performance: excessive differences in initial states (neuronal membrane potentials) across timesteps lead to unstable subnetwork outputs, resulting in degraded performance. To mitigate this, we promote the consistency of the initial membrane potential distribution and output through membrane potential smoothing and temporally adjacent subnetwork guidance, respectively, to improve overall stability and performance. Moreover, membrane potential smoothing facilitates forward propagation of information and backward propagation of gradients, mitigating the notorious temporal gradient vanishing problem. Our method requires only minimal modification of the spiking neurons without adapting the network structure, making our method generalizable and showing consistent performance gains in 1D speech, 2D object, and 3D point cloud recognition tasks. In particular, on the challenging CIFAR10-DVS dataset, we achieved 83.20\\% accuracy with only four timesteps. This provides valuable insights into unleashing the potential of SNNs.', 'abstract_zh': '基于时间的稀疏神经网络中通过膜电位平滑和暂态邻近子网络指导促进一致性以提升性能', 'title_zh': '从集成学习视角重新思考脉冲神经网络'}
{'arxiv_id': 'arXiv:2502.14205', 'title': 'Accurate Forgetting for Heterogeneous Federated Continual Learning', 'authors': 'Abudukelimu Wuerkaixi, Sen Cui, Jingfeng Zhang, Kunda Yan, Bo Han, Gang Niu, Lei Fang, Changshui Zhang, Masashi Sugiyama', 'link': 'https://arxiv.org/abs/2502.14205', 'abstract': 'Recent years have witnessed a burgeoning interest in federated learning (FL). However, the contexts in which clients engage in sequential learning remain under-explored. Bridging FL and continual learning (CL) gives rise to a challenging practical problem: federated continual learning (FCL). Existing research in FCL primarily focuses on mitigating the catastrophic forgetting issue of continual learning while collaborating with other clients. We argue that the forgetting phenomena are not invariably detrimental. In this paper, we consider a more practical and challenging FCL setting characterized by potentially unrelated or even antagonistic data/tasks across different clients. In the FL scenario, statistical heterogeneity and data noise among clients may exhibit spurious correlations which result in biased feature learning. While existing CL strategies focus on a complete utilization of previous knowledge, we found that forgetting biased information is beneficial in our study. Therefore, we propose a new concept accurate forgetting (AF) and develop a novel generative-replay method~\\method~which selectively utilizes previous knowledge in federated networks. We employ a probabilistic framework based on a normalizing flow model to quantify the credibility of previous knowledge. Comprehensive experiments affirm the superiority of our method over baselines.', 'abstract_zh': '近年来，联邦学习（FL）的研究呈现出快速增长的态势。然而，客户端在 sequential 学习中的应用场景仍相对未被充分探索。将联邦学习与连续学习（CL）相结合，产生了一个具有挑战性的实际问题：联邦连续学习（FCL）。现有 FCL 研究主要集中在如何在协作学习中缓解连续学习中的灾难性遗忘问题。我们认为遗忘现象并非总是不利的。本文探讨了一个更加实际和具有挑战性的 FCL 设置，其中不同客户端的数据或任务可能是不相关的甚至是对立的。在联邦学习场景下，客户端之间的统计异质性和数据噪声可能会表现出虚假的相关性，导致偏差的特征学习。现有的 CL 策略侧重于充分利用之前的知识，但我们发现遗忘偏差信息在我们的研究中有益。因此，我们提出了一个新的准确遗忘（AF）概念，并开发了一种新的生成式重放方法~\\method~，该方法在联邦网络中选择性地利用之前的知识。我们采用基于归一化流模型的概率框架来量化之前知识的可信度。全面的实验验证了我们方法相对于基线方法的优越性。', 'title_zh': '异构联邦持续学习中的准确遗忘'}
{'arxiv_id': 'arXiv:2502.14197', 'title': 'Adaptive Sparsified Graph Learning Framework for Vessel Behavior Anomalies', 'authors': 'Jeehong Kim, Minchan Kim, Jaeseong Ju, Youngseok Hwang, Wonhee Lee, Hyunwoo Park', 'link': 'https://arxiv.org/abs/2502.14197', 'abstract': 'Graph neural networks have emerged as a powerful tool for learning spatiotemporal interactions. However, conventional approaches often rely on predefined graphs, which may obscure the precise relationships being modeled. Additionally, existing methods typically define nodes based on fixed spatial locations, a strategy that is ill-suited for dynamic environments like maritime environments. Our method introduces an innovative graph representation where timestamps are modeled as distinct nodes, allowing temporal dependencies to be explicitly captured through graph edges. This setup is extended to construct a multi-ship graph that effectively captures spatial interactions while preserving graph sparsity. The graph is processed using Graph Convolutional Network layers to capture spatiotemporal patterns, with a forecasting layer for feature prediction and a Variational Graph Autoencoder for reconstruction, enabling robust anomaly detection.', 'abstract_zh': '图神经网络已 emerges as 一个 Powerful 工具 for 学习 空间时间 交互。然而， conventional 传统 方法 often 经常 依赖 预先定义 的图，这可能会 obscure 遮挡 精确 的关系 being 被建模。此外，现有 方法 typically 通常 基于 固定 空间 位置 定义 节点，这种策略不适合 动态 环境，如 海事 环境。我们的 方法 Introduces 引入 一个 创新的 图表示，其中 时间戳 被 建模 为 不同 的节点，允许 通过 图边 Explicitly 显式 捕获 时间依赖性。这种设置 被 扩展 以 构建 一个多船图，有效地 捕获 空间 交互 同时 保持 图稀疏性。图 通过 图卷积网络 层处理 以 捕获 空间时间 模式，具有 一个 预测 层 用于 特征 预测 以及 一个 变分 图自编码器 用于 重构，从而 实现 稳健 的异常 检测。', 'title_zh': '自适应稀疏化图学习框架以识别船舶行为异常'}
{'arxiv_id': 'arXiv:2502.14191', 'title': 'Multimodal RewardBench: Holistic Evaluation of Reward Models for Vision Language Models', 'authors': 'Michihiro Yasunaga, Luke Zettlemoyer, Marjan Ghazvininejad', 'link': 'https://arxiv.org/abs/2502.14191', 'abstract': 'Reward models play an essential role in training vision-language models (VLMs) by assessing output quality to enable aligning with human preferences. Despite their importance, the research community lacks comprehensive open benchmarks for evaluating multimodal reward models in VLMs. To address this gap, we introduce Multimodal RewardBench, an expert-annotated benchmark covering six domains: general correctness, preference, knowledge, reasoning, safety, and visual question-answering. Our dataset comprises 5,211 annotated (prompt, chosen response, rejected response) triplets collected from various VLMs. In evaluating a range of VLM judges, we find that even the top-performing models, Gemini 1.5 Pro and Claude 3.5 Sonnet, achieve only 72% overall accuracy. Notably, most models struggle in the reasoning and safety domains. These findings suggest that Multimodal RewardBench offers a challenging testbed for advancing reward model development across multiple domains. We release the benchmark at this https URL.', 'abstract_zh': '多模态奖励基准（Multimodal RewardBench）在视觉语言模型中的作用及其挑战', 'title_zh': '多模态奖励基准：视觉语言模型奖励模型的整体评估'}
{'arxiv_id': 'arXiv:2502.14183', 'title': 'Type 1 Diabetes Management using GLIMMER: Glucose Level Indicator Model with Modified Error Rate', 'authors': 'Saman Khamesian, Asiful Arefeen, Adela Grando, Bithika Thompson, Hassan Ghasemzadeh', 'link': 'https://arxiv.org/abs/2502.14183', 'abstract': 'Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals strive to regulate their blood glucose levels to avert the dangers of dysglycemia (hyperglycemia or hypoglycemia). Despite the advent of sophisticated technologies such as automated insulin delivery (AID) systems, achieving optimal glycemic control remains a formidable task. AID systems integrate continuous subcutaneous insulin infusion (CSII) and continuous glucose monitors (CGM) data, offering promise in reducing variability and increasing glucose time-in-range. However, these systems often fail to prevent dysglycemia, partly due to limitations in prediction algorithms that lack the precision to avert abnormal glucose events. This gap highlights the need for proactive behavioral adjustments. We address this need with GLIMMER, Glucose Level Indicator Model with Modified Error Rate, a machine learning approach for forecasting blood glucose levels. GLIMMER categorizes glucose values into normal and abnormal ranges and devises a novel custom loss function to prioritize accuracy in dysglycemic events where patient safety is critical. To evaluate the potential of GLIMMER for T1D management, we both use a publicly available dataset and collect new data involving 25 patients with T1D. In predicting next-hour glucose values, GLIMMER achieved a root mean square error (RMSE) of 23.97 (+/-3.77) and a mean absolute error (MAE) of 15.83 (+/-2.09) mg/dL. These results reflect a 23% improvement in RMSE and a 31% improvement in MAE compared to the best-reported error rates.', 'abstract_zh': '管理1型糖尿病（T1D）要求持续的警觉性，以调节血糖水平，避免血糖失常（高血糖或低血糖）的危险。尽管 sophisticated 技术如自动胰岛素输送（AID）系统的发展，实现最优血糖控制仍是一项艰巨的任务。AID 系统结合了持续皮下胰岛素输注（CSII）和持续葡萄糖监测（CGM）的数据，有望减少血糖波动并增加血糖在目标范围内的时间。然而，这些系统往往无法预防血糖失常，部分原因是预测算法缺乏精确性，无法避免异常血糖事件。这一差距突显了主动行为调整的必要性。我们通过 GLIMMER（Glucose Level Indicator Model with Modified Error Rate）这一机器学习方法来进行血糖水平预测，对葡萄糖值进行正常和异常范围分类，并设计了一种新颖的自定义损失函数，以在患者安全至关重要的低血糖事件中优先确保准确性。为了评估 GLIMMER 在 T1D 管理中的潜力，我们使用了一个公开可用的数据集并收集了涉及 25 名 T1D 患者的 newData。在预测下一个小时的血糖值方面，GLIMMER 达到了均方根误差（RMSE）23.97（±3.77）和平均绝对误差（MAE）15.83（±2.09）mg/dL。这些结果表明，与最佳报告的误差率相比，GLIMMER 在 RMSE 上提高了 23%，在 MAE 上提高了 31%。', 'title_zh': '使用GLIMMER进行1型糖尿病管理：修正误差率的血糖水平指示模型'}
{'arxiv_id': 'arXiv:2502.14176', 'title': 'A modal logic translation of the AGM axioms for belief revision', 'authors': 'Giacomo Bonanno', 'link': 'https://arxiv.org/abs/2502.14176', 'abstract': 'Building on the analysis of Bonanno (Artificial Intelligence, 2025) we introduce a simple modal logic containing three modal operators: a unimodal belief operator, a bimodal conditional operator and the unimodal global operator. For each AGM axiom for belief revision, we provide a corresponding modal axiom. The correspondence is as follows: each AGM axiom is characterized by a property of the Kripke-Lewis frames considered in Bonanno (Artificial Intelligence, 2025) and, in turn, that property characterizes the proposed modal axiom.', 'abstract_zh': '基于Bonanno（《人工智能》，2025）的研究，引入一种包含三种模态运算符的简单模态逻辑：单模态信念运算符、双模态条件运算符和单模态全局运算符。对于每条AGM信念修订公理，提供相应的模态公理。对应关系如下：每条AGM公理由Bonanno（《人工智能》，2025）中考虑的Kripke-Lewis框架的某个性质表征，反过来该性质表征了所提出的模态公理。', 'title_zh': '模态逻辑对AGM信念修正公理的翻译'}
{'arxiv_id': 'arXiv:2502.14174', 'title': 'Weighted Low-rank Approximation via Stochastic Gradient Descent on Manifolds', 'authors': 'Conglong Xu, Peiqi Yang, Hao Wu', 'link': 'https://arxiv.org/abs/2502.14174', 'abstract': 'We solve a regularized weighted low-rank approximation problem by a stochastic gradient descent on a manifold. To guarantee the convergence of our stochastic gradient descent, we establish a convergence theorem on manifolds for retraction-based stochastic gradient descents admitting confinements. On sample data from the Netflix Prize training dataset, our algorithm outperforms the existing stochastic gradient descent on Euclidean spaces. We also compare the accelerated line search on this manifold to the existing accelerated line search on Euclidean spaces.', 'abstract_zh': '我们通过流形上的修正加权低秩逼近问题求解方法，利用基于截断的随机梯度下降保证收敛性，并在Netflix Prize训练数据集的样本数据上，我们的算法优于欧几里得空间上的随机梯度下降。我们还比较了该流形上的加速线性搜索与欧几里得空间上的加速线性搜索。', 'title_zh': '基于流形上的随机梯度下降的加权低秩逼近'}
{'arxiv_id': 'arXiv:2502.14160', 'title': 'Efficient Inverse Multiagent Learning', 'authors': 'Denizalp Goktas, Amy Greenwald, Sadie Zhao, Alec Koppel, Sumitra Ganesh', 'link': 'https://arxiv.org/abs/2502.14160', 'abstract': "In this paper, we study inverse game theory (resp. inverse multiagent learning) in which the goal is to find parameters of a game's payoff functions for which the expected (resp. sampled) behavior is an equilibrium. We formulate these problems as generative-adversarial (i.e., min-max) optimization problems, for which we develop polynomial-time algorithms to solve, the former of which relies on an exact first-order oracle, and the latter, a stochastic one. We extend our approach to solve inverse multiagent simulacral learning in polynomial time and number of samples. In these problems, we seek a simulacrum, meaning parameters and an associated equilibrium that replicate the given observations in expectation. We find that our approach outperforms the widely-used ARIMA method in predicting prices in Spanish electricity markets based on time-series data.", 'abstract_zh': '在本文中，我们研究逆博弈理论（或逆多智能体学习），其目标是找到博弈收益函数的参数，使得期望（或采样）行为是均衡。我们将这些问题形式化为生成对抗（即，极小极大）优化问题，并为此类问题开发了多项式时间算法，前者依赖于精确的一阶oracle，后者依赖于随机的一阶oracle。我们将方法扩展以多项式时间内的样本数解决逆多智能体模拟学习问题。在这些问题中，我们寻求一个模拟物，即寻找参数及其相关的均衡，以期望方式复制给定的观察结果。我们发现，我们的方法在基于时间序列数据预测西班牙电力市场价格方面优于广泛使用的ARIMA方法。', 'title_zh': '高效逆多智能体学习'}
{'arxiv_id': 'arXiv:2502.14143', 'title': 'Multi-Agent Risks from Advanced AI', 'authors': 'Lewis Hammond, Alan Chan, Jesse Clifton, Jason Hoelscher-Obermaier, Akbir Khan, Euan McLean, Chandler Smith, Wolfram Barfuss, Jakob Foerster, Tomáš Gavenčiak, Anh Han, Edward Hughes, Vojtěch Kovařík, Jan Kulveit, Joel Z. Leibo, Caspar Oesterheld, Christian Schroeder de Witt, Nisarg Shah, Michael Wellman, Paolo Bova, Theodor Cimpeanu, Carson Ezell, Quentin Feuillade-Montixi, Matija Franklin, Esben Kran, Igor Krawczuk, Max Lamparth, Niklas Lauffer, Alexander Meinke, Sumeet Motwani, Anka Reuel, Vincent Conitzer, Michael Dennis, Iason Gabriel, Adam Gleave, Gillian Hadfield, Nika Haghtalab, Atoosa Kasirzadeh, Sébastien Krier, Kate Larson, Joel Lehman, David C. Parkes, Georgios Piliouras, Iyad Rahwan', 'link': 'https://arxiv.org/abs/2502.14143', 'abstract': "The rapid development of advanced AI agents and the imminent deployment of many instances of these agents will give rise to multi-agent systems of unprecedented complexity. These systems pose novel and under-explored risks. In this report, we provide a structured taxonomy of these risks by identifying three key failure modes (miscoordination, conflict, and collusion) based on agents' incentives, as well as seven key risk factors (information asymmetries, network effects, selection pressures, destabilising dynamics, commitment problems, emergent agency, and multi-agent security) that can underpin them. We highlight several important instances of each risk, as well as promising directions to help mitigate them. By anchoring our analysis in a range of real-world examples and experimental evidence, we illustrate the distinct challenges posed by multi-agent systems and their implications for the safety, governance, and ethics of advanced AI.", 'abstract_zh': '先进AI代理的快速发展及其部署实例将导致前所未有的复杂多代理系统。这些系统带来了新颖且尚未充分探索的风险。本报告通过基于代理激励识别三种关键失败模式（误协调、冲突和勾结），以及七种关键风险因素（信息不对称、网络效应、选择压力、不稳定性动态、承诺问题、新兴代理和多代理安全），对这些风险进行了结构化分类。我们强调了每种风险的重要实例，并指出了有助于减轻它们的有前途的方向。通过在多种现实世界例子和实验证据的基础上进行分析，我们阐明了多代理系统所带来的独特挑战及其对高级AI的安全性、治理和伦理的影响。', 'title_zh': '高级人工智能的多Agent风险'}
{'arxiv_id': 'arXiv:2502.14132', 'title': 'Can Community Notes Replace Professional Fact-Checkers?', 'authors': 'Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein', 'link': 'https://arxiv.org/abs/2502.14132', 'abstract': 'Two commonly-employed strategies to combat the rise of misinformation on social media are (i) fact-checking by professional organisations and (ii) community moderation by platform users. Policy changes by Twitter/X and, more recently, Meta, signal a shift away from partnerships with fact-checking organisations and towards an increased reliance on crowdsourced community notes. However, the extent and nature of dependencies between fact-checking and helpful community notes remain unclear. To address these questions, we use language models to annotate a large corpus of Twitter/X community notes with attributes such as topic, cited sources, and whether they refute claims tied to broader misinformation narratives. Our analysis reveals that community notes cite fact-checking sources up to five times more than previously reported. Fact-checking is especially crucial for notes on posts linked to broader narratives, which are twice as likely to reference fact-checking sources compared to other sources. In conclusion, our results show that successful community moderation heavily relies on professional fact-checking.', 'abstract_zh': '社交媒体上打击 misinformation 两个常见的策略是（i）专业组织的事实核查和（ii）平台用户的社区管理。Twitter/X 和最近的 Meta 的政策变化表明，从与事实核查组织的合作转向对众包社区注释的更大依赖。然而，事实核查与 helpful 社区注释之间的依赖程度和性质尚不明确。为了回答这些问题，我们使用语言模型对 Twitter/X 社区注释的大规模语料库进行注释，标注主题、引用来源以及是否反驳与广泛流传的 misinformation 讲述相关的内容。我们的分析显示，社区注释引用的事实核查来源比之前报道的多五倍。事实核查特别对于链接到更广泛叙述的帖子注释尤为重要，这些注释引用事实核查来源的可能性是其他来源的两倍。总之，我们的结果显示，成功的社区管理严重依赖于专业事实核查。', 'title_zh': '社区笔记能否取代专业事实核查员？'}
{'arxiv_id': 'arXiv:2502.14131', 'title': 'Gradients can train reward models: An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model', 'authors': 'Enoch H. Kang, Hema Yoganarasimhan, Lalit Jain', 'link': 'https://arxiv.org/abs/2502.14131', 'abstract': 'We study the problem of estimating Dynamic Discrete Choice (DDC) models, also known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning (offline MaxEnt-IRL) in machine learning. The objective is to recover reward or $Q^*$ functions that govern agent behavior from offline behavior data. In this paper, we propose a globally convergent gradient-based method for solving these problems without the restrictive assumption of linearly parameterized rewards. The novelty of our approach lies in introducing the Empirical Risk Minimization (ERM) based IRL/DDC framework, which circumvents the need for explicit state transition probability estimation in the Bellman equation. Furthermore, our method is compatible with non-parametric estimation techniques such as neural networks. Therefore, the proposed method has the potential to be scaled to high-dimensional, infinite state spaces. A key theoretical insight underlying our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL) condition -- a property that, while weaker than strong convexity, is sufficient to ensure fast global convergence guarantees. Through a series of synthetic experiments, we demonstrate that our approach consistently outperforms benchmark methods and state-of-the-art alternatives.', 'abstract_zh': '我们研究动态离散选择模型的估计问题，也称为机器学习中的offline最大熵逆 reinforcement learning (offline MaxEnt-IRL)。目标是从离线行为数据中恢复控制代理行为的奖励或$Q^*$函数。在本文中，我们提出了一种全局收敛的基于梯度的方法来解决这些问题，不局限于线性参数化的奖励假设。我们方法的创新之处在于引入了基于经验风险最小化(ERM)的IRL/DDC框架，避免了贝尔曼方程中显式状态转换概率的估计需求。此外，我们的方法与非参数估计技术（如神经网络）兼容。因此，所提出的方法有可能扩展到高维、无限状态空间。我们方法背后的 key 理论洞见是贝尔曼残差满足 Polyak-Lojasiewicz (PL) 条件——这一性质虽然弱于强凸性，但足以确保快速全局收敛保证。通过一系列合成实验，我们展示了我们的方法在基准方法和最先进的替代方法上具有一致的优越性能。', 'title_zh': '梯度可以训练奖励模型：离线逆强化学习和动态离散选择模型的 empirical risk minimization 方法'}
{'arxiv_id': 'arXiv:2502.14121', 'title': 'Multi-Objective Bayesian Optimization for Networked Black-Box Systems: A Path to Greener Profits and Smarter Designs', 'authors': 'Akshay Kudva, Wei-Ting Tang, Joel A. Paulson', 'link': 'https://arxiv.org/abs/2502.14121', 'abstract': 'Designing modern industrial systems requires balancing several competing objectives, such as profitability, resilience, and sustainability, while accounting for complex interactions between technological, economic, and environmental factors. Multi-objective optimization (MOO) methods are commonly used to navigate these tradeoffs, but selecting the appropriate algorithm to tackle these problems is often unclear, particularly when system representations vary from fully equation-based (white-box) to entirely data-driven (black-box) models. While grey-box MOO methods attempt to bridge this gap, they typically impose rigid assumptions on system structure, requiring models to conform to the underlying structural assumptions of the solver rather than the solver adapting to the natural representation of the system of interest. In this chapter, we introduce a unifying approach to grey-box MOO by leveraging network representations, which provide a general and flexible framework for modeling interconnected systems as a series of function nodes that share various inputs and outputs. Specifically, we propose MOBONS, a novel Bayesian optimization-inspired algorithm that can efficiently optimize general function networks, including those with cyclic dependencies, enabling the modeling of feedback loops, recycle streams, and multi-scale simulations - features that existing methods fail to capture. Furthermore, MOBONS incorporates constraints, supports parallel evaluations, and preserves the sample efficiency of Bayesian optimization while leveraging network structure for improved scalability. We demonstrate the effectiveness of MOBONS through two case studies, including one related to sustainable process design. By enabling efficient MOO under general graph representations, MOBONS has the potential to significantly enhance the design of more profitable, resilient, and sustainable engineering systems.', 'abstract_zh': '现代工业系统设计需要在盈利能力、韧性和可持续性等多个目标之间取得平衡，同时考虑技术、经济和环境因素之间的复杂交互。多目标优化（MOO）方法常用于解决这些权衡问题，但在选择合适的算法时，尤其是在系统表示从完全基于方程（白盒）到完全数据驱动（黑盒）模型之间变化时，往往不够清晰。虽然灰盒MOO方法试图弥合这一差距，但它们通常会对系统结构施加刚性假设，要求模型符合求解器的内在结构假设，而不是让求解器适应所需研究系统的自然表示。在本章中，我们通过利用网络表示提出了一种统一的灰盒MOO方法，网络表示提供了一种通用且灵活的框架，用于将相互连接的系统建模为一系列具有各种输入和输出的功能节点。具体而言，我们提出了一种MOBONS算法，这是一种受贝叶斯优化启发的新算法，能够高效优化一般功能网络，包括具有循环依赖性的网络，从而能够建模反馈回路、回收流和多层次仿真——这是现有方法未能捕捉到的功能。此外，MOBONS 支持约束条件、并行评估，并保持贝叶斯优化的样本效率，同时利用网络结构以提高可扩展性。通过两个案例研究，包括可持续工艺设计相关的案例，我们展示了MOBONS的有效性。通过在通用图表示下实现高效的MOO，MOBONS 有望显著增强更具盈利性、韧性和可持续性的工程系统设计。', 'title_zh': '网络黑盒系统多目标贝叶斯优化：通往更绿色利润和更智能设计的道路'}
{'arxiv_id': 'arXiv:2502.14114', 'title': 'Zero loss guarantees and explicit minimizers for generic overparametrized Deep Learning networks', 'authors': 'Thomas Chen, Andrew G. Moore', 'link': 'https://arxiv.org/abs/2502.14114', 'abstract': 'We determine sufficient conditions for overparametrized deep learning (DL) networks to guarantee the attainability of zero loss in the context of supervised learning, for the $\\mathcal{L}^2$ cost and {\\em generic} training data. We present an explicit construction of the zero loss minimizers without invoking gradient descent. On the other hand, we point out that increase of depth can deteriorate the efficiency of cost minimization using a gradient descent algorithm by analyzing the conditions for rank loss of the training Jacobian. Our results clarify key aspects on the dichotomy between zero loss reachability in underparametrized versus overparametrized DL.', 'abstract_zh': '我们确定了过参数化的深度学习网络在监督学习背景下，对于\\(\\mathcal{L}^2\\)损失和通用训练数据保证零损失可达性的充分条件。我们提供了一种无需使用梯度下降的方法构造零损失极小化器。另一方面，通过对训练雅可比秩损失条件的分析，我们指出网络深度增加可能会恶化梯度下降算法的成本最小化效率。我们的结果澄清了在欠参数化与过参数化深度学习之间实现零损失的二分法中的关键方面。', 'title_zh': '通用过度参数化深度学习网络的零损失保证和显式极小值'}
{'arxiv_id': 'arXiv:2502.14113', 'title': 'Object-centric Binding in Contrastive Language-Image Pretraining', 'authors': 'Rim Assouel, Pietro Astolfi, Florian Bordes, Michal Drozdzal, Adriana Romero-Soriano', 'link': 'https://arxiv.org/abs/2502.14113', 'abstract': 'Recent advances in vision language models (VLM) have been driven by contrastive models such as CLIP, which learn to associate visual information with their corresponding text descriptions. However, these models have limitations in understanding complex compositional scenes involving multiple objects and their spatial relationships. To address these challenges, we propose a novel approach that diverges from commonly used strategies, which rely on the design of hard-negative augmentations. Instead, our work focuses on integrating inductive biases into pre-trained CLIP-like models to improve their compositional understanding without using any additional hard-negatives. To that end, we introduce a binding module that connects a scene graph, derived from a text description, with a slot-structured image representation, facilitating a structured similarity assessment between the two modalities. We also leverage relationships as text-conditioned visual constraints, thereby capturing the intricate interactions between objects and their contextual relationships more effectively. Our resulting model not only enhances the performance of CLIP-based models in multi-object compositional understanding but also paves the way towards more accurate and sample-efficient image-text matching of complex scenes.', 'abstract_zh': '最近在视觉语言模型（VLM）方面的进展受到对比模型（如CLIP）的驱动，这些模型学会了将视觉信息与其相应的文本描述关联起来。然而，这些模型在理解涉及多个物体及其空间关系的复杂组合场景方面存在局限性。为了解决这些挑战，我们提出了一种新的方法，该方法偏离了依赖于硬负样本增强的设计策略，而是将归纳偏置集成到预训练的CLIP-like模型中，以提高其组合理解能力，而无需使用任何额外的硬负样本。为此，我们引入了一个绑定模块，将从文本描述中提取的场景图与槽结构化图像表示连接起来，从而促进这两种模态之间的结构化相似性评估。我们还利用关系作为文本条件的视觉约束，从而更有效地捕捉物体及其上下文关系之间的复杂相互作用。我们的模型不仅提高了基于CLIP的模型在多对象组合理解方面的性能，还为复杂场景的更准确和样本高效的图像-文本匹配奠定了基础。', 'title_zh': '对象中心的对比-langauge-image 预训练'}
{'arxiv_id': 'arXiv:2502.14080', 'title': 'Personalized Education with Generative AI and Digital Twins: VR, RAG, and Zero-Shot Sentiment Analysis for Industry 4.0 Workforce Development', 'authors': 'Yu-Zheng Lin, Karan Petal, Ahmed H Alhamadah, Sujan Ghimire, Matthew William Redondo, David Rafael Vidal Corona, Jesus Pacheco, Soheil Salehi, Pratik Satam', 'link': 'https://arxiv.org/abs/2502.14080', 'abstract': "The Fourth Industrial Revolution (4IR) technologies, such as cloud computing, machine learning, and AI, have improved productivity but introduced challenges in workforce training and reskilling. This is critical given existing workforce shortages, especially in marginalized communities like Underrepresented Minorities (URM), who often lack access to quality education. Addressing these challenges, this research presents gAI-PT4I4, a Generative AI-based Personalized Tutor for Industrial 4.0, designed to personalize 4IR experiential learning. gAI-PT4I4 employs sentiment analysis to assess student comprehension, leveraging generative AI and finite automaton to tailor learning experiences. The framework integrates low-fidelity Digital Twins for VR-based training, featuring an Interactive Tutor - a generative AI assistant providing real-time guidance via audio and text. It uses zero-shot sentiment analysis with LLMs and prompt engineering, achieving 86\\% accuracy in classifying student-teacher interactions as positive or negative. Additionally, retrieval-augmented generation (RAG) enables personalized learning content grounded in domain-specific knowledge. To adapt training dynamically, finite automaton structures exercises into states of increasing difficulty, requiring 80\\% task-performance accuracy for progression. Experimental evaluation with 22 volunteers showed improved accuracy exceeding 80\\%, reducing training time. Finally, this paper introduces a Multi-Fidelity Digital Twin model, aligning Digital Twin complexity with Bloom's Taxonomy and Kirkpatrick's model, providing a scalable educational framework.", 'abstract_zh': '第四次工业革命技术（4IR），如云计算、机器学习和AI，虽然提高了生产效率，但引入了劳动力培训和再培训的挑战。鉴于现有劳动力短缺，特别是在弱势群体如代表性不足的少数群体（URM）中，这些群体往往缺乏高质量的教育机会，因此解决这些挑战至关重要。本研究提出了一种基于生成AI的个性化工业4.0导师——gAI-PT4I4，旨在个性化4IR体验式学习。gAI-PT4I4利用情感分析评估学生理解程度，并结合生成AI和有穷自动机定制学习体验。该框架整合低保真度数字孪生用于基于VR的培训，包含交互式导师——一个通过语音和文本提供实时指导的生成AI助手。使用零样本情感分析和LLM以及提示工程，分类学生-教师互动为正面或负面的准确率达到86%。此外，检索增强生成（RAG）功能实现基于学科特定知识的个性化学习内容。为了动态适应培训需求，有穷自动机将练习划分成难度递增的状态，要求任务完成率达到80%方可继续进展。22名志愿者的实验评估显示，准确率超过80%，减少了培训时间。最后，本文介绍了多保真度数字孪生模型，将数字孪生的复杂度与布卢姆分类法和柯克帕特里克模型对齐，提供了一个可扩展的教育框架。', 'title_zh': '基于生成AI和数字孪生的个性化教育：面向工业4.0劳动力发展的VR、RAG和零-shot情感分析'}
{'arxiv_id': 'arXiv:2502.14070', 'title': 'DiffExp: Efficient Exploration in Reward Fine-tuning for Text-to-Image Diffusion Models', 'authors': 'Daewon Chae, June Suk Choi, Jinkyu Kim, Kimin Lee', 'link': 'https://arxiv.org/abs/2502.14070', 'abstract': 'Fine-tuning text-to-image diffusion models to maximize rewards has proven effective for enhancing model performance. However, reward fine-tuning methods often suffer from slow convergence due to online sample generation. Therefore, obtaining diverse samples with strong reward signals is crucial for improving sample efficiency and overall performance. In this work, we introduce DiffExp, a simple yet effective exploration strategy for reward fine-tuning of text-to-image models. Our approach employs two key strategies: (a) dynamically adjusting the scale of classifier-free guidance to enhance sample diversity, and (b) randomly weighting phrases of the text prompt to exploit high-quality reward signals. We demonstrate that these strategies significantly enhance exploration during online sample generation, improving the sample efficiency of recent reward fine-tuning methods, such as DDPO and AlignProp.', 'abstract_zh': 'Fine-tuning 文字到图像扩散模型以最大化奖励证明了可以有效提升模型性能。然而，奖励细调方法往往因在线样本生成缓慢而收敛较慢。因此，获得具有强烈奖励信号的多样化样本对于提高样本效率和整体性能至关重要。在本文中，我们引入了 DiffExp，这是一种简单有效的方法，用于奖励细调的文字到图像模型的探索策略。我们的方法采用了两种关键策略：(a) 动态调整无分类器引导的比例以增强样本多样性；(b) 随机加权文本提示中的短语以利用高质量的奖励信号。我们证明了这些策略显著提高了在线样本生成过程中的探索能力，提高了最近的奖励细调方法（如 DDPO 和 AlignProp）的样本效率。', 'title_zh': 'DiffExp: 奖励微调中高效探索的方法missive'}
{'arxiv_id': 'arXiv:2502.14047', 'title': 'Towards a Learning Theory of Representation Alignment', 'authors': 'Francesco Insulla, Shuo Huang, Lorenzo Rosasco', 'link': 'https://arxiv.org/abs/2502.14047', 'abstract': "It has recently been argued that AI models' representations are becoming aligned as their scale and performance increase. Empirical analyses have been designed to support this idea and conjecture the possible alignment of different representations toward a shared statistical model of reality. In this paper, we propose a learning-theoretic perspective to representation alignment. First, we review and connect different notions of alignment based on metric, probabilistic, and spectral ideas. Then, we focus on stitching, a particular approach to understanding the interplay between different representations in the context of a task. Our main contribution here is relating properties of stitching to the kernel alignment of the underlying representation. Our results can be seen as a first step toward casting representation alignment as a learning-theoretic problem.", 'abstract_zh': 'AI模型表示的泛化对齐：一个学习理论视角', 'title_zh': '向表示对齐的学习理论迈进'}
{'arxiv_id': 'arXiv:2502.14045', 'title': 'Position: There are no Champions in Long-Term Time Series Forecasting', 'authors': 'Lorenzo Brigato, Rafael Morand, Knut Strømmen, Maria Panagiotou, Markus Schmidt, Stavroula Mougiakakou', 'link': 'https://arxiv.org/abs/2502.14045', 'abstract': 'Recent advances in long-term time series forecasting have introduced numerous complex prediction models that consistently outperform previously published architectures. However, this rapid progression raises concerns regarding inconsistent benchmarking and reporting practices, which may undermine the reliability of these comparisons. Our position emphasizes the need to shift focus away from pursuing ever-more complex models and towards enhancing benchmarking practices through rigorous and standardized evaluation methods. To support our claim, we first perform a broad, thorough, and reproducible evaluation of the top-performing models on the most popular benchmark by training 3,500+ networks over 14 datasets. Then, through a comprehensive analysis, we find that slight changes to experimental setups or current evaluation metrics drastically shift the common belief that newly published results are advancing the state of the art. Our findings suggest the need for rigorous and standardized evaluation methods that enable more substantiated claims, including reproducible hyperparameter setups and statistical testing.', 'abstract_zh': '近期长期时间序列预测的进展引入了众多复杂的预测模型，这些模型的一致性表现超过了此前发布的架构。然而，这一快速进步引发了关于不一致基准测试和报告实践的担忧，这可能损害这些比较的可靠性。我们的立场强调，应将重点从追求更复杂的模型转移到通过严格的标准化评估方法改进基准测试实践上。为了支持这一观点，我们首先在最受欢迎的基准上对表现最好的模型进行了全面、彻底且可重复的评估，训练了3,500多个网络，覆盖14个数据集。随后，通过全面分析发现，实验设置或当前评估指标的微小变化会极大地改变人们对新公布结果推动前沿技术进步的普遍认识。我们的研究结果表明，需要采用严格的标准化评估方法，以支持更加扎实的断言，包括可重复的超参数设置和统计测试。', 'title_zh': '长期时间序列预测中无冠军准则'}
{'arxiv_id': 'arXiv:2502.14023', 'title': 'Dynamic Activation with Knowledge Distillation for Energy-Efficient Spiking NN Ensembles', 'authors': 'Orestis Konstantaropoulos, Theodoris Mallios, Maria Papadopouli', 'link': 'https://arxiv.org/abs/2502.14023', 'abstract': "While foundation AI models excel at tasks like classification and decision-making, their high energy consumption makes them unsuitable for energy-constrained applications. Inspired by the brain's efficiency, spiking neural networks (SNNs) have emerged as a viable alternative due to their event-driven nature and compatibility with neuromorphic chips. This work introduces a novel system that combines knowledge distillation and ensemble learning to bridge the performance gap between artificial neural networks (ANNs) and SNNs. A foundation AI model acts as a teacher network, guiding smaller student SNNs organized into an ensemble, called Spiking Neural Ensemble (SNE). SNE enables the disentanglement of the teacher's knowledge, allowing each student to specialize in predicting a distinct aspect of it, while processing the same input. The core innovation of SNE is the adaptive activation of a subset of SNN models of an ensemble, leveraging knowledge-distillation, enhanced with an informed-partitioning (disentanglement) of the teacher's feature space. By dynamically activating only a subset of these student SNNs, the system balances accuracy and energy efficiency, achieving substantial energy savings with minimal accuracy loss. Moreover, SNE is significantly more efficient than the teacher network, reducing computational requirements by up to 20x with only a 2% drop in accuracy on the CIFAR-10 dataset. This disentanglement procedure achieves an accuracy improvement of up to 2.4% on the CIFAR-10 dataset compared to other partitioning schemes. Finally, we comparatively analyze SNE performance under noisy conditions, demonstrating enhanced robustness compared to its ANN teacher. In summary, SNE offers a promising new direction for energy-constrained applications.", 'abstract_zh': '一种结合知识蒸馏和集成学习的事件触发神经网络系统：提高能量效率的同时保持性能', 'title_zh': '知识蒸馏指导的动态激活用于节能Spiking NN集成'}
{'arxiv_id': 'arXiv:2502.14011', 'title': 'DFDT: Dynamic Fast Decision Tree for IoT Data Stream Mining on Edge Devices', 'authors': 'Afonso Lourenço, João Rodrigo, João Gama, Goreti Marreiros', 'link': 'https://arxiv.org/abs/2502.14011', 'abstract': 'The Internet of Things generates massive data streams, with edge computing emerging as a key enabler for online IoT applications and 5G networks. Edge solutions facilitate real-time machine learning inference, but also require continuous adaptation to concept drifts. Ensemble-based solutions improve predictive performance, but incur higher resource consumption, latency, and memory demands. This paper presents DFDT: Dynamic Fast Decision Tree, a novel algorithm designed for energy-efficient memory-constrained data stream mining. DFDT improves hoeffding tree growth efficiency by dynamically adjusting grace periods, tie thresholds, and split evaluations based on incoming data. It incorporates stricter evaluation rules (based on entropy, information gain, and leaf instance count), adaptive expansion modes, and a leaf deactivation mechanism to manage memory, allowing more computation on frequently visited nodes while conserving energy on others. Experiments show that the proposed framework can achieve increased predictive performance (0.43 vs 0.29 ranking) with constrained memory and a fraction of the runtime of VFDT or SVFDT.', 'abstract_zh': '物联网生成大量数据流，边缘计算作为关键使能器促进了在线物联网应用和5G网络的发展。边缘解决方案支持实时机器学习推理，但也需要持续适应概念漂移。基于集成的方法可以提高预测性能，但会导致更高的资源消耗、延迟和内存需求。本文提出DFDT：动态快速决策树，一种针对能量高效和内存受限的数据流挖掘的新型算法。DFDT通过根据流入数据动态调整宽限期、平局阈值和分裂评估来提高霍夫丁树的增长效率。该算法结合了更严格的评估规则（基于熵、信息增益和叶节点实例计数），自适应扩展模式以及叶节点去激活机制来管理内存，从而在经常访问的节点上进行更多计算，而在其他节点上节省能量。实验结果显示，所提出的框架在受限内存和VFDT或SVFDT较少的运行时间内可以实现更高的预测性能（排名从0.29提升到0.43）。', 'title_zh': 'DFDT：边缘设备上物联网数据流 Mining 的动态快速决策树'}
{'arxiv_id': 'arXiv:2502.14003', 'title': 'Rectified Lagrangian for Out-of-Distribution Detection in Modern Hopfield Networks', 'authors': 'Ryo Moriai, Nakamasa Inoue, Masayuki Tanaka, Rei Kawakami, Satoshi Ikehata, Ikuro Sato', 'link': 'https://arxiv.org/abs/2502.14003', 'abstract': 'Modern Hopfield networks (MHNs) have recently gained significant attention in the field of artificial intelligence because they can store and retrieve a large set of patterns with an exponentially large memory capacity. A MHN is generally a dynamical system defined with Lagrangians of memory and feature neurons, where memories associated with in-distribution (ID) samples are represented by attractors in the feature space. One major problem in existing MHNs lies in managing out-of-distribution (OOD) samples because it was originally assumed that all samples are ID samples. To address this, we propose the rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that explicitly incorporates an attractor for OOD samples in the dynamical system of MHNs. RecLag creates a trivial point attractor for any interaction matrix, enabling OOD detection by identifying samples that fall into this attractor as OOD. The interaction matrix is optimized so that the probability densities can be estimated to identify ID/OOD. We demonstrate the effectiveness of RecLag-based MHNs compared to energy-based OOD detection methods, including those using state-of-the-art Hopfield energies, across nine image datasets.', 'abstract_zh': '现代霍普菲尔德网络（MHNs）近年来在人工智能领域引起了广泛关注，因为它们能够存储和检索大量模式，并具有指数级大的记忆容量。在现有的MHNs中，管理来自分布外（OOD）样本是一个主要问题，因为最初假设所有样本都是来自分布内（ID）样本。为了应对这一挑战，我们提出了修正拉格朗日（RegLag），这是一种新的用于记忆神经元的拉格朗日函数，它在MHN的动力系统中显式地引入了OOD样本的吸引子。RecLag通过在任何交互矩阵下创建一个平凡的点吸引子，使得可以通过识别落入该吸引子的样本来检测OOD。交互矩阵被优化以估计概率密度，从而识别ID和OOD样本。我们展示了基于RecLag的MHNs在九个图像数据集上的有效性和与基于能量的OOD检测方法（包括最先进的霍普菲尔德能量方法）的比较。', 'title_zh': '修正后的拉格朗日乘子法在现代霍普菲尔德网络中的离分布检测'}
{'arxiv_id': 'arXiv:2502.14001', 'title': 'Towards a perturbation-based explanation for medical AI as differentiable programs', 'authors': 'Takeshi Abe, Yoshiyuki Asai', 'link': 'https://arxiv.org/abs/2502.14001', 'abstract': 'Recent advancement in machine learning algorithms reaches a point where medical devices can be equipped with artificial intelligence (AI) models for diagnostic support and routine automation in clinical settings. In medicine and healthcare, there is a particular demand for sufficient and objective explainability of the outcome generated by AI models. However, AI models are generally considered as black boxes due to their complexity, and the computational process leading to their response is often opaque. Although several methods have been proposed to explain the behavior of models by evaluating the importance of each feature in discrimination and prediction, they may suffer from biases and opacities arising from the scale and sampling protocol of the dataset used for training or testing. To overcome the shortcomings of existing methods, we explore an alternative approach to provide an objective explanation of AI models that can be defined independently of the learning process and does not require additional data. As a preliminary study for this direction of research, this work examines a numerical availability of the Jacobian matrix of deep learning models that measures how stably a model responses against small perturbations added to the input. The indicator, if available, are calculated from a trained AI model for a given target input. This is a first step towards a perturbation-based explanation, which will assist medical practitioners in understanding and interpreting the response of the AI model in its clinical application.', 'abstract_zh': '最近机器学习算法的发展使得医疗设备能够配备人工智能模型以提供诊断支持和临床环境中的常规自动化。在医学和医疗保健领域，特别是需要足够的客观解释AI模型生成的结果。然而，由于其复杂性，AI模型通常被视为黑 box，并且其触发响应的计算过程往往是不透明的。尽管已经提出了一些方法通过评估每个特征在鉴别和预测中的重要性来解释模型的行为，但它们可能会因训练或测试所用数据集的规模和采样方案而产生偏见和不透明性。为了克服现有方法的局限性，我们探索了一种替代方法，旨在提供一种独立于学习过程的客观解释，无需额外数据。作为这一研究方向的初步研究，本工作检查了深度学习模型雅可比矩阵的数值可用性，以衡量在输入中添加小扰动时模型响应的稳定性。如果可用，该指标将从给定的目标输入训练的AI模型中计算得出。这是基于扰动的解释的第一步，将帮助医疗专业人员理解并解释AI模型在临床应用中的响应。', 'title_zh': '基于扰动的解释：医疗AI可微程序的方法'}
{'arxiv_id': 'arXiv:2502.13991', 'title': 'Learning to Discover Regulatory Elements for Gene Expression Prediction', 'authors': 'Xingyu Su, Haiyang Yu, Degui Zhi, Shuiwang Ji', 'link': 'https://arxiv.org/abs/2502.13991', 'abstract': 'We consider the problem of predicting gene expressions from DNA sequences. A key challenge of this task is to find the regulatory elements that control gene expressions. Here, we introduce Seq2Exp, a Sequence to Expression network explicitly designed to discover and extract regulatory elements that drive target gene expression, enhancing the accuracy of the gene expression prediction. Our approach captures the causal relationship between epigenomic signals, DNA sequences and their associated regulatory elements. Specifically, we propose to decompose the epigenomic signals and the DNA sequence conditioned on the causal active regulatory elements, and apply an information bottleneck with the Beta distribution to combine their effects while filtering out non-causal components. Our experiments demonstrate that Seq2Exp outperforms existing baselines in gene expression prediction tasks and discovers influential regions compared to commonly used statistical methods for peak detection such as MACS3. The source code is released as part of the AIRS library (this https URL).', 'abstract_zh': '从DNA序列预测基因表达：Seq2Exp网络的设计与应用', 'title_zh': '学习发现调控元件以预测基因表达'}
{'arxiv_id': 'arXiv:2502.13979', 'title': 'Utilizing Effective Dynamic Graph Learning to Shield Financial Stability from Risk Propagation', 'authors': 'Guanyuan Yu, Qing Li, Yu Zhao, Jun Wang, YiJun Chen, Shaolei Chen', 'link': 'https://arxiv.org/abs/2502.13979', 'abstract': 'Financial risks can propagate across both tightly coupled temporal and spatial dimensions, posing significant threats to financial stability. Moreover, risks embedded in unlabeled data are often difficult to detect. To address these challenges, we introduce GraphShield, a novel approach with three key innovations: Enhanced Cross-Domain Infor mation Learning: We propose a dynamic graph learning module to improve information learning across temporal and spatial domains. Advanced Risk Recognition: By leveraging the clustering characteristics of risks, we construct a risk recognizing module to enhance the identification of hidden threats. Risk Propagation Visualization: We provide a visualization tool for quantifying and validating nodes that trigger widespread cascading risks. Extensive experiments on two real-world and two open-source datasets demonstrate the robust performance of our framework. Our approach represents a significant advancement in leveraging artificial intelligence to enhance financial stability, offering a powerful solution to mitigate the spread of risks within financial networks.', 'abstract_zh': '金融风险可以在紧密耦合的时间和空间维度上传播，对金融稳定构成重大威胁。此外，嵌入未标记数据中的风险往往难以检测。为应对这些挑战，我们介绍了GraphShield这一新型方法，具备三大创新：增强跨域信息学习：我们提出了一种动态图学习模块，以提高跨时间和空间域的信息学习能力。高级风险识别：通过利用风险的聚类特性，我们构建了一种风险识别模块，以增强对潜在威胁的识别能力。风险传播可视化：我们提供了可视化工具，用于量化和验证触发广泛传导风险的节点。在两个真实世界和两个开源数据集上的广泛实验表明，该框架具有稳健的性能。我们的方法代表了利用人工智能增强金融稳定的显著进展，提供了一种强大的解决方案，以减轻金融网络内风险的传播。', 'title_zh': '利用有效的动态图学习来屏蔽金融稳定性免受风险传播的影响'}
{'arxiv_id': 'arXiv:2502.13972', 'title': 'IncepFormerNet: A multi-scale multi-head attention network for SSVEP classification', 'authors': 'Yan Huang, Yongru Chen, Lei Cao, Yongnian Cao, Xuechun Yang, Yilin Dong, Tianyu Liu', 'link': 'https://arxiv.org/abs/2502.13972', 'abstract': 'In recent years, deep learning (DL) models have shown outstanding performance in EEG classification tasks, particularly in Steady-State Visually Evoked Potential(SSVEP)-based Brain-Computer-Interfaces(BCI)systems. DL methods have been successfully applied to SSVEP-BCI. This study proposes a new model called IncepFormerNet, which is a hybrid of the Inception and Transformer architectures. IncepFormerNet adeptly extracts multi-scale temporal information from time series data using parallel convolution kernels of varying sizes, accurately capturing the subtle variations and critical features within SSVEP this http URL, the model integrates the multi-head attention mechanism from the Transformer architecture, which not only provides insights into global dependencies but also significantly enhances the understanding and representation of complex this http URL, it takes advantage of filter bank techniques to extract features based on the spectral characteristics of SSVEP data. To validate the effectiveness of the proposed model, we conducted experiments on two public datasets, . The experimental results show that IncepFormerNet achieves an accuracy of 87.41 on Dataset 1 and 71.97 on Dataset 2 using a 1.0-second time window. To further verify the superiority of the proposed model, we compared it with other deep learning models, and the results indicate that our method achieves significantly higher accuracy than the this http URL source codes in this work are available at: this https URL.', 'abstract_zh': '近年来，深度学习（DL）模型在脑电图（EEG）分类任务中表现出色，特别是在基于稳定状态视性诱发电位（SSVEP）的脑-机接口（BCI）系统中。深度学习方法已被成功应用于SSVEP-BCI系统。本研究提出了一种名为IncepFormerNet的新模型，该模型是Inception和Transformer架构的 hybrid。IncepFormerNet利用不同大小的并行卷积内核有效地从时间序列数据中提取多尺度时域信息，准确捕捉SSVEP中的微小变化和关键特征。该模型整合了Transformer架构中的多头注意力机制，不仅提供了全局依赖性的洞察，还显著增强了复杂信号的理解和表示。通过滤波器银行技术，IncepFormerNet基于SSVEP数据的频谱特性提取特征。为了验证所提模型的有效性，我们在两个公开数据集上进行了实验。实验结果表明，IncepFormerNet在数据集1中的准确率为87.41%，在数据集2中的准确率为71.97%。为了进一步验证所提模型的优越性，我们将其与其他深度学习模型进行了比较，结果表明我们的方法在准确率上显著优于其他方法。本文的源代码可在以下网址获取：this https URL。', 'title_zh': 'IncepFormerNet：一种多尺度多头注意力网络的SSVEP分类'}
