{'arxiv_id': 'arXiv:2508.09003', 'title': 'Large Scale Robotic Material Handling: Learning, Planning, and Control', 'authors': 'Filippo A. Spinelli, Yifan Zhai, Fang Nan, Pascal Egli, Julian Nubert, Thilo Bleumer, Lukas Miller, Ferdinand Hofmann, Marco Hutter', 'link': 'https://arxiv.org/abs/2508.09003', 'abstract': "Bulk material handling involves the efficient and precise moving of large quantities of materials, a core operation in many industries, including cargo ship unloading, waste sorting, construction, and demolition. These repetitive, labor-intensive, and safety-critical operations are typically performed using large hydraulic material handlers equipped with underactuated grippers. In this work, we present a comprehensive framework for the autonomous execution of large-scale material handling tasks. The system integrates specialized modules for environment perception, pile attack point selection, path planning, and motion control. The main contributions of this work are two reinforcement learning-based modules: an attack point planner that selects optimal grasping locations on the material pile to maximize removal efficiency and minimize the number of scoops, and a robust trajectory following controller that addresses the precision and safety challenges associated with underactuated grippers in movement, while utilizing their free-swinging nature to release material through dynamic throwing. We validate our framework through real-world experiments on a 40 t material handler in a representative worksite, focusing on two key tasks: high-throughput bulk pile management and high-precision truck loading. Comparative evaluations against human operators demonstrate the system's effectiveness in terms of precision, repeatability, and operational safety. To the best of our knowledge, this is the first complete automation of material handling tasks on a full scale.", 'abstract_zh': '大规模物料处理涉及大量材料的高效精准搬运，是许多行业，包括货物卸载、废物分类、建筑和拆除等核心操作。这些重复性强、劳动密集且安全性要求高的操作通常使用大型液压物料处理设备和欠驱动夹爪进行。本文提出了一种全面框架，用于自主执行大规模物料处理任务。该系统整合了专门用于环境感知、堆料攻击点选择、路径规划和运动控制的模块。本文的主要贡献是两个基于强化学习的模块：攻击点规划器，用于选择最大化移除效率并最小化铲斗次数的最佳抓取位置；以及鲁棒轨迹跟随控制器，该控制器解决了欠驱动夹爪在移动中面临的精确度和安全性挑战，并利用其自由摆动的特性通过动态投掷来释放物料。我们通过在典型工地上的40吨物料处理设备进行的实际实验验证了该框架，重点是两个关键任务：高通量堆料管理和高精度卡车装货。与人工操作者的对比评估表明，该系统在精确度、重复性和操作安全性方面具有显著效果。据我们所知，这是首次实现大规模物料处理任务的完全自动化。', 'title_zh': '大规模机器人物料处理：学习、计划与控制'}
{'arxiv_id': 'arXiv:2508.08748', 'title': 'Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT', 'authors': 'Muhammad A. Muttaqien, Tomohiro Motoda, Ryo Hanai, Yukiyasu Domae', 'link': 'https://arxiv.org/abs/2508.08748', 'abstract': 'Robotic pick-and-place tasks in convenience stores pose challenges due to dense object arrangements, occlusions, and variations in object properties such as color, shape, size, and texture. These factors complicate trajectory planning and grasping. This paper introduces a perception-action pipeline leveraging annotation-guided visual prompting, where bounding box annotations identify both pickable objects and placement locations, providing structured spatial guidance. Instead of traditional step-by-step planning, we employ Action Chunking with Transformers (ACT) as an imitation learning algorithm, enabling the robotic arm to predict chunked action sequences from human demonstrations. This facilitates smooth, adaptive, and data-driven pick-and-place operations. We evaluate our system based on success rate and visual analysis of grasping behavior, demonstrating improved grasp accuracy and adaptability in retail environments.', 'abstract_zh': '便利店中机器人捡取放置任务因密度大的物体排列、遮挡以及颜色、形状、大小和纹理等物体属性的变异而面临挑战。这些因素使轨迹规划和抓取操作复杂化。本文引入一种基于标注引导的视觉提示感知行动管道，其中边界框标注识别可捡取物体和放置位置，提供结构化的空间指导。我们采用基于 Transformers 的行动片段化（ACT）作为模仿学习算法，而非传统的逐步规划方式，使机器人臂能够从人类演示中预测分段动作序列。该方法促进平滑、适应性强且数据驱动的捡取放置操作。基于成功率和抓取行为的视觉分析，我们的系统在零售环境中展示了改进的抓取准确性和适应性。', 'title_zh': '基于标注引导Pick-and-Place的ACT视觉提示在机器人操作中的应用'}
{'arxiv_id': 'arXiv:2508.08690', 'title': 'ZS-Puffin: Design, Modeling and Implementation of an Unmanned Aerial-Aquatic Vehicle with Amphibious Wings', 'authors': 'Zhenjiang Wang, Yunhua Jiang, Zikun Zhen, Yifan Jiang, Yubin Tan, Wubin Wang', 'link': 'https://arxiv.org/abs/2508.08690', 'abstract': "Unmanned aerial-aquatic vehicles (UAAVs) can operate both in the air and underwater, giving them broad application prospects. Inspired by the dual-function wings of puffins, we propose a UAAV with amphibious wings to address the challenge posed by medium differences on the vehicle's propulsion system. The amphibious wing, redesigned based on a fixed-wing structure, features a single degree of freedom in pitch and requires no additional components. It can generate lift in the air and function as a flapping wing for propulsion underwater, reducing disturbance to marine life and making it environmentally friendly. Additionally, an artificial central pattern generator (CPG) is introduced to enhance the smoothness of the flapping motion. This paper presents the prototype, design details, and practical implementation of this concept.", 'abstract_zh': '无人驾驶水空两栖飞行器（UAAVs）可以在空中和水下操作，具有广泛的应用前景。受帝企鹅双功能翅膀的启发，我们提出了一种具有水空两栖翅膀的UAAV，以解决车辆推进系统在介质差异面前所面临的问题。基于固定翼结构重新设计的两栖翅膀仅具备俯仰单自由度，不需要额外组件，能够在空中产生升力，并在水下充当拍打翼进行推进，减少对海洋生命的干扰，使其更加环保。此外，引入人工中心模式生成器（CPG）以提高拍打运动的平滑度。本文介绍了该概念的原型、设计细节及其实际实施。', 'title_zh': 'ZS-Puffin：兼具两栖翼的无人驾驶空水_vehicle的设计、建模与实现'}
{'arxiv_id': 'arXiv:2508.08607', 'title': 'Autonomous Mobile Plant Watering Robot : A Kinematic Approach', 'authors': 'Justin London', 'link': 'https://arxiv.org/abs/2508.08607', 'abstract': 'Plants need regular and the appropriate amount of watering to thrive and survive. While agricultural robots exist that can spray water on plants and crops such as the , they are expensive and have limited mobility and/or functionality. We introduce a novel autonomous mobile plant watering robot that uses a 6 degree of freedom (DOF) manipulator, connected to a 4 wheel drive alloy chassis, to be able to hold a garden hose, recognize and detect plants, and to water them with the appropriate amount of water by being able to insert a soil humidity/moisture sensor into the soil. The robot uses Jetson Nano and Arduino microcontroller and real sense camera to perform computer vision to detect plants using real-time YOLOv5 with the Pl@ntNet-300K dataset. The robot uses LIDAR for object and collision avoideance and does not need to move on a pre-defined path and can keep track of which plants it has watered. We provide the Denavit-Hartenberg (DH) Table, forward kinematics, differential driving kinematics, and inverse kinematics along with simulation and experiment results', 'abstract_zh': '一种新型自主移动植物浇水机器人：使用6自由度机械臂和四轮驱动合金底盘进行植物识别与精确浇水', 'title_zh': '自主移动植物浇水机器人：一种运动学方法'}
{'arxiv_id': 'arXiv:2508.08303', 'title': 'Evaluation of an Autonomous Surface Robot Equipped with a Transformable Mobility Mechanism for Efficient Mobility Control', 'authors': 'Yasuyuki Fujii, Dinh Tuan Tran, Joo-Ho Lee', 'link': 'https://arxiv.org/abs/2508.08303', 'abstract': 'Efficient mobility and power consumption are critical for autonomous water surface robots in long-term water environmental monitoring. This study develops and evaluates a transformable mobility mechanism for a water surface robot with two control modes: station-keeping and traveling to improve energy efficiency and maneuverability. Field experiments show that, in a round-trip task between two points, the traveling mode reduces power consumption by 10\\% and decreases the total time required for travel by 5\\% compared to the station-keeping mode. These results confirm the effectiveness of the transformable mobility mechanism for enhancing operational efficiency in patrolling on water surface.', 'abstract_zh': '高效的移动能力和功率消耗对于自主水面机器人在长期水环境监测中的应用至关重要。本研究开发并评估了一种可变形移动机制，该机制适用于具有站保持和航行两种控制模式的水面机器人，以提高能源效率和机动性。实地实验表明，在两点之间的往返任务中，航行模式相较于站保持模式可减少功率消耗10%并降低总航行时间5%。这些结果证实了可变形移动机制在水面巡逻操作效率提升方面的有效性。', 'title_zh': '装有可变运动机制的自主水面机器人高效运动控制评估'}
{'arxiv_id': 'arXiv:2508.08269', 'title': 'emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands', 'authors': 'Sagar Verma', 'link': 'https://arxiv.org/abs/2508.08269', 'abstract': 'Tendon-driven robotic hands offer unparalleled dexterity for manipulation tasks, but learning control policies for such systems presents unique challenges. Unlike joint-actuated robotic hands, tendon-driven systems lack a direct one-to-one mapping between motion capture (mocap) data and tendon controls, making the learning process complex and expensive. Additionally, visual tracking methods for real-world applications are prone to occlusions and inaccuracies, further complicating joint tracking. Wrist-wearable surface electromyography (sEMG) sensors present an inexpensive, robust alternative to capture hand motion. However, mapping sEMG signals to tendon control remains a significant challenge despite the availability of EMG-to-pose data sets and regression-based models in the existing literature.\nWe introduce the first large-scale EMG-to-Tendon Control dataset for robotic hands, extending the emg2pose dataset, which includes recordings from 193 subjects, spanning 370 hours and 29 stages with diverse gestures. This dataset incorporates tendon control signals derived using the MyoSuite MyoHand model, addressing limitations such as invalid poses in prior methods. We provide three baseline regression models to demonstrate emg2tendon utility and propose a novel diffusion-based regression model for predicting tendon control from sEMG recordings. This dataset and modeling framework marks a significant step forward for tendon-driven dexterous robotic manipulation, laying the groundwork for scalable and accurate tendon control in robotic hands. this https URL', 'abstract_zh': '肌腱驱动的机器人手提供 unparalleled 灵巧性用于操作任务，但学习此类系统的控制策略面临着独特的挑战。与关节驱动的机器人手不同，肌腱驱动系统缺乏运动捕捉（mocap）数据与肌腱控制之间的一对一映射，使学习过程复杂且昂贵。此外，用于实际应用的视觉跟踪方法容易出现遮挡和不准确，进一步增加了关节跟踪的复杂性。腕戴式表面肌电图（sEMG）传感器提供了一种廉价且稳健的替代方案，用于捕捉手部运动。尽管文献中存在肌电图到姿态数据集和基于回归的模型，将sEMG信号映射到肌腱控制仍是一项重大挑战。', 'title_zh': 'EMG-Guided Tendon Control: 从表面肌电信号到肌腱控制在肌骨手中'}
{'arxiv_id': 'arXiv:2508.08923', 'title': 'Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions', 'authors': 'Miruna-Alexandra Gafencu, Reem Shaban, Yordanka Velikova, Mohammad Farid Azampour, Nassir Navab', 'link': 'https://arxiv.org/abs/2508.08923', 'abstract': 'Ultrasound (US) imaging is increasingly used in spinal procedures due to its real-time, radiation-free capabilities; however, its effectiveness is hindered by shadowing artifacts that obscure deeper tissue structures. Traditional approaches, such as CT-to-US registration, incorporate anatomical information from preoperative CT scans to guide interventions, but they are limited by complex registration requirements, differences in spine curvature, and the need for recent CT imaging. Recent shape completion methods can offer an alternative by reconstructing spinal structures in US data, while being pretrained on large set of publicly available CT scans. However, these approaches are typically offline and have limited reproducibility. In this work, we introduce a novel integrated system that combines robotic ultrasound with real-time shape completion to enhance spinal visualization. Our robotic platform autonomously acquires US sweeps of the lumbar spine, extracts vertebral surfaces from ultrasound, and reconstructs the complete anatomy using a deep learning-based shape completion network. This framework provides interactive, real-time visualization with the capability to autonomously repeat scans and can enable navigation to target locations. This can contribute to better consistency, reproducibility, and understanding of the underlying anatomy. We validate our approach through quantitative experiments assessing shape completion accuracy and evaluations of multiple spine acquisition protocols on a phantom setup. Additionally, we present qualitative results of the visualization on a volunteer scan.', 'abstract_zh': '基于超声成像的脊柱手术成像系统：结合机器人超声与实时形状补全', 'title_zh': '机器人超声脊柱检查中的形状完成与实时可视化'}
