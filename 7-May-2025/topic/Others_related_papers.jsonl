{'arxiv_id': 'arXiv:2505.03344', 'title': 'RIFT: Closed-Loop RL Fine-Tuning for Realistic and Controllable Traffic Simulation', 'authors': 'Keyu Chen, Wenchao Sun, Hao Cheng, Sifa Zheng', 'link': 'https://arxiv.org/abs/2505.03344', 'abstract': 'Achieving both realism and controllability in interactive closed-loop traffic simulation remains a key challenge in autonomous driving. Data-driven simulation methods reproduce realistic trajectories but suffer from covariate shift in closed-loop deployment, compounded by simplified dynamics models that further reduce reliability. Conversely, physics-based simulation methods enhance reliable and controllable closed-loop interactions but often lack expert demonstrations, compromising realism. To address these challenges, we introduce a dual-stage AV-centered simulation framework that conducts open-loop imitation learning pre-training in a data-driven simulator to capture trajectory-level realism and multimodality, followed by closed-loop reinforcement learning fine-tuning in a physics-based simulator to enhance controllability and mitigate covariate shift. In the fine-tuning stage, we propose RIFT, a simple yet effective closed-loop RL fine-tuning strategy that preserves the trajectory-level multimodality through a GRPO-style group-relative advantage formulation, while enhancing controllability and training stability by replacing KL regularization with the dual-clip mechanism. Extensive experiments demonstrate that RIFT significantly improves the realism and controllability of generated traffic scenarios, providing a robust platform for evaluating autonomous vehicle performance in diverse and interactive scenarios.', 'abstract_zh': '在自主驾驶中实现互动闭环交通模拟的现实性和可控性兼具仍是一项关键挑战。数据驱动的模拟方法可以重现现实轨迹，但在闭环部署中易受协变量偏移的影响，且简化的动力学模型进一步降低了可靠性。相反，基于物理的模拟方法可以增强可靠的闭环交互，但往往缺乏专家示范，影响现实性。为解决这些问题，我们提出了一种双阶段以自主车辆为中心的模拟框架，该框架首先在数据驱动的模拟器中进行开环模仿学习预训练，以捕捉轨迹级别的现实性和多模态性，随后在基于物理的模拟器中进行闭环强化学习微调，以增强可控性和减轻协变量偏移。在微调阶段，我们提出了一种名为RIFT的简单而有效的闭环RL微调策略，通过一种组相对优势的GRPO风格形式保留了轨迹级别的多模态性，同时通过使用双重剪辑机制替代KL正则化来增强可控性和训练稳定性。大量实验表明，RIFT显著提高了生成的交通场景的现实性和可控性，提供了一个在多样且交互的场景中评估自主车辆性能的稳健平台。', 'title_zh': 'RIFT: 闭环RL微调方法用于真实且可控的交通模拟'}
{'arxiv_id': 'arXiv:2505.03174', 'title': 'Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets', 'authors': 'Guillermo Roque, Erika Maquiling, Jose Giovanni Tapia Lopez, Ross Greer', 'link': 'https://arxiv.org/abs/2505.03174', 'abstract': 'Instruction-Action (IA) data pairs are valuable for training robotic systems, especially autonomous vehicles (AVs), but having humans manually annotate this data is costly and time-inefficient. This paper explores the potential of using mobile application Global Positioning System (GPS) references and Natural Language Processing (NLP) to automatically generate large volumes of IA commands and responses without having a human generate or retroactively tag the data. In our pilot data collection, by driving to various destinations and collecting voice instructions from GPS applications, we demonstrate a means to collect and categorize the diverse sets of instructions, further accompanied by video data to form complete vision-language-action triads. We provide details on our completely automated data collection prototype system, ADVLAT-Engine. We characterize collected GPS voice instructions into eight different classifications, highlighting the breadth of commands and referentialities available for curation from freely available mobile applications. Through research and exploration into the automation of IA data pairs using GPS references, the potential to increase the speed and volume at which high-quality IA datasets are created, while minimizing cost, can pave the way for robust vision-language-action (VLA) models to serve tasks in vision-language navigation (VLN) and human-interactive autonomous systems.', 'abstract_zh': '基于GPS参考和自然语言处理的指令-行动数据对自动生成研究', 'title_zh': '基于GPS与NLP的自动数据整理方法生成指令-操作对以构建自主车辆视觉-语言导航数据集'}
{'arxiv_id': 'arXiv:2505.03512', 'title': 'Artificial Protozoa Optimizer (APO): A novel bio-inspired metaheuristic algorithm for engineering optimization', 'authors': 'Xiaopeng Wang, Vaclav Snasel, Seyedali Mirjalili, Jeng-Shyang Pan, Lingping Kong, Hisham A. Shehadeh', 'link': 'https://arxiv.org/abs/2505.03512', 'abstract': 'This study proposes a novel artificial protozoa optimizer (APO) that is inspired by protozoa in nature. The APO mimics the survival mechanisms of protozoa by simulating their foraging, dormancy, and reproductive behaviors. The APO was mathematically modeled and implemented to perform the optimization processes of metaheuristic algorithms. The performance of the APO was verified via experimental simulations and compared with 32 state-of-the-art algorithms. Wilcoxon signed-rank test was performed for pairwise comparisons of the proposed APO with the state-of-the-art algorithms, and Friedman test was used for multiple comparisons. First, the APO was tested using 12 functions of the 2022 IEEE Congress on Evolutionary Computation benchmark. Considering practicality, the proposed APO was used to solve five popular engineering design problems in a continuous space with constraints. Moreover, the APO was applied to solve a multilevel image segmentation task in a discrete space with constraints. The experiments confirmed that the APO could provide highly competitive results for optimization problems. The source codes of Artificial Protozoa Optimizer are publicly available at this https URL and this https URL.', 'abstract_zh': '本研究提出了一种新型的人工原生动物优化器（APO），该优化器受自然界原生动物的行为启发。APO通过模拟原生动物的觅食、休眠和生殖行为来模仿其生存机制。APO通过数学建模并实现为元启发式算法的优化过程。通过实验仿真验证了APO的性能，并将其与32种最先进的算法进行了比较。Wilcoxon符号秩检验用于比较所提出的APO与最先进的算法，Friedman检验用于多重比较。首先，APO使用2022年IEEE演化计算大会基准测试中的12个函数进行了测试。考虑到实用性，提出的APO被用于解决连续空间中有约束条件的五个流行工程设计问题。此外，APO还应用于解决离散空间中有约束条件的多级图像分割任务。实验结果证实，APO在优化问题上可以提供具有很强竞争力的结果。人工原生动物优化器的源代码可从此处和此处公开获取。', 'title_zh': '人工原生动物优化算法（APO）：一种新型生物启发式元启发算法在工程优化中的应用'}
{'arxiv_id': 'arXiv:2505.03178', 'title': 'RADE: Learning Risk-Adjustable Driving Environment via Multi-Agent Conditional Diffusion', 'authors': 'Jiawei Wang, Xintao Yan, Yao Mu, Haowei Sun, Zhong Cao, Henry X. Liu', 'link': 'https://arxiv.org/abs/2505.03178', 'abstract': "Generating safety-critical scenarios in high-fidelity simulations offers a promising and cost-effective approach for efficient testing of autonomous vehicles. Existing methods typically rely on manipulating a single vehicle's trajectory through sophisticated designed objectives to induce adversarial interactions, often at the cost of realism and scalability. In this work, we propose the Risk-Adjustable Driving Environment (RADE), a simulation framework that generates statistically realistic and risk-adjustable traffic scenes. Built upon a multi-agent diffusion architecture, RADE jointly models the behavior of all agents in the environment and conditions their trajectories on a surrogate risk measure. Unlike traditional adversarial methods, RADE learns risk-conditioned behaviors directly from data, preserving naturalistic multi-agent interactions with controllable risk levels. To ensure physical plausibility, we incorporate a tokenized dynamics check module that efficiently filters generated trajectories using a motion vocabulary. We validate RADE on the real-world rounD dataset, demonstrating that it preserves statistical realism across varying risk levels and naturally increases the likelihood of safety-critical events as the desired risk level grows up. Our results highlight RADE's potential as a scalable and realistic tool for AV safety evaluation.", 'abstract_zh': '在高保真模拟中生成安全关键场景为自动驾驶车辆高效测试提供了有前途且成本效益高的方法。现有方法通常依赖于通过复杂设计的目标操控单个车辆的轨迹以诱导对抗性交互，往往牺牲了真实性和可扩展性。在这项工作中，我们提出了风险可调驾驶环境（RADE），一种生成统计上现实且风险可调交通场景的模拟框架。基于多智能体扩散架构，RADE 联合建模环境中所有智能体的行为，并基于代理风险度量条件化其轨迹。与传统的对抗性方法不同，RADE 直接从数据中学习风险条件下的行为，同时保持自然的多智能体交互并具备可控的风险水平。为了确保物理可行性，我们引入了一个标记化动力学检查模块，该模块利用运动词汇表高效地过滤生成的轨迹。我们使用现实世界中的 rounD 数据集验证了 RADE，结果表明它在不同风险水平下保持了统计现实性，并且随着期望的风险水平提高，自然地增加了安全关键事件发生的可能性。我们的结果突显了 RADE 作为自动驾驶车辆安全评估可扩展且现实工具的潜力。', 'title_zh': 'RADE：通过多Agent条件扩散学习可调整风险的驾驶环境'}
{'arxiv_id': 'arXiv:2505.03088', 'title': 'Global Task-aware Fault Detection, Identification For On-Orbit Multi-Spacecraft Collaborative Inspection', 'authors': 'Akshita Gupta, Yashwanth Kumar Nakka, Changrak Choi, Amir Rahmani', 'link': 'https://arxiv.org/abs/2505.03088', 'abstract': 'In this paper, we present a global-to-local task-aware fault detection and identification algorithm to detect failures in a multi-spacecraft system performing a collaborative inspection (referred to as global) task. The inspection task is encoded as a cost functional $\\costH$ that informs global (task allocation and assignment) and local (agent-level) decision-making. The metric $\\costH$ is a function of the inspection sensor model, and the agent full-pose. We use the cost functional $\\costH$ to design a metric that compares the expected and actual performance to detect the faulty agent using a threshold. We use higher-order cost gradients $\\costH$ to derive a new metric to identify the type of fault, including task-specific sensor fault, an agent-level actuator, and sensor faults. Furthermore, we propose an approach to design adaptive thresholds for each fault mentioned above to incorporate the time dependence of the inspection task. We demonstrate the efficacy of the proposed method empirically, by simulating and detecting faults (such as inspection sensor faults, actuators, and sensor faults) in a low-Earth orbit collaborative spacecraft inspection task using the metrics and the threshold designed using the global task cost $\\costH$.', 'abstract_zh': '在多卫星系统执行协作检查任务（简称全局任务）中的一种全局到局部任务感知故障检测与识别算法', 'title_zh': '基于轨道多卫星协同检查的全局任务意识故障检测与识别'}
{'arxiv_id': 'arXiv:2505.02842', 'title': 'Evaluation of Coordination Strategies for Underground Automated Vehicle Fleets in Mixed Traffic', 'authors': 'Olga Mironenko, Hadi Banaee, Amy Loutfi', 'link': 'https://arxiv.org/abs/2505.02842', 'abstract': 'This study investigates the efficiency and safety outcomes of implementing different adaptive coordination models for automated vehicle (AV) fleets, managed by a centralized coordinator that dynamically responds to human-controlled vehicle behavior. The simulated scenarios replicate an underground mining environment characterized by narrow tunnels with limited connectivity. To address the unique challenges of such settings, we propose a novel metric - Path Overlap Density (POD) - to predict efficiency and potentially the safety performance of AV fleets. The study also explores the impact of map features on AV fleets performance. The results demonstrate that both AV fleet coordination strategies and underground tunnel network characteristics significantly influence overall system performance. While map features are critical for optimizing efficiency, adaptive coordination strategies are essential for ensuring safe operations.', 'abstract_zh': '本研究探讨了由集中协调器动态响应人类控制车辆行为的不同自适应协调模型在自动化车辆（AV）车队中的效率和安全性能。模拟场景再现了由狭窄隧道和有限连接性组成的地下采矿环境。为应对此类环境的独特挑战，我们提出了一种新的指标——路径重叠密度（POD），以预测AV车队的效率和潜在的安全性能。研究还探讨了地图特征对AV车队性能的影响。结果表明，AV车队协调策略和地下隧道网络特性显著影响整体系统性能。虽然地图特征对于优化效率至关重要，但适应性协调策略对于确保安全运营也必不可少。', 'title_zh': '地下自动车辆车队在混行交通中的协调策略评估'}
{'arxiv_id': 'arXiv:2505.03674', 'title': "Gap the (Theory of) Mind: Sharing Beliefs About Teammates' Goals Boosts Collaboration Perception, Not Performance", 'authors': 'Yotam Amitai, Reuth Mirsky, Ofra Amir', 'link': 'https://arxiv.org/abs/2505.03674', 'abstract': "In human-agent teams, openly sharing goals is often assumed to enhance planning, collaboration, and effectiveness. However, direct communication of these goals is not always feasible, requiring teammates to infer their partner's intentions through actions. Building on this, we investigate whether an AI agent's ability to share its inferred understanding of a human teammate's goals can improve task performance and perceived collaboration. Through an experiment comparing three conditions-no recognition (NR), viable goals (VG), and viable goals on-demand (VGod) - we find that while goal-sharing information did not yield significant improvements in task performance or overall satisfaction scores, thematic analysis suggests that it supported strategic adaptations and subjective perceptions of collaboration. Cognitive load assessments revealed no additional burden across conditions, highlighting the challenge of balancing informativeness and simplicity in human-agent interactions. These findings highlight the nuanced trade-off of goal-sharing: while it fosters trust and enhances perceived collaboration, it can occasionally hinder objective performance gains.", 'abstract_zh': '在人类-代理团队中，公开共享目标通常被认为能增强规划、合作和有效性。然而，直接沟通这些目标并不总是可行的，需要团队成员通过观察行为推断伙伴的意图。基于此，我们研究AI代理分享其推断的人类队友目标能力是否能提高任务性能和感知的合作度。通过比较三种条件（无识别组、可行目标组和按需可行目标组）的实验，我们发现，虽然共享目标信息并未显著提高任务性能或总体满意度评分，但主题分析表明，它支持了战略调整并影响了对合作的主观感知。认知负荷评估显示，各组之间没有额外负担，突显了在人类-代理交互中平衡信息性和简洁性的挑战。这些发现强调了目标共享的微妙权衡：虽然它促进了信任并增强了感知的合作度，但也可能偶尔妨碍客观性能的提升。', 'title_zh': '认知差异（理论中的）：关于队友目标信念的共享增强合作感知，但不提升绩效'}
{'arxiv_id': 'arXiv:2505.03668', 'title': 'Learning Symbolic Persistent Macro-Actions for POMDP Solving Over Time', 'authors': 'Celeste Veronese, Daniele Meli, Alessandro Farinelli', 'link': 'https://arxiv.org/abs/2505.03668', 'abstract': 'This paper proposes an integration of temporal logical reasoning and Partially Observable Markov Decision Processes (POMDPs) to achieve interpretable decision-making under uncertainty with macro-actions. Our method leverages a fragment of Linear Temporal Logic (LTL) based on Event Calculus (EC) to generate \\emph{persistent} (i.e., constant) macro-actions, which guide Monte Carlo Tree Search (MCTS)-based POMDP solvers over a time horizon, significantly reducing inference time while ensuring robust performance. Such macro-actions are learnt via Inductive Logic Programming (ILP) from a few traces of execution (belief-action pairs), thus eliminating the need for manually designed heuristics and requiring only the specification of the POMDP transition model. In the Pocman and Rocksample benchmark scenarios, our learned macro-actions demonstrate increased expressiveness and generality when compared to time-independent heuristics, indeed offering substantial computational efficiency improvements.', 'abstract_zh': '本文提出了一种将时间逻辑推理与部分可观测马尔可夫决策过程（POMDP）结合的方法，以在宏操作的指导下实现不确定性下的可解释决策。该方法利用基于事件 calculus 的线性时序逻辑（LTL）片段生成持久性（即恒定）的宏操作，这些宏操作引导时间 horzion 上的蒙特卡罗树搜索（MCTS）基 POMDP 求解器，显著减少推理时间同时保证鲁棒性能。这些宏操作通过归纳逻辑编程（ILP）从少量执行轨迹（信念-操作对）中学得，从而省去了手动设计启发式函数的需求，只需指定 POMDP 过渡模型即可。在 Pocman 和 Rocksample 基准场景中，我们学习的宏操作在表达性和普适性方面优于时间无关的启发式函数，确实提供了显著的计算效率提升。', 'title_zh': '基于时间的POMDP求解中的符号持久宏操作学习'}
{'arxiv_id': 'arXiv:2505.03643', 'title': 'BURNS: Backward Underapproximate Reachability for Neural-Feedback-Loop Systems', 'authors': 'Chelsea Sidrane, Jana Tumova', 'link': 'https://arxiv.org/abs/2505.03643', 'abstract': 'Learning-enabled planning and control algorithms are increasingly popular, but they often lack rigorous guarantees of performance or safety. We introduce an algorithm for computing underapproximate backward reachable sets of nonlinear discrete time neural feedback loops. We then use the backward reachable sets to check goal-reaching properties. Our algorithm is based on overapproximating the system dynamics function to enable computation of underapproximate backward reachable sets through solutions of mixed-integer linear programs. We rigorously analyze the soundness of our algorithm and demonstrate it on a numerical example. Our work expands the class of properties that can be verified for learning-enabled systems.', 'abstract_zh': '学习驱动的规划与控制算法日益流行，但往往缺乏对性能或安全性的严格保证。我们提出了一种计算非线性离散时间神经反馈回路的下近似可到达集的算法。然后，我们使用可到达集来检验目标达成属性。我们的算法通过求解混合整数线性规划问题来计算下近似可到达集，基于对系统动力学函数的上近似。我们严格分析了该算法的正确性，并在数值示例上进行了演示。我们的工作扩展了可以验证的学习驱动系统属性的类别。', 'title_zh': 'BURNS: 后向近似可达性分析用于神经反馈系统'}
{'arxiv_id': 'arXiv:2505.03641', 'title': 'Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability', 'authors': 'Chen Wei, Chi Zhang, Jiachen Zou, Haotian Deng, Dietmar Heinke, Quanying Liu', 'link': 'https://arxiv.org/abs/2505.03641', 'abstract': 'Human decision-making in cognitive tasks and daily life exhibits considerable variability, shaped by factors such as task difficulty, individual preferences, and personal experiences. Understanding this variability across individuals is essential for uncovering the perceptual and decision-making mechanisms that humans rely on when faced with uncertainty and ambiguity. We present a computational framework BAM (Boundary Alignment & Manipulation framework) that combines perceptual boundary sampling in ANNs and human behavioral experiments to systematically investigate this phenomenon. Our perceptual boundary sampling algorithm generates stimuli along ANN decision boundaries that intrinsically induce significant perceptual variability. The efficacy of these stimuli is empirically validated through large-scale behavioral experiments involving 246 participants across 116,715 trials, culminating in the variMNIST dataset containing 19,943 systematically annotated images. Through personalized model alignment and adversarial generation, we establish a reliable method for simultaneously predicting and manipulating the divergent perceptual decisions of pairs of participants. This work bridges the gap between computational models and human individual difference research, providing new tools for personalized perception analysis.', 'abstract_zh': '人类在认知任务和日常生活中决策表现出显著的 variability，受任务难度、个人偏好和个人经历等因素的影响。了解个体间的这种 variability是揭示人类在面对不确定性和模糊性时依赖的知觉和决策机制的关键。我们提出了一种计算框架 BAM（边界对齐与操控框架），结合人工神经网络的知觉边界采样和人类行为实验，系统地研究这一现象。我们的知觉边界采样算法生成了沿人工神经网络决策边界的刺激，这些刺激内在地引起了显著的知觉变异。这些刺激的有效性通过涉及246名参与者和116,715次试次的大规模行为实验经验性验证，最终形成了包含19,943张系统标注图像的variMNIST数据集。通过个性化模型对齐和对抗生成，我们建立了一种同时预测和操控配对参与者发散知觉决策的可靠方法。这项工作填补了计算模型与人类个体差异研究之间的空白，提供了个性化知觉分析的新工具。', 'title_zh': '在ANN知觉边界上合成图像以揭示和操控人类知觉变异'}
{'arxiv_id': 'arXiv:2505.03359', 'title': 'Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental Health Detection', 'authors': 'June-Woo Kim, Haram Yoon, Wonkyo Oh, Dawoon Jung, Sung-Hoon Yoon, Dae-Jin Kim, Dong-Ho Lee, Sang-Yeol Lee, Chan-Mo Yang', 'link': 'https://arxiv.org/abs/2505.03359', 'abstract': 'Speech-based AI models are emerging as powerful tools for detecting depression and the presence of Post-traumatic stress disorder (PTSD), offering a non-invasive and cost-effective way to assess mental health. However, these models often struggle with gender bias, which can lead to unfair and inaccurate predictions. In this study, our study addresses this issue by introducing a domain adversarial training approach that explicitly considers gender differences in speech-based depression and PTSD detection. Specifically, we treat different genders as distinct domains and integrate this information into a pretrained speech foundation model. We then validate its effectiveness on the E-DAIC dataset to assess its impact on performance. Experimental results show that our method notably improves detection performance, increasing the F1-score by up to 13.29 percentage points compared to the baseline. This highlights the importance of addressing demographic disparities in AI-driven mental health assessment.', 'abstract_zh': '基于语音的AI模型在检测抑郁和创伤后应激障碍（PTSD）方面的应用正逐渐成为有力工具，提供了无侵入性和成本效益高的心理健康评估方式。然而，这些模型常常面临性别偏见问题，可能导致不公平和不准确的预测。本研究通过引入领域对抗训练方法来解决这一问题，该方法明确考虑了语音中抑郁和PTSD检测的性别差异。具体而言，我们将不同性别视为不同的领域，并将此信息整合到预训练的语音基础模型中。然后，我们在E-DAIC数据集上验证其有效性，评估其对性能的影响。实验结果表明，我们的方法显著提高了检测性能，F1分数相比基线提高了13.29个百分点。这突显了在AI驱动的心理健康评估中解决人口统计学差异的重要性。', 'title_zh': '基于语域对抗训练减轻语音情感健康检测中性别偏见'}
{'arxiv_id': 'arXiv:2505.02952', 'title': 'Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach', 'authors': 'Fabrizio Marozzo', 'link': 'https://arxiv.org/abs/2505.02952', 'abstract': 'Generative AI systems have revolutionized human interaction by enabling natural language-based coding and problem solving. However, the inherent ambiguity of natural language often leads to imprecise instructions, forcing users to iteratively test, correct, and resubmit their prompts. We propose an iterative approach that systematically narrows down these ambiguities through a structured series of clarification questions and alternative solution proposals, illustrated with input/output examples as well. Once every uncertainty is resolved, a final, precise solution is generated. Evaluated on a diverse dataset spanning coding, data analysis, and creative writing, our method demonstrates superior accuracy, competitive resolution times, and higher user satisfaction compared to conventional one-shot solutions, which typically require multiple manual iterations to achieve a correct output.', 'abstract_zh': '生成式AI系统通过基于自然语言的编码和问题解决重塑了人机交互，然而自然语言的固有模糊性常导致不精确的指令，迫使用户反复测试、修正并重新提交提示。我们提出了一种系统性的迭代方法，通过结构化的一系列澄清问题和替代方案提案逐步缩小模糊性，同时用输入/输出示例进行说明。待所有不确定性解决后，最终生成一个精确的解决方案。在涵盖编程、数据分析和创造性写作等多种数据集上的评估表明，我们的方法在准确性、响应时间以及用户满意度方面均优于传统的单次解决方案，后者通常需要多轮手动迭代才能获得正确的输出结果。', 'title_zh': '逐步切割-搜索方法解决提示歧义的迭代求解'}
{'arxiv_id': 'arXiv:2505.03710', 'title': 'Actor-Critics Can Achieve Optimal Sample Efficiency', 'authors': 'Kevin Tan, Wei Fan, Yuting Wei', 'link': 'https://arxiv.org/abs/2505.03710', 'abstract': 'Actor-critic algorithms have become a cornerstone in reinforcement learning (RL), leveraging the strengths of both policy-based and value-based methods. Despite recent progress in understanding their statistical efficiency, no existing work has successfully learned an $\\epsilon$-optimal policy with a sample complexity of $O(1/\\epsilon^2)$ trajectories with general function approximation when strategic exploration is necessary.\nWe address this open problem by introducing a novel actor-critic algorithm that attains a sample-complexity of $O(dH^5 \\log|\\mathcal{A}|/\\epsilon^2 + d H^4 \\log|\\mathcal{F}|/ \\epsilon^2)$ trajectories, and accompanying $\\sqrt{T}$ regret when the Bellman eluder dimension $d$ does not increase with $T$ at more than a $\\log T$ rate.\nHere, $\\mathcal{F}$ is the critic function class, $\\mathcal{A}$ is the action space, and $H$ is the horizon in the finite horizon MDP setting. Our algorithm integrates optimism, off-policy critic estimation targeting the optimal Q-function, and rare-switching policy resets.\nWe extend this to the setting of Hybrid RL, showing that initializing the critic with offline data yields sample efficiency gains compared to purely offline or online RL. Further, utilizing access to offline data, we provide a \\textit{non-optimistic} provably efficient actor-critic algorithm that only additionally requires $N_{\\text{off}} \\geq c_{\\text{off}}^*dH^4/\\epsilon^2$ in exchange for omitting optimism, where $c_{\\text{off}}^*$ is the single-policy concentrability coefficient and $N_{\\text{off}}$ is the number of offline samples. This addresses another open problem in the literature. We further provide numerical experiments to support our theoretical findings.', 'abstract_zh': '基于函数逼近的策略与价值共同学习算法在需要战略探索的情况下，实现了$\\epsilon$-最优策略的学习，其样本复杂度为$O(dH^5 \\log|\\mathcal{A}|/\\epsilon^2 + d H^4 \\log|\\mathcal{F}|/ \\epsilon^2)$轨迹，当贝尔曼庸人维度$d$以$\\log T$速率增加时，伴随$\\sqrt{T}$遗憾。', 'title_zh': '演员-评论家可以实现最优样本效率'}
{'arxiv_id': 'arXiv:2505.03655', 'title': 'Counterfactual Inference for Eliminating Sentiment Bias in Recommender Systems', 'authors': 'Le Pan, Yuanjiang Cao, Chengkai Huang, Wenjie Zhang, Lina Yao', 'link': 'https://arxiv.org/abs/2505.03655', 'abstract': 'Recommender Systems (RSs) aim to provide personalized recommendations for users. A newly discovered bias, known as sentiment bias, uncovers a common phenomenon within Review-based RSs (RRSs): the recommendation accuracy of users or items with negative reviews deteriorates compared with users or items with positive reviews. Critical users and niche items are disadvantaged by such unfair recommendations. We study this problem from the perspective of counterfactual inference with two stages. At the model training stage, we build a causal graph and model how sentiment influences the final rating score. During the inference stage, we decouple the direct and indirect effects to mitigate the impact of sentiment bias and remove the indirect effect using counterfactual inference. We have conducted extensive experiments, and the results validate that our model can achieve comparable performance on rating prediction for better recommendations and effective mitigation of sentiment bias. To the best of our knowledge, this is the first work to employ counterfactual inference on sentiment bias mitigation in RSs.', 'abstract_zh': '基于情绪偏差的推荐系统中的公平性研究：基于反事实推理的两阶段方法', 'title_zh': '消除推荐系统中情感偏见的事实推理方法'}
{'arxiv_id': 'arXiv:2505.03648', 'title': 'Binding threshold units with artificial oscillatory neurons', 'authors': 'Vladimir Fanaskov, Ivan Oseledets', 'link': 'https://arxiv.org/abs/2505.03648', 'abstract': 'Artificial Kuramoto oscillatory neurons were recently introduced as an alternative to threshold units. Empirical evidence suggests that oscillatory units outperform threshold units in several tasks including unsupervised object discovery and certain reasoning problems. The proposed coupling mechanism for these oscillatory neurons is heterogeneous, combining a generalized Kuramoto equation with standard coupling methods used for threshold units. In this research note, we present a theoretical framework that clearly distinguishes oscillatory neurons from threshold units and establishes a coupling mechanism between them. We argue that, from a biological standpoint, oscillatory and threshold units realise distinct aspects of neural coding: roughly, threshold units model intensity of neuron firing, while oscillatory units facilitate information exchange by frequency modulation. To derive interaction between these two types of units, we constrain their dynamics by focusing on dynamical systems that admit Lyapunov functions. For threshold units, this leads to Hopfield associative memory model, and for oscillatory units it yields a specific form of generalized Kuramoto model. The resulting dynamical systems can be naturally coupled to form a Hopfield-Kuramoto associative memory model, which also admits a Lyapunov function. Various forms of coupling are possible. Notably, oscillatory neurons can be employed to implement a low-rank correction to the weight matrix of a Hopfield network. This correction can be viewed either as a form of Hebbian learning or as a popular LoRA method used for fine-tuning of large language models. We demonstrate the practical realization of this particular coupling through illustrative toy experiments.', 'abstract_zh': '人工Kuramoto振荡神经元 Recently Introduced as an Alternative to Threshold Units: A Theoretical Framework and Coupling Mechanism', 'title_zh': '人工振荡神经元与绑定阈值单元结合'}
{'arxiv_id': 'arXiv:2505.03646', 'title': 'ALMA: Aggregated Lipschitz Maximization Attack on Auto-encoders', 'authors': 'Chethan Krishnamurthy Ramanaik, Arjun Roy, Eirini Ntoutsi', 'link': 'https://arxiv.org/abs/2505.03646', 'abstract': 'Despite the extensive use of deep autoencoders (AEs) in critical applications, their adversarial robustness remains relatively underexplored compared to classification models. AE robustness is characterized by the Lipschitz bounds of its components. Existing robustness evaluation frameworks based on white-box attacks do not fully exploit the vulnerabilities of intermediate ill-conditioned layers in AEs. In the context of optimizing imperceptible norm-bounded additive perturbations to maximize output damage, existing methods struggle to effectively propagate adversarial loss gradients throughout the network, often converging to less effective perturbations. To address this, we propose a novel layer-conditioning-based adversarial optimization objective that effectively guides the adversarial map toward regions of local Lipschitz bounds by enhancing loss gradient information propagation during attack optimization. We demonstrate through extensive experiments on state-of-the-art AEs that our adversarial objective results in stronger attacks, outperforming existing methods in both universal and sample-specific scenarios. As a defense method against this attack, we introduce an inference-time adversarially trained defense plugin that mitigates the effects of adversarial examples.', 'abstract_zh': '尽管深层自编码器（AEs）在关键应用中得到了广泛使用，但与分类模型相比，其对抗鲁棒性研究仍相对不足。AE的对抗鲁棒性可以由其组件的Lipschitz界来表征。基于白盒攻击的现有鲁棒性评估框架未能充分利用AE中间病态层的漏洞。在优化不可感知的范数界附加扰动以最大化输出损伤的背景下，现有方法在攻击优化过程中难以有效地传递对抗损失梯度信息，往往收敛到效果较差的扰动。为了解决这一问题，我们提出了一种新的基于层条件的对抗优化目标，该目标能够通过增强攻击优化过程中损失梯度信息的传递，有效地引导对抗映射朝向局部Lipschitz界区域。通过在最先进的AEs上的 extensive 实验，我们表明我们的对抗目标能够产生更强的攻击，在通用场景和样本特定场景中均优于现有方法。作为针对该攻击的防御方法，我们引入了一种推断时对抗训练的防御插件，以缓解对抗样本的影响。', 'title_zh': 'ALMA: 自编码器上的聚合Lipschitz最大化攻击'}
{'arxiv_id': 'arXiv:2505.03586', 'title': 'Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation', 'authors': 'Songchen Fu, Siang Chen, Shaojing Zhao, Letian Bai, Ta Li, Yonghong Yan', 'link': 'https://arxiv.org/abs/2505.03586', 'abstract': "In real-world multi-agent systems (MASs), observation delays are ubiquitous, preventing agents from making decisions based on the environment's true state. An individual agent's local observation often consists of multiple components from other agents or dynamic entities in the environment. These discrete observation components with varying delay characteristics pose significant challenges for multi-agent reinforcement learning (MARL). In this paper, we first formulate the decentralized stochastic individual delay partially observable Markov decision process (DSID-POMDP) by extending the standard Dec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL training framework for addressing stochastic individual delays, along with recommended implementations for its constituent modules. We implement the DSID-POMDP's observation generation pattern using standard MARL benchmarks, including MPE and SMAC. Experiments demonstrate that baseline MARL methods suffer severe performance degradation under fixed and unfixed delays. The RDC-enhanced approach mitigates this issue, remarkably achieving ideal delay-free performance in certain delay scenarios while maintaining generalization capability. Our work provides a novel perspective on multi-agent delayed observation problems and offers an effective solution framework.", 'abstract_zh': '在现实世界多Agent系统中，观测延迟普遍存在，阻碍agents基于环境的真实状态作出决策。个体agent的局部观测通常由环境中其他agent或动态实体的多个组成部分组成。这些具有不同延迟特性的离散观测组件对多Agent强化学习（MARL）提出了重大挑战。在本文中，我们首先通过扩展标准Dec-POMDP来形式化去中心化的随机个体延迟部分可观测马尔可夫决策过程（DSID-POMDP）。随后，我们提出了一种Rainbow Delay Compensation（RDC），这是一种用于解决随机个体延迟的MARL训练框架，并推荐了其组成部分模块的具体实现方式。我们使用标准的MARL基准，包括MPE和SMAC，来实现DSID-POMDP的观测生成模式。实验表明，基础的MARL方法在固定和非固定延迟下性能显著下降。RDC增强方法缓解了这一问题，在某些延迟场景中实现了理想的无延迟性能，同时保持了一定的泛化能力。我们的工作为多Agent延迟观测问题提供了一个新的视角，并提供了一种有效的解决方案框架。', 'title_zh': '多agent强化学习框架：缓解延迟观测的 Rainbow 延迟补偿'}
{'arxiv_id': 'arXiv:2505.03584', 'title': 'BCause: Human-AI collaboration to improve hybrid mapping and ideation in argumentation-grounded deliberation', 'authors': 'Lucas Anastasiou, Anna De Liddo', 'link': 'https://arxiv.org/abs/2505.03584', 'abstract': "Public deliberation, as in open discussion of issues of public concern, often suffers from scattered and shallow discourse, poor sensemaking, and a disconnect from actionable policy outcomes. This paper introduces BCause, a discussion system leveraging generative AI and human-machine collaboration to transform unstructured dialogue around public issues (such as urban living, policy changes, and current socio-economic transformations) into structured, actionable democratic processes. We present three innovations: (i) importing and transforming unstructured transcripts into argumentative discussions, (ii) geo-deliberated problem-sensing via a Telegram bot for local issue reporting, and (iii) smart reporting with customizable widgets (e.g., summaries, topic modelling, policy recommendations, clustered arguments). The system's human-AI partnership preserves critical human participation to ensure ethical oversight, contextual relevance, and creative synthesis.", 'abstract_zh': '公共事务讨论往往受到分散和浅薄的讨论、差的含义构建以及与可执行政策结果脱节的影响。本文介绍了BCause，这是一种利用生成型AI和人机合作的讨论系统，旨在将关于公共议题（如城市生活、政策变化和当前社会经济转型）的非结构化对话转化为结构化、可执行的民主过程。我们提出了三项创新：（i）将非结构化转录导入并转化为论辩性讨论，（ii）通过Telegram机器人进行地理导向的问题感知以报告当地问题，以及（iii）可定制的智能报告工具（例如，摘要、主题建模、政策建议、聚类论证）。该系统的人机伙伴关系保留了关键的人类参与，以确保伦理监督、情境相关性和创造性的综合。', 'title_zh': 'BCause: 人机协作以改进基于论据的混合映射与创意思考'}
{'arxiv_id': 'arXiv:2505.03561', 'title': 'Ergodic Generative Flows', 'authors': 'Leo Maxime Brunswic, Mateo Clemente, Rui Heng Yang, Adam Sigal, Amir Rasouli, Yinchuan Li', 'link': 'https://arxiv.org/abs/2505.03561', 'abstract': 'Generative Flow Networks (GFNs) were initially introduced on directed acyclic graphs to sample from an unnormalized distribution density. Recent works have extended the theoretical framework for generative methods allowing more flexibility and enhancing application range. However, many challenges remain in training GFNs in continuous settings and for imitation learning (IL), including intractability of flow-matching loss, limited tests of non-acyclic training, and the need for a separate reward model in imitation learning. The present work proposes a family of generative flows called Ergodic Generative Flows (EGFs) which are used to address the aforementioned issues. First, we leverage ergodicity to build simple generative flows with finitely many globally defined transformations (diffeomorphisms) with universality guarantees and tractable flow-matching loss (FM loss). Second, we introduce a new loss involving cross-entropy coupled to weak flow-matching control, coined KL-weakFM loss. It is designed for IL training without a separate reward model. We evaluate IL-EGFs on toy 2D tasks and real-world datasets from NASA on the sphere, using the KL-weakFM loss. Additionally, we conduct toy 2D reinforcement learning experiments with a target reward, using the FM loss.', 'abstract_zh': 'Ergodic Generative Flows (EGFs) for Generative Methods and Imitation Learning', 'title_zh': '遍历生成流'}
{'arxiv_id': 'arXiv:2505.03560', 'title': 'Rapid AI-based generation of coverage paths for dispensing applications', 'authors': 'Simon Baeuerle, Ian F. Mendonca, Kristof Van Laerhoven, Ralf Mikut, Andreas Steimer', 'link': 'https://arxiv.org/abs/2505.03560', 'abstract': 'Coverage Path Planning of Thermal Interface Materials (TIM) plays a crucial role in the design of power electronics and electronic control units. Up to now, this is done manually by experts or by using optimization approaches with a high computational effort. We propose a novel AI-based approach to generate dispense paths for TIM and similar dispensing applications. It is a drop-in replacement for optimization-based approaches. An Artificial Neural Network (ANN) receives the target cooling area as input and directly outputs the dispense path. Our proposed setup does not require labels and we show its feasibility on multiple target areas. The resulting dispense paths can be directly transferred to automated manufacturing equipment and do not exhibit air entrapments. The approach of using an ANN to predict process parameters for a desired target state in real-time could potentially be transferred to other manufacturing processes.', 'abstract_zh': '热界面材料(TIM)的覆盖路径规划在电源电子和电子控制单元的设计中起着至关重要的作用。目前，这通常是通过专家手动完成或使用高计算成本的优化方法。我们提出了一种基于人工智能的新颖方法，用于生成TIM和其他分配应用的分配路径。该方法是对基于优化的方法的一种即插即用替代方案。人工神经网络(ANN)接收目标冷却区域作为输入，并直接输出分配路径。我们提出的方法不需要标签，并在多个目标区域上展示了其可行性。生成的分配路径可以直接应用于自动化制造设备且不会出现气泡。使用ANN实时预测所需目标状态的工艺参数的方法有可能应用于其他制造过程中。', 'title_zh': '基于AI的快速生成涂布应用覆盖路径'}
{'arxiv_id': 'arXiv:2505.03522', 'title': 'Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks', 'authors': 'Haotong Cheng, Zhiqi Zhang, Hao Li, Xinshang Zhang', 'link': 'https://arxiv.org/abs/2505.03522', 'abstract': 'Deep learning has substantially advanced the Single Image Super-Resolution (SISR). However, existing researches have predominantly focused on raw performance gains, with little attention paid to quantifying the transferability of architectural components. In this paper, we introduce the concept of "Universality" and its associated definitions which extend the traditional notion of "Generalization" to encompass the modules\' ease of transferability, thus revealing the relationships between module universality and model generalizability. Then we propose the Universality Assessment Equation (UAE), a metric for quantifying how readily a given module could be transplanted across models. Guided by the UAE results of standard residual blocks and other plug-and-play modules, we further design two optimized modules, Cycle Residual Block (CRB) and Depth-Wise Cycle Residual Block (DCRB). Through comprehensive experiments on natural-scene benchmarks, remote-sensing datasets, extreme-industrial imagery and on-device deployments, we demonstrate that networks embedded with the proposed plug-and-play modules outperform several state-of-the-arts, reaching a PSNR enhancement of up to 0.83dB or enabling a 71.3% reduction in parameters with negligible loss in reconstruction fidelity.', 'abstract_zh': '深度学习显著推进了单张图像超分辨率（SISR）。然而，现有研究主要关注性能提升，忽视了架构组件转移性的量化。本文引入了“泛化性”及其相关定义，将传统的“泛化”概念扩展到涵盖模块的易转移性，从而揭示模块泛化性与模型泛化能力之间的关系。我们提出了泛化性评估方程（UAE），用于量化给定模块易于移植的程度。基于标准残差模块和其他即插即用模块的UAE结果，我们进一步设计了两种优化模块：周期残差块（CRB）和深度可分离周期残差块（DCRB）。通过在自然场景基准、遥感数据集、极端工业图像及设备端部署上的全面实验，我们证明嵌入所提出即插即用模块的网络优于多种最先进的方法，PSNR提升可达0.83dB或参数减少71.3%且重建保真度无明显下降。', 'title_zh': '单张图像超分辨率中模块可转移性优化：普适性评估与循环残差块'}
{'arxiv_id': 'arXiv:2505.03510', 'title': 'From Neurons to Computation: Biological Reservoir Computing for Pattern Recognition', 'authors': 'Ludovico Iannello, Luca Ciampi, Gabriele Lagani, Fabrizio Tonelli, Eleonora Crocco, Lucio Maria Calcagnile, Angelo Di Garbo, Federico Cremisi, Giuseppe Amato', 'link': 'https://arxiv.org/abs/2505.03510', 'abstract': 'In this paper, we introduce a novel paradigm for reservoir computing (RC) that leverages a pool of cultured biological neurons as the reservoir substrate, creating a biological reservoir computing (BRC). This system operates similarly to an echo state network (ESN), with the key distinction that the neural activity is generated by a network of cultured neurons, rather than being modeled by traditional artificial computational units. The neuronal activity is recorded using a multi-electrode array (MEA), which enables high-throughput recording of neural signals. In our approach, inputs are introduced into the network through a subset of the MEA electrodes, while the remaining electrodes capture the resulting neural activity. This generates a nonlinear mapping of the input data to a high-dimensional biological feature space, where distinguishing between data becomes more efficient and straightforward, allowing a simple linear classifier to perform pattern recognition tasks effectively. To evaluate the performance of our proposed system, we present an experimental study that includes various input patterns, such as positional codes, bars with different orientations, and a digit recognition task. The results demonstrate the feasibility of using biological neural networks to perform tasks traditionally handled by artificial neural networks, paving the way for further exploration of biologically-inspired computing systems, with potential applications in neuromorphic engineering and bio-hybrid computing.', 'abstract_zh': '本文介绍了一种新的神经计算（Reservoir Computing, RC）范式，利用培养的生物神经元池作为计算介质，创建了生物神经计算（Biological Reservoir Computing, BRC）系统。该系统类似于回声状态网络（Echo State Network, ESN），其关键区别在于神经活动由培养的神经元网络生成，而不是由传统的 artificial 计算单元建模。神经活动通过多电极阵列（Multi-Electrode Array,MEA）记录，实现了高通量神经信号记录。在本研究中，输入通过 MEA 的一部分电极注入网络，其余电极捕获由此产生的神经活动。这将输入数据非线性映射到高维生物特征空间，使得区分数据变得更加高效和直接，允许简单的线性分类器有效地完成模式识别任务。为了评估所提出系统的性能，我们展示了包括位置编码、不同方向的条纹以及数字识别任务在内的多种输入模式的实验研究。结果表明，可以使用生物神经网络执行传统由人工神经网络处理的任务，为生物启发计算系统的进一步探索铺平了道路，潜在应用于神经形态工程和生物混合计算。', 'title_zh': '从神经元到计算：生物型 reservoir 计算在模式识别中的应用'}
{'arxiv_id': 'arXiv:2505.03490', 'title': 'A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)', 'authors': 'Faiz Taleb, Ivan Gazeau, Maryline Laurent', 'link': 'https://arxiv.org/abs/2505.03490', 'abstract': 'Generative models can unintentionally memorize training data, posing significant privacy risks. This paper addresses the memorization phenomenon in time series imputation models, introducing the Loss-Based with Reference Model (LBRM) algorithm. The LBRM method leverages a reference model to enhance the accuracy of membership inference attacks, distinguishing between training and test data. Our contributions are twofold: first, we propose an innovative method to effectively extract and identify memorized training data, significantly improving detection accuracy. On average, without fine-tuning, the AUROC improved by approximately 40\\%. With fine-tuning, the AUROC increased by approximately 60\\%. Second, we validate our approach through membership inference attacks on two types of architectures designed for time series imputation, demonstrating the robustness and versatility of the LBRM approach in different contexts. These results highlight the significant enhancement in detection accuracy provided by the LBRM approach, addressing privacy risks in time series imputation models.', 'abstract_zh': '生成模型可能无意中记忆训练数据，带来重要的隐私风险。本文针对时间序列插补模型中的记忆现象，提出了一种基于损失的参考模型（LBRM）算法。LBRM 方法利用参考模型提高成员推理攻击的准确性，区分训练数据和测试数据。我们的贡献主要有两点：首先，我们提出了一种有效提取和识别记忆训练数据的创新方法，显著提高了检测准确性。平均而言，在未微调的情况下，AUROC 提高了约 40%。经过微调后，AUROC 提高了约 60%。其次，我们通过两种类型的时间序列插补架构上的成员推理攻击验证了我们的方法，展示了 LBRM 方法在不同场景下的鲁棒性和通用性。这些结果突显了 LBRM 方法在提高检测准确性方面的重要增强，解决了时间序列插补模型中的隐私风险。', 'title_zh': '一种基于损失与参考模型的新会员推断攻击算法：识别生成性和预测性模型中的记忆现象（LBRM）'}
{'arxiv_id': 'arXiv:2505.03452', 'title': 'An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation', 'authors': 'Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo', 'link': 'https://arxiv.org/abs/2505.03452', 'abstract': 'Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a given use case can be complex and expensive. Motivated by this challenge, frameworks for RAG hyper-parameter optimization (HPO) have recently emerged, yet their effectiveness has not been rigorously benchmarked. To address this gap, we present a comprehensive study involving 5 HPO algorithms over 5 datasets from diverse domains, including a new one collected for this work on real-world product documentation. Our study explores the largest HPO search space considered to date, with two optimized evaluation metrics. Analysis of the results shows that RAG HPO can be done efficiently, either greedily or with iterative random search, and that it significantly boosts RAG performance for all datasets. For greedy HPO approaches, we show that optimizing models first is preferable to the prevalent practice of optimizing sequentially according to the RAG pipeline order.', 'abstract_zh': '针对给定应用场景找到最佳检索增强生成（RAG）配置可能既复杂又昂贵。为应对这一挑战，最近出现了RAG超参数优化（HPO）框架，但其有效性尚未经过严格的基准测试。为进一步解决这一问题，我们进行了全面研究，涵盖了5种HPO算法和5个来自不同领域的数据集，其中包括一个为本次研究收集的新数据集，涉及真实-world产品文档。我们的研究探索了迄今最大的HPO搜索空间，并采用了两种优化评估指标。结果分析显示，无论是使用贪婪方法还是迭代随机搜索，RAG的HPO都可以高效进行，并且显著提升了所有数据集上的RAG性能。对于贪婪HPO方法，我们展示了首先优化模型比按照RAG管道顺序逐步优化更为可取。', 'title_zh': '检索增强生成的超参数优化方法分析'}
{'arxiv_id': 'arXiv:2505.03451', 'title': 'Detecting Quishing Attacks with Machine Learning Techniques Through QR Code Analysis', 'authors': 'Fouad Trad, Ali Chehab', 'link': 'https://arxiv.org/abs/2505.03451', 'abstract': 'The rise of QR code based phishing ("Quishing") poses a growing cybersecurity threat, as attackers increasingly exploit QR codes to bypass traditional phishing defenses. Existing detection methods predominantly focus on URL analysis, which requires the extraction of the QR code payload, and may inadvertently expose users to malicious content. Moreover, QR codes can encode various types of data beyond URLs, such as Wi-Fi credentials and payment information, making URL-based detection insufficient for broader security concerns. To address these gaps, we propose the first framework for quishing detection that directly analyzes QR code structure and pixel patterns without extracting the embedded content. We generated a dataset of phishing and benign QR codes and we used it to train and evaluate multiple machine learning models, including Logistic Regression, Decision Trees, Random Forest, Naive Bayes, LightGBM, and XGBoost. Our best-performing model (XGBoost) achieves an AUC of 0.9106, demonstrating the feasibility of QR-centric detection. Through feature importance analysis, we identify key visual indicators of malicious intent and refine our feature set by removing non-informative pixels, improving performance to an AUC of 0.9133 with a reduced feature space. Our findings reveal that the structural features of QR code correlate strongly with phishing risk. This work establishes a foundation for quishing mitigation and highlights the potential of direct QR analysis as a critical layer in modern phishing defenses.', 'abstract_zh': '基于二维码的恶意诱骗（Quishing）的兴起对网络安全构成了日益增长的威胁，攻击者越来越多地利用二维码规避传统诱骗防护。现有的检测方法主要侧重于URL分析，这需要提取二维码负载内容，可能会无意中使用户暴露在恶意内容中。此外，二维码可以编码超出URL的各种类型的数据，例如Wi-Fi凭据和支付信息，使得基于URL的检测对更广泛的安全部署不够充分。为了解决这些问题，我们提出了一种新的框架，直接分析二维码的结构和像素模式，而无需提取嵌入的内容。我们生成了一组恶意诱骗和良性二维码的数据集，并使用该数据集训练和评估了多种机器学习模型，包括逻辑回归、决策树、随机森林、朴素贝叶斯、LightGBM和XGBoost。我们的表现最佳模型（XGBoost）达到AUC值0.9106，证明了以二维码为中心的检测的可行性。通过特征重要性分析，我们识别出恶意意图的关键视觉指标，并通过去除不相关信息素来精简特征集，使性能在减少特征空间的情况下达到AUC值0.9133。我们的研究发现二维码的结构特征与诱骗风险紧密相关。本研究为防止恶意诱骗奠定了基础，并突显了直接分析二维码作为现代防诱骗防御体系关键层的潜力。', 'title_zh': '通过QR码分析利用机器学习技术检测弃权攻击'}
{'arxiv_id': 'arXiv:2505.03443', 'title': 'Elevating Semantic Exploration: A Novel Approach Utilizing Distributed Repositories', 'authors': 'Valerio Bellandi', 'link': 'https://arxiv.org/abs/2505.03443', 'abstract': 'Centralized and distributed systems are two main approaches to organizing ICT infrastructure, each with its pros and cons. Centralized systems concentrate resources in one location, making management easier but creating single points of failure. Distributed systems, on the other hand, spread resources across multiple nodes, offering better scalability and fault tolerance, but requiring more complex management. The choice between them depends on factors like application needs, scalability, and data sensitivity. Centralized systems suit applications with limited scalability and centralized control, while distributed systems excel in large-scale environments requiring high availability and performance. This paper explores a distributed document repository system developed for the Italian Ministry of Justice, using edge repositories to analyze textual data and metadata, enhancing semantic exploration capabilities.', 'abstract_zh': '集中式和分布式系统是组织ICT基础设施的两种主要方法，各有优缺点。集中式系统将资源集中在一个位置，便于管理但容易出现单点故障。分布式系统则将资源分布在多个节点上，提供了更好的可扩展性和容错性，但需要更复杂的管理。在应用需求、可扩展性和数据敏感性等因素的影响下，两者的选择各有利弊。集中式系统适用于需要有限扩展性和集中控制的应用，而分布式系统则在需要高可用性和高性能的大规模环境中表现出色。本文探讨了为意大利司法部开发的一个分布式文档存储系统，利用边缘存储库分析文本数据和元数据，增强语义探索能力。', 'title_zh': '提升语义探索：一种利用分布式仓库的新方法'}
{'arxiv_id': 'arXiv:2505.03426', 'title': 'Phenotype-Guided Generative Model for High-Fidelity Cardiac MRI Synthesis: Advancing Pretraining and Clinical Applications', 'authors': 'Ziyu Li, Yujian Hu, Zhengyao Ding, Yiheng Mao, Haitao Li, Fan Yi, Hongkun Zhang, Zhengxing Huang', 'link': 'https://arxiv.org/abs/2505.03426', 'abstract': 'Cardiac Magnetic Resonance (CMR) imaging is a vital non-invasive tool for diagnosing heart diseases and evaluating cardiac health. However, the limited availability of large-scale, high-quality CMR datasets poses a major challenge to the effective application of artificial intelligence (AI) in this domain. Even the amount of unlabeled data and the health status it covers are difficult to meet the needs of model pretraining, which hinders the performance of AI models on downstream tasks. In this study, we present Cardiac Phenotype-Guided CMR Generation (CPGG), a novel approach for generating diverse CMR data that covers a wide spectrum of cardiac health status. The CPGG framework consists of two stages: in the first stage, a generative model is trained using cardiac phenotypes derived from CMR data; in the second stage, a masked autoregressive diffusion model, conditioned on these phenotypes, generates high-fidelity CMR cine sequences that capture both structural and functional features of the heart in a fine-grained manner. We synthesized a massive amount of CMR to expand the pretraining data. Experimental results show that CPGG generates high-quality synthetic CMR data, significantly improving performance on various downstream tasks, including diagnosis and cardiac phenotypes prediction. These gains are demonstrated across both public and private datasets, highlighting the effectiveness of our approach. Code is availabel at this https URL.', 'abstract_zh': '基于心脏表型引导的心磁共振成像生成（CPGG）', 'title_zh': '基于表型指导的高保真心脏MRI生成模型：推进预训练与临床应用'}
{'arxiv_id': 'arXiv:2505.03424', 'title': 'Framework GNN-AID: Graph Neural Network Analysis Interpretation and Defense', 'authors': 'Kirill Lukyanov, Mikhail Drobyshevskiy, Georgii Sazonov, Mikhail Soloviov, Ilya Makarov', 'link': 'https://arxiv.org/abs/2505.03424', 'abstract': 'The growing need for Trusted AI (TAI) highlights the importance of interpretability and robustness in machine learning models. However, many existing tools overlook graph data and rarely combine these two aspects into a single solution. Graph Neural Networks (GNNs) have become a popular approach, achieving top results across various tasks. We introduce GNN-AID (Graph Neural Network Analysis, Interpretation, and Defense), an open-source framework designed for graph data to address this gap. Built as a Python library, GNN-AID supports advanced trust methods and architectural layers, allowing users to analyze graph datasets and GNN behavior using attacks, defenses, and interpretability methods.\nGNN-AID is built on PyTorch-Geometric, offering preloaded datasets, models, and support for any GNNs through customizable interfaces. It also includes a web interface with tools for graph visualization and no-code features like an interactive model builder, simplifying the exploration and analysis of GNNs. The framework also supports MLOps techniques, ensuring reproducibility and result versioning to track and revisit analyses efficiently.\nGNN-AID is a flexible tool for developers and researchers. It helps developers create, analyze, and customize graph models, while also providing access to prebuilt datasets and models for quick experimentation. Researchers can use the framework to explore advanced topics on the relationship between interpretability and robustness, test defense strategies, and combine methods to protect against different types of attacks.\nWe also show how defenses against evasion and poisoning attacks can conflict when applied to graph data, highlighting the complex connections between defense strategies.\nGNN-AID is available at \\href{this https URL}{this http URL}', 'abstract_zh': '可信人工智能（Trusted AI）的需求增长突显了可解释性和鲁棒性在机器学习模型中的重要性。然而，许多现有工具忽视了图数据，并且很少将这两者结合成一个解决方案。图神经网络（GNNs）已成为一种流行的方法，在各种任务中取得了顶尖的结果。我们介绍了GNN-AID（图神经网络的分析、解释和防御），这是一个开源框架，旨在为图数据填补这一空白。作为Python库构建，GNN-AID支持先进的信任方法和架构层，允许用户通过攻击、防御和可解释性方法分析图数据集和GNN行为。\n\nGNN-AID基于PyTorch-Geometric构建，提供了预加载的数据集、模型，并且通过自定义接口支持任何GNN。它还包括一个网络界面，包含用于图形可视化和无代码功能（如交互模型构建器）的工具，简化了GNN的探索和分析。该框架还支持MLOps技术，确保可重复性和结果版本化，从而高效地跟踪和回顾分析。\n\nGNN-AID是一种灵活的工具，适用于开发者和研究人员。它帮助开发者创建、分析和自定义图模型，同时提供快速实验所需的预构建数据集和模型的访问权限。研究人员可以使用该框架探索可解释性和鲁棒性之间的关系，测试防御策略，并结合方法以保护免受不同类型攻击的影响。\n\n我们还展示了当应用于图数据时，针对欺骗和投毒攻击的防御策略可能会产生冲突，突显了防御策略之间复杂的关系。\n\nGNN-AID可在\\href{this https URL}{this http URL}获取。', 'title_zh': 'GNN-AID框架：图神经网络分析、解释与防御'}
{'arxiv_id': 'arXiv:2505.03401', 'title': 'DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation', 'authors': 'Shanshan Song, Hui Tang, Honglong Yang, Xiaomeng Li', 'link': 'https://arxiv.org/abs/2505.03401', 'abstract': 'Radiology Report Generation (RRG) automates the creation of radiology reports from medical imaging, enhancing the efficiency of the reporting process. Longitudinal Radiology Report Generation (LRRG) extends RRG by incorporating the ability to compare current and prior exams, facilitating the tracking of temporal changes in clinical findings. Existing LRRG approaches only extract features from prior and current images using a visual pre-trained encoder, which are then concatenated to generate the final report. However, these methods struggle to effectively capture both spatial and temporal correlations during the feature extraction process. Consequently, the extracted features inadequately capture the information of difference across exams and thus underrepresent the expected progressions, leading to sub-optimal performance in LRRG. To address this, we develop a novel dynamic difference-aware temporal residual network (DDaTR). In DDaTR, we introduce two modules at each stage of the visual encoder to capture multi-level spatial correlations. The Dynamic Feature Alignment Module (DFAM) is designed to align prior features across modalities for the integrity of prior clinical information. Prompted by the enriched prior features, the dynamic difference-aware module (DDAM) captures favorable difference information by identifying relationships across exams. Furthermore, our DDaTR employs the dynamic residual network to unidirectionally transmit longitudinal information, effectively modelling temporal correlations. Extensive experiments demonstrated superior performance over existing methods on three benchmarks, proving its efficacy in both RRG and LRRG tasks.', 'abstract_zh': '放射报告生成（RRG）自动化医疗成像的放射报告创建，提升报告过程的效率。纵向放射报告生成（LRRG）通过整合当前和以往检查的对比能力，促进临床发现的时间变化跟踪。现有的LRRG方法仅使用视觉预训练编码器从以往和当前图像中提取特征，然后将这些特征连接起来生成最终报告。然而，这些方法在特征提取过程中难以有效捕捉空间和时间相关性，导致提取的特征未能充分捕捉考试之间的差异信息，从而无法充分代表预期的变化，导致LRRG表现不佳。为解决这一问题，我们开发了一种新颖的动态差异感知时间残差网络（DDaTR）。在DDaTR中，在视觉编码器的每个阶段引入两个模块以捕捉多级空间相关性。动态特征对齐模块（DFAM）旨在跨模态对齐以往特征，以确保以往临床信息的完整性。受丰富后的以往特征启发，动态差异感知模块（DDAM）通过识别考试间的关联来捕捉有利的差异信息。此外，我们的DDaTR采用动态残差网络单向传递纵向信息，有效建模时间相关性。实验结果证明，DDaTR在三个基准测试上的性能优于现有方法，验证了其在RRG和LRRG任务中的有效性。', 'title_zh': 'DDaTR：动态差异感知的时序残差网络在纵向放射学报告生成中的应用'}
{'arxiv_id': 'arXiv:2505.03338', 'title': 'Safer Prompts: Reducing IP Risk in Visual Generative AI', 'authors': 'Lena Reissinger, Yuanyuan Li, Anna-Carolina Haensch, Neeraj Sarna', 'link': 'https://arxiv.org/abs/2505.03338', 'abstract': 'Visual Generative AI models have demonstrated remarkable capability in generating high-quality images from simple inputs like text prompts. However, because these models are trained on images from diverse sources, they risk memorizing and reproducing specific content, raising concerns about intellectual property (IP) infringement. Recent advances in prompt engineering offer a cost-effective way to enhance generative AI performance. In this paper, we evaluate the effectiveness of prompt engineering techniques in mitigating IP infringement risks in image generation. Our findings show that Chain of Thought Prompting and Task Instruction Prompting significantly reduce the similarity between generated images and the training data of diffusion models, thereby lowering the risk of IP infringement.', 'abstract_zh': '视觉生成AI模型展示了从简单的输入如文本提示生成高质量图像的非凡能力。然而，由于这些模型是在多种来源的图像上进行训练的，它们存在记忆和复制特定内容的风险，这引发了关于知识产权（IP）侵权的担忧。最近的提示工程技术进步为提高生成型AI性能提供了成本有效的途径。本研究评估了提示工程技术在减轻图像生成中的IP侵权风险方面的有效性。我们的研究发现，Chain of Thought Prompting和Task Instruction Prompting显著降低了生成图像与扩散模型训练数据之间的相似性，从而降低了IP侵权的风险。', 'title_zh': '更安全的提示：降低视觉生成AI中的IP风险'}
{'arxiv_id': 'arXiv:2505.03314', 'title': 'Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation', 'authors': 'Jincheng Zhang, György Fazekas, Charalampos Saitis', 'link': 'https://arxiv.org/abs/2505.03314', 'abstract': 'The recent surge in the popularity of diffusion models for image synthesis has attracted new attention to their potential for generation tasks in other domains. However, their applications to symbolic music generation remain largely under-explored because symbolic music is typically represented as sequences of discrete events and standard diffusion models are not well-suited for discrete data. We represent symbolic music as image-like pianorolls, facilitating the use of diffusion models for the generation of symbolic music. Moreover, this study introduces a novel diffusion model that incorporates our proposed Transformer-Mamba block and learnable wavelet transform. Classifier-free guidance is utilised to generate symbolic music with target chords. Our evaluation shows that our method achieves compelling results in terms of music quality and controllability, outperforming the strong baseline in pianoroll generation. Our code is available at this https URL.', 'abstract_zh': '近期扩散模型在图像生成中的流行 resurgence 重新引发了人们对其他领域生成任务潜在应用的关注。然而，由于符号音乐通常表示为离散事件序列，而标准扩散模型不适用于离散数据，因此将其应用于符号音乐生成的研究仍相对较少。我们通过将符号音乐表示为类似图像的钢琴卷帘图，促进了扩散模型在符号音乐生成中的应用。此外，本研究引入了一种新型扩散模型，该模型结合了我们提出的Transformer-Mamba模块和可学习小波变换。我们利用无分类器引导生成具有目标和弦的符号音乐。评估结果显示，我们的方法在音乐质量和可控性方面取得了令人印象深刻的结果，并在钢琴卷帘图生成中超过了强大的基线模型。我们的代码可在以下链接获取。', 'title_zh': '具有可学习小波的Mamba-扩散模型可控符号Music生成'}
{'arxiv_id': 'arXiv:2505.03303', 'title': 'Comparative Analysis of Lightweight Deep Learning Models for Memory-Constrained Devices', 'authors': 'Tasnim Shahriar', 'link': 'https://arxiv.org/abs/2505.03303', 'abstract': 'This paper presents a comprehensive evaluation of lightweight deep learning models for image classification, emphasizing their suitability for deployment in resource-constrained environments such as low-memory devices. Five state-of-the-art architectures - MobileNetV3 Small, ResNet18, SqueezeNet, EfficientNetV2-S, and ShuffleNetV2 - are benchmarked across three diverse datasets: CIFAR-10, CIFAR-100, and Tiny ImageNet. The models are assessed using four key performance metrics: classification accuracy, inference time, floating-point operations (FLOPs), and model size. Additionally, we investigate the impact of hyperparameter tuning, data augmentation, and training paradigms by comparing pretrained models with scratch-trained counterparts, focusing on MobileNetV3 Small. Our findings reveal that transfer learning significantly enhances model accuracy and computational efficiency, particularly for complex datasets like Tiny ImageNet. EfficientNetV2 consistently achieves the highest accuracy, while MobileNetV3 offers the best balance between accuracy and efficiency, and SqueezeNet excels in inference speed and compactness. This study highlights critical trade-offs between accuracy and efficiency, offering actionable insights for deploying lightweight models in real-world applications where computational resources are limited. By addressing these challenges, this research contributes to optimizing deep learning systems for edge computing and mobile platforms.', 'abstract_zh': '这种轻量级深度学习模型在图像分类中的综合评估：面向资源受限环境的应用', 'title_zh': '轻量级深学习模型在内存约束设备上的比较分析'}
{'arxiv_id': 'arXiv:2505.03281', 'title': 'Physics-inspired Energy Transition Neural Network for Sequence Learning', 'authors': 'Zhou Wu, Junyi An, Baile Xu, Furao Shen, Jian Zhao', 'link': 'https://arxiv.org/abs/2505.03281', 'abstract': 'Recently, the superior performance of Transformers has made them a more robust and scalable solution for sequence modeling than traditional recurrent neural networks (RNNs). However, the effectiveness of Transformer in capturing long-term dependencies is primarily attributed to their comprehensive pair-modeling process rather than inherent inductive biases toward sequence semantics. In this study, we explore the capabilities of pure RNNs and reassess their long-term learning mechanisms. Inspired by the physics energy transition models that track energy changes over time, we propose a effective recurrent structure called the``Physics-inspired Energy Transition Neural Network" (PETNN). We demonstrate that PETNN\'s memory mechanism effectively stores information over long-term dependencies. Experimental results indicate that PETNN outperforms transformer-based methods across various sequence tasks. Furthermore, owing to its recurrent nature, PETNN exhibits significantly lower complexity. Our study presents an optimal foundational recurrent architecture and highlights the potential for developing effective recurrent neural networks in fields currently dominated by Transformer.', 'abstract_zh': '最近，Transformer 的出色性能使其成为比传统递归神经网络（RNNs）更 robust 和可扩展的序列建模解决方案。然而，Transformer 在捕捉长期依赖关系方面的有效性主要归因于其全面的配对建模过程，而非固有的序列语义归纳偏置。在本研究中，我们探索了纯 RNN 的能力并重新评估了其长期学习机制。受物理能量转移模型的启发，该模型随时间追踪能量变化，我们提出了一种有效的递归结构，称为“物理启发的能量转移神经网络”（PETNN）。研究表明，PETNN 的记忆机制有效地存储了长期依赖关系中的信息。实验结果表明，PETNN 在各种序列任务中优于基于 Transformer 的方法。此外，由于其递归性质，PETNN 的复杂性显著较低。本研究展示了最优的基础递归架构，并突显了在目前由 Transformer 占据主导地位的领域开发有效递归神经网络的潜力。', 'title_zh': '基于物理启发的能量转换神经网络序列表征'}
{'arxiv_id': 'arXiv:2505.03265', 'title': 'Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models', 'authors': 'Abdelkarim El-Hajjami, Camille Salinesi', 'link': 'https://arxiv.org/abs/2505.03265', 'abstract': 'While modern Requirements Engineering (RE) heavily relies on natural language processing and Machine Learning (ML) techniques, their effectiveness is limited by the scarcity of high-quality datasets. This paper introduces Synthline, a Product Line (PL) approach that leverages Large Language Models to systematically generate synthetic RE data for classification-based use cases. Through an empirical evaluation conducted in the context of using ML for the identification of requirements specification defects, we investigated both the diversity of the generated data and its utility for training downstream models. Our analysis reveals that while synthetic datasets exhibit less diversity than real data, they are good enough to serve as viable training resources. Moreover, our evaluation shows that combining synthetic and real data leads to substantial performance improvements. Specifically, hybrid approaches achieve up to 85% improvement in precision and a 2x increase in recall compared to models trained exclusively on real data. These findings demonstrate the potential of PL-based synthetic data generation to address data scarcity in RE. We make both our implementation and generated datasets publicly available to support reproducibility and advancement in the field.', 'abstract_zh': 'Synthline：基于产品线的大语言模型驱动的合成需求工程数据生成', 'title_zh': 'Synthline：一种使用大型语言模型生成合成需求工程数据的产品线方法'}
{'arxiv_id': 'arXiv:2505.03217', 'title': 'Accelerating Evolution: Integrating PSO Principles into Real-Coded Genetic Algorithm Crossover', 'authors': 'Xiaobo Jin, JiaShu Tu', 'link': 'https://arxiv.org/abs/2505.03217', 'abstract': "This study introduces an innovative crossover operator named Particle Swarm Optimization-inspired Crossover (PSOX), which is specifically developed for real-coded genetic algorithms. Departing from conventional crossover approaches that only exchange information between individuals within the same generation, PSOX uniquely incorporates guidance from both the current global best solution and historical optimal solutions across multiple generations. This novel mechanism enables the algorithm to maintain population diversity while simultaneously accelerating convergence toward promising regions of the search space. The effectiveness of PSOX is rigorously evaluated through comprehensive experiments on 15 benchmark test functions with diverse characteristics, including unimodal, multimodal, and highly complex landscapes. Comparative analysis against five state-of-the-art crossover operators reveals that PSOX consistently delivers superior performance in terms of solution accuracy, algorithmic stability, and convergence speed, especially when combined with an appropriate mutation strategy. Furthermore, the study provides an in-depth investigation of how different mutation rates influence PSOX's performance, yielding practical guidelines for parameter tuning when addressing optimization problems with varying landscape properties.", 'abstract_zh': '基于粒子群优化启发的交叉算子研究：一种用于实码遗传算法的新颖交叉算子', 'title_zh': '加速进化：将粒子 swarm 算子集成到实编码遗传算法交叉中'}
{'arxiv_id': 'arXiv:2505.03214', 'title': 'DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral', 'authors': 'Qiang Sun, Sirui Li, Tingting Bi, Du Huynh, Mark Reynolds, Yuanyi Luo, Wei Liu', 'link': 'https://arxiv.org/abs/2505.03214', 'abstract': 'Acquiring structured data from domain-specific, image-based documents such as scanned reports is crucial for many downstream tasks but remains challenging due to document variability. Many of these documents exist as images rather than as machine-readable text, which requires human annotation to train automated extraction systems. We present DocSpiral, the first Human-in-the-Spiral assistive document annotation platform, designed to address the challenge of extracting structured information from domain-specific, image-based document collections. Our spiral design establishes an iterative cycle in which human annotations train models that progressively require less manual intervention. DocSpiral integrates document format normalization, comprehensive annotation interfaces, evaluation metrics dashboard, and API endpoints for the development of AI / ML models into a unified workflow. Experiments demonstrate that our framework reduces annotation time by at least 41\\% while showing consistent performance gains across three iterations during model training. By making this annotation platform freely accessible, we aim to lower barriers to AI/ML models development in document processing, facilitating the adoption of large language models in image-based, document-intensive fields such as geoscience and healthcare. The system is freely available at: this https URL. The demonstration video is available: this https URL.', 'abstract_zh': '从特定领域基于图像的文档中获取结构化数据对于许多下游任务至关重要，但由于文档的差异性，这仍然具有挑战性。许多这些文档是以图像形式存在，而不是机器可读的文本，这需要人工注解以训练自动提取系统。我们提出了DocSpiral，这是第一个螺旋式人工介入辅助文档注解平台，旨在解决从特定领域基于图像的文档集合中提取结构化信息的挑战。我们的螺旋设计建立了一个迭代循环，在此过程中，人类注解训练模型，逐渐减少手动干预的需求。DocSpiral将文档格式规范化、全面的注解界面、评估指标仪表盘和API端点整合到一个统一的工作流程中，以支持AI/ML模型开发。实验结果显示，在模型训练过程中，我们的框架将注释时间减少了至少41%，并在三轮迭代中展现了持续的性能提升。通过使此注解平台免费开放，我们旨在降低AI/ML模型在文档处理中的开发门槛，促进大型语言模型在以图像为基础、文档密集型领域的应用，如地质科学和医疗保健。该系统可在以下链接获取：this https URL。演示视频可在以下链接获取：this https URL。', 'title_zh': 'DocSpiral: 一种集成辅助文档标注的人机螺旋平台'}
{'arxiv_id': 'arXiv:2505.03193', 'title': 'A study on audio synchronous steganography detection and distributed guide inference model based on sliding spectral features and intelligent inference drive', 'authors': 'Wei Meng', 'link': 'https://arxiv.org/abs/2505.03193', 'abstract': 'With the rise of short video platforms in global communication, embedding steganographic data in audio synchronization streams has emerged as a new covert communication method. To address the limitations of traditional techniques in detecting synchronized steganography, this paper proposes a detection and distributed guidance reconstruction model based on short video "Yupan" samples released by China\'s South Sea Fleet on TikTok. The method integrates sliding spectrum feature extraction and intelligent inference mechanisms. A 25 ms sliding window with short-time Fourier transform (STFT) is used to extract the main frequency trajectory and construct the synchronization frame detection model (M1), identifying a frame flag "FFFFFFFFFFFFFFFFFF80". The subsequent 32-byte payload is decoded by a structured model (M2) to infer distributed guidance commands. Analysis reveals a low-entropy, repetitive byte sequence in the 36 to 45 second audio segment with highly concentrated spectral energy, confirming the presence of synchronization frames. Although plaintext semantics are not restored, the consistency in command field layout suggests features of military communication protocols. The multi-segment splicing model further shows cross-video embedding and centralized decoding capabilities. The proposed framework validates the effectiveness of sliding spectral features for synchronized steganography detection and builds an extensible inference model for covert communication analysis and tactical guidance simulation on open platforms.', 'abstract_zh': '基于中国南海舰队抖音“ Yupan ”样例的短视频音频同步隐写检测与分布式解码模型', 'title_zh': '基于滑动频谱特征和智能推理驱动的分布式引导推断模型的音频同步隐写分析研究'}
{'arxiv_id': 'arXiv:2505.03176', 'title': 'seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models', 'authors': 'Hafez Ghaemi, Eilif Muller, Shahab Bakhtiari', 'link': 'https://arxiv.org/abs/2505.03176', 'abstract': 'Current self-supervised algorithms mostly rely on transformations such as data augmentation and masking to learn visual representations. This is achieved by inducing invariance or equivariance with respect to these transformations after encoding two views of an image. This dominant two-view paradigm can limit the flexibility of learned representations for downstream adaptation by creating performance trade-offs between invariance-related tasks such as image classification and more fine-grained equivariance-related tasks. In this work, we introduce \\emph{seq-JEPA}, a world modeling paradigm based on joint-embedding predictive architecture that leverages architectural inductive biases to resolve this trade-off. Without requiring an additional equivariance predictor or loss term, seq-JEPA simultaneously learns two architecturally segregated representations: one equivariant to the specified transformations and another invariant to them and suited for tasks such as classification. To do so, our model processes a short sequence of different views (observations) of an input image. Each encoded view is concatenated with embeddings corresponding to the relative transformation (action) producing the next observation in the sequence. A transformer encoder outputs an aggregate representation of this sequence, which is subsequently conditioned on the action leading to the next observation to predict its representation. Empirically, seq-JEPA achieves strong performance on equivariant benchmarks and image classification without sacrificing one for the other. Additionally, our framework excels at tasks that inherently require aggregating a sequence of observations, such as path integration across actions and predictive learning across eye movements.', 'abstract_zh': '当前的自监督算法主要依赖于数据增强和屏蔽等变换来学习视觉表示。这些方法通过编码图像的两个视图并在这些变换下诱导不变性或协变性来实现这一点。这种占主导地位的双视图范式可以通过在不变性相关的任务（如图像分类）和更细致的协变性相关的任务之间创建性能权衡来限制学习表示的灵活性。在此项工作中，我们引入了\\emph{seq-JEPA}，一种基于联合嵌入预测架构的环境建模范式，利用架构诱导偏置解决这一权衡问题。seq-JEPA 不需要额外的协变性预测器或损失项，同时学习两个架构上隔离的表示：一个是对指定变换协变的表示，另一个是对它们不变且适合分类等任务。为此，我们的模型处理输入图像的不同视图（观察）的短序列。每个编码的视图都与产生下一个观察的相对变换（动作）对应的嵌入拼接起来。变压器编码器输出该序列的聚合表示，随后根据导致下一个观察的动作对其进行条件化以预测其表示。实验上，seq-JEPA 在协变基准测试和图像分类上表现出色，而无需牺牲一个以换取另一个。此外，我们的框架在需要聚合序列观察的任务上表现出色，例如在动作间进行路径整合和在眼动间进行预测学习。', 'title_zh': 'seq-JEPA: 自回归预测不变-相伴世界模型'}
{'arxiv_id': 'arXiv:2505.03154', 'title': 'StableMotion: Training Motion Cleanup Models with Unpaired Corrupted Data', 'authors': 'Yuxuan Mu, Hung Yu Ling, Yi Shi, Ismael Baira Ojeda, Pengcheng Xi, Chang Shu, Fabio Zinno, Xue Bin Peng', 'link': 'https://arxiv.org/abs/2505.03154', 'abstract': 'Motion capture (mocap) data often exhibits visually jarring artifacts due to inaccurate sensors and post-processing. Cleaning this corrupted data can require substantial manual effort from human experts, which can be a costly and time-consuming process. Previous data-driven motion cleanup methods offer the promise of automating this cleanup process, but often require in-domain paired corrupted-to-clean training data. Constructing such paired datasets requires access to high-quality, relatively artifact-free motion clips, which often necessitates laborious manual cleanup. In this work, we present StableMotion, a simple yet effective method for training motion cleanup models directly from unpaired corrupted datasets that need cleanup. The core component of our method is the introduction of motion quality indicators, which can be easily annotated through manual labeling or heuristic algorithms and enable training of quality-aware motion generation models on raw motion data with mixed quality. At test time, the model can be prompted to generate high-quality motions using the quality indicators. Our method can be implemented through a simple diffusion-based framework, leading to a unified motion generate-discriminate model, which can be used to both identify and fix corrupted frames. We demonstrate that our proposed method is effective for training motion cleanup models on raw mocap data in production scenarios by applying StableMotion to SoccerMocap, a 245-hour soccer mocap dataset containing real-world motion artifacts. The trained model effectively corrects a wide range of motion artifacts, reducing motion pops and frozen frames by 68% and 81%, respectively. See this https URL for more results.', 'abstract_zh': '一种从未配对的受损数据集训练运动清理模型的方法：StableMotion', 'title_zh': '稳定运动：使用未配对的损坏数据训练运动清理模型'}
{'arxiv_id': 'arXiv:2505.03149', 'title': 'Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo)', 'authors': 'Joseph William Kettelkamp, Ludovica Romanin, Sarv Priya, Mathews Jacob', 'link': 'https://arxiv.org/abs/2505.03149', 'abstract': 'We introduce an unsupervised motion-compensated image reconstruction algorithm for free-breathing and ungated 3D cardiac magnetic resonance imaging (MRI). We express the image volume corresponding to each specific motion phase as the deformation of a single static image template. The main contribution of the work is the low-rank model for the compact joint representation of the family of diffeomorphisms, parameterized by the motion phases. The diffeomorphism at a specific motion phase is obtained by integrating a parametric velocity field along a path connecting the reference template phase to the motion phase. The velocity field at different phases is represented using a low-rank model. The static template and the low-rank motion model parameters are learned directly from the k-space data in an unsupervised fashion. The more constrained motion model is observed to offer improved recovery compared to current motion-resolved and motion-compensated algorithms for free-breathing 3D cine MRI.', 'abstract_zh': '无监督运动补偿图像重建算法用于自由呼吸和无门控3D心脏磁共振成像（MRI）', 'title_zh': '基于低秩 diffeomorphic 流的运动补偿心脏MRI（DMoCo）'}
{'arxiv_id': 'arXiv:2505.03132', 'title': 'VISLIX: An XAI Framework for Validating Vision Models with Slice Discovery and Analysis', 'authors': 'Xinyuan Yan, Xiwei Xuan, Jorge Piazentin Ono, Jiajing Guo, Vikram Mohanty, Shekar Arvind Kumar, Liang Gou, Bei Wang, Liu Ren', 'link': 'https://arxiv.org/abs/2505.03132', 'abstract': "Real-world machine learning models require rigorous evaluation before deployment, especially in safety-critical domains like autonomous driving and surveillance. The evaluation of machine learning models often focuses on data slices, which are subsets of the data that share a set of characteristics. Data slice finding automatically identifies conditions or data subgroups where models underperform, aiding developers in mitigating performance issues. Despite its popularity and effectiveness, data slicing for vision model validation faces several challenges. First, data slicing often needs additional image metadata or visual concepts, and falls short in certain computer vision tasks, such as object detection. Second, understanding data slices is a labor-intensive and mentally demanding process that heavily relies on the expert's domain knowledge. Third, data slicing lacks a human-in-the-loop solution that allows experts to form hypothesis and test them interactively. To overcome these limitations and better support the machine learning operations lifecycle, we introduce VISLIX, a novel visual analytics framework that employs state-of-the-art foundation models to help domain experts analyze slices in computer vision models. Our approach does not require image metadata or visual concepts, automatically generates natural language insights, and allows users to test data slice hypothesis interactively. We evaluate VISLIX with an expert study and three use cases, that demonstrate the effectiveness of our tool in providing comprehensive insights for validating object detection models.", 'abstract_zh': '实世界中的机器学习模型在部署前需要严格的评估，尤其是在自动驾驶和监控等安全关键领域。机器学习模型的评估通常集中在数据切片上，这是具有共同特征的数据子集。数据切片能够自动识别模型性能不佳的条件或数据子组，帮助开发者缓解性能问题。尽管数据切片在视觉模型验证中流行且有效，但仍面临几个挑战。首先，数据切片往往需要额外的图像元数据或视觉概念，在某些计算机视觉任务中应用受限，如目标检测。其次，理解数据切片是一个耗时且复杂的任务，高度依赖于专家领域的知识。第三，数据切片缺乏一个将专家纳入循环的解决方案，不支持专家形成和测试假设的交互过程。为了克服这些限制，更好地支持机器学习运维生命周期，我们提出了VISLIX，一种新颖的视觉分析框架，利用最先进的基础模型帮助领域专家分析计算机视觉模型中的数据切片。我们的方法不需要图像元数据或视觉概念，可以自动生成自然语言见解，并允许用户交互式地测试数据切片假设。我们通过专家研究和三个案例研究评估了VISLIX，展示了该工具在验证目标检测模型方面提供全面见解的有效性。', 'title_zh': 'VISLIX：一种基于切片发现与分析的可解释性验证框架用于视觉模型'}
{'arxiv_id': 'arXiv:2505.03025', 'title': 'A Typology of Synthetic Datasets for Dialogue Processing in Clinical Contexts', 'authors': 'Steven Bedrick, A. Seza Doğruöz, Sergiu Nisioi', 'link': 'https://arxiv.org/abs/2505.03025', 'abstract': 'Synthetic data sets are used across linguistic domains and NLP tasks, particularly in scenarios where authentic data is limited (or even non-existent). One such domain is that of clinical (healthcare) contexts, where there exist significant and long-standing challenges (e.g., privacy, anonymization, and data governance) which have led to the development of an increasing number of synthetic datasets. One increasingly important category of clinical dataset is that of clinical dialogues which are especially sensitive and difficult to collect, and as such are commonly synthesized.\nWhile such synthetic datasets have been shown to be sufficient in some situations, little theory exists to inform how they may be best used and generalized to new applications. In this paper, we provide an overview of how synthetic datasets are created, evaluated and being used for dialogue related tasks in the medical domain. Additionally, we propose a novel typology for use in classifying types and degrees of data synthesis, to facilitate comparison and evaluation.', 'abstract_zh': '合成数据集在语言学领域和NLP任务中被广泛应用，特别是在真实数据有限（甚至不存在）的情况下。在临床（医疗保健）背景下尤其如此，该背景下存在显著且长期存在的挑战（例如隐私、匿名化和数据治理），导致了越来越多合成数据集的发展。其中一类日益重要的临床数据集是临床对话数据，这些数据尤其敏感且难以收集，因此通常需要合成。\n\n尽管合成数据集在某些情况下已显示出足够性，但目前尚缺乏理论来指导如何最好地使用它们并将它们应用于新的应用场景。本文提供了一个如何创建、评估和用于医疗领域对话相关任务的合成数据集的综述。此外，我们还提出了一种新的分类类型学，用于分类不同类型和程度的数据合成，以促进比较和评估。', 'title_zh': '合成数据集类型在临床对话处理中的应用'}
{'arxiv_id': 'arXiv:2505.02945', 'title': 'The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence', 'authors': 'Egil Diau', 'link': 'https://arxiv.org/abs/2505.02945', 'abstract': 'A key challenge in multi-agent AI is modeling social cooperation under realistic behavioral constraints. Many foundational concepts in economics and ethics such as "trust" or "morality" are often defined informally, without operational criteria or cognitive grounding, which limits their testability and implementation in artificial agents. Drawing on converging empirical evidence from primate behavior, infant cognition, and economic anthropology, we propose a conceptual framework composed of three cognitively minimal mechanisms: individual recognition, reciprocal credence, and cost return sensitivity. This framework reframes trust as a graded cognitive expectation, providing a simulateable basis for reciprocal exchange in artificial agents, and enabling the bottom-up emergence of scalable cooperation and institutional dynamics.', 'abstract_zh': '多-agent AI 中的一个关键挑战是，在现实行为约束下建模社会合作。经济学和伦理学中的许多基础概念，如“信任”或“道德”，通常被非正式地定义，缺乏可操作标准或认知基础，这限制了它们在人工代理中的测试和实施。借鉴来自灵长类行为、婴儿认知和经济人类学的趋同实证证据，我们提出了一种由三种认知最小机制组成的概念框架：个体识别、互惠信任和成本回报敏感性。该框架将信任重新定义为分级的认知期望，为人工代理中的互惠交换提供可模拟的基础，并促进大规模合作和制度动态的自下而上涌现。', 'title_zh': '经济交换的认知基础：基于行为证据的模块化框架'}
{'arxiv_id': 'arXiv:2505.02931', 'title': 'The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models', 'authors': 'Fernando Vallecillos Ruiz, Max Hort, Leon Moonen', 'link': 'https://arxiv.org/abs/2505.02931', 'abstract': 'Automatic program repair (APR) aims to reduce the manual efforts required to identify and fix errors in source code. Before the rise of LLM-based agents, a common strategy was to increase the number of generated patches, sometimes to the thousands, to achieve better repair results on benchmarks. More recently, self-iterative capabilities enabled LLMs to refine patches over multiple rounds guided by feedback. However, literature often focuses on many iterations and disregards different numbers of outputs.\nWe investigate an APR pipeline that balances these two approaches, the generation of multiple outputs and multiple rounds of iteration, while imposing a limit of 10 total patches per bug. We apply three SOTA instruction-tuned LLMs - DeepSeekCoder-Instruct, Codellama-Instruct, Llama3.1-Instruct - to the APR task. We further fine-tune each model on an APR dataset with three sizes (1K, 30K, 65K) and two techniques (Full Fine-Tuning and LoRA), allowing us to assess their repair capabilities on two APR benchmarks: HumanEval-Java and Defects4J.\nOur results show that by using only a fraction (<1%) of the fine-tuning dataset, we can achieve improvements of up to 78% in the number of plausible patches generated, challenging prior studies that reported limited gains using Full Fine-Tuning. However, we find that exceeding certain thresholds leads to diminishing outcomes, likely due to overfitting. Moreover, we show that base models greatly benefit from creating patches in an iterative fashion rather than generating them all at once. In addition, the benefit of iterative strategies becomes more pronounced in complex benchmarks. Even fine-tuned models, while benefiting less from iterations, still gain advantages, particularly on complex benchmarks. The research underscores the need for balanced APR strategies that combine multi-output generation and iterative refinement.', 'abstract_zh': '一种平衡多输出与多轮迭代的自动程序修复管道：限制每个错误最多生成10个补丁', 'title_zh': '修复的艺术：基于指令调优模型的迭代程序修复优化'}
{'arxiv_id': 'arXiv:2505.02889', 'title': 'Early Prediction of Sepsis: Feature-Aligned Transfer Learning', 'authors': 'Oyindolapo O. Komolafe, Zhimin Mei, David Morales Zarate, Gregory William Spangenberg', 'link': 'https://arxiv.org/abs/2505.02889', 'abstract': 'Sepsis is a life threatening medical condition that occurs when the body has an extreme response to infection, leading to widespread inflammation, organ failure, and potentially death. Because sepsis can worsen rapidly, early detection is critical to saving lives. However, current diagnostic methods often identify sepsis only after significant damage has already occurred. Our project aims to address this challenge by developing a machine learning based system to predict sepsis in its early stages, giving healthcare providers more time to intervene.\nA major problem with existing models is the wide variability in the patient information or features they use, such as heart rate, temperature, and lab results. This inconsistency makes models difficult to compare and limits their ability to work across different hospitals and settings. To solve this, we propose a method called Feature Aligned Transfer Learning (FATL), which identifies and focuses on the most important and commonly reported features across multiple studies, ensuring the model remains consistent and clinically relevant.\nMost existing models are trained on narrow patient groups, leading to population bias. FATL addresses this by combining knowledge from models trained on diverse populations, using a weighted approach that reflects each models contribution. This makes the system more generalizable and effective across different patient demographics and clinical environments. FATL offers a practical and scalable solution for early sepsis detection, particularly in hospitals with limited resources, and has the potential to improve patient outcomes, reduce healthcare costs, and support more equitable healthcare delivery.', 'abstract_zh': '脓毒症是一种生命威胁性的医疗状况，发生在身体对感染产生极端反应导致全身炎症、器官失败甚至死亡的情况下。由于脓毒症可能迅速恶化，早期检测至关重要。然而，现有的诊断方法通常只有在已经造成严重损害后才识别出脓毒症。我们的项目旨在通过开发基于机器学习的系统来预测脓毒症的早期阶段，从而给医疗提供者更多的时间进行干预，以减少死亡率。\n\n现有模型的一个主要问题是使用的病人信息或特征的广泛差异，例如心率、体温和实验室结果。这种差异性使得模型难以比较，并限制了它们在不同医院和环境中的适用性。为了解决这一问题，我们提出了一种称为特征对齐迁移学习（FATL）的方法，该方法识别并关注多个研究中最重要的和最常报告的特征，确保模型的一致性和临床相关性。\n\n大多数现有的模型仅针对狭窄的患者群体进行训练，导致群体偏差。FATL 通过结合来自不同人群训练模型的知识，采用加权方法反映每个模型的贡献，从而使系统在不同的患者群体和临床环境中更具普适性和有效性。FATL 提供了一种实用且可扩展的早期脓毒症检测解决方案，特别是在资源有限的医院，并具有提高患者预后、降低医疗成本和促进更公平的医疗服务的潜力。', 'title_zh': '早期预测败血症：特征对齐迁移学习'}
{'arxiv_id': 'arXiv:2505.02887', 'title': 'CreoPep: A Universal Deep Learning Framework for Target-Specific Peptide Design and Optimization', 'authors': 'Cheng Ge, Han-Shen Tae, Zhenqiang Zhang, Lu Lu, Zhijie Huang, Yilin Wang, Tao Jiang, Wenqing Cai, Shan Chang, David J. Adams, Rilei Yu', 'link': 'https://arxiv.org/abs/2505.02887', 'abstract': 'Target-specific peptides, such as conotoxins, exhibit exceptional binding affinity and selectivity toward ion channels and receptors. However, their therapeutic potential remains underutilized due to the limited diversity of natural variants and the labor-intensive nature of traditional optimization strategies. Here, we present CreoPep, a deep learning-based conditional generative framework that integrates masked language modeling with a progressive masking scheme to design high-affinity peptide mutants while uncovering novel structural motifs. CreoPep employs an integrative augmentation pipeline, combining FoldX-based energy screening with temperature-controlled multinomial sampling, to generate structurally and functionally diverse peptides that retain key pharmacological properties. We validate this approach by designing conotoxin inhibitors targeting the $\\alpha$7 nicotinic acetylcholine receptor, achieving submicromolar potency in electrophysiological assays. Structural analysis reveals that CreoPep-generated variants engage in both conserved and novel binding modes, including disulfide-deficient forms, thus expanding beyond conventional design paradigms. Overall, CreoPep offers a robust and generalizable platform that bridges computational peptide design with experimental validation, accelerating the discovery of next-generation peptide therapeutics.', 'abstract_zh': 'CreoPep：一种基于深度学习的条件生成框架，用于设计高亲和力肽突变体并揭示新型结构动机', 'title_zh': 'CreoPep: 一种针对特定靶点的深度学习通用框架及其肽设计与优化'}
{'arxiv_id': 'arXiv:2505.02886', 'title': 'Taskmaster Deconstructed: A Quantitative Look at Tension, Volatility, and Viewer Ratings', 'authors': 'David H. Silver', 'link': 'https://arxiv.org/abs/2505.02886', 'abstract': "Taskmaster is a British television show that combines comedic performance with a formal scoring system. Despite the appearance of structured competition, it remains unclear whether scoring dynamics contribute meaningfully to audience engagement. We conducted a statistical analysis of 162 episodes across 18 series, using fifteen episode-level metrics to quantify rank volatility, point spread, lead changes, and winner dominance. None of these metrics showed a significant association with IMDb ratings, even after controlling for series effects. Long-term trends suggest that average points have increased over time, while volatility has slightly declined and rank spread has remained stable. These patterns indicate an attempt to enhance competitive visibility without altering the show's structural equilibrium. We also analyzed contestant rank trajectories and identified five recurring archetypes describing performance styles. These patterns suggest that viewer interest is shaped more by contestant behavior than by game mechanics.", 'abstract_zh': 'Taskmaster是英国一档结合 Comedy 表演与正式评分系统的电视节目：评分动态是否对观众参与度产生实质性影响的统计分析', 'title_zh': '任务掌控者拆解：紧张感、波动性与观众评分的定量分析'}
{'arxiv_id': 'arXiv:2505.02877', 'title': 'A Wireless Collaborated Inference Acceleration Framework for Plant Disease Recognition', 'authors': 'Hele Zhu, Xinyi Huang, Haojia Gao, Mengfei Jiang, Haohua Que, Lei Mu', 'link': 'https://arxiv.org/abs/2505.02877', 'abstract': "Plant disease is a critical factor affecting agricultural production. Traditional manual recognition methods face significant drawbacks, including low accuracy, high costs, and inefficiency. Deep learning techniques have demonstrated significant benefits in identifying plant diseases, but they still face challenges such as inference delays and high energy consumption. Deep learning algorithms are difficult to run on resource-limited embedded devices. Offloading these models to cloud servers is confronted with the restriction of communication bandwidth, and all of these factors will influence the inference's efficiency. We propose a collaborative inference framework for recognizing plant diseases between edge devices and cloud servers to enhance inference speed. The DNN model for plant disease recognition is pruned through deep reinforcement learning to improve the inference speed and reduce energy consumption. Then the optimal split point is determined by a greedy strategy to achieve the best collaborated inference acceleration. Finally, the system for collaborative inference acceleration in plant disease recognition has been implemented using Gradio to facilitate friendly human-machine interaction. Experiments indicate that the proposed collaborative inference framework significantly increases inference speed while maintaining acceptable recognition accuracy, offering a novel solution for rapidly diagnosing and preventing plant diseases.", 'abstract_zh': '植物病害是影响农业生产的关键因素。传统的手动识别方法面临低准确性、高成本和低效率等重大缺陷。深度学习技术在识别植物病害方面显示出显著优势，但仍面临推理延迟和高能耗等挑战。深度学习算法难以在资源受限的嵌入式设备上运行。将这些模型卸载到云服务器上则受限于通信带宽，所有这些因素都会影响推理的效率。我们提出了一种边缘设备与云服务器之间的协作推理框架，以增强推理速度。通过深度强化学习对植物病害识别的DNN模型进行剪枝，以提高推理速度和降低能耗。然后通过贪婪策略确定最优分拆点，以实现最佳协作推理加速。最后，我们使用Gradio实现了植物病害识别的协作推理加速系统，便于友好的人机交互。实验表明，所提协作推理框架在保持可接受识别准确性的前提下显著提高了推理速度，提供了快速诊断和预防植物病害的新型解决方案。', 'title_zh': '一种用于植物病害识别的无线协作推理加速框架'}
{'arxiv_id': 'arXiv:2505.02874', 'title': 'Uncertainty Quantification for Machine Learning in Healthcare: A Survey', 'authors': 'L. Julián Lechuga López, Shaza Elsharief, Dhiyaa Al Jorf, Firas Darwish, Congbo Ma, Farah E. Shamout', 'link': 'https://arxiv.org/abs/2505.02874', 'abstract': 'Uncertainty Quantification (UQ) is pivotal in enhancing the robustness, reliability, and interpretability of Machine Learning (ML) systems for healthcare, optimizing resources and improving patient care. Despite the emergence of ML-based clinical decision support tools, the lack of principled quantification of uncertainty in ML models remains a major challenge. Current reviews have a narrow focus on analyzing the state-of-the-art UQ in specific healthcare domains without systematically evaluating method efficacy across different stages of model development, and despite a growing body of research, its implementation in healthcare applications remains limited. Therefore, in this survey, we provide a comprehensive analysis of current UQ in healthcare, offering an informed framework that highlights how different methods can be integrated into each stage of the ML pipeline including data processing, training and evaluation. We also highlight the most popular methods used in healthcare and novel approaches from other domains that hold potential for future adoption in the medical context. We expect this study will provide a clear overview of the challenges and opportunities of implementing UQ in the ML pipeline for healthcare, guiding researchers and practitioners in selecting suitable techniques to enhance the reliability, safety and trust from patients and clinicians on ML-driven healthcare solutions.', 'abstract_zh': '不确定性量化（UQ）在提高医疗保健领域机器学习（ML）系统的稳健性、可靠性和可解释性方面至关重要，有助于优化资源并提高患者护理质量。尽管出现了基于ML的临床决策支持工具，但在ML模型中进行原则性的不确定性量化仍然是一个主要挑战。现有综述主要专注于具体医疗领域中最先进的UQ分析，而未系统评估不同模型开发阶段的方法有效性，尽管已有大量研究，但在医疗应用中的实施仍然有限。因此，在本文综述中，我们对当前医疗领域的不确定性量化进行全面分析，提供一个指导框架，展示不同方法如何集成到机器学习管道的每个阶段，包括数据处理、训练和评估。我们还强调在医疗领域最常用的方法以及来自其他领域的新颖方法，并指出其在未来医疗应用中的潜在采用价值。我们期望本研究能为在机器学习管道中实施不确定性量化提供清晰的概述，指导研究人员和实践者选择合适的techniques以增强ML驱动医疗解决方案的可靠性、安全性和信任度。', 'title_zh': '医疗领域机器学习中不确定性量化：一个综述'}
{'arxiv_id': 'arXiv:2505.02863', 'title': "Understanding University Students' Use of Generative AI: The Roles of Demographics and Personality Traits", 'authors': 'Newnew Deng, Edward Jiusi Liu, Xiaoming Zhai', 'link': 'https://arxiv.org/abs/2505.02863', 'abstract': "The use of generative AI (GAI) among university students is rapidly increasing, yet empirical research on students' GAI use and the factors influencing it remains limited. To address this gap, we surveyed 363 undergraduate and graduate students in the United States, examining their GAI usage and how it relates to demographic variables and personality traits based on the Big Five model (i.e., extraversion, agreeableness, conscientiousness, and emotional stability, and intellect/imagination). Our findings reveal: (a) Students in higher academic years are more inclined to use GAI and prefer it over traditional resources. (b) Non-native English speakers use and adopt GAI more readily than native speakers. (c) Compared to White, Asian students report higher GAI usage, perceive greater academic benefits, and express a stronger preference for it. Similarly, Black students report a more positive impact of GAI on their academic performance. Personality traits also play a significant role in shaping perceptions and usage of GAI. After controlling demographic factors, we found that personality still significantly predicts GAI use and attitudes: (a) Students with higher conscientiousness use GAI less. (b) Students who are higher in agreeableness perceive a less positive impact of GAI on academic performance and express more ethical concerns about using it for academic work. (c) Students with higher emotional stability report a more positive impact of GAI on learning and fewer concerns about its academic use. (d) Students with higher extraversion show a stronger preference for GAI over traditional resources. (e) Students with higher intellect/imagination tend to prefer traditional resources. These insights highlight the need for universities to provide personalized guidance to ensure students use GAI effectively, ethically, and equitably in their academic pursuits.", 'abstract_zh': '大学学生中生成式人工智能（GAI）的使用迅速增加，然而关于学生GAI使用及其影响因素的经验研究仍较为有限。为弥补这一空白，我们对美国363名本科生和研究生进行了调查，探讨了他们的GAI使用情况及其与人口统计学变量和基于五大人格特征模型的个性特质（即外向性、宜人性、尽责性、情绪稳定性和智力/想象力）的关系。研究发现：（a）高年级学生更倾向于使用GAI，并更偏好GAI而非传统资源。（b）非英语母语者比英语母语者更快速地使用和接受GAI。（c）与白人相比，亚裔学生报告了更高的GAI使用频率、更显著的学业益处以及更强的偏好。同样，黑人学生报告了GAI对学业成绩更积极的影响。个性特质也显著影响着对GAI的感知和使用。在控制了人口统计学因素后，我们发现个性仍然显著预测GAI的使用和态度：（a）更尽责的学生使用GAI较少。（b）更宜人的学生认为GAI对学业表现的影响较少积极，并对将其用于学术工作时的伦理问题表达了更多担忧。（c）更情绪稳定的学生报告了GAI对学习的更积极影响以及对其学术使用时的更少担忧。（d）更外向的学生对GAI比传统资源表现出了更强的偏好。（e）更高智力/想象力的学生倾向于偏好传统资源。这些洞察突显了大学需要提供个性化指导，以确保学生能够有效地、伦理地和公平地在学术追求中使用GAI。', 'title_zh': '理解大学学生使用生成式AI的作用：人口统计学特征和人格特质的角色'}
{'arxiv_id': 'arXiv:2505.02861', 'title': 'Neural Orchestration for Multi-Agent Systems: A Deep Learning Framework for Optimal Agent Selection in Multi-Domain Task Environments', 'authors': 'Kushagra Agrawal, Nisharg Nargund', 'link': 'https://arxiv.org/abs/2505.02861', 'abstract': 'Multi-agent systems (MAS) are foundational in simulating complex real-world scenarios involving autonomous, interacting entities. However, traditional MAS architectures often suffer from rigid coordination mechanisms and difficulty adapting to dynamic tasks. We propose MetaOrch, a neural orchestration framework for optimal agent selection in multi-domain task environments. Our system implements a supervised learning approach that models task context, agent histories, and expected response quality to select the most appropriate agent for each task. A novel fuzzy evaluation module scores agent responses along completeness, relevance, and confidence dimensions, generating soft supervision labels for training the orchestrator. Unlike previous methods that hard-code agent-task mappings, MetaOrch dynamically predicts the most suitable agent while estimating selection confidence. Experiments in simulated environments with heterogeneous agents demonstrate that our approach achieves 86.3% selection accuracy, significantly outperforming baseline strategies including random selection and round-robin scheduling. The modular architecture emphasizes extensibility, allowing agents to be registered, updated, and queried independently. Results suggest that neural orchestration offers a powerful approach to enhancing the autonomy, interpretability, and adaptability of multi-agent systems across diverse task domains.', 'abstract_zh': '元编排：多域任务环境中的神经优化代理选择框架', 'title_zh': '多域任务环境中的多代理系统神经编排：深度学习框架下的最优代理选择'}
{'arxiv_id': 'arXiv:2505.02856', 'title': 'AI Education in a Mirror: Challenges Faced by Academic and Industry Experts', 'authors': 'Mahir Akgun, Hadi Hosseini', 'link': 'https://arxiv.org/abs/2505.02856', 'abstract': 'As Artificial Intelligence (AI) technologies continue to evolve, the gap between academic AI education and real-world industry challenges remains an important area of investigation. This study provides preliminary insights into challenges AI professionals encounter in both academia and industry, based on semi-structured interviews with 14 AI experts - eight from industry and six from academia. We identify key challenges related to data quality and availability, model scalability, practical constraints, user behavior, and explainability. While both groups experience data and model adaptation difficulties, industry professionals more frequently highlight deployment constraints, resource limitations, and external dependencies, whereas academics emphasize theoretical adaptation and standardization issues. These exploratory findings suggest that AI curricula could better integrate real-world complexities, software engineering principles, and interdisciplinary learning, while recognizing the broader educational goals of building foundational and ethical reasoning skills.', 'abstract_zh': '随着人工智能（AI）技术的不断发展，学术AI教育与现实工业挑战之间的差距仍是值得深入研究的重要领域。本研究基于对14名AI专家的半结构化访谈（其中8人来自行业，6人来自学术界）提供了一些初步见解，探讨了AI专业人士在学术界和工业界面临的挑战。我们识别出与数据质量与可用性、模型可扩展性、实际约束、用户行为以及解释性相关的关键挑战。尽管两组人都经历了数据和模型适应的困难，但行业专业人士更频繁地强调部署约束、资源限制和外部依赖性，而学术界人士则更强调理论适应和标准化问题。这些探索性发现表明，AI课程应更好地融合现实世界的复杂性、软件工程原则以及跨学科学习，同时认识到更广泛的教育目标是培养基础性和伦理推理能力。', 'title_zh': '镜中的AI教育：学术与产业专家面临的挑战'}
{'arxiv_id': 'arXiv:2505.02854', 'title': 'Ensuring Reproducibility in Generative AI Systems for General Use Cases: A Framework for Regression Testing and Open Datasets', 'authors': 'Masumi Morishige, Ryo Koshihara', 'link': 'https://arxiv.org/abs/2505.02854', 'abstract': 'Reproducibility and reliability remain pressing challenges for generative AI systems whose behavior can drift with each model update or prompt revision. We introduce GPR-bench, a lightweight, extensible benchmark that operationalizes regression testing for general purpose use cases. GPR-bench couples an open, bilingual (English and Japanese) dataset covering eight task categories (e.g., text generation, code generation, and information retrieval) and 10 scenarios in each task categories (80 total test cases for each language) with an automated evaluation pipeline that employs "LLM-as-a-Judge" scoring of correctness and conciseness. Experiments across three recent model versions - gpt-4o-mini, o3-mini, and o4-mini - and two prompt configurations (default versus concise-writing instruction) reveal heterogeneous quality. Our results show that newer models generally improve correctness, but the differences are modest and not statistically significant, suggesting that GPR-bench may not be sufficiently challenging to differentiate between recent model versions. In contrast, the concise-writing instruction significantly enhances conciseness (+12.37 pp, Mann-Whitney U test: p < 0.001, effect size r = 0.2995) with minimal degradations on accuracy (-1.7 pp), demonstrating the effectiveness of prompt engineering. Released under the MIT License, GPR- bench lowers the barrier to initiating reproducibility monitoring and provides a foundation for community-driven extensions, while also raising important considerations about benchmark design for rapidly evolving language models.', 'abstract_zh': '生成式AI系统的重现性和可靠性仍然是紧迫的挑战，其行为可能会随着每次模型更新或提示修改而发生偏移。我们介绍了GPR-bench，这是一种轻量级、可扩展的基准测试工具，将回归测试应用于通用用途场景。GPR-bench 结合了一个包含八种任务类别（例如文本生成、代码生成和信息检索）的开放双语（英语和日语）数据集，每个任务类别中有10种场景（每种语言共有80个测试用例），以及一个自动评分管道，该管道采用“语言模型作为评判者”来评估正确性和简洁性。在三个最近模型版本（gpt-4o-mini、o3-mini和o4-mini）和两种提示配置（默认提示与简洁写作指令）下进行的实验揭示了不同的质量水平。结果显示，较新的模型通常提高了正确性，但差异不大且不具备统计显著性，表明GPR-bench可能不足以区分最近的模型版本。相比之下，简洁写作指令显著提高了简洁性（+12.37个百分点，曼-惠特尼U检验：p<0.001，效应大小r=0.2995），同时对准确性的影响较小（-1.7个百分点），这表明提示工程的有效性。GPR-bench在MIT许可证下发布，降低了开始重现性监控的门槛，并为社区驱动的扩展提供了基础，同时也引发了关于快速演化的语言模型基准设计的重要考虑。', 'title_zh': '确保通用场景下生成式AI系统可再现性：一种回归测试和开源数据集框架'}
{'arxiv_id': 'arXiv:2505.02853', 'title': 'A Computational Model of Inclusive Pedagogy: From Understanding to Application', 'authors': 'Francesco Balzan, Pedro P. Santos, Maurizio Gabbrielli, Mahault Albarracin, Manuel Lopes', 'link': 'https://arxiv.org/abs/2505.02853', 'abstract': 'Human education transcends mere knowledge transfer, it relies on co-adaptation dynamics -- the mutual adjustment of teaching and learning strategies between agents. Despite its centrality, computational models of co-adaptive teacher-student interactions (T-SI) remain underdeveloped. We argue that this gap impedes Educational Science in testing and scaling contextual insights across diverse settings, and limits the potential of Machine Learning systems, which struggle to emulate and adaptively support human learning processes. To address this, we present a computational T-SI model that integrates contextual insights on human education into a testable framework. We use the model to evaluate diverse T-SI strategies in a realistic synthetic classroom setting, simulating student groups with unequal access to sensory information. Results show that strategies incorporating co-adaptation principles (e.g., bidirectional agency) outperform unilateral approaches (i.e., where only the teacher or the student is active), improving the learning outcomes for all learning types. Beyond the testing and scaling of context-dependent educational insights, our model enables hypothesis generation in controlled yet adaptable environments. This work bridges non-computational theories of human education with scalable, inclusive AI in Education systems, providing a foundation for equitable technologies that dynamically adapt to learner needs.', 'abstract_zh': '人类教育超越了单纯的知识传递，它依赖于共适应动力学——教与学策略之间的相互调整。尽管共适应教师-学生互动(T-SI)在其中心地位，计算模型的研究仍有待发展。我们主张这一空白阻碍了教育科学在不同情境中测试和扩展洞察力，并限制了机器学习系统的能力，后者难以模拟和适应性支持人类学习过程。为解决这一问题，我们提出了一种计算T-SI模型，将人类教育的环境洞见整合到可测试的框架中。我们使用该模型在现实合成教室环境中评估多样化的T-SI策略，模拟具有不同感官信息访问权限的学生群体。结果表明，包含共适应原则（如双向自主）的策略优于单向方法（即仅教师或学生活跃），从而改善了各种学习类型的学习成果。除了测试和扩展情境依赖性教育洞察力之外，该模型还使人们能够在可控且可适应的环境中生成假设。本研究将非计算的人类教育理论与可扩展且包容性的教育人工智能系统相结合，为动态适应学习者需求的公平技术奠定了基础。', 'title_zh': '包容性教学计算模型：从理解到应用'}
{'arxiv_id': 'arXiv:2505.02846', 'title': 'The Precautionary Principle and the Innovation Principle: Incompatible Guides for AI Innovation Governance?', 'authors': 'Kim Kaivanto', 'link': 'https://arxiv.org/abs/2505.02846', 'abstract': 'In policy debates concerning the governance and regulation of Artificial Intelligence (AI), both the Precautionary Principle (PP) and the Innovation Principle (IP) are advocated by their respective interest groups. Do these principles offer wholly incompatible and contradictory guidance? Does one necessarily negate the other? I argue here that provided attention is restricted to weak-form PP and IP, the answer to both of these questions is "No." The essence of these weak formulations is the requirement to fully account for type-I error costs arising from erroneously preventing the innovation\'s diffusion through society (i.e. mistaken regulatory red-lighting) as well as the type-II error costs arising from erroneously allowing the innovation to diffuse through society (i.e. mistaken regulatory green-lighting). Within the Signal Detection Theory (SDT) model developed here, weak-PP red-light (weak-IP green-light) determinations are optimal for sufficiently small (large) ratios of expected type-I to type-II error costs. For intermediate expected cost ratios, an amber-light \'wait-and-monitor\' policy is optimal. Regulatory sandbox instruments allow AI testing and experimentation to take place within a structured environment of limited duration and societal scale, whereby the expected cost ratio falls within the \'wait-and-monitor\' range. Through sandboxing regulators and innovating firms learn more about the expected cost ratio, and what respective adaptations -- of regulation, of technical solution, of business model, or combination thereof, if any -- are needed to keep the ratio out of the weak-PP red-light zone.', 'abstract_zh': '人工智能治理和监管政策辩论中 precautionary principle 和 innovation principle 的兼容性探究', 'title_zh': '预防原则与创新原则：AI创新治理的矛盾向导？'}
{'arxiv_id': 'arXiv:2505.02843', 'title': 'Physical foundations for trustworthy medical imaging: a review for artificial intelligence researchers', 'authors': 'Miriam Cobo, David Corral Fontecha, Wilson Silva, Lara Lloret Iglesias', 'link': 'https://arxiv.org/abs/2505.02843', 'abstract': 'Artificial intelligence in medical imaging has seen unprecedented growth in the last years, due to rapid advances in deep learning and computing resources. Applications cover the full range of existing medical imaging modalities, with unique characteristics driven by the physics of each technique. Yet, artificial intelligence professionals entering the field, and even experienced developers, often lack a comprehensive understanding of the physical principles underlying medical image acquisition, which hinders their ability to fully leverage its potential. The integration of physics knowledge into artificial intelligence algorithms enhances their trustworthiness and robustness in medical imaging, especially in scenarios with limited data availability. In this work, we review the fundamentals of physics in medical images and their impact on the latest advances in artificial intelligence, particularly, in generative models and reconstruction algorithms. Finally, we explore the integration of physics knowledge into physics-inspired machine learning models, which leverage physics-based constraints to enhance the learning of medical imaging features.', 'abstract_zh': '医学影像中的人工智能在过去几年由于深度学习和计算资源的快速进步取得了前所未有的增长。应用涵盖了所有现有的医学影像模态，每种技术的独特特性由其物理原理驱动。然而，进入该领域的AI专业人士，甚至是经验丰富的开发人员，往往缺乏对医学影像获取物理原理的全面理解，这限制了他们充分发挥其潜力的能力。将物理知识整合到人工智能算法中，可以增强其在医学影像中的可信度和稳健性，特别是在数据有限的情况下。在本文中，我们回顾了医学影像中物理原理的基本知识及其对最新人工智能进展的影响，特别是生成模型和重建算法。最后，我们探讨了将物理知识整合到基于物理原理的机器学习模型中，利用基于物理的约束条件来增强医学影像特征的学习。', 'title_zh': '可信赖医疗成像的物理基础：人工智能研究者的综述'}
{'arxiv_id': 'arXiv:2505.02841', 'title': 'Snakemaker: Seamlessly transforming ad-hoc analyses into sustainable Snakemake workflows with generative AI', 'authors': 'Marco Masera, Alessandro Leone, Johannes Köster, Ivan Molineris', 'link': 'https://arxiv.org/abs/2505.02841', 'abstract': 'Reproducibility and sustainability present significant challenges in bioinformatics software development, where rapidly evolving tools and complex workflows often result in short-lived or difficult-to-adapt pipelines. This paper introduces Snakemaker, a tool that leverages generative AI to facilitate researchers build sustainable data analysis pipelines by converting unstructured code into well-defined Snakemake workflows. Snakemaker non-invasively tracks the work performed in the terminal by the researcher, analyzes execution patterns, and generates Snakemake workflows that can be integrated into existing pipelines. Snakemaker also supports the transformation of monolithic Ipython Notebooks into modular Snakemake pipelines, resolving the global state of the notebook into discrete, file-based interactions between rules. An integrated chat assistant provides users with fine-grained control through natural language instructions. Snakemaker generates high-quality Snakemake workflows by adhering to the best practices, including Conda environment tracking, generic rule generation and loop unrolling. By lowering the barrier between prototype and production-quality code, Snakemaker addresses a critical gap in computational reproducibility for bioinformatics research.', 'abstract_zh': '生物信息学软件开发中的可重复性和可持续性挑战显著，快速发展的工具和复杂的 workflows 通常导致短暂或难以适应的管道。本文介绍了 Snakemaker，一种利用生成式 AI 的工具，帮助研究人员通过将无结构代码转换为定义清晰的 Snakemake 工作流来构建可持续的数据分析管道。Snakemaker 非侵入性地跟踪研究人员在终端中完成的工作，分析执行模式，并生成可以集成到现有管道中的 Snakemake 工作流。Snakemaker 还支持将庞大的 IPython 笔记本转换为模块化的 Snakemake 管道，将笔记本的全局状态分解为离散的、基于文件的规则之间的交互。集成的聊天助手通过自然语言指令为用户提供精细控制。Snakemaker 通过遵守最佳实践（包括 Conda 环境跟踪、通用规则生成和循环展开），生成高质量的 Snakemake 工作流。通过降低从原型到生产质量代码的障碍，Snakemaker 解决了生物信息学研究中计算可重复性的一个关键缺口。', 'title_zh': 'Snakemaker: 使用生成式人工智能无缝将临时分析转换为可持续的Snakemake工作流'}
