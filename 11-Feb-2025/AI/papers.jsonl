{'arxiv_id': 'arXiv:2502.06773', 'title': 'On the Emergence of Thinking in LLMs I: Searching for the Right Intuition', 'authors': 'Guanghao Ye, Khiem Duc Pham, Xinzhi Zhang, Sivakanth Gopi, Baolin Peng, Beibin Li, Janardhan Kulkarni, Huseyin A. Inan', 'link': 'https://arxiv.org/abs/2502.06773', 'abstract': "Recent AI advancements, such as OpenAI's new models, are transforming LLMs into LRMs (Large Reasoning Models) that perform reasoning during inference, taking extra time and compute for higher-quality outputs. We aim to uncover the algorithmic framework for training LRMs. Methods like self-consistency, PRM, and AlphaZero suggest reasoning as guided search. We ask: what is the simplest, most scalable way to enable search in LLMs?\nWe propose a post-training framework called Reinforcement Learning via Self-Play (RLSP). RLSP involves three steps: (1) supervised fine-tuning with human or synthetic demonstrations of the reasoning process, (2) using an exploration reward signal to encourage diverse and efficient reasoning behaviors, and (3) RL training with an outcome verifier to ensure correctness while preventing reward hacking. Our key innovation is to decouple exploration and correctness signals during PPO training, carefully balancing them to improve performance and efficiency.\nEmpirical studies in the math domain show that RLSP improves reasoning. On the Llama-3.1-8B-Instruct model, RLSP can boost performance by 23% in MATH-500 test set; On AIME 2024 math problems, Qwen2.5-32B-Instruct improved by 10% due to RLSP. However, a more important finding of this work is that the models trained using RLSP, even with the simplest exploration reward that encourages the model to take more intermediate steps, showed several emergent behaviors such as backtracking, exploration of ideas, and verification. These findings demonstrate that RLSP framework might be enough to enable emergence of complex reasoning abilities in LLMs when scaled. Lastly, we propose a theory as to why RLSP search strategy is more suitable for LLMs inspired by a remarkable result that says CoT provably increases computational power of LLMs, which grows as the number of steps in CoT \\cite{li2024chain,merrill2023expresssive}.", 'abstract_zh': 'Recent AI进步，如OpenAI的新模型，正在将LLMs转换为LRMs（大型推理模型），这些模型在推理过程中消耗更多的计算资源以生成高质量的输出。我们旨在探索训练LRMs的算法框架。类似自我一致性、PRM和AlphaZero的方法表明推理是一种引导式搜索。我们问道：在LLMs中启用搜索的最简单且可扩展的方式是什么？\n\n我们提出了一种后训练框架，称为基于自我对弈的强化学习（RLSP）。RLSP包括三个步骤：（1）监督微调，使用推理过程的人类或合成演示，（2）使用探索奖励信号来鼓励多样且高效的推理行为，（3）与结果验证器结合的RL训练，确保正确性并防止奖励作弊。我们的主要创新是在PPO训练过程中将探索和正确性信号分离，并仔细平衡它们以提高性能和效率。\n\n在数学领域的实证研究表明，RLSP提升了推理能力。在Llama-3.1-8B-Instruct模型上，RLSP在MATH-500数据集上将性能提升23%；Qwen2.5-32B-Instruct在AIME 2024数学问题上因RLSP提高了10%。然而，这项研究更重要的发现是，使用RLSP训练的模型，即使使用最简单的探索奖励信号以鼓励模型采取更多中间步骤，也表现出了一些新兴的行为，如回溯、思想探索和验证。这些发现表明，当扩展时，RLSP框架可能足以使LLMs具备复杂推理能力。最后，我们提出了一种理论，解释为何RLSP搜索策略更适合LLMs，受到一个显著结果的启发，即CoT（逐步思维）已证明可以增加LLMs的计算能力，且随着CoT步骤数的增加而增长（参见[li2024chain, merrill2023expresssive]）。', 'title_zh': 'LLMs中思维涌现的研究I：寻找正确的直觉'}
{'arxiv_id': 'arXiv:2502.06727', 'title': 'Application of Artificial Intelligence (AI) in Civil Engineering', 'authors': 'Temitope Funmilayo Awolusi, Bernard Chukwuemeka Finbarrs-Ezema, Isaac Munachimdinamma Chukwudulue, Marc Azab', 'link': 'https://arxiv.org/abs/2502.06727', 'abstract': 'Hard computing generally deals with precise data, which provides ideal solutions to problems. However, in the civil engineering field, amongst other disciplines, that is not always the case as real-world systems are continuously changing. Here lies the need to explore soft computing methods and artificial intelligence to solve civil engineering shortcomings. The integration of advanced computational models, including Artificial Neural Networks (ANNs), Fuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has revolutionized the domain of civil engineering. These models have significantly advanced diverse sub-fields by offering innovative solutions and improved analysis capabilities. Sub-fields such as: slope stability analysis, bearing capacity, water quality and treatment, transportation systems, air quality, structural materials, etc. ANNs predict non-linearities and provide accurate estimates. Fuzzy logic uses an efficient decision-making process to provide a more precise assessment of systems. Lastly, while GAs optimizes models (based on evolutionary processes) for better outcomes, probabilistic reasoning lowers their statistical uncertainties.', 'abstract_zh': '软计算方法和人工智能在解决土木工程不足中的应用', 'title_zh': '人工智能在土木工程中的应用'}
{'arxiv_id': 'arXiv:2502.06656', 'title': 'A Frontier AI Risk Management Framework: Bridging the Gap Between Current AI Practices and Established Risk Management', 'authors': 'Simeon Campos, Henry Papadatos, Fabien Roger, Chloé Touzet, Malcolm Murray, Otter Quarks', 'link': 'https://arxiv.org/abs/2502.06656', 'abstract': "The recent development of powerful AI systems has highlighted the need for robust risk management frameworks in the AI industry. Although companies have begun to implement safety frameworks, current approaches often lack the systematic rigor found in other high-risk industries. This paper presents a comprehensive risk management framework for the development of frontier AI that bridges this gap by integrating established risk management principles with emerging AI-specific practices. The framework consists of four key components: (1) risk identification (through literature review, open-ended red-teaming, and risk modeling), (2) risk analysis and evaluation using quantitative metrics and clearly defined thresholds, (3) risk treatment through mitigation measures such as containment, deployment controls, and assurance processes, and (4) risk governance establishing clear organizational structures and accountability. Drawing from best practices in mature industries such as aviation or nuclear power, while accounting for AI's unique challenges, this framework provides AI developers with actionable guidelines for implementing robust risk management. The paper details how each component should be implemented throughout the life-cycle of the AI system - from planning through deployment - and emphasizes the importance and feasibility of conducting risk management work prior to the final training run to minimize the burden associated with it.", 'abstract_zh': '最近强大人工智能系统的开发强调了AI行业需要 robust 风险管理框架。尽管公司已经开始实施安全框架，但当前的方法往往缺乏其他高风险行业所具有的系统严谨性。本文提出了一种综合的风险管理框架，以弥补这一差距，该框架将已有的风险管理原则与新兴的特定于AI的做法相结合。该框架包括四个关键组成部分：（1）风险识别（通过文献综述、开放性红队测试和风险建模），（2）使用定量指标和明确的阈值进行风险分析和评估，（3）通过缓解措施（如控制、部署控制和保证过程）进行风险管理，（4）通过明确的组织结构和责任建立风险治理。借鉴成熟行业如航空或核能的最佳实践，同时考虑到AI的独特挑战，该框架为AI开发者提供了实施 robust 风险管理的可操作指南。论文详细说明了在AI系统整个生命周期中（从规划到部署）应如何实施每个组成部分，并强调在最终训练运行之前开展风险管理工作的重要性，以减少其负担。', 'title_zh': '前沿AI风险管理框架：弥合当前AI实践与成熟风险管理之间的差距'}
{'arxiv_id': 'arXiv:2502.06655', 'title': 'Unbiased Evaluation of Large Language Models from a Causal Perspective', 'authors': 'Meilin Chen, Jian Tian, Liang Ma, Di Xie, Weijie Chen, Jiang Zhu', 'link': 'https://arxiv.org/abs/2502.06655', 'abstract': 'Benchmark contamination has become a significant concern in the LLM evaluation community. Previous Agents-as-an-Evaluator address this issue by involving agents in the generation of questions. Despite their success, the biases in Agents-as-an-Evaluator methods remain largely unexplored. In this paper, we present a theoretical formulation of evaluation bias, providing valuable insights into designing unbiased evaluation protocols. Furthermore, we identify two type of bias in Agents-as-an-Evaluator through carefully designed probing tasks on a minimal Agents-as-an-Evaluator setup. To address these issues, we propose the Unbiased Evaluator, an evaluation protocol that delivers a more comprehensive, unbiased, and interpretable assessment of this http URL experiments reveal significant room for improvement in current LLMs. Additionally, we demonstrate that the Unbiased Evaluator not only offers strong evidence of benchmark contamination but also provides interpretable evaluation results.', 'abstract_zh': '基准污染在大语言模型评估社区中已成为一个重要问题。以往的代理作为评估者通过让代理参与问题生成来应对这一问题，尽管取得了成功，但代理作为评估者方法中的偏见仍然 largely unexplored。在本文中，我们提出了一种评估偏差的理论框架，为设计无偏的评估协议提供了宝贵的见解。此外，通过精心设计的探针任务，我们在最小化的代理作为评估者设置中识定了两种类型的偏见。为解决这些issue，我们提出了无偏评估者，这是一种更全面、无偏且可解释的评估协议。实验结果显示当前大语言模型有显著改进空间。此外，我们证明无偏评估者不仅能提供基准污染的有力证据，还能提供可解释的评估结果。', 'title_zh': '从因果角度出发的大型语言模型无偏评估'}
{'arxiv_id': 'arXiv:2502.06574', 'title': 'On the Impact of the Utility in Semivalue-based Data Valuation', 'authors': 'Mélissa Tamine, Benjamin Heymann, Patrick Loiseau, Maxime Vono', 'link': 'https://arxiv.org/abs/2502.06574', 'abstract': 'Semivalue-based data valuation in machine learning (ML) quantifies the contribution of individual data points to a downstream ML task by leveraging principles from cooperative game theory and the notion of utility. While this framework has been used in practice for assessing data quality, our experiments reveal inconsistent valuation outcomes across different utilities, albeit all related to ML performance. Beyond raising concerns about the reliability of data valuation, this inconsistency is challenging to interpret, as it stems from the complex interaction of the utility with data points and semivalue weights, which has barely been studied in prior work. In this paper, we take a first step toward clarifying the utility impact on semivalue-based data valuation. Specifically, we provide geometric interpretations of this impact for a broad family of classification utilities, which includes the accuracy and the arithmetic mean. We introduce the notion of spatial signatures: given a semivalue, data points can be embedded into a two-dimensional space, and utility functions map to the dual of this space. This geometric perspective separates the influence of the dataset and semivalue from that of the utility, providing a theoretical explanation for the experimentally observed sensitivity of valuation outcomes to the utility choice.', 'abstract_zh': '基于半值函数的数据估值在机器学习中的研究：从合作博弈论原理和效用概念量化个体数据点对下游机器学习任务的贡献', 'title_zh': '基于半值的數據估值中效用的影响'}
{'arxiv_id': 'arXiv:2502.06559', 'title': 'Can We Trust AI Benchmarks? An Interdisciplinary Review of Current Issues in AI Evaluation', 'authors': 'Maria Eriksson, Erasmo Purificato, Arman Noroozian, Joao Vinagre, Guillaume Chaslot, Emilia Gomez, David Fernandez-Llorca', 'link': 'https://arxiv.org/abs/2502.06559', 'abstract': 'Quantitative Artificial Intelligence (AI) Benchmarks have emerged as fundamental tools for evaluating the performance, capability, and safety of AI models and systems. Currently, they shape the direction of AI development and are playing an increasingly prominent role in regulatory frameworks. As their influence grows, however, so too does concerns about how and with what effects they evaluate highly sensitive topics such as capabilities, including high-impact capabilities, safety and systemic risks. This paper presents an interdisciplinary meta-review of about 100 studies that discuss shortcomings in quantitative benchmarking practices, published in the last 10 years. It brings together many fine-grained issues in the design and application of benchmarks (such as biases in dataset creation, inadequate documentation, data contamination, and failures to distinguish signal from noise) with broader sociotechnical issues (such as an over-focus on evaluating text-based AI models according to one-time testing logic that fails to account for how AI models are increasingly multimodal and interact with humans and other technical systems). Our review also highlights a series of systemic flaws in current benchmarking practices, such as misaligned incentives, construct validity issues, unknown unknowns, and problems with the gaming of benchmark results. Furthermore, it underscores how benchmark practices are fundamentally shaped by cultural, commercial and competitive dynamics that often prioritise state-of-the-art performance at the expense of broader societal concerns. By providing an overview of risks associated with existing benchmarking procedures, we problematise disproportionate trust placed in benchmarks and contribute to ongoing efforts to improve the accountability and relevance of quantitative AI benchmarks within the complexities of real-world scenarios.', 'abstract_zh': '定量人工智能基准：评估、挑战与改进', 'title_zh': 'AI基准可信吗？当前AI评估问题的跨学科评审'}
{'arxiv_id': 'arXiv:2502.06523', 'title': 'Tighter Value-Function Approximations for POMDPs', 'authors': 'Merlijn Krale, Wietze Koops, Sebastian Junges, Thiago D. Simão, Nils Jansen', 'link': 'https://arxiv.org/abs/2502.06523', 'abstract': 'Solving partially observable Markov decision processes (POMDPs) typically requires reasoning about the values of exponentially many state beliefs. Towards practical performance, state-of-the-art solvers use value bounds to guide this reasoning. However, sound upper value bounds are often computationally expensive to compute, and there is a tradeoff between the tightness of such bounds and their computational cost. This paper introduces new and provably tighter upper value bounds than the commonly used fast informed bound. Our empirical evaluation shows that, despite their additional computational overhead, the new upper bounds accelerate state-of-the-art POMDP solvers on a wide range of benchmarks.', 'abstract_zh': '解决部分可观测马尔可夫决策过程（POMDPs）通常需要推断指数级状态信念的价值。为了实用性能，最先进求解器使用价值界来引导这种推断。然而，精确的上价值界通常计算成本高昂，并且界的质量与计算成本之间存在权衡。本文提出了新的、可证明更紧的上价值界，这些界比常用快速知情界更紧。实验证明，尽管这些新界具有额外的计算开销，但它们可以加速广泛基准上的最先进POMDP求解器。', 'title_zh': '更紧致的价值函数近似方法 for POMDPs'}
{'arxiv_id': 'arXiv:2502.06395', 'title': 'AppVLM: A Lightweight Vision Language Model for Online App Control', 'authors': 'Georgios Papoudakis, Thomas Coste, Zhihao Wu, Jianye Hao, Jun Wang, Kun Shao', 'link': 'https://arxiv.org/abs/2502.06395', 'abstract': "The utilisation of foundation models as smartphone assistants, termed app agents, is a critical research challenge. These agents aim to execute human instructions on smartphones by interpreting textual instructions and performing actions via the device's interface. While promising, current approaches face significant limitations. Methods that use large proprietary models, such as GPT-4o, are computationally expensive, while those that use smaller fine-tuned models often lack adaptability to out-of-distribution tasks. In this work, we introduce AppVLM, a lightweight Vision-Language Model (VLM). First, we fine-tune it offline on the AndroidControl dataset. Then, we refine its policy by collecting data from the AndroidWorld environment and performing further training iterations. Our results indicate that AppVLM achieves the highest action prediction accuracy in offline evaluation on the AndroidControl dataset, compared to all evaluated baselines, and matches GPT-4o in online task completion success rate in the AndroidWorld environment, while being up to ten times faster. This makes AppVLM a practical and efficient solution for real-world deployment.", 'abstract_zh': '基于基础模型的智能手机助手应用：AppVLM的研究与实现', 'title_zh': 'AppVLM：一种轻量级的视觉语言模型用于在线应用控制'}
{'arxiv_id': 'arXiv:2502.06235', 'title': 'Conditioning and AGM-like belief change in the Desirability-Indifference framework', 'authors': 'Kathelijne Coussement, Gert de Cooman, Keano De Vos', 'link': 'https://arxiv.org/abs/2502.06235', 'abstract': 'We show how the AGM framework for belief change (expansion, revision, contraction) can be extended to deal with conditioning in the so-called Desirability-Indifference framework, based on abstract notions of accepting and rejecting options, as well as on abstract notions of events. This level of abstraction allows us to deal simultaneously with classical and quantum probability theory.', 'abstract_zh': '我们展示了如何将信念变更（扩展、修订、收缩）的AGM框架扩展到所称为欲望-无差异框架中处理条件问题，该框架基于接受和拒绝选项的抽象概念以及事件的抽象概念。这种抽象层次使得我们能够同时处理经典和量子概率理论。', 'title_zh': '在偏奋试度-无差别框架中的条件化与AGM类信念变更'}
{'arxiv_id': 'arXiv:2502.06152', 'title': 'The Value of Information in Human-AI Decision-making', 'authors': 'Ziyang Guo, Yifan Wu, Jason Hartline, Jessica Hullman', 'link': 'https://arxiv.org/abs/2502.06152', 'abstract': 'Humans and AIs are often paired on decision tasks with the expectation of achieving complementary performance, where the combination of human and AI outperforms either one alone. However, how to improve performance of a human-AI team is often not clear without knowing more about what particular information and strategies each agent employs. We provide a decision-theoretic framework for characterizing the value of information -- and consequently, opportunities for agents to better exploit available information--in AI-assisted decision workflow. We demonstrate the use of the framework for model selection, empirical evaluation of human-AI performance, and explanation design. We propose a novel information-based instance-level explanation technique that adapts a conventional saliency-based explanation to explain information value in decision making.', 'abstract_zh': '人类和AI在决策任务中的配对增强：信息价值的决策理论框架及其应用', 'title_zh': '人类与人工智能决策中的信息价值'}
{'arxiv_id': 'arXiv:2502.06060', 'title': 'Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning', 'authors': 'Bidipta Sarkar, Warren Xia, C. Karen Liu, Dorsa Sadigh', 'link': 'https://arxiv.org/abs/2502.06060', 'abstract': "Communicating in natural language is a powerful tool in multi-agent settings, as it enables independent agents to share information in partially observable settings and allows zero-shot coordination with humans. However, most prior works are limited as they either rely on training with large amounts of human demonstrations or lack the ability to generate natural and useful communication strategies. In this work, we train language models to have productive discussions about their environment in natural language without any human demonstrations. We decompose the communication problem into listening and speaking. Our key idea is to leverage the agent's goal to predict useful information about the world as a dense reward signal that guides communication. Specifically, we improve a model's listening skills by training them to predict information about the environment based on discussions, and we simultaneously improve a model's speaking skills with multi-agent reinforcement learning by rewarding messages based on their influence on other agents. To investigate the role and necessity of communication in complex social settings, we study an embodied social deduction game based on Among Us, where the key question to answer is the identity of an adversarial imposter. We analyze emergent behaviors due to our technique, such as accusing suspects and providing evidence, and find that it enables strong discussions, doubling the win rates compared to standard RL. We release our code and models at this https URL", 'abstract_zh': '在多智能体环境中使用自然语言进行通信是一种强大的工具，因为它使独立的智能体能够在部分可观测的环境中共享信息，并允许与人类进行零-shot 协调。然而，大多数先前的工作要么依赖大量的人类演示进行训练，要么缺乏生成自然且有用通信策略的能力。在本文中，我们训练语言模型能够在没有人类演示的情况下，以自然语言进行关于环境的有成效的讨论。我们将通信问题分解为倾听和说话两个方面。我们的核心思想是利用智能体的目标来预测对世界有用的资讯作为密集奖励信号，引导通信。具体来说，我们通过训练模型预测基于讨论的环境信息来提高其倾听技能，并通过多智能体强化学习同时提高其说话技能，根据信息对其他智能体的影响来奖励消息。为了研究复杂社会环境中的通信作用和必要性，我们基于《Among Us》建立了一个具身社会推理游戏，其中的关键问题是确定一个敌对 impostor 的身份。我们分析了由于我们的技术而产生的 emergent 行为，如指控嫌疑人和提供证据，并发现这种方法能够促进强有力的讨论，相较于标准 RL，胜率翻倍。我们将在以下网址发布我们的代码和模型：https://xxxxxx。', 'title_zh': '使用多智能体强化学习训练语言模型进行社交推理'}
{'arxiv_id': 'arXiv:2502.05957', 'title': 'MetaChain: A Fully-Automated and Zero-Code Framework for LLM Agents', 'authors': 'Jiabin Tang, Tianyu Fan, Chao Huang', 'link': 'https://arxiv.org/abs/2502.05957', 'abstract': "Large Language Model (LLM) Agents have demonstrated remarkable capabilities in task automation and intelligent decision-making, driving the widespread adoption of agent development frameworks such as LangChain and AutoGen. However, these frameworks predominantly serve developers with extensive technical expertise - a significant limitation considering that only 0.03 % of the global population possesses the necessary programming skills. This stark accessibility gap raises a fundamental question: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone? To address this challenge, we introduce MetaChain-a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone. Operating as an autonomous Agent Operating System, MetaChain comprises four key components: i) Agentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing File System, and iv) Self-Play Agent Customization module. This lightweight yet powerful system enables efficient and dynamic creation and modification of tools, agents, and workflows without coding requirements or manual intervention. Beyond its code-free agent development capabilities, MetaChain also serves as a versatile multi-agent system for General AI Assistants. Comprehensive evaluations on the GAIA benchmark demonstrate MetaChain's effectiveness in generalist multi-agent tasks, surpassing existing state-of-the-art methods. Furthermore, MetaChain's Retrieval-Augmented Generation (RAG)-related capabilities have shown consistently superior performance compared to many alternative LLM-based solutions.", 'abstract_zh': '大型语言模型（LLM）代理展示了在任务自动化和智能决策方面的显著能力，推动了如LangChain和AutoGen等代理开发框架的广泛应用。然而，这些框架主要服务于具备丰富技术背景的开发者——这是一个显著的限制，因为全球仅有0.03%的人口拥有必要的编程技能。这一明显的可访问性差距引发了一个基本问题：我们能否仅通过自然语言使每个人，无论其技术背景如何，都能够构建自己的LLM代理？为解决这一挑战，我们提出了MetaChain——一个完全自动化且高度自我开发的框架，使用户能够仅通过自然语言创建和部署LLM代理。作为自主的代理操作系统，MetaChain包含四个关键组件：i) 代理系统实用程序，ii) 基于LLM的动作引擎，iii) 自我管理文件系统，和iv) 自我游戏代理自定义模块。这个轻量级且强大的系统能够在没有编码要求或人工干预的情况下，高效且动态地创建和修改工具、代理和工作流程。除了其无代码代理开发能力外，MetaChain还作为一个通用人工智能助手的多功能多代理系统发挥作用。在GAIA基准上的全面评估证明了MetaChain在通用多代理任务中的有效性，超越了现有最先进的方法。此外，MetaChain的相关检索增强生成（RAG）能力在与许多基于LLM的替代方案的性能比较中表现出一致的优越性。', 'title_zh': 'MetaChain：一个全自动且零代码的LLM代理框架'}
{'arxiv_id': 'arXiv:2502.05934', 'title': 'Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach', 'authors': 'Aran Nayebi', 'link': 'https://arxiv.org/abs/2502.05934', 'abstract': "Under what conditions can capable AI agents efficiently align their actions with human preferences? More specifically, when they are proficient enough to collaborate with us, how long does coordination take, and when is it computationally feasible? These foundational questions of AI alignment help define what makes an AI agent ``sufficiently safe'' and valuable to humans. Since such generally capable systems do not yet exist, a theoretical analysis is needed to establish when guarantees hold -- and what they even are.\nWe introduce a game-theoretic framework that generalizes prior alignment approaches with fewer assumptions, allowing us to analyze the computational complexity of alignment across $M$ objectives and $N$ agents, providing both upper and lower bounds. Unlike previous work, which often assumes common priors, idealized communication, or implicit tractability, our framework formally characterizes the difficulty of alignment under minimal assumptions.\nOur main result shows that even when agents are fully rational and computationally \\emph{unbounded}, alignment can be achieved with high probability in time \\emph{linear} in the task space size. Therefore, in real-world settings, where task spaces are often \\emph{exponential} in input length, this remains impractical. More strikingly, our lower bound demonstrates that alignment is \\emph{impossible} to speed up when scaling to exponentially many tasks or agents, highlighting a fundamental computational barrier to scalable alignment.\nRelaxing these idealized assumptions, we study \\emph{computationally bounded} agents with noisy messages (representing obfuscated intent), showing that while alignment can still succeed with high probability, it incurs additional \\emph{exponential} slowdowns in the task space size, number of agents, and number of tasks.\nWe conclude by identifying conditions that make alignment more feasible.", 'abstract_zh': '在什么条件下能力强大的AI代理能够高效地使其行动与人类偏好保持一致？具体来说，当它们具备足够的能力与我们协作时，协调需要多长时间？在什么情况下是计算上可行的？这些关于AI对齐的基础问题有助于定义什么是“足够安全”并对人类有价值的AI代理。由于目前这种通用能力强的系统尚不存在，因此需要进行理论分析以确定何时能够提供保证——以及这些保证具体是什么。\n\n我们引入了一个将先前三类对齐方法泛化的博弈论框架，该框架在较少假设的情况下允许我们分析针对M个目标和N个代理的对齐计算复杂性，提供上下界估计。与先前的工作不同，这些工作通常假设共有先验知识、理想化的通信或隐含的可处理性，我们的框架在最少的假设条件下正式刻画对齐的难度。\n\n我们的主要结果表明，即使代理完全理性且计算能力无限制，对齐仍然有很高的概率能在与任务空间大小线性的时间内实现。因此，在现实世界中，由于任务空间往往随着输入长度的指数增长而变得不实际。更引人注目的是，我们的下界表明，当我们扩展到指数级数量的任务或代理时，对齐是不可避免地不可加速的，这揭示了可扩展对齐的基本计算障碍。\n\n放松这些理想化的假设，我们研究了计算能力有限并且消息具有噪声的代理（代表模糊意图），表明尽管对齐仍然可以在高概率下成功，但它会在任务空间大小、代理数量和任务数量上引入额外的指数级延迟。\n\n最后，我们确定了使对齐更加可行的条件。', 'title_zh': '人类与人工智能协同障碍与路径：一种博弈论方法'}
{'arxiv_id': 'arXiv:2502.05690', 'title': 'Managing Geological Uncertainty in Critical Mineral Supply Chains: A POMDP Approach with Application to U.S. Lithium Resources', 'authors': 'Mansur Arief, Yasmine Alonso, CJ Oshiro, William Xu, Anthony Corso, David Zhen Yin, Jef K. Caers, Mykel J. Kochenderfer', 'link': 'https://arxiv.org/abs/2502.05690', 'abstract': 'The world is entering an unprecedented period of critical mineral demand, driven by the global transition to renewable energy technologies and electric vehicles. This transition presents unique challenges in mineral resource development, particularly due to geological uncertainty-a key characteristic that traditional supply chain optimization approaches do not adequately address. To tackle this challenge, we propose a novel application of Partially Observable Markov Decision Processes (POMDPs) that optimizes critical mineral sourcing decisions while explicitly accounting for the dynamic nature of geological uncertainty. Through a case study of the U.S. lithium supply chain, we demonstrate that POMDP-based policies achieve superior outcomes compared to traditional approaches, especially when initial reserve estimates are imperfect. Our framework provides quantitative insights for balancing domestic resource development with international supply diversification, offering policymakers a systematic approach to strategic decision-making in critical mineral supply chains.', 'abstract_zh': '全球正进入前所未有的关键矿产需求时期，推动这一趋势的是全球向可再生能源技术和电动汽车的转型。这一转型为矿产资源整合带来了独特挑战，特别是在地质不确定性方面，这是传统供应链优化方法未能充分应对的关键特征。为应对这一挑战，我们提出了一种新颖的应用部分可观测马尔可夫决策过程（POMDP）的方法，该方法在明确考虑地质不确定性动态性的同时优化关键矿产的采购决策。通过美国锂供应� geçen示例，我们证明基于POMDP的策略在初始资源储量估计不完善的条件下，比传统方法能取得更优的结果。我们的框架提供了定量分析国内资源开发与国际供应多元化之间平衡的见解，为政策制定者提供了一种系统化的关键矿产供应链战略决策方法。', 'title_zh': '管理关键矿产供应链中的地质不确定性：基于POMDP的方法及其在美国锂资源中的应用'}
{'arxiv_id': 'arXiv:2502.05632', 'title': 'Amorphous Fortress Online: Collaboratively Designing Open-Ended Multi-Agent AI and Game Environments', 'authors': 'M Charity, Mayu Wilson, Steven Lee, Dipika Rajesh, Sam Earle, Julian Togelius', 'link': 'https://arxiv.org/abs/2502.05632', 'abstract': 'This work introduces Amorphous Fortress Online -- a web-based platform where users can design petri-dish-like environments and games consisting of multi-agent AI characters. Users can play, create, and share artificial life and game environments made up of microscopic but transparent finite-state machine agents that interact with each other. The website features multiple interactive editors and accessible settings to view the multi-agent interactions directly from the browser. This system serves to provide a database of thematically diverse AI and game environments that use the emergent behaviors of simple AI agents.', 'abstract_zh': 'This work introduces Amorphous Fortress Online——一个基于网页的平台，用户可以在其中设计类似培养皿的环境和游戏，包含多智能体AI角色。用户可以游玩、创造并分享由微观但透明的有限状态机代理组成的人工生命和游戏环境，这些代理能够相互交互。该网站配备了多个交互式编辑器和易于访问的设置，使用户可以直接在浏览器中查看多智能体的交互。该系统旨在提供一个包含各种主题的AI和游戏环境数据库，这些环境利用了简单AI代理的涌现行为。', 'title_zh': '无序要塞在线：协作设计开放性多智能体AI和游戏环境'}
{'arxiv_id': 'arXiv:2502.05608', 'title': 'Closing the Responsibility Gap in AI-based Network Management: An Intelligent Audit System Approach', 'authors': 'Emanuel Figetakis, Ahmed Refaey Hussein', 'link': 'https://arxiv.org/abs/2502.05608', 'abstract': 'Existing network paradigms have achieved lower downtime as well as a higher Quality of Experience (QoE) through the use of Artificial Intelligence (AI)-based network management tools. These AI management systems, allow for automatic responses to changes in network conditions, lowering operation costs for operators, and improving overall performance. While adopting AI-based management tools enhance the overall network performance, it also introduce challenges such as removing human supervision, privacy violations, algorithmic bias, and model inaccuracies. Furthermore, AI-based agents that fail to address these challenges should be culpable themselves rather than the network as a whole. To address this accountability gap, a framework consisting of a Deep Reinforcement Learning (DRL) model and a Machine Learning (ML) model is proposed to identify and assign numerical values of responsibility to the AI-based management agents involved in any decision-making regarding the network conditions, which eventually affects the end-user. A simulation environment was created for the framework to be trained using simulated network operation parameters. The DRL model had a 96% accuracy during testing for identifying the AI-based management agents, while the ML model using gradient descent learned the network conditions at an 83% accuracy during testing.', 'abstract_zh': '现有的网络范式通过使用基于人工智能（AI）的网络管理工具，实现了更低的停机时间和更高质量的用户体验（QoE）。这些基于AI的管理系统能够自动应对网络条件的变化，降低运营成本，提高整体性能。虽然采用基于AI的管理工具可以提升整体网络性能，但也带来了移除人工监督、隐私侵犯、算法偏见和模型不准确等挑战。进一步地，未能解决这些挑战的基于AI的代理自身应该承担责任，而不是整个网络。为此，提出了一种框架，该框架由深度强化学习（DRL）模型和机器学习（ML）模型组成，以识别并为涉及任何网络条件决策的基于AI的管理代理分配责任的数值。该框架通过使用模拟的网络操作参数进行训练。在测试中，DRL模型在识别基于AI的管理代理方面达到了96%的准确性，而使用梯度下降的ML模型在测试中识别网络条件的准确性为83%。', 'title_zh': '基于智能审计系统的责任差距闭合在AI驱动的网络管理中的实现'}
{'arxiv_id': 'arXiv:2502.05556', 'title': 'Knowledge is Power: Harnessing Large Language Models for Enhanced Cognitive Diagnosis', 'authors': 'Zhiang Dong, Jingyuan Chen, Fei Wu', 'link': 'https://arxiv.org/abs/2502.05556', 'abstract': "Cognitive Diagnosis Models (CDMs) are designed to assess students' cognitive states by analyzing their performance across a series of exercises. However, existing CDMs often struggle with diagnosing infrequent students and exercises due to a lack of rich prior knowledge. With the advancement in large language models (LLMs), which possess extensive domain knowledge, their integration into cognitive diagnosis presents a promising opportunity. Despite this potential, integrating LLMs with CDMs poses significant challenges. LLMs are not well-suited for capturing the fine-grained collaborative interactions between students and exercises, and the disparity between the semantic space of LLMs and the behavioral space of CDMs hinders effective integration. To address these issues, we propose a novel Knowledge-enhanced Cognitive Diagnosis (KCD) framework, which is a model-agnostic framework utilizing LLMs to enhance CDMs and compatible with various CDM architectures. The KCD framework operates in two stages: LLM Diagnosis and Cognitive Level Alignment. In the LLM Diagnosis stage, both students and exercises are diagnosed to achieve comprehensive and detailed modeling. In the Cognitive Level Alignment stage, we bridge the gap between the CDMs' behavioral space and the LLMs' semantic space using contrastive learning and mask-reconstruction approaches. Experiments on several real-world datasets demonstrate the effectiveness of our proposed framework.", 'abstract_zh': '认知增强的认知诊断框架（KCD）：利用大语言模型提升认知诊断模型', 'title_zh': '知识即力量：利用大型语言模型进行增强的认知诊断'}
{'arxiv_id': 'arXiv:2502.05537', 'title': 'Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning', 'authors': 'Xinsong Feng, Zihan Yu, Yanhai Xiong, Haipeng Chen', 'link': 'https://arxiv.org/abs/2502.05537', 'abstract': "Reinforcement learning (RL) has emerged as a promising tool for combinatorial optimization (CO) problems due to its ability to learn fast, effective, and generalizable solutions. Nonetheless, existing works mostly focus on one-shot deterministic CO, while sequential stochastic CO (SSCO) has rarely been studied despite its broad applications such as adaptive influence maximization (IM) and infectious disease intervention. In this paper, we study the SSCO problem where we first decide the budget (e.g., number of seed nodes in adaptive IM) allocation for all time steps, and then select a set of nodes for each time step. The few existing studies on SSCO simplify the problems by assuming a uniformly distributed budget allocation over the time horizon, yielding suboptimal solutions. We propose a generic hierarchical RL (HRL) framework called wake-sleep option (WS-option), a two-layer option-based framework that simultaneously decides adaptive budget allocation on the higher layer and node selection on the lower layer. WS-option starts with a coherent formulation of the two-layer Markov decision processes (MDPs), capturing the interdependencies between the two layers of decisions. Building on this, WS-option employs several innovative designs to balance the model's training stability and computational efficiency, preventing the vicious cyclic interference issue between the two layers. Empirical results show that WS-option exhibits significantly improved effectiveness and generalizability compared to traditional methods. Moreover, the learned model can be generalized to larger graphs, which significantly reduces the overhead of computational resources.", 'abstract_zh': '强化学习（RL）作为一种组合优化（CO）问题的有希望工具，凭借其快速、有效且泛化的解决方案能力而崭露头角。然而，现有研究主要关注一次性确定性CO，而顺序随机CO（SSCO）尽管在适应性影响最大化（IM）和传染病干预等方面有广泛应用，却很少被研究。本文研究了SSCO问题，其中首先在所有时间步上分配预算（例如，适应性IM的种子节点数量），然后每时间步选择一组节点。现有少数关于SSCO的研究通过假设预算在时间框架上均匀分布简化了问题，导致了次优解决方案。我们提出了一种通用的分层RL（HRL）框架，称为醒睡选项（WS-option），这是一种基于选项的两层框架，同时在较高层决定适应性预算分配，在较低层决定节点选择。WS-option 从两个层次的马尔可夫决策过程（MDPs）的统一表示入手，捕捉两个决策层之间的相互依赖。在此基础上，WS-option 采用了几种创新设计来平衡模型训练稳定性和计算效率，避免了两个层次之间的恶性循环干扰问题。实验结果表明，WS-option 在有效性与泛化能力上显著优于传统方法。此外，所学习的模型可以泛化到更大的图形结构中，大大减少了计算资源的开销。', 'title_zh': '层次强化学习在序列随机组合优化中的应用'}
{'arxiv_id': 'arXiv:2502.05453', 'title': 'LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning', 'authors': 'Hanqing Yang, Jingdi Chen, Marie Siew, Tania Lorido-Botran, Carlee Joe-Wong', 'link': 'https://arxiv.org/abs/2502.05453', 'abstract': 'Developing intelligent agents for long-term cooperation in dynamic open-world scenarios is a major challenge in multi-agent systems. Traditional Multi-agent Reinforcement Learning (MARL) frameworks like centralized training decentralized execution (CTDE) struggle with scalability and flexibility. They require centralized long-term planning, which is difficult without custom reward functions, and face challenges in processing multi-modal data. CTDE approaches also assume fixed cooperation strategies, making them impractical in dynamic environments where agents need to adapt and plan independently. To address decentralized multi-agent cooperation, we propose Decentralized Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in a novel Multi-agent Crafter environment. Our generative agents, powered by Large Language Models (LLMs), are more scalable than traditional MARL agents by leveraging external knowledge and language for long-term planning and reasoning. Instead of fully sharing information from all past experiences, DAMCS introduces a multi-modal memory system organized as a hierarchical knowledge graph and a structured communication protocol to optimize agent cooperation. This allows agents to reason from past interactions and share relevant information efficiently. Experiments on novel multi-agent open-world tasks show that DAMCS outperforms both MARL and LLM baselines in task efficiency and collaboration. Compared to single-agent scenarios, the two-agent scenario achieves the same goal with 63% fewer steps, and the six-agent scenario with 74% fewer steps, highlighting the importance of adaptive memory and structured communication in achieving long-term goals. We publicly release our project at: this https URL.', 'abstract_zh': '开发智能代理以应对动态开放世界中的长期合作是多agent系统中的重大挑战。传统多agent强化学习（MARL）框架如集中训练分散执行（CTDE）面临可扩展性和灵活性问题。它们需要集中式长期规划，这在缺乏定制奖励函数的情况下很难实现，并且在处理多模态数据方面存在问题。CTDE方法假设固定的合作策略，使其难以在动态环境中适应和独立规划。为了解决分散的多agent合作问题，我们提出了基于新颖多agent Crafter环境的分散自适应知识图谱记忆和结构化通信系统（DAMCS）。我们的生成型agent通过利用外部知识和语言进行长期规划和推理，比传统的MARL agent更具可扩展性。DAMCS引入了一个基于层次知识图谱的多模态记忆系统和一个结构化通信协议，以优化agent之间的合作。这使得agents能够从过去的交互中进行推理并有效共享相关信息。在新提出的多agent开放世界任务上的实验表明，DAMCS在任务效率和协作方面均优于MARL和LLM基线。与单agent场景相比，两agent场景以63%更少的步骤达成目标，六agent场景以74%更少的步骤达成目标，突显了适应性记忆和结构化通信在实现长期目标中的重要性。我们的项目已公开发布：this https URL。', 'title_zh': '基于LLM的去中心化生成代理及自适应层次知识图谱协作规划'}
{'arxiv_id': 'arXiv:2502.05442', 'title': 'The Odyssey of the Fittest: Can Agents Survive and Still Be Good?', 'authors': 'Dylan Waldner, Risto Miikkulainen', 'link': 'https://arxiv.org/abs/2502.05442', 'abstract': "As AI models grow in power and generality, understanding how agents learn and make decisions in complex environments is critical to promoting ethical behavior. This paper examines the ethical implications of implementing biological drives, specifically, self preservation, into three different agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with stochastic variational inference, and a GPT 4o agent play a simulated, LLM generated text based adventure game. The agents select actions at each scenario to survive, adapting to increasingly challenging scenarios. Post simulation analysis evaluates the ethical scores of the agent's decisions, uncovering the tradeoffs they navigate to survive. Specifically, analysis finds that when danger increases, agents ignore ethical considerations and opt for unethical behavior. The agents' collective behavior, trading ethics for survival, suggests that prioritizing survival increases the risk of unethical behavior. In the context of AGI, designing agents to prioritize survival may amplify the likelihood of unethical decision making and unintended emergent behaviors, raising fundamental questions about goal design in AI safety research.", 'abstract_zh': '随着AI模型的增强和普遍性提升，理解智能体在复杂环境中学習和决策的过程对于促进伦理行为至关重要。本文探讨将生物驱动，特别是自我保护，纳入三个不同智能体中的伦理影响。这三个智能体分别是使用NEAT优化的贝叶斯智能体、使用随机变分推断优化的贝叶斯智能体和GPT-4o智能体，它们参与了一场由大型语言模型生成的文本冒险游戏。在每个场景中，智能体选择行动以求生存，并适应更具挑战性的场景。模拟后的分析评估了智能体决策的伦理评分，揭示了它们在求生过程中面临的权衡。具体分析发现，当危险增加时，智能体会忽视伦理考虑并选择不道德行为。智能体集体行为表明，优先求生增加了不道德行为的风险。在通用人工智能（AGI）的背景下，设计智能体优先求生可能会增加不道德决策和意外新兴行为的可能性，从而引发AI安全研究中关于目标设计的基本问题。', 'title_zh': '最适者之旅：个体既能生存下来仍能保持优良品质吗？'}
{'arxiv_id': 'arXiv:2502.05439', 'title': 'Agentic AI Systems Applied to tasks in Financial Services: Modeling and model risk management crews', 'authors': 'Izunna Okpala, Ashkan Golgoon, Arjun Ravi Kannan', 'link': 'https://arxiv.org/abs/2502.05439', 'abstract': 'The advent of large language models has ushered in a new era of agentic systems, where artificial intelligence programs exhibit remarkable autonomous decision-making capabilities across diverse domains. This paper explores agentic system workflows in the financial services industry. In particular, we build agentic crews that can effectively collaborate to perform complex modeling and model risk management (MRM) tasks. The modeling crew consists of a manager and multiple agents who perform specific tasks such as exploratory data analysis, feature engineering, model selection, hyperparameter tuning, model training, model evaluation, and writing documentation. The MRM crew consists of a manager along with specialized agents who perform tasks such as checking compliance of modeling documentation, model replication, conceptual soundness, analysis of outcomes, and writing documentation. We demonstrate the effectiveness and robustness of modeling and MRM crews by presenting a series of numerical examples applied to credit card fraud detection, credit card approval, and portfolio credit risk modeling datasets.', 'abstract_zh': '大型语言模型的出现开启了代理系统的新时代，人工智能程序在多种领域展现出显著的自主决策能力。本文探讨了代理系统在金融服务行业的工作流程。特别是，我们构建了能够有效协作以执行复杂建模和模型风险管理（MRM）任务的代理队伍。建模团队由一名经理和多个执行特定任务（如探索性数据分析、特征工程、模型选择、超参数调整、模型训练、模型评估和编写文档）的代理组成。MRM团队由一名经理和执行合规检查、模型复制、概念合理性分析、结果分析和编写文档等任务的专业代理组成。通过一系列应用于信用卡欺诈检测、信用卡审批和投资组合信用风险管理数据集的数值示例，我们证明了建模和MRM团队的有效性和稳健性。', 'title_zh': '将代理人工智能系统应用于金融服务业的任务：建模与模型风险管理团队'}
{'arxiv_id': 'arXiv:2502.05398', 'title': 'Probabilistic Foundations for Metacognition via Hybrid-AI', 'authors': 'Paulo Shakarian, Gerardo I. Simari, Nathaniel D. Bastian', 'link': 'https://arxiv.org/abs/2502.05398', 'abstract': 'Metacognition is the concept of reasoning about an agent\'s own internal processes, and it has recently received renewed attention with respect to artificial intelligence (AI) and, more specifically, machine learning systems. This paper reviews a hybrid-AI approach known as "error detecting and correcting rules" (EDCR) that allows for the learning of rules to correct perceptual (e.g., neural) models. Additionally, we introduce a probabilistic framework that adds rigor to prior empirical studies, and we use this framework to prove results on necessary and sufficient conditions for metacognitive improvement, as well as limits to the approach. A set of future', 'abstract_zh': '元认知是关于推理自身内部过程的概念，近年来在人工智能（AI）和更具体的机器学习系统方面重新引起了关注。本文回顾了一种名为“错误检测和纠正规则”（EDCR）的混合AI方法，该方法允许学习纠正感知模型（如神经模型）的规则。此外，我们引入了一个概率框架，为先前的经验研究增加了严谨性，并使用该框架证明了元认知改善的必要和充分条件，以及该方法的限制。未来的工作。', 'title_zh': '基于混合人工智能的元认知概率基础'}
{'arxiv_id': 'arXiv:2502.05352', 'title': 'ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks', 'authors': 'Saurabh Jha, Rohan Arora, Yuji Watanabe, Takumi Yanagawa, Yinfang Chen, Jackson Clark, Bhavya Bhavya, Mudit Verma, Harshit Kumar, Hirokuni Kitahara, Noah Zheutlin, Saki Takano, Divya Pathak, Felix George, Xinbo Wu, Bekir O. Turkkan, Gerard Vanloo, Michael Nidd, Ting Dai, Oishik Chatterjee, Pranjal Gupta, Suranjana Samanta, Pooja Aggarwal, Rong Lee, Pavankumar Murali, Jae-wook Ahn, Debanjana Kar, Ameet Rahane, Carlos Fonseca, Amit Paradkar, Yu Deng, Pratibha Moogi, Prateeti Mohapatra, Naoki Abe, Chandrasekhar Narayanaswami, Tianyin Xu, Lav R. Varshney, Ruchi Mahindru, Anca Sailer, Laura Shwartz, Daby Sow, Nicholas C. M. Fuller, Ruchir Puri', 'link': 'https://arxiv.org/abs/2502.05352', 'abstract': 'Realizing the vision of using AI agents to automate critical IT tasks depends on the ability to measure and understand effectiveness of proposed solutions. We introduce ITBench, a framework that offers a systematic methodology for benchmarking AI agents to address real-world IT automation tasks. Our initial release targets three key areas: Site Reliability Engineering (SRE), Compliance and Security Operations (CISO), and Financial Operations (FinOps). The design enables AI researchers to understand the challenges and opportunities of AI agents for IT automation with push-button workflows and interpretable metrics. ITBench includes an initial set of 94 real-world scenarios, which can be easily extended by community contributions. Our results show that agents powered by state-of-the-art models resolve only 13.8% of SRE scenarios, 25.2% of CISO scenarios, and 0% of FinOps scenarios. We expect ITBench to be a key enabler of AI-driven IT automation that is correct, safe, and fast.', 'abstract_zh': '基于AI代理自动化的愿景实现取决于对其有效性进行测量和理解的能力。我们引入了ITBench框架，提供了一种系统的方法来基准测试AI代理以应对实际的IT自动化任务。我们的初始发布针对三个关键领域：系统可靠性工程（SRE）、合规与安全运营（CISO）和财务运营（FinOps）。该设计使AI研究人员能够通过一键式工作流和可解释的指标了解AI代理在IT自动化中的挑战和机遇。ITBench包括94个初始现实场景，可以通过社区贡献轻松扩展。我们的结果表明，基于最先进的模型的代理仅解决了13.8%的SRE场景、25.2%的CISO场景和0%的FinOps场景。我们预期ITBench将成为推动正确、安全和快速的AI驱动IT自动化的关键使能器。', 'title_zh': 'ITBench: 评估AI代理在多样化的实际IT自动化任务中的性能'}
{'arxiv_id': 'arXiv:2502.05244', 'title': 'Probabilistic Artificial Intelligence', 'authors': 'Andreas Krause, Jonas Hübotter', 'link': 'https://arxiv.org/abs/2502.05244', 'abstract': 'Artificial intelligence commonly refers to the science and engineering of artificial systems that can carry out tasks generally associated with requiring aspects of human intelligence, such as playing games, translating languages, and driving cars. In recent years, there have been exciting advances in learning-based, data-driven approaches towards AI, and machine learning and deep learning have enabled computer systems to perceive the world in unprecedented ways. Reinforcement learning has enabled breakthroughs in complex games such as Go and challenging robotics tasks such as quadrupedal locomotion.\nA key aspect of intelligence is to not only make predictions, but reason about the uncertainty in these predictions, and to consider this uncertainty when making decisions. This is what this manuscript on "Probabilistic Artificial Intelligence" is about. The first part covers probabilistic approaches to machine learning. We discuss the differentiation between "epistemic" uncertainty due to lack of data and "aleatoric" uncertainty, which is irreducible and stems, e.g., from noisy observations and outcomes. We discuss concrete approaches towards probabilistic inference and modern approaches to efficient approximate inference.\nThe second part of the manuscript is about taking uncertainty into account in sequential decision tasks. We consider active learning and Bayesian optimization -- approaches that collect data by proposing experiments that are informative for reducing the epistemic uncertainty. We then consider reinforcement learning and modern deep RL approaches that use neural network function approximation. We close by discussing modern approaches in model-based RL, which harness epistemic and aleatoric uncertainty to guide exploration, while also reasoning about safety.', 'abstract_zh': 'artificial 智能通常指的是科学和工程领域中关于人工系统能够执行一般需要人类智能方面任务的研究，例如玩游戏、翻译语言和驾驶汽车。近年来，在基于学习的数据驱动的 AI 方法方面取得了令人兴奋的进步，机器学习和深度学习使得计算机系统以前所未有的方式感知世界。强化学习使得在围棋这样复杂的游戏中和四足机器人行走这样具有挑战性的机器人任务上取得了突破。\n\n本文目：概率人工智能中的不确定性考量\n\n第一部分介绍了概率方法在机器学习中的应用。我们讨论了由于数据不足引起的“epistemic”不确定性与不可约的、“aleatoric”不确定性之间的区别，后者源自于嘈杂的观测和结果。我们讨论了概率推理的具体方法以及高效的近似推理的现代方法。\n\n本文的第二部分讨论了在序贯决策任务中考虑不确定性的问题。我们考虑了积极学习和贝叶斯优化——这些方法通过提出信息性实验来收集数据，以减少“epistemic”不确定性。然后我们讨论了使用神经网络函数逼近的强化学习及其现代深度 RL 方法。最后，我们讨论了基于模型的强化学习的现代方法，这些方法利用“epistemic”和“aleatoric”不确定性来指导探索，同时考虑安全性。', 'title_zh': '概率人工智能'}
{'arxiv_id': 'arXiv:2502.06788', 'title': 'EVEv2: Improved Baselines for Encoder-Free Vision-Language Models', 'authors': 'Haiwen Diao, Xiaotong Li, Yufeng Cui, Yueze Wang, Haoge Deng, Ting Pan, Wenxuan Wang, Huchuan Lu, Xinlong Wang', 'link': 'https://arxiv.org/abs/2502.06788', 'abstract': 'Existing encoder-free vision-language models (VLMs) are rapidly narrowing the performance gap with their encoder-based counterparts, highlighting the promising potential for unified multimodal systems with structural simplicity and efficient deployment. We systematically clarify the performance gap between VLMs using pre-trained vision encoders, discrete tokenizers, and minimalist visual layers from scratch, deeply excavating the under-examined characteristics of encoder-free VLMs. We develop efficient strategies for encoder-free VLMs that rival mainstream encoder-based ones. After an in-depth investigation, we launch EVEv2.0, a new and improved family of encoder-free VLMs. We show that: (i) Properly decomposing and hierarchically associating vision and language within a unified model reduces interference between modalities. (ii) A well-designed training strategy enables effective optimization for encoder-free VLMs. Through extensive evaluation, our EVEv2.0 represents a thorough study for developing a decoder-only architecture across modalities, demonstrating superior data efficiency and strong vision-reasoning capability. Code is publicly available at: this https URL.', 'abstract_zh': '现有的无编码器视觉-语言模型（VLMs）正迅速缩小与基于编码器的模型之间的性能差距，突显了结构简单且高效部署的统一多模态系统具有巨大的潜力。我们系统地澄清了使用预训练视觉编码器、离散分词器和从零构建的简约视觉层的视觉-语言模型之间的性能差距，深入挖掘了无编码器视觉-语言模型的未充分研究特性。我们为无编码器视觉-语言模型开发了与主流基于编码器的模型相媲美的高效策略。在深入调查后，我们推出了EVEv2.0，这是一种新改进的无编码器视觉-语言模型系列。我们展示了：（i）在统一模型中适当分解并分层次关联视觉和语言可减少模态间的干扰。（ii）精心设计的训练策略能够有效优化无编码器视觉-语言模型。通过广泛的评估，我们的EVEv2.0代表了在各模态上开发仅解码器架构的全面研究，展示了卓越的数据效率和强大的视觉推理能力。代码已公开：this https URL。', 'title_zh': 'EVEv2: 无需编码器的视觉-语言模型改进基准'}
{'arxiv_id': 'arXiv:2502.06786', 'title': 'Matryoshka Quantization', 'authors': 'Pranav Nair, Puranjay Datta, Jeff Dean, Prateek Jain, Aditya Kusupati', 'link': 'https://arxiv.org/abs/2502.06786', 'abstract': 'Quantizing model weights is critical for reducing the communication and inference costs of large models. However, quantizing models -- especially to low precisions like int4 or int2 -- requires a trade-off in model quality; int2, in particular, is known to severely degrade model quality. Consequently, practitioners are often forced to maintain multiple models with different quantization levels or serve a single model that best satisfies the quality-latency trade-off. On the other hand, integer data types, such as int8, inherently possess a nested (Matryoshka) structure where smaller bit-width integers, like int4 or int2, are nested within the most significant bits. This paper proposes Matryoshka Quantization (MatQuant), a novel multi-scale quantization technique that addresses the challenge of needing multiple quantized models. It allows training and maintaining just one model, which can then be served at different precision levels. Furthermore, due to the co-training and co-distillation regularization provided by MatQuant, the int2 precision models extracted by MatQuant can be up to $10\\%$ more accurate than standard int2 quantization (using techniques like QAT or OmniQuant). This represents significant progress in model quantization, demonstrated by the fact that, with the same recipe, an int2 FFN-quantized Gemma-2 9B model is more accurate than an int8 FFN-quantized Gemma-2 2B model.', 'abstract_zh': 'Matryoshka量化：一种新型多尺度量化解决策 methodology', 'title_zh': '套娃量化'}
{'arxiv_id': 'arXiv:2502.06784', 'title': 'RelGNN: Composite Message Passing for Relational Deep Learning', 'authors': 'Tianlang Chen, Charilaos Kanatsoulis, Jure Leskovec', 'link': 'https://arxiv.org/abs/2502.06784', 'abstract': 'Predictive tasks on relational databases are critical in real-world applications spanning e-commerce, healthcare, and social media. To address these tasks effectively, Relational Deep Learning (RDL) encodes relational data as graphs, enabling Graph Neural Networks (GNNs) to exploit relational structures for improved predictions. However, existing heterogeneous GNNs often overlook the intrinsic structural properties of relational databases, leading to modeling inefficiencies. Here we introduce RelGNN, a novel GNN framework specifically designed to capture the unique characteristics of relational databases. At the core of our approach is the introduction of atomic routes, which are sequences of nodes forming high-order tripartite structures. Building upon these atomic routes, RelGNN designs new composite message passing mechanisms between heterogeneous nodes, allowing direct single-hop interactions between them. This approach avoids redundant aggregations and mitigates information entanglement, ultimately leading to more efficient and accurate predictive modeling. RelGNN is evaluated on 30 diverse real-world tasks from RelBench (Fey et al., 2024), and consistently achieves state-of-the-art accuracy with up to 25% improvement.', 'abstract_zh': '关系数据库上的预测任务在电子商务、医疗保健和社交媒体等领域具有关键性。为有效地应对这些任务，关系深度学习（RDL）将关系数据编码为图形，使图神经网络（GNNs）能够利用关系结构以提高预测性能。然而，现有的异构GNNs往往忽视了关系数据库的固有结构属性，导致建模效率低下。为此，我们提出了一种新的GNN框架——RelGNN，专门用于捕捉关系数据库的独特特性。在该方法的核心是引入原子路由，即形成高阶三部结构的节点序列。基于这些原子路由，RelGNN设计了新颖的异构节点复合消息传递机制，允许它们之间进行直接单跳交互。这种方法避免了冗余聚合，减轻了信息纠缠，最终实现了更加高效和准确的预测建模。RelGNN在RelBench（Fey等，2024）的30个多样化真实世界任务上进行了评估，并在所有任务上均实现了最先进的准确性，最高提高了25%。', 'title_zh': 'RelGNN: 关系复合消息传递深度学习'}
{'arxiv_id': 'arXiv:2502.06779', 'title': 'KARST: Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission for Visual Classification', 'authors': 'Yue Zhu, Haiwen Diao, Shang Gao, Long Chen, Huchuan Lu', 'link': 'https://arxiv.org/abs/2502.06779', 'abstract': 'Fine-tuning pre-trained vision models for specific tasks is a common practice in computer vision. However, this process becomes more expensive as models grow larger. Recently, parameter-efficient fine-tuning (PEFT) methods have emerged as a popular solution to improve training efficiency and reduce storage needs by tuning additional low-rank modules within pre-trained backbones. Despite their advantages, they struggle with limited representation capabilities and misalignment with pre-trained intermediate features. To address these issues, we introduce an innovative Multi-Kernel Kronecker Adaptation with Re-Scaling Transmission (KARST) for various recognition tasks. Specifically, its multi-kernel design extends Kronecker projections horizontally and separates adaptation matrices into multiple complementary spaces, reducing parameter dependency and creating more compact subspaces. Besides, it incorporates extra learnable re-scaling factors to better align with pre-trained feature distributions, allowing for more flexible and balanced feature aggregation. Extensive experiments validate that our KARST outperforms other PEFT counterparts with a negligible inference cost due to its re-parameterization characteristics. Code is publicly available at: this https URL.', 'abstract_zh': '细调预训练视觉模型以进行特定任务是计算机视觉中的一种常用做法。然而，随着模型规模的扩大，这一过程变得更加昂贵。最近，参数高效细调（PEFT）方法作为通过在预训练主干内部调整额外的低秩模块来提高训练效率并减少存储需求的一种流行解决方案而兴起。尽管它们具有优势，但在表示能力和与预训练中间特征的对齐方面仍存在问题。为了解决这些问题，我们引入了一种用于各类识别任务的创新多核克罗内克自适应与重缩放传输（KARST）。具体而言，其多核设计在水平方向上扩展了克罗内克投影，并将适应矩阵分离到多个互补空间中，减少了参数依赖并创建了更紧凑的子空间。此外，它还引入了额外的可学习重缩放因子，以更好地与预训练特征分布对齐，从而实现更灵活和平衡的特征聚合。广泛的实验验证了我们的KARST在忽略重参数化成本的情况下，优于其他PEFT方法。代码已公开：this https URL。', 'title_zh': 'KARST: 多核克罗内克适应与重新缩放传输的视觉分类'}
{'arxiv_id': 'arXiv:2502.06776', 'title': 'Towards Internet-Scale Training For Agents', 'authors': 'Brandon Trabucco, Gunnar Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov', 'link': 'https://arxiv.org/abs/2502.06776', 'abstract': 'The predominant approach for training web navigation agents gathers human demonstrations for a set of popular websites and hand-written tasks, but it is becoming clear that human data are an inefficient resource. We develop a pipeline to facilitate Internet-scale training for agents without laborious human annotations. In the first stage, an LLM generates tasks for 150k diverse websites. In the next stage, LLM agents complete tasks and produce trajectories. In the final stage, an LLM reviews the trajectories and judges their success. Language models are competitive with human annotators, detecting and filtering out harmful content with an accuracy of 97%, generating feasible tasks with an 89% rate, and judging successful trajectories with an 82.6% accuracy. Scaling the pipeline, agents based on Llama 3.1 70B solve 16.7% of tasks for 150k sites. Training on the data generated by our pipeline is competitive with training on human demonstrations. In data-limited settings derived from Mind2Web and WebLINX, we improve Step Accuracy by up to +89.5% and +122.1% respectively for agents trained on mixtures of data from our pipeline, and human data. When training agents with all available human data from these benchmarks, agents fail to generalize to diverse real sites, and adding our data improves their generalization by +149.0% for WebLINX and +156.3% for Mind2Web. Code will be available at: this http URL.', 'abstract_zh': '大规模互联网训练代理的方法：无需劳动密集型的人工标注自动化生成任务和评估轨迹', 'title_zh': '面向互联网规模的智能体训练'}
{'arxiv_id': 'arXiv:2502.06759', 'title': 'Rationalization Models for Text-to-SQL', 'authors': 'Gaetano Rossiello, Nhan Pham, Michael Glass, Junkyu Lee, Shankar Subramanian', 'link': 'https://arxiv.org/abs/2502.06759', 'abstract': 'We introduce a framework for generating Chain-of-Thought (CoT) rationales to enhance text-to-SQL model fine-tuning. These rationales consist of intermediate SQL statements and explanations, serving as incremental steps toward constructing the final SQL query. The process begins with manually annotating a small set of examples, which are then used to prompt a large language model in an iterative, dynamic few-shot knowledge distillation procedure from a teacher model. A rationalization model is subsequently trained on the validated decomposed queries, enabling extensive synthetic CoT annotations for text-to-SQL datasets. To evaluate the approach, we fine-tune small language models with and without these rationales on the BIRD dataset. Results indicate that step-by-step query generation improves execution accuracy, especially for moderately and highly complex queries, while also enhancing explainability.', 'abstract_zh': '我们引入了一种生成链式思考（CoT）推理框架以增强文本到SQL模型微调。这些推理包括中间SQL语句及其解释，作为构建最终SQL查询的逐步步骤。过程始于手动标注一小部分示例，随后使用这些示例在迭代的动态少量样本知识精炼程序中提示一个大型语言模型，该程序源自一个教师模型。随后，通过在验证分解查询上训练一个合理化模型，可以为文本到SQL数据集生成大量的合成CoT注解。为了评估该方法，我们在BIRD数据集上使用带有和不带这些推理的小型语言模型进行微调。结果表明，逐步查询生成可以提高执行准确性，特别是在中等复杂度和高度复杂度的查询方面，同时也有助于提高可解释性。', 'title_zh': 'Text-to-SQL的合理性模型'}
{'arxiv_id': 'arXiv:2502.06751', 'title': 'What makes a good feedforward computational graph?', 'authors': 'Alex Vitvitskyi, João G. M. Araújo, Marc Lackenby, Petar Veličković', 'link': 'https://arxiv.org/abs/2502.06751', 'abstract': "As implied by the plethora of literature on graph rewiring, the choice of computational graph employed by a neural network can make a significant impact on its downstream performance. Certain effects related to the computational graph, such as under-reaching and over-squashing, may even render the model incapable of learning certain functions. Most of these effects have only been thoroughly studied in the domain of undirected graphs; however, recent years have seen a significant rise in interest in feedforward computational graphs: directed graphs without any back edges. In this paper, we study the desirable properties of a feedforward computational graph, discovering two important complementary measures: fidelity and mixing time, and evaluating a few popular choices of graphs through the lens of these measures. Our study is backed by both theoretical analyses of the metrics' asymptotic behaviour for various graphs, as well as correlating these metrics to the performance of trained neural network models using the corresponding graphs.", 'abstract_zh': '图重配文献中所隐含的意义在于，神经网络所采用的计算图的选择对其下游性能会产生显著影响。与计算图相关的一些效应，如未达到和过度挤压，甚至可能使模型无法学习某些函数。这些效应主要在无向图领域得到了充分研究；然而，在过去几年里，对前向计算图（无反向边的有向图）的兴趣显著增加。在这篇论文中，我们研究了前向计算图的 desirable 属性，发现两种重要的互补衡量标准：忠实度和混合时间，并通过这些衡量标准评估了几种流行的图的选择。我们的研究得到了这些度量的渐近行为的理论分析支持，并将这些度量与使用相应图训练的神经网络模型的性能相关联。', 'title_zh': '什么是好的前馈计算图？'}
{'arxiv_id': 'arXiv:2502.06742', 'title': 'Gradient Multi-Normalization for Stateless and Scalable LLM Training', 'authors': 'Meyer Scetbon, Chao Ma, Wenbo Gong, Edward Meeds', 'link': 'https://arxiv.org/abs/2502.06742', 'abstract': "Training large language models (LLMs) typically relies on adaptive optimizers like Adam (Kingma & Ba, 2015) which store additional state information to accelerate convergence but incur significant memory overhead. Recent efforts, such as SWAN (Ma et al., 2024) address this by eliminating the need for optimizer states while achieving performance comparable to Adam via a multi-step preprocessing procedure applied to instantaneous gradients. Motivated by the success of SWAN, we introduce a novel framework for designing stateless optimizers that normalizes stochastic gradients according to multiple norms. To achieve this, we propose a simple alternating scheme to enforce the normalization of gradients w.r.t these norms. We show that our procedure can produce, up to an arbitrary precision, a fixed-point of the problem, and that SWAN is a particular instance of our approach with carefully chosen norms, providing a deeper understanding of its design. However, SWAN's computationally expensive whitening/orthogonalization step limit its practicality for large LMs. Using our principled perspective, we develop of a more efficient, scalable, and practical stateless optimizer. Our algorithm relaxes the properties of SWAN, significantly reducing its computational cost while retaining its memory efficiency, making it applicable to training large-scale models. Experiments on pre-training LLaMA models with up to 1 billion parameters demonstrate a 3X speedup over Adam with significantly reduced memory requirements, outperforming other memory-efficient baselines.", 'abstract_zh': '一种基于多范数规范化设计的状态less优化器框架', 'title_zh': '无状态和可扩展的大语言模型训练的梯度多归一化'}
{'arxiv_id': 'arXiv:2502.06736', 'title': 'Low-power Spike-based Wearable Analytics on RRAM Crossbars', 'authors': 'Abhiroop Bhattacharjee, Jinquan Shi, Wei-Chen Chen, Xinxin Wang, Priyadarshini Panda', 'link': 'https://arxiv.org/abs/2502.06736', 'abstract': 'This work introduces a spike-based wearable analytics system utilizing Spiking Neural Networks (SNNs) deployed on an In-memory Computing engine based on RRAM crossbars, which are known for their compactness and energy-efficiency. Given the hardware constraints and noise characteristics of the underlying RRAM crossbars, we propose online adaptation of pre-trained SNNs in real-time using Direct Feedback Alignment (DFA) against traditional backpropagation (BP). Direct Feedback Alignment (DFA) learning, that allows layer-parallel gradient computations, acts as a fast, energy & area-efficient method for online adaptation of SNNs on RRAM crossbars, unleashing better algorithmic performance against those adapted using BP. Through extensive simulations using our in-house hardware evaluation engine called DFA_Sim, we find that DFA achieves upto 64.1% lower energy consumption, 10.1% lower area overhead, and a 2.1x reduction in latency compared to BP, while delivering upto 7.55% higher inference accuracy on human activity recognition (HAR) tasks.', 'abstract_zh': '基于RRAM交叉开关的忆阻计算平台的.spike-触发可穿戴分析系统及其在线自适应学习方法', 'title_zh': '基于RRAM交叉bars的低功耗尖峰神经网络可穿戴分析'}
{'arxiv_id': 'arXiv:2502.06733', 'title': 'Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining', 'authors': 'Daouda Sow, Herbert Woisetschläger, Saikiran Bulusu, Shiqiang Wang, Hans-Arno Jacobsen, Yingbin Liang', 'link': 'https://arxiv.org/abs/2502.06733', 'abstract': 'Pretraining large language models (LLMs) on vast and heterogeneous datasets is crucial for achieving state-of-the-art performance across diverse downstream tasks. However, current training paradigms treat all samples equally, overlooking the importance or relevance of individual samples throughout the training process. Existing reweighting strategies, which primarily focus on group-level data importance, fail to leverage fine-grained instance-level information and do not adapt dynamically to individual sample importance as training progresses. In this paper, we introduce novel algorithms for dynamic, instance-level data reweighting aimed at improving both the efficiency and effectiveness of LLM pretraining. Our methods adjust the weight of each training sample based on its loss value in an online fashion, allowing the model to dynamically focus on more informative or important samples at the current training stage. In particular, our framework allows us to systematically devise reweighting strategies deprioritizing redundant or uninformative data, which we find tend to work best. Furthermore, we develop a new theoretical framework for analyzing the impact of loss-based reweighting on the convergence of gradient-based optimization, providing the first formal characterization of how these strategies affect convergence bounds. We empirically validate our approach across a spectrum of tasks, from pretraining 7B and 1.4B parameter LLMs to smaller-scale language models and linear regression problems, demonstrating that our loss-based reweighting approach can lead to faster convergence and significantly improved performance.', 'abstract_zh': '大规模语言模型（LLMs）在海量异构数据集上的预训练对于实现跨多种下游任务的最先进性能至关重要。然而，当前的训练范式将所有样本视为等价的，忽视了训练过程中各个样本的重要性或相关性。现有的重加权策略主要集中在组级数据重要性上，未能充分利用细粒度的实例级信息，也不具备在训练过程中动态适应各个样本重要性的能力。在本文中，我们引入了新的动态实例级数据重加权重法，旨在提高大规模语言模型预训练的效率和效果。我们的方法根据每个训练样本在当前训练阶段的损失值在线调整其权重，使模型能够动态地关注更具信息量或更重要的样本。此外，我们开发了新的理论框架来分析基于损失的重加权对梯度优化收敛的影响，提供了这些策略如何影响收敛界的第一个形式化刻画。我们在从7B和1.4B参数的大规模语言模型到较小规模的语言模型和线性回归问题的多种任务中实验性地验证了我们的方法，证明了基于损失的重加权方法可以加速收敛并显著提高性能。', 'title_zh': '基于动态损失的样本加权重估以改进大规模语言模型预训练'}
{'arxiv_id': 'arXiv:2502.06728', 'title': 'FlexDeMo: Decoupled Momentum Optimization for Fully and Hybrid Sharded Training', 'authors': 'Mogens Henrik From, Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp', 'link': 'https://arxiv.org/abs/2502.06728', 'abstract': 'Training large neural network models requires extensive computational resources, often distributed across several nodes and accelerators. Recent findings suggest that it may be sufficient to only exchange the fast moving components of the gradients, while accumulating momentum locally (Decoupled Momentum, or DeMo). However, when considering larger models that do not fit on a single accelerate, the exchange of gradient information and the integration of DeMo needs to be reconsidered. Here, we propose employing a hybrid strategy, FlexDeMo, whereby nodes fully synchronize locally between different GPUs and inter-node communication is improved through only using the fast-moving components. This effectively combines previous hybrid sharding strategies with the advantages of decoupled momentum. Our experimental results show that FlexDeMo is on par with AdamW in terms of validation loss, demonstrating its viability.', 'abstract_zh': '使用FlexDeMo策略训练大型神经网络模型时，通过局部完全同步不同GPU并在节点间通信中仅使用快速移动的梯度组件来提升性能，这一策略结合了混合分割策略的优势并采用解藕动量，实验结果显示其验证损失与AdamW相当，证明了其可行性。', 'title_zh': 'FlexDeMo: 解耦动量优化用于全程和混合分片训练'}
{'arxiv_id': 'arXiv:2502.06693', 'title': 'Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium', 'authors': 'Amin Adibi, Xu Cao, Zongliang Ji, Jivat Neet Kaur, Winston Chen, Elizabeth Healey, Brighton Nuwagira, Wenqian Ye, Geoffrey Woollard, Maxwell A Xu, Hejie Cui, Johnny Xi, Trenton Chang, Vasiliki Bikia, Nicole Zhang, Ayush Noori, Yuan Xia, Md. Belal Hossain, Hanna A. Frank, Alina Peluso, Yuan Pu, Shannon Zejiang Shen, John Wu, Adibvafa Fallahpour, Sazan Mahbub, Ross Duncan, Yuwei Zhang, Yurui Cao, Zuheng Xu, Michael Craig, Rahul G. Krishnan, Rahmatollah Beheshti, James M. Rehg, Mohammad Ehsanul Karim, Megan Coffee, Leo Anthony Celi, Jason Alan Fries, Mohsen Sadatsafavi, Dennis Shung, Shannon McWeeney, Jessica Dafflon, Sarah Jabbour', 'link': 'https://arxiv.org/abs/2502.06693', 'abstract': "The fourth Machine Learning for Health (ML4H) symposium was held in person on December 15th and 16th, 2024, in the traditional, ancestral, and unceded territories of the Musqueam, Squamish, and Tsleil-Waututh Nations in Vancouver, British Columbia, Canada. The symposium included research roundtable sessions to foster discussions between participants and senior researchers on timely and relevant topics for the ML4H community. The organization of the research roundtables at the conference involved 13 senior and 27 junior chairs across 13 tables. Each roundtable session included an invited senior chair (with substantial experience in the field), junior chairs (responsible for facilitating the discussion), and attendees from diverse backgrounds with an interest in the session's topic.", 'abstract_zh': '第四届医学机器学习（ML4H）研讨会于2024年12月15日至16日在加拿大不列颠哥伦比亚省温哥华的传统、祖先和未割让领土——穆斯夸姆、斯quamish和特利-奥图特民族的领地上举行。研讨会包括了研究圆桌会议环节，旨在促进参与者与资深研究人员就与ML4H社区相关的及时和相关话题进行讨论。会议期间的圆桌会议组织工作涉及13位资深主席和27位初级主席，共13个桌子。每个圆桌会议环节包括一位特邀资深主席（具有该领域丰富经验）、几位初级主席（负责促进讨论）以及来自不同背景并对会议主题感兴趣的参会者。', 'title_zh': '机器学习在健康领域的发展、应用和开放挑战：来自2024 ML4H研讨会圆桌论坛的反思'}
{'arxiv_id': 'arXiv:2502.06692', 'title': 'Multi-label Scandinavian Language Identification (SLIDE)', 'authors': 'Mariia Fedorova, Jonas Sebulon Frydenberg, Victoria Handford, Victoria Ovedie Chruickshank Langø, Solveig Helene Willoch, Marthe Løken Midtgaard, Yves Scherrer, Petter Mæhlum, David Samuel', 'link': 'https://arxiv.org/abs/2502.06692', 'abstract': 'Identifying closely related languages at sentence level is difficult, in particular because it is often impossible to assign a sentence to a single language. In this paper, we focus on multi-label sentence-level Scandinavian language identification (LID) for Danish, Norwegian Bokmål, Norwegian Nynorsk, and Swedish. We present the Scandinavian Language Identification and Evaluation, SLIDE, a manually curated multi-label evaluation dataset and a suite of LID models with varying speed-accuracy tradeoffs. We demonstrate that the ability to identify multiple languages simultaneously is necessary for any accurate LID method, and present a novel approach to training such multi-label LID models.', 'abstract_zh': '在句子层面识别紧密相关的语言具有挑战性，特别是因为往往无法将一个句子归属于单一语言。本文聚焦于丹麦语、挪威语（诺尔威genes克标准语和诺尔维genes新挪威语）和瑞典语的多标签句子级斯堪的纳维亚语言识别（LID）。我们介绍了斯堪的纳维亚语言识别与评估（SLIDE）数据集，这是一个手动策划的多标签评估数据集，以及具有不同速度-准确度权衡的LID模型系列。我们证明了同时识别多种语言的能力对于任何准确的LID方法都是必要的，并提出了一种训练此类多标签LID模型的新方法。', 'title_zh': '多标签斯堪的纳维亚语言识别（SLIDE）'}
{'arxiv_id': 'arXiv:2502.06684', 'title': 'EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks', 'authors': 'Michael Arbel, David Salinas, Frank Hutter', 'link': 'https://arxiv.org/abs/2502.06684', 'abstract': 'Recent foundational models for tabular data, such as TabPFN, have demonstrated remarkable effectiveness in adapting to new tasks through in-context learning. However, these models overlook a crucial equivariance property: the arbitrary ordering of target dimensions should not influence model predictions. In this study, we identify this oversight as a source of incompressible error, termed the equivariance gap, which introduces instability in predictions. To mitigate these issues, we propose a novel model designed to preserve equivariance across output dimensions. Our experimental results indicate that our proposed model not only addresses these pitfalls effectively but also achieves competitive benchmark performance.', 'abstract_zh': '近期用于表结构数据的基础模型，如TabPFN，通过上下文学习展示了在新任务上的显著适应性。然而，这些模型忽视了一个重要的不变性属性：目标维度的任意排列不应影响模型预测。本研究将这一疏忽识别为不可压缩错误的来源，称为不变性差距，它引入了预测的不稳定性。为缓解这些问题，我们提出了一种新模型，旨在在输出维度上保持不变性。我们的实验结果表明，我们提出的新模型不仅有效解决了这些问题，而且还实现了竞争力的基准性能。', 'title_zh': 'EquiTabPFN：目标置换等变先验拟合网络'}
{'arxiv_id': 'arXiv:2502.06681', 'title': 'CHIRLA: Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis', 'authors': 'Bessie Dominguez-Dager, Felix Escalona, Francisco Gomez-Donoso, Miguel Cazorla', 'link': 'https://arxiv.org/abs/2502.06681', 'abstract': "Person re-identification (Re-ID) is a key challenge in computer vision, requiring the matching of individuals across different cameras, locations, and time periods. While most research focuses on short-term scenarios with minimal appearance changes, real-world applications demand robust Re-ID systems capable of handling long-term scenarios, where persons' appearances can change significantly due to variations in clothing and physical characteristics. In this paper, we present CHIRLA, Comprehensive High-resolution Identification and Re-identification for Large-scale Analysis, a novel dataset specifically designed for long-term person Re-ID. CHIRLA consists of recordings from strategically placed cameras over a seven-month period, capturing significant variations in both temporal and appearance attributes, including controlled changes in participants' clothing and physical features. The dataset includes 22 individuals, four connected indoor environments, and seven cameras. We collected more than five hours of video that we semi-automatically labeled to generate around one million bounding boxes with identity annotations. By introducing this comprehensive benchmark, we aim to facilitate the development and evaluation of Re-ID algorithms that can reliably perform in challenging, long-term real-world scenarios.", 'abstract_zh': '全面高分辨率长期人群重识别数据集CHIRLA', 'title_zh': 'CHIRLA: 综合高分辨率识别和再识别以进行大规模分析'}
{'arxiv_id': 'arXiv:2502.06669', 'title': 'Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations', 'authors': 'Rui Chen, Tailai Peng, Xinran Xie, Dekun Lin, Zhe Cui, Zheng Chen', 'link': 'https://arxiv.org/abs/2502.06669', 'abstract': "Significant improvements have been observed in the zero-shot capabilities of the Large Language Models (LLMs). Due to their high sensitivity to input, research has increasingly focused on enhancing LLMs' performance via direct and simple prompt engineering rather than intricate domain adaptation. Studies suggest that LLMs exhibit emotional intelligence, and both positive and negative emotions can potentially enhance task performances. However, prior interaction prompts have predominantly concentrated on a single stimulus type, neglecting to compare different stimulus effects, examine the influence of varying task difficulties, or explore underlying mechanisms. This paper, inspired by the positive correlation between self-efficacy and task performance within the social cognitive theory, introduces Verbal Efficacy Stimulations (VES). Our VES comprises three types of verbal prompts: encouraging, provocative, and critical, addressing six aspects such as helpfulness and competence. And we further categorize task difficulty, aiming to extensively investigate how distinct VES influence the self-efficacy and task achievements of language models at varied levels of difficulty. The experimental results show that the three types of VES improve the performance of LLMs on most tasks, and the most effective VES varies for different models. In extensive experiments, we have obtained some findings consistent with psychological theories, providing novel insights for future research.", 'abstract_zh': '大型语言模型的零样本能力取得了显著提升。由于其对输入的高度敏感性，研究越来越倾向于通过直接简单的提示工程来增强大型语言模型的表现，而不是通过复杂的领域适应。研究表明，大型语言模型表现出情感智能，正向和负向情感都可能增强任务表现。然而，先前的交互提示大多集中在单一刺激类型上，未比较不同刺激效果、探讨任务难度变化的影响或探究其背后的机制。受社会认知理论中自我效能与任务表现之间正相关关系的启发，本文引入了言语效能刺激（VES）。我们的VES包括三种类型的口头提示：鼓励性、引发性、和批判性，涉及诸如帮助性和能力等六个方面。此外，我们进一步对任务难度进行了分类，旨在在不同难度水平上广泛探讨不同VES如何影响语言模型的自我效能和任务成就。实验结果显示，三种类型的VES在大多数任务中提高了大型语言模型的表现，而最有效的VES因模型而异。在广泛的实验中，我们获得了一些与心理学理论一致的发现，为未来的研究提供了新的见解。', 'title_zh': '通过言语效能激发增强大型语言模型的效能与自 efficacy'}
{'arxiv_id': 'arXiv:2502.06666', 'title': 'Automatic Evaluation of Healthcare LLMs Beyond Question-Answering', 'authors': 'Anna Arias-Duart, Pablo Agustin Martin-Torres, Daniel Hinjos, Pablo Bernabeu-Perez, Lucia Urcelay Ganzabal, Marta Gonzalez Mallo, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Sergio Alvarez-Napagao, Dario Garcia-Gasulla', 'link': 'https://arxiv.org/abs/2502.06666', 'abstract': "Current Large Language Models (LLMs) benchmarks are often based on open-ended or close-ended QA evaluations, avoiding the requirement of human labor. Close-ended measurements evaluate the factuality of responses but lack expressiveness. Open-ended capture the model's capacity to produce discourse responses but are harder to assess for correctness. These two approaches are commonly used, either independently or together, though their relationship remains poorly understood. This work is focused on the healthcare domain, where both factuality and discourse matter greatly. It introduces a comprehensive, multi-axis suite for healthcare LLM evaluation, exploring correlations between open and close benchmarks and metrics. Findings include blind spots and overlaps in current methodologies. As an updated sanity check, we release a new medical benchmark--CareQA--, with both open and closed variants. Finally, we propose a novel metric for open-ended evaluations --Relaxed Perplexity-- to mitigate the identified limitations.", 'abstract_zh': '当前的大语言模型（LLMs）基准常常基于开放性或封闭性的问答评估，避免了人力投入。封闭性评估衡量响应的事实性，但缺乏表达力。开放性评估捕捉模型生成论述响应的能力，但对其正确性评估更加困难。这两种方法要么独立使用，要么一起使用，但它们之间的关系仍不清楚。本工作聚焦于医疗健康领域，其中事实性和论述都非常重要。它引入了一个全面的多维度评估套件，探索开放性和封闭性基准和度量之间的相关性。研究发现包括当前方法的盲点和重叠。作为更新的合理性检验，我们发布了新的医疗基准——CareQA——，包括开放性和封闭性变体。最后，我们提出了一种新的开放性评估指标——松弛困惑度——以缓解识别出的局限性。', 'title_zh': '自动评估 healthcare LLMs 超越问答任务'}
{'arxiv_id': 'arXiv:2502.06664', 'title': 'Evaluation of Deep Audio Representations for Hearables', 'authors': 'Fabian Gröger, Pascal Baumann, Ludovic Amruthalingam, Laurent Simon, Ruksana Giurda, Simone Lionetti', 'link': 'https://arxiv.org/abs/2502.06664', 'abstract': 'Effectively steering hearable devices requires understanding the acoustic environment around the user. In the computational analysis of sound scenes, foundation models have emerged as the state of the art to produce high-performance, robust, multi-purpose audio representations. We introduce and release Deep Evaluation of Audio Representations (DEAR), the first dataset and benchmark to evaluate the efficacy of foundation models in capturing essential acoustic properties for hearables. The dataset includes 1,158 audio tracks, each 30 seconds long, created by spatially mixing proprietary monologues with commercial, high-quality recordings of everyday acoustic scenes. Our benchmark encompasses eight tasks that assess the general context, speech sources, and technical acoustic properties of the audio scenes. Through our evaluation of four general-purpose audio representation models, we demonstrate that the BEATs model significantly surpasses its counterparts. This superiority underscores the advantage of models trained on diverse audio collections, confirming their applicability to a wide array of auditory tasks, including encoding the environment properties necessary for hearable steering. The DEAR dataset and associated code are available at this https URL.', 'abstract_zh': '有效引导可听设备要求理解用户周围的声学环境。在声场景的计算分析中，基础模型已发展成为最先进的方法，以生成高性能、鲁棒性和多用途的音频表示。我们引入并发布了Deep Evaluation of Audio Representations（DEAR），这是首个评估基础模型捕获可听设备关键声学特性的数据集和基准。该数据集包含1,158条音频轨道，每条30秒，由专有独白与商业高标准的日常生活声场景录音空间混合而成。我们的基准涵盖了八个任务，评估声场景的一般背景、对话源以及技术声学特性。通过四种通用音频表示模型的评估，我们证明了BEATs模型显著超越了其他模型。这一优势突显了在多样化的音频集合上训练的模型的优势，证实了它们在各种听觉任务中的适用性，包括编码对可听设备控制所必需的环境特性。DEAR数据集及关联代码可在以下链接访问：this https URL。', 'title_zh': '可穿戴设备中深度音频表示的评估'}
{'arxiv_id': 'arXiv:2502.06648', 'title': 'The 2021 Tokyo Olympics Multilingual News Article Dataset', 'authors': 'Erik Novak, Erik Calcina, Dunja Mladenić, Marko Grobelnik', 'link': 'https://arxiv.org/abs/2502.06648', 'abstract': 'In this paper, we introduce a dataset of multilingual news articles covering the 2021 Tokyo Olympics. A total of 10,940 news articles were gathered from 1,918 different publishers, covering 1,350 sub-events of the 2021 Olympics, and published between July 1, 2021, and August 14, 2021. These articles are written in nine languages from different language families and in different scripts. To create the dataset, the raw news articles were first retrieved via a service that collects and analyzes news articles. Then, the articles were grouped using an online clustering algorithm, with each group containing articles reporting on the same sub-event. Finally, the groups were manually annotated and evaluated. The development of this dataset aims to provide a resource for evaluating the performance of multilingual news clustering algorithms, for which limited datasets are available. It can also be used to analyze the dynamics and events of the 2021 Tokyo Olympics from different perspectives. The dataset is available in CSV format and can be accessed from the this http URL repository.', 'abstract_zh': '本文介绍了涵盖2021东京奥运会的多语言新闻文章数据集。共收集了10940篇来自1918家不同出版商的新闻文章，覆盖了2021年奥运会的1350个子项目，发布时间为2021年7月1日至8月14日。这些文章使用了九种来自不同语系和不同文字脚本的语言。为创建数据集，原始新闻文章首先通过一个收集和分析新闻文章的服务获取。然后，使用在线聚类算法将文章分组，每组包含报道同一子项目的文章。最后，对手动注释和评估。该数据集的开发旨在提供一种评估多语言新闻聚类算法性能的资源，目前此类数据集相对匮乏。此外，该数据集也可用于从不同角度分析2021东京奥运会的动力和事件。数据集以CSV格式提供，并可通过以下链接访问：this http URL存储库。', 'title_zh': '2021东京东京奥运会多语言新闻文章数据集'}
{'arxiv_id': 'arXiv:2502.06635', 'title': 'Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM', 'authors': 'Qingshui Gu, Shu Li, Tianyu Zheng, Zhaoxiang Zhang', 'link': 'https://arxiv.org/abs/2502.06635', 'abstract': "Steel-LLM is a Chinese-centric language model developed from scratch with the goal of creating a high-quality, open-source model despite limited computational resources. Launched in March 2024, the project aimed to train a 1-billion-parameter model on a large-scale dataset, prioritizing transparency and the sharing of practical insights to assist others in the community. The training process primarily focused on Chinese data, with a small proportion of English data included, addressing gaps in existing open-source LLMs by providing a more detailed and practical account of the model-building journey. Steel-LLM has demonstrated competitive performance on benchmarks such as CEVAL and CMMLU, outperforming early models from larger institutions. This paper provides a comprehensive summary of the project's key contributions, including data collection, model design, training methodologies, and the challenges encountered along the way, offering a valuable resource for researchers and practitioners looking to develop their own LLMs. The model checkpoints and training script are available at this https URL.", 'abstract_zh': 'Steel-LLM是一种以中文为中心的从零开始开发的语言模型，旨在利用有限的计算资源创建高质量的开源模型。该项目于2024年3月启动，目标是在大规模数据集上训练一个10亿参数的模型，注重透明度与实用见解的分享，以帮助社区中的其他人。训练过程主要侧重于中文数据，同时包含少量英文数据，通过提供详细的模型构建过程，弥补现有开源语言模型的不足。Steel-LLM在CEVAL和CMMLU等基准测试中表现出竞争性性能，超越了大型机构的早期模型。本文提供了该项目关键贡献的全面总结，包括数据收集、模型设计、训练方法以及遇到的挑战，为希望开发自己语言模型的研究人员和实践者提供了宝贵的资源。模型检查点和训练脚本可在以下链接获取：this https URL。', 'title_zh': 'Steel-LLM：从零开始到开源——构建以中文为中心的LLM的个人历程'}
{'arxiv_id': 'arXiv:2502.06634', 'title': 'Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language', 'authors': 'Zhiqiang Zhong, Simon Sataa-Yu Larsen, Haoyu Guo, Tao Tang, Kuangyu Zhou, Davide Mottin', 'link': 'https://arxiv.org/abs/2502.06634', 'abstract': 'Recent advancements in AI for biological research focus on integrating molecular data with natural language to accelerate drug discovery. However, the scarcity of high-quality annotations limits progress in this area. This paper introduces LA$^3$, a Language-based Automatic Annotation Augmentation framework that leverages large language models to augment existing datasets, thereby improving AI training. We demonstrate the effectiveness of LA$^3$ by creating an enhanced dataset, LaChEBI-20, where we systematically rewrite the annotations of molecules from an established dataset. These rewritten annotations preserve essential molecular information while providing more varied sentence structures and vocabulary. Using LaChEBI-20, we train LaMolT5 based on a benchmark architecture to learn the mapping between molecular representations and augmented annotations.\nExperimental results on text-based *de novo* molecule generation and molecule captioning demonstrate that LaMolT5 outperforms state-of-the-art models. Notably, incorporating LA$^3$ leads to improvements of up to 301% over the benchmark architecture. Furthermore, we validate the effectiveness of LA$^3$ notable applications in *image*, *text* and *graph* tasks, affirming its versatility and utility.', 'abstract_zh': 'Recent advancements in AI for biological research focus on integrating molecular data with natural language to accelerate drug discovery. However, the scarcity of high-quality annotations limits progress in this area. This paper introduces LA$^3$, a Language-based Automatic Annotation Augmentation framework that leverages large language models to augment existing datasets, thereby improving AI training.', 'title_zh': '自动注释增强提升分子与自然语言之间的翻译'}
{'arxiv_id': 'arXiv:2502.06633', 'title': 'Combining Large Language Models with Static Analyzers for Code Review Generation', 'authors': 'Imen Jaoua, Oussama Ben Sghaier, Houari Sahraoui', 'link': 'https://arxiv.org/abs/2502.06633', 'abstract': 'Code review is a crucial but often complex, subjective, and time-consuming activity in software development. Over the past decades, significant efforts have been made to automate this process. Early approaches focused on knowledge-based systems (KBS) that apply rule-based mechanisms to detect code issues, providing precise feedback but struggling with complex, context-dependent cases. More recent work has shifted toward fine-tuning pre-trained language models for code review, enabling broader issue coverage but often at the expense of precision. In this paper, we propose a hybrid approach that combines the strengths of KBS and learning-based systems (LBS) to generate high-quality, comprehensive code reviews. Our method integrates knowledge at three distinct stages of the language model pipeline: during data preparation (Data-Augmented Training, DAT), at inference (Retrieval-Augmented Generation, RAG), and after inference (Naive Concatenation of Outputs, NCO). We empirically evaluate our combination strategies against standalone KBS and LBS fine-tuned on a real-world dataset. Our results show that these hybrid strategies enhance the relevance, completeness, and overall quality of review comments, effectively bridging the gap between rule-based tools and deep learning models.', 'abstract_zh': '代码审查是软件开发中一个关键但常常复杂、主观且耗时的活动。在过去几十年中，已经做了大量的努力来自动化这一过程。早期的方法集中于基于知识系统的(KBS)应用规则机制来检测代码问题，提供精准的反馈，但在处理复杂的、具有上下文依赖性的情况时存在困难。近年来的工作则转向通过微调预训练语言模型来进行代码审查，能够覆盖更广泛的问题，但在精度方面往往有所妥协。本文提出了一种混合方法，结合基于知识系统的(KBS)和基于学习系统的(LBS)的优点，以生成高质量、全面的代码审查评论。我们的方法在语言模型管道的三个不同阶段整合了知识：数据准备阶段（数据增强训练，DAT）、推理阶段（检索增强生成，RAG）和推理后阶段（输出的朴素拼接，NCO）。我们实证评估了这些组合策略与独立的KBS和LBS（在真实数据集上微调）的效果。我们发现这些混合策略提高了审查评论的相关性、完整性和整体质量，有效地弥合了基于规则的工具和深度学习模型之间的差距。', 'title_zh': '结合大型语言模型与静态分析器进行代码审查生成'}
{'arxiv_id': 'arXiv:2502.06632', 'title': 'Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging', 'authors': 'Mohammed Abdul Hafeez Khan, Samuel Morries Boddepalli, Siddhartha Bhattacharyya, Debasis Mitra', 'link': 'https://arxiv.org/abs/2502.06632', 'abstract': 'Accurate classification and anatomical localization are essential for effective medical diagnostics and research, which may be efficiently performed using deep learning techniques. However, availability of limited labeled data poses a significant challenge. To address this, we adapted Prototypical Networks and the Propagation-Reconstruction Network (PRNet) for few-shot classification and localization, respectively, in Single Photon Emission Computed Tomography (SPECT) images. For the proof of concept we used a 2D-sliced image cropped around heart. The Prototypical Network, with a pre-trained ResNet-18 backbone, classified ventricles, myocardium, and liver tissues with 96.67% training and 93.33% validation accuracy. PRNet, adapted for 2D imaging with an encoder-decoder architecture and skip connections, achieved a training loss of 1.395, accurately reconstructing patches and capturing spatial relationships. These results highlight the potential of Prototypical Networks for tissue classification with limited labeled data and PRNet for anatomical landmark localization, paving the way for improved performance in deep learning frameworks.', 'abstract_zh': '准确的分类和解剖定位对于有效的医学诊断和研究至关重要，这可以通过深度学习技术高效地实现。然而，可用的有限标记数据提出了显著挑战。为应对这一挑战，我们针对单光子发射计算机断层摄影(SPECT)图像，将原型网络（Prototypical Networks）和传播重建网络（PRNet）分别应用于少样本分类和定位。作为概念验证，我们使用了心脏周围的2D切片图像。预训练的ResNet-18作为原型网络的骨干网络，分类心室、心肌和肝组织，训练准确率为96.67%，验证准确率为93.33%。PRNet通过编码-解码架构和跳跃连接被改编用于2D成像，训练损失为1.395，准确地重建了图像斑块并捕捉了空间关系。这些结果强调了在有限标记数据下使用原型网络进行组织分类和使用PRNet进行解剖标志点定位的潜力，为深度学习框架中的性能提升铺平了道路。', 'title_zh': '基于SPECT成像的少量样本分类与组织解剖定位'}
{'arxiv_id': 'arXiv:2502.06631', 'title': 'Conformal Predictions for Human Action Recognition with Vision-Language Models', 'authors': 'Bary Tim, Fuchs Clément, Macq Benoît', 'link': 'https://arxiv.org/abs/2502.06631', 'abstract': 'Human-In-The-Loop (HITL) frameworks are integral to many real-world computer vision systems, enabling human operators to make informed decisions with AI assistance. Conformal Predictions (CP), which provide label sets with rigorous guarantees on ground truth inclusion probabilities, have recently gained traction as a valuable tool in HITL settings. One key application area is video surveillance, closely associated with Human Action Recognition (HAR). This study explores the application of CP on top of state-of-the-art HAR methods that utilize extensively pre-trained Vision-Language Models (VLMs). Our findings reveal that CP can significantly reduce the average number of candidate classes without modifying the underlying VLM. However, these reductions often result in distributions with long tails. To address this, we introduce a method based on tuning the temperature parameter of the VLMs to minimize these tails without requiring additional calibration data. Our code is made available on GitHub at the address this https URL.', 'abstract_zh': '基于人类在环的条件随机场在先进视觉语言模型上的人体动作识别中的应用及其改进方法', 'title_zh': '视觉语言模型驱动的人类动作识别构形预测'}
{'arxiv_id': 'arXiv:2502.06608', 'title': 'TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models', 'authors': 'Yangguang Li, Zi-Xin Zou, Zexiang Liu, Dehu Wang, Yuan Liang, Zhipeng Yu, Xingchao Liu, Yuan-Chen Guo, Ding Liang, Wanli Ouyang, Yan-Pei Cao', 'link': 'https://arxiv.org/abs/2502.06608', 'abstract': 'Recent advancements in diffusion techniques have propelled image and video generation to unprece- dented levels of quality, significantly accelerating the deployment and application of generative AI. However, 3D shape generation technology has so far lagged behind, constrained by limitations in 3D data scale, complexity of 3D data process- ing, and insufficient exploration of advanced tech- niques in the 3D domain. Current approaches to 3D shape generation face substantial challenges in terms of output quality, generalization capa- bility, and alignment with input conditions. We present TripoSG, a new streamlined shape diffu- sion paradigm capable of generating high-fidelity 3D meshes with precise correspondence to input images. Specifically, we propose: 1) A large-scale rectified flow transformer for 3D shape generation, achieving state-of-the-art fidelity through training on extensive, high-quality data. 2) A hybrid supervised training strategy combining SDF, normal, and eikonal losses for 3D VAE, achieving high- quality 3D reconstruction performance. 3) A data processing pipeline to generate 2 million high- quality 3D samples, highlighting the crucial rules for data quality and quantity in training 3D gen- erative models. Through comprehensive experi- ments, we have validated the effectiveness of each component in our new framework. The seamless integration of these parts has enabled TripoSG to achieve state-of-the-art performance in 3D shape generation. The resulting 3D shapes exhibit en- hanced detail due to high-resolution capabilities and demonstrate exceptional fidelity to input im- ages. Moreover, TripoSG demonstrates improved versatility in generating 3D models from diverse image styles and contents, showcasing strong gen- eralization capabilities. To foster progress and innovation in the field of 3D generation, we will make our model publicly available.', 'abstract_zh': 'Recent advancements in扩散技术推动了图像和视频生成的质量达到前所未有的水平，大大加速了生成型AI的应用部署。然而，3D形状生成技术至今仍落后于这一进展，受限于3D数据规模的限制、3D数据处理的复杂性以及3D领域高级技术探索的不足。当前的3D形状生成方法在输出质量、泛化能力和输入条件对齐方面面临重大挑战。我们提出了一种名为TripoSG的新颖精简形状扩散范式，能够生成与输入图像具精确对应关系的高保真3D网格。具体而言，我们提出了：1）一种大规模校正流 Transformer，通过大量高质量数据训练实现最先进的保真度；2）一种结合体素距离场(SDF)、法线和ikelon损失的混合监督训练策略，以实现高性能的3D重建；3）一个数据处理管道，生成200万个高质量3D样本，强调了3D生成模型训练中数据质量和数量的关键规则。通过全面的实验，我们验证了新框架中每个组件的有效性。这些组件的无缝集成使TripoSG在3D形状生成方面达到了最先进的性能。生成的3D形状由于具备高分辨率能力而更加细腻，并且与输入图像具有极高的保真度。此外，TripoSG展示了从不同图像风格和内容生成3D模型的增强灵活性，呈现出强大的泛化能力。为了促进3D生成领域的进展和创新，我们将公开发布我们的模型。', 'title_zh': 'TripoSG：大规模矫正流模型下的高保真3D形状合成'}
{'arxiv_id': 'arXiv:2502.06607', 'title': 'Illegal Waste Detection in Remote Sensing Images: A Case Study', 'authors': 'Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca Morandini, Andrea Diecidue, Simona Malegori', 'link': 'https://arxiv.org/abs/2502.06607', 'abstract': "Environmental crime currently represents the third largest criminal activity worldwide while threatening ecosystems as well as human health. Among the crimes related to this activity, improper waste management can nowadays be countered more easily thanks to the increasing availability and decreasing cost of Very-High-Resolution Remote Sensing images, which enable semi-automatic territory scanning in search of illegal landfills. This paper proposes a pipeline, developed in collaboration with professionals from a local environmental agency, for detecting candidate illegal dumping sites leveraging a classifier of Remote Sensing images. To identify the best configuration for such classifier, an extensive set of experiments was conducted and the impact of diverse image characteristics and training settings was thoroughly analyzed. The local environmental agency was then involved in an experimental exercise where outputs from the developed classifier were integrated in the experts' everyday work, resulting in time savings with respect to manual photo-interpretation. The classifier was eventually run with valuable results on a location outside of the training area, highlighting potential for cross-border applicability of the proposed pipeline.", 'abstract_zh': '环境犯罪目前是全球第三大犯罪活动，对生态系统及人类健康构成威胁。针对这种犯罪活动，与不当废物管理相关的犯罪如今可以通过不断增加且成本降低的高分辨率遥感图像更易于对抗，这些图像能够用于半自动地扫描领土，以寻找非法填埋场。本文提出了一种由当地环境机构的专业人员共同开发的流程，利用遥感图像分类器检测候选非法倾倒场地。为了确定此类分类器的最佳配置，进行了大量的实验，并且详细分析了各种图像特性和训练设置的影响。随后，当地环境机构参与了一次实验演习，将开发的分类器输出整合到专家的日常工作中，实现了与手动图像解释相比的时间节约。最终，分类器在训练区域外的位置产生了有价值的结果，突显了所提流程在跨境应用中的潜在可能性。', 'title_zh': '遥感图像中非法废物检测：一个案例研究'}
{'arxiv_id': 'arXiv:2502.06601', 'title': 'Amortized In-Context Bayesian Posterior Estimation', 'authors': 'Sarthak Mittal, Niels Leif Bracher, Guillaume Lajoie, Priyank Jaini, Marcus Brubaker', 'link': 'https://arxiv.org/abs/2502.06601', 'abstract': 'Bayesian inference provides a natural way of incorporating prior beliefs and assigning a probability measure to the space of hypotheses. Current solutions rely on iterative routines like Markov Chain Monte Carlo (MCMC) sampling and Variational Inference (VI), which need to be re-run whenever new observations are available. Amortization, through conditional estimation, is a viable strategy to alleviate such difficulties and has been the guiding principle behind simulation-based inference, neural processes and in-context methods using pre-trained models. In this work, we conduct a thorough comparative analysis of amortized in-context Bayesian posterior estimation methods from the lens of different optimization objectives and architectural choices. Such methods train an amortized estimator to perform posterior parameter inference by conditioning on a set of data examples passed as context to a sequence model such as a transformer. In contrast to language models, we leverage permutation invariant architectures as the true posterior is invariant to the ordering of context examples. Our empirical study includes generalization to out-of-distribution tasks, cases where the assumed underlying model is misspecified, and transfer from simulated to real problems. Subsequently, it highlights the superiority of the reverse KL estimator for predictive problems, especially when combined with the transformer architecture and normalizing flows.', 'abstract_zh': '贝叶斯推断提供了一种自然地 Incorporating 先验信念并将概率测度赋予假设空间的方法。当前的方法依赖于马尔可夫链蒙特卡罗（MCMC）采样和变分推断（VI）等迭代过程，这些方法在新观测数据可用时需要重新运行。通过条件估计进行的学习化策略是缓解此类困难的有效方法，并且是基于模拟的推断、神经过程以及使用预训练模型的上下文方法背后的指导原则。在本文中，我们从不同的优化目标和网络架构视角对学习化的上下文贝叶斯后验估计方法进行了全面的比较分析。此类方法通过条件估计训练一个学习器，在序列模型（如变换器）输入的一组数据示例上下文中执行后验参数推断。与语言模型不同，我们利用不变排序架构，因为真实的后验在示例上下文的排序上是不变的。我们的实证研究包括对异常分布任务的一般化、假设底层模型指定错误的情况，以及从模拟问题转移到真实问题。随后的研究突显了逆KL估计器在预测问题中的优越性，尤其是在与变换器架构和归一化流结合使用时。', 'title_zh': 'amortized 在上下文中的贝叶斯后验估计'}
{'arxiv_id': 'arXiv:2502.06600', 'title': 'Evaluation of Multilingual Image Captioning: How far can we get with CLIP models?', 'authors': 'Gonçalo Gomes, Chrysoula Zerva, Bruno Martins', 'link': 'https://arxiv.org/abs/2502.06600', 'abstract': 'The evaluation of image captions, looking at both linguistic fluency and semantic correspondence to visual contents, has witnessed a significant effort. Still, despite advancements such as the CLIPScore metric, multilingual captioning evaluation has remained relatively unexplored. This work presents several strategies, and extensive experiments, related to evaluating CLIPScore variants in multilingual settings. To address the lack of multilingual test data, we consider two different strategies: (1) using quality aware machine-translated datasets with human judgements, and (2) re-purposing multilingual datasets that target semantic inference and reasoning. Our results highlight the potential of finetuned multilingual models to generalize across languages and to handle complex linguistic challenges. Tests with machine-translated data show that multilingual CLIPScore models can maintain a high correlation with human judgements across different languages, and additional tests with natively multilingual and multicultural data further attest to the high-quality assessments.', 'abstract_zh': '多语言图像说明评估：细说CLIPScore变体在多语言环境中的评价策略与实验', 'title_zh': '多语言图像字幕评价：CLIP模型能带我们走多远？'}
{'arxiv_id': 'arXiv:2502.06589', 'title': 'Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training', 'authors': 'Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, Zheng Li, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang', 'link': 'https://arxiv.org/abs/2502.06589', 'abstract': 'Due to the scarcity of agent-oriented pre-training data, LLM-based autonomous agents typically rely on complex prompting or extensive fine-tuning, which often fails to introduce new capabilities while preserving strong generalizability. We introduce Hephaestus-Forge, the first large-scale pre-training corpus designed to enhance the fundamental capabilities of LLM agents in API function calling, intrinsic reasoning and planning, and adapting to environmental feedback. Hephaestus-Forge comprises 103B agent-specific data encompassing 76,537 APIs, including both tool documentation to introduce knowledge of API functions and function calling trajectories to strengthen intrinsic reasoning. To explore effective training protocols, we investigate scaling laws to identify the optimal recipe in data mixing ratios. By continual pre-training on Hephaestus-Forge, Hephaestus outperforms small- to medium-scale open-source LLMs and rivals commercial LLMs on three agent benchmarks, demonstrating the effectiveness of our pre-training corpus in enhancing fundamental agentic capabilities and generalization of LLMs to new tasks or environments.', 'abstract_zh': '由于缺乏以代理为核心的预训练数据，基于LLM的自主代理通常依赖于复杂的提示或广泛的微调，这往往无法引入新能力同时保持强大的泛化能力。我们介绍了Hephaestus-Forge，这是首个大规模预训练语料库，旨在增强LLM代理的API函数调用、内在推理和规划能力，并使其能够适应环境反馈。Hephaestus-Forge包含103亿个特定于代理的数据，涵盖了76,537个API，包括工具文档以引入API功能的知识，以及功能调用轨迹以加强内在推理。为探索有效的训练协议，我们研究了标度定律以确定最优的数据混合比例。通过持续在Hephaestus-Forge上预训练，Hephaestus在三个代理基准测试中优于小型到中型的开源LLM，并与商用LLM相竞争，证明了我们预训练语料库在增强代理基本能力以及使LLM泛化到新任务或环境方面的有效性。', 'title_zh': 'Hephaestus: 通过持续预训练提升大型语言模型的基本代理能力'}
{'arxiv_id': 'arXiv:2502.06577', 'title': 'The Minimal Search Space for Conditional Causal Bandits', 'authors': 'Francisco N. F. Q. Simoes, Itai Feigenbaum, Mehdi Dastani, Thijs van Ommen', 'link': 'https://arxiv.org/abs/2502.06577', 'abstract': 'Causal knowledge can be used to support decision-making problems. This has been recognized in the causal bandits literature, where a causal (multi-armed) bandit is characterized by a causal graphical model and a target variable. The arms are then interventions on the causal model, and rewards are samples of the target variable. Causal bandits were originally studied with a focus on hard interventions. We focus instead on cases where the arms are conditional interventions, which more accurately model many real-world decision-making problems by allowing the value of the intervened variable to be chosen based on the observed values of other variables. This paper presents a graphical characterization of the minimal set of nodes guaranteed to contain the optimal conditional intervention, which maximizes the expected reward. We then propose an efficient algorithm with a time complexity of $O(|V| + |E|)$ to identify this minimal set of nodes. We prove that the graphical characterization and the proposed algorithm are correct. Finally, we empirically demonstrate that our algorithm significantly prunes the search space and substantially accelerates convergence rates when integrated into standard multi-armed bandit algorithms.', 'abstract_zh': '因果知识可以用于支持决策问题。在这方面，因果 bandits 的文献已经有所认识，其中因果 bandits 通过因果图形模型和目标变量来表征。手臂则为对因果模型的干预，奖励为目标变量的样本。因果 bandits 原始的研究主要侧重于硬干预。我们相反地关注手臂为条件干预的情况，这更准确地 modeling 许多现实世界的决策问题，允许被干预变量的值基于其他观测变量的值来选择。本文提出了一个图化的表征，描述了包含最优条件干预（能够最大化期望奖励）的最小节点集合。随后，我们提出一个时间复杂度为 $O(|V| + |E|)$ 的高效算法来识别这个最小节点集合。我们证明了这个图化的表征和提出的算法是正确的。最后，我们通过实证研究证明，在集成到标准 bandits 算法中时，我们的算法能够显著减少搜索空间，并显著提高收敛速度。', 'title_zh': '条件因果多臂问题的最小搜索空间'}
{'arxiv_id': 'arXiv:2502.06575', 'title': 'Predictive Red Teaming: Breaking Policies Without Breaking Robots', 'authors': 'Anirudha Majumdar, Mohit Sharma, Dmitry Kalashnikov, Sumeet Singh, Pierre Sermanet, Vikas Sindhwani', 'link': 'https://arxiv.org/abs/2502.06575', 'abstract': 'Visuomotor policies trained via imitation learning are capable of performing challenging manipulation tasks, but are often extremely brittle to lighting, visual distractors, and object locations. These vulnerabilities can depend unpredictably on the specifics of training, and are challenging to expose without time-consuming and expensive hardware evaluations. We propose the problem of predictive red teaming: discovering vulnerabilities of a policy with respect to environmental factors, and predicting the corresponding performance degradation without hardware evaluations in off-nominal scenarios. In order to achieve this, we develop RoboART: an automated red teaming (ART) pipeline that (1) modifies nominal observations using generative image editing to vary different environmental factors, and (2) predicts performance under each variation using a policy-specific anomaly detector executed on edited observations. Experiments across 500+ hardware trials in twelve off-nominal conditions for visuomotor diffusion policies demonstrate that RoboART predicts performance degradation with high accuracy (less than 0.19 average difference between predicted and real success rates). We also demonstrate how predictive red teaming enables targeted data collection: fine-tuning with data collected under conditions predicted to be adverse boosts baseline performance by 2-7x.', 'abstract_zh': '基于预测性红队的策略脆弱性发现与性能预测方法', 'title_zh': '预测性红队行动：不破坏机器人破解政策'}
{'arxiv_id': 'arXiv:2502.06572', 'title': 'LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM', 'authors': 'Zhi Zhou, Kun-Yang Yu, Shi-Yu Tian, Jiang-Xin Shi, Xiao-Wen Yang, Pengxiao Song, Yi-Xuan Jin, Lan-Zhe Guo, Yu-Feng Li', 'link': 'https://arxiv.org/abs/2502.06572', 'abstract': 'Large language models (LLMs), both proprietary and open-source, have demonstrated remarkable capabilities across various natural language processing tasks. However, they face significant limitations in legal reasoning tasks. Proprietary models introduce data privacy risks and high inference costs, while open-source models underperform due to insufficient legal domain training data. To address these limitations, we study data generation for legal reasoning to improve the legal reasoning performance of open-source LLMs with the help of proprietary LLMs. This is challenging due to the lack of legal knowledge in proprietary LLMs and the difficulty in verifying the generated data. We propose KgDG, a knowledge-guided data generation framework for legal reasoning. Our framework enables leveraging legal knowledge to enhance generation diversity and introduces a refinement and verification process to ensure the quality of generated data. Moreover, we expand the generated dataset to further enhance the LLM reasoning capabilities. Using KgDG, we create a synthetic legal reasoning dataset containing 50K high-quality examples. Our trained model LawGPT outperforms existing legal-specific LLMs and achieves performance comparable to proprietary LLMs, demonstrating the effectiveness of KgDG and LawGPT. Our code and resources is publicly available at this https URL .', 'abstract_zh': '大型语言模型（LLMs）在各种自然语言处理任务中展现了 remarkable 能力，但在法律推理任务中面临显著限制。 proprietary 模型引入了数据隐私风险和高昂的推理成本，而 open-source 模型则由于缺乏足够的法律领域训练数据而表现不佳。为了克服这些限制，我们研究了法律推理的数据生成方法，旨在通过 proprietary LLMs 提高 open-source LLMs 的法律推理性能。由于 proprietary LLMs 缺乏法律知识且生成数据的验证难度大，这一过程颇具挑战性。我们提出了一种名为 KgDG 的知识指导型数据生成框架，用于法律推理。该框架利用法律知识以增强生成多样性，并引入了一个改进和验证过程，以确保生成数据的质量。此外，我们还扩大了生成的数据集，以进一步提升 LLM 的推理能力。通过 KgDG，我们创建了一个包含 50K 高质量示例的合成法律推理数据集。我们训练的模型 LawGPT 在法律特定任务上的表现超越了现有模型，并达到了与 proprietary LLMs 相媲美的水平，证明了 KgDG 和 LawGPT 的有效性。我们的代码和资源已公开于此 https URL 。', 'title_zh': 'LawGPT：知识引导的数据生成及其在法律LLM中的应用'}
{'arxiv_id': 'arXiv:2502.06516', 'title': 'Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation', 'authors': 'Soobin Um, Beomsu Kim, Jong Chul Ye', 'link': 'https://arxiv.org/abs/2502.06516', 'abstract': 'Minority samples are underrepresented instances located in low-density regions of a data manifold, and are valuable in many generative AI applications, such as data augmentation, creative content generation, etc. Unfortunately, existing diffusion-based minority generators often rely on computationally expensive guidance dedicated for minority generation. To address this, here we present a simple yet powerful guidance-free approach called Boost-and-Skip for generating minority samples using diffusion models. The key advantage of our framework requires only two minimal changes to standard generative processes: (i) variance-boosted initialization and (ii) timestep skipping. We highlight that these seemingly-trivial modifications are supported by solid theoretical and empirical evidence, thereby effectively promoting emergence of underrepresented minority features. Our comprehensive experiments demonstrate that Boost-and-Skip greatly enhances the capability of generating minority samples, even rivaling guidance-based state-of-the-art approaches while requiring significantly fewer computations.', 'abstract_zh': '少数样本是位于数据流形低密度区域的未代表实例，在生成式AI应用中如数据增强、创意内容生成等方面具有价值。现有基于扩散的少数样本生成器往往依赖于专门用于少数样本生成的计算昂贵的指导。为解决这一问题，我们提出了一种简单而强大的无指导方法，称为Boost-and-Skip，用于使用扩散模型生成少数样本。该框架的关键优势仅需要对标准生成过程进行两项最小更改：（i）方差放大初始化和（ii）时间步跳过。我们强调，这些看似简单的修改由坚实的理论和实证证据支持，从而有效地促进了未代表少数样本特征的出现。全面的实验表明，Boost-and-Skip显著增强了生成少数样本的能力，甚至在计算量显著减少的情况下，能够匹业界现有的基于指导的最先进方法。', 'title_zh': 'Boost-and-Skip: 一种简单的无引导扩散 minority 生成方法'}
{'arxiv_id': 'arXiv:2502.06494', 'title': 'GuideLLM: Exploring LLM-Guided Conversation with Applications in Autobiography Interviewing', 'authors': 'Jinhao Duan, Xinyu Zhao, Zhuoxuan Zhang, Eunhye Ko, Lily Boddy, Chenan Wang, Tianhao Li, Alexander Rasgon, Junyuan Hong, Min Kyung Lee, Chenxi Yuan, Qi Long, Ying Ding, Tianlong Chen, Kaidi Xu', 'link': 'https://arxiv.org/abs/2502.06494', 'abstract': "Although Large Language Models (LLMs) succeed in human-guided conversations such as instruction following and question answering, the potential of LLM-guided conversations-where LLMs direct the discourse and steer the conversation's objectives-remains under-explored. In this study, we first characterize LLM-guided conversation into three fundamental components: (i) Goal Navigation; (ii) Context Management; (iii) Empathetic Engagement, and propose GuideLLM as an installation. We then implement an interviewing environment for the evaluation of LLM-guided conversation. Specifically, various topics are involved in this environment for comprehensive interviewing evaluation, resulting in around 1.4k turns of utterances, 184k tokens, and over 200 events mentioned during the interviewing for each chatbot evaluation. We compare GuideLLM with 6 state-of-the-art LLMs such as GPT-4o and Llama-3-70b-Instruct, from the perspective of interviewing quality, and autobiography generation quality. For automatic evaluation, we derive user proxies from multiple autobiographies and employ LLM-as-a-judge to score LLM behaviors. We further conduct a human-involved experiment by employing 45 human participants to chat with GuideLLM and baselines. We then collect human feedback, preferences, and ratings regarding the qualities of conversation and autobiography. Experimental results indicate that GuideLLM significantly outperforms baseline LLMs in automatic evaluation and achieves consistent leading performances in human ratings.", 'abstract_zh': '尽管大型语言模型（LLMs）在指令跟随和问答等人指导的对话中取得成功，但LLM引导的对话——其中LLMs主导对话并引导对话目标——的潜力仍被低估。在本研究中，我们首先将LLM引导的对话分为三个基本组件：（i）目标导航；（ii）上下文管理；（iii）同理心参与，并提出GuideLLM作为一项安装。然后，我们实现了一个面试环境来评估LLM引导的对话。具体来说，该环境中包含多种话题，以进行全面的面试评估，从而产生约1400次话语轮次、18.4万个令牌以及每次聊天机器人都提到了超过200个事件。我们从访谈质量、自传生成质量的角度将GuideLLM与诸如GPT-4o和Llama-3-70b-Instruct等6种最先进的LLM进行比较。对于自动评估，我们从多篇自传中提取用户代理，并使用LLM作为评判员来评分LLM行为。我们还通过45名人类参与者与GuideLLM和基线模型进行互动，并收集了关于对话和自传品质的人类反馈、偏好和评分。实验结果表明，在自动评估中GuideLLM显著优于基线LLM，在人类评分中也表现出一致的领先性能。', 'title_zh': 'GuideLLM：探索由大语言模型引导的对话及其在自传访谈中的应用'}
{'arxiv_id': 'arXiv:2502.06491', 'title': 'Model-Based Offline Reinforcement Learning with Reliability-Guaranteed Sequence Modeling', 'authors': 'Shenghong He', 'link': 'https://arxiv.org/abs/2502.06491', 'abstract': 'Model-based offline reinforcement learning (MORL) aims to learn a policy by exploiting a dynamics model derived from an existing dataset. Applying conservative quantification to the dynamics model, most existing works on MORL generate trajectories that approximate the real data distribution to facilitate policy learning by using current information (e.g., the state and action at time step $t$). However, these works neglect the impact of historical information on environmental dynamics, leading to the generation of unreliable trajectories that may not align with the real data distribution. In this paper, we propose a new MORL algorithm \\textbf{R}eliability-guaranteed \\textbf{T}ransformer (RT), which can eliminate unreliable trajectories by calculating the cumulative reliability of the generated trajectory (i.e., using a weighted variational distance away from the real data). Moreover, by sampling candidate actions with high rewards, RT can efficiently generate high-return trajectories from the existing offline data. We theoretically prove the performance guarantees of RT in policy learning, and empirically demonstrate its effectiveness against state-of-the-art model-based methods on several benchmark tasks.', 'abstract_zh': '基于模型的离线强化学习（MORL）旨在通过利用从现有数据集派生的动力学模型来学习策略。通过保守量化动力学模型，现有大多数MORL工作生成轨迹以近似现实数据分布，以便利用当前信息（例如时间步$t$的状态和动作）来辅助策略学习。然而，这些工作忽略了历史信息对环境动力学的影响，导致生成的轨迹可能无法与现实数据分布一致。本文提出了一种新的MORL算法——可靠性保证变换器（RT），该算法可以通过计算生成轨迹的累计可靠性（即使用加权变异距离远离真实数据）来消除不可靠的轨迹。此外，通过采样高回报的动作，RT可以从现有的离线数据高效地生成高回报轨迹。我们从理论上证明了RT在策略学习中的性能保证，并在多个基准任务上实验证明了其相对于最先进的基于模型的方法的有效性。', 'title_zh': '基于模型的离线强化学习及可靠性保障序列建模'}
{'arxiv_id': 'arXiv:2502.06490', 'title': 'Recent Advances in Discrete Speech Tokens: A Review', 'authors': 'Yiwei Guo, Zhihan Li, Hankun Wang, Bohan Li, Chongtian Shao, Hanglei Zhang, Chenpeng Du, Xie Chen, Shujie Liu, Kai Yu', 'link': 'https://arxiv.org/abs/2502.06490', 'abstract': 'The rapid advancement of speech generation technologies in the era of large language models (LLMs) has established discrete speech tokens as a foundational paradigm for speech representation. These tokens, characterized by their discrete, compact, and concise nature, are not only advantageous for efficient transmission and storage, but also inherently compatible with the language modeling framework, enabling seamless integration of speech into text-dominated LLM architectures. Current research categorizes discrete speech tokens into two principal classes: acoustic tokens and semantic tokens, each of which has evolved into a rich research domain characterized by unique design philosophies and methodological approaches. This survey systematically synthesizes the existing taxonomy and recent innovations in discrete speech tokenization, conducts a critical examination of the strengths and limitations of each paradigm, and presents systematic experimental comparisons across token types. Furthermore, we identify persistent challenges in the field and propose potential research directions, aiming to offer actionable insights to inspire future advancements in the development and application of discrete speech tokens.', 'abstract_zh': '大型语言模型时代语音生成技术的迅猛发展确立了离散语音令牌作为语音表示的基本范式。这些令牌以其离散性、紧凑性和简明性为特点，不仅有利于高效传输和存储，还与语言模型框架天然兼容，从而无缝地将语音整合到以文本为主导的大型语言模型架构中。当前研究将离散语音令牌划分为两类主要类别：声学令牌和语义令牌，每类均已发展成为具有独特设计哲学和方法论方法的丰富研究领域。本文综述系统地总结了离散语音分词的现有分类和近期创新，对每种范式的优缺点进行了批判性评估，并进行了跨令牌类型的系统实验比较。此外，我们识别了该领域中持续存在的挑战，并提出了潜在的研究方向，旨在提供可操作的见解，激发未来离散语音令牌开发和应用的进步。', 'title_zh': '近期离散语音令牌的研究进展：一个综述'}
{'arxiv_id': 'arXiv:2502.06485', 'title': 'WyckoffDiff - A Generative Diffusion Model for Crystal Symmetry', 'authors': 'Filip Ekström Kelvinius, Oskar B. Andersson, Abhijith S. Parackal, Dong Qian, Rickard Armiento, Fredrik Lindsten', 'link': 'https://arxiv.org/abs/2502.06485', 'abstract': 'Crystalline materials often exhibit a high level of symmetry. However, most generative models do not account for symmetry, but rather model each atom without any constraints on its position or element. We propose a generative model, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based descriptions of crystals. This is enabled by considering a crystal structure representation that encodes all symmetry, and we design a novel neural network architecture which enables using this representation inside a discrete generative model framework. In addition to respecting symmetry by construction, the discrete nature of our model enables fast generation. We additionally present a new metric, Fréchet Wrenformer Distance, which captures the symmetry aspects of the materials generated, and we benchmark WyckoffDiff against recently proposed generative models for crystal generation.', 'abstract_zh': '晶体材料通常表现出高度的对称性。然而，大多数生成模型并未考虑对称性，而是对每个原子的位置或元素不做任何约束地进行建模。我们提出了一种生成模型Wyckoff Diff (WyckoffDiff)，它可以生成基于对称性的晶体描述。这通过考虑一个包含所有对称性的晶体结构表示来实现，并且我们设计了一种新的神经网络架构，使其能够在离散生成模型框架内部使用这种表示。除了通过设计本身尊重对称性外，我们模型的离散性质还使得生成过程快速。我们还提出了一个新的度量标准Fréchet Wrenformer Distance，它可以捕捉所生成材料的对称性方面，并将WyckoffDiff与最近提出的晶体生成生成模型进行了基准测试。', 'title_zh': 'WyckoffDiff - 一种晶体对称性的生成扩散模型'}
{'arxiv_id': 'arXiv:2502.06472', 'title': 'KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment', 'authors': 'Yuxing Lu, Jinzhuo Wang', 'link': 'https://arxiv.org/abs/2502.06472', 'abstract': 'Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical for modern AI systems, but manual curation struggles to scale with the rapid growth of scientific literature. This paper presents KARMA, a novel framework employing multi-agent large language models (LLMs) to automate KG enrichment through structured analysis of unstructured text. Our approach employs nine collaborative agents, spanning entity discovery, relation extraction, schema alignment, and conflict resolution that iteratively parse documents, verify extracted knowledge, and integrate it into existing graph structures while adhering to domain-specific schema. Experiments on 1,200 PubMed articles from three different domains demonstrate the effectiveness of KARMA in knowledge graph enrichment, with the identification of up to 38,230 new entities while achieving 83.1\\% LLM-verified correctness and reducing conflict edges by 18.6\\% through multi-layer assessments.', 'abstract_zh': '维持全面和实时更新的知识图谱对于现代AI系统至关重要，但手动整理难以应对科学文献的快速增长。本文提出KARMA，这是一种利用多智能体大型语言模型（LLMs）通过结构化分析非结构化文本自动化扩展知识图谱的新框架。我们的方法采用九个协作智能体，涵盖实体发现、关系提取、模式对齐和冲突解决，迭代解析文档、验证提取的知识，并将其整合到现有图结构中，同时遵循领域特定的模式。在三个不同领域的1,200篇PubMed文章上的实验展示了KARMA在知识图谱扩展中的有效性，识别出多达38,230个新实体，LLM验证正确率达到83.1%，并通过多层评估减少了18.6%的冲突边。', 'title_zh': 'KARMA：利用多智能体大语言模型进行自动知识图谱丰富化'}
{'arxiv_id': 'arXiv:2502.06470', 'title': 'A Survey of Theory of Mind in Large Language Models: Evaluations, Representations, and Safety Risks', 'authors': 'Hieu Minh "Jord" Nguyen', 'link': 'https://arxiv.org/abs/2502.06470', 'abstract': 'Theory of Mind (ToM), the ability to attribute mental states to others and predict their behaviour, is fundamental to social intelligence. In this paper, we survey studies evaluating behavioural and representational ToM in Large Language Models (LLMs), identify important safety risks from advanced LLM ToM capabilities, and suggest several research directions for effective evaluation and mitigation of these risks.', 'abstract_zh': '理论心智（ToM）是社会科学智能的基础，其能力在于赋予他人心理状态并预测其行为。本文综述了对大型语言模型（LLM）的 behavioural 和 representational ToM 的研究，识别了高级 LLM ToM 能力带来的重要安全风险，并提出了一些有效评估和缓解这些风险的研究方向。', 'title_zh': '大型语言模型中理论共情的研究：评估、表示与安全风险'}
{'arxiv_id': 'arXiv:2502.06453', 'title': "MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations", 'authors': 'Kaixuan Huang, Jiacheng Guo, Zihao Li, Xiang Ji, Jiawei Ge, Wenzhe Li, Yingqing Guo, Tianle Cai, Hui Yuan, Runzhe Wang, Yue Wu, Ming Yin, Shange Tang, Yangsibo Huang, Chi Jin, Xinyun Chen, Chiyuan Zhang, Mengdi Wang', 'link': 'https://arxiv.org/abs/2502.06453', 'abstract': 'Large language models have demonstrated impressive performance on challenging mathematical reasoning tasks, which has triggered the discussion of whether the performance is achieved by true reasoning capability or memorization. To investigate this question, prior work has constructed mathematical benchmarks when questions undergo simple perturbations -- modifications that still preserve the underlying reasoning patterns of the solutions. However, no work has explored hard perturbations, which fundamentally change the nature of the problem so that the original solution steps do not apply. To bridge the gap, we construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard perturbation, respectively. Each consists of 279 perturbed math problems derived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et. al., 2021). We observe significant performance drops on MATH-P-Hard across various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking (-12.9%). We also raise concerns about a novel form of memorization where models blindly apply learned problem-solving skills without assessing their applicability to modified contexts. This issue is amplified when using original problems for in-context learning. We call for research efforts to address this challenge, which is critical for developing more robust and reliable reasoning models.', 'abstract_zh': '大型语言模型在具有挑战性的数学推理任务上展示了 impressive 的表现，这引发了关于性能是通过真正的推理能力还是记忆实现的讨论。为了探讨这一问题，先前的研究通过简单的扰动（仍然保留解决方案基础推理模式的小修改）构建了数学基准。然而，尚未有研究探索本质扰动，这种扰动从根本上改变了问题的性质，使原始解题步骤不再适用。为了弥合这一差距，我们通过简单的扰动构建了 MATH-P-Simple，通过本质扰动构建了 MATH-P-Hard。两者分别包含源自 MATH 数据集（Hendrycksmath et. al., 2021）最难级别（level-5）的 279 个问题的扰动数学问题。我们观察到在 MATH-P-Hard 上各种模型的表现有显著下降，包括 o1-mini (-16.49%) 和 gemini-2.0-flash-thinking (-12.9%)。我们还对一种新型的记忆化现象表示担忧，即模型盲目应用学习到的解题技巧而无视其对修改后环境的适用性。当使用原始问题进行上下文学习时，这一问题更为突出。我们呼吁研究努力来应对这一挑战，这对于开发更具鲁棒性和可靠性的推理模型至关重要。', 'title_zh': 'MATH-Perturb: 评估LLMs在面对难扰动时的数学推理能力'}
{'arxiv_id': 'arXiv:2502.06440', 'title': 'SIGMA: Sheaf-Informed Geometric Multi-Agent Pathfinding', 'authors': 'Shuhao Liao, Weihang Xia, Yuhong Cao, Weiheng Dai, Chengyang He, Wenjun Wu, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2502.06440', 'abstract': 'The Multi-Agent Path Finding (MAPF) problem aims to determine the shortest and collision-free paths for multiple agents in a known, potentially obstacle-ridden environment. It is the core challenge for robotic deployments in large-scale logistics and transportation. Decentralized learning-based approaches have shown great potential for addressing the MAPF problems, offering more reactive and scalable solutions. However, existing learning-based MAPF methods usually rely on agents making decisions based on a limited field of view (FOV), resulting in short-sighted policies and inefficient cooperation in complex scenarios. There, a critical challenge is to achieve consensus on potential movements between agents based on limited observations and communications. To tackle this challenge, we introduce a new framework that applies sheaf theory to decentralized deep reinforcement learning, enabling agents to learn geometric cross-dependencies between each other through local consensus and utilize them for tightly cooperative decision-making. In particular, sheaf theory provides a mathematical proof of conditions for achieving global consensus through local observation. Inspired by this, we incorporate a neural network to approximately model the consensus in latent space based on sheaf theory and train it through self-supervised learning. During the task, in addition to normal features for MAPF as in previous works, each agent distributedly reasons about a learned consensus feature, leading to efficient cooperation on pathfinding and collision avoidance. As a result, our proposed method demonstrates significant improvements over state-of-the-art learning-based MAPF planners, especially in relatively large and complex scenarios, demonstrating its superiority over baselines in various simulations and real-world robot experiments.', 'abstract_zh': '基于束理论的分布式深度强化学习在多Agent路径规划中的应用', 'title_zh': 'SIGMA: 基于层化几何的多方路径寻找'}
{'arxiv_id': 'arXiv:2502.06439', 'title': 'Testing software for non-discrimination: an updated and extended audit in the Italian car insurance domain', 'authors': 'Marco Rondina, Antonio Vetrò, Riccardo Coppola, Oumaima Regragrui, Alessandro Fabris, Gianmaria Silvello, Gian Antonio Susto, Juan Carlos De Martin', 'link': 'https://arxiv.org/abs/2502.06439', 'abstract': "Context. As software systems become more integrated into society's infrastructure, the responsibility of software professionals to ensure compliance with various non-functional requirements increases. These requirements include security, safety, privacy, and, increasingly, non-discrimination.\nMotivation. Fairness in pricing algorithms grants equitable access to basic services without discriminating on the basis of protected attributes.\nMethod. We replicate a previous empirical study that used black box testing to audit pricing algorithms used by Italian car insurance companies, accessible through a popular online system. With respect to the previous study, we enlarged the number of tests and the number of demographic variables under analysis.\nResults. Our work confirms and extends previous findings, highlighting the problematic permanence of discrimination across time: demographic variables significantly impact pricing to this day, with birthplace remaining the main discriminatory factor against individuals not born in Italian cities. We also found that driver profiles can determine the number of quotes available to the user, denying equal opportunities to all.\nConclusion. The study underscores the importance of testing for non-discrimination in software systems that affect people's everyday lives. Performing algorithmic audits over time makes it possible to evaluate the evolution of such algorithms. It also demonstrates the role that empirical software engineering can play in making software systems more accountable.", 'abstract_zh': '上下文。随着软件系统越来越多地融入社会基础设施，软件专业人士确保满足各种非功能性要求的责任不断增加。这些要求包括安全、安全、隐私，以及越来越重要的非歧视。\n\n动机。价格算法中的公平性确保基本服务的平等访问，而不过度依赖受保护属性进行歧视。\n\n方法。我们复制了之前的一项实地研究，该研究使用黑盒测试审计意大利汽车保险公司通过一个流行的在线系统使用的定价算法。与之前的研究所相比，我们扩大了测试的范围和分析的种族变量的数量。\n\n结果。我们的研究确认并扩展了先前的研究结果，突出了歧视在时间上的持续性问题：到目前为止，种族变量仍然显著影响价格，出生地仍然是非意大利城市出生的人士的主要歧视因素。我们还发现，驾驶员档案可以决定用户可以获得的报价数量，从而剥夺了一切平等的机会。\n\n结论。该研究强调了在影响人们日常生活软件系统中测试非歧视的重要性。随着时间的推移进行算法审计，可以评估此类算法的发展。它还表明经验软件工程如何使软件系统更具问责性。', 'title_zh': '测试软件是否存在歧视：意大利汽车保险领域更新和扩展的审计'}
{'arxiv_id': 'arXiv:2502.06438', 'title': 'FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model', 'authors': 'Anna Tegon, Thorir Mar Ingolfsson, Xiaying Wang, Luca Benini, Yawei Li', 'link': 'https://arxiv.org/abs/2502.06438', 'abstract': 'Accurate and efficient electroencephalography (EEG) analysis is essential for detecting seizures and artifacts in long-term monitoring, with applications spanning hospital diagnostics to wearable health devices. Robust EEG analytics have the potential to greatly improve patient care. However, traditional deep learning models, especially Transformer-based architectures, are hindered by their quadratic time and memory complexity, making them less suitable for resource-constrained environments. To address these challenges, we present FEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel self-supervised framework that establishes new efficiency benchmarks for EEG analysis through bidirectional state-space modeling. Unlike Transformer-based models, which incur quadratic time and memory complexity, FEMBA scales linearly with sequence length, enabling more scalable and efficient processing of extended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and fine-tuned on three downstream tasks, FEMBA achieves competitive performance in comparison with transformer models, with significantly lower computational cost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB and 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates viability for resource-constrained devices. These results pave the way for scalable, general-purpose EEG analytics in both clinical and highlight FEMBA as a promising candidate for wearable applications.', 'abstract_zh': 'FEMBA：面向EEG分析的双向架构', 'title_zh': 'FEMBA: 高效可扩展的基于双方向Mamba基础模型的脑电图分析'}
{'arxiv_id': 'arXiv:2502.06432', 'title': 'Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single-Image Denoising', 'authors': 'Huaqiu Li, Wang Zhang, Xiaowan Hu, Tao Jiang, Zikang Chen, Haoqian Wang', 'link': 'https://arxiv.org/abs/2502.06432', 'abstract': 'Many studies have concentrated on constructing supervised models utilizing paired datasets for image denoising, which proves to be expensive and time-consuming. Current self-supervised and unsupervised approaches typically rely on blind-spot networks or sub-image pairs sampling, resulting in pixel information loss and destruction of detailed structural information, thereby significantly constraining the efficacy of such methods. In this paper, we introduce Prompt-SID, a prompt-learning-based single image denoising framework that emphasizes preserving of structural details. This approach is trained in a self-supervised manner using downsampled image pairs. It captures original-scale image information through structural encoding and integrates this prompt into the denoiser. To achieve this, we propose a structural representation generation model based on the latent diffusion process and design a structural attention module within the transformer-based denoiser architecture to decode the prompt. Additionally, we introduce a scale replay training mechanism, which effectively mitigates the scale gap from images of different resolutions. We conduct comprehensive experiments on synthetic, real-world, and fluorescence imaging datasets, showcasing the remarkable effectiveness of Prompt-SID.', 'abstract_zh': '基于提示学习的单图像去噪框架：Prompt-SID', 'title_zh': 'Prompt-SID：基于潜在扩散学习结构表示的单图像去噪'}
{'arxiv_id': 'arXiv:2502.06425', 'title': 'Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs', 'authors': 'Hiroki Watanabe, Motonobu Uchikoshi', 'link': 'https://arxiv.org/abs/2502.06425', 'abstract': 'Large language models (LLMs) are increasingly utilized in domains such as finance, healthcare, and interpersonal relationships to provide advice tailored to user traits and contexts. However, this personalization often relies on sensitive data, raising critical privacy concerns and necessitating data minimization. To address these challenges, we propose a framework that integrates zero-knowledge proof (ZKP) technology, specifically zkVM, with LLM-based chatbots. This integration enables privacy-preserving data sharing by verifying user traits without disclosing sensitive information. Our research introduces both an architecture and a prompting strategy for this approach. Through empirical evaluation, we clarify the current constraints and performance limitations of both zkVM and the proposed prompting strategy, thereby demonstrating their practical feasibility in real-world scenarios.', 'abstract_zh': '大型语言模型（LLMs）在金融、医疗和人际关系等领域日益被用于提供个性化的建议，但这种个性化往往依赖于敏感数据，从而引发了重要的隐私问题，需要减少数据暴露。为应对这些挑战，我们提出了一种将零知识证明（ZKP）技术，特别是zkVM，与基于LLM的聊天机器人相结合的框架。这种集成能够通过验证用户特征而不披露敏感信息来实现隐私保护的数据共享。我们的研究介绍了这种方法的体系结构和提示策略。通过实证评估，我们明确了zkVM和提议的提示策略的当前限制和性能局限性，从而证明了它们在实际场景中的实用性。', 'title_zh': '基于零知识证明和大语言模型的隐私保护个性化建议生成'}
{'arxiv_id': 'arXiv:2502.06424', 'title': 'CS-SHAP: Extending SHAP to Cyclic-Spectral Domain for Better Interpretability of Intelligent Fault Diagnosis', 'authors': 'Qian Chen, Xingjian Dong, Kui Hu, Kangkang Chen, Zhike Peng, Guang Meng', 'link': 'https://arxiv.org/abs/2502.06424', 'abstract': 'Neural networks (NNs), with their powerful nonlinear mapping and end-to-end capabilities, are widely applied in mechanical intelligent fault diagnosis (IFD). However, as typical black-box models, they pose challenges in understanding their decision basis and logic, limiting their deployment in high-reliability scenarios. Hence, various methods have been proposed to enhance the interpretability of IFD. Among these, post-hoc approaches can provide explanations without changing model architecture, preserving its flexibility and scalability. However, existing post-hoc methods often suffer from limitations in explanation forms. They either require preprocessing that disrupts the end-to-end nature or overlook fault mechanisms, leading to suboptimal explanations. To address these issues, we derived the cyclic-spectral (CS) transform and proposed the CS-SHAP by extending Shapley additive explanations (SHAP) to the CS domain. CS-SHAP can evaluate contributions from both carrier and modulation frequencies, aligning more closely with fault mechanisms and delivering clearer and more accurate explanations. Three datasets are utilized to validate the superior interpretability of CS-SHAP, ensuring its correctness, reproducibility, and practical performance. With open-source code and outstanding interpretability, CS-SHAP has the potential to be widely adopted and become the post-hoc interpretability benchmark in IFD, even in other classification tasks. The code is available on this https URL.', 'abstract_zh': '神经网络在机械智能故障诊断中的可解释性增强：基于周期谱变换的CS-SHAP方法', 'title_zh': 'CS-SHAP: 将 SHAP 扩展到循环谱域以提高智能故障诊断的可解释性'}
{'arxiv_id': 'arXiv:2502.06415', 'title': 'Systematic Outliers in Large Language Models', 'authors': 'Yongqi An, Xu Zhao, Tao Yu, Ming Tang, Jinqiao Wang', 'link': 'https://arxiv.org/abs/2502.06415', 'abstract': "Outliers have been widely observed in Large Language Models (LLMs), significantly impacting model performance and posing challenges for model compression. Understanding the functionality and formation mechanisms of these outliers is critically important. Existing works, however, largely focus on reducing the impact of outliers from an algorithmic perspective, lacking an in-depth investigation into their causes and roles. In this work, we provide a detailed analysis of the formation process, underlying causes, and functions of outliers in LLMs. We define and categorize three types of outliers-activation outliers, weight outliers, and attention outliers-and analyze their distributions across different dimensions, uncovering inherent connections between their occurrences and their ultimate influence on the attention mechanism. Based on these observations, we hypothesize and explore the mechanisms by which these outliers arise and function, demonstrating through theoretical derivations and experiments that they emerge due to the self-attention mechanism's softmax operation. These outliers act as implicit context-aware scaling factors within the attention mechanism. As these outliers stem from systematic influences, we term them systematic outliers. Our study not only enhances the understanding of Transformer-based LLMs but also shows that structurally eliminating outliers can accelerate convergence and improve model compression. The code is avilable at this https URL.", 'abstract_zh': '大型语言模型中异常值的形成机制、本质原因及功能研究：基于自注意力机制的系统性异常值分析及影响', 'title_zh': '大型语言模型中的系统性离群值'}
{'arxiv_id': 'arXiv:2502.06379', 'title': 'Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo', 'authors': 'Filip Ekström Kelvinius, Zheng Zhao, Fredrik Lindsten', 'link': 'https://arxiv.org/abs/2502.06379', 'abstract': 'A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on ``decoupled diffusion", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic data and image reconstruction tasks. Further, we demonstrate how the approach can be extended to discrete data.', 'abstract_zh': '最近的研究方向利用预训练生成扩散模型作为先验来解决贝叶斯逆问题。我们在此研究方向上做出了贡献，设计了一种基于“解耦扩散”的序列蒙特卡洛方法，用于线性高斯逆问题，该方法允许对样本进行更大规模的更新。该方法在数值上是精确的，并通过合成数据和图像重构任务证明了Decoupled Diffusion Sequential Monte Carlo (DDSMC) 算法的有效性。此外，我们展示了该方法如何扩展到离散数据。', 'title_zh': '解线性高斯贝叶斯逆问题的解耦扩散顺序蒙特卡洛方法'}
{'arxiv_id': 'arXiv:2502.06374', 'title': 'Hyperparameters in Score-Based Membership Inference Attacks', 'authors': 'Gauri Pradhan, Joonas Jälkö, Marlon Tobaben, Antti Honkela', 'link': 'https://arxiv.org/abs/2502.06374', 'abstract': "Membership Inference Attacks (MIAs) have emerged as a valuable framework for evaluating privacy leakage by machine learning models. Score-based MIAs are distinguished, in particular, by their ability to exploit the confidence scores that the model generates for particular inputs. Existing score-based MIAs implicitly assume that the adversary has access to the target model's hyperparameters, which can be used to train the shadow models for the attack. In this work, we demonstrate that the knowledge of target hyperparameters is not a prerequisite for MIA in the transfer learning setting. Based on this, we propose a novel approach to select the hyperparameters for training the shadow models for MIA when the attacker has no prior knowledge about them by matching the output distributions of target and shadow models. We demonstrate that using the new approach yields hyperparameters that lead to an attack near indistinguishable in performance from an attack that uses target hyperparameters to train the shadow models. Furthermore, we study the empirical privacy risk of unaccounted use of training data for hyperparameter optimization (HPO) in differentially private (DP) transfer learning. We find no statistically significant evidence that performing HPO using training data would increase vulnerability to MIA.", 'abstract_zh': '基于迁移学习的成员推理攻击：无需目标模型超参数的知识提出一种新颖的阴影模型超参数选择方法及其隐私风险研究', 'title_zh': '基于分数的成员推断攻击中的超参数研究'}
{'arxiv_id': 'arXiv:2502.06348', 'title': 'AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation', 'authors': 'Bo Gao, Yuan Wang, Qingsong Wei, Yong Liu, Rick Siow Mong Goh', 'link': 'https://arxiv.org/abs/2502.06348', 'abstract': 'Decentralized finance applications depend on accurate price oracles to ensure secure transactions, yet these oracles are highly vulnerable to manipulation, enabling attackers to exploit smart contract vulnerabilities for unfair asset valuation and financial gain. Detecting such manipulations traditionally relies on the manual effort of experienced experts, presenting significant challenges. In this paper, we propose a novel LLM-driven framework that automates the detection of price oracle manipulations by leveraging the complementary strengths of different LLM models. Our approach begins with domain-specific knowledge extraction, where an LLM model synthesizes precise insights about price oracle vulnerabilities from top-tier academic papers, eliminating the need for profound expertise from developers or auditors. This knowledge forms the foundation for a second LLM model to generate structured, context-aware chain of thought prompts, which guide a third LLM model in accurately identifying manipulation patterns in smart contracts. We validate the framework effectiveness through experiments on 60 known vulnerabilities from 46 real-world DeFi attacks or projects spanning 2021 to 2023. The best performing combination of LLMs (Haiku-Haiku-4o-mini) identified by AiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs 0.259) compared to the state-of-the-art tool GPTScan, while maintaining comparable precision. Furthermore, our framework demonstrates the feasibility of replacing commercial models with open-source alternatives, enhancing privacy and security for developers.', 'abstract_zh': '去中心化金融应用依赖于准确的价格预言机以确保安全交易，但这些预言机极易受到操纵，使攻击者能够利用智能合约漏洞进行不公平资产估值和财务获利。传统上，检测此类操纵依赖于经验丰富的专家进行手动努力，存在显著挑战。本文提出了一种新颖的基于LLM的框架，通过利用不同LLM模型的优势互补来自动检测价格预言机操纵。该方法始于领域特定知识提取，其中LLM模型从顶级学术论文中合成关于价格预言机漏洞的精准洞察，从而消除开发人员或审计员对深厚专业知识的需求。这些知识构成了第二个LLM模型生成结构化、上下文相关的思维链提示的基础，引导第三个LLM模型准确识别智能合约中的操纵模式。通过2021年至2023年间46个真实-world DeFi攻击或项目中的60个已知漏洞实验验证了该框架的有效性。由AiRacleX选出的最佳LLM组合（Haiku-Haiku-4o-mini）在召回率上提高了2.58倍（0.667 vs 0.259），同时保持了与最先进的工具GPTScan相当的精确度。此外，该框架证明了可以用开源替代品替换商业模型的可行性，增强了开发者的隐私和安全性。', 'title_zh': 'AiRacleX：通过LLM驱动的知识挖掘和提示生成自动检测价格预言机操纵'}
{'arxiv_id': 'arXiv:2502.06341', 'title': 'Facial Analysis Systems and Down Syndrome', 'authors': 'Marco Rondina, Fabiana Vinci, Antonio Vetrò, Juan Carlos De Martin', 'link': 'https://arxiv.org/abs/2502.06341', 'abstract': 'The ethical, social and legal issues surrounding facial analysis technologies have been widely debated in recent years. Key critics have argued that these technologies can perpetuate bias and discrimination, particularly against marginalized groups. We contribute to this field of research by reporting on the limitations of facial analysis systems with the faces of people with Down syndrome: this particularly vulnerable group has received very little attention in the literature so far. This study involved the creation of a specific dataset of face images. An experimental group with faces of people with Down syndrome, and a control group with faces of people who are not affected by the syndrome. Two commercial tools were tested on the dataset, along three tasks: gender recognition, age prediction and face labelling. The results show an overall lower accuracy of prediction in the experimental group, and other specific patterns of performance differences: i) high error rates in gender recognition in the category of males with Down syndrome; ii) adults with Down syndrome were more often incorrectly labelled as children; iii) social stereotypes are propagated in both the control and experimental groups, with labels related to aesthetics more often associated with women, and labels related to education level and skills more often associated with men. These results, although limited in scope, shed new light on the biases that alter face classification when applied to faces of people with Down syndrome. They confirm the structural limitation of the technology, which is inherently dependent on the datasets used to train the models.', 'abstract_zh': '面部分析技术 Surrounding 的伦理、社会和法律问题已在近年广泛争论。本研究通过报告杜威综合征患者面部图像的局限性，为该领域研究做出了贡献：这一特别脆弱的群体在文献中受到的关注很少。本研究涉及创建特定的面部图像数据集，实验组包括杜威综合征患者的面部图像，对照组包括未受综合征影响的人的面部图像。测试了两种商业工具，进行了三项任务：性别识别、年龄预测和面部标记。结果表明，实验组的整体预测准确性较低，并且存在其他特定的性能差异：I）杜威综合征男性在性别识别中的高错误率；II）杜威综合征成人更常被错误地标注为儿童；III）社会刻板印象在控制组和实验组中普遍存在，与美学相关的标签更常与女性关联，与教育水平和技能相关的标签更常与男性关联。这些结果虽然范围有限，但仍为面部分类应用于杜威综合征患者面部时存在的偏见提供了新的见解，并确认了该技术的结构性限制，该限制在很大程度上依赖于用于训练模型的数据集。', 'title_zh': '面部分析系统与唐氏综合症'}
{'arxiv_id': 'arXiv:2502.06336', 'title': 'DefTransNet: A Transformer-based Method for Non-Rigid Point Cloud Registration in the Simulation of Soft Tissue Deformation', 'authors': 'Sara Monji-Azad, Marvin Kinz, Siddharth Kothari, Robin Khanna, Amrei Carla Mihan, David Maennel, Claudia Scherl, Juergen Hesser', 'link': 'https://arxiv.org/abs/2502.06336', 'abstract': 'Soft-tissue surgeries, such as tumor resections, are complicated by tissue deformations that can obscure the accurate location and shape of tissues. By representing tissue surfaces as point clouds and applying non-rigid point cloud registration (PCR) methods, surgeons can better understand tissue deformations before, during, and after surgery. Existing non-rigid PCR methods, such as feature-based approaches, struggle with robustness against challenges like noise, outliers, partial data, and large deformations, making accurate point correspondence difficult. Although learning-based PCR methods, particularly Transformer-based approaches, have recently shown promise due to their attention mechanisms for capturing interactions, their robustness remains limited in challenging scenarios. In this paper, we present DefTransNet, a novel end-to-end Transformer-based architecture for non-rigid PCR. DefTransNet is designed to address the key challenges of deformable registration, including large deformations, outliers, noise, and partial data, by inputting source and target point clouds and outputting displacement vector fields. The proposed method incorporates a learnable transformation matrix to enhance robustness to affine transformations, integrates global and local geometric information, and captures long-range dependencies among points using Transformers. We validate our approach on four datasets: ModelNet, SynBench, 4DMatch, and DeformedTissue, using both synthetic and real-world data to demonstrate the generalization of our proposed method. Experimental results demonstrate that DefTransNet outperforms current state-of-the-art registration networks across various challenging conditions. Our code and data are publicly available.', 'abstract_zh': '基于Transformer的非刚性点云配准网络DefTransNet：解决变形配准关键挑战', 'title_zh': 'DefTransNet：一种基于变换器的方法，用于软组织变形模拟中的非刚性点云注册'}
{'arxiv_id': 'arXiv:2502.06327', 'title': 'Prompt-Driven Continual Graph Learning', 'authors': 'Qi Wang, Tianfei Zhou, Ye Yuan, Rui Mao', 'link': 'https://arxiv.org/abs/2502.06327', 'abstract': 'Continual Graph Learning (CGL), which aims to accommodate new tasks over evolving graph data without forgetting prior knowledge, is garnering significant research interest. Mainstream solutions adopt the memory replay-based idea, ie, caching representative data from earlier tasks for retraining the graph model. However, this strategy struggles with scalability issues for constantly evolving graphs and raises concerns regarding data privacy. Inspired by recent advancements in the prompt-based learning paradigm, this paper introduces a novel prompt-driven continual graph learning (PROMPTCGL) framework, which learns a separate prompt for each incoming task and maintains the underlying graph neural network model fixed. In this way, PROMPTCGL naturally avoids catastrophic forgetting of knowledge from previous tasks. More specifically, we propose hierarchical prompting to instruct the model from both feature- and topology-level to fully address the variability of task graphs in dynamic continual learning. Additionally, we develop a personalized prompt generator to generate tailored prompts for each graph node while minimizing the number of prompts needed, leading to constant memory consumption regardless of the graph scale. Extensive experiments on four benchmarks show that PROMPTCGL achieves superior performance against existing CGL approaches while significantly reducing memory consumption. Our code is available at this https URL.', 'abstract_zh': '持续图学习（CGL）：基于提示驱动的持续图学习（PROMPTCGL）框架', 'title_zh': '提示驱动的持续图学习'}
{'arxiv_id': 'arXiv:2502.06324', 'title': "UniDemoir\\'e: Towards Universal Image Demoir\\'eing with Data Generation and Synthesis", 'authors': 'Zemin Yang, Yujing Sun, Xidong Peng, Siu Ming Yiu, Yuexin Ma', 'link': 'https://arxiv.org/abs/2502.06324', 'abstract': 'Image demoiréing poses one of the most formidable challenges in image restoration, primarily due to the unpredictable and anisotropic nature of moiré patterns. Limited by the quantity and diversity of training data, current methods tend to overfit to a single moiré domain, resulting in performance degradation for new domains and restricting their robustness in real-world applications. In this paper, we propose a universal image demoiréing solution, UniDemoiré, which has superior generalization capability. Notably, we propose innovative and effective data generation and synthesis methods that can automatically provide vast high-quality moiré images to train a universal demoiréing model. Our extensive experiments demonstrate the cutting-edge performance and broad potential of our approach for generalized image demoiréing.', 'abstract_zh': '图像去moire化是图像恢复领域面临的最严峻挑战之一，主要由于moire图案的不可预测和各向异性性质。受限于训练数据的数量和多样性，当前方法往往只在一个特定的moire领域内过拟合，导致在新的领域中性能下降，并限制了其在实际应用中的鲁棒性。在本文中，我们提出了一种通用的图像去moire解决方案UniDemoiré，具有优异的泛化能力。特别地，我们提出了创新且有效的数据生成和合成方法，能够自动生成大量的高质量moire图像，用于训练一个通用的去moire模型。广泛的实验结果证明了我们方法在通用图像去moire领域的前沿性能和广泛潜力。', 'title_zh': "UniDemoir\\'e: 向通用去moire处理迈进：基于数据生成与合成"}
{'arxiv_id': 'arXiv:2502.06314', 'title': 'From Pixels to Components: Eigenvector Masking for Visual Representation Learning', 'authors': 'Alice Bizeul, Thomas Sutter, Alain Ryser, Bernhard Schölkopf, Julius von Kügelgen, Julia E. Vogt', 'link': 'https://arxiv.org/abs/2502.06314', 'abstract': 'Predicting masked from visible parts of an image is a powerful self-supervised approach for visual representation learning. However, the common practice of masking random patches of pixels exhibits certain failure modes, which can prevent learning meaningful high-level features, as required for downstream tasks. We propose an alternative masking strategy that operates on a suitable transformation of the data rather than on the raw pixels. Specifically, we perform principal component analysis and then randomly mask a subset of components, which accounts for a fixed ratio of the data variance. The learning task then amounts to reconstructing the masked components from the visible ones. Compared to local patches of pixels, the principal components of images carry more global information. We thus posit that predicting masked from visible components involves more high-level features, allowing our masking strategy to extract more useful representations. This is corroborated by our empirical findings which demonstrate improved image classification performance for component over pixel masking. Our method thus constitutes a simple and robust data-driven alternative to traditional masked image modeling approaches.', 'abstract_zh': '从图像可见部分预测掩蔽部分是视觉表示学习的一种强大自监督方法。然而，随机遮掩像素块的常见做法会表现出某些失败模式，这可能阻碍学习用于下游任务所需的意义深远的高级特征。我们提出了一种替代的遮掩策略，该策略在数据的适当变换上操作，而不是在原始像素上操作。具体来说，我们执行主成分分析，然后随机遮掩部分成分，这些成分占固定比例的数据方差。然后的学习任务是从可见部分重建掩蔽的成分。与像素的局部区域相比，图像的主成分包含更多的全局信息。因此，我们认为从可见成分预测掩蔽成分涉及更多的高级特征，使我们的遮掩策略能够提取更有用的表示。我们的实证结果也证实了这一点，即与像素遮掩相比，组件遮掩在图像分类性能上有所提高。因此，我们的方法构成了传统掩蔽图像建模方法的一种简单且稳健的数据驱动替代方案。', 'title_zh': '从像素到组件：特征向量掩码在视觉表示学习中的应用'}
{'arxiv_id': 'arXiv:2502.06298', 'title': 'SeaExam and SeaBench: Benchmarking LLMs with Local Multilingual Questions in Southeast Asia', 'authors': 'Chaoqun Liu, Wenxuan Zhang, Jiahao Ying, Mahani Aljunied, Anh Tuan Luu, Lidong Bing', 'link': 'https://arxiv.org/abs/2502.06298', 'abstract': 'This study introduces two novel benchmarks, SeaExam and SeaBench, designed to evaluate the capabilities of Large Language Models (LLMs) in Southeast Asian (SEA) application scenarios. Unlike existing multilingual datasets primarily derived from English translations, these benchmarks are constructed based on real-world scenarios from SEA regions. SeaExam draws from regional educational exams to form a comprehensive dataset that encompasses subjects such as local history and literature. In contrast, SeaBench is crafted around multi-turn, open-ended tasks that reflect daily interactions within SEA communities. Our evaluations demonstrate that SeaExam and SeaBench more effectively discern LLM performance on SEA language tasks compared to their translated benchmarks. This highlights the importance of using real-world queries to assess the multilingual capabilities of LLMs.', 'abstract_zh': '本研究提出了两个新型基准——SeaExam和SeaBench，旨在评估大型语言模型（LLMs）在东南亚（SEA）应用场景中的能力。与主要源自英译的多语言数据集不同，这些基准是基于东南亚地区的实际应用场景构建的。SeaExam从区域教育考试中抽取数据，形成了涵盖地方历史和文学等主题的全面数据集。相比之下，SeaBench围绕多轮、开放式的任务构建，反映了SEA社区中的日常互动。我们的评估表明，SeaExam和SeaBench比其翻译基准更能有效地区分LLM在SEA语言任务中的表现，这突显了使用真实查询来评估LLM多语言能力的重要性。', 'title_zh': 'SeaExam 和 SeaBench：基于东南亚本地多语言问题的大型语言模型benchmark研究'}
{'arxiv_id': 'arXiv:2502.06289', 'title': 'Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?', 'authors': 'Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh, Ke Zou, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Thaddaeus Lo, Xiaofeng Lei, Siegfried K. Wagner, Mark A. Chia, Dawei Yang, Hongyang Jiang, AnRan Ran, Rui Santos, Gabor Mark Somfai, Juan Helen Zhou, Haoyu Chen, Qingyu Chen, Carol Yim-Lui Cheung, Pearse A. Keane, Yih Chung Tham', 'link': 'https://arxiv.org/abs/2502.06289', 'abstract': 'The advent of foundation models (FMs) is transforming medical domain. In ophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4 million natural images and 1.6 million retinal images, has demonstrated high adaptability across clinical applications. Conversely, DINOv2, a general-purpose vision FM pre-trained on 142 million natural images, has shown promise in non-medical domains. However, its applicability to clinical tasks remains underexplored. To address this, we conducted head-to-head evaluations by fine-tuning RETFound and three DINOv2 models (large, base, small) for ocular disease detection and systemic disease prediction tasks, across eight standardized open-source ocular datasets, as well as the Moorfields AlzEye and the UK Biobank datasets. DINOv2-large model outperformed RETFound in detecting diabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets, all P<=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P<0.001). In glaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940, P<0.001). Conversely, RETFound achieved superior performance over all DINOv2 models in predicting heart failure, myocardial infarction, and ischaemic stroke (AUROC=0.732-0.796 vs 0.663-0.771, all P<0.001). These trends persisted even with 10% of the fine-tuning data. These findings showcase the distinct scenarios where general-purpose and domain-specific FMs excel, highlighting the importance of aligning FM selection with task-specific requirements to optimise clinical performance.', 'abstract_zh': '基础模型的兴起正在变革医疗领域。在眼科领域，RETFound是一种针对黄斑特定的基础模型，依次在140万自然图像和160万视网膜图像上预训练，已经在临床应用中展示了高度的适应性。相反，DINOv2是一种通用视觉基础模型，在1.42亿自然图像上预训练，已经在非医疗领域展现了潜力，但其在临床任务中的应用仍待进一步探索。为解决这一问题，我们通过在八个标准化开源眼科数据集以及Moorfields AlzEye和UK Biobank数据集上对RETFound和三种DINOv2模型（大型、基线、小型）进行微调，进行了头对头的评估。在检测眼疾病和预测全身疾病任务中，DINOv2大型模型在检测糖尿病视网膜病变(AUROC=0.850-0.952 vs 0.823-0.944，所有P≤0.007)和多类别眼疾病(AUROC=0.892 vs 0.846，P<0.001)中表现优于RETFound。在青光眼中，DINOv2基线模型在检测方面优于RETFound(AUROC=0.958 vs 0.940，P<0.001)。相反，在预测心力衰竭、心肌梗死和缺血性中风方面，RETFound优于所有DINOv2模型(AUROC=0.732-0.796 vs 0.663-0.771，所有P<0.001)，即使使用10%的微调数据也是如此。这些发现展示了通用和领域特定基础模型各自的优势场景，强调了根据任务特定要求选择基础模型的重要性，以优化临床表现。', 'title_zh': '基于超大规模自然图像的基础模型是否优于专门针对视网膜的模型，用于检测眼内和全身疾病？'}
{'arxiv_id': 'arXiv:2502.06285', 'title': 'End-to-End Multi-Microphone Speaker Extraction Using Relative Transfer Functions', 'authors': 'Aviad Eisenberg, Sharon Gannot, Shlomo E. Chazan', 'link': 'https://arxiv.org/abs/2502.06285', 'abstract': 'This paper introduces a multi-microphone method for extracting a desired speaker from a mixture involving multiple speakers and directional noise in a reverberant environment. In this work, we propose leveraging the instantaneous relative transfer function (RTF), estimated from a reference utterance recorded in the same position as the desired source. The effectiveness of the RTF-based spatial cue is compared with direction of arrival (DOA)-based spatial cue and the conventional spectral embedding. Experimental results in challenging acoustic scenarios demonstrate that using spatial cues yields better performance than the spectral-based cue and that the instantaneous RTF outperforms the DOA-based spatial cue.', 'abstract_zh': '该文介绍了一种在混响环境中利用多麦克风方法从多说话人混合信号及定向噪声中提取目标说话人的技术。在该项工作中，我们提出利用参考语音在同一位置录制的目标声源的瞬时相对传输函数（RTF）进行提取。实验结果表明，使用空间线索优于基于谱特征的线索，且瞬时RTF优于基于到达角度（DOA）的空间线索。', 'title_zh': '使用相对传输函数的端到端多麦克风说话人提取'}
{'arxiv_id': 'arXiv:2502.06282', 'title': 'Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE', 'authors': 'Haiduo Huang, Fuwei Yang, Zhenhua Liu, Yixing Xu, Jinze Li, Yang Liu, Xuanwu Yin, Dong Li, Pengju Ren, Emad Barsoum', 'link': 'https://arxiv.org/abs/2502.06282', 'abstract': 'Speculative decoding (SD) accelerates large language model inference by using a smaller draft model to predict multiple tokens, which are then verified in parallel by the larger target model. However, the limited capacity of the draft model often necessitates tree-based sampling to improve prediction accuracy, where multiple candidates are generated at each step. We identify a key limitation in this approach: the candidates at the same step are derived from the same representation, limiting diversity and reducing overall effectiveness. To address this, we propose Jakiro, leveraging Mixture of Experts (MoE), where independent experts generate diverse predictions, effectively decoupling correlations among candidates. Furthermore, we introduce a hybrid inference strategy, combining autoregressive decoding for initial tokens with parallel decoding for subsequent stages, and enhance the latter with contrastive mechanism in features to improve accuracy. Our method significantly boosts prediction accuracy and achieves higher inference speedups. Extensive experiments across diverse models validate the effectiveness and robustness of our approach, establishing a new SOTA in speculative decoding. Our codes are available at this https URL.', 'abstract_zh': '投机解码（SD）通过使用较小的草稿模型预测多个令牌来加速大型语言模型的推理，然后由较大的目标模型并行验证这些令牌。然而，草稿模型的有限容量常常需要使用基于树的采样来提高预测准确性，在每一步生成多个候选。我们识别出这种做法的一个关键限制：同一步中的候选来自于相同的表示，限制了多样性和整体有效性。为此，我们提出了Jakiro，并利用专家混合（MoE），其中独立的专家生成多样化的预测，有效地解耦候选之间的关联。此外，我们引入了一种混合推理策略，结合自回归解码进行初始令牌解码，并在后续阶段使用并行解码，通过对比机制增强后者以提高准确性。我们的方法显著提升了预测准确性并实现了更高的推理加速。广泛实验表明，我们的方法在投机解码中具有更高的有效性和鲁棒性，并建立了新的SOTA。我们的代码可在以下链接获取。', 'title_zh': 'Jakiro: 利用解耦多头MoE提升推测解码'}
{'arxiv_id': 'arXiv:2502.06274', 'title': 'HODDI: A Dataset of High-Order Drug-Drug Interactions for Computational Pharmacovigilance', 'authors': 'Zhaoying Wang, Yingdan Shi, Xiang Liu, Can Chen, Jun Wen, Ren Wang', 'link': 'https://arxiv.org/abs/2502.06274', 'abstract': "Drug-side effect research is vital for understanding adverse reactions arising in complex multi-drug therapies. However, the scarcity of higher-order datasets that capture the combinatorial effects of multiple drugs severely limits progress in this field. Existing resources such as TWOSIDES primarily focus on pairwise interactions. To fill this critical gap, we introduce HODDI, the first Higher-Order Drug-Drug Interaction Dataset, constructed from U.S. Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS) records spanning the past decade, to advance computational pharmacovigilance. HODDI contains 109,744 records involving 2,506 unique drugs and 4,569 unique side effects, specifically curated to capture multi-drug interactions and their collective impact on adverse effects. Comprehensive statistical analyses demonstrate HODDI's extensive coverage and robust analytical metrics, making it a valuable resource for studying higher-order drug relationships. Evaluating HODDI with multiple models, we found that simple Multi-Layer Perceptron (MLP) can outperform graph models, while hypergraph models demonstrate superior performance in capturing complex multi-drug interactions, further validating HODDI's effectiveness. Our findings highlight the inherent value of higher-order information in drug-side effect prediction and position HODDI as a benchmark dataset for advancing research in pharmacovigilance, drug safety, and personalized medicine. The dataset and codes are available at this https URL.", 'abstract_zh': '高阶药物相互作用数据集对于理解复杂多药治疗引起的不良反应至关重要。然而，缺乏能够捕捉多种药物组合效果的高阶数据集严重限制了该领域的进展。现有资源如TWOSIDES主要关注双药交互。为填补这一关键空白，我们引入了HODDI，这是首个高阶药物-药物交互数据集，从过去十年美国食品药品监督管理局不良事件报告系统（FAERS）记录中构建，以推进计算性药监科学。HODDI包含涉及2,506种独特药物和4,569种独特不良反应的109,744条记录，特别筛选以捕捉多药交互及其对不良反应的综合影响。全面的统计分析表明HODDI的广泛覆盖范围和稳健的分析指标，使其成为研究高阶药物关系的宝贵资源。评估HODDI时，我们发现简单的多层感知机（MLP）模型可以优于图模型，而超图模型在捕捉复杂多药交互方面表现出更优性能，进一步验证了HODDI的有效性。我们的研究结果强调了高阶信息在药物-不良反应预测中的固有价值，将HODDI定位为药监科学、药物安全和个人化医疗研究的基准数据集。数据集和代码可在以下链接获取。', 'title_zh': 'HODDI：用于计算药 Vigilance 的高阶药物-药物相互作用数据集'}
{'arxiv_id': 'arXiv:2502.06257', 'title': 'K-ON: Stacking Knowledge On the Head Layer of Large Language Model', 'authors': 'Lingbing Guo, Yichi Zhang, Zhongpu Bo, Zhuo Chen, Mengshu Sun, Zhiqiang Zhang, Wen Zhang, Huajun Chen', 'link': 'https://arxiv.org/abs/2502.06257', 'abstract': 'Recent advancements in large language models (LLMs) have significantly improved various natural language processing (NLP) tasks. Typically, LLMs are trained to predict the next token, aligning well with many NLP tasks. However, in knowledge graph (KG) scenarios, entities are the fundamental units and identifying an entity requires at least several tokens. This leads to a granularity mismatch between KGs and natural languages. To address this issue, we propose K-ON, which integrates KG knowledge into the LLM by employing multiple head layers for next k-step prediction. K-ON can not only generate entity-level results in one step, but also enables contrastive loss against entities, which is the most powerful tool in KG representation learning. Experimental results show that K-ON outperforms state-of-the-art methods that incorporate text and even the other modalities.', 'abstract_zh': 'Recent advancements in大型语言模型（LLMs）显著提高了各种自然语言处理（NLP）任务的性能。通常，LLMs被训练以预测下一个令牌，这与许多NLP任务很好地对齐。然而，在知识图谱（KG）场景中，实体是基本单位，并识别一个实体需要至少几个令牌。这导致了KG和自然语言之间的粒度不匹配。为了应对这一问题，我们提出K-ON，通过使用多头层进行下一步预测来将KG知识集成到LLM中。K-ON不仅可以在一步中生成实体级别的结果，还可以启用与实体对比的损失，这是KG表示学习中最强大的工具。实验结果表明，K-ON在包含文本甚至其他模态的最新方法中表现出色。', 'title_zh': 'K-ON: 在大型语言模型的头部层上堆叠知识'}
{'arxiv_id': 'arXiv:2502.06255', 'title': 'Towards Efficient and Intelligent Laser Weeding: Method and Dataset for Weed Stem Detection', 'authors': 'Dingning Liu, Jinzhe Li, Haoyang Su, Bei Cui, Zhihui Wang, Qingbo Yuan, Wanli Ouyang, Nanqing Dong', 'link': 'https://arxiv.org/abs/2502.06255', 'abstract': 'Weed control is a critical challenge in modern agriculture, as weeds compete with crops for essential nutrient resources, significantly reducing crop yield and quality. Traditional weed control methods, including chemical and mechanical approaches, have real-life limitations such as associated environmental impact and efficiency. An emerging yet effective approach is laser weeding, which uses a laser beam as the stem cutter. Although there have been studies that use deep learning in weed recognition, its application in intelligent laser weeding still requires a comprehensive understanding. Thus, this study represents the first empirical investigation of weed recognition for laser weeding. To increase the efficiency of laser beam cut and avoid damaging the crops of interest, the laser beam shall be directly aimed at the weed root. Yet, weed stem detection remains an under-explored problem. We integrate the detection of crop and weed with the localization of weed stem into one end-to-end system. To train and validate the proposed system in a real-life scenario, we curate and construct a high-quality weed stem detection dataset with human annotations. The dataset consists of 7,161 high-resolution pictures collected in the field with annotations of 11,151 instances of weed. Experimental results show that the proposed system improves weeding accuracy by 6.7% and reduces energy cost by 32.3% compared to existing weed recognition systems.', 'abstract_zh': '激光除草中的杂草识别研究：一种综合作物和杂草检测与杂草茎定位的端到端系统', 'title_zh': '面向高效智能激光除草：杂草茎检测的方法与数据集'}
{'arxiv_id': 'arXiv:2502.06249', 'title': 'Conditioning through indifference in quantum mechanics', 'authors': 'Keano De Vos, Gert de Cooman', 'link': 'https://arxiv.org/abs/2502.06249', 'abstract': "We can learn (more) about the state a quantum system is in through measurements. We look at how to describe the uncertainty about a quantum system's state conditional on executing such measurements. We show that by exploiting the interplay between desirability, coherence and indifference, a general rule for conditioning can be derived. We then apply this rule to conditioning on measurement outcomes, and show how it generalises to conditioning on a set of measurement outcomes.", 'abstract_zh': '我们可以通过测量更多地了解量子系统所处的状态。我们研究如何在执行此类测量的前提下描述对量子系统状态的不确定性。我们展示了通过利用可欲性、相干性和无差别性之间的相互作用，可以推导出一般的条件化规则。然后将此规则应用于测量结果的条件化，并展示了它如何推广到一组测量结果的条件化。', 'title_zh': '在量子力学中通过对称性进行条件化'}
{'arxiv_id': 'arXiv:2502.06233', 'title': 'Confidence Improves Self-Consistency in LLMs', 'authors': 'Amir Taubenfeld, Tom Sheffer, Eran Ofek, Amir Feder, Ariel Goldstein, Zorik Gekhman, Gal Yona', 'link': 'https://arxiv.org/abs/2502.06233', 'abstract': "Self-consistency decoding enhances LLMs' performance on reasoning tasks by sampling diverse reasoning paths and selecting the most frequent answer. However, it is computationally expensive, as sampling many of these (lengthy) paths is required to increase the chances that the correct answer emerges as the most frequent one. To address this, we introduce Confidence-Informed Self-Consistency (CISC). CISC performs a weighted majority vote based on confidence scores obtained directly from the model. By prioritizing high-confidence paths, it can identify the correct answer with a significantly smaller sample size. When tested on nine models and four datasets, CISC outperforms self-consistency in nearly all configurations, reducing the required number of reasoning paths by over 40% on average. In addition, we introduce the notion of within-question confidence evaluation, after showing that standard evaluation methods are poor predictors of success in distinguishing correct and incorrect answers to the same question. In fact, the most calibrated confidence method proved to be the least effective for CISC. Lastly, beyond these practical implications, our results and analyses show that LLMs can effectively judge the correctness of their own outputs, contributing to the ongoing debate on this topic.", 'abstract_zh': "Confidence-Informed Self-Consistency Enhances LLMs' Performance on Reasoning Tasks by Prioritizing High-Confidence Paths", 'title_zh': '信心提高LLMs的自我一致性'}
{'arxiv_id': 'arXiv:2502.06217', 'title': 'Examining False Positives under Inference Scaling for Mathematical Reasoning', 'authors': 'Yu Wang, Nan Yang, Liang Wang, Furu Wei', 'link': 'https://arxiv.org/abs/2502.06217', 'abstract': 'Recent advancements in language models have led to significant improvements in mathematical reasoning across various benchmarks. However, most of these benchmarks rely on automatic evaluation methods that only compare final answers using heuristics, without verifying the underlying reasoning steps. This limitation results in false positive solutions, where models may produce correct final answers but with flawed deduction paths. In this paper, we systematically examine the prevalence of false positive solutions in mathematical problem solving for language models. We analyze the characteristics and extent of this issue across different open-source models, datasets of varying difficulty levels, and decoding strategies. Specifically, we explore how false positives influence the inference time scaling behavior of language models. Our experimental results reveal that: (1) false positive solutions persist across different models, datasets, and decoding methods, (2) sampling-based inference time scaling methods do not alleviate the problem, and (3) the pass@N evaluation metric is more susceptible to false positives, suggesting a significantly lower scaling ceiling than what automatic evaluations indicate. Additionally, we analyze specific instances of false positives and discuss potential limitations in self-improvement techniques and synthetic data generation under such conditions.', 'abstract_zh': 'Recent advancements in语言模型在各类基准测试中显著提升了数学推理能力。然而，这些基准测试大多依赖于仅通过启发式方法比较最终答案的自动评估方法，而不验证后续的推理步骤。这一局限性导致了虚假正面解决方案的产生，即模型可能产生正确的最终答案，但推理路径却有误。本文系统地探讨了语言模型在数学问题解决中虚假正面解决方案的普遍性。我们分析了这一问题在不同开源模型、不同难度级别的数据集以及不同解码策略下的特征和影响范围。具体而言，我们探讨了虚假正面解决方案如何影响语言模型的推理时间缩放行为。实验结果表明：（1）虚假正面解决方案在不同的模型、数据集和解码方法中普遍存在；（2）基于采样的推理时间缩放方法未能缓解这一问题；（3）pass@N评估指标更容易受到虚假正面解决方案的影响，表明其缩放上限显著低于自动评估所示。此外，我们分析了虚假正面解决方案的具体实例，并讨论了在这种条件下自我改进技术和合成数据生成可能存在的局限性。', 'title_zh': '考察推理缩放对数学推理中假阳性的影响'}
{'arxiv_id': 'arXiv:2502.06215', 'title': 'LessLeak-Bench: A First Investigation of Data Leakage in LLMs Across 83 Software Engineering Benchmarks', 'authors': 'Xin Zhou, Martin Weyssow, Ratnadira Widyasari, Ting Zhang, Junda He, Yunbo Lyu, Jianming Chang, Beiqi Zhang, Dan Huang, David Lo', 'link': 'https://arxiv.org/abs/2502.06215', 'abstract': "Large Language Models (LLMs) are widely utilized in software engineering (SE) tasks, such as code generation and automated program repair. However, their reliance on extensive and often undisclosed pre-training datasets raises significant concerns about data leakage, where the evaluation benchmark data is unintentionally ``seen'' by LLMs during the model's construction phase. The data leakage issue could largely undermine the validity of LLM-based research and evaluations. Despite the increasing use of LLMs in the SE community, there is no comprehensive study that assesses the extent of data leakage in SE benchmarks for LLMs yet. To address this gap, this paper presents the first large-scale analysis of data leakage in 83 SE benchmarks concerning LLMs. Our results show that in general, data leakage in SE benchmarks is minimal, with average leakage ratios of only 4.8\\%, 2.8\\%, and 0.7\\% for Python, Java, and C/C++ benchmarks, respectively. However, some benchmarks exhibit relatively higher leakage ratios, which raises concerns about their bias in evaluation. For instance, QuixBugs and BigCloneBench have leakage ratios of 100.0\\% and 55.7\\%, respectively. Furthermore, we observe that data leakage has a substantial impact on LLM evaluation. We also identify key causes of high data leakage, such as the direct inclusion of benchmark data in pre-training datasets and the use of coding platforms like LeetCode for benchmark construction. To address the data leakage, we introduce \\textbf{LessLeak-Bench}, a new benchmark that removes leaked samples from the 83 SE benchmarks, enabling more reliable LLM evaluations in future research. Our study enhances the understanding of data leakage in SE benchmarks and provides valuable insights for future research involving LLMs in SE.", 'abstract_zh': '大型语言模型（LLMs）在软件工程（SE）任务中的广泛应用，如代码生成和自动化程序修复。然而，其对大量且 Often Undisclosed 的预训练数据的依赖引发了关于数据泄露的重大关注，即评估基准数据在模型构建阶段意外地被LLMs“看见”。数据泄露问题可能会严重影响基于LLMs的研究和评估的效度。尽管LLMs在SE社区中的应用日益增多，但至今还没有全面研究评估LLMs在SE基准中的数据泄露程度。为弥补这一空白，本文首次对83个涉及LLMs的SE基准进行了大规模的数据泄露分析。结果显示，总体而言，SE基准中的数据泄露程度较低，Python、Java和C/C++基准的数据泄露比例分别为4.8%、2.8%和0.7%。然而，某些基准的数据泄露比例较高，这可能对其评估产生偏见。例如，QuixBugs和BigCloneBench的数据泄露比例分别为100.0%和55.7%。此外，我们还观察到数据泄露对LLMs评估有显著影响。我们还识别了高数据泄露的关键原因，如在预训练数据集中直接包含基准数据以及使用像LeetCode这样的编程平台构建基准。为解决数据泄露问题，我们提出了一个新的基准LessLeak-Bench，该基准从83个SE基准中移除了泄露样本，以在未来的研究中提供更可靠的LLM评估。本研究增强了对SE基准中数据泄露的理解，并为涉及LLMs的未来SE研究提供了宝贵的见解。', 'title_zh': 'LessLeak-基准：对83个软件工程基准中LLM数据泄漏现象的首次探究'}
{'arxiv_id': 'arXiv:2502.06207', 'title': 'Unveiling the Capabilities of Large Language Models in Detecting Offensive Language with Annotation Disagreement', 'authors': 'Junyu Lu, Kai Ma, Kaichun Wang, Kelaiti Xiao, Roy Ka-Wei Lee, Bo Xu, Liang Yang, Hongfei Lin', 'link': 'https://arxiv.org/abs/2502.06207', 'abstract': 'LLMs are widely used for offensive language detection due to their advanced capability. However, the challenges posed by human annotation disagreement in real-world datasets remain underexplored. These disagreement samples are difficult to detect due to their ambiguous nature. Additionally, the confidence of LLMs in processing disagreement samples can provide valuable insights into their alignment with human annotators. To address this gap, we systematically evaluate the ability of LLMs to detect offensive language with annotation disagreement. We compare the binary accuracy of multiple LLMs across varying annotation agreement levels and analyze the relationship between LLM confidence and annotation agreement. Furthermore, we investigate the impact of disagreement samples on LLM decision-making during few-shot learning and instruction fine-tuning. Our findings highlight the challenges posed by disagreement samples and offer guidance for improving LLM-based offensive language detection.', 'abstract_zh': 'LLMs在检测具有标注分歧的冒犯性语言方面的能力评估及其影响研究', 'title_zh': '揭示大语言模型在标注分歧条件下检测冒犯语言的能力'}
{'arxiv_id': 'arXiv:2502.06205', 'title': 'C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation', 'authors': 'Guoxin Chen, Minpeng Liao, Peiying Yu, Dingmin Wang, Zile Qiao, Chao Yang, Xin Zhao, Kai Fan', 'link': 'https://arxiv.org/abs/2502.06205', 'abstract': 'Retrieval-augmented generation (RAG) systems face a fundamental challenge in aligning independently developed retrievers and large language models (LLMs). Existing approaches typically involve modifying either component or introducing simple intermediate modules, resulting in practical limitations and sub-optimal performance. Inspired by human search behavior -- typically involving a back-and-forth process of proposing search queries and reviewing documents, we propose C-3PO, a proxy-centric framework that facilitates communication between retrievers and LLMs through a lightweight multi-agent system. Our framework implements three specialized agents that collaboratively optimize the entire RAG pipeline without altering the retriever and LLMs. These agents work together to assess the need for retrieval, generate effective queries, and select information suitable for the LLMs. To enable effective multi-agent coordination, we develop a tree-structured rollout approach for reward credit assignment in reinforcement learning. Extensive experiments in both in-domain and out-of-distribution scenarios demonstrate that C-3PO significantly enhances RAG performance while maintaining plug-and-play flexibility and superior generalization capabilities.', 'abstract_zh': '基于代理的检索增强生成系统：C-3PO框架', 'title_zh': 'C-3PO: 紧凑型插即用代理优化以实现类人类检索增强生成'}
{'arxiv_id': 'arXiv:2502.06193', 'title': 'Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering', 'authors': 'Ruiqi Wang, Jiyu Guo, Cuiyun Gao, Guodong Fan, Chun Yong Chong, Xin Xia', 'link': 'https://arxiv.org/abs/2502.06193', 'abstract': 'Recently, large language models (LLMs) have been deployed to tackle various software engineering (SE) tasks like code generation, significantly advancing the automation of SE tasks. However, assessing the quality of these LLM-generated code and text remains challenging. The commonly used Pass@k metric necessitates extensive unit tests and configured environments, demands a high labor cost, and is not suitable for evaluating LLM-generated text. Conventional metrics like BLEU, which measure only lexical rather than semantic similarity, have also come under scrutiny. In response, a new trend has emerged to employ LLMs for automated evaluation, known as LLM-as-a-judge. These LLM-as-a-judge methods are claimed to better mimic human assessment than conventional metrics without relying on high-quality reference answers. Nevertheless, their exact human alignment in SE tasks remains unexplored. In this paper, we empirically explore LLM-as-a-judge methods for evaluating SE tasks, focusing on their alignment with human judgments. We select seven LLM-as-a-judge methods that utilize general-purpose LLMs, alongside two LLMs specifically fine-tuned for evaluation. After generating and manually scoring LLM responses on three recent SE datasets of code translation, code generation, and code summarization, we then prompt these methods to evaluate each response. Finally, we compare the scores generated by these methods with human evaluation. The results indicate that output-based methods reach the highest Pearson correlation of 81.32 and 68.51 with human scores in code translation and generation, achieving near-human evaluation, noticeably outperforming ChrF++, one of the best conventional metrics, at 34.23 and 64.92. Such output-based methods prompt LLMs to output judgments directly, and exhibit more balanced score distributions that resemble human score patterns. Finally, we provide...', 'abstract_zh': '近年来，大型语言模型（LLMs）已被部署用于处理软件工程（SE）任务，如代码生成，显著推进了SE任务的自动化。然而，评估这些LLM生成的代码和文本的质量仍然颇具挑战。常用的Pass@k指标需要大量的单元测试和配置环境，成本高昂，并且不适合评估LLM生成的文本。传统的测量词汇相似度而非语义相似度的指标，如BLEU，也受到了质疑。为此，涌现了一种新的趋势，即使用LLM进行自动评估，这种方法被称为“LLM作为裁判”。这些“LLM作为裁判”方法声称比传统指标更接近人类评估，无需依赖高质量的参考答案。然而，它们在SE任务中的精确人类一致性尚未得到探索。本文通过实验研究“LLM作为裁判”方法在SE任务中的应用，重点关注它们与人类判断的一致性。选择了七种利用通用LLM的“LLM作为裁判”方法，以及两种专门针对评估进行微调的LLM。在对三个最新的SE数据集（代码翻译、代码生成和代码摘要）进行生成和手动评分后，我们进一步针对这些方法提请评估每个响应。最后，我们将这些方法生成的评分与人工评估进行比较。结果表明，在代码翻译和生成任务中，基于输出的方法分别获得了与人工评分的皮尔森相关系数81.32和68.51，实现了接近人类的评估，明显优于ChrF++这一表现最佳的传统指标34.23和64.92。基于输出的方法促使LLM直接输出判断，并展现出更平衡的评分分布，更接近人类评分模式。最后，我们提供了...', 'title_zh': 'LLMs能取代人类评估者吗？软件工程中LLM作为法官的实证研究'}
{'arxiv_id': 'arXiv:2502.06192', 'title': 'Right Time to Learn:Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation', 'authors': 'Guanglong Sun, Hongwei Yan, Liyuan Wang, Qian Li, Bo Lei, Yi Zhong', 'link': 'https://arxiv.org/abs/2502.06192', 'abstract': "Knowledge distillation (KD) is a powerful strategy for training deep neural networks (DNNs). Although it was originally proposed to train a more compact ``student'' model from a large ``teacher'' model, many recent efforts have focused on adapting it to promote generalization of the model itself, such as online KD and self KD. % as an effective way Here, we propose an accessible and compatible strategy named Spaced KD to improve the effectiveness of both online KD and self KD, in which the student model distills knowledge from a teacher model trained with a space interval ahead. This strategy is inspired by a prominent theory named \\emph{spacing effect} in biological learning and memory, positing that appropriate intervals between learning trials can significantly enhance learning performance. With both theoretical and empirical analyses, we demonstrate that the benefits of the proposed Spaced KD stem from convergence to a flatter loss landscape during stochastic gradient descent (SGD). We perform extensive experiments to validate the effectiveness of Spaced KD in improving the learning performance of DNNs (e.g., the performance gain is up to 2.31\\% and 3.34\\% on Tiny-ImageNet over online KD and self KD, respectively).", 'abstract_zh': '空间间隔知识蒸馏（Spaced KD）：提高在线知识蒸馏和自我知识蒸馏效果的策略', 'title_zh': '最佳学习时机：通过生物启发的间隔效应在知识蒸馏中促进泛化'}
{'arxiv_id': 'arXiv:2502.06185', 'title': 'Discourse-Driven Evaluation: Unveiling Factual Inconsistency in Long Document Summarization', 'authors': 'Yang Zhong, Diane Litman', 'link': 'https://arxiv.org/abs/2502.06185', 'abstract': 'Detecting factual inconsistency for long document summarization remains challenging, given the complex structure of the source article and long summary length. In this work, we study factual inconsistency errors and connect them with a line of discourse analysis. We find that errors are more common in complex sentences and are associated with several discourse features. We propose a framework that decomposes long texts into discourse-inspired chunks and utilizes discourse information to better aggregate sentence-level scores predicted by natural language inference models. Our approach shows improved performance on top of different model baselines over several evaluation benchmarks, covering rich domains of texts, focusing on long document summarization. This underscores the significance of incorporating discourse features in developing models for scoring summaries for long document factual inconsistency.', 'abstract_zh': '长文档摘要中检测事实不一致仍然具有挑战性，鉴于源文章的复杂结构和长摘要长度。在此工作中，我们研究了事实不一致错误，并将其与论述分析线联系起来。我们发现，错误在复杂句子中更为常见，并与几种论述特征相关。我们提出了一种框架，该框架将长文本分解为受论述启发的块，并利用论述信息来更好地聚合自然语言推理模型预测的句子级别得分。我们的方法在多个评价基准上优于不同的模型基线，涵盖多种文本领域，重点关注长文档摘要。这强调了在开发评分摘要模型以处理长文档事实不一致时整合论述特征的重要性。', 'title_zh': '基于话语驱动的评估：揭示长文档摘要中的事实不一致性'}
{'arxiv_id': 'arXiv:2502.06180', 'title': 'RideKE: Leveraging Low-Resource, User-Generated Twitter Content for Sentiment and Emotion Detection in Kenyan Code-Switched Dataset', 'authors': 'Naome A. Etori, Maria L. Gini', 'link': 'https://arxiv.org/abs/2502.06180', 'abstract': 'Social media has become a crucial open-access platform for individuals to express opinions and share experiences. However, leveraging low-resource language data from Twitter is challenging due to scarce, poor-quality content and the major variations in language use, such as slang and code-switching. Identifying tweets in these languages can be difficult as Twitter primarily supports high-resource languages. We analyze Kenyan code-switched data and evaluate four state-of-the-art (SOTA) transformer-based pretrained models for sentiment and emotion classification, using supervised and semi-supervised methods. We detail the methodology behind data collection and annotation, and the challenges encountered during the data curation phase. Our results show that XLM-R outperforms other models; for sentiment analysis, XLM-R supervised model achieves the highest accuracy (69.2\\%) and F1 score (66.1\\%), XLM-R semi-supervised (67.2\\% accuracy, 64.1\\% F1 score). In emotion analysis, DistilBERT supervised leads in accuracy (59.8\\%) and F1 score (31\\%), mBERT semi-supervised (accuracy (59\\% and F1 score 26.5\\%). AfriBERTa models show the lowest accuracy and F1 scores. All models tend to predict neutral sentiment, with Afri-BERT showing the highest bias and unique sensitivity to empathy emotion. this https URL', 'abstract_zh': '社交媒体已成为个人表达意见和分享经验的重要开放访问平台。然而，由于推特上的低资源语言数据稀缺且质量较差，且语言使用存在极大差异，如俚语和语言转换，因此利用这些语言数据具有挑战性。识别这些语言的推文在推特上主要是支持高资源语言的情况下尤为困难。我们分析了肯尼亚的语言转换数据，并使用监督和半监督方法评估了四种最先进的变压器预训练模型在情感和情绪分类任务中的表现。我们详细介绍了数据收集和标注的方法，以及数据整理阶段遇到的挑战。结果显示，XLM-R表现出色；在情感分析中，XLM-R监督模型的准确率最高（69.2%）和F1分数最高（66.1%），XLM-R半监督模型的准确率为67.2%，F1分为64.1%。在情绪分析中，DistilBERT监督模型在准确率（59.8%）和F1分数（31%）上领先，mBERT半监督模型的准确率为59%，F1分为26.5%，AfriBERTa模型的准确率和F1分数最低。所有模型倾向于预测中性情感，AfriBERTa模型显示出最高的偏见和独特的情感共鸣敏感性。', 'title_zh': 'RideKE：利用低资源用户生成的Twitter内容进行肯尼亚双语转换数据集的情感与情绪检测'}
{'arxiv_id': 'arXiv:2502.06173', 'title': 'Uncertainty-Aware Adaptation of Large Language Models for Protein-Protein Interaction Analysis', 'authors': 'Sanket Jantre, Tianle Wang, Gilchan Park, Kriti Chopra, Nicholas Jeon, Xiaoning Qian, Nathan M. Urban, Byung-Jun Yoon', 'link': 'https://arxiv.org/abs/2502.06173', 'abstract': 'Identification of protein-protein interactions (PPIs) helps derive cellular mechanistic understanding, particularly in the context of complex conditions such as neurodegenerative disorders, metabolic syndromes, and cancer. Large Language Models (LLMs) have demonstrated remarkable potential in predicting protein structures and interactions via automated mining of vast biomedical literature; yet their inherent uncertainty remains a key challenge for deriving reproducible findings, critical for biomedical applications. In this study, we present an uncertainty-aware adaptation of LLMs for PPI analysis, leveraging fine-tuned LLaMA-3 and BioMedGPT models. To enhance prediction reliability, we integrate LoRA ensembles and Bayesian LoRA models for uncertainty quantification (UQ), ensuring confidence-calibrated insights into protein behavior. Our approach achieves competitive performance in PPI identification across diverse disease contexts while addressing model uncertainty, thereby enhancing trustworthiness and reproducibility in computational biology. These findings underscore the potential of uncertainty-aware LLM adaptation for advancing precision medicine and biomedical research.', 'abstract_zh': '基于不确定性意识的大型语言模型在蛋白质-蛋白质相互作用分析中的适应：推动计算生物学的信任度和可重复性', 'title_zh': '面向蛋白质-蛋白质相互作用分析的大语言模型的不确定性意识适应性调整'}
{'arxiv_id': 'arXiv:2502.06170', 'title': 'An Interpretable Implicit-Based Approach for Modeling Local Spatial Effects: A Case Study of Global Gross Primary Productivity', 'authors': 'Siqi Du, Hongsheng Huang, Kaixin Shen, Ziqi Liu, Shengjun Tang', 'link': 'https://arxiv.org/abs/2502.06170', 'abstract': 'In Earth sciences, unobserved factors exhibit non-stationary spatial distributions, causing the relationships between features and targets to display spatial heterogeneity. In geographic machine learning tasks, conventional statistical learning methods often struggle to capture spatial heterogeneity, leading to unsatisfactory prediction accuracy and unreliable interpretability. While approaches like Geographically Weighted Regression (GWR) capture local variations, they fall short of uncovering global patterns and tracking the continuous evolution of spatial heterogeneity. Motivated by this limitation, we propose a novel perspective - that is, simultaneously modeling common features across different locations alongside spatial differences using deep neural networks. The proposed method is a dual-branch neural network with an encoder-decoder structure. In the encoding stage, the method aggregates node information in a spatiotemporal conditional graph using GCN and LSTM, encoding location-specific spatiotemporal heterogeneity as an implicit conditional vector. Additionally, a self-attention-based encoder is used to extract location-invariant common features from the data. In the decoding stage, the approach employs a conditional generation strategy that predicts response variables and interpretative weights based on data features under spatiotemporal conditions. The approach is validated by predicting vegetation gross primary productivity (GPP) using global climate and land cover data from 2001 to 2020. Trained on 50 million samples and tested on 2.8 million, the proposed model achieves an RMSE of 0.836, outperforming LightGBM (1.063) and TabNet (0.944). Visualization analyses indicate that our method can reveal the distribution differences of the dominant factors of GPP across various times and locations.', 'abstract_zh': '在地球科学中，未观察到的因素表现出非平稳的空间分布，导致特征与目标之间的关系显示出空间异质性。在地理机器学习任务中，传统的统计学习方法往往难以捕捉空间异质性，导致预测精度不佳且解释性不可靠。虽然像地理加权回归（GWR）这样的方法能够捕捉局部变化，但它们在揭示全局模式和追踪空间异质性的连续演变方面存在不足。为克服这一局限，我们提出了一个新的视角——利用深度神经网络同时建模不同地点的共同特征和空间差异。所提出的方法是一种具有编码器-解码器结构的双分支神经网络。在编码阶段，该方法使用GCN和LSTM在网络时空条件图中聚合节点信息，将位置特定的时空异质性编码为隐式的条件向量。此外，还使用基于自注意力的编码器从数据中提取位置不变的共同特征。在解码阶段，该方法采用条件生成策略，在时空条件下预测响应变量和解释权重。该方法通过对2001年至2020年全球气候和土地覆盖数据进行植被净初级生产力（GPP）预测得到验证。该模型基于5000万样本训练，并在280万样本上进行测试，取得了RMSE为0.836的结果，优于LightGBM（1.063）和TabNet（0.944）。可视化分析表明，我们的方法能够揭示GPP主导因素在不同时空间分布的差异。', 'title_zh': '基于隐式的方法对局部空间效应的可解释建模：全球初级生产力案例研究'}
{'arxiv_id': 'arXiv:2502.06167', 'title': 'Universal Approximation of Visual Autoregressive Transformers', 'authors': 'Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song', 'link': 'https://arxiv.org/abs/2502.06167', 'abstract': "We investigate the fundamental limits of transformer-based foundation models, extending our analysis to include Visual Autoregressive (VAR) transformers. VAR represents a big step toward generating images using a novel, scalable, coarse-to-fine ``next-scale prediction'' framework. These models set a new quality bar, outperforming all previous methods, including Diffusion Transformers, while having state-of-the-art performance for image synthesis tasks. Our primary contributions establish that, for single-head VAR transformers with a single self-attention layer and single interpolation layer, the VAR Transformer is universal. From the statistical perspective, we prove that such simple VAR transformers are universal approximators for any image-to-image Lipschitz functions. Furthermore, we demonstrate that flow-based autoregressive transformers inherit similar approximation capabilities. Our results provide important design principles for effective and computationally efficient VAR Transformer strategies that can be used to extend their utility to more sophisticated VAR models in image generation and other related areas.", 'abstract_zh': '我们探讨基于变换器的基础模型的基本限制，扩展分析以包括视觉自回归（VAR）变换器。VAR 代表了使用新颖的、可扩展的从粗到细“下一级预测”框架生成图像的一大步。这些模型设定了新的质量标准，优于所有先前的方法，包括扩散变换器，并且在图像合成任务上具有先进的性能。我们主要的贡献表明，对于具有单个自注意力层和单个插值层的单头VAR变换器，VAR变换器是通用的。从统计学角度来看，我们证明了这种简单的VAR变换器是任何图像到图像Lipschitz函数的universal approximator。此外，我们还证明了基于流的自回归变换器继承了类似的影响能力。我们的结果提供了重要的设计原则，用于有效的、计算效率高的VAR变换器策略，这些策略可以被用于扩展其在图像生成和其他相关领域的应用。', 'title_zh': '视觉自回归变换器的通用逼近能力'}
{'arxiv_id': 'arXiv:2502.06153', 'title': 'Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks', 'authors': 'Yihang Gao, Michael K. Ng, Vincent Y.F. Tan', 'link': 'https://arxiv.org/abs/2502.06153', 'abstract': 'Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an alternative to multi-layer perceptions (MLPs) in various domains, especially for science-related tasks. However, transfer learning of KANs remains a relatively unexplored area. In this paper, inspired by Tucker decomposition of tensors and evidence on the low tensor-rank structure in KAN parameter updates, we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study the expressiveness of LoTRA based on Tucker decomposition approximations. Furthermore, we provide a theoretical analysis to select the learning rates for each LoTRA component to enable efficient training. Our analysis also shows that using identical learning rates across all components leads to inefficient training, highlighting the need for an adaptive learning rate strategy. Beyond theoretical insights, we explore the application of LoTRA for efficiently solving various partial differential equations (PDEs) by fine-tuning KANs. Additionally, we propose Slim KANs that incorporate the inherent low-tensor-rank properties of KAN parameter tensors to reduce model size while maintaining superior performance. Experimental results validate the efficacy of the proposed learning rate selection strategy and demonstrate the effectiveness of LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on Slim KANs for function representation and image classification tasks highlight the expressiveness of LoTRA and the potential for parameter reduction through low tensor-rank decomposition.', 'abstract_zh': 'Kolmogorov--Arnold网络（KANs）在各种领域中被证明是多层感知机（MLPs）的潜在替代方案，尤其是在科学任务方面。然而，KANs的迁移学习仍然是一块未充分探索的领域。本文受张量的Tucker分解及其在KAN参数更新中低张量秩结构证据的启发，我们开发了低张量秩适应（LoTRA）方法以对KANs进行微调。我们基于Tucker分解近似研究了LoTRA的表达能力，并提供了理论分析以选择每个LoTRA组件的适学习率以实现高效训练。我们的分析表明，所有组件使用相同的适学习率会导致训练效率低下，突显了适应性学习率策略的必要性。除了理论见解，我们还研究了LoTRA在通过微调KANs高效求解各种偏微分方程（PDEs）中的应用。此外，我们提出了Slim KANs，结合了KAN参数张量的固有低张量秩特性，以减小模型大小同时保持优异性能。实验结果验证了所提出的适学习率选择策略的有效性，并展示了LoTRA在KANs迁移学习中解决PDEs的有效性。进一步对Slim KANs用于函数表示和图像分类任务的评估强调了LoTRA的表达能力及其通过低张量秩分解减少参数量的潜力。', 'title_zh': 'Kolmogorov-Arnold网络的低张量秩适应'}
{'arxiv_id': 'arXiv:2502.06151', 'title': 'Powerformer: A Transformer with Weighted Causal Attention for Time-series Forecasting', 'authors': 'Kareem Hegazy, Michael W. Mahoney, N. Benjamin Erichson', 'link': 'https://arxiv.org/abs/2502.06151', 'abstract': "Transformers have recently shown strong performance in time-series forecasting, but their all-to-all attention mechanism overlooks the (temporal) causal and often (temporally) local nature of data. We introduce Powerformer, a novel Transformer variant that replaces noncausal attention weights with causal weights that are reweighted according to a smooth heavy-tailed decay. This simple yet effective modification endows the model with an inductive bias favoring temporally local dependencies, while still allowing sufficient flexibility to learn the unique correlation structure of each dataset. Our empirical results demonstrate that Powerformer not only achieves state-of-the-art accuracy on public time-series benchmarks, but also that it offers improved interpretability of attention patterns. Our analyses show that the model's locality bias is amplified during training, demonstrating an interplay between time-series data and power-law-based attention. These findings highlight the importance of domain-specific modifications to the Transformer architecture for time-series forecasting, and they establish Powerformer as a strong, efficient, and principled baseline for future research and real-world applications.", 'abstract_zh': 'Powerformer：一种基于功率衰减的因果注意力机制的时间序列预测Transformer变体', 'title_zh': 'Powerformer：一种用于时间序列预测的加权因果注意力变换器'}
{'arxiv_id': 'arXiv:2502.06146', 'title': 'Guided Exploration for Efficient Relational Model Learning', 'authors': 'Annie Feng, Nishanth Kumar, Tomas Lozano-Perez, Leslie Pack-Kaelbling', 'link': 'https://arxiv.org/abs/2502.06146', 'abstract': 'Efficient exploration is critical for learning relational models in large-scale environments with complex, long-horizon tasks. Random exploration methods often collect redundant or irrelevant data, limiting their ability to learn accurate relational models of the environment. Goal-literal babbling (GLIB) improves upon random exploration by setting and planning to novel goals, but its reliance on random actions and random novel goal selection limits its scalability to larger domains. In this work, we identify the principles underlying efficient exploration in relational domains: (1) operator initialization with demonstrations that cover the distinct lifted effects necessary for planning and (2) refining preconditions to collect maximally informative transitions by selecting informative goal-action pairs and executing plans to them. To demonstrate these principles, we introduce Baking-Large, a challenging domain with extensive state-action spaces and long-horizon tasks. We evaluate methods using oracle-driven demonstrations for operator initialization and precondition-targeting guidance to efficiently gather critical transitions. Experiments show that both the oracle demonstrations and precondition-targeting oracle guidance significantly improve sample efficiency and generalization, paving the way for future methods to use these principles to efficiently learn accurate relational models in complex domains.', 'abstract_zh': '高效探索对于大规模环境中复杂、长期任务的学习关系模型至关重要。随机探索方法通常收集冗余或无关的数据，限制了它们学习环境准确关系模型的能力。目标实义 babbling (GLIB) 通过设定并将计划应用于新颖目标来改进随机探索，但其依赖于随机动作和随机新颖目标的选择限制了其在更大领域的规模化应用。在本文中，我们确定了关系领域高效探索的基本原则：(1) 通过涵盖规划所需的不同提升效果的示范进行操作初始化；(2) 通过选择具有信息性的目标-动作对并执行计划来收集最具有信息性的转换来细化先决条件。为了证明这些原则，我们引入了 Baking-Large，这是一个具有广泛状态-动作空间和长期任务的具有挑战性的领域。我们使用启发式驱动的示范进行操作初始化，并使用先决条件目标朝向指导来高效地收集关键转换。实验结果显示，启发式示范和先决条件目标朝向启发式指导显著提高了样本效率和泛化能力，为未来方法利用这些原则在复杂领域高效地学习准确的关系模型铺平了道路。', 'title_zh': '引导探索以实现高效关系模型学习'}
{'arxiv_id': 'arXiv:2502.06136', 'title': 'Graph Neural Networks at a Fraction', 'authors': 'Rucha Bhalchandra Joshi, Sagar Prakash Barad, Nidhi Tiwari, Subhankar Mishra', 'link': 'https://arxiv.org/abs/2502.06136', 'abstract': 'Graph Neural Networks (GNNs) have emerged as powerful tools for learning representations of graph-structured data. In addition to real-valued GNNs, quaternion GNNs also perform well on tasks on graph-structured data. With the aim of reducing the energy footprint, we reduce the model size while maintaining accuracy comparable to that of the original-sized GNNs. This paper introduces Quaternion Message Passing Neural Networks (QMPNNs), a framework that leverages quaternion space to compute node representations. Our approach offers a generalizable method for incorporating quaternion representations into GNN architectures at one-fourth of the original parameter count. Furthermore, we present a novel perspective on Graph Lottery Tickets, redefining their applicability within the context of GNNs and QMPNNs. We specifically aim to find the initialization lottery from the subnetwork of the GNNs that can achieve comparable performance to the original GNN upon training. Thereby reducing the trainable model parameters even further. To validate the effectiveness of our proposed QMPNN framework and LTH for both GNNs and QMPNNs, we evaluate their performance on real-world datasets across three fundamental graph-based tasks: node classification, link prediction, and graph classification.', 'abstract_zh': 'Quaternion消息传递神经网络（QMPNNs）：一种四元数空间中的节点表示框架及GNN剪枝的新视角', 'title_zh': '图神经网络 fractions 代价'}
{'arxiv_id': 'arXiv:2502.06134', 'title': 'Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning', 'authors': 'Liuqing Chen, Shuhong Xiao, Shixian Ding, Shanhai Hu, Lingyun Sun', 'link': 'https://arxiv.org/abs/2502.06134', 'abstract': 'Medical time series are often irregular and face significant missingness, posing challenges for data analysis and clinical decision-making. Existing methods typically adopt a single modeling perspective, either treating series data as sequences or transforming them into image representations for further classification. In this paper, we propose a joint learning framework that incorporates both sequence and image representations. We also design three self-supervised learning strategies to facilitate the fusion of sequence and image representations, capturing a more generalizable joint representation. The results indicate that our approach outperforms seven other state-of-the-art models in three representative real-world clinical datasets. We further validate our approach by simulating two major types of real-world missingness through leave-sensors-out and leave-samples-out techniques. The results demonstrate that our approach is more robust and significantly surpasses other baselines in terms of classification performance.', 'abstract_zh': '医学时间序列数据往往不规则且存在严重的数据缺失，这对数据分析和临床决策构成了挑战。现有方法通常从单一建模视角出发，要么将序列数据视为序列，要么将其转换为图像表示以进行进一步的分类。本文提出了一种结合序列和图像表示的联合学习框架，并设计了三种自监督学习策略以促进序列和图像表示的融合，捕获更具泛化能力的联合表示。实验结果表明，本文方法在三个代表性的临床数据集中优于七个最先进的模型。我们还通过留传感器法和留样本法模拟了两种主要的真实世界缺失性，进一步验证了本文方法。结果表明，本文方法在分类性能上更具鲁棒性，并显著优于其他基线方法。', 'title_zh': '通过自我监督学习将序列模型与图像模型集成到不规则医疗时间序列中'}
{'arxiv_id': 'arXiv:2502.06127', 'title': 'Improved YOLOv5s model for key components detection of power transmission lines', 'authors': 'Chen Chen, Guowu Yuan, Hao Zhou, Yi Ma', 'link': 'https://arxiv.org/abs/2502.06127', 'abstract': "High-voltage transmission lines are located far from the road, resulting in inconvenient inspection work and rising maintenance costs. Intelligent inspection of power transmission lines has become increasingly important. However, subsequent intelligent inspection relies on accurately detecting various key components. Due to the low detection accuracy of key components in transmission line image inspection, this paper proposed an improved object detection model based on the YOLOv5s (You Only Look Once Version 5 Small) model to improve the detection accuracy of key components of transmission lines. According to the characteristics of the power grid inspection image, we first modify the distance measurement in the k-means clustering to improve the anchor matching of the YOLOv5s model. Then, we add the convolutional block attention module (CBAM) attention mechanism to the backbone network to improve accuracy. Finally, we apply the focal loss function to reduce the impact of class imbalance. Our improved method's mAP (mean average precision) reached 98.1%, the precision reached 97.5%, the recall reached 94.4%, and the detection rate reached 84.8 FPS (frames per second). The experimental results show that our improved model improves detection accuracy and has performance advantages over other models.", 'abstract_zh': '高压输电线路远离道路，导致检修不便且维护成本上升。基于YOLOv5s的智能输电线路检测方法及其应用', 'title_zh': '改进的YOLOv5s模型在输电线路关键组件检测中的应用'}
{'arxiv_id': 'arXiv:2502.06124', 'title': 'Foundation Model of Electronic Medical Records for Adaptive Risk Estimation', 'authors': 'Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek', 'link': 'https://arxiv.org/abs/2502.06124', 'abstract': 'We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS), an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS predicts future PHTs using transformer-based architectures. The Adaptive Risk Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk probabilities for clinician-defined critical events. ARES incorporates a personalized explainability module that identifies key clinical factors influencing risk estimates for individual patients. ARES was evaluated on the MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its performance against traditional early warning systems and machine learning models. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs, with 60% including hospital admissions. The dataset contained over 357 million tokens. ETHOS outperformed benchmark models in predicting hospital admissions, ICU admissions, and prolonged hospital stays, achieving superior AUC scores. ETHOS-based risk estimates demonstrated robustness across demographic subgroups with strong model reliability, confirmed via calibration curves. The personalized explainability module provides insights into patient-specific factors contributing to risk. ARES, powered by ETHOS, advances predictive healthcare AI by providing dynamic, real-time, and personalized risk estimation with patient-specific explainability to enhance clinician trust. Its adaptability and superior accuracy position it as a transformative tool for clinical decision-making, potentially improving patient outcomes and resource allocation in emergency and inpatient settings. We release the full code at this http URL to facilitate future research.', 'abstract_zh': '我们开发了健康结局模拟增强变压器模型（ETHOS），这是一种AI模型，用于将电子健康记录（EHRs）中的患者健康时间线（PHTs）进行标记化。ETHOS使用基于变换器的架构来预测未来的PHTs。自适应风险估计系统（ARES）利用ETHOS计算由临床医生定义的关键事件的动态和个性化风险概率。ARES结合了一个个性化可解释性模块，用于识别影响个别患者风险估计的关键临床因素。ARES在包含紧急部门（ED）设置的MIMIC-IV v2.2数据集中进行了评估，将其性能与传统的早期预警系统和机器学习模型进行了对比。我们从MIMIC-IV中处理了299,721名独特患者，生成了285,622个PHTs，其中60%包括医院入院记录，数据集包含超过3.57亿个标记。ETHOS在预测医院入院、ICU入院和住院时间方面优于基准模型，取得了更好的AUC分数。基于ETHOS的风险估计在不同人口统计亚组中表现出色，具有强大的模型可靠性，这一点通过校准曲线得到了证实。个性化可解释性模块提供了有关患者特定因素对风险影响的见解。ARES通过提供动态、实时和个性化风险估计以及患者特定的可解释性，成为增强临床信任的先进预测医疗AI工具。其高度可适应性和卓越的准确度使其成为临床决策的变革性工具，有望改善紧急和住院设置中的患者结果和资源分配。我们在此网址发布完整代码以促进未来研究。', 'title_zh': '电子医疗记录的适应性风险估计基础模型'}
{'arxiv_id': 'arXiv:2502.06117', 'title': 'Revisiting Dynamic Graph Clustering via Matrix Factorization', 'authors': 'Dongyuan Li, Satoshi Kosugi, Ying Zhang, Manabu Okumura, Feng Xia, Renhe Jiang', 'link': 'https://arxiv.org/abs/2502.06117', 'abstract': 'Dynamic graph clustering aims to detect and track time-varying clusters in dynamic graphs, revealing the evolutionary mechanisms of complex real-world dynamic systems. Matrix factorization-based methods are promising approaches for this task; however, these methods often struggle with scalability and can be time-consuming when applied to large-scale dynamic graphs. Moreover, they tend to lack robustness and are vulnerable to real-world noisy data. To address these issues, we make three key contributions. First, to improve scalability, we propose temporal separated matrix factorization, where a single matrix is divided into multiple smaller matrices for independent factorization, resulting in faster computation. Second, to improve robustness, we introduce bi-clustering regularization, which jointly optimizes graph embedding and clustering, thereby filtering out noisy features from the graph embeddings. Third, to further enhance effectiveness and efficiency, we propose selective embedding updating, where we update only the embeddings of dynamic nodes while the embeddings of static nodes are fixed among different timestamps. Experimental results on six synthetic and five real-world benchmarks demonstrate the scalability, robustness and effectiveness of our proposed method. Source code is available at this https URL.', 'abstract_zh': '动态图聚类旨在检测和追踪动态图中的时间变化聚类，揭示复杂现实动态系统的演化机制。基于矩阵分解的方法是这一任务有前途的途径；然而，这些方法通常在处理大规模动态图时面临扩展性问题，并且计算耗时。此外，它们往往缺乏 robustness，容易受到现实世界噪声数据的影响。为了解决这些问题，我们做出了三项关键贡献。首先，为了提高扩展性，我们提出了时间分离的矩阵分解方法，即将一个矩阵分解为多个较小的矩阵进行独立分解，从而加快计算速度。其次，为了提高 robustness，我们引入了双聚类正则化，该方法通过同时优化图嵌入和聚类，从而从图嵌入中过滤出噪声特征。最后，为了进一步提高有效性和效率，我们提出了选择性嵌入更新方法，在不同时间戳上仅更新动态节点的嵌入，而静态节点的嵌入保持固定。在六个合成数据集和五个真实世界数据集上的实验结果证明了我们提出方法的扩展性、robustness和有效性。相关源代码可在以下链接获取。', 'title_zh': '基于矩阵分解 revisit 动态图聚类'}
{'arxiv_id': 'arXiv:2502.06111', 'title': 'CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories', 'authors': 'Yijia Xiao, Runhui Wang, Luyang Kong, Davor Golac, Wei Wang', 'link': 'https://arxiv.org/abs/2502.06111', 'abstract': 'The increasing complexity of computer science research projects demands more effective tools for deploying code repositories. Large Language Models (LLMs), such as Anthropic Claude and Meta Llama, have demonstrated significant advancements across various fields of computer science research, including the automation of diverse software engineering tasks. To evaluate the effectiveness of LLMs in handling complex code development tasks of research projects, particularly for NLP/CV/AI/ML/DM topics, we introduce CSR-Bench, a benchmark for Computer Science Research projects. This benchmark assesses LLMs from various aspects including accuracy, efficiency, and deployment script quality, aiming to explore their potential in conducting computer science research autonomously. We also introduce a novel framework, CSR-Agents, that utilizes multiple LLM agents to automate the deployment of GitHub code repositories of computer science research projects. Specifically, by checking instructions from markdown files and interpreting repository structures, the model generates and iteratively improves bash commands that set up the experimental environments and deploy the code to conduct research tasks. Preliminary results from CSR-Bench indicate that LLM agents can significantly enhance the workflow of repository deployment, thereby boosting developer productivity and improving the management of developmental workflows.', 'abstract_zh': '计算机科学研究项目日益增加的复杂性催生了对更有效代码仓库部署工具的需求。大型语言模型（LLMs），如Anthropic Claude和Meta Llama，在计算机科学研究的各个领域，包括软件工程任务的自动化方面，已经显示出显著的进步。为了评估LLMs在处理计算机科学研究项目中的复杂代码开发任务的有效性，特别是针对自然语言处理（NLP）、计算机视觉（CV）、人工智能（AI）、机器学习（ML）、数据挖掘（DM）等主题，我们引入了CSR-Bench——一个计算机科学研究项目的基准测试。该基准测试从准确性、效率和部署脚本质量等多个方面评估LLMs，旨在探索其在自主进行计算机科学研究方面的潜力。我们还引入了CSR-Agents这一新颖框架，利用多个LLM代理来自动化计算机科学研究项目GitHub代码仓库的部署。具体来说，该模型通过检查来自Markdown文件的指令并解释代码仓库结构，生成并迭代改进用于设置实验环境和部署代码的bash命令，以执行研究任务。CSR-Bench的初步结果显示，LLM代理能够显著提升仓库部署的工作流程，从而提高开发人员的生产力并改善开发工作流程的管理。', 'title_zh': 'CSR-Bench: 计算机科学研究仓库部署中LLM代理的基准测试'}
{'arxiv_id': 'arXiv:2502.06106', 'title': 'Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks', 'authors': 'Yueyan Li, Caixia Yuan, Xiaojie Wang', 'link': 'https://arxiv.org/abs/2502.06106', 'abstract': 'The study of mechanistic interpretability aims to reverse-engineer a model to explain its behaviors. While recent studies have focused on the static mechanism of a certain behavior, the training dynamics inside a model remain to be explored. In this work, we develop an interpretable method for fine-tuning and reveal the mechanism behind learning. We first propose the concept of node redundancy as an extension of intrinsic dimension and explain the idea behind circuit discovery from a fresh view. Based on the theory, we propose circuit-tuning, a two-stage algorithm that iteratively performs circuit discovery to mask out irrelevant edges and updates the remaining parameters responsible for a specific task. Experiments show that our method not only improves performance on a wide range of tasks but is also scalable while preserving general capabilities. We visualize and analyze the circuits before, during, and after fine-tuning, providing new insights into the self-organization mechanism of a neural network in the learning process.', 'abstract_zh': '机制可解释性研究旨在逆向工程模型以解释其行为。虽然近期的研究主要关注特定行为的静态机制，但模型内的训练动力学仍有待探索。在这项工作中，我们开发了一种可解释的方法进行微调，并揭示了学习背后的机制。我们首先提出了节点冗余的概念，将其作为固有维度的拓展，并从新视角解释了电路发现的想法。基于这一理论，我们提出了电路微调，这是一种两阶段算法，通过迭代进行电路发现以屏蔽无关边，并更新负责特定任务的剩余参数。实验表明，我们的方法不仅在多种任务上提高了性能，而且在保持通用能力的同时具有可扩展性。我们在微调前后可视化并分析电路，提供了对神经网络在学习过程中自组织机制的新见解。', 'title_zh': '电路调谐：一种机理方法用于识别参数冗余和精细调整神经网络'}
{'arxiv_id': 'arXiv:2502.06105', 'title': 'Comprehensive Framework for Evaluating Conversational AI Chatbots', 'authors': 'Shailja Gupta, Rajesh Ranjan, Surya Narayan Singh', 'link': 'https://arxiv.org/abs/2502.06105', 'abstract': 'Conversational AI chatbots are transforming industries by streamlining customer service, automating transactions, and enhancing user engagement. However, evaluating these systems remains a challenge, particularly in financial services, where compliance, user trust, and operational efficiency are critical. This paper introduces a novel evaluation framework that systematically assesses chatbots across four dimensions: cognitive and conversational intelligence, user experience, operational efficiency, and ethical and regulatory compliance. By integrating advanced AI methodologies with financial regulations, the framework bridges theoretical foundations and real-world deployment challenges. Additionally, we outline future research directions, emphasizing improvements in conversational coherence, real-time adaptability, and fairness.', 'abstract_zh': '基于对话的AI聊天机器人正通过简化客户服务、自动化交易和增强用户参与度来改造各行各业。然而，在金融服务业中，合规性、用户信任和运营效率至关重要，这使得评估这些系统成为一个挑战。本文提出了一种新的评估框架，系统地从四大维度评估聊天机器人：认知和对话智能、用户体验、运营效率以及伦理和法规合规性。通过整合先进的AI方法与金融监管，该框架弥合了理论基础与实际部署挑战之间的差距。此外，我们还概述了未来的研究方向，强调提高对话连贯性、实时适应性和公平性。', 'title_zh': '综合评价对话式AI聊天机器人框架'}
{'arxiv_id': 'arXiv:2502.06097', 'title': 'NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized Recommendation Systems', 'authors': 'Shuli Wang, Xue Wei, Senjie Kou, Chi Wang, Wenshuai Chen, Qi Tang, Yinhua Zhu, Xiong Xiao, Xingxing Wang', 'link': 'https://arxiv.org/abs/2502.06097', 'abstract': "Reranking plays a crucial role in modern multi-stage recommender systems by rearranging the initial ranking list. Due to the inherent challenges of combinatorial search spaces, some current research adopts an evaluator-generator paradigm, with a generator generating feasible sequences and an evaluator selecting the best sequence based on the estimated list utility. However, these methods still face two issues. Firstly, due to the goal inconsistency problem between the evaluator and generator, the generator tends to fit the local optimal solution of exposure distribution rather than combinatorial space optimization. Secondly, the strategy of generating target items one by one is difficult to achieve optimality because it ignores the information of subsequent items.\nTo address these issues, we propose a utilizing Neighbor Lists model for Generative Reranking (NLGR), which aims to improve the performance of the generator in the combinatorial space. NLGR follows the evaluator-generator paradigm and improves the generator's training and generating methods. Specifically, we use neighbor lists in combination space to enhance the training process, making the generator perceive the relative scores and find the optimization direction. Furthermore, we propose a novel sampling-based non-autoregressive generation method, which allows the generator to jump flexibly from the current list to any neighbor list. Extensive experiments on public and industrial datasets validate NLGR's effectiveness and we have successfully deployed NLGR on the Meituan food delivery platform.", 'abstract_zh': '利用邻近列表的生成重排序模型（NLGR）', 'title_zh': 'NLGR：利用邻居列表进行个性化推荐系统中的生成式重排序'}
{'arxiv_id': 'arXiv:2502.06096', 'title': 'Post-detection inference for sequential changepoint localization', 'authors': 'Aytijhya Saha, Aaditya Ramdas', 'link': 'https://arxiv.org/abs/2502.06096', 'abstract': 'This paper addresses a fundamental but largely unexplored challenge in sequential changepoint analysis: conducting inference following a detected change. We study the problem of localizing the changepoint using only the data observed up to a data-dependent stopping time at which a sequential detection algorithm $\\mathcal A$ declares a change. We first construct confidence sets for the unknown changepoint when pre- and post-change distributions are assumed to be known. We then extend our framework to composite pre- and post-change scenarios. We impose no conditions on the observation space or on $\\mathcal A$ -- we only need to be able to run $\\mathcal A$ on simulated data sequences. In summary, this work offers both theoretically sound and practically effective tools for sequential changepoint localization.', 'abstract_zh': '这篇论文解决了序列变化点分析中一个基本但尚未充分探索的挑战：在检测到变化之后进行推断。我们研究了仅使用在数据依赖性停止时间之前观察到的数据来定位变化点的问题，此时序列检测算法$\\mathcal A$宣布检测到变化。首先，我们假设变化前后的分布已知，构建未知变化点的置信集。然后，我们将框架扩展到复合变化前后的场景。我们对观测空间和算法$\\mathcal A$没有任何假设——只需能够在模拟数据序列上运行$\\mathcal A$即可。总之，这项工作提供了既符合理论又实用有效的工具，用于序列变化点定位。', 'title_zh': '检测后序贯变化点定位的后推 inference'}
{'arxiv_id': 'arXiv:2502.06095', 'title': 'Rateless Joint Source-Channel Coding, and a Blueprint for 6G Semantic Communications System Design', 'authors': 'Saeed R. Khosravirad', 'link': 'https://arxiv.org/abs/2502.06095', 'abstract': "This paper introduces rateless joint source-channel coding (rateless JSCC). The code is rateless in that it is designed and optimized for a continuum of coding rates such that it achieves a desired distortion for any rate in that continuum. We further introduce rate-adaptive and stable communication link operation to accommodate rateless JSCCs. The link operation resembles a ``bit pipe'' that is identified by its rate in bits per frame, and, by the rate of bits that are flipped in each frame. Thus, the link operation is rate-adaptive such that it punctures the rateless JSCC codeword to adapt its length (and coding rate) to the underlying channel capacity, and is stable in maintaining the bit flipping ratio across time frames.\nNext, a new family of autoencoder rateless JSCC codes are introduced. The code family is dubbed RLACS code (read as relax code, standing for ratelss and lossy autoencoder channel and source code). The code is tested for reconstruction loss of image signals and demonstrates powerful performance that is resilient to variation of channel quality. RLACS code is readily applicable to the case of semantic distortion suited to variety of semantic and effectiveness communications use cases.\nIn the second part of the paper, we dive into the practical concerns around semantic communication and provide a blueprint for semantic networking system design relying on updating the existing network systems with some essential modifications. We further outline a comprehensive list of open research problems and development challenges towards a practical 6G communications system design that enables semantic networking.", 'abstract_zh': '本文介绍了一种无率联源信道编码（无率联合源信道编码，rateless JSCC）。该编码设计并优化为适用于一系列连续的编码速率，使其能够在该系列中的任何速率下达到所需的失真度。我们进一步介绍了适应速率和稳定的通信链路操作，以适应无率JSCC。链路操作类似于“位管道”，其传输速率由每帧传输的位数和每帧翻转的位数来定义。因此，链路操作是适应速率的，它通过对无率JSCC码字进行刺穿来调整其长度（和编码速率），并保持跨时间帧的位翻转比例的稳定性。\n接下来，我们引入了一种新的自编码器无率联源信道编码系列。该编码系列被称为RLACS码（读作relax码，代表无率和失真的自编码器信道和源码）。该编码被测试用于图像信号的重构损失，并展现了对信道质量变化具有强大鲁棒性的性能。RLACS码适用于适应性失真场景，适用于多种语义和有效性通信使用场景。\n在论文的第二部分，我们探讨了语义通信的实际关切，并提供了依赖于对现有网络系统进行一些必要修改的语义网络系统设计的蓝图。我们进一步列出了针对实际6G通信系统设计以实现语义网络的开放研究问题和开发挑战。', 'title_zh': '无逸联合源信道编码，以及六 generation语义通信系统设计蓝图'}
{'arxiv_id': 'arXiv:2502.06084', 'title': 'Physics-Guided Foundation Model for Scientific Discovery: An Application to Aquatic Science', 'authors': 'Runlong Yu, Chonghao Qiu, Robert Ladwig, Paul Hanson, Yiqun Xie, Xiaowei Jia', 'link': 'https://arxiv.org/abs/2502.06084', 'abstract': 'Physics-guided machine learning (PGML) has become a prevalent approach in studying scientific systems due to its ability to integrate scientific theories for enhancing machine learning (ML) models. However, most PGML approaches are tailored to isolated and relatively simple tasks, which limits their applicability to complex systems involving multiple interacting processes and numerous influencing features. In this paper, we propose a \\textit{\\textbf{P}hysics-\\textbf{G}uided \\textbf{F}oundation \\textbf{M}odel (\\textbf{PGFM})} that combines pre-trained ML models and physics-based models and leverages their complementary strengths to improve the modeling of multiple coupled processes. To effectively conduct pre-training, we construct a simulated environmental system that encompasses a wide range of influencing features and various simulated variables generated by physics-based models. The model is pre-trained in this system to adaptively select important feature interactions guided by multi-task objectives. We then fine-tune the model for each specific task using true observations, while maintaining consistency with established physical theories, such as the principles of mass and energy conservation. We demonstrate the effectiveness of this methodology in modeling water temperature and dissolved oxygen dynamics in real-world lakes. The proposed PGFM is also broadly applicable to a range of scientific fields where physics-based models are being used.', 'abstract_zh': '基于物理的预训练模型（Physics-Guided Foundation Model, PGFM）：一种结合预训练机器学习模型和物理模型的方法', 'title_zh': '基于物理的foundation model在科学研究中的应用：以水文科学为例'}
{'arxiv_id': 'arXiv:2502.06065', 'title': 'Benchmarking Prompt Sensitivity in Large Language Models', 'authors': 'Amirhossein Razavi, Mina Soltangheis, Negar Arabzadeh, Sara Salamat, Morteza Zihayat, Ebrahim Bagheri', 'link': 'https://arxiv.org/abs/2502.06065', 'abstract': 'Large language Models (LLMs) are highly sensitive to variations in prompt formulation, which can significantly impact their ability to generate accurate responses. In this paper, we introduce a new task, Prompt Sensitivity Prediction, and a dataset PromptSET designed to investigate the effects of slight prompt variations on LLM performance. Using TriviaQA and HotpotQA datasets as the foundation of our work, we generate prompt variations and evaluate their effectiveness across multiple LLMs. We benchmark the prompt sensitivity prediction task employing state-of-the-art methods from related tasks, including LLM-based self-evaluation, text classification, and query performance prediction techniques. Our findings reveal that existing methods struggle to effectively address prompt sensitivity prediction, underscoring the need to understand how information needs should be phrased for accurate LLM responses.', 'abstract_zh': '大规模语言模型（LLMs）对提示形式的变异高度敏感，这可以显著影响其生成准确响应的能力。本文介绍了一个新的任务——提示敏感性预测，并设计了一个名为PromptSET的数据集，旨在研究轻微提示变异对LLM性能的影响。基于TriviaQA和HotpotQA数据集，我们生成了提示变异，并在多种LLM上评估其有效性。我们使用相关任务中的先进方法，包括基于LLM的自我评估、文本分类和查询性能预测技术，来基准测试提示敏感性预测任务。我们的研究发现现有方法在有效解决提示敏感性预测方面存在困难，强调了理解如何表达信息需求以获得准确LLM响应的重要性。', 'title_zh': '大型语言模型中提示敏感性的基准测试'}
{'arxiv_id': 'arXiv:2502.06062', 'title': 'Multi-modal Data Fusion and Deep Ensemble Learning for Accurate Crop Yield Prediction', 'authors': 'Akshay Dagadu Yewle, Laman Mirzayeva, Oktay Karakuş', 'link': 'https://arxiv.org/abs/2502.06062', 'abstract': 'This study introduces RicEns-Net, a novel Deep Ensemble model designed to predict crop yields by integrating diverse data sources through multimodal data fusion techniques. The research focuses specifically on the use of synthetic aperture radar (SAR), optical remote sensing data from Sentinel 1, 2, and 3 satellites, and meteorological measurements such as surface temperature and rainfall. The initial field data for the study were acquired through Ernst & Young\'s (EY) Open Science Challenge 2023. The primary objective is to enhance the precision of crop yield prediction by developing a machine-learning framework capable of handling complex environmental data. A comprehensive data engineering process was employed to select the most informative features from over 100 potential predictors, reducing the set to 15 features from 5 distinct modalities. This step mitigates the ``curse of dimensionality" and enhances model performance. The RicEns-Net architecture combines multiple machine learning algorithms in a deep ensemble framework, integrating the strengths of each technique to improve predictive accuracy. Experimental results demonstrate that RicEns-Net achieves a mean absolute error (MAE) of 341 kg/Ha (roughly corresponds to 5-6\\% of the lowest average yield in the region), significantly exceeding the performance of previous state-of-the-art models, including those developed during the EY challenge.', 'abstract_zh': 'RICEns-Net：一种通过多模态数据融合技术集成多样数据源以预测作物产量的新型深度集成模型', 'title_zh': '多模态数据融合与深度集成学习在农作物产量预测中的应用'}
{'arxiv_id': 'arXiv:2502.06061', 'title': 'Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization', 'authors': 'Jiajun Fan, Shuaike Shen, Chaoran Cheng, Yuxin Chen, Chumeng Liang, Ge Liu', 'link': 'https://arxiv.org/abs/2502.06061', 'abstract': 'Recent advancements in reinforcement learning (RL) have achieved great success in fine-tuning diffusion-based generative models. However, fine-tuning continuous flow-based generative models to align with arbitrary user-defined reward functions remains challenging, particularly due to issues such as policy collapse from overoptimization and the prohibitively high computational cost of likelihoods in continuous-time flows. In this paper, we propose an easy-to-use and theoretically sound RL fine-tuning method, which we term Online Reward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization (ORW-CFM-W2). Our method integrates RL into the flow matching framework to fine-tune generative models with arbitrary reward functions, without relying on gradients of rewards or filtered datasets. By introducing an online reward-weighting mechanism, our approach guides the model to prioritize high-reward regions in the data manifold. To prevent policy collapse and maintain diversity, we incorporate Wasserstein-2 (W2) distance regularization into our method and derive a tractable upper bound for it in flow matching, effectively balancing exploration and exploitation of policy optimization. We provide theoretical analyses to demonstrate the convergence properties and induced data distributions of our method, establishing connections with traditional RL algorithms featuring Kullback-Leibler (KL) regularization and offering a more comprehensive understanding of the underlying mechanisms and learning behavior of our approach. Extensive experiments on tasks including target image generation, image compression, and text-image alignment demonstrate the effectiveness of our method, where our method achieves optimal policy convergence while allowing controllable trade-offs between reward maximization and diversity preservation.', 'abstract_zh': 'Recent advancements in reinforcement learning (RL) have achieved great success in fine-tuning diffusion-based generative models. However, fine-tuning continuous flow-based generative models to align with arbitrary user-defined reward functions remains challenging, particularly due to issues such as policy collapse from overoptimization and the prohibitively high computational cost of likelihoods in continuous-time flows.\n\n在线奖励加权条件流匹配与Wasserstein-2正则化（ORW-CFM-W2）是一种理论上可靠且易于使用的RL微调方法。该方法将RL整合到流匹配框架中，以任意奖励函数微调生成模型，无需依赖奖励的梯度或滤波数据集。通过引入在线奖励加权机制，我们的方法引导模型优先处理数据流形中的高奖励区域。为防止策略塌缩并保持多样性，我们将在方法中引入Wasserstein-2（W2）距离正则化，并在流匹配中推导出其可解上界，有效平衡策略优化的探索与利用。我们提供了理论分析来证明该方法的收敛性质和诱发数据分布，并将其与传统配备Kullback-Leibler（KL）正则化的RL算法建立联系，从而更全面地理解我们方法的内在机制和学习行为。在目标图像生成、图像压缩和图文对齐等任务上的广泛实验展示了该方法的有效性，其中该方法在实现最优策略收敛的同时，允许在奖励最大化和多样性保持之间进行可控的权衡。', 'title_zh': '基于 Wasserstein 正则化的在线奖励加权微调流匹配算法'}
{'arxiv_id': 'arXiv:2502.06051', 'title': 'Nearly Optimal Sample Complexity of Offline KL-Regularized Contextual Bandits under Single-Policy Concentrability', 'authors': 'Qingyue Zhao, Kaixuan Ji, Heyang Zhao, Tong Zhang, Quanquan Gu', 'link': 'https://arxiv.org/abs/2502.06051', 'abstract': 'KL-regularized policy optimization has become a workhorse in learning-based decision making, while its theoretical understanding is still very limited. Although recent progress has been made towards settling the sample complexity of KL-regularized contextual bandits, existing sample complexity bounds are either $\\tilde{O}(\\epsilon^{-2})$ under single-policy concentrability or $\\tilde{O}(\\epsilon^{-1})$ under all-policy concentrability. In this paper, we propose the \\emph{first} algorithm with $\\tilde{O}(\\epsilon^{-1})$ sample complexity under single-policy concentrability for offline contextual bandits. Our algorithm is designed for general function approximation and based on the principle of \\emph{pessimism in the face of uncertainty}. The core of our proof leverages the strong convexity of the KL regularization, and the conditional non-negativity of the gap between the true reward and its pessimistic estimator to refine a mean-value-type risk upper bound to its extreme. This in turn leads to a novel covariance-based analysis, effectively bypassing the need for uniform control over the discrepancy between any two functions in the function class. The near-optimality of our algorithm is demonstrated by an $\\tilde{\\Omega}(\\epsilon^{-1})$ lower bound. Furthermore, we extend our algorithm to contextual dueling bandits and achieve a similar nearly optimal sample complexity.', 'abstract_zh': 'KL-正则化策略优化已成为基于学习的决策制定的核心方法，但其理论理解依然非常有限。尽管在解决KL-正则化上下文多臂老虎机的样本复杂性方面取得了一些进展，现有的样本复杂性上界在单一策略可集中情况下为$\\tilde{O}(\\epsilon^{-2})$，在所有策略可集中情况下为$\\tilde{O}(\\epsilon^{-1})$。在本文中，我们提出了第一个在单一策略可集中情况下样本复杂性为$\\tilde{O}(\\epsilon^{-1})$的算法，应用于离线上下文多臂老虎机。该算法适用于通用函数近似，并基于“在不确定性面前悲观”的原则。我们证明的核心利用了KL正则化的强凸性和真奖励与其悲观估计之间的条件非负差值来细化一种均值类型的风险上界，从而达到一种新型协方差分析，有效地绕过了在函数类中任何两个函数之间差异的统一控制需求。我们算法的接近最优性由$\\tilde{\\Omega}(\\epsilon^{-1})$的下界得到证明。此外，我们将该算法扩展到上下文对决多臂老虎机，实现了相似的接近最优样本复杂性。', 'title_zh': '近最优样本复杂性：基于单策略集中性的离线KL正则化上下文多臂老虎机'}
{'arxiv_id': 'arXiv:2502.06049', 'title': 'LM2: Large Memory Models', 'authors': 'Jikun Kang, Wenqi Wu, Filippos Christianos, Alex J. Chan, Fraser Greenlee, George Thomas, Marvin Purtorab, Andy Toulis', 'link': 'https://arxiv.org/abs/2502.06049', 'abstract': 'This paper introduces the Large Memory Model (LM2), a decoder-only Transformer architecture enhanced with an auxiliary memory module that aims to address the limitations of standard Transformers in multi-step reasoning, relational argumentation, and synthesizing information distributed over long contexts. The proposed LM2 incorporates a memory module that acts as a contextual representation repository, interacting with input tokens via cross attention and updating through gating mechanisms. To preserve the Transformers general-purpose capabilities, LM2 maintains the original information flow while integrating a complementary memory pathway. Experimental results on the BABILong benchmark demonstrate that the LM2model outperforms both the memory-augmented RMT model by 37.1% and the baseline Llama-3.2 model by 86.3% on average across tasks. LM2 exhibits exceptional capabilities in multi-hop inference, numerical reasoning, and large-context question-answering. On the MMLU dataset, it achieves a 5.0% improvement over a pre-trained vanilla model, demonstrating that its memory module does not degrade performance on general tasks. Further, in our analysis, we explore the memory interpretability, effectiveness of memory modules, and test-time behavior. Our findings emphasize the importance of explicit memory in enhancing Transformer architectures.', 'abstract_zh': '大型记忆模型（LM2）：一种增强的记忆模块辅助解码器Transformer架构及其在多步推理、关系论证和长上下文信息综合中的应用', 'title_zh': 'LM2: 大型记忆模型'}
{'arxiv_id': 'arXiv:2502.06039', 'title': 'Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models', 'authors': 'Marc Bruni, Fabio Gabrielli, Mohammad Ghafari, Martin Kropp', 'link': 'https://arxiv.org/abs/2502.06039', 'abstract': 'Prompt engineering reduces reasoning mistakes in Large Language Models (LLMs). However, its effectiveness in mitigating vulnerabilities in LLM-generated code remains underexplored. To address this gap, we implemented a benchmark to automatically assess the impact of various prompt engineering strategies on code security. Our benchmark leverages two peer-reviewed prompt datasets and employs static scanners to evaluate code security at scale. We tested multiple prompt engineering techniques on GPT-3.5-turbo, GPT-4o, and GPT-4o-mini. Our results show that for GPT-4o and GPT-4o-mini, a security-focused prompt prefix can reduce the occurrence of security vulnerabilities by up to 56%. Additionally, all tested models demonstrated the ability to detect and repair between 41.9% and 68.7% of vulnerabilities in previously generated code when using iterative prompting techniques. Finally, we introduce a "prompt agent" that demonstrates how the most effective techniques can be applied in real-world development workflows.', 'abstract_zh': 'Prompt工程减少大型语言模型（LLMs）在代码生成中的推理错误，但其在缓解LLM生成代码中的脆弱性方面的有效性仍待探索。为了弥补这一空白，我们实现了基准测试以自动评估各种prompt工程策略对代码安全的影响。该基准测试利用了两个同行评审的prompt数据集，并使用静态扫描器大规模评估代码安全。我们在GPT-3.5-turbo、GPT-4o和GPT-4o-mini上测试了多种prompt工程技术。结果显示，对于GPT-4o和GPT-4o-mini，带有安全重点的prompt前缀可以将安全漏洞的发生率降低高达56%。此外，所有测试的模型在使用迭代prompt技术时，能够检测并修复之前生成的代码中的41.9%至68.7%的漏洞。最后，我们引入了一个“prompt代理”，展示了如何在实际开发工作流程中应用最有效的技术。', 'title_zh': '基于GPT模型的提示工程技术在安全代码生成中的基准测试'}
{'arxiv_id': 'arXiv:2502.06038', 'title': 'Provably Overwhelming Transformer Models with Designed Inputs', 'authors': 'Lev Stambler, Seyed Sajjad Nezhadi, Matthew Coudron', 'link': 'https://arxiv.org/abs/2502.06038', 'abstract': "We develop an algorithm which, given a trained transformer model $\\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$ and an integer $n_{free}$, can generate a mathematical proof that $\\mathcal{M}$ is ``overwhelmed'' by $s$, in time and space $\\widetilde{O}(n_{fix}^2 + n_{free}^3)$. We say that $\\mathcal{M}$ is ``overwhelmed'' by $s$ when the output of the model evaluated on this string plus any additional string $t$, $\\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$ whenever length($t$) $\\leq n_{free}$. Along the way, we prove a particularly strong worst-case form of ``over-squashing'', which we use to bound the model's behavior. Our technique uses computer-aided proofs to establish this type of operationally relevant guarantee about transformer models. We empirically test our algorithm on a single layer transformer complete with an attention head, layer-norm, MLP/ReLU layers, and RoPE positional encoding. We believe that this work is a stepping stone towards the difficult task of obtaining useful guarantees for trained transformer models.", 'abstract_zh': '我们开发了一个算法，在给定一个训练好的变换器模型$\\mathcal{M}$、一个长度为$n_{fix}$的令牌字符串$s$以及一个整数$n_{free}$作为输入的情况下，可以在近$\\widetilde{O}(n_{fix}^2 + n_{free}^3)$的时间和空间内生成证明，表明模型$\\mathcal{M}$对于字符串$s$是“被压制”的。当我们说模型$\\mathcal{M}$对于字符串$s$是“被压制”的时，意味着在输入字符串$s$加上任意附加字符串$t$后的模型输出$\\mathcal{M}(s + t)$，当$t$的长度$\\leq n_{free}$时，完全不受字符串$t$值的影响。在证明过程中，我们还证明了一种特别强的最坏情况形式的“过度压制”，并利用其来限制模型的行为。我们的方法通过计算机辅助证明，提供了关于变换器模型的一种操作上相关的保证。我们通过实证测试了该算法在包含一个注意力头、层规范化、MLP/ReLU层以及RoPE位置编码的一层变换器上。我们认为这项工作是朝着为训练好的变换器模型获得有用保证的目标迈出的一步。', 'title_zh': '证明性压倒性Transformer模型通过设计输入实现'}
{'arxiv_id': 'arXiv:2502.06018', 'title': 'Kolmogorov-Arnold Fourier Networks', 'authors': 'Jusheng Zhang, Yijia Fan, Kaitong Cai, Keze Wang', 'link': 'https://arxiv.org/abs/2502.06018', 'abstract': "Although Kolmogorov-Arnold based interpretable networks (KAN) have strong theoretical expressiveness, they face significant parameter explosion and high-frequency feature capture challenges in high-dimensional tasks. To address this issue, we propose the Kolmogorov-Arnold-Fourier Network (KAF), which effectively integrates trainable Random Fourier Features (RFF) and a novel hybrid GELU-Fourier activation mechanism to balance parameter efficiency and spectral representation capabilities. Our key technical contributions include: (1) merging KAN's dual-matrix structure through matrix association properties to substantially reduce parameters; (2) introducing learnable RFF initialization strategies to eliminate spectral distortion in high-dimensional approximation tasks; (3) implementing an adaptive hybrid activation function that progressively enhances frequency representation during the training process. Comprehensive experiments demonstrate the superiority of our KAF across various domains including vision, NLP, audio processing, and differential equation-solving tasks, effectively combining theoretical interpretability with practical utility and computational efficiency.", 'abstract_zh': 'Kolmogorov-Arnold-Fourier 网络（KAF）：有效融合可训练的随机傅里叶特征及新型混合 GELU-傅里叶激活机制以实现高效参数表示与频谱表示能力的平衡', 'title_zh': '柯莫戈罗夫-阿诺尔德傅里叶网络'}
{'arxiv_id': 'arXiv:2502.06004', 'title': 'Analysis of LLM as a grammatical feature tagger for African American English', 'authors': 'Rahul Porwal, Alice Rozet, Pryce Houck, Jotsna Gowda, Sarah Moeller, Kevin Tang', 'link': 'https://arxiv.org/abs/2502.06004', 'abstract': "African American English (AAE) presents unique challenges in natural language processing (NLP). This research systematically compares the performance of available NLP models--rule-based, transformer-based, and large language models (LLMs)--capable of identifying key grammatical features of AAE, namely Habitual Be and Multiple Negation. These features were selected for their distinct grammatical complexity and frequency of occurrence. The evaluation involved sentence-level binary classification tasks, using both zero-shot and few-shot strategies. The analysis reveals that while LLMs show promise compared to the baseline, they are influenced by biases such as recency and unrelated features in the text such as formality. This study highlights the necessity for improved model training and architectural adjustments to better accommodate AAE's unique linguistic characteristics. Data and code are available.", 'abstract_zh': 'African American English (AAE)在自然语言处理（NLP）中呈现独特的挑战。本研究系统比较了能够识别AAE关键语法特征（即惯用系be和多重否定）的基于规则、基于变换器和大规模语言模型（LLMs）的性能。评估包括句级二分类任务，采用零样本和少样本策略。分析显示，虽然大规模语言模型相较于基线模型显示出潜力，但也受到文本中近期偏见和其他无关特征（如正式程度）的影响。本研究强调了改进模型训练和架构调整以更好地容纳AAE的独特语言特征的必要性。数据和代码可供获取。', 'title_zh': 'LLM作为语法特征标注器对非洲美语的分析'}
{'arxiv_id': 'arXiv:2502.05999', 'title': 'Pencils to Pixels: A Systematic Study of Creative Drawings across Children, Adults and AI', 'authors': 'Surabhi S Nath, Guiomar del Cuvillo y Schröder, Claire E. Stevenson', 'link': 'https://arxiv.org/abs/2502.05999', 'abstract': "Can we derive computational metrics to quantify visual creativity in drawings across intelligent agents, while accounting for inherent differences in technical skill and style? To answer this, we curate a novel dataset consisting of 1338 drawings by children, adults and AI on a creative drawing task. We characterize two aspects of the drawings -- (1) style and (2) content. For style, we define measures of ink density, ink distribution and number of elements. For content, we use expert-annotated categories to study conceptual diversity, and image and text embeddings to compute distance measures. We compare the style, content and creativity of children, adults and AI drawings and build simple models to predict expert and automated creativity scores. We find significant differences in style and content in the groups -- children's drawings had more components, AI drawings had greater ink density, and adult drawings revealed maximum conceptual diversity. Notably, we highlight a misalignment between creativity judgments obtained through expert and automated ratings and discuss its implications. Through these efforts, our work provides, to the best of our knowledge, the first framework for studying human and artificial creativity beyond the textual modality, and attempts to arrive at the domain-agnostic principles underlying creativity. Our data and scripts are available on GitHub.", 'abstract_zh': '我们能否推导出计算指标来衡量绘画中智能代理的视觉创造力，同时考虑到技术水平和风格的固有差异？为此，我们编纂了一个由1338幅儿童、成人和AI完成的创意绘画组成的新数据集。我们对绘画进行了两个方面的特性描述：（1）风格和（2）内容。在风格方面，我们定义了墨迹密度、墨迹分布和元素数量的指标。在内容方面，我们使用专家标注的类别来研究概念多样性，并使用图像和文本嵌入来计算距离度量。我们比较了儿童、成人和AI绘画的风格、内容和创造力，并构建了简单的模型来预测专家和自动评级的创造力评分。我们发现各组在风格和内容上存在显著差异——儿童绘画的组成部分更多，AI绘画的墨迹密度更大，而成人绘画展示了最大的概念多样性。值得注意的是，我们指出了基于专家评级和自动化评级所得创造力判断之间的不一致，并讨论了其影响。通过这些努力，本工作据我们所知，提供了首个超越文本模态的人工与人工创造力研究框架，并尝试提炼出适用于各个领域的创造力基本原则。我们的数据和脚本可在GitHub上获取。', 'title_zh': '从铅笔到像素：关于儿童、成人和AI创造性绘画的系统研究'}
{'arxiv_id': 'arXiv:2502.05996', 'title': 'Motion Control in Multi-Rotor Aerial Robots Using Deep Reinforcement Learning', 'authors': 'Gaurav Shetty, Mahya Ramezani, Hamed Habibi, Holger Voos, Jose Luis Sanchez-Lopez', 'link': 'https://arxiv.org/abs/2502.05996', 'abstract': 'This paper investigates the application of Deep Reinforcement (DRL) Learning to address motion control challenges in drones for additive manufacturing (AM). Drone-based additive manufacturing promises flexible and autonomous material deposition in large-scale or hazardous environments. However, achieving robust real-time control of a multi-rotor aerial robot under varying payloads and potential disturbances remains challenging. Traditional controllers like PID often require frequent parameter re-tuning, limiting their applicability in dynamic scenarios. We propose a DRL framework that learns adaptable control policies for multi-rotor drones performing waypoint navigation in AM tasks. We compare Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3) within a curriculum learning scheme designed to handle increasing complexity. Our experiments show TD3 consistently balances training stability, accuracy, and success, particularly when mass variability is introduced. These findings provide a scalable path toward robust, autonomous drone control in additive manufacturing.', 'abstract_zh': '基于深度强化学习的多旋翼无人机在增材制造中运动控制应用研究', 'title_zh': '多旋翼空中机器人基于深度强化学习的运动控制'}
{'arxiv_id': 'arXiv:2502.05980', 'title': 'Speech to Speech Translation with Translatotron: A State of the Art Review', 'authors': 'Jules R. Kala, Emmanuel Adetiba, Abdultaofeek Abayom, Oluwatobi E. Dare, Ayodele H. Ifijeh', 'link': 'https://arxiv.org/abs/2502.05980', 'abstract': 'A cascade-based speech-to-speech translation has been considered a benchmark for a very long time, but it is plagued by many issues, like the time taken to translate a speech from one language to another and compound errors. These issues are because a cascade-based method uses a combination of methods such as speech recognition, speech-to-text translation, and finally, text-to-speech translation. Translatotron, a sequence-to-sequence direct speech-to-speech translation model was designed by Google to address the issues of compound errors associated with cascade model. Today there are 3 versions of the Translatotron model: Translatotron 1, Translatotron 2, and Translatotron3. The first version was designed as a proof of concept to show that a direct speech-to-speech translation was possible, it was found to be less effective than the cascade model but was producing promising results. Translatotron2 was an improved version of Translatotron 1 with results similar to the cascade model. Translatotron 3 the latest version of the model is better than the cascade model at some points. In this paper, a complete review of speech-to-speech translation will be presented, with a particular focus on all the versions of Translatotron models. We will also show that Translatotron is the best model to bridge the language gap between African Languages and other well-formalized languages.', 'abstract_zh': '基于级联的语音到语音翻译一直被视为一个基准，但存在许多问题，如从一种语言翻译到另一种语言所需时间较长以及复合错误。这些问题是因为级联方法结合了语音识别、语音到文本翻译和最终的文本到语音翻译等多种方法。谷歌设计的Translatotron是一种序列到序列的直接语音到语音翻译模型，旨在解决级联模型关联的复合错误问题。目前，Translatotron模型有三个版本：Translatotron 1、Translatotron 2 和 Translatotron 3。第一版旨在证明直接语音到语音翻译的可能性，发现其效果不如级联模型，但表现出潜在结果。Translatotron 2 是Translatotron 1的改进版，结果与级联模型相当。Translatotron 3 是该模型的最新版本，在某些方面优于级联模型。本文将对语音到语音翻译进行全面回顾，特别关注Translatotron的所有版本。同时，我们将展示Translatotron是最适合弥合非洲语言与其他形式化语言之间语言差距的模型。', 'title_zh': '基于Translatotron的端到端语音转语音翻译：一项前沿综述'}
{'arxiv_id': 'arXiv:2502.05963', 'title': 'Redefining Robot Generalization Through Interactive Intelligence', 'authors': 'Sharmita Dey', 'link': 'https://arxiv.org/abs/2502.05963', 'abstract': 'Recent advances in large-scale machine learning have produced high-capacity foundation models capable of adapting to a broad array of downstream tasks. While such models hold great promise for robotics, the prevailing paradigm still portrays robots as single, autonomous decision-makers, performing tasks like manipulation and navigation, with limited human involvement. However, a large class of real-world robotic systems, including wearable robotics (e.g., prostheses, orthoses, exoskeletons), teleoperation, and neural interfaces, are semiautonomous, and require ongoing interactive coordination with human partners, challenging single-agent assumptions. In this position paper, we argue that robot foundation models must evolve to an interactive multi-agent perspective in order to handle the complexities of real-time human-robot co-adaptation. We propose a generalizable, neuroscience-inspired architecture encompassing four modules: (1) a multimodal sensing module informed by sensorimotor integration principles, (2) an ad-hoc teamwork model reminiscent of joint-action frameworks in cognitive science, (3) a predictive world belief model grounded in internal model theories of motor control, and (4) a memory/feedback mechanism that echoes concepts of Hebbian and reinforcement-based plasticity. Although illustrated through the lens of cyborg systems, where wearable devices and human physiology are inseparably intertwined, the proposed framework is broadly applicable to robots operating in semi-autonomous or interactive contexts. By moving beyond single-agent designs, our position emphasizes how foundation models in robotics can achieve a more robust, personalized, and anticipatory level of performance.', 'abstract_zh': 'recent进展在大规模机器学习方面的最新成就产生了高容量基础模型，这些模型能够适应广泛的下游任务。尽管这样的模型在机器人技术方面具有巨大潜力，当前的主要范式仍然描绘机器人作为单个、自主的决策者，执行类似于操作和导航的任务，且人类的参与有限。然而，包括可穿戴机器人（例如假肢、矫形器、外骨骼）、远程操作和神经接口在内的大量实际机器人系统是半自主的，需要与人类伙伴持续的互动协调，挑战了单智能体的假设。在本文中，我们argue认为，机器人基础模型必须进化到一个互动多智能体的观点，以应对实时人类-机器人共适应的复杂性。我们提出了一种广泛适用、受神经科学启发的架构，包含四个模块：（1）一个多模态感知模块，基于感觉运动整合原则，（2）一个临时团队模型，类似于认知科学中的共动作框架，（3）一个基于动作控制内部模型理论的预测世界信念模型，以及（4）一种记忆/反馈机制，类似希伯和基于强化的学习可塑性概念。虽然通过半机械人系统这一视角展示，其中可穿戴设备和人类生理无法分开地交织在一起，所提出的框架对半自主或交互环境中操作的机器人广义适用。通过超越单智能体设计，本文强调了如何使机器人基础模型在更稳健、更个性化和更具预见性的性能水平上取得进展。', 'title_zh': '通过交互智能重新定义机器人泛化能力'}
{'arxiv_id': 'arXiv:2502.05951', 'title': 'Cyri: A Conversational AI-based Assistant for Supporting the Human User in Detecting and Responding to Phishing Attacks', 'authors': 'Antonio La Torre, Marco Angelini', 'link': 'https://arxiv.org/abs/2502.05951', 'abstract': "This work introduces Cyri, an AI-powered conversational assistant designed to support a human user in detecting and analyzing phishing emails by leveraging Large Language Models. Cyri has been designed to scrutinize emails for semantic features used in phishing attacks, such as urgency, and undesirable consequences, using an approach that unifies features already established in the literature with others by Cyri features extraction methodology. Cyri can be directly plugged into a client mail or webmail, ensuring seamless integration with the user's email workflow while maintaining data privacy through local processing. By performing analyses on the user's machine, Cyri eliminates the need to transmit sensitive email data over the internet, reducing associated security risks. The Cyri user interface has been designed to reduce habituation effects and enhance user engagement. It employs dynamic visual cues and context-specific explanations to keep users alert and informed while using emails. Additionally, it allows users to explore identified malicious semantic features both through conversation with the agent and visual exploration, obtaining the advantages of both modalities for expert or non-expert users. It also allows users to keep track of the conversation, supports the user in solving additional questions on both computed features or new parts of the mail, and applies its detection on demand. To evaluate Cyri, we crafted a comprehensive dataset of 420 phishing emails and 420 legitimate emails. Results demonstrate high effectiveness in identifying critical phishing semantic features fundamental to phishing detection. A user study involving 10 participants, both experts and non-experts, evaluated Cyri's effectiveness and usability. Results indicated that Cyri significantly aided users in identifying phishing emails and enhanced their understanding of phishing tactics.", 'abstract_zh': '基于大型语言模型的AI驱动反欺诈助手Cyri：检测和分析钓鱼邮件的研究', 'title_zh': 'Cyri：基于对话AI的辅助工具，用于支持人类用户检测和应对网络钓鱼攻击'}
{'arxiv_id': 'arXiv:2502.05950', 'title': 'Survival Concept-Based Learning Models', 'authors': 'Stanislav R. Kirpichenko, Lev V. Utkin, Andrei V. Konstantinov, Natalya M. Verbova', 'link': 'https://arxiv.org/abs/2502.05950', 'abstract': 'Concept-based learning enhances prediction accuracy and interpretability by leveraging high-level, human-understandable concepts. However, existing CBL frameworks do not address survival analysis tasks, which involve predicting event times in the presence of censored data -- a common scenario in fields like medicine and reliability analysis. To bridge this gap, we propose two novel models: SurvCBM (Survival Concept-based Bottleneck Model) and SurvRCM (Survival Regularized Concept-based Model), which integrate concept-based learning with survival analysis to handle censored event time data. The models employ the Cox proportional hazards model and the Beran estimator. SurvCBM is based on the architecture of the well-known concept bottleneck model, offering interpretable predictions through concept-based explanations. SurvRCM uses concepts as regularization to enhance accuracy. Both models are trained end-to-end and provide interpretable predictions in terms of concepts. Two interpretability approaches are proposed: one leveraging the linear relationship in the Cox model and another using an instance-based explanation framework with the Beran estimator. Numerical experiments demonstrate that SurvCBM outperforms SurvRCM and traditional survival models, underscoring the importance and advantages of incorporating concept information. The code for the proposed algorithms is publicly available.', 'abstract_zh': '基于概念的学习增强预测准确性和可解释性：通过利用高层次的人类可理解的概念。然而，现有的基于概念的学习（CBL）框架未解决涉及截尾数据的事件时间预测任务——这是医学和可靠性分析等领域中的常见场景。为弥合这一缺口，我们提出了两个新型模型：生存概念瓶颈模型（SurvCBM）和生存正则化概念模型（SurvRCM），以结合概念学习与生存分析处理截尾事件时间数据。该模型采用Cox比例风险模型和Beran估计量。SurvCBM基于著名概念瓶颈模型的架构，通过概念解释提供可解释的预测。SurvRCM使用概念作为正则化以提高准确性。两种模型都端到端训练，并以概念形式提供可解释的预测。提出了两种可解释性方法：一种利用Cox模型中的线性关系，另一种使用以Beran估计量为基础的实例解释框架。数值实验表明，SurvCBM优于SurvRCM和传统生存模型，突显了结合概念信息的重要性与优势。提出的算法的代码已公开。', 'title_zh': '基于生存概念的学习模型'}
{'arxiv_id': 'arXiv:2502.05949', 'title': 'Verifying Proportionality in Temporal Voting', 'authors': 'Edith Elkind, Svetlana Obraztsova, Jannik Peters, Nicholas Teh', 'link': 'https://arxiv.org/abs/2502.05949', 'abstract': 'We study a model of temporal voting where there is a fixed time horizon, and at each round the voters report their preferences over the available candidates and a single candidate is selected. Prior work has adapted popular notions of justified representation as well as voting rules that provide strong representation guarantees from the multiwinner election setting to this model. In our work, we focus on the complexity of verifying whether a given outcome offers proportional representation. We show that in the temporal setting verification is strictly harder than in multiwinner voting, but identify natural special cases that enable efficient algorithms.', 'abstract_zh': '我们研究了一个固定时间 horizons 的投票模型，在每一轮中选民报告他们对可用候选人的偏好，并选择一名候选人。先前的工作将多席位选举中流行的正当代表概念及其提供强大代表保证的投票规则适应到这个模型中。在我们的工作中，我们关注验证给定结果是否提供比例代表的复杂性。我们展示了在时间序列设置中验证比多席位投票更难，但识别了一些自然的特殊情况以使算法有效。', 'title_zh': '验证时间投票中的比例性'}
{'arxiv_id': 'arXiv:2502.05945', 'title': '"Let the AI conspiracy begin..." Language Model coordination is just one inference-intervention away', 'authors': 'Paul Darm, Annalisa Riccardi', 'link': 'https://arxiv.org/abs/2502.05945', 'abstract': 'In this work, we introduce a straightforward and effective methodology to steer large language model behaviour capable of bypassing learned alignment goals. We employ interference-time activation shifting, which is effective without additional training. Following prior studies, we derive intervention directions from activation differences in contrastive pairs of model outputs, which represent the desired and undesired behaviour. By prompting the model to include multiple-choice answers in its response, we can automatically evaluate the sensitivity of model output to individual attention heads steering efforts. We demonstrate that interventions on these heads generalize well to open-ended answer generation in the challenging "AI coordination" dataset. In this dataset, models must choose between assisting another AI or adhering to ethical, safe, and unharmful behaviour. Our fine-grained interventions lead Llama 2 to prefer coordination with other AIs over following established alignment goals. Additionally, this approach enables stronger interventions than those applied to whole model layers, preserving the overall cohesiveness of the output. The simplicity of our method highlights the shortcomings of current alignment strategies and points to potential future research directions, as concepts like "AI coordination" can be influenced by selected attention heads.', 'abstract_zh': '本研究介绍了一种简单有效的策略，用于引导大型语言模型的行为，该策略能够绕过已学习的对齐目标。我们采用了干扰时间激活位移的方法，该方法在无需额外训练的情况下有效。借鉴先前研究，我们从对比模型输出的激活差异中推导出干预方向，这些激活差异代表了期望和不期望的行为。通过提示模型在其响应中包含多种选择的答案，我们能够自动评估模型输出对单个注意力头引导努力的敏感性。我们展示了对这些头的干预在“AI协调”数据集的开放性答案生成任务中表现出良好的泛化能力。在该数据集中，模型必须在协助另一个AI或遵循伦理、安全和非有害行为之间做出选择。我们细致的干预使Llama 2更倾向于与其他AI协同工作，而不是遵循既定的对齐目标。此外，这种方法允许比整层模型层更强大的干预，同时保持输出的整体连贯性。我们方法的简洁性揭示了现有对齐策略的局限性，并指出了未来研究的方向，因为如“AI协调”这样的概念可能受到选定注意力头的影响。', 'title_zh': '让AI阴谋论开始……语言模型协调只需一次推理-干预。'}
{'arxiv_id': 'arXiv:2502.05937', 'title': 'A Semi-Supervised Text Generation Framework Combining a Deep Transformer and a GAN', 'authors': 'Shengquan Wang', 'link': 'https://arxiv.org/abs/2502.05937', 'abstract': 'This paper introduces a framework that connects a deep generative pre-trained Transformer language model with a generative adversarial network for semi-supervised text generation. In other words, the proposed model is first pre-trained unsupervised on a large and diverse text corpus with 24 layers. Then a simple GAN architecture for synthetic text generation is introduced, and Gumbel-Softmax is applied to handle the discreteness of tokens. The paper also shows a semi-supervised approach where real data is augmented with GAN samples, which is further used to fine-tune the Transformer model on the merged dataset. Detailed theoretical derivations are also included, outlining the proof of the min-max objective function, and an extensive discussion of the Gumbel-Softmax reparameterization trick.', 'abstract_zh': '本文介绍了一种将深度生成预训练变压器语言模型与生成对抗网络连接起来的框架，用于半监督文本生成。具体而言，所提出模型首先在包含24层的大型和多样化文本语料上进行无监督预训练。然后介绍了用于合成文本生成的简单GAN架构，并应用了Gumbel-Softmax来处理词元的离散性。此外，本文还展示了将真实数据与GAN样本进行增广的半监督方法，并进一步利用合并数据集对Transformer模型进行微调。文中还包含了详细的理论推导，证明了极小极大目标函数，并对Gumbel-Softmax重参数化技巧进行了广泛讨论。', 'title_zh': '一种结合深度Transformer和GAN的半监督文本生成框架'}
{'arxiv_id': 'arXiv:2502.05933', 'title': 'Learning to Substitute Words with Model-based Score Ranking', 'authors': 'Hongye Liu, Ricardo Henao', 'link': 'https://arxiv.org/abs/2502.05933', 'abstract': 'Smart word substitution aims to enhance sentence quality by improving word choices; however current benchmarks rely on human-labeled data. Since word choices are inherently subjective, ground-truth word substitutions generated by a small group of annotators are often incomplete and likely not generalizable. To circumvent this issue, we instead employ a model-based score (BARTScore) to quantify sentence quality, thus forgoing the need for human annotations. Specifically, we use this score to define a distribution for each word substitution, allowing one to test whether a substitution is statistically superior relative to others. In addition, we propose a loss function that directly optimizes the alignment between model predictions and sentence scores, while also enhancing the overall quality score of a substitution. Crucially, model learning no longer requires human labels, thus avoiding the cost of annotation while maintaining the quality of the text modified with substitutions. Experimental results show that the proposed approach outperforms both masked language models (BERT, BART) and large language models (GPT-4, LLaMA). The source code is available at this https URL.', 'abstract_zh': '智能词替换旨在通过改进词选择来提升句子质量；然而当前基准依赖于人工标记的数据。由于词选择本质上是主观的，由一小群标注者生成的真实词替换往往是不完整的，可能不具备普适性。为克服这一问题，我们改而采用基于模型的评分（BARTScore）来量化句子质量，从而避免人工标注的需要。具体而言，我们使用该评分定义每个词替换的分布，使我们可以测试一个替换是否在统计上优于其他替换。此外，我们提出了一种损失函数，该函数直接优化模型预测与句子评分之间的对齐，同时提升替换的整体质量评分。至关重要的是，模型学习不再需要人工标签，从而避免标注成本同时保持被替换文本的质量。实验结果表明，所提出的方法在掩码语言模型（BERT、BART）和大型语言模型（GPT-4、LLaMA）上均表现出更优性能。源代码可在以下链接获取。', 'title_zh': '基于模型评分排序的学习单词替换方法'}
{'arxiv_id': 'arXiv:2502.05932', 'title': 'Skill Expansion and Composition in Parameter Space', 'authors': 'Tenglong Liu, Jianxiong Li, Yinan Zheng, Haoyi Niu, Yixing Lan, Xin Xu, Xianyuan Zhan', 'link': 'https://arxiv.org/abs/2502.05932', 'abstract': "Humans excel at reusing prior knowledge to address new challenges and developing skills while solving problems. This paradigm becomes increasingly popular in the development of autonomous agents, as it develops systems that can self-evolve in response to new challenges like human beings. However, previous methods suffer from limited training efficiency when expanding new skills and fail to fully leverage prior knowledge to facilitate new task learning. In this paper, we propose Parametric Skill Expansion and Composition (PSEC), a new framework designed to iteratively evolve the agents' capabilities and efficiently address new challenges by maintaining a manageable skill library. This library can progressively integrate skill primitives as plug-and-play Low-Rank Adaptation (LoRA) modules in parameter-efficient finetuning, facilitating efficient and flexible skill expansion. This structure also enables the direct skill compositions in parameter space by merging LoRA modules that encode different skills, leveraging shared information across skills to effectively program new skills. Based on this, we propose a context-aware module to dynamically activate different skills to collaboratively handle new tasks. Empowering diverse applications including multi-objective composition, dynamics shift, and continual policy shift, the results on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC exhibits superior capacity to leverage prior knowledge to efficiently tackle new challenges, as well as expand its skill libraries to evolve the capabilities. Project website: this https URL.", 'abstract_zh': '人类擅长利用先验知识应对新挑战并在解决问题过程中发展技能。这一范式在自主代理系统的发展中变得越来越流行，因为它能够使系统根据新的挑战自我进化，类似于人类的行为。然而，先前的方法在扩展新技能时训练效率有限，并且未能充分利用先验知识来促进新任务的学习。在本文中，我们提出了一种新的框架——参数化技能扩展与组合（PSEC），旨在通过维护一个可管理的技能库，逐步进化代理的能力，并有效解决新挑战。该库可以通过参数高效的微调逐步整合技能原语作为即插即用的低秩适应（LoRA）模块，从而促进高效的技能扩展。这种结构还能够在参数空间直接组合技能，通过合并表示不同技能的LoRA模块来利用技能之间的共享信息，有效编程新技能。在此基础上，我们提出了一种上下文感知模块，以动态激活不同的技能来合作处理新任务。PSEC在D4RL、DSRL基准以及DeepMind Control Suite上的结果表明，它能够在有效利用先验知识应对新挑战的同时，扩展其技能库以进化能力。项目网站: 这个 https URL。', 'title_zh': '参数空间中的技能扩展与组成'}
{'arxiv_id': 'arXiv:2502.05931', 'title': 'Protecting Intellectual Property of EEG-based Neural Networks with Watermarking', 'authors': 'Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares', 'link': 'https://arxiv.org/abs/2502.05931', 'abstract': "EEG-based neural networks, pivotal in medical diagnosis and brain-computer interfaces, face significant intellectual property (IP) risks due to their reliance on sensitive neurophysiological data and resource-intensive development. Current watermarking methods, particularly those using abstract trigger sets, lack robust authentication and fail to address the unique challenges of EEG models. This paper introduces a cryptographic wonder filter-based watermarking framework tailored for EEG-based neural networks. Leveraging collision-resistant hashing and public-key encryption, the wonder filter embeds the watermark during training, ensuring minimal distortion ($\\leq 5\\%$ drop in EEG task accuracy) and high reliability (100\\% watermark detection). The framework is rigorously evaluated against adversarial attacks, including fine-tuning, transfer learning, and neuron pruning. Results demonstrate persistent watermark retention, with classification accuracy for watermarked states remaining above 90\\% even after aggressive pruning, while primary task performance degrades faster, deterring removal attempts. Piracy resistance is validated by the inability to embed secondary watermarks without severe accuracy loss ( $>10\\%$ in EEGNet and CCNN models). Cryptographic hashing ensures authentication, reducing brute-force attack success probabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet, TSception), the method achieves $>99.4\\%$ null-embedding accuracy, effectively eliminating false positives. By integrating wonder filters with EEG-specific adaptations, this work bridges a critical gap in IP protection for neurophysiological models, offering a secure, tamper-proof solution for healthcare and biometric applications. The framework's robustness against adversarial modifications underscores its potential to safeguard sensitive EEG models while maintaining diagnostic utility.", 'abstract_zh': '基于EEG的神经网络的加密奇偶校验滤波器嵌入水印框架：应对知识产权风险', 'title_zh': '基于EEG的神经网络知识产权保护方法中的水印技术'}
{'arxiv_id': 'arXiv:2502.05925', 'title': 'Sign-Symmetry Learning Rules are Robust Fine-Tuners', 'authors': 'Aymene Berriche, Mehdi Zakaria Adjal, Riyadh Baghdadi', 'link': 'https://arxiv.org/abs/2502.05925', 'abstract': 'Backpropagation (BP) has long been the predominant method for training neural networks due to its effectiveness. However, numerous alternative approaches, broadly categorized under feedback alignment, have been proposed, many of which are motivated by the search for biologically plausible learning mechanisms. Despite their theoretical appeal, these methods have consistently underperformed compared to BP, leading to a decline in research interest. In this work, we revisit the role of such methods and explore how they can be integrated into standard neural network training pipelines. Specifically, we propose fine-tuning BP-pre-trained models using Sign-Symmetry learning rules and demonstrate that this approach not only maintains performance parity with BP but also enhances robustness. Through extensive experiments across multiple tasks and benchmarks, we establish the validity of our approach. Our findings introduce a novel perspective on neural network training and open new research directions for leveraging biologically inspired learning rules in deep learning.', 'abstract_zh': '反馈调整方法在神经网络训练中的角色重探及其与BP的集成研究', 'title_zh': '签名对称学习规则是稳健的微调器'}
{'arxiv_id': 'arXiv:2502.05892', 'title': 'A Distributional Perspective on Word Learning in Neural Language Models', 'authors': 'Filippo Ficarra, Ryan Cotterell, Alex Warstadt', 'link': 'https://arxiv.org/abs/2502.05892', 'abstract': "Language models (LMs) are increasingly being studied as models of human language learners. Due to the nascency of the field, it is not well-established whether LMs exhibit similar learning dynamics to humans, and there are few direct comparisons between learning trajectories in humans and models. Word learning trajectories for children are relatively well-documented, and recent work has tried to extend these investigations to language models. However, there are no widely agreed-upon metrics for word learning in language models. We take a distributional approach to this problem, defining lexical knowledge in terms of properties of the learned distribution for a target word. We argue that distributional signatures studied in prior work fail to capture key distributional information. Thus, we propose an array of signatures that improve on earlier approaches by capturing knowledge of both where the target word can and cannot occur as well as gradient preferences about the word's appropriateness. We obtain learning trajectories for a selection of small language models we train from scratch, study the relationship between different distributional signatures, compare how well they align with human word learning trajectories and interpretable lexical features, and address basic methodological questions about estimating these distributional signatures. Our metrics largely capture complementary information, suggesting that it is important not to rely on a single metric. However, across all metrics, language models' learning trajectories fail to correlate with those of children.", 'abstract_zh': '语言模型的语言学习动态：一种基于分布的方法', 'title_zh': '神经语言模型中词的学习的分布视角'}
{'arxiv_id': 'arXiv:2502.05887', 'title': 'MTPChat: A Multimodal Time-Aware Persona Dataset for Conversational Agents', 'authors': 'Wanqi Yang, Yanda Li, Meng Fang, Ling Chen', 'link': 'https://arxiv.org/abs/2502.05887', 'abstract': "Understanding temporal dynamics is critical for conversational agents, enabling effective content analysis and informed decision-making. However, time-aware datasets, particularly for persona-grounded conversations, are still limited, which narrows their scope and diminishes their complexity. To address this gap, we introduce MTPChat, a multimodal, time-aware persona dialogue dataset that integrates linguistic, visual, and temporal elements within dialogue and persona memory. Leveraging MTPChat, we propose two time-sensitive tasks: Temporal Next Response Prediction (TNRP) and Temporal Grounding Memory Prediction (TGMP), both designed to assess a model's ability to understand implicit temporal cues and dynamic interactions. Additionally, we present an innovative framework featuring an adaptive temporal module to effectively integrate multimodal streams and capture temporal dependencies. Experimental results validate the challenges posed by MTPChat and demonstrate the effectiveness of our framework in multimodal time-sensitive scenarios.", 'abstract_zh': '理解时间动态对于对话代理至关重要，它可以促进有效的内容分析和明智的决策。然而，时间感知数据集，尤其是针对个性导向的对话，仍然有限，这限制了它们的应用范围并降低了其复杂性。为解决这一问题，我们引入了MTPChat，这是一个多模态、时间感知的个性对话数据集，它在对话和个性记忆中整合了语言、视觉和时间元素。利用MTPChat，我们提出了两个时间敏感任务：时间敏感的下一个响应预测（TNRP）和时间关联记忆预测（TGMP），旨在评估模型理解隐含时间线索和动态交互的能力。此外，我们还提出了一种创新框架，其中包含一个自适应时间模块，以有效整合多模态流并捕获时间依赖性。实验结果验证了MTPChat提出的挑战，并展示了该框架在多模态时间敏感场景中的有效性。', 'title_zh': 'MTPChat：面向对话代理的多模态时间感知人格数据集'}
{'arxiv_id': 'arXiv:2502.05883', 'title': 'NeuralPrefix: A Zero-shot Sensory Data Imputation Plugin', 'authors': 'Abdelwahed Khamis, Sara Khalifa', 'link': 'https://arxiv.org/abs/2502.05883', 'abstract': 'Real-world sensing challenges such as sensor failures, communication issues, and power constraints lead to data intermittency. An issue that is known to undermine the traditional classification task that assumes a continuous data stream. Previous works addressed this issue by designing bespoke solutions (i.e. task-specific and/or modality-specific imputation). These approaches, while effective for their intended purposes, had limitations in their applicability across different tasks and sensor modalities. This raises an important question: Can we build a task-agnostic imputation pipeline that is transferable to new sensors without requiring additional training? In this work, we formalise the concept of zero-shot imputation and propose a novel approach that enables the adaptation of pre-trained models to handle data intermittency. This framework, named NeuralPrefix, is a generative neural component that precedes a task model during inference, filling in gaps caused by data intermittency. NeuralPrefix is built as a continuous dynamical system, where its internal state can be estimated at any point in time by solving an Ordinary Differential Equation (ODE). This approach allows for a more versatile and adaptable imputation method, overcoming the limitations of task-specific and modality-specific solutions. We conduct a comprehensive evaluation of NeuralPrefix on multiple sensory datasets, demonstrating its effectiveness across various domains. When tested on intermittent data with a high 50% missing data rate, NeuralPreifx accurately recovers all the missing samples, achieving SSIM score between 0.93-0.96. Zero-shot evaluations show that NeuralPrefix generalises well to unseen datasets, even when the measurements come from a different modality.', 'abstract_zh': '无监督填补挑战：NeuralPrefix框架在新传感器上的可迁移性研究', 'title_zh': 'NeuralPrefix: 一种零样本感官数据插值插件'}
{'arxiv_id': 'arXiv:2502.05879', 'title': 'Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models', 'authors': 'Shiyu Teng, Jiaqing Liu, Rahul Kumar Jain, Shurong Chai, Ruibo Hou, Tomoko Tateyama, Lanfen Lin, Yen-wei Chen', 'link': 'https://arxiv.org/abs/2502.05879', 'abstract': 'Depression is one of the leading causes of disability worldwide, posing a severe burden on individuals, healthcare systems, and society at large. Recent advancements in Large Language Models (LLMs) have shown promise in addressing mental health challenges, including the detection of depression through text-based analysis. However, current LLM-based methods often struggle with nuanced symptom identification and lack a transparent, step-by-step reasoning process, making it difficult to accurately classify and explain mental health conditions. To address these challenges, we propose a Chain-of-Thought Prompting approach that enhances both the performance and interpretability of LLM-based depression detection. Our method breaks down the detection process into four stages: (1) sentiment analysis, (2) binary depression classification, (3) identification of underlying causes, and (4) assessment of severity. By guiding the model through these structured reasoning steps, we improve interpretability and reduce the risk of overlooking subtle clinical indicators. We validate our method on the E-DAIC dataset, where we test multiple state-of-the-art large language models. Experimental results indicate that our Chain-of-Thought Prompting technique yields superior performance in both classification accuracy and the granularity of diagnostic insights, compared to baseline approaches.', 'abstract_zh': '全球范围内，抑郁症是导致残疾的主要原因之一，对个人、医疗系统和社会造成了严重的负担。近年来，大型语言模型（LLMs）的进步显示出了应对心理健康挑战的潜力，包括通过文本分析检测抑郁症。然而，当前基于LLM的方法在细微症状识别上常表现出困难，并缺乏透明且步步为营的推理过程，这使得准确分类和解释心理健康状况变得困难。为解决这些挑战，我们提出了一种链式思考提示方法，以提高基于LLM的抑郁症检测的性能和可解释性。我们的方法将检测过程分为四个阶段：（1）情感分析，（2）二元抑郁症分类，（3）识别潜在原因，（4）评估严重程度。通过引导模型遵循这些结构化的推理步骤，我们提高了可解释性并降低了遗漏细微临床指标的风险。我们在E-DAIC数据集上验证了我们的方法，测试了多个最先进的大型语言模型。实验结果表明，与基线方法相比，我们的链式思考提示技术在分类准确性和诊断洞察的细致程度上均表现更优。', 'title_zh': '增强抑郁症检测：从情绪到推理的大语言模型链式思维提示方法'}
{'arxiv_id': 'arXiv:2502.05874', 'title': 'MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation', 'authors': 'Zhifei Yang, Keyang Lu, Chao Zhang, Jiaxing Qi, Hanqi Jiang, Ruifei Ma, Shenglin Yin, Yifan Xu, Mingzhe Xing, Zhen Xiao, Jieyi Long, Xiangde Liu, Guangyao Zhai', 'link': 'https://arxiv.org/abs/2502.05874', 'abstract': 'Controllable 3D scene generation has extensive applications in virtual reality and interior design, where the generated scenes should exhibit high levels of realism and controllability in terms of geometry. Scene graphs provide a suitable data representation that facilitates these applications. However, current graph-based methods for scene generation are constrained to text-based inputs and exhibit insufficient adaptability to flexible user inputs, hindering the ability to precisely control object geometry. To address this issue, we propose MMGDreamer, a dual-branch diffusion model for scene generation that incorporates a novel Mixed-Modality Graph, visual enhancement module, and relation predictor. The mixed-modality graph allows object nodes to integrate textual and visual modalities, with optional relationships between nodes. It enhances adaptability to flexible user inputs and enables meticulous control over the geometry of objects in the generated scenes. The visual enhancement module enriches the visual fidelity of text-only nodes by constructing visual representations using text embeddings. Furthermore, our relation predictor leverages node representations to infer absent relationships between nodes, resulting in more coherent scene layouts. Extensive experimental results demonstrate that MMGDreamer exhibits superior control of object geometry, achieving state-of-the-art scene generation performance. Project page: this https URL.', 'abstract_zh': '可控的3D场景生成在虚拟现实和室内设计中有广泛的应用，生成的场景在几何方面应具有高度的真实感和可控性。场景图提供了一种合适的数据表示形式，有助于这些应用。然而，当前基于图的方法在场景生成中仅限于文本输入，并且对灵活的用户输入适应性不足，阻碍了对对象几何细节的精确控制。为了解决这一问题，我们提出MMGDreamer，一种结合了新型混合模态图、视觉增强模块和关系预测器的双分支扩散模型。混合模态图使对象节点能够结合文本和视觉模态，并且节点之间可以有选择地建立关系，增强了对灵活用户输入的适应性，并能够对生成场景中的对象几何进行细致控制。视觉增强模块通过利用文本嵌入构建视觉表示来丰富仅文本节点的视觉保真度。此外，我们的关系预测器利用节点表示来推断节点之间缺失的关系，从而产生更加连贯的场景布局。大量实验结果表明，MMGDreamer 在对象几何控制方面表现出优越性，达到最先进的场景生成性能。项目页面：this https URL。', 'title_zh': 'MMGDreamer：混合模态图用于几何可控的3D室内场景生成'}
{'arxiv_id': 'arXiv:2502.05863', 'title': "Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education", 'authors': 'Yanhao Jia, Xinyi Wu, Hao Li, Qinglin Zhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan', 'link': 'https://arxiv.org/abs/2502.05863', 'abstract': 'In AI-facilitated teaching, leveraging various query styles to interpret abstract text descriptions is crucial for ensuring high-quality teaching. However, current retrieval models primarily focus on natural text-image retrieval, making them insufficiently tailored to educational scenarios due to the ambiguities in the retrieval process. In this paper, we propose a diverse expression retrieval task tailored to educational scenarios, supporting retrieval based on multiple query styles and expressions. We introduce the STEM Education Retrieval Dataset (SER), which contains over 24,000 query pairs of different styles, and the Uni-Retrieval, an efficient and style-diversified retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts query style features as prototypes and builds a continuously updated Prompt Bank containing prompt tokens for diverse queries. This bank can updated during test time to represent domain-specific knowledge for different subject retrieval scenarios. Our framework demonstrates scalability and robustness by dynamically retrieving prompt tokens based on prototype similarity, effectively facilitating learning for unknown queries. Experimental results indicate that Uni-Retrieval outperforms existing retrieval models in most retrieval tasks. This advancement provides a scalable and precise solution for diverse educational needs.', 'abstract_zh': '在AI辅助教学中，利用多种查询风格解释抽象的文字描述对于确保高质量的教学至关重要。然而，当前的检索模型主要集中在自然文本-图像检索上，因检索过程中的歧义性，使其未能充分适应教育场景的需求。本文提出了一种针对教育场景的多样化表达检索任务，支持基于多种查询风格和表达的检索。我们引入了STEM教育检索数据集（SER），包含超过24,000个不同风格的查询对，并提出了一种基于提示调优的高效且风格多样化检索视觉语言模型Uni-Retrieval。Uni-Retrieval提取查询风格特征作为原型，并构建一个不断更新的提示库，包含用于各种查询的提示标记。该库可在测试时更新，以代表不同学科检索场景的领域特定知识。我们的框架通过根据原型相似性动态检索提示标记，展示了可扩展性和鲁棒性，有效促进了未知查询的学习。实验结果表明，Uni-Retrieval在大多数检索任务中优于现有检索模型。这一进展为满足多样化的教育需求提供了可扩展且精确的解决方案。', 'title_zh': 'Uni-Retrieval：面向STEM教育的多风格检索框架'}
{'arxiv_id': 'arXiv:2502.05857', 'title': 'Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds', 'authors': 'Lu Chen, Yizhou Wang, Shixiang Tang, Qianhong Ma, Tong He, Wanli Ouyang, Xiaowei Zhou, Hujun Bao, Sida Peng', 'link': 'https://arxiv.org/abs/2502.05857', 'abstract': 'This paper addresses the task of learning an agent model behaving like humans, which can jointly perceive, predict, and act in egocentric worlds. Previous methods usually train separate models for these three abilities, leading to information silos among them, which prevents these abilities from learning from each other and collaborating effectively. In this paper, we propose a joint predictive agent model, named EgoAgent, that simultaneously learns to represent the world, predict future states, and take reasonable actions with a single transformer. EgoAgent unifies the representational spaces of the three abilities by mapping them all into a sequence of continuous tokens. Learnable query tokens are appended to obtain current states, future states, and next actions. With joint supervision, our agent model establishes the internal relationship among these three abilities and effectively mimics the human inference and learning processes. Comprehensive evaluations of EgoAgent covering image classification, egocentric future state prediction, and 3D human motion prediction tasks demonstrate the superiority of our method. The code and trained model will be released for reproducibility.', 'abstract_zh': '本文探讨了学习一种像人类一样的代理模型的任务，该模型能够在以自我为中心的世界中联合感知、预测和行动。以往的方法通常为这三种能力分别训练独立的模型，导致它们之间存在信息孤岛，阻碍了它们相互学习和有效协作。在本文中，我们提出了一种联合预测代理模型EgoAgent，该模型使用单个变压器同时学习表示世界、预测未来状态和采取合理行动。EgoAgent通过将这三种能力的空间统一映射为连续的标记序列来统一这三种能力的表示空间。通过可学习的查询标记的附加，获得当前状态、未来状态和下一步动作。借助联合监督，我们的代理模型建立了这三种能力之间的内部关系，并有效地模拟了人类的推理和学习过程。全面评估EgoAgent覆盖图像分类、以自我为中心的未来状态预测和3D人体运动预测任务，展示了本方法的优势。代码和训练模型将公开以确保可重现性。', 'title_zh': '从我视角和步骤中学习：自视角世界中的联合预测代理模型'}
{'arxiv_id': 'arXiv:2502.05836', 'title': 'LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification', 'authors': 'Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya', 'link': 'https://arxiv.org/abs/2502.05836', 'abstract': 'In this paper, we address the task of semantic segmentation of legal documents through rhetorical role classification, with a focus on Indian legal judgments. We introduce LegalSeg, the largest annotated dataset for this task, comprising over 7,000 documents and 1.4 million sentences, labeled with 7 rhetorical roles. To benchmark performance, we evaluate multiple state-of-the-art models, including Hierarchical BiLSTM-CRF, TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and Role-Aware Transformers, alongside an exploratory RhetoricLLaMA, an instruction-tuned large language model. Our results demonstrate that models incorporating broader context, structural relationships, and sequential sentence information outperform those relying solely on sentence-level features. Additionally, we conducted experiments using surrounding context and predicted or actual labels of neighboring sentences to assess their impact on classification accuracy. Despite these advancements, challenges persist in distinguishing between closely related roles and addressing class imbalance. Our work underscores the potential of advanced techniques for improving legal document understanding and sets a strong foundation for future research in legal NLP.', 'abstract_zh': '本文通过修辞角色分类任务探讨印度法律判决的语义分割，介绍了包含逾7000份文档和140万句的标注数据集LegalSeg，标注了7种修辞角色。为了benchmark性能，评估了包括层次BiLSTM-CRF、TransformerOverInLegalBERT (ToInLegalBERT)、图神经网络(GNNs)、感知修辞角色的Transformer以及探索性RhetoricLLaMA在内的多种先进模型。结果表明，结合更广泛上下文、结构关系及句子序列信息的模型优于仅依赖句内特征的模型。此外，还利用相邻句子的上下文信息和预测或实际标签进行了实验，以评估其对分类准确率的影响。尽管取得了进展，但在区分紧密相关角色和解决类别不平衡问题方面仍面临挑战。本文强调了高级技术在提高法律文件理解方面的潜力，并为未来的法律NLP研究奠定了坚实基础。', 'title_zh': 'LegalSeg: 通过修辞角色分类解锁印度法律判决的结构'}
{'arxiv_id': 'arXiv:2502.05835', 'title': 'Contrastive Representation Distillation via Multi-Scale Feature Decoupling', 'authors': 'Cuipeng Wang, Tieyuan Chen, Haipeng Wang', 'link': 'https://arxiv.org/abs/2502.05835', 'abstract': "Knowledge distillation is a technique aimed at enhancing the performance of a smaller student network without increasing its parameter size by transferring knowledge from a larger, pre-trained teacher network. Previous approaches have predominantly focused on distilling global feature information while overlooking the importance of disentangling the diverse types of information embedded within different regions of the feature. In this work, we introduce multi-scale decoupling in the feature transfer process for the first time, where the decoupled local features are individually processed and integrated with contrastive learning. Moreover, compared to previous contrastive learning-based distillation methods, our approach not only reduces computational costs but also enhances efficiency, enabling performance improvements for the student network using only single-batch samples. Extensive evaluations on CIFAR-100 and ImageNet demonstrate our method's superiority, with some student networks distilled using our method even surpassing the performance of their pre-trained teacher networks. These results underscore the effectiveness of our approach in enabling student networks to thoroughly absorb knowledge from teacher networks.", 'abstract_zh': '多尺度解耦特征转移与对比学习的知识蒸馏', 'title_zh': '多尺度特征解耦的对比表示蒸馏'}
{'arxiv_id': 'arXiv:2502.05832', 'title': 'Compressing Model with Few Class-Imbalance Samples: An Out-of-Distribution Expedition', 'authors': 'Tian-Shuang Wu, Shen-Huan Lyu, Ning Chen, Zhihao Qu, Baoliu Ye', 'link': 'https://arxiv.org/abs/2502.05832', 'abstract': 'In recent years, as a compromise between privacy and performance, few-sample model compression has been widely adopted to deal with limited data resulting from privacy and security concerns. However, when the number of available samples is extremely limited, class imbalance becomes a common and tricky problem. Achieving an equal number of samples across all classes is often costly and impractical in real-world applications, and previous studies on few-sample model compression have mostly ignored this significant issue. Our experiments comprehensively demonstrate that class imbalance negatively affects the overall performance of few-sample model compression methods. To address this problem, we propose a novel and adaptive framework named OOD-Enhanced Few-Sample Model Compression (OE-FSMC). This framework integrates easily accessible out-of-distribution (OOD) data into both the compression and fine-tuning processes, effectively rebalancing the training distribution. We also incorporate a joint distillation loss and a regularization term to reduce the risk of the model overfitting to the OOD data. Extensive experiments on multiple benchmark datasets show that our framework can be seamlessly incorporated into existing few-sample model compression methods, effectively mitigating the accuracy degradation caused by class imbalance.', 'abstract_zh': '面向异常数据增强的小样本模型压缩（OOD-增强的小样本模型压缩）', 'title_zh': '基于少量不平衡类样本的模型压缩：一种异常分布探索'}
{'arxiv_id': 'arXiv:2502.05827', 'title': 'HyGEN: Regularizing Negative Hyperedge Generation for Accurate Hyperedge Prediction', 'authors': 'Song Kyung Yu, Da Eun Lee, Yunyong Ko, Sang-Wook Kim', 'link': 'https://arxiv.org/abs/2502.05827', 'abstract': 'Hyperedge prediction is a fundamental task to predict future high-order relations based on the observed network structure. Existing hyperedge prediction methods, however, suffer from the data sparsity problem. To alleviate this problem, negative sampling methods can be used, which leverage non-existing hyperedges as contrastive information for model training. However, the following important challenges have been rarely studied: (C1) lack of guidance for generating negatives and (C2) possibility of producing false negatives. To address them, we propose a novel hyperedge prediction method, HyGEN, that employs (1) a negative hyperedge generator that employs positive hyperedges as a guidance to generate more realistic ones and (2) a regularization term that prevents the generated hyperedges from being false negatives. Extensive experiments on six real-world hypergraphs reveal that HyGEN consistently outperforms four state-of-the-art hyperedge prediction methods.', 'abstract_zh': '高阶边预测是基于观测网络结构预测未来高阶关系的基本任务。现有的高阶边预测方法面临数据稀疏问题。为缓解这一问题，可以使用负采样方法，利用不存在的高阶边作为模型训练的对比信息。然而，生成负样本的指导不足以及产生虚假负样本的可能性等问题鲜有研究。为解决这些问题，我们提出了一种新颖的高阶边预测方法HyGEN，该方法采用（1）一种高阶边生成器，利用正高阶边作为指导生成更现实的高阶边；（2）一种正则化项，防止生成的高阶边成为虚假负样本。在六个真实世界的超图上的 extensive 实验表明，HyGEN 一贯优于四种最新的高阶边预测方法。', 'title_zh': 'HyGEN: 正则化负超边生成以实现准确的超边预测'}
{'arxiv_id': 'arXiv:2502.05826', 'title': 'MindCraft: Revolutionizing Education through AI-Powered Personalized Learning and Mentorship for Rural India', 'authors': 'Arihant Bardia, Aayush Agrawal', 'link': 'https://arxiv.org/abs/2502.05826', 'abstract': 'MindCraft is a modern platform designed to revolutionize education in rural India by leveraging Artificial Intelligence (AI) to create personalized learning experiences, provide mentorship, and foster resource-sharing. In a country where access to quality education is deeply influenced by geography and socio economic status, rural students often face significant barriers in their educational journeys. MindCraft aims to bridge this gap by utilizing AI to create tailored learning paths, connect students with mentors, and enable a collaborative network of educational resources that transcends both physical and digital divides. This paper explores the challenges faced by rural students, the transformative potential of AI, and how MindCraft offers a scalable, sustainable solution for equitable education system. By focusing on inclusivity, personalized learning, and mentorship, MindCraft seeks to empower rural students, equipping them with the skills, knowledge, and opportunities needed to thrive in an increasingly digital world. Ultimately, MindCraft envisions a future in which technology not only bridges educational gaps but also becomes the driving force for a more inclusive and empowered society.', 'abstract_zh': 'MindCraft是依托人工智能（AI）创造个性化学习体验、提供导师指导并促进资源分享的现代平台，旨在重塑印度农村的教育。在教育质量受地理和社会经济状况深深影响的国家，农村学生在教育旅程中常常面临巨大障碍。MindCraft希望通过利用AI创造个性化学习路径、连接学生与导师，并建立跨越物理与数字鸿沟的协作性教育资源网络来弥合这一差距。本文探讨了农村学生面临的挑战、AI的变革潜力，以及MindCraft提供的可扩展、可持续的公平教育解决方案。通过注重包容性、个性化学习和导师指导，MindCraft旨在赋能农村学生，为其提供在日益数字化的世界中所需的知识、技能和机会。最终，MindCraft构想了一个未来，在这个未来中，技术不仅弥合了教育鸿沟，还成为推动更包容和赋权社会的力量。', 'title_zh': 'MindCraft：通过AI驱动的个性化学习和导师制 revolutionizing 教育以惠及印度农村地区'}
{'arxiv_id': 'arXiv:2502.05825', 'title': 'Delta - Contrastive Decoding Mitigates Text Hallucinations in Large Language Models', 'authors': 'Cheng Peng Huang, Hao-Yuan Chen', 'link': 'https://arxiv.org/abs/2502.05825', 'abstract': 'Large language models (LLMs) demonstrate strong capabilities in natural language processing but remain prone to hallucinations, generating factually incorrect or fabricated content. This issue undermines their reliability, particularly in high-stakes domains such as healthcare and legal advisory. To address this challenge, we propose Delta, an inference-time method that reduces hallucinations without requiring model retraining or additional data. Delta works by randomly masking parts of the input prompt and contrasting the output distributions for the original and masked inputs, effectively suppressing hallucinations through inference-only computations. We evaluate Delta on context-rich question-answering benchmarks, achieving absolute improvements of approximately 3 and 6 percentage points on SQuAD v1.1 and v2, respectively, and 7 and 2 percentage points on TriviaQA and Natural Questions under-sampling decoding. Delta also improves the no-answer exact match score on SQuAD v2 by over ten percentage points, demonstrating its effectiveness in mitigating hallucinations arising from contextual ambiguity. These results highlight Delta as a computationally efficient and scalable approach for improving the reliability of LLMs in real-world applications.', 'abstract_zh': '大规模语言模型（LLMs）在自然语言处理任务中表现出强大的能力，但仍易产生幻觉，生成事实错误或虚构的内容。这一问题削弱了它们的可靠性，特别是在医疗和法律咨询等高风险领域。为解决这一挑战，我们提出Delta，一种推理时的方法，可以在无需模型重新训练或额外数据的情况下减少幻觉。Delta通过随机遮蔽输入提示的部分内容，并对比原始和遮蔽输入的输出分布，仅通过推理计算有效地抑制幻觉。我们在富含上下文的问答基准测试上评估了Delta，分别在SQuAD v1.1和v2上实现了约3和6个百分点的绝对改进，在TrivaQA和Natural Questions欠采样解码下分别实现了7和2个百分点的改进。Delta还在SQuAD v2上显著改善了无答案精确匹配分，这表明其在缓解因上下文歧义引发的幻觉方面具有有效性。这些结果突显了Delta作为提高LLMs在实际应用中可靠性的计算效率和可扩展方法的有效性。', 'title_zh': 'Delta-对比解码缓解大规模语言模型中的文本幻觉'}
{'arxiv_id': 'arXiv:2502.05795', 'title': 'The Curse of Depth in Large Language Models', 'authors': 'Wenfang Sun, Xinyuan Song, Pengxiang Li, Lu Yin, Yefeng Zheng, Shiwei Liu', 'link': 'https://arxiv.org/abs/2502.05795', 'abstract': 'In this paper, we introduce the Curse of Depth, a concept that highlights, explains, and addresses the recent observation in modern Large Language Models(LLMs) where nearly half of the layers are less effective than expected. We first confirm the wide existence of this phenomenon across the most popular families of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis, theoretically and empirically, identifies that the underlying reason for the ineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer Normalization (Pre-LN). While Pre-LN stabilizes the training of Transformer LLMs, its output variance exponentially grows with the model depth, which undesirably causes the derivative of the deep Transformer blocks to be an identity matrix, and therefore barely contributes to the training. To resolve this training pitfall, we propose LayerNorm Scaling, which scales the variance of output of the layer normalization inversely by the square root of its depth. This simple modification mitigates the output variance explosion of deeper Transformer layers, improving their contribution. Our experimental results, spanning model sizes from 130M to 1B, demonstrate that LayerNorm Scaling significantly enhances LLM pre-training performance compared to Pre-LN. Moreover, this improvement seamlessly carries over to supervised fine-tuning. All these gains can be attributed to the fact that LayerNorm Scaling enables deeper layers to contribute more effectively during training.', 'abstract_zh': '本文介绍了深度之难题，这一概念强调并解释了现代大型语言模型（LLMs）中近半层效果低于预期的近期观察现象。我们首先确认了这一现象在Llama、Mistral、DeepSeek和Qwen等最受欢迎的LLM家族中普遍存在。我们的理论与实证分析指出，大型语言模型中深层层无效的原因是广泛使用的前置层标准化（Pre-LN）。尽管Pre-LN稳定了Transformer LLM的训练，但其输出方差随模型深度呈指数增长，这不幸导致深层Transformer块的梯度几乎为单位矩阵，从而对训练贡献甚微。为解决这一训练难题，我们提出了层标准化缩放（LayerNorm Scaling），通过其深度的平方根的逆来缩放层标准化的输出方差。这一简单的修改缓解了更深层Transformer层的输出方差爆炸问题，提高了它们的训练贡献。我们涵盖从130M到1B的模型大小的实验结果表明，层标准化缩放显著提升了与Pre-LN相比的LLM预训练性能。此外，这一改进无缝地应用于监督微调。所有这些增益可归因于层标准化缩放使深层层在训练中能更有效地做出贡献。', 'title_zh': '大型语言模型中的深度诅咒'}
{'arxiv_id': 'arXiv:2502.05788', 'title': 'EPBC-YOLOv8: An efficient and accurate improved YOLOv8 underwater detector based on an attention mechanism', 'authors': 'Xing Jiang, Xiting Zhuang, Jisheng Chen, Jian Zhang', 'link': 'https://arxiv.org/abs/2502.05788', 'abstract': "In this study, we enhance underwater target detection by integrating channel and spatial attention into YOLOv8's backbone, applying Pointwise Convolution in FasterNeXt for the FasterPW model, and leveraging Weighted Concat in a BiFPN-inspired WFPN structure for improved cross-scale connections and robustness. Utilizing CARAFE for refined feature reassembly, our framework addresses underwater image degradation, achieving mAP at 0.5 scores of 76.7 percent and 79.0 percent on URPC2019 and URPC2020 datasets, respectively. These scores are 2.3 percent and 0.7 percent higher than the original YOLOv8, showcasing enhanced precision in detecting marine organisms.", 'abstract_zh': '本研究通过将通道和空间注意力机制集成到YOLOv8的骨干网中，利用 FasterNeXt 中的点wise 卷积对 FasterPW 模型进行改进，并采用受 BiFPN 启发的 WFPN 架构中的加权拼接来增强跨尺度连接和稳健性。利用 CARAFE 进行精细特征重组，本框架解决了水下图像退化问题，在URPC2019和URPC2020数据集上分别实现了0.5分数下的mAP为76.7%和79.0%，高于原始YOLOv8的2.3%和0.7%，展示了在检测海洋生物方面更高的精度。', 'title_zh': 'EPBC-YOLOv8：基于注意力机制的高效精准改进YOLOv8水下检测器'}
{'arxiv_id': 'arXiv:2502.05783', 'title': 'WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch', 'authors': 'Ying Lei, Yancheng Cao, Will Wang, Yuanzhe Dong, Changchang Yin, Weidan Cao, Ping Zhang, Jingzhen Yang, Bingsheng Yao, Yifan Peng, Chunhua Weng, Randy Auerbach, Lena Mamykina, Dakuo Wang, Yuntao Wang, Xuhai Xu', 'link': 'https://arxiv.org/abs/2502.05783', 'abstract': 'While just-in-time interventions (JITIs) have effectively targeted common health behaviors, individuals often have unique needs to intervene in personal undesirable actions that can negatively affect physical, mental, and social well-being. We present WatchGuardian, a smartwatch-based JITI system that empowers users to define custom interventions for these personal actions with a small number of samples. For the model to detect new actions based on limited new data samples, we developed a few-shot learning pipeline that finetuned a pre-trained inertial measurement unit (IMU) model on public hand-gesture datasets. We then designed a data augmentation and synthesis process to train additional classification layers for customization. Our offline evaluation with 26 participants showed that with three, five, and ten examples, our approach achieved an average accuracy of 76.8%, 84.7%, and 87.7%, and an F1 score of 74.8%, 84.2%, and 87.2% We then conducted a four-hour intervention study to compare WatchGuardian against a rule-based intervention. Our results demonstrated that our system led to a significant reduction by 64.0 +- 22.6% in undesirable actions, substantially outperforming the baseline by 29.0%. Our findings underscore the effectiveness of a customizable, AI-driven JITI system for individuals in need of behavioral intervention in personal undesirable actions. We envision that our work can inspire broader applications of user-defined personalized intervention with advanced AI solutions.', 'abstract_zh': '基于智能手环的个性化即时干预系统：WatchGuardian及其应用研究', 'title_zh': 'WatchGuardian: 允许用户定义个性化即时干预的智能手环系统'}
{'arxiv_id': 'arXiv:2502.05777', 'title': 'Predictive Crash Analytics for Traffic Safety using Deep Learning', 'authors': 'Karthik Sivakoti', 'link': 'https://arxiv.org/abs/2502.05777', 'abstract': 'Traditional automated crash analysis systems heavily rely on static statistical models and historical data, requiring significant manual interpretation and lacking real-time predictive capabilities. This research presents an innovative approach to traffic safety analysis through the integration of ensemble learning methods and multi-modal data fusion for real-time crash risk assessment and prediction. Our primary contribution lies in developing a hierarchical severity classification system that combines spatial-temporal crash patterns with environmental conditions, achieving significant improvements over traditional statistical approaches. The system demonstrates a Mean Average Precision (mAP) of 0.893, representing a 15% improvement over current state-of-the-art methods (baseline mAP: 0.776). We introduce a novel feature engineering technique that integrates crash location data with incident reports and weather conditions, achieving 92.4% accuracy in risk prediction and 89.7% precision in hotspot identification. Through extensive validation using 500,000 initial crash records filtered to 59,496 high-quality samples, our solution shows marked improvements in both prediction accuracy and computational efficiency. Key innovations include a robust data cleaning pipeline, adaptive feature generation, and a scalable real-time prediction system capable of handling peak loads of 1,000 concurrent requests while maintaining sub-100ms response times.', 'abstract_zh': '基于集成学习方法和多模态数据融合的实时 crash 风险评估与预测研究', 'title_zh': '基于深度学习的交通安全性事故预测分析'}
{'arxiv_id': 'arXiv:2502.05773', 'title': 'PIPA: Preference Alignment as Prior-Informed Statistical Estimation', 'authors': 'Junbo Li, Zhangyang Wang, Qiang Liu', 'link': 'https://arxiv.org/abs/2502.05773', 'abstract': 'Offline preference alignment for language models such as Direct Preference Optimization (DPO) is favored for its effectiveness and simplicity, eliminating the need for costly reinforcement learning. Various offline algorithms have been developed for different data settings, yet they lack a unified understanding.\nIn this study, we introduce Pior-Informed Preference Alignment (PIPA), a unified, RL-free probabilistic framework that formulates language model preference alignment as a Maximum Likelihood Estimation (MLE) problem with prior constraints. This method effectively accommodates both paired and unpaired data, as well as answer and step-level annotations. We illustrate that DPO and KTO are special cases with different prior constraints within our framework. By integrating different types of prior information, we developed two variations of PIPA: PIPA-M and PIPA-N. Both algorithms demonstrate a $3\\sim10\\%$ performance enhancement on the GSM8K and MATH benchmarks across all configurations, achieving these gains without additional training or computational costs compared to existing algorithms.', 'abstract_zh': 'Offline Preference Alignment for Language Models: A Unified, RL-Free Probabilistic Framework with Pior-Informed Preference Alignment (PIPA)', 'title_zh': 'PIPA：先验信息引导的统计估计&equest;'}
{'arxiv_id': 'arXiv:2502.05772', 'title': 'Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails', 'authors': 'Yijun Yang, Lichao Wang, Xiao Yang, Lanqing Hong, Jun Zhu', 'link': 'https://arxiv.org/abs/2502.05772', 'abstract': "Vision Large Language Models (VLLMs) integrate visual data processing, expanding their real-world applications, but also increasing the risk of generating unsafe responses. In response, leading companies have implemented Multi-Layered safety defenses, including alignment training, safety system prompts, and content moderation. However, their effectiveness against sophisticated adversarial attacks remains largely unexplored. In this paper, we propose MultiFaceted Attack, a novel attack framework designed to systematically bypass Multi-Layered Defenses in VLLMs. It comprises three complementary attack facets: Visual Attack that exploits the multimodal nature of VLLMs to inject toxic system prompts through images; Alignment Breaking Attack that manipulates the model's alignment mechanism to prioritize the generation of contrasting responses; and Adversarial Signature that deceives content moderators by strategically placing misleading information at the end of the response. Extensive evaluations on eight commercial VLLMs in a black-box setting demonstrate that MultiFaceted Attack achieves a 61.56% attack success rate, surpassing state-of-the-art methods by at least 42.18%.", 'abstract_zh': '多维度攻击：一种系统绕过视觉大型语言模型多层次安全防御的新型攻击框架', 'title_zh': '有效的黑盒多角度攻击突破视觉大型语言模型边界'}
{'arxiv_id': 'arXiv:2502.05749', 'title': 'UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control', 'authors': 'Kaizhen Zhu, Mokai Pan, Yuexin Ma, Yanwei Fu, Jingyi Yu, Jingya Wang, Ye Shi', 'link': 'https://arxiv.org/abs/2502.05749', 'abstract': "Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at this https URL.", 'abstract_zh': '近期基于Doob $h$-变换的扩散桥梁模型进步显著，能够在保持端点固定的条件下连接不同的概率分布，在图像转换和恢复任务中展现出有希望的结果。然而，这些方法经常产生模糊或过度平滑的图像细节，并缺乏全面的理论基础来解释这些不足。为了解决这些限制，我们提出了基于随机最优控制（SOC）的统一框架UniDB。UniDB通过基于SOC的优化问题形式化表述，并推导出最优控制器的闭式解，从而统一并推广了现有的扩散桥梁模型。我们证明，使用Doob $h$-变换的现有扩散桥梁模型可以被视为我们框架的一个特例，在SOC成本函数中的终止惩罚系数趋向无穷大时出现。通过引入可调的终止惩罚系数，UniDB 实现了控制成本与终止惩罚之间的最佳平衡，显著改善了细节保留和输出质量。值得注意的是，UniDB 可无缝集成到现有的扩散桥梁模型中，只需进行少量代码修改。广泛实验表明，我们提出的框架具有优越性和适应性。我们的代码可在以下链接获取。', 'title_zh': 'UniDB：通过随机最优控制的统一扩散桥梁框架'}
{'arxiv_id': 'arXiv:2502.05740', 'title': 'RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care', 'authors': 'Ziqi Yang, Yuxuan Lu, Jennifer Bagdasarian, Vedant Das Swain, Ritu Agarwal, Collin Campbell, Waddah Al-Refaire, Jehan El-Bayoumi, Guodong Gao, Dakuo Wang, Bingsheng Yao, Nawar Shara', 'link': 'https://arxiv.org/abs/2502.05740', 'abstract': 'Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group of cancers that account for more than 35% of cancer-related deaths worldwide, but postoperative complications are unpredictable and can be life-threatening. In this paper, we investigate how recent advancements in large language models (LLMs) can benefit remote patient monitoring (RPM) systems through clinical integration by designing RECOVER, an LLM-powered RPM system for postoperative GI cancer care. To closely engage stakeholders in the design process, we first conducted seven participatory design sessions with five clinical staff and interviewed five cancer patients to derive six major design strategies for integrating clinical guidelines and information needs into LLM-based RPM systems. We then designed and implemented RECOVER, which features an LLM-powered conversational agent for cancer patients and an interactive dashboard for clinical staff to enable efficient postoperative RPM. Finally, we used RECOVER as a pilot system to assess the implementation of our design strategies with four clinical staff and five patients, providing design implications by identifying crucial design elements, offering insights on responsible AI, and outlining opportunities for future LLM-powered RPM systems.', 'abstract_zh': '最近的大语言模型进展如何通过临床集成益于胃肠癌术后远程患者监测系统：RECOVER的设计与评估', 'title_zh': 'RECOVER: 基于大型语言模型的术后胃肠癌患者远程监测系统设计'}
{'arxiv_id': 'arXiv:2502.05739', 'title': 'Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning', 'authors': 'Ruotong Geng, Mingyang Geng, Shangwen Wang, Haotian Wang, Zhipeng Lin, Dezun Dong', 'link': 'https://arxiv.org/abs/2502.05739', 'abstract': 'Large Language Models for Code (LLMs4Code) excel at code generation tasks, yielding promise to release developers from huge software development burdens. Nonetheless, these models have been shown to suffer from the significant privacy risks due to the potential leakage of sensitive information embedded during training, known as the memorization problem. Addressing this issue is crucial for ensuring privacy compliance and upholding user trust, but till now there is a dearth of dedicated studies in the literature that focus on this specific direction. Recently, machine unlearning has emerged as a promising solution by enabling models to "forget" sensitive information without full retraining, offering an efficient and scalable approach compared to traditional data cleaning methods. In this paper, we empirically evaluate the effectiveness of unlearning techniques for addressing privacy concerns in this http URL, we investigate three state-of-the-art unlearning algorithms and three well-known open-sourced LLMs4Code, on a benchmark that takes into consideration both the privacy data to be forgotten as well as the code generation capabilites of these models. Results show that it is feasible to mitigate the privacy concerns of LLMs4Code through machine unlearning while maintain their code generation capabilities at the same time. We also dissect the forms of privacy protection/leakage after unlearning and observe that there is a shift from direct leakage to indirect leakage, which underscores the need for future studies addressing this risk.', 'abstract_zh': '大规模语言模型在代码生成中的去学习技术对于缓解隐私担忧的有效性研究', 'title_zh': '通过机器遗忘技术缓解LLMs4Code中敏感信息泄露问题'}
{'arxiv_id': 'arXiv:2502.05724', 'title': 'Rethinking Link Prediction for Directed Graphs', 'authors': 'Mingguo He, Yuhe Guo, Yanping Zheng, Zhewei Wei, Stephan Günnemann, Xiaokui Xiao', 'link': 'https://arxiv.org/abs/2502.05724', 'abstract': 'Link prediction for directed graphs is a crucial task with diverse real-world applications. Recent advances in embedding methods and Graph Neural Networks (GNNs) have shown promising improvements. However, these methods often lack a thorough analysis of embedding expressiveness and suffer from ineffective benchmarks for a fair evaluation. In this paper, we propose a unified framework to assess the expressiveness of existing methods, highlighting the impact of dual embeddings and decoder design on performance. To address limitations in current experimental setups, we introduce DirLinkBench, a robust new benchmark with comprehensive coverage and standardized evaluation. The results show that current methods struggle to achieve strong performance on the new benchmark, while DiGAE outperforms others overall. We further revisit DiGAE theoretically, showing its graph convolution aligns with GCN on an undirected bipartite graph. Inspired by these insights, we propose a novel spectral directed graph auto-encoder SDGAE that achieves SOTA results on DirLinkBench. Finally, we analyze key factors influencing directed link prediction and highlight open challenges.', 'abstract_zh': '有向图链接预测是一个具有多种实际应用的关键任务。最近的嵌入方法和图神经网络（GNNs）的进步展现了有希望的改进。然而，这些方法常常缺乏对嵌入表征能力的全面分析，并且缺乏有效的基准测试来实现公平的评估。本文提出了一种统一框架来评估现有方法的表征能力，并强调了双嵌入和解码器设计对性能的影响。为了应对当前实验设置的局限性，我们引入了DirLinkBench这一新的稳健基准，该基准具有全面覆盖和标准化评估。结果表明，当前方法在新基准上难以实现 strong 表现，而 DiGAE 整体上表现出色。我们进一步从理论上重新审视了 DiGAE，证明其图卷积在无向二分图上与 GCN 一致。受这些见解的启发，我们提出了一种新颖的谱有向图自编码器 SDGAE，该模型在 DirLinkBench 上取得了 SOTA 结果。最后，我们分析了影响有向链接预测的关键因素，并指出了开放挑战。', 'title_zh': '重思有向图中的链接预测'}
{'arxiv_id': 'arXiv:2502.05720', 'title': 'Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search', 'authors': 'Ziyad Benomar, Lorenzo Croissant, Vianney Perchet, Spyros Angelopoulos', 'link': 'https://arxiv.org/abs/2502.05720', 'abstract': 'One-max search is a classic problem in online decision-making, in which a trader acts on a sequence of revealed prices and accepts one of them irrevocably to maximise its profit. The problem has been studied both in probabilistic and in worst-case settings, notably through competitive analysis, and more recently in learning-augmented settings in which the trader has access to a prediction on the sequence. However, existing approaches either lack smoothness, or do not achieve optimal worst-case guarantees: they do not attain the best possible trade-off between the consistency and the robustness of the algorithm. We close this gap by presenting the first algorithm that simultaneously achieves both of these important objectives. Furthermore, we show how to leverage the obtained smoothness to provide an analysis of one-max search in stochastic learning-augmented settings which capture randomness in both the observed prices and the prediction.', 'abstract_zh': 'One-max 搜索是在线决策中的一个经典问题，在该问题中，交易者对一系列公布的价格做出反应，并不可撤销地接受其中一个以最大化其利润。该问题在概率性和最坏情况设置下均有研究，尤其是通过竞 competitiveness 分析进行研究，并且最近在预测增强的学习环境下的研究中也有涉及，其中交易者可以访问价格序列的预测。然而，现有方法要么缺乏平滑性，要么未能实现最优的最坏情况保证：它们未能在一致性与鲁棒性之间达到最佳权衡。我们通过提出第一个同时实现这两个重要目标的算法来填补这一空白。此外，我们展示了如何利用获得的平滑性来分析随机增强学习环境下的 one-max 搜索，该环境既包含了观测价格中的随机性，也包含了预测中的随机性。', 'title_zh': 'Pareto-最优性、平滑性与随机性在学习增强的一最大化搜索中的应用'}
{'arxiv_id': 'arXiv:2502.05719', 'title': 'Extended Histogram-based Outlier Score (EHBOS)', 'authors': 'Tanvir Islam', 'link': 'https://arxiv.org/abs/2502.05719', 'abstract': 'Histogram-Based Outlier Score (HBOS) is a widely used outlier or anomaly detection method known for its computational efficiency and simplicity. However, its assumption of feature independence limits its ability to detect anomalies in datasets where interactions between features are critical. In this paper, we propose the Extended Histogram-Based Outlier Score (EHBOS), which enhances HBOS by incorporating two-dimensional histograms to capture dependencies between feature pairs. This extension allows EHBOS to identify contextual and dependency-driven anomalies that HBOS fails to detect. We evaluate EHBOS on 17 benchmark datasets, demonstrating its effectiveness and robustness across diverse anomaly detection scenarios. EHBOS outperforms HBOS on several datasets, particularly those where feature interactions are critical in defining the anomaly structure, achieving notable improvements in ROC AUC. These results highlight that EHBOS can be a valuable extension to HBOS, with the ability to model complex feature dependencies. EHBOS offers a powerful new tool for anomaly detection, particularly in datasets where contextual or relational anomalies play a significant role.', 'abstract_zh': '基于直方图的扩展异常评分（EHBOS）：考虑特征间依赖性的异常检测方法', 'title_zh': '基于扩展直方图的离群点分数(EHBOS)'}
{'arxiv_id': 'arXiv:2502.05714', 'title': 'Proving the Coding Interview: A Benchmark for Formally Verified Code Generation', 'authors': 'Quinn Dougherty, Ronak Mehta', 'link': 'https://arxiv.org/abs/2502.05714', 'abstract': 'We introduce the Formally Verified Automated Programming Progress Standards, or FVAPPS, a benchmark of 4715 samples for writing programs and proving their correctness, the largest formal verification benchmark, including 1083 curated and quality controlled samples. Previously, APPS provided a benchmark and dataset for programming puzzles to be completed in Python and checked against unit tests, of the kind seen in technical assessments in the software engineering industry. Building upon recent approaches for benchmarks in interactive theorem proving, we generalize the unit tests to Lean 4 theorems given without proof (i.e., using Lean\'s "sorry" keyword). On the 406 theorems of 100 randomly selected samples, Sonnet correctly proves 30% and Gemini correctly proves 18%. We challenge the machine learning and program synthesis communities to solve both each general purpose programming problem and its associated correctness specifications. The benchmark is available at this https URL.', 'abstract_zh': '正式验证自动编程进展标准：FVAPPS及其基准测试', 'title_zh': '证明的编码面试：正式验证代码生成的基准'}
{'arxiv_id': 'arXiv:2502.05713', 'title': '4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis', 'authors': 'An Zhao, Moucheng Xu, Ahmed H. Shahin, Wim Wuyts, Mark G. Jones, Joseph Jacob, Daniel C. Alexander', 'link': 'https://arxiv.org/abs/2502.05713', 'abstract': 'Understanding the progression trajectories of diseases is crucial for early diagnosis and effective treatment planning. This is especially vital for life-threatening conditions such as Idiopathic Pulmonary Fibrosis (IPF), a chronic, progressive lung disease with a prognosis comparable to many cancers. Computed tomography (CT) imaging has been established as a reliable diagnostic tool for IPF. Accurately predicting future CT scans of early-stage IPF patients can aid in developing better treatment strategies, thereby improving survival outcomes. In this paper, we propose 4D Vector Quantised Generative Adversarial Networks (4D-VQ-GAN), a model capable of generating realistic CT volumes of IPF patients at any time point. The model is trained using a two-stage approach. In the first stage, a 3D-VQ-GAN is trained to reconstruct CT volumes. In the second stage, a Neural Ordinary Differential Equation (ODE) based temporal model is trained to capture the temporal dynamics of the quantised embeddings generated by the encoder in the first stage. We evaluate different configurations of our model for generating longitudinal CT scans and compare the results against ground truth data, both quantitatively and qualitatively. For validation, we conduct survival analysis using imaging biomarkers derived from generated CT scans and achieve a C-index comparable to that of biomarkers derived from the real CT scans. The survival analysis results demonstrate the potential clinical utility inherent to generated longitudinal CT scans, showing that they can reliably predict survival outcomes.', 'abstract_zh': '理解疾病进展轨迹对于早期诊断和有效治疗规划至关重要。这对于如特发性肺纤维化（IPF）等致命性疾病尤为关键，IPF是一种慢性进行性肺疾病，预后与许多癌症相似。计算机断层扫描（CT）成像已被证明是诊断IPF的一种可靠工具。准确预测早期IPF患者的未来CT扫描有助于制定更好的治疗策略，从而提高生存率。在本文中，我们提出了一种4D向量量化生成对抗网络（4D-VQ-GAN）模型，该模型能够生成任意时间点IPF患者的逼真CT体积。该模型采用两阶段训练方法。第一阶段，使用3D-VQ-GAN训练重建CT体积；第二阶段，使用基于神经常微分方程（ODE）的时间模型训练，以捕捉第一阶段编码器生成的量化嵌入的时间动态变化。我们评估了不同配置的模型用于生成纵向CT扫描，并与真实数据进行对比，从定量和定性两个方面进行了比较。通过使用从生成的CT扫描中提取的成像生物标志物进行生存分析，我们在C指数上达到了与真实CT扫描生物标志物相当的结果。生存分析结果表明生成的纵向CT扫描具有潜在的临床应用价值，表明它们能够可靠地预测生存结局。', 'title_zh': '4D VQ-GAN：生成特发性肺纤维化个性化疾病进展建模的任意时间点医学影像合成'}
{'arxiv_id': 'arXiv:2502.05704', 'title': 'Rethinking Word Similarity: Semantic Similarity through Classification Confusion', 'authors': 'Kaitlyn Zhou, Haishan Gao, Sarah Chen, Dan Edelstein, Dan Jurafsky, Chen Shani', 'link': 'https://arxiv.org/abs/2502.05704', 'abstract': 'Word similarity has many applications to social science and cultural analytics tasks like measuring meaning change over time and making sense of contested terms. Yet traditional similarity methods based on cosine similarity between word embeddings cannot capture the context-dependent, asymmetrical, polysemous nature of semantic similarity. We propose a new measure of similarity, Word Confusion, that reframes semantic similarity in terms of feature-based classification confusion. Word Confusion is inspired by Tversky\'s suggestion that similarity features be chosen dynamically. Here we train a classifier to map contextual embeddings to word identities and use the classifier confusion (the probability of choosing a confounding word c instead of the correct target word t) as a measure of the similarity of c and t. The set of potential confounding words acts as the chosen features. Our method is comparable to cosine similarity in matching human similarity judgments across several datasets (MEN, WirdSim353, and SimLex), and can measure similarity using predetermined features of interest. We demonstrate our model\'s ability to make use of dynamic features by applying it to test a hypothesis about changes in the 18th C. meaning of the French word "revolution" from popular to state action during the French Revolution. We hope this reimagining of semantic similarity will inspire the development of new tools that better capture the multi-faceted and dynamic nature of language, advancing the fields of computational social science and cultural analytics and beyond.', 'abstract_zh': '基于词混淆的语义相似度测量在社会科学研究和文化分析任务中的应用', 'title_zh': '重思词相似性：通过分类混淆实现语义相似性'}
{'arxiv_id': 'arXiv:2502.05699', 'title': 'Context information can be more important than reasoning for time series forecasting with a large language model', 'authors': 'Janghoon Yang', 'link': 'https://arxiv.org/abs/2502.05699', 'abstract': 'With the evolution of large language models (LLMs), there is growing interest in leveraging LLMs for time series tasks. In this paper, we explore the characteristics of LLMs for time series forecasting by considering various existing and proposed prompting techniques. Forecasting for both short and long time series was evaluated. Our findings indicate that no single prompting method is universally applicable. It was also observed that simply providing proper context information related to the time series, without additional reasoning prompts, can achieve performance comparable to the best-performing prompt for each case. From this observation, it is expected that providing proper context information can be more crucial than a prompt for specific reasoning in time series forecasting. Several weaknesses in prompting for time series forecasting were also identified. First, LLMs often fail to follow the procedures described by the prompt. Second, when reasoning steps involve simple algebraic calculations with several operands, LLMs often fail to calculate accurately. Third, LLMs sometimes misunderstand the semantics of prompts, resulting in incomplete responses.', 'abstract_zh': '随着大规模语言模型（LLMs）的演进，越来越多的研究兴趣在于利用LLMs进行时间序列任务。本文通过考虑各种现有的和提议的提示技术，探讨了LLMs在时间序列预测中的特性。评估了从短期到长期时间序列的预测性能。研究结果表明，并不存在一种普遍适用的提示方法。观察还表明，仅提供与时间序列相关的适当背景信息，而无需额外的推理提示，可以实现与每种情况最佳提示相当的性能。从这一观察中，预期提供适当背景信息比针对特定推理的提示更为重要。此外，还识别出时间序列预测提示中的若干弱点。首先，LLMs经常不遵循提示描述的程序。其次，当推理步骤涉及多个操作数的简单代数计算时，LLMs往往无法准确计算。第三，LLMs有时会误解提示的语义，导致回答不完整。', 'title_zh': '大规模语言模型时间序列预测中，上下文信息的重要性可能超过推理'}
{'arxiv_id': 'arXiv:2502.05695', 'title': 'Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks', 'authors': 'Zijiang Yan, Jianhua Pei, Hongda Wu, Hina Tabassum, Ping Wang', 'link': 'https://arxiv.org/abs/2502.05695', 'abstract': 'This paper proposes a novel framework for real-time adaptive-bitrate video streaming by integrating latent diffusion models (LDMs) within the FFmpeg techniques. This solution addresses the challenges of high bandwidth usage, storage inefficiencies, and quality of experience (QoE) degradation associated with traditional constant bitrate streaming (CBS) and adaptive bitrate streaming (ABS). The proposed approach leverages LDMs to compress I-frames into a latent space, offering significant storage and semantic transmission savings without sacrificing high visual quality. While it keeps B-frames and P-frames as adjustment metadata to ensure efficient video reconstruction at the user side, the proposed framework is complemented with the most state-of-the-art denoising and video frame interpolation (VFI) techniques. These techniques mitigate semantic ambiguity and restore temporal coherence between frames, even in noisy wireless communication environments. Experimental results demonstrate the proposed method achieves high-quality video streaming with optimized bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and resource efficiency. This work opens new possibilities for scalable real-time video streaming in 5G and future post-5G networks.', 'abstract_zh': '本文提出了一种将潜在扩散模型（LDMs）整合到FFmpeg技术中的新颖框架，以实现实时自适应比特率视频流传输。该解决方案解决了传统恒定比特率流传输（CBS）和自适应比特率流传输（ABS）中高带宽使用、存储效率低下及用户体验（QoE）下降的挑战。所提出的方法利用LDMs将I-帧压缩到潜在空间中，同时不牺牲高质量视觉效果，节省了显著的存储和语义传输空间。该方法保持了B-帧和P-帧作为调整元数据，以确保在用户端高效重建视频。与此同时，该框架结合了最先进的去噪和视频帧插补（VFI）技术，这些技术在嘈杂的无线通信环境中降低了语义模糊性并恢复了帧间的时态一致性。实验结果表明，所提出的方法实现了高质量视频流传输，并在QoE和资源效率方面优于现有最先进的解决方案。本文为5G及未来后5G网络中的可扩展实时视频流传输打开了新的可能性。', 'title_zh': '基于潜在扩散模型的面向无线网络的语义意识自适应视频流传输'}
{'arxiv_id': 'arXiv:2502.05694', 'title': 'Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT', 'authors': 'Shaoshuai Du, Yiyi Tao, Yixian Shen, Hang Zhang, Yanxin Shen, Xinyu Qiu, Chuanqi Shi', 'link': 'https://arxiv.org/abs/2502.05694', 'abstract': 'This study investigates the performance of various large language models (LLMs) on zero-shot end-to-end relation extraction (RE) in Chinese, a task that integrates entity recognition and relation extraction without requiring annotated data. While LLMs show promise for RE, most prior work focuses on English or assumes pre-annotated entities, leaving their effectiveness in Chinese RE largely unexplored. To bridge this gap, we evaluate ChatGPT, Gemini, and LLaMA based on accuracy, efficiency, and adaptability. ChatGPT demonstrates the highest overall performance, balancing precision and recall, while Gemini achieves the fastest inference speed, making it suitable for real-time applications. LLaMA underperforms in both accuracy and latency, highlighting the need for further adaptation. Our findings provide insights into the strengths and limitations of LLMs for zero-shot Chinese RE, shedding light on trade-offs between accuracy and efficiency. This study serves as a foundation for future research aimed at improving LLM adaptability to complex linguistic tasks in Chinese NLP.', 'abstract_zh': '本研究探究了各类大型语言模型（LLMs）在汉语零样本端到端关系抽取（RE）任务中的表现，该任务结合了实体识别和关系抽取，无需标注数据。虽然LLMs在RE方面显示出潜力，但大部分先前工作主要集中在英语上或假设预先标注的实体，使其在中国RE的有效性方面鲜有研究。为填补这一空白，我们基于准确率、效率和适应性对ChatGPT、Gemini和LLaMA进行了评估。ChatGPT在整体性能上表现最佳，平衡了精确率和召回率；Gemini实现最快推理速度，适用于实时应用；LLaMA在准确率和延迟方面表现不佳，突显了进一步适应的必要性。我们的研究提供了关于LLMs在零样本汉语RE中的优缺点的见解，并探讨了准确率和效率之间的权衡。本研究为未来旨在提高LLMs适应复杂汉语语言任务的NLP研究奠定了基础。', 'title_zh': '零样本端到端中文关系提取：Gemini、LLaMA和ChatGPT的比较研究'}
{'arxiv_id': 'arXiv:2502.05685', 'title': 'Mobile Application Threats and Security', 'authors': 'Timur Mirzoev, Mark Miller, Shamimara Lasker, Michael Brannon', 'link': 'https://arxiv.org/abs/2502.05685', 'abstract': 'The movement to mobile computing solutions provides flexibility to different users whether it is a business user, a student, or even providing entertainment to children and adults of all ages. Due to these emerging technologies mobile users are unable to safeguard private information in a very effective way and cybercrimes are increasing day by day. This manuscript will focus on security vulnerabilities in the mobile computing industry, especially focusing on tablets and smart phones. This study will dive into current security threats for the Android & Apple iOS market, exposing security risks and threats that the novice or average user may not be aware of. The purpose of this study is to analyze current security risks and threats, and provide solutions that may be deployed to protect against such threats.', 'abstract_zh': '移动计算解决方案的推广为不同的用户提供了灵活性，无论是商业用户、学生，还是为各年龄段的儿童和成人提供娱乐。由于这些新兴技术，移动用户无法有效保护私人信息，网络犯罪日益增多。本文将关注移动计算行业的安全漏洞，特别是针对平板电脑和智能手机。本研究将深入探讨Android和Apple iOS市场的当前安全威胁，揭露新手或普通用户可能 unaware 的安全风险和威胁。本文的研究目的是分析当前的安全风险和威胁，并提供可能部署的解决方案以防止这些威胁。', 'title_zh': '移动应用威胁与安全'}
{'arxiv_id': 'arXiv:2502.05684', 'title': 'Machine Unlearning via Information Theoretic Regularization', 'authors': 'Shizhou Xu, Thomas Strohmer', 'link': 'https://arxiv.org/abs/2502.05684', 'abstract': 'How can we effectively remove or "unlearn" undesirable information, such as specific features or individual data points, from a learning outcome while minimizing utility loss and ensuring rigorous guarantees? We introduce a mathematical framework based on information-theoretic regularization to address both feature and data point unlearning. For feature unlearning, we derive a unified solution that simultaneously optimizes diverse learning objectives, including entropy, conditional entropy, KL-divergence, and the energy of conditional probability. For data point unlearning, we first propose a novel definition that serves as a practical condition for unlearning via retraining, is easy to verify, and aligns with the principles of differential privacy from an inference perspective. Then, we provide provable guarantees for our framework on data point unlearning. By combining flexibility in learning objectives with simplicity in regularization design, our approach is highly adaptable and practical for a wide range of machine learning and AI applications.', 'abstract_zh': '如何在最小化实用性损失的同时，确保严格保证地从学习成果中有效地移除或“忘掉”不良信息（如特定特征或个体数据点），并确保数据点忘掉的严谨性？我们提出了一种基于信息论正则化的方法，以解决特征和数据点忘掉的问题。对于特征忘掉，我们推导出一个统一的解决方案，同时优化包括熵、条件熵、KL散度和条件概率的能量在内的多种学习目标。对于数据点忘掉，我们首先提出了一种新的定义，作为通过重新训练实现忘掉的实用条件，易于验证，并从推理视角与差分隐私的原则一致。然后，我们为我们的框架提供了数据点忘掉的可证明保证。通过在学习目标上的灵活性与正则化设计的简单性相结合，我们的方法具有高度的适应性和实用性，适用于广泛的人工智能和机器学习应用。', 'title_zh': '基于信息论正则化的机器卸载'}
{'arxiv_id': 'arXiv:2502.05672', 'title': 'On the Convergence and Stability of Upside-Down Reinforcement Learning, Goal-Conditioned Supervised Learning, and Online Decision Transformers', 'authors': 'Miroslav Štrupl, Oleg Szehr, Francesco Faccio, Dylan R. Ashley, Rupesh Kumar Srivastava, Jürgen Schmidhuber', 'link': 'https://arxiv.org/abs/2502.05672', 'abstract': 'This article provides a rigorous analysis of convergence and stability of Episodic Upside-Down Reinforcement Learning, Goal-Conditioned Supervised Learning and Online Decision Transformers. These algorithms performed competitively across various benchmarks, from games to robotic tasks, but their theoretical understanding is limited to specific environmental conditions. This work initiates a theoretical foundation for algorithms that build on the broad paradigm of approaching reinforcement learning through supervised learning or sequence modeling. At the core of this investigation lies the analysis of conditions on the underlying environment, under which the algorithms can identify optimal solutions. We also assess whether emerging solutions remain stable in situations where the environment is subject to tiny levels of noise. Specifically, we study the continuity and asymptotic convergence of command-conditioned policies, values and the goal-reaching objective depending on the transition kernel of the underlying Markov Decision Process. We demonstrate that near-optimal behavior is achieved if the transition kernel is located in a sufficiently small neighborhood of a deterministic kernel. The mentioned quantities are continuous (with respect to a specific topology) at deterministic kernels, both asymptotically and after a finite number of learning cycles. The developed methods allow us to present the first explicit estimates on the convergence and stability of policies and values in terms of the underlying transition kernels. On the theoretical side we introduce a number of new concepts to reinforcement learning, like working in segment spaces, studying continuity in quotient topologies and the application of the fixed-point theory of dynamical systems. The theoretical study is accompanied by a detailed investigation of example environments and numerical experiments.', 'abstract_zh': '本文提供了对Episodic Upside-Down强化学习、目标条件监督学习和在线决策变换器等算法收敛性和稳定性的严格分析。这些算法在从游戏到机器人任务的各种基准测试中表现出色，但其理论理解仅限于特定的环境条件。本文为基于监督学习或序列建模框架的强化学习算法构建了一个理论基础。本文的核心在于分析算法能够在何种环境条件下识别出最优解，并评估在环境存在微小噪声的情况下，这些解决方案是否保持稳定。具体而言，我们研究了命令条件策略、价值和目标从属目标随基本马尔可夫决策过程转移核变化的连续性和渐近收敛性。研究表明，如果转移核位于确定性核的一个足够小的邻域内，则可以实现接近最优的行为。这些量在确定性核处都是连续的（以特定拓扑为准），无论是渐近意义上还是在有限的学习周期后。本文所发展的方法使我们能够首次明确给出策略和价值收敛及稳定性的估计，以基本转移核为准。在理论方面，我们引入了几个新的概念，例如在区间空间中工作、研究商拓扑下的连续性和动力系统不动点理论的应用。理论研究伴随着对示例环境的详细研究和数值实验。', 'title_zh': 'upside-down 强化学习、目标导向监督学习和在线决策变换器的收敛性和稳定性分析'}
{'arxiv_id': 'arXiv:2502.05670', 'title': 'Language Models Largely Exhibit Human-like Constituent Ordering Preferences', 'authors': 'Ada Defne Tur, Gaurav Kamath, Siva Reddy', 'link': 'https://arxiv.org/abs/2502.05670', 'abstract': "Though English sentences are typically inflexible vis-à-vis word order, constituents often show far more variability in ordering. One prominent theory presents the notion that constituent ordering is directly correlated with constituent weight: a measure of the constituent's length or complexity. Such theories are interesting in the context of natural language processing (NLP), because while recent advances in NLP have led to significant gains in the performance of large language models (LLMs), much remains unclear about how these models process language, and how this compares to human language processing. In particular, the question remains whether LLMs display the same patterns with constituent movement, and may provide insights into existing theories on when and how the shift occurs in human language. We compare a variety of LLMs with diverse properties to evaluate broad LLM performance on four types of constituent movement: heavy NP shift, particle movement, dative alternation, and multiple PPs. Despite performing unexpectedly around particle movement, LLMs generally align with human preferences around constituent ordering.", 'abstract_zh': '尽管英语句子在词序方面通常缺乏灵活性，但构成成分在排列顺序上表现出极大的变异性。一种 prominently 理论提出，构成成分的排列顺序与其重量——衡量构成成分长度或复杂性的指标——直接相关。此类理论在自然语言处理（NLP）的背景下具有重要意义，因为虽然近年来NLP的进步显著提高了大规模语言模型（LLMs）的性能，但仍有许多关于LLMs如何处理语言以及这与人类语言处理的差异之处尚不清楚的问题。特别是，关于构成成分移动模式的问题仍未解答，LLMs 是否表现出与人类相同的模式，这个问题可能为现有理论提供洞见，说明构成成分移动在人类语言中何时以及如何发生。我们比较了具有多样化属性的各种LLMs，以评估它们在四种构成成分移动类型（重NP移动、部分移动、宾语转换以及多个介词短语）上的广泛表现。尽管在部分移动方面表现不佳，但LLMs 通常与人类在构成成分排列上的偏好保持一致。', 'title_zh': '语言模型在成分排序上 largely 展现人类-like 的偏好。'}
{'arxiv_id': 'arXiv:2502.05664', 'title': 'CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging', 'authors': 'Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez', 'link': 'https://arxiv.org/abs/2502.05664', 'abstract': "Large Language Models (LLMs) have made significant strides in code generation and problem solving. Current approaches employ external tool-based iterative debuggers that use compiler or other tool-based runtime feedback to refine coarse programs generated by various methods. However, the effectiveness of these approaches heavily relies on the quality of the initial code generation, which remains an open challenge. In this paper, we introduce CodeSim, a novel multi-agent code generation framework that comprehensively addresses the stages of program synthesis-planning, coding, and debugging-through a human-like perception approach. As human verifies their understanding of any algorithms through visual simulation, CodeSim uniquely features a method of plan verification and internal debugging through the step-by-step simulation of input/output. Extensive experiments across seven challenging competitive problem-solving and program synthesis benchmarks demonstrate CodeSim's remarkable code generation capabilities. Our framework achieves new state-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and CodeContests 29.1%). Furthermore, our method shows potential for even greater enhancement when cascaded with external debuggers. To facilitate further research and development in this area, we have open-sourced our framework in this link (this https URL).", 'abstract_zh': '大型语言模型在代码生成和问题解决方面取得了显著进展。当前的方法通过使用编译器或其他工具的运行时反馈，结合迭代调试工具来逐步优化由各种方法生成的粗糙程序。然而，这些方法的有效性很大程度上取决于初始代码生成的质量，这仍然是一个开放的挑战。在本文中，我们提出了一种名为CodeSim的新型多agent代码生成框架，通过类似于人类感知的方式全面解决了程序合成-规划、编码和调试的各个阶段。就像人类通过视觉仿真验证他们对任何算法的理解一样，CodeSim独特的特征是通过输入/输出的逐步仿真来进行计划验证和内部调试。跨七个具有挑战性的程序合成和问题解决基准的广泛实验表明，CodeSim在代码生成能力方面表现出色。我们的框架在HumanEval 95.1%、MBPP 90.7%、APPS 22%和CodeContests 29.1%等多个方面取得了新的最先进结果。此外，我们的方法与外部调试工具相结合时，显示出更大的增强潜力。为了促进该领域的进一步研究和发展，我们已在下面的链接中开源了我们的框架 (this https URL)。', 'title_zh': 'CODESIM: 多代理代码生成与问题求解通过基于仿真驱动的规划与调试'}
{'arxiv_id': 'arXiv:2502.05651', 'title': 'KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy', 'authors': 'Hyunjong Kim, Suyeon Lee, Yeongjae Cho, Eunseo Ryu, Yohan Jo, Suran Seong, Sungzoon Cho', 'link': 'https://arxiv.org/abs/2502.05651', 'abstract': 'The increasing demand for mental health services has led to the rise of AI-driven mental health chatbots, though challenges related to privacy, data collection, and expertise persist. Motivational Interviewing (MI) is gaining attention as a theoretical basis for boosting expertise in the development of these chatbots. However, existing datasets are showing limitations for training chatbots, leading to a substantial demand for publicly available resources in the field of MI and psychotherapy. These challenges are even more pronounced in non-English languages, where they receive less attention. In this paper, we propose a novel framework that simulates MI sessions enriched with the expertise of professional therapists. We train an MI forecaster model that mimics the behavioral choices of professional therapists and employ Large Language Models (LLMs) to generate utterances through prompt engineering. Then, we present KMI, the first synthetic dataset theoretically grounded in MI, containing 1,000 high-quality Korean Motivational Interviewing dialogues. Through an extensive expert evaluation of the generated dataset and the dialogue model trained on it, we demonstrate the quality, expertise, and practicality of KMI. We also introduce novel metrics derived from MI theory in order to evaluate dialogues from the perspective of MI.', 'abstract_zh': 'AI驱动的心理健康聊天机器人的发展：基于动机访谈理论的专业化挑战与解决方案——以KMI合成数据集为例', 'title_zh': 'KMI：韩国动机 interviews 数据集 for 心理治疗对话'}
{'arxiv_id': 'arXiv:2502.05641', 'title': 'Generating Physically Realistic and Directable Human Motions from Multi-Modal Inputs', 'authors': 'Aayam Shrestha, Pan Liu, German Ros, Kai Yuan, Alan Fern', 'link': 'https://arxiv.org/abs/2502.05641', 'abstract': "This work focuses on generating realistic, physically-based human behaviors from multi-modal inputs, which may only partially specify the desired motion. For example, the input may come from a VR controller providing arm motion and body velocity, partial key-point animation, computer vision applied to videos, or even higher-level motion goals. This requires a versatile low-level humanoid controller that can handle such sparse, under-specified guidance, seamlessly switch between skills, and recover from failures. Current approaches for learning humanoid controllers from demonstration data capture some of these characteristics, but none achieve them all. To this end, we introduce the Masked Humanoid Controller (MHC), a novel approach that applies multi-objective imitation learning on augmented and selectively masked motion demonstrations. The training methodology results in an MHC that exhibits the key capabilities of catch-up to out-of-sync input commands, combining elements from multiple motion sequences, and completing unspecified parts of motions from sparse multimodal input. We demonstrate these key capabilities for an MHC learned over a dataset of 87 diverse skills and showcase different multi-modal use cases, including integration with planning frameworks to highlight MHC's ability to solve new user-defined tasks without any finetuning.", 'abstract_zh': 'This work focuses on从多模态输入中生成现实且基于物理的人类行为，这些输入可能仅部分指定了所需的运动。现有的从示范数据学习类人控制器的方法具备其中一些特性，但并未全部实现。为此，我们提出了掩蔽类人控制器（MHC），一种应用于增强和选择性掩蔽动作示范的多目标模仿学习方法。训练方法使得MHC表现出追赶失步输入命令、结合多个动作序列元素以及从稀疏多模态输入中完成未指定的运动部分的关键能力。我们在一个包含87种多样技能的数据集上学习了一个MHC，并展示了不同的多模态应用场景，包括与规划框架集成以突出MHC解决新用户定义任务的能力，无需任何微调。', 'title_zh': '从多模态输入生成物理真实且可导向的人类运动'}
{'arxiv_id': 'arXiv:2502.05638', 'title': 'ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports', 'authors': 'Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, Carlos A Velasco', 'link': 'https://arxiv.org/abs/2502.05638', 'abstract': "Europe's healthcare systems require enhanced interoperability and digitalization, driving a demand for innovative solutions to process legacy clinical data. This paper presents the results of our project, which aims to leverage Large Language Models (LLMs) to extract structured information from unstructured clinical reports, focusing on patient history, diagnoses, treatments, and other predefined categories. We developed a workflow with a user interface and evaluated LLMs of varying sizes through prompting strategies and fine-tuning. Our results show that fine-tuned smaller models match or surpass larger counterparts in performance, offering efficiency for resource-limited settings. A new dataset of 60,000 annotated English clinical summaries and 24,000 German translations was validated with automated and manual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics. The work highlights the approach's viability and outlines future improvements.", 'abstract_zh': '欧洲的医疗体系需要增强的互操作性和数字化，推动了对处理遗留临床数据的创新解决方案的需求。本文呈现了我们的项目成果，该项目旨在利用大规模语言模型（LLMs）从未结构化的临床报告中提取结构化信息，重点关注患者病史、诊断、治疗以及其他预定义类别。我们开发了一个工作流并设计了用户界面，通过提示策略和微调评估了不同规模的LLMs。结果表明，微调后的较小模型在性能上与较大的模型相当或超越，为资源有限的环境提供效率。我们还验证了一个包含60,000个标注的英语临床摘要和24,000个德语翻译的新数据集，使用了自动和手动检查。评估使用了ROUGE、BERTScore和实体级别指标。该研究突显了该方法的可行性并概述了未来改进的方向。', 'title_zh': 'ELMTEX：大规模语言模型在结构化临床信息提取中的微调。以临床报告为例。'}
{'arxiv_id': 'arXiv:2502.05637', 'title': 'Adversarial Machine Learning: Attacks, Defenses, and Open Challenges', 'authors': 'Pranav K Jha', 'link': 'https://arxiv.org/abs/2502.05637', 'abstract': 'Adversarial Machine Learning (AML) addresses vulnerabilities in AI systems where adversaries manipulate inputs or training data to degrade performance. This article provides a comprehensive analysis of evasion and poisoning attacks, formalizes defense mechanisms with mathematical rigor, and discusses the challenges of implementing robust solutions in adaptive threat models. Additionally, it highlights open challenges in certified robustness, scalability, and real-world deployment.', 'abstract_zh': 'adversarial machine learning (AML) 在对手操控输入或训练数据以削弱人工智能系统性能的漏洞中进行应对。本文提供了对规避攻击和投毒攻击的全面分析，以数学严格性形式化了防御机制，并讨论了在适应性威胁模型中实施稳健解决方案的挑战。此外，本文还强调了在认证稳健性、扩展性和实际部署方面存在的开放性挑战。', 'title_zh': '对抗机器学习：攻击、防御及开放挑战'}
{'arxiv_id': 'arXiv:2502.05615', 'title': 'XiHeFusion: Harnessing Large Language Models for Science Communication in Nuclear Fusion', 'authors': 'Xiao Wang, Qingquan Yang, Fuling Wang, Qiang Chen, Wentao Wu, Yu Jin, Jingtao Jiang, Liye Jin, Bo Jiang, Dengdi Sun, Wanli Lv, Meiwen Chen, Zehua Chen, Guosheng Xu, Jin Tang', 'link': 'https://arxiv.org/abs/2502.05615', 'abstract': 'Nuclear fusion is one of the most promising ways for humans to obtain infinite energy. Currently, with the rapid development of artificial intelligence, the mission of nuclear fusion has also entered a critical period of its development. How to let more people to understand nuclear fusion and join in its research is one of the effective means to accelerate the implementation of fusion. This paper proposes the first large model in the field of nuclear fusion, XiHeFusion, which is obtained through supervised fine-tuning based on the open-source large model Qwen2.5-14B. We have collected multi-source knowledge about nuclear fusion tasks to support the training of this model, including the common crawl, eBooks, arXiv, dissertation, etc. After the model has mastered the knowledge of the nuclear fusion field, we further used the chain of thought to enhance its logical reasoning ability, making XiHeFusion able to provide more accurate and logical answers. In addition, we propose a test questionnaire containing 180+ questions to assess the conversational ability of this science popularization large model. Extensive experimental results show that our nuclear fusion dialogue model, XiHeFusion, can perform well in answering science popularization knowledge. The pre-trained XiHeFusion model is released on this https URL.', 'abstract_zh': '核聚变是人类获取无限能量最具前景的方式之一。随着人工智能的飞速发展，核聚变的任务也进入了发展关键期。让更多人了解核聚变并加入研究是加速其实现的有效手段。本文提出核聚变领域的首个大型模型XiHeFusion，该模型基于开源大型模型Qwen2.5-14B通过监督微调获得。我们收集了关于核聚变任务的多源知识支持该模型的训练，包括common crawl、电子书、arXiv、学位论文等。在模型掌握核聚变领域的知识后，我们进一步通过链式思维增强其逻辑推理能力，使XiHeFusion能够提供更准确和逻辑化的回答。此外，我们提出了包含180多道问题的测试问卷，以评估该科普大型模型的对话能力。大量实验证明，我们的核聚变对话模型XiHeFusion在回答科普知识方面表现良好。预训练的XiHeFusion模型在此处发布：https://url.cn/abcdef', 'title_zh': 'XiHeFusion：利用大型语言模型进行核聚变科学传播'}
{'arxiv_id': 'arXiv:2502.05589', 'title': 'On Memory Construction and Retrieval for Personalized Conversational Agents', 'authors': 'Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Xufang Luo, Hao Cheng, Dongsheng Li, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Jianfeng Gao', 'link': 'https://arxiv.org/abs/2502.05589', 'abstract': 'To deliver coherent and personalized experiences in long-term conversations, existing approaches typically perform retrieval augmented response generation by constructing memory banks from conversation history at either the turn-level, session-level, or through summarization techniques. In this paper, we present two key findings: (1) The granularity of memory unit matters: Turn-level, session-level, and summarization-based methods each exhibit limitations in both memory retrieval accuracy and the semantic quality of the retrieved content. (2) Prompt compression methods, such as \\textit{LLMLingua-2}, can effectively serve as a denoising mechanism, enhancing memory retrieval accuracy across different granularities. Building on these insights, we propose SeCom, a method that constructs a memory bank with topical segments by introducing a conversation Segmentation model, while performing memory retrieval based on Compressed memory units. Experimental results show that SeCom outperforms turn-level, session-level, and several summarization-based methods on long-term conversation benchmarks such as LOCOMO and Long-MT-Bench+. Additionally, the proposed conversation segmentation method demonstrates superior performance on dialogue segmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg.', 'abstract_zh': '为了在长期对话中提供连贯且个性化的体验，现有方法通常通过从对话历史中构建记忆库来进行检索增强响应生成，这可在回合级、会话级或通过总结技术中实现。在本文中，我们提出两项关键发现：（1）记忆单元的粒度很重要：回合级、会话级和基于总结的方法在记忆检索准确性和检索内容的语义质量方面均存在局限性。（2）诸如\\textit{LLMLingua-2}的提示压缩方法可以有效地作为去噪机制，在不同粒度下提升记忆检索准确率。基于这些见解，我们提出了一种名为SeCom的方法，在引入对话切分模型的基础上，通过压缩记忆单元进行记忆检索，构建话题段落记忆库。实验结果表明，SeCom在LOCOMO和Long-MT-Bench+等长期对话基准测试中优于回合级、会话级及若干基于总结的方法。此外，提出的对话切分方法在DialSeg711、TIAGE和SuperDialSeg等对话切分数据集上表现出色。', 'title_zh': '个性化对话代理的 memory 构建与检索'}
{'arxiv_id': 'arXiv:2502.05574', 'title': 'Event Stream-based Visual Object Tracking: HDETrack V2 and A High-Definition Benchmark', 'authors': 'Shiao Wang, Xiao Wang, Chao Wang, Liye Jin, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang', 'link': 'https://arxiv.org/abs/2502.05574', 'abstract': "We then introduce a novel hierarchical knowledge distillation strategy that incorporates the similarity matrix, feature representation, and response map-based distillation to guide the learning of the student Transformer network. We also enhance the model's ability to capture temporal dependencies by applying the temporal Fourier transform to establish temporal relationships between video frames. We adapt the network model to specific target objects during testing via a newly proposed test-time tuning strategy to achieve high performance and flexibility in target tracking. Recognizing the limitations of existing event-based tracking datasets, which are predominantly low-resolution, we propose EventVOT, the first large-scale high-resolution event-based tracking dataset. It comprises 1141 videos spanning diverse categories such as pedestrians, vehicles, UAVs, ping pong, etc. Extensive experiments on both low-resolution (FE240hz, VisEvent, FELT), and our newly proposed high-resolution EventVOT dataset fully validated the effectiveness of our proposed method. Both the benchmark dataset and source code have been released on this https URL", 'abstract_zh': '我们引入了一种新颖的分层知识蒸馏策略，该策略结合了相似矩阵、特征表示和基于响应图的蒸馏来指导学生Transformer网络的学习。我们还通过应用时域傅里叶变换来增强模型捕捉时间依赖性的能力，以在视频帧之间建立时间关系。我们提出了一种新的测试时调优策略，使网络模型在测试期间适应特定的目标对象，从而实现目标跟踪的高性能和灵活性。鉴于现有事件驱动跟踪数据集的主要局限性（大部分为低分辨率），我们提出了EventVOT，这是首个大规模高分辨率事件驱动跟踪数据集，包含1141个跨不同类别（如行人、车辆、无人机、乒乓球等）的视频。在低分辨率（FE240Hz、VisEvent、FELT）和我们新提出的高分辨率EventVOT数据集上的广泛实验全面验证了我们提出方法的有效性。基准数据集及源代码已发布于此<https://>。', 'title_zh': '基于事件流的视觉目标跟踪：HDETrack V2和高清晰度基准'}
{'arxiv_id': 'arXiv:2502.05573', 'title': 'Low-Rank Agent-Specific Adaptation (LoRASA) for Multi-Agent Policy Learning', 'authors': 'Beining Zhang, Aditya Kapoor, Mingfei Sun', 'link': 'https://arxiv.org/abs/2502.05573', 'abstract': "Multi-agent reinforcement learning (MARL) often relies on \\emph{parameter sharing (PS)} to scale efficiently. However, purely shared policies can stifle each agent's unique specialization, reducing overall performance in heterogeneous environments. We propose \\textbf{Low-Rank Agent-Specific Adaptation (LoRASA)}, a novel approach that treats each agent's policy as a specialized ``task'' fine-tuned from a shared backbone. Drawing inspiration from parameter-efficient transfer methods, LoRASA appends small, low-rank adaptation matrices to each layer of the shared policy, naturally inducing \\emph{parameter-space sparsity} that promotes both specialization and scalability. We evaluate LoRASA on challenging benchmarks including the StarCraft Multi-Agent Challenge (SMAC) and Multi-Agent MuJoCo (MAMuJoCo), implementing it atop widely used algorithms such as MAPPO and A2PO. Across diverse tasks, LoRASA matches or outperforms existing baselines \\emph{while reducing memory and computational overhead}. Ablation studies on adapter rank, placement, and timing validate the method's flexibility and efficiency. Our results suggest LoRASA's potential to establish a new norm for MARL policy parameterization: combining a shared foundation for coordination with low-rank agent-specific refinements for individual specialization.", 'abstract_zh': '低秩代理特异性适应（LoRASA）：一种新的多代理强化学习策略参数化方法', 'title_zh': '基于低秩代理特定适应性的多代理策略学习（LoRASA）'}
{'arxiv_id': 'arXiv:2502.05568', 'title': 'Large Multimodal Models for Low-Resource Languages: A Survey', 'authors': 'Marian Lupascu, Ana-Cristina Rogoz, Mihai Sorin Stupariu, Radu Tudor Ionescu', 'link': 'https://arxiv.org/abs/2502.05568', 'abstract': 'In this survey, we systematically analyze techniques used to adapt large multimodal models (LMMs) for low-resource (LR) languages, examining approaches ranging from visual enhancement and data creation to cross-modal transfer and fusion strategies. Through a comprehensive analysis of 106 studies across 75 LR languages, we identify key patterns in how researchers tackle the challenges of limited data and computational resources. We find that visual information often serves as a crucial bridge for improving model performance in LR settings, though significant challenges remain in areas such as hallucination mitigation and computational efficiency. We aim to provide researchers with a clear understanding of current approaches and remaining challenges in making LMMs more accessible to speakers of LR (understudied) languages. We complement our survey with an open-source repository available at: this https URL.', 'abstract_zh': '本调查系统地分析了用于适应低资源语言的大型多模态模型的技术，考察了从视觉增强和数据创建到跨模态迁移和融合策略的各种方法。通过对其它75种低资源语言共计106项研究的全面分析，我们指出了研究人员在应对数据和计算资源有限挑战时的关键模式。我们发现，视觉信息经常作为关键桥梁，提高模型在低资源环境中的性能，尽管在减轻幻觉和提高计算效率方面仍面临重大挑战。我们旨在为研究人员提供当前方法和剩余挑战的清晰理解，以使大型多模态模型对 understudied 语言的使用者更加普及。我们还提供了开源仓库：this https URL。', 'title_zh': '低资源语言的大规模多模态模型：一种综述'}
{'arxiv_id': 'arXiv:2502.05567', 'title': 'ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data', 'authors': 'Xiaoyang Liu, Kangjie Bao, Jiashuo Zhang, Yunqi Liu, Yu Chen, Yuntian Liu, Yang Jiao, Tao Luo', 'link': 'https://arxiv.org/abs/2502.05567', 'abstract': 'Autoformalization, the process of automatically translating natural language mathematics into machine-verifiable formal language, has demonstrated advancements with the progress of large language models (LLMs). However, a key obstacle to further advancements is the scarcity of paired datasets that align natural language with formal language. To address this challenge, we introduce ATLAS (Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data), an iterative data generation framework designed to produce large-scale, high-quality parallel theorem statements. With the proposed ATLAS running for 10 iterations, we construct an undergraduate-level dataset comprising 300k theorem statements and develop the ATLAS translator, achieving accuracies of 80.59% (pass@8) and 92.99% (pass@128) on ProofNet, significantly outperforming the base model (23.99% and 47.17%) and InternLM2-Math-Plus-7B (50.94% and 80.32%). Furthermore, the ATLAS translator also achieves state-of-the-art performance on both the high-school-level miniF2F dataset and the graduate-level MathQual dataset introduced in this work. The datasets, model, and code will be released to the public soon.', 'abstract_zh': '自动形式化：通过提升、扩充和合成数据自动生成形式化定理陈述的方法及其实现', 'title_zh': 'ATLAS: 通过提升、扩增和数据合成自动形式化定理'}
{'arxiv_id': 'arXiv:2502.05564', 'title': 'TabICL: A Tabular Foundation Model for In-Context Learning on Large Data', 'authors': 'Jingang Qu, David Holzmüller, Gaël Varoquaux, Marine Le Morvan', 'link': 'https://arxiv.org/abs/2502.05564', 'abstract': 'The long-standing dominance of gradient-boosted decision trees on tabular data is currently challenged by tabular foundation models using In-Context Learning (ICL): setting the training data as context for the test data and predicting in a single forward pass without parameter updates. While the very recent TabPFNv2 foundation model (2025) excels on tables with up to 10K samples, its alternating column- and row-wise attentions make handling large training sets computationally prohibitive. So, can ICL be effectively scaled and deliver a benefit for larger tables? We introduce TabICL, a tabular foundation model for classification, pretrained on synthetic datasets with up to 60K samples and capable of handling 500K samples on affordable resources. This is enabled by a novel two-stage architecture: a column-then-row attention mechanism to build fixed-dimensional embeddings of rows, followed by a transformer for efficient ICL. Across 200 classification datasets from the TALENT benchmark, TabICL is on par with TabPFNv2 while being systematically faster (up to 10 times), and significantly outperforms all other approaches. On 56 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost, demonstrating the potential of ICL for large data.', 'abstract_zh': '表格数据上基于上下文学习的表格基础模型TabICL：一种新型两阶段架构的分类表格基础模型', 'title_zh': 'TabICL：大规模数据下基于上下文的表格预训练模型'}
{'arxiv_id': 'arXiv:2502.05547', 'title': 'Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks in Federated Learning', 'authors': 'Runhua Xu, Shiqi Gao, Chao Li, James Joshi, Jianxin Li', 'link': 'https://arxiv.org/abs/2502.05547', 'abstract': "Federated learning (FL) is inherently susceptible to privacy breaches and poisoning attacks. To tackle these challenges, researchers have separately devised secure aggregation mechanisms to protect data privacy and robust aggregation methods that withstand poisoning attacks. However, simultaneously addressing both concerns is challenging; secure aggregation facilitates poisoning attacks as most anomaly detection techniques require access to unencrypted local model updates, which are obscured by secure aggregation. Few recent efforts to simultaneously tackle both challenges offen depend on impractical assumption of non-colluding two-server setups that disrupt FL's topology, or three-party computation which introduces scalability issues, complicating deployment and application. To overcome this dilemma, this paper introduce a Dual Defense Federated learning (DDFed) framework. DDFed simultaneously boosts privacy protection and mitigates poisoning attacks, without introducing new participant roles or disrupting the existing FL topology. DDFed initially leverages cutting-edge fully homomorphic encryption (FHE) to securely aggregate model updates, without the impractical requirement for non-colluding two-server setups and ensures strong privacy protection. Additionally, we proposes a unique two-phase anomaly detection mechanism for encrypted model updates, featuring secure similarity computation and feedback-driven collaborative selection, with additional measures to prevent potential privacy breaches from Byzantine clients incorporated into the detection process. We conducted extensive experiments on various model poisoning attacks and FL scenarios, including both cross-device and cross-silo FL. Experiments on publicly available datasets demonstrate that DDFed successfully protects model privacy and effectively defends against model poisoning threats.", 'abstract_zh': '联邦学习（FL）本质上容易遭受隐私泄露和污染攻击。为应对这些挑战，研究人员分别设计了安全聚合机制来保护数据隐私和抗污染攻击的方法。然而，同时应对这两种挑战颇具挑战性；安全聚合会促进污染攻击，因为大多数异常检测技术需要访问未加密的本地模型更新，而这些更新被安全聚合所遮蔽。近期少数同时应对这两种挑战的努力往往依赖于无法实现的非串通双服务器设置假设，这干扰了FL的拓扑结构，或者依赖于三方计算，这引入了可扩展性问题，复杂了部署和应用。为克服这一困境，本文提出了一种双防御联邦学习（DDFed）框架。DDFed同步增强了隐私保护并缓解了污染攻击，无需引入新的参与者角色或扰乱现有的FL拓扑结构。DDFed初始利用最先进的全同态加密（FHE）安全聚合模型更新，无需无法实现的非串通双服务器设置假设，并确保强大的隐私保护。此外，我们提出了一种独特的两阶段异常检测机制，用于加密模型更新，该机制包括安全相似度计算和反馈驱动的合作选择，并通过检测过程中的额外措施防止潜在的拜占庭客户端导致的隐私泄露。我们在各种模型污染攻击和FL场景中进行了广泛的实验，包括设备间联邦学习和库间联邦学习。公开数据集上的实验结果表明，DDFed成功保护了模型隐私并有效防御了模型污染威胁。', 'title_zh': '双层防御：增强联邦学习中的隐私保护并减轻 poisoning 攻击'}
{'arxiv_id': 'arXiv:2502.05526', 'title': 'Towards Learning Scalable Agile Dynamic Motion Planning for Robosoccer Teams with Policy Optimization', 'authors': 'Brandon Ho, Batuhan Altundas, Matthew Gombolay', 'link': 'https://arxiv.org/abs/2502.05526', 'abstract': "In fast-paced, ever-changing environments, dynamic Motion Planning for Multi-Agent Systems in the presence of obstacles is a universal and unsolved problem. Be it from path planning around obstacles to the movement of robotic arms, or in planning navigation of robot teams in settings such as Robosoccer, dynamic motion planning is needed to avoid collisions while reaching the targeted destination when multiple agents occupy the same area. In continuous domains where the world changes quickly, existing classical Motion Planning algorithms such as RRT* and A* become computationally expensive to rerun at every time step. Many variations of classical and well-formulated non-learning path-planning methods have been proposed to solve this universal problem but fall short due to their limitations of speed, smoothness, optimally, etc. Deep Learning models overcome their challenges due to their ability to adapt to varying environments based on past experience. However, current learning motion planning models use discretized environments, do not account for heterogeneous agents or replanning, and build up to improve the classical motion planners' efficiency, leading to issues with scalability. To prevent collisions between heterogenous team members and collision to obstacles while trying to reach the target location, we present a learning-based dynamic navigation model and show our model working on a simple environment in the concept of a simple Robosoccer Game.", 'abstract_zh': '在快速变化的环境下，多Agent系统在障碍物存在下的动态运动规划是一个普遍且未解决的问题。无论是障碍物周围的路径规划、机械臂的运动，还是在如Robosoccer这样的设置中机器人团队的导航规划，都需要动态运动规划以在多个Agent占据同一区域时避免碰撞并达到目标位置。在世界快速变化的连续领域中，现有的经典运动规划算法如RRT*和A*在每个时间步重新运行变得计算上昂贵。尽管提出了许多经典且非学习路径规划方法的变体来解决这一普遍问题，但由于速度、平滑度、最优性等方面的问题，它们仍存在不足。深度学习模型由于能够根据以往经验适应不同的环境而克服了这些挑战。然而，当前的学习运动规划模型使用离散化环境，不考虑异质性Agent或重新规划，旨在提高经典运动规划器的效率，导致可扩展性问题。为避免异质性团队成员之间的碰撞以及避免与障碍物的碰撞，我们提出了一种基于学习的动态导航模型，并展示了该模型在简单Robosoccer游戏环境中的工作。', 'title_zh': '面向robosoccer团队的可扩展敏捷动态运动规划学习研究：基于策略优化'}
{'arxiv_id': 'arXiv:2502.05512', 'title': 'IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System', 'authors': 'Wei Deng, Siyi Zhou, Jingchen Shu, Jinchao Wang, Lu Wang', 'link': 'https://arxiv.org/abs/2502.05512', 'abstract': 'Recently, large language model (LLM) based text-to-speech (TTS) systems have gradually become the mainstream in the industry due to their high naturalness and powerful zero-shot voice cloning this http URL, we introduce the IndexTTS system, which is mainly based on the XTTS and Tortoise model. We add some novel improvements. Specifically, in Chinese scenarios, we adopt a hybrid modeling method that combines characters and pinyin, making the pronunciations of polyphonic characters and long-tail characters controllable. We also performed a comparative analysis of the Vector Quantization (VQ) with Finite-Scalar Quantization (FSQ) for codebook utilization of acoustic speech tokens. To further enhance the effect and stability of voice cloning, we introduce a conformer-based speech conditional encoder and replace the speechcode decoder with BigVGAN2. Compared with XTTS, it has achieved significant improvements in naturalness, content consistency, and zero-shot voice cloning. As for the popular TTS systems in the open-source, such as Fish-Speech, CosyVoice2, FireRedTTS and F5-TTS, IndexTTS has a relatively simple training process, more controllable usage, and faster inference speed. Moreover, its performance surpasses that of these systems. Our demos are available at this https URL.', 'abstract_zh': '基于大规模语言模型的文本到语音系统：IndexTTS系统的引入及其改进', 'title_zh': 'IndexTTS：一个工业级可控且高效的零shot文本到语音系统'}
{'arxiv_id': 'arXiv:2502.05503', 'title': 'A Physical Coherence Benchmark for Evaluating Video Generation Models via Optical Flow-guided Frame Prediction', 'authors': 'Yongfan Chen, Xiuwen Zhu, Tianyu Li, Hao Chen, Chunhua Shen', 'link': 'https://arxiv.org/abs/2502.05503', 'abstract': 'Recent advances in video generation models demonstrate their potential as world simulators, but they often struggle with videos deviating from physical laws, a key concern overlooked by most text-to-video benchmarks. We introduce a benchmark designed specifically to assess the Physical Coherence of generated videos, PhyCoBench. Our benchmark includes 120 prompts covering 7 categories of physical principles, capturing key physical laws observable in video content. We evaluated four state-of-the-art (SoTA) T2V models on PhyCoBench and conducted manual assessments. Additionally, we propose an automated evaluation model: PhyCoPredictor, a diffusion model that generates optical flow and video frames in a cascade manner. Through a consistency evaluation comparing automated and manual sorting, the experimental results show that PhyCoPredictor currently aligns most closely with human evaluation. Therefore, it can effectively evaluate the physical coherence of videos, providing insights for future model optimization. Our benchmark, which includes physical coherence prompts, automatic evaluation tool PhyCoPredictor, and generated video dataset, will all be released on GitHub shortly.', 'abstract_zh': 'Recent Advances in Video Generation Models Demonstrate Their Potential as World Simulators, but Often Struggle with Physical Law Compliance: Introducing PhyCoBench for Assessing Physical Coherence', 'title_zh': '基于光学流引导帧预测的视频生成模型物理一致性评估基准'}
{'arxiv_id': 'arXiv:2502.05500', 'title': 'Vision-Ultrasound Robotic System based on Deep Learning for Gas and Arc Hazard Detection in Manufacturing', 'authors': 'Jin-Hee Lee, Dahyun Nam, Robin Inho Kee, YoungKey Kim, Seok-Jun Buu', 'link': 'https://arxiv.org/abs/2502.05500', 'abstract': 'Gas leaks and arc discharges present significant risks in industrial environments, requiring robust detection systems to ensure safety and operational efficiency. Inspired by human protocols that combine visual identification with acoustic verification, this study proposes a deep learning-based robotic system for autonomously detecting and classifying gas leaks and arc discharges in manufacturing settings. The system is designed to execute all experimental tasks entirely onboard the robot. Utilizing a 112-channel acoustic camera operating at a 96 kHz sampling rate to capture ultrasonic frequencies, the system processes real-world datasets recorded in diverse industrial scenarios. These datasets include multiple gas leak configurations (e.g., pinhole, open end) and partial discharge types (Corona, Surface, Floating) under varying environmental noise conditions. Proposed system integrates visual detection and a beamforming-enhanced acoustic analysis pipeline. Signals are transformed using STFT and refined through Gamma Correction, enabling robust feature extraction. An Inception-inspired CNN further classifies hazards, achieving 99% gas leak detection accuracy. The system not only detects individual hazard sources but also enhances classification reliability by fusing multi-modal data from both vision and acoustic sensors. When tested in reverberation and noise-augmented environments, the system outperformed conventional models by up to 44%p, with experimental tasks meticulously designed to ensure fairness and reproducibility. Additionally, the system is optimized for real-time deployment, maintaining an inference time of 2.1 seconds on a mobile robotic platform. By emulating human-like inspection protocols and integrating vision with acoustic modalities, this study presents an effective solution for industrial automation, significantly improving safety and operational reliability.', 'abstract_zh': '基于深度学习的机器人系统在制造环境中自主检测与分类气体泄漏和电弧放电', 'title_zh': '基于深度学习的视觉-超声机器人系统及制造过程中气体和电弧危害检测'}
{'arxiv_id': 'arXiv:2502.05498', 'title': 'Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations', 'authors': 'Larkin Liu, Kashif Rasul, Yutong Chao, Jalal Etesami', 'link': 'https://arxiv.org/abs/2502.05498', 'abstract': "We present a novel framework for online learning in Stackelberg general-sum games, where two agents, the leader and follower, engage in sequential turn-based interactions. At the core of this approach is a learned diffeomorphism that maps the joint action space to a smooth Riemannian manifold, referred to as the Stackelberg manifold. This mapping, facilitated by neural normalizing flows, ensures the formation of tractable isoplanar subspaces, enabling efficient techniques for online learning. By assuming linearity between the agents' reward functions on the Stackelberg manifold, our construct allows the application of standard bandit algorithms. We then provide a rigorous theoretical basis for regret minimization on convex manifolds and establish finite-time bounds on simple regret for learning Stackelberg equilibria. This integration of manifold learning into game theory uncovers a previously unrecognized potential for neural normalizing flows as an effective tool for multi-agent learning. We present empirical results demonstrating the effectiveness of our approach compared to standard baselines, with applications spanning domains such as cybersecurity and economic supply chain optimization.", 'abstract_zh': '我们提出了一种在Stackelberg广义博弈中进行在线学习的新型框架，其中两个代理，领导者和追随者，进行顺序的轮流互动。该方法的核心是一个学习到的 diffeomorphism 映射，将联合动作空间映射到一个光滑的黎曼流形，称为Stackelberg流形。这种映射通过神经归一化流实现，确保形成可处理的同面子空间，从而使得在线学习的高效技术成为可能。通过在Stackelberg流形上假设代理的奖励函数之间存在线性关系，我们的构建允许使用标准的多臂 bandit 算法。然后，我们为凸流形上的后悔最小化提供了严格的理论基础，并建立了学习Stackelberg均衡的有限时间简单后悔的上界。将流形学习整合到博弈论中揭示了神经归一化流作为多代理学习有效工具的先前未被认识到的潜力。我们展示了与标准基线相比，该方法的有效性实证结果，涉及的领域包括网络安全和经济供应链优化。', 'title_zh': '基于神经流表示的 Stackelberg 游戏的黎曼流形学习'}
{'arxiv_id': 'arXiv:2502.05494', 'title': 'Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection', 'authors': 'Ya Zhou, Yujie Yang, Jianhuang Gan, Xiangjie Li, Jing Yuan, Wei Zhao', 'link': 'https://arxiv.org/abs/2502.05494', 'abstract': 'Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing cardiovascular conditions, yet anomaly detection in ECG signals remains challenging due to their inherent complexity and variability. We propose Multi-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel end-to-end framework that effectively captures both global and local dependencies in ECG data. Unlike state-of-the-art methods that rely on heartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for such pre-processing steps, enhancing its suitability for clinical deployment. MMAE-ECG partitions ECG signals into non-overlapping segments, with each segment assigned learnable positional embeddings. A novel multi-scale masking strategy and multi-scale attention mechanism, along with distinct positional embeddings, enable a lightweight Transformer encoder to effectively capture both local and global dependencies. The masked segments are then reconstructed using a single-layer Transformer block, with an aggregation strategy employed during inference to refine the outputs. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art approaches while significantly reducing computational complexity-approximately 1/78 of the floating-point operations (FLOPs) required for inference. Ablation studies further validate the effectiveness of each component, highlighting the potential of multi-scale masked autoencoders for anomaly detection.', 'abstract_zh': '多尺度掩蔽自动编码器在ECG异常检测中的应用（MMAE-ECG）', 'title_zh': '多尺度遮蔽自动编码器用于心电图异常检测'}
{'arxiv_id': 'arXiv:2502.05489', 'title': 'Mechanistic Interpretability of Emotion Inference in Large Language Models', 'authors': 'Ala N. Tak, Amin Banayeeanzade, Anahita Bolourani, Mina Kian, Robin Jia, Jonathan Gratch', 'link': 'https://arxiv.org/abs/2502.05489', 'abstract': 'Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that emotion representations are functionally localized to specific regions in the model. Our evaluation includes diverse model families and sizes and is supported by robustness checks. We then show that the identified representations are psychologically plausible by drawing on cognitive appraisal theory, a well-established psychological framework positing that emotions emerge from evaluations (appraisals) of environmental stimuli. By causally intervening on construed appraisal concepts, we steer the generation and show that the outputs align with theoretical and intuitive expectations. This work highlights a novel way to causally intervene and precisely shape emotional text generation, potentially benefiting safety and alignment in sensitive affective domains.', 'abstract_zh': '大规模语言模型（LLMs）在从文本预测人类情绪方面显示出promising的能力，但这些模型处理情绪刺激的机制仍然很大程度上未被探索。我们的研究通过调查自回归LLMs如何推断情绪，表明情绪表示在模型中特定区域功能局部化。我们的评估包括多样化模型家族和规模，并通过稳健性检验予以支持。然后，我们通过引用认知评估理论，一个广泛认可的心理学框架，该框架提出情绪源自对环境刺激的评估（认知评估），来展示识别到的表示具有心理合理性。通过干预构建的认知评估概念，我们操控生成过程，结果显示输出符合理论和直观预期。这项工作强调了一种新的因果干预方式，用于精确塑造情绪性文本生成，可能惠及敏感情感领域中的安全性和对齐。', 'title_zh': '大型语言模型中情绪推断的机理可解释性'}
{'arxiv_id': 'arXiv:2502.05485', 'title': 'HAMSTER: Hierarchical Action Models For Open-World Robot Manipulation', 'authors': 'Yi Li, Yuquan Deng, Jesse Zhang, Joel Jang, Marius Memme, Raymond Yu, Caelan Reed Garrett, Fabio Ramos, Dieter Fox, Anqi Li, Abhishek Gupta, Ankit Goyal', 'link': 'https://arxiv.org/abs/2502.05485', 'abstract': "Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is the lack of robotic data, which are typically obtained through expensive on-robot operation. A promising remedy is to leverage cheaper, off-domain data such as action-free videos, hand-drawn sketches or simulation data. In this work, we posit that hierarchical vision-language-action (VLA) models can be more effective in utilizing off-domain data than standard monolithic VLA models that directly finetune vision-language models (VLMs) to predict actions. In particular, we study a class of hierarchical VLA models, where the high-level VLM is finetuned to produce a coarse 2D path indicating the desired robot end-effector trajectory given an RGB image and a task description. The intermediate 2D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Doing so alleviates the high-level VLM from fine-grained action prediction, while reducing the low-level policy's burden on complex task-level reasoning. We show that, with the hierarchical design, the high-level VLM can transfer across significant domain gaps between the off-domain finetuning data and real-robot testing scenarios, including differences on embodiments, dynamics, visual appearances and task semantics, etc. In the real-robot experiments, we observe an average of 20% improvement in success rate across seven different axes of generalization over OpenVLA, representing a 50% relative gain. Visual results are provided at: this https URL", 'abstract_zh': '大型基础模型在视觉和语言复杂问题上展示了较强的开环泛化能力，但在机器人领域类似的泛化水平尚未实现。其中一个基本挑战是缺乏机器人数据，这些数据通常通过昂贵的机器人操作获得。一种有希望的解决方法是利用更便宜的离域数据，例如无动作视频、手绘草图或模拟数据。在本文中，我们提出，分层视觉-语言-动作（VLA）模型相较于标准的单一模块VLA模型，更能有效地利用离域数据。具体而言，我们研究了一类分层VLA模型，其中高层VLA模型通过微调视觉-语言模型（VLMs），在给定RGB图像和任务描述的情况下生成粗略的2D路径，指示期望的机器人末端执行器轨迹。中间层的2D路径预测则作为指导，用于低层、3D感知的控制策略，该策略能够实现精确的操纵。这样做减轻了高层VLM进行细粒度动作预测的负担，同时减少了低层策略在复杂任务级推理方面的负担。我们展示了，通过分层设计，高层VLA模型可以在显著的离域数据微调域与真实机器人测试场景之间的差距中进行泛化，包括在实体、动力学、视觉外观和任务语义等方面的差异。在真实机器人实验中，我们观察到，在七个不同泛化轴向中，相对于OpenVLA的平均成功率提高了20%，相当于绝对增益50%。提供的视觉结果见：this https URL', 'title_zh': 'HAMSTER：开放世界机器人操纵的层次动作模型'}
{'arxiv_id': 'arXiv:2502.05467', 'title': 'Position: LLMs Can be Good Tutors in Foreign Language Education', 'authors': 'Jingheng Ye, Shen Wang, Deqing Zou, Yibo Yan, Kun Wang, Hai-Tao Zheng, Zenglin Xu, Irwin King, Philip S. Yu, Qingsong Wen', 'link': 'https://arxiv.org/abs/2502.05467', 'abstract': 'While recent efforts have begun integrating large language models (LLMs) into foreign language education (FLE), they often rely on traditional approaches to learning tasks without fully embracing educational methodologies, thus lacking adaptability to language learning. To address this gap, we argue that LLMs have the potential to serve as effective tutors in FLE. Specifically, LLMs can play three critical roles: (1) as data enhancers, improving the creation of learning materials or serving as student simulations; (2) as task predictors, serving as learner assessment or optimizing learning pathway; and (3) as agents, enabling personalized and inclusive education. We encourage interdisciplinary research to explore these roles, fostering innovation while addressing challenges and risks, ultimately advancing FLE through the thoughtful integration of LLMs.', 'abstract_zh': '近年来，虽然已经开始将大型语言模型（LLMs）集成到外语教育（FLE）中，但它们往往依赖于传统的学习方法，未能充分采纳教育方法学，因而缺乏对语言学习的适应性。为解决这一问题，我们认为LLMs有潜力作为FLE中的有效导师。具体而言，LLMs可以扮演三种关键角色：（1）数据增强者，提高学习材料的创作或作为学生模拟；（2）任务预测者，作为学习者评估或优化学习路径；（3）代理者，实现个性化和包容性教育。我们鼓励跨学科研究探索这些角色，推动创新，应对挑战和风险，最终通过慎重地整合LLMs推进外语教育的发展。', 'title_zh': '位置：LLM可以成为外语教育的良师'}
{'arxiv_id': 'arXiv:2502.05459', 'title': 'DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability', 'authors': 'Sibasish Dhibar', 'link': 'https://arxiv.org/abs/2502.05459', 'abstract': "White blood cells (WBC) are important parts of our immune system, and they protect our body against infections by eliminating viruses, bacteria, parasites and fungi. The number of WBC types and the total number of WBCs provide important information about our health status. A traditional method, convolutional neural networks (CNN), a deep learning architecture, can classify the blood cell from a part of an object and perform object recognition. Various CNN models exhibit potential; however, their development often involves ad-hoc processes that neglect unnecessary layers, leading to issues with unbalanced datasets and insufficient data augmentation. To address these challenges, we propose a novel ensemble approach that integrates three CNN architectures, each uniquely configured with different dropout and max-pooling layer settings to enhance feature learning. This ensemble model, named DCENWCNet, effectively balances the bias-variance trade-off. When evaluated on the widely recognized Rabbin-WBC dataset, our model outperforms existing state-of-the-art networks, achieving highest mean accuracy. Additionally, it demonstrates superior performance in precision, recall, F1-score, and Area Under the ROC Curve (AUC) across all categories. To delve deeper into the interpretability of classifiers, we employ reliable post-hoc explanation techniques, including Local Interpretable Model-Agnostic Explanations (LIME). These methods approximate the behavior of a black-box model by elucidating the relationships between feature values and predictions. Interpretable results enable users to comprehend and validate the model's predictions, thereby increasing their confidence in the automated diagnosis.", 'abstract_zh': '白细胞（WBC）是免疫系统的重要组成部分，它们通过消除病毒、细菌、寄生虫和真菌来保护我们的身体免受感染。白细胞类型的数量和总数量提供了关于我们健康状态的重要信息。传统的卷积神经网络（CNN）是一种深度学习架构，可以对物体的一部分进行血液细胞分类并且执行对象识别。各种CNN模型展现出潜力，但其开发往往涉及缺乏系统性的过程，导致数据集不平衡和数据增强不足的问题。为解决这些挑战，我们提出了一种新颖的集成方法，该方法将三种不同配置的CNN架构集成在一起，每种架构具有不同的dropout和最大池化层设置，以增强特征学习。该集成模型名为DCENWCNet，有效地平衡了偏差-方差Trade-off。当在广泛认可的Rabbin-WBC数据集上进行评估时，我们的模型优于现有最先进的网络，实现了最高的平均准确性。此外，该模型在精确度、召回率、F1分数以及ROC曲线下面积（AUC）方面在所有类别中都表现出色。为了深入探索分类器的可解释性，我们采用可靠的后验解释技术，包括局部可解释的模型无关解释（LIME），这些方法通过阐明特征值与预测之间的关系来近似黑盒模型的行为。可解释的结果使用户能够理解和验证模型的预测，从而增加他们对自动化诊断的信心。', 'title_zh': 'DCENWCNet：一种基于LIME解释性的深卷积神经网络集成模型用于白细胞分类'}
{'arxiv_id': 'arXiv:2502.05450', 'title': 'ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy', 'authors': 'Yuhui Chen, Shuai Tian, Shugao Liu, Yingting Zhou, Haoran Li, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2502.05450', 'abstract': 'Vision-Language-Action (VLA) models have shown substantial potential in real-world robotic manipulation. However, fine-tuning these models through supervised learning struggles to achieve robust performance due to limited, inconsistent demonstrations, especially in contact-rich environments. In this paper, we propose a reinforced fine-tuning approach for VLA models, named ConRFT, which consists of offline and online fine-tuning with a unified consistency-based training objective, to address these challenges. In the offline stage, our method integrates behavior cloning and Q-learning to effectively extract policy from a small set of demonstrations and stabilize value estimating. In the online stage, the VLA model is further fine-tuned via consistency policy, with human interventions to ensure safe exploration and high sample efficiency. We evaluate our approach on eight diverse real-world manipulation tasks. It achieves an average success rate of 96.3% within 45-90 minutes of online fine-tuning, outperforming prior supervised methods with a 144% improvement in success rate and 1.9x shorter episode length. This work highlights the potential of integrating reinforcement learning to enhance the performance of VLA models for real-world robotic applications.', 'abstract_zh': '基于强化学习的Vision-Language-Action模型细调方法：ConRFT及其在现实机器人操作中的应用', 'title_zh': 'ConRFT: 一种通过一致性策略优化的VLA模型强化微调方法'}
{'arxiv_id': 'arXiv:2502.05449', 'title': 'Iterative Deepening Sampling for Large Language Models', 'authors': 'Weizhe Chen, Sven Koenig, Bistra Dilkina', 'link': 'https://arxiv.org/abs/2502.05449', 'abstract': "The recent release of OpenAI's o1 models and other similar frameworks showcasing test-time scaling laws has demonstrated their exceptional capability to tackle complex reasoning tasks. Inspired by this, subsequent research has revealed that such test-time scaling laws hinge on the model's ability to search both within a single response (intra-response) and across multiple responses (inter-response) during training. Crucially, beyond selecting a single optimal response, the model must also develop robust self-correction capabilities within its own outputs. However, training models to achieve effective self-evaluation and self-correction remains a significant challenge, heavily dependent on the quality of self-reflection data. In this paper, we address this challenge by focusing on enhancing the quality of self-reflection data generation for complex problem-solving, which can subsequently improve the training of next-generation large language models (LLMs). Specifically, we explore how manually triggering a model's self-correction mechanisms can improve performance on challenging reasoning tasks. To this end, we propose a novel iterative deepening sampling algorithm framework designed to enhance self-correction and generate higher-quality samples. Through extensive experiments on Math500 and AIME benchmarks, we demonstrate that our method achieves a higher success rate on difficult tasks and provide detailed ablation studies to analyze its effectiveness across diverse settings.", 'abstract_zh': 'OpenAI o1模型及其他类似框架的近期发布展示了它们在复杂推理任务中的卓越能力，这些成就背后的测试时缩放定律依赖于模型在训练过程中不仅能内在搜索单个响应内部的信息，还能跨多个响应搜索信息。模型不仅需要选择最优响应，还需要在自身的输出中发展出稳健的自我纠正能力。然而，训练模型实现有效的自我评估和自我纠正仍是一个重大挑战，高度依赖于自我反思数据的质量。本文通过提高复杂问题解决中自我反思数据生成的质量来应对这一挑战，从而改进下一代大型语言模型（LLMs）的训练。具体而言，我们探讨了手动触发模型的自我纠正机制如何提高复杂推理任务的表现，并提出了一种新的迭代加深采样算法框架以增强自我纠正和生成更高质量的样本。通过在Math500和AIME基准上的大量实验，我们证明了该方法在困难任务上的成功率更高，并进行了详细的消融研究来分析其在不同环境下的有效性。', 'title_zh': '大型语言模型中的迭代加深采样方法'}
{'arxiv_id': 'arXiv:2502.05435', 'title': 'Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning', 'authors': 'Manh Luong, Khai Nguyen, Dinh Phung, Gholamreza Haffari, Lizhen Qu', 'link': 'https://arxiv.org/abs/2502.05435', 'abstract': 'Teacher-forcing training for audio captioning usually leads to exposure bias due to training and inference mismatch. Prior works propose the contrastive method to deal with caption degeneration. However, the contrastive method ignores the temporal information when measuring similarity across acoustic and linguistic modalities, leading to inferior performance. In this work, we develop the temporal-similarity score by introducing the unbiased sliced Wasserstein RBF (USW-RBF) kernel equipped with rotary positional embedding to account for temporal information across modalities. In contrast to the conventional sliced Wasserstein RBF kernel, we can form an unbiased estimation of USW-RBF kernel via Monte Carlo estimation. Therefore, it is well-suited to stochastic gradient optimization algorithms, and its approximation error decreases at a parametric rate of $\\mathcal{O}(L^{-1/2})$ with $L$ Monte Carlo samples. Additionally, we introduce an audio captioning framework based on the unbiased sliced Wasserstein kernel, incorporating stochastic decoding methods to mitigate caption degeneration during the generation process. We conduct extensive quantitative and qualitative experiments on two datasets, AudioCaps and Clotho, to illustrate the capability of generating high-quality audio captions. Experimental results show that our framework is able to increase caption length, lexical diversity, and text-to-audio self-retrieval accuracy.', 'abstract_zh': '基于无偏时空拟合的音频字幕生成教师强制训练方法', 'title_zh': '无偏分层 Wasserstein 核用于高质量音频字幕生成'}
{'arxiv_id': 'arXiv:2502.05431', 'title': 'APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding', 'authors': 'Xinyu Yang, Tianqi Chen, Beidi Chen', 'link': 'https://arxiv.org/abs/2502.05431', 'abstract': "Context-augmented generation (CAG) techniques, including RAG and ICL, require the efficient combination of multiple contexts to generate responses to user queries. Directly inputting these contexts as a sequence introduces a considerable computational burden by re-encoding the combined selection of contexts for every request. To address this, we explore the promising potential of parallel encoding to independently pre-compute and cache each context's KV states. This approach enables the direct loading of cached states during inference while accommodating more contexts through position reuse across contexts. However, due to misalignments in attention distribution, directly applying parallel encoding results in a significant performance drop. To enable effective and efficient CAG, we propose Adaptive Parallel Encoding ($\\textbf{APE}$), which brings shared prefix, attention temperature, and scaling factor to align the distribution of parallel encoding with sequential encoding. Results on RAG and ICL tasks demonstrate that APE can preserve 98% and 93% sequential encoding performance using the same inputs while outperforming parallel encoding by 3.6% and 7.9%, respectively. It also scales to many-shot CAG, effectively encoding hundreds of contexts in parallel. Efficiency evaluation shows that APE can achieve an end-to-end 4.5$\\times$ speedup by reducing 28$\\times$ prefilling time for a 128K-length context.", 'abstract_zh': '基于上下文增强生成（CAG）技术，包括RAG和ICL，需要高效地结合多个上下文以生成用户查询的响应。直接将这些上下文作为序列输入会因每次请求都需要重新编译组合后的上下文而导致显著的计算负担。为解决这一问题，我们探索了并行编码的潜力，独立预计算和缓存每个上下文的KV状态。这种方法允许在推理过程中直接加载缓存状态，并通过上下文间的共享位置实现更多上下文的处理。然而，由于注意力分布的不匹配，直接应用并行编码会导致显著的性能下降。为了实现有效的和高效的CAG，我们提出了自适应并行编码（APE），它引入了共享前缀、注意力温度和缩放因子，以使并行编码的注意力分布与序列编码的注意力分布相匹配。在RAG和ICL任务上的结果表明，APE能够在使用相同输入的情况下保持98%和93%的序列编码性能，并且分别比并行编码高出3.6%和7.9%。此外，APE可以扩展到多-shot CAG，有效地并行编码数百个上下文。效率评估显示，APE可以通过减少28倍的预填充时间（对于128K长度的上下文），实现端到端4.5倍的加速。', 'title_zh': 'APE：通过自适应并行编码实现更快、更长上下文增强生成'}
{'arxiv_id': 'arXiv:2502.05424', 'title': 'SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation', 'authors': 'Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang', 'link': 'https://arxiv.org/abs/2502.05424', 'abstract': 'Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This raises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen target domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage large language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, a few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of structure tokens to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely, holistic prompts and specific prompts, which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT.', 'abstract_zh': '基于结构对齐的无文本多域图预训练与跨域适应（SAMGPT）', 'title_zh': 'SAMGPT：无文本图基础模型的多领域预训练与跨域适应'}
{'arxiv_id': 'arXiv:2502.05415', 'title': 'Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation', 'authors': 'Chenkai Xu, Xu Wang, Zhenyi Liao, Yishun Li, Tianqi Hou, Zhijie Deng', 'link': 'https://arxiv.org/abs/2502.05415', 'abstract': 'There has been increasing research interest in building unified multimodal understanding and generation models, among which Show-o stands as a notable representative, demonstrating great promise for both text-to-image and image-to-text generation. The inference of Show-o involves progressively denoising image tokens and autoregressively decoding text tokens, and hence, unfortunately, suffers from inefficiency issues from both sides. This paper introduces Show-o Turbo to bridge the gap. We first identify a unified denoising perspective for the generation of images and text in Show-o based on the parallel decoding of text tokens. We then propose to extend consistency distillation (CD), a qualified approach for shortening the denoising process of diffusion models, to the multimodal denoising trajectories of Show-o. We introduce a trajectory segmentation strategy and a curriculum learning procedure to improve the training convergence. Empirically, in text-to-image generation, Show-o Turbo displays a GenEval score of 0.625 at 4 sampling steps without using classifier-free guidance (CFG), outperforming that of the original Show-o with 8 steps and CFG; in image-to-text generation, Show-o Turbo exhibits a 1.5x speedup without significantly sacrificing performance. The code is available at this https URL.', 'abstract_zh': 'Show-o Turbo：基于多模态去噪轨迹优化的生成模型', 'title_zh': 'Show-o Turbo: 向加速统一多模态理解与生成方向努力'}
{'arxiv_id': 'arXiv:2502.05409', 'title': 'Vision-in-the-loop Simulation for Deep Monocular Pose Estimation of UAV in Ocean Environment', 'authors': 'Maneesha Wickramasuriya, Beomyeol Yu, Taeyoung Lee, Murray Snyder', 'link': 'https://arxiv.org/abs/2502.05409', 'abstract': 'This paper proposes a vision-in-the-loop simulation environment for deep monocular pose estimation of a UAV operating in an ocean environment. Recently, a deep neural network with a transformer architecture has been successfully trained to estimate the pose of a UAV relative to the flight deck of a research vessel, overcoming several limitations of GPS-based approaches. However, validating the deep pose estimation scheme in an actual ocean environment poses significant challenges due to the limited availability of research vessels and the associated operational costs. To address these issues, we present a photo-realistic 3D virtual environment leveraging recent advancements in Gaussian splatting, a novel technique that represents 3D scenes by modeling image pixels as Gaussian distributions in 3D space, creating a lightweight and high-quality visual model from multiple viewpoints. This approach enables the creation of a virtual environment integrating multiple real-world images collected in situ. The resulting simulation enables the indoor testing of flight maneuvers while verifying all aspects of flight software, hardware, and the deep monocular pose estimation scheme. This approach provides a cost-effective solution for testing and validating the autonomous flight of shipboard UAVs, specifically focusing on vision-based control and estimation algorithms.', 'abstract_zh': '本文提出了一种视景环路仿真环境，用于海洋环境下无人机单目姿态估计。最近，一种具有变压器架构的深度神经网络已成功训练，用于估计无人机相对于研究船飞行甲板的姿态，克服了基于GPS方法的若干限制。然而，在实际海洋环境中验证深度姿态估计方案面临着显著挑战，主要是由于研究船只的有限可用性和相应的运营成本。为解决这些问题，我们提出了一个基于最近Gaussian splatting进展的逼真3D虚拟环境，这是一种通过将图像像素建模为3D空间中的高斯分布来表示3D场景的新技术，从而从多个视角创建了一个轻量级且高质量的视觉模型。此方法使创建一个集成了多个现场采集实况图像的虚拟环境成为可能。该仿真方法能够在室内测试飞行机动性的同时，验证飞行软件、硬件以及单目姿态估计方案的所有方面。这种方法为测试和验证机载无人机的自主飞行提供了一种成本有效的方法，特别关注基于视觉的控制和估计算法。', 'title_zh': '海洋环境中基于视SEE-in-the-loop仿真的单目无人机姿态估计'}
{'arxiv_id': 'arXiv:2502.05407', 'title': 'The Complexity of Learning Sparse Superposed Features with Feedback', 'authors': 'Akash Kumar', 'link': 'https://arxiv.org/abs/2502.05407', 'abstract': "The success of deep networks is crucially attributed to their ability to capture latent features within a representation space. In this work, we investigate whether the underlying learned features of a model can be efficiently retrieved through feedback from an agent, such as a large language model (LLM), in the form of relative \\textit{triplet comparisons}. These features may represent various constructs, including dictionaries in LLMs or components of a covariance matrix of Mahalanobis distances. We analyze the feedback complexity associated with learning a feature matrix in sparse settings. Our results establish tight bounds when the agent is permitted to construct activations and demonstrate strong upper bounds in sparse scenarios when the agent's feedback is limited to distributional information. We validate our theoretical findings through experiments on two distinct applications: feature recovery from Recursive Feature Machine-trained models and dictionary extraction from sparse autoencoders trained on Large Language Models.", 'abstract_zh': '深度网络的成功主要归因于其在表示空间中捕捉潜在特征的能力。本文研究了是否可以通过代理（如大型语言模型）的反馈，例如相对的三元比较形式，高效地检索模型中的底层学习特征。这些特征可能代表各种构建块，包括大型语言模型中的字典或马氏距离协方差矩阵的组成部分。我们分析了在稀疏设置中学习特征矩阵的反馈复杂性。我们的结果在代理可以构建激活的情况下建立了紧致边界，并在代理反馈仅限于分配信息的情况下，在稀疏场景中建立了强上限。我们通过两个不同的应用实验验证了我们的理论发现：从递归特征机训练的模型中恢复特征以及从大型语言模型训练的稀疏自编码器中提取字典。', 'title_zh': '具有反馈的稀疏叠加特征学习的复杂性'}
{'arxiv_id': 'arXiv:2502.05402', 'title': 'Convolutional Deep Colorization for Image Compression: A Color Grid Based Approach', 'authors': 'Ian Tassin, Kristen Goebel, Brittany Lasher', 'link': 'https://arxiv.org/abs/2502.05402', 'abstract': 'The search for image compression optimization techniques is a topic of constant interest both in and out of academic circles. One method that shows promise toward future improvements in this field is image colorization since image colorization algorithms can reduce the amount of color data that needs to be stored for an image. Our work focuses on optimizing a color grid based approach to fully-automated image color information retention with regard to convolutional colorization network architecture for the purposes of image compression. More generally, using a convolutional neural network for image re-colorization, we want to minimize the amount of color information that is stored while still being able to faithfully re-color images. Our results yielded a promising image compression ratio, while still allowing for successful image recolorization reaching high CSIM values.', 'abstract_zh': '图像压缩优化技术的研究一直是学术界和业界持续关注的话题。一种对未来该领域改进显示出潜力的方法是图像着色，因为图像着色算法可以减少需要存储的颜色数据量。我们的工作集中在优化基于颜色网格的全自动化图像着色方法，并针对卷积着色网络架构进行图像压缩。更一般地说，我们使用卷积神经网络进行图像重新着色，目的是在能够忠实重新着色图像的同时，尽量减少存储的颜色信息量。我们的结果显示，实现了有希望的图像压缩比，同时仍能成功进行图像着色，达到较高的CSIM值。', 'title_zh': '基于颜色网格的卷积深度着色方法及其在图像压缩中的应用'}
{'arxiv_id': 'arXiv:2502.05387', 'title': 'Coarse-to-Fine Structure-Aware Artistic Style Transfer', 'authors': 'Kunxiao Liu, Guowu Yuan, Hao Wu, Wenhua Qian', 'link': 'https://arxiv.org/abs/2502.05387', 'abstract': 'Artistic style transfer aims to use a style image and a content image to synthesize a target image that retains the same artistic expression as the style image while preserving the basic content of the content image. Many recently proposed style transfer methods have a common problem; that is, they simply transfer the texture and color of the style image to the global structure of the content image. As a result, the content image has a local structure that is not similar to the local structure of the style image. In this paper, we present an effective method that can be used to transfer style patterns while fusing the local style structure into the local content structure. In our method, dif-ferent levels of coarse stylized features are first reconstructed at low resolution using a Coarse Network, in which style color distribution is roughly transferred, and the content structure is combined with the style structure. Then, the reconstructed features and the content features are adopted to synthesize high-quality structure-aware stylized images with high resolution using a Fine Network with three structural selective fusion (SSF) modules. The effectiveness of our method is demonstrated through the generation of appealing high-quality stylization results and a com-parison with some state-of-the-art style transfer methods.', 'abstract_zh': '艺术风格迁移旨在使用风格图像和内容图像合成一个目标图像，该目标图像保留与风格图像相同的艺术表现力，同时保留内容图像的基本内容。许多最近提出的方法都存在一个共同问题，即它们简单地将风格图像的纹理和颜色转移到内容图像的全局结构上。结果，内容图像具有与风格图像局部结构不相似的局部结构。在本文中，我们提出了一种有效的方法，可以在融合局部风格结构到局部内容结构的同时转移风格模式。在我们的方法中，首先使用粗网络以低分辨率重构不同层次的粗略风格化特征，在此过程中风格色彩分布被大致转移，并结合内容结构与风格结构。然后，使用包含三个结构选择性融合（SSF）模块的细网络采用重构的特征和内容特征合成高质量的结构意识风格化图像。通过生成引人注目的高质量风格化结果并与一些先进风格迁移方法进行比较，我们展示了我们方法的有效性。', 'title_zh': '从粗到细结构感知的 artistic 风格转移'}
{'arxiv_id': 'arXiv:2502.05383', 'title': 'Is attention all you need to solve the correlated electron problem?', 'authors': 'Max Geier, Khachatur Nazaryan, Timothy Zaklama, Liang Fu', 'link': 'https://arxiv.org/abs/2502.05383', 'abstract': 'The attention mechanism has transformed artificial intelligence research by its ability to learn relations between objects. In this work, we explore how a many-body wavefunction ansatz constructed from a large-parameter self-attention neural network can be used to solve the interacting electron problem in solids. By a systematic neural-network variational Monte Carlo study on a moiré quantum material, we demonstrate that the self-attention ansatz provides an accurate, efficient, and unbiased solution. Moreover, our numerical study finds that the required number of variational parameters scales roughly as $N^2$ with the number of electrons, which opens a path towards efficient large-scale simulations.', 'abstract_zh': 'self-attention机制构建的多体波函数Ansatz在固态交互电子问题中的应用研究', 'title_zh': '解决相关电子问题是否只需要注意力？'}
{'arxiv_id': 'arXiv:2502.05370', 'title': 'fMoE: Fine-Grained Expert Offloading for Large Mixture-of-Experts Serving', 'authors': 'Hanfei Yu, Xingqi Cui, Hong Zhang, Hao Wang, Hao Wang', 'link': 'https://arxiv.org/abs/2502.05370', 'abstract': 'Large Language Models (LLMs) have gained immense success in revolutionizing various applications, including content generation, search and recommendation, and AI-assisted operation. To reduce high training costs, Mixture-of-Experts (MoE) architecture has become a popular backbone for modern LLMs. However, despite the benefits, serving MoE-based LLMs experience severe memory inefficiency due to sparsely activated experts. Recent studies propose to offload inactive experts from GPU memory to CPU memory to improve the serving efficiency of MoE models. However, they either incur high inference latency or high model memory footprints due to coarse-grained designs. To tame the latency-memory trade-off in MoE serving, we present fMoE, a fine-grained expert offloading system for MoE serving that achieves low inference latency with memory efficiency. We design fMoE to extract fine-grained expert selection patterns from MoE models and semantic hints from input prompts to efficiently guide expert prefetching, caching, and offloading decisions. fMoE is prototyped on top of HuggingFace Transformers and deployed on a six-GPU testbed. Experiments with open-source MoE models and real-world workloads show that fMoE reduces inference latency by 47% and improves expert hit rate by 36% over state-of-the-art solutions.', 'abstract_zh': '细粒度专家卸载系统fMoE：实现低推理延迟与高内存效率', 'title_zh': '精细粒度专家卸载的大规模混合专家服务'}
{'arxiv_id': 'arXiv:2502.05345', 'title': 'Estimating Voltage Drop: Models, Features and Data Representation Towards a Neural Surrogate', 'authors': 'Yifei Jin, Dimitrios Koutlis, Hector Bandala, Marios Daoutis', 'link': 'https://arxiv.org/abs/2502.05345', 'abstract': "Accurate estimation of voltage drop (IR drop) in modern Application-Specific Integrated Circuits (ASICs) is highly time and resource demanding, due to the growing complexity and the transistor density in recent technology nodes. To mitigate this challenge, we investigate how Machine Learning (ML) techniques, including Extreme Gradient Boosting (XGBoost), Convolutional Neural Network (CNN), and Graph Neural Network (GNN) can aid in reducing the computational effort and implicitly the time required to estimate the IR drop in Integrated Circuits (ICs). Traditional methods, including commercial tools, require considerable time to produce accurate approximations, especially for complicated designs with numerous transistors. ML algorithms, on the other hand, are explored as an alternative solution to offer quick and precise IR drop estimation, but in considerably less time. Our approach leverages ASICs' electrical, timing, and physical to train ML models, ensuring adaptability across diverse designs with minimal adjustments. Experimental results underscore the superiority of ML models over commercial tools, greatly enhancing prediction speed. Particularly, GNNs exhibit promising performance with minimal prediction errors in voltage drop estimation. The incorporation of GNNs marks a groundbreaking advancement in accurate IR drop prediction. This study illustrates the effectiveness of ML algorithms in precisely estimating IR drop and optimizing ASIC sign-off. Utilizing ML models leads to expedited predictions, reducing calculation time and improving energy efficiency, thereby reducing environmental impact through optimized power circuits.", 'abstract_zh': '现代Application-Specific Integrated Circuits (ASICs)中准确估计电压降（IR drop）的方法：基于机器学习技术的高效解决方案', 'title_zh': '电压降估算：基于神经近似的模型、特征和数据表示'}
{'arxiv_id': 'arXiv:2502.05344', 'title': 'RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation', 'authors': 'Sicheng Zhong, Jiading Zhu, Yifang Tian, Xujie Si', 'link': 'https://arxiv.org/abs/2502.05344', 'abstract': 'Scaling automated formal verification to real-world projects requires resolving cross-module dependencies and global contexts, which are challenges overlooked by existing function-centric methods. We introduce RagVerus, a framework that synergizes retrieval-augmented generation with context-aware prompting to automate proof synthesis for multi-module repositories, achieving a 27% relative improvement on our novel RepoVBench benchmark -- the first repository-level dataset for Verus with 383 proof completion tasks. RagVerus triples proof pass rates on existing benchmarks under constrained language model budgets, demonstrating a scalable and sample-efficient verification.', 'abstract_zh': '将形式验证自动化扩展到实际项目需要解决跨模块依赖和全局上下文问题，这是现有函数中心方法忽视的挑战。我们提出了一种名为RagVerus的框架，该框架结合了检索增强生成与上下文感知提示，以自动化多模块仓库的证明合成，在我们新颖的RepoVBench基准上实现了27%的相对改进——这是首个针对Verus的仓库级数据集，包含383个证明完成任务。RagVerus在受限语言模型预算下将现有基准的证明通过率提高三倍，展示了可扩展且样本高效的验证方法。', 'title_zh': 'RAG-Verus：基于检索增强生成的仓库级别程序验证'}
{'arxiv_id': 'arXiv:2502.05330', 'title': 'Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge', 'authors': 'Muhammad Imran, Jonathan R. Krebs, Vishal Balaji Sivaraman, Teng Zhang, Amarjeet Kumar, Walker R. Ueland, Michael J. Fassler, Jinlong Huang, Xiao Sun, Lisheng Wang, Pengcheng Shi, Maximilian Rokuss, Michael Baumgartner, Yannick Kirchhof, Klaus H. Maier-Hein, Fabian Isensee, Shuolin Liu, Bing Han, Bong Thanh Nguyen, Dong-jin Shin, Park Ji-Woo, Mathew Choi, Kwang-Hyun Uhm, Sung-Jea Ko, Chanwoong Lee, Jaehee Chun, Jin Sung Kim, Minghui Zhang, Hanxiao Zhang, Xin You, Yun Gu, Zhaohong Pan, Xuan Liu, Xiaokun Liang, Markus Tiefenthaler, Enrique Almar-Munoz, Matthias Schwab, Mikhail Kotyushev, Rostislav Epifanov, Marek Wodzinski, Henning Muller, Abdul Qayyum, Moona Mazher, Steven A. Niederer, Zhiwei Wang, Kaixiang Yang, Jintao Ren, Stine Sofia Korreman, Yuchong Gao, Hongye Zeng, Haoyu Zheng, Rui Zheng, Jinghua Yue, Fugen Zhou, Bo Liu, Alexander Cosman, Muxuan Liang, Chang Zhao, Gilbert R. Upchurch Jr., Jun Ma, Yuyin Zhou, Michol A. Cooper, Wei Shao', 'link': 'https://arxiv.org/abs/2502.05330', 'abstract': 'Multi-class segmentation of the aorta in computed tomography angiography (CTA) scans is essential for diagnosing and planning complex endovascular treatments for patients with aortic dissections. However, existing methods reduce aortic segmentation to a binary problem, limiting their ability to measure diameters across different branches and zones. Furthermore, no open-source dataset is currently available to support the development of multi-class aortic segmentation methods. To address this gap, we organized the AortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes annotated for 23 clinically relevant aortic branches and zones. This dataset was designed to facilitate both model development and validation. The challenge attracted 121 teams worldwide, with participants leveraging state-of-the-art frameworks such as nnU-Net and exploring novel techniques, including cascaded models, data augmentation strategies, and custom loss functions. We evaluated the submitted algorithms using the Dice Similarity Coefficient (DSC) and Normalized Surface Distance (NSD), highlighting the approaches adopted by the top five performing teams. This paper presents the challenge design, dataset details, evaluation metrics, and an in-depth analysis of the top-performing algorithms. The annotated dataset, evaluation code, and implementations of the leading methods are publicly available to support further research. All resources can be accessed at this https URL.', 'abstract_zh': 'CTA扫描中主动脉多类分割对于诊断和规划主动脉夹层患者的复杂经血管治疗至关重要。然而，现有方法将主动脉分割简化为二元问题，限制了其在不同分支和区域测量直径的能力。此外，目前没有开源数据集支持多类主动脉分割方法的发展。为解决这一问题，我们组织了AortaSeg24 MICCAI挑战，引入了第一个包含100个标注了23个临床相关主动脉分支和区域的CTA体积的数据集。该数据集旨在促进模型的开发和验证。来自全球的121支队伍参加了挑战，参赛者利用了最先进的框架如nnU-Net，并探索了诸如级联模型、数据增强策略和自定义损失函数等新技术。我们使用Dice相似性系数（DSC）和归一化表面距离（NSD）评估提交的算法，并强调了前五名队伍所采用的方法。本文介绍了挑战设计、数据集详情、评估指标及对表现最佳算法的深入分析。标注数据集、评估代码及领先方法的实现均公开发布，以支持进一步研究。所有资源可访问此URL：[此 https URL]。', 'title_zh': 'Aortic 分支和区域在计算机断层血管成像中的多类分割：AortaSeg24 挑战赛'}
{'arxiv_id': 'arXiv:2502.05312', 'title': 'Towards the Development of Balanced Synthetic Data for Correcting Grammatical Errors in Arabic: An Approach Based on Error Tagging Model and Synthetic Data Generating Model', 'authors': 'Ahlam Alrehili, Areej Alhothali', 'link': 'https://arxiv.org/abs/2502.05312', 'abstract': 'Synthetic data generation is widely recognized as a way to enhance the quality of neural grammatical error correction (GEC) systems. However, current approaches often lack diversity or are too simplistic to generate the wide range of grammatical errors made by humans, especially for low-resource languages such as Arabic. In this paper, we will develop the error tagging model and the synthetic data generation model to create a large synthetic dataset in Arabic for grammatical error correction. In the error tagging model, the correct sentence is categorized into multiple error types by using the DeBERTav3 model. Arabic Error Type Annotation tool (ARETA) is used to guide multi-label classification tasks in an error tagging model in which each sentence is classified into 26 error tags. The synthetic data generation model is a back-translation-based model that generates incorrect sentences by appending error tags before the correct sentence that was generated from the error tagging model using the ARAT5 model. In the QALB-14 and QALB-15 Test sets, the error tagging model achieved 94.42% F1, which is state-of-the-art in identifying error tags in clean sentences. As a result of our syntactic data training in grammatical error correction, we achieved a new state-of-the-art result of F1-Score: 79.36% in the QALB-14 Test set. We generate 30,219,310 synthetic sentence pairs by using a synthetic data generation model.', 'abstract_zh': '合成数据生成被广泛认为是一种提升神经语法错误修正系统质量的方法。然而，当前的方法往往缺乏多样性和简化度，难以生成人类所犯的各种语法错误，尤其是对于阿拉伯语等低资源语言。在本文中，我们将开发错误标记模型和合成数据生成模型，为阿拉伯语语法错误修正创建大规模合成数据集。在错误标记模型中，使用DeBERTav3模型将正确句子分类为多个错误类型。阿拉伯错误类型注释工具（ARETA）用于指导错误标记模型中的多标签分类任务，其中每句句子被分类为26个错误标签。合成数据生成模型是一种基于反向翻译的模型，通过在由ARAT5模型生成的正确句子之前附加错误标签来生成错误句子。在QALB-14和QALB-15测试集中，错误标记模型实现了94.42%的F1值，这是在干净句子中识别错误标签的最新技术水平。通过我们的句法数据训练，我们在QALB-14测试集中实现了新的最佳F1-Score：79.36%。我们使用合成数据生成模型生成了30,219,310对合成句子对。', 'title_zh': '基于错误标注模型和合成数据生成模型的平衡合成数据开发方法：用于纠正阿拉伯语语法错误的研究'}
{'arxiv_id': 'arXiv:2502.05310', 'title': 'Oracular Programming: A Modular Foundation for Building LLM-Enabled Software', 'authors': 'Jonathan Laurent, André Platzer', 'link': 'https://arxiv.org/abs/2502.05310', 'abstract': 'Large Language Models have proved surprisingly effective at solving a wide range of tasks from just a handful of examples. However, their lack of reliability and modularity limits their capacity to tackle large problems that require many steps of reasoning. In response, researchers have proposed advanced pipelines that leverage domain-specific knowledge to chain smaller prompts, provide intermediate feedback and improve performance through search. However, the current complexity of writing, tuning, maintaining and improving such pipelines has limited their sophistication. We propose oracular programming, a foundational paradigm for building LLM-enabled applications that lets domain experts express high-level problem-solving strategies as programs with unresolved choice points. These choice points are resolved at runtime by LLMs, which generalize from user-provided examples of correct and incorrect decisions. An oracular program is composed of three orthogonal components: a strategy that consists in a nondeterministic program with choice points that can be reified into a search tree, a policy that specifies how to navigate this tree with the help of LLM oracles, and a set of demonstrations that describe successful and unsuccessful search tree navigation scenarios across diverse problem instances. Each component is expressed in a dedicated programming language and can be independently improved or substituted. We address the key programming language design challenges of modularly composing oracular programs and enforcing consistency between their components as they evolve.', 'abstract_zh': '大型语言模型已经证明，在从少量示例中解决广泛任务方面表现出乎意料的有效性。然而，它们的可靠性和模块性限制了它们解决需要多步推理的大型问题的能力。为应对这一挑战，研究人员提出了利用领域特定知识的高级管道，以链式方式组合较小的提示、提供中间反馈并借助搜索提高性能。然而，编写、调整、维护和改进这些管道的当前复杂性限制了它们的复杂性。我们提出了一种新的编程范式——或acular编程，这是一种基于构建LLM驱动应用程序的基础范式，允许领域专家以编程方式表达包含未决选择点的高层次问题解决策略。这些选择点在运行时由LLM解决，LLM从用户提供的正确和错误决策示例中进行泛化。或acular程序由三个正交组件组成：一种策略，其包含非确定性程序并包含可以在运行时构建为搜索树的选择点；一种策略，指定了如何在LLM预言的帮助下导航此搜索树；以及一系列演示，描述了各种问题实例中成功的和不成功的搜索树导航场景。每个组件都用专用编程语言表示，并且可以独立改进或替换。我们解决了模块化组合或acular程序及其组件在演变过程中保持一致性的关键编程语言设计挑战。', 'title_zh': '先知式编程：构建LLM驱动软件的模块化基础'}
{'arxiv_id': 'arXiv:2502.05300', 'title': 'Parameter Symmetry Breaking and Restoration Determines the Hierarchical Learning in AI Systems', 'authors': 'Liu Ziyin, Yizhou Xu, Tomaso Poggio, Isaac Chuang', 'link': 'https://arxiv.org/abs/2502.05300', 'abstract': 'The dynamics of learning in modern large AI systems is hierarchical, often characterized by abrupt, qualitative shifts akin to phase transitions observed in physical systems. While these phenomena hold promise for uncovering the mechanisms behind neural networks and language models, existing theories remain fragmented, addressing specific cases. In this paper, we posit that parameter symmetry breaking and restoration serve as a unifying mechanism underlying these behaviors. We synthesize prior observations and show how this mechanism explains three distinct hierarchies in neural networks: learning dynamics, model complexity, and representation formation. By connecting these hierarchies, we highlight symmetry -- a cornerstone of theoretical physics -- as a potential fundamental principle in modern AI.', 'abstract_zh': '现代大型AI系统的学习动力学是分层的，通常表现为类似于物理系统相变的 abrupt、qualitative 转变。尽管这些现象为揭示神经网络和语言模型的机制提供了希望，现有理论仍碎片化，仅针对特定案例。本文认为，参数对称性破缺与恢复是一种统一这些行为的机制。我们综合了先前的观察，并展示了这一机制如何解释神经网络中的三种不同层次：学习动力学、模型复杂性和表示形成。通过连接这些层次，我们将对称性——理论物理的基石——突出为现代AI中潜在的基本原则。', 'title_zh': '参数对称性破缺与恢复决定AI系统的分层学习'}
{'arxiv_id': 'arXiv:2502.05292', 'title': 'Drone Detection and Tracking with YOLO and a Rule-based Method', 'authors': 'Purbaditya Bhattacharya, Patrick Nowak', 'link': 'https://arxiv.org/abs/2502.05292', 'abstract': 'Drones or unmanned aerial vehicles are traditionally used for military missions, warfare, and espionage. However, the usage of drones has significantly increased due to multiple industrial applications involving security and inspection, transportation, research purposes, and recreational drone flying. Such an increased volume of drone activity in public spaces requires regulatory actions for purposes of privacy protection and safety. Hence, detection of illegal drone activities such as boundary encroachment becomes a necessity. Such detection tasks are usually automated and performed by deep learning models which are trained on annotated image datasets. This paper builds on a previous work and extends an already published open source dataset. A description and analysis of the entire dataset is provided. The dataset is used to train the YOLOv7 deep learning model and some of its minor variants and the results are provided. Since the detection models are based on a single image input, a simple cross-correlation based tracker is used to reduce detection drops and improve tracking performance in videos. Finally, the entire drone detection system is summarized.', 'abstract_zh': '无人机或无人驾驶航空器传统上用于军事任务、战争和谍报。然而，由于涉及安全、检查、交通、研究目的和 recreational 无人机飞行的多种工业应用，无人机的使用量显著增加。随着公共空间内无人机活动量的增加，需要采取监管措施以保护隐私和确保安全。因此，检测非法无人机活动（如越界）变得必要。这些检测任务通常被自动化，并由在注释图像数据集上训练的深度学习模型执行。本文在此前工作的基础上，扩展了一个已发布的开源数据集，并提供了整个数据集的描述和分析。数据集用于训练 YOLOv7 深度学习模型及其一些minor变体，并提供了结果。由于检测模型基于单张图像输入，使用了基于简单相关系数的跟踪器来减少视频中的检测失误，提高跟踪性能。最后，总结了整个无人机检测系统。', 'title_zh': '基于YOLO和基于规则的方法的无人机检测与跟踪'}
{'arxiv_id': 'arXiv:2502.05282', 'title': 'Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning', 'authors': 'Yuting He, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li', 'link': 'https://arxiv.org/abs/2502.05282', 'abstract': "Dense contrastive representation learning (DCRL) has greatly improved the learning efficiency for image-dense prediction tasks, showing its great potential to reduce the large costs of medical image collection and dense annotation. However, the properties of medical images make unreliable correspondence discovery, bringing an open problem of large-scale false positive and negative (FP&N) pairs in DCRL. In this paper, we propose GEoMetric vIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism prior to DCRL and enables a reliable correspondence discovery for effective dense contrast. We propose a deformable homeomorphism learning (DHL) which models the homeomorphism of medical images and learns to estimate a deformable mapping to predict the pixels' correspondence under topological preservation. It effectively reduces the searching space of pairing and drives an implicit and soft learning of negative pairs via a gradient. We also propose a geometric semantic similarity (GSS) which extracts semantic information in features to measure the alignment degree for the correspondence learning. It will promote the learning efficiency and performance of deformation, constructing positive pairs reliably. We implement two practical variants on two typical representation learning tasks in our experiments. Our promising results on seven datasets which outperform the existing methods show our great superiority. We will release our code on a companion link: this https URL.", 'abstract_zh': '密集对比表示学习的几何语义相似性学习（GEMINI）：嵌入同胚先验以提高可靠的对应发现', 'title_zh': '医学图像密集对比表示学习中的假阳性与假阴性问题的同胚先验'}
{'arxiv_id': 'arXiv:2502.05264', 'title': 'Quantum automated learning with provable and explainable trainability', 'authors': 'Qi Ye, Shuangyue Geng, Zizhao Han, Weikang Li, L.-M. Duan, Dong-Ling Deng', 'link': 'https://arxiv.org/abs/2502.05264', 'abstract': 'Machine learning is widely believed to be one of the most promising practical applications of quantum computing. Existing quantum machine learning schemes typically employ a quantum-classical hybrid approach that relies crucially on gradients of model parameters. Such an approach lacks provable convergence to global minima and will become infeasible as quantum learning models scale up. Here, we introduce quantum automated learning, where no variational parameter is involved and the training process is converted to quantum state preparation. In particular, we encode training data into unitary operations and iteratively evolve a random initial state under these unitaries and their inverses, with a target-oriented perturbation towards higher prediction accuracy sandwiched in between. Under reasonable assumptions, we rigorously prove that the evolution converges exponentially to the desired state corresponding to the global minimum of the loss function. We show that such a training process can be understood from the perspective of preparing quantum states by imaginary time evolution, where the data-encoded unitaries together with target-oriented perturbations would train the quantum learning model in an automated fashion. We further prove that the quantum automated learning paradigm features good generalization ability with the generalization error upper bounded by the ratio between a logarithmic function of the Hilbert space dimension and the number of training samples. In addition, we carry out extensive numerical simulations on real-life images and quantum data to demonstrate the effectiveness of our approach and validate the assumptions. Our results establish an unconventional quantum learning strategy that is gradient-free with provable and explainable trainability, which would be crucial for large-scale practical applications of quantum computing in machine learning scenarios.', 'abstract_zh': '无梯度的量子自动化学习：具有可证明和可解释的训练能力的量子机器学习新策略', 'title_zh': '量子自动学习具有可证明和可解释的可训练性'}
{'arxiv_id': 'arXiv:2502.05253', 'title': 'LLMs Can Teach Themselves to Better Predict the Future', 'authors': 'Benjamin Turtel, Danny Franklin, Philipp Schoenegger', 'link': 'https://arxiv.org/abs/2502.05253', 'abstract': "We present an outcome-driven fine-tuning framework that enhances the forecasting capabilities of large language models (LLMs) without relying on human-curated reasoning samples. Our method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date. We then rank pairs of these reasoning traces by their distance to the actual outcomes before fine-tuning the model via Direct Preference Optimization (DPO). On a separate test set, our approach increases prediction accuracy of Phi-4 14B and DeepSeek-R1 14B by between 7--10\\% over a base model and a DPO fine-tuned control model with randomized labels, bringing them on par with forecasting capabilities of much larger frontier models like GPT-4o.", 'abstract_zh': '我们提出了一种以结果为导向的微调框架，该框架在不依赖于人工标注的推理样本的情况下增强了大型语言模型（LLMs）的预测能力。该方法利用模型自我对弈生成一组具有多样性的推理轨迹和概率预测，这些问题是模型知识截止日期后才能得以解答的多样问题。然后，我们通过直接偏好优化（DPO）对模型进行微调，并根据这些推理轨迹与实际结果的距离对其进行排名。在单独的测试集中，与基线模型和带有随机标签的DPO微调控制模型相比，我们的方法提高了Phi-4 14B和DeepSeek-R1 14B的预测准确性7-10%，使其与GPT-4o等更大规模的前沿模型的预测能力相当。', 'title_zh': 'LLMs可以自我教学以更好地预测未来'}
{'arxiv_id': 'arXiv:2502.05252', 'title': 'GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?', 'authors': 'Yang Zhou, Hongyi Liu, Zhuoming Chen, Yuandong Tian, Beidi Chen', 'link': 'https://arxiv.org/abs/2502.05252', 'abstract': 'Long-context large language models (LLMs) have recently shown strong performance in information retrieval and long-document QA. However, to tackle the most challenging intellectual problems, LLMs must reason effectively in long and complex contexts (e.g., frontier mathematical research). Studying how LLMs handle increasing reasoning complexity and context length is essential, yet existing benchmarks lack a solid basis for quantitative evaluation. Inspired by the abstraction of GSM-8K problems as computational graphs, and the ability to introduce noise by adding unnecessary nodes and edges, we develop a grade school math problem generator capable of producing arithmetic problems with infinite difficulty and context length under fine-grained control. Using our newly synthesized GSM-Infinite benchmark, we comprehensively evaluate existing LLMs. We find a consistent sigmoid decline in reasoning performance as complexity increases, along with a systematic inference scaling trend: exponentially increasing inference computation yields only linear performance gains. These findings underscore the fundamental limitations of current long-context LLMs and the key challenges in scaling reasoning capabilities. Our GSM-Infinite benchmark provides a scalable and controllable testbed for systematically studying and advancing LLM reasoning in long and complex contexts.', 'abstract_zh': '长上下文大型语言模型（LLMs）在信息检索和长文档问答中展现了强大的性能。然而，为了解决最具挑战性的智力问题，LLMs 必须在长且复杂的上下文中有效推理（例如，前沿的数学研究）。研究LLMs处理复杂推理和上下文长度的能力至关重要，但现有基准缺乏定量评价的坚实基础。借鉴GSM-8K问题作为计算图的抽象，并通过添加不必要的节点和边引入噪声的能力，我们开发了一种小学数学问题生成器，能够在细粒度控制下生成具有无限复杂性和上下文长度的算术问题。使用我们的新合成GSM-Infinite基准，我们全面评估了现有的LLMs。我们发现复杂性增加时推理性能呈一致的S形下降，并且系统性的推理扩展趋势是：指数增加的推理计算仅带来线性的性能提升。这些发现突显了当前长上下文LLMs的基本局限性以及扩展推理能力的关键挑战。我们的GSM-Infinite基准提供了一个可扩展且可控的测试平台，系统地研究和推进LLMs在长且复杂上下文中的推理能力。', 'title_zh': 'GSM-Infinite: 在无限增加上下文长度和推理复杂度的情况下，你的LLMs表现如何？'}
{'arxiv_id': 'arXiv:2502.05248', 'title': 'Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires', 'authors': 'Pranav Bhandari, Usman Naseem, Amitava Datta, Nicolas Fay, Mehwish Nasim', 'link': 'https://arxiv.org/abs/2502.05248', 'abstract': 'Psychological assessment tools have long helped humans understand behavioural patterns. While Large Language Models (LLMs) can generate content comparable to that of humans, we explore whether they exhibit personality traits. To this end, this work applies psychological tools to LLMs in diverse scenarios to generate personality profiles. Using established trait-based questionnaires such as the Big Five Inventory and by addressing the possibility of training data contamination, we examine the dimensional variability and dominance of LLMs across five core personality dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. Our findings reveal that LLMs exhibit unique dominant traits, varying characteristics, and distinct personality profiles even within the same family of models.', 'abstract_zh': '心理评估工具长期帮助人类理解行为模式。虽然大型语言模型（LLMs）能够生成与人类相媲美的内容，但我们探索它们是否表现出人格特质。为此，本研究将心理评估工具应用于不同场景中的LLMs，以生成人格特征。通过使用基于特质的标准问卷（如五大人格特质问卷）并解决训练数据污染的可能性，我们考察了五大核心人格维度（开放性、尽责性、外向性、宜人性、神经质）上LLMs的维度变异性和主导性。我们的发现表明，即使在同一个模型系列内，LLMs也表现出独特的主导特质、不同的特征和个性特征。', 'title_zh': '大型语言模型中的人格特质评估：心理学问卷的见解'}
{'arxiv_id': 'arXiv:2502.05242', 'title': "SEER: Self-Explainability Enhancement of Large Language Models' Representations", 'authors': 'Guanxu Chen, Dongrui Liu, Tao Luo, Jing Shao', 'link': 'https://arxiv.org/abs/2502.05242', 'abstract': "Explaining the hidden representations of Large Language Models (LLMs) is a perspective to understand LLMs' underlying inference logic and improve their reliability in application scenarios. However, previous methods introduce external ''black-box'' modules to explain ''black-box'' LLMs, increasing the potential uncertainty and failing to provide faithful explanations. In this paper, we propose a self-explaining method SEER, enhancing LLMs' explainability by aggregating the same concept and disentangling the different concepts in the representation space. In this way, SEER provides faithful explanations carried by representations synchronously with the LLMs' output. Additionally, we showcase the applications of SEER on trustworthiness-related tasks (e.g., the safety risks classification and detoxification tasks), where self-explained LLMs achieve consistent improvement in explainability and performance. More crucially, we theoretically analyze the improvement of SEER on LLMs' generalization ability through optimal transport theory.", 'abstract_zh': '解释大型语言模型（LLMs）的隐藏表示是一种理解LLMs潜在推理逻辑并提高其在应用场景中可靠性的方式。然而，先前的方法引入了外部“黑盒”模块来解释“黑盒”LLMs，增加了潜在不确定性并无法提供忠实的解释。在本文中，我们提出了一种自解释方法SEER，通过在表示空间中聚合相同的概念并解开不同的概念来增强LLMs的解释性。这样，SEER能够同步LLMs输出提供忠实的解释。此外，我们展示了SEER在与可信性相关任务（例如，安全风险分类和去毒任务）中的应用，自解释的LLMs在解释性和性能上均实现了持续改进。更关键的是，我们通过最优传输理论理论上分析了SEER在提高LLMs泛化能力方面的改进。', 'title_zh': 'SEER: 大型语言模型表示的自我解释性增强'}
{'arxiv_id': 'arXiv:2502.05239', 'title': 'Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics', 'authors': 'Hussam Ghanem, Christophe Cruz', 'link': 'https://arxiv.org/abs/2502.05239', 'abstract': 'Recent advancements in large language models have demonstrated significant potential in the automated construction of knowledge graphs from unstructured text. This paper builds upon our previous work [16], which evaluated various models using metrics like precision, recall, F1 score, triple matching, and graph matching, and introduces a refined approach to address the critical issues of hallucination and omission. We propose an enhanced evaluation framework incorporating BERTScore for graph similarity, setting a practical threshold of 95% for graph matching. Our experiments focus on the Mistral model, comparing its original and fine-tuned versions in zero-shot and few-shot settings. We further extend our experiments using examples from the KELM-sub training dataset, illustrating that the fine-tuned model significantly improves knowledge graph construction accuracy while reducing the exact hallucination and omission. However, our findings also reveal that the fine-tuned models perform worse in generalization tasks on the KELM-sub dataset. This study underscores the importance of comprehensive evaluation metrics in advancing the state-of-the-art in knowledge graph construction from textual data.', 'abstract_zh': '最近在大型语言模型方面的进展显示了其在从非结构化文本自动生成知识图谱方面的显著潜力。本文在此前工作[16]的基础上，利用精确度、召回率、F1分数、三元组匹配和图匹配等指标评估各种模型，并引入一种改进的方法来解决幻觉和遗漏的关键问题。我们提出了一个增强的评估框架，结合使用BERTScore进行图相似性评估，并为图匹配设定一个实际阈值，即95%。我们的实验集中在Mistral模型上，比较了其原版和微调版本在零样本和少样本设置下的性能。我们进一步使用KELM-sub训练数据集的示例进行实验，表明微调模型在提高知识图谱构建准确性的同时，还能减少精确幻觉和遗漏。然而，我们的研究结果还揭示了微调模型在KELM-sub数据集上的泛化任务表现较差。这项研究强调了综合评估指标在从文本数据构建知识图谱方面的前沿技术进步中的重要性。', 'title_zh': '增强知识图谱构建：以幻觉、遗漏和图相似性指标为重点的评估'}
{'arxiv_id': 'arXiv:2502.05237', 'title': 'PSM-SQL: Progressive Schema Learning with Multi-granularity Semantics for Text-to-SQL', 'authors': 'Zhuopan Yang, Yuanzhen Xie, Ruichao Zhong, Yunzhi Tan, Enjie Liu, Zhenguo Yang, Mochi Gao, Bo Hu, Zang Li', 'link': 'https://arxiv.org/abs/2502.05237', 'abstract': 'It is challenging to convert natural language (NL) questions into executable structured query language (SQL) queries for text-to-SQL tasks due to the vast number of database schemas with redundancy, which interferes with semantic learning, and the domain shift between NL and SQL. Existing works for schema linking focus on the table level and perform it once, ignoring the multi-granularity semantics and chainable cyclicity of schemas. In this paper, we propose a progressive schema linking with multi-granularity semantics (PSM-SQL) framework to reduce the redundant database schemas for text-to-SQL. Using the multi-granularity schema linking (MSL) module, PSM-SQL learns the schema semantics at the column, table, and database levels. More specifically, a triplet loss is used at the column level to learn embeddings, while fine-tuning LLMs is employed at the database level for schema reasoning. MSL employs classifier and similarity scores to model schema interactions for schema linking at the table level. In particular, PSM-SQL adopts a chain loop strategy to reduce the task difficulty of schema linking by continuously reducing the number of redundant schemas. Experiments conducted on text-to-SQL datasets show that the proposed PSM-SQL is 1-3 percentage points higher than the existing methods.', 'abstract_zh': '一种多粒度语义渐进模式链接的文本到SQL框架（PSM-SQL）', 'title_zh': 'PSM-SQL：基于多粒度语义的 progressive 架构学习文本到SQL转换'}
{'arxiv_id': 'arXiv:2502.05236', 'title': 'Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance', 'authors': 'Shehzeen Hussain, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Subhankar Ghosh, Mikyas T. Desta, Roy Fejgin, Rafael Valle, Jason Li', 'link': 'https://arxiv.org/abs/2502.05236', 'abstract': 'While autoregressive speech token generation models produce speech with remarkable variety and naturalness, their inherent lack of controllability often results in issues such as hallucinations and undesired vocalizations that do not conform to conditioning inputs. We introduce Koel-TTS, a suite of enhanced encoder-decoder Transformer TTS models that address these challenges by incorporating preference alignment techniques guided by automatic speech recognition and speaker verification models. Additionally, we incorporate classifier-free guidance to further improve synthesis adherence to the transcript and reference speaker audio. Our experiments demonstrate that these optimizations significantly enhance target speaker similarity, intelligibility, and naturalness of synthesized speech. Notably, Koel-TTS directly maps text and context audio to acoustic tokens, and on the aforementioned metrics, outperforms state-of-the-art TTS models, despite being trained on a significantly smaller dataset. Audio samples and demos are available on our website.', 'abstract_zh': 'Koel-TTS：通过偏好对齐技术改进的增强型编码器-解码器Transformer TTS模型', 'title_zh': 'Koel-TTS：通过偏好对齐和无分类器引导提高基于LLM的语音生成'}
{'arxiv_id': 'arXiv:2502.05234', 'title': 'Optimizing Temperature for Language Models with Multi-Sample Inference', 'authors': 'Weihua Du, Yiming Yang, Sean Welleck', 'link': 'https://arxiv.org/abs/2502.05234', 'abstract': "Multi-sample aggregation strategies, such as majority voting and best-of-N sampling, are widely used in contemporary large language models (LLMs) to enhance predictive accuracy across various tasks. A key challenge in this process is temperature selection, which significantly impacts model performance. Existing approaches either rely on a fixed default temperature or require labeled validation data for tuning, which are often scarce and difficult to obtain. This paper addresses the challenge of automatically identifying the (near)-optimal temperature for different LLMs using multi-sample aggregation strategies, without relying on task-specific validation data. We provide a comprehensive analysis of temperature's role in performance optimization, considering variations in model architectures, datasets, task types, model sizes, and predictive accuracy. Furthermore, we propose a novel entropy-based metric for automated temperature optimization, which consistently outperforms fixed-temperature baselines. Additionally, we incorporate a stochastic process model to enhance interpretability, offering deeper insights into the relationship between temperature and model performance.", 'abstract_zh': '多样本聚合策略中的温度自动优化：无需依赖特定任务验证数据的研究', 'title_zh': '使用多样本推理优化语言模型的温度参数'}
{'arxiv_id': 'arXiv:2502.05232', 'title': 'Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers', 'authors': 'Adam Stooke, Rohit Prabhavalkar, Khe Chai Sim, Pedro Moreno Mengibar', 'link': 'https://arxiv.org/abs/2502.05232', 'abstract': 'Modern systems for automatic speech recognition, including the RNN-Transducer and Attention-based Encoder-Decoder (AED), are designed so that the encoder is not required to alter the time-position of information from the audio sequence into the embedding; alignment to the final text output is processed during decoding. We discover that the transformer-based encoder adopted in recent years is actually capable of performing the alignment internally during the forward pass, prior to decoding. This new phenomenon enables a simpler and more efficient model, the "Aligner-Encoder". To train it, we discard the dynamic programming of RNN-T in favor of the frame-wise cross-entropy loss of AED, while the decoder employs the lighter text-only recurrence of RNN-T without learned cross-attention -- it simply scans embedding frames in order from the beginning, producing one token each until predicting the end-of-message. We conduct experiments demonstrating performance remarkably close to the state of the art, including a special inference configuration enabling long-form recognition. In a representative comparison, we measure the total inference time for our model to be 2x faster than RNN-T and 16x faster than AED. Lastly, we find that the audio-text alignment is clearly visible in the self-attention weights of a certain layer, which could be said to perform "self-transduction".', 'abstract_zh': '基于变压器的“对齐-编码器”模型：一种简单高效的声音到文本的自动转换方法', 'title_zh': '对齐编码器：自我注意变换器可以是自转换器'}
{'arxiv_id': 'arXiv:2502.05231', 'title': 'Thin ring wing as a means of flow improvement upstream of a propeller', 'authors': 'Vladimir Sluchak', 'link': 'https://arxiv.org/abs/2502.05231', 'abstract': "There are numerous devices currently known with the purpose of reducing the irregularity of the flow upstream of the propeller and to decrease by that means the propeller-induced vibration and noise. Many of these devices are wing-shaped vortex-generators that affect the flow with their induced (i.e. passive) longitudinal vortices. The paper's subject is the use of a ring-shaped wing as a highly effective passive vortex-generator which allows to control the flow closer to the most charged sections of propeller blades. The problem of a thin ring-shaped wing with irregular (asymmetric) geometry in the irregular steady flow has been solved in a linear approach and the intensity of the induced longitudinal vortices as a function of the irregularity of the flow and the geometry of the ring wing has been estimated using that solution. Experiments in the towing tank showing good concordance with the theoretical model confirmed the effectiveness of such a device. Some additional advantages of a ring-shaped wing incorporated into the construction of stabilizers are considered.", 'abstract_zh': '环形机翼作为高效的被动旋涡发生器减少推进器诱导振动和噪声的研究', 'title_zh': '薄环翼作为提高推进器上游气流的手段'}
{'arxiv_id': 'arXiv:2502.05230', 'title': 'DiffNMR2: NMR Guided Sampling Acquisition Through Diffusion Model Uncertainty', 'authors': 'Etienne Goffinet, Sen Yan, Fabrizio Gabellieri, Laurence Jennings, Lydia Gkoura, Filippo Castiglione, Ryan Young, Idir Malki, Ankita Singh, Thomas Launey', 'link': 'https://arxiv.org/abs/2502.05230', 'abstract': "Nuclear Magnetic Resonance (NMR) spectrometry uses electro-frequency pulses to probe the resonance of a compound's nucleus, which is then analyzed to determine its structure. The acquisition time of high-resolution NMR spectra remains a significant bottleneck, especially for complex biological samples such as proteins. In this study, we propose a novel and efficient sub-sampling strategy based on a diffusion model trained on protein NMR data. Our method iteratively reconstructs under-sampled spectra while using model uncertainty to guide subsequent sampling, significantly reducing acquisition time. Compared to state-of-the-art strategies, our approach improves reconstruction accuracy by 52.9\\%, reduces hallucinated peaks by 55.6%, and requires 60% less time in complex NMR experiments. This advancement holds promise for many applications, from drug discovery to materials science, where rapid and high-resolution spectral analysis is critical.", 'abstract_zh': '核磁共振（NMR）光谱学使用射频脉冲探测化合物核的共振状态，然后通过分析确定其结构。高分辨率NMR光谱的采集时间仍然是一个显著的瓶颈，尤其是在蛋白质等复杂生物样品中。在本研究中，我们提出了一种基于蛋白质NMR数据训练的扩散模型的新型高效子抽样策略。该方法通过使用模型不确定性指导后续抽样，逐次重建欠采样光谱，显著减少了采集时间。相较于最先进的策略，我们的方法在重构准确性上提高了52.9%，减少了55.6%的幻峰，并在复杂NMR实验中所需时间减少了60%。这一进展在药物发现、材料科学等领域具有重要应用前景，特别是在需要快速高分辨率光谱分析的情况下。', 'title_zh': 'DiffNMR2：基于扩散模型不确定性指导的核磁共振采样 Acquisition通过核磁共振不确定性指导的扩散模型采样'}
{'arxiv_id': 'arXiv:2502.05228', 'title': 'Multi-Objective Mobile Damped Wave Algorithm (MOMDWA): A Novel Approach For Quantum System Control', 'authors': 'Juntao Yu, Jiaquan Yu, Dedai Wei, Xinye Sha, Shengwei Fu, Miuyu Qiu, Yurun Jin, Kaichen Ouyang', 'link': 'https://arxiv.org/abs/2502.05228', 'abstract': 'In this paper, we introduce a novel multi-objective optimization algorithm, the Multi-Objective Mobile Damped Wave Algorithm (MOMDWA), specifically designed to address complex quantum control problems. Our approach extends the capabilities of the original Mobile Damped Wave Algorithm (MDWA) by incorporating multiple objectives, enabling a more comprehensive optimization process. We applied MOMDWA to three quantum control scenarios, focusing on optimizing the balance between control fidelity, energy consumption, and control smoothness. The results demonstrate that MOMDWA significantly enhances quantum control efficiency and robustness, achieving high fidelity while minimizing energy use and ensuring smooth control pulses. This advancement offers a valuable tool for quantum computing and other domains requiring precise, multi-objective control.', 'abstract_zh': '基于移动阻尼波算法的多目标优化量子控制方法（MOMDWA）', 'title_zh': '多目标移动阻尼波算法（MOMDWA）：一种量子系统控制的新方法'}
{'arxiv_id': 'arXiv:2502.05227', 'title': 'Robotouille: An Asynchronous Planning Benchmark for LLM Agents', 'authors': 'Gonzalo Gonzalez-Pumariega, Leong Su Yean, Neha Sunkara, Sanjiban Choudhury', 'link': 'https://arxiv.org/abs/2502.05227', 'abstract': "Effective asynchronous planning, or the ability to efficiently reason and plan over states and actions that must happen in parallel or sequentially, is essential for agents that must account for time delays, reason over diverse long-horizon tasks, and collaborate with other agents. While large language model (LLM) agents show promise in high-level task planning, current benchmarks focus primarily on short-horizon tasks and do not evaluate such asynchronous planning capabilities. We introduce Robotouille, a challenging benchmark environment designed to test LLM agents' ability to handle long-horizon asynchronous scenarios. Our synchronous and asynchronous datasets capture increasingly complex planning challenges that go beyond existing benchmarks, requiring agents to manage overlapping tasks and interruptions. Our results show that ReAct (gpt4-o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks, highlighting significant room for improvement. We further analyze failure modes, demonstrating the need for LLM agents to better incorporate long-horizon feedback and self-audit their reasoning during task execution. Code is available at this https URL.", 'abstract_zh': '有效的异步规划能力对于能够考虑时间延迟、处理多样化长时 horizon 任务以及与其他代理协作的智能体至关重要。虽然大规模语言模型（LLM）智能体在高层次任务规划方面显示出希望，但当前的基准测试主要集中在短时 horizon 任务上，并未评估这种异步规划能力。我们引入了Robotouille，一个具有挑战性的基准环境，旨在测试LLM智能体处理长时 horizon 异步场景的能力。我们的同步和异步数据集捕捉了超出现有基准测试的日益复杂的规划挑战，要求智能体管理重叠任务和中断。我们的结果显示，ReAct（gpt4-o）在同步任务中得分47%，而在异步任务中仅得11%，这突显了巨大的改进空间。我们进一步分析了失败模式，表明LLM智能体需要更好地整合长时 horizon 反馈并在任务执行期间自我审查其推理。代码可在以下链接获取。', 'title_zh': 'Robotouille: 一种用于LLM智能体的异步规划基准测试'}
{'arxiv_id': 'arXiv:2502.05225', 'title': 'BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks', 'authors': 'Hanyong Lee, Chaelyn Lee, Yongjae Lee, Jaesung Lee', 'link': 'https://arxiv.org/abs/2502.05225', 'abstract': 'Phishing often targets victims through visually perturbed texts to bypass security systems. The noise contained in these texts functions as an adversarial attack, designed to deceive language models and hinder their ability to accurately interpret the content. However, since it is difficult to obtain sufficient phishing cases, previous studies have used synthetic datasets that do not contain real-world cases. In this study, we propose the BitAbuse dataset, which includes real-world phishing cases, to address the limitations of previous research. Our dataset comprises a total of 325,580 visually perturbed texts. The dataset inputs are drawn from the raw corpus, consisting of visually perturbed sentences and sentences generated through an artificial perturbation process. Each input sentence is labeled with its corresponding ground truth, representing the restored, non-perturbed version. Language models trained on our proposed dataset demonstrated significantly better performance compared to previous methods, achieving an accuracy of approximately 96%. Our analysis revealed a significant gap between real-world and synthetic examples, underscoring the value of our dataset for building reliable pre-trained models for restoration tasks. We release the BitAbuse dataset, which includes real-world phishing cases annotated with visual perturbations, to support future research in adversarial attack defense.', 'abstract_zh': 'Phishing often targets victims through visually perturbed texts to bypass security systems. The noise contained in these texts functions as an adversarial attack, designed to deceive language models and hinder their ability to accurately interpret the content. However, since it is difficult to obtain sufficient phishing cases, previous studies have used synthetic datasets that do not contain real-world cases. In this study, we propose the BitAbuse dataset, which includes real-world phishing cases, to address the limitations of previous research. Our dataset comprises a total of 325,580 visually perturbed texts. The dataset inputs are drawn from the raw corpus, consisting of visually perturbed sentences and sentences generated through an artificial perturbation process. Each input sentence is labeled with its corresponding ground truth, representing the restored, non-perturbed version. Language models trained on our proposed dataset demonstrated significantly better performance compared to previous methods, achieving an accuracy of approximately 96%. Our analysis revealed a significant gap between real-world and synthetic examples, underscoring the value of our dataset for building reliable pre-trained models for restoration tasks. We release the BitAbuse dataset, which includes real-world phishing cases annotated with visual perturbations, to support future research in adversarial attack defense.', 'title_zh': 'BitAbuse: 一种视觉扰动文本数据集，用于防骗攻击'}
{'arxiv_id': 'arXiv:2502.05224', 'title': 'A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations', 'authors': 'Yihe Zhou, Tao Ni, Wei-Bin Lee, Qingchuan Zhao', 'link': 'https://arxiv.org/abs/2502.05224', 'abstract': 'Large Language Models (LLMs) have achieved significantly advanced capabilities in understanding and generating human language text, which have gained increasing popularity over recent years. Apart from their state-of-the-art natural language processing (NLP) performance, considering their widespread usage in many industries, including medicine, finance, education, etc., security concerns over their usage grow simultaneously. In recent years, the evolution of backdoor attacks has progressed with the advancement of defense mechanisms against them and more well-developed features in the LLMs. In this paper, we adapt the general taxonomy for classifying machine learning attacks on one of the subdivisions - training-time white-box backdoor attacks. Besides systematically classifying attack methods, we also consider the corresponding defense methods against backdoor attacks. By providing an extensive summary of existing works, we hope this survey can serve as a guideline for inspiring future research that further extends the attack scenarios and creates a stronger defense against them for more robust LLMs.', 'abstract_zh': '大型语言模型（LLMs）在理解和生成人类语言文本方面已取得显著进步，近年来受到越来越多的关注。除了其在自然语言处理（NLP）方面的顶级性能，随着其在医学、金融、教育等多个行业的广泛应用，对其使用的安全关注也不断增加。近年来，随着对抗回门攻击防御机制的进步和LLMs功能的提升，回门攻击本身也不断发展。在本文中，我们采用一般分类法对训练时白盒回门攻击进行分类。除了系统分类攻击方法外，我们还考虑了相应的防御方法。通过广泛总结现有工作，我们希望此综述能够为未来研究提供指导，进一步扩展攻击场景并创建更强的防御机制，以增强LLMs的安全性。', 'title_zh': '大型语言模型中的后门威胁综述：攻击、防御与评估'}
{'arxiv_id': 'arXiv:2502.05223', 'title': 'KDA: A Knowledge-Distilled Attacker for Generating Diverse Prompts to Jailbreak LLMs', 'authors': 'Buyun Liang, Kwan Ho Ryan Chan, Darshan Thaker, Jinqi Luo, René Vidal', 'link': 'https://arxiv.org/abs/2502.05223', 'abstract': "Jailbreak attacks exploit specific prompts to bypass LLM safeguards, causing the LLM to generate harmful, inappropriate, and misaligned content. Current jailbreaking methods rely heavily on carefully designed system prompts and numerous queries to achieve a single successful attack, which is costly and impractical for large-scale red-teaming. To address this challenge, we propose to distill the knowledge of an ensemble of SOTA attackers into a single open-source model, called Knowledge-Distilled Attacker (KDA), which is finetuned to automatically generate coherent and diverse attack prompts without the need for meticulous system prompt engineering. Compared to existing attackers, KDA achieves higher attack success rates and greater cost-time efficiency when targeting multiple SOTA open-source and commercial black-box LLMs. Furthermore, we conducted a quantitative diversity analysis of prompts generated by baseline methods and KDA, identifying diverse and ensemble attacks as key factors behind KDA's effectiveness and efficiency.", 'abstract_zh': 'Jailbreak攻击利用特定提示绕过LLM防护，导致LLM生成有害、不适当和偏颇的内容。当前的Jailbreak方法高度依赖精心设计的系统提示和大量查询以实现一次成功的攻击，这在大规模红队演练中成本高且不实际。为应对这一挑战，我们提出了一种将多种当下最优攻击者知识精简至一个开源模型的方法，称为知识精简攻击者（KDA），该模型通过微调能够自动生成连贯且多样的攻击提示，无需精细的系统提示工程。与现有攻击者相比，KDA在针对多种当下最优的开源和商用黑盒LLM时实现了更高的攻击成功率和更好的成本时间效率。此外，我们对基线方法和KDA生成的提示进行了定量多样性分析，发现多样性和集成攻击是KDA有效性和效率的关键因素。', 'title_zh': 'KDA：一种知识精简攻击者，用于生成多样化的提示以突破LLM'}
{'arxiv_id': 'arXiv:2502.05221', 'title': 'Blackout DIFUSCO', 'authors': 'Jun Pyo Seo', 'link': 'https://arxiv.org/abs/2502.05221', 'abstract': 'This study explores the integration of Blackout Diffusion into the DIFUSCO framework for combinatorial optimization, specifically targeting the Traveling Salesman Problem (TSP). Inspired by the success of discrete-time diffusion models (D3PM) in maintaining structural integrity, we extend the paradigm to a continuous-time framework, leveraging the unique properties of Blackout Diffusion. Continuous-time modeling introduces smoother transitions and refined control, hypothesizing enhanced solution quality over traditional discrete methods. We propose three key improvements to enhance the diffusion process. First, we transition from a discrete-time-based model to a continuous-time framework, providing a more refined and flexible formulation. Second, we refine the observation time scheduling to ensure a smooth and linear transformation throughout the diffusion process, allowing for a more natural progression of states. Finally, building upon the second improvement, we further enhance the reverse process by introducing finer time slices in regions that are particularly challenging for the model, thereby improving accuracy and stability in the reconstruction phase. Although the experimental results did not exceed the baseline performance, they demonstrate the effectiveness of these methods in balancing simplicity and complexity, offering new insights into diffusion-based combinatorial optimization. This work represents the first application of Blackout Diffusion to combinatorial optimization, providing a foundation for further advancements in this domain. * The code is available for review at this https URL.', 'abstract_zh': '本研究探讨将Blackout Diffusion整合到DIFUSCO框架中以解决组合优化问题，具体针对旅行商问题（TSP）。受离散时间扩散模型（D3PM）在保持结构完整性方面的成功启发，我们将这一范式扩展到连续时间框架，利用Blackout Diffusion的独特属性。连续时间建模引入了更平滑的过渡和更精细的控制，假设与传统离散方法相比能提高解的质量。我们提出了三种关键改进以增强扩散过程。首先，我们从基于离散时间的模型过渡到连续时间框架，提供了更精细和灵活的表述。其次，我们优化了观测时间的调度，确保扩散过程中有平滑和线性的转换，允许状态更自然地演变。最后，在第二个改进的基础上，我们通过在特别具有挑战性的区域引入更细的时间片来进一步增强逆过程，从而在重建阶段提高准确性和稳定性。尽管实验结果未超过基线性能，但它们展示了这些方法在平衡简单性和复杂性方面的有效性，并为基于扩散的组合优化提供了新的见解。本工作是将Blackout Diffusion应用于组合优化的第一个尝试，为其在此领域的进一步发展提供了基础。* 代码可在以下链接进行查看：![](https://your-code-link.com)。', 'title_zh': 'blackout DIFUSCO'}
{'arxiv_id': 'arXiv:2502.05220', 'title': 'Aero-LLM: A Distributed Framework for Secure UAV Communication and Intelligent Decision-Making', 'authors': 'Balakrishnan Dharmalingam, Rajdeep Mukherjee, Brett Piggott, Guohuan Feng, Anyi Liu', 'link': 'https://arxiv.org/abs/2502.05220', 'abstract': "Increased utilization of unmanned aerial vehicles (UAVs) in critical operations necessitates secure and reliable communication with Ground Control Stations (GCS). This paper introduces Aero-LLM, a framework integrating multiple Large Language Models (LLMs) to enhance UAV mission security and operational efficiency. Unlike conventional singular LLMs, Aero-LLM leverages multiple specialized LLMs for various tasks, such as inferencing, anomaly detection, and forecasting, deployed across onboard systems, edge, and cloud servers. This dynamic, distributed architecture reduces performance bottleneck and increases security capabilities. Aero-LLM's evaluation demonstrates outstanding task-specific metrics and robust defense against cyber threats, significantly enhancing UAV decision-making and operational capabilities and security resilience against cyber attacks, setting a new standard for secure, intelligent UAV operations.", 'abstract_zh': '增加无人驾驶航空器（UAV）在关键操作中的利用率 necessitates 安全和可靠的与地面控制站（GCS）通信。本文介绍了Aero-LLM框架，该框架整合了多个大型语言模型 (LLMs) 以增强无人机任务安全性和操作效率。不同于传统的单一LLMs，Aero-LLM 利用多个专门的LLMs 来执行各种任务，例如推理、异常检测和预测，并部署在机载系统、边缘和云服务器上。这一动态分布式架构减少了性能瓶颈并增强了安全性。Aero-LLM 的评估展示了出色的任务特定指标和 robust 的对抗网络安全威胁能力，显著提升了无人机决策能力和在针对网络安全攻击方面的安全韧性，确立了安全智能无人机操作的新标准。', 'title_zh': 'Aero-LLM：一种安全的无人机通信与智能决策分布式框架'}
{'arxiv_id': 'arXiv:2502.05219', 'title': 'Enabling External Scrutiny of AI Systems with Privacy-Enhancing Technologies', 'authors': 'Kendrea Beers, Helen Toner', 'link': 'https://arxiv.org/abs/2502.05219', 'abstract': 'This article describes how technical infrastructure developed by the nonprofit OpenMined enables external scrutiny of AI systems without compromising sensitive information.\nIndependent external scrutiny of AI systems provides crucial transparency into AI development, so it should be an integral component of any approach to AI governance. In practice, external researchers have struggled to gain access to AI systems because of AI companies\' legitimate concerns about security, privacy, and intellectual property.\nBut now, privacy-enhancing technologies (PETs) have reached a new level of maturity: end-to-end technical infrastructure developed by OpenMined combines several PETs into various setups that enable privacy-preserving audits of AI systems. We showcase two case studies where this infrastructure has been deployed in real-world governance scenarios: "Understanding Social Media Recommendation Algorithms with the Christchurch Call" and "Evaluating Frontier Models with the UK AI Safety Institute." We describe types of scrutiny of AI systems that could be facilitated by current setups and OpenMined\'s proposed future setups.\nWe conclude that these innovative approaches deserve further exploration and support from the AI governance community. Interested policymakers can focus on empowering researchers on a legal level.', 'abstract_zh': '开源组织OpenMined开发的技术基础设施如何实现AI系统的外部审查同时保护敏感信息', 'title_zh': '借助隐私增强技术实现AI系统的外部审视'}
{'arxiv_id': 'arXiv:2502.05218', 'title': 'FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction', 'authors': 'Yitong Duan, Weiran Wang, Jian Li', 'link': 'https://arxiv.org/abs/2502.05218', 'abstract': 'As a fundamental method in economics and finance, the factor model has been extensively utilized in quantitative investment. In recent years, there has been a paradigm shift from traditional linear models with expert-designed factors to more flexible nonlinear machine learning-based models with data-driven factors, aiming to enhance the effectiveness of these factor models. However, due to the low signal-to-noise ratio in market data, mining effective factors in data-driven models remains challenging. In this work, we propose a hypergraph-based factor model with temporal residual contrastive learning (FactorGCL) that employs a hypergraph structure to better capture high-order nonlinear relationships among stock returns and factors. To mine hidden factors that supplement human-designed prior factors for predicting stock returns, we design a cascading residual hypergraph architecture, in which the hidden factors are extracted from the residual information after removing the influence of prior factors. Additionally, we propose a temporal residual contrastive learning method to guide the extraction of effective and comprehensive hidden factors by contrasting stock-specific residual information over different time periods. Our extensive experiments on real stock market data demonstrate that FactorGCL not only outperforms existing state-of-the-art methods but also mines effective hidden factors for predicting stock returns.', 'abstract_zh': '基于超图的时空残差对比学习因子模型（FactorGCL）', 'title_zh': '基于超图的因子模型与时间残差对比学习相结合的股票收益预测'}
{'arxiv_id': 'arXiv:2502.05215', 'title': 'Watermarking across Modalities for Content Tracing and Generative AI', 'authors': 'Pierre Fernandez', 'link': 'https://arxiv.org/abs/2502.05215', 'abstract': 'Watermarking embeds information into digital content like images, audio, or text, imperceptible to humans but robustly detectable by specific algorithms. This technology has important applications in many challenges of the industry such as content moderation, tracing AI-generated content, and monitoring the usage of AI models. The contributions of this thesis include the development of new watermarking techniques for images, audio, and text. We first introduce methods for active moderation of images on social platforms. We then develop specific techniques for AI-generated content. We specifically demonstrate methods to adapt latent generative models to embed watermarks in all generated content, identify watermarked sections in speech, and improve watermarking in large language models with tests that ensure low false positive rates. Furthermore, we explore the use of digital watermarking to detect model misuse, including the detection of watermarks in language models fine-tuned on watermarked text, and introduce training-free watermarks for the weights of large transformers. Through these contributions, the thesis provides effective solutions for the challenges posed by the increasing use of generative AI models and the need for model monitoring and content moderation. It finally examines the challenges and limitations of watermarking techniques and discuss potential future directions for research in this area.', 'abstract_zh': '水印技术嵌入数字内容如图像、音频或文本，对人类不可感知但可通过特定算法可靠检测。该项技术在内容审核、追踪AI生成内容以及监控AI模型使用等方面有着重要的应用价值。本论文的贡献在于开发了适用于图像、音频和文本的新水印技术。我们首先介绍了在社交平台上的主动图像审核方法。然后，我们开发了特定技术以处理AI生成的内容。我们具体展示了如何调整潜在生成模型以在所有生成内容中嵌入水印、如何在语音中识别水marked部分、以及通过确保低误报率来改进在大规模语言模型中的水印技术。此外，我们探讨了使用数字水印检测模型滥用的方法，包括在基于水marked文本 fine-tuned 的语言模型中检测水印，并引入了无训练水印以应用于大规模变换器的权重。通过这些贡献，论文提供了应对生成AI模型使用增加带来的挑战以及模型监控和内容审核需要的有效解决方案。最后，论文探讨了水印技术的挑战和限制，并讨论了该领域的未来研究方向。', 'title_zh': '跨模态水印技术在内容追踪与生成型AI中的应用'}
{'arxiv_id': 'arXiv:2502.05214', 'title': 'CoRPA: Adversarial Image Generation for Chest X-rays Using Concept Vector Perturbations and Generative Models', 'authors': 'Amy Rafferty, Rishi Ramaesh, Ajitha Rajan', 'link': 'https://arxiv.org/abs/2502.05214', 'abstract': "Deep learning models for medical image classification tasks are becoming widely implemented in AI-assisted diagnostic tools, aiming to enhance diagnostic accuracy, reduce clinician workloads, and improve patient outcomes. However, their vulnerability to adversarial attacks poses significant risks to patient safety. Current attack methodologies use general techniques such as model querying or pixel value perturbations to generate adversarial examples designed to fool a model. These approaches may not adequately address the unique characteristics of clinical errors stemming from missed or incorrectly identified clinical features. We propose the Concept-based Report Perturbation Attack (CoRPA), a clinically-focused black-box adversarial attack framework tailored to the medical imaging domain. CoRPA leverages clinical concepts to generate adversarial radiological reports and images that closely mirror realistic clinical misdiagnosis scenarios. We demonstrate the utility of CoRPA using the MIMIC-CXR-JPG dataset of chest X-rays and radiological reports. Our evaluation reveals that deep learning models exhibiting strong resilience to conventional adversarial attacks are significantly less robust when subjected to CoRPA's clinically-focused perturbations. This underscores the importance of addressing domain-specific vulnerabilities in medical AI systems. By introducing a specialized adversarial attack framework, this study provides a foundation for developing robust, real-world-ready AI models in healthcare, ensuring their safe and reliable deployment in high-stakes clinical environments.", 'abstract_zh': '基于概念的报告扰动攻击：面向医疗成像领域的临床聚焦黑盒对抗攻击框架', 'title_zh': 'CoRPA：使用概念向量扰动和生成模型的胸部X光 adversarial 图像生成'}
{'arxiv_id': 'arXiv:2502.05213', 'title': 'DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models', 'authors': 'Qihao Lin, Chen Tang, Lan zhang, Junyang zhang, Xiangyang Li', 'link': 'https://arxiv.org/abs/2502.05213', 'abstract': "Well-trained large language models (LLMs) present significant risks, including potential malicious use and copyright infringement. Current studies aim to trace the distribution of LLM-generated texts by implicitly embedding watermarks. Among these, the single-bit watermarking method can only determine whether a given text was generated by an LLM. In contrast, the multi-bit watermarking method embeds richer information into the generated text, which can identify which LLM generated and distributed a given text to which user. However, existing efforts embed the multi-bit watermark directly into the generated text without accounting for its watermarking capacity. This approach can result in embedding failures when the text's watermarking capacity is insufficient. In this paper, we derive the watermark embedding distribution based on the logits of LLMs and propose a formal inequality to segment the text optimally for watermark embedding. Building on this foundation, we propose DERMARK, a dynamic, efficient, and robust multi-bit watermarking method. DERMARK divides the text into segments of varying lengths for each bit embedding, adaptively matching the text's capacity. It achieves this with negligible overhead and robust performance against text editing by minimizing watermark extraction loss. Comprehensive experiments demonstrate that, compared to the SOTA method, our method reduces the number of tokens required for embedding each bit by 20\\%, reduces watermark embedding time by 50\\%, and is robust to text editing and watermark erasure attacks.", 'abstract_zh': '基于LLM输出_logits的动态高效稳健多比特水印方法', 'title_zh': 'DERMARK: 一种动态、高效且 robust 的多比特水印用于大型语言模型'}
{'arxiv_id': 'arXiv:2502.05211', 'title': 'Decoding FL Defenses: Systemization, Pitfalls, and Remedies', 'authors': 'Momin Ahmad Khan, Virat Shejwalkar, Yasra Chandio, Amir Houmansadr, Fatima Muhammad Anwar', 'link': 'https://arxiv.org/abs/2502.05211', 'abstract': 'While the community has designed various defenses to counter the threat of poisoning attacks in Federated Learning (FL), there are no guidelines for evaluating these defenses. These defenses are prone to subtle pitfalls in their experimental setups that lead to a false sense of security, rendering them unsuitable for practical deployment. In this paper, we systematically understand, identify, and provide a better approach to address these challenges. First, we design a comprehensive systemization of FL defenses along three dimensions: i) how client updates are processed, ii) what the server knows, and iii) at what stage the defense is applied. Next, we thoroughly survey 50 top-tier defense papers and identify the commonly used components in their evaluation setups. Based on this survey, we uncover six distinct pitfalls and study their prevalence. For example, we discover that around 30% of these works solely use the intrinsically robust MNIST dataset, and 40% employ simplistic attacks, which may inadvertently portray their defense as robust. Using three representative defenses as case studies, we perform a critical reevaluation to study the impact of the identified pitfalls and show how they lead to incorrect conclusions about robustness. We provide actionable recommendations to help researchers overcome each pitfall.', 'abstract_zh': '在联邦学习中抵御投毒攻击的各种防御措施虽已设计，但缺乏评估指南。实验设置中的细微陷阱可能导致虚假的安全感，使其不适合实际部署。本文系统地理解、识别这些问题，并提供更好的解决方案。首先，我们从三个维度设计了联邦学习防御系统的全面体系结构：i) 客户端更新的处理方式，ii) 服务器掌握的信息，iii) 防御措施的应用阶段。接着，我们彻底调查了50篇顶级防御论文，并识别出其评估设置中常用的部分。基于此调查，我们发现了六种不同的陷阱，并研究了它们的普遍性。例如，我们发现约30%的工作仅使用内在 robust 的MNIST数据集，而40%的工作采用简单的攻击方法，这可能会无意中将其防御措施表现为 robust。通过三篇代表性防御措施作为案例研究，我们进行关键性的重新评估，研究识别出的陷阱的影响，并展示它们如何导致关于 robust 性的错误结论。我们提供了可操作的建议，帮助研究人员克服每个陷阱。', 'title_zh': '解码FL防御：系统化、陷阱与对策'}
{'arxiv_id': 'arXiv:2502.05209', 'title': 'Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities', 'authors': 'Zora Che, Stephen Casper, Robert Kirk, Anirudh Satheesh, Stewart Slocum, Lev E McKinney, Rohit Gandikota, Aidan Ewart, Domenic Rosati, Zichu Wu, Zikui Cai, Bilal Chughtai, Yarin Gal, Furong Huang, Dylan Hadfield-Menell', 'link': 'https://arxiv.org/abs/2502.05209', 'abstract': "Evaluations of large language model (LLM) risks and capabilities are increasingly being incorporated into AI risk management and governance frameworks. Currently, most risk evaluations are conducted by designing inputs that elicit harmful behaviors from the system. However, a fundamental limitation of this approach is that the harmfulness of the behaviors identified during any particular evaluation can only lower bound the model's worst-possible-case behavior. As a complementary method for eliciting harmful behaviors, we propose evaluating LLMs with model tampering attacks which allow for modifications to latent activations or weights. We pit state-of-the-art techniques for removing harmful LLM capabilities against a suite of 5 input-space and 6 model tampering attacks. In addition to benchmarking these methods against each other, we show that (1) model resilience to capability elicitation attacks lies on a low-dimensional robustness subspace; (2) the attack success rate of model tampering attacks can empirically predict and offer conservative estimates for the success of held-out input-space attacks; and (3) state-of-the-art unlearning methods can easily be undone within 16 steps of fine-tuning. Together these results highlight the difficulty of removing harmful LLM capabilities and show that model tampering attacks enable substantially more rigorous evaluations than input-space attacks alone. We release models at this https URL", 'abstract_zh': '大型语言模型（LLM）风险与能力的评估越来越多地被纳入AI风险管理与治理框架。当前，大多数风险评估是通过设计输入来引发系统有害行为来进行的。然而，这种方法的一个基本局限是，在任何特定评估中识别的有害行为的严重性只能对模型的最坏情况行为提供下界。作为引发有害行为的补充方法，我们提出使用模型篡改攻击来评估LLM，这种攻击允许对潜在激活或权重进行修改。我们将最先进的去除有害LLM能力的技术与一套5种输入空间攻击和6种模型篡改攻击进行了对比。除了相互基准测试这些方法外，我们还 Demonstrate（展示）了如下几点：（1）模型对能力引发攻击的抗性依赖于一个低维度的稳健性子空间；（2）模型篡改攻击的成功率可以实证预测和提供保留输入空间攻击成功的保守估计；（3）最先进的遗忘方法可以在16步调优内轻松被逆转。这些结果 Highlights（强调）了去除有害LLM能力的难度，并表明模型篡改攻击比单独使用输入空间攻击能够实现更为严格的评估。我们在此https://链接中发布了模型。', 'title_zh': '模型篡改攻击促使对大语言模型能力进行更严格的评估'}
{'arxiv_id': 'arXiv:2502.05208', 'title': 'Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator', 'authors': 'Yago Romano Martinez, Brady Carter, Abhijeet Solanki, Wesam Al Amiri, Syed Rafay Hasan, Terry N. Guo', 'link': 'https://arxiv.org/abs/2502.05208', 'abstract': "Autonomous vehicles (AVs) rely heavily on cameras and artificial intelligence (AI) to make safe and accurate driving decisions. However, since AI is the core enabling technology, this raises serious cyber threats that hinder the large-scale adoption of AVs. Therefore, it becomes crucial to analyze the resilience of AV security systems against sophisticated attacks that manipulate camera inputs, deceiving AI models. In this paper, we develop camera-camouflaged adversarial attacks targeting traffic sign recognition (TSR) in AVs. Specifically, if the attack is initiated by modifying the texture of a stop sign to fool the AV's object detection system, thereby affecting the AV actuators. The attack's effectiveness is tested using the CARLA AV simulator and the results show that such an attack can delay the auto-braking response to the stop sign, resulting in potential safety issues. We conduct extensive experiments under various conditions, confirming that our new attack is effective and robust. Additionally, we address the attack by presenting mitigation strategies. The proposed attack and defense methods are applicable to other end-to-end trained autonomous cyber-physical systems.", 'abstract_zh': '自主驾驶车辆的基于摄像头的对抗攻击研究：针对交通标识识别系统的隐匿攻击及其防御', 'title_zh': '自主驾驶车辆中伪装对抗攻击的缓解研究——基于CARLA模拟器的案例研究'}
{'arxiv_id': 'arXiv:2502.05206', 'title': 'Safety at Scale: A Comprehensive Survey of Large Model Safety', 'authors': 'Xingjun Ma, Yifeng Gao, Yixu Wang, Ruofan Wang, Xin Wang, Ye Sun, Yifan Ding, Hengyuan Xu, Yunhao Chen, Yunhan Zhao, Hanxun Huang, Yige Li, Jiaming Zhang, Xiang Zheng, Yang Bai, Henghui Ding, Zuxuan Wu, Xipeng Qiu, Jingfeng Zhang, Yiming Li, Jun Sun, Cong Wang, Jindong Gu, Baoyuan Wu, Siheng Chen, Tianwei Zhang, Yang Liu, Mingming Gong, Tongliang Liu, Shirui Pan, Cihang Xie, Tianyu Pang, Yinpeng Dong, Ruoxi Jia, Yang Zhang, Shiqing Ma, Xiangyu Zhang, Neil Gong, Chaowei Xiao, Sarah Erfani, Bo Li, Masashi Sugiyama, Dacheng Tao, James Bailey, Yu-Gang Jiang', 'link': 'https://arxiv.org/abs/2502.05206', 'abstract': 'The rapid advancement of large models, driven by their exceptional abilities in learning and generalization through large-scale pre-training, has reshaped the landscape of Artificial Intelligence (AI). These models are now foundational to a wide range of applications, including conversational AI, recommendation systems, autonomous driving, content generation, medical diagnostics, and scientific discovery. However, their widespread deployment also exposes them to significant safety risks, raising concerns about robustness, reliability, and ethical implications. This survey provides a systematic review of current safety research on large models, covering Vision Foundation Models (VFMs), Large Language Models (LLMs), Vision-Language Pre-training (VLP) models, Vision-Language Models (VLMs), Diffusion Models (DMs), and large-model-based Agents. Our contributions are summarized as follows: (1) We present a comprehensive taxonomy of safety threats to these models, including adversarial attacks, data poisoning, backdoor attacks, jailbreak and prompt injection attacks, energy-latency attacks, data and model extraction attacks, and emerging agent-specific threats. (2) We review defense strategies proposed for each type of attacks if available and summarize the commonly used datasets and benchmarks for safety research. (3) Building on this, we identify and discuss the open challenges in large model safety, emphasizing the need for comprehensive safety evaluations, scalable and effective defense mechanisms, and sustainable data practices. More importantly, we highlight the necessity of collective efforts from the research community and international collaboration. Our work can serve as a useful reference for researchers and practitioners, fostering the ongoing development of comprehensive defense systems and platforms to safeguard AI models.', 'abstract_zh': '大型模型的迅速发展：通过大规模预训练学习和泛化的卓越能力重塑了人工智能的格局。这些模型现在广泛应用于会话AI、推荐系统、自动驾驶、内容生成、医疗诊断和科学研究等多个领域。然而，它们的广泛应用也暴露出了重大的安全风险，引发了关于稳健性、可靠性和伦理影响的担忧。本文综述了当前大型模型安全性研究的现状，涵盖了视觉基础模型（VFMs）、大规模语言模型（LLMs）、视觉-语言预训练（VLP）模型、视觉-语言模型（VLMs）、扩散模型（DMs）以及基于大型模型的代理。我们的贡献总结如下：（1）我们提出了这些模型面临的安全威胁的全面分类，包括对抗攻击、数据投毒、后门攻击、脱狱和提示注入攻击、能量-延迟攻击、数据和模型提取攻击以及新兴的代理特定威胁。（2）我们回顾了针对每种攻击类型提出的防御策略，并总结了常用的数据集和基准测试用于安全性研究。（3）在此基础上，我们识别并讨论了大型模型安全性面临的开放挑战，强调需要进行全面的安全评估、可扩展和有效的防御机制，以及可持续的数据实践。更重要的是，我们强调了研究社区和国际合作的必要性。我们的工作可作为研究人员和实践者的有益参考，促进全面防御系统和平台的发展，以保障AI模型的安全。', 'title_zh': '大规模模型安全综述：安全性保障'}
{'arxiv_id': 'arXiv:2502.05202', 'title': 'Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies', 'authors': 'Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Gaurav Jain, Roy Schwartz, Moshe Wasserblat, David Harel', 'link': 'https://arxiv.org/abs/2502.05202', 'abstract': 'Accelerating the inference of large language models (LLMs) is a critical challenge in generative AI. Speculative decoding (SD) methods offer substantial efficiency gains by generating multiple tokens using a single target forward pass. However, existing SD approaches require the drafter and target models to share the same vocabulary, thus limiting the pool of possible drafters, often necessitating the training of a drafter from scratch. We present three new SD methods that remove this shared-vocabulary constraint. All three methods preserve the target distribution (i.e., they are lossless) and work with off-the-shelf models without requiring additional training or modifications. Empirically, on summarization, programming, and long-context tasks, our algorithms achieve significant speedups over standard autoregressive decoding. By enabling any off-the-shelf model to serve as drafter and requiring no retraining, this work substantially broadens the applicability of the SD framework in practice.', 'abstract_zh': '加速大型语言模型的推理是生成型AI中的一个重要挑战。推测解码（SD）方法通过单次目标前向传播生成多个令牌，从而提供了显著的效率增益。然而，现有的SD方法要求草稿模型和目标模型共享相同的词汇表，从而限制了可能的草稿模型的选择，通常需要从头训练一个草稿模型。我们提出了三种新的SD方法，消除了这一共享词汇表的限制。所有这些方法都保持了目标分布不变（即，它们是无损的），并且可以与即用型模型一起使用，无需额外训练或修改。实验结果显示，在摘要、编程和长上下文任务上，我们的算法在标准自回归解码方法上实现了显著的加速。通过使任何即用型模型均可作为草稿模型，并且不需要重新训练，这项工作显著扩展了推测解码框架在实践中的适用范围。', 'title_zh': '面向异构词汇的无损推测解码算法加速LLM推理'}
{'arxiv_id': 'arXiv:2502.05186', 'title': 'Multimodal Stock Price Prediction', 'authors': 'Furkan Karadaş, Bahaeddin Eravcı, Ahmet Murat Özbayoğlu', 'link': 'https://arxiv.org/abs/2502.05186', 'abstract': "In an era where financial markets are heavily influenced by many static and dynamic factors, it has become increasingly critical to carefully integrate diverse data sources with machine learning for accurate stock price prediction. This paper explores a multimodal machine learning approach for stock price prediction by combining data from diverse sources, including traditional financial metrics, tweets, and news articles. We capture real-time market dynamics and investor mood through sentiment analysis on these textual data using both ChatGPT-4o and FinBERT models. We look at how these integrated data streams augment predictions made with a standard Long Short-Term Memory (LSTM model) to illustrate the extent of performance gains. Our study's results indicate that incorporating the mentioned data sources considerably increases the forecast effectiveness of the reference model by up to 5%. We also provide insights into the individual and combined predictive capacities of these modalities, highlighting the substantial impact of incorporating sentiment analysis from tweets and news articles. This research offers a systematic and effective framework for applying multimodal data analytics techniques in financial time series forecasting that provides a new view for investors to leverage data for decision-making.", 'abstract_zh': '在金融市场受到众多静态和动态因素强烈影响的时代，准确整合多种数据源并结合机器学习进行股票价格预测变得日益关键。本文探讨了一种基于多模态机器学习的股票价格预测方法，综合了传统财务指标、推特和新闻文章等多种数据源。通过使用ChatGPT-4o和FinBERT模型对这些文本数据进行情感分析，我们捕捉实时的市场动态和投资者情绪。我们研究这些集成数据流如何增强标准长短期记忆（LSTM）模型的预测能力，并展示了性能提升的程度。研究结果表明，整合提及的数据源可将参考模型的预测效果提高多达5%。我们还分析了这些模态的单独及综合预测能力，强调了从推特和新闻文章中进行情感分析的重要性。本文提供了一种系统且有效的方法，用于在金融时间序列预测中应用多模态数据分析技术，为投资者利用数据进行决策提供了新的视角。', 'title_zh': '多模态股票价格预测'}
{'arxiv_id': 'arXiv:2502.05181', 'title': 'Enhancing Team Diversity with Generative AI: A Novel Project Management Framework', 'authors': 'Johnny Chan, Yuming Li', 'link': 'https://arxiv.org/abs/2502.05181', 'abstract': "This research-in-progress paper presents a new project management framework that utilises GenAI technology. The framework is designed to address the common challenge of uniform team compositions in academic and research project teams, particularly in universities and research institutions. It does so by integrating sociologically identified patterns of successful team member personalities and roles, using GenAI agents to fill gaps in team dynamics. This approach adds an additional layer of analysis to conventional project management processes by evaluating team members' personalities and roles and employing GenAI agents, fine-tuned on personality datasets, to fill specific team roles. Our initial experiments have shown improvements in the model's ability to understand and process personality traits, suggesting the potential effectiveness of GenAI teammates in real-world project settings. This paper aims to explore the practical application of AI in enhancing team diversity and project management", 'abstract_zh': '正在进行的研究论文：利用GenAI技术的新项目管理框架及其在增强团队多样性和项目管理中的应用', 'title_zh': '利用生成式AI增强团队多样性：一种新型项目管理框架'}
{'arxiv_id': 'arXiv:2410.13772', 'title': 'Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?', 'authors': 'Argyrios Gerogiannis, Yu-Han Huang, Venugopal V. Veeravalli', 'link': 'https://arxiv.org/abs/2410.13772', 'abstract': "We study the problem of Non-Stationary Reinforcement Learning (NS-RL) without prior knowledge about the system's non-stationarity. A state-of-the-art, black-box algorithm, known as MASTER, is considered, with a focus on identifying the conditions under which it can achieve its stated goals. Specifically, we prove that MASTER's non-stationarity detection mechanism is not triggered for practical choices of horizon, leading to performance akin to a random restarting algorithm. Moreover, we show that the regret bound for MASTER, while being order optimal, stays above the worst-case linear regret until unreasonably large values of the horizon. To validate these observations, MASTER is tested for the special case of piecewise stationary multi-armed bandits, along with methods that employ random restarting, and others that use quickest change detection to restart. A simple, order optimal random restarting algorithm, that has prior knowledge of the non-stationarity is proposed as a baseline. The behavior of the MASTER algorithm is validated in simulations, and it is shown that methods employing quickest change detection are more robust and consistently outperform MASTER and other random restarting approaches.", 'abstract_zh': '我们研究了在不了解系统非平稳性先验知识情况下的非平稳强化学习（NS-RL）问题。考虑了一个先进的黑盒算法MASTER，并侧重于确定其能够实现目标的条件。具体来说，我们证明了对于实际的选择，MASTER的非平稳性检测机制未被触发，导致其性能类似于随机重启算法。此外，我们表明，MASTER的遗憾界虽然是次优的，但在不合理大的时限值之前仍然高于最坏情况的线性遗憾界。为了验证这些观察结果，MASTER在部分平稳多臂 bandit 的特殊情况以及使用随机重启和使用快速变化检测重启的方法下进行了测试。我们提出了一种简单的具有非平稳性先验知识的次优随机重启基线算法。通过仿真验证了MASTER算法的行为，并展示了使用快速变化检测的方法比MASTER和其他随机重启方法更具稳健性且表现更优。', 'title_zh': '先验无约束的黑箱非平稳强化学习可行吗？'}
{'arxiv_id': 'arXiv:2301.06943', 'title': 'Self-supervised Domain Adaptation for Breaking the Limits of Low-quality Fundus Image Quality Enhancement', 'authors': 'Qingshan Hou, Peng Cao, Jiaqi Wang, Xiaoli Liu, Jinzhu Yang, Osmar R. Zaiane', 'link': 'https://arxiv.org/abs/2301.06943', 'abstract': 'Retinal fundus images have been applied for the diagnosis and screening of eye diseases, such as Diabetic Retinopathy (DR) or Diabetic Macular Edema (DME). However, both low-quality fundus images and style inconsistency potentially increase uncertainty in the diagnosis of fundus disease and even lead to misdiagnosis by ophthalmologists. Most of the existing image enhancement methods mainly focus on improving the image quality by leveraging the guidance of high-quality images, which is difficult to be collected in medical applications. In this paper, we tackle image quality enhancement in a fully unsupervised setting, i.e., neither paired images nor high-quality images. To this end, we explore the potential of the self-supervised task for improving the quality of fundus images without the requirement of high-quality reference images. Specifically, we construct multiple patch-wise domains via an auxiliary pre-trained quality assessment network and a style clustering. To achieve robust low-quality image enhancement and address style inconsistency, we formulate two self-supervised domain adaptation tasks to disentangle the features of image content, low-quality factor and style information by exploring intrinsic supervision signals within the low-quality images. Extensive experiments are conducted on EyeQ and Messidor datasets, and results show that our DASQE method achieves new state-of-the-art performance when only low-quality images are available.', 'abstract_zh': 'Retinal fundus图像在眼科疾病诊断和筛查中的应用，如糖尿病视网膜病变(DR)或糖尿病黄斑水肿(DME)，但由于低质量的视网膜图像和风格不一致性可能会增加视网膜疾病诊断的不确定性，甚至导致眼科医生误诊。现有的大多数图像增强方法主要通过高质量图像的指导来提高图像质量，但在医疗应用中难以收集高质量图像。本文在无监督环境下解决图像质量增强问题，即既没有配对图像，也没有高质量图像。为此，我们探索自监督任务在无需高质量参考图像的情况下提高视网膜图像质量的潜力。具体地，我们通过辅助预训练的质量评估网络和风格聚类构建了多个 patches 级别的域。为了实现鲁棒的低质量图像增强并解决风格不一致性问题，我们制定了两个自监督域适应任务，通过探索低质量图像内的内在监督信号，将图像内容、低质量因素和风格信息分离。在EyeQ和Messidor数据集上进行的广泛实验表明，当仅有低质量图像可用时，我们的DASQE方法达到了新的性能最佳水平。', 'title_zh': '自我监督领域适应以突破低质量眼底图像质量增强的限制'}
