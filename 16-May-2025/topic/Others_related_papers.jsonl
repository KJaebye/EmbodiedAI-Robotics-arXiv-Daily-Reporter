{'arxiv_id': 'arXiv:2505.10542', 'title': 'AORRTC: Almost-Surely Asymptotically Optimal Planning with RRT-Connect', 'authors': 'Tyler Wilson, Wil Thomason, Zachary Kingston, Jonathan Gammell', 'link': 'https://arxiv.org/abs/2505.10542', 'abstract': 'Finding high-quality solutions quickly is an important objective in motion planning. This is especially true for high-degree-of-freedom robots. Satisficing planners have traditionally found feasible solutions quickly but provide no guarantees on their optimality, while almost-surely asymptotically optimal (a.s.a.o.) planners have probabilistic guarantees on their convergence towards an optimal solution but are more computationally expensive.\nThis paper uses the AO-x meta-algorithm to extend the satisficing RRT-Connect planner to optimal planning. The resulting Asymptotically Optimal RRT-Connect (AORRTC) finds initial solutions in similar times as RRT-Connect and uses any additional planning time to converge towards the optimal solution in an anytime manner. It is proven to be probabilistically complete and a.s.a.o.\nAORRTC was tested with the Panda (7 DoF) and Fetch (8 DoF) robotic arms on the MotionBenchMaker dataset. These experiments show that AORRTC finds initial solutions as fast as RRT-Connect and faster than the tested state-of-the-art a.s.a.o. algorithms while converging to better solutions faster. AORRTC finds solutions to difficult high-DoF planning problems in milliseconds where the other a.s.a.o. planners could not consistently find solutions in seconds. This performance was demonstrated both with and without single instruction/multiple data (SIMD) acceleration.', 'abstract_zh': '快速找到高质量解决方案是运动规划中的一个重要目标，尤其对于高自由度机器人而言。机会型规划器可以快速找到可行解，但不保证解的最优化；几乎肯定渐近最优（a.s.a.o.）规划器在概率上可以向最优解收敛，但计算成本更高。\n\n本文利用AO-x元算法将机会型RRT-Connect规划器扩展为最优规划器。由此产生的渐近最优RRT-Connect (AORRTC)可以在与RRT-Connect类似的时间内找到初始解，并利用额外的规划时间以任意时间的方式向最优解收敛。证明其具有概率完备性和几乎肯定渐近最优性。\n\nAORRTC在MotionBenchMaker数据集上使用Panda（7自由度）和Fetch（8自由度）机器人臂进行了测试。这些实验表明，AORRTC可以像RRT-Connect一样快速找到初始解，并且在收敛到更好解时更快。AORRTC可以在毫秒内找到困难的高自由度规划问题的解，而其他几乎肯定渐近最优规划器在数秒内无法一致地找到解。无论是否有单指令多数据（SIMD）加速，这种性能都得到了验证。', 'title_zh': 'AORRTC：几乎 surely 趋近最优的 RRT-Connect 规划算法'}
{'arxiv_id': 'arXiv:2505.10151', 'title': 'Training People to Reward Robots', 'authors': 'Endong Sun, Yuqing Zhu, Matthew Howard', 'link': 'https://arxiv.org/abs/2505.10151', 'abstract': 'Learning from demonstration (LfD) is a technique that allows expert teachers to teach task-oriented skills to robotic systems. However, the most effective way of guiding novice teachers to approach expert-level demonstrations quantitatively for specific teaching tasks remains an open question. To this end, this paper investigates the use of machine teaching (MT) to guide novice teachers to improve their teaching skills based on reinforcement learning from demonstration (RLfD). The paper reports an experiment in which novices receive MT-derived guidance to train their ability to teach a given motor skill with only 8 demonstrations and generalise this to previously unseen ones. Results indicate that the MT-guidance not only enhances robot learning performance by 89% on the training skill but also causes a 70% improvement in robot learning performance on skills not seen by subjects during training. These findings highlight the effectiveness of MT-guidance in upskilling human teaching behaviours, ultimately improving demonstration quality in RLfD.', 'abstract_zh': '基于机器教学的示谱方法提升新老师的教学技能：强化学习从演示中指导初学者教师的行为分析', 'title_zh': '训练人类奖励机器人'}
{'arxiv_id': 'arXiv:2505.10018', 'title': 'LEMON-Mapping: Loop-Enhanced Large-Scale Multi-Session Point Cloud Merging and Optimization for Globally Consistent Mapping', 'authors': 'Lijie Wang, Xiaoyi Zhong, Ziyi Xu, Kaixin Chai, Anke Zhao, Tianyu Zhao, Qianhao Wang, Fei Gao', 'link': 'https://arxiv.org/abs/2505.10018', 'abstract': 'With the rapid development of robotics, multi-robot collaboration has become critical and challenging. One key problem is integrating data from multiple robots to build a globally consistent and accurate map for robust cooperation and precise localization. While traditional multi-robot pose graph optimization (PGO) maintains basic global consistency, it focuses primarily on pose optimization and ignores the geometric structure of the map. Moreover, PGO only uses loop closure as a constraint between two nodes, failing to fully exploit its capability to maintaining local consistency of multi-robot maps. Therefore, PGO-based multi-robot mapping methods often suffer from serious map divergence and blur, especially in regions with overlapping submaps. To address this issue, we propose Lemon-Mapping, a loop-enhanced framework for large-scale multi-session point cloud map fusion and optimization, which reasonably utilizes loop closure and improves the geometric quality of the map. We re-examine the role of loops for multi-robot mapping and introduce three key innovations. First, we develop a robust loop processing mechanism that effectively rejects outliers and a novel loop recall strategy to recover mistakenly removed loops. Second, we introduce a spatial bundle adjustment method for multi-robot maps that significantly reduces the divergence in overlapping regions and eliminates map blur. Third, we design a PGO strategy that leverages the refined constraints of bundle adjustment to extend the local accuracy to the global map. We validate our framework on several public datasets and a self-collected dataset. Experimental results demonstrate that our method outperforms traditional map merging approaches in terms of mapping accuracy and reduction of map divergence. Scalability experiments also demonstrate the strong capability of our framework to handle scenarios involving numerous robots.', 'abstract_zh': '基于循环增强的大规模多会话点云地图融合与优化框架', 'title_zh': 'LEMON-Mapping：循环增强的大规模多会话点云合并与优化以实现全局一致的地图构建'}
{'arxiv_id': 'arXiv:2505.09887', 'title': 'Unsupervised Radar Point Cloud Enhancement via Arbitrary LiDAR Guided Diffusion Prior', 'authors': 'Yanlong Yang, Jianan Liu, Guanxiong Luo, Hao Li, Euijoon Ahn, Mostafa Rahimi Azghadi, Tao Huang', 'link': 'https://arxiv.org/abs/2505.09887', 'abstract': "In industrial automation, radar is a critical sensor in machine perception. However, the angular resolution of radar is inherently limited by the Rayleigh criterion, which depends on both the radar's operating wavelength and the effective aperture of its antenna this http URL overcome these hardware-imposed limitations, recent neural network-based methods have leveraged high-resolution LiDAR data, paired with radar measurements, during training to enhance radar point cloud resolution. While effective, these approaches require extensive paired datasets, which are costly to acquire and prone to calibration error. These challenges motivate the need for methods that can improve radar resolution without relying on paired high-resolution ground-truth data. Here, we introduce an unsupervised radar points enhancement algorithm that employs an arbitrary LiDAR-guided diffusion model as a prior without the need for paired training data. Specifically, our approach formulates radar angle estimation recovery as an inverse problem and incorporates prior knowledge through a diffusion model with arbitrary LiDAR domain knowledge. Experimental results demonstrate that our method attains high fidelity and low noise performance compared to traditional regularization techniques. Additionally, compared to paired training methods, it not only achieves comparable performance but also offers improved generalization capability. To our knowledge, this is the first approach that enhances radar points output by integrating prior knowledge via a diffusion model rather than relying on paired training data. Our code is available at this https URL.", 'abstract_zh': '工业自动化中，雷达是机器感知中的关键传感器。然而，雷达的角分辨率受瑞利准则的固有限制，取决于雷达的工作波长和天线的有效孔径。为了克服这些由硬件引起的限制，近年来基于神经网络的方法在训练中结合了高分辨率LiDAR数据和雷达测量数据，以提升雷达点云分辨率。虽然这些方法有效，但它们需要大量的配对数据集，这些数据集获取成本高且容易出现校准误差。这些问题推动了需要不依赖配对高分辨率真实数据的方法来提高雷达分辨率的需求。在这里，我们引入了一种无需配对训练数据的无监督雷达点增强算法，该算法采用任意LiDAR引导的扩散模型作为先验。具体而言，我们的方法将雷达角度估计恢复视为一个逆问题，并通过具有任意LiDAR领域知识的扩散模型融入先验知识。实验结果表明，与传统的正则化技术相比，我们的方法具有更高的保真度和更低的噪声性能。此外，与配对训练方法相比，它不仅实现了可比的性能，还提高了泛化能力。据我们所知，这是第一个通过扩散模型整合先验知识来提升雷达点输出的方法，而不是依赖配对训练数据。我们的代码可在以下链接获取：this https URL。', 'title_zh': '基于任意LiDAR引导扩散先验的无监督雷达点云增强'}
{'arxiv_id': 'arXiv:2505.10020', 'title': 'Threshold Strategy for Leaking Corner-Free Hamilton-Jacobi Reachability with Decomposed Computations', 'authors': 'Chong He, Mugilan Mariappan, Keval Vora, Mo Chen', 'link': 'https://arxiv.org/abs/2505.10020', 'abstract': 'Hamilton-Jacobi (HJ) Reachability is widely used to compute value functions for states satisfying specific control objectives. However, it becomes intractable for high-dimensional problems due to the curse of dimensionality. Dimensionality reduction approaches are essential for mitigating this challenge, whereas they could introduce the ``leaking corner issue", leading to inaccuracies in the results. In this paper, we define the ``leaking corner issue" in terms of value functions, propose and prove a necessary condition for its occurrence. We then use these theoretical contributions to introduce a new local updating method that efficiently corrects inaccurate value functions while maintaining the computational efficiency of the dimensionality reduction approaches. We demonstrate the effectiveness of our method through numerical simulations. Although we validate our method with the self-contained subsystem decomposition (SCSD), our approach is applicable to other dimensionality reduction techniques that introduce the ``leaking corners".', 'abstract_zh': 'Hamilton-Jacobi (HJ)可达性广泛用于计算满足特定控制目标的状态的价值函数。然而，由于维数灾难，它在高维问题上变得不可行。降维方法对于缓解这一挑战至关重要，但可能会引入“泄露角问题”，导致结果不准确。在本文中，我们从价值函数的角度定义了“泄露角问题”，提出了其发生的一个必要条件，并进行了证明。然后，我们利用这些理论贡献引入了一种新的局部更新方法，该方法能够高效地修正不准确的价值函数，同时保持降维方法的计算效率。我们通过数值模拟验证了方法的有效性。尽管我们使用自包含子系统分解（SCSD）验证了该方法，但我们的方法适用于其他引入“泄露角问题”的降维技术。', 'title_zh': '泄漏角-free哈密尔顿-雅可比可达性分解计算的门槛策略'}
{'arxiv_id': 'arXiv:2505.09988', 'title': 'Provably safe and human-like car-following behaviors: Part 2. A parsimonious multi-phase model with projected braking', 'authors': 'Wen-Long Jin', 'link': 'https://arxiv.org/abs/2505.09988', 'abstract': "Ensuring safe and human-like trajectory planning for automated vehicles amidst real-world uncertainties remains a critical challenge. While existing car-following models often struggle to consistently provide rigorous safety proofs alongside human-like acceleration and deceleration patterns, we introduce a novel multi-phase projection-based car-following model. This model is designed to balance safety and performance by incorporating bounded acceleration and deceleration rates while emulating key human driving principles. Building upon a foundation of fundamental driving principles and a multi-phase dynamical systems analysis (detailed in Part 1 of this study \\citep{jin2025WA20-02_Part1}), we first highlight the limitations of extending standard models like Newell's with simple bounded deceleration. Inspired by human drivers' anticipatory behavior, we mathematically define and analyze projected braking profiles for both leader and follower vehicles, establishing safety criteria and new phase definitions based on the projected braking lead-vehicle problem. The proposed parsimonious model combines an extended Newell's model for nominal driving with a new control law for scenarios requiring projected braking. Using speed-spacing phase plane analysis, we provide rigorous mathematical proofs of the model's adherence to defined safe and human-like driving principles, including collision-free operation, bounded deceleration, and acceptable safe stopping distance, under reasonable initial conditions. Numerical simulations validate the model's superior performance in achieving both safety and human-like braking profiles for the stationary lead-vehicle problem. Finally, we discuss the model's implications and future research directions.", 'abstract_zh': '确保在现实世界不确定性中的自动驾驶车辆安全且拟人化的轨迹规划仍然是一个关键挑战。尽管现有的车跟随模型往往难以一致地提供严格的安全证明同时保持拟人化的加减速模式，我们介绍了基于多阶段投影的新型车跟随模型。该模型旨在通过引入有界加减速率并模拟关键的人类驾驶原则来平衡安全与性能。基于基本驾驶原则和多阶段动力学系统分析（详见本研究第1部分 \\citep{jin2025WA20-02_Part1}），我们首先指出将标准模型如Newell模型简单地扩展到带有限制的减速行为时的局限性。借鉴人类驾驶员的预见性行为，我们从数学上定义和分析了领导者和跟随者车辆的投影制动廓线，并基于投影制动前车问题建立了新的安全准则和阶段定义。提出的简约模型结合了扩展的Newell模型用于常规驾驶，并引入了新的控制律以应对需要投影制动的场景。利用速度-间距相平面分析，我们提供了关于该模型如何在合理初始条件下严格遵守定义的安全和拟人化驾驶原则（包括无碰撞运行、有界的减速和可接受的安全停车距离）的数学证明。数值仿真实验证了该模型在解决静止前车问题时在安全性和拟人化制动轮廓方面的优越性能。最后，我们讨论了模型的含义及其未来的研究方向。', 'title_zh': '可验证安全且类人的跟随行为：第2部分——一种精简的多阶段模型及其制动力投影方法'}
{'arxiv_id': 'arXiv:2505.09987', 'title': 'Provably safe and human-like car-following behaviors: Part 1. Analysis of phases and dynamics in standard models', 'authors': 'Wen-Long Jin', 'link': 'https://arxiv.org/abs/2505.09987', 'abstract': "Trajectory planning is essential for ensuring safe driving in the face of uncertainties related to communication, sensing, and dynamic factors such as weather, road conditions, policies, and other road users. Existing car-following models often lack rigorous safety proofs and the ability to replicate human-like driving behaviors consistently. This article applies multi-phase dynamical systems analysis to well-known car-following models to highlight the characteristics and limitations of existing approaches. We begin by formulating fundamental principles for safe and human-like car-following behaviors, which include zeroth-order principles for comfort and minimum jam spacings, first-order principles for speeds and time gaps, and second-order principles for comfort acceleration/deceleration bounds as well as braking profiles. From a set of these zeroth- and first-order principles, we derive Newell's simplified car-following model. Subsequently, we analyze phases within the speed-spacing plane for the stationary lead-vehicle problem in Newell's model and its extensions, which incorporate both bounded acceleration and deceleration. We then analyze the performance of the Intelligent Driver Model and the Gipps model. Through this analysis, we highlight the limitations of these models with respect to some of the aforementioned principles. Numerical simulations and empirical observations validate the theoretical insights. Finally, we discuss future research directions to further integrate safety, human-like behaviors, and vehicular automation in car-following models, which are addressed in Part 2 of this study \\citep{jin2025WA20-02_Part2}, where we develop a novel multi-phase projection-based car-following model that addresses the limitations identified here.", 'abstract_zh': '轨迹规划对于在通信、感知以及天气、道路条件、政策及其他道路使用者等动态因素带来的不确定性中确保安全驾驶至关重要。现有的跟随车辆模型往往缺乏严格的 safety 证明，并且不能一致地复制人类驾驶行为。本文应用多阶段动力系统分析方法对现有的跟随车辆模型进行研究，以突显现有方法的特点和局限性。我们首先提出了安全和类似人类的跟随车辆行为的基本原则，包括舒适性零阶原则和最小堵塞距离，速度和时间间隔的一阶原则，以及舒适加速度/减速度的边界和制动轨迹的二阶原则。基于这些零阶和一阶原则，我们推导出简化的新ell跟随车辆模型。随后，我们分析了新ell模型及其扩展版本在速度-间距平面上的各个阶段，这些扩展版本同时包含了有界加速度和减速度。接着，我们分析了智能驾驶模型和Gipps模型的性能。通过这些分析，我们指出了这些模型在某些基本原则方面的局限性。数值仿真和实证观察验证了理论洞见。最后，我们讨论了未来的研究方向以进一步将安全、类似人类的行为和车辆自动化整合到跟随车辆模型中，这些问题将在本文的第二部分［1］中详细讨论，在那里我们开发了一种新型多阶段投影跟随车辆模型，以解决本文中指出的限制。', 'title_zh': '可验证的安全且类人的跟随行为：标准模型中的相位与动力学分析（第1部分）'}
{'arxiv_id': 'arXiv:2505.09737', 'title': 'General Dynamic Goal Recognition', 'authors': 'Osher Elhadad, Reuth Mirsky', 'link': 'https://arxiv.org/abs/2505.09737', 'abstract': "Understanding an agent's intent through its behavior is essential in human-robot interaction, interactive AI systems, and multi-agent collaborations. This task, known as Goal Recognition (GR), poses significant challenges in dynamic environments where goals are numerous and constantly evolving. Traditional GR methods, designed for a predefined set of goals, often struggle to adapt to these dynamic scenarios. To address this limitation, we introduce the General Dynamic GR problem - a broader definition of GR - aimed at enabling real-time GR systems and fostering further research in this area. Expanding on this foundation, this paper employs a model-free goal-conditioned RL approach to enable fast adaptation for GR across various changing tasks.", 'abstract_zh': '通过行为理解代理意图是人类与机器人交互、交互式AI系统和多代理协作中至关重要的任务。这种任务，即目标识别（GR），在目标众多且不断演变的动态环境中提出了重大挑战。传统的GR方法，针对预定义的目标集，往往难以适应这些动态场景。为了解决这一局限性，我们引入了通用动态GR问题——一种更广泛的GR定义，旨在使实时GR系统成为可能，并促进该领域进一步的研究。在此基础上，本文采用模型自由的目标条件RL方法，使GR在各种变化的任务中实现快速适应。', 'title_zh': '通用动态目标识别'}
{'arxiv_id': 'arXiv:2505.10399', 'title': 'Evaluating Model Explanations without Ground Truth', 'authors': 'Kaivalya Rawal, Zihao Fu, Eoin Delaney, Chris Russell', 'link': 'https://arxiv.org/abs/2505.10399', 'abstract': 'There can be many competing and contradictory explanations for a single model prediction, making it difficult to select which one to use. Current explanation evaluation frameworks measure quality by comparing against ideal "ground-truth" explanations, or by verifying model sensitivity to important inputs. We outline the limitations of these approaches, and propose three desirable principles to ground the future development of explanation evaluation strategies for local feature importance explanations. We propose a ground-truth Agnostic eXplanation Evaluation framework (AXE) for evaluating and comparing model explanations that satisfies these principles. Unlike prior approaches, AXE does not require access to ideal ground-truth explanations for comparison, or rely on model sensitivity - providing an independent measure of explanation quality. We verify AXE by comparing with baselines, and show how it can be used to detect explanation fairwashing. Our code is available at this https URL.', 'abstract_zh': '一种无偏见的真实标签无关特征重要性解释评价框架（AXE）', 'title_zh': '不基于ground truth评估模型解释'}
{'arxiv_id': 'arXiv:2505.10361', 'title': 'Plasticity as the Mirror of Empowerment', 'authors': 'David Abel, Michael Bowling, André Barreto, Will Dabney, Shi Dong, Steven Hansen, Anna Harutyunyan, Khimya Khetarpal, Clare Lyle, Razvan Pascanu, Georgios Piliouras, Doina Precup, Jonathan Richens, Mark Rowland, Tom Schaul, Satinder Singh', 'link': 'https://arxiv.org/abs/2505.10361', 'abstract': "Agents are minimally entities that are influenced by their past observations and act to influence future observations. This latter capacity is captured by empowerment, which has served as a vital framing concept across artificial intelligence and cognitive science. This former capacity, however, is equally foundational: In what ways, and to what extent, can an agent be influenced by what it observes? In this paper, we ground this concept in a universal agent-centric measure that we refer to as plasticity, and reveal a fundamental connection to empowerment. Following a set of desiderata on a suitable definition, we define plasticity using a new information-theoretic quantity we call the generalized directed information. We show that this new quantity strictly generalizes the directed information introduced by Massey (1990) while preserving all of its desirable properties. Our first finding is that plasticity is the mirror of empowerment: The agent's plasticity is identical to the empowerment of the environment, and vice versa. Our second finding establishes a tension between the plasticity and empowerment of an agent, suggesting that agent design needs to be mindful of both characteristics. We explore the implications of these findings, and suggest that plasticity, empowerment, and their relationship are essential to understanding agency.", 'abstract_zh': '代理是受过去观察影响并影响未来观察的最小实体。这种影响未来观察的能力由赋权捕获，已成为人工智能和认知科学中的关键框架概念。然而，受过去观察影响的能力同样基础：代理在多大程度上以及通过何种方式受其观察影响？在本文中，我们基于一个通用的代理中心测度来阐述这一概念，并将其称为塑性，并揭示了其与赋权的基本联系。按照适合定义的要求，我们使用一种新的信息论量度——广义定向信息来定义塑性。我们证明了这种新量度严格推广了Massey（1990）引入的定向信息，同时保留了其所有优良性质。我们的第一个发现是塑性是赋权的镜像：代理的塑性与其环境的赋权相同；反之亦然。我们的第二个发现表明代理的塑性和赋权之间存在紧张关系，这表明代理设计需要同时考虑这两种特性。我们探讨了这些发现的含义，并建议塑性、赋权及其关系对于理解代理性是至关重要的。', 'title_zh': '塑性作为赋能的镜子'}
{'arxiv_id': 'arXiv:2505.10328', 'title': 'A Comparative Study of SMT and MILP for the Nurse Rostering Problem', 'authors': 'Alvin Combrink, Stephie Do, Kristofer Bengtsson, Sabino Francesco Roselli, Martin Fabian', 'link': 'https://arxiv.org/abs/2505.10328', 'abstract': 'The effects of personnel scheduling on the quality of care and working conditions for healthcare personnel have been thoroughly documented. However, the ever-present demand and large variation of constraints make healthcare scheduling particularly challenging. This problem has been studied for decades, with limited research aimed at applying Satisfiability Modulo Theories (SMT). SMT has gained momentum within the formal verification community in the last decades, leading to the advancement of SMT solvers that have been shown to outperform standard mathematical programming techniques.\nIn this work, we propose generic constraint formulations that can model a wide range of real-world scheduling constraints. Then, the generic constraints are formulated as SMT and MILP problems and used to compare the respective state-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired rostering problems. Experimental results show how each solver excels for certain types of problems; the MILP solver generally performs better when the problem is highly constrained or infeasible, while the SMT solver performs better otherwise. On real-world inspired problems containing a more varied set of shifts and personnel, the SMT solver excels. Additionally, it was noted during experimentation that the SMT solver was more sensitive to the way the generic constraints were formulated, requiring careful consideration and experimentation to achieve better performance. We conclude that SMT-based methods present a promising avenue for future research within the domain of personnel scheduling.', 'abstract_zh': '人员排班对护理质量和工作人员条件的影响已被充分记录。然而，不断增长的需求和大量约束的变化使医疗服务排班尤为具有挑战性。这一问题已经研究了数十年，但主要集中在Satisfiability Modulo Theories (SMT)的应用研究上有限。过去几十年中，SMT在形式验证领域取得了显著进展，推动了SMT求解器的发展，这些求解器已被证明优于标准的数学规划技术。\n\n在本工作中，我们提出了一种通用的约束公式化方法，可以模型化一系列实际世界的排班约束。然后，这些通用约束被公式化为SMT和MILP问题，并用于在学术性和现实世界的排班问题上比较最先进的求解器Z3和Gurobi的表现。实验结果表明，每种求解器在不同类型的问题上各有优势；当问题高度受限或无解时，MILP求解器通常表现更好，而SMT求解器在其他情况下表现更佳。在包含更多种类轮班和人员的现实世界启发性问题上，SMT求解器表现更优。此外，在实验过程中发现，SMT求解器对通用约束的公式化方式更加敏感，需要仔细考虑和实验以获得更好的性能。我们得出结论，基于SMT的方法为人员排班领域的未来研究提供了富有前景的途径。', 'title_zh': 'SMT和MILP方法解决护士排班问题的比较研究'}
{'arxiv_id': 'arXiv:2505.10278', 'title': 'MASS: Multi-Agent Simulation Scaling for Portfolio Construction', 'authors': 'Taian Guo, Haiyang Shen, Jinsheng Huang, Zhengyang Mao, Junyu Luo, Zhuoru Chen, Xuhui Liu, Bingyu Xia, Luchen Liu, Yun Ma, Ming Zhang', 'link': 'https://arxiv.org/abs/2505.10278', 'abstract': 'LLM-based multi-agent has gained significant attention for their potential in simulation and enhancing performance. However, existing works are limited to pure simulations or are constrained by predefined workflows, restricting their applicability and effectiveness. In this paper, we introduce the Multi-Agent Scaling Simulation (MASS) for portfolio construction. MASS achieves stable and continuous excess returns by progressively increasing the number of agents for large-scale simulations to gain a superior understanding of the market and optimizing agent distribution end-to-end through a reverse optimization process, rather than relying on a fixed workflow. We demonstrate its superiority through performance experiments, ablation studies, backtesting experiments, experiments on updated data and stock pools, scaling experiments, parameter sensitivity experiments, and visualization experiments, conducted in comparison with 6 state-of-the-art baselines on 3 challenging A-share stock pools. We expect the paradigm established by MASS to expand to other tasks with similar characteristics. The implementation of MASS has been open-sourced at this https URL.', 'abstract_zh': '基于LLM的多智能体在模拟和提升性能方面的应用获得了广泛关注。然而，现有工作要么局限于纯粹的模拟，要么受限于预定义的工作流程，限制了其适用性和有效性。本文介绍了用于投资组合构建的多智能体扩展仿真（MASS）。MASS通过逐步增加智能体的数量进行大规模仿真，从而获得对市场的深刻理解，并通过逆优化过程端到端优化智能体分布，而非依赖固定的工作流程。我们通过性能实验、消融研究、回测实验、更新数据和股票池实验、扩展实验、参数灵敏度实验和可视化实验，与3个具有挑战性的A股股票池的6个先进基线进行了比较，展示了其优越性。我们期望由MASS建立的范式能够扩展到其他具有类似特征的任务中。MASS的实现已开源，地址请见附注。', 'title_zh': 'MASS：多代理仿真扩展在投资组合构建中的应用'}
{'arxiv_id': 'arXiv:2505.10188', 'title': 'A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support', 'authors': 'Felix Liedeker, Olivia Sanchez-Graillet, Moana Seidler, Christian Brandt, Jörg Wellmer, Philipp Cimiano', 'link': 'https://arxiv.org/abs/2505.10188', 'abstract': 'As the field of healthcare increasingly adopts artificial intelligence, it becomes important to understand which types of explanations increase transparency and empower users to develop confidence and trust in the predictions made by machine learning (ML) systems. In shared decision-making scenarios where doctors cooperate with ML systems to reach an appropriate decision, establishing mutual trust is crucial. In this paper, we explore different approaches to generating explanations in eXplainable AI (XAI) and make their underlying arguments explicit so that they can be evaluated by medical experts. In particular, we present the findings of a user study conducted with physicians to investigate their perceptions of various types of AI-generated explanations in the context of diagnostic decision support. The study aims to identify the most effective and useful explanations that enhance the diagnostic process. In the study, medical doctors filled out a survey to assess different types of explanations. Further, an interview was carried out post-survey to gain qualitative insights on the requirements of explanations incorporated in diagnostic decision support. Overall, the insights gained from this study contribute to understanding the types of explanations that are most effective.', 'abstract_zh': '随着医疗领域越来越多地采用人工智能，理解哪些类型的解释能增加透明度并让用户在信任机器学习（ML）系统预测方面建立信心和信任变得至关重要。在医生与ML系统合作以达成适当决策的共同决策场景中，建立互信至关重要。本文探讨了可解释人工智能（XAI）中生成不同解释的方法，并使其背后的论点明确，以便医学专家进行评估。特别地，我们基于与医生进行的一项用户研究，调查他们在诊断决策支持背景下对不同类型的AI生成解释的看法，旨在识别最有效的和最有用的解释，以提高诊断过程。在研究中，医生填写了一份调查问卷来评估不同类型解释，并在问卷后进行访谈以获取关于诊断决策支持中所需解释的定性见解。总体而言，本研究获得的见解有助于理解最有效的解释类型。', 'title_zh': '用户研究评价论辩性解释在诊断决策支持中的效果'}
{'arxiv_id': 'arXiv:2505.10093', 'title': 'From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI', 'authors': 'Hsuan-Lei Shao', 'link': 'https://arxiv.org/abs/2505.10093', 'abstract': 'Taiwanese China Studies (CS) has developed into a rich, interdisciplinary research field shaped by the unique geopolitical position and long standing academic engagement with Mainland China. This study responds to the growing need to systematically revisit and reorganize decades of Taiwan based CS scholarship by proposing an AI assisted approach that transforms unstructured academic texts into structured, interactive knowledge representations. We apply generative AI (GAI) techniques and large language models (LLMs) to extract and standardize entity relation triples from 1,367 peer reviewed CS articles published between 1996 and 2019. These triples are then visualized through a lightweight this http URL based system, forming the foundation of a domain specific knowledge graph and vector database for the field. This infrastructure allows users to explore conceptual nodes and semantic relationships across the corpus, revealing previously uncharted intellectual trajectories, thematic clusters, and research gaps. By decomposing textual content into graph structured knowledge units, our system enables a paradigm shift from linear text consumption to network based knowledge navigation. In doing so, it enhances scholarly access to CS literature while offering a scalable, data driven alternative to traditional ontology construction. This work not only demonstrates how generative AI can augment area studies and digital humanities but also highlights its potential to support a reimagined scholarly infrastructure for regional knowledge systems.', 'abstract_zh': '台湾中国研究（CS）已成为一个丰富且跨学科的研究领域，受到独特的地缘政治位置和长期对大陆中国研究的学术参与的塑造。本研究针对日益增长的需求，系统回顾和重新组织20世纪末以来基于台湾的CS研究成果，提出了一种基于AI的帮助方法，将不结构化的学术文本转化为结构化、互动的知识表示。我们运用生成式AI技术和大规模语言模型，从1996年至2019年发表的1,367篇经过同行评审的CS文章中提取并标准化实体关系三元组。这些三元组通过基于轻量级This\xa0httpURL系统进行可视化，成为该领域专用知识图谱和向量数据库的基础。该基础设施使用户能够探索语料库中的概念节点和语义关系，揭示先前未被发现的学术轨迹、主题集群和研究空白。通过将文本内容分解为图形结构化的知识单元，我们的系统实现了从线性文本消费到基于网络的知识导航的范式转变。这不仅增强了学者对CS文献的访问，还提供了一种可扩展的数据驱动替代方案，用于传统的本体构建。本工作不仅展示了生成式AI如何增强区域研究和数字人文的发展，还强调了其在支持重新构想的区域知识系统学术基础设施方面的作用。', 'title_zh': '从文本到网络：利用生成式AI构建基于台湾的中国研究知识图谱'}
{'arxiv_id': 'arXiv:2505.09923', 'title': '"There Is No Such Thing as a Dumb Question," But There Are Good Ones', 'authors': 'Minjung Shin, Donghyun Kim, Jeh-Kwang Ryu', 'link': 'https://arxiv.org/abs/2505.09923', 'abstract': 'Questioning has become increasingly crucial for both humans and artificial intelligence, yet there remains limited research comprehensively assessing question quality. In response, this study defines good questions and presents a systematic evaluation framework. We propose two key evaluation dimensions: appropriateness (sociolinguistic competence in context) and effectiveness (strategic competence in goal achievement). Based on these foundational dimensions, a rubric-based scoring system was developed. By incorporating dynamic contextual variables, our evaluation framework achieves structure and flexibility through semi-adaptive criteria. The methodology was validated using the CAUS and SQUARE datasets, demonstrating the ability of the framework to access both well-formed and problematic questions while adapting to varied contexts. As we establish a flexible and comprehensive framework for question evaluation, this study takes a significant step toward integrating questioning behavior with structured analytical methods grounded in the intrinsic nature of questioning.', 'abstract_zh': '对问题的质量进行质疑与人工智能日益成为关键，但全面评估问题质量的研究仍然有限。为此，本研究定义了优质问题并提出了一套系统化的评估框架。我们提出了两个核心评估维度：适切性（上下文中的社会语言能力）和有效性（目标达成的战略能力）。基于这两个基础维度，我们开发了一套基于评分等级的评分系统。通过纳入动态的上下文变量，我们的评估框架通过半自适应标准实现了结构与灵活性。该方法通过使用CAUS和SQUARE数据集进行了验证，展示了框架能够评估良好形成和存在问题的问题，并适应各种不同的上下文。通过建立一个灵活和全面的问题评价框架，本研究在将问题行为与根植于问题本质的结构化分析方法相结合方面迈出了重要一步。', 'title_zh': '“没有愚蠢的问题，但有好的问题。”'}
{'arxiv_id': 'arXiv:2505.09920', 'title': 'Offline Reinforcement Learning for Microgrid Voltage Regulation', 'authors': 'Shan Yang, Yongli Zhu', 'link': 'https://arxiv.org/abs/2505.09920', 'abstract': 'This paper presents a study on using different offline reinforcement learning algorithms for microgrid voltage regulation with solar power penetration. When environment interaction is unviable due to technical or safety reasons, the proposed approach can still obtain an applicable model through offline-style training on a previously collected dataset, lowering the negative impact of lacking online environment interactions. Experiment results on the IEEE 33-bus system demonstrate the feasibility and effectiveness of the proposed approach on different offline datasets, including the one with merely low-quality experience.', 'abstract_zh': '本文研究了使用不同的离线强化学习算法对含有太阳能渗透的微电网电压调节的应用。即使由于技术或安全原因无法进行环境交互，所提出的方法仍然可以通过之前收集的数据集进行离线风格的训练，从而获得一个适用的模型，减少缺乏在线环境交互的负面影响。针对IEEE 33节点系统进行的实验结果表明，所提出的方法在不同的离线数据集上具有可行性和有效性，包括仅包含低质量经验的数据集。', 'title_zh': '离线强化学习在微电网电压调节中的应用'}
{'arxiv_id': 'arXiv:2505.09755', 'title': 'Explainability Through Human-Centric Design for XAI in Lung Cancer Detection', 'authors': 'Amy Rafferty, Rishi Ramaesh, Ajitha Rajan', 'link': 'https://arxiv.org/abs/2505.09755', 'abstract': 'Deep learning models have shown promise in lung pathology detection from chest X-rays, but widespread clinical adoption remains limited due to opaque model decision-making. In prior work, we introduced ClinicXAI, a human-centric, expert-guided concept bottleneck model (CBM) designed for interpretable lung cancer diagnosis. We now extend that approach and present XpertXAI, a generalizable expert-driven model that preserves human-interpretable clinical concepts while scaling to detect multiple lung pathologies. Using a high-performing InceptionV3-based classifier and a public dataset of chest X-rays with radiology reports, we compare XpertXAI against leading post-hoc explainability methods and an unsupervised CBM, XCBs. We assess explanations through comparison with expert radiologist annotations and medical ground truth. Although XpertXAI is trained for multiple pathologies, our expert validation focuses on lung cancer. We find that existing techniques frequently fail to produce clinically meaningful explanations, omitting key diagnostic features and disagreeing with radiologist judgments. XpertXAI not only outperforms these baselines in predictive accuracy but also delivers concept-level explanations that better align with expert reasoning. While our focus remains on explainability in lung cancer detection, this work illustrates how human-centric model design can be effectively extended to broader diagnostic contexts - offering a scalable path toward clinically meaningful explainable AI in medical diagnostics.', 'abstract_zh': '深度学习模型在胸部X光片肺病理检测中展现了潜力，但由于模型决策透明度不足，临床广泛应用受限。我们先前引入了ClinicXAI，一种以人为中心、专家指导的概念瓶颈模型（CBM），旨在实现可解释的肺癌诊断。现在我们将这种方法扩展，并提出XpertXAI，这是一种通用的专家驱动模型，在保留可由人类解释的临床概念的同时，能够扩展到检测多种肺病理。使用高性能的InceptionV3分类器和胸部X光片及其放射学报告的公开数据集，我们将XpertXAI与领先的后验可解释性方法和一种无监督CBM XCBs进行比较。我们通过与专家放射科医生注释和医学真实情况进行比较来评估解释。尽管XpertXAI是为多种病理设计的，但我们的专家验证主要集中在肺癌。我们发现，现有的技术经常无法产生临床意义的解释，忽略了关键的诊断特征，并且与放射科医生的判断不符。XpertXAI不仅在预测准确性方面优于这些基准方法，而且在其概念层面的解释与专家推理更好地对齐。尽管我们的主要关注点仍然是肺癌检测的解释性，但这项工作展示了以人为中心的模型设计如何有效地扩展到更广泛的诊断上下文，为医疗诊断中的有意义的可解释AI提供可扩展的途径。', 'title_zh': '基于以人为本设计的可解释性在肺癌检测中的XAI解释ability通过以人为本设计在肺癌检测中的XAI'}
{'arxiv_id': 'arXiv:2505.09640', 'title': 'Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms', 'authors': 'Tomás Capdevielle, Santiago Cifuentes', 'link': 'https://arxiv.org/abs/2505.09640', 'abstract': 'Given a classification model and a prediction for some input, there are heuristic strategies for ranking features according to their importance in regard to the prediction. One common approach to this task is rooted in propositional logic and the notion of \\textit{sufficient reason}. Through this concept, the categories of relevant and necessary features were proposed in order to identify the crucial aspects of the input. This paper improves the existing techniques and algorithms for deciding which are the relevant and/or necessary features, showing in particular that necessity can be detected efficiently in complex models such as neural networks. We also generalize the notion of relevancy and study associated problems. Moreover, we present a new global notion (i.e. that intends to explain whether a feature is important for the behavior of the model in general, not depending on a particular input) of \\textit{usefulness} and prove that it is related to relevancy and necessity. Furthermore, we develop efficient algorithms for detecting it in decision trees and other more complex models, and experiment on three datasets to analyze its practical utility.', 'abstract_zh': '给定一个分类模型和某些输入的预测，存在启发式策略根据特征对于预测的重要性进行排序。这一任务的一种常见方法基于命题逻辑和“充足理由”的概念。通过这一概念，提出了相关和必需特征的类别，以识别输入的关键方面。本文改进了决定哪些特征是相关和/或必需的现有技术和算法，特别是在神经网络等复杂模型中高效检测必要性的方法。我们还推广了相关性的概念并研究了相关问题。此外，我们提出了一种新的全局概念（旨在解释一个特征是否对模型整体行为重要，而不依赖于特定输入）——效用，并证明其与相关性和必要性相关。我们还为决策树和其他更复杂模型开发了检测其效用的有效算法，并在三个数据集上进行实验以分析其实用性。', 'title_zh': '特征相关性、必要性和有用性：复杂性与算法'}
{'arxiv_id': 'arXiv:2505.09639', 'title': 'Study and improvement of search algorithms in two-players perfect information games', 'authors': 'Quentin Cohen-Solal', 'link': 'https://arxiv.org/abs/2505.09639', 'abstract': 'Games, in their mathematical sense, are everywhere (game industries, economics, defense, education, chemistry, biology, ...).Search algorithms in games are artificial intelligence methods for playing such games. Unfortunately, there is no study on these algorithms that evaluates the generality of their performance. We propose to address this gap in the case of two-player zero-sum games with perfect information. Furthermore, we propose a new search algorithm and we show that, for a short search time, it outperforms all studied algorithms on all games in this large experiment and that, for a medium search time, it outperforms all studied algorithms on 17 of the 22 studied games.', 'abstract_zh': '在完美信息的两人零和博弈中，游戏中的搜索算法是对这类游戏进行人工智能博弈的方法。遗憾的是，目前没有研究评估这些算法的一般性能。我们提出填补这一空白的方法，并提出一个新的搜索算法，在短时间搜索时，该算法在大规模实验中的所有测试游戏中均优于所有已研究的算法；在中时间搜索时，该算法在22个测试游戏中有17个游戏中优于所有已研究的算法。', 'title_zh': '两玩家完美信息博弈中搜索算法的研究与改进'}
{'arxiv_id': 'arXiv:2505.10551', 'title': 'Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data', 'authors': 'Yiwen Liu, Jessica Bader, Jae Myung Kim', 'link': 'https://arxiv.org/abs/2505.10551', 'abstract': "With the development of photorealistic diffusion models, models trained in part or fully on synthetic data achieve progressively better results. However, diffusion models still routinely generate images that would not exist in reality, such as a dog floating above the ground or with unrealistic texture artifacts. We define the concept of feasibility as whether attributes in a synthetic image could realistically exist in the real-world domain; synthetic images containing attributes that violate this criterion are considered infeasible. Intuitively, infeasible images are typically considered out-of-distribution; thus, training on such images is expected to hinder a model's ability to generalize to real-world data, and they should therefore be excluded from the training set whenever possible. However, does feasibility really matter? In this paper, we investigate whether enforcing feasibility is necessary when generating synthetic training data for CLIP-based classifiers, focusing on three target attributes: background, color, and texture. We introduce VariReal, a pipeline that minimally edits a given source image to include feasible or infeasible attributes given by the textual prompt generated by a large language model. Our experiments show that feasibility minimally affects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference in top-1 accuracy across three fine-grained datasets. Also, the attribute matters on whether the feasible/infeasible images adversarially influence the classification performance. Finally, mixing feasible and infeasible images in training datasets does not significantly impact performance compared to using purely feasible or infeasible datasets.", 'abstract_zh': '随着照片级真实感扩散模型的发展，部分或完全在合成数据上训练的模型逐渐取得更好的效果。然而，扩散模型仍然会生成现实中不存在的图像，如悬空在空中的狗或具有不现实的纹理伪影的图像。我们将可行性定义为合成图像中的属性是否能在现实世界域中现实地存在；包含违反这一标准的属性的合成图像被认为是不可行的。直观上，不可行的图像通常被认为是分布外的；因此，使用这类图像训练模型可能会阻碍其在现实世界数据上的泛化能力，尽可能地将它们从训练集中排除是有必要的。然而，可行性真的重要吗？在本文中，我们研究了在CLIP基于分类器生成合成训练数据时强制实施可行性的必要性，重点关注三个目标属性：背景、颜色和纹理。我们提出了VariReal框架，该框架根据大型语言模型生成的文本提示，对给定源图像进行最小编辑，以包含可行或不可行的属性。我们的实验表明，可行性对LoRA微调的CLIP性能的影响最小，顶1精度在三个细粒度数据集上的差异大多不到0.3%。此外，属性决定了可行/不可行图像是否对分类性能产生对抗性影响。最后，在训练数据集中混合可行和不可行的图像对性能的影响与仅使用完全可行或完全不可行的数据集相比，没有显著差异。', 'title_zh': '可行性重要吗？理解可行性对合成训练数据的影响'}
{'arxiv_id': 'arXiv:2505.10537', 'title': 'LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps', 'authors': "Filippo Olimpieri, Noemi Giustini, Andrea Lacava, Salvatore D'Oro, Tommaso Melodia, Francesca Cuomo", 'link': 'https://arxiv.org/abs/2505.10537', 'abstract': 'The O-RAN architecture is transforming cellular networks by adopting RAN softwarization and disaggregation concepts to enable data-driven monitoring and control of the network. Such management is enabled by RICs, which facilitate near-real-time and non-real-time network control through xApps and rApps. However, they face limitations, including latency overhead in data exchange between the RAN and RIC, restricting real-time monitoring, and the inability to access user plain data due to privacy and security constraints, hindering use cases like beamforming and spectrum classification. In this paper, we leverage the dApps concept to enable real-time RF spectrum classification with LibIQ, a novel library for RF signals that facilitates efficient spectrum monitoring and signal classification by providing functionalities to read I/Q samples as time-series, create datasets and visualize time-series data through plots and spectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to detect external RF signals, which are subsequently classified using a CNN inside the library. To achieve accurate spectrum analysis, we created an extensive dataset of time-series-based I/Q samples, representing distinct signal types captured using a custom dApp running on a 5G deployment over the Colosseum network emulator and an OTA testbed. We evaluate our model by deploying LibIQ in heterogeneous scenarios with varying center frequencies, time windows, and external RF signals. In real-time analysis, the model classifies the processed I/Q samples, achieving an average accuracy of approximately 97.8\\% in identifying signal types across all scenarios. We pledge to release both LibIQ and the dataset created as a publicly available framework upon acceptance.', 'abstract_zh': 'O-RAN架构通过采用RAN软化和分解概念，实现基于数据的网络监控和控制，这种管理通过RICs实现，RICs通过xApps和rApps实现接近实时和非实时网络控制。然而，它们面临数据交换延迟、限制实时监控以及因隐私和安全限制无法访问用户明文数据的挑战，阻碍了波束成型和频谱分类等用例。本文利用dApps概念，结合LibIQ这一新型射频信号库，实现射频频谱的实时分类，LibIQ提供读取I/Q样本作为时间序列、创建数据集和通过图表和频谱图可视化时间序列数据的功能。利用LibIQ，可以高效处理I/Q样本以检测外部射频信号，随后使用库内的CNN进行分类。为了实现准确的频谱分析，我们创建了一个包含时间序列I/Q样本的广泛数据集，这些样本是通过在Colosseum网络仿真器和OTA测试床上的5G部署中运行自定义dApp捕获的不同信号类型。我们通过在具有不同中心频率、时间窗口和外部射频信号的异构场景中部署LibIQ来评估我们的模型，在实时分析中，模型分类处理后的I/Q样本，所有场景中的平均准确率约为97.8%。论文接受后，我们将公开发布LibIQ和创建的数据集框架。', 'title_zh': 'LibIQ: 向O-RAN dApps中的实时频谱分类迈进'}
{'arxiv_id': 'arXiv:2505.10515', 'title': 'PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models', 'authors': 'Seongun Kim, Sol A Kim, Geonhyeong Kim, Enver Menadjiev, Chanwoo Lee, Seongwook Chung, Nari Kim, Jaesik Choi', 'link': 'https://arxiv.org/abs/2505.10515', 'abstract': "Recently, post hoc explanation methods have emerged to enhance model transparency by attributing model outputs to input features. However, these methods face challenges due to their specificity to certain neural network architectures and data modalities. Existing explainable artificial intelligence (XAI) frameworks have attempted to address these challenges but suffer from several limitations. These include limited flexibility to diverse model architectures and data modalities due to hard-coded implementations, a restricted number of supported XAI methods because of the requirements for layer-specific operations of attribution methods, and sub-optimal recommendations of explanations due to the lack of evaluation and optimization phases. Consequently, these limitations impede the adoption of XAI technology in real-world applications, making it difficult for practitioners to select the optimal explanation method for their domain. To address these limitations, we introduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data modalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI automatically detects model architectures, recommends applicable explanation methods, and optimizes hyperparameters for optimal explanations. We validate the framework's effectiveness through user surveys and showcase its versatility across various domains, including medicine and finance.", 'abstract_zh': "Recently, post hoc explanation methods have emerged to enhance model transparency by attributing model outputs to input features. However, these methods face challenges due to their specificity to certain neural network architectures and data modalities. Existing explainable artificial intelligence (XAI) frameworks have attempted to address these challenges but suffer from several limitations. These include limited flexibility to diverse model architectures and data modalities due to hard-coded implementations, a restricted number of supported XAI methods because of the requirements for layer-specific operations of attribution methods, and sub-optimal recommendations of explanations due to the lack of evaluation and optimization phases. Consequently, these limitations impede the adoption of XAI technology in real-world applications, making it difficult for practitioners to select the optimal explanation method for their domain. To address these limitations, we introduce **PnPXAI**, a universal XAI framework that supports diverse data modalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI automatically detects model architectures, recommends applicable explanation methods, and optimizes hyperparameters for optimal explanations. We validate the framework's effectiveness through user surveys and showcase its versatility across various domains, including medicine and finance。", 'title_zh': 'PnPXAI：一个跨模态和模型提供自动解释的通用XAI框架'}
{'arxiv_id': 'arXiv:2505.10457', 'title': 'SEAL: Searching Expandable Architectures for Incremental Learning', 'authors': 'Matteo Gambella, Vicente Javier Castro Solar, Manuel Roveri', 'link': 'https://arxiv.org/abs/2505.10457', 'abstract': 'Incremental learning is a machine learning paradigm where a model learns from a sequential stream of tasks. This setting poses a key challenge: balancing plasticity (learning new tasks) and stability (preserving past knowledge). Neural Architecture Search (NAS), a branch of AutoML, automates the design of the architecture of Deep Neural Networks and has shown success in static settings. However, existing NAS-based approaches to incremental learning often rely on expanding the model at every task, making them impractical in resource-constrained environments. In this work, we introduce SEAL, a NAS-based framework tailored for data-incremental learning, a scenario where disjoint data samples arrive sequentially and are not stored for future access. SEAL adapts the model structure dynamically by expanding it only when necessary, based on a capacity estimation metric. Stability is preserved through cross-distillation training after each expansion step. The NAS component jointly searches for both the architecture and the optimal expansion policy. Experiments across multiple benchmarks demonstrate that SEAL effectively reduces forgetting and enhances accuracy while maintaining a lower model size compared to prior methods. These results highlight the promise of combining NAS and selective expansion for efficient, adaptive learning in incremental scenarios.', 'abstract_zh': '增量学习是一种机器学习范式，其中模型从连续的任务流中学习。这一设置提出了一个关键挑战：平衡塑性（学习新任务）和稳定性（保留过往知识）。神经架构搜索（NAS），作为自动化机器学习（AutoML）的一个分支，自动化了深度神经网络架构的设计，并在静态设置中显示出成功。然而，现有的基于NAS的增量学习方法往往依赖于在每个任务中扩展模型，这使它们在资源受限的环境中不实用。在本文中，我们介绍了SEAL，一个针对数据增量学习的NAS基征框架，一种不存储未来访问所需离散数据样本的顺序到达场景。SEAL动态调整模型结构，仅在必要时扩展模型，基于容量估算指标。通过每次扩展后的交叉蒸馏训练保持稳定性。NAS组件联合搜索架构和最佳扩展策略。跨多个基准的实验结果表明，SEAL有效地减少了遗忘并提高了准确性，同时保持了较低的模型大小，优于先前的方法。这些结果突显了将NAS与选择性扩展结合用于增量场景中高效、自适应学习的潜力。', 'title_zh': 'SEAL: 搜索可扩展架构以实现增量学习'}
{'arxiv_id': 'arXiv:2505.10441', 'title': 'PIF: Anomaly detection via preference embedding', 'authors': 'Filippo Leveni, Luca Magri, Giacomo Boracchi, Cesare Alippi', 'link': 'https://arxiv.org/abs/2505.10441', 'abstract': 'We address the problem of detecting anomalies with respect to structured patterns. To this end, we conceive a novel anomaly detection method called PIF, that combines the advantages of adaptive isolation methods with the flexibility of preference embedding. Specifically, we propose to embed the data in a high dimensional space where an efficient tree-based method, PI-Forest, is employed to compute an anomaly score. Experiments on synthetic and real datasets demonstrate that PIF favorably compares with state-of-the-art anomaly detection techniques, and confirm that PI-Forest is better at measuring arbitrary distances and isolate points in the preference space.', 'abstract_zh': '我们提出了一种新的异常检测方法PIF，结合了自适应隔离方法的优势和偏好嵌入的灵活性，用于检测与结构化模式相关的异常。实验表明，PIF在合成和真实数据集上优于现有最先进的异常检测技术，并证实PI-Forest在偏好空间中测量任意距离和隔离点方面更具优势。', 'title_zh': 'PIF：基于偏好嵌入的异常检测'}
{'arxiv_id': 'arXiv:2505.10420', 'title': 'Learned Lightweight Smartphone ISP with Unpaired Data', 'authors': 'Andrei Arhire, Radu Timofte', 'link': 'https://arxiv.org/abs/2505.10420', 'abstract': 'The Image Signal Processor (ISP) is a fundamental component in modern smartphone cameras responsible for conversion of RAW sensor image data to RGB images with a strong focus on perceptual quality. Recent work highlights the potential of deep learning approaches and their ability to capture details with a quality increasingly close to that of professional cameras. A difficult and costly step when developing a learned ISP is the acquisition of pixel-wise aligned paired data that maps the raw captured by a smartphone camera sensor to high-quality reference images. In this work, we address this challenge by proposing a novel training method for a learnable ISP that eliminates the need for direct correspondences between raw images and ground-truth data with matching content. Our unpaired approach employs a multi-term loss function guided by adversarial training with multiple discriminators processing feature maps from pre-trained networks to maintain content structure while learning color and texture characteristics from the target RGB dataset. Using lightweight neural network architectures suitable for mobile devices as backbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm UltraISP datasets. Compared to paired training methods, our unpaired learning strategy shows strong potential and achieves high fidelity across multiple evaluation metrics. The code and pre-trained models are available at this https URL .', 'abstract_zh': '图像信号处理器（ISP）是现代智能手机相机中的基础组件，负责将RAW传感器图像数据转换为具有强烈感知质量的RGB图像。最近的研究强调了深度学习方法的潜力及其捕获与专业相机质量日益接近的细节的能力。在开发可学习的ISP时，一个困难且昂贵的步骤是获取像素级对齐的配对数据，将智能手机相机传感器捕获的RAW图像映射到高质量的参考图像。在本文中，我们提出了一种新的训练方法，用于可学习的ISP，该方法消除了直接对应RAW图像和匹配内容的ground-truth数据的需要。我们的非配对方法采用由多个判别器引导的多项损失函数，在预训练网络的特征图上进行训练，以保持内容结构并从目标RGB数据集中学习颜色和纹理特征。使用适合移动设备的轻量级神经网络架构作为骨干，我们在Zurich RAW to RGB和Fujifilm UltraISP数据集上评估了我们的方法。与配对训练方法相比，我们的非配对学习策略显示出强大的潜力，并在多个评估指标上实现了高保真度。代码和预训练模型可在以下链接获取。', 'title_zh': '基于无配对数据的轻量级智能手机ISP学习模型'}
{'arxiv_id': 'arXiv:2505.10394', 'title': 'Inconsistency Handling in DatalogMTL', 'authors': 'Meghyn Bienvenu, Camille Bourgaux, Atefe Khodadaditaghanaki', 'link': 'https://arxiv.org/abs/2505.10394', 'abstract': 'In this paper, we explore the issue of inconsistency handling in DatalogMTL, an extension of Datalog with metric temporal operators. Since facts are associated with time intervals, there are different manners to restore consistency when they contradict the rules, such as removing facts or modifying their time intervals. Our first contribution is the definition of relevant notions of conflicts (minimal explanations for inconsistency) and repairs (possible ways of restoring consistency) for this setting and the study of the properties of these notions and the associated inconsistency-tolerant semantics. Our second contribution is a data complexity analysis of the tasks of generating a single conflict / repair and query entailment under repair-based semantics.', 'abstract_zh': '本文探讨了基于度量时态操作符扩展Datalog的DatalogMTL中不一致处理的问题。由于事实与时间区间关联，当事实与规则矛盾时，可以通过删除事实或修改其时间区间等方式恢复一致性。我们的第一项贡献是对该背景下不一致冲突的相关概念（不一致的最小解释）和修复（恢复一致性的可能方式）进行了定义，并研究了这些概念及其相关容错语义的性质。我们的第二项贡献是对基于修复的语义下生成单个冲突/修复以及查询蕴含的数据复杂性进行了分析。', 'title_zh': 'DatalogMTL中的一致性处理'}
{'arxiv_id': 'arXiv:2505.10393', 'title': 'Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training', 'authors': 'Agustin Medina, Marcelo Arlego, Carlos A. Lamas', 'link': 'https://arxiv.org/abs/2505.10393', 'abstract': "We investigate the efficient learning of magnetic phases using artificial neural networks trained on synthetic data, combining computational simplicity with physics-informed strategies. Focusing on the diluted Ising model, which lacks an exact analytical solution, we explore two complementary approaches: a supervised classification using simple dense neural networks, and an unsupervised detection of phase transitions using convolutional autoencoders trained solely on idealized spin configurations.\nTo enhance model performance, we incorporate two key forms of physics-informed guidance. First, we exploit architectural biases which preferentially amplify features related to symmetry breaking. Second, we include training configurations that explicitly break $\\mathbb{Z}_2$ symmetry, reinforcing the network's ability to detect ordered phases. These mechanisms, acting in tandem, increase the network's sensitivity to phase structure even in the absence of explicit labels. We validate the machine learning predictions through comparison with direct numerical estimates of critical temperatures and percolation thresholds.\nOur results show that synthetic, structured, and computationally efficient training schemes can reveal physically meaningful phase boundaries, even in complex systems. This framework offers a low-cost and robust alternative to conventional methods, with potential applications in broader condensed matter and statistical physics contexts.", 'abstract_zh': '我们研究使用人工神经网络在合成数据上训练以高效学习磁性相位，结合计算简明性和物理启发式策略。聚焦于缺乏精确解析解的稀释伊辛模型，我们探索了两种互补的方法：监督分类，使用简单的密集神经网络，以及基于卷积自编码器的无监督相变检测，后者仅通过理想化的自旋配置进行训练。\n\n为了提升模型性能，我们引入了两种关键的物理启发式指导。首先，利用架构偏置以优先放大与对称破缺相关的特征。其次，包含打破$\\mathbb{Z}_2$对称性的训练配置，强化网络检测有序相的能力。这些机制协同作用，即使在没有明确标签的情况下，也能增加网络对相结构的敏感性。我们通过将机器学习预测与直接数值估计的临界温度和渗流阈值进行比较来验证这些结果。\n\n我们的研究结果表明，合成、结构化且计算高效的训练方案能在复杂系统中揭示物理意义的相界。该框架提供了一种成本低且稳健的替代传统方法的选择，具有在更广泛的凝聚态物理和统计物理背景下应用的潜力。', 'title_zh': '用合成数据和物理导向训练揭示磁性相态'}
{'arxiv_id': 'arXiv:2505.10392', 'title': 'Schreier-Coset Graph Propagation', 'authors': 'Aryan Mishra, Lizhen Lin', 'link': 'https://arxiv.org/abs/2505.10392', 'abstract': 'Graph Neural Networks (GNNs) offer a principled framework for learning over graph-structured data, yet their expressive capacity is often hindered by over-squashing, wherein information from distant nodes is compressed into fixed-size vectors. Existing solutions, including graph rewiring and bottleneck-resistant architectures such as Cayley and expander graphs, avoid this problem but introduce scalability bottlenecks. In particular, the Cayley graphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical properties, yet suffer from cubic node growth $O(n^3)$, leading to high memory usage. To address this, this work introduces Schrier-Coset Graph Propagation (SCGP), a group-theoretic augmentation method that enriches node features through Schreier-coset embeddings without altering the input graph topology. SCGP embeds bottleneck-free connectivity patterns into a compact feature space, improving long-range message passing while maintaining computational efficiency. Empirical evaluations across standard node and graph classification benchmarks demonstrate that SCGP achieves performance comparable to, or exceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits particular advantages in processing hierarchical and modular graph structures, offering reduced inference latency, improved scalability, and a low memory footprint, making it suitable for real-time and resource-constrained applications.', 'abstract_zh': '基于群论的Schreier-相伴图传播（SCGP）在图结构数据上的学习', 'title_zh': '舒尔-余子图传播'}
{'arxiv_id': 'arXiv:2505.10387', 'title': 'Multi-Agent Path Finding For Large Agents Is Intractable', 'authors': 'Artem Agafonov, Konstantin Yakovlev', 'link': 'https://arxiv.org/abs/2505.10387', 'abstract': "The multi-agent path finding (MAPF) problem asks to find a set of paths on a graph such that when synchronously following these paths the agents never encounter a conflict. In the most widespread MAPF formulation, the so-called Classical MAPF, the agents sizes are neglected and two types of conflicts are considered: occupying the same vertex or using the same edge at the same time step. Meanwhile in numerous practical applications, e.g. in robotics, taking into account the agents' sizes is vital to ensure that the MAPF solutions can be safely executed. Introducing large agents yields an additional type of conflict arising when one agent follows an edge and its body overlaps with the body of another agent that is actually not using this same edge (e.g. staying still at some distinct vertex of the graph). Until now it was not clear how harder the problem gets when such conflicts are to be considered while planning. Specifically, it was known that Classical MAPF problem on an undirected graph can be solved in polynomial time, however no complete polynomial-time algorithm was presented to solve MAPF with large agents. In this paper we, for the first time, establish that the latter problem is NP-hard and, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be presented. Our proof is based on the prevalent in the field technique of reducing the seminal 3SAT problem (which is known to be an NP-complete problem) to the problem at hand. In particular, for an arbitrary 3SAT formula we procedurally construct a dedicated graph with specific start and goal vertices and show that the given 3SAT formula is satisfiable iff the corresponding path finding instance has a solution.", 'abstract_zh': '多智能体路径寻找问题（MAPF）要求在同步遵循这些路径时，智能体之间不会发生冲突。在最广泛的MAPF形式化表述——所谓的经典MAPF中，忽略了智能体的大小，并考虑了两种类型的冲突：占据同一顶点或在同一时间步使用同一边。而在许多实际应用中，例如机器人领域，考虑智能体的大小是确保MAPF解能够安全执行的关键。引入大型智能体会产生一种额外的冲突，当一个智能体沿着某边移动并其身体与另一未使用该边而停留在图中不同顶点上的智能体的身体重叠时。直到现在，尚未明确考虑此类冲突的规划问题难度如何增加。特别地，已知经典MAPF问题在无向图上可以在多项式时间内求解，然而没有提出完整的多项式时间算法来解决具有大型智能体的MAPF问题。在本文中，我们首次证明了后者是NP难问题，因此不幸的是无法提供其多项式算法。我们的证明基于领域内常用的将经典3SAT问题（已知为NP完全问题）归约为目标问题的方法。具体地，对于任意的3SAT公式，我们逐步构造一个专用图，并展示给定的3SAT公式可满足当且仅当相应路径寻找实例有解。', 'title_zh': '大规模代理的多agent路径寻找问题是不可计算的'}
{'arxiv_id': 'arXiv:2505.10371', 'title': 'ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks', 'authors': 'Kai Sun, Peibo Duan, Levin Kuhlmann, Beilun Wang, Bin Zhang', 'link': 'https://arxiv.org/abs/2505.10371', 'abstract': 'The Spiking Neural Network (SNN) has drawn increasing attention for its energy-efficient, event-driven processing and biological plausibility. To train SNNs via backpropagation, surrogate gradients are used to approximate the non-differentiable spike function, but they only maintain nonzero derivatives within a narrow range of membrane potentials near the firing threshold, referred to as the surrogate gradient support width gamma. We identify a major challenge, termed the dilemma of gamma: a relatively large gamma leads to overactivation, characterized by excessive neuron firing, which in turn increases energy consumption, whereas a small gamma causes vanishing gradients and weakens temporal dependencies. To address this, we propose a temporal Inhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological inhibitory mechanisms. This model incorporates interconnected inhibitory units for membrane potential and current, effectively mitigating overactivation while preserving gradient propagation. Theoretical analysis demonstrates ILIF effectiveness in overcoming the gamma dilemma, and extensive experiments on multiple datasets show that ILIF improves energy efficiency by reducing firing rates, stabilizes training, and enhances accuracy. The code is available at this http URL.', 'abstract_zh': '基于事件驱动的脉冲神经网络（SNN）因其能效高、事件驱动的处理方式和生物可行性而备受关注。为了通过反向传播训练SNN，使用替代梯度来近似非可微的脉冲函数，但替代梯度仅在膜电位接近放电阈值的狭窄范围内保持非零导数，这一范围被称为替代梯度支持宽度γ。我们识别出一个主要挑战，被称为γ悖论：较大的γ会导致过度激活，表现为神经元过度放电，从而增加能耗，而较小的γ会导致梯度消失和时间依赖性的减弱。为解决这一问题，我们提出了一种受生物抑制机制启发的时序抑制性耗尽型积分-放电（ILIF）神经元模型。该模型结合了相互连接的抑制性单元，有效缓解了过度激活，同时保持了梯度的传播。理论分析表明，ILIF在克服γ悖论方面具有有效性，并且在多个数据集的广泛实验中显示出ILIF通过降低放电率提高能效、稳定训练和提升准确率的效果。相关代码可在以下链接获取。', 'title_zh': 'ILIF：用于脉冲神经网络中过度激活的时变抑制泄漏积分并.fire �神经营元'}
{'arxiv_id': 'arXiv:2505.10360', 'title': 'FactsR: A Safer Method for Producing High Quality Healthcare Documentation', 'authors': 'Victor Petrén Bach Hansen, Lasse Krogsbøll, Jonas Lyngsø, Mathias Baltzersen, Andreas Motzfeldt, Kevin Pelgrims, Lars Maaløe', 'link': 'https://arxiv.org/abs/2505.10360', 'abstract': 'There are now a multitude of AI-scribing solutions for healthcare promising the utilization of large language models for ambient documentation. However, these AI scribes still rely on one-shot, or few-shot prompts for generating notes after the consultation has ended, employing little to no reasoning. This risks long notes with an increase in hallucinations, misrepresentation of the intent of the clinician, and reliance on the proofreading of the clinician to catch errors. A dangerous combination for patient safety if vigilance is compromised by workload and fatigue. In this paper, we introduce a method for extracting salient clinical information in real-time alongside the healthcare consultation, denoted Facts, and use that information recursively to generate the final note. The FactsR method results in more accurate and concise notes by placing the clinician-in-the-loop of note generation, while opening up new use cases within real-time decision support.', 'abstract_zh': '实时提取临床信息并在诊疗过程中生成笔记的方法：FactsR及其在实时决策支持中的新应用', 'title_zh': 'FactsR：一种更安全的高质量 Healthcare 记录生成方法'}
{'arxiv_id': 'arXiv:2505.10347', 'title': 'Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning', 'authors': 'Gabriel S. Gama, Valdir Grassi Jr', 'link': 'https://arxiv.org/abs/2505.10347', 'abstract': 'Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task Learning by addressing issues like conflicting gradients and differing gradient norms, which hinder equal-weighted task training. However, recent critiques suggest that equally weighted tasks can achieve competitive results compared to SMTOs, arguing that previous SMTO results were influenced by poor hyperparameter optimization and lack of regularization. In this work, we evaluate these claims through an extensive empirical evaluation of SMTOs, including some of the latest methods, on more complex multi-task problems to clarify this behavior. Our findings indicate that SMTOs perform well compared to uniform loss and that fixed weights can achieve competitive performance compared to SMTOs. Furthermore, we demonstrate why uniform loss perform similarly to SMTOs in some instances. The code will be made publicly available.', 'abstract_zh': '专门化的多任务优化器（SMTOs）通过解决如冲突梯度和梯度范数差异等问题，在多任务学习中平衡任务学习，从而避免等权重任务训练。然而，近期的批评指出，等权重任务可以达到与SMTOs相当的结果，认为SMTOs的先前结果受到了不良超参数优化和缺乏正则化的 影响。在本文中，我们通过在更复杂多任务问题上的广泛实证评估，包括一些最新方法，来检验这些观点，以澄清这一行为。我们的发现表明，与均匀损失相比，SMTOs表现良好，固定权重也可以达到与SMTOs相当的性能。此外，我们展示了为什么在某些情况下均匀损失的表现与SMTOs相似。相关代码将公开发布。', 'title_zh': '统一损失函数 vs. 专业化优化：多任务学习中的比较分析'}
{'arxiv_id': 'arXiv:2505.10331', 'title': 'Emergence of Structure in Ensembles of Random Neural Networks', 'authors': 'Luca Muscarnera, Luigi Loreti, Giovanni Todeschini, Alessio Fumagalli, Francesco Regazzoni', 'link': 'https://arxiv.org/abs/2505.10331', 'abstract': 'Randomness is ubiquitous in many applications across data science and machine learning. Remarkably, systems composed of random components often display emergent global behaviors that appear deterministic, manifesting a transition from microscopic disorder to macroscopic organization. In this work, we introduce a theoretical model for studying the emergence of collective behaviors in ensembles of random classifiers. We argue that, if the ensemble is weighted through the Gibbs measure defined by adopting the classification loss as an energy, then there exists a finite temperature parameter for the distribution such that the classification is optimal, with respect to the loss (or the energy). Interestingly, for the case in which samples are generated by a Gaussian distribution and labels are constructed by employing a teacher perceptron, we analytically prove and numerically confirm that such optimal temperature does not depend neither on the teacher classifier (which is, by construction of the learning problem, unknown), nor on the number of random classifiers, highlighting the universal nature of the observed behavior. Experiments on the MNIST dataset underline the relevance of this phenomenon in high-quality, noiseless, datasets. Finally, a physical analogy allows us to shed light on the self-organizing nature of the studied phenomenon.', 'abstract_zh': '随机性在数据科学和机器学习的许多应用中无处不在。令人Remarkably,由随机组件组成的系统常常表现出从微观无序到宏观有序的涌现全局行为，显示出随机性和确定性的转变。在本文中，我们提出一个理论模型来研究随机分类器集合中的集体行为的涌现。我们argue，如果通过采用分类损失作为能量的吉布斯测度加权，那么存在一个有限的温度参数，使得分类在损失（或能量）方面达到最优。有趣的是，在样本由高斯分布生成，标签通过教师感知机构建的情况下，我们不仅从理论上证明，而且通过数值实验确认最优温度与教师分类器（通过学习问题的构建，该分类器是未知的）和随机分类器的数量无关，突显了观察到的行为的普遍性。MNIST数据集上的实验强调了这一现象在高质量、无噪声数据集中的重要性。最后，一个物理类比有助于阐明所研究现象的自我组织性质。', 'title_zh': '随机神经网络集成中的结构涌现'}
{'arxiv_id': 'arXiv:2505.10315', 'title': 'Private Transformer Inference in MLaaS: A Survey', 'authors': 'Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao', 'link': 'https://arxiv.org/abs/2505.10315', 'abstract': 'Transformer models have revolutionized AI, powering applications like content generation and sentiment analysis. However, their deployment in Machine Learning as a Service (MLaaS) raises significant privacy concerns, primarily due to the centralized processing of sensitive user data. Private Transformer Inference (PTI) offers a solution by utilizing cryptographic techniques such as secure multi-party computation and homomorphic encryption, enabling inference while preserving both user data and model privacy. This paper reviews recent PTI advancements, highlighting state-of-the-art solutions and challenges. We also introduce a structured taxonomy and evaluation framework for PTI, focusing on balancing resource efficiency with privacy and bridging the gap between high-performance inference and data privacy.', 'abstract_zh': 'Transformer模型颠覆了AI领域，推动了内容生成和情感分析等应用的发展。然而，在Machine Learning as a Service (MLaaS)中的部署引发了重大的隐私担忧，主要是由于敏感用户数据的集中处理。Private Transformer Inference (PTI)通过使用安全多方计算和同态加密等加密技术提供了解决方案，从而在保持用户数据和模型隐私的同时进行推理。本文回顾了近期PTI的进展，重点介绍了最新的解决方案和挑战。我们还引入了一个结构化的分类体系和评估框架，旨在平衡资源效率与隐私，并弥合高性能推理与数据隐私之间的差距。', 'title_zh': '基于MLaaS的私有Transformer推理：一种综述'}
{'arxiv_id': 'arXiv:2505.10300', 'title': 'AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages', 'authors': 'Muzhe Wu, Yanzhi Zhao, Shuyi Han, Michael Xieyang Liu, Hong Shen', 'link': 'https://arxiv.org/abs/2505.10300', 'abstract': 'Responsible AI (RAI) efforts increasingly emphasize the importance of addressing potential harms early in the AI development lifecycle through social-technical lenses. However, in cross-functional industry teams, this work is often stalled by a persistent knowledge handoff challenge: the difficulty of transferring high-level, early-stage technical design rationales from technical experts to non-technical or user-facing roles for ethical evaluation and harm identification. Through literature review and a co-design study with 8 practitioners, we unpack how this challenge manifests -- technical design choices are rarely handed off in ways that support meaningful engagement by non-technical roles; collaborative workflows lack shared, visual structures to support mutual understanding; and non-technical practitioners are left without scaffolds for systematic harm evaluation. Existing tools like JIRA or Google Docs, while useful for product tracking, are ill-suited for supporting joint harm identification across roles, often requiring significant extra effort to align understanding. To address this, we developed AI LEGO, a web-based prototype that supports cross-functional AI practitioners in effectively facilitating knowledge handoff and identifying harmful design choices in the early design stages. Technical roles use interactive blocks to draft development plans, while non-technical roles engage with those blocks through stage-specific checklists and LLM-driven persona simulations to surface potential harms. In a study with 18 cross-functional practitioners, AI LEGO increased the volume and likelihood of harms identified compared to baseline worksheets. Participants found that its modular structure and persona prompts made harm identification more accessible, fostering clearer and more collaborative RAI practices in early design.', 'abstract_zh': '负责任的人工智能（RAI）努力 increasingly 强调通过社会-技术视角在人工智能开发生命周期早期识别潜在危害的重要性。然而，在跨职能行业团队中，这项工作往往因持续的知识传递挑战而停滞：技术专家难以将高层次的技术设计理由传递给非技术或面向用户的角色，以便进行伦理评估和危害识别。通过文献回顾和与8位实践者进行共同设计研究，我们剖析了这一挑战的表现——技术设计选择很少以支持非技术角色有意义参与的方式传递；合作工作流程缺乏共享的可视化结构来支持相互理解；非技术从业者在系统性危害评估方面缺乏支柱。现有的工具如JIRA或Google Docs虽然适用于产品追踪，但不适合支持跨角色的联合危害识别，常常需要额外的努力来实现理解的统一。为了解决这一问题，我们开发了AI LEGO，这是一种基于Web的原型，支持跨职能的人工智能从业者在早期设计阶段有效地促进知识传递和识别有害设计选择。技术人员使用交互式模块草拟开发计划，而非技术人员则通过阶段特定的检查列表和由LLM驱动的人格模拟与这些模块互动，以揭示潜在的危害。在一项涉及18名跨职能从业者的研究中，AI LEGO相比于基线工作表，增加了危害识别的数量和可能性。参与者发现其模块式结构和个人角色提示使危害识别更加容易，促进了早期设计中的更清晰和更协作的RAI实践。', 'title_zh': 'AI LEGO：在工业负责任人工智能实践早期设计阶段支撑跨功能协作'}
{'arxiv_id': 'arXiv:2505.10297', 'title': 'Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning', 'authors': 'Chibueze Peace Obioma, Youcheng Sun, Mustafa A. Mustafa', 'link': 'https://arxiv.org/abs/2505.10297', 'abstract': "Federated learning (FL) enhances privacy and reduces communication cost for resource-constrained edge clients by supporting distributed model training at the edge. However, the heterogeneous nature of such devices produces diverse, non-independent, and identically distributed (non-IID) data, making the detection of backdoor attacks more challenging. In this paper, we propose a novel federated representative-attention-based defense mechanism, named FeRA, that leverages cross-client attention over internal feature representations to distinguish benign from malicious clients. FeRA computes an anomaly score based on representation reconstruction errors, effectively identifying clients whose internal activations significantly deviate from the group consensus. Our evaluation demonstrates FeRA's robustness across various FL scenarios, including challenging non-IID data distributions typical of edge devices. Experimental results show that it effectively reduces backdoor attack success rates while maintaining high accuracy on the main task. The method is model-agnostic, attack-agnostic, and does not require labeled reference data, making it well suited to heterogeneous and resource-limited edge deployments.", 'abstract_zh': '联邦学习(FedRA)通过利用客户端间的注意力机制在边缘设备上实现模型分布式训练，增强隐私并减少通信成本。然而，这类设备的异质性产生了多样且非独立同分布的数据，使得后门攻击检测更加困难。本文提出了一种新颖的联邦代表-注意防御机制，FeRA，它通过跨客户端的注意力机制区分良性客户端和恶意客户端。FeRA基于表示重构错误计算异常得分，有效识别内部激活与群体共识显著偏离的客户端。评价结果显示，FeRA在包括边缘设备典型的非同分布数据分布的各种联邦学习场景中表现出 robust 性。实验结果表明，它能有效降低后门攻击的成功率并保持较高的主要任务准确性。该方法是模型无关、攻击无关的，不需要标记参考数据，适用于异构和资源受限的边缘部署。', 'title_zh': '防御边缘端后门攻击：代表注意力机制的研究'}
{'arxiv_id': 'arXiv:2505.10273', 'title': 'AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons', 'authors': 'Hexu Li, Konstantinos Kalogiannis, Ahmed Mohamed Hussain, Panos Papadimitratos', 'link': 'https://arxiv.org/abs/2505.10273', 'abstract': 'Vehicle platooning, with vehicles traveling in close formation coordinated through Vehicle-to-Everything (V2X) communications, offers significant benefits in fuel efficiency and road utilization. However, it is vulnerable to sophisticated falsification attacks by authenticated insiders that can destabilize the formation and potentially cause catastrophic collisions. This paper addresses this challenge: misbehavior detection in vehicle platooning systems. We present AttentionGuard, a transformer-based framework for misbehavior detection that leverages the self-attention mechanism to identify anomalous patterns in mobility data. Our proposal employs a multi-head transformer-encoder to process sequential kinematic information, enabling effective differentiation between normal mobility patterns and falsification attacks across diverse platooning scenarios, including steady-state (no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an extensive simulation dataset featuring various attack vectors (constant, gradual, and combined falsifications) and operational parameters (controller types, vehicle speeds, and attacker positions). Experimental results demonstrate that AttentionGuard achieves up to 0.95 F1-score in attack detection, with robust performance maintained during complex maneuvers. Notably, our system performs effectively with minimal latency (100ms decision intervals), making it suitable for real-time transportation safety applications. Comparative analysis reveals superior detection capabilities and establishes the transformer-encoder as a promising approach for securing Cooperative Intelligent Transport Systems (C-ITS) against sophisticated insider threats.', 'abstract_zh': '基于自注意力机制的车辆编队恶意行为检测框架：AttentionGuard', 'title_zh': 'AttentionGuard: 基于Transformer的车队恶意行为检测方法以确保安全'}
{'arxiv_id': 'arXiv:2505.10264', 'title': 'Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning', 'authors': 'Francesco Diana, André Nusser, Chuan Xu, Giovanni Neglia', 'link': 'https://arxiv.org/abs/2505.10264', 'abstract': "Federated Learning (FL) enables collaborative training of machine learning models across distributed clients without sharing raw data, ostensibly preserving data privacy. Nevertheless, recent studies have revealed critical vulnerabilities in FL, showing that a malicious central server can manipulate model updates to reconstruct clients' private training data. Existing data reconstruction attacks have important limitations: they often rely on assumptions about the clients' data distribution or their efficiency significantly degrades when batch sizes exceed just a few tens of samples.\nIn this work, we introduce a novel data reconstruction attack that overcomes these limitations. Our method leverages a new geometric perspective on fully connected layers to craft malicious model parameters, enabling the perfect recovery of arbitrarily large data batches in classification tasks without any prior knowledge of clients' data. Through extensive experiments on both image and tabular datasets, we demonstrate that our attack outperforms existing methods and achieves perfect reconstruction of data batches two orders of magnitude larger than the state of the art.", 'abstract_zh': '联邦学习（FL）使得跨分布式客户端协作训练机器学习模型成为可能，而不共享原始数据，从而在一定程度上保护了数据隐私。然而，最近的研究揭示了FL中的关键漏洞，表明恶意中央服务器可以通过操纵模型更新重建客户端的私人训练数据。现有的数据重建攻击存在重要限制：它们通常依赖于对客户端数据分布的假设，或者当批量大小超过几十个样本时效率显著降低。\n\n在本工作中，我们介绍了一种新的数据重建攻击，克服了这些限制。我们的方法利用完全连接层的新几何视角来构建恶意模型参数，在没有任何关于客户端数据的知识的情况下，能够在分类任务中完美恢复任意大小的数据批量。通过在图像和表格数据集上的广泛实验，我们展示了我们的攻击方法优于现有方法，并实现了比现有技术大两个数量级的数据批量的完美重建。', 'title_zh': '穿过隐私：联邦学习中基于超平面的数据重构攻击'}
{'arxiv_id': 'arXiv:2505.10231', 'title': 'On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging', 'authors': 'Haozhe Luo, Ziyu Zhou, Zixin Shu, Aurélie Pahud de Mortanges, Robert Berke, Mauricio Reyes', 'link': 'https://arxiv.org/abs/2505.10231', 'abstract': 'Deep neural networks excel in medical imaging but remain prone to biases, leading to fairness gaps across demographic groups. We provide the first systematic exploration of Human-AI alignment and fairness in this domain. Our results show that incorporating human insights consistently reduces fairness gaps and enhances out-of-domain generalization, though excessive alignment can introduce performance trade-offs, emphasizing the need for calibrated strategies. These findings highlight Human-AI alignment as a promising approach for developing fair, robust, and generalizable medical AI systems, striking a balance between expert guidance and automated efficiency. Our code is available at this https URL.', 'abstract_zh': '深度神经网络在医疗成像领域表现出色，但仍易产生偏差，导致不同人口统计学群体之间的公平性差距。我们首次系统地探讨了该领域的人工智能与人类的对齐及其公平性问题。研究表明，持续融入人类见解可以一致地减少公平性差距并增强跨域泛化能力，尽管过度对齐可能会引入性能trade-offs，从而强调需要校准的策略。这些发现强调了人工智能与人类对齐作为一种开发公平、稳健和泛化能力强的医疗AI系统的有前景的方法，能够在专家指导与自动化效率之间取得平衡。相关代码可访问此网址。', 'title_zh': '人类与AI的一致性、公平性与性能权衡在医学成像中的相互作用'}
{'arxiv_id': 'arXiv:2505.10201', 'title': 'A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds', 'authors': 'Victor Lagerkvist, Mohamed Maizia, Johannes Schmidt', 'link': 'https://arxiv.org/abs/2505.10201', 'abstract': 'The Boolean satisfiability problem (SAT) is a well-known example of monotonic reasoning, of intense practical interest due to fast solvers, complemented by rigorous fine-grained complexity results. However, for non-monotonic reasoning, e.g., abductive reasoning, comparably little is known outside classic complexity theory. In this paper we take a first step of bridging the gap between monotonic and non-monotonic reasoning by analyzing the complexity of intractable abduction problems under the seemingly overlooked but natural parameter n: the number of variables in the knowledge base. We obtain several positive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments, which implies the first example of beating exhaustive search for a $\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement this with lower bounds and for many fragments rule out improvements under the (strong) exponential-time hypothesis.', 'abstract_zh': '单调推理中的布尔满足性问题（SAT）是一个著名的例子，由于快速求解器的存在，它在实践中具有重要性，同时伴随着严格的细粒度复杂性结果。然而，在非单调推理，例如演绎推理方面，经典复杂性理论之外了解相对较少。本文通过分析不可解演绎问题的复杂性，以变量数量n作为看似被忽视但自然的参数，迈出了弥合单调推理与非单调推理之间差距的第一步。我们获得了几个$\\Sigma^P_2$-、NP-和coNP-完全片段的积极结果，这表明了首个能够在我们所知的情况下击败穷举搜索的$\\Sigma^P_2$-完全问题的例子。我们还提供了下界，并对于许多片段排除了在强指数时间假设下的改进。', 'title_zh': '命题 abduction 的细粒度复杂性分析：算法与下界'}
{'arxiv_id': 'arXiv:2505.10197', 'title': 'Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion', 'authors': 'Anjali de Silva, Gang Chen, Hui Ma, Seyed Mohammad Nekooei, Xingquan Zuo', 'link': 'https://arxiv.org/abs/2505.10197', 'abstract': 'Community detection, a vital technology for real-world applications, uncovers cohesive node groups (communities) by leveraging both topological and attribute similarities in social networks. However, existing Graph Convolutional Networks (GCNs) trained to maximize modularity often converge to suboptimal solutions. Additionally, directly using human-labeled communities for training can undermine topological cohesiveness by grouping disconnected nodes based solely on node attributes. We address these issues by proposing a novel Topological and Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com introduces a novel loss function that exploits the highly effective and scalable Leiden algorithm to detect community structures with global optimal modularity. Leiden is further utilized to refine human-labeled communities to ensure connectivity within each community, enabling TAS-Com to detect community structures with desirable trade-offs between modularity and compliance with human labels. Experimental results on multiple benchmark networks confirm that TAS-Com can significantly outperform several state-of-the-art algorithms.', 'abstract_zh': '基于拓扑和属性相似性的社区检测（TAS-Com）方法', 'title_zh': '基于图卷积神经网络的社区检测推进：拓扑与属性凝聚力桥接'}
{'arxiv_id': 'arXiv:2505.10191', 'title': 'LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting', 'authors': 'Qingyu Zheng, Qi Shao, Guijun Han, Wei Li, Hong Li, Xuan Wang', 'link': 'https://arxiv.org/abs/2505.10191', 'abstract': 'Mesoscale eddies dominate the spatiotemporal multiscale variability of the ocean, and their impact on the energy cascade of the global ocean cannot be ignored. Eddy-resolving ocean forecasting is providing more reliable protection for fisheries and navigational safety, but also presents significant scientific challenges and high computational costs for traditional numerical models. Artificial intelligence (AI)-based weather and ocean forecasting systems are becoming powerful tools that balance forecast performance with computational efficiency. However, the complex multiscale features in the ocean dynamical system make AI models still face many challenges in mesoscale eddy forecasting (especially regional modelling). Here, we develop LanTu, a regional eddy-resolving ocean forecasting system based on dynamics-enhanced deep learning. We incorporate cross-scale interactions into LanTu and construct multiscale physical constraint for optimising LanTu guided by knowledge of eddy dynamics in order to improve the forecasting skill of LanTu for mesoscale evolution. The results show that LanTu outperforms the existing advanced operational numerical ocean forecasting system (NOFS) and AI-based ocean forecasting system (AI-OFS) in temperature, salinity, sea level anomaly and current prediction, with a lead time of more than 10 days. Our study highlights that dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for eddy-resolving ocean forecasting.', 'abstract_zh': '中尺度涡度主导海洋的时空多尺度变异性，其对全球海洋能量cascade的影响不容忽视。涡度分辨的海洋预报为渔业保护和航行安全提供了更可靠的保障，但同时对传统数值模型提出了重大科学挑战和高昂的计算成本。基于人工智能的气象和海洋预报系统正成为兼具预报性能与计算效率的强大力工具。然而，海洋动力系统的复杂多尺度特征使得人工智能模型在中尺度涡度预报（特别是区域建模）方面仍面临诸多挑战。为此，我们开发了基于动力增强深度学习的区域性涡度分辨海洋预报系统——兰图（LanTu）。通过将跨尺度交互纳入兰图系统，并以涡度动力学知识为指导构建多尺度物理约束，优化兰图以提升其在中尺度演化的预报技能。结果表明，在温度、盐度、海平面异常和流速预测方面，兰图在超过10天的预报时效内显著优于现有的先进海洋预报系统（高级海洋数值预报系统NOFS）和人工智能海洋预报系统（AI海洋预报系统AI-OFS）。我们的研究表明，动力增强深度学习（兰图）可以成为一种强大的中尺度涡度分辨海洋预报范式。', 'title_zh': 'LanTu: 动态增强深度学习的大涡分辨率海洋预报'}
{'arxiv_id': 'arXiv:2505.10185', 'title': 'The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think', 'authors': 'Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo', 'link': 'https://arxiv.org/abs/2505.10185', 'abstract': 'Long chain-of-thought (CoT) is an essential ingredient in effective usage of modern large language models, but our understanding of the reasoning strategies underlying these capabilities remains limited. While some prior works have attempted to categorize CoTs using predefined strategy types, such approaches are constrained by human intuition and fail to capture the full diversity of model behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up framework for analyzing and steering model reasoning. Our method automatically extracts diverse reasoning criteria from model-generated CoTs, embeds them into a semantic space, clusters them into representative categories, and derives contrastive rubrics to interpret reasoning behavior. Human evaluations show that this framework produces more interpretable and comprehensive analyses than existing methods. Moreover, we demonstrate that this understanding enables performance gains: we can predict which strategy a model is likely to use and guide it toward more effective alternatives. Finally, we provide practical insights, such as that training data format (e.g., free-form vs. multiple-choice) has a far greater impact on reasoning behavior than data domain, underscoring the importance of format-aware model design.', 'abstract_zh': 'Long链思维（CoT）是有效使用现代大型语言模型的一个重要组成部分，但对我们理解支撑这些能力的推理策略仍缺乏深刻理解。虽然一些先前的工作尝试使用预定义的策略类型对CoT进行分类，但这些方法受限于人类直觉，无法捕捉模型行为的全部多样性。在本工作中，我们引入了CoT百科全书，这是一种自下而上的框架，用于分析和引导模型推理。我们的方法自动从模型生成的CoT中提取多样的推理标准，将其嵌入到语义空间中，将其聚类成代表性类别，并推导出对比性标准来解释推理行为。人类评估表明，该框架产生的分析比现有方法更具可解释性和全面性。此外，我们证明了这种理解能够带来性能提升：我们可以预测模型可能使用的策略，并引导其朝向更有效的替代方式。最后，我们提供了实用见解，例如，训练数据格式（例如，自由格式 vs. 多选格式）对推理行为的影响远远大于数据领域，突显了格式意识模型设计的重要性。', 'title_zh': 'CoT百科：分析、预测和控制推理模型的思维过程'}
{'arxiv_id': 'arXiv:2505.10172', 'title': 'Does Scaling Law Apply in Time Series Forecasting?', 'authors': 'Zeyan Li, Libing Chen, Yin Tang', 'link': 'https://arxiv.org/abs/2505.10172', 'abstract': 'Rapid expansion of model size has emerged as a key challenge in time series forecasting. From early Transformer with tens of megabytes to recent architectures like TimesNet with thousands of megabytes, performance gains have often come at the cost of exponentially increasing parameter counts. But is this scaling truly necessary? To question the applicability of the scaling law in time series forecasting, we propose Alinear, an ultra-lightweight forecasting model that achieves competitive performance using only k-level parameters. We introduce a horizon-aware adaptive decomposition mechanism that dynamically rebalances component emphasis across different forecast lengths, alongside a progressive frequency attenuation strategy that achieves stable prediction in various forecasting horizons without incurring the computational overhead of attention mechanisms. Extensive experiments on seven benchmark datasets demonstrate that Alinear consistently outperforms large-scale models while using less than 1% of their parameters, maintaining strong accuracy across both short and ultra-long forecasting horizons. Moreover, to more fairly evaluate model efficiency, we propose a new parameter-aware evaluation metric that highlights the superiority of ALinear under constrained model budgets. Our analysis reveals that the relative importance of trend and seasonal components varies depending on data characteristics rather than following a fixed pattern, validating the necessity of our adaptive design. This work challenges the prevailing belief that larger models are inherently better and suggests a paradigm shift toward more efficient time series modeling.', 'abstract_zh': 'Rapid扩展的模型规模已成为时间序列预测中的关键挑战。从早期带有几十兆参数的Transformer，到最近的TimesNet等带有数千兆参数的架构，性能提升往往伴随着参数数量呈指数级增加。但这种扩展是否真有必要？为了质疑时间序列预测中的规模法则适用性，我们提出了Alinear，一个超轻量级的预测模型，仅使用k级参数即可实现竞争力的性能。我们引入了一种基于预测时长的自适应分解机制，动态平衡不同预测长度下的组件重点，并采用了一种渐进频率衰减策略，能够在各种预测时长下实现稳定的预测，而无需引入注意力机制的计算开销。在七个基准数据集上的广泛实验表明，Alinear在使用不到1%参数的情况下，无论是短期还是超长期预测均保持强健的准确性，始终优于大型模型。此外，为更公平地评价模型效率，我们提出了一种新的参数感知评估指标，突显了Alinear在受限模型预算下的优越性。我们的分析结果表明，趋势和季节性组件的相对重要性取决于数据特征而非固定模式，从而验证了我们自适应设计的必要性。这项工作挑战了更大模型必然更好的普遍信念，并建议向更高效的时间序列建模范式转变。', 'title_zh': '时间序列预测中适用规模律吗？'}
{'arxiv_id': 'arXiv:2505.10167', 'title': 'QuXAI: Explainers for Hybrid Quantum Machine Learning Models', 'authors': 'Saikat Barua, Mostafizur Rahman, Shehenaz Khaled, Md Jafor Sadek, Rafiul Islam, Shahnewaz Siddique', 'link': 'https://arxiv.org/abs/2505.10167', 'abstract': 'The emergence of hybrid quantum-classical machine learning (HQML) models opens new horizons of computational intelligence but their fundamental complexity frequently leads to black box behavior that undermines transparency and reliability in their application. Although XAI for quantum systems still in its infancy, a major research gap is evident in robust global and local explainability approaches that are designed for HQML architectures that employ quantized feature encoding followed by classical learning. The gap is the focus of this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an explainer for explaining feature importance in these hybrid systems. Our model entails the creation of HQML models incorporating quantum feature maps, the use of Q-MEDLEY, which combines feature based inferences, preserving the quantum transformation stage and visualizing the resulting attributions. Our result shows that Q-MEDLEY delineates influential classical aspects in HQML models, as well as separates their noise, and competes well against established XAI techniques in classical validation settings. Ablation studies more significantly expose the virtues of the composite structure used in Q-MEDLEY. The implications of this work are critically important, as it provides a route to improve the interpretability and reliability of HQML models, thus promoting greater confidence and being able to engage in safer and more responsible use of quantum-enhanced AI technology.', 'abstract_zh': '混合量子-经典机器学习（HQML）模型的涌现为计算智能打开了新视野，但其基础复杂性常常导致黑盒行为，损害了其应用的透明度和可靠性。尽管对量子系统的可解释性人工智能（XAI）仍处于初级阶段，但在针对采用量化特征编码后进行经典学习的HQML架构设计的稳健全局和局部可解释性方法方面存在明显的研究空白。本文聚焦于此空白，提出了基于Q-MEDLEY的QuXAI框架，Q-MEDLEY是一种用于解释这些混合系统中特征重要性的解释器。我们的模型包括创建包含量子特征映射的HQML模型，采用Q-MEDLEY，该方法结合了基于特征的推理，保留了量子变换阶段，并可视化了产生的归因。结果显示，Q-MEDLEY能够明确HQML模型中具有影响力的经典方面，分离出其噪声，并在经典验证设置中与现有XAI技术竞争。消融研究更显著地揭示了Q-MEDLEY所使用复合结构的优点。本研究的意义至关重要，它提供了一条提高HQML模型的可解释性和可靠性的途径，从而推动更大程度的信心，并促进更安全和负责任地使用量子增强的人工智能技术。', 'title_zh': 'QuXAI: 混合量子机器学习模型的解释器'}
{'arxiv_id': 'arXiv:2505.10134', 'title': 'Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks', 'authors': 'Guangjin Pan, Kaixuan Huang, Hui Chen, Shunqing Zhang, Christian Häger, Henk Wymeersch', 'link': 'https://arxiv.org/abs/2505.10134', 'abstract': 'Accurate and robust localization is a critical enabler for emerging 5G and 6G applications, including autonomous driving, extended reality (XR), and smart manufacturing. While data-driven approaches have shown promise, most existing models require large amounts of labeled data and struggle to generalize across deployment scenarios and wireless configurations. To address these limitations, we propose a foundation-model-based solution tailored for wireless localization. We first analyze how different self-supervised learning (SSL) tasks acquire general-purpose and task-specific semantic features based on information bottleneck (IB) theory. Building on this foundation, we design a pretraining methodology for the proposed Large Wireless Localization Model (LWLM). Specifically, we propose an SSL framework that jointly optimizes three complementary objectives: (i) spatial-frequency masked channel modeling (SF-MCM), (ii) domain-transformation invariance (DTI), and (iii) position-invariant contrastive learning (PICL). These objectives jointly capture the underlying semantics of wireless channel from multiple perspectives. We further design lightweight decoders for key downstream tasks, including time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation, single base station (BS) localization, and multiple BS localization. Comprehensive experimental results confirm that LWLM consistently surpasses both model-based and supervised learning baselines across all localization tasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer models without pretraining, and exhibits strong generalization under label-limited fine-tuning and unseen BS configurations, confirming its potential as a foundation model for wireless localization.', 'abstract_zh': '准确且鲁棒的定位是推动新兴5G和6G应用（包括自动驾驶、扩展现实(XR)和智能制造）的关键使能技术。虽然基于数据的方法具有潜力，但现有大多数模型需要大量标注数据，并且在跨部署场景和无线配置的泛化能力上存在局限。为克服这些局限，我们提出了一种基于基础模型的无线定位解决方案。我们首先基于信息瓶颈理论分析了不同半监督学习任务如何获取通用和任务特定的语义特征。在此基础上，我们为提出的大型无线定位模型（LWLM）设计了一种预训练方法。具体而言，我们提出了一种半监督学习框架，联合优化三个互补的目标：（i）空间-频率掩码信道建模（SF-MCM），（ii）领域变换不变性（DTI），以及（iii）位置不变对比学习（PICL）。这些目标从多个角度共同捕捉无线信道的潜在语义。我们进一步为关键下游任务设计了轻量级解码器，包括到达时间（ToA）估计、到达角度（AoA）估计、单基站（BS）定位和多基站定位。全面的实验结果证实了LWLM在所有定位任务中的表现始终优于基于模型和监督学习的基线。特别地，LWLM在未预训练的变换模型上实现了26.0%到87.5%的性能提升，并在标注有限的微调和未见过的基站配置下展现出强大的泛化能力，证实其作为无线定位的基础模型的潜力。', 'title_zh': '大规模无线定位模型（LWLM）：6G网络中定位的基础模型'}
{'arxiv_id': 'arXiv:2505.10128', 'title': 'Robust Federated Learning on Edge Devices with Domain Heterogeneity', 'authors': 'Huy Q. Le, Latif U. Khan, Choong Seon Hong', 'link': 'https://arxiv.org/abs/2505.10128', 'abstract': "Federated Learning (FL) allows collaborative training while ensuring data privacy across distributed edge devices, making it a popular solution for privacy-sensitive applications. However, FL faces significant challenges due to statistical heterogeneity, particularly domain heterogeneity, which impedes the global mode's convergence. In this study, we introduce a new framework to address this challenge by improving the generalization ability of the FL global model under domain heterogeneity, using prototype augmentation. Specifically, we introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a prototype-based FL framework designed to enhance feature diversity and model robustness. FedAPC leverages prototypes derived from the mean features of augmented data to capture richer representations. By aligning local features with global prototypes, we enable the model to learn meaningful semantic features while reducing overfitting to any specific domain. Experimental results on the Office-10 and Digits datasets illustrate that our framework outperforms SOTA baselines, demonstrating superior performance.", 'abstract_zh': '联邦学习（FL）通过确保分布式边缘设备上的数据隐私来进行协作培训，使其成为敏感隐私应用的流行解决方案。然而，由于统计异质性，特别是领域异质性，FL面临重大挑战，这阻碍了全局模型的收敛。在本研究中，我们提出了一种新的框架来应对这一挑战，通过在领域异质性下改进FL全局模型的泛化能力，采用原型增强方法。具体而言，我们提出了一种基于原型的联邦学习框架FedAPC（联邦增强原型对比学习），旨在增强特征多样性和模型稳健性。FedAPC利用增强数据的均值特征衍生的原型来捕捉更丰富的表示。通过将局部特征对齐到全局原型，我们使模型能够学习有意义的语义特征，同时减少对特定领域的过度拟合。在Office-10和Digits数据集上的实验结果表明，我们的框架优于当前最佳基线，显示出更好的性能。', 'title_zh': '边缘设备上具有领域异质性的鲁棒联邦学习'}
{'arxiv_id': 'arXiv:2505.10120', 'title': 'All You Need Is Synthetic Task Augmentation', 'authors': 'Guillaume Godin', 'link': 'https://arxiv.org/abs/2505.10120', 'abstract': 'Injecting rule-based models like Random Forests into differentiable neural network frameworks remains an open challenge in machine learning. Recent advancements have demonstrated that pretrained models can generate efficient molecular embeddings. However, these approaches often require extensive pretraining and additional techniques, such as incorporating posterior probabilities, to boost performance. In our study, we propose a novel strategy that jointly trains a single Graph Transformer neural network on both sparse multitask molecular property experimental targets and synthetic targets derived from XGBoost models trained on Osmordred molecular descriptors. These synthetic tasks serve as independent auxiliary tasks. Our results show consistent and significant performance improvement across all 19 molecular property prediction tasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms the XGBoost single-task learner. This demonstrates that synthetic task augmentation is an effective method for enhancing neural model performance in multitask molecular property prediction without the need for feature injection or pretraining.', 'abstract_zh': '将基于规则的模型如随机森林注入可微神经网络框架仍然是机器学习中的一个开放挑战。近期的研究表明，预训练模型可以生成高效的分子嵌入。然而，这些方法通常需要大量的预训练和额外的技术，如整合后概率，来提升性能。在本研究中，我们提出了一种新的策略，即在同一Graph Transformer神经网络中联合训练单个模型，该模型同时考虑稀疏多任务分子性质实验目标和从训练于Osmordred分子描述符上的XGBoost模型导出的合成目标。这些合成任务作为独立的辅助任务。我们的结果显示，在所有19个分子性质预测任务中都表现出一致且显著的性能提升。在16个目标中，多任务Graph Transformer优于XGBoost单任务学习器。这表明，合成任务增强是提高多任务分子性质预测神经模型性能的有效方法，无需特征注入或预训练。', 'title_zh': '你需要的只是合成任务增强。'}
{'arxiv_id': 'arXiv:2505.10055', 'title': 'PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language', 'authors': 'Ijazul Haq, Yingjie Zhang, Irfan Ali Khan', 'link': 'https://arxiv.org/abs/2505.10055', 'abstract': "This paper evaluates the performance of Large Multimodal Models (LMMs) on Optical Character Recognition (OCR) in the low-resource Pashto language. Natural Language Processing (NLP) in Pashto faces several challenges due to the cursive nature of its script and a scarcity of structured datasets. To address this, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one million images annotated with bounding boxes at word, line, and document levels, suitable for training and evaluating models based on different architectures, including Convolutional Neural Networks (CNNs) and Transformers. PsOCR covers variations across 1,000 unique font families, colors, image sizes, and layouts. A benchmark subset of 10K images was selected to evaluate the performance of several LMMs, including seven open-source models: DeepSeek's Janus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four closed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results demonstrate that Gemini achieves the best performance among all models, whereas among open-source models, Qwen-7B stands out. This work provides an insightful assessment of the capabilities and limitations of current LMMs for OCR tasks in Pashto and establishes a foundation for further research not only in Pashto OCR but also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is available at this https URL.", 'abstract_zh': '本研究评估了大型多模态模型（LMMs）在低资源普什图语光学字符识别（OCR）中的性能。由于普什图语的连写特性和结构化数据的缺乏，普什图语自然语言处理面临着多项挑战。为此，我们开发了一个合成的普什图语OCR数据集PsOCR，包含一百万张图像，并标有单词、行和文档级别的边界框，适用于不同架构的模型训练和评估，包括卷积神经网络（CNNs）和Transformer。PsOCR覆盖了1000种不同的字体家族、颜色、图像大小和布局的变体。选择了10K张图像作为基准子集，用于评估多种LMMs的表现，包括七个开源模型：DeepSeek的Janus、InternVL、MiniCPM、Florence和Qwen（3B和7B），以及四个闭源模型：GPT-4o、Gemini、Claude和Grok。实验结果表明，Gemini在所有模型中表现最佳，而开源模型中，Qwen-7B表现出色。本研究为当前LMMs在普什图语OCR任务中的能力和限制提供了有价值的评估，并为普什图语OCR以及阿拉伯语、波斯语和乌尔都语等类似脚本的进一步研究奠定了基础。PsOCR可在以下链接获取：this https URL。', 'title_zh': 'PsOCR：低资源普什图语光学字符识别的大规模多模态模型基准测试'}
{'arxiv_id': 'arXiv:2505.10050', 'title': 'Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods', 'authors': 'Fahad Almalki, Mehedi Masud', 'link': 'https://arxiv.org/abs/2505.10050', 'abstract': "Traditional machine learning models often prioritize predictive accuracy, often at the expense of model transparency and interpretability. The lack of transparency makes it difficult for organizations to comply with regulatory requirements and gain stakeholders trust. In this research, we propose a fraud detection framework that combines a stacking ensemble of well-known gradient boosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable artificial intelligence (XAI) techniques are used to enhance the transparency and interpretability of the model's decisions. We used SHAP (SHapley Additive Explanations) for feature selection to identify the most important features. Further efforts were made to explain the model's predictions using Local Interpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots (PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection dataset, which includes more than 590,000 real transaction records, was used to evaluate the proposed model. The model achieved a high performance with an accuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent related approaches. These results indicate that combining high prediction accuracy with transparent interpretability is possible and could lead to a more ethical and trustworthy solution in financial fraud detection.", 'abstract_zh': '传统机器学习模型通常优先考虑预测准确性，往往以牺牲模型透明度和可解释性为代价。缺乏透明度使得组织在遵守监管要求和赢得利益相关者信任方面面临困难。在本研究中，我们提出了一种欺诈检测框架，该框架结合了著名的梯度提升模型集成：XGBoost、LightGBM和CatBoost。此外，我们使用可解释人工智能（XAI）技术来增强模型决策的透明度和可解释性。我们使用SHAP（SHapley Additive Explanations）进行特征选择以识别最重要的特征，并通过局部可解释的模型agnostic解释（LIME）、部分依赖图（PDP）和置换特征重要性（PFI）进一步解释模型的预测。我们使用包含超过59万条真实交易记录的IEEE-CIS欺诈检测数据集来评估所提出的模型。该模型的性能很高，准确率为99%，AUC-ROC得分为0.99，优于多个近期相关方法。这些结果表明，结合高预测准确性和透明的可解释性是可能的，并可能导致金融欺诈检测中更具伦理性和可信度的解决方案。', 'title_zh': '使用可解释人工智能和堆叠集成方法的金融欺诈检测'}
{'arxiv_id': 'arXiv:2505.10043', 'title': 'Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights', 'authors': 'Yifan Wu, Lutao Yan, Yizhang Zhu, Yinan Mei, Jiannan Wang, Nan Tang, Yuyu Luo', 'link': 'https://arxiv.org/abs/2505.10043', 'abstract': 'Charts are crucial for data analysis and this http URL-to-chart retrieval systems have become increasingly important for Business Intelligence (BI), where users need to find relevant charts that match their analytical needs. These needs can be categorized into precise queries that are well-specified and fuzzy queries that are more exploratory -- both require understanding the semantics and context of the charts. However, existing text-to-chart retrieval solutions often fail to capture the semantic content and contextual information of charts, primarily due to the lack of comprehensive metadata (or semantic insights). To address this limitation, we propose a training data development pipeline that automatically synthesizes hierarchical semantic insights for charts, covering visual patterns (visual-oriented), statistical properties (statistics-oriented), and practical applications (task-oriented), which produces 207,498 semantic insights for 69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to learn better representations of charts for text-to-chart retrieval. Our method leverages rich semantic insights during the training phase to develop a model that understands both visual and semantic aspects of this http URL evaluate text-to-chart retrieval performance, we curate the first benchmark, CRBench, for this task with 21,862 charts and 326 text queries from real-world BI applications, with ground-truth labels verified by the crowd this http URL show that ChartFinder significantly outperforms existing methods in text-to-chart retrieval tasks across various settings. For precise queries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than state-of-the-art models. In fuzzy query tasks, our method also demonstrates consistent improvements, with an average increase of 5% across nearly all metrics.', 'abstract_zh': '图表对于数据解析至关重要，尤其是在商业智能中，用户需要找到符合其分析需求的相关图表。这些需求可以分为明确的查询和探索性的查询——两者都需要理解图表的语义和上下文。然而，现有的文本到图表检索解决方案常常无法捕捉到图表的语义内容和上下文信息，主要是因为缺乏全面的元数据（或语义洞察）。为解决这一局限，我们提出了一种训练数据开发管道，可以自动为图表生成层次化的语义洞察，涵盖视觉模式（视觉导向）、统计属性（统计导向）和实际应用（任务导向），共生成了207,498条语义洞察，用于69,166张图表。基于这些，我们训练了一个基于CLIP的模型ChartFinder，以学习更好的图表表示，用于文本到图表检索。我们的方法在训练阶段利用丰富的语义洞察来开发一个理解和掌握图表视觉和语义方面的模型。为了评估文本到图表检索性能，我们构建了第一个用于此任务的基准CRBench，包括21,862张图表和326条来自实际商业智能应用的文本查询，并通过群众核实了真实标签。实验结果显示，ChartFinder在各种设置下的文本到图表检索任务中显著优于现有方法。对于精确查询，ChartFinder的NDCG@10最高可达66.9%，比最先进的模型高出11.58%。在模糊查询任务中，我们的方法也显示出一致的改进，几乎所有指标平均提高了5%。', 'title_zh': '通过训练生成语义洞察提升文本到图表检索'}
{'arxiv_id': 'arXiv:2505.10037', 'title': 'Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction', 'authors': 'Takafumi Ito, Lysenko Artem, Tatsuhiko Tsunoda', 'link': 'https://arxiv.org/abs/2505.10037', 'abstract': 'Quantum-classical Hybrid Machine Learning (QHML) models are recognized for their robust performance and high generalization ability even for relatively small datasets. These qualities offer unique advantages for anti-cancer drug response prediction, where the number of available samples is typically small. However, such hybrid models appear to be very sensitive to the data encoding used at the interface of a neural network and a quantum circuit, with suboptimal choices leading to stability issues. To address this problem, we propose a novel strategy that uses a normalization function based on a moderated gradient version of the $\\tanh$. This method transforms the outputs of the neural networks without concentrating them at the extreme value ranges. Our idea was evaluated on a dataset of gene expression and drug response measurements for various cancer cell lines, where we compared the prediction performance of a classical deep learning model and several QHML models. These results confirmed that QHML performed better than the classical models when data was optimally normalized. This study opens up new possibilities for biomedical data analysis using quantum computers.', 'abstract_zh': '量子经典混合机器学习（QHML）模型因其在相对较小数据集上的稳健性能和高泛化能力而受到认可，这些特性使其在癌药响应预测中具有独特的优势。然而，这类混合模型在神经网络与量子电路接口的数据编码方面表现出很高的敏感性，次优的选择会导致稳定性问题。为解决这个问题，我们提出了一种新型策略，该策略基于经过调节的梯度版本的$\\tanh$函数使用规范化函数。该方法将神经网络的输出进行变换而不会使其集中在极端值范围。我们的想法在基因表达和癌细胞系药物响应测量的数据集上进行了评估，我们将经典深度学习模型和几种QHML模型的预测性能进行了比较。结果证实，在数据最优规范化的情况下，QHML比经典模型表现更优。这项研究为使用量子计算机进行生物医学数据分析开启了新的可能性。', 'title_zh': '量子经典混合模型中抗癌药物响应预测的最佳归一化方法'}
{'arxiv_id': 'arXiv:2505.10012', 'title': 'Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering', 'authors': 'Tadashi Kadowaki', 'link': 'https://arxiv.org/abs/2505.10012', 'abstract': 'Recent advances in artificial intelligence (AI) and quantum computing are accelerating automation in scientific and engineering processes, fundamentally reshaping research methodologies. This perspective highlights parallels between scientific automation and established Computer-Aided Engineering (CAE) practices, introducing Quantum CAE as a framework that leverages quantum algorithms for simulation, optimization, and machine learning within engineering design. Practical implementations of Quantum CAE are illustrated through case studies for combinatorial optimization problems. Further discussions include advancements toward higher automation levels, highlighting the critical role of specialized AI agents proficient in quantum algorithm design. The integration of quantum computing with AI raises significant questions about the collaborative dynamics among human scientists and engineers, AI systems, and quantum computational resources, underscoring a transformative future for automated discovery and innovation.', 'abstract_zh': '最近人工智能和量子计算的进步正在加速科学和工程过程的自动化，从根本上重塑研究方法。本文探讨了科学自动化与现有计算机辅助工程（CAE）实践之间的相似性，引出量子CAE这一框架，其利用量子算法在工程设计中进行仿真、优化和机器学习。通过组合优化问题的应用案例，展示了量子CAE的实际实施。进一步的讨论包括向更高自动化水平迈进的过程中，强调了专门负责量子算法设计的人工智能代理的重要作用。将量子计算与人工智能集成引发了关于人类科学家和工程师、人工智能系统和量子计算资源之间协作动态的重大问题，预示着自动化发现和创新的变革性未来。', 'title_zh': '量子计算与人工智能：科学与工程中高级自动化的新视角'}
{'arxiv_id': 'arXiv:2505.09989', 'title': 'AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron', 'authors': 'Tella Rajashekhar Reddy, Palak, Rohan Gandhi, Anjaly Parayil, Chaojie Zhang, Mike Shepperd, Liangcheng Yu, Jayashree Mohan, Srinivasan Iyengar, Shivkumar Kalyanaraman, Debopam Bhattacherjee', 'link': 'https://arxiv.org/abs/2505.09989', 'abstract': 'AI power demand is growing unprecedentedly thanks to the high power density of AI compute and the emerging inferencing workload. On the supply side, abundant wind power is waiting for grid access in interconnection queues. In this light, this paper argues bringing AI workload to modular compute clusters co-located in wind farms. Our deployment right-sizing strategy makes it economically viable to deploy more than 6 million high-end GPUs today that could consume cheap, green power at its source. We built Heron, a cross-site software router, that could efficiently leverage the complementarity of power generation across wind farms by routing AI inferencing workload around power drops. Using 1-week ofcoding and conversation production traces from Azure and (real) variable wind power traces, we show how Heron improves aggregate goodput of AI compute by up to 80% compared to the state-of-the-art.', 'abstract_zh': 'AI算力需求因高密度计算和新兴推断工作负载而空前增长。在供应侧，大量风能正等待接入电网。基于此，本文提出将AI工作负载部署到风场内共置的模块化计算集群中。我们的部署尺寸优化策略使得今天可以经济地部署超过600万台高性能GPU，这些GPU能够就地消耗廉价、绿色的电力。我们构建了Heron，一种跨站点软件路由器，能够通过路由AI推断工作负载来有效利用风场间发电的互补性。使用Azure一周的编码和对话生产跟踪数据以及实际的可变风力发电跟踪数据，我们展示了Heron相比当前领先技术可将AI计算的整体吞吐量提升高达80%。', 'title_zh': 'AI Greenferencing: 将AI推理路由至配备Heron的绿色模块化数据中心'}
{'arxiv_id': 'arXiv:2505.09969', 'title': 'A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives', 'authors': 'Ali Azimi Lamir, Shiva Razzagzadeh, Zeynab Rezaei', 'link': 'https://arxiv.org/abs/2505.09969', 'abstract': 'This study presents a machine learning-based framework for heart disease prediction using the heart-disease dataset, comprising 303 samples with 14 features. The methodology involves data preprocessing, model training, and evaluation using three classifiers: Logistic Regression, K-Nearest Neighbors (KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and RandomizedSearchCV was employed to enhance model performance. The Random Forest classifier outperformed other models, achieving an accuracy of 91% and an F1-score of 0.89. Evaluation metrics, including precision, recall, and confusion matrix, revealed balanced performance across classes. The proposed model demonstrates strong potential for aiding clinical decision-making by effectively predicting heart disease. Limitations such as dataset size and generalizability underscore the need for future studies using larger and more diverse datasets. This work highlights the utility of machine learning in healthcare, offering insights for further advancements in predictive diagnostics.', 'abstract_zh': '基于机器学习的心脏疾病预测框架：使用包含303个样本和14个特征的心脏疾病数据集', 'title_zh': '一种全面的机器学习框架用于心脏疾病预测：性能评估与未来视角'}
{'arxiv_id': 'arXiv:2505.09955', 'title': 'TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation', 'authors': 'Jaeho Kim, Seulki Lee', 'link': 'https://arxiv.org/abs/2505.09955', 'abstract': "Unsupervised domain adaptation (UDA) for time series data remains a critical challenge in deep learning, with traditional pseudo-labeling strategies failing to capture temporal patterns and channel-wise shifts between domains, producing sub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that addresses these limitations by modeling the joint distribution $P(\\mathbf{X}, y)$ of the source domain through code transition matrices, where the codes are derived from vector quantization (VQ) of time series patches. Our method constructs class- and channel-wise code transition matrices from the source domain and employs Bayes' rule for target domain adaptation, generating pseudo-labels based on channel-wise weighted class-conditional likelihoods. TransPL offers three key advantages: explicit modeling of temporal transitions and channel-wise shifts between different domains, versatility towards different UDA scenarios (e.g., weakly-supervised UDA), and explainable pseudo-label generation. We validate TransPL's effectiveness through extensive analysis on four time series UDA benchmarks and confirm that it consistently outperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1% accuracy improvement, 4.9% F1 improvement), while providing interpretable insights into the domain adaptation process through its learned code transition matrices.", 'abstract_zh': '无监督领域适应（UDA）在时间序列数据中的挑战：TransPL方法及其优势', 'title_zh': 'TransPL: VQ-码转换矩阵用于时间序列无监督领域适应的伪标签生成'}
{'arxiv_id': 'arXiv:2505.09952', 'title': 'Task-Core Memory Management and Consolidation for Long-term Continual Learning', 'authors': 'Tianyu Huai, Jie Zhou, Yuxuan Cai, Qin Chen, Wen Wu, Xingjiao Wu, Xipeng Qiu, Liang He', 'link': 'https://arxiv.org/abs/2505.09952', 'abstract': 'In this paper, we focus on a long-term continual learning (CL) task, where a model learns sequentially from a stream of vast tasks over time, acquiring new knowledge while retaining previously learned information in a manner akin to human learning. Unlike traditional CL settings, long-term CL involves handling a significantly larger number of tasks, which exacerbates the issue of catastrophic forgetting. Our work seeks to address two critical questions: 1) How do existing CL methods perform in the context of long-term CL? and 2) How can we mitigate the catastrophic forgetting that arises from prolonged sequential updates? To tackle these challenges, we propose a novel framework inspired by human memory mechanisms for long-term continual learning (Long-CL). Specifically, we introduce a task-core memory management strategy to efficiently index crucial memories and adaptively update them as learning progresses. Additionally, we develop a long-term memory consolidation mechanism that selectively retains hard and discriminative samples, ensuring robust knowledge retention. To facilitate research in this area, we construct and release two multi-modal and textual benchmarks, MMLongCL-Bench and TextLongCL-Bench, providing a valuable resource for evaluating long-term CL approaches. Experimental results show that Long-CL outperforms the previous state-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively, demonstrating the effectiveness of our approach.', 'abstract_zh': '长周期连续学习任务中的模型记忆管理与知识保留方法', 'title_zh': '长期持续学习中的任务核心内存管理与合并'}
{'arxiv_id': 'arXiv:2505.09935', 'title': 'VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety', 'authors': 'Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Quoc Dai Tran', 'link': 'https://arxiv.org/abs/2505.09935', 'abstract': 'Understanding and predicting human behavior in-thewild, particularly at urban intersections, remains crucial for enhancing interaction safety between road users. Among the most critical behaviors are crossing intentions of Vulnerable Road Users (VRUs), where misinterpretation may result in dangerous conflicts with oncoming vehicles. In this work, we propose the VRU-CIPI framework with a sequential attention-based model designed to predict VRU crossing intentions at intersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal dynamics in VRU movements, combined with a multi-head Transformer self-attention mechanism to encode contextual and spatial dependencies critical for predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed achieves state-of-the-art performance with an accuracy of 96.45% and achieving real-time inference speed reaching 33 frames per second. Furthermore, by integrating with Infrastructure-to-Vehicles (I2V) communication, our approach can proactively enhance intersection safety through timely activation of crossing signals and providing early warnings to connected vehicles, ensuring smoother and safer interactions for all road users.', 'abstract_zh': '理解并预测城市交叉口行人等弱势道路使用者的穿越意图，对于提升道路使用者交互安全性至关重要。本文提出了一种基于顺序注意力机制的VRU-CIPI框架，用于预测交叉口行人等弱势道路使用者的穿越意图。VRU-CIPI框架采用门控循环单元（GRU）捕捉行人等动态，并结合多头Transformer自注意力机制编码对预测穿越方向至关重要的上下文和空间依赖性。在UCF-VRU数据集上评估，所提出的模型达到了96.45%的准确率，并实现了每秒33帧的实时推断速度。此外，通过集成基础设施到车辆（I2V）通信，该方法能够通过及时激活 crossing信号并为连接车辆提供早期预警，主动提升交叉口安全性，确保所有道路使用者的交互更加顺畅和安全。', 'title_zh': 'VRU-CIPI：交叉口行人过街意图预测以提高脆弱道路使用者安全'}
{'arxiv_id': 'arXiv:2505.09907', 'title': 'Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture', 'authors': 'Linwei Zhang, LuFeng, Ruijia Liang', 'link': 'https://arxiv.org/abs/2505.09907', 'abstract': 'With the growing demand for healthy foods, agricultural product price forecasting has become increasingly important. Hass avocados, as a high-value crop, exhibit complex price fluctuations influenced by factors such as seasonality, region, and weather. Traditional prediction models often struggle with highly nonlinear and dynamic data. To address this, we propose a hybrid deep learning model, TCN-MLP-Attention Architecture, combining Temporal Convolutional Networks (TCN) for sequential feature extraction, Multi-Layer Perceptrons (MLP) for nonlinear interactions, and an Attention mechanism for dynamic feature weighting. The dataset used covers over 50,000 records of Hass avocado sales across the U.S. from 2015 to 2018, including variables such as sales volume, average price, time, region, weather, and variety type, collected from point-of-sale systems and the Hass Avocado Board. After systematic preprocessing, including missing value imputation and feature normalization, the proposed model was trained and evaluated. Experimental results demonstrate that the TCN-MLP-Attention model achieves excellent predictive performance, with an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods. This research provides a scalable and effective approach for time series forecasting in agricultural markets and offers valuable insights for intelligent supply chain management and price strategy optimization.', 'abstract_zh': '随着对健康食品需求的增长，农产品价格预测变得越来越重要。哈斯牛油果作为一种高价值作物，其价格波动受到季节、区域和天气等多种因素的影响，传统预测模型往往难以处理高度非线性和动态的数据。为解决这一问题，我们提出了一种结合时序卷积网络（TCN）、多层感知机（MLP）和注意机制的混合深度学习模型——TCN-MLP-Attention架构，该模型利用TCN进行序贯特征提取，利用MLP进行非线性交互，并利用注意机制进行动态特征加权。所使用的数据集涵盖了2015年至2018年间美国哈斯牛油果销售的超过50,000条记录，包括销售量、平均价格、时间、区域、天气和品种类型等变量，数据来源于销售点系统和哈斯牛油果委员会。经过系统预处理，包括缺失值填充和特征标准化后，提出的模型进行了训练和评估。实验结果表明，TCN-MLP-Attention模型在预测性能上表现出色，RMSE为1.23，MSE为1.51，优于传统方法。该研究为农业市场的时间序列预测提供了一种可扩展和有效的方法，并为智能化供应链管理和价格策略优化提供了宝贵见解。', 'title_zh': '基于TCN-MLP-注意力架构的混合深度学习模型的鳄梨价格预测'}
{'arxiv_id': 'arXiv:2505.09868', 'title': 'Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?', 'authors': 'Tin Trung Nguyen, Jiannan Xu, Phuong-Anh Nguyen-Le, Jonathan Lazar, Donald Braman, Hal Daumé III, Zubin Jelveh', 'link': 'https://arxiv.org/abs/2505.09868', 'abstract': "Despite its U.S. constitutional foundation, the technical ``individual fairness'' criterion has not been operationalized in state or federal statutes/regulations. We conduct a human subjects experiment to address this gap, evaluating which demographic features are relevant for individual fairness evaluation of recidivism risk assessment (RRA) tools. Our analyses conclude that the individual similarity function should consider age and sex, but it should ignore race.", 'abstract_zh': '尽管基于美国宪法，技术上的“个体公平”标准并未在州或联邦法律规章中得以落实。我们通过一项人类受试者实验来弥补这一空白，评估哪些人口统计特征对于重新犯罪风险评估（RRA）工具的个体公平性评估是相关的。我们的分析认为，个体相似性函数应考虑年龄和性别，但不应考虑种族。', 'title_zh': '哪些人口统计学特征与美国再犯风险评估工具的个体公平性评估相关？'}
{'arxiv_id': 'arXiv:2505.09861', 'title': 'LiDDA: Data Driven Attribution at LinkedIn', 'authors': 'John Bencina, Erkut Aykutlug, Yue Chen, Zerui Zhang, Stephanie Sorenson, Shao Tang, Changshuai Wei', 'link': 'https://arxiv.org/abs/2505.09861', 'abstract': 'Data Driven Attribution, which assigns conversion credits to marketing interactions based on causal patterns learned from data, is the foundation of modern marketing intelligence and vital to any marketing businesses and advertising platform. In this paper, we introduce a unified transformer-based attribution approach that can handle member-level data, aggregate-level data, and integration of external macro factors. We detail the large scale implementation of the approach at LinkedIn, showcasing significant impact. We also share learning and insights that are broadly applicable to the marketing and ad tech fields.', 'abstract_zh': '基于数据驱动归因的方法，即根据从数据中学习到的因果模式为营销互动分配转化信用，是现代营销智能的基础，对任何营销业务和广告平台都至关重要。本文介绍了一种统一的基于变压器的归因方法，可以处理成员级数据、聚合级数据，并整合外部宏观因素。我们详细阐述了该方法在LinkedIn的大规模实施，并展示了其显著影响。我们还分享了广泛适用于营销和技术广告领域的学习和见解。', 'title_zh': 'LiDDA：领英驱动的数据归因'}
{'arxiv_id': 'arXiv:2505.09855', 'title': 'Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers', 'authors': 'Alexander Y. Ku, Thomas L. Griffiths, Stephanie C.Y. Chan', 'link': 'https://arxiv.org/abs/2505.09855', 'abstract': "Transformer models learn in two distinct modes: in-weights learning (IWL), encoding knowledge into model weights, and in-context learning (ICL), adapting flexibly to context without weight modification. To better understand the interplay between these learning modes, we draw inspiration from evolutionary biology's analogous adaptive strategies: genetic encoding (akin to IWL, adapting over generations and fixed within an individual's lifetime) and phenotypic plasticity (akin to ICL, enabling flexible behavioral responses to environmental cues). In evolutionary biology, environmental predictability dictates the balance between these strategies: stability favors genetic encoding, while reliable predictive cues promote phenotypic plasticity. We experimentally operationalize these dimensions of predictability and systematically investigate their influence on the ICL/IWL balance in Transformers. Using regression and classification tasks, we show that high environmental stability decisively favors IWL, as predicted, with a sharp transition at maximal stability. Conversely, high cue reliability enhances ICL efficacy, particularly when stability is low. Furthermore, learning dynamics reveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift occurs in some settings (e.g., classification with many classes), we demonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL acquisition (e.g., regression) can exhibit an initial IWL phase later yielding to ICL dominance. These findings support a relative-cost hypothesis for explaining these learning mode transitions, establishing predictability as a critical factor governing adaptive strategies in Transformers, and offering novel insights for understanding ICL and guiding training methodologies.", 'abstract_zh': 'Transformer模型以两种不同的模式学习：权重内在学习（IWL）和上下文内在学习（ICL）。借鉴进化生物学中的类似适应策略：遗传编码（类似于IWL，在代际之间稳定，并固定在一生命期内）和表型塑性（类似于ICL，能够灵活地对环境提示作出行为响应）。在进化生物学中，环境可预测性决定了这些策略之间的平衡：稳定性有利于遗传编码，而可靠的预测提示促进表型塑性。我们通过实验证明这些可预测性维度，并系统地调查它们对Transformer中ICL/IWL平衡的影响。通过回归和分类任务，我们表明，在环境高度稳定的情况下，IWL明显占据优势，特别是在最大稳定性时。相反，当稳定性较低时，高提示可靠性增强ICL的效能。此外，学习动态揭示了随任务而变的时间演变：虽然在某些情况下（例如多类别分类）会发生从ICL到IWL的经典转变，我们证明在容易的IWL（例如类别较少）或较慢的ICL获取（例如回归）的场景下，可能会出现一个早期的IWL阶段，随后转为ICL主导。这些发现支持一种相对成本假设，以解释这些学习模式转换，确立了环境可预测性作为调控Transformer中适应策略的关键因素，并为理解ICL和指导训练方法提供了新的见解。', 'title_zh': '可预测性塑造适应：从进化视角看Transformer的学习模式'}
{'arxiv_id': 'arXiv:2505.09847', 'title': 'Causal Predictive Optimization and Generation for Business AI', 'authors': 'Liyang Zhao, Olurotimi Seton, Himadeep Reddy Reddivari, Suvendu Jena, Shadow Zhao, Rachit Kumar, Changshuai Wei', 'link': 'https://arxiv.org/abs/2505.09847', 'abstract': 'The sales process involves sales functions converting leads or opportunities to customers and selling more products to existing customers. The optimization of the sales process thus is key to success of any B2B business. In this work, we introduce a principled approach to sales optimization and business AI, namely the Causal Predictive Optimization and Generation, which includes three layers: 1) prediction layer with causal ML 2) optimization layer with constraint optimization and contextual bandit 3) serving layer with Generative AI and feedback-loop for system enhancement. We detail the implementation and deployment of the system in LinkedIn, showcasing significant wins over legacy systems and sharing learning and insight broadly applicable to this field.', 'abstract_zh': '销售过程涉及将潜在客户或机会转化为实际客户，并向现有客户销售更多产品。因此，销售过程的优化对任何B2B业务的成功至关重要。本工作中，我们介绍了一种原理性的销售优化和商业AI方法，即因果预测优化与生成，包括三个层面：1) 因果机器学习的预测层；2) 约束优化和上下文Bandit的优化层；3) 生成AI和服务层及系统增强的反馈循环。我们详细介绍了该系统在LinkedIn上的实现与部署，展示了其相对于传统系统的显著优势，并广泛分享了学习和见解，适用于该领域。', 'title_zh': '因果预测优化与生成for Business AI'}
{'arxiv_id': 'arXiv:2505.09814', 'title': '$XX^{t}$ Can Be Faster', 'authors': 'Dmitry Rybin, Yushun Zhang, Zhi-Quan Luo', 'link': 'https://arxiv.org/abs/2505.09814', 'abstract': 'We present a new algorithm RXTX that computes product of matrix by its transpose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than State-of-the-Art and achieves accelerations even for small sizes of matrix $X$. The algorithm was discovered by combining Machine Learning-based search methods with Combinatorial Optimization.', 'abstract_zh': '我们提出了一种新算法RXTX，用于计算矩阵与其转置的乘积$XX^{t}$。RXTX相比现有最佳算法少用了5%的乘法和加法运算，并且即使对于矩阵$X$的小规模也能实现加速效果。该算法是通过结合基于机器学习的搜索方法与组合优化方法发现的。', 'title_zh': '$XX^{t}$可以更快。'}
{'arxiv_id': 'arXiv:2505.09796', 'title': 'Virtual Dosimetrists: A Radiotherapy Training "Flight Simulator"', 'authors': 'Skylar S. Gay, Tucker Netherton, Barbara Marquez, Raymond Mumme, Mary Gronberg, Brent Parker, Chelsea Pinnix, Sanjay Shete, Carlos Cardenas, Laurence Court', 'link': 'https://arxiv.org/abs/2505.09796', 'abstract': "Effective education in radiotherapy plan quality review requires a robust, regularly updated set of examples and the flexibility to demonstrate multiple possible planning approaches and their consequences. However, the current clinic-based paradigm does not support these needs. To address this, we have developed 'Virtual Dosimetrist' models that can both generate training examples of suboptimal treatment plans and then allow trainees to improve the plan quality through simple natural language prompts, as if communicating with a dosimetrist. The dose generation and modification process is accurate, rapid, and requires only modest resources. This work is the first to combine dose distribution prediction with natural language processing; providing a robust pipeline for both generating suboptimal training plans and allowing trainees to practice their critical plan review and improvement skills that addresses the challenges of the current clinic-based paradigm.", 'abstract_zh': '有效的放射治疗计划质量审查教育需要一套坚实且定期更新的实例和展示多种可能的计划方法及其后果的灵活性。然而，当前的临床 paradigm 并不支持这些需求。为了解决这一问题，我们开发了“虚拟剂量师”模型，该模型既能生成亚优治疗计划的培训实例，又能通过简单的自然语言提示让受训者改进计划质量，仿佛在与剂量师交流。剂量的生成和修改过程准确、迅速且只需 modest 的资源。这项工作首次将剂量分布预测与自然语言处理相结合，提供了一个坚实的工作流，既可以生成亚优训练计划，又可以让受训者练习其关键的计划审查和改进技能，从而解决当前临床 paradigm 的挑战。', 'title_zh': '虚拟剂量师：放射治疗培训“飞行模拟器”'}
{'arxiv_id': 'arXiv:2505.09794', 'title': 'Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques', 'authors': 'J. Moreno-Casanova, J.M. Auñón, A. Mártinez-Pérez, M.E. Pérez-Martínez, M.E. Gas-López', 'link': 'https://arxiv.org/abs/2505.09794', 'abstract': "Research projects, including those focused on cancer, rely on the manual extraction of information from clinical reports. This process is time-consuming and prone to errors, limiting the efficiency of data-driven approaches in healthcare. To address these challenges, Natural Language Processing (NLP) offers an alternative for automating the extraction of relevant data from electronic health records (EHRs). In this study, we focus on lung and breast cancer due to their high incidence and the significant impact they have on public health. Early detection and effective data management in both types of cancer are crucial for improving patient outcomes. To enhance the accuracy and efficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels at identifying relevant entities in clinical texts and converting them into standardized formats such as SNOMED and OMOP. uQuery not only detects and classifies entities but also associates them with contextual information, including negated entities, temporal aspects, and patient-related details. In this work, we explore the use of NLP techniques, specifically Named Entity Recognition (NER), to automatically identify and extract key clinical information from EHRs related to these two cancers. A dataset from Health Research Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast cancer and 400 lung cancer reports, was used, with eight clinical entities manually labeled using the Doccano platform. To perform NER, we fine-tuned the bsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained in Spanish. Fine-tuning was performed using the Transformers architecture, enabling accurate recognition of clinical entities in these cancer types. Our results demonstrate strong overall performance, particularly in identifying entities like MET and PAT, although challenges remain with less frequent entities like EVOL.", 'abstract_zh': '基于自然语言处理的肺癌和乳腺癌相关临床报告中关键临床信息的自动提取', 'title_zh': '使用NLP技术在肺癌和乳腺癌报告中自动检测临床实体'}
{'arxiv_id': 'arXiv:2505.09766', 'title': "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion", 'authors': 'Roberto Ponciroli', 'link': 'https://arxiv.org/abs/2505.09766', 'abstract': "This work presents a methodology for reconstructing the spatial distribution of the neutron flux in a nuclear reactor, leveraging real-time measurements obtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation inherently defines the problem of estimating a scalar field within a domain based on boundary data, making it a natural mathematical framework for this task. The main challenge lies in deriving the Green's function specific to the domain and the neutron diffusion process. While analytical solutions for Green's functions exist for simplified geometries, their derivation of complex, heterogeneous domains-such as a nuclear reactor-requires a numerical approach. The objective of this work is to demonstrate the well-posedness of the data-driven Green's function approximation by formulating and solving the K-H equation as an inverse problem. After establishing the symmetry properties that the Green's function must satisfy, the K-H equation is derived from the one-speed neutron diffusion model. This is followed by a comprehensive description of the procedure for interpreting sensor readings and implementing the neutron flux reconstruction algorithm. Finally, the existence and uniqueness of the Green's function inferred from the sampled data are demonstrated, ensuring the reliability of the proposed method and its predictions.", 'abstract_zh': "利用核反应堆外探测器的实时测量重建中子通量的空间分布的方法学：基于边界数据的Kirchhoff-Helmholtz方程及其在Green's函数数据驱动逼近中的应用", 'title_zh': '关于通过Kirchhoff-Helmholtz方程重建格林函数的一速中子扩散问题适定性研究'}
{'arxiv_id': 'arXiv:2505.09747', 'title': 'Healthy Distrust in AI systems', 'authors': 'Benjamin Paaßen, Suzana Alpsancar, Tobias Matzner, Ingrid Scharlau', 'link': 'https://arxiv.org/abs/2505.09747', 'abstract': 'Under the slogan of trustworthy AI, much of contemporary AI research is focused on designing AI systems and usage practices that inspire human trust and, thus, enhance adoption of AI systems. However, a person affected by an AI system may not be convinced by AI system design alone -- neither should they, if the AI system is embedded in a social context that gives good reason to believe that it is used in tension with a person\'s interest. In such cases, distrust in the system may be justified and necessary to build meaningful trust in the first place. We propose the term "healthy distrust" to describe such a justified, careful stance towards certain AI usage practices. We investigate prior notions of trust and distrust in computer science, sociology, history, psychology, and philosophy, outline a remaining gap that healthy distrust might fill and conceptualize healthy distrust as a crucial part for AI usage that respects human autonomy.', 'abstract_zh': '在可信AI的口号下，当代许多AI研究集中在设计能够激发人类信任的AI系统和使用实践，从而提高AI系统的采用率。然而，如果AI系统嵌入的社会环境让人怀疑其与个人利益相冲突，受影响的人未必会被AI系统的设计说服——在这种情况下，对系统的不信任可能是合理的，甚至必要的，以此为基础才能建立有意义的信任。我们提出“健康不信任”这一术语，描述对某些AI使用实践采取的一种合理的慎重态度。我们考察了计算机科学、社会学、历史学、心理学和哲学中关于信任和不信任的先前概念，指出健康不信任可以填补的一个空白，并从尊重人类自主性的角度概念化健康不信任，作为AI使用的重要组成部分。', 'title_zh': 'AI系统的健康怀疑'}
{'arxiv_id': 'arXiv:2505.09742', 'title': 'A Generative Neural Annealer for Black-Box Combinatorial Optimization', 'authors': 'Yuan-Hang Zhang, Massimiliano Di Ventra', 'link': 'https://arxiv.org/abs/2505.09742', 'abstract': 'We propose a generative, end-to-end solver for black-box combinatorial optimization that emphasizes both sample efficiency and solution quality on NP problems. Drawing inspiration from annealing-based algorithms, we treat the black-box objective as an energy function and train a neural network to model the associated Boltzmann distribution. By conditioning on temperature, the network captures a continuum of distributions--from near-uniform at high temperatures to sharply peaked around global optima at low temperatures--thereby learning the structure of the energy landscape and facilitating global optimization. When queries are expensive, the temperature-dependent distributions naturally enable data augmentation and improve sample efficiency. When queries are cheap but the problem remains hard, the model learns implicit variable interactions, effectively "opening" the black box. We validate our approach on challenging combinatorial tasks under both limited and unlimited query budgets, showing competitive performance against state-of-the-art black-box optimizers.', 'abstract_zh': '我们提出了一种端到端的生成型求解器，用于黑箱组合优化问题，强调在NP问题上的样本效率和解的质量。该求解器借鉴了退火算法的思想，将黑箱目标函数视为能量函数，并训练神经网络来建模相应的玻尔兹曼分布。通过温度调节，网络可以捕捉从高温下的接近均匀分布到低温时围绕全局极值的尖峰分布的连续分布，从而学习能量 landscape 的结构并促进全局优化。当查询昂贵时，温度依赖的分布自然地支持数据增强并提高样本效率；当查询便宜但问题仍然复杂时，模型学习隐含的变量交互，有效地“开启”黑箱。我们在有限和无限查询预算下的挑战性组合任务上验证了该方法，显示出与最先进的黑箱优化器竞争的性能。', 'title_zh': '生成神经退火器用于黑盒组合优化'}
{'arxiv_id': 'arXiv:2505.09733', 'title': 'Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data', 'authors': 'Alpaslan Gokcen, Ali Boyaci', 'link': 'https://arxiv.org/abs/2505.09733', 'abstract': 'Federated learning (FL) presents an effective solution for collaborative model training while maintaining data privacy across decentralized client datasets. However, data quality issues such as noisy labels, missing classes, and imbalanced distributions significantly challenge its effectiveness. This study proposes a federated learning methodology that systematically addresses data quality issues, including noise, class imbalance, and missing labels. The proposed approach systematically enhances data integrity through adaptive noise cleaning, collaborative conditional GAN-based synthetic data generation, and robust federated model training. Experimental evaluations conducted on benchmark datasets (MNIST and Fashion-MNIST) demonstrate significant improvements in federated model performance, particularly macro-F1 Score, under varying noise and class imbalance conditions. Additionally, the proposed framework carefully balances computational feasibility and substantial performance gains, ensuring practicality for resource constrained edge devices while rigorously maintaining data privacy. Our results indicate that this method effectively mitigates common data quality challenges, providing a robust, scalable, and privacy compliant solution suitable for diverse real-world federated learning scenarios.', 'abstract_zh': '联邦学习（FL）提供了一种维护跨去中心化客户端数据集数据隐私的同时进行协作模型训练的有效解决方案。然而，数据质量问题，如噪声标签、缺失类别以及分布不均衡，显著影响其效果。本研究提出了一种系统性解决数据质量问题（包括噪声、类别不均衡和缺失标签）的联邦学习方法。该提出的方法通过自适应噪声清洗、协作条件GAN基础的合成数据生成以及稳健的联邦模型训练系统性提升数据完整性。在基准数据集（MNIST和Fashion-MNIST）上的实验评估表明，在各种噪声和类别不均衡条件下，该方法显著提高了联邦模型性能，特别是宏F1分数。此外，所提出的框架在保持数据隐私的同时，谨慎平衡计算可行性和显著的性能提升，确保了对资源受限的边缘设备的实用性。我们的结果表明，该方法有效地缓解了常见的数据质量问题，提供了一种稳健、可扩展且符合隐私要求的解决方案，适用于各种实际的联邦学习场景。', 'title_zh': '在噪声和不完整数据下的鲁棒 federated 学习：基于置信加权过滤和 GAN 生成的完成'}
{'arxiv_id': 'arXiv:2505.09716', 'title': 'Out-of-distribution generalisation is hard: evidence from ARC-like tasks', 'authors': 'George Dimitriadis. Spyridon Samothrakis', 'link': 'https://arxiv.org/abs/2505.09716', 'abstract': 'Out-of-distribution (OOD) generalisation is considered a hallmark of human and animal intelligence. To achieve OOD through composition, a system must discover the environment-invariant properties of experienced input-output mappings and transfer them to novel inputs. This can be realised if an intelligent system can identify appropriate, task-invariant, and composable input features, as well as the composition methods, thus allowing it to act based not on the interpolation between learnt data points but on the task-invariant composition of those features. We propose that in order to confirm that an algorithm does indeed learn compositional structures from data, it is not enough to just test on an OOD setup, but one also needs to confirm that the features identified are indeed compositional. We showcase this by exploring two tasks with clearly defined OOD metrics that are not OOD solvable by three commonly used neural networks: a Multi-Layer Perceptron (MLP), a Convolutional Neural Network (CNN), and a Transformer. In addition, we develop two novel network architectures imbued with biases that allow them to be successful in OOD scenarios. We show that even with correct biases and almost perfect OOD performance, an algorithm can still fail to learn the correct features for compositional generalisation.', 'abstract_zh': 'Out-of-distribution泛化是人类和动物智能的标志。通过组合实现Out-of-distribution能力，系统必须发现环境不变的输入-输出映射属性，并将其转移到新的输入中。这可以通过智能系统识别适当的、任务不变的和可组合的输入特征以及组合方法来实现，从而使系统不仅基于学习数据点之间的内插，而是基于这些特征的任务不变组合来进行操作。我们提出，为了确认算法确实从数据中学习了组合结构，除了在Out-of-distribution设置下进行测试外，还需要确认所识别的特征确实是组合的。我们通过探索两个具有明确定义的Out-of-distribution指标任务来展示这一点，这些任务无法通过三种常用神经网络（多层感知机、卷积神经网络和变换器）解决。此外，我们还开发了两种具有偏见的新网络架构，使它们在Out-of-distribution场景中取得成功。我们显示，即使具有正确的偏见和几乎完美的Out-of-distribution性能，算法仍可能无法学习正确的特征以实现组合泛化。', 'title_zh': '领域外泛化很难：来自ARC类似任务的证据'}
{'arxiv_id': 'arXiv:2505.09704', 'title': 'Energy-Efficient Federated Learning for AIoT using Clustering Methods', 'authors': 'Roberto Pereira, Fernanda Famá, Charalampos Kalalas, Paolo Dini', 'link': 'https://arxiv.org/abs/2505.09704', 'abstract': 'While substantial research has been devoted to optimizing model performance, convergence rates, and communication efficiency, the energy implications of federated learning (FL) within Artificial Intelligence of Things (AIoT) scenarios are often overlooked in the existing literature. This study examines the energy consumed during the FL process, focusing on three main energy-intensive processes: pre-processing, communication, and local learning, all contributing to the overall energy footprint. We rely on the observation that device/client selection is crucial for speeding up the convergence of model training in a distributed AIoT setting and propose two clustering-informed methods. These clustering solutions are designed to group AIoT devices with similar label distributions, resulting in clusters composed of nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity often encountered in real-world distributed learning applications. Throughout extensive numerical experimentation, we demonstrate that our clustering strategies typically achieve high convergence rates while maintaining low energy consumption when compared to other recent approaches available in the literature.', 'abstract_zh': '尽管已有大量的研究致力于优化模型性能、收敛速率和通信效率，现有文献往往忽视了在人工智能物联网（AIoT）场景下联邦学习（FL）的能耗问题。本研究关注FL过程中三个主要的能耗密集型过程——预处理、通信和本地学习，以评估其对整体能耗的影响。我们注意到，在分布式AIoT环境中，设备/客户端的选择对于加快模型训练的收敛速度至关重要，并提出两种基于聚类的方法。这些聚类解决方案旨在将具有类似标签分布的AIoT设备分组为高度异构的簇。因此，我们的方法可以缓解现实世界分布式学习应用中常见的异构性问题。通过广泛的数值实验，我们证明了与现有文献中的其他方法相比，我们的聚类策略通常能够在保持低能耗的情况下实现较高的收敛速率。', 'title_zh': '基于聚类方法的能效联邦学习在AIoT中应用'}
{'arxiv_id': 'arXiv:2505.09661', 'title': 'Introducing voice timbre attribute detection', 'authors': 'Jinghao He, Zhengyan Sheng, Liping Chen, Kong Aik Lee, Zhen-Hua Ling', 'link': 'https://arxiv.org/abs/2505.09661', 'abstract': 'This paper focuses on explaining the timbre conveyed by speech signals and introduces a task termed voice timbre attribute detection (vTAD). In this task, voice timbre is explained with a set of sensory attributes describing its human perception. A pair of speech utterances is processed, and their intensity is compared in a designated timbre descriptor. Moreover, a framework is proposed, which is built upon the speaker embeddings extracted from the speech utterances. The investigation is conducted on the VCTK-RVA dataset. Experimental examinations on the ECAPA-TDNN and FACodec speaker encoders demonstrated that: 1) the ECAPA-TDNN speaker encoder was more capable in the seen scenario, where the testing speakers were included in the training set; 2) the FACodec speaker encoder was superior in the unseen scenario, where the testing speakers were not part of the training, indicating enhanced generalization capability. The VCTK-RVA dataset and open-source code are available on the website this https URL.', 'abstract_zh': '本文专注于解释语音信号中的音色，并引入了一项称为语音音色属性检测（vTAD）的任务。在该任务中，语音音色通过描述其人类感知的一组感官属性来进行解释。一对语音片段被 processing，并在指定的音色描述符中比较其强度。此外，提出了一种框架，该框架基于从语音片段中提取的说话人嵌入。研究在VCTK-RVA数据集上进行。对ECAPA-TDNN和FACodec说话人编码器的实验检查表明：1) 在测试说话人在训练集中出现的场景中，ECAPA-TDNN说话人编码器更具优势；2) 在测试说话人未包含在训练集中的场景中，FACodec说话人编码器表现更佳，表明其具有更强的泛化能力。VCTK-RVA数据集和开源代码可在以下网址获取：this https URL。', 'title_zh': '引入语音音色属性检测'}
{'arxiv_id': 'arXiv:2505.09653', 'title': 'Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation', 'authors': 'Samuel Yen-Chi Chen, Chen-Yu Liu, Kuan-Cheng Chen, Wei-Jia Huang, Yen-Jui Chang, Wei-Hao Huang', 'link': 'https://arxiv.org/abs/2505.09653', 'abstract': 'The rapid advancements in quantum computing (QC) and machine learning (ML) have led to the emergence of quantum machine learning (QML), which integrates the strengths of both fields. Among QML approaches, variational quantum circuits (VQCs), also known as quantum neural networks (QNNs), have shown promise both empirically and theoretically. However, their broader adoption is hindered by reliance on quantum hardware during inference. Hardware imperfections and limited access to quantum devices pose practical challenges. To address this, the Quantum-Train (QT) framework leverages the exponential scaling of quantum amplitudes to generate classical neural network parameters, enabling inference without quantum hardware and achieving significant parameter compression. Yet, designing effective quantum circuit architectures for such quantum-enhanced neural programmers remains non-trivial and often requires expertise in quantum information science. In this paper, we propose an automated solution using differentiable optimization. Our method jointly optimizes both conventional circuit parameters and architectural parameters in an end-to-end manner via automatic differentiation. We evaluate the proposed framework on classification, time-series prediction, and reinforcement learning tasks. Simulation results show that our method matches or outperforms manually designed QNN architectures. This work offers a scalable and automated pathway for designing QNNs that can generate classical neural network parameters across diverse applications.', 'abstract_zh': '快速发展的量子计算和机器学习促进了量子机器学习（QML）的 emergence，QML 综合了两者的优点。在 QML 方法中，变分量子电路（VQCs），也称为量子神经网络（QNNs），在理论和实践上都显示出潜力。然而，由于推理过程中依赖量子硬件，其广泛应用受到限制。硬件缺陷和量子设备访问受限带来了实际挑战。为此，Quantum-Train（QT）框架利用量子振幅的指数级扩展生成经典神经网络参数，从而在没有量子硬件的情况下进行推理，并实现显著的参数压缩。然而，设计有效的量子电路架构以适应这些增强的量子神经编程器仍然具有挑战性，通常需要量子信息科学方面的专业知识。在这项研究中，我们提出了一种基于可微优化的自动化解决方案。我们的方法通过自动微分以端到端的方式同时优化传统电路参数和架构参数。我们评估了该框架在分类、时间序列预测和强化学习任务上的性能。仿真结果表明，我们的方法能够匹配甚至超越人工设计的QNN架构。这项工作为设计能够在多种应用中生成经典神经网络参数的QNN提供了可扩展和自动化的途径。', 'title_zh': '使用量子增强神经网络参数生成中的可微量子架构搜索'}
{'arxiv_id': 'arXiv:2505.09646', 'title': 'Temporal Interception and Present Reconstruction: A Cognitive-Signal Model for Human and AI Decision Making', 'authors': 'Carmel Mary Esther A', 'link': 'https://arxiv.org/abs/2505.09646', 'abstract': 'This paper proposes a novel theoretical model to explain how the human mind and artificial intelligence can approach real-time awareness by reducing perceptual delays. By investigating cosmic signal delay, neurological reaction times, and the ancient cognitive state of stillness, we explore how one may shift from reactive perception to a conscious interface with the near future. This paper introduces both a physical and cognitive model for perceiving the present not as a linear timestamp, but as an interference zone where early-arriving cosmic signals and reactive human delays intersect. We propose experimental approaches to test these ideas using human neural observation and neuro-receptive extensions. Finally, we propose a mathematical framework to guide the evolution of AI systems toward temporally efficient, ethically sound, and internally conscious decision-making processes', 'abstract_zh': '本文提出了一种新的理论模型，以解释人类思维和人工智能如何通过减少感知延迟来接近实时意识。通过对 cosmic 信号延迟、神经反应时间及古代静谧认知状态的研究，我们探索了如何从被动感知转变为与近未来的自觉接口。本文介绍了物理和认知模型，将当前时刻视为早期到达的 cosmic 信号与人类反应延迟交集的干扰区，而非线性时间戳。我们提出实验方法，利用人类神经观察和神经感知扩展来测试这些想法。最后，我们提出了一种数学框架，指导 AI 系统向时间高效、合乎伦理和内在自觉的决策过程演化。', 'title_zh': '时间截获与现时重构：人类与AI决策的认知-信号模型'}
{'arxiv_id': 'arXiv:2505.09624', 'title': 'Neurophysiologically Realistic Environment for Comparing Adaptive Deep Brain Stimulation Algorithms in Parkinson Disease', 'authors': 'Ekaterina Kuzmina, Dmitrii Kriukov, Mikhail Lebedev, Dmitry V. Dylov', 'link': 'https://arxiv.org/abs/2505.09624', 'abstract': 'Adaptive deep brain stimulation (aDBS) has emerged as a promising treatment for Parkinson disease (PD). In aDBS, a surgically placed electrode sends dynamically altered stimuli to the brain based on neurophysiological feedback: an invasive gadget that limits the amount of data one could collect for optimizing the control offline. As a consequence, a plethora of synthetic models of PD and those of the control algorithms have been proposed. Herein, we introduce the first neurophysiologically realistic benchmark for comparing said models. Specifically, our methodology covers not only conventional basal ganglia circuit dynamics and pathological oscillations, but also captures 15 previously dismissed physiological attributes, such as signal instabilities and noise, neural drift, electrode conductance changes and individual variability - all modeled as spatially distributed and temporally registered features via beta-band activity in the brain and a feedback. Furthermore, we purposely built our framework as a structured environment for training and evaluating deep reinforcement learning (RL) algorithms, opening new possibilities for optimizing aDBS control strategies and inviting the machine learning community to contribute to the emerging field of intelligent neurostimulation interfaces.', 'abstract_zh': '自适应深脑刺激（aDBS）已成为帕金森病（PD）治疗的有前景的方法。在自适应深脑刺激中，植入的电极根据神经生理反馈发送动态改变的刺激到大脑：一个侵入性的装置，限制了可收集的数据量以进行离线优化控制。因此，提出了许多帕金森病及其控制算法的合成模型。在此，我们介绍了第一个神经生理学上现实的基准，用于比较这些模型。具体来说，我们的方法不仅涵盖了传统的基底 ganglia 电路动力学和病理性振荡，还捕捉了15种先前被忽略的生理特性，如信号不稳定性和噪声、神经漂移、电极电导变化和个体差异——所有这些均通过脑部和反馈的时空分布特征以β频带活动的形式建模。我们特意构建了框架作为训练和评估深度强化学习（RL）算法的结构化环境，为优化 aDBS 控制策略开辟了新的可能性，并邀请机器学习社区为智能神经刺激界面这一新兴领域做出贡献。', 'title_zh': 'Parkinson病中适应性深脑刺激算法比较的神经生理学现实环境'}
{'arxiv_id': 'arXiv:2505.09619', 'title': 'Predictive Models for Chronic Heart Failure', 'authors': 'Pietro Cassieri, Aiman Faiz, Anna Maria De Roberto, Claudio Pascarelli, Gianvito Mitrano, Gianluca Fimiani, Marina Garofano, Christiancarmine Esposito, Genoveffa Tortora, Alessia Bramanti, Giuseppe Scanniello', 'link': 'https://arxiv.org/abs/2505.09619', 'abstract': 'The management of chronic Heart Failure (HF) presents significant challenges in modern healthcare, requiring continuous monitoring, early detection of exacerbations, and personalized treatment strategies. In this paper, we present a predictive model founded on Machine Learning (ML) techniques to identify patients at HF risk. This model is an ensemble learning approach, a modified stacking technique, that uses two specialized models leveraging clinical and echocardiographic features and then a meta-model to combine the predictions of these two models. We initially assess the model on a real dataset and the obtained results suggest that it performs well in the stratification of patients at HR risk. Specifically, we obtained high sensitivity (95\\%), ensuring that nearly all high-risk patients are identified. As for accuracy, we obtained 84\\%, which can be considered moderate in some ML contexts. However, it is acceptable given our priority of identifying patients at risk of HF because they will be asked to participate in the telemonitoring program of the PrediHealth research project on which some of the authors of this paper are working. The initial findings also suggest that ML-based risk stratification models can serve as valuable decision-support tools not only in the PrediHealth project but also for healthcare professionals, aiding in early intervention and personalized patient management. To have a better understanding of the value and of potentiality of our predictive model, we also contrasted its results with those obtained by using three baseline models. The preliminary results indicate that our predictive model outperforms these baselines that flatly consider features, \\ie not grouping them in clinical and echocardiographic features.', 'abstract_zh': '现代医疗中慢性心力衰竭的管理呈现出显著的挑战，要求持续监测、早期检测恶化情况和个人化治疗策略。本文提出了一种基于机器学习技术的预测模型，用于识别心力衰竭风险患者。该模型采用集成学习方法，通过修改后的堆叠技术，使用两种专门模型分别利用临床和超声心动图特征，并通过元模型将这两种模型的预测结果结合。我们首先在实际数据集上评估了该模型，结果表明，它在区分心力衰竭风险患者方面表现良好。具体而言，我们获得了95%的高灵敏度，确保几乎识别出所有高风险患者。对于准确性，我们获得了84%，在某些机器学习背景下可被视为中等。然而，考虑到我们优先识别心力衰竭高风险患者，以便他们参与PrediHealth研究项目的远程监测计划，这一准确性是可以接受的。初步发现还表明，基于机器学习的风险分层模型可以作为有价值的决策支持工具，不仅在PrediHealth项目中，也在其他医疗保健专业人员中，帮助早期干预和个性化患者管理。为了更好地理解我们预测模型的价值及其潜力，我们还将其结果与使用三种基线模型获得的结果进行了对比。初步结果表明，我们的预测模型优于这些仅基于特征不分组的基线模型。', 'title_zh': '慢性心力衰竭的预测模型'}
{'arxiv_id': 'arXiv:2505.09616', 'title': 'SpecWav-Attack: Leveraging Spectrogram Resizing and Wav2Vec 2.0 for Attacking Anonymized Speech', 'authors': 'Yuqi Li, Yuanzhong Zheng, Zhongtian Guo, Yaoxuan Wang, Jianjun Yin, Haojun Fei', 'link': 'https://arxiv.org/abs/2505.09616', 'abstract': 'This paper presents SpecWav-Attack, an adversarial model for detecting speakers in anonymized speech. It leverages Wav2Vec2 for feature extraction and incorporates spectrogram resizing and incremental training for improved performance. Evaluated on librispeech-dev and librispeech-test, SpecWav-Attack outperforms conventional attacks, revealing vulnerabilities in anonymized speech systems and emphasizing the need for stronger defenses, benchmarked against the ICASSP 2025 Attacker Challenge.', 'abstract_zh': 'SpecWav-Attack：一种用于检测匿名语音中演讲者的对抗模型', 'title_zh': 'SpecWav-攻击：利用 spectrogram 缩放和 Wav2Vec 2.0 对匿名语音进行攻击'}
{'arxiv_id': 'arXiv:2505.09593', 'title': 'Online Isolation Forest', 'authors': 'Filippo Leveni, Guilherme Weigert Cassales, Bernhard Pfahringer, Albert Bifet, Giacomo Boracchi', 'link': 'https://arxiv.org/abs/2505.09593', 'abstract': 'The anomaly detection literature is abundant with offline methods, which require repeated access to data in memory, and impose impractical assumptions when applied to a streaming context. Existing online anomaly detection methods also generally fail to address these constraints, resorting to periodic retraining to adapt to the online context. We propose Online-iForest, a novel method explicitly designed for streaming conditions that seamlessly tracks the data generating process as it evolves over time. Experimental validation on real-world datasets demonstrated that Online-iForest is on par with online alternatives and closely rivals state-of-the-art offline anomaly detection techniques that undergo periodic retraining. Notably, Online-iForest consistently outperforms all competitors in terms of efficiency, making it a promising solution in applications where fast identification of anomalies is of primary importance such as cybersecurity, fraud and fault detection.', 'abstract_zh': 'Online-iForest：一种专门设计用于流式环境的在线异步检测方法及其实验验证', 'title_zh': '在线隔离森林'}
{'arxiv_id': 'arXiv:2410.13778', 'title': 'Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree', 'authors': 'Michelangelo Olmo Nogara Notarianni, Filippo Leveni, Diego Stucchi, Luca Frittoli, Giacomo Boracchi', 'link': 'https://arxiv.org/abs/2410.13778', 'abstract': 'We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA), a non-parametric change-detection algorithm that combines the Kernel-QuantTree (KQT) histogram and the EWMA statistic to monitor multivariate data streams online. The resulting monitoring scheme is very flexible, since histograms can be used to model any stationary distribution, and practical, since the distribution of test statistics does not depend on the distribution of datastream in stationary conditions (non-parametric monitoring). KQT-EWMA enables controlling false alarms by operating at a pre-determined Average Run Length ($ARL_0$), which measures the expected number of stationary samples to be monitored before triggering a false alarm. The latter peculiarity is in contrast with most non-parametric change-detection tests, which rarely can control the $ARL_0$ a priori. Our experiments on synthetic and real-world datasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving detection delays comparable to or lower than state-of-the-art methods designed to work in the same conditions.', 'abstract_zh': '基于Kernel-QuantTree指数加权移动平均的非参数变化检测算法（KQT-EWMA）', 'title_zh': '多变量数据流中的变化检测：基于Kernel-QuantTree的在线分析'}
