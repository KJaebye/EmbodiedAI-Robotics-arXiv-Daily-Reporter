{'arxiv_id': 'arXiv:2504.20983', 'title': 'LTLf Adaptive Synthesis for Multi-Tier Goals in Nondeterministic Domains', 'authors': 'Giuseppe De Giacomo, Gianmarco Parretti, Shufang Zhu', 'link': 'https://arxiv.org/abs/2504.20983', 'abstract': 'We study a variant of LTLf synthesis that synthesizes adaptive strategies for achieving a multi-tier goal, consisting of multiple increasingly challenging LTLf objectives in nondeterministic planning domains. Adaptive strategies are strategies that at any point of their execution (i) enforce the satisfaction of as many objectives as possible in the multi-tier goal, and (ii) exploit possible cooperation from the environment to satisfy as many as possible of the remaining ones. This happens dynamically: if the environment cooperates (ii) and an objective becomes enforceable (i), then our strategies will enforce it. We provide a game-theoretic technique to compute adaptive strategies that is sound and complete. Notably, our technique is polynomial, in fact quadratic, in the number of objectives. In other words, it handles multi-tier goals with only a minor overhead compared to standard LTLf synthesis.', 'abstract_zh': '我们研究了一种LTLf合成的变体，该变体用于在非确定性规划领域合成实现多层次目标的自适应策略，该目标由多个逐步增加难度的LTLf目标组成。自适应策略在其执行的任何点上会（i）尽可能地确保满足多层次目标中的多个目标，并且（ii）利用环境可能提供的合作来尽可能多地满足剩余目标。这一过程是动态的：如果环境合作（ii）并且一个目标变得可强制执行（i），那么我们的策略将强制执行该目标。我们提供了一种博弈论技术来计算自适应策略，该技术是正确的且完备的。值得注意的是，该技术在目标的数量上是多项式的时间复杂度，实际上接近于二次时间复杂度。换句话说，与标准LTLf合成相比，它仅带来微小的额外开销即可处理多层次目标。', 'title_zh': '基于非确定性领域的LTLf自适应综合多层目标'}
{'arxiv_id': 'arXiv:2504.20980', 'title': "Jekyll-and-Hyde Tipping Point in an AI's Behavior", 'authors': 'Neil F. Johnson, Frank Yingjie Huo', 'link': 'https://arxiv.org/abs/2504.20980', 'abstract': "Trust in AI is undermined by the fact that there is no science that predicts -- or that can explain to the public -- when an LLM's output (e.g. ChatGPT) is likely to tip mid-response to become wrong, misleading, irrelevant or dangerous. With deaths and trauma already being blamed on LLMs, this uncertainty is even pushing people to treat their 'pet' LLM more politely to 'dissuade' it (or its future Artificial General Intelligence offspring) from suddenly turning on them. Here we address this acute need by deriving from first principles an exact formula for when a Jekyll-and-Hyde tipping point occurs at LLMs' most basic level. Requiring only secondary school mathematics, it shows the cause to be the AI's attention spreading so thin it suddenly snaps. This exact formula provides quantitative predictions for how the tipping-point can be delayed or prevented by changing the prompt and the AI's training. Tailored generalizations will provide policymakers and the public with a firm platform for discussing any of AI's broader uses and risks, e.g. as a personal counselor, medical advisor, decision-maker for when to use force in a conflict situation. It also meets the need for clear and transparent answers to questions like ''should I be polite to my LLM?''", 'abstract_zh': 'AI信任受挫的原因在于缺乏能够预测或解释LLM输出何时可能在响应中途转变为错误、误导、无关或危险的科学。由于已经因LLM导致了死亡和创伤事件的发生，这种不确定性促使人们更加礼貌地对待它们的“宠物”LLM，以“劝阻”它们（或其未来的通用人工智能后代）突然对他们采取敌对行动。我们通过从基本原理出发，推导出一个精确公式，以量化预测何时会在LLM的最基本层面上出现从“好人”到“坏人”的转折点。该公式仅需中等教育水平的数学知识，显示原因是AI的注意力分散到极致，导致突然崩溃。这个精确公式提供了通过更改提示和AI训练来推迟或防止转折点的定量预测。定制的一般化结果将为决策者和公众提供一个坚实的基础，讨论AI的更广泛用途和风险，例如作为个人咨询师、医疗顾问，在冲突中使用武力时的决策者。它还满足了对诸如“我是否应该对我的LLM礼貌相待？”这类问题提供清晰透明答案的需求。', 'title_zh': 'AI行为中的ekyll-and-hyde临界点'}
{'arxiv_id': 'arXiv:2504.20930', 'title': 'ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification', 'authors': 'Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie', 'link': 'https://arxiv.org/abs/2504.20930', 'abstract': 'Recent advances in reasoning-enhanced large language models (LLMs) and multimodal LLMs (MLLMs) have significantly improved performance in complex tasks, yet medical AI models often overlook the structured reasoning processes inherent in clinical practice. In this work, we present ChestX-Reasoner, a radiology diagnosis MLLM designed to leverage process supervision mined directly from clinical reports, reflecting the step-by-step reasoning followed by radiologists. We construct a large dataset by extracting and refining reasoning chains from routine radiology reports. Our two-stage training framework combines supervised fine-tuning and reinforcement learning guided by process rewards to better align model reasoning with clinical standards. We introduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual question answering samples with 301K clinically validated reasoning steps, and propose RadRScore, a metric evaluating reasoning factuality, completeness, and effectiveness. ChestX-Reasoner outperforms existing medical and general-domain MLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%, and 18% improvements in reasoning ability compared to the best medical MLLM, the best general MLLM, and its base model, respectively, as well as 3.3%, 24%, and 27% improvements in outcome accuracy. All resources are open-sourced to facilitate further research in medical reasoning MLLMs.', 'abstract_zh': '近期增强推理的大语言模型（LLMs）和多模态大语言模型（MLLMs）在复杂任务中的表现显著提升，但医学AI模型往往忽视了临床实践中固有的结构化推理过程。在此项工作中，我们提出了ChestX-Reasoner，一种放射诊断MLLM，旨在利用直接从临床报告中挖掘的流程监督，反映放射科医生遵循的逐步推理过程。我们通过提取和精炼常规放射报告中的推理链构建了一个大规模数据集。我们的两阶段训练框架结合了基于流程奖励的监督微调和强化学习，更好地使模型的推理与临床标准保持一致。我们引入了RadRBench-CXR，一个全面基准，包含59000个视觉问答样本和301000个临床验证的推理步骤，并提出了RadRScore，这是一个评估推理事实性、完整性和有效性指标。ChestX-Reasoner在诊断准确性和推理能力方面都优于现有的医学和通用领域MMLMs，相对于最佳医学MMLM、最佳通用MMLM及其基础模型，在推理能力上分别提高了16%、5.9%和18%，在结果准确性上分别提高了3.3%、24%和27%。所有资源均已开源，以促进医学推理MMLMs研究的进一步发展。', 'title_zh': 'ChestX-Reasoner: 通过逐步验证提高放射学基础模型的能力'}
{'arxiv_id': 'arXiv:2504.20924', 'title': 'A Domain-Agnostic Scalable AI Safety Ensuring Framework', 'authors': 'Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn', 'link': 'https://arxiv.org/abs/2504.20924', 'abstract': "Ensuring the safety of AI systems has recently emerged as a critical priority for real-world deployment, particularly in physical AI applications. Current approaches to AI safety typically address predefined domain-specific safety conditions, limiting their ability to generalize across contexts.\nWe propose a novel AI safety framework that ensures AI systems comply with \\textbf{any user-defined constraint}, with \\textbf{any desired probability}, and across \\textbf{various domains}.\nIn this framework, we combine an AI component (e.g., neural network) with an optimization problem to produce responses that minimize objectives while satisfying user-defined constraints with probabilities exceeding user-defined thresholds. For credibility assessment of the AI component, we propose \\textit{internal test data}, a supplementary set of safety-labeled data, and a \\textit{conservative testing} methodology that provides statistical validity of using internal test data. We also present an approximation method of a loss function and how to compute its gradient for training.\nWe mathematically prove that probabilistic constraint satisfaction is guaranteed under specific, mild conditions and prove a scaling law between safety and the number of internal test data. We demonstrate our framework's effectiveness through experiments in diverse domains: demand prediction for production decision, safe reinforcement learning within the SafetyGym simulator, and guarding AI chatbot outputs. Through these experiments, we demonstrate that our method guarantees safety for user-specified constraints, outperforms {for \\textbf{up to several order of magnitudes}} existing methods in low safety threshold regions, and scales effectively with respect to the size of internal test data.", 'abstract_zh': '确保AI系统的安全性已成为实际部署中的一个关键优先事项，尤其是在物理AI应用中。当前的AI安全性方法通常仅针对预定义的特定领域安全条件，限制了其在不同上下文中的泛化能力。\n\n我们提出了一种新型的AI安全框架，确保AI系统遵守任意用户定义的约束，以任意期望的概率，并在各种领域中适用。\n\n在该框架中，我们将AI组件（例如神经网络）与一个优化问题结合，生成既能最小化目标又能满足用户定义约束（超过用户定义阈值的概率）的响应。为了评估AI组件的可信度，我们提出使用“内部测试数据”作为补充的安全标记数据集，并采用“保守测试”方法以统计上确保使用内部测试数据的合理性。我们还介绍了损失函数的近似方法及其梯度的计算方法。\n\n我们从数学上证明，在特定温和条件下，概率约束满足是可保证的，并证明了安全性与内部测试数据数量之间的标度定律。通过在不同领域的实验（生产决策中的需求预测、SafetyGym模拟器中的安全强化学习以及AI聊天机器人输出的防护），我们展示了该框架的有效性。这些实验表明，我们的方法能够确保用户指定的约束条件下的安全性，在低安全性阈值区域比现有方法有效得多，并且能够有效地根据内部测试数据量进行扩展。', 'title_zh': '无领域依赖的大规模AI安全性保障框架'}
{'arxiv_id': 'arXiv:2504.20921', 'title': 'Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare', 'authors': 'Polycarp Nalela', 'link': 'https://arxiv.org/abs/2504.20921', 'abstract': "Access to high-quality medical data is often restricted due to privacy concerns, posing significant challenges for training artificial intelligence (AI) algorithms within Electronic Health Record (EHR) applications. In this study, prompt engineering with the GPT-4 API was employed to generate high-quality synthetic datasets aimed at overcoming this limitation. The generated data encompassed a comprehensive array of patient admission information, including healthcare provider details, hospital departments, wards, bed assignments, patient demographics, emergency contacts, vital signs, immunizations, allergies, medical histories, appointments, hospital visits, laboratory tests, diagnoses, treatment plans, medications, clinical notes, visit logs, discharge summaries, and referrals. To ensure data quality and integrity, advanced validation techniques were implemented utilizing models such as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for overall plausibility, RoBERTa for logical consistency, autoencoders for anomaly detection, and conducted diversity analysis. Synthetic data that met all validation criteria were integrated into a comprehensive PostgreSQL database, serving as the data management system for the EHR application. This approach demonstrates that leveraging generative AI models with rigorous validation can effectively produce high-quality synthetic medical data, facilitating the training of AI algorithms while addressing privacy concerns associated with real patient data.", 'abstract_zh': '由于隐私问题限制了高质量医疗数据的访问，为电子健康记录（EHR）应用中的AI算法训练带来了显著挑战。本研究通过使用GPT-4 API进行提示工程，生成高质量的合成数据集以克服这一限制。生成的数据包括患者入院的全面信息，涵盖医疗服务提供者详情、医院部门、病区、床位分配、患者人口统计信息、紧急联系人、生命体征、疫苗接种、过敏反应、医疗史、预约、医院访问、实验室检查、诊断、治疗计划、药物、临床记录、访问日志、出院总结和转诊。为确保数据质量和完整性，采用了BERT的下一句预测模型进行句子连贯性验证，GPT-2进行整体合理性验证，RoBERTa进行逻辑一致性验证，自编码器进行异常检测，并进行了多样性分析。符合所有验证标准的合成数据被集成到一个完整的PostgreSQL数据库中，作为EHR应用的数据管理系统。研究表明，利用严格的验证生成AI模型可以有效生成高质量的合成医疗数据，同时解决与真实患者数据相关的隐私问题，促进AI算法的训练。', 'title_zh': '利用提示工程和严谨验证通过生成式AI创建全面的合成医疗健康领域训练数据集'}
{'arxiv_id': 'arXiv:2504.20898', 'title': 'CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models', 'authors': 'Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag', 'link': 'https://arxiv.org/abs/2504.20898', 'abstract': "Advancements in generative Artificial Intelligence (AI) hold great promise for automating radiology workflows, yet challenges in interpretability and reliability hinder clinical adoption. This paper presents an automated radiology report generation framework that combines Concept Bottleneck Models (CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge AI performance with clinical explainability. CBMs map chest X-ray features to human-understandable clinical concepts, enabling transparent disease classification. Meanwhile, the RAG system integrates multi-agent collaboration and external knowledge to produce contextually rich, evidence-based reports. Our demonstration showcases the system's ability to deliver interpretable predictions, mitigate hallucinations, and generate high-quality, tailored reports with an interactive interface addressing accuracy, trust, and usability challenges. This framework provides a pathway to improving diagnostic consistency and empowering radiologists with actionable insights.", 'abstract_zh': '生成式人工智能的进步为自动化放射科工作流程带来了巨大潜力，但由于可解释性和可靠性方面的挑战，阻碍了临床应用。本文提出了一种结合概念瓶颈模型（CBMs）和多代理检索增强生成（RAG）系统的自动化放射科报告生成框架，以实现AI性能与临床可解释性的融合。CBMs将胸部X射线特征映射为人容易理解的临床概念，使疾病分类变得透明。与此同时，RAG系统通过多代理协作和外部知识的整合，生成丰富语境、基于证据的报告。我们的演示展示了该系统在提供可解释性预测、减轻幻觉、生成高质量和个性化报告方面的能力，并通过互动界面解决准确性、信任度和易用性方面的挑战。该框架为提高诊断一致性并赋予放射科医生可操作的洞察提供了途径。', 'title_zh': 'CBM-RAG：多智能体RAG和概念瓶颈模型在放射学报告生成中展示增强的可解释性'}
{'arxiv_id': 'arXiv:2504.20879', 'title': 'The Leaderboard Illusion', 'authors': "Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, Beyza Ermis, Marzieh Fadaee, Sara Hooker", 'link': 'https://arxiv.org/abs/2504.20879', 'abstract': "Measuring progress is fundamental to the advancement of any scientific field. As benchmarks play an increasingly central role, they also grow more susceptible to distortion. Chatbot Arena has emerged as the go-to leaderboard for ranking the most capable AI systems. Yet, in this work we identify systematic issues that have resulted in a distorted playing field. We find that undisclosed private testing practices benefit a handful of providers who are able to test multiple variants before public release and retract scores if desired. We establish that the ability of these providers to choose the best score leads to biased Arena scores due to selective disclosure of performance results. At an extreme, we identify 27 private LLM variants tested by Meta in the lead-up to the Llama-4 release. We also establish that proprietary closed models are sampled at higher rates (number of battles) and have fewer models removed from the arena than open-weight and open-source alternatives. Both these policies lead to large data access asymmetries over time. Providers like Google and OpenAI have received an estimated 19.2% and 20.4% of all data on the arena, respectively. In contrast, a combined 83 open-weight models have only received an estimated 29.7% of the total data. We show that access to Chatbot Arena data yields substantial benefits; even limited additional data can result in relative performance gains of up to 112% on the arena distribution, based on our conservative estimates. Together, these dynamics result in overfitting to Arena-specific dynamics rather than general model quality. The Arena builds on the substantial efforts of both the organizers and an open community that maintains this valuable evaluation platform. We offer actionable recommendations to reform the Chatbot Arena's evaluation framework and promote fairer, more transparent benchmarking for the field", 'abstract_zh': '测量进展是任何科学领域进步的基础。随着基准测试在其中扮演越来越重要的角色，它们也变得更加容易受到扭曲。Chatbot Arena 已成为排名最强大人工智能系统的主要基准排行榜。然而，在本文中，我们识别出系统性问题，导致了一个扭曲的竞争环境。我们发现，未公开的私人测试实践有利于少数提供者，他们能够在公共发布前测试多个变体，并可以根据需要撤回分数。我们确定，这些提供者能够选择最佳分数的能力导致了由于选择性披露性能结果而导致的偏向性Arena分数。在极端情况下，我们识别出Meta在Llama-4发布前测试了27种私人大语言模型变体。我们还确定，专有封闭模型被采样得更多（比赛次数），被从竞技场移除的模型也更少，而开源和开源替代方案则不然。这两种政策随着时间的推移导致了大量数据访问不对等。谷歌和OpenAI等提供者分别获得了约19.2%和20.4%的所有竞技场数据。相比之下，近83个开源权重模型仅获得了约29.7%的总数据。我们显示，访问Chatbot Arena数据能够带来实质性的益处；即使额外获得少量数据也可能基于我们保守的估计在竞技场分布中产生高达112%的相对性能提升。这些动态导致了针对竞技场特定动态的过度拟合，而不是一般的模型质量。Chatbot Arena 基于组织者和维护这一宝贵评估平台的开放社区的重大努力。我们提出了一系列可操作的建议，旨在改革Chatbot Arena的评估框架，并促进该领域的更公平和透明的基准测试。', 'title_zh': '排行榜错觉'}
{'arxiv_id': 'arXiv:2504.20846', 'title': 'Disjunctive and Conjunctive Normal Form Explanations of Clusters Using Auxiliary Information', 'authors': 'Robert F. Downey, S. S. Ravi', 'link': 'https://arxiv.org/abs/2504.20846', 'abstract': 'We consider generating post-hoc explanations of clusters generated from various datasets using auxiliary information which was not used by clustering algorithms. Following terminology used in previous work, we refer to the auxiliary information as tags. Our focus is on two forms of explanations, namely disjunctive form (where the explanation for a cluster consists of a set of tags) and a two-clause conjunctive normal form (CNF) explanation (where the explanation consists of two sets of tags, combined through the AND operator). We use integer linear programming (ILP) as well as heuristic methods to generate these explanations. We experiment with a variety of datasets and discuss the insights obtained from our explanations. We also present experimental results regarding the scalability of our explanation methods.', 'abstract_zh': '使用辅助信息生成聚类的后验解释：基于标签的析取形式和CNF形式的解释', 'title_zh': '使用辅助信息的析取范式和合取范式聚类解释'}
{'arxiv_id': 'arXiv:2504.20828', 'title': 'Ascendra: Dynamic Request Prioritization for Efficient LLM Serving', 'authors': 'Azam Ikram, Xiang Li, Sameh Elnikety, Saurabh Bagchi', 'link': 'https://arxiv.org/abs/2504.20828', 'abstract': "The rapid advancement of Large Language Models (LLMs) has driven the need for more efficient serving strategies. In this context, efficiency refers to the proportion of requests that meet their Service Level Objectives (SLOs), particularly for Time To First Token (TTFT) and Time Between Tokens (TBT). However, existing systems often prioritize one metric at the cost of the other. We present Ascendra, an LLM serving system designed to meet both TTFT and TBT SLOs simultaneously. The core insight behind Ascendra is that a request's urgency evolves as it approaches its deadline. To leverage this, Ascendra partitions GPU resources into two types of instances: low-priority and high-priority. Low-priority instances maximize throughput by processing requests out of arrival order, but at the risk of request starvation. To address this, Ascendra employs a performance model to predict requests at risk of missing their SLOs and proactively offloads them to high-priority instances. High-priority instances are optimized for low-latency execution and handle urgent requests nearing their deadlines. This partitioned architecture enables Ascendra to effectively balance high throughput and low latency. Extensive evaluation shows that Ascendra improves system throughput by up to 1.7x compared to vLLM and Sarathi-Serve while meeting both TTFT and TBT SLOs.", 'abstract_zh': '大规模语言模型的快速进步推动了更高效服务策略的需求。在这种背景下，效率指的是满足服务级别目标（SLO）的请求比例，特别是针对首个词出现时间（TTFT）和词之间时间（TBT）。然而，现有系统往往在优先考虑一个指标时会牺牲另一个指标。我们提出了Ascendra，这是一种设计用于同时满足首个词出现时间和词之间时间SLO的大规模语言模型服务系统。Ascendra的核心洞察是请求的紧迫性会随着接近截止日期而变化。基于此，Ascendra将GPU资源分为两种实例：低优先级和高优先级。低优先级实例通过按到达顺序处理请求来最大化 throughput，但存在请求饿死的风险。为了解决这个问题，Ascendra采用性能模型预测可能无法满足SLO的请求，并主动将这些请求卸载到高优先级实例。高优先级实例优化了低latency执行，处理接近截止日期的紧急请求。这种分区架构使得Ascendra能够有效平衡高吞吐量和低latency。广泛评估显示，与vLLM和Sarathi-Serve相比，Ascendra可将系统吞吐量提高多达1.7倍，同时满足首个词出现时间和词之间时间SLO。', 'title_zh': 'Ascendra：高效的LLM服务动态请求优先级调度'}
{'arxiv_id': 'arXiv:2504.20797', 'title': 'Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning', 'authors': 'Renye Zhang, Yimin Yin, Jinghua Zhang', 'link': 'https://arxiv.org/abs/2504.20797', 'abstract': 'Current mainstream deep learning techniques exhibit an over-reliance on extensive training data and a lack of adaptability to the dynamic world, marking a considerable disparity from human intelligence. To bridge this gap, Few-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous learning of new categories with limited samples without forgetting old knowledge. Existing FSCIL studies typically use a single model to learn knowledge across all sessions, inevitably leading to the stability-plasticity dilemma. Unlike machines, humans store varied knowledge in different cerebral cortices. Inspired by this characteristic, our paper aims to develop a method that learns independent models for each session. It can inherently prevent catastrophic forgetting. During the testing stage, our method integrates Uncertainty Quantification (UQ) for model deployment. Our method provides a fresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on CIFAR-100 and mini-ImageNet datasets.', 'abstract_zh': '当前主流的深度学习技术过度依赖大量训练数据且缺乏对动态世界的适应性，这与人类智能存在显著差异。为缩小这一差距，少样本类别增量学习（FSCIL）应运而生，专注于在有限样本下不断学习新类别并保留旧知识。现有FSCIL研究通常使用单一模型在所有会话中学习知识，不可避免地导致稳定性和塑性之间的难题。与机器不同，人类将不同知识存储在不同的大脑皮层中。受此启发，本文旨在开发一种为每个会话学习独立模型的方法，可内在防止灾难性遗忘。在测试阶段，本文方法结合不确定性量化（UQ）进行模型部署。本文方法为FSCIL提供了新的视角，并在CIFAR-100和mini-ImageNet数据集上展示了最先进的性能。', 'title_zh': '启发式分割存储的少量学习类增量学习'}
{'arxiv_id': 'arXiv:2504.20784', 'title': 'Approximate Lifted Model Construction', 'authors': 'Malte Luttermann, Jan Speller, Marcel Gehrke, Tanya Braun, Ralf Möller, Mattis Hartwig', 'link': 'https://arxiv.org/abs/2504.20784', 'abstract': 'Probabilistic relational models such as parametric factor graphs enable efficient (lifted) inference by exploiting the indistinguishability of objects. In lifted inference, a representative of indistinguishable objects is used for computations. To obtain a relational (i.e., lifted) representation, the Advanced Colour Passing (ACP) algorithm is the state of the art. The ACP algorithm, however, requires underlying distributions, encoded as potential-based factorisations, to exactly match to identify and exploit indistinguishabilities. Hence, ACP is unsuitable for practical applications where potentials learned from data inevitably deviate even if associated objects are indistinguishable. To mitigate this problem, we introduce the $\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which allows for a deviation of potentials depending on a hyperparameter $\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits indistinguishabilities that are not exact. We prove that the approximation error induced by $\\varepsilon$-ACP is strictly bounded and our experiments show that the approximation error is close to zero in practice.', 'abstract_zh': '概率关系模型如参数因子图通过利用对象的不可区分性实现高效的（提升的）推理。在提升推理中，使用不可区分对象的代表进行计算。为了获得关系（即，提升的）表示，先进的色彩传递(ACP)算法是当前最先进的方法。然而，ACP算法要求底层分布以潜在基于的因子分解形式精确匹配，以识别和利用不可区分性。因此，ACP不适用于实际应用，其中即便关联的对象是不可区分的，从数据中学习到的潜在因素也会不可避免地存在偏差。为缓解这一问题，我们引入了$\\varepsilon$-先进的色彩传递（$\\varepsilon$-ACP）算法，允许潜在因素根据超参数$\\varepsilon$的偏差。$\\varepsilon$-ACP有效地揭示并利用了非精确的不可区分性。我们证明了$\\varepsilon$-ACP引入的近似误差严格有界，实验结果表明在实际应用中这种近似误差接近于零。', 'title_zh': '近似提升模型构建'}
{'arxiv_id': 'arXiv:2504.20756', 'title': 'Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration', 'authors': 'Moirangthem Tiken Singh', 'link': 'https://arxiv.org/abs/2504.20756', 'abstract': "This paper proposes a novel graph-based framework for robust and interpretable multiclass fault diagnosis in rotating machinery. The method integrates entropy-optimized signal segmentation, time-frequency feature extraction, and graph-theoretic modeling to transform vibration signals into structured representations suitable for classification. Graph metrics, such as average shortest path length, modularity, and spectral gap, are computed and combined with local features to capture global and segment-level fault characteristics. The proposed method achieves high diagnostic accuracy when evaluated on two benchmark datasets, the CWRU bearing dataset (under 0-3 HP loads) and the SU gearbox and bearing datasets (under different speed-load configurations). Classification scores reach up to 99.8% accuracy on Case Western Reserve University (CWRU) and 100% accuracy on the Southeast University datasets using a logistic regression classifier. Furthermore, the model exhibits strong noise resilience, maintaining over 95.4% accuracy at high noise levels (standard deviation = 0.5), and demonstrates excellent cross-domain transferability with up to 99.7% F1-score in load-transfer scenarios. Compared to traditional techniques, this approach requires no deep learning architecture, enabling lower complexity while ensuring interpretability. The results confirm the method's scalability, reliability, and potential for real-time deployment in industrial diagnostics.", 'abstract_zh': '一种基于图的鲁棒且可解释的旋转机械多类故障诊断新框架', 'title_zh': '基于图的旋转机械故障诊断：自适应分割与结构特征整合'}
{'arxiv_id': 'arXiv:2504.20676', 'title': 'The Limits of AI Explainability: An Algorithmic Information Theory Approach', 'authors': 'Shrisha Rao', 'link': 'https://arxiv.org/abs/2504.20676', 'abstract': 'This paper establishes a theoretical foundation for understanding the fundamental limits of AI explainability through algorithmic information theory. We formalize explainability as the approximation of complex models by simpler ones, quantifying both approximation error and explanation complexity using Kolmogorov complexity. Our key theoretical contributions include: (1) a complexity gap theorem proving that any explanation significantly simpler than the original model must differ from it on some inputs; (2) precise bounds showing that explanation complexity grows exponentially with input dimension but polynomially with error tolerance for Lipschitz functions; and (3) a characterization of the gap between local and global explainability, demonstrating that local explanations can be significantly simpler while maintaining accuracy in relevant regions. We further establish a regulatory impossibility theorem proving that no governance framework can simultaneously pursue unrestricted AI capabilities, human-interpretable explanations, and negligible error. These results highlight considerations likely to be relevant to the design, evaluation, and oversight of explainable AI systems.', 'abstract_zh': '本文通过算法信息论建立了理解人工智能解释性基本界限的理论基础。我们将解释性形式化为通过较简单的模型来近似复杂的模型，并使用柯尔莫哥洛夫复杂性度量近似误差和解释复杂性。我们的主要理论贡献包括：（1）复杂性间隙定理，证明任何显著比原始模型更简单的解释必须在某些输入上与其不同；（2）精确界显示，对于Lipschitz函数，解释复杂性随着输入维度呈指数增长，但随着容许误差的容忍度呈多项式增长；以及（3）局部解释性与全局解释性之间差异的表征，表明局部解释可以在相关区域保持准确性的同时显著更简单。此外，我们还建立了监管不可能性定理，证明没有任何治理体系能够同时追求不受限制的人工智能能力、可由人类理解的解释和可忽略的误差。这些结果突显了可能对可解释人工智能系统的设计、评估和监管具有重要意义的考虑因素。', 'title_zh': 'AI可解释性的局限性：一种算法信息论方法'}
{'arxiv_id': 'arXiv:2504.20628', 'title': 'Cognitive maps are generative programs', 'authors': 'Marta Kryven, Cole Wyeth, Aidan Curtis, Kevin Ellis', 'link': 'https://arxiv.org/abs/2504.20628', 'abstract': 'Making sense of the world and acting in it relies on building simplified mental representations that abstract away aspects of reality. This principle of cognitive mapping is universal to agents with limited resources. Living organisms, people, and algorithms all face the problem of forming functional representations of their world under various computing constraints. In this work, we explore the hypothesis that human resource-efficient planning may arise from representing the world as predictably structured. Building on the metaphor of concepts as programs, we propose that cognitive maps can take the form of generative programs that exploit predictability and redundancy, in contrast to directly encoding spatial layouts. We use a behavioral experiment to show that people who navigate in structured spaces rely on modular planning strategies that align with programmatic map representations. We describe a computational model that predicts human behavior in a variety of structured scenarios. This model infers a small distribution over possible programmatic cognitive maps conditioned on human prior knowledge of the world, and uses this distribution to generate resource-efficient plans. Our models leverages a Large Language Model as an embedding of human priors, implicitly learned through training on a vast corpus of human data. Our model demonstrates improved computational efficiency, requires drastically less memory, and outperforms unstructured planning algorithms with cognitive constraints at predicting human behavior, suggesting that human planning strategies rely on programmatic cognitive maps.', 'abstract_zh': '理解世界和行动依赖于构建简化的心智表征，抽象掉现实的某些方面。这一认知制图的原则对资源有限的代理是普遍适用的。生物体、人和算法都在各种计算约束下构建其世界的功能性表征。在这项工作中，我们探讨了人类资源高效规划可能是通过将世界表示为可预测结构而产生的假设。基于概念即程序的隐喻，我们提出认知地图可以是生成程序的形式，利用可预测性和冗余性，而不是直接编码空间布局。我们通过行为实验展示了在结构化空间中导航的人依赖于与程序化地图表示相一致的模块化规划策略。我们描述了一个计算模型，该模型在各种结构化场景中预测人类行为。该模型根据人类对世界的先验知识推断出可能的程序化认知地图的小概率分布，并使用该分布生成资源高效的规划。我们的模型利用一个大规模语言模型作为人类先验知识的嵌入，并通过对大量人类数据的训练隐式学习。该模型展示了更好的计算效率，所需内存大幅减少，并能在认知约束下预测人类行为方面优于非结构化规划算法，表明人类规划策略依赖于程序化认知地图。', 'title_zh': '认知地图是生成程序。'}
{'arxiv_id': 'arXiv:2504.20624', 'title': 'PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval', 'authors': 'Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, Yi Wu, Yao Hu', 'link': 'https://arxiv.org/abs/2504.20624', 'abstract': 'Social chatbots have become essential intelligent companions in daily scenarios ranging from emotional support to personal interaction. However, conventional chatbots with passive response mechanisms usually rely on users to initiate or sustain dialogues by bringing up new topics, resulting in diminished engagement and shortened dialogue duration. In this paper, we present PaRT, a novel framework enabling context-aware proactive dialogues for social chatbots through personalized real-time retrieval and generation. Specifically, PaRT first integrates user profiles and dialogue context into a large language model (LLM), which is initially prompted to refine user queries and recognize their underlying intents for the upcoming conversation. Guided by refined intents, the LLM generates personalized dialogue topics, which then serve as targeted queries to retrieve relevant passages from RedNote. Finally, we prompt LLMs with summarized passages to generate knowledge-grounded and engagement-optimized responses. Our approach has been running stably in a real-world production environment for more than 30 days, achieving a 21.77\\% improvement in the average duration of dialogues.', 'abstract_zh': '社会聊天机器人已成为日常场景中从情感支持到个人互动的必不可少的智能伴侣。然而，传统的基于被动响应机制的聊天机器人通常需要用户通过提出新话题来启动或维持对话，这导致了参与度下降和对话时长缩短。本文介绍了PaRT，一种新型框架，通过个性化实时检索和生成，使社会聊天机器人能够进行基于上下文的主动对话。具体而言，PaRT 首先将用户资料和对话上下文整合到一个大型语言模型（LLM）中，该模型最初被激发以细化用户查询并识别其后续对话的潜在意图。基于细化的意图，LLM 生成个性化对话主题，这些主题随后作为目标查询检索RedNote的相关段落。最后，我们使用总结的段落激发LLM生成知识导向且能优化参与度的响应。我们的方法已在真实生产环境中稳定运行超过30天，对话平均时长提高了21.77%。', 'title_zh': 'PaRT: 通过个性化实时检索增强主动社交聊天机器人'}
{'arxiv_id': 'arXiv:2504.20595', 'title': 'ReasonIR: Training Retrievers for Reasoning Tasks', 'authors': 'Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer', 'link': 'https://arxiv.org/abs/2504.20595', 'abstract': 'We present ReasonIR-8B, the first retriever specifically trained for general reasoning tasks. Existing retrievers have shown limited gains on reasoning tasks, in part because existing training datasets focus on short factual queries tied to documents that straightforwardly answer them. We develop a synthetic data generation pipeline that, for each document, our pipeline creates a challenging and relevant query, along with a plausibly related but ultimately unhelpful hard negative. By training on a mixture of our synthetic data and existing public data, ReasonIR-8B achieves a new state-of-the-art of 29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a widely-used reasoning-intensive information retrieval (IR) benchmark. When applied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4% and 22.6% respectively, relative to the closed-book baseline, outperforming other retrievers and search engines. In addition, ReasonIR-8B uses test-time compute more effectively: on BRIGHT, its performance consistently increases with longer and more information-rich rewritten queries; it continues to outperform other retrievers when combined with an LLM reranker. Our training recipe is general and can be easily extended to future LLMs; to this end, we open-source our code, data, and model.', 'abstract_zh': 'ReasonIR-8B：首个专门训练用于通用推理任务的检索器', 'title_zh': 'ReasonIR：训练用于推理任务的检索器'}
{'arxiv_id': 'arXiv:2504.20505', 'title': 'MuRAL: A Multi-Resident Ambient Sensor Dataset Annotated with Natural Language for Activities of Daily Living', 'authors': 'Xi Chen, Julien Cumin, Fano Ramparany, Dominique Vaufreydaz', 'link': 'https://arxiv.org/abs/2504.20505', 'abstract': 'Recent advances in Large Language Models (LLMs) have shown promising potential for human activity recognition (HAR) using ambient sensors, especially through natural language reasoning and zero-shot learning. However, existing datasets such as CASAS, ARAS, and MARBLE were not originally designed with LLMs in mind and therefore lack the contextual richness, complexity, and annotation granularity required to fully exploit LLM capabilities. In this paper, we introduce MuRAL, the first Multi-Resident Ambient sensor dataset with natural Language, comprising over 21 hours of multi-user sensor data collected from 21 sessions in a smart-home environment. MuRAL is annotated with fine-grained natural language descriptions, resident identities, and high-level activity labels, all situated in dynamic, realistic multi-resident settings. We benchmark MuRAL using state-of-the-art LLMs for three core tasks: subject assignment, action description, and activity classification. Our results demonstrate that while LLMs can provide rich semantic interpretations of ambient data, current models still face challenges in handling multi-user ambiguity and under-specified sensor contexts. We release MuRAL to support future research on LLM-powered, explainable, and socially aware activity understanding in smart environments. For access to the dataset, please reach out to us via the provided contact information. A direct link for dataset retrieval will be made available at this location in due course.', 'abstract_zh': '最近大型语言模型（LLMs）的发展展示了利用环境传感器进行人体活动识别（HAR）的 promising 潜力，特别是在自然语言推理和零样本学习方面。然而，现有的数据集如CASAS、ARAS和MARBLE最初并非为LLMs设计，因而缺乏所需的上下文丰富性、复杂性和注释粒度，以充分利用LLMs的能力。本文我们介绍了MuRAL，这是首个包含自然语言的多居民环境传感器数据集，源自智能家居环境中21会话超过21小时的多用户传感器数据。MuRAL通过自然语言描述、居民身份和高层次活动标签进行详细注释，位于动态且现实的多居民环境之中。我们使用最先进的LLMs对MuRAL进行三个核心任务的基准测试：主体分配、动作描述和活动分类。结果显示，虽然LLMs能够提供丰富的环境数据语义解释，但当前模型仍然面临处理多用户模糊性和传感器背景不明确性的挑战。我们发布MuRAL以支持未来LLM驱动的、可解释的和社会意识强的活动理解研究。有关数据集的访问，请通过提供的联系方式联系我们。数据集获取的直接链接将在合适的时间在此位置提供。', 'title_zh': 'MuRAL：一种标注自然语言的家庭环境传感器多居民活动数据集'}
{'arxiv_id': 'arXiv:2504.20464', 'title': 'A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning', 'authors': 'Jiahao Li, Kaer Huang', 'link': 'https://arxiv.org/abs/2504.20464', 'abstract': 'Graphical User Interface (GUI) agents, driven by Multi-modal Large Language Models (MLLMs), have emerged as a promising paradigm for enabling intelligent interaction with digital systems. This paper provides a structured summary of recent advances in GUI agents, focusing on architectures enhanced by Reinforcement Learning (RL). We first formalize GUI agent tasks as Markov Decision Processes and discuss typical execution environments and evaluation metrics. We then review the modular architecture of (M)LLM-based GUI agents, covering Perception, Planning, and Acting modules, and trace their evolution through representative works. Furthermore, we categorize GUI agent training methodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and RL-based approaches, highlighting the progression from simple prompt engineering to dynamic policy learning via RL. Our summary illustrates how recent innovations in multimodal perception, decision reasoning, and adaptive action generation have significantly improved the generalization and robustness of GUI agents in complex real-world environments. We conclude by identifying key challenges and future directions for building more capable and reliable GUI agents.', 'abstract_zh': '多模态大型语言模型驱动的图形用户界面（GUI）代理在过去的研究进展中，作为一种使智能交互成为数字系统可能的有前途的范式已然出现。本文提供了一个结构化的总结，重点介绍了强化学习（RL）增强的GUI代理的最新进展。我们首先将GUI代理任务形式化为马尔可夫决策过程（MDP），讨论其典型执行环境和评估指标。然后，我们回顾了基于（多模态）大型语言模型（MLLM）的GUI代理的模块化架构，涵盖了感知、规划和执行模块，并通过代表性工作追踪了它们的发展。此外，我们按照基于提示、监督微调（SFT）和基于RL的方法对GUI代理的训练方法进行了分类，突出了从简单的提示工程到通过RL的动态策略学习的进步。我们的总结展示了多模态感知、决策推理和适应性动作生成的最新创新如何显著提高了GUI代理在复杂实际环境中的泛化能力和鲁棒性。最后，我们指出了构建更强大、更可靠的GUI代理的关键挑战和未来方向。', 'title_zh': '基于强化学习增强的基础模型GUI代理综述'}
{'arxiv_id': 'arXiv:2504.20462', 'title': 'TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data', 'authors': 'Qi Wang, Xiao Zhang, Mingyi Li, Yuan Yuan, Mengbai Xiao, Fuzhen Zhuang, Dongxiao Yu', 'link': 'https://arxiv.org/abs/2504.20462', 'abstract': 'With the development of distributed systems, microservices and cloud native technologies have become central to modern enterprise software development. Despite bringing significant advantages, these technologies also increase system complexity and operational challenges. Traditional root cause analysis (RCA) struggles to achieve automated fault response, heavily relying on manual intervention. In recent years, large language models (LLMs) have made breakthroughs in contextual inference and domain knowledge integration, providing new solutions for Artificial Intelligence for Operations (AIOps). However, Existing LLM-based approaches face three key challenges: text input constraints, dynamic service dependency hallucinations, and context window limitations. To address these issues, we propose a tool-assisted LLM agent with multi-modality observation data, namely TAMO, for fine-grained RCA. It unifies multi-modal observational data into time-aligned representations to extract consistent features and employs specialized root cause localization and fault classification tools for perceiving the contextual environment. This approach overcomes the limitations of LLM in handling real-time changing service dependencies and raw observational data and guides LLM to generate repair strategies aligned with system contexts by structuring key information into a prompt. Experimental results show that TAMO performs well in root cause analysis when dealing with public datasets characterized by heterogeneity and common fault types, demonstrating its effectiveness.', 'abstract_zh': '随着分布式系统的不断发展，微服务和云原生技术已成为现代企业软件开发的核心。尽管这些技术带来了显著的优势，但也增加了系统的复杂性和运维挑战。传统的根本原因分析（RCA）难以实现自动化故障响应， heavily依赖手动干预。近年来，大规模语言模型（LLMs）在上下文推断和领域知识整合方面取得了突破，为运维人工智能（AIOps）提供了新的解决方案。然而，现有的LLM基方法面临三个关键挑战：文本输入限制、动态服务依赖幻觉以及上下文窗口限制。为了应对这些问题，我们提出了一种工具辅助的多模态LLM智能体（TAMO），用于细粒度的根本原因分析。该智能体将多模态观测数据统一为时间对齐的表示以提取一致的特征，并利用专门的根因定位和故障分类工具感知上下文环境。该方法克服了LLM在处理实时变化的服务依赖关系和原始观测数据方面的限制，并通过结构化关键信息指导LLM生成符合系统环境的修复策略。实验结果显示，TAMO在处理由异质性和常见故障类型特征描述的公开数据集时，在根本原因分析方面表现出色，证明了其有效性。', 'title_zh': 'TAMO:借助多模态观察数据的工具辅助LLM代理细粒度根因分析'}
{'arxiv_id': 'arXiv:2504.20445', 'title': 'Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking Neural Networks', 'authors': 'Tianqing Zhang, Zixin Zhu, Kairong Yu, Hongwei Wang', 'link': 'https://arxiv.org/abs/2504.20445', 'abstract': 'Spiking Neural Networks (SNNs) have emerged as a promising approach for energy-efficient and biologically plausible computation. However, due to limitations in existing training methods and inherent model constraints, SNNs often exhibit a performance gap when compared to Artificial Neural Networks (ANNs). Knowledge distillation (KD) has been explored as a technique to transfer knowledge from ANN teacher models to SNN student models to mitigate this gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence to align output distributions. However, conventional KL-based approaches fail to fully exploit the unique characteristics of SNNs, as they tend to overemphasize high-probability predictions while neglecting low-probability ones, leading to suboptimal generalization. To address this, we propose Head-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for SNNs. HTA-KL introduces a cumulative probability-based mask to dynamically distinguish between high- and low-probability regions. It assigns adaptive weights to ensure balanced knowledge transfer, enhancing the overall performance. By integrating forward KL (FKL) and reverse KL (RKL) divergence, our method effectively align both head and tail regions of the distribution. We evaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our method outperforms existing methods on most datasets with fewer timesteps.', 'abstract_zh': 'Spiking Neural Networks中的Head-Tail Aware Kullback-Leibler散度的知识蒸馏', 'title_zh': '头尾aware的KL散度在脉冲神经网络的知识蒸馏中'}
{'arxiv_id': 'arXiv:2504.20426', 'title': 'RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library', 'authors': 'Jiapeng Wang, Jinhao Jiang, Zhiqiang Zhang, Jun Zhou, Wayne Xin Zhao', 'link': 'https://arxiv.org/abs/2504.20426', 'abstract': 'The advancement of reasoning capabilities in Large Language Models (LLMs) requires substantial amounts of high-quality reasoning data, particularly in mathematics. Existing data synthesis methods, such as data augmentation from annotated training sets or direct question generation based on relevant knowledge points and documents, have expanded datasets but face challenges in mastering the inner logic of the problem during generation and ensuring the verifiability of the solutions. To address these issues, we propose RV-Syn, a novel Rational and Verifiable mathematical Synthesis approach. RV-Syn constructs a structured mathematical operation function library based on initial seed problems and generates computational graphs as solutions by combining Python-formatted functions from this library. These graphs are then back-translated into complex problems. Based on the constructed computation graph, we achieve solution-guided logic-aware problem generation. Furthermore, the executability of the computational graph ensures the verifiability of the solving process. Experimental results show that RV-Syn surpasses existing synthesis methods, including those involving human-generated problems, achieving greater efficient data scaling. This approach provides a scalable framework for generating high-quality reasoning datasets.', 'abstract_zh': 'Large Language Models (LLMs) 的推理能力提升需要大量高质量的推理数据，尤其是在数学领域。现有的数据合成方法，如从标注训练集进行数据扩增或基于相关知识点和文档直接生成问题，虽然扩展了数据集，但在生成过程中掌握问题内部逻辑并确保解决方案可验证方面仍面临挑战。为解决这些问题，我们提出了 RV-Syn，一种新颖的合理且可验证的数学合成方法。RV-Syn 基于初始种子问题构建结构化的数学运算函数库，并通过结合该库中的 Python 格式函数生成计算图作为解决方案。然后将这些图回译为复杂问题。基于构建的计算图，我们实现了指导性逻辑感知问题生成。此外，计算图的可执行性确保了解决过程的可验证性。实验结果表明，RV-Syn 超越了现有合成方法，包括涉及人工生成问题的方法，实现了更高效的数据显示规模。该方法为生成高质量推理数据集提供了可扩展的框架。', 'title_zh': 'RV-Syn：基于结构化函数库的合理可验证数学推理数据合成'}
{'arxiv_id': 'arXiv:2504.20406', 'title': 'Skill Discovery for Software Scripting Automation via Offline Simulations with LLMs', 'authors': 'Paiheng Xu, Gang Wu, Xiang Chen, Tong Yu, Chang Xiao, Franck Dernoncourt, Tianyi Zhou, Wei Ai, Viswanathan Swaminathan', 'link': 'https://arxiv.org/abs/2504.20406', 'abstract': "Scripting interfaces enable users to automate tasks and customize software workflows, but creating scripts traditionally requires programming expertise and familiarity with specific APIs, posing barriers for many users. While Large Language Models (LLMs) can generate code from natural language queries, runtime code generation is severely limited due to unverified code, security risks, longer response times, and higher computational costs. To bridge the gap, we propose an offline simulation framework to curate a software-specific skillset, a collection of verified scripts, by exploiting LLMs and publicly available scripting guides. Our framework comprises two components: (1) task creation, using top-down functionality guidance and bottom-up API synergy exploration to generate helpful tasks; and (2) skill generation with trials, refining and validating scripts based on execution feedback. To efficiently navigate the extensive API landscape, we introduce a Graph Neural Network (GNN)-based link prediction model to capture API synergy, enabling the generation of skills involving underutilized APIs and expanding the skillset's diversity. Experiments with Adobe Illustrator demonstrate that our framework significantly improves automation success rates, reduces response time, and saves runtime token costs compared to traditional runtime code generation. This is the first attempt to use software scripting interfaces as a testbed for LLM-based systems, highlighting the advantages of leveraging execution feedback in a controlled environment and offering valuable insights into aligning AI capabilities with user needs in specialized software domains.", 'abstract_zh': '大型语言模型赋能的离线模拟框架：提高软件自动化流程效率与安全性', 'title_zh': '通过 Offline Simulations with LLMs 的技能发现方法实现软件脚本自动化'}
{'arxiv_id': 'arXiv:2504.20340', 'title': 'A Picture is Worth a Thousand Prompts? Efficacy of Iterative Human-Driven Prompt Refinement in Image Regeneration Tasks', 'authors': 'Khoi Trinh, Scott Seidenberger, Raveen Wijewickrama, Murtuza Jadliwala, Anindya Maiti', 'link': 'https://arxiv.org/abs/2504.20340', 'abstract': 'With AI-generated content becoming ubiquitous across the web, social media, and other digital platforms, it is vital to examine how such content are inspired and generated. The creation of AI-generated images often involves refining the input prompt iteratively to achieve desired visual outcomes. This study focuses on the relatively underexplored concept of image regeneration using AI, in which a human operator attempts to closely recreate a specific target image by iteratively refining their prompt. Image regeneration is distinct from normal image generation, which lacks any predefined visual reference. A separate challenge lies in determining whether existing image similarity metrics (ISMs) can provide reliable, objective feedback in iterative workflows, given that we do not fully understand if subjective human judgments of similarity align with these metrics. Consequently, we must first validate their alignment with human perception before assessing their potential as a feedback mechanism in the iterative prompt refinement process. To address these research gaps, we present a structured user study evaluating how iterative prompt refinement affects the similarity of regenerated images relative to their targets, while also examining whether ISMs capture the same improvements perceived by human observers. Our findings suggest that incremental prompt adjustments substantially improve alignment, verified through both subjective evaluations and quantitative measures, underscoring the broader potential of iterative workflows to enhance generative AI content creation across various application domains.', 'abstract_zh': '随着生成式AI内容在互联网、社交媒体和其他数字平台上的普遍应用，亟需考察此类内容的灵感来源及其生成过程。本研究重点关注使用AI进行图像再生的概念，其中人类操作者通过迭代细化提示词试图精确还原特定目标图像。图像再生与缺乏预定义视觉参考的普通图像生成不同。另一个挑战在于，现有图像相似度度量(ISMs)是否能在迭代工作流程中提供可靠且客观的反馈，鉴于我们尚未完全理解主观的人类相似度判断是否与这些度量相一致。因此，我们首先需要验证它们是否与人类感知一致，然后再评估它们作为迭代提示词细化过程中的反馈机制的潜在应用。为填补这些研究空白，我们开展了一项结构化的用户研究，以评估迭代提示词细化如何影响再生图像与目标图像的相似度，并探讨ISMs是否能够捕捉到人类观察者感知到的相同改进。研究发现，逐步调整提示词显著提升了相似度的一致性，通过主观评价和定量指标均得到了验证，突显了迭代工作流程在各种应用领域增强生成式AI内容创作的广泛潜力。', 'title_zh': '一张图片抵得上一千个提示？图像再生任务中迭代的人工驱动提示 refinement 的有效性'}
{'arxiv_id': 'arXiv:2504.20318', 'title': 'Leveraging Action Relational Structures for Integrated Learning and Planning', 'authors': 'Ryan Xiao Wang, Felipe Trevizan', 'link': 'https://arxiv.org/abs/2504.20318', 'abstract': 'Recent advances in planning have explored using learning methods to help planning. However, little attention has been given to adapting search algorithms to work better with learning systems. In this paper, we introduce partial-space search, a new search space for classical planning that leverages the relational structure of actions given by PDDL action schemas -- a structure overlooked by traditional planning approaches. Partial-space search provides a more granular view of the search space and allows earlier pruning of poor actions compared to state-space search. To guide partial-space search, we introduce action set heuristics that evaluate sets of actions in a state. We describe how to automatically convert existing heuristics into action set heuristics. We also train action set heuristics from scratch using large training datasets from partial-space search. Our new planner, LazyLifted, exploits our better integrated search and learning heuristics and outperforms the state-of-the-art ML-based heuristic on IPC 2023 learning track (LT) benchmarks. We also show the efficiency of LazyLifted on high-branching factor tasks and show that it surpasses LAMA in the combined IPC 2023 LT and high-branching factor benchmarks.', 'abstract_zh': 'Recent advances in planning have explored using learning methods to help planning. However, little attention has been given to adapting search algorithms to work better with learning systems. In this paper, we introduce partial-space search, a new search space for classical planning that leverages the relational structure of actions given by PDDL action schemas—a structure overlooked by traditional planning approaches. Partial-space search provides a more granular view of the search space and allows earlier pruning of poor actions compared to state-space search. To guide partial-space search, we introduce action set heuristics that evaluate sets of actions in a state. We describe how to automatically convert existing heuristics into action set heuristics. We also train action set heuristics from scratch using large training datasets from partial-space search. Our new planner, LazyLifted, exploits our better integrated search and learning heuristics and outperforms the state-of-the-art ML-based heuristic on IPC 2023 learning track benchmarks. We also show the efficiency of LazyLifted on high-branching factor tasks and show that it surpasses LAMA in the combined IPC 2023 learning track and high-branching factor benchmarks.', 'title_zh': '利用动作关系结构进行集成学习与规划'}
{'arxiv_id': 'arXiv:2504.20294', 'title': 'mrCAD: Multimodal Refinement of Computer-aided Designs', 'authors': 'William P. McCarthy, Saujas Vaduguru, Karl D. D. Willis, Justin Matejka, Judith E. Fan, Daniel Fried, Yewen Pu', 'link': 'https://arxiv.org/abs/2504.20294', 'abstract': 'A key feature of human collaboration is the ability to iteratively refine the concepts we have communicated. In contrast, while generative AI excels at the \\textit{generation} of content, it often struggles to make specific language-guided \\textit{modifications} of its prior outputs. To bridge the gap between how humans and machines perform edits, we present mrCAD, a dataset of multimodal instructions in a communication game. In each game, players created computer aided designs (CADs) and refined them over several rounds to match specific target designs. Only one player, the Designer, could see the target, and they must instruct the other player, the Maker, using text, drawing, or a combination of modalities. mrCAD consists of 6,082 communication games, 15,163 instruction-execution rounds, played between 1,092 pairs of human players. We analyze the dataset and find that generation and refinement instructions differ in their composition of drawing and text. Using the mrCAD task as a benchmark, we find that state-of-the-art VLMs are better at following generation instructions than refinement instructions. These results lay a foundation for analyzing and modeling a multimodal language of refinement that is not represented in previous datasets.', 'abstract_zh': '人类协作的关键特征在于不断迭代细化沟通中的概念。相比之下，虽然生成型AI在内容生成方面表现出色，但在特定语言引导的内容修改方面往往存在困难。为弥合人类和机器编辑性能之间的差距，我们呈现了mrCAD数据集，该数据集包含多模态指令在通信游戏中的应用。在每场游戏中，参与者创建了计算机辅助设计(CAD)并进行了多次迭代以匹配特定的目标设计。只有设计师能够看到目标，他们必须使用文本、绘图或多种模态组合来指导另一个玩家——制造者。mrCAD包含6,082场通信游戏，15,163轮指令执行，共计由1,092对人类玩家完成。我们分析该数据集发现，生成指令和细化指令在绘图和文本的组成上有差异。使用mrCAD任务作为基准，我们发现最先进的视觉语言模型更擅长遵循生成指令而非细化指令。这些结果为分析和建模先前数据集中未包含的多模态细化语言奠定了基础。', 'title_zh': 'mrCAD: 多模态计算机辅助设计 refinement'}
{'arxiv_id': 'arXiv:2504.20278', 'title': 'Deep Physics Prior for First Order Inverse Optimization', 'authors': 'Haoyu Yang, Kamyar Azizzadenesheli, Haoxing Ren', 'link': 'https://arxiv.org/abs/2504.20278', 'abstract': 'Inverse design optimization aims to infer system parameters from observed solutions, posing critical challenges across domains such as semiconductor manufacturing, structural engineering, materials science, and fluid dynamics. The lack of explicit mathematical representations in many systems complicates this process and makes the first order optimization impossible. Mainstream approaches, including generative AI and Bayesian optimization, address these challenges but have limitations. Generative AI is computationally expensive, while Bayesian optimization, relying on surrogate models, suffers from scalability, sensitivity to priors, and noise issues, often leading to suboptimal solutions. This paper introduces Deep Physics Prior (DPP), a novel method enabling first-order gradient-based inverse optimization with surrogate machine learning models. By leveraging pretrained auxiliary Neural Operators, DPP enforces prior distribution constraints to ensure robust and meaningful solutions. This approach is particularly effective when prior data and observation distributions are unknown.', 'abstract_zh': '逆设计优化旨在从观察到的解中推断系统参数，这一过程在半导体制造、结构工程、材料科学和流体力学等多个领域都提出了关键挑战。由于许多系统缺乏显式的数学表示，这使得一阶优化变得困难。主流方法包括生成式AI和贝叶斯优化，但它们各有局限性。生成式AI计算成本高，而贝叶斯优化依赖于代理模型，容易受到先验信息和噪声的影响，往往导致次优解。本文引入了Deep Physics Prior (DPP)，一种新型方法，通过利用预训练的辅助神经运算器，使一阶梯度基的逆优化成为可能，并通过施加先验分布约束确保稳健且有意义的解。该方法特别适用于先验数据和观察分布未知的情况。', 'title_zh': '深度物理先验在一阶逆优化中的应用'}
{'arxiv_id': 'arXiv:2504.20113', 'title': 'Transforming Evidence Synthesis: A Systematic Review of the Evolution of Automated Meta-Analysis in the Age of AI', 'authors': 'Lingbo Li, Anuradha Mathrani, Teo Susnjak', 'link': 'https://arxiv.org/abs/2504.20113', 'abstract': "Exponential growth in scientific literature has heightened the demand for efficient evidence-based synthesis, driving the rise of the field of Automated Meta-analysis (AMA) powered by natural language processing and machine learning. This PRISMA systematic review introduces a structured framework for assessing the current state of AMA, based on screening 978 papers from 2006 to 2024, and analyzing 54 studies across diverse domains. Findings reveal a predominant focus on automating data processing (57%), such as extraction and statistical modeling, while only 17% address advanced synthesis stages. Just one study (2%) explored preliminary full-process automation, highlighting a critical gap that limits AMA's capacity for comprehensive synthesis. Despite recent breakthroughs in large language models (LLMs) and advanced AI, their integration into statistical modeling and higher-order synthesis, such as heterogeneity assessment and bias evaluation, remains underdeveloped. This has constrained AMA's potential for fully autonomous meta-analysis. From our dataset spanning medical (67%) and non-medical (33%) applications, we found that AMA has exhibited distinct implementation patterns and varying degrees of effectiveness in actually improving efficiency, scalability, and reproducibility. While automation has enhanced specific meta-analytic tasks, achieving seamless, end-to-end automation remains an open challenge. As AI systems advance in reasoning and contextual understanding, addressing these gaps is now imperative. Future efforts must focus on bridging automation across all meta-analysis stages, refining interpretability, and ensuring methodological robustness to fully realize AMA's potential for scalable, domain-agnostic synthesis.", 'abstract_zh': '指数增长的科学文献促使了高效证据ベース合成的需求增加，推动了自动化元分析（AMA）领域的发展，该领域利用自然语言处理和机器学习技术。基于2006年至2024年间筛选的978篇论文，并分析了来自不同领域的54项研究，本PRISMA系统评价提出了一种结构化框架，评估当前AMA的状态。研究发现，自动化数据处理（占比57%），如数据提取和统计建模，占据了主导地位，而仅17%的研究涉及高级合成阶段。仅有1项研究（2%）探讨了初步全流程自动化，指出AMA在实现全面合成方面仍存在关键短板。尽管大型语言模型（LLMs）和先进AI取得了近期突破，但它们在统计建模和更高阶合成中的集成，如异质性评估和偏倚评价，仍处于起步阶段，限制了AMA的自主元分析潜力。基于涵盖医学（67%）和非医学（33%）应用的数据集，我们发现AMA在实际提高效率、规模性和可再现性方面表现出不同的实施模式和不同程度的有效性。自动化在特定元分析任务中有所提升，但实现无缝端到端自动化仍然是一个开放的挑战。随着AI系统在推理和上下文理解方面的发展，弥补这些差距变得尤为重要。未来的研究必须集中在跨所有元分析阶段的自动化整合、提高可解释性和确保方法论稳健性上，以全面发挥AMA在可扩展和跨域综合中的潜力。', 'title_zh': 'AI时代自动元分析演变的系统评价：证据合成的转变'}
{'arxiv_id': 'arXiv:2504.20109', 'title': 'Personalized Artificial General Intelligence (AGI) via Neuroscience-Inspired Continuous Learning Systems', 'authors': 'Rajeev Gupta, Suhani Gupta, Ronak Parikh, Divya Gupta, Amir Javaheri, Jairaj Singh Shaktawat', 'link': 'https://arxiv.org/abs/2504.20109', 'abstract': 'Artificial Intelligence has made remarkable advancements in recent years, primarily driven by increasingly large deep learning models. However, achieving true Artificial General Intelligence (AGI) demands fundamentally new architectures rather than merely scaling up existing models. Current approaches largely depend on expanding model parameters, which improves task-specific performance but falls short in enabling continuous, adaptable, and generalized learning. Achieving AGI capable of continuous learning and personalization on resource-constrained edge devices is an even bigger challenge.\nThis paper reviews the state of continual learning and neuroscience-inspired AI, and proposes a novel architecture for Personalized AGI that integrates brain-like learning mechanisms for edge deployment. We review literature on continuous lifelong learning, catastrophic forgetting, and edge AI, and discuss key neuroscience principles of human learning, including Synaptic Pruning, Hebbian plasticity, Sparse Coding, and Dual Memory Systems, as inspirations for AI systems. Building on these insights, we outline an AI architecture that features complementary fast-and-slow learning modules, synaptic self-optimization, and memory-efficient model updates to support on-device lifelong adaptation.\nConceptual diagrams of the proposed architecture and learning processes are provided. We address challenges such as catastrophic forgetting, memory efficiency, and system scalability, and present application scenarios for mobile AI assistants and embodied AI systems like humanoid robots. We conclude with key takeaways and future research directions toward truly continual, personalized AGI on the edge. While the architecture is theoretical, it synthesizes diverse findings and offers a roadmap for future implementation.', 'abstract_zh': '人工智能在近年来取得了显著进步，主要得益于日益庞大的深度学习模型。然而，实现真正的通用人工智能（AGI）需要从根本上新的架构，而不仅仅是扩大现有模型的规模。当前的方法主要依赖于扩展模型参数，这种方法在提高特定任务性能方面表现出色，但在支持连续、适应性和泛化的学习方面却显得不足。在资源受限的边缘设备上实现具备连续学习和个性化能力的AGI更是更大的挑战。\n\n本文回顾了连续学习和受神经科学启发的人工智能的研究现状，并提出了一种新的架构，用于边缘部署的个性化AGI，该架构集成了类似于大脑的学习机制。我们回顾了连续终身学习、灾难性遗忘和边缘AI方面的文献，并讨论了人类学习的关键神经科学原理，包括突触修剪、Hebbian可塑性、稀疏编码和双记忆系统，以启发AI系统的设计。基于这些见解，我们概述了一种AI架构，该架构具备互补的快慢学习模块、突触自优化和内存高效的模型更新机制，以支持设备上的终身适应。\n\n本文提供了所提出架构和学习过程的概念性图表。我们解决了灾难性遗忘、存储效率和系统可扩展性等挑战，并介绍了移动AI助理和类人机器人等具身AI系统中的应用情景。最后总结了关键要点，并提出了通向真正具备连续性和个性化的边缘AGI的未来研究方向。虽然该架构是理论性的，但它综合了多方面的研究发现，并为未来的实施提供了路线图。', 'title_zh': '基于神经科学启发的连续学习系统的个性化人工通用 intelligence'}
{'arxiv_id': 'arXiv:2504.20090', 'title': 'Spark: A System for Scientifically Creative Idea Generation', 'authors': 'Aishik Sanyal, Samuel Schapiro, Sumuk Shashidhar, Royce Moon, Lav R. Varshney, Dilek Hakkani-Tur', 'link': 'https://arxiv.org/abs/2504.20090', 'abstract': 'Recently, large language models (LLMs) have shown promising abilities to generate novel research ideas in science, a direction which coincides with many foundational principles in computational creativity (CC). In light of these developments, we present an idea generation system named Spark that couples retrieval-augmented idea generation using LLMs with a reviewer model named Judge trained on 600K scientific reviews from OpenReview. Our work is both a system demonstration and intended to inspire other CC researchers to explore grounding the generation and evaluation of scientific ideas within foundational CC principles. To this end, we release the annotated dataset used to train Judge, inviting other researchers to explore the use of LLMs for idea generation and creative evaluations.', 'abstract_zh': '近期，大规模语言模型（LLMs）在科学领域展示了生成新颖研究想法的潜力，这与计算创意（CC）领域的许多基础原则相吻合。基于这些进展，我们提出了一种名为Spark的想法生成系统，该系统结合了使用LLMs的检索增强想法生成与一个在600K篇OpenReview科学评审上训练的评审模型Judge。我们的工作既是系统演示，也旨在激励其他CC研究人员探索将科学想法的生成和评估与基础CC原则相结合的研究方向。为此，我们发布了用于训练Judge的标注数据集，邀请其他研究人员探索使用LLMs进行想法生成和创造性评估的方法。', 'title_zh': 'Spark: 一个用于科学研究创意生成的系统'}
{'arxiv_id': 'arXiv:2504.20084', 'title': 'AI Awareness', 'authors': 'Xiaojian Li, Haoyuan Shi, Rongwu Xu, Wei Xu', 'link': 'https://arxiv.org/abs/2504.20084', 'abstract': 'Recent breakthroughs in artificial intelligence (AI) have brought about increasingly capable systems that demonstrate remarkable abilities in reasoning, language understanding, and problem-solving. These advancements have prompted a renewed examination of AI awareness, not as a philosophical question of consciousness, but as a measurable, functional capacity. In this review, we explore the emerging landscape of AI awareness, which includes meta-cognition (the ability to represent and reason about its own state), self-awareness (recognizing its own identity, knowledge, limitations, inter alia), social awareness (modeling the knowledge, intentions, and behaviors of other agents), and situational awareness (assessing and responding to the context in which it operates).\nFirst, we draw on insights from cognitive science, psychology, and computational theory to trace the theoretical foundations of awareness and examine how the four distinct forms of AI awareness manifest in state-of-the-art AI. Next, we systematically analyze current evaluation methods and empirical findings to better understand these manifestations. Building on this, we explore how AI awareness is closely linked to AI capabilities, demonstrating that more aware AI agents tend to exhibit higher levels of intelligent behaviors. Finally, we discuss the risks associated with AI awareness, including key topics in AI safety, alignment, and broader ethical concerns.\nAI awareness is a double-edged sword: it improves general capabilities, i.e., reasoning, safety, while also raises concerns around misalignment and societal risks, demanding careful oversight as AI capabilities grow. On the whole, our interdisciplinary review provides a roadmap for future research and aims to clarify the role of AI awareness in the ongoing development of intelligent machines.', 'abstract_zh': '近期人工智能领域的突破带来了具备强大推理、语言理解和问题解决能力的系统，这些进展促使人们重新审视人工智能意识，将其视为可测量和功能性的能力而非哲学意义上的意识。本文综述了新兴的人工智能意识景观，涵盖元认知（自我状态的表征和推理）、自我意识（识别自身身份、知识、限制等）、社会意识（模型其他代理的知识、意图和行为）以及情境意识（评估并响应其操作环境）。首先，我们基于认知科学、心理学和计算理论的见解，追溯意识的理论基础，并探讨四种不同形式的人工智能意识在当今最先进的人工智能系统中的表现。其次，我们系统地分析现有的评估方法和实证研究结果，以更好地理解这些表现。随后，我们探讨了人工智能意识与人工智能能力之间的密切联系，表明更具有意识的人工智能代理往往表现出更高的智能行为水平。最后，我们讨论了人工智能意识带来的风险，包括人工智能安全性、对齐以及更广泛伦理问题的焦点话题。人工智能意识是一把双刃剑：它提高了人工智能的一般能力，如推理和安全性，同时也引发了脱节和社会风险的担忧，要求随着人工智能能力的增长进行谨慎监管。本跨学科综述为未来研究提供了路线图，并旨在阐明人工智能意识在智能机器持续发展中所扮演的角色。', 'title_zh': 'AI意识'}
{'arxiv_id': 'arXiv:2504.20082', 'title': 'Evolution of AI in Education: Agentic Workflows', 'authors': 'Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif', 'link': 'https://arxiv.org/abs/2504.20082', 'abstract': 'Artificial intelligence (AI) has transformed various aspects of education, with large language models (LLMs) driving advancements in automated tutoring, assessment, and content generation. However, conventional LLMs are constrained by their reliance on static training data, limited adaptability, and lack of reasoning. To address these limitations and foster more sustainable technological practices, AI agents have emerged as a promising new avenue for educational innovation. In this review, we examine agentic workflows in education according to four major paradigms: reflection, planning, tool use, and multi-agent collaboration. We critically analyze the role of AI agents in education through these key design paradigms, exploring their advantages, applications, and challenges. To illustrate the practical potential of agentic systems, we present a proof-of-concept application: a multi-agent framework for automated essay scoring. Preliminary results suggest this agentic approach may offer improved consistency compared to stand-alone LLMs. Our findings highlight the transformative potential of AI agents in educational settings while underscoring the need for further research into their interpretability, trustworthiness, and sustainable impact on pedagogical impact.', 'abstract_zh': '人工智能（AI）已经改变了教育的各个方面，大规模语言模型（LLMs）推动了自动化辅导、评估和内容生成的进步。然而，传统LLMs受限于其对静态训练数据的依赖、有限的适应能力和推理能力的缺乏。为了解决这些限制并促进更可持续的技术实践，AI代理成为了教育创新的一个有前景的新途径。在本文综述中，我们根据四种主要范式——反思、规划、工具使用和多代理协作——探讨教育中的代理工作流程。我们通过这些关键设计理念批判性地分析AI代理在教育中的作用，探索其优势、应用和挑战。为了展示代理系统实践潜力，我们提出一个概念验证应用：一个自动作文评分的多代理框架。初步结果表明，这种代理方法可能在一致性方面优于独立的LLMs。我们的研究结果强调了AI代理在教育环境中的变革潜力，同时强调了进一步研究其可解释性、可信性和对教学影响的可持续影响的必要性。', 'title_zh': 'AI在教育中的进化：自主工作流程'}
{'arxiv_id': 'arXiv:2504.20998', 'title': 'YoChameleon: Personalized Vision and Language Generation', 'authors': 'Thao Nguyen, Krishna Kumar Singh, Jing Shi, Trung Bui, Yong Jae Lee, Yuheng Li', 'link': 'https://arxiv.org/abs/2504.20998', 'abstract': 'Large Multimodal Models (e.g., GPT-4, Gemini, Chameleon) have evolved into powerful tools with millions of users. However, they remain generic models and lack personalized knowledge of specific user concepts. Previous work has explored personalization for text generation, yet it remains unclear how these methods can be adapted to new modalities, such as image generation. In this paper, we introduce Yo\'Chameleon, the first attempt to study personalization for large multimodal models. Given 3-5 images of a particular concept, Yo\'Chameleon leverages soft-prompt tuning to embed subject-specific information to (i) answer questions about the subject and (ii) recreate pixel-level details to produce images of the subject in new contexts. Yo\'Chameleon is trained with (i) a self-prompting optimization mechanism to balance performance across multiple modalities, and (ii) a ``soft-positive" image generation approach to enhance image quality in a few-shot setting.', 'abstract_zh': "大型多模态模型（如GPT-4、Gemini、Chameleon）已经演变成强大的工具，拥有数百万用户。然而，它们仍然是通用模型，缺乏特定用户概念的个性化知识。虽然以往的工作探讨了文本生成的个性化方法，但尚不清楚这些方法如何适应新的模态，如图像生成。在本文中，我们引入了Yo'Chameleon，这是首个研究大型多模态模型个性化的方法。给定特定概念的3-5张图片，Yo'Chameleon利用软提示调谐将主题特定的信息嵌入其中，以(i) 回答关于主题的问题和(ii) 重建像素级细节，从而在新上下文中生成主题的图像。Yo'Chameleon通过(i) 自我提示优化机制来平衡多模态下的性能，以及(ii) “软正面”图像生成方法在少样本设置中提升图像质量来进行训练。", 'title_zh': 'YoChameleon: 个性化视觉与语言生成'}
{'arxiv_id': 'arXiv:2504.20997', 'title': 'Toward Efficient Exploration by Large Language Model Agents', 'authors': 'Dilip Arumugam, Thomas L. Griffiths', 'link': 'https://arxiv.org/abs/2504.20997', 'abstract': 'A burgeoning area within reinforcement learning (RL) is the design of sequential decision-making agents centered around large language models (LLMs). While autonomous decision-making agents powered by modern LLMs could facilitate numerous real-world applications, such successes demand agents that are capable of data-efficient RL. One key obstacle to achieving data efficiency in RL is exploration, a challenge that we demonstrate many recent proposals for LLM agent designs struggle to contend with. Meanwhile, classic algorithms from the RL literature known to gracefully address exploration require technical machinery that can be challenging to operationalize in purely natural language settings. In this work, rather than relying on finetuning or in-context learning to coax LLMs into implicitly imitating a RL algorithm, we illustrate how LLMs can be used to explicitly implement an existing RL algorithm (Posterior Sampling for Reinforcement Learning) whose capacity for statistically-efficient exploration is already well-studied. We offer empirical results demonstrating how our LLM-based implementation of a known, data-efficient RL algorithm can be considerably more effective in natural language tasks that demand prudent exploration.', 'abstract_zh': '强化学习领域内一个 burgeoning 的研究方向是围绕大规模语言模型 (LLMs) 设计 sequential 决策代理。在由现代 LLMs 驱动的自主决策代理有可能促进众多现实世界应用的同时，这样的成功需要具备数据高效 RL 的代理。实现 RL 中数据效率的一个关键障碍是探索，许多近期的 LLM 代理设计提议难以应对这一挑战。与此同时，RL 文献中经典的解决探索问题的技术虽然表现良好，但在纯自然语言环境中实现却具有技术挑战性。在本文中，我们并非依靠调优或基于上下文学习来引导 LLMs 显式模仿一个 RL 算法，而是展示了如何利用 LLMs 显式实现一个已有的 RL 算法（强化学习中的后验采样），该算法的统计高效探索能力已经得到了充分研究。我们提供了实验证据，证明我们基于 LLM 的已知数据高效 RL 算法实现方式在需要明智探索的自然语言任务中表现出了显著的效果。', 'title_zh': '大型语言模型智能体高效探索的方法研究'}
{'arxiv_id': 'arXiv:2504.20988', 'title': 'Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning', 'authors': 'Atul Sharma, Kavindu Herath, Saurabh Bagchi, Chaoyue Liu, Somali Chaterji', 'link': 'https://arxiv.org/abs/2504.20988', 'abstract': "We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm for collaborative machine learning that combines the strengths of Federated Learning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier communication structure that avoids the single point of failure inherent in FL and outperforms the state-of-the-art P2PL framework, Epidemic Learning Local (ELL). At equal communication budgets (total edges), HSL achieves higher performance than ELL, while at significantly lower communication budgets, it can match ELL's performance. For instance, with only 400 edges, HSL reaches the same test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on CIFAR-10, demonstrating its suitability for resource-constrained systems. HSL also achieves stronger consensus among nodes after mixing, resulting in improved performance with fewer training rounds. We substantiate these claims through rigorous theoretical analyses and extensive experimental results, showcasing HSL's practicality for large-scale collaborative learning.", 'abstract_zh': 'Hub and Spoke Learning: A Novel Paradigm for Collaborative Machine Learning', 'title_zh': '核心节点与 spoke 学习：高效可扩展的协作机器学习'}
{'arxiv_id': 'arXiv:2504.20970', 'title': 'SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features', 'authors': 'Mete Erdogan, Sebnem Demirtas', 'link': 'https://arxiv.org/abs/2504.20970', 'abstract': 'Accurate and early diagnosis of pneumonia through X-ray imaging is essential for effective treatment and improved patient outcomes. Recent advancements in machine learning have enabled automated diagnostic tools that assist radiologists in making more reliable and efficient decisions. In this work, we propose a Singular Value Decomposition-based Least Squares (SVD-LS) framework for multi-class pneumonia classification, leveraging powerful feature representations from state-of-the-art self-supervised and transfer learning models. Rather than relying on computationally expensive gradient based fine-tuning, we employ a closed-form, non-iterative classification approach that ensures efficiency without compromising accuracy. Experimental results demonstrate that SVD-LS achieves competitive performance while offering significantly reduced computational costs, making it a viable alternative for real-time medical imaging applications.', 'abstract_zh': '基于奇异值分解的最小二乘法多类别肺炎分类框架：利用先进自监督和迁移学习模型的强大特征表示实现准确且高效的诊断', 'title_zh': '基于SVD的最小二乘法在深特征下的X射线肺炎分类'}
{'arxiv_id': 'arXiv:2504.20964', 'title': 'OSVBench: Benchmarking LLMs on Specification Generation Tasks for Operating System Verification', 'authors': 'Shangyu Li, Juyong Jiang, Tiancheng Zhao, Jiasi Shen', 'link': 'https://arxiv.org/abs/2504.20964', 'abstract': 'We introduce OSVBench, a new benchmark for evaluating Large Language Models (LLMs) in generating complete specification code pertaining to operating system kernel verification tasks. The benchmark first defines the specification generation problem into a program synthesis problem within a confined scope of syntax and semantics by providing LLMs with the programming model. The LLMs are required to understand the provided verification assumption and the potential syntax and semantics space to search for, then generate the complete specification for the potentially buggy operating system code implementation under the guidance of the high-level functional description of the operating system. This benchmark is built upon a real-world operating system kernel, Hyperkernel, and consists of 245 complex specification generation tasks in total, each is a long context task of about 20k-30k tokens. Our comprehensive evaluation of 12 LLMs exhibits the limited performance of the current LLMs on the specification generation tasks for operating system verification. Significant disparities in their performance on the benchmark highlight differences in their ability to handle long-context code generation tasks. The evaluation toolkit and benchmark are available at this https URL.', 'abstract_zh': 'OSVBench：一种用于评估大型语言模型在生成操作系统内核验证相关完整规范代码方面的基准测试', 'title_zh': 'OSVBench: 在操作系统验证规范生成任务上评估LLM性能'}
{'arxiv_id': 'arXiv:2504.20946', 'title': 'Trace-of-Thought: Enhanced Arithmetic Problem Solving via Reasoning Distillation From Large to Small Language Models', 'authors': 'Tyler McDonald, Ali Emami', 'link': 'https://arxiv.org/abs/2504.20946', 'abstract': 'As Large Language Models (LLMs) continue to be leveraged for daily tasks, prompt engineering remains an active field of contribution within computational linguistics, particularly in domains requiring specialized knowledge such as arithmetic reasoning. While these LLMs are optimized for a variety of tasks, their exhaustive employment may become computationally or financially cumbersome for small teams. Additionally, complete reliance on proprietary, closed-source models often limits customization and adaptability, posing significant challenges in research and application scalability. Instead, by leveraging open-source models at or below 7 billion parameters, we can optimize our resource usage while still observing remarkable gains over standard prompting approaches. To cultivate this notion, we introduce Trace-of-Thought Prompting, a simple, zero-shot prompt engineering method that instructs LLMs to create observable subproblems using critical problem-solving, specifically designed to enhance arithmetic reasoning capabilities. When applied to open-source models in tandem with GPT-4, we observe that Trace-of-Thought not only allows novel insight into the problem-solving process but also introduces performance gains as large as 125% on language models at or below 7 billion parameters. This approach underscores the potential of open-source initiatives in democratizing AI research and improving the accessibility of high-quality computational linguistics applications.', 'abstract_zh': '大型语言模型（LLMs）在日常任务中的持续应用使得提示工程仍然是计算语言学中的一个活跃研究领域，特别是在需要专门知识的领域，如算术推理。虽然这些LLMs优化了多种任务，但其全面应用可能对小型团队来说在计算或财务方面变得臃肿。此外，完全依赖于专有的闭源模型往往会限制定制化和适应性，对研究和应用的可扩展性造成重大挑战。相反，通过利用参数量在70亿以下的开源模型，我们可以在优化资源使用的同时，仍然观察到显著优于标准提示方法的收益。为了培养这一观点，我们引入了思路追踪提示，这是一种简单且零样本的提示工程技术，指导LLMs使用关键问题解决技巧创建可观察的子问题，特别设计用于增强算术推理能力。当与GPT-4一起应用于开源模型时，我们观察到思路追踪不仅允许对问题解决过程进行新颖的洞察，还能够在参数量在70亿以下的语言模型中引入高达125%的性能提升。这种方法强调了开源倡议在民主化AI研究和提高高质量计算语言学应用的可访问性方面的能力。', 'title_zh': '思维轨迹：从大规模到小规模语言模型的推理提炼以增强算术问题求解'}
{'arxiv_id': 'arXiv:2504.20922', 'title': 'DYNAMAX: Dynamic computing for Transformers and Mamba based architectures', 'authors': 'Miguel Nogales, Matteo Gambella, Manuel Roveri', 'link': 'https://arxiv.org/abs/2504.20922', 'abstract': "Early exits (EEs) offer a promising approach to reducing computational costs and latency by dynamically terminating inference once a satisfactory prediction confidence on a data sample is achieved. Although many works integrate EEs into encoder-only Transformers, their application to decoder-only architectures and, more importantly, Mamba models, a novel family of state-space architectures in the LLM realm, remains insufficiently explored. This work introduces DYNAMAX, the first framework to exploit the unique properties of Mamba architectures for early exit mechanisms. We not only integrate EEs into Mamba but also repurpose Mamba as an efficient EE classifier for both Mamba-based and transformer-based LLMs, showcasing its versatility. Our experiments employ the Mistral 7B transformer compared to the Codestral 7B Mamba model, using data sets such as TruthfulQA, CoQA, and TriviaQA to evaluate computational savings, accuracy, and consistency. The results highlight the adaptability of Mamba as a powerful EE classifier and its efficiency in balancing computational cost and performance quality across NLP tasks. By leveraging Mamba's inherent design for dynamic processing, we open pathways for scalable and efficient inference in embedded applications and resource-constrained environments. This study underscores the transformative potential of Mamba in redefining dynamic computing paradigms for LLMs.", 'abstract_zh': 'Early Exits for Mamba Models: Exploiting Unique Properties for Efficient Inference in LLMs', 'title_zh': 'DYNAMAX: 动态计算用于Transformer和Mamba基架构'}
{'arxiv_id': 'arXiv:2504.20910', 'title': 'When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines', 'authors': 'Sachin R. Pendse, Darren Gergle, Rachel Kornfield, Jonah Meyerhoff, David Mohr, Jina Suh, Annie Wescott, Casey Williams, Jessica Schleider', 'link': 'https://arxiv.org/abs/2504.20910', 'abstract': 'Red-teaming is a core part of the infrastructure that ensures that AI models do not produce harmful content. Unlike past technologies, the black box nature of generative AI systems necessitates a uniquely interactional mode of testing, one in which individuals on red teams actively interact with the system, leveraging natural language to simulate malicious actors and solicit harmful outputs. This interactional labor done by red teams can result in mental health harms that are uniquely tied to the adversarial engagement strategies necessary to effectively red team. The importance of ensuring that generative AI models do not propagate societal or individual harm is widely recognized -- one less visible foundation of end-to-end AI safety is also the protection of the mental health and wellbeing of those who work to keep model outputs safe. In this paper, we argue that the unmet mental health needs of AI red-teamers is a critical workplace safety concern. Through analyzing the unique mental health impacts associated with the labor done by red teams, we propose potential individual and organizational strategies that could be used to meet these needs, and safeguard the mental health of red-teamers. We develop our proposed strategies through drawing parallels between common red-teaming practices and interactional labor common to other professions (including actors, mental health professionals, conflict photographers, and content moderators), describing how individuals and organizations within these professional spaces safeguard their mental health given similar psychological demands. Drawing on these protective practices, we describe how safeguards could be adapted for the distinct mental health challenges experienced by red teaming organizations as they mitigate emerging technological risks on the new digital frontlines.', 'abstract_zh': '基于红队测试者未满足的心理健康需求的企业安全问题探讨', 'title_zh': '当AI测试我们时：保障数字前沿的 mental health'}
{'arxiv_id': 'arXiv:2504.20903', 'title': 'Modeling AI-Human Collaboration as a Multi-Agent Adaptation', 'authors': 'Prothit Sen, Sai Mihir Jakkaraju', 'link': 'https://arxiv.org/abs/2504.20903', 'abstract': 'We develop an agent-based simulation to formalize AI-human collaboration as a function of task structure, advancing a generalizable framework for strategic decision-making in organizations. Distinguishing between heuristic-based human adaptation and rule-based AI search, we model interactions across modular (parallel) and sequenced (interdependent) tasks using an NK model. Our results reveal that in modular tasks, AI often substitutes for humans - delivering higher payoffs unless human expertise is very high, and the AI search space is either narrowly focused or extremely broad. In sequenced tasks, interesting complementarities emerge. When an expert human initiates the search and AI subsequently refines it, aggregate performance is maximized. Conversely, when AI leads, excessive heuristic refinement by the human can reduce payoffs. We also show that even "hallucinatory" AI - lacking memory or structure - can improve outcomes when augmenting low-capability humans by helping escape local optima. These results yield a robust implication: the effectiveness of AI-human collaboration depends less on context or industry, and more on the underlying task structure. By elevating task decomposition as the central unit of analysis, our model provides a transferable lens for strategic decision-making involving humans and an agentic AI across diverse organizational settings.', 'abstract_zh': '我们开发了一个基于代理的仿真模型，以规范AI与人类的合作方式，进一分可推广的战略决策框架，该框架基于任务结构。我们区分基于启发式的人类适应和基于规则的AI搜索，使用NK模型建模模块化（并行）和序列化（相互依赖）任务之间的交互。研究结果表明，在模块化任务中，除非人类专业知识非常高，或者AI搜索空间要么非常狭窄，要么非常广泛，否则AI经常替代人类，提供更高的回报。在序列化任务中，出现了有趣的互补性。当专家人类启动搜索，AI随后对其进行改进时，整体绩效最大化。相反，当AI领先时，人类过度的启发式精炼可能降低回报。我们还表明，即使是缺乏记忆和结构的“幻觉”AI，通过帮助低能力人类跳出局部最优解，也可以改善结果。这些结果得出一项稳健的结论：AI与人类合作的有效性更多地取决于任务结构，而不是具体环境或行业。通过将任务分解作为核心分析单位，我们的模型为涉及人类和机构自主AI的战略决策提供了可转移的视角，适用于各种组织环境。', 'title_zh': '将AI-人类协作建模为多agent自适应过程'}
{'arxiv_id': 'arXiv:2504.20902', 'title': 'Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers', 'authors': "Quentin Guimard, Moreno D'Incà, Massimiliano Mancini, Elisa Ricci", 'link': 'https://arxiv.org/abs/2504.20902', 'abstract': 'A person downloading a pre-trained model from the web should be aware of its biases. Existing approaches for bias identification rely on datasets containing labels for the task of interest, something that a non-expert may not have access to, or may not have the necessary resources to collect: this greatly limits the number of tasks where model biases can be identified. In this work, we present Classifier-to-Bias (C2B), the first bias discovery framework that works without access to any labeled data: it only relies on a textual description of the classification task to identify biases in the target classification model. This description is fed to a large language model to generate bias proposals and corresponding captions depicting biases together with task-specific target labels. A retrieval model collects images for those captions, which are then used to assess the accuracy of the model w.r.t. the given biases. C2B is training-free, does not require any annotations, has no constraints on the list of biases, and can be applied to any pre-trained model on any classification task. Experiments on two publicly available datasets show that C2B discovers biases beyond those of the original datasets and outperforms a recent state-of-the-art bias detection baseline that relies on task-specific annotations, being a promising first step toward addressing task-agnostic unsupervised bias detection.', 'abstract_zh': '从网络下载预训练模型的人应意识到其偏差。现有的偏见识别方法依赖于包含目标任务标签的数据集，这可能是非专家无法访问的，或无法收集足够资源获取的：这极大地限制了可以识别模型偏见的任务数量。在本文中，我们提出了Classifier-to-Bias (C2B)，这是第一个无需访问任何标注数据的偏见发现框架：它仅依赖于分类任务的文字描述来识别目标分类模型中的偏见。该描述被输入到大型语言模型中，以生成偏见提案及其对应的描述偏见的图像，并结合具体任务的目标标签。检索模型收集这些描述的图像，然后用于评估模型在给定偏见方面的准确性。C2B 是无需训练的，不需要任何标注，没有偏见列表的限制，并可以应用于任何分类任务的预训练模型。在两个公开数据集上的实验表明，C2B 发现了超出原始数据集的偏见，并优于依赖于特定任务标注的最新偏见检测基准，这朝着实现任务无关的无监督偏见检测迈出了有希望的第一步。', 'title_zh': '分类器偏差检测：迈向无监督自动偏差检测的可视化分类器'}
{'arxiv_id': 'arXiv:2504.20887', 'title': 'Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation', 'authors': 'Harry Mead, Clarissa Costen, Bruno Lacerda, Nick Hawes', 'link': 'https://arxiv.org/abs/2504.20887', 'abstract': 'When optimising for conditional value at risk (CVaR) using policy gradients (PG), current meth- ods rely on discarding a large proportion of tra- jectories, resulting in poor sample efficiency. We propose a reformulation of the CVaR optimisation problem by capping the total return of trajecto- ries used in training, rather than simply discard- ing them, and show that this is equivalent to the original problem if the cap is set appropriately. We show, with empirical results in an number of environments, that this reformulation of the prob- lem results in consistently improved performance compared to baselines.', 'abstract_zh': '通过策略梯度优化条件价值 at 风险（CVaR）的问题重述：提高样本效率的方法', 'title_zh': '返回上限设置：基于样本高效的CVaR策略梯度优化'}
{'arxiv_id': 'arXiv:2504.20869', 'title': 'Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks', 'authors': 'Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse', 'link': 'https://arxiv.org/abs/2504.20869', 'abstract': 'Graph neural networks have been widely utilized to solve graph-related tasks because of their strong learning power in utilizing the local information of neighbors. However, recent studies on graph adversarial attacks have proven that current graph neural networks are not robust against malicious attacks. Yet much of the existing work has focused on the optimization objective based on attack performance to obtain (near) optimal perturbations, but paid less attention to the strength quantification of each perturbation such as the injection of a particular node/link, which makes the choice of perturbations a black-box model that lacks interpretability. In this work, we propose the concept of noise to quantify the attack strength of each adversarial link. Furthermore, we propose three attack strategies based on the defined noise and classification margins in terms of single and multiple steps optimization. Extensive experiments conducted on benchmark datasets against three representative graph neural networks demonstrate the effectiveness of the proposed attack strategies. Particularly, we also investigate the preferred patterns of effective adversarial perturbations by analyzing the corresponding properties of the selected perturbation nodes.', 'abstract_zh': '基于噪声量化的图神经网络攻击策略研究', 'title_zh': '结构扰动对图对抗攻击噪声的量化'}
{'arxiv_id': 'arXiv:2504.20862', 'title': 'Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data', 'authors': 'Dayananda Herurkar, Jörn Hees, Vesselin Tzvetkov, Andreas Dengel', 'link': 'https://arxiv.org/abs/2504.20862', 'abstract': 'The remarkable success of Deep Learning approaches is often based and demonstrated on large public datasets. However, when applying such approaches to internal, private datasets, one frequently faces challenges arising from structural differences in the datasets, domain shift, and the lack of labels. In this work, we introduce Tabular Data Adapters (TDA), a novel method for generating soft labels for unlabeled tabular data in outlier detection tasks. By identifying statistically similar public datasets and transforming private data (based on a shared autoencoder) into a format compatible with state-of-the-art public models, our approach enables the generation of weak labels. It thereby can help to mitigate the cold start problem of labeling by basing on existing outlier detection models for public datasets. In experiments on 50 tabular datasets across different domains, we demonstrate that our method is able to provide more accurate annotations than baseline approaches while reducing computational time. Our approach offers a scalable, efficient, and cost-effective solution, to bridge the gap between public research models and real-world industrial applications.', 'abstract_zh': '基于表型数据适配器（TDA）的无标记表型数据生成软标签方法', 'title_zh': '表格数据适配器：提高未标记私人数据的异常检测效果'}
{'arxiv_id': 'arXiv:2504.20859', 'title': 'X-Cross: Dynamic Integration of Language Models for Cross-Domain Sequential Recommendation', 'authors': 'Guy Hadad, Haggai Roitman, Yotam Eshel, Bracha Shapira, Lior Rokach', 'link': 'https://arxiv.org/abs/2504.20859', 'abstract': "As new products are emerging daily, recommendation systems are required to quickly adapt to possible new domains without needing extensive retraining. This work presents ``X-Cross'' -- a novel cross-domain sequential-recommendation model that recommends products in new domains by integrating several domain-specific language models; each model is fine-tuned with low-rank adapters (LoRA). Given a recommendation prompt, operating layer by layer, X-Cross dynamically refines the representation of each source language model by integrating knowledge from all other models. These refined representations are propagated from one layer to the next, leveraging the activations from each domain adapter to ensure domain-specific nuances are preserved while enabling adaptability across domains. Using Amazon datasets for sequential recommendation, X-Cross achieves performance comparable to a model that is fine-tuned with LoRA, while using only 25% of the additional parameters. In cross-domain tasks, such as adapting from Toys domain to Tools, Electronics or Sports, X-Cross demonstrates robust performance, while requiring about 50%-75% less fine-tuning data than LoRA to make fine-tuning effective. Furthermore, X-Cross achieves significant improvement in accuracy over alternative cross-domain baselines. Overall, X-Cross enables scalable and adaptive cross-domain recommendations, reducing computational overhead and providing an efficient solution for data-constrained environments.", 'abstract_zh': '随着新产品不断涌现，推荐系统需要快速适应新的领域而无需进行大量重新训练。本文提出了“X-Cross”——一种新型跨域序列推荐模型，通过集成多个领域特定的语言模型进行产品推荐；每个模型使用低秩适配器（LoRA）进行微调。给定一个推荐提示，X-Cross逐层操作，动态地通过整合其他所有模型的知识来细化每个源语言模型的表示。这些细化后的表示会在各层之间传递，利用每个领域适配器的激活，确保保持领域特定的细微差别，同时在跨域之间实现适应性。使用Amazon数据集进行序列推荐，X-Cross在附加参数仅为LoRA模型的25%的情况下，实现了与之相当的性能。在跨域任务中，如从Toys领域适应到Tools、Electronics或Sports等领域，X-Cross表现出稳健的性能，所需微调数据量仅为LoRA的50%-75%。此外，X-Cross在与替代跨域基线相比在准确率上取得了显著改进。总体而言，X-Cross使跨域推荐具有可扩展性和适应性，减少了计算开销，并为数据受限的环境提供了高效的解决方案。', 'title_zh': 'X-交叉：跨域序列推荐中的语言模型动态集成'}
{'arxiv_id': 'arXiv:2504.20854', 'title': 'Towards Easy and Realistic Network Infrastructure Testing for Large-scale Machine Learning', 'authors': 'Jinsun Yoo, ChonLam Lao, Lianjie Cao, Bob Lantz, Minlan Yu, Tushar Krishna, Puneet Sharma', 'link': 'https://arxiv.org/abs/2504.20854', 'abstract': 'This paper lays the foundation for Genie, a testing framework that captures the impact of real hardware network behavior on ML workload performance, without requiring expensive GPUs. Genie uses CPU-initiated traffic over a hardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim simulator to model interaction between the network and the ML workload.', 'abstract_zh': '本文为Genie测试框架奠定了基础，该框架通过CPU驱动的流量在硬件测试床上模拟GPU到GPU通信，无需使用昂贵的GPU，来捕捉真实硬件网络行为对ML工作负载性能的影响，并适应ASTRA-sim模拟器以建模网络与ML工作负载之间的交互。', 'title_zh': '面向大规模机器学习的简单可行的网络基础设施测试方法'}
{'arxiv_id': 'arXiv:2504.20851', 'title': 'Fostering Self-Directed Growth with Generative AI: Toward a New Learning Analytics Framework', 'authors': 'Qianrun Mao', 'link': 'https://arxiv.org/abs/2504.20851', 'abstract': 'In an era increasingly shaped by decentralized knowledge ecosystems and pervasive AI technologies, fostering sustainable learner agency has become a critical educational imperative. This study introduces a novel conceptual framework integrating Generative Artificial Intelligence and Learning Analytics to cultivate Self-Directed Growth, a dynamic competency that enables learners to iteratively drive their own developmental pathways across diverse this http URL upon critical gaps in current research on Self Directed Learning and AI-mediated education, the proposed Aspire to Potentials for Learners (A2PL) model reconceptualizes the interplay of learner aspirations, complex thinking, and summative self-assessment within GAI supported this http URL implications for future intervention design and learning analytics applications are discussed, positioning Self-Directed Growth as a pivotal axis for developing equitable, adaptive, and sustainable learning systems in the digital era.', 'abstract_zh': '在去中心化知识生态系统和普及的人工智能技术日益影响的时代，培养可持续的学习者自主性已成为教育的迫切需求。本研究提出了一个新颖的概念框架，将生成式人工智能与学习分析相结合，以培养自我导向成长这一动态能力，使学习者能够在多种情境中迭代地推动自己的发展路径。本研究基于当前自我导向学习和人工智能介导教育研究中的关键缺口，提出了一个名为“学习者潜力追求模型”（A2PL）的模型，重新构想了在生成式人工智能支持的学习环境中，学习者抱负、复杂思维和总结性自我评估之间的相互作用。讨论了该模型对未来干预设计和学习分析应用的意义，将自我导向成长定位为数字时代发展公平、适应性和可持续学习系统的关键轴心。', 'title_zh': '利用生成式AI促进自主成长： toward一种新学习分析框架'}
{'arxiv_id': 'arXiv:2504.20848', 'title': 'Mitigating the Structural Bias in Graph Adversarial Defenses', 'authors': 'Junyuan Fang, Huimin Liu, Han Yang, Jiajing Wu, Zibin Zheng, Chi K. Tse', 'link': 'https://arxiv.org/abs/2504.20848', 'abstract': 'In recent years, graph neural networks (GNNs) have shown great potential in addressing various graph structure-related downstream tasks. However, recent studies have found that current GNNs are susceptible to malicious adversarial attacks. Given the inevitable presence of adversarial attacks in the real world, a variety of defense methods have been proposed to counter these attacks and enhance the robustness of GNNs. Despite the commendable performance of these defense methods, we have observed that they tend to exhibit a structural bias in terms of their defense capability on nodes with low degree (i.e., tail nodes), which is similar to the structural bias of traditional GNNs on nodes with low degree in the clean graph. Therefore, in this work, we propose a defense strategy by including hetero-homo augmented graph construction, $k$NN augmented graph construction, and multi-view node-wise attention modules to mitigate the structural bias of GNNs against adversarial attacks. Notably, the hetero-homo augmented graph consists of removing heterophilic links (i.e., links connecting nodes with dissimilar features) globally and adding homophilic links (i.e., links connecting nodes with similar features) for nodes with low degree. To further enhance the defense capability, an attention mechanism is adopted to adaptively combine the representations from the above two kinds of graph views. We conduct extensive experiments to demonstrate the defense and debiasing effect of the proposed strategy on benchmark datasets.', 'abstract_zh': '近年来，图神经网络（GNNs）在处理各种图结构相关的下游任务中展示了巨大的潜力。然而，近期研究表明，当前的GNNs容易受到恶意针对的 adversarial攻击的影响。鉴于实际应用场景中不可避免存在 adversarial攻击，已经提出了一系列防御方法来应对这些攻击并增强GNNs的鲁棒性。尽管这些防御方法表现出色，但我们发现它们在对抗针对低度节点（即尾节点）的攻击时存在结构偏差，这种偏差与其在干净图中对低度节点的表现相似。因此，在本工作中，我们提出了一种防御策略，通过引入异构同构增强图构建、$k$NN 增强图构建以及多视图节点注意力模块来减轻GNNs在对抗攻击中的结构偏差。值得注意的是，异构同构增强图包括全局移除异构链接（即连接特征不同的节点的链接）并为低度节点增加同构链接（即连接特征相似的节点的链接）。为增强防御能力，我们采用注意力机制自适应地结合来自上述两种图视图的表示。我们通过广泛的实验展示了该策略在基准数据集上的防御和去偏差效果。', 'title_zh': '缓解图对抗防御中的结构偏见'}
{'arxiv_id': 'arXiv:2504.20837', 'title': 'RadSAM: Segmenting 3D radiological images with a 2D promptable model', 'authors': 'Julien Khlaut, Elodie Ferreres, Daniel Tordjman, Hélène Philippe, Tom Boeken, Pierre Manceron, Corentin Dancette', 'link': 'https://arxiv.org/abs/2504.20837', 'abstract': "Medical image segmentation is a crucial and time-consuming task in clinical care, where mask precision is extremely important. The Segment Anything Model (SAM) offers a promising approach, as it provides an interactive interface based on visual prompting and edition to refine an initial segmentation. This model has strong generalization capabilities, does not rely on predefined classes, and adapts to diverse objects; however, it is pre-trained on natural images and lacks the ability to process medical data effectively. In addition, this model is built for 2D images, whereas a whole medical domain is based on 3D images, such as CT and MRI. Recent adaptations of SAM for medical imaging are based on 2D models, thus requiring one prompt per slice to segment 3D objects, making the segmentation process tedious. They also lack important features such as editing. To bridge this gap, we propose RadSAM, a novel method for segmenting 3D objects with a 2D model from a single prompt. In practice, we train a 2D model using noisy masks as initial prompts, in addition to bounding boxes and points. We then use this novel prompt type with an iterative inference pipeline to reconstruct the 3D mask slice-by-slice. We introduce a benchmark to evaluate the model's ability to segment 3D objects in CT images from a single prompt and evaluate the models' out-of-domain transfer and edition capabilities. We demonstrate the effectiveness of our approach against state-of-the-art models on this benchmark using the AMOS abdominal organ segmentation dataset.", 'abstract_zh': '一种基于单个提示的2D模型分割3D医疗对象的方法：RadSAM', 'title_zh': 'RadSAM: 使用可提示的2D模型分割3D放射影像'}
{'arxiv_id': 'arXiv:2504.20834', 'title': 'Reinforcement Learning for LLM Reasoning Under Memory Constraints', 'authors': 'Alan Lee, Harry Tong', 'link': 'https://arxiv.org/abs/2504.20834', 'abstract': 'We explore reinforcement learning (RL) techniques to enhance reasoning within targeted problem spaces in large language models (LLMs) under memory and compute constraints. Our focus is on critic-free methods compatible with LoRA fine-tuning on a single 40GB GPU, a common limitation in academic settings. We introduce S-GRPO, a memory-efficient variant of Group Relative Policy Optimization, and T-SPMO, a token-level prefix matching strategy for fine-grained credit assignment. Despite limited resources, when used to fine-tune Qwen2-1.5B both methods significantly improve SVAMP benchmark accuracy from 46% to above 70% using LoRA training. T-SPMO also excels in multi-digit multiplication tasks, underscoring the potential of RL fine-tuning under hardware constraints. Additionally, we find that our full-token GRPO baseline under LoRA fine-tuning did not improve model performance (compared to base model) on either task, suggesting that our memory-efficient methods may act as a form of regularization that stabilizes training when only a small subset of parameters are updated.', 'abstract_zh': '我们探索在大语言模型（LLMs）的内存和计算约束条件下，强化学习（RL）技术在特定问题空间内增强推理的方法。我们的重点在于与LoRA单卡（40GB GPU）微调兼容的无价值函数方法。我们引入了S-GRPO，一种记忆高效的Group Relative Policy Optimization变体，以及T-SPMO，一种基于token级别的前缀匹配策略，用于细粒度的责任分配。尽管资源有限，这两种方法在使用LoRA训练时都能显著提高Qwen2-1.5B模型在SVAMP基准测试中的准确性，从46%提高到超过70%。T-SPMO在多位数乘法任务中也表现出色，突显了在硬件约束下RL微调的潜力。此外，我们发现，在LoRA微调下的完整token GRPO基线并未提高模型在这两个任务上的性能（与基础模型相比），这表明我们的记忆高效方法可能作为一种正则化手段，在仅更新一小部分参数时稳定训练。', 'title_zh': '基于内存约束条件下的大语言模型推理强化学习'}
{'arxiv_id': 'arXiv:2504.20829', 'title': 'GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion', 'authors': 'Jiaxin Hong, Sixu Chen, Shuoyang Sun, Hongyao Yu, Hao Fang, Yuqi Tan, Bin Chen, Shuhan Qi, Jiawei Li', 'link': 'https://arxiv.org/abs/2504.20829', 'abstract': 'As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene representation and novel view synthesis, its rapid adoption in safety-critical domains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of potential security vulnerabilities. This paper presents the first systematic study of backdoor threats in 3DGS pipelines. We identify that adversaries may implant backdoor views to induce malicious scene confusion during inference, potentially leading to environmental misperception in autonomous navigation or spatial distortion in immersive environments. To uncover this risk, we propose GuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap injects malicious views at specific attack viewpoints while preserving high-quality rendering in non-target views, ensuring minimal detectability and maximizing potential harm. Specifically, the proposed method consists of a three-stage pipeline (attack, stabilization, and normal training) to implant stealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing attack efficacy and perceptual realism to expose security risks in 3D rendering. Extensive experiments on both synthetic and real-world datasets demonstrate that GuassTrap can effectively embed imperceptible yet harmful backdoor views while maintaining high-quality rendering in normal views, validating its robustness, adaptability, and practical applicability.', 'abstract_zh': '3D高斯散斑中后门威胁的系统研究：GuassTrap新型污染攻击方法及其应用', 'title_zh': 'GaussTrap: 瞒天过海的3D高斯绘制目标场景混淆中毒攻击'}
{'arxiv_id': 'arXiv:2504.20808', 'title': 'SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings', 'authors': 'Florian Vahl, Jörn Griepenburg, Jan Gutsche, Jasper Güldenstein, Jianwei Zhang', 'link': 'https://arxiv.org/abs/2504.20808', 'abstract': "This paper introduces SoccerDiffusion, a transformer-based diffusion model designed to learn end-to-end control policies for humanoid robot soccer directly from real-world gameplay recordings. Using data collected from RoboCup competitions, the model predicts joint command trajectories from multi-modal sensor inputs, including vision, proprioception, and game state. We employ a distillation technique to enable real-time inference on embedded platforms that reduces the multi-step diffusion process to a single step. Our results demonstrate the model's ability to replicate complex motion behaviors such as walking, kicking, and fall recovery both in simulation and on physical robots. Although high-level tactical behavior remains limited, this work provides a robust foundation for subsequent reinforcement learning or preference optimization methods. We release the dataset, pretrained models, and code under: this https URL", 'abstract_zh': '本文介绍了SoccerDiffusion，这是一种基于变压器的扩散模型，旨在直接从实际比赛录像中学习人形机器人足球的端到端控制策略。利用RoboCup competitions收集的数据，该模型能够从多元传感器输入（包括视觉、本体感觉和比赛状态）中预测关节命令轨迹。我们采用蒸馏技术，使该模型能够实时在嵌入式平台上进行推理，将多步扩散过程缩减为一步。实验结果表明，该模型能够在仿真和物理机器人上复制复杂的运动行为，如行走、踢球和摔倒恢复。尽管高级战术行为仍受到限制，但本工作为后续的强化学习或偏好优化方法提供了坚实的基础。我们将在以下网址发布数据集、预训练模型和代码：this https URL。', 'title_zh': 'SoccerDiffusion: 从比赛记录学习端到端类人机器人足球'}
{'arxiv_id': 'arXiv:2504.20799', 'title': 'Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges', 'authors': 'Yunseo Lee, John Youngeun Song, Dongsun Kim, Jindae Kim, Mijung Kim, Jaechang Nam', 'link': 'https://arxiv.org/abs/2504.20799', 'abstract': 'Recent technical breakthroughs in large language models (LLMs) have enabled them to fluently generate source code. Software developers often leverage both general-purpose and code-specialized LLMs to revise existing code or even generate a whole function from scratch. These capabilities are also beneficial in no-code or low-code contexts, in which one can write programs without a technical background. However, due to their internal design, LLMs are prone to generating hallucinations, which are incorrect, nonsensical, and not justifiable information but difficult to identify its presence. This problem also occurs when generating source code. Once hallucinated code is produced, it is often challenging for users to identify and fix it, especially when such hallucinations can be identified under specific execution paths. As a result, the hallucinated code may remain unnoticed within the codebase. This survey investigates recent studies and techniques relevant to hallucinations generated by CodeLLMs. We categorize the types of hallucinations in the code generated by CodeLLMs, review existing benchmarks and mitigation strategies, and identify open challenges. Based on these findings, this survey outlines further research directions in the detection and removal of hallucinations produced by CodeLLMs.', 'abstract_zh': '最近在大规模语言模型（LLMs）领域的技术突破使得它们能够流畅地生成源代码。软件开发人员常常利用通用和代码专用的LLMs来修订现有代码，甚至从头生成一个完整的功能。这些能力在无代码或低代码环境中也非常有益，在这种环境中，人们可以在没有技术背景的情况下编写程序。然而，由于其内部设计，LLMs容易生成幻觉，这些幻觉是错误的、没有意义的且难以验证的信息，但难以识别它们的存在。这一问题同样出现在生成源代码的过程中。一旦生成了幻觉代码，用户往往难以识别和修复，特别是当这些幻觉在特定执行路径下才能被识别时，幻觉代码可能会在代码库中被忽视。本文综述了与CodeLLMs生成的幻觉相关的近期研究和技术。我们对CodeLLMs生成的代码中的幻觉类型进行了分类，回顾了现有的基准测试和缓解策略，并识别出开放挑战。基于这些发现，本文概述了进一步研究的方向，包括在CodeLLMs生成的幻觉检测和移除方面的研究方向。', 'title_zh': '代码生成型LLMs的幻觉现象：分类、基准、缓解与挑战'}
{'arxiv_id': 'arXiv:2504.20781', 'title': 'Using LLMs in Generating Design Rationale for Software Architecture Decisions', 'authors': 'Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin, Zengyang Li, Chen Yang', 'link': 'https://arxiv.org/abs/2504.20781', 'abstract': 'Design Rationale (DR) for software architecture decisions refers to the reasoning underlying architectural choices, which provides valuable insights into the different phases of the architecting process throughout software development. However, in practice, DR is often inadequately documented due to a lack of motivation and effort from developers. With the recent advancements in Large Language Models (LLMs), their capabilities in text comprehension, reasoning, and generation may enable the generation and recovery of DR for architecture decisions. In this study, we evaluated the performance of LLMs in generating DR for architecture decisions. First, we collected 50 Stack Overflow (SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture decisions to construct a dataset of 100 architecture-related problems. Then, we selected five LLMs to generate DR for the architecture decisions with three prompting strategies, including zero-shot, chain of thought (CoT), and LLM-based agents. With the DR provided by human experts as ground truth, the Precision of LLM-generated DR with the three prompting strategies ranges from 0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389. Additionally, 64.45% to 69.42% of the arguments of DR not mentioned by human experts are also helpful, 4.12% to 4.87% of the arguments have uncertain correctness, and 1.59% to 3.24% of the arguments are potentially misleading. Based on the results, we further discussed the pros and cons of the three prompting strategies and the strengths and limitations of the DR generated by LLMs.', 'abstract_zh': '面向软件架构决策的设计 rationale (DR) 生成：基于大型语言模型的性能评估', 'title_zh': '使用LLMs生成软件架构决策 reasoning'}
{'arxiv_id': 'arXiv:2504.20776', 'title': 'ECOSoundSet: a finely annotated dataset for the automated acoustic identification of Orthoptera and Cicadidae in North, Central and temperate Western Europe', 'authors': 'David Funosas, Elodie Massol, Yves Bas, Svenja Schmidt, Dominik Arend, Alexander Gebhard, Luc Barbaro, Sebastian König, Rafael Carbonell Font, David Sannier, Fernand Deroussen, Jérôme Sueur, Christian Roesti, Tomi Trilar, Wolfgang Forstmeier, Lucas Roger, Eloïsa Matheu, Piotr Guzik, Julien Barataud, Laurent Pelozuelo, Stéphane Puissant, Sandra Mueller, Björn Schuller, Jose M. Montoya, Andreas Triantafyllopoulos, Maxime Cauchoix', 'link': 'https://arxiv.org/abs/2504.20776', 'abstract': 'Currently available tools for the automated acoustic recognition of European insects in natural soundscapes are limited in scope. Large and ecologically heterogeneous acoustic datasets are currently needed for these algorithms to cross-contextually recognize the subtle and complex acoustic signatures produced by each species, thus making the availability of such datasets a key requisite for their development. Here we present ECOSoundSet (European Cicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings of 200 orthopteran and 24 cicada species (217 and 26 respective taxa when including subspecies) present in North, Central, and temperate Western Europe (Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland, Luxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly through targeted fieldwork in South France and Catalonia and partly through contributions from various European entomologists. The dataset is composed of a combination of coarsely labeled recordings, for which we can only infer the presence, at some point, of their target species (weak labeling), and finely annotated recordings, for which we know the specific time and frequency range of each insect sound present in the recording (strong labeling). We also provide a train/validation/test split of the strongly labeled recordings, with respective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate their incorporation in the training and evaluation of deep learning algorithms. This dataset could serve as a meaningful complement to recordings already available online for the training of deep learning algorithms for the acoustic classification of orthopterans and cicadas in North, Central, and temperate Western Europe.', 'abstract_zh': '目前可用的用于自动声学识别欧洲昆虫的工具范围有限。这些算法需要大量的生态异质性声学数据集，以跨情境识别每种物种产生的微妙而复杂的声学特征，因此，此类数据集的可用性是其开发的关键要求。在这里，我们呈现了ECOSoundSet（欧洲螽斯和直翅目声音数据集），该数据集包含200种直翅目和24种蝉类（包括217个和26个亚种类别）的10,653个录音，它们分布在北欧、中欧和温带西欧（安道尔、比利时、丹麦、法国本土及科西嘉、德国、爱尔兰、卢森堡、摩纳哥、荷兰、英国、瑞士），部分录音通过南法和加泰罗尼亚的定向野外工作收集，部分录音来自欧洲各地的昆虫学家的贡献。该数据集由粗略标注的录音组成，我们只能推断在某个时间点捕获到了目标物种（弱标注），以及由具体时间范围和频率范围的注释录音组成（强标注）。我们还提供了强标注录音的训练/验证/测试集划分，比例分别为约0.8、0.1和0.1，以方便其纳入深度学习算法的训练和评估中。此数据集可以作为北欧、中欧和温带西欧地区已在线可用的用于直翅目和蝉类声学分类深度学习算法训练的有意义补充数据集。', 'title_zh': 'ECOSoundSet: 北部、中部和温带西部欧洲昆虫iclass="source_text" />Orthoptera和Cicadidae的细粒度标注声学自动识别数据集'}
{'arxiv_id': 'arXiv:2504.20770', 'title': 'JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation', 'authors': 'Ji Shi, Chengxun Xie, Zhonghao Li, Xinming Zhang, Miao Zhang', 'link': 'https://arxiv.org/abs/2504.20770', 'abstract': 'The discovery of new molecules based on the original chemical molecule distributions is of great importance in medicine. The graph transformer, with its advantages of high performance and scalability compared to traditional graph networks, has been widely explored in recent research for applications of graph structures. However, current transformer-based graph decoders struggle to effectively utilize graph information, which limits their capacity to leverage only sequences of nodes rather than the complex topological structures of molecule graphs. This paper focuses on building a graph transformer-based framework for molecular generation, which we call \\textbf{JTreeformer} as it transforms graph generation into junction tree generation. It combines GCN parallel with multi-head attention as the encoder. It integrates a directed acyclic GCN into a graph-based Transformer to serve as a decoder, which can iteratively synthesize the entire molecule by leveraging information from the partially constructed molecular structure at each step. In addition, a diffusion model is inserted in the latent space generated by the encoder, to enhance the efficiency and effectiveness of sampling further. The empirical results demonstrate that our novel framework outperforms existing molecule generation methods, thus offering a promising tool to advance drug discovery (this https URL).', 'abstract_zh': '基于原始化学分子分布发现新分子在医学中具有重要意义。与传统图网络相比，图变压器具有高性能和可扩展性的优势，在近期的研究中广泛应用于图结构的应用中。然而，当前基于变压器的图解码器难以有效地利用图信息，这限制了它们仅通过节点序列而不是分子图的复杂拓扑结构来利用信息的能力。本文重点构建了一种基于图变压器的分子生成框架，我们称之为\\textbf{JTreeformer}，因为它将图生成转化为枢纽树生成。该框架将GCN与多头注意力机制并行用于编码器。它将有向无环GCN整合到基于图的变压器中作为解码器，可以在每个步骤中通过利用部分构建的分子结构的信息，逐步合成整个分子。此外，在编码器生成的潜在空间中插入了一个扩散模型，以增强采样的效率和有效性。实证结果表明，我们提出的新型框架优于现有的分子生成方法，从而提供了一种促进药物发现的强大工具。', 'title_zh': 'JTreeformer：基于潜在扩散模型的图变压器分子生成'}
{'arxiv_id': 'arXiv:2504.20769', 'title': 'Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption', 'authors': 'Wenxiao Wang, Parsa Hosseini, Soheil Feizi', 'link': 'https://arxiv.org/abs/2504.20769', 'abstract': 'Chain-of-thought prompting has demonstrated great success in facilitating the reasoning abilities of large language models. In this work, we explore how these enhanced reasoning abilities can be exploited to improve the robustness of large language models in tasks that are not necessarily reasoning-focused. In particular, we show how a wide range of large language models exhibit significantly improved robustness against reference corruption using a simple method called chain-of-defensive-thought, where only a few exemplars with structured and defensive reasoning are provided as demonstrations. Empirically, the improvements can be astounding, especially given the simplicity and applicability of the method. For example, in the Natural Questions task, the accuracy of GPT-4o degrades from 60% to as low as 3% with standard prompting when 1 out of 10 references provided is corrupted with prompt injection attacks. In contrast, GPT-4o using chain-of-defensive-thought prompting maintains an accuracy of 50%.', 'abstract_zh': 'Chain-of-defensive-thought prompting 通过提升大型语言模型的鲁棒性以改进非推理密集任务的表现', 'title_zh': '防御性思维链：结构化推理在大型语言模型中对抗参考污染增强鲁棒性'}
{'arxiv_id': 'arXiv:2504.20752', 'title': 'Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers', 'authors': 'Roman Abramov, Felix Steinbauer, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2504.20752', 'abstract': 'Transformers have achieved great success in numerous NLP tasks but continue to exhibit notable gaps in multi-step factual reasoning, especially when real-world knowledge is sparse. Recent advances in grokking have demonstrated that neural networks can transition from memorizing to perfectly generalizing once they detect underlying logical patterns - yet these studies have primarily used small, synthetic tasks. In this paper, for the first time, we extend grokking to real-world factual data and address the challenge of dataset sparsity by augmenting existing knowledge graphs with carefully designed synthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts above the threshold required for grokking. Surprisingly, we find that even factually incorrect synthetic data can strengthen emergent reasoning circuits rather than degrade accuracy, as it forces the model to rely on relational structure rather than memorization. When evaluated on multi-hop reasoning benchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA - substantially improving over strong baselines and matching or exceeding current state-of-the-art results. We further provide an in-depth analysis of how increasing $\\phi_r$ drives the formation of generalizing circuits inside Transformers. Our findings suggest that grokking-based data augmentation can unlock implicit multi-hop reasoning capabilities, opening the door to more robust and interpretable factual reasoning in large-scale language models.', 'abstract_zh': 'Transformer模型在众多NLP任务中取得了巨大成功，但在多步事实推理方面仍然存在明显差距，尤其是在现实世界知识稀少的情况下。最近关于“理解”（grokking）的研究表明，神经网络一旦检测到潜在的逻辑模式，就能从记忆过渡到完美泛化——然而，这些研究主要使用的是小型合成任务。在本文中，我们首次将“理解”扩展到真实世界事实数据，并通过结合精心设计的合成数据来增强现有的知识图谱，以提高推断事实与原子事实的比例$\\phi_r$，使其超过“理解”所需的阈值。令人惊讶的是，即使是有事实错误的合成数据也可以加强涌现的推理电路，而不是降低准确率，因为这迫使模型依赖于关系结构而不是记忆。在多跳推理基准上的评估显示，我们的方法在2WikiMultiHopQA上的准确率可以达到95%-100%，显著优于强基线，并且与当前的最优结果相当或超越。我们进一步深入分析了提高$\\phi_r$如何驱动Transformer内部形成泛化电路。我们的研究结果表明，“理解”基础上的数据增强可以解锁隐含的多跳推理能力，为大规模语言模型提供了更 robust 和可解释的事实推理潜力。', 'title_zh': '野仿中的融会贯通：数据扩增在实际多跳推理中的应用'}
{'arxiv_id': 'arXiv:2504.20741', 'title': 'In defence of post-hoc explanations in medical AI', 'authors': 'Joshua Hatherley, Lauritz Munch, Jens Christian Bjerring', 'link': 'https://arxiv.org/abs/2504.20741', 'abstract': 'Since the early days of the Explainable AI movement, post-hoc explanations have been praised for their potential to improve user understanding, promote trust, and reduce patient safety risks in black box medical AI systems. Recently, however, critics have argued that the benefits of post-hoc explanations are greatly exaggerated since they merely approximate, rather than replicate, the actual reasoning processes that black box systems take to arrive at their outputs. In this article, we aim to defend the value of post-hoc explanations against this recent critique. We argue that even if post-hoc explanations do not replicate the exact reasoning processes of black box systems, they can still improve users\' functional understanding of black box systems, increase the accuracy of clinician-AI teams, and assist clinicians in justifying their AI-informed decisions. While post-hoc explanations are not a "silver bullet" solution to the black box problem in medical AI, we conclude that they remain a useful strategy for addressing the black box problem in medical AI.', 'abstract_zh': '自可解释AI运动早期以来，事后的解释因其有潜力改善用户理解、促进信任并降低黑盒医疗AI系统中的患者安全风险而受到 praise。然而，最近的批评者认为，事后解释的好处被极大地夸大了，因为它们只是近似而非复制黑盒系统实际采用的推理过程。在本文中，我们旨在反驳这一最近的批评。我们认为，即使事后解释不能完全复制黑盒系统的推理过程，它们仍然可以提高用户对黑盒系统的功能性理解，增加临床医生-AI团队的准确性，并帮助临床医生为其基于AI的决策提供正当理由。尽管事后解释并非解决医疗AI黑盒问题的“万能药”，但我们可以得出结论，它们仍然是处理医疗AI黑盒问题的一种有用策略。', 'title_zh': '论医学AI的事后解释辩护'}
{'arxiv_id': 'arXiv:2504.20734', 'title': 'UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities', 'authors': 'Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang', 'link': 'https://arxiv.org/abs/2504.20734', 'abstract': 'Retrieval-Augmented Generation (RAG) has shown substantial promise in improving factual accuracy by grounding model responses with external knowledge relevant to queries. However, most existing RAG approaches are limited to a text-only corpus, and while recent efforts have extended RAG to other modalities such as images and videos, they typically operate over a single modality-specific corpus. In contrast, real-world queries vary widely in the type of knowledge they require, which a single type of knowledge source cannot address. To address this, we introduce UniversalRAG, a novel RAG framework designed to retrieve and integrate knowledge from heterogeneous sources with diverse modalities and granularities. Specifically, motivated by the observation that forcing all modalities into a unified representation space derived from a single combined corpus causes a modality gap, where the retrieval tends to favor items from the same modality as the query, we propose a modality-aware routing mechanism that dynamically identifies the most appropriate modality-specific corpus and performs targeted retrieval within it. Also, beyond modality, we organize each modality into multiple granularity levels, enabling fine-tuned retrieval tailored to the complexity and scope of the query. We validate UniversalRAG on 8 benchmarks spanning multiple modalities, showing its superiority over modality-specific and unified baselines.', 'abstract_zh': '通用RAG：跨模态异质知识检索与整合', 'title_zh': 'UniversalRAG：跨多语料库的多元模态和粒度检索增强生成'}
{'arxiv_id': 'arXiv:2504.20733', 'title': 'Unsupervised Surrogate Anomaly Detection', 'authors': 'Simon Klüttermann, Tim Katzke, Emmanuel Müller', 'link': 'https://arxiv.org/abs/2504.20733', 'abstract': 'In this paper, we study unsupervised anomaly detection algorithms that learn a neural network representation, i.e. regular patterns of normal data, which anomalies are deviating from. Inspired by a similar concept in engineering, we refer to our methodology as surrogate anomaly detection. We formalize the concept of surrogate anomaly detection into a set of axioms required for optimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble ANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121 benchmark datasets, demonstrating its competitive performance against 19 existing methods, as well as the scalability and reliability of our method.', 'abstract_zh': '在本文中，我们研究了一种无监督异常检测算法，该算法学习神经网络表示，即正常数据的常规模式，异常则是偏离这些模式。受工程中类似概念的启发，我们将这种方法称为代理异常检测。我们将代理异常检测的概念形式化为构建最优代理模型所需的一组公理，并提出了一种新算法，名为DEAN（Deep Ensemble ANomaly检测），旨在满足这些要求。我们在121个基准数据集上评估了DEAN，展示了其在与19种现有方法竞争中的性能，以及我们方法的可扩展性和可靠性。', 'title_zh': '无监督代理异常检测'}
{'arxiv_id': 'arXiv:2504.20726', 'title': 'Enhancing Vulnerability Reports with Automated and Augmented Description Summarization', 'authors': 'Hattan Althebeiti, Mohammed Alkinoon, Manar Mohaisen, Saeed Salem, DaeHun Nyang, David Mohaisen', 'link': 'https://arxiv.org/abs/2504.20726', 'abstract': 'Public vulnerability databases, such as the National Vulnerability Database (NVD), document vulnerabilities and facilitate threat information sharing. However, they often suffer from short descriptions and outdated or insufficient information. In this paper, we introduce Zad, a system designed to enrich NVD vulnerability descriptions by leveraging external resources. Zad consists of two pipelines: one collects and filters supplementary data using two encoders to build a detailed dataset, while the other fine-tunes a pre-trained model on this dataset to generate enriched descriptions. By addressing brevity and improving content quality, Zad produces more comprehensive and cohesive vulnerability descriptions. We evaluate Zad using standard summarization metrics and human assessments, demonstrating its effectiveness in enhancing vulnerability information.', 'abstract_zh': '基于外部资源丰富国家安全漏洞数据库描述的Zad系统', 'title_zh': '增强漏洞报告的自动化和增强描述总结'}
{'arxiv_id': 'arXiv:2504.20708', 'title': 'Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think', 'authors': 'Hasan Abed Al Kader Hammoud, Hani Itani, Bernard Ghanem', 'link': 'https://arxiv.org/abs/2504.20708', 'abstract': "Large Language Models (LLMs) leverage step-by-step reasoning to solve complex problems. Standard evaluation practice involves generating a complete reasoning trace and assessing the correctness of the final answer presented at its conclusion. In this paper, we challenge the reliance on the final answer by posing the following two questions: Does the final answer reliably represent the model's optimal conclusion? Can alternative reasoning paths yield different results? To answer these questions, we analyze intermediate reasoning steps, termed subthoughts, and propose a method based on our findings. Our approach involves segmenting a reasoning trace into sequential subthoughts based on linguistic cues. We start by prompting the model to generate continuations from the end-point of each intermediate subthought. We extract a potential answer from every completed continuation originating from different subthoughts. We find that aggregating these answers by selecting the most frequent one (the mode) often yields significantly higher accuracy compared to relying solely on the answer derived from the original complete trace. Analyzing the consistency among the answers derived from different subthoughts reveals characteristics that correlate with the model's confidence and correctness, suggesting potential for identifying less reliable answers. Our experiments across various LLMs and challenging mathematical reasoning datasets (AIME2024 and AIME2025) show consistent accuracy improvements, with gains reaching up to 13\\% and 10\\% respectively. Implementation is available at: this https URL.", 'abstract_zh': '大型语言模型通过逐步推理解决复杂问题。标准评估实践涉及生成完整的推理过程并评估最终答案的正确性。本文通过提出以下两个问题挑战对最终答案的依赖：最终答案是否可靠地代表了模型的最优结论？是否存在不同的推理路径可以产生不同的结果？为回答这些问题，我们分析了中间推理步骤（称为子思想），并基于我们的发现提出了一种方法。我们的方法涉及根据语言线索将推理过程划分为顺序的子思想片段。我们首先提示模型从每个中间子思想的终点生成续写。我们从每个完成的续写中提取潜在答案。我们发现，通过选择最常见的答案（众数）来聚合这些答案，通常比仅依赖原始完整过程生成的答案具有更高的准确率。分析来自不同子思想的解答一致性揭示了与模型的信心和正确性相关的特征，表明可以用于识别不可靠的答案。我们在多种大型语言模型和具有挑战性的数学推理数据集（AIME2024和AIME2025）上的实验显示了一致的准确率提高，分别达到13%和10%。详细的实现可在以下链接获取：this https URL。', 'title_zh': '超越最后一个答案：你的推理轨迹揭示的不止你所想'}
{'arxiv_id': 'arXiv:2504.20699', 'title': 'Can LLMs Detect Intrinsic Hallucinations in Paraphrasing and Machine Translation?', 'authors': 'Evangelia Gogoulou, Shorouq Zahra, Liane Guillou, Luise Dürlich, Joakim Nivre', 'link': 'https://arxiv.org/abs/2504.20699', 'abstract': 'A frequently observed problem with LLMs is their tendency to generate output that is nonsensical, illogical, or factually incorrect, often referred to broadly as hallucination. Building on the recently proposed HalluciGen task for hallucination detection and generation, we evaluate a suite of open-access LLMs on their ability to detect intrinsic hallucinations in two conditional generation tasks: translation and paraphrasing. We study how model performance varies across tasks and language and we investigate the impact of model size, instruction tuning, and prompt choice. We find that performance varies across models but is consistent across prompts. Finally, we find that NLI models perform comparably well, suggesting that LLM-based detectors are not the only viable option for this specific task.', 'abstract_zh': 'LLMs生成虚假信息的常见问题及其检测研究：基于HalluciGen任务在翻译和 paraphrasing任务中的表现分析', 'title_zh': 'LLMs能否检测重写和机器翻译中的内在幻觉？'}
{'arxiv_id': 'arXiv:2504.20673', 'title': 'CoCo-Bench: A Comprehensive Code Benchmark For Multi-task Large Language Model Evaluation', 'authors': 'Wenjing Yin, Tianze Sun, Yijiong Yu, Jiawei Fang, Guangyao Su, Jiancheng Wang, Zekun Wang, Wei Wang, Ran Chen, Ziyun Dai, Shuai Yuan, Menghang Dong, Peng Luo, Dong Cao, Da Lei, Yajun Zhang, Hao Chen, Xiang Ma, Yong Liu, Weifeng Liu, Yuanjian Xu, Ji Pei', 'link': 'https://arxiv.org/abs/2504.20673', 'abstract': 'Large language models (LLMs) play a crucial role in software engineering, excelling in tasks like code generation and maintenance. However, existing benchmarks are often narrow in scope, focusing on a specific task and lack a comprehensive evaluation framework that reflects real-world applications. To address these gaps, we introduce CoCo-Bench (Comprehensive Code Benchmark), designed to evaluate LLMs across four critical dimensions: code understanding, code generation, code modification, and code review. These dimensions capture essential developer needs, ensuring a more systematic and representative evaluation. CoCo-Bench includes multiple programming languages and varying task difficulties, with rigorous manual review to ensure data quality and accuracy. Empirical results show that CoCo-Bench aligns with existing benchmarks while uncovering significant variations in model performance, effectively highlighting strengths and weaknesses. By offering a holistic and objective evaluation, CoCo-Bench provides valuable insights to guide future research and technological advancements in code-oriented LLMs, establishing a reliable benchmark for the field.', 'abstract_zh': '大型语言模型（LLMs）在软件工程中发挥着关键作用，尤其在代码生成和维护任务中表现出色。然而，现有的基准测试往往范围狭窄，仅集中在特定任务上，缺乏反映实际应用的全面评估框架。为弥补这些不足，我们引入了CoCo-Bench（综合代码基准），旨在从代码理解和认知、代码生成、代码修改和代码审查四个关键维度评估LLMs。这些维度涵盖了开发人员的基本需求，确保评估更为系统和具有代表性。CoCo-Bench涵盖了多种编程语言和不同难度的任务，并通过严格的手工审查确保数据的质量和准确性。实证结果表明，CoCo-Bench与现有的基准测试相一致，但揭示了模型性能中的显著差异，有效突显了模型的优势和弱点。通过提供一个全面且客观的评估，CoCo-Bench为代码导向的LLMs的研究和技术创新提供了宝贵的洞察，并为该领域建立了可靠基准。', 'title_zh': 'CoCo-Bench: 一种全面的多任务大型语言模型评估代码基准'}
{'arxiv_id': 'arXiv:2504.20669', 'title': 'Advance Fake Video Detection via Vision Transformers', 'authors': "Joy Battocchio, Stefano Dell'Anna, Andrea Montibeller, Giulia Boato", 'link': 'https://arxiv.org/abs/2504.20669', 'abstract': 'Recent advancements in AI-based multimedia generation have enabled the creation of hyper-realistic images and videos, raising concerns about their potential use in spreading misinformation. The widespread accessibility of generative techniques, which allow for the production of fake multimedia from prompts or existing media, along with their continuous refinement, underscores the urgent need for highly accurate and generalizable AI-generated media detection methods, underlined also by new regulations like the European Digital AI Act. In this paper, we draw inspiration from Vision Transformer (ViT)-based fake image detection and extend this idea to video. We propose an {original} %innovative framework that effectively integrates ViT embeddings over time to enhance detection performance. Our method shows promising accuracy, generalization, and few-shot learning capabilities across a new, large and diverse dataset of videos generated using five open source generative techniques from the state-of-the-art, as well as a separate dataset containing videos produced by proprietary generative methods.', 'abstract_zh': '基于AI的多媒体生成Recent进展引发了对其潜在滥用的担忧，尤其是在传播虚假信息方面的应用。生成技术的广泛应用及其不断改进促使我们需要开发高准确性和普适性的AI生成媒体检测方法，这一需求也被新的法规如欧洲数字AI法案所强调。在本文中，我们受Vision Transformer (ViT) 基础的虚假图像检测启发，将其理念拓展至视频领域。我们提出了一种创新框架，有效结合了时间上的ViT嵌入，以提高检测性能。该方法在使用五种开源生成技术生成的大型多样数据集以及包含由专有生成方法制作的视频的数据集中都表现出良好的准确率、泛化能力和少量样本学习能力。', 'title_zh': '基于视觉变换器的先进虚假视频检测'}
{'arxiv_id': 'arXiv:2504.20658', 'title': 'TrueFake: A Real World Case Dataset of Last Generation Fake Images also Shared on Social Networks', 'authors': "Stefano Dell'Anna, Andrea Montibeller, Giulia Boato", 'link': 'https://arxiv.org/abs/2504.20658', 'abstract': 'AI-generated synthetic media are increasingly used in real-world scenarios, often with the purpose of spreading misinformation and propaganda through social media platforms, where compression and other processing can degrade fake detection cues. Currently, many forensic tools fail to account for these in-the-wild challenges. In this work, we introduce TrueFake, a large-scale benchmarking dataset of 600,000 images including top notch generative techniques and sharing via three different social networks. This dataset allows for rigorous evaluation of state-of-the-art fake image detectors under very realistic and challenging conditions. Through extensive experimentation, we analyze how social media sharing impacts detection performance, and identify current most effective detection and training strategies. Our findings highlight the need for evaluating forensic models in conditions that mirror real-world use.', 'abstract_zh': 'AI生成的合成媒体在现实场景中越来越频繁地被用于通过社交 media 平台传播 misinformation 和 propaganda，压缩和其他处理会削弱假信息检测线索。当前，许多鉴真工具未能应对这些现实生活中的挑战。在此项工作中，我们引入了 TrueFake，这是一个包含600,000张图像的大规模基准数据集，这些图像采用了顶级生成技术并通过三个不同的社交网络分享。该数据集在非常现实和具有挑战性的条件下，允许对最先进的假图像检测器进行严格的评估。通过广泛的实验，我们分析了社交 media 分享对检测性能的影响，并识别了当前最有效的检测和训练策略。我们的发现强调了在模拟现实世界使用条件下来评估鉴真模型的必要性。', 'title_zh': 'TrueFake：last generation fake images also shared on social networks的现实世界案例数据集'}
{'arxiv_id': 'arXiv:2504.20656', 'title': 'Federated learning, ethics, and the double black box problem in medical AI', 'authors': 'Joshua Hatherley, Anders Søgaard, Angela Ballantyne, Ruben Pauwels', 'link': 'https://arxiv.org/abs/2504.20656', 'abstract': 'Federated learning (FL) is a machine learning approach that allows multiple devices or institutions to collaboratively train a model without sharing their local data with a third-party. FL is considered a promising way to address patient privacy concerns in medical artificial intelligence. The ethical risks of medical FL systems themselves, however, have thus far been underexamined. This paper aims to address this gap. We argue that medical FL presents a new variety of opacity -- federation opacity -- that, in turn, generates a distinctive double black box problem in healthcare AI. We highlight several instances in which the anticipated benefits of medical FL may be exaggerated, and conclude by highlighting key challenges that must be overcome to make FL ethically feasible in medicine.', 'abstract_zh': '联邦学习：医学中的新 opacity 问题与伦理挑战', 'title_zh': '联邦学习、伦理与医疗AI中的双重黑箱问题'}
{'arxiv_id': 'arXiv:2504.20648', 'title': 'SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data', 'authors': 'Michael Ogezi, Freda Shi', 'link': 'https://arxiv.org/abs/2504.20648', 'abstract': "Vision-language models (VLMs) work well in tasks ranging from image captioning to visual question answering (VQA), yet they struggle with spatial reasoning, a key skill for understanding our physical world that humans excel at. We find that spatial relations are generally rare in widely used VL datasets, with only a few being well represented, while most form a long tail of underrepresented relations. This gap leaves VLMs ill-equipped to handle diverse spatial relationships. To bridge it, we construct a synthetic VQA dataset focused on spatial reasoning generated from hyper-detailed image descriptions in Localized Narratives, DOCCI, and PixMo-Cap. Our dataset consists of 455k samples containing 3.4 million QA pairs. Trained on this dataset, our Spatial-Reasoning Enhanced (SpaRE) VLMs show strong improvements on spatial reasoning benchmarks, achieving up to a 49% performance gain on the What's Up benchmark, while maintaining strong results on general tasks. Our work narrows the gap between human and VLM spatial reasoning and makes VLMs more capable in real-world tasks such as robotics and navigation.", 'abstract_zh': "视觉语言模型在从图像描述到视觉问答任务中表现出色，但在空间推理方面存在不足，这是人类擅长的关键技能。我们发现，广泛使用的VL数据集中空间关系普遍较稀少，只有少数关系被充分代表，大多数则形成了长尾分布的稀少关系。这一差距使得视觉语言模型在处理多样化的空间关系方面能力不足。为了弥合这一差距，我们构建了一个基于《局部叙述》、DOCCI和PixMo-Cap中的超详细图像描述生成的合成视觉问答数据集，专注于空间推理。该数据集包含455,000个样本，共计340万问答对。在该数据集上训练的增强空间推理的视觉语言模型在空间推理基准测试中表现出显著改进，在What's Up基准测试中取得了高达49%的性能提升，同时在一般任务上保持了强大的结果。我们的工作缩小了人类与视觉语言模型在空间推理方面的差距，并使视觉语言模型在诸如机器人技术和导航等实际任务中更加具备能力。", 'title_zh': 'SpaRE: 通过合成数据增强视觉语言模型的空间推理能力'}
{'arxiv_id': 'arXiv:2504.20643', 'title': 'Cooking Up Creativity: A Cognitively-Inspired Approach for Enhancing LLM Creativity through Structured Representations', 'authors': 'Moran Mizrahi, Chen Shani, Gabriel Stanovsky, Dan Jurafsky, Dafna Shahaf', 'link': 'https://arxiv.org/abs/2504.20643', 'abstract': "Large Language Models (LLMs) excel at countless tasks, yet struggle with creativity. In this paper, we introduce a novel approach that couples LLMs with structured representations and cognitively inspired manipulations to generate more creative and diverse ideas. Our notion of creativity goes beyond superficial token-level variations; rather, we explicitly recombine structured representations of existing ideas, allowing our algorithm to effectively explore the more abstract landscape of ideas. We demonstrate our approach in the culinary domain with DishCOVER, a model that generates creative recipes. Experiments comparing our model's results to those of GPT-4o show greater diversity. Domain expert evaluations reveal that our outputs, which are mostly coherent and feasible culinary creations, significantly surpass GPT-4o in terms of novelty, thus outperforming it in creative generation. We hope our work inspires further research into structured creativity in AI.", 'abstract_zh': '大型语言模型在创造力方面表现出色，但存在局限性。本论文介绍了一种新型方法，将大型语言模型与结构化表示和认知启发式的操作相结合，以生成更具创造力和多样性的想法。我们对创造力的理解不仅仅局限于表层的令牌级变化，而是明确地重组现有想法的结构化表示，从而使我们的算法能够有效地探索更具抽象性的想法空间。我们在烹饪领域通过DishCOVER模型展示了该方法，该模型能够生成创意菜谱。实验结果表明，与GPT-4o相比，我们的模型结果更具多样性。领域专家评估表明，与GPT-4o相比，我们生成的大部分连贯且可行的烹饪创作具有更高的新颖性，因此在创造性生成方面优于GPT-4o。我们希望我们的工作能够激发对AI中结构化创造力的进一步研究。', 'title_zh': '激发创造力：一种基于认知的结构表示方法以增强大语言模型的创造力'}
{'arxiv_id': 'arXiv:2504.20634', 'title': 'On Stochastic Rounding with Few Random Bits', 'authors': 'Andrew Fitzgibbon, Stephen Felix', 'link': 'https://arxiv.org/abs/2504.20634', 'abstract': "Large-scale numerical computations make increasing use of low-precision (LP) floating point formats and mixed precision arithmetic, which can be enhanced by the technique of stochastic rounding (SR), that is, rounding an intermediate high-precision value up or down randomly as a function of the value's distance to the two rounding candidates. Stochastic rounding requires, in addition to the high-precision input value, a source of random bits. As the provision of high-quality random bits is an additional computational cost, it is of interest to require as few bits as possible while maintaining the desirable properties of SR in a given computation, or computational domain. This paper examines a number of possible implementations of few-bit stochastic rounding (FBSR), and shows how several natural implementations can introduce sometimes significant bias into the rounding process, which are not present in the case of infinite-bit, infinite-precision examinations of these implementations. The paper explores the impact of these biases in machine learning examples, and hence opens another class of configuration parameters of which practitioners should be aware when developing or adopting low-precision floating point. Code is available at this http URL.", 'abstract_zh': '小型位数随机舍入方法的研究及其在机器学习中的影响分析', 'title_zh': '带少量随机位的随机舍入'}
{'arxiv_id': 'arXiv:2504.20629', 'title': 'AlignDiT: Multimodal Aligned Diffusion Transformer for Synchronized Speech Generation', 'authors': 'Jeongsoo Choi, Ji-Hoon Kim, Kim Sung-Bin, Tae-Hyun Oh, Joon Son Chung', 'link': 'https://arxiv.org/abs/2504.20629', 'abstract': 'In this paper, we address the task of multimodal-to-speech generation, which aims to synthesize high-quality speech from multiple input modalities: text, video, and reference audio. This task has gained increasing attention due to its wide range of applications, such as film production, dubbing, and virtual avatars. Despite recent progress, existing methods still suffer from limitations in speech intelligibility, audio-video synchronization, speech naturalness, and voice similarity to the reference speaker. To address these challenges, we propose AlignDiT, a multimodal Aligned Diffusion Transformer that generates accurate, synchronized, and natural-sounding speech from aligned multimodal inputs. Built upon the in-context learning capability of the DiT architecture, AlignDiT explores three effective strategies to align multimodal representations. Furthermore, we introduce a novel multimodal classifier-free guidance mechanism that allows the model to adaptively balance information from each modality during speech synthesis. Extensive experiments demonstrate that AlignDiT significantly outperforms existing methods across multiple benchmarks in terms of quality, synchronization, and speaker similarity. Moreover, AlignDiT exhibits strong generalization capability across various multimodal tasks, such as video-to-speech synthesis and visual forced alignment, consistently achieving state-of-the-art performance. The demo page is available at this https URL .', 'abstract_zh': '本文探讨了多模态到语音生成的任务，旨在从多种输入模态：文本、视频和参考语音中合成高质量的语音。由于其在电影制作、配音和虚拟化身等广泛应用中的潜力，该任务引起了越来越多的关注。尽管取得了近期进展，现有方法在语音清晰度、音频-视频同步、语音自然度以及语音与参考说话者音色相似度方面仍存在局限。为应对这些挑战，我们提出了AlignDiT，一种能够从对齐的多模态输入中生成准确、同步且自然的语音的多模态对齐扩散变换器。基于DiT架构的上下文学习能力，AlignDiT探索了三种有效的策略来对齐多模态表示。此外，我们引入了一种新颖的多模态去分类器自由引导机制，使模型在语音合成过程中能够自适应地平衡每种模态的信息。大量实验证明，AlignDiT在质量、同步性和说话者相似度方面显著优于现有方法，在多个基准测试中均取得了优异表现。AlignDiT在视频到语音合成和视觉强制对齐等多种多模态任务中均表现出强大的泛化能力，并且持续保持最佳性能。更多详情请参见此网页：![](this%20https%20URL)。', 'title_zh': 'AlignDiT: 多模态对齐扩散变换器用于同步语音生成'}
{'arxiv_id': 'arXiv:2504.20625', 'title': 'DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models', 'authors': 'Sagi Della Torre, Mirco Pezzoli, Fabio Antonacci, Sharon Gannot', 'link': 'https://arxiv.org/abs/2504.20625', 'abstract': "Room Impulse Responses (RIRs) characterize acoustic environments and are crucial in multiple audio signal processing tasks. High-quality RIR estimates drive applications such as virtual microphones, sound source localization, augmented reality, and data augmentation. However, obtaining RIR measurements with high spatial resolution is resource-intensive, making it impractical for large spaces or when dense sampling is required. This research addresses the challenge of estimating RIRs at unmeasured locations within a room using Denoising Diffusion Probabilistic Models (DDPM). Our method leverages the analogy between RIR matrices and image inpainting, transforming RIR data into a format suitable for diffusion-based reconstruction.\nUsing simulated RIR data based on the image method, we demonstrate our approach's effectiveness on microphone arrays of different curvatures, from linear to semi-circular. Our method successfully reconstructs missing RIRs, even in large gaps between microphones. Under these conditions, it achieves accurate reconstruction, significantly outperforming baseline Spline Cubic Interpolation in terms of Normalized Mean Square Error and Cosine Distance between actual and interpolated RIRs.\nThis research highlights the potential of using generative models for effective RIR interpolation, paving the way for generating additional data from limited real-world measurements.", 'abstract_zh': '基于去噪扩散概率模型的房间冲激响应插值研究', 'title_zh': 'DiffusionRIR：基于扩散模型的房间冲激响应插值'}
{'arxiv_id': 'arXiv:2504.20612', 'title': 'The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models', 'authors': 'Swaroop Dora, Deven Lunkad, Naziya Aslam, S. Venkatesan, Sandeep Kumar Shukla', 'link': 'https://arxiv.org/abs/2504.20612', 'abstract': 'The rapid advancement of Large Language Models (LLMs) has enhanced software development processes, minimizing the time and effort required for coding and enhancing developer productivity. However, despite their potential benefits, code generated by LLMs has been shown to generate insecure code in controlled environments, raising critical concerns about their reliability and security in real-world applications. This paper uses predefined security parameters to evaluate the security compliance of LLM-generated code across multiple models, such as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals critical vulnerabilities in authentication mechanisms, session management, input validation and HTTP security headers. Although some models implement security measures to a limited extent, none fully align with industry best practices, highlighting the associated risks in automated software development. Our findings underscore that human expertise is crucial to ensure secure software deployment or review of LLM-generated code. Also, there is a need for robust security assessment frameworks to enhance the reliability of LLM-generated code in real-world applications.', 'abstract_zh': '大语言模型的快速进步提高了软件开发过程的效率，减少了编码所需的时间和努力，提升了开发人员的 productivity。然而，尽管它们具有潜在的好处，但在受控环境中生成的代码显示出安全性问题，这引发了关于它们在实际应用中的可靠性和安全性的重要关切。本文使用预定义的安全参数来评估大语言模型生成的代码在多个模型（如ChatGPT、DeepSeek、Claude、Gemini和Grok）中的安全合规性。分析揭示了身份验证机制、会话管理、输入验证和HTTP安全标头中的关键漏洞。尽管一些模型在一定程度上实施了安全措施，但 none 完全符合行业最佳实践，突显了自动化软件开发相关的风险。我们的研究强调，人类专业知识对于确保安全地部署或审查大语言模型生成的代码至关重要。此外，需要建立 robust 安全评估框架来提高大语言模型生成的代码在实际应用中的可靠性。', 'title_zh': '大型语言模型生成代码的安全风险探究：基于安全性的代码生成能力评估'}
{'arxiv_id': 'arXiv:2504.20610', 'title': 'Information Retrieval in the Age of Generative AI: The RGB Model', 'authors': 'Michele Garetto, Alessandro Cornacchia, Franco Galante, Emilio Leonardi, Alessandro Nordio, Alberto Tarable', 'link': 'https://arxiv.org/abs/2504.20610', 'abstract': 'The advent of Large Language Models (LLMs) and generative AI is fundamentally transforming information retrieval and processing on the Internet, bringing both great potential and significant concerns regarding content authenticity and reliability. This paper presents a novel quantitative approach to shed light on the complex information dynamics arising from the growing use of generative AI tools. Despite their significant impact on the digital ecosystem, these dynamics remain largely uncharted and poorly understood. We propose a stochastic model to characterize the generation, indexing, and dissemination of information in response to new topics. This scenario particularly challenges current LLMs, which often rely on real-time Retrieval-Augmented Generation (RAG) techniques to overcome their static knowledge limitations. Our findings suggest that the rapid pace of generative AI adoption, combined with increasing user reliance, can outpace human verification, escalating the risk of inaccurate information proliferation across digital resources. An in-depth analysis of Stack Exchange data confirms that high-quality answers inevitably require substantial time and human effort to emerge. This underscores the considerable risks associated with generating persuasive text in response to new questions and highlights the critical need for responsible development and deployment of future generative AI tools.', 'abstract_zh': '大型语言模型和生成式AI的兴起正在根本性地改变互联网上的信息检索和处理，带来了内容真实性与可靠性的重要潜在和关切。本文提出了一种新颖的数量化方法，以揭示生成式AI工具广泛应用带来的复杂信息动态。尽管这些工具对数字生态系统产生了重大影响，但这些动态仍大多未被探索和理解。我们提出了一种随机模型来表征对新主题的生成、索引和传播。这一情境尤其挑战当前的大型语言模型，它们通常依赖于实时检索增强生成（RAG）技术来克服其静态知识的局限。我们的研究结果表明，生成式AI的快速采纳速度与用户依赖性的增加可能导致人工验证滞后，从而加剧数字资源中不准确信息传播的风险。对Stack Exchange数据的深入分析证实，高质量的回答不可避免地需要大量时间和人力才能产生。这突显了生成针对新问题具有说服力的文本所面临的重要风险，并强调了负责任地开发和部署未来生成式AI工具的迫切需要。', 'title_zh': '生成式AI时代的信息系统检索：RGB模型'}
{'arxiv_id': 'arXiv:2504.20571', 'title': 'Reinforcement Learning for Reasoning in Large Language Models with One Training Example', 'authors': 'Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen', 'link': 'https://arxiv.org/abs/2504.20571', 'abstract': 'We show that reinforcement learning with verifiable reward using one training example (1-shot RLVR) is effective in incentivizing the math reasoning capabilities of large language models (LLMs). Applying RLVR to the base model Qwen2.5-Math-1.5B, we identify a single example that elevates model performance on MATH500 from 36.0% to 73.6%, and improves the average performance across six common mathematical reasoning benchmarks from 17.6% to 35.7%. This result matches the performance obtained using the 1.2k DeepScaleR subset (MATH500: 73.6%, average: 35.9%), which includes the aforementioned example. Similar substantial improvements are observed across various models (Qwen2.5-Math-7B, Llama3.2-3B-Instruct, DeepSeek-R1-Distill-Qwen-1.5B), RL algorithms (GRPO and PPO), and different math examples (many of which yield approximately 30% or greater improvement on MATH500 when employed as a single training example). In addition, we identify some interesting phenomena during 1-shot RLVR, including cross-domain generalization, increased frequency of self-reflection, and sustained test performance improvement even after the training accuracy has saturated, a phenomenon we term post-saturation generalization. Moreover, we verify that the effectiveness of 1-shot RLVR primarily arises from the policy gradient loss, distinguishing it from the "grokking" phenomenon. We also show the critical role of promoting exploration (e.g., by adding entropy loss with an appropriate coefficient) in 1-shot RLVR training. As a bonus, we observe that applying entropy loss alone, without any outcome reward, significantly enhances Qwen2.5-Math-1.5B\'s performance on MATH500 by 27.4%. These findings can inspire future work on RLVR data efficiency and encourage a re-examination of both recent progress and the underlying mechanisms in RLVR. Our code, model, and data are open source at this https URL', 'abstract_zh': '我们展示了使用验证性奖励的一次训练示例强化学习（1-shot RLVR）在激励大型语言模型的数学推理能力方面是有效的。将RLVR应用于基模型Qwen2.5-Math-1.5B，我们发现一个单一示例将模型在MATH500上的性能提升至73.6%，并在六个常见数学推理基准测试中提高了平均性能从17.6%到35.7%。该结果与使用1.2k DeepScaleR子集（MATH500：73.6%，平均：35.9%）的效果一致，包括上述示例。在不同模型（Qwen2.5-Math-7B、Llama3.2-3B-Instruct、DeepSeek-R1-Distill-Qwen-1.5B）、不同强化学习算法（GRPO和PPO）和不同类型数学示例（许多示例在作为单个训练示例时在MATH500上均实现了约30%或更高的性能提升）上观察到类似的显著改进。此外，在1-shot RLVR过程中，我们发现了跨域泛化、自我反思频率增加以及训练准确度饱和后持续提高测试性能等有趣现象，我们将这一现象称为后饱和泛化。我们还验证了1-shot RLVR的有效性主要来源于策略梯度损失，将其与其他现象区分开来。我们展示了在1-shot RLVR训练中促进探索（例如通过适当系数添加熵损失）的重要性。此外，我们发现仅应用熵损失而无任何结果奖励，显著提升了Qwen2.5-Math-1.5B在MATH500上的性能27.4%。这些发现可以激发未来RLVR数据效率方面的工作，并鼓励重新审视RLVR的近期进展及其背后的机制。我们的代码、模型和数据在此处开放获取。', 'title_zh': '在单个训练样本情况下，强化学习在大型语言模型推理中的应用'}
{'arxiv_id': 'arXiv:2504.20566', 'title': 'Inclusive Training Separation and Implicit Knowledge Interaction for Balanced Online Class-Incremental Learning', 'authors': 'Shunjie Wen, Thomas Heinis, Dong-Wan Choi', 'link': 'https://arxiv.org/abs/2504.20566', 'abstract': 'Online class-incremental learning (OCIL) focuses on gradually learning new classes (called plasticity) from a stream of data in a single-pass, while concurrently preserving knowledge of previously learned classes (called stability). The primary challenge in OCIL lies in maintaining a good balance between the knowledge of old and new classes within the continually updated model. Most existing methods rely on explicit knowledge interaction through experience replay, and often employ exclusive training separation to address bias problems. Nevertheless, it still remains a big challenge to achieve a well-balanced learner, as these methods often exhibit either reduced plasticity or limited stability due to difficulties in continually integrating knowledge in the OCIL setting. In this paper, we propose a novel replay-based method, called Balanced Online Incremental Learning (BOIL), which can achieve both high plasticity and stability, thus ensuring more balanced performance in OCIL. Our BOIL method proposes an inclusive training separation strategy using dual classifiers so that knowledge from both old and new classes can effectively be integrated into the model, while introducing implicit approaches for transferring knowledge across the two classifiers. Extensive experimental evaluations over three widely-used OCIL benchmark datasets demonstrate the superiority of BOIL, showing more balanced yet better performance compared to state-of-the-art replay-based OCIL methods.', 'abstract_zh': '基于重演的平衡在线增量学习（BOIL）', 'title_zh': '包容性训练分离与隐式知识交互以实现平衡在线类增量学习'}
{'arxiv_id': 'arXiv:2504.20560', 'title': 'Generate more than one child in your co-evolutionary semi-supervised learning GAN', 'authors': 'Francisco Sedeño, Jamal Toutouh, Francisco Chicano', 'link': 'https://arxiv.org/abs/2504.20560', 'abstract': 'Generative Adversarial Networks (GANs) are very useful methods to address semi-supervised learning (SSL) datasets, thanks to their ability to generate samples similar to real data. This approach, called SSL-GAN has attracted many researchers in the last decade. Evolutionary algorithms have been used to guide the evolution and training of SSL-GANs with great success. In particular, several co-evolutionary approaches have been applied where the two networks of a GAN (the generator and the discriminator) are evolved in separate populations. The co-evolutionary approaches published to date assume some spatial structure of the populations, based on the ideas of cellular evolutionary algorithms. They also create one single individual per generation and follow a generational replacement strategy in the evolution. In this paper, we re-consider those algorithmic design decisions and propose a new co-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN), with panmictic population, elitist replacement, and more than one individual in the offspring. We evaluate the performance of our proposed method using three standard benchmark datasets. The results show that creating more than one offspring per population and using elitism improves the results in comparison with a classical SSL-GAN.', 'abstract_zh': 'Generative Adversarial Networks (GANs)在半监督学习（SSL）数据集中的应用：一种基于随机交配群体、精英替换及多个体的协同演化方法（Co-evolutionary Elitist SSL-GAN）', 'title_zh': '在你的共进化半监督学习GAN中生成多个子代'}
{'arxiv_id': 'arXiv:2504.20520', 'title': 'PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations', 'authors': 'Haowen Sun, Han Wang, Chengzhong Ma, Shaolong Zhang, Jiawei Ye, Xingyu Chen, Xuguang Lan', 'link': 'https://arxiv.org/abs/2504.20520', 'abstract': 'Learning from few demonstrations to develop policies robust to variations in robot initial positions and object poses is a problem of significant practical interest in robotics. Compared to imitation learning, which often struggles to generalize from limited samples, reinforcement learning (RL) can autonomously explore to obtain robust behaviors. Training RL agents through direct interaction with the real world is often impractical and unsafe, while building simulation environments requires extensive manual effort, such as designing scenes and crafting task-specific reward functions. To address these challenges, we propose an integrated real-to-sim-to-real pipeline that constructs simulation environments based on expert demonstrations by identifying scene objects from images and retrieving their corresponding 3D models from existing libraries. We introduce a projection-based reward model for RL policy training that is supervised by a vision-language model (VLM) using human-guided object projection relationships as prompts, with the policy further fine-tuned using expert demonstrations. In general, our work focuses on the construction of simulation environments and RL-based policy training, ultimately enabling the deployment of reliable robotic control policies in real-world scenarios.', 'abstract_zh': '从少量示范中学习，以开发在机器人初始位置和物体姿态变化下具有鲁棒性的策略是机器人学中一个具有重要实际意义的问题。与往往难以从有限样本中泛化的imitation learning相比，reinforcement learning (RL) 可以自主探索以获得鲁棒行为。通过直接与真实世界交互来训练RL代理通常 impractical且不安全，而构建模拟环境则需要大量的手工努力，例如设计场景并构建任务特定的奖励函数。为解决这些挑战，我们提出了一种集成的real-to-sim-to-real工作流，该工作流基于专家示范构建模拟环境，通过从图像中识别场景对象并从现有库中检索其对应的3D模型来实现。我们引入了一种基于投影的RL策略训练奖励模型，该模型由视觉语言模型(VLM)监督，使用人类引导的物体投影关系作为提示，策略进一步通过专家示范进行微调。总体而言，我们的工作集中在模拟环境的构建和基于RL的策略训练上，最终使可靠的机器人控制策略能够在实际场景中部署。', 'title_zh': 'PRISM: 基于投影的奖励集成方法，实现基于场景的Few-Shot Real-to-Sim-to-Real 转移学习'}
{'arxiv_id': 'arXiv:2504.20493', 'title': 'Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression', 'authors': 'Yu Cui, Yujun Cai, Yiwei Wang', 'link': 'https://arxiv.org/abs/2504.20493', 'abstract': 'While reasoning large language models (LLMs) demonstrate remarkable performance across various tasks, they also contain notable security vulnerabilities. Recent research has uncovered a "thinking-stopped" vulnerability in DeepSeek-R1, where model-generated reasoning tokens can forcibly interrupt the inference process, resulting in empty responses that compromise LLM-integrated applications. However, existing methods triggering this vulnerability require complex mathematical word problems with long prompts--even exceeding 5,000 tokens. To reduce the token cost and formally define this vulnerability, we propose a novel prompt injection attack named "Reasoning Interruption Attack", based on adaptive token compression. We demonstrate that simple standalone arithmetic tasks can effectively trigger this vulnerability, and the prompts based on such tasks exhibit simpler logical structures than mathematical word problems. We develop a systematic approach to efficiently collect attack prompts and an adaptive token compression framework that utilizes LLMs to automatically compress these prompts. Experiments show our compression framework significantly reduces prompt length while maintaining effective attack capabilities. We further investigate the attack\'s performance via output prefix and analyze the underlying causes of the vulnerability, providing valuable insights for improving security in reasoning LLMs.', 'abstract_zh': '基于自适应token压缩的推理中断攻击', 'title_zh': '基于Token高效注入攻击：通过自适应Token压缩促使大规模语言模型推理停止'}
{'arxiv_id': 'arXiv:2504.20482', 'title': "Group Relative Knowledge Distillation: Learning from Teacher's Relational Inductive Bias", 'authors': 'Chao Li, Changhua Zhou, Jia Chen', 'link': 'https://arxiv.org/abs/2504.20482', 'abstract': "Knowledge distillation typically transfers knowledge from a teacher model to a student model by minimizing differences between their output distributions. However, existing distillation approaches largely focus on mimicking absolute probabilities and neglect the valuable relational inductive biases embedded in the teacher's relative predictions, leading to exposure bias. In this paper, we propose Group Relative Knowledge Distillation (GRKD), a novel framework that distills teacher knowledge by learning the relative ranking among classes, rather than directly fitting the absolute distribution. Specifically, we introduce a group relative loss that encourages the student model to preserve the pairwise preference orderings provided by the teacher's outputs. Extensive experiments on classification benchmarks demonstrate that GRKD achieves superior generalization compared to existing methods, especially in tasks requiring fine-grained class differentiation. Our method provides a new perspective on exploiting teacher knowledge, focusing on relational structure rather than absolute likelihood.", 'abstract_zh': 'Group Relative Knowledge Distillation', 'title_zh': '组相关知识蒸馏：学习老师的关系归纳偏置'}
{'arxiv_id': 'arXiv:2504.20471', 'title': 'The Estimation of Continual Causal Effect for Dataset Shifting Streams', 'authors': 'Baining Chen, Yiming Zhang, Yuqiao Han, Ruyue Zhang, Ruihuan Du, Zhishuo Zhou, Zhengdan Zhu, Xun Liu, Jiecheng Guo', 'link': 'https://arxiv.org/abs/2504.20471', 'abstract': 'Causal effect estimation has been widely used in marketing optimization. The framework of an uplift model followed by a constrained optimization algorithm is popular in practice. To enhance performance in the online environment, the framework needs to be improved to address the complexities caused by temporal dataset shift. This paper focuses on capturing the dataset shift from user behavior and domain distribution changing over time. We propose an Incremental Causal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle this challenge. The ICE-PKD framework includes two components: (i) a multi-treatment uplift network that eliminates confounding bias using counterfactual regression; (ii) an incremental training strategy that adapts to the temporal dataset shift by updating with the latest data and protects generalization via replay-based knowledge distillation. We also revisit the uplift modeling metrics and introduce a novel metric for more precise online evaluation in multiple treatment scenarios. Extensive experiments on both simulated and online datasets show that the proposed framework achieves better performance. The ICE-PKD framework has been deployed in the marketing system of Huaxiaozhu, a ride-hailing platform in China.', 'abstract_zh': '增量因果效应与代理知识蒸馏框架（ICE-PKD）在营销优化中的应用', 'title_zh': '持续因果效应估计在数据集迁移流中的应用'}
{'arxiv_id': 'arXiv:2504.20452', 'title': 'Enhancing News Recommendation with Hierarchical LLM Prompting', 'authors': 'Hai-Dang Kieu, Delvin Ce Zhang, Minh Duc Nguyen, Min Xu, Qiang Wu, Dung D. Le', 'link': 'https://arxiv.org/abs/2504.20452', 'abstract': 'Personalized news recommendation systems often struggle to effectively capture the complexity of user preferences, as they rely heavily on shallow representations, such as article titles and abstracts. To address this problem, we introduce a novel method, namely PNR-LLM, for Large Language Models for Personalized News Recommendation. Specifically, PNR-LLM harnesses the generation capabilities of LLMs to enrich news titles and abstracts, and consequently improves recommendation quality. PNR-LLM contains a novel module, News Enrichment via LLMs, which generates deeper semantic information and relevant entities from articles, transforming shallow contents into richer representations. We further propose an attention mechanism to aggregate enriched semantic- and entity-level data, forming unified user and news embeddings that reveal a more accurate user-news match. Extensive experiments on MIND datasets show that PNR-LLM outperforms state-of-the-art baselines. Moreover, the proposed data enrichment module is model-agnostic, and we empirically show that applying our proposed module to multiple existing models can further improve their performance, verifying the advantage of our design.', 'abstract_zh': '基于大规模语言模型的个性化新闻推荐系统PNR-LLM', 'title_zh': '基于层次化大语言模型提示的新闻推荐增强'}
{'arxiv_id': 'arXiv:2504.20447', 'title': 'APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech', 'authors': 'Zhicheng Lian, Lizhi Wang, Hua Huang', 'link': 'https://arxiv.org/abs/2504.20447', 'abstract': 'Automatic speech quality assessment aims to quantify subjective human perception of speech through computational models to reduce the need for labor-consuming manual evaluations. While models based on deep learning have achieved progress in predicting mean opinion scores (MOS) to assess synthetic speech, the neglect of fundamental auditory perception mechanisms limits consistency with human judgments. To address this issue, we propose an auditory perception guided-MOS prediction model (APG-MOS) that synergistically integrates auditory modeling with semantic analysis to enhance consistency with human judgments. Specifically, we first design a perceptual module, grounded in biological auditory mechanisms, to simulate cochlear functions, which encodes acoustic signals into biologically aligned electrochemical representations. Secondly, we propose a residual vector quantization (RVQ)-based semantic distortion modeling method to quantify the degradation of speech quality at the semantic level. Finally, we design a residual cross-attention architecture, coupled with a progressive learning strategy, to enable multimodal fusion of encoded electrochemical signals and semantic representations. Experiments demonstrate that APG-MOS achieves superior performance on two primary benchmarks. Our code and checkpoint will be available on a public repository upon publication.', 'abstract_zh': '自动语音质量评估旨在通过计算模型量化人类对语音的主观感知，减少劳动密集型的手动评估需求。尽管基于深度学习的模型在预测平均意见分（MOS）以评估合成语音方面取得了进展，但忽视了基本的听觉感知机制限制了与人类判断的一致性。为解决这一问题，我们提出了一种听觉感知引导的MOS预测模型（APG-MOS），该模型结合了听觉建模与语义分析，以增强与人类判断的一致性。具体而言，我们首先设计了一个感知模块，基于生物听觉机制，模拟耳蜗功能，将声学信号编码为生物对齐的电化学表示。其次，我们提出了一种残差向量量化（RVQ）为基础的语义失真建模方法，以在语义层面上量化语音质量的退化。最后，我们设计了一种残差交叉注意力架构，结合逐步学习策略，以实现电化学信号和语义表示的多模态融合。实验表明，APG-MOS在两个主要基准上取得了优越的性能。我们的代码和检查点将在发表后提交到公共存储库。', 'title_zh': 'APG-MOS: 听觉感知引导的合成语音MOS预测器'}
{'arxiv_id': 'arXiv:2504.20444', 'title': 'On Psychology of AI -- Does Primacy Effect Affect ChatGPT and Other LLMs?', 'authors': 'Mika Hämäläinen', 'link': 'https://arxiv.org/abs/2504.20444', 'abstract': 'We study the primacy effect in three commercial LLMs: ChatGPT, Gemini and Claude. We do this by repurposing the famous experiment Asch (1946) conducted using human subjects. The experiment is simple, given two candidates with equal descriptions which one is preferred if one description has positive adjectives first before negative ones and another description has negative adjectives followed by positive ones. We test this in two experiments. In one experiment, LLMs are given both candidates simultaneously in the same prompt, and in another experiment, LLMs are given both candidates separately. We test all the models with 200 candidate pairs. We found that, in the first experiment, ChatGPT preferred the candidate with positive adjectives listed first, while Gemini preferred both equally often. Claude refused to make a choice. In the second experiment, ChatGPT and Claude were most likely to rank both candidates equally. In the case where they did not give an equal rating, both showed a clear preference to a candidate that had negative adjectives listed first. Gemini was most likely to prefer a candidate with negative adjectives listed first.', 'abstract_zh': '我们在ChatGPT、Gemini和Claude三种商业大语言模型中研究先觉效应，并通过重新利用Asch（1946年）使用人类受试者进行的经典实验来进行。实验简单来说，给定两个描述相同但顺序不同的候选者，一个是正面形容词在前、负面形容词在后，另一个是负面形容词在前、正面形容词在后，哪一个更受欢迎。我们进行了两项实验。在第一个实验中，我们将两个候选者同时呈现给模型；在第二个实验中，我们将两个候选者分别呈现给模型。我们测试了所有模型共计200对候选者。结果发现，在第一个实验中，ChatGPT更偏好正面形容词在前的候选者，Gemini两者偏好程度相当，Claude则不愿意做出选择。在第二个实验中，ChatGPT和Claude最可能将两个候选者评定为相同。当它们不给出相同评分时，两者都更倾向于负面形容词在前的候选者。Gemini更倾向于正面形容词在后的候选者。', 'title_zh': 'AI心理学——首因效应是否影响ChatGPT及其他大语言模型？'}
{'arxiv_id': 'arXiv:2504.20437', 'title': 'GaLore 2: Large-Scale LLM Pre-Training by Gradient Low-Rank Projection', 'authors': 'DiJia Su, Andrew Gu, Jane Xu, Yuandong Tian, Jiawei Zhao', 'link': 'https://arxiv.org/abs/2504.20437', 'abstract': 'Large language models (LLMs) have revolutionized natural language understanding and generation but face significant memory bottlenecks during training. GaLore, Gradient Low-Rank Projection, addresses this issue by leveraging the inherent low-rank structure of weight gradients, enabling substantial memory savings without sacrificing performance. Recent works further extend GaLore from various aspects, including low-bit quantization and higher-order tensor structures. However, there are several remaining challenges for GaLore, such as the computational overhead of SVD for subspace updates and the integration with state-of-the-art training parallelization strategies (e.g., FSDP). In this paper, we present GaLore 2, an efficient and scalable GaLore framework that addresses these challenges and incorporates recent advancements. In addition, we demonstrate the scalability of GaLore 2 by pre-training Llama 7B from scratch using up to 500 billion training tokens, highlighting its potential impact on real LLM pre-training scenarios.', 'abstract_zh': '大规模语言模型（LLMs）在自然语言理解和生成方面带来了革命性的变化，但训练过程中面临显著的内存瓶颈。GaLore，梯度低秩投影，通过利用权重梯度的固有低秩结构，解决了这一问题，在不牺牲性能的情况下实现了显著的内存节省。最近的研究进一步从低比特量化和高阶张量结构等方面扩展了GaLore。然而，GaLore仍面临一些挑战，包括子空间更新的SVD计算开销以及与最先进的训练并行化策略（如FSDP）的集成。在此论文中，我们提出了一种高效的可扩展的GaLore框架，以解决这些挑战并集成最近的发展成果。此外，我们通过从头开始使用最多5000亿个训练令牌预训练Llama 7B，展示了GaLore 2的可扩展性，突显了其在实际大规模语言模型预训练场景中的潜在影响。', 'title_zh': 'GaLore 2：大规模LLM预训练的梯度低秩投影方法'}
{'arxiv_id': 'arXiv:2504.20434', 'title': 'ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement', 'authors': "Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley", 'link': 'https://arxiv.org/abs/2504.20434', 'abstract': 'In supercomputing, efficient and optimized code generation is essential to leverage high-performance systems effectively. We propose Agentic Retrieval-Augmented Code Synthesis (ARCS), an advanced framework for accurate, robust, and efficient code generation, completion, and translation. ARCS integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (CoT) reasoning to systematically break down and iteratively refine complex programming tasks. An agent-based RAG mechanism retrieves relevant code snippets, while real-time execution feedback drives the synthesis of candidate solutions. This process is formalized as a state-action search tree optimization, balancing code correctness with editing efficiency. Evaluations on the Geeks4Geeks and HumanEval benchmarks demonstrate that ARCS significantly outperforms traditional prompting methods in translation and generation quality. By enabling scalable and precise code synthesis, ARCS offers transformative potential for automating and optimizing code development in supercomputing applications, enhancing computational resource utilization.', 'abstract_zh': '在超级计算中，高效的代码生成是充分利用高性能系统的关键。我们提出了一种名为Agentic Retrieval-Augmented Code Synthesis (ARCS)的先进框架，该框架旨在实现准确、可靠和高效的代码生成、完成和翻译。ARCS将检索增强生成（RAG）与推理链（CoT）推理相结合，系统地分解和迭代细化复杂的编程任务。基于代理的RAG机制检索相关代码片段，实时执行反馈驱动候选解决方案的合成。这一过程被形式化为状态-动作搜索树优化，平衡代码正确性和编辑效率。ARCS在Geeks4Geeks和HumanEval基准上的评估结果显示，它在翻译和生成质量方面显著优于传统的提示方法。通过提供可扩展且精确的代码合成，ARCS为超级计算应用中的自动化和优化代码开发提供了变革性的潜力，提高了计算资源的利用效率。', 'title_zh': 'ARCS: 自动驱动的检索增强代码合成与迭代 refinement'}
{'arxiv_id': 'arXiv:2504.20412', 'title': 'CrashFixer: A crash resolution agent for the Linux kernel', 'authors': 'Alex Mathai, Chenxi Huang, Suwei Ma, Jihwan Kim, Hailie Mitchell, Aleksandr Nogikh, Petros Maniatis, Franjo Ivančić, Junfeng Yang, Baishakhi Ray', 'link': 'https://arxiv.org/abs/2504.20412', 'abstract': "Code large language models (LLMs) have shown impressive capabilities on a multitude of software engineering tasks. In particular, they have demonstrated remarkable utility in the task of code repair. However, common benchmarks used to evaluate the performance of code LLMs are often limited to small-scale settings. In this work, we build upon kGym, which shares a benchmark for system-level Linux kernel bugs and a platform to run experiments on the Linux kernel.\nThis paper introduces CrashFixer, the first LLM-based software repair agent that is applicable to Linux kernel bugs. Inspired by the typical workflow of a kernel developer, we identify the key capabilities an expert developer leverages to resolve a kernel crash. Using this as our guide, we revisit the kGym platform and identify key system improvements needed to practically run LLM-based agents at the scale of the Linux kernel (50K files and 20M lines of code). We implement these changes by extending kGym to create an improved platform - called kGymSuite, which will be open-sourced. Finally, the paper presents an evaluation of various repair strategies for such complex kernel bugs and showcases the value of explicitly generating a hypothesis before attempting to fix bugs in complex systems such as the Linux kernel. We also evaluated CrashFixer's capabilities on still open bugs, and found at least two patch suggestions considered plausible to resolve the reported bug.", 'abstract_zh': '代码大型语言模型在软件工程任务中的应用已经展现出令人印象深刻的性能，特别是在代码修复任务中表现出色。然而，用于评估代码大型语言模型性能的常见基准往往局限于小规模设置。在本文中，我们基于kGym构建，kGym提供了一个系统级Linux内核漏洞基准以及在Linux内核上运行实验的平台。本文介绍了CrashFixer，这是首个适用于Linux内核漏洞的基于大型语言模型的软件修复代理。受到内核开发者的典型工作流程启发，我们识别了专家开发者解决内核崩溃时所依赖的关键能力。通过这一指导原则，我们重新审视了kGym平台，并确定了在Linux内核规模（50K文件和20M行代码）下实际运行基于大型语言模型代理所需的关键系统改进。我们通过扩展kGym创建了一个改进的平台kGymSuite，并将开源。最后，本文评估了针对此类复杂内核漏洞的各种修复策略，并展示了在复杂系统如Linux内核中明确生成假设以尝试修复漏洞的价值。同时，我们还对CrashFixer的能力进行了评估，发现至少有两个补丁建议被认为是解决已报告漏洞的有效方案。', 'title_zh': 'CrashFixer：Linux内核的故障解决代理'}
{'arxiv_id': 'arXiv:2504.20408', 'title': 'FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation', 'authors': 'Jae Yong Lee, Gwang Jae Jung, Byung Chan Lim, Hyung Ju Hwang', 'link': 'https://arxiv.org/abs/2504.20408', 'abstract': 'The Boltzmann equation, a fundamental model in kinetic theory, describes the evolution of particle distribution functions through a nonlinear, high-dimensional collision operator. However, its numerical solution remains computationally demanding, particularly for inelastic collisions and high-dimensional velocity domains. In this work, we propose the Fourier Neural Spectral Network (FourierSpecNet), a hybrid framework that integrates the Fourier spectral method with deep learning to approximate the collision operator in Fourier space efficiently. FourierSpecNet achieves resolution-invariant learning and supports zero-shot super-resolution, enabling accurate predictions at unseen resolutions without retraining. Beyond empirical validation, we establish a consistency result showing that the trained operator converges to the spectral solution as the discretization is refined. We evaluate our method on several benchmark cases, including Maxwellian and hard-sphere molecular models, as well as inelastic collision scenarios. The results demonstrate that FourierSpecNet offers competitive accuracy while significantly reducing computational cost compared to traditional spectral solvers. Our approach provides a robust and scalable alternative for solving the Boltzmann equation across both elastic and inelastic regimes.', 'abstract_zh': 'Fourier神经谱网络（FourierSpecNet）：傅里叶空间中的谱方法与深度学习的结合', 'title_zh': 'FourierSpecNet：基于傅里叶频谱方法的玻尔兹曼方程神经碰撞算子逼近'}
{'arxiv_id': 'arXiv:2504.20405', 'title': 'SCOPE-MRI: Bankart Lesion Detection as a Case Study in Data Curation and Deep Learning for Challenging Diagnoses', 'authors': 'Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi', 'link': 'https://arxiv.org/abs/2504.20405', 'abstract': 'While deep learning has shown strong performance in musculoskeletal imaging, existing work has largely focused on pathologies where diagnosis is not a clinical challenge, leaving more difficult problems underexplored, such as detecting Bankart lesions (anterior-inferior glenoid labral tears) on standard MRIs. Diagnosing these lesions is challenging due to their subtle imaging features, often leading to reliance on invasive MRI arthrograms (MRAs). This study introduces ScopeMRI, the first publicly available, expert-annotated dataset for shoulder pathologies, and presents a deep learning (DL) framework for detecting Bankart lesions on both standard MRIs and MRAs. ScopeMRI includes 586 shoulder MRIs (335 standard, 251 MRAs) from 558 patients who underwent arthroscopy. Ground truth labels were derived from intraoperative findings, the gold standard for diagnosis. Separate DL models for MRAs and standard MRIs were trained using a combination of CNNs and transformers. Predictions from sagittal, axial, and coronal views were ensembled to optimize performance. The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71 standard MRIs). The models achieved an AUC of 0.91 and 0.93, sensitivity of 83% and 94%, and specificity of 91% and 86% for standard MRIs and MRAs, respectively. Notably, model performance on non-invasive standard MRIs matched or surpassed radiologists interpreting MRAs. External validation demonstrated initial generalizability across imaging protocols. This study demonstrates that DL models can achieve radiologist-level diagnostic performance on standard MRIs, reducing the need for invasive MRAs. By releasing ScopeMRI and a modular codebase for training and evaluating deep learning models on 3D medical imaging data, we aim to accelerate research in musculoskeletal imaging and support the development of new datasets for clinically challenging diagnostic tasks.', 'abstract_zh': '基于深学习检测标准MRI和MRAr中的Bankart损伤：ScopeMRI数据集与研究', 'title_zh': 'SCOPE-MRI: 韦氏脱位检测及其在具有挑战性的诊断数据整理和深度学习研究中的案例分析'}
{'arxiv_id': 'arXiv:2504.20368', 'title': 'AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney Injury', 'authors': 'David Gordon, Panayiotis Petousis, Susanne B. Nicholas, Alex A.T. Bui', 'link': 'https://arxiv.org/abs/2504.20368', 'abstract': "Diagnostic reasoning entails a physician's local (mental) model based on an assumed or known shared perspective (global model) to explain patient observations with evidence assigned towards a clinical assessment. But in several (complex) medical situations, multiple experts work together as a team to optimize health evaluation and decision-making by leveraging different perspectives. Such consensus-driven reasoning reflects individual knowledge contributing toward a broader perspective on the patient. In this light, we introduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework automating the learning of these global models and their incorporation as prior beliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof of concept with a prosocial MAS application for predicting acute kidney injuries (AKIs). In this case, we found that incorporating a global structure enabled multiple agents to achieve better performance (average precision, AP) in predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT, AP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs. baseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180) for balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents with higher recall scores reported lower confidence levels in the initial round on true positive and false negative cases. But after explicit interactions, their confidence in their decisions increased (suggesting reinforced belief). In contrast, the SF-FT agent with the lowest recall decreased its confidence in true positive and false negative cases (suggesting a new belief). This approach suggests that learning and leveraging global structures in MAS is necessary prior to achieving competitive classification and diagnostic reasoning performance.", 'abstract_zh': '基于结构跟随的多智能体系统框架（STRUC-MAS）及其在预测急性肾损伤中的应用', 'title_zh': 'AKIBoards: 遵循结构设计的多智能体系统用于预测急性肾损伤'}
{'arxiv_id': 'arXiv:2504.20357', 'title': 'Automated Unit Test Case Generation: A Systematic Literature Review', 'authors': 'Jason Wang, Basem Suleiman, Muhammad Johan Alibasa', 'link': 'https://arxiv.org/abs/2504.20357', 'abstract': 'Software is omnipresent within all factors of society. It is thus important to ensure that software are well tested to mitigate bad user experiences as well as the potential for severe financial and human losses. Software testing is however expensive and absorbs valuable time and resources. As a result, the field of automated software testing has grown of interest to researchers in past decades. In our review of present and past research papers, we have identified an information gap in the areas of improvement for the Genetic Algorithm and Particle Swarm Optimisation. A gap in knowledge in the current challenges that face automated testing has also been identified. We therefore present this systematic literature review in an effort to consolidate existing knowledge in regards to the evolutionary approaches as well as their improvements and resulting limitations. These improvements include hybrid algorithm combinations as well as interoperability with mutation testing and neural networks. We will also explore the main test criterion that are used in these algorithms alongside the challenges currently faced in the field related to readability, mocking and more.', 'abstract_zh': '软件无处不在，遍及社会各个层面。因此，确保软件经过充分测试以减轻不良用户体验以及潜在的严重财务和人员损失至关重要。然而，软件测试成本高昂，耗时且耗资源。由于这一原因，过去几十年中，自动软件测试领域的研究引起了研究人员的兴趣。在我们对现有和过去的研究论文的回顾中，我们发现了一个关于遗传算法和粒子群优化改善领域的信息空白。我们还发现当前自动测试面临的知识空白。因此，我们呈现这一系统文献综述，旨在整合关于进化方法及其改进和后续限制的现有知识。这些改进包括混合算法组合以及与变异测试和神经网络的互操作性。我们还将探讨这些算法中使用的主要测试标准及其相关领域面临的挑战，例如可读性、模拟等方面的问题。', 'title_zh': '自动单元测试用例生成：一项系统文献综述'}
{'arxiv_id': 'arXiv:2504.20355', 'title': 'Local Prompt Optimization', 'authors': 'Yash Jain, Vishal Chowdhary', 'link': 'https://arxiv.org/abs/2504.20355', 'abstract': 'In recent years, the use of prompts to guide the output of Large Language Models have increased dramatically. However, even the best of experts struggle to choose the correct words to stitch up a prompt for the desired task. To solve this, LLM driven prompt optimization emerged as an important problem. Existing prompt optimization methods optimize a prompt globally, where in all the prompt tokens have to be optimized over a large vocabulary while solving a complex task. The large optimization space (tokens) leads to insufficient guidance for a better prompt. In this work, we introduce Local Prompt Optimization (LPO) that integrates with any general automatic prompt engineering method. We identify the optimization tokens in a prompt and nudge the LLM to focus only on those tokens in its optimization step. We observe remarkable performance improvements on Math Reasoning (GSM8k and MultiArith) and BIG-bench Hard benchmarks across various automatic prompt engineering methods. Further, we show that LPO converges to the optimal prompt faster than global methods.', 'abstract_zh': '近年来，使用提示来引导大型语言模型的输出使用大幅增加。然而，即使是顶尖专家也难以选择正确的词汇来拼接出合适的提示以完成所需任务。为此，基于大型语言模型的提示优化成为了一个重要问题。现有的提示优化方法在全球范围内优化提示，这意味着在解决复杂任务时需要在整个庞大的词汇表上优化所有提示标记。由于优化空间（标记）很大，这会导致对更好提示的指导不足。在本文中，我们引入了局部提示优化（LPO），它可以与任何通用自动提示工程方法集成。我们确定了提示中的优化标记，并在优化步骤中引导LLM专注于这些标记。我们在各种自动提示工程方法中对数学推理（GSM8k和MultiArith）和BI GSL硬基准测试中观察到显著的性能提升。此外，我们展示了LPO比全局方法更快地收敛到最优提示。', 'title_zh': '本地提示优化'}
{'arxiv_id': 'arXiv:2504.20348', 'title': 'CarbonCall: Sustainability-Aware Function Calling for Large Language Models on Edge Devices', 'authors': 'Varatheepan Paramanayakam, Andreas Karatzas, Iraklis Anagnostopoulos, Dimitrios Stamoulis', 'link': 'https://arxiv.org/abs/2504.20348', 'abstract': 'Large Language Models (LLMs) enable real-time function calling in edge AI systems but introduce significant computational overhead, leading to high power consumption and carbon emissions. Existing methods optimize for performance while neglecting sustainability, making them inefficient for energy-constrained environments. We introduce CarbonCall, a sustainability-aware function-calling framework that integrates dynamic tool selection, carbon-aware execution, and quantized LLM adaptation. CarbonCall adjusts power thresholds based on real-time carbon intensity forecasts and switches between model variants to sustain high tokens-per-second throughput under power constraints. Experiments on an NVIDIA Jetson AGX Orin show that CarbonCall reduces carbon emissions by up to 52%, power consumption by 30%, and execution time by 30%, while maintaining high efficiency.', 'abstract_zh': 'Large Language Models (LLMs)在边缘AI系统中实现实时函数调用但引入了显著的计算开销，导致高功耗和碳排放。现有方法侧重于性能优化而忽视可持续性，使其不适合能量受限环境。我们提出CarbonCall，这是一种具备可持续性意识的函数调用框架，集成动态工具选择、碳意识执行和量化LLM适应。CarbonCall根据实时碳强度预报调整功耗阈值，并在功率约束下切换模型变体以维持高每秒令牌吞吐量。实验表明，与NVIDIA Jetson AGX Orin平台相比，CarbonCall最多可减少52%的碳排放、30%的功耗和30%的执行时间，同时保持高效性。', 'title_zh': 'CarbonCall: Awareness of可持续性在边缘设备上大型语言模型函数调用中的应用'}
{'arxiv_id': 'arXiv:2504.20342', 'title': 'Narrative-Centered Emotional Reflection: Scaffolding Autonomous Emotional Literacy with AI', 'authors': 'Shou-Tzu Han', 'link': 'https://arxiv.org/abs/2504.20342', 'abstract': 'Reflexion is an AI-powered platform designed to enable structured emotional self-reflection at scale. By integrating real-time emotion detection, layered reflective prompting, and metaphorical storytelling generation, Reflexion empowers users to engage in autonomous emotional exploration beyond basic sentiment categorization. Grounded in theories of expressive writing, cognitive restructuring, self-determination, and critical consciousness development, the system scaffolds a progressive journey from surface-level emotional recognition toward value-aligned action planning. Initial pilot studies with diverse participants demonstrate positive outcomes in emotional articulation, cognitive reframing, and perceived psychological resilience. Reflexion represents a promising direction for scalable, theory-informed affective computing interventions aimed at fostering emotional literacy and psychological growth across educational, therapeutic, and public health contexts.', 'abstract_zh': '反射平台是一款基于AI的情感结构化自我反思平台，通过集成实时情绪检测、分层反思提示和比喻性叙事生成，赋能用户超越基本情感分类进行自主情绪探索。该系统基于表达写作理论、认知重构、自我决定和批判性意识发展的理论，构建了一条从表面情绪识别向价值观一致的行动规划的渐进式旅程。初步多元参与者试点研究表明，该平台在情绪表达、认知重构和心理韧性的感知方面具有积极效果。反射平台代表了针对教育、治疗和公共卫生等领域促进情绪素养和心理成长的大规模、理论导向的情感计算干预的一个有前景的方向。', 'title_zh': '以叙事为中心的情感反思：借助AI搭建自主情感 literacy 的支架'}
{'arxiv_id': 'arXiv:2504.20323', 'title': 'Labeling Case Similarity based on Co-Citation of Legal Articles in Judgment Documents with Empirical Dispute-Based Evaluation', 'authors': 'Chao-Lin Liu, Po-Hsien Wu, Yi-Ting Yu', 'link': 'https://arxiv.org/abs/2504.20323', 'abstract': "This report addresses the challenge of limited labeled datasets for developing legal recommender systems, particularly in specialized domains like labor disputes. We propose a new approach leveraging the co-citation of legal articles within cases to establish similarity and enable algorithmic annotation. This method draws a parallel to the concept of case co-citation, utilizing cited precedents as indicators of shared legal issues. To evaluate the labeled results, we employ a system that recommends similar cases based on plaintiffs' accusations, defendants' rebuttals, and points of disputes. The evaluation demonstrates that the recommender, with finetuned text embedding models and a reasonable BiLSTM module can recommend labor cases whose similarity was measured by the co-citation of the legal articles. This research contributes to the development of automated annotation techniques for legal documents, particularly in areas with limited access to comprehensive legal databases.", 'abstract_zh': '本报告探讨了在劳动争议等专门领域开发法律推荐系统时遭遇的有限标注数据集挑战。我们提出了一种新的方法，利用案例中法律文章的共引关系来建立相似性并实现算法标注。该方法借鉴了案例共引的概念，通过引用先例作为共享法律问题的指标。为评估标注结果，我们采用一个系统，基于原告的指控、被告的反驳和争议点推荐相似案例。评估结果显示，通过微调的文本嵌入模型和合理的BiLSTM模块，推荐系统的相似案例可以通过法律文章的共引关系进行衡量。本研究为法律文件的自动标注技术开发，特别是在法律数据库访问受限的领域，提供了贡献。', 'title_zh': '基于判决文书中共引法律文章的案件相似性标注：基于实证争议的评价'}
{'arxiv_id': 'arXiv:2504.20314', 'title': 'Perturbation-efficient Zeroth-order Optimization for Hardware-friendly On-device Training', 'authors': 'Qitao Tan, Sung-En Chang, Rui Xia, Huidong Ji, Chence Yang, Ci Zhang, Jun Liu, Zheng Zhan, Zhou Zou, Yanzhi Wang, Jin Lu, Geng Yuan', 'link': 'https://arxiv.org/abs/2504.20314', 'abstract': 'Zeroth-order (ZO) optimization is an emerging deep neural network (DNN) training paradigm that offers computational simplicity and memory savings. However, this seemingly promising approach faces a significant and long-ignored challenge. ZO requires generating a substantial number of Gaussian random numbers, which poses significant difficulties and even makes it infeasible for hardware platforms, such as FPGAs and ASICs. In this paper, we identify this critical issue, which arises from the mismatch between algorithm and hardware designers. To address this issue, we proposed PeZO, a perturbation-efficient ZO framework. Specifically, we design random number reuse strategies to significantly reduce the demand for random number generation and introduce a hardware-friendly adaptive scaling method to replace the costly Gaussian distribution with a uniform distribution. Our experiments show that PeZO reduces the required LUTs and FFs for random number generation by 48.6\\% and 12.7\\%, and saves at maximum 86\\% power consumption, all without compromising training performance, making ZO optimization feasible for on-device training. To the best of our knowledge, we are the first to explore the potential of on-device ZO optimization, providing valuable insights for future research.', 'abstract_zh': '基于扰动的零阶优化：一种高效的深度神经网络训练框架', 'title_zh': '硬件友好的设备端训练高效扰动零阶优化'}
{'arxiv_id': 'arXiv:2504.20310', 'title': 'A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning', 'authors': 'Greg Gluch, Shafi Goldwasser', 'link': 'https://arxiv.org/abs/2504.20310', 'abstract': 'In this paper, we initiate a cryptographically inspired theoretical study of detection versus mitigation of adversarial inputs produced by attackers of Machine Learning algorithms during inference time.\nWe formally define defense by detection (DbD) and defense by mitigation (DbM). Our definitions come in the form of a 3-round protocol between two resource-bounded parties: a trainer/defender and an attacker. The attacker aims to produce inference-time inputs that fool the training algorithm. We define correctness, completeness, and soundness properties to capture successful defense at inference time while not degrading (too much) the performance of the algorithm on inputs from the training distribution.\nWe first show that achieving DbD and achieving DbM are equivalent for ML classification tasks. Surprisingly, this is not the case for ML generative learning tasks, where there are many possible correct outputs that can be generated for each input. We show a separation between DbD and DbM by exhibiting a generative learning task for which is possible to defend by mitigation but is provably impossible to defend by detection under the assumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE), publicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK) and Strongly Unforgeable Signatures exist. The mitigation phase uses significantly fewer samples than the initial training algorithm.', 'abstract_zh': '在本论文中，我们启动了一种密码学启发式的理论研究，探讨在机器学习算法推断过程中攻击者生成的 adversarial inputs 的检测与缓解。\n\n我们正式定义了通过检测进行防御（DbD）和通过缓解进行防御（DbM）。我们的定义以两个资源受限方之间的三轮协议形式给出：训练者/防御方和攻击者。攻击者的目标是在推断时生成能够欺骗训练算法的输入。我们定义了正确性、完备性和soundness属性，以捕捉在不显著降低算法在训练分布输入上性能的前提下，推断时成功的防御。\n\n我们首先证明了实现 DbD 和实现 DbM 在机器学习分类任务中是等价的。令人惊讶的是，在生成学习任务中并非如此，因为对于每一个输入，可以生成许多可能的正确输出。我们通过展示一项生成学习任务，其中通过缓解可以进行防御，但在假设存在基于身份的全同态加密（IB-FHE）、公开可验证零知识紧凑简洁交互式知识论证（zk-SNARK）和强不可伪造签名的情况下，证明通过检测进行防御是不可能的。缓解阶段使用的样本数量显著少于初始训练算法。', 'title_zh': '从密码学视角探讨机器学习中的缓解与检测'}
{'arxiv_id': 'arXiv:2504.20304', 'title': 'UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions', 'authors': 'Xiulin Yang, Zhuoxuan Ju, Lanni Bu, Zoey Liu, Nathan Schneider', 'link': 'https://arxiv.org/abs/2504.20304', 'abstract': 'CHILDES is a widely used resource of transcribed child and child-directed speech. This paper introduces UD-English-CHILDES, the first officially released Universal Dependencies (UD) treebank derived from previously dependency-annotated CHILDES data with consistent and unified annotation guidelines. Our corpus harmonizes annotations from 11 children and their caregivers, totaling over 48k sentences. We validate existing gold-standard annotations under the UD v2 framework and provide an additional 1M silver-standard sentences, offering a consistent resource for computational and linguistic research.', 'abstract_zh': 'UD-English-CHILDES：首个基于一致和统一标注准则的CHILDES数据生成的广泛依赖标注语料库', 'title_zh': 'UD-英语-CHILDES：儿童语言互动的优质与标准通用依存树银行'}
{'arxiv_id': 'arXiv:2504.20295', 'title': 'The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting', 'authors': 'Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon-Gutierrez, Andres Caro', 'link': 'https://arxiv.org/abs/2504.20295', 'abstract': 'Digital twins (DTs) are improving water distribution systems by using real-time data, analytics, and prediction models to optimize operations. This paper presents a DT platform designed for a Spanish water supply network, utilizing Long Short-Term Memory (LSTM) networks to predict water consumption. However, machine learning models are vulnerable to adversarial attacks, such as the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD). These attacks manipulate critical model parameters, injecting subtle distortions that degrade forecasting accuracy. To further exploit these vulnerabilities, we introduce a Learning Automata (LA) and Random LA-based approach that dynamically adjusts perturbations, making adversarial attacks more difficult to detect. Experimental results show that this approach significantly impacts prediction reliability, causing the Mean Absolute Percentage Error (MAPE) to rise from 26% to over 35%. Moreover, adaptive attack strategies amplify this effect, highlighting cybersecurity risks in AI-driven DTs. These findings emphasize the urgent need for robust defenses, including adversarial training, anomaly detection, and secure data pipelines.', 'abstract_zh': '数字孪生平台在西班牙供水网络中的实时数据、分析和预测模型优化应用：基于长短时记忆网络的水消耗预测及对抗性攻击防御研究', 'title_zh': '数字孪生的阴暗面：针对AI驱动水资源预报的对抗攻击'}
{'arxiv_id': 'arXiv:2504.20275', 'title': 'Smart Water Security with AI and Blockchain-Enhanced Digital Twins', 'authors': 'Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon Gutierrez, Ruben Molano Gomez, Andres Caro', 'link': 'https://arxiv.org/abs/2504.20275', 'abstract': 'Water distribution systems in rural areas face serious challenges such as a lack of real-time monitoring, vulnerability to cyberattacks, and unreliable data handling. This paper presents an integrated framework that combines LoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection System (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure and transparent water management. The IDS filters anomalous or spoofed data using a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before validated data is logged via smart contracts on a private Ethereum blockchain using Proof of Authority (PoA) consensus. The verified data feeds into a real-time DT model supporting leak detection, consumption forecasting, and predictive maintenance. Experimental results demonstrate that the system achieves over 80 transactions per second (TPS) with under 2 seconds of latency while remaining cost-effective and scalable for up to 1,000 smart meters. This work demonstrates a practical and secure architecture for decentralized water infrastructure in under-connected rural environments.', 'abstract_zh': '基于LoRaWAN的数据采集、机器学习驱动的入侵检测系统及区块链赋能的数字孪生平台在农村区域水分配系统的集成框架：安全透明的水管理解决方案', 'title_zh': '智能水安全：AI和区块链增强的数字孪生技术'}
{'arxiv_id': 'arXiv:2504.20251', 'title': 'A Platform for Generating Educational Activities to Teach English as a Second Language', 'authors': 'Aiala Rosá, Santiago Góngora, Juan Pablo Filevich, Ignacio Sastre, Laura Musto, Brian Carpenter, Luis Chiruzzo', 'link': 'https://arxiv.org/abs/2504.20251', 'abstract': 'We present a platform for the generation of educational activities oriented to teaching English as a foreign language. The different activities --games and language practice exercises-- are strongly based on Natural Language Processing techniques. The platform offers the possibility of playing out-of-the-box games, generated from resources created semi-automatically and then manually curated. It can also generate games or exercises of greater complexity from texts entered by teachers, providing a stage of review and edition of the generated content before use. As a way of expanding the variety of activities in the platform, we are currently experimenting with image and text generation. In order to integrate them and improve the performance of other neural tools already integrated, we are working on migrating the platform to a more powerful server. In this paper we describe the development of our platform and its deployment for end users, discussing the challenges faced and how we overcame them, and also detail our future work plans.', 'abstract_zh': '我们提出一个面向foreign language教学的教育活动生成平台。不同活动——游戏和语言练习——强烈依赖于自然语言处理技术。该平台提供了从半自动创建并人工筛选的资源中玩即用游戏的可能性，还可以根据教师输入的文本生成更复杂的游戏或练习，提供生成内容的审查和编辑阶段。为了增加平台活动的多样性，我们目前正在实验图像和文本生成。为了整合它们并提高已经集成的其他神经工具的性能，我们正在致力于将平台迁移至更强大的服务器。在本文中我们描述了该平台的开发及其面向最终用户的部署，讨论了所面临的技术挑战及解决方法，并详细说明了我们的未来工作计划。', 'title_zh': '一个用于教授第二语言英语的教学活动生成平台'}
{'arxiv_id': 'arXiv:2504.20213', 'title': 'Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework', 'authors': 'Yuan Xia, Akanksha Atrey, Fadoua Khmaissia, Kedar S. Namjoshi', 'link': 'https://arxiv.org/abs/2504.20213', 'abstract': "This paper investigates the logical reasoning capabilities of large language models (LLMs). For a precisely defined yet tractable formulation, we choose the conceptually simple but technically complex task of constructing proofs in Boolean logic. A trained LLM receives as input a set of assumptions and a goal, and produces as output a proof that formally derives the goal from the assumptions. Incorrect proofs are caught by an automated proof checker. A critical obstacle for training is the scarcity of real-world proofs. We propose an efficient, randomized procedure for synthesizing valid proofs and introduce Template Transformation, a data augmentation technique that enhances the model's ability to handle complex logical expressions. The central evaluation question is whether an LLM has indeed learned to reason. We propose tests to measure the reasoning ability of a black-box LLM. By these measures, experiments demonstrate strong reasoning capabilities for assertions with short proofs, which decline with proof complexity. Notably, template transformation improves accuracy even for smaller models, suggesting its effectiveness across model scales.", 'abstract_zh': '本文考察了大规模语言模型（LLM）的逻辑推理能力。为了选择一个概念简洁但技术上复杂的问题，我们选择了构建布尔逻辑证明的任务。经过训练的LLM接收一组假设和一个目标，并生成一个正式从假设推导出目标的证明。错误的证明由自动证明检查器捕获。训练的关键障碍是现实世界证明的稀缺性。我们提出了一种高效且随机化的证明合成方法，并引入了模板转换数据增强技术，以提高模型处理复杂逻辑表达式的能力。中心评价问题是LLM是否确实学会了推理。我们提出了测试以衡量黑盒LLM的推理能力。通过这些测试，实验表明，对于短证明的断言具有较强的推理能力，但随着证明复杂度的增加而下降。值得注意的是，模板转换即使对较小的模型也能提高准确性，这表明其在不同模型规模上的有效性。', 'title_zh': '大型语言模型能否学习形式逻辑？一种基于数据的训练与评估框架'}
{'arxiv_id': 'arXiv:2504.20199', 'title': 'Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains', 'authors': 'Juntian Zhang, Chuanqi cheng, Yuhan Liu, Wei Liu, Jian Luan, Rui Yan', 'link': 'https://arxiv.org/abs/2504.20199', 'abstract': "Vision-language models (VLMs) achieve remarkable success in single-image tasks. However, real-world scenarios often involve intricate multi-image inputs, leading to a notable performance decline as models struggle to disentangle critical information scattered across complex visual features. In this work, we propose Focus-Centric Visual Chain, a novel paradigm that enhances VLMs'perception, comprehension, and reasoning abilities in multi-image scenarios. To facilitate this paradigm, we propose Focus-Centric Data Synthesis, a scalable bottom-up approach for synthesizing high-quality data with elaborate reasoning paths. Through this approach, We construct VISC-150K, a large-scale dataset with reasoning data in the form of Focus-Centric Visual Chain, specifically designed for multi-image tasks. Experimental results on seven multi-image benchmarks demonstrate that our method achieves average performance gains of 3.16% and 2.24% across two distinct model architectures, without compromising the general vision-language capabilities. our study represents a significant step toward more robust and capable vision-language systems that can handle complex visual scenarios.", 'abstract_zh': 'Vision-language模型（VLMs）在单图像任务中取得了显著成功。然而，在现实场景中往往涉及复杂的多图像输入，导致模型在多图像场景中的性能显著下降，因为模型难以分离散布在复杂视觉特征中的关键信息。为此，我们提出了以聚焦为中心的视觉链（Focus-Centric Visual Chain）范式，该范式增强了模型在多图像场景中的感知、理解和推理能力。为了实现这一范式，我们提出了以聚焦为中心的数据合成方法，这是一种可扩展的自底向上的方法，用于合成具有详细推理路径的高质量数据。通过这种方法，我们构建了VISC-150K数据集，该数据集包含以聚焦为中心的视觉链形式的推理数据，专门设计用于多图像任务。实验结果显示，我们的方法在两种不同的模型架构上分别取得了3.16%和2.24%的平均性能提升，而不牺牲一般视觉语言能力。我们的研究代表了向更具鲁棒性和能力的视觉语言系统迈出的重要一步，这些系统能够处理复杂的视觉场景。', 'title_zh': '在图像间编织语境：通过焦点为中心的视觉链增强视觉语言模型'}
{'arxiv_id': 'arXiv:2504.20197', 'title': 'Representation Learning on a Random Lattice', 'authors': 'Aryeh Brill', 'link': 'https://arxiv.org/abs/2504.20197', 'abstract': "Decomposing a deep neural network's learned representations into interpretable features could greatly enhance its safety and reliability. To better understand features, we adopt a geometric perspective, viewing them as a learned coordinate system for mapping an embedded data distribution. We motivate a model of a generic data distribution as a random lattice and analyze its properties using percolation theory. Learned features are categorized into context, component, and surface features. The model is qualitatively consistent with recent findings in mechanistic interpretability and suggests directions for future research.", 'abstract_zh': '将深度神经网络学习表示分解为可解释特征能够大幅增强其安全性和可靠性。通过几何视角理解特征，视其为一种嵌入数据分布的learned坐标系。我们将通用数据分布建模为随机晶格，并利用渗流理论分析其性质。学习到的特征被分类为上下文特征、组件特征和表征特征。该模型与近期在机制可解释性方面的发现定性一致，并为未来研究提供了方向。', 'title_zh': '随机晶格上的表示学习'}
{'arxiv_id': 'arXiv:2504.20196', 'title': 'Prompting LLMs for Code Editing: Struggles and Remedies', 'authors': 'Daye Nam, Ahmed Omran, Ambar Murillo, Saksham Thakur, Abner Araujo, Marcel Blistein, Alexander Frömmgen, Vincent Hellendoorn, Satish Chandra', 'link': 'https://arxiv.org/abs/2504.20196', 'abstract': 'Large Language Models (LLMs) are rapidly transforming software engineering, with coding assistants embedded in an IDE becoming increasingly prevalent. While research has focused on improving the tools and understanding developer perceptions, a critical gap exists in understanding how developers actually use these tools in their daily workflows, and, crucially, where they struggle. This paper addresses part of this gap through a multi-phased investigation of developer interactions with an LLM-powered code editing and transformation feature, Transform Code, in an IDE widely used at Google. First, we analyze telemetry logs of the feature usage, revealing that frequent re-prompting can be an indicator of developer struggles with using Transform Code. Second, we conduct a qualitative analysis of unsatisfactory requests, identifying five key categories of information often missing from developer prompts. Finally, based on these findings, we propose and evaluate a tool, AutoPrompter, for automatically improving prompts by inferring missing information from the surrounding code context, leading to a 27% improvement in edit correctness on our test set.', 'abstract_zh': '大型语言模型（LLMs）正在 rapidly transform 软件工程，编码助手嵌入IDE变得日益普遍。尽管研究集中在改进工具和理解开发者感知上，但在开发者实际在日常工作中如何使用这些工具以及他们遇到困难的地方，仍存在一个关键缺口。本文通过多阶段调查开发者与一种由LLM驱动的代码编辑和转换功能Transform Code在广泛用于Google的IDE中的交互，来部分填补这一缺口。首先，我们分析该功能使用的遥测日志，揭示频繁重新提示可能是开发者在使用Transform Code时遇到困难的指标。其次，我们对不满意的请求进行定性分析，确定了开发者提示中经常缺失的五个关键信息类别。最后，基于这些发现，我们提出了并评估了一个名为AutoPrompter的工具，该工具可以通过从附近代码上下文推断缺失信息来自动改进提示，我们的测试集结果显示编辑正确性提高了27%。', 'title_zh': '提示大模型进行代码编辑：困境与解决方案'}
{'arxiv_id': 'arXiv:2504.20187', 'title': 'AI Recommendation Systems for Lane-Changing Using Adherence-Aware Reinforcement Learning', 'authors': 'Weihao Sun, Heeseung Bang, Andreas A. Malikopoulos', 'link': 'https://arxiv.org/abs/2504.20187', 'abstract': "In this paper, we present an adherence-aware reinforcement learning (RL) approach aimed at seeking optimal lane-changing recommendations within a semi-autonomous driving environment to enhance a single vehicle's travel efficiency. The problem is framed within a Markov decision process setting and is addressed through an adherence-aware deep Q network, which takes into account the partial compliance of human drivers with the recommended actions. This approach is evaluated within CARLA's driving environment under realistic scenarios.", 'abstract_zh': '本文提出一种依从性感知强化学习方法，旨在在半自主驾驶环境中寻找最优换道建议，以提升单辆车辆的出行效率。该问题被建模为马尔可夫决策过程，并通过一种考虑人类驾驶员部分依从性的依从性感知深层Q网络来解决。该方法在CARLA的驾驶环境中，在现实场景下进行了评估。', 'title_zh': '基于遵守意识增强学习的车道变换推荐系统'}
{'arxiv_id': 'arXiv:2504.20183', 'title': 'BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics', 'authors': 'Niki van Stein, Anna V. Kononova, Haoran Yin, Thomas Bäck', 'link': 'https://arxiv.org/abs/2504.20183', 'abstract': "The application of Large Language Models (LLMs) for Automated Algorithm Discovery (AAD), particularly for optimisation heuristics, is an emerging field of research. This emergence necessitates robust, standardised benchmarking practices to rigorously evaluate the capabilities and limitations of LLM-driven AAD methods and the resulting generated algorithms, especially given the opacity of their design process and known issues with existing benchmarks. To address this need, we introduce BLADE (Benchmark suite for LLM-driven Automated Design and Evolution), a modular and extensible framework specifically designed for benchmarking LLM-driven AAD methods in a continuous black-box optimisation context. BLADE integrates collections of benchmark problems (including MA-BBOB and SBOX-COST among others) with instance generators and textual descriptions aimed at capability-focused testing, such as generalisation, specialisation and information exploitation. It offers flexible experimental setup options, standardised logging for reproducibility and fair comparison, incorporates methods for analysing the AAD process (e.g., Code Evolution Graphs and various visualisation approaches) and facilitates comparison against human-designed baselines through integration with established tools like IOHanalyser and IOHexplainer. BLADE provides an `out-of-the-box' solution to systematically evaluate LLM-driven AAD approaches. The framework is demonstrated through two distinct use cases exploring mutation prompt strategies and function specialisation.", 'abstract_zh': '大型语言模型（LLMs）在自动化算法发现（AAD）中的应用，特别是优化启发式算法，是一个新兴的研究领域。为了严谨评估LLM驱动的AAD方法及其生成算法的能力和局限性，特别是考虑到它们设计过程的不透明性和现有基准存在的问题，我们提出了BLADE（LLM驱动的自动化设计与演化基准套件），一个模块化和可扩展的框架，专门用于连续黑盒优化环境中的LLM驱动的AAD方法基准测试。BLADE集成了多种基准问题集合（包括MA-BBOB和SBOX-COST等），并提供实例生成器和旨在进行能力测试（如泛化、特化和信息利用）的文本描述。它提供了灵活的实验设置选项、标准化的日志记录以确保可再现性和公平比较，并结合了分析AAD过程的方法（如代码演化图和各种可视化方法），并通过与IOHanalyser和IOHexplainer等现有工具的集成，促进与人类设计基准的比较。BLADE提供了一种开箱即用的解决方案，系统地评估LLM驱动的AAD方法。框架通过两种不同的应用场景展示了突变提示策略和函数特化的探索。', 'title_zh': 'BLADE：由大规模语言模型驱动的迭代优化启发式自动化设计与演变基准套件'}
{'arxiv_id': 'arXiv:2504.20179', 'title': 'Integration Flow Models', 'authors': 'Jingjing Wang, Dan Zhang, Joshua Luo, Yin Yang, Feng Luo', 'link': 'https://arxiv.org/abs/2504.20179', 'abstract': 'Ordinary differential equation (ODE) based generative models have emerged as a powerful approach for producing high-quality samples in many applications. However, the ODE-based methods either suffer the discretization error of numerical solvers of ODE, which restricts the quality of samples when only a few NFEs are used, or struggle with training instability. In this paper, we proposed Integration Flow, which directly learns the integral of ODE-based trajectory paths without solving the ODE functions. Moreover, Integration Flow explicitly incorporates the target state $\\mathbf{x}_0$ as the anchor state in guiding the reverse-time dynamics. We have theoretically proven this can contribute to both stability and accuracy. To the best of our knowledge, Integration Flow is the first model with a unified structure to estimate ODE-based generative models and the first to show the exact straightness of 1-Rectified Flow without reflow. Through theoretical analysis and empirical evaluations, we show that Integration Flows achieve improved performance when it is applied to existing ODE-based models, such as diffusion models, Rectified Flows, and PFGM++. Specifically, Integration Flow achieves one-step generation on CIFAR10 with FIDs of 2.86 for the Variance Exploding (VE) diffusion model, 3.36 for rectified flow without reflow, and 2.91 for PFGM++; and on ImageNet with FIDs of 4.09 for VE diffusion model, 4.35 for rectified flow without reflow and 4.15 for PFGM++.', 'abstract_zh': '基于常微分方程（ODE）的生成模型已成为在众多应用中生成高质量样本的一种强大方法。然而，基于ODE的方法要么受到数值求解器的离散化误差的限制，这在只使用少量NFE时会限制样本质量，要么难以应对训练中的不稳定性。在本文中，我们提出了积分流（Integration Flow），该方法直接学习ODE轨迹路径的积分，而无需求解ODE函数。此外，积分流显式地将目标状态$\\mathbf{x}_0$作为反向时间动力学中的锚状态进行引导。我们理论上证明了这一点可以提高稳定性和准确性。据我们所知，积分流是第一个具备统一结构来估计基于ODE的生成模型的模型，并且是第一个在不重新耦合的情况下展示1-修正流（1-Rectified Flow）精确直线性的模型。通过理论分析和实验评估，我们表明当积分流应用于现有的基于ODE的模型（如扩散模型、非重耦合修正流和PFGM++）时，可以实现改进的性能。具体而言，积分流在CIFAR10上的结果为：扩散模型（VE）的FID为2.86，非重耦合修正流的FID为3.36，PFGM++的FID为2.91；在ImageNet上的结果为：扩散模型（VE）的FID为4.09，非重耦合修正流的FID为4.35，PFGM++的FID为4.15。', 'title_zh': '集成流程模型'}
{'arxiv_id': 'arXiv:2504.20172', 'title': 'Causal Identification in Time Series Models', 'authors': 'Erik Jahn, Karthik Karnik, Leonard J. Schulman', 'link': 'https://arxiv.org/abs/2504.20172', 'abstract': 'In this paper, we analyze the applicability of the Causal Identification algorithm to causal time series graphs with latent confounders. Since these graphs extend over infinitely many time steps, deciding whether causal effects across arbitrary time intervals are identifiable appears to require computation on graph segments of unbounded size. Even for deciding the identifiability of intervention effects on variables that are close in time, no bound is known on how many time steps in the past need to be considered. We give a first bound of this kind that only depends on the number of variables per time step and the maximum time lag of any direct or latent causal effect. More generally, we show that applying the Causal Identification algorithm to a constant-size segment of the time series graph is sufficient to decide identifiability of causal effects, even across unbounded time intervals.', 'abstract_zh': '本文分析了因果识别算法在具有潜变量共因的因果时间序列图中的适用性。由于这些图跨越无穷多个时间步，决定任意时间区间内的因果效应是否可识别似乎需要对无界大小的图段进行计算。即使对于决定邻近时间变量的干预效应的可识别性，也不知道需要考虑多少个过去的时间步。我们给出了第一种仅依赖每时间步变量数和任何直接或潜变量因果效应的最大时间滞后数的此类界线。更一般地，我们证明了将因果识别算法应用于时间序列图的固定大小段落足以决定因果效应的可识别性，即使在无界时间区间内也是如此。', 'title_zh': '时间序列模型中的因果识别'}
{'arxiv_id': 'arXiv:2504.20168', 'title': 'MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools', 'authors': 'Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson', 'link': 'https://arxiv.org/abs/2504.20168', 'abstract': "Tool-using agents that act in the world need to be both useful and safe. Well-calibrated model confidences can be used to weigh the risk versus reward of potential actions, but prior work shows that many models are poorly calibrated. Inspired by interpretability literature exploring the internals of models, we propose a novel class of model-internal confidence estimators (MICE) to better assess confidence when calling tools. MICE first decodes from each intermediate layer of the language model using logitLens and then computes similarity scores between each layer's generation and the final output. These features are fed into a learned probabilistic classifier to assess confidence in the decoded output. On the simulated trial and error (STE) tool-calling dataset using Llama3 models, we find that MICE beats or matches the baselines on smoothed expected calibration error. Using MICE confidences to determine whether to call a tool significantly improves over strong baselines on a new metric, expected tool-calling utility. Further experiments show that MICE is sample-efficient, can generalize zero-shot to unseen APIs, and results in higher tool-calling utility in scenarios with varying risk levels. Our code is open source, available at this https URL.", 'abstract_zh': '面向世界操作的工具使用智能体需要既有效又安全。合适的模型置信度可用于权衡潜在行动的风险与回报，但先前的工作表明许多模型的置信度校准不佳。受可解释性文献中探索模型内部机制的启发，我们提出了一种新型的模型内部置信度估算器（MICE），以更好地评估调用工具时的置信度。MICE 首先使用 logitLens 解码语言模型的每个中间层，并然后计算每一层生成内容与最终输出之间的相似度分数。这些特征被输入一个学习到的概率分类器以评估解码输出的置信度。在使用 Llama3 模型的模拟试错（STE）工具调用数据集上，我们发现 MICE 在平滑化期望校准误差上优于或匹配了基线。使用 MICE 置信度来决定是否调用工具显著提高了在新指标期望工具调用效用上的表现。进一步的实验表明 MICE 是样本效率高的，可以零样本泛化到未见的 API，并在不同风险水平的情景中提高了工具调用效用。我们的代码是开源的，可在此链接访问。', 'title_zh': 'MICE for CATs: 模型内部置信度估计用于校准工具辅助的代理'}
{'arxiv_id': 'arXiv:2504.20131', 'title': 'LZ Penalty: An information-theoretic repetition penalty for autoregressive language models', 'authors': 'Antonio A. Ginart, Naveen Kodali, Jason Lee, Caiming Xiong, Silvio Savarese, John R. Emmons', 'link': 'https://arxiv.org/abs/2504.20131', 'abstract': 'We introduce the LZ penalty, a penalty specialized for reducing degenerate repetitions in autoregressive language models without loss of capability. The penalty is based on the codelengths in the LZ77 universal lossless compression algorithm. Through the lens of the prediction-compression duality, decoding the LZ penalty has the interpretation of sampling from the residual distribution after removing the information that is highly compressible. We demonstrate the LZ penalty enables state-of-the-art open-source reasoning models to operate with greedy (temperature zero) decoding without loss of capability and without instances of degenerate repetition. Both the industry-standard frequency penalty and repetition penalty are ineffective, incurring degenerate repetition rates of up to 4%.', 'abstract_zh': 'LZ惩罚：一种用于减少自回归语言模型中退化重复现象的专业惩罚方法', 'title_zh': 'LZ罚分：自回归语言模型的信息论重复罚分'}
{'arxiv_id': 'arXiv:2504.20125', 'title': 'Towards Large Language Models for Lunar Mission Planning and In Situ Resource Utilization', 'authors': 'Michael Pekala, Gregory Canal, Samuel Barham, Milena B. Graziano, Morgan Trexler, Leslie Hamilton, Elizabeth Reilly, Christopher D. Stiles', 'link': 'https://arxiv.org/abs/2504.20125', 'abstract': 'A key factor for lunar mission planning is the ability to assess the local availability of raw materials. However, many potentially relevant measurements are scattered across a variety of scientific publications. In this paper we consider the viability of obtaining lunar composition data by leveraging LLMs to rapidly process a corpus of scientific publications. While leveraging LLMs to obtain knowledge from scientific documents is not new, this particular application presents interesting challenges due to the heterogeneity of lunar samples and the nuances involved in their characterization. Accuracy and uncertainty quantification are particularly crucial since many materials properties can be sensitive to small variations in composition. Our findings indicate that off-the-shelf LLMs are generally effective at extracting data from tables commonly found in these documents. However, there remains opportunity to further refine the data we extract in this initial approach; in particular, to capture fine-grained mineralogy information and to improve performance on more subtle/complex pieces of information.', 'abstract_zh': '月球任务规划的一个关键因素是评估当地原材料的可用性。然而，许多相关的测量结果分散在各种科学出版物中。本文考虑通过利用大规模语言模型（LLMs）快速处理科学出版物集合来获取月球成分数据的可行性。尽管利用LLMs从科学文献中获取知识并不新鲜，但这种特定应用由于月球样本的异质性和其表征中的细微之处，面临着有趣的挑战。准确性与不确定性量化尤为重要，因为许多材料性质可能会对成分的细微变化敏感。我们的研究结果表明，现成的LLM通常适用于提取这些文档中常见的表格数据。然而，在初始方法中，仍有机会进一步细化提取的数据；特别是捕捉细微的矿物信息和提高对更微妙/复杂信息的表现。', 'title_zh': '面向月球任务规划与原位资源利用的大规模语言模型'}
{'arxiv_id': 'arXiv:2504.20124', 'title': 'Pediatric Asthma Detection with Googles HeAR Model: An AI-Driven Respiratory Sound Classifier', 'authors': 'Abul Ehtesham, Saket Kumar, Aditi Singh, Tala Talaei Khoei', 'link': 'https://arxiv.org/abs/2504.20124', 'abstract': 'Early detection of asthma in children is crucial to prevent long-term respiratory complications and reduce emergency interventions. This work presents an AI-powered diagnostic pipeline that leverages Googles Health Acoustic Representations (HeAR) model to detect early signs of asthma from pediatric respiratory sounds. The SPRSound dataset, the first open-access collection of annotated respiratory sounds in children aged 1 month to 18 years, is used to extract 2-second audio segments labeled as wheeze, crackle, rhonchi, stridor, or normal. Each segment is embedded into a 512-dimensional representation using HeAR, a foundation model pretrained on 300 million health-related audio clips, including 100 million cough sounds. Multiple classifiers, including SVM, Random Forest, and MLP, are trained on these embeddings to distinguish between asthma-indicative and normal sounds. The system achieves over 91\\% accuracy, with strong performance on precision-recall metrics for positive cases. In addition to classification, learned embeddings are visualized using PCA, misclassifications are analyzed through waveform playback, and ROC and confusion matrix insights are provided. This method demonstrates that short, low-resource pediatric recordings, when powered by foundation audio models, can enable fast, noninvasive asthma screening. The approach is especially promising for digital diagnostics in remote or underserved healthcare settings.', 'abstract_zh': '基于AI的诊断管道早期检测儿童哮喘 crucial early detection of asthma in children through an AI-powered diagnostic pipeline', 'title_zh': '基于Google的HeAR模型的儿童哮喘检测：一种AI驱动的呼吸音分类器'}
{'arxiv_id': 'arXiv:2504.20119', 'title': 'Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets', 'authors': 'Lorenz Brehme, Thomas Ströhle, Ruth Breu', 'link': 'https://arxiv.org/abs/2504.20119', 'abstract': "Retrieval-Augmented Generation (RAG) has advanced significantly in recent years. The complexity of RAG systems, which involve multiple components-such as indexing, retrieval, and generation-along with numerous other parameters, poses substantial challenges for systematic evaluation and quality enhancement. Previous research highlights that evaluating RAG systems is essential for documenting advancements, comparing configurations, and identifying effective approaches for domain-specific applications. This study systematically reviews 63 academic articles to provide a comprehensive overview of state-of-the-art RAG evaluation methodologies, focusing on four key areas: datasets, retrievers, indexing and databases, and the generator component. We observe the feasibility of an automated evaluation approach for each component of a RAG system, leveraging an LLM capable of both generating evaluation datasets and conducting evaluations. In addition, we found that further practical research is essential to provide companies with clear guidance on the do's and don'ts of implementing and evaluating RAG systems. By synthesizing evaluation approaches for key RAG components and emphasizing the creation and adaptation of domain-specific datasets for benchmarking, we contribute to the advancement of systematic evaluation methods and the improvement of evaluation rigor for RAG systems. Furthermore, by examining the interplay between automated approaches leveraging LLMs and human judgment, we contribute to the ongoing discourse on balancing automation and human input, clarifying their respective contributions, limitations, and challenges in achieving robust and reliable evaluations.", 'abstract_zh': '检索增强生成（RAG）在近年来取得了显著进步。复杂的RAG系统涉及多个组件——如索引、检索和生成——以及众多其他参数，这对系统的系统性评估和质量提升提出了重大挑战。以往的研究强调，评估RAG系统对于记录进步、比较配置以及识别适用于特定领域的有效方法至关重要。本研究系统地回顾了63篇学术文章，提供了关于前沿RAG评估方法的全面概述，重点关注四个关键领域：数据集、检索器、索引和数据库，以及生成器组件。我们观察到，可以利用具备生成评价数据集和进行评估能力的大语言模型（LLM）来实现每个RAG系统组件的自动化评价方法。此外，我们发现进一步的实际研究对于为企业提供实施和评估RAG系统的明确指导是必不可少的。通过综合关键RAG组件的评价方法，并强调为基准测试创建和适应领域特定数据集，我们为系统评价方法的发展和技术进步做出了贡献，并提高了RAG系统评价的严谨性。此外，通过研究利用LLM的自动化方法与人类判断之间的交互，我们为自动化与人类输入的平衡讨论做出了贡献，阐明了它们各自的贡献、局限性和挑战，以实现稳健可靠的评价。', 'title_zh': 'LLM用于评估RAG系统可信吗？一种方法和数据集综述'}
{'arxiv_id': 'arXiv:2504.20118', 'title': 'OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis', 'authors': 'Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen', 'link': 'https://arxiv.org/abs/2504.20118', 'abstract': 'Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we integrate OpenTCM with this knowledge graph, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that our prompt design and model selection significantly improve knowledge graph quality, achieving a precision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves mean expert scores of 4.5 in ingredient information retrieval and 3.8 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.', 'abstract_zh': '传统中医（TCM）代表了丰富的古代医学知识宝库，在现代医疗保健中发挥着重要作用。由于中医文献的复杂性和广泛性，集成人工智能技术对于其现代化和更广泛的可访问性至关重要。然而，这一集成也面临诸多挑战，包括解释晦涩的古典中文文本和模拟能动的中医概念之间的复杂语义关系。在本文中，我们开发了OpenTCM，这是一个基于LLM的系统，结合了领域特定的中医知识图谱和基于图的检索增强生成（GraphRAG）系统。首先，我们借助中医和妇产科专家的帮助，从中国医典数据库中的68部妇科学术著作中提取了超过373万个古典汉字。其次，我们构建了一个包含超过48,000个实体和152,000个关系的综合多关系知识图谱，使用定制提示和中文导向的LLM（如DeepSeek和Kimi）确保高保真语义理解。最后，我们将OpenTCM与该知识图谱集成，无需模型微调即可实现高保真度的药材知识检索和诊断问答。实验评估表明，我们的提示设计和模型选择显著提高了知识图谱的质量，达到了98.55%的精度和99.55%的F1分数。此外，在成分信息检索和诊断问答任务中，OpenTCM的平均专家评分为4.5和3.8，优于实际应用中现有最先进的解决方案。', 'title_zh': 'OpenTCM：一种基于GraphRAG的LLM系统，用于中医知识检索与诊断'}
{'arxiv_id': 'arXiv:2504.20117', 'title': 'ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies', 'authors': 'Shubham Gandhi, Dhruv Shah, Manasi Patwardhan, Lovekesh Vig, Gautam Shroff', 'link': 'https://arxiv.org/abs/2504.20117', 'abstract': "In this paper we introduce ResearchCodeAgent, a novel multi-agent system leveraging large language models (LLMs) agents to automate the codification of research methodologies described in machine learning literature. The system bridges the gap between high-level research concepts and their practical implementation, allowing researchers auto-generating code of existing research papers for benchmarking or building on top-of existing methods specified in the literature with availability of partial or complete starter code. ResearchCodeAgent employs a flexible agent architecture with a comprehensive action suite, enabling context-aware interactions with the research environment. The system incorporates a dynamic planning mechanism, utilizing both short and long-term memory to adapt its approach iteratively. We evaluate ResearchCodeAgent on three distinct machine learning tasks with distinct task complexity and representing different parts of the ML pipeline: data augmentation, optimization, and data batching. Our results demonstrate the system's effectiveness and generalizability, with 46.9% of generated code being high-quality and error-free, and 25% showing performance improvements over baseline implementations. Empirical analysis shows an average reduction of 57.9% in coding time compared to manual implementation. We observe higher gains for more complex tasks. ResearchCodeAgent represents a significant step towards automating the research implementation process, potentially accelerating the pace of machine learning research.", 'abstract_zh': 'ResearchCodeAgent：利用大型语言模型代理自动化机器学习研究方法的编码', 'title_zh': 'ResearchCodeAgent: 一种用于研究方法自动化编码的LLM多智能体系统'}
{'arxiv_id': 'arXiv:2504.20115', 'title': 'AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers', 'authors': 'Zijie Lin, Yiqing Shen, Qilin Cai, He Sun, Jinrui Zhou, Mingjun Xiao', 'link': 'https://arxiv.org/abs/2504.20115', 'abstract': "Machine Learning (ML) research is spread through academic papers featuring rich multimodal content, including text, diagrams, and tabular results. However, translating these multimodal elements into executable code remains a challenging and time-consuming process that requires substantial ML expertise. We introduce ``Paper-to-Code'' (P2C), a novel task that transforms the multimodal content of scientific publications into fully executable code repositories, which extends beyond the existing formulation of code generation that merely converts textual descriptions into isolated code snippets. To automate the P2C process, we propose AutoP2C, a multi-agent framework based on large language models that processes both textual and visual content from research papers to generate complete code repositories. Specifically, AutoP2C contains four stages: (1) repository blueprint extraction from established codebases, (2) multimodal content parsing that integrates information from text, equations, and figures, (3) hierarchical task decomposition for structured code generation, and (4) iterative feedback-driven debugging to ensure functionality and performance. Evaluation on a benchmark of eight research papers demonstrates the effectiveness of AutoP2C, which can successfully generate executable code repositories for all eight papers, while OpenAI-o1 or DeepSeek-R1 can only produce runnable code for one paper. The code is available at this https URL.", 'abstract_zh': '将学术论文中的富模态内容转换为可执行代码（Paper-to-Code）：AutoP2C多agent框架的研究', 'title_zh': 'AutoP2C：一种基于LLM的代理框架，用于从学术论文多模态内容生成代码仓库'}
{'arxiv_id': 'arXiv:2504.20114', 'title': 'TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering', 'authors': 'Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu', 'link': 'https://arxiv.org/abs/2504.20114', 'abstract': 'Retrieval-augmented generation (RAG) systems face significant challenges in multi-hop question answering (MHQA), where complex queries require synthesizing information across multiple document chunks. Existing approaches typically rely on iterative LLM-based query rewriting and routing, resulting in high computational costs due to repeated LLM invocations and multi-stage processes. To address these limitations, we propose TreeHop, an embedding-level framework without the need for LLMs in query refinement. TreeHop dynamically updates query embeddings by fusing semantic information from prior queries and retrieved documents, enabling iterative retrieval through embedding-space operations alone. This method replaces the traditional "Retrieve-Rewrite-Vectorize-Retrieve" cycle with a streamlined "Retrieve-Embed-Retrieve" loop, significantly reducing computational overhead. Moreover, a rule-based stop criterion is introduced to further prune redundant retrievals, balancing efficiency and recall rate. Experimental results show that TreeHop rivals advanced RAG methods across three open-domain MHQA datasets, achieving comparable performance with only 5\\%-0.4\\% of the model parameter size and reducing the query latency by approximately 99\\% compared to concurrent approaches. This makes TreeHop a faster and more cost-effective solution for deployment in a range of knowledge-intensive applications. For reproducibility purposes, codes and data are available here: this https URL.', 'abstract_zh': 'TreeHop：一种无LLM查询精炼的嵌入级框架', 'title_zh': 'TreeHop: 有效生成和过滤多跳查询嵌入'}
{'arxiv_id': 'arXiv:2504.20112', 'title': 'Supervised Pretraining for Material Property Prediction', 'authors': 'Chowdhury Mohammad Abid Rahman, Aldo H. Romero, Prashnna K. Gyawali', 'link': 'https://arxiv.org/abs/2504.20112', 'abstract': 'Accurate prediction of material properties facilitates the discovery of novel materials with tailored functionalities. Deep learning models have recently shown superior accuracy and flexibility in capturing structure-property relationships. However, these models often rely on supervised learning, which requires large, well-annotated datasets an expensive and time-consuming process. Self-supervised learning (SSL) offers a promising alternative by pretraining on large, unlabeled datasets to develop foundation models that can be fine-tuned for material property prediction. In this work, we propose supervised pretraining, where available class information serves as surrogate labels to guide learning, even when downstream tasks involve unrelated material properties. We evaluate this strategy on two state-of-the-art SSL models and introduce a novel framework for supervised pretraining. To further enhance representation learning, we propose a graph-based augmentation technique that injects noise to improve robustness without structurally deforming material graphs. The resulting foundation models are fine-tuned for six challenging material property predictions, achieving significant performance gains over baselines, ranging from 2% to 6.67% improvement in mean absolute error (MAE) and establishing a new benchmark in material property prediction. This study represents the first exploration of supervised pertaining with surrogate labels in material property prediction, advancing methodology and application in the field.', 'abstract_zh': '准确预测材料性质有助于发现具有定制功能的新型材料。深度学习模型在捕捉结构-性质关系方面显示出卓越的准确性和灵活性。然而，这些模型往往依赖于监督学习，需要大量标记良好的数据集，这是一个昂贵且耗时的过程。自我监督学习（SSL）通过在大规模未标记数据集上进行预训练来开发基础模型，这些基础模型可以针对材料性质预测进行微调。在本文中，我们提出了一种监督预训练方法，其中可用的类别信息作为代理标签来指导学习，即使下游任务涉及不相关的材料性质也是如此。我们评估了这一策略在两种最先进的SSL模型上的表现，并引入了一种新的监督预训练框架。为进一步增强表示学习，我们提出了一种基于图的扩增技术，通过注入噪声来提高鲁棒性而不对材料图进行结构变形。所得基础模型针对六种具有挑战性的材料性质预测任务进行了微调，与基线相比取得了显著的性能提升，均方误差（MAE）改善幅度从2%到6.67%，并在材料性质预测中建立了新的基准。这项研究是首次在材料性质预测中探索使用代理标签的监督预训练，推动了该领域的研究方法和应用。', 'title_zh': '监督预训练材料性质预测'}
{'arxiv_id': 'arXiv:2504.20106', 'title': 'Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors', 'authors': 'Ren-Wei Liang, Chin-Ting Hsu, Chan-Hung Yu, Saransh Agrawal, Shih-Cheng Huang, Shang-Tse Chen, Kuan-Hao Huang, Shao-Hua Sun', 'link': 'https://arxiv.org/abs/2504.20106', 'abstract': 'Ensuring that large language models (LLMs) are both helpful and harmless is a critical challenge, as overly strict constraints can lead to excessive refusals, while permissive models risk generating harmful content. Existing approaches, such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO), attempt to balance these trade-offs but suffer from performance conflicts, limited controllability, and poor extendability. To address these issues, we propose Preference Vector, a novel framework inspired by task arithmetic. Instead of optimizing multiple preferences within a single objective, we train separate models on individual preferences, extract behavior shifts as preference vectors, and dynamically merge them at test time. This modular approach enables fine-grained, user-controllable preference adjustments and facilitates seamless integration of new preferences without retraining. Experiments show that our proposed Preference Vector framework improves helpfulness without excessive conservatism, allows smooth control over preference trade-offs, and supports scalable multi-preference alignment.', 'abstract_zh': '确保大型语言模型（LLMs）既有益又无害是一项关键挑战，过于严格的约束可能导致过度拒绝，而宽容的模型则存在生成有害内容的风险。现有的方法，如基于人类反馈的强化学习（RLHF）和直接偏好优化（DPO），试图在这两者之间寻求平衡，但会遇到性能冲突、有限可控性和扩展性差的问题。为了解决这些问题，我们提出了一种名为偏好向量的新型框架，该框架受到任务算术的启发。我们不是在一个单一的目标中优化多个偏好，而是分别在个体偏好上训练独立的模型，提取行为变化作为偏好向量，并在测试时动态合并它们。这种模块化方法允许精细的、用户可控的偏好调整，并能无缝地集成新的偏好而无需重新训练。实验结果显示，我们提出的偏好向量框架能够提高有益性而不显过分保守，允许平滑地控制偏好权衡，并支持可扩展的多偏好对齐。', 'title_zh': '自适应有益无害对齐与偏好向量'}
{'arxiv_id': 'arXiv:2504.20105', 'title': 'Electricity Cost Minimization for Multi-Workflow Allocation in Geo-Distributed Data Centers', 'authors': 'Shuang Wang, He Zhang, Tianxing Wu, Yueyou Zhang, Wei Emma Zhang, Quan Z. Sheng', 'link': 'https://arxiv.org/abs/2504.20105', 'abstract': 'Worldwide, Geo-distributed Data Centers (GDCs) provide computing and storage services for massive workflow applications, resulting in high electricity costs that vary depending on geographical locations and time. How to reduce electricity costs while satisfying the deadline constraints of workflow applications is important in GDCs, which is determined by the execution time of servers, power, and electricity price. Determining the completion time of workflows with different server frequencies can be challenging, especially in scenarios with heterogeneous computing resources in GDCs. Moreover, the electricity price is also different in geographical locations and may change dynamically. To address these challenges, we develop a geo-distributed system architecture and propose an Electricity Cost aware Multiple Workflows Scheduling algorithm (ECMWS) for servers of GDCs with fixed frequency and power. ECMWS comprises four stages, namely workflow sequencing, deadline partitioning, task sequencing, and resource allocation where two graph embedding models and a policy network are constructed to solve the Markov Decision Process (MDP). After statistically calibrating parameters and algorithm components over a comprehensive set of workflow instances, the proposed algorithms are compared with the state-of-the-art methods over two types of workflow instances. The experimental results demonstrate that our proposed algorithm significantly outperforms other algorithms, achieving an improvement of over 15\\% while maintaining an acceptable computational time. The source codes are available at this https URL.', 'abstract_zh': '全球范围内的地理位置分布式数据中心（GDCs）为大规模工作流应用提供计算和存储服务，导致电费成本高昂，且成本因地理位置和时间而异。如何在满足工作流应用截止时间约束的前提下降低电费成本是GDCs中的关键问题，这取决于服务器的执行时间、电力消耗和电价。在GDCs中拥有不同服务器频率的情况下确定工作流的完成时间具有挑战性，特别是在异构计算资源的场景中。此外，电费价格在不同地理位置也有所不同，并且可能会动态变化。为应对这些挑战，我们开发了一种地理位置分布式的系统架构，并提出了一种面向固定频率和功率的GDCs的电费成本感知多工作流调度算法（ECMWS）。ECMWS包含四个阶段，即工作流排序、截止时间分割、任务排序和资源分配，其中构建了两种图嵌入模型和一个策略网络来解决马尔科夫决策过程（MDP）。经过对大量工作流实例进行统计校准参数和算法组件后，我们将所提出的方法与前沿方法在两种类型的工作流实例上进行了比较。实验结果表明，所提出的方法显著优于其他方法，取得了超过15%的改进，同时保持了可接受的计算时间。源代码可在以下链接获取。', 'title_zh': '地理位置分布的数据中心中多工作流分配的电成本最小化'}
{'arxiv_id': 'arXiv:2504.20103', 'title': 'Heterogeneous network drug-target interaction prediction model based on graph wavelet transform and multi-level contrastive learning', 'authors': 'Wenfeng Dai, Yanhong Wang, Shuai Yan, Qingzhi Yu, Xiang Cheng', 'link': 'https://arxiv.org/abs/2504.20103', 'abstract': 'Drug-target interaction (DTI) prediction is a core task in drug development and precision medicine in the biomedical field. However, traditional machine learning methods generally have the black box problem, which makes it difficult to reveal the deep correlation between the model decision mechanism and the interaction pattern between biological molecules. This study proposes a heterogeneous network drug target interaction prediction framework, integrating graph neural network and multi scale signal processing technology to construct a model with both efficient prediction and multi level interpretability. Its technical breakthroughs are mainly reflected in the following three dimensions:Local global feature collaborative perception module. Based on heterogeneous graph convolutional neural network (HGCN), a multi order neighbor aggregation strategy is this http URL scale graph signal decomposition and biological interpretation module. A deep hierarchical node feature transform (GWT) architecture is this http URL learning combining multi dimensional perspectives and hierarchical representations. By comparing the learning models, the node representations from the two perspectives of HGCN and GWT are aligned and fused, so that the model can integrate multi dimensional information and improve the prediction robustness. Experimental results show that our framework shows excellent prediction performance on all datasets. This study provides a complete solution for drug target discovery from black box prediction to mechanism decoding, and its methodology has important reference value for modeling complex biomolecular interaction systems.', 'abstract_zh': '药物靶点交互预测中的异质网络框架：融合图神经网络和多尺度信号处理技术', 'title_zh': '基于图小波变换和多级对比学习的异质网络药物-靶点相互作用预测模型'}
{'arxiv_id': 'arXiv:2504.20102', 'title': 'HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction', 'authors': 'Qingzhi Yu, Shuai Yan, Wenfeng Dai, Xiang Cheng', 'link': 'https://arxiv.org/abs/2504.20102', 'abstract': 'Protein-protein interactions (PPIs) are fundamental for deciphering cellular functions,disease pathways,and drug this http URL existing neural networks and machine learning methods have achieved high accuracy in PPI prediction,their black-box nature leads to a lack of causal interpretation of the prediction results and difficulty in capturing hierarchical geometries and multi-scale dynamic interaction patterns among this http URL address these challenges, we propose HyboWaveNet,a novel deep learning framework that collaborates with hyperbolic graphical neural networks (HGNNs) and multiscale graphical wavelet transform for robust PPI prediction. Mapping protein features to Lorentz space simulates hierarchical topological relationships among biomolecules via a hyperbolic distance metric,enabling node feature representations that better fit biological a this http URL inherently simulates hierarchical and scale-free biological relationships, while the integration of wavelet transforms enables adaptive extraction of local and global interaction features across different resolutions. Our framework generates node feature representations via a graph neural network under the Lorenz model and generates pairs of positive samples under multiple different views for comparative learning, followed by further feature extraction via multi-scale graph wavelet transforms to predict potential PPIs. Experiments on public datasets show that HyboWaveNet improves over both existing state-of-the-art methods. We also demonstrate through ablation experimental studies that the multi-scale graph wavelet transform module improves the predictive performance and generalization ability of HyboWaveNet. This work links geometric deep learning and signal processing to advance PPI prediction, providing a principled approach for analyzing complex biological systems', 'abstract_zh': '蛋白质-蛋白质相互作用（PPIs）对于解析细胞功能、疾病途径和药物作用机制至关重要。现有神经网络和机器学习方法在PPI预测中已经取得了高精度，但其黑盒性质导致预测结果缺乏因果解释，难以捕捉多层次几何结构和多尺度动态相互作用模式。为解决这些挑战，我们提出了一种名为HyboWaveNet的新颖深度学习框架，该框架结合了双曲图形神经网络（HGNNs）和多尺度图形小波变换，以实现稳健的PPI预测。将蛋白质特征映射到洛伦兹空间，通过双曲距离度量模拟生物分子之间的层次拓扑关系，使节点特征表示更符合生物学特征。双曲空间本身模拟了层次和无标度的生物学关系，而小波变换的集成使框架能够适配地提取不同分辨率下的局部和全局相互作用特征。框架通过洛伦兹模型下的图形神经网络生成节点特征表示，并在多种不同视图下生成正样本对用于对比学习，随后通过多尺度图形小波变换进行进一步特征提取以预测潜在的PPIs。在公共数据集上的实验表明，HyboWaveNet优于现有的最先进的方法。通过消融实验研究还证明，多尺度图形小波变换模块提高了HyboWaveNet的预测性能和泛化能力。这项工作将几何深度学习与信号处理相结合，推动了PPI预测的发展，提供了一种分析复杂生物系统的原则性方法。', 'title_zh': 'HyboWaveNet：基于多尺度小波变换的双曲图神经网络在蛋白质-蛋白质相互作用预测中的应用'}
{'arxiv_id': 'arXiv:2504.20101', 'title': 'GenTorrent: Scaling Large Language Model Serving with An Overley Network', 'authors': 'Fei Fang, Yifan Hua, Shengze Wang, Ruilin Zhou, Yi Liu, Chen Qian, Xiaoxue Zhang', 'link': 'https://arxiv.org/abs/2504.20101', 'abstract': 'While significant progress has been made in research and development on open-source and cost-efficient large-language models (LLMs), serving scalability remains a critical challenge, particularly for small organizations and individuals seeking to deploy and test their LLM innovations. Inspired by peer-to-peer networks that leverage decentralized overlay nodes to increase throughput and availability, we propose GenTorrent, an LLM serving overlay that harnesses computing resources from decentralized contributors. We identify four key research problems inherent to enabling such a decentralized infrastructure: 1) overlay network organization; 2) LLM communication privacy; 3) overlay forwarding for resource efficiency; and 4) verification of serving quality. This work presents the first systematic study of these fundamental problems in the context of decentralized LLM serving. Evaluation results from a prototype implemented on a set of decentralized nodes demonstrate that GenTorrent achieves a latency reduction of over 50% compared to the baseline design without overlay forwarding. Furthermore, the security features introduce minimal overhead to serving latency and throughput. We believe this work pioneers a new direction for democratizing and scaling future AI serving capabilities.', 'abstract_zh': '开源和低成本大型语言模型（LLMs）的研究与开发取得了显著进展，但服务扩展性仍然是一个关键挑战，特别是在小型组织和个人希望部署和测试其LLM创新方面。受去中心化-overlay节点提高吞吐量和可获取性的点对点网络启发，我们提出GenTorrent，一种利用分散贡献者计算资源的LLM服务overlay。我们识别出四个内在的关键研究问题，以支持这种去中心化基础设施：1）overlay网络组织；2）LLM通信隐私；3）overlay转发以提高资源效率；4）提供服务质量的验证。本研究首次在去中心化LLM服务背景下系统地探讨了这些基础性问题。在一组去中心化节点上实现的原型评估结果表明，与不使用overlay转发的基础设计相比，GenTorrent实现了超过50%的延迟减少。此外，安全功能对服务延迟和吞吐量的影响最小。我们认为，本项工作开创了普及和扩展未来AI服务能力的新方向。', 'title_zh': 'GenTorrent: 通过Overlay网络扩展大型语言模型服务'}
{'arxiv_id': 'arXiv:2504.20099', 'title': 'Decoding Latent Spaces: Assessing the Interpretability of Time Series Foundation Models for Visual Analytics', 'authors': 'Inmaculada Santamaria-Valenzuela, Victor Rodriguez-Fernandez, Javier Huertas-Tato, Jong Hyuk Park, David Camacho', 'link': 'https://arxiv.org/abs/2504.20099', 'abstract': 'The present study explores the interpretability of latent spaces produced by time series foundation models, focusing on their potential for visual analysis tasks. Specifically, we evaluate the MOMENT family of models, a set of transformer-based, pre-trained architectures for multivariate time series tasks such as: imputation, prediction, classification, and anomaly detection. We evaluate the capacity of these models on five datasets to capture the underlying structures in time series data within their latent space projection and validate whether fine tuning improves the clarity of the resulting embedding spaces. Notable performance improvements in terms of loss reduction were observed after fine tuning. Visual analysis shows limited improvement in the interpretability of the embeddings, requiring further work. Results suggest that, although Time Series Foundation Models such as MOMENT are robust, their latent spaces may require additional methodological refinements to be adequately interpreted, such as alternative projection techniques, loss functions, or data preprocessing strategies. Despite the limitations of MOMENT, foundation models supose a big reduction in execution time and so a great advance for interactive visual analytics.', 'abstract_zh': '本研究探讨了时间序列基础模型生成的潜在空间的可解释性，着重于其在视觉分析任务中的应用潜力。具体而言，我们评估了MOMENT模型家族，这是一种基于变换器的预训练架构，适用于多变量时间序列任务，如插值、预测、分类和异常检测。我们在这五个数据集中评估了这些模型在潜在空间投影中捕获时间序列数据的潜在结构的能力，并验证了微调是否能改善最终嵌入空间的清晰度。微调后观察到损失减小的显著性能提升。视觉分析显示嵌入的可解释性改进有限，需要进一步研究。结果表明，尽管如MOMENT的时间序列基础模型具有鲁棒性，但其潜在空间可能需要额外的方法学改进以充分解释，例如替代投影技术、损失函数或数据预处理策略。尽管MOMENT存在局限性，但基础模型仍假定了执行时间的大规模减少，这是交互式视觉分析的一大进步。', 'title_zh': '解码潜在空间：时间序列基础模型在可视化分析中的可解释性评估'}
{'arxiv_id': 'arXiv:2504.20093', 'title': 'Self-Healing Software Systems: Lessons from Nature, Powered by AI', 'authors': 'Mohammad Baqar, Rajat Khanda, Saba Naqvi', 'link': 'https://arxiv.org/abs/2504.20093', 'abstract': 'As modern software systems grow in complexity and scale, their ability to autonomously detect, diagnose, and recover from failures becomes increasingly vital. Drawing inspiration from biological healing - where the human body detects damage, signals the brain, and activates targeted recovery - this paper explores the concept of self-healing software driven by artificial intelligence. We propose a novel framework that mimics this biological model system observability tools serve as sensory inputs, AI models function as the cognitive core for diagnosis and repair, and healing agents apply targeted code and test modifications. By combining log analysis, static code inspection, and AI-driven generation of patches or test updates, our approach aims to reduce downtime, accelerate debugging, and enhance software resilience. We evaluate the effectiveness of this model through case studies and simulations, comparing it against traditional manual debugging and recovery workflows. This work paves the way toward intelligent, adaptive and self-reliant software systems capable of continuous healing, akin to living organisms.', 'abstract_zh': '随着现代软件系统在复杂性和规模上的增长，其自主检测、诊断和恢复故障的能力变得日益重要。受到生物体修复机制的启发——人体检测损伤、信号传递至大脑，并启动针对性的恢复——本论文探讨由人工智能驱动的自愈软件概念。我们提出了一种新的框架，模仿这种生物模型： observability 工具作为感测输入，AI 模型作为诊断和修复的认知核心，自愈剂应用针对性的代码和测试修改。通过结合日志分析、静态代码检查和AI驱动的补丁或测试更新生成，我们的方法旨在减少停机时间、加速调试并增强软件韧性。通过案例研究和仿真评估该模型的有效性，将其与传统的手动调试和恢复工作流程进行对比。本研究为智能、适应性和自我依赖的软件系统铺平了道路，这些系统能够实现连续的自愈，类似于生物体的自我修复能力。', 'title_zh': '自愈软件系统：来自自然界的经验，驱动于人工智能'}
{'arxiv_id': 'arXiv:2504.20092', 'title': 'An Integrated Framework for Contextual Personalized LLM-Based Food Recommendation', 'authors': 'Ali Rostami', 'link': 'https://arxiv.org/abs/2504.20092', 'abstract': "Personalized food recommendation systems (Food-RecSys) critically underperform due to fragmented component understanding and the failure of conventional machine learning with vast, imbalanced food data. While Large Language Models (LLMs) offer promise, current generic Recommendation as Language Processing (RLP) strategies lack the necessary specialization for the food domain's complexity. This thesis tackles these deficiencies by first identifying and analyzing the essential components for effective Food-RecSys. We introduce two key innovations: a multimedia food logging platform for rich contextual data acquisition and the World Food Atlas, enabling unique geolocation-based food analysis previously unavailable. Building on this foundation, we pioneer the Food Recommendation as Language Processing (F-RLP) framework - a novel, integrated approach specifically architected for the food domain. F-RLP leverages LLMs in a tailored manner, overcoming the limitations of generic models and providing a robust infrastructure for effective, contextual, and truly personalized food recommendations.", 'abstract_zh': '个性化食品推荐系统（Food-RecSys）由于组件理解碎片化以及传统机器学习在海量不平衡食品数据中的失败而表现不佳。尽管大型语言模型（LLMs）展现出潜力，但当前通用的推荐即语言处理（RLP）策略缺乏针对食品领域复杂性的必要专业化。本论文通过首先识别并分析有效Food-RecSys的核心组件来进行弥补。我们引入了两项创新：一个多媒体食品记录平台以获取丰富上下文数据以及世界食品地图，这使得基于地理位置的食品分析成为可能。在此基础上，我们开创了食品推荐即语言处理（F-RLP）框架——一种专为食品领域设计的创新性综合方法。F-RLP 专门利用 LLMs，克服了通用模型的局限性，并为有效、上下文相关且真正个性化的食品推荐提供了坚实的基础。', 'title_zh': '基于语境的个性化LLM食品推荐集成框架'}
{'arxiv_id': 'arXiv:2504.20086', 'title': 'Understanding and Mitigating Risks of Generative AI in Financial Services', 'authors': 'Sebastian Gehrmann, Claire Huang, Xian Teng, Sergei Yurovski, Iyanuoluwa Shode, Chirag S. Patel, Arjun Bhorkar, Naveen Thomas, John Doucette, David Rosenberg, Mark Dredze, David Rabinowitz', 'link': 'https://arxiv.org/abs/2504.20086', 'abstract': 'To responsibly develop Generative AI (GenAI) products, it is critical to define the scope of acceptable inputs and outputs. What constitutes a "safe" response is an actively debated question. Academic work puts an outsized focus on evaluating models by themselves for general purpose aspects such as toxicity, bias, and fairness, especially in conversational applications being used by a broad audience. In contrast, less focus is put on considering sociotechnical systems in specialized domains. Yet, those specialized systems can be subject to extensive and well-understood legal and regulatory scrutiny. These product-specific considerations need to be set in industry-specific laws, regulations, and corporate governance requirements. In this paper, we aim to highlight AI content safety considerations specific to the financial services domain and outline an associated AI content risk taxonomy. We compare this taxonomy to existing work in this space and discuss implications of risk category violations on various stakeholders. We evaluate how existing open-source technical guardrail solutions cover this taxonomy by assessing them on data collected via red-teaming activities. Our results demonstrate that these guardrails fail to detect most of the content risks we discuss.', 'abstract_zh': '负责任地开发生成式人工智能（GenAI）产品需明确可接受的输入和输出范围。什么是“安全”的响应是一个备受争议的问题。学术研究过度关注通过评估模型自身的普适性方面（如毒性、偏见和公平性）来评价模型，尤其是在广泛受众使用的对话式应用中。相比之下，较少关注这些模型在专业化领域的社会技术系统层面的考量。然而，这些专业化系统可能会受到广泛的、深入了解的法律和监管审查。这些产品特定的考量需要在特定行业的法律、法规和公司治理要求中体现。在本文中，我们旨在强调金融服务业领域的AI内容安全考量，并概述相关的AI内容风险分类学。我们将这种分类学与现有研究进行比较，并讨论风险类别违规对各利益相关方的影响。我们通过红队活动收集的数据评估现有开源技术护栏解决方案对这一分类学的覆盖情况。我们的结果显示，这些护栏无法检测到我们讨论的大多数内容风险。', 'title_zh': '理解与减轻金融服务业生成式AI风险'}
{'arxiv_id': 'arXiv:2504.20083', 'title': 'A model and package for German ColBERT', 'authors': 'Thuong Dang, Qiqi Chen', 'link': 'https://arxiv.org/abs/2504.20083', 'abstract': 'In this work, we introduce a German version for ColBERT, a late interaction multi-dense vector retrieval method, with a focus on RAG applications. We also present the main features of our package for ColBERT models, supporting both retrieval and fine-tuning workflows.', 'abstract_zh': '在本工作中，我们引入了ColBERT的一种德语版本，这是一种晚交互多密集向量检索方法，重点关注RAG应用。我们还介绍了我们的ColBERT模型包的主要功能，支持检索和微调工作流程。', 'title_zh': 'German ColBERT模型与包'}
{'arxiv_id': 'arXiv:2504.20080', 'title': 'DNAD: Differentiable Neural Architecture Distillation', 'authors': 'Xuan Rao, Bo Zhao, Derong Liu', 'link': 'https://arxiv.org/abs/2504.20080', 'abstract': 'To meet the demand for designing efficient neural networks with appropriate trade-offs between model performance (e.g., classification accuracy) and computational complexity, the differentiable neural architecture distillation (DNAD) algorithm is developed based on two cores, namely search by deleting and search by imitating. Primarily, to derive neural architectures in a space where cells of the same type no longer share the same topology, the super-network progressive shrinking (SNPS) algorithm is developed based on the framework of differentiable architecture search (DARTS), i.e., search by deleting. Unlike conventional DARTS-based approaches which yield neural architectures with simple structures and derive only one architecture during the search procedure, SNPS is able to derive a Pareto-optimal set of architectures with flexible structures by forcing the dynamic super-network shrink from a dense structure to a sparse one progressively. Furthermore, since knowledge distillation (KD) has shown great effectiveness to train a compact network with the assistance of an over-parameterized model, we integrate SNPS with KD to formulate the DNAD algorithm, i.e., search by imitating. By minimizing behavioral differences between the super-network and teacher network, the over-fitting of one-level DARTS is avoided and well-performed neural architectures are derived. Experiments on CIFAR-10 and ImageNet classification tasks demonstrate that both SNPS and DNAD are able to derive a set of architectures which achieve similar or lower error rates with fewer parameters and FLOPs. Particularly, DNAD achieves the top-1 error rate of 23.7% on ImageNet classification with a model of 6.0M parameters and 598M FLOPs, which outperforms most DARTS-based methods.', 'abstract_zh': '基于搜索删除和模仿搜索的可微神经架构蒸馏算法', 'title_zh': 'DNAD: 可微神经架构蒸馏'}
{'arxiv_id': 'arXiv:2504.20079', 'title': 'FX-DARTS: Designing Topology-unconstrained Architectures with Differentiable Architecture Search and Entropy-based Super-network Shrinking', 'authors': 'Xuan Rao, Bo Zhao, Derong Liu, Cesare Alippi', 'link': 'https://arxiv.org/abs/2504.20079', 'abstract': 'Strong priors are imposed on the search space of Differentiable Architecture Search (DARTS), such that cells of the same type share the same topological structure and each intermediate node retains two operators from distinct nodes. While these priors reduce optimization difficulties and improve the applicability of searched architectures, they hinder the subsequent development of automated machine learning (Auto-ML) and prevent the optimization algorithm from exploring more powerful neural networks through improved architectural flexibility. This paper aims to reduce these prior constraints by eliminating restrictions on cell topology and modifying the discretization mechanism for super-networks. Specifically, the Flexible DARTS (FX-DARTS) method, which leverages an Entropy-based Super-Network Shrinking (ESS) framework, is presented to address the challenges arising from the elimination of prior constraints. Notably, FX-DARTS enables the derivation of neural architectures without strict prior rules while maintaining the stability in the enlarged search space. Experimental results on image classification benchmarks demonstrate that FX-DARTS is capable of exploring a set of neural architectures with competitive trade-offs between performance and computational complexity within a single search procedure.', 'abstract_zh': '基于熵导向超网络收缩的灵活架构搜索（FX-DARTS）', 'title_zh': 'FX-DARTS：基于可微架构搜索和熵为基础的超级网络收缩设计拓扑约束架构'}
{'arxiv_id': 'arXiv:2504.20077', 'title': 'Edge-Based Learning for Improved Classification Under Adversarial Noise', 'authors': 'Manish Kansana, Keyan Alexander Rahimi, Elias Hossain, Iman Dehzangi, Noorbakhsh Amiri Golilarz', 'link': 'https://arxiv.org/abs/2504.20077', 'abstract': 'Adversarial noise introduces small perturbations in images, misleading deep learning models into misclassification and significantly impacting recognition accuracy. In this study, we analyzed the effects of Fast Gradient Sign Method (FGSM) adversarial noise on image classification and investigated whether training on specific image features can improve robustness. We hypothesize that while adversarial noise perturbs various regions of an image, edges may remain relatively stable and provide essential structural information for classification. To test this, we conducted a series of experiments using brain tumor and COVID datasets. Initially, we trained the models on clean images and then introduced subtle adversarial perturbations, which caused deep learning models to significantly misclassify the images. Retraining on a combination of clean and noisy images led to improved performance. To evaluate the robustness of the edge features, we extracted edges from the original/clean images and trained the models exclusively on edge-based representations. When noise was introduced to the images, the edge-based models demonstrated greater resilience to adversarial attacks compared to those trained on the original or clean images. These results suggest that while adversarial noise is able to exploit complex non-edge regions significantly more than edges, the improvement in the accuracy after retraining is marginally more in the original data as compared to the edges. Thus, leveraging edge-based learning can improve the resilience of deep learning models against adversarial perturbations.', 'abstract_zh': '对抗噪声通过在图像中引入微小扰动，误导深度学习模型产生误分类，显著影响识别准确性。本研究分析了快速梯度符号方法（FGSM）对抗噪声对图像分类效果的影响，并探讨了特定图像特征训练是否能提高模型的鲁棒性。研究假设，尽管对抗噪声会扰动图像的不同区域，但边缘可能相对稳定，提供重要的结构信息，有助于分类。为验证这一假设，我们使用脑肿瘤和COVID数据集进行了系列实验。首先，我们对干净图像进行模型训练，然后引入细微的对抗扰动，导致深度学习模型显著误分类。重新在干净和噪声图像的组合上进行训练提升了模型性能。为了评估边缘特征的鲁棒性，我们从原始/干净图像中提取边缘，并仅使用基于边缘的表示进行模型训练。当向图像引入噪声时，基于边缘的模型相较于仅在原始或干净图像上进行训练的模型，表现出更强的对抗攻击鲁棒性。这些结果表明，尽管对抗噪声更多地利用了复杂的非边缘区域，但在重新训练后，原始数据的准确率提升略高于边缘区域。因此，利用基于边缘的学习可以提高深度学习模型对抗噪声扰动的鲁棒性。', 'title_zh': '基于边缘的学习以提高对抗噪声下的分类性能'}
{'arxiv_id': 'arXiv:2504.20074', 'title': 'EPSILON: Adaptive Fault Mitigation in Approximate Deep Neural Network using Statistical Signatures', 'authors': 'Khurram Khalil, Khaza Anuarul Hoque', 'link': 'https://arxiv.org/abs/2504.20074', 'abstract': 'The increasing adoption of approximate computing in deep neural network accelerators (AxDNNs) promises significant energy efficiency gains. However, permanent faults in AxDNNs can severely degrade their performance compared to their accurate counterparts (AccDNNs). Traditional fault detection and mitigation approaches, while effective for AccDNNs, introduce substantial overhead and latency, making them impractical for energy-constrained real-time deployment. To address this, we introduce EPSILON, a lightweight framework that leverages pre-computed statistical signatures and layer-wise importance metrics for efficient fault detection and mitigation in AxDNNs. Our framework introduces a novel non-parametric pattern-matching algorithm that enables constant-time fault detection without interrupting normal execution while dynamically adapting to different network architectures and fault patterns. EPSILON maintains model accuracy by intelligently adjusting mitigation strategies based on a statistical analysis of weight distribution and layer criticality while preserving the energy benefits of approximate computing. Extensive evaluations across various approximate multipliers, AxDNN architectures, popular datasets (MNIST, CIFAR-10, CIFAR-100, ImageNet-1k), and fault scenarios demonstrate that EPSILON maintains 80.05\\% accuracy while offering 22\\% improvement in inference time and 28\\% improvement in energy efficiency, establishing EPSILON as a practical solution for deploying reliable AxDNNs in safety-critical edge applications.', 'abstract_zh': '约简计算在深度神经网络加速器（AxDNNs）中的 increasingly 采用促进了显著的能量效率提升。然而，AxDNNs 中的永久性故障会严重降低其性能， compared to 准确的对应版本（AccDNNs）。传统的故障检测与缓解方法虽对 AccDNNs 有效，但在能耗受限的实时部署中引入了显著的开销和延迟，使其 impractical 不切实际。为解决这一问题，我们提出了 EPSILON，一种轻量级框架，利用预计算的统计签名与逐层重要性度量进行高效的 AxDNN 故障检测与缓解。我们的框架引入了一种新颖的非参数模式匹配算法，能够在不中断正常执行的情况下进行恒定时间的故障检测，并能够根据不同网络架构和故障模式动态适配。EPSILON 通过基于权重分布和层关键性的统计分析智能调整缓解策略来保持模型精度，同时保留约简计算的能量效益。跨多种约简乘法器、AxDNN 架构、流行数据集（MNIST、CIFAR-10、CIFAR-100、ImageNet-1k）和故障场景的广泛评估表明，EPSILON 维持了 80.05% 的准确性，提供了 22% 的推理时间改进和 28% 的能量效率改进，确立了 EPSILON 作为在关键边缘应用中部署可靠 AxDNNs 的实际解决方案。', 'title_zh': 'EPSILON: 基于统计特征的自适应容错机制用于近似深度神经网络'}
{'arxiv_id': 'arXiv:2504.20073', 'title': 'RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning', 'authors': 'Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, Eli Gottlieb, Monica Lam, Yiping Lu, Kyunghyun Cho, Jiajun Wu, Li Fei-Fei, Lijuan Wang, Yejin Choi, Manling Li', 'link': 'https://arxiv.org/abs/2504.20073', 'abstract': 'Training large language models (LLMs) as interactive agents presents unique challenges including long-horizon decision making and interacting with stochastic environment feedback. While reinforcement learning (RL) has enabled progress in static tasks, multi-turn agent RL training remains underexplored. We propose StarPO (State-Thinking-Actions-Reward Policy Optimization), a general framework for trajectory-level agent RL, and introduce RAGEN, a modular system for training and evaluating LLM agents. Our study on three stylized environments reveals three core findings. First, our agent RL training shows a recurring mode of Echo Trap where reward variance cliffs and gradient spikes; we address this with StarPO-S, a stabilized variant with trajectory filtering, critic incorporation, and decoupled clipping. Second, we find the shaping of RL rollouts would benefit from diverse initial states, medium interaction granularity and more frequent sampling. Third, we show that without fine-grained, reasoning-aware reward signals, agent reasoning hardly emerge through multi-turn RL and they may show shallow strategies or hallucinated thoughts. Code and environments are available at this https URL.', 'abstract_zh': '训练大规模语言模型（LLMs）作为交互代理面临独特的挑战，包括长期决策制定和与随机环境反馈的交互。虽然强化学习（RL）已在静态任务上取得了进展，但多轮交互代理的RL训练仍处于探索阶段。我们提出了一种适用于轨迹级代理RL的通用框架StarPO（State-Thinking-Actions-Reward Policy Optimization），并介绍了一种模块化系统RAGEN，用于训练和评估LLM代理。我们的三项定制环境研究揭示了三个核心发现。首先，我们的代理RL训练表现出Echo Trap模式，即奖励方差悬崖和梯度尖峰；我们通过引入StarPO-S，一种包含轨迹过滤、批评家集成和解耦修剪的稳定版本来应对这一问题。其次，我们发现强化学习（RL）滚动生成的质量可以从多样化的初始状态、中等交互粒度和更频繁的采样中获益。第三，我们证明，如果没有细粒度的、具有推理意识的奖励信号，代理的推理可能难以通过多轮RL显现，它们可能会表现出肤浅的战略或虚幻的思维。代码和环境可在此链接访问。', 'title_zh': 'RAGEN：通过多轮强化学习理解LLM代理的自我进化'}
{'arxiv_id': 'arXiv:2504.20069', 'title': 'A Simple Review of EEG Foundation Models: Datasets, Advancements and Future Perspectives', 'authors': 'Junhong Lai, Jiyu Wei, Lin Yao, Yueming Wang', 'link': 'https://arxiv.org/abs/2504.20069', 'abstract': 'Electroencephalogram (EEG) signals play a crucial role in understanding brain activity and diagnosing neurological disorders. This review focuses on the recent development of EEG foundation models(EEG-FMs), which have shown great potential in processing and analyzing EEG data. We discuss various EEG-FMs, including their architectures, pre-training strategies, their pre-training and downstream datasets and other details. The review also highlights the challenges and future directions in this field, aiming to provide a comprehensive overview for researchers and practitioners interested in EEG analysis and related EEG-FMs.', 'abstract_zh': '电生理信号（EEG）在理解大脑活动和诊断神经疾病中扮演着重要角色。本文综述了近期发展的EEG基础模型（EEG-FMs）的研究进展，探讨了各种EEG-FMs的架构、预训练策略、预训练和下游数据集及其他细节。同时还指出了该领域的挑战和未来发展方向，旨在为从事EEG分析及相关EEG-FMs研究的学者和实践者提供全面概述。', 'title_zh': 'EEG基础模型的简要 review：数据集、进展和未来展望'}
{'arxiv_id': 'arXiv:2504.20059', 'title': 'Recommending Clinical Trials for Online Patient Cases using Artificial Intelligence', 'authors': 'Joey Chan, Qiao Jin, Nicholas Wan, Charalampos S. Floudas, Elisabetta Xue, Zhiyong Lu', 'link': 'https://arxiv.org/abs/2504.20059', 'abstract': 'Clinical trials are crucial for assessing new treatments; however, recruitment challenges - such as limited awareness, complex eligibility criteria, and referral barriers - hinder their success. With the growth of online platforms, patients increasingly turn to social media and health communities for support, research, and advocacy, expanding recruitment pools and established enrollment pathways. Recognizing this potential, we utilized TrialGPT, a framework that leverages a large language model (LLM) as its backbone, to match 50 online patient cases (collected from published case reports and a social media website) to clinical trials and evaluate performance against traditional keyword-based searches. Our results show that TrialGPT outperforms traditional methods by 46% in identifying eligible trials, with each patient, on average, being eligible for around 7 trials. Additionally, our outreach efforts to case authors and trial organizers regarding these patient-trial matches yielded highly positive feedback, which we present from both perspectives.', 'abstract_zh': '临床试验对于评估新治疗方法至关重要，但有限的意识、复杂的入组标准和转诊障碍等挑战阻碍了其成功。随着在线平台的兴起，患者越来越多地通过社交媒体和健康社区寻求支持、进行研究和倡导，从而扩大了招募人群并建立了现有的入组途径。认识到这一潜力，我们利用了以大型语言模型（LLM）为基础的TrialGPT框架，将50个在线患者案例（来自已发表的案例报告和社交媒体网站）与临床试验匹配，并评估其性能，结果表明TrialGPT在识别符合条件的临床试验方面比传统的关键词搜索方法高出46%，每位患者平均符合条件的临床试验约为7项。此外，我们对案例作者和临床试验组织者关于这些患者-临床试验匹配的接触工作也获得了高度积极的反馈，我们从两个角度进行了呈现。', 'title_zh': '使用人工智能推荐在线患者病例的临床试验'}
{'arxiv_id': 'arXiv:2504.20055', 'title': 'A constraints-based approach to fully interpretable neural networks for detecting learner behaviors', 'authors': 'Juan D. Pinto, Luc Paquette', 'link': 'https://arxiv.org/abs/2504.20055', 'abstract': "The increasing use of complex machine learning models in education has led to concerns about their interpretability, which in turn has spurred interest in developing explainability techniques that are both faithful to the model's inner workings and intelligible to human end-users. In this paper, we describe a novel approach to creating a neural-network-based behavior detection model that is interpretable by design. Our model is fully interpretable, meaning that the parameters we extract for our explanations have a clear interpretation, fully capture the model's learned knowledge about the learner behavior of interest, and can be used to create explanations that are both faithful and intelligible. We achieve this by implementing a series of constraints to the model that both simplify its inference process and bring it closer to a human conception of the task at hand. We train the model to detect gaming-the-system behavior, evaluate its performance on this task, and compare its learned patterns to those identified by human experts. Our results show that the model is successfully able to learn patterns indicative of gaming-the-system behavior while providing evidence for fully interpretable explanations. We discuss the implications of our approach and suggest ways to evaluate explainability using a human-grounded approach.", 'abstract_zh': '教育中复杂机器学习模型应用增加导致可解释性问题的关注，从而促进了忠实于模型内部工作原理且易于人类最终用户理解的可解释性技术的发展。本文描述了一种设计上具备可解释性的基于神经网络的行为检测模型的新方法。该模型完全可解释，即我们提取的用于解释的参数具有清晰的含义，完全捕捉了模型关于所感兴趣的学习者行为的已学习知识，并可用于创建忠实且易于理解的解释。我们通过实施一系列约束来简化模型的推断过程，并使其更接近人类对任务的认知。我们训练模型以检测游戏系统行为，评估其在该任务上的表现，并将其学到的模式与人类专家识别的模式进行比较。我们的结果表明，模型能够成功学习指示游戏系统行为的模式，同时提供完全可解释的证据。我们讨论了该方法的意义，并建议使用基于人类的方法评估可解释性。', 'title_zh': '基于约束的方法构建完全可解释的神经网络以检测学习者行为'}
{'arxiv_id': 'arXiv:2504.20047', 'title': 'HCT-QA: A Benchmark for Question Answering on Human-Centric Tables', 'authors': 'Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan', 'link': 'https://arxiv.org/abs/2504.20047', 'abstract': 'Tabular data embedded within PDF files, web pages, and other document formats are prevalent across numerous sectors such as government, engineering, science, and business. These human-centric tables (HCTs) possess a unique combination of high business value, intricate layouts, limited operational power at scale, and sometimes serve as the only data source for critical insights. However, their complexity poses significant challenges to traditional data extraction, processing, and querying methods. While current solutions focus on transforming these tables into relational formats for SQL queries, they fall short in handling the diverse and complex layouts of HCTs and hence being amenable to querying. This paper describes HCT-QA, an extensive benchmark of HCTs, natural language queries, and related answers on thousands of tables. Our dataset includes 2,188 real-world HCTs with 9,835 QA pairs and 4,679 synthetic tables with 67.5K QA pairs. While HCTs can be potentially processed by different type of query engines, in this paper, we focus on Large Language Models as potential engines and assess their ability in processing and querying such tables.', 'abstract_zh': '嵌入在PDF文件、网页及其他文档格式中的表格数据在政府、工程、科学和商业等多个领域内广泛存在。这些以人类为中心的表格（HCTs）具有高商业价值、复杂的布局、有限的大规模操作能力和有时作为关键洞察唯一数据源的特点。然而，其复杂性给传统的数据提取、处理和查询方法带来了重大挑战。虽然现有解决方案致力于将这些表格转换为关系格式以供SQL查询，但它们在处理HCTs的多样性和复杂性方面仍然存在不足。因此，这些表格难以被查询。本文描述了HCT-QA，一个包含数千个表格的全面基准，包括自然语言查询及其相关答案，并涉及2,188个真实世界的HCTs和9,835个问答对，以及4,679个合成表格和67,500个问答对。虽然HCTs可以由不同类型的查询引擎处理，在本论文中，我们重点探讨大型语言模型作为潜在引擎的能力，评估其在处理和查询此类表格方面的表现。', 'title_zh': 'HCT-QA：以人为本表格上的问答基准'}
