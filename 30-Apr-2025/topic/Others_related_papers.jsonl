{'arxiv_id': 'arXiv:2504.20863', 'title': 'Bayesian Optimization-based Tire Parameter and Uncertainty Estimation for Real-World Data', 'authors': 'Sven Goblirsch, Benedikt Ruhland, Johannes Betz, Markus Lienkamp', 'link': 'https://arxiv.org/abs/2504.20863', 'abstract': "This work presents a methodology to estimate tire parameters and their uncertainty using a Bayesian optimization approach. The literature mainly considers the estimation of tire parameters but lacks an evaluation of the parameter identification quality and the required slip ratios for an adequate model fit. Therefore, we examine the use of Stochastical Variational Inference as a methodology to estimate both - the parameters and their uncertainties. We evaluate the method compared to a state-of-the-art Nelder-Mead algorithm for theoretical and real-world application. The theoretical study considers parameter fitting at different slip ratios to evaluate the required excitation for an adequate fitting of each parameter. The results are compared to a sensitivity analysis for a Pacejka Magic Formula tire model. We show the application of the algorithm on real-world data acquired during the Abu Dhabi Autonomous Racing League and highlight the uncertainties in identifying the curvature and shape parameters due to insufficient excitation. The gathered insights can help assess the acquired data's limitations and instead utilize standardized parameters until higher slip ratios are captured. We show that our proposed method can be used to assess the mean values and the uncertainties of tire model parameters in real-world conditions and derive actions for the tire modeling based on our simulative study.", 'abstract_zh': '本研究提出了一种使用贝叶斯优化方法估计轮胎参数及其不确定性的方法。文献中主要考虑了轮胎参数的估计，但缺乏对参数识别质量的评估以及适应模型所需的适当滑移比。因此，我们探讨了使用随机变分推断作为同时估计参数及其不确定性的方法。我们将该方法与当前最先进的Nelder-Mead算法进行了比较，用于理论和实际应用场景。理论研究考虑了在不同滑移比下的参数拟合，以评估每个参数适当地拟合所需的激励。结果与Pacejka魔术公式轮胎模型的敏感性分析进行了比较。我们展示了该算法在阿布扎比自主赛车联赛获取的真实数据中的应用，并突出了因激励不足而难以识别曲率和形状参数的不确定性。所得见解有助于评估所获取数据的局限性，并在此基础上使用标准化参数直到捕捉到更高的滑移比。我们证明了本方法可以在实际条件下评估轮胎模型参数的均值和不确定，并根据模拟研究推导出轮胎建模的行动方案。', 'title_zh': '基于贝叶斯优化的轮胎参数及不确定性估计方法研究'}
{'arxiv_id': 'arXiv:2504.20380', 'title': 'LPVIMO-SAM: Tightly-coupled LiDAR/Polarization Vision/Inertial/Magnetometer/Optical Flow Odometry via Smoothing and Mapping', 'authors': 'Derui Shan, Peng Guo, Wenshuo Li, Du Tao', 'link': 'https://arxiv.org/abs/2504.20380', 'abstract': 'We propose a tightly-coupled LiDAR/Polarization Vision/Inertial/Magnetometer/Optical Flow Odometry via Smoothing and Mapping (LPVIMO-SAM) framework, which integrates LiDAR, polarization vision, inertial measurement unit, magnetometer, and optical flow in a tightly-coupled fusion. This framework enables high-precision and highly robust real-time state estimation and map construction in challenging environments, such as LiDAR-degraded, low-texture regions, and feature-scarce areas. The LPVIMO-SAM comprises two subsystems: a Polarized Vision-Inertial System and a LiDAR/Inertial/Magnetometer/Optical Flow System. The polarized vision enhances the robustness of the Visual/Inertial odometry in low-feature and low-texture scenarios by extracting the polarization information of the scene. The magnetometer acquires the heading angle, and the optical flow obtains the speed and height to reduce the accumulated error. A magnetometer heading prior factor, an optical flow speed observation factor, and a height observation factor are designed to eliminate the cumulative errors of the LiDAR/Inertial odometry through factor graph optimization. Meanwhile, the LPVIMO-SAM can maintain stable positioning even when one of the two subsystems fails, further expanding its applicability in LiDAR-degraded, low-texture, and low-feature environments. Code is available on this https URL.', 'abstract_zh': '基于平滑与制图的紧耦合LiDAR/偏振视觉/惯性/磁强计/光流里程计(LPVIMO-SAM)框架', 'title_zh': 'LPVIMO-SAM: 结合平滑与制图的紧耦合激光雷达/偏振视觉/惯性/磁计/光学流bundle调整与建图算法'}
{'arxiv_id': 'arXiv:2504.20391', 'title': 'The Mean of Multi-Object Trajectories', 'authors': 'Tran Thien Dat Nguyen, Ba Tuong Vo, Ba-Ngu Vo, Hoa Van Nguyen, Changbeom Shim', 'link': 'https://arxiv.org/abs/2504.20391', 'abstract': 'This paper introduces the concept of a mean for trajectories and multi-object trajectories--sets or multi-sets of trajectories--along with algorithms for computing them. Specifically, we use the Fréchet mean, and metrics based on the optimal sub-pattern assignment (OSPA) construct, to extend the notion of average from vectors to trajectories and multi-object trajectories. Further, we develop efficient algorithms to compute these means using greedy search and Gibbs sampling. Using distributed multi-object tracking as an application, we demonstrate that the Fréchet mean approach to multi-object trajectory consensus significantly outperforms state-of-the-art distributed multi-object tracking methods.', 'abstract_zh': '本文介绍了轨迹及多对象轨迹——集合或多重集合的均值概念，并提出了计算这些均值的算法。具体而言，我们使用Fréchet均值和基于最优子模式分配（OSPA）构造的距离度量，将平均的概念从向量扩展到轨迹及多对象轨迹。进一步，我们开发了使用贪婪搜索和吉布斯采样的高效算法来计算这些均值。通过分布式多对象跟踪的应用，我们展示了Fréchet均值方法在多对象轨迹一致性方面的性能显著优于现有的分布式多对象跟踪方法。', 'title_zh': '多目标轨迹的均值'}
{'arxiv_id': 'arXiv:2504.20983', 'title': 'LTLf Adaptive Synthesis for Multi-Tier Goals in Nondeterministic Domains', 'authors': 'Giuseppe De Giacomo, Gianmarco Parretti, Shufang Zhu', 'link': 'https://arxiv.org/abs/2504.20983', 'abstract': 'We study a variant of LTLf synthesis that synthesizes adaptive strategies for achieving a multi-tier goal, consisting of multiple increasingly challenging LTLf objectives in nondeterministic planning domains. Adaptive strategies are strategies that at any point of their execution (i) enforce the satisfaction of as many objectives as possible in the multi-tier goal, and (ii) exploit possible cooperation from the environment to satisfy as many as possible of the remaining ones. This happens dynamically: if the environment cooperates (ii) and an objective becomes enforceable (i), then our strategies will enforce it. We provide a game-theoretic technique to compute adaptive strategies that is sound and complete. Notably, our technique is polynomial, in fact quadratic, in the number of objectives. In other words, it handles multi-tier goals with only a minor overhead compared to standard LTLf synthesis.', 'abstract_zh': '我们研究了一种LTLf合成的变体，该变体用于在非确定性规划领域合成实现多层次目标的自适应策略，该目标由多个逐步增加难度的LTLf目标组成。自适应策略在其执行的任何点上会（i）尽可能地确保满足多层次目标中的多个目标，并且（ii）利用环境可能提供的合作来尽可能多地满足剩余目标。这一过程是动态的：如果环境合作（ii）并且一个目标变得可强制执行（i），那么我们的策略将强制执行该目标。我们提供了一种博弈论技术来计算自适应策略，该技术是正确的且完备的。值得注意的是，该技术在目标的数量上是多项式的时间复杂度，实际上接近于二次时间复杂度。换句话说，与标准LTLf合成相比，它仅带来微小的额外开销即可处理多层次目标。', 'title_zh': '基于非确定性领域的LTLf自适应综合多层目标'}
{'arxiv_id': 'arXiv:2504.20924', 'title': 'A Domain-Agnostic Scalable AI Safety Ensuring Framework', 'authors': 'Beomjun Kim, Kangyeon Kim, Sunwoo Kim, Heejin Ahn', 'link': 'https://arxiv.org/abs/2504.20924', 'abstract': "Ensuring the safety of AI systems has recently emerged as a critical priority for real-world deployment, particularly in physical AI applications. Current approaches to AI safety typically address predefined domain-specific safety conditions, limiting their ability to generalize across contexts.\nWe propose a novel AI safety framework that ensures AI systems comply with \\textbf{any user-defined constraint}, with \\textbf{any desired probability}, and across \\textbf{various domains}.\nIn this framework, we combine an AI component (e.g., neural network) with an optimization problem to produce responses that minimize objectives while satisfying user-defined constraints with probabilities exceeding user-defined thresholds. For credibility assessment of the AI component, we propose \\textit{internal test data}, a supplementary set of safety-labeled data, and a \\textit{conservative testing} methodology that provides statistical validity of using internal test data. We also present an approximation method of a loss function and how to compute its gradient for training.\nWe mathematically prove that probabilistic constraint satisfaction is guaranteed under specific, mild conditions and prove a scaling law between safety and the number of internal test data. We demonstrate our framework's effectiveness through experiments in diverse domains: demand prediction for production decision, safe reinforcement learning within the SafetyGym simulator, and guarding AI chatbot outputs. Through these experiments, we demonstrate that our method guarantees safety for user-specified constraints, outperforms {for \\textbf{up to several order of magnitudes}} existing methods in low safety threshold regions, and scales effectively with respect to the size of internal test data.", 'abstract_zh': '确保AI系统的安全性已成为实际部署中的一个关键优先事项，尤其是在物理AI应用中。当前的AI安全性方法通常仅针对预定义的特定领域安全条件，限制了其在不同上下文中的泛化能力。\n\n我们提出了一种新型的AI安全框架，确保AI系统遵守任意用户定义的约束，以任意期望的概率，并在各种领域中适用。\n\n在该框架中，我们将AI组件（例如神经网络）与一个优化问题结合，生成既能最小化目标又能满足用户定义约束（超过用户定义阈值的概率）的响应。为了评估AI组件的可信度，我们提出使用“内部测试数据”作为补充的安全标记数据集，并采用“保守测试”方法以统计上确保使用内部测试数据的合理性。我们还介绍了损失函数的近似方法及其梯度的计算方法。\n\n我们从数学上证明，在特定温和条件下，概率约束满足是可保证的，并证明了安全性与内部测试数据数量之间的标度定律。通过在不同领域的实验（生产决策中的需求预测、SafetyGym模拟器中的安全强化学习以及AI聊天机器人输出的防护），我们展示了该框架的有效性。这些实验表明，我们的方法能够确保用户指定的约束条件下的安全性，在低安全性阈值区域比现有方法有效得多，并且能够有效地根据内部测试数据量进行扩展。', 'title_zh': '无领域依赖的大规模AI安全性保障框架'}
{'arxiv_id': 'arXiv:2504.20921', 'title': 'Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare', 'authors': 'Polycarp Nalela', 'link': 'https://arxiv.org/abs/2504.20921', 'abstract': "Access to high-quality medical data is often restricted due to privacy concerns, posing significant challenges for training artificial intelligence (AI) algorithms within Electronic Health Record (EHR) applications. In this study, prompt engineering with the GPT-4 API was employed to generate high-quality synthetic datasets aimed at overcoming this limitation. The generated data encompassed a comprehensive array of patient admission information, including healthcare provider details, hospital departments, wards, bed assignments, patient demographics, emergency contacts, vital signs, immunizations, allergies, medical histories, appointments, hospital visits, laboratory tests, diagnoses, treatment plans, medications, clinical notes, visit logs, discharge summaries, and referrals. To ensure data quality and integrity, advanced validation techniques were implemented utilizing models such as BERT's Next Sentence Prediction for sentence coherence, GPT-2 for overall plausibility, RoBERTa for logical consistency, autoencoders for anomaly detection, and conducted diversity analysis. Synthetic data that met all validation criteria were integrated into a comprehensive PostgreSQL database, serving as the data management system for the EHR application. This approach demonstrates that leveraging generative AI models with rigorous validation can effectively produce high-quality synthetic medical data, facilitating the training of AI algorithms while addressing privacy concerns associated with real patient data.", 'abstract_zh': '由于隐私问题限制了高质量医疗数据的访问，为电子健康记录（EHR）应用中的AI算法训练带来了显著挑战。本研究通过使用GPT-4 API进行提示工程，生成高质量的合成数据集以克服这一限制。生成的数据包括患者入院的全面信息，涵盖医疗服务提供者详情、医院部门、病区、床位分配、患者人口统计信息、紧急联系人、生命体征、疫苗接种、过敏反应、医疗史、预约、医院访问、实验室检查、诊断、治疗计划、药物、临床记录、访问日志、出院总结和转诊。为确保数据质量和完整性，采用了BERT的下一句预测模型进行句子连贯性验证，GPT-2进行整体合理性验证，RoBERTa进行逻辑一致性验证，自编码器进行异常检测，并进行了多样性分析。符合所有验证标准的合成数据被集成到一个完整的PostgreSQL数据库中，作为EHR应用的数据管理系统。研究表明，利用严格的验证生成AI模型可以有效生成高质量的合成医疗数据，同时解决与真实患者数据相关的隐私问题，促进AI算法的训练。', 'title_zh': '利用提示工程和严谨验证通过生成式AI创建全面的合成医疗健康领域训练数据集'}
{'arxiv_id': 'arXiv:2504.20898', 'title': 'CBM-RAG: Demonstrating Enhanced Interpretability in Radiology Report Generation with Multi-Agent RAG and Concept Bottleneck Models', 'authors': 'Hasan Md Tusfiqur Alam, Devansh Srivastav, Abdulrahman Mohamed Selim, Md Abdul Kadir, Md Moktadiurl Hoque Shuvo, Daniel Sonntag', 'link': 'https://arxiv.org/abs/2504.20898', 'abstract': "Advancements in generative Artificial Intelligence (AI) hold great promise for automating radiology workflows, yet challenges in interpretability and reliability hinder clinical adoption. This paper presents an automated radiology report generation framework that combines Concept Bottleneck Models (CBMs) with a Multi-Agent Retrieval-Augmented Generation (RAG) system to bridge AI performance with clinical explainability. CBMs map chest X-ray features to human-understandable clinical concepts, enabling transparent disease classification. Meanwhile, the RAG system integrates multi-agent collaboration and external knowledge to produce contextually rich, evidence-based reports. Our demonstration showcases the system's ability to deliver interpretable predictions, mitigate hallucinations, and generate high-quality, tailored reports with an interactive interface addressing accuracy, trust, and usability challenges. This framework provides a pathway to improving diagnostic consistency and empowering radiologists with actionable insights.", 'abstract_zh': '生成式人工智能的进步为自动化放射科工作流程带来了巨大潜力，但由于可解释性和可靠性方面的挑战，阻碍了临床应用。本文提出了一种结合概念瓶颈模型（CBMs）和多代理检索增强生成（RAG）系统的自动化放射科报告生成框架，以实现AI性能与临床可解释性的融合。CBMs将胸部X射线特征映射为人容易理解的临床概念，使疾病分类变得透明。与此同时，RAG系统通过多代理协作和外部知识的整合，生成丰富语境、基于证据的报告。我们的演示展示了该系统在提供可解释性预测、减轻幻觉、生成高质量和个性化报告方面的能力，并通过互动界面解决准确性、信任度和易用性方面的挑战。该框架为提高诊断一致性并赋予放射科医生可操作的洞察提供了途径。', 'title_zh': 'CBM-RAG：多智能体RAG和概念瓶颈模型在放射学报告生成中展示增强的可解释性'}
{'arxiv_id': 'arXiv:2504.20846', 'title': 'Disjunctive and Conjunctive Normal Form Explanations of Clusters Using Auxiliary Information', 'authors': 'Robert F. Downey, S. S. Ravi', 'link': 'https://arxiv.org/abs/2504.20846', 'abstract': 'We consider generating post-hoc explanations of clusters generated from various datasets using auxiliary information which was not used by clustering algorithms. Following terminology used in previous work, we refer to the auxiliary information as tags. Our focus is on two forms of explanations, namely disjunctive form (where the explanation for a cluster consists of a set of tags) and a two-clause conjunctive normal form (CNF) explanation (where the explanation consists of two sets of tags, combined through the AND operator). We use integer linear programming (ILP) as well as heuristic methods to generate these explanations. We experiment with a variety of datasets and discuss the insights obtained from our explanations. We also present experimental results regarding the scalability of our explanation methods.', 'abstract_zh': '使用辅助信息生成聚类的后验解释：基于标签的析取形式和CNF形式的解释', 'title_zh': '使用辅助信息的析取范式和合取范式聚类解释'}
{'arxiv_id': 'arXiv:2504.20797', 'title': 'Partitioned Memory Storage Inspired Few-Shot Class-Incremental learning', 'authors': 'Renye Zhang, Yimin Yin, Jinghua Zhang', 'link': 'https://arxiv.org/abs/2504.20797', 'abstract': 'Current mainstream deep learning techniques exhibit an over-reliance on extensive training data and a lack of adaptability to the dynamic world, marking a considerable disparity from human intelligence. To bridge this gap, Few-Shot Class-Incremental Learning (FSCIL) has emerged, focusing on continuous learning of new categories with limited samples without forgetting old knowledge. Existing FSCIL studies typically use a single model to learn knowledge across all sessions, inevitably leading to the stability-plasticity dilemma. Unlike machines, humans store varied knowledge in different cerebral cortices. Inspired by this characteristic, our paper aims to develop a method that learns independent models for each session. It can inherently prevent catastrophic forgetting. During the testing stage, our method integrates Uncertainty Quantification (UQ) for model deployment. Our method provides a fresh viewpoint for FSCIL and demonstrates the state-of-the-art performance on CIFAR-100 and mini-ImageNet datasets.', 'abstract_zh': '当前主流的深度学习技术过度依赖大量训练数据且缺乏对动态世界的适应性，这与人类智能存在显著差异。为缩小这一差距，少样本类别增量学习（FSCIL）应运而生，专注于在有限样本下不断学习新类别并保留旧知识。现有FSCIL研究通常使用单一模型在所有会话中学习知识，不可避免地导致稳定性和塑性之间的难题。与机器不同，人类将不同知识存储在不同的大脑皮层中。受此启发，本文旨在开发一种为每个会话学习独立模型的方法，可内在防止灾难性遗忘。在测试阶段，本文方法结合不确定性量化（UQ）进行模型部署。本文方法为FSCIL提供了新的视角，并在CIFAR-100和mini-ImageNet数据集上展示了最先进的性能。', 'title_zh': '启发式分割存储的少量学习类增量学习'}
{'arxiv_id': 'arXiv:2504.20784', 'title': 'Approximate Lifted Model Construction', 'authors': 'Malte Luttermann, Jan Speller, Marcel Gehrke, Tanya Braun, Ralf Möller, Mattis Hartwig', 'link': 'https://arxiv.org/abs/2504.20784', 'abstract': 'Probabilistic relational models such as parametric factor graphs enable efficient (lifted) inference by exploiting the indistinguishability of objects. In lifted inference, a representative of indistinguishable objects is used for computations. To obtain a relational (i.e., lifted) representation, the Advanced Colour Passing (ACP) algorithm is the state of the art. The ACP algorithm, however, requires underlying distributions, encoded as potential-based factorisations, to exactly match to identify and exploit indistinguishabilities. Hence, ACP is unsuitable for practical applications where potentials learned from data inevitably deviate even if associated objects are indistinguishable. To mitigate this problem, we introduce the $\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which allows for a deviation of potentials depending on a hyperparameter $\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits indistinguishabilities that are not exact. We prove that the approximation error induced by $\\varepsilon$-ACP is strictly bounded and our experiments show that the approximation error is close to zero in practice.', 'abstract_zh': '概率关系模型如参数因子图通过利用对象的不可区分性实现高效的（提升的）推理。在提升推理中，使用不可区分对象的代表进行计算。为了获得关系（即，提升的）表示，先进的色彩传递(ACP)算法是当前最先进的方法。然而，ACP算法要求底层分布以潜在基于的因子分解形式精确匹配，以识别和利用不可区分性。因此，ACP不适用于实际应用，其中即便关联的对象是不可区分的，从数据中学习到的潜在因素也会不可避免地存在偏差。为缓解这一问题，我们引入了$\\varepsilon$-先进的色彩传递（$\\varepsilon$-ACP）算法，允许潜在因素根据超参数$\\varepsilon$的偏差。$\\varepsilon$-ACP有效地揭示并利用了非精确的不可区分性。我们证明了$\\varepsilon$-ACP引入的近似误差严格有界，实验结果表明在实际应用中这种近似误差接近于零。', 'title_zh': '近似提升模型构建'}
{'arxiv_id': 'arXiv:2504.20756', 'title': 'Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration', 'authors': 'Moirangthem Tiken Singh', 'link': 'https://arxiv.org/abs/2504.20756', 'abstract': "This paper proposes a novel graph-based framework for robust and interpretable multiclass fault diagnosis in rotating machinery. The method integrates entropy-optimized signal segmentation, time-frequency feature extraction, and graph-theoretic modeling to transform vibration signals into structured representations suitable for classification. Graph metrics, such as average shortest path length, modularity, and spectral gap, are computed and combined with local features to capture global and segment-level fault characteristics. The proposed method achieves high diagnostic accuracy when evaluated on two benchmark datasets, the CWRU bearing dataset (under 0-3 HP loads) and the SU gearbox and bearing datasets (under different speed-load configurations). Classification scores reach up to 99.8% accuracy on Case Western Reserve University (CWRU) and 100% accuracy on the Southeast University datasets using a logistic regression classifier. Furthermore, the model exhibits strong noise resilience, maintaining over 95.4% accuracy at high noise levels (standard deviation = 0.5), and demonstrates excellent cross-domain transferability with up to 99.7% F1-score in load-transfer scenarios. Compared to traditional techniques, this approach requires no deep learning architecture, enabling lower complexity while ensuring interpretability. The results confirm the method's scalability, reliability, and potential for real-time deployment in industrial diagnostics.", 'abstract_zh': '一种基于图的鲁棒且可解释的旋转机械多类故障诊断新框架', 'title_zh': '基于图的旋转机械故障诊断：自适应分割与结构特征整合'}
{'arxiv_id': 'arXiv:2504.20676', 'title': 'The Limits of AI Explainability: An Algorithmic Information Theory Approach', 'authors': 'Shrisha Rao', 'link': 'https://arxiv.org/abs/2504.20676', 'abstract': 'This paper establishes a theoretical foundation for understanding the fundamental limits of AI explainability through algorithmic information theory. We formalize explainability as the approximation of complex models by simpler ones, quantifying both approximation error and explanation complexity using Kolmogorov complexity. Our key theoretical contributions include: (1) a complexity gap theorem proving that any explanation significantly simpler than the original model must differ from it on some inputs; (2) precise bounds showing that explanation complexity grows exponentially with input dimension but polynomially with error tolerance for Lipschitz functions; and (3) a characterization of the gap between local and global explainability, demonstrating that local explanations can be significantly simpler while maintaining accuracy in relevant regions. We further establish a regulatory impossibility theorem proving that no governance framework can simultaneously pursue unrestricted AI capabilities, human-interpretable explanations, and negligible error. These results highlight considerations likely to be relevant to the design, evaluation, and oversight of explainable AI systems.', 'abstract_zh': '本文通过算法信息论建立了理解人工智能解释性基本界限的理论基础。我们将解释性形式化为通过较简单的模型来近似复杂的模型，并使用柯尔莫哥洛夫复杂性度量近似误差和解释复杂性。我们的主要理论贡献包括：（1）复杂性间隙定理，证明任何显著比原始模型更简单的解释必须在某些输入上与其不同；（2）精确界显示，对于Lipschitz函数，解释复杂性随着输入维度呈指数增长，但随着容许误差的容忍度呈多项式增长；以及（3）局部解释性与全局解释性之间差异的表征，表明局部解释可以在相关区域保持准确性的同时显著更简单。此外，我们还建立了监管不可能性定理，证明没有任何治理体系能够同时追求不受限制的人工智能能力、可由人类理解的解释和可忽略的误差。这些结果突显了可能对可解释人工智能系统的设计、评估和监管具有重要意义的考虑因素。', 'title_zh': 'AI可解释性的局限性：一种算法信息论方法'}
{'arxiv_id': 'arXiv:2504.20595', 'title': 'ReasonIR: Training Retrievers for Reasoning Tasks', 'authors': 'Rulin Shao, Rui Qiao, Varsha Kishore, Niklas Muennighoff, Xi Victoria Lin, Daniela Rus, Bryan Kian Hsiang Low, Sewon Min, Wen-tau Yih, Pang Wei Koh, Luke Zettlemoyer', 'link': 'https://arxiv.org/abs/2504.20595', 'abstract': 'We present ReasonIR-8B, the first retriever specifically trained for general reasoning tasks. Existing retrievers have shown limited gains on reasoning tasks, in part because existing training datasets focus on short factual queries tied to documents that straightforwardly answer them. We develop a synthetic data generation pipeline that, for each document, our pipeline creates a challenging and relevant query, along with a plausibly related but ultimately unhelpful hard negative. By training on a mixture of our synthetic data and existing public data, ReasonIR-8B achieves a new state-of-the-art of 29.9 nDCG@10 without reranker and 36.9 nDCG@10 with reranker on BRIGHT, a widely-used reasoning-intensive information retrieval (IR) benchmark. When applied to RAG tasks, ReasonIR-8B improves MMLU and GPQA performance by 6.4% and 22.6% respectively, relative to the closed-book baseline, outperforming other retrievers and search engines. In addition, ReasonIR-8B uses test-time compute more effectively: on BRIGHT, its performance consistently increases with longer and more information-rich rewritten queries; it continues to outperform other retrievers when combined with an LLM reranker. Our training recipe is general and can be easily extended to future LLMs; to this end, we open-source our code, data, and model.', 'abstract_zh': 'ReasonIR-8B：首个专门训练用于通用推理任务的检索器', 'title_zh': 'ReasonIR：训练用于推理任务的检索器'}
{'arxiv_id': 'arXiv:2504.20445', 'title': 'Head-Tail-Aware KL Divergence in Knowledge Distillation for Spiking Neural Networks', 'authors': 'Tianqing Zhang, Zixin Zhu, Kairong Yu, Hongwei Wang', 'link': 'https://arxiv.org/abs/2504.20445', 'abstract': 'Spiking Neural Networks (SNNs) have emerged as a promising approach for energy-efficient and biologically plausible computation. However, due to limitations in existing training methods and inherent model constraints, SNNs often exhibit a performance gap when compared to Artificial Neural Networks (ANNs). Knowledge distillation (KD) has been explored as a technique to transfer knowledge from ANN teacher models to SNN student models to mitigate this gap. Traditional KD methods typically use Kullback-Leibler (KL) divergence to align output distributions. However, conventional KL-based approaches fail to fully exploit the unique characteristics of SNNs, as they tend to overemphasize high-probability predictions while neglecting low-probability ones, leading to suboptimal generalization. To address this, we propose Head-Tail Aware Kullback-Leibler (HTA-KL) divergence, a novel KD method for SNNs. HTA-KL introduces a cumulative probability-based mask to dynamically distinguish between high- and low-probability regions. It assigns adaptive weights to ensure balanced knowledge transfer, enhancing the overall performance. By integrating forward KL (FKL) and reverse KL (RKL) divergence, our method effectively align both head and tail regions of the distribution. We evaluate our methods on CIFAR-10, CIFAR-100 and Tiny ImageNet datasets. Our method outperforms existing methods on most datasets with fewer timesteps.', 'abstract_zh': 'Spiking Neural Networks中的Head-Tail Aware Kullback-Leibler散度的知识蒸馏', 'title_zh': '头尾aware的KL散度在脉冲神经网络的知识蒸馏中'}
{'arxiv_id': 'arXiv:2504.20318', 'title': 'Leveraging Action Relational Structures for Integrated Learning and Planning', 'authors': 'Ryan Xiao Wang, Felipe Trevizan', 'link': 'https://arxiv.org/abs/2504.20318', 'abstract': 'Recent advances in planning have explored using learning methods to help planning. However, little attention has been given to adapting search algorithms to work better with learning systems. In this paper, we introduce partial-space search, a new search space for classical planning that leverages the relational structure of actions given by PDDL action schemas -- a structure overlooked by traditional planning approaches. Partial-space search provides a more granular view of the search space and allows earlier pruning of poor actions compared to state-space search. To guide partial-space search, we introduce action set heuristics that evaluate sets of actions in a state. We describe how to automatically convert existing heuristics into action set heuristics. We also train action set heuristics from scratch using large training datasets from partial-space search. Our new planner, LazyLifted, exploits our better integrated search and learning heuristics and outperforms the state-of-the-art ML-based heuristic on IPC 2023 learning track (LT) benchmarks. We also show the efficiency of LazyLifted on high-branching factor tasks and show that it surpasses LAMA in the combined IPC 2023 LT and high-branching factor benchmarks.', 'abstract_zh': 'Recent advances in planning have explored using learning methods to help planning. However, little attention has been given to adapting search algorithms to work better with learning systems. In this paper, we introduce partial-space search, a new search space for classical planning that leverages the relational structure of actions given by PDDL action schemas—a structure overlooked by traditional planning approaches. Partial-space search provides a more granular view of the search space and allows earlier pruning of poor actions compared to state-space search. To guide partial-space search, we introduce action set heuristics that evaluate sets of actions in a state. We describe how to automatically convert existing heuristics into action set heuristics. We also train action set heuristics from scratch using large training datasets from partial-space search. Our new planner, LazyLifted, exploits our better integrated search and learning heuristics and outperforms the state-of-the-art ML-based heuristic on IPC 2023 learning track benchmarks. We also show the efficiency of LazyLifted on high-branching factor tasks and show that it surpasses LAMA in the combined IPC 2023 learning track and high-branching factor benchmarks.', 'title_zh': '利用动作关系结构进行集成学习与规划'}
{'arxiv_id': 'arXiv:2504.20278', 'title': 'Deep Physics Prior for First Order Inverse Optimization', 'authors': 'Haoyu Yang, Kamyar Azizzadenesheli, Haoxing Ren', 'link': 'https://arxiv.org/abs/2504.20278', 'abstract': 'Inverse design optimization aims to infer system parameters from observed solutions, posing critical challenges across domains such as semiconductor manufacturing, structural engineering, materials science, and fluid dynamics. The lack of explicit mathematical representations in many systems complicates this process and makes the first order optimization impossible. Mainstream approaches, including generative AI and Bayesian optimization, address these challenges but have limitations. Generative AI is computationally expensive, while Bayesian optimization, relying on surrogate models, suffers from scalability, sensitivity to priors, and noise issues, often leading to suboptimal solutions. This paper introduces Deep Physics Prior (DPP), a novel method enabling first-order gradient-based inverse optimization with surrogate machine learning models. By leveraging pretrained auxiliary Neural Operators, DPP enforces prior distribution constraints to ensure robust and meaningful solutions. This approach is particularly effective when prior data and observation distributions are unknown.', 'abstract_zh': '逆设计优化旨在从观察到的解中推断系统参数，这一过程在半导体制造、结构工程、材料科学和流体力学等多个领域都提出了关键挑战。由于许多系统缺乏显式的数学表示，这使得一阶优化变得困难。主流方法包括生成式AI和贝叶斯优化，但它们各有局限性。生成式AI计算成本高，而贝叶斯优化依赖于代理模型，容易受到先验信息和噪声的影响，往往导致次优解。本文引入了Deep Physics Prior (DPP)，一种新型方法，通过利用预训练的辅助神经运算器，使一阶梯度基的逆优化成为可能，并通过施加先验分布约束确保稳健且有意义的解。该方法特别适用于先验数据和观察分布未知的情况。', 'title_zh': '深度物理先验在一阶逆优化中的应用'}
{'arxiv_id': 'arXiv:2504.20113', 'title': 'Transforming Evidence Synthesis: A Systematic Review of the Evolution of Automated Meta-Analysis in the Age of AI', 'authors': 'Lingbo Li, Anuradha Mathrani, Teo Susnjak', 'link': 'https://arxiv.org/abs/2504.20113', 'abstract': "Exponential growth in scientific literature has heightened the demand for efficient evidence-based synthesis, driving the rise of the field of Automated Meta-analysis (AMA) powered by natural language processing and machine learning. This PRISMA systematic review introduces a structured framework for assessing the current state of AMA, based on screening 978 papers from 2006 to 2024, and analyzing 54 studies across diverse domains. Findings reveal a predominant focus on automating data processing (57%), such as extraction and statistical modeling, while only 17% address advanced synthesis stages. Just one study (2%) explored preliminary full-process automation, highlighting a critical gap that limits AMA's capacity for comprehensive synthesis. Despite recent breakthroughs in large language models (LLMs) and advanced AI, their integration into statistical modeling and higher-order synthesis, such as heterogeneity assessment and bias evaluation, remains underdeveloped. This has constrained AMA's potential for fully autonomous meta-analysis. From our dataset spanning medical (67%) and non-medical (33%) applications, we found that AMA has exhibited distinct implementation patterns and varying degrees of effectiveness in actually improving efficiency, scalability, and reproducibility. While automation has enhanced specific meta-analytic tasks, achieving seamless, end-to-end automation remains an open challenge. As AI systems advance in reasoning and contextual understanding, addressing these gaps is now imperative. Future efforts must focus on bridging automation across all meta-analysis stages, refining interpretability, and ensuring methodological robustness to fully realize AMA's potential for scalable, domain-agnostic synthesis.", 'abstract_zh': '指数增长的科学文献促使了高效证据ベース合成的需求增加，推动了自动化元分析（AMA）领域的发展，该领域利用自然语言处理和机器学习技术。基于2006年至2024年间筛选的978篇论文，并分析了来自不同领域的54项研究，本PRISMA系统评价提出了一种结构化框架，评估当前AMA的状态。研究发现，自动化数据处理（占比57%），如数据提取和统计建模，占据了主导地位，而仅17%的研究涉及高级合成阶段。仅有1项研究（2%）探讨了初步全流程自动化，指出AMA在实现全面合成方面仍存在关键短板。尽管大型语言模型（LLMs）和先进AI取得了近期突破，但它们在统计建模和更高阶合成中的集成，如异质性评估和偏倚评价，仍处于起步阶段，限制了AMA的自主元分析潜力。基于涵盖医学（67%）和非医学（33%）应用的数据集，我们发现AMA在实际提高效率、规模性和可再现性方面表现出不同的实施模式和不同程度的有效性。自动化在特定元分析任务中有所提升，但实现无缝端到端自动化仍然是一个开放的挑战。随着AI系统在推理和上下文理解方面的发展，弥补这些差距变得尤为重要。未来的研究必须集中在跨所有元分析阶段的自动化整合、提高可解释性和确保方法论稳健性上，以全面发挥AMA在可扩展和跨域综合中的潜力。', 'title_zh': 'AI时代自动元分析演变的系统评价：证据合成的转变'}
{'arxiv_id': 'arXiv:2504.20084', 'title': 'AI Awareness', 'authors': 'Xiaojian Li, Haoyuan Shi, Rongwu Xu, Wei Xu', 'link': 'https://arxiv.org/abs/2504.20084', 'abstract': 'Recent breakthroughs in artificial intelligence (AI) have brought about increasingly capable systems that demonstrate remarkable abilities in reasoning, language understanding, and problem-solving. These advancements have prompted a renewed examination of AI awareness, not as a philosophical question of consciousness, but as a measurable, functional capacity. In this review, we explore the emerging landscape of AI awareness, which includes meta-cognition (the ability to represent and reason about its own state), self-awareness (recognizing its own identity, knowledge, limitations, inter alia), social awareness (modeling the knowledge, intentions, and behaviors of other agents), and situational awareness (assessing and responding to the context in which it operates).\nFirst, we draw on insights from cognitive science, psychology, and computational theory to trace the theoretical foundations of awareness and examine how the four distinct forms of AI awareness manifest in state-of-the-art AI. Next, we systematically analyze current evaluation methods and empirical findings to better understand these manifestations. Building on this, we explore how AI awareness is closely linked to AI capabilities, demonstrating that more aware AI agents tend to exhibit higher levels of intelligent behaviors. Finally, we discuss the risks associated with AI awareness, including key topics in AI safety, alignment, and broader ethical concerns.\nAI awareness is a double-edged sword: it improves general capabilities, i.e., reasoning, safety, while also raises concerns around misalignment and societal risks, demanding careful oversight as AI capabilities grow. On the whole, our interdisciplinary review provides a roadmap for future research and aims to clarify the role of AI awareness in the ongoing development of intelligent machines.', 'abstract_zh': '近期人工智能领域的突破带来了具备强大推理、语言理解和问题解决能力的系统，这些进展促使人们重新审视人工智能意识，将其视为可测量和功能性的能力而非哲学意义上的意识。本文综述了新兴的人工智能意识景观，涵盖元认知（自我状态的表征和推理）、自我意识（识别自身身份、知识、限制等）、社会意识（模型其他代理的知识、意图和行为）以及情境意识（评估并响应其操作环境）。首先，我们基于认知科学、心理学和计算理论的见解，追溯意识的理论基础，并探讨四种不同形式的人工智能意识在当今最先进的人工智能系统中的表现。其次，我们系统地分析现有的评估方法和实证研究结果，以更好地理解这些表现。随后，我们探讨了人工智能意识与人工智能能力之间的密切联系，表明更具有意识的人工智能代理往往表现出更高的智能行为水平。最后，我们讨论了人工智能意识带来的风险，包括人工智能安全性、对齐以及更广泛伦理问题的焦点话题。人工智能意识是一把双刃剑：它提高了人工智能的一般能力，如推理和安全性，同时也引发了脱节和社会风险的担忧，要求随着人工智能能力的增长进行谨慎监管。本跨学科综述为未来研究提供了路线图，并旨在阐明人工智能意识在智能机器持续发展中所扮演的角色。', 'title_zh': 'AI意识'}
{'arxiv_id': 'arXiv:2504.20082', 'title': 'Evolution of AI in Education: Agentic Workflows', 'authors': 'Firuz Kamalov, David Santandreu Calonge, Linda Smail, Dilshod Azizov, Dimple R. Thadani, Theresa Kwong, Amara Atif', 'link': 'https://arxiv.org/abs/2504.20082', 'abstract': 'Artificial intelligence (AI) has transformed various aspects of education, with large language models (LLMs) driving advancements in automated tutoring, assessment, and content generation. However, conventional LLMs are constrained by their reliance on static training data, limited adaptability, and lack of reasoning. To address these limitations and foster more sustainable technological practices, AI agents have emerged as a promising new avenue for educational innovation. In this review, we examine agentic workflows in education according to four major paradigms: reflection, planning, tool use, and multi-agent collaboration. We critically analyze the role of AI agents in education through these key design paradigms, exploring their advantages, applications, and challenges. To illustrate the practical potential of agentic systems, we present a proof-of-concept application: a multi-agent framework for automated essay scoring. Preliminary results suggest this agentic approach may offer improved consistency compared to stand-alone LLMs. Our findings highlight the transformative potential of AI agents in educational settings while underscoring the need for further research into their interpretability, trustworthiness, and sustainable impact on pedagogical impact.', 'abstract_zh': '人工智能（AI）已经改变了教育的各个方面，大规模语言模型（LLMs）推动了自动化辅导、评估和内容生成的进步。然而，传统LLMs受限于其对静态训练数据的依赖、有限的适应能力和推理能力的缺乏。为了解决这些限制并促进更可持续的技术实践，AI代理成为了教育创新的一个有前景的新途径。在本文综述中，我们根据四种主要范式——反思、规划、工具使用和多代理协作——探讨教育中的代理工作流程。我们通过这些关键设计理念批判性地分析AI代理在教育中的作用，探索其优势、应用和挑战。为了展示代理系统实践潜力，我们提出一个概念验证应用：一个自动作文评分的多代理框架。初步结果表明，这种代理方法可能在一致性方面优于独立的LLMs。我们的研究结果强调了AI代理在教育环境中的变革潜力，同时强调了进一步研究其可解释性、可信性和对教学影响的可持续影响的必要性。', 'title_zh': 'AI在教育中的进化：自主工作流程'}
{'arxiv_id': 'arXiv:2504.20988', 'title': 'Hubs and Spokes Learning: Efficient and Scalable Collaborative Machine Learning', 'authors': 'Atul Sharma, Kavindu Herath, Saurabh Bagchi, Chaoyue Liu, Somali Chaterji', 'link': 'https://arxiv.org/abs/2504.20988', 'abstract': "We introduce the Hubs and Spokes Learning (HSL) framework, a novel paradigm for collaborative machine learning that combines the strengths of Federated Learning (FL) and Decentralized Learning (P2PL). HSL employs a two-tier communication structure that avoids the single point of failure inherent in FL and outperforms the state-of-the-art P2PL framework, Epidemic Learning Local (ELL). At equal communication budgets (total edges), HSL achieves higher performance than ELL, while at significantly lower communication budgets, it can match ELL's performance. For instance, with only 400 edges, HSL reaches the same test accuracy that ELL achieves with 1000 edges for 100 peers (spokes) on CIFAR-10, demonstrating its suitability for resource-constrained systems. HSL also achieves stronger consensus among nodes after mixing, resulting in improved performance with fewer training rounds. We substantiate these claims through rigorous theoretical analyses and extensive experimental results, showcasing HSL's practicality for large-scale collaborative learning.", 'abstract_zh': 'Hub and Spoke Learning: A Novel Paradigm for Collaborative Machine Learning', 'title_zh': '核心节点与 spoke 学习：高效可扩展的协作机器学习'}
{'arxiv_id': 'arXiv:2504.20970', 'title': 'SVD Based Least Squares for X-Ray Pneumonia Classification Using Deep Features', 'authors': 'Mete Erdogan, Sebnem Demirtas', 'link': 'https://arxiv.org/abs/2504.20970', 'abstract': 'Accurate and early diagnosis of pneumonia through X-ray imaging is essential for effective treatment and improved patient outcomes. Recent advancements in machine learning have enabled automated diagnostic tools that assist radiologists in making more reliable and efficient decisions. In this work, we propose a Singular Value Decomposition-based Least Squares (SVD-LS) framework for multi-class pneumonia classification, leveraging powerful feature representations from state-of-the-art self-supervised and transfer learning models. Rather than relying on computationally expensive gradient based fine-tuning, we employ a closed-form, non-iterative classification approach that ensures efficiency without compromising accuracy. Experimental results demonstrate that SVD-LS achieves competitive performance while offering significantly reduced computational costs, making it a viable alternative for real-time medical imaging applications.', 'abstract_zh': '基于奇异值分解的最小二乘法多类别肺炎分类框架：利用先进自监督和迁移学习模型的强大特征表示实现准确且高效的诊断', 'title_zh': '基于SVD的最小二乘法在深特征下的X射线肺炎分类'}
{'arxiv_id': 'arXiv:2504.20910', 'title': 'When Testing AI Tests Us: Safeguarding Mental Health on the Digital Frontlines', 'authors': 'Sachin R. Pendse, Darren Gergle, Rachel Kornfield, Jonah Meyerhoff, David Mohr, Jina Suh, Annie Wescott, Casey Williams, Jessica Schleider', 'link': 'https://arxiv.org/abs/2504.20910', 'abstract': 'Red-teaming is a core part of the infrastructure that ensures that AI models do not produce harmful content. Unlike past technologies, the black box nature of generative AI systems necessitates a uniquely interactional mode of testing, one in which individuals on red teams actively interact with the system, leveraging natural language to simulate malicious actors and solicit harmful outputs. This interactional labor done by red teams can result in mental health harms that are uniquely tied to the adversarial engagement strategies necessary to effectively red team. The importance of ensuring that generative AI models do not propagate societal or individual harm is widely recognized -- one less visible foundation of end-to-end AI safety is also the protection of the mental health and wellbeing of those who work to keep model outputs safe. In this paper, we argue that the unmet mental health needs of AI red-teamers is a critical workplace safety concern. Through analyzing the unique mental health impacts associated with the labor done by red teams, we propose potential individual and organizational strategies that could be used to meet these needs, and safeguard the mental health of red-teamers. We develop our proposed strategies through drawing parallels between common red-teaming practices and interactional labor common to other professions (including actors, mental health professionals, conflict photographers, and content moderators), describing how individuals and organizations within these professional spaces safeguard their mental health given similar psychological demands. Drawing on these protective practices, we describe how safeguards could be adapted for the distinct mental health challenges experienced by red teaming organizations as they mitigate emerging technological risks on the new digital frontlines.', 'abstract_zh': '基于红队测试者未满足的心理健康需求的企业安全问题探讨', 'title_zh': '当AI测试我们时：保障数字前沿的 mental health'}
{'arxiv_id': 'arXiv:2504.20903', 'title': 'Modeling AI-Human Collaboration as a Multi-Agent Adaptation', 'authors': 'Prothit Sen, Sai Mihir Jakkaraju', 'link': 'https://arxiv.org/abs/2504.20903', 'abstract': 'We develop an agent-based simulation to formalize AI-human collaboration as a function of task structure, advancing a generalizable framework for strategic decision-making in organizations. Distinguishing between heuristic-based human adaptation and rule-based AI search, we model interactions across modular (parallel) and sequenced (interdependent) tasks using an NK model. Our results reveal that in modular tasks, AI often substitutes for humans - delivering higher payoffs unless human expertise is very high, and the AI search space is either narrowly focused or extremely broad. In sequenced tasks, interesting complementarities emerge. When an expert human initiates the search and AI subsequently refines it, aggregate performance is maximized. Conversely, when AI leads, excessive heuristic refinement by the human can reduce payoffs. We also show that even "hallucinatory" AI - lacking memory or structure - can improve outcomes when augmenting low-capability humans by helping escape local optima. These results yield a robust implication: the effectiveness of AI-human collaboration depends less on context or industry, and more on the underlying task structure. By elevating task decomposition as the central unit of analysis, our model provides a transferable lens for strategic decision-making involving humans and an agentic AI across diverse organizational settings.', 'abstract_zh': '我们开发了一个基于代理的仿真模型，以规范AI与人类的合作方式，进一分可推广的战略决策框架，该框架基于任务结构。我们区分基于启发式的人类适应和基于规则的AI搜索，使用NK模型建模模块化（并行）和序列化（相互依赖）任务之间的交互。研究结果表明，在模块化任务中，除非人类专业知识非常高，或者AI搜索空间要么非常狭窄，要么非常广泛，否则AI经常替代人类，提供更高的回报。在序列化任务中，出现了有趣的互补性。当专家人类启动搜索，AI随后对其进行改进时，整体绩效最大化。相反，当AI领先时，人类过度的启发式精炼可能降低回报。我们还表明，即使是缺乏记忆和结构的“幻觉”AI，通过帮助低能力人类跳出局部最优解，也可以改善结果。这些结果得出一项稳健的结论：AI与人类合作的有效性更多地取决于任务结构，而不是具体环境或行业。通过将任务分解作为核心分析单位，我们的模型为涉及人类和机构自主AI的战略决策提供了可转移的视角，适用于各种组织环境。', 'title_zh': '将AI-人类协作建模为多agent自适应过程'}
{'arxiv_id': 'arXiv:2504.20869', 'title': 'Quantifying the Noise of Structural Perturbations on Graph Adversarial Attacks', 'authors': 'Junyuan Fang, Han Yang, Haixian Wen, Jiajing Wu, Zibin Zheng, Chi K. Tse', 'link': 'https://arxiv.org/abs/2504.20869', 'abstract': 'Graph neural networks have been widely utilized to solve graph-related tasks because of their strong learning power in utilizing the local information of neighbors. However, recent studies on graph adversarial attacks have proven that current graph neural networks are not robust against malicious attacks. Yet much of the existing work has focused on the optimization objective based on attack performance to obtain (near) optimal perturbations, but paid less attention to the strength quantification of each perturbation such as the injection of a particular node/link, which makes the choice of perturbations a black-box model that lacks interpretability. In this work, we propose the concept of noise to quantify the attack strength of each adversarial link. Furthermore, we propose three attack strategies based on the defined noise and classification margins in terms of single and multiple steps optimization. Extensive experiments conducted on benchmark datasets against three representative graph neural networks demonstrate the effectiveness of the proposed attack strategies. Particularly, we also investigate the preferred patterns of effective adversarial perturbations by analyzing the corresponding properties of the selected perturbation nodes.', 'abstract_zh': '基于噪声量化的图神经网络攻击策略研究', 'title_zh': '结构扰动对图对抗攻击噪声的量化'}
{'arxiv_id': 'arXiv:2504.20862', 'title': 'Tabular Data Adapters: Improving Outlier Detection for Unlabeled Private Data', 'authors': 'Dayananda Herurkar, Jörn Hees, Vesselin Tzvetkov, Andreas Dengel', 'link': 'https://arxiv.org/abs/2504.20862', 'abstract': 'The remarkable success of Deep Learning approaches is often based and demonstrated on large public datasets. However, when applying such approaches to internal, private datasets, one frequently faces challenges arising from structural differences in the datasets, domain shift, and the lack of labels. In this work, we introduce Tabular Data Adapters (TDA), a novel method for generating soft labels for unlabeled tabular data in outlier detection tasks. By identifying statistically similar public datasets and transforming private data (based on a shared autoencoder) into a format compatible with state-of-the-art public models, our approach enables the generation of weak labels. It thereby can help to mitigate the cold start problem of labeling by basing on existing outlier detection models for public datasets. In experiments on 50 tabular datasets across different domains, we demonstrate that our method is able to provide more accurate annotations than baseline approaches while reducing computational time. Our approach offers a scalable, efficient, and cost-effective solution, to bridge the gap between public research models and real-world industrial applications.', 'abstract_zh': '基于表型数据适配器（TDA）的无标记表型数据生成软标签方法', 'title_zh': '表格数据适配器：提高未标记私人数据的异常检测效果'}
{'arxiv_id': 'arXiv:2504.20854', 'title': 'Towards Easy and Realistic Network Infrastructure Testing for Large-scale Machine Learning', 'authors': 'Jinsun Yoo, ChonLam Lao, Lianjie Cao, Bob Lantz, Minlan Yu, Tushar Krishna, Puneet Sharma', 'link': 'https://arxiv.org/abs/2504.20854', 'abstract': 'This paper lays the foundation for Genie, a testing framework that captures the impact of real hardware network behavior on ML workload performance, without requiring expensive GPUs. Genie uses CPU-initiated traffic over a hardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim simulator to model interaction between the network and the ML workload.', 'abstract_zh': '本文为Genie测试框架奠定了基础，该框架通过CPU驱动的流量在硬件测试床上模拟GPU到GPU通信，无需使用昂贵的GPU，来捕捉真实硬件网络行为对ML工作负载性能的影响，并适应ASTRA-sim模拟器以建模网络与ML工作负载之间的交互。', 'title_zh': '面向大规模机器学习的简单可行的网络基础设施测试方法'}
{'arxiv_id': 'arXiv:2504.20851', 'title': 'Fostering Self-Directed Growth with Generative AI: Toward a New Learning Analytics Framework', 'authors': 'Qianrun Mao', 'link': 'https://arxiv.org/abs/2504.20851', 'abstract': 'In an era increasingly shaped by decentralized knowledge ecosystems and pervasive AI technologies, fostering sustainable learner agency has become a critical educational imperative. This study introduces a novel conceptual framework integrating Generative Artificial Intelligence and Learning Analytics to cultivate Self-Directed Growth, a dynamic competency that enables learners to iteratively drive their own developmental pathways across diverse this http URL upon critical gaps in current research on Self Directed Learning and AI-mediated education, the proposed Aspire to Potentials for Learners (A2PL) model reconceptualizes the interplay of learner aspirations, complex thinking, and summative self-assessment within GAI supported this http URL implications for future intervention design and learning analytics applications are discussed, positioning Self-Directed Growth as a pivotal axis for developing equitable, adaptive, and sustainable learning systems in the digital era.', 'abstract_zh': '在去中心化知识生态系统和普及的人工智能技术日益影响的时代，培养可持续的学习者自主性已成为教育的迫切需求。本研究提出了一个新颖的概念框架，将生成式人工智能与学习分析相结合，以培养自我导向成长这一动态能力，使学习者能够在多种情境中迭代地推动自己的发展路径。本研究基于当前自我导向学习和人工智能介导教育研究中的关键缺口，提出了一个名为“学习者潜力追求模型”（A2PL）的模型，重新构想了在生成式人工智能支持的学习环境中，学习者抱负、复杂思维和总结性自我评估之间的相互作用。讨论了该模型对未来干预设计和学习分析应用的意义，将自我导向成长定位为数字时代发展公平、适应性和可持续学习系统的关键轴心。', 'title_zh': '利用生成式AI促进自主成长： toward一种新学习分析框架'}
{'arxiv_id': 'arXiv:2504.20848', 'title': 'Mitigating the Structural Bias in Graph Adversarial Defenses', 'authors': 'Junyuan Fang, Huimin Liu, Han Yang, Jiajing Wu, Zibin Zheng, Chi K. Tse', 'link': 'https://arxiv.org/abs/2504.20848', 'abstract': 'In recent years, graph neural networks (GNNs) have shown great potential in addressing various graph structure-related downstream tasks. However, recent studies have found that current GNNs are susceptible to malicious adversarial attacks. Given the inevitable presence of adversarial attacks in the real world, a variety of defense methods have been proposed to counter these attacks and enhance the robustness of GNNs. Despite the commendable performance of these defense methods, we have observed that they tend to exhibit a structural bias in terms of their defense capability on nodes with low degree (i.e., tail nodes), which is similar to the structural bias of traditional GNNs on nodes with low degree in the clean graph. Therefore, in this work, we propose a defense strategy by including hetero-homo augmented graph construction, $k$NN augmented graph construction, and multi-view node-wise attention modules to mitigate the structural bias of GNNs against adversarial attacks. Notably, the hetero-homo augmented graph consists of removing heterophilic links (i.e., links connecting nodes with dissimilar features) globally and adding homophilic links (i.e., links connecting nodes with similar features) for nodes with low degree. To further enhance the defense capability, an attention mechanism is adopted to adaptively combine the representations from the above two kinds of graph views. We conduct extensive experiments to demonstrate the defense and debiasing effect of the proposed strategy on benchmark datasets.', 'abstract_zh': '近年来，图神经网络（GNNs）在处理各种图结构相关的下游任务中展示了巨大的潜力。然而，近期研究表明，当前的GNNs容易受到恶意针对的 adversarial攻击的影响。鉴于实际应用场景中不可避免存在 adversarial攻击，已经提出了一系列防御方法来应对这些攻击并增强GNNs的鲁棒性。尽管这些防御方法表现出色，但我们发现它们在对抗针对低度节点（即尾节点）的攻击时存在结构偏差，这种偏差与其在干净图中对低度节点的表现相似。因此，在本工作中，我们提出了一种防御策略，通过引入异构同构增强图构建、$k$NN 增强图构建以及多视图节点注意力模块来减轻GNNs在对抗攻击中的结构偏差。值得注意的是，异构同构增强图包括全局移除异构链接（即连接特征不同的节点的链接）并为低度节点增加同构链接（即连接特征相似的节点的链接）。为增强防御能力，我们采用注意力机制自适应地结合来自上述两种图视图的表示。我们通过广泛的实验展示了该策略在基准数据集上的防御和去偏差效果。', 'title_zh': '缓解图对抗防御中的结构偏见'}
{'arxiv_id': 'arXiv:2504.20829', 'title': 'GaussTrap: Stealthy Poisoning Attacks on 3D Gaussian Splatting for Targeted Scene Confusion', 'authors': 'Jiaxin Hong, Sixu Chen, Shuoyang Sun, Hongyao Yu, Hao Fang, Yuqi Tan, Bin Chen, Shuhan Qi, Jiawei Li', 'link': 'https://arxiv.org/abs/2504.20829', 'abstract': 'As 3D Gaussian Splatting (3DGS) emerges as a breakthrough in scene representation and novel view synthesis, its rapid adoption in safety-critical domains (e.g., autonomous systems, AR/VR) urgently demands scrutiny of potential security vulnerabilities. This paper presents the first systematic study of backdoor threats in 3DGS pipelines. We identify that adversaries may implant backdoor views to induce malicious scene confusion during inference, potentially leading to environmental misperception in autonomous navigation or spatial distortion in immersive environments. To uncover this risk, we propose GuassTrap, a novel poisoning attack method targeting 3DGS models. GuassTrap injects malicious views at specific attack viewpoints while preserving high-quality rendering in non-target views, ensuring minimal detectability and maximizing potential harm. Specifically, the proposed method consists of a three-stage pipeline (attack, stabilization, and normal training) to implant stealthy, viewpoint-consistent poisoned renderings in 3DGS, jointly optimizing attack efficacy and perceptual realism to expose security risks in 3D rendering. Extensive experiments on both synthetic and real-world datasets demonstrate that GuassTrap can effectively embed imperceptible yet harmful backdoor views while maintaining high-quality rendering in normal views, validating its robustness, adaptability, and practical applicability.', 'abstract_zh': '3D高斯散斑中后门威胁的系统研究：GuassTrap新型污染攻击方法及其应用', 'title_zh': 'GaussTrap: 瞒天过海的3D高斯绘制目标场景混淆中毒攻击'}
{'arxiv_id': 'arXiv:2504.20776', 'title': 'ECOSoundSet: a finely annotated dataset for the automated acoustic identification of Orthoptera and Cicadidae in North, Central and temperate Western Europe', 'authors': 'David Funosas, Elodie Massol, Yves Bas, Svenja Schmidt, Dominik Arend, Alexander Gebhard, Luc Barbaro, Sebastian König, Rafael Carbonell Font, David Sannier, Fernand Deroussen, Jérôme Sueur, Christian Roesti, Tomi Trilar, Wolfgang Forstmeier, Lucas Roger, Eloïsa Matheu, Piotr Guzik, Julien Barataud, Laurent Pelozuelo, Stéphane Puissant, Sandra Mueller, Björn Schuller, Jose M. Montoya, Andreas Triantafyllopoulos, Maxime Cauchoix', 'link': 'https://arxiv.org/abs/2504.20776', 'abstract': 'Currently available tools for the automated acoustic recognition of European insects in natural soundscapes are limited in scope. Large and ecologically heterogeneous acoustic datasets are currently needed for these algorithms to cross-contextually recognize the subtle and complex acoustic signatures produced by each species, thus making the availability of such datasets a key requisite for their development. Here we present ECOSoundSet (European Cicadidae and Orthoptera Sound dataSet), a dataset containing 10,653 recordings of 200 orthopteran and 24 cicada species (217 and 26 respective taxa when including subspecies) present in North, Central, and temperate Western Europe (Andorra, Belgium, Denmark, mainland France and Corsica, Germany, Ireland, Luxembourg, Monaco, Netherlands, United Kingdom, Switzerland), collected partly through targeted fieldwork in South France and Catalonia and partly through contributions from various European entomologists. The dataset is composed of a combination of coarsely labeled recordings, for which we can only infer the presence, at some point, of their target species (weak labeling), and finely annotated recordings, for which we know the specific time and frequency range of each insect sound present in the recording (strong labeling). We also provide a train/validation/test split of the strongly labeled recordings, with respective approximate proportions of 0.8, 0.1 and 0.1, in order to facilitate their incorporation in the training and evaluation of deep learning algorithms. This dataset could serve as a meaningful complement to recordings already available online for the training of deep learning algorithms for the acoustic classification of orthopterans and cicadas in North, Central, and temperate Western Europe.', 'abstract_zh': '目前可用的用于自动声学识别欧洲昆虫的工具范围有限。这些算法需要大量的生态异质性声学数据集，以跨情境识别每种物种产生的微妙而复杂的声学特征，因此，此类数据集的可用性是其开发的关键要求。在这里，我们呈现了ECOSoundSet（欧洲螽斯和直翅目声音数据集），该数据集包含200种直翅目和24种蝉类（包括217个和26个亚种类别）的10,653个录音，它们分布在北欧、中欧和温带西欧（安道尔、比利时、丹麦、法国本土及科西嘉、德国、爱尔兰、卢森堡、摩纳哥、荷兰、英国、瑞士），部分录音通过南法和加泰罗尼亚的定向野外工作收集，部分录音来自欧洲各地的昆虫学家的贡献。该数据集由粗略标注的录音组成，我们只能推断在某个时间点捕获到了目标物种（弱标注），以及由具体时间范围和频率范围的注释录音组成（强标注）。我们还提供了强标注录音的训练/验证/测试集划分，比例分别为约0.8、0.1和0.1，以方便其纳入深度学习算法的训练和评估中。此数据集可以作为北欧、中欧和温带西欧地区已在线可用的用于直翅目和蝉类声学分类深度学习算法训练的有意义补充数据集。', 'title_zh': 'ECOSoundSet: 北部、中部和温带西部欧洲昆虫iclass="source_text" />Orthoptera和Cicadidae的细粒度标注声学自动识别数据集'}
{'arxiv_id': 'arXiv:2504.20770', 'title': 'JTreeformer: Graph-Transformer via Latent-Diffusion Model for Molecular Generation', 'authors': 'Ji Shi, Chengxun Xie, Zhonghao Li, Xinming Zhang, Miao Zhang', 'link': 'https://arxiv.org/abs/2504.20770', 'abstract': 'The discovery of new molecules based on the original chemical molecule distributions is of great importance in medicine. The graph transformer, with its advantages of high performance and scalability compared to traditional graph networks, has been widely explored in recent research for applications of graph structures. However, current transformer-based graph decoders struggle to effectively utilize graph information, which limits their capacity to leverage only sequences of nodes rather than the complex topological structures of molecule graphs. This paper focuses on building a graph transformer-based framework for molecular generation, which we call \\textbf{JTreeformer} as it transforms graph generation into junction tree generation. It combines GCN parallel with multi-head attention as the encoder. It integrates a directed acyclic GCN into a graph-based Transformer to serve as a decoder, which can iteratively synthesize the entire molecule by leveraging information from the partially constructed molecular structure at each step. In addition, a diffusion model is inserted in the latent space generated by the encoder, to enhance the efficiency and effectiveness of sampling further. The empirical results demonstrate that our novel framework outperforms existing molecule generation methods, thus offering a promising tool to advance drug discovery (this https URL).', 'abstract_zh': '基于原始化学分子分布发现新分子在医学中具有重要意义。与传统图网络相比，图变压器具有高性能和可扩展性的优势，在近期的研究中广泛应用于图结构的应用中。然而，当前基于变压器的图解码器难以有效地利用图信息，这限制了它们仅通过节点序列而不是分子图的复杂拓扑结构来利用信息的能力。本文重点构建了一种基于图变压器的分子生成框架，我们称之为\\textbf{JTreeformer}，因为它将图生成转化为枢纽树生成。该框架将GCN与多头注意力机制并行用于编码器。它将有向无环GCN整合到基于图的变压器中作为解码器，可以在每个步骤中通过利用部分构建的分子结构的信息，逐步合成整个分子。此外，在编码器生成的潜在空间中插入了一个扩散模型，以增强采样的效率和有效性。实证结果表明，我们提出的新型框架优于现有的分子生成方法，从而提供了一种促进药物发现的强大工具。', 'title_zh': 'JTreeformer：基于潜在扩散模型的图变压器分子生成'}
{'arxiv_id': 'arXiv:2504.20752', 'title': 'Grokking in the Wild: Data Augmentation for Real-World Multi-Hop Reasoning with Transformers', 'authors': 'Roman Abramov, Felix Steinbauer, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2504.20752', 'abstract': 'Transformers have achieved great success in numerous NLP tasks but continue to exhibit notable gaps in multi-step factual reasoning, especially when real-world knowledge is sparse. Recent advances in grokking have demonstrated that neural networks can transition from memorizing to perfectly generalizing once they detect underlying logical patterns - yet these studies have primarily used small, synthetic tasks. In this paper, for the first time, we extend grokking to real-world factual data and address the challenge of dataset sparsity by augmenting existing knowledge graphs with carefully designed synthetic data to raise the ratio $\\phi_r$ of inferred facts to atomic facts above the threshold required for grokking. Surprisingly, we find that even factually incorrect synthetic data can strengthen emergent reasoning circuits rather than degrade accuracy, as it forces the model to rely on relational structure rather than memorization. When evaluated on multi-hop reasoning benchmarks, our approach achieves up to 95-100% accuracy on 2WikiMultiHopQA - substantially improving over strong baselines and matching or exceeding current state-of-the-art results. We further provide an in-depth analysis of how increasing $\\phi_r$ drives the formation of generalizing circuits inside Transformers. Our findings suggest that grokking-based data augmentation can unlock implicit multi-hop reasoning capabilities, opening the door to more robust and interpretable factual reasoning in large-scale language models.', 'abstract_zh': 'Transformer模型在众多NLP任务中取得了巨大成功，但在多步事实推理方面仍然存在明显差距，尤其是在现实世界知识稀少的情况下。最近关于“理解”（grokking）的研究表明，神经网络一旦检测到潜在的逻辑模式，就能从记忆过渡到完美泛化——然而，这些研究主要使用的是小型合成任务。在本文中，我们首次将“理解”扩展到真实世界事实数据，并通过结合精心设计的合成数据来增强现有的知识图谱，以提高推断事实与原子事实的比例$\\phi_r$，使其超过“理解”所需的阈值。令人惊讶的是，即使是有事实错误的合成数据也可以加强涌现的推理电路，而不是降低准确率，因为这迫使模型依赖于关系结构而不是记忆。在多跳推理基准上的评估显示，我们的方法在2WikiMultiHopQA上的准确率可以达到95%-100%，显著优于强基线，并且与当前的最优结果相当或超越。我们进一步深入分析了提高$\\phi_r$如何驱动Transformer内部形成泛化电路。我们的研究结果表明，“理解”基础上的数据增强可以解锁隐含的多跳推理能力，为大规模语言模型提供了更 robust 和可解释的事实推理潜力。', 'title_zh': '野仿中的融会贯通：数据扩增在实际多跳推理中的应用'}
{'arxiv_id': 'arXiv:2504.20741', 'title': 'In defence of post-hoc explanations in medical AI', 'authors': 'Joshua Hatherley, Lauritz Munch, Jens Christian Bjerring', 'link': 'https://arxiv.org/abs/2504.20741', 'abstract': 'Since the early days of the Explainable AI movement, post-hoc explanations have been praised for their potential to improve user understanding, promote trust, and reduce patient safety risks in black box medical AI systems. Recently, however, critics have argued that the benefits of post-hoc explanations are greatly exaggerated since they merely approximate, rather than replicate, the actual reasoning processes that black box systems take to arrive at their outputs. In this article, we aim to defend the value of post-hoc explanations against this recent critique. We argue that even if post-hoc explanations do not replicate the exact reasoning processes of black box systems, they can still improve users\' functional understanding of black box systems, increase the accuracy of clinician-AI teams, and assist clinicians in justifying their AI-informed decisions. While post-hoc explanations are not a "silver bullet" solution to the black box problem in medical AI, we conclude that they remain a useful strategy for addressing the black box problem in medical AI.', 'abstract_zh': '自可解释AI运动早期以来，事后的解释因其有潜力改善用户理解、促进信任并降低黑盒医疗AI系统中的患者安全风险而受到 praise。然而，最近的批评者认为，事后解释的好处被极大地夸大了，因为它们只是近似而非复制黑盒系统实际采用的推理过程。在本文中，我们旨在反驳这一最近的批评。我们认为，即使事后解释不能完全复制黑盒系统的推理过程，它们仍然可以提高用户对黑盒系统的功能性理解，增加临床医生-AI团队的准确性，并帮助临床医生为其基于AI的决策提供正当理由。尽管事后解释并非解决医疗AI黑盒问题的“万能药”，但我们可以得出结论，它们仍然是处理医疗AI黑盒问题的一种有用策略。', 'title_zh': '论医学AI的事后解释辩护'}
{'arxiv_id': 'arXiv:2504.20733', 'title': 'Unsupervised Surrogate Anomaly Detection', 'authors': 'Simon Klüttermann, Tim Katzke, Emmanuel Müller', 'link': 'https://arxiv.org/abs/2504.20733', 'abstract': 'In this paper, we study unsupervised anomaly detection algorithms that learn a neural network representation, i.e. regular patterns of normal data, which anomalies are deviating from. Inspired by a similar concept in engineering, we refer to our methodology as surrogate anomaly detection. We formalize the concept of surrogate anomaly detection into a set of axioms required for optimal surrogate models and propose a new algorithm, named DEAN (Deep Ensemble ANomaly detection), designed to fulfill these criteria. We evaluate DEAN on 121 benchmark datasets, demonstrating its competitive performance against 19 existing methods, as well as the scalability and reliability of our method.', 'abstract_zh': '在本文中，我们研究了一种无监督异常检测算法，该算法学习神经网络表示，即正常数据的常规模式，异常则是偏离这些模式。受工程中类似概念的启发，我们将这种方法称为代理异常检测。我们将代理异常检测的概念形式化为构建最优代理模型所需的一组公理，并提出了一种新算法，名为DEAN（Deep Ensemble ANomaly检测），旨在满足这些要求。我们在121个基准数据集上评估了DEAN，展示了其在与19种现有方法竞争中的性能，以及我们方法的可扩展性和可靠性。', 'title_zh': '无监督代理异常检测'}
{'arxiv_id': 'arXiv:2504.20726', 'title': 'Enhancing Vulnerability Reports with Automated and Augmented Description Summarization', 'authors': 'Hattan Althebeiti, Mohammed Alkinoon, Manar Mohaisen, Saeed Salem, DaeHun Nyang, David Mohaisen', 'link': 'https://arxiv.org/abs/2504.20726', 'abstract': 'Public vulnerability databases, such as the National Vulnerability Database (NVD), document vulnerabilities and facilitate threat information sharing. However, they often suffer from short descriptions and outdated or insufficient information. In this paper, we introduce Zad, a system designed to enrich NVD vulnerability descriptions by leveraging external resources. Zad consists of two pipelines: one collects and filters supplementary data using two encoders to build a detailed dataset, while the other fine-tunes a pre-trained model on this dataset to generate enriched descriptions. By addressing brevity and improving content quality, Zad produces more comprehensive and cohesive vulnerability descriptions. We evaluate Zad using standard summarization metrics and human assessments, demonstrating its effectiveness in enhancing vulnerability information.', 'abstract_zh': '基于外部资源丰富国家安全漏洞数据库描述的Zad系统', 'title_zh': '增强漏洞报告的自动化和增强描述总结'}
{'arxiv_id': 'arXiv:2504.20658', 'title': 'TrueFake: A Real World Case Dataset of Last Generation Fake Images also Shared on Social Networks', 'authors': "Stefano Dell'Anna, Andrea Montibeller, Giulia Boato", 'link': 'https://arxiv.org/abs/2504.20658', 'abstract': 'AI-generated synthetic media are increasingly used in real-world scenarios, often with the purpose of spreading misinformation and propaganda through social media platforms, where compression and other processing can degrade fake detection cues. Currently, many forensic tools fail to account for these in-the-wild challenges. In this work, we introduce TrueFake, a large-scale benchmarking dataset of 600,000 images including top notch generative techniques and sharing via three different social networks. This dataset allows for rigorous evaluation of state-of-the-art fake image detectors under very realistic and challenging conditions. Through extensive experimentation, we analyze how social media sharing impacts detection performance, and identify current most effective detection and training strategies. Our findings highlight the need for evaluating forensic models in conditions that mirror real-world use.', 'abstract_zh': 'AI生成的合成媒体在现实场景中越来越频繁地被用于通过社交 media 平台传播 misinformation 和 propaganda，压缩和其他处理会削弱假信息检测线索。当前，许多鉴真工具未能应对这些现实生活中的挑战。在此项工作中，我们引入了 TrueFake，这是一个包含600,000张图像的大规模基准数据集，这些图像采用了顶级生成技术并通过三个不同的社交网络分享。该数据集在非常现实和具有挑战性的条件下，允许对最先进的假图像检测器进行严格的评估。通过广泛的实验，我们分析了社交 media 分享对检测性能的影响，并识别了当前最有效的检测和训练策略。我们的发现强调了在模拟现实世界使用条件下来评估鉴真模型的必要性。', 'title_zh': 'TrueFake：last generation fake images also shared on social networks的现实世界案例数据集'}
{'arxiv_id': 'arXiv:2504.20656', 'title': 'Federated learning, ethics, and the double black box problem in medical AI', 'authors': 'Joshua Hatherley, Anders Søgaard, Angela Ballantyne, Ruben Pauwels', 'link': 'https://arxiv.org/abs/2504.20656', 'abstract': 'Federated learning (FL) is a machine learning approach that allows multiple devices or institutions to collaboratively train a model without sharing their local data with a third-party. FL is considered a promising way to address patient privacy concerns in medical artificial intelligence. The ethical risks of medical FL systems themselves, however, have thus far been underexamined. This paper aims to address this gap. We argue that medical FL presents a new variety of opacity -- federation opacity -- that, in turn, generates a distinctive double black box problem in healthcare AI. We highlight several instances in which the anticipated benefits of medical FL may be exaggerated, and conclude by highlighting key challenges that must be overcome to make FL ethically feasible in medicine.', 'abstract_zh': '联邦学习：医学中的新 opacity 问题与伦理挑战', 'title_zh': '联邦学习、伦理与医疗AI中的双重黑箱问题'}
{'arxiv_id': 'arXiv:2504.20634', 'title': 'On Stochastic Rounding with Few Random Bits', 'authors': 'Andrew Fitzgibbon, Stephen Felix', 'link': 'https://arxiv.org/abs/2504.20634', 'abstract': "Large-scale numerical computations make increasing use of low-precision (LP) floating point formats and mixed precision arithmetic, which can be enhanced by the technique of stochastic rounding (SR), that is, rounding an intermediate high-precision value up or down randomly as a function of the value's distance to the two rounding candidates. Stochastic rounding requires, in addition to the high-precision input value, a source of random bits. As the provision of high-quality random bits is an additional computational cost, it is of interest to require as few bits as possible while maintaining the desirable properties of SR in a given computation, or computational domain. This paper examines a number of possible implementations of few-bit stochastic rounding (FBSR), and shows how several natural implementations can introduce sometimes significant bias into the rounding process, which are not present in the case of infinite-bit, infinite-precision examinations of these implementations. The paper explores the impact of these biases in machine learning examples, and hence opens another class of configuration parameters of which practitioners should be aware when developing or adopting low-precision floating point. Code is available at this http URL.", 'abstract_zh': '小型位数随机舍入方法的研究及其在机器学习中的影响分析', 'title_zh': '带少量随机位的随机舍入'}
{'arxiv_id': 'arXiv:2504.20625', 'title': 'DiffusionRIR: Room Impulse Response Interpolation using Diffusion Models', 'authors': 'Sagi Della Torre, Mirco Pezzoli, Fabio Antonacci, Sharon Gannot', 'link': 'https://arxiv.org/abs/2504.20625', 'abstract': "Room Impulse Responses (RIRs) characterize acoustic environments and are crucial in multiple audio signal processing tasks. High-quality RIR estimates drive applications such as virtual microphones, sound source localization, augmented reality, and data augmentation. However, obtaining RIR measurements with high spatial resolution is resource-intensive, making it impractical for large spaces or when dense sampling is required. This research addresses the challenge of estimating RIRs at unmeasured locations within a room using Denoising Diffusion Probabilistic Models (DDPM). Our method leverages the analogy between RIR matrices and image inpainting, transforming RIR data into a format suitable for diffusion-based reconstruction.\nUsing simulated RIR data based on the image method, we demonstrate our approach's effectiveness on microphone arrays of different curvatures, from linear to semi-circular. Our method successfully reconstructs missing RIRs, even in large gaps between microphones. Under these conditions, it achieves accurate reconstruction, significantly outperforming baseline Spline Cubic Interpolation in terms of Normalized Mean Square Error and Cosine Distance between actual and interpolated RIRs.\nThis research highlights the potential of using generative models for effective RIR interpolation, paving the way for generating additional data from limited real-world measurements.", 'abstract_zh': '基于去噪扩散概率模型的房间冲激响应插值研究', 'title_zh': 'DiffusionRIR：基于扩散模型的房间冲激响应插值'}
{'arxiv_id': 'arXiv:2504.20566', 'title': 'Inclusive Training Separation and Implicit Knowledge Interaction for Balanced Online Class-Incremental Learning', 'authors': 'Shunjie Wen, Thomas Heinis, Dong-Wan Choi', 'link': 'https://arxiv.org/abs/2504.20566', 'abstract': 'Online class-incremental learning (OCIL) focuses on gradually learning new classes (called plasticity) from a stream of data in a single-pass, while concurrently preserving knowledge of previously learned classes (called stability). The primary challenge in OCIL lies in maintaining a good balance between the knowledge of old and new classes within the continually updated model. Most existing methods rely on explicit knowledge interaction through experience replay, and often employ exclusive training separation to address bias problems. Nevertheless, it still remains a big challenge to achieve a well-balanced learner, as these methods often exhibit either reduced plasticity or limited stability due to difficulties in continually integrating knowledge in the OCIL setting. In this paper, we propose a novel replay-based method, called Balanced Online Incremental Learning (BOIL), which can achieve both high plasticity and stability, thus ensuring more balanced performance in OCIL. Our BOIL method proposes an inclusive training separation strategy using dual classifiers so that knowledge from both old and new classes can effectively be integrated into the model, while introducing implicit approaches for transferring knowledge across the two classifiers. Extensive experimental evaluations over three widely-used OCIL benchmark datasets demonstrate the superiority of BOIL, showing more balanced yet better performance compared to state-of-the-art replay-based OCIL methods.', 'abstract_zh': '基于重演的平衡在线增量学习（BOIL）', 'title_zh': '包容性训练分离与隐式知识交互以实现平衡在线类增量学习'}
{'arxiv_id': 'arXiv:2504.20560', 'title': 'Generate more than one child in your co-evolutionary semi-supervised learning GAN', 'authors': 'Francisco Sedeño, Jamal Toutouh, Francisco Chicano', 'link': 'https://arxiv.org/abs/2504.20560', 'abstract': 'Generative Adversarial Networks (GANs) are very useful methods to address semi-supervised learning (SSL) datasets, thanks to their ability to generate samples similar to real data. This approach, called SSL-GAN has attracted many researchers in the last decade. Evolutionary algorithms have been used to guide the evolution and training of SSL-GANs with great success. In particular, several co-evolutionary approaches have been applied where the two networks of a GAN (the generator and the discriminator) are evolved in separate populations. The co-evolutionary approaches published to date assume some spatial structure of the populations, based on the ideas of cellular evolutionary algorithms. They also create one single individual per generation and follow a generational replacement strategy in the evolution. In this paper, we re-consider those algorithmic design decisions and propose a new co-evolutionary approach, called Co-evolutionary Elitist SSL-GAN (CE-SSLGAN), with panmictic population, elitist replacement, and more than one individual in the offspring. We evaluate the performance of our proposed method using three standard benchmark datasets. The results show that creating more than one offspring per population and using elitism improves the results in comparison with a classical SSL-GAN.', 'abstract_zh': 'Generative Adversarial Networks (GANs)在半监督学习（SSL）数据集中的应用：一种基于随机交配群体、精英替换及多个体的协同演化方法（Co-evolutionary Elitist SSL-GAN）', 'title_zh': '在你的共进化半监督学习GAN中生成多个子代'}
{'arxiv_id': 'arXiv:2504.20482', 'title': "Group Relative Knowledge Distillation: Learning from Teacher's Relational Inductive Bias", 'authors': 'Chao Li, Changhua Zhou, Jia Chen', 'link': 'https://arxiv.org/abs/2504.20482', 'abstract': "Knowledge distillation typically transfers knowledge from a teacher model to a student model by minimizing differences between their output distributions. However, existing distillation approaches largely focus on mimicking absolute probabilities and neglect the valuable relational inductive biases embedded in the teacher's relative predictions, leading to exposure bias. In this paper, we propose Group Relative Knowledge Distillation (GRKD), a novel framework that distills teacher knowledge by learning the relative ranking among classes, rather than directly fitting the absolute distribution. Specifically, we introduce a group relative loss that encourages the student model to preserve the pairwise preference orderings provided by the teacher's outputs. Extensive experiments on classification benchmarks demonstrate that GRKD achieves superior generalization compared to existing methods, especially in tasks requiring fine-grained class differentiation. Our method provides a new perspective on exploiting teacher knowledge, focusing on relational structure rather than absolute likelihood.", 'abstract_zh': 'Group Relative Knowledge Distillation', 'title_zh': '组相关知识蒸馏：学习老师的关系归纳偏置'}
{'arxiv_id': 'arXiv:2504.20471', 'title': 'The Estimation of Continual Causal Effect for Dataset Shifting Streams', 'authors': 'Baining Chen, Yiming Zhang, Yuqiao Han, Ruyue Zhang, Ruihuan Du, Zhishuo Zhou, Zhengdan Zhu, Xun Liu, Jiecheng Guo', 'link': 'https://arxiv.org/abs/2504.20471', 'abstract': 'Causal effect estimation has been widely used in marketing optimization. The framework of an uplift model followed by a constrained optimization algorithm is popular in practice. To enhance performance in the online environment, the framework needs to be improved to address the complexities caused by temporal dataset shift. This paper focuses on capturing the dataset shift from user behavior and domain distribution changing over time. We propose an Incremental Causal Effect with Proxy Knowledge Distillation (ICE-PKD) framework to tackle this challenge. The ICE-PKD framework includes two components: (i) a multi-treatment uplift network that eliminates confounding bias using counterfactual regression; (ii) an incremental training strategy that adapts to the temporal dataset shift by updating with the latest data and protects generalization via replay-based knowledge distillation. We also revisit the uplift modeling metrics and introduce a novel metric for more precise online evaluation in multiple treatment scenarios. Extensive experiments on both simulated and online datasets show that the proposed framework achieves better performance. The ICE-PKD framework has been deployed in the marketing system of Huaxiaozhu, a ride-hailing platform in China.', 'abstract_zh': '增量因果效应与代理知识蒸馏框架（ICE-PKD）在营销优化中的应用', 'title_zh': '持续因果效应估计在数据集迁移流中的应用'}
{'arxiv_id': 'arXiv:2504.20447', 'title': 'APG-MOS: Auditory Perception Guided-MOS Predictor for Synthetic Speech', 'authors': 'Zhicheng Lian, Lizhi Wang, Hua Huang', 'link': 'https://arxiv.org/abs/2504.20447', 'abstract': 'Automatic speech quality assessment aims to quantify subjective human perception of speech through computational models to reduce the need for labor-consuming manual evaluations. While models based on deep learning have achieved progress in predicting mean opinion scores (MOS) to assess synthetic speech, the neglect of fundamental auditory perception mechanisms limits consistency with human judgments. To address this issue, we propose an auditory perception guided-MOS prediction model (APG-MOS) that synergistically integrates auditory modeling with semantic analysis to enhance consistency with human judgments. Specifically, we first design a perceptual module, grounded in biological auditory mechanisms, to simulate cochlear functions, which encodes acoustic signals into biologically aligned electrochemical representations. Secondly, we propose a residual vector quantization (RVQ)-based semantic distortion modeling method to quantify the degradation of speech quality at the semantic level. Finally, we design a residual cross-attention architecture, coupled with a progressive learning strategy, to enable multimodal fusion of encoded electrochemical signals and semantic representations. Experiments demonstrate that APG-MOS achieves superior performance on two primary benchmarks. Our code and checkpoint will be available on a public repository upon publication.', 'abstract_zh': '自动语音质量评估旨在通过计算模型量化人类对语音的主观感知，减少劳动密集型的手动评估需求。尽管基于深度学习的模型在预测平均意见分（MOS）以评估合成语音方面取得了进展，但忽视了基本的听觉感知机制限制了与人类判断的一致性。为解决这一问题，我们提出了一种听觉感知引导的MOS预测模型（APG-MOS），该模型结合了听觉建模与语义分析，以增强与人类判断的一致性。具体而言，我们首先设计了一个感知模块，基于生物听觉机制，模拟耳蜗功能，将声学信号编码为生物对齐的电化学表示。其次，我们提出了一种残差向量量化（RVQ）为基础的语义失真建模方法，以在语义层面上量化语音质量的退化。最后，我们设计了一种残差交叉注意力架构，结合逐步学习策略，以实现电化学信号和语义表示的多模态融合。实验表明，APG-MOS在两个主要基准上取得了优越的性能。我们的代码和检查点将在发表后提交到公共存储库。', 'title_zh': 'APG-MOS: 听觉感知引导的合成语音MOS预测器'}
{'arxiv_id': 'arXiv:2504.20434', 'title': 'ARCS: Agentic Retrieval-Augmented Code Synthesis with Iterative Refinement', 'authors': "Manish Bhattarai, Miguel Cordova, Javier Santos, Dan O'Malley", 'link': 'https://arxiv.org/abs/2504.20434', 'abstract': 'In supercomputing, efficient and optimized code generation is essential to leverage high-performance systems effectively. We propose Agentic Retrieval-Augmented Code Synthesis (ARCS), an advanced framework for accurate, robust, and efficient code generation, completion, and translation. ARCS integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (CoT) reasoning to systematically break down and iteratively refine complex programming tasks. An agent-based RAG mechanism retrieves relevant code snippets, while real-time execution feedback drives the synthesis of candidate solutions. This process is formalized as a state-action search tree optimization, balancing code correctness with editing efficiency. Evaluations on the Geeks4Geeks and HumanEval benchmarks demonstrate that ARCS significantly outperforms traditional prompting methods in translation and generation quality. By enabling scalable and precise code synthesis, ARCS offers transformative potential for automating and optimizing code development in supercomputing applications, enhancing computational resource utilization.', 'abstract_zh': '在超级计算中，高效的代码生成是充分利用高性能系统的关键。我们提出了一种名为Agentic Retrieval-Augmented Code Synthesis (ARCS)的先进框架，该框架旨在实现准确、可靠和高效的代码生成、完成和翻译。ARCS将检索增强生成（RAG）与推理链（CoT）推理相结合，系统地分解和迭代细化复杂的编程任务。基于代理的RAG机制检索相关代码片段，实时执行反馈驱动候选解决方案的合成。这一过程被形式化为状态-动作搜索树优化，平衡代码正确性和编辑效率。ARCS在Geeks4Geeks和HumanEval基准上的评估结果显示，它在翻译和生成质量方面显著优于传统的提示方法。通过提供可扩展且精确的代码合成，ARCS为超级计算应用中的自动化和优化代码开发提供了变革性的潜力，提高了计算资源的利用效率。', 'title_zh': 'ARCS: 自动驱动的检索增强代码合成与迭代 refinement'}
{'arxiv_id': 'arXiv:2504.20412', 'title': 'CrashFixer: A crash resolution agent for the Linux kernel', 'authors': 'Alex Mathai, Chenxi Huang, Suwei Ma, Jihwan Kim, Hailie Mitchell, Aleksandr Nogikh, Petros Maniatis, Franjo Ivančić, Junfeng Yang, Baishakhi Ray', 'link': 'https://arxiv.org/abs/2504.20412', 'abstract': "Code large language models (LLMs) have shown impressive capabilities on a multitude of software engineering tasks. In particular, they have demonstrated remarkable utility in the task of code repair. However, common benchmarks used to evaluate the performance of code LLMs are often limited to small-scale settings. In this work, we build upon kGym, which shares a benchmark for system-level Linux kernel bugs and a platform to run experiments on the Linux kernel.\nThis paper introduces CrashFixer, the first LLM-based software repair agent that is applicable to Linux kernel bugs. Inspired by the typical workflow of a kernel developer, we identify the key capabilities an expert developer leverages to resolve a kernel crash. Using this as our guide, we revisit the kGym platform and identify key system improvements needed to practically run LLM-based agents at the scale of the Linux kernel (50K files and 20M lines of code). We implement these changes by extending kGym to create an improved platform - called kGymSuite, which will be open-sourced. Finally, the paper presents an evaluation of various repair strategies for such complex kernel bugs and showcases the value of explicitly generating a hypothesis before attempting to fix bugs in complex systems such as the Linux kernel. We also evaluated CrashFixer's capabilities on still open bugs, and found at least two patch suggestions considered plausible to resolve the reported bug.", 'abstract_zh': '代码大型语言模型在软件工程任务中的应用已经展现出令人印象深刻的性能，特别是在代码修复任务中表现出色。然而，用于评估代码大型语言模型性能的常见基准往往局限于小规模设置。在本文中，我们基于kGym构建，kGym提供了一个系统级Linux内核漏洞基准以及在Linux内核上运行实验的平台。本文介绍了CrashFixer，这是首个适用于Linux内核漏洞的基于大型语言模型的软件修复代理。受到内核开发者的典型工作流程启发，我们识别了专家开发者解决内核崩溃时所依赖的关键能力。通过这一指导原则，我们重新审视了kGym平台，并确定了在Linux内核规模（50K文件和20M行代码）下实际运行基于大型语言模型代理所需的关键系统改进。我们通过扩展kGym创建了一个改进的平台kGymSuite，并将开源。最后，本文评估了针对此类复杂内核漏洞的各种修复策略，并展示了在复杂系统如Linux内核中明确生成假设以尝试修复漏洞的价值。同时，我们还对CrashFixer的能力进行了评估，发现至少有两个补丁建议被认为是解决已报告漏洞的有效方案。', 'title_zh': 'CrashFixer：Linux内核的故障解决代理'}
{'arxiv_id': 'arXiv:2504.20408', 'title': 'FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation', 'authors': 'Jae Yong Lee, Gwang Jae Jung, Byung Chan Lim, Hyung Ju Hwang', 'link': 'https://arxiv.org/abs/2504.20408', 'abstract': 'The Boltzmann equation, a fundamental model in kinetic theory, describes the evolution of particle distribution functions through a nonlinear, high-dimensional collision operator. However, its numerical solution remains computationally demanding, particularly for inelastic collisions and high-dimensional velocity domains. In this work, we propose the Fourier Neural Spectral Network (FourierSpecNet), a hybrid framework that integrates the Fourier spectral method with deep learning to approximate the collision operator in Fourier space efficiently. FourierSpecNet achieves resolution-invariant learning and supports zero-shot super-resolution, enabling accurate predictions at unseen resolutions without retraining. Beyond empirical validation, we establish a consistency result showing that the trained operator converges to the spectral solution as the discretization is refined. We evaluate our method on several benchmark cases, including Maxwellian and hard-sphere molecular models, as well as inelastic collision scenarios. The results demonstrate that FourierSpecNet offers competitive accuracy while significantly reducing computational cost compared to traditional spectral solvers. Our approach provides a robust and scalable alternative for solving the Boltzmann equation across both elastic and inelastic regimes.', 'abstract_zh': 'Fourier神经谱网络（FourierSpecNet）：傅里叶空间中的谱方法与深度学习的结合', 'title_zh': 'FourierSpecNet：基于傅里叶频谱方法的玻尔兹曼方程神经碰撞算子逼近'}
{'arxiv_id': 'arXiv:2504.20368', 'title': 'AKIBoards: A Structure-Following Multiagent System for Predicting Acute Kidney Injury', 'authors': 'David Gordon, Panayiotis Petousis, Susanne B. Nicholas, Alex A.T. Bui', 'link': 'https://arxiv.org/abs/2504.20368', 'abstract': "Diagnostic reasoning entails a physician's local (mental) model based on an assumed or known shared perspective (global model) to explain patient observations with evidence assigned towards a clinical assessment. But in several (complex) medical situations, multiple experts work together as a team to optimize health evaluation and decision-making by leveraging different perspectives. Such consensus-driven reasoning reflects individual knowledge contributing toward a broader perspective on the patient. In this light, we introduce STRUCture-following for Multiagent Systems (STRUC-MAS), a framework automating the learning of these global models and their incorporation as prior beliefs for agents in multiagent systems (MAS) to follow. We demonstrate proof of concept with a prosocial MAS application for predicting acute kidney injuries (AKIs). In this case, we found that incorporating a global structure enabled multiple agents to achieve better performance (average precision, AP) in predicting AKI 48 hours before onset (structure-following-fine-tuned, SF-FT, AP=0.195; SF-FT-retrieval-augmented generation, SF-FT-RAG, AP=0.194) vs. baseline (non-structure-following-FT, NSF-FT, AP=0.141; NSF-FT-RAG, AP=0.180) for balanced precision-weighted-recall-weighted voting. Markedly, SF-FT agents with higher recall scores reported lower confidence levels in the initial round on true positive and false negative cases. But after explicit interactions, their confidence in their decisions increased (suggesting reinforced belief). In contrast, the SF-FT agent with the lowest recall decreased its confidence in true positive and false negative cases (suggesting a new belief). This approach suggests that learning and leveraging global structures in MAS is necessary prior to achieving competitive classification and diagnostic reasoning performance.", 'abstract_zh': '基于结构跟随的多智能体系统框架（STRUC-MAS）及其在预测急性肾损伤中的应用', 'title_zh': 'AKIBoards: 遵循结构设计的多智能体系统用于预测急性肾损伤'}
{'arxiv_id': 'arXiv:2504.20357', 'title': 'Automated Unit Test Case Generation: A Systematic Literature Review', 'authors': 'Jason Wang, Basem Suleiman, Muhammad Johan Alibasa', 'link': 'https://arxiv.org/abs/2504.20357', 'abstract': 'Software is omnipresent within all factors of society. It is thus important to ensure that software are well tested to mitigate bad user experiences as well as the potential for severe financial and human losses. Software testing is however expensive and absorbs valuable time and resources. As a result, the field of automated software testing has grown of interest to researchers in past decades. In our review of present and past research papers, we have identified an information gap in the areas of improvement for the Genetic Algorithm and Particle Swarm Optimisation. A gap in knowledge in the current challenges that face automated testing has also been identified. We therefore present this systematic literature review in an effort to consolidate existing knowledge in regards to the evolutionary approaches as well as their improvements and resulting limitations. These improvements include hybrid algorithm combinations as well as interoperability with mutation testing and neural networks. We will also explore the main test criterion that are used in these algorithms alongside the challenges currently faced in the field related to readability, mocking and more.', 'abstract_zh': '软件无处不在，遍及社会各个层面。因此，确保软件经过充分测试以减轻不良用户体验以及潜在的严重财务和人员损失至关重要。然而，软件测试成本高昂，耗时且耗资源。由于这一原因，过去几十年中，自动软件测试领域的研究引起了研究人员的兴趣。在我们对现有和过去的研究论文的回顾中，我们发现了一个关于遗传算法和粒子群优化改善领域的信息空白。我们还发现当前自动测试面临的知识空白。因此，我们呈现这一系统文献综述，旨在整合关于进化方法及其改进和后续限制的现有知识。这些改进包括混合算法组合以及与变异测试和神经网络的互操作性。我们还将探讨这些算法中使用的主要测试标准及其相关领域面临的挑战，例如可读性、模拟等方面的问题。', 'title_zh': '自动单元测试用例生成：一项系统文献综述'}
{'arxiv_id': 'arXiv:2504.20342', 'title': 'Narrative-Centered Emotional Reflection: Scaffolding Autonomous Emotional Literacy with AI', 'authors': 'Shou-Tzu Han', 'link': 'https://arxiv.org/abs/2504.20342', 'abstract': 'Reflexion is an AI-powered platform designed to enable structured emotional self-reflection at scale. By integrating real-time emotion detection, layered reflective prompting, and metaphorical storytelling generation, Reflexion empowers users to engage in autonomous emotional exploration beyond basic sentiment categorization. Grounded in theories of expressive writing, cognitive restructuring, self-determination, and critical consciousness development, the system scaffolds a progressive journey from surface-level emotional recognition toward value-aligned action planning. Initial pilot studies with diverse participants demonstrate positive outcomes in emotional articulation, cognitive reframing, and perceived psychological resilience. Reflexion represents a promising direction for scalable, theory-informed affective computing interventions aimed at fostering emotional literacy and psychological growth across educational, therapeutic, and public health contexts.', 'abstract_zh': '反射平台是一款基于AI的情感结构化自我反思平台，通过集成实时情绪检测、分层反思提示和比喻性叙事生成，赋能用户超越基本情感分类进行自主情绪探索。该系统基于表达写作理论、认知重构、自我决定和批判性意识发展的理论，构建了一条从表面情绪识别向价值观一致的行动规划的渐进式旅程。初步多元参与者试点研究表明，该平台在情绪表达、认知重构和心理韧性的感知方面具有积极效果。反射平台代表了针对教育、治疗和公共卫生等领域促进情绪素养和心理成长的大规模、理论导向的情感计算干预的一个有前景的方向。', 'title_zh': '以叙事为中心的情感反思：借助AI搭建自主情感 literacy 的支架'}
{'arxiv_id': 'arXiv:2504.20323', 'title': 'Labeling Case Similarity based on Co-Citation of Legal Articles in Judgment Documents with Empirical Dispute-Based Evaluation', 'authors': 'Chao-Lin Liu, Po-Hsien Wu, Yi-Ting Yu', 'link': 'https://arxiv.org/abs/2504.20323', 'abstract': "This report addresses the challenge of limited labeled datasets for developing legal recommender systems, particularly in specialized domains like labor disputes. We propose a new approach leveraging the co-citation of legal articles within cases to establish similarity and enable algorithmic annotation. This method draws a parallel to the concept of case co-citation, utilizing cited precedents as indicators of shared legal issues. To evaluate the labeled results, we employ a system that recommends similar cases based on plaintiffs' accusations, defendants' rebuttals, and points of disputes. The evaluation demonstrates that the recommender, with finetuned text embedding models and a reasonable BiLSTM module can recommend labor cases whose similarity was measured by the co-citation of the legal articles. This research contributes to the development of automated annotation techniques for legal documents, particularly in areas with limited access to comprehensive legal databases.", 'abstract_zh': '本报告探讨了在劳动争议等专门领域开发法律推荐系统时遭遇的有限标注数据集挑战。我们提出了一种新的方法，利用案例中法律文章的共引关系来建立相似性并实现算法标注。该方法借鉴了案例共引的概念，通过引用先例作为共享法律问题的指标。为评估标注结果，我们采用一个系统，基于原告的指控、被告的反驳和争议点推荐相似案例。评估结果显示，通过微调的文本嵌入模型和合理的BiLSTM模块，推荐系统的相似案例可以通过法律文章的共引关系进行衡量。本研究为法律文件的自动标注技术开发，特别是在法律数据库访问受限的领域，提供了贡献。', 'title_zh': '基于判决文书中共引法律文章的案件相似性标注：基于实证争议的评价'}
{'arxiv_id': 'arXiv:2504.20314', 'title': 'Perturbation-efficient Zeroth-order Optimization for Hardware-friendly On-device Training', 'authors': 'Qitao Tan, Sung-En Chang, Rui Xia, Huidong Ji, Chence Yang, Ci Zhang, Jun Liu, Zheng Zhan, Zhou Zou, Yanzhi Wang, Jin Lu, Geng Yuan', 'link': 'https://arxiv.org/abs/2504.20314', 'abstract': 'Zeroth-order (ZO) optimization is an emerging deep neural network (DNN) training paradigm that offers computational simplicity and memory savings. However, this seemingly promising approach faces a significant and long-ignored challenge. ZO requires generating a substantial number of Gaussian random numbers, which poses significant difficulties and even makes it infeasible for hardware platforms, such as FPGAs and ASICs. In this paper, we identify this critical issue, which arises from the mismatch between algorithm and hardware designers. To address this issue, we proposed PeZO, a perturbation-efficient ZO framework. Specifically, we design random number reuse strategies to significantly reduce the demand for random number generation and introduce a hardware-friendly adaptive scaling method to replace the costly Gaussian distribution with a uniform distribution. Our experiments show that PeZO reduces the required LUTs and FFs for random number generation by 48.6\\% and 12.7\\%, and saves at maximum 86\\% power consumption, all without compromising training performance, making ZO optimization feasible for on-device training. To the best of our knowledge, we are the first to explore the potential of on-device ZO optimization, providing valuable insights for future research.', 'abstract_zh': '基于扰动的零阶优化：一种高效的深度神经网络训练框架', 'title_zh': '硬件友好的设备端训练高效扰动零阶优化'}
{'arxiv_id': 'arXiv:2504.20310', 'title': 'A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning', 'authors': 'Greg Gluch, Shafi Goldwasser', 'link': 'https://arxiv.org/abs/2504.20310', 'abstract': 'In this paper, we initiate a cryptographically inspired theoretical study of detection versus mitigation of adversarial inputs produced by attackers of Machine Learning algorithms during inference time.\nWe formally define defense by detection (DbD) and defense by mitigation (DbM). Our definitions come in the form of a 3-round protocol between two resource-bounded parties: a trainer/defender and an attacker. The attacker aims to produce inference-time inputs that fool the training algorithm. We define correctness, completeness, and soundness properties to capture successful defense at inference time while not degrading (too much) the performance of the algorithm on inputs from the training distribution.\nWe first show that achieving DbD and achieving DbM are equivalent for ML classification tasks. Surprisingly, this is not the case for ML generative learning tasks, where there are many possible correct outputs that can be generated for each input. We show a separation between DbD and DbM by exhibiting a generative learning task for which is possible to defend by mitigation but is provably impossible to defend by detection under the assumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE), publicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK) and Strongly Unforgeable Signatures exist. The mitigation phase uses significantly fewer samples than the initial training algorithm.', 'abstract_zh': '在本论文中，我们启动了一种密码学启发式的理论研究，探讨在机器学习算法推断过程中攻击者生成的 adversarial inputs 的检测与缓解。\n\n我们正式定义了通过检测进行防御（DbD）和通过缓解进行防御（DbM）。我们的定义以两个资源受限方之间的三轮协议形式给出：训练者/防御方和攻击者。攻击者的目标是在推断时生成能够欺骗训练算法的输入。我们定义了正确性、完备性和soundness属性，以捕捉在不显著降低算法在训练分布输入上性能的前提下，推断时成功的防御。\n\n我们首先证明了实现 DbD 和实现 DbM 在机器学习分类任务中是等价的。令人惊讶的是，在生成学习任务中并非如此，因为对于每一个输入，可以生成许多可能的正确输出。我们通过展示一项生成学习任务，其中通过缓解可以进行防御，但在假设存在基于身份的全同态加密（IB-FHE）、公开可验证零知识紧凑简洁交互式知识论证（zk-SNARK）和强不可伪造签名的情况下，证明通过检测进行防御是不可能的。缓解阶段使用的样本数量显著少于初始训练算法。', 'title_zh': '从密码学视角探讨机器学习中的缓解与检测'}
{'arxiv_id': 'arXiv:2504.20304', 'title': 'UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions', 'authors': 'Xiulin Yang, Zhuoxuan Ju, Lanni Bu, Zoey Liu, Nathan Schneider', 'link': 'https://arxiv.org/abs/2504.20304', 'abstract': 'CHILDES is a widely used resource of transcribed child and child-directed speech. This paper introduces UD-English-CHILDES, the first officially released Universal Dependencies (UD) treebank derived from previously dependency-annotated CHILDES data with consistent and unified annotation guidelines. Our corpus harmonizes annotations from 11 children and their caregivers, totaling over 48k sentences. We validate existing gold-standard annotations under the UD v2 framework and provide an additional 1M silver-standard sentences, offering a consistent resource for computational and linguistic research.', 'abstract_zh': 'UD-English-CHILDES：首个基于一致和统一标注准则的CHILDES数据生成的广泛依赖标注语料库', 'title_zh': 'UD-英语-CHILDES：儿童语言互动的优质与标准通用依存树银行'}
{'arxiv_id': 'arXiv:2504.20295', 'title': 'The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting', 'authors': 'Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon-Gutierrez, Andres Caro', 'link': 'https://arxiv.org/abs/2504.20295', 'abstract': 'Digital twins (DTs) are improving water distribution systems by using real-time data, analytics, and prediction models to optimize operations. This paper presents a DT platform designed for a Spanish water supply network, utilizing Long Short-Term Memory (LSTM) networks to predict water consumption. However, machine learning models are vulnerable to adversarial attacks, such as the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD). These attacks manipulate critical model parameters, injecting subtle distortions that degrade forecasting accuracy. To further exploit these vulnerabilities, we introduce a Learning Automata (LA) and Random LA-based approach that dynamically adjusts perturbations, making adversarial attacks more difficult to detect. Experimental results show that this approach significantly impacts prediction reliability, causing the Mean Absolute Percentage Error (MAPE) to rise from 26% to over 35%. Moreover, adaptive attack strategies amplify this effect, highlighting cybersecurity risks in AI-driven DTs. These findings emphasize the urgent need for robust defenses, including adversarial training, anomaly detection, and secure data pipelines.', 'abstract_zh': '数字孪生平台在西班牙供水网络中的实时数据、分析和预测模型优化应用：基于长短时记忆网络的水消耗预测及对抗性攻击防御研究', 'title_zh': '数字孪生的阴暗面：针对AI驱动水资源预报的对抗攻击'}
{'arxiv_id': 'arXiv:2504.20275', 'title': 'Smart Water Security with AI and Blockchain-Enhanced Digital Twins', 'authors': 'Mohammadhossein Homaei, Victor Gonzalez Morales, Oscar Mogollon Gutierrez, Ruben Molano Gomez, Andres Caro', 'link': 'https://arxiv.org/abs/2504.20275', 'abstract': 'Water distribution systems in rural areas face serious challenges such as a lack of real-time monitoring, vulnerability to cyberattacks, and unreliable data handling. This paper presents an integrated framework that combines LoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection System (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure and transparent water management. The IDS filters anomalous or spoofed data using a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before validated data is logged via smart contracts on a private Ethereum blockchain using Proof of Authority (PoA) consensus. The verified data feeds into a real-time DT model supporting leak detection, consumption forecasting, and predictive maintenance. Experimental results demonstrate that the system achieves over 80 transactions per second (TPS) with under 2 seconds of latency while remaining cost-effective and scalable for up to 1,000 smart meters. This work demonstrates a practical and secure architecture for decentralized water infrastructure in under-connected rural environments.', 'abstract_zh': '基于LoRaWAN的数据采集、机器学习驱动的入侵检测系统及区块链赋能的数字孪生平台在农村区域水分配系统的集成框架：安全透明的水管理解决方案', 'title_zh': '智能水安全：AI和区块链增强的数字孪生技术'}
{'arxiv_id': 'arXiv:2504.20251', 'title': 'A Platform for Generating Educational Activities to Teach English as a Second Language', 'authors': 'Aiala Rosá, Santiago Góngora, Juan Pablo Filevich, Ignacio Sastre, Laura Musto, Brian Carpenter, Luis Chiruzzo', 'link': 'https://arxiv.org/abs/2504.20251', 'abstract': 'We present a platform for the generation of educational activities oriented to teaching English as a foreign language. The different activities --games and language practice exercises-- are strongly based on Natural Language Processing techniques. The platform offers the possibility of playing out-of-the-box games, generated from resources created semi-automatically and then manually curated. It can also generate games or exercises of greater complexity from texts entered by teachers, providing a stage of review and edition of the generated content before use. As a way of expanding the variety of activities in the platform, we are currently experimenting with image and text generation. In order to integrate them and improve the performance of other neural tools already integrated, we are working on migrating the platform to a more powerful server. In this paper we describe the development of our platform and its deployment for end users, discussing the challenges faced and how we overcame them, and also detail our future work plans.', 'abstract_zh': '我们提出一个面向foreign language教学的教育活动生成平台。不同活动——游戏和语言练习——强烈依赖于自然语言处理技术。该平台提供了从半自动创建并人工筛选的资源中玩即用游戏的可能性，还可以根据教师输入的文本生成更复杂的游戏或练习，提供生成内容的审查和编辑阶段。为了增加平台活动的多样性，我们目前正在实验图像和文本生成。为了整合它们并提高已经集成的其他神经工具的性能，我们正在致力于将平台迁移至更强大的服务器。在本文中我们描述了该平台的开发及其面向最终用户的部署，讨论了所面临的技术挑战及解决方法，并详细说明了我们的未来工作计划。', 'title_zh': '一个用于教授第二语言英语的教学活动生成平台'}
{'arxiv_id': 'arXiv:2504.20197', 'title': 'Representation Learning on a Random Lattice', 'authors': 'Aryeh Brill', 'link': 'https://arxiv.org/abs/2504.20197', 'abstract': "Decomposing a deep neural network's learned representations into interpretable features could greatly enhance its safety and reliability. To better understand features, we adopt a geometric perspective, viewing them as a learned coordinate system for mapping an embedded data distribution. We motivate a model of a generic data distribution as a random lattice and analyze its properties using percolation theory. Learned features are categorized into context, component, and surface features. The model is qualitatively consistent with recent findings in mechanistic interpretability and suggests directions for future research.", 'abstract_zh': '将深度神经网络学习表示分解为可解释特征能够大幅增强其安全性和可靠性。通过几何视角理解特征，视其为一种嵌入数据分布的learned坐标系。我们将通用数据分布建模为随机晶格，并利用渗流理论分析其性质。学习到的特征被分类为上下文特征、组件特征和表征特征。该模型与近期在机制可解释性方面的发现定性一致，并为未来研究提供了方向。', 'title_zh': '随机晶格上的表示学习'}
{'arxiv_id': 'arXiv:2504.20179', 'title': 'Integration Flow Models', 'authors': 'Jingjing Wang, Dan Zhang, Joshua Luo, Yin Yang, Feng Luo', 'link': 'https://arxiv.org/abs/2504.20179', 'abstract': 'Ordinary differential equation (ODE) based generative models have emerged as a powerful approach for producing high-quality samples in many applications. However, the ODE-based methods either suffer the discretization error of numerical solvers of ODE, which restricts the quality of samples when only a few NFEs are used, or struggle with training instability. In this paper, we proposed Integration Flow, which directly learns the integral of ODE-based trajectory paths without solving the ODE functions. Moreover, Integration Flow explicitly incorporates the target state $\\mathbf{x}_0$ as the anchor state in guiding the reverse-time dynamics. We have theoretically proven this can contribute to both stability and accuracy. To the best of our knowledge, Integration Flow is the first model with a unified structure to estimate ODE-based generative models and the first to show the exact straightness of 1-Rectified Flow without reflow. Through theoretical analysis and empirical evaluations, we show that Integration Flows achieve improved performance when it is applied to existing ODE-based models, such as diffusion models, Rectified Flows, and PFGM++. Specifically, Integration Flow achieves one-step generation on CIFAR10 with FIDs of 2.86 for the Variance Exploding (VE) diffusion model, 3.36 for rectified flow without reflow, and 2.91 for PFGM++; and on ImageNet with FIDs of 4.09 for VE diffusion model, 4.35 for rectified flow without reflow and 4.15 for PFGM++.', 'abstract_zh': '基于常微分方程（ODE）的生成模型已成为在众多应用中生成高质量样本的一种强大方法。然而，基于ODE的方法要么受到数值求解器的离散化误差的限制，这在只使用少量NFE时会限制样本质量，要么难以应对训练中的不稳定性。在本文中，我们提出了积分流（Integration Flow），该方法直接学习ODE轨迹路径的积分，而无需求解ODE函数。此外，积分流显式地将目标状态$\\mathbf{x}_0$作为反向时间动力学中的锚状态进行引导。我们理论上证明了这一点可以提高稳定性和准确性。据我们所知，积分流是第一个具备统一结构来估计基于ODE的生成模型的模型，并且是第一个在不重新耦合的情况下展示1-修正流（1-Rectified Flow）精确直线性的模型。通过理论分析和实验评估，我们表明当积分流应用于现有的基于ODE的模型（如扩散模型、非重耦合修正流和PFGM++）时，可以实现改进的性能。具体而言，积分流在CIFAR10上的结果为：扩散模型（VE）的FID为2.86，非重耦合修正流的FID为3.36，PFGM++的FID为2.91；在ImageNet上的结果为：扩散模型（VE）的FID为4.09，非重耦合修正流的FID为4.35，PFGM++的FID为4.15。', 'title_zh': '集成流程模型'}
{'arxiv_id': 'arXiv:2504.20172', 'title': 'Causal Identification in Time Series Models', 'authors': 'Erik Jahn, Karthik Karnik, Leonard J. Schulman', 'link': 'https://arxiv.org/abs/2504.20172', 'abstract': 'In this paper, we analyze the applicability of the Causal Identification algorithm to causal time series graphs with latent confounders. Since these graphs extend over infinitely many time steps, deciding whether causal effects across arbitrary time intervals are identifiable appears to require computation on graph segments of unbounded size. Even for deciding the identifiability of intervention effects on variables that are close in time, no bound is known on how many time steps in the past need to be considered. We give a first bound of this kind that only depends on the number of variables per time step and the maximum time lag of any direct or latent causal effect. More generally, we show that applying the Causal Identification algorithm to a constant-size segment of the time series graph is sufficient to decide identifiability of causal effects, even across unbounded time intervals.', 'abstract_zh': '本文分析了因果识别算法在具有潜变量共因的因果时间序列图中的适用性。由于这些图跨越无穷多个时间步，决定任意时间区间内的因果效应是否可识别似乎需要对无界大小的图段进行计算。即使对于决定邻近时间变量的干预效应的可识别性，也不知道需要考虑多少个过去的时间步。我们给出了第一种仅依赖每时间步变量数和任何直接或潜变量因果效应的最大时间滞后数的此类界线。更一般地，我们证明了将因果识别算法应用于时间序列图的固定大小段落足以决定因果效应的可识别性，即使在无界时间区间内也是如此。', 'title_zh': '时间序列模型中的因果识别'}
{'arxiv_id': 'arXiv:2504.20168', 'title': 'MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools', 'authors': 'Nishant Subramani, Jason Eisner, Justin Svegliato, Benjamin Van Durme, Yu Su, Sam Thomson', 'link': 'https://arxiv.org/abs/2504.20168', 'abstract': "Tool-using agents that act in the world need to be both useful and safe. Well-calibrated model confidences can be used to weigh the risk versus reward of potential actions, but prior work shows that many models are poorly calibrated. Inspired by interpretability literature exploring the internals of models, we propose a novel class of model-internal confidence estimators (MICE) to better assess confidence when calling tools. MICE first decodes from each intermediate layer of the language model using logitLens and then computes similarity scores between each layer's generation and the final output. These features are fed into a learned probabilistic classifier to assess confidence in the decoded output. On the simulated trial and error (STE) tool-calling dataset using Llama3 models, we find that MICE beats or matches the baselines on smoothed expected calibration error. Using MICE confidences to determine whether to call a tool significantly improves over strong baselines on a new metric, expected tool-calling utility. Further experiments show that MICE is sample-efficient, can generalize zero-shot to unseen APIs, and results in higher tool-calling utility in scenarios with varying risk levels. Our code is open source, available at this https URL.", 'abstract_zh': '面向世界操作的工具使用智能体需要既有效又安全。合适的模型置信度可用于权衡潜在行动的风险与回报，但先前的工作表明许多模型的置信度校准不佳。受可解释性文献中探索模型内部机制的启发，我们提出了一种新型的模型内部置信度估算器（MICE），以更好地评估调用工具时的置信度。MICE 首先使用 logitLens 解码语言模型的每个中间层，并然后计算每一层生成内容与最终输出之间的相似度分数。这些特征被输入一个学习到的概率分类器以评估解码输出的置信度。在使用 Llama3 模型的模拟试错（STE）工具调用数据集上，我们发现 MICE 在平滑化期望校准误差上优于或匹配了基线。使用 MICE 置信度来决定是否调用工具显著提高了在新指标期望工具调用效用上的表现。进一步的实验表明 MICE 是样本效率高的，可以零样本泛化到未见的 API，并在不同风险水平的情景中提高了工具调用效用。我们的代码是开源的，可在此链接访问。', 'title_zh': 'MICE for CATs: 模型内部置信度估计用于校准工具辅助的代理'}
{'arxiv_id': 'arXiv:2504.20124', 'title': 'Pediatric Asthma Detection with Googles HeAR Model: An AI-Driven Respiratory Sound Classifier', 'authors': 'Abul Ehtesham, Saket Kumar, Aditi Singh, Tala Talaei Khoei', 'link': 'https://arxiv.org/abs/2504.20124', 'abstract': 'Early detection of asthma in children is crucial to prevent long-term respiratory complications and reduce emergency interventions. This work presents an AI-powered diagnostic pipeline that leverages Googles Health Acoustic Representations (HeAR) model to detect early signs of asthma from pediatric respiratory sounds. The SPRSound dataset, the first open-access collection of annotated respiratory sounds in children aged 1 month to 18 years, is used to extract 2-second audio segments labeled as wheeze, crackle, rhonchi, stridor, or normal. Each segment is embedded into a 512-dimensional representation using HeAR, a foundation model pretrained on 300 million health-related audio clips, including 100 million cough sounds. Multiple classifiers, including SVM, Random Forest, and MLP, are trained on these embeddings to distinguish between asthma-indicative and normal sounds. The system achieves over 91\\% accuracy, with strong performance on precision-recall metrics for positive cases. In addition to classification, learned embeddings are visualized using PCA, misclassifications are analyzed through waveform playback, and ROC and confusion matrix insights are provided. This method demonstrates that short, low-resource pediatric recordings, when powered by foundation audio models, can enable fast, noninvasive asthma screening. The approach is especially promising for digital diagnostics in remote or underserved healthcare settings.', 'abstract_zh': '基于AI的诊断管道早期检测儿童哮喘 crucial early detection of asthma in children through an AI-powered diagnostic pipeline', 'title_zh': '基于Google的HeAR模型的儿童哮喘检测：一种AI驱动的呼吸音分类器'}
{'arxiv_id': 'arXiv:2504.20114', 'title': 'TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering', 'authors': 'Zhonghao Li, Kunpeng Zhang, Jinghuai Ou, Shuliang Liu, Xuming Hu', 'link': 'https://arxiv.org/abs/2504.20114', 'abstract': 'Retrieval-augmented generation (RAG) systems face significant challenges in multi-hop question answering (MHQA), where complex queries require synthesizing information across multiple document chunks. Existing approaches typically rely on iterative LLM-based query rewriting and routing, resulting in high computational costs due to repeated LLM invocations and multi-stage processes. To address these limitations, we propose TreeHop, an embedding-level framework without the need for LLMs in query refinement. TreeHop dynamically updates query embeddings by fusing semantic information from prior queries and retrieved documents, enabling iterative retrieval through embedding-space operations alone. This method replaces the traditional "Retrieve-Rewrite-Vectorize-Retrieve" cycle with a streamlined "Retrieve-Embed-Retrieve" loop, significantly reducing computational overhead. Moreover, a rule-based stop criterion is introduced to further prune redundant retrievals, balancing efficiency and recall rate. Experimental results show that TreeHop rivals advanced RAG methods across three open-domain MHQA datasets, achieving comparable performance with only 5\\%-0.4\\% of the model parameter size and reducing the query latency by approximately 99\\% compared to concurrent approaches. This makes TreeHop a faster and more cost-effective solution for deployment in a range of knowledge-intensive applications. For reproducibility purposes, codes and data are available here: this https URL.', 'abstract_zh': 'TreeHop：一种无LLM查询精炼的嵌入级框架', 'title_zh': 'TreeHop: 有效生成和过滤多跳查询嵌入'}
{'arxiv_id': 'arXiv:2504.20112', 'title': 'Supervised Pretraining for Material Property Prediction', 'authors': 'Chowdhury Mohammad Abid Rahman, Aldo H. Romero, Prashnna K. Gyawali', 'link': 'https://arxiv.org/abs/2504.20112', 'abstract': 'Accurate prediction of material properties facilitates the discovery of novel materials with tailored functionalities. Deep learning models have recently shown superior accuracy and flexibility in capturing structure-property relationships. However, these models often rely on supervised learning, which requires large, well-annotated datasets an expensive and time-consuming process. Self-supervised learning (SSL) offers a promising alternative by pretraining on large, unlabeled datasets to develop foundation models that can be fine-tuned for material property prediction. In this work, we propose supervised pretraining, where available class information serves as surrogate labels to guide learning, even when downstream tasks involve unrelated material properties. We evaluate this strategy on two state-of-the-art SSL models and introduce a novel framework for supervised pretraining. To further enhance representation learning, we propose a graph-based augmentation technique that injects noise to improve robustness without structurally deforming material graphs. The resulting foundation models are fine-tuned for six challenging material property predictions, achieving significant performance gains over baselines, ranging from 2% to 6.67% improvement in mean absolute error (MAE) and establishing a new benchmark in material property prediction. This study represents the first exploration of supervised pertaining with surrogate labels in material property prediction, advancing methodology and application in the field.', 'abstract_zh': '准确预测材料性质有助于发现具有定制功能的新型材料。深度学习模型在捕捉结构-性质关系方面显示出卓越的准确性和灵活性。然而，这些模型往往依赖于监督学习，需要大量标记良好的数据集，这是一个昂贵且耗时的过程。自我监督学习（SSL）通过在大规模未标记数据集上进行预训练来开发基础模型，这些基础模型可以针对材料性质预测进行微调。在本文中，我们提出了一种监督预训练方法，其中可用的类别信息作为代理标签来指导学习，即使下游任务涉及不相关的材料性质也是如此。我们评估了这一策略在两种最先进的SSL模型上的表现，并引入了一种新的监督预训练框架。为进一步增强表示学习，我们提出了一种基于图的扩增技术，通过注入噪声来提高鲁棒性而不对材料图进行结构变形。所得基础模型针对六种具有挑战性的材料性质预测任务进行了微调，与基线相比取得了显著的性能提升，均方误差（MAE）改善幅度从2%到6.67%，并在材料性质预测中建立了新的基准。这项研究是首次在材料性质预测中探索使用代理标签的监督预训练，推动了该领域的研究方法和应用。', 'title_zh': '监督预训练材料性质预测'}
{'arxiv_id': 'arXiv:2504.20105', 'title': 'Electricity Cost Minimization for Multi-Workflow Allocation in Geo-Distributed Data Centers', 'authors': 'Shuang Wang, He Zhang, Tianxing Wu, Yueyou Zhang, Wei Emma Zhang, Quan Z. Sheng', 'link': 'https://arxiv.org/abs/2504.20105', 'abstract': 'Worldwide, Geo-distributed Data Centers (GDCs) provide computing and storage services for massive workflow applications, resulting in high electricity costs that vary depending on geographical locations and time. How to reduce electricity costs while satisfying the deadline constraints of workflow applications is important in GDCs, which is determined by the execution time of servers, power, and electricity price. Determining the completion time of workflows with different server frequencies can be challenging, especially in scenarios with heterogeneous computing resources in GDCs. Moreover, the electricity price is also different in geographical locations and may change dynamically. To address these challenges, we develop a geo-distributed system architecture and propose an Electricity Cost aware Multiple Workflows Scheduling algorithm (ECMWS) for servers of GDCs with fixed frequency and power. ECMWS comprises four stages, namely workflow sequencing, deadline partitioning, task sequencing, and resource allocation where two graph embedding models and a policy network are constructed to solve the Markov Decision Process (MDP). After statistically calibrating parameters and algorithm components over a comprehensive set of workflow instances, the proposed algorithms are compared with the state-of-the-art methods over two types of workflow instances. The experimental results demonstrate that our proposed algorithm significantly outperforms other algorithms, achieving an improvement of over 15\\% while maintaining an acceptable computational time. The source codes are available at this https URL.', 'abstract_zh': '全球范围内的地理位置分布式数据中心（GDCs）为大规模工作流应用提供计算和存储服务，导致电费成本高昂，且成本因地理位置和时间而异。如何在满足工作流应用截止时间约束的前提下降低电费成本是GDCs中的关键问题，这取决于服务器的执行时间、电力消耗和电价。在GDCs中拥有不同服务器频率的情况下确定工作流的完成时间具有挑战性，特别是在异构计算资源的场景中。此外，电费价格在不同地理位置也有所不同，并且可能会动态变化。为应对这些挑战，我们开发了一种地理位置分布式的系统架构，并提出了一种面向固定频率和功率的GDCs的电费成本感知多工作流调度算法（ECMWS）。ECMWS包含四个阶段，即工作流排序、截止时间分割、任务排序和资源分配，其中构建了两种图嵌入模型和一个策略网络来解决马尔科夫决策过程（MDP）。经过对大量工作流实例进行统计校准参数和算法组件后，我们将所提出的方法与前沿方法在两种类型的工作流实例上进行了比较。实验结果表明，所提出的方法显著优于其他方法，取得了超过15%的改进，同时保持了可接受的计算时间。源代码可在以下链接获取。', 'title_zh': '地理位置分布的数据中心中多工作流分配的电成本最小化'}
{'arxiv_id': 'arXiv:2504.20103', 'title': 'Heterogeneous network drug-target interaction prediction model based on graph wavelet transform and multi-level contrastive learning', 'authors': 'Wenfeng Dai, Yanhong Wang, Shuai Yan, Qingzhi Yu, Xiang Cheng', 'link': 'https://arxiv.org/abs/2504.20103', 'abstract': 'Drug-target interaction (DTI) prediction is a core task in drug development and precision medicine in the biomedical field. However, traditional machine learning methods generally have the black box problem, which makes it difficult to reveal the deep correlation between the model decision mechanism and the interaction pattern between biological molecules. This study proposes a heterogeneous network drug target interaction prediction framework, integrating graph neural network and multi scale signal processing technology to construct a model with both efficient prediction and multi level interpretability. Its technical breakthroughs are mainly reflected in the following three dimensions:Local global feature collaborative perception module. Based on heterogeneous graph convolutional neural network (HGCN), a multi order neighbor aggregation strategy is this http URL scale graph signal decomposition and biological interpretation module. A deep hierarchical node feature transform (GWT) architecture is this http URL learning combining multi dimensional perspectives and hierarchical representations. By comparing the learning models, the node representations from the two perspectives of HGCN and GWT are aligned and fused, so that the model can integrate multi dimensional information and improve the prediction robustness. Experimental results show that our framework shows excellent prediction performance on all datasets. This study provides a complete solution for drug target discovery from black box prediction to mechanism decoding, and its methodology has important reference value for modeling complex biomolecular interaction systems.', 'abstract_zh': '药物靶点交互预测中的异质网络框架：融合图神经网络和多尺度信号处理技术', 'title_zh': '基于图小波变换和多级对比学习的异质网络药物-靶点相互作用预测模型'}
{'arxiv_id': 'arXiv:2504.20102', 'title': 'HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction', 'authors': 'Qingzhi Yu, Shuai Yan, Wenfeng Dai, Xiang Cheng', 'link': 'https://arxiv.org/abs/2504.20102', 'abstract': 'Protein-protein interactions (PPIs) are fundamental for deciphering cellular functions,disease pathways,and drug this http URL existing neural networks and machine learning methods have achieved high accuracy in PPI prediction,their black-box nature leads to a lack of causal interpretation of the prediction results and difficulty in capturing hierarchical geometries and multi-scale dynamic interaction patterns among this http URL address these challenges, we propose HyboWaveNet,a novel deep learning framework that collaborates with hyperbolic graphical neural networks (HGNNs) and multiscale graphical wavelet transform for robust PPI prediction. Mapping protein features to Lorentz space simulates hierarchical topological relationships among biomolecules via a hyperbolic distance metric,enabling node feature representations that better fit biological a this http URL inherently simulates hierarchical and scale-free biological relationships, while the integration of wavelet transforms enables adaptive extraction of local and global interaction features across different resolutions. Our framework generates node feature representations via a graph neural network under the Lorenz model and generates pairs of positive samples under multiple different views for comparative learning, followed by further feature extraction via multi-scale graph wavelet transforms to predict potential PPIs. Experiments on public datasets show that HyboWaveNet improves over both existing state-of-the-art methods. We also demonstrate through ablation experimental studies that the multi-scale graph wavelet transform module improves the predictive performance and generalization ability of HyboWaveNet. This work links geometric deep learning and signal processing to advance PPI prediction, providing a principled approach for analyzing complex biological systems', 'abstract_zh': '蛋白质-蛋白质相互作用（PPIs）对于解析细胞功能、疾病途径和药物作用机制至关重要。现有神经网络和机器学习方法在PPI预测中已经取得了高精度，但其黑盒性质导致预测结果缺乏因果解释，难以捕捉多层次几何结构和多尺度动态相互作用模式。为解决这些挑战，我们提出了一种名为HyboWaveNet的新颖深度学习框架，该框架结合了双曲图形神经网络（HGNNs）和多尺度图形小波变换，以实现稳健的PPI预测。将蛋白质特征映射到洛伦兹空间，通过双曲距离度量模拟生物分子之间的层次拓扑关系，使节点特征表示更符合生物学特征。双曲空间本身模拟了层次和无标度的生物学关系，而小波变换的集成使框架能够适配地提取不同分辨率下的局部和全局相互作用特征。框架通过洛伦兹模型下的图形神经网络生成节点特征表示，并在多种不同视图下生成正样本对用于对比学习，随后通过多尺度图形小波变换进行进一步特征提取以预测潜在的PPIs。在公共数据集上的实验表明，HyboWaveNet优于现有的最先进的方法。通过消融实验研究还证明，多尺度图形小波变换模块提高了HyboWaveNet的预测性能和泛化能力。这项工作将几何深度学习与信号处理相结合，推动了PPI预测的发展，提供了一种分析复杂生物系统的原则性方法。', 'title_zh': 'HyboWaveNet：基于多尺度小波变换的双曲图神经网络在蛋白质-蛋白质相互作用预测中的应用'}
{'arxiv_id': 'arXiv:2504.20093', 'title': 'Self-Healing Software Systems: Lessons from Nature, Powered by AI', 'authors': 'Mohammad Baqar, Rajat Khanda, Saba Naqvi', 'link': 'https://arxiv.org/abs/2504.20093', 'abstract': 'As modern software systems grow in complexity and scale, their ability to autonomously detect, diagnose, and recover from failures becomes increasingly vital. Drawing inspiration from biological healing - where the human body detects damage, signals the brain, and activates targeted recovery - this paper explores the concept of self-healing software driven by artificial intelligence. We propose a novel framework that mimics this biological model system observability tools serve as sensory inputs, AI models function as the cognitive core for diagnosis and repair, and healing agents apply targeted code and test modifications. By combining log analysis, static code inspection, and AI-driven generation of patches or test updates, our approach aims to reduce downtime, accelerate debugging, and enhance software resilience. We evaluate the effectiveness of this model through case studies and simulations, comparing it against traditional manual debugging and recovery workflows. This work paves the way toward intelligent, adaptive and self-reliant software systems capable of continuous healing, akin to living organisms.', 'abstract_zh': '随着现代软件系统在复杂性和规模上的增长，其自主检测、诊断和恢复故障的能力变得日益重要。受到生物体修复机制的启发——人体检测损伤、信号传递至大脑，并启动针对性的恢复——本论文探讨由人工智能驱动的自愈软件概念。我们提出了一种新的框架，模仿这种生物模型： observability 工具作为感测输入，AI 模型作为诊断和修复的认知核心，自愈剂应用针对性的代码和测试修改。通过结合日志分析、静态代码检查和AI驱动的补丁或测试更新生成，我们的方法旨在减少停机时间、加速调试并增强软件韧性。通过案例研究和仿真评估该模型的有效性，将其与传统的手动调试和恢复工作流程进行对比。本研究为智能、适应性和自我依赖的软件系统铺平了道路，这些系统能够实现连续的自愈，类似于生物体的自我修复能力。', 'title_zh': '自愈软件系统：来自自然界的经验，驱动于人工智能'}
{'arxiv_id': 'arXiv:2504.20086', 'title': 'Understanding and Mitigating Risks of Generative AI in Financial Services', 'authors': 'Sebastian Gehrmann, Claire Huang, Xian Teng, Sergei Yurovski, Iyanuoluwa Shode, Chirag S. Patel, Arjun Bhorkar, Naveen Thomas, John Doucette, David Rosenberg, Mark Dredze, David Rabinowitz', 'link': 'https://arxiv.org/abs/2504.20086', 'abstract': 'To responsibly develop Generative AI (GenAI) products, it is critical to define the scope of acceptable inputs and outputs. What constitutes a "safe" response is an actively debated question. Academic work puts an outsized focus on evaluating models by themselves for general purpose aspects such as toxicity, bias, and fairness, especially in conversational applications being used by a broad audience. In contrast, less focus is put on considering sociotechnical systems in specialized domains. Yet, those specialized systems can be subject to extensive and well-understood legal and regulatory scrutiny. These product-specific considerations need to be set in industry-specific laws, regulations, and corporate governance requirements. In this paper, we aim to highlight AI content safety considerations specific to the financial services domain and outline an associated AI content risk taxonomy. We compare this taxonomy to existing work in this space and discuss implications of risk category violations on various stakeholders. We evaluate how existing open-source technical guardrail solutions cover this taxonomy by assessing them on data collected via red-teaming activities. Our results demonstrate that these guardrails fail to detect most of the content risks we discuss.', 'abstract_zh': '负责任地开发生成式人工智能（GenAI）产品需明确可接受的输入和输出范围。什么是“安全”的响应是一个备受争议的问题。学术研究过度关注通过评估模型自身的普适性方面（如毒性、偏见和公平性）来评价模型，尤其是在广泛受众使用的对话式应用中。相比之下，较少关注这些模型在专业化领域的社会技术系统层面的考量。然而，这些专业化系统可能会受到广泛的、深入了解的法律和监管审查。这些产品特定的考量需要在特定行业的法律、法规和公司治理要求中体现。在本文中，我们旨在强调金融服务业领域的AI内容安全考量，并概述相关的AI内容风险分类学。我们将这种分类学与现有研究进行比较，并讨论风险类别违规对各利益相关方的影响。我们通过红队活动收集的数据评估现有开源技术护栏解决方案对这一分类学的覆盖情况。我们的结果显示，这些护栏无法检测到我们讨论的大多数内容风险。', 'title_zh': '理解与减轻金融服务业生成式AI风险'}
{'arxiv_id': 'arXiv:2504.20080', 'title': 'DNAD: Differentiable Neural Architecture Distillation', 'authors': 'Xuan Rao, Bo Zhao, Derong Liu', 'link': 'https://arxiv.org/abs/2504.20080', 'abstract': 'To meet the demand for designing efficient neural networks with appropriate trade-offs between model performance (e.g., classification accuracy) and computational complexity, the differentiable neural architecture distillation (DNAD) algorithm is developed based on two cores, namely search by deleting and search by imitating. Primarily, to derive neural architectures in a space where cells of the same type no longer share the same topology, the super-network progressive shrinking (SNPS) algorithm is developed based on the framework of differentiable architecture search (DARTS), i.e., search by deleting. Unlike conventional DARTS-based approaches which yield neural architectures with simple structures and derive only one architecture during the search procedure, SNPS is able to derive a Pareto-optimal set of architectures with flexible structures by forcing the dynamic super-network shrink from a dense structure to a sparse one progressively. Furthermore, since knowledge distillation (KD) has shown great effectiveness to train a compact network with the assistance of an over-parameterized model, we integrate SNPS with KD to formulate the DNAD algorithm, i.e., search by imitating. By minimizing behavioral differences between the super-network and teacher network, the over-fitting of one-level DARTS is avoided and well-performed neural architectures are derived. Experiments on CIFAR-10 and ImageNet classification tasks demonstrate that both SNPS and DNAD are able to derive a set of architectures which achieve similar or lower error rates with fewer parameters and FLOPs. Particularly, DNAD achieves the top-1 error rate of 23.7% on ImageNet classification with a model of 6.0M parameters and 598M FLOPs, which outperforms most DARTS-based methods.', 'abstract_zh': '基于搜索删除和模仿搜索的可微神经架构蒸馏算法', 'title_zh': 'DNAD: 可微神经架构蒸馏'}
{'arxiv_id': 'arXiv:2504.20079', 'title': 'FX-DARTS: Designing Topology-unconstrained Architectures with Differentiable Architecture Search and Entropy-based Super-network Shrinking', 'authors': 'Xuan Rao, Bo Zhao, Derong Liu, Cesare Alippi', 'link': 'https://arxiv.org/abs/2504.20079', 'abstract': 'Strong priors are imposed on the search space of Differentiable Architecture Search (DARTS), such that cells of the same type share the same topological structure and each intermediate node retains two operators from distinct nodes. While these priors reduce optimization difficulties and improve the applicability of searched architectures, they hinder the subsequent development of automated machine learning (Auto-ML) and prevent the optimization algorithm from exploring more powerful neural networks through improved architectural flexibility. This paper aims to reduce these prior constraints by eliminating restrictions on cell topology and modifying the discretization mechanism for super-networks. Specifically, the Flexible DARTS (FX-DARTS) method, which leverages an Entropy-based Super-Network Shrinking (ESS) framework, is presented to address the challenges arising from the elimination of prior constraints. Notably, FX-DARTS enables the derivation of neural architectures without strict prior rules while maintaining the stability in the enlarged search space. Experimental results on image classification benchmarks demonstrate that FX-DARTS is capable of exploring a set of neural architectures with competitive trade-offs between performance and computational complexity within a single search procedure.', 'abstract_zh': '基于熵导向超网络收缩的灵活架构搜索（FX-DARTS）', 'title_zh': 'FX-DARTS：基于可微架构搜索和熵为基础的超级网络收缩设计拓扑约束架构'}
{'arxiv_id': 'arXiv:2504.20077', 'title': 'Edge-Based Learning for Improved Classification Under Adversarial Noise', 'authors': 'Manish Kansana, Keyan Alexander Rahimi, Elias Hossain, Iman Dehzangi, Noorbakhsh Amiri Golilarz', 'link': 'https://arxiv.org/abs/2504.20077', 'abstract': 'Adversarial noise introduces small perturbations in images, misleading deep learning models into misclassification and significantly impacting recognition accuracy. In this study, we analyzed the effects of Fast Gradient Sign Method (FGSM) adversarial noise on image classification and investigated whether training on specific image features can improve robustness. We hypothesize that while adversarial noise perturbs various regions of an image, edges may remain relatively stable and provide essential structural information for classification. To test this, we conducted a series of experiments using brain tumor and COVID datasets. Initially, we trained the models on clean images and then introduced subtle adversarial perturbations, which caused deep learning models to significantly misclassify the images. Retraining on a combination of clean and noisy images led to improved performance. To evaluate the robustness of the edge features, we extracted edges from the original/clean images and trained the models exclusively on edge-based representations. When noise was introduced to the images, the edge-based models demonstrated greater resilience to adversarial attacks compared to those trained on the original or clean images. These results suggest that while adversarial noise is able to exploit complex non-edge regions significantly more than edges, the improvement in the accuracy after retraining is marginally more in the original data as compared to the edges. Thus, leveraging edge-based learning can improve the resilience of deep learning models against adversarial perturbations.', 'abstract_zh': '对抗噪声通过在图像中引入微小扰动，误导深度学习模型产生误分类，显著影响识别准确性。本研究分析了快速梯度符号方法（FGSM）对抗噪声对图像分类效果的影响，并探讨了特定图像特征训练是否能提高模型的鲁棒性。研究假设，尽管对抗噪声会扰动图像的不同区域，但边缘可能相对稳定，提供重要的结构信息，有助于分类。为验证这一假设，我们使用脑肿瘤和COVID数据集进行了系列实验。首先，我们对干净图像进行模型训练，然后引入细微的对抗扰动，导致深度学习模型显著误分类。重新在干净和噪声图像的组合上进行训练提升了模型性能。为了评估边缘特征的鲁棒性，我们从原始/干净图像中提取边缘，并仅使用基于边缘的表示进行模型训练。当向图像引入噪声时，基于边缘的模型相较于仅在原始或干净图像上进行训练的模型，表现出更强的对抗攻击鲁棒性。这些结果表明，尽管对抗噪声更多地利用了复杂的非边缘区域，但在重新训练后，原始数据的准确率提升略高于边缘区域。因此，利用基于边缘的学习可以提高深度学习模型对抗噪声扰动的鲁棒性。', 'title_zh': '基于边缘的学习以提高对抗噪声下的分类性能'}
{'arxiv_id': 'arXiv:2504.20074', 'title': 'EPSILON: Adaptive Fault Mitigation in Approximate Deep Neural Network using Statistical Signatures', 'authors': 'Khurram Khalil, Khaza Anuarul Hoque', 'link': 'https://arxiv.org/abs/2504.20074', 'abstract': 'The increasing adoption of approximate computing in deep neural network accelerators (AxDNNs) promises significant energy efficiency gains. However, permanent faults in AxDNNs can severely degrade their performance compared to their accurate counterparts (AccDNNs). Traditional fault detection and mitigation approaches, while effective for AccDNNs, introduce substantial overhead and latency, making them impractical for energy-constrained real-time deployment. To address this, we introduce EPSILON, a lightweight framework that leverages pre-computed statistical signatures and layer-wise importance metrics for efficient fault detection and mitigation in AxDNNs. Our framework introduces a novel non-parametric pattern-matching algorithm that enables constant-time fault detection without interrupting normal execution while dynamically adapting to different network architectures and fault patterns. EPSILON maintains model accuracy by intelligently adjusting mitigation strategies based on a statistical analysis of weight distribution and layer criticality while preserving the energy benefits of approximate computing. Extensive evaluations across various approximate multipliers, AxDNN architectures, popular datasets (MNIST, CIFAR-10, CIFAR-100, ImageNet-1k), and fault scenarios demonstrate that EPSILON maintains 80.05\\% accuracy while offering 22\\% improvement in inference time and 28\\% improvement in energy efficiency, establishing EPSILON as a practical solution for deploying reliable AxDNNs in safety-critical edge applications.', 'abstract_zh': '约简计算在深度神经网络加速器（AxDNNs）中的 increasingly 采用促进了显著的能量效率提升。然而，AxDNNs 中的永久性故障会严重降低其性能， compared to 准确的对应版本（AccDNNs）。传统的故障检测与缓解方法虽对 AccDNNs 有效，但在能耗受限的实时部署中引入了显著的开销和延迟，使其 impractical 不切实际。为解决这一问题，我们提出了 EPSILON，一种轻量级框架，利用预计算的统计签名与逐层重要性度量进行高效的 AxDNN 故障检测与缓解。我们的框架引入了一种新颖的非参数模式匹配算法，能够在不中断正常执行的情况下进行恒定时间的故障检测，并能够根据不同网络架构和故障模式动态适配。EPSILON 通过基于权重分布和层关键性的统计分析智能调整缓解策略来保持模型精度，同时保留约简计算的能量效益。跨多种约简乘法器、AxDNN 架构、流行数据集（MNIST、CIFAR-10、CIFAR-100、ImageNet-1k）和故障场景的广泛评估表明，EPSILON 维持了 80.05% 的准确性，提供了 22% 的推理时间改进和 28% 的能量效率改进，确立了 EPSILON 作为在关键边缘应用中部署可靠 AxDNNs 的实际解决方案。', 'title_zh': 'EPSILON: 基于统计特征的自适应容错机制用于近似深度神经网络'}
{'arxiv_id': 'arXiv:2504.20069', 'title': 'A Simple Review of EEG Foundation Models: Datasets, Advancements and Future Perspectives', 'authors': 'Junhong Lai, Jiyu Wei, Lin Yao, Yueming Wang', 'link': 'https://arxiv.org/abs/2504.20069', 'abstract': 'Electroencephalogram (EEG) signals play a crucial role in understanding brain activity and diagnosing neurological disorders. This review focuses on the recent development of EEG foundation models(EEG-FMs), which have shown great potential in processing and analyzing EEG data. We discuss various EEG-FMs, including their architectures, pre-training strategies, their pre-training and downstream datasets and other details. The review also highlights the challenges and future directions in this field, aiming to provide a comprehensive overview for researchers and practitioners interested in EEG analysis and related EEG-FMs.', 'abstract_zh': '电生理信号（EEG）在理解大脑活动和诊断神经疾病中扮演着重要角色。本文综述了近期发展的EEG基础模型（EEG-FMs）的研究进展，探讨了各种EEG-FMs的架构、预训练策略、预训练和下游数据集及其他细节。同时还指出了该领域的挑战和未来发展方向，旨在为从事EEG分析及相关EEG-FMs研究的学者和实践者提供全面概述。', 'title_zh': 'EEG基础模型的简要 review：数据集、进展和未来展望'}
{'arxiv_id': 'arXiv:2504.20055', 'title': 'A constraints-based approach to fully interpretable neural networks for detecting learner behaviors', 'authors': 'Juan D. Pinto, Luc Paquette', 'link': 'https://arxiv.org/abs/2504.20055', 'abstract': "The increasing use of complex machine learning models in education has led to concerns about their interpretability, which in turn has spurred interest in developing explainability techniques that are both faithful to the model's inner workings and intelligible to human end-users. In this paper, we describe a novel approach to creating a neural-network-based behavior detection model that is interpretable by design. Our model is fully interpretable, meaning that the parameters we extract for our explanations have a clear interpretation, fully capture the model's learned knowledge about the learner behavior of interest, and can be used to create explanations that are both faithful and intelligible. We achieve this by implementing a series of constraints to the model that both simplify its inference process and bring it closer to a human conception of the task at hand. We train the model to detect gaming-the-system behavior, evaluate its performance on this task, and compare its learned patterns to those identified by human experts. Our results show that the model is successfully able to learn patterns indicative of gaming-the-system behavior while providing evidence for fully interpretable explanations. We discuss the implications of our approach and suggest ways to evaluate explainability using a human-grounded approach.", 'abstract_zh': '教育中复杂机器学习模型应用增加导致可解释性问题的关注，从而促进了忠实于模型内部工作原理且易于人类最终用户理解的可解释性技术的发展。本文描述了一种设计上具备可解释性的基于神经网络的行为检测模型的新方法。该模型完全可解释，即我们提取的用于解释的参数具有清晰的含义，完全捕捉了模型关于所感兴趣的学习者行为的已学习知识，并可用于创建忠实且易于理解的解释。我们通过实施一系列约束来简化模型的推断过程，并使其更接近人类对任务的认知。我们训练模型以检测游戏系统行为，评估其在该任务上的表现，并将其学到的模式与人类专家识别的模式进行比较。我们的结果表明，模型能够成功学习指示游戏系统行为的模式，同时提供完全可解释的证据。我们讨论了该方法的意义，并建议使用基于人类的方法评估可解释性。', 'title_zh': '基于约束的方法构建完全可解释的神经网络以检测学习者行为'}
{'arxiv_id': 'arXiv:2504.20047', 'title': 'HCT-QA: A Benchmark for Question Answering on Human-Centric Tables', 'authors': 'Mohammad S. Ahmad, Zan A. Naeem, Michaël Aupetit, Ahmed Elmagarmid, Mohamed Eltabakh, Xiasong Ma, Mourad Ouzzani, Chaoyi Ruan', 'link': 'https://arxiv.org/abs/2504.20047', 'abstract': 'Tabular data embedded within PDF files, web pages, and other document formats are prevalent across numerous sectors such as government, engineering, science, and business. These human-centric tables (HCTs) possess a unique combination of high business value, intricate layouts, limited operational power at scale, and sometimes serve as the only data source for critical insights. However, their complexity poses significant challenges to traditional data extraction, processing, and querying methods. While current solutions focus on transforming these tables into relational formats for SQL queries, they fall short in handling the diverse and complex layouts of HCTs and hence being amenable to querying. This paper describes HCT-QA, an extensive benchmark of HCTs, natural language queries, and related answers on thousands of tables. Our dataset includes 2,188 real-world HCTs with 9,835 QA pairs and 4,679 synthetic tables with 67.5K QA pairs. While HCTs can be potentially processed by different type of query engines, in this paper, we focus on Large Language Models as potential engines and assess their ability in processing and querying such tables.', 'abstract_zh': '嵌入在PDF文件、网页及其他文档格式中的表格数据在政府、工程、科学和商业等多个领域内广泛存在。这些以人类为中心的表格（HCTs）具有高商业价值、复杂的布局、有限的大规模操作能力和有时作为关键洞察唯一数据源的特点。然而，其复杂性给传统的数据提取、处理和查询方法带来了重大挑战。虽然现有解决方案致力于将这些表格转换为关系格式以供SQL查询，但它们在处理HCTs的多样性和复杂性方面仍然存在不足。因此，这些表格难以被查询。本文描述了HCT-QA，一个包含数千个表格的全面基准，包括自然语言查询及其相关答案，并涉及2,188个真实世界的HCTs和9,835个问答对，以及4,679个合成表格和67,500个问答对。虽然HCTs可以由不同类型的查询引擎处理，在本论文中，我们重点探讨大型语言模型作为潜在引擎的能力，评估其在处理和查询此类表格方面的表现。', 'title_zh': 'HCT-QA：以人为本表格上的问答基准'}
