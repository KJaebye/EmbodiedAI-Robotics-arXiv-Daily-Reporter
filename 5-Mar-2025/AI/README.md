# Bringing Comparative Cognition To Computers 

**Title (ZH)**: 将比较认知带入计算机 

**Authors**: Konstantinos Voudouris, Lucy G. Cheke, Eric Schulz  

**Link**: [PDF](https://arxiv.org/pdf/2503.02882)  

**Abstract**: Researchers are increasingly subjecting artificial intelligence systems to psychological testing. But to rigorously compare their cognitive capacities with humans and other animals, we must avoid both over- and under-stating our similarities and differences. By embracing a comparative approach, we can integrate AI cognition research into the broader cognitive sciences. 

**Abstract (ZH)**: 研究人员 increasingly 将人工智能系统置于心理学测试之下。但为了严格比较其认知能力与人类和其他动物的相似性和差异性，我们必须避免夸大或低估这些相似性和差异性。通过采用比较方法，我们可以将人工智能认知研究纳入更广泛的认知科学领域。 

---
# Evaluation of Architectural Synthesis Using Generative AI 

**Title (ZH)**: 使用生成式人工智能进行建筑合成评估 

**Authors**: Jingfei Huang, Alexandros Haridis  

**Link**: [PDF](https://arxiv.org/pdf/2503.02861)  

**Abstract**: Recent advancements in multimodal Generative AI have the potential to democratize specialized architectural tasks, such as interpreting technical drawings and creating 3D CAD models, which traditionally require expert knowledge. This paper presents a comparative evaluation of two systems: GPT-4o and Claude 3.5, in the task of architectural 3D synthesis. We conduct a case study on two buildings from Palladio's Four Books of Architecture (1965): Villa Rotonda and Palazzo Porto. High-level architectural models and drawings of these buildings were prepared, inspired by Palladio's original texts and drawings. Through sequential text and image prompting, we assess the systems' abilities in (1) interpreting 2D and 3D representations of buildings from drawings, (2) encoding the buildings into a CAD software script, and (3) self-improving based on outputs. While both systems successfully generate individual parts, they struggle to accurately assemble these parts into the desired spatial relationships, with Claude 3.5 demonstrating better performance, particularly in self-correcting its output. This study contributes to ongoing research on benchmarking the strengths and weaknesses of off-the-shelf AI systems in performing intelligent human tasks that require discipline-specific knowledge. The findings highlight the potential of language-enabled AI systems to act as collaborative technical assistants in the architectural design process. 

**Abstract (ZH)**: Recent advancements in multimodal Generative AI有潜力使专门的建筑任务民主化，如解读技术图纸和创建3D CAD模型，这些任务 traditionally需要专家知识。本文对GPT-4o和Claude 3.5两个系统在建筑3D合成任务中的表现进行了比较评估。我们以帕拉第奥《四本建筑著作》（1965年）中的Villa Rotonda和Palazzo Porto两座建筑为例进行了案例研究。根据帕拉第奥原始文本和图纸的启发，我们准备了这些建筑的高层建筑模型和图纸。通过顺序的文字和图像提示，我们评估了这些系统在（1）从图纸解读建筑的2D和3D表示，（2）将建筑编码到CAD软件脚本中，以及（3）基于输出自我改进方面的能力。尽管两个系统都能生成独立的部分，但在准确组装这些部分以达到预期的空间关系方面存在困难，Claude 3.5在自我纠正输出方面表现更好。本研究为评估现成AI系统在执行需要学科特定知识的智能人类任务方面的强项和弱点的持续研究做出了贡献。研究结果突显了语言驱动的AI系统在建筑设计过程中的合作技术助手潜力。 

---
# Prime Convolutional Model: Breaking the Ground for Theoretical Explainability 

**Title (ZH)**: 首要卷积模型：理论可解释性的基石 

**Authors**: Francesco Panelli, Doaa Almhaithawi, Tania Cerquitelli, Alessandro Bellini  

**Link**: [PDF](https://arxiv.org/pdf/2503.02773)  

**Abstract**: In this paper, we propose a new theoretical approach to Explainable AI. Following the Scientific Method, this approach consists in formulating on the basis of empirical evidence, a mathematical model to explain and predict the behaviors of Neural Networks. We apply the method to a case study created in a controlled environment, which we call Prime Convolutional Model (p-Conv for short). p-Conv operates on a dataset consisting of the first one million natural numbers and is trained to identify the congruence classes modulo a given integer $m$. Its architecture uses a convolutional-type neural network that contextually processes a sequence of $B$ consecutive numbers to each input. We take an empirical approach and exploit p-Conv to identify the congruence classes of numbers in a validation set using different values for $m$ and $B$. The results show that the different behaviors of p-Conv (i.e., whether it can perform the task or not) can be modeled mathematically in terms of $m$ and $B$. The inferred mathematical model reveals interesting patterns able to explain when and why p-Conv succeeds in performing task and, if not, which error pattern it follows. 

**Abstract (ZH)**: 本文提出了一种新的理论方法来解释AI。该方法基于科学方法，通过对神经网络行为进行基于实证证据的数学建模来进行解释和预测。我们将这种方法应用于一个在受控环境中创建的案例如“质数卷积模型”（简称为p-Conv）。p-Conv处理由前一百万个自然数组成的数据集，并被训练识别给定整数$m$模下的同余类。其架构使用了一种卷积型神经网络，能够对每个输入的$B$个连续数字进行上下文处理。我们采用实证方法，利用p-Conv识别验证集中的数字的同余类，使用不同的$m$和$B$值。结果表明，p-Conv的不同行为（即它能否执行任务）可以用$B$和$m$的数学模型来建模。从推导出的数学模型中，我们可以发现能够解释p-Conv何时以及为何成功执行任务，如果不成功，则遵循何种错误模式的有趣模式。 

---
# MindBridge: Scalable and Cross-Model Knowledge Editing via Memory-Augmented Modality 

**Title (ZH)**: MindBridge：基于记忆增强模态的可扩展跨模型知识编辑 

**Authors**: Shuaike Li, Kai Zhang, Qi Liu, Enhong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.02701)  

**Abstract**: Knowledge editing is a technique for efficiently and accurately updating the knowledge of large language models (LLMs) to alleviate obsolescence and correct errors. However, most existing methods overfit to specific models, causing edited knowledge to be discarded during each LLM update and requiring frequent re-editing, which is particularly burdensome in today's rapidly evolving open-source community. To address this issue, we propose the problem of cross-model knowledge editing and introduce MindBridge, a scalable solution inspired by the low coupling between modality processing and LLMs in multi-modal models. MindBridge introduces the novel concept of memory modality, which encodes edited knowledge as an independent modality. It first performs LLM-agnostic pre-training of the memory modality and then integrates it with various LLMs. Extensive experiments on multiple LLMs and popular knowledge editing datasets demonstrate that MindBridge achieves superior performance even in editing tens of thousands of knowledge entries and can flexibly adapt to different LLMs. Our code is available at this https URL. 

**Abstract (ZH)**: 跨模型知识编辑：MindBridge——一种可扩展的解决方案 

---
# Seeding for Success: Skill and Stochasticity in Tabletop Games 

**Title (ZH)**: seeding for Success: 技能与随机性在桌游中的作用 

**Authors**: James Goodman, Diego Perez-Liebana, Simon Lucas  

**Link**: [PDF](https://arxiv.org/pdf/2503.02686)  

**Abstract**: Games often incorporate random elements in the form of dice or shuffled card decks. This randomness is a key contributor to the player experience and the variety of game situations encountered. There is a tension between a level of randomness that makes the game interesting and contributes to the player enjoyment of a game, and a level at which the outcome itself is effectively random and the game becomes dull. The optimal level for a game will depend on the design goals and target audience. We introduce a new technique to quantify the level of randomness in game outcome and use it to compare 15 tabletop games and disentangle the different contributions to the overall randomness from specific parts of some games. We further explore the interaction between game randomness and player skill, and how this innate randomness can affect error analysis in common game experiments. 

**Abstract (ZH)**: 游戏常常通过骰子或洗牌的牌组等随机元素来融入不确定性。这种不确定性是玩家体验和游戏中遇到的各种情况的关键因素。随机性的适宜水平在于既能使游戏有趣并增加玩家的愉悦感，又不至于使得游戏结果完全随机而变得乏味。游戏的最佳随机性水平将取决于设计目标和目标受众。我们提出了一种新的技术来量化游戏结果中的随机性，并利用它来比较15款桌面游戏，并从一些游戏中特定部分的角度解构整体随机性。进一步探讨了游戏随机性与玩家技能之间的互动，以及这种固有的随机性如何影响常见游戏实验中的误差分析。 

---
# The Effectiveness of Large Language Models in Transforming Unstructured Text to Standardized Formats 

**Title (ZH)**: 大型语言模型在转换非结构化文本为标准化格式方面的有效性 

**Authors**: William Brach, Kristián Košťál, Michal Ries  

**Link**: [PDF](https://arxiv.org/pdf/2503.02650)  

**Abstract**: The exponential growth of unstructured text data presents a fundamental challenge in modern data management and information retrieval. While Large Language Models (LLMs) have shown remarkable capabilities in natural language processing, their potential to transform unstructured text into standardized, structured formats remains largely unexplored - a capability that could revolutionize data processing workflows across industries. This study breaks new ground by systematically evaluating LLMs' ability to convert unstructured recipe text into the structured Cooklang format. Through comprehensive testing of four models (GPT-4o, GPT-4o-mini, Llama3.1:70b, and Llama3.1:8b), an innovative evaluation approach is introduced that combines traditional metrics (WER, ROUGE-L, TER) with specialized metrics for semantic element identification. Our experiments reveal that GPT-4o with few-shot prompting achieves breakthrough performance (ROUGE-L: 0.9722, WER: 0.0730), demonstrating for the first time that LLMs can reliably transform domain-specific unstructured text into structured formats without extensive training. Although model performance generally scales with size, we uncover surprising potential in smaller models like Llama3.1:8b for optimization through targeted fine-tuning. These findings open new possibilities for automated structured data generation across various domains, from medical records to technical documentation, potentially transforming the way organizations process and utilize unstructured information. 

**Abstract (ZH)**: 无结构文本数据的指数增长为现代数据管理和信息检索带来了一项基础挑战。虽然大型语言模型（LLMs）在自然语言处理方面表现出色，但它们将无结构文本转换为标准化、结构化格式的潜力尚未得到充分探讨——这种能力有可能革新各行业数据处理工作流程。本研究首次系统评估了LLMs将无结构食谱文本转换为结构化Cooklang格式的能力。通过四种模型（GPT-4o、GPT-4o-mini、Llama3.1:70b 和 Llama3.1:8b）的全面测试，提出了结合传统指标（WER、ROUGE-L、TER）和语义元素识别特殊指标的创新评估方法。实验结果显示，带有少量提示的GPT-4o模型取得了突破性能（ROUGE-L: 0.9722，WER: 0.0730），首次证明LLMs可以在无需大量训练的情况下可靠地将领域特定的无结构文本转换为结构化格式。虽然模型性能通常随规模扩大而提升，但研究发现，如Llama3.1:8b这样的小型模型通过目标微调具有优化潜力。这些发现为各领域自动化结构化数据生成开辟了新可能性，从医疗记录到技术文档，可能彻底改变组织处理和利用无结构信息的方式。 

---
# Playing games with Large language models: Randomness and strategy 

**Title (ZH)**: 用大型语言模型玩策略游戏：随机性和策略 

**Authors**: Alicia Vidler, Toby Walsh  

**Link**: [PDF](https://arxiv.org/pdf/2503.02582)  

**Abstract**: Playing games has a long history of describing intricate interactions in simplified forms. In this paper we explore if large language models (LLMs) can play games, investigating their capabilities for randomisation and strategic adaptation through both simultaneous and sequential game interactions. We focus on GPT-4o-Mini-2024-08-17 and test two games between LLMs: Rock Paper Scissors (RPS) and games of strategy (Prisoners Dilemma PD). LLMs are often described as stochastic parrots, and while they may indeed be parrots, our results suggest that they are not very stochastic in the sense that their outputs - when prompted to be random - are often very biased. Our research reveals that LLMs appear to develop loss aversion strategies in repeated games, with RPS converging to stalemate conditions while PD shows systematic shifts between cooperative and competitive outcomes based on prompt design. We detail programmatic tools for independent agent interactions and the Agentic AI challenges faced in implementation. We show that LLMs can indeed play games, just not very well. These results have implications for the use of LLMs in multi-agent LLM systems and showcase limitations in current approaches to model output for strategic decision-making. 

**Abstract (ZH)**: 大型语言模型能否玩游戏：探索其在随机化和战略适应方面的能力——以GPT-4o-Mini-2024-08-17为例，测试石头剪刀布和囚徒困境游戏 

---
# ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment 

**Title (ZH)**: ROCKET-2: 通过跨视图目标对齐引导视觉运动策略 

**Authors**: Shaofei Cai, Zhancun Mu, Anji Liu, Yitao Liang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02505)  

**Abstract**: We aim to develop a goal specification method that is semantically clear, spatially sensitive, and intuitive for human users to guide agent interactions in embodied environments. Specifically, we propose a novel cross-view goal alignment framework that allows users to specify target objects using segmentation masks from their own camera views rather than the agent's observations. We highlight that behavior cloning alone fails to align the agent's behavior with human intent when the human and agent camera views differ significantly. To address this, we introduce two auxiliary objectives: cross-view consistency loss and target visibility loss, which explicitly enhance the agent's spatial reasoning ability. According to this, we develop ROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an improvement in the efficiency of inference 3x to 6x. We show ROCKET-2 can directly interpret goals from human camera views for the first time, paving the way for better human-agent interaction. 

**Abstract (ZH)**: 我们旨在开发一种语义明确、空间敏感且易于人类用户直观使用的任务规范方法，以指导代理在具身环境中的交互。具体而言，我们提出了一种新颖的跨视角任务对齐框架，允许用户使用自身相机视角下的分割掩码来指定目标对象，而不仅仅是依靠代理的观察结果。我们强调，仅通过行为克隆无法在人类与代理相机视角差异显著时使代理行为与人类意图对齐。为此，我们引入了两个辅助目标：跨视角一致性损失和目标可见性损失，以明确增强代理的空间推理能力。基于此，我们开发了ROCKET-2，这是一个在Minecraft中训练的先进代理，实现了推理效率提高3至6倍的效果。我们首次展示了ROCKET-2可以直接从人类相机视角解析任务需求，为改善人机交互奠定了基础。 

---
# PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset 

**Title (ZH)**: PennyLang: 基于新型PennyLane中心数据集的LLM驱动量子代码生成先驱研究 

**Authors**: Haider Asif, Abdul Basit, Nouhaila Innan, Muhammad Kashif, Alberto Marchisio, Muhammad Shafique  

**Link**: [PDF](https://arxiv.org/pdf/2503.02497)  

**Abstract**: Large Language Models (LLMs) offer remarkable capabilities in code generation, natural language processing, and domain-specific reasoning. Their potential in aiding quantum software development remains underexplored, particularly for the PennyLane framework-a leading platform for hybrid quantum-classical computing. To address this gap, we introduce a novel, high-quality dataset comprising 3,347 PennyLane-specific code samples of quantum circuits and their contextual descriptions, specifically curated to train/fine-tune LLM-based quantum code assistance. Our key contributions are threefold: (1) the automatic creation and open-source release of a comprehensive PennyLane dataset leveraging quantum computing textbooks, official documentation, and open-source repositories; (2) the development of a systematic methodology for data refinement, annotation, and formatting to optimize LLM training efficiency; and (3) a thorough evaluation, based on a Retrieval-Augmented Generation (RAG) framework, demonstrating the effectiveness of our dataset in streamlining PennyLane code generation and improving quantum development workflows. Compared to existing efforts that predominantly focus on Qiskit, our dataset significantly broadens the spectrum of quantum frameworks covered in AI-driven code assistance. By bridging this gap and providing reproducible dataset-creation methodologies, we aim to advance the field of AI-assisted quantum programming, making quantum computing more accessible to both newcomers and experienced developers. 

**Abstract (ZH)**: 大型语言模型（LLMs）在代码生成、自然语言处理和领域特定推理方面展现出卓越的能力。它们在辅助量子软件开发方面的潜力尚未充分探索，尤其是在PennyLane框架方面——这是一种领先的混合量子-古典计算平台。为了解决这一缺口，我们介绍了一个人工智能驱动的量子代码辅助领域首个高质量数据集，该数据集包含3,347个PennyLane特定的量子电路代码样本及其上下文描述，特别针对训练/微调基于LLM的量子代码辅助系统进行了精心遴选。我们的主要贡献包括三个方面：（1）利用量子计算教科书、官方文档和开源仓库自动生成并开源一个全面的PennyLane数据集；（2）开发了一种系统性的数据精炼、标注和格式化方法，以优化LLM的训练效率；（3）基于检索增强生成（RAG）框架进行详尽评估，展示了该数据集在简化PennyLane代码生成和改善量子开发工作流程方面的有效性。与主要关注Qiskit的现有努力相比，我们的数据集显著扩大了人工智能驱动代码辅助所覆盖的量子框架范围。通过填补这一空白并提供可复现的数据集创建方法，我们旨在推进人工智能辅助量子编程领域的发展，使量子计算对新手和经验丰富的开发人员都更加易于接触。 

---
# Don't Get Too Excited -- Eliciting Emotions in LLMs 

**Title (ZH)**: 不要过于兴奋——引发LLMs的情感响应 

**Authors**: Gino Franco Fazzi, Julie Skoven Hinge, Stefan Heinrich, Paolo Burelli  

**Link**: [PDF](https://arxiv.org/pdf/2503.02457)  

**Abstract**: This paper investigates the challenges of affect control in large language models (LLMs), focusing on their ability to express appropriate emotional states during extended dialogues. We evaluated state-of-the-art open-weight LLMs to assess their affective expressive range in terms of arousal and valence. Our study employs a novel methodology combining LLM-based sentiment analysis with multiturn dialogue simulations between LLMs. We quantify the models' capacity to express a wide spectrum of emotions and how they fluctuate during interactions. Our findings reveal significant variations among LLMs in their ability to maintain consistent affect, with some models demonstrating more stable emotional trajectories than others. Furthermore, we identify key challenges in affect control, including difficulties in producing and maintaining extreme emotional states and limitations in adapting affect to changing conversational contexts. These findings have important implications for the development of more emotionally intelligent AI systems and highlight the need for improved affect modelling in LLMs. 

**Abstract (ZH)**: 本文探讨了大型语言模型在表达适当情感状态方面的挑战，重点关注其在长时间对话中表达恰当情感的能力。我们评估了最先进的开放权重语言模型，以评估它们在唤醒度和价值度方面的的情绪表达范围。本研究采用了一种新颖的方法论，结合基于语言模型的情绪分析与语言模型之间的多轮对话模拟。我们量化了模型表达广泛情感范围的能力及其在互动过程中的波动情况。研究发现，语言模型在维持一致情感方面的能力存在显著差异，有些模型在情感轨迹的稳定性方面优于其他模型。此外，我们还识别出情感控制中的关键挑战，包括生成和维持极端情感状态的难度以及适应变化的对话环境的情感限制。这些发现对于开发更具有情感智能的AI系统具有重要意义，并强调了改进语言模型中情感建模的必要性。 

---
# AutoEval: A Practical Framework for Autonomous Evaluation of Mobile Agents 

**Title (ZH)**: AutoEval：移动代理自主评估的实用框架 

**Authors**: Jiahui Sun, Zhichao Hua, Yubin Xia  

**Link**: [PDF](https://arxiv.org/pdf/2503.02403)  

**Abstract**: Accurate and systematic evaluation of mobile agents can significantly advance their development and real-world applicability. However, existing benchmarks for mobile agents lack practicality and scalability due to the extensive manual effort required to define task reward signals and implement corresponding evaluation codes. To this end, we propose AutoEval, an autonomous agent evaluation framework that tests a mobile agent without any manual effort. First, we design a Structured Substate Representation to describe the UI state changes while agent execution, such that task reward signals can be automatically generated. Second, we utilize a Judge System that can autonomously evaluate agents' performance given the automatically generated task reward signals. By providing only a task description, our framework evaluates agents with fine-grained performance feedback to that task without any extra manual effort. We implement a prototype of our framework and validate the automatically generated task reward signals, finding over 93% coverage to human-annotated reward signals. Moreover, to prove the effectiveness of our autonomous Judge System, we manually verify its judge results and demonstrate that it achieves 94% accuracy. Finally, we evaluate the state-of-the-art mobile agents using our framework, providing detailed insights into their performance characteristics and limitations. 

**Abstract (ZH)**: 移动代理的自动准确与系统评价可显著促进其发展与实际应用。然而，现有移动代理基准缺乏实用性和可扩展性，因为定义任务奖励信号和实现相应的评价代码需要大量的手工 effort。为此，我们提出 AutoEval，一种无需任何手工努力即可测试移动代理的自主代理评估框架。首先，我们设计了一种结构化子状态表示法，用于描述代理执行过程中的 UI 状态变化，以便能够自动生成任务奖励信号。其次，我们利用一个裁判系统，在给定自动生成的任务奖励信号的情况下，可自主评估代理的性能。仅提供任务描述，我们的框架即可在不进行额外手工努力的情况下，对代理进行细粒度性能反馈评价。我们实现了该框架的一个原型，并验证了自动生成的任务奖励信号，发现其覆盖率超过 93%。此外，为了证明我们自主裁判系统的有效性，我们手工验证了其裁判结果，并证明其准确率达到 94%。最后，我们使用该框架评估最先进的移动代理，提供了对其性能特征和限制的详细见解。 

---
# EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram Reports 

**Title (ZH)**: EchoQA：心脏超声报告指令调优数据集 

**Authors**: Lama Moukheiber, Mira Moukheiber, Dana Moukheiiber, Hyung-Chul Lee  

**Link**: [PDF](https://arxiv.org/pdf/2503.02365)  

**Abstract**: We introduce a novel question-answering (QA) dataset using echocardiogram reports sourced from the Medical Information Mart for Intensive Care database. This dataset is specifically designed to enhance QA systems in cardiology, consisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities and their severity. We compare large language models (LLMs), including open-source and biomedical-specific models for zero-shot evaluation, and closed-source models for zero-shot and three-shot evaluation. Our results show that fine-tuning LLMs improves performance across various QA metrics, validating the value of our dataset. Clinicians also qualitatively evaluate the best-performing model to assess the LLM responses for correctness. Further, we conduct fine-grained fairness audits to assess the bias-performance trade-off of LLMs across various social determinants of health. Our objective is to propel the field forward by establishing a benchmark for LLM AI agents aimed at supporting clinicians with cardiac differential diagnoses, thereby reducing the documentation burden that contributes to clinician burnout and enabling healthcare professionals to focus more on patient care. 

**Abstract (ZH)**: 我们引入了一个使用来自重症护理医学信息市场数据库的心脏超声报告数据构建的新颖问答（QA）数据集，旨在增强心脏病学领域的问答系统。该数据集包含771,244个问答对，涵盖了广泛的心脏异常及其严重程度。我们对比了大型语言模型（LLMs），包括开源和生物医学专用模型的零样本评估，以及封闭源模型的零样本和三样本评估。结果显示，微调LLMs在各种问答指标上的表现都有所提升，验证了该数据集的价值。临床医生还从定性的角度评估了表现最佳的模型，以检查LLM的回答是否正确。此外，我们进行了精细粒度的公平性审计，评估了LLMs在各种健康社会决定因素上的偏见-性能权衡。我们的目标是通过建立支持心脏病鉴别诊断的大型语言模型AI代理基准，推动该领域的发展，从而减轻导致医生倦怠的文档负担，并使医疗卫生专业人员能够更多地专注于患者护理。 

---
# Enhancing the Product Quality of the Injection Process Using eXplainable Artificial Intelligence 

**Title (ZH)**: 使用可解释的人工智能提升注射成型过程的产品质量 

**Authors**: Jisoo Hong, Yongmin Hong, Jung-Woo Baek, Sung-Woo Kang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02338)  

**Abstract**: The injection molding process is a traditional technique for making products in various industries such as electronics and automobiles via solidifying liquid resin into certain molds. Although the process is not related to creating the main part of engines or semiconductors, this manufacturing methodology sets the final form of the products. Re-cently, research has continued to reduce the defect rate of the injection molding process. This study proposes an optimal injection molding process control system to reduce the defect rate of injection molding products with XAI (eXplainable Artificial Intelligence) ap-proaches. Boosting algorithms (XGBoost and LightGBM) are used as tree-based classifiers for predicting whether each product is normal or defective. The main features to control the process for improving the product are extracted by SHapley Additive exPlanations, while the individual conditional expectation analyzes the optimal control range of these extracted features. To validate the methodology presented in this work, the actual injection molding AI manufacturing dataset provided by KAMP (Korea AI Manufacturing Platform) is employed for the case study. The results reveal that the defect rate decreases from 1.00% (Original defect rate) to 0.21% with XGBoost and 0.13% with LightGBM, respectively. 

**Abstract (ZH)**: 采用XAI方法优化注塑成型工艺控制系统的研究 

---
# Memorize or Generalize? Evaluating LLM Code Generation with Evolved Questions 

**Title (ZH)**: 记忆还是泛化？评估预训练模型的代码生成能力与演变问题 

**Authors**: Wentao Chen, Lizhe Zhang, Li Zhong, Letian Peng, Zilong Wang, Jingbo Shang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02296)  

**Abstract**: Large Language Models (LLMs) are known to exhibit a memorization phenomenon in code generation: instead of truly understanding the underlying principles of a programming problem, they tend to memorize the original prompt and its solution together in the training. Consequently, when facing variants of the original problem, their answers very likely resemble the memorized solutions and fail to generalize. In this paper, we investigate this phenomenon by designing three evolution strategies to create variants: mutation, paraphrasing, and code-rewriting. By comparing the performance and AST similarity of the LLM-generated codes before and after these three evolutions, we develop a memorization score that positively correlates with the level of memorization. As expected, as supervised fine-tuning goes on, the memorization score rises before overfitting, suggesting more severe memorization. We demonstrate that common mitigation approaches, such as prompt translation and using evolved variants as data augmentation in supervised learning and reinforcement learning, either compromise the performance or fail to alleviate the memorization issue. Therefore, memorization remains a significant challenge in LLM code generation, highlighting the need for a more effective solution. 

**Abstract (ZH)**: 大型语言模型在代码生成中表现出记忆现象：它们倾向于记住原始提示及其解决方案，而不是真正理解编程问题的原理。因此，当面对原始问题的变体时，它们的答案很可能与记忆中的解决方案相似，无法泛化。本文通过设计三种进化策略（突变、改写和代码重构）来创建变体，并通过比较进化前后模型生成的代码的性能和抽象语法树相似度，开发了一个与记忆程度正相关的评分方法。正如预期的那样，随着监督微调的进行，记忆评分在过拟合前上升，表明记忆更为严重。我们展示了常见的缓解方法，如提示翻译和在监督学习和强化学习中使用进化后的变体作为数据增强，要么牺牲性能，要么无法缓解记忆问题。因此，记忆问题仍然是大型语言模型代码生成中的一个重大挑战，突显了需要更有效的解决方案的必要性。 

---
# AppAgentX: Evolving GUI Agents as Proficient Smartphone Users 

**Title (ZH)**: AppAgentX: 进化为 proficient 智能手机用户的 GUI 代理 

**Authors**: Wenjia Jiang, Yangyang Zhuang, Chenxi Song, Xu Yang, Chi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02268)  

**Abstract**: Recent advancements in Large Language Models (LLMs) have led to the development of intelligent LLM-based agents capable of interacting with graphical user interfaces (GUIs). These agents demonstrate strong reasoning and adaptability, enabling them to perform complex tasks that traditionally required predefined rules. However, the reliance on step-by-step reasoning in LLM-based agents often results in inefficiencies, particularly for routine tasks. In contrast, traditional rule-based systems excel in efficiency but lack the intelligence and flexibility to adapt to novel scenarios. To address this challenge, we propose a novel evolutionary framework for GUI agents that enhances operational efficiency while retaining intelligence and flexibility. Our approach incorporates a memory mechanism that records the agent's task execution history. By analyzing this history, the agent identifies repetitive action sequences and evolves high-level actions that act as shortcuts, replacing these low-level operations and improving efficiency. This allows the agent to focus on tasks requiring more complex reasoning, while simplifying routine actions. Experimental results on multiple benchmark tasks demonstrate that our approach significantly outperforms existing methods in both efficiency and accuracy. The code will be open-sourced to support further research. 

**Abstract (ZH)**: recent 进展 在大规模语言模型中的最新进展导致了能够与图形用户界面（GUI）交互的智能基于语言模型的代理的发展。这些代理展示了强大的推理能力和适应性，能够执行传统上需要预定义规则才能完成的复杂任务。然而，基于语言模型的代理在依赖逐步推理时往往会受到效率上的限制，特别是在处理常规任务时。相比之下，传统的基于规则的系统在效率方面表现出色，但在面对新颖场景时缺乏智能和灵活性。为了解决这一挑战，我们提出了一种新型的进化框架，该框架提升了操作效率同时保留了智能和灵活性。我们的方法结合了记忆机制，记录代理的任务执行历史。通过分析这一历史记录，代理识别重复的动作序列，并进化出高层次的动作作为捷径，取代这些低层次的操作，从而提高效率。这使得代理能够专注于需要更复杂推理的任务，同时简化常规操作。在多个基准任务上的实验结果表明，我们的方法在效率和准确性方面显著优于现有方法。代码将开源以支持进一步研究。 

---
# V2X-LLM: Enhancing V2X Integration and Understanding in Connected Vehicle Corridors 

**Title (ZH)**: V2X-LLM：增强连接车辆走廊中的V2X集成与理解 

**Authors**: Keshu Wu, Pei Li, Yang Zhou, Rui Gan, Junwei You, Yang Cheng, Jingwen Zhu, Steven T. Parker, Bin Ran, David A. Noyce, Zhengzhong Tu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02239)  

**Abstract**: The advancement of Connected and Automated Vehicles (CAVs) and Vehicle-to-Everything (V2X) offers significant potential for enhancing transportation safety, mobility, and sustainability. However, the integration and analysis of the diverse and voluminous V2X data, including Basic Safety Messages (BSMs) and Signal Phase and Timing (SPaT) data, present substantial challenges, especially on Connected Vehicle Corridors. These challenges include managing large data volumes, ensuring real-time data integration, and understanding complex traffic scenarios. Although these projects have developed an advanced CAV data pipeline that enables real-time communication between vehicles, infrastructure, and other road users for managing connected vehicle and roadside unit (RSU) data, significant hurdles in data comprehension and real-time scenario analysis and reasoning persist. To address these issues, we introduce the V2X-LLM framework, a novel enhancement to the existing CV data pipeline. V2X-LLM leverages Large Language Models (LLMs) to improve the understanding and real-time analysis of V2X data. The framework includes four key tasks: Scenario Explanation, offering detailed narratives of traffic conditions; V2X Data Description, detailing vehicle and infrastructure statuses; State Prediction, forecasting future traffic states; and Navigation Advisory, providing optimized routing instructions. By integrating LLM-driven reasoning with V2X data within the data pipeline, the V2X-LLM framework offers real-time feedback and decision support for traffic management. This integration enhances the accuracy of traffic analysis, safety, and traffic optimization. Demonstrations in a real-world urban corridor highlight the framework's potential to advance intelligent transportation systems. 

**Abstract (ZH)**: Connected和自动化车辆（CAVs）及Vehicle-to-Everything（V2X）技术的进步为提升交通运输安全、机动性和可持续性提供了巨大潜力。然而，集成和分析包含基础安全消息（BSMs）和信号相位与定时（SPaT）数据在内的多样化且庞大的V2X数据，特别是在Connected Vehicle Corridors中，提出了重大挑战。这些挑战包括管理大量数据、确保实时数据集成以及理解复杂的路况场景。尽管这些项目已开发出先进的CAV数据管道，能够实现车辆、基础设施与其他道路用户之间的实时通信，管理连接车辆和路边单元（RSU）数据，但在数据理解和实时场景分析与推理方面仍存在重大障碍。为解决这些问题，我们提出了V2X-LLM框架，这是现有CV数据管道的一个全新增强。V2X-LLM利用大型语言模型（LLMs）来改善对V2X数据的理解和实时分析。该框架包括四个关键任务：场景解释、提供详细的交通状况叙述；V2X数据描述、详细说明车辆和基础设施的状态；状态预测、预测未来交通状态；导航建议、提供优化的路线指令。通过将LLM驱动的推理与V2X数据集成到数据管道中，V2X-LLM框架为交通管理提供即时反馈和支持。这一集成提高了交通分析的准确性、安全性和交通优化水平。在实际城市走廊的演示中，展示了该框架在推进智能交通系统方面的能力。 

---
# Attention Bootstrapping for Multi-Modal Test-Time Adaptation 

**Title (ZH)**: 多模态测试时自适应的注意力强化方法 

**Authors**: Yusheng Zhao, Junyu Luo, Xiao Luo, Jinsheng Huang, Jingyang Yuan, Zhiping Xiao, Ming Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02221)  

**Abstract**: Test-time adaptation aims to adapt a well-trained model to potential distribution shifts at test time using only unlabeled test data, without access to the original training data. While previous efforts mainly focus on a single modality, test-time distribution shift in the multi-modal setting is more complex and calls for new solutions. This paper tackles the problem of multi-modal test-time adaptation by proposing a novel method named Attention Bootstrapping with Principal Entropy Minimization (ABPEM). We observe that test-time distribution shift causes misalignment across modalities, leading to a large gap between intra-modality discrepancies (measured by self-attention) and inter-modality discrepancies (measured by cross-attention). We name this the attention gap. This attention gap widens with more severe distribution shifts, hindering effective modality fusion. To mitigate this attention gap and encourage better modality fusion, we propose attention bootstrapping that promotes cross-attention with the guidance of self-attention. Moreover, to reduce the gradient noise in the commonly-used entropy minimization, we adopt principal entropy minimization, a refinement of entropy minimization that reduces gradient noise by focusing on the principal parts of entropy, excluding less reliable gradient information. Extensive experiments on the benchmarks validate the effectiveness of the proposed ABPEM in comparison with competing baselines. 

**Abstract (ZH)**: 多模态测试时自适应：基于主熵最小化的注意力-bootstrap方法（Attention Bootstrapping with Principal Entropy Minimization for Multi-modal Test-time Adaptation） 

---
# KGCompiler: Deep Learning Compilation Optimization for Knowledge Graph Complex Logical Query Answering 

**Title (ZH)**: KGCompiler: 深度学习编译优化以解答知识图谱复杂逻辑查询 

**Authors**: Hongyu Lin, Haoran Luo, Hanghang Cao, Yang Liu, Shihao Gao, Kaichun Yao, Libo Zhang, Mingjie Xing, Yanjun Wu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02172)  

**Abstract**: Complex Logical Query Answering (CLQA) involves intricate multi-hop logical reasoning over large-scale and potentially incomplete Knowledge Graphs (KGs). Although existing CLQA algorithms achieve high accuracy in answering such queries, their reasoning time and memory usage scale significantly with the number of First-Order Logic (FOL) operators involved, creating serious challenges for practical deployment. In addition, current research primarily focuses on algorithm-level optimizations for CLQA tasks, often overlooking compiler-level optimizations, which can offer greater generality and scalability. To address these limitations, we introduce a Knowledge Graph Compiler, namely KGCompiler, the first deep learning compiler specifically designed for CLQA tasks. By incorporating KG-specific optimizations proposed in this paper, KGCompiler enhances the reasoning performance of CLQA algorithms without requiring additional manual modifications to their implementations. At the same time, it significantly reduces memory usage. Extensive experiments demonstrate that KGCompiler accelerates CLQA algorithms by factors ranging from 1.04x to 8.26x, with an average speedup of 3.71x. We also provide an interface to enable hands-on experience with KGCompiler. 

**Abstract (ZH)**: 知识图谱复合逻辑查询编译器（KGCompiler）：针对复合逻辑查询回答任务的深度学习编译器 

---
# TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models 

**Title (ZH)**: TMIQ: 在大规模语言模型中量化测试与测量领域智能 

**Authors**: Emmanuel A. Olowe, Danial Chitnis  

**Link**: [PDF](https://arxiv.org/pdf/2503.02123)  

**Abstract**: The Test and Measurement domain, known for its strict requirements for accuracy and efficiency, is increasingly adopting Generative AI technologies to enhance the performance of data analysis, automation, and decision-making processes. Among these, Large Language Models (LLMs) show significant promise for advancing automation and precision in testing. However, the evaluation of LLMs in this specialized area remains insufficiently explored. To address this gap, we introduce the Test and Measurement Intelligence Quotient (TMIQ), a benchmark designed to quantitatively assess LLMs across a wide range of electronic engineering tasks. TMIQ offers a comprehensive set of scenarios and metrics for detailed evaluation, including SCPI command matching accuracy, ranked response evaluation, Chain-of-Thought Reasoning (CoT), and the impact of output formatting variations required by LLMs on performance. In testing various LLMs, our findings indicate varying levels of proficiency, with exact SCPI command match accuracy ranging from around 56% to 73%, and ranked matching first-position scores achieving around 33% for the best-performing model. We also assess token usage, cost-efficiency, and response times, identifying trade-offs between accuracy and operational efficiency. Additionally, we present a command-line interface (CLI) tool that enables users to generate datasets using the same methodology, allowing for tailored assessments of LLMs. TMIQ and the CLI tool provide a rigorous, reproducible means of evaluating LLMs for production environments, facilitating continuous monitoring and identifying strengths and areas for improvement, and driving innovation in their selections for applications within the Test and Measurement industry. 

**Abstract (ZH)**: 测试与测量领域因其对准确性和效率的严格要求，正越来越多地采用生成式AI技术以增强数据处理、自动化和决策过程的表现。在此领域中，大型语言模型（LLMs）在提高测试的自动化和精确性方面显示出巨大的潜力。然而，对于这类专业领域的LLM评估仍缺乏足够的探索。为填补这一空白，我们提出了测试与测量智能商（TMIQ），这是一个用于定量评估LLM在广泛电子工程任务中的基准测试。TMIQ提供了一套全面的情景和指标，包括SCPI命令匹配准确性、排名响应评估、链式思维推理（CoT）以及输出格式化要求对性能的影响。在测试各种LLM后，我们的发现显示不同水平的能力，具体而言，精确的SCPI命令匹配准确性范围在约56%到73%之间，最优模型的第一位置排名匹配得分为约33%。我们还评估了标记使用情况、成本效益和响应时间，并确定了准确性与操作效率之间的权衡。此外，我们还提供了一个命令行界面（CLI）工具，使用户能够使用相同的方法生成数据集，从而实现对LLM的定制评估。TMIQ和CLI工具为生产环境下的LLM评估提供了一种严谨且可复制的方法，有助于持续监控、识别强项和改进领域，并推动测试与测量行业中LLM选择的创新。 

---
# EPEE: Towards Efficient and Effective Foundation Models in Biomedicine 

**Title (ZH)**: EPEE: 向生物医学领域高效且有效的基础模型迈进 

**Authors**: Zaifu Zhan, Shuang Zhou, Huixue Zhou, Zirui Liu, Rui Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02053)  

**Abstract**: Foundation models, including language models, e.g., GPT, and vision models, e.g., CLIP, have significantly advanced numerous biomedical tasks. Despite these advancements, the high inference latency and the "overthinking" issues in model inference impair the efficiency and effectiveness of foundation models, thus limiting their application in real-time clinical settings. To address these challenges, we proposed EPEE (Entropy- and Patience-based Early Exiting), a novel hybrid strategy designed to improve the inference efficiency of foundation models. The core idea was to leverage the strengths of entropy-based and patience-based early exiting methods to overcome their respective weaknesses. To evaluate EPEE, we conducted experiments on three core biomedical tasks-classification, relation extraction, and event extraction-using four foundation models (BERT, ALBERT, GPT-2, and ViT) across twelve datasets, including clinical notes and medical images. The results showed that EPEE significantly reduced inference time while maintaining or improving accuracy, demonstrating its adaptability to diverse datasets and tasks. EPEE addressed critical barriers to deploying foundation models in healthcare by balancing efficiency and effectiveness. It potentially provided a practical solution for real-time clinical decision-making with foundation models, supporting reliable and efficient workflows. 

**Abstract (ZH)**: 基于熵和耐心早期退出的混合策略EPEE：提升基础模型推理效率的方法 

---
# Pretrained Embeddings as a Behavior Specification Mechanism 

**Title (ZH)**: 预训练嵌入作为行为规范机制 

**Authors**: Parv Kapoor, Abigail Hammer, Ashish Kapoor, Karen Leung, Eunsuk Kang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02012)  

**Abstract**: We propose an approach to formally specifying the behavioral properties of systems that rely on a perception model for interactions with the physical world. The key idea is to introduce embeddings -- mathematical representations of a real-world concept -- as a first-class construct in a specification language, where properties are expressed in terms of distances between a pair of ideal and observed embeddings. To realize this approach, we propose a new type of temporal logic called Embedding Temporal Logic (ETL), and describe how it can be used to express a wider range of properties about AI-enabled systems than previously possible. We demonstrate the applicability of ETL through a preliminary evaluation involving planning tasks in robots that are driven by foundation models; the results are promising, showing that embedding-based specifications can be used to steer a system towards desirable behaviors. 

**Abstract (ZH)**: 我们提出了一种通过感知模型正式规定系统行为属性的方法。关键思想是将嵌入——现实世界概念的数学表示——作为规范语言中的一级构造，其中属性用理想嵌入和观测嵌入之间的距离来表达。为了实现这一方法，我们提出了一种新的时序逻辑类型，称为嵌入时序逻辑(ETL)，并描述了它是如何能够表达比以往更多的关于AI使能系统属性的方法。通过在由基础模型驱动的机器人规划任务中的初步评估，展示了ETL的应用前景，结果表明基于嵌入的规范可以引导系统朝向期望的行为。 

---
# Nexus-O: An Omni-Perceptive And -Interactive Model for Language, Audio, And Vision 

**Title (ZH)**: Nexus-O：一种综合感知和交互的语言、音频和视觉模型 

**Authors**: Che Liu, Yingji Zhang, Dong Zhang, Weijie Zhang, Chenggong Gong, Haohan Li, Yu Lu, Shilin Zhou, Yue Lu, Ziliang Gan, Ziao Wang, Junwei Liao, Haipang Wu, Ji Liu, André Freitas, Qifan Wang, Zenglin Xu, Rongjuncheng Zhang, Yong Dai  

**Link**: [PDF](https://arxiv.org/pdf/2503.01879)  

**Abstract**: Human beings perceive the real world through a spectrum of sensory modalities, encompassing auditory, visual, and linguistic faculties. The journey towards achieving Artificial General Intelligence (AGI) necessitates the development of models that can emulate these multifaceted perceptual capabilities and comprehensively understand these diversified data. To this end, we introduce \textbf{Nexus-O}, an industry-level \textbf{omni-perceptive and -interactive} model capable of efficiently processing Audio, Image, Video, and Text data in any combination and output audio/text in an end-to-end way. We systematically investigate Nexus-O by addressing three key research questions: First, how can models be efficiently designed and trained to achieve tri-modal alignment, understanding and reasoning capabilities across multiple modalities? Second, what approaches can be implemented to evaluate tri-modal model robustness, ensuring reliable performance and applicability in real-world scenarios? Third, what strategies can be employed to curate and obtain high-quality, real-life scenario speech datasets? For the first question, we design and pre-train Nexus-O based on the vision-language model, rather than the language model. By pre-training the model over high-quality synthetic audio data, our model is capable of tri-modal perception and interaction. For the second question, we introduce a new audio testbed, Nexus-O-audio, comprising diverse Automatic Speech Recognition (ASR) samples, spanning various real-world scenarios, such as corporate meetings and live stream. For the third question, we design the speech data synthesis pipeline to obtain high-quality speech training datasets, covering various real-world scenarios. Comprehensive experimentation and an in-depth analysis of tri-modal alignment over latent space demonstrate the advantages of our model on downstream tasks. 

**Abstract (ZH)**: 人类通过听觉、视觉和语言等多种感知模态来认知真实世界。实现通用人工智能（AGI）的旅程需要开发能够模拟这些多维感知能力并全面理解这些多样化数据的模型。为此，我们介绍了一种工业级的**全感知全交互**模型**Nexus-O**，该模型能够高效地处理音频、图像、视频和文本数据的任意组合，并以端到端的方式输出音频/文本。我们系统地探讨了Nexus-O，针对三个关键研究问题进行了研究：首先，如何设计和训练模型以实现跨多种模态的三模态对齐、理解和推理能力？其次，采用什么方法评估三模态模型的鲁棒性，确保其在实际场景中的可靠表现和适用性？第三，如何收集和获得高质量的真实场景语音数据集？对于第一个问题，我们基于视觉-语言模型而非语言模型设计并预训练了Nexus-O，通过在高质量合成音频数据上进行预训练，使模型具备三模态感知和交互的能力。对于第二个问题，我们引入了一个新的音频测试平台Nexus-O-audio，包含多种自动语音识别（ASR）样本，覆盖各种实际场景，如企业会议和直播。对于第三个问题，我们设计了语音数据合成流水线，以获得高质量的语音训练数据集，涵盖各种实际场景。全面的实验和潜空间三模态对齐的深入分析证明了该模型在下游任务中的优势。 

---
# Neural Manifolds and Cognitive Consistency: A New Approach to Memory Consolidation in Artificial Systems 

**Title (ZH)**: 神经流形与认知一致性：人工系统中记忆巩固的新方法 

**Authors**: Phuong-Nam Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2503.01867)  

**Abstract**: We introduce a novel mathematical framework that unifies neural population dynamics, hippocampal sharp wave-ripple (SpWR) generation, and cognitive consistency constraints inspired by Heider's theory. Our model leverages low-dimensional manifold representations to capture structured neural drift and incorporates a balance energy function to enforce coherent synaptic interactions, effectively simulating the memory consolidation processes observed in biological systems. Simulation results demonstrate that our approach not only reproduces key features of SpWR events but also enhances network interpretability. This work paves the way for scalable neuromorphic architectures that bridge neuroscience and artificial intelligence, offering more robust and adaptive learning mechanisms for future intelligent systems. 

**Abstract (ZH)**: 我们提出了一种新的数学框架，该框架统一了神经群体动力学、海马尖波-成簇波（SpWR）生成以及受Heider理论启发的认知一致性约束。该模型利用低维流形表示来捕获结构化的神经漂移，并引入平衡能量函数以强制执行一致的突触交互，有效地模拟了生物系统中观察到的记忆巩固过程。仿真结果表明，我们的方法不仅能够重现SpWR事件的关键特征，还能增强网络的可解释性。这项工作为将神经科学与人工智能结合起来的可扩展神经形态架构铺平了道路，提供了更稳健和适应性强的学习机制，以供未来的智能系统使用。 

---
# Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation 

**Title (ZH)**: 反应扩散策略：接触丰富操作中的慢-快视觉-触觉策略学习 

**Authors**: Han Xue, Jieji Ren, Wendi Chen, Gu Zhang, Yuan Fang, Guoying Gu, Huazhe Xu, Cewu Lu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02881)  

**Abstract**: Humans can accomplish complex contact-rich tasks using vision and touch, with highly reactive capabilities such as quick adjustments to environmental changes and adaptive control of contact forces; however, this remains challenging for robots. Existing visual imitation learning (IL) approaches rely on action chunking to model complex behaviors, which lacks the ability to respond instantly to real-time tactile feedback during the chunk execution. Furthermore, most teleoperation systems struggle to provide fine-grained tactile / force feedback, which limits the range of tasks that can be performed. To address these challenges, we introduce TactAR, a low-cost teleoperation system that provides real-time tactile feedback through Augmented Reality (AR), along with Reactive Diffusion Policy (RDP), a novel slow-fast visual-tactile imitation learning algorithm for learning contact-rich manipulation skills. RDP employs a two-level hierarchy: (1) a slow latent diffusion policy for predicting high-level action chunks in latent space at low frequency, (2) a fast asymmetric tokenizer for closed-loop tactile feedback control at high frequency. This design enables both complex trajectory modeling and quick reactive behavior within a unified framework. Through extensive evaluation across three challenging contact-rich tasks, RDP significantly improves performance compared to state-of-the-art visual IL baselines through rapid response to tactile / force feedback. Furthermore, experiments show that RDP is applicable across different tactile / force sensors. Code and videos are available on this https URL. 

**Abstract (ZH)**: 人类可以使用视觉和触觉完成复杂的接触密集型任务，并具备快速适应环境变化和调整接触力的高反应能力；然而这对机器人来说仍然具有挑战性。现有的视觉imitation learning（IL）方法依赖于动作切片来建模复杂行为，在动作切片执行过程中缺乏对实时触觉反馈的即时响应能力。此外，大多数远程操作系统难以提供精细的触觉/力反馈，这限制了可执行任务的范围。为了解决这些挑战，我们引入了TactAR，这是一种通过增强现实（AR）提供实时触觉反馈的低成本远程操作系统，以及用于学习接触密集型操作技能的新型慢速-快速视觉-触觉imitation learning算法Reactive Diffusion Policy（RDP）。RDP采用两层层次结构：（1）低频的慢速潜在扩散策略用于预测低维潜在空间中的高层动作切片；（2）高频的不对称标记器用于闭环触觉反馈控制。这一设计使得复杂轨迹建模和快速反应行为可以在统一框架内实现。通过在三个具有挑战性的接触密集型任务上的广泛评估，RDP相较于最先进的视觉IL基准实现了显著的性能提升，通过快速响应触觉/力反馈。此外，实验表明RDP适用于不同类型的触觉/力传感器。相关代码和视频可在以下链接获得。 

---
# Wikipedia in the Era of LLMs: Evolution and Risks 

**Title (ZH)**: Wikipedia在大语言模型时代：演化与风险 

**Authors**: Siming Huang, Yuliang Xu, Mingmeng Geng, Yao Wan, Dongping Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.02879)  

**Abstract**: In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks. We begin by analyzing page views and article content to study Wikipedia's recent changes and assess the impact of LLMs. Subsequently, we evaluate how LLMs affect various Natural Language Processing (NLP) tasks related to Wikipedia, including machine translation and retrieval-augmented generation (RAG). Our findings and simulation results reveal that Wikipedia articles have been influenced by LLMs, with an impact of approximately 1%-2% in certain categories. If the machine translation benchmark based on Wikipedia is influenced by LLMs, the scores of the models may become inflated, and the comparative results among models might shift as well. Moreover, the effectiveness of RAG might decrease if the knowledge base becomes polluted by LLM-generated content. While LLMs have not yet fully changed Wikipedia's language and knowledge structures, we believe that our empirical findings signal the need for careful consideration of potential future risks. 

**Abstract (ZH)**: 本文对大型语言模型（LLMs）对Wikipedia的影响进行了彻底分析，通过现有数据研究Wikipedia的变化，并使用模拟来探索潜在风险。我们首先分析页面浏览量和文章内容，以研究Wikipedia的 recent变化并评估LLMs的影响。随后，我们评估LLMs对与Wikipedia相关的各种自然语言处理（NLP）任务的影响，包括机器翻译和检索增强生成（RAG）。我们的发现和模拟结果表明，Wikipedia的文章受到了LLMs的影响，在某些类别中的影响约为1%-2%。如果基于Wikipedia的机器翻译基准受到LLMs的影响，模型的得分可能会膨胀，模型之间的比较结果也可能发生变化。此外，如果知识库受到LLM生成内容的污染，检索增强生成的有效性可能会下降。虽然LLMs尚未完全改变Wikipedia的语言和知识结构，但我们的实证结果表明，需要谨慎考虑潜在的未来风险。 

---
# Language Models can Self-Improve at State-Value Estimation for Better Search 

**Title (ZH)**: 语言模型可以在状态值估计方面自我提升以改善搜索性能 

**Authors**: Ethan Mendes, Alan Ritter  

**Link**: [PDF](https://arxiv.org/pdf/2503.02878)  

**Abstract**: Collecting ground truth task completion rewards or human demonstrations for multi-step reasoning tasks is often cost-prohibitive and time-consuming, especially in interactive domains like web tasks. To address this bottleneck, we present self-taught lookahead, a self-supervised method that leverages state-transition dynamics to train a value model capable of effectively guiding language model-controlled search. We find that moderately sized (8 billion parameters) open-weight value models improved with self-taught lookahead can match the performance of using a frontier LLM such as gpt-4o as the value model. Furthermore, we find that self-taught lookahead improves performance by 20% while reducing costs 37x compared to previous LLM-based tree search, without relying on ground truth rewards. 

**Abstract (ZH)**: 自我教学前瞻：一种利用状态转换动力学训练价值模型的方法，以有效指导语言模型控制的搜索 

---
# Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024 

**Title (ZH)**: Deepfake-Eval-2024：2024年传播的多模态野生深度合成基准 

**Authors**: Nuria Alina Chandra, Ryan Murtfeldt, Lin Qiu, Arnab Karmakar, Hannah Lee, Emmanuel Tanumihardja, Kevin Farhat, Ben Caffee, Sejin Paik, Changyeon Lee, Jongwook Choi, Aerin Kim, Oren Etzioni  

**Link**: [PDF](https://arxiv.org/pdf/2503.02857)  

**Abstract**: In the age of increasingly realistic generative AI, robust deepfake detection is essential for mitigating fraud and disinformation. While many deepfake detectors report high accuracy on academic datasets, we show that these academic benchmarks are out of date and not representative of recent deepfakes. We introduce Deepfake-Eval-2024, a new deepfake detection benchmark consisting of in-the-wild deepfakes collected from social media and deepfake detection platform users in 2024. Deepfake-Eval-2024 consists of 44 hours of videos, 56.5 hours of audio, and 1,975 images, encompassing the latest manipulation technologies. The benchmark contains diverse media content from 88 different websites in 52 different languages. We find that the performance of open-source state-of-the-art deepfake detection models drops precipitously when evaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for audio, and 45% for image models compared to previous benchmarks. We also evaluate commercial deepfake detection models and models finetuned on Deepfake-Eval-2024, and find that they have superior performance to off-the-shelf open-source models, but they do not yet reach the accuracy of human deepfake forensic analysts. The dataset is available at this https URL. 

**Abstract (ZH)**: 在生成式AI日益逼真化的时代，稳健的深度合成检测对于减轻欺诈和虚假信息至关重要。虽然许多深度合成检测器在学术数据集上报告了高准确率，但我们发现这些学术基准已经过时且不具有代表性。我们引入了Deepfake-Eval-2024，这是一个新的深度合成检测基准，包括从社交媒体和2024年深度合成检测平台用户收集的“野生”深度合成媒体。Deepfake-Eval-2024包含44小时的视频、56.5小时的音频和1,975张图像，涵盖了最新的合成技术。基准数据集包含来自52种语言88个不同网站的多样媒体内容。我们发现，当在Deepfake-Eval-2024上评估时，开源的最先进的深度合成检测模型性能急剧下降，视频模型的AUC下降50%，音频模型下降48%，图像模型下降45%。我们还评估了商用深度合成检测模型和在Deepfake-Eval-2024上微调的模型，发现它们的性能优于现成的开源模型，但尚未达到人类深度合成法医分析师的准确度。数据集可在以下链接获取。 

---
# (How) Do Language Models Track State? 

**Title (ZH)**: 语言模型如何追踪状态？ 

**Authors**: Belinda Z. Li, Zifan Carl Guo, Jacob Andreas  

**Link**: [PDF](https://arxiv.org/pdf/2503.02854)  

**Abstract**: Transformer language models (LMs) exhibit behaviors -- from storytelling to code generation -- that appear to require tracking the unobserved state of an evolving world. How do they do so? We study state tracking in LMs trained or fine-tuned to compose permutations (i.e., to compute the order of a set of objects after a sequence of swaps). Despite the simple algebraic structure of this problem, many other tasks (e.g., simulation of finite automata and evaluation of boolean expressions) can be reduced to permutation composition, making it a natural model for state tracking in general. We show that LMs consistently learn one of two state tracking mechanisms for this task. The first closely resembles the "associative scan" construction used in recent theoretical work by Liu et al. (2023) and Merrill et al. (2024). The second uses an easy-to-compute feature (permutation parity) to partially prune the space of outputs, then refines this with an associative scan. The two mechanisms exhibit markedly different robustness properties, and we show how to steer LMs toward one or the other with intermediate training tasks that encourage or suppress the heuristics. Our results demonstrate that transformer LMs, whether pretrained or fine-tuned, can learn to implement efficient and interpretable state tracking mechanisms, and the emergence of these mechanisms can be predicted and controlled. 

**Abstract (ZH)**: 变换器语言模型（LMs）在从讲故事到代码生成的行为中，似乎需要跟踪一个演变世界的未观察状态。它们是如何做到这一点的？我们研究了在排列组合（即，在一系列交换后计算一组对象的顺序）任务中训练或微调的LMs的状态跟踪机制。尽管这个问题具有简单的代数结构，但许多其他任务（例如有限自动机的仿真和布尔表达式的评估）都可以简化为排列组合，使其成为一种自然的状态跟踪模型。我们证明这些LMs在该任务中一致地学习两种状态跟踪机制之一。第一种机制与Liu et al. (2023) 和 Merrill et al. (2024) 最近的理论工作中使用的“关联扫描”构造类似。第二种机制利用一个易于计算的特征（排列偶性）部分剪枝输出空间，然后使用关联扫描进行细化。这两种机制表现出明显不同的稳健性特征，并展示了如何通过中间训练任务引导LMs偏向于或抑制其中一种启发式方法。我们的结果表明，无论是预训练还是微调的变换器LMs都能够学习实现高效且可解释的状态跟踪机制，这些机制的出现可以被预测和控制。 

---
# Multimodal Deep Learning for Subtype Classification in Breast Cancer Using Histopathological Images and Gene Expression Data 

**Title (ZH)**: 基于组织病理图像和基因表达数据的乳腺癌亚型分类的多模态深度学习 

**Authors**: Amin Honarmandi Shandiz  

**Link**: [PDF](https://arxiv.org/pdf/2503.02849)  

**Abstract**: Molecular subtyping of breast cancer is crucial for personalized treatment and prognosis. Traditional classification approaches rely on either histopathological images or gene expression profiling, limiting their predictive power. In this study, we propose a deep multimodal learning framework that integrates histopathological images and gene expression data to classify breast cancer into this http URL and this http URL / Her2 subtypes. Our approach employs a ResNet-50 model for image feature extraction and fully connected layers for gene expression processing, with a cross-attention fusion mechanism to enhance modality interaction. We conduct extensive experiments using five-fold cross-validation, demonstrating that our multimodal integration outperforms unimodal approaches in terms of classification accuracy, precision-recall AUC, and F1-score. Our findings highlight the potential of deep learning for robust and interpretable breast cancer subtype classification, paving the way for improved clinical decision-making. 

**Abstract (ZH)**: 基于多模态学习的乳腺癌分子亚型分类对于个性化治疗和预后至关重要。传统分类方法依赖于组织病理学图像或基因表达谱，限制了其预测能力。在本研究中，我们提出了一种深度多模态学习框架，将组织病理学图像和基因表达数据结合起来，将乳腺癌分类为luminal A/luminal B /Her2亚型。我们的方法使用ResNet-50模型进行图像特征提取，并使用全连接层处理基因表达数据，采用交叉注意力融合机制以增强模态间交互。通过五折交叉验证进行广泛的实验，结果显示，我们的多模态集成在分类准确性、精确召回AUC和F1分数等方面优于单一模态方法。我们的研究结果强调了深度学习在稳健且可解释的乳腺癌亚型分类中的潜力，为改进临床决策铺平了道路。 

---
# SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting 

**Title (ZH)**: SeqFusion: 预训练模型的序列融合在零样本时间序列预测中的应用 

**Authors**: Ting-Ji Huang, Xu-Yang Chen, Han-Jia Ye  

**Link**: [PDF](https://arxiv.org/pdf/2503.02836)  

**Abstract**: Unlike traditional time-series forecasting methods that require extensive in-task data for training, zero-shot forecasting can directly predict future values given a target time series without additional training data. Current zero-shot approaches primarily rely on pre-trained generalized models, with their performance often depending on the variety and relevance of the pre-training data, which can raise privacy concerns. Instead of collecting diverse pre-training data, we introduce SeqFusion in this work, a novel framework that collects and fuses diverse pre-trained models (PTMs) sequentially for zero-shot forecasting. Based on the specific temporal characteristics of the target time series, SeqFusion selects the most suitable PTMs from a batch of pre-collected PTMs, performs sequential predictions, and fuses all the predictions while using minimal data to protect privacy. Each of these PTMs specializes in different temporal patterns and forecasting tasks, allowing SeqFusion to select by measuring distances in a shared representation space of the target time series with each PTM. Experiments demonstrate that SeqFusion achieves competitive accuracy in zero-shot forecasting compared to state-of-the-art methods. 

**Abstract (ZH)**: 不同于传统的时间序列预测方法需要大量的在任务数据进行训练，零样本预测可以直接根据目标时间序列预测未来值而无需额外的训练数据。当前的零样本方法主要依赖于预训练的一般模型，其性能往往取决于预训练数据的多样性和相关性，这可能会引起隐私问题。本工作中，我们引入SeqFusion框架，该框架可以通过序列化地收集和融合预训练模型（PTMs）来进行零样本预测，基于目标时间序列的特定时序特征，SeqFusion从预收集的PTMs中选择最合适的模型进行序列化预测，并在使用 minimal 数据保护隐私的同时融合所有预测。每个PTMs专注于不同的时序模式和预测任务，SeqFusion通过在目标时间序列与每个PTM的共享表示空间中测量距离来选择最合适的模型。实验表明，SeqFusion在零样本预测中的准确性与最先进的方法相当。 

---
# AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation 

**Title (ZH)**: AlignDistil: 令牌级别语言模型对齐作为自适应策略蒸馏 

**Authors**: Songming Zhang, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02832)  

**Abstract**: In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization. 

**Abstract (ZH)**: 现代大规模语言模型（LLMs）的对齐优化：基于DPO的token级奖励优化蒸馏方法 

---
# Developing a PET/CT Foundation Model for Cross-Modal Anatomical and Functional Imaging 

**Title (ZH)**: 开发一种PET/CT跨模态解剖与功能成像基础模型 

**Authors**: Yujin Oh, Robert Seifert, Yihan Cao, Christoph Clement, Justin Ferdinandus, Constantin Lapa, Alessandro Liebich, Michelle Amon, Johanna Enke, Sifan Song, Runqi Meng, Fang Zeng, Ning Guo, Xiang Li, Pedram Heidari, Axel Rominger, Kuangyu Shi, Quanzheng Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.02824)  

**Abstract**: In oncology, Positron Emission Tomography-Computed Tomography (PET/CT) is widely used in cancer diagnosis, staging, and treatment monitoring, as it combines anatomical details from CT with functional metabolic activity and molecular marker expression information from PET. However, existing artificial intelligence-driven PET/CT analyses rely predominantly on task-specific models trained from scratch or on limited datasets, limiting their generalizability and robustness. To address this, we propose a foundation model approach specifically designed for multimodal PET/CT imaging. We introduce the Cross-Fraternal Twin Masked Autoencoder (FratMAE), a novel framework that effectively integrates whole-body anatomical and functional or molecular information. FratMAE employs separate Vision Transformer (ViT) encoders for PET and CT scans, along with cross-attention decoders that enable synergistic interactions between modalities during masked autoencoder training. Additionally, it incorporates textual metadata to enhance PET representation learning. By pre-training on PET/CT datasets, FratMAE captures intricate cross-modal relationships and global uptake patterns, achieving superior performance on downstream tasks and demonstrating its potential as a generalizable foundation model. 

**Abstract (ZH)**: 在肿瘤学中，正电子发射断层扫描-计算机断层扫描（PET/CT）广泛用于癌症诊断、分期和治疗监测，因为它结合了CT的解剖细节和PET的功能代谢活动及分子标志物表达信息。然而，现有的基于人工智能的PET/CT分析主要依赖于从头训练的任务特定模型或有限的数据集，限制了其泛化能力和 robustness。为此，我们提出了一种专门为多模态PET/CT成像设计的基础模型方法。我们引入了跨同胞双胞胎掩蔽自动编码器（FratMAE）这一新颖框架，能够有效地整合全身解剖和功能或分子信息。FratMAE使用分别针对PET和CT扫描的视觉变换器（ViT）编码器，以及跨注意力解码器，在掩蔽自动编码器训练过程中实现模态间的协同交互。此外，它还整合了文本元数据以增强PET表征学习。通过在PET/CT数据集上进行预训练，FratMAE捕获了复杂的跨模态关系和全球摄取模式，实现了下游任务的优越性能，并展示了其作为泛化基础模型的潜力。 

---
# A Multimodal Symphony: Integrating Taste and Sound through Generative AI 

**Title (ZH)**: 多模态交响曲：通过生成式AI整合味觉与听觉 

**Authors**: Matteo Spanio, Massimiliano Zampini, Antonio Rodà, Franco Pierucci  

**Link**: [PDF](https://arxiv.org/pdf/2503.02823)  

**Abstract**: In recent decades, neuroscientific and psychological research has traced direct relationships between taste and auditory perceptions. This article explores multimodal generative models capable of converting taste information into music, building on this foundational research. We provide a brief review of the state of the art in this field, highlighting key findings and methodologies. We present an experiment in which a fine-tuned version of a generative music model (MusicGEN) is used to generate music based on detailed taste descriptions provided for each musical piece. The results are promising: according the participants' ($n=111$) evaluation, the fine-tuned model produces music that more coherently reflects the input taste descriptions compared to the non-fine-tuned model. This study represents a significant step towards understanding and developing embodied interactions between AI, sound, and taste, opening new possibilities in the field of generative AI. We release our dataset, code and pre-trained model at: this https URL. 

**Abstract (ZH)**: 近几十年来，神经科学和心理学研究已揭示了味觉与听觉感知之间的直接关系。本文探讨了能够将味觉信息转换为音乐的多模态生成模型，建立在这一基础研究之上。我们简要回顾了该领域的最新进展，突出显示了关键发现和研究方法。我们提出了一项实验，在该实验中，对生成音乐模型（MusicGEN）进行了微调，并根据为每首音乐作品提供的详细味觉描述生成音乐。结果显示：根据111名参与者的意见评价，微调后的模型生成的音乐更连贯地反映了输入的味觉描述，与未经微调的模型相比更为一致。本文代表了理解并发展人工智能、声音和味觉之间实体交互的重要一步，为生成人工智能领域开辟了新的可能性。我们发布了我们的数据集、代码和预训练模型：[这个链接](this https URL)。 

---
# Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression 

**Title (ZH)**: Q-滤波器：利用QK几何学高效键值缓存压缩 

**Authors**: Nathan Godey, Alessio Devoto, Yu Zhao, Simone Scardapane, Pasquale Minervini, Éric de la Clergerie, Benoît Sagot  

**Link**: [PDF](https://arxiv.org/pdf/2503.02812)  

**Abstract**: Autoregressive language models rely on a Key-Value (KV) Cache, which avoids re-computing past hidden states during generation, making it faster. As model sizes and context lengths grow, the KV Cache becomes a significant memory bottleneck, which calls for compression methods that limit its size during generation. In this paper, we discover surprising properties of Query (Q) and Key (K) vectors that allow us to efficiently approximate attention scores without computing the attention maps. We propose Q-Filters, a training-free KV Cache compression method that filters out less crucial Key-Value pairs based on a single context-agnostic projection. Contrarily to many alternatives, Q-Filters is compatible with FlashAttention, as it does not require direct access to attention weights. Experimental results in long-context settings demonstrate that Q-Filters is competitive with attention-based compression methods such as SnapKV in retrieval tasks while consistently outperforming efficient compression schemes such as Streaming-LLM in generation setups. Notably, Q-Filters achieves a 99% accuracy in the needle-in-a-haystack task with a x32 compression level while reducing the generation perplexity drop by up to 65% in text generation compared to Streaming-LLM. 

**Abstract (ZH)**: 自动回归语言模型依赖于键值（KV）缓存，这在生成过程中避免了重新计算过去的隐藏状态，从而使模型更快。随着模型规模和上下文长度的增长，KV缓存成为显著的内存瓶颈，需要压缩方法来限制其生成过程中的大小。在本文中，我们发现了查询（Q）向量和键（K）向量的意外属性，允许我们高效地近似注意力分数而无需计算注意力图。我们提出了一种无需训练的KV缓存压缩方法Q-Filters，该方法基于单个上下文无关的投影过滤掉不那么关键的键值对。与许多替代方案不同，Q-Filters与FlashAttention兼容，因为它不需要直接访问注意力权重。在长上下文设置下的实验结果表明，在检索任务中，Q-Filters与基于注意力的压缩方法（如SnapKV）具有竞争力，而在生成设置中，其性能始终优于诸如Streaming-LLM等高效的压缩方案。值得注意的是，Q-Filters在稀疏检索任务中实现了99%的准确性，压缩比为32倍，在文本生成中将生成困惑度下降最多减少65%，相较于Streaming-LLM。 

---
# A Causal Framework for Aligning Image Quality Metrics and Deep Neural Network Robustness 

**Title (ZH)**: 因果框架下图像质量度量与深度神经网络鲁棒性的对齐 

**Authors**: Nathan Drenkow, Mathias Unberath  

**Link**: [PDF](https://arxiv.org/pdf/2503.02797)  

**Abstract**: Image quality plays an important role in the performance of deep neural networks (DNNs) and DNNs have been widely shown to exhibit sensitivity to changes in imaging conditions. Large-scale datasets often contain images under a wide range of conditions prompting a need to quantify and understand their underlying quality distribution in order to better characterize DNN performance and robustness. Aligning the sensitivities of image quality metrics and DNNs ensures that estimates of quality can act as proxies for image/dataset difficulty independent of the task models trained/evaluated on the data. Conventional image quality assessment (IQA) seeks to measure and align quality relative to human perceptual judgments, but here we seek a quality measure that is not only sensitive to imaging conditions but also well-aligned with DNN sensitivities. We first ask whether conventional IQA metrics are also informative of DNN performance. In order to answer this question, we reframe IQA from a causal perspective and examine conditions under which quality metrics are predictive of DNN performance. We show theoretically and empirically that current IQA metrics are weak predictors of DNN performance in the context of classification. We then use our causal framework to provide an alternative formulation and a new image quality metric that is more strongly correlated with DNN performance and can act as a prior on performance without training new task models. Our approach provides a means to directly estimate the quality distribution of large-scale image datasets towards characterizing the relationship between dataset composition and DNN performance. 

**Abstract (ZH)**: 图像质量在深度神经网络（DNN）性能中扮演重要角色，并且DNNs已被广泛证明对成像条件的变化表现出敏感性。为了更好地表征DNN性能和鲁棒性，需要量化和理解大规模数据集在不同条件下的内在质量分布。使图像质量度量的敏感性与DNNs相一致，可以确保质量估计能够作为独立于任务模型训练/评估的图像/数据难度的代理指标。传统的图像质量评估（IQA）旨在测量和调整质量与人类感知判断的相对关系，但在这里我们寻求一种不仅对成像条件敏感，而且与DNNs敏感性高度一致的质量度量。我们首先询问传统的IQA度量是否也对DNN性能有信息价值。为了回答这个问题，我们从因果角度重新定义IQA，并研究在哪些条件下质量度量能够预测DNN性能。我们理论和实验证明，当前的IQA度量在分类背景下对DNN性能的预测能力较弱。然后，我们使用我们的因果框架提出一种替代的方法和一个新的图像质量度量，该度量与DNN性能的相关性更强，并且可以在不训练新的任务模型的情况下作为性能的先验。我们的方法提供了一种直接估计大规模图像数据集的质量分布的方法，旨在表征数据集组成与DNN性能之间的关系。 

---
# Do Not Trust Licenses You See -- Dataset Compliance Requires Massive-Scale AI-Powered Lifecycle Tracing 

**Title (ZH)**: 不要轻信你看到的许可——数据集合规需要大规模AI驱动的生命周期追踪 

**Authors**: Jaekyeom Kim, Sungryull Sohn, Gerrard Jeongwon Jo, Jihoon Choi, Kyunghoon Bae, Hwayoung Lee, Yongmin Park, Honglak Lee  

**Link**: [PDF](https://arxiv.org/pdf/2503.02784)  

**Abstract**: This paper argues that a dataset's legal risk cannot be accurately assessed by its license terms alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this process is too complex for legal experts to handle manually at scale. Tracking dataset provenance, verifying redistribution rights, and assessing evolving legal risks across multiple stages require a level of precision and efficiency that exceeds human capabilities. Addressing this challenge effectively demands AI agents that can systematically trace dataset redistribution, analyze compliance, and identify legal risks. We develop an automated data compliance system called NEXUS and show that AI can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts. Our massive legal analysis of 17,429 unique entities and 8,072 license terms using this approach reveals the discrepancies in legal rights between the original datasets before redistribution and their redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance. For instance, we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21%) are legally permissible for commercialization. This work sets a new standard for AI data governance, advocating for a framework that systematically examines the entire lifecycle of dataset redistribution to ensure transparent, legal, and responsible dataset management. 

**Abstract (ZH)**: 本文argues数据集的法律风险不能仅通过其许可条款来准确评估；而是需要跟踪数据集的再分配及其完整生命周期。然而，这一过程对法律专家来说在大规模处理时太过复杂。追踪数据集的来源、验证再分配权利并在多个阶段评估不断变化的法律风险需要超出人类能力的精度和效率。有效应对这一挑战需要能够系统追踪数据集再分配、分析合规性并识别法律风险的AI代理。我们开发了一种名为NEXUS的自动化数据合规系统，并证明AI能够比人类专家以更高的准确率、效率和成本效益执行这些任务。采用这种方法对17,429个独特实体和8,072个许可条款进行大规模法律分析揭示了再分配前的数据集与其再分配子集之间的法律权利差异，强调了数据生命周期意识合规的重要性。例如，我们发现，在2,852个具有商业可行许可条款的数据集中，只有605个（21%）合法可用于商业化。这项工作为AI数据治理设定了新的标准，倡导一种系统地检查数据集再分配全流程的框架，以确保透明、合法和负责任的数据管理。 

---
# IterPref: Focal Preference Learning for Code Generation via Iterative Debugging 

**Title (ZH)**: IterPref: 通过迭代调试进行代码生成的焦点偏好学习 

**Authors**: Jie Wu, Haoling Li, Xin Zhang, Jianwen Luo, Yangyu Huang, Ruihang Chu, Yujiu Yang, Scarlett Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.02783)  

**Abstract**: Preference learning enhances Code LLMs beyond supervised fine-tuning by leveraging relative quality comparisons. Existing methods construct preference pairs from
candidates based on test case success, treating the higher pass rate sample as positive and the lower as negative. However, this approach does not pinpoint specific errors in the code, which prevents the model from learning more informative error correction patterns, as aligning failing code as a whole lacks the granularity needed to capture meaningful error-resolution relationships. To address these issues, we propose IterPref, a new preference alignment framework that mimics human iterative debugging to refine Code LLMs. IterPref explicitly locates error regions and aligns the corresponding tokens via a tailored DPO algorithm. To generate informative pairs, we introduce the CodeFlow dataset, where samples are iteratively refined until passing tests, with modifications capturing error corrections. Extensive experiments show that a diverse suite of Code LLMs equipped with IterPref achieves significant performance gains in code generation and improves on challenging tasks like BigCodeBench. In-depth analysis reveals that IterPref yields fewer errors. Our code and data will be made publicaly available. 

**Abstract (ZH)**: 偏好学习通过利用相对质量比较提升代码LLM，超越监督微调。现有方法基于测试案例成功构建偏好对，将通过率较高的样本视为正样本，通过率较低的视为负样本。然而，这种方法不能具体指出代码中的错误，这妨碍了模型学习更有信息量的错误修正模式，因为将整体失败的代码对齐缺乏捕捉有意义的错误解决关系所需的粒度。为了应对这些问题，我们提出了一种新的偏好对齐框架IterPref，其模仿人类迭代调试以精炼代码LLM。IterPref明确定位错误区域并通过定制的DPO算法对相应的标记进行对齐。为了生成有信息量的对，我们引入了CodeFlow数据集，在该数据集中，样本经过迭代精炼直到通过测试，并且修改记录了错误修正。广泛的实验表明，配备IterPref的多样化代码LLM在代码生成中取得了显著性能提升，并在BigCodeBench等具有挑战性的任务上有所改进。深入分析显示，IterPref产生的错误更少。我们的代码和数据将公开提供。 

---
# Implicit Bias in LLMs: A Survey 

**Title (ZH)**: LLMs中的隐性偏见：一项综述 

**Authors**: Xinru Lin, Luyang Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.02776)  

**Abstract**: Due to the implement of guardrails by developers, Large language models (LLMs) have demonstrated exceptional performance in explicit bias tests. However, bias in LLMs may occur not only explicitly, but also implicitly, much like humans who consciously strive for impartiality yet still harbor implicit bias. The unconscious and automatic nature of implicit bias makes it particularly challenging to study. This paper provides a comprehensive review of the existing literature on implicit bias in LLMs. We begin by introducing key concepts, theories and methods related to implicit bias in psychology, extending them from humans to LLMs. Drawing on the Implicit Association Test (IAT) and other psychological frameworks, we categorize detection methods into three primary approaches: word association, task-oriented text generation and decision-making. We divide our taxonomy of evaluation metrics for implicit bias into two categories: single-value-based metrics and comparison-value-based metrics. We classify datasets into two types: sentences with masked tokens and complete sentences, incorporating datasets from various domains to reflect the broad application of LLMs. Although research on mitigating implicit bias in LLMs is still limited, we summarize existing efforts and offer insights on future challenges. We aim for this work to serve as a clear guide for researchers and inspire innovative ideas to advance exploration in this task. 

**Abstract (ZH)**: 由于开发人员实施了护栏措施，大型语言模型（LLMs）在显性偏见测试中表现出色。然而，LLMs中的偏见不仅可能以显性形式存在，也可能以隐性形式存在，如同人类虽然会主动追求公正，但仍可能存在隐性偏见一样。隐性和自动化的性质使隐性偏见特别难以研究。本文对LLMs中隐性偏见的现有文献进行了全面综述。我们首先介绍与心理学中隐性偏见相关的关键概念、理论和方法，并将其扩展到LLMs。借助隐含关联测试（IAT）及其他心理学框架，我们将检测方法分为三大类：词联想法、任务导向文本生成和决策。我们将评估隐性偏见的一套综合指标分为两类：单值指标和比较值指标。我们将数据集分为两类：包含掩码词的句子和完整句子，并且结合了来自不同领域的数据集以反映LLMs的广泛应用。尽管缓解LLMs中隐性偏见的研究仍有限，但我们总结了现有努力并提供了对未来挑战的见解。我们希望这项工作能够为研究人员提供清晰的指南，并激发创新思路以推进这一领域的探索。 

---
# Improving Oil Slick Trajectory Simulations with Bayesian Optimization 

**Title (ZH)**: 使用贝叶斯优化改进油污轨迹仿真 

**Authors**: Gabriele Accarino, Marco M. De Carlo, Igor Atake, Donatello Elia, Anusha L. Dissanayake, Antonio Augusto Sepp Neves, Juan Peña Ibañez, Italo Epicoco, Paola Nassisi, Sandro Fiore, Giovanni Coppini  

**Link**: [PDF](https://arxiv.org/pdf/2503.02749)  

**Abstract**: Accurate simulations of oil spill trajectories are essential for supporting practitioners' response and mitigating environmental and socioeconomic impacts. Numerical models, such as MEDSLIK-II, simulate advection, dispersion, and transformation processes of oil particles. However, simulations heavily rely on accurate parameter tuning, still based on expert knowledge and manual calibration. To overcome these limitations, we integrate the MEDSLIK-II numerical oil spill model with a Bayesian optimization framework to iteratively estimate the best physical parameter configuration that yields simulation closer to satellite observations of the slick. We focus on key parameters, such as horizontal diffusivity and drift factor, maximizing the Fraction Skill Score (FSS) as a measure of spatio-temporal overlap between simulated and observed oil distributions. We validate the framework for the Baniyas oil incident that occurred in Syria between August 23 and September 4, 2021, which released over 12,000 $m^3$ of oil. We show that, on average, the proposed approach systematically improves the FSS from 5.82% to 11.07% compared to control simulations initialized with default parameters. The optimization results in consistent improvement across multiple time steps, particularly during periods of increased drift variability, demonstrating the robustness of our method in dynamic environmental conditions. 

**Abstract (ZH)**: 准确模拟油污轨迹对于支持应急响应和减轻环境及经济影响至关重要。我们结合MEDSLIK-II数值油污模型与贝叶斯优化框架，迭代估计最优物理参数配置，使模拟结果更接近于油污的卫星观测数据。我们专注于关键参数，如水平扩散系数和漂流因子，以分数技能评分（FSS）作为模拟和观测油污时空分布重叠的度量。我们对2021年8月23日至9月4日在叙利亚发生的巴尼雅斯油污事件进行了验证，该事件导致超过12,000立方米的原油泄漏。结果显示，与使用默认参数初始化的控制模拟相比，所提出的方法平均提高了FSS，从5.82%提高到11.07%。优化结果在多个时间步长中表现出一致的改进，特别是在漂移可变性增加的时期，证明了该方法在动态环境条件下的鲁棒性。 

---
# UAR-NVC: A Unified AutoRegressive Framework for Memory-Efficient Neural Video Compression 

**Title (ZH)**: 统一自回归框架：一种内存高效神经视频压缩方法 

**Authors**: Jia Wang, Xinfeng Zhang, Gai Zhang, Jun Zhu, Lv Tang, Li Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02733)  

**Abstract**: Implicit Neural Representations (INRs) have demonstrated significant potential in video compression by representing videos as neural networks. However, as the number of frames increases, the memory consumption for training and inference increases substantially, posing challenges in resource-constrained scenarios. Inspired by the success of traditional video compression frameworks, which process video frame by frame and can efficiently compress long videos, we adopt this modeling strategy for INRs to decrease memory consumption, while aiming to unify the frameworks from the perspective of timeline-based autoregressive modeling. In this work, we present a novel understanding of INR models from an autoregressive (AR) perspective and introduce a Unified AutoRegressive Framework for memory-efficient Neural Video Compression (UAR-NVC). UAR-NVC integrates timeline-based and INR-based neural video compression under a unified autoregressive paradigm. It partitions videos into several clips and processes each clip using a different INR model instance, leveraging the advantages of both compression frameworks while allowing seamless adaptation to either in form. To further reduce temporal redundancy between clips, we design two modules to optimize the initialization, training, and compression of these model parameters. UAR-NVC supports adjustable latencies by varying the clip length. Extensive experimental results demonstrate that UAR-NVC, with its flexible video clip setting, can adapt to resource-constrained environments and significantly improve performance compared to different baseline models. 

**Abstract (ZH)**: 基于自回归建模的统一记忆高效神经视频压缩框架（UAR-NVC） 

---
# Vibration-Assisted Hysteresis Mitigation for Achieving High Compensation Efficiency 

**Title (ZH)**: 振动辅助滞回回程抑制以实现高补偿效率 

**Authors**: Myeongbo Park, Chunggil An, Junhyun Park, Jonghyun Kang, Minho Hwang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02720)  

**Abstract**: Tendon-sheath mechanisms (TSMs) are widely used in minimally invasive surgical (MIS) applications, but their inherent hysteresis-caused by friction, backlash, and tendon elongation-leads to significant tracking errors. Conventional modeling and compensation methods struggle with these nonlinearities and require extensive parameter tuning. To address this, we propose a vibration-assisted hysteresis compensation approach, where controlled vibrational motion is applied along the tendon's movement direction to mitigate friction and reduce dead zones. Experimental results demonstrate that the exerted vibration consistently reduces hysteresis across all tested frequencies, decreasing RMSE by up to 23.41% (from 2.2345 mm to 1.7113 mm) and improving correlation, leading to more accurate trajectory tracking. When combined with a Temporal Convolutional Network (TCN)-based compensation model, vibration further enhances performance, achieving an 85.2% reduction in MAE (from 1.334 mm to 0.1969 mm). Without vibration, the TCN-based approach still reduces MAE by 72.3% (from 1.334 mm to 0.370 mm) under the same parameter settings. These findings confirm that vibration effectively mitigates hysteresis, improving trajectory accuracy and enabling more efficient compensation models with fewer trainable parameters. This approach provides a scalable and practical solution for TSM-based robotic applications, particularly in MIS. 

**Abstract (ZH)**: 腱鞘机制(TSMs)在微创手术(MIS)应用中广泛使用，但由于摩擦、间隙和肌腱伸长导致的固有滞后性，造成了显著的跟踪误差。传统建模和补偿方法难以应对这些非线性特性，并需要大量参数调整。为解决这一问题，我们提出了一种振动辅助滞后补偿方法，该方法通过在肌腱运动方向施加受控的振动运动来缓解摩擦并减少无效区域。实验结果表明，施加的振动在所有测试频率下都能一致地减少滞后性，RMSE最多降低23.41%（从2.2345 mm降至1.7113 mm），并提高了相关性，从而实现更准确的轨迹跟踪。当与基于时序卷积网络(TCN)的补偿模型结合使用时，振动进一步提升了性能，MAE降低了85.2%（从1.334 mm降至0.1969 mm）。在没有振动的情况下，基于TCN的方法在同一参数设置下仍能使MAE降低72.3%（从1.334 mm降至0.370 mm）。这些发现证实了振动有效地缓解了滞后性，提高了轨迹准确性，并使补偿模型更加高效，具有更少的可训练参数。该方法为基于TSM的机器人应用提供了可扩展且实用的解决方案，特别是在微创手术中。 

---
# Generative Tools for Graphical Assets: Empirical Guidelines based on Game Designers' and Developers' Preferences 

**Title (ZH)**: 图形资产生成工具：基于游戏设计师和开发者偏好的实证指南 

**Authors**: Kaisei Fukaya, Damon Daylamani-Zad, Harry Agius  

**Link**: [PDF](https://arxiv.org/pdf/2503.02703)  

**Abstract**: Graphical assets play an important role in the design and development of games. There is potential in the use of generative tools, to aid in creating graphical assets, thus improving game design and development pipelines. However, there is little research to address how the generative methods can fit into the wider pipeline. We conducted a user study with 16 game designers and developers to examine their preferences regarding generative tools for graphical assets. The findings highlight that early design stage is preferred by all participants (mean values above 0.67 and p < .001 for early stages). Designers and developers prefer to use such tools for creating large amounts of variations at the cost of quality as they can improve the quality of the artefacts once they generate a suitable asset (mean value 0.17 where 1 is high quality, p < .001). They also strongly (mean value .78, p < .001) raised the need for better integration of such tools in existing design and development environments and the need for the outputs to be in common data formats, to be manipulatable and integrate smoothly into existing environments (mean 3.5 out of 5, p = .004). The study also highlights the requirement for further emphasis on the needs of the users to incorporate these tools effectively in existing pipelines. Informed by these results, we provide a set of guidelines for creating tools that meet the expectations and needs of game designers and developers. 

**Abstract (ZH)**: 图形资产在游戏设计与开发中的作用日益重要。生成性工具的应用有望提升图形资产的创建，进而改进游戏设计与开发流程。然而，关于生成性方法如何融入更广泛流程的研究较为不足。我们通过一项包含16名游戏设计师与开发者的用户研究，探索了他们对生成性工具的偏好。研究发现，所有参与者均偏好于在早期设计阶段使用这些工具（早期阶段均值高于0.67，p < .001）。设计师和开发者倾向于利用这些工具生成大量变体，尽管代价可能是质量的牺牲，但一旦生成合适资产，它们能够提升最终产出的质量（质量均值0.17，1表示高质量，p < .001）。研究还显示，参与者强烈要求更好地将此类工具整合到现有设计与开发环境中，并希望输出可采用常见数据格式、可操作且能平滑整合到现有环境（均值3.5，p = .004）。另外，研究进一步强调了需更关注用户需求，以有效将这些工具整合到现有流程中。根据这些结果，我们提出了设计满足游戏设计师和开发人员期望与需求工具的指导原则。 

---
# Memory Efficient Continual Learning for Edge-Based Visual Anomaly Detection 

**Title (ZH)**: 基于边缘的视觉异常检测的高效持续学习方法 

**Authors**: Manuel Barusco, Lorenzo D'Antoni, Davide Dalle Pezze, Francesco Borsatti, Gian Antonio Susto  

**Link**: [PDF](https://arxiv.org/pdf/2503.02691)  

**Abstract**: Visual Anomaly Detection (VAD) is a critical task in computer vision with numerous real-world applications. However, deploying these models on edge devices presents significant challenges, such as constrained computational and memory resources. Additionally, dynamic data distributions in real-world settings necessitate continuous model adaptation, further complicating deployment under limited resources. To address these challenges, we present a novel investigation into the problem of Continual Learning for Visual Anomaly Detection (CLAD) on edge devices. We evaluate the STFPM approach, given its low memory footprint on edge devices, which demonstrates good performance when combined with the Replay approach. Furthermore, we propose to study the behavior of a recently proposed approach, PaSTe, specifically designed for the edge but not yet explored in the Continual Learning context. Our results show that PaSTe is not only a lighter version of STPFM, but it also achieves superior anomaly detection performance, improving the f1 pixel performance by 10% with the Replay technique. In particular, the structure of PaSTe allows us to test it using a series of Compressed Replay techniques, reducing memory overhead by a maximum of 91.5% compared to the traditional Replay for STFPM. Our study proves the feasibility of deploying VAD models that adapt and learn incrementally on CLAD scenarios on resource-constrained edge devices. 

**Abstract (ZH)**: Visual异常检测持续学习（CLAD）在边缘设备上的研究 

---
# Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds? 

**Title (ZH)**: 基于类别的柱状混合增强：混合样本数据增强能否提升雷达点云的3D目标检测？ 

**Authors**: Miao Zhang, Sherif Abdulatif, Benedikt Loesch, Marco Altmann, Bin Yang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02687)  

**Abstract**: Due to the significant effort required for data collection and annotation in 3D perception tasks, mixed sample data augmentation (MSDA) has been widely studied to generate diverse training samples by mixing existing data. Recently, many MSDA techniques have been developed for point clouds, but they mainly target LiDAR data, leaving their application to radar point clouds largely unexplored. In this paper, we examine the feasibility of applying existing MSDA methods to radar point clouds and identify several challenges in adapting these techniques. These obstacles stem from the radar's irregular angular distribution, deviations from a single-sensor polar layout in multi-radar setups, and point sparsity. To address these issues, we propose Class-Aware PillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar level in 3D point clouds, guided by class labels. Unlike methods that rely a single mix ratio to the entire sample, CAPMix assigns an independent ratio to each pillar, boosting sample diversity. To account for the density of different classes, we use class-specific distributions: for dense objects (e.g., large vehicles), we skew ratios to favor points from another sample, while for sparse objects (e.g., pedestrians), we sample more points from the original. This class-aware mixing retains critical details and enriches each sample with new information, ultimately generating more diverse training data. Experimental results demonstrate that our method not only significantly boosts performance but also outperforms existing MSDA approaches across two datasets (Bosch Street and K-Radar). We believe that this straightforward yet effective approach will spark further investigation into MSDA techniques for radar data. 

**Abstract (ZH)**: 基于雷达点云的类意识柱混合（CAPMix）：一种用于3D感知任务的混合样本数据增强方法 

---
# MPO: Boosting LLM Agents with Meta Plan Optimization 

**Title (ZH)**: MPO: 通过元计划优化提升语言模型代理 

**Authors**: Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song, Xun Wang, Sujian Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.02682)  

**Abstract**: Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance. Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent's task execution. Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines. Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios. 

**Abstract (ZH)**: Recent advancements in大型语言模型（LLMs）使基于LLM的代理能够成功解决交互式规划任务。然而，尽管取得了成功，现有方法往往遭受规划幻觉的问题，并且需要为每个新代理重新训练。为应对这些挑战，我们提出了一种Meta Plan Optimization（MPO）框架，通过直接引入明确的指导来增强代理的规划能力。与依赖复杂知识的先前方法不同，这些知识要么需要大量的人工努力，要么缺乏质量保证，MPO利用高层次的一般指导（元计划）来协助代理规划，并根据代理任务执行的反馈持续优化元计划。我们在两个代表性任务上的实验表明，MPO显著优于现有baseline。此外，我们的分析表明，MPO提供了一种即插即用的解决方案，能够提升任务完成效率和在以前未见场景中的泛化能力。 

---
# State of play and future directions in industrial computer vision AI standards 

**Title (ZH)**: 工业计算机视觉AI标准的发展现状与未来方向 

**Authors**: Artemis Stefanidou, Panagiotis Radoglou-Grammatikis, Vasileios Argyriou, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos  

**Link**: [PDF](https://arxiv.org/pdf/2503.02675)  

**Abstract**: The recent tremendous advancements in the areas of Artificial Intelligence (AI) and Deep Learning (DL) have also resulted into corresponding remarkable progress in the field of Computer Vision (CV), showcasing robust technological solutions in a wide range of application sectors of high industrial interest (e.g., healthcare, autonomous driving, automation, etc.). Despite the outstanding performance of CV systems in specific domains, their development and exploitation at industrial-scale necessitates, among other, the addressing of requirements related to the reliability, transparency, trustworthiness, security, safety, and robustness of the developed AI models. The latter raises the imperative need for the development of efficient, comprehensive and widely-adopted industrial standards. In this context, this study investigates the current state of play regarding the development of industrial computer vision AI standards, emphasizing on critical aspects, like model interpretability, data quality, and regulatory compliance. In particular, a systematic analysis of launched and currently developing CV standards, proposed by the main international standardization bodies (e.g. ISO/IEC, IEEE, DIN, etc.) is performed. The latter is complemented by a comprehensive discussion on the current challenges and future directions observed in this regularization endeavor. 

**Abstract (ZH)**: 最近在人工智能（AI）和深度学习（DL）领域的显著进展也推动了计算机视觉（CV）领域取得了相应的重大进展，展示了在多个具有高度工业兴趣的应用领域（例如医疗保健、自动驾驶、自动化等）中 robust 的技术解决方案。尽管CV系统在其特定领域表现出色，但其在工业规模上的开发和利用需要解决与 AI 模型的可靠性和透明度、可信性、安全性和鲁棒性等相关要求，这迫切需要开发高效、全面且广泛采用的工业标准。在此背景下，本研究调查了目前工业计算机视觉 AI 标准的发展状况，重点强调了模型可解释性、数据质量和监管合规等关键方面。特别地，对主要国际标准化机构（如 ISO/IEC、IEEE、DIN 等）推出的和正在开发的 CV 标准进行了系统的分析。该分析补充了对该标准化努力中当前挑战和未来方向的全面讨论。 

---
# A dataset-free approach for self-supervised learning of 3D reflectional symmetries 

**Title (ZH)**: 无数据集自监督学习三维反射对称性的方法 

**Authors**: Issac Aguirre, Ivan Sipiran, Gabriel Montañana  

**Link**: [PDF](https://arxiv.org/pdf/2503.02660)  

**Abstract**: In this paper, we explore a self-supervised model that learns to detect the symmetry of a single object without requiring a dataset-relying solely on the input object itself. We hypothesize that the symmetry of an object can be determined by its intrinsic features, eliminating the need for large datasets during training. Additionally, we design a self-supervised learning strategy that removes the necessity of ground truth labels. These two key elements make our approach both effective and efficient, addressing the prohibitive costs associated with constructing large, labeled datasets for this task. The novelty of our method lies in computing features for each point on the object based on the idea that symmetric points should exhibit similar visual appearances. To achieve this, we leverage features extracted from a foundational image model to compute a visual descriptor for the points. This approach equips the point cloud with visual features that facilitate the optimization of our self-supervised model. Experimental results demonstrate that our method surpasses the state-of-the-art models trained on large datasets. Furthermore, our model is more efficient, effective, and operates with minimal computational and data resources. 

**Abstract (ZH)**: 本文探索了一种自监督模型，该模型能够在无需依赖数据集的情况下，仅通过输入的对象本身来学习检测单个对象的对称性。我们假设对象的对称性可以通过其固有特征来确定，从而在训练过程中无需大量数据集。此外，我们设计了一种自监督学习策略，消除了对ground truth标签的依赖。这两个关键元素使得我们的方法既有效又高效，能够解决构建大型标注数据集的高昂成本问题。我们的方法的创新之处在于，基于对称点应具有相似视觉特征的想法，为对象上的每个点计算特征。通过利用基础图像模型抽取的特征来计算点的视觉描述符，该方法为点云增添了视觉特征，促进了我们自监督模型的优化。实验结果表明，我们的方法在大型数据集上训练的模型上表现出更优越的效果。此外，我们的模型更高效、更有效，并且所需计算和数据资源较少。 

---
# YARE-GAN: Yet Another Resting State EEG-GAN 

**Title (ZH)**: YARE-GAN：又一休息状态EEG-GAN 

**Authors**: Yeganeh Farahzadi, Morteza Ansarinia, Zoltan Kekecs  

**Link**: [PDF](https://arxiv.org/pdf/2503.02636)  

**Abstract**: Generative Adversarial Networks (GANs) have shown promise in synthesising realistic neural data, yet their potential for unsupervised representation learning in resting-state EEG remains under explored. In this study, we implement a Wasserstein GAN with Gradient Penalty (WGAN-GP) to generate multi-channel resting-state EEG data and assess the quality of the synthesised signals through both visual and feature-based evaluations. Our results indicate that the model effectively captures the statistical and spectral characteristics of real EEG data, although challenges remain in replicating high-frequency oscillations in the frontal region. Additionally, we demonstrate that the Critic's learned representations can be fine-tuned for age group classification, achieving an out-of-sample accuracy, significantly better than a shuffled-label baseline. These findings suggest that generative models can serve not only as EEG data generators but also as unsupervised feature extractors, reducing the need for manual feature engineering. This study highlights the potential of GAN-based unsupervised learning for EEG analysis, suggesting avenues for more data-efficient deep learning applications in neuroscience. 

**Abstract (ZH)**: 生成对抗网络（GANs）在合成真实的神经数据方面展现了前景，但在静息态EEG的无监督表示学习方面仍待探索。在本研究中，我们采用带梯度惩罚的Wasserstein GAN（WGAN-GP）生成多通道静息态EEG数据，并通过视觉评估和特征评估来评估合成信号的质量。研究结果表明，模型有效地捕捉了真实EEG数据的统计和频谱特性，尽管在前额区域高频率振荡的复制上仍面临挑战。此外，我们展示了判别器学习到的表示可以微调用于年龄分组分类，其外样本准确性显著优于随机标签基线。这些发现表明，生成模型不仅可以作为EEG数据生成器，还可以作为无监督特征提取器，减少手动特征工程的需求。本研究突显了基于GAN的无监督学习在EEG分析中的潜在价值，为神经科学中的更高效深度学习应用指出了方向。 

---
# Reflection on Data Storytelling Tools in the Generative AI Era from the Human-AI Collaboration Perspective 

**Title (ZH)**: 从人机协作视角反思生成式AI时代的数据 storytelling 工具 

**Authors**: Haotian Li, Yun Wang, Huamin Qu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02631)  

**Abstract**: Human-AI collaborative tools attract attentions from the data storytelling community to lower the barrier of expertise and streamline the workflow. The recent advance in large-scale generative AI techniques, e.g., large language models (LLMs) and text-to-image models, has the potential to enhance data storytelling with their power in visual and narration generation. After two years since these techniques were publicly available, it is important to reflect our progress of applying them and have an outlook for future opportunities. To achieve the goal, we compare the collaboration patterns of the latest tools with those of earlier ones using a dedicated framework for understanding human-AI collaboration in data storytelling. Through comparison, we identify persistent collaboration patterns, e.g., human-creator + AI-assistant, and emerging ones, e.g., AI-creator + human-reviewer. The benefits of these AI techniques and other implications to human-AI collaboration are also revealed. We further propose future directions to hopefully ignite innovations. 

**Abstract (ZH)**: 大规模生成AI技术的进步吸引了数据讲故事社区的关注，以降低专业门槛并简化工作流程。近年来，大型语言模型（LLMs）和文本转图像模型等技术的发展为数据讲故事提供了强大的视觉和叙述生成能力。自这些技术公开以来两年时间里，反思其应用进展并对未来机遇进行展望变得尤为重要。为实现这一目标，我们使用一个专门的框架比较了最新工具与早期工具的人机协作模式。通过比较，我们识别出持续的人机协作模式，如人类创作+AI助理，以及新兴模式，如AI创作+人类审阅者。这些AI技术的优势及其他对人机协作的影响也得到了揭示。我们进一步提出未来方向，以期激发创新。 

---
# Towards Event Extraction with Massive Types: LLM-based Collaborative Annotation and Partitioning Extraction 

**Title (ZH)**: 面向大规模事件类型的事件提取：基于LLM的合作标注与分区提取 

**Authors**: Wenxuan Liu, Zixuan Li, Long Bai, Yuxin Zuo, Daozhu Xu, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2503.02628)  

**Abstract**: Developing a general-purpose extraction system that can extract events with massive types is a long-standing target in Event Extraction (EE). In doing so, the challenge comes from two aspects: 1) The absence of an efficient and effective annotation method. 2) The absence of a powerful extraction method can handle massive types. For the first challenge, we propose a collaborative annotation method based on Large Language Models (LLMs). Through collaboration among multiple LLMs, it first refines annotations of trigger words from distant supervision and then carries out argument annotation. Next, a voting phase consolidates the annotation preferences across different LLMs. Finally, we create the EEMT dataset, the largest EE dataset to date, featuring over 200,000 samples, 3,465 event types, and 6,297 role types. For the second challenge, we propose an LLM-based Partitioning EE method called LLM-PEE. To overcome the limited context length of LLMs, LLM-PEE first recalls candidate event types and then splits them into multiple partitions for LLMs to extract events. The results in the supervised setting show that LLM-PEE outperforms the state-of-the-art methods by 5.4 in event detection and 6.1 in argument extraction. In the zero-shot setting, LLM-PEE achieves up to 12.9 improvement compared to mainstream LLMs, demonstrating its strong generalization capabilities. 

**Abstract (ZH)**: 开发一种能够提取大量类型事件的一般-purpose抽取系统是事件抽取领域长期追求的目标。为应对这一挑战，我们提出了一种基于大规模语言模型的协作注释方法。通过多个大规模语言模型的合作，首先从弱监督中精炼触发词的注释，然后进行论元注释。接着，通过投票阶段整合不同大规模语言模型的注释偏好。最后，我们构建了EEMT数据集，这是迄今为止最大的事件抽取数据集，包含超过200,000个样本、3,465个事件类型和6,297个角色类型。为应对第二个挑战，我们提出了一种基于大规模语言模型的划分事件抽取方法（LLM-PEE）。为克服大规模语言模型上下文长度的限制，LLM-PEE首先召回候选事件类型，然后将它们划分为多个部分供大规模语言模型抽取事件。在监督设置下的实验结果表明，LLM-PEE在事件检测和论元抽取上的性能比当前最先进的方法分别高出5.4%和6.1%。在零样本设置下，LLM-PEE相比主流的大规模语言模型改善了最高12.9%，展示了其强大的泛化能力。 

---
# Rewarding Doubt: A Reinforcement Learning Approach to Confidence Calibration of Large Language Models 

**Title (ZH)**: 质疑的价值：大规模语言模型信心校准的强化学习方法 

**Authors**: Paul Stangel, David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Kamilia Zaripova, Matthias Keicher, Nassir Navab  

**Link**: [PDF](https://arxiv.org/pdf/2503.02623)  

**Abstract**: A safe and trustworthy use of Large Language Models (LLMs) requires an accurate expression of confidence in their answers. We introduce a novel Reinforcement Learning (RL) approach for LLM calibration that fine-tunes LLMs to elicit calibrated confidence estimations in their answers to factual questions. We model the problem as a betting game where the model predicts a confidence score together with every answer, and design a reward function that penalizes both over and under-confidence. We prove that under our reward design an optimal policy would result in a perfectly calibrated confidence estimation. Our experiments demonstrate significantly improved confidence calibration and generalization to new tasks without re-training, indicating that our approach teaches a general confidence awareness. This approach enables the training of inherently calibrated LLMs. 

**Abstract (ZH)**: 大型语言模型的安全和可信赖使用要求对其答案的准确信心表达。我们提出了一种新颖的强化学习（RL）方法来校准大型语言模型（LLMs），通过微调LLMs使其在回答事实性问题时能提供校准的信心估计。我们将问题建模为一个赌注游戏，模型在预测答案的同时也预测信心分数，并设计了一个既能惩罚过度信心又能惩罚不足信心的奖励函数。我们证明，在我们的奖励设计下，最优策略将导致完全校准的信心估计。我们的实验表明，这种方法在不重新训练的情况下显著提高了信心校准，并且能够泛化到新任务，表明该方法教会了模型一般的信心意识。这种方法使得训练出固有校准的大型语言模型成为可能。 

---
# Reinforcement Learning-based Threat Assessment 

**Title (ZH)**: 基于强化学习的威胁评估 

**Authors**: Wuzhou Sun, Siyi Li, Qingxiang Zou, Zixing Liao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02612)  

**Abstract**: In some game scenarios, due to the uncertainty of the number of enemy units and the priority of various attributes, the evaluation of the threat level of enemy units as well as the screening has been a challenging research topic, and the core difficulty lies in how to reasonably set the priority of different attributes in order to achieve quantitative evaluation of the threat. In this paper, we innovatively transform the problem of threat assessment into a reinforcement learning problem, and through systematic reinforcement learning training, we successfully construct an efficient neural network evaluator. The evaluator can not only comprehensively integrate the multidimensional attribute features of the enemy, but also effectively combine our state information, thus realizing a more accurate and scientific threat assessment. 

**Abstract (ZH)**: 在一些游戏场景中，由于敌方单位数量和各种属性优先级的不确定性，敌方单位威胁级别评估及其筛选一直是一个具有挑战性的研究课题，核心难点在于如何合理设定不同属性的优先级以实现威胁量化的评估。本文创新性地将威胁评估问题转化为强化学习问题，并通过系统的强化学习训练，成功构建了一个高效的人工神经网络评估器。该评估器不仅能够全面整合敌方的多维属性特征，还能有效结合我们的状态信息，从而实现更为准确和科学的威胁评估。 

---
# Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual Attention for Multimodal LLMs 

**Title (ZH)**: 所见即所解：解锁模态互注意中的因果注意力以改善多模态LLMs 

**Authors**: Wei-Yao Wang, Zhao Wang, Helen Suzuki, Yoshiyuki Kobayashi  

**Link**: [PDF](https://arxiv.org/pdf/2503.02597)  

**Abstract**: Recent Multimodal Large Language Models (MLLMs) have demonstrated significant progress in perceiving and reasoning over multimodal inquiries, ushering in a new research era for foundation models. However, vision-language misalignment in MLLMs has emerged as a critical challenge, where the textual responses generated by these models are not factually aligned with the given text-image inputs. Existing efforts to address vision-language misalignment have focused on developing specialized vision-language connectors or leveraging visual instruction tuning from diverse domains. In this paper, we tackle this issue from a fundamental yet unexplored perspective by revisiting the core architecture of MLLMs. Most MLLMs are typically built on decoder-only LLMs consisting of a causal attention mechanism, which limits the ability of earlier modalities (e.g., images) to incorporate information from later modalities (e.g., text). To address this problem, we propose AKI, a novel MLLM that unlocks causal attention into modality-mutual attention (MMA) to enable image tokens to attend to text tokens. This simple yet effective design allows AKI to achieve superior performance in 12 multimodal understanding benchmarks (+7.2% on average) without introducing additional parameters and increasing training time. Our MMA design is intended to be generic, allowing for application across various modalities, and scalable to accommodate diverse multimodal scenarios. The code is publicly available at this https URL, and we will release our AKI-4B model to encourage further advancements in MLLMs across various directions. 

**Abstract (ZH)**: 近期的多模态大型语言模型在处理和推理多模态查询方面取得了显著进步，开启了基础模型研究的新时代。然而，多模态大型语言模型中的视觉-语言不一致性已成为一个关键挑战，模型生成的文本响应与给定的文本-图像输入不一致。现有解决视觉-语言不一致性的方法主要集中在开发专门的视觉-语言连接器或利用来自不同领域的视觉指令调优上。本文从一个基础但未被充分探索的角度出发，重新审视多模态大型语言模型的核心架构。大多数多模态大型语言模型通常基于仅解码器的大规模语言模型，其中包含因果注意力机制，这限制了早期模态（如图像）从后续模态（如文本）获取信息的能力。为了解决这一问题，我们提出了一种名为AKI的新颖多模态大型语言模型，解锁因果注意力到模态互注意力（MMA），使图像令牌能够关注文本令牌。这一简单而有效的设计使AKI在12个多模态理解基准测试中表现卓越（平均提高7.2%），且无需增加参数数量和提高训练时间。我们的MMA设计旨在通用且可扩展，适用于各种模态，并可适应不同的多模态场景。有关代码请访问此网址，我们将发布AKI-4B模型，以促进在各种方向上进一步推进多模态大型语言模型的研究。 

---
# StageDesigner: Artistic Stage Generation for Scenography via Theater Scripts 

**Title (ZH)**: 舞台设计师：基于戏剧剧本的舞台艺术生成 

**Authors**: Zhaoxing Gan, Mengtian Li, Ruhua Chen, Zhongxia Ji, Sichen Guo, Huanling Hu, Guangnan Ye, Zuo Hu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02595)  

**Abstract**: In this work, we introduce StageDesigner, the first comprehensive framework for artistic stage generation using large language models combined with layout-controlled diffusion models. Given the professional requirements of stage scenography, StageDesigner simulates the workflows of seasoned artists to generate immersive 3D stage scenes. Specifically, our approach is divided into three primary modules: Script Analysis, which extracts thematic and spatial cues from input scripts; Foreground Generation, which constructs and arranges essential 3D objects; and Background Generation, which produces a harmonious background aligned with the narrative atmosphere and maintains spatial coherence by managing occlusions between foreground and background elements. Furthermore, we introduce the StagePro-V1 dataset, a dedicated dataset with 276 unique stage scenes spanning different historical styles and annotated with scripts, images, and detailed 3D layouts, specifically tailored for this task. Finally, evaluations using both standard and newly proposed metrics, along with extensive user studies, demonstrate the effectiveness of StageDesigner. Project can be found at: this https URL 

**Abstract (ZH)**: 本研究引入了StageDesigner，这是首个结合大规模语言模型与布局控制扩散模型的艺术舞台生成综合性框架。面对舞台布景的专业要求，StageDesigner模拟了资深艺术家的工作流程，生成沉浸式的3D舞台场景。具体而言，我们的方法分为三个主要模块：脚本分析，提取输入脚本中的主题和空间线索；前景生成，构建和排列关键3D对象；背景生成，产生与叙事氛围和谐一致的背景，并通过管理前景与背景元素间的遮挡保持空间连贯性。此外，我们还引入了StagePro-V1数据集，这是一个专门针对此项任务的数据集，包含276个不同历史风格的独特舞台场景，并标注有脚本、图像和详细的3D布局。最后，使用标准和新提出的评价指标以及广泛用户研究展示了StageDesigner的有效性。项目可在以下链接找到：this https URL。 

---
# LLM-Safety Evaluations Lack Robustness 

**Title (ZH)**: LLM安全评估缺乏稳健性 

**Authors**: Tim Beyer, Sophie Xhonneux, Simon Geisler, Gauthier Gidel, Leo Schwinn, Stephan Günnemann  

**Link**: [PDF](https://arxiv.org/pdf/2503.02574)  

**Abstract**: In this paper, we argue that current safety alignment research efforts for large language models are hindered by many intertwined sources of noise, such as small datasets, methodological inconsistencies, and unreliable evaluation setups. This can, at times, make it impossible to evaluate and compare attacks and defenses fairly, thereby slowing progress. We systematically analyze the LLM safety evaluation pipeline, covering dataset curation, optimization strategies for automated red-teaming, response generation, and response evaluation using LLM judges. At each stage, we identify key issues and highlight their practical impact. We also propose a set of guidelines for reducing noise and bias in evaluations of future attack and defense papers. Lastly, we offer an opposing perspective, highlighting practical reasons for existing limitations. We believe that addressing the outlined problems in future research will improve the field's ability to generate easily comparable results and make measurable progress. 

**Abstract (ZH)**: 本文 argues that当前大语言模型安全对齐研究的努力受到多种交织噪声源的阻碍，如小数据集、方法论不一致和不可靠的评估设置。这有时使得公正评估和比较攻击和防御变得不可能，从而拖慢了研究进展。我们系统地分析了LLM安全评估流程，涵盖数据集策管、自动红队优化策略、响应生成及使用LLM裁判的响应评估。在每个阶段，我们识别关键问题并强调其实际影响。我们还提出了一套指南，以减少未来攻击和防御论文评估中的噪声和偏见。最后，我们提供了一个对立的观点，强调现有限制的实践原因。我们认为，未来研究中解决这些问题将提高该领域生成可比结果和可衡量进展的能力。 

---
# RaceVLA: VLA-based Racing Drone Navigation with Human-like Behaviour 

**Title (ZH)**: 基于VLA的人类行为类比赛无人机导航 

**Authors**: Valerii Serpiva, Artem Lykov, Artyom Myshlyaev, Muhammad Haris Khan, Ali Alridha Abdulkarim, Oleg Sautenkov, Dzmitry Tsetserukou  

**Link**: [PDF](https://arxiv.org/pdf/2503.02572)  

**Abstract**: RaceVLA presents an innovative approach for autonomous racing drone navigation by leveraging Visual-Language-Action (VLA) to emulate human-like behavior. This research explores the integration of advanced algorithms that enable drones to adapt their navigation strategies based on real-time environmental feedback, mimicking the decision-making processes of human pilots. The model, fine-tuned on a collected racing drone dataset, demonstrates strong generalization despite the complexity of drone racing environments. RaceVLA outperforms OpenVLA in motion (75.0 vs 60.0) and semantic generalization (45.5 vs 36.3), benefiting from the dynamic camera and simplified motion tasks. However, visual (79.6 vs 87.0) and physical (50.0 vs 76.7) generalization were slightly reduced due to the challenges of maneuvering in dynamic environments with varying object sizes. RaceVLA also outperforms RT-2 across all axes - visual (79.6 vs 52.0), motion (75.0 vs 55.0), physical (50.0 vs 26.7), and semantic (45.5 vs 38.8), demonstrating its robustness for real-time adjustments in complex environments. Experiments revealed an average velocity of 1.04 m/s, with a maximum speed of 2.02 m/s, and consistent maneuverability, demonstrating RaceVLA's ability to handle high-speed scenarios effectively. These findings highlight the potential of RaceVLA for high-performance navigation in competitive racing contexts. The RaceVLA codebase, pretrained weights, and dataset are available at this http URL: this https URL 

**Abstract (ZH)**: RaceVLA：一种利用视觉-语言-行动（VLA）实现类人类行为的自主赛车无人机导航创新方法 

---
# World Models for Anomaly Detection during Model-Based Reinforcement Learning Inference 

**Title (ZH)**: 基于模型的强化学习推理过程中异常检测的World Models研究 

**Authors**: Fabian Domberg, Georg Schildbach  

**Link**: [PDF](https://arxiv.org/pdf/2503.02552)  

**Abstract**: Learning-based controllers are often purposefully kept out of real-world applications due to concerns about their safety and reliability. We explore how state-of-the-art world models in Model-Based Reinforcement Learning can be utilized beyond the training phase to ensure a deployed policy only operates within regions of the state-space it is sufficiently familiar with. This is achieved by continuously monitoring discrepancies between a world model's predictions and observed system behavior during inference. It allows for triggering appropriate measures, such as an emergency stop, once an error threshold is surpassed. This does not require any task-specific knowledge and is thus universally applicable. Simulated experiments on established robot control tasks show the effectiveness of this method, recognizing changes in local robot geometry and global gravitational magnitude. Real-world experiments using an agile quadcopter further demonstrate the benefits of this approach by detecting unexpected forces acting on the vehicle. These results indicate how even in new and adverse conditions, safe and reliable operation of otherwise unpredictable learning-based controllers can be achieved. 

**Abstract (ZH)**: 基于模型的强化学习中先进世界模型的应用：通过持续监控确保部署策略仅在充分熟悉的状态空间区域内运行 

---
# Federated nnU-Net for Privacy-Preserving Medical Image Segmentation 

**Title (ZH)**: 联邦nnU-Netfor隐私保护医疗图像分割 

**Authors**: Grzegorz Skorupko, Fotios Avgoustidis, Carlos Martín-Isla, Lidia Garrucho, Dimitri A. Kessler, Esmeralda Ruiz Pujadas, Oliver Díaz, Maciej Bobowicz, Katarzyna Gwoździewicz, Xavier Bargalló, Paulius Jaruševičius, Kaisar Kushibar, Karim Lekadir  

**Link**: [PDF](https://arxiv.org/pdf/2503.02549)  

**Abstract**: The nnU-Net framework has played a crucial role in medical image segmentation and has become the gold standard in multitudes of applications targeting different diseases, organs, and modalities. However, so far it has been used primarily in a centralized approach where the data collected from hospitals are stored in one center and used to train the nnU-Net. This centralized approach has various limitations, such as leakage of sensitive patient information and violation of patient privacy. Federated learning is one of the approaches to train a segmentation model in a decentralized manner that helps preserve patient privacy. In this paper, we propose FednnU-Net, a federated learning extension of nnU-Net. We introduce two novel federated learning methods to the nnU-Net framework - Federated Fingerprint Extraction (FFE) and Asymmetric Federated Averaging (AsymFedAvg) - and experimentally show their consistent performance for breast, cardiac and fetal segmentation using 6 datasets representing samples from 18 institutions. Additionally, to further promote research and deployment of decentralized training in privacy constrained institutions, we make our plug-n-play framework public. The source-code is available at this https URL . 

**Abstract (ZH)**: nnU-Net框架在医学图像分割中发挥了关键作用，并已成为针对不同疾病、器官和模态的众多应用中的黄金标准。然而，迄今为止，它主要在集中式方法中使用，其中医院收集的数据存储在一个中心，并用于训练nnU-Net。集中式方法存在各种限制，如敏感患者信息泄露和患者隐私侵犯。联邦学习是一种在分布式方式下训练分割模型的方法，有助于保护患者隐私。本文提出FednnU-Net，这是nnU-Net的联邦学习扩展。我们向nnU-Net框架引入了两种新的联邦学习方法——联邦指纹提取（FFE）和非对称联邦平均（AsymFedAvg），并通过6个数据集（代表来自18个机构的样本）实验证明了它们在乳腺、心脏和胎儿分割任务中的一致性能。此外，为了进一步促进在限制隐私的研究和部署去中心化训练，我们公开了我们的即插即用框架。源代码可从以下链接获取。 

---
# RectifiedHR: Enable Efficient High-Resolution Image Generation via Energy Rectification 

**Title (ZH)**: RectifiedHR: 通过能量校正实现高效高分辨率图像生成 

**Authors**: Zhen Yang, Guibao Shen, Liang Hou, Mushui Liu, Luozhou Wang, Xin Tao, Pengfei Wan, Di Zhang, Ying-Cong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.02537)  

**Abstract**: Diffusion models have achieved remarkable advances in various image generation tasks. However, their performance notably declines when generating images at resolutions higher than those used during the training period. Despite the existence of numerous methods for producing high-resolution images, they either suffer from inefficiency or are hindered by complex operations. In this paper, we propose RectifiedHR, an efficient and straightforward solution for training-free high-resolution image generation. Specifically, we introduce the noise refresh strategy, which theoretically only requires a few lines of code to unlock the model's high-resolution generation ability and improve efficiency. Additionally, we first observe the phenomenon of energy decay that may cause image blurriness during the high-resolution image generation process. To address this issue, we propose an Energy Rectification strategy, where modifying the hyperparameters of the classifier-free guidance effectively improves the generation performance. Our method is entirely training-free and boasts a simple implementation logic. Through extensive comparisons with numerous baseline methods, our RectifiedHR demonstrates superior effectiveness and efficiency. 

**Abstract (ZH)**: 基于噪声刷新和能量校正的训练免费高分辨率图像生成方法 

---
# LTL Verification of Memoryful Neural Agents 

**Title (ZH)**: 内存型神经代理的LTL验证 

**Authors**: Mehran Hosseini, Alessio Lomuscio, Nicola Paoletti  

**Link**: [PDF](https://arxiv.org/pdf/2503.02512)  

**Abstract**: We present a framework for verifying Memoryful Neural Multi-Agent Systems (MN-MAS) against full Linear Temporal Logic (LTL) specifications. In MN-MAS, agents interact with a non-deterministic, partially observable environment. Examples of MN-MAS include multi-agent systems based on feed-forward and recurrent neural networks or state-space models. Different from previous approaches, we support the verification of both bounded and unbounded LTL specifications. We leverage well-established bounded model checking techniques, including lasso search and invariant synthesis, to reduce the verification problem to that of constraint solving. To solve these constraints, we develop efficient methods based on bound propagation, mixed-integer linear programming, and adaptive splitting. We evaluate the effectiveness of our algorithms in single and multi-agent environments from the Gymnasium and PettingZoo libraries, verifying unbounded specifications for the first time and improving the verification time for bounded specifications by an order of magnitude compared to the SoA. 

**Abstract (ZH)**: 我们提出了一种框架，用于验证含有内存的神经多智能体系统（MN-MAS） against 全局线性时序逻辑（LTL）规范。我们支持有界和无界LTL规范的验证。我们利用成熟的有界模型检查技术，包括lasso搜索和不变式的合成，将验证问题转化为约束求解问题。为了解这些约束，我们基于边界传播、混合整数线性规划和自适应分裂开发了高效的方法。我们在来自Gymnasium和PettingZoo库的单智能体和多智能体环境中评估了算法的有效性，首次验证了无界规范，并将有界规范的验证时间提高了数量级，超过当前最佳方法（SoA）。 

---
# Union of Experts: Adapting Hierarchical Routing to Equivalently Decomposed Transformer 

**Title (ZH)**: 专家联盟：将分层路由适应等效分解的变压器模型 

**Authors**: Yujiao Yang, Jing Lian, Linhui Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.02495)  

**Abstract**: Mixture-of-Experts (MoE) enhances model performance while maintaining computational efficiency, making it well-suited for large-scale applications. However, expert in exist MoE paradigm works as an individual, thereby lacking high-quality expert interactions. Moreover, they have not been effectively extended to attention block, which constrains further efficiency improvements. To tackle these issues, we propose Union-of-Experts (UoE), which decomposes transformer into an equitant group of experts, and then implement dynamic routing on input data and experts. Our approach advances MoE design with three key innovations: (1) We conducted equitant expert decomposition on both MLP blocks and attention blocks based on matrix partition in tensor parallelism. (2) We developed two routing paradigms: patch wise data selection and expert selection, to apply routing across different levels. (3) We design the architecture of UoE model, including Selective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We develop parallel implementation of UoE's routing and computation operation, and optimize efficiency based on the hardware processing analysis. The experiments demonstrate that the model employed with UoE surpass Full Attention, state-of-art MoEs and efficient transformers in several tasks across image and natural language domains. The source codes are available at this https URL. 

**Abstract (ZH)**: 专家集合（UoE）增强了模型性能的同时保持了计算效率，使其适合大规模应用。然而，现有专家集合（MoE）范式中的专家独立工作，缺乏高质量的专家交互。此外，它们未有效扩展到注意块中，限制了进一步的效率提升。为了应对这些问题，我们提出了专家集合（UoE），将Transformer分解为等效的专家组，并在输入数据和专家之间实施动态路由。我们的方法通过三个关键创新促进了MoE设计：（1）基于张量并行中的矩阵分割，在MLP块和注意块上进行了等效专家分解。（2）开发了两种路由范式：基于块的数据选择和专家选择，以在不同级别应用路由。（3）设计了UoE模型的架构，包括选择性多头注意（SMHA）和专家集合MLP（UoME）。（4）开发了UoE路由和计算操作的并行实现，并基于硬件处理分析进行了效率优化。实验结果表明，使用UoE的模型在图像和自然语言处理任务中优于全注意、最先进的MoE模型和高效Transformer模型。源代码可在以下网址获取。 

---
# ERetinex: Event Camera Meets Retinex Theory for Low-Light Image Enhancement 

**Title (ZH)**: ERetinex：事件相机与Retinex理论在低光照图像增强中的结合 

**Authors**: Xuejian Guo, Zhiqiang Tian, Yuehang Wang, Siqi Li, Yu Jiang, Shaoyi Du, Yue Gao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02484)  

**Abstract**: Low-light image enhancement aims to restore the under-exposure image captured in dark scenarios. Under such scenarios, traditional frame-based cameras may fail to capture the structure and color information due to the exposure time limitation. Event cameras are bio-inspired vision sensors that respond to pixel-wise brightness changes asynchronously. Event cameras' high dynamic range is pivotal for visual perception in extreme low-light scenarios, surpassing traditional cameras and enabling applications in challenging dark environments. In this paper, inspired by the success of the retinex theory for traditional frame-based low-light image restoration, we introduce the first methods that combine the retinex theory with event cameras and propose a novel retinex-based low-light image restoration framework named ERetinex. Among our contributions, the first is developing a new approach that leverages the high temporal resolution data from event cameras with traditional image information to estimate scene illumination accurately. This method outperforms traditional image-only techniques, especially in low-light environments, by providing more precise lighting information. Additionally, we propose an effective fusion strategy that combines the high dynamic range data from event cameras with the color information of traditional images to enhance image quality. Through this fusion, we can generate clearer and more detail-rich images, maintaining the integrity of visual information even under extreme lighting conditions. The experimental results indicate that our proposed method outperforms state-of-the-art (SOTA) methods, achieving a gain of 1.0613 dB in PSNR while reducing FLOPS by \textbf{84.28}\%. 

**Abstract (ZH)**: 低光图像增强旨在恢复在黑暗场景中拍摄的欠曝光图像。在这种场景下，传统的帧基相机可能会由于曝光时间限制而无法捕捉到结构和颜色信息。事件摄像头是受生物启发的视觉传感器，能够异步响应像素级别的亮度变化。事件摄像头的高动态范围在极端低光场景中的视觉感知中至关重要，超过了传统相机，并在具有挑战性的黑暗环境中实现了应用。在本文中，受传统帧基低光图像恢复中Retinex理论成功的启发，我们首次引入了将Retinex理论与事件摄像头相结合的方法，并提出了一种新的基于Retinex的低光图像增强框架，命名为ERetinex。在我们的贡献中，首先开发了一种新的方法，该方法利用事件摄像头的高时间分辨率数据与传统图像信息相结合，以精确估计场景光照。该方法在低光环境下优于仅使用图像的技术，通过提供更精确的照明信息。此外，我们提出了一种有效的融合策略，将事件摄像头的高动态范围数据与传统图像的颜色信息相结合，以增强图像质量。通过这种融合，可以生成更清晰且细节更丰富的图像，即使在极端光照条件下也能保持视觉信息的完整性。实验结果表明，我们提出的方法优于当前最先进的方法，在PSNR上提高了1.0613 dB，同时FLOPS减少了84.28%。 

---
# BioD2C: A Dual-level Semantic Consistency Constraint Framework for Biomedical VQA 

**Title (ZH)**: BioD2C：一种生物医学VQA的双层语义一致性约束框架 

**Authors**: Zhengyang Ji, Shang Gao, Li Liu, Yifan Jia, Yutao Yue  

**Link**: [PDF](https://arxiv.org/pdf/2503.02476)  

**Abstract**: Biomedical visual question answering (VQA) has been widely studied and has demonstrated significant application value and potential in fields such as assistive medical diagnosis. Despite their success, current biomedical VQA models perform multimodal information interaction only at the model level within large language models (LLMs), leading to suboptimal multimodal semantic alignment when dealing with complex tasks. To address this issue, we propose BioD2C: a novel Dual-level Semantic Consistency Constraint Framework for Biomedical VQA, which achieves dual-level semantic interaction alignment at both the model and feature levels, enabling the model to adaptively learn visual features based on the question. Specifically, we firstly integrate textual features into visual features via an image-text fusion mechanism as feature-level semantic interaction, obtaining visual features conditioned on the given text; and then introduce a text-queue-based cross-modal soft semantic loss function to further align the image semantics with the question semantics. Specifically, in this work, we establish a new dataset, BioVGQ, to address inherent biases in prior datasets by filtering manually-altered images and aligning question-answer pairs with multimodal context, and train our model on this dataset. Extensive experimental results demonstrate that BioD2C achieves state-of-the-art (SOTA) performance across multiple downstream datasets, showcasing its robustness, generalizability, and potential to advance biomedical VQA research. 

**Abstract (ZH)**: 医学生物视觉问答（VQA）已经在辅助医疗诊断等领域展示了显著的应用价值和潜力，并广泛研究。尽管取得了成功，当前的医学生物VQA模型仅在大规模语言模型（LLMs）的模型层面进行多模态信息交互，导致在处理复杂任务时的多模态语义对齐不足。为了解决这一问题，我们提出了BioD2C：一种新型的双层语义一致性约束框架，该框架在模型和特征层面实现了双层语义交互对齐，使模型能够根据问题自适应地学习视觉特征。具体而言，我们首先通过图文融合机制将文本特征整合到视觉特征中，实现特征层面的语义交互，获得基于给定文本的视觉特征；然后引入基于文本队列的跨模态软语义损失函数，进一步将图像语义与问题语义对齐。在本文中，我们建立了新的数据集BioVGQ，通过筛选手动修改的图像并使问题-答案对与多模态上下文对齐，解决了先前数据集中的固有偏差，并在该数据集上训练我们的模型。广泛的实验结果表明，BioD2C 在多个下游数据集中取得了最先进的（SOTA）性能，展示了其稳健性、通用性和推动医学生物VQA研究的潜力。 

---
# Sparse Meets Dense: Unified Generative Recommendations with Cascaded Sparse-Dense Representations 

**Title (ZH)**: 稀疏遇密集：级联稀疏-密集表示的一体化生成推荐 

**Authors**: Yuhao Yang, Zhi Ji, Zhaopeng Li, Yi Li, Zhonglin Mo, Yue Ding, Kai Chen, Zijian Zhang, Jie Li, Shuanglong Li, Lin Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02453)  

**Abstract**: Generative models have recently gained attention in recommendation systems by directly predicting item identifiers from user interaction sequences. However, existing methods suffer from significant information loss due to the separation of stages such as quantization and sequence modeling, hindering their ability to achieve the modeling precision and accuracy of sequential dense retrieval techniques. Integrating generative and dense retrieval methods remains a critical challenge. To address this, we introduce the Cascaded Organized Bi-Represented generAtive retrieval (COBRA) framework, which innovatively integrates sparse semantic IDs and dense vectors through a cascading process. Our method alternates between generating these representations by first generating sparse IDs, which serve as conditions to aid in the generation of dense vectors. End-to-end training enables dynamic refinement of dense representations, capturing both semantic insights and collaborative signals from user-item interactions. During inference, COBRA employs a coarse-to-fine strategy, starting with sparse ID generation and refining them into dense vectors via the generative model. We further propose BeamFusion, an innovative approach combining beam search with nearest neighbor scores to enhance inference flexibility and recommendation diversity. Extensive experiments on public datasets and offline tests validate our method's robustness. Online A/B tests on a real-world advertising platform with over 200 million daily users demonstrate substantial improvements in key metrics, highlighting COBRA's practical advantages. 

**Abstract (ZH)**: 生成模型Recently在推荐系统中通过直接从用户交互序列预测项目标识符获得了关注。然而，现有方法由于量化和序列建模阶段的分离而导致了显著的信息损失，阻碍了它们实现与序列密集检索技术相当的建模精确度和准确性。将生成方法和密集检索方法的集成仍然是一项关键挑战。为此，我们引入了级联组织双表示生成检索（COBRA）框架，该框架创新地通过级联过程将稀疏语义ID和稠密向量结合起来。我们的方法交替生成这些表示，首先生成稀疏ID，它们作为条件以辅助稠密向量的生成。端到端的训练使稠密表示能够动态优化，捕捉用户项目交互中的语义洞察和协作信号。在推理过程中，COBRA采用粗到细策略，首先生成稀疏ID，再通过生成模型将它们细化成稠密向量。我们进一步提出了BeamFusion，这是一种结合了束搜索和最近邻评分的创新方法，以增强推理灵活性和推荐多样性。广泛的公开数据集实验和离线测试验证了我们方法的鲁棒性。在线A/B测试在具有超过2亿日活跃用户的实际广告平台上也证明了其显著改进，突显了COBRA的实用优势。 

---
# Exploring Model Quantization in GenAI-based Image Inpainting and Detection of Arable Plants 

**Title (ZH)**: 基于GenAI的图像修复与可耕地植物检测中模型量化探索 

**Authors**: Sourav Modak, Ahmet Oğuz Saltık, Anthony Stein  

**Link**: [PDF](https://arxiv.org/pdf/2503.02420)  

**Abstract**: Deep learning-based weed control systems often suffer from limited training data diversity and constrained on-board computation, impacting their real-world performance. To overcome these challenges, we propose a framework that leverages Stable Diffusion-based inpainting to augment training data progressively in 10% increments -- up to an additional 200%, thus enhancing both the volume and diversity of samples. Our approach is evaluated on two state-of-the-art object detection models, YOLO11(l) and RT-DETR(l), using the mAP50 metric to assess detection performance. We explore quantization strategies (FP16 and INT8) for both the generative inpainting and detection models to strike a balance between inference speed and accuracy. Deployment of the downstream models on the Jetson Orin Nano demonstrates the practical viability of our framework in resource-constrained environments, ultimately improving detection accuracy and computational efficiency in intelligent weed management systems. 

**Abstract (ZH)**: 基于深度学习的杂草控制系统常常受到有限的训练数据多样性以及车载计算能力受限的影响，影响其实用性能。为克服这些挑战，我们提出了一种框架，利用Stable Diffusion-based inpainting逐步增加训练数据——每次增加10%，最高可达200%的额外数据，从而增加样本的数量和多样性。我们的方法在YOLO11(l)和RT-DETR(l)两种先进的目标检测模型上进行了评估，使用mAP50指标来评估检测性能。我们探索了生成性 inpainting 模型和检测模型的量化策略（FP16 和 INT8），以在推理速度和准确性之间寻求平衡。在Jetson Orin Nano上的下游模型部署证明了该框架在资源受限环境中的实用可行性，最终提高了智能杂草管理系统中的检测准确性和计算效率。 

---
# VisAgent: Narrative-Preserving Story Visualization Framework 

**Title (ZH)**: VisAgent: 故事叙述保真的叙事可视化框架 

**Authors**: Seungkwon Kim, GyuTae Park, Sangyeon Kim, Seung-Hun Nam  

**Link**: [PDF](https://arxiv.org/pdf/2503.02399)  

**Abstract**: Story visualization is the transformation of narrative elements into image sequences. While existing research has primarily focused on visual contextual coherence, the deeper narrative essence of stories often remains overlooked. This limitation hinders the practical application of these approaches, as generated images frequently fail to capture the intended meaning and nuances of the narrative fully. To address these challenges, we propose VisAgent, a training-free multi-agent framework designed to comprehend and visualize pivotal scenes within a given story. By considering story distillation, semantic consistency, and contextual coherence, VisAgent employs an agentic workflow. In this workflow, multiple specialized agents collaborate to: (i) refine layered prompts based on the narrative structure and (ii) seamlessly integrate \gt{generated} elements, including refined prompts, scene elements, and subject placement, into the final image. The empirically validated effectiveness confirms the framework's suitability for practical story visualization applications. 

**Abstract (ZH)**: 故事可视化是将叙事元素转化为图像序列的过程。尽管现有研究主要集中在视觉上下文连贯性上，但故事深层次的叙事本质往往被忽视。这一局限性阻碍了这些方法的实际应用，因为生成的图像通常无法充分捕捉叙事的意图意义和细微之处。为应对这些挑战，我们提出了一种无需训练的多智能体框架VisAgent，旨在理解并可视化给定故事中的关键场景。VisAgent通过考虑故事提炼、语义一致性及上下文连贯性，采用智能工作流。在此工作流中，多个专业智能体协作：（i）根据叙事结构细化分层提示，以及（ii）无缝集成生成的元素，包括细化提示、场景元素和主体布局，最终整合到图像中。经实验证明的有效性证实了该框架适用于实际故事可视化应用。 

---
# PersonaX: A Recommendation Agent Oriented User Modeling Framework for Long Behavior Sequence 

**Title (ZH)**: PersonaX：面向长期行为序列的用户模型推荐代理框架 

**Authors**: Yunxiao Shi, Wujiang Xu, Zeqi Zhang, Xing Zi, Qiang Wu, Min Xu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02398)  

**Abstract**: Recommendation agents leverage large language models for user modeling LLM UM to construct textual personas guiding alignment with real users. However existing LLM UM methods struggle with long user generated content UGC due to context limitations and performance degradation. To address this sampling strategies prioritize relevance or recency are often applied yet they inevitably neglect the diverse user interests embedded within the discarded behaviors resulting in incomplete modeling and degraded profiling quality. Furthermore relevance based sampling requires real time retrieval forcing the user modeling process to operate online which introduces significant latency overhead. In this paper we propose PersonaX an agent agnostic LLM UM framework that tackles these challenges through sub behavior sequence SBS selection and offline multi persona construction. PersonaX extracts compact SBS segments offline to capture diverse user interests generating fine grained textual personas that are cached for efficient online retrieval. This approach ensures that the user persona used for prompting remains highly relevant to the current context while eliminating the need for online user modeling. For SBS selection we ensure both efficiency length less than five and high representational quality by balancing prototypicality and diversity within the sampled data. Extensive experiments validate the effectiveness and versatility of PersonaX in high quality user profiling. Utilizing only 30 to 50 percent of the behavioral data with a sequence length of 480 integrating PersonaX with AgentCF yields an absolute performance improvement of 3 to 11 percent while integration with Agent4Rec results in a gain of 10 to 50 percent. PersonaX as an agent agnostic framework sets a new benchmark for scalable user modeling paving the way for more accurate and efficient LLM driven recommendation agents. 

**Abstract (ZH)**: 基于大型语言模型的推荐代理构建用户模型：PersonaX框架解决长用户生成内容挑战 

---
# A Binary Classification Social Network Dataset for Graph Machine Learning 

**Title (ZH)**: 二元分类社交网络数据集用于图机器学习 

**Authors**: Adnan Ali, Jinglong Li, Huanhuan Chen, AlMotasem Bellah Al Ajlouni  

**Link**: [PDF](https://arxiv.org/pdf/2503.02397)  

**Abstract**: Social networks have a vast range of applications with graphs. The available benchmark datasets are citation, co-occurrence, e-commerce networks, etc, with classes ranging from 3 to 15. However, there is no benchmark classification social network dataset for graph machine learning. This paper fills the gap and presents the Binary Classification Social Network Dataset (\textit{BiSND}), designed for graph machine learning applications to predict binary classes. We present the BiSND in \textit{tabular and graph} formats to verify its robustness across classical and advanced machine learning. We employ a diverse set of classifiers, including four traditional machine learning algorithms (Decision Trees, K-Nearest Neighbour, Random Forest, XGBoost), one Deep Neural Network (multi-layer perceptrons), one Graph Neural Network (Graph Convolutional Network), and three state-of-the-art Graph Contrastive Learning methods (BGRL, GRACE, DAENS). Our findings reveal that BiSND is suitable for classification tasks, with F1-scores ranging from 67.66 to 70.15, indicating promising avenues for future enhancements. 

**Abstract (ZH)**: 社交网络具有广泛的应用范围，其中涉及图的数据。现有的基准数据集包括引用网络、共现网络、电子商务网络等，其类别从3到15不等。然而，还没有适用于图机器学习的基准分类社交网络数据集。本文填补了这一空白，提出了二分类社交网络数据集（\textit{BiSND}），旨在为图机器学习应用中的二分类预测任务提供支持。我们以表格式和图格式展示了\textit{BiSND}，以验证其在经典和高级机器学习方法中的 robustness。我们使用了多样化的分类器，包括四种传统的机器学习算法（决策树、K-最近邻、随机森林、XGBoost）、一个深度神经网络（多层感知机）、一个图神经网络（图卷积网络）以及三种最新的图对比学习方法（BGRL、GRACE、DAENS）。我们的研究结果表明，\textit{BiSND} 适用于分类任务，F1分数范围从67.66到70.15，这为未来的研究提供了有希望的途径。 

---
# An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning 

**Title (ZH)**: 过程监督奖励模型在数学推理中高效精准的训练数据构建框架 

**Authors**: Wei Sun, Qianlong Du, Fuwei Cui, Jiajun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02382)  

**Abstract**: Enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) is of great scientific and practical significance. Researchers typically employ process-supervised reward models (PRMs) to guide the reasoning process, effectively improving the models' reasoning abilities. However, existing methods for constructing process supervision training data, such as manual annotation and per-step Monte Carlo estimation, are often costly or suffer from poor quality. To address these challenges, this paper introduces a framework called EpicPRM, which annotates each intermediate reasoning step based on its quantified contribution and uses an adaptive binary search algorithm to enhance both annotation precision and efficiency. Using this approach, we efficiently construct a high-quality process supervision training dataset named Epic50k, consisting of 50k annotated intermediate steps. Compared to other publicly available datasets, the PRM trained on Epic50k demonstrates significantly superior performance. Getting Epic50k at this https URL. 

**Abstract (ZH)**: 增强大型语言模型的数学推理能力具有重要的科学和实践意义。研究人员通常通过过程监督奖励模型（PRM）来引导推理过程，有效提高模型的推理能力。然而，现有的过程监督训练数据构建方法，如手动标注和每步蒙特卡洛估计，往往成本高昂或质量较差。为应对这些挑战，本文提出了一种名为EpicPRM的框架，该框架根据每个中间推理步骤的量化贡献进行标注，并使用自适应二分搜索算法提高标注的准确性和效率。通过这种方法，我们高效地构建了一个高质量的过程监督训练数据集Epic50k，包含50k个标注的中间步骤。与现有的其他公开数据集相比，基于Epic50k训练的PRM表现出显著的优越性能。获取Epic50k请访问此链接。 

---
# JPDS-NN: Reinforcement Learning-Based Dynamic Task Allocation for Agricultural Vehicle Routing Optimization 

**Title (ZH)**: JPDS-NN：基于强化学习的农业生产车辆动态任务分配与路径优化 

**Authors**: Yixuan Fan, Haotian Xu, Mengqiao Liu, Qing Zhuo, Tao Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02369)  

**Abstract**: The Entrance Dependent Vehicle Routing Problem (EDVRP) is a variant of the Vehicle Routing Problem (VRP) where the scale of cities influences routing outcomes, necessitating consideration of their entrances. This paper addresses EDVRP in agriculture, focusing on multi-parameter vehicle planning for irregularly shaped fields. To address the limitations of traditional methods, such as heuristic approaches, which often overlook field geometry and entrance constraints, we propose a Joint Probability Distribution Sampling Neural Network (JPDS-NN) to effectively solve the EDVRP. The network uses an encoder-decoder architecture with graph transformers and attention mechanisms to model routing as a Markov Decision Process, and is trained via reinforcement learning for efficient and rapid end-to-end planning. Experimental results indicate that JPDS-NN reduces travel distances by 48.4-65.4%, lowers fuel consumption by 14.0-17.6%, and computes two orders of magnitude faster than baseline methods, while demonstrating 15-25% superior performance in dynamic arrangement scenarios. Ablation studies validate the necessity of cross-attention and pre-training. The framework enables scalable, intelligent routing for large-scale farming under dynamic constraints. 

**Abstract (ZH)**: 基于入口依赖的车辆路由问题（EDVRP）在农业中的多参数车辆规划：一种联合概率分布采样神经网络（JPDS-NN）方法 

---
# Iterative Value Function Optimization for Guided Decoding 

**Title (ZH)**: 迭代价值函数优化引导解码 

**Authors**: Zhenhua Liu, Lijun Li, Ruizhe Chen, Yuxian Jiang, Tong Zhu, Wenliang Chen, Jing Shao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02368)  

**Abstract**: While Reinforcement Learning from Human Feedback (RLHF) has become the predominant method for controlling language model outputs, it suffers from high computational costs and training instability. Guided decoding, especially value-guided methods, offers a cost-effective alternative by controlling outputs without re-training models. However, the accuracy of the value function is crucial for value-guided decoding, as inaccuracies can lead to suboptimal decision-making and degraded performance. Existing methods struggle with accurately estimating the optimal value function, leading to less effective control. We propose Iterative Value Function Optimization, a novel framework that addresses these limitations through two key components: Monte Carlo Value Estimation, which reduces estimation variance by exploring diverse trajectories, and Iterative On-Policy Optimization, which progressively improves value estimation through collecting trajectories from value-guided policies. Extensive experiments on text summarization, multi-turn dialogue, and instruction following demonstrate the effectiveness of value-guided decoding approaches in aligning language models. These approaches not only achieve alignment but also significantly reduce computational costs by leveraging principled value function optimization for efficient and effective control. 

**Abstract (ZH)**: 基于人类反馈的强化学习（RLHF）已成为控制语言模型输出的主要方法，但面临高计算成本和训练不稳定的问题。引导解码，尤其是值导向方法，通过不重新训练模型来控制输出，提供了一种成本效益高的替代方案。然而，值函数的准确性对于值导向解码至关重要，不准确的值函数会导致次优决策和性能下降。现有方法难以准确估计最优值函数，导致控制效果不佳。我们提出了一种名为迭代值函数优化的新型框架，通过两个关键组件解决这些限制：蒙特卡洛值估计，通过探索多样化的轨迹来减少估计方差；以及迭代在线策略优化，通过收集值导向策略的轨迹逐步改进值估计。在文本摘要、多轮对话和指令跟随等任务上的广泛实验表明，值导向解码方法在使语言模型对齐方面效果显著。这些方法不仅实现了对齐，还通过利用有效的值函数优化原则显著降低了计算成本。 

---
# BdSLW401: Transformer-Based Word-Level Bangla Sign Language Recognition Using Relative Quantization Encoding (RQE) 

**Title (ZH)**: BdSLW401：基于相对量化编码（RQE）的变压器驱动的孟加拉手语单词级识别 

**Authors**: Husne Ara Rubaiyeat, Njayou Youssouf, Md Kamrul Hasan, Hasan Mahmud  

**Link**: [PDF](https://arxiv.org/pdf/2503.02360)  

**Abstract**: Sign language recognition (SLR) for low-resource languages like Bangla suffers from signer variability, viewpoint variations, and limited annotated datasets. In this paper, we present BdSLW401, a large-scale, multi-view, word-level Bangla Sign Language (BdSL) dataset with 401 signs and 102,176 video samples from 18 signers in front and lateral views. To improve transformer-based SLR, we introduce Relative Quantization Encoding (RQE), a structured embedding approach anchoring landmarks to physiological reference points and quantize motion trajectories. RQE improves attention allocation by decreasing spatial variability, resulting in 44.3% WER reduction in WLASL100, 21.0% in SignBD-200, and significant gains in BdSLW60 and SignBD-90. However, fixed quantization becomes insufficient on large-scale datasets (e.g., WLASL2000), indicating the need for adaptive encoding strategies. Further, RQE-SF, an extended variant that stabilizes shoulder landmarks, achieves improvements in pose consistency at the cost of small trade-offs in lateral view recognition. The attention graphs prove that RQE improves model interpretability by focusing on the major articulatory features (fingers, wrists) and the more distinctive frames instead of global pose changes. Introducing BdSLW401 and demonstrating the effectiveness of RQE-enhanced structured embeddings, this work advances transformer-based SLR for low-resource languages and sets a benchmark for future research in this area. 

**Abstract (ZH)**: 低资源语言孟加拉手语识别中相对量化编码的大规模多视角单词级孟加拉手语数据集(BdSLW401)及其应用 

---
# Are Large Vision Language Models Good Game Players? 

**Title (ZH)**: 大型视觉语言模型是好的游戏选手吗？ 

**Authors**: Xinyu Wang, Bohan Zhuang, Qi Wu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02358)  

**Abstract**: Large Vision Language Models (LVLMs) have demonstrated remarkable abilities in understanding and reasoning about both visual and textual information. However, existing evaluation methods for LVLMs, primarily based on benchmarks like Visual Question Answering and image captioning, often fail to capture the full scope of LVLMs' capabilities. These benchmarks are limited by issues such as inadequate assessment of detailed visual perception, data contamination, and a lack of focus on multi-turn reasoning. To address these challenges, we propose \method{}, a game-based evaluation framework designed to provide a comprehensive assessment of LVLMs' cognitive and reasoning skills in structured environments. \method{} uses a set of games to evaluate LVLMs on four core tasks: Perceiving, Question Answering, Rule Following, and End-to-End Playing, with each target task designed to assess specific abilities, including visual perception, reasoning, decision-making, etc. Based on this framework, we conduct extensive experiments that explore the limitations of current LVLMs, such as handling long structured outputs and perceiving detailed and dense elements. Code and data are publicly available at this https URL. 

**Abstract (ZH)**: 大型视觉语言模型（LVLMs）在理解和推理视觉及文本信息方面展现了出色的 ability。然而，现有 LVLMs 的评价方法主要依托视觉问答和图像字幕等基准测试，往往无法全面捕捉 LVLMs 的能力。这些基准测试受限于详细视觉感知评估不足、数据污染以及多轮推理关注不充分等问题。为应对这些挑战，我们提出 \method{}，一种基于游戏的设计评价框架，旨在为 LVLMs 在结构化环境中的认知和推理能力提供全面评估。\method{} 使用一系列游戏来评估 LVLMs 在四个核心任务上的表现：感知、问答、规则遵循和端到端游戏，每个目标任务都旨在评估特定的能力，包括视觉感知、推理、决策等。基于此框架，我们进行了广泛的实验，探讨当前 LVLMs 的局限性，如处理长结构化输出和感知详细密集元素等问题。相关代码和数据可以在该 URL 公开访问：[这个 https URL]。 

---
# CoServe: Efficient Collaboration-of-Experts (CoE) Model Inference with Limited Memory 

**Title (ZH)**: CoServe: 有限内存下高效的专家协作（CoE）模型推理 

**Authors**: Jiashun Suo, Xiaojian Liao, Limin Xiao, Li Ruan, Jinquan Wang, Xiao Su, Zhisheng Huo  

**Link**: [PDF](https://arxiv.org/pdf/2503.02354)  

**Abstract**: Large language models like GPT-4 are resource-intensive, but recent advancements suggest that smaller, specialized experts can outperform the monolithic models on specific tasks. The Collaboration-of-Experts (CoE) approach integrates multiple expert models, improving the accuracy of generated results and offering great potential for precision-critical applications, such as automatic circuit board quality inspection. However, deploying CoE serving systems presents challenges to memory capacity due to the large number of experts required, which can lead to significant performance overhead from frequent expert switching across different memory and storage tiers.
We propose CoServe, an efficient CoE model serving system on heterogeneous CPU and GPU with limited memory. CoServe reduces unnecessary expert switching by leveraging expert dependency, a key property of CoE inference. CoServe introduces a dependency-aware request scheduler and dependency-aware expert management for efficient inference. It also introduces an offline profiler to automatically find optimal resource allocation on various processors and devices. In real-world intelligent manufacturing workloads, CoServe achieves 4.5$\times$ to 12$\times$ higher throughput compared to state-of-the-art systems. 

**Abstract (ZH)**: 一种基于异构CPU和GPU的高效CoE模型服务系统：CoServe 

---
# MindSimulator: Exploring Brain Concept Localization via Synthetic FMRI 

**Title (ZH)**: MindSimulator: 探索脑概念定位的合成功能性磁共振成像方法 

**Authors**: Guangyin Bao, Qi Zhang, Zixuan Gong, Zhuojia Wu, Duoqian Miao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02351)  

**Abstract**: Concept-selective regions within the human cerebral cortex exhibit significant activation in response to specific visual stimuli associated with particular concepts. Precisely localizing these regions stands as a crucial long-term goal in neuroscience to grasp essential brain functions and mechanisms. Conventional experiment-driven approaches hinge on manually constructed visual stimulus collections and corresponding brain activity recordings, constraining the support and coverage of concept localization. Additionally, these stimuli often consist of concept objects in unnatural contexts and are potentially biased by subjective preferences, thus prompting concerns about the validity and generalizability of the identified regions. To address these limitations, we propose a data-driven exploration approach. By synthesizing extensive brain activity recordings, we statistically localize various concept-selective regions. Our proposed MindSimulator leverages advanced generative technologies to learn the probability distribution of brain activity conditioned on concept-oriented visual stimuli. This enables the creation of simulated brain recordings that reflect real neural response patterns. Using the synthetic recordings, we successfully localize several well-studied concept-selective regions and validate them against empirical findings, achieving promising prediction accuracy. The feasibility opens avenues for exploring novel concept-selective regions and provides prior hypotheses for future neuroscience research. 

**Abstract (ZH)**: 人类大脑皮层中的概念选择性区域对特定概念相关的视觉刺激表现出显著激活响应。精确定位这些区域是神经科学中长期的关键目标，以理解基本的脑功能和机制。传统的实验驱动方法依赖于手动构建的视觉刺激集合及其相应的脑活动记录，这限制了概念定位的支持和覆盖范围。此外，这些刺激通常包含在不自然情境下的概念对象，并可能受主观偏好的影响，从而引发了关于所识别区域的有效性和普适性的担忧。为了解决这些限制，我们提出了一个数据驱动的探索方法。通过合成大量脑活动记录，我们统计性地定位了各种概念选择性区域。我们提出的MindSimulator利用先进的生成技术学习概念导向的视觉刺激条件下的脑活动概率分布，从而创建反映真实神经反应模式的模拟脑记录。利用合成记录，我们成功定位了多个已研究的概念选择性区域，并通过与实证发现进行验证，实现了有前景的预测准确性。该可行性为探索新的概念选择性区域并为未来的神经科学研究提供先验假设提供了途径。 

---
# CQ CNN: A Hybrid Classical Quantum Convolutional Neural Network for Alzheimer's Disease Detection Using Diffusion Generated and U Net Segmented 3D MRI 

**Title (ZH)**: CQ CNN：一种用于阿尔茨海默病检测的混合经典量子卷积神经网络，基于扩散生成和U-net分割的3D MRI 

**Authors**: Mominul Islam, Mohammad Junayed Hasan, M.R.C. Mahdy  

**Link**: [PDF](https://arxiv.org/pdf/2503.02345)  

**Abstract**: The detection of Alzheimer disease (AD) from clinical MRI data is an active area of research in medical imaging. Recent advances in quantum computing, particularly the integration of parameterized quantum circuits (PQCs) with classical machine learning architectures, offer new opportunities to develop models that may outperform traditional methods. However, quantum machine learning (QML) remains in its early stages and requires further experimental analysis to better understand its behavior and limitations. In this paper, we propose an end to end hybrid classical quantum convolutional neural network (CQ CNN) for AD detection using clinically formatted 3D MRI data. Our approach involves developing a framework to make 3D MRI data usable for machine learning, designing and training a brain tissue segmentation model (Skull Net), and training a diffusion model to generate synthetic images for the minority class. Our converged models exhibit potential quantum advantages, achieving higher accuracy in fewer epochs than classical models. The proposed beta8 3 qubit model achieves an accuracy of 97.50%, surpassing state of the art (SOTA) models while requiring significantly fewer computational resources. In particular, the architecture employs only 13K parameters (0.48 MB), reducing the parameter count by more than 99.99% compared to current SOTA models. Furthermore, the diffusion-generated data used to train our quantum models, in conjunction with real samples, preserve clinical structural standards, representing a notable first in the field of QML. We conclude that CQCNN architecture like models, with further improvements in gradient optimization techniques, could become a viable option and even a potential alternative to classical models for AD detection, especially in data limited and resource constrained clinical settings. 

**Abstract (ZH)**: 基于临床MRI数据的阿尔茨海默病检测中的端到端混合经典量子卷积神经网络研究 

---
# GRADEO: Towards Human-Like Evaluation for Text-to-Video Generation via Multi-Step Reasoning 

**Title (ZH)**: GRADEO: 向量人类评价的文本到视频生成多步推理方法 

**Authors**: Zhun Mou, Bin Xia, Zhengchao Huang, Wenming Yang, Jiaya Jia  

**Link**: [PDF](https://arxiv.org/pdf/2503.02341)  

**Abstract**: Recent great advances in video generation models have demonstrated their potential to produce high-quality videos, bringing challenges to effective evaluation. Unlike human evaluation, existing automated evaluation metrics lack high-level semantic understanding and reasoning capabilities for video, thus making them infeasible and unexplainable. To fill this gap, we curate GRADEO-Instruct, a multi-dimensional T2V evaluation instruction tuning dataset, including 3.3k videos from over 10 existing video generation models and multi-step reasoning assessments converted by 16k human annotations. We then introduce GRADEO, one of the first specifically designed video evaluation models, which grades AI-generated videos for explainable scores and assessments through multi-step reasoning. Experiments show that our method aligns better with human evaluations than existing methods. Furthermore, our benchmarking reveals that current video generation models struggle to produce content that aligns with human reasoning and complex real-world scenarios. The models, datasets, and codes will be released soon. 

**Abstract (ZH)**: 近期在视频生成模型方面的重大进展展示了其产生高质量视频的潜力，但也带来了有效评估的挑战。现有自动评估指标缺乏对视频的高层语义理解和推理能力，因此使其不可行且难以解释。为了解决这一问题，我们编纂了GRADEO-Instruct多维度T2V评估指令调优数据集，包含来自超过10个现有视频生成模型的3300个视频和由16000个人工注释转换而来的多步推理评估。我们随后引入了GRADEO，这是首个专门设计的视频评估模型之一，能够通过多步推理为可解释的评分和评估打分AI生成的视频。实验结果显示，我们的方法比现有方法更符合人类评估。此外，我们的基准测试表明，当前的视频生成模型在产生符合人类推理和复杂现实场景的内容方面存在困难。相关模型、数据集和代码将很快发布。 

---
# BiasICL: In-Context Learning and Demographic Biases of Vision Language Models 

**Title (ZH)**: BiasICL: 在上下文学习与视觉语言模型的群体偏差 

**Authors**: Sonnet Xu, Joseph Janizek, Yixing Jiang, Roxana Daneshjou  

**Link**: [PDF](https://arxiv.org/pdf/2503.02334)  

**Abstract**: Vision language models (VLMs) show promise in medical diagnosis, but their performance across demographic subgroups when using in-context learning (ICL) remains poorly understood. We examine how the demographic composition of demonstration examples affects VLM performance in two medical imaging tasks: skin lesion malignancy prediction and pneumothorax detection from chest radiographs. Our analysis reveals that ICL influences model predictions through multiple mechanisms: (1) ICL allows VLMs to learn subgroup-specific disease base rates from prompts and (2) ICL leads VLMs to make predictions that perform differently across demographic groups, even after controlling for subgroup-specific disease base rates. Our empirical results inform best-practices for prompting current VLMs (specifically examining demographic subgroup performance, and matching base rates of labels to target distribution at a bulk level and within subgroups), while also suggesting next steps for improving our theoretical understanding of these models. 

**Abstract (ZH)**: 视觉语言模型（VLMs）在医学诊断中展现出潜力，但在使用上下文学习（ICL）时，其在不同人口子组中的性能仍然知之甚少。我们探讨了示范示例的人口组成如何影响VLM在两项医学影像任务中的表现：皮肤病变恶性预测和胸部X光片中气胸检测。我们的分析揭示了ICL通过多种机制影响模型预测：（1）ICL使VLM能够从提示中学习子组特定的疾病基率；（2）ICL导致VLM在不同人口组中的预测表现不同，即使在控制了子组特定的疾病基率后也是如此。我们的实证结果为当前VLM的启提示最佳实践提供了指导（特别关注人口子组的表现，并在总体层面和子组内部将标签基率与目标分布相匹配），同时也指出了需要进一步研究以改进我们对这些模型的理论理解的方向。 

---
# Examining the Mental Health Impact of Misinformation on Social Media Using a Hybrid Transformer-Based Approach 

**Title (ZH)**: 使用混合变压器方法探究社交媒体上 misinformation 对心理健康的影响 

**Authors**: Sarvesh Arora, Sarthak Arora, Deepika Kumar, Vallari Agrawal, Vedika Gupta, Dipit Vasdev  

**Link**: [PDF](https://arxiv.org/pdf/2503.02333)  

**Abstract**: Social media has significantly reshaped interpersonal communication, fostering connectivity while also enabling the proliferation of misinformation. The unchecked spread of false narratives has profound effects on mental health, contributing to increased stress, anxiety, and misinformation-driven paranoia. This study presents a hybrid transformer-based approach using a RoBERTa-LSTM classifier to detect misinformation, assess its impact on mental health, and classify disorders linked to misinformation exposure. The proposed models demonstrate accuracy rates of 98.4, 87.8, and 77.3 in detecting misinformation, mental health implications, and disorder classification, respectively. Furthermore, Pearson's Chi-Squared Test for Independence (p-value = 0.003871) validates the direct correlation between misinformation and deteriorating mental well-being. This study underscores the urgent need for better misinformation management strategies to mitigate its psychological repercussions. Future research could explore broader datasets incorporating linguistic, demographic, and cultural variables to deepen the understanding of misinformation-induced mental health distress. 

**Abstract (ZH)**: 社交媒体显著重塑了人际沟通，促进了连接性的同时也使得虚假信息的传播无约束。未经约束的虚假叙事蔓延对心理健康产生了深远影响，增加了压力、焦虑和由虚假信息驱动的猜疑。本研究提出了一种基于混合变换器的 approaching，使用 RoBERTa-LSTM 分类器来检测虚假信息、评估其对心理健康的影响以及分类与虚假信息暴露相关的障碍。所提出的模型在检测虚假信息、心理健康影响和障碍分类方面的准确率分别为 98.4%、87.8% 和 77.3%。此外，皮尔森独立性卡方检验（p值 = 0.003871）证实了虚假信息与心理健康恶化之间的直接关联。本研究强调了迫切需要更好的虚假信息管理策略以减轻其心理影响。未来的研究可以探索包含语言学、人口统计和文化变量的更广泛的数据库，以深化对虚假信息引发的心理健康困扰的理解。 

---
# PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models 

**Title (ZH)**: PromptCoT: 合成奥林匹克级别问题以供大型语言模型进行数学推理 

**Authors**: Xueliang Zhao, Wei Wu, Jian Guan, Lingpeng Kong  

**Link**: [PDF](https://arxiv.org/pdf/2503.02324)  

**Abstract**: The ability of large language models to solve complex mathematical problems has progressed significantly, particularly for tasks requiring advanced reasoning. However, the scarcity of sufficiently challenging problems, particularly at the Olympiad level, hinders further advancements. In this work, we introduce PromptCoT, a novel approach for automatically generating high-quality Olympiad-level math problems. The proposed method synthesizes complex problems based on mathematical concepts and the rationale behind problem construction, emulating the thought processes of experienced problem designers. We provide a theoretical analysis demonstrating that an optimal rationale should maximize both the likelihood of rationale generation given the associated concepts and the likelihood of problem generation conditioned on both the rationale and the concepts. Our method is evaluated on standard benchmarks including GSM8K, MATH-500, and AIME2024, where it consistently outperforms existing problem generation methods. Furthermore, we demonstrate that PromptCoT exhibits superior data scalability, consistently maintaining high performance as the dataset size increases, outperforming the baselines. The implementation is available at this https URL. 

**Abstract (ZH)**: 大型语言模型解决复杂数学问题的能力显著进步，尤其是在需要高级推理的任务方面。然而，足够有挑战性的问题，特别是在奥林匹克级别上的问题的缺乏阻碍了进一步的进步。本文介绍了PromptCoT，一种生成高质量奥林匹克级别数学问题的新方法。所提出的方法基于数学概念和问题构建的原理，模拟了有经验的问题设计师的思维过程。我们提供了理论分析，证明最优原理应该最大化给定相关概念的原理生成的可能性以及同时基于原理和概念的问题生成的可能性。该方法在包括GSM8K、MATH-500和AIME2024的标准基准上进行了评估，一致优于现有的问题生成方法。此外，我们证明了PromptCoT在数据规模增加时表现出更好的数据扩展性，始终维持高性能，并优于基线方法。代码可通过以下链接获取。 

---
# Audio-Reasoner: Improving Reasoning Capability in Large Audio Language Models 

**Title (ZH)**: Audio-Reasoner: 提高大规模音频语言模型的推理能力 

**Authors**: Zhifei Xie, Mingbao Lin, Zihang Liu, Pengcheng Wu, Shuicheng Yan, Chunyan Miao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02318)  

**Abstract**: Recent advancements in multimodal reasoning have largely overlooked the audio modality. We introduce Audio-Reasoner, a large-scale audio language model for deep reasoning in audio tasks. We meticulously curated a large-scale and diverse multi-task audio dataset with simple annotations. Then, we leverage closed-source models to conduct secondary labeling, QA generation, along with structured COT process. These datasets together form a high-quality reasoning dataset with 1.2 million reasoning-rich samples, which we name CoTA. Following inference scaling principles, we train Audio-Reasoner on CoTA, enabling it to achieve great logical capabilities in audio reasoning. Experiments show state-of-the-art performance across key benchmarks, including MMAU-mini (+25.42%), AIR-Bench chat/foundation(+14.57%/+10.13%), and MELD (+8.01%). Our findings stress the core of structured CoT training in advancing audio reasoning. 

**Abstract (ZH)**: 近期多模态推理的进展大多忽视了音频模态。我们引入了Audio-Reasoner，这是一个大规模的音频语言模型，用于深入的音频任务推理。我们精心策划了一个大规模且多任务的音频数据集，并附有简洁的标注。然后，我们利用封闭源模型进行二次标注、问题-答案生成以及结构化的批判性思维过程。这些数据集共同形成了一个高质量的推理数据集，包含120万富有推理性的样本，我们将其命名为CoTA。遵循推理缩放原则，我们在CoTA上训练了Audio-Reasoner，使其具备出色的音频推理逻辑能力。实验结果显示，Audio-Reasoner在关键基准测试中表现优异，包括MMAU-mini (+25.42%)、AIR-Bench chat/foundation (+14.57%/+10.13%)和MELD (+8.01%)。我们的研究强调了结构化CoT训练在推动音频推理方面的重要性。 

---
# Target Return Optimizer for Multi-Game Decision Transformer 

**Title (ZH)**: 多游戏决策变换器的目标回报优化器 

**Authors**: Kensuke Tatematsu, Akifumi Wachi  

**Link**: [PDF](https://arxiv.org/pdf/2503.02311)  

**Abstract**: Achieving autonomous agents with robust generalization capabilities across diverse games and tasks remains one of the ultimate goals in AI research. Recent advancements in transformer-based offline reinforcement learning, exemplified by the MultiGame Decision Transformer [Lee et al., 2022], have shown remarkable performance across various games or tasks. However, these approaches depend heavily on human expertise, presenting substantial challenges for practical deployment, particularly in scenarios with limited prior game-specific knowledge. In this paper, we propose an algorithm called Multi-Game Target Return Optimizer (MTRO) to autonomously determine game-specific target returns within the Multi-Game Decision Transformer framework using solely offline datasets. MTRO addresses the existing limitations by automating the target return configuration process, leveraging environmental reward information extracted from offline datasets. Notably, MTRO does not require additional training, enabling seamless integration into existing Multi-Game Decision Transformer architectures. Our experimental evaluations on Atari games demonstrate that MTRO enhances the performance of RL policies across a wide array of games, underscoring its potential to advance the field of autonomous agent development. 

**Abstract (ZH)**: 实现跨多种游戏和任务具有稳健泛化能力的自主代理仍是AI研究中的终极目标。Recent advancements in transformer-based offline reinforcement learning, exemplified by the MultiGame Decision Transformer [Lee et al., 2022], have shown remarkable performance across various games or tasks.然而，这些方法高度依赖于人类专业知识，为实际部署带来了重大挑战，尤其是在有限的游戏特定先验知识的情景下。本文提出了一种称为Multi-Game Target Return Optimizer (MTRO)的算法，该算法在Multi-Game Decision Transformer框架中仅使用离线数据集自主确定游戏特定的目标回报。MTRO通过利用从离线数据集中提取的环境奖励信息自动化目标回报配置过程，解决了现有方法的局限性。值得注意的是，MTRO无需额外训练，可以无缝集成到现有的Multi-Game Decision Transformer架构中。我们在 Atari 游戏上的实验评估表明，MTRO 改善了强化学习策略在多种游戏中的性能，突显了其在自主代理开发领域进步的潜力。 

---
# Flexible Prefrontal Control over Hippocampal Episodic Memory for Goal-Directed Generalization 

**Title (ZH)**: 前额叶对目标引导性泛化的 hippocampal 事件记忆的灵活控制 

**Authors**: Yicong Zheng, Nora Wolf, Charan Ranganath, Randall C. O'Reilly, Kevin L. McKee  

**Link**: [PDF](https://arxiv.org/pdf/2503.02303)  

**Abstract**: Many tasks require flexibly modifying perception and behavior based on current goals. Humans can retrieve episodic memories from days to years ago, using them to contextualize and generalize behaviors across novel but structurally related situations. The brain's ability to control episodic memories based on task demands is often attributed to interactions between the prefrontal cortex (PFC) and hippocampus (HPC). We propose a reinforcement learning model that incorporates a PFC-HPC interaction mechanism for goal-directed generalization. In our model, the PFC learns to generate query-key representations to encode and retrieve goal-relevant episodic memories, modulating HPC memories top-down based on current task demands. Moreover, the PFC adapts its encoding and retrieval strategies dynamically when faced with multiple goals presented in a blocked, rather than interleaved, manner. Our results show that: (1) combining working memory with selectively retrieved episodic memory allows transfer of decisions among similar environments or situations, (2) top-down control from PFC over HPC improves learning of arbitrary structural associations between events for generalization to novel environments compared to a bottom-up sensory-driven approach, and (3) the PFC encodes generalizable representations during both encoding and retrieval of goal-relevant memories, whereas the HPC exhibits event-specific representations. Together, these findings highlight the importance of goal-directed prefrontal control over hippocampal episodic memory for decision-making in novel situations and suggest a computational mechanism by which PFC-HPC interactions enable flexible behavior. 

**Abstract (ZH)**: 基于目标控制情景相关性的强化学习模型：前额皮层-海马体交互机制 

---
# Semi-Supervised Audio-Visual Video Action Recognition with Audio Source Localization Guided Mixup 

**Title (ZH)**: 基于音频源定位引导Mixup的半监督音频-视觉视频动作识别 

**Authors**: Seokun Kang, Taehwan Kim  

**Link**: [PDF](https://arxiv.org/pdf/2503.02284)  

**Abstract**: Video action recognition is a challenging but important task for understanding and discovering what the video does. However, acquiring annotations for a video is costly, and semi-supervised learning (SSL) has been studied to improve performance even with a small number of labeled data in the task. Prior studies for semi-supervised video action recognition have mostly focused on using single modality - visuals - but the video is multi-modal, so utilizing both visuals and audio would be desirable and improve performance further, which has not been explored well. Therefore, we propose audio-visual SSL for video action recognition, which uses both visual and audio together, even with quite a few labeled data, which is challenging. In addition, to maximize the information of audio and video, we propose a novel audio source localization-guided mixup method that considers inter-modal relations between video and audio modalities. In experiments on UCF-51, Kinetics-400, and VGGSound datasets, our model shows the superior performance of the proposed semi-supervised audio-visual action recognition framework and audio source localization-guided mixup. 

**Abstract (ZH)**: 基于音频-视觉半监督学习的视频动作识别 

---
# Experience Replay with Random Reshuffling 

**Title (ZH)**: 随机重排的经验重演 

**Authors**: Yasuhiro Fujita  

**Link**: [PDF](https://arxiv.org/pdf/2503.02269)  

**Abstract**: Experience replay is a key component in reinforcement learning for stabilizing learning and improving sample efficiency. Its typical implementation samples transitions with replacement from a replay buffer. In contrast, in supervised learning with a fixed dataset, it is a common practice to shuffle the dataset every epoch and consume data sequentially, which is called random reshuffling (RR). RR enjoys theoretically better convergence properties and has been shown to outperform with-replacement sampling empirically. To leverage the benefits of RR in reinforcement learning, we propose sampling methods that extend RR to experience replay, both in uniform and prioritized settings. We evaluate our sampling methods on Atari benchmarks, demonstrating their effectiveness in deep reinforcement learning. 

**Abstract (ZH)**: 经验回放是强化学习中稳定学习和提高样本效率的关键组件。其典型的实现方式是从回放缓冲区中带替换地采样过渡。相比之下，在监督学习中，每轮使用固定的数据集时，常见的做法是每轮重新洗牌数据集并顺序消费数据，这种方法称为随机重新洗牌（RR）。理论上，RR 具有更好的收敛性质，并且实验表明它优于带替换采样。为了在强化学习中利用 RR 的益处，我们提出了一种采样方法，将 RR 扩展到经验回放中，既适用于均匀采样也适用于优先级采样。我们在 Atari 基准上评估了我们的采样方法，展示了其在深度强化学习中的有效性。 

---
# REAct: Rational Exponential Activation for Better Learning and Generalization in PINNs 

**Title (ZH)**: REAct: 基于理性指数激活以提高物理 informer 网络的学习能力和泛化能力 

**Authors**: Sourav Mishra, Shreya Hallikeri, Suresh Sundaram  

**Link**: [PDF](https://arxiv.org/pdf/2503.02267)  

**Abstract**: Physics-Informed Neural Networks (PINNs) offer a promising approach to simulating physical systems. Still, their application is limited by optimization challenges, mainly due to the lack of activation functions that generalize well across several physical systems. Existing activation functions often lack such flexibility and generalization power. To address this issue, we introduce Rational Exponential Activation (REAct), a generalized form of tanh consisting of four learnable shape parameters. Experiments show that REAct outperforms many standard and benchmark activations, achieving an MSE three orders of magnitude lower than tanh on heat problems and generalizing well to finer grids and points beyond the training domain. It also excels at function approximation tasks and improves noise rejection in inverse problems, leading to more accurate parameter estimates across varying noise levels. 

**Abstract (ZH)**: 基于物理的神经网络（PINNs）提供了一种模拟物理系统的有前途的方法。然而，其应用受限于优化挑战，主要原因是缺乏能够在多种物理系统中泛化的激活函数。现有的激活函数通常缺乏这种灵活性和泛化能力。为了解决这一问题，我们引入了一种tanh的广义形式——理性指数激活（REAct），它包含四个可学习的形状参数。实验结果显示，REAct在热问题上的均方误差比tanh低三个数量级，并且能够在细网格和训练域外的点上很好地泛化。此外，REAct在函数逼近任务中表现出色，提高了逆问题中的噪声抵制能力，从而在不同噪声水平下获得更准确的参数估计。 

---
# Large Language Models as Natural Selector for Embodied Soft Robot Design 

**Title (ZH)**: 大型语言模型作为自然选择器用于体现式软机器人设计 

**Authors**: Changhe Chen, Xiaohao Xu, Xiangdong Wang, Xiaonan Huang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02249)  

**Abstract**: Designing soft robots is a complex and iterative process that demands cross-disciplinary expertise in materials science, mechanics, and control, often relying on intuition and extensive experimentation. While Large Language Models (LLMs) have demonstrated impressive reasoning abilities, their capacity to learn and apply embodied design principles--crucial for creating functional robotic systems--remains largely unexplored. This paper introduces RoboCrafter-QA, a novel benchmark to evaluate whether LLMs can learn representations of soft robot designs that effectively bridge the gap between high-level task descriptions and low-level morphological and material choices. RoboCrafter-QA leverages the EvoGym simulator to generate a diverse set of soft robot design challenges, spanning robotic locomotion, manipulation, and balancing tasks. Our experiments with state-of-the-art multi-modal LLMs reveal that while these models exhibit promising capabilities in learning design representations, they struggle with fine-grained distinctions between designs with subtle performance differences. We further demonstrate the practical utility of LLMs for robot design initialization. Our code and benchmark will be available to encourage the community to foster this exciting research direction. 

**Abstract (ZH)**: 设计软机器人是一个复杂且迭代的过程，要求多学科专业知识，包括材料科学、机械学和控制学，通常依赖直觉和大量实验。尽管大型语言模型（LLMs）展现出了强大的推理能力，但它们在学习和应用体现于设计的基本原理方面的能力——这对于创建功能性的机器人系统至关重要——仍然 largely unexplored 省略为“缺乏探索”。本文介绍 RoboCrafter-QA，这是一个新的基准，用于评估 LLMs 是否能够学习代表软机器人设计的表示，这些表示能够有效地弥合高层次任务描述与低层次形态和材料选择之间的差距。RoboCrafter-QA 利用 EvoGym 模拟器生成一系列软机器人设计挑战，涵盖机器人运动、操作和平衡任务。我们的实验证明，虽然这些模型在学习设计表示方面表现出令人鼓舞的能力，但在区分具有微妙性能差异的设计方面存在困难。我们进一步展示了 LLMs 在机器人设计初始化方面的实际应用价值。我们的代码和基准将可供社区使用，以促进这一令人兴奋的研究方向。 

---
# Deficient Excitation in Parameter Learning 

**Title (ZH)**: 参数学习中的激发不足 

**Authors**: Ganghui Cao, Shimin Wang, Martin Guay, Jinzhi Wang, Zhisheng Duan, Marios M. Polycarpou  

**Link**: [PDF](https://arxiv.org/pdf/2503.02235)  

**Abstract**: This paper investigates parameter learning problems under deficient excitation (DE). The DE condition is a rank-deficient, and therefore, a more general evolution of the well-known persistent excitation condition. Under the DE condition, a proposed online algorithm is able to calculate the identifiable and non-identifiable subspaces, and finally give an optimal parameter estimate in the sense of least squares. In particular, the learning error within the identifiable subspace exponentially converges to zero in the noise-free case, even without persistent excitation. The DE condition also provides a new perspective for solving distributed parameter learning problems, where the challenge is posed by local regressors that are often insufficiently excited. To improve knowledge of the unknown parameters, a cooperative learning protocol is proposed for a group of estimators that collect measured information under complementary DE conditions. This protocol allows each local estimator to operate locally in its identifiable subspace, and reach a consensus with neighbours in its non-identifiable subspace. As a result, the task of estimating unknown parameters can be achieved in a distributed way using cooperative local estimators. Application examples in system identification are given to demonstrate the effectiveness of the theoretical results developed in this paper. 

**Abstract (ZH)**: 本文探讨在 deficient excitation (DE) 条件下的参数学习问题。DE 条件是一种秩亏条件，因而是一种已知的持久激励条件的更通用形式。在 DE 条件下，提出了一种在线算法，能够计算可识别子空间和不可识别子空间，并最终给出最小二乘意义下的最优参数估计。特别地，在无噪声情况下，可识别子空间内的学习误差指数地收敛于零，即使没有持久激励。DE 条件还为解决分布式参数学习问题提供了新的视角，这些建模器面临的挑战在于局部 regressors 通常激励不足。为了提高未知参数的知识，提出了一种合作学习协议，用于一组在互补 DE 条件下收集测量信息的估计器。该协议允许每个局部估计器在其可识别子空间内进行局部操作，并在不可识别子空间内与邻居达成一致。结果表明，可以通过合作局部估计器以分布式方式实现未知参数的估计。本文给出了系统识别的应用实例，以证明所发展的理论结果的有效性。 

---
# Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling 

**Title (ZH)**: 通过明确定界知识边界提升大规模语言模型可靠性 

**Authors**: Hang Zheng, Hongshen Xu, Yuncong Liu, Lu Chen, Pascale Fung, Kai Yu  

**Link**: [PDF](https://arxiv.org/pdf/2503.02233)  

**Abstract**: Large language models (LLMs) frequently hallucinate due to misaligned self-awareness, generating erroneous outputs when addressing queries beyond their knowledge boundaries. While existing approaches mitigate hallucinations via uncertainty estimation or query rejection, they suffer from computational inefficiency or sacrificed helpfulness. To address these issues, we propose the Explicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and slow reasoning systems to harmonize reliability and usability. The framework first employs a fast-thinking model to generate confidence-labeled responses, enabling immediate use of high-confidence outputs. For uncertain predictions, a slow refinement model conducts targeted reasoning to improve accuracy. To align model behavior with our proposed object, we propose a hybrid training pipeline, enhancing self-awareness without degrading task performance. Evaluations on dialogue state tracking tasks demonstrate that EKBM achieves superior model reliability over uncertainty-based baselines. Further analysis reveals that refinement substantially boosts accuracy while maintaining low computational overhead. Our work establishes a scalable paradigm for advancing LLM reliability and balancing accuracy and practical utility in error-sensitive applications. 

**Abstract (ZH)**: Explicit Knowledge Boundary Modeling (EKBM)框架：和谐提升大型语言模型的可靠性和可用性 

---
# One Patient's Annotation is Another One's Initialization: Towards Zero-Shot Surgical Video Segmentation with Cross-Patient Initialization 

**Title (ZH)**: 一位患者的标注是另一位患者的初始化：面向跨患者初始化的零样本手术视频分割 

**Authors**: Seyed Amir Mousavi, Utku Ozbulak, Francesca Tozzi, Nikdokht Rashidian, Wouter Willaert, Joris Vankerschaver, Wesley De Neve  

**Link**: [PDF](https://arxiv.org/pdf/2503.02228)  

**Abstract**: Video object segmentation is an emerging technology that is well-suited for real-time surgical video segmentation, offering valuable clinical assistance in the operating room by ensuring consistent frame tracking. However, its adoption is limited by the need for manual intervention to select the tracked object, making it impractical in surgical settings. In this work, we tackle this challenge with an innovative solution: using previously annotated frames from other patients as the tracking frames. We find that this unconventional approach can match or even surpass the performance of using patients' own tracking frames, enabling more autonomous and efficient AI-assisted surgical workflows. Furthermore, we analyze the benefits and limitations of this approach, highlighting its potential to enhance segmentation accuracy while reducing the need for manual input. Our findings provide insights into key factors influencing performance, offering a foundation for future research on optimizing cross-patient frame selection for real-time surgical video analysis. 

**Abstract (ZH)**: 基于其他患者标注帧的实时手术视频对象分割：一种创新的自动解决方案及其影响分析 

---
# Words or Vision: Do Vision-Language Models Have Blind Faith in Text? 

**Title (ZH)**: 词语or视觉：视觉语言模型对文本是否盲目信赖？ 

**Authors**: Ailin Deng, Tri Cao, Zhirui Chen, Bryan Hooi  

**Link**: [PDF](https://arxiv.org/pdf/2503.02199)  

**Abstract**: Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual data and varied textual inputs in vision-centered settings. By introducing textual variations to four vision-centric tasks and evaluating ten Vision-Language Models (VLMs), we discover a \emph{``blind faith in text''} phenomenon: VLMs disproportionately trust textual data over visual data when inconsistencies arise, leading to significant performance drops under corrupted text and raising safety concerns. We analyze factors influencing this text bias, including instruction prompts, language model size, text relevance, token order, and the interplay between visual and textual certainty. While certain factors, such as scaling up the language model size, slightly mitigate text bias, others like token order can exacerbate it due to positional biases inherited from language models. To address this issue, we explore supervised fine-tuning with text augmentation and demonstrate its effectiveness in reducing text bias. Additionally, we provide a theoretical analysis suggesting that the blind faith in text phenomenon may stem from an imbalance of pure text and multi-modal data during training. Our findings highlight the need for balanced training and careful consideration of modality interactions in VLMs to enhance their robustness and reliability in handling multi-modal data inconsistencies. 

**Abstract (ZH)**: 视觉-语言模型（VLMs）在视觉中心任务中擅长整合视觉和文本信息，但它们处理不同模态之间不一致性的方法尚未充分探讨。我们调查了在面对视觉数据和不同文本输入时，视觉中心设置中VLMs对不同模态的偏好。通过向四个视觉中心任务引入文本变化并评估十种视觉-语言模型（VLMs），我们发现了一种“过度依赖文本”的现象：当出现不一致性时，VLMs过度信任文本数据而忽视视觉数据，导致在文本受污染时性能显著下降，并引发安全关切。我们分析了影响这一文本偏差的因素，包括指令提示、语言模型规模、文本相关性、标记顺序以及视觉和文本一致性的互动。虽然某些因素，如扩大语言模型规模，可以略微减轻文本偏差，但其他因素，如标记顺序，却可能因继承自语言模型的位置偏差而加剧偏差。为了解决这一问题，我们探索了带有文本增强的数据监督微调方法，并展示了其在减少文本偏差方面的有效性。此外，我们提供了一种理论分析，表明这一“过度依赖文本”现象可能源于训练过程中纯文本和多模态数据之间失衡。我们的研究结果强调了平衡训练和仔细考虑模态交互的重要性，以增强VLMs在处理多模态数据不一致性时的稳健性和可靠性。 

---
# ATLaS: Agent Tuning via Learning Critical Steps 

**Title (ZH)**: ATLaS: 基于学习关键步骤的智能体调优 

**Authors**: Zhixun Chen, Ming Li, Yuxuan Huang, Yali Du, Meng Fang, Tianyi Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2503.02197)  

**Abstract**: Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and weaken generalization to states not covered by the expert data. Additionally, critical steps, such as planning, complex reasoning for intermediate subtasks, and strategic decision-making, are essential to success in agent tasks, so learning these steps is the key to improving LLM agents. For more effective and efficient agent tuning, we propose ATLaS that identifies the critical steps in expert trajectories and finetunes LLMs solely on these steps with reduced costs. By steering the training's focus to a few critical steps, our method mitigates the risk of overfitting entire trajectories and promotes generalization across different environments and tasks. In extensive experiments, an LLM finetuned on only 30% critical steps selected by ATLaS outperforms the LLM finetuned on all steps and recent open-source LLM agents. ATLaS maintains and improves base LLM skills as generalist agents interacting with diverse environments. 

**Abstract (ZH)**: Large Language Model (LLM) 前代理(Agent)在多领域任务中展现了显著的泛化能力。现有的代理调优方法通常通过监督微调整个专家轨迹来实现。然而，直接克隆完整轨迹的行为克隆方法可能会引入专家偏差，削弱对专家数据未涵盖状态的泛化能力。另外，规划、复杂中间子任务的理性推理以及战略决策等关键步骤在代理任务的成功中至关重要，因此学习这些步骤是提高LLM代理的关键。为了实现更有效的和高效的代理调优，我们提出ATLaS，该方法识别专家轨迹中的关键步骤，并仅在此基础上对LLM进行微调，从而降低成本。通过将训练的重点转向少量关键步骤，我们的方法减轻了对完整轨迹过拟合的风险，并促进了在不同环境和任务中的泛化能力。在广泛的实验中，仅使用ATLaS选择的30%关键步骤进行微调的LLM，在性能上优于使用所有步骤进行微调的LLM和最近的开源LLM代理。ATLaS能够保持和提升基础LLM在作为通用代理与多样化环境交互时的技能。 

---
# Discrete Differential Evolution Particle Swarm Optimization Algorithm for Energy Saving Flexible Job Shop Scheduling Problem Considering Machine Multi States 

**Title (ZH)**: 考虑机器多状态的节能柔性作业 shop排程问题的离散差分进化粒子群优化算法 

**Authors**: Da Wang, Yu Zhang, Kai Zhang, Junqing Li, Dengwang Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.02180)  

**Abstract**: As the continuous deepening of low-carbon emission reduction policies, the manufacturing industries urgently need sensible energy-saving scheduling schemes to achieve the balance between improving production efficiency and reducing energy consumption. In energy-saving scheduling, reasonable machine states-switching is a key point to achieve expected goals, i.e., whether the machines need to switch speed between different operations, and whether the machines need to add extra setup time between different jobs. Regarding this matter, this work proposes a novel machine multi states-based energy saving flexible job scheduling problem (EFJSP-M), which simultaneously takes into account machine multi speeds and setup time. To address the proposed EFJSP-M, a kind of discrete differential evolution particle swarm optimization algorithm (D-DEPSO) is designed. In specific, D-DEPSO includes a hybrid initialization strategy to improve the initial population performance, an updating mechanism embedded with differential evolution operators to enhance population diversity, and a critical path variable neighborhood search strategy to expand the solution space. At last, based on datasets DPs and MKs, the experiment results compared with five state-of-the-art algorithms demonstrate the feasible of EFJSP-M and the superior of D-DEPSO. 

**Abstract (ZH)**: 随着低碳减排政策的不断深化，制造业迫切需要 sensible 能源节约调度方案以实现提高生产效率与降低能耗之间的平衡。在能源节约调度中，合理的机器状态切换是实现预期目标的关键，即是否需要在不同工序间切换机器速度，以及是否需要在不同任务间增加额外的切换时间。针对此问题，本文提出了一种新型的基于多状态的节能柔性作业调度问题 (EFJSP-M)，同时考虑了机器多速性和切换时间。为解决提出的 EFJSP-M，设计了一种离散微分进化粒子群优化算法 (D-DEPSO)。具体而言，D-DEPSO 包括混合初始化策略以提高初始种群性能，嵌入差异进化算子的更新机制以增强种群多样性，以及关键路径变邻域搜索策略以扩展解空间。最后，基于 DPs 和 MKs 数据集，与五种先进算法的实验结果对比证明了 EFJSP-M 的可行性和 D-DEPSO 的优越性。 

---
# DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models 

**Title (ZH)**: DivPrune：基于多样性的视觉词元剪枝用于大型多模态模型 

**Authors**: Saeed Ranjbar Alvar, Gursimran Singh, Mohammad Akbari, Yong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02175)  

**Abstract**: Large Multimodal Models (LMMs) have emerged as powerful models capable of understanding various data modalities, including text, images, and videos. LMMs encode both text and visual data into tokens that are then combined and processed by an integrated Large Language Model (LLM). Including visual tokens substantially increases the total token count, often by thousands. The increased input length for LLM significantly raises the complexity of inference, resulting in high latency in LMMs. To address this issue, token pruning methods, which remove part of the visual tokens, are proposed. The existing token pruning methods either require extensive calibration and fine-tuning or rely on suboptimal importance metrics which results in increased redundancy among the retained tokens. In this paper, we first formulate token pruning as Max-Min Diversity Problem (MMDP) where the goal is to select a subset such that the diversity among the selected {tokens} is maximized. Then, we solve the MMDP to obtain the selected subset and prune the rest. The proposed method, DivPrune, reduces redundancy and achieves the highest diversity of the selected tokens. By ensuring high diversity, the selected tokens better represent the original tokens, enabling effective performance even at high pruning ratios without requiring fine-tuning. Extensive experiments with various LMMs show that DivPrune achieves state-of-the-art accuracy over 16 image- and video-language datasets. Additionally, DivPrune reduces both the end-to-end latency and GPU memory usage for the tested models. The code is available $\href{this https URL}{\text{here}}$. 

**Abstract (ZH)**: 大型多模态模型中的token剪枝方法：最大化最小多样性的剪枝方法（DivPrune） 

---
# Adversarial Tokenization 

**Title (ZH)**: 对抗性标记化 

**Authors**: Renato Lui Geh, Zilei Shao, Guy Van den Broeck  

**Link**: [PDF](https://arxiv.org/pdf/2503.02174)  

**Abstract**: Current LLM pipelines account for only one possible tokenization for a given string, ignoring exponentially many alternative tokenizations during training and inference. For example, the standard Llama3 tokenization of penguin is [p,enguin], yet [peng,uin] is another perfectly valid alternative. In this paper, we show that despite LLMs being trained solely on one tokenization, they still retain semantic understanding of other tokenizations, raising questions about their implications in LLM safety. Put succinctly, we answer the following question: can we adversarially tokenize an obviously malicious string to evade safety and alignment restrictions? We show that not only is adversarial tokenization an effective yet previously neglected axis of attack, but it is also competitive against existing state-of-the-art adversarial approaches without changing the text of the harmful request. We empirically validate this exploit across three state-of-the-art LLMs and adversarial datasets, revealing a previously unknown vulnerability in subword models. 

**Abstract (ZH)**: 当前的LLM管道只考虑给定字符串的一种可能分词方式，在训练和推理过程中忽略了指数级的其他分词方式。例如，标准的Llama3分词“penguin”为[p,enguin]，但[peng,uin]也是另一 perfectly valid 的替代分词。在本文中，我们证明尽管LLM仅被训练于一种分词方式，它们仍然保留了对其他分词方式的语义理解，从而引发了其在LLM安全方面的意义问题。简而言之，我们回答了以下问题：我们能否对抗性地分词一个明显恶意的字符串以规避安全和对齐限制？我们展示对抗性分词不仅是有效的且先前被忽略的一种攻击方式，而且还与现有的先进对抗性方法具有竞争力，无需改变有害请求的文本。我们在三个最先进的LLM和对抗性数据集中实证验证了这一利用方式，揭示了子词模型中一个未知的漏洞。 

---
# Adaptive Camera Sensor for Vision Models 

**Title (ZH)**: 自适应摄像头传感器以供视觉模型使用 

**Authors**: Eunsu Baek, Sunghwan Han, Taesik Gong, Hyung-Sin Kim  

**Link**: [PDF](https://arxiv.org/pdf/2503.02170)  

**Abstract**: Domain shift remains a persistent challenge in deep-learning-based computer vision, often requiring extensive model modifications or large labeled datasets to address. Inspired by human visual perception, which adjusts input quality through corrective lenses rather than over-training the brain, we propose Lens, a novel camera sensor control method that enhances model performance by capturing high-quality images from the model's perspective rather than relying on traditional human-centric sensor control. Lens is lightweight and adapts sensor parameters to specific models and scenes in real-time. At its core, Lens utilizes VisiT, a training-free, model-specific quality indicator that evaluates individual unlabeled samples at test time using confidence scores without additional adaptation costs. To validate Lens, we introduce ImageNet-ES Diverse, a new benchmark dataset capturing natural perturbations from varying sensor and lighting conditions. Extensive experiments on both ImageNet-ES and our new ImageNet-ES Diverse show that Lens significantly improves model accuracy across various baseline schemes for sensor control and model modification while maintaining low latency in image captures. Lens effectively compensates for large model size differences and integrates synergistically with model improvement techniques. Our code and dataset are available at this http URL. 

**Abstract (ZH)**: 基于深度学习的计算机视觉领域中，域适应仍然是一个持续性的挑战，往往需要对模型进行大量修改或依赖大量标记数据来解决。受人类视觉感知的启发，人类通过矫正镜头调整输入质量而非过度训练大脑，我们提出了一种新的摄像传感器控制方法Lens，该方法通过从模型视角捕获高质量图像来提升模型性能，而非依赖传统的人本中心传感器控制。Lens轻量级且能够实现实时自适应调整传感器参数，以适应特定模型和场景。核心上，Lens利用了VisiT，这是一种无需额外适应成本且针对特定模型的质量指标，在测试时使用置信分数评估未标记样本。为了验证Lens的有效性，我们引入了ImageNet-ES Diverse新基准数据集，该数据集捕捉了不同传感器和光照条件下自然的扰动。在ImageNet-ES和新引入的ImageNet-ES Diverse两个基准上的广泛实验表明，Lens显著提升了传感器控制和模型修改的各种基线方案的模型准确性，同时保持了低延迟的图像捕获。Lens能够有效补偿大型模型尺寸差异，并与模型改进技术协同工作。我们的代码和数据集可访问于此网址。 

---
# MedHEval: Benchmarking Hallucinations and Mitigation Strategies in Medical Large Vision-Language Models 

**Title (ZH)**: MedHEval: 医学大规模视觉-语言模型中的幻觉benchmark及缓解策略 

**Authors**: Aofei Chang, Le Huang, Parminder Bhatia, Taha Kass-Hout, Fenglong Ma, Cao Xiao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02157)  

**Abstract**: Large Vision Language Models (LVLMs) are becoming increasingly important in the medical domain, yet Medical LVLMs (Med-LVLMs) frequently generate hallucinations due to limited expertise and the complexity of medical applications. Existing benchmarks fail to effectively evaluate hallucinations based on their underlying causes and lack assessments of mitigation strategies. To address this gap, we introduce MedHEval, a novel benchmark that systematically evaluates hallucinations and mitigation strategies in Med-LVLMs by categorizing them into three underlying causes: visual misinterpretation, knowledge deficiency, and context misalignment. We construct a diverse set of close- and open-ended medical VQA datasets with comprehensive evaluation metrics to assess these hallucination types. We conduct extensive experiments across 11 popular (Med)-LVLMs and evaluate 7 state-of-the-art hallucination mitigation techniques. Results reveal that Med-LVLMs struggle with hallucinations arising from different causes while existing mitigation methods show limited effectiveness, especially for knowledge- and context-based errors. These findings underscore the need for improved alignment training and specialized mitigation strategies to enhance Med-LVLMs' reliability. MedHEval establishes a standardized framework for evaluating and mitigating medical hallucinations, guiding the development of more trustworthy Med-LVLMs. 

**Abstract (ZH)**: MedHEval: Systematically Evaluating and Mitigating Hallucinations in Medical Large Vision Language Models 

---
# MobRFFI: Non-cooperative Device Re-identification for Mobility Intelligence 

**Title (ZH)**: MobRFFI: 不合作设备识别以提高移动智能 

**Authors**: Stepan Mazokha, Fanchen Bao, George Sklivanitis, Jason O. Hallstrom  

**Link**: [PDF](https://arxiv.org/pdf/2503.02156)  

**Abstract**: WiFi-based mobility monitoring in urban environments can provide valuable insights into pedestrian and vehicle movements. However, MAC address randomization introduces a significant obstacle in accurately estimating congestion levels and path trajectories. To this end, we consider radio frequency fingerprinting and re-identification for attributing WiFi traffic to emitting devices without the use of MAC addresses.
We present MobRFFI, an AI-based device fingerprinting and re-identification framework for WiFi networks that leverages an encoder deep learning model to extract unique features based on WiFi chipset hardware impairments. It is entirely independent of frame type. When evaluated on the WiFi fingerprinting dataset WiSig, our approach achieves 94% and 100% device accuracy in multi-day and single-day re-identification scenarios, respectively.
We also collect a novel dataset, MobRFFI, for granular multi-receiver WiFi device fingerprinting evaluation. Using the dataset, we demonstrate that the combination of fingerprints from multiple receivers boosts re-identification performance from 81% to 100% on a single-day scenario and from 41% to 100% on a multi-day scenario. 

**Abstract (ZH)**: 基于WiFi的移动监控在城市环境中可以提供行人和车辆移动的宝贵见解。然而，MAC地址随机化给准确估计拥堵水平和路径轨迹带来重大障碍。为此，我们考虑使用射频指纹识别和再识别，以不依赖MAC地址的方式将WiFi流量归因于发出设备。
MobRFFI：一种基于AI的WiFi网络设备指纹识别和再识别框架，利用编码深度学习模型根据WiFi芯片组硬件缺陷提取独特的特征。该框架完全不依赖于帧类型。在WiSig WiFi指纹识别数据集上评估，我们的方法在多天和单日再识别场景中分别实现了94%和100%的设备准确性。
我们还收集了一个新的数据集MobRFFI，用于细粒度多接收器WiFi设备指纹识别评估。利用该数据集，我们展示了多接收器指纹组合在单日场景中将再识别性能从81%提升到100%，在多天场景中提升从41%到100%。 

---
# AugFL: Augmenting Federated Learning with Pretrained Models 

**Title (ZH)**: AugFL：利用预训练模型增强联邦学习 

**Authors**: Sheng Yue, Zerui Qin, Yongheng Deng, Ju Ren, Yaoxue Zhang, Junshan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.02154)  

**Abstract**: Federated Learning (FL) has garnered widespread interest in recent years. However, owing to strict privacy policies or limited storage capacities of training participants such as IoT devices, its effective deployment is often impeded by the scarcity of training data in practical decentralized learning environments. In this paper, we study enhancing FL with the aid of (large) pre-trained models (PMs), that encapsulate wealthy general/domain-agnostic knowledge, to alleviate the data requirement in conducting FL from scratch. Specifically, we consider a networked FL system formed by a central server and distributed clients. First, we formulate the PM-aided personalized FL as a regularization-based federated meta-learning problem, where clients join forces to learn a meta-model with knowledge transferred from a private PM stored at the server. Then, we develop an inexact-ADMM-based algorithm, AugFL, to optimize the problem with no need to expose the PM or incur additional computational costs to local clients. Further, we establish theoretical guarantees for AugFL in terms of communication complexity, adaptation performance, and the benefit of knowledge transfer in general non-convex cases. Extensive experiments corroborate the efficacy and superiority of AugFL over existing baselines. 

**Abstract (ZH)**: 联邦学习（FL）近年来引起了广泛兴趣。然而，由于严格的隐私政策或训练参与者如物联网设备的有限存储容量，其在实际去中心化学习环境中有效部署往往受限于训练数据的稀缺性。本文研究了通过辅助机制（如大型）预训练模型（PMs）来增强FL，以减少从头进行FL时的数据需求。具体而言，我们考虑由中央服务器和分布式客户端组成的一个网络化FL系统。首先，我们将PM辅助个性化FL形式化为基于正则化联邦元学习问题，客户端共同努力通过存储在服务器上的私人PM转移知识来学习一个元模型。然后，我们开发了一个基于不精确ADMM的算法AugFL，该算法优化该问题而不需暴露PM或给本地客户端增加额外的计算成本。此外，我们在一般非凸情况下为AugFL建立了通信复杂度、适应性能和知识转移收益的理论保证。广泛的实验验证了AugFL的有效性和优越性。 

---
# Elliptic Loss Regularization 

**Title (ZH)**: 椭圆损失正则化 

**Authors**: Ali Hasan, Haoming Yang, Yuting Ng, Vahid Tarokh  

**Link**: [PDF](https://arxiv.org/pdf/2503.02138)  

**Abstract**: Regularizing neural networks is important for anticipating model behavior in regions of the data space that are not well represented. In this work, we propose a regularization technique for enforcing a level of smoothness in the mapping between the data input space and the loss value. We specify the level of regularity by requiring that the loss of the network satisfies an elliptic operator over the data domain. To do this, we modify the usual empirical risk minimization objective such that we instead minimize a new objective that satisfies an elliptic operator over points within the domain. This allows us to use existing theory on elliptic operators to anticipate the behavior of the error for points outside the training set. We propose a tractable computational method that approximates the behavior of the elliptic operator while being computationally efficient. Finally, we analyze the properties of the proposed regularization to understand the performance on common problems of distribution shift and group imbalance. Numerical experiments confirm the utility of the proposed regularization technique. 

**Abstract (ZH)**: 强制神经网络在数据空间中未充分代表的区域具有一致的行为对于预测模型行为很重要。本文提出了一种正则化技术，以确保数据输入空间与损失值之间的映射具有一定程度的平滑性。通过要求网络的损失满足数据域上的椭圆算子来指定这种正则性。为此，我们修改了通常的经验风险最小化目标，使其而是最小化一个满足数据域内点上的椭圆算子的新目标。这使得我们可以利用现有的椭圆算子理论来预测训练集外点的误差行为。我们提出了一种计算上可行的方法来近似椭圆算子的行为，同时保持计算效率。最后，我们分析了所提正则化技术的性质，以了解其在常见分布转移和组不平衡问题上的性能。数值实验证实了所提正则化技术的有效性。 

---
# Forgetting Transformer: Softmax Attention with a Forget Gate 

**Title (ZH)**: 遗忘变换器：带有遗忘门的softmax注意机制 

**Authors**: Zhixuan Lin, Evgenii Nikishin, Xu Owen He, Aaron Courville  

**Link**: [PDF](https://arxiv.org/pdf/2503.02130)  

**Abstract**: An essential component of modern recurrent sequence models is the forget gate. While Transformers do not have an explicit recurrent form, we show that a forget gate can be naturally incorporated into Transformers by down-weighting the unnormalized attention scores in a data-dependent way. We name this attention mechanism the Forgetting Attention and the resulting model the Forgetting Transformer (FoX). We show that FoX outperforms the Transformer on long-context language modeling, length extrapolation, and short-context downstream tasks, while performing on par with the Transformer on long-context downstream tasks. Moreover, it is compatible with the FlashAttention algorithm and does not require any positional embeddings. Several analyses, including the needle-in-the-haystack test, show that FoX also retains the Transformer's superior long-context capabilities over recurrent sequence models such as Mamba-2, HGRN2, and DeltaNet. We also introduce a "Pro" block design that incorporates some common architectural components in recurrent sequence models and find it significantly improves the performance of both FoX and the Transformer. Our code is available at this https URL. 

**Abstract (ZH)**: 现代递归序列模型的一个基本组件是忘门。虽然变压器没有显式的递归形式，但我们展示了可以通过数据依赖的方式降低未归一化的注意力分数来自然地将忘门融入到变压器中。我们称这种注意力机制为忘门注意力，并将相应的模型命名为忘门变压器（FoX）。我们展示了FoX在长上下文语言建模、长度外推以及短上下文下游任务上优于变压器，而在长上下文下游任务上与变压器性能相当。此外，FoX 与 FlashAttention 算法兼容，无需任何位置嵌入。包括针扎 haystack 测试在内的一些分析表明，FoX 也保留了变压器在与 Mamba-2、HGRN2 和 DeltaNet 这种递归序列模型相比时优于长上下文能力。我们还引入了一种“Pro”块设计，将一些常见的递归序列模型架构组件整合其中，并发现它显著提高了FoX和变压器的性能。我们的代码可在以下链接获取。 

---
# A Near Complete Nonasymptotic Generalization Theory For Multilayer Neural Networks: Beyond the Bias-Variance Tradeoff 

**Title (ZH)**: 近完全非渐近通用化理论：超越偏差-方差权衡的多层神经网络 

**Authors**: Hao Yu, Xiangyang Ji  

**Link**: [PDF](https://arxiv.org/pdf/2503.02129)  

**Abstract**: We propose a first near complete (that will make explicit sense in the main text) nonasymptotic generalization theory for multilayer neural networks with arbitrary Lipschitz activations and general Lipschitz loss functions (with some very mild conditions). In particular, it doens't require the boundness of loss function, as commonly assumed in the literature. Our theory goes beyond the bias-variance tradeoff, aligned with phenomenon typically encountered in deep learning. It is therefore sharp different with other existing nonasymptotic generalization error bounds for neural networks. More explicitly, we propose an explicit generalization error upper bound for multilayer neural networks with arbitrary Lipschitz activations $\sigma$ with $\sigma(0)=0$ and broad enough Lipschitz loss functions, without requiring either the width, depth or other hyperparameters of the neural network approaching infinity, a specific neural network architect (e.g. sparsity, boundness of some norms), a particular activation function, a particular optimization algorithm or boundness of the loss function, and with taking the approximation error into consideration. General Lipschitz activation can also be accommodated into our framework. A feature of our theory is that it also considers approximation errors. Furthermore, we show the near minimax optimality of our theory for multilayer ReLU networks for regression problems. Notably, our upper bound exhibits the famous double descent phenomenon for such networks, which is the most distinguished characteristic compared with other existing results. This work emphasizes a view that many classical results should be improved to embrace the unintuitive characteristics of deep learning to get a better understanding of it. 

**Abstract (ZH)**: 我们提出了一种接近完备的非渐近泛化理论，适用于具有任意Lipschitz激活函数和广义Lipschitz损失函数的多层神经网络（在主文中将明确阐述）。特别地，该理论不要求损失函数有界，这不同于文献中的常见假设。该理论超越了偏差-方差权衡，与在深度学习中通常遇到的现象相一致。因此，它与现有的非渐近神经网络泛化误差边界有显著不同。更具体地说，我们提出了一个关于具有任意Lipschitz激活函数$\sigma(\sigma(0)=0)$和足够广义的Lipschitz损失函数的多层神经网络的显式泛化误差上界，而不需要神经网络的宽度、深度或其他超参数趋于无穷大，也不需要特定的神经网络结构（如稀疏性、某些范数有界性）、特定的激活函数、特定的优化算法或损失函数有界性，同时考虑了逼近误差。我们理论框架也可以容纳广义Lipschitz激活函数。我们的理论的一个特点是考虑了逼近误差。此外，我们证明了对于回归问题，我们对于多层ReLU网络的理论近乎最小最大最优，并且我们的上界表现出著名的双下降现象，这是与其他现有结果最显著的区别。这项工作强调了一种观点，即许多经典结果需要改进，以便纳入深度学习的直觉之外的特性，从而更好地理解它。 

---
# Parabolic Continual Learning 

**Title (ZH)**: 抛物线连续学习 

**Authors**: Haoming Yang, Ali Hasan, Vahid Tarokh  

**Link**: [PDF](https://arxiv.org/pdf/2503.02117)  

**Abstract**: Regularizing continual learning techniques is important for anticipating algorithmic behavior under new realizations of data. We introduce a new approach to continual learning by imposing the properties of a parabolic partial differential equation (PDE) to regularize the expected behavior of the loss over time. This class of parabolic PDEs has a number of favorable properties that allow us to analyze the error incurred through forgetting and the error induced through generalization. Specifically, we do this through imposing boundary conditions where the boundary is given by a memory buffer. By using the memory buffer as a boundary, we can enforce long term dependencies by bounding the expected error by the boundary loss. Finally, we illustrate the empirical performance of the method on a series of continual learning tasks. 

**Abstract (ZH)**: 通过施加抛物型偏微分方程（PDE）的性质来正则化持续学习技术，以预测在新数据实现下的算法行为至关重要。我们提出了一种新的持续学习方法，通过对损失在时间上的预期行为施加抛物型偏微分方程（PDE）的性质来进行正则化。此类抛物型偏微分方程具有许多有利特性，允许我们分析由于遗忘引起的误差和由于泛化引起的误差。具体而言，我们通过施加由记忆缓冲区给出的边界条件来实现这一点。通过将记忆缓冲区作为边界，我们可以通过边界损失来约束预期误差，从而确保长期依赖性。最后，我们在一系列持续学习任务中展示了该方法的实证性能。 

---
# Provable Benefits of Task-Specific Prompts for In-context Learning 

**Title (ZH)**: 任务特定提示在上下文学习中的证明益处 

**Authors**: Xiangyu Chang, Yingcong Li, Muti Kara, Samet Oymak, Amit K. Roy-Chowdhury  

**Link**: [PDF](https://arxiv.org/pdf/2503.02102)  

**Abstract**: The in-context learning capabilities of modern language models have motivated a deeper mathematical understanding of sequence models. A line of recent work has shown that linear attention models can emulate projected gradient descent iterations to implicitly learn the task vector from the data provided in the context window. In this work, we consider a novel setting where the global task distribution can be partitioned into a union of conditional task distributions. We then examine the use of task-specific prompts and prediction heads for learning the prior information associated with the conditional task distribution using a one-layer attention model. Our results on loss landscape show that task-specific prompts facilitate a covariance-mean decoupling where prompt-tuning explains the conditional mean of the distribution whereas the variance is learned/explained through in-context learning. Incorporating task-specific head further aids this process by entirely decoupling estimation of mean and variance components. This covariance-mean perspective similarly explains how jointly training prompt and attention weights can provably help over fine-tuning after pretraining. 

**Abstract (ZH)**: 现代语言模型的上下文学习能力推动了序列模型的深层次数学理解。近期研究表明，线性注意力模型可以通过隐式学习上下文窗口提供的数据来模拟投影梯度下降迭代。在本文中，我们考虑了一种新颖的设置，即全局任务分布可以分解为条件任务分布的并集。然后，我们探讨了使用任务特定的提示和预测头，通过一层注意力模型学习与条件任务分布相关的先验信息。我们的损失景观结果表明，任务特定的提示促进了协方差-均值的解耦，其中提示调优解释了分布的条件均值，而方差是通过上下文学习来学习和解释的。进一步引入任务特定的预测头完全解耦了均值和方差的估计过程。这种协方差-均值的视角同样解释了共同训练提示和注意权重如何在预训练后超越微调以实现证明的帮助。 

---
# LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports 

**Title (ZH)**: LLMs作为教育分析师：将多模态数据轨迹转化为可操作的阅读评估报告 

**Authors**: Eduardo Davalos, Yike Zhang, Namrata Srivastava, Jorge Alberto Salas, Sara McFadden, Sun-Joo Cho, Gautam Biswas, Amanda Goodwin  

**Link**: [PDF](https://arxiv.org/pdf/2503.02099)  

**Abstract**: Reading assessments are essential for enhancing students' comprehension, yet many EdTech applications focus mainly on outcome-based metrics, providing limited insights into student behavior and cognition. This study investigates the use of multimodal data sources -- including eye-tracking data, learning outcomes, assessment content, and teaching standards -- to derive meaningful reading insights. We employ unsupervised learning techniques to identify distinct reading behavior patterns, and then a large language model (LLM) synthesizes the derived information into actionable reports for educators, streamlining the interpretation process. LLM experts and human educators evaluate these reports for clarity, accuracy, relevance, and pedagogical usefulness. Our findings indicate that LLMs can effectively function as educational analysts, turning diverse data into teacher-friendly insights that are well-received by educators. While promising for automating insight generation, human oversight remains crucial to ensure reliability and fairness. This research advances human-centered AI in education, connecting data-driven analytics with practical classroom applications. 

**Abstract (ZH)**: 多模态数据源在阅读评估中的应用：从行为和认知洞察到教师友好的报告生成 

---
# Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction 

**Title (ZH)**: 因果关联：北极海冰预测的因果深度学习框架 

**Authors**: Emam Hossain, Muhammad Hasan Ferdous, Jianwu Wang, Aneesh Subramanian, Md Osman Gani  

**Link**: [PDF](https://arxiv.org/pdf/2503.02093)  

**Abstract**: Traditional machine learning and deep learning techniques rely on correlation-based learning, often failing to distinguish spurious associations from true causal relationships, which limits robustness, interpretability, and generalizability. To address these challenges, we propose a causality-driven deep learning framework that integrates Multivariate Granger Causality (MVGC) and PCMCI+ causal discovery algorithms with a hybrid deep learning architecture. Using 43 years (1979-2021) of daily and monthly Arctic Sea Ice Extent (SIE) and ocean-atmospheric datasets, our approach identifies causally significant factors, prioritizes features with direct influence, reduces feature overhead, and improves computational efficiency. Experiments demonstrate that integrating causal features enhances the deep learning model's predictive accuracy and interpretability across multiple lead times. Beyond SIE prediction, the proposed framework offers a scalable solution for dynamic, high-dimensional systems, advancing both theoretical understanding and practical applications in predictive modeling. 

**Abstract (ZH)**: 传统的机器学习和深度学习技术依赖于基于相关性的学习，往往难以区分虚假关联和真正的因果关系，这限制了模型的稳健性、可解释性和泛化能力。为了解决这些问题，我们提出了一种因果驱动的深度学习框架，该框架结合了多元格兰杰因果性（MVGC）和PCMCI+因果发现算法，并采用混合深度学习架构。通过1979-2021年43年的日度和月度北极海冰Extent (SIE) 和海洋-大气数据集，我们的方法识别出具有因果意义的因素，优先考虑具有直接影响的特征，减少特征过载，并提高计算效率。实验结果表明，集成因果特征提升了深度学习模型在多个预见时长的预测准确性和可解释性。该框架不仅适用于SIE预测，还提供了动态高维系统的可扩展解决方案，推进了预测建模的理论理解和实际应用。 

---
# Linear Representations of Political Perspective Emerge in Large Language Models 

**Title (ZH)**: 政治视角的线性表示在大型语言模型中 Emerges 

**Authors**: Junsol Kim, James Evans, Aaron Schein  

**Link**: [PDF](https://arxiv.org/pdf/2503.02080)  

**Abstract**: Large language models (LLMs) have demonstrated the ability to generate text that realistically reflects a range of different subjective human perspectives. This paper studies how LLMs are seemingly able to reflect more liberal versus more conservative viewpoints among other political perspectives in American politics. We show that LLMs possess linear representations of political perspectives within activation space, wherein more similar perspectives are represented closer together. To do so, we probe the attention heads across the layers of three open transformer-based LLMs (\texttt{Llama-2-7b-chat}, \texttt{Mistral-7b-instruct}, \texttt{Vicuna-7b}). We first prompt models to generate text from the perspectives of different U.S.~lawmakers. We then identify sets of attention heads whose activations linearly predict those lawmakers' DW-NOMINATE scores, a widely-used and validated measure of political ideology. We find that highly predictive heads are primarily located in the middle layers, often speculated to encode high-level concepts and tasks. Using probes only trained to predict lawmakers' ideology, we then show that the same probes can predict measures of news outlets' slant from the activations of models prompted to simulate text from those news outlets. These linear probes allow us to visualize, interpret, and monitor ideological stances implicitly adopted by an LLM as it generates open-ended responses. Finally, we demonstrate that by applying linear interventions to these attention heads, we can steer the model outputs toward a more liberal or conservative stance. Overall, our research suggests that LLMs possess a high-level linear representation of American political ideology and that by leveraging recent advances in mechanistic interpretability, we can identify, monitor, and steer the subjective perspective underlying generated text. 

**Abstract (ZH)**: 大型语言模型（LLMs）能够生成反映不同主观人类视角的文本。本文研究了LLMs在反映美国政治中的自由派与保守派以及其他政治观点方面的差异。我们展示了LLMs在激活空间中线性表示不同的政治观点，其中更相似的观点被更接近地表示。为此，我们对三个开放的基于Transformer的LLMs（\texttt{Llama-2-7b-chat}、\texttt{Mistral-7b-instruct}、\texttt{Vicuna-7b}）的注意力头进行了探测。首先，我们提示模型从不同美国参议员的视角生成文本。然后，我们确定了一组注意力头的激活，这些激活线性预测参议员的DW-NOMINATE评分，这是一种广泛使用且验证过的政治意识形态衡量标准。我们发现，高度预测性的头主要位于中间层，这些层通常被认为编码高层次的概念和任务。利用仅训练用于预测参议员意识形态的探针，我们展示了相同的探针可以从模拟新闻机构文本的模型激活中预测新闻机构的倾向度。线性探针使我们能够可视化、解释并监控LLM在生成开放式响应时隐含持有的立场。最后，我们证明通过对这些注意力头应用线性干预，可以使模型输出更倾向于自由派或保守派。总体而言，我们的研究建议，LLMs拥有美国政治意识形态的高层次线性表示，并且通过利用机制可解释性的最新进展，我们能够识别、监控并引导生成文本所基于的主观视角。 

---
# Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation 

**Title (ZH)**: 超范围：放大内部特征表示以提高语言模型解释性 

**Authors**: Jonathan Jacobi, Gal Niv  

**Link**: [PDF](https://arxiv.org/pdf/2503.02078)  

**Abstract**: Understanding and interpreting the internal representations of large language models (LLMs) remains an open challenge. Patchscopes introduced a method for probing internal activations by patching them into new prompts, prompting models to self-explain their hidden representations. We introduce Superscopes, a technique that systematically amplifies superposed features in MLP outputs (multilayer perceptron) and hidden states before patching them into new contexts. Inspired by the "features as directions" perspective and the Classifier-Free Guidance (CFG) approach from diffusion models, Superscopes amplifies weak but meaningful features, enabling the interpretation of internal representations that previous methods failed to explain-all without requiring additional training. This approach provides new insights into how LLMs build context and represent complex concepts, further advancing mechanistic interpretability. 

**Abstract (ZH)**: 理解并解释大规模语言模型内部表示的方法仍是一个开放性的挑战。Superscopes：系统性增强MLP输出和隐藏状态中的叠加特征以促进解释 

---
# AI persuading AI vs AI persuading Humans: LLMs' Differential Effectiveness in Promoting Pro-Environmental Behavior 

**Title (ZH)**: AI说服AI vs AI说服人类：LLMs在促进环保行为方面的差异化效果 

**Authors**: Alexander Doudkin, Pat Pataranutaporn, Pattie Maes  

**Link**: [PDF](https://arxiv.org/pdf/2503.02067)  

**Abstract**: Pro-environmental behavior (PEB) is vital to combat climate change, yet turning awareness into intention and action remains elusive. We explore large language models (LLMs) as tools to promote PEB, comparing their impact across 3,200 participants: real humans (n=1,200), simulated humans based on actual participant data (n=1,200), and fully synthetic personas (n=1,200). All three participant groups faced personalized or standard chatbots, or static statements, employing four persuasion strategies (moral foundations, future self-continuity, action orientation, or "freestyle" chosen by the LLM). Results reveal a "synthetic persuasion paradox": synthetic and simulated agents significantly affect their post-intervention PEB stance, while human responses barely shift. Simulated participants better approximate human trends but still overestimate effects. This disconnect underscores LLM's potential for pre-evaluating PEB interventions but warns of its limits in predicting real-world behavior. We call for refined synthetic modeling and sustained and extended human trials to align conversational AI's promise with tangible sustainability outcomes. 

**Abstract (ZH)**: 大型语言模型促进环境友好行为的研究：真实人类、模拟人类和合成 persona 的比较 

---
# Survey Perspective: The Role of Explainable AI in Threat Intelligence 

**Title (ZH)**: 解释性人工智能在威胁情报中的作用调查视角 

**Authors**: Nidhi Rastogi, Devang Dhanuka, Amulya Saxena, Pranjal Mairal, Le Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2503.02065)  

**Abstract**: The increasing reliance on AI-based security tools in Security Operations Centers (SOCs) has transformed threat detection and response, yet analysts frequently struggle with alert overload, false positives, and lack of contextual relevance. The inability to effectively analyze AI-generated security alerts lead to inefficiencies in incident response and reduces trust in automated decision-making. In this paper, we show results and analysis of our investigation of how SOC analysts navigate AI-based alerts, their challenges with current security tools, and how explainability (XAI) integrated into their security workflows has the potential to become an effective decision support. In this vein, we conducted an industry survey. Using the survey responses, we analyze how security analysts' process, retrieve, and prioritize alerts. Our findings indicate that most analysts have not yet adopted XAI-integrated tools, but they express high interest in attack attribution, confidence scores, and feature contribution explanations to improve interpretability, and triage efficiency. Based on our findings, we also propose practical design recommendations for XAI-enhanced security alert systems, enabling AI-based cybersecurity solutions to be more transparent, interpretable, and actionable. 

**Abstract (ZH)**: 基于AI的安全工具在安全运营中心的应用日益增多：分析师面临的挑战及解释性人工智能的潜在价值分析 

---
# Hebbian learning the local structure of language 

**Title (ZH)**: 基于希布规则学习语言的局部结构 

**Authors**: P. Myles Eugenio  

**Link**: [PDF](https://arxiv.org/pdf/2503.02057)  

**Abstract**: Learning in the brain is local and unsupervised (Hebbian). We derive the foundations of an effective human language model inspired by these microscopic constraints. It has two parts: (1) a hierarchy of neurons which learns to tokenize words from text (whichiswhatyoudowhenyoureadthis); and (2) additional neurons which bind the learned symanticless patterns of the tokenizer into a symanticful token (an embedding). The model permits continuous parallel learning without forgetting; and is a powerful tokenizer which performs renormalization group. This allows it to exploit redundancy, such that it generates tokens which are always decomposable into a basis set (e.g an alphabet), and can mix features learned from multiple languages. We find that the structure of this model allows it to learn a natural language morphology WITHOUT data. The language data generated by this model predicts the correct distribution of word-forming patterns observed in real languages, and further demonstrates why microscopically human speech is broken up into words. This model provides the basis for understanding the microscopic origins of language and human creativity. 

**Abstract (ZH)**: 大脑中的学习是局部的和无监督的（基于海BI式原则）。我们以这些微观约束为基础推导出一种有效的机器语言模型。该模型有两部分组成：（1）层次结构的神经元，学习从文本中识别词（这正是你阅读时所做的）；（2）额外的神经元，将词识别器学习到的意义贫乏模式绑定成一个有意义的词（嵌入）。该模型允许持续并行学习而不会遗忘；并且是强大的词识别器，能够执行重整化组操作。这使得它能够利用冗余性，生成的词总是可以分解为基本集（例如字母表），并且可以从多种语言中混合学习到的特征进行组合。我们发现该模型的结构使其能够在没有数据的情况下学习自然语言形态学。该模型生成的语言数据预测了真实语言中词形模式的正确分布，并进一步展示了为什么人类语言在微观层面上被分解成词。该模型为基础了解语言和人类创造力的微观起源提供了基础。 

---
# FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation 

**Title (ZH)**: FRMD：快速机器人运动扩散与一致性提炼运动基元的平滑动作生成 

**Authors**: Xirui Shi, Jun Jin  

**Link**: [PDF](https://arxiv.org/pdf/2503.02048)  

**Abstract**: We consider the problem of using diffusion models to generate fast, smooth, and temporally consistent robot motions. Although diffusion models have demonstrated superior performance in robot learning due to their task scalability and multi-modal flexibility, they suffer from two fundamental limitations: (1) they often produce non-smooth, jerky motions due to their inability to capture temporally consistent movement dynamics, and (2) their iterative sampling process incurs prohibitive latency for many robotic tasks. Inspired by classic robot motion generation methods such as DMPs and ProMPs, which capture temporally and spatially consistent dynamic of trajectories using low-dimensional vectors -- and by recent advances in diffusion-based image generation that use consistency models with probability flow ODEs to accelerate the denoising process, we propose Fast Robot Motion Diffusion (FRMD). FRMD uniquely integrates Movement Primitives (MPs) with Consistency Models to enable efficient, single-step trajectory generation. By leveraging probabilistic flow ODEs and consistency distillation, our method models trajectory distributions while learning a compact, time-continuous motion representation within an encoder-decoder architecture. This unified approach eliminates the slow, multi-step denoising process of conventional diffusion models, enabling efficient one-step inference and smooth robot motion generation. We extensively evaluated our FRMD on the well-recognized Meta-World and ManiSkills Benchmarks, ranging from simple to more complex manipulation tasks, comparing its performance against state-of-the-art baselines. Our results show that FRMD generates significantly faster, smoother trajectories while achieving higher success rates. 

**Abstract (ZH)**: 使用快速机器人运动扩散模型生成快速、平滑且时间一致的机器人运动 

---
# Dynamic Search for Inference-Time Alignment in Diffusion Models 

**Title (ZH)**: 差分模型推断时动态搜索对齐方法 

**Authors**: Xiner Li, Masatoshi Uehara, Xingyu Su, Gabriele Scalia, Tommaso Biancalani, Aviv Regev, Sergey Levine, Shuiwang Ji  

**Link**: [PDF](https://arxiv.org/pdf/2503.02039)  

**Abstract**: Diffusion models have shown promising generative capabilities across diverse domains, yet aligning their outputs with desired reward functions remains a challenge, particularly in cases where reward functions are non-differentiable. Some gradient-free guidance methods have been developed, but they often struggle to achieve optimal inference-time alignment. In this work, we newly frame inference-time alignment in diffusion as a search problem and propose Dynamic Search for Diffusion (DSearch), which subsamples from denoising processes and approximates intermediate node rewards. It also dynamically adjusts beam width and tree expansion to efficiently explore high-reward generations. To refine intermediate decisions, DSearch incorporates adaptive scheduling based on noise levels and a lookahead heuristic function. We validate DSearch across multiple domains, including biological sequence design, molecular optimization, and image generation, demonstrating superior reward optimization compared to existing approaches. 

**Abstract (ZH)**: 在不同领域中，扩散模型展示了强大的生成能力，但在将模型输出与期望的奖励函数对齐时仍面临挑战，特别是在奖励函数非可微的情况下。一些无梯度引导方法已被开发，但它们在实现最佳推理时对齐方面往往表现不佳。在本文中，我们将扩散模型的推理时对齐重新定义为一个搜索问题，并提出了Dynamic Search for Diffusion (DSearch)，该方法从去噪过程中抽样并近似中间节点奖励。此外，DSearch动态调整搜索宽度和树扩展，以高效探索高奖励生成。为了细化中间决策，DSearch结合了基于噪声水平的自适应调度和前瞻启发式函数。我们在生物序列设计、分子优化和图像生成等多个领域对DSearch进行了验证，展示了与现有方法相比的优越奖励优化效果。 

---
# Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA 

**Title (ZH)**: Abn-BLIP: 与异常对齐的引导语言-图像预训练在CTPA肺栓塞诊断与报告生成中的应用 

**Authors**: Zhusi Zhong, Yuli Wang, Lulu Bi, Zhuoqi Ma, Sun Ho Ahn, Christopher J. Mullin, Colin F. Greineder, Michael K. Atalay, Scott Collins, Grayson L. Baird, Cheng Ting Lin, Webster Stayman, Todd M. Kolb, Ihab Kamel, Harrison X. Bai, Zhicheng Jiao  

**Link**: [PDF](https://arxiv.org/pdf/2503.02034)  

**Abstract**: Medical imaging plays a pivotal role in modern healthcare, with computed tomography pulmonary angiography (CTPA) being a critical tool for diagnosing pulmonary embolism and other thoracic conditions. However, the complexity of interpreting CTPA scans and generating accurate radiology reports remains a significant challenge. This paper introduces Abn-BLIP (Abnormality-aligned Bootstrapping Language-Image Pretraining), an advanced diagnosis model designed to align abnormal findings to generate the accuracy and comprehensiveness of radiology reports. By leveraging learnable queries and cross-modal attention mechanisms, our model demonstrates superior performance in detecting abnormalities, reducing missed findings, and generating structured reports compared to existing methods. Our experiments show that Abn-BLIP outperforms state-of-the-art medical vision-language models and 3D report generation methods in both accuracy and clinical relevance. These results highlight the potential of integrating multimodal learning strategies for improving radiology reporting. The source code is available at this https URL. 

**Abstract (ZH)**: 医学影像在现代医疗保健中扮演着关键角色，计算机断层扫描肺动脉造影（CTPA）是诊断肺栓塞和其他胸腔疾病的重要工具。然而，CTPA扫描的解释复杂性和生成准确的放射学报告仍是一项重大挑战。本文介绍了一种先进的诊断模型Abn-BLIP（异常对齐的自举语言-图像预训练），该模型旨在将异常发现对齐以生成放射学报告的准确性和全面性。通过利用可学习的查询和跨模态注意力机制，我们的模型在检测异常、减少遗漏发现以及生成结构化报告方面表现出色，优于现有方法。实验结果表明，Abn-BLIP在准确性和临床相关性方面均优于最先进的医疗视觉-语言模型和3D报告生成方法。这些结果突显了结合多模态学习策略以提高放射学报告的质量的潜力。源代码可在以下链接获取。 

---
# Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering 

**Title (ZH)**: OpenAI GPT-4o与DeepSeek R1在科学文本分类中的Prompt工程比较分析 

**Authors**: Aniruddha Maiti, Samuel Adewumi, Temesgen Alemayehu Tikure, Zichun Wang, Niladri Sengupta, Anastasiia Sukhanova, Ananya Jana  

**Link**: [PDF](https://arxiv.org/pdf/2503.02032)  

**Abstract**: This study examines how large language models categorize sentences from scientific papers using prompt engineering. We use two advanced web-based models, GPT-4o (by OpenAI) and DeepSeek R1, to classify sentences into predefined relationship categories. DeepSeek R1 has been tested on benchmark datasets in its technical report. However, its performance in scientific text categorization remains unexplored. To address this gap, we introduce a new evaluation method designed specifically for this task. We also compile a dataset of cleaned scientific papers from diverse domains. This dataset provides a platform for comparing the two models. Using this dataset, we analyze their effectiveness and consistency in categorization. 

**Abstract (ZH)**: 本研究使用提示工程方法探讨大规模语言模型如何对科学论文中的句子进行分类，并使用两个先进的基于Web模型GPT-4o（由OpenAI提供）和DeepSeek R1对句子进行预定义关系类别的分类。DeepSeek R1在其技术报告中已在基准数据集上进行了测试，但在科学文本分类方面的性能尚待探索。为了填补这一空白，我们引入了一种专门为该任务设计的新评估方法，并汇集了一组来自多个领域的清理后的科学论文数据集，为两个模型提供了一个比较平台。使用该数据集，我们分析了它们在分类上的有效性与一致性。 

---
# Mind the (Belief) Gap: Group Identity in the World of LLMs 

**Title (ZH)**: 注意（信念）差距：大规模语言模型 worlds 中的群体身份 

**Authors**: Angana Borah, Marwa Houalla, Rada Mihalcea  

**Link**: [PDF](https://arxiv.org/pdf/2503.02016)  

**Abstract**: Social biases and belief-driven behaviors can significantly impact Large Language Models (LLMs) decisions on several tasks. As LLMs are increasingly used in multi-agent systems for societal simulations, their ability to model fundamental group psychological characteristics remains critical yet under-explored. In this study, we present a multi-agent framework that simulates belief congruence, a classical group psychology theory that plays a crucial role in shaping societal interactions and preferences. Our findings reveal that LLMs exhibit amplified belief congruence compared to humans, across diverse contexts. We further investigate the implications of this behavior on two downstream tasks: (1) misinformation dissemination and (2) LLM learning, finding that belief congruence in LLMs increases misinformation dissemination and impedes learning. To mitigate these negative impacts, we propose strategies inspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global citizenship framework. Our results show that the best strategies reduce misinformation dissemination by up to 37% and enhance learning by 11%. Bridging social psychology and AI, our work provides insights to navigate real-world interactions using LLMs while addressing belief-driven biases. 

**Abstract (ZH)**: 社会偏见和信念驱动的行为会显著影响大型语言模型（LLMs）在多种任务上的决策。随着LLMs在多Agent系统中的社会模拟中应用日益广泛，它们建模基本群体心理特征的能力仍具有关键性但尚未充分探索。在本研究中，我们提出了一种多Agent框架，模拟信念一致性，这一经典群体心理学理论在塑造社会互动和偏好方面发挥着重要作用。我们的研究发现，无论是在哪种背景下，LLMs的信念一致性都比人类更为放大。我们进一步探究了这种行为对两个下游任务的影响：（1）错误信息传播和（2）LLMs学习。研究发现，LLMs中的信念一致性会增加错误信息传播并阻碍学习。为减轻这些负面影响，我们提出了一些策略：（1）接触假说，（2）准确度提示，以及（3）全球公民框架。我们的结果显示，最优策略可将错误信息传播减少多达37%，并增强学习11%。结合社会心理学与人工智能，我们的研究为利用LLMs导航现实世界互动并解决信念驱动的偏见提供了见解。 

---
# TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication 

**Title (ZH)**: TactStyle：使用生成式人工智能生成触觉纹理以应用于数字 fabrication 

**Authors**: Faraz Faruqi, Maxine Perroni-Scharf, Jaskaran Singh Walia, Yunyi Zhu, Shuyue Feng, Donald Degraen, Stefanie Mueller  

**Link**: [PDF](https://arxiv.org/pdf/2503.02007)  

**Abstract**: Recent work in Generative AI enables the stylization of 3D models based on image prompts. However, these methods do not incorporate tactile information, leading to designs that lack the expected tactile properties. We present TactStyle, a system that allows creators to stylize 3D models with images while incorporating the expected tactile properties. TactStyle accomplishes this using a modified image-generation model fine-tuned to generate heightfields for given surface textures. By optimizing 3D model surfaces to embody a generated texture, TactStyle creates models that match the desired style and replicate the tactile experience. We utilize a large-scale dataset of textures to train our texture generation model. In a psychophysical experiment, we evaluate the tactile qualities of a set of 3D-printed original textures and TactStyle's generated textures. Our results show that TactStyle successfully generates a wide range of tactile features from a single image input, enabling a novel approach to haptic design. 

**Abstract (ZH)**: 基于图像提示的生成AI Recent Work使3D模型的风格化成为可能，但这些方法没有纳入触觉信息，导致设计缺乏预期的触觉特性。我们提出了TactStyle系统，该系统允许创作人员在使用图像风格化3D模型的同时，纳入预期的触觉特性。TactStyle通过调整 fine-tuned 以生成给定表面纹理的高度场的图像生成模型来实现这一点。通过优化3D模型表面以体现生成的纹理，TactStyle 创建了符合期望样式且复制触觉体验的模型。我们利用大规模纹理数据集来训练我们的纹理生成模型。在一项心理物理实验中，我们评估了一组3D打印原始纹理和TactStyle生成纹理的触觉质量。结果显示，TactStyle 成功地从单个图像输入生成了广泛的触觉特性，提供了一种新颖的触觉设计方法。 

---
# Adaptively evaluating models with task elicitation 

**Title (ZH)**: 自适应地通过任务引出评估模型 

**Authors**: Davis Brown, Prithvi Balehannina, Helen Jin, Shreya Havaldar, Hamed Hassani, Eric Wong  

**Link**: [PDF](https://arxiv.org/pdf/2503.01986)  

**Abstract**: Manual curation of evaluation datasets is struggling to keep up with the rapidly expanding capabilities and deployment scenarios of language models. Towards scalable model profiling, we introduce and validate a framework for evaluating LLMs, called Adaptive Evaluations. Adaptive evaluations use scaffolded language models (evaluator agents) to search through a target model's behavior on a domain dataset and create difficult questions (tasks) that can discover and probe the model's failure modes. We find that frontier models lack consistency when adaptively probed with our framework on a diverse suite of datasets and tasks, including but not limited to legal reasoning, forecasting, and online harassment. Generated questions pass human validity checks and often transfer to other models with different capability profiles, demonstrating that adaptive evaluations can also be used to create difficult domain-specific datasets. 

**Abstract (ZH)**: 手动构建评估数据集难以跟上语言模型快速扩展的能力和应用场景。为实现可扩展的模型 profiling，我们引入并验证了一个评估大语言模型的框架，称为自适应评估。自适应评估利用梯度语言模型（评估代理）在领域数据集上搜索目标模型的行为，并生成能够发现和探究模型失效模式的复杂问题（任务）。我们发现，前沿模型在我们的框架上对多样化的数据集和任务进行自适应探究时缺乏一致性，涉及但不限于法律推理、预测和在线骚扰等领域。生成的问题通过了人类有效性检查，并且往往能够迁移到具有不同能力轮廓的其他模型，这表明自适应评估也可用于创建特定领域的复杂数据集。 

---
# Proportionality in Thumbs Up and Down Voting 

**Title (ZH)**: 拇指点赞与反对投票的比例性 

**Authors**: Sonja Kraiczy, Georgios Papasotiropoulos, Grzegorz Pierczyński, Piotr Skowron  

**Link**: [PDF](https://arxiv.org/pdf/2503.01985)  

**Abstract**: Consider the decision-making setting where agents elect a panel by expressing both positive and negative preferences. Prominently, in constitutional AI, citizens democratically select a slate of ethical preferences on which a foundation model is to be trained. There, in practice, agents may both approve and disapprove of different ethical principles. Proportionality has been well-studied in computational social choice for approval ballots, but its meaning remains unclear when negative sentiments are also considered. In this work, we propose two conceptually distinct approaches to interpret proportionality in the presence of up and down votes. The first approach treats the satisfaction from electing candidates and the impact of vetoing them as comparable, leading to combined proportionality guarantees. The second approach considers veto power separately, introducing guarantees distinct from traditional proportionality. We formalize axioms for each perspective and examine their satisfiability by suitable adaptations of Phragmén's rule, Proportional Approval Voting rule and the Method of Equal Shares. 

**Abstract (ZH)**: 考虑代理通过表达正负偏好来选举委员会的决策设置。在宪法AI中，公民民主地选择一组伦理偏好，作为基础模型的训练依据。在此实践中，代理可能既批准又反对不同的伦理原则。对于有赞同和反对票的批准票，相同比例性在计算社会选择中已被广泛研究，但当也考虑负面情感时，其含义仍然不清楚。在本文中，我们提出了两种概念上不同的方法来解释在有赞成和反对票情况下相同比例性的含义。第一种方法将选举候选人的满意度与其否决投票的影响视为可比的，从而提供综合比例性保证。第二种方法单独考虑否决权，引入不同于传统比例性的保证。我们为每种视角形式化了公理，并通过Phragmén规则、比例性批准投票规则和均等份额方法的适当改编来检查它们的可满足性。 

---
# Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval 

**Title (ZH)**: 增强循环机制的视觉-语言变换器for稳健的多模态文档检索 

**Authors**: Davide Caffagni, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara  

**Link**: [PDF](https://arxiv.org/pdf/2503.01980)  

**Abstract**: Cross-modal retrieval is gaining increasing efficacy and interest from the research community, thanks to large-scale training, novel architectural and learning designs, and its application in LLMs and multimodal LLMs. In this paper, we move a step forward and design an approach that allows for multimodal queries, composed of both an image and a text, and can search within collections of multimodal documents, where images and text are interleaved. Our model, ReT, employs multi-level representations extracted from different layers of both visual and textual backbones, both at the query and document side. To allow for multi-level and cross-modal understanding and feature extraction, ReT employs a novel Transformer-based recurrent cell that integrates both textual and visual features at different layers, and leverages sigmoidal gates inspired by the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR benchmarks show that ReT achieves state-of-the-art performance across diverse settings. Our source code and trained models are publicly available at this https URL. 

**Abstract (ZH)**: 跨模态检索随着大规模训练、新颖的架构和学习设计的进步，以及在大型语言模型和多模态大型语言模型中的应用，正日益显示出其有效性并引起了研究社区的兴趣。本文在此基础上提出了一种方法，该方法能够处理由图像和文本组成的多模态查询，并能在图像和文本交织的多模态文档集合中进行搜索。我们的模型ReT利用来自视觉和文本骨干网络不同层的多级表示，应用于查询和文档两侧。为实现多层次和跨模态的理解和特征提取，ReT采用了一种新颖的基于Transformer的递归单元，该单元在不同层中整合了文本和视觉特征，并借鉴了经典LSTM设计中的sigmoid门控机制。在M2KR和M-BEIR基准上的广泛实验表明，ReT在各种设置中均实现了最先进的性能。我们的源代码和训练模型已公开在此URL：this https URL。 

---
# Mathematical Foundation of Interpretable Equivariant Surrogate Models 

**Title (ZH)**: 可解释等变替代模型的数学基础 

**Authors**: Jacopo Joy Colombini, Filippo Bonchi, Francesco Giannini, Fosca Giannotti, Roberto Pellungrini, Patrizio Frosini  

**Link**: [PDF](https://arxiv.org/pdf/2503.01942)  

**Abstract**: This paper introduces a rigorous mathematical framework for neural network explainability, and more broadly for the explainability of equivariant operators called Group Equivariant Operators (GEOs) based on Group Equivariant Non-Expansive Operators (GENEOs) transformations. The central concept involves quantifying the distance between GEOs by measuring the non-commutativity of specific diagrams. Additionally, the paper proposes a definition of interpretability of GEOs according to a complexity measure that can be defined according to each user preferences. Moreover, we explore the formal properties of this framework and show how it can be applied in classical machine learning scenarios, like image classification with convolutional neural networks. 

**Abstract (ZH)**: 基于Group Equivariant Non-Expansive Operators（GENEOs）变换的Group Equivariant Operators（GEOs）可解释性严格数学框架研究 

---
# Task Scheduling & Forgetting in Multi-Task Reinforcement Learning 

**Title (ZH)**: 多任务强化学习中的任务调度与遗忘 

**Authors**: Marc Speckmann, Theresa Eimer  

**Link**: [PDF](https://arxiv.org/pdf/2503.01941)  

**Abstract**: Reinforcement learning (RL) agents can forget tasks they have previously been trained on. There is a rich body of work on such forgetting effects in humans. Therefore we look for commonalities in the forgetting behavior of humans and RL agents across tasks and test the viability of forgetting prevention measures from learning theory in RL. We find that in many cases, RL agents exhibit forgetting curves similar to those of humans. Methods like Leitner or SuperMemo have been shown to be effective at counteracting human forgetting, but we demonstrate they do not transfer as well to RL. We identify a likely cause: asymmetrical learning and retention patterns between tasks that cannot be captured by retention-based or performance-based curriculum strategies. 

**Abstract (ZH)**: 强化学习代理可能会忘记之前训练的任务。人类在任务中的遗忘效应已有丰富的研究。因此，我们在不同任务中寻找人类和强化学习代理遗忘行为的共同点，并测试学习理论中的遗忘预防措施在强化学习中的有效性。我们发现，在许多情况下，强化学习代理的遗忘曲线与人类相似。Leitner或SuperMemo等方法已被证明对人类遗忘有有效的对抗作用，但我们表明这些方法在转移到强化学习中并不如预期有效。我们确定了可能的原因：任务之间不对称的学习和保持模式，这些模式不能被基于保持或基于性能的课程策略捕获。 

---
# AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification 

**Title (ZH)**: AskToAct: 通过自我修正澄清提升LLMs工具使用能力 

**Authors**: Xuan Zhang, Yongliang Shen, Zhe Zheng, Linjuan Wu, Wenqi Zhang, Yuchen Yan, Qiuying Peng, Jun Wang, Weiming Lu  

**Link**: [PDF](https://arxiv.org/pdf/2503.01940)  

**Abstract**: Large language models (LLMs) have demonstrated remarkable capabilities in tool learning. In real-world scenarios, user queries are often ambiguous and incomplete, requiring effective clarification. However, existing interactive clarification approaches face two critical limitations: reliance on manually constructed datasets and lack of error correction mechanisms during multi-turn clarification. We present AskToAct, which addresses these challenges by exploiting the structural mapping between queries and their tool invocation solutions. Our key insight is that tool parameters naturally represent explicit user intents. By systematically removing key parameters from queries while retaining them as ground truth, we enable automated construction of high-quality training data. We further enhance model robustness by fine-tuning on error-correction augmented data using selective masking mechanism, enabling dynamic error detection during clarification interactions. Comprehensive experiments demonstrate that AskToAct significantly outperforms existing approaches, achieving above 79% accuracy in recovering critical unspecified intents and enhancing clarification efficiency by an average of 48.34% while maintaining high accuracy in tool invocation. Our framework exhibits robust performance across varying complexity levels and successfully generalizes to entirely unseen APIs without additional training, achieving performance comparable to GPT-4 with substantially fewer computational resources. 

**Abstract (ZH)**: AskToAct：通过查询与工具调用解决方案的结构映射实现有效的澄清 

---
# Synthetic Tabular Data Detection In the Wild 

**Title (ZH)**: 合成表格数据的野生环境检测 

**Authors**: G. Charbel N. Kindji, Elisa Fromont, Lina Maria Rojas-Barahona, Tanguy Urvoy  

**Link**: [PDF](https://arxiv.org/pdf/2503.01937)  

**Abstract**: Detecting synthetic tabular data is essential to prevent the distribution of false or manipulated datasets that could compromise data-driven decision-making. This study explores whether synthetic tabular data can be reliably identified across different tables. This challenge is unique to tabular data, where structures (such as number of columns, data types, and formats) can vary widely from one table to another. We propose four table-agnostic detectors combined with simple preprocessing schemes that we evaluate on six evaluation protocols, with different levels of ''wildness''. Our results show that cross-table learning on a restricted set of tables is possible even with naive preprocessing schemes. They confirm however that cross-table transfer (i.e. deployment on a table that has not been seen before) is challenging. This suggests that sophisticated encoding schemes are required to handle this problem. 

**Abstract (ZH)**: 检测合成表格数据对于防止分发虚假或操纵的数据集、确保数据驱动决策的安全至关重要。本研究探讨了合成表格数据是否能在不同表格间可靠地被识别。这一挑战性问题特别适用于表格数据，因为各张表格的结构（如列数、数据类型和格式）差异很大。我们提出了一种结合简单预处理方案的四款跨表通用检测器，并在六个不同“野度”的评估协议上进行了评估。结果显示，即使使用简单的预处理方案，对有限几张表格的跨表学习也是可行的。然而，这些结果也证实了跨表迁移（即在未见过的表格上部署）的挑战性。这表明，为了解决这一问题，需要采用复杂的编码方案。 

---
# Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization 

**Title (ZH)**: 基于决策的时间序列基础模型可调度配电线优化的微调方法 

**Authors**: Maximilian Beichter, Nils Friederich, Janik Pinter, Dorina Werling, Kaleb Phipps, Sebastian Beichter, Oliver Neumann, Ralf Mikut, Veit Hagenmeyer, Benedikt Heidrich  

**Link**: [PDF](https://arxiv.org/pdf/2503.01936)  

**Abstract**: Time series foundation models provide a universal solution for generating forecasts to support optimization problems in energy systems. Those foundation models are typically trained in a prediction-focused manner to maximize forecast quality. In contrast, decision-focused learning directly improves the resulting value of the forecast in downstream optimization rather than merely maximizing forecasting quality. The practical integration of forecast values into forecasting models is challenging, particularly when addressing complex applications with diverse instances, such as buildings. This becomes even more complicated when instances possess specific characteristics that require instance-specific, tailored predictions to increase the forecast value. To tackle this challenge, we use decision-focused fine-tuning within time series foundation models to offer a scalable and efficient solution for decision-focused learning applied to the dispatchable feeder optimization problem. To obtain more robust predictions for scarce building data, we use Moirai as a state-of-the-art foundation model, which offers robust and generalized results with few-shot parameter-efficient fine-tuning. Comparing the decision-focused fine-tuned Moirai with a state-of-the-art classical prediction-focused fine-tuning Morai, we observe an improvement of 9.45% in average total daily costs. 

**Abstract (ZH)**: 时间序列基础模型为能源系统中的优化问题提供了一种通用的预测解决方案。与预测导向的学习相比，决策导向的学习直接通过改进预测值在下游优化中的结果来提高决策质量，而不是仅追求最佳预测质量。将预测值集成到预测模型中以满足复杂且多样化应用的需求（如建筑物）具有挑战性。当实例具有特定特征需要实例特定的预测以提高预测值时，这一挑战更为复杂。为解决这一挑战，我们利用时间序列基础模型中的决策导向微调来提供一种可扩展且高效的解决方案，应用于调度支路优化问题的决策导向学习。为了获得更 robust 的预测结果，我们使用 Moirai 作为最先进的基础模型，该模型通过少量样本高效的参数微调提供 robust 和通用的结果。在平均总日成本方面，与最先进的经典预测导向微调模型 Morai 相比，决策导向微调的 Moirai 显示出 9.45% 的改进。 

---
# MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents 

**Title (ZH)**: 多智能体基准：评估LLM代理的协作与竞争 

**Authors**: Kunlun Zhu, Hongyi Du, Zhaochen Hong, Xiaocheng Yang, Shuyi Guo, Zhe Wang, Zhenhailong Wang, Cheng Qian, Xiangru Tang, Heng Ji, Jiaxuan You  

**Link**: [PDF](https://arxiv.org/pdf/2503.01935)  

**Abstract**: Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios. Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators. Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning. Notably, gpt-4o-mini reaches the average highest task score, graph structure performs the best among coordination protocols in the research scenario, and cognitive planning improves milestone achievement rates by 3%. Code and datasets are public available at this https URL. 

**Abstract (ZH)**: 大型语言模型(LLMs)在自主代理方面展示了卓越的能力，但现有基准要么专注于单代理任务，要么局限于狭窄领域，无法捕捉多代理协调和竞争的动力学。在本文中，我们引入了MultiAgentBench，这是一个全面的基准，用于评估基于LLM的多代理系统在多样的交互场景中的表现。我们的框架不仅衡量任务完成情况，还通过新的里程碑式关键绩效指标来评估合作与竞争的质量。此外，我们评估了多种协调协议（包括星型、链型、树型和图型拓扑结构）以及分组讨论和认知规划等创新策略。值得注意的是，gpt-4o-mini达到了平均最高任务得分，研究场景中图结构在协调协议中表现最佳，认知规划将里程碑成就率提高了3%。代码和数据集可在以下网址获取。 

---
# Adversarial Generative Flow Network for Solving Vehicle Routing Problems 

**Title (ZH)**: 对抗生成流网络解决车辆路线问题 

**Authors**: Ni Zhang, Jingfeng Yang, Zhiguang Cao, Xu Chi  

**Link**: [PDF](https://arxiv.org/pdf/2503.01931)  

**Abstract**: Recent research into solving vehicle routing problems (VRPs) has gained significant traction, particularly through the application of deep (reinforcement) learning for end-to-end solution construction. However, many current construction-based neural solvers predominantly utilize Transformer architectures, which can face scalability challenges and struggle to produce diverse solutions. To address these limitations, we introduce a novel framework beyond Transformer-based approaches, i.e., Adversarial Generative Flow Networks (AGFN). This framework integrates the generative flow network (GFlowNet)-a probabilistic model inherently adept at generating diverse solutions (routes)-with a complementary model for discriminating (or evaluating) the solutions. These models are trained alternately in an adversarial manner to improve the overall solution quality, followed by a proposed hybrid decoding method to construct the solution. We apply the AGFN framework to solve the capacitated vehicle routing problem (CVRP) and travelling salesman problem (TSP), and our experimental results demonstrate that AGFN surpasses the popular construction-based neural solvers, showcasing strong generalization capabilities on synthetic and real-world benchmark instances. 

**Abstract (ZH)**: 基于对抗生成流网络的车辆路由问题求解研究 

---
# QCS-ADME: Quantum Circuit Search for Drug Property Prediction with Imbalanced Data and Regression Adaptation 

**Title (ZH)**: QCS-ADME：量子电路搜索在不均衡数据和回归适应下的药物性质预测 

**Authors**: Kangyu Zheng, Tianfan Fu, Zhiding Liang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01927)  

**Abstract**: The biomedical field is beginning to explore the use of quantum machine learning (QML) for tasks traditionally handled by classical machine learning, especially in predicting ADME (absorption, distribution, metabolism, and excretion) properties, which are essential in drug evaluation. However, ADME tasks pose unique challenges for existing quantum computing systems (QCS) frameworks, as they involve both classification with unbalanced dataset and regression problems. These dual requirements make it necessary to adapt and refine current QCS frameworks to effectively address the complexities of ADME predictions. We propose a novel training-free scoring mechanism to evaluate QML circuit performance on imbalanced classification and regression tasks. Our mechanism demonstrates significant correlation between scoring metrics and test performance on imbalanced classification tasks. Additionally, we develop methods to quantify continuous similarity relationships between quantum states, enabling performance prediction for regression tasks. This represents the first comprehensive approach to searching and evaluating QCS circuits specifically for regression applications. Validation on representative ADME tasks-one imbalanced classification and one regression-demonstrates moderate positive correlation between our scoring metrics and circuit performance, significantly outperforming baseline scoring methods that show negligible correlation. 

**Abstract (ZH)**: 生物医药领域开始探索使用量子机器学习（QML）来处理传统由经典机器学习处理的任务，特别是在预测ADME（吸收、分布、代谢、排泄）属性方面，这些属性对于药物评价至关重要。然而，ADME任务为现有的量子计算系统框架带来了独特的挑战，因为它们同时涉及不平衡数据集的分类问题和回归问题。这些双重要求使得适应和改进现有的量子计算系统框架变得必要，以有效应对ADME预测的复杂性。我们提出了一种新的无需训练的评分机制，用于评估QML电路在不平衡分类和回归任务中的性能。我们的机制在不平衡分类任务中显示了评分指标与测试性能之间显著的相关性。此外，我们开发了量化量子态之间连续相似关系的方法，从而能够预测回归任务的性能。这代表了第一个专门针对回归应用搜索和评估量子计算系统电路的全面方法。代表性的ADME任务（一个不平衡分类和一个回归任务）的验证显示，我们的评分指标与电路性能之间存在适度的正相关，显著优于基准评分方法，后者显示几乎不存在相关性。 

---
# Unnatural Languages Are Not Bugs but Features for LLMs 

**Title (ZH)**: unnatural languages are not bugs but features for LLMs 不是bug而是功能： unnatural语言不是_bug而是特征_for 大型语言模型 

**Authors**: Keyu Duan, Yiran Zhao, Zhili Feng, Jinjie Ni, Tianyu Pang, Qian Liu, Tianle Cai, Longxu Dou, Kenji Kawaguchi, Anirudh Goyal, J. Zico Kolter, Michael Qizhe Shieh  

**Link**: [PDF](https://arxiv.org/pdf/2503.01926)  

**Abstract**: Large Language Models (LLMs) have been observed to process non-human-readable text sequences, such as jailbreak prompts, often viewed as a bug for aligned LLMs. In this work, we present a systematic investigation challenging this perception, demonstrating that unnatural languages - strings that appear incomprehensible to humans but maintain semantic meanings for LLMs - contain latent features usable by models. Notably, unnatural languages possess latent features that can be generalized across different models and tasks during inference. Furthermore, models fine-tuned on unnatural versions of instruction datasets perform on-par with those trained on natural language, achieving 49.71 win rates in Length-controlled AlpacaEval 2.0 in average across various base models. In addition, through comprehensive analysis, we demonstrate that LLMs process unnatural languages by filtering noise and inferring contextual meaning from filtered words. 

**Abstract (ZH)**: 大型语言模型（LLMs）被观察到处理非人类可读的文本序列，如 Jailbreak 提示，这些常常被视为对齐 LLM 的一个bug。在本文中，我们系统地探讨了这一观点，证明了非自然语言——对人类看似不可理解但对LLMs保持语义意义的字符串——包含了可用于模型的潜在特征。值得注意的是，非自然语言包含的潜在特征可以在不同的模型和任务推断过程中泛化。此外，使用非自然语言版本的指令数据集 fine-tuned 的模型在各种基础模型中表现出色，平均在 Length-controlled AlpacaEval 2.0 中取得了49.71%的胜率，与使用自然语言训练的模型表现相当。通过全面分析，我们还证明了LLMs处理非自然语言通过过滤噪声并从筛选出的词中推断上下文意义。 

---
# TAET: Two-Stage Adversarial Equalization Training on Long-Tailed Distributions 

**Title (ZH)**: TAET：两阶段对抗均衡训练在长尾分布上的应用 

**Authors**: Wang YuHang, Junkang Guo, Aolei Liu, Kaihao Wang, Zaitong Wu, Zhenyu Liu, Wenfei Yin, Jian Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.01924)  

**Abstract**: Adversarial robustness is a critical challenge in deploying deep neural networks for real-world applications. While adversarial training is a widely recognized defense strategy, most existing studies focus on balanced datasets, overlooking the prevalence of long-tailed distributions in real-world data, which significantly complicates robustness. This paper provides a comprehensive analysis of adversarial training under long-tailed distributions and identifies limitations in the current state-of-the-art method, AT-BSL, in achieving robust performance under such conditions. To address these challenges, we propose a novel training framework, TAET, which integrates an initial stabilization phase followed by a stratified equalization adversarial training phase. Additionally, prior work on long-tailed robustness has largely ignored the crucial evaluation metric of balanced accuracy. To bridge this gap, we introduce the concept of balanced robustness, a comprehensive metric tailored for assessing robustness under long-tailed distributions. Extensive experiments demonstrate that our method surpasses existing advanced defenses, achieving significant improvements in both memory and computational efficiency. This work represents a substantial advancement in addressing robustness challenges in real-world applications. Our code is available at: this https URL. 

**Abstract (ZH)**: adversarial稳健性是将深度神经网络应用于实际应用中的一个关键挑战。虽然已有研究表明对抗训练是一种广为人知的防御策略，但大多数现有研究集中在均衡数据集上，忽视了实际数据中长尾分布的普遍性，这极大地增加了稳健性的复杂性。本文对长尾分布下的对抗训练进行了全面分析，并指出现有最先进的方法AT-BSL在实现此类条件下的稳健性能时存在局限性。为应对这些挑战，我们提出了一种新颖的训练框架TAET，该框架包括一个初始稳定阶段，随后是分层等化对抗训练阶段。此外，关于长尾稳健性的现有研究很大程度上忽略了平衡准确率这一关键评估指标。为弥补这一不足，我们引入了平衡稳健性的概念，这是一种专门用于评估长尾分布下稳健性的综合指标。广泛的实验表明，我们的方法在内存和计算效率上均显著优于现有先进的防御方法。这项工作代表了在实际应用中解决稳健性挑战的一个重要进展。我们的代码可在以下链接获取：this https URL。 

---
# Output Length Effect on DeepSeek-R1's Safety in Forced Thinking 

**Title (ZH)**: DeepSeek-R1在强迫思考中输出长度对其安全性的影响 

**Authors**: Xuying Li, Zhuo Li, Yuji Kosuga, Victor Bian  

**Link**: [PDF](https://arxiv.org/pdf/2503.01923)  

**Abstract**: Large Language Models (LLMs) have demonstrated strong reasoning capabilities, but their safety under adversarial conditions remains a challenge. This study examines the impact of output length on the robustness of DeepSeek-R1, particularly in Forced Thinking scenarios. We analyze responses across various adversarial prompts and find that while longer outputs can improve safety through self-correction, certain attack types exploit extended generations. Our findings suggest that output length should be dynamically controlled to balance reasoning effectiveness and security. We propose reinforcement learning-based policy adjustments and adaptive token length regulation to enhance LLM safety. 

**Abstract (ZH)**: 大型语言模型（LLMs）显示出强大的推理能力，但在对抗条件下安全性依然面临挑战。本研究探讨了输出长度对DeepSeek-R1稳健性的影响，特别是在强制思考场景中的影响。我们分析了各种对抗性提示下的响应，发现虽然较长的输出可以通过自我纠正提高安全性，但某些攻击类型会利用扩展生成。研究结果表明，输出长度应动态控制以平衡推理效果和安全性。我们提出了基于强化学习的策略调整和自适应token长度调节以增强LLM的安全性。 

---
# NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT 

**Title (ZH)**: NCL-UoR参加SemEval-2025任务3：利用修改后的RefChecker和修改后的SelfCheckGPT检测多语言幻觉及相关可观察的过度生成文本片段 

**Authors**: Jiaying Hong, Thanet Markchom, Jianfei Xu, Tong Wu, Huizhi Liang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01921)  

**Abstract**: SemEval-2025 Task 3 (Mu-SHROOM) focuses on detecting hallucinations in content generated by various large language models (LLMs) across multiple languages. This task involves not only identifying the presence of hallucinations but also pinpointing their specific occurrences. To tackle this challenge, this study introduces two methods: modified RefChecker and modified SelfCheckGPT. The modified RefChecker integrates prompt-based factual verification into References, structuring them as claim-based tests rather than single external knowledge sources. The modified SelfCheckGPT incorporates external knowledge to overcome its reliance on internal knowledge. In addition, both methods' original prompt designs are enhanced to identify hallucinated words within LLM-generated texts. Experimental results demonstrate the effectiveness of the approach, achieving a high ranking on the test dataset in detecting hallucinations across various languages, with an average IoU of 0.5310 and an average COR of 0.5669. 

**Abstract (ZH)**: SemEval-2025 任务3 (Mu-SHROOM) 专注于检测各种大型语言模型（LLMs）生成的内容中的幻觉，覆盖多种语言。该任务不仅涉及识别幻觉的存在，还涉及具体定位其发生。为应对这一挑战，本研究介绍了两种方法：修改后的 RefChecker 和修改后的 SelfCheckGPT。修改后的 RefChecker 将基于提示的事实验证集成到 References 中，将其结构化为基于断言的测试，而非单一的外部知识来源。修改后的 SelfCheckGPT 结合外部知识以克服其对内部知识的依赖。此外，两种方法的原始提示设计也得到了增强，以识别 LLM 生成文本中的幻觉词。实验结果表明该方法的有效性，在检测多种语言中的幻觉时在测试数据集中取得了高排名，平均 IoU 为 0.5310，平均 COR 为 0.5669。 

---
# Reinforcement learning with combinatorial actions for coupled restless bandits 

**Title (ZH)**: 组合动作强化学习在耦合不安定bandits中的应用 

**Authors**: Lily Xu, Bryan Wilder, Elias B. Khalil, Milind Tambe  

**Link**: [PDF](https://arxiv.org/pdf/2503.01919)  

**Abstract**: Reinforcement learning (RL) has increasingly been applied to solve real-world planning problems, with progress in handling large state spaces and time horizons. However, a key bottleneck in many domains is that RL methods cannot accommodate large, combinatorially structured action spaces. In such settings, even representing the set of feasible actions at a single step may require a complex discrete optimization formulation. We leverage recent advances in embedding trained neural networks into optimization problems to propose SEQUOIA, an RL algorithm that directly optimizes for long-term reward over the feasible action space. Our approach embeds a Q-network into a mixed-integer program to select a combinatorial action in each timestep. Here, we focus on planning over restless bandits, a class of planning problems which capture many real-world examples of sequential decision making. We introduce coRMAB, a broader class of restless bandits with combinatorial actions that cannot be decoupled across the arms of the restless bandit, requiring direct solving over the joint, exponentially large action space. We empirically validate SEQUOIA on four novel restless bandit problems with combinatorial constraints: multiple interventions, path constraints, bipartite matching, and capacity constraints. Our approach significantly outperforms existing methods -- which cannot address sequential planning and combinatorial selection simultaneously -- by an average of 26.4% on these difficult instances. 

**Abstract (ZH)**: 强化学习（RL）越来越被应用于解决实际规划问题，尤其是在处理大型状态空间和时间 horizon 方面取得了进展。然而，在许多领域中，强化学习方法无法容纳大规模的组合结构动作空间。在这种情况下，即使在单个时间步表示可行动作集也可能需要复杂的离散优化建模。我们利用最新将训练好的神经网络嵌入到优化问题中的进展，提出了一种名为 SEQUOIA 的强化学习算法，该算法可以直接优化长期奖励，目标是可行动作空间。我们的方法将 Q 网络嵌入混合整数规划中，在每个时间步选择一个组合动作。我们关注的是不朽-bedenech（restless bandit）类规划问题，这类问题涵盖了大量现实世界中的序贯决策实例。我们引入了带组合动作的共RMAB（coRMAB），这是一种更广泛的不朽-bedenech 类问题，其中的动作不能在不朽-bedenech 的各个臂之间解耦，需要直接解决联合的、指数级大的动作空间。我们在四个带有组合约束的新型不朽-bedenech 问题上实证验证了 SEQUOIA：多干预、路径约束、二分匹配和容量约束。我们的方法在这些困难实例中平均表现比现有方法（无法同时解决序贯规划和组合选择问题）提高了 26.4%。 

---
# How to Steer LLM Latents for Hallucination Detection? 

**Title (ZH)**: 如何引导LLM潜在表示以进行幻觉检测？ 

**Authors**: Seongheon Park, Xuefeng Du, Min-Hsuan Yeh, Haobo Wang, Yixuan Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.01917)  

**Abstract**: Hallucinations in LLMs pose a significant concern to their safe deployment in real-world applications. Recent approaches have leveraged the latent space of LLMs for hallucination detection, but their embeddings, optimized for linguistic coherence rather than factual accuracy, often fail to clearly separate truthful and hallucinated content. To this end, we propose the Truthfulness Separator Vector (TSV), a lightweight and flexible steering vector that reshapes the LLM's representation space during inference to enhance the separation between truthful and hallucinated outputs, without altering model parameters. Our two-stage framework first trains TSV on a small set of labeled exemplars to form compact and well-separated clusters. It then augments the exemplar set with unlabeled LLM generations, employing an optimal transport-based algorithm for pseudo-labeling combined with a confidence-based filtering process. Extensive experiments demonstrate that TSV achieves state-of-the-art performance with minimal labeled data, exhibiting strong generalization across datasets and providing a practical solution for real-world LLM applications. 

**Abstract (ZH)**: LLM中幻觉的问题对其在真实世界应用中的安全部署构成了重大关切。近期方法利用了LLM的潜在空间进行幻觉检测，但这些方法优化的语言连贯性往往不足以清晰地区分真实和幻觉内容。为此，我们提出了一种轻量级和灵活的控制向量——真相分离向量（TSV），该向量在推理过程中重塑LLM的表示空间，以增强真实和幻觉输出之间的分离，而不改变模型参数。我们的两阶段框架首先在少量标记的示例上训练TSV，形成紧凑且分离良好的聚类。然后，通过基于最优传输的伪标签算法与基于置信度的过滤过程，扩充示例集以包含未标记的LLM生成数据。广泛的实验表明，TSV在最少标记数据下实现了最先进的性能，展现出强大的泛化能力，并为真实的LLM应用提供了实用的解决方案。 

---
# Conceptual Contrastive Edits in Textual and Vision-Language Retrieval 

**Title (ZH)**: 文本和跨模态检索中的概念对比编辑 

**Authors**: Maria Lymperaiou, Giorgos Stamou  

**Link**: [PDF](https://arxiv.org/pdf/2503.01914)  

**Abstract**: As deep learning models grow in complexity, achieving model-agnostic interpretability becomes increasingly vital. In this work, we employ post-hoc conceptual contrastive edits to expose noteworthy patterns and biases imprinted in representations of retrieval models. We systematically design optimal and controllable contrastive interventions targeting various parts of speech, and effectively apply them to explain both linguistic and visiolinguistic pre-trained models in a black-box manner. Additionally, we introduce a novel metric to assess the per-word impact of contrastive interventions on model outcomes, providing a comprehensive evaluation of each intervention's effectiveness. 

**Abstract (ZH)**: 随着深度学习模型变得日益复杂，实现模型通用可解释性变得越来越重要。在本文中，我们采用事后概念对比编辑方法揭示检索模型表示中突出的模式和偏见。我们系统地设计了针对各种词性的最优且可控的对比干预措施，并以黑盒方式有效地应用于解释语言和语意图像预训练模型。此外，我们引入了一个新的度量标准来评估对比干预措施对模型结果的单词影响，从而全面评估每种干预措施的效果。 

---
# dyAb: Flow Matching for Flexible Antibody Design with AlphaFold-driven Pre-binding Antigen 

**Title (ZH)**: dyAb: 基于AlphaFold驱动的预结合抗原的流式抗体设计 

**Authors**: Cheng Tan, Yijie Zhang, Zhangyang Gao, Yufei Huang, Haitao Lin, Lirong Wu, Fandi Wu, Mathieu Blanchette, Stan. Z. Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.01910)  

**Abstract**: The development of therapeutic antibodies heavily relies on accurate predictions of how antigens will interact with antibodies. Existing computational methods in antibody design often overlook crucial conformational changes that antigens undergo during the binding process, significantly impacting the reliability of the resulting antibodies. To bridge this gap, we introduce dyAb, a flexible framework that incorporates AlphaFold2-driven predictions to model pre-binding antigen structures and specifically addresses the dynamic nature of antigen conformation changes. Our dyAb model leverages a unique combination of coarse-grained interface alignment and fine-grained flow matching techniques to simulate the interaction dynamics and structural evolution of the antigen-antibody complex, providing a realistic representation of the binding process. Extensive experiments show that dyAb significantly outperforms existing models in antibody design involving changing antigen conformations. These results highlight dyAb's potential to streamline the design process for therapeutic antibodies, promising more efficient development cycles and improved outcomes in clinical applications. 

**Abstract (ZH)**: 基于抗原构象变化预测的治疗性抗体开发 

---
# Attend or Perish: Benchmarking Attention in Algorithmic Reasoning 

**Title (ZH)**: Attendance or Perish: 评估算法推理中的注意力机制 

**Authors**: Michal Spiegel, Michal Štefánik, Marek Kadlčík, Josef Kuchař  

**Link**: [PDF](https://arxiv.org/pdf/2503.01909)  

**Abstract**: Can transformers learn to perform algorithmic tasks reliably across previously unseen input/output domains? While pre-trained language models show solid accuracy on benchmarks incorporating algorithmic reasoning, assessing the reliability of these results necessitates an ability to cleanse models' functional capabilities from memorization. In this paper, we propose an algorithmic benchmark comprising six tasks of infinite input domains where we can also disentangle and trace the correct, robust algorithm necessary for the task. This allows us to assess (i) models' ability to extrapolate to unseen types of inputs, including new lengths, value ranges or input domains, but also (ii) to assess the robustness of the functional mechanism in recent models through the lens of their attention maps. We make the implementation of all our tasks and interoperability methods publicly available at this https URL . 

**Abstract (ZH)**: Transformers能否可靠地执行跨未见过的输入/输出领域的算法任务？虽然预训练语言模型在包含算法推理的基准测试中表现出色，但评估这些结果的可靠性需要能够清除模型的功能能力中的记忆现象。在本文中，我们提出了一种算法基准，包括六个具有无限输入域的任务，我们可以在其中拆分并追踪完成任务所需的正确且稳健的算法。这使我们能够评估（i）模型能否将任务扩展到未见过的输入类型，包括新的长度、值范围或输入域，以及（ii）通过注意力图评估最近模型的功能机制的鲁棒性。我们在<这个链接>公开了所有任务的实现和互操作方法。 

---
# UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning 

**Title (ZH)**: UDora：一种通过动态劫持其自身推理来对抗LLM代理的统一红队框架 

**Authors**: Jiawei Zhang, Shuang Yang, Bo Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.01908)  

**Abstract**: Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for handling complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements also amplify the risks of adversarial attacks, particularly when LLM agents can access sensitive external functionalities. Moreover, because LLM agents engage in extensive reasoning or planning before executing final actions, manipulating them into performing targeted malicious actions or invoking specific tools remains a significant challenge. Consequently, directly embedding adversarial strings in malicious instructions or injecting malicious prompts into tool interactions has become less effective against modern LLM agents. In this work, we present UDora, a unified red teaming framework designed for LLM Agents that dynamically leverages the agent's own reasoning processes to compel it toward malicious behavior. Specifically, UDora first samples the model's reasoning for the given task, then automatically identifies multiple optimal positions within these reasoning traces to insert targeted perturbations. Subsequently, it uses the modified reasoning as the objective to optimize the adversarial strings. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets. 

**Abstract (ZH)**: 具有外部工具辅助的大型语言模型（LLM）代理在处理复杂任务如网络购物、自动化邮件回复和金融交易方面的能力不断增强。然而，这些进步也放大了对抗攻击的风险，特别是在LLM代理能够访问敏感外部功能时。此外，由于LLM代理在执行最终操作前会进行广泛的推理或规划，操纵它们执行定向恶意操作或调用特定工具仍然是一项重大挑战。因此，直接在恶意指令中嵌入对抗字符串或将恶意提示注入工具交互已不再是现代LLM代理的有效手段。在本工作中，我们提出了一种名为UDora的统一红队框架，专门为LLM代理设计，动态利用代理自身的推理过程来使其朝向恶意行为。具体而言，UDora首先随机采样模型针对给定任务的推理过程，然后自动识别这些推理轨迹中的多个最优位置，插入目标扰动。接下来，它将修改后的推理作为优化目标来优化对抗字符串。通过迭代应用这一过程，LLM代理将被诱导执行指定的恶意操作或调用特定的恶意工具。我们的方法在三个LLM代理数据集上的效果优于现有的方法。 

---
# Learning to Chain Operations by Routing Information Through a Global Workspace 

**Title (ZH)**: 通过全局工作空间传输信息以学习串联操作 

**Authors**: Hugo Chateau-Laurent, Rufin VanRullen  

**Link**: [PDF](https://arxiv.org/pdf/2503.01906)  

**Abstract**: We present a model inspired by the Global Workspace Theory that integrates specialized modules to perform a sequential reasoning task. A controller selectively routes information between modules through the workspace using a gating mechanism. This approach allows the model to chain operations by iteratively broadcasting information between specialized domains, mimicking System-2 reasoning. We evaluate the model's performance on a simple addition task, where two addends must be summed. The task can be solved by routing information sequentially through an Input module, an Increment module (multiple times), and finally an Output module. We consider two implementations of this system with increasing complexity. First, using hand-designed modules operating on one-hot digit representations, the controller (a LSTM recurrent network) learns to select the appropriate modules (input, increment, output) in the appropriate sequence. Second, we replace the hand-designed modules with learned representation modules for MNIST images and an increment module trained on the task objectives; here again, the controller learns the appropriate sequential module selection to solve the task. Finally, we show that the Global Workspace model, while having fewer parameters, outperforms LSTMs and Transformers when tested on unseen addition operations (both interpolations and extrapolations of addition operations seen during training). Our results highlight the potential of architectures inspired by the Global Workspace Theory to enhance deep learning's reasoning capabilities. 

**Abstract (ZH)**: 基于全局工作区理论的序列推理模型研究 

---
# PaCA: Partial Connection Adaptation for Efficient Fine-Tuning 

**Title (ZH)**: PaCA: 部分连接适应性调整以实现高效的微调 

**Authors**: Sunghyeon Woo, Sol Namkung, Sunwoo Lee, Inho Jeong, Beomseok Kim, Dongsuk Jeon  

**Link**: [PDF](https://arxiv.org/pdf/2503.01905)  

**Abstract**: Prior parameter-efficient fine-tuning (PEFT) algorithms reduce memory usage and computational costs of fine-tuning large neural network models by training only a few additional adapter parameters, rather than the entire model. However, the reduction in computational costs due to PEFT does not necessarily translate to a reduction in training time; although the computational costs of the adapter layers are much smaller than the pretrained layers, it is well known that those two types of layers are processed sequentially on GPUs, resulting in significant latency overhead. LoRA and its variants merge low-rank adapter matrices with pretrained weights during inference to avoid latency overhead, but during training, the pretrained weights remain frozen while the adapter matrices are continuously updated, preventing such merging. To mitigate this issue, we propose Partial Connection Adaptation (PaCA), which fine-tunes randomly selected partial connections within the pretrained weights instead of introducing adapter layers in the model. PaCA not only enhances training speed by eliminating the time overhead due to the sequential processing of the adapter and pretrained layers but also reduces activation memory since only partial activations, rather than full activations, need to be stored for gradient computation. Compared to LoRA, PaCA reduces training time by 22% and total memory usage by 16%, while maintaining comparable accuracy across various fine-tuning scenarios, such as fine-tuning on the MMLU dataset and instruction tuning on the Oasst1 dataset. PaCA can also be combined with quantization, enabling the fine-tuning of large models such as LLaMA3.1-70B. In addition, PaCA enables training with 23% longer sequence and improves throughput by 16% on both NVIDIA A100 GPU and INTEL Gaudi2 HPU compared to LoRA. The code is available at this https URL. 

**Abstract (ZH)**: 部分连接适应（PaCA）：一种减少训练时间与内存使用的新方法 

---
# What are You Looking at? Modality Contribution in Multimodal Medical Deep Learning Methods 

**Title (ZH)**: 你正在关注什么？多模态医疗深度学习方法中的模态贡献 

**Authors**: Christian Gapp, Elias Tappeiner, Martin Welk, Karl Fritscher, Elke Ruth Gizewski, Rainer Schubert  

**Link**: [PDF](https://arxiv.org/pdf/2503.01904)  

**Abstract**: Purpose High dimensional, multimodal data can nowadays be analyzed by huge deep neural networks with little effort. Several fusion methods for bringing together different modalities have been developed. Particularly, in the field of medicine with its presence of high dimensional multimodal patient data, multimodal models characterize the next step. However, what is yet very underexplored is how these models process the source information in detail. Methods To this end, we implemented an occlusion-based both model and performance agnostic modality contribution method that quantitatively measures the importance of each modality in the dataset for the model to fulfill its task. We applied our method to three different multimodal medical problems for experimental purposes. Results Herein we found that some networks have modality preferences that tend to unimodal collapses, while some datasets are imbalanced from the ground up. Moreover, we could determine a link between our metric and the performance of single modality trained nets. Conclusion The information gain through our metric holds remarkable potential to improve the development of multimodal models and the creation of datasets in the future. With our method we make a crucial contribution to the field of interpretability in deep learning based multimodal research and thereby notably push the integrability of multimodal AI into clinical practice. Our code is publicly available at this https URL. 

**Abstract (ZH)**: 目的：现有的大型深度神经网络可以轻松分析高维多模态数据。已经开发出了多种融合不同模态的方法。特别是，在医学领域，由于存在高维多模态患者数据，多模态模型是进一步的发展方向。然而，这些模型如何处理源信息的具体细节仍然很少被探索。方法：为此，我们实现了一种基于遮罩的、与模型和性能无关的模态贡献方法，用于定量测量数据集中每个模态对于模型完成任务的重要性。我们针对三种不同的多模态医学问题进行了实验研究。结果：我们发现，某些网络具有模态偏好，倾向于单一模态的收敛；某些数据集从一开始就存在不平衡性。此外，我们能够确定我们的指标与单模态训练网络性能之间的联系。结论：通过我们的指标获得的信息增益对未来多模态模型的发展和数据集的创建具有显著潜力。我们的方法在基于深度学习的多模态研究的可解释性领域做出了关键性贡献，从而显著推动了多模态AI在临床实践中的集成。我们的代码已在以下网址公开 доступ于此：this https URL。 

---
# PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice 

**Title (ZH)**: PsychBench：评估LLM辅助精神科临床实践性能的全面专业基准 

**Authors**: Ruoxi Wang, Shuyu Liu, Ling Zhang, Xuequan Zhu, Rui Yang, Xinzhu Zhou, Fei Wu, Zhi Yang, Cheng Jin, Gang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01903)  

**Abstract**: The advent of Large Language Models (LLMs) offers potential solutions to address problems such as shortage of medical resources and low diagnostic consistency in psychiatric clinical practice. Despite this potential, a robust and comprehensive benchmarking framework to assess the efficacy of LLMs in authentic psychiatric clinical environments is absent. This has impeded the advancement of specialized LLMs tailored to psychiatric applications. In response to this gap, by incorporating clinical demands in psychiatry and clinical data, we proposed a benchmarking system, PsychBench, to evaluate the practical performance of LLMs in psychiatric clinical settings. We conducted a comprehensive quantitative evaluation of 16 LLMs using PsychBench, and investigated the impact of prompt design, chain-of-thought reasoning, input text length, and domain-specific knowledge fine-tuning on model performance. Through detailed error analysis, we identified strengths and potential limitations of the existing models and suggested directions for improvement. Subsequently, a clinical reader study involving 60 psychiatrists of varying seniority was conducted to further explore the practical benefits of existing LLMs as supportive tools for psychiatrists of varying seniority. Through the quantitative and reader evaluation, we show that while existing models demonstrate significant potential, they are not yet adequate as decision-making tools in psychiatric clinical practice. The reader study further indicates that, as an auxiliary tool, LLM could provide particularly notable support for junior psychiatrists, effectively enhancing their work efficiency and overall clinical quality. To promote research in this area, we will make the dataset and evaluation framework publicly available, with the hope of advancing the application of LLMs in psychiatric clinical settings. 

**Abstract (ZH)**: 大型语言模型（LLMs）的出现为解决医学资源短缺和精神科临床诊断一致性低等问题提供了潜在解决方案。尽管具备这些潜力，但缺乏一个能够在真实精神科临床环境中全面评估LLMs有效性的基准框架，这阻碍了针对精神科应用的专业化LLMs的发展。为弥补这一空白，通过融入精神病学的临床需求和临床数据，我们提出了一套基准评估系统PsychBench，用于评估LLMs在精神科临床环境中的实际表现。我们使用PsychBench对16种LLM进行了全面的定量评估，并探究了提示设计、链式思考推理、输入文本长度和领域特定知识微调对模型性能的影响。通过详细的错误分析，我们识别了现有模型的优势和潜在局限性，并提出了改进方向。随后，我们开展了涉及60名不同资历精神科医生的临床读者研究，进一步探讨了现有LLMs作为不同资历精神科医生支持工具的实际益处。通过对定量和读者评估结果的研究，我们表明，虽然现有模型具有巨大的潜力，但它们尚不足以作为精神科临床实践中决策工具。读者研究进一步表明，作为辅助工具，LLM能够特别显著地支持初级精神科医生，有效提高他们的工作效率和整体临床质量。为促进这一领域的研究，我们将数据集和评估框架公开，希望能推动LLMs在精神科临床环境中的应用。 

---
# An Empirical Analysis of LLMs for Countering Misinformation 

**Title (ZH)**: 对抗谬误的大型语言模型实证分析 

**Authors**: Adiba Mahbub Proma, Neeley Pate, James Druckman, Gourab Ghoshal, Hangfeng He, Ehsan Hoque  

**Link**: [PDF](https://arxiv.org/pdf/2503.01902)  

**Abstract**: While Large Language Models (LLMs) can amplify online misinformation, they also show promise in tackling misinformation. In this paper, we empirically study the capabilities of three LLMs -- ChatGPT, Gemini, and Claude -- in countering political misinformation. We implement a two-step, chain-of-thought prompting approach, where models first identify credible sources for a given claim and then generate persuasive responses. Our findings suggest that models struggle to ground their responses in real news sources, and tend to prefer citing left-leaning sources. We also observe varying degrees of response diversity among models. Our findings highlight concerns about using LLMs for fact-checking through only prompt-engineering, emphasizing the need for more robust guardrails. Our results have implications for both researchers and non-technical users. 

**Abstract (ZH)**: 大型语言模型在对抗政治 misinformation方面的能力研究：基于实证的探讨与应对策略 

---
# Identifying Sensitive Weights via Post-quantization Integral 

**Title (ZH)**: 通过后量化积分识别敏感权重 

**Authors**: Yuezhou Hu, Weiyu Huang, Zichen Liang, Chang Chen, Jintao Zhang, Jun Zhu, Jianfei Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.01901)  

**Abstract**: Serving Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on a sensitivity metric, which indicates the element-wise influence of weights on loss function and is used to preprocess original weights for better quantization. In this work, we conduct an empirical study on the accuracy of the sensitivity metric, and find that existing gradient and Hessian based metrics are very inaccurate: they underestimate quantization's impact on the loss function by orders of magnitude, mainly due to the small convergence radius of local 2nd order approximation, \ie, gradient and Hessian term in Taylor's formula. To tackle this problem, we propose Post-quantization Integral (PQI), an accurate metric to estimate posterior sensitivity in a fine-grained manner. To leverage this accurate metric, we further propose ReQuant, a simple yet powerful framework that mainly consists of two Dense-and-Sparse detach components: self-adaptive outlier selection and step-wise significant weights detach. Results show that ReQuant boosts state-of-the-art post-training quantization methods, with a pronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP. 

**Abstract (ZH)**: 大型语言模型的服务成本较高。然而，通过后训练权重量化可以解决这一问题，既可以通过压缩模型大小来限制内存使用，也可以通过加速来节省带宽。由于并不是所有权重维度同等重要，这些方法通常依赖于一个敏感度度量，该度量指示权重对损失函数的影响，并用于预处理原始权重以获得更好的量化效果。在本文中，我们对敏感度度量的准确性进行了实证研究，并发现现有的基于梯度和海森矩阵的度量非常不准确：它们严重低估了量化对损失函数的影响，主要是由于局部二次逼近的收敛半径很小，即泰勒公式中的梯度和海森矩阵项。为解决这一问题，我们提出了后量化积分（PQI），这是一种精确的度量方法，用于以细粒度的方式估计后验敏感度。为进一步利用这一精确的度量方法，我们提出了ReQuant，这是一种简单而强大的框架，主要由两个密集和稀疏分离组件组成：自适应异常值选择和逐步分离显著权重。结果显示，ReQuant提升了现有的后训练量化方法，在Llama 3.2 1B模型上使用QTIP实现了2.66困惑度的显著改善。 

---
# LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection 

**Title (ZH)**: LLM赋能的类别不平衡图提示学习在线毒品交易检测 

**Authors**: Tianyi Ma, Yiyue Qian, Zehong Wang, Zheyuan Zhang, Chuxu Zhang, Yanfang Ye  

**Link**: [PDF](https://arxiv.org/pdf/2503.01900)  

**Abstract**: As the market for illicit drugs remains extremely profitable, major online platforms have become direct-to-consumer intermediaries for illicit drug trafficking participants. These online activities raise significant social concerns that require immediate actions. Existing approaches to combating this challenge are generally impractical, due to the imbalance of classes and scarcity of labeled samples in real-world applications. To this end, we propose a novel Large Language Model-empowered Heterogeneous Graph Prompt Learning framework for illicit Drug Trafficking detection, called LLM-HetGDT, that leverages LLM to facilitate heterogeneous graph neural networks (HGNNs) to effectively identify drug trafficking activities in the class-imbalanced scenarios. Specifically, we first pre-train HGNN over a contrastive pretext task to capture the inherent node and structure information over the unlabeled drug trafficking heterogeneous graph (HG). Afterward, we employ LLM to augment the HG by generating high-quality synthetic user nodes in minority classes. Then, we fine-tune the soft prompts on the augmented HG to capture the important information in the minority classes for the downstream drug trafficking detection task. To comprehensively study online illicit drug trafficking activities, we collect a new HG dataset over Twitter, called Twitter-HetDrug. Extensive experiments on this dataset demonstrate the effectiveness, efficiency, and applicability of LLM-HetGDT. 

**Abstract (ZH)**: 基于大型语言模型的异构图提示学习框架：非法毒品交易检测（LLM-HetGDT） 

---
# FASTer: Focal Token Acquiring-and-Scaling Transformer for Long-term 3D Object Detection 

**Title (ZH)**: FASTer: 用于长期三维物体检测的焦点 token 获取与缩放变换器 

**Authors**: Chenxu Dang, Zaipeng Duan, Pei An, Xinmin Zhang, Xuzhong Hu, Jie Ma  

**Link**: [PDF](https://arxiv.org/pdf/2503.01899)  

**Abstract**: Recent top-performing temporal 3D detectors based on Lidars have increasingly adopted region-based paradigms. They first generate coarse proposals, followed by encoding and fusing regional features. However, indiscriminate sampling and fusion often overlook the varying contributions of individual points and lead to exponentially increased complexity as the number of input frames grows. Moreover, arbitrary result-level concatenation limits the global information extraction. In this paper, we propose a Focal Token Acquring-and-Scaling Transformer (FASTer), which dynamically selects focal tokens and condenses token sequences in an adaptive and lightweight manner. Emphasizing the contribution of individual tokens, we propose a simple but effective Adaptive Scaling mechanism to capture geometric contexts while sifting out focal points. Adaptively storing and processing only focal points in historical frames dramatically reduces the overall complexity. Furthermore, a novel Grouped Hierarchical Fusion strategy is proposed, progressively performing sequence scaling and Intra-Group Fusion operations to facilitate the exchange of global spatial and temporal information. Experiments on the Waymo Open Dataset demonstrate that our FASTer significantly outperforms other state-of-the-art detectors in both performance and efficiency while also exhibiting improved flexibility and robustness. The code is available at this https URL. 

**Abstract (ZH)**: 基于激光雷达的 Recent 顶级时序 3D 检测器越来越多地采用区域为基础的范式。它们首先生成粗略的提议，然后编码和融合区域特征。然而，非区分性的采样和融合往往忽视了单个点的不同贡献，并随着输入帧数量的增长导致复杂性呈指数级增加。此外，任意的结果级拼接限制了全局信息的提取。在本文中，我们提出了一种焦点标记获取和缩放变换器（FASTer），它以动态选择焦点标记并在适应性和轻量化的方式中浓缩标记序列。强调单个标记的贡献，我们提出了一种简单而有效的自适应缩放机制，以捕获几何上下文并筛选出焦点点。仅在历史帧中适当地存储和处理焦点点显著降低了整体复杂性。此外，我们还提出了一种新的分组层次融合策略，逐步执行序列缩放和组内融合操作，以促进全局空间和时间信息的交换。在 Waymo 开放数据集上的实验表明，在性能和效率方面，我们的 FASTer 显著优于其他最先进的检测器，同时还表现出更好的灵活性和鲁棒性。代码可在以下链接获取：this https URL。 

---
# Continual Learning-Aided Super-Resolution Scheme for Channel Reconstruction and Generalization in OFDM Systems 

**Title (ZH)**: 基于连续学习的OFDM系统信道重建与泛化超分辨率方案 

**Authors**: Jianqiao Chen, Nan Ma, Wenkai Liu, Xiaodong Xu, Ping Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01897)  

**Abstract**: Channel reconstruction and generalization capability are of equal importance for developing channel estimation schemes within deep learning (DL) framework. In this paper, we exploit a novel DL-based scheme for efficient OFDM channel estimation where the neural networks for channel reconstruction and generalization are respectively designed. For the former, we propose a dual-attention-aided super-resolution neural network (DA-SRNN) to map the channels at pilot positions to the whole time-frequency channels. Specifically, the channel-spatial attention mechanism is first introduced to sequentially infer attention maps along two separate dimensions corresponding to two types of underlying channel correlations, and then the lightweight SR module is developed for efficient channel reconstruction. For the latter, we introduce continual learning (CL)-aided training strategies to make the neural network adapt to different channel distributions. Specifically, the elastic weight consolidation (EWC) is introduced as the regularization term in regard to loss function of channel reconstruction, which can constrain the direction and space of updating the important weights of neural networks among different channel distributions. Meanwhile, the corresponding training process is provided in detail. By evaluating under 3rd Generation Partnership Project (3GPP) channel models, numerical results verify the superiority of the proposed channel estimation scheme with significantly improved channel reconstruction and generalization performance over counterparts. 

**Abstract (ZH)**: 基于深度学习的信道估计方案中，信道重建和泛化能力具有同等重要性。本文提出了一种新颖的基于深度学习的OFDM信道估计算法，在该算法中分别设计了适用于信道重建和泛化的神经网络。对于信道重建，我们提出了一种双注意力辅助超分辨率神经网络（DA-SRNN），用于将导频位置的信道映射到整个时频信道。具体来说，首先引入了信道-空间注意力机制，以逐步推断出与两种不同信道相关性类型对应的注意力图，然后开发了轻量级的超分辨率模块以实现高效的信道重建。对于泛化能力，我们引入了连续学习（CL）辅助训练策略，使得神经网络能够适应不同的信道分布。具体而言，我们引入了弹性权重聚合（EWC）作为重构损失函数的正则化项，可以约束不同信道分布下重要权重更新的方向和空间。同时，详细描述了相应的训练过程。通过在3GPP信道模型下的评估，数值结果验证了所提信道估计算法在信道重建和泛化性能上的优越性。 

---
# Neuroplasticity and Corruption in Model Mechanisms: A Case Study Of Indirect Object Identification 

**Title (ZH)**: 神经可塑性与模型机制中的腐败：间接宾语识别的案例研究 

**Authors**: Vishnu Kabir Chhabra, Ding Zhu, Mohammad Mahdi Khalili  

**Link**: [PDF](https://arxiv.org/pdf/2503.01896)  

**Abstract**: Previous research has shown that fine-tuning language models on general tasks enhance their underlying mechanisms. However, the impact of fine-tuning on poisoned data and the resulting changes in these mechanisms are poorly understood. This study investigates the changes in a model's mechanisms during toxic fine-tuning and identifies the primary corruption mechanisms. We also analyze the changes after retraining a corrupted model on the original dataset and observe neuroplasticity behaviors, where the model relearns original mechanisms after fine-tuning the corrupted model. Our findings indicate that: (i) Underlying mechanisms are amplified across task-specific fine-tuning which can be generalized to longer epochs, (ii) Model corruption via toxic fine-tuning is localized to specific circuit components, (iii) Models exhibit neuroplasticity when retraining corrupted models on clean dataset, reforming the original model mechanisms. 

**Abstract (ZH)**: 以往的研究表明，对通用任务进行微调可以增强语言模型的内部机制。然而，微调对有毒数据的影响及其导致的机制变化尚不完全清楚。本研究探讨了有毒微调过程中模型机制的变化，并识别出了主要的污染机制。我们还分析了在原始数据集上重新训练被污染模型后的变化，观察到了神经可塑性行为，即模型在重新微调被污染模型后重新学习了原始机制。研究发现：(i) 任务特定微调增强了内部机制，并可普遍适用于更长的训练周期；(ii) 通过有毒微调对模型的污染局限于特定电路组件；(iii) 在清洁数据集上重新训练被污染模型时，模型表现出神经可塑性，重构了原始模型机制。 

---
# Evaluating System 1 vs. 2 Reasoning Approaches for Zero-Shot Time-Series Forecasting: A Benchmark and Insights 

**Title (ZH)**: 评估系统1 vs. 系统2推理方法在零样本时间序列预测中的性能：基准与见解 

**Authors**: Haoxin Liu, Zhiyuan Zhao, Shiduo Li, B. Aditya Prakash  

**Link**: [PDF](https://arxiv.org/pdf/2503.01895)  

**Abstract**: Reasoning ability is crucial for solving challenging tasks. With the advancement of foundation models, such as the emergence of large language models (LLMs), a wide range of reasoning strategies has been proposed, including test-time enhancements, such as Chain-ofThought, and post-training optimizations, as used in DeepSeek-R1. While these reasoning strategies have demonstrated effectiveness across various challenging language or vision tasks, their applicability and impact on time-series forecasting (TSF), particularly the challenging zero-shot TSF, remain largely unexplored. In particular, it is unclear whether zero-shot TSF benefits from reasoning and, if so, what types of reasoning strategies are most effective. To bridge this gap, we propose ReC4TS, the first benchmark that systematically evaluates the effectiveness of popular reasoning strategies when applied to zero-shot TSF tasks. ReC4TS conducts comprehensive evaluations across datasets spanning eight domains, covering both unimodal and multimodal with short-term and longterm forecasting tasks. More importantly, ReC4TS provides key insights: (1) Self-consistency emerges as the most effective test-time reasoning strategy; (2) Group-relative policy optimization emerges as a more suitable approach for incentivizing reasoning ability during post-training; (3) Multimodal TSF benefits more from reasoning strategies compared to unimodal TSF. Beyond these insights, ReC4TS establishes two pioneering starting blocks to support future zero-shot TSF reasoning research: (1) A novel dataset, TimeThinking, containing forecasting samples annotated with reasoning trajectories from multiple advanced LLMs, and (2) A new and simple test-time scaling-law validated on foundational TSF models enabled by self-consistency reasoning strategy. All data and code are publicly accessible at: this https URL 

**Abstract (ZH)**: ReC4TS：系统评估推理策略在零样本时间序列预测中的有效性 

---
# LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces 

**Title (ZH)**: LIVS: 包容性公共空间多样共识数据集 

**Authors**: Rashid Mushkani, Shravan Nayak, Hugo Berard, Allison Cohen, Shin Koseki, Hadrien Bertrand  

**Link**: [PDF](https://arxiv.org/pdf/2503.01894)  

**Abstract**: We introduce the Local Intersectional Visual Spaces (LIVS) dataset, a benchmark for multi-criteria alignment of text-to-image (T2I) models in inclusive urban planning. Developed through a two-year participatory process with 30 community organizations, LIVS encodes diverse spatial preferences across 634 initial concepts, consolidated into six core criteria: Accessibility, Safety, Comfort, Invitingness, Inclusivity, and Diversity, through 37,710 pairwise comparisons. Using Direct Preference Optimization (DPO) to fine-tune Stable Diffusion XL, we observed a measurable increase in alignment with community preferences, though a significant proportion of neutral ratings highlights the complexity of modeling intersectional needs. Additionally, as annotation volume increases, accuracy shifts further toward the DPO-tuned model, suggesting that larger-scale preference data enhances fine-tuning effectiveness. LIVS underscores the necessity of integrating context-specific, stakeholder-driven criteria into generative modeling and provides a resource for evaluating AI alignment methodologies across diverse socio-spatial contexts. 

**Abstract (ZH)**: 我们介绍了局部交叉视域数据集（LIVS），这是一个用于包容性城市规划中多准则文本到图像（T2I）模型对齐的基准数据集。通过与30个社区组织进行为期两年的参与式过程开发，LIVS 编码了634个初始概念中的多样化空间偏好，并通过37,710对两两比较将其整合为六项核心标准：可达性、安全性、舒适性、亲和性、包容性和多样性。利用直接偏好优化（DPO）对Stable Diffusion XL进行微调，我们观察到与社区偏好对齐的可测量增加，尽管大量的中间评分突显了建模交叉需求的复杂性。此外，随着注释量的增加，准确性更加倾向于DPO微调模型，表明大规模偏好数据增强了微调效果。LIVS 强调了将具体情境和利益相关者驱动的标准整合到生成建模中的必要性，并提供了一个跨多元社会空间环境评估AI对齐方法论的资源。 

---
# Enhancing Transformer with GNN Structural Knowledge via Distillation: A Novel Approach 

**Title (ZH)**: 基于蒸馏的变换器增强新方法：通过图神经网络结构知识 

**Authors**: Zhihua Duan, Jialin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01888)  

**Abstract**: Integrating the structural inductive biases of Graph Neural Networks (GNNs) with the global contextual modeling capabilities of Transformers represents a pivotal challenge in graph representation learning. While GNNs excel at capturing localized topological patterns through message-passing mechanisms, their inherent limitations in modeling long-range dependencies and parallelizability hinder their deployment in large-scale scenarios. Conversely, Transformers leverage self-attention mechanisms to achieve global receptive fields but struggle to inherit the intrinsic graph structural priors of GNNs. This paper proposes a novel knowledge distillation framework that systematically transfers multiscale structural knowledge from GNN teacher models to Transformer student models, offering a new perspective on addressing the critical challenges in cross-architectural distillation. The framework effectively bridges the architectural gap between GNNs and Transformers through micro-macro distillation losses and multiscale feature alignment. This work establishes a new paradigm for inheriting graph structural biases in Transformer architectures, with broad application prospects. 

**Abstract (ZH)**: 将图神经网络（GNNs）的结构诱导偏置与变换器的全局上下文建模能力集成是图表示学习中的一个关键挑战。尽管GNNs通过消息传递机制擅长捕捉局部拓扑模式，但它们在建模长程依赖关系和并行化方面的固有局限性限制了其在大规模场景中的部署。相反，变换器通过自注意力机制实现了全局的感受野但难以继承GNNs的内在图结构先验。本文提出了一种新的知识蒸馏框架，系统地将多尺度结构知识从GNN教师模型转移到变换器学生模型，为跨架构蒸馏的关键挑战提供了新的视角。该框架通过微宏观蒸馏损失和多尺度特征对齐有效地弥合了GNNs和变换器之间的架构差距。这项工作为在变换器架构中继承图结构偏置建立了新的范式，具有广泛的应用前景。 

---
# When Continue Learning Meets Multimodal Large Language Model: A Survey 

**Title (ZH)**: 当持续学习遇到多模态大型语言模型：一个综述 

**Authors**: Yukang Huo, Hao Tang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01887)  

**Abstract**: Recent advancements in Artificial Intelligence have led to the development of Multimodal Large Language Models (MLLMs). However, adapting these pre-trained models to dynamic data distributions and various tasks efficiently remains a challenge. Fine-tuning MLLMs for specific tasks often causes performance degradation in the model's prior knowledge domain, a problem known as 'Catastrophic Forgetting'. While this issue has been well-studied in the Continual Learning (CL) community, it presents new challenges for MLLMs. This review paper, the first of its kind in MLLM continual learning, presents an overview and analysis of 440 research papers in this this http URL review is structured into four sections. First, it discusses the latest research on MLLMs, covering model innovations, benchmarks, and applications in various fields. Second, it categorizes and overviews the latest studies on continual learning, divided into three parts: non-large language models unimodal continual learning (Non-LLM Unimodal CL), non-large language models multimodal continual learning (Non-LLM Multimodal CL), and continual learning in large language models (CL in LLM). The third section provides a detailed analysis of the current state of MLLM continual learning research, including benchmark evaluations, architectural innovations, and a summary of theoretical and empirical this http URL, the paper discusses the challenges and future directions of continual learning in MLLMs, aiming to inspire future research and development in the field. This review connects the foundational concepts, theoretical insights, method innovations, and practical applications of continual learning for multimodal large models, providing a comprehensive understanding of the research progress and challenges in this field, aiming to inspire researchers in the field and promote the advancement of related technologies. 

**Abstract (ZH)**: 近期人工智能的发展推动了多模态大型语言模型（MLLMs）的开发。然而，高效地将这些预训练模型适应动态数据分布和各种任务仍然是一项挑战。对特定任务进行微调往往会导致模型在先前知识领域的性能下降，这种现象被称为“灾难性遗忘”。虽然灾难性遗忘在持续学习（CL）领域已有良好的研究，但对MLLMs来说，这提出了新的挑战。本文是第一篇关于MLLMs持续学习的综述论文，概述并分析了440篇相关研究论文。该综述分为四个部分。首先，讨论了MLLMs的最新研究，涵盖模型创新、基准测试和各领域的应用。其次，分类概述了最新的持续学习研究，分为三个部分：非大型语言模型的单模态持续学习（Non-LLM Unimodal CL）、非大型语言模型的多模态持续学习（Non-LLM Multimodal CL）和大型语言模型中的持续学习（CL in LLM）。第三部分详细分析了MLLMs持续学习研究的现状，包括基准评估、架构创新和理论与实证总结。最后，论文讨论了MLLMs持续学习面临的挑战和未来方向，旨在激励未来的研究与发展。该综述将持续学习的基础概念、理论洞见、方法创新和实际应用与多模态大型模型相结合，提供对该领域研究进展和挑战的全面理解，旨在激励研究人员并促进相关技术的发展。 

---
# Advanced Deep Learning Techniques for Analyzing Earnings Call Transcripts: Methodologies and Applications 

**Title (ZH)**: 基于财务报告电话会议文本分析的先进深度学习技术：方法与应用 

**Authors**: Umair Zakir, Evan Daykin, Amssatou Diagne, Jacob Faile  

**Link**: [PDF](https://arxiv.org/pdf/2503.01886)  

**Abstract**: This study presents a comparative analysis of deep learning methodologies such as BERT, FinBERT and ULMFiT for sentiment analysis of earnings call transcripts. The objective is to investigate how Natural Language Processing (NLP) can be leveraged to extract sentiment from large-scale financial transcripts, thereby aiding in more informed investment decisions and risk management strategies. We examine the strengths and limitations of each model in the context of financial sentiment analysis, focusing on data preprocessing requirements, computational efficiency, and model optimization. Through rigorous experimentation, we evaluate their performance using key metrics, including accuracy, precision, recall, and F1-score. Furthermore, we discuss potential enhancements to improve the effectiveness of these models in financial text analysis, providing insights into their applicability for real-world financial decision-making. 

**Abstract (ZH)**: 本研究对BERT、FinBERT和ULMFiT等深度学习方法在收益电话会议转录文本情感分析中的应用进行比较分析，旨在探讨自然语言处理（NLP）如何通过提取大规模财务转录文中的情感信息，辅助更明智的投资决策和风险管理策略。我们考察了每种模型在金融情感分析中的优势与局限性，重点包括数据预处理要求、计算效率和模型优化。通过严格的实证研究，我们使用准确率、精确率、召回率和F1分数等关键指标评估其性能。此外，我们讨论了改进这些模型在金融文本分析中有效性的潜在方法，提供了它们在实际金融决策中应用的洞察。 

---
# Learning Policy Committees for Effective Personalization in MDPs with Diverse Tasks 

**Title (ZH)**: 学习策略委员会以实现MDPs中多样化任务的有效个性化 

**Authors**: Luise Ge, Michael Lanier, Anindya Sarkar, Bengisu Guresti, Yevgeniy Vorobeychik, Chongjie Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01885)  

**Abstract**: Many dynamic decision problems, such as robotic control, involve a series of tasks, many of which are unknown at training time. Typical approaches for these problems, such as multi-task and meta reinforcement learning, do not generalize well when the tasks are diverse. On the other hand, approaches that aim to tackle task diversity, such as using task embedding as policy context and task clustering, typically lack performance guarantees and require a large number of training tasks. To address these challenges, we propose a novel approach for learning a policy committee that includes at least one near-optimal policy with high probability for tasks encountered during execution. While we show that this problem is in general inapproximable, we present two practical algorithmic solutions. The first yields provable approximation and task sample complexity guarantees when tasks are low-dimensional (the best we can do due to inapproximability), whereas the second is a general and practical gradient-based approach. In addition, we provide a provable sample complexity bound for few-shot learning. Our experiments on MuJoCo and Meta-World show that the proposed approach outperforms state-of-the-art multi-task, meta-, and task clustering baselines in training, generalization, and few-shot learning, often by a large margin. 

**Abstract (ZH)**: 一种学习执行过程中遇到的任务至少包含一个高概率近最优策略的政策委员会的新方法：克服多样性挑战 

---
# Contextual Quantum Neural Networks for Stock Price Prediction 

**Title (ZH)**: 基于上下文的量子神经网络股票价格预测 

**Authors**: Sharan Mourya, Hannes Leipold, Bibhas Adhikari  

**Link**: [PDF](https://arxiv.org/pdf/2503.01884)  

**Abstract**: In this paper, we apply quantum machine learning (QML) to predict the stock prices of multiple assets using a contextual quantum neural network. Our approach captures recent trends to predict future stock price distributions, moving beyond traditional models that focus on entire historical data, enhancing adaptability and precision. Utilizing the principles of quantum superposition, we introduce a new training technique called the quantum batch gradient update (QBGU), which accelerates the standard stochastic gradient descent (SGD) in quantum applications and improves convergence. Consequently, we propose a quantum multi-task learning (QMTL) architecture, specifically, the share-and-specify ansatz, that integrates task-specific operators controlled by quantum labels, enabling the simultaneous and efficient training of multiple assets on the same quantum circuit as well as enabling efficient portfolio representation with logarithmic overhead in the number of qubits. This architecture represents the first of its kind in quantum finance, offering superior predictive power and computational efficiency for multi-asset stock price forecasting. Through extensive experimentation on S\&P 500 data for Apple, Google, Microsoft, and Amazon stocks, we demonstrate that our approach not only outperforms quantum single-task learning (QSTL) models but also effectively captures inter-asset correlations, leading to enhanced prediction accuracy. Our findings highlight the transformative potential of QML in financial applications, paving the way for more advanced, resource-efficient quantum algorithms in stock price prediction and other complex financial modeling tasks. 

**Abstract (ZH)**: 基于上下文的量子神经网络在多重资产股票价格预测中的量子机器学习应用 

---
# Learning Surrogates for Offline Black-Box Optimization via Gradient Matching 

**Title (ZH)**: 基于梯度匹配的 Offline 黑盒优化代理学习 

**Authors**: Minh Hoang, Azza Fadhel, Aryan Deshwal, Janardhan Rao Doppa, Trong Nghia Hoang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01883)  

**Abstract**: Offline design optimization problem arises in numerous science and engineering applications including material and chemical design, where expensive online experimentation necessitates the use of in silico surrogate functions to predict and maximize the target objective over candidate designs. Although these surrogates can be learned from offline data, their predictions are often inaccurate outside the offline data regime. This challenge raises a fundamental question about the impact of imperfect surrogate model on the performance gap between its optima and the true optima, and to what extent the performance loss can be mitigated. Although prior work developed methods to improve the robustness of surrogate models and their associated optimization processes, a provably quantifiable relationship between an imperfect surrogate and the corresponding performance gap, as well as whether prior methods directly address it, remain elusive. To shed light on this important question, we present a theoretical framework to understand offline black-box optimization, by explicitly bounding the optimization quality based on how well the surrogate matches the latent gradient field that underlines the offline data. Inspired by our theoretical analysis, we propose a principled black-box gradient matching algorithm to create effective surrogate models for offline optimization, improving over prior approaches on various real-world benchmarks. 

**Abstract (ZH)**: 离线设计优化问题在材料和化学设计等科学与工程应用中普遍存在，其中昂贵的在线实验需要使用计算仿真的代理函数来预测并最大化目标性能。尽管这些代理函数可以基于离线数据进行学习，但它们在离线数据范围之外的预测往往不够准确。这一挑战引发了关于不完善的代理模型对其最优解与真实最优解之间的性能差距的影响以及性能损失可减少程度的基本问题。尽管已有研究发展了改进代理模型稳健性及其优化过程的方法，但不完善代理模型与相应性能差距之间的可证明可量化关系，以及先前方法是否直接解决该问题依然不清楚。为了揭示这一重要问题，我们提出了一种理论框架来理解离线黑盒优化问题，并通过明确界定制约代理函数与潜在梯度场的一致性来评估优化质量。受到理论分析的启发，我们提出了一个原则性的黑盒梯度匹配算法来创建有效的代理模型，该算法在多种实际基准测试上优于先前的方法。 

---
# Mapping representations in Reinforcement Learning via Semantic Alignment for Zero-Shot Stitching 

**Title (ZH)**: 通过语义对齐映射强化学习中的表示用于零样本缝合 

**Authors**: Antonio Pio Ricciardi, Valentino Maiorca, Luca Moschella, Riccardo Marin, Emanuele Rodolà  

**Link**: [PDF](https://arxiv.org/pdf/2503.01881)  

**Abstract**: Deep Reinforcement Learning (RL) models often fail to generalize when even small changes occur in the environment's observations or task requirements. Addressing these shifts typically requires costly retraining, limiting the reusability of learned policies. In this paper, we build on recent work in semantic alignment to propose a zero-shot method for mapping between latent spaces across different agents trained on different visual and task variations. Specifically, we learn a transformation that maps embeddings from one agent's encoder to another agent's encoder without further fine-tuning. Our approach relies on a small set of "anchor" observations that are semantically aligned, which we use to estimate an affine or orthogonal transform. Once the transformation is found, an existing controller trained for one domain can interpret embeddings from a different (existing) encoder in a zero-shot fashion, skipping additional trainings. We empirically demonstrate that our framework preserves high performance under visual and task domain shifts. We empirically demonstrate zero-shot stitching performance on the CarRacing environment with changing background and task. By allowing modular re-assembly of existing policies, it paves the way for more robust, compositional RL in dynamically changing environments. 

**Abstract (ZH)**: 深度强化学习模型在环境观察或任务需求发生微小变化时往往难以泛化，通常需要昂贵的重新训练才能应对这些变化，限制了学习策略的可重用性。在本文中，我们基于近期在语义对齐方面的研究工作，提出了一种零shot方法，用于在训练于不同视觉和任务变异上的不同智能体之间映射潜在空间。具体来说，我们学习一个变换，该变换将一个智能体编码器的嵌入映射到另一个智能体编码器，而无需进一步微调。我们的方法依赖于一组“锚点”观察，它们在语义上是齐的，我们使用这些观察来估计仿射或正交变换。一旦找到变换，一个为一个领域训练的现有控制器可以以零shot的方式解释另一个（现有）编码器的嵌入，从而跳过额外的训练。我们实证结果显示，我们的框架在视觉和任务领域变化下能够保持高性能。我们展示了在背景和任务变化的CarRacing环境中实现零shot拼接性能。通过允许模块化重组现有策略，我们的方法为动态变化环境中的更稳健和组合式强化学习铺平了道路。 

---
# BEYONDWORDS is All You Need: Agentic Generative AI based Social Media Themes Extractor 

**Title (ZH)**: BEYONWORDS 是你需要的：基于自主生成AI的社会媒体主题提取器 

**Authors**: Mohammed-Khalil Ghali, Abdelrahman Farrag, Sarah Lam, Daehan Won  

**Link**: [PDF](https://arxiv.org/pdf/2503.01880)  

**Abstract**: Thematic analysis of social media posts provides a major understanding of public discourse, yet traditional methods often struggle to capture the complexity and nuance of unstructured, large-scale text data. This study introduces a novel methodology for thematic analysis that integrates tweet embeddings from pre-trained language models, dimensionality reduction using and matrix factorization, and generative AI to identify and refine latent themes. Our approach clusters compressed tweet representations and employs generative AI to extract and articulate themes through an agentic Chain of Thought (CoT) prompting, with a secondary LLM for quality assurance. This methodology is applied to tweets from the autistic community, a group that increasingly uses social media to discuss their experiences and challenges. By automating the thematic extraction process, the aim is to uncover key insights while maintaining the richness of the original discourse. This autism case study demonstrates the utility of the proposed approach in improving thematic analysis of social media data, offering a scalable and adaptable framework that can be applied to diverse contexts. The results highlight the potential of combining machine learning and Generative AI to enhance the depth and accuracy of theme identification in online communities. 

**Abstract (ZH)**: 基于预训练语言模型嵌入、维度减少、矩阵分解和生成AI的主题分析新方法在自闭症社群社交媒体帖子中的应用 

---
# District Vitality Index Using Machine Learning Methods for Urban Planners 

**Title (ZH)**: 基于机器学习方法的城市活力指数研究 

**Authors**: Sylvain Marcoux, Jean-Sébastien Dessureault  

**Link**: [PDF](https://arxiv.org/pdf/2503.01878)  

**Abstract**: City leaders face critical decisions regarding budget allocation and investment priorities. How can they identify which city districts require revitalization? To address this challenge, a Current Vitality Index and a Long-Term Vitality Index are proposed. These indexes are based on a carefully curated set of indicators. Missing data is handled using K-Nearest Neighbors imputation, while Random Forest is employed to identify the most reliable and significant features. Additionally, k-means clustering is utilized to generate meaningful data groupings for enhanced monitoring of Long-Term Vitality. Current vitality is visualized through an interactive map, while Long-Term Vitality is tracked over 15 years with predictions made using Multilayer Perceptron or Linear Regression. The results, approved by urban planners, are already promising and helpful, with the potential for further improvement as more data becomes available. This paper proposes leveraging machine learning methods to optimize urban planning and enhance citizens' quality of life. 

**Abstract (ZH)**: 城市领导者面临关于预算分配和投资优先级的关键决策。如何确定哪些城市区域需要 revitalization? 为应对这一挑战，本文提出了当前活力指数和长期活力指数。这些指数基于精心挑选的一系列指标。缺失数据使用K-最近邻插补，而随机森林被用于识别最可靠和显著的特征。此外，K-means聚类用于生成有意义的数据组，以增强对长期活力的监控。当前活力通过互动地图可视化，而长期活力则通过15年的跟踪和使用多层感知器或线性回归做出的预测来跟踪。结果得到了城市规划者的批准，初步结果显示出希望并具有提升潜力，随着更多数据的可用，仍有进一步改进的空间。本文提出利用机器学习方法来优化城市规划并提升市民生活质量。 

---
# Starjob: Dataset for LLM-Driven Job Shop Scheduling 

**Title (ZH)**: Starjob: 由大规模语言模型驱动的车间调度数据集 

**Authors**: Henrik Abgaryan, Tristan Cazenave, Ararat Harutyunyan  

**Link**: [PDF](https://arxiv.org/pdf/2503.01877)  

**Abstract**: Large Language Models (LLMs) have shown remarkable capabilities across various domains, but their potential for solving combinatorial optimization problems remains largely unexplored. In this paper, we investigate the applicability of LLMs to the Job Shop Scheduling Problem (JSSP), a classic challenge in combinatorial optimization that requires efficient job allocation to machines to minimize makespan. To this end, we introduce Starjob, the first supervised dataset for JSSP, comprising 130k instances specifically designed for training LLMs. Leveraging this dataset, we fine-tune the LLaMA 8B 4-bit quantized model with the LoRA method to develop an end-to-end scheduling approach. Our evaluation on standard benchmarks demonstrates that the proposed LLM-based method not only surpasses traditional Priority Dispatching Rules (PDRs) but also achieves notable improvements over state-of-the-art neural approaches like L2D, with an average improvement of 15.36% on DMU and 7.85% on Taillard benchmarks. These results highlight the untapped potential of LLMs in tackling combinatorial optimization problems, paving the way for future advancements in this area. 

**Abstract (ZH)**: 大型语言模型（LLMs）在各种领域展现了卓越的能力，但在解决组合优化问题方面的潜力尚未充分利用。本文 investigation 了 LLMs 在工件车间调度问题（JSSP）中的适用性，JSSP 是组合优化中的一个经典挑战，涉及高效地将工件分配给机器以最小化生产周期。为此，我们引入了 Starjob，这是第一个针对 JSSP 的监督数据集，包含 130,000 个专门设计用于训练 LLMs 的实例。借助该数据集，我们使用 LoRA 方法对量化后的 LLaMA 8B 模型进行微调，开发出一个端到端的调度方法。在标准基准上的评估结果显示，提出的基于 LLM 的方法不仅超越了传统的优先级调度规则（PDRs），还在最新的神经方法 L2D 上取得了显著改进，DMU 基准平均改进 15.36%，Taillard 基准平均改进 7.85%。这些结果突显了 LLMs 在解决组合优化问题方面的未充分利用的潜力，为该领域的未来进步铺平了道路。 

---
# Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement 

**Title (ZH)**: 时间序列多任务问答/context增强 

**Authors**: Yaxuan Kong, Yiyuan Yang, Yoontae Hwang, Wenjie Du, Stefan Zohren, Zhangyang Wang, Ming Jin, Qingsong Wen  

**Link**: [PDF](https://arxiv.org/pdf/2503.01875)  

**Abstract**: Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-MQA), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset containing $\sim$200k question-answer pairs derived from diverse time series spanning environment, traffic, etc. This comprehensive resource covers various time series lengths and promotes robust model development. We further demonstrate how continually pre-training large language models (Mistral 7B, Llama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning capabilities, moving beyond mere numeric tasks and enabling more advanced and intuitive interactions with temporal data. The complete TSQA dataset, models, executable codes, user study questionnaires for evaluation, and results have all been open-sourced. 

**Abstract (ZH)**: 时间序列多任务问答：跨多个时间序列任务的自然语言查询与推理 

---
# CABS: Conflict-Aware and Balanced Sparsification for Enhancing Model Merging 

**Title (ZH)**: 冲突感知和平衡稀疏化方法以增强模型融合 

**Authors**: Zongzhen Yang, Binhang Qi, Hailong Sun, Wenrui Long, Ruobing Zhao, Xiang Gao  

**Link**: [PDF](https://arxiv.org/pdf/2503.01874)  

**Abstract**: Model merging based on task vectors, i.e., the parameter differences between fine-tuned models and a shared base model, provides an efficient way to integrate multiple task-specific models into a multitask model without retraining. Recent works have endeavored to address the conflicts between task vectors, one of the significant challenges faced by model merging, through sparsification; however, two issues significantly limit their performance: high parameter overlap and unbalanced weight distribution. To address these issues, we propose a simple, yet effective framework called CABS (Conflict-Aware and Balanced Sparsification), consisting of Conflict-Aware Sparsification (CA) and Balanced Sparsification (BS). CA can reduce parameter overlap by applying masks during sequential pruning, ensuring that each task vector retains distinct, non-overlapping parameters. BS leverages $n$: $m$ pruning to preserve critical weights while maintaining an even distribution across layers. Our comprehensive experiments demonstrate that CABS outperforms state-of-the-art methods across diverse tasks and model sizes. 

**Abstract (ZH)**: 基于任务向量的模型合并，即微调模型与共享基模型参数差异的合并，提供了一种在不重新训练的情况下将多个任务特定模型集成到多任务模型中的高效方式。为了应对模型合并中任务向量之间的冲突这一重大挑战，近期研究尝试通过稀疏化进行解决；然而，高参数重叠和权重分布不平衡显著限制了其性能。为了解决这些问题，我们提出了一种名为CABS（冲突意识和平衡稀疏化）的简单而有效的框架，包括冲突意识稀疏化（CA）和平衡稀疏化（BS）。CA通过在顺序剪枝过程中应用掩码来减少参数重叠，确保每个任务向量保留独特的非重叠参数。BS利用$n:m$剪枝来保留关键权重，并在各层中维持权重分布的均衡。我们的全面实验表明，CABS在多种任务和模型规模上优于现有方法。 

---
# Online Pseudo-average Shifting Attention(PASA) for Robust Low-precision LLM Inference: Algorithms and Numerical Analysis 

**Title (ZH)**: 基于在线伪平均转移注意力(PASA)的鲁棒低精度大语言模型推理：算法与数值分析 

**Authors**: Long Cheng, Qichen Liao, Fan Wu, Junlin Mu, Tengfei Han, Zhe Qiu, Lianqiang Li, Tianyi Liu, Fangzheng Miao, Keming Gao, Liang Wang, Zhen Zhang, Qiande Yin  

**Link**: [PDF](https://arxiv.org/pdf/2503.01873)  

**Abstract**: Attention calculation is extremely time-consuming for long-sequence inference tasks, such as text or image/video generation, in large models. To accelerate this process, we developed a low-precision, mathematically-equivalent algorithm called PASA, based on Flash Attention. PASA introduces two novel techniques: online pseudo-average shifting and global recovering. These techniques enable the use of half-precision computation throughout the Flash Attention process without incurring overflow instability or unacceptable numerical accuracy loss. This algorithm enhances performance on memory-restricted AI hardware architectures, such as the Ascend Neural-network Processing Unit(NPU), by reducing data movement and increasing computational FLOPs. The algorithm is validated using both designed random benchmarks and real large models. We find that the large bias and amplitude of attention input data are critical factors contributing to numerical overflow ($>65504$ for half precision) in two different categories of large models (Qwen2-7B language models and Stable-Video-Diffusion multi-modal models). Specifically, overflow arises due to the large bias in the sequence dimension and the resonance mechanism between the query and key in the head dimension of the Stable-Video-Diffusion models. The resonance mechanism is defined as phase coincidence or 180-degree phase shift between query and key matrices. It will remarkably amplify the element values of attention score matrix. This issue also applies to the Qwen models. Additionally, numerical accuracy is assessed through root mean square error (RMSE) and by comparing the final generated texts and videos to those produced using high-precision attention. 

**Abstract (ZH)**: 基于Flash Attention的PASA算法：一种低精度加速注意力计算的方法 

---
# FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance 

**Title (ZH)**: FairGen：通过自适应潜在引导控制敏感属性在扩散模型中生成公正的内容 

**Authors**: Mintong Kang, Vinayshekhar Bannihatti Kumar, Shamik Roy, Abhishek Kumar, Sopan Khosla, Balakrishnan Murali Narayanaswamy, Rashmi Gangadharaiah  

**Link**: [PDF](https://arxiv.org/pdf/2503.01872)  

**Abstract**: Text-to-image diffusion models often exhibit biases toward specific demographic groups, such as generating more males than females when prompted to generate images of engineers, raising ethical concerns and limiting their adoption. In this paper, we tackle the challenge of mitigating generation bias towards any target attribute value (e.g., "male" for "gender") in diffusion models while preserving generation quality. We propose FairGen, an adaptive latent guidance mechanism which controls the generation distribution during inference. In FairGen, a latent guidance module dynamically adjusts the diffusion process to enforce specific attributes, while a memory module tracks the generation statistics and steers latent guidance to align with the targeted fair distribution of the attribute values. Further, given the limitations of existing datasets in comprehensively assessing bias in diffusion models, we introduce a holistic bias evaluation benchmark HBE, covering diverse domains and incorporating complex prompts across various applications. Extensive evaluations on HBE and Stable Bias datasets demonstrate that FairGen outperforms existing bias mitigation approaches, achieving substantial bias reduction (e.g., 68.5% gender bias reduction on Stable Diffusion 2). Ablation studies highlight FairGen's ability to flexibly and precisely control generation distribution at any user-specified granularity, ensuring adaptive and targeted bias mitigation. 

**Abstract (ZH)**: 面向任意目标属性值的文本到图像扩散模型公平生成机制及全面偏倚评估基准HBE 

---
# Data Augmentation for Instruction Following Policies via Trajectory Segmentation 

**Title (ZH)**: 基于轨迹分割的指令跟随策略数据增强方法 

**Authors**: Niklas Höpner, Ilaria Tiddi, Herke van Hoof  

**Link**: [PDF](https://arxiv.org/pdf/2503.01871)  

**Abstract**: The scalability of instructable agents in robotics or gaming is often hindered by limited data that pairs instructions with agent trajectories. However, large datasets of unannotated trajectories containing sequences of various agent behaviour (play trajectories) are often available. In a semi-supervised setup, we explore methods to extract labelled segments from play trajectories. The goal is to augment a small annotated dataset of instruction-trajectory pairs to improve the performance of an instruction-following policy trained downstream via imitation learning. Assuming little variation in segment length, recent video segmentation methods can effectively extract labelled segments. To address the constraint of segment length, we propose Play Segmentation (PS), a probabilistic model that finds maximum likely segmentations of extended subsegments, while only being trained on individual instruction segments. Our results in a game environment and a simulated robotic gripper setting underscore the importance of segmentation; randomly sampled segments diminish performance, while incorporating labelled segments from PS improves policy performance to the level of a policy trained on twice the amount of labelled data. 

**Abstract (ZH)**: 指令可执行代理在机器人学或游戏中的可扩展性常受限于指令与代理轨迹配对数据的有限性。然而，通常有大量的未标注轨迹数据包含各种代理行为序列（游戏轨迹）。在半监督设置中，我们探索从游戏轨迹中提取标注片段的方法。目标是扩展一个小型标注数据集，以通过模仿学习增强指令跟随策略的性能。假设片段长度变化不大，近期的视频分割方法可以有效提取标注片段。为了解决片段长度的限制，我们提出了Play Segmentation (PS)，一种概率模型，能够在仅使用个体指令片段进行训练的情况下找到最有可能的片段划分。我们的实验结果在游戏环境和模拟的机器人夹持器设置中强调了分割的重要性；随机抽取的片段降低了性能，而结合PS生成的标注片段可以提升策略性能，使其与在两倍标注数据上训练的策略性能相当。 

---
# Can Large Language Models Extract Customer Needs as well as Professional Analysts? 

**Title (ZH)**: 大型语言模型能否像专业分析师一样提取客户需求？ 

**Authors**: Artem Timoshenko, Chengfeng Mao, John R. Hauser  

**Link**: [PDF](https://arxiv.org/pdf/2503.01870)  

**Abstract**: Identifying customer needs (CNs) is important for product management, product development, and marketing. Applications rely on professional analysts interpreting textual data (e.g., interview transcripts, online reviews) to understand the nuances of customer experience and concisely formulate "jobs to be done." The task is cognitively complex and time-consuming. Current practice facilitates the process with keyword search and machine learning but relies on human judgment to formulate CNs. We examine whether Large Language Models (LLMs) can automatically extract CNs. Because evaluating CNs requires professional judgment, we partnered with a marketing consulting firm to conduct a blind study of CNs extracted by: (1) a foundational LLM with prompt engineering only (Base LLM), (2) an LLM fine-tuned with professionally identified CNs (SFT LLM), and (3) professional analysts. The SFT LLM performs as well as or better than professional analysts when extracting CNs. The extracted CNs are well-formulated, sufficiently specific to identify opportunities, and justified by source content (no hallucinations). The SFT LLM is efficient and provides more complete coverage of CNs. The Base LLM was not sufficiently accurate or specific. Organizations can rely on SFT LLMs to reduce manual effort, enhance the precision of CN articulation, and provide improved insight for innovation and marketing strategy. 

**Abstract (ZH)**: 基于大型语言模型自动提取客户需要的研究 

---
# Systems and Algorithms for Convolutional Multi-Hybrid Language Models at Scale 

**Title (ZH)**: 大规模卷积多混合语言模型的系统与算法 

**Authors**: Jerome Ku, Eric Nguyen, David W. Romero, Garyk Brixi, Brandon Yang, Anton Vorontsov, Ali Taghibakhshi, Amy X. Lu, Dave P. Burke, Greg Brockman, Stefano Massaroli, Christopher Ré, Patrick D. Hsu, Brian L. Hie, Stefano Ermon, Michael Poli  

**Link**: [PDF](https://arxiv.org/pdf/2503.01868)  

**Abstract**: We introduce convolutional multi-hybrid architectures, with a design grounded on two simple observations. First, operators in hybrid models can be tailored to token manipulation tasks such as in-context recall, multi-token recall, and compression, with input-dependent convolutions and attention offering complementary performance. Second, co-designing convolution operators and hardware-aware algorithms enables efficiency gains in regimes where previous alternative architectures struggle to surpass Transformers. At the 40 billion parameter scale, we train end-to-end 1.2 to 2.9 times faster than optimized Transformers, and 1.1 to 1.4 times faster than previous generation hybrids. On H100 GPUs and model width 4096, individual operators in the proposed multi-hybrid StripedHyena 2 architecture achieve two-fold throughput improvement over linear attention and state-space models. Multi-hybrids excel at sequence modeling over byte-tokenized data, as demonstrated by the Evo 2 line of models. We discuss the foundations that enable these results, including architecture design, overlap-add blocked kernels for tensor cores, and dedicated all-to-all and point-to-point context parallelism strategies. 

**Abstract (ZH)**: 我们介绍了基于两项简单观察设计的卷积多混合架构。首先，混合模型中的操作可以针对诸如上下文召回、多令牌召回和压缩等令牌操作任务进行定制，输入依赖的卷积和注意力提供了互补的性能。其次，卷积操作与硬件感知算法的协同设计能够在先前替代架构难以超越Transformer的领域中实现效率提升。在400亿参数规模下，我们端到端训练的速度比优化后的Transformer快1.2到2.9倍，比上一代混合模型快1.1到1.4倍。在H100 GPU和模型宽度4096的情况下，所提出的多混合架构StripedHyena 2中提出的各个操作在吞吐量上比线性注意力和状态空间模型提高了两倍。多混合架构在字节分片数据序列建模中表现出色，Evolution 2系列模型证明了这一点。我们讨论了这些结果的基础，包括架构设计、张量核的重叠添加块化策略以及专用的全对全和点对点上下文并行策略。 

---
# Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints 

**Title (ZH)**: 引导而非强制：通过去除多余约束增强对大语言模型的越狱攻击的迁移性 

**Authors**: Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01865)  

**Abstract**: Jailbreaking attacks can effectively induce unsafe behaviors in Large Language Models (LLMs); however, the transferability of these attacks across different models remains limited. This study aims to understand and enhance the transferability of gradient-based jailbreaking methods, which are among the standard approaches for attacking white-box models. Through a detailed analysis of the optimization process, we introduce a novel conceptual framework to elucidate transferability and identify superfluous constraints-specifically, the response pattern constraint and the token tail constraint-as significant barriers to improved transferability. Removing these unnecessary constraints substantially enhances the transferability and controllability of gradient-based attacks. Evaluated on Llama-3-8B-Instruct as the source model, our method increases the overall Transfer Attack Success Rate (T-ASR) across a set of target models with varying safety levels from 18.4% to 50.3%, while also improving the stability and controllability of jailbreak behaviors on both source and target models. 

**Abstract (ZH)**: Jailbreaking 攻击可以有效地诱导大型语言模型（LLMs）执行不安全行为；然而，这些攻击在不同模型之间的可转移性仍然有限。本研究旨在理解并增强基于梯度的 Jailbreaking 方法的可转移性，这些方法是攻击白盒模型的标准方法之一。通过详细分析优化过程，我们引入了一个新的概念框架来阐明可转移性，并识别出特定的回答模式约束和标记尾部约束作为提高可转移性的主要障碍。去除这些不必要的约束显著增强了基于梯度的攻击的可转移性和可控性。在以 Llama-3-8B-Instruct 作为源模型的评估中，我们的方法将一组具有不同安全级别的目标模型的整体 Transfer Attack Success Rate (T-ASR) 从 18.4% 提高到了 50.3%，同时在源模型和目标模型上也提高了 Jailbreak 行为的稳定性和可控性。 

---
# Larger or Smaller Reward Margins to Select Preferences for Alignment? 

**Title (ZH)**: 更大的奖励边际或更小的奖励边际以选择对齐的偏好？ 

**Authors**: Kexin Huang, Junkang Wu, Ziqian Chen, Xue Wang, Jinyang Gao, Bolin Ding, Jiancan Wu, Xiangnan He, Xiang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.01864)  

**Abstract**: Preference learning is critical for aligning large language models (LLMs) with human values, with the quality of preference datasets playing a crucial role in this process. While existing metrics primarily assess data quality based on either explicit or implicit reward margins, they often provide contradictory evaluations for the same data. To address this issue, we introduce the alignment potential metric, which quantifies the gap from the model's current implicit reward margin to the target explicit reward margin, thereby estimating the model's potential to align with the preference data. Empirical results demonstrate that training on data selected by this metric consistently enhances alignment performance, surpassing existing metrics across different base models and optimization objectives. Furthermore, our method extends to self-play data generation frameworks, where the metric is used to identify high-quality data within the self-generated content by LLMs. Under this data generation scenario, our method surpasses current state-of-the-art (SOTA) results across various training settings and demonstrates continuous improvements in alignment performance as dataset size and training iterations increase. 

**Abstract (ZH)**: 偏好学习对于使大规模语言模型与人类价值观对齐至关重要，偏好数据集的质量在这一过程中起着关键作用。虽然现有的评估指标主要基于显式或隐式奖励边际来评估数据质量，但它们往往对同一数据给出矛盾的评估。为了解决这一问题，我们引入了对齐潜力指标，该指标量化了模型当前隐式奖励边际与目标显式奖励边际之间的差距，从而估计模型与偏好数据对齐的潜在能力。实验结果表明，使用该指标选择的数据训练可以一致地提高对齐性能，在不同的基础模型和优化目标下超越现有指标。此外，我们的方法还适用于自我对弈数据生成框架，在这种数据生成场景中，该指标用于识别LLM自动生成内容中的高质量数据。在各种训练设置下，我们的方法超越了当前的最先进结果，并随着数据集规模和训练迭代次数的增加，展示了对齐性能的持续改进。 

---
# Vision Language Models in Medicine 

**Title (ZH)**: 医学中的视觉语言模型 

**Authors**: Beria Chingnabe Kalpelbe, Angel Gabriel Adaambiik, Wei Peng  

**Link**: [PDF](https://arxiv.org/pdf/2503.01863)  

**Abstract**: With the advent of Vision-Language Models (VLMs), medical artificial intelligence (AI) has experienced significant technological progress and paradigm shifts. This survey provides an extensive review of recent advancements in Medical Vision-Language Models (Med-VLMs), which integrate visual and textual data to enhance healthcare outcomes. We discuss the foundational technology behind Med-VLMs, illustrating how general models are adapted for complex medical tasks, and examine their applications in healthcare. The transformative impact of Med-VLMs on clinical practice, education, and patient care is highlighted, alongside challenges such as data scarcity, narrow task generalization, interpretability issues, and ethical concerns like fairness, accountability, and privacy. These limitations are exacerbated by uneven dataset distribution, computational demands, and regulatory hurdles. Rigorous evaluation methods and robust regulatory frameworks are essential for safe integration into healthcare workflows. Future directions include leveraging large-scale, diverse datasets, improving cross-modal generalization, and enhancing interpretability. Innovations like federated learning, lightweight architectures, and Electronic Health Record (EHR) integration are explored as pathways to democratize access and improve clinical relevance. This review aims to provide a comprehensive understanding of Med-VLMs' strengths and limitations, fostering their ethical and balanced adoption in healthcare. 

**Abstract (ZH)**: 随视觉语言模型（VLMs）的出现，医疗人工智能（AI）经历了显著的技术进步和范式转变。本文综述了近期在医学视觉语言模型（Med-VLMs）方面的进展，这些模型将视觉和文本数据结合起来以提升医疗保健结果。文中讨论了Med-VLMs的基础技术，展示了通用模型如何适应复杂的医疗任务，并探讨了它们在医疗保健中的应用。Med-VLMs在临床实践、教育和患者护理中的变革性影响及其面临的挑战，如数据稀缺性、任务泛化不足、可解释性问题以及公平性、可问责性和隐私等伦理问题得到了强调。这些限制因数据集分布不均、计算需求和监管障碍而加剧。严格的评估方法和健全的监管框架是实现Med-VLMs安全集成到医疗工作流程中的关键。未来方向包括利用大规模多样化的数据集、提高跨模态泛化能力和增强可解释性。探索联邦学习、轻量级架构和电子健康记录（EHR）集成等创新作为使医学生物语言模型民主化和临床相关性提升的途径。本文旨在提供Med-VLMs的强项和局限性的全面理解，促进其在医疗保健中的道德和平衡采用。 

---
# Towards Enterprise-Ready Computer Using Generalist Agent 

**Title (ZH)**: 面向企业应用的通用型智能体 

**Authors**: Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov, Ido Levy, Aviad Sela, Asaf Adi, Nir Mashkif  

**Link**: [PDF](https://arxiv.org/pdf/2503.01861)  

**Abstract**: This paper presents our ongoing work toward developing an enterprise-ready Computer Using Generalist Agent (CUGA) system. Our research highlights the evolutionary nature of building agentic systems suitable for enterprise environments. By integrating state-of-the-art agentic AI techniques with a systematic approach to iterative evaluation, analysis, and refinement, we have achieved rapid and cost-effective performance gains, notably reaching a new state-of-the-art performance on the WebArena benchmark. We detail our development roadmap, the methodology and tools that facilitated rapid learning from failures and continuous system refinement, and discuss key lessons learned and future challenges for enterprise adoption. 

**Abstract (ZH)**: 本文介绍了我们正在开发的企业级通用智能体（CUGA）系统的持续工作。我们的研究突显了构建适合企业环境的代理系统的发展性质。通过将最先进的代理AI技术与系统化的迭代评估、分析和改进方法相结合，我们实现了快速且成本效益高的性能提升，特别是在WebArena基准测试中达到了新的前沿性能。我们详细介绍了我们的开发路线图、促进快速从失败中学习并持续系统改进的方法和工具，以及讨论了企业采用的关键经验教训和未来挑战。 

---
# Optimizing Retrieval-Augmented Generation of Medical Content for Spaced Repetition Learning 

**Title (ZH)**: 优化基于检索增强生成的医学内容间隔重复学习检索算法 

**Authors**: Jeremi I. Kaczmarek, Jakub Pokrywka, Krzysztof Biedalak, Grzegorz Kurzyp, Łukasz Grzybowski  

**Link**: [PDF](https://arxiv.org/pdf/2503.01859)  

**Abstract**: Advances in Large Language Models revolutionized medical education by enabling scalable and efficient learning solutions. This paper presents a pipeline employing Retrieval-Augmented Generation (RAG) system to prepare comments generation for Poland's State Specialization Examination (PES) based on verified resources. The system integrates these generated comments and source documents with a spaced repetition learning algorithm to enhance knowledge retention while minimizing cognitive overload. By employing a refined retrieval system, query rephraser, and an advanced reranker, our modified RAG solution promotes accuracy more than efficiency. Rigorous evaluation by medical annotators demonstrates improvements in key metrics such as document relevance, credibility, and logical coherence of generated content, proven by a series of experiments presented in the paper. This study highlights the potential of RAG systems to provide scalable, high-quality, and individualized educational resources, addressing non-English speaking users. 

**Abstract (ZH)**: 大型语言模型的发展 revolutionized 医学教育，通过提供可扩展和高效的學習解決方案。本文提出了一种基于验证资源的管线，采用检索增强生成（RAG）系统为波兰国家专门化考试（PES）准备评论生成。该系统将生成的评论和源文档与间隔重复学习算法结合，以提高知识保留并减轻认知负担。通过采用改进的检索系统、查询重写器和高级重排序器，我们修改后的RAG解决方案更注重准确性而非效率。医学注释者的严格评估表明，在文档相关性、可信度和生成内容的逻辑连贯性等关键指标上取得了改进，这由论文中介绍的一系列实验所证明。本研究强调了RAG系统在提供可扩展、高质量和个性化教育资源方面的潜力，以满足非英语母语用户的需求。 

---
# A Review of Artificial Intelligence Impacting Statistical Process Monitoring and Future Directions 

**Title (ZH)**: 人工智能影响统计过程监控的综述及未来方向 

**Authors**: Shing I Chang, Parviz Ghafariasl  

**Link**: [PDF](https://arxiv.org/pdf/2503.01858)  

**Abstract**: It has been 100 years since statistical process control (SPC) or statistical process monitoring (SPM) was first introduced for production processes and later applied to service, healthcare, and other industries. The techniques applied to SPM applications are mostly statistically oriented. Recent advances in Artificial Intelligence (AI) have reinvigorated the imagination of adopting AI for SPM applications. This manuscript begins with a concise review of the historical development of the statistically based SPM methods. Next, this manuscript explores AI and Machine Learning (ML) algorithms and methods applied in various SPM applications, addressing quality characteristics of univariate, multivariate, profile, and image. These AI methods can be classified into the following categories: classification, pattern recognition, time series applications, and generative AI. Specifically, different kinds of neural networks, such as artificial neural networks (ANN), convolutional neural networks (CNN), recurrent neural networks (RNN), and generative adversarial networks (GAN), are among the most implemented AI methods impacting SPM. Finally, this manuscript outlines a couple of future directions that harness the potential of the Large Multimodal Model (LMM) for advancing SPM research and applications in complex systems. The ultimate objective is to transform statistical process monitoring (SPM) into smart process control (SMPC), where corrective actions are autonomously implemented to either prevent quality issues or restore process performance. 

**Abstract (ZH)**: 统计过程控制（SPC）或统计过程监控（SPM）自首次应用于生产过程至今已有一百周年，并后被应用于服务、医疗及其他行业。用于SPM应用的技术大多基于统计方法。近年来，人工智能（AI）的发展重新激发了采用AI进行SPM应用的想象。本文首先简要回顾了基于统计方法的SPM方法的发展历史。接着，本文探讨了应用于各种SPM应用的AI和机器学习（ML）算法与方法，涉及单一变量、多变量、特性和图像的质量特性。这些AI方法可以分为分类、模式识别、时间序列应用和生成性AI等类别。特别是，各种类型的神经网络，如人工神经网络（ANN）、卷积神经网络（CNN）、循环神经网络（RNN）和生成对抗网络（GAN），是影响SPM应用最多的AI方法之一。最后，本文概述了利用大型多模态模型（LMM）潜力以推动SPM研究和复杂系统应用的若干未来方向。最终目标是将统计过程监控（SPM）转变为智能过程控制（SMPC），其中自动实施纠正措施以预防质量问题或恢复过程性能。 

---
# A Comprehensive Survey of Machine Unlearning Techniques for Large Language Models 

**Title (ZH)**: 大规模语言模型的全面回顾：机器卸载技术 

**Authors**: Jiahui Geng, Qing Li, Herbert Woisetschlaeger, Zongxiong Chen, Yuxia Wang, Preslav Nakov, Hans-Arno Jacobsen, Fakhri Karray  

**Link**: [PDF](https://arxiv.org/pdf/2503.01854)  

**Abstract**: This study investigates the machine unlearning techniques within the context of large language models (LLMs), referred to as \textit{LLM unlearning}. LLM unlearning offers a principled approach to removing the influence of undesirable data (e.g., sensitive or illegal information) from LLMs, while preserving their overall utility without requiring full retraining. Despite growing research interest, there is no comprehensive survey that systematically organizes existing work and distills key insights; here, we aim to bridge this gap. We begin by introducing the definition and the paradigms of LLM unlearning, followed by a comprehensive taxonomy of existing unlearning studies. Next, we categorize current unlearning approaches, summarizing their strengths and limitations. Additionally, we review evaluation metrics and benchmarks, providing a structured overview of current assessment methodologies. Finally, we outline promising directions for future research, highlighting key challenges and opportunities in the field. 

**Abstract (ZH)**: 本研究探讨了大型语言模型（LLMs）中的机器遗忘技术，称为“LLM遗忘”。LLM遗忘为从LLMs中去除不良数据（例如，敏感或非法信息）的影响提供了原则性的方法，同时保留其整体效用，无需进行全面重新训练。尽管研究兴趣日益增长，但目前尚无系统整理现有工作的综合综述，提炼关键洞察； herein we aim to bridge this gap. 首先，我们将介绍LLM遗忘的定义和范式，随后进行现有遗忘研究的全面分类。接下来，我们将分类当前的遗忘方法，总结它们的优势和局限性。此外，我们将回顾评估指标和基准，提供当前评估方法的结构化概述。最后，我们将阐明未来研究的有希望方向，突出该领域的关键挑战和机会。 

---
# Efficient Diffusion as Low Light Enhancer 

**Title (ZH)**: 高效扩散作为低光增强器 

**Authors**: Guanzhou Lan, Qianli Ma, Yuqi Yang, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2410.12346)  

**Abstract**: The computational burden of the iterative sampling process remains a major challenge in diffusion-based Low-Light Image Enhancement (LLIE). Current acceleration methods, whether training-based or training-free, often lead to significant performance degradation, highlighting the trade-off between performance and efficiency. In this paper, we identify two primary factors contributing to performance degradation: fitting errors and the inference gap. Our key insight is that fitting errors can be mitigated by linearly extrapolating the incorrect score functions, while the inference gap can be reduced by shifting the Gaussian flow to a reflectance-aware residual space. Based on the above insights, we design Reflectance-Aware Trajectory Refinement (RATR) module, a simple yet effective module to refine the teacher trajectory using the reflectance component of images. Following this, we introduce \textbf{Re}flectance-aware \textbf{D}iffusion with \textbf{Di}stilled \textbf{T}rajectory (\textbf{ReDDiT}), an efficient and flexible distillation framework tailored for LLIE. Our framework achieves comparable performance to previous diffusion-based methods with redundant steps in just 2 steps while establishing new state-of-the-art (SOTA) results with 8 or 4 steps. Comprehensive experimental evaluations on 10 benchmark datasets validate the effectiveness of our method, consistently outperforming existing SOTA methods. 

**Abstract (ZH)**: 反射-aware 扩散与提炼轨迹蒸馏 (ReDDiT) 用于低光图像增强 

---
