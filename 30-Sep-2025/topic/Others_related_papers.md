# SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions 

**Title (ZH)**: SafeFlowMatcherï¼šåŸºäºæµåŠ¨åŒ¹é…ä¸æ§åˆ¶éšœç¢å‡½æ•°çš„å®‰å…¨å¿«é€Ÿè§„åˆ’ 

**Authors**: Jeongyong Yang, Seunghwan Jang, Soojean Han  

**Link**: [PDF](https://arxiv.org/pdf/2509.24243)  

**Abstract**: Generative planners based on flow matching (FM) can produce high-quality paths in one or a few ODE steps, but their sampling dynamics offer no formal safety guarantees and can yield incomplete paths near constraints. We present SafeFlowMatcher, a planning framework that couples FM with control barrier functions (CBFs) to achieve both real-time efficiency and certified safety. SafeFlowMatcher uses a two-phase prediction-correction (PC) integrator: (i) a prediction phase integrates the learned FM once (or a few steps) to obtain a candidate path without intervention; (ii) a correction phase refines this path with a vanishing time-scaled vector field and a CBF-based quadratic program that minimally perturbs the vector field. We prove a barrier certificate for the resulting flow system, establishing forward invariance of a robust safe set and finite-time convergence to the safe set. By enforcing safety only on the executed path (rather than on all intermediate latent paths), SafeFlowMatcher avoids distributional drift and mitigates local trap problems. Across maze navigation and locomotion benchmarks, SafeFlowMatcher attains faster, smoother, and safer paths than diffusion- and FM-based baselines. Extensive ablations corroborate the contributions of the PC integrator and the barrier certificate. 

**Abstract (ZH)**: åŸºäºæµåŒ¹é…çš„ç”Ÿæˆå¼è§„åˆ’å™¨ç»“åˆæ§åˆ¶éšœç¢å‡½æ•°çš„å®‰å…¨æµåŒ¹é…è§„åˆ’æ¡†æ¶ 

---
# Towards Tighter Convex Relaxation of Mixed-integer Programs: Leveraging Logic Network Flow for Task and Motion Planning 

**Title (ZH)**: åŸºäºé€»è¾‘ç½‘ç»œæµçš„æ··åˆæ•´æ•°è§„åˆ’ tighter å‡¸æ¾å¼›æ–¹æ³•ç ”ç©¶ï¼šä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’ä¸­çš„åº”ç”¨ 

**Authors**: Xuan Lin, Jiming Ren, Yandong Luo, Weijun Xie, Ye Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2509.24235)  

**Abstract**: This paper proposes an optimization-based task and motion planning framework, named "Logic Network Flow", that integrates temporal logic specifications into mixed-integer programs for efficient robot planning. Inspired by the Graph-of-Convex-Sets formulation, temporal predicates are encoded as polyhedron constraints on each edge of a network flow model, instead of as constraints between nodes in traditional Logic Tree formulations. We further propose a network-flow-based Fourier-Motzkin elimination procedure that removes continuous flow variables while preserving convex relaxation tightness, leading to provably tighter convex relaxations and fewer constraints than Logic Tree formulations. For temporal logic motion planning with piecewise-affine dynamic systems, comprehensive experiments across vehicle routing, multi-robot coordination, and temporal logic control on dynamical systems using point mass and linear inverted pendulum models demonstrate computational speedups of up to several orders of magnitude. Hardware demonstrations with quadrupedal robots validate real-time replanning capabilities under dynamically changing environmental conditions. The project website is at this https URL. 

**Abstract (ZH)**: åŸºäºä¼˜åŒ–çš„ä»»åŠ¡ä¸è¿åŠ¨è§„åˆ’æ¡†æ¶â€œé€»è¾‘ç½‘ç»œæµâ€ï¼šå°†æ—¶é—´é€»è¾‘è§„èŒƒæ•´åˆåˆ°æ··åˆæ•´æ•°è§„åˆ’ä¸­ç”¨äºé«˜æ•ˆæœºå™¨äººè§„åˆ’ 

---
# Ancestry Tree Clustering for Particle Filter Diversity Maintenance 

**Title (ZH)**: ç¥–å…ˆæ ‘èšç±»ä»¥ç»´æŠ¤ç²’å­æ»¤æ³¢å¤šæ ·æ€§ 

**Authors**: Ilari Vallivaara, Bingnan Duan, Yinhuan Dong, Tughrul Arslan  

**Link**: [PDF](https://arxiv.org/pdf/2509.24124)  

**Abstract**: We propose a method for linear-time diversity maintenance in particle filtering. It clusters particles based on ancestry tree topology: closely related particles in sufficiently large subtrees are grouped together. The main idea is that the tree structure implicitly encodes similarity without the need for spatial or other domain-specific metrics. This approach, when combined with intra-cluster fitness sharing and the protection of particles not included in a cluster, effectively prevents premature convergence in multimodal environments while maintaining estimate compactness. We validate our approach in a multimodal robotics simulation and a real-world multimodal indoor environment. We compare the performance to several diversity maintenance algorithms from the literature, including Deterministic Resampling and Particle Gaussian Mixtures. Our algorithm achieves high success rates with little to no negative effect on compactness, showing particular robustness to different domains and challenging initial conditions. 

**Abstract (ZH)**: ä¸€ç§çº¿æ€§æ—¶é—´ç²’å­æ»¤æ³¢å¤šæ ·æ€§ç»´æŠ¤æ–¹æ³•ï¼šåŸºäºç¥–å…ˆæ ‘æ‹“æ‰‘çš„ç¾¤ç»„åŒ–ç­–ç•¥ 

---
# MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control 

**Title (ZH)**: MAD-PINNï¼šä¸€ç§å®‰å…¨ä¸”æœ€ä¼˜çš„å¤šæ™ºèƒ½ä½“æ§åˆ¶å»ä¸­å¿ƒåŒ–ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ æ¡†æ¶ 

**Authors**: Manan Tayal, Aditya Singh, Shishir Kolathaya, Somil Bansal  

**Link**: [PDF](https://arxiv.org/pdf/2509.23960)  

**Abstract**: Co-optimizing safety and performance in large-scale multi-agent systems remains a fundamental challenge. Existing approaches based on multi-agent reinforcement learning (MARL), safety filtering, or Model Predictive Control (MPC) either lack strict safety guarantees, suffer from conservatism, or fail to scale effectively. We propose MAD-PINN, a decentralized physics-informed machine learning framework for solving the multi-agent state-constrained optimal control problem (MASC-OCP). Our method leverages an epigraph-based reformulation of SC-OCP to simultaneously capture performance and safety, and approximates its solution via a physics-informed neural network. Scalability is achieved by training the SC-OCP value function on reduced-agent systems and deploying them in a decentralized fashion, where each agent relies only on local observations of its neighbours for decision-making. To further enhance safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based neighbour selection strategy to prioritize safety-critical interactions, and a receding-horizon policy execution scheme that adapts to dynamic interactions while reducing computational burden. Experiments on multi-agent navigation tasks demonstrate that MAD-PINN achieves superior safety-performance trade-offs, maintains scalability as the number of agents grows, and consistently outperforms state-of-the-art baselines. 

**Abstract (ZH)**: åœ¨å¤§è§„æ¨¡å¤šAgentç³»ç»Ÿä¸­åŒæ—¶ä¼˜åŒ–å®‰å…¨æ€§å’Œæ€§èƒ½ä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ç°æœ‰çš„åŸºäºå¤šAgentå¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ã€å®‰å…¨ç­›é€‰æˆ–æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰çš„æ–¹æ³•è¦ä¹ˆç¼ºä¹ä¸¥æ ¼çš„å®‰å…¨æ€§ä¿è¯ï¼Œè¦ä¹ˆå…·æœ‰ä¿å®ˆæ€§ï¼Œè¦ä¹ˆæ— æ³•æœ‰æ•ˆæ‰©å±•ã€‚æˆ‘ä»¬æå‡ºäº†MAD-PINNï¼Œè¿™æ˜¯ä¸€ç§åˆ†å¸ƒå¼çš„ç‰©ç†ä¿¡æ¯æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè§£å†³å…·æœ‰çŠ¶æ€çº¦æŸçš„å¤šAgentæœ€ä¼˜æ§åˆ¶é—®é¢˜ï¼ˆMASC-OCPï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨SC-OCPçš„episodeå›¾è¡¨å½¢å¼é‡æ–°è¡¨è¿°æ¥åŒæ—¶æ•æ‰æ€§èƒ½å’Œå®‰å…¨æ€§ï¼Œå¹¶é€šè¿‡ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œè¿‘ä¼¼å…¶è§£ã€‚é€šè¿‡åœ¨ç¼©å‡Agentçš„ç³»ç»Ÿä¸­è®­ç»ƒSC-OCPä»·å€¼å‡½æ•°å¹¶åœ¨åˆ†å¸ƒå¼æ–¹å¼ä¸‹éƒ¨ç½²å®ƒä»¬ï¼Œå®ç°äº†å¯æ‰©å±•æ€§ï¼Œå…¶ä¸­æ¯ä¸ªAgentä»…ä¾èµ–äºå…¶é‚»å±…çš„å±€éƒ¨è§‚å¯Ÿæ¥è¿›è¡Œå†³ç­–ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜å®‰å…¨æ€§å’Œæ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºHamilton-Jacobiï¼ˆHJï¼‰å¯è¾¾æ€§çš„é‚»å±…é€‰æ‹©ç­–ç•¥æ¥ä¼˜å…ˆå¤„ç†å®‰å…¨å…³é”®çš„äº¤äº’ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åŸºäºåé€€è§†ç•Œçš„ç­–ç•¥æ‰§è¡Œæ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿé€‚åº”åŠ¨æ€äº¤äº’å¹¶å‡å°‘è®¡ç®—è´Ÿæ‹…ã€‚åœ¨å¤šAgentå¯¼èˆªä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMAD-PINNå®ç°äº†æ›´å¥½çš„å®‰å…¨æ€§å’Œæ€§èƒ½ trade-offsï¼Œåœ¨Agentæ•°é‡å¢åŠ æ—¶ä¿æŒäº†å¯æ‰©å±•æ€§ï¼Œå¹¶ä¸”ä¸€è‡´åœ°ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ã€‚ 

---
# Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse 

**Title (ZH)**: ä»“åº“ä¸­å¤š-agentæ‹¾å–ä¸äº¤ä»˜çš„åºåˆ—æ¢ç´¢è€… 

**Authors**: Zeyuan Zhang, Chaoran Li, Shao Zhang, Ying Wen  

**Link**: [PDF](https://arxiv.org/pdf/2509.23778)  

**Abstract**: Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of Multi-Agent Path Finding (MAPF), where agents are required to sequentially complete tasks with fixed-location pickup and delivery demands. Although learning-based methods have made progress in MAPD, they often perform poorly in warehouse-like environments with narrow pathways and long corridors when relying only on local observations for distributed decision-making. Communication learning can alleviate the lack of global information but introduce high computational complexity due to point-to-point communication. To address this challenge, we formulate MAPF as a sequence modeling problem and prove that path-finding policies under sequence modeling possess order-invariant optimality, ensuring its effectiveness in MAPD. Building on this, we propose the Sequential Pathfinder (SePar), which leverages the Transformer paradigm to achieve implicit information exchange, reducing decision-making complexity from exponential to linear while maintaining efficiency and global awareness. Experiments demonstrate that SePar consistently outperforms existing learning-based methods across various MAPF tasks and their variants, and generalizes well to unseen environments. Furthermore, we highlight the necessity of integrating imitation learning in complex maps like warehouses. 

**Abstract (ZH)**: å¤šä»£ç†å–é€ä»»åŠ¡ï¼ˆMAPDï¼‰æ˜¯å¤šä»£ç†è·¯å¾„è§„åˆ’ï¼ˆMAPFï¼‰çš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ‰©å±•ï¼Œåœ¨å…¶ä¸­ä»£ç†éœ€è¦é¡ºåºå®Œæˆå›ºå®šä½ç½®çš„å–é€ä»»åŠ¡ã€‚å°½ç®¡åŸºäºå­¦ä¹ çš„æ–¹æ³•åœ¨MAPDé¢†åŸŸå–å¾—äº†è¿›å±•ï¼Œä½†åœ¨ä¾èµ–å±€éƒ¨è§‚å¯Ÿè¿›è¡Œåˆ†å¸ƒå¼å†³ç­–çš„ä»“åº“-likeç¯å¢ƒä¸­ï¼Œå®ƒä»¬é€šå¸¸è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨ç‹­çª„é€šé“å’Œé•¿èµ°å»Šçš„ç¯å¢ƒä¸‹ã€‚é€šä¿¡å­¦ä¹ å¯ä»¥ç¼“è§£ç¼ºä¹å…¨å±€ä¿¡æ¯çš„é—®é¢˜ï¼Œä½†ç”±äºç‚¹å¯¹ç‚¹é€šä¿¡å¯¼è‡´è®¡ç®—å¤æ‚æ€§å¢åŠ ã€‚ä¸ºè§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å°†MAPFå½¢å¼åŒ–ä¸ºåºåˆ—å»ºæ¨¡é—®é¢˜ï¼Œå¹¶è¯æ˜åœ¨åºåˆ—å»ºæ¨¡ä¸‹çš„è·¯å¾„è§„åˆ’ç­–ç•¥å…·æœ‰é¡ºåºä¸å˜çš„æœ€ä¼˜æ€§ï¼Œç¡®ä¿å…¶åœ¨MAPDä¸­çš„æœ‰æ•ˆæ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†åºåˆ—è·¯å¾„è§„åˆ’è€…ï¼ˆSeParï¼‰ï¼Œå®ƒåˆ©ç”¨TransformerèŒƒå¼å®ç°éšå¼ä¿¡æ¯äº¤æ¢ï¼Œå°†å†³ç­–å¤æ‚æ€§ä»æŒ‡æ•°çº§é™ä½åˆ°çº¿æ€§çº§ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆæ€§å’Œå…¨å±€æ„è¯†ã€‚å®éªŒè¡¨æ˜ï¼ŒSeParåœ¨å„ç§MAPFä»»åŠ¡åŠå…¶å˜ä½“ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¾ˆå¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„ç¯å¢ƒä¸­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼ºè°ƒåœ¨å¤æ‚åœ°å›¾ï¼ˆå¦‚ä»“åº“ï¼‰ä¸­æ•´åˆæ¨¡ä»¿å­¦ä¹ çš„å¿…è¦æ€§ã€‚ 

---
# MDCPP: Multi-robot Dynamic Coverage Path Planning for Workload Adaptation 

**Title (ZH)**: å¤šæœºå™¨äººåŠ¨æ€è¦†ç›–è·¯å¾„è§„åˆ’ä»¥é€‚åº”å·¥ä½œè´Ÿè½½ 

**Authors**: Jun Chen, Mingjia Chen, Shinkyu Park  

**Link**: [PDF](https://arxiv.org/pdf/2509.23705)  

**Abstract**: Multi-robot Coverage Path Planning (MCPP) addresses the problem of computing paths for multiple robots to effectively cover a large area of interest. Conventional approaches to MCPP typically assume that robots move at fixed velocities, which is often unrealistic in real-world applications where robots must adapt their speeds based on the specific coverage tasks assigned to this http URL, conventional approaches often lead to imbalanced workload distribution among robots and increased completion time for coverage tasks. To address this, we introduce a novel Multi-robot Dynamic Coverage Path Planning (MDCPP) algorithm for complete coverage in two-dimensional environments. MDCPP dynamically estimates each robot's remaining workload by approximating the target distribution with Gaussian mixture models, and assigns coverage regions using a capacity-constrained Voronoi diagram. We further develop a distributed implementation of MDCPP for range-constrained robotic networks. Simulation results validate the efficacy of MDCPP, showing qualitative improvements and superior performance compared to an existing sweeping algorithm, and a quantifiable impact of communication range on coverage efficiency. 

**Abstract (ZH)**: å¤šæœºå™¨äººåŠ¨æ€è¦†ç›–è·¯å¾„è§„åˆ’ï¼ˆMDCPPï¼‰ï¼šäºŒç»´ç¯å¢ƒä¸­çš„å®Œå…¨è¦†ç›–é—®é¢˜ 

---
# Online Dynamic Goal Recognition in Gym Environments 

**Title (ZH)**: åœ¨çº¿åŠ¨æ€ç›®æ ‡è¯†åˆ«åœ¨Gymç¯å¢ƒä¸­ 

**Authors**: Shamir Matan, Elhadad Osher, Nageris Ben, Mirsky Reuth  

**Link**: [PDF](https://arxiv.org/pdf/2509.23244)  

**Abstract**: Goal Recognition (GR) is the task of inferring an agent's intended goal from partial observations of its behavior, typically in an online and one-shot setting. Despite recent advances in model-free GR, particularly in applications such as human-robot interaction, surveillance, and assistive systems, the field remains fragmented due to inconsistencies in benchmarks, domains, and evaluation protocols.
To address this, we introduce gr-libs (this https URL) and gr-envs (this https URL), two complementary open-source frameworks that support the development, evaluation, and comparison of GR algorithms in Gym-compatible environments. gr-libs includes modular implementations of MDP-based GR baselines, diagnostic tools, and evaluation utilities. gr-envs provides a curated suite of environments adapted for dynamic and goal-directed behavior, along with wrappers that ensure compatibility with standard reinforcement learning toolkits. Together, these libraries offer a standardized, extensible, and reproducible platform for advancing GR research. Both packages are open-source and available on GitHub and PyPI. 

**Abstract (ZH)**: Goal Recognition: A Standardized Framework for Developing and Evaluating Goal Recognition Algorithms 

---
# DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes 

**Title (ZH)**: DBF-MA: ä¸€ç§ç”¨äºå¤šAgentè‡ªä¸»ç«é€Ÿè¶…è½¦çš„å·®åˆ†è´å¶æ–¯è¿‡æ»¤è§„åˆ’å™¨ 

**Authors**: Trent Weiss, Amar Kulkarni, Madhur Behl  

**Link**: [PDF](https://arxiv.org/pdf/2509.22937)  

**Abstract**: A significant challenge in autonomous racing is to generate overtaking maneuvers. Racing agents must execute these maneuvers on complex racetracks with little room for error. Optimization techniques and graph-based methods have been proposed, but these methods often rely on oversimplified assumptions for collision-avoidance and dynamic constraints. In this work, we present an approach to trajectory synthesis based on an extension of the Differential Bayesian Filtering framework. Our approach for collision-free trajectory synthesis frames the problem as one of Bayesian Inference over the space of Composite Bezier Curves. Our method is derivative-free, does not require a spherical approximation of the vehicle footprint, linearization of constraints, or simplifying upper bounds on collision avoidance. We conduct a closed-loop analysis of DBF-MA and find it successfully overtakes an opponent in 87% of tested scenarios, outperforming existing methods in autonomous overtaking. 

**Abstract (ZH)**: è‡ªä¸»èµ›è½¦ä¸­çš„ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜æ˜¯å¦‚ä½•ç”Ÿæˆè¶…è¶Š maneuversã€‚èµ›è½¦ä»£ç†å¿…é¡»åœ¨å¤æ‚èµ›é“ä¸Šæ‰§è¡Œè¿™äº› maneuversï¼Œå¹¶ä¸”å‡ ä¹æ²¡æœ‰é”™è¯¯ä½™åœ°ã€‚å·²ç»æå‡ºäº†ä¼˜åŒ–æŠ€æœ¯å’Œå›¾åŸºæ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€ä¾èµ–äºç¢°æ’é¿å…å’ŒåŠ¨åŠ›å­¦çº¦æŸçš„è¿‡åº¦ç®€åŒ–å‡è®¾ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå·®åˆ†è´å¶æ–¯æ»¤æ³¢æ¡†æ¶æ‰©å±•çš„æ–¹æ³•æ¥åˆæˆè½¨è¿¹ã€‚æˆ‘ä»¬çš„ç¢°æ’è‡ªç”±è½¨è¿¹åˆæˆæ–¹æ³•å°†é—®é¢˜å»ºæ¨¡ä¸ºè´å¶æ–¯æ¨ç†åœ¨å¤åˆè´å¡å°”æ›²çº¿ç©ºé—´ä¸­çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€å¯¼æ•°ã€ä¸éœ€è¦è½¦è¾†è¶³è¿¹çš„çƒå½¢è¿‘ä¼¼ã€æ— éœ€çº¦æŸçº¿æ€§åŒ–æˆ–ç¢°æ’é¿å…çš„ç®€åŒ–ä¸Šç•Œã€‚æˆ‘ä»¬å¯¹DBF-MAè¿›è¡Œäº†é—­ç¯åˆ†æï¼Œå‘ç°è¯¥æ–¹æ³•åœ¨æµ‹è¯•åœºæ™¯ä¸­æœ‰87%çš„æƒ…å†µä¸‹æˆåŠŸè¶…è¶Šå¯¹æ‰‹ï¼Œä¼˜äºç°æœ‰æ–¹æ³•åœ¨è‡ªä¸»è¶…è¶Šæ–¹é¢çš„è¡¨ç°ã€‚ 

---
# Multi-Robot Allocation for Information Gathering in Non-Uniform Spatiotemporal Environments 

**Title (ZH)**: éå‡åŒ€æ—¶ç©ºç¯å¢ƒä¸­çš„å¤šæœºå™¨äººä¿¡æ¯é‡‡é›†åˆ†é… 

**Authors**: Kaleb Ben Naveed, Haejoon Lee, Dimitra Panagou  

**Link**: [PDF](https://arxiv.org/pdf/2509.22883)  

**Abstract**: Autonomous robots are increasingly deployed to estimate spatiotemporal fields (e.g., wind, temperature, gas concentration) that vary across space and time. We consider environments divided into non-overlapping regions with distinct spatial and temporal dynamics, termed non-uniform spatiotemporal environments. Gaussian Processes (GPs) can be used to estimate these fields. The GP model depends on a kernel that encodes how the field co-varies in space and time, with its spatial and temporal lengthscales defining the correlation. Hence, when these lengthscales are incorrect or do not correspond to the actual field, the estimates of uncertainty can be highly inaccurate. Existing GP methods often assume one global lengthscale or update only periodically; some allow spatial variation but ignore temporal changes. To address these limitations, we propose a two-phase framework for multi-robot field estimation. Phase 1 uses a variogram-driven planner to learn region-specific spatial lengthscales. Phase 2 employs an allocation strategy that reassigns robots based on the current uncertainty, and updates sampling as temporal lengthscales are refined. For encoding uncertainty, we utilize clarity, an information metric from our earlier work. We evaluate the proposed method across diverse environments and provide convergence analysis for spatial lengthscale estimation, along with dynamic regret bounds quantifying the gap to the oracle's allocation sequence. 

**Abstract (ZH)**: è‡ªä¸»æœºå™¨äººåœ¨éå‡åŒ€æ—¶ç©ºç¯å¢ƒä¸‹çš„åœºä¼°è®¡ä¸­å¾—åˆ°äº†è¶Šæ¥è¶Šå¹¿æ³›çš„åº”ç”¨ã€‚æˆ‘ä»¬è€ƒè™‘å°†ç¯å¢ƒåˆ’åˆ†ä¸ºä¸é‡å çš„å…·æœ‰ä¸åŒæ—¶ç©ºåŠ¨æ€çš„åŒºåŸŸï¼Œç§°ä¸ºéå‡åŒ€æ—¶ç©ºç¯å¢ƒã€‚é«˜æ–¯è¿‡ç¨‹ï¼ˆGPsï¼‰å¯ä»¥ç”¨äºä¼°è®¡è¿™äº›åœºã€‚GPæ¨¡å‹ä¾èµ–äºä¸€ä¸ªå†…æ ¸ï¼Œè¯¥å†…æ ¸ç¼–ç äº†åœºåœ¨æ—¶ç©ºä¸­çš„åå˜å…³ç³»ï¼Œå…¶æ—¶ç©ºé•¿åº¦å°ºåº¦å®šä¹‰äº†ç›¸å…³æ€§ã€‚å› æ­¤ï¼Œå½“è¿™äº›é•¿åº¦å°ºåº¦ä¸æ­£ç¡®æˆ–ä¸å¯¹åº”äºå®é™…åœºæ—¶ï¼Œä¸ç¡®å®šæ€§ä¼°è®¡å¯èƒ½ä¼šéå¸¸ä¸å‡†ç¡®ã€‚ç°æœ‰çš„GPæ–¹æ³•é€šå¸¸å‡è®¾ä¸€ä¸ªå…¨å±€é•¿åº¦å°ºåº¦æˆ–ä»…å‘¨æœŸæ€§æ›´æ–°ï¼›ä¸€äº›æ–¹æ³•å…è®¸ç©ºé—´å˜å¼‚æ€§ä½†å¿½ç•¥æ—¶é—´å˜åŒ–ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µæ¡†æ¶è¿›è¡Œå¤šæœºå™¨äººåœºä¼°è®¡ã€‚ç¬¬ä¸€é˜¶æ®µä½¿ç”¨å˜å¼‚å‡½æ•°é©±åŠ¨çš„è§„åˆ’å™¨å­¦ä¹ åŒºåŸŸç‰¹å®šçš„ç©ºé—´é•¿åº¦å°ºåº¦ã€‚ç¬¬äºŒé˜¶æ®µé‡‡ç”¨åˆ†é…ç­–ç•¥æ ¹æ®å½“å‰ä¸ç¡®å®šæ€§é‡æ–°åˆ†é…æœºå™¨äººï¼Œå¹¶éšç€æ—¶ç©ºé•¿åº¦å°ºåº¦çš„ç»†åŒ–æ›´æ–°é‡‡æ ·ã€‚ä¸ºäº†ç¼–ç ä¸ç¡®å®šæ€§çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†æˆ‘ä»¬ä¹‹å‰å·¥ä½œä¸­æå‡ºçš„æ¸…æ™°åº¦è¿™ä¸€ä¿¡æ¯åº¦é‡ã€‚æˆ‘ä»¬åœ¨å¤šç§ç¯å¢ƒä¸­è¯„ä¼°äº†æå‡ºçš„æ–¹æ³•ï¼Œå¹¶æä¾›äº†ç©ºé—´é•¿åº¦å°ºåº¦ä¼°è®¡çš„æ”¶æ•›æ€§åˆ†æï¼Œä»¥åŠè¡¡é‡åˆ°æœ€ä¼˜åˆ†é…åºåˆ—å·®è·çš„åŠ¨æ€é—æ†¾ç•Œã€‚ 

---
# Large Language Models for 3D IC Space Planning 

**Title (ZH)**: å¤§å‹è¯­è¨€æ¨¡å‹åœ¨3D ICç©ºé—´è§„åˆ’ä¸­çš„åº”ç”¨ 

**Authors**: Hung-Ying Chu, Guan-Wei Chen, Shao-Yu Wei, Yu-Cheng Lin  

**Link**: [PDF](https://arxiv.org/pdf/2509.22716)  

**Abstract**: Three-dimensional integrated circuits (3D ICs) have emerged as a promising solution to the scaling limits of two-dimensional designs, offering higher integration density, shorter interconnects, and improved performance. As design complexity increases, effective space planning becomes essential to reduce dead space and ensure layout quality. This study investigates the use of large language models (LLMs) for 3D IC space planning through a post-order slicing tree representation, which guarantees legal space plans while aiming to minimize dead space. Open-source LLMs were fine-tuned on large-scale synthetic datasets and further evaluated on MCNC-derived 3D benchmarks. Experimental results indicate that the proposed framework achieves a favorable balance between runtime efficiency, legality, and dead-space reduction, with zero-dead-space layouts obtained in a significant portion of test cases under practical runtime budgets. Beyond synthetic benchmarks, the method generalizes to MCNC cases such as ami33 and ami49, though larger and irregular instances remain challenging. The approach also shows potential for cross-domain applications, including logistics and 3D object placement, where spatial efficiency is critical. Overall, the results suggest that LLM-based space planning can serve as a data-driven complement to traditional electronic design automation (EDA) methods, providing new insights for scalable 3D layout generation. 

**Abstract (ZH)**: ä¸‰ç»´é›†æˆç”µè·¯ï¼ˆ3D ICsï¼‰çš„ç©ºé—´è§„åˆ’é€šè¿‡ååºåˆ‡ç‰‡æ ‘è¡¨ç¤ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç ”ç©¶ï¼šå®ç°é«˜æ•ˆçš„åˆæ³•æ€§ã€å‡å°‘æ­»ç©ºé—´çš„å¹³è¡¡ 

---
# Safety-Critical Input-Constrained Nonlinear Intercept Guidance in Multiple Engagement Zones 

**Title (ZH)**: å¤šä½œæˆ˜åŒºå†…çš„å®‰å…¨å…³é”®è¾“å…¥çº¦æŸéçº¿æ€§æˆªè·åˆ¶å¯¼ 

**Authors**: Praveen Kumar Ranjan, Abhinav Sinha, Yongcan Cao  

**Link**: [PDF](https://arxiv.org/pdf/2509.25053)  

**Abstract**: This paper presents an input-constrained nonlinear guidance law to address the problem of intercepting a stationary target in contested environments with multiple defending agents. Contrary to prior approaches that rely on explicit knowledge of defender strategies or utilize conservative safety conditions based on a defender's range, our work characterizes defender threats geometrically through engagement zones that delineate inevitable interception regions. Outside these engagement zones, the interceptor remains invulnerable. The proposed guidance law switches between a repulsive safety maneuver near these zones and a pursuit maneuver outside their influence. To deal with multiple engagement zones, we employ a smooth minimum function (log-sum-exponent approximation) that aggregates threats from all the zones while prioritizing the most critical threats. Input saturation is modeled and embedded in the non-holonomic vehicle dynamics so the controller respects actuator limits while maintaining stability. Numerical simulations with several defenders demonstrate the proposed method's ability to avoid engagement zones and achieve interception across diverse initial conditions. 

**Abstract (ZH)**: åŸºäºè¾“å…¥çº¦æŸçš„éçº¿æ€§åˆ¶å¯¼å¾‹ä»¥åº”å¯¹å¤šé˜²æŠ¤å®ä½“çš„äº¤æˆ˜åŒºç¯å¢ƒä¸‹å¯¹é™æ­¢ç›®æ ‡çš„æ‹¦æˆªé—®é¢˜ 

---
# Discrete Variational Autoencoding via Policy Search 

**Title (ZH)**: ç¦»æ•£å˜åˆ†è‡ªç¼–ç é€šè¿‡ç­–ç•¥æœç´¢ 

**Authors**: Michael Drolet, Firas Al-Hafez, Aditya Bhatt, Jan Peters, Oleg Arenz  

**Link**: [PDF](https://arxiv.org/pdf/2509.24716)  

**Abstract**: Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit efficiency and can be modeled with autoregressive discrete distributions, enabling parameter-efficient multimodal search with transformers. However, discrete random variables do not allow for exact differentiable parameterization; therefore, discrete VAEs typically rely on approximations, such as Gumbel-Softmax reparameterization or straight-through gradient estimates, or employ high-variance gradient-free methods such as REINFORCE that have had limited success on high-dimensional tasks such as image reconstruction. Inspired by popular techniques in policy search, we propose a training framework for discrete VAEs that leverages the natural gradient of a non-parametric encoder to update the parametric encoder without requiring reparameterization. Our method, combined with automatic step size adaptation and a transformer-based encoder, scales to challenging datasets such as ImageNet and outperforms both approximate reparameterization methods and quantization-based discrete autoencoders in reconstructing high-dimensional data from compact latent spaces, achieving a 20% improvement on FID Score for ImageNet 256. 

**Abstract (ZH)**: ç¦»æ•£æ½œç“¶é¢ˆåœ¨å˜åˆ†è‡ªç¼–ç å™¨ä¸­çš„åº”ç”¨æä¾›äº†é«˜æ¯”ç‰¹æ•ˆç‡ï¼Œå¹¶å¯ä»¥é€šè¿‡è‡ªå›å½’ç¦»æ•£åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå¯ä»¥ç”¨å˜å‹å™¨å®ç°å‚æ•°é«˜æ•ˆçš„å¤šæ¨¡æ€æœç´¢ã€‚ç„¶è€Œï¼Œç¦»æ•£éšæœºå˜é‡ä¸å…è®¸ç²¾ç¡®çš„å¯å¾®å‚æ•°åŒ–ï¼›å› æ­¤ï¼Œç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨é€šå¸¸ä¾èµ–äºè¿‘ä¼¼æ–¹æ³•ï¼Œå¦‚Gumbel-Softmaxé‡å‚æ•°åŒ–æˆ–ç›´æ¥é€šè¿‡æ¢¯åº¦ä¼°è®¡ï¼Œæˆ–è€…ä½¿ç”¨é«˜æ–¹å·®çš„æ— æ¢¯åº¦æ–¹æ³•å¦‚REINFORCEï¼Œè¿™äº›æ–¹æ³•åœ¨å¦‚å›¾åƒé‡å»ºç­‰é«˜ç»´ä»»åŠ¡ä¸Šæ•ˆæœæœ‰é™ã€‚å—æ”¿ç­–æœç´¢ä¸­æµè¡ŒæŠ€æœ¯çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨çš„è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨éå‚æ•°ç¼–ç å™¨çš„è‡ªç„¶æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ç¼–ç å™¨ï¼Œæ— éœ€é‡å‚æ•°åŒ–ã€‚ç»“åˆè‡ªé€‚åº”æ­¥é•¿è°ƒæ•´å’ŒåŸºäºå˜å‹å™¨çš„ç¼–ç å™¨ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å¦‚ImageNetè¿™æ ·çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼Œå¹¶åœ¨ä»ç´§å‡‘çš„æ½œç©ºé—´é‡æ„é«˜ç»´æ•°æ®æ–¹é¢ä¼˜äºè¿‘ä¼¼é‡å‚æ•°åŒ–æ–¹æ³•å’ŒåŸºäºé‡åŒ–çš„æ–¹æ³•ï¼Œå®ç°äº†ImageNet 256åœ¨FIDåˆ†æ•°ä¸Šçš„20%æ”¹è¿›ã€‚ 

---
# Clebsch-Gordan Transformer: Fast and Global Equivariant Attention 

**Title (ZH)**: Clebsch-Gordan å˜ä½“å˜å‹å™¨ï¼šå¿«é€Ÿä¸”å…¨å±€ equivariant æ³¨æ„åŠ› 

**Authors**: Owen Lewis Howell, Linfeng Zhao, Xupeng Zhu, Yaoyao Qian, Haojie Huang, Lingfeng Sun, Wil Thomason, Robert Platt, Robin Walters  

**Link**: [PDF](https://arxiv.org/pdf/2509.24093)  

**Abstract**: The global attention mechanism is one of the keys to the success of transformer architecture, but it incurs quadratic computational costs in relation to the number of tokens. On the other hand, equivariant models, which leverage the underlying geometric structures of problem instance, often achieve superior accuracy in physical, biochemical, computer vision, and robotic tasks, at the cost of additional compute requirements. As a result, existing equivariant transformers only support low-order equivariant features and local context windows, limiting their expressiveness and performance. This work proposes Clebsch-Gordan Transformer, achieving efficient global attention by a novel Clebsch-Gordon Convolution on $\SO(3)$ irreducible representations. Our method enables equivariant modeling of features at all orders while achieving ${O}(N \log N)$ input token complexity. Additionally, the proposed method scales well with high-order irreducible features, by exploiting the sparsity of the Clebsch-Gordon matrix. Lastly, we also incorporate optional token permutation equivariance through either weight sharing or data augmentation. We benchmark our method on a diverse set of benchmarks including n-body simulation, QM9, ModelNet point cloud classification and a robotic grasping dataset, showing clear gains over existing equivariant transformers in GPU memory size, speed, and accuracy. 

**Abstract (ZH)**: Clebsch-Gordan Transformerï¼šåŸºäº$\SO(3)$ä¸å¯çº¦è¡¨ç¤ºçš„æ–°é¢–Clebsch-Gordanå·ç§¯å®ç°é«˜æ•ˆå…¨å±€æ³¨æ„åŠ› 

---
# Systematic Alias Sampling: an efficient and low-variance way to sample from a discrete distribution 

**Title (ZH)**: ç³»ç»ŸåŒ–çš„åˆ«åé‡‡æ ·ï¼šä¸€ç§é«˜æ•ˆä¸”ä½æ–¹å·®çš„ç¦»æ•£åˆ†å¸ƒé‡‡æ ·æ–¹æ³• 

**Authors**: Ilari Vallivaara, Katja PoikselkÃ¤, Pauli Rikula, Juha RÃ¶ning  

**Link**: [PDF](https://arxiv.org/pdf/2509.24089)  

**Abstract**: In this paper we combine the Alias method with the concept of systematic sampling, a method commonly used in particle filters for efficient low-variance resampling. The proposed method allows very fast sampling from a discrete distribution: drawing k samples is up to an order of magnitude faster than binary search from the cumulative distribution function (cdf) or inversion methods used in many libraries. The produced empirical distribution function is evaluated using a modified CramÃ©r-Von Mises goodness-of-fit statistic, showing that the method compares very favourably to multinomial sampling. As continuous distributions can often be approximated with discrete ones, the proposed method can be used as a very general way to efficiently produce random samples for particle filter proposal distributions, e.g. for motion models in robotics. 

**Abstract (ZH)**: æœ¬æ–‡å°†Aliasæ–¹æ³•ä¸ç³»ç»ŸæŠ½æ ·æ¦‚å¿µç»“åˆï¼Œç”¨äºç²’å­æ»¤æ³¢ä¸­çš„é«˜æ•ˆä½æ–¹å·®é‡é‡‡æ ·ã€‚æ‰€æå‡ºçš„æ–¹æ³•å…è®¸ä»ç¦»æ•£åˆ†å¸ƒä¸­è¿›è¡Œéå¸¸å¿«é€Ÿçš„æŠ½æ ·ï¼šæŠ½å–kä¸ªæ ·æœ¬çš„é€Ÿåº¦æ¯”ä»ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰æˆ–è®¸å¤šåº“ä¸­ä½¿ç”¨çš„å€’ç½®æ–¹æ³•å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚é€šè¿‡ä½¿ç”¨ä¿®æ”¹åçš„CramÃ©r-Von Misesæ‹Ÿåˆä¼˜åº¦ç»Ÿè®¡è¯„ä¼°ç”Ÿæˆçš„ç»éªŒåˆ†å¸ƒå‡½æ•°ï¼Œè¡¨æ˜è¯¥æ–¹æ³•ä¸å¤šé¡¹å¼æŠ½æ ·ç›¸æ¯”å…·æœ‰å¾ˆå¤§çš„ä¼˜åŠ¿ã€‚ç”±äºè¿ç»­åˆ†å¸ƒå¾€å¾€å¯ä»¥ç”¨ç¦»æ•£åˆ†å¸ƒé€¼è¿‘ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å¯ä»¥ä½œä¸ºä¸€ç§éå¸¸é€šç”¨çš„æ–¹æ³•ï¼Œç”¨äºé«˜æ•ˆåœ°ä¸ºç²’å­æ»¤æ³¢çš„æè®®åˆ†å¸ƒç”Ÿæˆéšæœºæ ·æœ¬ï¼Œä¾‹å¦‚åœ¨æœºå™¨äººä¸­çš„è¿åŠ¨æ¨¡å‹ã€‚ 

---
# Advancing Multi-agent Traffic Simulation via R1-Style Reinforcement Fine-Tuning 

**Title (ZH)**: åŸºäºR1é£æ ¼å¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„å¤šagentsäº¤é€šæ¨¡æ‹Ÿæ¨è¿› 

**Authors**: Muleilan Pei, Shaoshuai Shi, Shaojie Shen  

**Link**: [PDF](https://arxiv.org/pdf/2509.23993)  

**Abstract**: Scalable and realistic simulation of multi-agent traffic behavior is critical for advancing autonomous driving technologies. Although existing data-driven simulators have made significant strides in this domain, they predominantly rely on supervised learning to align simulated distributions with real-world driving scenarios. A persistent challenge, however, lies in the distributional shift that arises between training and testing, which often undermines model generalization in unseen environments. To address this limitation, we propose SMART-R1, a novel R1-style reinforcement fine-tuning paradigm tailored for next-token prediction models to better align agent behavior with human preferences and evaluation metrics. Our approach introduces a metric-oriented policy optimization algorithm to improve distribution alignment and an iterative "SFT-RFT-SFT" training strategy that alternates between Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) to maximize performance gains. Extensive experiments on the large-scale Waymo Open Motion Dataset (WOMD) validate the effectiveness of this simple yet powerful R1-style training framework in enhancing foundation models. The results on the Waymo Open Sim Agents Challenge (WOSAC) showcase that SMART-R1 achieves state-of-the-art performance with an overall realism meta score of 0.7858, ranking first on the leaderboard at the time of submission. 

**Abstract (ZH)**: é€‚ç”¨å¤§è§„æ¨¡ä¸”çœŸå®çš„å¤šæ™ºèƒ½ä½“äº¤é€šè¡Œä¸ºä»¿çœŸå¯¹äºæ¨åŠ¨è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å‘å±•è‡³å…³é‡è¦ã€‚å°½ç®¡ç°æœ‰çš„æ•°æ®é©±åŠ¨ä»¿çœŸå™¨åœ¨æ­¤é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå®ƒä»¬ä¸»è¦ä¾èµ–ç›‘ç£å­¦ä¹ æ¥å¯¹é½ä»¿çœŸåˆ†å¸ƒä¸ç°å®é©¾é©¶åœºæ™¯ã€‚ç„¶è€Œï¼Œè®­ç»ƒä¸æµ‹è¯•ä¹‹é—´æŒç»­å­˜åœ¨çš„åˆ†å¸ƒåå·®å¾€å¾€å‰Šå¼±äº†æ¨¡å‹åœ¨æœªè§ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºè§£å†³è¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºSMART-R1ï¼Œä¸€ç§é’ˆå¯¹ä¸‹ä¸€æ ‡è®°é¢„æµ‹æ¨¡å‹çš„æ–°å‹R1é£æ ¼å¼ºåŒ–å¾®è°ƒèŒƒå¼ï¼Œä»¥æ›´å¥½åœ°ä½¿æ™ºèƒ½ä½“è¡Œä¸ºä¸äººç±»åå¥½å’Œè¯„ä¼°æŒ‡æ ‡ä¿æŒä¸€è‡´ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ç§ä»¥åº¦é‡ä¸ºå¯¼å‘çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•ï¼Œä»¥æé«˜åˆ†å¸ƒå¯¹é½ï¼Œå¹¶æå‡ºäº†ä¸€ç§è¿­ä»£çš„â€œSFT-RFT-SFTâ€è®­ç»ƒç­–ç•¥ï¼Œäº¤æ›¿è¿›è¡Œç›‘ç£å¾®è°ƒ(SFT)å’Œå¼ºåŒ–å¾®è°ƒ(RFT)ï¼Œä»¥æœ€å¤§åŒ–æ€§èƒ½æå‡ã€‚å¤§è§„æ¨¡Waymo Open Motion Dataset (WOMD)ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†è¿™ç§ç®€å•è€Œå¼ºå¤§çš„R1é£æ ¼è®­ç»ƒæ¡†æ¶åœ¨å¢å¼ºåŸºç¡€æ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚Waymo Open Sim Agents Challenge (WOSAC)ä¸Šçš„ç»“æœè¡¨æ˜ï¼ŒSMART-R1 è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ€»ä½“ç°å®åº¦metaåˆ†ä¸º0.7858ï¼Œåœ¨æäº¤æ—¶æ’åé¢†å¯¼è€…æ¦œç¬¬ä¸€ã€‚ 

---
# From Static to Dynamic: a Survey of Topology-Aware Perception in Autonomous Driving 

**Title (ZH)**: ä»é™æ€åˆ°åŠ¨æ€ï¼šè‡ªä¸»é©¾é©¶ä¸­æ‹“æ‰‘æ„ŸçŸ¥ç»¼è¿° 

**Authors**: Yixiao Chen, Ruining Yang, Xin Chen, Jia He, Dongliang Xu, Yue Yao  

**Link**: [PDF](https://arxiv.org/pdf/2509.23641)  

**Abstract**: The key to achieving autonomous driving lies in topology-aware perception, the structured understanding of the driving environment with an emphasis on lane topology and road semantics. This survey systematically reviews four core research directions under this theme: vectorized map construction, topological structure modeling, prior knowledge fusion, and language model-based perception. Across these directions, we observe a unifying trend: a paradigm shift from static, pre-built maps to dynamic, sensor-driven perception. Specifically, traditional static maps have provided semantic context for autonomous systems. However, they are costly to construct, difficult to update in real time, and lack generalization across regions, limiting their scalability. In contrast, dynamic representations leverage on-board sensor data for real-time map construction and topology reasoning. Each of the four research directions contributes to this shift through compact spatial modeling, semantic relational reasoning, robust domain knowledge integration, and multimodal scene understanding powered by pre-trained language models. Together, they pave the way for more adaptive, scalable, and explainable autonomous driving systems. 

**Abstract (ZH)**: å®ç°è‡ªåŠ¨é©¾é©¶çš„å…³é”®åœ¨äºæ‹“æ‰‘æ„ŸçŸ¥ï¼Œå³ä»¥è½¦é“æ‹“æ‰‘å’Œé“è·¯è¯­ä¹‰ä¸ºé‡ç‚¹çš„é©¾é©¶ç¯å¢ƒçš„ç»“æ„åŒ–ç†è§£ã€‚æœ¬æ–‡ç»¼è¿°äº†è¯¥ä¸»é¢˜ä¸‹çš„å››å¤§æ ¸å¿ƒç ”ç©¶æ–¹å‘ï¼šçŸ¢é‡åœ°å›¾æ„å»ºã€æ‹“æ‰‘ç»“æ„å»ºæ¨¡ã€å…ˆéªŒçŸ¥è¯†èåˆä»¥åŠåŸºäºè¯­è¨€æ¨¡å‹çš„æ„ŸçŸ¥ã€‚åœ¨è¿™å››å¤§æ–¹å‘ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä¸€ä¸ªç»Ÿä¸€çš„è¶‹åŠ¿ï¼šä»é™æ€ã€é¢„å…ˆæ„å»ºçš„åœ°å›¾å‘åŸºäºä¼ æ„Ÿå™¨çš„åŠ¨æ€æ„ŸçŸ¥çš„èŒƒå¼è½¬å˜ã€‚ä¼ ç»Ÿé™æ€åœ°å›¾ä¸ºè‡ªä¸»ç³»ç»Ÿæä¾›äº†è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œä½†æ„å»ºæˆæœ¬é«˜ã€éš¾ä»¥å®æ—¶æ›´æ–°ä¸”è·¨åŒºåŸŸç¼ºä¹æ³›åŒ–èƒ½åŠ›ï¼Œé™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŠ¨æ€è¡¨ç¤ºåˆ©ç”¨è½¦è½½ä¼ æ„Ÿå™¨æ•°æ®å®ç°å®æ—¶åœ°å›¾æ„å»ºå’Œæ‹“æ‰‘æ¨ç†ã€‚å››å¤§ç ”ç©¶æ–¹å‘åˆ†åˆ«é€šè¿‡ç´§å‡‘çš„ç©ºé—´å»ºæ¨¡ã€è¯­ä¹‰å…³ç³»æ¨ç†ã€é²æ£’é¢†åŸŸçŸ¥è¯†èåˆä»¥åŠåŸºäºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€åœºæ™¯ç†è§£ä¿ƒè¿›è¿™ä¸€è½¬å˜ã€‚è¿™äº›ç ”ç©¶å…±åŒä¸ºæ›´åŠ é€‚åº”ç¯å¢ƒã€å¯æ‰©å±•ä¸”å¯è§£é‡Šçš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚ 

---
# Visual serial processing deficits explain divergences in human and VLM reasoning 

**Title (ZH)**: è§†è§‰åºåˆ—åŠ å·¥ç¼ºé™·è§£é‡Šäººç±»ä¸VLMæ¨ç†çš„å·®å¼‚ 

**Authors**: Nicholas Budny, Kia Ghods, Declan Campbell, Raja Marjieh, Amogh Joshi, Sreejan Kumar, Jonathan D. Cohen, Taylor W. Webb, Thomas L. Griffiths  

**Link**: [PDF](https://arxiv.org/pdf/2509.25142)  

**Abstract**: Why do Vision Language Models (VLMs), despite success on standard benchmarks, often fail to match human performance on surprisingly simple visual reasoning tasks? While the underlying computational principles are still debated, we hypothesize that a crucial factor is a deficit in visually-grounded serial processing. To test this hypothesis, we compared human and VLM performance across tasks designed to vary serial processing demands in three distinct domains: geometric reasoning, perceptual enumeration, and mental rotation. Tasks within each domain varied serial processing load by manipulating factors such as geometric concept complexity, perceptual individuation load, and transformation difficulty. Across all domains, our results revealed a consistent pattern: decreased VLM accuracy was strongly correlated with increased human reaction time (used as a proxy for serial processing load). As tasks require more demanding serial processing -- whether composing concepts, enumerating items, or performing mental transformations -- the VLM-human performance gap widens reliably. These findings support our hypothesis, indicating that limitations in serial, visually grounded reasoning represent a fundamental bottleneck that distinguishes current VLMs from humans. 

**Abstract (ZH)**: ä¸ºä»€ä¹ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰å°½ç®¡åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­å–å¾—æˆåŠŸï¼Œä½†åœ¨ä¸€äº›å‡ºäººæ„æ–™çš„ç®€å•è§†è§‰æ¨ç†ä»»åŠ¡ä¸­å¾€å¾€æ— æ³•åŒ¹é…äººç±»çš„è¡¨ç°ï¼Ÿè™½ç„¶æ ¸å¿ƒè®¡ç®—åŸç†ä»ç„¶å­˜åœ¨äº‰è®®ï¼Œä½†æˆ‘ä»¬å‡è®¾ä¸€ä¸ªå…³é”®å› ç´ æ˜¯åœ¨è§†è§‰æ”¯æ’‘çš„åºè´¯å¤„ç†æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚ä¸ºäº†æ£€éªŒè¿™ä¸€å‡è®¾ï¼Œæˆ‘ä»¬åœ¨ä¸‰ä¸ªä¸åŒçš„é¢†åŸŸï¼ˆå‡ ä½•æ¨ç†ã€çŸ¥è§‰è®¡æ•°å’Œå¿ƒç†æ—‹è½¬ï¼‰è®¾è®¡çš„ä»»åŠ¡ä¸­æ¯”è¾ƒäº†äººç±»å’ŒVLMçš„è¡¨ç°ï¼Œè¿™äº›ä»»åŠ¡æ—¨åœ¨æ”¹å˜åºè´¯å¤„ç†çš„è¦æ±‚ã€‚åœ¨æ¯ä¸ªé¢†åŸŸå†…ï¼Œé€šè¿‡æ“æ§è¯¸å¦‚å‡ ä½•æ¦‚å¿µå¤æ‚æ€§ã€çŸ¥è§‰ä¸ªä½“åŒ–è´Ÿæ‹…å’Œå˜æ¢éš¾åº¦ç­‰å› ç´ æ¥æ”¹å˜åºè´¯å¤„ç†è´Ÿè½½ã€‚åœ¨æ‰€æœ‰é¢†åŸŸä¸­ï¼Œæˆ‘ä»¬çš„ç»“æœæ˜¾ç°å‡ºäº†ä¸€ä¸ªä¸€è‡´çš„æ¨¡å¼ï¼šVLMå‡†ç¡®ç‡çš„ä¸‹é™å¼ºçƒˆç›¸å…³äºäººç±»ååº”æ—¶é—´çš„å¢åŠ ï¼ˆä½œä¸ºåºè´¯å¤„ç†è´Ÿè½½çš„ä»£ç†ï¼‰ã€‚éšç€ä»»åŠ¡å¯¹åºè´¯å¤„ç†çš„è¦æ±‚å˜å¾—æ›´ä¸ºè‹›åˆ»â€”â€”æ— è®ºæ˜¯ç»„æˆæ¦‚å¿µã€è®¡æ•°ç‰©å“è¿˜æ˜¯æ‰§è¡Œå¿ƒç†å˜æ¢â€”â€”VLMä¸äººç±»çš„è¡¨ç°å·®è·ä¼šå¯é åœ°æ‰©å¤§ã€‚è¿™äº›å‘ç°æ”¯æŒäº†æˆ‘ä»¬çš„å‡è®¾ï¼Œè¡¨æ˜åœ¨åºåˆ—ã€è§†è§‰æ”¯æ’‘çš„æ¨ç†æ–¹é¢çš„å±€é™æ€§æ„æˆäº†å½“å‰VLMsä¸äººç±»ä¹‹é—´çš„ä¸€ä¸ªåŸºæœ¬ç“¶é¢ˆã€‚ 

---
# HeDA: An Intelligent Agent System for Heatwave Risk Discovery through Automated Knowledge Graph Construction and Multi-layer Risk Propagation Analysis 

**Title (ZH)**: HeDAï¼šä¸€ç§é€šè¿‡è‡ªåŠ¨åŒ–çŸ¥è¯†å›¾æ„å»ºå’Œå¤šå±‚é£é™©ä¼ æ’­åˆ†æçš„çƒ­æ³¢é£é™©å‘ç°æ™ºèƒ½ä»£ç†ç³»ç»Ÿ 

**Authors**: Yiquan Wang, Tin-Yeh Huang, Qingyun Gao, Jialin Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.25112)  

**Abstract**: Heatwaves pose complex cascading risks across interconnected climate, social, and economic systems, but knowledge fragmentation in scientific literature hinders comprehensive understanding of these risk pathways. We introduce HeDA (Heatwave Discovery Agent), an intelligent multi-agent system designed for automated scientific discovery through knowledge graph construction and multi-layer risk propagation analysis. HeDA processes over 10,247 academic papers to construct a comprehensive knowledge graph with 23,156 nodes and 89,472 relationships, employing novel multi-layer risk propagation analysis to systematically identify overlooked risk transmission pathways. Our system achieves 78.9% accuracy on complex question-answering tasks, outperforming state-of-the-art baselines including GPT-4 by 13.7%. Critically, HeDA successfully discovered five previously unidentified high-impact risk chains, such as the pathway where a heatwave leads to a water demand surge, resulting in industrial water restrictions and ultimately causing small business disruption, which were validated through historical case studies and domain expert review. This work presents a new paradigm for AI-driven scientific discovery, providing actionable insights for developing more resilient climate adaptation strategies. 

**Abstract (ZH)**: çƒ­æµªåœ¨äº’è”çš„æ°”å€™ã€ç¤¾ä¼šå’Œç»æµç³»ç»Ÿä¸­æ„æˆå¤æ‚è¿é”é£é™©ï¼Œä½†ç§‘å­¦æ–‡çŒ®ä¸­çš„çŸ¥è¯†ç¢ç‰‡åŒ–é˜»ç¢äº†å¯¹è¿™äº›é£é™©è·¯å¾„çš„å…¨é¢ç†è§£ã€‚æˆ‘ä»¬ä»‹ç»äº†HeDAï¼ˆçƒ­æµªå‘ç°ä»£ç†ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ™ºèƒ½å¤šagentç³»ç»Ÿï¼Œè®¾è®¡ç”¨äºé€šè¿‡çŸ¥è¯†å›¾è°±æ„å»ºå’Œå¤šå±‚æ¬¡é£é™©ä¼ æ’­åˆ†æè¿›è¡Œè‡ªåŠ¨ç§‘å­¦ç ”ç©¶ã€‚HeDA å¤„ç†äº†è¶…è¿‡10,247ç¯‡å­¦æœ¯è®ºæ–‡ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«23,156ä¸ªèŠ‚ç‚¹å’Œ89,472ä¸ªå…³ç³»çš„å…¨é¢çŸ¥è¯†å›¾è°±ï¼Œå¹¶é‡‡ç”¨æ–°é¢–çš„å¤šå±‚æ¬¡é£é™©ä¼ æ’­åˆ†æç³»ç»Ÿåœ°è¯†åˆ«å‡ºè¢«å¿½è§†çš„é£é™©ä¼ è¾“è·¯å¾„ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿåœ¨å¤æ‚é—®ç­”ä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡è¾¾åˆ°78.9%ï¼Œåœ¨åŒ…æ‹¬GPT-4åœ¨å†…çš„æœ€æ–°åŸºçº¿æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œè¶…è¿‡äº†13.7%ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒHeDA æˆåŠŸå‘ç°äº†äº”ä¸ªå…ˆå‰æœªè¢«è¯†åˆ«çš„é«˜å½±å“é£é™©é“¾è·¯ï¼Œä¾‹å¦‚çƒ­æµªå¯¼è‡´æ°´èµ„æºéœ€æ±‚æ¿€å¢ï¼Œè¿›è€Œå¼•å‘å·¥ä¸šç”¨æ°´é™åˆ¶ï¼Œæœ€ç»ˆå¯¼è‡´å°å‹ä¼ä¸šä¸­æ–­ç­‰é“¾æ¡ï¼Œè¿™äº›å‘ç°é€šè¿‡å†å²æ¡ˆä¾‹ç ”ç©¶å’Œé¢†åŸŸä¸“å®¶è¯„å®¡å¾—åˆ°äº†éªŒè¯ã€‚è¿™é¡¹å·¥ä½œç¡®ç«‹äº†AIé©±åŠ¨ç§‘å­¦ç ”ç©¶çš„æ–°èŒƒå¼ï¼Œä¸ºåˆ¶å®šæ›´å…·å¼¹æ€§çš„æ°”å€™é€‚åº”ç­–ç•¥æä¾›äº†å¯æ“ä½œçš„è§è§£ã€‚ 

---
# KIRETT - A wearable device to support rescue operations using artificial intelligence to improve first aid 

**Title (ZH)**: KIRETT - ä¸€ç§ä½¿ç”¨äººå·¥æ™ºèƒ½æ”¯æŒæ•‘æ´è¡ŒåŠ¨çš„å¯ç©¿æˆ´è®¾å¤‡ä»¥æ”¹è¿›æ€¥æ•‘ 

**Authors**: Johannes Zenkert, Christian Weber, Mubaris Nadeem, Lisa Bender, Madjid Fathi, Abu Shad Ahammed, Aniebiet Micheal Ezekiel, Roman Obermaisser, Maximilian Bradford  

**Link**: [PDF](https://arxiv.org/pdf/2509.24934)  

**Abstract**: This short paper presents first steps in the scientific part of the KIRETT project, which aims to improve first aid during rescue operations using a wearable device. The wearable is used for computer-aided situation recognition by means of artificial intelligence. It provides contextual recommendations for actions and operations to rescue personnel and is intended to minimize damage to patients due to incorrect treatment, as well as increase the probability of survival. The paper describes a first overview of research approaches within the project. 

**Abstract (ZH)**: è¿™ç¯‡ç®€çŸ­çš„æ–‡ç« ä»‹ç»äº†KIRETTé¡¹ç›®ç§‘å­¦éƒ¨åˆ†çš„åˆæ­¥æˆæœï¼Œè¯¥é¡¹ç›®æ—¨åœ¨é€šè¿‡ç©¿æˆ´è®¾å¤‡æ”¹å–„æ•‘æ´æ“ä½œä¸­çš„æ€¥æ•‘æªæ–½ã€‚ç©¿æˆ´è®¾å¤‡åˆ©ç”¨äººå·¥æ™ºèƒ½è¿›è¡Œè®¡ç®—æœºè¾…åŠ©æƒ…å†µè¯†åˆ«ï¼Œå¹¶æä¾›ä¸Šä¸‹æ–‡ç›¸å…³çš„è¡ŒåŠ¨å’Œæ“ä½œå»ºè®®ï¼Œæ—¨åœ¨å› ä¸æ­£ç¡®çš„æ²»ç–—å‡å°‘æ‚£è€…æŸä¼¤ï¼Œæé«˜ç”Ÿå­˜æ¦‚ç‡ã€‚æ–‡ç« æè¿°äº†é¡¹ç›®å†…çš„åˆæ­¥ç ”ç©¶æ–¹æ³• overviewã€‚ 

---
# Meta-Learning Theory-Informed Inductive Biases using Deep Kernel Gaussian Processes 

**Title (ZH)**: åŸºäºæ·±åº¦å†…æ ¸é«˜æ–¯è¿‡ç¨‹çš„ç†è®ºæŒ‡å¯¼å½’çº³åç½®å…ƒå­¦ä¹  

**Authors**: Bahti Zakirov, GaÅ¡per TkaÄik  

**Link**: [PDF](https://arxiv.org/pdf/2509.24919)  

**Abstract**: Normative and task-driven theories offer powerful top-down explanations for biological systems, yet the goals of quantitatively arbitrating between competing theories, and utilizing them as inductive biases to improve data-driven fits of real biological datasets are prohibitively laborious, and often impossible. To this end, we introduce a Bayesian meta-learning framework designed to automatically convert raw functional predictions from normative theories into tractable probabilistic models. We employ adaptive deep kernel Gaussian processes, meta-learning a kernel on synthetic data generated from a normative theory. This Theory-Informed Kernel specifies a probabilistic model representing the theory predictions -- usable for both fitting data and rigorously validating the theory. As a demonstration, we apply our framework to the early visual system, using efficient coding as our normative theory. We show improved response prediction accuracy in ex vivo recordings of mouse retinal ganglion cells stimulated by natural scenes compared to conventional data-driven baselines, while providing well-calibrated uncertainty estimates and interpretable representations. Using exact Bayesian model selection, we also show that our informed kernel can accurately infer the degree of theory-match from data, confirming faithful encapsulation of theory structure. This work provides a more general, scalable, and automated approach for integrating theoretical knowledge into data-driven scientific inquiry in neuroscience and beyond. 

**Abstract (ZH)**: åŸºäºè§„èŒƒå’Œä»»åŠ¡é©±åŠ¨ç†è®ºçš„è´å¶æ–¯å…ƒå­¦ä¹ æ¡†æ¶ï¼šè‡ªåŠ¨å°†åŠŸèƒ½é¢„æµ‹è½¬åŒ–ä¸ºå¯å¤„ç†çš„æ¦‚ç‡æ¨¡å‹ï¼Œå¹¶ç”¨äºæ•°æ®é©±åŠ¨çš„ç”Ÿç‰©å­¦æ•°æ®æ‹Ÿåˆå’Œç†è®ºéªŒè¯ 

---
# Neural network embeddings recover value dimensions from psychometric survey items on par with human data 

**Title (ZH)**: ç¥ç»ç½‘ç»œåµŒå…¥å¯ä»¥ä»å¿ƒç†æµ‹é‡è°ƒæŸ¥é¡¹ç›®ä¸­æ¢å¤ä»·å€¼ç»´åº¦ï¼Œæ•ˆæœåª²å¤§äººç±»æ•°æ®ã€‚ 

**Authors**: Max Pellert, Clemens M. Lechner, Indira Sen, Markus Strohmaier  

**Link**: [PDF](https://arxiv.org/pdf/2509.24906)  

**Abstract**: This study introduces "Survey and Questionnaire Item Embeddings Differentials" (SQuID), a novel methodological approach that enables neural network embeddings to effectively recover latent dimensions from psychometric survey items. We demonstrate that embeddings derived from large language models, when processed with SQuID, can recover the structure of human values obtained from human rater judgments on the Revised Portrait Value Questionnaire (PVQ-RR). Our experimental validation compares multiple embedding models across a number of evaluation metrics. Unlike previous approaches, SQuID successfully addresses the challenge of obtaining negative correlations between dimensions without requiring domain-specific fine-tuning. Quantitative analysis reveals that our embedding-based approach explains 55% of variance in dimension-dimension similarities compared to human data. Multidimensional scaling configurations from both types of data show fair factor congruence coefficients and largely follow the underlying theory. These results demonstrate that semantic embeddings can effectively replicate psychometric structures previously established through extensive human surveys. The approach offers substantial advantages in cost, scalability and flexibility while maintaining comparable quality to traditional methods. Our findings have significant implications for psychometrics and social science research, providing a complementary methodology that could expand the scope of human behavior and experience represented in measurement tools. 

**Abstract (ZH)**: "Surveyå’Œé—®å·é¡¹ç›®åµŒå…¥å·®å¼‚æ€§ï¼šSQuIDæ–¹æ³•åŠå…¶åœ¨å¿ƒç†æµ‹é‡ç»´åº¦æ¢å¤ä¸­çš„åº”ç”¨" 

---
# PhysicsMinions: Winning Gold Medals in the Latest Physics Olympiads with a Coevolutionary Multimodal Multi-Agent System 

**Title (ZH)**: PhysicsMinionsï¼šåœ¨æœ€æ–°ç‰©ç†å¥¥èµ›ä¸­ä½¿ç”¨å…±è¿›åŒ–å¤šæ¨¡æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¤ºé‡‘ğŸ† 

**Authors**: Fangchen Yu, Junchi Yao, Ziyi Wang, Haiyuan Wan, Youling Huang, Bo Zhang, Shuyue Hu, Dongzhan Zhou, Ning Ding, Ganqu Cui, Lei Bai, Wanli Ouyang, Peng Ye  

**Link**: [PDF](https://arxiv.org/pdf/2509.24855)  

**Abstract**: Physics is central to understanding and shaping the real world, and the ability to solve physics problems is a key indicator of real-world physical intelligence. Physics Olympiads, renowned as the crown of competitive physics, provide a rigorous testbed requiring complex reasoning and deep multimodal understanding, yet they remain largely underexplored in AI research. Existing approaches are predominantly single-model based, and open-source MLLMs rarely reach gold-medal-level performance. To address this gap, we propose PhysicsMinions, a coevolutionary multi-agent system for Physics Olympiad. Its architecture features three synergistic studios: a Visual Studio to interpret diagrams, a Logic Studio to formulate solutions, and a Review Studio to perform dual-stage verification. The system coevolves through an iterative refinement loop where feedback from the Review Studio continuously guides the Logic Studio, enabling the system to self-correct and converge towards the ground truth. Evaluated on the HiPhO benchmark spanning 7 latest physics Olympiads, PhysicsMinions delivers three major breakthroughs: (i) Strong generalization: it consistently improves both open-source and closed-source models of different sizes, delivering clear benefits over their single-model baselines; (ii) Historic breakthroughs: it elevates open-source models from only 1-2 to 6 gold medals across 7 Olympiads, achieving the first-ever open-source gold medal in the latest International Physics Olympiad (IPhO) under the average-score metric; and (iii) Scaling to human expert: it further advances the open-source Pass@32 score to 26.8/30 points on the latest IPhO, ranking 4th of 406 contestants and far surpassing the top single-model score of 22.7 (ranked 22nd). Generally, PhysicsMinions offers a generalizable framework for Olympiad-level problem solving, with the potential to extend across disciplines. 

**Abstract (ZH)**: ç‰©ç†å­¦æ˜¯ç†è§£å¹¶å¡‘é€ ç°å®ä¸–ç•Œçš„å…³é”®ï¼Œè§£å†³ç‰©ç†å­¦é—®é¢˜çš„èƒ½åŠ›æ˜¯ç°å®ç‰©ç†æ™ºèƒ½çš„é‡è¦æŒ‡æ ‡ã€‚ç‰©ç†å­¦å¥¥æ—åŒ¹å…‹ç«èµ›è¢«èª‰ä¸ºç«èµ›ç‰©ç†å­¦çš„çš‡å† ï¼Œæä¾›äº†ä¸€ä¸ªéœ€è¦å¤æ‚æ¨ç†å’Œæ·±åˆ»å¤šæ¨¡æ€ç†è§£çš„ä¸¥æ ¼æµ‹è¯•å¹³å°ï¼Œä½†åœ¨äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­ä» largely æ¬ å¼€å‘ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºå•ä¸€æ¨¡å‹ï¼Œå¼€æº MLLMs å¾ˆå°‘è¾¾åˆ°é‡‘ç‰Œæ°´å¹³ã€‚ä¸ºè§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº† PhysicsMinionsï¼Œä¸€ç§ç”¨äºç‰©ç†å­¦å¥¥æ—åŒ¹å…‹ç«èµ›çš„ååŒè¿›åŒ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚å…¶æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªååŒçš„å·¥ä½œå®¤ï¼šå¯è§†åŒ–å·¥ä½œå®¤ä»¥è§£æå›¾è¡¨ã€é€»è¾‘å·¥ä½œå®¤ä»¥åˆ¶å®šè§£å†³æ–¹æ¡ˆã€å®¡æ ¸å·¥ä½œå®¤ä»¥è¿›è¡ŒåŒé‡éªŒè¯ã€‚è¯¥ç³»ç»Ÿé€šè¿‡ä¸€ä¸ªè¿­ä»£ç»†åŒ–å¾ªç¯ååŒè¿›åŒ–ï¼Œåœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ¥è‡ªå®¡æ ¸å·¥ä½œå®¤çš„åé¦ˆä¸æ–­å¼•å¯¼é€»è¾‘å·¥ä½œå®¤ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿè‡ªæˆ‘çº æ­£å¹¶æœç€çœŸå®ç­”æ¡ˆæ”¶æ•›ã€‚åœ¨æ¶µç›– 7 åœºæœ€æ–°ç‰©ç†å¥¥æ—åŒ¹å…‹ç«èµ›çš„ HiPhO åº•çº¿æ ‡å‡†ä¸Šï¼ŒPhysicsMinions å®ç°äº†ä¸‰é¡¹é‡å¤§çªç ´ï¼šï¼ˆiï¼‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼šå®ƒä¸€è‡´åœ°æå‡äº†ä¸åŒè§„æ¨¡çš„å¼€æºå’Œå°é—­æºæ¨¡å‹ï¼Œå¯¹å•ä¸€æ¨¡å‹åŸºçº¿æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼›ï¼ˆiiï¼‰å†å²çªç ´ï¼šå®ƒå°†å¼€æºæ¨¡å‹ä»ä»…è·å¾— 1 åˆ° 2 é‡‘ç‰Œæå‡è‡³åœ¨ 7 åœºå¥¥æ—åŒ¹å…‹ç«èµ›ä¸­è·å¾— 6 é‡‘ç‰Œï¼Œé¦–æ¬¡åœ¨å¹³å‡åˆ†æ ‡å‡†ä¸‹å®ç°äº†å¼€æºé‡‘ç‰Œï¼Œåœ¨æœ€æ–°çš„å›½é™…ç‰©ç†å¥¥æ—åŒ¹å…‹ç«èµ›ï¼ˆIPhOï¼‰ä¸­å–å¾—çªç ´ï¼›ï¼ˆiiiï¼‰è¾¾åˆ°äººç±»ä¸“å®¶æ°´å¹³ï¼šè¿›ä¸€æ­¥å°†å¼€æº Pass@32 å¾—åˆ†æå‡è‡³æœ€æ–° IPhO çš„ 26.8/30 åˆ†ï¼Œåœ¨ 406 åå‚èµ›è€…ä¸­æ’åç¬¬ 4ï¼Œå¹¶è¿œè¶…æ’åç¬¬ä¸€çš„å•ä¸€æ¨¡å‹å¾—åˆ† 22.7ï¼ˆæ’åç¬¬ 22ï¼‰ã€‚æ€»ä½“è€Œè¨€ï¼ŒPhysicsMinions æä¾›äº†ä¸€ä¸ªå¯æ³›åŒ–çš„æ¡†æ¶ï¼Œç”¨äºå¥¥æ—åŒ¹å…‹çº§åˆ«é—®é¢˜è§£å†³ï¼Œå…·æœ‰è·¨å­¦ç§‘æ‰©å±•çš„æ½œåŠ›ã€‚ 

---
# Spatial-Functional awareness Transformer-based graph archetype contrastive learning for Decoding Visual Neural Representations from EEG 

**Title (ZH)**: åŸºäºç©ºé—´-åŠŸèƒ½æ„ŸçŸ¥çš„Transformerå›¾åŸå‹å¯¹æ¯”å­¦ä¹ æ–¹æ³•ä»EEGè§£ç è§†è§‰ç¥ç»è¡¨ç¤º 

**Authors**: Yueming Sun, Long Yang  

**Link**: [PDF](https://arxiv.org/pdf/2509.24761)  

**Abstract**: Decoding visual neural representations from Electroencephalography (EEG) signals remains a formidable challenge due to their high-dimensional, noisy, and non-Euclidean nature. In this work, we propose a Spatial-Functional Awareness Transformer-based Graph Archetype Contrastive Learning (SFTG) framework to enhance EEG-based visual decoding. Specifically, we introduce the EEG Graph Transformer (EGT), a novel graph-based neural architecture that simultaneously encodes spatial brain connectivity and temporal neural dynamics. To mitigate high intra-subject variability, we propose Graph Archetype Contrastive Learning (GAC), which learns subject-specific EEG graph archetypes to improve feature consistency and class separability. Furthermore, we conduct comprehensive subject-dependent and subject-independent evaluations on the Things-EEG dataset, demonstrating that our approach significantly outperforms prior state-of-the-art EEG decoding this http URL results underscore the transformative potential of integrating graph-based learning with contrastive objectives to enhance EEG-based brain decoding, paving the way for more generalizable and robust neural representations. 

**Abstract (ZH)**: ä»è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·è§£ç è§†è§‰ç¥ç»è¡¨å¾æ˜¯ä¸€é¡¹è‰°å·¨çš„æŒ‘æˆ˜ï¼Œç”±äºå…¶é«˜ç»´ã€å™ªå£°å’Œéæ¬§å‡ é‡Œå¾—ç‰¹æ€§ã€‚åœ¨æ­¤å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºç©ºé—´-åŠŸèƒ½æ„è¯†å˜æ¢å™¨çš„å›¾åŸå‹å¯¹æ¯”å­¦ä¹ ï¼ˆSFTGï¼‰æ¡†æ¶ï¼Œä»¥å¢å¼ºåŸºäºEEGçš„è§†è§‰è§£ç ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†è„‘ç”µå›¾å˜æ¢å™¨ï¼ˆEGTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„åŸºäºå›¾çš„ç¥ç»æ¶æ„ï¼Œèƒ½å¤ŸåŒæ—¶ç¼–ç ç©ºé—´è„‘è¿æ¥æ€§å’Œæ—¶é—´ç¥ç»åŠ¨åŠ›å­¦ã€‚ä¸ºäº†å‡è½»é«˜è¢«è¯•å†…å˜å¼‚æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†å›¾åŸå‹å¯¹æ¯”å­¦ä¹ ï¼ˆGACï¼‰ï¼Œä»¥å­¦ä¹ è¢«è¯•ç‰¹å¼‚æ€§çš„EEGå›¾åŸå‹ï¼Œä»è€Œæé«˜ç‰¹å¾ä¸€è‡´æ€§å¹¶å¢å¼ºç±»åˆ«å¯åˆ†æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨Things-EEGæ•°æ®é›†ä¸­è¿›è¡Œäº†å…¨é¢çš„è¢«è¯•ä¾èµ–æ€§å’Œè¢«è¯•ç‹¬ç«‹æ€§è¯„ä¼°ï¼Œç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æœ€ä½³EEGè§£ç æ–¹æ³•ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†å°†åŸºäºå›¾çš„å­¦ä¹ ä¸å¯¹æ¯”ç›®æ ‡é›†æˆä»¥å¢å¼ºåŸºäºEEGçš„å¤§è„‘è§£ç çš„å˜é©æ½œåŠ›ï¼Œä¸ºæ›´æ³›åŒ–å’Œç¨³å¥çš„ç¥ç»è¡¨ç¤ºå¼€è¾Ÿäº†é“è·¯ã€‚ 

---
# Successful Misunderstandings: Learning to Coordinate Without Being Understood 

**Title (ZH)**: æˆåŠŸçš„è¯¯è§£ï¼šå­¦ä¹ åœ¨ä¸è¢«ç†è§£çš„æƒ…å†µä¸‹åè°ƒ 

**Authors**: Nikolaos Kondylidis, Anil Yaman, Frank van Harmelen, Erman Acar, Annette ten Teije  

**Link**: [PDF](https://arxiv.org/pdf/2509.24660)  

**Abstract**: The main approach to evaluating communication is by assessing how well it facilitates coordination. If two or more individuals can coordinate through communication, it is generally assumed that they understand one another. We investigate this assumption in a signaling game where individuals develop a new vocabulary of signals to coordinate successfully. In our game, the individuals do not have common observations besides the communication signal and outcome of the interaction, i.e. received reward. This setting is used as a proxy to study communication emergence in populations of agents that perceive their environment very differently, e.g. hybrid populations that include humans and artificial agents. Agents develop signals, use them, and refine interpretations while not observing how other agents are using them. While populations always converge to optimal levels of coordination, in some cases, interacting agents interpret and use signals differently, converging to what we call successful misunderstandings. However, agents of population that coordinate using misaligned interpretations, are unable to establish successful coordination with new interaction partners. Not leading to coordination failure immediately, successful misunderstandings are difficult to spot and repair. Having at least three agents that all interact with each other are the two minimum conditions to ensure the emergence of shared interpretations. Under these conditions, the agent population exhibits this emergent property of compensating for the lack of shared observations of signal use, ensuring the emergence of shared interpretations. 

**Abstract (ZH)**: è¯„ä¼°é€šä¿¡çš„ä¸»è¦æ–¹æ³•æ˜¯è€ƒå¯Ÿå…¶ä¿ƒè¿›åè°ƒçš„æ•ˆæœã€‚å¦‚æœä¸¤äººæˆ–å¤šäººèƒ½å¤Ÿé€šè¿‡é€šä¿¡åè°ƒä¸€è‡´ï¼Œé€šå¸¸å‡å®šä»–ä»¬ç›¸äº’ç†è§£ã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªä¿¡å·æ¸¸æˆä¸­ç ”ç©¶è¿™ä¸€å‡è®¾ï¼Œè¯¥æ¸¸æˆä¸­ä¸ªä½“å‘å±•å‡ºæ–°çš„ä¿¡å·è¯æ±‡ä»¥æˆåŠŸåè°ƒã€‚åœ¨æ¸¸æˆä¸­ï¼Œä¸ªä½“é™¤äº†é€šä¿¡ä¿¡å·å’Œäº¤äº’ç»“æœï¼ˆå³è·å¾—çš„å¥–åŠ±ï¼‰ä¹‹å¤–æ²¡æœ‰å…¶ä»–å…±åŒè§‚å¯Ÿã€‚è¿™ä¸€è®¾å®šè¢«ç”¨ä½œä»£ç†ï¼Œä»¥ç ”ç©¶åœ¨æ„ŸçŸ¥ç¯å¢ƒå·®å¼‚æå¤§çš„ä»£ç†ç§ç¾¤ä¸­é€šä¿¡çš„æ¶Œç°ã€‚ä»£ç†å¼€å‘ä¿¡å·ã€ä½¿ç”¨ä¿¡å·å¹¶æ”¹è¿›è§£é‡Šï¼Œä½†ä¸è§‚å¯Ÿå…¶ä»–ä»£ç†å¦‚ä½•ä½¿ç”¨ã€‚å°½ç®¡ç§ç¾¤æ€»æ˜¯ä¼šæ”¶æ•›åˆ°æœ€ä¼˜çš„åè°ƒæ°´å¹³ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œäº¤äº’ä»£ç†ä¼šä»¥ä¸åŒçš„æ–¹å¼è§£é‡Šå’Œä½¿ç”¨ä¿¡å·ï¼Œæœ€ç»ˆè¾¾åˆ°æˆ‘ä»¬ç§°ä¹‹ä¸ºæˆåŠŸçš„è¯¯è§£ã€‚ç„¶è€Œï¼Œä½¿ç”¨ä¸ä¸€è‡´è§£é‡Šè¿›è¡Œåè°ƒçš„ä»£ç†ç§ç¾¤æ— æ³•ä¸æ–°çš„äº¤äº’ä¼™ä¼´å»ºç«‹æœ‰æ•ˆçš„åè°ƒã€‚æˆåŠŸçš„è¯¯è§£ä¸å®¹æ˜“è¢«å‘ç°å’Œä¿®æ­£ï¼Œç›´åˆ°åè°ƒå¤±è´¥æ‰æ˜¾ç°å‡ºæ¥ã€‚è‡³å°‘æœ‰ä¸‰ä¸ªç›¸äº’ä½œç”¨çš„ä»£ç†æ˜¯ç¡®ä¿å…±äº«è§£é‡Šæ¶Œç°çš„ä¸¤ä¸ªæœ€å°æ¡ä»¶ã€‚åœ¨è¿™äº›æ¡ä»¶ä¸‹ï¼Œä»£ç†ç§ç¾¤è¡¨ç°å‡ºè¡¥å¿ç¼ºä¹ä¿¡å·ä½¿ç”¨å…±äº«è§‚å¯Ÿçš„æ¶Œç°ç‰¹æ€§ï¼Œä»è€Œç¡®ä¿å…±äº«è§£é‡Šçš„æ¶Œç°ã€‚ 

---
# "Stop replacing salt with sugar!'': Towards Intuitive Human-Agent Teaching 

**Title (ZH)**: â€œåœæ­¢ç”¨ç³–æ›¿ä»£ç›!â€ï¼šå‘ç€ç›´è§‰çš„äººæœºæ•™å­¦ 

**Authors**: Nikolaos Kondylidis, Andrea Rafanelli, Ilaria Tiddi, Annette ten Teije, Frank van Harmelen  

**Link**: [PDF](https://arxiv.org/pdf/2509.24651)  

**Abstract**: Humans quickly learn new concepts from a small number of examples. Replicating this capacity with Artificial Intelligence (AI) systems has proven to be challenging. When it comes to learning subjective tasks-where there is an evident scarcity of data-this capacity needs to be recreated. In this work, we propose an intuitive human-agent teaching architecture in which the human can teach an agent how to perform a task by providing demonstrations, i.e., examples. To have an intuitive interaction, we argue that the agent should be able to learn incrementally from a few single examples. To allow for this, our objective is to broaden the agent's task understanding using domain knowledge. Then, using a learning method to enable the agent to learn efficiently from a limited number of examples. Finally, to optimize how human can select the most representative and less redundant examples to provide the agent with. We apply our proposed method to the subjective task of ingredient substitution, where the agent needs to learn how to substitute ingredients in recipes based on human examples. We replicate human input using the Recipe1MSubs dataset. In our experiments, the agent achieves half its task performance after only 100 examples are provided, compared to the complete training set of 50k examples. We show that by providing examples in strategic order along with a learning method that leverages external symbolic knowledge, the agent can generalize more efficiently. 

**Abstract (ZH)**: äººç±»å¯ä»¥ä»å°‘é‡ç¤ºä¾‹ä¸­è¿…é€Ÿå­¦ä¹ æ–°æ¦‚å¿µã€‚åœ¨äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­å¤åˆ¶è¿™ä¸€èƒ½åŠ› provenå…·æœ‰æŒ‘æˆ˜æ€§ã€‚å¯¹äºå…·æœ‰æ˜æ˜¾æ•°æ®ç¨€ç¼ºæ€§çš„ä¸»è§‚ä»»åŠ¡ï¼Œè¿™ç§èƒ½åŠ›éœ€è¦é‡æ–°åˆ›é€ ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç›´è§‰çš„äººæœºæ•™å­¦æ¶æ„ï¼Œå…¶ä¸­äººç±»å¯ä»¥é€šè¿‡æ¼”ç¤ºï¼ˆå³ç¤ºä¾‹ï¼‰æ¥æ•™å¯¼ä»£ç†æ‰§è¡Œä»»åŠ¡ã€‚ä¸ºäº†å®ç°ç›´è§‚çš„äº¤äº’ï¼Œæˆ‘ä»¬è®¤ä¸ºä»£ç†åº”è¯¥èƒ½å¤Ÿä»å°‘é‡å•ä¸ªç¤ºä¾‹ä¸­è¿›è¡Œå¢é‡å­¦ä¹ ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ©ç”¨é¢†åŸŸçŸ¥è¯†æ¥æ‰©å±•ä»£ç†çš„ä»»åŠ¡ç†è§£ï¼Œç„¶åé€šè¿‡å­¦ä¹ æ–¹æ³•ä½¿ä»£ç†èƒ½å¤Ÿé«˜æ•ˆåœ°ä»æœ‰é™æ•°é‡çš„ç¤ºä¾‹ä¸­å­¦ä¹ ã€‚æœ€åï¼Œæˆ‘ä»¬ä¼˜åŒ–äº†äººç±»å¦‚ä½•é€‰æ‹©æœ€å…·ä»£è¡¨æ€§å’Œè¾ƒå°‘å†—ä½™çš„ç¤ºä¾‹æ¥æä¾›ç»™ä»£ç†çš„è¿‡ç¨‹ã€‚æˆ‘ä»¬å°†æå‡ºçš„æ–¹æ³•åº”ç”¨äºä¸»è§‚ä»»åŠ¡çš„ææ–™æ›¿æ¢ä»»åŠ¡ï¼Œä»£ç†éœ€è¦æ ¹æ®äººç±»ç¤ºä¾‹å­¦ä¹ å¦‚ä½•åœ¨é£Ÿè°±ä¸­æ›¿æ¢ææ–™ã€‚æˆ‘ä»¬ä½¿ç”¨Recipe1MSubsæ•°æ®é›†å¤åˆ¶äººç±»è¾“å…¥ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œä»£ç†åœ¨ä»…æä¾›100ä¸ªç¤ºä¾‹åå®Œæˆäº†å…¶ä»»åŠ¡æ€§èƒ½çš„ä¸€åŠï¼Œä¸å®Œæ•´çš„50,000ä¸ªç¤ºä¾‹è®­ç»ƒé›†ç›¸æ¯”ã€‚æˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡æŒ‰æˆ˜ç•¥é¡ºåºæä¾›ç¤ºä¾‹å¹¶ç»“åˆåˆ©ç”¨å¤–éƒ¨ç¬¦å·çŸ¥è¯†çš„å­¦ä¹ æ–¹æ³•ï¼Œä»£ç†å¯ä»¥æ›´æœ‰æ•ˆåœ°æ³›åŒ–ã€‚ 

---
# LTL$_f$ Learning Meets Boolean Set Cover 

**Title (ZH)**: LTL$_f$ å­¦ä¹ ä¸å¸ƒå°”é›†åˆè¦†ç›–ç›¸ç»“åˆ 

**Authors**: Gabriel Bathie, NathanaÃ«l Fijalkow, ThÃ©o Matricon, Baptiste Mouillon, Pierre Vandenhove  

**Link**: [PDF](https://arxiv.org/pdf/2509.24616)  

**Abstract**: Learning formulas in Linear Temporal Logic (LTLf) from finite traces is a fundamental research problem which has found applications in artificial intelligence, software engineering, programming languages, formal methods, control of cyber-physical systems, and robotics. We implement a new CPU tool called Bolt improving over the state of the art by learning formulas more than 100x faster over 70% of the benchmarks, with smaller or equal formulas in 98% of the cases. Our key insight is to leverage a problem called Boolean Set Cover as a subroutine to combine existing formulas using Boolean connectives. Thanks to the Boolean Set Cover component, our approach offers a novel trade-off between efficiency and formula size. 

**Abstract (ZH)**: ä»æœ‰é™è½¨è¿¹å­¦ä¹ çº¿æ€§æ—¶åºé€»è¾‘ï¼ˆLTLfï¼‰å…¬å¼ï¼šä¸€ç§æ¯”ç°æœ‰æŠ€æœ¯å¿«è¶…è¿‡100å€çš„æ–°CPUå·¥å…·åŠå…¶é«˜æ•ˆä¸å…¬å¼å¤§å°çš„æ–°å‹æƒè¡¡ 

---
# Neuroplasticity-inspired dynamic ANNs for multi-task demand forecasting 

**Title (ZH)**: ç¥ç»å¯å¡‘æ€§å¯å‘çš„åŠ¨æ€å¤šä»»åŠ¡éœ€æ±‚é¢„æµ‹ç¥ç»ç½‘ç»œ 

**Authors**: Mateusz Å»arski, SÅ‚awomir Nowaczyk  

**Link**: [PDF](https://arxiv.org/pdf/2509.24495)  

**Abstract**: This paper introduces a novel approach to Dynamic Artificial Neural Networks (D-ANNs) for multi-task demand forecasting called Neuroplastic Multi-Task Network (NMT-Net). Unlike conventional methods focusing on inference-time dynamics or computational efficiency, our proposed method enables structural adaptability of the computational graph during training, inspired by neuroplasticity as seen in biological systems. Each new task triggers a dynamic network adaptation, including similarity-based task identification and selective training of candidate ANN heads, which are then assessed and integrated into the model based on their performance. We evaluated our framework using three real-world multi-task demand forecasting datasets from Kaggle. We demonstrated its superior performance and consistency, achieving lower RMSE and standard deviation compared to traditional baselines and state-of-the-art multi-task learning methods. NMT-Net offers a scalable, adaptable solution for multi-task and continual learning in time series prediction. The complete code for NMT-Net is available from our GitHub repository. 

**Abstract (ZH)**: ä¸€ç§åŸºäºç¥ç»å¯å¡‘æ€§çš„å¤šä»»åŠ¡ç½‘ç»œï¼ˆNMT-Netï¼‰ç”¨äºå¤šä»»åŠ¡éœ€æ±‚é¢„æµ‹çš„åŠ¨æ€äººå·¥ç¥ç»ç½‘ç»œæ–¹æ³• 

---
# Overcoming Over-Fitting in Constraint Acquisition via Query-Driven Interactive Refinement 

**Title (ZH)**: é€šè¿‡æŸ¥è¯¢é©±åŠ¨çš„äº¤äº’å¼ç»†åŒ–å…‹æœçº¦æŸè·å–ä¸­çš„è¿‡æ‹Ÿåˆ 

**Authors**: Vasileios Balafas, Dimos Tsouros, Nikolaos Ploskas, Kostas Stergiou  

**Link**: [PDF](https://arxiv.org/pdf/2509.24489)  

**Abstract**: Manual modeling in Constraint Programming is a substantial bottleneck, which Constraint Acquisition (CA) aims to automate. However, passive CA methods are prone to over-fitting, often learning models that include spurious global constraints when trained on limited data, while purely active methods can be query-intensive. We introduce a hybrid CA framework specifically designed to address the challenge of over-fitting in CA. Our approach integrates passive learning for initial candidate generation, a query-driven interactive refinement phase that utilizes probabilistic confidence scores (initialized by machine learning priors) to systematically identify over-fitted constraints, and a specialized subset exploration mechanism to recover valid substructures from rejected candidates. A final active learning phase ensures model completeness. Extensive experiments on diverse benchmarks demonstrate that our interactive refinement phase is crucial for achieving high target model coverage and overall model accuracy from limited examples, doing so with manageable query complexity. This framework represents a substantial advancement towards robust and practical constraint acquisition in data-limited scenarios. 

**Abstract (ZH)**: æ‰‹åŠ¨å»ºæ¨¡æ˜¯çº¦æŸç¼–ç¨‹ä¸­çš„ä¸€ä¸ªé‡å¤§ç“¶é¢ˆï¼Œçº¦æŸè·å–ï¼ˆCAï¼‰æ—¨åœ¨è‡ªåŠ¨å®Œæˆè¿™ä¸€è¿‡ç¨‹ã€‚ç„¶è€Œï¼Œè¢«åŠ¨çš„CAæ–¹æ³•å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œåœ¨æœ‰é™æ•°æ®ä¸‹å¾€å¾€ä¼šå­¦ä¹ åˆ°åŒ…å«è™šå‡å…¨å±€çº¦æŸçš„æ¨¡å‹ï¼Œè€Œçº¯ç²¹çš„ä¸»åŠ¨æ–¹æ³•åˆ™å¯èƒ½æŸ¥è¯¢å¯†é›†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆCAæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³CAä¸­çš„è¿‡æ‹ŸåˆæŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡è¢«åŠ¨å­¦ä¹ ç”Ÿæˆåˆå§‹å€™é€‰æ¨¡å‹ï¼Œé€šè¿‡åŸºäºæ¦‚ç‡ç½®ä¿¡åˆ†æ•°ï¼ˆç”±æœºå™¨å­¦ä¹ å…ˆéªŒåˆå§‹åŒ–ï¼‰çš„æŸ¥è¯¢é©±åŠ¨äº¤äº’å¼ç»†åŒ–é˜¶æ®µç³»ç»Ÿåœ°è¯†åˆ«è¿‡æ‹Ÿåˆçº¦æŸï¼Œå¹¶é€šè¿‡ä¸“é—¨çš„å­é›†æ¢ç´¢æœºåˆ¶ä»è¢«æ‹’ç»çš„å€™é€‰æ¨¡å‹ä¸­æ¢å¤æœ‰æ•ˆçš„å­ç»“æ„ã€‚æœ€ç»ˆçš„ä¸»åŠ¨å­¦ä¹ é˜¶æ®µç¡®ä¿æ¨¡å‹å®Œå¤‡æ€§ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„äº¤äº’å¼ç»†åŒ–é˜¶æ®µå¯¹äºä»æœ‰é™ç¤ºä¾‹ä¸­å®ç°é«˜ç›®æ ‡æ¨¡å‹è¦†ç›–åº¦å’Œæ•´ä½“æ¨¡å‹å‡†ç¡®æ€§è‡³å…³é‡è¦ï¼Œå¹¶ä¸”æŸ¥è¯¢å¤æ‚æ€§å¯ç®¡ç†ã€‚è¯¥æ¡†æ¶æœç€åœ¨æ•°æ®å—é™åœºæ™¯ä¸‹å®ç°ç¨³å¥ä¸”å®ç”¨çš„çº¦æŸè·å–è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚ 

---
# A Systematic Review of Digital Twin-Driven Predictive Maintenance in Industrial Engineering: Taxonomy, Architectural Elements, and Future Research Directions 

**Title (ZH)**: æ•°å­—å­ªç”Ÿé©±åŠ¨çš„å·¥ä¸šå·¥ç¨‹é¢„æµ‹æ€§ç»´æŠ¤ç»¼è¿°ï¼šåˆ†ç±»ã€æ¶æ„è¦ç´ åŠæœªæ¥ç ”ç©¶æ–¹å‘ 

**Authors**: Leila Ismail, Abdelmoneim Abdelmoti, Arkaprabha Basu, Aymen Dia Eddine Berini, Mohammad Naouss  

**Link**: [PDF](https://arxiv.org/pdf/2509.24443)  

**Abstract**: With the increasing complexity of industrial systems, there is a pressing need for predictive maintenance to avoid costly downtime and disastrous outcomes that could be life-threatening in certain domains. With the growing popularity of the Internet of Things, Artificial Intelligence, machine learning, and real-time big data analytics, there is a unique opportunity for efficient predictive maintenance to forecast equipment failures for real-time intervention and optimize maintenance actions, as traditional reactive and preventive maintenance practices are often inadequate to meet the requirements for the industry to provide quality-of-services of operations. Central to this evolution is digital twin technology, an adaptive virtual replica that continuously monitors and integrates sensor data to simulate and improve asset performance. Despite remarkable progress in digital twin implementations, such as considering DT in predictive maintenance for industrial engineering. This paper aims to address this void. We perform a retrospective analysis of the temporal evolution of the digital twin in predictive maintenance for industrial engineering to capture the applications, middleware, and technological requirements that led to the development of the digital twin from its inception to the AI-enabled digital twin and its self-learning models. We provide a layered architecture of the digital twin technology, as well as a taxonomy of the technology-enabled industrial engineering applications systems, middleware, and the used Artificial Intelligence algorithms. We provide insights into these systems for the realization of a trustworthy and efficient smart digital-twin industrial engineering ecosystem. We discuss future research directions in digital twin for predictive maintenance in industrial engineering. 

**Abstract (ZH)**: éšç€å·¥ä¸šç³»ç»Ÿçš„æ—¥ç›Šå¤æ‚ï¼Œè¿«åˆ‡éœ€è¦é¢„æµ‹æ€§ç»´æŠ¤ä»¥é¿å…æ˜‚è´µçš„åœæœºæ—¶é—´å’Œå¯èƒ½åœ¨æŸäº›é¢†åŸŸå¸¦æ¥ç”Ÿå‘½å±é™©çš„ç¾éš¾æ€§ç»“æœã€‚éšç€ç‰©è”ç½‘ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ å’Œå®æ—¶å¤§æ•°æ®åˆ†æçš„æ—¥ç›Šæµè¡Œï¼Œè¿™ä¸ºé«˜æ•ˆçš„é¢„æµ‹æ€§ç»´æŠ¤æä¾›äº†ç‹¬ç‰¹æœºä¼šï¼Œå¯ä»¥é¢„æµ‹è®¾å¤‡æ•…éšœå¹¶è¿›è¡Œå®æ—¶å¹²é¢„ï¼Œä¼˜åŒ–ç»´æŠ¤è¡ŒåŠ¨ï¼Œè€Œä¼ ç»Ÿçš„è¢«åŠ¨å’Œé¢„é˜²æ€§ç»´æŠ¤å®è·µå¾€å¾€æ— æ³•æ»¡è¶³å·¥ä¸šæä¾›æœåŠ¡è´¨é‡çš„è¦æ±‚ã€‚è¿™ä¸€æ¼”å˜çš„æ ¸å¿ƒæ˜¯æ•°å­—å­ªç”ŸæŠ€æœ¯ï¼Œè¿™æ˜¯ä¸€ç§é€‚åº”æ€§çš„è™šæ‹Ÿå¤åˆ¶å“ï¼ŒæŒç»­ç›‘æ§å¹¶æ•´åˆä¼ æ„Ÿå™¨æ•°æ®ä»¥æ¨¡æ‹Ÿå’Œæ”¹å–„èµ„äº§æ€§èƒ½ã€‚å°½ç®¡åœ¨æ•°å­—å­ªç”Ÿå®æ–½æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¦‚å°†æ•°å­—å­ªç”Ÿåº”ç”¨äºå·¥ä¸šå·¥ç¨‹çš„é¢„æµ‹æ€§ç»´æŠ¤ã€‚æœ¬æ–‡æ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬å¯¹æ•°å­—å­ªç”Ÿåœ¨å·¥ä¸šå·¥ç¨‹ä¸­é¢„æµ‹æ€§ç»´æŠ¤é¢†åŸŸçš„å†æ—¶æ¼”å˜è¿›è¡Œäº†å›é¡¾æ€§åˆ†æï¼Œä»¥æ•æ‰ä»æ•°å­—å­ªç”Ÿçš„èµ·æºåˆ°AIé©±åŠ¨çš„æ•°å­—å­ªç”ŸåŠå…¶è‡ªå­¦ä¹ æ¨¡å‹çš„å‘å±•è¿‡ç¨‹ä¸­æ‰€ä¾èµ–çš„åº”ç”¨ã€ä¸­é—´ä»¶å’ŒæŠ€æœ¯è¦æ±‚ã€‚æˆ‘ä»¬æä¾›äº†æ•°å­—å­ªç”ŸæŠ€æœ¯çš„åˆ†å±‚æ¶æ„ï¼Œå¹¶å¯¹æŠ€æœ¯èµ‹èƒ½çš„å·¥ä¸šå·¥ç¨‹åº”ç”¨ç³»ç»Ÿã€ä¸­é—´ä»¶ä»¥åŠä½¿ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œäº†åˆ†ç±»ã€‚æˆ‘ä»¬æä¾›äº†è¿™äº›ç³»ç»Ÿçš„è§è§£ï¼Œä»¥å®ç°å¯ä¿¡èµ–ä¸”é«˜æ•ˆçš„æ™ºèƒ½æ•°å­—å­ªç”Ÿå·¥ä¸šå·¥ç¨‹ç”Ÿæ€ä½“ç³»ã€‚æˆ‘ä»¬è®¨è®ºäº†æ•°å­—å­ªç”Ÿåœ¨å·¥ä¸šå·¥ç¨‹ä¸­é¢„æµ‹æ€§ç»´æŠ¤æ–¹é¢çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚ 

---
# humancompatible.detect: a Python Toolkit for Detecting Bias in AI Models 

**Title (ZH)**: humancompatible.detect: ä¸€ä¸ªæ£€æµ‹AIæ¨¡å‹åè§çš„Pythonå·¥å…·åŒ… 

**Authors**: German M. Matilla, Jiri Nemecek, Illia Kryvoviaz, Jakub Marecek  

**Link**: [PDF](https://arxiv.org/pdf/2509.24340)  

**Abstract**: There is a strong recent emphasis on trustworthy AI. In particular, international regulations, such as the AI Act, demand that AI practitioners measure data quality on the input and estimate bias on the output of high-risk AI systems. However, there are many challenges involved, including scalability (MMD) and computability (Wasserstein-1) issues of traditional methods for estimating distances on measure spaces. Here, we present this http URL, a toolkit for bias detection that addresses these challenges. It incorporates two newly developed methods to detect and evaluate bias: maximum subgroup discrepancy (MSD) and subsampled $\ell_\infty$ distances. It has an easy-to-use API documented with multiple examples. this http URL is licensed under the Apache License, Version 2.0. 

**Abstract (ZH)**: è¿‘æœŸå¯¹å¯ä¿¡AIçš„é«˜åº¦å…³æ³¨ã€‚ç‰¹åˆ«æ˜¯å›½é™…æ³•è§„ï¼Œå¦‚AIæ³•æ¡ˆï¼Œè¦æ±‚AIä»ä¸šäººå‘˜è¡¡é‡è¾“å…¥æ•°æ®è´¨é‡å¹¶åœ¨é«˜é£é™©AIç³»ç»Ÿçš„è¾“å‡ºä¸­ä¼°ç®—åå·®ã€‚ç„¶è€Œï¼Œè¿™æ¶‰åŠè®¸å¤šæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬è¡¡é‡ç©ºé—´ä¸­ä¼ ç»Ÿæ–¹æ³•ä¼°è®¡è·ç¦»çš„å¯æ‰©å±•æ€§ï¼ˆMMDï¼‰å’Œå¯è®¡ç®—æ€§ï¼ˆWasserstein-1ï¼‰é—®é¢˜ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬ä»‹ç»è¿™ä¸ªå·¥å…·åŒ…ï¼šç”¨äºæ£€æµ‹åå·®çš„å·¥å…·åŒ…ï¼Œå®ƒè§£å†³äº†è¿™äº›æŒ‘æˆ˜ã€‚è¯¥å·¥å…·åŒ…æ•´åˆäº†ä¸¤ç§æ–°å¼€å‘çš„æ–¹æ³•æ¥æ£€æµ‹å’Œè¯„ä¼°åå·®ï¼šæœ€å¤§å­ç»„ç¦»æ•£åº¦ï¼ˆMSDï¼‰å’Œé‡‡æ ·åçš„$\ell_\infty$è·ç¦»ã€‚å®ƒå…·æœ‰æ˜“äºä½¿ç”¨çš„APIï¼Œå¹¶é™„æœ‰å¤šä¾‹æ–‡æ¡£è¯´æ˜ã€‚è¿™ä¸ªå·¥å…·åŒ…é‡‡ç”¨Apache License, Version 2.0è®¸å¯ã€‚ 

---
# Experience Paper: Adopting Activity Recognition in On-demand Food Delivery Business 

**Title (ZH)**: ç»éªŒè®ºæ–‡ï¼šåœ¨å³æ—¶é£Ÿå“é…é€ä¸šåŠ¡ä¸­é‡‡ç”¨æ´»åŠ¨è¯†åˆ« 

**Authors**: Huatao Xu, Yan Zhang, Wei Gao, Guobin Shen, Mo Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.24303)  

**Abstract**: This paper presents the first nationwide deployment of human activity recognition (HAR) technology in the on-demand food delivery industry. We successfully adapted the state-of-the-art LIMU-BERT foundation model to the delivery platform. Spanning three phases over two years, the deployment progresses from a feasibility study in Yangzhou City to nationwide adoption involving 500,000 couriers across 367 cities in China. The adoption enables a series of downstream applications, and large-scale tests demonstrate its significant operational and economic benefits, showcasing the transformative potential of HAR technology in real-world applications. Additionally, we share lessons learned from this deployment and open-source our LIMU-BERT pretrained with millions of hours of sensor data. 

**Abstract (ZH)**: æœ¬æ–‡ä»‹ç»äº†é¦–æ¬¡åœ¨å…¨å›½èŒƒå›´å†…å°†äººä½“æ´»åŠ¨è¯†åˆ«ï¼ˆHARï¼‰æŠ€æœ¯åº”ç”¨äºæŒ‰éœ€é£Ÿå“é…é€è¡Œä¸šã€‚æˆ‘ä»¬æˆåŠŸå°†å…ˆè¿›çš„LIMU-BERTåŸºç¡€æ¨¡å‹é€‚åº”åˆ°é…é€å¹³å°ã€‚å†æ—¶ä¸¤å¹´ï¼Œéƒ¨ç½²åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œä»æ‰¬å·å¸‚çš„å¯è¡Œæ€§ç ”ç©¶æ‰©å±•åˆ°å…¨å›½367ä¸ªåŸå¸‚ï¼Œæ¶‰åŠ500,000åé…é€å‘˜ã€‚è¯¥é‡‡ç”¨ä½¿ä¸€ç³»åˆ—ä¸‹æ¸¸åº”ç”¨æˆä¸ºå¯èƒ½ï¼Œå¤§è§„æ¨¡æµ‹è¯•è¡¨æ˜å…¶åœ¨è¿è¥å’Œç»æµæ–¹é¢çš„æ˜¾è‘—æ•ˆç›Šï¼Œå±•ç¤ºäº†HARæŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„å˜é©æ½œåŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†äº«äº†æ­¤æ¬¡éƒ¨ç½²çš„ç»éªŒæ•™è®­ï¼Œå¹¶å¼€æºäº†åŸºäºæ•°ç™¾ä¸‡å°æ—¶ä¼ æ„Ÿå™¨æ•°æ®é¢„è®­ç»ƒçš„LIMU-BERTæ¨¡å‹ã€‚ 

---
# PAME-AI: Patient Messaging Creation and Optimization using Agentic AI 

**Title (ZH)**: PAME-AIï¼šä½¿ç”¨ä»£ç†äººå·¥æ™ºèƒ½è¿›è¡Œæ‚£è€…æ¶ˆæ¯åˆ›å»ºä¸ä¼˜åŒ– 

**Authors**: Junjie Luo, Yihong Guo, Anqi Liu, Ritu Agarwal, Gordon  

**Link**: [PDF](https://arxiv.org/pdf/2509.24263)  

**Abstract**: Messaging patients is a critical part of healthcare communication, helping to improve things like medication adherence and healthy behaviors. However, traditional mobile message design has significant limitations due to its inability to explore the high-dimensional design space. We develop PAME-AI, a novel approach for Patient Messaging Creation and Optimization using Agentic AI. Built on the Data-Information-Knowledge-Wisdom (DIKW) hierarchy, PAME-AI offers a structured framework to move from raw data to actionable insights for high-performance messaging design. PAME-AI is composed of a system of specialized computational agents that progressively transform raw experimental data into actionable message design strategies. We demonstrate our approach's effectiveness through a two-stage experiment, comprising of 444,691 patient encounters in Stage 1 and 74,908 in Stage 2. The best-performing generated message achieved 68.76% engagement compared to the 61.27% baseline, representing a 12.2\% relative improvement in click-through rates. This agentic architecture enables parallel processing, hypothesis validation, and continuous learning, making it particularly suitable for large-scale healthcare communication optimization. 

**Abstract (ZH)**: åŸºäºä»£ç†AIçš„æ‚£è€…ä¿¡æ¯åˆ›è®¾ä¸ä¼˜åŒ–ï¼šPAME-AIæ–¹æ³• 

---
# Interactive Program Synthesis for Modeling Collaborative Physical Activities from Narrated Demonstrations 

**Title (ZH)**: åŸºäºå™è¿°æ¼”ç¤ºçš„åä½œç‰©ç†æ´»åŠ¨å»ºæ¨¡çš„äº¤äº’å¼ç¨‹åºåˆæˆ 

**Authors**: Edward Kim, Daniel He, Jorge Chao, Wiktor Rajca, Mohammed Amin, Nishant Malpani, Ruta Desai, Antti Oulasvirta, Bjoern Hartmann, Sanjit Seshia  

**Link**: [PDF](https://arxiv.org/pdf/2509.24250)  

**Abstract**: Teaching systems physical tasks is a long standing goal in HCI, yet most prior work has focused on non collaborative physical activities. Collaborative tasks introduce added complexity, requiring systems to infer users assumptions about their teammates intent, which is an inherently ambiguous and dynamic process. This necessitates representations that are interpretable and correctable, enabling users to inspect and refine system behavior. We address this challenge by framing collaborative task learning as a program synthesis problem. Our system represents behavior as editable programs and uses narrated demonstrations, i.e. paired physical actions and natural language, as a unified modality for teaching, inspecting, and correcting system logic without requiring users to see or write code. The same modality is used for the system to communicate its learning to users. In a within subjects study, 20 users taught multiplayer soccer tactics to our system. 70 percent (14/20) of participants successfully refined learned programs to match their intent and 90 percent (18/20) found it easy to correct the programs. The study surfaced unique challenges in representing learning as programs and in enabling users to teach collaborative physical activities. We discuss these issues and outline mitigation strategies. 

**Abstract (ZH)**: åœ¨äººæœºäº¤äº’ä¸­æ•™æˆç³»ç»Ÿæ‰§è¡Œç‰©ç†ä»»åŠ¡æ˜¯ä¸€é¡¹é•¿æœŸç›®æ ‡ï¼Œä½†å¤§å¤šæ•°å…ˆå‰çš„å·¥ä½œé›†ä¸­åœ¨éåä½œçš„ç‰©ç†æ´»åŠ¨ä¸Šã€‚åä½œä»»åŠ¡å¢åŠ äº†å¤æ‚æ€§ï¼Œè¦æ±‚ç³»ç»Ÿæ¨æ–­ç”¨æˆ·å¯¹å…¶é˜Ÿå‹æ„å›¾çš„å‡è®¾ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ¬è´¨ä¸Šæ—¢æ¨¡ç³ŠåˆåŠ¨æ€çš„è¿‡ç¨‹ã€‚è¿™éœ€è¦å¯è§£é‡Šä¸”å¯çº æ­£çš„è¡¨ç¤ºï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ£€æŸ¥å’Œæ”¹è¿›ç³»ç»Ÿè¡Œä¸ºã€‚æˆ‘ä»¬é€šè¿‡å°†åä½œä»»åŠ¡å­¦ä¹ æ¡†å®šä¸ºç¨‹åºåˆæˆé—®é¢˜æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå°†è¡Œä¸ºè¡¨ç¤ºä¸ºå¯ç¼–è¾‘çš„ç¨‹åºï¼Œå¹¶ä½¿ç”¨å™è¿°æ€§ç¤ºèŒƒï¼Œå³é…å¯¹çš„ç‰©ç†åŠ¨ä½œå’Œè‡ªç„¶è¯­è¨€ï¼Œä½œä¸ºä¸€ç§ç»Ÿä¸€çš„æ¨¡æ€ï¼Œç”¨äºæ•™å­¦ã€æ£€æŸ¥å’Œçº æ­£ç³»ç»Ÿé€»è¾‘ï¼Œè€Œæ— éœ€ç”¨æˆ·çœ‹åˆ°æˆ–ç¼–å†™ä»£ç ã€‚ç³»ç»ŸåŒæ ·ä½¿ç”¨è¿™ç§æ¨¡æ€å‘ç”¨æˆ·ä¼ è¾¾å…¶æ‰€å­¦å†…å®¹ã€‚åœ¨ä¸€é¡¹å•è¢«è¯•å†…ç ”ç©¶ä¸­ï¼Œ20åç”¨æˆ·æ•™æˆ‘ä»¬çš„ç³»ç»Ÿå¤šç©å®¶è¶³çƒæˆ˜æœ¯ã€‚70%ï¼ˆ14/20ï¼‰çš„å‚ä¸è€…æˆåŠŸåœ°ä¿®æ­£äº†æ‰€å­¦ç¨‹åºä»¥åŒ¹é…å…¶æ„å›¾ï¼Œ90%ï¼ˆ18/20ï¼‰çš„å‚ä¸è€…å‘ç°ä¿®æ­£ç¨‹åºå¾ˆå®¹æ˜“ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†å°†å­¦ä¹ è¡¨ç¤ºä¸ºç¨‹åºä»¥åŠä½¿ç”¨æˆ·èƒ½å¤Ÿæ•™æˆåä½œç‰©ç†æ´»åŠ¨æ—¶çš„ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æˆ‘ä»¬è®¨è®ºäº†è¿™äº›é—®é¢˜å¹¶æ¦‚è¿°äº†ç¼“è§£ç­–ç•¥ã€‚ 

---
# SpecExit: Accelerating Large Reasoning Model via Speculative Exit 

**Title (ZH)**: SpecExitï¼š throughæ¨æµ‹æ€§é€€å‡ºåŠ é€Ÿå¤§å‹æ¨ç†æ¨¡å‹ 

**Authors**: Rubing Yang, Huajun Bai, Song Liu, Guanghua Yu, Runzhi Fan, Yanbin Dang, Jiejing Zhang, Kai Liu, Jianchen Zhu, Peng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.24248)  

**Abstract**: Despite their strong performance on reasoning tasks, large reasoning models (LRMs) often suffer from overthinking, producing unnecessarily long outputs and incurring high end-to-end latency, a significant limitation to their real-world deployment. To address overthinking, early-exit mechanisms have been proposed to terminate reasoning before typical completion, showing that this approach can effectively shorten generation length with minimal impact on accuracy. However, their reliance on probing mechanisms introduces a detection overhead that limits their end-to-end latency gains and compromises their generalizability across diverse problems. Inspired by the use of hidden states in speculative decoding, we propose SpecExit, a novel framework that predicts both future tokens and an early-exit signal directly from a lightweight draft model without probing overhead. Our method offers significant improvements, reducing average generation length by 66\% and achieving a 2.5x speedup in end-to-end latency compared to the speculative decoding baseline, without compromising accuracy. Our method leverages the inherent signals from hidden states to provide effective early-exit signals, suggesting broader use of hidden states for efficient reasoning. Our code is available at this https URL. 

**Abstract (ZH)**: å°½ç®¡å¤§å‹æ¨ç†æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬å¾€å¾€ä¼šè¿‡åº¦æ¨ç†ï¼Œç”Ÿæˆä¸å¿…è¦çš„é•¿è¾“å‡ºï¼Œå¹¶å¯¼è‡´è¾ƒé«˜çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œè¿™æˆä¸ºå…¶å®é™…éƒ¨ç½²ä¸­çš„ä¸€ä¸ªé‡è¦é™åˆ¶ã€‚ä¸ºè§£å†³è¿‡åº¦æ¨ç†é—®é¢˜ï¼Œå·²æå‡ºäº†æ—©æœŸé€€å‡ºæœºåˆ¶ï¼Œå¯ä»¥åœ¨å…¸å‹å®Œæˆä¹‹å‰ç»ˆæ­¢æ¨ç†ï¼Œè¡¨æ˜è¿™ç§æ–¹æ³•å¯ä»¥åœ¨ä¸æ˜¾è‘—å½±å“å‡†ç¡®æ€§çš„å‰æä¸‹æœ‰æ•ˆç¼©çŸ­ç”Ÿæˆé•¿åº¦ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºæ¢é’ˆæœºåˆ¶ï¼Œå¼•å…¥äº†æ£€æµ‹å¼€é”€ï¼Œé™åˆ¶äº†å…¶ç«¯åˆ°ç«¯å»¶è¿Ÿçš„æ”¹è¿›ï¼Œå¹¶é™ä½äº†å…¶åœ¨å¤šæ ·é—®é¢˜ä¸Šçš„æ™®é€‚æ€§ã€‚å—æŠ•æœºè§£ç ä¸­éšè—çŠ¶æ€ä½¿ç”¨å¯å‘ï¼Œæˆ‘ä»¬æå‡ºSpecExitï¼Œä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œå¯ä»¥ç›´æ¥ä»è½»é‡çº§è‰å›¾æ¨¡å‹ä¸­é¢„æµ‹æœªæ¥çš„ä»¤ç‰Œå’Œæ—©æœŸé€€å‡ºä¿¡å·ï¼Œè€Œä¸éœ€è¦æ¢é’ˆå¼€é”€ã€‚æˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œå¹³å‡ç”Ÿæˆé•¿åº¦å‡å°‘äº†66%ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿæé«˜äº†2.5å€ï¼ŒåŒæ—¶ä¿æŒäº†å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨éšè—çŠ¶æ€ä¸­çš„å›ºæœ‰ä¿¡å·æä¾›æœ‰æ•ˆçš„æ—©æœŸé€€å‡ºä¿¡å·ï¼Œè¡¨æ˜éšè—çŠ¶æ€åœ¨é«˜æ•ˆæ¨ç†ä¸­çš„æ›´å¹¿æ³›ä½¿ç”¨ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨æ­¤è®¿é—®ï¼šthis https URLã€‚ 

---
# Humanline: Online Alignment as Perceptual Loss 

**Title (ZH)**: Humanline: åœ¨çº¿å¯¹é½ä½œä¸ºæ„ŸçŸ¥æŸå¤± 

**Authors**: Sijia Liu, Niklas Muennighoff, Kawin Ethayarajh  

**Link**: [PDF](https://arxiv.org/pdf/2509.24207)  

**Abstract**: Online alignment (e.g., GRPO) is generally more performant than offline alignment (e.g., DPO) -- but why? Drawing on prospect theory from behavioral economics, we propose a human-centric explanation. We prove that online on-policy sampling better approximates the human-perceived distribution of what the model can produce, and PPO/GRPO-style clipping -- originally introduced to just stabilize training -- recovers a perceptual bias in how humans perceive probability. In this sense, PPO/GRPO act as perceptual losses already. Our theory further suggests that the online/offline dichotomy is itself incidental to maximizing human utility, since we can achieve the same effect by selectively training on any data in a manner that mimics human perception, rather than restricting ourselves to online on-policy data. Doing so would allow us to post-train more quickly, cheaply, and flexibly without sacrificing performance. To this end, we propose a design pattern that explicitly incorporates perceptual distortions of probability into objectives like DPO/KTO/GRPO, creating humanline variants of them. Surprisingly, we find that these humanline variants, even when trained with offline off-policy data, can match the performance of their online counterparts on both verifiable and unverifiable tasks. 

**Abstract (ZH)**: åŸºäºè¡Œä¸ºç»æµå­¦å‰æ™¯ç†è®ºçš„åœ¨çº¿å¯¹é½ä¸ºä½•æ›´ä¼˜â€”â€”ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„è§£é‡ŠåŠå…¶å®éªŒè®¾è®¡ 

---
# Reasoning or Retrieval? A Study of Answer Attribution on Large Reasoning Models 

**Title (ZH)**: æ¨ç†è¿˜æ˜¯æ£€ç´¢ï¼Ÿå¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„ç­”æ¡ˆå½’å› ç ”ç©¶ 

**Authors**: Yuhui Wang, Changjiang Li, Guangke Chen, Jiacheng Liang, Ting Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.24156)  

**Abstract**: Large reasoning models (LRMs) exhibit unprecedented capabilities in solving complex problems through Chain-of-Thought (CoT) reasoning. However, recent studies reveal that their final answers often contradict their own reasoning traces. We hypothesize that this inconsistency stems from two competing mechanisms for generating answers: CoT reasoning and memory retrieval. To test this hypothesis, we conduct controlled experiments that challenge LRMs with misleading cues during reasoning and/or corrupted answers during retrieval. Our results across models and datasets confirm that both mechanisms operate simultaneously, with their relative dominance influenced by multiple factors: problem domains, model scales, and fine-tuning approaches (e.g., reinforcement learning vs. distillation). The findings reveal a critical limitation in current reasoning fine-tuning paradigms: models can exploit the retrieval mechanism as a shortcut, effectively "hacking" the reward signal and undermining genuine reasoning development. To address this challenge, we introduce FARL, a novel fine-tuning framework that integrates memory unlearning with reinforcement learning. By carefully suppressing retrieval shortcuts during the fine-tuning process, FARL promotes reasoning-dominant behavior and enhances generalizable reasoning capabilities. 

**Abstract (ZH)**: å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰é€šè¿‡é“¾å¼æ¨ç†ï¼ˆCoTï¼‰å±•ç°å‡ºè§£å†³å¤æ‚é—®é¢˜çš„å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œå®ƒä»¬çš„æœ€ç»ˆç­”æ¡ˆå¾€å¾€ä¸å…¶æ¨ç†è½¨è¿¹ç›¸çŸ›ç›¾ã€‚æˆ‘ä»¬å‡è®¾è¿™ç§ä¸ä¸€è‡´æ€§æºè‡ªç”Ÿæˆç­”æ¡ˆçš„ä¸¤ç§ç«äº‰æœºåˆ¶ï¼šé“¾å¼æ¨ç†å’Œè®°å¿†æ£€ç´¢ã€‚ä¸ºäº†æ£€éªŒè¿™ä¸€å‡è®¾ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ§åˆ¶å®éªŒï¼Œè¿™äº›å®éªŒåœ¨æ¨ç†è¿‡ç¨‹ä¸­æˆ–æ£€ç´¢è¿‡ç¨‹ä¸­å‘LRMsæä¾›è¯¯å¯¼æ€§çº¿ç´¢æˆ–é”™è¯¯çš„ç­”æ¡ˆã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¯å®ï¼Œè¿™ä¸¤ç§æœºåˆ¶åŒæ—¶è¿ä½œï¼Œå®ƒä»¬çš„ç›¸å¯¹ä¸»å¯¼åœ°ä½å—å¤šç§å› ç´ å½±å“ï¼šé—®é¢˜é¢†åŸŸã€æ¨¡å‹è§„æ¨¡ä»¥åŠå¾®è°ƒæ–¹æ³•ï¼ˆä¾‹å¦‚å¼ºåŒ–å­¦ä¹ ä¸è’¸é¦ï¼‰ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å½“å‰æ¨ç†å¾®è°ƒèŒƒå¼çš„ä¸€ä¸ªå…³é”®å±€é™æ€§ï¼šæ¨¡å‹å¯ä»¥åˆ©ç”¨æ£€ç´¢æœºåˆ¶ä½œä¸ºæ·å¾„ï¼Œæœ‰æ•ˆåœ°â€œ hackâ€å¥–åŠ±ä¿¡å·ï¼Œå‰Šå¼±çœŸæ­£çš„æ¨ç†å‘å±•ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºFARLçš„æ–°é¢–å¾®è°ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†è®°å¿†é—å¿˜ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆã€‚é€šè¿‡åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ç²¾å¿ƒæŠ‘åˆ¶æ£€ç´¢æ·å¾„ï¼ŒFARLä¿ƒè¿›äº†ä»¥æ¨ç†ä¸ºä¸»çš„æœºåˆ¶å¹¶å¢å¼ºäº†å¯æ³›åŒ–çš„æ¨ç†èƒ½åŠ›ã€‚ 

---
# Transparent, Evaluable, and Accessible Data Agents: A Proof-of-Concept Framework 

**Title (ZH)**: é€æ˜ã€å¯è¯„ä¼°ä¸”å¯è®¿é—®çš„æ•°æ®ä»£ç†ï¼šä¸€ä¸ªæ¦‚å¿µéªŒè¯æ¡†æ¶ 

**Authors**: Nooshin Bahador  

**Link**: [PDF](https://arxiv.org/pdf/2509.24127)  

**Abstract**: This article presents a modular, component-based architecture for developing and evaluating AI agents that bridge the gap between natural language interfaces and complex enterprise data warehouses. The system directly addresses core challenges in data accessibility by enabling non-technical users to interact with complex data warehouses through a conversational interface, translating ambiguous user intent into precise, executable database queries to overcome semantic gaps. A cornerstone of the design is its commitment to transparent decision-making, achieved through a multi-layered reasoning framework that explains the "why" behind every decision, allowing for full interpretability by tracing conclusions through specific, activated business rules and data points. The architecture integrates a robust quality assurance mechanism via an automated evaluation framework that serves multiple functions: it enables performance benchmarking by objectively measuring agent performance against golden standards, and it ensures system reliability by automating the detection of performance regressions during updates. The agent's analytical depth is enhanced by a statistical context module, which quantifies deviations from normative behavior, ensuring all conclusions are supported by quantitative evidence including concrete data, percentages, and statistical comparisons. We demonstrate the efficacy of this integrated agent-development-with-evaluation framework through a case study on an insurance claims processing system. The agent, built on a modular architecture, leverages the BigQuery ecosystem to perform secure data retrieval, apply domain-specific business rules, and generate human-auditable justifications. The results confirm that this approach creates a robust, evaluable, and trustworthy system for deploying LLM-powered agents in data-sensitive, high-stakes domains. 

**Abstract (ZH)**: åŸºäºæ¨¡å—åŒ–ç»„ä»¶çš„è®¾è®¡ï¼šç»“åˆè‡ªç„¶è¯­è¨€æ¥å£ä¸å¤æ‚ä¼ä¸šæ•°æ®ä»“åº“çš„AIä»£ç†å¼€å‘ä¸è¯„ä¼°æ¶æ„ 

---
# Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and Synthesis for SLMs 

**Title (ZH)**: Fathom-DeepResearch: è§£é”SLMsçš„é•¿æ—¶ä¿¡æ¯æ£€ç´¢ä¸åˆæˆèƒ½åŠ› 

**Authors**: Shreyas Singh, Kunal Singh, Pradeep Moturi  

**Link**: [PDF](https://arxiv.org/pdf/2509.24107)  

**Abstract**: Tool-integrated reasoning has emerged as a key focus for enabling agentic applications. Among these, DeepResearch Agents have gained significant attention for their strong performance on complex, open-ended information-seeking tasks. We introduce Fathom-DeepResearch, an agentic system composed of two specialized models. The first is Fathom-Search-4B, a DeepSearch model trained from Qwen3-4B and optimized for evidence-based investigation through live web search and targeted webpage querying. Its training combines three advances: (i) DUETQA, a 5K-sample dataset generated via multi-agent self-play that enforces strict web-search dependence and heterogeneous source grounding; (ii) RAPO, a zero-overhead extension of GRPO that stabilizes multi-turn Reinforcement Learning with Verifiable Rewards through curriculum pruning, reward-aware advantage scaling, and per-prompt replay buffers; and (iii) a steerable step-level reward that classifies each tool call by cognitive behavior and marginal utility, enabling explicit control over search trajectory breadth, depth, and horizon. These improvements enable reliable extension of tool-calling beyond 20 calls when warranted. The second is Fathom-Synthesizer-4B, trained from Qwen3-4B, which converts multi-turn DeepSearch traces into structured, citation-dense DeepResearch Reports for comprehensive synthesis. Evaluated on DeepSearch benchmarks (SimpleQA, FRAMES, WebWalker, Seal0, MuSiQue) and DeepResearch-Bench, the system achieves state-of-the-art performance in the open-weights category while demonstrating strong generalization to diverse reasoning tasks including HLE, AIME-25, GPQA-Diamond, and MedQA. 

**Abstract (ZH)**: åŸºäºå·¥å…·é›†æˆçš„æ¨ç†å·²æˆä¸ºæ¨åŠ¨è‡ªä¸»åº”ç”¨çš„å…³é”®ç„¦ç‚¹ã€‚åœ¨å…¶ä¸­ï¼ŒDeepResearch ä»£ç†å› å…¶åœ¨å¤æ‚å¼€æ”¾æ€§ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸Šçš„å‡ºè‰²è¡¨ç°è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åä¸ºFathom-DeepResearchçš„è‡ªä¸»ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç”±ä¸¤ä¸ªä¸“é—¨æ¨¡å‹ç»„æˆã€‚ç¬¬ä¸€ä¸ªæ˜¯Fathom-Search-4Bï¼Œè¿™æ˜¯ä¸€ç§ä»Qwen3-4Bè®­ç»ƒè€Œæ¥çš„DeepSearchæ¨¡å‹ï¼Œé€šè¿‡å®æ—¶ç½‘ç»œæœç´¢å’Œå®šå‘ç½‘é¡µæŸ¥è¯¢ä¼˜åŒ–ç”¨äºè¯æ®åŸºç¡€çš„è°ƒæŸ¥ã€‚å…¶è®­ç»ƒç»“åˆäº†ä¸‰é¡¹æ”¹è¿›ï¼š(i) DUETQAï¼Œä¸€ä¸ªé€šè¿‡å¤šæ™ºèƒ½ä½“è‡ªæˆ‘å¯¹å¼ˆç”Ÿæˆçš„5åƒæ ·æœ¬æ•°æ®é›†ï¼Œå¼ºåˆ¶æ‰§è¡Œä¸¥æ ¼çš„ç½‘ç»œæœç´¢ä¾èµ–æ€§å’Œå¼‚è´¨æ¥æºæ¥åœ°ï¼›(ii) RAPOï¼Œè¿™æ˜¯ä¸€ç§é›¶å¼€é”€çš„GRPOæ‰©å±•ï¼Œé€šè¿‡è¯¾ç¨‹å‰ªæã€å¥–åŠ±æ„è¯†ä¼˜åŠ¿ç¼©æ”¾å’Œæ¯ä¸ªæç¤ºå›æ”¾ç¼“å†²åŒºå®ç°äº†å¯éªŒè¯å¥–åŠ±çš„å¤šè½®å¼ºåŒ–å­¦ä¹ ç¨³å®šï¼›(iii) å¯è°ƒèŠ‚çš„æ­¥éª¤çº§å¥–åŠ±ï¼Œæ ¹æ®è®¤çŸ¥è¡Œä¸ºå’Œè¾¹é™…æ•ˆç”¨å¯¹æ¯æ¬¡å·¥å…·è°ƒç”¨è¿›è¡Œåˆ†ç±»ï¼Œå…è®¸å¯¹æœç´¢è½¨è¿¹çš„å®½åº¦ã€æ·±åº¦å’Œè§†ç•Œè¿›è¡Œæ˜¾å¼æ§åˆ¶ã€‚è¿™äº›æ”¹è¿›ä½¿Fathom-Search-4Bèƒ½å¤Ÿåœ¨å¿…è¦æ—¶å¯é åœ°æ‰©å±•å·¥å…·è°ƒç”¨è¶…è¿‡20æ¬¡ã€‚ç¬¬äºŒä¸ªæ˜¯Fathom-Synthesizer-4Bï¼Œè¿™æ˜¯ä¸€ç§ä»Qwen3-4Bè®­ç»ƒè€Œæ¥çš„æ¨¡å‹ï¼Œå°†å¤šè½®DeepSearchè¸ªè¿¹è½¬æ¢ä¸ºç»“æ„åŒ–ã€å¼•æ–‡å¯†é›†å‹çš„DeepResearchæŠ¥å‘Šï¼Œç”¨äºç»¼åˆæ€»ç»“ã€‚è¯¥ç³»ç»Ÿåœ¨DeepSearchåŸºå‡†æµ‹è¯•ï¼ˆSimpleQAã€FRAMESã€WebWalkerã€Seal0ã€MuSiQueï¼‰å’ŒDeepResearch-Benchä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå®ç°äº†å¼€æ”¾æƒé‡ç±»åˆ«ä¸­çš„æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶å±•ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ¶µç›–äº†åŒ…æ‹¬HLEã€AIME-25ã€GPQA-Diamondå’ŒMedQAåœ¨å†…çš„å¤šç§æ¨ç†ä»»åŠ¡ã€‚ 

---
# Future-Proofing Programmers: Optimal Knowledge Tracing for AI-Assisted Personalized Education 

**Title (ZH)**: é¢å‘æœªæ¥çš„ç¨‹åºå‘˜ï¼šAIè¾…åŠ©ä¸ªæ€§åŒ–æ•™è‚²çš„æœ€ä½³çŸ¥è¯†è¿½è¸ª 

**Authors**: Yuchen Wang, Pei-Duo Yu, Chee Wei Tan  

**Link**: [PDF](https://arxiv.org/pdf/2509.23996)  

**Abstract**: Learning to learn is becoming a science, driven by the convergence of knowledge tracing, signal processing, and generative AI to model student learning states and optimize education. We propose CoTutor, an AI-driven model that enhances Bayesian Knowledge Tracing with signal processing techniques to improve student progress modeling and deliver adaptive feedback and strategies. Deployed as an AI copilot, CoTutor combines generative AI with adaptive learning technology. In university trials, it has demonstrated measurable improvements in learning outcomes while outperforming conventional educational tools. Our results highlight its potential for AI-driven personalization, scalability, and future opportunities for advancing privacy and ethical considerations in educational technology. Inspired by Richard Hamming's vision of computer-aided 'learning to learn,' CoTutor applies convex optimization and signal processing to automate and scale up learning analytics, while reserving pedagogical judgment for humans, ensuring AI facilitates the process of knowledge tracing while enabling learners to uncover new insights. 

**Abstract (ZH)**: å­¦ä¹ å¦‚ä½•å­¦ä¹ æ­£æˆä¸ºä¸€é—¨ç§‘å­¦ï¼Œç”±çŸ¥è¯†è¿½è¸ªã€ä¿¡å·å¤„ç†å’Œç”Ÿæˆå¼AIçš„ç»“åˆé©±åŠ¨ï¼Œä»¥å»ºæ¨¡å­¦ç”Ÿçš„å­¦ä¹ çŠ¶æ€å¹¶ä¼˜åŒ–æ•™è‚²ã€‚æˆ‘ä»¬æå‡ºCoTutorï¼Œä¸€ç§åŸºäºç”Ÿæˆå¼AIå’Œé€‚é…å­¦ä¹ æŠ€æœ¯å¢å¼ºè´å¶æ–¯çŸ¥è¯†è¿½è¸ªçš„AIé©±åŠ¨æ¨¡å‹ï¼Œä»¥æå‡å­¦ç”Ÿè¿›å±•å»ºæ¨¡å’Œæä¾›é€‚åº”æ€§åé¦ˆå’Œç­–ç•¥ã€‚ä½œä¸ºAIå‰¯é©¾éƒ¨ç½²ï¼ŒCoTutoråœ¨å¤§å­¦è¯•éªŒä¸­è¡¨ç°å‡ºå¯æµ‹é‡çš„å­¦ä¹ æˆæœæå‡ï¼Œå¹¶è¶…è¶Šäº†ä¼ ç»Ÿæ•™è‚²å·¥å…·ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†å…¶åœ¨AIé©±åŠ¨ä¸ªæ€§åŒ–ã€å¯æ‰©å±•æ€§ä»¥åŠæ•™è‚²æŠ€æœ¯ä¸­éšç§å’Œä¼¦ç†è€ƒè™‘æ–¹é¢æœªæ¥æœºé‡çš„æ½œåŠ›ã€‚å—Richard Hammingå…³äºâ€˜å­¦ä¹ å¦‚ä½•å­¦ä¹ â€™çš„è®¡ç®—æœºè¾…åŠ©æ„¿æ™¯å¯å‘ï¼ŒCoTutoråº”ç”¨å‡¸ä¼˜åŒ–å’Œä¿¡å·å¤„ç†æŠ€æœ¯è‡ªåŠ¨åŒ–å’Œè§„æ¨¡åŒ–å­¦ä¹ åˆ†æï¼ŒåŒæ—¶ä¿ç•™æ•™å­¦åˆ¤æ–­æƒäºäººç±»ï¼Œç¡®ä¿AIä¿ƒè¿›çŸ¥è¯†è¿½è¸ªè¿‡ç¨‹ï¼ŒåŒæ—¶å¸®åŠ©å­¦ä¹ è€…å‘ç°æ–°çš„è§è§£ã€‚ 

---
# Automatic selection of primary studies in systematic reviews with evolutionary rule-based classification 

**Title (ZH)**: åŸºäºè¿›åŒ–è§„åˆ™åˆ†ç±»çš„ç³»ç»Ÿè¯„ä»·ä¸­ä¸»è¦ç ”ç©¶çš„è‡ªåŠ¨é€‰æ‹© 

**Authors**: JosÃ© de la Torre-LÃ³pez, Aurora RamÃ­rez, JosÃ© RaÃºl Romero  

**Link**: [PDF](https://arxiv.org/pdf/2509.23981)  

**Abstract**: Searching, filtering and analysing scientific literature are time-consuming tasks when performing a systematic literature review. With the rise of artificial intelligence, some steps in the review process are progressively being automated. In particular, machine learning for automatic paper selection can greatly reduce the effort required to identify relevant literature in scientific databases. We propose an evolutionary machine learning approach, called \ourmodel, to automatically determine whether a paper retrieved from a literature search process is relevant. \ourmodel builds an interpretable rule-based classifier using grammar-guided genetic programming. The use of a grammar to define the syntax and the structure of the rules allows \ourmodel to easily combine the usual textual information with other bibliometric data not considered by state-of-the-art methods. Our experiments demonstrate that it is possible to generate accurate classifiers without impairing interpretability and using configurable information sources not supported so far. 

**Abstract (ZH)**: ç³»ç»Ÿæ–‡çŒ®ç»¼è¿°ä¸­æœç´¢ã€ç­›é€‰å’Œåˆ†æç§‘å­¦æ–‡çŒ®æ˜¯è€—æ—¶çš„ä»»åŠ¡ã€‚éšç€äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œå®¡æŸ¥è¿‡ç¨‹ä¸­çš„æŸäº›æ­¥éª¤æ­£é€æ¸å®ç°è‡ªåŠ¨åŒ–ã€‚ç‰¹åˆ«æ˜¯ï¼Œç”¨äºè‡ªåŠ¨è®ºæ–‡ç­›é€‰çš„æœºå™¨å­¦ä¹ å¯ä»¥å¤§å¤§å‡å°‘åœ¨ç§‘å­¦æ•°æ®åº“ä¸­è¯†åˆ«ç›¸å…³æ–‡çŒ®æ‰€éœ€çš„åŠªåŠ›ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è¿›åŒ–æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç§°ä¸º\ourmodelï¼Œä»¥è‡ªåŠ¨ç¡®å®šä»æ–‡çŒ®æœç´¢è¿‡ç¨‹ä¸­æ£€ç´¢åˆ°çš„è®ºæ–‡æ˜¯å¦ç›¸å…³ã€‚\ourmodel ä½¿ç”¨è¯­æ³•å¼•å¯¼çš„é—ä¼ ç¼–ç¨‹æ„å»ºäº†ä¸€ä¸ªå¯è§£é‡Šçš„åŸºäºè§„åˆ™çš„åˆ†ç±»å™¨ã€‚ä½¿ç”¨è¯­æ³•æ¥å®šä¹‰è§„åˆ™çš„è¯­æ³•å’Œç»“æ„ï¼Œä½¿å¾—\ourmodel å¯ä»¥è½»æ¾åœ°ç»“åˆé€šå¸¸çš„æ–‡æœ¬ä¿¡æ¯å’Œå…¶ä»–ä¸å±äºç°æœ‰æ–¹æ³•è€ƒè™‘çš„å¼•æ–‡è®¡é‡æ•°æ®ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå¯ä»¥åœ¨ä¸æŸå®³å¯è§£é‡Šæ€§çš„æƒ…å†µä¸‹ç”Ÿæˆå‡†ç¡®çš„åˆ†ç±»å™¨ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨è¿„ä»Šä¸ºæ­¢å°šæœªé…ç½®çš„ä¿¡æ¯æ¥æºã€‚ 

---
# From Neural Networks to Logical Theories: The Correspondence between Fibring Modal Logics and Fibring Neural Networks 

**Title (ZH)**: ä»ç¥ç»ç½‘ç»œåˆ°é€»è¾‘ç†è®ºï¼šçº¤ç»´åŒ–æ¨¡æ€é€»è¾‘ä¸çº¤ç»´åŒ–ç¥ç»ç½‘ç»œä¹‹é—´çš„å¯¹åº”å…³ç³» 

**Authors**: Ouns El Harzli, Bernardo Cuenca Grau, Artur d'Avila Garcez, Ian Horrocks, Tarek R. Besold  

**Link**: [PDF](https://arxiv.org/pdf/2509.23912)  

**Abstract**: Fibring of modal logics is a well-established formalism for combining countable families of modal logics into a single fibred language with common semantics, characterized by fibred models. Inspired by this formalism, fibring of neural networks was introduced as a neurosymbolic framework for combining learning and reasoning in neural networks. Fibring of neural networks uses the (pre-)activations of a trained network to evaluate a fibring function computing the weights of another network whose outputs are injected back into the original network. However, the exact correspondence between fibring of neural networks and fibring of modal logics was never formally established. In this paper, we close this gap by formalizing the idea of fibred models \emph{compatible} with fibred neural networks. Using this correspondence, we then derive non-uniform logical expressiveness results for Graph Neural Networks (GNNs), Graph Attention Networks (GATs) and Transformer encoders. Longer-term, the goal of this paper is to open the way for the use of fibring as a formalism for interpreting the logical theories learnt by neural networks with the tools of computational logic. 

**Abstract (ZH)**: æ¨¡æ€é€»è¾‘çš„çº¤ç»´åŒ–æ˜¯ä¸€ç§å°†å¯æ•°ç³»åˆ—æ¨¡æ€é€»è¾‘ç»“åˆæˆå…·æœ‰å…±åŒè¯­ä¹‰çš„çº¤ç»´åŒ–è¯­è¨€çš„å½¢å¼ä¸»ä¹‰ã€‚å—æ­¤å½¢å¼ä¸»ä¹‰çš„å¯å‘ï¼Œç¥ç»ç½‘ç»œçš„çº¤ç»´åŒ–è¢«å¼•å…¥ä½œä¸ºä¸€ç§å°†å­¦ä¹ å’Œæ¨ç†ç»“åˆåˆ°ç¥ç»ç½‘ç»œä¸­çš„ç¥ç»ç¬¦å·æ¡†æ¶ã€‚ç¥ç»ç½‘ç»œçš„çº¤ç»´åŒ–åˆ©ç”¨è®­ç»ƒç½‘ç»œçš„ï¼ˆé¢„ï¼‰æ¿€æ´»æ¥è¯„ä¼°çº¤ç»´åŒ–å‡½æ•°ï¼Œè®¡ç®—å¦ä¸€ä¸ªç½‘ç»œçš„æƒé‡å¹¶å°†è¾“å‡ºæ³¨å…¥åŸå§‹ç½‘ç»œã€‚ç„¶è€Œï¼Œç¥ç»ç½‘ç»œçš„çº¤ç»´åŒ–ä¸æ¨¡æ€é€»è¾‘çš„çº¤ç»´åŒ–ä¹‹é—´çš„ç²¾ç¡®å¯¹åº”å…³ç³»ä»æœªæ­£å¼å»ºç«‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å½¢å¼åŒ–ä¸çº¤ç»´åŒ–ç¥ç»ç½‘ç»œç›¸å…¼å®¹çš„çº¤ç»´åŒ–æ¨¡å‹çš„æ¦‚å¿µæ¥å¡«è¡¥è¿™ä¸€å·®è·ã€‚å€ŸåŠ©è¿™ç§å¯¹åº”å…³ç³»ï¼Œæˆ‘ä»¬éšåæ¨å¯¼å‡ºäº†å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰ã€å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATsï¼‰å’Œå˜æ¢å™¨ç¼–ç å™¨çš„éå‡åŒ€é€»è¾‘è¡¨è¾¾èƒ½åŠ›ç»“æœã€‚é•¿è¿œæ¥çœ‹ï¼Œæœ¬æ–‡çš„ç›®æ ‡æ˜¯ä¸ºä½¿ç”¨çº¤ç»´åŒ–ä½œä¸ºå·¥å…·æ¥è§£é‡Šç¥ç»ç½‘ç»œå­¦ä¹ çš„é€»è¾‘ç†è®ºçš„è®¡ç®—é€»è¾‘å·¥å…·é“ºå¹³é“è·¯ã€‚ 

---
# AgentGuard: Runtime Verification of AI Agents 

**Title (ZH)**: AgentGuardï¼šAIä»£ç†çš„è¿è¡Œæ—¶éªŒè¯ 

**Authors**: Roham Koohestani  

**Link**: [PDF](https://arxiv.org/pdf/2509.23864)  

**Abstract**: The rapid evolution to autonomous, agentic AI systems introduces significant risks due to their inherent unpredictability and emergent behaviors; this also renders traditional verification methods inadequate and necessitates a shift towards probabilistic guarantees where the question is no longer if a system will fail, but the probability of its failure within given constraints. This paper presents AgentGuard, a framework for runtime verification of Agentic AI systems that provides continuous, quantitative assurance through a new paradigm called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection layer that observes an agent's raw I/O and abstracts it into formal events corresponding to transitions in a state model. It then uses online learning to dynamically build and update a Markov Decision Process (MDP) that formally models the agent's emergent behavior. Using probabilistic model checking, the framework then verifies quantitative properties in real-time. 

**Abstract (ZH)**: è‡ªä¸»æ™ºèƒ½ä½“AIç³»ç»Ÿçš„å¿«é€Ÿè¿›åŒ–å¼•å…¥äº†ç”±äºå…¶å›ºæœ‰çš„ä¸å¯é¢„æµ‹æ€§å’Œ emergent è¡Œä¸ºè€Œå¸¦æ¥çš„æ˜¾è‘—é£é™©ï¼›è¿™ä½¿å¾—ä¼ ç»Ÿçš„éªŒè¯æ–¹æ³•å˜å¾—ä¸è¶³ï¼Œéœ€è¦è½¬å‘åŸºäºæ¦‚ç‡ä¿è¯çš„æ–¹æ³•ï¼Œå…¶ä¸­çš„é—®é¢˜ä¸å†æ˜¯ç³»ç»Ÿæ˜¯å¦ä¼šå¤±è´¥ï¼Œè€Œæ˜¯ç³»ç»Ÿåœ¨ç»™å®šçº¦æŸä¸‹çš„å¤±è´¥æ¦‚ç‡ã€‚æœ¬æ–‡æå‡ºäº†AgentGuardæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè¿è¡Œæ—¶éªŒè¯æ™ºèƒ½ä½“AIç³»ç»Ÿçš„æ¡†æ¶ï¼Œé€šè¿‡ä¸€ç§æ–°æå‡ºçš„åŠ¨æ€æ¦‚ç‡ä¿è¯ paradigmn æä¾›è¿ç»­çš„å®šé‡ä¿éšœã€‚AgentGuardä½œä¸ºä¸€ç§æ£€æŸ¥å±‚ï¼Œè§‚å¯Ÿæ™ºèƒ½ä½“çš„åŸå§‹è¾“å…¥/è¾“å‡ºï¼Œå¹¶å°†å…¶æŠ½è±¡ä¸ºä¸çŠ¶æ€æ¨¡å‹è½¬æ¢å¯¹åº”çš„æ­£å¼äº‹ä»¶ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨åœ¨çº¿å­¦ä¹ æ¥åŠ¨æ€æ„å»ºå’Œæ›´æ–°é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œä»¥æ­£å¼å»ºæ¨¡æ™ºèƒ½ä½“çš„ emergent è¡Œä¸ºã€‚åˆ©ç”¨æ¦‚ç‡æ¨¡å‹æ£€æµ‹ï¼Œè¯¥æ¡†æ¶åœ¨å®æ—¶æƒ…å†µä¸‹éªŒè¯å®šé‡å±æ€§ã€‚ 

---
# AnveshanaAI: A Multimodal Platform for Adaptive AI/ML Education through Automated Question Generation and Interactive Assessment 

**Title (ZH)**: AnveshanaAIï¼šä¸€ç§é€šè¿‡è‡ªåŠ¨åŒ–é—®é¢˜ç”Ÿæˆå’Œäº’åŠ¨è¯„ä¼°å®ç°è‡ªé€‚åº”AI/MLæ•™è‚²çš„å¤šæ¨¡æ€å¹³å° 

**Authors**: Rakesh Thakur, Diksha Khandelwal, Shreya Tiwari  

**Link**: [PDF](https://arxiv.org/pdf/2509.23811)  

**Abstract**: We propose AnveshanaAI, an application-based learning platform for artificial intelligence. With AnveshanaAI, learners are presented with a personalized dashboard featuring streaks, levels, badges, and structured navigation across domains such as data science, machine learning, deep learning, transformers, generative AI, large language models, and multimodal AI, with scope to include more in the future. The platform incorporates gamified tracking with points and achievements to enhance engagement and learning, while switching between Playground, Challenges, Simulator, Dashboard, and Community supports exploration and collaboration. Unlike static question repositories used in existing platforms, AnveshanaAI ensures balanced learning progression through a dataset grounded in Bloom's taxonomy, with semantic similarity checks and explainable AI techniques improving transparency and reliability. Adaptive, automated, and domain-aware assessment methods are also employed. Experiments demonstrate broad dataset coverage, stable fine-tuning with reduced perplexity, and measurable gains in learner engagement. Together, these features illustrate how AnveshanaAI integrates adaptivity, gamification, interactivity, and explainability to support next-generation AI education. 

**Abstract (ZH)**: æˆ‘ä»¬æå‡ºAnveshanaAIï¼Œä¸€ä¸ªåŸºäºåº”ç”¨çš„äººå·¥æ™ºèƒ½å­¦ä¹ å¹³å°ã€‚AnveshanaAIä¸ºå­¦ä¹ è€…æä¾›äº†ä¸ªæ€§åŒ–ä»ªè¡¨ç›˜ï¼Œå±•ç¤ºè¿ç»­å­¦ä¹ è®°å½•ã€å±‚çº§ã€å¾½ç« ï¼Œå¹¶è·¨æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€å˜æ¢å™¨ã€ç”Ÿæˆäººå·¥æ™ºèƒ½ã€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä»¥åŠå¤šæ¨¡æ€äººå·¥æ™ºèƒ½é¢†åŸŸæä¾›äº†ç»“æ„åŒ–çš„å¯¼èˆªï¼Œæœªæ¥è¿˜å°†åŒ…æ‹¬æ›´å¤šé¢†åŸŸã€‚è¯¥å¹³å°é›†æˆäº†æ¸¸æˆåŒ–çš„è·Ÿè¸ªæœºåˆ¶ï¼Œå¹¶é€šè¿‡ç‚¹æ•°å’Œæˆå°±æé«˜å‚ä¸åº¦å’Œå­¦ä¹ æ•ˆæœï¼›å­¦ä¹ è€…å¯åœ¨æ¸¸ä¹åœºã€æŒ‘æˆ˜ã€æ¨¡æ‹Ÿå™¨ã€ä»ªè¡¨ç›˜å’Œç¤¾åŒºä¹‹é—´åˆ‡æ¢ï¼Œä¿ƒè¿›æ¢ç´¢ä¸åˆä½œã€‚ä¸ç°æœ‰å¹³å°ä½¿ç”¨çš„é™æ€é—®é¢˜åº“ä¸åŒï¼ŒAnveshanaAIé€šè¿‡åŸºäºBloom taxonomyçš„æ•°æ®é›†ç¡®ä¿å¹³è¡¡çš„å­¦ä¹ è¿›å±•ï¼Œå¹¶é€šè¿‡è¯­ä¹‰ç›¸ä¼¼æ€§æ£€æŸ¥å’Œå¯è§£é‡Šçš„äººå·¥æ™ºèƒ½æŠ€æœ¯æé«˜é€æ˜åº¦å’Œå¯é æ€§ã€‚è¯¥å¹³å°è¿˜é‡‡ç”¨äº†è‡ªé€‚åº”ã€è‡ªåŠ¨åŒ–å’Œé¢†åŸŸæ„ŸçŸ¥çš„è¯„ä¼°æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAnveshanaAIå®ç°äº†å¹¿æ³›çš„æ•°æ®é›†è¦†ç›–ã€ç¨³å®šçš„æ•°æ®é›†å¾®è°ƒå’Œå›°æƒ‘åº¦é™ä½ï¼Œå¹¶åœ¨å­¦ä¹ è€…å‚ä¸åº¦æ–¹é¢å–å¾—å¯æµ‹é‡çš„æå‡ã€‚è¿™äº›åŠŸèƒ½å…±åŒå±•ç¤ºäº†AnveshanaAIå¦‚ä½•é€šè¿‡è‡ªé€‚åº”ã€æ¸¸æˆåŒ–ã€äº’åŠ¨æ€§å’Œå¯è§£é‡Šæ€§æ¥æ”¯æŒä¸‹ä¸€ä»£äººå·¥æ™ºèƒ½æ•™è‚²ã€‚ 

---
# From Frustration to Fun: An Adaptive Problem-Solving Puzzle Game Powered by Genetic Algorithm 

**Title (ZH)**: ä»æŒ«æŠ˜åˆ°ä¹è¶£ï¼šä¸€ç§åŸºäºé—ä¼ ç®—æ³•çš„è‡ªé€‚åº”é—®é¢˜è§£å†³ç›Šæ™ºæ¸¸æˆ 

**Authors**: Matthew McConnell, Richard Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2509.23796)  

**Abstract**: This paper explores adaptive problem solving with a game designed to support the development of problem-solving skills. Using an adaptive, AI-powered puzzle game, our adaptive problem-solving system dynamically generates pathfinding-based puzzles using a genetic algorithm, tailoring the difficulty of each puzzle to individual players in an online real-time approach. A player-modeling system records user interactions and informs the generation of puzzles to approximate a target difficulty level based on various metrics of the player. By combining procedural content generation with online adaptive difficulty adjustment, the system aims to maintain engagement, mitigate frustration, and maintain an optimal level of challenge. A pilot user study investigates the effectiveness of this approach, comparing different types of adaptive difficulty systems and interpreting players' responses. This work lays the foundation for further research into emotionally informed player models, advanced AI techniques for adaptivity, and broader applications beyond gaming in educational settings. 

**Abstract (ZH)**: æœ¬æ–‡æ¢è®¨äº†ä¸€ç§é€šè¿‡è®¾è®¡ç”¨äºæ”¯æŒé—®é¢˜è§£å†³æŠ€èƒ½å‘å±•çš„æ¸¸æˆæ¥è¿›è¡Œè‡ªé€‚åº”é—®é¢˜è§£å†³çš„æ–¹æ³•ã€‚é€šè¿‡ä¸€ä¸ªè‡ªé€‚åº”çš„AIé©±åŠ¨çš„è°œé¢˜æ¸¸æˆï¼Œæˆ‘ä»¬çš„è‡ªé€‚åº”é—®é¢˜è§£å†³ç³»ç»Ÿä½¿ç”¨é—ä¼ ç®—æ³•åŠ¨æ€ç”Ÿæˆè·¯å¾„findingä¸ºåŸºç¡€çš„è°œé¢˜ï¼Œå¹¶é‡‡ç”¨åœ¨çº¿å®æ—¶æ–¹å¼ä¸ªæ€§åŒ–è°ƒæ•´æ¯ä¸ªè°œé¢˜çš„éš¾åº¦ã€‚ç©å®¶å»ºæ¨¡ç³»ç»Ÿè®°å½•ç”¨æˆ·äº¤äº’ï¼Œå¹¶æ ¹æ®ç©å®¶çš„å„ç§æŒ‡æ ‡ä¿¡æ¯æ¥è°ƒæ•´è°œé¢˜çš„éš¾åº¦ä»¥é€¼è¿‘ç›®æ ‡éš¾åº¦æ°´å¹³ã€‚é€šè¿‡ç»“åˆè¿‡ç¨‹åŒ–å†…å®¹ç”Ÿæˆä¸åœ¨çº¿è‡ªé€‚åº”éš¾åº¦è°ƒæ•´ï¼Œè¯¥ç³»ç»Ÿæ—¨åœ¨ä¿æŒå‚ä¸åº¦ã€å‡è½»æŒ«è´¥æ„Ÿï¼Œå¹¶ç»´æŒé€‚å½“çš„æŒ‘æˆ˜æ°´å¹³ã€‚ä¸€é¡¹è¯•ç‚¹ç”¨æˆ·ç ”ç©¶æ¢è®¨äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ¯”è¾ƒäº†ä¸åŒç±»å‹è‡ªé€‚åº”éš¾åº¦ç³»ç»Ÿï¼Œå¹¶åˆ†æäº†ç©å®¶çš„ååº”ã€‚æœ¬æ–‡ä¸ºæƒ…æ„ŸåŒ–ç©å®¶æ¨¡å‹ã€é«˜çº§è‡ªé€‚åº”AIæŠ€æœ¯ä»¥åŠæ•™è‚²ç­‰æ›´å¹¿æ³›é¢†åŸŸä¸­çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚ 

---
# GUI-Shepherd: Reliable Process Reward and Verification for Long-Sequence GUI Tasks 

**Title (ZH)**: GUI-ç‰§ç¾Šäºº: å¯é çš„é•¿åºåˆ—GUIä»»åŠ¡è¿‡ç¨‹å¥–åŠ±ä¸éªŒè¯ 

**Authors**: Cong Chen, Kaixiang Ji, Hao Zhong, Muzhi Zhu, Anzhou Li, Guo Gan, Ziyuan Huang, Cheng Zou, Jiajia Liu, Jingdong Chen, Hao Chen, Chunhua Shen  

**Link**: [PDF](https://arxiv.org/pdf/2509.23738)  

**Abstract**: Autonomous agents for long-sequence Graphical User Interface tasks are hindered by sparse rewards and the intractable credit assignment problem. To address these challenges, we introduce GUI-Shepherd, a Process Reward Model that provides dense, step-by-step feedback to guide agents. GUI-Shepherd is trained on a diverse large-scale data set of $52$k interactions that features human-annotated scores and GPT-4o generated rationales, enabling it to serve both as a reward provider for RL training and as a verifier for inference. As far as we know, we are the first to conduct a systematic study of process supervision in GUI agents, across diverse settings from online long-horizon tasks to offline single-step prediction. On the online AndroidWorld benchmark, GUI-Shepherd improves success rate by $7.7$ points via multi-turn online PPO, significantly outperforming Outcome Reward Model based competitors. When used as an inference verifier, it brings $5.1$ points improvements. The benefits generalize to the offline AndroidControl benchmark, with gains of $2.2$ points as a reward provider and $4.3$ points as a verifier. Collectively, our results establish that high-fidelity process supervision is critical for building more capable GUI agents and present a generalizable solution. 

**Abstract (ZH)**: è‡ªä¸»ä»£ç†åœ¨é•¿æ—¶é—´åºåˆ—å›¾å½¢ç”¨æˆ·ç•Œé¢ä»»åŠ¡ä¸­å—åˆ°ç¨€ç–å¥–åŠ±å’Œå½’å› éš¾é¢˜çš„é˜»ç¢ã€‚ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†GUI-Shepherdï¼Œä¸€ç§è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼Œèƒ½å¤Ÿæä¾›è¯¦ç»†é€æ­¥åé¦ˆä»¥æŒ‡å¯¼ä»£ç†ã€‚GUI-ShepherdåŸºäºåŒ…å«äººç±»æ ‡æ³¨è¯„åˆ†å’ŒGPT-4oç”Ÿæˆçš„è§£é‡Šçš„å¤§è§„æ¨¡å¤šæ ·æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶æ—¢èƒ½ä½œä¸ºå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„å¥–åŠ±æä¾›è€…ï¼Œåˆèƒ½ä½œä¸ºæ¨ç†çš„éªŒè¯å™¨ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡ç³»ç»Ÿç ”ç©¶GUIä»£ç†çš„è¿‡ç¨‹ç›‘ç£ï¼Œä»åœ¨çº¿é•¿æ—¶é—´ä»»åŠ¡åˆ°ç¦»çº¿å•æ­¥é¢„æµ‹ã€‚åœ¨åœ¨çº¿AndroidWorldåŸºå‡†æµ‹è¯•ä¸­ï¼Œé€šè¿‡å¤šè½®åœ¨çº¿PPOï¼ŒGUI-Shepherdå°†æˆåŠŸç‡æé«˜äº†7.7ä¸ªç™¾åˆ†ç‚¹ï¼Œæ˜¾è‘—ä¼˜äºåŸºäºç»“æœå¥–åŠ±æ¨¡å‹çš„ç«äº‰è€…ã€‚ä½œä¸ºæ¨ç†éªŒè¯å™¨æ—¶ï¼Œå®ƒå¸¦æ¥äº†5.1ä¸ªç™¾åˆ†ç‚¹çš„æé«˜ã€‚è¿™äº›å¥½å¤„åœ¨ç¦»çº¿AndroidControlåŸºå‡†æµ‹è¯•ä¸­ä¹Ÿå¾—åˆ°éªŒè¯ï¼Œä½œä¸ºå¥–åŠ±æä¾›è€…æ—¶æé«˜äº†2.2ä¸ªç™¾åˆ†ç‚¹ï¼Œä½œä¸ºéªŒè¯å™¨æ—¶æé«˜äº†4.3ä¸ªç™¾åˆ†ç‚¹ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé«˜ä¿çœŸè¿‡ç¨‹ç›‘ç£å¯¹äºæ„å»ºæ›´å¼ºå¤§çš„GUIä»£ç†è‡³å…³é‡è¦ï¼Œå¹¶æå‡ºäº†ä¸€ç§å¯æ³›åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚ 

---
# Diagnosing Failure Root Causes in Platform-Orchestrated Agentic Systems: Dataset, Taxonomy, and Benchmark 

**Title (ZH)**: å¹³å° orchestration æ‰§è¡Œä½“ç³»ç»Ÿä¸­å¤±è´¥æ ¹æœ¬åŸå› è¯Šæ–­ï¼šæ•°æ®é›†ã€åˆ†ç±»å­¦å’ŒåŸºå‡† 

**Authors**: Xuyan Ma, Xiaofei Xie, Yawen Wang, Junjie Wang, Boyu Wu, Mingyang Li, Qing Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23735)  

**Abstract**: Agentic systems consisting of multiple LLM-driven agents coordinating through tools and structured interactions, are increasingly deployed for complex reasoning and problem-solving tasks. At the same time, emerging low-code and template-based agent development platforms (e.g., Dify) enable users to rapidly build and orchestrate agentic systems, which we refer to as platform-orchestrated agentic systems. However, these systems are also fragile and it remains unclear how to systematically identify their potential failure root cause. This paper presents a study of root cause identification of these platform-orchestrated agentic systems. To support this initiative, we construct a dataset AgentFail containing 307 failure logs from ten agentic systems, each with fine-grained annotations linking failures to their root causes. We additionally utilize counterfactual reasoning-based repair strategy to ensure the reliability of the annotation. Building on the dataset, we develop a taxonomy that characterizes failure root causes and analyze their distribution across different platforms and task domains. Furthermore, we introduce a benchmark that leverages LLMs for automatically identifying root causes, in which we also utilize the proposed taxonomy as guidance for LLMs. Results show that the taxonomy can largely improve the performance, thereby confirming its utility. Nevertheless, the accuracy of root cause identification reaches at most 33.6%, which indicates that this task still remains challenging. In light of these results, we also provide actionable guidelines for building such agentic systems. In summary, this paper provides a reliable dataset of failure root cause for platform-orchestrated agentic systems, corresponding taxonomy and benchmark, which serves as a foundation for advancing the development of more reliable agentic systems. 

**Abstract (ZH)**: å¹³å° orchestration çš„ä»£ç†ç³»ç»Ÿæ ¹å› è¯†åˆ«ç ”ç©¶ 

---
# MedLA: A Logic-Driven Multi-Agent Framework for Complex Medical Reasoning with Large Language Models 

**Title (ZH)**: MedLAï¼šä¸€ç§é€»è¾‘é©±åŠ¨çš„å¤šagentæ¡†æ¶ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚åŒ»ç–—æ¨ç†ä¸­çš„åº”ç”¨ 

**Authors**: Siqi Ma, Jiajie Huang, Bolin Yang, Fan Zhang, Jinlin Wu, Yue Shen, Guohui Fan, Zhu Zhang, Zelin Zang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23725)  

**Abstract**: Answering complex medical questions requires not only domain expertise and patient-specific information, but also structured and multi-perspective reasoning. Existing multi-agent approaches often rely on fixed roles or shallow interaction prompts, limiting their ability to detect and resolve fine-grained logical inconsistencies. To address this, we propose \textsc{MedLA}, a logic-driven multi-agent framework built on large language models. Each agent organizes its reasoning process into an explicit logical tree based on syllogistic triads (major premise, minor premise, and conclusion), enabling transparent inference and premise-level alignment. Agents engage in a multi-round, graph-guided discussion to compare and iteratively refine their logic trees, achieving consensus through error correction and contradiction resolution. We demonstrate that \textsc{MedLA} consistently outperforms both static role-based systems and single-agent baselines on challenging benchmarks such as MedDDx and standard medical QA tasks. Furthermore, \textsc{MedLA} scales effectively across both open-source and commercial LLM backbones, achieving state-of-the-art performance and offering a generalizable paradigm for trustworthy medical reasoning. 

**Abstract (ZH)**: é€»è¾‘é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶\textsc{MedLA}ï¼šåº”å¯¹å¤æ‚åŒ»ç–—é—®é¢˜éœ€è¦ä¸“ä¸šçŸ¥è¯†ã€æ‚£è€…ç‰¹å®šä¿¡æ¯ä»¥åŠç»“æ„åŒ–çš„å¤šè§†è§’æ¨ç† 

---
# Measuring Sparse Autoencoder Feature Sensitivity 

**Title (ZH)**: æµ‹é‡ç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾æ•æ„Ÿæ€§ 

**Authors**: Claire Tian, Katherine Tian, Nathan Hu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23717)  

**Abstract**: Sparse Autoencoder (SAE) features have become essential tools for mechanistic interpretability research. SAE features are typically characterized by examining their activating examples, which are often "monosemantic" and align with human interpretable concepts. However, these examples don't reveal feature sensitivity: how reliably a feature activates on texts similar to its activating examples. In this work, we develop a scalable method to evaluate feature sensitivity. Our approach avoids the need to generate natural language descriptions for features; instead we use language models to generate text with the same semantic properties as a feature's activating examples. We then test whether the feature activates on these generated texts. We demonstrate that sensitivity measures a new facet of feature quality and find that many interpretable features have poor sensitivity. Human evaluation confirms that when features fail to activate on our generated text, that text genuinely resembles the original activating examples. Lastly, we study feature sensitivity at the SAE level and observe that average feature sensitivity declines with increasing SAE width across 7 SAE variants. Our work establishes feature sensitivity as a new dimension for evaluating both individual features and SAE architectures. 

**Abstract (ZH)**: ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰ç‰¹å¾å·²æˆä¸ºæœºåˆ¶è§£é‡Šæ€§ç ”ç©¶ä¸­ä¸å¯æˆ–ç¼ºçš„å·¥å…·ã€‚æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•æ¥è¯„ä¼°ç‰¹å¾æ•æ„Ÿæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¿å…ä¸ºç‰¹å¾ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°ï¼Œè€Œæ˜¯ä½¿ç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ç‰¹å¾æ¿€æ´»ç¤ºä¾‹å…·æœ‰ç›¸åŒè¯­ä¹‰å±æ€§çš„æ–‡æœ¬ï¼Œç„¶åæµ‹è¯•ç‰¹å¾æ˜¯å¦èƒ½å¤Ÿåœ¨è¿™äº›ç”Ÿæˆçš„æ–‡æœ¬ä¸Šæ¿€æ´»ã€‚æˆ‘ä»¬å±•ç¤ºæ•æ„Ÿæ€§è¡¡é‡äº†ç‰¹å¾è´¨é‡çš„ä¸€ä¸ªæ–°çš„æ–¹é¢ï¼Œå¹¶å‘ç°è®¸å¤šå¯è§£é‡Šçš„ç‰¹å¾åœ¨æ•æ„Ÿæ€§æ–¹é¢è¡¨ç°è¾ƒå·®ã€‚äººç±»è¯„ä¼°æ˜¾ç¤ºï¼Œå½“ç‰¹å¾æœªèƒ½åœ¨ç”Ÿæˆçš„æ–‡æœ¬ä¸Šæ¿€æ´»æ—¶ï¼Œè¿™äº›æ–‡æœ¬ç¡®å®ç±»ä¼¼äºåŸå§‹çš„æ¿€æ´»ç¤ºä¾‹ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰å±‚æ¬¡ä¸Šç ”ç©¶äº†ç‰¹å¾æ•æ„Ÿæ€§ï¼Œå‘ç°åœ¨7ç§ä¸åŒå®½åº¦çš„SAEå˜ä½“ä¸­ï¼Œå¹³å‡ç‰¹å¾æ•æ„Ÿæ€§éšç€SAEå®½åº¦å¢åŠ è€Œä¸‹é™ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç¡®ç«‹äº†ç‰¹å¾æ•æ„Ÿæ€§ä½œä¸ºè¯„ä¼°å•ä¸ªç‰¹å¾å’ŒSAEæ¶æ„çš„æ–°ç»´åº¦ã€‚ 

---
# From Reasoning to Answer: Empirical, Attention-Based and Mechanistic Insights into Distilled DeepSeek R1 Models 

**Title (ZH)**: ä»æ¨ç†åˆ°ç­”æ¡ˆï¼šå…³äºDistilled DeepSeek R1æ¨¡å‹çš„ç»éªŒã€æ³¨æ„åŠ›æœºåˆ¶å’Œæœºç†æ´å¯Ÿ 

**Authors**: Jue Zhang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23676)  

**Abstract**: Large Reasoning Models (LRMs) generate explicit reasoning traces alongside final answers, yet the extent to which these traces influence answer generation remains unclear. In this work, we conduct a three-stage investigation into the interplay between reasoning and answer generation in three distilled DeepSeek R1 models. First, through empirical evaluation, we demonstrate that including explicit reasoning consistently improves answer quality across diverse domains. Second, attention analysis reveals that answer tokens attend substantially to reasoning tokens, with certain mid-layer Reasoning-Focus Heads (RFHs) closely tracking the reasoning trajectory, including self-reflective cues. Third, we apply mechanistic interventions using activation patching to assess the dependence of answer tokens on reasoning activations. Our results show that perturbations to key reasoning tokens can reliably alter the final answers, confirming a directional and functional flow of information from reasoning to answer. These findings deepen our understanding of how LRMs leverage reasoning tokens for answer generation, highlighting the functional role of intermediate reasoning in shaping model outputs. Our data and code are publicly available at \href{this https URL}{this URL}. 

**Abstract (ZH)**: å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ç”Ÿæˆæ˜¾å¼çš„æ¨ç†ç—•è¿¹ä»¥åŠæœ€ç»ˆç­”æ¡ˆï¼Œä½†è¿™äº›ç—•è¿¹å¯¹ç­”æ¡ˆç”Ÿæˆçš„å½±å“ç¨‹åº¦å°šä¸æ˜ç¡®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹ä¸‰ä¸ªç»è¿‡æç‚¼çš„DeepSeek R1æ¨¡å‹ä¸­çš„æ¨ç†ä¸ç­”æ¡ˆç”Ÿæˆçš„äº¤äº’ä½œç”¨è¿›è¡Œäº†ä¸‰é˜¶æ®µçš„ç ”ç©¶ã€‚é¦–å…ˆï¼Œé€šè¿‡å®è¯è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†åŒ…å«æ˜¾å¼æ¨ç†å¯ä»¥ä¸€è‡´åœ°æé«˜è·¨ä¸åŒé¢†åŸŸç­”æ¡ˆçš„è´¨é‡ã€‚å…¶æ¬¡ï¼Œæ³¨æ„åŠ›åˆ†ææ˜¾ç¤ºç­”æ¡ˆæ ‡è®°ä¼šæ˜¾è‘—åœ°å…³æ³¨æ¨ç†æ ‡è®°ï¼ŒæŸäº›ä¸­é—´å±‚çš„æ¨ç†èšç„¦å¤´ï¼ˆRFHsï¼‰ç´§å¯†è·Ÿè¸ªæ¨ç†è½¨è¿¹ï¼ŒåŒ…æ‹¬è‡ªæˆ‘åæ€çº¿ç´¢ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬é€šè¿‡æ¿€æ´»ä¿®è¡¥çš„æ–¹æ³•åº”ç”¨æœºç†å¹²é¢„ï¼Œè¯„ä¼°ç­”æ¡ˆæ ‡è®°å¯¹æ¨ç†æ¿€æ´»çš„ä¾èµ–æ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¯¹å…³é”®æ¨ç†æ ‡è®°çš„æ‰°åŠ¨å¯ä»¥å¯é åœ°æ”¹å˜æœ€ç»ˆç­”æ¡ˆï¼Œè¯å®äº†ä»æ¨ç†åˆ°ç­”æ¡ˆçš„ä¿¡æ¯ä¼ é€’æ˜¯å…·æœ‰æ–¹å‘æ€§å’ŒåŠŸèƒ½æ€§çš„ã€‚è¿™äº›å‘ç°åŠ æ·±äº†æˆ‘ä»¬å¯¹LRMså¦‚ä½•åˆ©ç”¨æ¨ç†æ ‡è®°è¿›è¡Œç­”æ¡ˆç”Ÿæˆçš„ç†è§£ï¼Œçªå‡ºäº†ä¸­é—´æ¨ç†çš„åŠŸèƒ½æ€§ä½œç”¨ä»¥å¡‘é€ æ¨¡å‹è¾“å‡ºã€‚æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç åœ¨\href{this https URL}{this URL}å…¬å¼€å¯ç”¨ã€‚ 

---
# A Hierarchical Structure-Enhanced Personalized Recommendation Model for Traditional Chinese Medicine Formulas Based on KG Diffusion Guidance 

**Title (ZH)**: åŸºäºKGæ‰©æ•£æŒ‡å¯¼çš„å±‚æ¬¡ç»“æ„å¢å¼ºä¸­åŒ»è¯æ–¹ä¸ªæ€§åŒ–æ¨èæ¨¡å‹ 

**Authors**: ChaoBo Zhang, Long Tan  

**Link**: [PDF](https://arxiv.org/pdf/2509.23560)  

**Abstract**: Artificial intelligence technology plays a crucial role in recommending prescriptions for traditional Chinese medicine (TCM). Previous studies have made significant progress by focusing on the symptom-herb relationship in prescriptions. However, several limitations hinder model performance: (i) Insufficient attention to patient-personalized information such as age, BMI, and medical history, which hampers accurate identification of syndrome and reduces efficacy. (ii) The typical long-tailed distribution of herb data introduces training biases and affects generalization ability. (iii) The oversight of the 'monarch, minister, assistant and envoy' compatibility among herbs increases the risk of toxicity or side effects, opposing the 'treatment based on syndrome differentiation' principle in clinical TCM. Therefore, we propose a novel hierarchical structure-enhanced personalized recommendation model for TCM formulas based on knowledge graph diffusion guidance, namely TCM-HEDPR. Specifically, we pre-train symptom representations using patient-personalized prompt sequences and apply prompt-oriented contrastive learning for data augmentation. Furthermore, we employ a KG-guided homogeneous graph diffusion method integrated with a self-attention mechanism to globally capture the non-linear symptom-herb relationship. Lastly, we design a heterogeneous graph hierarchical network to integrate herbal dispensing relationships with implicit syndromes, guiding the prescription generation process at a fine-grained level and mitigating the long-tailed herb data distribution problem. Extensive experiments on two public datasets and one clinical dataset demonstrate the effectiveness of TCM-HEDPR. In addition, we incorporate insights from modern medicine and network pharmacology to evaluate the recommended prescriptions comprehensively. It can provide a new paradigm for the recommendation of modern TCM. 

**Abstract (ZH)**: äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨æ¨èä¸­åŒ»è¯æ–¹ä¸­çš„ä½œç”¨è‡³å…³é‡è¦ã€‚å°½ç®¡ä»¥å¾€ç ”ç©¶é›†ä¸­åœ¨å¤„æ–¹ä¸­çš„ç—‡çŠ¶-è¯å…³ç³»ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†æ¨¡å‹æ€§èƒ½ä»å—åˆ°å¤šé‡é™åˆ¶ï¼šï¼ˆiï¼‰ç¼ºä¹å¯¹å¹´é¾„ã€BMIå’Œç—…å²ç­‰æ‚£è€…ä¸ªæ€§åŒ–ä¿¡æ¯çš„å…³æ³¨ï¼Œå½±å“äº†ç—…æœºè¯†åˆ«çš„å‡†ç¡®æ€§å¹¶é™ä½äº†ç–—æ•ˆã€‚ï¼ˆiiï¼‰è‰è¯æ•°æ®çš„å…¸å‹é•¿å°¾åˆ†å¸ƒå¼•å…¥äº†è®­ç»ƒåå·®ï¼Œå½±å“äº†æ³›åŒ–èƒ½åŠ›ã€‚ï¼ˆiiiï¼‰å¿½è§†äº†è‰è¯é—´çš„â€˜å›ã€è‡£ã€ä½ã€ä½¿â€™é…ä¼å…³ç³»ï¼Œå¢åŠ äº†æ¯’å‰¯ä½œç”¨çš„é£é™©ï¼Œè¿èƒŒäº†ä¸´åºŠä¸­åŒ»è¯â€˜è¾¨è¯æ–½æ²»â€™çš„åŸåˆ™ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±æ‰©æ•£æŒ‡å¯¼çš„æ–°å‹å±‚æ¬¡ç»“æ„å¢å¼ºä¸ªæ€§åŒ–æ¨èæ¨¡å‹ï¼Œå³TCM-HEDPRã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ä½¿ç”¨æ‚£è€…ä¸ªæ€§åŒ–æç¤ºåºåˆ—æå‰è®­ç»ƒç—‡çŠ¶è¡¨ç¤ºï¼Œå¹¶åº”ç”¨æç¤ºå¯¼å‘çš„å¯¹æ¯”å­¦ä¹ è¿›è¡Œæ•°æ®å¢å¼ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨çŸ¥è¯†å›¾è°±å¼•å¯¼çš„åŒè´¨å›¾æ‰©æ•£æ–¹æ³•ç»“åˆè‡ªæˆ‘æ³¨æ„æœºåˆ¶ï¼Œå…¨å±€æ•æ‰éçº¿æ€§çš„ç—‡çŠ¶-è¯å…³ç³»ã€‚æœ€åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å¼‚è´¨å›¾å±‚æ¬¡ç½‘ç»œï¼Œå°†ä¸­è¯é…ä¼å…³ç³»ä¸éšå«ç—…æœºç›¸ç»“åˆï¼Œç²¾ç»†æŒ‡å¯¼å¤„æ–¹ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶ç¼“è§£é•¿å°¾è‰è¯æ•°æ®åˆ†å¸ƒé—®é¢˜ã€‚åœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†å’Œä¸€ä¸ªä¸´åºŠæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜äº†TCM-HEDPRçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆç°ä»£åŒ»å­¦å’Œç½‘ç»œè¯ç†å­¦çš„è§è§£ï¼Œå…¨é¢è¯„ä¼°æ¨èå¤„æ–¹çš„æœ‰æ•ˆæ€§ï¼Œä¸ºç°ä»£ä¸­åŒ»è¯æ¨èæä¾›äº†ä¸€ä¸ªæ–°çš„èŒƒå¼ã€‚ 

---
# DOoM: Difficult Olympiads of Math 

**Title (ZH)**: DOoM: å›°éš¾çš„æ•°å­¦å¥¥æ—åŒ¹å…‹é—®é¢˜é›† 

**Authors**: Ilya Kuleshov, Ilin Pavel, Nikolay Kompanets, Ksenia Sycheva, Aleksandr Nikolich  

**Link**: [PDF](https://arxiv.org/pdf/2509.23529)  

**Abstract**: This paper introduces DOoM, a new open-source benchmark designed to assess the capabilities of language models in solving mathematics and physics problems in Russian. The benchmark includes problems of varying difficulty, ranging from school-level tasks to university Olympiad and entrance exam questions. In this paper we discuss the motivation behind its creation, describe dataset's structure and evaluation methodology, and present initial results from testing various models. Analysis of the results shows a correlation between model performance and the number of tokens used, and highlights differences in performance between mathematics and physics tasks. 

**Abstract (ZH)**: è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†DOoMï¼Œä¸€ä¸ªæ–°æ¨å‡ºçš„å¼€æºåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹è§£å†³ä¿„è¯­æ•°å­¦å’Œç‰©ç†é—®é¢˜çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…å«ä¸åŒéš¾åº¦çš„é—®é¢˜ï¼Œä»å­¦æ ¡çº§ä»»åŠ¡åˆ°å¤§å­¦çº§å¥¥æ—åŒ¹å…‹ç«èµ›å’Œå…¥å­¦è€ƒè¯•é¢˜ç›®ã€‚æœ¬æ–‡è®¨è®ºäº†å…¶åˆ›å»ºåŠ¨æœºï¼Œæè¿°äº†æ•°æ®é›†ç»“æ„å’Œè¯„ä¼°æ–¹æ³•ï¼Œå¹¶ä»‹ç»äº†æµ‹è¯•å„ç§æ¨¡å‹çš„åˆå§‹ç»“æœã€‚åˆ†æç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹æ€§èƒ½ä¸æ‰€ç”¨ä»¤ç‰Œæ•°ä¹‹é—´å­˜åœ¨å…³è”ï¼Œå¹¶æŒ‡å‡ºäº†æ•°å­¦ä»»åŠ¡å’Œç‰©ç†ä»»åŠ¡åœ¨æ€§èƒ½ä¸Šçš„å·®å¼‚ã€‚ 

---
# Dynamic Trust Calibration Using Contextual Bandits 

**Title (ZH)**: åŸºäºä¸Šä¸‹æ–‡è‡‚èµ›çš„åŠ¨æ€ä¿¡ä»»æ ¡å‡† 

**Authors**: Bruno M. Henrique, Eugene Santos Jr  

**Link**: [PDF](https://arxiv.org/pdf/2509.23497)  

**Abstract**: Trust calibration between humans and Artificial Intelligence (AI) is crucial for optimal decision-making in collaborative settings. Excessive trust can lead users to accept AI-generated outputs without question, overlooking critical flaws, while insufficient trust may result in disregarding valuable insights from AI systems, hindering performance. Despite its importance, there is currently no definitive and objective method for measuring trust calibration between humans and AI. Current approaches lack standardization and consistent metrics that can be broadly applied across various contexts, and they don't distinguish between the formation of opinions and subsequent human decisions. In this work, we propose a novel and objective method for dynamic trust calibration, introducing a standardized trust calibration measure and an indicator. By utilizing Contextual Bandits-an adaptive algorithm that incorporates context into decision-making-our indicator dynamically assesses when to trust AI contributions based on learned contextual information. We evaluate this indicator across three diverse datasets, demonstrating that effective trust calibration results in significant improvements in decision-making performance, as evidenced by 10 to 38% increase in reward metrics. These findings not only enhance theoretical understanding but also provide practical guidance for developing more trustworthy AI systems supporting decisions in critical domains, for example, disease diagnoses and criminal justice. 

**Abstract (ZH)**: äººç±»ä¸äººå·¥æ™ºèƒ½çš„ä¿¡ä»»æ ¡å‡†å¯¹äºåä½œç¯å¢ƒä¸­çš„æœ€ä¼˜å†³ç­–è‡³å…³é‡è¦ã€‚è¿‡åº¦ä¿¡ä»»å¯èƒ½å¯¼è‡´ç”¨æˆ·æ— æ¡ä»¶æ¥å—AIç”Ÿæˆçš„ç»“æœï¼Œå¿½è§†å…³é”®ç¼ºé™·ï¼›è€Œä¸è¶³çš„ä¿¡ä»»åˆ™å¯èƒ½å¯¼è‡´å¿½è§†AIç³»ç»Ÿçš„æœ‰ä»·å€¼è§è§£ï¼Œé˜»ç¢æ€§èƒ½æå‡ã€‚å°½ç®¡å…¶é‡è¦æ€§æ—¥ç›Šå‡¸æ˜¾ï¼Œç›®å‰ä»ç¼ºä¹ä¸€ç§æ—¢å®šä¸”å®¢è§‚çš„æ–¹æ³•æ¥è¡¡é‡äººç±»ä¸AIä¹‹é—´çš„ä¿¡ä»»æ ¡å‡†ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æ ‡å‡†åŒ–ä¸”å¯å¹¿æ³›åº”ç”¨äºä¸åŒåœºæ™¯çš„ä¸€è‡´é‡åŒ–æŒ‡æ ‡ï¼Œå¹¶ä¸”æœªèƒ½åŒºåˆ†æ„è§å½¢æˆä¸åç»­çš„äººç±»å†³ç­–ã€‚åœ¨æ­¤é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”å®¢è§‚çš„åŠ¨æ€ä¿¡ä»»æ ¡å‡†æ–¹æ³•ï¼Œå¼•å…¥äº†æ ‡å‡†åŒ–çš„ä¿¡ä»»æ ¡å‡†æµ‹é‡æŒ‡æ ‡å’ŒæŒ‡ç¤ºå™¨ã€‚é€šè¿‡åˆ©ç”¨ä¸Šä¸‹æ–‡è‡‚æ‹‰å§†è¾¾ï¼ˆContextual Banditsï¼‰â€”â€”ä¸€ç§å°†æƒ…å¢ƒä¿¡æ¯çº³å…¥å†³ç­–è¿‡ç¨‹çš„é€‚åº”æ€§ç®—æ³•ï¼Œæˆ‘ä»¬çš„æŒ‡ç¤ºå™¨èƒ½å¤ŸåŸºäºå­¦ä¹ åˆ°çš„æƒ…å¢ƒä¿¡æ¯åŠ¨æ€è¯„ä¼°ä½•æ—¶åº”ä¿¡ä»»AIçš„è´¡çŒ®ã€‚æˆ‘ä»¬è·¨ä¸‰ä¸ªä¸åŒæ•°æ®é›†è¯„ä¼°äº†è¿™ä¸€æŒ‡æ ‡ï¼Œç»“æœè¡¨æ˜æœ‰æ•ˆçš„ä¿¡ä»»æ ¡å‡†èƒ½å¤Ÿæ˜¾è‘—æå‡å†³ç­–æ€§èƒ½ï¼Œè¡¨ç°ä¸ºå¥–åŠ±æŒ‡æ ‡æé«˜äº†10%è‡³38%ã€‚è¿™äº›å‘ç°ä¸ä»…æ·±åŒ–äº†ç†è®ºç†è§£ï¼Œè¿˜ä¸ºåœ¨å…³é”®é¢†åŸŸï¼ˆå¦‚ç–¾ç—…è¯Šæ–­å’Œåˆ‘äº‹å¸æ³•ï¼‰å¼€å‘æ›´å¯é çš„AIå†³ç­–æ”¯æŒç³»ç»Ÿæä¾›äº†å®ç”¨æŒ‡å¯¼ã€‚ 

---
# Accurate Predictions in Education with Discrete Variational Inference 

**Title (ZH)**: åŸºäºç¦»æ•£å˜åˆ†æ¨æ–­çš„æ•™è‚²ä¸­å‡†ç¡®é¢„æµ‹ 

**Authors**: Tom Quilter, Anastasia Ilick, Anastasia Ilick, Richard Turner  

**Link**: [PDF](https://arxiv.org/pdf/2509.23484)  

**Abstract**: One of the largest drivers of social inequality is unequal access to personal tutoring, with wealthier individuals able to afford it, while the majority cannot. Affordable, effective AI tutors offer a scalable solution. We focus on adaptive learning, predicting whether a student will answer a question correctly, a key component of any effective tutoring system. Yet many platforms struggle to achieve high prediction accuracy, especially in data-sparse settings. To address this, we release the largest open dataset of professionally marked formal mathematics exam responses to date. We introduce a probabilistic modelling framework rooted in Item Response Theory (IRT) that achieves over 80 percent accuracy, setting a new benchmark for mathematics prediction accuracy of formal exam papers. Extending this, our collaborative filtering models incorporate topic-level skill profiles, but reveal a surprising and educationally significant finding, a single latent ability parameter alone is needed to achieve the maximum predictive accuracy. Our main contribution though is deriving and implementing a novel discrete variational inference framework, achieving our highest prediction accuracy in low-data settings and outperforming all classical IRT and matrix factorisation baselines. 

**Abstract (ZH)**: ä¸€ç§å¹¿æ³›çš„ç¤¾ä¼šä¸å¹³ç­‰é©±åŠ¨å› ç´ æ˜¯ä¸ªäººè¾…å¯¼çš„ä¸å¹³ç­‰è·å–ï¼Œwealthierä¸ªä½“èƒ½å¤Ÿè´Ÿæ‹…å¾—èµ·è¾…å¯¼ï¼Œè€Œå¤§å¤šæ•°äººåˆ™ä¸èƒ½ã€‚è´Ÿæ‹…å¾—èµ·ä¸”æœ‰æ•ˆçš„AIè¾…å¯¼æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬å…³æ³¨è‡ªé€‚åº”å­¦ä¹ ï¼Œé¢„æµ‹å­¦ç”Ÿæ˜¯å¦èƒ½æ­£ç¡®å›ç­”é—®é¢˜ï¼Œè¿™æ˜¯ä»»ä½•æœ‰æ•ˆè¾…å¯¼ç³»ç»Ÿçš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚ç„¶è€Œï¼Œè®¸å¤šå¹³å°åœ¨ä½æ•°æ®æƒ…å†µä¸‹éš¾ä»¥å®ç°é«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å‘å¸ƒäº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„ä¸“ä¸šæ ‡è®°å½¢å¼æ•°å­¦è€ƒè¯•ç­”æ¡ˆå¼€æ”¾æ•°æ®é›†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé¡¹ç›®ååº”ç†è®ºï¼ˆIRTï¼‰çš„æ¦‚ç‡å»ºæ¨¡æ¡†æ¶ï¼Œå®ç°äº†è¶…è¿‡80%çš„å‡†ç¡®æ€§ï¼Œä¸ºå½¢å¼è€ƒè¯•è®ºæ–‡çš„æ•°å­¦é¢„æµ‹å‡†ç¡®æ€§è®¾ç«‹äº†æ–°åŸºå‡†ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬çš„ååŒè¿‡æ»¤æ¨¡å‹ç»“åˆäº†ä¸»é¢˜çº§åˆ«çš„æŠ€èƒ½é…ç½®æ–‡ä»¶ï¼Œä½†æ­ç¤ºäº†ä¸€ä¸ªä»¤äººæƒŠè®¶ä¸”æ•™è‚²æ„ä¹‰é‡å¤§çš„å‘ç°â€”â€”å•ä¸ªæ½œåœ¨èƒ½åŠ›å‚æ•°è¶³ä»¥å®ç°æœ€å¤§é¢„æµ‹å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯æ¨å¯¼å¹¶å®ç°äº†ä¸€ç§æ–°é¢–çš„ç¦»æ•£å˜åˆ†æ¨æ–­æ¡†æ¶ï¼Œåœ¨ä½æ•°æ®ç¯å¢ƒä¸‹å®ç°äº†æœ€é«˜çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œå¹¶ä¼˜äºæ‰€æœ‰ç»å…¸çš„IRTå’ŒçŸ©é˜µåˆ†è§£åŸºçº¿ã€‚ 

---
# GeoBS: Information-Theoretic Quantification of Geographic Bias in AI Models 

**Title (ZH)**: GeoBS:åŸºäºä¿¡æ¯ç†è®ºçš„åœ°ç†åå·®é‡åŒ–æ–¹æ³•åœ¨AIæ¨¡å‹ä¸­çš„åº”ç”¨ 

**Authors**: Zhangyu Wang, Nemin Wu, Qian Cao, Jiangnan Xia, Zeping Liu, Yiqun Xie, Akshay Nambi, Tanuja Ganu, Ni Lao, Ninghao Liu, Gengchen Mai  

**Link**: [PDF](https://arxiv.org/pdf/2509.23482)  

**Abstract**: The widespread adoption of AI models, especially foundation models (FMs), has made a profound impact on numerous domains. However, it also raises significant ethical concerns, including bias issues. Although numerous efforts have been made to quantify and mitigate social bias in AI models, geographic bias (in short, geo-bias) receives much less attention, which presents unique challenges. While previous work has explored ways to quantify geo-bias, these measures are model-specific (e.g., mean absolute deviation of LLM ratings) or spatially implicit (e.g., average fairness scores of all spatial partitions). We lack a model-agnostic, universally applicable, and spatially explicit geo-bias evaluation framework that allows researchers to fairly compare the geo-bias of different AI models and to understand what spatial factors contribute to the geo-bias. In this paper, we establish an information-theoretic framework for geo-bias evaluation, called GeoBS (Geo-Bias Scores). We demonstrate the generalizability of the proposed framework by showing how to interpret and analyze existing geo-bias measures under this framework. Then, we propose three novel geo-bias scores that explicitly take intricate spatial factors (multi-scalability, distance decay, and anisotropy) into consideration. Finally, we conduct extensive experiments on 3 tasks, 8 datasets, and 8 models to demonstrate that both task-specific GeoAI models and general-purpose foundation models may suffer from various types of geo-bias. This framework will not only advance the technical understanding of geographic bias but will also establish a foundation for integrating spatial fairness into the design, deployment, and evaluation of AI systems. 

**Abstract (ZH)**: AIæ¨¡å‹ï¼Œå°¤å…¶æ˜¯åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰çš„å¹¿æ³›åº”ç”¨å¯¹ä¼—å¤šé¢†åŸŸäº§ç”Ÿäº†æ·±è¿œå½±å“ï¼Œä½†ä¹Ÿå¼•å‘äº†æ˜¾è‘—çš„ä¼¦ç†é—®é¢˜ï¼ŒåŒ…æ‹¬å…¬å¹³æ€§é—®é¢˜ã€‚å°½ç®¡å·²åšäº†å¤§é‡åŠªåŠ›æ¥é‡åŒ–å’Œå‡è½»AIæ¨¡å‹ä¸­çš„ç¤¾ä¼šåè§ï¼Œä½†åœ°ç†åè§ï¼ˆç®€ç§°Geo-biasï¼‰å´å—åˆ°è¾ƒå°‘å…³æ³¨ï¼Œè¿™æå‡ºäº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚å°½ç®¡ä»¥å¾€å·¥ä½œå·²æ¢ç´¢äº†é‡åŒ–Geo-biasçš„æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸æ˜¯æ¨¡å‹ç‰¹å®šçš„ï¼ˆä¾‹å¦‚ï¼Œå¤§è¯­è¨€æ¨¡å‹è¯„åˆ†çš„ç»å¯¹å‡å·®ï¼‰æˆ–ç©ºé—´éšå«çš„ï¼ˆä¾‹å¦‚ï¼Œæ‰€æœ‰ç©ºé—´åˆ†åŒºå¹³å‡å…¬å¹³æ€§å¾—åˆ†ï¼‰ã€‚ç¼ºä¹ä¸€ç§æ¨¡å‹æ— å…³çš„ã€æ™®éé€‚ç”¨çš„ã€ç©ºé—´æ˜ç¡®çš„Geo-biasè¯„ä»·æ¡†æ¶ï¼Œä½¿ç ”ç©¶äººå‘˜æ— æ³•å…¬å¹³æ¯”è¾ƒä¸åŒAIæ¨¡å‹çš„Geo-biasï¼Œå¹¶ç†è§£å“ªäº›ç©ºé—´å› ç´ å¯¼è‡´äº†Geo-biasã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å»ºç«‹äº†åŸºäºä¿¡æ¯ç†è®ºçš„Geo-biasè¯„ä»·æ¡†æ¶ï¼Œç§°ä¸ºGeoBSï¼ˆGeo-bias Scoresï¼‰ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¡†æ¶çš„ä¸€èˆ¬é€‚ç”¨æ€§ï¼Œé€šè¿‡å±•ç¤ºå¦‚ä½•åœ¨è¯¥æ¡†æ¶ä¸‹è§£é‡Šå’Œåˆ†æç°æœ‰Geo-biasåº¦é‡ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ç§æ–°çš„Geo-biasè¯„åˆ†ï¼Œæ˜ç¡®è€ƒè™‘äº†å¤æ‚çš„ç©ºé—´å› ç´ ï¼ˆå¤šçº§å¯æ‰©å±•æ€§ã€è·ç¦»è¡°å‡å’Œå„å‘å¼‚æ€§ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨3é¡¹ä»»åŠ¡ã€8ä¸ªæ•°æ®é›†å’Œ8ä¸ªæ¨¡å‹ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œè¯æ˜äº†ä¸“é—¨é’ˆå¯¹ä»»åŠ¡çš„GeoAIæ¨¡å‹å’Œé€šç”¨åŸºç¡€æ¨¡å‹éƒ½å¯èƒ½é­å—å„ç§ç±»å‹çš„Geo-biasã€‚è¯¥æ¡†æ¶ä¸ä»…å°†æ¨åŠ¨åœ°ç†åè§çš„æŠ€æœ¯ç†è§£ï¼Œè¿˜å°†ä¸ºå°†ç©ºé—´å…¬å¹³æ€§æ•´åˆåˆ°AIç³»ç»Ÿçš„è®¾è®¡ã€éƒ¨ç½²å’Œè¯„ä¼°ä¸­å¥ å®šåŸºç¡€ã€‚ 

---
# ViTSP: A Vision Language Models Guided Framework for Large-Scale Traveling Salesman Problems 

**Title (ZH)**: ViTSP: ç”±vision-languageæ¨¡å‹æŒ‡å¯¼çš„å¤§è§„æ¨¡æ—…è¡Œå•†é—®é¢˜æ¡†æ¶ 

**Authors**: Zhuoli Yin, Yi Ding, Reem Khir, Hua Cai  

**Link**: [PDF](https://arxiv.org/pdf/2509.23465)  

**Abstract**: Solving Traveling Salesman Problem (TSP) is NP-hard yet fundamental for wide real-world applications. Classical exact methods face challenges in scaling, and heuristic methods often require domain-specific parameter calibration. While learning-based approaches have shown promise, they suffer from poor generalization and limited scalability due to fixed training data. This work proposes ViTSP, a novel framework that leverages pre-trained vision language models (VLMs) to visually guide the solution process for large-scale TSPs. The VLMs function to identify promising small-scale subproblems from a visualized TSP instance, which are then efficiently optimized using an off-the-shelf solver to improve the global solution. ViTSP bypasses the dedicated model training at the user end while maintaining effectiveness across diverse instances. Experiments on real-world TSP instances ranging from 1k to 88k nodes demonstrate that ViTSP consistently achieves solutions with average optimality gaps below 0.2%, outperforming existing learning-based methods. Under the same runtime budget, it surpasses the best-performing heuristic solver, LKH-3, by reducing its gaps by 12% to 100%, particularly on very-large-scale instances with more than 10k nodes. Our framework offers a new perspective in hybridizing pre-trained generative models and operations research solvers in solving combinatorial optimization problems, with practical implications for integration into more complex logistics systems. The code is available at this https URL. 

**Abstract (ZH)**: åŸºäºé¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹çš„Traveling Salesman Problemæ±‚è§£æ–°æ¡†æ¶ 

---
# Beyond Embeddings: Interpretable Feature Extraction for Binary Code Similarity 

**Title (ZH)**: è¶…è¶ŠåµŒå…¥ï¼šäºŒè¿›åˆ¶ä»£ç ç›¸ä¼¼æ€§è§£é‡Šæ€§ç‰¹å¾æå– 

**Authors**: Charles E. Gagnon, Steven H. H. Ding, Philippe Charland, Benjamin C. M. Fung  

**Link**: [PDF](https://arxiv.org/pdf/2509.23449)  

**Abstract**: Binary code similarity detection is a core task in reverse engineering. It supports malware analysis and vulnerability discovery by identifying semantically similar code in different contexts. Modern methods have progressed from manually engineered features to vector representations. Hand-crafted statistics (e.g., operation ratios) are interpretable, but shallow and fail to generalize. Embedding-based methods overcome this by learning robust cross-setting representations, but these representations are opaque vectors that prevent rapid verification. They also face a scalability-accuracy trade-off, since high-dimensional nearest-neighbor search requires approximations that reduce precision. Current approaches thus force a compromise between interpretability, generalizability, and scalability.
We bridge these gaps using a language model-based agent to conduct structured reasoning analysis of assembly code and generate features such as input/output types, side effects, notable constants, and algorithmic intent. Unlike hand-crafted features, they are richer and adaptive. Unlike embeddings, they are human-readable, maintainable, and directly searchable with inverted or relational indexes. Without any matching training, our method respectively achieves 42% and 62% for recall@1 in cross-architecture and cross-optimization tasks, comparable to embedding methods with training (39% and 34%). Combined with embeddings, it significantly outperforms the state-of-the-art, demonstrating that accuracy, scalability, and interpretability can coexist. 

**Abstract (ZH)**: åŸºäºäºŒè¿›åˆ¶ä»£ç ç›¸ä¼¼æ€§æ£€æµ‹çš„é€†å‘å·¥ç¨‹æ ¸å¿ƒä»»åŠ¡ï¼šç»“åˆè¯­è¨€æ¨¡å‹çš„ç»“æ„åŒ–æ¨ç†åœ¨æ¶æ„å’Œä¼˜åŒ–ä»»åŠ¡ä¸­çš„åº”ç”¨ 

---
# Democratizing AI scientists using ToolUniverse 

**Title (ZH)**: ä½¿ç”¨ToolUniverseä½¿äººå·¥æ™ºèƒ½ç§‘å­¦å®¶ democratization 

**Authors**: Shanghua Gao, Richard Zhu, Pengwei Sui, Zhenglun Kong, Sufian Aldogom, Yepeng Huang, Ayush Noori, Reza Shamji, Krishna Parvataneni, Theodoros Tsiligkaridis, Marinka Zitnik  

**Link**: [PDF](https://arxiv.org/pdf/2509.23426)  

**Abstract**: AI scientists are emerging computational systems that serve as collaborative partners in discovery. These systems remain difficult to build because they are bespoke, tied to rigid workflows, and lack shared environments that unify tools, data, and analyses into a common ecosystem. In omics, unified ecosystems have transformed research by enabling interoperability, reuse, and community-driven development; AI scientists require comparable infrastructure. We present ToolUniverse, an ecosystem for building AI scientists from any language or reasoning model, whether open or closed. TOOLUNIVERSE standardizes how AI scientists identify and call tools, integrating more than 600 machine learning models, datasets, APIs, and scientific packages for data analysis, knowledge retrieval, and experimental design. It automatically refines tool interfaces for correct use by AI scientists, creates new tools from natural language descriptions, iteratively optimizes tool specifications, and composes tools into agentic workflows. In a case study of hypercholesterolemia, ToolUniverse was used to create an AI scientist to identify a potent analog of a drug with favorable predicted properties. The open-source ToolUniverse is available at this https URL. 

**Abstract (ZH)**: AIç§‘å­¦å®¶æ˜¯æ–°å…´çš„è®¡ç®—ç³»ç»Ÿï¼Œä½œä¸ºå‘ç°è¿‡ç¨‹ä¸­çš„åˆä½œè€…ã€‚ç”±äºå®ƒä»¬æ˜¯å®šåˆ¶çš„ã€ä¸åˆšæ€§çš„å·¥ä½œæµç¨‹ç›¸å…³è”ä¸”ç¼ºä¹ç»Ÿä¸€çš„ç¯å¢ƒå°†å·¥å…·ã€æ•°æ®å’Œåˆ†æé›†æˆåˆ°ä¸€ä¸ªå…±åŒç”Ÿæ€ç³»ç»Ÿä¸­ï¼Œå› æ­¤æ„å»ºè¿™äº›ç³»ç»Ÿä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨omicsé¢†åŸŸï¼Œç»Ÿä¸€çš„ç”Ÿæ€ç³»ç»Ÿé€šè¿‡ä¿ƒè¿›äº’æ“ä½œæ€§ã€é‡ç”¨å’Œç¤¾åŒºé©±åŠ¨çš„å‘å±•è€Œè½¬å˜äº†ç ”ç©¶ï¼›AIç§‘å­¦å®¶éœ€è¦ç±»ä¼¼çš„åŸºç¡€è®¾æ–½ã€‚æˆ‘ä»¬æå‡ºToolUniverseï¼Œè¿™æ˜¯ä¸€ä¸ªæ„å»ºæ¥è‡ªä»»ä½•è¯­è¨€æˆ–æ¨ç†æ¨¡å‹ï¼ˆæ— è®ºæ˜¯å¼€æºè¿˜æ˜¯å°é—­ï¼‰çš„AIç§‘å­¦å®¶çš„ç”Ÿæ€ç³»ç»Ÿã€‚TOOLUNIVERSEæ ‡å‡†åŒ–äº†AIç§‘å­¦å®¶è¯†åˆ«å’Œè°ƒç”¨å·¥å…·çš„æ–¹å¼ï¼Œé›†æˆäº†è¶…è¿‡600ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ã€æ•°æ®é›†ã€APIå’Œç§‘å­¦åŒ…ï¼Œç”¨äºæ•°æ®åˆ†æã€çŸ¥è¯†æ£€ç´¢å’Œå®éªŒè®¾è®¡ã€‚ToolUniverseè‡ªåŠ¨ç»†åŒ–å·¥å…·æ¥å£ä»¥ä¾›AIç§‘å­¦å®¶æ­£ç¡®ä½¿ç”¨ï¼Œä»è‡ªç„¶è¯­è¨€æè¿°ä¸­åˆ›å»ºæ–°å·¥å…·ï¼Œè¿­ä»£ä¼˜åŒ–å·¥å…·è§„èŒƒï¼Œå¹¶ç»„æˆå…·æœ‰è‡ªä¸»æ€§çš„å·¥ä½œæµç¨‹ã€‚åœ¨é«˜èƒ†å›ºé†‡ç ”ç©¶æ¡ˆä¾‹ä¸­ï¼ŒToolUniverseè¢«ç”¨äºåˆ›å»ºä¸€ä¸ªAIç§‘å­¦å®¶æ¥è¯†åˆ«ä¸€ç§å…·æœ‰æœ‰åˆ©é¢„æµ‹æ€§è´¨çš„è¯ç‰©ç±»ä¼¼ç‰©ã€‚å¼€æºToolUniverseå¯ä»è¯¥é“¾æ¥è®¿é—®ï¼šthis https URLã€‚ 

---
# Socio-Economic Model of AI Agents 

**Title (ZH)**: AIä»£ç†çš„ç»æµç¤¾ä¼šæ¨¡å‹ 

**Authors**: Yuxinyue Qian, Jun Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23270)  

**Abstract**: Modern socio-economic systems are undergoing deep integration with artificial intelligence technologies. This paper constructs a heterogeneous agent-based modeling framework that incorporates both human workers and autonomous AI agents, to study the impact of AI collaboration under resource constraints on aggregate social output. We build five progressively extended models: Model 1 serves as the baseline of pure human collaboration; Model 2 introduces AI as collaborators; Model 3 incorporates network effects among agents; Model 4 treats agents as independent producers; and Model 5 integrates both network effects and independent agent production. Through theoretical derivation and simulation analysis, we find that the introduction of AI agents can significantly increase aggregate social output. When considering network effects among agents, this increase exhibits nonlinear growth far exceeding the simple sum of individual contributions. Under the same resource inputs, treating agents as independent producers provides higher long-term growth potential; introducing network effects further demonstrates strong characteristics of increasing returns to scale. 

**Abstract (ZH)**: ç°ä»£ç¤¾ä¼šç»æµç³»ç»Ÿæ­£ä¸äººå·¥æ™ºèƒ½æŠ€æœ¯æ·±åº¦èåˆã€‚æœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªåŒ…å«äººç±»å·¥äººå’Œè‡ªä¸»AIä»£ç†çš„å¼‚è´¨ä»£ç†åŸºäºæ¨¡å‹æ¡†æ¶ï¼Œç ”ç©¶èµ„æºçº¦æŸæ¡ä»¶ä¸‹AIåä½œå¯¹æ€»ä½“ç¤¾ä¼šäº§å‡ºçš„å½±å“ã€‚æˆ‘ä»¬æ„å»ºäº†äº”ä¸ªé€æ­¥æ‰©å±•çš„æ¨¡å‹ï¼šæ¨¡å‹1ä½œä¸ºçº¯äººç±»åä½œçš„åŸºçº¿ï¼›æ¨¡å‹2å¼•å…¥AIä½œä¸ºåˆä½œè€…ï¼›æ¨¡å‹3çº³å…¥ä»£ç†é—´çš„ç½‘ç»œæ•ˆåº”ï¼›æ¨¡å‹4å°†ä»£ç†è§†ä¸ºç‹¬ç«‹ç”Ÿäº§è€…ï¼›æ¨¡å‹5ç»“åˆäº†ç½‘ç»œæ•ˆåº”å’Œç‹¬ç«‹ä»£ç†ç”Ÿäº§ã€‚é€šè¿‡ç†è®ºæ¨å¯¼å’Œä»¿çœŸåˆ†æå‘ç°ï¼Œå¼•å…¥AIä»£ç†å¯ä»¥æ˜¾è‘—å¢åŠ æ€»ä½“ç¤¾ä¼šäº§å‡ºã€‚è€ƒè™‘ä»£ç†é—´çš„ç½‘ç»œæ•ˆåº”æ—¶ï¼Œè¿™ç§å¢é•¿å‘ˆç°å‡ºéçº¿æ€§å¢é•¿ï¼Œè¿œè¶…ä¸ªä½“è´¡çŒ®çš„ç®€å•ç›¸åŠ ã€‚åœ¨ç›¸åŒçš„èµ„æºè¾“å…¥ä¸‹ï¼Œå°†ä»£ç†è§†ä¸ºç‹¬ç«‹ç”Ÿäº§è€…æä¾›äº†æ›´é«˜çš„é•¿æœŸå¢é•¿æ½œåŠ›ï¼›å¼•å…¥ç½‘ç»œæ•ˆåº”è¿›ä¸€æ­¥å±•ç¤ºäº†è§„æ¨¡æ”¶ç›Šé€’å¢çš„å¼ºçƒˆç‰¹å¾ã€‚ 

---
# Limit Analysis for Symbolic Multi-step Reasoning Tasks with Information Propagation Rules Based on Transformers 

**Title (ZH)**: åŸºäºTransformerçš„ä¿¡æ¯ä¼ æ’­è§„åˆ™ç¬¦å·å¤šæ­¥æ¨ç†ä»»åŠ¡çš„æé™åˆ†æ 

**Authors**: Tian Qin, Yuhan Chen, Zhiwei Wang, Zhi-Qin John Xu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23178)  

**Abstract**: Transformers are able to perform reasoning tasks, however the intrinsic mechanism remains widely open. In this paper we propose a set of information propagation rules based on Transformers and utilize symbolic reasoning tasks to theoretically analyze the limit reasoning steps. We show that the limit number of reasoning steps is between $O(3^{L-1})$ and $O(2^{L-1})$ for a model with $L$ attention layers in a single-pass. 

**Abstract (ZH)**: åŸºäºTransformerçš„ä¿¡æ¯ä¼ æ’­è§„åˆ™åŠå•ä¸€.passä¸­æ¨¡å‹Attentionå±‚æ•°é‡ä¸ºLæ—¶æé™æ¨ç†æ­¥æ•°çš„ç†è®ºåˆ†æ 

---
# AI-Enhanced Distributed Channel Access for Collision Avoidance in Future Wi-Fi 8 

**Title (ZH)**: AIå¢å¼ºçš„åˆ†å¸ƒå¼ä¿¡é“è®¿é—®æŠ€æœ¯ä»¥é¿å…æœªæ¥Wi-Fi 8ä¸­çš„ç¢°æ’ 

**Authors**: Jinzhe Pan, Jingqing Wang, Yuehui Ouyang, Wenchi Cheng, Wei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23154)  

**Abstract**: The exponential growth of wireless devices and stringent reliability requirements of emerging applications demand fundamental improvements in distributed channel access mechanisms for unlicensed bands. Current Wi-Fi systems, which rely on binary exponential backoff (BEB), suffer from suboptimal collision resolution in dense deployments and persistent fairness challenges due to inherent randomness. This paper introduces a multi-agent reinforcement learning framework that integrates artificial intelligence (AI) optimization with legacy device coexistence. We first develop a dynamic backoff selection mechanism that adapts to real-time channel conditions through access deferral events while maintaining full compatibility with conventional CSMA/CA operations. Second, we introduce a fairness quantification metric aligned with enhanced distributed channel access (EDCA) principles to ensure equitable medium access opportunities. Finally, we propose a centralized training decentralized execution (CTDE) architecture incorporating neighborhood activity patterns as observational inputs, optimized via constrained multi-agent proximal policy optimization (MAPPO) to jointly minimize collisions and guarantee fairness. Experimental results demonstrate that our solution significantly reduces collision probability compared to conventional BEB while preserving backward compatibility with commercial Wi-Fi devices. The proposed fairness metric effectively eliminates starvation risks in heterogeneous scenarios. 

**Abstract (ZH)**: æ— çº¿è®¾å¤‡çš„æŒ‡æ•°å¢é•¿å’Œæ–°å…´åº”ç”¨ä¸¥æ ¼çš„åŠŸèƒ½è¦æ±‚ä¿ƒä½¿å¯¹æœªæˆæƒé¢‘å¸¦ä¸­åˆ†å¸ƒå¼ä¿¡é“è®¿é—®æœºåˆ¶è¿›è¡Œæ ¹æœ¬æ€§æ”¹è¿›ã€‚å½“å‰ä¾èµ–äºŒè¿›åˆ¶æŒ‡æ•°é€€é¿ï¼ˆBEBï¼‰çš„Wi-Fiç³»ç»Ÿåœ¨å¯†é›†éƒ¨ç½²ä¸­é¢ä¸´æ¬¡ä¼˜ç¢°æ’è§£å†³å’Œå›ºæœ‰çš„éšæœºæ€§å¯¼è‡´çš„æŒç»­å…¬å¹³æ€§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é›†æˆäº†äººå·¥æ™ºèƒ½ä¼˜åŒ–ä¸ä¼ ç»Ÿè®¾å¤‡å…±å­˜çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŠ¨æ€é€€é¿é€‰æ‹©æœºåˆ¶ï¼Œè¯¥æœºåˆ¶é€šè¿‡æ¥å…¥å»¶è¿Ÿäº‹ä»¶é€‚åº”å®æ—¶ä¿¡é“æ¡ä»¶ï¼ŒåŒæ—¶ä¿æŒä¸ä¼ ç»ŸCSMA/CAæ“ä½œçš„å®Œå…¨å…¼å®¹æ€§ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¸å¢å¼ºåˆ†å¸ƒå¼ä¿¡é“è®¿é—®ï¼ˆEDCAï¼‰åŸåˆ™ç›¸ä¸€è‡´çš„å…¬å¹³æ€§é‡åŒ–æŒ‡æ ‡ï¼Œä»¥ç¡®ä¿å…¬å¹³çš„ä»‹è´¨è®¿é—®æœºä¼šã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé›†æˆé‚»åŸŸæ´»åŠ¨æ¨¡å¼ä½œä¸ºè§‚æµ‹è¾“å…¥çš„é›†ä¸­è®­ç»ƒåˆ†å¸ƒå¼æ‰§è¡Œï¼ˆCTDEï¼‰æ¶æ„ï¼Œé€šè¿‡å—çº¦æŸçš„å¤šæ™ºèƒ½ä½“è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆMAPPOï¼‰ä¼˜åŒ–ï¼Œä»¥è”åˆæœ€å°åŒ–ç¢°æ’å¹¶ä¿è¯å…¬å¹³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»ŸBEBç›¸æ¯”ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆæ˜¾è‘—é™ä½äº†ç¢°æ’æ¦‚ç‡ï¼ŒåŒæ—¶ä¿æŒäº†ä¸å•†ç”¨Wi-Fiè®¾å¤‡çš„å‘åå…¼å®¹æ€§ã€‚æå‡ºçš„å…¬å¹³æ€§æŒ‡æ ‡åœ¨å¼‚æ„åœºæ™¯ä¸­æœ‰æ•ˆåœ°æ¶ˆé™¤äº†é¥¿æ­»é£é™©ã€‚ 

---
# Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence 

**Title (ZH)**: åè°ƒéœ€è¦ç®€åŒ–ï¼šè‡ªç„¶ä¸äººå·¥æ™ºèƒ½å¤šç›®æ ‡å¦¥åçš„çƒ­åŠ›å­¦ç•Œé™ 

**Authors**: Atma Anand  

**Link**: [PDF](https://arxiv.org/pdf/2509.23144)  

**Abstract**: Information-processing systems coordinating across multiple agents and objectives face fundamental thermodynamic constraints. We show that solutions with maximum utility to act as coordination focal points have much higher selection pressure for being findable across agents rather than accuracy. We derive that the information-theoretic minimum description length of coordination protocols to precision $\varepsilon$ scales as $L(P)\geq NK\log_2 K+N^2d^2\log (1/\varepsilon)$ for $N$ agents with $d$ potentially conflicting objectives and internal model complexity $K$. This scaling forces progressive simplification, with coordination dynamics changing the environment itself and shifting optimization across hierarchical levels. Moving from established focal points requires re-coordination, creating persistent metastable states and hysteresis until significant environmental shifts trigger phase transitions through spontaneous symmetry breaking. We operationally define coordination temperature to predict critical phenomena and estimate coordination work costs, identifying measurable signatures across systems from neural networks to restaurant bills to bureaucracies. Extending the topological version of Arrow's theorem on the impossibility of consistent preference aggregation, we find it recursively binds whenever preferences are combined. This potentially explains the indefinite cycling in multi-objective gradient descent and alignment faking in Large Language Models trained with reinforcement learning with human feedback. We term this framework Thermodynamic Coordination Theory (TCT), which demonstrates that coordination requires radical information loss. 

**Abstract (ZH)**: ä¿¡æ¯å¤„ç†ç³»ç»Ÿåœ¨å¤šä»£ç†å’Œå¤šç›®æ ‡ä¹‹é—´åè°ƒæ—¶é¢ä¸´åŸºæœ¬çš„çƒ­åŠ›å­¦çº¦æŸã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œå…·æœ‰æœ€å¤§æ•ˆç”¨ä½œä¸ºåè°ƒç„¦ç‚¹çš„è§£å†³æ–¹æ¡ˆåœ¨è¢«å¤šä¸ªä»£ç†å‘ç°æ–¹é¢çš„é€‰æ‹©å‹åŠ›æ¯”å‡†ç¡®æ€§æ›´é«˜ã€‚æˆ‘ä»¬æ¨å¯¼å‡ºï¼Œç”¨äºç²¾ç¡®åº¦ä¸ºÎµçš„åè°ƒåè®®çš„ä¿¡æ¯è®ºæœ€å°æè¿°é•¿åº¦ä¸º$L(P)\geq NK\log_2 K+N^2d^2\log (1/\varepsilon)$ï¼Œé€‚ç”¨äºæ‹¥æœ‰dä¸ªæ½œåœ¨å†²çªç›®æ ‡å’Œå†…éƒ¨æ¨¡å‹å¤æ‚åº¦ä¸ºKçš„Nä¸ªä»£ç†ã€‚è¿™ç§ç¼©æ”¾è¿«ä½¿é€æ­¥ç®€åŒ–ï¼Œåè°ƒåŠ¨åŠ›å­¦ä¼šæ”¹å˜ç¯å¢ƒæœ¬èº«å¹¶æ²¿å±‚çº§é‡å¡‘ä¼˜åŒ–ã€‚ä»å·²å»ºç«‹çš„ç„¦ç‚¹è¿ç§»åˆ°æ–°çš„ç„¦ç‚¹éœ€è¦é‡æ–°åè°ƒï¼Œå½¢æˆæŒä¹…çš„äºšç¨³æ€å’Œæ»å›ï¼Œç›´åˆ°ç¯å¢ƒå‘ç”Ÿé‡è¦å˜åŒ–æ—¶ï¼Œé€šè¿‡è‡ªå‘å¯¹ç§°ç ´ç¼ºè§¦å‘ç›¸å˜ã€‚æˆ‘ä»¬æ“ä½œæ€§åœ°å®šä¹‰åè°ƒæ¸©åº¦æ¥é¢„æµ‹å…³é”®ç°è±¡ï¼Œä¼°è®¡åè°ƒå·¥ä½œæˆæœ¬ï¼Œå¹¶è¯†åˆ«ä»ç¥ç»ç½‘ç»œåˆ°é¤é¦†è´¦å•å†åˆ°å®˜åƒšæœºæ„ç­‰ç³»ç»Ÿä¸­çš„å¯æµ‹é‡ç‰¹å¾ã€‚æ‰©å±•Arrowä¸å¯èƒ½ä¸€è‡´åå¥½èšåˆå®šç†çš„æ‹“æ‰‘ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å‘ç°å®ƒæ¯å½“åå¥½è¢«ç»“åˆæ—¶éƒ½ä¼šé€’å½’åœ°é€‚ç”¨ã€‚è¿™å¯èƒ½è§£é‡Šäº†å¤šç›®æ ‡æ¢¯åº¦ä¸‹é™ä¸­çš„æ— é™å¾ªç¯ä»¥åŠä½¿ç”¨å¼ºåŒ–å­¦ä¹ å’Œäººç±»åé¦ˆè®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¯¹é½ä½œå¼Šç°è±¡ã€‚æˆ‘ä»¬ç§°è¿™ä¸€æ¡†æ¶ä¸ºçƒ­åŠ›å­¦åè°ƒç†è®ºï¼ˆTCTï¼‰ï¼Œå¹¶è¯æ˜åè°ƒéœ€è¦æ ¹æœ¬çš„ä¿¡æ¯ä¸¢å¤±ã€‚ 

---
# SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems 

**Title (ZH)**: SysMoBench: è¯„ä¼°AIåœ¨æ­£å¼å»ºæ¨¡å¤æ‚ç°å®ç³»ç»Ÿä¸­çš„æ€§èƒ½ 

**Authors**: Qian Cheng, Ruize Tang, Emilie Ma, Finn Hackett, Peiyang He, Yiming Su, Ivan Beschastnikh, Yu Huang, Xiaoxing Ma, Tianyin Xu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23130)  

**Abstract**: Formal models are essential to specifying large, complex computer systems and verifying their correctness, but are notoriously expensive to write and maintain. Recent advances in generative AI show promise in generating certain forms of specifications. However, existing work mostly targets small code, not complete systems. It is unclear whether AI can deal with realistic system artifacts, as this requires abstracting their complex behavioral properties into formal models. We present SysMoBench, a benchmark that evaluates AI's ability to formally model large, complex systems. We focus on concurrent and distributed systems, which are keystones of today's critical computing infrastructures, encompassing operating systems and cloud infrastructure. We use TLA+, the it de facto specification language for concurrent and distributed systems, though the benchmark can be extended to other specification languages. We address the primary challenge of evaluating AI-generated models by automating metrics like syntactic and runtime correctness, conformance to system code, and invariant correctness. SysMoBench currently includes nine diverse system artifacts: the Raft implementation of Etcd and Redis, the Spinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively added. SysMoBench enables us to understand the capabilities and limitations of today's LLMs and agents, putting tools in this area on a firm footing and opening up promising new research directions. 

**Abstract (ZH)**: SysMoBenchï¼šè¯„ä¼°AIæ„å»ºå¤§å‹å¤æ‚ç³»ç»Ÿå½¢å¼æ¨¡å‹çš„èƒ½åŠ› 

---
# Creative Adversarial Testing (CAT): A Novel Framework for Evaluating Goal-Oriented Agentic AI Systems 

**Title (ZH)**: åˆ›é€ æ€§å¯¹æŠ—æ€§æµ‹è¯•ï¼ˆCATï¼‰ï¼šä¸€ç§è¯„ä¼°ç›®æ ‡å¯¼å‘è‡ªä¸»AIç³»ç»Ÿçš„æ–°å‹æ¡†æ¶ 

**Authors**: Hassen Dhrif  

**Link**: [PDF](https://arxiv.org/pdf/2509.23006)  

**Abstract**: Agentic AI represents a paradigm shift in enhancing the capabilities of generative AI models. While these systems demonstrate immense potential and power, current evaluation techniques primarily focus on assessing their efficacy in identifying appropriate agents, tools, and parameters. However, a critical gap exists in evaluating the alignment between an Agentic AI system's tasks and its overarching goals. This paper introduces the Creative Adversarial Testing (CAT) framework, a novel approach designed to capture and analyze the complex relationship between Agentic AI tasks and the system's intended objectives.
We validate the CAT framework through extensive simulation using synthetic interaction data modeled after Alexa+ audio services, a sophisticated Agentic AI system that shapes the user experience for millions of users globally. This synthetic data approach enables comprehensive testing of edge cases and failure modes while protecting user privacy. Our results demonstrate that the CAT framework provides unprecedented insights into goal-task alignment, enabling more effective optimization and development of Agentic AI systems. 

**Abstract (ZH)**: ä»£ç†å‹AIä»£è¡¨äº†å¢å¼ºç”Ÿæˆå‹AIæ¨¡å‹èƒ½åŠ›çš„èŒƒå¼è½¬å˜ã€‚è™½ç„¶è¿™äº›ç³»ç»Ÿå±•ç°å‡ºäº†å·¨å¤§çš„æ½œåŠ›å’ŒåŠ›é‡ï¼Œå½“å‰çš„è¯„ä¼°æŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨è¯„ä¼°å…¶åœ¨è¯†åˆ«åˆé€‚ä»£ç†ã€å·¥å…·å’Œå‚æ•°æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œåœ¨è¯„ä¼°ä»£ç†å‹AIç³»ç»Ÿçš„ä»»åŠ¡ä¸å…¶æ•´ä½“ç›®æ ‡ä¹‹é—´çš„å¯¹é½æ–¹é¢å­˜åœ¨å…³é”®ç¼ºå£ã€‚æœ¬æ–‡å¼•å…¥äº†åˆ›æ„å¯¹æŠ—æµ‹è¯•ï¼ˆCATï¼‰æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æ•æ‰å’Œåˆ†æä»£ç†å‹AIä»»åŠ¡ä¸ç³»ç»Ÿé¢„æœŸç›®æ ‡ä¹‹é—´å¤æ‚å…³ç³»çš„æ–°æ–¹æ³•ã€‚ 

---
# AI Noether -- Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference 

**Title (ZH)**: AI Noetherâ€”â€”é€šè¿‡ abduction æ¨è®ºå¼¥åˆç”± AI ç³»ç»Ÿæ¨å¯¼å‡ºçš„ç§‘å­¦å®šå¾‹ä¸ç»å…¸çŸ¥è¯†ä¹‹é—´çš„å·®è· 

**Authors**: Karan Srivastava, Sanjeeb Dash, Ryan Cory-Wright, Barry Trager, Lior Horesh  

**Link**: [PDF](https://arxiv.org/pdf/2509.23004)  

**Abstract**: A core goal in modern science is to harness recent advances in AI and computer processing to automate and accelerate the scientific method. Symbolic regression can fit interpretable models to data, but these models often sit outside established theory. Recent systems (e.g., AI Descartes, AI Hilbert) enforce derivability from prior axioms. However, sometimes new data and associated hypotheses derived from data are not consistent with existing theory because the existing theory is incomplete or incorrect. Automating abductive inference to close this gap remains open. We propose a solution: an algebraic geometry-based system that, given an incomplete axiom system and a hypothesis that it cannot explain, automatically generates a minimal set of missing axioms that suffices to derive the axiom, as long as axioms and hypotheses are expressible as polynomial equations. We formally establish necessary and sufficient conditions for the successful retrieval of such axioms. We illustrate the efficacy of our approach by demonstrating its ability to explain Kepler's third law and a few other laws, even when key axioms are absent. 

**Abstract (ZH)**: ç°ä»£ç§‘å­¦çš„æ ¸å¿ƒç›®æ ‡æ˜¯åˆ©ç”¨æœ€è¿‘åœ¨äººå·¥æ™ºèƒ½å’Œè®¡ç®—æœºå¤„ç†æ–¹é¢çš„è¿›å±•æ¥è‡ªåŠ¨åŒ–å’ŒåŠ é€Ÿç§‘å­¦ç ”ç©¶æ–¹æ³•ã€‚åŸºäºä»£æ•°å‡ ä½•çš„æ–¹æ³•å¯ä»¥åœ¨ç»™å®šä¸å®Œæ•´å…¬ç†ç³»ç»Ÿå’Œç°æœ‰å…¬ç†æ— æ³•è§£é‡Šçš„å‡è®¾æ—¶ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€å¥—æœ€å°åŒ–çš„ç¼ºå¤±å…¬ç†ï¼Œä»¥æ¨å¯¼å‡ºæ‰€éœ€çš„å…¬ç†ï¼Œå‰ææ˜¯å…¬ç†å’Œå‡è®¾å¯ä»¥è¡¨ç¤ºä¸ºå¤šé¡¹å¼æ–¹ç¨‹ã€‚æˆ‘ä»¬æ­£å¼å»ºç«‹äº†æˆåŠŸæ£€ç´¢æ­¤ç±»å…¬ç†çš„å¿…è¦å’Œå……åˆ†æ¡ä»¶ã€‚é€šè¿‡å±•ç¤ºå…¶èƒ½å¤Ÿè§£é‡Šå¼€æ™®å‹’ç¬¬ä¸‰å®šå¾‹å’Œå…¶ä»–ä¸€äº›å®šå¾‹çš„èƒ½åŠ›ï¼Œå³ä½¿åœ¨å…³é”®å…¬ç†ç¼ºå¸­çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è¯´æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ 

---
# Guided Diffusion for the Discovery of New Superconductors 

**Title (ZH)**: å¼•å¯¼æ€§æ‰©æ•£åœ¨æ–°å‹è¶…å¯¼ä½“çš„å‘ç°ä¸­çš„åº”ç”¨ 

**Authors**: Pawan Prakash, Jason B. Gibson, Zhongwei Li, Gabriele Di Gianluca, Juan Esquivel, Eric Fuemmeler, Benjamin Geisler, Jung Soo Kim, Adrian Roitberg, Ellad B. Tadmor, Mingjie Liu, Stefano Martiniani, Gregory R. Stewart, James J. Hamlin, Peter J. Hirschfeld, Richard G. Hennig  

**Link**: [PDF](https://arxiv.org/pdf/2509.25186)  

**Abstract**: The inverse design of materials with specific desired properties, such as high-temperature superconductivity, represents a formidable challenge in materials science due to the vastness of chemical and structural space. We present a guided diffusion framework to accelerate the discovery of novel superconductors. A DiffCSP foundation model is pretrained on the Alexandria Database and fine-tuned on 7,183 superconductors with first principles derived labels. Employing classifier-free guidance, we sample 200,000 structures, which lead to 34,027 unique candidates. A multistage screening process that combines machine learning and density functional theory (DFT) calculations to assess stability and electronic properties, identifies 773 candidates with DFT-calculated $T_\mathrm{c}>5$ K. Notably, our generative model demonstrates effective property-driven design. Our computational findings were validated against experimental synthesis and characterization performed as part of this work, which highlighted challenges in sparsely charted chemistries. This end-to-end workflow accelerates superconductor discovery while underscoring the challenge of predicting and synthesizing experimentally realizable materials. 

**Abstract (ZH)**: å…·æœ‰ç‰¹å®š desired ç‰¹æ€§çš„ææ–™çš„é€†è®¾è®¡ï¼šåŠ é€Ÿæ–°å‹é«˜æ¸©è¶…å¯¼ä½“çš„å‘ç° 

---
# NAIPv2: Debiased Pairwise Learning for Efficient Paper Quality Estimation 

**Title (ZH)**: NAIPv2: å»åè§çš„æˆå¯¹å­¦ä¹ ä»¥å®ç°é«˜æ•ˆè®ºæ–‡è´¨é‡ä¼°è®¡ 

**Authors**: Penghai Zhao, Jinyu Tian, Qinghua Xing, Xin Zhang, Zheng Li, Jianjun Qian, Ming-Ming Cheng, Xiang Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.25179)  

**Abstract**: The ability to estimate the quality of scientific papers is central to how both humans and AI systems will advance scientific knowledge in the future. However, existing LLM-based estimation methods suffer from high inference cost, whereas the faster direct score regression approach is limited by scale inconsistencies. We present NAIPv2, a debiased and efficient framework for paper quality estimation. NAIPv2 employs pairwise learning within domain-year groups to reduce inconsistencies in reviewer ratings and introduces the Review Tendency Signal (RTS) as a probabilistic integration of reviewer scores and confidences. To support training and evaluation, we further construct NAIDv2, a large-scale dataset of 24,276 ICLR submissions enriched with metadata and detailed structured content. Trained on pairwise comparisons but enabling efficient pointwise prediction at deployment, NAIPv2 achieves state-of-the-art performance (78.2% AUC, 0.432 Spearman), while maintaining scalable, linear-time efficiency at inference. Notably, on unseen NeurIPS submissions, it further demonstrates strong generalization, with predicted scores increasing consistently across decision categories from Rejected to Oral. These findings establish NAIPv2 as a debiased and scalable framework for automated paper quality estimation, marking a step toward future scientific intelligence systems. Code and dataset are released at this https URL. 

**Abstract (ZH)**: NAIPv2ï¼šå»åå·®ä¸”é«˜æ•ˆçš„è®ºæ–‡è´¨é‡ä¼°è®¡æ¡†æ¶ 

---
# GLASS Flows: Transition Sampling for Alignment of Flow and Diffusion Models 

**Title (ZH)**: GLASS æµåŠ¨: æµä¸æ‰©æ•£æ¨¡å‹å¯¹é½çš„è½¬æ¢é‡‡æ ·æ–¹æ³• 

**Authors**: Peter Holderrieth, Uriel Singer, Tommi Jaakkola, Ricky T. Q. Chen, Yaron Lipman, Brian Karrer  

**Link**: [PDF](https://arxiv.org/pdf/2509.25170)  

**Abstract**: The performance of flow matching and diffusion models can be greatly improved at inference time using reward alignment algorithms, yet efficiency remains a major limitation. While several algorithms were proposed, we demonstrate that a common bottleneck is the sampling method these algorithms rely on: many algorithms require to sample Markov transitions via SDE sampling, which is significantly less efficient and often less performant than ODE sampling. To remove this bottleneck, we introduce GLASS Flows, a new sampling paradigm that simulates a "flow matching model within a flow matching model" to sample Markov transitions. As we show in this work, this "inner" flow matching model can be retrieved from a pre-trained model without any re-training, combining the efficiency of ODEs with the stochastic evolution of SDEs. On large-scale text-to-image models, we show that GLASS Flows eliminate the trade-off between stochastic evolution and efficiency. Combined with Feynman-Kac Steering, GLASS Flows improve state-of-the-art performance in text-to-image generation, making it a simple, drop-in solution for inference-time scaling of flow and diffusion models. 

**Abstract (ZH)**: ä½¿ç”¨å¥–åŠ±å¯¹é½ç®—æ³•å¯ä»¥åœ¨æ¨ç†æ—¶å¤§å¹…æé«˜æµåŠ¨åŒ¹é…å’Œæ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ï¼Œä½†æ•ˆç‡ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦é™åˆ¶ã€‚è™½ç„¶æå‡ºäº†å‡ ç§ç®—æ³•ï¼Œä½†æˆ‘ä»¬å±•ç¤ºäº†è¿™äº›ç®—æ³•ä¾èµ–çš„é‡‡æ ·æ–¹æ³•æ˜¯ä¸€ä¸ªå…±åŒç“¶é¢ˆï¼šè®¸å¤šç®—æ³•éœ€è¦é€šè¿‡SDEé‡‡æ ·æ¥é‡‡æ ·é©¬å°”ç§‘å¤«è½¬æ¢ï¼Œè¿™åœ¨æ•ˆç‡å’Œæ€§èƒ½ä¸Šé€šå¸¸è¿œé€ŠäºODEé‡‡æ ·ã€‚ä¸ºäº†æ¶ˆé™¤è¿™ä¸€ç“¶é¢ˆï¼Œæˆ‘ä»¬æå‡ºäº†GLASS Flowsï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„é‡‡æ ·èŒƒå¼ï¼Œæ¨¡æ‹Ÿâ€œåœ¨ä¸€ä¸ªæµåŠ¨åŒ¹é…æ¨¡å‹å†…éƒ¨æ¨¡æ‹Ÿä¸€ä¸ªæµåŠ¨åŒ¹é…æ¨¡å‹â€æ¥é‡‡æ ·é©¬å°”ç§‘å¤«è½¬æ¢ã€‚å¦‚æœ¬æ–‡æ‰€ç¤ºï¼Œè¿™ç§â€œå†…éƒ¨â€çš„æµåŠ¨åŒ¹é…æ¨¡å‹å¯ä»¥ä»é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ä¸­æå–å‡ºæ¥ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œä»è€Œç»“åˆäº†ODEçš„é«˜æ•ˆæ€§å’ŒSDEçš„éšæœºæ¼”åŒ–ã€‚åœ¨å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸Šï¼Œæˆ‘ä»¬å±•ç¤ºäº†GLASS Flowsæ¶ˆé™¤äº†éšæœºæ¼”åŒ–ä¸æ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚ç»“åˆè´¹æ›¼-å¡èŒ¨å¼•å¯¼ï¼ŒGLASS Flowsæé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„æœ€æ–°æ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºæµåŠ¨å’Œæ‰©æ•£æ¨¡å‹æ¨ç†æ—¶é—´æ‰©å±•çš„ä¸€ä¸ªç®€å•å³æ’å³ç”¨è§£å†³æ–¹æ¡ˆã€‚ 

---
# Chance-constrained Flow Matching for High-Fidelity Constraint-aware Generation 

**Title (ZH)**: é«˜ä¿çœŸçº¦æŸawareç”Ÿæˆçš„æœºé‡çº¦æŸæµåŒ¹é… 

**Authors**: Jinhao Liang, Yixuan Sun, Anirban Samaddar, Sandeep Madireddy, Ferdinando Fioretto  

**Link**: [PDF](https://arxiv.org/pdf/2509.25157)  

**Abstract**: Generative models excel at synthesizing high-fidelity samples from complex data distributions, but they often violate hard constraints arising from physical laws or task specifications. A common remedy is to project intermediate samples onto the feasible set; however, repeated projection can distort the learned distribution and induce a mismatch with the data manifold. Thus, recent multi-stage procedures attempt to defer projection to clean samples during sampling, but they increase algorithmic complexity and accumulate errors across steps. This paper addresses these challenges by proposing a novel training-free method, Chance-constrained Flow Matching (CCFM), that integrates stochastic optimization into the sampling process, enabling effective enforcement of hard constraints while maintaining high-fidelity sample generation. Importantly, CCFM guarantees feasibility in the same manner as conventional repeated projection, yet, despite operating directly on noisy intermediate samples, it is theoretically equivalent to projecting onto the feasible set defined by clean samples. This yields a sampler that mitigates distributional distortion. Empirical experiments show that CCFM outperforms current state-of-the-art constrained generative models in modeling complex physical systems governed by partial differential equations and molecular docking problems, delivering higher feasibility and fidelity. 

**Abstract (ZH)**: æœºä¼šçº¦æŸæµé‡åŒ¹é…ï¼šä¸€ç§è®­ç»ƒ-Free çš„é«˜ä¿çœŸç”Ÿæˆæ–¹æ³• 

---
# Paired by the Teacher: Turning Unpaired Data into High-Fidelity Pairs for Low-Resource Text Generation 

**Title (ZH)**: ç”±è€å¸ˆé…å¯¹ï¼šå°†æ— é…å¯¹æ•°æ®è½¬æ¢ä¸ºä½èµ„æºæ–‡æœ¬ç”Ÿæˆçš„é«˜ä¿çœŸé…å¯¹ 

**Authors**: Yen-Ju Lu, Thomas Thebaud, Laureano Moro-Velazquez, Najim Dehak, Jesus Villalba  

**Link**: [PDF](https://arxiv.org/pdf/2509.25144)  

**Abstract**: We present Paired by the Teacher (PbT), a two-stage teacher-student pipeline that synthesizes accurate input-output pairs without human labels or parallel data. In many low-resource natural language generation (NLG) scenarios, practitioners may have only raw outputs, like highlights, recaps, or questions, or only raw inputs, such as articles, dialogues, or paragraphs, but seldom both. This mismatch forces small models to learn from very few examples or rely on costly, broad-scope synthetic examples produced by large LLMs. PbT addresses this by asking a teacher LLM to compress each unpaired example into a concise intermediate representation (IR), and training a student to reconstruct inputs from IRs. This enables outputs to be paired with student-generated inputs, yielding high-quality synthetic data. We evaluate PbT on five benchmarks-document summarization (XSum, CNNDM), dialogue summarization (SAMSum, DialogSum), and question generation (SQuAD)-as well as an unpaired setting on SwitchBoard (paired with DialogSum summaries). An 8B student trained only on PbT data outperforms models trained on 70 B teacher-generated corpora and other unsupervised baselines, coming within 1.2 ROUGE-L of human-annotated pairs and closing 82% of the oracle gap at one-third the annotation cost of direct synthesis. Human evaluation on SwitchBoard further confirms that only PbT produces concise, faithful summaries aligned with the target style, highlighting its advantage of generating in-domain sources that avoid the mismatch, limiting direct synthesis. 

**Abstract (ZH)**: Paired by the Teacherï¼šä¸€ç§æ— éœ€äººå·¥æ ‡ç­¾æˆ–å¹³è¡Œæ•°æ®çš„ä¸¤é˜¶æ®µæ•™å¸ˆ-å­¦ç”Ÿç®¡é“ 

---
# Towards Personalized Deep Research: Benchmarks and Evaluations 

**Title (ZH)**: é¢å‘ä¸ªæ€§åŒ–æ·±åº¦ç ”ç©¶çš„åŸºå‡†ä¸è¯„ä¼° 

**Authors**: Yuan Liang, Jiaxian Li, Yuqing Wang, Piaohong Wang, Motong Tian, Pai Liu, Shuofei Qiao, Runnan Fang, He Zhu, Ge Zhang, Minghao Liu, Yuchen Eleanor Jiang, Ningyu Zhang, Wangchunshu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.25106)  

**Abstract**: Deep Research Agents (DRAs) can autonomously conduct complex investigations and generate comprehensive reports, demonstrating strong real-world potential. However, existing evaluations mostly rely on close-ended benchmarks, while open-ended deep research benchmarks remain scarce and typically neglect personalized scenarios. To bridge this gap, we introduce Personalized Deep Research Bench, the first benchmark for evaluating personalization in DRAs. It pairs 50 diverse research tasks across 10 domains with 25 authentic user profiles that combine structured persona attributes with dynamic real-world contexts, yielding 250 realistic user-task queries. To assess system performance, we propose the PQR Evaluation Framework, which jointly measures (P) Personalization Alignment, (Q) Content Quality, and (R) Factual Reliability. Our experiments on a range of systems highlight current capabilities and limitations in handling personalized deep research. This work establishes a rigorous foundation for developing and evaluating the next generation of truly personalized AI research assistants. 

**Abstract (ZH)**: ä¸ªæ€§åŒ–çš„æ·±åº¦ç ”ç©¶åŸºå‡†ï¼šè¯„ä¼°DRAsçš„é¦–ä¸ªåŸºå‡† 

---
# jina-reranker-v3: Last but Not Late Interaction for Document Reranking 

**Title (ZH)**: jina-reranker-v3ï¼šæœ€åä½†å¹¶éæœ€ä¸é‡è¦äº¤äº’çš„æ–‡æ¡£é‡æ’ 

**Authors**: Feng Wang, Yuqing Li, Han Xiao  

**Link**: [PDF](https://arxiv.org/pdf/2509.25085)  

**Abstract**: jina-reranker-v3 is a 0.6B parameter multilingual document reranker that introduces a novel last but not late interaction. Unlike late interaction models such as ColBERT that perform separate encoding followed by multi-vector matching, our approach conducts causal self-attention between query and documents within the same context window, enabling rich cross-document interactions before extracting contextual embeddings from the last token of each document. This compact architecture achieves state-of-the-art BEIR performance with 61.94 nDCG@10 while being ten times smaller than generative listwise rerankers. 

**Abstract (ZH)**: Jina-Reranker-v3æ˜¯ä¸€ç§å‚æ•°é‡ä¸º0.6Bçš„å¤šè¯­è¨€æ–‡æ¡£é‡æ’åºå™¨ï¼Œå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„éæ™šäº¤äº’æ–¹å¼ã€‚ä¸åŒäºColBERTç­‰æ™šäº¤äº’æ¨¡å‹åœ¨åˆ†åˆ«ç¼–ç åè¿›è¡Œå¤šå‘é‡åŒ¹é…çš„åšæ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒä¸€ä¸ªä¸Šä¸‹æ–‡çª—å£å†…å¯¹æŸ¥è¯¢å’Œæ–‡æ¡£ä¹‹é—´è¿›è¡Œå› æœè‡ªæ³¨æ„åŠ›äº¤äº’ï¼Œä»è€Œåœ¨æå–æ¯ä¸ªæ–‡æ¡£æœ€åä¸€è¯çš„ä¸Šä¸‹æ–‡åµŒå…¥ä¹‹å‰å®ç°ä¸°å¯Œçš„è·¨æ–‡æ¡£äº¤äº’ã€‚è¿™ç§ç´§å‡‘çš„æ¶æ„åœ¨BEIRä¸Šè¾¾åˆ°äº†61.94çš„nDCG@10æ€§èƒ½ï¼ŒåŒæ—¶ä»…æœ‰ç”Ÿæˆå‹åˆ—è¡¨é‡æ’åºå™¨çš„ååˆ†ä¹‹ä¸€å¤§å°ã€‚ 

---
# Scaling Generalist Data-Analytic Agents 

**Title (ZH)**: æ‰©å±•é€šç”¨æ•°æ®åˆ†æå¸ˆä»£ç† 

**Authors**: Shuofei Qiao, Yanqiu Zhao, Zhisong Qiu, Xiaobin Wang, Jintian Zhang, Zhao Bin, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.25084)  

**Abstract**: Data-analytic agents are emerging as a key catalyst for automated scientific discovery and for the vision of Innovating AI. Current approaches, however, rely heavily on prompt engineering over proprietary models, while open-source models struggle to face diverse-format, large-scale data files and long-horizon, multi-step reasoning that real-world analytics demands. This paper introduces DataMind, a scalable data synthesis and agent training recipe designed to build generalist data-analytic agents. DataMind tackles three key challenges in building open-source data-analytic agents, including insufficient data resources, improper training strategy, and unstable code-based multi-turn rollout. Concretely, DataMind applies 1) a fine-grained task taxonomy and a recursive easy-to-hard task composition mechanism to increase the diversity and difficulty of synthesized queries; 2) a knowledge-augmented trajectory sampling strategy followed by model-based and rule-based filtering; 3) a dynamically adjustable training objective combining both SFT and RL losses; 4) a memory-frugal and stable code-based multi-turn rollout framework. Built on DataMind, we curate DataMind-12K, a high-quality trajectory set spanning diverse domains, task categories, and data file formats for data-analytic tasks. Trained on DataMind-12K, our DataMind-14B achieves state-of-the-art with an average score of 71.16% on multiple data analysis benchmarks, outperforming the strongest proprietary baselines DeepSeek-V3.1 and GPT-5. Our DataMind-7B also performs best among all open-source models with a score of 68.10%. We also incorporate some empirical insights gained from our exploratory trials into the analysis experiments, aiming to provide actionable insights about agentic training for the community. We will release DataMind-12K and DataMind-7B,14B for the community's future research. 

**Abstract (ZH)**: DataMindï¼šé¢å‘å¼€æºæ•°æ®åˆ†æä»£ç†çš„å¯æ‰©å±•æ•°æ®åˆæˆä¸æ™ºèƒ½ä½“è®­ç»ƒæ–¹æ³• 

---
# Learning Distinguishable Representations in Deep Q-Networks for Linear Transfer 

**Title (ZH)**: åŸºäºæ·±å±‚Qç½‘ç»œçš„å­¦ä¹ å¯åŒºåˆ†è¡¨ç¤ºæ–¹æ³•åŠå…¶åœ¨çº¿æ€§è½¬ç§»ä¸­çš„åº”ç”¨ 

**Authors**: Sooraj Sathish, Keshav Goyal, Raghuram Bharadwaj Diddigi  

**Link**: [PDF](https://arxiv.org/pdf/2509.24947)  

**Abstract**: Deep Reinforcement Learning (RL) has demonstrated success in solving complex sequential decision-making problems by integrating neural networks with the RL framework. However, training deep RL models poses several challenges, such as the need for extensive hyperparameter tuning and high computational costs. Transfer learning has emerged as a promising strategy to address these challenges by enabling the reuse of knowledge from previously learned tasks for new, related tasks. This avoids the need for retraining models entirely from scratch. A commonly used approach for transfer learning in RL is to leverage the internal representations learned by the neural network during training. Specifically, the activations from the last hidden layer can be viewed as refined state representations that encapsulate the essential features of the input. In this work, we investigate whether these representations can be used as input for training simpler models, such as linear function approximators, on new tasks. We observe that the representations learned by standard deep RL models can be highly correlated, which limits their effectiveness when used with linear function approximation. To mitigate this problem, we propose a novel deep Q-learning approach that introduces a regularization term to reduce positive correlations between feature representation of states. By leveraging these reduced correlated features, we enable more effective use of linear function approximation in transfer learning. Through experiments and ablation studies on standard RL benchmarks and MinAtar games, we demonstrate the efficacy of our approach in improving transfer learning performance and thereby reducing computational overhead. 

**Abstract (ZH)**: æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é€šè¿‡å°†ç¥ç»ç½‘ç»œä¸RLæ¡†æ¶ç»“åˆï¼Œå±•ç¤ºäº†åœ¨è§£å†³å¤æ‚åºè´¯å†³ç­–é—®é¢˜æ–¹é¢çš„æˆåŠŸã€‚ç„¶è€Œï¼Œè®­ç»ƒæ·±åº¦RLæ¨¡å‹é¢ä¸´ç€è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚è¶…å‚æ•°è°ƒä¼˜éœ€æ±‚å¹¿æ³›å’Œé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚è¿ç§»å­¦ä¹ ä½œä¸ºä¸€ç§æœ‰å‰é€”çš„ç­–ç•¥ï¼Œé€šè¿‡åˆ©ç”¨å…ˆå‰å­¦ä¹ ä»»åŠ¡ä¸­è·å¾—çš„çŸ¥è¯†æ¥è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œä½¿å…¶èƒ½å¤Ÿä¸ºç›®æ ‡ç›¸å…³çš„æ–°ä»»åŠ¡å¤ç”¨çŸ¥è¯†ï¼Œä»è€Œé¿å…ä»å¤´é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚åœ¨RLä¸­ï¼Œä½¿ç”¨è¿ç§»å­¦ä¹ çš„ä¸€ä¸ªå¸¸ç”¨æ–¹æ³•æ˜¯åˆ©ç”¨ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ åˆ°çš„å†…éƒ¨è¡¨ç¤ºã€‚å…·ä½“è€Œè¨€ï¼Œæœ€åä¸€éšè—å±‚çš„æ¿€æ´»å¯ä»¥è§†ä¸ºæ”¹è¿›çš„çŠ¶æ€è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºåŒ…å«äº†è¾“å…¥çš„é‡è¦ç‰¹å¾ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶è¿™äº›è¡¨ç¤ºæ˜¯å¦å¯ä»¥ä½œä¸ºè¾“å…¥ç”¨äºè®­ç»ƒç®€å•æ¨¡å‹ï¼Œå¦‚çº¿æ€§å‡½æ•°é€¼è¿‘å™¨ï¼Œåœ¨æ–°ä»»åŠ¡ä¸Šçš„è®­ç»ƒã€‚æˆ‘ä»¬å‘ç°æ ‡å‡†æ·±åº¦RLæ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨ç¤ºä¹‹é—´é«˜åº¦ç›¸å…³ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨ä½¿ç”¨çº¿æ€§å‡½æ•°é€¼è¿‘æ—¶çš„æœ‰æ•ˆæ€§ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ·±åº¦Qå­¦ä¹ æ–¹æ³•ï¼Œå¼•å…¥æ­£åˆ™åŒ–é¡¹ä»¥å‡å°‘çŠ¶æ€ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„æ­£ç›¸å…³æ€§ã€‚é€šè¿‡åˆ©ç”¨è¿™äº›å‡å°‘çš„ç›¸å…³ç‰¹å¾ï¼Œæˆ‘ä»¬ä½¿çº¿æ€§å‡½æ•°é€¼è¿‘åœ¨è¿ç§»å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å¾—ä»¥æå‡ã€‚é€šè¿‡åœ¨æ ‡å‡†RLåŸºå‡†å’ŒMinAtaræ¸¸æˆä¸­è¿›è¡Œå®éªŒå’Œæ¶ˆèç ”ç©¶ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨æé«˜è¿ç§»å­¦ä¹ æ€§èƒ½æ–¹é¢çš„èƒ½åŠ›ï¼Œä»è€Œå‡å°‘äº†è®¡ç®—å¼€é”€ã€‚ 

---
# Scalable GANs with Transformers 

**Title (ZH)**: å¯æ‰©å±•çš„Transformeråœ°å¸¦ç½‘ç»œ 

**Authors**: Sangeek Hyun, MinKyu Lee, Jae-Pil Heo  

**Link**: [PDF](https://arxiv.org/pdf/2509.24935)  

**Abstract**: Scalability has driven recent advances in generative modeling, yet its principles remain underexplored for adversarial learning. We investigate the scalability of Generative Adversarial Networks (GANs) through two design choices that have proven to be effective in other types of generative models: training in a compact Variational Autoencoder latent space and adopting purely transformer-based generators and discriminators. Training in latent space enables efficient computation while preserving perceptual fidelity, and this efficiency pairs naturally with plain transformers, whose performance scales with computational budget. Building on these choices, we analyze failure modes that emerge when naively scaling GANs. Specifically, we find issues as underutilization of early layers in the generator and optimization instability as the network scales. Accordingly, we provide simple and scale-friendly solutions as lightweight intermediate supervision and width-aware learning-rate adjustment. Our experiments show that GAT, a purely transformer-based and latent-space GANs, can be easily trained reliably across a wide range of capacities (S through XL). Moreover, GAT-XL/2 achieves state-of-the-art single-step, class-conditional generation performance (FID of 2.96) on ImageNet-256 in just 40 epochs, 6x fewer epochs than strong baselines. 

**Abstract (ZH)**: ç”Ÿæˆæ¨¡å‹çš„å¯æ‰©å±•æ€§å·²æ¨åŠ¨äº†è¿‘æœŸçš„è¿›æ­¥ï¼Œç„¶è€Œå…¶åŸç†åœ¨å¯¹æŠ—å­¦ä¹ ä¸­çš„åº”ç”¨ä»å¾…æ·±å…¥æ¢ç´¢ã€‚æˆ‘ä»¬é€šè¿‡ä¸¤ç§åœ¨å…¶ä»–ç”Ÿæˆæ¨¡å‹ä¸­ proven effective çš„è®¾è®¡é€‰æ‹©æ¥ç ”ç©¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰çš„å¯æ‰©å±•æ€§ï¼šåœ¨ç´§å‡‘çš„å˜åˆ†è‡ªç¼–ç å™¨æ½œç©ºé—´ä¸­è®­ç»ƒä»¥åŠé‡‡ç”¨çº¯å˜å‹å™¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ã€‚åœ¨æ½œç©ºé—´ä¸­è®­ç»ƒä½¿å¾—è®¡ç®—é«˜æ•ˆä¸”ä¿ç•™æ„ŸçŸ¥ä¿çœŸåº¦ï¼Œè¿™ç§æ•ˆç‡ä¸æ€§èƒ½éšè®¡ç®—é¢„ç®—çº¿æ€§æ‰©å±•çš„çº¯Transformerè‡ªç„¶é…å¯¹ã€‚åŸºäºè¿™äº›é€‰æ‹©ï¼Œæˆ‘ä»¬åˆ†æäº†ç›²ç›®æ‰©å±•GANsæ—¶å‡ºç°çš„æ•…éšœæ¨¡å¼ï¼Œç‰¹åˆ«æ˜¯å‘ç°ç”Ÿæˆå™¨æ—©æœŸå±‚çš„åˆ©ç”¨ç‡ä¸è¶³å’Œç½‘ç»œæ‰©å±•æ—¶çš„ä¼˜åŒ–ä¸ç¨³å®šé—®é¢˜ã€‚ç›¸åº”åœ°ï¼Œæˆ‘ä»¬æä¾›äº†è§£å†³æ–¹æ¡ˆï¼Œå³è½»é‡çº§ä¸­é—´ç›‘ç£å’Œå®½åº¦æ„ŸçŸ¥çš„å­¦ä¹ ç‡è°ƒæ•´ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒGATï¼ˆçº¯Transformerå’Œæ½œç©ºé—´GANsï¼‰å¯ä»¥åœ¨å¹¿æ³›çš„èƒ½åŠ›èŒƒå›´å†…ï¼ˆSåˆ°XLï¼‰å¯é åœ°è®­ç»ƒã€‚æ­¤å¤–ï¼ŒGAT-XL/2åœ¨ImageNet-256ä¸Šçš„å•æ­¥æ¡ä»¶ç”Ÿæˆæ€§èƒ½ï¼ˆFIDä¸º2.96ï¼‰è¾¾åˆ°æœ€å…ˆè¿›çš„æ•ˆæœï¼Œå¹¶ä¸”ä»…éœ€40ä¸ªepochï¼Œæ¯”å¼ºå¤§åŸºçº¿å°‘6å€ã€‚ 

---
# Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime 

**Title (ZH)**: æµ…ç¥ç»ç½‘ç»œåœ¨ç‰¹å¾å­¦ä¹ é˜¶æ®µçš„æ ‡åº¦å®šå¾‹ä¸é¢‘è°±åˆ†å¸ƒ 

**Authors**: Leonardo Defilippis, Yizhou Xu, Julius Girardin, Emanuele Troiani, Vittorio Erba, Lenka ZdeborovÃ¡, Bruno Loureiro, Florent Krzakala  

**Link**: [PDF](https://arxiv.org/pdf/2509.24882)  

**Abstract**: Neural scaling laws underlie many of the recent advances in deep learning, yet their theoretical understanding remains largely confined to linear models. In this work, we present a systematic analysis of scaling laws for quadratic and diagonal neural networks in the feature learning regime. Leveraging connections with matrix compressed sensing and LASSO, we derive a detailed phase diagram for the scaling exponents of the excess risk as a function of sample complexity and weight decay. This analysis uncovers crossovers between distinct scaling regimes and plateau behaviors, mirroring phenomena widely reported in the empirical neural scaling literature. Furthermore, we establish a precise link between these regimes and the spectral properties of the trained network weights, which we characterize in detail. As a consequence, we provide a theoretical validation of recent empirical observations connecting the emergence of power-law tails in the weight spectrum with network generalization performance, yielding an interpretation from first principles. 

**Abstract (ZH)**: ç¥ç»ç½‘ç»œä¸­çš„äºŒæ¬¡å’Œå¯¹è§’ç»“æ„åœ¨ç‰¹å¾å­¦ä¹ ä¸­çš„æ ‡åº¦å¾‹æ­ç¤ºäº†è¿‘æœŸæ·±åº¦å­¦ä¹ è¿›å±•çš„è®¸å¤šå¥¥ç§˜ï¼Œç„¶è€Œè¿™äº›ç†è®ºç†è§£ä¸»è¦å±€é™äºçº¿æ€§æ¨¡å‹ã€‚æœ¬æ–‡ç³»ç»Ÿåˆ†æäº†ç‰¹å¾å­¦ä¹ ç¯å¢ƒä¸‹äºŒæ¬¡å’Œå¯¹è§’ç¥ç»ç½‘ç»œçš„æ ‡åº¦å¾‹ã€‚å€ŸåŠ©çŸ©é˜µå‹ç¼©æ„ŸçŸ¥å’ŒLASSOçš„è”ç³»ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†è¿‡å‰©é£é™©æ ‡åº¦æŒ‡æ•°ä¸æ ·æœ¬å¤æ‚åº¦å’Œæƒé‡è¡°å‡ä¹‹é—´çš„è¯¦ç»†ç›¸å›¾ã€‚è¿™ä¸€åˆ†ææ­ç¤ºäº†ä¸åŒæ ‡åº¦å¾‹ä¹‹é—´çš„äº¤å‰è¡Œä¸ºå’Œå¹³å°è¡Œä¸ºï¼Œåæ˜ äº†åœ¨ç»éªŒç¥ç»ç½‘ç»œæ ‡åº¦æ–‡çŒ®ä¸­å¹¿æ³›æŠ¥é“çš„ç°è±¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å»ºç«‹äº†è¿™äº›åŒºåŸŸä¸è®­ç»ƒç½‘ç»œæƒé‡çš„è°±æ€§è´¨ä¹‹é—´çš„ç²¾ç¡®è”ç³»ï¼Œå¹¶è¯¦ç»†æè¿°äº†è¿™äº›æ€§è´¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ç§ä»ç¬¬ä¸€åŸç†å‡ºå‘çš„ç†è®ºéªŒè¯ï¼Œæœ€è¿‘çš„ç»éªŒè§‚å¯Ÿå°†æƒé‡è°±ä¸­å¹‚å¾‹å°¾å·´çš„å‡ºç°ä¸ç½‘ç»œæ³›åŒ–æ€§èƒ½è”ç³»èµ·æ¥ã€‚ 

---
# Vehicle Classification under Extreme Imbalance: A Comparative Study of Ensemble Learning and CNNs 

**Title (ZH)**: åœ¨æç«¯ä¸å‡è¡¡æƒ…å†µä¸‹çš„è½¦è¾†åˆ†ç±»ï¼šé›†æˆå­¦ä¹ ä¸CNNsçš„æ¯”è¾ƒç ”ç©¶ 

**Authors**: Abu Hanif Muhammad Syarubany  

**Link**: [PDF](https://arxiv.org/pdf/2509.24880)  

**Abstract**: Accurate vehicle type recognition underpins intelligent transportation and logistics, but severe class imbalance in public datasets suppresses performance on rare categories. We curate a 16-class corpus (~47k images) by merging Kaggle, ImageNet, and web-crawled data, and create six balanced variants via SMOTE oversampling and targeted undersampling. Lightweight ensembles, such as Random Forest, AdaBoost, and a soft-voting combiner built on MobileNet-V2 features are benchmarked against a configurable ResNet-style CNN trained with strong augmentation and label smoothing. The best ensemble (SMOTE-combined) attains 74.8% test accuracy, while the CNN achieves 79.19% on the full test set and 81.25% on an unseen inference batch, confirming the advantage of deep models. Nonetheless, the most under-represented class (Barge) remains a failure mode, highlighting the limits of rebalancing alone. Results suggest prioritizing additional minority-class collection and cost-sensitive objectives (e.g., focal loss) and exploring hybrid ensemble or CNN pipelines to combine interpretability with representational power. 

**Abstract (ZH)**: ç²¾ç¡®çš„è½¦è¾†ç±»å‹è¯†åˆ«æ˜¯æ™ºèƒ½äº¤é€šå’Œç‰©æµçš„åŸºç¡€ï¼Œä½†åœ¨å…¬å…±æ•°æ®é›†ä¸­ä¸¥é‡çš„ç±»åˆ«ä¸å¹³è¡¡æŠ‘åˆ¶äº†å¯¹ç¨€æœ‰ç±»åˆ«çš„æ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡åˆå¹¶Kaggleã€ImageNetå’Œç½‘ç»œæŠ“å–æ•°æ®æ„å»ºäº†ä¸€ä¸ªåŒ…å«16ç±»ï¼ˆçº¦47kå¼ å›¾ç‰‡ï¼‰çš„è¯­æ–™åº“ï¼Œå¹¶é€šè¿‡SMOTEè¿‡é‡‡æ ·å’Œç›®æ ‡æ€§ä¸‹é‡‡æ ·åˆ›å»ºäº†å…­ä¸ªå¹³è¡¡å˜ä½“ã€‚åŸºå‡†æµ‹è¯•äº†è½»é‡çº§é›†æˆæ¨¡å‹ï¼Œå¦‚éšæœºæ£®æ—ã€AdaBoostä»¥åŠåŸºäºMobileNet-V2ç‰¹å¾çš„è½¯æŠ•ç¥¨ç»„åˆå™¨ï¼Œè¿™äº›æ¨¡å‹ä¸é…ç½®å¯è°ƒçš„å…·æœ‰å¼ºå¢å¼ºå’Œæ ‡ç­¾å¹³æ»‘çš„ResNeté£æ ¼CNNè¿›è¡Œäº†å¯¹æ¯”ã€‚æœ€ä¼˜é›†æˆæ¨¡å‹ï¼ˆSMOTEç»„åˆï¼‰åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º74.8%ï¼Œè€ŒCNNåœ¨å®Œæ•´æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º79.19%ï¼Œåœ¨æœªè§è¿‡çš„æ¨ç†æ‰¹æ¬¡ä¸Šçš„å‡†ç¡®ç‡ä¸º81.25%ï¼Œè¯å®äº†æ·±åº¦æ¨¡å‹çš„ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œæœ€æ¬ ä»£è¡¨çš„ç±»åˆ«ï¼ˆé©³èˆ¹ï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªå¤±è´¥æ¨¡å¼ï¼Œè¡¨æ˜ä»…é€šè¿‡é‡æ–°å¹³è¡¡æ— æ³•å®Œå…¨è§£å†³é—®é¢˜ã€‚ç»“æœè¡¨æ˜ï¼Œåº”ä¼˜å…ˆè€ƒè™‘é¢å¤–çš„å°ç±»åˆ«é‡‡é›†å’Œæˆæœ¬æ•æ„Ÿç›®æ ‡ï¼ˆå¦‚ç„¦ç‚¹æŸå¤±ï¼‰ï¼Œå¹¶æ¢ç´¢æ··åˆé›†æˆæˆ–CNNç®¡é“ï¼Œä»¥ç»“åˆè§£é‡Šæ€§å’Œè¡¨ç°åŠ›ã€‚ 

---
# Uncertainty-Guided Expert-AI Collaboration for Efficient Soil Horizon Annotation 

**Title (ZH)**: åŸºäºä¸ç¡®å®šæ€§æŒ‡å¯¼çš„ä¸“å®¶-AIåä½œé«˜æ•ˆåœŸå£¤å±‚æ ‡æ³¨ 

**Authors**: Teodor Chiaburu, Vipin Singh, Frank HauÃŸer, Felix BieÃŸmann  

**Link**: [PDF](https://arxiv.org/pdf/2509.24873)  

**Abstract**: Uncertainty quantification is essential in human-machine collaboration, as human agents tend to adjust their decisions based on the confidence of the machine counterpart. Reliably calibrated model uncertainties, hence, enable more effective collaboration, targeted expert intervention and more responsible usage of Machine Learning (ML) systems. Conformal prediction has become a well established model-agnostic framework for uncertainty calibration of ML models, offering statistically valid confidence estimates for both regression and classification tasks. In this work, we apply conformal prediction to $\textit{SoilNet}$, a multimodal multitask model for describing soil profiles. We design a simulated human-in-the-loop (HIL) annotation pipeline, where a limited budget for obtaining ground truth annotations from domain experts is available when model uncertainty is high. Our experiments show that conformalizing SoilNet leads to more efficient annotation in regression tasks and comparable performance scores in classification tasks under the same annotation budget when tested against its non-conformal counterpart. All code and experiments can be found in our repository: this https URL 

**Abstract (ZH)**: ä¸ç¡®å®šæ€§é‡åŒ–å¯¹äºäººæœºåä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºäººç±»ä»£ç†å¾€å¾€ä¼šæ ¹æ®æœºå™¨åŒä¼´çš„ä¿¡å¿ƒè°ƒæ•´å…¶å†³ç­–ã€‚å› æ­¤ï¼Œå¯é æ ¡å‡†çš„æ¨¡å‹ä¸ç¡®å®šæ€§èƒ½å¤Ÿä¿ƒè¿›æ›´æœ‰æ•ˆçš„åä½œã€é’ˆå¯¹æ€§çš„ä¸“å®¶å¹²é¢„ï¼Œå¹¶æ›´è´Ÿè´£ä»»åœ°ä½¿ç”¨æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚ä¸€è‡´æ€§é¢„æµ‹å·²æˆä¸ºä¸€ç§æˆç†Ÿçš„æ— æ¨¡å‹æ¡†æ¶ï¼Œå¯ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¸ç¡®å®šæ€§æ ¡å‡†ï¼Œæä¾›ç»Ÿè®¡ä¸Šæœ‰æ•ˆçš„ç½®ä¿¡åŒºé—´ä¼°è®¡ï¼Œé€‚ç”¨äºå›å½’å’Œåˆ†ç±»ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€è‡´æ€§é¢„æµ‹åº”ç”¨äºSoilNetï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡æ€å¤šä»»åŠ¡æ¨¡å‹ï¼Œç”¨äºæè¿°åœŸå£¤å‰–é¢ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ¨¡æ‹Ÿçš„äººæœºç¯æ³¨é‡Špipelineï¼Œåœ¨æ¨¡å‹ä¸ç¡®å®šæ€§é«˜æ—¶ï¼Œå¯ç”¨çš„é¢†åŸŸä¸“å®¶ ground truth æ³¨é‡Šé¢„ç®—æœ‰é™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸€è‡´æ€§æ ¡å‡† SoilNet å¯ä»¥åœ¨å›å½’ä»»åŠ¡ä¸­æ›´é«˜æ•ˆåœ°è¿›è¡Œæ³¨é‡Šï¼Œå¹¶ä¸”åœ¨ç›¸åŒæ³¨é‡Šé¢„ç®—ä¸‹ï¼Œå…¶åˆ†ç±»ä»»åŠ¡çš„è¡¨ç°ä¸éä¸€è‡´æ€§æ ¡å‡†ç‰ˆæœ¬ç›¸å½“ã€‚æ‰€æœ‰ä»£ç å’Œå®éªŒå¯ä»¥åœ¨æˆ‘ä»¬çš„ä»“åº“ä¸­æ‰¾åˆ°ï¼šthis https URL 

---
# Of-SemWat: High-payload text embedding for semantic watermarking of AI-generated images with arbitrary size 

**Title (ZH)**: Of-SemWat: é«˜è½½è·æ–‡æœ¬åµŒå…¥ç”¨äºä»»æ„å¤§å°AIç”Ÿæˆå›¾åƒçš„è¯­ä¹‰æ°´å°æŠ€æœ¯ 

**Authors**: Benedetta Tondi, Andrea Costanzo, Mauro Barni  

**Link**: [PDF](https://arxiv.org/pdf/2509.24823)  

**Abstract**: We propose a high-payload image watermarking method for textual embedding, where a semantic description of the image - which may also correspond to the input text prompt-, is embedded inside the image. In order to be able to robustly embed high payloads in large-scale images - such as those produced by modern AI generators - the proposed approach builds upon a traditional watermarking scheme that exploits orthogonal and turbo codes for improved robustness, and integrates frequency-domain embedding and perceptual masking techniques to enhance watermark imperceptibility. Experiments show that the proposed method is extremely robust against a wide variety of image processing, and the embedded text can be retrieved also after traditional and AI inpainting, permitting to unveil the semantic modification the image has undergone via image-text mismatch analysis. 

**Abstract (ZH)**: åŸºäºè¯­ä¹‰æè¿°çš„å¤§è½½è·å›¾åƒæ°´å°æ–¹æ³•ï¼šé’ˆå¯¹æ–‡æœ¬åµŒå…¥çš„é²æ£’æ€§å¢å¼º 

---
# RDD: Pareto Analysis of the Rate-Distortion-Distinguishability Trade-off 

**Title (ZH)**: RDDï¼šç‡-å¤±çœŸ-å¯åŒºåˆ†æ€§æƒè¡¡çš„å¸•ç´¯æ‰˜åˆ†æ 

**Authors**: Andriy Enttsel, Alex Marchioni, Andrea Zanellini, Mauro Mangia, Gianluca Setti, Riccardo Rovatti  

**Link**: [PDF](https://arxiv.org/pdf/2509.24805)  

**Abstract**: Extensive monitoring systems generate data that is usually compressed for network transmission. This compressed data might then be processed in the cloud for tasks such as anomaly detection. However, compression can potentially impair the detector's ability to distinguish between regular and irregular patterns due to information loss. Here we extend the information-theoretic framework introduced in [1] to simultaneously address the trade-off between the three features on which the effectiveness of the system depends: the effectiveness of compression, the amount of distortion it introduces, and the distinguishability between compressed normal signals and compressed anomalous signals. We leverage a Gaussian assumption to draw curves showing how moving on a Pareto surface helps administer such a trade-off better than simply relying on optimal rate-distortion compression and hoping that compressed signals can be distinguished from each other. 

**Abstract (ZH)**: å¹¿æ³›ç›‘æµ‹ç³»ç»Ÿç”Ÿæˆçš„æ•°æ®é€šå¸¸è¢«å‹ç¼©ä»¥ä¾›ç½‘ç»œä¼ è¾“ã€‚è¿™äº›å‹ç¼©æ•°æ®éšåå¯èƒ½åœ¨äº‘ç«¯å¤„ç†ä»¥è¿›è¡Œå¼‚å¸¸æ£€æµ‹ç­‰ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå‹ç¼©å¯èƒ½ä¼šç”±äºä¿¡æ¯ä¸¢å¤±è€Œå½±å“æ£€æµ‹å™¨åŒºåˆ†æ­£å¸¸å’Œå¼‚å¸¸æ¨¡å¼çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æ‰©å±•äº†åœ¨[1]ä¸­å¼•å…¥çš„ä¿¡æ¯è®ºæ¡†æ¶ï¼ŒåŒæ—¶å¤„ç†ç³»ç»Ÿæœ‰æ•ˆæ€§çš„ä¸‰ä¸ªç‰¹å¾ä¹‹é—´çš„æƒè¡¡ï¼šå‹ç¼©çš„æœ‰æ•ˆæ€§ã€å®ƒå¼•å…¥çš„å¤±çœŸé‡ä»¥åŠå‹ç¼©æ­£å¸¸ä¿¡å·å’Œå‹ç¼©å¼‚å¸¸ä¿¡å·ä¹‹é—´çš„å¯åŒºåˆ†æ€§ã€‚æˆ‘ä»¬åˆ©ç”¨é«˜æ–¯å‡è®¾ç»˜åˆ¶æ›²çº¿ï¼Œå±•ç¤ºåœ¨å¸•ç´¯æ‰˜æ›²é¢ä¸Šç§»åŠ¨å¦‚ä½•æ›´å¥½åœ°ç®¡ç†è¿™ç§æƒè¡¡ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¾èµ–æœ€ä¼˜ç‡å¤±çœŸå‹ç¼©å¹¶å¸Œæœ›å‹ç¼©ä¿¡å·èƒ½å¤Ÿå½¼æ­¤åŒºåˆ†ã€‚ 

---
# DSAT-HD: Dual-Stream Adaptive Transformer with Hybrid Decomposition for Multivariate Time Series Forecasting 

**Title (ZH)**: DSAT-HDï¼šåŒé‡æµè‡ªé€‚åº”å˜æ¢å™¨ç»“åˆæ··åˆåˆ†è§£çš„å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ 

**Authors**: Zixu Wang, Hongbin Dong, Xiaoping Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.24800)  

**Abstract**: Time series forecasting is crucial for various applications, such as weather, traffic, electricity, and energy predictions. Currently, common time series forecasting methods are based on Transformers. However, existing approaches primarily model limited time series or fixed scales, making it more challenging to capture diverse features cross different ranges. Additionally, traditional methods like STL for complex seasonality-trend decomposition require pre-specified seasonal periods and typically handle only single, fixed seasonality. We propose the Hybrid Decomposition Dual-Stream Adaptive Transformer (DSAT-HD), which integrates three key innovations to address the limitations of existing methods: 1) A hybrid decomposition mechanism combining EMA and Fourier decomposition with RevIN normalization, dynamically balancing seasonal and trend components through noise Top-k gating; 2) A multi-scale adaptive pathway leveraging a sparse allocator to route features to four parallel Transformer layers, followed by feature merging via a sparse combiner, enhanced by hybrid attention combining local CNNs and global interactions; 3) A dual-stream residual learning framework where CNN and MLP branches separately process seasonal and trend components, coordinated by a balanced loss function minimizing expert collaboration variance. Extensive experiments on nine datasets demonstrate that DSAT-HD outperforms existing methods overall and achieves state-of-the-art performance on some datasets. Notably, it also exhibits stronger generalization capabilities across various transfer scenarios. 

**Abstract (ZH)**: Hybrid Decomposition Dual-Stream Adaptive Transformer (DSAT-HD) for Time Series Forecasting 

---
# Sparse Autoencoders Make Audio Foundation Models more Explainable 

**Title (ZH)**: ç¨€ç–è‡ªç¼–ç å™¨ä½¿éŸ³é¢‘åŸºç¡€æ¨¡å‹æ›´å…·å¯è§£é‡Šæ€§ 

**Authors**: ThÃ©o Mariotte, Martin Lebourdais, Antonio AlmudÃ©var, Marie Tahon, Alfonso Ortega, Nicolas DuguÃ©  

**Link**: [PDF](https://arxiv.org/pdf/2509.24793)  

**Abstract**: Audio pretrained models are widely employed to solve various tasks in speech processing, sound event detection, or music information retrieval. However, the representations learned by these models are unclear, and their analysis mainly restricts to linear probing of the hidden representations. In this work, we explore the use of Sparse Autoencoders (SAEs) to analyze the hidden representations of pretrained models, focusing on a case study in singing technique classification. We first demonstrate that SAEs retain both information about the original representations and class labels, enabling their internal structure to provide insights into self-supervised learning systems. Furthermore, we show that SAEs enhance the disentanglement of vocal attributes, establishing them as an effective tool for identifying the underlying factors encoded in the representations. 

**Abstract (ZH)**: é¢„è®­ç»ƒæ¨¡å‹åœ¨è¯­éŸ³å¤„ç†ã€å£°æºæ£€æµ‹æˆ–éŸ³ä¹ä¿¡æ¯æ£€ç´¢ç­‰ä»»åŠ¡ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†è¿™äº›æ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨ç¤ºå°šä¸æ˜ç¡®ï¼Œå…¶åˆ†æä¸»è¦å±€é™äºéšè—è¡¨ç¤ºçš„çº¿æ€§æ¢æŸ¥ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢ä½¿ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰æ¥åˆ†æé¢„è®­ç»ƒæ¨¡å‹çš„éšè—è¡¨ç¤ºï¼Œå¹¶é›†ä¸­è®¨è®ºå…¶åœ¨æ­Œå”±æŠ€å·§åˆ†ç±»ä¸­çš„åº”ç”¨æ¡ˆä¾‹ã€‚æˆ‘ä»¬é¦–å…ˆè¯æ˜SAEsèƒ½å¤Ÿä¿ç•™åŸå§‹è¡¨ç¤ºå’Œç±»åˆ«æ ‡ç­¾çš„ä¿¡æ¯ï¼Œä½¿å…¶å®å†…ç»“æ„èƒ½å¤Ÿä¸ºç›‘ç£å­¦ä¹ ç³»ç»Ÿæä¾›æ´è§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†SAEsåœ¨åŒºåˆ†å£°å­¦å±æ€§æ–¹é¢çš„å¢å¼ºä½œç”¨ï¼Œç¡®ç«‹äº†å…¶ä½œä¸ºè¯†åˆ«è¡¨ç¤ºä¸­æ½œåœ¨å› å­çš„æœ‰æ•ˆå·¥å…·çš„åœ°ä½ã€‚ 

---
# Quantifying Generalisation in Imitation Learning 

**Title (ZH)**: é‡åŒ–æ¨¡ä»¿å­¦ä¹ ä¸­çš„æ³›åŒ–èƒ½åŠ› 

**Authors**: Nathan Gavenski, Odinaldo Rodrigues  

**Link**: [PDF](https://arxiv.org/pdf/2509.24784)  

**Abstract**: Imitation learning benchmarks often lack sufficient variation between training and evaluation, limiting meaningful generalisation assessment. We introduce Labyrinth, a benchmarking environment designed to test generalisation with precise control over structure, start and goal positions, and task complexity. It enables verifiably distinct training, evaluation, and test settings. Labyrinth provides a discrete, fully observable state space and known optimal actions, supporting interpretability and fine-grained evaluation. Its flexible setup allows targeted testing of generalisation factors and includes variants like partial observability, key-and-door tasks, and ice-floor hazards. By enabling controlled, reproducible experiments, Labyrinth advances the evaluation of generalisation in imitation learning and provides a valuable tool for developing more robust agents. 

**Abstract (ZH)**: æ¨¡ä»¿å­¦ä¹ åŸºå‡†å¾€å¾€ç¼ºä¹è®­ç»ƒå’Œè¯„ä¼°ä¹‹é—´çš„è¶³å¤Ÿå˜åŒ–ï¼Œé™åˆ¶äº†æœ‰æ„ä¹‰çš„æ³›åŒ–è¯„ä¼°ã€‚æˆ‘ä»¬å¼•å…¥äº†Labyrinthï¼Œä¸€ç§è®¾è®¡ç”¨äºæµ‹è¯•æ³›åŒ–çš„åŸºå‡†ç¯å¢ƒï¼Œå¯é€šè¿‡ç²¾ç¡®æ§åˆ¶ç»“æ„ã€èµ·å§‹å’Œç›®æ ‡ä½ç½®ä»¥åŠä»»åŠ¡å¤æ‚æ€§æ¥å®ç°ã€‚å®ƒå…è®¸éªŒè¯ä¸åŒçš„è®­ç»ƒã€è¯„ä¼°å’Œæµ‹è¯•è®¾ç½®ã€‚Labyrinthæä¾›äº†ä¸€ä¸ªç¦»æ•£ä¸”å®Œå…¨å¯è§‚æµ‹çš„çŠ¶æ€ç©ºé—´åŠå·²çŸ¥çš„æœ€ä¼˜åŠ¨ä½œï¼Œæ”¯æŒå¯è§£é‡Šæ€§å’Œç²¾ç»†è¯„ä¼°ã€‚å…¶çµæ´»çš„è®¾ç½®å…è®¸é’ˆå¯¹æ³›åŒ–å› ç´ è¿›è¡Œç›®æ ‡æµ‹è¯•ï¼Œå¹¶åŒ…æ‹¬è¯¸å¦‚éƒ¨åˆ†å¯è§‚æµ‹æ€§ã€é’¥åŒ™ä¸é—¨ä»»åŠ¡ä»¥åŠå†°é¢éšœç¢ç­‰å˜ä½“ã€‚é€šè¿‡å®ç°å¯æ§ä¸”å¯é‡å¤çš„å®éªŒï¼ŒLabyrinthæ¨è¿›äº†æ¨¡ä»¿å­¦ä¹ ä¸­æ³›åŒ–çš„è¯„ä¼°ï¼Œå¹¶æä¾›äº†ä¸€ç§å¼€å‘æ›´é«˜é²æ£’æ€§ä»£ç†çš„é‡è¦å·¥å…·ã€‚ 

---
# Surjective Independence of Causal Influences for Local Bayesian Network Structures 

**Title (ZH)**: å±€éƒ¨è´å¶æ–¯ç½‘ç»œç»“æ„ä¸Šçš„å› æœå½±å“çš„æ»¡å°„ç‹¬ç«‹æ€§ 

**Authors**: Kieran Drury, Martine J. Barons, Jim Q. Smith  

**Link**: [PDF](https://arxiv.org/pdf/2509.24759)  

**Abstract**: The very expressiveness of Bayesian networks can introduce fresh challenges due to the large number of relationships they often model. In many domains, it is thus often essential to supplement any available data with elicited expert judgements. This in turn leads to two key challenges: the cognitive burden of these judgements is often very high, and there are a very large number of judgements required to obtain a full probability model. We can mitigate both issues by introducing assumptions such as independence of causal influences (ICI) on the local structures throughout the network, restricting the parameter space of the model. However, the assumption of ICI is often unjustified and overly strong. In this paper, we introduce the surjective independence of causal influences (SICI) model which relaxes the ICI assumption and provides a more viable, practical alternative local structure model that facilitates efficient Bayesian network parameterisation. 

**Abstract (ZH)**: è´å¶æ–¯ç½‘ç»œçš„å¾ˆå¼ºçš„è¡¨è¾¾èƒ½åŠ›å› å®ƒä»¬é€šå¸¸å»ºæ¨¡çš„å…³ç³»æ•°é‡åºå¤§è€Œå¼•å…¥äº†æ–°çš„æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œåœ¨è®¸å¤šé¢†åŸŸä¸­ï¼Œå¸¸éœ€è¦è¡¥å……å¯ç”¨æ•°æ®ä»¥è·å–ä¸“å®¶åˆ¤æ–­ã€‚è¿™è¿›è€Œå¯¼è‡´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šè¿™äº›åˆ¤æ–­çš„è®¤çŸ¥è´Ÿæ‹…é€šå¸¸å¾ˆé«˜ï¼Œä¸”éœ€è¦å¤§é‡çš„åˆ¤æ–­ä»¥è·å¾—å®Œæ•´çš„æ¦‚ç‡æ¨¡å‹ã€‚é€šè¿‡å¼•å…¥å±€éƒ¨ç»“æ„ä¸­çš„å› æœå½±å“çš„æ»¡å°„ç‹¬ç«‹æ€§ï¼ˆSICIï¼‰å‡è®¾ï¼Œé™åˆ¶æ¨¡å‹çš„å‚æ•°ç©ºé—´ï¼Œæˆ‘ä»¬å¯ä»¥ç¼“è§£è¿™äº›é—®é¢˜ã€‚ç„¶è€Œï¼Œå› æœå½±å“ç‹¬ç«‹æ€§ï¼ˆICIï¼‰å‡è®¾å¾€å¾€ä¸åˆç†ä¸”è¿‡äºå¼ºç¡¬ã€‚æœ¬æ–‡å¼•å…¥äº†å› æœå½±å“çš„æ»¡å°„ç‹¬ç«‹æ€§ï¼ˆSICIï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ”¾æ¾äº†ICIå‡è®¾ï¼Œæä¾›äº†ä¸€ç§æ›´å¯è¡Œä¸”å®ç”¨çš„å±€éƒ¨ç»“æ„æ¨¡å‹ï¼Œæœ‰åŠ©äºé«˜æ•ˆåœ°è¿›è¡Œè´å¶æ–¯ç½‘ç»œå‚æ•°åŒ–ã€‚ 

---
# Robust Policy Expansion for Offline-to-Online RL under Diverse Data Corruption 

**Title (ZH)**: ç¦»çº¿åˆ°åœ¨çº¿RLåœ¨å¤šæ ·åŒ–æ•°æ®æ±¡æŸ“ä¸‹çš„é²æ£’ç­–ç•¥æ‰©å±• 

**Authors**: Longxiang He, Deheng Ye, Junbo Tan, Xueqian Wang, Li Shen  

**Link**: [PDF](https://arxiv.org/pdf/2509.24748)  

**Abstract**: Pretraining a policy on offline data followed by fine-tuning through online interactions, known as Offline-to-Online Reinforcement Learning (O2O RL), has emerged as a promising paradigm for real-world RL deployment. However, both offline datasets and online interactions in practical environments are often noisy or even maliciously corrupted, severely degrading the performance of O2O RL. Existing works primarily focus on mitigating the conservatism of offline policies via online exploration, while the robustness of O2O RL under data corruption, including states, actions, rewards, and dynamics, is still unexplored. In this work, we observe that data corruption induces heavy-tailed behavior in the policy, thereby substantially degrading the efficiency of online exploration. To address this issue, we incorporate Inverse Probability Weighted (IPW) into the online exploration policy to alleviate heavy-tailedness, and propose a novel, simple yet effective method termed $\textbf{RPEX}$: $\textbf{R}$obust $\textbf{P}$olicy $\textbf{EX}$pansion. Extensive experimental results on D4RL datasets demonstrate that RPEX achieves SOTA O2O performance across a wide range of data corruption scenarios. Code is available at $\href{this https URL}{this https URL}$. 

**Abstract (ZH)**: ç¦»çº¿æ•°æ®é¢„è®­ç»ƒç»“åˆåœ¨çº¿å¾®è°ƒçš„ç¦»çº¿åˆ°åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆO2O RLï¼‰åœ¨å®é™…éƒ¨ç½²ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ç”±äºå®é™…ç¯å¢ƒä¸­çš„ç¦»çº¿æ•°æ®é›†å’Œåœ¨çº¿äº¤äº’å¾€å¾€å­˜åœ¨å™ªéŸ³ç”šè‡³æ¶æ„ç¯¡æ”¹ï¼Œä¸¥é‡é™ä½äº†O2O RLçš„æ€§èƒ½ã€‚ç°æœ‰å·¥ä½œä¸»è¦å…³æ³¨é€šè¿‡åœ¨çº¿æ¢ç´¢å‡è½»ç¦»çº¿ç­–ç•¥çš„ä¿å®ˆæ€§ï¼Œè€Œæ•°æ®ç¯¡æ”¹å¯¹çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±å’ŒåŠ¨åŠ›å­¦çš„å½±å“ä¸‹çš„O2O RLé²æ£’æ€§å°šæœªè¢«ç ”ç©¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‘ç°æ•°æ®ç¯¡æ”¹å¯¼è‡´ç­–ç•¥è¡Œä¸ºæœä»åšå°¾åˆ†å¸ƒï¼Œæ˜¾è‘—é™ä½äº†åœ¨çº¿æ¢ç´¢çš„æ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨çº¿æ¢ç´¢ç­–ç•¥ä¸­å¼•å…¥é€†æ¦‚ç‡åŠ æƒï¼ˆIPWï¼‰ä»¥ç¼“è§£åšå°¾æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”æœ‰æ•ˆçš„æ–¹æ³•RPEXï¼šé²æ£’ç­–ç•¥æ‰©å±•ã€‚åœ¨D4RLæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒRPEXåœ¨å¤šç§æ•°æ®ç¯¡æ”¹åœºæ™¯ä¸­è¾¾åˆ°äº†SOTAçš„O2Oæ€§èƒ½ã€‚ä»£ç å¯åœ¨$\href{this https URL}{this https URL}$è·å–ã€‚ 

---
# Q-Net: Transferable Queue Length Estimation via Kalman-based Neural Networks 

**Title (ZH)**: Q-ç½‘ï¼šåŸºäºå¡å°”æ›¼æ»¤æ³¢çš„ç¥ç»ç½‘ç»œæ’é˜Ÿé•¿åº¦ä¼°è®¡ 

**Authors**: Ting Gao, Elvin Isufi, Winnie Daamen, Erik-Sander Smits, Serge Hoogendoorn  

**Link**: [PDF](https://arxiv.org/pdf/2509.24725)  

**Abstract**: Estimating queue lengths at signalized intersections remains a challenge in traffic management, especially under partially observed conditions where vehicle flows are not fully captured. This paper introduces Q-Net, a data-efficient and interpretable framework for queue length estimation that performs robustly even when traffic conservation assumptions are violated. Q-Net integrates two widely available and privacy-friendly data sources: (i) vehicle counts from loop detectors near stop lines, and (ii) aggregated floating car data (aFCD), which divides each road section into segments and provides segment-wise average speed measurements. These data sources often differ in spatial and temporal resolution, creating fusion challenges. Q-Net addresses this by employing a tailored state-space model and an AI-augmented Kalman filter, KalmanNet, which learns the Kalman gain from data without requiring prior knowledge of noise covariances or full system dynamics. We build on the vanilla KalmanNet pipeline to decouple measurement dimensionality from section length, enabling spatial transferability across road segments. Unlike black-box models, Q-Net maintains physical interpretability, with internal variables linked to real-world traffic dynamics. Evaluations on main roads in Rotterdam, the Netherlands, demonstrate that Q-Net outperforms baseline methods by over 60\% in Root Mean Square Error (RMSE), accurately tracking queue formation and dissipation while correcting aFCD-induced delays. Q-Net also demonstrates strong spatial and temporal transferability, enabling deployment without costly sensing infrastructure like cameras or radar. Additionally, we propose a real-time variant of Q-Net, highlighting its potential for integration into dynamic, queue-based traffic control systems. 

**Abstract (ZH)**: åŸºäºä¿¡å·äº¤å‰å£é˜Ÿåˆ—é•¿åº¦ä¼°è®¡çš„Q-Netæ¡†æ¶ï¼šä¸€ç§åœ¨éƒ¨åˆ†è§‚æµ‹æ¡ä»¶ä¸‹æ•°æ®é«˜æ•ˆä¸”å¯è§£é‡Šçš„æ–¹æ³• 

---
# Circuit-Aware Reward Training: A Mechanistic Framework for Longtail Robustness in RLHF 

**Title (ZH)**: ç”µè·¯æ„è¯†å¥–åŠ±è®­ç»ƒï¼šRLHFé•¿å°¾ç¨³å¥æ€§çš„æœ¬å¾æ¡†æ¶ 

**Authors**: Jing Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.24713)  

**Abstract**: Reinforcement Learning from Human Feedback (RLHF) reward models exhibit systematic failures on longtail distributions, leading to reward hacking and misalignment. We propose a mechanistic interpretability framework that identifies specialized neural circuits responsible for rare-event processing in reward models. Drawing from recent advances showing distributed specialization for rare tokens in language models\citep{liu2025no, liu2025emergent}, we hypothesize that reward models also develop functionally distinct circuits for longtail scenarios. Our theoretical framework establishes formal connections between circuit specialization, reward generalization bounds, and longtail performance. We introduce \textbf{Circuit-Aware Reward Training (CART)}, which uses circuit analysis to guide data augmentation, regularization, and ensemble strategies. This approach provides both theoretical insights into reward model failures and practical interventions for improving longtail robustness. 

**Abstract (ZH)**: åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰å¥–åŠ±æ¨¡å‹åœ¨é•¿å°¾åˆ†å¸ƒä¸Šè¡¨ç°å‡ºç³»ç»Ÿæ€§çš„å¤±è´¥ï¼Œå¯¼è‡´å¥–åŠ±ä½œå¼Šå’Œä¸ä¸€è‡´ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æœºåˆ¶å¯è§£é‡Šæ€§æ¡†æ¶ï¼Œè¯¥æ¡†æ¶è¯†åˆ«å‡ºè´Ÿè´£å¤„ç†ç¨€æœ‰äº‹ä»¶çš„ç‰¹æ®Šç¥ç»ç”µè·¯ã€‚å€Ÿé‰´è¿‘æœŸç ”ç©¶è¡¨æ˜è¯­è¨€æ¨¡å‹ä¸­å¯¹ç¨€æœ‰è¯å­˜åœ¨åˆ†å¸ƒå¼ä¸“ä¸šåŒ–ï¼ˆdistributed specialization for rare tokensï¼‰çš„ç°è±¡ï¼ˆ\citet{liu2025no, liu2025emergent}ï¼‰ï¼Œæˆ‘ä»¬å‡è®¾å¥–åŠ±æ¨¡å‹ä¹Ÿå‘å±•å‡ºäº†åŠŸèƒ½ä¸Šä¸åŒçš„ç”µè·¯æ¥å¤„ç†é•¿å°¾åœºæ™¯ã€‚æˆ‘ä»¬çš„ç†è®ºæ¡†æ¶å»ºç«‹äº†ç”µè·¯ä¸“ä¸šåŒ–ã€å¥–åŠ±æ³›åŒ–è¾¹ç•Œå’Œé•¿å°¾æ€§èƒ½ä¹‹é—´çš„æ­£å¼è”ç³»ã€‚æˆ‘ä»¬å¼•å…¥äº†**ç”µè·¯æ„ŸçŸ¥å¥–åŠ±è®­ç»ƒï¼ˆCARTï¼‰**æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ç”µè·¯åˆ†ææ¥æŒ‡å¯¼æ•°æ®å¢å¼ºã€æ­£åˆ™åŒ–å’Œé›†æˆç­–ç•¥ã€‚è¯¥æ–¹æ³•ä¸ºç†è§£å’Œæ”¹è¿›å¥–åŠ±æ¨¡å‹çš„é•¿å°¾ç¨³å¥æ€§æä¾›äº†ç†è®ºæ´è§å’Œå®é™…å¹²é¢„æªæ–½ã€‚ 

---
# CoTune: Co-evolutionary Configuration Tuning 

**Title (ZH)**: å…±è¿›åŒ–çš„é…ç½®è°ƒä¼˜ 

**Authors**: Gangda Xiong, Tao Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.24694)  

**Abstract**: To automatically tune configurations for the best possible system performance (e.g., runtime or throughput), much work has been focused on designing intelligent heuristics in a tuner. However, existing tuner designs have mostly ignored the presence of complex performance requirements (e.g., the latency shall ideally be 2 seconds), but simply assume that better performance is always more preferred. This would not only waste valuable information in a requirement but might also consume extensive resources to tune for a goal with little gain. Yet, prior studies have shown that simply incorporating the requirement as a tuning objective is problematic since the requirement might be too strict, harming convergence; or its highly diverse satisfactions might lead to premature convergence. In this paper, we propose CoTune, a tool that takes the information of a given target performance requirement into account through co-evolution. CoTune is unique in the sense that it creates an auxiliary performance requirement to be co-evolved with the configurations, which assists the target performance requirement when it becomes ineffective or even misleading, hence allowing the tuning to be guided by the requirement while being robust to its harm. Experiment results on 162 cases (nine systems and 18 requirements) reveal that CoTune considerably outperforms existing tuners, ranking as the best for 90% cases (against the 0%--35% for other tuners) with up to 2.9x overall improvements, while doing so under a much better efficiency. 

**Abstract (ZH)**: ä¸€ç§é€šè¿‡å…±è¿›åŒ–è€ƒè™‘ç›®æ ‡æ€§èƒ½éœ€æ±‚çš„è‡ªåŠ¨è°ƒä¼˜å·¥å…·ï¼šCoTune 

---
# Data-Driven Discrete Geofence Design Using Binary Quadratic Programming 

**Title (ZH)**: åŸºäºæ•°æ®é©±åŠ¨çš„ç¦»æ•£åœ°ç†å›´æ è®¾è®¡â€”â€”äºŒå…ƒäºŒæ¬¡è§„åˆ’æ–¹æ³• 

**Authors**: Keisuke Otaki, Akihisa Okada, Tadayoshi Matsumori, Hiroaki Yoshida  

**Link**: [PDF](https://arxiv.org/pdf/2509.24679)  

**Abstract**: Geofences have attracted significant attention in the design of spatial and virtual regions for managing and engaging spatiotemporal events. By using geofences to monitor human activity across their boundaries, content providers can create spatially triggered events that include notifications about points of interest within a geofence by pushing spatial information to the devices of users. Traditionally, geofences were hand-crafted by providers. In addition to the hand-crafted approach, recent advances in collecting human mobility data through mobile devices can accelerate the automatic and data-driven design of geofences, also known as the geofence design problem. Previous approaches assume circular shapes; thus, their flexibility is insufficient, and they can only handle geofence-based applications for large areas with coarse resolutions. A challenge with using circular geofences in urban and high-resolution areas is that they often overlap and fail to align with political district boundaries and road segments, such as one-way streets and median barriers. In this study, we address the problem of extracting arbitrary shapes as geofences from human mobility data to mitigate this problem. In our formulation, we cast the existing optimization problems for circular geofences to 0-1 integer programming problems to represent arbitrary shapes. Although 0-1 integer programming problems are computationally hard, formulating them as quadratic (unconstrained) binary optimization problems enables efficient approximation of optimal solutions, because this allows the use of specialized quadratic solvers, such as the quantum annealing, and other state-of-the-art algorithms. We then develop and compare different formulation methods to extract discrete geofences. We confirmed that our new modeling approach enables flexible geofence design. 

**Abstract (ZH)**: åœ°ç†å›´æ åœ¨ç©ºé—´å’Œè™šæ‹ŸåŒºåŸŸè®¾è®¡ä¸­çš„å…³æ³¨ç‚¹ï¼šåŸºäºäººç±»ç§»åŠ¨æ•°æ®çš„ä»»æ„å½¢çŠ¶åœ°ç†å›´æ æå– 

---
# Community detection robustness of graph neural networks 

**Title (ZH)**: å›¾ç¥ç»ç½‘ç»œçš„ç¤¾åŒºæ£€æµ‹é²æ£’æ€§ 

**Authors**: Jaidev Goel, Pablo Moriano, Ramakrishnan Kannan, Yulia R. Gel  

**Link**: [PDF](https://arxiv.org/pdf/2509.24662)  

**Abstract**: Graph neural networks (GNNs) are increasingly widely used for community detection in attributed networks. They combine structural topology with node attributes through message passing and pooling. However, their robustness or lack of thereof with respect to different perturbations and targeted attacks in conjunction with community detection tasks is not well understood. To shed light into latent mechanisms behind GNN sensitivity on community detection tasks, we conduct a systematic computational evaluation of six widely adopted GNN architectures: GCN, GAT, Graph- SAGE, DiffPool, MinCUT, and DMoN. The analysis covers three perturbation categories: node attribute manipulations, edge topology distortions, and adversarial attacks. We use element-centric similarity as the evaluation metric on synthetic benchmarks and real-world citation networks. Our findings indicate that supervised GNNs tend to achieve higher baseline accuracy, while unsupervised methods, particularly DMoN, maintain stronger resilience under targeted and adversarial pertur- bations. Furthermore, robustness appears to be strongly influenced by community strength, with well-defined communities reducing performance loss. Across all models, node attribute perturba- tions associated with targeted edge deletions and shift in attribute distributions tend to cause the largest degradation in community recovery. These findings highlight important trade-offs between accuracy and robustness in GNN-based community detection and offer new insights into selecting architectures resilient to noise and adversarial attacks. 

**Abstract (ZH)**: å›¾ç¥ç»ç½‘ç»œåœ¨å±æ€§ç½‘ç»œç¤¾åŒºæ£€æµ‹ä¸­çš„é²æ£’æ€§ç ”ç©¶ï¼šåŸºäºå…­ç§å¹¿æ³›é‡‡ç”¨çš„GNNæ¶æ„çš„ç³»ç»Ÿè®¡ç®—è¯„ä¼° 

---
# Algorithms and data structures for automatic precision estimation of neural networks 

**Title (ZH)**: ç¥ç»ç½‘ç»œè‡ªåŠ¨ç²¾åº¦ä¼°è®¡çš„ç®—æ³•ä¸æ•°æ®ç»“æ„ 

**Authors**: Igor V. Netay  

**Link**: [PDF](https://arxiv.org/pdf/2509.24607)  

**Abstract**: We describe algorithms and data structures to extend a neural network library with automatic precision estimation for floating point computations. We also discuss conditions to make estimations exact and preserve high computation performance of neural networks training and inference. Numerical experiments show the consequences of significant precision loss for particular values such as inference, gradients and deviations from mathematically predicted behavior.
It turns out that almost any neural network accumulates computational inaccuracies. As a result, its behavior does not coincide with predicted by the mathematical model of neural network. This shows that tracking of computational inaccuracies is important for reliability of inference, training and interpretability of results. 

**Abstract (ZH)**: æˆ‘ä»¬æè¿°äº†ç®—æ³•å’Œæ•°æ®ç»“æ„ï¼Œä»¥æ‰©å±•ç¥ç»ç½‘ç»œåº“ï¼Œå¹¶å®ç°æµ®ç‚¹è®¡ç®—çš„è‡ªåŠ¨ç²¾åº¦ä¼°è®¡ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†ä½¿ä¼°è®¡ç²¾ç¡®å¹¶ä¿æŒç¥ç»ç½‘ç»œè®­ç»ƒå’Œæ¨ç†é«˜æ€§èƒ½çš„æ¡ä»¶ã€‚æ•°å€¼å®éªŒè¡¨æ˜ï¼Œå¯¹äºç‰¹å®šå€¼å¦‚æ¨ç†ã€æ¢¯åº¦å’Œæ•°å­¦é¢„æµ‹è¡Œä¸ºåå·®ï¼Œç²¾åº¦æŸå¤±ä¼šå¯¹ç»“æœäº§ç”Ÿæ˜¾è‘—å½±å“ã€‚äº‹å®ä¸Šï¼Œå‡ ä¹ä»»ä½•ç¥ç»ç½‘ç»œéƒ½ä¼šç´¯ç§¯è®¡ç®—ä¸å‡†ç¡®ï¼Œå¯¼è‡´å…¶è¡Œä¸ºä¸ç¥ç»ç½‘ç»œæ•°å­¦æ¨¡å‹çš„é¢„æµ‹ä¸ç¬¦ï¼Œè¿™è¡¨æ˜è·Ÿè¸ªè®¡ç®—ä¸å‡†ç¡®å¯¹äºæ¨ç†ã€è®­ç»ƒå¯é æ€§å’Œç»“æœå¯è§£é‡Šæ€§çš„é‡è¦æ€§ã€‚ 

---
# Bandits roaming Hilbert space 

**Title (ZH)**: æ¸¸èµ°äºå¸Œå°”ä¼¯ç‰¹ç©ºé—´çš„Bandits 

**Authors**: Josep Lumbreras  

**Link**: [PDF](https://arxiv.org/pdf/2509.24569)  

**Abstract**: This thesis studies the exploration and exploitation trade-off in online learning of properties of quantum states using multi-armed bandits. Given streaming access to an unknown quantum state, in each round we select an observable from a set of actions to maximize its expectation value. Using past information, we refine actions to minimize regret; the cumulative gap between current reward and the maximum possible. We derive information-theoretic lower bounds and optimal strategies with matching upper bounds, showing regret typically scales as the square root of rounds. As an application, we reframe quantum state tomography to both learn the state efficiently and minimize measurement disturbance. For pure states and continuous actions, we achieve polylogarithmic regret using a sample-optimal algorithm based on a weighted online least squares estimator. The algorithm relies on the optimistic principle and controls the eigenvalues of the design matrix. We also apply our framework to quantum recommender systems and thermodynamic work extraction from unknown states. In this last setting, our results demonstrate an exponential advantage in work dissipation over tomography-based protocols. 

**Abstract (ZH)**: æœ¬è®ºæ–‡ç ”ç©¶äº†åœ¨å¤šè‡‚ bandit æ¡†æ¶ä¸‹å­¦ä¹ é‡å­çŠ¶æ€æ€§è´¨æ—¶åœ¨çº¿å­¦ä¹ ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨æƒè¡¡é—®é¢˜ã€‚é€šè¿‡é€è½®è®¿é—®æœªçŸ¥çš„é‡å­æ€ï¼Œæˆ‘ä»¬ä»ä¸€ç³»åˆ—å¯è§‚æµ‹é‡ä¸­é€‰æ‹©ä¸€ä¸ªä»¥æœ€å¤§åŒ–å…¶æœŸæœ›å€¼ã€‚åˆ©ç”¨è¿‡å¾€ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¸æ–­ç»†åŒ–è¡ŒåŠ¨ä»¥æœ€å°åŒ–é—æ†¾ï¼›é—æ†¾å³å½“å‰å¥–åŠ±ä¸æœ€å¤§å¯èƒ½å¥–åŠ±ä¹‹é—´çš„ç´¯ç§¯å·®è·ã€‚æˆ‘ä»¬æ¨å¯¼äº†ä¿¡æ¯è®ºä¸‹çš„ä¸‹ç•Œï¼Œå¹¶ç»™å‡ºäº†åŒ¹é…çš„ä¸Šç•Œæœ€ä¼˜ç­–ç•¥ï¼Œè¡¨æ˜é—æ†¾é€šå¸¸éšè½®æ¬¡å¹³æ–¹æ ¹å¢é•¿ã€‚ä½œä¸ºä¸€ç§åº”ç”¨ï¼Œæˆ‘ä»¬å°†é‡å­æ€ tomography é—®é¢˜é‡æ–°å®šæ¡†ï¼Œä»¥é«˜æ•ˆå­¦ä¹ é‡å­æ€å¹¶æœ€å°åŒ–æµ‹é‡æ‰°åŠ¨ã€‚å¯¹äºçº¯æ€å’Œè¿ç»­è¡ŒåŠ¨ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºåŠ æƒåœ¨çº¿æœ€å°äºŒä¹˜ä¼°è®¡å™¨çš„æ ·æœ¬æœ€ä¼˜ç®—æ³•å®ç°äº†å¤šé¡¹å¼å¯¹æ•°é—æ†¾ã€‚è¯¥ç®—æ³•ä¾é ä¹è§‚åŸåˆ™ï¼Œå¹¶æ§åˆ¶è®¾è®¡çŸ©é˜µçš„ç‰¹å¾å€¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†è¯¥æ¡†æ¶åº”ç”¨äºé‡å­æ¨èç³»ç»Ÿï¼Œå¹¶ä»æœªçŸ¥æ€ä¸­æå–çƒ­åŠ›å­¦å·¥ä½œã€‚åœ¨åè€…åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬çš„ç»“æœå±•ç¤ºäº†ä¸åŸºäº tomography çš„åè®®ç›¸æ¯”ï¼Œåœ¨å·¥ä½œè€—æ•£æ–¹é¢å…·æœ‰æŒ‡æ•°çº§ä¼˜åŠ¿ã€‚ 

---
# Short window attention enables long-term memorization 

**Title (ZH)**: çŸ­çª—æ³¨æ„åŠ›å®ç°é•¿æœŸè®°å¿† 

**Authors**: LoÃ¯c Cabannes, Maximilian Beck, Gergely Szilvasy, Matthijs Douze, Maria Lomeli, Jade Copet, Pierre-Emmanuel MazarÃ©, Gabriel Synnaeve, HervÃ© JÃ©gou  

**Link**: [PDF](https://arxiv.org/pdf/2509.24552)  

**Abstract**: Recent works show that hybrid architectures combining sliding window softmax attention layers with linear recurrent neural network (RNN) layers outperform both of these architectures taken separately. However, the impact of the window length and the interplay between softmax attention and linear RNN layers remain under-studied. In this work, we introduce SWAX, a hybrid architecture consisting of sliding-window attention and xLSTM linear RNN layers.
A counter-intuitive finding with SWAX is that larger sliding windows do not improve the long-context performance. In fact, short window attention encourages the model to better train the long-term memory of the xLSTM, by relying less on the softmax attention mechanism for long context-retrieval.
The issue with small sliding windows is that they are detrimental for short-context tasks, which could be solved with information from moderately larger sliding windows otherwise. Therefore, we train SWAX by stochastically changing the sliding window size, forcing the model to leverage both a longer context window and the xLSTM memory. SWAX trained with stochastic window sizes significantly outperforms regular window attention both on short and long-context problems. 

**Abstract (ZH)**: æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆæ»‘åŠ¨çª—å£softmaxæ³¨æ„åŠ›å±‚å’Œçº¿æ€§é€’å½’ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å±‚çš„æ··åˆæ¶æ„ä¼˜äºå•ç‹¬ä½¿ç”¨è¿™ä¸¤ç§æ¶æ„ã€‚ç„¶è€Œï¼Œæ»‘åŠ¨çª—å£é•¿åº¦çš„å½±å“ä»¥åŠsoftmaxæ³¨æ„åŠ›ä¸çº¿æ€§RNNå±‚ä¹‹é—´çš„äº’åŠ¨å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†SWAXï¼Œè¿™æ˜¯ä¸€ç§ç”±æ»‘åŠ¨çª—å£æ³¨æ„åŠ›å’ŒxLSTMçº¿æ€§RNNå±‚ç»„æˆçš„æ··åˆæ¶æ„ã€‚

SWAXçš„ä¸€ä¸ªå‡ºä¹æ„æ–™çš„å‘ç°æ˜¯ï¼Œè¾ƒå¤§çš„æ»‘åŠ¨çª—å£å¹¶ä¸æé«˜é•¿ä¸Šä¸‹æ–‡æ€§èƒ½ã€‚å®é™…ä¸Šï¼Œè¾ƒçŸ­çš„æ»‘åŠ¨çª—å£ä¼šä¿ƒä½¿æ¨¡å‹æ›´æœ‰æ•ˆåœ°è®­ç»ƒxLSTMçš„é•¿æœŸè®°å¿†ï¼Œå› ä¸ºå®ƒè¾ƒå°‘ä¾èµ–äºsoftmaxæ³¨æ„åŠ›æœºåˆ¶æ¥è¿›è¡Œé•¿ä¸Šä¸‹æ–‡æ£€ç´¢ã€‚

è¾ƒå°æ»‘åŠ¨çª—å£çš„é—®é¢˜åœ¨äºå®ƒä»¬å¯¹çŸ­ä¸Šä¸‹æ–‡ä»»åŠ¡æœ‰å®³ï¼Œè¿™å¯ä»¥é€šè¿‡è¾ƒå¤§ä½†é€‚åº¦çš„æ»‘åŠ¨çª—å£ä¿¡æ¯æ¥è§£å†³ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡éšæœºæ”¹å˜æ»‘åŠ¨çª—å£å¤§å°æ¥è®­ç»ƒSWAXï¼Œè¿«ä½¿æ¨¡å‹åˆ©ç”¨æ›´é•¿çš„ä¸Šä¸‹æ–‡çª—å£å’ŒxLSTMçš„è®°å¿†ã€‚éšæœºæ»‘åŠ¨çª—å£å¤§å°è®­ç»ƒçš„SWAXåœ¨çŸ­ä¸Šä¸‹æ–‡å’Œé•¿ä¸Šä¸‹æ–‡é—®é¢˜ä¸Šéƒ½æ˜¾è‘—ä¼˜äºå›ºå®šçª—å£æ³¨æ„åŠ›ã€‚ 

---
# CMT: Mid-Training for Efficient Learning of Consistency, Mean Flow, and Flow Map Models 

**Title (ZH)**: CMTï¼šä¸­é—´è®­ç»ƒä»¥é«˜æ•ˆå­¦ä¹ ä¸€è‡´æ€§å’Œæµå¹³å‡æ¨¡å‹ 

**Authors**: Zheyuan Hu, Chieh-Hsin Lai, Yuki Mitsufuji, Stefano Ermon  

**Link**: [PDF](https://arxiv.org/pdf/2509.24526)  

**Abstract**: Flow map models such as Consistency Models (CM) and Mean Flow (MF) enable few-step generation by learning the long jump of the ODE solution of diffusion models, yet training remains unstable, sensitive to hyperparameters, and costly. Initializing from a pre-trained diffusion model helps, but still requires converting infinitesimal steps into a long-jump map, leaving instability unresolved. We introduce mid-training, the first concept and practical method that inserts a lightweight intermediate stage between the (diffusion) pre-training and the final flow map training (i.e., post-training) for vision generation. Concretely, Consistency Mid-Training (CMT) is a compact and principled stage that trains a model to map points along a solver trajectory from a pre-trained model, starting from a prior sample, directly to the solver-generated clean sample. It yields a trajectory-consistent and stable initialization. This initializer outperforms random and diffusion-based baselines and enables fast, robust convergence without heuristics. Initializing post-training with CMT weights further simplifies flow map learning. Empirically, CMT achieves state of the art two step FIDs: 1.97 on CIFAR-10, 1.32 on ImageNet 64x64, and 1.84 on ImageNet 512x512, while using up to 98% less training data and GPU time, compared to CMs. On ImageNet 256x256, CMT reaches 1-step FID 3.34 while cutting total training time by about 50% compared to MF from scratch (FID 3.43). This establishes CMT as a principled, efficient, and general framework for training flow map models. 

**Abstract (ZH)**: Mid-Training for Stable and Efficient Flow Map Learning 

---
# Moravec's Paradox and Restrepo's Model: Limits of AGI Automation in Growth 

**Title (ZH)**: è«æ‹‰ç»´å…‹æ‚–è®ºä¸é›·æ–¯ç‰¹é›·æ³¢æ¨¡å‹ï¼šAGIè‡ªåŠ¨åŒ–åœ¨å¢é•¿é¢†åŸŸçš„å±€é™æ€§ 

**Authors**: Marc Bara  

**Link**: [PDF](https://arxiv.org/pdf/2509.24466)  

**Abstract**: This note extends Restrepo (2025)'s model of economic growth under AGI by incorporating Moravec's Paradox -the observation that tasks requiring sensorimotor skills remain computationally expensive relative to cognitive tasks. We partition the task space into cognitive and physical components with differential automation costs, allowing infinite costs for some physical bottlenecks. Our key result shows that when physical tasks constitute economic bottlenecks with sufficiently high (or infinite) computational requirements, the labor share of income converges to a positive constant in the finite-compute regime (rather than zero). This fundamentally alters the distributional implications of AGI while preserving the growth dynamics for cognitive-intensive economies. 

**Abstract (ZH)**: è¿™é¦–ç¬”è®°å°†Restrepo (2025)å…³äºAGIçš„ç»æµå¢é•¿æ¨¡å‹æ‰©å±•è‡³çº³å…¥äº†è«æ‹‰å…‹æ‚–è®ºï¼Œå³æ„Ÿè§‰è¿åŠ¨æŠ€èƒ½éœ€æ±‚çš„ä»»åŠ¡ç›¸æ¯”äºè®¤çŸ¥ä»»åŠ¡ä»å…·æœ‰ç›¸å¯¹è¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚æˆ‘ä»¬å°†ä»»åŠ¡ç©ºé—´åˆ’åˆ†ä¸ºè®¤çŸ¥å’Œç‰©ç†ç»„æˆéƒ¨åˆ†ï¼Œå¹¶å…è®¸ç‰©ç†ç“¶é¢ˆå…·æœ‰æ— é™çš„è‡ªåŠ¨åŒ–æˆæœ¬ã€‚æˆ‘ä»¬çš„ä¸»è¦ç»“æœè¡¨æ˜ï¼Œåœ¨ç‰©ç†ä»»åŠ¡æ„æˆå…·æœ‰è¶³å¤Ÿé«˜ï¼ˆæˆ–æ— é™ï¼‰è®¡ç®—è¦æ±‚çš„ç»æµç“¶é¢ˆæ—¶ï¼Œåœ¨æœ‰é™è®¡ç®—èƒ½åŠ›èŒƒå›´å†…ï¼Œæ”¶å…¥ä¸­çš„åŠ³åŠ¨ä»½é¢å°†è¶‹äºä¸€ä¸ªæ­£çš„å¸¸æ•°ï¼ˆè€Œä¸æ˜¯é›¶ï¼‰ã€‚è¿™ä¸€å‘ç°ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†AGIçš„åˆ†é…å½±å“ï¼ŒåŒæ—¶ä¿ç•™äº†å¯¹è®¤çŸ¥å¯†é›†å‹ç»æµçš„ç»æµå¢é•¿åŠ¨æ€ã€‚ 

---
# An Agent-Based Framework for Automated Higher-Voice Harmony Generation 

**Title (ZH)**: åŸºäºä»£ç†çš„è‡ªåŠ¨åŒ–é«˜éŸ³å’Œè°ç”Ÿæˆæ¡†æ¶ 

**Authors**: Nia D'Souza Ganapathy, Arul Selvamani Shaja  

**Link**: [PDF](https://arxiv.org/pdf/2509.24463)  

**Abstract**: The generation of musically coherent and aesthetically pleasing harmony remains a significant challenge in the field of algorithmic composition. This paper introduces an innovative Agentic AI-enabled Higher Harmony Music Generator, a multi-agent system designed to create harmony in a collaborative and modular fashion. Our framework comprises four specialized agents: a Music-Ingestion Agent for parsing and standardizing input musical scores; a Chord-Knowledge Agent, powered by a Chord-Former (Transformer model), to interpret and provide the constituent notes of complex chord symbols; a Harmony-Generation Agent, which utilizes a Harmony-GPT and a Rhythm-Net (RNN) to compose a melodically and rhythmically complementary harmony line; and an Audio-Production Agent that employs a GAN-based Symbolic-to-Audio Synthesizer to render the final symbolic output into high-fidelity audio. By delegating specific tasks to specialized agents, our system effectively mimics the collaborative process of human musicians. This modular, agent-based approach allows for robust data processing, deep theoretical understanding, creative composition, and realistic audio synthesis, culminating in a system capable of generating sophisticated and contextually appropriate higher-voice harmonies for given melodies. 

**Abstract (ZH)**: ç®—æ³•ä½œæ›²ä¸­å…·æœ‰éŸ³ä¹è¿è´¯æ€§å’Œå®¡ç¾å¸å¼•åŠ›å’Œå£°ç”Ÿæˆä¾ç„¶æ˜¯ä¸€é¡¹é‡è¦æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ›æ–°çš„Agentic AIé©±åŠ¨çš„é«˜å£°éƒ¨å’Œå£°ç”Ÿæˆå™¨ï¼Œè¿™æ˜¯ä¸€ç§å¤šä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨ä»¥åä½œå’Œæ¨¡å—åŒ–çš„æ–¹å¼ç”Ÿæˆå’Œå£°ã€‚è¯¥æ¡†æ¶åŒ…å«å››ä¸ªä¸“é—¨çš„ä»£ç†ï¼šä¸€ä¸ªéŸ³ä¹æ‘„å…¥ä»£ç†ï¼Œç”¨äºè§£æå’Œæ ‡å‡†åŒ–è¾“å…¥çš„éŸ³ä¹æ›²è°±ï¼›ä¸€ä¸ªç”±Chord-Formerï¼ˆå˜æ¢å™¨æ¨¡å‹ï¼‰é©±åŠ¨çš„å’Œå¼¦çŸ¥è¯†ä»£ç†ï¼Œä»¥è§£é‡Šå’Œæä¾›å¤æ‚çš„å’Œå¼¦ç¬¦å·çš„æ„æˆéŸ³ï¼›ä¸€ä¸ªå’Œå£°ç”Ÿæˆä»£ç†ï¼Œåˆ©ç”¨Harmony-GPTå’ŒRhythm-Netï¼ˆRNNï¼‰æ¥åˆ›ä½œæ—‹å¾‹å’ŒèŠ‚å¥ç›¸è¡¥çš„å’Œå£°çº¿ï¼›ä»¥åŠä¸€ä¸ªé‡‡ç”¨åŸºäºGANçš„ç¬¦å·åˆ°éŸ³é¢‘åˆæˆå™¨è¿›è¡ŒéŸ³é¢‘æ¸²æŸ“çš„éŸ³é¢‘ç”Ÿäº§ä»£ç†ã€‚é€šè¿‡å°†å…·ä½“ä»»åŠ¡å§”æ´¾ç»™ä¸“é—¨çš„ä»£ç†ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿæœ‰æ•ˆåœ°æ¨¡æ‹Ÿäº†äººç±»éŸ³ä¹å®¶çš„åä½œè¿‡ç¨‹ã€‚è¿™ç§æ¨¡å—åŒ–çš„ä»£ç†æ–¹æ³•å…è®¸ç¨³å¥çš„æ•°æ®å¤„ç†ã€æ·±å…¥çš„ç†è®ºç†è§£ã€åˆ›æ„æ€ç»´çš„ç»„æˆä»¥åŠç°å®ä¸»ä¹‰çš„éŸ³é¢‘åˆæˆï¼Œæœ€ç»ˆç”Ÿæˆç»™å®šæ—‹å¾‹çš„å¤æ‚ä¸”ä¸Šä¸‹æ–‡ç›¸å…³çš„é«˜å£°éƒ¨å’Œå£°ã€‚ 

---
# Multi-Item-Query Attention for Stable Sequential Recommendation 

**Title (ZH)**: å¤šé¡¹æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ä¸‹çš„ç¨³å®šåºåˆ—æ¨è 

**Authors**: Mingshi Xu, Haoren Zhu, Wilfred Siu Hung Ng  

**Link**: [PDF](https://arxiv.org/pdf/2509.24424)  

**Abstract**: The inherent instability and noise in user interaction data challenge sequential recommendation systems. Prevailing masked attention models, relying on a single query from the most recent item, are sensitive to this noise, reducing prediction reliability. We propose the Multi-Item-Query attention mechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn constructs multiple diverse query vectors from user interactions, effectively mitigating noise and improving consistency. It is designed for easy adoption as a drop-in replacement for existing single-query attention. Experiments show MIQ-Attn significantly improves performance on benchmark datasets. 

**Abstract (ZH)**: ç”¨æˆ·äº¤äº’æ•°æ®ä¸­çš„å›ºæœ‰ä¸ç¨³å®šæ€§å’Œå™ªå£°æŒ‘æˆ˜äº†åºåˆ—æ¨èç³»ç»Ÿã€‚ä¾èµ–äºæœ€è¿‘ä¸€é¡¹çš„å•ä¸€æŸ¥è¯¢çš„ç››è¡Œæ©ç æ³¨æ„åŠ›æ¨¡å‹å¯¹æ­¤å™ªå£°æ•æ„Ÿï¼Œé™ä½äº†é¢„æµ‹å¯é æ€§ã€‚æˆ‘ä»¬æå‡ºå¤šé¡¹æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼ˆMIQ-Attnï¼‰ä»¥å¢å¼ºæ¨¡å‹ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚MIQ-Attnä»ç”¨æˆ·äº¤äº’ä¸­æ„å»ºå¤šä¸ªå¤šæ ·åŒ–çš„æŸ¥è¯¢å‘é‡ï¼Œæœ‰æ•ˆå‡è½»å™ªå£°å¹¶æé«˜ä¸€è‡´æ€§ã€‚è¯¥æœºåˆ¶è®¾è®¡ä¸ºæ˜“äºæ›¿æ¢ç°æœ‰å•ä¸€æŸ¥è¯¢æ³¨æ„åŠ›çš„å³æ’å³ç”¨æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMIQ-Attnåœ¨åŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚ 

---
# CLQ: Cross-Layer Guided Orthogonal-based Quantization for Diffusion Transformers 

**Title (ZH)**: CLQ: ä¸åŒå±‚å¼•å¯¼æ­£äº¤åŸºé‡åŒ–æŠ€æœ¯ç”¨äºæ‰©æ•£å˜æ¢å™¨ 

**Authors**: Kai Liu, Shaoqiu Zhang, Linghe Kong, Yulun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.24416)  

**Abstract**: Visual generation quality has been greatly promoted with the rapid advances in diffusion transformers (DiTs), which is attributed to the scaling of model size and complexity. However, these attributions also hinder the practical deployment of DiTs on edge devices, limiting their development and application. Serve as an efficient model compression technique, model post-training quantization (PTQ) can reduce the memory consumption and speed up the inference, with inevitable performance degradation. To alleviate the degradation, we propose CLQ, a cross-layer guided orthogonal-based quantization method for DiTs. To be specific, CLQ consists of three key designs. First, we observe that the calibration data used by most of the PTQ methods can not honestly represent the distribution of the activations. Therefore, we propose cross-block calibration (CBC) to obtain accurate calibration data, with which the quantization can be better guided. Second, we propose orthogonal-based smoothing (OBS), which quantifies the outlier score of each channel and leverages block Hadamard matrix to smooth the outliers with negligible overhead. Third, we propose cross-layer parameter searching (CLPS) to search. We evaluate CLQ with both image generation and video generation models and successfully compress the model into W4A4 with negligible degradation in visual quality and metrics. CLQ achieves 3.98x memory saving and 3.95x speedup. Our code is available at \hyperlink{this https URL}{this https URL}. 

**Abstract (ZH)**: è§†è§‰ç”Ÿæˆè´¨é‡éšç€æ‰©æ•£å˜å‹å™¨ï¼ˆDiTsï¼‰çš„å¿«é€Ÿè¿›æ­¥å¾—åˆ°äº†æå¤§çš„æå‡ï¼Œè¿™å½’å› äºæ¨¡å‹è§„æ¨¡å’Œå¤æ‚æ€§çš„æ‰©å¤§ã€‚ç„¶è€Œï¼Œè¿™äº›å½’å› ä¹Ÿé˜»ç¢äº†DiTsåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®é™…éƒ¨ç½²ï¼Œé™åˆ¶äº†å…¶å‘å±•å’Œåº”ç”¨ã€‚ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼Œåè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰å¯ä»¥å‡å°‘å†…å­˜æ¶ˆè€—å¹¶åŠ é€Ÿæ¨ç†ï¼Œä½†ä¸å¯é¿å…åœ°ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ç§ä¸‹é™ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è·¨å±‚å¼•å¯¼æ­£äº¤åŸºé‡åŒ–æ–¹æ³•CLQï¼ˆCross-layer Guided Orthogonal-based Quantizationï¼‰ç”¨äºDiTsã€‚å…·ä½“è€Œè¨€ï¼ŒCLQ åŒ…å«ä¸‰ä¸ªå…³é”®è®¾è®¡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å‘ç°å¤§å¤šæ•°PTQæ–¹æ³•ä½¿ç”¨çš„æ ¡å‡†æ•°æ®ä¸èƒ½çœŸå®åœ°ä»£è¡¨æ¿€æ´»å€¼çš„åˆ†å¸ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†è·¨å—æ ¡å‡†ï¼ˆCBCï¼ŒCross-block Calibrationï¼‰ä»¥è·å¾—å‡†ç¡®çš„æ ¡å‡†æ•°æ®ï¼Œä»è€Œä½¿é‡åŒ–å¾—åˆ°æ›´å¥½çš„å¼•å¯¼ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºæ­£äº¤çš„å¹³æ»‘ï¼ˆOBSï¼ŒOrthogonal-based Smoothingï¼‰ï¼Œé‡åŒ–æ¯ä¸ªé€šé“çš„å¼‚å¸¸å€¼å¾—åˆ†ï¼Œå¹¶åˆ©ç”¨å—HadamardçŸ©é˜µå¹³æ»‘å¼‚å¸¸å€¼ï¼Œè€Œå‡ ä¹ä¸å¢åŠ å¼€é”€ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†è·¨å±‚å‚æ•°æœç´¢ï¼ˆCLPSï¼ŒCross-layer Parameter Searchingï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨å›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹è¯„ä¼°äº†CLQï¼Œå¹¶æˆåŠŸå°†æ¨¡å‹å‹ç¼©åˆ°W4A4ï¼ŒåŒæ—¶è§†è§‰è´¨é‡å’ŒæŒ‡æ ‡çš„ä¸‹é™å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚CLQ å®ç°äº†3.98å€çš„å†…å­˜èŠ‚çœå’Œ3.95å€çš„é€Ÿåº¦æå‡ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ \hyperlink{this https URL}{this https URL} è·å–ã€‚ 

---
# ScatterAD: Temporal-Topological Scattering Mechanism for Time Series Anomaly Detection 

**Title (ZH)**: ScatterADï¼šæ—¶é—´æ‹“æ‰‘æ•£å°„æœºåˆ¶åœ¨æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸­çš„åº”ç”¨ 

**Authors**: Tao Yin, Xiaohong Zhang, Shaochen Fu, Zhibin Zhang, Li Huang, Yiyuan Yang, Kaixiang Yang, Meng Yan  

**Link**: [PDF](https://arxiv.org/pdf/2509.24414)  

**Abstract**: One main challenge in time series anomaly detection for industrial IoT lies in the complex spatio-temporal couplings within multivariate data. However, traditional anomaly detection methods focus on modeling spatial or temporal dependencies independently, resulting in suboptimal representation learning and limited sensitivity to anomalous dispersion in high-dimensional spaces. In this work, we conduct an empirical analysis showing that both normal and anomalous samples tend to scatter in high-dimensional space, especially anomalous samples are markedly more dispersed. We formalize this dispersion phenomenon as scattering, quantified by the mean pairwise distance among sample representations, and leverage it as an inductive signal to enhance spatio-temporal anomaly detection. Technically, we propose ScatterAD to model representation scattering across temporal and topological dimensions. ScatterAD incorporates a topological encoder for capturing graph-structured scattering and a temporal encoder for constraining over-scattering through mean squared error minimization between neighboring time steps. We introduce a contrastive fusion mechanism to ensure the complementarity of the learned temporal and topological representations. Additionally, we theoretically show that maximizing the conditional mutual information between temporal and topological views improves cross-view consistency and enhances more discriminative representations. Extensive experiments on multiple public benchmarks show that ScatterAD achieves state-of-the-art performance on multivariate time series anomaly detection. Code is available at this repository: this https URL. 

**Abstract (ZH)**: å·¥ä¸šç‰©è”ç½‘ä¸­æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºå¤šå˜é‡æ•°æ®ä¸­çš„å¤æ‚ç©ºæ—¶è€¦åˆã€‚ä¼ ç»Ÿå¼‚å¸¸æ£€æµ‹æ–¹æ³•ç‹¬ç«‹å»ºæ¨¡ç©ºåŸŸæˆ–æ—¶åŸŸä¾èµ–æ€§ï¼Œå¯¼è‡´ä¸è¶³çš„è¡¨å¾å­¦ä¹ ï¼Œå¹¶åœ¨é«˜ç»´ç©ºé—´ä¸­å¯¹å¼‚å¸¸åˆ†æ•£çš„æ•æ„Ÿæ€§æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å®è¯åˆ†æè¡¨æ˜ï¼Œæ­£å¸¸æ ·æœ¬å’Œå¼‚å¸¸æ ·æœ¬éƒ½å€¾å‘äºåœ¨é«˜ç»´ç©ºé—´ä¸­åˆ†æ•£ï¼Œå°¤å…¶æ˜¯å¼‚å¸¸æ ·æœ¬çš„åˆ†æ•£ç¨‹åº¦æ›´ä¸ºæ˜¾è‘—ã€‚æˆ‘ä»¬å°†è¿™ç§åˆ†æ•£ç°è±¡å½¢å¼åŒ–ä¸ºæ•£å¸ƒï¼Œé€šè¿‡æ ·æœ¬è¡¨ç¤ºçš„å¹³å‡æˆå¯¹è·ç¦»æ¥é‡åŒ–ï¼Œå¹¶åˆ©ç”¨å…¶ä½œä¸ºå½’çº³ä¿¡å·ä»¥å¢å¼ºç©ºæ—¶å¼‚å¸¸æ£€æµ‹ã€‚æŠ€æœ¯ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ScatterADæ¥å»ºæ¨¡è·¨æ—¶é—´å’Œæ‹“æ‰‘ç»´åº¦çš„è¡¨å¾æ•£å¸ƒã€‚ScatterADç»“åˆäº†æ‹“æ‰‘ç¼–è§£ç å™¨æ¥æ•æ‰åŸºäºå›¾çš„æ•£å¸ƒï¼Œå¹¶é€šè¿‡é‚»è¿‘æ—¶é—´æ­¥ä¹‹é—´çš„å‡æ–¹è¯¯å·®æœ€å°åŒ–æ¥é™åˆ¶è¿‡åº¦æ•£å¸ƒã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¯¹æ¯”èåˆæœºåˆ¶ä»¥ç¡®ä¿å­¦ä¹ åˆ°çš„æ—¶é—´å’Œæ‹“æ‰‘è¡¨å¾çš„äº’è¡¥æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä»ç†è®ºä¸Šè¯æ˜ï¼Œæœ€å¤§åŒ–æ—¶é—´è§†å›¾å’Œæ‹“æ‰‘è§†å›¾çš„æ¡ä»¶äº’ä¿¡æ¯å¯ä»¥æé«˜è·¨è§†å›¾ä¸€è‡´æ€§å¹¶ç”Ÿæˆæ›´å…·åˆ¤åˆ«åŠ›çš„è¡¨ç¤ºã€‚åœ¨å¤šä¸ªå…¬å¼€åŸºå‡†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒScatterADåœ¨å¤šå˜é‡æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä»£ç å¯åœ¨ä»¥ä¸‹ä»“åº“è·å–ï¼šthis https URLã€‚ 

---
# Hybrid Layer-Wise ANN-SNN With Surrogate Spike Encoding-Decoding Structure 

**Title (ZH)**: æ··åˆå±‚-wise ANN-SNNé… Browse_surrogate çªå˜ç¼–ç -è§£ç ç»“æ„ 

**Authors**: Nhan T. Luu, Duong T. Luu, Pham Ngoc Nam, Truong Cong Thang  

**Link**: [PDF](https://arxiv.org/pdf/2509.24411)  

**Abstract**: Spiking Neural Networks (SNNs) have gained significant traction in both computational neuroscience and artificial intelligence for their potential in energy-efficient computing. In contrast, artificial neural networks (ANNs) excel at gradient-based optimization and high accuracy. This contrast has consequently led to a growing subfield of hybrid ANN-SNN research. However, existing hybrid approaches often rely on either a strict separation between ANN and SNN components or employ SNN-only encoders followed by ANN classifiers due to the constraints of non-differentiability of spike encoding functions, causing prior hybrid architectures to lack deep layer-wise cooperation during backpropagation. To address this gap, we propose a novel hybrid ANN-SNN framework that integrates layer-wise encode-decode SNN blocks within conventional ANN pipelines. Central to our method is the use of surrogate gradients for a bit-plane-based spike encoding function, enabling end-to-end differentiable training across ANN and SNN layers. This design achieves competitive accuracy with state-of-the-art pure ANN and SNN models while retaining the potential efficiency and temporal representation benefits of spiking computation. To the best of our knowledge, this is the first implementation of a surrogate gradient for bit plane coding specifically and spike encoder interface in general to be utilized in the context of hybrid ANN-SNN, successfully leading to a new class of hybrid models that pave new directions for future research. 

**Abstract (ZH)**: åŸºäºçªè§¦ç¥ç»ç½‘ç»œçš„æ–°å‹æ··åˆANN-SNNæ¡†æ¶ï¼šåŸºäºä½å¹³é¢çš„æ›¿ä»£æ¢¯åº¦çªè§¦ç¼–ç  

---
# The 2025 OpenAI Preparedness Framework does not guarantee any AI risk mitigation practices: a proof-of-concept for affordance analyses of AI safety policies 

**Title (ZH)**: 2025å¹´OpenAIå‡†å¤‡æ¡†æ¶å¹¶ä¸ä¿è¯ä»»ä½•AIé£é™©ç¼“è§£å®è·µï¼šAIå®‰å…¨æ”¿ç­–èƒ½åŠ›åˆ†æçš„å¯è¡Œæ€§ç ”ç©¶ 

**Authors**: Sam Coggins, Alex Saeri, Katherine A. Daniell, Lorenn P. Ruster, Jessie Liu, Jenny L. Davis  

**Link**: [PDF](https://arxiv.org/pdf/2509.24394)  

**Abstract**: Prominent AI companies are producing 'safety frameworks' as a type of voluntary self-governance. These statements purport to establish risk thresholds and safety procedures for the development and deployment of highly capable AI. Understanding which AI risks are covered and what actions are allowed, refused, demanded, encouraged, or discouraged by these statements is vital for assessing how these frameworks actually govern AI development and deployment. We draw on affordance theory to analyse the OpenAI 'Preparedness Framework Version 2' (April 2025) using the Mechanisms & Conditions model of affordances and the MIT AI Risk Repository. We find that this safety policy requests evaluation of a small minority of AI risks, encourages deployment of systems with 'Medium' capabilities for what OpenAI itself defines as 'severe harm' (potential for >1000 deaths or >$100B in damages), and allows OpenAI's CEO to deploy even more dangerous capabilities. These findings suggest that effective mitigation of AI risks requires more robust governance interventions beyond current industry self-regulation. Our affordance analysis provides a replicable method for evaluating what safety frameworks actually permit versus what they claim. 

**Abstract (ZH)**: prominenteçš„äººå·¥æ™ºèƒ½å…¬å¸æ­£åœ¨åˆ¶å®šâ€œå®‰å…¨æ¡†æ¶â€ä½œä¸ºä¸€ç§è‡ªæ„¿è‡ªæˆ‘æ²»ç†æ–¹å¼ã€‚è¿™äº›å£°æ˜æ—¨åœ¨ä¸ºé«˜åº¦å…·å¤‡èƒ½åŠ›çš„äººå·¥æ™ºèƒ½çš„ç ”å‘å’Œéƒ¨ç½²è®¾å®šé£é™©é˜ˆå€¼å’Œå®‰å…¨ç¨‹åºã€‚äº†è§£è¿™äº›å£°æ˜æ¶µç›–å“ªäº›äººå·¥æ™ºèƒ½é£é™©ä»¥åŠå…è®¸ã€æ‹’ç»ã€è¦æ±‚ã€é¼“åŠ±æˆ–åå¯¹å“ªäº›è¡ŒåŠ¨å¯¹äºè¯„ä¼°è¿™äº›æ¡†æ¶å®é™…ä¸Šå¦‚ä½•æ²»ç†äººå·¥æ™ºèƒ½çš„ç ”å‘å’Œéƒ¨ç½²è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å€Ÿé‰´äº†æœºä¼šç†è®ºï¼Œä½¿ç”¨æœºä¼šæœºåˆ¶ä¸æ¡ä»¶æ¨¡å‹å’ŒMITäººå·¥æ™ºèƒ½é£é™©ä»“åº“æ¥åˆ†æOpenAIâ€œå‡†å¤‡æ¡†æ¶ç‰ˆæœ¬2â€ï¼ˆ2025å¹´4æœˆï¼‰ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™ä¸€å®‰å…¨æ”¿ç­–è¦æ±‚å¯¹å°‘æ•°å‡ é¡¹äººå·¥æ™ºèƒ½é£é™©è¿›è¡Œè¯„ä¼°ï¼Œé¼“åŠ±éƒ¨ç½²â€œä¸­ç­‰â€èƒ½åŠ›çš„ç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿè¢«OpenAIè‡ªèº«å®šä¹‰ä¸ºâ€œä¸¥é‡ä¼¤å®³â€ï¼ˆæ½œåœ¨è‡´æ­»äººæ•°è¶…è¿‡1000äººæˆ–é€ æˆè¶…è¿‡1000äº¿ç¾å…ƒçš„æŸå®³ï¼‰ï¼Œå¹¶ä¸”å…è®¸OpenAIé¦–å¸­æ‰§è¡Œå®˜éƒ¨ç½²æ›´ä¸ºå±é™©çš„èƒ½åŠ›ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œæœ‰æ•ˆçš„é™ä½äººå·¥æ™ºèƒ½é£é™©éœ€è¦è¶…å‡ºå½“å‰è¡Œä¸šè‡ªæˆ‘ç›‘ç®¡çš„æ›´ç¨³å¥çš„æ²»ç†å¹²é¢„æªæ–½ã€‚æˆ‘ä»¬çš„æœºä¼šåˆ†ææä¾›äº†ä¸€ç§å¯å¤åˆ¶çš„æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°å®é™…å®‰å…¨æ¡†æ¶å…è®¸çš„å†…å®¹ä¸å®ƒä»¬æ‰€å£°ç§°çš„å†…å®¹ä¹‹é—´çš„å·®å¼‚ã€‚ 

---
# Towards Generalizable PDE Dynamics Forecasting via Physics-Guided Invariant Learning 

**Title (ZH)**: åŸºäºç‰©ç†å¼•å¯¼ä¸å˜æ€§å­¦ä¹ çš„æ³›åŒ–åå¾®åˆ†æ–¹ç¨‹åŠ¨åŠ›å­¦é¢„æµ‹ 

**Authors**: Siyang Li, Yize Chen, Yan Guo, Ming Huang, Hui Xiong  

**Link**: [PDF](https://arxiv.org/pdf/2509.24332)  

**Abstract**: Advanced deep learning-based approaches have been actively applied to forecast the spatiotemporal physical dynamics governed by partial differential equations (PDEs), which acts as a critical procedure in tackling many science and engineering problems. As real-world physical environments like PDE system parameters are always capricious, how to generalize across unseen out-of-distribution (OOD) forecasting scenarios using limited training data is of great importance. To bridge this barrier, existing methods focus on discovering domain-generalizable representations across various PDE dynamics trajectories. However, their zero-shot OOD generalization capability remains deficient, since extra test-time samples for domain-specific adaptation are still required. This is because the fundamental physical invariance in PDE dynamical systems are yet to be investigated or integrated. To this end, we first explicitly define a two-fold PDE invariance principle, which points out that ingredient operators and their composition relationships remain invariant across different domains and PDE system evolution. Next, to capture this two-fold PDE invariance, we propose a physics-guided invariant learning method termed iMOOE, featuring an Invariance-aligned Mixture Of Operator Expert architecture and a frequency-enriched invariant learning objective. Extensive experiments across simulated benchmarks and real-world applications validate iMOOE's superior in-distribution performance and zero-shot generalization capabilities on diverse OOD forecasting scenarios. 

**Abstract (ZH)**: åŸºäºæ·±åº¦å­¦ä¹ çš„å…ˆè¿›æ–¹æ³•å·²è¢«ç§¯æåº”ç”¨äºé¢„æŠ¥ç”±åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰æ”¯é…çš„æ—¶ç©ºç‰©ç†åŠ¨åŠ›å­¦ï¼Œè¿™æ˜¯è§£å†³è®¸å¤šç§‘å­¦ä¸å·¥ç¨‹é—®é¢˜çš„å…³é”®æ­¥éª¤ã€‚ç”±äºç°å®ä¸–ç•Œä¸­çš„ç‰©ç†ç¯å¢ƒå¦‚PDEç³»ç»Ÿå‚æ•°æ€»æ˜¯ä¸å¯é¢„æµ‹çš„ï¼Œå¦‚ä½•åœ¨æœ‰é™çš„è®­ç»ƒæ•°æ®ä¸‹æ³›åŒ–åˆ°æœªè§è¿‡çš„åˆ†å¸ƒå¤–ï¼ˆOODï¼‰é¢„æŠ¥åœºæ™¯å…·æœ‰é‡è¦æ„ä¹‰ã€‚ä¸ºè§£å†³è¿™ä¸€éšœç¢ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å‘ç°é€‚ç”¨äºå„ç§PDEåŠ¨åŠ›å­¦è½¨è¿¹çš„åŸŸæ³›åŒ–è¡¨ç¤ºã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„é›¶æ ·æœ¬åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›ä»ç„¶ä¸è¶³ï¼Œå› ä¸ºä»éœ€é¢å¤–çš„æµ‹è¯•æ—¶æ ·æœ¬è¿›è¡Œé¢†åŸŸç‰¹å¼‚æ€§é€‚åº”ã€‚è¿™æ˜¯å› ä¸ºPDEåŠ¨åŠ›ç³»ç»Ÿä¸­çš„åŸºæœ¬ç‰©ç†ä¸å˜æ€§å°šæœªè¢«ç ”ç©¶æˆ–é›†æˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆæ˜ç¡®å®šä¹‰äº†ä¸¤æ–¹é¢çš„PDEä¸å˜æ€§åŸç†ï¼ŒæŒ‡å‡ºæˆåˆ†ç®—å­åŠå…¶ç»„åˆå…³ç³»åœ¨ä¸åŒé¢†åŸŸå’ŒPDEç³»ç»Ÿæ¼”åŒ–ä¸­ä¿æŒä¸å˜ã€‚æ¥ä¸‹æ¥ï¼Œä¸ºæ•æ‰è¿™ç§ä¸¤æ–¹é¢çš„PDEä¸å˜æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‰©ç†å¼•å¯¼çš„ä¸å˜å­¦ä¹ æ–¹æ³•iMOOEï¼Œè¯¥æ–¹æ³•é‡‡ç”¨ä¸å˜æ€§å¯¹é½çš„ç®—å­ä¸“å®¶æ··åˆæ¶æ„å’Œé¢‘ç‡å¢å¼ºçš„ä¸å˜å­¦ä¹ ç›®æ ‡ã€‚åœ¨æ¨¡æ‹ŸåŸºå‡†å’Œå®é™…åº”ç”¨ä¸­çš„å¹¿æ³›å®éªŒéªŒè¯äº†iMOOEåœ¨ä¸åŒåˆ†å¸ƒå¤–é¢„æŠ¥åœºæ™¯ä¸­çš„ä¼˜è¶Šçš„å†…åˆ†å¸ƒæ€§èƒ½å’Œé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚ 

---
# TraitSpaces: Towards Interpretable Visual Creativity for Human-AI Co-Creation 

**Title (ZH)**: TraitSpaces: å‘å¯è§£é‡Šçš„äººå·¥æ™ºèƒ½è§†è§‰åˆ›é€ åŠ›æ–¹å‘çš„äººæœºå…±åˆ› 

**Authors**: Prerna Luthra  

**Link**: [PDF](https://arxiv.org/pdf/2509.24326)  

**Abstract**: We introduce a psychologically grounded and artist-informed framework for modeling visual creativity across four domains: Inner, Outer, Imaginative, and Moral Worlds. Drawing on interviews with practicing artists and theories from psychology, we define 12 traits that capture affective, symbolic, cultural, and ethical dimensions of this http URL 20k artworks from the SemArt dataset, we annotate images with GPT 4.1 using detailed, theory-aligned prompts, and evaluate the learnability of these traits from CLIP image embeddings. Traits such as Environmental Dialogicity and Redemptive Arc are predicted with high reliability ($R^2 \approx 0.64 - 0.68$), while others like Memory Imprint remain challenging, highlighting the limits of purely visual encoding. Beyond technical metrics, we visualize a "creativity trait-space" and illustrate how it can support interpretable, trait-aware co-creation - e.g., sliding along a Redemptive Arc axis to explore works of adversity and renewal. By linking cultural-aesthetic insights with computational modeling, our work aims not to reduce creativity to numbers, but to offer shared language and interpretable tools for artists, researchers, and AI systems to collaborate meaningfully. 

**Abstract (ZH)**: åŸºäºå¿ƒç†ä¾æ®å’Œè‰ºæœ¯å®¶æŒ‡å¯¼çš„è·¨é¢†åŸŸè§†è§‰åˆ›é€ åŠ›å»ºæ¨¡æ¡†æ¶ï¼šå†…å¤–æƒ³è±¡ä¸é“å¾·ä¸–ç•Œä¸­çš„æƒ…æ„Ÿã€è±¡å¾ã€æ–‡åŒ–ä¸ä¼¦ç†ç»´åº¦æ¢ç©¶ 

---
# A study of Universal ODE approaches to predicting soil organic carbon 

**Title (ZH)**: åŸºäºé€šç”¨ODEæ–¹æ³•é¢„æµ‹åœŸå£¤æœ‰æœºç¢³çš„ç ”ç©¶ 

**Authors**: Satyanarayana Raju G.V.V, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat  

**Link**: [PDF](https://arxiv.org/pdf/2509.24306)  

**Abstract**: Soil Organic Carbon (SOC) is a foundation of soil health and global climate resilience, yet its prediction remains difficult because of intricate physical, chemical, and biological processes. In this study, we explore a Scientific Machine Learning (SciML) framework built on Universal Differential Equations (UDEs) to forecast SOC dynamics across soil depth and time. UDEs blend mechanistic physics, such as advection diffusion transport, with neural networks that learn nonlinear microbial production and respiration. Using synthetic datasets, we systematically evaluated six experimental cases, progressing from clean, noise free benchmarks to stress tests with high (35%) multiplicative, spatially correlated noise. Our results highlight both the potential and limitations of the approach. In noise free and moderate noise settings, the UDE accurately reconstructed SOC dynamics. In clean terminal profile at 50 years (Case 4) achieved near perfect fidelity, with MSE = 1.6e-5, and R2 = 0.9999. Case 5, with 7% noise, remained robust (MSE = 3.4e-6, R2 = 0.99998), capturing depth wise SOC trends while tolerating realistic measurement uncertainty. In contrast, Case 3 (35% noise at t = 0) showed clear evidence of overfitting: the model reproduced noisy inputs with high accuracy but lost generalization against the clean truth (R2 = 0.94). Case 6 (35% noise at t = 50) collapsed toward overly smooth mean profiles, failing to capture depth wise variability and yielding negative R2, underscoring the limits of standard training under severe uncertainty. These findings suggest that UDEs are well suited for scalable, noise tolerant SOC forecasting, though advancing toward field deployment will require noise aware loss functions, probabilistic modelling, and tighter integration of microbial dynamics. 

**Abstract (ZH)**: åŸºäºé€šç”¨å¾®åˆ†æ–¹ç¨‹çš„ç§‘å­¦æœºå™¨å­¦ä¹ æ¡†æ¶åœ¨åœŸå£¤æœ‰æœºç¢³åŠ¨æ€é¢„æµ‹ä¸­çš„åº”ç”¨ï¼šå™ªå£°é²æ£’æ€§ç ”ç©¶ 

---
# Q-Mirror: Unlocking the Multi-Modal Potential of Scientific Text-Only QA Pairs 

**Title (ZH)**: Q-é•œåƒï¼šé‡Šæ”¾ç§‘å­¦æ–‡æœ¬å‹é—®ç­” pair çš„å¤šæ¨¡æ€æ½œåŠ› 

**Authors**: Junying Wang, Zicheng Zhang, Ye Shen, Yalun Wu, Yingji Liang, Yijin Guo, Farong Wen, Wenzhe Li, Xuezhi Zhao, Qi Jia, Guangtao Zhai  

**Link**: [PDF](https://arxiv.org/pdf/2509.24297)  

**Abstract**: High-quality, multi-modal benchmarks are crucial for advancing scientific reasoning in large models yet their manual creation is costly and unscalable. To address this bottleneck, we explore the potential for transforming Text-Only QA Pairs (TQAs) into high-quality Multi-Modal QA Pairs (MMQAs), which include three parts: 1) Task Definition \& Evaluation Rubric: We develop a TQA-to-MMQA framework and establish a comprehensive, multi-dimensional MMQA quality rubric that provides principles for the transformation. 2) Benchmark Construction: Then we construct two extensive benchmarks to rigorously evaluate state-of-the-art generation \& understanding models on the distinct tasks of MMQA generation \& MMQA quality evaluation. 3) Preliminary Solution: We develop an agentic system (Q-Mirror), which operationalizes our framework by integrating MMQA generation and evaluation into a closed loop for iterative refinement. Our experiments show that while state-of-the-art models can generate MMQAs, their outputs still leave substantial gaps, underscoring the need for reliable evaluation. We further demonstrate that top-tier understanding models align closely with human judgment in MMQA quality assessment. Leveraging both insights, the Q-Mirror agent raises average scores from 78.90 to 85.22 and pass rates from 72\% to 95\%, offering a practical path to large-scale scientific benchmarks. 

**Abstract (ZH)**: é«˜è´¨é‡ã€å¤šæ¨¡æ€åŸºå‡†å¯¹äºå¤§å‹æ¨¡å‹ä¿ƒè¿›ç§‘å­¦æ¨ç†è‡³å…³é‡è¦ï¼Œä½†å…¶æ‰‹åŠ¨åˆ›å»ºæˆæœ¬é«˜æ˜‚ä¸”ä¸å¯æ‰©å±•ã€‚ä¸ºåº”å¯¹è¿™ä¸€ç“¶é¢ˆï¼Œæˆ‘ä»¬æ¢ç´¢å°†æ–‡æœ¬_ONLY_é—®ç­”å¯¹ï¼ˆTQAsï¼‰è½¬æ¢ä¸ºé«˜è´¨é‡å¤šæ¨¡æ€é—®ç­”å¯¹ï¼ˆMMQAsï¼‰çš„æ½œåŠ›ï¼ŒMMQAsåŒ…æ‹¬ä¸‰ä¸ªéƒ¨åˆ†ï¼š1ï¼‰ä»»åŠ¡å®šä¹‰ä¸è¯„ä¼°å‡†åˆ™ï¼šæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªTQA-to-MMQAæ¡†æ¶ï¼Œå¹¶å»ºç«‹äº†å…¨é¢çš„å¤šç»´åº¦MMQAè´¨é‡è¯„ä¼°å‡†åˆ™ï¼Œæä¾›äº†è½¬æ¢çš„åŸåˆ™ã€‚2ï¼‰åŸºå‡†å»ºè®¾ï¼šæ¥ä¸‹æ¥æˆ‘ä»¬æ„å»ºäº†ä¸¤ä¸ªå¹¿æ³›çš„åŸºå‡†ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°æœ€å…ˆè¿›çš„ç”Ÿæˆä¸ç†è§£æ¨¡å‹åœ¨å¤šæ¨¡æ€é—®ç­”ç”Ÿæˆä¸å¤šæ¨¡æ€é—®ç­”è´¨é‡è¯„ä¼°ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚3ï¼‰åˆæ­¥è§£å†³æ–¹æ¡ˆï¼šæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªè‡ªä¸»ç³»ç»Ÿï¼ˆQ-Mirrorï¼‰ï¼Œé€šè¿‡å°†å¤šæ¨¡æ€é—®ç­”ç”Ÿæˆä¸è¯„ä¼°é›†æˆåˆ°ä¸€ä¸ªé—­ç¯ä¸­è¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œå…·ä½“åŒ–äº†æˆ‘ä»¬çš„æ¡†æ¶ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡æœ€å…ˆè¿›çš„æ¨¡å‹èƒ½å¤Ÿç”ŸæˆMMQAsï¼Œä½†å…¶è¾“å‡ºä»ç„¶å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œå¼ºè°ƒäº†å¯é è¯„ä¼°çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†é¡¶çº§ç†è§£æ¨¡å‹åœ¨å¤šæ¨¡æ€é—®ç­”è´¨é‡è¯„ä¼°ä¸­ä¸äººç±»åˆ¤æ–­é«˜åº¦ä¸€è‡´ã€‚ç»“åˆè¿™äº›è§è§£ï¼ŒQ-Mirrorä»£ç†å°†å¹³å‡å¾—åˆ†ä»78.90æé«˜åˆ°85.22ï¼Œé€šè¿‡ç‡è¾¾åˆ°ä»72%æé«˜åˆ°95%ï¼Œæä¾›äº†ä¸€æ¡å¤§è§„æ¨¡ç§‘å­¦åŸºå‡†å»ºè®¾çš„å®ç”¨è·¯å¾„ã€‚ 

---
# LAMP-PRo: Label-aware Attention for Multi-label Prediction of DNA- and RNA-binding Proteins using Protein Language Models 

**Title (ZH)**: LAMP-PRoï¼šåŸºäºæ ‡ç­¾çš„æ³¨æ„åŠ›æœºåˆ¶ç”¨äºè›‹ç™½è´¨è¯­è¨€æ¨¡å‹é¢„æµ‹DNA-å’ŒRNAç»“åˆè›‹ç™½å¤šæ ‡ç­¾åˆ†ç±» 

**Authors**: Nimisha Ghosh, Dheeran Sankaran, Rahul Balakrishnan Adhi, Sharath S, Amrut Anand  

**Link**: [PDF](https://arxiv.org/pdf/2509.24262)  

**Abstract**: Identifying DNA- (DBPs) and RNA-binding proteins (RBPs) is crucial for the understanding of cell function, molecular interactions as well as regulatory functions. Owing to their high similarity, most of the existing approaches face challenges in differentiating between DBPs and RBPs leading to high cross-prediction errors. Moreover, identifying proteins which bind to both DNA and RNA (DRBPs) is also quite a challenging task. In this regard, we propose a novel framework viz. LAMP-PRo which is based on pre-trained protein language model (PLM), attention mechanisms and multi-label learning to mitigate these issues. First, pre-trained PLM such ESM-2 is used for embedding the protein sequences followed by convolutional neural network (CNN). Subsequently multi-head self-attention mechanism is applied for the contextual information while label-aware attention is used to compute class-specific representations by attending to the sequence in a way that is tailored to each label (DBP, RBP and non-NABP) in a multi-label setup. We have also included a novel cross-label attention mechanism to explicitly capture dependencies between DNA- and RNA-binding proteins, enabling more accurate prediction of DRBP. Finally, a linear layer followed by a sigmoid function are used for the final prediction. Extensive experiments are carried out to compare LAMP-PRo with the existing methods wherein the proposed model shows consistent competent performance. Furthermore, we also provide visualization to showcase model interpretability, highlighting which parts of the sequence are most relevant for a predicted label. The original datasets are available at this http URL\_MMC and the codes are available at this https URL. 

**Abstract (ZH)**: è¯†åˆ«DNA-ç»“åˆè›‹ç™½(DBPs)å’ŒRNAç»“åˆè›‹ç™½(RBPs)å¯¹äºç†è§£ç»†èƒåŠŸèƒ½ã€åˆ†å­äº’åŠ¨ä»¥åŠè°ƒæ§åŠŸèƒ½è‡³å…³é‡è¦ã€‚ç”±äºå®ƒä»¬çš„é«˜åº¦ç›¸ä¼¼æ€§ï¼Œå½“å‰å¤§å¤šæ•°æ–¹æ³•åœ¨åŒºåˆ†DBPså’ŒRBPsæ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¯¼è‡´é«˜äº¤å‰é¢„æµ‹è¯¯å·®ã€‚æ­¤å¤–ï¼Œè¯†åˆ«åŒæ—¶ç»“åˆDNAå’ŒRNAçš„åŒé‡ç»“åˆè›‹ç™½(DRBPs)ä¹Ÿæ˜¯ä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶LAMP-PRoï¼Œè¯¥æ¡†æ¶åŸºäºé¢„è®­ç»ƒè›‹ç™½è´¨è¯­è¨€æ¨¡å‹(PLM)ã€æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šæ ‡ç­¾å­¦ä¹ ï¼Œä»¥å‡è½»è¿™äº›é—®é¢˜ã€‚é¦–å…ˆï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„PLMå¦‚ESM-2åµŒå…¥è›‹ç™½è´¨åºåˆ—ï¼Œç„¶åé€šè¿‡å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ã€‚éšååº”ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶å¤„ç†ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒæ—¶ä½¿ç”¨æ ‡ç­¾æ„ŸçŸ¥æ³¨æ„åŠ›æ¥é€šè¿‡é’ˆå¯¹æ¯ä¸ªæ ‡ç­¾(DBPã€RBPå’ŒéNABP)ç‰¹åŒ–çš„åºåˆ—è®¡ç®—ç±»ç‰¹å®šè¡¨ç¤ºã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„è·¨æ ‡ç­¾æ³¨æ„åŠ›æœºåˆ¶ä»¥æ˜ç¡®æ•æ‰DNA-ç»“åˆè›‹ç™½å’ŒRNA-ç»“åˆè›‹ç™½ä¹‹é—´çš„ä¾èµ–æ€§ï¼Œä½¿DRBPçš„å‡†ç¡®é¢„æµ‹æ›´ä¸ºå¯èƒ½ã€‚æœ€åï¼Œä½¿ç”¨çº¿æ€§å±‚å’ŒSigmoidå‡½æ•°è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚åœ¨ä¸ç°æœ‰æ–¹æ³•çš„å¹¿æ³›å®éªŒæ¯”è¾ƒä¸­ï¼Œæå‡ºçš„æ¨¡å‹æ˜¾ç¤ºå‡ºä¸€è‡´çš„ç«äº‰æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†å¯è§†åŒ–ä»¥å±•ç¤ºæ¨¡å‹å¯è§£é‡Šæ€§ï¼Œçªå‡ºå“ªäº›åºåˆ—éƒ¨åˆ†å¯¹é¢„æµ‹æ ‡ç­¾æœ€ä¸ºç›¸å…³ã€‚åŸå§‹æ•°æ®é›†å¯åœ¨ä»¥ä¸‹é“¾æ¥ä¸‹è½½ï¼šthis http URL\_MMCï¼Œä»£ç å¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ï¼šthis https URLã€‚ 

---
# Uni-NTFM: A Unified Foundation Model for EEG Signal Representation Learning 

**Title (ZH)**: ç»Ÿä¸€çš„è„‘ç”µæ³¢ä¿¡å·è¡¨ç¤ºå­¦ä¹ åŸºç¡€æ¨¡å‹ï¼šUni-NTFM 

**Authors**: Zhisheng Chen, Yingwei Zhang, Qizhen Lan, Tianyu Liu, Huacan Wang, Yi Ding, Ziyu Jia, Ronghao Chen, Kun Wang, Xinliang Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.24222)  

**Abstract**: Foundation models pretrained on various and unlabeled data have demonstrated significant success in natural language and vision, but their application to electroencephalography (EEG) remains challenged due to the signal's unique properties. Existing brain foundation models that inherit architectures designed for text or images lead to three limitations in pre-training: 1) conflating time-domain waveform patterns with frequency-domain rhythmic features in a single processing stream, 2) ignoring the critical spatial topology of electrodes with different standards, and 3) reliance on the inflexible, dense network to process functionally distinct EEG patterns. To address these challenges, we introduce the Unified Neural Topological Foundation Model (Uni-NTFM), which is designed based on neuroscience principles to produce universal and interpretable representations. Uni-NTFM integrates three core innovations: 1) a decoupled architecture parallelly encodes time, frequency, and raw signal representations before performing cross-domain feature integration; 2) a topological embedding mechanism to unify electrodes from different international standards and generate structured input sequences for brain regions; and 3) a Mixture-of-Experts neural Transformer that efficiently scales model capacity by routing signal patterns to specialized subnetworks. The largest model, Uni-NTFM$_{large}$, has a record-breaking 1.9B parameters and was pretrained on over 28,000 hours of diverse EEG data via a dual-domain masked reconstruction objective. Uni-NTFM significantly outperforms existing task-specific methods and foundation models across nine distinct downstream tasks under both linear probing and fine-tuning settings, demonstrating a superior ability to learn universal representations of brain activity. 

**Abstract (ZH)**: åŸºäºç»Ÿä¸€ç¥ç»æ‹“æ‰‘åŸºç¡€æ¨¡å‹åœ¨è„‘ç”µä¿¡å·ä¸­çš„é€šç”¨å’Œå¯è§£é‡Šè¡¨ç¤º 

---
# Metamorphic Testing for Audio Content Moderation Software 

**Title (ZH)**: éŸ³é¢‘å†…å®¹å®¡æ ¸è½¯ä»¶çš„ metamorphic æµ‹è¯• 

**Authors**: Wenxuan Wang, Yongjiang Wu, Junyuan Zhang, Shuqing Li, Yun Peng, Wenting Chen, Shuai Wang, Michael R. Lyu  

**Link**: [PDF](https://arxiv.org/pdf/2509.24215)  

**Abstract**: The rapid growth of audio-centric platforms and applications such as WhatsApp and Twitter has transformed the way people communicate and share audio content in modern society. However, these platforms are increasingly misused to disseminate harmful audio content, such as hate speech, deceptive advertisements, and explicit material, which can have significant negative consequences (e.g., detrimental effects on mental health). In response, researchers and practitioners have been actively developing and deploying audio content moderation tools to tackle this issue. Despite these efforts, malicious actors can bypass moderation systems by making subtle alterations to audio content, such as modifying pitch or inserting noise. Moreover, the effectiveness of modern audio moderation tools against such adversarial inputs remains insufficiently studied. To address these challenges, we propose MTAM, a Metamorphic Testing framework for Audio content Moderation software. Specifically, we conduct a pilot study on 2000 audio clips and define 14 metamorphic relations across two perturbation categories: Audio Features-Based and Heuristic perturbations. MTAM applies these metamorphic relations to toxic audio content to generate test cases that remain harmful while being more likely to evade detection. In our evaluation, we employ MTAM to test five commercial textual content moderation software and an academic model against three kinds of toxic content. The results show that MTAM achieves up to 38.6%, 18.3%, 35.1%, 16.7%, and 51.1% error finding rates (EFR) when testing commercial moderation software provided by Gladia, Assembly AI, Baidu, Nextdata, and Tencent, respectively, and it obtains up to 45.7% EFR when testing the state-of-the-art algorithms from the academy. 

**Abstract (ZH)**: éŸ³é¢‘ä¸­å¿ƒå¹³å°å’Œåº”ç”¨ï¼ˆå¦‚WhatsAppå’ŒTwitterï¼‰çš„å¿«é€Ÿå¢é•¿å·²æ”¹å˜äººä»¬åœ¨ç°ä»£ç¤¾ä¼šä¸­è¿›è¡ŒéŸ³é¢‘å†…å®¹äº¤æµå’Œåˆ†äº«çš„æ–¹å¼ã€‚ç„¶è€Œï¼Œè¿™äº›å¹³å°æ­£è¶Šæ¥è¶Šå¤šåœ°è¢«æ»¥ç”¨ä»¥ä¼ æ’­æœ‰å®³éŸ³é¢‘å†…å®¹ï¼Œå¦‚ä»‡æ¨è¨€è®ºã€æ¬ºéª—æ€§å¹¿å‘Šå’Œéœ²éª¨ææ–™ï¼Œè¿™å¯èƒ½äº§ç”Ÿä¸¥é‡çš„è´Ÿé¢å½±å“ï¼ˆä¾‹å¦‚å¯¹å¿ƒç†å¥åº·é€ æˆæŸå®³ï¼‰ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶äººå‘˜å’Œå®è·µè€…æ­£åœ¨ç§¯æå¼€å‘å’Œéƒ¨ç½²éŸ³é¢‘å†…å®¹å®¡æ ¸å·¥å…·ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ¶æ„è¡Œä¸ºè€…å¯ä»¥é€šè¿‡å¯¹éŸ³é¢‘å†…å®¹è¿›è¡Œç»†å¾®ä¿®æ”¹ï¼ˆå¦‚ä¿®æ”¹éŸ³è°ƒæˆ–æ’å…¥å™ªéŸ³ï¼‰æ¥è§„é¿å®¡æ ¸ç³»ç»Ÿï¼Œè€Œä¸”ç°ä»£éŸ³é¢‘å®¡æ ¸å·¥å…·å¯¹è¿™äº›å¯¹æŠ—æ€§è¾“å…¥çš„æœ‰æ•ˆæ€§ç ”ç©¶ä»ä¸å¤Ÿå……åˆ†ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºMTAMçš„éŸ³é¢‘å†…å®¹å®¡æ ¸è½¯ä»¶çš„å˜å½¢æµ‹è¯•æ¡†æ¶ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åœ¨2000ä¸ªéŸ³é¢‘ç‰‡æ®µä¸Šè¿›è¡Œè¯•ç‚¹ç ”ç©¶ï¼Œå¹¶å®šä¹‰äº†è·¨è¶Šä¸¤ç±»æ‰°åŠ¨åˆ†ç±»ï¼ˆåŸºäºéŸ³é¢‘ç‰¹å¾å’Œå¯å‘å¼æ‰°åŠ¨ï¼‰çš„14ç§å˜å½¢å…³ç³»ã€‚MTAMåº”ç”¨è¿™äº›å˜å½¢å…³ç³»å¯¹æœ‰æ¯’éŸ³é¢‘å†…å®¹è¿›è¡Œæµ‹è¯•ï¼Œç”Ÿæˆæ›´æœ‰å¯èƒ½è§„é¿æ£€æµ‹ä½†ä»ä¿æŒæœ‰å®³æ€§çš„æµ‹è¯•æ¡ˆä¾‹ã€‚åœ¨è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨MTAMå¯¹äº”æ¬¾å•†ç”¨æ–‡æœ¬å†…å®¹å®¡æ ¸è½¯ä»¶å’Œä¸€æ¬¾å­¦æœ¯æ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ï¼Œé’ˆå¯¹ä¸‰ç§ç±»å‹çš„æœ‰æ¯’å†…å®¹ã€‚ç»“æœæ˜¾ç¤ºï¼ŒMTAMåˆ†åˆ«åœ¨ç”±Gladiaã€Assembly AIã€Baiduã€Nextdataå’ŒTencentæä¾›çš„å•†ä¸šå®¡æ ¸è½¯ä»¶ä¸­å®ç°äº†å¤šè¾¾38.6%ã€18.3%ã€35.1%ã€16.7%å’Œ51.1%çš„é”™è¯¯å‘ç°ç‡ï¼ˆEFRï¼‰ï¼Œå¹¶åœ¨å­¦æœ¯ç•Œçš„æœ€æ–°ç®—æ³•æµ‹è¯•ä¸­å®ç°äº†é«˜è¾¾45.7%çš„é”™è¯¯å‘ç°ç‡ã€‚ 

---
# ASTROCO: Self-Supervised Conformer-Style Transformers for Light-Curve Embeddings 

**Title (ZH)**: ASTROCO: è‡ªç›‘ç£Conformeré£æ ¼å˜æ¢å™¨åŠå…¶åœ¨å…‰å˜æ›²çº¿åµŒå…¥ä¸­çš„åº”ç”¨ 

**Authors**: Antony Tan, Pavlos Protopapas, Martina CÃ¡diz-Leyton, Guillermo Cabrera-Vives, Cristobal Donoso-Oliva, Ignacio Becker  

**Link**: [PDF](https://arxiv.org/pdf/2509.24134)  

**Abstract**: We present AstroCo, a Conformer-style encoder for irregular stellar light curves. By combining attention with depthwise convolutions and gating, AstroCo captures both global dependencies and local features. On MACHO R-band, AstroCo outperforms Astromer v1 and v2, yielding 70 percent and 61 percent lower error respectively and a relative macro-F1 gain of about 7 percent, while producing embeddings that transfer effectively to few-shot classification. These results highlight AstroCo's potential as a strong and label-efficient foundation for time-domain astronomy. 

**Abstract (ZH)**: AstroCoï¼šä¸€ç§é€‚ç”¨äºä¸è§„åˆ™æ’æ˜Ÿå…‰æ›²çº¿çš„Conformer-styleç¼–ç å™¨ 

---
# PerfBench: Can Agents Resolve Real-World Performance Bugs? 

**Title (ZH)**: PerfBench: å‰æ²¿åŸºå‡†ï¼šæ™ºèƒ½ä½“èƒ½è§£å†³çœŸå®ä¸–ç•Œçš„æ€§èƒ½ bug å—ï¼Ÿ 

**Authors**: Spandan Garg, Roshanak Zilouchian Moghaddam  

**Link**: [PDF](https://arxiv.org/pdf/2509.24091)  

**Abstract**: Performance bugs are inefficiencies in software that waste computational resources without causing functional failures, making them particularly challenging to detect and fix. While recent advances in Software Engineering agents have shown promise in automated bug fixing, existing benchmarks primarily focus on functional correctness and fail to evaluate agents' abilities to identify and resolve non-functional issues like performance bugs. We introduce PerfBench, a benchmark comprising 81 real-world performance bug-fixing tasks from popular .NET repositories on GitHub. Unlike existing benchmarks that rely on pre-existing test suites, PerfBench features a novel evaluation harness that allows agents to generate their own performance benchmarks and validates fixes by comparing execution metrics collected for developer fix and agent fix. Each task in PerfBench is derived from actual developer fixes linked to performance-related issues, which are then verified by human experts, ensuring real-world relevance. Our evaluation reveals that current state-of-the-art coding agents struggle with performance optimization tasks, with baseline OpenHands agent achieving only a ~3% success rate on our benchmark. We develop OpenHands-Perf-Agent, which incorporates performance-aware tooling and instructions and achieves a ~20% success rate on the benchmark. We show that by ensuring the agent has proper instructions to benchmark its changes and tooling for benchmark output processing, we can improve the agent performance significantly, but room for improvement still remains. PerfBench provides a challenging test set for furthering the capabilities of agents in fixing performance issues. 

**Abstract (ZH)**: PerformanceBenchï¼šä¸€ä¸ªç”¨äºè¯„ä¼°è½¯ä»¶ä»£ç†è§£å†³æ€§èƒ½é—®é¢˜èƒ½åŠ›çš„æ–°åŸºå‡† 

---
# AQUAIR: A High-Resolution Indoor Environmental Quality Dataset for Smart Aquaculture Monitoring 

**Title (ZH)**: AQUAIR: ä¸€ç§é«˜åˆ†è¾¨ç‡å®¤å†…ç¯å¢ƒè´¨é‡æ•°æ®é›†ï¼Œç”¨äºæ™ºèƒ½æ°´äº§ç›‘æ§ 

**Authors**: Youssef Sabiri, Walid Houmaidi, Ouail El Maadi, Yousra Chtouki  

**Link**: [PDF](https://arxiv.org/pdf/2509.24069)  

**Abstract**: Smart aquaculture systems depend on rich environmental data streams to protect fish welfare, optimize feeding, and reduce energy use. Yet public datasets that describe the air surrounding indoor tanks remain scarce, limiting the development of forecasting and anomaly-detection tools that couple head-space conditions with water-quality dynamics. We therefore introduce AQUAIR, an open-access public dataset that logs six Indoor Environmental Quality (IEQ) variables--air temperature, relative humidity, carbon dioxide, total volatile organic compounds, PM2.5 and PM10--inside a fish aquaculture facility in Amghass, Azrou, Morocco. A single Awair HOME monitor sampled every five minutes from 14 October 2024 to 9 January 2025, producing more than 23,000 time-stamped observations that are fully quality-controlled and publicly archived on Figshare. We describe the sensor placement, ISO-compliant mounting height, calibration checks against reference instruments, and an open-source processing pipeline that normalizes timestamps, interpolates short gaps, and exports analysis-ready tables. Exploratory statistics show stable conditions (median CO2 = 758 ppm; PM2.5 = 12 micrograms/m3) with pronounced feeding-time peaks, offering rich structure for short-horizon forecasting, event detection, and sensor drift studies. AQUAIR thus fills a critical gap in smart aquaculture informatics and provides a reproducible benchmark for data-centric machine learning curricula and environmental sensing research focused on head-space dynamics in recirculating aquaculture systems. 

**Abstract (ZH)**: æ™ºèƒ½æ°´äº§å…»æ®–ç³»ç»Ÿä¾èµ–ä¸°å¯Œçš„ç¯å¢ƒæ•°æ®æµæ¥ä¿æŠ¤é±¼çš„ç¦åˆ©ã€ä¼˜åŒ–æŠ•å–‚å’Œå‡å°‘èƒ½è€—ã€‚ç„¶è€Œï¼Œæè¿°å®¤å†…æ°´æ§½å‘¨å›´ç©ºæ°”çš„å…¬å¼€æ•°æ®é›†ä»ç„¶ç¨€ç¼ºï¼Œé™åˆ¶äº†å°†ç©ºé—´æ¡ä»¶ä¸æ°´è´¨åŠ¨æ€è€¦åˆçš„é¢„æµ‹å’Œå¼‚å¸¸æ£€æµ‹å·¥å…·çš„å‘å±•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä»‹ç»äº†AQUAIRï¼Œä¸€ä¸ªå¼€æ”¾è®¿é—®çš„å…¬å¼€æ•°æ®é›†ï¼Œåœ¨æ‘©æ´›å“¥é˜¿å§†åŠ æ–¯ã€é˜¿ç¥–é²çš„é±¼å¡˜è®¾æ–½å†…è®°å½•å…­ç§å®¤å†…ç¯å¢ƒè´¨é‡ï¼ˆIEQï¼‰å˜é‡â€”â€”ç©ºæ°”æ¸©åº¦ã€ç›¸å¯¹æ¹¿åº¦ã€äºŒæ°§åŒ–ç¢³ã€æ€»æŒ¥å‘æ€§æœ‰æœºåŒ–åˆç‰©ã€PM2.5å’ŒPM10ã€‚ä»2024å¹´10æœˆ14æ—¥è‡³2025å¹´1æœˆ9æ—¥ï¼Œæ¯5åˆ†é’Ÿé‡‡æ ·ä¸€æ¬¡çš„å•ä¸ªAwair HOMEç›‘æµ‹å™¨ç”Ÿæˆäº†è¶…è¿‡23,000ä¸ªå¸¦æ—¶é—´æˆ³çš„è§‚æµ‹æ•°æ®ï¼Œå¹¶åœ¨Figshareä¸Šå®Œå…¨è´¨é‡æ§åˆ¶å¹¶å…¬å¼€å­˜æ¡£ã€‚æˆ‘ä»¬æè¿°äº†ä¼ æ„Ÿå™¨å¸ƒå±€ã€ISOåˆè§„çš„å®‰è£…é«˜åº¦ã€å‚è€ƒä»ªå™¨æ ¡å‡†æ£€æŸ¥ä»¥åŠå¼€æºå¤„ç†ç®¡é“ï¼Œè¯¥ç®¡é“è§„èŒƒæ—¶é—´æˆ³ã€æ’è¡¥çŸ­é—´éš™å¹¶å¯¼å‡ºåˆ†æå‡†å¤‡çš„è¡¨æ ¼ã€‚åˆæ­¥ç»Ÿè®¡ç»“æœæ˜¾ç¤ºç¨³å®šæ¡ä»¶ï¼ˆä¸­ä½æ•°äºŒæ°§åŒ–ç¢³=758 ppmï¼›PM2.5=12å¾®å…‹/ç«‹æ–¹ç±³ï¼‰ï¼Œåœ¨æŠ•å–‚æ—¶é—´å‡ºç°å³°å€¼ï¼Œä¸ºçŸ­æœŸé¢„æµ‹ã€äº‹ä»¶æ£€æµ‹å’Œä¼ æ„Ÿå™¨æ¼‚ç§»ç ”ç©¶æä¾›äº†ä¸°å¯Œçš„ç»“æ„ã€‚AQUAIRå› æ­¤å¡«è¡¥äº†æ™ºèƒ½æ°´äº§å…»æ®–ä¿¡æ¯æŠ€æœ¯ä¸­çš„ä¸€ä¸ªé‡è¦ç©ºç™½ï¼Œå¹¶ä¸ºåŸºäºæ•°æ®çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹å’Œå…³æ³¨å¾ªç¯æ°´äº§å…»æ®–ç³»ç»Ÿç©ºé—´åŠ¨æ€çš„ç¯å¢ƒä¼ æ„Ÿç ”ç©¶æä¾›äº†å¯é‡å¤çš„åŸºå‡†ã€‚ 

---
# In-Context Compositional Q-Learning for Offline Reinforcement Learning 

**Title (ZH)**: ä¸Šä¸‹æ–‡ä¾èµ–ç»„åˆQå­¦ä¹ åœ¨ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨ 

**Authors**: Qiushui Xu, Yuhao Huang, Yushu Jiang, Lei Song, Jinyu Wang, Wenliang Zheng, Jiang Bian  

**Link**: [PDF](https://arxiv.org/pdf/2509.24067)  

**Abstract**: Accurately estimating the Q-function is a central challenge in offline reinforcement learning. However, existing approaches often rely on a single global Q-function, which struggles to capture the compositional nature of tasks involving diverse subtasks. We propose In-context Compositional Q-Learning (\texttt{ICQL}), the first offline RL framework that formulates Q-learning as a contextual inference problem, using linear Transformers to adaptively infer local Q-functions from retrieved transitions without explicit subtask labels. Theoretically, we show that under two assumptions--linear approximability of the local Q-function and accurate weight inference from retrieved context--\texttt{ICQL} achieves bounded Q-function approximation error, and supports near-optimal policy extraction. Empirically, \texttt{ICQL} substantially improves performance in offline settings: improving performance in kitchen tasks by up to 16.4\%, and in Gym and Adroit tasks by up to 8.6\% and 6.3\%. These results highlight the underexplored potential of in-context learning for robust and compositional value estimation, positioning \texttt{ICQL} as a principled and effective framework for offline RL. 

**Abstract (ZH)**: å‡†ç¡®ä¼°è®¡Qå‡½æ•°æ˜¯ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå•ä¸€å…¨å±€Qå‡½æ•°ï¼Œéš¾ä»¥æ•æ‰åŒ…å«å¤šæ ·å­ä»»åŠ¡çš„ç»„åˆæ€§è´¨ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºIn-context Compositional Q-Learning (\texttt{ICQL})ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†Qå­¦ä¹ å½¢å¼åŒ–ä¸ºä¸Šä¸‹æ–‡æ¨ç†é—®é¢˜çš„ç¦»çº¿RLæ¡†æ¶ï¼Œé‡‡ç”¨çº¿æ€§Transformerä»æ£€ç´¢å¾—åˆ°çš„è½¬æ¢ä¸­è‡ªé€‚åº”åœ°æ¨æ–­å±€éƒ¨Qå‡½æ•°ï¼Œè€Œæ— éœ€æ˜¾å¼å­ä»»åŠ¡æ ‡ç­¾ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œåœ¨å±€éƒ¨Qå‡½æ•°çº¿æ€§å¯è¿‘ä¼¼å’Œä»æ£€ç´¢ä¸Šä¸‹æ–‡å‡†ç¡®æ¨æ–­æƒé‡çš„å‡è®¾ä¸‹ï¼Œ\texttt{ICQL}å®ç°æœ‰ç•ŒQå‡½æ•°è¿‘ä¼¼è¯¯å·®ï¼Œå¹¶æ”¯æŒæ¥è¿‘æœ€ä¼˜ç­–ç•¥æå–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç¦»çº¿è®¾ç½®ä¸­ï¼Œ\texttt{ICQL}æ˜¾è‘—æé«˜äº†æ€§èƒ½ï¼šåœ¨å¨æˆ¿ä»»åŠ¡ä¸­æé«˜äº†16.4%ï¼Œåœ¨Gymå’ŒAdroitä»»åŠ¡ä¸­åˆ†åˆ«æé«˜äº†8.6%å’Œ6.3%ã€‚è¿™äº›ç»“æœçªæ˜¾äº†ä¸Šä¸‹æ–‡å­¦ä¹ åœ¨é²æ£’å’Œç»„åˆä»·å€¼ä¼°è®¡æ–¹é¢çš„æœªå……åˆ†å¼€å‘çš„æ½œåŠ›ï¼Œå°†\texttt{ICQL}å®šä½ä¸ºåŸºäºåŸç†ä¸”æœ‰æ•ˆçš„ç¦»çº¿RLæ¡†æ¶ã€‚ 

---
# A Second-Order Perspective on Pruning at Initialization and Knowledge Transfer 

**Title (ZH)**: åˆå§‹åŒ–æ—¶çš„å‰ªæç¬¬äºŒ-orderè§†è§’ä¸çŸ¥è¯†è¿ç§» 

**Authors**: Leonardo Iurada, Beatrice Occhiena, Tatiana Tommasi  

**Link**: [PDF](https://arxiv.org/pdf/2509.24066)  

**Abstract**: The widespread availability of pre-trained vision models has enabled numerous deep learning applications through their transferable representations. However, their computational and storage costs often limit practical deployment. Pruning-at-Initialization has emerged as a promising approach to compress models before training, enabling efficient task-specific adaptation. While conventional wisdom suggests that effective pruning requires task-specific data, this creates a challenge when downstream tasks are unknown in advance. In this paper, we investigate how data influences the pruning of pre-trained vision models. Surprisingly, pruning on one task retains the model's zero-shot performance also on unseen tasks. Furthermore, fine-tuning these pruned models not only improves performance on original seen tasks but can recover held-out tasks' performance. We attribute this phenomenon to the favorable loss landscapes induced by extensive pre-training on large-scale datasets. 

**Abstract (ZH)**: é¢„è®­ç»ƒè§†è§‰æ¨¡å‹çš„å‰ªæåˆå§‹åŒ–ï¼šæ•°æ®çš„å½±å“åŠæ€§èƒ½æ¢å¤ 

---
# End-to-end Topographic Auditory Models Replicate Signatures of Human Auditory Cortex 

**Title (ZH)**: ç«¯åˆ°ç«¯æ‹“æ‰‘å¬è§‰æ¨¡å‹å†ç°äººç±»å¬è§‰çš®å±‚çš„ç‰¹å¾ 

**Authors**: Haider Al-Tahan, Mayukh Deb, Jenelle Feather, N. Apurva Ratan Murty  

**Link**: [PDF](https://arxiv.org/pdf/2509.24039)  

**Abstract**: The human auditory cortex is topographically organized. Neurons with similar response properties are spatially clustered, forming smooth maps for acoustic features such as frequency in early auditory areas, and modular regions selective for music and speech in higher-order cortex. Yet, evaluations for current computational models of auditory perception do not measure whether such topographic structure is present in a candidate model. Here, we show that cortical topography is not present in the previous best-performing models at predicting human auditory fMRI responses. To encourage the emergence of topographic organization, we adapt a cortical wiring-constraint loss originally designed for visual perception. The new class of topographic auditory models, TopoAudio, are trained to classify speech, and environmental sounds from cochleagram inputs, with an added constraint that nearby units on a 2D cortical sheet develop similar tuning. Despite these additional constraints, TopoAudio achieves high accuracy on benchmark tasks comparable to the unconstrained non-topographic baseline models. Further, TopoAudio predicts the fMRI responses in the brain as well as standard models, but unlike standard models, TopoAudio develops smooth, topographic maps for tonotopy and amplitude modulation (common properties of early auditory representation, as well as clustered response modules for music and speech (higher-order selectivity observed in the human auditory cortex). TopoAudio is the first end-to-end biologically grounded auditory model to exhibit emergent topography, and our results emphasize that a wiring-length constraint can serve as a general-purpose regularization tool to achieve biologically aligned representations. 

**Abstract (ZH)**: äººç±»å¬çš®å±‚æŒ‰æ‹“æ‰‘ç»“æ„ç»„ç»‡ã€‚å…·æœ‰ç›¸ä¼¼å“åº”æ€§è´¨çš„ç¥ç»å…ƒåœ¨ç©ºé—´ä¸Šèšç±»ï¼Œå½¢æˆæ—©æœŸå¬è§‰åŒºåŸŸä¸­é¢‘ç‡ç­‰å£°å­¦ç‰¹å¾çš„å¹³æ»‘åœ°å›¾ï¼Œå¹¶åœ¨é«˜çº§çš®å±‚ä¸­å½¢æˆå¯¹éŸ³ä¹å’Œè¯­è¨€å…·æœ‰æ¨¡å—åŒ–é€‰æ‹©æ€§çš„åŒºåŸŸã€‚ç„¶è€Œï¼Œå½“å‰å¬è§‰æ„ŸçŸ¥è®¡ç®—æ¨¡å‹çš„è¯„ä¼°å¹¶æœªè¡¡é‡å€™é€‰æ¨¡å‹ä¸­æ˜¯å¦å­˜åœ¨è¿™ç§æ‹“æ‰‘ç»“æ„ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä¹‹å‰çš„æœ€ä½³é¢„æµ‹äººç±»å¬è§‰fMRIååº”çš„æ¨¡å‹ä¸­ä¸å­˜åœ¨çš®å±‚æ‹“æ‰‘ç»“æ„ã€‚ä¸ºäº†é¼“åŠ±æ‹“æ‰‘ç»“æ„çš„å‡ºç°ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æœ€åˆä¸ºè§†è§‰æ„ŸçŸ¥è®¾è®¡çš„çš®å±‚è¿æ¥çº¦æŸæŸå¤±ã€‚æ–°çš„æ‹“æ‰‘å¬è§‰æ¨¡å‹ç±»TopoAudioè¢«è®­ç»ƒç”¨äºä»è€³èœ—å›¾è¾“å…¥åˆ†ç±»è¯­éŸ³å’Œç¯å¢ƒå£°éŸ³ï¼Œå¹¶ä¸”å¢åŠ äº†é™„è¿‘äºŒç»´çš®å±‚å•å…ƒå‘å±•ç›¸ä¼¼è°ƒè°çš„çº¦æŸã€‚å°½ç®¡å¢åŠ äº†è¿™äº›é¢å¤–çº¦æŸï¼ŒTopoAudioåœ¨åŸºå‡†ä»»åŠ¡ä¸Šçš„å‡†ç¡®åº¦ä¸æœªå—çº¦æŸçš„éæ‹“æ‰‘åŸºçº¿æ¨¡å‹ç›¸å½“ã€‚æ­¤å¤–ï¼ŒTopoAudioé¢„æµ‹å¤§è„‘çš„fMRIååº”ä¸æ ‡å‡†æ¨¡å‹ä¸€æ ·å‡†ç¡®ï¼Œä½†ä¸æ ‡å‡†æ¨¡å‹ä¸åŒçš„æ˜¯ï¼ŒTopoAudioå‘å±•äº†å¯¹äºéŸ³è°ƒå®šä½å’ŒæŒ¯å¹…è°ƒåˆ¶çš„å¹³æ»‘æ‹“æ‰‘å›¾ï¼ˆæ—©æœŸå¬è§‰è¡¨å¾çš„å¸¸è§å±æ€§ï¼‰ï¼Œä»¥åŠå¯¹éŸ³ä¹å’Œè¯­éŸ³å…·æœ‰èšç±»ååº”æ¨¡å—ï¼ˆäººç±»å¬è§‰çš®å±‚ä¸­è§‚å¯Ÿåˆ°çš„é«˜é˜¶é€‰æ‹©æ€§ï¼‰ã€‚TopoAudioæ˜¯ç¬¬ä¸€ä¸ªè¡¨ç°å‡ºæ–°å…´æ‹“æ‰‘ç»“æ„çš„ç«¯åˆ°ç«¯ç”Ÿç‰©åŸºç¡€å¬è§‰æ¨¡å‹ï¼Œæˆ‘ä»¬çš„ç»“æœå¼ºè°ƒï¼Œè¿æ¥é•¿åº¦çº¦æŸå¯ä»¥ä½œä¸ºä¸€ç§é€šç”¨æ­£åˆ™åŒ–å·¥å…·ï¼Œä»¥å®ç°ç”Ÿç‰©å¯¹é½çš„è¡¨ç¤ºã€‚ 

---
# GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning 

**Title (ZH)**: GPS-MTMï¼šä½¿ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ æ•æ‰GPSè½¨è¿¹ä¸­çš„æ­£å¸¸æ¨¡å¼ 

**Authors**: Umang Garg, Bowen Zhang, Anantanjit Subrahmanya, Chandrakanth Gudavalli, BS Manjunath  

**Link**: [PDF](https://arxiv.org/pdf/2509.24031)  

**Abstract**: Foundation models have driven remarkable progress in text, vision, and video understanding, and are now poised to unlock similar breakthroughs in trajectory modeling. We introduce the GPSMasked Trajectory Transformer (GPS-MTM), a foundation model for large-scale mobility data that captures patterns of normalcy in human movement. Unlike prior approaches that flatten trajectories into coordinate streams, GPS-MTM decomposes mobility into two complementary modalities: states (point-of-interest categories) and actions (agent transitions). Leveraging a bi-directional Transformer with a self-supervised masked modeling objective, the model reconstructs missing segments across modalities, enabling it to learn rich semantic correlations without manual labels. Across benchmark datasets, including Numosim-LA, Urban Anomalies, and Geolife, GPS-MTM consistently outperforms on downstream tasks such as trajectory infilling and next-stop prediction. Its advantages are most pronounced in dynamic tasks (inverse and forward dynamics), where contextual reasoning is critical. These results establish GPS-MTM as a robust foundation model for trajectory analytics, positioning mobility data as a first-class modality for large-scale representation learning. Code is released for further reference. 

**Abstract (ZH)**: GPSMasked è½¨è¿¹å˜æ¢å™¨ï¼šå¤§è§„æ¨¡ç§»åŠ¨æ•°æ®çš„åŸºç¡€æ¨¡å‹ 

---
# From Edge to HPC: Investigating Cross-Facility Data Streaming Architectures 

**Title (ZH)**: ä»è¾¹ç¼˜åˆ°è¶…ç®—ï¼šæ¢ç©¶è·¨è®¾æ–½æ•°æ®æµæ¶æ„ 

**Authors**: Anjus George, Michael Brim, Christopher Zimmer, David Rogers, Sarp Oral, Zach Mayes  

**Link**: [PDF](https://arxiv.org/pdf/2509.24030)  

**Abstract**: In this paper, we investigate three cross-facility data streaming architectures, Direct Streaming (DTS), Proxied Streaming (PRS), and Managed Service Streaming (MSS). We examine their architectural variations in data flow paths and deployment feasibility, and detail their implementation using the Data Streaming to HPC (DS2HPC) architectural framework and the SciStream memory-to-memory streaming toolkit on the production-grade Advanced Computing Ecosystem (ACE) infrastructure at Oak Ridge Leadership Computing Facility (OLCF). We present a workflow-specific evaluation of these architectures using three synthetic workloads derived from the streaming characteristics of scientific workflows. Through simulated experiments, we measure streaming throughput, round-trip time, and overhead under work sharing, work sharing with feedback, and broadcast and gather messaging patterns commonly found in AI-HPC communication motifs. Our study shows that DTS offers a minimal-hop path, resulting in higher throughput and lower latency, whereas MSS provides greater deployment feasibility and scalability across multiple users but incurs significant overhead. PRS lies in between, offering a scalable architecture whose performance matches DTS in most cases. 

**Abstract (ZH)**: æœ¬æ–‡ç ”ç©¶äº†ä¸‰ç§è·¨è®¾æ–½æ•°æ®æµæ¶æ„â€”â€”ç›´æ¥æµï¼ˆDTSï¼‰ã€ä»£ç†æµï¼ˆPRSï¼‰å’Œç®¡ç†æœåŠ¡æµï¼ˆMSSï¼‰ï¼Œæ¢è®¨äº†å®ƒä»¬åœ¨æ•°æ®æµè·¯å¾„å’Œéƒ¨ç½²å¯è¡Œæ€§æ–¹é¢çš„æ¶æ„å˜ä½“ï¼Œå¹¶ä½¿ç”¨Data Streaming to HPCï¼ˆDS2HPCï¼‰æ¶æ„æ¡†æ¶å’ŒSciStreamå†…å­˜åˆ°å†…å­˜æµä¼ è¾“å·¥å…·åŒ…åœ¨æ©¡æ ‘å²­é¢†å¯¼è®¡ç®—è®¾æ–½ï¼ˆOLCFï¼‰çš„ç”Ÿäº§çº§å…ˆè¿›è®¡ç®—ç”Ÿæ€ç³»ç»Ÿï¼ˆACEï¼‰åŸºç¡€è®¾æ–½ä¸Šè¯¦ç»†é˜è¿°äº†å…¶å®ç°ã€‚é€šè¿‡ç‰¹å®šå·¥ä½œæµçš„è¯„ä¼°ï¼Œä½¿ç”¨æºè‡ªç§‘å­¦å·¥ä½œæµæµç‰¹æ€§çš„äººå·¥åˆæˆå·¥ä½œè´Ÿè½½è¿›è¡Œè¯„ä¼°ã€‚é€šè¿‡æ¨¡æ‹Ÿå®éªŒï¼Œæµ‹é‡äº†å·¥ä½œåˆ†æ‹…ã€å¸¦æœ‰åé¦ˆçš„å·¥ä½œåˆ†æ‹…ã€å¹¿æ’­å’Œæ”¶é›†æ¶ˆæ¯æ¨¡å¼ä¸‹çš„æµä¼ è¾“ååé‡ã€å¾€è¿”æ—¶é—´å’Œå¼€é”€ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒDTSæä¾›äº†æœ€å°‘è·³è·ƒè·¯å¾„ï¼Œä»è€Œå®ç°æ›´é«˜çš„ååé‡å’Œæ›´ä½çš„å»¶è¿Ÿï¼Œè€ŒMSSæä¾›äº†æ›´å¥½çš„éƒ¨ç½²å¯è¡Œæ€§å’Œè·¨å¤šä¸ªç”¨æˆ·çš„å¤§è§„æ¨¡æ‰©å±•æ€§ï¼Œä½†ä¼šå¸¦æ¥æ˜¾è‘—çš„å¼€é”€ã€‚PRSä»‹äºä¸¤è€…ä¹‹é—´ï¼Œæä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ¶æ„ï¼Œå…¶æ€§èƒ½åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¸DTSåŒ¹é…ã€‚ 

---
# Easy Turn: Integrating Acoustic and Linguistic Modalities for Robust Turn-Taking in Full-Duplex Spoken Dialogue Systems 

**Title (ZH)**: Easy Turn: ç»“åˆå£°å­¦å’Œè¯­è¨€æ¨¡æ€å®ç°å…¨åŒå·¥ spoken å¯¹è¯ç³»ç»Ÿä¸­ç¨³å¥çš„è½®æ›¿ 

**Authors**: Guojian Li, Chengyou Wang, Hongfei Xue, Shuiyuan Wang, Dehui Gao, Zihan Zhang, Yuke Lin, Wenjie Li, Longshuai Xiao, Zhonghua Fu, Lei Xie  

**Link**: [PDF](https://arxiv.org/pdf/2509.23938)  

**Abstract**: Full-duplex interaction is crucial for natural human-machine communication, yet remains challenging as it requires robust turn-taking detection to decide when the system should speak, listen, or remain silent. Existing solutions either rely on dedicated turn-taking models, most of which are not open-sourced. The few available ones are limited by their large parameter size or by supporting only a single modality, such as acoustic or linguistic. Alternatively, some approaches finetune LLM backbones to enable full-duplex capability, but this requires large amounts of full-duplex data, which remain scarce in open-source form. To address these issues, we propose Easy Turn, an open-source, modular turn-taking detection model that integrates acoustic and linguistic bimodal information to predict four dialogue turn states: complete, incomplete, backchannel, and wait, accompanied by the release of Easy Turn trainset, a 1,145-hour speech dataset designed for training turn-taking detection models. Compared to existing open-source models like TEN Turn Detection and Smart Turn V2, our model achieves state-of-the-art turn-taking detection accuracy on our open-source Easy Turn testset. The data and model will be made publicly available on GitHub. 

**Abstract (ZH)**: å…¨åŒå·¥äº¤äº’å¯¹äºè‡ªç„¶çš„äººæœºé€šä¿¡è‡³å…³é‡è¦ï¼Œä½†ä¾ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒéœ€è¦ robust çš„è½®æµè½¬æ¢æ£€æµ‹ä»¥å†³å®šç³»ç»Ÿåº”è¯¥ä½•æ—¶è¯´è¯ã€è†å¬æˆ–ä¿æŒæ²‰é»˜ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆè¦ä¹ˆä¾èµ–ä¸“ç”¨çš„è½®æµè½¬æ¢æ¨¡å‹ï¼Œä½†å¤§å¤šæ•°æ¨¡å‹å¹¶æœªå¼€æºï¼›ç°æœ‰çš„å°‘æ•°å¼€æºæ¨¡å‹è¦ä¹ˆå‚æ•°é‡å¤§ï¼Œè¦ä¹ˆä»…æ”¯æŒå•ä¸€æ¨¡æ€ï¼Œå¦‚å£°å­¦æˆ–è¯­è¨€ã€‚æ­¤å¤–ï¼Œä¸€äº›æ–¹æ³•é€šè¿‡å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹æ¥å®ç°å…¨åŒå·¥èƒ½åŠ›ï¼Œä½†è¿™éœ€è¦å¤§é‡å…¨åŒå·¥æ•°æ®ï¼Œè€Œå¼€æºæ•°æ®ä»ç„¶ç¨€ç¼ºã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¼€æºä¸”æ¨¡å—åŒ–çš„è½®æµè½¬æ¢æ£€æµ‹æ¨¡å‹ Easy Turnï¼Œå®ƒç»“åˆäº†å£°å­¦å’Œè¯­è¨€çš„åŒæ¨¡æ€ä¿¡æ¯æ¥é¢„æµ‹å››ç§å¯¹è¯è½®æµçŠ¶æ€ï¼šå®Œæ•´ã€ä¸å®Œæ•´ã€å“åº”æ€§åé¦ˆå’Œç­‰å¾…ï¼Œå¹¶åŒæ—¶å‘å¸ƒäº† Easy Turn è®­ç»ƒé›†ï¼Œè¿™æ˜¯ä¸€ä¸ªè®¾è®¡ç”¨äºè®­ç»ƒè½®æµè½¬æ¢æ£€æµ‹æ¨¡å‹çš„ 1,145 å°æ—¶è¯­éŸ³æ•°æ®é›†ã€‚ä¸ç°æœ‰çš„å¼€æºæ¨¡å‹ï¼ˆå¦‚ TEN Turn Detection å’Œ Smart Turn V2ï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æˆ‘ä»¬çš„å¼€æº Easy Turn æµ‹è¯•é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è½®æµè½¬æ¢æ£€æµ‹å‡†ç¡®æ€§ã€‚æ•°æ®å’Œæ¨¡å‹å°†åœ¨ GitHub ä¸Šå…¬å¼€å‘å¸ƒã€‚ 

---
# Diffusion Models are Kelly Gamblers 

**Title (ZH)**: æ‰©æ•£æ¨¡å‹æ˜¯å‡¯åˆ©èµŒå¾’ 

**Authors**: Akhil Premkumar  

**Link**: [PDF](https://arxiv.org/pdf/2509.23937)  

**Abstract**: We draw a connection between diffusion models and the Kelly criterion for maximizing returns in betting games. We find that conditional diffusion models store additional information to bind the signal $X$ with the conditioning information $Y$, equal to the mutual information between them. Classifier-free guidance effectively boosts the mutual information between $X$ and $Y$ at sampling time. This is especially helpful in image models, since the mutual information between images and their labels is low, a fact which is intimately connected to the manifold hypothesis. Finally, we point out some nuances in the popular perspective that diffusion models are infinitely deep autoencoders. In doing so, we relate the denoising loss to the Fermi Golden Rule from quantum mechanics. 

**Abstract (ZH)**: æˆ‘ä»¬å°†æ‰©æ•£æ¨¡å‹ä¸èµŒåšæ¸¸æˆä¸­æœ€å¤§åŒ–å›æŠ¥çš„å‡¯åˆ©å‡†åˆ™è¿›è¡Œè¿æ¥ã€‚æˆ‘ä»¬å‘ç°æ¡ä»¶æ‰©æ•£æ¨¡å‹å­˜å‚¨äº†é¢å¤–çš„ä¿¡æ¯ï¼Œå°†ä¿¡å·$X$ä¸æ¡ä»¶ä¿¡æ¯$Y$ç»‘å®šï¼Œç­‰ä»·äºå®ƒä»¬ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚æ— åˆ†ç±»å¼•å¯¼æœ‰æ•ˆåœ°åœ¨é‡‡æ ·æ—¶é—´æé«˜$X$ä¸$Y$ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚ç‰¹åˆ«æ˜¯åœ¨å›¾åƒæ¨¡å‹ä¸­è¿™ä¸€ç‚¹å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºå›¾åƒä¸å…¶æ ‡ç­¾ä¹‹é—´çš„äº’ä¿¡æ¯è¾ƒä½ï¼Œè¿™ä¸€äº‹å®ä¸æµå½¢å‡è®¾å¯†åˆ‡ç›¸å…³ã€‚æœ€åï¼Œæˆ‘ä»¬æŒ‡å‡ºå¯¹æ‰©æ•£æ¨¡å‹æ˜¯æ— é™æ·±è‡ªç¼–ç å™¨çš„æµè¡Œè§‚ç‚¹å­˜åœ¨ä¸€äº›ç»†å¾®å·®åˆ«ï¼Œå¹¶å°†å»å™ªæŸå¤±ä¸é‡å­åŠ›å­¦ä¸­çš„è´¹ç±³-é‡‘è§„åˆ™ç›¸è”ç³»ã€‚ 

---
# Graph Mixing Additive Networks 

**Title (ZH)**: å›¾æ··åˆåŠ æ€§ç½‘ç»œ 

**Authors**: Maya Bechler-Speicher, Andrea Zerio, Maor Huri, Marie Vibeke Vestergaard, Ran Gilad-Bachrach, Tine Jess, Samir Bhatt, Aleksejs Sazonovs  

**Link**: [PDF](https://arxiv.org/pdf/2509.23923)  

**Abstract**: We introduce GMAN, a flexible, interpretable, and expressive framework that extends Graph Neural Additive Networks (GNANs) to learn from sets of sparse time-series data. GMAN represents each time-dependent trajectory as a directed graph and applies an enriched, more expressive GNAN to each graph. It allows users to control the interpretability-expressivity trade-off by grouping features and graphs to encode priors, and it provides feature, node, and graph-level interpretability. On real-world datasets, including mortality prediction from blood tests and fake-news detection, GMAN outperforms strong non-interpretable black-box baselines while delivering actionable, domain-aligned explanations. 

**Abstract (ZH)**: GMANï¼šä¸€ç§çµæ´»ã€å¯è§£é‡Šä¸”è¡¨è¾¾èƒ½åŠ›å¼ºçš„æ¡†æ¶ï¼Œç”¨äºå¤„ç†ç¨€ç–æ—¶é—´åºåˆ—æ•°æ®é›†çš„å­¦ä¹  

---
# Continual Learning to Generalize Forwarding Strategies for Diverse Mobile Wireless Networks 

**Title (ZH)**: æŒç»­å­¦ä¹ ä»¥æ³›åŒ–è½¬å‘ç­–ç•¥äºå¤šæ ·åŒ–çš„ç§»åŠ¨æ— çº¿ç½‘ç»œ 

**Authors**: Cheonjin Park, Victoria Manfredi, Xiaolan Zhang, Chengyi Liu, Alicia P Wolfe, Dongjin Song, Sarah Tasneem, Bing Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23913)  

**Abstract**: Deep reinforcement learning (DRL) has been successfully used to design forwarding strategies for multi-hop mobile wireless networks. While such strategies can be used directly for networks with varied connectivity and dynamic conditions, developing generalizable approaches that are effective on scenarios significantly different from the training environment remains largely unexplored. In this paper, we propose a framework to address the challenge of generalizability by (i) developing a generalizable base model considering diverse mobile network scenarios, and (ii) using the generalizable base model for new scenarios, and when needed, fine-tuning the base model using a small amount of data from the new scenarios. To support this framework, we first design new features to characterize network variation and feature quality, thereby improving the information used in DRL-based forwarding decisions. We then develop a continual learning (CL) approach able to train DRL models across diverse network scenarios without ``catastrophic forgetting.'' Using extensive evaluation, including real-world scenarios in two cities, we show that our approach is generalizable to unseen mobility scenarios. Compared to a state-of-the-art heuristic forwarding strategy, it leads to up to 78% reduction in delay, 24% improvement in delivery rate, and comparable or slightly higher number of forwards. 

**Abstract (ZH)**: æ·±å¼ºåŒ–å­¦ä¹ åœ¨å¤šè·³ç§»åŠ¨æ— çº¿ç½‘ç»œè½¬å‘ç­–ç•¥è®¾è®¡ä¸­çš„åº”ç”¨ï¼šé€šè¿‡é€šç”¨åŸºç¡€æ¨¡å‹å’ŒæŒç»­å­¦ä¹ æ–¹æ³•å®ç°æ³›åŒ–èƒ½åŠ› 

---
# EWC-Guided Diffusion Replay for Exemplar-Free Continual Learning in Medical Imaging 

**Title (ZH)**: åŸºäºEWCæŒ‡å¯¼çš„æ‰©æ•£é‡æ”¾ä»¥å®ç°æ— èŒƒä¾‹æŒç»­å­¦ä¹ åœ¨åŒ»å­¦æˆåƒä¸­ 

**Authors**: Anoushka Harit, William Prew, Zhongtian Sun, Florian Markowetz  

**Link**: [PDF](https://arxiv.org/pdf/2509.23906)  

**Abstract**: Medical imaging foundation models must adapt over time, yet full retraining is often blocked by privacy constraints and cost. We present a continual learning framework that avoids storing patient exemplars by pairing class conditional diffusion replay with Elastic Weight Consolidation. Using a compact Vision Transformer backbone, we evaluate across eight MedMNIST v2 tasks and CheXpert. On CheXpert our approach attains 0.851 AUROC, reduces forgetting by more than 30\% relative to DER\texttt{++}, and approaches joint training at 0.869 AUROC, while remaining efficient and privacy preserving. Analyses connect forgetting to two measurable factors: fidelity of replay and Fisher weighted parameter drift, highlighting the complementary roles of replay diffusion and synaptic stability. The results indicate a practical route for scalable, privacy aware continual adaptation of clinical imaging models. 

**Abstract (ZH)**: åŒ»ç–—å½±åƒåŸºç¡€æ¨¡å‹å¿…é¡»éšæ—¶é—´è¿›è¡Œé€‚åº”ï¼Œä½†å®Œå…¨é‡æ–°è®­ç»ƒå¾€å¾€å—é™äºéšç§çº¦æŸå’Œæˆæœ¬ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æŒç»­å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å°†ç±»æ¡ä»¶æ‰©æ•£é‡æ”¾ä¸å¼¹æ€§æƒé‡å·©å›ºç›¸ç»“åˆï¼Œé¿å…å­˜å‚¨æ‚£è€…ç¤ºä¾‹ã€‚é‡‡ç”¨ç´§å‡‘çš„è§†è§‰å˜å‹å™¨éª¨å¹²ï¼Œæˆ‘ä»¬åœ¨å…«ä¸ªMedMNIST v2ä»»åŠ¡å’ŒCheXpertä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚åœ¨CheXpertä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•å–å¾—äº†0.851çš„AUROCï¼Œç›¸å¯¹äºDER\texttt{++}å‡å°‘äº†è¶…è¿‡30%çš„é—å¿˜ï¼Œå¹¶æ¥è¿‘è”åˆè®­ç»ƒçš„0.869 AUROCï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆå’Œéšç§ä¿æŠ¤ã€‚åˆ†æå°†é—å¿˜å…³è”åˆ°ä¸¤ä¸ªå¯æµ‹é‡çš„å› ç´ ï¼šé‡æ”¾ä¿çœŸåº¦å’Œè´¹èˆå°”åŠ æƒå‚æ•°æ¼‚ç§»ï¼Œå¼ºè°ƒäº†é‡æ”¾æ‰©æ•£å’Œçªè§¦ç¨³å®šæ€§çš„äº’è¡¥ä½œç”¨ã€‚ç»“æœè¡¨æ˜äº†ä¸€æ¡å®ç”¨é€”å¾„ï¼Œç”¨äºå®ç°ä¸´åºŠå½±åƒæ¨¡å‹çš„ scalableã€éšç§æ„è¯†æŒç»­é€‚åº”ã€‚ 

---
# Interpreting deep learning-based stellar mass estimation via causal analysis and mutual information decomposition 

**Title (ZH)**: åŸºäºå› æœåˆ†æå’Œäº’ä¿¡æ¯åˆ†è§£çš„æ·±åº¦å­¦ä¹ æ’æ˜Ÿè´¨é‡ä¼°è®¡è§£é‡Š 

**Authors**: Wei Zhang, Qiufan Lin, Yuan-Sen Ting, Shupei Chen, Hengxin Ruan, Song Li, Yifan Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23901)  

**Abstract**: End-to-end deep learning models fed with multi-band galaxy images are powerful data-driven tools used to estimate galaxy physical properties in the absence of spectroscopy. However, due to a lack of interpretability and the associational nature of such models, it is difficult to understand how the information additional to integrated photometry (e.g., morphology) contributes to the estimation task. Improving our understanding in this field would enable further advances into unraveling the physical connections among galaxy properties and optimizing data exploitation. Therefore, our work is aimed at interpreting the deep learning-based estimation of stellar mass via two interpretability techniques: causal analysis and mutual information decomposition. The former reveals the causal paths between multiple variables beyond nondirectional statistical associations, while the latter quantifies the multicomponent contributions (i.e., redundant, unique, and synergistic) of different input data to the stellar mass estimation. Using data from the Sloan Digital Sky Survey (SDSS) and the Wide-field Infrared Survey Explorer (WISE), we obtained meaningful results that provide physical interpretations for image-based models. Our work demonstrates the gains from combining deep learning with interpretability techniques, and holds promise in promoting more data-driven astrophysical research (e.g., astrophysical parameter estimations and investigations on complex multivariate physical processes). 

**Abstract (ZH)**: åŸºäºå¤šé¢‘æ®µæ˜Ÿç³»å›¾åƒçš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¨¡å‹èƒ½å¤Ÿä»æ— å…‰è°±æ•°æ®ä¸­ä¼°è®¡æ˜Ÿç³»ç‰©ç†æ€§è´¨ï¼Œç„¶è€Œç”±äºè¿™äº›æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§å’Œå…³è”æ€§æœ¬è´¨ï¼Œéš¾ä»¥ç†è§£é¢å¤–çš„ç»¼åˆå…‰åº¦å­¦ä¿¡æ¯ï¼ˆå¦‚å½¢æ€å­¦ï¼‰å¦‚ä½• contributesåˆ°ä¼°è®¡ä»»åŠ¡ã€‚ä¸ºäº†ä¿ƒè¿›å¯¹è¯¥é¢†åŸŸçš„ç†è§£å¹¶ä¼˜åŒ–æ•°æ®åˆ©ç”¨ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ—¨åœ¨é€šè¿‡å› æœåˆ†æå’Œäº’ä¿¡æ¯åˆ†è§£ä¸¤ç§å¯è§£é‡Šæ€§æŠ€æœ¯æ¥è§£é‡ŠåŸºäºæ·±åº¦å­¦ä¹ çš„æ’æ˜Ÿè´¨é‡ä¼°è®¡ã€‚å‰è€…æ­ç¤ºäº†å¤šä¸ªå˜é‡ä¹‹é—´çš„å› æœè·¯å¾„ï¼Œè€Œåè€…é‡åŒ–äº†ä¸åŒè¾“å…¥æ•°æ®å¯¹æ’æ˜Ÿè´¨é‡ä¼°è®¡çš„å¤šæˆåˆ†è´¡çŒ®ï¼ˆå³å†—ä½™ã€ç‹¬ç‰¹å’ŒååŒè´¡çŒ®ï¼‰ã€‚ä½¿ç”¨æ–¯éš†æ•°å­—å¤©ç©ºå·¡å¤©ï¼ˆSDSSï¼‰å’Œå¹¿åŸŸçº¢å¤–å·¡å¤©æ¢ç´¢è€…ï¼ˆWISEï¼‰æ•°æ®ï¼Œæˆ‘ä»¬è·å¾—äº†æœ‰æ„ä¹‰çš„ç»“æœï¼Œä¸ºå›¾åƒæ¨¡å‹æä¾›äº†ç‰©ç†è§£é‡Šã€‚æˆ‘ä»¬çš„å·¥ä½œå±•ç¤ºäº†å°†æ·±åº¦å­¦ä¹ ä¸å¯è§£é‡Šæ€§æŠ€æœ¯ç»“åˆçš„ä¼˜åŠ¿ï¼Œå¹¶æœ‰æœ›ä¿ƒè¿›æ›´å…·æ•°æ®é©±åŠ¨æ€§çš„å¤©ä½“ç‰©ç†ç ”ç©¶ï¼ˆä¾‹å¦‚å¤©ä½“ç‰©ç†å‚æ•°ä¼°è®¡å’Œå¤æ‚å¤šå˜é‡ç‰©ç†è¿‡ç¨‹çš„ç ”ç©¶ï¼‰ã€‚ 

---
# Gradient Flow Convergence Guarantee for General Neural Network Architectures 

**Title (ZH)**: æ¢¯åº¦æµæ”¶æ•›æ€§ä¿è¯ï¼šé€šç”¨ç¥ç»ç½‘ç»œæ¶æ„ 

**Authors**: Yash Jakhmola  

**Link**: [PDF](https://arxiv.org/pdf/2509.23887)  

**Abstract**: A key challenge in modern deep learning theory is to explain the remarkable success of gradient-based optimization methods when training large-scale, complex deep neural networks. Though linear convergence of such methods has been proved for a handful of specific architectures, a united theory still evades researchers. This article presents a unified proof for linear convergence of continuous gradient descent, also called gradient flow, while training any neural network with piecewise non-zero polynomial activations or ReLU, sigmoid activations. Our primary contribution is a single, general theorem that not only covers architectures for which this result was previously unknown but also consolidates existing results under weaker assumptions. While our focus is theoretical and our results are only exact in the infinitesimal step size limit, we nevertheless find excellent empirical agreement between the predictions of our result and those of the practical step-size gradient descent method. 

**Abstract (ZH)**: ç°ä»£æ·±åº¦å­¦ä¹ ç†è®ºä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯åœ¨è®­ç»ƒå¤§è§„æ¨¡å¤æ‚æ·±åº¦ç¥ç»ç½‘ç»œæ—¶ï¼Œè§£é‡ŠåŸºäºæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•çš„æ˜¾è‘—æˆåŠŸã€‚å°½ç®¡å·²ç»è¯æ˜äº†è¿™äº›æ–¹æ³•åœ¨å°‘æ•°ç‰¹å®šæ¶æ„ä¸Šçš„çº¿æ€§æ”¶æ•›æ€§ï¼Œä½†ç»Ÿä¸€ç†è®ºä»æœªèƒ½è®©ç ”ç©¶äººå‘˜è¾¾æˆå…±è¯†ã€‚æœ¬æ–‡ç»™å‡ºäº†å¯¹ä»»ä½•å…·æœ‰åˆ†æ®µéé›¶å¤šé¡¹å¼æ¿€æ´»æˆ–ReLUã€Sigmoidæ¿€æ´»çš„ç¥ç»ç½‘ç»œä½¿ç”¨è¿ç»­æ¢¯åº¦ä¸‹é™ï¼ˆä¹Ÿç§°ä¸ºæ¢¯åº¦æµï¼‰æ–¹æ³•çš„çº¿æ€§æ”¶æ•›æ€§çš„ç»Ÿä¸€è¯æ˜ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯ä¸€ä¸ªé€šç”¨çš„å•ä¸€å®šç†ï¼Œä¸ä»…æ¶µç›–äº†ä¹‹å‰æœªçŸ¥æ¶æ„çš„ç»“æœï¼Œè¿˜å°†åœ¨è¾ƒå¼±å‡è®¾ä¸‹æ±‡æ€»äº†ç°æœ‰ç»“æœã€‚è™½ç„¶æˆ‘ä»¬å…³æ³¨çš„æ˜¯ç†è®ºæ–¹é¢ï¼Œä¸”ç»“æœä»…åœ¨æ— ç©·å°æ­¥é•¿æé™ä¸‹ç²¾ç¡®ï¼Œä½†æˆ‘ä»¬ä»ç„¶å‘ç°æˆ‘ä»¬çš„ç»“æœé¢„æµ‹ä¸å®é™…æ­¥é•¿æ¢¯åº¦ä¸‹é™æ–¹æ³•çš„é¢„æµ‹ä¹‹é—´æœ‰å¾ˆå¥½çš„å®éªŒä¸€è‡´æ€§ã€‚ 

---
# Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction 

**Title (ZH)**: åŸºäºè‡ªä¸»ç›‘ç£ä¸Šä¸‹æ–‡å­æ•°æ®çš„å¯è°ƒé€šç”¨æ‰©æ•£ç”¨äºä½å‰‚é‡CTé‡å»º 

**Authors**: Guoquan Wei, Zekun Zhou, Liu Shi, Wenzhe Shan, Qiegen Liu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23885)  

**Abstract**: Current models based on deep learning for low-dose CT denoising rely heavily on paired data and generalize poorly. Even the more concerned diffusion models need to learn the distribution of clean data for reconstruction, which is difficult to satisfy in medical clinical applications. At the same time, self-supervised-based methods face the challenge of significant degradation of generalizability of models pre-trained for the current dose to expand to other doses. To address these issues, this paper proposes a novel method of tunable-generalization diffusion powered by self-supervised contextual sub-data for low-dose CT reconstruction, named SuperDiff. Firstly, a contextual subdata similarity adaptive sensing strategy is designed for denoising centered on the LDCT projection domain, which provides an initial prior for the subsequent progress. Subsequently, the initial prior is used to combine knowledge distillation with a deep combination of latent diffusion models for optimizing image details. The pre-trained model is used for inference reconstruction, and the pixel-level self-correcting fusion technique is proposed for fine-grained reconstruction of the image domain to enhance the image fidelity, using the initial prior and the LDCT image as a guide. In addition, the technique is flexibly applied to the generalization of upper and lower doses or even unseen doses. Dual-domain strategy cascade for self-supervised LDCT denoising, SuperDiff requires only LDCT projection domain data for training and testing. Full qualitative and quantitative evaluations on both datasets and real data show that SuperDiff consistently outperforms existing state-of-the-art methods in terms of reconstruction and generalization performance. 

**Abstract (ZH)**: åŸºäºè‡ªç›‘ç£ä¸Šä¸‹æ–‡å­æ•°æ®çš„å¯è°ƒæ³›åŒ–æ‰©æ•£æ–¹æ³•ï¼šä½å‰‚é‡CTé‡å»ºï¼ˆSuperDiffï¼‰ 

---
# Multi-Value-Product Retrieval-Augmented Generation for Industrial Product Attribute Value Identification 

**Title (ZH)**: åŸºäºå¤šå€¼äº§å“æ£€ç´¢å¢å¼ºç”Ÿæˆçš„å·¥ä¸šäº§å“å±æ€§å€¼è¯†åˆ« 

**Authors**: Huike Zou, Haiyang Yang, Yindu Su, Liyu Chen, Chengbao Lian, Qingheng Zhang, Shuguang Han, Jufeng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.23874)  

**Abstract**: Identifying attribute values from product profiles is a key task for improving product search, recommendation, and business analytics on e-commerce platforms, which we called Product Attribute Value Identification (PAVI) . However, existing PAVI methods face critical challenges, such as cascading errors, inability to handle out-of-distribution (OOD) attribute values, and lack of generalization capability. To address these limitations, we introduce Multi-Value-Product Retrieval-Augmented Generation (MVP-RAG), combining the strengths of retrieval, generation, and classification paradigms. MVP-RAG defines PAVI as a retrieval-generation task, where the product title description serves as the query, and products and attribute values act as the corpus. It first retrieves similar products of the same category and candidate attribute values, and then generates the standardized attribute values. The key advantages of this work are: (1) the proposal of a multi-level retrieval scheme, with products and attribute values as distinct hierarchical levels in PAVI domain (2) attribute value generation of large language model to significantly alleviate the OOD problem and (3) its successful deployment in a real-world industrial environment. Extensive experimental results demonstrate that MVP-RAG performs better than the state-of-the-art baselines. 

**Abstract (ZH)**: äº§å“å±æ€§å€¼è¯†åˆ«ï¼ˆPAVIï¼‰æ˜¯ä»äº§å“æè¿°ä¸­è¯†åˆ«å±æ€§å€¼çš„å…³é”®ä»»åŠ¡ï¼Œæœ‰åŠ©äºç”µå•†å¹³å°çš„äº§å“æœç´¢ã€æ¨èå’Œå•†ä¸šåˆ†æã€‚ç„¶è€Œï¼Œç°æœ‰çš„PAVIæ–¹æ³•é¢ä¸´å…³é”®æŒ‘æˆ˜ï¼Œå¦‚è¿é”é”™è¯¯ã€æ— æ³•å¤„ç†åˆ†å¸ƒå¤–ï¼ˆOODï¼‰å±æ€§å€¼ä»¥åŠç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºè§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤šå€¼äº§å“æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆMVP-RAGï¼‰æ–¹æ³•ï¼Œç»“åˆäº†æ£€ç´¢ã€ç”Ÿæˆå’Œåˆ†ç±» paradigm çš„ä¼˜åŠ¿ã€‚MVP-RAG å°† PAVI å®šä¹‰ä¸ºä¸€ä¸ªæ£€ç´¢-ç”Ÿæˆä»»åŠ¡ï¼Œå…¶ä¸­äº§å“æ ‡é¢˜æè¿°ä½œä¸ºæŸ¥è¯¢ï¼Œäº§å“å’Œå±æ€§å€¼ä½œä¸ºè¯­æ–™åº“ã€‚å®ƒé¦–å…ˆæ£€ç´¢ç›¸åŒç±»åˆ«ç›¸ä¼¼çš„äº§å“å’Œå€™é€‰å±æ€§å€¼ï¼Œç„¶åç”Ÿæˆæ ‡å‡†åŒ–çš„å±æ€§å€¼ã€‚æœ¬æ–‡çš„å…³é”®ä¼˜åŠ¿åœ¨äºï¼šï¼ˆ1ï¼‰æå‡ºä¸€ä¸ªå¤šçº§æ£€ç´¢æ–¹æ¡ˆï¼Œäº§å“å’Œå±æ€§å€¼åœ¨PAVIé¢†åŸŸä½œä¸ºä¸åŒçš„å±‚çº§ï¼›ï¼ˆ2ï¼‰é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå±æ€§å€¼ï¼Œæ˜¾è‘—ç¼“è§£åˆ†å¸ƒå¤–é—®é¢˜ï¼›ï¼ˆ3ï¼‰æˆåŠŸéƒ¨ç½²äºå®é™…å·¥ä¸šç¯å¢ƒã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMVP-RAG åœ¨ä¸å…ˆè¿›åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ä¸­è¡¨ç°æ›´ä¼˜ã€‚ 

---
# Taught Well Learned Ill: Towards Distillation-conditional Backdoor Attack 

**Title (ZH)**: æ•™å¾—å¥½äº†ä¹Ÿä¼šå—éª—ï¼šé¢å‘è’¸é¦æ¡ä»¶åé—¨æ”»å‡» 

**Authors**: Yukun Chen, Boheng Li, Yu Yuan, Leyi Qi, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren  

**Link**: [PDF](https://arxiv.org/pdf/2509.23871)  

**Abstract**: Knowledge distillation (KD) is a vital technique for deploying deep neural networks (DNNs) on resource-constrained devices by transferring knowledge from large teacher models to lightweight student models. While teacher models from third-party platforms may undergo security verification (\eg, backdoor detection), we uncover a novel and critical threat: distillation-conditional backdoor attacks (DCBAs). DCBA injects dormant and undetectable backdoors into teacher models, which become activated in student models via the KD process, even with clean distillation datasets. While the direct extension of existing methods is ineffective for DCBA, we implement this attack by formulating it as a bilevel optimization problem and proposing a simple yet effective method (\ie, SCAR). Specifically, the inner optimization simulates the KD process by optimizing a surrogate student model, while the outer optimization leverages outputs from this surrogate to optimize the teacher model for implanting the conditional backdoor. Our SCAR addresses this complex optimization utilizing an implicit differentiation algorithm with a pre-optimized trigger injection function. Extensive experiments across diverse datasets, model architectures, and KD techniques validate the effectiveness of our SCAR and its resistance against existing backdoor detection, highlighting a significant yet previously overlooked vulnerability in the KD process. Our code is available at this https URL. 

**Abstract (ZH)**: çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰çš„å®‰å…¨å¨èƒï¼šè’¸é¦æ¡ä»¶ä¸‹çš„åé—¨æ”»å‡»ï¼ˆDCBAï¼‰ 

---
# Efficient Multi-turn RL for GUI Agents via Decoupled Training and Adaptive Data Curation 

**Title (ZH)**: é€šè¿‡è§£è€¦è®­ç»ƒå’Œè‡ªé€‚åº”æ•°æ®ç®¡ç†çš„é«˜æ•ˆå¤šè½®RL Ğ´Ğ»Ñ GUIä»£ç† 

**Authors**: Pengxiang Li, Zechen Hu, Zirui Shang, Jingrong Wu, Yang Liu, Hui Liu, Zhi Gao, Chenrui Shi, Bofei Zhang, Zihao Zhang, Xiaochuan Shi, Zedong YU, Yuwei Wu, Xinxiao Wu, Yunde Jia, Liuyu Xiang, Zhaofeng He, Qing Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.23866)  

**Abstract**: Vision-language model (VLM) based GUI agents show promise for automating complex desktop and mobile tasks, but face significant challenges in applying reinforcement learning (RL): (1) slow multi-turn interactions with GUI environments for policy rollout, and (2) insufficient high-quality agent-environment interactions for policy learning. To address these challenges, we propose DART, a Decoupled Agentic RL Training framework for GUI agents, which coordinates heterogeneous modules in a highly decoupled manner. DART separates the training system into four asynchronous modules: environment cluster, rollout service, data manager, and trainer. This design enables non-blocking communication, asynchronous training, rollout-wise trajectory sampling, and per-worker model synchronization, significantly improving the system efficiency: 1.6*GPU utilization for rollout, 1.9* training throughput, and 5.5* environment utilization. To facilitate effective learning from abundant samples, we introduce an adaptive data curation scheme: (1) pre-collecting successful trajectories for challenging tasks to supplement sparse success in online sampling; (2) dynamically adjusting rollout numbers and trajectory lengths based on task difficulty; (3) training selectively on high-entropy steps to prioritize critical decisions; (4) stabilizing learning via truncated importance sampling for policy mismatch between policy rollout and updating. On the OSWorld benchmark, DART-GUI-7B achieves a 42.13% task success rate, a 14.61% absolute gain over the base model, and 7.34% higher than open-source SOTA. We will fully open-source our training framework, data, and model checkpoints via this http URL, which we believe is a timely contribution to the open-source community of agentic RL training. 

**Abstract (ZH)**: åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„GUIä»£ç†åœ¨è‡ªåŠ¨åŒ–å¤æ‚æ¡Œé¢å’Œç§»åŠ¨ä»»åŠ¡æ–¹é¢æ˜¾ç¤ºå‡ºå‰æ™¯ï¼Œä½†åœ¨åº”ç”¨å¼ºåŒ–å­¦ä¹ æ–¹é¢é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼š(1) ä¸GUIç¯å¢ƒè¿›è¡Œå¤šè½®äº¤äº’çš„æ•ˆç‡ä½ä¸‹ï¼Œ(2) ç”¨äºç­–ç•¥å­¦ä¹ çš„ä»£ç†-ç¯å¢ƒäº¤äº’ä¸è¶³ã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºDARTçš„åˆ†é˜¶ä»£ç†å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»¥é«˜åº¦è§£è€¦çš„æ–¹å¼åè°ƒå¼‚æ„æ¨¡å—ã€‚DARTå°†è®­ç»ƒç³»ç»Ÿåˆ†è§£ä¸ºå››ä¸ªå¼‚æ­¥æ¨¡å—ï¼šç¯å¢ƒé›†ç¾¤ã€è¿ç»´æœåŠ¡ã€æ•°æ®ç®¡ç†å’Œè®­ç»ƒå™¨ã€‚è¿™ç§è®¾è®¡å®ç°äº†éé˜»å¡é€šä¿¡ã€å¼‚æ­¥è®­ç»ƒã€è½¨è¿¹é‡‡æ ·ä»¥åŠæŒ‰å·¥ä½œè¿›ç¨‹åŒæ­¥æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†ç³»ç»Ÿæ•ˆç‡ï¼šæ¯è½®äº¤äº’çš„GPUåˆ©ç”¨ç‡æé«˜1.6å€ï¼Œè®­ç»ƒååé‡æé«˜1.9å€ï¼Œç¯å¢ƒåˆ©ç”¨ç‡æé«˜5.5å€ã€‚ä¸ºäº†æœ‰æ•ˆåˆ©ç”¨ä¸°å¯Œçš„æ ·æœ¬è¿›è¡Œå­¦ä¹ ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”æ•°æ®æ•´ç†æ–¹æ¡ˆï¼š(1) åœ¨çº¿é‡‡æ ·å‰é¢„å…ˆæ”¶é›†å›°éš¾ä»»åŠ¡çš„æˆåŠŸè½¨è¿¹ï¼Œè¡¥å……ç¨€ç–çš„æˆåŠŸæ ·æœ¬ï¼›(2) æ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´è½®æ¬¡æ•°é‡å’Œè½¨è¿¹é•¿åº¦ï¼›(3) é€‰æ‹©æ€§åœ°åœ¨é«˜ç†µæ­¥éª¤ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¼˜å…ˆå¤„ç†å…³é”®å†³ç­–ï¼›(4) é€šè¿‡æˆªæ–­é‡è¦æ€§é‡‡æ ·æ¥ç¨³å®šå­¦ä¹ ï¼Œè§£å†³ç­–ç•¥è½®æ’­å’Œæ›´æ–°ä¹‹é—´çš„ä¸åŒ¹é…é—®é¢˜ã€‚åœ¨OSWorldåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDART-GUI-7Bå®ç°äº†42.13%çš„ä»»åŠ¡æˆåŠŸç‡ï¼Œç›¸å¯¹äºåŸºçº¿æ¨¡å‹ç»å¯¹æå‡14.61%ï¼Œå¹¶ä¸”é«˜äºå¼€æºSOTAæ¨¡å‹7.34%ã€‚æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹ç½‘å€å…¨é¢å¼€æºæˆ‘ä»¬çš„è®­ç»ƒæ¡†æ¶ã€æ•°æ®å’Œæ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ä¸€é¡¹å¯¹ä»£ç†å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¼€æºç¤¾åŒºçš„åŠæ—¶è´¡çŒ®ã€‚ 

---
# GSID: Generative Semantic Indexing for E-Commerce Product Understanding 

**Title (ZH)**: GSID: ç”Ÿæˆè¯­ä¹‰ç´¢å¼•ä»¥ç†è§£ç”µå­å•†åŠ¡äº§å“ 

**Authors**: Haiyang Yang, Qinye Xie, Qingheng Zhang, Liyu Chen, Huike Zou, Chengbao Lian, Shuguang Han, Fei Huang, Jufeng Chen, Bo Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.23860)  

**Abstract**: Structured representation of product information is a major bottleneck for the efficiency of e-commerce platforms, especially in second-hand ecommerce platforms. Currently, most product information are organized based on manually curated product categories and attributes, which often fail to adequately cover long-tail products and do not align well with buyer preference. To address these problems, we propose \textbf{G}enerative \textbf{S}emantic \textbf{I}n\textbf{D}exings (GSID), a data-driven approach to generate product structured representations. GSID consists of two key components: (1) Pre-training on unstructured product metadata to learn in-domain semantic embeddings, and (2) Generating more effective semantic codes tailored for downstream product-centric applications. Extensive experiments are conducted to validate the effectiveness of GSID, and it has been successfully deployed on the real-world e-commerce platform, achieving promising results on product understanding and other downstream tasks. 

**Abstract (ZH)**: åŸºäºç”Ÿæˆè¯­ä¹‰ç´¢å¼•çš„ç”µå­å•†åŠ¡äº§å“ç»“æ„åŒ–è¡¨ç¤º 

---
# Space Group Conditional Flow Matching 

**Title (ZH)**: ç©ºé—´ç¾¤æ¡ä»¶æµåŒ¹é… 

**Authors**: Omri Puny, Yaron Lipman, Benjamin Kurt Miller  

**Link**: [PDF](https://arxiv.org/pdf/2509.23822)  

**Abstract**: Inorganic crystals are periodic, highly-symmetric arrangements of atoms in three-dimensional space. Their structures are constrained by the symmetry operations of a crystallographic \emph{space group} and restricted to lie in specific affine subspaces known as \emph{Wyckoff positions}. The frequency an atom appears in the crystal and its rough positioning are determined by its Wyckoff position. Most generative models that predict atomic coordinates overlook these symmetry constraints, leading to unrealistically high populations of proposed crystals exhibiting limited symmetry. We introduce Space Group Conditional Flow Matching, a novel generative framework that samples significantly closer to the target population of highly-symmetric, stable crystals. We achieve this by conditioning the entire generation process on a given space group and set of Wyckoff positions; specifically, we define a conditionally symmetric noise base distribution and a group-conditioned, equivariant, parametric vector field that restricts the motion of atoms to their initial Wyckoff position. Our form of group-conditioned equivariance is achieved using an efficient reformulation of \emph{group averaging} tailored for symmetric crystals. Importantly, it reduces the computational overhead of symmetrization to a negligible level. We achieve state of the art results on crystal structure prediction and de novo generation benchmarks. We also perform relevant ablations. 

**Abstract (ZH)**: æ— æœºæ™¶ä½“æ˜¯ä¸‰ç»´ç©ºé—´ä¸­å…·æœ‰å‘¨æœŸæ€§å’Œé«˜å¯¹ç§°æ€§çš„åŸå­æ’åˆ—ã€‚å®ƒä»¬çš„ç»“æ„å—åˆ°æ™¶ä½“å­¦ç©ºé—´ç¾¤çš„å¯¹ç§°æ“ä½œçº¦æŸï¼Œå¹¶é™å®šåœ¨ç‰¹å®šçš„ä»¿å°„å­ç©ºé—´å³æ²ƒå…‹å¤«ä½ç½®ä¸­ã€‚åŸå­åœ¨æ™¶ä½“ä¸­çš„å‡ºç°é¢‘ç‡åŠå…¶å¤§è‡´ä½ç½®ç”±å…¶æ²ƒå…‹å¤«ä½ç½®å†³å®šã€‚å¤§å¤šæ•°ç”¨äºé¢„æµ‹åŸå­åæ ‡ç”Ÿæˆæ¨¡å‹æœªè€ƒè™‘è¿™äº›å¯¹ç§°çº¦æŸï¼Œå¯¼è‡´ç”Ÿæˆçš„æ™¶ä½“è¡¨ç°å‡ºæœ‰é™å¯¹ç§°æ€§çš„ä¸åˆ‡å®é™…é«˜æ¯”ä¾‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç©ºé—´ç¾¤æ¡ä»¶æµåŒ¹é…ç”Ÿæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åŸºäºç»™å®šç©ºé—´ç¾¤å’Œæ²ƒå…‹å¤«ä½ç½®å¯¹æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œæ˜¾è‘—åœ°æ¥è¿‘ç›®æ ‡ç¾¤ä½“çš„é«˜å¯¹ç§°æ€§å’Œç¨³å®šæ™¶ä½“ã€‚æˆ‘ä»¬é€šè¿‡å®šä¹‰æ¡ä»¶å¯¹ç§°å™ªå£°åŸºåˆ†å¸ƒå’Œç¾¤æ¡ä»¶ä¸‹çš„å®ˆæ’å‚æ•°å‘é‡åœºï¼Œé™åˆ¶åŸå­è¿åŠ¨åˆ°å…¶åˆå§‹æ²ƒå…‹å¤«ä½ç½®æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å½¢å¼ä¸‹çš„ç¾¤æ¡ä»¶ä¸‹çš„å®ˆæ’æ€§æ˜¯é€šè¿‡é’ˆå¯¹å¯¹ç§°æ™¶ä½“ä¼˜åŒ–çš„ç¾¤å¹³å‡çš„ä¸€ç§é«˜æ•ˆé‡å†™å®ç°çš„ã€‚é‡è¦çš„æ˜¯ï¼Œå®ƒå°†å¯¹ç§°åŒ–çš„è®¡ç®—å¼€é”€é™ä½åˆ°äº†å¯ä»¥å¿½ç•¥çš„æ°´å¹³ã€‚æˆ‘ä»¬åœ¨æ™¶ä½“ç»“æ„é¢„æµ‹å’Œä»å¤´ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶è¿›è¡Œäº†ç›¸å…³çš„æ¶ˆèå®éªŒã€‚ 

---
# IndexNet: Timestamp and Variable-Aware Modeling for Time Series Forecasting 

**Title (ZH)**: IndexNet: è€ƒè™‘æ—¶é—´æˆ³å’Œå˜é‡çš„æ—¶é—´åºåˆ—é¢„æµ‹å»ºæ¨¡ 

**Authors**: Beiliang Wu, Peiyuan Liu, Yifan Hu, Luyan Zhang, Ao Hu, Zenglin Xu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23813)  

**Abstract**: Multivariate time series forecasting (MTSF) plays a vital role in a wide range of real-world applications, such as weather prediction and traffic flow forecasting. Although recent advances have significantly improved the modeling of temporal dynamics and inter-variable dependencies, most existing methods overlook index-related descriptive information, such as timestamps and variable indices, which carry rich contextual semantics. To unlock the potential of such information and take advantage of the lightweight and powerful periodic capture ability of MLP-based architectures, we propose IndexNet, an MLP-based framework augmented with an Index Embedding (IE) module. The IE module consists of two key components: Timestamp Embedding (TE) and Channel Embedding (CE). Specifically, TE transforms timestamps into embedding vectors and injects them into the input sequence, thereby improving the model's ability to capture long-term complex periodic patterns. In parallel, CE assigns each variable a unique and trainable identity embedding based on its index, allowing the model to explicitly distinguish between heterogeneous variables and avoid homogenized predictions when input sequences seem close. Extensive experiments on 12 diverse real-world datasets demonstrate that IndexNet achieves comparable performance across mainstream baselines, validating the effectiveness of our temporally and variably aware design. Moreover, plug-and-play experiments and visualization analyses further reveal that IndexNet exhibits strong generality and interpretability, two aspects that remain underexplored in current MTSF research. 

**Abstract (ZH)**: å¤šå˜é‡æ—¶é—´åºåˆ— forecasting (MTSF) åœ¨å¤©æ°”é¢„æµ‹å’Œäº¤é€šæµé¢„æµ‹ç­‰å¹¿æ³›çš„å®é™…åº”ç”¨ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚å°½ç®¡è¿‘å¹´æ¥çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†å¯¹æ—¶é—´åŠ¨æ€å’Œå˜é‡é—´ä¾èµ–å…³ç³»çš„å»ºæ¨¡èƒ½åŠ›ï¼Œä½†å¤§å¤šæ•°ç°æœ‰æ–¹æ³•å¿½ç•¥äº†ä¸ç´¢å¼•ç›¸å…³çš„æè¿°æ€§ä¿¡æ¯ï¼Œå¦‚æ—¶é—´æˆ³å’Œå˜é‡ç´¢å¼•ï¼Œè¿™äº›ä¿¡æ¯å¯Œå«ä¸°å¯Œçš„ä¸Šä¸‹æ–‡è¯­ä¹‰ã€‚ä¸ºå……åˆ†åˆ©ç”¨æ­¤ç±»ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨åŸºäºMLPæ¶æ„çš„è½»é‡çº§ä¸”å¼ºå¤§çš„å‘¨æœŸæ•è·èƒ½åŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†IndexNetï¼Œä¸€ç§å¢å¼ºæœ‰ç´¢å¼•åµŒå…¥ (IE) æ¨¡å—çš„MLPæ¡†æ¶ã€‚IEæ¨¡å—åŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼šæ—¶é—´æˆ³åµŒå…¥ (TE) å’Œé€šé“åµŒå…¥ (CE)ã€‚å…·ä½“æ¥è¯´ï¼ŒTEå°†æ—¶é—´æˆ³è½¬æ¢ä¸ºåµŒå…¥å‘é‡å¹¶æ³¨å…¥è¾“å…¥åºåˆ—ï¼Œä»è€Œå¢å¼ºæ¨¡å‹æ•æ‰é•¿æœŸå¤æ‚å‘¨æœŸæ¨¡å¼çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼ŒCEæ ¹æ®å˜é‡ç´¢å¼•ä¸ºæ¯ä¸ªå˜é‡åˆ†é…ä¸€ä¸ªç‹¬ç‰¹çš„å¯è®­ç»ƒèº«ä»½åµŒå…¥ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ˜ç¡®åŒºåˆ†å¼‚è´¨å˜é‡å¹¶é¿å…åœ¨è¾“å…¥åºåˆ—çœ‹ä¼¼ç›¸è¿‘æ—¶äº§ç”ŸåŒè´¨é¢„æµ‹ã€‚åœ¨12ä¸ªå¤šæ ·åŒ–çš„å®é™…æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒIndexNetåœ¨ä¸»æµåŸºçº¿ä¸­å–å¾—äº†å¯æ¯”çš„æ€§èƒ½ï¼ŒéªŒè¯äº†æˆ‘ä»¬å…·æœ‰æ—¶é—´å’Œå˜é‡æ„ŸçŸ¥è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å—åŒ–å®éªŒå’Œå¯è§†åŒ–åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†IndexNetçš„å¼ºå¤§é€šç”¨æ€§å’Œå¯è§£é‡Šæ€§ï¼Œè¿™ä¸¤ä¸ªæ–¹é¢åœ¨å½“å‰æ—¶é—´åºåˆ—é¢„æµ‹ç ”ç©¶ä¸­å°šæœªå……åˆ†æ¢ç´¢ã€‚ 

---
# From Unstable to Playable: Stabilizing Angry Birds Levels via Object Segmentation 

**Title (ZH)**: ä»ä¸ç¨³å®šåˆ°å¯ç©ï¼šé€šè¿‡å¯¹è±¡åˆ†å‰²ç¨³å®šã€Šæ„¤æ€’çš„å°é¸Ÿã€‹å…³å¡ 

**Authors**: Mahdi Farrokhimaleki, Parsa Rahmati, Richard Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2509.23787)  

**Abstract**: Procedural Content Generation (PCG) techniques enable automatic creation of diverse and complex environments. While PCG facilitates more efficient content creation, ensuring consistently high-quality, industry-standard content remains a significant challenge. In this research, we propose a method to identify and repair unstable levels generated by existing PCG models. We use Angry Birds as a case study, demonstrating our method on game levels produced by established PCG approaches. Our method leverages object segmentation and visual analysis of level images to detect structural gaps and perform targeted repairs. We evaluate multiple object segmentation models and select the most effective one as the basis for our repair pipeline. Experimental results show that our method improves the stability and playability of AI-generated levels. Although our evaluation is specific to Angry Birds, our image-based approach is designed to be applicable to a wide range of 2D games with similar level structures. 

**Abstract (ZH)**: åŸºäºå›¾åƒçš„Procedural Content Generationæ¨¡å‹ç”Ÿæˆä¸ç¨³å®šå…³å¡çš„è¯†åˆ«ä¸ä¿®å¤æ–¹æ³• 

---
# GroupCoOp: Group-robust Fine-tuning via Group Prompt Learning 

**Title (ZH)**: GroupCoOp: ç»„ç¾¤ç¨³å¥å¾®è°ƒé€šè¿‡ç»„æç¤ºå­¦ä¹  

**Authors**: Nayeong Kim, Seong Joon Oh, Suha Kwak  

**Link**: [PDF](https://arxiv.org/pdf/2509.23781)  

**Abstract**: Parameter-efficient fine-tuning (PEFT) of vision-language models (VLMs) excels in various vision tasks thanks to the rich knowledge and generalization ability of VLMs. However, recent studies revealed that such fine-tuned VLMs are vulnerable to spurious correlations stemming from the subgroup imbalance in the fine-tuning datasets. To resolve this issue, we propose Group Context Optimization (GroupCoOp), a simple and effective debiased fine-tuning algorithm that enhances the group robustness of fine-tuned VLMs. Its key idea is to employ group-specific text prompts as group representatives serving as multiple classifiers for their target class. The rich semantic knowledge of the text encoder of VLM enables the discovery of effective group prompts even for groups with a small number of training samples. Leveraging the group prompts for each class addresses the issues caused by the group-imbalanced training set, such as the neglect of minority groups and the scattered distribution of each class in the embedding space. GroupCoOp achieved the best results on five benchmarks across five CLIP architectures and occasionally outperformed prior methods that fine-tune the entire network, despite training only 0.016\% of the network's parameters. 

**Abstract (ZH)**: Group Context Optimization (GroupCoOp): A Simple and Effective Debiasing Fine-Tuning Algorithm for Vision-Language Models 

---
# Accuracy-Robustness Trade Off via Spiking Neural Network Gradient Sparsity Trail 

**Title (ZH)**: åŸºäºå°–å³°ç¥ç»ç½‘ç»œæ¢¯åº¦ç¨€ç–æ€§æ¬Šè¡¡çš„ç²¾åº¦-ç¨³å¥æ€§ TRADE-OFF via Spiking Neural Network Gradient Sparsity Trail 

**Authors**: Nhan T. Luu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23762)  

**Abstract**: Spiking Neural Networks (SNNs) have attracted growing interest in both computational neuroscience and artificial intelligence, primarily due to their inherent energy efficiency and compact memory footprint. However, achieving adversarial robustness in SNNs, particularly for vision-related tasks, remains a nascent and underexplored challenge. Recent studies have proposed leveraging sparse gradients as a form of regularization to enhance robustness against adversarial perturbations. In this work, we present a surprising finding: under specific architectural configurations, SNNs exhibit natural gradient sparsity and can achieve state-of-the-art adversarial defense performance without the need for any explicit regularization. Further analysis reveals a trade-off between robustness and generalization: while sparse gradients contribute to improved adversarial resilience, they can impair the model's ability to generalize; conversely, denser gradients support better generalization but increase vulnerability to attacks. 

**Abstract (ZH)**: è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNsï¼‰åœ¨è®¡ç®—ç¥ç»ç§‘å­¦å’Œäººå·¥æ™ºèƒ½é¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œä¸»è¦æ˜¯ç”±äºå…¶å›ºæœ‰çš„èƒ½æºæ•ˆç‡å’Œç´§å‡‘çš„å†…å­˜å ç”¨ã€‚ç„¶è€Œï¼Œç‰¹åˆ«æ˜¯åœ¨è§†è§‰ä»»åŠ¡ä¸­å®ç°å¯¹æŠ—é²æ£’æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæ–°å…´ä¸”å°šæœªå……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ã€‚æœ€è¿‘çš„ç ”ç©¶æå‡ºï¼Œåˆ©ç”¨ç¨€ç–æ¢¯åº¦ä½œä¸ºæ­£åˆ™åŒ–çš„ä¸€ç§å½¢å¼ï¼Œä»¥å¢å¼ºå¯¹å¯¹æŠ—æ€§æ‰°åŠ¨çš„é²æ£’æ€§ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºä¸€ä¸ªä»¤äººæƒŠè®¶çš„å‘ç°ï¼šåœ¨ç‰¹å®šçš„æ¶æ„é…ç½®ä¸‹ï¼ŒSNNsè¡¨ç°å‡ºè‡ªç„¶çš„æ¢¯åº¦ç¨€ç–æ€§ï¼Œå¹¶ä¸”åœ¨ä¸éœ€è¦ä»»ä½•æ˜¾å¼æ­£åˆ™åŒ–çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥è¾¾åˆ°æœ€å…ˆè¿›çš„å¯¹æŠ—é˜²å¾¡æ€§èƒ½ã€‚è¿›ä¸€æ­¥çš„åˆ†ææ­ç¤ºäº†é²æ£’æ€§å’Œæ³›åŒ–çš„æƒè¡¡ï¼šè™½ç„¶ç¨€ç–æ¢¯åº¦æœ‰åŠ©äºæé«˜å¯¹æŠ—æ€§é²æ£’æ€§ï¼Œä½†ä¼šå½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼›ç›¸åï¼Œç¨ å¯†çš„æ¢¯åº¦æ”¯æŒæ›´å¥½çš„æ³›åŒ–ï¼Œä½†ä¹Ÿå¢åŠ äº†æ¨¡å‹å¯¹æ”»å‡»çš„è„†å¼±æ€§ã€‚ 

---
# SHAPoint: Task-Agnostic, Efficient, and Interpretable Point-Based Risk Scoring via Shapley Values 

**Title (ZH)**: SHAPoint: ä»»åŠ¡æ— å…³ã€é«˜æ•ˆä¸”å¯è§£é‡Šçš„åŸºäºç‚¹çš„é£é™©è¯„åˆ†æ–¹æ³•é€šè¿‡Shapleyå€¼ 

**Authors**: Tomer D. Meirman, Bracha Shapira, Noa Dagan, Lior S. Rokach  

**Link**: [PDF](https://arxiv.org/pdf/2509.23756)  

**Abstract**: Interpretable risk scores play a vital role in clinical decision support, yet traditional methods for deriving such scores often rely on manual preprocessing, task-specific modeling, and simplified assumptions that limit their flexibility and predictive power. We present SHAPoint, a novel, task-agnostic framework that integrates the predictive accuracy of gradient boosted trees with the interpretability of point-based risk scores. SHAPoint supports classification, regression, and survival tasks, while also inheriting valuable properties from tree-based models, such as native handling of missing data and support for monotonic constraints. Compared to existing frameworks, SHAPoint offers superior flexibility, reduced reliance on manual preprocessing, and faster runtime performance. Empirical results show that SHAPoint produces compact and interpretable scores with predictive performance comparable to state-of-the-art methods, but at a fraction of the runtime, making it a powerful tool for transparent and scalable risk stratification. 

**Abstract (ZH)**: å¯è§£é‡Šçš„é£é™©è¯„åˆ†åœ¨ä¸´åºŠå†³ç­–æ”¯æŒä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•å¸¸ä¾èµ–äºæ‰‹åŠ¨é¢„å¤„ç†ã€ä»»åŠ¡ç‰¹å®šå»ºæ¨¡å’Œç®€åŒ–å‡è®¾ï¼Œè¿™é™åˆ¶äº†å…¶çµæ´»æ€§å’Œé¢„æµ‹èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºSHAPointçš„æ–°å‹ã€ä»»åŠ¡æ— å…³æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ¢¯åº¦æå‡æ ‘çš„é¢„æµ‹å‡†ç¡®æ€§å’Œç‚¹åŸºé£é™©è¯„åˆ†çš„å¯è§£é‡Šæ€§ã€‚SHAPointæ”¯æŒåˆ†ç±»ã€å›å½’å’Œç”Ÿå­˜ä»»åŠ¡ï¼ŒåŒæ—¶ç»§æ‰¿äº†åŸºäºæ ‘æ¨¡å‹çš„å¤©ç„¶ç¼ºå¤±æ•°æ®å¤„ç†èƒ½åŠ›å’Œå•è°ƒçº¦æŸæ”¯æŒã€‚ä¸ç°æœ‰æ¡†æ¶ç›¸æ¯”ï¼ŒSHAPointæä¾›äº†æ›´é«˜çš„çµæ´»æ€§ã€å‡å°‘äº†å¯¹æ‰‹åŠ¨é¢„å¤„ç†çš„ä¾èµ–ï¼Œå¹¶å…·æœ‰æ›´å¿«çš„è¿è¡Œæ—¶æ€§èƒ½ã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒSHAPointäº§ç”Ÿçš„ç´§å‡‘ä¸”å…·æœ‰è§£é‡Šæ€§çš„è¯„åˆ†åœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ï¼Œä½†è¿è¡Œæ—¶é—´å´å¤§å¹…ç¼©å‡ï¼Œä½¿å…¶æˆä¸ºä¸€ç§å¼ºå¤§çš„é€æ˜ä¸”å¯æ‰©å±•çš„é£é™©åˆ†å±‚å·¥å…·ã€‚ 

---
# AdaPtis: Reducing Pipeline Bubbles with Adaptive Pipeline Parallelism on Heterogeneous Models 

**Title (ZH)**: AdaPtis: é™ä½å¼‚æ„æ¨¡å‹æµæ°´çº¿æ°”æ³¡çš„æ–¹æ³•åŸºäºè‡ªé€‚åº”æµæ°´çº¿å¹¶è¡Œæ€§ 

**Authors**: Jihu Guo, Tenghui Ma, Wei Gao, Peng Sun, Jiaxing Li, Xun Chen, Yuyang Jin, Dahua Lin  

**Link**: [PDF](https://arxiv.org/pdf/2509.23722)  

**Abstract**: Pipeline parallelism is widely used to train large language models (LLMs). However, increasing heterogeneity in model architectures exacerbates pipeline bubbles, thereby reducing training efficiency. Existing approaches overlook the co-optimization of model partition, model placement, and workload scheduling, resulting in limited efficiency improvement or even performance degradation. To respond, we propose AdaPtis, an LLM training system that supports adaptive pipeline parallelism. First, we develop a pipeline performance model to accurately estimate training throughput. Second, AdaPtis jointly optimizes model partition, model placement, and workload scheduling policies guided by this performance model. Third, we design a unified pipeline executor that efficiently supports the execution of diverse pipeline strategies. Extensive experiments show that AdaPtis achieves an average speedup of 1.42x (up to 2.14x) over Megatron-LM I-1F1B across various LLM architectures and scales. 

**Abstract (ZH)**: AdaPtisï¼šä¸€ç§æ”¯æŒè‡ªé€‚åº”ç®¡é“å¹¶è¡Œæ€§çš„å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒç³»ç»Ÿ 

---
# Bridging Discrete and Continuous RL: Stable Deterministic Policy Gradient with Martingale Characterization 

**Title (ZH)**: ç¦»æ•£ä¸è¿ç»­RLçš„æ¡¥æ¢ï¼šå…·æœ‰é…ç‰¹å¾çš„ç¨³å®šç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ 

**Authors**: Ziheng Cheng, Xin Guo, Yufei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23711)  

**Abstract**: The theory of discrete-time reinforcement learning (RL) has advanced rapidly over the past decades. Although primarily designed for discrete environments, many real-world RL applications are inherently continuous and complex. A major challenge in extending discrete-time algorithms to continuous-time settings is their sensitivity to time discretization, often leading to poor stability and slow convergence. In this paper, we investigate deterministic policy gradient methods for continuous-time RL. We derive a continuous-time policy gradient formula based on an analogue of the advantage function and establish its martingale characterization. This theoretical foundation leads to our proposed algorithm, CT-DDPG, which enables stable learning with deterministic policies in continuous-time environments. Numerical experiments show that the proposed CT-DDPG algorithm offers improved stability and faster convergence compared to existing discrete-time and continuous-time methods, across a wide range of control tasks with varying time discretizations and noise levels. 

**Abstract (ZH)**: è¿ç»­æ—¶é—´å¼ºåŒ–å­¦ä¹ ä¸­çš„ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦æ–¹æ³• 

---
# Estimating Time Series Foundation Model Transferability via In-Context Learning 

**Title (ZH)**: åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹è¿ç§»æ€§ä¼°æµ‹ 

**Authors**: Qingren Yao, Ming Jin, Chengqi Zhang, Chao-Han Huck Yang, Jun Qi, Shirui Pan  

**Link**: [PDF](https://arxiv.org/pdf/2509.23695)  

**Abstract**: Time series foundation models (TSFMs) offer strong zero-shot forecasting via large-scale pre-training, yet fine-tuning remains critical for boosting performance in domains with limited public data. With the growing number of TSFMs, efficiently identifying the best model for downstream fine-tuning becomes increasingly challenging. In this work, we introduce TimeTic, a transferability estimation framework that recasts model selection as an in-context-learning problem: given observations on known (source) datasets, it predicts how a TSFM will perform after fine-tuning on a downstream (target) dataset. TimeTic flexibly organizes the observed model-data relationships as contextual information, allowing it to adapt seamlessly to various test-time scenarios. Leveraging the natural tabular structure formed by dataset meta-features, model characteristics, and fine-tuned performance, we employ tabular foundation models to serve as in-context learners. We further introduce a novel model characterization based on entropy evolution across model layers, capturing embedding-space distinctions and enabling TimeTic to generalize across arbitrary model sets. We establish a comprehensive benchmark for transferability estimation including 10 datasets, 10 foundation models, and 3 forecasting tasks. On this benchmark, TimeTic's estimation demonstrates strong alignment with actual fine-tuned performance for previously unseen datasets, achieving a mean rank correlation of approximately 0.6 and a 30% improvement compared to using zero-shot performance as the transferability score. 

**Abstract (ZH)**: TimeTicï¼šä¸€ç§æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹è¿ç§»æ€§ä¼°è®¡æ¡†æ¶ 

---
# Joint Hybrid Beamforming and Artificial Noise Design for Secure Multi-UAV ISAC Networks 

**Title (ZH)**: è”åˆæ··åˆæ³¢æŸå½¢æˆä¸äººå·¥å™ªå£°è®¾è®¡ä»¥å®ç°å®‰å…¨çš„å¤šæ— äººæœºå¼‚æ„æ¥å…¥ç½‘ç»œ 

**Authors**: Runze Dong, Buhong Wang, Cunqian Feng, Jiang Weng, Chen Han, Jiwei Tian  

**Link**: [PDF](https://arxiv.org/pdf/2509.23687)  

**Abstract**: Integrated sensing and communication (ISAC) emerges as a key enabler for next-generation applications such as smart cities and autonomous systems. Its integration with unmanned aerial vehicles (UAVs) unlocks new potentials for reliable communication and precise sensing in dynamic aerial environments. However, existing research predominantly treats UAVs as aerial base stations, overlooking their role as ISAC users, and fails to leverage large-scale antenna arrays at terrestrial base stations to enhance security and spectral efficiency. This paper propose a secure and spectral efficient ISAC framework for multi-UAV networks, and a two-stage optimization approach is developed to jointly design hybrid beamforming (HBF), artificial noise (AN) injection, and UAV trajectories. Aiming at maximizing the sum secrecy rate, the first stage employs Proximal Policy Optimization (PPO) to optimize digital beamformers and trajectories, and the second stage decomposes the digital solution into analog and digital components via low-complexity matrix factorization. Simulation results demonstrate the effectiveness of the proposed framework compared to benchmark schemes. 

**Abstract (ZH)**: é›†æˆä¼ æ„Ÿä¸é€šä¿¡(ISAC)æŠ€æœ¯æˆä¸ºæ™ºèƒ½åŸå¸‚å’Œè‡ªä¸»ç³»ç»Ÿç­‰ä¸‹ä¸€ä»£åº”ç”¨çš„å…³é”®ä½¿èƒ½å™¨ã€‚å°†å…¶ä¸æ— äººé©¾é©¶é£è¡Œå™¨(UAVs)ç»“åˆï¼Œä¸ºåŠ¨æ€é«˜ç©ºç¯å¢ƒä¸‹çš„å¯é é€šä¿¡å’Œç²¾ç¡®ä¼ æ„Ÿå¼€å¯äº†æ–°æ½œèƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä¸»è¦å°†UAVsè§†ä¸ºé«˜ç©ºåŸºç«™ï¼Œå¿½è§†äº†å…¶ä½œä¸ºISACç”¨æˆ·çš„è§’è‰²ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨åœ°é¢åŸºç«™çš„å¤§è§„æ¨¡å¤©çº¿é˜µåˆ—ä»¥æå‡å®‰å…¨æ€§å’Œé¢‘è°±æ•ˆç‡ã€‚æœ¬æ–‡æå‡ºä¸€ç§é€‚ç”¨äºå¤šUAVç½‘ç»œçš„ä¿å¯†æ€§å’Œé¢‘è°±æ•ˆç‡å…¼å¤‡çš„ISACæ¡†æ¶ï¼Œå¹¶å¼€å‘äº†ä¸€ç§ä¸¤é˜¶æ®µä¼˜åŒ–æ–¹æ³•ï¼Œä»¥è”åˆè®¾è®¡æ··åˆæ³¢æŸå½¢æˆ(HBF)ã€äººå·¥å™ªå£°(AN)æ³¨å…¥å’ŒUAVèˆªè¿¹ã€‚ä¸ºæœ€å¤§åŒ–æ€»ä¿å¯†ç‡ï¼Œç¬¬ä¸€é˜¶æ®µé‡‡ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(Proximal Policy Optimization, PPO)ä¼˜åŒ–æ•°å­—æ³¢æŸå½¢æˆå™¨å’Œèˆªè¿¹ï¼Œç¬¬äºŒé˜¶æ®µé€šè¿‡ä½å¤æ‚åº¦çŸ©é˜µåˆ†è§£å°†æ•°å­—è§£å†³æ–¹æ¡ˆåˆ†è§£ä¸ºæ¨¡æ‹Ÿå’Œæ•°å­—ç»„ä»¶ã€‚ä»¿çœŸç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºæ¡†æ¶çš„æœ‰æ•ˆæ€§ä¼˜äºåŸºå‡†æ–¹æ¡ˆã€‚ 

---
# Graph Neural Networks with Diversity-aware Neighbor Selection and Dynamic Multi-scale Fusion for Multivariate Time Series Forecasting 

**Title (ZH)**: å…·æœ‰å¤šæ ·æ€§æ„è¯†çš„é‚»åŸŸé€‰æ‹©å’ŒåŠ¨æ€å¤šå°ºåº¦èåˆçš„å›¾ç¥ç»ç½‘ç»œåœ¨å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨ 

**Authors**: Jingqi Xu, Guibin Chen, Jingxi Lu, Yuzhang Lin  

**Link**: [PDF](https://arxiv.org/pdf/2509.23671)  

**Abstract**: Recently, numerous deep models have been proposed to enhance the performance of multivariate time series (MTS) forecasting. Among them, Graph Neural Networks (GNNs)-based methods have shown great potential due to their capability to explicitly model inter-variable dependencies. However, these methods often overlook the diversity of information among neighbors, which may lead to redundant information aggregation. In addition, their final prediction typically relies solely on the representation from a single temporal scale. To tackle these issues, we propose a Graph Neural Networks (GNNs) with Diversity-aware Neighbor Selection and Dynamic Multi-scale Fusion (DIMIGNN). DIMIGNN introduces a Diversity-aware Neighbor Selection Mechanism (DNSM) to ensure that each variable shares high informational similarity with its neighbors while maintaining diversity among neighbors themselves. Furthermore, a Dynamic Multi-Scale Fusion Module (DMFM) is introduced to dynamically adjust the contributions of prediction results from different temporal scales to the final forecasting result. Extensive experiments on real-world datasets demonstrate that DIMIGNN consistently outperforms prior methods. 

**Abstract (ZH)**: åŸºäºå¤šæ ·æ€§awareé‚»å±…é€‰æ‹©å’ŒåŠ¨æ€å¤šå°ºåº¦èåˆçš„å›¾ç¥ç»ç½‘ç»œï¼ˆDIMIGNNï¼‰åŠå…¶åœ¨å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨ 

---
# Beyond Greedy Exits: Improved Early Exit Decisions for Risk Control and Reliability 

**Title (ZH)**: è¶…è¶Šè´ªå©ªé€€å‡ºï¼šæ”¹è¿›çš„é£é™©æ§åˆ¶å’Œå¯é æ€§æ—©æœŸé€€å‡ºå†³ç­– 

**Authors**: Divya Jyoti Bajpai, Manjesh Kumar Hanawal  

**Link**: [PDF](https://arxiv.org/pdf/2509.23666)  

**Abstract**: Early-Exit Deep Neural Networks enable adaptive inference by allowing prediction at intermediary layers, significantly reducing computational costs and latency. Most of the early exit strategies greedily exit a sample at an intermediary layer if the confidence in class prediction exceeds a predefined threshold that is set using a static validation set. This is problematic as the model might be overconfident in a wrong class. Also, they are not robust to distribution shifts encountered in deployment, which can undermine model trustworthiness and accuracy. To address these challenges, we propose UAT that adapts the threshold for exit decisions using a Multi-Armed Bandit framework, enabling online, unsupervised adjustment of exit decisions. UAT makes decisions based on a new reward function that assesses predictive certainty and its reliability to balance computational efficiency and prediction quality while penalizing unnecessary late exits. We provide guarantees on risk achieved by UAT and validate its performance on diverse tasks spanning vision-language understanding, text generation, and classification. Our framework demonstrates consistent improvements in speedup (1.70-2.10x) with a minimal performance drop (<2%) as compared to full model performance. Our source code is available at this https URL. 

**Abstract (ZH)**: åŸºäºå¤šè‡‚è€è™æœºæ¡†æ¶çš„è‡ªé€‚åº”é˜ˆå€¼é€€å‡ºæœºåˆ¶ä½¿æ—©é€€å‡ºæ·±åº¦ç¥ç»ç½‘ç»œèƒ½å¤Ÿåœ¨ä¸­é—´å±‚è¿›è¡Œé¢„æµ‹ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿå¹¶å®ç°é€‚åº”æ€§æ¨ç†ã€‚ç°æœ‰çš„å¤§å¤šæ•°æ—©é€€å‡ºç­–ç•¥åœ¨ç±»é¢„æµ‹ç½®ä¿¡åº¦è¶…è¿‡é¢„è®¾é˜ˆå€¼æ—¶è´ªå©ªåœ°åœ¨ä¸­é—´å±‚é€€å‡ºæ ·æœ¬ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½å¯¼è‡´æ¨¡å‹è¿‡è‡ªä¿¡äºé”™è¯¯çš„ç±»åˆ«ï¼Œå¹¶åœ¨éƒ¨ç½²æ—¶é‡åˆ°åˆ†å¸ƒåç§»æ—¶ç¼ºä¹é²æ£’æ€§ï¼Œä»è€Œå½±å“æ¨¡å‹çš„ä¿¡ä»»å’Œå‡†ç¡®æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šè‡‚è€è™æœºæ¡†æ¶çš„è‡ªé€‚åº”é˜ˆå€¼ï¼ˆUATï¼‰æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€ç›‘ç£çš„æƒ…å†µä¸‹åœ¨çº¿è°ƒæ•´é€€å‡ºå†³ç­–ï¼Œå¹¶åŸºäºæ–°çš„å¥–åŠ±å‡½æ•°è¯„ä¼°é¢„æµ‹çš„ç¡®å®šæ€§å’Œå¯é æ€§æ¥å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œé¢„æµ‹è´¨é‡ï¼ŒåŒæ—¶æƒ©ç½šä¸å¿…è¦çš„å»¶è¿Ÿé€€å‡ºã€‚æˆ‘ä»¬æä¾›äº†UATå®ç°çš„é£é™©ä¿è¯ï¼Œå¹¶åœ¨è§†è§‰-è¯­è¨€ç†è§£ã€æ–‡æœ¬ç”Ÿæˆå’Œåˆ†ç±»ç­‰å¤šæ ·ä»»åŠ¡ä¸­éªŒè¯äº†å…¶æ€§èƒ½ã€‚ä¸å…¨æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨ä¿è¯æ€§èƒ½æŸå¤±å°äº2%çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†1.70-2.10å€çš„åŠ é€Ÿã€‚æºä»£ç å¯è®¿é—®æ­¤é“¾æ¥ã€‚ 

---
# Calibration Meets Reality: Making Machine Learning Predictions Trustworthy 

**Title (ZH)**: æ ¡å‡†é‡è§ç°å®ï¼šä½¿æœºå™¨å­¦ä¹ é¢„æµ‹å€¼å¾—ä¿¡èµ– 

**Authors**: Kristina P. Sinaga, Arjun S. Nair  

**Link**: [PDF](https://arxiv.org/pdf/2509.23665)  

**Abstract**: Post-hoc calibration methods are widely used to improve the reliability of probabilistic predictions from machine learning models. Despite their prevalence, a comprehensive theoretical understanding of these methods remains elusive, particularly regarding their performance across different datasets and model architectures. Input features play a crucial role in shaping model predictions and, consequently, their calibration. However, the interplay between feature quality and calibration performance has not been thoroughly investigated. In this work, we present a rigorous theoretical analysis of post-hoc calibration methods, focusing on Platt scaling and isotonic regression. We derive convergence guarantees, computational complexity bounds, and finite-sample performance metrics for these methods. Furthermore, we explore the impact of feature informativeness on calibration performance through controlled synthetic experiments. Our empirical evaluation spans a diverse set of real-world datasets and model architectures, demonstrating consistent improvements in calibration metrics across various scenarios. By examining calibration performance under varying feature conditions utilizing only informative features versus complete feature spaces including noise dimensions, we provide fundamental insights into the robustness and reliability of different calibration approaches. Our findings offer practical guidelines for selecting appropriate calibration methods based on dataset characteristics and computational constraints, bridging the gap between theoretical understanding and practical implementation in uncertainty quantification. Code and experimental data are available at: this https URL. 

**Abstract (ZH)**: äº‹åæ ¡å‡†æ–¹æ³•å¹¿æ³›ç”¨äºæé«˜æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¦‚ç‡é¢„æµ‹å¯é æ€§ã€‚å°½ç®¡è¿™äº›æ–¹æ³•è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†å¯¹å…¶åœ¨ä¸åŒæ•°æ®é›†å’Œæ¨¡å‹æ¶æ„ä¸Šçš„è¡¨ç°çš„å…¨é¢ç†è®ºç†è§£ä»ç¼ºä¹ï¼Œç‰¹åˆ«æ˜¯å…³äºç‰¹å¾è´¨é‡ä¸æ ¡å‡†æ€§èƒ½ä¹‹é—´çš„å…³ç³»ã€‚è¾“å…¥ç‰¹å¾åœ¨å¡‘é€ æ¨¡å‹é¢„æµ‹å’Œæ ¡å‡†æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ï¼Œä½†ç‰¹å¾è´¨é‡å’Œæ ¡å‡†æ€§èƒ½ä¹‹é—´çš„ç›¸äº’ä½œç”¨å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¯¹äº‹åæ ¡å‡†æ–¹æ³•è¿›è¡Œäº†ä¸¥æ ¼çš„ç†è®ºåˆ†æï¼Œé›†ä¸­äºPlattæ ¡å‡†å’Œç­‰è·å›å½’ã€‚æˆ‘ä»¬æ¨å¯¼äº†è¿™äº›æ–¹æ³•çš„æ”¶æ•›ä¿è¯ã€è®¡ç®—å¤æ‚åº¦è¾¹ç•Œå’Œæœ‰é™æ ·æœ¬æ€§èƒ½åº¦é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å—æ§çš„åˆæˆå®éªŒæ¢è®¨äº†ç‰¹å¾ä¿¡æ¯é‡å¯¹æ ¡å‡†æ€§èƒ½çš„å½±å“ã€‚æˆ‘ä»¬çš„å®è¯è¯„ä¼°æ¶µç›–äº†å¤šç§çœŸå®ä¸–ç•Œçš„æ•°æ®é›†å’Œæ¨¡å‹æ¶æ„ï¼Œå±•ç¤ºäº†åœ¨å„ç§åœºæ™¯ä¸‹æ ¡å‡†æŒ‡æ ‡çš„ä¸€è‡´æ€§æ”¹è¿›ã€‚é€šè¿‡åœ¨ä»…ä½¿ç”¨ä¿¡æ¯ç‰¹å¾ä¸åŒ…å«å™ªå£°ç»´åº¦çš„å®Œæ•´ç‰¹å¾ç©ºé—´ä¸‹è€ƒå¯Ÿä¸åŒæ ¡å‡†æ–¹æ³•çš„æ ¡å‡†æ€§èƒ½ï¼Œæˆ‘ä»¬æä¾›äº†å…³äºä¸åŒæ ¡å‡†æ–¹æ³•çš„ç¨³å¥æ€§å’Œå¯é æ€§çš„é‡è¦è§è§£ã€‚æˆ‘ä»¬çš„å‘ç°ä¸ºåŸºäºæ•°æ®é›†ç‰¹æ€§å’Œè®¡ç®—çº¦æŸé€‰æ‹©åˆé€‚çš„æ ¡å‡†æ–¹æ³•æä¾›äº†å®ç”¨æŒ‡å—ï¼Œå¡«è¡¥äº†ç†è®ºç†è§£å’Œå®é™…å®æ–½åœ¨ä¸ç¡®å®šæ€§é‡åŒ–ä¸­çš„å·®è·ã€‚ä»£ç å’Œå®éªŒæ•°æ®å¯åœ¨ï¼šthis https URL è·å–ã€‚ 

---
# Pure Node Selection for Imbalanced Graph Node Classification 

**Title (ZH)**: æ— åèŠ‚ç‚¹é€‰æ‹©çš„å›¾èŠ‚ç‚¹åˆ†ç±» 

**Authors**: Fanlong Zeng, Wensheng Gan, Jiayang Wu, Philip S. Yu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23662)  

**Abstract**: The problem of class imbalance refers to an uneven distribution of quantity among classes in a dataset, where some classes are significantly underrepresented compared to others. Class imbalance is also prevalent in graph-structured data. Graph neural networks (GNNs) are typically based on the assumption of class balance, often overlooking the issue of class imbalance. In our investigation, we identified a problem, which we term the Randomness Anomalous Connectivity Problem (RACP), where certain off-the-shelf models are affected by random seeds, leading to a significant performance degradation. To eliminate the influence of random factors in algorithms, we proposed PNS (Pure Node Sampling) to address the RACP in the node synthesis stage. Unlike existing approaches that design specialized algorithms to handle either quantity imbalance or topological imbalance, PNS is a novel plug-and-play module that operates directly during node synthesis to mitigate RACP. Moreover, PNS also alleviates performance degradation caused by abnormal distribution of node neighbors. We conduct a series of experiments to identify what factors are influenced by random seeds. Experimental results demonstrate the effectiveness and stability of our method, which not only eliminates the effect of unfavorable random seeds but also outperforms the baseline across various benchmark datasets with different GNN backbones. Data and code are available at this https URL. 

**Abstract (ZH)**: ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜æŒ‡çš„æ˜¯æ•°æ®é›†ä¸­å„ç±»åˆ«æ•°é‡åˆ†å¸ƒä¸å‡ï¼Œå…¶ä¸­æŸäº›ç±»åˆ«ç›¸è¾ƒäºå…¶ä»–ç±»åˆ«æ˜¾è‘—æ¬ ä»£è¡¨ã€‚ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜åœ¨å›¾ç»“æ„æ•°æ®ä¸­ä¹Ÿå¾ˆå¸¸è§ã€‚å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰é€šå¸¸åŸºäºç±»åˆ«å¹³è¡¡çš„å‡è®¾ï¼Œå¸¸å¿½è§†ç±»åˆ«ä¸å¹³è¡¡çš„é—®é¢˜ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œç§°ä¹‹ä¸ºéšæœºå¼‚å¸¸è¿æ¥é—®é¢˜ï¼ˆRACPï¼‰ï¼ŒæŸäº›ç°æˆæ¨¡å‹å—éšæœºç§å­å½±å“ï¼Œå¯¼è‡´æ˜¾è‘—æ€§èƒ½ä¸‹é™ã€‚ä¸ºæ¶ˆé™¤ç®—æ³•ä¸­éšæœºå› ç´ çš„å½±å“ï¼Œæˆ‘ä»¬æå‡ºäº†PNSï¼ˆçº¯èŠ‚ç‚¹é‡‡æ ·ï¼‰æ¥è§£å†³RACPé—®é¢˜ã€‚PNSä¸åŒäºç°æœ‰çš„ä¸“ä¸ºå¤„ç†æ•°é‡ä¸å¹³è¡¡æˆ–æ‹“æ‰‘ä¸å¹³è¡¡è®¾è®¡çš„ç®—æ³•ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ–°é¢–çš„å³æ’å³ç”¨æ¨¡å—ï¼Œåœ¨èŠ‚ç‚¹åˆæˆé˜¶æ®µç›´æ¥è¿è¡Œä»¥ç¼“è§£RACPã€‚æ­¤å¤–ï¼ŒPNSè¿˜èƒ½ç¼“è§£ç”±äºèŠ‚ç‚¹é‚»å±…å¼‚å¸¸åˆ†å¸ƒå¯¼è‡´çš„æ€§èƒ½ä¸‹é™ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€ç³»åˆ—å®éªŒä»¥ç¡®å®šå“ªäº›å› ç´ å—éšæœºç§å­å½±å“ã€‚å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ï¼Œä¸ä»…æ¶ˆé™¤äº†ä¸åˆ©éšæœºç§å­çš„å½±å“ï¼Œè¿˜åœ¨ä¸åŒGNNåç«¯çš„ä¸åŒåŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æ•°æ®å’Œä»£ç å¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ã€‚ 

---
# LightFair: Towards an Efficient Alternative for Fair T2I Diffusion via Debiasing Pre-trained Text Encoders 

**Title (ZH)**: LightFair: å‘é«˜æ•ˆå…¬å¹³çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£è½¬åŒ–çš„å»åè§é¢„è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨æ›¿ä»£æ–¹æ¡ˆ 

**Authors**: Boyu Han, Qianqian Xu, Shilong Bao, Zhiyong Yang, Kangli Zi, Qingming Huang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23639)  

**Abstract**: This paper explores a novel lightweight approach LightFair to achieve fair text-to-image diffusion models (T2I DMs) by addressing the adverse effects of the text encoder. Most existing methods either couple different parts of the diffusion model for full-parameter training or rely on auxiliary networks for correction. They incur heavy training or sampling burden and unsatisfactory performance. Since T2I DMs consist of multiple components, with the text encoder being the most fine-tunable and front-end module, this paper focuses on mitigating bias by fine-tuning text embeddings. To validate feasibility, we observe that the text encoder's neutral embedding output shows substantial skewness across image embeddings of various attributes in the CLIP space. More importantly, the noise prediction network further amplifies this imbalance. To finetune the text embedding, we propose a collaborative distance-constrained debiasing strategy that balances embedding distances to improve fairness without auxiliary references. However, mitigating bias can compromise the original generation quality. To address this, we introduce a two-stage text-guided sampling strategy to limit when the debiased text encoder intervenes. Extensive experiments demonstrate that LightFair is effective and efficient. Notably, on Stable Diffusion v1.5, our method achieves SOTA debiasing at just $1/4$ of the training burden, with virtually no increase in sampling burden. The code is available at this https URL. 

**Abstract (ZH)**: ä¸€ç§æ–°å‹è½»é‡çº§æ–¹æ³•LightFairå®ç°å…¬å¹³çš„æ–‡å­—åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ 

---
# Generalizable Speech Deepfake Detection via Information Bottleneck Enhanced Adversarial Alignment 

**Title (ZH)**: åŸºäºä¿¡æ¯ç“¶é¢ˆå¢å¼ºå¯¹æŠ—å¯¹é½çš„é€šç”¨è¯­éŸ³æ·±åº¦å‡å£°æ£€æµ‹ 

**Authors**: Pu Huang, Shouguang Wang, Siya Yao, Mengchu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.23618)  

**Abstract**: Neural speech synthesis techniques have enabled highly realistic speech deepfakes, posing major security risks. Speech deepfake detection is challenging due to distribution shifts across spoofing methods and variability in speakers, channels, and recording conditions. We explore learning shared discriminative features as a path to robust detection and propose Information Bottleneck enhanced Confidence-Aware Adversarial Network (IB-CAAN). Confidence-guided adversarial alignment adaptively suppresses attack-specific artifacts without erasing discriminative cues, while the information bottleneck removes nuisance variability to preserve transferable features. Experiments on ASVspoof 2019/2021, ASVspoof 5, and In-the-Wild demonstrate that IB-CAAN consistently outperforms baseline and achieves state-of-the-art performance on many benchmarks. 

**Abstract (ZH)**: ç¥ç»è¯­éŸ³åˆæˆæŠ€æœ¯å‚¬ç”Ÿäº†é«˜åº¦é€¼çœŸçš„è¯­éŸ³æ·±ä¼ªï¼Œå¼•å‘äº†é‡å¤§å®‰å…¨é£é™©ã€‚ç”±äºæ¬ºéª—æ–¹æ³•ã€è¯´è¯äººã€ä¿¡é“å’Œå½•éŸ³æ¡ä»¶çš„åˆ†å¸ƒå˜åŒ–ï¼Œè¯­éŸ³æ·±ä¼ªæ£€æµ‹å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æˆ‘ä»¬æ¢ç´¢å­¦ä¹ å…±äº«é‰´åˆ«ç‰¹å¾ä½œä¸ºç¨³å¥æ£€æµ‹çš„æ–¹æ³•ï¼Œå¹¶æå‡ºä¿¡æ¯ç“¶é¢ˆå¢å¼ºçš„ç½®ä¿¡æ„ŸçŸ¥å¯¹æŠ—ç½‘ç»œï¼ˆIB-CAANï¼‰ã€‚ç½®ä¿¡å¯¼å‘çš„å¯¹æŠ—å¯¹é½è‡ªé€‚åº”åœ°æŠ‘åˆ¶æ”»å‡»ç‰¹å®šçš„-artifactsï¼ŒåŒæ—¶ä¸æŠ¹é™¤é‰´åˆ«çº¿ç´¢ï¼Œä¿¡æ¯ç“¶é¢ˆå»é™¤æ— å…³å˜å¼‚ï¼Œä¿ç•™å¯è¿ç§»ç‰¹å¾ã€‚å®éªŒè¡¨æ˜ï¼ŒIB-CAAN åœ¨ ASVspoof 2019/2021ã€ASVspoof 5 å’Œåœ¨é‡æ•°æ®ä¸Šçš„è¡¨ç°å‡ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¹¶åœ¨è®¸å¤šåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚ 

---
# GraphIFE: Rethinking Graph Imbalance Node Classification via Invariant Learning 

**Title (ZH)**: GraphIFE: é€šè¿‡ä¸å˜å­¦ä¹ é‡æ–°æ€è€ƒå›¾çš„ä¸å‡è¡¡èŠ‚ç‚¹åˆ†ç±» 

**Authors**: Fanlong Zeng, Wensheng Gan, Philip S. Yu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23616)  

**Abstract**: The class imbalance problem refers to the disproportionate distribution of samples across different classes within a dataset, where the minority classes are significantly underrepresented. This issue is also prevalent in graph-structured data. Most graph neural networks (GNNs) implicitly assume a balanced class distribution and therefore often fail to account for the challenges introduced by class imbalance, which can lead to biased learning and degraded performance on minority classes. We identify a quality inconsistency problem in synthesized nodes, which leads to suboptimal performance under graph imbalance conditions. To mitigate this issue, we propose GraphIFE (Graph Invariant Feature Extraction), a novel framework designed to mitigate quality inconsistency in synthesized nodes. Our approach incorporates two key concepts from graph invariant learning and introduces strategies to strengthen the embedding space representation, thereby enhancing the model's ability to identify invariant features. Extensive experiments demonstrate the framework's efficiency and robust generalization, as GraphIFE consistently outperforms various baselines across multiple datasets. The code is publicly available at this https URL. 

**Abstract (ZH)**: ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜æŒ‡çš„æ˜¯æ•°æ®é›†ä¸­ä¸åŒç±»åˆ«æ ·æœ¬åˆ†å¸ƒä¸å‡ï¼Œå…¶ä¸­å°‘æ•°ç±»æ˜¾è‘—æ¬ ä»£è¡¨æ€§ã€‚è¿™ä¸€é—®é¢˜åœ¨å›¾ç»“æ„æ•°æ®ä¸­ä¹Ÿéå¸¸æ™®éã€‚å¤§å¤šæ•°å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰éšå«åœ°å‡è®¾ç±»åˆ«åˆ†å¸ƒå‡è¡¡ï¼Œå› æ­¤å¾€å¾€æœªèƒ½å……åˆ†è€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œè¿™å¯èƒ½å¯¼è‡´å¯¹å°‘æ•°ç±»çš„å­¦ä¹ åå·®å’Œæ€§èƒ½é€€åŒ–ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºåˆæˆèŠ‚ç‚¹è´¨é‡ä¸ä¸€è‡´æ€§é—®é¢˜ï¼Œè¿™åœ¨å›¾ç»“æ„ä¸å¹³è¡¡æ¡ä»¶ä¸‹ä¼šå¯¼è‡´æ¬¡ä¼˜æ€§èƒ½ã€‚ä¸ºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶GraphIFEï¼ˆå›¾ä¸å˜ç‰¹å¾æå–ï¼‰ï¼Œæ—¨åœ¨ç¼“è§£åˆæˆèŠ‚ç‚¹çš„è´¨é‡ä¸ä¸€è‡´æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†å›¾ä¸å˜å­¦ä¹ ä¸­çš„ä¸¤ä¸ªå…³é”®æ¦‚å¿µï¼Œå¹¶å¼•å…¥ç­–ç•¥ä»¥å¢å¼ºåµŒå…¥ç©ºé—´è¡¨ç¤ºï¼Œä»è€Œæé«˜æ¨¡å‹è¯†åˆ«ä¸å˜ç‰¹å¾çš„èƒ½åŠ›ã€‚å¹¿æ³›çš„å®éªŒå±•ç¤ºäº†è¯¥æ¡†æ¶çš„æ•ˆç‡å’Œç¨³å¥çš„æ³›åŒ–èƒ½åŠ›ï¼ŒGraphIFEåœ¨å¤šä¸ªæ•°æ®é›†ä¸­å‡ä¼˜äºå„ç§åŸºçº¿ã€‚ä»£ç å¯åœ¨ä»¥ä¸‹ç½‘å€è·å–ã€‚ 

---
# Characteristic Root Analysis and Regularization for Linear Time Series Forecasting 

**Title (ZH)**: çº¿æ€§æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ç‰¹å¾æ ¹åˆ†æä¸æ­£åˆ™åŒ– 

**Authors**: Zheng Wang, Kaixuan Zhang, Wanfang Chen, Xiaonan Lu, Longyuan Li, Tobias Schlagenhauf  

**Link**: [PDF](https://arxiv.org/pdf/2509.23597)  

**Abstract**: Time series forecasting remains a critical challenge across numerous domains, yet the effectiveness of complex models often varies unpredictably across datasets. Recent studies highlight the surprising competitiveness of simple linear models, suggesting that their robustness and interpretability warrant deeper theoretical investigation. This paper presents a systematic study of linear models for time series forecasting, with a focus on the role of characteristic roots in temporal dynamics. We begin by analyzing the noise-free setting, where we show that characteristic roots govern long-term behavior and explain how design choices such as instance normalization and channel independence affect model capabilities. We then extend our analysis to the noisy regime, revealing that models tend to produce spurious roots. This leads to the identification of a key data-scaling property: mitigating the influence of noise requires disproportionately large training data, highlighting the need for structural regularization. To address these challenges, we propose two complementary strategies for robust root restructuring. The first uses rank reduction techniques, including Reduced-Rank Regression and Direct Weight Rank Reduction, to recover the low-dimensional latent dynamics. The second, a novel adaptive method called Root Purge, encourages the model to learn a noise-suppressing null space during training. Extensive experiments on standard benchmarks demonstrate the effectiveness of both approaches, validating our theoretical insights and achieving state-of-the-art results in several settings. Our findings underscore the potential of integrating classical theories for linear systems with modern learning techniques to build robust, interpretable, and data-efficient forecasting models. 

**Abstract (ZH)**: æ—¶é—´åºåˆ—é¢„æµ‹ä»ç„¶æ˜¯è¯¸å¤šé¢†åŸŸä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œä½†å¤æ‚æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§å¾€å¾€ä¸å¯é¢„æµ‹ã€‚è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œç®€å•çš„çº¿æ€§æ¨¡å‹è¡¨ç°å‡ºä»¤äººæƒŠè®¶çš„ç«äº‰æ€§ï¼Œè¿™è¡¨æ˜å…¶é²æ£’æ€§å’Œå¯è§£é‡Šæ€§åº”è¿›è¡Œæ›´æ·±å…¥çš„ç†è®ºæ¢è®¨ã€‚æœ¬æ–‡å¯¹çº¿æ€§æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼Œé‡ç‚¹å…³æ³¨ç‰¹å¾æ ¹åœ¨æ—¶åºåŠ¨æ€ä¸­çš„ä½œç”¨ã€‚æˆ‘ä»¬é¦–å…ˆåˆ†æäº†æ— å™ªå£°çš„æƒ…å¢ƒï¼Œè¯æ˜äº†ç‰¹å¾æ ¹å†³å®šäº†é•¿æœŸè¡Œä¸ºï¼Œå¹¶è§£é‡Šäº†è¯¸å¦‚å®ä¾‹å½’ä¸€åŒ–å’Œé€šé“ç‹¬ç«‹æ€§ç­‰è®¾è®¡é€‰æ‹©å¦‚ä½•å½±å“æ¨¡å‹èƒ½åŠ›ã€‚éšåï¼Œæˆ‘ä»¬å°†åˆ†ææ‰©å±•åˆ°äº†æœ‰å™ªå£°çš„æƒ…å¢ƒï¼Œæ­ç¤ºæ¨¡å‹å€¾å‘äºç”Ÿæˆè™šå‡æ ¹ã€‚è¿™å¯¼è‡´æˆ‘ä»¬è¯†åˆ«å‡ºä¸€ä¸ªå…³é”®çš„æ•°æ®ç¼©æ”¾ç‰¹æ€§ï¼šå‡è½»å™ªå£°å½±å“éœ€è¦ä¸æˆæ¯”ä¾‹çš„å¤§é‡è®­ç»ƒæ•°æ®ï¼Œçªæ˜¾äº†ç»“æ„æ­£åˆ™åŒ–çš„éœ€æ±‚ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§äº’è¡¥çš„ç¨³å¥ç‰¹å¾æ ¹é‡æ„ç­–ç•¥ã€‚ç¬¬ä¸€ç§ä½¿ç”¨ç§©çº¦ç®€æŠ€æœ¯ï¼ŒåŒ…æ‹¬é™ç§©å›å½’å’Œç›´æ¥æƒé‡ç§©çº¦ç®€ï¼Œä»¥æ¢å¤ä½ç»´æ½œåœ¨åŠ¨åŠ›ã€‚ç¬¬äºŒç§æ˜¯æ–°é¢–çš„è‡ªé€‚åº”æ–¹æ³•æ ¹å‡€åŒ–ï¼ˆRoot Purgeï¼‰ï¼Œé¼“åŠ±æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´å­¦ä¹ ä¸€ä¸ªæŠ‘åˆ¶å™ªå£°çš„é›¶ç©ºé—´ã€‚åœ¨æ ‡å‡†åŸºå‡†ä¸Šçš„è¯¦å°½å®éªŒè¡¨æ˜ï¼Œè¿™ä¸¤ç§æ–¹æ³•éƒ½è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„ç†è®ºæ´è§ï¼Œå¹¶åœ¨æŸäº›åœºæ™¯ä¸‹è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†å°†ç»å…¸çº¿æ€§ç³»ç»Ÿç†è®ºä¸ç°ä»£å­¦ä¹ æŠ€æœ¯ç»“åˆèµ·æ¥ä»¥æ„å»ºç¨³å¥ã€å¯è§£é‡Šå’Œæ•°æ®é«˜æ•ˆçš„é¢„æµ‹æ¨¡å‹çš„æ½œåŠ›ã€‚ 

---
# Multi-Level Heterogeneous Knowledge Transfer Network on Forward Scattering Center Model for Limited Samples SAR ATR 

**Title (ZH)**: å¤šå±‚æ¬¡å¼‚è´¨çŸ¥è¯†è½¬ç§»ç½‘ç»œåœ¨å‰æ•£å°„ä¸­å¿ƒæ¨¡å‹ä¸‹çš„é™æ ·é›·è¾¾ç„å‡†è¯†åˆ« 

**Authors**: Chenxi Zhao, Daochang Wang, Siqian Zhang, Gangyao Kuang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23596)  

**Abstract**: Simulated data-assisted SAR target recognition methods are the research hotspot currently, devoted to solving the problem of limited samples. Existing works revolve around simulated images, but the large amount of irrelevant information embedded in the images, such as background, noise, etc., seriously affects the quality of the migrated information. Our work explores a new simulated data to migrate purer and key target knowledge, i.e., forward scattering center model (FSCM) which models the actual local structure of the target with strong physical meaning and interpretability. To achieve this purpose, multi-level heterogeneous knowledge transfer (MHKT) network is proposed, which fully migrates FSCM knowledge from the feature, distribution and category levels, respectively. Specifically, we permit the more suitable feature representations for the heterogeneous data and separate non-informative knowledge by task-associated information selector (TAIS), to complete purer target feature migration. In the distribution alignment, the new metric function maximum discrimination divergence (MDD) in target generic knowledge transfer (TGKT) module perceives transferable knowledge efficiently while preserving discriminative structure about classes. Moreover, category relation knowledge transfer (CRKT) module leverages the category relation consistency constraint to break the dilemma of optimization bias towards simulation data due to imbalance between simulated and measured data. Such stepwise knowledge selection and migration will ensure the integrity of the migrated FSCM knowledge. Notably, extensive experiments on two new datasets formed by FSCM data and measured SAR images demonstrate the superior performance of our method. 

**Abstract (ZH)**: åŸºäºæ¨¡æ‹Ÿæ•°æ®è¾…åŠ©çš„SARç›®æ ‡è¯†åˆ«æ–¹æ³•ï¼šæ¢ç´¢çº¯å‡€ç›®æ ‡çŸ¥è¯†è¿ç§»çš„æ–°é€”å¾„ 

---
# Toward a Holistic Approach to Continual Model Merging 

**Title (ZH)**: èµ°å‘ç»¼åˆæ€§çš„æŒç»­æ¨¡å‹åˆå¹¶æ–¹æ³• 

**Authors**: Hoang Phan, Sungmin Cha, Tung Lam Tran, Qi Lei  

**Link**: [PDF](https://arxiv.org/pdf/2509.23592)  

**Abstract**: We present a holistic framework for continual model merging that intervenes at three critical stages: pre-merging, during merging, and post-merging-to address two fundamental challenges in continual learning. In particular, conventional approaches either maintain a growing list of per-domain task vectors, leading to scalability issues or rely solely on weight-space merging when old data is inaccessible, thereby losing crucial functional information. Our method overcomes these limitations by first fine-tuning the main model within its tangent space on domain-specific data; this linearization amplifies per-task weight disentanglement, effectively mitigating across-task interference. During merging, we leverage functional information from available optimizer states beyond mere parameter averages to avoid the need to revisit old data. Finally, a post-merging correction aligns the representation discrepancy between pre- and post-merged models, reducing bias and enhancing overall performance-all while operating under constant memory constraints without accessing historical data. Extensive experiments on standard class-incremental and domain-incremental benchmarks demonstrate that our approach not only achieves competitive performance but also provides a scalable and efficient solution to the catastrophic forgetting problem. 

**Abstract (ZH)**: æˆ‘ä»¬æå‡ºäº†ä¸€ç§é¢å‘æŒç»­å­¦ä¹ çš„é›†æˆæ¨¡å‹å…¨é¢æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¹²é¢„äº†åˆå¹¶å‰ä¸‰ Critial é˜¶æ®µï¼šåˆå¹¶å‰ã€åˆå¹¶ä¸­å’Œåˆå¹¶åï¼Œä»¥åº”å¯¹æŒç»­å­¦ä¹ ä¸­çš„ä¸¤å¤§æ ¹æœ¬æŒ‘æˆ˜ã€‚å…·ä½“è€Œè¨€ï¼Œä¼ ç»Ÿæ–¹æ³•è¦ä¹ˆç»´æŠ¤ä¸€ä¸ªä¸æ–­å¢é•¿çš„é¢†åŸŸç‰¹å®šä»»åŠ¡å‘é‡åˆ—è¡¨ï¼Œå¯¼è‡´å¯æ‰©å±•æ€§é—®é¢˜ï¼Œè¦ä¹ˆä»…ä¾èµ–äºæƒé‡ç©ºé—´çš„åˆå¹¶ï¼Œå½“æ—§æ•°æ®ä¸å¯è®¿é—®æ—¶ä¸¢å¤±é‡è¦çš„åŠŸèƒ½ä¿¡æ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡é¦–å…ˆåœ¨é¢†åŸŸç‰¹å®šæ•°æ®ä¸Šå°†ä¸»æ¨¡å‹åœ¨å…¶åˆ‡çº¿ç©ºé—´å†…è¿›è¡Œå¾®è°ƒï¼Œä»è€Œå…‹æœäº†è¿™äº›é™åˆ¶ï¼›è¿™ç§çº¿æ€§åŒ–å¢å¼ºäº†ä»»åŠ¡é—´æƒé‡çš„åˆ†ç¦»ï¼Œæœ‰æ•ˆåœ°é™ä½äº†è·¨ä»»åŠ¡å¹²æ‰°ã€‚åœ¨åˆå¹¶è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å¯ç”¨ä¼˜åŒ–å™¨çŠ¶æ€ä¸­çš„åŠŸèƒ½ä¿¡æ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯å‚æ•°å¹³å‡å€¼ï¼Œä»¥é¿å…é‡æ–°è®¿é—®æ—§æ•°æ®ã€‚æœ€åï¼Œåœ¨åˆå¹¶åï¼Œé€šè¿‡æ ¡å‡†åˆå¹¶å‰å’Œåˆå¹¶åæ¨¡å‹ä¹‹é—´çš„è¡¨ç¤ºå·®å¼‚ï¼Œå‡å°‘åå·®å¹¶æé«˜æ•´ä½“æ€§èƒ½ï¼ŒåŒæ—¶åœ¨ä¸è®¿é—®å†å²æ•°æ®çš„æƒ…å†µä¸‹ä¿æŒæ’å®šçš„å†…å­˜çº¦æŸã€‚åœ¨æ ‡å‡†çš„ç±»å¢é‡å’Œé¢†åŸŸå¢é‡åŸºå‡†æµ‹è¯•ä¸­çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…å®ç°äº†ç«äº‰åŠ›çš„è¡¨ç°ï¼Œè¿˜æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é«˜æ•ˆçš„è§£å†³ç¾éš¾æ€§é—å¿˜é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚ 

---
# ML-Asset Management: Curation, Discovery, and Utilization 

**Title (ZH)**: ML-èµ„äº§ç®¡ç†ç³»ç»Ÿï¼šç¼–ç›®ã€å‘ç°ä¸åˆ©ç”¨ 

**Authors**: Mengying Wang, Moming Duan, Yicong Huang, Chen Li, Bingsheng He, Yinghui Wu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23577)  

**Abstract**: Machine learning (ML) assets, such as models, datasets, and metadata, are central to modern ML workflows. Despite their explosive growth in practice, these assets are often underutilized due to fragmented documentation, siloed storage, inconsistent licensing, and lack of unified discovery mechanisms, making ML-asset management an urgent challenge. This tutorial offers a comprehensive overview of ML-asset management activities across its lifecycle, including curation, discovery, and utilization. We provide a categorization of ML assets, and major management issues, survey state-of-the-art techniques, and identify emerging opportunities at each stage. We further highlight system-level challenges related to scalability, lineage, and unified indexing. Through live demonstrations of systems, this tutorial equips both researchers and practitioners with actionable insights and practical tools for advancing ML-asset management in real-world and domain-specific settings. 

**Abstract (ZH)**: æœºå™¨å­¦ä¹ èµ„äº§ç®¡ç†ï¼šä»æ”¶é›†ã€å‘ç°åˆ°åˆ©ç”¨çš„å…¨é¢æ¦‚è¿° 

---
# Node Classification via Simplicial Interaction with Augmented Maximal Clique Selection 

**Title (ZH)**: åŸºäºå¢å¼ºæœ€å¤§é—­åŒ…çš„é€‰æ‹©çš„ç®€åŒ–ä½“äº¤äº’èŠ‚ç‚¹åˆ†ç±» 

**Authors**: Eunho Koo, Tongseok Lim  

**Link**: [PDF](https://arxiv.org/pdf/2509.23568)  

**Abstract**: Considering higher-order interactions allows for a more comprehensive understanding of network structures beyond simple pairwise connections. While leveraging all cliques in a network to handle higher-order interactions is intuitive, it often leads to computational inefficiencies due to overlapping information between higher-order and lower-order cliques. To address this issue, we propose an augmented maximal clique strategy. Although using only maximal cliques can reduce unnecessary overlap and provide a concise representation of the network, certain nodes may still appear in multiple maximal cliques, resulting in imbalanced training data. Therefore, our augmented maximal clique approach selectively includes some non-maximal cliques to mitigate the overrepresentation of specific nodes and promote more balanced learning across the network. Comparative analyses on synthetic networks and real-world citation datasets demonstrate that our method outperforms approaches based on pairwise interactions, all cliques, or only maximal cliques. Finally, by integrating this strategy into GNN-based semi-supervised learning, we establish a link between maximal clique-based methods and GNNs, showing that incorporating higher-order structures improves predictive accuracy. As a result, the augmented maximal clique strategy offers a computationally efficient and effective solution for higher-order network learning. 

**Abstract (ZH)**: è€ƒè™‘é«˜é˜¶äº¤äº’å…³ç³»æœ‰åŠ©äºè¶…è¶Šç®€å•äºŒå…ƒè¿æ¥ï¼Œæ›´å…¨é¢åœ°ç†è§£ç½‘ç»œç»“æ„ã€‚å°½ç®¡åˆ©ç”¨ç½‘ç»œä¸­çš„æ‰€æœ‰å›¢æ¥å¤„ç†é«˜é˜¶äº¤äº’ç›´è§‚æ˜“è¡Œï¼Œä½†ç”±äºé«˜é˜¶å’Œä½é˜¶å›¢ä¹‹é—´å­˜åœ¨é‡å ä¿¡æ¯ï¼Œå¾€å¾€ä¼šå¼•å‘è®¡ç®—æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¢å¼ºæœ€å¤§å›¢ç­–ç•¥ã€‚è™½ç„¶ä»…ä½¿ç”¨æœ€å¤§å›¢å¯ä»¥å‡å°‘ä¸å¿…è¦çš„é‡å å¹¶æä¾›ç½‘ç»œçš„ç®€æ´è¡¨ç¤ºï¼Œä½†æŸäº›èŠ‚ç‚¹ä»ç„¶å¯èƒ½å‡ºç°åœ¨å¤šä¸ªæœ€å¤§å›¢ä¸­ï¼Œå¯¼è‡´è®­ç»ƒæ•°æ®ä¸å¹³è¡¡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„å¢å¼ºæœ€å¤§å›¢æ–¹æ³•æœ‰é€‰æ‹©åœ°åŒ…æ‹¬ä¸€äº›éæœ€å¤§å›¢ï¼Œä»¥å‡è½»ç‰¹å®šèŠ‚ç‚¹çš„è¿‡åº¦ä»£è¡¨ï¼Œä¿ƒè¿›ç½‘ç»œæ›´å‡è¡¡çš„å­¦ä¹ ã€‚åœ¨åˆæˆç½‘ç»œå’Œå®é™…å¼•ç”¨æ•°æ®é›†ä¸Šçš„å¯¹æ¯”åˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºåŸºäºäºŒå…ƒäº¤äº’ã€æ‰€æœ‰å›¢æˆ–ä»…æœ€å¤§å›¢çš„æ–¹æ³•ã€‚æœ€åï¼Œé€šè¿‡å°†æ­¤ç­–ç•¥æ•´åˆåˆ°åŸºäºå›¾ç¥ç»ç½‘ç»œçš„åŠç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å»ºç«‹äº†åŸºäºæœ€å¤§å›¢æ–¹æ³•ä¸å›¾ç¥ç»ç½‘ç»œä¹‹é—´çš„è”ç³»ï¼Œè¯æ˜å¼•å…¥é«˜é˜¶ç»“æ„å¯ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚å› æ­¤ï¼Œå¢å¼ºæœ€å¤§å›¢ç­–ç•¥æä¾›äº†ä¸€ç§è®¡ç®—ä¸Šé«˜æ•ˆä¸”æœ‰æ•ˆçš„é«˜é˜¶ç½‘ç»œå­¦ä¹ è§£å†³æ–¹æ¡ˆã€‚ 

---
# Pancreas Part Segmentation under Federated Learning Paradigm 

**Title (ZH)**: è”é‚¦å­¦ä¹ èŒƒå¼ä¸‹çš„èƒ°è…ºéƒ¨åˆ†åˆ†å‰² 

**Authors**: Ziliang Hong, Halil Ertugrul Aktas, Andrea Mia Bejar, Katherine Wu, Hongyi Pan, Gorkem Durak, Zheyuan Zhang, Sait Kayali, Temel Tirkes, Federica Proietto Salanitri, Concetto Spampinato, Michael Goggins, Tamas Gonda, Candice Bolan, Raj Keswani, Frank Miller, Michael Wallace, Ulas Bagci  

**Link**: [PDF](https://arxiv.org/pdf/2509.23562)  

**Abstract**: We present the first federated learning (FL) approach for pancreas part(head, body and tail) segmentation in MRI, addressing a critical clinical challenge as a significant innovation. Pancreatic diseases exhibit marked regional heterogeneity cancers predominantly occur in the head region while chronic pancreatitis causes tissue loss in the tail, making accurate segmentation of the organ into head, body, and tail regions essential for precise diagnosis and treatment planning. This segmentation task remains exceptionally challenging in MRI due to variable morphology, poor soft-tissue contrast, and anatomical variations across patients. Our novel contribution tackles two fundamental challenges: first, the technical complexity of pancreas part delineation in MRI, and second the data scarcity problem that has hindered prior approaches. We introduce a privacy-preserving FL framework that enables collaborative model training across seven medical institutions without direct data sharing, leveraging a diverse dataset of 711 T1W and 726 T2W MRI scans. Our key innovations include: (1) a systematic evaluation of three state-of-the-art segmentation architectures (U-Net, Attention U-Net,Swin UNETR) paired with two FL algorithms (FedAvg, FedProx), revealing Attention U-Net with FedAvg as optimal for pancreatic heterogeneity, which was never been done before; (2) a novel anatomically-informed loss function prioritizing region-specific texture contrasts in MRI. Comprehensive evaluation demonstrates that our approach achieves clinically viable performance despite training on distributed, heterogeneous datasets. 

**Abstract (ZH)**: æˆ‘ä»¬ä»‹ç»äº†é¦–ä¸ªç”¨äºMRIä¸­èƒ°è…ºéƒ¨åˆ†ï¼ˆå¤´ã€ä½“ã€å°¾ï¼‰åˆ†å‰²çš„è”é‚¦å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³äº†ä¸´åºŠä¸­çš„ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œæ˜¯ä¸€é¡¹é‡è¦çš„åˆ›æ–°ã€‚ 

---
# Fusing Sequence Motifs and Pan-Genomic Features: Antimicrobial Resistance Prediction using an Explainable Lightweight 1D CNN-XGBoost Ensemble 

**Title (ZH)**: èåˆåºåˆ—motifå’Œæ³›åŸºå› ç»„ç‰¹å¾ï¼šåŸºäºå¯è§£é‡Šè½»é‡çº§1D CNN-XGBoosté›†æˆçš„æŠ—èŒè¯ç‰©è€è¯æ€§é¢„æµ‹ 

**Authors**: Md. Saiful Bari Siddiqui, Nowshin Tarannum  

**Link**: [PDF](https://arxiv.org/pdf/2509.23552)  

**Abstract**: Antimicrobial Resistance (AMR) is a rapidly escalating global health crisis. While genomic sequencing enables rapid prediction of resistance phenotypes, current computational methods have limitations. Standard machine learning models treat the genome as an unordered collection of features, ignoring the sequential context of Single Nucleotide Polymorphisms (SNPs). State-of-the-art sequence models like Transformers are often too data-hungry and computationally expensive for the moderately-sized datasets that are typical in this domain. To address these challenges, we propose AMR-EnsembleNet, an ensemble framework that synergistically combines sequence-based and feature-based learning. We developed a lightweight, custom 1D Convolutional Neural Network (CNN) to efficiently learn predictive sequence motifs from high-dimensional SNP data. This sequence-aware model was ensembled with an XGBoost model, a powerful gradient boosting system adept at capturing complex, non-local feature interactions. We trained and evaluated our framework on a benchmark dataset of 809 E. coli strains, predicting resistance across four antibiotics with varying class imbalance. Our 1D CNN-XGBoost ensemble consistently achieved top-tier performance across all the antibiotics, reaching a Matthews Correlation Coefficient (MCC) of 0.926 for Ciprofloxacin (CIP) and the highest Macro F1-score of 0.691 for the challenging Gentamicin (GEN) AMR prediction. We also show that our model consistently focuses on SNPs within well-known AMR genes like fusA and parC, confirming it learns the correct genetic signals for resistance. Our work demonstrates that fusing a sequence-aware 1D CNN with a feature-based XGBoost model creates a powerful ensemble, overcoming the limitations of using either an order-agnostic or a standalone sequence model. 

**Abstract (ZH)**: æŠ—å¾®ç”Ÿç‰©è€è¯æ€§ï¼ˆAMRï¼‰æ˜¯äºŸå¾…åº”å¯¹çš„å…¨çƒå¥åº·å±æœºã€‚åŸºå› ç»„æµ‹åºèƒ½å¤Ÿå®ç°å¿«é€Ÿé¢„æµ‹è€è¯è¡¨å‹ï¼Œä½†ç°æœ‰çš„è®¡ç®—æ–¹æ³•å­˜åœ¨å±€é™æ€§ã€‚æ ‡å‡†æœºå™¨å­¦ä¹ æ¨¡å‹å°†åŸºå› ç»„è§†ä¸ºæ— åºçš„ç‰¹å¾é›†åˆï¼Œå¿½ç•¥äº†å•æ ¸è‹·é…¸å¤šæ€æ€§ï¼ˆSNPsï¼‰çš„åºåˆ—ä¸Šä¸‹æ–‡ã€‚æœ€å…ˆè¿›çš„åºåˆ—æ¨¡å‹å¦‚å˜æ¢å™¨é€šå¸¸å› æ•°æ®éœ€æ±‚å¤§ä¸”è®¡ç®—æˆæœ¬é«˜è€Œéš¾ä»¥åº”ç”¨äºè¯¥é¢†åŸŸå…¸å‹çš„ä¸­ç­‰è§„æ¨¡æ•°æ®é›†ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºAMR-EnsembleNetï¼Œä¸€ç§ç»“åˆåºåˆ—åŸºç¡€å­¦ä¹ å’Œç‰¹å¾åŸºç¡€å­¦ä¹ çš„é›†æˆæ¡†æ¶ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªè½»é‡çº§çš„è‡ªå®šä¹‰1Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°ä»é«˜ç»´SNPæ•°æ®ä¸­å­¦ä¹ é¢„æµ‹æ€§åºåˆ—æ¨¡å¼ã€‚è¯¥åºåˆ—æ„ŸçŸ¥æ¨¡å‹ä¸å¼ºå¤§çš„æ¢¯åº¦æå‡ç³»ç»ŸXGBoostæ¨¡å‹è¿›è¡Œé›†æˆï¼Œåè€…æ“…é•¿æ•æ‰å¤æ‚ä¸”éå±€éƒ¨çš„ç‰¹å¾äº¤äº’ã€‚æˆ‘ä»¬åœ¨åŒ…å«809æ ªå¤§è‚ æ†èŒçš„æ ‡å‡†æ•°æ®é›†ä¸Šè®­ç»ƒå’Œè¯„ä¼°äº†æˆ‘ä»¬çš„æ¡†æ¶ï¼Œé’ˆå¯¹å››ç±»æŠ—ç”Ÿç´ ä¸‹çš„ä¸åŒç±»åˆ«ä¸å¹³è¡¡è¿›è¡Œè€è¯é¢„æµ‹ã€‚æˆ‘ä»¬çš„1D CNN-XGBoosté›†æˆæ¡†æ¶åœ¨æ‰€æœ‰æŠ—ç”Ÿç´ ä¸Šå®ç°äº†æœ€ä¼˜æ€§èƒ½ï¼ŒCIPçš„é©¬ä¿®ç›¸å…³ç³»æ•°ï¼ˆMCCï¼‰è¾¾åˆ°0.926ï¼ŒGENçš„å®F1åˆ†æ•°è¾¾åˆ°0.691ï¼Œè¿™æ˜¯æœ€å…·æŒ‘æˆ˜æ€§çš„è€è¯é¢„æµ‹ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†æ¨¡å‹å§‹ç»ˆå…³æ³¨è¯¸å¦‚fusAå’ŒparCç­‰å·²çŸ¥æŠ—è¯åŸºå› ä¸­çš„SNPï¼Œè¯å®äº†å®ƒå­¦ä¹ åˆ°æ­£ç¡®çš„é—ä¼ ä¿¡å·ã€‚æˆ‘ä»¬çš„å·¥ä½œè¯æ˜ï¼Œå°†åºåˆ—æ„ŸçŸ¥çš„1D CNNä¸ç‰¹å¾åŸºç¡€çš„XGBoostæ¨¡å‹èåˆå½¢æˆå¼ºå¤§çš„é›†æˆæ¡†æ¶ï¼Œèƒ½å¤Ÿå…‹æœå•ç‹¬ä½¿ç”¨æ— åºæ„ŸçŸ¥æ¨¡å‹æˆ–ä»…åºåˆ—æ¨¡å‹çš„å±€é™æ€§ã€‚ 

---
# Automatic Speech Recognition for Greek Medical Dictation 

**Title (ZH)**: å¸Œè…ŠåŒ»ç–—å£è¿°çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ« 

**Authors**: Vardis Georgilas, Themos Stafylakis  

**Link**: [PDF](https://arxiv.org/pdf/2509.23550)  

**Abstract**: Medical dictation systems are essential tools in modern healthcare, enabling accurate and efficient conversion of speech into written medical documentation. The main objective of this paper is to create a domain-specific system for Greek medical speech transcriptions. The ultimate goal is to assist healthcare professionals by reducing the overload of manual documentation and improving workflow efficiency. Towards this goal, we develop a system that combines automatic speech recognition techniques with text correction model, allowing better handling of domain-specific terminology and linguistic variations in Greek. Our approach leverages both acoustic and textual modeling to create more realistic and reliable transcriptions. We focused on adapting existing language and speech technologies to the Greek medical context, addressing challenges such as complex medical terminology and linguistic inconsistencies. Through domain-specific fine-tuning, our system achieves more accurate and coherent transcriptions, contributing to the development of practical language technologies for the Greek healthcare sector. 

**Abstract (ZH)**: åŒ»å­¦å£è¿°ç³»ç»Ÿæ˜¯ç°ä»£åŒ»ç–—ä¿å¥ä¸­ä¸å¯æˆ–ç¼ºçš„å·¥å…·ï¼Œèƒ½å¤Ÿå®ç°è¯­éŸ³åˆ°ä¹¦é¢åŒ»ç–—æ–‡æ¡£çš„å‡†ç¡®é«˜æ•ˆè½¬æ¢ã€‚æœ¬æ–‡çš„ä¸»è¦ç›®æ ‡æ˜¯ä¸ºå¸Œè…ŠåŒ»å­¦è¯­éŸ³è½¬å½•åˆ›å»ºä¸€ä¸ªä¸“ç”¨ç³»ç»Ÿã€‚æœ€ç»ˆç›®æ ‡æ˜¯é€šè¿‡å‡è½»æ‰‹å†™æ–‡æ¡£çš„è´Ÿæ‹…å¹¶æé«˜å·¥ä½œæµç¨‹æ•ˆç‡æ¥è¾…åŠ©åŒ»ç–—ä¸“ä¸šäººå‘˜ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªç»“åˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«æŠ€æœ¯å’Œæ–‡æœ¬æ ¡æ­£æ¨¡å‹çš„ç³»ç»Ÿï¼Œä»¥æ›´å¥½åœ°å¤„ç†å¸Œè…ŠåŒ»å­¦é¢†åŸŸçš„ä¸“æœ‰åè¯å’Œè¯­è¨€å˜å¼‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†å£°å­¦å’Œæ–‡æœ¬å»ºæ¨¡ï¼Œä»¥ç”Ÿæˆæ›´åŠ çœŸå®å¯é çš„è½¬å½•ã€‚æˆ‘ä»¬ä¸“æ³¨äºå°†ç°æœ‰çš„è¯­è¨€å’ŒæŠ€æœ¯é€‚åº”å¸Œè…ŠåŒ»ç–—èƒŒæ™¯ï¼Œè§£å†³å¤æ‚åŒ»å­¦æœ¯è¯­å’Œè¯­è¨€ä¸ä¸€è‡´ç­‰æŒ‘æˆ˜ã€‚é€šè¿‡é¢†åŸŸç‰¹å®šçš„å¾®è°ƒï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿå®ç°äº†æ›´å‡†ç¡®å’Œè¿è´¯çš„è½¬å½•ï¼Œä¸ºå¸Œè…ŠåŒ»ç–—ä¿å¥é¢†åŸŸçš„å‘å±•è´¡çŒ®äº†å®ç”¨çš„è¯­è¨€æŠ€æœ¯ã€‚ 

---
# End-to-End Deep Learning for Predicting Metric Space-Valued Outputs 

**Title (ZH)**: ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ ç”¨äºé¢„æµ‹åº¦é‡ç©ºé—´å€¼è¾“å‡º 

**Authors**: Yidong Zhou, Su I Iao, Hans-Georg MÃ¼ller  

**Link**: [PDF](https://arxiv.org/pdf/2509.23544)  

**Abstract**: Many modern applications involve predicting structured, non-Euclidean outputs such as probability distributions, networks, and symmetric positive-definite matrices. These outputs are naturally modeled as elements of general metric spaces, where classical regression techniques that rely on vector space structure no longer apply. We introduce E2M (End-to-End Metric regression), a deep learning framework for predicting metric space-valued outputs. E2M performs prediction via a weighted FrÃ©chet means over training outputs, where the weights are learned by a neural network conditioned on the input. This construction provides a principled mechanism for geometry-aware prediction that avoids surrogate embeddings and restrictive parametric assumptions, while fully preserving the intrinsic geometry of the output space. We establish theoretical guarantees, including a universal approximation theorem that characterizes the expressive capacity of the model and a convergence analysis of the entropy-regularized training objective. Through extensive simulations involving probability distributions, networks, and symmetric positive-definite matrices, we show that E2M consistently achieves state-of-the-art performance, with its advantages becoming more pronounced at larger sample sizes. Applications to human mortality distributions and New York City taxi networks further demonstrate the flexibility and practical utility of the framework. 

**Abstract (ZH)**: ç«¯åˆ°ç«¯åº¦é‡å›å½’ï¼šä¸€ç§é¢„æµ‹ä¸€èˆ¬åº¦é‡ç©ºé—´è¾“å‡ºçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ 

---
# Imaging-Based Mortality Prediction in Patients with Systemic Sclerosis 

**Title (ZH)**: åŸºäºæˆåƒçš„ç³»ç»Ÿæ€§ç¡¬åŒ–ç—‡æ‚£è€… mortality é¢„æµ‹ 

**Authors**: Alec K. Peltekian, Karolina Senkow, Gorkem Durak, Kevin M. Grudzinski, Bradford C. Bemiss, Jane E. Dematte, Carrie Richardson, Nikolay S. Markov, Mary Carns, Kathleen Aren, Alexandra Soriano, Matthew Dapas, Harris Perlman, Aaron Gundersheimer, Kavitha C. Selvan, John Varga, Monique Hinchcliff, Krishnan Warrior, Catherine A. Gao, Richard G. Wunderink, GR Scott Budinger, Alok N. Choudhary, Anthony J. Esposito, Alexander V. Misharin, Ankit Agrawal, Ulas Bagci  

**Link**: [PDF](https://arxiv.org/pdf/2509.23530)  

**Abstract**: Interstitial lung disease (ILD) is a leading cause of morbidity and mortality in systemic sclerosis (SSc). Chest computed tomography (CT) is the primary imaging modality for diagnosing and monitoring lung complications in SSc patients. However, its role in disease progression and mortality prediction has not yet been fully clarified. This study introduces a novel, large-scale longitudinal chest CT analysis framework that utilizes radiomics and deep learning to predict mortality associated with lung complications of SSc. We collected and analyzed 2,125 CT scans from SSc patients enrolled in the Northwestern Scleroderma Registry, conducting mortality analyses at one, three, and five years using advanced imaging analysis techniques. Death labels were assigned based on recorded deaths over the one-, three-, and five-year intervals, confirmed by expert physicians. In our dataset, 181, 326, and 428 of the 2,125 CT scans were from patients who died within one, three, and five years, respectively. Using ResNet-18, DenseNet-121, and Swin Transformer we use pre-trained models, and fine-tuned on 2,125 images of SSc patients. Models achieved an AUC of 0.769, 0.801, 0.709 for predicting mortality within one-, three-, and five-years, respectively. Our findings highlight the potential of both radiomics and deep learning computational methods to improve early detection and risk assessment of SSc-related interstitial lung disease, marking a significant advancement in the literature. 

**Abstract (ZH)**: ç³»ç»Ÿç¡¬åŒ–ç—…ç›¸å…³é—´è´¨æ€§è‚ºç—…çš„èƒ¸éƒ¨CTçºµå‘åˆ†ææ¡†æ¶ï¼šåŸºäºæ”¾å°„omicså’Œæ·±åº¦å­¦ä¹ çš„æ­»äº¡ç‡é¢„æµ‹ç ”ç©¶ 

---
# Revisiting Multivariate Time Series Forecasting with Missing Values 

**Title (ZH)**: revisit å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ç¼ºå¤±å€¼é—®é¢˜ 

**Authors**: Jie Yang, Yifan Hu, Kexin Zhang, Luyang Niu, Yushun Dong, Philip S. Yu, Kaize Ding  

**Link**: [PDF](https://arxiv.org/pdf/2509.23494)  

**Abstract**: Missing values are common in real-world time series, and multivariate time series forecasting with missing values (MTSF-M) has become a crucial area of research for ensuring reliable predictions. To address the challenge of missing data, current approaches have developed an imputation-then-prediction framework that uses imputation modules to fill in missing values, followed by forecasting on the imputed data. However, this framework overlooks a critical issue: there is no ground truth for the missing values, making the imputation process susceptible to errors that can degrade prediction accuracy. In this paper, we conduct a systematic empirical study and reveal that imputation without direct supervision can corrupt the underlying data distribution and actively degrade prediction accuracy. To address this, we propose a paradigm shift that moves away from imputation and directly predicts from the partially observed time series. We introduce Consistency-Regularized Information Bottleneck (CRIB), a novel framework built on the Information Bottleneck principle. CRIB combines a unified-variate attention mechanism with a consistency regularization scheme to learn robust representations that filter out noise introduced by missing values while preserving essential predictive signals. Comprehensive experiments on four real-world datasets demonstrate the effectiveness of CRIB, which predicts accurately even under high missing rates. Our code is available in this https URL. 

**Abstract (ZH)**: ç¼ºå¤±å€¼åœ¨å®æ—¶åºåˆ—ä¸­å¾ˆå¸¸è§ï¼Œå¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ç¼ºå¤±å€¼ï¼ˆMTSF-Mï¼‰å·²æˆä¸ºç¡®ä¿å¯é é¢„æµ‹çš„å…³é”®ç ”ç©¶é¢†åŸŸã€‚æœ¬æ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†ç¼ºå¤±æ•°æ®çš„é—®é¢˜ï¼Œæ­ç¤ºäº†åœ¨ç¼ºä¹ç›´æ¥ç›‘ç£çš„æƒ…å†µä¸‹è¿›è¡Œæ’è¡¥ä¼šç ´ååº•å±‚æ•°æ®åˆ†å¸ƒå¹¶ä¸»åŠ¨é™ä½é¢„æµ‹ç²¾åº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§èŒƒå¼è½¬å˜ï¼Œå³ä»æ’è¡¥è½¬å‘ç›´æ¥ä»éƒ¨åˆ†è§‚å¯Ÿåˆ°çš„æ—¶é—´åºåˆ—è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€è‡´æ€§æ­£åˆ™åŒ–ä¿¡æ¯ç“¶é¢ˆï¼ˆCRIBï¼‰æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºä¿¡æ¯ç“¶é¢ˆåŸç†çš„æ–°å‹æ¡†æ¶ã€‚CRIB ç»“åˆäº†ä¸€è‡´æ€§æ­£åˆ™åŒ–æ–¹æ¡ˆå’Œç»Ÿä¸€å˜é‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºå­¦ä¹ ç¨³å¥çš„è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºå¯ä»¥è¿‡æ»¤æ‰ç”±ç¼ºå¤±å€¼å¼•å…¥çš„å™ªå£°ï¼ŒåŒæ—¶ä¿ç•™é‡è¦çš„é¢„æµ‹ä¿¡å·ã€‚åœ¨å››ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å…¨é¢å®éªŒè¡¨æ˜ï¼ŒCRIB å³ä½¿åœ¨é«˜ç¼ºå¤±ç‡ä¸‹ä¹Ÿèƒ½å‡†ç¡®é¢„æµ‹ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ä»¥ä¸‹é“¾æ¥è·å–ï¼šthis https URLã€‚ 

---
# Text-Based Approaches to Item Difficulty Modeling in Large-Scale Assessments: A Systematic Review 

**Title (ZH)**: åŸºäºæ–‡æœ¬çš„æ–¹æ³•åœ¨å¤§è§„æ¨¡è¯„ä¼°ä¸­é¡¹ç›®éš¾åº¦å»ºæ¨¡ï¼šä¸€é¡¹ç³»ç»Ÿå›é¡¾ 

**Authors**: Sydney Peters, Nan Zhang, Hong Jiao, Ming Li, Tianyi Zhou, Robert Lissitz  

**Link**: [PDF](https://arxiv.org/pdf/2509.23486)  

**Abstract**: Item difficulty plays a crucial role in test performance, interpretability of scores, and equity for all test-takers, especially in large-scale assessments. Traditional approaches to item difficulty modeling rely on field testing and classical test theory (CTT)-based item analysis or item response theory (IRT) calibration, which can be time-consuming and costly. To overcome these challenges, text-based approaches leveraging machine learning and language models, have emerged as promising alternatives. This paper reviews and synthesizes 37 articles on automated item difficulty prediction in large-scale assessment settings published through May 2025. For each study, we delineate the dataset, difficulty parameter, subject domain, item type, number of items, training and test data split, input, features, model, evaluation criteria, and model performance outcomes. Results showed that although classic machine learning models remain relevant due to their interpretability, state-of-the-art language models, using both small and large transformer-based architectures, can capture syntactic and semantic patterns without the need for manual feature engineering. Uniquely, model performance outcomes were summarized to serve as a benchmark for future research and overall, text-based methods have the potential to predict item difficulty with root mean square error (RMSE) as low as 0.165, Pearson correlation as high as 0.87, and accuracy as high as 0.806. The review concludes by discussing implications for practice and outlining future research directions for automated item difficulty modeling. 

**Abstract (ZH)**: é¡¹ç›®éš¾åº¦åœ¨æµ‹è¯•è¡¨ç°ã€åˆ†æ•°è§£é‡Šæ€§å’Œæ‰€æœ‰åº”è¯•è€…çš„å…¬å¹³æ€§ä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡è¯„ä¼°ä¸­ã€‚ä¼ ç»Ÿçš„é¡¹ç›®éš¾åº¦å»ºæ¨¡æ–¹æ³•ä¾èµ–äºåœºæµ‹å’ŒåŸºäºç»å…¸æµ‹éªŒç†è®ºï¼ˆCTTï¼‰çš„é¡¹ç›®åˆ†ææˆ–åŸºäºé¡¹ç›®ååº”ç†è®ºï¼ˆIRTï¼‰çš„æ ¡å‡†ï¼Œè¿™å¯èƒ½ä¼šè€—è´¹å¤§é‡æ—¶é—´å’Œæˆæœ¬ã€‚ä¸ºå…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œåˆ©ç”¨æœºå™¨å­¦ä¹ å’Œè¯­è¨€æ¨¡å‹çš„åŸºäºæ–‡æœ¬çš„æ–¹æ³•å·²æˆä¸ºæœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆã€‚æœ¬æ–‡é€šè¿‡2025å¹´5æœˆå›é¡¾å¹¶ç»¼åˆäº†37ç¯‡å…³äºå¤§è§„æ¨¡è¯„ä¼°ç¯å¢ƒä¸­è‡ªåŠ¨åŒ–é¡¹ç›®éš¾åº¦é¢„æµ‹çš„æ–‡ç« ã€‚å¯¹äºæ¯é¡¹ç ”ç©¶ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†æ•°æ®é›†ã€éš¾åº¦å‚æ•°ã€ç ”ç©¶é¢†åŸŸã€é¡¹ç›®ç±»å‹ã€é¡¹ç›®æ•°é‡ã€è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å‰²ã€è¾“å…¥ã€ç‰¹å¾ã€æ¨¡å‹ã€è¯„ä¼°æ ‡å‡†ä»¥åŠæ¨¡å‹æ€§èƒ½ç»“æœã€‚ç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡ç»å…¸çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä»å…·æœ‰ä¸€å®šçš„è§£é‡Šæ€§ï¼Œä½†æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œæ— è®ºæ˜¯å°å‹è¿˜æ˜¯å¤§å‹å˜å‹å™¨æ¶æ„ï¼Œéƒ½èƒ½å¤Ÿæ•è·å¥æ³•å’Œè¯­ä¹‰æ¨¡å¼ï¼Œæ— éœ€æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹ã€‚æ¨¡å‹æ€§èƒ½ç»“æœè¢«æ€»ç»“ä¸ºæœªæ¥ç ”ç©¶çš„åŸºå‡†ï¼Œæ€»ä½“è€Œè¨€ï¼ŒåŸºäºæ–‡æœ¬çš„æ–¹æ³•æœ‰å¯èƒ½é¢„æµ‹é¡¹ç›®éš¾åº¦ï¼Œå…¶ä¸­å‡æ–¹æ ¹è¯¯å·®(RMSE)ä½è‡³0.165ï¼Œçš®å°”é€Šç›¸å…³ç³»æ•°é«˜è¾¾0.87ï¼Œå‡†ç¡®ç‡é«˜è¾¾0.806ã€‚æœ¬æ–‡ç»“è®ºè®¨è®ºäº†å®è·µå¯ç¤ºå¹¶æ¦‚è¿°äº†è‡ªåŠ¨åŒ–é¡¹ç›®éš¾åº¦å»ºæ¨¡çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚ 

---
# Memory-Efficient Fine-Tuning via Low-Rank Activation Compression 

**Title (ZH)**: ä½ç§©æ¿€æ´»å‹ç¼©å®ç°é«˜æ•ˆå†…å­˜å¾®è°ƒ 

**Authors**: Jiang-Xin Shi, Wen-Da Wei, Jin-Fei Qi, Xuanyu Chen, Tong Wei, Yu-Feng Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.23472)  

**Abstract**: The parameter-efficient fine-tuning paradigm has garnered significant attention with the advancement of foundation models. Although numerous methods have been proposed to reduce the number of trainable parameters, their substantial memory overhead remains a critical bottleneck that hinders practical deployment. In this paper, we observe that model activations constitute a major source of memory consumption, especially under large batch sizes and long context lengths; however, the rank of the activations remains consistently low. Motivated by this insight, we propose a memory-efficient fine-tuning approach Low-Rank Activation Compression (LoRAct). Unlike prior work, LoRAct provides a more flexible and versatile compressing strategy that can be applied online during the forward pass without the need for any calibration data. Moreover, LoRAct incorporates a novel sampling-based orthogonal decomposition algorithm specifically designed for low-rank matrices, offering improved computational efficiency and a tighter error bound compared to the widely used RSVD. Experiments on both vision and language tasks demonstrate the effectiveness of LoRAct. Notably, LoRAct further reduces activation memory by approximately 80% in comparison with the widely adopted LoRA method, while maintaining competitive performance. The source code is available at this https URL. 

**Abstract (ZH)**: åŸºç¡€æ¨¡å‹å‘å±•çš„å‚æ•°é«˜æ•ˆå¾®è°ƒèŒƒå¼å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚å°½ç®¡æå‡ºäº†è®¸å¤šå‡å°‘å¯è®­ç»ƒå‚æ•°æ•°é‡çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬å¸¦æ¥çš„æ˜¾å­˜ overhead ä»ç„¶æ˜¯é˜»ç¢å…¶å®ç”¨éƒ¨ç½²çš„å…³é”®ç“¶é¢ˆã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ¨¡å‹æ¿€æ´»æ„æˆäº†ä¸»è¦çš„æ˜¾å­˜æ¶ˆè€—æ¥æºï¼Œå°¤å…¶æ˜¯åœ¨å¤§æ‰¹æ¬¡å’Œé•¿ä¸Šä¸‹æ–‡é•¿åº¦çš„æƒ…å†µä¸‹ï¼›ç„¶è€Œï¼Œè¿™äº›æ¿€æ´»çš„ç§©ä¿æŒåœ¨è¾ƒä½æ°´å¹³ã€‚åŸºäºè¿™ä¸€è§è§£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•â€”â€”ä½ç§©æ¿€æ´»å‹ç¼©ï¼ˆLoRActï¼‰ã€‚ä¸ä»¥å¾€å·¥ä½œä¸åŒï¼ŒLoRAct æä¾›äº†ä¸€ç§æ›´ä¸ºçµæ´»å’Œé€šç”¨çš„å‹ç¼©ç­–ç•¥ï¼Œå¯ä»¥åœ¨å‰å‘é€šè¿‡è¿‡ç¨‹ä¸­åœ¨çº¿åº”ç”¨è€Œæ— éœ€ä»»ä½•æ ¡å‡†æ•°æ®ã€‚æ­¤å¤–ï¼ŒLoRAct ç»“åˆäº†ä¸€ç§æ–°é¢–çš„åŸºäºæŠ½æ ·çš„æ­£äº¤åˆ†è§£ç®—æ³•ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä½ç§©çŸ©é˜µï¼Œæä¾›æ¯”å¹¿æ³›ä½¿ç”¨çš„RSVDæ›´å¥½çš„è®¡ç®—æ•ˆç‡å’Œæ›´ç´§çš„è¯¯å·®ç•Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLoRAct åœ¨è§†è§‰å’Œè¯­è¨€ä»»åŠ¡ä¸­å‡æœ‰æ•ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸å¹¿æ³›é‡‡ç”¨çš„LoRAæ–¹æ³•ç›¸æ¯”ï¼ŒLoRAct è¿›ä¸€æ­¥å‡å°‘äº†çº¦80%çš„æ¿€æ´»æ˜¾å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒäº†ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æºä»£ç å¯é€šè¿‡æ­¤é“¾æ¥è·å–ã€‚ 

---
# Generative Evolutionary Meta-Solver (GEMS): Scalable Surrogate-Free Multi-Agent Learning 

**Title (ZH)**: ç”Ÿæˆè¿›åŒ–å…ƒæ±‚è§£å™¨ï¼ˆGEMSï¼‰ï¼šå¯æ‰©å±•çš„æ— ä»£ç†æ¨¡æ‹Ÿå¤šagentå­¦ä¹  

**Authors**: Alakh Sharma, Gaurish Trivedi, Kartikey Bhandari, Yash Sinha, Dhruv Kumar, Pratik Narang, Jagat Sesh Challa  

**Link**: [PDF](https://arxiv.org/pdf/2509.23462)  

**Abstract**: Scalable multi-agent reinforcement learning (MARL) remains a central challenge for AI. Existing population-based methods, like Policy-Space Response Oracles, PSRO, require storing explicit policy populations and constructing full payoff matrices, incurring quadratic computation and linear memory costs. We present Generative Evolutionary Meta-Solver (GEMS), a surrogate-free framework that replaces explicit populations with a compact set of latent anchors and a single amortized generator. Instead of exhaustively constructing the payoff matrix, GEMS relies on unbiased Monte Carlo rollouts, multiplicative-weights meta-dynamics, and a model-free empirical-Bernstein UCB oracle to adaptively expand the policy set. Best responses are trained within the generator using an advantage-based trust-region objective, eliminating the need to store and train separate actors. We evaluated GEMS in a variety of Two-player and Multi-Player games such as the Deceptive Messages Game, Kuhn Poker and Multi-Particle environment. We find that GEMS is up to ~6x faster, has 1.3x less memory usage than PSRO, while also reaps higher rewards simultaneously. These results demonstrate that GEMS retains the game theoretic guarantees of PSRO, while overcoming its fundamental inefficiencies, hence enabling scalable multi-agent learning in multiple domains. 

**Abstract (ZH)**: æ— è¡¥è´´è¿›åŒ–å…ƒæ±‚è§£å™¨ï¼ˆGEMSï¼‰ï¼šScalable Multi-Agent Reinforcement Learning Framework 

---
# Data-Efficient Training by Evolved Sampling 

**Title (ZH)**: è¿›åŒ–é‡‡æ ·å®ç°æ•°æ®é«˜æ•ˆè®­ç»ƒ 

**Authors**: Ziheng Cheng, Zhong Li, Jiang Bian  

**Link**: [PDF](https://arxiv.org/pdf/2509.23461)  

**Abstract**: Data selection is designed to accelerate learning with preserved performance. To achieve this, a fundamental thought is to identify informative data samples with significant contributions to the training. In this work, we propose \textbf{Evolved Sampling} (\textbf{ES}), a simple yet effective framework for \emph{dynamic} sampling along the training process. This method conducts \em batch \em level data selection based on the dynamics of losses and augmented \emph{loss differences}, which enables flexible \emph{frequency tuning}, and hence significantly reduces the back propagation time with maintained model performance. Due to its conciseness, ES is also readily extensible to incorporate \em set \em level data selection (to form ES with pruning, \textbf{ESWP}) for further accelerations. As a plug-and-play framework, ES(WP) consistently achieves lossless training accelerations across various pre-training and post-training tasks, saving up to nearly 45\% wall-clock time. Our results motivate further investigations on the data efficiency aspect of modern large-scale machine learning. 

**Abstract (ZH)**: æ•°æ®é€‰æ‹©æ—¨åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶åŠ é€Ÿå­¦ä¹ ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œä¸€ä¸ªæ ¹æœ¬æ€§çš„æƒ³æ³•æ˜¯è¯†åˆ«å¯¹è®­ç»ƒæœ‰æ˜¾è‘—è´¡çŒ®çš„ä¿¡æ¯æ€§æ•°æ®æ ·æœ¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³• \textbf{è¿›åŒ–é‡‡æ ·} (\textbf{ES})ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡ŒåŠ¨æ€é‡‡æ ·çš„æ¡†æ¶ã€‚è¯¥æ–¹æ³•åŸºäºæŸå¤±åŠ¨æ€å’Œå¢å¼ºçš„æŸå¤±å·®è¿›è¡Œæ‰¹æ¬¡çº§åˆ«æ•°æ®é€‰æ‹©ï¼Œä»è€Œå®ç°çµæ´»çš„é¢‘ç‡è°ƒä¼˜ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†å›ä¼ æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚ç”±äºå…¶ç®€æ´æ€§ï¼ŒES ä¹Ÿå¯ä»¥æ–¹ä¾¿åœ°æ‰©å±•ä¸ºç»“åˆé›†åˆçº§åˆ«æ•°æ®é€‰æ‹©ï¼ˆå½¢æˆå…·æœ‰å‰ªæçš„ \textbf{ESWP}ï¼‰ä»¥è¿›ä¸€æ­¥åŠ é€Ÿã€‚ä½œä¸ºä¸€ç§å³æ’å³ç”¨æ¡†æ¶ï¼ŒES(WP) åœ¨å„ç§é¢„è®­ç»ƒå’Œåè®­ç»ƒä»»åŠ¡ä¸­å®ç°äº†æ— æŸè®­ç»ƒåŠ é€Ÿï¼Œæœ€é«˜å¯èŠ‚çœè¿‘ 45% çš„å®é™…æ—¶é—´ã€‚æˆ‘ä»¬çš„ç»“æœä¿ƒä½¿æˆ‘ä»¬è¿›ä¸€æ­¥ç ”ç©¶ç°ä»£å¤§è§„æ¨¡æœºå™¨å­¦ä¹ ä¸­çš„æ•°æ®æ•ˆç‡æ–¹é¢ã€‚ 

---
# AudioFuse: Unified Spectral-Temporal Learning via a Hybrid ViT-1D CNN Architecture for Robust Phonocardiogram Classification 

**Title (ZH)**: AudioFuseï¼š atravÃ©s æ··åˆ ViT-1D CNN æ¶æ„çš„ç»Ÿä¸€é¢‘è°±-æ—¶é—´å­¦ä¹ ï¼Œç”¨äºç¨³å¥çš„ Phonocardiogram åˆ†ç±» 

**Authors**: Md. Saiful Bari Siddiqui, Utsab Saha  

**Link**: [PDF](https://arxiv.org/pdf/2509.23454)  

**Abstract**: Biomedical audio signals, such as phonocardiograms (PCG), are inherently rhythmic and contain diagnostic information in both their spectral (tonal) and temporal domains. Standard 2D spectrograms provide rich spectral features but compromise the phase information and temporal precision of the 1D waveform. We propose AudioFuse, an architecture that simultaneously learns from both complementary representations to classify PCGs. To mitigate the overfitting risk common in fusion models, we integrate a custom, wide-and-shallow Vision Transformer (ViT) for spectrograms with a shallow 1D CNN for raw waveforms. On the PhysioNet 2016 dataset, AudioFuse achieves a state-of-the-art competitive ROC-AUC of 0.8608 when trained from scratch, outperforming its spectrogram (0.8066) and waveform (0.8223) baselines. Moreover, it demonstrates superior robustness to domain shift on the challenging PASCAL dataset, maintaining an ROC-AUC of 0.7181 while the spectrogram baseline collapses (0.4873). Fusing complementary representations thus provides a strong inductive bias, enabling the creation of efficient, generalizable classifiers without requiring large-scale pre-training. 

**Abstract (ZH)**: biomedical éŸ³é¢‘ä¿¡å·ï¼Œå¦‚å¿ƒéŸ³å›¾ (PCG)ï¼Œæœ¬è´¨ä¸Šæ˜¯ rhythmic çš„ï¼Œå¹¶ä¸”åœ¨å…¶é¢‘è°± (éŸ³è°ƒ) å’Œæ—¶é—´åŸŸä¸­åŒ…å«è¯Šæ–­ä¿¡æ¯ã€‚æ ‡å‡†çš„ 2D è°±å›¾æä¾›äº†ä¸°å¯Œçš„é¢‘è°±ç‰¹å¾ï¼Œä½†ç‰ºç‰²äº†æ—¶é—´æ³¢å½¢çš„ç›¸ä½ä¿¡æ¯å’Œæ—¶é—´ç²¾åº¦ã€‚æˆ‘ä»¬æå‡º AudioFuse æ¶æ„ï¼Œè¯¥æ¶æ„åŒæ—¶ä»äº’è¡¥çš„è¡¨ç¤ºä¸­å­¦ä¹ ä»¥åˆ†ç±» PCGã€‚ä¸ºç¼“è§£èåˆæ¨¡å‹ä¸­å¸¸è§çš„è¿‡æ‹Ÿåˆé£é™©ï¼Œæˆ‘ä»¬æ•´åˆäº†ä¸€ä¸ªå®šåˆ¶çš„å®½æµ… Vision Transformer (ViT) ç”¨äºè°±å›¾ï¼Œä»¥åŠä¸€ä¸ªæµ…å±‚ 1D CNN ç”¨äºåŸå§‹æ³¢å½¢ã€‚åœ¨ PhysioNet 2016 æ•°æ®é›†ä¸Šï¼Œä»å¤´è®­ç»ƒçš„ AudioFuse è¾¾åˆ°äº† 0.8608 çš„ç«äº‰æ€§ ROC-AUCï¼Œä¼˜äºå…¶è°±å›¾ baselines (0.8066) å’Œæ³¢å½¢ baselines (0.8223)ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ PASCAL æ•°æ®é›†ä¸Šå±•ç¤ºäº†å¯¹é¢†åŸŸè½¬ç§»çš„ä¼˜è¶Šé²æ£’æ€§ï¼Œåœ¨ä¿æŒ ROC-AUC ä¸º 0.7181 çš„åŒæ—¶ï¼Œè°±å›¾ baseline ä¸‹é™è‡³ 0.4873ã€‚å› æ­¤ï¼Œèåˆäº’è¡¥è¡¨ç¤ºæä¾›äº†å¼ºå¤§çš„å½’çº³åç½®ï¼Œä½¿å¾—å¯ä»¥åˆ›å»ºé«˜æ•ˆä¸”å¯æ³›åŒ–çš„åˆ†ç±»å™¨ï¼Œè€Œæ— éœ€å¤§è§„æ¨¡é¢„è®­ç»ƒã€‚ 

---
# Factor Decorrelation Enhanced Data Removal from Deep Predictive Models 

**Title (ZH)**: æ·±åº¦é¢„æµ‹æ¨¡å‹ä¸­å› ç´ å»ç›¸å…³å¢å¼ºçš„æ•°æ®åˆ é™¤ 

**Authors**: Wenhao Yang, Lin Li, Xiaohui Tao, Kaize Shi  

**Link**: [PDF](https://arxiv.org/pdf/2509.23443)  

**Abstract**: The imperative of user privacy protection and regulatory compliance necessitates sensitive data removal in model training, yet this process often induces distributional shifts that undermine model performance-particularly in out-of-distribution (OOD) scenarios. We propose a novel data removal approach that enhances deep predictive models through factor decorrelation and loss perturbation. Our approach introduces: (1) a discriminative-preserving factor decorrelation module employing dynamic adaptive weight adjustment and iterative representation updating to reduce feature redundancy and minimize inter-feature correlations. (2) a smoothed data removal mechanism with loss perturbation that creates information-theoretic safeguards against data leakage during removal operations. Extensive experiments on five benchmark datasets show that our approach outperforms other baselines and consistently achieves high predictive accuracy and robustness even under significant distribution shifts. The results highlight its superior efficiency and adaptability in both in-distribution and out-of-distribution scenarios. 

**Abstract (ZH)**: ç”¨æˆ·éšç§ä¿æŠ¤å’Œç›‘ç®¡åˆè§„çš„è¿«åˆ‡æ€§è¦æ±‚åœ¨æ¨¡å‹è®­ç»ƒä¸­ç§»é™¤æ•æ„Ÿæ•°æ®ï¼Œä½†è¿™ä¸€è¿‡ç¨‹å¸¸ä¼šå¼•èµ·åˆ†å¸ƒå˜åŒ–ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†å¸ƒå¤–(OOD)åœºæ™¯ä¸­æŸå®³æ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ•°æ®ç§»é™¤æ–¹æ³•ï¼Œé€šè¿‡å› å­å»ç›¸å…³å’ŒæŸå¤±æ‰°åŠ¨æ¥å¢å¼ºæ·±åº¦é¢„æµ‹æ¨¡å‹ã€‚(1) ä¸€ç§ä¿æŒé‰´åˆ«ä¿¡æ¯çš„å› å­å»ç›¸å…³æ¨¡å—ï¼Œé‡‡ç”¨åŠ¨æ€è‡ªé€‚åº”æƒé‡è°ƒæ•´å’Œè¿­ä»£è¡¨ç¤ºæ›´æ–°æ¥å‡å°‘ç‰¹å¾å†—ä½™å¹¶æœ€å°åŒ–ç‰¹å¾é—´çš„ç›¸å…³æ€§ã€‚(2) ä¸€ç§å¹³æ»‘çš„æ•°æ®ç§»é™¤æœºåˆ¶ï¼Œé€šè¿‡æŸå¤±æ‰°åŠ¨åˆ›å»ºä¿¡æ¯è®ºä¸Šçš„å®‰å…¨é˜²æŠ¤ï¼Œé˜²æ­¢åœ¨æ•°æ®ç§»é™¤æ“ä½œä¸­å‘ç”Ÿæ•°æ®æ³„æ¼ã€‚åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæœ¬æ–¹æ³•ä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨æ˜¾è‘—åˆ†å¸ƒå˜åŒ–ä¸‹ä¸€è‡´åœ°å®ç°é«˜é¢„æµ‹å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚ç»“æœçªæ˜¾äº†å…¶åœ¨åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–åœºæ™¯ä¸­çš„ä¼˜è¶Šæ•ˆç‡å’Œé€‚åº”æ€§ã€‚ 

---
# Enhancing Communication Efficiency in FL with Adaptive Gradient Quantization and Communication Frequency Optimization 

**Title (ZH)**: é€‚åº”æ€§æ¢¯åº¦é‡åŒ–ä¸é€šä¿¡é¢‘ç‡ä¼˜åŒ–ä»¥æå‡è”é‚¦å­¦ä¹ ä¸­çš„é€šä¿¡æ•ˆç‡ 

**Authors**: Asadullah Tariq, Tariq Qayyum, Mohamed Adel Serhani, Farag Sallabi, Ikbal Taleb, Ezedin S. Barka  

**Link**: [PDF](https://arxiv.org/pdf/2509.23419)  

**Abstract**: Federated Learning (FL) enables participant devices to collaboratively train deep learning models without sharing their data with the server or other devices, effectively addressing data privacy and computational concerns. However, FL faces a major bottleneck due to high communication overhead from frequent model updates between devices and the server, limiting deployment in resource-constrained wireless networks. In this paper, we propose a three-fold strategy. Firstly, an Adaptive Feature-Elimination Strategy to drop less important features while retaining high-value ones; secondly, Adaptive Gradient Innovation and Error Sensitivity-Based Quantization, which dynamically adjusts the quantization level for innovative gradient compression; and thirdly, Communication Frequency Optimization to enhance communication efficiency. We evaluated our proposed model's performance through extensive experiments, assessing accuracy, loss, and convergence compared to baseline techniques. The results show that our model achieves high communication efficiency in the framework while maintaining accuracy. 

**Abstract (ZH)**: è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰ä½¿å‚ä¸è®¾å¤‡èƒ½å¤Ÿåœ¨ä¸å…±äº«æ•°æ®ç»™æœåŠ¡å™¨æˆ–å…¶ä»–è®¾å¤‡çš„æƒ…å†µä¸‹åä½œè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†æ•°æ®éšç§å’Œè®¡ç®—é—®é¢˜ã€‚ç„¶è€Œï¼ŒFLç”±äºé¢‘ç¹çš„æ¨¡å‹æ›´æ–°å¯¼è‡´çš„é«˜é€šä¿¡å¼€é”€é¢ä¸´é‡å¤§ç“¶é¢ˆï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™çš„æ— çº¿ç½‘ç»œä¸­çš„éƒ¨ç½²ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸‰ç®¡é½ä¸‹çš„ç­–ç•¥ã€‚é¦–å…ˆï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”ç‰¹å¾æ¶ˆé™¤ç­–ç•¥ä»¥ä¸¢å¼ƒä¸é‡è¦çš„ç‰¹å¾åŒæ—¶ä¿ç•™é«˜ä»·å€¼ç‰¹å¾ï¼›å…¶æ¬¡ï¼Œæå‡ºäº†è‡ªé€‚åº”æ¢¯åº¦åˆ›æ–°å’Œè¯¯å·®æ•æ„Ÿé‡åŒ–æ–¹æ³•ï¼ŒåŠ¨æ€è°ƒæ•´åˆ›æ–°æ¢¯åº¦å‹ç¼©çš„é‡åŒ–çº§åˆ«ï¼›ç¬¬ä¸‰ï¼Œä¼˜åŒ–é€šä¿¡é¢‘ç‡ä»¥æé«˜é€šä¿¡æ•ˆç‡ã€‚é€šè¿‡å¹¿æ³›å®éªŒè¯„ä¼°äº†æˆ‘ä»¬æå‡ºæ¨¡å‹çš„æ€§èƒ½ï¼Œä¸åŸºå‡†æŠ€æœ¯ç›¸æ¯”ï¼Œè¯„ä¼°äº†å‡†ç¡®ç‡ã€æŸå¤±å’Œæ”¶æ•›æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶å®ç°äº†é«˜æ•ˆçš„é€šä¿¡ã€‚ 

---
# Hybrid Graph Embeddings and Louvain Algorithm for Unsupervised Community Detection 

**Title (ZH)**: æ··åˆå›¾åµŒå…¥å’ŒLouvainç®—æ³•åœ¨æ— ç›‘ç£ç¤¾åŒºæ£€æµ‹ä¸­çš„åº”ç”¨ 

**Authors**: Dalila Khettaf, Djamel Djenouri, Zeinab Rezaeifar, Youcef Djenouri  

**Link**: [PDF](https://arxiv.org/pdf/2509.23411)  

**Abstract**: This paper proposes a novel community detection method that integrates the Louvain algorithm with Graph Neural Networks (GNNs), enabling the discovery of communities without prior knowledge. Compared to most existing solutions, the proposed method does not require prior knowledge of the number of communities. It enhances the Louvain algorithm using node embeddings generated by a GNN to capture richer structural and feature information. Furthermore, it introduces a merging algorithm to refine the results of the enhanced Louvain algorithm, reducing the number of detected communities. To the best of our knowledge, this work is the first one that improves the Louvain algorithm using GNNs for community detection. The improvement of the proposed method was empirically confirmed through an evaluation on real-world datasets. The results demonstrate its ability to dynamically adjust the number of detected communities and increase the detection accuracy in comparison with the benchmark solutions. 

**Abstract (ZH)**: æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†Louvainç®—æ³•ä¸å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰é›†æˆçš„æ–°é¢–ç¤¾åŒºæ£€æµ‹æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ— å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹å‘ç°ç¤¾åŒºã€‚ä¸å¤§å¤šæ•°ç°æœ‰è§£å†³æ–¹æ¡ˆä¸åŒï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦çŸ¥é“ç¤¾åŒºçš„æ•°é‡ã€‚è¯¥æ–¹æ³•é€šè¿‡ä½¿ç”¨GNNç”Ÿæˆçš„èŠ‚ç‚¹åµŒå…¥æ¥å¢å¼ºLouvainç®—æ³•ï¼Œä»¥æ•è·æ›´ä¸°å¯Œçš„ç»“æ„å’Œç‰¹å¾ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œå®ƒå¼•å…¥äº†ä¸€ç§èšç±»ç®—æ³•æ¥ç»†åŒ–å¢å¼ºåçš„Louvainç®—æ³•çš„ç»“æœï¼Œå‡å°‘äº†æ£€æµ‹åˆ°çš„ç¤¾åŒºæ•°é‡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡ä½¿ç”¨GNNså¢å¼ºLouvainç®—æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹çš„å·¥ä½œã€‚é€šè¿‡åœ¨å®é™…æ•°æ®é›†ä¸Šçš„è¯„ä¼°ï¼Œå®è¯éªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æ”¹è¿›æ•ˆæœã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨åŠ¨æ€è°ƒæ•´æ£€æµ‹åˆ°çš„ç¤¾åŒºæ•°é‡å’Œæé«˜æ£€æµ‹å‡†ç¡®æ€§æ–¹é¢ä¼˜äºåŸºå‡†è§£å†³æ–¹æ¡ˆã€‚ 

---
# Graph Your Own Prompt 

**Title (ZH)**: ç»˜åˆ¶ä½ è‡ªå·±çš„æç¤ºå›¾è°± 

**Authors**: Xi Ding, Lei Wang, Piotr Koniusz, Yongsheng Gao  

**Link**: [PDF](https://arxiv.org/pdf/2509.23373)  

**Abstract**: We propose Graph Consistency Regularization (GCR), a novel framework that injects relational graph structures, derived from model predictions, into the learning process to promote class-aware, semantically meaningful feature representations. Functioning as a form of self-prompting, GCR enables the model to refine its internal structure using its own outputs. While deep networks learn rich representations, these often capture noisy inter-class similarities that contradict the model's predicted semantics. GCR addresses this issue by introducing parameter-free Graph Consistency Layers (GCLs) at arbitrary depths. Each GCL builds a batch-level feature similarity graph and aligns it with a global, class-aware masked prediction graph, derived by modulating softmax prediction similarities with intra-class indicators. This alignment enforces that feature-level relationships reflect class-consistent prediction behavior, acting as a semantic regularizer throughout the network. Unlike prior work, GCR introduces a multi-layer, cross-space graph alignment mechanism with adaptive weighting, where layer importance is learned from graph discrepancy magnitudes. This allows the model to prioritize semantically reliable layers and suppress noisy ones, enhancing feature quality without modifying the architecture or training procedure. GCR is model-agnostic, lightweight, and improves semantic structure across various networks and datasets. Experiments show that GCR promotes cleaner feature structure, stronger intra-class cohesion, and improved generalization, offering a new perspective on learning from prediction structure. [Project website](this https URL) [Code](this https URL) 

**Abstract (ZH)**: æˆ‘ä»¬æå‡ºå›¾ä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼ˆGCRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡å°†æºè‡ªæ¨¡å‹é¢„æµ‹çš„å…³ç³»å›¾ç»“æ„æ³¨å…¥å­¦ä¹ è¿‡ç¨‹ï¼Œä¿ƒè¿›å…·æœ‰ç±»æ„è¯†å’Œè¯­ä¹‰æ„ä¹‰çš„ç‰¹å¾è¡¨ç¤ºã€‚ä½œä¸ºä¸€ç§è‡ªæˆ‘æç¤ºçš„å½¢å¼ï¼ŒGCRä½¿æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨è‡ªèº«çš„è¾“å‡ºæ¥ç²¾åŒ–å…¶å†…éƒ¨ç»“æ„ã€‚è™½ç„¶æ·±å±‚ç½‘ç»œå­¦ä¹ åˆ°ä¸°å¯Œçš„è¡¨ç¤ºï¼Œä½†è¿™äº›è¡¨ç¤ºå¾€å¾€åŒ…å«ä¸æ¨¡å‹é¢„æµ‹çš„è¯­ä¹‰ç›¸çŸ›ç›¾çš„å˜ˆæ‚è·¨ç±»ç›¸ä¼¼æ€§ã€‚GCRé€šè¿‡åœ¨ä»»æ„æ·±åº¦å¼•å…¥æ— å‚æ•°çš„å›¾ä¸€è‡´æ€§å±‚ï¼ˆGCLsï¼‰æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æ¯ä¸ªGCLæ„å»ºä¸€æ‰¹æ¬¡çº§åˆ«çš„ç‰¹å¾ç›¸ä¼¼å›¾ï¼Œå¹¶å°†å…¶ä¸é€šè¿‡è°ƒæ•´softmaxé¢„æµ‹ç›¸ä¼¼åº¦ä¸ç±»åˆ«å†…æŒ‡ç¤ºç¬¦æ¥ç”Ÿæˆçš„å…¨å±€ç±»æ„è¯†æ©ç é¢„æµ‹å›¾å¯¹é½ã€‚è¿™ç§å¯¹é½ç¡®ä¿ç‰¹å¾çº§åˆ«çš„å…³ç³»åæ˜ å‡ºç±»ä¸€è‡´çš„é¢„æµ‹è¡Œä¸ºï¼Œä½œä¸ºä¸€ç§è¯­ä¹‰æ­£åˆ™åŒ–åœ¨æ•´ä¸ªç½‘ç»œä¸­èµ·ä½œç”¨ã€‚ä¸ä»¥å‰çš„å·¥ä½œä¸åŒï¼ŒGCRå¼•å…¥äº†ä¸€ç§å¤šå±‚ã€è·¨ç©ºé—´çš„å›¾å¯¹é½æœºåˆ¶ï¼Œå…·æœ‰è‡ªé€‚åº”åŠ æƒï¼Œå…¶ä¸­å±‚çš„é‡è¦æ€§æ˜¯ä»å›¾å·®å¼‚å¹…åº¦ä¸­å­¦ä¹ åˆ°çš„ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿä¼˜å…ˆè€ƒè™‘è¯­ä¹‰å¯é çš„å±‚å¹¶æŠ‘åˆ¶å˜ˆæ‚çš„å±‚ï¼Œæé«˜ç‰¹å¾è´¨é‡è€Œä¸ä¿®æ”¹æ¶æ„æˆ–è®­ç»ƒè¿‡ç¨‹ã€‚GCRå…·æœ‰æ¨¡å‹æ— å…³æ€§ï¼Œè½»é‡çº§ï¼Œå¹¶åœ¨å„ç§ç½‘ç»œå’Œæ•°æ®é›†ä¸Šå¢å¼ºäº†è¯­ä¹‰ç»“æ„ã€‚å®éªŒè¡¨æ˜ï¼ŒGCRä¿ƒè¿›äº†æ›´æ¸…æ´çš„ç‰¹å¾ç»“æ„ã€æ›´å¼ºçš„ç±»å†…å‡èšæ€§å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºä»é¢„æµ‹ç»“æ„å­¦ä¹ æä¾›äº†æ–°çš„è§†è§’ã€‚[é¡¹ç›®ç½‘ç«™](this https URL) [ä»£ç ](this https URL) 

---
# AI Education in Higher Education: A Taxonomy for Curriculum Reform and the Mission of Knowledge 

**Title (ZH)**: é«˜ç­‰æ•™è‚²ä¸­çš„AIæ•™è‚²ï¼šè¯¾ç¨‹æ”¹é©çš„åˆ†ç±»å­¦åŠå…¶çŸ¥è¯†ä½¿å‘½ 

**Authors**: Tian Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.23363)  

**Abstract**: Artificial intelligence (AI) is reshaping higher education, yet current debates often feel tangled, mixing concerns about pedagogy, operations, curriculum, and the future of work without a shared framework. This paper offers a first attempt at a taxonomy to organize the diverse narratives of AI education and to inform discipline-based curricular discussions. We place these narratives within the enduring responsibility of higher education: the mission of knowledge. This mission includes not only the preservation and advancement of disciplinary expertise, but also the cultivation of skills and wisdom, i.e., forms of meta-knowledge that encompass judgment, ethics, and social responsibility. For the purpose of this paper's discussion, AI is defined as adaptive, data-driven systems that automate analysis, modeling, and decision-making, highlighting its dual role as enabler and disruptor across disciplines. We argue that the most consequential challenges lie at the level of curriculum and disciplinary purpose, where AI accelerates inquiry but also unsettles expertise and identity. We show how disciplines evolve through the interplay of research, curriculum, pedagogy, and faculty expertise, and why curricular reform is the central lever for meaningful change. Pedagogical innovation offers a strategic and accessible entry point, providing actionable steps that help faculty and students build the expertise needed to engage in deeper curricular rethinking and disciplinary renewal. Within this framing, we suggest that meaningful reform can move forward through structured faculty journeys: from AI literacy to pedagogy, curriculum design, and research integration. The key is to align these journeys with the mission of knowledge, turning the disruptive pressures of AI into opportunities for disciplines to sustain expertise, advance inquiry, and serve society. 

**Abstract (ZH)**: äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ­£é‡å¡‘é«˜ç­‰æ•™è‚²ï¼Œç„¶è€Œå½“å‰çš„è¾©è®ºå¾€å¾€æ˜¾å¾—æ‚ä¹±æ— ç« ï¼Œäº¤ç»‡ç€å…³äºæ•™å­¦æ–¹æ³•ã€è¿è¥ã€è¯¾ç¨‹å’Œæœªæ¥å·¥ä½œå‰æ™¯çš„æ‹…å¿§ï¼Œç¼ºä¹ä¸€ä¸ªå…±åŒçš„æ¡†æ¶ã€‚æœ¬æ–‡æ—¨åœ¨é¦–æ¬¡å°è¯•æ„å»ºä¸€ç§åˆ†ç±»æ³•ï¼Œä»¥ç»„ç»‡AIæ•™è‚²çš„å¤šæ ·å™äº‹ï¼Œå¹¶ä¸ºåŸºäºå­¦ç§‘çš„è¯¾ç¨‹è®¨è®ºæä¾›æŒ‡å¯¼ã€‚æˆ‘ä»¬å°†è¿™äº›å™äº‹ç½®äºé«˜ç­‰æ•™è‚²æ°¸æ’çš„è´£ä»»ä¹‹ä¸­ï¼šçŸ¥è¯†ä¼ æ‰¿çš„ä»»åŠ¡ã€‚è¿™ä¸€ä»»åŠ¡ä¸ä»…åŒ…æ‹¬å­¦ç§‘ä¸“é•¿çš„ä¿å­˜ä¸å‘å±•ï¼Œè¿˜åŒ…æ‹¬æŠ€èƒ½å’Œæ™ºæ…§ï¼ˆå³åˆ¤æ–­ã€ä¼¦ç†å’Œç¤¾ä¼šè´£ä»»ç­‰å½¢å¼çš„å…ƒçŸ¥è¯†ï¼‰çš„åŸ¹å…»ã€‚ä¸ºäº†æœ¬æ–‡çš„è®¨è®ºï¼Œæˆ‘ä»¬å°†äººå·¥æ™ºèƒ½å®šä¹‰ä¸ºé€‚åº”æ€§å¼ºã€æ•°æ®é©±åŠ¨çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–åˆ†æã€å»ºæ¨¡å’Œå†³ç­–ï¼Œå¼ºè°ƒå…¶åœ¨å„å­¦ç§‘ä¸­ä½œä¸ºåŠ©æ¨å™¨å’Œé¢ è¦†è€…çš„åŒé‡è§’è‰²ã€‚æˆ‘ä»¬ä¸»å¼ ï¼Œæœ€é‡å¤§çš„æŒ‘æˆ˜åœ¨äºè¯¾ç¨‹å’Œå­¦ç§‘ç›®æ ‡çš„å±‚é¢ï¼ŒAIåŠ é€Ÿäº†æ¢ç©¶ä½†åŒæ—¶ä¹ŸåŠ¨æ‘‡äº†ä¸“ä¸šå’Œèº«ä»½ã€‚æˆ‘ä»¬å±•ç¤ºäº†å­¦ç§‘é€šè¿‡ç ”ç©¶ã€è¯¾ç¨‹ã€æ•™å­¦å’Œæ•™å‘˜ä¸“é•¿çš„ç›¸äº’ä½œç”¨è€Œæ¼”å˜çš„è¿‡ç¨‹ï¼Œå¹¶é˜æ˜äº†è¯¾ç¨‹æ”¹é©æ˜¯æ¨åŠ¨æœ‰æ„ä¹‰å˜åŒ–çš„ä¸»è¦æ æ†ã€‚æ•™å­¦åˆ›æ–°æä¾›äº†æˆ˜ç•¥æ€§çš„åˆ‡å…¥ç‚¹ï¼Œæä¾›äº†ä¸€ç³»åˆ—å¯æ“ä½œçš„æ­¥éª¤ï¼Œå¸®åŠ©æ•™å‘˜å’Œå­¦ç”ŸåŸ¹å…»åœ¨æ·±å…¥è¯¾ç¨‹é‡æ€å’Œå­¦ç§‘æ›´æ–°ä¸­æ‰€éœ€çš„ä¸“ä¸šèƒ½åŠ›ã€‚åœ¨è¿™ç§æ¡†æ¶ä¸‹ï¼Œæˆ‘ä»¬å»ºè®®ï¼Œæœ‰æ„ä¹‰çš„æ”¹é©å¯ä»¥é€šè¿‡ç»“æ„åŒ–æ•™å‘˜æ—…ç¨‹æ¨è¿›ï¼šä»äººå·¥æ™ºèƒ½ç´ å…»åˆ°æ•™å­¦æ–¹æ³•ã€è¯¾ç¨‹è®¾è®¡å’Œç ”ç©¶æ•´åˆã€‚å…³é”®åœ¨äºå°†è¿™äº›æ—…ç¨‹ä¸çŸ¥è¯†ä¼ æ‰¿ä»»åŠ¡ç›¸ä¸€è‡´ï¼Œå°†AIå¸¦æ¥çš„é¢ è¦†æ€§å‹åŠ›è½¬å˜ä¸ºå­¦ç§‘ä¿æŒä¸“ä¸šèƒ½åŠ›ã€æ¨è¿›æ¢ç©¶å’Œç¤¾ä¼šæœåŠ¡çš„æœºä¼šã€‚ 

---
# Dynamic-TreeRPO: Breaking the Independent Trajectory Bottleneck with Structured Sampling 

**Title (ZH)**: åŠ¨æ€æ ‘RPOï¼šé€šè¿‡ç»“æ„åŒ–é‡‡æ ·æ‰“ç ´ç‹¬ç«‹è½¨è¿¹ç“¶é¢ˆ 

**Authors**: Xiaolong Fu, Lichen Ma, Zipeng Guo, Gaojing Zhou, Chongxiao Wang, ShiPing Dong, Shizhe Zhou, Shizhe Zhou, Ximan Liu, Jingling Fu, Tan Lit Sin, Yu Shi, Zhen Chen, Junshi Huang, Jason Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.23352)  

**Abstract**: The integration of Reinforcement Learning (RL) into flow matching models for text-to-image (T2I) generation has driven substantial advances in generation quality. However, these gains often come at the cost of exhaustive exploration and inefficient sampling strategies due to slight variation in the sampling group. Building on this insight, we propose Dynamic-TreeRPO, which implements the sliding-window sampling strategy as a tree-structured search with dynamic noise intensities along depth. We perform GRPO-guided optimization and constrained Stochastic Differential Equation (SDE) sampling within this tree structure. By sharing prefix paths of the tree, our design effectively amortizes the computational overhead of trajectory search. With well-designed noise intensities for each tree layer, Dynamic-TreeRPO can enhance the variation of exploration without any extra computational cost. Furthermore, we seamlessly integrate Supervised Fine-Tuning (SFT) and RL paradigm within Dynamic-TreeRPO to construct our proposed LayerTuning-RL, reformulating the loss function of SFT as a dynamically weighted Progress Reward Model (PRM) rather than a separate pretraining method. By associating this weighted PRM with dynamic-adaptive clipping bounds, the disruption of exploration process in Dynamic-TreeRPO is avoided. Benefiting from the tree-structured sampling and the LayerTuning-RL paradigm, our model dynamically explores a diverse search space along effective directions. Compared to existing baselines, our approach demonstrates significant superiority in terms of semantic consistency, visual fidelity, and human preference alignment on established benchmarks, including HPS-v2.1, PickScore, and ImageReward. In particular, our model outperforms SoTA by $4.9\%$, $5.91\%$, and $8.66\%$ on those benchmarks, respectively, while improving the training efficiency by nearly $50\%$. 

**Abstract (ZH)**: åŠ¨æ€æ ‘ç»“æ„RPOç»“åˆç›‘ç£å¾®è°ƒä¸ reinforcement learning åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„åº”ç”¨ 

---
# Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal Transfer With Adversarial Scheduling 

**Title (ZH)**: ä»éé²æ£’é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé²æ£’å¾®è°ƒï¼šé€šè¿‡å¯¹æŠ—æ€§è°ƒåº¦å‡è½»æ¬¡ä¼˜è½¬ç§»å½±å“ 

**Authors**: Jonas NgnawÃ©, Maxime Heuillet, Sabyasachi Sahoo, Yann Pequignot, Ola Ahmad, Audrey Durand, FrÃ©dÃ©ric Precioso, Christian GagnÃ©  

**Link**: [PDF](https://arxiv.org/pdf/2509.23325)  

**Abstract**: Fine-tuning pretrained models is a standard and effective workflow in modern machine learning. However, robust fine-tuning (RFT), which aims to simultaneously achieve adaptation to a downstream task and robustness to adversarial examples, remains challenging. Despite the abundance of non-robust pretrained models in open-source repositories, their potential for RFT is less understood. We address this knowledge gap by systematically examining RFT from such non-robust models. Our experiments reveal that fine-tuning non-robust models with a robust objective, even under small perturbations, can lead to poor performance, a phenomenon that we dub \emph{suboptimal transfer}. In challenging scenarios (eg, difficult tasks, high perturbation), the resulting performance can be so low that it may be considered a transfer failure. We find that fine-tuning using a robust objective impedes task adaptation at the beginning of training and eventually prevents optimal transfer. However, we propose a novel heuristic, \emph{Epsilon-Scheduling}, a schedule over perturbation strength used during training that promotes optimal transfer. Additionally, we introduce \emph{expected robustness}, a metric that captures performance across a range of perturbations, providing a more comprehensive evaluation of the accuracy-robustness trade-off for diverse models at test time. Extensive experiments on a wide range of configurations (six pretrained models and five datasets) show that \emph{Epsilon-Scheduling} successfully prevents \emph{suboptimal transfer} and consistently improves expected robustness. 

**Abstract (ZH)**: å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹æ˜¯ç°ä»£æœºå™¨å­¦ä¹ ä¸­çš„æ ‡å‡†ä¸”æœ‰æ•ˆçš„workflowã€‚ç„¶è€Œï¼Œé²æ£’å¾®è°ƒï¼ˆRFTï¼‰ï¼Œå…¶ç›®æ ‡æ˜¯åœ¨é€‚åº”ä¸‹æ¸¸ä»»åŠ¡çš„åŒæ—¶å¢å¼ºå¯¹å¯¹æŠ—æ ·æœ¬çš„é²æ£’æ€§ï¼Œä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å°½ç®¡å¼€æºåº“ä¸­æœ‰å¤§é‡çš„éé²æ£’é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†å®ƒä»¬çš„RFTæ½œåŠ›å°šæœªå……åˆ†ç†è§£ã€‚æˆ‘ä»¬é€šè¿‡ç³»ç»Ÿåœ°ç ”ç©¶è¿™äº›éé²æ£’æ¨¡å‹çš„RFTæ¥å¡«è¡¥è¿™ä¸€çŸ¥è¯†ç©ºç™½ã€‚æˆ‘ä»¬çš„å®éªŒæ­ç¤ºï¼Œå³ä½¿åœ¨å°æ‰°åŠ¨ä¸‹ä½¿ç”¨é²æ£’ç›®æ ‡å¾®è°ƒéé²æ£’æ¨¡å‹ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸ä½³ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œæ¬¡ä¼˜è½¬ç§»â€ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ï¼ˆä¾‹å¦‚ï¼Œå›°éš¾çš„ä»»åŠ¡ã€é«˜æ‰°åŠ¨ï¼‰ï¼Œè¿™ç§æ€§èƒ½å¯èƒ½å¦‚æ­¤ä½ï¼Œä»¥è‡³äºå¯ä»¥è¢«è§†ä¸ºè½¬ç§»å¤±è´¥ã€‚æˆ‘ä»¬å‘ç°ï¼Œä½¿ç”¨é²æ£’ç›®æ ‡è¿›è¡Œå¾®è°ƒåœ¨è®­ç»ƒåˆæœŸé˜»ç¢äº†ä»»åŠ¡é€‚åº”ï¼Œå¹¶æœ€ç»ˆé˜»æ­¢äº†æœ€ä¼˜è½¬ç§»ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯å‘å¼æ–¹æ³•ï¼Œç§°ä¸ºâ€œÎµè°ƒåº¦â€ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ‰°åŠ¨å¼ºåº¦è°ƒåº¦æ–¹æ¡ˆï¼Œå¯ä¿ƒè¿›æœ€ä¼˜è½¬ç§»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†â€œæœŸæœ›é²æ£’æ€§â€è¿™ä¸€åº¦é‡æ ‡å‡†ï¼Œå®ƒæ•æ‰äº†åœ¨ä¸€ç³»åˆ—æ‰°åŠ¨ä¸‹çš„æ€§èƒ½ï¼Œä¸ºæµ‹è¯•æ—¶ä¸åŒæ¨¡å‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§æƒè¡¡æä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°ã€‚å¹¿æ³›é…ç½®ï¼ˆå…­ç§é¢„è®­ç»ƒæ¨¡å‹å’Œäº”ç§æ•°æ®é›†ï¼‰çš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œâ€œÎµè°ƒåº¦â€æˆåŠŸåœ°é˜²æ­¢äº†â€œæ¬¡ä¼˜è½¬ç§»â€ï¼Œå¹¶ä¸”å§‹ç»ˆæé«˜äº†æœŸæœ›é²æ£’æ€§ã€‚ 

---
# MELCOT: A Hybrid Learning Architecture with Marginal Preservation for Matrix-Valued Regression 

**Title (ZH)**: MELCOT: ä¸€ç§å…¼é¡¾è¾¹ç¼˜ä¿ç•™çš„çŸ©é˜µå€¼å›å½’æ··åˆå­¦ä¹ æ¶æ„ 

**Authors**: Khang Tran, Hieu Cao, Thinh Pham, Nghiem Diep, Tri Cao, Binh Nguyen  

**Link**: [PDF](https://arxiv.org/pdf/2509.23315)  

**Abstract**: Regression is essential across many domains but remains challenging in high-dimensional settings, where existing methods often lose spatial structure or demand heavy storage. In this work, we address the problem of matrix-valued regression, where each sample is naturally represented as a matrix. We propose MELCOT, a hybrid model that integrates a classical machine learning-based Marginal Estimation (ME) block with a deep learning-based Learnable-Cost Optimal Transport (LCOT) block. The ME block estimates data marginals to preserve spatial information, while the LCOT block learns complex global features. This design enables MELCOT to inherit the strengths of both classical and deep learning methods. Extensive experiments across diverse datasets and domains demonstrate that MELCOT consistently outperforms all baselines while remaining highly efficient. 

**Abstract (ZH)**: çŸ©é˜µå€¼å›å½’åœ¨é«˜ç»´è®¾ç½®ä¸­è‡³å…³é‡è¦ä½†ä¾ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¼šåœ¨ä¿ç•™ç©ºé—´ç»“æ„æˆ–éœ€è¦å¤§é‡å­˜å‚¨æ–¹é¢é‡åˆ°å›°éš¾ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é›†æˆæ¨¡å‹MELCOTï¼Œè¯¥æ¨¡å‹ç»“åˆäº†åŸºäºç»å…¸æœºå™¨å­¦ä¹ çš„è¾¹ç¼˜ä¼°è®¡ï¼ˆMEï¼‰æ¨¡å—å’ŒåŸºäºæ·±åº¦å­¦ä¹ çš„å¯å­¦ä¹ æˆæœ¬æœ€ä¼˜ä¼ è¾“ï¼ˆLCOTï¼‰æ¨¡å—ã€‚MEæ¨¡å—ä¼°è®¡æ•°æ®è¾¹ç¼˜ä»¥ä¿ç•™ç©ºé—´ä¿¡æ¯ï¼Œè€ŒLCOTæ¨¡å—å­¦ä¹ å¤æ‚çš„å…¨å±€ç‰¹å¾ã€‚è¿™ç§è®¾è®¡ä½¿å¾—MELCOTèƒ½å¤Ÿç»§æ‰¿ç»å…¸å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•çš„ä¼˜ç‚¹ã€‚å¹¿æ³›çš„æ•°æ®é›†å’Œé¢†åŸŸå®éªŒè¡¨æ˜ï¼ŒMELCOTåœ¨æ‰€æœ‰åŸºçº¿æ–¹æ³•ä¸­è¡¨ç°æœ€ä¼˜ä¸”å…·æœ‰å¾ˆé«˜çš„æ•ˆç‡ã€‚ 

---
# A Neural ODE Approach to Aircraft Flight Dynamics Modelling 

**Title (ZH)**: ä¸€ç§åŸºäºç¥ç»ODEçš„èˆªç©ºé£è¡ŒåŠ¨åŠ›å­¦å»ºæ¨¡æ–¹æ³• 

**Authors**: Gabriel Jarry, Ramon Dalmau, Xavier Olive, Philippe Very  

**Link**: [PDF](https://arxiv.org/pdf/2509.23307)  

**Abstract**: Accurate aircraft trajectory prediction is critical for air traffic management, airline operations, and environmental assessment. This paper introduces NODE-FDM, a Neural Ordinary Differential Equations-based Flight Dynamics Model trained on Quick Access Recorder (QAR) data. By combining analytical kinematic relations with data-driven components, NODE-FDM achieves a more accurate reproduction of recorded trajectories than state-of-the-art models such as a BADA-based trajectory generation methodology (BADA4 performance model combined with trajectory control routines), particularly in the descent phase of the flight. The analysis demonstrates marked improvements across altitude, speed, and mass dynamics. Despite current limitations, including limited physical constraints and the limited availability of QAR data, the results demonstrate the potential of physics-informed neural ordinary differential equations as a high-fidelity, data-driven approach to aircraft performance modelling. Future work will extend the framework to incorporate a full modelling of the lateral dynamics of the aircraft. 

**Abstract (ZH)**: åŸºäºç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹çš„é£è¡ŒåŠ¨åŠ›å­¦æ¨¡å‹NODE-FDMåŠå…¶å¯¹é£æœºè½¨è¿¹é¢„æµ‹çš„åº”ç”¨ 

---
# Continuous-Time Reinforcement Learning for Asset-Liability Management 

**Title (ZH)**: è¿ç»­æ—¶é—´å¼ºåŒ–å­¦ä¹ åœ¨èµ„äº§-è´Ÿå€ºç®¡ç†ä¸­çš„åº”ç”¨ 

**Authors**: Yilie Huang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23280)  

**Abstract**: This paper proposes a novel approach for Asset-Liability Management (ALM) by employing continuous-time Reinforcement Learning (RL) with a linear-quadratic (LQ) formulation that incorporates both interim and terminal objectives. We develop a model-free, policy gradient-based soft actor-critic algorithm tailored to ALM for dynamically synchronizing assets and liabilities. To ensure an effective balance between exploration and exploitation with minimal tuning, we introduce adaptive exploration for the actor and scheduled exploration for the critic. Our empirical study evaluates this approach against two enhanced traditional financial strategies, a model-based continuous-time RL method, and three state-of-the-art RL algorithms. Evaluated across 200 randomized market scenarios, our method achieves higher average rewards than all alternative strategies, with rapid initial gains and sustained superior performance. The outperformance stems not from complex neural networks or improved parameter estimation, but from directly learning the optimal ALM strategy without learning the environment. 

**Abstract (ZH)**: åŸºäºè¿ç»­æ—¶é—´å¼ºåŒ–å­¦ä¹ çš„èµ„äº§-è´Ÿå€ºç®¡ç†æ–°æ–¹æ³•ï¼šçº¿æ€§äºŒæ¬¡å½¢å¼å…¼é¡¾ä¸­é—´å’Œæœ€ç»ˆç›®æ ‡ 

---
# Patch Rebirth: Toward Fast and Transferable Model Inversion of Vision Transformers 

**Title (ZH)**: Patch é‡ç”Ÿï¼šæœå‘å¿«é€Ÿå¯ç§»æ¤çš„è§†è§‰å˜æ¢å™¨æ¨¡å‹å€’ç½® 

**Authors**: Seongsoo Heo, Dong-Wan Choi  

**Link**: [PDF](https://arxiv.org/pdf/2509.23235)  

**Abstract**: Model inversion is a widely adopted technique in data-free learning that reconstructs synthetic inputs from a pretrained model through iterative optimization, without access to original training data. Unfortunately, its application to state-of-the-art Vision Transformers (ViTs) poses a major computational challenge, due to their expensive self-attention mechanisms. To address this, Sparse Model Inversion (SMI) was proposed to improve efficiency by pruning and discarding seemingly unimportant patches, which were even claimed to be obstacles to knowledge transfer. However, our empirical findings suggest the opposite: even randomly selected patches can eventually acquire transferable knowledge through continued inversion. This reveals that discarding any prematurely inverted patches is inefficient, as it suppresses the extraction of class-agnostic features essential for knowledge transfer, along with class-specific features. In this paper, we propose Patch Rebirth Inversion (PRI), a novel approach that incrementally detaches the most important patches during the inversion process to construct sparse synthetic images, while allowing the remaining patches to continue evolving for future selection. This progressive strategy not only improves efficiency, but also encourages initially less informative patches to gradually accumulate more class-relevant knowledge, a phenomenon we refer to as the Re-Birth effect, thereby effectively balancing class-agnostic and class-specific knowledge. Experimental results show that PRI achieves up to 10x faster inversion than standard Dense Model Inversion (DMI) and 2x faster than SMI, while consistently outperforming SMI in accuracy and matching the performance of DMI. 

**Abstract (ZH)**: Patch Rebirth Inversionï¼šä¸€ç§æ¸è¿›å¼å…³é”®åŒºåŸŸå†ç”Ÿçš„ç¨€ç–æ¨¡å‹åè½¬æ–¹æ³• 

---
# One-Shot Multi-Label Causal Discovery in High-Dimensional Event Sequences 

**Title (ZH)**: ä¸€-shotå¤šæ ‡ç­¾å› æœå‘ç°é«˜ç»´äº‹ä»¶åºåˆ— 

**Authors**: Hugo Math, Robin SchÃ¶n, Rainer Lienhart  

**Link**: [PDF](https://arxiv.org/pdf/2509.23213)  

**Abstract**: Understanding causality in event sequences with thousands of sparse event types is critical in domains such as healthcare, cybersecurity, or vehicle diagnostics, yet current methods fail to scale. We present OSCAR, a one-shot causal autoregressive method that infers per-sequence Markov Boundaries using two pretrained Transformers as density estimators. This enables efficient, parallel causal discovery without costly global CI testing. On a real-world automotive dataset with 29,100 events and 474 labels, OSCAR recovers interpretable causal structures in minutes, while classical methods fail to scale, enabling practical scientific diagnostics at production scale. 

**Abstract (ZH)**: ç†è§£å«æœ‰æ•°åƒç§ç¨€ç–äº‹ä»¶ç±»å‹çš„äº‹ä»¶åºåˆ—å› æœå…³ç³»åœ¨åŒ»ç–—ä¿å¥ã€ç½‘ç»œå®‰å…¨æˆ–è½¦è¾†è¯Šæ–­ç­‰é¢†åŸŸè‡³å…³é‡è¦ï¼Œä½†å½“å‰æ–¹æ³•æ— æ³•æ‰©å±•ã€‚æˆ‘ä»¬æå‡ºäº†OSCARï¼Œä¸€ç§åŸºäºä¸¤ä¸ªé¢„è®­ç»ƒTransformerä½œä¸ºå¯†åº¦ä¼°è®¡å™¨çš„ä¸€æ¬¡æ€§å› æœè‡ªå›å½’æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ¨æ–­æ¯ä¸ªåºåˆ—çš„é©¬å°”å¯å¤«è¾¹ç•Œï¼Œå®ç°äº†é«˜æ•ˆçš„å¹¶è¡Œå› æœå‘ç°ï¼Œè€Œæ— éœ€æ˜‚è´µçš„å…¨å±€CIæµ‹è¯•ã€‚åœ¨åŒ…å«29,100ä¸ªäº‹ä»¶å’Œ474ä¸ªæ ‡ç­¾çš„ç°å®ä¸–ç•Œæ±½è½¦æ•°æ®é›†ä¸­ï¼ŒOSCARèƒ½å¤Ÿåœ¨å‡ åˆ†é’Ÿå†…æ¢å¤å¯è§£é‡Šçš„å› æœç»“æ„ï¼Œè€Œç»å…¸æ–¹æ³•æ— æ³•æ‰©å±•ï¼Œä»è€Œåœ¨ç”Ÿäº§è§„æ¨¡ä¸Šå®ç°äº†å®ç”¨çš„ç§‘å­¦è¯Šæ–­ã€‚ 

---
# WARBERT: A Hierarchical BERT-based Model for Web API Recommendation 

**Title (ZH)**: WARBERTï¼šä¸€ç§åŸºäºå±‚çº§BERTçš„Web APIæ¨èæ¨¡å‹ 

**Authors**: Zishuo Xu, Yuhong Gu, Dezhong Yao  

**Link**: [PDF](https://arxiv.org/pdf/2509.23175)  

**Abstract**: With the emergence of Web 2.0 and microservices architecture, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Existing solutions typically fall into two categories: recommendation-type methods, which treat each API as a label for classification, and match-type methods, which focus on matching mashups through API retrieval. However, three critical challenges persist: 1) the semantic ambiguities in comparing API and mashup descriptions, 2) the lack of detailed comparisons between the individual API and the mashup in recommendation-type methods, and 3) time inefficiencies for API retrieval in match-type methods. To address these challenges, we propose WARBERT, a hierarchical BERT-based model for Web API recommendation. WARBERT leverages dual-component feature fusion and attention comparison to extract precise semantic representations of API and mashup descriptions. WARBERT consists of two main components: WARBERT(R) for Recommendation and WARBERT(M) for Matching. Specifically, WAR-BERT(R) serves as an initial filter, narrowing down the candidate APIs, while WARBERT(M) refines the matching process by calculating the similarity between candidate APIs and mashup. The final likelihood of a mashup being matched with an API is determined by combining the predictions from WARBERT(R) and WARBERT(M). Additionally, WARBERT(R) incorporates an auxiliary task of mashup category judgment, which enhances its effectiveness in candidate selection. Experimental results on the ProgrammableWeb dataset demonstrate that WARBERT outperforms most existing solutions and achieves improvements of up to 11.7% compared to the model MTFM (Multi-Task Fusion Model), delivering significant enhancements in accuracy and effiency. 

**Abstract (ZH)**: åŸºäºBERTçš„å±‚æ¬¡æ¨¡å‹WARBERTé¢å‘Web APIæ¨è 

---
# Dense associative memory on the Bures-Wasserstein space 

**Title (ZH)**: Bures-Wassersteinç©ºé—´ä¸­çš„å¯†é›†å…³è”è®°å¿† 

**Authors**: Chandan Tankala, Krishnakumar Balasubramanian  

**Link**: [PDF](https://arxiv.org/pdf/2509.23162)  

**Abstract**: Dense associative memories (DAMs) store and retrieve patterns via energy-functional fixed points, but existing models are limited to vector representations. We extend DAMs to probability distributions equipped with the 2-Wasserstein distance, focusing mainly on the Bures-Wasserstein class of Gaussian densities. Our framework defines a log-sum-exp energy over stored distributions and a retrieval dynamics aggregating optimal transport maps in a Gibbs-weighted manner. Stationary points correspond to self-consistent Wasserstein barycenters, generalizing classical DAM fixed points. We prove exponential storage capacity, provide quantitative retrieval guarantees under Wasserstein perturbations, and validate the model on synthetic and real-world distributional tasks. This work elevates associative memory from vectors to full distributions, bridging classical DAMs with modern generative modeling and enabling distributional storage and retrieval in memory-augmented learning. 

**Abstract (ZH)**: ç¨ å¯†å…³è”è®°å¿†ï¼ˆDAMsï¼‰é€šè¿‡èƒ½é‡å‡½æ•°çš„å›ºå®šç‚¹å­˜å‚¨å’Œæ£€ç´¢æ¨¡å¼ï¼Œä½†ç°æœ‰æ¨¡å‹ä»…é™äºå‘é‡è¡¨ç¤ºã€‚æˆ‘ä»¬æ‰©å±•äº†DAMsåˆ°é…å¤‡2- Wassersteinè·ç¦»çš„æ¦‚ç‡åˆ†å¸ƒï¼Œé‡ç‚¹å…³æ³¨Bures-Wassersteinç±»é«˜æ–¯å¯†åº¦ã€‚æˆ‘ä»¬çš„æ¡†æ¶å®šä¹‰äº†å­˜å‚¨åˆ†å¸ƒä¸Šçš„å¯¹æ•°å’Œæœ€å¤§å€¼èƒ½é‡ï¼Œå¹¶é€šè¿‡å‰å¸ƒæ–¯åŠ æƒæ–¹å¼èšåˆå¹¶æ£€ç´¢æœ€ä¼˜è¿è¾“æ˜ å°„ã€‚ç¨³å®šç‚¹å¯¹åº”äºè‡ªæ´½çš„Wassersteinå¹³å‡ä¸­å¿ƒï¼Œæ¨å¹¿äº†ç»å…¸çš„DAMå›ºå®šç‚¹ã€‚æˆ‘ä»¬è¯æ˜äº†æŒ‡æ•°çº§çš„å­˜å‚¨å®¹é‡ï¼Œåœ¨Wassersteinæ‰°åŠ¨ä¸‹æä¾›äº†å®šé‡çš„æ£€ç´¢ä¿è¯ï¼Œå¹¶åœ¨åˆæˆå’Œå®é™…åˆ†å¸ƒä»»åŠ¡ä¸ŠéªŒè¯äº†è¯¥æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œå°†å…³è”è®°å¿†ä»å‘é‡æå‡åˆ°å®Œæ•´çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå°†ç»å…¸çš„DAMä¸ç°ä»£ç”Ÿæˆå»ºæ¨¡ç›¸ç»“åˆï¼Œä½¿è®°å¿†å¢å¼ºå­¦ä¹ ä¸­çš„åˆ†å¸ƒå­˜å‚¨å’Œæ£€ç´¢æˆä¸ºå¯èƒ½ã€‚ 

---
# Deep Learning-Based Detection of Cognitive Impairment from Passive Smartphone Sensing with Routine-Aware Augmentation and Demographic Personalization 

**Title (ZH)**: åŸºäºæ·±åº¦å­¦ä¹ çš„åŸºäºè¢«åŠ¨æ™ºèƒ½æ‰‹æœº sensing çš„è®¤çŸ¥éšœç¢æ£€æµ‹ï¼šå¸¦æœ‰æ´»åŠ¨æ„ŸçŸ¥å¢å¼ºå’Œä¸ªäººåŒ–demographicå‚æ•°æ–¹æ³• 

**Authors**: Yufei Shen, Ji Hwan Park, Minchao Huang, Jared F. Benge, Justin F. Rousseau, Rosemary A. Lester-Smith, Edison Thomaz  

**Link**: [PDF](https://arxiv.org/pdf/2509.23158)  

**Abstract**: Early detection of cognitive impairment is critical for timely diagnosis and intervention, yet infrequent clinical assessments often lack the sensitivity and temporal resolution to capture subtle cognitive declines in older adults. Passive smartphone sensing has emerged as a promising approach for naturalistic and continuous cognitive monitoring. Building on this potential, we implemented a Long Short-Term Memory (LSTM) model to detect cognitive impairment from sequences of daily behavioral features, derived from multimodal sensing data collected in an ongoing one-year study of older adults. Our key contributions are two techniques to enhance model generalizability across participants: (1) routine-aware augmentation, which generates synthetic sequences by replacing each day with behaviorally similar alternatives, and (2) demographic personalization, which reweights training samples to emphasize those from individuals demographically similar to the test participant. Evaluated on 6-month data from 36 older adults, these techniques jointly improved the Area Under the Precision-Recall Curve (AUPRC) of the model trained on sensing and demographic features from 0.637 to 0.766, highlighting the potential of scalable monitoring of cognitive impairment in aging populations with passive sensing. 

**Abstract (ZH)**: æ—©æœŸè®¤çŸ¥æŸå®³çš„æ£€æµ‹å¯¹äºåŠæ—¶è¯Šæ–­å’Œå¹²é¢„è‡³å…³é‡è¦ï¼Œä½†é¢‘ç¹ä¸è¶³çš„ä¸´åºŠè¯„ä¼°å¾€å¾€ç¼ºä¹æ•æ„Ÿæ€§å’Œæ—¶åºåˆ†è¾¨ç‡æ¥æ•æ‰è€å¹´äººçš„ç»†å¾®è®¤çŸ¥ä¸‹é™ã€‚è¢«åŠ¨æ™ºèƒ½æ‰‹æœºä¼ æ„Ÿå·²æˆä¸ºè‡ªç„¶ä¸”æŒç»­è®¤çŸ¥ç›‘æµ‹çš„æœ‰å‰é€”çš„æ–¹æ³•ã€‚åŸºäºè¿™ä¸€æ½œåŠ›ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªé•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰æ¨¡å‹ï¼Œç”¨äºä»æŒç»­ä¸€å¹´çš„è€å¹´äººç¾¤å¤šæ¨¡æ€ä¼ æ„Ÿæ•°æ®ä¸­æå–çš„æ¯æ—¥è¡Œä¸ºç‰¹å¾åºåˆ—æ£€æµ‹è®¤çŸ¥æŸå®³ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯ä¸¤ç§å¢å¼ºæ¨¡å‹æ³›åŒ–æ€§çš„æŠ€æœ¯ï¼šï¼ˆ1ï¼‰åŸºäºæ—¥å¸¸ä¹ æƒ¯çš„å¢å¼ºï¼Œé€šè¿‡ç”¨è¡Œä¸ºç›¸ä¼¼çš„æ›¿ä»£æ—¥æ¥æ›¿æ¢æ¯ä¸€å¤©ç”Ÿæˆåˆæˆåºåˆ—ï¼Œä»¥åŠï¼ˆ2ï¼‰åŸºäºäººå£ç‰¹å¾ä¸ªæ€§åŒ–ï¼Œé€šè¿‡å¯¹ç±»ä¼¼äºæµ‹è¯•å‚ä¸è€…çš„äººç¾¤çš„æ ·æœ¬é‡æ–°åŠ æƒæ¥å¼ºè°ƒå…¶é‡è¦æ€§ã€‚åœ¨36åè€å¹´äºº6ä¸ªæœˆçš„æ•°æ®ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¿™ä¸¤ç§æŠ€æœ¯å…±åŒå°†ä½¿ç”¨ä¼ æ„Ÿå’Œäººå£ç‰¹å¾è®­ç»ƒçš„æ¨¡å‹çš„ç²¾å‡†å¬å›æ›²çº¿ä¸‹é¢ç§¯ï¼ˆAUPRCï¼‰ä»0.637æé«˜åˆ°0.766ï¼Œçªæ˜¾äº†ä½¿ç”¨è¢«åŠ¨ä¼ æ„Ÿè¿›è¡Œè®¤çŸ¥æŸå®³çš„å¯æ‰©å±•ç›‘æµ‹åœ¨è€é¾„åŒ–äººç¾¤ä¸­çš„æ½œåŠ›ã€‚ 

---
# Trust Region Reward Optimization and Proximal Inverse Reward Optimization Algorithm 

**Title (ZH)**: ä¿¡èµ–åŒºåŸŸå¥–åŠ±ä¼˜åŒ–ä¸è¿‘ç«¯é€†å¥–åŠ±ä¼˜åŒ–ç®—æ³• 

**Authors**: Yang Chen, Menglin Zou, Jiaqi Zhang, Yitan Zhang, Junyi Yang, Gael Gendron, Libo Zhang, Jiamou Liu, Michael J. Witbrock  

**Link**: [PDF](https://arxiv.org/pdf/2509.23135)  

**Abstract**: Inverse Reinforcement Learning (IRL) learns a reward function to explain expert demonstrations. Modern IRL methods often use the adversarial (minimax) formulation that alternates between reward and policy optimization, which often lead to unstable training. Recent non-adversarial IRL approaches improve stability by jointly learning reward and policy via energy-based formulations but lack formal guarantees. This work bridges this gap. We first present a unified view showing canonical non-adversarial methods explicitly or implicitly maximize the likelihood of expert behavior, which is equivalent to minimizing the expected return gap. This insight leads to our main contribution: Trust Region Reward Optimization (TRRO), a framework that guarantees monotonic improvement in this likelihood via a Minorization-Maximization process. We instantiate TRRO into Proximal Inverse Reward Optimization (PIRO), a practical and stable IRL algorithm. Theoretically, TRRO provides the IRL counterpart to the stability guarantees of Trust Region Policy Optimization (TRPO) in forward RL. Empirically, PIRO matches or surpasses state-of-the-art baselines in reward recovery, policy imitation with high sample efficiency on MuJoCo and Gym-Robotics benchmarks and a real-world animal behavior modeling task. 

**Abstract (ZH)**: é€†å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¿¡ä»»åŒºåŸŸå¥–åŠ±ä¼˜åŒ–ï¼ˆTRROï¼‰ 

---
# C$^2$GSPG: Confidence-calibrated Group Sequence Policy Gradient towards Self-aware Reasoning 

**Title (ZH)**: C$^2$GSPG: ä¿¡å¿ƒæ ¡å‡†çš„ç¾¤ä½“åºåˆ—ç­–ç•¥æ¢¯åº¦ toward è‡ªæˆ‘æ„è¯†æ¨ç† 

**Authors**: Haotian Liu, Shuo Wang, Hongteng Xu  

**Link**: [PDF](https://arxiv.org/pdf/2509.23129)  

**Abstract**: Reinforcement Learning (RL) methods, exemplified by Group Relative Policy Optimization (GRPO) and its variants, play a central role in developing reasoning models. However, these methods often suffer from a critical overconfidence issue, which prevents them from achieving self-aware reasoning models. In this study, we propose a simple yet effective confidence-calibration group sequence policy gradient method, called C$^2$GSPG, which simultaneously enhances reasoning performance while suppressing overconfidence. In principle, we propose a Group Sequence Policy Gradient (GSPG) framework for learning reasoning models, which eliminates the token-level bias commonly appearing in GRPO and its variants. In this framework, we define the model confidence for each reasoning problem using the normalized sequence-level probability, and then apply a cross-entropy regularizer to calibrate the model confidence to the sequence's reward. We demonstrate that the confidence calibration regularizer and GSPG are collaborative for binary rewards, as their objectives always share the same gradient direction. For non-binary rewards, we apply nonlinear reward normalization and adaptive regularizer clipping, mitigating the potential conflict between the two objectives. Applying C$^2$GSPG to post-train large language models in logical and mathematical reasoning tasks, we show its superiority over state-of-the-art methods in both reasoning accuracy and confidence calibration. The code of C$^2$GSPG is available at this https URL. 

**Abstract (ZH)**: åŸºäºä¿¡å¿ƒæ ¡å‡†çš„ç»„åºåˆ—ç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼ˆC$^2$GSPGï¼‰åŠå…¶åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨ 

---
# HTMA-Net: Towards Multiplication-Avoiding Neural Networks via Hadamard Transform and In-Memory Computing 

**Title (ZH)**: HTMA-Netï¼šé€šè¿‡å“ˆè¾¾ç›å˜æ¢å’Œå†…å­˜è®¡ç®—å®ç°çš„é¿å…ä¹˜æ³•çš„ç¥ç»ç½‘ç»œ 

**Authors**: Emadeldeen Hamdan, Ahmet Enis Cetin  

**Link**: [PDF](https://arxiv.org/pdf/2509.23103)  

**Abstract**: Reducing the cost of multiplications is critical for efficient deep neural network deployment, especially in energy-constrained edge devices. In this work, we introduce HTMA-Net, a novel framework that integrates the Hadamard Transform (HT) with multiplication-avoiding (MA) SRAM-based in-memory computing to reduce arithmetic complexity while maintaining accuracy. Unlike prior methods that only target multiplications in convolutional layers or focus solely on in-memory acceleration, HTMA-Net selectively replaces intermediate convolutions with Hybrid Hadamard-based transform layers whose internal convolutions are implemented via multiplication-avoiding in-memory operations. We evaluate HTMA-Net on ResNet-18 using CIFAR-10, CIFAR-100, and Tiny ImageNet, and provide a detailed comparison against regular, MF-only, and HT-only variants. Results show that HTMA-Net eliminates up to 52\% of multiplications compared to baseline ResNet-18, ResNet-20, and ResNet-50 models, while achieving comparable accuracy in evaluation and significantly reducing computational complexity and the number of parameters. Our results demonstrate that combining structured Hadamard transform layers with SRAM-based in-memory computing multiplication-avoiding operators is a promising path towards efficient deep learning architectures. 

**Abstract (ZH)**: é™ä½ä¹˜æ³•æˆæœ¬å¯¹äºé«˜æ•ˆéƒ¨ç½²æ·±åº¦ç¥ç»ç½‘ç»œè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨èƒ½é‡å—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚æœ¬æ–‡æå‡ºHTMA-Netï¼Œè¿™æ˜¯ä¸€ç§å°†å“ˆè¾¾ç›å˜æ¢ï¼ˆHTï¼‰ä¸é¿å…ä¹˜æ³•ï¼ˆMAï¼‰çš„SRAMåŸºå†…å­˜è®¡ç®—ç›¸ç»“åˆçš„æ–°æ¡†æ¶ï¼Œä»¥å‡å°‘ç®—æœ¯å¤æ‚åº¦åŒæ—¶ä¿æŒç²¾åº¦ã€‚ 

---
# Towards Quantum-Ready Blockchain Fraud Detection via Ensemble Graph Neural Networks 

**Title (ZH)**: é¢å‘é‡å­è®¡ç®—çš„åŒºå—é“¾æ¬ºè¯ˆæ£€æµ‹ ensemble å›¾ç¥ç»ç½‘ç»œæ–¹æ³• 

**Authors**: M.Z. Haider, Tayyaba Noreen, M. Salman  

**Link**: [PDF](https://arxiv.org/pdf/2509.23101)  

**Abstract**: Blockchain Business applications and cryptocurrencies such as enable secure, decentralized value transfer, yet their pseudonymous nature creates opportunities for illicit activity, challenging regulators and exchanges in anti money laundering (AML) enforcement. Detecting fraudulent transactions in blockchain networks requires models that can capture both structural and temporal dependencies while remaining resilient to noise, imbalance, and adversarial behavior. In this work, we propose an ensemble framework that integrates Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and Graph Isomorphism Networks (GIN) to enhance blockchain fraud detection. Using the real-world Elliptic dataset, our tuned soft voting ensemble achieves high recall of illicit transactions while maintaining a false positive rate below 1%, beating individual GNN models and baseline methods. The modular architecture incorporates quantum-ready design hooks, allowing seamless future integration of quantum feature mappings and hybrid quantum classical graph neural networks. This ensures scalability, robustness, and long-term adaptability as quantum computing technologies mature. Our findings highlight ensemble GNNs as a practical and forward-looking solution for real-time cryptocurrency monitoring, providing both immediate AML utility and a pathway toward quantum-enhanced financial security analytics. 

**Abstract (ZH)**: åŒºå—é“¾ä¸šåŠ¡åº”ç”¨ä¸åŠ å¯†è´§å¸ enables å®‰å…¨çš„ã€å»ä¸­å¿ƒåŒ–çš„ä»·å€¼ä¼ è¾“ï¼Œä½†å…¶å‡åæ€§è´¨ä¸ºéæ³•æ´»åŠ¨åˆ›é€ äº†æœºä¼šï¼ŒæŒ‘æˆ˜ç€ç›‘ç®¡æœºæ„å’Œäº¤æ˜“æ‰€çš„åæ´—é’±ï¼ˆAMLï¼‰æ‰§æ³•å·¥ä½œã€‚æ£€æµ‹åŒºå—é“¾ç½‘ç»œä¸­çš„è™šå‡äº¤æ˜“éœ€è¦èƒ½å¤Ÿæ•æ‰ç»“æ„å’Œæ—¶é—´ä¾èµ–æ€§åŒæ—¶å¯¹æŠ—å™ªå£°ã€ä¸å¹³è¡¡å’Œæ¶æ„è¡Œä¸ºçš„æ¨¡å‹ã€‚åœ¨æ­¤é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é›†æˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰ã€å›¾æ³¨æ„ç½‘ç»œï¼ˆGATï¼‰å’Œå›¾åŒæ„ç½‘ç»œï¼ˆGINï¼‰ï¼Œä»¥å¢å¼ºåŒºå—é“¾æ¬ºè¯ˆæ£€æµ‹ã€‚é€šè¿‡ä½¿ç”¨å®é™…ä¸–ç•Œä¸­çš„Ellipticæ•°æ®é›†ï¼Œæˆ‘ä»¬è°ƒä¼˜åçš„è½¯æŠ•ç¥¨é›†æˆæ–¹æ³•åœ¨ä¿æŒå‡é˜³æ€§ç‡ä½äº1%çš„å‰æä¸‹å®ç°äº†å¯¹éæ³•äº¤æ˜“çš„é«˜å¬å›ç‡ï¼Œè¶…è¶Šäº†å•ç‹¬çš„å›¾ç¥ç»ç½‘ç»œæ¨¡å‹å’ŒåŸºçº¿æ–¹æ³•ã€‚è¯¥æ¨¡å—åŒ–æ¶æ„é›†æˆäº†é‡å­å°±ç»ªçš„è®¾è®¡é’©å­ï¼Œå…è®¸æ— ç¼åœ°å°†é‡å­ç‰¹å¾æ˜ å°„å’Œæ··åˆé‡å­ç»å…¸å›¾ç¥ç»ç½‘ç»œé›†æˆè¿›æ¥ã€‚è¿™ç¡®ä¿äº†éšç€é‡å­è®¡ç®—æŠ€æœ¯çš„å‘å±•ï¼Œç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€é²æ£’æ€§å’Œé•¿æœŸé€‚åº”æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†é›†æˆGNNsä½œä¸ºä¸€ç§å®ç”¨ä¸”å‰ç»æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºå®æ—¶åŠ å¯†è´§å¸ç›‘æ§ï¼Œæä¾›äº†å³æ—¶çš„åæ´—é’±ï¼ˆAMLï¼‰å®ç”¨æ€§å’Œé€šå¾€é‡å­å¢å¼ºçš„é‡‘èå®‰å…¨åˆ†æçš„é€”å¾„ã€‚ 

---
# Signal Preserving Weight Initialization for Odd-Sigmoid Activations 

**Title (ZH)**: Odd-Sigmoid æ¿€æ´»å‡½æ•°çš„ä¿¡å·ä¿ï¿½ skincare é‡åˆå§‹åŒ– 

**Authors**: Hyunwoo Lee, Hayoung Choi, Hyunju Kim  

**Link**: [PDF](https://arxiv.org/pdf/2509.23085)  

**Abstract**: Activation functions critically influence trainability and expressivity, and recent work has therefore explored a broad range of nonlinearities. However, activations and weight initialization are interdependent: without an appropriate initialization method, nonlinearities can cause saturation, variance collapse, and increased learning rate sensitivity. We address this by defining an odd sigmoid function class and, given any activation f in this class, proposing an initialization method tailored to f. The method selects a noise scale in closed form so that forward activations remain well dispersed up to a target layer, thereby avoiding collapse to zero or saturation. Empirically, the approach trains reliably without normalization layers, exhibits strong data efficiency, and enables learning for activations under which standard initialization methods (Xavier, He, Orthogonal) often do not converge reliably. 

**Abstract (ZH)**: æ¿€æ´»å‡½æ•°å¯¹å¯è®­ç»ƒæ€§å’Œè¡¨å¾èƒ½åŠ›è‡³å…³é‡è¦ï¼Œè¿‘æœŸç ”ç©¶å› æ­¤æ¢ç´¢äº†å¹¿æ³›çš„ä¸€ç³»åˆ—éçº¿æ€§å‡½æ•°ã€‚ç„¶è€Œï¼Œæ¿€æ´»å‡½æ•°å’Œæƒé‡åˆå§‹åŒ–ç›¸äº’ä¾èµ–ï¼šæ²¡æœ‰åˆé€‚çš„æ–¹æ³•ï¼Œéçº¿æ€§å‡½æ•°å¯èƒ½å¯¼è‡´é¥±å’Œã€æ–¹å·®æ¶ˆå¤±å’Œå­¦ä¹ ç‡æ•æ„Ÿæ€§å¢åŠ ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå¥‡æ•°sigmoidå‡½æ•°ç±»ï¼Œå¹¶ä¸ºè¯¥ç±»ä¸­çš„ä»»ä¸€æ¿€æ´»å‡½æ•°æå‡ºäº†ä¸€ç§å®šåˆ¶åŒ–çš„åˆå§‹åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä»¥å°é—­å½¢å¼é€‰æ‹©å™ªå£°å°ºåº¦ï¼Œç¡®ä¿å‰å‘æ¿€æ´»åœ¨ç›®æ ‡å±‚ä¹‹å‰ä¿æŒè‰¯å¥½çš„åˆ†æ•£ï¼Œä»è€Œé¿å…å½’é›¶æˆ–é¥±å’Œã€‚å®è¯ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸ä½¿ç”¨å½’ä¸€åŒ–å±‚çš„æƒ…å†µä¸‹èƒ½å¤Ÿå¯é åœ°è®­ç»ƒï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„æ•°æ®æ•ˆç‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨æ ‡å‡†åˆå§‹åŒ–æ–¹æ³•ï¼ˆXavierã€Heã€æ­£äº¤ï¼‰é€šå¸¸æ— æ³•å¯é æ”¶æ•›çš„æƒ…å†µä¸‹å­¦ä¹ æ¿€æ´»å‡½æ•°ã€‚ 

---
# Beyond Model Ranking: Predictability-Aligned Evaluation for Time Series Forecasting 

**Title (ZH)**: è¶…è¶Šæ¨¡å‹æ’åï¼šæ—¶é—´åºåˆ—é¢„æµ‹çš„å¯é¢„æµ‹æ€§å¯¹é½è¯„ä¼° 

**Authors**: Wanjin Feng, Yuan Yuan, Jingtao Ding, Yong Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.23074)  

**Abstract**: In the era of increasingly complex AI models for time series forecasting, progress is often measured by marginal improvements on benchmark leaderboards. However, this approach suffers from a fundamental flaw: standard evaluation metrics conflate a model's performance with the data's intrinsic unpredictability. To address this pressing challenge, we introduce a novel, predictability-aligned diagnostic framework grounded in spectral coherence. Our framework makes two primary contributions: the Spectral Coherence Predictability (SCP), a computationally efficient ($O(N\log N)$) and task-aligned score that quantifies the inherent difficulty of a given forecasting instance, and the Linear Utilization Ratio (LUR), a frequency-resolved diagnostic tool that precisely measures how effectively a model exploits the linearly predictable information within the data. We validate our framework's effectiveness and leverage it to reveal two core insights. First, we provide the first systematic evidence of "predictability drift", demonstrating that a task's forecasting difficulty varies sharply over time. Second, our evaluation reveals a key architectural trade-off: complex models are superior for low-predictability data, whereas linear models are highly effective on more predictable tasks. We advocate for a paradigm shift, moving beyond simplistic aggregate scores toward a more insightful, predictability-aware evaluation that fosters fairer model comparisons and a deeper understanding of model behavior. 

**Abstract (ZH)**: åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­æ—¥ç›Šå¤æ‚çš„AIæ¨¡å‹æ—¶ä»£ï¼Œè¿›å±•é€šå¸¸é€šè¿‡åŸºå‡†æ’è¡Œæ¦œä¸Šçš„è¾¹é™…æ”¹è¿›æ¥è¡¡é‡ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨æ ¹æœ¬æ€§ç¼ºé™·ï¼šæ ‡å‡†è¯„ä¼°æŒ‡æ ‡å°†æ¨¡å‹æ€§èƒ½ä¸æ•°æ®çš„å›ºæœ‰ä¸å¯é¢„æµ‹æ€§æ··æ·†ã€‚ä¸ºè§£å†³è¿™ä¸€ç´§è¿«æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºé¢‘è°±ç›¸å¹²æ€§çš„æ–°é¢–å¯é¢„æµ‹æ€§å¯¹é½è¯Šæ–­æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„ä¸¤å¤§ä¸»è¦è´¡çŒ®æ˜¯ï¼šé¢‘è°±ç›¸å¹²æ€§å¯é¢„æµ‹æ€§ï¼ˆSCPï¼‰ï¼Œä¸€ç§è®¡ç®—æ•ˆç‡é«˜ï¼ˆ$O(N\log N)$ï¼‰ä¸”ä»»åŠ¡å¯¹é½çš„è¯„åˆ†ï¼Œé‡åŒ–ç»™å®šé¢„æµ‹å®ä¾‹çš„å›ºæœ‰éš¾åº¦ï¼›ä»¥åŠçº¿æ€§åˆ©ç”¨ç‡æ¯”ï¼ˆLURï¼‰ï¼Œä¸€ç§é¢‘ç‡è§£æè¯Šæ–­å·¥å…·ï¼Œç²¾ç¡®æµ‹é‡æ¨¡å‹å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æ•°æ®ä¸­çš„çº¿æ€§å¯é¢„æµ‹ä¿¡æ¯ã€‚æˆ‘ä»¬éªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åˆ©ç”¨å®ƒæ­ç¤ºäº†ä¸¤ä¸ªæ ¸å¿ƒè§è§£ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬é¦–æ¬¡ç³»ç»Ÿåœ°è¯æ˜äº†â€œå¯é¢„æµ‹æ€§æ¼‚ç§»â€ï¼Œæ˜¾ç¤ºä»»åŠ¡çš„é¢„æµ‹éš¾åº¦éšæ—¶é—´æ˜¾è‘—å˜åŒ–ï¼›å…¶æ¬¡ï¼Œæˆ‘ä»¬çš„è¯„ä¼°æ­ç¤ºäº†ä¸€ä¸ªå…³é”®çš„æ¶æ„æƒè¡¡ï¼šå¤æ‚æ¨¡å‹é€‚ç”¨äºä½å¯é¢„æµ‹æ€§æ•°æ®ï¼Œè€Œçº¿æ€§æ¨¡å‹åœ¨æ›´å…·å¯é¢„æµ‹æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä½³ã€‚æˆ‘ä»¬å€¡å¯¼ paradigm shiftï¼Œè½¬å‘ä¸€ç§æ›´åŠ é€å½»ã€å¯é¢„æµ‹æ€§æ„ŸçŸ¥çš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥ä¿ƒè¿›æ›´å…¬å¹³çš„æ¨¡å‹æ¯”è¾ƒå’Œæ›´æ·±å…¥çš„æ¨¡å‹è¡Œä¸ºç†è§£ã€‚ 

---
# From Evidence to Trajectory: Abductive Reasoning Path Synthesis for Training Retrieval-Augmented Generation Agents 

**Title (ZH)**: ä»è¯æ®åˆ°è½¨è¿¹ï¼šç”¨äºè®­ç»ƒæ£€ç´¢å¢å¼ºç”Ÿæˆä»£ç†çš„æº¯å› æ¨ç†è·¯å¾„åˆæˆ 

**Authors**: Muzhi Li, Jinhu Qi, Yihong Wu, Minghao Zhao, Liheng Ma, Yifan Li, Xinyu Wang, Yingxue Zhang, Ho-fung Leung, Irwin King  

**Link**: [PDF](https://arxiv.org/pdf/2509.23071)  

**Abstract**: Retrieval-augmented generation agents development is hindered by the lack of process-level supervision to effectively guide agentic capabilities like task decomposition, retriever invocation, and stepwise decision-making. While reinforcement learning offers a potential solution, it suffers from sparse rewards and the limited reasoning capabilities of large language models (LLMs). Meanwhile, existing data synthesis methods only produce chain-of-thought rationales and fail to model environmental interactions. In this paper, we propose EviPath, an evidence-anchored reasoning path synthesis paradigm for RAG agent development. EviPath comprises: (i) Abductive Subtask Planning, which decomposes the problem into sub-questions and iteratively plans an optimal solution path based on the dependencies between them; (ii) Faithful Sub-question Answering, which uses supporting evidence to construct a proxy environment to generate reasoning thoughts and answers for each sub-question; and (iii) Conversational Fine-Tuning, which formats the complete agent-environment interaction trajectory into a dialogue format suitable for Supervised Fine-Tuning. EviPath allows LLMs to learn complex reasoning and tool-use capabilities directly from synthesized data. Extensive experiments on widely-used question-answering benchmarks show that an 8B parameter model trained with EviPath-synthesized data significantly and consistently outperforms state-of-the-art baselines with a double-digit absolute EM gain of 14.7% in open-domain question answering. 

**Abstract (ZH)**: åŸºäºè¯æ®çš„æ¨ç†è·¯å¾„åˆæˆèŒƒå¼ï¼šç”¨äºRAGä»£ç†å¼€å‘çš„EviPath 

---
# Beyond Aggregation: Guiding Clients in Heterogeneous Federated Learning 

**Title (ZH)**: è¶…è¶Šèšåˆï¼šå¼•å¯¼å®¢æˆ·ç«¯çš„å¼‚æ„è”é‚¦å­¦ä¹  

**Authors**: Zijian Wang, Xiaofei Zhang, Xin Zhang, Yukun Liu, Qiong Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2509.23049)  

**Abstract**: Federated learning (FL) is increasingly adopted in domains like healthcare, where data privacy is paramount. A fundamental challenge in these systems is statistical heterogeneity-the fact that data distributions vary significantly across clients (e.g., different hospitals may treat distinct patient demographics). While current FL algorithms focus on aggregating model updates from these heterogeneous clients, the potential of the central server remains under-explored. This paper is motivated by a healthcare scenario: could a central server not only build a model but also guide a new patient to the hospital best equipped for their specific condition? We generalize this idea to propose a novel paradigm for FL systems where the server actively guides the allocation of new tasks or queries to the most appropriate client in the network. To enable this, we introduce an empirical likelihood-based framework that simultaneously addresses two goals: (1) learning effective local models on each client, and (2) finding the best matching client for a new query. Empirical results demonstrate the framework's effectiveness on benchmark datasets, showing improvements in both model accuracy and the precision of client guidance compared to standard FL approaches. This work opens a new direction for building more intelligent and resource-efficient federated systems that leverage heterogeneity as a feature, not just a bug. Code is available at this https URL. 

**Abstract (ZH)**: è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰åœ¨åŒ»ç–—å¥åº·ç­‰é‡è§†æ•°æ®éšç§çš„é¢†åŸŸè¢«è¶Šæ¥è¶Šå¹¿æ³›åœ°é‡‡ç”¨ã€‚è¿™äº›ç³»ç»Ÿä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜æ˜¯ç»Ÿè®¡å¼‚è´¨æ€§â€”â€”å³å„å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒå·®å¼‚æ˜¾è‘—ï¼ˆä¾‹å¦‚ï¼Œä¸åŒçš„åŒ»é™¢å¯èƒ½æ²»ç–—ä¸åŒçš„æ‚£è€…ç¾¤ä½“ï¼‰ã€‚å°½ç®¡å½“å‰çš„è”é‚¦å­¦ä¹ ç®—æ³•ä¸»è¦å…³æ³¨ä»è¿™äº›å¼‚è´¨å®¢æˆ·ç«¯èšåˆæ¨¡å‹æ›´æ–°ï¼Œä¸­å¤®æœåŠ¡å™¨çš„æ½œåŠ›ä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡å—åˆ°åŒ»ç–—å¥åº·åœºæ™¯çš„å¯å‘ï¼šä¸­å¤®æœåŠ¡å™¨æ˜¯å¦ä¸ä»…èƒ½æ„å»ºæ¨¡å‹ï¼Œè¿˜èƒ½æŒ‡å¯¼æ–°æ‚£è€…å‰å¾€æœ€åˆé€‚çš„åŒ»é™¢è¿›è¡Œæ²»ç–—ï¼Ÿæˆ‘ä»¬æ¨å¹¿è¿™ä¸€æ€æƒ³ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„è”é‚¦å­¦ä¹ èŒƒå¼ï¼Œå…¶ä¸­æœåŠ¡å™¨ç§¯ææŒ‡å¯¼æ–°ä»»åŠ¡æˆ–æŸ¥è¯¢åœ¨ç½‘ç»œä¸­æœ€åˆé€‚çš„å®¢æˆ·ç«¯å¤„è¿›è¡Œåˆ†é…ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç»éªŒä¼¼ç„¶ä¸ºåŸºç¡€çš„æ¡†æ¶ï¼ŒåŒæ—¶å®ç°ä¸¤ä¸ªç›®æ ‡ï¼š1) åœ¨æ¯ä¸ªå®¢æˆ·ç«¯ä¸Šå­¦ä¹ æœ‰æ•ˆçš„æœ¬åœ°æ¨¡å‹ï¼Œ2) ä¸ºæ–°çš„æŸ¥è¯¢æ‰¾åˆ°æœ€åˆé€‚çš„åŒ¹é…å®¢æˆ·ç«¯ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åŸºå‡†æ•°æ®é›†ä¸Šæ˜¾ç¤ºäº†æ¯”æ ‡å‡†è”é‚¦å­¦ä¹ æ–¹æ³•æ›´é«˜çš„æ¨¡å‹å‡†ç¡®æ€§å’Œæ›´ç²¾å‡†çš„å®¢æˆ·ç«¯æŒ‡å¯¼æ•ˆæœã€‚è¿™é¡¹å·¥ä½œå¼€å¯äº†åˆ©ç”¨å¼‚è´¨æ€§ä½œä¸ºç‰¹å¾è€Œéç¼ºé™·æ¥æ„å»ºæ›´æ™ºèƒ½å’Œèµ„æºé«˜æ•ˆçš„è”é‚¦ç³»ç»Ÿçš„æ–°çš„ç ”ç©¶æ–¹å‘ã€‚ä»£ç å¯ä»ä»¥ä¸‹é“¾æ¥è·å–ã€‚ 

---
# IsingFormer: Augmenting Parallel Tempering With Learned Proposals 

**Title (ZH)**: IsingFormer: ç”¨å­¦ä¹ å¾—åˆ°çš„ææ¡ˆå¢å¼ºå¹³è¡Œé€€ç«æ–¹æ³• 

**Authors**: Saleh Bunaiyan, Corentin Delacour, Shuvro Chowdhury, Kyle Lee, Kerem Y. Camsari  

**Link**: [PDF](https://arxiv.org/pdf/2509.23043)  

**Abstract**: Markov Chain Monte Carlo (MCMC) underlies both statistical physics and combinatorial optimization, but mixes slowly near critical points and in rough landscapes. Parallel Tempering (PT) improves mixing by swapping replicas across temperatures, yet each replica still relies on slow local updates to change its configuration. We introduce IsingFormer, a Transformer trained on equilibrium samples that can generate entire spin configurations resembling those from the target distribution. These uncorrelated samples are used as proposals for global moves within a Metropolis step in PT, complementing the usual single-spin flips. On 2D Ising models (sampling), IsingFormer reproduces magnetization and free-energy curves and generalizes to unseen temperatures, including the critical region. Injecting even a single proposal sharply reduces equilibration time, replacing thousands of local updates. On 3D spin glasses (optimization), PT enhanced with IsingFormer finds substantially lower-energy states, demonstrating how global moves accelerate search in rugged landscapes. Finally, applied to integer factorization encoded as Ising problems, IsingFormer trained on a limited set of semiprimes transfers successfully to unseen semiprimes, boosting success rates beyond the training distribution. Since factorization is a canonical hard benchmark, this ability to generalize across instances highlights the potential of learning proposals that move beyond single problems to entire families of instances. The IsingFormer demonstrates that Monte Carlo methods can be systematically accelerated by neural proposals that capture global structure, yielding faster sampling and stronger performance in combinatorial optimization. 

**Abstract (ZH)**: Markové“¾è’™ç‰¹å¡æ´›ï¼ˆMCMCï¼‰æ—¢å­˜åœ¨äºç»Ÿè®¡ç‰©ç†ä¸­ä¹Ÿå­˜åœ¨äºç»„åˆä¼˜åŒ–ä¸­ï¼Œä½†åœ¨ä¸´ç•Œç‚¹é™„è¿‘å’Œå´å²–çš„æ™¯è§‚ä¸­æ··åˆé€Ÿåº¦ç¼“æ…¢ã€‚å¹¶è¡Œæ¸©åº¦è°ƒè°ï¼ˆPTï¼‰é€šè¿‡åœ¨ä¸åŒæ¸©åº¦ä¸‹äº¤æ¢å¤åˆ¶å“æ¥æé«˜æ··åˆæ•ˆæœï¼Œä½†æ¯ä¸ªå¤åˆ¶å“ä»ç„¶ä¾èµ–äºç¼“æ…¢çš„å±€éƒ¨æ›´æ–°æ¥æ”¹å˜å…¶é…ç½®ã€‚æˆ‘ä»¬ä»‹ç»äº†IsingFormerï¼Œè¿™æ˜¯ä¸€ç§åœ¨å¹³è¡¡æ ·æœ¬ä¸Šè®­ç»ƒçš„Transformerï¼Œèƒ½å¤Ÿç”Ÿæˆç±»ä¼¼äºç›®æ ‡åˆ†å¸ƒçš„å®Œæ•´è‡ªæ—‹é…ç½®ã€‚è¿™äº›æœªå…³è”çš„æ ·æœ¬è¢«ç”¨ä½œPTä¸­å…¨å±€ç§»åŠ¨çš„ææ¡ˆï¼Œåœ¨Metropolisæ­¥éª¤ä¸­è¡¥å……äº†ä¼ ç»Ÿçš„å•ä¸ªè‡ªæ—‹ç¿»è½¬ã€‚åœ¨2Dè‡ªæ—‹ç»ç’ƒæ¨¡å‹ï¼ˆé‡‡æ ·ï¼‰ä¸­ï¼ŒIsingFormeré‡ç°äº†ç£åŒ–ç‡å’Œè‡ªç”±èƒ½æ›²çº¿ï¼Œå¹¶å¯ä»¥åœ¨æœªè§è¿‡çš„æ¸©åº¦ä¸‹æ³›åŒ–ï¼ŒåŒ…æ‹¬ä¸´ç•ŒåŒºåŸŸã€‚å³ä½¿æ³¨å…¥ä¸€ä¸ªææ¡ˆä¹Ÿèƒ½æ˜¾è‘—å‡å°‘å¹³è¡¡æ—¶é—´ï¼Œå–ä»£æ•°åƒæ¬¡çš„å±€éƒ¨æ›´æ–°ã€‚åœ¨3Dè‡ªæ—‹ç»ç’ƒæ¨¡å‹ï¼ˆä¼˜åŒ–ï¼‰ä¸­ï¼Œå¢å¼ºäº†IsingFormerçš„PTæ‰¾åˆ°äº†æ˜¾è‘—æ›´ä½èƒ½é‡çš„çŠ¶æ€ï¼Œè¯æ˜äº†å…¨å±€ç§»åŠ¨åœ¨å´å²–æ™¯è§‚ä¸­å¦‚ä½•åŠ é€Ÿæœç´¢ã€‚æœ€åï¼Œå°†å…¶åº”ç”¨äºæ•´æ•°å› å­åˆ†è§£ç¼–ç ä¸ºè‡ªæ—‹ç»ç’ƒé—®é¢˜ï¼ŒIsingFormeråœ¨æœ‰é™çš„åŠç´ æ•°é›†ä¸Šè®­ç»ƒåå¯ä»¥æˆåŠŸè¿ç§»åˆ°æœªè§è¿‡çš„åŠç´ æ•°ä¸Šï¼Œæå‡äº†è§£å†³ç‡è¶…å‡ºè®­ç»ƒåˆ†å¸ƒã€‚ç”±äºå› å­åˆ†è§£æ˜¯ç»å…¸ç¡¬åŸºå‡†æµ‹è¯•ï¼Œè¿™ç§åœ¨å®ä¾‹ä¹‹é—´æ³›åŒ–çš„èƒ½åŠ›çªæ˜¾äº†å­¦ä¹ è¶…è¶Šå•ä¸€é—®é¢˜çš„å…¨å±€ç»“æ„ç§»åŠ¨ææ¡ˆçš„æ½œåŠ›ã€‚IsingFormerå±•ç¤ºäº†é€šè¿‡æ•æ‰å…¨å±€ç»“æ„çš„ç¥ç»ææ¡ˆç³»ç»ŸåŠ é€Ÿè’™ç‰¹å¡æ´›æ–¹æ³•çš„å¯èƒ½æ€§ï¼Œä»è€Œå®ç°æ›´å¿«çš„é‡‡æ ·å’Œæ›´å¼ºçš„ç»„åˆä¼˜åŒ–æ€§èƒ½ã€‚ 

---
# DPFNAS: Differential Privacy-Enhanced Federated Neural Architecture Search for 6G Edge Intelligence 

**Title (ZH)**: DPFNASï¼šå¢å¼ºå·®åˆ†éšç§çš„6Gè¾¹ç¼˜æ™ºèƒ½è”é‚¦ç¥ç»æ¶æ„æœç´¢ 

**Authors**: Yang Lv, Jin Cao, Ben Niu, Zhe Sun, Fengwei Wang, Fenghua Li, Hui Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.23030)  

**Abstract**: The Sixth-Generation (6G) network envisions pervasive artificial intelligence (AI) as a core goal, enabled by edge intelligence through on-device data utilization. To realize this vision, federated learning (FL) has emerged as a key paradigm for collaborative training across edge devices. However, the sensitivity and heterogeneity of edge data pose key challenges to FL: parameter sharing risks data reconstruction, and a unified global model struggles to adapt to diverse local distributions. In this paper, we propose a novel federated learning framework that integrates personalized differential privacy (DP) and adaptive model design. To protect training data, we leverage sample-level representations for knowledge sharing and apply a personalized DP strategy to resist reconstruction attacks. To ensure distribution-aware adaptation under privacy constraints, we develop a privacy-aware neural architecture search (NAS) algorithm that generates locally customized architectures and hyperparameters. To the best of our knowledge, this is the first personalized DP solution tailored for representation-based FL with theoretical convergence guarantees. Our scheme achieves strong privacy guarantees for training data while significantly outperforming state-of-the-art methods in model performance. Experiments on benchmark datasets such as CIFAR-10 and CIFAR-100 demonstrate that our scheme improves accuracy by 6.82\% over the federated NAS method PerFedRLNAS, while reducing model size to 1/10 and communication cost to 1/20. 

**Abstract (ZH)**: ç¬¬å…­ä»£ï¼ˆ6Gï¼‰ç½‘ç»œæ„¿æ™¯é€šè¿‡è¾¹ç¼˜æ™ºèƒ½å®ç°æ³›åœ¨çš„äººå·¥æ™ºèƒ½ï¼Œè¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ•°æ®åˆ©ç”¨æ˜¯å…³é”®ç›®æ ‡ã€‚ä¸ºå®ç°è¿™ä¸€æ„¿æ™¯ï¼Œè”é‚¦å­¦ä¹ ï¼ˆFLï¼‰å·²æˆä¸ºè·¨è¾¹ç¼˜è®¾å¤‡åä½œè®­ç»ƒçš„å…³é”®èŒƒå¼ã€‚ç„¶è€Œï¼Œè¾¹ç¼˜æ•°æ®çš„æ•æ„Ÿæ€§å’Œå¼‚è´¨æ€§ç»™FLå¸¦æ¥äº†å…³é”®æŒ‘æˆ˜ï¼šå‚æ•°å…±äº«å­˜åœ¨æ•°æ®é‡æ„é£é™©ï¼Œç»Ÿä¸€çš„å…¨å±€æ¨¡å‹éš¾ä»¥é€‚åº”å¤šæ ·åŒ–çš„æœ¬åœ°åˆ†å¸ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»“åˆä¸ªæ€§åŒ–å·®åˆ†éšç§ï¼ˆDPï¼‰å’Œè‡ªé€‚åº”æ¨¡å‹è®¾è®¡çš„æ–°å‹è”é‚¦å­¦ä¹ æ¡†æ¶ã€‚ä¸ºäº†ä¿æŠ¤è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬åˆ©ç”¨æ ·æœ¬çº§è¡¨ç¤ºè¿›è¡ŒçŸ¥è¯†å…±äº«ï¼Œå¹¶åº”ç”¨ä¸ªæ€§åŒ–DPç­–ç•¥ä»¥æŠµå¾¡é‡æ„æ”»å‡»ã€‚ä¸ºäº†åœ¨éšç§çº¦æŸä¸‹ç¡®ä¿åˆ†å¸ƒæ„ŸçŸ¥çš„é€‚åº”æ€§ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§éšç§æ„ŸçŸ¥ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰ç®—æ³•ï¼Œç”Ÿæˆæœ¬åœ°å®šåˆ¶çš„æ¶æ„å’Œè¶…å‚æ•°ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªé’ˆå¯¹è¡¨ç¤ºé©±åŠ¨çš„FLçš„ä¸ªæ€§åŒ–DPè§£å†³æ–¹æ¡ˆï¼Œå¹¶å…·æœ‰ç†è®ºæ”¶æ•›ä¿è¯ã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨ä¿æŠ¤è®­ç»ƒæ•°æ®éšç§æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„ä¿è¯ï¼ŒåŒæ—¶åœ¨æ¨¡å‹æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åŸºå‡†æ•°æ®é›†ï¼ˆå¦‚CIFAR-10å’ŒCIFAR-100ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸PerFedRLNASæ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨å‡†ç¡®ç‡ä¸Šæé«˜äº†6.82%ï¼ŒåŒæ—¶æ¨¡å‹å¤§å°å‡å°‘äº†10å€ï¼Œé€šä¿¡æˆæœ¬å‡å°‘äº†20å€ã€‚ 

---
# MoE-PHDS: One MoE checkpoint for flexible runtime sparsity 

**Title (ZH)**: MoE-PHDS: ä¸€ä¸ªMoEæ£€æŸ¥ç‚¹ç”¨äºçµæ´»çš„è¿è¡Œæ—¶ç¨€ç–æ€§ 

**Authors**: Lauren. A Hannah, Soheil Zibakhsh, Kumari Nishu, Arnav Kundu, Mohammad Samragh Razlighi, Mehrdad Farajtabar, Minsik Cho  

**Link**: [PDF](https://arxiv.org/pdf/2509.23012)  

**Abstract**: Sparse Mixtures of Experts (MoEs) are typically trained to operate at a fixed sparsity level, e.g. $k$ in a top-$k$ gating function. This global sparsity level determines an operating point on the accuracy/latency curve; currently, meeting multiple efficiency targets means training and maintaining multiple models. This practice complicates serving, increases training and maintenance costs, and limits flexibility in meeting diverse latency, efficiency, and energy requirements. We show that pretrained MoEs are more robust to runtime sparsity shifts than commonly assumed, and introduce MoE-PHDS ({\bf P}ost {\bf H}oc {\bf D}eclared {\bf S}parsity), a lightweight SFT method that turns a single checkpoint into a global sparsity control surface. PHDS mixes training across sparsity levels and anchors with a short curriculum at high sparsity, requiring no architectural changes. The result is predictable accuracy/latency tradeoffs from one model: practitioners can ``dial $k$'' at inference time without swapping checkpoints, changing architecture, or relying on token-level heuristics. Experiments on OLMoE-1B-7B-0125, Qwen1.5-MoE-A2.7B, and proprietary models fit on multiple operating points show that PHDS matches or exceeds well-specified oracle models, improves cross-sparsity agreement by up to 22\% vs. well-specified oracle models, and enables simplified, flexible runtime MoE deployment by making global sparsity a first-class serving primitive. 

**Abstract (ZH)**: é¢„è®­ç»ƒçš„ä¸“å®¶æ··åˆæ¨¡å‹æ›´å…·é²æ£’æ€§ï¼šåŸºäºåæ˜¾å¼ç¨€ç–åº¦çš„è½»é‡çº§å¾®è°ƒæ–¹æ³•ï¼ˆMoE-PHDSï¼‰ 

---
# Functional Critic Modeling for Provably Convergent Off-Policy Actor-Critic 

**Title (ZH)**: è¯æ˜æ”¶æ•›çš„ç¦»ç­– Actor-Critc æ¨¡å‹ä¸­çš„åŠŸèƒ½è¯„è®ºè€…å»ºæ¨¡ 

**Authors**: Qinxun Bai, Yuxuan Han, Wei Xu, Zhengyuan Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2509.22964)  

**Abstract**: Off-policy reinforcement learning (RL) with function approximation offers an effective way to improve sample efficiency by reusing past experience. Within this setting, the actor-critic (AC) framework has achieved strong empirical success. However, both the critic and actor learning is challenging for the off-policy AC methods: first of all, in addition to the classic "deadly triad" instability of off-policy evaluation, it also suffers from a "moving target" problem, where the policy being evaluated changes continually; secondly, actor learning becomes less efficient due to the difficulty of estimating the exact off-policy policy gradient. The first challenge essentially reduces the problem to repeatedly performing off-policy evaluation for changing policies. For the second challenge, the off-policy policy gradient theorem requires a complex and often impractical algorithm to estimate an additional emphasis critic, which is typically neglected in practice, thereby reducing to the on-policy policy gradient as an approximation. In this work, we introduce a novel concept of functional critic modeling, which leads to a new AC framework that addresses both challenges for actor-critic learning under the deadly triad setting. We provide a theoretical analysis in the linear function setting, establishing the provable convergence of our framework, which, to the best of our knowledge, is the first convergent off-policy target-based AC algorithm. From a practical perspective, we further propose a carefully designed neural network architecture for the functional critic modeling and demonstrate its effectiveness through preliminary experiments on widely used RL tasks from the DeepMind Control Benchmark. 

**Abstract (ZH)**: å¸¦æœ‰å‡½æ•°é€¼è¿‘çš„ç¦»ç­– reinforcement learningä¸­çš„actor-criticæ¡†æ¶ï¼šè§£å†³è‡´å‘½ä¸‰è§’é—®é¢˜çš„åŠŸèƒ½æ€§criticå»ºæ¨¡ 

---
# What Matters More For In-Context Learning under Matched Compute Budgets: Pretraining on Natural Text or Incorporating Targeted Synthetic Examples? 

**Title (ZH)**: åœ¨åŒ¹é…è®¡ç®—é¢„ç®—æ¡ä»¶ä¸‹ï¼Œå½±å“åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ æ›´ä¸ºé‡è¦çš„å› ç´ æ˜¯è‡ªç„¶æ–‡æœ¬é¢„è®­ç»ƒè¿˜æ˜¯èå…¥é’ˆå¯¹æ€§åˆæˆä¾‹è¯ï¼Ÿ 

**Authors**: Mohammed Sabry, Anya Belz  

**Link**: [PDF](https://arxiv.org/pdf/2509.22947)  

**Abstract**: Does explicitly exercising the induction circuit during pretraining improve in-context learning (ICL), or is natural text sufficient when compute is held constant (iso-FLOPs)? To test whether targeted synthetic data can accelerate induction-head emergence and enhance ICL, we introduce Bi-Induct, a lightweight curriculum that injects forward-copy (Induction), backward-copy (Anti), or a balanced mix into the pretraining stream. We train models from 0.13B to 1B parameters under iso-FLOPs, evaluating (i) few-shot ICL benchmarks, (ii) head-level telemetry, and (iii) held-out language modeling perplexity. Our findings challenge the assumption that early induction circuit activation directly improves ICL. While Bi-Induct accelerates induction-head emergence at small scales, this does not consistently yield stronger generalization. On standard LM benchmarks, Bi-Induct matches natural-only training; on function-style ICL probes, the 1B natural-only performs best. Stress tests (e.g., label permutation, HITS@1 vs. HITS@3, 1 vs. 10 shots) preserve these trends. Telemetry shows larger natural-only models develop broader, earlier induction heads without explicit induction patterns. Anti-induction data fails to elicit meaningful activation. Perplexity penalties from synthetic data shrink with scale, suggesting larger models can absorb non-natural patterns with minimal cost. Crucially, ablating the top 2% of induction heads degrades ICL more than random ablations, especially for natural-only models, indicating more centralized, load-bearing circuits. Bi-Induct variants exhibit more redundant induction activity, implying different circuit utilization. Overall, inducing activation is not sufficient: ICL gains depend on these circuits becoming functionally necessary. These results underscore mechanism-aware pretraining diagnostics and data mixtures that foster load-bearing, not merely present, structure. 

**Abstract (ZH)**: does explicitly exercising the induction circuit during pretraining improve in-context learning (icl), or is natural text sufficient when compute is held constant (iso-flops)? introducing bi-induct to test the acceleration of induction-head emergence and enhancement of icl 

---
# Unsupervised Speech Enhancement using Data-defined Priors 

**Title (ZH)**: åŸºäºæ•°æ®å®šä¹‰å…ˆéªŒçš„æ— ç›‘ç£è¯­éŸ³å¢å¼º 

**Authors**: Dominik Klement, Matthew Maciejewski, Sanjeev Khudanpur, Jan ÄŒernockÃ½, LukÃ¡Å¡ Burget  

**Link**: [PDF](https://arxiv.org/pdf/2509.22942)  

**Abstract**: The majority of deep learning-based speech enhancement methods require paired clean-noisy speech data. Collecting such data at scale in real-world conditions is infeasible, which has led the community to rely on synthetically generated noisy speech. However, this introduces a gap between the training and testing phases. In this work, we propose a novel dual-branch encoder-decoder architecture for unsupervised speech enhancement that separates the input into clean speech and residual noise. Adversarial training is employed to impose priors on each branch, defined by unpaired datasets of clean speech and, optionally, noise. Experimental results show that our method achieves performance comparable to leading unsupervised speech enhancement approaches. Furthermore, we demonstrate the critical impact of clean speech data selection on enhancement performance. In particular, our findings reveal that performance may appear overly optimistic when in-domain clean speech data are used for prior definition -- a practice adopted in previous unsupervised speech enhancement studies. 

**Abstract (ZH)**: åŸºäºæ·±åº¦å­¦ä¹ çš„æ— ç›‘ç£è¯­éŸ³å¢å¼ºæ–¹æ³•ï¼šä¸€ç§åˆ†ç¦»è¾“å…¥ä¸ºå¹²å‡€è¯­éŸ³å’Œæ®‹ä½™å™ªå£°çš„åŒåˆ†æ”¯ç¼–ç å™¨-è§£ç å™¨æ¶æ„ 

---
# Compute-Optimal Quantization-Aware Training 

**Title (ZH)**: è®¡ç®—æœ€ä¼˜é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ 

**Authors**: Aleksandr Dremov, David Grangier, Angelos Katharopoulos, Awni Hannun  

**Link**: [PDF](https://arxiv.org/pdf/2509.22935)  

**Abstract**: Quantization-aware training (QAT) is a leading technique for improving the accuracy of quantized neural networks. Previous work has shown that decomposing training into a full-precision (FP) phase followed by a QAT phase yields superior accuracy compared to QAT alone. However, the optimal allocation of compute between the FP and QAT phases remains unclear. We conduct extensive experiments with various compute budgets, QAT bit widths, and model sizes from 86.0M to 2.2B to investigate how different QAT durations impact final performance. We demonstrate that, contrary to previous findings, the loss-optimal ratio of QAT to FP training increases with the total amount of compute. Moreover, the optimal fraction can be accurately predicted for a wide range of model sizes and quantization widths using the tokens-per-parameter-byte statistic. From experimental data, we derive a loss scaling law that predicts both optimal QAT ratios and final model performance across different QAT/FP compute allocation strategies and QAT bit widths. We use the scaling law to make further predictions, which we verify experimentally, including which QAT bit width is optimal under a given memory constraint and how QAT accuracy with different bit widths compares to full-precision model accuracy. Additionally, we propose a novel cooldown and QAT fusion approach that performs learning rate decay jointly with quantization-aware training, eliminating redundant full-precision model updates and achieving significant compute savings. These findings provide practical insights into efficient QAT planning and enable the training of higher-quality quantized models with the same compute budget. 

**Abstract (ZH)**: Quantization-awareè®­ç»ƒï¼ˆQATï¼‰æ˜¯ä¸€ç§æé«˜é‡åŒ–ç¥ç»ç½‘ç»œå‡†ç¡®æ€§çš„é¢†å…ˆæŠ€æœ¯ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œå°†è®­ç»ƒåˆ†è§£ä¸ºå…¨ç²¾åº¦ï¼ˆFPï¼‰é˜¶æ®µå’ŒQATé˜¶æ®µå¯ä»¥æ¯”å•ç‹¬ä½¿ç”¨QATè·å¾—æ›´é«˜çš„ç²¾åº¦ã€‚ç„¶è€Œï¼ŒFPå’ŒQATé˜¶æ®µä¹‹é—´çš„è®¡ç®—åˆ†é…ä»ä¸æ¸…æ¥šã€‚æˆ‘ä»¬é€šè¿‡å„ç§è®¡ç®—é¢„ç®—ã€QATæ¯”ç‰¹å®½å’Œä»86.0Måˆ°2.2Bçš„æ¨¡å‹è§„æ¨¡è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œç ”ç©¶ä¸åŒçš„QATæŒç»­æ—¶é—´å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“ã€‚æˆ‘ä»¬è¯æ˜ï¼Œä¸ä¹‹å‰çš„ç ”ç©¶å‘ç°ç›¸åï¼ŒQATä¸FPè®­ç»ƒçš„ç†æƒ³æ¯”ä¾‹éšæ€»è®¡ç®—é‡çš„å¢åŠ è€Œå¢åŠ ã€‚æ­¤å¤–ï¼Œä½¿ç”¨tokens-per-parameter-byteç»Ÿè®¡å€¼å¯ä»¥å‡†ç¡®é¢„æµ‹å¹¿æ³›æ¨¡å‹è§„æ¨¡å’Œé‡åŒ–å®½åº¦ä¸‹çš„æœ€ä¼˜æ¯”ä¾‹ã€‚ä»å®éªŒæ•°æ®ä¸­ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºä¸€ä¸ªæŸå¤±æ”¾å¤§å®šå¾‹ï¼Œè¯¥å®šå¾‹å¯ä»¥é¢„æµ‹ä¸åŒQAT/FPè®¡ç®—åˆ†é…ç­–ç•¥å’ŒQATæ¯”ç‰¹å®½ä¸‹çš„æœ€ä¼˜QATæ¯”ä¾‹å’Œæœ€ç»ˆæ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬ä½¿ç”¨è¯¥å®šå¾‹è¿›è¡Œè¿›ä¸€æ­¥é¢„æµ‹ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯ï¼ŒåŒ…æ‹¬åœ¨ç»™å®šçš„å†…å­˜çº¦æŸä¸‹å“ªç§QATæ¯”ç‰¹å®½æ˜¯æœ€ä¼˜çš„ï¼Œä»¥åŠä¸åŒæ¯”ç‰¹å®½ä¸‹çš„QATå‡†ç¡®æ€§ä¸å…¨ç²¾åº¦æ¨¡å‹å‡†ç¡®æ€§ä¹‹é—´çš„æ¯”è¾ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å†·å´å’ŒQATèåˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†é‡åŒ–æ„ŸçŸ¥è®­ç»ƒå’Œå­¦ä¹ ç‡è¡°å‡ï¼Œæ¶ˆé™¤äº†å†—ä½™çš„å…¨ç²¾åº¦æ¨¡å‹æ›´æ–°ï¼Œå¹¶å®ç°äº†æ˜¾è‘—çš„è®¡ç®—èŠ‚çœã€‚è¿™äº›å‘ç°ä¸ºæœ‰æ•ˆçš„QATè§„åˆ’æä¾›äº†å®ç”¨è§è§£ï¼Œå¹¶ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿåœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—ä¸‹è®­ç»ƒå‡ºæ›´é«˜è´¨é‡çš„é‡åŒ–æ¨¡å‹ã€‚ 

---
# MonoCon: A general framework for learning ultra-compact high-fidelity representations using monotonicity constraints 

**Title (ZH)**: MonoConï¼šä¸€ç§ä½¿ç”¨å•è°ƒæ€§çº¦æŸå­¦ä¹ è¶…ç´§å‡‘é«˜ä¿çœŸè¡¨ç¤ºçš„ä¸€èˆ¬æ¡†æ¶ 

**Authors**: Shreyas Gokhale  

**Link**: [PDF](https://arxiv.org/pdf/2509.22931)  

**Abstract**: Learning high-quality, robust, efficient, and disentangled representations is a central challenge in artificial intelligence (AI). Deep metric learning frameworks tackle this challenge primarily using architectural and optimization constraints. Here, we introduce a third approach that instead relies on $\textit{functional}$ constraints. Specifically, we present MonoCon, a simple framework that uses a small monotonic multi-layer perceptron (MLP) head attached to any pre-trained encoder. Due to co-adaptation between encoder and head guided by contrastive loss and monotonicity constraints, MonoCon learns robust, disentangled, and highly compact embeddings at a practically negligible performance cost. On the CIFAR-100 image classification task, MonoCon yields representations that are nearly 9x more compact and 1.5x more robust than the fine-tuned encoder baseline, while retaining 99\% of the baseline's 5-NN classification accuracy. We also report a 3.4x more compact and 1.4x more robust representation on an SNLI sentence similarity task for a marginal reduction in the STSb score, establishing MonoCon as a general domain-agnostic framework. Crucially, these robust, ultra-compact representations learned via functional constraints offer a unified solution to critical challenges in disparate contexts ranging from edge computing to cloud-scale retrieval. 

**Abstract (ZH)**: å­¦ä¹ é«˜è´¨é‡ã€ç¨³å¥ã€é«˜æ•ˆä¸”è§£è€¦çš„è¡¨ç¤ºæ˜¯äººå·¥æ™ºèƒ½ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ã€‚åŸºäºåŠŸèƒ½çº¦æŸçš„MonoConæ¡†æ¶ 

---
# From Noise to Knowledge: A Comparative Study of Acoustic Anomaly Detection Models in Pumped-storage Hydropower Plants 

**Title (ZH)**: ä»å™ªå£°åˆ°çŸ¥è¯†ï¼š Pumped-storage Hydropower Plants ä¸­ acoustic å¼‚å¸¸æ£€æµ‹æ¨¡å‹çš„æ¯”è¾ƒç ”ç©¶ 

**Authors**: Karim Khamaisi, Nicolas Keller, Stefan Krummenacher, Valentin Huber, Bernhard FÃ¤ssler, Bruno Rodrigues  

**Link**: [PDF](https://arxiv.org/pdf/2509.22881)  

**Abstract**: In the context of industrial factories and energy producers, unplanned outages are highly costly and difficult to service. However, existing acoustic-anomaly detection studies largely rely on generic industrial or synthetic datasets, with few focused on hydropower plants due to limited access. This paper presents a comparative analysis of acoustic-based anomaly detection methods, as a way to improve predictive maintenance in hydropower plants. We address key challenges in the acoustic preprocessing under highly noisy conditions before extracting time- and frequency-domain features. Then, we benchmark three machine learning models: LSTM AE, K-Means, and OC-SVM, which are tested on two real-world datasets from the Rodundwerk II pumped-storage plant in Austria, one with induced anomalies and one with real-world conditions. The One-Class SVM achieved the best trade-off of accuracy (ROC AUC 0.966-0.998) and minimal training time, while the LSTM autoencoder delivered strong detection (ROC AUC 0.889-0.997) at the expense of higher computational cost. 

**Abstract (ZH)**: åŸºäºå£°å­¦å¼‚å¸¸æ£€æµ‹æ–¹æ³•åœ¨æ°´åŠ›å‘ç”µå‚é¢„æµ‹æ€§ç»´æŠ¤ä¸­çš„æ¯”è¾ƒç ”ç©¶ 

---
# Scalable Wi-Fi RSS-Based Indoor Localization via Automatic Vision-Assisted Calibration 

**Title (ZH)**: åŸºäºè‡ªåŠ¨è§†è§‰è¾…åŠ©æ ¡å‡†çš„å¯æ‰©å±•Wi-Fi RSSå®¤å†…å¤–å®šä½ 

**Authors**: Abdulkadir Bilge, Erdem Ergen, Burak Soner, Sinem Coleri  

**Link**: [PDF](https://arxiv.org/pdf/2509.22869)  

**Abstract**: Wi-Fi-based positioning promises a scalable and privacy-preserving solution for location-based services in indoor environments such as malls, airports, and campuses. RSS-based methods are widely deployable as RSS data is available on all Wi-Fi-capable devices, but RSS is highly sensitive to multipath, channel variations, and receiver characteristics. While supervised learning methods offer improved robustness, they require large amounts of labeled data, which is often costly to obtain. We introduce a lightweight framework that solves this by automating high-resolution synchronized RSS-location data collection using a short, camera-assisted calibration phase. An overhead camera is calibrated only once with ArUco markers and then tracks a device collecting RSS data from broadcast packets of nearby access points across Wi-Fi channels. The resulting (x, y, RSS) dataset is used to automatically train mobile-deployable localization algorithms, avoiding the privacy concerns of continuous video monitoring. We quantify the accuracy limits of such vision-assisted RSS data collection under key factors such as tracking precision and label synchronization. Using the collected experimental data, we benchmark traditional and supervised learning approaches under varying signal conditions and device types, demonstrating improved accuracy and generalization, validating the utility of the proposed framework for practical use. All code, tools, and datasets are released as open source. 

**Abstract (ZH)**: åŸºäºWi-Fiçš„å®šä½æŠ€æœ¯åœ¨å•†åœºã€æœºåœºå’Œæ ¡å›­ç­‰å®¤å†…ç¯å¢ƒä¸­æä¾›äº†å¯æ‰©å±•ä¸”ä¿æŠ¤éšç§çš„è§£å†³æ–¹æ¡ˆã€‚åŸºäºRSSçš„æ–¹æ³•å¹¿æ³›éƒ¨ç½²ï¼Œå› ä¸ºæ‰€æœ‰Wi-Fiè®¾å¤‡éƒ½èƒ½æä¾›RSSæ•°æ®ï¼Œä½†RSSå¯¹å¤šå¾„ä¼ æ’­ã€ä¿¡é“å˜åŒ–å’Œæ¥æ”¶å™¨ç‰¹æ€§é«˜åº¦æ•æ„Ÿã€‚å°½ç®¡ç›‘ç£å­¦ä¹ æ–¹æ³•æé«˜äº†é²æ£’æ€§ï¼Œä½†å®ƒä»¬éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè¿™é€šå¸¸æˆæœ¬é«˜æ˜‚ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§æ¡†æ¶ï¼Œé€šè¿‡ä½¿ç”¨çŸ­çš„ã€æ‘„åƒå¤´è¾…åŠ©çš„æ ¡å‡†é˜¶æ®µè‡ªåŠ¨æ”¶é›†é«˜åˆ†è¾¨ç‡åŒæ­¥RSS-ä½ç½®æ•°æ®æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚æ‘„åƒæœºä»…éœ€ä¸€æ¬¡æ ¡å‡†å³å¯ä½¿ç”¨ArUcoæ ‡è®°ï¼Œå¹¶éšåè·Ÿè¸ªä»é™„è¿‘æ¥å…¥ç‚¹å¹¿æ’­æ•°æ®åŒ…ä¸­æ”¶é›†RSSæ•°æ®çš„è®¾å¤‡ï¼Œè·¨è¶Šå¤šä¸ªWi-Fiä¿¡é“ã€‚ç”Ÿæˆçš„(x, y, RSS)æ•°æ®é›†ç”¨äºè‡ªåŠ¨è®­ç»ƒå¯ç§»åŠ¨éƒ¨ç½²çš„å®šä½ç®—æ³•ï¼Œé¿å…äº†è¿ç»­è§†é¢‘ç›‘æ§å¸¦æ¥çš„éšç§é—®é¢˜ã€‚æˆ‘ä»¬é‡åŒ–äº†åœ¨å…³é”®å› ç´ å¦‚è·Ÿè¸ªç²¾åº¦å’Œæ ‡ç­¾åŒæ­¥ä¸‹çš„è¿™ç§è§†è§‰è¾…åŠ©RSSæ•°æ®æ”¶é›†çš„å‡†ç¡®æ€§æé™ã€‚åˆ©ç”¨æ”¶é›†çš„å®éªŒæ•°æ®ï¼Œæˆ‘ä»¬åœ¨ä¸åŒä¿¡å·æ¡ä»¶å’Œè®¾å¤‡ç±»å‹ä¸‹å¯¹ä¼ ç»Ÿå’Œç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œè¯æ˜äº†å‡†ç¡®æ€§ä¸æ³›åŒ–èƒ½åŠ›çš„æå‡ï¼Œå¹¶éªŒè¯äº†æ‰€ææ¡†æ¶åœ¨å®é™…åº”ç”¨ä¸­çš„å®ç”¨æ€§ã€‚æ‰€æœ‰ä»£ç ã€å·¥å…·å’Œæ•°æ®é›†å‡ä½œä¸ºå¼€æºå‘å¸ƒã€‚ 

---
# Observation-Free Attacks on Online Learning to Rank 

**Title (ZH)**: æ— éœ€è§‚å¯Ÿçš„åœ¨çº¿å­¦ä¹ æ’åºæ”»å‡» 

**Authors**: Sameep Chattopadhyay, Nikhil Karamchandani, Sharayu Mohair  

**Link**: [PDF](https://arxiv.org/pdf/2509.22855)  

**Abstract**: Online learning to rank (OLTR) plays a critical role in information retrieval and machine learning systems, with a wide range of applications in search engines and content recommenders. However, despite their extensive adoption, the susceptibility of OLTR algorithms to coordinated adversarial attacks remains poorly understood. In this work, we present a novel framework for attacking some of the widely used OLTR algorithms. Our framework is designed to promote a set of target items so that they appear in the list of top-K recommendations for T - o(T) rounds, while simultaneously inducing linear regret in the learning algorithm. We propose two novel attack strategies: CascadeOFA for CascadeUCB1 and PBMOFA for PBM-UCB . We provide theoretical guarantees showing that both strategies require only O(log T) manipulations to succeed. Additionally, we supplement our theoretical analysis with empirical results on real-world data. 

**Abstract (ZH)**: åœ¨çº¿å­¦ä¹ æ’åºï¼ˆOLTRï¼‰åœ¨ä¿¡æ¯æ£€ç´¢å’Œæœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œå¹¿æ³›åº”ç”¨äºæœç´¢å¼•æ“å’Œå†…å®¹æ¨èç³»ç»Ÿã€‚ç„¶è€Œï¼Œå°½ç®¡OLTRç®—æ³•è¢«å¹¿æ³›é‡‡ç”¨ï¼Œå®ƒä»¬å¯¹åè°ƒå¼ adversarial æ”»å‡»çš„è„†å¼±æ€§ä»ç„¶ä¸ç”šäº†è§£ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç”¨äºæ”»å‡»ä¸€äº›å¹¿æ³›ä½¿ç”¨çš„OLTRç®—æ³•ã€‚æˆ‘ä»¬çš„æ¡†æ¶æ—¨åœ¨ä¿ƒè¿›ä¸€ç»„ç›®æ ‡é¡¹ï¼Œä½¿å…¶åœ¨T-è‡³T roundså†…å‡ºç°åœ¨å‰Ké¡¹æ¨èåˆ—è¡¨ä¸­ï¼ŒåŒæ—¶åœ¨å­¦ä¹ ç®—æ³•ä¸­è¯±å¯¼çº¿æ€§åæ‚”ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–°çš„æ”»å‡»ç­–ç•¥ï¼šCascadeOFAç”¨äºCascadeUCB1ï¼ŒPBMOFAç”¨äºPBM-UCBã€‚æˆ‘ä»¬æä¾›äº†ç†è®ºä¿è¯ï¼Œè¡¨æ˜è¿™ä¸¤ç§ç­–ç•¥åªéœ€O(log T)æ¬¡æ“çºµå³å¯æˆåŠŸã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡å®é™…æ•°æ®çš„å®è¯ç»“æœè¡¥å……äº†æˆ‘ä»¬çš„ç†è®ºåˆ†æã€‚ 

---
# Patient-specific Biomolecular Instruction Tuning 

**Title (ZH)**: æ‚£è€…ç‰¹å¼‚æ€§ç”Ÿç‰©åˆ†å­æŒ‡ä»¤è°ƒè° 

**Authors**: Irsyad Adam, Zekai Chen, David Laub, Shaun Porwal, Arda Pekis, Kevin Brown  

**Link**: [PDF](https://arxiv.org/pdf/2509.22853)  

**Abstract**: Proteomics data is essential to pathogenic understanding of a disease phenotype. In cancer, analysis of molecular signatures enables precision medicine through the identification of biological processes that drive individualized tumor progression, therapeutic resistance, and clinical heterogeneity. Recent advances in multimodal large language models (LLMs) have shown remarkable capacity to integrate and reason across heterogeneous data modalities. However, performing multi-modal language modeling for molecular understanding of patient-specific proteomics remains a significant challenge due to two barriers: (1) the lack of instruction-tuning datasets that enable clinical interpretation from proteomics data, and (2) the absence of language modeling architectures designed to capture the rich heterogeneity of molecular data. In this work, we introduce CPTAC-PROTSTRUCT, the first instruction tuning dataset for molecular understanding of oncology, comprising over 400k open-ended examples derived from individualized proteomic profiles curated from the largest national proteomics cancer study (CPTAC). Additionally, we propose KRONOS (Knowledge Representation of patient Omics Networks in Oncology via Structured tuning), a novel graph-LLM framework that leverages molecular interaction topology with proteomics to learn patient-specific graph representations for enhanced clinical reasoning. We show that KRONOS achieves competitive performance across benchmark clinical tasks, including molecular classification, temporal trajectory modeling, and tumor stage prediction from proteomics data. Ultimately, this approach empowers LLMs to understand patient-level pathogenesis, advancing precision medicine through more accurate diagnosis, prognosis, and treatment stratification. 

**Abstract (ZH)**: è›‹ç™½è´¨ç»„å­¦æ•°æ®å¯¹äºç†è§£ç–¾ç—…çš„è¡¨å‹è‡´ç—…æœºåˆ¶è‡³å…³é‡è¦ã€‚åœ¨ç™Œç—‡ä¸­ï¼Œåˆ†å­æ ‡è®°çš„åˆ†æèƒ½å¤Ÿé€šè¿‡è¯†åˆ«é©±åŠ¨ä¸ªä½“è‚¿ç˜¤è¿›å±•ã€æ²»ç–—æŠµæŠ—å’Œä¸´åºŠå¼‚è´¨æ€§çš„ç”Ÿç‰©è¿‡ç¨‹ï¼Œå®ç°ç²¾å‡†åŒ»ç–—ã€‚è¿‘æœŸï¼Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥å±•ç°äº†å…¶æ•´åˆå’Œè·¨å¼‚è´¨æ•°æ®æ¨¡æ€æ¨ç†çš„å·¨å¤§èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºä¸¤ä¸ªéšœç¢ï¼Œå°†å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åº”ç”¨äºæ‚£è€…ç‰¹å¼‚æ€§è›‹ç™½è´¨ç»„å­¦çš„åˆ†å­ç†è§£ä»ç„¶é¢ä¸´é‡å¤§æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰ç¼ºä¹èƒ½å¤Ÿä»è›‹ç™½è´¨ç»„å­¦æ•°æ®ä¸­è¿›è¡Œä¸´åºŠè§£é‡Šçš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼›ï¼ˆ2ï¼‰ç¼ºä¹èƒ½å¤Ÿæ•æ‰åˆ†å­æ•°æ®ä¸°å¯Œå¼‚è´¨æ€§çš„è¯­è¨€æ¨¡å‹æ¶æ„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†CPTAC-PROTSTRUCTï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè‚¿ç˜¤å­¦ä¸­åˆ†å­ç†è§£çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªæœ€å¤§å›½å®¶çº§è›‹ç™½è´¨ç»„å­¦ç™Œç—‡ç ”ç©¶ï¼ˆCPTACï¼‰ä¸­ä¸ªä½“åŒ–è›‹ç™½è´¨è°±ç»˜åˆ¶çš„è¶…è¿‡40ä¸‡ä¸ªå¼€æ”¾æ€§ç¤ºä¾‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†KRONOSï¼ˆè‚¿ç˜¤å­¦ä¸­åŸºäºç»“æ„è°ƒä¼˜çš„æ‚£è€…ç»„å­¦ç½‘ç»œçŸ¥è¯†è¡¨ç¤ºï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å›¾-LLMæ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨è›‹ç™½è´¨ç»„å­¦ä¸­çš„åˆ†å­ç›¸äº’ä½œç”¨æ‹“æ‰‘ç»“æ„æ¥å­¦ä¹ æ‚£è€…ç‰¹å¼‚æ€§çš„å›¾è¡¨ç¤ºï¼Œä»¥å¢å¼ºä¸´åºŠæ¨ç†ã€‚æˆ‘ä»¬å±•ç¤ºäº†KRONOSåœ¨åŸºå‡†ä¸´åºŠä»»åŠ¡ä¸­çš„ç«äº‰åŠ›ï¼ŒåŒ…æ‹¬åˆ†å­åˆ†ç±»ã€æ—¶é—´è½¨è¿¹å»ºæ¨¡å’Œä»è›‹ç™½è´¨ç»„å­¦æ•°æ®ä¸­é¢„æµ‹è‚¿ç˜¤åˆ†æœŸã€‚æœ€ç»ˆï¼Œè¿™ç§æ–¹æ³•ä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç†è§£æ‚£è€…æ°´å¹³çš„ç—…ç†æœºåˆ¶ï¼Œä»è€Œæ¨åŠ¨æ›´åŠ å‡†ç¡®çš„è¯Šæ–­ã€é¢„åå’Œæ²»ç–—åˆ†å±‚ï¼Œä»¥å®ç°ç²¾å‡†åŒ»ç–—ã€‚ 

---
# Boundary on the Table: Efficient Black-Box Decision-Based Attacks for Structured Data 

**Title (ZH)**: è¾¹ç•Œä¹‹ä¸Šï¼šé¢å‘ç»“æ„åŒ–æ•°æ®çš„é«˜æ•ˆé»‘ç›’å†³ç­–åŸºæ”»å‡» 

**Authors**: Roie Kazoom, Yuval Ratzabi, Etamar Rothstein, Ofer Hadar  

**Link**: [PDF](https://arxiv.org/pdf/2509.22850)  

**Abstract**: Adversarial robustness in structured data remains an underexplored frontier compared to vision and language domains. In this work, we introduce a novel black-box, decision-based adversarial attack tailored for tabular data. Our approach combines gradient-free direction estimation with an iterative boundary search, enabling efficient navigation of discrete and continuous feature spaces under minimal oracle access. Extensive experiments demonstrate that our method successfully compromises nearly the entire test set across diverse models, ranging from classical machine learning classifiers to large language model (LLM)-based pipelines. Remarkably, the attack achieves success rates consistently above 90%, while requiring only a small number of queries per instance. These results highlight the critical vulnerability of tabular models to adversarial perturbations, underscoring the urgent need for stronger defenses in real-world decision-making systems. 

**Abstract (ZH)**: ç»“æ„åŒ–æ•°æ®çš„å¯¹æŠ—é²æ£’æ€§ç›¸è¾ƒäºè§†è§‰å’Œè¯­è¨€é¢†åŸŸä»æ˜¯ä¸€ä¸ªæœªå……åˆ†æ¢ç´¢çš„å‰æ²¿é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹è¡¨æ ¼æ•°æ®çš„æ–°å‹é»‘ç›’å†³ç­–å‹å¯¹æŠ—æ”»å‡»æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç»“åˆäº†æ— æ¢¯åº¦æ–¹å‘ä¼°è®¡ä¸è¿­ä»£è¾¹ç•Œæœç´¢ï¼Œèƒ½å¤Ÿåœ¨æœ€å°‘çš„oracleè®¿é—®ä¸‹é«˜æ•ˆå¯¼èˆªç¦»æ•£å’Œè¿ç»­ç‰¹å¾ç©ºé—´ã€‚å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æˆåŠŸåœ°å‡ ä¹å°†æ•´ä¸ªæµ‹è¯•é›†ä¸­çš„å¤šç§æ¨¡å‹ï¼ˆä»ç»å…¸æœºå™¨å­¦ä¹ åˆ†ç±»å™¨åˆ°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ç®¡é“ï¼‰æ”»å‡»æˆåŠŸç‡ä¿æŒåœ¨90%ä»¥ä¸Šã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†è¡¨æ ¼æ¨¡å‹å¯¹å¯¹æŠ—æ‰°åŠ¨çš„ä¸¥é‡æ˜“å—æ”»å‡»æ€§ï¼Œçªæ˜¾äº†æ€¥éœ€åœ¨å®é™…å†³ç­–ç³»ç»Ÿä¸­åŠ å¼ºé˜²å¾¡æªæ–½çš„é‡è¦æ€§ã€‚ 

---
# MTRec: Learning to Align with User Preferences via Mental Reward Models 

**Title (ZH)**: MTRec: åŸºäºå¿ƒæ™ºå¥–åŠ±æ¨¡å‹çš„å­¦ä¹ ç”¨æˆ·åå¥½å¤šæ¨¡æ€å¯¹é½æ–¹æ³• 

**Authors**: Mengchen Zhao, Yifan Gao, Yaqing Hou, Xiangyang Li, Pengjie Gu, Zhenhua Dong, Ruiming Tang, Yi Cai  

**Link**: [PDF](https://arxiv.org/pdf/2509.22807)  

**Abstract**: Recommendation models are predominantly trained using implicit user feedback, since explicit feedback is often costly to obtain. However, implicit feedback, such as clicks, does not always reflect users' real preferences. For example, a user might click on a news article because of its attractive headline, but end up feeling uncomfortable after reading the content. In the absence of explicit feedback, such erroneous implicit signals may severely mislead recommender systems. In this paper, we propose MTRec, a novel sequential recommendation framework designed to align with real user preferences by uncovering their internal satisfaction on recommended items. Specifically, we introduce a mental reward model to quantify user satisfaction and propose a distributional inverse reinforcement learning approach to learn it. The learned mental reward model is then used to guide recommendation models to better align with users' real preferences. Our experiments show that MTRec brings significant improvements to a variety of recommendation models. We also deploy MTRec on an industrial short video platform and observe a 7 percent increase in average user viewing time. 

**Abstract (ZH)**: ä¸€ç§æ–°å‹é¡ºåºæ¨èæ¡†æ¶MTRecï¼šé€šè¿‡æ­ç¤ºç”¨æˆ·å¯¹æ¨èé¡¹ç›®çš„å†…éƒ¨æ»¡æ„åº¦æ¥å¼•å¯¼æ¨èæ¨¡å‹æ›´å¥½åœ°å¥‘åˆç”¨æˆ·çš„çœŸå®åå¥½ 

---
# Generative Modeling and Decision Fusion for Unknown Event Detection and Classification Using Synchrophasor Data 

**Title (ZH)**: åŸºäºåŒæ­¥ç›¸é‡æ•°æ®çš„æœªçŸ¥äº‹ä»¶æ£€æµ‹ä¸åˆ†ç±»çš„ç”Ÿæˆå»ºæ¨¡å’Œå†³ç­–èåˆ 

**Authors**: Yi Hu, Zheyuan Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.22795)  

**Abstract**: Reliable detection and classification of power system events are critical for maintaining grid stability and situational awareness. Existing approaches often depend on limited labeled datasets, which restricts their ability to generalize to rare or unseen disturbances. This paper proposes a novel framework that integrates generative modeling, sliding-window temporal processing, and decision fusion to achieve robust event detection and classification using synchrophasor data. A variational autoencoder-generative adversarial network is employed to model normal operating conditions, where both reconstruction error and discriminator error are extracted as anomaly indicators. Two complementary decision strategies are developed: a threshold-based rule for computational efficiency and a convex hull-based method for robustness under complex error distributions. These features are organized into spatiotemporal detection and classification matrices through a sliding-window mechanism, and an identification and decision fusion stage integrates the outputs across PMUs. This design enables the framework to identify known events while systematically classifying previously unseen disturbances into a new category, addressing a key limitation of supervised classifiers. Experimental results demonstrate state-of-the-art accuracy, surpassing machine learning, deep learning, and envelope-based baselines. The ability to recognize unknown events further highlights the adaptability and practical value of the proposed approach for wide-area event analysis in modern power systems. 

**Abstract (ZH)**: å¯é çš„ç”µåŠ›ç³»ç»Ÿäº‹ä»¶æ£€æµ‹ä¸åˆ†ç±»å¯¹äºç»´æŒç”µç½‘ç¨³å®šæ€§å’Œæ€åŠ¿æ„ŸçŸ¥è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºæœ‰é™çš„æ ‡æ³¨æ•°æ®é›†ï¼Œé™åˆ¶äº†å®ƒä»¬å¯¹ç½•è§æˆ–æœªè§å¹²æ‰°çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†ç”Ÿæˆå»ºæ¨¡ã€æ»‘åŠ¨çª—å£æ—¶é—´å¤„ç†å’Œå†³ç­–èåˆï¼Œåˆ©ç”¨åŒæ­¥ç›¸é‡æ•°æ®å®ç°ç¨³å¥çš„äº‹ä»¶æ£€æµ‹ä¸åˆ†ç±»ã€‚é‡‡ç”¨å˜åˆ†è‡ªç¼–ç å™¨-ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¥å»ºæ¨¡æ­£å¸¸è¿è¡ŒçŠ¶æ€ï¼Œå…¶ä¸­é‡æ„è¯¯å·®å’Œé‰´åˆ«å™¨è¯¯å·®è¢«æå–ä¸ºå¼‚å¸¸æŒ‡æ ‡ã€‚å¼€å‘äº†ä¸¤ç§äº’è¡¥çš„å†³ç­–ç­–ç•¥ï¼šåŸºäºé˜ˆå€¼çš„è§„åˆ™ä»¥æé«˜è®¡ç®—æ•ˆç‡ï¼Œä»¥åŠåŸºäºå‡¸åŒ…çš„æ–¹æ³•ä»¥åœ¨å¤æ‚è¯¯å·®åˆ†å¸ƒä¸‹æé«˜é²æ£’æ€§ã€‚è¿™äº›ç‰¹å¾é€šè¿‡æ»‘åŠ¨çª—å£æœºåˆ¶ç»„ç»‡æˆæ—¶ç©ºæ£€æµ‹ä¸åˆ†ç±»çŸ©é˜µï¼Œå¹¶åœ¨è¯†åˆ«ä¸å†³ç­–èåˆé˜¶æ®µé›†æˆPMUè¾“å‡ºã€‚è¯¥è®¾è®¡ä½¿æ¡†æ¶èƒ½å¤Ÿè¯†åˆ«å·²çŸ¥äº‹ä»¶ï¼Œå¹¶ç³»ç»Ÿåœ°å°†æœªè§å¹²æ‰°åˆ†ç±»åˆ°æ–°ç±»åˆ«ä¸­ï¼Œè§£å†³äº†ç›‘ç£åˆ†ç±»å™¨çš„ä¸€ä¸ªå…³é”®å±€é™æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®åº¦ä¸Šè¾¾åˆ°æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼Œè¶…è¶Šäº†æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ å’ŒåŒ…ç»œåŸºçº¿æ–¹æ³•ã€‚èƒ½å¤Ÿè¯†åˆ«æœªçŸ¥äº‹ä»¶è¿›ä¸€æ­¥çªæ˜¾äº†æ‰€æå‡ºæ–¹æ³•åœ¨ç°ä»£ç”µåŠ›ç³»ç»Ÿå¹¿åŸŸäº‹ä»¶åˆ†æä¸­çš„é€‚åº”æ€§å’Œå®é™…ä»·å€¼ã€‚ 

---
# Differentially Private Two-Stage Gradient Descent for Instrumental Variable Regression 

**Title (ZH)**: å·®åˆ†éšç§ä¸¤é˜¶æ®µæ¢¯åº¦ä¸‹é™æ³•åœ¨å·¥å…·å˜é‡å›å½’ä¸­çš„åº”ç”¨ 

**Authors**: Haodong Liang, Yanhao Jin, Krishnakumar Balasubramanian, Lifeng Lai  

**Link**: [PDF](https://arxiv.org/pdf/2509.22794)  

**Abstract**: We study instrumental variable regression (IVaR) under differential privacy constraints. Classical IVaR methods (like two-stage least squares regression) rely on solving moment equations that directly use sensitive covariates and instruments, creating significant risks of privacy leakage and posing challenges in designing algorithms that are both statistically efficient and differentially private. We propose a noisy two-state gradient descent algorithm that ensures $\rho$-zero-concentrated differential privacy by injecting carefully calibrated noise into the gradient updates. Our analysis establishes finite-sample convergence rates for the proposed method, showing that the algorithm achieves consistency while preserving privacy. In particular, we derive precise bounds quantifying the trade-off among privacy parameters, sample size, and iteration-complexity. To the best of our knowledge, this is the first work to provide both privacy guarantees and provable convergence rates for instrumental variable regression in linear models. We further validate our theoretical findings with experiments on both synthetic and real datasets, demonstrating that our method offers practical accuracy-privacy trade-offs. 

**Abstract (ZH)**: æˆ‘ä»¬ç ”ç©¶å·®åˆ†éšç§çº¦æŸä¸‹çš„å·¥å…·å˜é‡å›å½’ï¼ˆIVaRï¼‰ã€‚ç»å…¸çš„å·¥å…·å˜é‡å›å½’æ–¹æ³•ï¼ˆå¦‚ä¸¤é˜¶æ®µæœ€å°å¹³æ–¹æ³•ï¼‰ä¾èµ–äºç›´æ¥ä½¿ç”¨æ•æ„Ÿåå˜é‡å’Œå·¥å…·å˜é‡æ±‚è§£çŸ©æ–¹ç¨‹ï¼Œè¿™äº§ç”Ÿäº†é‡å¤§çš„éšç§æ³„éœ²é£é™©ï¼Œå¹¶ç»™è®¾è®¡åŒæ—¶å…·å¤‡ç»Ÿè®¡æ•ˆç‡å’Œå·®åˆ†éšç§æ€§çš„ç®—æ³•å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å™ªå£°äºŒçŠ¶æ€æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œé€šè¿‡åœ¨æ¢¯åº¦æ›´æ–°ä¸­æ³¨å…¥ç²¾å¿ƒæ ¡å‡†çš„å™ªå£°æ¥ç¡®ä¿$\rho$-é›¶é›†ä¸­å·®åˆ†éšç§ã€‚æˆ‘ä»¬çš„åˆ†æå»ºç«‹äº†æ‰€ææ–¹æ³•çš„æœ‰é™æ ·æœ¬æ”¶æ•›é€Ÿç‡ï¼Œè¡¨æ˜è¯¥ç®—æ³•æ—¢èƒ½ä¿æŒä¸€è‡´æ€§åˆèƒ½ä¿æŠ¤éšç§ã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†ç²¾ç¡®ç•Œå®šé‡åŒ–çš„éšç§å‚æ•°ã€æ ·æœ¬é‡å’Œè¿­ä»£å¤æ‚åº¦ä¹‹é—´çš„æƒè¡¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªåŒæ—¶æä¾›å·¥å…·å˜é‡å›å½’åœ¨çº¿æ€§æ¨¡å‹ä¸­å·®åˆ†éšç§ä¿è¯å’Œå¯è¯æ˜æ”¶æ•›é€Ÿç‡çš„å·¥ä½œã€‚æˆ‘ä»¬è¿˜é€šè¿‡åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„ç†è®ºå‘ç°ï¼Œè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†å®ç”¨çš„å‡†ç¡®æ€§å’Œéšç§ä¹‹é—´çš„æƒè¡¡ã€‚ 

---
# A theoretical guarantee for SyncRank 

**Title (ZH)**: SyncRankçš„ç†è®ºä¿è¯ 

**Authors**: Yang Rao  

**Link**: [PDF](https://arxiv.org/pdf/2509.22766)  

**Abstract**: We present a theoretical and empirical analysis of the SyncRank algorithm for recovering a global ranking from noisy pairwise comparisons. By adopting a complex-valued data model where the true ranking is encoded in the phases of a unit-modulus vector, we establish a sharp non-asymptotic recovery guarantee for the associated semidefinite programming (SDP) relaxation. Our main theorem characterizes a critical noise threshold - scaling as sigma = O(sqrt(n / log n)) - below which SyncRank achieves exact ranking recovery with high probability. Extensive experiments under this model confirm the theoretical predictions and demonstrate the algorithm's robustness across varying problem sizes and noise regimes. 

**Abstract (ZH)**: æˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹å™ªå£°åŒè¾¹æ¯”è¾ƒè¿›è¡Œå…¨å±€æ’åæ¢å¤çš„SyncRankç®—æ³•çš„ç†è®ºå’Œå®è¯åˆ†æã€‚é€šè¿‡é‡‡ç”¨å¤å€¼æ•°æ®æ¨¡å‹ï¼Œå…¶ä¸­çœŸå®çš„æ’åç¼–ç åœ¨å•ä½æ¨¡å‘é‡çš„ç›¸ä½ä¸­ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸ä¹‹ç›¸å…³çš„åŠå®šè§„åˆ’ï¼ˆSDPï¼‰æ¾å¼›çš„ç²¾ç¡®éæ¸è¿‘æ¢å¤ä¿è¯ã€‚æˆ‘ä»¬çš„ä¸»è¦å®šç†åˆ»ç”»äº†ä¸€ä¸ªå…³é”®çš„å™ªå£°é˜ˆå€¼â€”â€”çº¦ä¸ºÏƒ=O(âˆš(n/logn))â€”åœ¨è¯¥é˜ˆå€¼ä»¥ä¸‹ï¼ŒSyncRankä»¥é«˜æ¦‚ç‡å®ç°ç²¾ç¡®çš„æ’åæ¢å¤ã€‚åœ¨è¯¥æ¨¡å‹ä¸‹çš„å¤§é‡å®éªŒè¯æ˜äº†ç†è®ºé¢„æµ‹ï¼Œå¹¶å±•ç¤ºäº†è¯¥ç®—æ³•åœ¨ä¸åŒé—®é¢˜è§„æ¨¡å’Œå™ªå£°æ¡ä»¶ä¸‹çš„ç¨³å¥æ€§ã€‚ 

---
# Red Teaming Quantum-Resistant Cryptographic Standards: A Penetration Testing Framework Integrating AI and Quantum Security 

**Title (ZH)**: çº¢é˜Ÿæµ‹è¯•é‡å­æŠ—æ€§åŠ å¯†æ ‡å‡†ï¼šèåˆAIä¸é‡å­å®‰å…¨çš„æ¸—é€æµ‹è¯•æ¡†æ¶ 

**Authors**: Petar Radanliev  

**Link**: [PDF](https://arxiv.org/pdf/2509.22757)  

**Abstract**: This study presents a structured approach to evaluating vulnerabilities within quantum cryptographic protocols, focusing on the BB84 quantum key distribution method and National Institute of Standards and Technology (NIST) approved quantum-resistant algorithms. By integrating AI-driven red teaming, automated penetration testing, and real-time anomaly detection, the research develops a framework for assessing and mitigating security risks in quantum networks. The findings demonstrate that AI can be effectively used to simulate adversarial attacks, probe weaknesses in cryptographic implementations, and refine security mechanisms through iterative feedback. The use of automated exploit simulations and protocol fuzzing provides a scalable means of identifying latent vulnerabilities, while adversarial machine learning techniques highlight novel attack surfaces within AI-enhanced cryptographic processes. This study offers a comprehensive methodology for strengthening quantum security and provides a foundation for integrating AI-driven cybersecurity practices into the evolving quantum landscape. 

**Abstract (ZH)**: æœ¬ç ”ç©¶æä¾›äº†ä¸€ç§ç»“æ„åŒ–çš„æ–¹æ³•æ¥è¯„ä¼°é‡å­åŠ å¯†åè®®ä¸­çš„æ¼æ´ï¼Œé‡ç‚¹å…³æ³¨BB84é‡å­å¯†é’¥åˆ†å‘æ–¹æ³•å’Œç¾å›½å›½å®¶æ ‡å‡†ä¸æŠ€æœ¯ç ”ç©¶é™¢ï¼ˆNISTï¼‰æ‰¹å‡†çš„é‡å­æŠ—æ”»å‡»ç®—æ³•ã€‚é€šè¿‡æ•´åˆåŸºäºAIçš„çº¢é˜Ÿæ”»å‡»ã€è‡ªåŠ¨åŒ–æ¸—é€æµ‹è¯•å’Œå®æ—¶å¼‚å¸¸æ£€æµ‹ï¼Œç ”ç©¶å¼€å‘äº†ä¸€ç§è¯„ä¼°å’Œç¼“è§£é‡å­ç½‘ç»œä¸­å®‰å…¨é£é™©çš„æ¡†æ¶ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒAIå¯ä»¥æœ‰æ•ˆç”¨äºæ¨¡æ‹Ÿå¯¹æ‰‹æ”»å‡»ã€æ¢æµ‹ cryptographic å®æ–½ä¸­çš„å¼±ç‚¹ï¼Œå¹¶é€šè¿‡è¿­ä»£åé¦ˆç²¾ç‚¼å®‰å…¨æœºåˆ¶ã€‚è‡ªåŠ¨åŒ–æ¼æ´åˆ©ç”¨æ¨¡æ‹Ÿå’Œåè®® fuzzing æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•æ¥è¯†åˆ«æ½œåœ¨æ¼æ´ï¼Œè€Œå¯¹æŠ—æ€§æœºå™¨å­¦ä¹ æŠ€æœ¯åˆ™çªæ˜¾äº†å¢å¼ºå‹ cryptographic è¿‡ç¨‹ä¸­çš„æ–°å‹æ”»å‡»é¢ã€‚æœ¬ç ”ç©¶æä¾›äº†ä¸€ç§å…¨é¢çš„æ–¹æ³•æ¥åŠ å¼ºé‡å­å®‰å…¨ï¼Œå¹¶ä¸ºå°†åŸºäºAIçš„ç½‘ç»œå®‰å…¨å®è·µé›†æˆåˆ°ä¸æ–­å‘å±•çš„é‡å­ç¯å¢ƒä¸­å¥ å®šäº†åŸºç¡€ã€‚ 

---
# Variance-Bounded Evaluation without Ground Truth: VB-Score 

**Title (ZH)**: æ—  ground truth æ¡ä»¶ä¸‹çš„æ–¹å·®æœ‰ç•Œè¯„ä¼°ï¼šVB-Score 

**Authors**: Kaihua Ding  

**Link**: [PDF](https://arxiv.org/pdf/2509.22751)  

**Abstract**: Reliable evaluation is a central challenge in machine learning when tasks lack ground truth labels or involve ambiguity and noise. Conventional frameworks, rooted in the Cranfield paradigm and label-based metrics, fail in such cases because they cannot assess how robustly a system performs under uncertain interpretations. We introduce VB-Score, a variance-bounded evaluation framework that measures both effectiveness and robustness without requiring ground truth. Given a query or input, VB-Score enumerates plausible interpretations, assigns probabilities, and evaluates output by expected success penalized by variance, rewarding consistent performance across intents. We provide a formal analysis of VB-Score, establishing range, monotonicity, and stability properties, and relate it to risk-sensitive measures such as mean-variance utility. Experiments on ambiguous queries and entity-centric retrieval tasks show that VB-Score surfaces robustness differences hidden by conventional metrics. By enabling reproducible, label-free evaluation, VB-Score offers a principled foundation for benchmarking machine learning systems in ambiguous or label-scarce domains. 

**Abstract (ZH)**: å¯é çš„è¯„ä¼°æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€é¡¹ä¸­å¿ƒæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»»åŠ¡ç¼ºä¹ ground truth æ ‡ç­¾æˆ–æ¶‰åŠæ¨¡ç³Šæ€§å’Œå™ªå£°çš„æƒ…å†µä¸‹ã€‚ä¼ ç»Ÿçš„æ¡†æ¶æ ¹æ¤äº Cranfield å¸•ç´¯æ‰˜æ€æƒ³å’ŒåŸºäºæ ‡ç­¾çš„åº¦é‡æ ‡å‡†ï¼Œæ— æ³•åœ¨è¿™ç§æƒ…å†µä¸‹å‘æŒ¥ä½œç”¨ï¼Œå› ä¸ºå®ƒä»¬æ— æ³•è¯„ä¼°ç³»ç»Ÿåœ¨ä¸ç¡®å®šè§£é‡Šä¸‹çš„é²æ£’æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº† VB-Scoreï¼Œè¿™æ˜¯ä¸€ç§æ–¹å·®å—é™çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€ ground truth çš„æƒ…å†µä¸‹è¡¡é‡æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚ç»™å®šæŸ¥è¯¢æˆ–è¾“å…¥ï¼ŒVB-Score åˆ—ä¸¾å¯èƒ½çš„è§£é‡Šï¼Œåˆ†é…æ¦‚ç‡ï¼Œå¹¶é€šè¿‡é¢„æœŸæˆåŠŸæƒ©ç½šæ–¹å·®è¿›è¡Œè¯„ä¼°ï¼Œå¥–åŠ±æ„å›¾ä¸€è‡´çš„æ€§èƒ½ã€‚æˆ‘ä»¬å¯¹ VB-Score è¿›è¡Œäº†å½¢å¼åŒ–åˆ†æï¼Œé˜æ˜äº†å…¶èŒƒå›´ã€å•è°ƒæ€§å’Œç¨³å®šæ€§æ€§è´¨ï¼Œå¹¶å°†å…¶ä¸å‡å€¼æ–¹å·®æ•ˆç”¨ç­‰é£é™©æ•æ„Ÿåº¦é‡è¿›è¡Œäº†å…³è”ã€‚å®éªŒè¡¨æ˜ï¼ŒVB-Score å¯ä»¥æ­ç¤ºä¼ ç»Ÿåº¦é‡æ‰€éšè—çš„é²æ£’æ€§å·®å¼‚ã€‚é€šè¿‡ä½¿è¯„ä¼°å¯é‡å¤ä¸”æ— éœ€æ ‡ç­¾ï¼ŒVB-Score ä¸ºåœ¨æ¨¡ç³Šæˆ–æ ‡ç­¾ç¨€ç¼ºé¢†åŸŸè¯„ä¼°æœºå™¨å­¦ä¹ ç³»ç»Ÿæä¾›äº†æœ‰åŸåˆ™çš„åŸºç¡€ã€‚ 

---
# MIRAGE: Multi-hop Reasoning with Ambiguity Evaluation for Illusory Questions 

**Title (ZH)**: MIRAGE: å¤šè·³æ¨ç†ç»“åˆæ­§ä¹‰è¯„ä¼°ç”¨äºè™šå‡é—®é¢˜ 

**Authors**: Jeonghyun Park, Ingeol Baek, Seunghyun Yoon, Haeun Jang, Aparna Garimella, Akriti Jain, Nedim Lipka, Hwanhee Lee  

**Link**: [PDF](https://arxiv.org/pdf/2509.22750)  

**Abstract**: Real-world Multi-hop Question Answering (QA) often involves ambiguity that is inseparable from the reasoning process itself. This ambiguity creates a distinct challenge, where multiple reasoning paths emerge from a single question, each requiring independent resolution. Since each sub-question is ambiguous, the model must resolve ambiguity at every step. Thus, answering a single question requires handling multiple layers of ambiguity throughout the reasoning chain. We find that current Large Language Models (LLMs) struggle in this setting, typically exploring wrong reasoning paths and producing incomplete answers. To facilitate research on multi-hop ambiguity, we introduce MultI-hop Reasoning with AmbiGuity Evaluation for Illusory Questions (MIRAGE), a benchmark designed to analyze and evaluate this challenging intersection of ambiguity interpretation and multi-hop reasoning. MIRAGE contains 1,142 high-quality examples of ambiguous multi-hop questions, categorized under a taxonomy of syntactic, general, and semantic ambiguity, and curated through a rigorous multi-LLM verification pipeline. Our experiments reveal that even state-of-the-art models struggle on MIRAGE, confirming that resolving ambiguity combined with multi-step inference is a distinct and significant challenge. To establish a robust baseline, we propose CLarifying Ambiguity with a Reasoning and InstructiON (CLARION), a multi-agent framework that significantly outperforms existing approaches on MIRAGE, paving the way for more adaptive and robust reasoning systems. 

**Abstract (ZH)**: çœŸå®ä¸–ç•Œå¤šè·³é—®ç­”ä¸­å­˜åœ¨çš„æ¨ç†è¿‡ç¨‹ä¸­ä¸å¯é¿å…çš„æ­§ä¹‰æ€§æå‡ºäº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼šMIRAGEå¤šæ­§ä¹‰æ¨ç†åŸºå‡† 

---
# Societal Capacity Assessment Framework: Measuring Resilience to Inform Advanced AI Risk Management 

**Title (ZH)**: ç¤¾ä¼šèƒ½åŠ›è¯„ä¼°æ¡†æ¶ï¼šè¡¡é‡éŸ§æ€§ä»¥æŒ‡å¯¼å…ˆè¿›äººå·¥æ™ºèƒ½é£é™©ç®¡ç† 

**Authors**: Milan Gandhi, Peter Cihon, Owen Larter, Rebecca Anselmetti  

**Link**: [PDF](https://arxiv.org/pdf/2509.22742)  

**Abstract**: Risk assessments for advanced AI systems require evaluating both the models themselves and their deployment contexts. We introduce the Societal Capacity Assessment Framework (SCAF), an indicators-based approach to measuring a society's vulnerability, coping capacity, and adaptive capacity in response to AI-related risks. SCAF adapts established resilience analysis methodologies to AI, enabling organisations to ground risk management in insights about country-level deployment conditions. It can also support stakeholders in identifying opportunities to strengthen societal preparedness for emerging AI capabilities. By bridging disparate literatures and the "context gap" in AI evaluation, SCAF promotes more holistic risk assessment and governance as advanced AI systems proliferate globally. 

**Abstract (ZH)**: é«˜çº§AIç³»ç»Ÿçš„é£é™©è¯„ä¼°éœ€è¦è¯„ä¼°æ¨¡å‹æœ¬èº«åŠå…¶éƒ¨ç½²ç¯å¢ƒã€‚æˆ‘ä»¬ä»‹ç»äº†ç¤¾ä¼šèƒ½åŠ›è¯„ä¼°æ¡†æ¶ï¼ˆSCAFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæŒ‡æ ‡çš„æ–¹æ³•ï¼Œç”¨äºè¡¡é‡ç¤¾ä¼šåœ¨åº”å¯¹AIç›¸å…³é£é™©æ—¶çš„è„†å¼±æ€§ã€åº”å¯¹èƒ½åŠ›å’Œé€‚åº”èƒ½åŠ›ã€‚SCAFå°†ç°æœ‰çš„éŸ§æ€§åˆ†ææ–¹æ³•åº”ç”¨äºAIï¼Œä½¿ç»„ç»‡èƒ½å¤ŸåŸºäºå›½å®¶å±‚é¢éƒ¨ç½²æ¡ä»¶çš„é£é™©ç®¡ç†æ´å¯Ÿã€‚å®ƒè¿˜å¯ä»¥å¸®åŠ©åˆ©ç›Šç›¸å…³è€…è¯†åˆ«åŠ å¼ºç¤¾ä¼šå¯¹æ–°å…´AIèƒ½åŠ›å‡†å¤‡çš„æœºä¼šã€‚é€šè¿‡å¼¥åˆä¸åŒæ–‡çŒ®ä¹‹é—´çš„é¸¿æ²Ÿä»¥åŠAIè¯„ä¼°ä¸­çš„â€œç¯å¢ƒå·®è·â€ï¼ŒSCAFä¿ƒè¿›äº†æ›´å…¨é¢çš„é£é™©è¯„ä¼°å’Œæ²»ç†ï¼Œéšç€é«˜çº§AIç³»ç»Ÿçš„å…¨çƒæ™®åŠã€‚ 

---
# Consistency Models as Plug-and-Play Priors for Inverse Problems 

**Title (ZH)**: ä¸€è‡´æ€§æ¨¡å‹ä½œä¸ºå³æ’å³ç”¨å…ˆéªŒç”¨äºé€†é—®é¢˜ 

**Authors**: Merve GÃ¼lle, Junno Yun, YaÅŸar Utku AlÃ§alar, Mehmet AkÃ§akaya  

**Link**: [PDF](https://arxiv.org/pdf/2509.22736)  

**Abstract**: Diffusion models have found extensive use in solving numerous inverse problems. Such diffusion inverse problem solvers aim to sample from the posterior distribution of data given the measurements, using a combination of the unconditional score function and an approximation of the posterior related to the forward process. Recently, consistency models (CMs) have been proposed to directly predict the final output from any point on the diffusion ODE trajectory, enabling high-quality sampling in just a few NFEs. CMs have also been utilized for inverse problems, but existing CM-based solvers either require additional task-specific training or utilize data fidelity operations with slow convergence, not amenable to large-scale problems. In this work, we reinterpret CMs as proximal operators of a prior, enabling their integration into plug-and-play (PnP) frameworks. We propose a solver based on PnP-ADMM, which enables us to leverage the fast convergence of conjugate gradient method. We further accelerate this with noise injection and momentum, dubbed PnP-CM, and show it maintains the convergence properties of the baseline PnP-ADMM. We evaluate our approach on a variety of inverse problems, including inpainting, super-resolution, Gaussian deblurring, and magnetic resonance imaging (MRI) reconstruction. To the best of our knowledge, this is the first CM trained for MRI datasets. Our results show that PnP-CM achieves high-quality reconstructions in as few as 4 NFEs, and can produce meaningful results in 2 steps, highlighting its effectiveness in real-world inverse problems while outperforming comparable CM-based approaches. 

**Abstract (ZH)**: æ‰©æ•£æ¨¡å‹åœ¨è§£å†³ä¼—å¤šé€†é—®é¢˜ä¸­æ‰¾åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚è¿™æ ·çš„æ‰©æ•£é€†é—®é¢˜æ±‚è§£å™¨æ—¨åœ¨åˆ©ç”¨æ— æ¡ä»¶å¾—åˆ†å‡½æ•°ä¸å‰å‘è¿‡ç¨‹ç›¸å…³è”çš„åéªŒè¿‘ä¼¼å…±åŒä»ç»™å®šæµ‹é‡çš„æ•°æ®åéªŒåˆ†å¸ƒä¸­é‡‡æ ·ã€‚æœ€è¿‘ï¼Œä¸€è‡´æ€§æ¨¡å‹ï¼ˆCMsï¼‰å·²è¢«æå‡ºï¼Œå¯ä»¥ç›´æ¥ä»æ‰©æ•£å¾®åˆ†æ–¹ç¨‹è½¨è¿¹ä¸Šçš„ä»»ä½•ç‚¹é¢„æµ‹æœ€ç»ˆè¾“å‡ºï¼Œä»è€Œä½¿é«˜è´¨é‡é‡‡æ ·ä»…éœ€å°‘é‡NFEsã€‚CMsä¹Ÿè¢«ç”¨äºé€†é—®é¢˜ï¼Œä½†ç°æœ‰çš„CMåŸºæ±‚è§£å™¨è¦ä¹ˆéœ€è¦é™„åŠ çš„ä»»åŠ¡ç‰¹å®šè®­ç»ƒï¼Œè¦ä¹ˆä½¿ç”¨æ•°æ®ä¿çœŸæ“ä½œä¸”æ”¶æ•›ç¼“æ…¢ï¼Œä¸é€‚ç”¨äºå¤§è§„æ¨¡é—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡æ–°è§£é‡ŠCMsä½œä¸ºå…ˆéªŒçš„è¿‘é‚»ç®—å­ï¼Œä½¿å…¶èƒ½å¤Ÿé›†æˆåˆ°å³æ’å³ç”¨ï¼ˆPnPï¼‰æ¡†æ¶ä¸­ã€‚æˆ‘ä»¬æå‡ºä¸€ç§åŸºäºPnP-ADMMçš„æ–¹æ³•ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨å…±è½­æ¢¯åº¦æ³•çš„å¿«é€Ÿæ”¶æ•›ç‰¹æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡å™ªå£°æ³¨å…¥å’ŒåŠ¨é‡åŠ é€Ÿè¿™ç§æ–¹æ³•ï¼Œå‘½åä¸ºPnP-CMï¼Œå¹¶è¯æ˜å…¶ä¿æŒäº†åŸºç¡€PnP-ADMMçš„æ”¶æ•›ç‰¹æ€§ã€‚æˆ‘ä»¬åœ¨å›¾åƒä¿®å¤ã€è¶…åˆ†è¾¨ç‡ã€é«˜æ–¯å»æ¨¡ç³Šå’Œç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰é‡å»ºç­‰å¤šç§é€†é—®é¢˜ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºMRIæ•°æ®é›†çš„CMè®­ç»ƒæ–¹æ³•ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒPnP-CMå¯ä»¥åœ¨ä»…4ä¸ªNFEså†…å®ç°é«˜è´¨é‡çš„é‡å»ºï¼Œå¹¶ä¸”å¯ä»¥åœ¨ä¸¤æ­¥å†…ç”Ÿæˆæœ‰æ„ä¹‰çš„ç»“æœï¼Œçªæ˜¾äº†å…¶åœ¨çœŸå®ä¸–ç•Œé€†é—®é¢˜ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¼˜äºç›¸ä¼¼çš„CMåŸºæ–¹æ³•ã€‚ 

---
# Rebuild AC Power Flow Models with Graph Attention Networks 

**Title (ZH)**: åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œé‡æ„ACåŠŸç‡æµæ¨¡å‹ 

**Authors**: Yuting Hu, Jinjun Xiong  

**Link**: [PDF](https://arxiv.org/pdf/2509.22733)  

**Abstract**: A full power flow (PF) model is a complete representation of the physical power network. Traditional model-based methods rely on the full PF model to implement power flow analysis. In practice, however, some PF model parameters can be inaccurate or even unavailable due to the uncertainties or dynamics in the power systems. Moreover, because the power network keeps evolving with possibly changing topology, the generalizability of a PF model to different network sizes and typologies should be considered. In this paper, we propose a PF rebuild model based on graph attention networks (GAT) by constructing a new graph based on the real and imaginary parts of voltage at each bus. By comparing with two state-of-the-art PF rebuild models for different standard IEEE power system cases and their modified topology variants, we demonstrate the feasibility of our method. Experimental results show that our proposed model achieves better accuracy for a changing network and can generalize to different networks with less accuracy discount. 

**Abstract (ZH)**: åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œçš„å…¨åŠŸç‡æµé‡å»ºæ¨¡å‹ 

---
# Prompt-aware classifier free guidance for diffusion models 

**Title (ZH)**: åŸºäºæç¤ºæ„ŸçŸ¥çš„åˆ†ç±»å™¨ Free æŒ‡å¯¼çš„æ‰©æ•£æ¨¡å‹ 

**Authors**: Xuanhao Zhang, Chang Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.22728)  

**Abstract**: Diffusion models have achieved remarkable progress in image and audio generation, largely due to Classifier-Free Guidance. However, the choice of guidance scale remains underexplored: a fixed scale often fails to generalize across prompts of varying complexity, leading to oversaturation or weak alignment. We address this gap by introducing a prompt-aware framework that predicts scale-dependent quality and selects the optimal guidance at inference. Specifically, we construct a large synthetic dataset by generating samples under multiple scales and scoring them with reliable evaluation metrics. A lightweight predictor, conditioned on semantic embeddings and linguistic complexity, estimates multi-metric quality curves and determines the best scale via a utility function with regularization. Experiments on MSCOCO~2014 and AudioCaps show consistent improvements over vanilla CFG, enhancing fidelity, alignment, and perceptual preference. This work demonstrates that prompt-aware scale selection provides an effective, training-free enhancement for pretrained diffusion backbones. 

**Abstract (ZH)**: å·®åˆ†æ¨¡å‹åœ¨å›¾åƒå’ŒéŸ³é¢‘ç”Ÿæˆä¸­çš„è¿›æ­¥ largelyå¾—ç›Šäº Classifier-Free Guidanceã€‚ç„¶è€Œï¼ŒæŒ‡å¯¼å°ºåº¦çš„é€‰æ‹©ä»ç„¶æ²¡æœ‰å¾—åˆ°å……åˆ†æ¢ç´¢ï¼šå›ºå®šå°ºåº¦å¾€å¾€æ— æ³•é€‚åº”ä¸åŒå¤æ‚åº¦æç¤ºçš„æ³›åŒ–ï¼Œå¯¼è‡´è¿‡åº¦é¥±å’Œæˆ–å¯¹é½ä¸è¶³ã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªæç¤ºæ„ŸçŸ¥æ¡†æ¶æ¥å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œè¯¥æ¡†æ¶é¢„æµ‹å°ºåº¦ä¾èµ–çš„è´¨é‡å¹¶é€‰æ‹©æœ€ä½³æŒ‡å¯¼è§„æ¨¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨å¤šä¸ªå°ºåº¦ä¸‹ç”Ÿæˆæ ·æœ¬å¹¶ä½¿ç”¨å¯é çš„è¯„ä¼°æŒ‡æ ‡å¯¹å…¶è¿›è¡Œè¯„åˆ†ï¼Œæ„é€ äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„åˆæˆæ•°æ®é›†ã€‚ä¸€ä¸ªè½»é‡çº§çš„é¢„æµ‹å™¨ï¼ŒåŸºäºè¯­ä¹‰åµŒå…¥å’Œè¯­è¨€å¤æ‚æ€§è¿›è¡Œæ¡ä»¶åŒ–ï¼Œä¼°è®¡å¤šæŒ‡æ ‡è´¨é‡æ›²çº¿ï¼Œå¹¶é€šè¿‡å¸¦æ­£åˆ™åŒ–çš„æ•ˆç”¨å‡½æ•°ç¡®å®šæœ€ä½³å°ºåº¦ã€‚åœ¨ MSCOCO 2014 å’Œ AudioCaps ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸ vanilla CFG ç›¸æ¯”ï¼Œæ­¤å·¥ä½œä¸€è‡´åœ°æé«˜äº†ä¿çœŸåº¦ã€å¯¹é½å’Œæ„ŸçŸ¥åå¥½ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†æç¤ºæ„ŸçŸ¥å°ºåº¦é€‰æ‹©ä¸ºé¢„è®­ç»ƒçš„å·®åˆ†æ¨¡å‹éª¨æ¶æä¾›äº†æœ‰æ•ˆä¸”æ— éœ€è®­ç»ƒçš„å¢å¼ºã€‚ 

---
# A Data-Driven Framework for Digital Transformation in Smart Cities: Integrating AI, Dashboards, and IoT Readiness 

**Title (ZH)**: é¢å‘æ™ºèƒ½åŸå¸‚çš„åŸºäºæ•°æ®çš„æ•°å­—è½¬å‹æ¡†æ¶ï¼šé›†æˆAIã€ä»ªè¡¨ç›˜å’Œç‰©è”ç½‘ readiness 

**Authors**: Ãngel Lloret, JesÃºs Peral, Antonio FerrÃ¡ndez, MarÃ­a Auladell, Rafael MuÃ±oz  

**Link**: [PDF](https://arxiv.org/pdf/2509.22721)  

**Abstract**: Digital transformation (DT) has become a strategic priority for public administrations, particularly due to the need to deliver more efficient and citizen-centered services and respond to societal expectations, ESG (Environmental, Social, and Governance) criteria, and the United Nations Sustainable Development Goals (UN SDGs). In this context, the main objective of this study is to propose an innovative methodology to automatically evaluate the level of digital transformation (DT) in public sector organizations. The proposed approach combines traditional assessment methods with Artificial Intelligence (AI) techniques. The methodology follows a dual approach: on the one hand, surveys are conducted using specialized staff from various public entities; on the other, AI-based models (including neural networks and transformer architectures) are used to estimate the DT level of the organizations automatically. Our approach has been applied to a real-world case study involving local public administrations in the Valencian Community (Spain) and shown effective performance in assessing DT. While the proposed methodology has been validated in a specific local context, its modular structure and dual-source data foundation support its international scalability, acknowledging that administrative, regulatory, and DT maturity factors may condition its broader applicability. The experiments carried out in this work include (i) the creation of a domain-specific corpus derived from the surveys and websites of several organizations, used to train the proposed models; (ii) the use and comparison of diverse AI methods; and (iii) the validation of our approach using real data. The integration of technologies such as the IoT, sensor networks, and AI-based analytics can significantly support resilient, agile urban environments and the transition towards more effective and sustainable Smart City models. 

**Abstract (ZH)**: æ•°å­—è½¬å‹ï¼ˆDTï¼‰å·²æˆä¸ºå…¬å…±ç®¡ç†çš„æˆ˜ç•¥ä¼˜å…ˆäº‹é¡¹ï¼Œç‰¹åˆ«æ˜¯åœ¨æä¾›æ›´é«˜æ•ˆå’Œä»¥å…¬æ°‘ä¸ºä¸­å¿ƒçš„æœåŠ¡ä»¥åŠå›åº”ç¤¾ä¼šæœŸæœ›ã€ESGï¼ˆç¯å¢ƒã€ç¤¾ä¼šå’Œæ²»ç†ï¼‰æ ‡å‡†å’Œè”åˆå›½å¯æŒç»­å‘å±•ç›®æ ‡ï¼ˆUN SDGsï¼‰æ–¹é¢ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œæœ¬ç ”ç©¶çš„ä¸»è¦ç›®æ ‡æ˜¯æå‡ºä¸€ç§åˆ›æ–°æ–¹æ³•ï¼Œè‡ªåŠ¨è¯„ä¼°å…¬å…±éƒ¨é—¨ç»„ç»‡çš„æ•°å­—è½¬å‹æ°´å¹³ã€‚æ‰€æå‡ºçš„æ–¹æ³•å°†ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ä¸äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æŠ€æœ¯ç›¸ç»“åˆã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŒè½¨ç­–ç•¥ï¼šä¸€æ–¹é¢é‡‡ç”¨æ¥è‡ªå„ç±»å…¬å…±æœºæ„çš„ä¸“ä¸šäººå‘˜è¿›è¡Œé—®å·è°ƒæŸ¥ï¼›å¦ä¸€æ–¹é¢ä½¿ç”¨åŸºäºAIçš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ç¥ç»ç½‘ç»œå’Œå˜æ¢å™¨æ¶æ„ï¼‰è‡ªåŠ¨ä¼°è®¡ç»„ç»‡çš„æ•°å­—è½¬å‹æ°´å¹³ã€‚è¯¥æ–¹æ³•åœ¨è¥¿ç­ç‰™ç“¦ä¼¦è¥¿äºšè‡ªæ²»åŒºçš„åœ°æ–¹å…¬å…±ç®¡ç†æœºæ„çš„å®é™…æ¡ˆä¾‹ç ”ç©¶ä¸­å¾—åˆ°åº”ç”¨ï¼Œå¹¶å±•ç¤ºäº†å…¶è¯„ä¼°æ•°å­—è½¬å‹çš„æœ‰æ•ˆæ€§ã€‚è™½ç„¶æ‰€æå‡ºçš„æ–¹æ³•åœ¨ç‰¹å®šçš„åœ°æ–¹èƒŒæ™¯ä¸‹å¾—åˆ°äº†éªŒè¯ï¼Œä½†å…¶æ¨¡å—åŒ–ç»“æ„å’Œå¤šæ•°æ®æºåŸºç¡€ä½¿å…¶å…·æœ‰å›½é™…æ‰©å±•æ€§ï¼Œè®¤è¯†åˆ°è¡Œæ”¿ã€ç›‘ç®¡å’Œæ•°å­—è½¬å‹æˆç†Ÿåº¦ç­‰å› ç´ å¯èƒ½å¯¹å…¶æ›´å¹¿æ³›çš„åº”ç”¨äº§ç”Ÿå½±å“ã€‚æœ¬ç ”ç©¶ä¸­çš„å®éªŒåŒ…æ‹¬ï¼šï¼ˆiï¼‰ä»å¤šä¸ªç»„ç»‡çš„è°ƒæŸ¥å’Œç½‘ç«™ä¸­åˆ›å»ºç‰¹å®šé¢†åŸŸçš„è¯­æ–™åº“ï¼Œç”¨äºè®­ç»ƒæ‰€æå‡ºæ¨¡å‹ï¼›ï¼ˆiiï¼‰ä½¿ç”¨å’Œæ¯”è¾ƒå¤šç§AIæ–¹æ³•ï¼›ä»¥åŠï¼ˆiiiï¼‰ä½¿ç”¨å®è¯æ•°æ®éªŒè¯è¯¥æ–¹æ³•ã€‚é›†æˆè¯¸å¦‚ç‰©è”ç½‘ã€ä¼ æ„Ÿå™¨ç½‘ç»œå’ŒåŸºäºAIçš„åˆ†ææŠ€æœ¯ç­‰æŠ€æœ¯å¯ä»¥æ˜¾è‘—æ”¯æŒå…·æœ‰éŸ§æ€§å’Œæ•æ·æ€§çš„åŸå¸‚ç¯å¢ƒï¼Œå¹¶å®ç°æ›´æœ‰æ•ˆå’Œå¯æŒç»­çš„æ™ºèƒ½åŸå¸‚æ¨¡å‹ã€‚ 

---
# Localizing Adversarial Attacks To Produces More Imperceptible Noise 

**Title (ZH)**: å®šä½ adversarial æ”»å‡»ä»¥ç”Ÿæˆæ›´å…·ä¸å¯æ„ŸçŸ¥æ€§çš„å™ªå£° 

**Authors**: Pavan Reddy, Aditya Sanjay Gujral  

**Link**: [PDF](https://arxiv.org/pdf/2509.22710)  

**Abstract**: Adversarial attacks in machine learning traditionally focus on global perturbations to input data, yet the potential of localized adversarial noise remains underexplored. This study systematically evaluates localized adversarial attacks across widely-used methods, including FGSM, PGD, and C&W, to quantify their effectiveness, imperceptibility, and computational efficiency. By introducing a binary mask to constrain noise to specific regions, localized attacks achieve significantly lower mean pixel perturbations, higher Peak Signal-to-Noise Ratios (PSNR), and improved Structural Similarity Index (SSIM) compared to global attacks. However, these benefits come at the cost of increased computational effort and a modest reduction in Attack Success Rate (ASR). Our results highlight that iterative methods, such as PGD and C&W, are more robust to localization constraints than single-step methods like FGSM, maintaining higher ASR and imperceptibility metrics. This work provides a comprehensive analysis of localized adversarial attacks, offering practical insights for advancing attack strategies and designing robust defensive systems. 

**Abstract (ZH)**: å±€éƒ¨å¯¹æŠ—æ”»å‡»åœ¨æœºå™¨å­¦ä¹ ä¸­çš„ä¼ ç»Ÿç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è¾“å…¥æ•°æ®çš„å…¨å±€æ‰°åŠ¨ï¼Œè€Œå±€éƒ¨å¯¹æŠ—å™ªå£°çš„åº”ç”¨æ½œåŠ›å°šæœªå……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†å¹¿æ³›ä½¿ç”¨çš„FGSMã€PGDå’ŒC&Wç­‰æ–¹æ³•çš„å±€éƒ¨å¯¹æŠ—æ”»å‡»ï¼Œä»¥é‡åŒ–å…¶æœ‰æ•ˆæ€§ã€ä¸å¯æ„ŸçŸ¥æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚é€šè¿‡å¼•å…¥äºŒè¿›åˆ¶æ©ç é™åˆ¶å™ªå£°åˆ°ç‰¹å®šåŒºåŸŸï¼Œå±€éƒ¨æ”»å‡»å®ç°äº†æ˜¾è‘—æ›´ä½çš„å¹³å‡åƒç´ æ‰°åŠ¨ã€æ›´é«˜çš„å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰å’Œæ”¹è¿›çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼ˆSSIMï¼‰ï¼Œä½†è¿™äº›ä¼˜åŠ¿ä¼´éšç€è®¡ç®—åŠªåŠ›å¢åŠ ä»¥åŠè½»å¾®çš„æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ä¸‹é™ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè¿­ä»£æ–¹æ³•å¦‚PGDå’ŒC&Wå¯¹å±€éƒ¨åŒ–çº¦æŸæ›´ä¸º robustï¼Œä¿æŒäº†è¾ƒé«˜çš„ASRå’Œä¸å¯æ„ŸçŸ¥æ€§ã€‚æœ¬ç ”ç©¶ä¸ºå±€éƒ¨å¯¹æŠ—æ”»å‡»æä¾›äº†å…¨é¢åˆ†æï¼Œä¸ºæ”»å‡»ç­–ç•¥çš„æ”¹è¿›å’Œè®¾è®¡ robust é˜²å¾¡ç³»ç»Ÿæä¾›äº†å®ç”¨è§è§£ã€‚ 

---
# Intelligent Load Balancing in Cloud Computer Systems 

**Title (ZH)**: äº‘è®¡ç®—æœºç³»ç»Ÿä¸­çš„æ™ºèƒ½è´Ÿè½½å‡è¡¡ 

**Authors**: Leszek Sliwko  

**Link**: [PDF](https://arxiv.org/pdf/2509.22704)  

**Abstract**: Cloud computing is an established technology allowing users to share resources on a large scale, never before seen in IT history. A cloud system connects multiple individual servers in order to process related tasks in several environments at the same time. Clouds are typically more cost-effective than single computers of comparable computing performance. The sheer physical size of the system itself means that thousands of machines may be involved. The focus of this research was to design a strategy to dynamically allocate tasks without overloading Cloud nodes which would result in system stability being maintained at minimum cost. This research has added the following new contributions to the state of knowledge: (i) a novel taxonomy and categorisation of three classes of schedulers, namely OS-level, Cluster and Big Data, which highlight their unique evolution and underline their different objectives; (ii) an abstract model of cloud resources utilisation is specified, including multiple types of resources and consideration of task migration costs; (iii) a virtual machine live migration was experimented with in order to create a formula which estimates the network traffic generated by this process; (iv) a high-fidelity Cloud workload simulator, based on a month-long workload traces from Google's computing cells, was created; (v) two possible approaches to resource management were proposed and examined in the practical part of the manuscript: the centralised metaheuristic load balancer and the decentralised agent-based system. The project involved extensive experiments run on the University of Westminster HPC cluster, and the promising results are presented together with detailed discussions and a conclusion. 

**Abstract (ZH)**: äº‘è®¡ç®—æ˜¯ä¸€ç§å·²ç¡®ç«‹çš„æŠ€æœ¯ï¼Œå…è®¸ç”¨æˆ·å¤§è§„æ¨¡å…±äº«èµ„æºï¼Œè¿™åœ¨ITå²ä¸Šå‰æ‰€æœªè§ã€‚äº‘ç³»ç»Ÿè¿æ¥å¤šä¸ªç‹¬ç«‹æœåŠ¡å™¨ï¼Œä»¥ä¾¿åœ¨åŒä¸€æ—¶é—´å¤„ç†å¤šä¸ªç¯å¢ƒä¸­çš„ç›¸å…³ä»»åŠ¡ã€‚ä¸æ€§èƒ½ç›¸å½“çš„å•å°è®¡ç®—æœºç›¸æ¯”ï¼Œäº‘ç³»ç»Ÿé€šå¸¸æ›´å…·æˆæœ¬æ•ˆç›Šã€‚ç³»ç»Ÿçš„ç‰©ç†è§„æ¨¡å·¨å¤§ï¼Œæ„å‘³ç€å¯èƒ½æ¶‰åŠæˆåƒä¸Šä¸‡å°æœºå™¨ã€‚æœ¬ç ”ç©¶çš„é‡ç‚¹æ˜¯è®¾è®¡ä¸€ç§ç­–ç•¥ï¼Œä»¥åŠ¨æ€åˆ†é…ä»»åŠ¡è€Œä¸ overloaded äº‘èŠ‚ç‚¹ï¼Œä»è€Œåœ¨æœ€å°æˆæœ¬ä¸‹ç»´æŒç³»ç»Ÿç¨³å®šæ€§ã€‚æœ¬ç ”ç©¶ä¸ºç°æœ‰çŸ¥è¯†å¢æ·»äº†ä»¥ä¸‹æ–°è´¡çŒ®ï¼šï¼ˆiï¼‰æå‡ºäº†ä¸€ç§æ–°é¢–çš„è°ƒåº¦å™¨åˆ†ç±»æ³•ï¼ŒåŒ…æ‹¬OSçº§ã€é›†ç¾¤å’Œå¤§æ•°æ®ä¸‰ç±»ï¼Œçªæ˜¾äº†å®ƒä»¬çš„ç‹¬ç‰¹æ¼”åŒ–å†ç¨‹å¹¶å¼ºè°ƒäº†å®ƒä»¬çš„ä¸åŒç›®æ ‡ï¼›ï¼ˆiiï¼‰è§„å®šäº†ä¸€ä¸ªäº‘èµ„æºåˆ©ç”¨çš„æŠ½è±¡æ¨¡å‹ï¼ŒåŒ…æ‹¬å¤šç§ç±»å‹èµ„æºä»¥åŠä»»åŠ¡è¿ç§»æˆæœ¬çš„è€ƒè™‘ï¼›ï¼ˆiiiï¼‰å®éªŒäº†è™šæ‹Ÿæœºåœ¨çº¿è¿ç§»ï¼Œä»¥åˆ›å»ºä¼°è®¡æ­¤è¿‡ç¨‹äº§ç”Ÿç½‘ç»œæµé‡çš„å…¬å¼ï¼›ï¼ˆivï¼‰åŸºäºè°·æ­Œè®¡ç®—å•å…ƒä¸€ä¸ªæœˆçš„å·¥ä½œè´Ÿè½½è¿½è¸ªï¼Œåˆ›å»ºäº†ä¸€ä¸ªé«˜ä¿çœŸåº¦çš„äº‘å·¥ä½œè´Ÿè½½æ¨¡æ‹Ÿå™¨ï¼›ï¼ˆvï¼‰åœ¨æ‰‹ç¨¿çš„å®è·µéƒ¨åˆ†æå‡ºäº†ä¸¤ç§èµ„æºç®¡ç†æ–¹æ³•ï¼šé›†ä¸­å¼çš„å…ƒå¯å‘å¼è´Ÿè½½å‡è¡¡å™¨å’Œå»ä¸­å¿ƒåŒ–çš„åŸºäºä»£ç†çš„ç³»ç»Ÿã€‚è¯¥é¡¹ç›®åœ¨å¨æ–¯æ•æ–¯ç‰¹å¤§å­¦é«˜æ€§èƒ½è®¡ç®—é›†ç¾¤ä¸Šè¿›è¡Œäº†å¤§é‡çš„å®éªŒï¼Œå±•ç¤ºäº†ä»¤äººé¼“èˆçš„ç»“æœï¼Œå¹¶é™„æœ‰è¯¦ç»†çš„è®¨è®ºå’Œç»“è®ºã€‚ 

---
# Enhancing Cluster Scheduling in HPC: A Continuous Transfer Learning for Real-Time Optimization 

**Title (ZH)**: å¢å¼ºé«˜æ€§èƒ½è®¡ç®—ä¸­çš„èšç±»è°ƒåº¦ï¼šä¸€ç§å®æ—¶ä¼˜åŒ–çš„è¿ç»­è¿ç§»å­¦ä¹  

**Authors**: Leszek Sliwko, Jolanta Mizera-Pietraszko  

**Link**: [PDF](https://arxiv.org/pdf/2509.22701)  

**Abstract**: This study presents a machine learning-assisted approach to optimize task scheduling in cluster systems, focusing on node-affinity constraints. Traditional schedulers like Kubernetes struggle with real-time adaptability, whereas the proposed continuous transfer learning model evolves dynamically during operations, minimizing retraining needs. Evaluated on Google Cluster Data, the model achieves over 99% accuracy, reducing computational overhead and improving scheduling latency for constrained tasks. This scalable solution enables real-time optimization, advancing machine learning integration in cluster management and paving the way for future adaptive scheduling strategies. 

**Abstract (ZH)**: åŸºäºæœºå™¨å­¦ä¹ è¾…åŠ©çš„æ–¹æ³•åœ¨ç¾¤é›†ç³»ç»Ÿä¸­ä¼˜åŒ–ä»»åŠ¡è°ƒåº¦ï¼Œå…³æ³¨èŠ‚ç‚¹äº²å’Œæ€§çº¦æŸ 

---
# Learning Hyperspectral Images with Curated Text Prompts for Efficient Multimodal Alignment 

**Title (ZH)**: ä½¿ç”¨ç²¾é€‰æ–‡æœ¬æç¤ºå­¦ä¹ è¶…å…‰è°±å›¾åƒä»¥å®ç°é«˜æ•ˆçš„å¤šæ¨¡æ€å¯¹é½ 

**Authors**: Abhiroop Chatterjee, Susmita Ghosh  

**Link**: [PDF](https://arxiv.org/pdf/2509.22697)  

**Abstract**: As data requirements continue to grow, efficient learning increasingly depends on the curation and distillation of high-value data rather than brute-force scaling of model sizes. In the case of a hyperspectral image (HSI), the challenge is amplified by the high-dimensional 3D voxel structure, where each spatial location is associated with hundreds of contiguous spectral channels. While vision and language models have been optimized effectively for natural image or text tasks, their cross-modal alignment in the hyperspectral domain remains an open and underexplored problem. In this article, we make an attempt to optimize a Vision-Language Model (VLM) for hyperspectral scene understanding by exploiting a CLIP-style contrastive training framework. Our framework maps voxel-level embeddings from a vision backbone onto the latent space of a frozen large embedding model (LEM), where a trainable probe aligns vision features with the model's textual token representations. The two modalities are aligned via a contrastive loss restricted to a curated set of hard (closest wrong classes) and semi-hard (random distractors) negatives, along with positive pairs. To further enhance alignment, descriptive prompts that encode class semantics are introduced and act as structured anchors for the HSI embeddings. It is seen that the proposed method updates only 0.07 percent of the total parameters, yet yields state-of-the-art performance. For example, on Indian Pines (IP) the model produces better results over unimodal and multimodal baselines by +0.92 Overall Accuracy (OA) and +1.60 Kappa ($\kappa$), while on Pavia University (PU) data it provides gains of +0.69 OA and +0.90 $\kappa$. Moreover, this is achieved with the set of parameters, nearly 50$\times$ smaller than DCTN and 90$\times$ smaller than SS-TMNet. 

**Abstract (ZH)**: éšç€æ•°æ®éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œé«˜æ•ˆçš„learnè¿‡ç¨‹ increasinglyä¾èµ–äºé«˜è´¨é‡æ•°æ®çš„ç­–åˆ’å’Œæç‚¼ï¼Œè€Œä¸æ˜¯ç®€å•åœ°æ‰©å¤§æ¨¡å‹è§„æ¨¡ã€‚åœ¨é«˜å…‰è°±å›¾åƒï¼ˆHSIï¼‰çš„æƒ…å†µä¸‹ï¼Œç”±äºå…¶é«˜ç»´åº¦çš„3Dä½“ç´ ç»“æ„ï¼Œæ¯ä¸ªç©ºé—´ä½ç½®å…³è”ç€ä¸Šç™¾ä¸ªè¿ç»­çš„å…‰è°±é€šé“ï¼ŒæŒ‘æˆ˜è¿›ä¸€æ­¥æ”¾å¤§ã€‚è™½ç„¶è§†è§‰å’Œè¯­è¨€æ¨¡å‹å·²åœ¨è‡ªç„¶å›¾åƒæˆ–æ–‡æœ¬ä»»åŠ¡ä¸­å¾—åˆ°äº†æœ‰æ•ˆä¼˜åŒ–ï¼Œä½†åœ¨é«˜å…‰è°±åŸŸä¸­çš„è·¨æ¨¡æ€å¯¹é½ä»æ˜¯ä¸€ä¸ªå¼€æ”¾ä¸”æœªå……åˆ†æ¢ç´¢çš„é—®é¢˜ã€‚æœ¬æ–‡å°è¯•é€šè¿‡åˆ©ç”¨CLIPé£æ ¼çš„å¯¹æ¯”è®­ç»ƒæ¡†æ¶ä¼˜åŒ–ä¸€ä¸ªVision-Languageæ¨¡å‹ï¼ˆVLMï¼‰ä»¥è¿›è¡Œé«˜å…‰è°±åœºæ™¯ç†è§£ã€‚è¯¥æ¡†æ¶å°†è§†è§‰ä¸»å¹²çš„ä½“ç´ çº§åµŒå…¥æ˜ å°„åˆ°ä¸€ä¸ªå†»ç»“çš„å¤§åµŒå…¥æ¨¡å‹ï¼ˆLEMï¼‰çš„æ½œåœ¨ç©ºé—´ä¸­ï¼Œå…¶ä¸­å¯è®­ç»ƒçš„æ¢é’ˆå°†è§†è§‰ç‰¹å¾ä¸æ¨¡å‹çš„æ–‡æœ¬æ ‡è®°è¡¨ç¤ºå¯¹é½ã€‚é€šè¿‡é™åˆ¶åœ¨ç­–åˆ’çš„ç¡¬ï¼ˆæœ€æ¥è¿‘çš„é”™è¯¯ç±»åˆ«ï¼‰å’ŒåŠç¡¬ï¼ˆéšæœºåˆ†æ•£è€…ï¼‰è´Ÿæ ·æœ¬é›†å†…çš„å¯¹æ¯”æŸå¤±ï¼Œä»¥åŠæ­£æ ·æœ¬å¯¹ï¼Œä¸¤æ¨¡æ€å¾—ä»¥å¯¹é½ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºå¯¹é½ï¼Œå¼•å…¥äº†æè¿°æ€§æç¤ºä»¥ç¼–ç ç±»åˆ«è¯­ä¹‰ï¼Œä½œä¸ºHSIåµŒå…¥çš„ç»“æ„é”šç‚¹ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä»…æ›´æ–°äº†æ€»å‚æ•°çš„0.07%ï¼Œä½†èƒ½è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨Indian Pinesï¼ˆIPï¼‰æ•°æ®é›†ä¸Šï¼Œæ¨¡å‹ç›¸å¯¹äºå•æ¨¡æ€å’Œå¤šæ¨¡æ€åŸºçº¿æ–¹æ³•åœ¨æ€»ä½“ç²¾åº¦ï¼ˆOAï¼‰ä¸Šæå‡äº†0.92ï¼Œåœ¨å¡å¸•ç³»æ•°ï¼ˆ$\kappa$ï¼‰ä¸Šæå‡äº†1.60ï¼›è€Œåœ¨Pavia Universityï¼ˆPUï¼‰æ•°æ®é›†ä¸Šï¼Œæ¨¡å‹æä¾›äº†0.69çš„OAå’Œ0.90çš„$\kappa$çš„æå‡ã€‚æ­¤å¤–ï¼Œè¿™å®ç°äº†å‚æ•°é‡å‡ ä¹æ˜¯DCTNçš„50å€å°‘ï¼ŒSS-TMNetçš„90å€å°‘ã€‚ 

---
# PISA: An AI Pipeline for Interpretable-by-design Survival Analysis Providing Multiple Complexity-Accuracy Trade-off Models 

**Title (ZH)**: PISAï¼šä¸€ç§ç”¨äºå¯è§£é‡Šè®¾è®¡ç”Ÿå­˜åˆ†æçš„äººå·¥æ™ºèƒ½ç®¡é“ï¼Œæä¾›å¤šç§å¤æ‚æ€§-å‡†ç¡®æ€§trade-offæ¨¡å‹ 

**Authors**: Thalea Schlender, Catharina J.A. Romme, Yvette M. van der Linden, Luc R.C.W. van Lonkhuijzen, Peter A.N. Bosman, Tanja Alderliesten  

**Link**: [PDF](https://arxiv.org/pdf/2509.22673)  

**Abstract**: Survival analysis is central to clinical research, informing patient prognoses, guiding treatment decisions, and optimising resource allocation. Accurate time-to-event predictions not only improve quality of life but also reveal risk factors that shape clinical practice. For these models to be relevant in healthcare, interpretability is critical: predictions must be traceable to patient-specific characteristics, and risk factors should be identifiable to generate actionable insights for both clinicians and researchers. Traditional survival models often fail to capture non-linear interactions, while modern deep learning approaches, though powerful, are limited by poor interpretability.
We propose a Pipeline for Interpretable Survival Analysis (PISA) - a pipeline that provides multiple survival analysis models that trade off complexity and performance. Using multiple-feature, multi-objective feature engineering, PISA transforms patient characteristics and time-to-event data into multiple survival analysis models, providing valuable insights into the survival prediction task. Crucially, every model is converted into simple patient stratification flowcharts supported by Kaplan-Meier curves, whilst not compromising on performance. While PISA is model-agnostic, we illustrate its flexibility through applications of Cox regression and shallow survival trees, the latter avoiding proportional hazards assumptions.
Applied to two clinical benchmark datasets, PISA produced interpretable survival models and intuitive stratification flowcharts whilst achieving state-of-the-art performances. Revisiting a prior departmental study further demonstrated its capacity to automate survival analysis workflows in real-world clinical research. 

**Abstract (ZH)**: å¯è§£é‡Šç”Ÿå­˜åˆ†æç®¡é“ï¼ˆPISAï¼‰ï¼šä¸€ç§æƒè¡¡å¤æ‚æ€§å’Œæ€§èƒ½çš„å¤šæ¨¡å‹ç®¡é“ 

---
# Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding 

**Title (ZH)**: åŸºäºå¤šæ¨¡æ€æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥çš„ä¸‹ä¸€ä¸ªç‚¹Interestæ¨èæ¨¡å‹ 

**Authors**: Lingyu Zhang, Guobin Wu, Yan Wang, Pengfei Xu, Jian Liang, Xuan Song, Yunhai Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.22661)  

**Abstract**: The next Point-of-interest (POI) recommendation is mainly based on sequential traffic information to predict the user's next boarding point location. This is a highly regarded and widely applied research task in the field of intelligent transportation, and there have been many research results to date. Traditional POI prediction models primarily rely on short-term traffic sequence information, often neglecting both long-term and short-term preference data, as well as crucial spatiotemporal context features in user behavior. To address this issue, this paper introduces user long-term preference information and key spatiotemporal context information, and proposes a POI recommendation model based on multimodal spatiotemporal context feature embedding. The model extracts long-term preference features and key spatiotemporal context features from traffic data through modules such as spatiotemporal feature processing, multimodal embedding, and self-attention aggregation. It then uses a weighted fusion method to dynamically adjust the weights of long-term and short-term features based on users' historical behavior patterns and the current context. Finally, the fused features are matched using attention, and the probability of each location candidate becoming the next location is calculated. This paper conducts experimental verification on multiple transportation datasets, and the results show that the POI prediction model combining multiple types of features has higher prediction accuracy than existing SOTA models and methods. 

**Abstract (ZH)**: åŸºäºå¤šæ¨¡æ€æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥çš„POIæ¨èæ–¹æ³• 

---
# Fairness for niche users and providers: algorithmic choice and profile portability 

**Title (ZH)**: ä¸º niche ç”¨æˆ·å’Œä¾›åº”å•†æä¾›å…¬å¹³æ€§ï¼šç®—æ³•é€‰æ‹©ä¸èµ„æ–™æ¡£æ¡ˆç§»æ¤ 

**Authors**: Elizabeth McKinnie, Anas Buhayh, Clement Canel, Robin Burke  

**Link**: [PDF](https://arxiv.org/pdf/2509.22660)  

**Abstract**: Ensuring fair outcomes for multiple stakeholders in recommender systems has been studied mostly in terms of algorithmic interventions: building new models with better fairness properties, or using reranking to improve outcomes from an existing algorithm. What has rarely been studied is structural changes in the recommendation ecosystem itself. Our work explores the fairness impact of algorithmic pluralism, the idea that the recommendation algorithm is decoupled from the platform through which users access content, enabling user choice in algorithms. Prior work using a simulation approach has shown that niche consumers and (especially) niche providers benefit from algorithmic choice. In this paper, we use simulation to explore the question of profile portability, to understand how different policies regarding the handling of user profiles interact with fairness outcomes for consumers and providers. 

**Abstract (ZH)**: ç¡®ä¿æ¨èç³»ç»Ÿä¸­å¤šåˆ©ç›Šç›¸å…³æ–¹çš„å…¬å¹³ç»“æœåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ä»ç®—æ³•å¹²é¢„çš„è§’åº¦è¿›è¡Œç ”ç©¶çš„ï¼šé€šè¿‡æ„å»ºå…·æœ‰è‰¯å¥½å…¬å¹³å±æ€§çš„æ–°æ¨¡å‹ï¼Œæˆ–é€šè¿‡é‡æ–°æ’åºæ¥æ”¹è¿›ç°æœ‰ç®—æ³•çš„ç»“æœæ¥å®ç°ã€‚å¾ˆå°‘ç ”ç©¶çš„æ˜¯æ¨èç”Ÿæ€ç³»ç»Ÿæœ¬èº«çš„ç»“æ„å˜åŒ–ã€‚æˆ‘ä»¬çš„å·¥ä½œæ¢è®¨äº†ç®—æ³•å¤šå…ƒä¸»ä¹‰çš„å…¬å¹³å½±å“ï¼Œå³æ¨èç®—æ³•é€šè¿‡ç”¨æˆ·è®¿é—®å†…å®¹çš„å¹³å°è¿›è¡Œè§£è€¦ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨ç®—æ³•ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚å…ˆå‰çš„å·¥ä½œé€šè¿‡ä»¿çœŸæ–¹æ³•è¡¨æ˜ï¼Œåˆ©åŸºæ¶ˆè´¹è€…å’Œï¼ˆå°¤å…¶æ˜¯ï¼‰åˆ©åŸºæä¾›å•†ä»ç®—æ³•é€‰æ‹©ä¸­å—ç›Šã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¿çœŸæ¥æ¢ç´¢èµ„æ–™æ¡£æ¡ˆå¯æºæ€§çš„é—®é¢˜ï¼Œä»¥äº†è§£ä¸åŒçš„ç”¨æˆ·èµ„æ–™å¤„ç†æ”¿ç­–å¦‚ä½•ä¸æ¶ˆè´¹è€…å’Œæä¾›å•†çš„å…¬å¹³ç»“æœç›¸äº’ä½œç”¨ã€‚ 

---
# GOAT: A Large Dataset of Paired Guitar Audio Recordings and Tablatures 

**Title (ZH)**: GOATï¼šé…å¯¹å‰ä»–éŸ³é¢‘å½•åˆ¶å’Œè°±è¡¨çš„å¤§è§„æ¨¡æ•°æ®é›† 

**Authors**: Jackson Loth, Pedro Sarmento, Saurjya Sarkar, Zixun Guo, Mathieu Barthet, Mark Sandler  

**Link**: [PDF](https://arxiv.org/pdf/2509.22655)  

**Abstract**: In recent years, the guitar has received increased attention from the music information retrieval (MIR) community driven by the challenges posed by its diverse playing techniques and sonic characteristics. Mainly fueled by deep learning approaches, progress has been limited by the scarcity and limited annotations of datasets. To address this, we present the Guitar On Audio and Tablatures (GOAT) dataset, comprising 5.9 hours of unique high-quality direct input audio recordings of electric guitars from a variety of different guitars and players. We also present an effective data augmentation strategy using guitar amplifiers which delivers near-unlimited tonal variety, of which we provide a starting 29.5 hours of audio. Each recording is annotated using guitar tablatures, a guitar-specific symbolic format supporting string and fret numbers, as well as numerous playing techniques. For this we utilise both the Guitar Pro format, a software for tablature playback and editing, and a text-like token encoding. Furthermore, we present competitive results using GOAT for MIDI transcription and preliminary results for a novel approach to automatic guitar tablature transcription. We hope that GOAT opens up the possibilities to train novel models on a wide variety of guitar-related MIR tasks, from synthesis to transcription to playing technique detection. 

**Abstract (ZH)**: è¿‘å¹´æ¥ï¼Œå‰ä»–å› å…¶å¤šæ ·çš„æ¼”å¥æŠ€å·§å’ŒéŸ³è‰²ç‰¹æ€§ï¼Œå—åˆ°éŸ³ä¹ä¿¡æ¯æ£€ç´¢ï¼ˆMIRï¼‰ç¤¾åŒºçš„è¶Šæ¥è¶Šå¤šå…³æ³¨ã€‚ä¸»è¦å€ŸåŠ©æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œè¿›å±•å—é™äºæ•°æ®é›†ç¨€ç¼ºä¸”æ ‡æ³¨ä¸è¶³ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å‰ä»–éŸ³é¢‘å’Œè°±è¡¨æ•°æ®é›†ï¼ˆGuitar On Audio and Tablatures, GOATï¼‰ï¼ŒåŒ…å«5.9å°æ—¶å¤šç§å‰ä»–å’Œæ¼”å¥è€…ç‹¬ç‰¹é«˜è´¨é‡çš„ç›´æ¥è¾“å…¥éŸ³é¢‘ recordingsã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œåˆ©ç”¨å‰ä»–æ”¾å¤§å™¨äº§ç”Ÿè¿‘ä¹æ— é™çš„éŸ³è‰²å˜åŒ–ï¼Œæä¾›äº†åˆå§‹çš„29.5å°æ—¶éŸ³é¢‘ã€‚æ¯ä¸ªå½•éŸ³ä½¿ç”¨å‰ä»–è°±è¡¨è¿›è¡Œäº†æ ‡æ³¨ï¼Œè¿™æ˜¯æ”¯æŒç´å¼¦å’Œå“æŒ‰é”®å·ç çš„å‰ä»–ä¸“ç”¨ç¬¦å·æ ¼å¼ï¼Œä»¥åŠä¼—å¤šæ¼”å¥æŠ€å·§ã€‚æˆ‘ä»¬åˆ©ç”¨å‰æ™®ç”Ÿè½¯ä»¶ï¼ˆGuitar Proï¼‰è¿›è¡Œè°±è¡¨æ’­æ”¾å’Œç¼–è¾‘ï¼Œå¹¶é‡‡ç”¨ç±»ä¼¼æ–‡æœ¬çš„æ ‡è®°ç¼–ç ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨MIDIè½¬å½•ä»»åŠ¡ä¸­ä½¿ç”¨GOATçš„ç«äº‰æ€§ç»“æœï¼Œå¹¶ä»‹ç»äº†è‡ªåŠ¨å‰ä»–è°±è¡¨è½¬å½•çš„æ–°é¢–æ–¹æ³•çš„åˆæ­¥ç»“æœã€‚æˆ‘ä»¬å¸Œæœ›GOATèƒ½å¤Ÿå¼€å¯é’ˆå¯¹å‰ä»–ç›¸å…³MIRä»»åŠ¡çš„æ–°å‹æ¨¡å‹è®­ç»ƒçš„å¯èƒ½æ€§ï¼Œä»åˆæˆåˆ°è½¬å½•å†åˆ°æ¼”å¥æŠ€å·§æ£€æµ‹ã€‚ 

---
# Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI 

**Title (ZH)**: åŸºäºRISè¾…åŠ©æ¯«ç±³æ³¢MIMOç³»ç»Ÿçš„å¯æŒç»­LSTMåŸºé¢„ç¼–ç æ–¹æ³•ï¼šéšå¼CSIæƒ…å½¢ 

**Authors**: Po-Heng Chou, Jiun-Jia Wu, Wan-Jen Huang, Ronald Y. Chang  

**Link**: [PDF](https://arxiv.org/pdf/2509.12658)  

**Abstract**: In this paper, we propose a sustainable long short-term memory (LSTM)-based precoding framework for reconfigurable intelligent surface (RIS)-assisted millimeter-wave (mmWave) MIMO systems. Instead of explicit channel state information (CSI) estimation, the framework exploits uplink pilot sequences to implicitly learn channel characteristics, reducing both pilot overhead and inference complexity. Practical hardware constraints are addressed by incorporating the phase-dependent amplitude model of RIS elements, while a multi-label training strategy improves robustness when multiple near-optimal codewords yield comparable performance. Simulations show that the proposed design achieves over 90% of the spectral efficiency of exhaustive search (ES) with only 2.2% of its computation time, cutting energy consumption by nearly two orders of magnitude. The method also demonstrates resilience under distribution mismatch and scalability to larger RIS arrays, making it a practical and energy-efficient solution for sustainable 6G wireless networks. 

**Abstract (ZH)**: åŸºäºå¯é‡æ„æ™ºèƒ½è¡¨é¢è¾…åŠ©æ¯«ç±³æ³¢MIMOç³»ç»Ÿçš„å¯æŒç»­é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰é¢„ç¼–ç æ¡†æ¶ 

---
# How are Scientific Concepts Birthed? Typing Rules of Concept Formation in Theoretical Physics Reasoning 

**Title (ZH)**: ç§‘å­¦æ¦‚å¿µæ˜¯å¦‚ä½•è¯ç”Ÿçš„ï¼Ÿç†è®ºç‰©ç†å­¦æ¨ç†ä¸­æ¦‚å¿µå½¢æˆçš„åŸºæœ¬è§„åˆ™ 

**Authors**: Omar Aguilar, Anthony Aguirre  

**Link**: [PDF](https://arxiv.org/pdf/2509.10740)  

**Abstract**: This work aims to formalize some of the ways scientific concepts are formed in the process of theoretical physics discovery. Since this may at first seem like a task beyond the scope of the exact sciences (natural and formal sciences), we begin by presenting arguments for why scientific concept formation can be formalized. Then, we introduce type theory as a natural and well-suited framework for this formalization. We formalize what we call "ways of discovering new concepts" including concept distinction, property preservation, and concept change, as cognitive typing rules. Next, we apply these cognitive typing rules to two case studies of conceptual discovery in the history of physics: Einstein's reasoning leading to the impossibility of frozen waves, and his conceptual path to the relativity of time. In these historical episodes, we recast what a physicist might informally call "ways of discovering new scientific concepts" as compositional typing rules built from cognitive typing rules - thus formalizing them as scientific discovery mechanisms. Lastly, we computationally model the type-theoretic reconstruction of Einstein's conceptual path to the relativity of time as a program synthesis task. 

**Abstract (ZH)**: æœ¬ç ”ç©¶æ—¨åœ¨å½¢å¼åŒ–ç†è®ºç‰©ç†å‘ç°è¿‡ç¨‹ä¸­å½¢æˆç§‘å­¦æ¦‚å¿µçš„ä¸€äº›æ–¹å¼ã€‚è™½ç„¶è¿™å¯èƒ½æœ€åˆçœ‹èµ·æ¥è¶…å‡ºäº†ç²¾ç¡®ç§‘å­¦ï¼ˆè‡ªç„¶ç§‘å­¦å’Œå½¢å¼ç§‘å­¦ï¼‰çš„èŒƒç•´ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡è®ºè¿°ç§‘å­¦æ¦‚å¿µå½¢æˆå¯ä»¥å½¢å¼åŒ–çš„ç†ç”±æ¥å¼€å§‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¼•å…¥ç±»å‹ç†è®ºä½œä¸ºè‡ªç„¶ä¸”åˆé€‚çš„æ¡†æ¶æ¥è¿›è¡Œè¿™ç§å½¢å¼åŒ–ã€‚æˆ‘ä»¬å°†â€œå‘ç°æ–°æ¦‚å¿µçš„æ–¹å¼â€å½¢å¼åŒ–ï¼ŒåŒ…æ‹¬æ¦‚å¿µåŒºåˆ†ã€å±æ€§ä¿å­˜å’Œæ¦‚å¿µå˜åŒ–ï¼Œä½œä¸ºè®¤çŸ¥ç±»å‹è§„åˆ™ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åº”ç”¨è¿™äº›è®¤çŸ¥ç±»å‹è§„åˆ™å¯¹ç‰©ç†å­¦å²ä¸Šä¸¤ä¸ªæ¦‚å¿µå‘ç°æ¡ˆä¾‹è¿›è¡Œç ”ç©¶ï¼šçˆ±å› æ–¯å¦å¯¼è‡´æ— æ³•å­˜åœ¨å†»ç»“æ³¢çš„æ¨ç†è¿‡ç¨‹ï¼Œä»¥åŠä»–å¯¹æ—¶é—´ç›¸å¯¹æ€§çš„æ¦‚å¿µè·¯å¾„ã€‚åœ¨è¿™äº›å†å²äº‹ä»¶ä¸­ï¼Œæˆ‘ä»¬å°†ç‰©ç†å­¦å®¶å¯èƒ½éæ­£å¼ç§°ä¹‹ä¸ºâ€œå‘ç°æ–°ç§‘å­¦æ¦‚å¿µçš„æ–¹å¼â€é‡æ–°è¡¨è¿°ä¸ºç”±è®¤çŸ¥ç±»å‹è§„åˆ™æ„å»ºçš„ç»„åˆç±»å‹è§„åˆ™ï¼Œä»è€Œå°†å®ƒä»¬å½¢å¼åŒ–ä¸ºç§‘å­¦å‘ç°æœºåˆ¶ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡ç¨‹åºåˆæˆä»»åŠ¡æ¥è®¡ç®—å»ºæ¨¡çˆ±å› æ–¯å¦ä»æ¦‚å¿µè·¯å¾„åˆ°æ—¶é—´ç›¸å¯¹æ€§çš„ç±»å‹è®ºé‡æ„ã€‚ 

---
# Green Learning for STAR-RIS mmWave Systems with Implicit CSI 

**Title (ZH)**: ç»¿è”å­¦ä¹ åœ¨IMCSIçš„STAR-RISæ¯«ç±³æ³¢ç³»ç»Ÿä¸­ 

**Authors**: Yu-Hsiang Huang, Po-Heng Chou, Wan-Jen Huang, Walid Saad, C.-C. Jay Kuo  

**Link**: [PDF](https://arxiv.org/pdf/2509.06820)  

**Abstract**: In this paper, a green learning (GL)-based precoding framework is proposed for simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided millimeter-wave (mmWave) MIMO broadcasting systems. Motivated by the growing emphasis on environmental sustainability in future 6G networks, this work adopts a broadcasting transmission architecture for scenarios where multiple users share identical information, improving spectral efficiency and reducing redundant transmissions and power consumption. Different from conventional optimization methods, such as block coordinate descent (BCD) that require perfect channel state information (CSI) and iterative computation, the proposed GL framework operates directly on received uplink pilot signals without explicit CSI estimation. Unlike deep learning (DL) approaches that require CSI-based labels for training, the proposed GL approach also avoids deep neural networks and backpropagation, leading to a more lightweight design. Although the proposed GL framework is trained with supervision generated by BCD under full CSI, inference is performed in a fully CSI-free manner. The proposed GL integrates subspace approximation with adjusted bias (Saab), relevant feature test (RFT)-based supervised feature selection, and eXtreme gradient boosting (XGBoost)-based decision learning to jointly predict the STAR-RIS coefficients and transmit precoder. Simulation results show that the proposed GL approach achieves competitive spectral efficiency compared to BCD and DL-based models, while reducing floating-point operations (FLOPs) by over four orders of magnitude. These advantages make the proposed GL approach highly suitable for real-time deployment in energy- and hardware-constrained broadcasting scenarios. 

**Abstract (ZH)**: åŸºäºç»¿è‰²å­¦ä¹ çš„STAR-RISè¾…åŠ©æ¯«ç±³æ³¢MIMOå¹¿æ’­ç³»ç»ŸåŒæ—¶ä¼ è¾“ä¸åå°„æ¡†æ¶ 

---
# BenLOC: A Benchmark for Learning to Configure MIP Optimizers 

**Title (ZH)**: BenLOC: ä¸€ä¸ªå­¦ä¹ é…ç½®MIPä¼˜åŒ–å™¨çš„æ ‡å‡†æ•°æ®é›† 

**Authors**: Hongpei Li, Ziyan He, Yufei Wang, Wenting Tu, Shanwen Pu, Qi Deng, Dongdong Ge  

**Link**: [PDF](https://arxiv.org/pdf/2506.02752)  

**Abstract**: The automatic configuration of Mixed-Integer Programming (MIP) optimizers has become increasingly critical as the large number of configurations can significantly affect solver performance. Yet the lack of standardized evaluation frameworks has led to data leakage and over-optimistic claims, as prior studies often rely on homogeneous datasets and inconsistent experimental setups. To promote a fair evaluation process, we present BenLOC, a comprehensive benchmark and open-source toolkit, which not only offers an end-to-end pipeline for learning instance-wise MIP optimizer configurations, but also standardizes dataset selection, train-test splits, feature engineering and baseline choice for unbiased and comprehensive evaluations. Leveraging this framework, we conduct an empirical analysis on five well-established MIP datasets and compare classical machine learning models with handcrafted features against state-of-the-art deep-learning techniques. The results demonstrate the importance of datasets, features and baseline criteria proposed by BenLOC and the effectiveness of BenLOC in providing unbiased and comprehensive evaluations. 

**Abstract (ZH)**: Mixed-Integer Programming (MIP) ä¼˜åŒ–å™¨çš„è‡ªåŠ¨é…ç½®å·²æˆä¸ºè¶Šæ¥è¶Šå…³é”®çš„é—®é¢˜ï¼Œå› ä¸ºå¤§é‡é…ç½®ä¼šæ˜¾è‘—å½±å“æ±‚è§£å™¨æ€§èƒ½ã€‚ç„¶è€Œï¼Œç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°æ¡†æ¶å¯¼è‡´äº†æ•°æ®æ³„æ¼å’Œè¿‡äºä¹è§‚çš„å£°æ˜ï¼Œæ­¤å‰çš„ç ”ç©¶ç»å¸¸ä¾èµ–åŒè´¨æ•°æ®é›†å’Œä¸ä¸€è‡´çš„å®éªŒè®¾ç½®ã€‚ä¸ºäº†ä¿ƒè¿›å…¬å¹³çš„è¯„ä¼°è¿‡ç¨‹ï¼Œæˆ‘ä»¬æå‡º BenLOCï¼Œä¸€ä¸ªå…¨é¢çš„åŸºå‡†å’Œå¼€æºå·¥å…·åŒ…ï¼Œä¸ä»…æä¾›äº†ä¸€ç«™å¼çš„å®ä¾‹çº§ MIP ä¼˜åŒ–å™¨é…ç½®å­¦ä¹ ç®¡é“ï¼Œè¿˜å¯¹æ•°æ®é›†é€‰æ‹©ã€è®­ç»ƒ-æµ‹è¯•åˆ†å‰²ã€ç‰¹å¾å·¥ç¨‹å’ŒåŸºå‡†é€‰æ‹©è¿›è¡Œäº†æ ‡å‡†åŒ–ï¼Œä»¥å®ç°æ— åä¸”å…¨é¢çš„è¯„ä¼°ã€‚åˆ©ç”¨è¿™ä¸€æ¡†æ¶ï¼Œæˆ‘ä»¬åœ¨äº”ä¸ªå¹¿æ³›è®¤å¯çš„ MIP æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®è¯åˆ†æï¼Œå¹¶å°†ç»å…¸çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸æ‰‹å·¥è®¾è®¡çš„ç‰¹å¾ä¸æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯è¿›è¡Œäº†å¯¹æ¯”ã€‚ç»“æœè¡¨æ˜ï¼ŒBenLOC æå‡ºçš„æ•°æ®é›†ã€ç‰¹å¾å’ŒåŸºå‡†æ ‡å‡†çš„é‡è¦æ€§ï¼Œä»¥åŠ BenLOC åœ¨æä¾›æ— åä¸”å…¨é¢è¯„ä¼°æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ 

---
# Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via In-Context Learning 

**Title (ZH)**: é€‚ç”¨äºé›¶æ ·æœ¬è¯­éŸ³è½¬æ¢çš„åŸºäºä¸Šä¸‹æ–‡å­¦ä¹ çš„è¯­è°ƒè‡ªé€‚åº”éŸ³é¢‘ç¼–è§£ç å™¨ 

**Authors**: Junchuan Zhao, Xintong Wang, Ye Wang  

**Link**: [PDF](https://arxiv.org/pdf/2505.15402)  

**Abstract**: Recent advances in discrete audio codecs have significantly improved speech representation modeling, while codec language models have enabled in-context learning for zero-shot speech synthesis. Inspired by this, we propose a voice conversion (VC) model within the VALLE-X framework, leveraging its strong in-context learning capabilities for speaker adaptation. To enhance prosody control, we introduce a prosody-aware audio codec encoder (PACE) module, which isolates and refines prosody from other sources, improving expressiveness and control. By integrating PACE into our VC model, we achieve greater flexibility in prosody manipulation while preserving speaker timbre. Experimental evaluation results demonstrate that our approach outperforms baseline VC systems in prosody preservation, timbre consistency, and overall naturalness, surpassing baseline VC systems. 

**Abstract (ZH)**: æœ€è¿‘åœ¨ç¦»æ•£éŸ³é¢‘ç¼–è§£ç å™¨æ–¹é¢çš„è¿›å±•æ˜¾è‘—æ”¹å–„äº†è¯­éŸ³è¡¨ç¤ºå»ºæ¨¡ï¼Œè€Œç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹ä½¿é›¶-shotè¯­éŸ³åˆæˆå…·å¤‡äº†ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»“åˆåœ¨VALLE-Xæ¡†æ¶å†…çš„è¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰æ¨¡å‹ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›è¿›è¡Œè¯´è¯äººé€‚åº”ã€‚ä¸ºäº†å¢å¼ºè¯­è°ƒæ§åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ„ŸçŸ¥è¯­è°ƒçš„éŸ³é¢‘ç¼–è§£ç å™¨ç¼–ç å™¨ï¼ˆPACEï¼‰æ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿå­¤ç«‹å¹¶ç²¾ç‚¼è¯­è°ƒä»¥æ”¹å–„è¡¨è¾¾æ€§å’Œæ§åˆ¶æ€§ã€‚é€šè¿‡å°†PACEé›†æˆåˆ°æˆ‘ä»¬çš„VCæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬åœ¨ä¿æŒè¯´è¯äººéŸ³è‰²çš„åŒæ—¶å®ç°äº†æ›´çµæ´»çš„è¯­è°ƒæ“æ§ã€‚å®éªŒè¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¯­è°ƒä¿æŒã€éŸ³è‰²ä¸€è‡´æ€§åŠæ€»ä½“è‡ªç„¶åº¦æ–¹é¢å‡ä¼˜äºåŸºçº¿VCç³»ç»Ÿï¼Œè¶…è¶Šäº†åŸºçº¿VCç³»ç»Ÿã€‚ 

---
