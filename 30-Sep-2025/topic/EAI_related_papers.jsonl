{'arxiv_id': 'arXiv:2509.25124', 'title': 'Safe Planning in Unknown Environments using Conformalized Semantic Maps', 'authors': 'David Smith Sundarsingh, Yifei Li, Tianji Tang, George J. Pappas, Nikolay Atanasov, Yiannis Kantaros', 'link': 'https://arxiv.org/abs/2509.25124', 'abstract': 'This paper addresses semantic planning problems in unknown environments under perceptual uncertainty. The environment contains multiple unknown semantically labeled regions or objects, and the robot must reach desired locations while maintaining class-dependent distances from them. We aim to compute robot paths that complete such semantic reach-avoid tasks with user-defined probability despite uncertain perception. Existing planning algorithms either ignore perceptual uncertainty - thus lacking correctness guarantees - or assume known sensor models and noise characteristics. In contrast, we present the first planner for semantic reach-avoid tasks that achieves user-specified mission completion rates without requiring any knowledge of sensor models or noise. This is enabled by quantifying uncertainty in semantic maps - constructed on-the-fly from perceptual measurements - using conformal prediction in a model- and distribution-free manner. We validate our approach and the theoretical mission completion rates through extensive experiments, showing that it consistently outperforms baselines in mission success rates.', 'abstract_zh': '本文探讨了感知不确定性下未知环境中的语义规划问题。环境中包含多个未知语义标记的区域或物体，机器人必须到达目标位置并保持类相关的距离。我们的目标是在用户定义的概率下，尽管存在感知不确定性，仍能计算出完成此类语义接近避免任务的机器人路径。现有的规划算法要么忽视感知不确定性，从而缺乏正确性保证，要么假设已知传感器模型和噪声特性。相比之下，我们提出了第一个在无需任何传感器模型或噪声知识的情况下，实现用户指定的任务完成率的语义接近避免任务规划器。这得益于通过在无模型和无分布的前提下，使用自适应预测对从感知测量动态构建的语义地图中的不确定性进行量化。我们通过大量的实验验证了该方法和理论的任务完成率，并且表明它在任务成功率上始终优于基线方法。', 'title_zh': '在未知环境中基于可信语义地图的安全规划'}
{'arxiv_id': 'arXiv:2509.25097', 'title': 'Curriculum Imitation Learning of Distributed Multi-Robot Policies', 'authors': 'Jesús Roche, Eduardo Sebastián, Eduardo Montijano', 'link': 'https://arxiv.org/abs/2509.25097', 'abstract': 'Learning control policies for multi-robot systems (MRS) remains a major challenge due to long-term coordination and the difficulty of obtaining realistic training data. In this work, we address both limitations within an imitation learning framework. First, we shift the typical role of Curriculum Learning in MRS, from scalability with the number of robots, to focus on improving long-term coordination. We propose a curriculum strategy that gradually increases the length of expert trajectories during training, stabilizing learning and enhancing the accuracy of long-term behaviors. Second, we introduce a method to approximate the egocentric perception of each robot using only third-person global state demonstrations. Our approach transforms idealized trajectories into locally available observations by filtering neighbors, converting reference frames, and simulating onboard sensor variability. Both contributions are integrated into a physics-informed technique to produce scalable, distributed policies from observations. We conduct experiments across two tasks with varying team sizes and noise levels. Results show that our curriculum improves long-term accuracy, while our perceptual estimation method yields policies that are robust to realistic uncertainty. Together, these strategies enable the learning of robust, distributed controllers from global demonstrations, even in the absence of expert actions or onboard measurements.', 'abstract_zh': '基于模仿学习的多机器人系统控制策略学习仍是一项重大挑战，由于长期协调的复杂性和现实训练数据的获取难度。在本工作中，我们在一个模仿学习框架内同时解决了这两个限制。首先，我们将Curriculum Learning在多机器人系统中的典型角色从随着机器人数量增加的可扩展性，转向专注于改善长期协调。我们提出了一种渐进增加专家轨迹长度的课程策略，以稳定学习并提高长期行为的准确性。其次，我们引入了一种方法，仅使用第三人称全局状态演示来近似每个机器人的第一人称感知。我们的方法通过过滤邻居、转换参考系和模拟机载传感器的变异性，将理想化的轨迹转化为局部可用的观察。这两项贡献被集成到一个基于物理的方法中，从观察中生成可扩展且分布式化的策略。我们在两个具有不同团队规模和噪声级别的任务上进行了实验。结果显示，我们的课程学习方法提高了长期准确性，而我们的感知估计方法则产生了对现实不确定性具有鲁棒性的策略。这些策略共同使全局演示能够实现鲁棒的分布式控制器学习，即使在没有专家行动或机载测量的情况下也是如此。', 'title_zh': '分布式多机器人政策的课程模仿学习'}
{'arxiv_id': 'arXiv:2509.24972', 'title': 'Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks', 'authors': 'Vijja Wichitwechkarn, Emlyn Williams, Charles Fox, Ruchi Choudhary', 'link': 'https://arxiv.org/abs/2509.24972', 'abstract': 'Recent advances in one-shot imitation learning have enabled robots to acquire new manipulation skills from a single human demonstration. While existing methods achieve strong performance on single-step tasks, they remain limited in their ability to handle long-horizon, multi-step tasks without additional model training or manual annotation. We propose a method that can be applied to this setting provided a single demonstration without additional model training or manual annotation. We evaluated our method on multi-step and single-step manipulation tasks where our method achieves an average success rate of 82.5% and 90%, respectively. Our method matches and exceeds the performance of the baselines in both these cases. We also compare the performance and computational efficiency of alternative pre-trained feature extractors within our framework.', 'abstract_zh': '近期单次演示模仿学习的进展使机器人能够从单次人类演示中获取新的操作技能。尽管现有方法在单步任务上表现出色，但在处理长时程多步任务时，仍需要额外的模型训练或手动注释。我们提出了一种方法，在无需额外模型训练或手动注释的情况下，可以从单次演示中应用于此类场景。我们在多步和单步操作任务上评估了该方法，分别实现了82.5%和90%的成功率。该方法在两种情况下均匹配并超过了基线方法的性能。我们还比较了不同预训练特征提取器在该框架内的性能和计算效率。', 'title_zh': '无注释一次性模仿学习以应用于多步骤操作任务'}
{'arxiv_id': 'arXiv:2509.24956', 'title': 'MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation', 'authors': 'Jan Ole von Hartz, Lukas Schweizer, Joschka Boedecker, Abhinav Valada', 'link': 'https://arxiv.org/abs/2509.24956', 'abstract': 'Generative robot policies such as Flow Matching offer flexible, multi-modal policy learning but are sample-inefficient. Although object-centric policies improve sample efficiency, it does not resolve this limitation. In this work, we propose Multi-Stream Generative Policy (MSG), an inference-time composition framework that trains multiple object-centric policies and combines them at inference to improve generalization and sample efficiency. MSG is model-agnostic and inference-only, hence widely applicable to various generative policies and training paradigms. We perform extensive experiments both in simulation and on a real robot, demonstrating that our approach learns high-quality generative policies from as few as five demonstrations, resulting in a 95% reduction in demonstrations, and improves policy performance by 89 percent compared to single-stream approaches. Furthermore, we present comprehensive ablation studies on various composition strategies and provide practical recommendations for deployment. Finally, MSG enables zero-shot object instance transfer. We make our code publicly available at this https URL.', 'abstract_zh': '生成式机器人策略（如流匹配）提供了灵活的多模态策略学习能力，但样本利用效率较低。尽管以对象为中心的策略提高了样本利用效率，但这并未解决这一局限性。在本文中，我们提出了一种多流生成式策略（Multi-Stream Generative Policy, MSG），这是一种推理时的组合框架，训练多个以对象为中心的策略，并在推理时将它们结合起来，以提高泛化能力和样本利用效率。MSG 是模型无关且仅用于推理，因此可以广泛应用于各种生成式策略和训练范式。我们在仿真和实际机器人上进行了广泛的实验，证明我们的方法可以从最少五个演示中学习高质量的生成式策略，导致演示次数减少了95%，并且与单流方法相比，策略性能提高了89%。此外，我们对多种组合策略进行了全面的消融研究，并提供了实用的部署建议。最后，MSG 允许零样本对象实例迁移。我们将在以下网址公开我们的代码：这个 https URL。', 'title_zh': 'MSG：多流生成策略在样本高效机器人操作中的应用'}
{'arxiv_id': 'arXiv:2509.24948', 'title': 'World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training', 'authors': 'Junjin Xiao, Yandan Yang, Xinyuan Chang, Ronghan Chen, Feng Xiong, Mu Xu, Wei-Shi Zheng, Qing Zhang', 'link': 'https://arxiv.org/abs/2509.24948', 'abstract': 'Vision-Language-Action (VLA) models trained via imitation learning suffer from significant performance degradation in data-scarce scenarios due to their reliance on large-scale demonstration datasets. Although reinforcement learning (RL)-based post-training has proven effective in addressing data scarcity, its application to VLA models is hindered by the non-resettable nature of real-world environments. This limitation is particularly critical in high-risk domains such as industrial automation, where interactions often induce state changes that are costly or infeasible to revert. Furthermore, existing VLA approaches lack a reliable mechanism for detecting task completion, leading to redundant actions that reduce overall task success rates. To address these challenges, we propose World-Env, an RL-based post-training framework that replaces physical interaction with a low-cost, world model-based virtual simulator. World-Env consists of two key components: (1) a video-based world simulator that generates temporally consistent future visual observations, and (2) a vision-language model (VLM)-guided instant reflector that provides continuous reward signals and predicts action termination. This simulated environment enables VLA models to safely explore and generalize beyond their initial imitation learning distribution. Our method achieves notable performance gains with as few as five expert demonstrations per task. Experiments on complex robotic manipulation tasks demonstrate that World-Env effectively overcomes the data inefficiency, safety constraints, and inefficient execution of conventional VLA models that rely on real-world interaction, offering a practical and scalable solution for post-training in resource-constrained settings.', 'abstract_zh': '基于世界模型的RL后训练框架World-Env：解决Vision-Language-Action模型在数据稀缺场景下的性能退化问题', 'title_zh': 'World-Env: 利用世界模型作为虚拟环境进行多视图学习后训练'}
{'arxiv_id': 'arXiv:2509.24928', 'title': 'Trajectory Prediction via Bayesian Intention Inference under Unknown Goals and Kinematics', 'authors': 'Shunan Yin, Zehui Lu, Shaoshuai Mou', 'link': 'https://arxiv.org/abs/2509.24928', 'abstract': "This work introduces an adaptive Bayesian algorithm for real-time trajectory prediction via intention inference, where a target's intentions and motion characteristics are unknown and subject to change. The method concurrently estimates two critical variables: the target's current intention, modeled as a Markovian latent state, and an intention parameter that describes the target's adherence to a shortest-path policy. By integrating this joint update technique, the algorithm maintains robustness against abrupt intention shifts and unknown motion dynamics. A sampling-based trajectory prediction mechanism then exploits these adaptive estimates to generate probabilistic forecasts with quantified uncertainty. We validate the framework through numerical experiments: Ablation studies of two cases, and a 500-trial Monte Carlo analysis; Hardware demonstrations on quadrotor and quadrupedal platforms. Experimental results demonstrate that the proposed approach significantly outperforms non-adaptive and partially adaptive methods. The method operates in real time around 270 Hz without requiring training or detailed prior knowledge of target behavior, showcasing its applicability in various robotic systems.", 'abstract_zh': '基于意图推理的自适应贝叶斯实时轨迹预测算法', 'title_zh': '基于未知目标和运动学的贝叶斯意图推理轨迹预测'}
{'arxiv_id': 'arXiv:2509.24917', 'title': 'From Code to Action: Hierarchical Learning of Diffusion-VLM Policies', 'authors': 'Markus Peschl, Pietro Mazzaglia, Daniel Dijkman', 'link': 'https://arxiv.org/abs/2509.24917', 'abstract': 'Imitation learning for robotic manipulation often suffers from limited generalization and data scarcity, especially in complex, long-horizon tasks. In this work, we introduce a hierarchical framework that leverages code-generating vision-language models (VLMs) in combination with low-level diffusion policies to effectively imitate and generalize robotic behavior. Our key insight is to treat open-source robotic APIs not only as execution interfaces but also as sources of structured supervision: the associated subtask functions - when exposed - can serve as modular, semantically meaningful labels. We train a VLM to decompose task descriptions into executable subroutines, which are then grounded through a diffusion policy trained to imitate the corresponding robot behavior. To handle the non-Markovian nature of both code execution and certain real-world tasks, such as object swapping, our architecture incorporates a memory mechanism that maintains subtask context across time. We find that this design enables interpretable policy decomposition, improves generalization when compared to flat policies and enables separate evaluation of high-level planning and low-level control.', 'abstract_zh': '基于视觉语言模型的层次化模仿学习在机器人操作中的应用：处理复杂长时间任务的局限性和数据稀缺性', 'title_zh': '从代码到行动：扩散-VLM 策略的层级学习'}
{'arxiv_id': 'arXiv:2509.24907', 'title': 'Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation', 'authors': 'Thanh Long Nguyen, Duc Phu Nguyen, Thanh Thao Ton Nu, Quan Le, Thuan Hoang Tran, Manh Duong Phung', 'link': 'https://arxiv.org/abs/2509.24907', 'abstract': '{Recognizing human interactions is essential for social robots as it enables them to navigate safely and naturally in shared environments. Conventional robotic systems however often focus on obstacle avoidance, neglecting social cues necessary for seamless human-robot interaction. To address this gap, we propose a framework to recognize human group interactions for socially aware navigation. Our method utilizes color and depth frames from a monocular RGB-D camera to estimate 3D human keypoints and positions. Principal component analysis (PCA) is then used to determine dominant interaction directions. The shoelace formula is finally applied to compute interest points and engagement areas. Extensive experiments have been conducted to evaluate the validity of the proposed method. The results show that our method is capable of recognizing group interactions across different scenarios with varying numbers of individuals. It also achieves high-speed performance, processing each frame in approximately 4 ms on a single-board computer used in robotic systems. The method is implemented as a ROS 2 package making it simple to integrate into existing navigation systems. Source code is available at this https URL', 'abstract_zh': '识别人类互动对于社会机器人至关重要，因为它使机器人能够在共享环境中安全自然地导航。传统的机器人系统通常侧重于避障，忽视了无缝人类-机器人交互所需的社会线索。为了解决这一问题，我们提出了一种框架来识别人类群体互动，以实现社会意识导航。该方法利用单目RGB-D相机的颜色和深度帧来估算3D人体关键点和位置。然后使用主成分分析（PCA）来确定主导的互动方向。最后，应用鞋带公式计算兴趣点和参与区域。进行了广泛的实验以评估所提出方法的有效性。结果表明，该方法能够识别不同场景下不同数量个体的群体互动，并且具有高效性能，在用于机器人系统的单板计算机上每帧处理时间约为4毫秒。该方法以ROS 2包的形式实现，易于集成到现有的导航系统中。源代码可通过此链接获取。', 'title_zh': '基于单个RGB-D摄像头的实时人类交互识别技术及其在社会感知机器人导航中的应用'}
{'arxiv_id': 'arXiv:2509.24903', 'title': 'DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits', 'authors': 'Lantao Li, Kang Yang, Rui Song, Chen Sun', 'link': 'https://arxiv.org/abs/2509.24903', 'abstract': "Cooperative perception enabled by Vehicle-to-Everything communication has shown great promise in enhancing situational awareness for autonomous vehicles and other mobile robotic platforms. Despite recent advances in perception backbones and multi-agent fusion, real-world deployments remain challenged by hard detection cases, exemplified by partial detections and noise accumulation which limit downstream detection accuracy. This work presents Diffusion on Reinforced Cooperative Perception (DRCP), a real-time deployable framework designed to address aforementioned issues in dynamic driving environments. DRCP integrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent, a cross-modal cooperative perception module that leverages camera-intrinsic-aware angular partitioning for attention-based fusion and adaptive convolution to better exploit external features; and (2) Mask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement module that encourages robustness against feature perturbations and aligns bird's-eye-view features closer to the task-optimal manifold. The proposed system achieves real-time performance on mobile platforms while significantly improving robustness under challenging conditions. Code will be released in late 2025.", 'abstract_zh': '基于Vehicle-to-Everything通信的协作感知在增强自主车辆和其他移动机器人平台的情境感知方面展现了巨大的潜力。尽管在感知骨干和多agent融合方面取得了近期进展，但由于部分检测和噪声累积等实际部署挑战，下游检测准确性仍受限。本文提出了一种名为Diffusion on Reinforced Cooperative Perception (DRCP)的实时可部署框架，旨在解决动态驾驶环境中的上述问题。DRCP结合了两个关键组件：(1) Precise-Pyramid-Cross-Modality-Cross-Agent，这是一种跨模态协作感知模块，利用相机固有角度分区进行基于注意力的融合和自适应卷积，以更好地利用外部特征；和(2) Mask-Diffusion-Mask-Aggregation，这是一种新颖的轻量级扩散基础精炼模块，鼓励对特征扰动的鲁棒性，并使鸟瞰视图特征更接近任务最优流形。所提出系统在移动平台上实现了实时性能，在恶劣条件下显著提高了鲁棒性。代码将于2025年底发布。', 'title_zh': 'DRCP: 扩展感知限界的强化协作感知扩散方法'}
{'arxiv_id': 'arXiv:2509.24892', 'title': 'JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning', 'authors': "Shilong Ji, Yinuo Chen, Chuqi Wang, Jiayu Chen, Ruize Zhang, Feng Gao, Wenhao Tang, Shu'ang Yu, Sirui Xiang, Xinlei Chen, Chao Yu, Yu Wang", 'link': 'https://arxiv.org/abs/2509.24892', 'abstract': 'Aerial robots interacting with objects must perform precise, contact-rich maneuvers under uncertainty. In this paper, we study the problem of aerial ball juggling using a quadrotor equipped with a racket, a task that demands accurate timing, stable control, and continuous adaptation. We propose JuggleRL, the first reinforcement learning-based system for aerial juggling. It learns closed-loop policies in large-scale simulation using systematic calibration of quadrotor and ball dynamics to reduce the sim-to-real gap. The training incorporates reward shaping to encourage racket-centered hits and sustained juggling, as well as domain randomization over ball position and coefficient of restitution to enhance robustness and transferability. The learned policy outputs mid-level commands executed by a low-level controller and is deployed zero-shot on real hardware, where an enhanced perception module with a lightweight communication protocol reduces delays in high-frequency state estimation and ensures real-time control. Experiments show that JuggleRL achieves an average of $311$ hits over $10$ consecutive trials in the real world, with a maximum of $462$ hits observed, far exceeding a model-based baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the policy generalizes to unseen conditions, successfully juggling a lighter $5$ g ball with an average of $145.9$ hits. This work demonstrates that reinforcement learning can empower aerial robots with robust and stable control in dynamic interaction tasks.', 'abstract_zh': '基于强化学习的飞行拍球机器人系统：在不确定性下的精准接触操作', 'title_zh': 'JuggleRL：通过深度强化学习使四旋翼无人机掌握球技'}
{'arxiv_id': 'arXiv:2509.24763', 'title': 'SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework', 'authors': 'Xiangyi Meng, Delun Li, Zihao Mao, Yi Yang, Wenjie Song', 'link': 'https://arxiv.org/abs/2509.24763', 'abstract': 'Zero-shot object navigation in unknown environments presents significant challenges, mainly due to two key limitations: insufficient semantic guidance leads to inefficient exploration, while limited spatial memory resulting from environmental structure causes entrapment in local regions. To address these issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object navigation method based on the TARE hierarchical exploration framework, integrating a viewpoint generation strategy balancing spatial coverage and semantic density with an LLM-based global guidance mechanism. The performance improvement of the proposed method is due to two key innovations. First, the viewpoint generation strategy prioritizes areas of high semantic density within traversable sub-regions to maximize spatial coverage and minimize invalid exploration. Second, coupled with an LLM-based global guidance mechanism, it assesses semantic associations to direct navigation toward high-value spaces, preventing local entrapment and ensuring efficient exploration. Deployed on hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves real-time operation and superior performance. On Matterport3D and Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\\% and 11.2\\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140, respectively, over state-of-the-art methods.', 'abstract_zh': '未知环境下零样本物体导航面临显著挑战，主要是由于两个关键限制：语义指导不足导致探索效率低下，而有限的空间记忆导致在局部区域陷入。为了解决这些问题，我们提出了一种基于TARE层次探索框架的SSR-ZSON空间语义相对零样本物体导航方法，该方法结合了平衡空间覆盖度和语义密度的视角生成策略和基于大语言模型的全局指导机制。所提出的该方法的性能提升归功于两个关键创新。首先，视角生成策略优先考虑可通行子区域内的高语义密度区域，以最大化空间覆盖度并最小化无效探索。其次，结合基于大语言模型的全局指导机制，通过评估语义关联性来引导导航至高价值空间，防止局部陷入并确保高效探索。在混合Habitat-Gazebo仿真和物理平台上部署，SSR-ZSON实现实时操作并表现出优越性能。在Matterport3D和Habitat-Matterport3D数据集上，SSR-ZSON分别将成功率（Success Rate，SR）提高了18.5%和11.2%，平均成功率加权路径长度（Success weighted by Path Length，SPL）提高了0.181和0.140，超过最先进的方法。', 'title_zh': 'SSR-ZSON: 基于层次探索框架内的空间语义关系的零样本对象导航'}
{'arxiv_id': 'arXiv:2509.24733', 'title': 'APREBot: Active Perception System for Reflexive Evasion Robot', 'authors': 'Zihao Xu, Kuankuan Sima, Junhao Deng, Zixuan Zhuang, Chunzheng Wang, Ce Hao, Jin Song Dong', 'link': 'https://arxiv.org/abs/2509.24733', 'abstract': "Reliable onboard perception is critical for quadruped robots navigating dynamic environments, where obstacles can emerge from any direction under strict reaction-time constraints. Single-sensor systems face inherent limitations: LiDAR provides omnidirectional coverage but lacks rich texture information, while cameras capture high-resolution detail but suffer from restricted field of view. We introduce APREBot (Active Perception System for Reflexive Evasion Robot), a novel framework that integrates reflexive evasion with active hierarchical perception. APREBot strategically combines LiDAR-based omnidirectional scanning with camera-based active focusing, achieving comprehensive environmental awareness essential for agile obstacle avoidance in quadruped robots. We validate APREBot through extensive sim-to-real experiments on a quadruped platform, evaluating diverse obstacle types, trajectories, and approach directions. Our results demonstrate substantial improvements over state-of-the-art baselines in both safety metrics and operational efficiency, highlighting APREBot's potential for dependable autonomy in safety-critical scenarios. Videos are available at this https URL", 'abstract_zh': '可靠的机载感知对于四足机器人在动态环境中的导航至关重要，严格的时间限制约束下，障碍物可以从任何方向出现。单传感器系统存在固有限制：LiDAR提供全方位覆盖但缺乏丰富的纹理信息，而相机能够捕捉高分辨率的细节但视野受限。我们介绍了APREBot（具有反射性规避的主动感知系统），这是一种将反射性规避与主动分层感知相结合的创新框架。APREBot战略性地结合了基于LiDAR的全方位扫描与基于相机的主动聚焦，实现了四足机器人灵活避障所需的全面环境意识。我们通过在四足平台上进行广泛的仿真实验验证了APREBot，评估了不同的障碍类型、路径和接近方向。我们的结果表明，APREBot在安全指标和操作效率方面显著优于最先进的 baseline，突显了其在安全关键场景中可靠自主性的潜力。视频可在以下链接获取：这个 https URL。', 'title_zh': 'APREBot: 反应式避障机器人主动感知系统'}
{'arxiv_id': 'arXiv:2509.24706', 'title': 'LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers', 'authors': 'Andreea Tulbure, Rene Zurbruegg, Timm Grigat, Marco Hutter', 'link': 'https://arxiv.org/abs/2509.24706', 'abstract': 'Effective human-robot collaboration depends on task-oriented handovers, where robots present objects in ways that support the partners intended use. However, many existing approaches neglect the humans post-handover action, relying on assumptions that limit generalizability. To address this gap, we propose LLM-Handover, a novel framework that integrates large language model (LLM)-based reasoning with part segmentation to enable context-aware grasp selection and execution. Given an RGB-D image and a task description, our system infers relevant object parts and selects grasps that optimize post-handover usability. To support evaluation, we introduce a new dataset of 60 household objects spanning 12 categories, each annotated with detailed part labels. We first demonstrate that our approach improves the performance of the used state-of-the-art part segmentation method, in the context of robot-human handovers. Next, we show that LLM-Handover achieves higher grasp success rates and adapts better to post-handover task constraints. During hardware experiments, we achieve a success rate of 83% in a zero-shot setting over conventional and unconventional post-handover tasks. Finally, our user study underlines that our method enables more intuitive, context-aware handovers, with participants preferring it in 86% of cases.', 'abstract_zh': '有效的机器人-人类协作依赖于任务导向的手递过程，其中机器人以支持合作伙伴预期使用的方式呈现物体。然而，许多现有方法忽视了人类手递后的动作，依赖于限制泛化的假设。为了解决这一问题，我们提出了LLM-Handover这一新型框架，该框架结合了基于大规模语言模型（LLM）的推理与部分分割技术，以实现上下文感知的抓取选择与执行。给定一个RGB-D图像和任务描述，我们的系统推断相关物体部分并选择最大化手递后易用性的抓取。为支持评估，我们引入了一个包含60件家庭用品的新数据集，这些用品分为12个类别，每个类别都详细标注了部分标签。我们首先证明，我们的方法提高了所使用的最新部分分割方法在机器人-人类手递中的性能。接着，我们展示了LLM-Handover实现了更高的抓取成功率并且更好地适应手递后的任务约束。在硬件实验中，在零样本设置下，对于常规和非常规手递后任务，我们实现了83%的成功率。最后，我们的用户研究强调，我们的方法能够实现更直观、上下文感知的手递，86%的参与者更偏好我们的方法。', 'title_zh': 'LLM-手递：利用大语言模型进行任务导向的机器人-人类手递'}
{'arxiv_id': 'arXiv:2509.24697', 'title': 'Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering', 'authors': "Evelyn D'Elia, Paolo Maria Viceconte, Lorenzo Rapetti, Diego Ferigo, Giulio Romualdi, Giuseppe L'Erario, Raffaello Camoriano, Daniele Pucci", 'link': 'https://arxiv.org/abs/2509.24697', 'abstract': 'Recent trends in humanoid robot control have successfully employed imitation learning to enable the learned generation of smooth, human-like trajectories from human data. While these approaches make more realistic motions possible, they are limited by the amount of available motion data, and do not incorporate prior knowledge about the physical laws governing the system and its interactions with the environment. Thus they may violate such laws, leading to divergent trajectories and sliding contacts which limit real-world stability. We address such limitations via a two-pronged learning strategy which leverages the known physics of the system and fundamental control principles. First, we encode physics priors during supervised imitation learning to promote trajectory feasibility. Second, we minimize drift at inference time by applying a proportional-integral controller directly to the generated output state. We validate our method on various locomotion behaviors for the ergoCub humanoid robot, where a physics-informed loss encourages zero contact foot velocity. Our experiments demonstrate that the proposed approach is compatible with multiple controllers on a real robot and significantly improves the accuracy and physical constraint conformity of generated trajectories.', 'abstract_zh': 'Recent trends in humanoid robot control have successfully employed imitation learning to enable the learned generation of smooth, human-like trajectories from human data. While these approaches make more realistic motions possible, they are limited by the amount of available motion data, and do not incorporate prior knowledge about the physical laws governing the system and its interactions with the environment. Thus they may violate such laws, leading to divergent trajectories and sliding contacts which limit real-world stability. We address such limitations via a two-pronged learning strategy which leverages the known physics of the system and fundamental control principles. First, we encode physics priors during supervised imitation learning to promote trajectory feasibility. Second, we minimize drift at inference time by applying a proportional-integral controller directly to the generated output state. We validate our method on various locomotion behaviors for the ergoCub humanoid robot, where a physics-informed loss encourages zero contact foot velocity. Our experiments demonstrate that the proposed approach is compatible with multiple controllers on a real robot and significantly improves the accuracy and physical constraint conformity of generated trajectories.', 'title_zh': '通过物理告知学习和控制导向导向控制实现类人机器人轨迹生成的稳定性增强'}
{'arxiv_id': 'arXiv:2509.24661', 'title': 'CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations', 'authors': 'Zhiyuan Wu, Rolandos Alexandros Potamias, Xuyang Zhang, Zhongqun Zhang, Jiankang Deng, Shan Luo', 'link': 'https://arxiv.org/abs/2509.24661', 'abstract': "Cross-embodiment dexterous grasp synthesis refers to adaptively generating and optimizing grasps for various robotic hands with different morphologies. This capability is crucial for achieving versatile robotic manipulation in diverse environments and requires substantial amounts of reliable and diverse grasp data for effective model training and robust generalization. However, existing approaches either rely on physics-based optimization that lacks human-like kinematic understanding or require extensive manual data collection processes that are limited to anthropomorphic structures. In this paper, we propose CEDex, a novel cross-embodiment dexterous grasp synthesis method at scale that bridges human grasping kinematics and robot kinematics by aligning robot kinematic models with generated human-like contact representations. Given an object's point cloud and an arbitrary robotic hand model, CEDex first generates human-like contact representations using a Conditional Variational Auto-encoder pretrained on human contact data. It then performs kinematic human contact alignment through topological merging to consolidate multiple human hand parts into unified robot components, followed by a signed distance field-based grasp optimization with physics-aware constraints. Using CEDex, we construct the largest cross-embodiment grasp dataset to date, comprising 500K objects across four gripper types with 20M total grasps. Extensive experiments show that CEDex outperforms state-of-the-art approaches and our dataset benefits cross-embodiment grasp learning with high-quality diverse grasps.", 'abstract_zh': '跨身躯 Dexterous 抓取合成', 'title_zh': 'CEDex: 大规模从类人接触表示生成跨越载体的灵巧抓取'}
{'arxiv_id': 'arXiv:2509.24591', 'title': 'PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control', 'authors': 'Haozhuo Zhang, Michele Caprio, Jing Shao, Qiang Zhang, Jian Tang, Shanghang Zhang, Wei Pan', 'link': 'https://arxiv.org/abs/2509.24591', 'abstract': 'We present PoseDiff, a conditional diffusion model that unifies robot state estimation and control within a single framework. At its core, PoseDiff maps raw visual observations into structured robot states-such as 3D keypoints or joint angles-from a single RGB image, eliminating the need for multi-stage pipelines or auxiliary modalities. Building upon this foundation, PoseDiff extends naturally to video-to-action inverse dynamics: by conditioning on sparse video keyframes generated by world models, it produces smooth and continuous long-horizon action sequences through an overlap-averaging strategy. This unified design enables scalable and efficient integration of perception and control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy and real-time performance for pose estimation. On Libero-Object manipulation tasks, it substantially improves success rates over existing inverse dynamics modules, even under strict offline settings. Together, these results show that PoseDiff provides a scalable, accurate, and efficient bridge between perception, planning, and control in embodied AI. The video visualization results can be found on the project page: this https URL.', 'abstract_zh': 'PoseDiff：统一机器人状态估计与控制的条件扩散模型', 'title_zh': 'PoseDiff: 一个统一的扩散模型，连接机器人姿态估计与视频到动作控制'}
{'arxiv_id': 'arXiv:2509.24579', 'title': 'U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation', 'authors': 'Linzhi Wu, Aoran Mei, Xiyue Wang, Guo-Niu Zhu, Zhongxue Gan', 'link': 'https://arxiv.org/abs/2509.24579', 'abstract': 'Diffusion-based methods have been acknowledged as a powerful paradigm for end-to-end visuomotor control in robotics. Most existing approaches adopt a Diffusion Policy in U-Net architecture (DP-U), which, while effective, suffers from limited global context modeling and over-smoothing artifacts. To address these issues, we propose U-DiT Policy, a novel U-shaped Diffusion Transformer framework. U-DiT preserves the multi-scale feature fusion advantages of U-Net while integrating the global context modeling capability of Transformers, thereby enhancing representational power and policy expressiveness. We evaluate U-DiT extensively across both simulation and real-world robotic manipulation tasks. In simulation, U-DiT achieves an average performance gain of 10\\% over baseline methods and surpasses Transformer-based diffusion policies (DP-T) that use AdaLN blocks by 6\\% under comparable parameter budgets. On real-world robotic tasks, U-DiT demonstrates superior generalization and robustness, achieving an average improvement of 22.5\\% over DP-U. In addition, robustness and generalization experiments under distractor and lighting variations further highlight the advantages of U-DiT. These results highlight the effectiveness and practical potential of U-DiT Policy as a new foundation for diffusion-based robotic manipulation.', 'abstract_zh': '基于扩散的方法已被公认为机器人端到端视觉-运动控制的一种强大范式。现有的大多数方法采用了U-Net架构的扩散策略（DP-U），尽管有效，但存在全局上下文建模能力有限和过度平滑的缺点。为了解决这些问题，我们提出了一种新的U形扩散变压器框架U-DiT策略。U-DiT保留了U-Net的多尺度特征融合优势，同时整合了Transformer的全局上下文建模能力，从而增强了表示能力和策略表达能力。我们在模拟和实际机器人操作任务中广泛评估了U-DiT。在模拟环境中，U-DiT在基线方法上实现了平均10%的性能提升，并在与基于Transformer的扩散策略（DP-T）使用AdaLN模块的情况下，拥有相似的参数预算时，超越了6%。在实际机器人任务中，U-DiT展示了更好的泛化能力和鲁棒性，相对于DP-U实现了平均22.5%的改进。此外，在干扰和照明变化的鲁棒性和泛化实验中，进一步突显了U-DiT的优势。这些结果表明，U-DiT策略作为一种新的基于扩散的机器人操作基础框架具有有效性和实际潜力。', 'title_zh': 'U-DiT策略：U形扩散变换器在机器人操作中的应用'}
{'arxiv_id': 'arXiv:2509.24575', 'title': 'Prompting Robot Teams with Natural Language', 'authors': 'Nicolas Pfitzer, Eduardo Sebastián, Ajay Shankar, Amanda Prorok', 'link': 'https://arxiv.org/abs/2509.24575', 'abstract': "This paper presents a framework towards prompting multi-robot teams with high-level tasks using natural language expressions. Our objective is to use the reasoning capabilities demonstrated by recent language models in understanding and decomposing human expressions of intent, and repurpose these for multi-robot collaboration and decision-making. The key challenge is that an individual's behavior in a collective can be hard to specify and interpret, and must continuously adapt to actions from others. This necessitates a framework that possesses the representational capacity required by the logic and semantics of a task, and yet supports decentralized and interactive real-time operation. We solve this dilemma by recognizing that a task can be represented as a deterministic finite automaton (DFA), and that recurrent neural networks (RNNs) can encode numerous automata. This allows us to distill the logic and sequential decompositions of sub-tasks obtained from a language model into an RNN, and align its internal states with the semantics of a given task. By training a graph neural network (GNN) control policy that is conditioned on the hidden states of the RNN and the language embeddings, our method enables robots to execute task-relevant actions in a decentralized manner. We present evaluations of this single light-weight interpretable model on various simulated and real-world multi-robot tasks that require sequential and collaborative behavior by the team -- this http URL.", 'abstract_zh': '本文提出了一种使用自然语言表达提示多机器人团队执行高层任务的框架。我们的目标是利用最近的语言模型在理解和分解人类意图表达方面的推理能力，并将这些能力应用于多机器人协作和决策。关键挑战在于，在集体中个体的行为难以具体化和解释，并且必须不断适应他人的行动。这就需要一个具备任务所需的逻辑和语义表示能力的框架，并且支持分布式和交互式的实时操作。我们通过认识到任务可以表示为确定性有限自动机（DFA），并且循环神经网络（RNN）可以编码多种自动机来解决这一矛盾。这使我们能够从语言模型中提炼出子任务的逻辑和序列分解，并将其输入到RNN中，使其内部状态与给定任务的语义相吻合。通过训练一个基于RNN隐藏状态和语言嵌入的图神经网络（GNN）控制策略，我们的方法使得机器人能够以分布式的方式执行与任务相关的行为。我们在各种需要序列化和协作行为的模拟和真实世界多机器人任务上评估了这一单一轻量级可解释模型——请访问这个网址。', 'title_zh': '用自然语言指令驱动机器人团队'}
{'arxiv_id': 'arXiv:2509.24539', 'title': 'Unlocking the Potential of Soft Actor-Critic for Imitation Learning', 'authors': 'Nayari Marie Lessa, Melya Boukheddimi, Frank Kirchner', 'link': 'https://arxiv.org/abs/2509.24539', 'abstract': 'Learning-based methods have enabled robots to acquire bio-inspired movements with increasing levels of naturalness and adaptability. Among these, Imitation Learning (IL) has proven effective in transferring complex motion patterns from animals to robotic systems. However, current state-of-the-art frameworks predominantly rely on Proximal Policy Optimization (PPO), an on-policy algorithm that prioritizes stability over sample efficiency and policy generalization. This paper proposes a novel IL framework that combines Adversarial Motion Priors (AMP) with the off-policy Soft Actor-Critic (SAC) algorithm to overcome these limitations. This integration leverages replay-driven learning and entropy-regularized exploration, enabling naturalistic behavior and task execution, improving data efficiency and robustness. We evaluate the proposed approach (AMP+SAC) on quadruped gaits involving multiple reference motions and diverse terrains. Experimental results demonstrate that the proposed framework not only maintains stable task execution but also achieves higher imitation rewards compared to the widely used AMP+PPO method. These findings highlight the potential of an off-policy IL formulation for advancing motion generation in robotics.', 'abstract_zh': '基于学习的方法使机器人能够获得越来越自然和适应性强的生物启发运动。在这之中， imitation learning (IL) 已证明有效于将复杂的运动模式从动物转移至机器人系统。然而，当前最先进的框架主要依赖于优先稳定性和样本效率的近端策略优化(PPO)算法。本文提出了一种新型的IL框架，该框架结合了对抗运动先验(AMP)与离策 Soft Actor-Critic (SAC) 算法，以克服这些局限性。这种集成利用了回放驱动的学习和熵正则化探索，从而实现自然的行为和任务执行，提高数据效率和鲁棒性。我们在涉及多种参考运动和不同地形的四足运动中评估了该方法(AMP+SAC)。实验结果表明，所提出的框架不仅能够保持稳定的任务执行，还能比广泛使用的AMP+PPO方法获得更高的仿真正奖。这些发现强调了离策IL方案在推进机器人动作生成方面的潜力。', 'title_zh': '解锁Soft Actor-Critic在 imitation learning 中的潜力'}
{'arxiv_id': 'arXiv:2509.24530', 'title': 'Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game', 'authors': 'Giulia Pusceddu, Sara Mongile, Francesco Rea, Alessandra Sciutti', 'link': 'https://arxiv.org/abs/2509.24530', 'abstract': "In this study, we explore the potential of Game Theory as a means to investigate cooperation and trust in human-robot mixed groups. Particularly, we introduce the Public Good Game (PGG), a model highlighting the tension between individual self-interest and collective well-being. In this work, we present a modified version of the PGG, where three human participants engage in the game with the humanoid robot iCub to assess whether various robot game strategies (e.g., always cooperate, always free ride, and tit-for-tat) can influence the participants' inclination to cooperate. We test our setup during a pilot study with nineteen participants. A preliminary analysis indicates that participants prefer not to invest their money in the common pool, despite they perceive the robot as generous. By conducting this research, we seek to gain valuable insights into the role that robots can play in promoting trust and cohesion during human-robot interactions within group contexts. The results of this study may hold considerable potential for developing social robots capable of fostering trust and cooperation within mixed human-robot groups.", 'abstract_zh': '本研究探讨博弈理论作为研究人类-机器人混合群体中合作与信任的手段的潜在可能性。具体而言，我们引入了公共物品游戏（PGG）模型，该模型突显了个体自我利益与集体福祉之间的张力。在本文中，我们提出了公共物品游戏的一种修改版本，三人参与者与类人机器人iCub进行游戏，以评估不同类型机器人游戏策略（例如始终合作、始终搭便车和以牙还牙）是否会影响参与者合作的倾向。我们在包含十九名参与者的试点研究中测试了我们的设置。初步分析表明，尽管参与者认为机器人很慷慨，但他们还是倾向于不将钱投入共享池。通过进行这项研究，我们旨在深入了解机器人在促进人类-机器人互动中群体内的信任与凝聚力方面的作用。本研究的结果可能对于开发能够促进人类-机器人混合群体中信任与合作的社会机器人具有重要意义。', 'title_zh': '基于博弈论研究人类与机器人混合组中的合作：探索公共物品博弈的潜在价值'}
{'arxiv_id': 'arXiv:2509.24524', 'title': 'PhysiAgent: An Embodied Agent Framework in Physical World', 'authors': 'Zhihao Wang, Jianxiong Li, Jinliang Zheng, Wencong Zhang, Dongxiu Liu, Yinan Zheng, Haoyi Niu, Junzhi Yu, Xianyuan Zhan', 'link': 'https://arxiv.org/abs/2509.24524', 'abstract': "Vision-Language-Action (VLA) models have achieved notable success but often struggle with limited generalizations. To address this, integrating generalized Vision-Language Models (VLMs) as assistants to VLAs has emerged as a popular solution. However, current approaches often combine these models in rigid, sequential structures: using VLMs primarily for high-level scene understanding and task planning, and VLAs merely as executors of lower-level actions, leading to ineffective collaboration and poor grounding challenges. In this paper, we propose an embodied agent framework, PhysiAgent, tailored to operate effectively in physical environments. By incorporating monitor, memory, self-reflection mechanisms, and lightweight off-the-shelf toolboxes, PhysiAgent offers an autonomous scaffolding framework to prompt VLMs to organize different components based on real-time proficiency feedback from VLAs to maximally exploit VLAs' capabilities. Experimental results demonstrate significant improvements in task-solving performance on complex real-world robotic tasks, showcasing effective self-regulation of VLMs, coherent tool collaboration, and adaptive evolution of the framework during execution. PhysiAgent makes practical and pioneering efforts to integrate VLMs and VLAs, effectively grounding embodied agent frameworks in real-world settings.", 'abstract_zh': '基于物理环境的Vision-Language-Action（VLA） embodiment代理框架：VLMs和VLAs的有效集成与自适应进化', 'title_zh': 'PhysiAgent：物理世界中的体态代理框架'}
{'arxiv_id': 'arXiv:2509.24413', 'title': 'DynaMIC: Dynamic Multimodal In-Context Learning Enabled Embodied Robot Counterfactual Resistance Ability', 'authors': 'Tianqiang Yan, Ziqiao Lin, Sicheng Wang, Tianwei Zhang, Zhenglong Sun', 'link': 'https://arxiv.org/abs/2509.24413', 'abstract': 'The emergence of large pre-trained models based on natural language has breathed new life into robotics development. Extensive research has integrated large models with robots, utilizing the powerful semantic understanding and generation capabilities of large models to facilitate robot control through natural language instructions gradually. However, we found that robots that strictly adhere to human instructions, especially those containing misleading information, may encounter errors during task execution, potentially leading to safety hazards. This resembles the concept of counterfactuals in natural language processing (NLP), which has not yet attracted much attention in robotic research. In an effort to highlight this issue for future studies, this paper introduced directive counterfactuals (DCFs) arising from misleading human directives. We present DynaMIC, a framework for generating robot task flows to identify DCFs and relay feedback to humans proactively. This capability can help robots be sensitive to potential DCFs within a task, thus enhancing the reliability of the execution process. We conducted semantic-level experiments and ablation studies, showcasing the effectiveness of this framework.', 'abstract_zh': '基于自然语言的大型预训练模型的出现为机器人研发注入了新的活力。大量研究将大型模型与机器人结合，利用其强大的语义理解和生成能力，通过自然语言指令逐步实现机器人控制。然而，我们发现严格遵循人类指令，尤其是包含误导信息的指令的机器人，在任务执行过程中可能会遇到错误，从而可能带来安全风险。这类似于自然语言处理（NLP）中反事实概念，但在机器人研究中尚未引起广泛关注。为了在未来的研究中突出这一问题，本文介绍了一种源自误导性人类指令的指令反事实(DCFs)。我们提出了DynaMIC框架，用于生成机器人任务流程以识别DCF并主动向人类传达反馈。这一能力可以使机器人对任务中潜在的DCF更加敏感，从而提高执行过程的可靠性。我们进行了语义层面的实验和消融研究，展示了该框架的有效性。', 'title_zh': 'DynaMIC: 动态多模态上下文学习赋能的 embodied 机器人反事实抵抗力'}
{'arxiv_id': 'arXiv:2509.24387', 'title': 'AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation', 'authors': 'Xin Ding, Jianyu Wei, Yifan Yang, Shiqi Jiang, Qianxi Zhang, Hao Wu, Fucheng Jia, Liang Mi, Yuxuan Yan, Weijun Wang, Yunxin Liu, Zhibo Chen, Ting Cao', 'link': 'https://arxiv.org/abs/2509.24387', 'abstract': 'Vision Language Navigation (VLN) requires agents to follow natural language instructions by grounding them in sequential visual observations over long horizons. Explicit reasoning could enhance temporal consistency and perception action alignment, but reasoning at fixed steps often leads to suboptimal performance and unnecessary computation. To address this, we propose AdaNav, an uncertainty-based adaptive reasoning framework for VLN. At its core is the Uncertainty Adaptive Reasoning Block (UAR), a lightweight plugin that dynamically triggers reasoning. We introduce Action Entropy as a policy prior for UAR and progressively refine it through a Heuristics to RL training method, enabling agents to learn difficulty aware reasoning policies under the strict data limitations of embodied tasks. Results show that with only 6K training samples, AdaNav achieves substantial gains over closed source models trained on million scale data, improving success rate by 20% on R2R val-unseen, 11.7% on RxR-CE, and 11.4% in real world scenes. The code is available at this https URL.', 'abstract_zh': '基于视觉语言的导航（Vision Language Navigation，VLN）要求代理通过将自然语言指令 grounding 在长时序的视觉观察中来遵循这些指令。基于不确定性的自适应推理框架（AdaNav）可以通过动态触发推理来增强时间一致性和感知动作对齐，但固定步长的推理经常导致性能不佳和不必要的计算。为此，我们提出了一种基于不确定性的自适应推理框架（AdaNav）以增强视觉语言导航（VLN）。其核心是不确定性自适应推理块（UAR），这是一种轻量级插件，可以动态触发推理。我们引入了动作熵作为UAR的策略先验，并通过启发式到强化学习的训练方法逐步对其进行细化，使代理在有严格数据限制的体感任务中能够学习到难度感知的推理策略。结果表明，仅使用6K训练样本，AdaNav在R2R val-unseen上的成功率提高了20%，在RxR-CE上提高了11.7%，在真实世界场景中提高了11.4%。代码可在此处访问：this https URL。', 'title_zh': 'AdaNav: 带有不确定性自适应推理的视觉-语言导航'}
{'arxiv_id': 'arXiv:2509.24321', 'title': 'SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm', 'authors': 'Yao Wang, Zhirui Sun, Wenzheng Chi, Baozhi Jia, Wenjun Xu, Jiankun Wang', 'link': 'https://arxiv.org/abs/2509.24321', 'abstract': 'Understanding human instructions and accomplishing Vision-Language Navigation tasks in unknown environments is essential for robots. However, existing modular approaches heavily rely on the quality of training data and often exhibit poor generalization. Vision-Language Model based methods, while demonstrating strong generalization capabilities, tend to perform unsatisfactorily when semantic cues are weak. To address these issues, this paper proposes SONAR, an aggregated reasoning approach through a cross modal paradigm. The proposed method integrates a semantic map based target prediction module with a Vision-Language Model based value map module, enabling more robust navigation in unknown environments with varying levels of semantic cues, and effectively balancing generalization ability with scene adaptability. In terms of target localization, we propose a strategy that integrates multi-scale semantic maps with confidence maps, aiming to mitigate false detections of target objects. We conducted an evaluation of the SONAR within the Gazebo simulator, leveraging the most challenging Matterport 3D (MP3D) dataset as the experimental benchmark. Experimental results demonstrate that SONAR achieves a success rate of 38.4% and an SPL of 17.7%.', 'abstract_zh': '基于跨模态聚合推理的SONAR：在未知环境中实现目标定位与语义导航', 'title_zh': 'SONAR：基于跨模态推理框架的语义对象导航与聚合推理'}
{'arxiv_id': 'arXiv:2509.24313', 'title': 'Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning', 'authors': 'Korbinian Moller, Roland Stroop, Mattia Piccinini, Alexander Langmann, Johannes Betz', 'link': 'https://arxiv.org/abs/2509.24313', 'abstract': 'Sampling-based motion planning is a well-established approach in autonomous driving, valued for its modularity and analytical tractability. In complex urban scenarios, however, uniform or heuristic sampling often produces many infeasible or irrelevant trajectories. We address this limitation with a hybrid framework that learns where to sample while keeping trajectory generation and evaluation fully analytical and verifiable. A reinforcement learning (RL) agent guides the sampling process toward regions of the action space likely to yield feasible trajectories, while evaluation and final selection remains governed by deterministic feasibility checks and cost functions. We couple the RL sampler with a world model (WM) based on a decodable deep set encoder, enabling both variable numbers of traffic participants and reconstructable latent representations. The approach is evaluated in the CommonRoad simulation environment, showing up to 99% fewer required samples and a runtime reduction of up to 84% while maintaining planning quality in terms of success and collision-free rates. These improvements lead to faster, more reliable decision-making for autonomous vehicles in urban environments, achieving safer and more responsive navigation under real-world constraints. Code and trained artifacts are publicly available at: this https URL', 'abstract_zh': '基于采样的运动规划是自主驾驶中一个成熟的 approach，因其模块化和分析可处理性而受到重视。然而，在复杂的城市场景中，均匀或启发式的采样往往会产生许多不可行或无关的轨迹。我们提出一种混合框架来解决这一局限性，该框架在保持轨迹生成和评估的完全分析性和可验证性的同时，学习如何采样。基于强化学习（RL）的代理引导采样过程，使其趋向于行动空间中可能性较大的可行轨迹区域，而评价和最终选择仍然由确定性的可行性和成本函数进行控制。我们将RL采样器与基于可解码深度集合编码器的世界模型耦合，允许交通参与者数量可变且能重建潜在表示。该方法在CommonRoad仿真环境中进行评估，结果显示所需的样本次数最多减少99%，运行时间最多减少84%，同时在成功和无碰撞率方面保持了规划质量。这些改进使得自主车辆在城市环境中能够更快、更可靠地做出决策，在实际约束条件下实现更安全、更响应的导航。相关代码和训练成果已在以下网址公开：this https URL。', 'title_zh': '基于学习的采样：强化学习引导的自主车辆运动规划采样'}
{'arxiv_id': 'arXiv:2509.24219', 'title': 'ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning', 'authors': 'Tomoyuki Kagaya, Subramanian Lakshmi, Anbang Ye, Thong Jing Yuan, Jayashree Karlekar, Sugiri Pranata, Natsuki Murakami, Akira Kinose, Yang You', 'link': 'https://arxiv.org/abs/2509.24219', 'abstract': 'Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL) often adapt slowly to new tasks, whereas recent Large Language Models (LLMs) and Vision-Language Models (VLMs) promise knowledge-rich planning from minimal data. Deploying LLMs/VLMs for motion planning, however, faces two key obstacles: (i) symbolic plans are rarely grounded in scene geometry and object physics, and (ii) model outputs can vary for identical prompts, undermining execution reliability. We propose ViReSkill, a framework that pairs vision-grounded replanning with a skill memory for accumulation and reuse. When a failure occurs, the replanner generates a new action sequence conditioned on the current scene, tailored to the observed state. On success, the executed plan is stored as a reusable skill and replayed in future encounters without additional calls to LLMs/VLMs. This feedback loop enables autonomous continual learning: each attempt immediately expands the skill set and stabilizes subsequent executions. We evaluate ViReSkill on simulators such as LIBERO and RLBench as well as on a physical robot. Across all settings, it consistently outperforms conventional baselines in task success rate, demonstrating robust sim-to-real generalization.', 'abstract_zh': '基于视觉的重规划与技能记忆结合的持续学习框架：ViReSkill', 'title_zh': 'ViReSkill: 基于视觉的技能记忆重规划方法在终身机器人学习中面向LLM的规划'}
{'arxiv_id': 'arXiv:2509.24163', 'title': 'Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models', 'authors': 'Wanming Yu, Adrian Röfer, Abhinav Valada, Sethu Vijayakumar', 'link': 'https://arxiv.org/abs/2509.24163', 'abstract': 'Pretrained large language models (LLMs) can work as high-level robotic planners by reasoning over abstract task descriptions and natural language instructions, etc. However, they have shown a lack of knowledge and effectiveness in planning long-horizon robotic manipulation tasks where the physical properties of the objects are essential. An example is the stacking of containers with hidden objects inside, which involves reasoning over hidden physics properties such as weight and stability. To this end, this paper proposes to use multimodal LLMs as high-level planners for such long-horizon robotic stacking tasks. The LLM takes multimodal inputs for each object to stack and infers the current best stacking sequence by reasoning over stacking preferences. Furthermore, in order to enable the LLM to reason over multiple preferences at the same time without giving explicit instructions, we propose to create a custom dataset considering stacking preferences including weight, stability, size, and footprint, to fine-tune the LLM. Compared to the pretrained LLM with prompt tuning, we demonstrate the improved stacking completion of the LLM fine-tuned with our custom dataset via large-scale simulation evaluation. Furthermore, we showcase the effectiveness of the proposed framework for the long-horizon stacking task on a real humanoid robot in an online manner.', 'abstract_zh': '预训练大型语言模型可以作为高级机器人规划者，通过推理抽象的任务描述和自然语言指令等信息。然而，在规划长期 horizon 的机器人操作任务方面，它们在涉及物体物理特性的任务中显示出知识和效果的不足。例如，在含有隐藏物体的集装箱堆叠任务中，需要推理隐藏的物理属性，如重量和稳定性。为此，本文提议使用多模态大型语言模型作为此类长期 horizon 机器人堆叠任务的高级规划者。该语言模型接受每个待堆叠对象的多模态输入，并通过推理堆叠偏好来推断当前最佳的堆叠顺序。此外，为了使语言模型能够在不给出明确指令的情况下同时推理多种偏好，我们提议创建一个包含重量、稳定性、大小和占地面积等堆叠偏好的自定义数据集，以微调大型语言模型。与使用提示调整的预训练大型语言模型相比，我们通过大规模模拟评估展示了使用我们自定义数据集微调后的大型语言模型在堆叠完成方面的改进。此外，我们在线展示了所提议框架在真实人形机器人上的有效性，用于长期 horizon 的堆叠任务。', 'title_zh': '基于偏好远期规划的多模态大型语言模型 Docker 堆叠'}
{'arxiv_id': 'arXiv:2509.24160', 'title': 'Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation', 'authors': 'Tomoyuki Kagaya, Subramanian Lakshmi, Yuxuan Lou, Thong Jing Yuan, Jayashree Karlekar, Sugiri Pranata, Natsuki Murakami, Akira Kinose, Yang You', 'link': 'https://arxiv.org/abs/2509.24160', 'abstract': 'Large language models (LLMs) are increasingly explored in robot manipulation, but many existing methods struggle to adapt to new environments. Many systems require either environment-specific policy training or depend on fixed prompts and single-shot code generation, leading to limited transferability and manual re-tuning. We introduce Memory Transfer Planning (MTP), a framework that leverages successful control-code examples from different environments as procedural knowledge, using them as in-context guidance for LLM-driven planning. Specifically, MTP (i) generates an initial plan and code using LLMs, (ii) retrieves relevant successful examples from a code memory, and (iii) contextually adapts the retrieved code to the target setting for re-planning without updating model parameters. We evaluate MTP on RLBench, CALVIN, and a physical robot, demonstrating effectiveness beyond simulation. Across these settings, MTP consistently improved success rate and adaptability compared with fixed-prompt code generation, naive retrieval, and memory-free re-planning. Furthermore, in hardware experiments, leveraging a memory constructed in simulation proved effective. MTP provides a practical approach that exploits procedural knowledge to realize robust LLM-based planning across diverse robotic manipulation scenarios, enhancing adaptability to novel environments and bridging simulation and real-world deployment.', 'abstract_zh': '大型语言模型（LLMs）在机器人操作中的应用日益增多，但许多现有方法难以适应新环境。我们引入了记忆迁移规划（MTP）框架，该框架利用来自不同环境的成功控制代码示例作为过程性知识，并将其作为上下文指导，用于LLM驱动的规划。具体来说，MTP（i）使用LLM生成初始计划和代码，（ii）从代码记忆中检索相关成功示例，（iii）在不更新模型参数的情况下，上下文适配检索到的代码以适应目标环境进行重新规划。我们在RLBench、CALVIN和物理机器人上评估了MTP，展示了其在仿真之外的有效性。在这些设置中，MTP始终在成功率和适应性方面优于固定提示代码生成、简单检索和无记忆重新规划。此外，在硬件实验中，利用仿真中构建的记忆证明是有效的。MTP提供了一种实用的方法，利用过程性知识在多种机器人操作场景中实现稳健的LLM基规划，增强对新环境的适应性和连接仿真与现实世界部署。', 'title_zh': '记忆传输规划：基于LLM的认知适应代码优化用于机器人操作'}
{'arxiv_id': 'arXiv:2509.24129', 'title': 'Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress', 'authors': 'Priyanka Mandikal, Jiaheng Hu, Shivin Dass, Sagnik Majumder, Roberto Martín-Martín, Kristen Grauman', 'link': 'https://arxiv.org/abs/2509.24129', 'abstract': "Most robot manipulation focuses on changing the kinematic state of objects: picking, placing, opening, or rotating them. However, a wide range of real-world manipulation tasks involve a different class of object state change--such as mashing, spreading, or slicing--where the object's physical and visual state evolve progressively without necessarily changing its position. We present SPARTA, the first unified framework for the family of object state change manipulation tasks. Our key insight is that these tasks share a common structural pattern: they involve spatially-progressing, object-centric changes that can be represented as regions transitioning from an actionable to a transformed state. Building on this insight, SPARTA integrates spatially progressing object change segmentation maps, a visual skill to perceive actionable vs. transformed regions for specific object state change tasks, to generate a) structured policy observations that strip away appearance variability, and b) dense rewards that capture incremental progress over time. These are leveraged in two SPARTA policy variants: reinforcement learning for fine-grained control without demonstrations or simulation; and greedy control for fast, lightweight deployment. We validate SPARTA on a real robot for three challenging tasks across 10 diverse real-world objects, achieving significant improvements in training time and accuracy over sparse rewards and visual goal-conditioned baselines. Our results highlight progress-aware visual representations as a versatile foundation for the broader family of object state manipulation tasks. Project website: this https URL", 'abstract_zh': '一种统一的物体状态变化操作框架：SPARTA', 'title_zh': '压碎、涂抹、切片！通过视觉空间进展学习操控物体状态'}
{'arxiv_id': 'arXiv:2509.23829', 'title': 'DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation', 'authors': 'Kefei Zhu, Fengshuo Bai, YuanHao Xiang, Yishuai Cai, Xinglin Chen, Ruochong Li, Xingtao Wang, Hao Dong, Yaodong Yang, Xiaopeng Fan, Yuanpei Chen', 'link': 'https://arxiv.org/abs/2509.23829', 'abstract': 'Dexterous manipulation is critical for advancing robot capabilities in real-world applications, yet diverse and high-quality datasets remain scarce. Existing data collection methods either rely on human teleoperation or require significant human engineering, or generate data with limited diversity, which restricts their scalability and generalization. In this paper, we introduce DexFlyWheel, a scalable data generation framework that employs a self-improving cycle to continuously enrich data diversity. Starting from efficient seed demonstrations warmup, DexFlyWheel expands the dataset through iterative cycles. Each cycle follows a closed-loop pipeline that integrates Imitation Learning (IL), residual Reinforcement Learning (RL), rollout trajectory collection, and data augmentation. Specifically, IL extracts human-like behaviors from demonstrations, and residual RL enhances policy generalization. The learned policy is then used to generate trajectories in simulation, which are further augmented across diverse environments and spatial configurations before being fed back into the next cycle. Over successive iterations, a self-improving data flywheel effect emerges, producing datasets that cover diverse scenarios and thereby scaling policy performance. Experimental results demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across four challenging tasks. Policies trained on our dataset achieve an average success rate of 81.9\\% on the challenge test sets and successfully transfer to the real world through digital twin, achieving a 78.3\\% success rate on dual-arm lift tasks.', 'abstract_zh': 'DexFlyWheel：一种可扩展的数据生成框架以促进机器人灵巧操作能力的发展', 'title_zh': 'DexFlyWheel: 一种可扩展且自我改进的 Dexterous 操作数据生成框架'}
{'arxiv_id': 'arXiv:2509.23823', 'title': 'Control Your Robot: A Unified System for Robot Control and Policy Deployment', 'authors': 'Tian Nian, Weijie Ke, Yao Mu, Tianxing Chen, Shaolong Zhu, Bingshan Hu', 'link': 'https://arxiv.org/abs/2509.23823', 'abstract': 'Cross-platform robot control remains difficult because hardware interfaces, data formats, and control paradigms vary widely, which fragments toolchains and slows deployment. To address this, we present Control Your Robot, a modular, general-purpose framework that unifies data collection and policy deployment across diverse platforms. The system reduces fragmentation through a standardized workflow with modular design, unified APIs, and a closed-loop architecture. It supports flexible robot registration, dual-mode control with teleoperation and trajectory playback, and seamless integration from multimodal data acquisition to inference. Experiments on single-arm and dual-arm systems show efficient, low-latency data collection and effective support for policy learning with imitation learning and vision-language-action models. Policies trained on data gathered by Control Your Robot match expert demonstrations closely, indicating that the framework enables scalable and reproducible robot learning across platforms.', 'abstract_zh': '跨平台机器人控制仍然困难，因为硬件接口、数据格式和控制范式差异很大，导致工具链碎片化并减缓部署速度。为此，我们提出了一种模块化、通用的框架——Control Your Robot，该框架统一了多种平台的数据采集和策略部署。该系统通过标准化的工作流、模块化设计、统一的API接口和闭环架构来减少碎片化。它支持灵活的机器人注册、远程操作与轨迹回放的双模式控制，并从多模态数据采集无缝集成到推理过程中。实验结果显示，在单臂和双臂系统上的高效、低延迟数据采集以及在模仿学习和视觉-语言-行动模型中的有效策略学习支持。使用Control Your Robot收集的数据训练出的策略能够紧密匹配专家演示，表明该框架使跨平台的机器人学习实现规模化和可重复性成为可能。', 'title_zh': '控制你的机器人：统一的机器人控制与策略部署系统'}
{'arxiv_id': 'arXiv:2509.23821', 'title': 'Fostering Robots: A Governance-First Conceptual Framework for Domestic, Curriculum-Based Trajectory Collection', 'authors': 'Federico Pablo-Marti, Carlos Mir Fernandez', 'link': 'https://arxiv.org/abs/2509.23821', 'abstract': 'We propose a conceptual, empirically testable framework for Robot Fostering, -a curriculum-driven, governance-first approach to domestic robot deployments, emphasizing long-term, curated interaction trajectories. We formalize trajectory quality with quantifiable metrics and evaluation protocols aligned with EU-grade governance standards, delineating a low-resource empirical roadmap to enable rigorous validation through future pilot studies.', 'abstract_zh': '我们提出了一种概念性、可验证的框架，用于机器人培养——一种以课程驱动、治理优先的方法，专注于长期、精心策划的互动轨迹。我们通过与欧盟级治理标准对齐的可量化指标和评估协议，形式化轨迹质量，并划分一个低资源的实证路线图，以通过未来的试点研究实现严格的验证。', 'title_zh': '培育机器人：一种以治理为导向的基于课程的轨迹收集概念框架'}
{'arxiv_id': 'arXiv:2509.23801', 'title': 'High-Precision Climbing Robot Localization Using Planar Array UWB/GPS/IMU/Barometer Integration', 'authors': 'Shuning Zhang, Renjing Xu, Zhanchen Zhu, Xiangyu Chen, Yunheng Wang, Xu Jiang, Peibo Duan', 'link': 'https://arxiv.org/abs/2509.23801', 'abstract': 'To address the need for high-precision localization of climbing robots in complex high-altitude environments, this paper proposes a multi-sensor fusion system that overcomes the limitations of single-sensor approaches. Firstly, the localization scenarios and the problem model are analyzed. An integrated architecture of Attention Mechanism-based Fusion Algorithm (AMFA) incorporating planar array Ultra-Wideband (UWB), GPS, Inertial Measurement Unit (IMU), and barometer is designed to handle challenges such as GPS occlusion and UWB Non-Line-of-Sight (NLOS) problem. Then, End-to-end neural network inference models for UWB and barometer are developed, along with a multimodal attention mechanism for adaptive data fusion. An Unscented Kalman Filter (UKF) is applied to refine the trajectory, improving accuracy and robustness. Finally, real-world experiments show that the method achieves 0.48 m localization accuracy and lower MAX error of 1.50 m, outperforming baseline algorithms such as GPS/INS-EKF and demonstrating stronger robustness.', 'abstract_zh': '基于多传感器融合的攀爬机器人高精度定位系统研究', 'title_zh': '使用平面阵列UWB/GPS/IMU/气压计集成实现高精度爬行机器人定位'}
{'arxiv_id': 'arXiv:2509.23745', 'title': 'LocoFormer: Generalist Locomotion via Long-context Adaptation', 'authors': 'Min Liu, Deepak Pathak, Ananye Agarwal', 'link': 'https://arxiv.org/abs/2509.23745', 'abstract': 'Modern locomotion controllers are manually tuned for specific embodiments. We present LocoFormer, a generalist omni-bodied locomotion model that can control previously unseen legged and wheeled robots, even without precise knowledge of their kinematics. LocoFormer is able to adapt to changes in morphology and dynamics at test time. We find that two key choices enable adaptation. First, we train massive scale RL on procedurally generated robots with aggressive domain randomization. Second, in contrast to previous policies that are myopic with short context lengths, we extend context by orders of magnitude to span episode boundaries. We deploy the same LocoFormer to varied robots and show robust control even with large disturbances such as weight change and motor failures. In extreme scenarios, we see emergent adaptation across episodes, LocoFormer learns from falls in early episodes to improve control strategies in later ones. We believe that this simple, yet general recipe can be used to train foundation models for other robotic skills in the future. Videos at this http URL.', 'abstract_zh': '现代运动控制器是为特定身体手动调优的。我们提出了LocoFormer，这是一种通用型全能身体运动模型，能够控制之前未见过的腿式和轮式机器人，即使没有精确的运动学知识。LocoFormer能够在测试时适应形态和动力学的变化。我们发现两种关键选择使得这种适应成为可能。首先，在生成的机器人上进行大规模强化学习训练，并采用激进的领域随机化。其次，与之前仅具有短视上下文长度的策略不同，我们大幅扩展了上下文，使其跨越整个 episode 边界。我们将相同的LocoFormer部署到多种机器人上，并展示了即便在重量变化和电机故障等大干扰下也能实现鲁棒控制。在极端情况下，LocoFormer表现出跨episode的自适应能力，在早期跌倒中学习以改进后续episode的控制策略。我们相信，这一简单而通用的方法将来可用于训练其他机器人技能的基础模型。视频见此链接。', 'title_zh': 'LocoFormer: 通过长上下文适应实现通用 locomotion'}
{'arxiv_id': 'arXiv:2509.23721', 'title': 'DA-MMP: Learning Coordinated and Accurate Throwing with Dynamics-Aware Motion Manifold Primitives', 'authors': 'Chi Chu, Huazhe Xu', 'link': 'https://arxiv.org/abs/2509.23721', 'abstract': 'Dynamic manipulation is a key capability for advancing robot performance, enabling skills such as tossing. While recent learning-based approaches have pushed the field forward, most methods still rely on manually designed action parameterizations, limiting their ability to produce the highly coordinated motions required in complex tasks. Motion planning can generate feasible trajectories, but the dynamics gap-stemming from control inaccuracies, contact uncertainties, and aerodynamic effects-often causes large deviations between planned and executed trajectories. In this work, we propose Dynamics-Aware Motion Manifold Primitives (DA-MMP), a motion generation framework for goal-conditioned dynamic manipulation, and instantiate it on a challenging real-world ring-tossing task. Our approach extends motion manifold primitives to variable-length trajectories through a compact parametrization and learns a high-quality manifold from a large-scale dataset of planned motions. Building on this manifold, a conditional flow matching model is trained in the latent space with a small set of real-world trials, enabling the generation of throwing trajectories that account for execution dynamics. Experiments show that our method can generate coordinated and smooth motion trajectories for the ring-tossing task. In real-world evaluations, it achieves high success rates and even surpasses the performance of trained human experts. Moreover, it generalizes to novel targets beyond the training range, indicating that it successfully learns the underlying trajectory-dynamics mapping.', 'abstract_zh': '动态感知运动流形基元（DA-MMP）：面向目标条件动态操控的运动生成框架', 'title_zh': 'DA-MMP：具有动力学意识的运动流形基元学习协调和准确的投掷动作'}
{'arxiv_id': 'arXiv:2509.23655', 'title': 'Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models', 'authors': 'Rokas Bendikas, Daniel Dijkman, Markus Peschl, Sanjay Haresh, Pietro Mazzaglia', 'link': 'https://arxiv.org/abs/2509.23655', 'abstract': "Vision-Language-Action (VLA) models offer a pivotal approach to learning robotic manipulation at scale by repurposing large pre-trained Vision-Language-Models (VLM) to output robotic actions. However, adapting VLMs for robotic domains comes with an unnecessarily high computational cost, which we attribute to the tokenization scheme of visual inputs. In this work, we aim to enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric Tokenization for VLAs. Building on the insights of object-centric representation learning, our method introduces an inductive bias towards scene objects and the agent's own visual information. As a result, we find that Oat-VLA can drastically reduce the number of visual tokens to just a few tokens without sacrificing performance. We reveal that Oat-VLA converges at least twice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in diverse real-world pick and place tasks.", 'abstract_zh': '面向物体-代理的分词(Oat-VLA)为VLA模型提供高效训练', 'title_zh': '聚焦关键：面向对象-代理的标记化方法用于视觉语言行动模型'}
{'arxiv_id': 'arXiv:2509.23651', 'title': 'HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot', 'authors': 'Xinrong Yang, Peizhuo Li, Hongyi Li, Junkai Lu, Linnan Chang, Yuhong Cao, Yifeng Zhang, Ge Sun, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2509.23651', 'abstract': "Robots in real-world environments are often required to move/manipulate objects comparable in weight to their own bodies. Compared to grasping and carrying, pushing provides a more straightforward and efficient non-prehensile manipulation strategy, avoiding complex grasp design while leveraging direct contact to regulate an object's pose. Achieving effective pushing, however, demands both sufficient manipulation forces and the ability to maintain stability, which is particularly challenging when dealing with heavy or irregular objects. To address these challenges, we propose HeLoM, a learning-based hierarchical whole-body manipulation framework for a hexapod robot that exploits coordinated multi-limb control. Inspired by the cooperative strategies of multi-legged insects, our framework leverages redundant contact points and high degrees of freedom to enable dynamic redistribution of contact forces. HeLoM's high-level planner plans pushing behaviors and target object poses, while its low-level controller maintains locomotion stability and generates dynamically consistent joint actions. Our policies trained in simulation are directly deployed on real robots without additional fine-tuning. This design allows the robot to maintain balance while exerting continuous and controllable pushing forces through coordinated foreleg interaction and supportive hind-leg propulsion. We validate the effectiveness of HeLoM through both simulation and real-world experiments. Results show that our framework can stably push boxes of varying sizes and unknown physical properties to designated goal poses in the real world.", 'abstract_zh': '六足机器人在冗余接触点和高自由度的利用下实现高效动态推举策略：HeLoM框架', 'title_zh': 'HeLoM: 分级学习在六足机器人全身移动物体中的应用'}
{'arxiv_id': 'arXiv:2509.23650', 'title': 'KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion', 'authors': 'Peizhuo Li, Hongyi Li, Yuxuan Ma, Linnan Chang, Xinrong Yang, Ruiqi Yu, Yifeng Zhang, Yuhong Cao, Qiuguo Zhu, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2509.23650', 'abstract': 'Vision-based locomotion has shown great promise in enabling legged robots to perceive and adapt to complex environments. However, visual information is inherently fragile, being vulnerable to occlusions, reflections, and lighting changes, which often cause instability in locomotion. Inspired by animal sensorimotor integration, we propose KiVi, a Kinesthetic-Visuospatial integration framework, where kinesthetics encodes proprioceptive sensing of body motion and visuospatial reasoning captures visual perception of surrounding terrain. Specifically, KiVi separates these pathways, leveraging proprioception as a stable backbone while selectively incorporating vision for terrain awareness and obstacle avoidance. This modality-balanced, yet integrative design, combined with memory-enhanced attention, allows the robot to robustly interpret visual cues while maintaining fallback stability through proprioception. Extensive experiments show that our method enables quadruped robots to stably traverse diverse terrains and operate reliably in unstructured outdoor environments, remaining robust to out-of-distribution (OOD) visual noise and occlusion unseen during training, thereby highlighting its effectiveness and applicability to real-world legged locomotion.', 'abstract_zh': '基于视觉的运动控制在使腿式机器人感知和适应复杂环境方面展现了巨大潜力。然而，视觉信息本质上是脆弱的，容易受到遮挡、反射和光照变化的影响，这往往会引起运动不稳定性。受动物感觉运动整合的启发，我们提出KiVi，一种运动感知识觉与空间视觉整合框架，其中运动感知识觉编码身体运动的本体感觉，而空间视觉推理捕捉周围地形的视觉感知。具体来说，KiVi 分离了这些途径，利用本体感觉作为稳定的支撑，同时选择性地融入视觉以增强地形意识和障碍物避让能力。这种多模态平衡但又整合的设计，结合增强的记忆注意力机制，使机器人能够在利用视觉提示的同时，通过本体感觉维持退化稳定性。广泛的实验表明，我们的方法使四足机器人能够稳定地穿越各种地形，并可靠地在未结构化的户外环境中操作，对训练期间未见过的分布外（OOD）的视觉噪声和遮挡保持鲁棒性，从而突显了其在实际腿式运动中的有效性和适用性。', 'title_zh': 'KiVi: 动觉-视空整合技术用于动态和安全的自我中心腿足运动'}
{'arxiv_id': 'arXiv:2509.23575', 'title': 'Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints', 'authors': 'Jianshu Hu, Lidi Wang, Shujia Li, Yunpeng Jiang, Xiao Li, Paul Weng, Yutong Ban', 'link': 'https://arxiv.org/abs/2509.23575', 'abstract': 'Hierarchical coarse-to-fine policy, where a coarse branch predicts a region of interest to guide a fine-grained action predictor, has demonstrated significant potential in robotic 3D manipulation tasks by especially enhancing sample efficiency and enabling more precise manipulation. However, even augmented with pre-trained models, these hierarchical policies still suffer from generalization issues. To enhance generalization to novel instructions and environment variations, we propose Coarse-to-fine Language-Aligned manipulation Policy (CLAP), a framework that integrates three key components: 1) task decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware representation. Through comprehensive experiments in simulation and on a real robot, we demonstrate its superior generalization capability. Specifically, on GemBench, a benchmark designed for evaluating generalization, our approach achieves a 12\\% higher average success rate than the SOTA method while using only 1/5 of the training trajectories. In real-world experiments, our policy, trained on only 10 demonstrations, successfully generalizes to novel instructions and environments.', 'abstract_zh': '从粗到细语言对齐操纵策略（CLAP）：一种结合任务拆解、VLM微调和三维aware表示的框架', 'title_zh': '基于语言对齐3D关键点的可泛化粗细粒度机器人操作方法'}
{'arxiv_id': 'arXiv:2509.23563', 'title': 'RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation', 'authors': 'Seungchan Kim, Omar Alama, Dmytro Kurdydyk, John Keller, Nikhil Keetha, Wenshan Wang, Yonatan Bisk, Sebastian Scherer', 'link': 'https://arxiv.org/abs/2509.23563', 'abstract': 'Aerial outdoor semantic navigation requires robots to explore large, unstructured environments to locate target objects. Recent advances in semantic navigation have demonstrated open-set object-goal navigation in indoor settings, but these methods remain limited by constrained spatial ranges and structured layouts, making them unsuitable for long-range outdoor search. While outdoor semantic navigation approaches exist, they either rely on reactive policies based on current observations, which tend to produce short-sighted behaviors, or precompute scene graphs offline for navigation, limiting adaptability to online deployment. We present RAVEN, a 3D memory-based, behavior tree framework for aerial semantic navigation in unstructured outdoor environments. It (1) uses a spatially consistent semantic voxel-ray map as persistent memory, enabling long-horizon planning and avoiding purely reactive behaviors, (2) combines short-range voxel search and long-range ray search to scale to large environments, (3) leverages a large vision-language model to suggest auxiliary cues, mitigating sparsity of outdoor targets. These components are coordinated by a behavior tree, which adaptively switches behaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor simulation environments over 100 semantic tasks, encompassing single-object search, multi-class, multi-instance navigation and sequential task changes. Results show RAVEN outperforms baselines by 85.25% in simulation and demonstrate its real-world applicability through deployment on an aerial robot in outdoor field tests.', 'abstract_zh': '基于空中环境的户外语义导航要求机器人探索大型非结构化环境以定位目标物体。最近在语义导航方面的进展展示了室内环境下的开放集合语义导航，但这些方法仍受限于有限的空间范围和结构化布局，使其不适合进行远程户外搜索。虽然存在户外语义导航方法，但它们要么依赖于基于当前观察的反应策略，容易产生短视行为，要么需要提前在线下计算场景图以进行导航，限制了其在线部署的适应性。我们提出了RAVEN，一种基于3D记忆的行为树框架，用于非结构化户外环境的语义导航。(1) 使用空间一致的语义体素射线图作为持久性记忆，实现长期规划并避免完全反应性行为；(2) 结合短距离体素搜索和长距离射线搜索，以适应大型环境；(3) 利用大规模的视觉语言模型提出辅助线索，缓解户外目标稀疏性。这些组件由行为树协调，能够自适应切换行为以实现稳健操作。我们通过在10个逼真的户外仿真环境中执行100个语义任务来评估RAVEN，包括单对象搜索、多类多实例导航以及顺序任务变化。结果表明，RAVEN在仿真中的性能优于基线85.25%，并通过在户外实地测试中部署到空中机器人上展示了其实用性。', 'title_zh': 'RAVEN：基于开放集语义记忆和行为适应的鲁棒航空导航'}
{'arxiv_id': 'arXiv:2509.23308', 'title': 'Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment', 'authors': 'Jun Chen, Jiaqing Ma, Philip Dames', 'link': 'https://arxiv.org/abs/2509.23308', 'abstract': "In unknown non-convex environments, such as indoor and underground spaces, deploying a fleet of robots to explore the surroundings while simultaneously searching for and tracking targets of interest to maintain high-precision data collection represents a fundamental challenge that urgently requires resolution in applications such as environmental monitoring and rescue operations. Current research has made significant progress in addressing environmental exploration, information search, and target tracking problems, but has yet to establish a framework for simultaneously optimizing these tasks in complex environments. In this paper, we propose a novel motion planning algorithm framework that integrates three control strategies: a frontier-based exploration strategy, a guaranteed coverage strategy based on Lloyd's algorithm, and a sensor-based multi-target tracking strategy. By incorporating these three strategies, the proposed algorithm balances coverage search and high-precision active tracking during exploration. Our approach is validated through a series of MATLAB simulations, demonstrating validity and superiority over standard approaches.", 'abstract_zh': '在未知非凸环境中，如室内和地下空间，部署机器人队列以同时探索环境、搜索和跟踪目标以维持高精度数据采集，是环境监测和救援操作等领域面临的基本挑战，亟待解决。当前研究在环境探索、信息搜索和目标跟踪方面取得了显著进展，但尚未建立同时优化这些任务的框架。本文提出了一种新的运动规划算法框架，结合了三种控制策略：基于边界的探索策略、基于Lloyd算法的保证覆盖策略以及基于传感器的多目标跟踪策略。通过结合这三种策略，所提出的算法在探索过程中平衡了覆盖搜索和高精度主动跟踪。我们的方法通过一系列MATLAB仿真得到验证，显示出比标准方法的有效性和优越性。', 'title_zh': '未知非凸环境中的分布式多机器人多目标同时搜索与跟踪'}
{'arxiv_id': 'arXiv:2509.23281', 'title': 'Preventing Robotic Jailbreaking via Multimodal Domain Adaptation', 'authors': 'Francesco Marchiori, Rohan Sinha, Christopher Agia, Alexander Robey, George J. Pappas, Mauro Conti, Marco Pavone', 'link': 'https://arxiv.org/abs/2509.23281', 'abstract': 'Large Language Models (LLMs) and Vision-Language Models (VLMs) are increasingly deployed in robotic environments but remain vulnerable to jailbreaking attacks that bypass safety mechanisms and drive unsafe or physically harmful behaviors in the real world. Data-driven defenses such as jailbreak classifiers show promise, yet they struggle to generalize in domains where specialized datasets are scarce, limiting their effectiveness in robotics and other safety-critical contexts. To address this gap, we introduce J-DAPT, a lightweight framework for multimodal jailbreak detection through attention-based fusion and domain adaptation. J-DAPT integrates textual and visual embeddings to capture both semantic intent and environmental grounding, while aligning general-purpose jailbreak datasets with domain-specific reference data. Evaluations across autonomous driving, maritime robotics, and quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100% with minimal overhead. These results demonstrate that J-DAPT provides a practical defense for securing VLMs in robotic applications. Additional materials are made available at: this https URL.', 'abstract_zh': '大型语言模型(LLMs)和视觉-语言模型(VLMs)在越来越多的机器人环境中得到部署，但仍然容易遭受越狱攻击，这些攻击 bypass 安全机制，导致现实世界中的不安全或物理上有害行为。数据驱动的防御措施如越狱分类器显示出了潜力，但在缺乏专门数据集的领域中难以泛化，限制了其在机器人和其他安全性关键领域的有效性。为了解决这一问题，我们引入了J-DAPT，一种基于注意力融合和领域适应的轻量级多模态越狱检测框架。J-DAPT 结合文本和视觉嵌入，捕捉语义意图和环境基础，同时将通用越狱数据集与特定领域的参考数据对齐。在自动驾驶、海洋机器人和四足导航等领域的评估表明，J-DAPT 在几乎不增加开销的情况下将检测准确性提升至接近100%。这些结果证明了 J-DAPT 提供了在机器人应用中保护 VLMs 的实用防御方法。更多材料参见: this https URL。', 'title_zh': '防止机器人越狱的多模态领域适应方法'}
{'arxiv_id': 'arXiv:2509.23224', 'title': 'Leave No Observation Behind: Real-time Correction for VLA Action Chunks', 'authors': 'Kohei Sendai, Maxime Alvarez, Tatsuya Matsushima, Yutaka Matsuo, Yusuke Iwasawa', 'link': 'https://arxiv.org/abs/2509.23224', 'abstract': "To improve efficiency and temporal coherence, Vision-Language-Action (VLA) models often predict action chunks; however, this action chunking harms reactivity under inference delay and long horizons. We introduce Asynchronous Action Chunk Correction (A2C2), which is a lightweight real-time chunk correction head that runs every control step and adds a time-aware correction to any off-the-shelf VLA's action chunk. The module combines the latest observation, the predicted action from VLA (base action), a positional feature that encodes the index of the base action within the chunk, and some features from the base policy, then outputs a per-step correction. This preserves the base model's competence while restoring closed-loop responsiveness. The approach requires no retraining of the base policy and is orthogonal to asynchronous execution schemes such as Real Time Chunking (RTC). On the dynamic Kinetix task suite (12 tasks) and LIBERO Spatial, our method yields consistent success rate improvements across increasing delays and execution horizons (+23% point and +7% point respectively, compared to RTC), and also improves robustness for long horizons even with zero injected delay. Since the correction head is small and fast, there is minimal overhead compared to the inference of large VLA models. These results indicate that A2C2 is an effective, plug-in mechanism for deploying high-capacity chunking policies in real-time control.", 'abstract_zh': '异步动作块修正（A2C2）：一种轻量级实时动作块修正头', 'title_zh': '不留任何观测数据于身后: 实时修正VLA动作块'}
{'arxiv_id': 'arXiv:2509.23223', 'title': 'SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion', 'authors': 'Aoqian Zhang, Zixuan Zhuang, Chunzheng Wang, Shuzhi Sam Ge, Fan Shi, Cheng Xiang', 'link': 'https://arxiv.org/abs/2509.23223', 'abstract': 'Quadruped robots are designed to achieve agile locomotion by mimicking legged animals. However, existing control methods for quadrupeds often lack one of the key capabilities observed in animals: adaptive and adjustable compliance in response to external disturbances. Most locomotion controllers do not provide tunable compliance and tend to fail under large perturbations. In this work, we propose a switched policy framework for compliant and safe quadruped locomotion. First, we train a force compliant policy with adjustable compliance levels using a teacher student reinforcement learning framework, eliminating the need for explicit force sensing. Next, we develop a safe policy based on the capture point concept to stabilize the robot when the compliant policy fails. Finally, we introduce a recoverability network that predicts the likelihood of failure and switches between the compliant and safe policies. Together, this framework enables quadruped robots to achieve both force compliance and robust safety when subjected to severe external disturbances.', 'abstract_zh': '四足机器人通过模仿-legged动物的设计来实现敏捷移动。然而，现有的四足机器人控制方法往往缺乏一类关键能力：在面对外部干扰时能够表现出适应性和可调节的柔顺性。大多数运动控制器不具备可调节的柔顺性，容易在遭受较大扰动时失效。本文提出了一种切换策略框架以实现柔顺且安全的四足机器人移动。首先，使用教师学生强化学习框架训练一个具有可调节柔顺性的力柔顺策略，消除显式力感知的需要。其次，基于捕获点概念开发一个安全策略，以在力柔顺策略失效时稳定机器人。最后，引入一个恢复网络预测失败的可能性，并在力柔顺策略和安全策略之间切换。该框架使四足机器人在遭受严重外部干扰时既能实现力柔顺性，又能确保鲁棒安全性。', 'title_zh': 'SAC-Loco: 安全可调的 compliant 四足行走'}
{'arxiv_id': 'arXiv:2509.23203', 'title': 'CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation', 'authors': 'Kai Yang, Tianlin Zhang, Zhengbo Wang, Zedong Chu, Xiaolong Wu, Yang Cai, Mu Xu', 'link': 'https://arxiv.org/abs/2509.23203', 'abstract': 'Generalizing local navigation policies across diverse robot morphologies is a critical challenge. Progress is often hindered by the need for costly and embodiment-specific data, the tight coupling of planning and control, and the "disastrous averaging" problem where deterministic models fail to capture multi-modal decisions (e.g., turning left or right). We introduce CE-Nav, a novel two-stage (IL-then-RL) framework that systematically decouples universal geometric reasoning from embodiment-specific dynamic adaptation. First, we train an embodiment-agnostic General Expert offline using imitation learning. This expert, a conditional normalizing flow model named VelFlow, learns the full distribution of kinematically-sound actions from a large-scale dataset generated by a classical planner, completely avoiding real robot data and resolving the multi-modality issue. Second, for a new robot, we freeze the expert and use it as a guiding prior to train a lightweight, Dynamics-Aware Refiner via online reinforcement learning. This refiner rapidly learns to compensate for the target robot\'s specific dynamics and controller imperfections with minimal environmental interaction. Extensive experiments on quadrupeds, bipeds, and quadrotors show that CE-Nav achieves state-of-the-art performance while drastically reducing adaptation cost. Successful real-world deployments further validate our approach as an efficient and scalable solution for building generalizable navigation systems.', 'abstract_zh': '跨多样化机器人形态泛化局部导航策略是一项关键挑战。我们提出了CE-Nav，一种新颖的两阶段（IL-then-RL）框架，系统地解耦了通用几何推理与体现特定的动力学适应。首先，我们使用 imitation learning 在离线模式下训练一个体现无关的通用专家。该专家是一个名为 VelFlow 的条件归一化流模型，从由经典规划器生成的大规模数据集中学习全动作的分布，完全避免了真实机器人数据并解决了多模态问题。其次，对于一个新的机器人，我们冻结专家并将其用作引导先验，通过在线强化学习训练一个轻量级的动力学感知修整器。该修整器能够快速学习补偿目标机器人特定动力学和控制器缺陷，同时减少环境交互。在四足机器人、两足机器人和四旋翼无人机上的 extensively 实验显示，CE-Nav 达到了最先进的性能，大幅减少了适应成本。成功的真实世界部署进一步验证了我们方法作为一种高效且可扩展的通用导航系统构建解决方案的有效性。', 'title_zh': 'CE-Nav: 流向引导的跨体态局部导航强化学习精炼'}
{'arxiv_id': 'arXiv:2509.23185', 'title': 'Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion', 'authors': 'Ziyi Zhou, Qian Meng, Hadas Kress-Gazit, Ye Zhao', 'link': 'https://arxiv.org/abs/2509.23185', 'abstract': "We present an integrated planning framework for quadrupedal locomotion over dynamically changing, unforeseen terrains. Existing methods often depend on heuristics for real-time foothold selection-limiting robustness and adaptability-or rely on computationally intensive trajectory optimization across complex terrains and long horizons. In contrast, our approach combines reactive synthesis for generating correct-by-construction symbolic-level controllers with mixed-integer convex programming (MICP) for dynamic and physically feasible footstep planning during each symbolic transition. To reduce the reliance on costly MICP solves and accommodate specifications that may be violated due to physical infeasibility, we adopt a symbolic repair mechanism that selectively generates only the required symbolic transitions. During execution, real-time MICP replanning based on actual terrain data, combined with runtime symbolic repair and delay-aware coordination, enables seamless bridging between offline synthesis and online operation. Through extensive simulation and hardware experiments, we validate the framework's ability to identify missing locomotion skills and respond effectively in safety-critical environments, including scattered stepping stones and rebar scenarios.", 'abstract_zh': '一种用于动态变化未预见地形下四足运动综合规划框架', 'title_zh': '地形自适应运动的物理可行反应合成'}
{'arxiv_id': 'arXiv:2509.23155', 'title': 'LAGEA: Language Guided Embodied Agents for Robotic Manipulation', 'authors': 'Abdul Monaf Chowdhury, Akm Moshiur Rahman Mazumder, Rabeya Akter, Safaeid Hossain Arib', 'link': 'https://arxiv.org/abs/2509.23155', 'abstract': "Robotic manipulation benefits from foundation models that describe goals, but today's agents still lack a principled way to learn from their own mistakes. We ask whether natural language can serve as feedback, an error reasoning signal that helps embodied agents diagnose what went wrong and correct course. We introduce LAGEA (Language Guided Embodied Agents), a framework that turns episodic, schema-constrained reflections from a vision language model (VLM) into temporally grounded guidance for reinforcement learning. LAGEA summarizes each attempt in concise language, localizes the decisive moments in the trajectory, aligns feedback with visual state in a shared representation, and converts goal progress and feedback agreement into bounded, step-wise shaping rewardswhose influence is modulated by an adaptive, failure-aware coefficient. This design yields dense signals early when exploration needs direction and gracefully recedes as competence grows. On the Meta-World MT10 embodied manipulation benchmark, LAGEA improves average success over the state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed goals, while converging faster. These results support our hypothesis: language, when structured and grounded in time, is an effective mechanism for teaching robots to self-reflect on mistakes and make better choices. Code will be released soon.", 'abstract_zh': '基于自然语言反馈的机器人操作改进框架', 'title_zh': '语言引导的实体代理用于机器人操作'}
{'arxiv_id': 'arXiv:2509.23112', 'title': 'FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task', 'authors': 'Ryo Watanabe, Maxime Alvarez, Pablo Ferreiro, Pavel Savkin, Genki Sano', 'link': 'https://arxiv.org/abs/2509.23112', 'abstract': 'Manipulator robots are increasingly being deployed in retail environments, yet contact rich edge cases still trigger costly human teleoperation. A prominent example is upright lying beverage bottles, where purely visual cues are often insufficient to resolve subtle contact events required for precise manipulation. We present a multimodal Imitation Learning policy that augments the Action Chunking Transformer with force and torque sensing, enabling end-to-end learning over images, joint states, and forces and torques. Deployed on Ghost, single-arm platform by Telexistence Inc, our approach improves Pick-and-Reorient bottle task by detecting and exploiting contact transitions during pressing and placement. Hardware experiments demonstrate greater task success compared to baseline matching the observation space of ACT as an ablation and experiments indicate that force and torque signals are beneficial in the press and place phases where visual observability is limited, supporting the use of interaction forces as a complementary modality for contact rich skills. The results suggest a practical path to scaling retail manipulation by combining modern imitation learning architectures with lightweight force and torque sensing.', 'abstract_zh': 'manipulator机器人在零售环境中越来越多地被部署，但在接触丰富的边缘案例中，仍然会触发成本高昂的人类远程操作。一个典型的例子是直立躺着的饮料瓶，其中纯粹的视觉线索往往不足以解决精确操作所需的微妙接触事件。我们提出了一种多模态模仿学习策略，将动作分块变换器与力和扭矩感知相结合，实现了从图像、关节状态和力及扭矩的端到端学习。该方法部署在Telexistence Inc的单臂平台Ghost上，通过检测和利用压放和放置过程中的接触转换，提高了拿取并重新定向瓶子任务的成功率。硬件实验表明，在视觉可观察性受限的压放阶段，力和扭矩信号有助于提高任务成功率，支持将交互力作为接触丰富技能的补充模态。结果表明，通过结合现代模仿学习架构和轻量级力和扭矩感知，可以实现零售操作的可扩展路径。', 'title_zh': 'FTACT: 带有力和扭矩意识的动作片段变换器用于捡取并重新定向瓶子任务'}
{'arxiv_id': 'arXiv:2509.23107', 'title': 'Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning', 'authors': 'Yi Wang, Zeyu Xue, Mujie Liu, Tongqin Zhang, Yan Hu, Zhou Zhao, Chenguang Yang, Zhenyu Lu', 'link': 'https://arxiv.org/abs/2509.23107', 'abstract': 'Teleoperation via natural-language reduces operator workload and enhances safety in high-risk or remote settings. However, in dynamic remote scenes, transmission latency during bidirectional communication creates gaps between remote perceived states and operator intent, leading to command misunderstanding and incorrect execution. To mitigate this, we introduce the Spatio-Temporal Open-Vocabulary Scene Graph (ST-OVSG), a representation that enriches open-vocabulary perception with temporal dynamics and lightweight latency annotations. ST-OVSG leverages LVLMs to construct open-vocabulary 3D object representations, and extends them into the temporal domain via Hungarian assignment with our temporal matching cost, yielding a unified spatio-temporal scene graph. A latency tag is embedded to enable LVLM planners to retrospectively query past scene states, thereby resolving local-remote state mismatches caused by transmission delays. To further reduce redundancy and highlight task-relevant cues, we propose a task-oriented subgraph filtering strategy that produces compact inputs for the planner. ST-OVSG generalizes to novel categories and enhances planning robustness against transmission latency without requiring fine-tuning. Experiments show that our method achieves 74 percent node accuracy on the Replica benchmark, outperforming ConceptGraph. Notably, in the latency-robustness experiment, the LVLM planner assisted by ST-OVSG achieved a planning success rate of 70.5 percent.', 'abstract_zh': '自然语言介导的遥控减少操作员工作负荷并提升高风险或远程环境中的安全性。然而，在动态远程场景中，双向通信过程中的传输延迟会导致远程感知状态与操作员意图之间的差距，进而导致指令误解和错误执行。为缓解这一问题，我们引入了时空开放词汇场景图（ST-OVSG），这是一种能够通过引入时间动态和轻量级延迟注释来丰富开放词汇感知的表现形式。ST-OVSG 利用低级视觉语言模型（LVLM）构建开放词汇的3D对象表示，并通过我们的时间匹配成本和匈牙利指派将其扩展到时间领域，从而生成统一的时空场景图。嵌入了一个延迟标签，使LVLM规划器能够回顾性地查询过去的状态，从而解决由传输延迟引起的局部-远程状态不匹配问题。为了进一步减少冗余并突出任务相关线索，我们提出了一种任务导向的子图过滤策略，以生成更适合规划器的紧凑输入。ST-OVSG 具备泛化到新类别并增强对传输延迟的规划鲁棒性而不需微调的能力。实验结果显示，我们的方法在Replica基准测试中实现了74%的节点准确性，超越了ConceptGraph。值得注意的是，在传输延迟稳健性实验中，辅以ST-OVSG的LVLM规划器的规划成功率为70.5%。', 'title_zh': '具有开放词汇量的空间-时间场景图在机器人感知与远程操作规划中的应用'}
{'arxiv_id': 'arXiv:2509.23075', 'title': 'In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer', 'authors': 'Soofiyan Atar, Daniel Huang, Florian Richter, Michael Yip', 'link': 'https://arxiv.org/abs/2509.23075', 'abstract': "Reinforcement learning (RL) and sim-to-real transfer have advanced robotic manipulation of rigid objects. Yet, policies remain brittle when applied to articulated mechanisms due to contact-rich dynamics and under-modeled joint phenomena such as friction, stiction, backlash, and clearances. We address this challenge through dexterous in-hand manipulation of articulated tools using a robotic hand with reduced articulation and kinematic redundancy relative to the human hand. Our controller augments a simulation-trained base policy with a sensor-driven refinement learned from hardware demonstrations, conditioning on proprioception and target articulation states while fusing whole-hand tactile and force feedback with the policy's internal action intent via cross-attention-based integration. This design enables online adaptation to instance-specific articulation properties, stabilizes contact interactions, regulates internal forces, and coordinates coupled-link motion under perturbations. We validate our approach across a diversity of real-world examples, including scissors, pliers, minimally invasive surgical tools, and staplers. We achieve robust transfer from simulation to hardware, improved disturbance resilience, and generalization to previously unseen articulated tools, thereby reducing reliance on precise physical modeling in contact-rich settings.", 'abstract_zh': '基于灵巧的在手操纵的类人手机器人手在附着机制上的强化学习和仿真实验到现实应用', 'title_zh': '灵巧机器人手进行有骨架工具的在手操作与仿真实验到实际应用的转移'}
{'arxiv_id': 'arXiv:2509.23021', 'title': 'UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes', 'authors': 'Xiao Hu, Qi Yin, Yangming Shi, Yang Ye', 'link': 'https://arxiv.org/abs/2509.23021', 'abstract': 'Data scarcity remains a fundamental challenge in robot learning. While human demonstrations benefit from abundant motion capture data and vast internet resources, robotic manipulation suffers from limited training examples. To bridge this gap between human and robot manipulation capabilities, we propose UniPrototype, a novel framework that enables effective knowledge transfer from human to robot domains via shared motion primitives. ur approach makes three key contributions: (1) We introduce a compositional prototype discovery mechanism with soft assignments, enabling multiple primitives to co-activate and thus capture blended and hierarchical skills; (2) We propose an adaptive prototype selection strategy that automatically adjusts the number of prototypes to match task complexity, ensuring scalable and efficient representation; (3) We demonstrate the effectiveness of our method through extensive experiments in both simulation environments and real-world robotic systems. Our results show that UniPrototype successfully transfers human manipulation knowledge to robots, significantly improving learning efficiency and task performance compared to existing this http URL code and dataset will be released upon acceptance at an anonymous repository.', 'abstract_zh': '数据稀缺依然是机器人学习中的一个根本性挑战。尽管人类演示可以从丰富的动作捕捉数据和广泛的互联网资源中受益，机器人操控却面临训练样本有限的问题。为缩小人类与机器人操控能力之间的差距，我们提出了UniPrototype，一种新颖的框架，通过共享运动基本要素实现从人类到机器人的有效知识迁移。我们的方法做出了三项关键贡献：(1) 引入了一种具有软指派的组合原型发现机制，使多个基本要素能够协同激活，从而捕捉融合技能和层级技能；(2) 提出了一种自适应原型选择策略，自动调整原型的数量以匹配任务复杂度，确保可扩展和高效的表示；(3) 通过在仿真环境和真实世界机器人系统中的大量实验展示了我们方法的有效性。我们的结果显示，UniPrototype 成功地将人类操控知识转移到机器人上，与现有方法相比，显著提高了学习效率和任务性能。接受投稿后，代码和数据集将匿名发布于公开仓库。', 'title_zh': 'UniPrototype：人类-机器人技能学习的统一原型'}
{'arxiv_id': 'arXiv:2509.22970', 'title': 'Robot Learning from Any Images', 'authors': 'Siheng Zhao, Jiageng Mao, Wei Chow, Zeyu Shangguan, Tianheng Shi, Rong Xue, Yuxi Zheng, Yijia Weng, Yang You, Daniel Seita, Leonidas Guibas, Sergey Zakharov, Vitor Guizilini, Yue Wang', 'link': 'https://arxiv.org/abs/2509.22970', 'abstract': "We introduce RoLA, a framework that transforms any in-the-wild image into an interactive, physics-enabled robotic environment. Unlike previous methods, RoLA operates directly on a single image without requiring additional hardware or digital assets. Our framework democratizes robotic data generation by producing massive visuomotor robotic demonstrations within minutes from a wide range of image sources, including camera captures, robotic datasets, and Internet images. At its core, our approach combines a novel method for single-view physical scene recovery with an efficient visual blending strategy for photorealistic data collection. We demonstrate RoLA's versatility across applications like scalable robotic data generation and augmentation, robot learning from Internet images, and single-image real-to-sim-to-real systems for manipulators and humanoids. Video results are available at this https URL .", 'abstract_zh': 'RoLA：一种将任意现实世界图像转换为互动物理-enabled机器人环境的框架', 'title_zh': '机器人从任意图像学习'}
{'arxiv_id': 'arXiv:2509.22910', 'title': 'Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM', 'authors': 'Yanwei Du, Jing-Chen Peng, Patricio A. Vela', 'link': 'https://arxiv.org/abs/2509.22910', 'abstract': 'Given that Visual SLAM relies on appearance cues for localization and scene understanding, texture-less or visually degraded environments (e.g., plain walls or low lighting) lead to poor pose estimation and track loss. However, robots are typically equipped with sensors that provide some form of dead reckoning odometry with reasonable short-time performance but unreliable long-time performance. The Good Weights (GW) algorithm described here provides a framework to adaptively integrate dead reckoning (DR) with passive visual SLAM for continuous and accurate frame-level pose estimation. Importantly, it describes how all modules in a comprehensive SLAM system must be modified to incorporate DR into its design. Adaptive weighting increases DR influence when visual tracking is unreliable and reduces when visual feature information is strong, maintaining pose track without overreliance on DR. Good Weights yields a practical solution for mobile navigation that improves visual SLAM performance and robustness. Experiments on collected datasets and in real-world deployment demonstrate the benefits of Good Weights.', 'abstract_zh': '视觉SLAM中基于纹理的适应性融合方法提高移动导航性能和鲁棒性', 'title_zh': '好的权重：主动适配的航位推算融合算法以实现连续可靠的视觉SLAM'}
{'arxiv_id': 'arXiv:2509.22825', 'title': 'Parameter Identification of a Differentiable Human Arm Musculoskeletal Model without Deep Muscle EMG Reconstruction', 'authors': 'Philip Sanderink, Yingfan Zhou, Shuzhen Luo, Cheng Fang', 'link': 'https://arxiv.org/abs/2509.22825', 'abstract': 'Accurate parameter identification of a subject-specific human musculoskeletal model is crucial to the development of safe and reliable physically collaborative robotic systems, for instance, assistive exoskeletons. Electromyography (EMG)-based parameter identification methods have demonstrated promising performance for personalized musculoskeletal modeling, whereas their applicability is limited by the difficulty of measuring deep muscle EMGs invasively. Although several strategies have been proposed to reconstruct deep muscle EMGs or activations for parameter identification, their reliability and robustness are limited by assumptions about the deep muscle behavior. In this work, we proposed an approach to simultaneously identify the bone and superficial muscle parameters of a human arm musculoskeletal model without reconstructing the deep muscle EMGs. This is achieved by only using the least-squares solution of the deep muscle forces to calculate a loss gradient with respect to the model parameters for identifying them in a framework of differentiable optimization. The results of extensive comparative simulations manifested that our proposed method can achieve comparable estimation accuracy compared to a similar method, but with all the muscle EMGs available.', 'abstract_zh': '基于最少二乘解的人体上肢 musculoskeletal 模型骨和浅表肌肉参数的同时精准识别', 'title_zh': '无需深入肌电图重建的可微人类手臂肌骨模型参数识别'}
{'arxiv_id': 'arXiv:2509.22815', 'title': 'Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots', 'authors': 'Ruturaj Sambhus, Muneeb Ahmad, Basit Muhammad Imran, Sujith Vijayan, Dylan P. Losey, Kaveh Akbari Hamed', 'link': 'https://arxiv.org/abs/2509.22815', 'abstract': 'Ensuring safe and effective collaboration between humans and autonomous legged robots is a fundamental challenge in shared autonomy, particularly for teleoperated systems navigating cluttered environments. Conventional shared-control approaches often rely on fixed blending strategies that fail to capture the dynamics of legged locomotion and may compromise safety. This paper presents a teleoperator-aware, safety-critical, adaptive nonlinear model predictive control (ANMPC) framework for shared autonomy of quadrupedal robots in obstacle-avoidance tasks. The framework employs a fixed arbitration weight between human and robot actions but enhances this scheme by modeling the human input with a noisily rational Boltzmann model, whose parameters are adapted online using a projected gradient descent (PGD) law from observed joystick commands. Safety is enforced through control barrier function (CBF) constraints integrated into a computationally efficient NMPC, ensuring forward invariance of safe sets despite uncertainty in human behavior. The control architecture is hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz) enforces reduced-order single rigid body (SRB) dynamics to track these references, and a low-level nonlinear whole-body controller (500 Hz) imposes the full-order dynamics via quadratic programming to track the mid-level trajectories. Extensive numerical and hardware experiments, together with a user study, on a Unitree Go2 quadrupedal robot validate the framework, demonstrating real-time obstacle avoidance, online learning of human intent parameters, and safe teleoperator collaboration.', 'abstract_zh': '确保腿式自主机器人与人类在受电信号操作系统中在杂乱环境下的安全有效协作是共享自主性中的一个基本挑战。本文提出了一种适用于四足机器人避障任务的电信操縱员意识安全关键自适应非线性模型预测控制框架。', 'title_zh': '面向遥控操作员的安全关键自适应非线性模型预测控制在腿式机器人障碍避险中的共享自主控制'}
{'arxiv_id': 'arXiv:2509.22698', 'title': 'Advancing Audio-Visual Navigation Through Multi-Agent Collaboration in 3D Environments', 'authors': 'Hailong Zhang, Yinfeng Yu, Liejun Wang, Fuchun Sun, Wendong Zheng', 'link': 'https://arxiv.org/abs/2509.22698', 'abstract': "Intelligent agents often require collaborative strategies to achieve complex tasks beyond individual capabilities in real-world scenarios. While existing audio-visual navigation (AVN) research mainly focuses on single-agent systems, their limitations emerge in dynamic 3D environments where rapid multi-agent coordination is critical, especially for time-sensitive applications like emergency response. This paper introduces MASTAVN (Multi-Agent Scalable Transformer Audio-Visual Navigation), a scalable framework enabling two agents to collaboratively localize and navigate toward an audio target in shared 3D environments. By integrating cross-agent communication protocols and joint audio-visual fusion mechanisms, MASTAVN enhances spatial reasoning and temporal synchronization. Through rigorous evaluation in photorealistic 3D simulators (Replica and Matterport3D), MASTAVN achieves significant reductions in task completion time and notable improvements in navigation success rates compared to single-agent and non-collaborative baselines. This highlights the essential role of spatiotemporal coordination in multi-agent systems. Our findings validate MASTAVN's effectiveness in time-sensitive emergency scenarios and establish a paradigm for advancing scalable multi-agent embodied intelligence in complex 3D environments.", 'abstract_zh': '多Agent可扩展变换音频视觉导航（MASTAVN）：多Agent协同定位与导航的时空协调机制', 'title_zh': '通过多代理协作在3D环境中的音视频导航进步'}
{'arxiv_id': 'arXiv:2509.24527', 'title': 'Training Agents Inside of Scalable World Models', 'authors': 'Danijar Hafner, Wilson Yan, Timothy Lillicrap', 'link': 'https://arxiv.org/abs/2509.24527', 'abstract': 'World models learn general knowledge from videos and simulate experience for training behaviors in imagination, offering a path towards intelligent agents. However, previous world models have been unable to accurately predict object interactions in complex environments. We introduce Dreamer 4, a scalable agent that learns to solve control tasks by reinforcement learning inside of a fast and accurate world model. In the complex video game Minecraft, the world model accurately predicts object interactions and game mechanics, outperforming previous world models by a large margin. The world model achieves real-time interactive inference on a single GPU through a shortcut forcing objective and an efficient transformer architecture. Moreover, the world model learns general action conditioning from only a small amount of data, allowing it to extract the majority of its knowledge from diverse unlabeled videos. We propose the challenge of obtaining diamonds in Minecraft from only offline data, aligning with practical applications such as robotics where learning from environment interaction can be unsafe and slow. This task requires choosing sequences of over 20,000 mouse and keyboard actions from raw pixels. By learning behaviors in imagination, Dreamer 4 is the first agent to obtain diamonds in Minecraft purely from offline data, without environment interaction. Our work provides a scalable recipe for imagination training, marking a step towards intelligent agents.', 'abstract_zh': 'Dreamer 4: 一种通过快速准确的世界模型进行强化学习的可扩展智能体，在复杂视频游戏Minecraft中实现对象交互的精确预测', 'title_zh': '在可扩展世界模型内部训练代理'}
{'arxiv_id': 'arXiv:2509.24001', 'title': 'Gaze Estimation for Human-Robot Interaction: Analysis Using the NICO Platform', 'authors': 'Matej Palider, Omar Eldardeer, Viktor Kocur', 'link': 'https://arxiv.org/abs/2509.24001', 'abstract': 'This paper evaluates the current gaze estimation methods within an HRI context of a shared workspace scenario. We introduce a new, annotated dataset collected with the NICO robotic platform. We evaluate four state-of-the-art gaze estimation models. The evaluation shows that the angular errors are close to those reported on general-purpose benchmarks. However, when expressed in terms of distance in the shared workspace the best median error is 16.48 cm quantifying the practical limitations of current methods. We conclude by discussing these limitations and offering recommendations on how to best integrate gaze estimation as a modality in HRI systems.', 'abstract_zh': '本文在共享工作站场景的HRI背景下评估当前的凝视估计方法。我们引入了一个使用NICO机器人平台收集的新注释数据集。我们评估了四种最先进的凝视估计模型。评估结果显示，角误差接近通用基准上报告的误差。但在以共享工作站中的距离表示时，最佳中位误差为16.48厘米，量化了当前方法的实际限制。最后，我们讨论了这些限制，并提出了关于如何最好地将凝视估计作为HRI系统中的一种模态的建议。', 'title_zh': '基于NICO平台的人类机器人交互注视估计分析'}
{'arxiv_id': 'arXiv:2509.23922', 'title': 'DriveE2E: Closed-Loop Benchmark for End-to-End Autonomous Driving through Real-to-Simulation', 'authors': 'Haibao Yu, Wenxian Yang, Ruiyang Hao, Chuanye Wang, Jiaru Zhong, Ping Luo, Zaiqing Nie', 'link': 'https://arxiv.org/abs/2509.23922', 'abstract': 'Closed-loop evaluation is increasingly critical for end-to-end autonomous driving. Current closed-loop benchmarks using the CARLA simulator rely on manually configured traffic scenarios, which can diverge from real-world conditions, limiting their ability to reflect actual driving performance. To address these limitations, we introduce a simple yet challenging closed-loop evaluation framework that closely integrates real-world driving scenarios into the CARLA simulator with infrastructure cooperation. Our approach involves extracting 800 dynamic traffic scenarios selected from a comprehensive 100-hour video dataset captured by high-mounted infrastructure sensors, and creating static digital twin assets for 15 real-world intersections with consistent visual appearance. These digital twins accurately replicate the traffic and environmental characteristics of their real-world counterparts, enabling more realistic simulations in CARLA. This evaluation is challenging due to the diversity of driving behaviors, locations, weather conditions, and times of day at complex urban intersections. In addition, we provide a comprehensive closed-loop benchmark for evaluating end-to-end autonomous driving models. Project URL: \\href{this https URL}{this https URL}.', 'abstract_zh': '闭环评估对于端到端自动驾驶越来越关键。当前使用CARLA仿真器的闭环基准依赖于手动配置的交通场景，这些场景可能与实际情况有偏差，限制了它们反映实际驾驶性能的能力。为解决这些问题，我们引入了一个简单而具有挑战性的闭环评估框架，该框架紧密整合了现实世界的行车场景到CARLA仿真器中，并与基础设施合作。我们的方法包括从高空安装的基础设施传感器记录的100小时视频数据集中提取800个动态交通场景，并为15个现实世界的交叉口创建具有一致视觉外观的静态数字孪生资产。这些数字孪生精确地复制了其真实世界的特性，使CARLA中的模拟更加逼真。由于复杂城市交叉口的驾驶行为、地点、天气状况和时间段的多样性，这一评估具有挑战性。此外，我们还提供了一个全面的闭环基准，用于评估端到端自动驾驶模型。项目网址：\\href{this https URL}{这个链接}。', 'title_zh': 'DriveE2E：从真实到模拟的端到端自动驾驶闭环基准测试'}
{'arxiv_id': 'arXiv:2509.23852', 'title': 'SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where', 'authors': 'Yiheng Huang, Junran Peng, Silei Shen, Jingwei Yang, ZeJi Wei, ChenCheng Bai, Yonghao He, Wei Sui, Muyi Sun, Yan Liu, Xu-Cheng Yin, Man Zhang, Zhaoxiang Zhang, Chuanchen Luo', 'link': 'https://arxiv.org/abs/2509.23852', 'abstract': 'The accompanying actions and gestures in dialogue are often closely linked to interactions with the environment, such as looking toward the interlocutor or using gestures to point to the described target at appropriate moments. Speech and semantics guide the production of gestures by determining their timing (WHEN) and style (HOW), while the spatial locations of interactive objects dictate their directional execution (WHERE). Existing approaches either rely solely on descriptive language to generate motions or utilize audio to produce non-interactive gestures, thereby lacking the characterization of interactive timing and spatial intent. This significantly limits the applicability of conversational gesture generation, whether in robotics or in the fields of game and animation production. To address this gap, we present a full-stack solution. We first established a unique data collection method to simultaneously capture high-precision human motion and spatial intent. We then developed a generation model driven by audio, language, and spatial data, alongside dedicated metrics for evaluating interaction timing and spatial accuracy. Finally, we deployed the solution on a humanoid robot, enabling rich, context-aware physical interactions.', 'abstract_zh': '伴随对话的互动动作和手势往往紧密关联于与环境的交互，如目光注视对话伙伴或在恰当时刻用手势指向描述的目标。言语和语义指导手势的产生，决定了其时间（WHEN）和风格（HOW），而互动对象的空间位置则决定了其方向性的执行（WHERE）。现有方法要么仅依赖描述性语言生成动作，要么利用音频产生非互动手势，因而缺乏互动时间与空间意图的 characterization。这极大地限制了对话手势生成在机器人技术、游戏制作和动画生产领域的应用。为解决这一问题，我们提出了一套完整的解决方案。我们首先建立了一种独特的数据采集方法，同时捕捉高精度的人体运动和空间意图。然后开发了一个由音频、语言和空间数据驱动的生成模型，并设计了专门的评估指标来衡量互动时间和空间准确性。最后，我们在类人机器人上部署了该方案，使其能够实现丰富、情境感知的物理交互。', 'title_zh': 'SIG-Chat: 空间意图导向的对话性手势生成涉及如何、何时和何地'}
{'arxiv_id': 'arXiv:2509.25140', 'title': 'ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory', 'authors': 'Siru Ouyang, Jun Yan, I-Hung Hsu, Yanfei Chen, Ke Jiang, Zifeng Wang, Rujun Han, Long T. Le, Samira Daruki, Xiangru Tang, Vishy Tirumalashetty, George Lee, Mahsan Rofouei, Hangfei Lin, Jiawei Han, Chen-Yu Lee, Tomas Pfister', 'link': 'https://arxiv.org/abs/2509.25140', 'abstract': "With the growing adoption of large language model agents in persistent real-world roles, they naturally encounter continuous streams of tasks. A key limitation, however, is their failure to learn from the accumulated interaction history, forcing them to discard valuable insights and repeat past errors. We propose ReasoningBank, a novel memory framework that distills generalizable reasoning strategies from an agent's self-judged successful and failed experiences. At test time, an agent retrieves relevant memories from ReasoningBank to inform its interaction and then integrates new learnings back, enabling it to become more capable over time. Building on this powerful experience learner, we further introduce memory-aware test-time scaling (MaTTS), which accelerates and diversifies this learning process by scaling up the agent's interaction experience. By allocating more compute to each task, the agent generates abundant, diverse experiences that provide rich contrastive signals for synthesizing higher-quality memory. The better memory in turn guides more effective scaling, establishing a powerful synergy between memory and test-time scaling. Across web browsing and software engineering benchmarks, ReasoningBank consistently outperforms existing memory mechanisms that store raw trajectories or only successful task routines, improving both effectiveness and efficiency; MaTTS further amplifies these gains. These findings establish memory-driven experience scaling as a new scaling dimension, enabling agents to self-evolve with emergent behaviors naturally arise.", 'abstract_zh': '基于推理的内存框架和记忆感知的测试时扩增（ReasoningBank and Memory-Aware Test-Time Scaling）', 'title_zh': '推理银行：通过推理记忆扩展代理自进化的规模'}
{'arxiv_id': 'arXiv:2509.25139', 'title': 'Vision-and-Language Navigation with Analogical Textual Descriptions in LLMs', 'authors': 'Yue Zhang, Tianyi Ma, Zun Wang, Yanyuan Qiao, Parisa Kordjamshidi', 'link': 'https://arxiv.org/abs/2509.25139', 'abstract': "Integrating large language models (LLMs) into embodied AI models is becoming increasingly prevalent. However, existing zero-shot LLM-based Vision-and-Language Navigation (VLN) agents either encode images as textual scene descriptions, potentially oversimplifying visual details, or process raw image inputs, which can fail to capture abstract semantics required for high-level reasoning. In this paper, we improve the navigation agent's contextual understanding by incorporating textual descriptions from multiple perspectives that facilitate analogical reasoning across images. By leveraging text-based analogical reasoning, the agent enhances its global scene understanding and spatial reasoning, leading to more accurate action decisions. We evaluate our approach on the R2R dataset, where our experiments demonstrate significant improvements in navigation performance.", 'abstract_zh': '将大型语言模型（LLM）集成到具身AI模型中正变得越来越普遍。然而，现有的零样本基于语言和视觉导航（VLN）的LLM代理要么将图像编码为文本场景描述，有可能简化视觉细节，要么处理原始图像输入，这可能无法捕捉到高层推理所需的抽象语义。在本文中，我们通过引入多角度的文本描述来提高导航代理的情境理解，这些文本描述有助于促进图像间的类比推理。利用基于文本的类比推理，该代理增强其全局场景理解和空间推理能力，从而做出更准确的动作决策。我们在R2R数据集上评估了我们的方法，实验结果表明在导航性能方面取得了显著的改进。', 'title_zh': '基于类比文本描述的大规模语言模型的视觉-语言导航'}
{'arxiv_id': 'arXiv:2509.25137', 'title': 'The Era of Real-World Human Interaction: RL from User Conversations', 'authors': 'Chuanyang Jin, Jing Xu, Bo Liu, Leitian Tao, Olga Golovneva, Tianmin Shu, Wenting Zhao, Xian Li, Jason Weston', 'link': 'https://arxiv.org/abs/2509.25137', 'abstract': "We posit that to achieve continual model improvement and multifaceted alignment, future models must learn from natural human interaction. Current conversational models are aligned using pre-annotated, expert-generated human feedback. In this work, we introduce Reinforcement Learning from Human Interaction (RLHI), a paradigm that learns directly from in-the-wild user conversations. We develop two complementary methods: (1) RLHI with User-Guided Rewrites, which revises unsatisfactory model outputs based on users' natural-language follow-up responses, (2) RLHI with User-Based Rewards, which learns via a reward model conditioned on knowledge of the user's long-term interaction history (termed persona). Together, these methods link long-term user personas to turn-level preferences via persona-conditioned preference optimization. Trained on conversations derived from WildChat, both RLHI variants outperform strong baselines in personalization and instruction-following, and similar feedback enhances performance on reasoning benchmarks. These results suggest organic human interaction offers scalable, effective supervision for personalized alignment.", 'abstract_zh': '我们提出，为了实现持续模型改进和多维度对齐，未来的模型必须从自然的人类交互中学习。当前的对话模型是通过预标注的专家生成的人工反馈进行对齐的。在这项工作中，我们引入了基于人类交互的强化学习（RLHI）框架，该框架直接学习来自真实用户对话的数据。我们开发了两种互补的方法：（1）基于用户指导修正的RLHI，该方法根据用户的自然语言后续响应修订不满意的数据模型输出；（2）基于用户奖励的RLHI，该方法通过一个根据用户长期交互历史（即人设）条件化的奖励模型进行学习。这两种方法通过人设条件化的偏好优化将长期用户人设与回合级别的偏好链接起来。在来源于WildChat的对话数据上训练这两种RLHI变体，它们在个性化和指令遵循方面均优于强基线，并且类似的反馈提高了推理基准上的性能。这些结果表明，有机的人类交互为个性化对齐提供了可扩展且有效的监督。', 'title_zh': '现实世界人类交互的时代：来自用户对话的强化学习'}
{'arxiv_id': 'arXiv:2509.25052', 'title': 'Cogito, Ergo Ludo: An Agent that Learns to Play by Reasoning and Planning', 'authors': 'Sai Wang, Yu Wu, Zhongwen Xu', 'link': 'https://arxiv.org/abs/2509.25052', 'abstract': "The pursuit of artificial agents that can learn to master complex environments has led to remarkable successes, yet prevailing deep reinforcement learning methods often rely on immense experience, encoding their knowledge opaquely within neural network weights. We propose a different paradigm, one in which an agent learns to play by reasoning and planning. We introduce Cogito, ergo ludo (CEL), a novel agent architecture that leverages a Large Language Model (LLM) to build an explicit, language-based understanding of its environment's mechanics and its own strategy. Starting from a tabula rasa state with no prior knowledge (except action set), CEL operates on a cycle of interaction and reflection. After each episode, the agent analyzes its complete trajectory to perform two concurrent learning processes: Rule Induction, where it refines its explicit model of the environment's dynamics, and Strategy and Playbook Summarization, where it distills experiences into an actionable strategic playbook. We evaluate CEL on diverse grid-world tasks (i.e., Minesweeper, Frozen Lake, and Sokoban), and show that the CEL agent successfully learns to master these games by autonomously discovering their rules and developing effective policies from sparse rewards. Ablation studies confirm that the iterative process is critical for sustained learning. Our work demonstrates a path toward more general and interpretable agents that not only act effectively but also build a transparent and improving model of their world through explicit reasoning on raw experience.", 'abstract_zh': 'Cogito, ergo ludo:一种通过推理和规划学习的新型代理架构', 'title_zh': 'Cogito, Ergo Ludo：通过推理和规划学习玩游戏的智能体'}
{'arxiv_id': 'arXiv:2509.24978', 'title': 'Agentic Exploration of Physics Models', 'authors': 'Maximilian Nägele, Florian Marquardt', 'link': 'https://arxiv.org/abs/2509.24978', 'abstract': 'The process of scientific discovery relies on an interplay of observations, analysis, and hypothesis generation. Machine learning is increasingly being adopted to address individual aspects of this process. However, it remains an open challenge to fully automate the open-ended, heuristic, iterative loop required to discover the laws of an unknown system by exploring it through experiments and analysis, without tailoring the approach to the specifics of a given task. Here, we introduce SciExplorer, an agent that leverages large language model tool-use capabilities to enable free-form exploration of systems without any domain-specific blueprints, and apply it to the exploration of physical systems that are initially unknown to the agent. We test SciExplorer on a broad set of models spanning mechanical dynamical systems, wave evolution, and quantum many-body physics. Despite using a minimal set of tools, primarily based on code execution, we observe impressive performance on tasks such as recovering equations of motion from observed dynamics and inferring Hamiltonians from expectation values. The demonstrated effectiveness of this setup opens the door towards similar scientific exploration in other domains, without the need for finetuning or task-specific instructions.', 'abstract_zh': '科学发现的过程依赖于观察、分析和假设生成的相互作用。机器学习在处理这一过程的各个方面时正变得越来越重要。然而，完全自动化探索未知系统并发现其规律的开放式、启发式、迭代循环仍然是一个开放性的挑战，这种探索需要通过实验和分析来完成，而无需针对特定任务进行定制。在这里，我们引入了SciExplorer，这是一种利用大型语言模型工具使用能力的代理，能够无需任何特定领域的蓝图来自由探索系统，并将其应用于代理初始未知的物理系统探索。我们对涵盖机械动力系统、波演化和量子多体物理的一系列模型进行了测试。尽管仅使用了一小套基于代码执行的工具，我们在从观察到的动力恢复运动方程和从期望值推断哈密顿量等方面观察到了令人印象深刻的表现。这一示范性的有效性为其他领域的类似科学探索打开了大门，无需微调或特定任务的指令。', 'title_zh': '物理模型的主体性探索'}
{'arxiv_id': 'arXiv:2509.24314', 'title': 'MedMMV: A Controllable Multimodal Multi-Agent Framework for Reliable and Verifiable Clinical Reasoning', 'authors': 'Hongjun Liu, Yinghao Zhu, Yuhui Wang, Yitao Long, Zeyu Lai, Lequan Yu, Chen Zhao', 'link': 'https://arxiv.org/abs/2509.24314', 'abstract': 'Recent progress in multimodal large language models (MLLMs) has demonstrated promising performance on medical benchmarks and in preliminary trials as clinical assistants. Yet, our pilot audit of diagnostic cases uncovers a critical failure mode: instability in early evidence interpretation precedes hallucination, creating branching reasoning trajectories that cascade into globally inconsistent conclusions. This highlights the need for clinical reasoning agents that constrain stochasticity and hallucination while producing auditable decision flows. We introduce MedMMV, a controllable multimodal multi-agent framework for reliable and verifiable clinical reasoning. MedMMV stabilizes reasoning through diversified short rollouts, grounds intermediate steps in a structured evidence graph under the supervision of a Hallucination Detector, and aggregates candidate paths with a Combined Uncertainty scorer. On six medical benchmarks, MedMMV improves accuracy by up to 12.7% and, more critically, demonstrates superior reliability. Blind physician evaluations confirm that MedMMV substantially increases reasoning truthfulness without sacrificing informational content. By controlling instability through a verifiable, multi-agent process, our framework provides a robust path toward deploying trustworthy AI systems in high-stakes domains like clinical decision support.', 'abstract_zh': '近期多模态大型语言模型在医疗领域的进展已经在医学基准测试和初步临床辅助试验中展示了令人鼓舞的性能。然而，我们对诊断案例的初步审计揭示了一个关键的失败模式：在幻觉之前，早期证据解释的不稳定性引发了分支推理轨迹，导致全局不一致的结论。这突显了在约束不确定性与幻觉的同时，产生可验证决策流的临床推理代理的需求。我们引入了MedMMV，这是一种可控的多模态多代理框架，用于可靠的和可验证的临床推理。MedMMV通过多样化的短期模拟稳定推理，并在幻觉检测器的监督下，将中间步骤置于结构化的证据图中，并通过结合不确定性评分器聚合候选路径。在六个医疗基准测试中，MedMMV将准确性提高了最多12.7%，更重要的是，展示了更高的可靠性。盲评医师评估证实，MedMMV在提高推理真实性的同时并未牺牲信息含量。通过控制可能验证的多代理过程中的不稳定性，我们的框架为在高风险领域如临床决策支持中部署可信赖的AI系统提供了稳健的途径。', 'title_zh': 'MedMMV：一个多模态多代理框架，用于可靠和可验证的临床推理'}
{'arxiv_id': 'arXiv:2509.23870', 'title': 'Rethinking Reward Miscalibration of GRPO in Agentic RL', 'authors': 'Jingyu Liu, Xiaopeng Wu, Jingquan Peng, Kehan Chen, Chuan Yu, Lizhong Ding, Yong Liu', 'link': 'https://arxiv.org/abs/2509.23870', 'abstract': 'Building autonomous agents capable of solving long-horizon, real-world tasks has garnered significant research interest. But outcome based rewards may cause reward miscalibration which means it might mistakenly allocate positive reward to flawed middle steps which is regarded as the key reason making the bad actions being reinforced during training. However we reveal that outcome based reward ensures expected negative advantage for those flawed middle steps, which means the flawed actions should be punished during training. Even accounting for the ``squeezing effect", the probability mass of good actions should increase and the actor should gradually get rid of harmful actions. This shows that flawed actions should be punished during training. We further identify gradient coupling between similar samples as a key issue in agentic RL, the input prompt is extremely similar and the output action space is limited, therefore during training, gradients from well-performing samples can inadvertently strengthen suboptimal or incorrect actions due to similar input observation and output actions. We show that with gradient coupling, some flawed actions might be enhanced. To address this, we propose training the actor to classify good or bad actions to separate the embedding of good/bad actions and alleviate the gradient interference, extensive experiments shows its effectiveness.', 'abstract_zh': '构建能够解决长期任务的自主代理引起了广泛的研究兴趣。但基于结果的奖励可能导致奖励校准失误，这意味着它可能会错误地将积极的奖励分配给有缺陷的中间步骤，这些步骤在训练过程中被认为是不良行为被强化的关键原因。然而，我们发现基于结果的奖励确保了对有缺陷中间步骤的预期负优势，这意味着在训练过程中应该惩罚不良行为。即使考虑“挤压效应”，优质行为的概率质量应增加，且代理应逐渐摆脱有害行为。这表明在训练过程中应该惩罚有缺陷的行为。我们进一步认为，在代理强化学习中，梯度耦合相似样本是一个关键问题，输入提示非常相似且输出行为空间受限，因此在训练过程中，来自表现良好的样本的梯度可能会无意中加强次优或错误的行为，由于输入观察和输出行为的相似性。我们证明了梯度耦合可能会增强某些有缺陷的行为。为此，我们提出训练代理以分类优质或不良行为从而分离优质/不良行为的嵌入并减轻梯度干扰，大量实验显示其有效性。', 'title_zh': '重新审视GRPO在代理强化学习中奖励失 cal 校准问题'}
{'arxiv_id': 'arXiv:2509.23757', 'title': 'Transparent Visual Reasoning via Object-Centric Agent Collaboration', 'authors': 'Benjamin Teoh, Ben Glocker, Francesca Toni, Avinash Kori', 'link': 'https://arxiv.org/abs/2509.23757', 'abstract': "A central challenge in explainable AI, particularly in the visual domain, is producing explanations grounded in human-understandable concepts. To tackle this, we introduce OCEAN (Object-Centric Explananda via Agent Negotiation), a novel, inherently interpretable framework built on object-centric representations and a transparent multi-agent reasoning process. The game-theoretic reasoning process drives agents to agree on coherent and discriminative evidence, resulting in a faithful and interpretable decision-making process. We train OCEAN end-to-end and benchmark it against standard visual classifiers and popular posthoc explanation tools like GradCAM and LIME across two diagnostic multi-object datasets. Our results demonstrate competitive performance with respect to state-of-the-art black-box models with a faithful reasoning process, which was reflected by our user study, where participants consistently rated OCEAN's explanations as more intuitive and trustworthy.", 'abstract_zh': '可解释人工智能领域的核心挑战，特别是在视觉领域，是如何生成基于人类可理解概念的解释。为应对这一挑战，我们提出了OCEAN（基于对象的解释体通过代理协商）这一新颖的、固有可解释的框架，该框架基于对象中心表示和透明的多代理推理过程。基于博弈论的推理过程促使代理们达成一致并提供连贯和区分性的证据，从而实现忠实且可解释的决策过程。我们端到端训练OCEAN，并在两个诊断的多对象数据集上将其与标准视觉分类器和流行的后 hoc 解释工具（如 GradCAM 和 LIME）进行基准测试。我们的结果显示出与最先进的黑盒模型相当的性能，并在忠实的推理过程方面得到了用户研究的支持，参与者一致认为OCEAN的解释更直观且可信。', 'title_zh': '基于对象中心代理协作的透明视觉推理'}
{'arxiv_id': 'arXiv:2509.23250', 'title': 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned', 'authors': 'Brandon Ong, Tej Deep Pala, Vernon Toh, William Chandra Tjhi, Soujanya Poria', 'link': 'https://arxiv.org/abs/2509.23250', 'abstract': 'Process Reward Models (PRMs) provide step-level supervision that improves the reliability of reasoning in large language models. While PRMs have been extensively studied in text-based domains, their extension to Vision Language Models (VLMs) remains limited. Existing Vision-Language PRMs (VL-PRMs) rely on Monte Carlo Tree Search (MCTS) for data construction, which can often produce noisy supervision signals and limit generalization across tasks. In this work, we aim to elucidate the design space of VL-PRMs by exploring diverse strategies for dataset construction, training, and test-time scaling. First, we introduce a hybrid data synthesis framework that combines MCTS with judgments from a strong VLM, producing more accurate step-level labels. Second, we propose perception-focused supervision, enabling our PRM to explicitly detect errors at the visual grounding stage of reasoning. Third, we systematically evaluate multiple test-time scaling strategies, showing that our PRMs can reliably guide VLMs toward more accurate solutions. Our experiments covering five diverse multimodal benchmarks (MMMU, PuzzleVQA, AlgoPuzzleVQA, MathVista, and MathVision) reveal several key insights: (i) VL-PRMs when used as Outcome Reward Models (ORMs) during test-time scaling (TTS) can outperform VL-PRM guided process step selection, (ii) smaller VL-PRMs can match or even surpass larger ones in detecting process errors, (iii) VL-PRMs uncover latent reasoning abilities in stronger VLM backbones, (iv) perception-level supervision leads to significant gains in test-time scaling, and (v) TTS performance of different policies improve on advanced math reasoning datasets despite not training VL-PRMs on such datasets. We hope our work will motivate further research and support the advancement of VLMs.', 'abstract_zh': '过程奖励模型（PRMs）为大规模语言模型提供步骤级的监督，提高推理的可靠性。尽管PRMs在文本领域得到了广泛研究，但将其扩展到视觉语言模型（VLMs）仍然有限。现有的视觉语言PRMs（VL-PRMs）依赖蒙特卡洛树搜索（MCTS）进行数据构建，这常常会产生噪声监督信号并限制跨任务的一般化能力。本文旨在通过探索多样化的数据集构建、训练和测试时扩展策略来阐明VL-PRMs的设计空间。首先，我们提出了一种结合MCTS和强VLM判断的混合数据合成框架，生成更准确的步骤级标签。其次，我们提出了感知焦点监督，使我们的PRM能够明确在视觉锚定推理阶段检测错误。第三，我们系统地评估了多种测试时扩展策略，展示了我们的PRMs能够可靠地引导VLMs获得更准确的解决方案。我们的实验覆盖了五个多模态基准（MMMU、PuzzleVQA、AlgoPuzzleVQA、MathVista和MathVision），揭示了几项关键洞察：（i）在测试时扩展（TTS）期间作为结果奖励模型（ORMs）使用的VL-PRMs可以优于指导过程步骤选择的VL-PRM，（ii）较小的VL-PRMs可以匹配甚至超越较大的VL-PRMs以检测过程错误，（iii）VL-PRMs在较强的VLM主干中揭示了潜在的推理能力，（iv）感知级监督在测试时扩展中带来了显著的改进，（v）不同策略的TTS性能即使在未对VL-PRMs进行此类数据集训练的情况下也改善了高级数学推理数据集的表现。我们希望本研究能够激发进一步的研究，支持VLMs的发展。', 'title_zh': '训练视觉-语言过程奖励模型以实现多模态推理中的测试时扩展：关键见解与经验教训'}
{'arxiv_id': 'arXiv:2509.23248', 'title': 'Agentic AI Reasoning for Mobile Edge General Intelligence: Fundamentals, Approaches, and Directions', 'authors': 'Mingyi Luo, Ruichen Zhang, Xiangwang Hou, Jun Du, Chunxiao Jiang, Yong Ren, Dusit Niyato, Shiwen Mao', 'link': 'https://arxiv.org/abs/2509.23248', 'abstract': "The rapid advancement of large language models (LLMs) has enabled an emergence of agentic artificial intelligence (AI) with powerful reasoning and autonomous decision-making capabilities. This integration with edge computing has led to the development of Mobile Edge General Intelligence (MEGI), which brings real-time, privacy-preserving reasoning to the network edge. However, deploying LLM-based agentic AI reasoning in MEGI environments poses significant challenges due to the high computational demands of reasoning and the limited resources of edge devices. To address these challenges, we propose a joint optimization framework for efficient LLM reasoning deployment in MEGI. First, we review methods that enhance LLM reasoning capabilities, such as Chain-of-Thought (CoT) prompting, Supervised Fine-Tuning (SFT), and Mixture of Experts (MoE). Next, we present a distributed framework that addresses two correlated aspects: reasoning enhancement through adaptive CoT prompting and scalable deployment through distributed MoE architecture. The framework dynamically activates expert networks and adjusts reasoning depth based on task complexity and device capabilities. We further conduct experimental evaluations in mobile edge environments. Experimental results demonstrate the framework's effectiveness in balancing reasoning quality with resource efficiency, validating the practical viability of deploying sophisticated LLM reasoning capabilities in resource-constrained MEGI environments.", 'abstract_zh': '大规模语言模型的迅速发展推动了具有强大推理和自主决策能力的智能代理人工智能的 emergence，这一集成与边缘计算促进了移动边缘通用智能（MEGI）的发展，将实时、隐私保护的推理带到了网络边缘。然而，在 MEGI 环境中部署基于 LLM 的智能代理推理面临着显著挑战，因为推理的高计算需求与边缘设备的有限资源之间的矛盾。为解决这些挑战，我们提出了一种联合优化框架，以实现 MEGI 中高效的大规模语言模型推理部署。首先，我们回顾了增强 LLM 推理能力的方法，如思维链（CoT）提示、监督微调（SFT）和专家混合（MoE）。接着，我们提出了一个分布式框架，来应对两个相关的方面：通过自适应 CoT 提示进行推理增强以及通过分布式 MoE 架构进行可扩展部署。该框架根据任务复杂度和设备能力动态激活专家网络并调整推理深度。我们进一步在移动边缘环境中进行了实验评估。实验结果表明，该框架有效平衡了推理质量和资源效率，验证了在资源受限的 MEGI 环境中部署复杂的大规模语言模型推理能力的可行性。', 'title_zh': '代理型AI推理在移动边缘通用智能中的应用：基础、方法及方向'}
{'arxiv_id': 'arXiv:2509.23121', 'title': 'Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges', 'authors': 'Shuai Li, Chen Yizhe, Li Dong, Liu Sichao, Lan Dapeng, Liu Yu, Zhibo Pang', 'link': 'https://arxiv.org/abs/2509.23121', 'abstract': 'The application of artificial intelligence (AI) in industry is accelerating the shift from traditional automation to intelligent systems with perception and cognition. Vision language-action (VLA) models have been a key paradigm in AI to unify perception, reasoning, and control. Has the performance of the VLA models met the industrial requirements? In this paper, from the perspective of industrial deployment, we compare the performance of existing state-of-the-art VLA models in industrial scenarios and analyze the limitations of VLA models for real-world industrial deployment from the perspectives of data collection and model architecture. The results show that the VLA models retain their ability to perform simple grasping tasks even in industrial settings after fine-tuning. However, there is much room for performance improvement in complex industrial environments, diverse object categories, and high precision placing tasks. Our findings provide practical insight into the adaptability of VLA models for industrial use and highlight the need for task-specific enhancements to improve their robustness, generalization, and precision.', 'abstract_zh': '人工智能在工业中的应用加速了从传统自动化向具有感知和认知能力的智能系统的转变。视觉语言动作（VLA）模型是统一感知、推理和控制的AI关键范式。VLA模型的性能是否满足工业需求？从工业部署的角度，本文将现有最先进的VLA模型在工业场景中的性能进行比较，并从数据收集和模型架构的角度分析VLA模型在实际工业部署中的局限性。研究结果表明，在经过微调后，VLA模型仍能够执行简单的抓取任务，但在复杂工业环境、多样化的对象类别和高精度放置任务中，其性能有很大提升空间。我们的研究提供了有关VLA模型在工业应用中适应性的实用洞察，并强调了为提高其鲁棒性、泛化能力和精度而进行任务特定增强的需求。', 'title_zh': '视觉-语言-动作模型在工业应用中的迁移：架构、性能与挑战'}
{'arxiv_id': 'arXiv:2509.25189', 'title': 'InfoAgent: Advancing Autonomous Information-Seeking Agents', 'authors': 'Gongrui Zhang, Jialiang Zhu, Ruiqi Yang, Kai Qiu, Miaosen Zhang, Zhirong Wu, Qi Dai, Bei Liu, Chong Luo, Zhengyuan Yang, Linjie Li, Lijuan Wang, Weizhu Chen, Yuan Zhang, Xin Li, Zhaoyi Liu, Xin Geng, Baining Guo', 'link': 'https://arxiv.org/abs/2509.25189', 'abstract': 'Building Large Language Model agents that expand their capabilities by interacting with external tools represents a new frontier in AI research and applications. In this paper, we introduce InfoAgent, a deep research agent powered by an innovative data synthesis pipeline and orchestrated web search tools. To construct challenging, hard-to-find queries,we build entity trees and apply sub-tree sampling with entity fuzzification to systematically increase question difficulty. Unlike prior work that relies heavily on commercial search tools, we develop a dedicated self-hosted search infrastructure, enhancing transparency of agent environments and facilitating further advancement of agent capacity. We evaluate the effectiveness of our data pipeline by measuring the average number of tool calls required to correctly answer a question, and also show that our agent yields better performance when equipped with our tools. Our \\mbox{InfoAgent} is post-trained from Qwen3-14B using a two-stage recipe: cold-start supervised finetuning to instill long-horizon search behaviors, followed by reinforcement learning which significantly improves reasoning-driven tool use. With our methods, InfoAgent achieves 15.3\\% accuracy on BrowseComp, 29.2\\% on BrowseComp-ZH, and 40.4\\% on Xbench-DS, outperforming prior open-source deep research agents such as WebSailor-72B and DeepDive-32B.', 'abstract_zh': '构建通过与外部工具交互来扩展其能力的大规模语言模型代理代表了人工智能研究与应用的新前沿。本文介绍了InfoAgent，这是一种由创新性数据合成管道和协调式网络搜索工具驱动的深度研究代理。为了构建具有挑战性和难以找到的问题查询，我们构建了实体树并应用子树采样与实体模糊化方法，系统地增加问题难度。与依赖于商业搜索工具的先前工作不同，我们开发了专用的自托管搜索基础设施，增强了代理环境的透明度并促进了代理能力的进一步发展。通过测量回答一个问题所需的平均工具调用量来评估我们的数据管道的有效性，并展示了在配备我们工具的情况下，我们的代理表现出更好的性能。通过我们的方法，InfoAgent 在 BrowseComp 上实现了 15.3% 的准确率，在 BrowseComp-ZH 上实现了 29.2% 的准确率，在 Xbench-DS 上实现了 40.4% 的准确率，优于之前的开源深度研究代理，如 WebSailor-72B 和 DeepDive-32B。', 'title_zh': '信息代理：推动自主信息寻求代理的发展'}
{'arxiv_id': 'arXiv:2509.25174', 'title': 'XQC: Well-conditioned Optimization Accelerates Deep Reinforcement Learning', 'authors': 'Daniel Palenicek, Florian Vogt, Joe Watson, Ingmar Posner, Jan Peters', 'link': 'https://arxiv.org/abs/2509.25174', 'abstract': "Sample efficiency is a central property of effective deep reinforcement learning algorithms. Recent work has improved this through added complexity, such as larger models, exotic network architectures, and more complex algorithms, which are typically motivated purely by empirical performance. We take a more principled approach by focusing on the optimization landscape of the critic network. Using the eigenspectrum and condition number of the critic's Hessian, we systematically investigate the impact of common architectural design decisions on training dynamics. Our analysis reveals that a novel combination of batch normalization (BN), weight normalization (WN), and a distributional cross-entropy (CE) loss produces condition numbers orders of magnitude smaller than baselines. This combination also naturally bounds gradient norms, a property critical for maintaining a stable effective learning rate under non-stationary targets and bootstrapping. Based on these insights, we introduce XQC: a well-motivated, sample-efficient deep actor-critic algorithm built upon soft actor-critic that embodies these optimization-aware principles. We achieve state-of-the-art sample efficiency across 55 proprioception and 15 vision-based continuous control tasks, all while using significantly fewer parameters than competing methods.", 'abstract_zh': '有效深度强化学习算法中的样本效率是一项核心属性。近期的研究通过增加复杂性，如使用更大规模的模型、奇特的网络架构和更复杂的算法来改进这一属性，这些方法通常仅基于经验性能进行动机说明。我们采取更为原则化的方法，重点关注批判网络的优化景观。利用批判网络海森矩阵的本征谱和条件数，系统研究了常见架构设计决策对训练动力学的影响。我们的分析表明，将批标准化（BN）、权重标准化（WN）与分布交叉熵（CE）损失结合使用，产生的条件数比基线低几个数量级。此外，该组合还自然地限制了梯度范数，这是在非平稳目标和自举下保持稳定有效学习率的关键属性。基于这些洞见，我们提出了XQC：一种基于软Actor-Critic构建的、具有优化意识原则的有效深度Actor-Critic算法。我们在55个 proprioception 和15个 vision-based 连续控制任务上实现了最先进的样本效率，同时使用了比竞争方法显著 fewer 的参数。', 'title_zh': 'XQC：良好条件化优化加速深度强化学习'}
{'arxiv_id': 'arXiv:2509.25133', 'title': 'Rethinking Entropy Regularization in Large Reasoning Models', 'authors': 'Yuxian Jiang, Yafu Li, Guanxu Chen, Dongrui Liu, Yu Cheng, Jing Shao', 'link': 'https://arxiv.org/abs/2509.25133', 'abstract': 'Reinforcement learning with verifiable rewards (RLVR) has shown great promise in enhancing the reasoning abilities of large reasoning models (LRMs). However, it suffers from a critical issue: entropy collapse and premature convergence. Naive entropy regularization, a common approach for encouraging exploration in the traditional RL literature, fails to address this problem in the context of LRM. Our analysis reveals that this failure stems from the vast action space and long trajectories in LRMs, which easily trigger a global entropy explosion as the model indiscriminately explores all possible actions and states. To address this, we propose SIREN (SelectIve entRopy rEgularizatioN), a method that confines exploration to a meaningful subset of actions and states. SIREN achieves this through a two-step entropy masking mechanism, consisting of a top-p mask and a peak-entropy mask. In addition, regularization is transformed into a self-anchored form to stabilize training. Across five mathematical benchmarks, SIREN attains superior average performance over previous entropy-related RLVR approaches, exemplified by a +6.6 maj@k improvement on AIME24/25 with Qwen2.5-Math-7B. Further analysis confirms that SIREN promotes greater response diversity and maintains entropy at an appropriate level, which helps to preserve the validation pass@k throughout training. This effectively mitigates the premature convergence problem common in RLVR for LRM.', 'abstract_zh': '验证奖励的强化学习（RLVR）在提升大型推理模型（LRM）的推理能力方面展现了巨大潜力。然而，它面临一个关键问题：熵坍缩和过早收敛。传统的RL文献中常用的简单熵正则化方法在LRM的背景下无法解决这一问题。我们的分析表明，这种失败源于LRM广阔的动作空间和长轨迹，模型在无差异地探索所有可能的动作和状态时容易引发全局熵爆炸。为解决这一问题，我们提出了SIREN（SelectIve entRopy rEgularizatioN），一种将探索限制在有意义的动作和状态子集中的方法。SIREN通过一个两步熵遮罩机制实现这一点，包括一个top-p遮罩和一个峰值熵遮罩。此外，正则化被转化为自我锚定的形式以稳定训练。在五个数学基准测试中，SIREN在之前的与熵相关的RLVR方法中表现出 superior 的平均性能，例如在Qwen2.5-Math-7B上AIME24/25的maj@k上提升了6.6分。进一步分析证实，SIREN促进了更大的响应多样性，并保持了适当的熵水平，这有助于在整个训练过程中保持验证pass@k。这一方法有效缓解了LRM的RLVR中常见的过早收敛问题。', 'title_zh': '重新思考大型推理模型中的熵正则化'}
{'arxiv_id': 'arXiv:2509.25032', 'title': 'AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation', 'authors': 'Ryosuke Takanami, Petr Khrapchenkov, Shu Morikuni, Jumpei Arima, Yuta Takaba, Shunsuke Maeda, Takuya Okubo, Genki Sano, Satoshi Sekioka, Aoi Kadoya, Motonari Kambara, Naoya Nishiura, Haruto Suzuki, Takanori Yoshimoto, Koya Sakamoto, Shinnosuke Ono, Hu Yang, Daichi Yashima, Aoi Horo, Tomohiro Motoda, Kensuke Chiyoma, Hiroshi Ito, Koki Fukuda, Akihito Goto, Kazumi Morinaga, Yuya Ikeda, Riko Kawada, Masaki Yoshikawa, Norio Kosuge, Yuki Noguchi, Kei Ota, Tatsuya Matsushima, Yusuke Iwasawa, Yutaka Matsuo, Tetsuya Ogata', 'link': 'https://arxiv.org/abs/2509.25032', 'abstract': 'As robots transition from controlled settings to unstructured human environments, building generalist agents that can reliably follow natural language instructions remains a central challenge. Progress in robust mobile manipulation requires large-scale multimodal datasets that capture contact-rich and long-horizon tasks, yet existing resources lack synchronized force-torque sensing, hierarchical annotations, and explicit failure cases. We address this gap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset for mobile manipulation. It includes synchronized RGB images, joint states, six-axis wrist force-torque signals, and internal robot states, together with a novel two-layer annotation schema of sub-goals and primitive actions for hierarchical learning and error analysis. The initial dataset comprises 25,469 episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is fully standardized in the LeRobot v2.1 format. By uniquely integrating mobile manipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa provides a critical benchmark for advancing the next generation of Vision-Language-Action models. The first version of our dataset is now available at this https URL .', 'abstract_zh': '随着机器人从受控环境过渡到无结构的人类环境，构建能够可靠遵循自然语言指令的通用代理仍是一项核心挑战。为了实现稳健的移动操作，需要大规模的多模态数据集来捕捉接触丰富的和长时序的任务，但现有资源缺乏同步的力-力矩感知、层次注释和明确的失败案例。我们通过AIRoA MoMa数据集来弥补这一差距，这是一个用于移动操作的大规模真实世界多模态数据集。它包括同步的RGB图像、关节状态、六轴手腕力-力矩信号和内部机器人状态，以及一个新颖的两级注释方案，用于层次学习和错误分析。初始数据集包含25,469集（约94小时）数据，使用Human Support Robot (HSR)收集，完全标准化为LeRobot v2.1格式。通过独特地整合移动操作、丰富接触交互和长时序结构，AIRoA MoMa提供了推进下一辈视觉-语言-动作模型的关键基准。我们的数据集第一个版本现已可用，请访问这个网址：[请提供网址]。', 'title_zh': 'AIRoA MoMa 数据集：一个大规模层次化移动 manipulator 数据集'}
{'arxiv_id': 'arXiv:2509.24819', 'title': 'Intelligent Optimization of Wireless Access Point Deployment for Communication-Based Train Control Systems Using Deep Reinforcement Learning', 'authors': 'Kunyu Wu, Qiushi Zhao, Zihan Feng, Yunxi Mu, Hao Qin, Xinyu Zhang, Xingqi Zhang', 'link': 'https://arxiv.org/abs/2509.24819', 'abstract': 'Urban railway systems increasingly rely on communication based train control (CBTC) systems, where optimal deployment of access points (APs) in tunnels is critical for robust wireless coverage. Traditional methods, such as empirical model-based optimization algorithms, are hindered by excessive measurement requirements and suboptimal solutions, while machine learning (ML) approaches often struggle with complex tunnel environments. This paper proposes a deep reinforcement learning (DRL) driven framework that integrates parabolic wave equation (PWE) channel modeling, conditional generative adversarial network (cGAN) based data augmentation, and a dueling deep Q network (Dueling DQN) for AP placement optimization. The PWE method generates high-fidelity path loss distributions for a subset of AP positions, which are then expanded by the cGAN to create high resolution path loss maps for all candidate positions, significantly reducing simulation costs while maintaining physical accuracy. In the DRL framework, the state space captures AP positions and coverage, the action space defines AP adjustments, and the reward function encourages signal improvement while penalizing deployment costs. The dueling DQN enhances convergence speed and exploration exploitation balance, increasing the likelihood of reaching optimal configurations. Comparative experiments show that the proposed method outperforms a conventional Hooke Jeeves optimizer and traditional DQN, delivering AP configurations with higher average received power, better worst-case coverage, and improved computational efficiency. This work integrates high-fidelity electromagnetic simulation, generative modeling, and AI-driven optimization, offering a scalable and data-efficient solution for next-generation CBTC systems in complex tunnel environments.', 'abstract_zh': '基于深度强化学习的高精度隧道AP部署优化框架：集成抛物波方程信道建模、条件生成对抗网络数据增强和对冲深度Q网络', 'title_zh': '基于深度强化学习的通信导向列车控制系统的无线接入点智能部署优化'}
{'arxiv_id': 'arXiv:2509.24556', 'title': 'Deep Reinforcement Learning in Action: Real-Time Control of Vortex-Induced Vibrations', 'authors': 'Hussam Sababha, Bernat Font, Mohammed Daqaq', 'link': 'https://arxiv.org/abs/2509.24556', 'abstract': 'This study showcases an experimental deployment of deep reinforcement learning (DRL) for active flow control (AFC) of vortex-induced vibrations (VIV) in a circular cylinder at a high Reynolds number (Re = 3000) using rotary actuation. Departing from prior work that relied on low-Reynolds-number numerical simulations, this research demonstrates real-time control in a challenging experimental setting, successfully addressing practical constraints such as actuator delay. When the learning algorithm is provided with state feedback alone (displacement and velocity of the oscillating cylinder), the DRL agent learns a low-frequency rotary control strategy that achieves up to 80% vibration suppression which leverages the traditional lock-on phenomenon. While this level of suppression is significant, it remains below the performance achieved using high-frequency rotary actuation. The reduction in performance is attributed to actuation delays and can be mitigated by augmenting the learning algorithm with past control actions. This enables the agent to learn a high-frequency rotary control strategy that effectively modifies vortex shedding and achieves over 95% vibration attenuation. These results demonstrate the adaptability of DRL for AFC in real-world experiments and its ability to overcome instrumental limitations such as actuation lag.', 'abstract_zh': '利用深度强化学习在高雷诺数圆柱涡诱发振动主动流动控制中的实验部署', 'title_zh': '深度强化学习在行动：涡激振动的实时控制'}
{'arxiv_id': 'arXiv:2509.24528', 'title': 'CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D', 'authors': 'Mohamad Amin Mirzaei, Pantea Amoie, Ali Ekhterachian, Matin Mirzababaei', 'link': 'https://arxiv.org/abs/2509.24528', 'abstract': '3D scene understanding is fundamental for embodied AI and robotics, supporting reliable perception for interaction and navigation. Recent approaches achieve zero-shot, open-vocabulary 3D semantic mapping by assigning embedding vectors to 2D class-agnostic masks generated via vision-language models (VLMs) and projecting these into 3D. However, these methods often produce fragmented masks and inaccurate semantic assignments due to the direct use of raw masks, limiting their effectiveness in complex environments. To address this, we leverage SemanticSAM with progressive granularity refinement to generate more accurate and numerous object-level masks, mitigating the over-segmentation commonly observed in mask generation models such as vanilla SAM, and improving downstream 3D semantic segmentation. To further enhance semantic context, we employ a context-aware CLIP encoding strategy that integrates multiple contextual views of each mask using empirically determined weighting, providing much richer visual context. We evaluate our approach on multiple 3D scene understanding tasks, including 3D semantic segmentation and object retrieval from language queries, across several benchmark datasets. Experimental results demonstrate significant improvements over existing methods, highlighting the effectiveness of our approach.', 'abstract_zh': '三维场景理解对于嵌入式AI和机器人技术是基础性的，支持可靠的感知以实现交互和导航。最近的方法通过将嵌入向量分配给由视觉语言模型（VLMs）生成的2D类无感知掩码，并将这些掩码投影到3D空间中，实现了零样本、开放式词汇的三维语义建模。然而，这些方法往往由于直接使用原始掩码而产生碎片化的掩码和不准确的语义分配，限制了其在复杂环境中的效果。为了解决这个问题，我们利用具有渐进粒度细化的SemanticSAM生成更准确且数量更多的对象级掩码，减少生成掩码模型（如vanilla SAM）中常见的过度分割现象，并提高下游的三维语义分割效果。为进一步增强语义上下文，我们采用了一种基于上下文的CLIP编码策略，利用经验确定的权重整合每个掩码的多种上下文视图，提供了更加丰富的视觉上下文。我们在多个三维场景理解任务上评估了我们的方法，包括三维语义分割和基于语言查询的对象检索，并在几个基准数据集上展示了实验结果，证明了我们方法的优越性。', 'title_zh': 'CORE-3D：基于三维空间的语境感知开放词汇检索'}
{'arxiv_id': 'arXiv:2509.24274', 'title': 'Adversarial Reinforcement Learning Framework for ESP Cheater Simulation', 'authors': 'Inkyu Park, Jeong-Gwan Lee, Taehwan Kwon, Juheon Choi, Seungku Kim, Junsu Kim, Kimin Lee', 'link': 'https://arxiv.org/abs/2509.24274', 'abstract': 'Extra-Sensory Perception (ESP) cheats, which reveal hidden in-game information such as enemy locations, are difficult to detect because their effects are not directly observable in player behavior. The lack of observable evidence makes it difficult to collect reliably labeled data, which is essential for training effective anti-cheat systems. Furthermore, cheaters often adapt their behavior by limiting or disguising their cheat usage, which further complicates detection and detector development. To address these challenges, we propose a simulation framework for controlled modeling of ESP cheaters, non-cheaters, and trajectory-based detectors. We model cheaters and non-cheaters as reinforcement learning agents with different levels of observability, while detectors classify their behavioral trajectories. Next, we formulate the interaction between the cheater and the detector as an adversarial game, allowing both players to co-adapt over time. To reflect realistic cheater strategies, we introduce a structured cheater model that dynamically switches between cheating and non-cheating behaviors based on detection risk. Experiments demonstrate that our framework successfully simulates adaptive cheater behaviors that strategically balance reward optimization and detection evasion. This work provides a controllable and extensible platform for studying adaptive cheating behaviors and developing effective cheat detectors.', 'abstract_zh': '异感知（ESP）作弊者的行为建模及检测仿真框架', 'title_zh': '对抗强化学习框架下的ESP作弊模拟'}
{'arxiv_id': 'arXiv:2509.24256', 'title': 'Graph Foundation Models: Bridging Language Model Paradigms and Graph Optimization', 'authors': 'Yunhao Liang, Pujun Zhang, Yuan Qu, Shaochong Lin, Zuo-jun Max Shen', 'link': 'https://arxiv.org/abs/2509.24256', 'abstract': "The pretrain-transfer paradigm, which underpins the success of large language models (LLMs), has demonstrated the immense power of creating foundation models that learn generalizable representations from vast datasets. However, extending this paradigm to Operations Research (OR) problems on graph structures remains challenging due to the fundamental conflict between the statistical flexibility of language and the strict combinatorial constraints of graphs. To bridge this gap, we introduce the Graph Foundation Model (GFM), the first framework capable of solving all distance-based optimization problems on graph structures. By introducing the LLM-like self-supervised pre-training paradigm on the paths generated from random walks in the graph, GFM is compelled to internalize the graph's complex topological and combinatorial rules, where the connectivity of the structure itself can be treated as the supervisory signal. Unlike existing neural methods that learn complex and task-specific solving policies, our approach leverages the pre-trained GFM as a foundational model of the graph's intrinsic structure, which in turn enables a simple generative heuristic to tackle a diverse range of optimization challenges effectively. Comprehensive experiments on networks ranging from 20 to 893 nodes demonstrate that GFM achieves competitive performance against specialized solvers across a variety of distinct optimization task classes, while maintaining significantly faster inference times. Our work establishes a new paradigm of adapting the pretrain-transfer framework to graph optimization, opening the door for applying foundation model innovations to OR.", 'abstract_zh': 'Graph Foundation Model: A Pretrain-Transfer Paradigm for Solving Graph-Based Optimization Problems', 'title_zh': '图基础模型：连接语言模型范式与图优化的研究'}
{'arxiv_id': 'arXiv:2509.24183', 'title': 'Retrieval-augmented GUI Agents with Generative Guidelines', 'authors': 'Ran Xu, Kaixin Ma, Wenhao Yu, Hongming Zhang, Joyce C. Ho, Carl Yang, Dong Yu', 'link': 'https://arxiv.org/abs/2509.24183', 'abstract': 'GUI agents powered by vision-language models (VLMs) show promise in automating complex digital tasks. However, their effectiveness in real-world applications is often limited by scarce training data and the inherent complexity of these tasks, which frequently require long-tailed knowledge covering rare, unseen scenarios. We propose RAG-GUI , a lightweight VLM that leverages web tutorials at inference time. RAG-GUI is first warm-started via supervised finetuning (SFT) and further refined through self-guided rejection sampling finetuning (RSF). Designed to be model-agnostic, RAG-GUI functions as a generic plug-in that enhances any VLM-based agent. Evaluated across three distinct tasks, it consistently outperforms baseline agents and surpasses other inference baselines by 2.6% to 13.3% across two model sizes, demonstrating strong generalization and practical plug-and-play capabilities in real-world scenarios.', 'abstract_zh': '由视觉-语言模型驱动的GUI代理显示了自动化复杂数字任务的潜力。然而，它们在实际应用中的有效性常常受到稀缺训练数据和这些任务固有复杂性的限制，这些任务通常需要涵盖罕见未见情景的长尾知识。我们提出了一种轻量级视觉-语言模型RAG-GUI，在推理时利用网页教程。RAG-GUI首先通过监督微调(SFT)预热，并进一步通过自我指导式拒绝采样微调(RSF)进行优化。设计为模型无关的，RAG-GUI作为通用插件增强任何基于视觉-语言模型的代理。在三个不同的任务中进行了评估，它在两个模型大小下分别优于基线代理2.6%至13.3%，展示了强大的泛化能力和实际插拔即用能力。', 'title_zh': '基于检索增强的GUI代理与生成性准则'}
{'arxiv_id': 'arXiv:2509.24165', 'title': 'LatXGen: Towards Radiation-Free and Accurate Quantitative Analysis of Sagittal Spinal Alignment Via Cross-Modal Radiographic View Synthesis', 'authors': 'Moxin Zhao, Nan Meng, Jason Pui Yin Cheung, Chris Yuk Kwan Tang, Chenxi Yu, Wenting Zhong, Pengyu Lu, Chang Shi, Yipeng Zhuang, Teng Zhang', 'link': 'https://arxiv.org/abs/2509.24165', 'abstract': 'Adolescent Idiopathic Scoliosis (AIS) is a complex three-dimensional spinal deformity, and accurate morphological assessment requires evaluating both coronal and sagittal alignment. While previous research has made significant progress in developing radiation-free methods for coronal plane assessment, reliable and accurate evaluation of sagittal alignment without ionizing radiation remains largely underexplored. To address this gap, we propose LatXGen, a novel generative framework that synthesizes realistic lateral spinal radiographs from posterior Red-Green-Blue and Depth (RGBD) images of unclothed backs. This enables accurate, radiation-free estimation of sagittal spinal alignment. LatXGen tackles two core challenges: (1) inferring sagittal spinal morphology changes from a lateral perspective based on posteroanterior surface geometry, and (2) performing cross-modality translation from RGBD input to the radiographic domain. The framework adopts a dual-stage architecture that progressively estimates lateral spinal structure and synthesizes corresponding radiographs. To enhance anatomical consistency, we introduce an attention-based Fast Fourier Convolution (FFC) module for integrating anatomical features from RGBD images and 3D landmarks, and a Spatial Deformation Network (SDN) to model morphological variations in the lateral view. Additionally, we construct the first large-scale paired dataset for this task, comprising 3,264 RGBD and lateral radiograph pairs. Experimental results demonstrate that LatXGen produces anatomically accurate radiographs and outperforms existing GAN-based methods in both visual fidelity and quantitative metrics. This study offers a promising, radiation-free solution for sagittal spine assessment and advances comprehensive AIS evaluation.', 'abstract_zh': '青少年特发性脊柱侧弯（AIS）是一种复杂的三维脊柱畸形，准确的形态评估需要同时评估冠状面和冠状轴对齐情况。尽管先前研究在无辐射冠状面评估方法的研发方面取得了显著进展，但在不使用电离辐射的情况下可靠且准确地评估冠状轴对齐情况仍鲜有探索。为填补这一空白，我们提出了LatXGen，这是一种新颖的生成框架，能够从未经穿着衣物背部的后前向红绿蓝和深度（RGBD）图像中合成逼真的侧位脊柱X光片。这使得能够无辐射地准确估计冠状轴对齐情况。LatXGen 应对了两大核心挑战：（1）基于后前向表面几何结构从侧位视角推断冠状脊柱形态变化，（2）从 RGBD 输入跨模态转换到放射学领域。该框架采用双重架构，逐步估算侧位脊柱结构并生成相应的X光片。为了增强解剖一致性，我们引入了基于注意力的快速傅里叶卷积（FFC）模块，用于整合RGBD图像和三维标志点的解剖特征，并采用空间变形网络（SDN）来建模侧位视图中的形态变化。此外，我们构建了首个用于该任务的大规模配对数据集，包含了3,264对RGBD和侧位X光片。实验结果表明，LatXGen生成了解剖学上准确的X光片，并在视觉保真度和定量指标方面显著优于现有基于生成对抗网络（GAN）的方法。这一研究提供了一种有前景的无辐射解决方案，用于评估冠状脊柱，并推动了全面的青少年特发性脊柱侧弯评估。', 'title_zh': 'LatXGen：用于冠状脊柱对齐跨模态放射学视图合成的辐射-free 和精确定量分析方法'}
{'arxiv_id': 'arXiv:2509.23846', 'title': 'Adversarial Diffusion for Robust Reinforcement Learning', 'authors': 'Daniele Foffano, Alessio Russo, Alexandre Proutiere', 'link': 'https://arxiv.org/abs/2509.23846', 'abstract': 'Robustness to modeling errors and uncertainties remains a central challenge in reinforcement learning (RL). In this work, we address this challenge by leveraging diffusion models to train robust RL policies. Diffusion models have recently gained popularity in model-based RL due to their ability to generate full trajectories "all at once", mitigating the compounding errors typical of step-by-step transition models. Moreover, they can be conditioned to sample from specific distributions, making them highly flexible. We leverage conditional sampling to learn policies that are robust to uncertainty in environment dynamics. Building on the established connection between Conditional Value at Risk (CVaR) optimization and robust RL, we introduce Adversarial Diffusion for Robust Reinforcement Learning (AD-RRL). AD-RRL guides the diffusion process to generate worst-case trajectories during training, effectively optimizing the CVaR of the cumulative return. Empirical results across standard benchmarks show that AD-RRL achieves superior robustness and performance compared to existing robust RL methods.', 'abstract_zh': '差分模型在强化学习中的鲁棒性研究：对抗差分用于稳健强化学习（Adversarial Diffusion for Robust Reinforcement Learning, AD-RRL）', 'title_zh': '对抗扩散以实现鲁棒的强化学习'}
{'arxiv_id': 'arXiv:2509.23746', 'title': 'Poivre: Self-Refining Visual Pointing with Reinforcement Learning', 'authors': 'Wenjie Yang, Zengfeng Huang', 'link': 'https://arxiv.org/abs/2509.23746', 'abstract': 'Visual pointing, which aims to localize a target by predicting its coordinates on an image, has emerged as an important problem in the realm of vision-language models (VLMs). Despite its broad applicability, recent benchmarks show that current VLMs still fall far behind human performance on this task. A key limitation is that VLMs are typically required to complete the pointing task in a single step, akin to asking humans to point at an object without seeing their own fingers. To address this issue, we propose a simple yet effective self-refining procedure: Point, Visualize, then Refine (Poivre). This procedure enables a VLM to first mark its estimated point, then iteratively refine the coordinates if necessary. Inspired by advances of reasoning models in the natural language domain, we employ reinforcement learning (RL) to incentivize this self-refining ability. For the RL training, we design a neat process reward that is not only empirically effective but also grounded in appealing properties. Our trained model, Poivre-7B, sets a new state of the art on Point-Bench, outperforming both proprietary models such as Gemini-2.5-Pro and large open-source models such as Molmo-72B by over 3%. To support future research, we release our training and inference code, dataset, and the Poivre-7B checkpoint.', 'abstract_zh': '视觉指针任务旨在通过预测目标在图像中的坐标来定位目标，已成为视觉语言模型（VLMs）领域的一个重要问题。尽管具有广泛的应用性，但近期基准测试显示，当前的VLMs在该任务上仍然远逊于人类表现。一个关键限制是，VLMs通常需要一次性完成指针任务，类似于要求人类在看不到自己手指的情况下指认一个物体。为解决这一问题，我们提出了一种简单而有效的自我完善流程：指针、可视化、再精炼（Poivre）。该流程使VLM能够首先标记其估计的点，然后根据需要迭代精炼坐标。受到自然语言领域推理模型发展的启发，我们采用强化学习（RL）来激励这种自我完善的能力。在RL训练中，我们设计了一种简洁的过程奖励，不仅在实验中有效，而且基于引人注目的特性。经过训练的模型Poivre-7B在Point-Bench上达到了新的最佳水平，比专有模型如Gemini-2.5-Pro以及大型开源模型如Molmo-72B高出超过3%。为支持未来研究，我们公开了训练和推理代码、数据集以及Poivre-7B的检查点。', 'title_zh': 'Poivre: 基于强化学习的自我精炼视觉指针'}
{'arxiv_id': 'arXiv:2509.23517', 'title': 'Evaluating point-light biological motion in multimodal large language models', 'authors': 'Akila Kadambi, Marco Iacoboni, Lisa Aziz-Zadeh, Srini Narayanan', 'link': 'https://arxiv.org/abs/2509.23517', 'abstract': 'Humans can extract rich semantic information from minimal visual cues, as demonstrated by point-light displays (PLDs), which consist of sparse sets of dots localized to key joints of the human body. This ability emerges early in development and is largely attributed to human embodied experience. Since PLDs isolate body motion as the sole source of meaning, they represent key stimuli for testing the constraints of action understanding in these systems. Here we introduce ActPLD, the first benchmark to evaluate action processing in MLLMs from human PLDs. Tested models include state-of-the-art proprietary and open-source systems on single-actor and socially interacting PLDs. Our results reveal consistently low performance across models, introducing fundamental gaps in action and spatiotemporal understanding.', 'abstract_zh': '人类可以从少量的视觉线索中提取丰富的语义信息，这一点由点光显示（PLD）实验所证明，PLD仅由人体关键关节位置的稀疏点组成。这种能力早在发育早期就显现出来，并很大程度上归因于人类的经验性体验。由于PLD将身体运动作为唯一的意义来源，它们代表了测试这些系统动作理解限制的关键刺激。在这里，我们引入了ActPLD，这是首个基于人类PLD评估MLLMs动作处理能力的基准。测试的模型包括最先进的专有和开源系统在单人和社交互动PLD上的表现。我们的结果揭示了模型在动作和空间时间理解方面的低表现，暴露出根本性的差距。', 'title_zh': '评估多元模态大型语言模型中的点光生物运动'}
{'arxiv_id': 'arXiv:2509.23468', 'title': 'Multi-Modal Manipulation via Multi-Modal Policy Consensus', 'authors': 'Haonan Chen, Jiaming Xu, Hongyu Chen, Kaiwen Hong, Binghao Huang, Chaoqi Liu, Jiayuan Mao, Yunzhu Li, Yilun Du, Katherine Driggs-Campbell', 'link': 'https://arxiv.org/abs/2509.23468', 'abstract': 'Effectively integrating diverse sensory modalities is crucial for robotic manipulation. However, the typical approach of feature concatenation is often suboptimal: dominant modalities such as vision can overwhelm sparse but critical signals like touch in contact-rich tasks, and monolithic architectures cannot flexibly incorporate new or missing modalities without retraining. Our method factorizes the policy into a set of diffusion models, each specialized for a single representation (e.g., vision or touch), and employs a router network that learns consensus weights to adaptively combine their contributions, enabling incremental of new representations. We evaluate our approach on simulated manipulation tasks in {RLBench}, as well as real-world tasks such as occluded object picking, in-hand spoon reorientation, and puzzle insertion, where it significantly outperforms feature-concatenation baselines on scenarios requiring multimodal reasoning. Our policy further demonstrates robustness to physical perturbations and sensor corruption. We further conduct perturbation-based importance analysis, which reveals adaptive shifts between modalities.', 'abstract_zh': '有效融合多种感官模态对于机器人操作至关重要。然而，典型的特征拼接方法往往不尽optimal：如视觉等主导模态在接触丰富任务中可能会压制稀疏但关键的触觉信号，而整体型架构无法灵活地在无需重新训练的情况下整合新出现或缺失的模态。我们的方法将策略分解为一组专门用于单一表示（如视觉或触觉）的扩散模型，并使用一个路由器网络学习共识权重以自适应地组合它们的贡献，从而实现新表示的增量整合。我们在{RLBench}模拟操作任务以及实际任务（如遮挡物体拾取、手持勺子重新定向和拼图插入）中评估了这种方法，结果表明其在需要多模态推理的情况下显著优于特征拼接基准。此外，我们的策略还展示了对物理扰动和传感器故障的鲁棒性。我们进一步开展了基于扰动的重要性分析，揭示了模态间适应性变化。', 'title_zh': '多模态操作 via 多模态策略共识'}
{'arxiv_id': 'arXiv:2509.23209', 'title': 'Towards Monotonic Improvement in In-Context Reinforcement Learning', 'authors': 'Wenhao Zhang, Shao Zhang, Xihuai Wang, Yang Li, Ying Wen', 'link': 'https://arxiv.org/abs/2509.23209', 'abstract': "In-Context Reinforcement Learning (ICRL) has emerged as a promising paradigm for developing agents that can rapidly adapt to new tasks by leveraging past experiences as context, without updating their parameters. Recent approaches train large sequence models on monotonic policy improvement data from online RL, aiming to a continue improved testing time performance. However, our experimental analysis reveals a critical flaw: these models cannot show a continue improvement like the training data during testing time. Theoretically, we identify this phenomenon as Contextual Ambiguity, where the model's own stochastic actions can generate an interaction history that misleadingly resembles that of a sub-optimal policy from the training data, initiating a vicious cycle of poor action selection. To resolve the Contextual Ambiguity, we introduce Context Value into training phase and propose Context Value Informed ICRL (CV-ICRL). CV-ICRL use Context Value as an explicit signal representing the ideal performance theoretically achievable by a policy given the current context. As the context expands, Context Value could include more task-relevant information, and therefore the ideal performance should be non-decreasing. We prove that the Context Value tightens the lower bound on the performance gap relative to an ideal, monotonically improving policy. We fruther propose two methods for estimating Context Value at both training and testing time. Experiments conducted on the Dark Room and Minigrid testbeds demonstrate that CV-ICRL effectively mitigates performance degradation and improves overall ICRL abilities across various tasks and environments. The source code and data of this paper are available at this https URL .", 'abstract_zh': '基于上下文的强化学习（ICRL）：缓解上下文模糊性的方法', 'title_zh': '向单调改进的在上下文强化学习方向探索'}
{'arxiv_id': 'arXiv:2509.23003', 'title': 'Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery', 'authors': 'Jiayin Liu, Yulong Yang, Vineet Bansal, Christine Allen-Blanchette', 'link': 'https://arxiv.org/abs/2509.23003', 'abstract': 'From metronomes to celestial bodies, mechanics underpins how the world evolves in time and space. With consideration of this, a number of recent neural network models leverage inductive biases from classical mechanics to encourage model interpretability and ensure forecasted states are physical. However, in general, these models are designed to capture the dynamics of a single system with fixed physical parameters, from state-space measurements of a known configuration space. In this paper we introduce Symplectic Phase Space GAN (SPS-GAN) which can capture the dynamics of multiple systems, and generalize to unseen physical parameters from. Moreover, SPS-GAN does not require prior knowledge of the system configuration space. In fact, SPS-GAN can discover the configuration space structure of the system from arbitrary measurement types (e.g., state-space measurements, video frames). To achieve physically plausible generation, we introduce a novel architecture which embeds a Hamiltonian neural network recurrent module in a conditional GAN backbone. To discover the structure of the configuration space, we optimize the conditional time-series GAN objective with an additional physically motivated term to encourages a sparse representation of the configuration space. We demonstrate the utility of SPS-GAN for trajectory prediction, video generation and symmetry discovery. Our approach captures multiple systems and achieves performance on par with supervised models designed for single systems.', 'abstract_zh': '从摆钟到天体，力学贯穿了世界在时间和空间中的演变。考虑到这一点，近期的一些神经网络模型借鉴了经典力学的归纳偏置，以促进模型的可解释性并确保预测的状态具有物理意义。然而，通常这些模型设计用于捕捉单个系统（具有固定物理参数）从已知配置空间的状态空间测量中动态。本文我们引入了辛相空间生成对抗网络（SPS-GAN），它可以捕捉多个系统的动态，并且可以从未知物理参数中进行泛化。此外，SPS-GAN 不需要事先了解系统的配置空间结构。实际上，SPS-GAN 可以从任意测量类型（例如状态空间测量、视频帧）中发现系统的配置空间结构。为了实现物理上合理的生成，我们引入了一种新型架构，在条件生成对抗网络骨干中嵌入了哈密顿神经网络递归模块。为了发现配置空间的结构，我们通过一个额外的物理驱动项优化条件时间序列生成对抗网络目标，以促进配置空间的稀疏表示。我们表明，SPS-GAN 在轨迹预测、视频生成和对称性发现方面的应用价值。我们的方法可以捕捉多个系统，并且在性能上与专门为单个系统设计的监督模型相当。', 'title_zh': '物理可验证的多系统轨迹生成与对称性发现'}
{'arxiv_id': 'arXiv:2509.22851', 'title': 'Adaptive Margin RLHF via Preference over Preferences', 'authors': 'Yaswanth Chittepu, Prasann Singhal, Greg Durrett, Scott Niekum', 'link': 'https://arxiv.org/abs/2509.22851', 'abstract': 'Margin-based optimization is fundamental to improving generalization and robustness in classification tasks. In the context of reward model learning from preferences within Reinforcement Learning from Human Feedback (RLHF), existing methods typically rely on no margins, fixed margins, or margins that are simplistic functions of preference ratings. However, such formulations often fail to account for the varying strengths of different preferences, for example some preferences are associated with larger margins between responses, or they rely on noisy margin information derived from ratings. We argue that modeling the strength of preferences can lead to better generalization and more faithful alignment. Furthermore, many existing methods that use adaptive margins assume access to accurate preference scores, which can be difficult for humans to provide reliably. We propose an approach that leverages preferences over preferences, that is annotations indicating which of two preferences reflects a stronger distinction. We use this ordinal signal to infer adaptive margins on a per-datapoint basis. We introduce an extension to Direct Preference Optimization (DPO), DPO-PoP, that incorporates adaptive margins from preference-over-preference supervision, enabling improved discriminative and generative performance. Empirically, our method outperforms vanilla DPO, DPO with fixed margins, and DPO with ground-truth margins on the UltraFeedback dataset. Additionally, we show that there is a tradeoff between discriminative and generative performance: improving test classification accuracy, particularly by correctly labeling weaker preferences at the expense of stronger ones, can lead to a decline in generative quality. To navigate this tradeoff, we propose two sampling strategies to gather preference-over-preference labels: one favoring discriminative performance and one favoring generative performance.', 'abstract_zh': '基于偏好的加权优化对于提高分类任务的泛化能力和鲁棒性是基础的。在强化学习中有来自人类反馈（RLHF）的偏好强化学习中，现有方法通常依赖于没有加权、固定加权或基于偏好评分的简单加权函数。然而，这样的形式化往往未能考虑到不同偏好强度的不同，例如，某些偏好与响应之间的更大加权差相关，或者依赖于从评分中derive出的 noisy 加权信息。我们认为建模偏好强度可以导致更好的泛化和更忠实的对齐。此外，许多使用自适应加权的方法假定可以访问准确的偏好评分，而这对于人类来说可能是难以可靠提供的。我们提出了一种方法，利用偏好之间的偏好作为监督，即指示哪一种偏好表现出更强区分性的标注。我们使用这种序关系信号，在每个数据点基础上推断自适应加权。我们提出了直接偏好优化（DPO）的扩展DPO-PoP，该扩展方法纳入了偏好之间的偏好监督得到的自适应加权，从而提高了判别和生成性能。实验表明，我们的方法在UltraFeedback数据集上优于传统的DPO、带有固定加权的DPO和带有真实加权的DPO。此外，我们展示了判别和生成性能之间的权衡：通过正确标记较弱偏好而提高测试分类准确性，可能会导致生成质量下降。为此，我们提出了两种采样策略来收集偏好之间的偏好标签：一种侧重于判别性能，另一种侧重于生成性能。', 'title_zh': '基于偏好的偏好适应性RLHF'}
{'arxiv_id': 'arXiv:2509.06775', 'title': 'Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks', 'authors': 'Po-Heng Chou, Pin-Qi Fu, Walid Saad, Li-Chun Wang', 'link': 'https://arxiv.org/abs/2509.06775', 'abstract': 'In this paper, we present an agentic double deep Q-network (DDQN) scheduler for licensed/unlicensed band allocation in New Radio (NR) sidelink (SL) networks. Beyond conventional reward-seeking reinforcement learning (RL), the agent perceives and reasons over a multi-dimensional context that jointly captures queueing delay, link quality, coexistence intensity, and switching stability. A capacity-aware, quality of service (QoS)-constrained reward aligns the agent with goal-oriented scheduling rather than static thresholding. Under constrained bandwidth, the proposed design reduces blocking by up to 87.5% versus threshold policies while preserving throughput, highlighting the value of context-driven decisions in coexistence-limited NR SL networks. The proposed scheduler is an embodied agent (E-agent) tailored for task-specific, resource-efficient operation at the network edge.', 'abstract_zh': '一种用于新无线电侧链路网络频段分配的代理双深度Q网络调度器', 'title_zh': '基于代理DDQN的Licensed和Unlicensed频带分配侧联网络调度'}
