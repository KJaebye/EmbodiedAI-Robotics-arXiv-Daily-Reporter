{'arxiv_id': 'arXiv:2505.02664', 'title': 'Grasp the Graph (GtG) 2.0: Ensemble of GNNs for High-Precision Grasp Pose Detection in Clutter', 'authors': 'Ali Rashidi Moghadam, Sayedmohammadreza Rastegari, Mehdi Tale Masouleh, Ahmad Kalhor', 'link': 'https://arxiv.org/abs/2505.02664', 'abstract': 'Grasp pose detection in cluttered, real-world environments remains a significant challenge due to noisy and incomplete sensory data combined with complex object geometries. This paper introduces Grasp the Graph 2.0 (GtG 2.0) method, a lightweight yet highly effective hypothesis-and-test robotics grasping framework which leverages an ensemble of Graph Neural Networks for efficient geometric reasoning from point cloud data. Building on the success of GtG 1.0, which demonstrated the potential of Graph Neural Networks for grasp detection but was limited by assumptions of complete, noise-free point clouds and 4-Dof grasping, GtG 2.0 employs a conventional Grasp Pose Generator to efficiently produce 7-Dof grasp candidates. Candidates are assessed with an ensemble Graph Neural Network model which includes points within the gripper jaws (inside points) and surrounding contextual points (outside points). This improved representation boosts grasp detection performance over previous methods using the same generator. GtG 2.0 shows up to a 35% improvement in Average Precision on the GraspNet-1Billion benchmark compared to hypothesis-and-test and Graph Neural Network-based methods, ranking it among the top three frameworks. Experiments with a 3-Dof Delta Parallel robot and Kinect-v1 camera show a success rate of 91% and a clutter completion rate of 100%, demonstrating its flexibility and reliability.', 'abstract_zh': 'Grasp Pose Detection in Cluttered, Real-World Environments via Grasp the Graph 2.0 (GtG 2.0) Method', 'title_zh': 'Grasp the Graph (GtG) 2.0: 基于GNNs的高精度杂乱环境中抓取姿态检测集成方法'}
{'arxiv_id': 'arXiv:2505.02598', 'title': 'LiDAR-Inertial SLAM-Based Navigation and Safety-Oriented AI-Driven Control System for Skid-Steer Robots', 'authors': 'Mehdi Heydari Shahna, Eemil Haaparanta, Pauli Mustalahti, Jouni Mattila', 'link': 'https://arxiv.org/abs/2505.02598', 'abstract': 'Integrating artificial intelligence (AI) and stochastic technologies into the mobile robot navigation and control (MRNC) framework while adhering to rigorous safety standards presents significant challenges. To address these challenges, this paper proposes a comprehensively integrated MRNC framework for skid-steer wheeled mobile robots (SSWMRs), in which all components are actively engaged in real-time execution. The framework comprises: 1) a LiDAR-inertial simultaneous localization and mapping (SLAM) algorithm for estimating the current pose of the robot within the built map; 2) an effective path-following control system for generating desired linear and angular velocity commands based on the current pose and the desired pose; 3) inverse kinematics for transferring linear and angular velocity commands into left and right side velocity commands; and 4) a robust AI-driven (RAID) control system incorporating a radial basis function network (RBFN) with a new adaptive algorithm to enforce in-wheel actuation systems to track each side motion commands. To further meet safety requirements, the proposed RAID control within the MRNC framework of the SSWMR constrains AI-generated tracking performance within predefined overshoot and steady-state error limits, while ensuring robustness and system stability by compensating for modeling errors, unknown RBF weights, and external forces. Experimental results verify the proposed MRNC framework performance for a 4,836 kg SSWMR operating on soft terrain.', 'abstract_zh': '将人工智能和随机技术集成到履带式移动机器人导航与控制框架中，同时遵守严格的安全标准，面临着显著的挑战。本文提出了一种全面集成的履带式移动机器人（SSWMR）导航与控制框架，所有组件都在实时执行中积极参与，该框架包括：1）LiDAR-惯性同时定位与建图（SLAM）算法，用于估计机器人在构建地图中的当前位置；2）有效的路径跟踪控制系统，根据当前位置和期望位置生成期望的线性和角速度指令；3）逆运动学，将线性和角速度指令转换为左右侧速度指令；4）一种鲁棒的基于人工智能驱动（RAID）控制系统，结合径向基函数网络（RBFN）和一种新的自适应算法，以确保轮内执行系统能够跟踪每侧运动指令。为了进一步满足安全要求，提出的RAID控制限制了SSWMR MRNC框架中由人工智能生成的跟踪性能在预定义的超调和稳态误差限制内，同时通过补偿建模误差、未知RBF权重和外部力，确保系统的鲁棒性和稳定性。实验结果验证了该提出的MRNC框架在软地形上操作的4,836 kg SSWMR的性能。', 'title_zh': '基于LiDAR-惯性SLAM的履带式机器人导航及安全导向AI驱动控制系统'}
{'arxiv_id': 'arXiv:2505.02574', 'title': 'Learning and Online Replication of Grasp Forces from Electromyography Signals for Prosthetic Finger Control', 'authors': 'Robin Arbaud, Elisa Motta, Marco Domenico Avaro, Stefano Picinich, Marta Lorenzini, Arash Ajoudani', 'link': 'https://arxiv.org/abs/2505.02574', 'abstract': 'Partial hand amputations significantly affect the physical and psychosocial well-being of individuals, yet intuitive control of externally powered prostheses remains an open challenge. To address this gap, we developed a force-controlled prosthetic finger activated by electromyography (EMG) signals. The prototype, constructed around a wrist brace, functions as a supernumerary finger placed near the index, allowing for early-stage evaluation on unimpaired subjects. A neural network-based model was then implemented to estimate fingertip forces from EMG inputs, allowing for online adjustment of the prosthetic finger grip strength. The force estimation model was validated through experiments with ten participants, demonstrating its effectiveness in predicting forces. Additionally, online trials with four users wearing the prosthesis exhibited precise control over the device. Our findings highlight the potential of using EMG-based force estimation to enhance the functionality of prosthetic fingers.', 'abstract_zh': '部分手部截肢显著影响个体的生理和心理福祉，但外部动力假肢的直观控制仍是一项挑战。为解决这一问题，我们开发了一种由 electromyography (EMG) 信号控制的力控制假指，并将其原型构建于手腕固定器上，作为位于食指附近的人工额外手指，以在未受损个体上进行初步评估。随后，实现了一种基于神经网络的模型来从 EMG 输入中估计指尖力，从而实现假指握力的在线调整。通过十名参与者的实验验证了力估计模型的有效性，展示了其在预测力方面的性能。此外，四位穿戴该假肢的用户在线试验中展示了对设备的精确控制。我们的研究结果强调了使用基于 EMG 的力估计来增强假指功能的潜力。', 'title_zh': '基于 electromyography 信号的学习与在线复制握力控制arrings for 仿生指控制'}
{'arxiv_id': 'arXiv:2505.02460', 'title': 'ZeloS -- A Research Platform for Early-Stage Validation of Research Findings Related to Automated Driving', 'authors': 'Christopher Bohn, Florian Siebenrock, Janne Bosch, Tobias Hetzner, Samuel Mauch, Philipp Reis, Timo Staudt, Manuel Hess, Ben-Micha Piscol, Sören Hohmann', 'link': 'https://arxiv.org/abs/2505.02460', 'abstract': "This paper presents ZeloS, a research platform designed and built for practical validation of automated driving methods in an early stage of research. We overview ZeloS' hardware setup and automation architecture and focus on motion planning and control. ZeloS weighs 69 kg, measures a length of 117 cm, and is equipped with all-wheel steering, all-wheel drive, and various onboard sensors for localization. The hardware setup and the automation architecture of ZeloS are designed and built with a focus on modularity and the goal of being simple yet effective. The modular design allows the modification of individual automation modules without the need for extensive onboarding into the automation architecture. As such, this design supports ZeloS in being a versatile research platform for validating various automated driving methods. The motion planning component and control of ZeloS feature optimization-based methods that allow for explicitly considering constraints. We demonstrate the hardware and automation setup by presenting experimental data.", 'abstract_zh': '本文介绍了ZeloS，一个用于早期研究阶段自动驾驶方法实践验证的研究平台。我们概述了ZeloS的硬件配置和自动化架构，并重点介绍了运动规划与控制。', 'title_zh': 'ZeloS -- 一种用于自动化驾驶相关研究发现早期验证的研究平台'}
{'arxiv_id': 'arXiv:2505.02395', 'title': 'A Real-Time Control Barrier Function-Based Safety Filter for Motion Planning with Arbitrary Road Boundary Constraints', 'authors': 'Jianye Xu, Chang Che, Bassam Alrifaee', 'link': 'https://arxiv.org/abs/2505.02395', 'abstract': 'We present a real-time safety filter for motion planning, such as learning-based methods, using Control Barrier Functions (CBFs), which provides formal guarantees for collision avoidance with road boundaries. A key feature of our approach is its ability to directly incorporate road geometries of arbitrary shape without resorting to conservative overapproximations. We formulate the safety filter as a constrained optimization problem in the form of a Quadratic Program (QP). It achieves safety by making minimal, necessary adjustments to the control actions issued by the nominal motion planner. We validate our safety filter through extensive numerical experiments across a variety of traffic scenarios featuring complex roads. The results confirm its reliable safety and high computational efficiency (execution frequency up to 40 Hz). Code & Video Demo: this http URL', 'abstract_zh': '基于Control Barrier Functions的实时安全过滤器：一种无需保守近似的动态规划方法及其在复杂道路场景下的验证', 'title_zh': '基于实时控制障碍函数的安全滤波器在任意道路边界约束下的运动规划'}
{'arxiv_id': 'arXiv:2505.02323', 'title': 'Riemannian Direct Trajectory Optimization of Rigid Bodies on Matrix Lie Groups', 'authors': 'Sangli Teng, Tzu-Yuan Lin, William A Clark, Ram Vasudevan, Maani Ghaffari', 'link': 'https://arxiv.org/abs/2505.02323', 'abstract': 'Designing dynamically feasible trajectories for rigid bodies is a fundamental problem in robotics. Although direct trajectory optimization is widely applied to solve this problem, inappropriate parameterizations of rigid body dynamics often result in slow convergence and violations of the intrinsic topological structure of the rotation group. This paper introduces a Riemannian optimization framework for direct trajectory optimization of rigid bodies. We first use the Lie Group Variational Integrator to formulate the discrete rigid body dynamics on matrix Lie groups. We then derive the closed-form first- and second-order Riemannian derivatives of the dynamics. Finally, this work applies a line-search Riemannian Interior Point Method (RIPM) to perform trajectory optimization with general nonlinear constraints. As the optimization is performed on matrix Lie groups, it is correct-by-construction to respect the topological structure of the rotation group and be free of singularities. The paper demonstrates that both the derivative evaluations and Newton steps required to solve the RIPM exhibit linear complexity with respect to the planning horizon and system degrees of freedom. Simulation results illustrate that the proposed method is faster than conventional methods by an order of magnitude in challenging robotics tasks.', 'abstract_zh': '基于黎曼优化的刚体直接轨迹优化设计', 'title_zh': '刚体在矩阵李群上的黎曼直接轨迹优化'}
{'arxiv_id': 'arXiv:2505.02294', 'title': 'RNBF: Real-Time RGB-D Based Neural Barrier Functions for Safe Robotic Navigation', 'authors': 'Satyajeet Das, Yifan Xue, Haoming Li, Nadia Figueroa', 'link': 'https://arxiv.org/abs/2505.02294', 'abstract': 'Autonomous safe navigation in unstructured and novel environments poses significant challenges, especially when environment information can only be provided through low-cost vision sensors. Although safe reactive approaches have been proposed to ensure robot safety in complex environments, many base their theory off the assumption that the robot has prior knowledge on obstacle locations and geometries. In this paper, we present a real-time, vision-based framework that constructs continuous, first-order differentiable Signed Distance Fields (SDFs) of unknown environments without any pre-training. Our proposed method ensures full compatibility with established SDF-based reactive controllers. To achieve robust performance under practical sensing conditions, our approach explicitly accounts for noise in affordable RGB-D cameras, refining the neural SDF representation online for smoother geometry and stable gradient estimates. We validate the proposed method in simulation and real-world experiments using a Fetch robot.', 'abstract_zh': '自主导航于未结构化和新颖环境中的安全性面临显著挑战，尤其是在只能通过低成本视觉传感器提供环境信息的情况下。尽管安全反应式方法已被提出以确保机器人在复杂环境中的安全性，但许多方法的前提假设是机器人对障碍物的位置和几何结构有先验知识。在本文中，我们提出了一种实时的视觉基于框架，无需任何预训练即可构建未知环境的连续可微签量距离场（SDF）。所提出的方法确保了与现有的基于SDF的反应式控制器的完全兼容性。为了在实际传感条件下实现稳健的性能，我们的方法明确考虑了经济实惠的RGB-D摄像头中的噪声，通过在线细化神经网络表示的签量距离场，以获得更平滑的几何结构和稳定的梯度估计。我们在使用Fetch机器人进行的仿真和实际实验中验证了所提出的方法。', 'title_zh': 'RNBF: 基于实时RGB-D神经屏障函数的机器人安全导航'}
{'arxiv_id': 'arXiv:2505.02291', 'title': 'Dexterous Contact-Rich Manipulation via the Contact Trust Region', 'authors': 'H.J. Terry Suh, Tao Pang, Tong Zhao, Russ Tedrake', 'link': 'https://arxiv.org/abs/2505.02291', 'abstract': 'What is a good local description of contact dynamics for contact-rich manipulation, and where can we trust this local description? While many approaches often rely on the Taylor approximation of dynamics with an ellipsoidal trust region, we argue that such approaches are fundamentally inconsistent with the unilateral nature of contact. As a remedy, we present the Contact Trust Region (CTR), which captures the unilateral nature of contact while remaining efficient for computation. With CTR, we first develop a Model-Predictive Control (MPC) algorithm capable of synthesizing local contact-rich plans. Then, we extend this capability to plan globally by stitching together local MPC plans, enabling efficient and dexterous contact-rich manipulation. To verify the performance of our method, we perform comprehensive evaluations, both in high-fidelity simulation and on hardware, on two contact-rich systems: a planar IiwaBimanual system and a 3D AllegroHand system. On both systems, our method offers a significantly lower-compute alternative to existing RL-based approaches to contact-rich manipulation. In particular, our Allegro in-hand manipulation policy, in the form of a roadmap, takes fewer than 10 minutes to build offline on a standard laptop using just its CPU, with online inference taking just a few seconds. Experiment data, video and code are available at this http URL.', 'abstract_zh': '接触丰富的操作中良好的局部描述是什么，我们在哪里可以信任这种局部描述？尽管许多方法往往依靠具有椭球信任区域的动力学泰勒近似，我们argue认为这些方法本质上无法与单向接触的性质相一致。作为解决方案，我们提出了接触信任区域（CTR），它捕捉了接触的单向性质同时保持计算效率。使用CTR，我们首先开发了一个模型预测控制（MPC）算法，能够合成局部接触丰富的计划。然后，通过拼接局部MPC计划，将这一能力扩展到全局规划，从而实现高效的灵巧接触丰富操作。为了验证我们方法的性能，我们在高保真仿真和硬件上对两个接触丰富的系统——平面双臂iiwa系统和3D AllegroHand系统——进行了全面评估。在两个系统上，我们的方法提供了比现有基于强化学习的接触丰富操作方法更低计算量的替代方案。特别是，我们的Allegro手内操作策略以路网的形式，在标准笔记本电脑上仅使用CPU构建所需的时间少于10分钟，而在线推理只需几秒钟。更多实验数据、视频和代码可访问此链接。', 'title_zh': 'Dexterous接触丰富的 manipulation 通过接触信任区域'}
{'arxiv_id': 'arXiv:2505.02081', 'title': 'Simulation Based Control Architecture Using Webots and Simulink', 'authors': 'Harun Kurt, Ahmet Cayir, Kadir Erkan', 'link': 'https://arxiv.org/abs/2505.02081', 'abstract': 'This paper presents a simulation based control architecture that integrates Webots and Simulink for the development and testing of robotic systems. Using Webots for 3D physics based simulation and Simulink for control system design, real time testing and controller validation are achieved efficiently. The proposed approach aims to reduce hardware in the loop dependency in early development stages, offering a cost effective and modular control framework for academic, industrial, and robotics applications.', 'abstract_zh': '基于Webots和Simulink的仿真驱动控制架构及其在机器人系统开发与测试中的应用', 'title_zh': '基于Webots和Simulink的仿真驱动控制架构'}
{'arxiv_id': 'arXiv:2505.01974', 'title': 'KineDex: Learning Tactile-Informed Visuomotor Policies via Kinesthetic Teaching for Dexterous Manipulation', 'authors': 'Di Zhang, Chengbo Yuan, Chuan Wen, Hai Zhang, Junqiao Zhao, Yang Gao', 'link': 'https://arxiv.org/abs/2505.01974', 'abstract': "Collecting demonstrations enriched with fine-grained tactile information is critical for dexterous manipulation, particularly in contact-rich tasks that require precise force control and physical interaction. While prior works primarily focus on teleoperation or video-based retargeting, they often suffer from kinematic mismatches and the absence of real-time tactile feedback, hindering the acquisition of high-fidelity tactile data. To mitigate this issue, we propose KineDex, a hand-over-hand kinesthetic teaching paradigm in which the operator's motion is directly transferred to the dexterous hand, enabling the collection of physically grounded demonstrations enriched with accurate tactile feedback. To resolve occlusions from human hand, we apply inpainting technique to preprocess the visual observations. Based on these demonstrations, we then train a visuomotor policy using tactile-augmented inputs and implement force control during deployment for precise contact-rich manipulation. We evaluate KineDex on a suite of challenging contact-rich manipulation tasks, including particularly difficult scenarios such as squeezing toothpaste onto a toothbrush, which require precise multi-finger coordination and stable force regulation. Across these tasks, KineDex achieves an average success rate of 74.4%, representing a 57.7% improvement over the variant without force control. Comparative experiments with teleoperation and user studies further validate the advantages of KineDex in data collection efficiency and operability. Specifically, KineDex collects data over twice as fast as teleoperation across two tasks of varying difficulty, while maintaining a near-100% success rate, compared to under 50% for teleoperation.", 'abstract_zh': '富含细粒度触觉信息的演示收集对于灵巧操作至关重要，特别是在需要精确力控制和物理交互的接触丰富任务中。尽管前期工作主要关注于遥操作或基于视频的重目标，但它们经常遭受运动学不匹配和实时触觉反馈缺失的问题，阻碍了高质量触觉数据的采集。为解决这一问题，我们提出了KineDex，一种手把手的触觉教学范式，操作者的运动直接转移到灵巧手中，从而能够收集富含准确触觉反馈的物理接地演示。为解决人类手部遮挡问题，我们应用 inpainting 技术预处理视觉观察。基于这些演示，我们使用触觉增强的输入训练了一种视触觉策略，并在部署过程中实施了力控制以实现精确的接触丰富操作。我们在一系列接触丰富操作任务上评估了KineDex，包括需要精确多指协调和稳定力调节的特别困难场景，如将牙膏挤到牙刷上。在这些任务中，KineDex 的平均成功率达到了 74.4%，与不使用力控制的变体相比，提高了 57.7%。与遥操作的比较实验和用户研究表明，KineDex 在数据采集效率和可操作性方面具有优势。特别是，KineDex 在两个不同难度级别的任务中数据采集速度比遥操作快两倍，且成功率达到近 100%，而遥操作的成功率不到 50%。', 'title_zh': 'KineDex: 通过动能教学学习触觉指导的视知觉运动策略以实现灵巧 manipulation'}
{'arxiv_id': 'arXiv:2505.01956', 'title': 'SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment', 'authors': 'Ganesh Sapkota, Sanjay Madria', 'link': 'https://arxiv.org/abs/2505.01956', 'abstract': 'In battlefield environments, adversaries frequently disrupt GPS signals, requiring alternative localization and navigation methods. Traditional vision-based approaches like Simultaneous Localization and Mapping (SLAM) and Visual Odometry (VO) involve complex sensor fusion and high computational demand, whereas range-free methods like DV-HOP face accuracy and stability challenges in sparse, dynamic networks. This paper proposes LanBLoc-BMM, a navigation approach using landmark-based localization (LanBLoc) combined with a battlefield-specific motion model (BMM) and Extended Kalman Filter (EKF). Its performance is benchmarked against three state-of-the-art visual localization algorithms integrated with BMM and Bayesian filters, evaluated on synthetic and real-imitated trajectory datasets using metrics including Average Displacement Error (ADE), Final Displacement Error (FDE), and a newly introduced Average Weighted Risk Score (AWRS). LanBLoc-BMM (with EKF) demonstrates superior performance in ADE, FDE, and AWRS on real-imitated datasets. Additionally, two safe navigation methods, SafeNav-CHull and SafeNav-Centroid, are introduced by integrating LanBLoc-BMM(EKF) with a novel Risk-Aware RRT* (RAw-RRT*) algorithm for obstacle avoidance and risk exposure minimization. Simulation results in battlefield scenarios indicate SafeNav-Centroid excels in accuracy, risk exposure, and trajectory efficiency, while SafeNav-CHull provides superior computational speed.', 'abstract_zh': '基于地标定位和战场特定运动模型的扩展卡尔曼滤波导航方法', 'title_zh': 'SafeNav: 基于地标定位的GPS受限环境中安全路径导航'}
{'arxiv_id': 'arXiv:2505.01752', 'title': 'NMPCB: A Lightweight and Safety-Critical Motion Control Framework', 'authors': 'Longze Zheng, Qinghe Liu', 'link': 'https://arxiv.org/abs/2505.01752', 'abstract': 'In multi-obstacle environments, real-time performance and safety in robot motion control have long been challenging issues, as conventional methods often struggle to balance the two. In this paper, we propose a novel motion control framework composed of a Neural network-based path planner and a Model Predictive Control (MPC) controller based on control Barrier function (NMPCB) . The planner predicts the next target point through a lightweight neural network and generates a reference trajectory for the controller. In the design of the controller, we introduce the dual problem of control barrier function (CBF) as the obstacle avoidance constraint, enabling it to ensure robot motion safety while significantly reducing computation time. The controller directly outputs control commands to the robot by tracking the reference trajectory. This framework achieves a balance between real-time performance and safety. We validate the feasibility of the framework through numerical simulations and real-world experiments.', 'abstract_zh': '在多障碍物环境中，机器人的实时性能和运动控制安全性长期是具有挑战性的问题，因为传统方法往往难以在这两者之间找到平衡。本文提出了一种新颖的运动控制框架，该框架由基于神经网络的路径规划器和基于控制屏障函数（CBF）的模型预测控制（NMPCB）控制器组成。规划器通过轻量级神经网络预测下一个目标点，并生成供控制器使用的参考轨迹。在控制器的设计中，我们引入控制屏障函数的对偶问题作为避障约束，使其能够在显著减少计算时间的同时保证机器人的运动安全。控制器直接通过跟踪参考轨迹输出控制命令。该框架实现了实时性能和安全性之间的平衡。我们通过数值仿真和实际实验验证了该框架的可行性。', 'title_zh': 'NMPCB: 一种轻量级和安全关键的运动控制框架'}
{'arxiv_id': 'arXiv:2505.01718', 'title': 'Mitigating Compensatory Movements in Prosthesis Users via Adaptive Collaborative Robotics', 'authors': 'Marta Lagomarsino, Robin Arbaud, Francesco Tassi, Arash Ajoudani', 'link': 'https://arxiv.org/abs/2505.01718', 'abstract': "Prosthesis users can regain partial limb functionality, however, full natural limb mobility is rarely restored, often resulting in compensatory movements that lead to discomfort, inefficiency, and long-term physical strain. To address this issue, we propose a novel human-robot collaboration framework to mitigate compensatory mechanisms in upper-limb prosthesis users by exploiting their residual motion capabilities while respecting task requirements. Our approach introduces a personalised mobility model that quantifies joint-specific functional limitations and the cost of compensatory movements. This model is integrated into a constrained optimisation framework that computes optimal user postures for task performance, balancing functionality and comfort. The solution guides a collaborative robot to reconfigure the task environment, promoting effective interaction. We validated the framework using a new body-powered prosthetic device for single-finger amputation, which enhances grasping capabilities through synergistic closure with the hand but imposes wrist constraints. Initial experiments with healthy subjects wearing the prosthesis as a supernumerary finger demonstrated that a robotic assistant embedding the user-specific mobility model outperformed human partners in handover tasks, improving both the efficiency of the prosthesis user's grasp and reducing compensatory movements in functioning joints. These results highlight the potential of collaborative robots as effective workplace and caregiving assistants, promoting inclusion and better integration of prosthetic devices into daily tasks.", 'abstract_zh': '假肢用户可以恢复部分肢体功能，但通常难以恢复完全自然的肢体灵活性，往往会导致代偿动作，引起不适、效率低下和长期的身体负担。为解决这一问题，我们提出了一种新型的人机协作框架，通过利用用户残存的运动能力来减轻上肢假肢单用户中的代偿机制，同时尊重任务要求。该方法引入了一个个性化的运动模型，量化了关节特异性的功能限制和代偿动作的成本。该模型被整合到一个受约束的优化框架中，该框架计算任务执行时的最佳用户姿势，平衡功能和舒适性。该解决方案引导协作机器人重新配置任务环境，促进有效互动。我们使用一种新的体驱动假肢装置对单指缺失进行了验证，该装置通过与手的协同闭合来增强抓握能力，但对手腕施加了限制。初步实验表明，配备了用户特定运动模型的机器人助手在手递手任务中优于人类伙伴，既提高了假肢使用者的抓握效率，又减少了功能关节的代偿动作。这些结果突显了协作机器人作为有效的工作场所和护理助手的潜力，促进了假肢设备在日常任务中的包容性和更好整合。', 'title_zh': '通过自适应协作机器人减轻假肢用户补偿运动的影响'}
{'arxiv_id': 'arXiv:2505.01654', 'title': 'T-REX: Vision-Based System for Autonomous Leaf Detection and Grasp Estimation', 'authors': 'Srecharan Selvam, Abhisesh Silwal, George Kantor', 'link': 'https://arxiv.org/abs/2505.01654', 'abstract': 'T-Rex (The Robot for Extracting Leaf Samples) is a gantry-based robotic system developed for autonomous leaf localization, selection, and grasping in greenhouse environments. The system integrates a 6-degree-of-freedom manipulator with a stereo vision pipeline to identify and interact with target leaves. YOLOv8 is used for real-time leaf segmentation, and RAFT-Stereo provides dense depth maps, allowing the reconstruction of 3D leaf masks. These observations are processed through a leaf grasping algorithm that selects the optimal leaf based on clutter, visibility, and distance, and determines a grasp point by analyzing local surface flatness, top-down approachability, and margin from edges. The selected grasp point guides a trajectory executed by ROS-based motion controllers, driving a custom microneedle-equipped end-effector to clamp the leaf and simulate tissue sampling. Experiments conducted with artificial plants under varied poses demonstrate that the T-Rex system can consistently detect, plan, and perform physical interactions with plant-like targets, achieving a grasp success rate of 66.6\\%. This paper presents the system architecture, implementation, and testing of T-Rex as a step toward plant sampling automation in Controlled Environment Agriculture (CEA).', 'abstract_zh': 'T-Rex（用于提取叶片样本的机器人）是为温室环境中自主叶片定位、选择和抓取而开发的基于龙门架的机器人系统。该系统集成了六自由度 manipulator 与立体视觉处理管道，用于识别和与目标叶片交互。YOLOv8 用于实时叶片分割，RAFT-Stereo 提供密集深度图，允许重建叶片的 3D 掩模。这些观察结果通过叶片抓取算法处理，该算法根据杂物、可见性和距离选择最优叶片，并通过分析局部表面平坦度、顶部可接近性和边缘距离来确定握持点。选定的握持点引导由 ROS 基础运动控制器执行的轨迹，驱动配备微针的自定义末端执行器夹紧叶片并模拟组织取样。在不同姿态的人工植物上进行的实验表明，T-Rex 系统可以一致地检测、规划并与植物样靶进行物理交互，实现夹持成功率 66.6%。本文介绍了 T-Rex 的系统架构、实现和测试，旨在推进受控环境农业（CEA）中的植物采样自动化。', 'title_zh': '基于视觉的自主叶片检测与抓取估计系统'}
{'arxiv_id': 'arXiv:2505.01624', 'title': 'Triangle-Decomposable Graphs for Isoperimetric Robots', 'authors': 'Nathan Usevitch, Isaac Weaver, James Usevitch', 'link': 'https://arxiv.org/abs/2505.01624', 'abstract': 'Isoperimetric robots are large scale, untethered inflatable robots that can undergo large shape changes, but have only been demonstrated in one 3D shape -- an octahedron. These robots consist of independent triangles that can change shape while maintaining their perimeter by moving the relative position of their joints. We introduce an optimization routine that determines if an arbitrary graph can be partitioned into unique triangles, and thus be constructed as an isoperimetric robotic system. We enumerate all minimally rigid graphs that can be constructed with unique triangles up to 9 nodes (7 triangles), and characterize the workspace of one node of each these robots. We also present a method for constructing larger graphs that can be partitioned by assembling subgraphs that are already partitioned into triangles. This enables a wide variety of isoperimetric robot configurations.', 'abstract_zh': '可周长性的机器人是由独立三角形组成的大型无缆充气机器人，能够发生显著形状变化，但仅在八面体这一种三维形状中得到证明。本文介绍了一种优化方法，用于判断任意图形是否可以分解为唯一的三角形，从而被构建为可周长性机器人系统。我们列出了最多包含9个节点（7个三角形）的全部最小刚性图形，并对其每个节点的工作空间进行了characterization。我们还提出了一种方法，通过组装已经分解为三角形的子图形来构建更大的图形。这使得可周长性机器人的配置更为多样化。', 'title_zh': '三角分解图中的等周机器人'}
{'arxiv_id': 'arXiv:2505.01617', 'title': 'High Speed Robotic Table Tennis Swinging Using Lightweight Hardware with Model Predictive Control', 'authors': 'David Nguyen, Kendrick D. Cancio, Sangbae Kim', 'link': 'https://arxiv.org/abs/2505.01617', 'abstract': 'We present a robotic table tennis platform that achieves a variety of hit styles and ball-spins with high precision, power, and consistency. This is enabled by a custom lightweight, high-torque, low rotor inertia, five degree-of-freedom arm capable of high acceleration. To generate swing trajectories, we formulate an optimal control problem (OCP) that constrains the state of the paddle at the time of the strike. The terminal position is given by a predicted ball trajectory, and the terminal orientation and velocity of the paddle are chosen to match various possible styles of hits: loops (topspin), drives (flat), and chops (backspin). Finally, we construct a fixed-horizon model predictive controller (MPC) around this OCP to allow the hardware to quickly react to changes in the predicted ball trajectory. We validate on hardware that the system is capable of hitting balls with an average exit velocity of 11 m/s at an 88% success rate across the three swing types.', 'abstract_zh': '一种实现高精度、高功率和高一致性的乒乓球机器人平台及其控制方法', 'title_zh': '使用轻量化硬件和模型预测控制的高速机器人乒乓球摆动'}
{'arxiv_id': 'arXiv:2505.01515', 'title': 'Comparison of Waymo Rider-Only Crash Rates by Crash Type to Human Benchmarks at 56.7 Million Miles', 'authors': 'Kristofer D. Kusano, John M. Scanlon, Yin-Hsiu Chen, Timothy L. McMurry, Tilia Gode, Trent Victor', 'link': 'https://arxiv.org/abs/2505.01515', 'abstract': "SAE Level 4 Automated Driving Systems (ADSs) are deployed on public roads, including Waymo's Rider-Only (RO) ride-hailing service (without a driver behind the steering wheel). The objective of this study was to perform a retrospective safety assessment of Waymo's RO crash rate compared to human benchmarks, including disaggregated by crash type.\nEleven crash type groups were identified from commonly relied upon crash typologies that are derived from human crash databases. Human benchmarks were aligned to the same vehicle types, road types, and locations as where the Waymo Driver operated. Waymo crashes were extracted from the NHTSA Standing General Order (SGO). RO mileage was provided by the company via a public website. Any-injury-reported, Airbag Deployment, and Suspected Serious Injury+ crash outcomes were examined because they represented previously established, safety-relevant benchmarks where statistical testing could be performed at the current mileage.\nData was examined over 56.7 million RO miles through the end of January 2025, resulting in a statistically significant lower crashed vehicle rate for all crashes compared to the benchmarks in Any-Injury-Reported and Airbag Deployment, and Suspected Serious Injury+ crashes. Of the crash types, V2V Intersection crash events represented the largest total crash reduction, with a 96% reduction in Any-injury-reported (87%-99% CI) and a 91% reduction in Airbag Deployment (76%-98% CI) events. Cyclist, Motorcycle, Pedestrian, Secondary Crash, and Single Vehicle crashes were also statistically reduced for the Any-Injury-Reported outcome. There was no statistically significant disbenefit found in any of the 11 crash type groups.\nThis study represents the first retrospective safety assessment of an RO ADS that made statistical conclusions about more serious crash outcomes and analyzed crash rates on a crash type basis.", 'abstract_zh': 'SAE Level 4 自动驾驶系统 (ADS) 在公共道路上的应用，包括 Waymo 仅乘客（RO）网约车服务（无驾驶者）。本研究旨在对比 Waymo RO 碰撞率与人类基准，包括按碰撞类型细分。', 'title_zh': 'Waymo仅乘客车祸类型比率与人类基准在5670万公里的比较'}
{'arxiv_id': 'arXiv:2505.01486', 'title': 'Aerial Path Online Planning for Urban Scene Updation', 'authors': 'Mingfeng Tang, Ziyuan Xie, Ke Xie, Hui Huang, Jianwei Hu, Ningna Wang, Xiaohu Guo', 'link': 'https://arxiv.org/abs/2505.01486', 'abstract': 'We present the first scene-update aerial path planning algorithm specifically designed for detecting and updating change areas in urban environments. While existing methods for large-scale 3D urban scene reconstruction focus on achieving high accuracy and completeness, they are inefficient for scenarios requiring periodic updates, as they often re-explore and reconstruct entire scenes, wasting significant time and resources on unchanged areas. To address this limitation, our method leverages prior reconstructions and change probability statistics to guide UAVs in detecting and focusing on areas likely to have changed. Our approach introduces a novel changeability heuristic to evaluate the likelihood of changes, driving the planning of two flight paths: a prior path informed by static priors and a dynamic real-time path that adapts to newly detected changes. The framework integrates surface sampling and candidate view generation strategies, ensuring efficient coverage of change areas with minimal redundancy. Extensive experiments on real-world urban datasets demonstrate that our method significantly reduces flight time and computational overhead, while maintaining high-quality updates comparable to full-scene re-exploration and reconstruction. These contributions pave the way for efficient, scalable, and adaptive UAV-based scene updates in complex urban environments.', 'abstract_zh': '我们提出了首个专门用于检测和更新城市环境中变化区域的场景更新空中路径规划算法。现有的大规模3D城市场景重建方法侧重于提高准确性和完整性，但在需要定期更新的场景中效率低下，因为它们往往会重新探索和重建整个场景，浪费大量时间和资源在未发生变化的区域上。为解决这一限制，我们的方法利用先验重建和变化概率统计来引导无人机检测和关注可能发生变化的区域。我们的方法引入了一种新颖的变化性启发式方法，以评估变化的可能性，并据此规划两种飞行路径：一种基于静态先验信息的先验路径，一种动态实时路径，能够根据新检测到的变化进行适应调整。该框架集成了表面采样和候选视图生成策略，以确保高效覆盖变化区域，同时减少冗余。在现实世界的城市数据集上的广泛实验表明，我们的方法显著减少了飞行时间和计算开销，同时保持了与完全场景重新探索和重建相当的质量更新。这些贡献为复杂城市环境中高效的、可扩展的和自适应的无人机基于场景更新铺平了道路。', 'title_zh': '城市场景更新的空中路径在线规划'}
{'arxiv_id': 'arXiv:2505.01947', 'title': 'Runtime Anomaly Detection for Drones: An Integrated Rule-Mining and Unsupervised-Learning Approach', 'authors': 'Ivan Tan, Wei Minn, Christopher M. Poskitt, Lwin Khin Shar, Lingxiao Jiang', 'link': 'https://arxiv.org/abs/2505.01947', 'abstract': 'UAVs, commonly referred to as drones, have witnessed a remarkable surge in popularity due to their versatile applications. These cyber-physical systems depend on multiple sensor inputs, such as cameras, GPS receivers, accelerometers, and gyroscopes, with faults potentially leading to physical instability and serious safety concerns. To mitigate such risks, anomaly detection has emerged as a crucial safeguarding mechanism, capable of identifying the physical manifestations of emerging issues and allowing operators to take preemptive action at runtime. Recent anomaly detection methods based on LSTM neural networks have shown promising results, but three challenges persist: the need for models that can generalise across the diverse mission profiles of drones; the need for interpretability, enabling operators to understand the nature of detected problems; and the need for capturing domain knowledge that is difficult to infer solely from log data. Motivated by these challenges, this paper introduces RADD, an integrated approach to anomaly detection in drones that combines rule mining and unsupervised learning. In particular, we leverage rules (or invariants) to capture expected relationships between sensors and actuators during missions, and utilise unsupervised learning techniques to cover more subtle relationships that the rules may have missed. We implement this approach using the ArduPilot drone software in the Gazebo simulator, utilising 44 rules derived across the main phases of drone missions, in conjunction with an ensemble of five unsupervised learning models. We find that our integrated approach successfully detects 93.84% of anomalies over six types of faults with a low false positive rate (2.33%), and can be deployed effectively at runtime. Furthermore, RADD outperforms a state-of-the-art LSTM-based method in detecting the different types of faults evaluated in our study.', 'abstract_zh': 'UAVs（无人机）由于其多样的应用而见证了显著的 popularity 增长。这些网络物理系统依赖于多种传感器输入，如摄像头、GPS 接收器、加速度计和陀螺仪，故障可能导致物理不稳定性和严重的安全问题。为了减轻这些风险，异常检测已成为一种关键的安全机制，能够识别新兴问题的物理表现，并允许操作者在运行时采取预防措施。基于 LSTM 神经网络的最近异常检测方法展示了有前途的结果，但存在三个挑战：能够普遍适用于无人机多样化任务配置的模型需求；增加可解释性，使操作者能够理解检测到的问题的性质；以及捕捉仅从日志数据中难以推断的领域知识的需求。基于这些挑战，本文介绍了一种集成的无人机异常检测方法 RADD，该方法结合了规则挖掘和无监督学习。特别是，我们利用规则（或不变量）来捕获任务期间传感器和执行器之间预期的关系，并利用无监督学习技术来覆盖规则可能遗漏的更微妙的关系。我们使用 ArduPilot 无人机软件在 Gazebo 模拟器中实现该方法，利用跨越无人机任务主要阶段的 44 条规则，结合五种无监督学习模型的集成。我们发现，我们的集成方法在六种类型故障中成功检测了 93.84% 的异常，且假阳性率较低（2.33%），并且可以在运行时有效部署。此外，RADD 在检测我们在研究中评估的不同类型故障方面优于最先进的基于 LSTM 的方法。', 'title_zh': '无人机运行异常检测：一种集成规则挖掘和无监督学习的方法'}
