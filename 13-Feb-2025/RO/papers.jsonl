{'arxiv_id': 'arXiv:2502.08645', 'title': 'Re$^3$Sim: Generating High-Fidelity Simulation Data via 3D-Photorealistic Real-to-Sim for Robotic Manipulation', 'authors': 'Xiaoshen Han, Minghuan Liu, Yilun Chen, Junqiu Yu, Xiaoyang Lyu, Yang Tian, Bolun Wang, Weinan Zhang, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2502.08645', 'abstract': 'Real-world data collection for robotics is costly and resource-intensive, requiring skilled operators and expensive hardware. Simulations offer a scalable alternative but often fail to achieve sim-to-real generalization due to geometric and visual gaps. To address these challenges, we propose a 3D-photorealistic real-to-sim system, namely, RE$^3$SIM, addressing geometric and visual sim-to-real gaps. RE$^3$SIM employs advanced 3D reconstruction and neural rendering techniques to faithfully recreate real-world scenarios, enabling real-time rendering of simulated cross-view cameras within a physics-based simulator. By utilizing privileged information to collect expert demonstrations efficiently in simulation, and train robot policies with imitation learning, we validate the effectiveness of the real-to-sim-to-real pipeline across various manipulation task scenarios. Notably, with only simulated data, we can achieve zero-shot sim-to-real transfer with an average success rate exceeding 58%. To push the limit of real-to-sim, we further generate a large-scale simulation dataset, demonstrating how a robust policy can be built from simulation data that generalizes across various objects. Codes and demos are available at: this http URL.', 'abstract_zh': '真实世界数据收集对于机器人技术来说成本高且资源密集，需要 skilled 操作员和昂贵的硬件。模拟提供了可扩展的替代方案，但由于几何和视觉缺口，往往无法实现从模拟到现实的有效迁移。为了解决这些挑战，我们提出了一个3D-写实的真实世界到模拟系统，即 RE$^3$SIM，以解决几何和视觉上的模拟到现实的缺口。RE$^3$SIM 使用先进的3D重建和神经渲染技术忠实再现真实世界场景，在基于物理的模拟器中实时渲染模拟交叉视角相机。通过利用特权信息高效地在模拟中收集专家演示，并使用模仿学习训练机器人策略，我们验证了真实世界到模拟再到现实流水线在各种操作任务场景中的有效性。值得注意的是，仅使用模拟数据，我们可以实现零样本的模拟到现实迁移，成功率平均超过58%。为进一步推动真实世界到模拟的极限，我们还生成了一个大规模的模拟数据集，展示了如何从模拟数据中构建一个鲁棒策略，并在各种物体上有效推广。代码和演示可在：this http URL 获取。', 'title_zh': 'Re$^3$Sim: 通过3D逼真实时转换生成机器人操作的高保真模拟数据'}
{'arxiv_id': 'arXiv:2502.08643', 'title': 'A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards', 'authors': 'Shivansh Patel, Xinchen Yin, Wenlong Huang, Shubham Garg, Hooshang Nayyeri, Li Fei-Fei, Svetlana Lazebnik, Yunzhu Li', 'link': 'https://arxiv.org/abs/2502.08643', 'abstract': "Task specification for robotic manipulation in open-world environments is challenging, requiring flexible and adaptive objectives that align with human intentions and can evolve through iterative feedback. We introduce Iterative Keypoint Reward (IKER), a visually grounded, Python-based reward function that serves as a dynamic task specification. Our framework leverages VLMs to generate and refine these reward functions for multi-step manipulation tasks. Given RGB-D observations and free-form language instructions, we sample keypoints in the scene and generate a reward function conditioned on these keypoints. IKER operates on the spatial relationships between keypoints, leveraging commonsense priors about the desired behaviors, and enabling precise SE(3) control. We reconstruct real-world scenes in simulation and use the generated rewards to train reinforcement learning (RL) policies, which are then deployed into the real world-forming a real-to-sim-to-real loop. Our approach demonstrates notable capabilities across diverse scenarios, including both prehensile and non-prehensile tasks, showcasing multi-step task execution, spontaneous error recovery, and on-the-fly strategy adjustments. The results highlight IKER's effectiveness in enabling robots to perform multi-step tasks in dynamic environments through iterative reward shaping.", 'abstract_zh': '开放世界环境中机器人操作的任务指定具有挑战性，要求灵活且适应性强的目标，能与人类意图对齐并通过迭代反馈进行演化。我们引入了迭代关键点奖励（IKER），这是一种基于视觉的、用Python编写的奖励函数，作为动态任务指定。我们的框架利用VLMs生成和细化这些奖励函数以适应多步骤操作任务。给定RGB-D观察和自由形式的语言指令，我们在场景中采样关键点，并生成条件依赖于这些关键点的奖励函数。IKER基于关于期望行为的常识先验，操作关键点间的空间关系，实现精确的SE(3)控制。我们在模拟中重构现实场景，使用生成的奖励训练强化学习（RL）策略，然后部署到现实世界，形成了一个从现实到模拟再到现实的闭环。我们的方法在多种场景中展示了显著的能力，包括抓持和非抓持任务，展示了多步骤任务执行、自发错误恢复和实时策略调整。实验结果强调了IKER在通过迭代奖励塑造使机器人能够在动态环境中执行多步骤任务方面的有效性。', 'title_zh': '一种基于VLM生成迭代关键点奖励的实到 sim 再到实的机器人 manipulation 方法'}
{'arxiv_id': 'arXiv:2502.08623', 'title': 'Robot Data Curation with Mutual Information Estimators', 'authors': 'Joey Hejna, Suvir Mirchandani, Ashwin Balakrishna, Annie Xie, Ayzaan Wahid, Jonathan Tompson, Pannag Sanketi, Dhruv Shah, Coline Devin, Dorsa Sadigh', 'link': 'https://arxiv.org/abs/2502.08623', 'abstract': 'The performance of imitation learning policies often hinges on the datasets with which they are trained. Consequently, investment in data collection for robotics has grown across both industrial and academic labs. However, despite the marked increase in the quantity of demonstrations collected, little work has sought to assess the quality of said data despite mounting evidence of its importance in other areas such as vision and language. In this work, we take a critical step towards addressing the data quality in robotics. Given a dataset of demonstrations, we aim to estimate the relative quality of individual demonstrations in terms of both state diversity and action predictability. To do so, we estimate the average contribution of a trajectory towards the mutual information between states and actions in the entire dataset, which precisely captures both the entropy of the state distribution and the state-conditioned entropy of actions. Though commonly used mutual information estimators require vast amounts of data often beyond the scale available in robotics, we introduce a novel technique based on k-nearest neighbor estimates of mutual information on top of simple VAE embeddings of states and actions. Empirically, we demonstrate that our approach is able to partition demonstration datasets by quality according to human expert scores across a diverse set of benchmarks spanning simulation and real world environments. Moreover, training policies based on data filtered by our method leads to a 5-10% improvement in RoboMimic and better performance on real ALOHA and Franka setups.', 'abstract_zh': 'imitation学习策略的表现往往取决于其训练所用的数据集。因此，工业和学术实验室在机器人领域的数据收集投资都有所增长。尽管收集的演示数据量显著增加，但很少有研究致力于评估这些数据的质量，尽管其他领域如视觉和语言的证据表明数据质量十分重要。在本文中，我们朝着解决机器人领域的数据质量问题迈出了关键一步。给定一组演示数据，我们旨在从状态多样性和动作可预测性的角度估计单个演示的质量。为此，我们估计轨迹对整个数据集中状态和动作之间互信息的平均贡献，这准确地捕捉到了状态分布的熵和动作条件熵。尽管常用的互信息估计器通常需要大量数据，往往超过机器人领域可获得的规模，我们提出了基于k-最近邻互信息估计和简单的VAE状态-动作嵌入的新技术。通过实验证明，我们的方法可以根据人类专家评分对不同基准测试中的模拟和真实环境的演示数据集进行按质量分割。此外，使用我们方法过滤后的数据训练策略在RoboMimic上的性能提高了5-10%，在真实的ALOHA和Franka系统上表现更好。', 'title_zh': '基于互信息估计器的机器人数据整理'}
{'arxiv_id': 'arXiv:2502.08452', 'title': 'Learning to Group and Grasp Multiple Objects', 'authors': 'Takahiro Yonemaru, Weiwei Wan, Tatsuki Nishimura, Kensuke Harada', 'link': 'https://arxiv.org/abs/2502.08452', 'abstract': 'Simultaneously grasping and transporting multiple objects can significantly enhance robotic work efficiency and has been a key research focus for decades. The primary challenge lies in determining how to push objects, group them, and execute simultaneous grasping for respective groups while considering object distribution and the hardware constraints of the robot. Traditional rule-based methods struggle to flexibly adapt to diverse scenarios. To address this challenge, this paper proposes an imitation learning-based approach. We collect a series of expert demonstrations through teleoperation and train a diffusion policy network, enabling the robot to dynamically generate action sequences for pushing, grouping, and grasping, thereby facilitating efficient multi-object grasping and transportation. We conducted experiments to evaluate the method under different training dataset sizes, varying object quantities, and real-world object scenarios. The results demonstrate that the proposed approach can effectively and adaptively generate multi-object grouping and grasping strategies. With the support of more training data, imitation learning is expected to be an effective approach for solving the multi-object grasping problem.', 'abstract_zh': '同时抓取和运输多个物体能显著提升机器人工作效率，一直是数十年来的关键研究方向。主要挑战在于如何推动物体、分组并执行针对各自组别的同时抓取，同时考虑物体分布和机器人的硬件限制。传统的基于规则的方法难以灵活适应各种场景。为应对这一挑战，本文提出了一种模拟学习方法。我们通过遥控操作收集了一系列专家演示，并训练了一个扩散策略网络，使机器人能够动态生成推动物体、分组和抓取的动作序列，从而促进高效的多物体抓取和运输。我们在不同训练数据集大小、不同物体数量和真实世界物体场景下进行了实验评估。结果表明，所提出的方法能够有效地且适应性地生成多物体分组和抓取策略。随着训练数据的支持，模拟学习有望成为解决多物体抓取问题的有效方法。', 'title_zh': '学习分组和抓取多个物体'}
{'arxiv_id': 'arXiv:2502.08449', 'title': 'CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World', 'authors': 'Yankai Fu, Qiuxuan Feng, Ning Chen, Zichen Zhou, Mengzhen Liu, Mingdong Wu, Tianxing Chen, Shanyu Rong, Jiaming Liu, Hao Dong, Shanghang Zhang', 'link': 'https://arxiv.org/abs/2502.08449', 'abstract': 'Achieving human-level dexterity in robots is a key objective in the field of robotic manipulation. Recent advancements in 3D-based imitation learning have shown promising results, providing an effective pathway to achieve this goal. However, obtaining high-quality 3D representations presents two key problems: (1) the quality of point clouds captured by a single-view camera is significantly affected by factors such as camera resolution, positioning, and occlusions caused by the dexterous hand; (2) the global point clouds lack crucial contact information and spatial correspondences, which are necessary for fine-grained dexterous manipulation tasks. To eliminate these limitations, we propose CordViP, a novel framework that constructs and learns correspondences by leveraging the robust 6D pose estimation of objects and robot proprioception. Specifically, we first introduce the interaction-aware point clouds, which establish correspondences between the object and the hand. These point clouds are then used for our pre-training policy, where we also incorporate object-centric contact maps and hand-arm coordination information, effectively capturing both spatial and temporal dynamics. Our method demonstrates exceptional dexterous manipulation capabilities with an average success rate of 90\\% in four real-world tasks, surpassing other baselines by a large margin. Experimental results also highlight the superior generalization and robustness of CordViP to different objects, viewpoints, and scenarios. Code and videos are available on this https URL.', 'abstract_zh': '基于3D模仿学习的机器人实现人类级别的灵巧操作：一种新颖框架CordViP的研究', 'title_zh': 'Correspondence-based Visuomotor Policy for Dexterous Manipulation in the Real World'}
{'arxiv_id': 'arXiv:2502.08378', 'title': 'Learning Humanoid Standing-up Control across Diverse Postures', 'authors': 'Tao Huang, Junli Ren, Huayi Wang, Zirui Wang, Qingwei Ben, Muning Wen, Xiao Chen, Jianan Li, Jiangmiao Pang', 'link': 'https://arxiv.org/abs/2502.08378', 'abstract': 'Standing-up control is crucial for humanoid robots, with the potential for integration into current locomotion and loco-manipulation systems, such as fall recovery. Existing approaches are either limited to simulations that overlook hardware constraints or rely on predefined ground-specific motion trajectories, failing to enable standing up across postures in real-world scenes. To bridge this gap, we present HoST (Humanoid Standing-up Control), a reinforcement learning framework that learns standing-up control from scratch, enabling robust sim-to-real transfer across diverse postures. HoST effectively learns posture-adaptive motions by leveraging a multi-critic architecture and curriculum-based training on diverse simulated terrains. To ensure successful real-world deployment, we constrain the motion with smoothness regularization and implicit motion speed bound to alleviate oscillatory and violent motions on physical hardware, respectively. After simulation-based training, the learned control policies are directly deployed on the Unitree G1 humanoid robot. Our experimental results demonstrate that the controllers achieve smooth, stable, and robust standing-up motions across a wide range of laboratory and outdoor environments. Videos are available at this https URL.', 'abstract_zh': '基于强化学习的人形机器人站立控制：HoST框架', 'title_zh': '学习跨越多种姿态的人形站立控制'}
{'arxiv_id': 'arXiv:2502.08158', 'title': 'Open-Source Factor Graph Optimization Package for GNSS: Examples and Applications', 'authors': 'Taro Suzuki', 'link': 'https://arxiv.org/abs/2502.08158', 'abstract': 'State estimation methods using factor graph optimization (FGO) have garnered significant attention in global navigation satellite system (GNSS) research. FGO exhibits superior estimation accuracy compared with traditional state estimation methods that rely on least-squares or Kalman filters. However, only a few FGO libraries are specialized for GNSS observations. This paper introduces an open-source GNSS FGO package named gtsam\\_gnss, which has a simple structure and can be easily applied to GNSS research and development. This package separates the preprocessing of GNSS observations from factor optimization. Moreover, it describes the error function of the GNSS factor in a straightforward manner, allowing for general-purpose inputs. This design facilitates the transition from ordinary least-squares-based positioning to FGO and supports user-specific GNSS research. In addition, gtsam\\_gnss includes analytical examples involving various factors using GNSS data in real urban environments. This paper presents three application examples: the use of a robust error model, estimation of integer ambiguity in the carrier phase, and combination of GNSS and inertial measurements from smartphones. The proposed framework demonstrates excellent state estimation performance across all use cases.', 'abstract_zh': '使用因子图优化（FGO）的方法在全球导航卫星系统（GNSS）研究中的状态估计方法受到了广泛关注。FGO相较于依赖最小二乘法或卡尔曼滤波的传统状态估计方法展现出更好的估计精度。然而，专门针对GNSS观测的FGO库并不多。本文介绍了一个开源的GNSS FGO包gtsam\\_gnss，该包结构简单，易于应用于GNSS研究和开发。该包将GNSS观测的预处理与因子优化分离，并以简洁的方式描述GNSS因子的误差函数，支持通用输入。这种设计便于从基于普通最小二乘的位置估计过渡到FGO，并支持用户特定的GNSS研究。此外，gtsam\\_gnss使用实际城市环境中的GNSS数据提供了各种因子的分析示例。本文提出了三个应用示例：使用稳健的误差模型、载波相位整数模糊度估计以及智能手机GNSS和惯性测量的结合。提出的框架在所有应用案例中都表现出优秀的状态估计性能。', 'title_zh': 'GNSS开源因子图优化软件包：示例与应用'}
{'arxiv_id': 'arXiv:2502.08093', 'title': 'Ground-Optimized 4D Radar-Inertial Odometry via Continuous Velocity Integration using Gaussian Process', 'authors': 'Wooseong Yang, Hyesu Jang, Ayoung Kim', 'link': 'https://arxiv.org/abs/2502.08093', 'abstract': 'Radar ensures robust sensing capabilities in adverse weather conditions, yet challenges remain due to its high inherent noise level. Existing radar odometry has overcome these challenges with strategies such as filtering spurious points, exploiting Doppler velocity, or integrating with inertial measurements. This paper presents two novel improvements beyond the existing radar-inertial odometry: ground-optimized noise filtering and continuous velocity preintegration. Despite the widespread use of ground planes in LiDAR odometry, imprecise ground point distributions of radar measurements cause naive plane fitting to fail. Unlike plane fitting in LiDAR, we introduce a zone-based uncertainty-aware ground modeling specifically designed for radar. Secondly, we note that radar velocity measurements can be better combined with IMU for a more accurate preintegration in radar-inertial odometry. Existing methods often ignore temporal discrepancies between radar and IMU by simplifying the complexities of asynchronous data streams with discretized propagation models. Tackling this issue, we leverage GP and formulate a continuous preintegration method for tightly integrating 3-DOF linear velocity with IMU, facilitating full 6-DOF motion directly from the raw measurements. Our approach demonstrates remarkable performance (less than 1% vertical drift) in public datasets with meticulous conditions, illustrating substantial improvement in elevation accuracy. The code will be released as open source for the community: this https URL.', 'abstract_zh': '雷达在恶劣天气条件下确保了 robust 的感知能力，但其固有的高噪声水平仍带来挑战。现有雷达里程计通过过滤虚假点、利用多普勒速度或与惯性测量融合等策略克服了这些挑战。本文提出两种超越现有雷达惯性里程计的新改进：地面优化噪声过滤和连续速度预积分。尽管在 LiDAR 里程计中广泛使用地面平面，但雷达测量的不精确地面点分布导致简单的平面拟合失效。不同于 LiDAR，我们引入基于区域的不确定性感知地面建模，专门设计用于雷达。其次，我们注意到雷达速度测量可以更好地与 IMU 结合，以提高雷达惯性里程计中的预积分精度。现有方法通常通过简化异步数据流的复杂性来忽略雷达和 IMU 之间的时序差异，仅用离散传播模型。为解决这一问题，我们利用高斯过程（GP）并提出一种连续预积分方法，使线性速度的 3-DOF 与 IMU 紧密集成，直接从原始测量中实现完整的 6-DOF 运动。我们的方法在公开数据集中的表现卓越（垂直漂移低于 1%），展示了显著的高程精度改进。代码将作为开源发布给社区：this https URL。', 'title_zh': '基于地面优化的4D雷达-惯性里程计通过高斯过程进行连续速度积分'}
{'arxiv_id': 'arXiv:2502.08089', 'title': 'A Cooperative Bearing-Rate Approach for Observability-Enhanced Target Motion Estimation', 'authors': 'Canlun Zheng, Hanqing Guo, Shiyu Zhao', 'link': 'https://arxiv.org/abs/2502.08089', 'abstract': 'Vision-based target motion estimation is a fundamental problem in many robotic tasks. The existing methods have the limitation of low observability and, hence, face challenges in tracking highly maneuverable targets. Motivated by the aerial target pursuit task where a target may maneuver in 3D space, this paper studies how to further enhance observability by incorporating the \\emph{bearing rate} information that has not been well explored in the literature. The main contribution of this paper is to propose a new cooperative estimator called STT-R (Spatial-Temporal Triangulation with bearing Rate), which is designed under the framework of distributed recursive least squares. This theoretical result is further verified by numerical simulation and real-world experiments. It is shown that the proposed STT-R algorithm can effectively generate more accurate estimations and effectively reduce the lag in velocity estimation, enabling tracking of more maneuverable targets.', 'abstract_zh': '基于视觉的目标运动估计是许多机器人任务中的一个基本问题。现有的方法存在观测性较低的局限性，因此在跟踪高度机动的目标时面临挑战。受空中目标捕获任务的启发，其中目标可能在三维空间中机动，本文研究如何通过结合文献中尚未充分探索的航向角速率信息来进一步提高观测性。本文的主要贡献是提出了一种新的协同估计器STT-R（空间-时间 triangulation with 航向角速率），该估计器是在分布式递推最小二乘框架下设计的。该理论结果通过数值模拟和实际实验进一步得到验证。研究结果表明，所提出的STT-R算法能够有效生成更准确的估计，并有效减少速度估计滞后，从而实现对更机动目标的跟踪。', 'title_zh': '一种基于协作航向率的方法以增强目标运动估计可观察性'}
{'arxiv_id': 'arXiv:2502.08054', 'title': 'COMBO-Grasp: Learning Constraint-Based Manipulation for Bimanual Occluded Grasping', 'authors': 'Jun Yamada, Alexander L. Mitchell, Jack Collins, Ingmar Posner', 'link': 'https://arxiv.org/abs/2502.08054', 'abstract': "This paper addresses the challenge of occluded robot grasping, i.e. grasping in situations where the desired grasp poses are kinematically infeasible due to environmental constraints such as surface collisions. Traditional robot manipulation approaches struggle with the complexity of non-prehensile or bimanual strategies commonly used by humans in these circumstances. State-of-the-art reinforcement learning (RL) methods are unsuitable due to the inherent complexity of the task. In contrast, learning from demonstration requires collecting a significant number of expert demonstrations, which is often infeasible. Instead, inspired by human bimanual manipulation strategies, where two hands coordinate to stabilise and reorient objects, we focus on a bimanual robotic setup to tackle this challenge. In particular, we introduce Constraint-based Manipulation for Bimanual Occluded Grasping (COMBO-Grasp), a learning-based approach which leverages two coordinated policies: a constraint policy trained using self-supervised datasets to generate stabilising poses and a grasping policy trained using RL that reorients and grasps the target object. A key contribution lies in value function-guided policy coordination. Specifically, during RL training for the grasping policy, the constraint policy's output is refined through gradients from a jointly trained value function, improving bimanual coordination and task performance. Lastly, COMBO-Grasp employs teacher-student policy distillation to effectively deploy point cloud-based policies in real-world environments. Empirical evaluations demonstrate that COMBO-Grasp significantly improves task success rates compared to competitive baseline approaches, with successful generalisation to unseen objects in both simulated and real-world environments.", 'abstract_zh': '基于约束的双臂遮挡抓取学习方法（COMBO-Grasp）', 'title_zh': 'COMBO-Grasp: 基于约束的学习双臂遮挡抓取操作'}
{'arxiv_id': 'arXiv:2502.08033', 'title': 'End-to-End Predictive Planner for Autonomous Driving with Consistency Models', 'authors': 'Anjian Li, Sangjae Bae, David Isele, Ryne Beeson, Faizan M. Tariq', 'link': 'https://arxiv.org/abs/2502.08033', 'abstract': "Trajectory prediction and planning are fundamental components for autonomous vehicles to navigate safely and efficiently in dynamic environments. Traditionally, these components have often been treated as separate modules, limiting the ability to perform interactive planning and leading to computational inefficiency in multi-agent scenarios. In this paper, we present a novel unified and data-driven framework that integrates prediction and planning with a single consistency model. Trained on real-world human driving datasets, our consistency model generates samples from high-dimensional, multimodal joint trajectory distributions of the ego and multiple surrounding agents, enabling end-to-end predictive planning. It effectively produces interactive behaviors, such as proactive nudging and yielding to ensure both safe and efficient interactions with other road users. To incorporate additional planning constraints on the ego vehicle, we propose an alternating direction method for multi-objective guidance in online guided sampling. Compared to diffusion models, our consistency model achieves better performance with fewer sampling steps, making it more suitable for real-time deployment. Experimental results on Waymo Open Motion Dataset (WOMD) demonstrate our method's superiority in trajectory quality, constraint satisfaction, and interactive behavior compared to various existing approaches.", 'abstract_zh': '自主车辆在动态环境中的轨迹预测与规划是确保安全高效导航的基础组件。传统上，这些组件常被视作独立模块，限制了交互规划的能力，并在多智能体场景中导致了计算效率低下。本文提出了一种新颖的统一且数据驱动的框架，将预测与规划整合到单一的一致性模型中。通过训练于实际人类驾驶数据集上，该一致性模型生成高维、多模态的环境ego与多个周围智能体的联合轨迹分布样本，实现了端到端的预测规划。该模型有效地生成了互动行为，如主动提示和礼让，以确保与其他道路使用者的安全和高效互动。为了在在线引导采样中对ego车辆施加额外的规划约束，我们提出了一种多目标引导的交替方向方法。与扩散模型相比，我们的一致性模型在较少的采样步骤中表现出更优的性能，更适合实时部署。实验结果在Waymo Open Motion Dataset (WOMD) 上表明，与各种现有方法相比，该方法在轨迹质量、约束满足和互动行为方面具有明显优势。', 'title_zh': '端到端一致性预测规划器 for 自动驾驶'}
{'arxiv_id': 'arXiv:2502.07922', 'title': 'Visual-Haptic Model Mediated Teleoperation for Remote Ultrasound', 'authors': 'David Black, Maria Tirindelli, Septimiu Salcudean, Wolfgang Wein, Marco Esposito', 'link': 'https://arxiv.org/abs/2502.07922', 'abstract': 'Tele-ultrasound has the potential greatly to improve health equity for countless remote communities. However, practical scenarios involve potentially large time delays which cause current implementations of telerobotic ultrasound (US) to fail. Using a local model of the remote environment to provide haptics to the expert operator can decrease teleoperation instability, but the delayed visual feedback remains problematic. This paper introduces a robotic tele-US system in which the local model is not only haptic, but also visual, by re-slicing and rendering a pre-acquired US sweep in real time to provide the operator a preview of what the delayed image will resemble. A prototype system is presented and tested with 15 volunteer operators. It is found that visual-haptic model-mediated teleoperation (MMT) compensates completely for time delays up to 1000 ms round trip in terms of operator effort and completion time while conventional MMT does not. Visual-haptic MMT also significantly outperforms MMT for longer time delays in terms of motion accuracy and force control. This proof-of-concept study suggests that visual-haptic MMT may facilitate remote robotic tele-US.', 'abstract_zh': '基于视觉-触觉模型中介的远程超声系统在远程医疗中的应用潜力与挑战：时间延迟补偿研究', 'title_zh': '视觉-触觉模型介导的远程超声操作'}
{'arxiv_id': 'arXiv:2502.07851', 'title': 'Fast and Safe Scheduling of Robots', 'authors': 'Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul G. Spirakis', 'link': 'https://arxiv.org/abs/2502.07851', 'abstract': "In this paper, we present an experimental analysis of a fast heuristic algorithm that was designed to generate a fast, collision-free schedule for a set of robots on a path graph. The experiments confirm the algorithm's effectiveness in producing collision-free schedules as well as achieving the optimal solution when all tasks assigned to the robots are of equal duration. Additionally, we provide an integer linear programming formulation that guarantees an optimal solution for this scheduling problem on any input graph, at the expense of significantly greater computational resources. We prove the correctness of our integer linear program. By comparing the solutions of these two algorithms, including the time required by the schedule itself, and the run time of each algorithm, we show that the heuristic algorithm is optimal or near optimal in nearly all cases, with a far faster run time than the integer linear program.", 'abstract_zh': '本文提出了一个快速启发式算法的实验分析，该算法用于生成路径图上一组机器人无碰撞调度方案。实验结果验证了该算法在所有任务持续时间相等时能够产生无碰撞调度方案并找到最优解。同时，我们提供了一个整数线性规划模型，该模型能在任何输入图上保证找到最优解，但需要消耗显著更多的计算资源。我们证明了该整数线性规划模型的正确性。通过对这两种算法的解及执行时间进行比较，我们证明了启发式算法在几乎所有情况下都是最优或近似最优的，并且执行速度远快于整数线性规划模型。', 'title_zh': '快速且安全的机器人调度'}
{'arxiv_id': 'arXiv:2502.07839', 'title': 'Optimal Actuator Attacks on Autonomous Vehicles Using Reinforcement Learning', 'authors': 'Pengyu Wang, Jialu Li, Ling Shi', 'link': 'https://arxiv.org/abs/2502.07839', 'abstract': 'With the increasing prevalence of autonomous vehicles (AVs), their vulnerability to various types of attacks has grown, presenting significant security challenges. In this paper, we propose a reinforcement learning (RL)-based approach for designing optimal stealthy integrity attacks on AV actuators. We also analyze the limitations of state-of-the-art RL-based secure controllers developed to counter such attacks. Through extensive simulation experiments, we demonstrate the effectiveness and efficiency of our proposed method.', 'abstract_zh': '随着自动驾驶车辆（AVs）的逐渐普及，它们受到了各种类型攻击的威胁，这提出了重大的安全挑战。本文提出了一种基于强化学习（RL）的方法来设计针对AV执行器的最优隐蔽性完整性攻击。我们还分析了用于抵御此类攻击的最先进的基于RL的安全控制器的局限性。通过广泛的仿真实验，我们展示了所提出方法的有效性和效率。', 'title_zh': '基于强化学习的自主车辆最优执行器攻击'}
{'arxiv_id': 'arXiv:2502.07837', 'title': 'RoboBERT: An End-to-end Multimodal Robotic Manipulation Model', 'authors': 'Sicheng Wang, Jianhua Shan, Jianwei Zhang, Haozhang Gao, Hailiang Han, Yipeng Chen, Kang Wei, Chengkun Zhang, Kairos Wong, Jie Zhao, Lei Zhao, Bin Fang', 'link': 'https://arxiv.org/abs/2502.07837', 'abstract': 'Embodied intelligence integrates multiple modalities, enabling agents to understand images, language, and actions simultaneously. However, existing models always depend on additional datasets or extensive pre-training to maximize performance improvements, consuming abundant training time and expensive hardware cost. To tackle this issue, we present RoboBERT, a novel end-to-end robotic manipulation model integrated with a unique training strategy. This model utilizes a CNN-based diffusion policy, enhancing and stabilizing the effectiveness of this model by separating training processes for different modalities. It also underscores the importance of data augmentation, verifying various techniques to significantly boost performance. Unlike models that depend on extra data or large foundation models, RoboBERT achieves a highly competitive success rate while using only language-labeled expert demonstrations and maintaining a relatively smaller model size. Specifically, RoboBERT achieves an average length of 4.52 on the CALVIN benchmark for \\(ABCD \\rightarrow D\\) task, setting a new state-of-the-art (SOTA) record. Furthermore, when tested on a real robot, the model demonstrates superior performance, achieving a higher success rate than other methods trained with the same data. We propose that these concepts and methodologies of RoboBERT demonstrate extensive versatility and compatibility, contributing significantly to the development of lightweight multimodal robotic models. The code can be accessed on this https URL', 'abstract_zh': '具身智能融合多种模态，使代理能够同时理解图像、语言和动作。然而，现有模型总是依赖额外的数据集或 extensive 预训练来最大化性能改进，消耗大量的训练时间和昂贵的硬件成本。为解决这一问题，我们提出了 RoboBERT，这是一种新颖的一体化机器人操作模型，结合了独特的训练策略。该模型利用基于 CNN 的扩散策略，通过分离不同模态的训练过程来增强和稳定模型效果。它还强调了数据增强的重要性，验证了多种技术以显著提升性能。与依赖额外数据或大型基础模型的模型不同，RoboBERT 在仅使用语言标注的专家演示和较小的模型规模下，实现了高度竞争的准确率。具体而言，RoboBERT 在 CALVIN 基准上 \\(ABCD \\rightarrow D\\) 任务中达到平均长度 4.52，创下了新的state-of-the-art（SOTA）记录。此外，在实际机器人上测试时，该模型表现出色，与使用相同数据训练的其他方法相比，成功率达到更高。我们提出，RoboBERT 这些概念和方法展示了广泛的灵活性和兼容性，对轻量级多模态机器人模型的发展做出了重要贡献。代码可在以下链接访问：this https URL。', 'title_zh': 'RoboBERT：一种端到端多模态机器人操作模型'}
{'arxiv_id': 'arXiv:2502.08428', 'title': 'Robot-Initiated Social Control of Sedentary Behavior: Comparing the Impact of Relationship- and Target-Focused Strategies', 'authors': 'Jiaxin Xu, Sterre Anna Mariam van der Horst, Chao Zhang, Raymond H. Cuijpers, Wijnand A. IJsselsteijn', 'link': 'https://arxiv.org/abs/2502.08428', 'abstract': "To design social robots to effectively promote health behavior change, it is essential to understand how people respond to various health communication strategies employed by these robots. This study examines the effectiveness of two types of social control strategies from a social robot, relationship-focused strategies (emphasizing relational consequences) and target-focused strategies (emphasizing health consequences), in encouraging people to reduce sedentary behavior. A two-session lab experiment was conducted (n = 135), where participants first played a game with a robot, followed by the robot persuading them to stand up and move using one of the strategies. Half of the participants joined a second session to have a repeated interaction with the robot. Results showed that relationship-focused strategies motivated participants to stay active longer. Repeated sessions did not strengthen participants' relationship with the robot, but those who felt more attached to the robot responded more actively to the target-focused strategies. These findings offer valuable insights for designing persuasive strategies for social robots in health communication contexts.", 'abstract_zh': '设计社交机器人以有效促进健康行为改变需理解人们对其各种健康沟通策略的反应。本研究探讨了社交机器人采用的两种类型的社会控制策略——关系聚焦策略（强调关系后果）和目标聚焦策略（强调健康后果）——在鼓励人们减少久坐行为方面的有效性。本研究进行了两阶段实验室实验（n=135），参与者首先与机器人玩游戏，之后通过机器人使用其中一种策略劝说他们站立并运动。一半参与者参加了第二次会话以再次与机器人互动。结果显示，关系聚焦策略促使参与者更长时间保持活跃。重复会话并未增强参与者与机器人的关系，但对机器人感觉更依恋的参与者对目标聚焦策略的反应更为积极。这些发现为健康通信背景下设计说服策略提供了宝贵见解。', 'title_zh': '机器人主动发起的社会控制以减少久坐行为：关系导向与目标导向策略的对比影响'}
{'arxiv_id': 'arXiv:2502.08119', 'title': 'Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles', 'authors': 'Jiahao You, Ziye Jia, Chao Dong, Qihui Wu, Zhu Han', 'link': 'https://arxiv.org/abs/2502.08119', 'abstract': 'The increasing deployment of unmanned surface vehicles (USVs) require computational support and coverage in applications such as maritime search and rescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerial services, and ground stations (GSs) can provide powerful supports, which can cooperate to help the USVs in complex scenarios. However, the collaboration between UAVs and GSs for USVs faces challenges of task uncertainties, USVs trajectory uncertainties, heterogeneities, and limited computational resources. To address these issues, we propose a cooperative UAV and GS based robust multi-access edge computing framework to assist USVs in completing computational tasks. Specifically, we formulate the optimization problem of joint task offloading and UAV trajectory to minimize the total execution time, which is in the form of mixed integer nonlinear programming and NP-hard to tackle. Therefore, we propose the algorithm of generative artificial intelligence-enhanced heterogeneous agent proximal policy optimization (GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actor network ability to model complex environments and extract high-level features, thereby allowing the algorithm to predict uncertainties and adapt to dynamic conditions. Additionally, GAI stabilizes the critic network, addressing the instability of multi-agent reinforcement learning approaches. Finally, extensive simulations demonstrate that the proposed algorithm outperforms the existing benchmark methods, thus highlighting the potentials in tackling intricate, cross-domain issues in the considered scenarios.', 'abstract_zh': '无人_surface_车辆_USVs_越来越多的应用需求计算支持与覆盖，如海上搜索与救援。无人驾驶航空 vehicle_(UAVs) 可以提供低成本、灵活的航空气球服务，地面站_(GSs) 可以提供强大的支持，可以合作帮助USVs应对复杂场景。然而，UAVs和GSs为USVs的合作面临着任务不确定性、USVs航迹不确定性、异构性和有限的计算资源等挑战。为解决这些问题，我们提出了一种协作的UAV和GS基于鲁棒多接入边缘计算框架，以帮助USVs完成计算任务。具体来说，我们构建了一个联合任务卸载和UAV航迹优化的优化问题，以最小化总执行时间，该优化问题形式为混合整数非线性规划且NP难解。因此，我们提出了生成型人工智能增强异构智能体近端策略优化算法_(GAI-HAPPO)。所提出的算法整合了GAI模型以增强演员网络建模复杂环境和提取高层特征的能力，从而使算法能够预测不确定性并适应动态条件。此外，GAI稳定了批判网络，解决了多智能体强化学习方法的不稳定性问题。最后，广泛的仿真实验表明，所提出的算法在现有基准方法中表现出更优的性能，从而突出了其在所考虑场景中解决复杂跨域问题的潜力。', 'title_zh': '基于生成AI增强的UAV与地面站协同MEC系统用于无人水面车辆'}
{'arxiv_id': 'arXiv:2502.07840', 'title': 'TranSplat: Surface Embedding-guided 3D Gaussian Splatting for Transparent Object Manipulation', 'authors': 'Jeongyun Kim, Jeongho Noh, Dong-Guw Lee, Ayoung Kim', 'link': 'https://arxiv.org/abs/2502.07840', 'abstract': 'Transparent object manipulation remains a sig- nificant challenge in robotics due to the difficulty of acquiring accurate and dense depth measurements. Conventional depth sensors often fail with transparent objects, resulting in in- complete or erroneous depth data. Existing depth completion methods struggle with interframe consistency and incorrectly model transparent objects as Lambertian surfaces, leading to poor depth reconstruction. To address these challenges, we propose TranSplat, a surface embedding-guided 3D Gaussian Splatting method tailored for transparent objects. TranSplat uses a latent diffusion model to generate surface embeddings that provide consistent and continuous representations, making it robust to changes in viewpoint and lighting. By integrating these surface embeddings with input RGB images, TranSplat effectively captures the complexities of transparent surfaces, enhancing the splatting of 3D Gaussians and improving depth completion. Evaluations on synthetic and real-world transpar- ent object benchmarks, as well as robot grasping tasks, show that TranSplat achieves accurate and dense depth completion, demonstrating its effectiveness in practical applications. We open-source synthetic dataset and model: https://github. com/jeongyun0609/TranSplat', 'abstract_zh': '透明物体 manipulation 由于难以获得准确且密集的深度测量而仍然是机器人领域的一个重大挑战。传统深度传感器在处理透明物体时经常失败，导致不完整或错误的深度数据。现有深度完成方法在帧间一致性和错误地将透明物体建模为朗伯表面方面存在困难，导致深度重建效果不佳。为了解决这些问题，我们提出了 TranSplat，一种面向透明物体的表面嵌入引导的 3D 高斯点云集方法。TranSplat 使用潜扩散模型生成表面嵌入，提供一致且连续的表示，使其能够应对视角和照明变化。通过将这些表面嵌入与输入 RGB 图像集成，TranSplat 有效地捕捉透明表面的复杂性，改进了 3D 高斯的云集并提高了深度完成效果。在合成和真实世界透明物体基准测试以及机器人抓取任务上的评估表明，TranSplat 能够实现准确且密集的深度完成，展示了其在实际应用中的有效性。我们开源了合成数据集和模型：https://github.com/jeongyun0609/TranSplat。', 'title_zh': 'TranSplat: 表面嵌入引导的3D高斯点云表示及其在透明物体操作中的应用'}
