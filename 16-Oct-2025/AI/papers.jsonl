{'arxiv_id': 'arXiv:2510.13744', 'title': 'Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math', 'authors': 'Shrey Pandit, Austin Xu, Xuan-Phi Nguyen, Yifei Ming, Caiming Xiong, Shafiq Joty', 'link': 'https://arxiv.org/abs/2510.13744', 'abstract': 'Large language model (LLM)-based reasoning systems have recently achieved gold medal-level performance in the IMO 2025 competition, writing mathematical proofs where, to receive full credit, each step must be not only correct but also sufficiently supported. To train LLM-based reasoners in such challenging, open-ended settings, strong verifiers capable of catching step-level mistakes are necessary prerequisites. We introduce Hard2Verify, a human-annotated, step-level verification benchmark produced with over 500 hours of human labor. Hard2Verify is designed to rigorously assess step-level verifiers at the frontier: Verifiers must provide step-level annotations or identify the first error in responses generated by frontier LLMs for very recent, challenging, and open-ended math questions. We evaluate 29 generative critics and process reward models, demonstrating that, beyond a few standouts, open-source verifiers lag closed source models. We subsequently analyze what drives poor performance in step-level verification, the impacts of scaling verifier compute, as well as fundamental questions such as self-verification and verification-generation dynamics.', 'abstract_zh': '基于大型语言模型（LLM）的推理系统在2025年国际数学奥林匹克竞赛中取得了满分性能，在编写数学证明时，每一步不仅必须正确，而且必须充分支持。为了在如此具有挑战性和开放性的环境中训练基于LLM的推理系统，需要具备在步骤层面发现错误的强大验证器作为先决条件。我们介绍了Hard2Verify，这是一个经过人类注释的步骤层面验证基准，耗费了超过500小时的人工劳动。Hard2Verify旨在严格评估处于前沿的步骤层面验证器：验证器必须提供步骤层面的注释或识别由前沿LLM生成的响应中的第一个错误。我们评估了29个生成批评者和过程奖励模型，结果显示，除了几个表现出色的模型外，开源验证器落后于封闭源模型。随后，我们分析了步骤层面验证性能不佳的原因，验证器计算量扩展的影响，以及自我验证和验证生成动力学等基本问题。', 'title_zh': 'Hard2Verify: 一种针对开放性前沿数学问题的步骤级验证基准'}
{'arxiv_id': 'arXiv:2510.13727', 'title': 'From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails', 'authors': 'Ravi Pandya, Madison Bland, Duy P. Nguyen, Changliu Liu, Jaime Fernández Fisac, Andrea Bajcsy', 'link': 'https://arxiv.org/abs/2510.13727', 'abstract': "Generative AI systems are increasingly assisting and acting on behalf of end users in practical settings, from digital shopping assistants to next-generation autonomous cars. In this context, safety is no longer about blocking harmful content, but about preempting downstream hazards like financial or physical harm. Yet, most AI guardrails continue to rely on output classification based on labeled datasets and human-specified criteria,making them brittle to new hazardous situations. Even when unsafe conditions are flagged, this detection offers no path to recovery: typically, the AI system simply refuses to act--which is not always a safe choice. In this work, we argue that agentic AI safety is fundamentally a sequential decision problem: harmful outcomes arise from the AI system's continually evolving interactions and their downstream consequences on the world. We formalize this through the lens of safety-critical control theory, but within the AI model's latent representation of the world. This enables us to build predictive guardrails that (i) monitor an AI system's outputs (actions) in real time and (ii) proactively correct risky outputs to safe ones, all in a model-agnostic manner so the same guardrail can be wrapped around any AI model. We also offer a practical training recipe for computing such guardrails at scale via safety-critical reinforcement learning. Our experiments in simulated driving and e-commerce settings demonstrate that control-theoretic guardrails can reliably steer LLM agents clear of catastrophic outcomes (from collisions to bankruptcy) while preserving task performance, offering a principled dynamic alternative to today's flag-and-block guardrails.", 'abstract_zh': '生成式AI系统在实际应用场景中 increasingly 协助和代理终端用户，从数字购物助手到下一代自动驾驶汽车。在这种背景下，安全性不再仅仅是阻止有害内容，而是关于预判下游风险，如财务或身体伤害。然而，大多数AI护栏仍然依赖于基于标记数据集和人工指定标准的输出分类，这使它们对新的有害情况变得脆弱。即使检测到不安全的情况，这种检测也不提供恢复路径：通常，AI系统只是拒绝采取行动——而这并不是总是安全的选择。在本文中，我们认为有机关能AI的安全从根本上来说是一个序列决策问题：有害结果源自AI系统不断演化的行为以及其对世界下游影响的累积效应。我们通过安全关键控制理论的视角来形式化这一观点，但立足于AI模型对世界的潜在表示。这使我们能够构建预测性护栏，(i) 实时监控AI系统的输出（行为），(ii) 主动将高风险输出矫正为安全输出，以一种模型无关的方式实现，使同一个护栏能够包裹在任何AI模型上。我们还提供了一种实用的训练方法，可通过安全关键强化学习大规模计算这些护栏。我们在模拟驾驶和电子商务环境中的实验表明，控制理论护栏能够可靠地引导LLM代理避开灾难性结果（从碰撞到破产），同时保持任务性能，为当前的标记并阻断护栏提供了一种原则性的动态替代方案。', 'title_zh': '从拒绝到恢复：基于控制理论的生成型AI防护措施方法'}
{'arxiv_id': 'arXiv:2510.13709', 'title': 'Training LLM Agents to Empower Humans', 'authors': 'Evan Ellis, Vivek Myers, Jens Tuyls, Sergey Levine, Anca Dragan, Benjamin Eysenbach', 'link': 'https://arxiv.org/abs/2510.13709', 'abstract': "Assistive agents should not only take actions on behalf of a human, but also step out of the way and cede control when there are important decisions to be made. However, current methods for building assistive agents, whether via mimicking expert humans or via RL finetuning on an inferred reward, often encourage agents to complete tasks on their own rather than truly assisting the human attain their objectives. Additionally, these methods often require costly explicit human feedback to provide a training signal. We propose a new approach to tuning assistive language models based on maximizing the human's empowerment, their ability to effect desired changes in the environment. Our empowerment-maximizing method, Empower, only requires offline text data, providing a self-supervised method for fine-tuning language models to better assist humans. To study the efficacy of our approach, we conducted an 18-person user study comparing our empowerment assistant with a strong baseline. Participants preferred our assistant 78% of the time (p=0.015), with a 31% higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a new environment for evaluating multi-turn code assistance using simulated humans. Using this environment, we show that agents trained with Empower increase the success rate of a simulated human programmer on challenging coding questions by an average of 192% over an SFT baseline. With this empowerment objective, we provide a framework for useful aligned AI agents at scale using only offline data without the need for any additional human feedback or verifiable rewards.", 'abstract_zh': '辅助代理不仅应代表人类执行操作，还应在需要重要决策时主动让位于人类并放弃控制权。然而，当前构建辅助代理的方法，无论是通过模仿专家人类还是通过基于推测奖励的RL微调，往往促使代理自行完成任务，而不是真正帮助人类达成目标。此外，这些方法常常需要昂贵的显式人类反馈来提供训练信号。我们提出了一种新的基于最大化人类赋能的辅助语言模型调整方法。我们的赋能最大化方法Empower仅需离线文本数据，提供了一种半监督的方法，用于微调语言模型以更好地辅助人类。为了研究我们方法的有效性，我们进行了一项包含18名参与者的用户研究，比较了我们的赋能助手与一个强有力的基线。参与者中有78%（p=0.015）更喜欢我们的助手，接受率高31%，建议数减少38%。此外，我们引入了一个新的多轮次代码辅助评估环境，利用模拟的人类。利用这个环境，我们展示了使用Empower训练的代理将模拟的人类程序员在解决棘手的编程问题时的成功率平均提高了192%，相比SFT基线。通过这一赋能目标，我们提供了一种仅使用离线数据、无需额外人类反馈或可验证奖励的框架，用于构建大规模有用且目标一致的AI代理。', 'title_zh': '训练大规模语言模型代理以赋能人类'}
{'arxiv_id': 'arXiv:2510.13691', 'title': 'A Modal Logic for Temporal and Jurisdictional Classifier Models', 'authors': 'Cecilia Di Florio, Huimin Dong, Antonino Rotolo', 'link': 'https://arxiv.org/abs/2510.13691', 'abstract': 'Logic-based models can be used to build verification tools for machine learning classifiers employed in the legal field. ML classifiers predict the outcomes of new cases based on previous ones, thereby performing a form of case-based reasoning (CBR). In this paper, we introduce a modal logic of classifiers designed to formally capture legal CBR. We incorporate principles for resolving conflicts between precedents, by introducing into the logic the temporal dimension of cases and the hierarchy of courts within the legal system.', 'abstract_zh': '基于逻辑的模型可用于构建法律领域中机器学习分类器的验证工具。机器学习分类器根据以往案例预测新案例的结果，从而进行案例-based推理（CBR）。在本文中，我们引入了一种分类器模态逻辑，旨在正式捕捉法律领域的CBR。通过引入案例的时间维度和法律体系中的法院层级原则，来解决先例之间的冲突。', 'title_zh': '一种时间与管辖分类模型的模态逻辑'}
{'arxiv_id': 'arXiv:2510.13551', 'title': 'Tandem Training for Language Models', 'authors': 'Robert West, Ashton Anderson, Ece Kamar, Eric Horvitz', 'link': 'https://arxiv.org/abs/2510.13551', 'abstract': "As language models continue to rapidly improve, we can expect their actions and reasoning to become difficult or impossible for weaker agents and humans to follow, undermining interpretability and oversight. With an eye on long-term futures, we pursue methods that encourage models to produce solutions that remain intelligible to weaker collaborators. We formalize intelligibility as handoff robustness: a strong model's solution is intelligible to a weaker model if randomly handing off control to the weaker model along the solution path does not cause failure. Building on this criterion, we introduce tandem training for language models, a reinforcement learning (RL) paradigm in which rollout tokens are intermittently and randomly sampled from a frozen weak model rather than the strong model being trained. Because rollouts succeed only when the strong model's actions and reasoning process can be continued by the weak model -- when the two can co-construct a successful solution -- optimizing standard RL objectives with tandem training implicitly incentivizes both correctness and intelligibility. In the GSM8K math reasoning task, tandem training reliably teaches models to abandon jargon and adapt their language to weaker partners while keeping task accuracy high. Our results demonstrate a promising route to building AI systems that remain auditable by weaker agents, with implications for human--AI collaboration and multi-agent communication.", 'abstract_zh': '语言模型持续快速进步，其行为和推理将变得难以甚至不可能被较弱代理和人类理解，削弱了可解释性和监督能力。着眼于长期未来，我们探索促进模型生成对较弱合作者依然具有可理解性的解决方案的方法。我们将可理解性形式化为交接稳健性：如果随机在解决方案路径中将控制权交接给较弱模型而不导致失败，则强模型的解决方案对较弱模型来说是可理解的。基于这一标准，我们引入了语言模型的串联训练方法，这是一种强化学习（RL）范式，在此范式中，插件样例会间歇性且随机地从冻结的弱模型中抽取，而不是从正在训练的强模型中抽取。由于只有当强模型的行为和推理过程可以由弱模型延续时插件样例才能成功，即当两者能够共同构建成功解决方案时，使用串联训练优化标准RL目标会隐式地激励正确性和可理解性。在GSM8K数学推理任务中，串联训练有效地教会模型放弃术语并调整语言以适应较弱的同伴，同时保持任务准确性。我们的结果表明，这为构建更具审计性的AI系统提供了一条有希望的路径，这对于人类-AI合作以及多智能体通信具有重要意义。', 'title_zh': '语言模型的串联训练'}
{'arxiv_id': 'arXiv:2510.13524', 'title': 'A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain', 'authors': 'William Flanagan, Mukunda Das, Rajitha Ramanyake, Swaunja Maslekar, Meghana Manipuri, Joong Ho Choi, Shruti Nair, Shambhavi Bhusan, Sanjana Dulam, Mouni Pendharkar, Nidhi Singh, Vashisth Doshi, Sachi Shah Paresh', 'link': 'https://arxiv.org/abs/2510.13524', 'abstract': 'As Generative Artificial Intelligence is adopted across the financial services industry, a significant barrier to adoption and usage is measuring model performance. Historical machine learning metrics can oftentimes fail to generalize to GenAI workloads and are often supplemented using Subject Matter Expert (SME) Evaluation. Even in this combination, many projects fail to account for various unique risks present in choosing specific metrics. Additionally, many widespread benchmarks created by foundational research labs and educational institutions fail to generalize to industrial use. This paper explains these challenges and provides a Risk Assessment Framework to allow for better application of SME and machine learning Metrics', 'abstract_zh': '随着生成式人工智能在金融服务业的应用逐渐普及，采用和使用过程中一个显著的障碍是对模型性能的衡量。历史上的机器学习指标常常无法泛化到生成式人工智能的工作负载中，因此经常需要结合领域专家评估（SME Evaluation）来补充。即使在这种结合下，许多项目仍未考虑到选择特定指标时所面临的各种独特风险。此外，许多由基础研究实验室和教育机构创建的广泛基准在应用于工业环境时也无法泛化。本文阐释了这些挑战，并提供了一个风险评估框架，以更好地应用领域专家和机器学习指标。', 'title_zh': '评估金融领域大模型指标失败风险的方法论'}
{'arxiv_id': 'arXiv:2510.13501', 'title': 'Confidence as a Reward: Transforming LLMs into Reward Models', 'authors': 'He Du, Bowen Li, Chengxing Xie, Chang Gao, Kai Chen, Dacheng Tao', 'link': 'https://arxiv.org/abs/2510.13501', 'abstract': "Reward models can significantly enhance the reasoning capabilities of large language models (LLMs), but they typically require extensive curated data and costly training. To mitigate these challenges, training-free approaches such as LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate responses, achieving promising results. Recent works have also indicated that model confidence can serve effectively as a reward metric, distinguishing between chain-of-thought (CoT) and non-CoT paths. However, the concept of using confidence as a reward has not been comprehensively studied. In this work, we systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful training-free method that utilizes token-level confidence in the model's final answers as a proxy for reward, especially suitable for close-ended tasks. Through extensive experiments on mathematical reasoning tasks, we demonstrate that CRew outperforms existing training-free reward approaches on the MATH500 and RewardMATH benchmarks, and even surpasses most trained reward models. We further identify a strong correlation between CRew scores and the actual reasoning performance of the model. Additionally, we find that CRew can effectively filter high-quality training data. Building upon these insights, we propose CRew-DPO, a training strategy that constructs preference data from confidence scores combined with correctness signals. Finetuning with CRew-DPO further enhances the model's judging capabilities and consistently outperforms existing self-training methods.", 'abstract_zh': '奖励模型可以显著增强大型语言模型的推理能力，但通常需要大量的精心标注数据和昂贵的训练成本。为了缓解这些挑战，无需训练的方法如LLM-as-a-Judge利用大型语言模型的固有推理能力来评估响应，取得了令人鼓舞的结果。最近的研究还表明，模型的信心可以有效地作为奖励指标，区分链式思维路径和非链式思维路径。然而，将信心作为奖励的概念尚未得到全面研究。在这项工作中，我们系统地研究了基于信心的奖励(CRew)方法，这是一种简单而强大的无需训练的方法，利用模型最终答案的令牌级信心作为奖励的代理，特别适用于封闭式任务。通过在数学推理任务上的大量实验，我们证明了CRew在MATH500和RewardMATH基准上优于现有的无需训练的奖励方法，并且甚至超越了大多数经过训练的奖励模型。我们进一步发现CRew分数与模型的实际推理性能之间存在强烈的相关性。此外，我们发现CRew可以有效地过滤高质量的训练数据。基于这些见解，我们提出了一种训练策略CRew-DPO，该策略从信心分数与正确性信号相结合的数据中构建偏好数据。使用CRew-DPO进行微调进一步增强了模型的评估能力，并且在所有现有的自我训练方法中表现最佳。', 'title_zh': '自信作为奖励：将大语言模型转变为奖励模型'}
{'arxiv_id': 'arXiv:2510.13459', 'title': 'Mobile Coverage Analysis using Crowdsourced Data', 'authors': 'Timothy Wong, Tom Freeman, Joseph Feehily', 'link': 'https://arxiv.org/abs/2510.13459', 'abstract': 'Effective assessment of mobile network coverage and the precise identification of service weak spots are paramount for network operators striving to enhance user Quality of Experience (QoE). This paper presents a novel framework for mobile coverage and weak spot analysis utilising crowdsourced QoE data. The core of our methodology involves coverage analysis at the individual cell (antenna) level, subsequently aggregated to the site level, using empirical geolocation data. A key contribution of this research is the application of One-Class Support Vector Machine (OC-SVM) algorithm for calculating mobile network coverage. This approach models the decision hyperplane as the effective coverage contour, facilitating robust calculation of coverage areas for individual cells and entire sites. The same methodology is extended to analyse crowdsourced service loss reports, thereby identifying and quantifying geographically localised weak spots. Our findings demonstrate the efficacy of this novel framework in accurately mapping mobile coverage and, crucially, in highlighting granular areas of signal deficiency, particularly within complex urban environments.', 'abstract_zh': '基于 crowdsourced QoE 数据的移动网络覆盖和弱点分析新型框架', 'title_zh': '基于众包数据的移动网络覆盖分析'}
{'arxiv_id': 'arXiv:2510.13417', 'title': 'Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse', 'authors': 'Liesbeth Allein, Nataly Pineda-Castañeda, Andrea Rocci, Marie-Francine Moens', 'link': 'https://arxiv.org/abs/2510.13417', 'abstract': 'How does a cause lead to an effect, and which intermediate causal steps explain their connection? This work scrutinizes the mechanistic causal reasoning capabilities of large language models (LLMs) to answer these questions through the task of implicit causal chain discovery. In a diagnostic evaluation framework, we instruct nine LLMs to generate all possible intermediate causal steps linking given cause-effect pairs in causal chain structures. These pairs are drawn from recent resources in argumentation studies featuring polarized discussion on climate change. Our analysis reveals that LLMs vary in the number and granularity of causal steps they produce. Although they are generally self-consistent and confident about the intermediate causal connections in the generated chains, their judgments are mainly driven by associative pattern matching rather than genuine causal reasoning. Nonetheless, human evaluations confirmed the logical coherence and integrity of the generated chains. Our baseline causal chain discovery approach, insights from our diagnostic evaluation, and benchmark dataset with causal chains lay a solid foundation for advancing future work in implicit, mechanistic causal reasoning in argumentation settings.', 'abstract_zh': '大型语言模型在隐含因果链发现任务中如何揭示因果机制：一项诊断评估的研究', 'title_zh': '通过隐式因果链发现评估大语言模型在气候话语中的推理能力'}
{'arxiv_id': 'arXiv:2510.13393', 'title': 'Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization', 'authors': 'Yunxiao Zhao, Zhiqiang Wang, Xingtong Yu, Xiaoli Li, Jiye Liang, Ru Li', 'link': 'https://arxiv.org/abs/2510.13393', 'abstract': 'Rationalization, a data-centric framework, aims to build self-explanatory models to explain the prediction outcome by generating a subset of human-intelligible pieces of the input data. It involves a cooperative game model where a generator generates the most human-intelligible parts of the input (i.e., rationales), followed by a predictor that makes predictions based on these generated rationales. Conventional rationalization methods typically impose constraints via regularization terms to calibrate or penalize undesired generation. However, these methods are suffering from a problem called mode collapse, in which the predictor produces correct predictions yet the generator consistently outputs rationales with collapsed patterns. Moreover, existing studies are typically designed separately for specific collapsed patterns, lacking a unified consideration. In this paper, we systematically revisit cooperative rationalization from a novel game-theoretic perspective and identify the fundamental cause of this problem: the generator no longer tends to explore new strategies to uncover informative rationales, ultimately leading the system to converge to a suboptimal game equilibrium (correct predictions v.s collapsed rationales). To solve this problem, we then propose a novel approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT), which progressively introduces policy interventions to address the game equilibrium in the cooperative game process, thereby guiding the model toward a more optimal solution state. We theoretically analyse the cause of such a suboptimal equilibrium and prove the feasibility of the proposed method. Furthermore, we validate our method on nine widely used real-world datasets and two synthetic settings, where PORAT achieves up to 8.1% performance improvements over existing state-of-the-art methods.', 'abstract_zh': '基于博弈论策略优化的协 UITableView Reasonalization (PORAT)', 'title_zh': '基于数据为中心的游戏理论策略可学习优化的自解释合理性'}
{'arxiv_id': 'arXiv:2510.13262', 'title': 'SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning', 'authors': 'Weiqi Guo, Guanjun Liu, Ziyuan Zhou', 'link': 'https://arxiv.org/abs/2510.13262', 'abstract': "Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for cooperative and competitive tasks such as autonomous driving and strategic gaming. However, models trained by MADRL are vulnerable to adversarial perturbations on states and actions. Therefore, it is essential to investigate the robustness of MADRL models from an attack perspective. Existing studies focus on either state-only attacks or action-only attacks, but do not consider how to effectively joint them. Simply combining state and action perturbations such as randomly perturbing states and actions does not exploit their potential synergistic effects. In this paper, we propose the State-Action Joint Attack (SAJA) framework that has a good synergistic effects. SAJA consists of two important phases: (1) In the state attack phase, a multi-step gradient ascent method utilizes both the actor network and the critic network to compute an adversarial state, and (2) in the action attack phase, based on the perturbed state, a second gradient ascent uses the critic network to craft the final adversarial action. Additionally, a heuristic regularizer measuring the distance between the perturbed actions and the original clean ones is added into the loss function to enhance the effectiveness of the critic's guidance. We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating that (1) it outperforms and is more stealthy than state-only or action-only attacks, and (2) existing state or action defense methods cannot defend its attacks.", 'abstract_zh': '基于状态-动作联合攻击的多智能体深度强化学习robustness研究', 'title_zh': 'SAJA：多智能体深度强化学习中的状态-动作联合攻击框架'}
{'arxiv_id': 'arXiv:2510.13230', 'title': 'An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities', 'authors': 'Jalal Khan, Manzoor Khan, Sherzod Turaev, Sumbal Malik, Hesham El-Sayed, Farman Ullah', 'link': 'https://arxiv.org/abs/2510.13230', 'abstract': "The driving environment perception has a vital role for autonomous driving and nowadays has been actively explored for its realization. The research community and relevant stakeholders necessitate the development of Deep Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles (AVs) for smart mobility. There is a need to develop a model that accurately perceives multiple objects on the road and predicts the driver's perception to control the car's movements. This article proposes a novel utility-based analytical model that enables perception systems of AVs to understand the driving environment. The article consists of modules: acquiring a custom dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a DL-based model (YOLOv8s) for object detection; and a module to measure the utility of perception service from the performance values of trained model instances. The perception model is validated based on the object detection task, and its process is benchmarked by state-of-the-art deep learning models' performance metrics from the nuScense dataset. The experimental results show three best-performing YOLOv8s instances based on mAP@0.5 values, i.e., SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.) still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892, truck: 0.781, etc.) because it has better class-level performance values, confirmed by the proposed perception model. We validate that the proposed function is capable of finding the right perception for AVs. The results above encourage using the proposed perception model to evaluate the utility of learning models and determine the appropriate perception for AVs.", 'abstract_zh': '自主驾驶环境感知在智能出行中的作用及其基于Deep Learning的新型分析模型研究', 'title_zh': '自主车辆感知增强的分析框架以促进智能城市的发展'}
{'arxiv_id': 'arXiv:2510.13220', 'title': 'EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems', 'authors': 'Yufei He, Juncheng Liu, Yue Liu, Yibo Li, Tri Cao, Zhiyuan Hu, Xinxing Xu, Bryan Hooi', 'link': 'https://arxiv.org/abs/2510.13220', 'abstract': 'A fundamental limitation of current AI agents is their inability to learn complex skills on the fly at test time, often behaving like "clever but clueless interns" in novel environments. This severely limits their practical utility. To systematically measure and drive progress on this challenge, we first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a new evaluation setup where an agent must play the same game for several consecutive episodes, attempting to improve its performance from one episode to the next. On J-TTL, we find that existing adaptation methods like reflection, memory, or reinforcement learning struggle. To address the challenges posed by our benchmark, we present EvoTest, an evolutionary test-time learning framework that improves an agent without any fine-tuning or gradients-by evolving the entire agentic system after every episode. EvoTest has two roles: the Actor Agent, which plays the game, and the Evolver Agent, which analyzes the episode transcript to propose a revised configuration for the next run. This configuration rewrites the prompt, updates memory by logging effective state-action choices, tunes hyperparameters, and learns the tool-use routines. On our J-TTL benchmark, EvoTest consistently increases performance, outperforming not only reflection and memory-only baselines but also more complex online fine-tuning methods. Notably, our method is the only one capable of winning two games (Detective and Library), while all baselines fail to win any.', 'abstract_zh': '当前AI代理的一个基本限制是它们无法在测试时学习复杂的技能，往往在新环境中表现得像“机灵但迷茫的实习生”。这严重限制了它们的实际应用价值。为了系统地衡量和驱动在这一挑战上的进展，我们首先引入了Jericho测试时学习（J-TTL）基准。J-TTL是一个新的评估框架，其中代理必须连续多局游戏，并尝试在每一局中改进其表现。在J-TTL上，我们发现现有的适应方法，如反思、记忆或强化学习都很挣扎。为了解决我们的基准带来的挑战，我们提出了EvoTest，这是一种进化测试时学习框架，无需微调或梯度，便能在每次游戏后进化整个代理系统以提升性能。EvoTest有两个角色：执行代理，负责玩游戏；进化代理，分析每一局的游戏转录，为下一次运行提出修订配置。该配置重写提示、更新记忆、调整超参数，并学习工具使用策略。在我们的J-TTL基准上，EvoTest能够在所有测试中持续提升性能，不仅超越了仅使用反思和记忆的基线，还超过了更复杂的在线微调方法。值得注意的是，我们的方法是唯一能够在两个游戏中获胜（侦探和图书馆）的方法，而所有基线都无法获胜。', 'title_zh': 'EvoTest：自我提升代理系统中的进化测试时学习'}
{'arxiv_id': 'arXiv:2510.13215', 'title': 'Personalized Learning Path Planning with Goal-Driven Learner State Modeling', 'authors': 'Joy Jia Yin Lim, Ye He, Jifan Yu, Xin Cong, Daniel Zhang-Li, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li, Bin Xu', 'link': 'https://arxiv.org/abs/2510.13215', 'abstract': "Personalized Learning Path Planning (PLPP) aims to design adaptive learning paths that align with individual goals. While large language models (LLMs) show potential in personalizing learning experiences, existing approaches often lack mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework for PLPP that integrates a reinforcement-based training paradigm and an LLM-driven educational architecture. We design a structured learner state model and an automated reward function that transforms abstract objectives into computable signals. We train the policy combining supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), and deploy it within a real-world learning platform. Extensive experiments validate Pxplore's effectiveness in producing coherent, personalized, and goal-driven learning paths. We release our code and dataset to facilitate future research.", 'abstract_zh': '个性化学习路径规划 (PLPP) 致力于设计与个人目标相一致的自适应学习路径。尽管大型语言模型 (LLMs) 在个性化学习体验方面展现出潜力，但现有方法往往缺少面向目标规划的机制。我们引入了 Pxplore，这是一种新颖的 PLPP 框架，结合了基于强化学习的训练范式和 LLM 驱动的教育架构。我们设计了一种结构化的学习者状态模型和自动化的奖励函数，将抽象目标转换为可计算信号。我们通过监督微调 (SFT) 和组相对策略优化 (GRPO) 来训练策略，并在现实世界的学习平台中部署它。广泛的实验验证了 Pxplore 在生成连贯、个性化和目标导向的学习路径方面的有效性。我们发布了代码和数据集，以促进未来研究。', 'title_zh': '基于目标驱动学习者状态 modeling 的个性化学习路径规划'}
{'arxiv_id': 'arXiv:2510.13214', 'title': 'Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning', 'authors': 'Zehui Ling, Deshu Chen, Yichi Zhang, Yuchen Liu, Xigui Li, Xin Guo, Yuan Cheng', 'link': 'https://arxiv.org/abs/2510.13214', 'abstract': 'Recent advances in Large Language Models (LLMs) demonstrate that chain-of-thought prompting and deep reasoning substantially enhance performance on complex tasks, and multi-agent systems can further improve accuracy by enabling model debates. However, applying deep reasoning to all problems is computationally expensive. To mitigate these costs, we propose a complementary agent system integrating small and large LLMs. The small LLM first generates an initial answer, which is then verified by the large LLM. If correct, the answer is adopted directly; otherwise, the large LLM performs in-depth reasoning. Experimental results show that, for simple problems, our approach reduces the computational cost of the large LLM by more than 50% with negligible accuracy loss, while consistently maintaining robust performance on complex tasks.', 'abstract_zh': 'Recent Advances in Large Language Models: Integrating Small and Large LLMs for Efficient Deep Reasoning and Accuracy Improvement', 'title_zh': '自适应推理执行器：一种高效的协作代理系统'}
{'arxiv_id': 'arXiv:2510.13195', 'title': 'Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation', 'authors': 'Qun Ma, Xiao Xue, Xuwen Zhang, Zihan Zhao, Yuwei Guo, Ming Zhang', 'link': 'https://arxiv.org/abs/2510.13195', 'abstract': 'The advent of large language models (LLMs) has enabled agents to represent virtual humans in societal simulations, facilitating diverse interactions within complex social systems. However, existing LLM-based agents exhibit severe limitations in affective cognition: They fail to simulate the bounded rationality essential for bridging virtual and real-world services; They lack empirically validated integration mechanisms embedding emotions within agent decision architectures. This paper constructs an emotional cognition framework incorporating desire generation and objective management, designed to achieve emotion alignment between LLM-based agents and humans, modeling the complete decision-making process of LLM-based agents, encompassing state evolution, desire generation, objective optimization, decision generation, and action execution. This study implements the proposed framework within our proprietary multi-agent interaction environment. Experimental results demonstrate that agents governed by our framework not only exhibit behaviors congruent with their emotional states but also, in comparative assessments against other agent types, demonstrate superior ecological validity and generate decision outcomes that significantly more closely approximate human behavioral patterns.', 'abstract_zh': '大型语言模型（LLMs）的出现使代理能够代表虚拟人类参与社会模拟，促进了复杂社会系统中多样化互动的可能性。然而，现有的基于LLM的代理在情感认知方面存在严重限制：它们无法模拟将虚拟与现实世界服务衔接所需的有限理性；缺乏将情绪嵌入代理决策架构中的经验证实整合机制。本文构建了一个包含欲望生成和目标管理的情感认知框架，旨在实现基于LLM的代理与人类之间的情感对齐，模型了基于LLM的代理完整的决策过程，涵盖状态演化、欲望生成、目标优化、决策生成和动作执行。本文在我们自主开发的多代理交互环境中实现了所提出框架。实验结果表明，受该框架指导的代理不仅表现出与其情感状态一致的行为，而且与其它代理类型相比，表现出更高的生态效度，并生成决策结果与人类行为模式更为接近。', 'title_zh': '基于欲望驱动目标优化的情感认知建模框架在社会模拟中的应用——赋能于大规模语言模型的代理'}
{'arxiv_id': 'arXiv:2510.13036', 'title': 'Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking', 'authors': 'Stephane Hatgis-Kessell, Logan Mondal Bhamidipaty, Emma Brunskill', 'link': 'https://arxiv.org/abs/2510.13036', 'abstract': "Human-designed reward functions for reinforcement learning (RL) agents are frequently misaligned with the humans' true, unobservable objectives, and thus act only as proxies. Optimizing for a misspecified proxy reward function often induces reward hacking, resulting in a policy misaligned with the human's true objectives. An alternative is to perform RL from human feedback, which involves learning a reward function from scratch by collecting human preferences over pairs of trajectories. However, building such datasets is costly. To address the limitations of both approaches, we propose Preference-Based Reward Repair (PBRR): an automated iterative framework that repairs a human-specified proxy reward function by learning an additive, transition-dependent correction term from preferences. A manually specified reward function can yield policies that are highly suboptimal under the ground-truth objective, yet corrections on only a few transitions may suffice to recover optimal performance. To identify and correct for those transitions, PBRR uses a targeted exploration strategy and a new preference-learning objective. We prove in tabular domains PBRR has a cumulative regret that matches, up to constants, that of prior preference-based RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR consistently outperforms baselines that learn a reward function from scratch from preferences or modify the proxy reward function using other approaches, requiring substantially fewer preferences to learn high performing policies.", 'abstract_zh': '基于偏好的奖励修复：一种自动迭代框架', 'title_zh': '利用人类反馈修复奖励函数以减轻奖励劫持'}
{'arxiv_id': 'arXiv:2510.13029', 'title': 'Toward Reasoning-Centric Time-Series Analysis', 'authors': 'Xinlei Wang, Mingtian Tan, Jing Qiu, Junhua Zhao, Jinjin Gu', 'link': 'https://arxiv.org/abs/2510.13029', 'abstract': 'Traditional time series analysis has long relied on pattern recognition, trained on static and well-established benchmarks. However, in real-world settings -- where policies shift, human behavior adapts, and unexpected events unfold -- effective analysis must go beyond surface-level trends to uncover the actual forces driving them. The recent rise of Large Language Models (LLMs) presents new opportunities for rethinking time series analysis by integrating multimodal inputs. However, as the use of LLMs becomes popular, we must remain cautious, asking why we use LLMs and how to exploit them effectively. Most existing LLM-based methods still employ their numerical regression ability and ignore their deeper reasoning potential. This paper argues for rethinking time series with LLMs as a reasoning task that prioritizes causal structure and explainability. This shift brings time series analysis closer to human-aligned understanding, enabling transparent and context-aware insights in complex real-world environments.', 'abstract_zh': '利用大型语言模型重新思考时间序列分析：作为因果结构和可解释性优先的推理任务', 'title_zh': '面向推理的时间序列分析'}
{'arxiv_id': 'arXiv:2510.13002', 'title': "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model", 'authors': 'Boyou Chen, Gerui Xu, Zifei Wang, Huizhong Guo, Ananna Ahmed, Zhaonan Sun, Zhen Hu, Kaihan Zhang, Shan Bao', 'link': 'https://arxiv.org/abs/2510.13002', 'abstract': 'Vehicle crashes involve complex interactions between road users, split-second decisions, and challenging environmental conditions. Among these, two-vehicle crashes are the most prevalent, accounting for approximately 70% of roadway crashes and posing a significant challenge to traffic safety. Identifying Driver Hazardous Action (DHA) is essential for understanding crash causation, yet the reliability of DHA data in large-scale databases is limited by inconsistent and labor-intensive manual coding practices. Here, we present an innovative framework that leverages a fine-tuned large language model to automatically infer DHAs from textual crash narratives, thereby improving the validity and interpretability of DHA classifications. Using five years of two-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on detailed crash narratives and benchmarked its performance against conventional machine learning classifiers, including Random Forest, XGBoost, CatBoost, and a neural network. The fine-tuned LLM achieved an overall accuracy of 80%, surpassing all baseline models and demonstrating pronounced improvements in scenarios with imbalanced data. To increase interpretability, we developed a probabilistic reasoning approach, analyzing model output shifts across original test sets and three targeted counterfactual scenarios: variations in driver distraction and age. Our analysis revealed that introducing distraction for one driver substantially increased the likelihood of "General Unsafe Driving"; distraction for both drivers maximized the probability of "Both Drivers Took Hazardous Actions"; and assigning a teen driver markedly elevated the probability of "Speed and Stopping Violations." Our framework and analytical methods provide a robust and interpretable solution for large-scale automated DHA detection, offering new opportunities for traffic safety analysis and intervention.', 'abstract_zh': '车辆碰撞涉及道路使用者之间的复杂交互、瞬间决策以及具有挑战性的环境条件。其中，两车碰撞最为普遍，约占道路碰撞的70%，对交通安全构成了重大挑战。识别驾驶危险行为（DHA）对于理解碰撞成因至关重要，但由于大规模数据库中DHA数据的一致性和手动编码的劳动密集型特征，其可靠性受到限制。在这里，我们提出了一种创新框架，利用微调的大语言模型自动从交通事故文本叙述中推断DHA，从而提高DHA分类的有效性和可解释性。通过对MTCF五年来的两车碰撞数据进行微调，我们将Llama 3.2 1B模型应用到详细的事故叙述中，并将其性能与传统的机器学习分类器，包括随机森林、XGBoost、CatBoost和神经网络进行了比较。微调后的LLM整体准确率达到80%，超过了所有基线模型，并在不平衡数据情况下显示出显著改进。为了提高可解释性，我们开发了一种概率推理方法，分析模型输出在原始测试集和三个针对性的假设场景中的变化：司机分心程度的变化和年龄。我们的分析表明，对一名司机引入分心显著增加了“一般不安全驾驶”的可能性；对两名司机引入分心最大化了“双方司机采取了危险行为”的概率；指定一名青少年司机显著提高了“超速和停车违规”的概率。我们的框架和分析方法为大规模自动DHA检测提供了稳健且可解释的解决方案，为交通安全分析和干预提供了新的机会。', 'title_zh': '从叙述到概率推理：利用大型语言模型预测和解释碰撞中驾驶员的危险行为'}
{'arxiv_id': 'arXiv:2510.12985', 'title': 'SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents', 'authors': 'Simon Sinong Zhan, Yao Liu, Philip Wang, Zinan Wang, Qineng Wang, Zhian Ruan, Xiangyu Shi, Xinyu Cao, Frank Yang, Kangrui Wang, Huajie Shao, Manling Li, Qi Zhu', 'link': 'https://arxiv.org/abs/2510.12985', 'abstract': "We present Sentinel, the first framework for formally evaluating the physical safety of Large Language Model(LLM-based) embodied agents across the semantic, plan, and trajectory levels. Unlike prior methods that rely on heuristic rules or subjective LLM judgments, Sentinel grounds practical safety requirements in formal temporal logic (TL) semantics that can precisely specify state invariants, temporal dependencies, and timing constraints. It then employs a multi-level verification pipeline where (i) at the semantic level, intuitive natural language safety requirements are formalized into TL formulas and the LLM agent's understanding of these requirements is probed for alignment with the TL formulas; (ii) at the plan level, high-level action plans and subgoals generated by the LLM agent are verified against the TL formulas to detect unsafe plans before execution; and (iii) at the trajectory level, multiple execution trajectories are merged into a computation tree and efficiently verified against physically-detailed TL specifications for a final safety check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate multiple LLM-based embodied agents against diverse safety requirements. Our experiments show that by grounding physical safety in temporal logic and applying verification methods across multiple levels, Sentinel provides a rigorous foundation for systematically evaluating LLM-based embodied agents in physical environments, exposing safety violations overlooked by previous methods and offering insights into their failure modes.", 'abstract_zh': 'Sentinel: 一种用于正式评估基于大型语言模型的具身代理物理安全性的一体化框架', 'title_zh': '哨兵：基于大语言模型的体态智能体安全评估的多层次形式化框架'}
{'arxiv_id': 'arXiv:2510.12979', 'title': 'DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping', 'authors': 'Wei Fan, Wenlin Yao, Zheng Li, Feng Yao, Xin Liu, Liang Qiu, Qingyu Yin, Yangqiu Song, Bing Yin', 'link': 'https://arxiv.org/abs/2510.12979', 'abstract': 'Large language models (LLMs) augmented with multi-step reasoning and action generation abilities have shown promise in leveraging external tools to tackle complex tasks that require long-horizon planning. However, existing approaches either rely on implicit planning in the reasoning stage or introduce explicit planners without systematically addressing how to optimize the planning stage. As evidence, we observe that under vanilla reinforcement learning (RL), planning tokens exhibit significantly higher entropy than other action tokens, revealing uncertain decision points that remain under-optimized. To address this, we propose DeepPlanner, an end-to-end RL framework that effectively enhances the planning capabilities of deep research agents. Our approach shapes token-level advantage with an entropy-based term to allocate larger updates to high entropy tokens, and selectively upweights sample-level advantages for planning-intensive rollouts. Extensive experiments across seven deep research benchmarks demonstrate that DeepPlanner improves planning quality and achieves state-of-the-art results under a substantially lower training budget.', 'abstract_zh': '增强多步推理和动作生成能力的大语言模型通过利用外部工具解决需要长期规划的复杂任务显示出潜力。然而，现有方法要么依赖于推理阶段的隐式规划，要么引入显式的规划器但没有系统地解决如何优化规划阶段的问题。为了解决这个问题，我们提出了DeepPlanner，一个端到端的 reinforcement learning 框架，有效提高了深度研究代理的规划能力。我们的方法通过基于熵的项塑造 token 级别的优势，为高熵 token 分配更大的更新，并有选择性地提升规划密集型 rollout 的样本级别优势。在七个深度研究基准上的广泛实验表明，DeepPlanner 提高了规划质量，并在显著降低的训练预算下达到了最先进的结果。', 'title_zh': 'DeepPlanner: 通过优势塑造扩展深入研究代理的规划能力'}
{'arxiv_id': 'arXiv:2510.12864', 'title': 'From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models', 'authors': 'Imran Khan', 'link': 'https://arxiv.org/abs/2510.12864', 'abstract': 'Large Language Models (LLMs) are increasingly being deployed as the reasoning engines for agentic AI systems, yet they exhibit a critical flaw: a rigid adherence to explicit rules that leads to decisions misaligned with human common sense and intent. This "rule-rigidity" is a significant barrier to building trustworthy autonomous agents. While prior work has shown that supervised fine-tuning (SFT) with human explanations can mitigate this issue, SFT is computationally expensive and inaccessible to many practitioners. To address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a novel, low-compute meta-prompting technique designed to elicit human-aligned exception handling in LLMs in a zero-shot manner. The RID framework provides the model with a structured cognitive schema for deconstructing tasks, classifying rules, weighing conflicting outcomes, and justifying its final decision. We evaluated the RID framework against baseline and Chain-of-Thought (CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced judgment across diverse domains. Our human-verified results demonstrate that the RID framework significantly improves performance, achieving a 95% Human Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT. Furthermore, it consistently produces higher-quality, intent-driven reasoning. This work presents a practical, accessible, and effective method for steering LLMs from literal instruction-following to liberal, goal-oriented reasoning, paving the way for more reliable and pragmatic AI agents.', 'abstract_zh': 'Large Language Models (LLMs)在代理AI系统中的推理引擎部署日益增多，但仍表现出一个关键缺陷：严格遵循显式规则，导致决策与人类常识和意图不符。“规则僵化”是构建可信赖自治代理的重大障碍。虽然已有研究表明，带有人类解释的监督微调（SFT）可以缓解这一问题，但SFT计算成本高且难以为许多实践者所用。为解决这一问题，我们提出了规则与意图区分（RID）框架，这是一种新颖的低计算量元提示技术，旨在以零样本方式引发与人类意图一致的异常处理。RID框架为模型提供了一个结构化的认知框架，用于分解任务、分类规则、评估冲突结果以及解释其最终决策。我们利用一个包含20种跨不同领域的细腻判断场景的自定义基准测试，评估了RID框架与基线和思维链（CoT）提示的效果。经人类验证的结果显示，RID框架显著提高了性能，实现了95%的人类一致性评分（HAS），而基线为80%，思维链为75%。此外，RID框架持续生成更高质量、意图驱动的推理。本工作提供了一种实用、易用且有效的办法，引导LLMs从严格遵循指令向自由、目标导向的推理转变，为更可靠和实际的AI代理铺平了道路。', 'title_zh': '从字面到自由：一种促进大型语言模型中人类一致异常处理的元提示框架'}
{'arxiv_id': 'arXiv:2510.13804', 'title': 'Generative Universal Verifier as Multimodal Meta-Reasoner', 'authors': 'Xinchen Zhang, Xiaoying Zhang, Youbin Wu, Yanbin Cao, Renrui Zhang, Ruihang Chu, Ling Yang, Yujiu Yang', 'link': 'https://arxiv.org/abs/2510.13804', 'abstract': 'We introduce Generative Universal Verifier, a novel concept and plugin designed for next-generation multimodal reasoning in vision-language models and unified multimodal models, providing the fundamental capability of reflection and refinement on visual outcomes during the reasoning and generation process. This work makes three main contributions: (1) We build ViVerBench, a comprehensive benchmark spanning 16 categories of critical tasks for evaluating visual outcomes in multimodal reasoning. Results show that existing VLMs consistently underperform across these tasks, underscoring a substantial gap from human-level capability in reliable visual verification. (2) We design two automated pipelines to construct large-scale visual verification data and train OmniVerifier-7B, the first omni-capable generative verifier trained for universal visual verification and achieves notable gains on ViVerBench(+8.3). Through training, we identify three atomic capabilities in visual verification and demonstrate how they generalize and interact synergistically. (3) We propose OmniVerifier-TTS, a sequential test-time scaling paradigm that leverages the universal verifier to bridge image generation and editing within unified models, enhancing the upper bound of generative ability through iterative fine-grained optimization. Beyond generation, we extend universal verifier to broader world-modeling interleaved reasoning scenarios. Empirically, OmniVerifier-TTS achieves improvements on T2I-ReasonBench(+3.7), and GenEval++(+4.3), outperforming existing parallel test-time scaling methods, such as Best-of-N. By endowing multimodal reasoning with reliable visual verification, OmniVerifier advances both reliable reflection during generation and scalable test-time refinement, marking a step toward more trustworthy and controllable next-generation reasoning systems.', 'abstract_zh': '生成式通用验证器：下一代多模态推理在视觉语言模型和统一多模态模型中的新概念与插件', 'title_zh': '生成式通用验证器作为多模态元推理器'}
{'arxiv_id': 'arXiv:2510.13795', 'title': 'Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs', 'authors': 'Yi Zhang, Bolin Ni, Xin-Sheng Chen, Heng-Rui Zhang, Yongming Rao, Houwen Peng, Qinglin Lu, Han Hu, Meng-Hao Guo, Shi-Min Hu', 'link': 'https://arxiv.org/abs/2510.13795', 'abstract': 'Fully open multimodal large language models (MLLMs) currently lag behind proprietary counterparts, primarily due to a significant gap in data quality for supervised fine-tuning (SFT). Existing open-source datasets are often plagued by widespread noise and a critical deficit in complex reasoning data, such as Chain-of-Thought (CoT), which hinders the development of advanced model capabilities. Addressing these challenges, our work makes three primary contributions. First, we introduce Honey-Data-15M, a new SFT dataset comprising approximately 15 million QA pairs, processed through multiple cleaning techniques and enhanced with a novel dual-level (short and long) CoT enrichment strategy. Second, we introduce HoneyPipe, the data curation pipeline, and its underlying framework DataStudio, providing the community with a transparent and adaptable methodology for data curation that moves beyond static dataset releases. Finally, to validate our dataset and pipeline, we train Bee-8B, an 8B model on Honey-Data-15M. Experiments show that Bee-8B establishes a new state-of-the-art (SOTA) for fully open MLLMs, achieving performance that is competitive with, and in some cases surpasses, recent semi-open models such as InternVL3.5-8B. Our work delivers to the community a suite of foundational resources, including: the Honey-Data-15M corpus; the full-stack suite comprising HoneyPipe and DataStudio; training recipes; an evaluation harness; and the model weights. This effort demonstrates that a principled focus on data quality is a key pathway to developing fully open MLLMs that are highly competitive with their semi-open counterparts.', 'abstract_zh': '全开放多模态大语言模型（MLLMs）目前落后于专有模型，主要原因是监督微调（SFT）数据质量存在显著差距。现有开源数据集通常存在广泛噪声和复杂推理数据（如Chain-of-Thought，CoT）严重不足的问题，这阻碍了高级模型能力的发展。为应对这些挑战，我们的工作做出了三项主要贡献。首先，我们引入了包含约1500万QA对的Honey-Data-15M新SFT数据集，经过多重清洗技术处理，并通过新颖的双层级（短和长）CoT增强策略进行了增强。其次，我们引入了HoneyPipe数据采编流水线及其底层框架DataStudio，为社区提供了一个透明且可适应的数据采编方法，超越了静态数据集发布。最后，为了验证我们的数据集和流水线，我们在Honey-Data-15M上训练了Bee-8B，一个8B模型。实验结果显示，Bee-8B在全开放MLLM中建立了新的最高水平，其性能与近期部分开放模型（如InternVL3.5-8B）相当，甚至在某些情况下超越了它们。我们的工作为社区提供了基础资源套件：Honey-Data-15M语料库；包括HoneyPipe和DataStudio的全栈套件；训练食谱；评估框架；以及模型权重。本研究证明，专注于数据质量是开发与部分开放模型高度竞争的全开放MLLM的关键途径。', 'title_zh': '蜂巢：高质量语料库与全栈套件，以解锁高级全开放MLLM'}
{'arxiv_id': 'arXiv:2510.13792', 'title': 'Provably Invincible Adversarial Attacks on Reinforcement Learning Systems: A Rate-Distortion Information-Theoretic Approach', 'authors': 'Ziqing Lu, Lifeng Lai, Weiyu Xu', 'link': 'https://arxiv.org/abs/2510.13792', 'abstract': "Reinforcement learning (RL) for the Markov Decision Process (MDP) has emerged in many security-related applications, such as autonomous driving, financial decisions, and drone/robot algorithms. In order to improve the robustness/defense of RL systems against adversaries, studying various adversarial attacks on RL systems is very important. Most previous work considered deterministic adversarial attack strategies in MDP, which the recipient (victim) agent can defeat by reversing the deterministic attacks. In this paper, we propose a provably ``invincible'' or ``uncounterable'' type of adversarial attack on RL. The attackers apply a rate-distortion information-theoretic approach to randomly change agents' observations of the transition kernel (or other properties) so that the agent gains zero or very limited information about the ground-truth kernel (or other properties) during the training. We derive an information-theoretic lower bound on the recipient agent's reward regret and show the impact of rate-distortion attacks on state-of-the-art model-based and model-free algorithms. We also extend this notion of an information-theoretic approach to other types of adversarial attack, such as state observation attacks.", 'abstract_zh': '强化学习（RL）在马尔可夫决策过程（MDP）中的应用已 emergence 在许多安全相关领域，如自动驾驶、金融决策和无人机/机器人算法中。为了提高 RL 系统的健壮性/防御能力以对抗对手，研究各种对 RL 系统的对手攻击变得非常关键。大多数先前的工作考虑了在 MDP 中的确定性对手攻击策略，接受者（受害）代理可以通过逆转确定性攻击来击败这些攻击。在本文中，我们提出了一种可证明的“无敌”或“无法计数”的对手攻击类型。攻击者采用率失真信息论方法，随机改变代理对转移内核（或其他属性）的观察，使得代理在训练过程中几乎获得零或非常有限关于真实内核（或其他属性）的信息。我们推导出接受者代理的奖励后悔的信息论下界，并展示了率失真攻击对基于模型和无模型算法的影响。我们还将这一信息论方法的概念扩展到其他类型的对手攻击，如状态观察攻击。', 'title_zh': 'provably不可战胜的对抗攻击：强化学习系统的率--distortion信息论方法'}
{'arxiv_id': 'arXiv:2510.13786', 'title': 'The Art of Scaling Reinforcement Learning Compute for LLMs', 'authors': 'Devvrit Khatri, Lovish Madaan, Rishabh Tiwari, Rachit Bansal, Sai Surya Duvvuri, Manzil Zaheer, Inderjit S. Dhillon, David Brandfonbrener, Rishabh Agarwal', 'link': 'https://arxiv.org/abs/2510.13786', 'abstract': 'Reinforcement learning (RL) has become central to training large language models (LLMs), yet the field lacks predictive scaling methodologies comparable to those established for pre-training. Despite rapidly rising compute budgets, there is no principled understanding of how to evaluate algorithmic improvements for scaling RL compute. We present the first large-scale systematic study, amounting to more than 400,000 GPU-hours, that defines a principled framework for analyzing and predicting RL scaling in LLMs. We fit sigmoidal compute-performance curves for RL training and ablate a wide range of common design choices to analyze their effects on asymptotic performance and compute efficiency. We observe: (1) Not all recipes yield similar asymptotic performance, (2) Details such as loss aggregation, normalization, curriculum, and off-policy algorithm primarily modulate compute efficiency without materially shifting the asymptote, and (3) Stable, scalable recipes follow predictable scaling trajectories, enabling extrapolation from smaller-scale runs. Combining these insights, we propose a best-practice recipe, ScaleRL, and demonstrate its effectiveness by successfully scaling and predicting validation performance on a single RL run scaled up to 100,000 GPU-hours. Our work provides both a scientific framework for analyzing scaling in RL and a practical recipe that brings RL training closer to the predictability long achieved in pre-training.', 'abstract_zh': '强化学习（RL）已成为培训大规模语言模型（LLMs）的核心，但该领域缺乏与预训练领域建立的方法学相媲美的预测扩展方法。尽管计算预算迅速增加，但对于评估RL计算扩展的算法改进却缺乏基本原则的理解。我们进行了首次大规模系统的研究，总计超过400,000个GPU小时，定义了一个分析和预测LLMs中RL扩展的严谨框架。我们拟合了RL训练的S形计算-性能曲线，并消除了一大范围常见的设计选择，以分析其对渐近性能和计算效率的影响。我们观察到：（1）并非所有配方都能实现相似的渐近性能，（2）细节如损失聚合、 normalization、递增式学习和离策算法主要调节计算效率而未实质性地改变渐近线，（3）稳定且可扩展的配方遵循可预测的扩展轨迹，从而允许从小规模运行中进行外推。结合这些洞见，我们提出了一种最佳实践配方——ScaleRL，并通过成功地将其扩展并预测到单个RL运行达到100,000个GPU小时的验证性能，证明了其有效性。我们的工作为分析RL扩展提供了科学框架，并提供了一种实用的配方，使RL训练更接近预训练领域已经实现的可预测性。', 'title_zh': 'Reinforcement Learning 算法在大语言模型中的扩展计算艺术'}
{'arxiv_id': 'arXiv:2510.13778', 'title': 'InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy', 'authors': 'Xinyi Chen, Yilun Chen, Yanwei Fu, Ning Gao, Jiaya Jia, Weiyang Jin, Hao Li, Yao Mu, Jiangmiao Pang, Yu Qiao, Yang Tian, Bin Wang, Bolun Wang, Fangjing Wang, Hanqing Wang, Tai Wang, Ziqin Wang, Xueyuan Wei, Chao Wu, Shuai Yang, Jinhui Ye, Junqiu Yu, Jia Zeng, Jingjing Zhang, Jinyu Zhang, Shi Zhang, Feng Zheng, Bowen Zhou, Yangkun Zhu', 'link': 'https://arxiv.org/abs/2510.13778', 'abstract': "We introduce InternVLA-M1, a unified framework for spatial grounding and robot control that advances instruction-following robots toward scalable, general-purpose intelligence. Its core idea is spatially guided vision-language-action training, where spatial grounding serves as the critical link between instructions and robot actions. InternVLA-M1 employs a two-stage pipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning data to determine ``where to act'' by aligning instructions with visual, embodiment-agnostic positions, and (ii) spatially guided action post-training to decide ``how to act'' by generating embodiment-aware actions through plug-and-play spatial prompting. This spatially guided training recipe yields consistent gains: InternVLA-M1 outperforms its variant without spatial guidance by +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO Franka, while demonstrating stronger spatial reasoning capability in box, point, and trace prediction. To further scale instruction following, we built a simulation engine to collect 244K generalizable pick-and-place episodes, enabling a 6.2% average improvement across 200 tasks and 3K+ objects. In real-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with synthetic co-training, achieved +20.6% on unseen objects and novel configurations. Moreover, in long-horizon reasoning-intensive scenarios, it surpassed existing works by over 10%. These results highlight spatially guided training as a unifying principle for scalable and resilient generalist robots. Code and models are available at this https URL.", 'abstract_zh': '统一空间定位与机器人控制框架：InternVLA-M1及其在可扩展通用智能机器人指令遵循中的应用', 'title_zh': 'InternVLA-M1：一种面向通用机器人政策的空间引导型视觉-语言-行动框架'}
{'arxiv_id': 'arXiv:2510.13768', 'title': 'Scaling Vision Transformers for Functional MRI with Flat Maps', 'authors': 'Connor Lane, Daniel Z. Kaplan, Tanishq Mathew Abraham, Paul S. Scotti', 'link': 'https://arxiv.org/abs/2510.13768', 'abstract': 'A key question for adapting modern deep learning architectures to functional MRI (fMRI) is how to represent the data for model input. To bridge the modality gap between fMRI and natural images, we transform the 4D volumetric fMRI data into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K hours of fMRI flat map videos from the Human Connectome Project using the spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law. Downstream classification benchmarks show that our model learns rich representations supporting both fine-grained state decoding across subjects, as well as subject-specific trait decoding across changes in brain state. This work is part of an ongoing open science project to build foundation models for fMRI data. Our code and datasets are available at this https URL.', 'abstract_zh': '将现代深度学习架构适应功能性磁共振成像（fMRI）的关键问题是如何表示数据以供模型输入。为了弥合fMRI与自然图像之间的模态差距，我们将4D体积fMRI数据转换为2D fMRI活动平面图的视频。我们使用时空掩蔽自编码器（MAE）框架在人类连接组计划的2.3万小时fMRI平面图视频上训练视觉变换器。我们观察到，掩蔽fMRI建模性能随着数据集大小严格遵循幂律扩展。下游分类基准表明，我们的模型学会了支持跨被试的精细状态解码以及跨脑状态变化的被试特定特质解码的丰富表示。这项工作是构建fMRI数据基础模型的持续开源项目的一部分。我们的代码和数据集可在以下链接获得。', 'title_zh': '用于功能性磁共振成像的平铺图扩展视觉变换器'}
{'arxiv_id': 'arXiv:2510.13756', 'title': 'RECODE: Reasoning Through Code Generation for Visual Question Answering', 'authors': 'Junhong Shen, Mu Cai, Bo Hu, Ameet Talwalkar, David A Ross, Cordelia Schmid, Alireza Fathi', 'link': 'https://arxiv.org/abs/2510.13756', 'abstract': 'Multimodal Large Language Models (MLLMs) struggle with precise reasoning for structured visuals like charts and diagrams, as pixel-based perception lacks a mechanism for verification. To address this, we propose to leverage derendering -- the process of reverse-engineering visuals into executable code -- as a new modality for verifiable visual reasoning. Specifically, we propose RECODE, an agentic framework that first generates multiple candidate programs to reproduce the input image. It then uses a critic to select the most faithful reconstruction and iteratively refines the code. This process not only transforms an ambiguous perceptual task into a verifiable, symbolic problem, but also enables precise calculations and logical inferences later on. On various visual reasoning benchmarks such as CharXiv, ChartQA, and Geometry3K, RECODE significantly outperforms methods that do not leverage code or only use code for drawing auxiliary lines or cropping. Our work demonstrates that grounding visual perception in executable code provides a new path toward more accurate and verifiable multimodal reasoning.', 'abstract_zh': '多模态大语言模型（MLLMs）在处理图表和图表等结构化视觉内容的精确推理方面存在困难，基于像素的感知缺乏验证机制。为解决这一问题，我们提出利用反渲染——将视觉内容逆向工程化为可执行代码的过程——作为一种新的验证性视觉推理模态。具体地，我们提出了RECODE，一种代理框架，首先生成多个候选程序以再现输入图像，然后使用批评家选择最忠实的重建，并迭代完善代码。这一过程不仅将含糊的感知任务转化为可验证的符号问题，还使得后续的精确计算和逻辑推理成为可能。在诸如CharXiv、ChartQA和Geometry3K等视觉推理基准测试中，RECODE显著优于未利用代码或仅使用代码绘制辅助线或裁剪的方法。我们的工作证明，将视觉感知 grounding 在可执行代码上为实现更准确和可验证的多模态推理开辟了新途径。', 'title_zh': 'RECODE: 通过代码生成进行视觉问答的推理'}
{'arxiv_id': 'arXiv:2510.13740', 'title': 'Multi-Scale High-Resolution Logarithmic Grapher Module for Efficient Vision GNNs', 'authors': 'Mustafa Munir, Alex Zhang, Radu Marculescu', 'link': 'https://arxiv.org/abs/2510.13740', 'abstract': "Vision graph neural networks (ViG) have demonstrated promise in vision tasks as a competitive alternative to conventional convolutional neural nets (CNN) and transformers (ViTs); however, common graph construction methods, such as k-nearest neighbor (KNN), can be expensive on larger images. While methods such as Sparse Vision Graph Attention (SVGA) have shown promise, SVGA's fixed step scale can lead to over-squashing and missing multiple connections to gain the same information that could be gained from a long-range link. Through this observation, we propose a new graph construction method, Logarithmic Scalable Graph Construction (LSGC) to enhance performance by limiting the number of long-range links. To this end, we propose LogViG, a novel hybrid CNN-GNN model that utilizes LSGC. Furthermore, inspired by the successes of multi-scale and high-resolution architectures, we introduce and apply a high-resolution branch and fuse features between our high-resolution and low-resolution branches for a multi-scale high-resolution Vision GNN network. Extensive experiments show that LogViG beats existing ViG, CNN, and ViT architectures in terms of accuracy, GMACs, and parameters on image classification and semantic segmentation tasks. Our smallest model, Ti-LogViG, achieves an average top-1 accuracy on ImageNet-1K of 79.9% with a standard deviation of 0.2%, 1.7% higher average accuracy than Vision GNN with a 24.3% reduction in parameters and 35.3% reduction in GMACs. Our work shows that leveraging long-range links in graph construction for ViGs through our proposed LSGC can exceed the performance of current state-of-the-art ViGs. Code is available at this https URL.", 'abstract_zh': '基于对数可扩展图构建的Vision图神经网络（LogViG）', 'title_zh': '多尺度高分辨率对数图模块：用于高效视觉图神经网络的设计'}
{'arxiv_id': 'arXiv:2510.13724', 'title': 'FIRST: Federated Inference Resource Scheduling Toolkit for Scientific AI Model Access', 'authors': 'Aditya Tanikanti, Benoit Côté, Yanfei Guo, Le Chen, Nickolaus Saint, Ryan Chard, Ken Raffenetti, Rajeev Thakur, Thomas Uram, Ian Foster, Michael E. Papka, Venkatram Vishwanath', 'link': 'https://arxiv.org/abs/2510.13724', 'abstract': 'We present the Federated Inference Resource Scheduling Toolkit (FIRST), a framework enabling Inference-as-a-Service across distributed High-Performance Computing (HPC) clusters. FIRST provides cloud-like access to diverse AI models, like Large Language Models (LLMs), on existing HPC infrastructure. Leveraging Globus Auth and Globus Compute, the system allows researchers to run parallel inference workloads via an OpenAI-compliant API on private, secure environments. This cluster-agnostic API allows requests to be distributed across federated clusters, targeting numerous hosted models. FIRST supports multiple inference backends (e.g., vLLM), auto-scales resources, maintains "hot" nodes for low-latency execution, and offers both high-throughput batch and interactive modes. The framework addresses the growing demand for private, secure, and scalable AI inference in scientific workflows, allowing researchers to generate billions of tokens daily on-premises without relying on commercial cloud infrastructure.', 'abstract_zh': 'Federated Inference Resource Scheduling Toolkit (FIRST): 一种跨分布高性能计算集群的推理即服务框架', 'title_zh': 'FIRST: Federated Inference Resource Scheduling Toolkit for Scientific AI Model Access'}
{'arxiv_id': 'arXiv:2510.13721', 'title': 'NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching', 'authors': 'Run Luo, Xiaobo Xia, Lu Wang, Longze Chen, Renke Shan, Jing Luo, Min Yang, Tat-Seng Chua', 'link': 'https://arxiv.org/abs/2510.13721', 'abstract': 'Next-generation multimodal foundation models capable of any-to-any cross-modal generation and multi-turn interaction will serve as core components of artificial general intelligence systems, playing a pivotal role in human-machine interaction. However, most existing multimodal models remain constrained by autoregressive architectures, whose inherent limitations prevent a balanced integration of understanding and generation capabilities. Although hybrid and decoupling strategies have been explored to address these tasks within unified frameworks separately, their redundant, non-integrated designs limit their applicability to broader scenarios, such as cross-modal this http URL this work, we introduce NExT-OMNI, an open-source omnimodal foundation model that achieves unified modeling through discrete flow paradigms. By leveraging metric-induced probability paths and kinetic optimal velocities, NExT-OMNI natively supports any-to-any understanding and generation with enhanced response efficiency, while enabling broader application scenarios through concise unified representations rather than task-decoupled designs. Trained on large-scale interleaved text, image, video, and audio data, NExT-OMNI delivers competitive performance on multimodal generation and understanding benchmarks, while outperforming prior unified models in multi-turn multimodal interaction and cross-modal retrieval, highlighting its architectural advantages as a next-generation multimodal foundation model. To advance further research, we release training details, data protocols, and open-source both the code and model checkpoints.', 'abstract_zh': '下一代多模态基础模型：通过离散流 paradigms 实现统一建模的 NExT-OMNI', 'title_zh': 'NExT-OMNI: 向任意模态到任意模态的全能基础模型进发，基于离散流匹配'}
{'arxiv_id': 'arXiv:2510.13714', 'title': 'Dedelayed: Deleting remote inference delay via on-device correction', 'authors': 'Dan Jacobellis, Mateen Ulhaq, Fabien Racapé, Hyomin Choi, Neeraja J. Yadwadkar', 'link': 'https://arxiv.org/abs/2510.13714', 'abstract': 'Remote inference allows lightweight devices to leverage powerful cloud models. However, communication network latency makes predictions stale and unsuitable for real-time tasks. To address this, we introduce Dedelayed, a delay-corrective method that mitigates arbitrary remote inference delays, allowing the local device to produce low-latency outputs in real time. Our method employs a lightweight local model that processes the current frame and fuses in features that a heavyweight remote model computes from past frames. On video from the BDD100K driving dataset, Dedelayed improves semantic segmentation accuracy over the stronger of the local-only and remote-only baselines across all realistic communication network delays beyond 33 ms. Without incurring additional delay, it improves accuracy by 6.4 mIoU compared to fully local inference and 9.8 mIoU compared to remote inference, for a round-trip delay of 100 ms. The advantage grows under longer delays and higher-motion scenes, as delay-mitigated split inference sustains accuracy more effectively, providing clear advantages for real-time tasks that must remain aligned with the current world state.', 'abstract_zh': '延迟补偿允许轻量级设备利用强大的云模型。然而，通信网络延迟使得预测过时而不适合实时任务。为了解决这个问题，我们介绍了Dedelayed，一种延迟校正方法，可以缓解任意远程推理延迟，使本地设备能够在实时中生成低延迟输出。我们的方法采用一个轻量级的本地模型，处理当前帧并融合远程模型从过去帧计算出的特征。在BDD100K驾驶数据集的视频上，Dedelayed在所有通信网络延迟超过33 ms的所有实际情况下，其语义分割准确性优于仅本地和仅远程基线。在100 ms往返延迟下，与完全本地推理相比，它提高了6.4 mIoU的准确性，与远程推理相比提高了9.8 mIoU的准确性。在更长的延迟和更高运动场景下，这种优势更加明显，因为延迟缓解的拆分流推理更有效地保持准确性，为必须与当前世界状态保持一致的实时任务提供明显优势。', 'title_zh': 'Dedelayed: 通过设备端校正删除远程推理延迟'}
{'arxiv_id': 'arXiv:2510.13704', 'title': 'Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents', 'authors': 'Johan Obando-Ceron, Walter Mayor, Samuel Lavoie, Scott Fujimoto, Aaron Courville, Pablo Samuel Castro', 'link': 'https://arxiv.org/abs/2510.13704', 'abstract': 'Recent works have proposed accelerating the wall-clock training time of actor-critic methods via the use of large-scale environment parallelization; unfortunately, these can sometimes still require large number of environment interactions to achieve a desired level of performance. Noting that well-structured representations can improve the generalization and sample efficiency of deep reinforcement learning (RL) agents, we propose the use of simplicial embeddings: lightweight representation layers that constrain embeddings to simplicial structures. This geometric inductive bias results in sparse and discrete features that stabilize critic bootstrapping and strengthen policy gradients. When applied to FastTD3, FastSAC, and PPO, simplicial embeddings consistently improve sample efficiency and final performance across a variety of continuous- and discrete-control environments, without any loss in runtime speed.', 'abstract_zh': '近期的研究提出了通过大规模环境并行化加速演员-评论家方法的wall-clock训练时间；然而，这有时仍然需要大量的环境交互来达到期望的性能水平。考虑到结构良好的表示能够提高深度强化学习代理的泛化能力和样本效率，我们提出使用单纯复嵌入：一种轻量级的表示层，将嵌入约束在单纯复结构中。这种几何归纳偏置导致稀疏且离散的特征，稳定评论家递推并强化策略梯度。当应用于FastTD3、FastSAC和PPO时，在各种连续控制和离散控制环境中，单纯复嵌入始终一致地提高了样本效率和最终性能，而不损失运行时速度。', 'title_zh': '简化锥体嵌入提高演员-评论家代理的样本效率'}
{'arxiv_id': 'arXiv:2510.13702', 'title': 'MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion', 'authors': 'Minjung Shin, Hyunin Cho, Sooyeon Go, Jin-Hwa Kim, Youngjung Uh', 'link': 'https://arxiv.org/abs/2510.13702', 'abstract': "Multi-view generation with camera pose control and prompt-based customization are both essential elements for achieving controllable generative models. However, existing multi-view generation models do not support customization with geometric consistency, whereas customization models lack explicit viewpoint control, making them challenging to unify. Motivated by these gaps, we introduce a novel task, multi-view customization, which aims to jointly achieve multi-view camera pose control and customization. Due to the scarcity of training data in customization, existing multi-view generation models, which inherently rely on large-scale datasets, struggle to generalize to diverse prompts. To address this, we propose MVCustom, a novel diffusion-based framework explicitly designed to achieve both multi-view consistency and customization fidelity. In the training stage, MVCustom learns the subject's identity and geometry using a feature-field representation, incorporating the text-to-video diffusion backbone enhanced with dense spatio-temporal attention, which leverages temporal coherence for multi-view consistency. In the inference stage, we introduce two novel techniques: depth-aware feature rendering explicitly enforces geometric consistency, and consistent-aware latent completion ensures accurate perspective alignment of the customized subject and surrounding backgrounds. Extensive experiments demonstrate that MVCustom is the only framework that simultaneously achieves faithful multi-view generation and customization.", 'abstract_zh': '多视角定制生成：兼具多视角相机姿态控制和基于提示的定制的新型任务与框架', 'title_zh': 'MVCustom: 多视图定制扩散通过几何潜在渲染和完成'}
{'arxiv_id': 'arXiv:2510.13669', 'title': 'CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas', 'authors': 'Zian Li, Muhan Zhang', 'link': 'https://arxiv.org/abs/2510.13669', 'abstract': 'Masked autoregressive models (MAR) have recently emerged as a powerful paradigm for image and video generation, combining the flexibility of masked modeling with the potential of continuous tokenizer. However, video MAR models suffer from two major limitations: the slow-start problem, caused by the lack of a structured global prior at early sampling stages, and error accumulation across the autoregression in both spatial and temporal dimensions. In this work, we propose CanvasMAR, a novel video MAR model that mitigates these issues by introducing a canvas mechanism--a blurred, global prediction of the next frame, used as the starting point for masked generation. The canvas provides global structure early in sampling, enabling faster and more coherent frame synthesis. Furthermore, we introduce compositional classifier-free guidance that jointly enlarges spatial (canvas) and temporal conditioning, and employ noise-based canvas augmentation to enhance robustness. Experiments on the BAIR and Kinetics-600 benchmarks demonstrate that CanvasMAR produces high-quality videos with fewer autoregressive steps. Our approach achieves remarkable performance among autoregressive models on Kinetics-600 dataset and rivals diffusion-based methods.', 'abstract_zh': '基于遮蔽机制的视频生成模型CanvasMAR：通过画布机制缓解缓慢启动问题和错误累积', 'title_zh': 'CanvasMAR: 在Canvas上改进掩蔽自回归视频生成'}
{'arxiv_id': 'arXiv:2510.13665', 'title': 'Axial Neural Networks for Dimension-Free Foundation Models', 'authors': 'Hyunsu Kim, Jonggeon Park, Joan Bruna, Hongseok Yang, Juho Lee', 'link': 'https://arxiv.org/abs/2510.13665', 'abstract': 'The advent of foundation models in AI has significantly advanced general-purpose learning, enabling remarkable capabilities in zero-shot inference and in-context learning. However, training such models on physics data, including solutions to partial differential equations (PDEs), poses a unique challenge due to varying dimensionalities across different systems. Traditional approaches either fix a maximum dimension or employ separate encoders for different dimensionalities, resulting in inefficiencies. To address this, we propose a dimension-agnostic neural network architecture, the Axial Neural Network (XNN), inspired by parameter-sharing structures such as Deep Sets and Graph Neural Networks. XNN generalizes across varying tensor dimensions while maintaining computational efficiency. We convert existing PDE foundation models into axial neural networks and evaluate their performance across three training scenarios: training from scratch, pretraining on multiple PDEs, and fine-tuning on a single PDE. Our experiments show that XNNs perform competitively with original models and exhibit superior generalization to unseen dimensions, highlighting the importance of multidimensional pretraining for foundation models.', 'abstract_zh': '基础模型在AI中的出现显著提升了通用学习能力，使其在零样本推理和上下文学习方面表现出了 remarkable 的能力。然而，这类模型在训练时需要处理物理数据，包括偏微分方程（PDEs）的解，这因其不同系统间维度的差异而带来了独特挑战。传统的approach要么固定最大维度，要么为不同维度使用独立编码器，这导致了效率低下。为了解决这一问题，我们提出了一种维度无关的神经网络架构——轴向神经网络（Axial Neural Network，XNN），它受到了如Deep Sets和图神经网络等参数共享结构的启发。XNN能够在保持计算效率的同时，泛化到不同的张量维度。我们将现有的PDE基础模型转换为轴向神经网络，并在三种训练场景下评估其性能：从零开始训练、基于多个PDE的预训练以及基于单个PDE的微调。我们的实验表明，XNN在性能上与原始模型相当，并且在泛化到未见过的维度时表现出优越的能力，强调了多维度预训练对基础模型的重要性。', 'title_zh': '轴向神经网络在维度无关基础模型中的应用'}
{'arxiv_id': 'arXiv:2510.13654', 'title': 'Time Series Foundation Models: Benchmarking Challenges and Requirements', 'authors': 'Marcel Meyer, Sascha Kaltenpoth, Kevin Zalipski, Oliver Müller', 'link': 'https://arxiv.org/abs/2510.13654', 'abstract': 'Time Series Foundation Models (TSFMs) represent a new paradigm for time series forecasting, offering zero-shot forecasting capabilities without the need for domain-specific pre-training or fine-tuning. However, as with Large Language Models (LLMs), evaluating TSFMs is tricky, as with ever more extensive training sets, it becomes more and more challenging to ensure the integrity of benchmarking data. Our investigation of existing TSFM evaluation highlights multiple challenges, ranging from the representativeness of the benchmark datasets, over the lack of spatiotemporal evaluation, to risks of information leakage due to overlapping and obscure datasets, and the memorization of global patterns caused by external shocks like economic crises or pandemics. Our findings reveal widespread confusion regarding data partitions, risking inflated performance estimates and incorrect transfer of global knowledge to local time series. We argue for the development of robust evaluation methodologies to prevent pitfalls already observed in LLM and classical time series benchmarking, and call upon the research community to design new, principled approaches, such as evaluations on truly out-of-sample future data, to safeguard the integrity of TSFM assessment.', 'abstract_zh': 'Time Series Foundation Models (TSFMs)代表了一种新的时间序列预测范式，无需领域特定的预训练或微调即可提供零样本预测能力。然而，与大型语言模型（LLMs）一样，评估TSFMs也颇具挑战性，随着训练数据集的不断扩大，确保基准数据完整性的难度也在不断增加。我们对现有TSFM评估的调查揭示了多个挑战，包括基准数据集的代表性不足、缺乏时空评估、因重叠和模糊的数据集引发的信息泄漏风险，以及由于经济危机或疫情等外部冲击导致的全局模式记忆风险。我们的发现表明，广泛的数据分区混淆可能导致夸大了的性能评估和全球知识向本地时间序列的错误转移。我们主张开发稳健的评估方法以防止已经观察到的LLMs和经典时间序列基准测试中的陷阱，并呼吁研究界设计新的、原则性的评估方法，如在真正的未来数据上进行评估，以确保TSFM评估的完整性。', 'title_zh': '时间序列基础模型：基准测试挑战与要求'}
{'arxiv_id': 'arXiv:2510.13632', 'title': 'Closing the Gap Between Text and Speech Understanding in LLMs', 'authors': 'Santiago Cuervo, Skyler Seto, Maureen de Seyssel, Richard He Bai, Zijin Gu, Tatiana Likhomanenko, Navdeep Jaitly, Zakaria Aldeneh', 'link': 'https://arxiv.org/abs/2510.13632', 'abstract': 'Large Language Models (LLMs) can be adapted to extend their text capabilities to speech inputs. However, these speech-adapted LLMs consistently underperform their text-based counterparts--and even cascaded pipelines--on language understanding tasks. We term this shortfall the text-speech understanding gap: the performance drop observed when a speech-adapted LLM processes spoken inputs relative to when the original text-based LLM processes the equivalent text. Recent approaches to narrowing this gap either rely on large-scale speech synthesis of text corpora, which is costly and heavily dependent on synthetic data, or on large-scale proprietary speech datasets, which are not reproducible. As a result, there remains a need for more data-efficient alternatives for closing the text-speech understanding gap. In this work, we analyze the gap as driven by two factors: (i) forgetting of text capabilities during adaptation, and (ii) cross-modal misalignment between speech and text. Based on this analysis, we introduce SALAD--Sample-efficient Alignment with Learning through Active selection and cross-modal Distillation--which combines cross-modal distillation with targeted synthetic data to improve alignment while mitigating forgetting. Applied to 3B and 7B LLMs, SALAD achieves competitive performance with a strong open-weight model across broad-domain benchmarks in knowledge, language understanding, and reasoning, while training on over an order of magnitude less speech data from public corpora.', 'abstract_zh': '大型语言模型（LLMs）可以适应以扩展其文本能力至语音输入。然而，这些语音适应的LLMs在其语言理解任务上的表现普遍低于其基于文本的同类模型——甚至串接管道模型。我们称此差距为文本-语音理解鸿沟：当语音适应的LLM处理语音输入时相对于原基于文本的LLM处理等效文本时观察到的表现下降。最近缩小这一差距的方法要么依赖大规模语音合成文本语料库，这成本高昂且高度依赖合成数据，要么依赖大规模专有语音数据集，这些数据集不可再现。因此，仍需更数据高效的选择替代方案来缩小文本-语音理解鸿沟。在本工作中，我们分析了这一差距由两个因素驱动：(i) 适应过程中的文本能力遗忘，(ii) 语音和文本的跨模态不对齐。基于此分析，我们引入了SALAD —— 通过积极选择和跨模态蒸馏进行学习的数据高效对齐，其结合了跨模态蒸馏和目标合成数据以改进对齐并减轻遗忘。应用于3B和7B LLMs，SALAD在广泛领域的知识、语言理解和推理基准测试中实现了与强开源权重模型相当的表现，同时仅使用公共语料库中语音数据量的数个数量级进行训练。', 'title_zh': '在大规模语言模型中缩小文本和语音理解的差距'}
{'arxiv_id': 'arXiv:2510.13624', 'title': 'Unlocking Public Catalogues: Instruction-Tuning LLMs for ICD Coding of German Tumor Diagnoses', 'authors': 'Stefan Lenz, Lakisha Ortiz Rosario, Georg Vollmar, Arsenij Ustjanzew, Fatma Alickovic, Thomas Kindler, Torsten Panholzer', 'link': 'https://arxiv.org/abs/2510.13624', 'abstract': 'Accurate coding of tumor diagnoses with ICD-10-GM and ICD-O-3 is essential for structured cancer documentation in Germany. Smaller open-weight LLMs are appealing for privacy-preserving automation but often struggle with coding accuracy in German-language contexts. This study investigates whether instruction-based fine-tuning on public datasets improves the coding accuracy of open-weight LLMs for German tumor diagnosis texts. The evaluation uses coded diagnoses from the local tumor documentation system as test data. In a systematic data quality assessment, the upper limit for ICD-10 coding performance was estimated at 60-79% for exact and 81-94% for partial (three-character codes only) derivation. As training data, over 500,000 question-answer pairs were created based on the ICD-10-GM, ICD-O-3, and OPS catalogues. Eight open-weight models from the Qwen, Llama, and Mistral families (7-70 B parameters) were fine-tuned. ICD-10-GM accuracy rose from 1.4-24% to 41-58%, and partial accuracy from 31-74% to 73-83%. The accuracy of ICD-O-3 topography coding also improved but started and remained considerably lower with an exact accuracy of 22-40% and a partial accuracy of 56-67% after fine-tuning. Malformed code outputs dropped to 0% for all models. Tumor-diagnosis recognition reached 99%. Accuracy correlated positively with model size, but gaps between small and large models narrowed after fine-tuning. The reasoning mode in Qwen3 generally yielded a lower performance than fine-tuning and was over 100 times slower. Our findings highlight the potential of leveraging public catalogues to build instruction datasets that improve LLMs in medical documentation tasks. The complete training dataset and the best-performing checkpoints of the fine-tuned models are available from this https URL.', 'abstract_zh': '使用ICD-10-GM和ICD-O-3精确编码肿瘤诊断对于德国结构化癌症文档记录至关重要。基于公共数据集的指令调整能否提高德语肿瘤诊断文本的编码准确性？性能评估使用了当地肿瘤文档系统中的编码诊断数据。在系统数据质量评估中，ICD-10精确编码的上限估计为60-79%，部分编码（仅三字符代码）的上限为81-94%。作为训练数据，基于ICD-10-GM、ICD-O-3和OPS目录创建了超过50万个问答对。使用Qwen、Llama和Mistral家族的8个开源模型（7-70亿参数）进行了指令调整。ICD-10-GM编码准确性从1.4-24%提高到41-58%，部分准确性从31-74%提高到73-83%。ICD-O-3组织学编码准确性也有所提高，但调整后精确编码为22-40%，部分编码为56-67%。所有模型的错误编码输出降至0%，肿瘤诊断识别率达到99%。准确性与模型大小正相关，但在调整后，小模型和大模型之间的差距缩小。Qwen3的推理模式通常性能较低，比调整慢100多倍。我们的研究结果突显了利用公共目录构建指令数据集以提高LLM在医疗文档任务中的性能的潜力。完整的训练数据集和最佳性能的模型检查点可在以下网址获取。', 'title_zh': '解锁公共目录：针对德国肿瘤诊断ICD编码的指令调优大语言模型'}
{'arxiv_id': 'arXiv:2510.13621', 'title': 'The Role of Computing Resources in Publishing Foundation Model Research', 'authors': 'Yuexing Hao, Yue Huang, Haoran Zhang, Chenyang Zhao, Zhenwen Liang, Paul Pu Liang, Yue Zhao, Lichao Sun, Saleh Kalantari, Xiangliang Zhang, Marzyeh Ghassemi', 'link': 'https://arxiv.org/abs/2510.13621', 'abstract': "Cutting-edge research in Artificial Intelligence (AI) requires considerable resources, including Graphics Processing Units (GPUs), data, and human resources. In this paper, we evaluate of the relationship between these resources and the scientific advancement of foundation models (FM). We reviewed 6517 FM papers published between 2022 to 2024, and surveyed 229 first-authors to the impact of computing resources on scientific output. We find that increased computing is correlated with national funding allocations and citations, but our findings don't observe the strong correlations with research environment (academic or industrial), domain, or study methodology. We advise that individuals and institutions focus on creating shared and affordable computing opportunities to lower the entry barrier for under-resourced researchers. These steps can help expand participation in FM research, foster diversity of ideas and contributors, and sustain innovation and progress in AI. The data will be available at: this https URL", 'abstract_zh': '人工智能（AI）领域的尖端研究需要大量的资源，包括图形处理单元（GPUs）、数据和人力资源。本文评估了这些资源与基础模型（FM）科学进步之间的关系。我们回顾了2022年至2024年间发表的6517篇FM论文，并调查了229位通讯作者，评估计算资源对科研产出的影响。我们发现，增加的计算资源与国家拨款和引用次数相关，但我们的研究未观察到与研究环境（学术界或工业界）、研究领域或研究方法的强相关性。我们建议个人和机构应致力于创造共享且负担得起的计算机会，以降低资源不足的研究人员的入门门槛。这些步骤有助于扩大FM研究的参与度，促进思想和贡献者的多样性，并维持AI领域的创新与发展。数据将在此处获取：this https URL。', 'title_zh': '计算资源在发布基础模型研究中的作用'}
{'arxiv_id': 'arXiv:2510.13615', 'title': 'Message Passing on the Edge: Towards Scalable and Expressive GNNs', 'authors': 'Pablo Barceló, Fabian Jogl, Alexander Kozachinskiy, Matthias Lanzinger, Stefan Neumann, Cristóbal Rojas', 'link': 'https://arxiv.org/abs/2510.13615', 'abstract': 'We propose EB-1WL, an edge-based color-refinement test, and a corresponding GNN architecture, EB-GNN. Our architecture is inspired by a classic triangle counting algorithm by Chiba and Nishizeki, and explicitly uses triangles during message passing. We achieve the following results: (1)~EB-1WL is significantly more expressive than 1-WL. Further, we provide a complete logical characterization of EB-1WL based on first-order logic, and matching distinguishability results based on homomorphism counting. (2)~In an important distinction from previous proposals for more expressive GNN architectures, EB-1WL and EB-GNN require near-linear time and memory on practical graph learning tasks. (3)~Empirically, we show that EB-GNN is a highly-efficient general-purpose architecture: It substantially outperforms simple MPNNs, and remains competitive with task-specialized GNNs while being significantly more computationally efficient.', 'abstract_zh': '基于边的颜色细化检验EB-1WL及其对应的EB-GNN架构：三角计数启发的图神经网络', 'title_zh': '边缘计算中的消息传递：走向 scalable 和 expressive 的图神经网络'}
{'arxiv_id': 'arXiv:2510.13602', 'title': 'NOSA: Native and Offloadable Sparse Attention', 'authors': 'Yuxiang Huang, Chaojun Xiao, Xu Han, Zhiyuan Liu', 'link': 'https://arxiv.org/abs/2510.13602', 'abstract': 'Trainable sparse attention has emerged as a promising solution to address the decoding efficiency bottleneck of LLMs in long-context processing, significantly saving memory accesses while minimally impacting task performance. However, existing sparse attention methods leave a crucial limitation unresolved: the size of the key-value (KV) cache remains unreduced, which constrains on-GPU batch sizes and throttles decoding throughput, especially in large-scale batched inference. In this paper, we show that trainable sparse attention naturally exhibits strong locality in token selection across adjacent decoding steps, thereby enabling KV cache offloading without altering the underlying attention computation. However, the inherent locality remains insufficient to achieve efficient offloading, as the transfer of selected KV pairs between the CPU and GPU continues to dominate the overall decoding cost. Building on this insight, we present NOSA, a trainable sparse attention framework designed to natively support KV cache offloading. NOSA introduces explicit locality constraints by decomposing token selection into query-aware and query-agnostic components, thereby reducing KV transfers while preserving the same attention computation as used during training. We pretrain a 1B-parameter model with NOSA and conduct extensive benchmarks, showing that it preserves near-lossless performance while achieving up to a 2.3x improvement in decoding throughput compared with the vanilla trainable sparse attention baseline (InfLLM-V2).', 'abstract_zh': '可训练稀疏注意力已成为解决LLMs在长上下文处理中解码效率瓶颈的有前途的解决方案，显著减少了内存访问次数，同时 minimally 影响任务性能。然而，现有的稀疏注意力方法未能解决一个关键限制：键值（KV）缓存的大小未被缩减，这限制了GPU上的批量大小，并使解码吞吐量受到影响，尤其是在大规模批量推理中。在本文中，我们展示了可训练稀疏注意力在相邻解码步骤中自然表现出很强的tokens选择局部性，从而能够在不改变基础注意力计算的情况下实现KV缓存卸载。然而，固有的局部性仍然不足以实现高效的卸载，因为CPU和GPU之间选定的KV对的传输继续主导整体解码成本。基于这一见解，我们提出了NOSA，这是一种设计用于原生支持KV缓存卸载的可训练稀疏注意力框架。NOSA通过将token选择分解为query-aware和query-agnostic部分，引入明确的局部性约束，从而减少KV传输，同时保持与训练中相同的注意力计算。我们使用NOSA预训练了一个1亿参数模型，并进行了广泛的基准测试，结果显示它保留了接近无损的性能，解码吞吐量相比 vanilla 可训练稀疏注意力 baselines（InfLLM-V2）提高了2.3倍。', 'title_zh': 'NOSA: 原生可卸载稀疏注意力机制'}
{'arxiv_id': 'arXiv:2510.13591', 'title': 'Subject Roles in the EU AI Act: Mapping and Regulatory Implications', 'authors': 'Nicola Fabiano', 'link': 'https://arxiv.org/abs/2510.13591', 'abstract': 'The European Union\'s Artificial Intelligence Act (Regulation (EU) 2024/1689) establishes the world\'s first comprehensive regulatory framework for AI systems through a sophisticated ecosystem of interconnected subjects defined in Article 3. This paper provides a structured examination of the six main categories of actors - providers, deployers, authorized representatives, importers, distributors, and product manufacturers - collectively referred to as "operators" within the regulation. Through examination of these Article 3 definitions and their elaboration across the regulation\'s 113 articles, 180 recitals, and 13 annexes, we map the complete governance structure and analyze how the AI Act regulates these subjects. Our analysis reveals critical transformation mechanisms whereby subjects can assume different roles under specific conditions, particularly through Article 25 provisions ensuring accountability follows control. We identify how obligations cascade through the supply chain via mandatory information flows and cooperation requirements, creating a distributed yet coordinated governance system. The findings demonstrate how the regulation balances innovation with the protection of fundamental rights through risk-based obligations that scale with the capabilities and deployment contexts of AI systems, providing essential guidance for stakeholders implementing the AI Act\'s requirements.', 'abstract_zh': '欧盟人工智能法案（条例（EU）2024/1689）通过在第3条中定义的复杂互联主体体系，确立了全球首个全面的人工智能系统监管框架。本文对条例中规定的六大主要类别主体——提供者、部署者、授权代表、进口商、分销商和产品制造商——进行了结构化的考察，并将其统称为“经营者”。通过对条例113条、180条说明和13个附录中这些第3条定义的审查和展开，我们绘制出完整的治理结构，并分析人工智能法案对这些主体的监管方式。我们的分析揭示了关键的转型机制，即在特定条件下，主体可以根据控制权的变化承担不同的角色，特别是第25条规定的责任跟随控制的保障机制。我们还识别了这些义务如何通过强制性信息流动和合作要求在供应链中层层传递，形成一种分散但仍协调的治理系统。研究结果表明，该条例在风险基础上平衡了创新与基本权利保护，通过与人工智能系统能力和部署环境相匹配的义务规模，为实施人工智能法案要求的各方面提供了必要的指导。', 'title_zh': 'EU AI法案中的主体角色：映射与监管 implications'}
{'arxiv_id': 'arXiv:2510.13586', 'title': 'Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs', 'authors': 'Pasin Buakhaw, Kun Kerdthaisong, Phuree Phenhiran, Pitikorn Khlaisamniang, Supasate Vorathammathorn, Piyalitt Ittichaiwong, Nutchanon Yongsatianchot', 'link': 'https://arxiv.org/abs/2510.13586', 'abstract': 'The emergence of large language models (LLMs) has opened new opportunities for cre- ating dynamic non-player characters (NPCs) in gaming environments, enabling both func- tional task execution and persona-consistent dialogue generation. In this paper, we (Tu_Character_lab) report our participation in the Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 Round 2, which eval- uates agents across three tracks: task-oriented dialogue, context-aware dialogue, and their integration. Our approach combines two complementary strategies: (i) lightweight prompting techniques in the API track, including a Deflanderization prompting method to suppress excessive role-play and improve task fidelity, and (ii) fine-tuned large models in the GPU track, leveraging Qwen3-14B with supervisedfinetuning (SFT) and Low-Rank Adaptation(LoRA). Our best submissions ranked 2nd on Task 1, 2nd on Task 3 (API track), and 4th on Task 3 (GPU track).', 'abstract_zh': '大型语言模型的出现为在游戏环境中创建动态非玩家角色（NPC）开辟了新机遇，使其既能执行功能性任务，又能生成符合人设的对话。在本文中，Tu_Character_lab报道了我们参加Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 Round 2的情况，该挑战在三个赛道上评估了智能体：任务导向对话、上下文感知对话及其集成。我们的方法结合了两种互补策略：（i）API赛道中的轻量级提示技术，包括Deflander化提示方法以抑制过度角色模仿并提高任务真实性，和（ii）GPU赛道中微调的大规模模型，利用Qwen3-14B的有监督微调（SFT）和低秩适应（LoRA）技术。我们的最佳提交在Task 1中排名第二，在API赛道的Task 3中排名第二，在GPU赛道的Task 3中排名第四。', 'title_zh': '基于LLM的NPC中角色真实性与任务执行的平衡之道：游戏对话中的解防设计'}
{'arxiv_id': 'arXiv:2510.13561', 'title': 'OpenDerisk: An Industrial Framework for AI-Driven SRE, with Design, Implementation, and Case Studies', 'authors': 'Peng Di, Faqiang Chen, Xiao Bai, Hongjun Yang, Qingfeng Li, Ganglin Wei, Jian Mou, Feng Shi, Keting Chen, Peng Tang, Zhitao Shen, Zheng Li, Wenhui Shi, Junwei Guo, Hang Yu', 'link': 'https://arxiv.org/abs/2510.13561', 'abstract': 'The escalating complexity of modern software imposes an unsustainable operational burden on Site Reliability Engineering (SRE) teams, demanding AI-driven automation that can emulate expert diagnostic reasoning. Existing solutions, from traditional AI methods to general-purpose multi-agent systems, fall short: they either lack deep causal reasoning or are not tailored for the specialized, investigative workflows unique to SRE. To address this gap, we present OpenDerisk, a specialized, open-source multi-agent framework architected for SRE. OpenDerisk integrates a diagnostic-native collaboration model, a pluggable reasoning engine, a knowledge engine, and a standardized protocol (MCP) to enable specialist agents to collectively solve complex, multi-domain problems. Our comprehensive evaluation demonstrates that OpenDerisk significantly outperforms state-of-the-art baselines in both accuracy and efficiency. This effectiveness is validated by its large-scale production deployment at Ant Group, where it serves over 3,000 daily users across diverse scenarios, confirming its industrial-grade scalability and practical impact. OpenDerisk is open source and available at this https URL', 'abstract_zh': '现代软件日益增加的复杂性对 site reliability engineering (SRE) 团队施加了不可持续的操作负担，要求采用基于AI的自动化技术来模拟专家诊断推理。现有的解决方案，从传统的AI方法到通用的多代理系统，均未达标：它们要么缺乏深入的因果推理能力，要么未能针对SRE特有的调查性工作流程进行定制。为填补这一空白，我们提出了OpenDerisk，这是一个专为SRE设计的开源多代理框架。OpenDerisk集成了诊断本源的合作模型、可插拔的推理引擎、知识引擎以及标准化协议（MCP），以使专家代理能够共同解决复杂的跨域问题。我们的全面评估表明，OpenDerisk在准确性和效率方面显著优于现有的最先进的基准。这一效果在蚂蚁集团的大规模生产部署中得到了验证，该系统每天为3,000多名用户提供服务，涉及多种场景，证明了其工业级的可扩展性和实际影响。OpenDerisk开源，可访问： this https URL', 'title_zh': 'OpenDerisk：一种基于AI的运维框架的设计、实现与案例研究'}
{'arxiv_id': 'arXiv:2510.13557', 'title': 'Modeling Cultural Bias in Facial Expression Recognition with Adaptive Agents', 'authors': 'David Freire-Obregón, José Salas-Cáceres, Javier Lorenzo-Navarro, Oliverio J. Santana, Daniel Hernández-Sosa, Modesto Castrillón-Santana', 'link': 'https://arxiv.org/abs/2510.13557', 'abstract': 'Facial expression recognition (FER) must remain robust under both cultural variation and perceptually degraded visual conditions, yet most existing evaluations assume homogeneous data and high-quality imagery. We introduce an agent-based, streaming benchmark that reveals how cross-cultural composition and progressive blurring interact to shape face recognition robustness. Each agent operates in a frozen CLIP feature space with a lightweight residual adapter trained online at sigma=0 and fixed during testing. Agents move and interact on a 5x5 lattice, while the environment provides inputs with sigma-scheduled Gaussian blur. We examine monocultural populations (Western-only, Asian-only) and mixed environments with balanced (5/5) and imbalanced (8/2, 2/8) compositions, as well as different spatial contact structures. Results show clear asymmetric degradation curves between cultural groups: JAFFE (Asian) populations maintain higher performance at low blur but exhibit sharper drops at intermediate stages, whereas KDEF (Western) populations degrade more uniformly. Mixed populations exhibit intermediate patterns, with balanced mixtures mitigating early degradation, but imbalanced settings amplify majority-group weaknesses under high blur. These findings quantify how cultural composition and interaction structure influence the robustness of FER as perceptual conditions deteriorate.', 'abstract_zh': '基于代理的流媒体基准揭示了跨文化构成和渐进模糊交互如何塑造面部识别鲁棒性', 'title_zh': '基于适应性代理建模面部表情识别中的文化偏见'}
{'arxiv_id': 'arXiv:2510.13543', 'title': 'In-Browser LLM-Guided Fuzzing for Real-Time Prompt Injection Testing in Agentic AI Browsers', 'authors': 'Avihay Cohen', 'link': 'https://arxiv.org/abs/2510.13543', 'abstract': 'Large Language Model (LLM) based agents integrated into web browsers (often called agentic AI browsers) offer powerful automation of web tasks. However, they are vulnerable to indirect prompt injection attacks, where malicious instructions hidden in a webpage deceive the agent into unwanted actions. These attacks can bypass traditional web security boundaries, as the AI agent operates with the user privileges across sites. In this paper, we present a novel fuzzing framework that runs entirely in the browser and is guided by an LLM to automatically discover such prompt injection vulnerabilities in real time.', 'abstract_zh': '基于大规模语言模型（LLM）的网络浏览器代理（通常称为具身AI浏览器）能够实现网页任务的强大自动化。然而，它们容易受到间接提示注入攻击的影响，恶意指令潜藏在网页中，欺骗代理执行不必要的操作。这些攻击可以绕过传统的网页安全边界，因为AI代理以用户的特权跨站点运行。本文介绍了一个全新的浏览器内置 fuzzing 框架，该框架由LLM引导，可以实时自动发现此类提示注入漏洞。', 'title_zh': '基于浏览器的LLM引导模糊测试用于实时提示注入测试在自主AI浏览器中'}
{'arxiv_id': 'arXiv:2510.13537', 'title': 'K-Merge: Online Continual Merging of Adapters for On-device Large Language Models', 'authors': 'Donald Shenaj, Ondrej Bohdal, Taha Ceritli, Mete Ozay, Pietro Zanuttigh, Umberto Michieli', 'link': 'https://arxiv.org/abs/2510.13537', 'abstract': 'On-device deployment of Large Language Models (LLMs) frequently leverages Low-Rank Adapters (LoRAs) to support diverse downstream tasks under tight resource constraints. To address the limited storage capacity of mobile devices, recent works have explored model merging techniques to fuse multiple LoRAs into a single one. In practice, however, LoRAs are often delivered incrementally, as users request support for new tasks (e.g., novel problem types or languages). This scenario introduces a new challenge: on-device online continual merging, where the objective is to incorporate new LoRAs while preserving the performance on previously supported tasks. In this paper, we propose a data-free and computationally efficient strategy for selecting and merging LoRAs when a new one becomes available, assuming the device can store only a limited number of adapters. Extensive experiments across real-world tasks demonstrate the superiority of our approach compared to alternative strategies while adhering to the storage budget and compute limitations of on-device settings.', 'abstract_zh': '设备端部署大语言模型中的低秩适配器在线连续合并策略', 'title_zh': 'K-Merge: 在设备上大型语言模型的在线连续适应器合并方法'}
{'arxiv_id': 'arXiv:2510.13521', 'title': 'Narrow Operator Models of Stellarator Equilibria in Fourier Zernike Basis', 'authors': 'Timo Thun, Rory Conlin, Dario Panici, Daniel Böckenhoff', 'link': 'https://arxiv.org/abs/2510.13521', 'abstract': 'Numerical computation of the ideal Magnetohydrodynamic (MHD) equilibrium magnetic field is at the base of stellarator optimisation and provides the starting point for solving more sophisticated Partial Differential Equations (PDEs) like transport or turbulence models. Conventional approaches solve for a single stationary point of the ideal MHD equations, which is fully defined by three invariants and the numerical scheme employed by the solver. We present the first numerical approach that can solve for a continuous distribution of equilibria with fixed boundary and rotational transform, varying only the pressure invariant. This approach minimises the force residual by optimising parameters of multilayer perceptrons (MLP) that map from a scalar pressure multiplier to the Fourier Zernike basis as implemented in the modern stellarator equilibrium solver DESC.', 'abstract_zh': '理想的磁流体力学（MHD）平衡磁场的数值计算是优化 Stellarator 的基础，并为解决更复杂的偏微分方程（如输运或湍流模型）提供起点。传统方法求解理想 MHD 方程的单一稳态解，该解由三个不变量和求解器采用的数值方案完全定义。我们提出了第一个能够求解具有固定边界和旋转变换的连续平衡分布的方法，仅改变压力不变量。该方法通过优化多层感知器（MLP）参数来最小化力残差，这些参数将标量压力乘子映射到现代 Stellarator 平衡求解器 DESC 中实现的傅里叶 Zernike 基础。', 'title_zh': '狭义算子模型下的stellarator等离子体平衡的Fourier-Zernike基表示'}
{'arxiv_id': 'arXiv:2510.13515', 'title': 'UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning', 'authors': 'Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, Xiang An, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng, Lidong Bing', 'link': 'https://arxiv.org/abs/2510.13515', 'abstract': 'Universal multimodal embedding models are foundational to various tasks. Existing approaches typically employ in-batch negative mining by measuring the similarity of query-candidate pairs. However, these methods often struggle to capture subtle semantic differences among candidates and lack diversity in negative samples. Moreover, the embeddings exhibit limited discriminative ability in distinguishing false and hard negatives. In this paper, we leverage the advanced understanding capabilities of MLLMs to enhance representation learning and present a novel Universal Multimodal Embedding (UniME-V2) model. Our approach first constructs a potential hard negative set through global retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes MLLMs to assess the semantic alignment of query-candidate pairs and generate soft semantic matching scores. These scores serve as a foundation for hard negative mining, mitigating the impact of false negatives and enabling the identification of diverse, high-quality hard negatives. Furthermore, the semantic matching scores are used as soft labels to mitigate the rigid one-to-one mapping constraint. By aligning the similarity matrix with the soft semantic matching score matrix, the model learns semantic distinctions among candidates, significantly enhancing its discriminative capacity. To further improve performance, we propose UniME-V2-Reranker, a reranking model trained on our mined hard negatives through a joint pairwise and listwise optimization approach. We conduct comprehensive experiments on the MMEB benchmark and multiple retrieval tasks, demonstrating that our method achieves state-of-the-art performance on average across all tasks.', 'abstract_zh': '通用多模态嵌入模型是各种任务的基础。现有方法通常通过测量查询-候选对之间的相似性来抽取内批次负样本。然而，这些方法往往难以捕捉候选者之间的微妙语义差异，并且负样本缺乏多样性。此外，嵌入在区分虚假负样本和难负样本方面表现出有限的辨别能力。在本文中，我们利用大规模预训练语言模型的高级理解能力来增强表示学习，并提出了一种新型的通用多模态嵌入（UniME-V2）模型。我们的方法首先通过全局检索构建一个潜在的难负样本集。然后引入大规模语言模型作为裁判机制，利用大规模语言模型评估查询-候选对之间的语义对齐并生成软语义匹配得分。这些得分作为难负样本挖掘的基础，减轻了虚假负样本的影响，并能够识别多样化的高质量难负样本。此外，语义匹配得分作为软标签用于缓解刚性的一对一映射约束。通过将相似性矩阵与软语义匹配得分矩阵对齐，模型学习候选者之间的语义差异，显著增强了其辨别能力。为了进一步提高性能，我们提出了基于我们在挖掘难负样本时通过联合成对和列表优化方法训练的UniME-V2-Reranker重排序模型。我们对MMEB基准和多个检索任务进行了全面实验，表明我们的方法在所有任务上的平均表现达到了最先进的水平。', 'title_zh': 'UniME-V2: 作为通用多模态嵌入学习裁判的MLLM'}
{'arxiv_id': 'arXiv:2510.13512', 'title': 'Offline and Online KL-Regularized RLHF under Differential Privacy', 'authors': 'Yulian Wu, Rushil Thareja, Praneeth Vepakomma, Francesco Orabona', 'link': 'https://arxiv.org/abs/2510.13512', 'abstract': 'In this paper, we study the offline and online settings of reinforcement learning from human feedback (RLHF) with KL-regularization -- a widely used objective function in large language model alignment -- under the $\\epsilon$ local differential privacy ($\\epsilon$-LDP) model on the label of the human preference. In the offline setting, we design an algorithm based on the principle of pessimism and derive a new suboptimality gap of $\\tilde{O}(1/[(e^\\epsilon-1)^2 n])$ on the KL-regularized objective under single-policy concentrability. We also prove its optimality by providing a matching lower bound where $n$ is the sample size.\nIn the online setting, we are the first one to theoretically investigate the problem of KL-regularized RLHF with LDP. We design an optimism-based algorithm and derive a logarithmic regret bound of $O(d_{\\mathcal{F}}\\log (N_{\\mathcal{F}}\\cdot T) /(e^\\epsilon-1)^2 )$, where $T$ is the total time step, $N_{\\mathcal{F}}$ is cardinality of the reward function space $\\mathcal{F}$ and $d_{\\mathcal{F}}$ is a variant of eluder dimension for RLHF. As a by-product of our analysis, our results also imply the first analysis for online KL-regularized RLHF without privacy. We implement our algorithm in the offline setting to verify our theoretical results and release our open source code at: this https URL.', 'abstract_zh': '在$\\epsilon$局部差分隐私（$\\epsilon$-LDP）模型下的人类偏好标签下，具有KL-正则化的大语言模型对齐的离线和在线设置中的强化学习-from-人类反馈（RLHF）研究', 'title_zh': '离线和在线KL正则化RLHF下的差异隐私CloseOperation'}
{'arxiv_id': 'arXiv:2510.13500', 'title': 'MedREK: Retrieval-Based Editing for Medical LLMs with Key-Aware Prompts', 'authors': 'Shujun Xia, Haokun Lin, Yichen Wu, Yinan Zhou, Zixuan Li, Zhongwei Wan, Xingrun Xing, Yefeng Zheng, Xiang Li, Caifeng Shan, Zhenan Sun, Quanzheng Li', 'link': 'https://arxiv.org/abs/2510.13500', 'abstract': 'LLMs hold great promise for healthcare applications, but the rapid evolution of medical knowledge and errors in training data often cause them to generate outdated or inaccurate information, limiting their applicability in high-stakes clinical practice. Model editing has emerged as a potential remedy without full retraining. While parameter-based editing often compromises locality and is thus ill-suited for the medical domain, retrieval-based editing offers a more viable alternative. However, it still faces two critical challenges: (1) representation overlap within the medical knowledge space often causes inaccurate retrieval and reduces editing accuracy; (2) existing methods are restricted to single-sample edits, while batch-editing remains largely unexplored despite its importance for real-world medical applications. To address these challenges, we first construct MedVersa, \\hk{an enhanced benchmark with broader coverage of medical subjects, designed to evaluate both single and batch edits under strict locality constraints}. We then propose MedREK, a retrieval-based editing framework that integrates a shared query-key module for precise matching with an attention-based prompt encoder for informative guidance. Experimental results on various medical benchmarks demonstrate that our MedREK achieves superior performance across different core metrics and provides the first validated solution for batch-editing in medical LLMs. Our code and dataset are available at this https URL.', 'abstract_zh': 'LLMs在医疗应用中前景广阔，但快速演进的医学知识和训练数据中的错误常常导致它们生成过时或不准确的信息，限制了其在高风险临床实践中的应用。基于模型的编辑作为一种潜在的解决方案而出现，无需进行全面重新训练。虽然基于参数的编辑通常会牺牲局部性，因此不适于医疗领域，但基于检索的编辑提供了一个更可行的选择。然而，它仍然面临两个关键挑战：（1）医学知识空间内的表示重叠往往导致不准确的检索，降低了编辑的准确性；（2）现有的方法主要针对单样本编辑，而批量编辑在实际医疗应用中至关重要，但这一领域仍然鲜有探索。为应对这些挑战，我们首先构建了MedVersa，一种增强的基准测试，旨在在严格的局部性约束下评估单样本和批量编辑；然后，我们提出了MedREK，一种基于检索的编辑框架，该框架结合了共享查询-键模块以实现精确匹配，并采用基于注意力的提示编码器以提供信息指导。我们在多种医疗基准测试上的实验结果表明，我们的MedREK在不同核心指标上取得了优越的表现，并提供了首个批量编辑的验证解决方案。我们的代码和数据集可通过以下链接获取。', 'title_zh': 'MedREK: 基于检索的关键意识提示编辑医疗LLMs'}
{'arxiv_id': 'arXiv:2510.13499', 'title': 'ConsintBench: Evaluating Language Models on Real-World Consumer Intent Understanding', 'authors': 'Xiaozhe Li, TianYi Lyu, Siyi Yang, Yuxi Gong, Yizhao Yang, Jinxuan Huang, Ligao Zhang, Zhuoyi Huang, Qingwen Liu', 'link': 'https://arxiv.org/abs/2510.13499', 'abstract': 'Understanding human intent is a complex, high-level task for large language models (LLMs), requiring analytical reasoning, contextual interpretation, dynamic information aggregation, and decision-making under uncertainty. Real-world public discussions, such as consumer product discussions, are rarely linear or involve a single user. Instead, they are characterized by interwoven and often conflicting perspectives, divergent concerns, goals, emotional tendencies, as well as implicit assumptions and background knowledge about usage scenarios. To accurately understand such explicit public intent, an LLM must go beyond parsing individual sentences; it must integrate multi-source signals, reason over inconsistencies, and adapt to evolving discourse, similar to how experts in fields like politics, economics, or finance approach complex, uncertain environments. Despite the importance of this capability, no large-scale benchmark currently exists for evaluating LLMs on real-world human intent understanding, primarily due to the challenges of collecting real-world public discussion data and constructing a robust evaluation pipeline. To bridge this gap, we introduce \\bench, the first dynamic, live evaluation benchmark specifically designed for intent understanding, particularly in the consumer domain. \\bench is the largest and most diverse benchmark of its kind, supporting real-time updates while preventing data contamination through an automated curation pipeline.', 'abstract_zh': '理解人类意图是大型语言模型（LLMs）的一项复杂高阶任务，要求进行分析推理、情境诠释、动态信息聚合以及在不确定性下的决策制定。像消费者产品讨论这样的真实世界公共讨论通常不是线性的，也往往不仅仅涉及单一用户，而是由交织并且经常互相冲突的观点、分散的关注点、目标、情绪倾向以及关于使用场景的隐含假设和背景知识所界定。为了准确理解这种显性的公共意图，一个LLM必须超越仅仅解析单个句子，还必须整合多源信号、推理解决不一致之处，并适应不断演变的对话，类似于政治、经济学或金融领域的专家是如何应对复杂不确定环境的方式。尽管此项能力的重要性不言而喻，但目前尚无大规模基准可以评估LLMs在真实世界中的人类意图理解能力，主要原因在于收集真实世界公共讨论数据和构建健壮评估管道的挑战。为解决这一问题，我们引入了\\bench，这是首个专为意图理解设计的动态实时评估基准，特别适用于消费者领域。\\bench是此类中规模最大、多样性最高的基准，通过自动化策展管道支持实时更新并防止数据污染。', 'title_zh': 'ConsintBench: 评估语言模型在消费者意图理解中的现实世界表现'}
{'arxiv_id': 'arXiv:2510.13497', 'title': 'DistilCLIP-EEG: Enhancing Epileptic Seizure Detection Through Multi-modal Learning and Knowledge Distillation', 'authors': 'Zexin Wang, Lin Shi, Haoyu Wu, Junru Luo, Xiangzeng Kong, Jun Qi', 'link': 'https://arxiv.org/abs/2510.13497', 'abstract': "Epilepsy is a prevalent neurological disorder marked by sudden, brief episodes of excessive neuronal activity caused by abnormal electrical discharges, which may lead to some mental disorders. Most existing deep learning methods for epilepsy detection rely solely on unimodal EEG signals, neglecting the potential benefits of multimodal information. To address this, we propose a novel multimodal model, DistilCLIP-EEG, based on the CLIP framework, which integrates both EEG signals and text descriptions to capture comprehensive features of epileptic seizures. The model involves an EEG encoder based on the Conformer architecture as a text encoder, the proposed Learnable BERT (BERT-LP) as prompt learning within the encoders. Both operate in a shared latent space for effective cross-modal representation learning. To enhance efficiency and adaptability, we introduce a knowledge distillation method where the trained DistilCLIP-EEG serves as a teacher to guide a more compact student model to reduce training complexity and time. On the TUSZ, AUBMC, and CHB-MIT datasets, both the teacher and student models achieved accuracy rates exceeding 97%. Across all datasets, the F1-scores were consistently above 0.94, demonstrating the robustness and reliability of the proposed framework. Moreover, the student model's parameter count and model size are approximately 58.1% of those of the teacher model, significantly reducing model complexity and storage requirements while maintaining high performance. These results highlight the potential of our proposed model for EEG-based epilepsy detection and establish a solid foundation for deploying lightweight models in resource-constrained settings.", 'abstract_zh': '癫痫是一种常见的神经性疾病，由异常电活动引起突发短暂的神经元过度放电导致，可能导致一些精神障碍。现有的大多数深度学习方法仅依赖单模EEG信号进行癫痫检测，忽略了多模信息的优势。为了解决这个问题，我们提出了一种基于CLIP框架的新型多模态模型DistilCLIP-EEG，该模型结合EEG信号和文本描述以捕捉癫痫发作的综合特征。该模型采用基于Conformer架构的EEG编码器作为文本编码器，并提出一种可学习的BERT (BERT-LP) 进行编码器内的提示学习，两者共同作用于共享的潜在空间进行有效的跨模态表示学习。为了提高效率和适应性，我们引入了一种知识蒸馏方法，其中训练好的DistilCLIP-EEG作为教师模型指导一个更紧凑的学生模型以减少训练复杂性和时间。在TUSZ、AUBMC和CHB-MIT数据集上，教师模型和学生模型均实现了超过97%的准确率。各数据集上的一致性F1分数均高于0.94，证明了所提框架的稳健性和可靠性。此外，学生模型的参数量和模型大小约为教师模型的58.1%，显著降低了模型复杂性和存储要求，同时保持了高性能。这些结果突显了我们所提模型在基于EEG的癫痫检测中的潜力，并为在资源受限环境下部署轻量级模型奠定了坚实基础。', 'title_zh': 'DistilCLIP-EEG：通过多模态学习和知识蒸馏增强癫痫发作检测'}
{'arxiv_id': 'arXiv:2510.13494', 'title': 'LiteraryQA: Towards Effective Evaluation of Long-document Narrative QA', 'authors': 'Tommaso Bonomo, Luca Gioffré, Roberto Navigli', 'link': 'https://arxiv.org/abs/2510.13494', 'abstract': 'Question Answering (QA) on narrative text poses a unique challenge to current systems, requiring a deep understanding of long, complex documents. However, the reliability of NarrativeQA, the most widely used benchmark in this domain, is hindered by noisy documents and flawed QA pairs. In this work, we introduce LiteraryQA, a high-quality subset of NarrativeQA focused on literary works. Using a human- and LLM-validated pipeline, we identify and correct low-quality QA samples while removing extraneous text from source documents. We then carry out a meta-evaluation of automatic metrics to clarify how systems should be evaluated on LiteraryQA. This analysis reveals that all n-gram-based metrics have a low system-level correlation to human judgment, while LLM-as-a-Judge evaluations, even with small open-weight models, can strongly agree with the ranking identified by humans. Finally, we benchmark a set of long-context LLMs on LiteraryQA. We release our code and data at this https URL.', 'abstract_zh': '基于叙事文本的问答（QA）对当前系统构成独特的挑战，需要深入理解长篇复杂文档。然而，广泛用于这一领域的NarrativeQA基准因其嘈杂的文档和有缺陷的问答对而可靠性受到限制。在此项工作中，我们介绍了LiteraryQA，这是一个专注于文学作品的NarrativeQA高质量子集。通过结合人工和大语言模型验证的管道，我们识别并修正了低质量的问答样本，去除了源文档中的多余文本。然后，我们对自动评估指标进行了元评估，以澄清系统在处理LiteraryQA时的评估方式。此分析揭示了所有基于n-gram的指标在系统级与人工判断的相关性较低，而即使是小的预训练模型充当评估者时，它们在排名方面也能与人类的判断强烈一致。最后，我们在LiteraryQA上基准测试了一组长上下文的大语言模型。我们在此网址https://提供我们的代码和数据。', 'title_zh': '文学QA：朝着有效评价长文档叙事问答的方向努力'}
{'arxiv_id': 'arXiv:2510.13444', 'title': 'Neural Sum-of-Squares: Certifying the Nonnegativity of Polynomials with Transformers', 'authors': 'Nico Pelleriti, Christoph Spiegel, Shiwei Liu, David Martínez-Rubio, Max Zimmer, Sebastian Pokutta', 'link': 'https://arxiv.org/abs/2510.13444', 'abstract': 'Certifying nonnegativity of polynomials is a well-known NP-hard problem with direct applications spanning non-convex optimization, control, robotics, and beyond. A sufficient condition for nonnegativity is the Sum of Squares (SOS) property, i.e., it can be written as a sum of squares of other polynomials. In practice, however, certifying the SOS criterion remains computationally expensive and often involves solving a Semidefinite Program (SDP), whose dimensionality grows quadratically in the size of the monomial basis of the SOS expression; hence, various methods to reduce the size of the monomial basis have been proposed. In this work, we introduce the first learning-augmented algorithm to certify the SOS criterion. To this end, we train a Transformer model that predicts an almost-minimal monomial basis for a given polynomial, thereby drastically reducing the size of the corresponding SDP. Our overall methodology comprises three key components: efficient training dataset generation of over 100 million SOS polynomials, design and training of the corresponding Transformer architecture, and a systematic fallback mechanism to ensure correct termination, which we analyze theoretically. We validate our approach on over 200 benchmark datasets, achieving speedups of over $100\\times$ compared to state-of-the-art solvers and enabling the solution of instances where competing approaches fail. Our findings provide novel insights towards transforming the practical scalability of SOS programming.', 'abstract_zh': '认证多项式的非负性是直接应用于非凸优化、控制、机器人等领域的一个已知NP-hard问题。一种非负性的充分条件是稀疏多项式和（SOS性质），即它可以表示为其他多项式的平方和。然而，在实践中，认证SOS准则仍然计算复杂，通常需要求解二次规划维度增长的半定规划（SDP）问题；因此，已经提出了多种方法来减少SOS表达式的单项式基大小。在本工作中，我们首次提出了一个基于学习的算法来认证SOS准则。为此，我们训练了一个Transformer模型来预测给定多项式的几乎最小单项式基，从而大大减少了相应的SDP规模。我们的整体方法包含三个关键组件：生成超过1亿个SOS多项式的高效训练数据集、设计并训练相应的Transformer架构，以及一种系统性的后备机制以确保正确的终止，我们对其进行了理论分析。我们在超过200个基准数据集上验证了该方法，实现了比最先进的求解器快100倍以上的加速，并能够在竞争方法失败的情况下解决问题实例。我们的发现为转化SOS编程的实际可扩展性提供了新的见解。', 'title_zh': '神经平方和：使用变换器验证多项式的非负性'}
{'arxiv_id': 'arXiv:2510.13439', 'title': 'Rectify and Align GPS Points to Parking Spots via Rank-1 Constraint', 'authors': 'Jiaxing Deng, Junbiao Pang, Zhicheng Wang, Haitao Yu', 'link': 'https://arxiv.org/abs/2510.13439', 'abstract': 'Parking spots are essential components, providing vital mobile resources for residents in a city. Accurate Global Positioning System (GPS) points of parking spots are the core data for subsequent applications,e.g., parking management, parking policy, and urban development. However, high-rise buildings tend to cause GPS points to drift from the actual locations of parking spots; besides, the standard lower-cost GPS equipment itself has a certain location error. Therefore, it is a non-trivial task to correct a few wrong GPS points from a large number of parking spots in an unsupervised approach. In this paper, motivated by the physical constraints of parking spots (i.e., parking spots are parallel to the sides of roads), we propose an unsupervised low-rank method to effectively rectify errors in GPS points and further align them to the parking spots in a unified framework. The proposed unconventional rectification and alignment method is simple and yet effective for any type of GPS point errors. Extensive experiments demonstrate the superiority of the proposed method to solve a practical problem. The data set and the code are publicly accessible at:this https URL.', 'abstract_zh': '停车泊位是城市居民移动资源的重要组成部分，准确的全球定位系统(GPS)坐标是后续应用（如停车管理、停车政策和城市开发）的核心数据。然而，高层建筑物会导致GPS坐标点偏离实际的停车泊位位置，且标准的低成本GPS设备本身存在一定位置误差。因此，在无监督方法下，纠正大量停车泊位中的少量错误坐标点是一项非平凡的任务。受停车泊位物理约束（即停车泊位平行于道路两侧）的启发，本文提出了一种无监督低秩方法，以有效纠正GPS坐标点的错误，并在统一框架中进一步将它们对齐到停车泊位。提出的非传统校正和对齐方法简单有效，适用于任何类型的GPS坐标点错误。大量实验表明，所提出的方法在解决实际问题方面具有优势。数据集和代码可在以下网址公开访问：this https URL。', 'title_zh': '基于秩一约束的GPS点校正与对齐至停车位'}
{'arxiv_id': 'arXiv:2510.13408', 'title': 'Semantic Communication Enabled Holographic Video Processing and Transmission', 'authors': 'Jingkai Ying, Zhiyuan Qi, Yulong Feng, Zhijin Qin, Zhu Han, Rahim Tafazolli, Yonina C. Eldar', 'link': 'https://arxiv.org/abs/2510.13408', 'abstract': 'Holographic video communication is considered a paradigm shift in visual communications, becoming increasingly popular for its ability to offer immersive experiences. This article provides an overview of holographic video communication and outlines the requirements of a holographic video communication system. Particularly, following a brief review of semantic com- munication, an architecture for a semantic-enabled holographic video communication system is presented. Key technologies, including semantic sampling, joint semantic-channel coding, and semantic-aware transmission, are designed based on the proposed architecture. Two related use cases are presented to demonstrate the performance gain of the proposed methods. Finally, potential research topics are discussed to pave the way for the realization of semantic-enabled holographic video communications.', 'abstract_zh': '全息视频通信被视为视觉通信领域的 paradigm shift，因其能提供沉浸式体验而日益受欢迎。本文对全息视频通信进行了综述，并概述了全息视频通信系统的需求。特别是，在简要回顾语义通信后，提出了一个支持语义的全息视频通信系统的架构。基于该架构，设计了关键技术，包括语义采样、联合语义-信道编码和语义感知传输，并展示了两种相关应用场景以证明所提方法的性能增益。最后，讨论了潜在的研究方向以推动语义支持的全息视频通信的实现。', 'title_zh': '基于语义通信的全息视频处理与传输'}
{'arxiv_id': 'arXiv:2510.13400', 'title': 'From Minimal Existence to Human Definition: The CES-IMU-HSG Theoretical Framework', 'authors': 'Kei Itoh', 'link': 'https://arxiv.org/abs/2510.13400', 'abstract': "This study presents an inter-universal mathematical-logical framework constructed upon the minimal axiom Cogito, ergo sum (CES), integrating the Intermediate Meta-Universe (IMU) and the Hierarchical State Grid (HSG). The CES defines existence as a reflexive correspondence --'to be' and 'to be sayable'--and positions any formal system, including ZFC or HoTT, as an attachable extension atop this minimal structure. The IMU functions as a registry of axiomatic dependencies that connect heterogeneous theories, employing the Institution-theoretic framework to ensure coherent inter-theoretical linkages. The HSG concretizes these ideas through categorical construction, defined by three orthogonal axes: the state-depth axis, the mapping-hierarchy axis, and the temporal axis incorporating the principle of 'no future reference.' Through these, the identity of 'definition = state' is formally established as a categorical property. Extending this structure to biological systems, the neural system is implemented as a 0-3D complex of neuron-function fields on the HSG, while its categorical extensions via fiberization over the material base enable the parallel integration of multiple physiological universes-neural, endocrine, learning, genetic, and input/output systems-into a coherent adjoint ensemble. Within this framework, human behavior and cognition emerge as temporal compositions of inter-universal algorithms constrained by the material base. Finally, by contrasting human cognition, which relies on external CES, with machine existence, this study introduces the concept of internal CES, wherein a machine grounds its own logic upon the factuality of its operation. This internal self-axiomatization establishes a continuous bridge between philosophical ontology and engineering implementation, providing a new foundation for the autonomous and self-defining existence of artificial intelligence.", 'abstract_zh': '基于Cogito, ergo sum最小公理的跨宇宙数学逻辑框架：整合中间元宇宙与层次状态网格', 'title_zh': '从最小存在到人性定义：CES-IMU-HSG理论框架'}
{'arxiv_id': 'arXiv:2510.13371', 'title': 'MADREC: A Multi-Aspect Driven LLM Agent for Explainable and Adaptive Recommendation', 'authors': 'Jiin Park, Misuk Kim', 'link': 'https://arxiv.org/abs/2510.13371', 'abstract': 'Recent attempts to integrate large language models (LLMs) into recommender systems have gained momentum, but most remain limited to simple text generation or static prompt-based inference, failing to capture the complexity of user preferences and real-world interactions. This study proposes the Multi-Aspect Driven LLM Agent MADRec, an autonomous LLM-based recommender that constructs user and item profiles by unsupervised extraction of multi-aspect information from reviews and performs direct recommendation, sequential recommendation, and explanation generation. MADRec generates structured profiles via aspect-category-based summarization and applies Re-Ranking to construct high-density inputs. When the ground-truth item is missing from the output, the Self-Feedback mechanism dynamically adjusts the inference criteria. Experiments across multiple domains show that MADRec outperforms traditional and LLM-based baselines in both precision and explainability, with human evaluation further confirming the persuasiveness of the generated explanations.', 'abstract_zh': 'Recent Attempts to Integrate Large Language Models into Recommender Systems Have Gained Momentum, but Most Remain Limited to Simple Text Generation or Static Prompt-Based Inference, Failing to Capture the Complexity of User Preferences and Real-World Interactions: Proposing the Multi-Aspect Driven LLM Agent MADRec', 'title_zh': 'MADREC：一个多方面驱动的LLM代理，用于可解释和自适应推荐'}
{'arxiv_id': 'arXiv:2510.13367', 'title': 'A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control', 'authors': 'Nikita Kachaev, Daniil Zelezetsky, Egor Cherepanov, Alexey K. Kovelev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2510.13367', 'abstract': 'Despite their effectiveness and popularity in offline or model-based reinforcement learning (RL), transformers remain underexplored in online model-free RL due to their sensitivity to training setups and model design decisions such as how to structure the policy and value networks, share components, or handle temporal information. In this paper, we show that transformers can be strong baselines for continuous control in online model-free RL. We investigate key design questions: how to condition inputs, share components between actor and critic, and slice sequential data for training. Our experiments reveal stable architectural and training strategies enabling competitive performance across fully and partially observable tasks, and in both vector- and image-based settings. These findings offer practical guidance for applying transformers in online RL.', 'abstract_zh': '尽管变压器在离线或模型依赖的强化学习（RL）中表现出色且广受欢迎，但在在线模型自由的RL中仍受到探索不足，主要是由于其对训练设置和模型设计决策（如如何结构化策略和价值网络、共享组件或处理时间信息）的高度敏感性。本文展示了变压器可以作为在线模型自由RL中连续控制的有效基线。我们探讨了关键的设计问题：如何条件化输入、在演员和评论家之间共享组件以及在训练中切分序列数据。我们的实验揭示了稳定且有效的架构和训练策略，使其在完全可观测和部分可观测任务中以及向量和图像基设置中均能获得竞争力的性能。这些发现为在在线RL中应用变压器提供了实用指导。', 'title_zh': '在线连续控制中变换器的新视角'}
{'arxiv_id': 'arXiv:2510.13366', 'title': 'Document Intelligence in the Era of Large Language Models: A Survey', 'authors': 'Weishi Wang, Hengchang Hu, Zhijie Zhang, Zhaochen Li, Hongxin Shao, Daniel Dahlmeier', 'link': 'https://arxiv.org/abs/2510.13366', 'abstract': "Document AI (DAI) has emerged as a vital application area, and is significantly transformed by the advent of large language models (LLMs). While earlier approaches relied on encoder-decoder architectures, decoder-only LLMs have revolutionized DAI, bringing remarkable advancements in understanding and generation. This survey provides a comprehensive overview of DAI's evolution, highlighting current research attempts and future prospects of LLMs in this field. We explore key advancements and challenges in multimodal, multilingual, and retrieval-augmented DAI, while also suggesting future research directions, including agent-based approaches and document-specific foundation models. This paper aims to provide a structured analysis of the state-of-the-art in DAI and its implications for both academic and practical applications.", 'abstract_zh': '文档AI（DAI）已成为一个至关重要的应用领域，大型语言模型（LLMs）的出现对其进行了显著改造。虽然早期的方法依赖于编码器-解码器架构，但仅解码器的LLMs已彻底革新了DAI，带来了理解和生成能力的显著提升。本文综述了DAI的发展历程，强调了当前在该领域使用LLMs的研究尝试及其未来前景。我们探讨了多模态、多语言和检索增强的DAI的关键进展和挑战，并建议了基于代理的方法和文档特定的基础模型作为未来的研究方向。本文旨在提供DAI最新进展的结构化分析，并探讨其对学术和实际应用的意义。', 'title_zh': '大型语言模型时代的内容智能：一个综述'}
{'arxiv_id': 'arXiv:2510.13364', 'title': 'Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity', 'authors': 'MingZe Tang, Jubal Chandy Jacob', 'link': 'https://arxiv.org/abs/2510.13364', 'abstract': 'Recent Vision-Language Models (VLMs) enable zero-shot classification by aligning images and text in a shared space, a promising approach for data-scarce conditions. However, the influence of prompt design on recognizing visually similar categories, such as human postures, is not well understood. This study investigates how prompt specificity affects the zero-shot classification of sitting, standing, and walking/running on a small, 285-image COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2, and SigLip, were evaluated using a three-tiered prompt design that systematically increases linguistic detail. Our findings reveal a compelling, counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and OpenCLIP), the simplest, most basic prompts consistently achieve the best results. Adding descriptive detail significantly degrades performance for instance, MetaCLIP 2\'s multi-class accuracy drops from 68.8\\% to 55.1\\% a phenomenon we term "prompt overfitting". Conversely, the lower-performing SigLip model shows improved classification on ambiguous classes when given more descriptive, body-cue-based prompts.', 'abstract_zh': '近期的多模态视觉-语言模型通过在共享空间对齐图像和文本实现零样本分类，这是一种在数据稀缺条件下颇具前景的方法。然而，提示设计对识别视觉相似类别（如人体姿态）的影响尚未得到充分理解。本研究探讨了提示特异性对一个小规模、包含285张图片的COCO衍生数据集上坐着、站立和行走/跑步的零样本分类的影响。评估了包括OpenCLIP、MetaCLIP 2和SigLip在内的多种现代多模态视觉-语言模型，使用了三级提示设计，逐步增加了语言细节。研究发现，对于表现最佳的模型（MetaCLIP 2和OpenCLIP），最简单、最基本的提示始终能取得最佳效果。添加描述性细节显著降低了性能，例如，MetaCLIP 2的多类别准确率从68.8%下降到55.1%，我们称之为“提示过拟合”。相反，表现较差的SigLip模型在获得更多描述性和基于身体提示时，对模糊类别分类能力有所提升。', 'title_zh': '语言作为一种标签：在数据稀缺条件下实现日常姿态的零样本多模态分类'}
{'arxiv_id': 'arXiv:2510.13361', 'title': 'Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training', 'authors': 'Yisen Wang, Yichuan Mo, Hongjun Wang, Junyi Li, Zhouchen Lin', 'link': 'https://arxiv.org/abs/2510.13361', 'abstract': 'Despite the rapid progress of neural networks, they remain highly vulnerable to adversarial examples, for which adversarial training (AT) is currently the most effective defense. While AT has been extensively studied, its practical applications expose two major limitations: natural accuracy tends to degrade significantly compared with standard training, and robustness does not transfer well across attacks crafted under different norm constraints. Unlike prior works that attempt to address only one issue within a single network, we propose to partition the overall generalization goal into multiple sub-tasks, each assigned to a dedicated base learner. By specializing in its designated objective, each base learner quickly becomes an expert in its field. In the later stages of training, we interpolate their parameters to form a knowledgeable global learner, while periodically redistributing the global parameters back to the base learners to prevent their optimization trajectories from drifting too far from the shared target. We term this framework Generalist and introduce three variants tailored to different application scenarios. Both theoretical analysis and extensive experiments demonstrate that Generalist achieves lower generalization error and significantly alleviates the trade-off problems compared with baseline methods. Our results suggest that Generalist provides a promising step toward developing fully robust classifiers in the future.', 'abstract_zh': '尽管神经网络取得了快速进展，它们仍然高度易受对抗样本的影响，目前最优的防御方法是对抗训练（AT）。尽管AT已经被广泛研究，其在实际应用中暴露出两大主要局限性：自然准确率较标准训练显著下降，鲁棒性在不同范数约束下的攻击中不能很好地转移。不同于之前只专注于解决单一问题的工作，我们提议将整体泛化目标拆分为多个子任务，每个子任务分配给一个专用的基础学习器。通过专门专注于其指定目标，每个基础学习器会迅速成为该领域的专家。在训练的后期，我们通过插值其参数形成一个知识丰富的全局学习器，并定期将全局参数重新分配给基础学习器以防止它们的优化轨迹偏移共享目标太远。我们称这一框架为通用主义，并提出了三种针对不同应用场景的变体。理论分析和大量实验表明，通用主义在降低泛化误差和显著缓解基线方法中的权衡问题方面表现更优。我们的结果表明，通用主义为未来开发完全鲁棒的分类器提供了有前途的步骤。', 'title_zh': 'Generalist++：减轻对抗训练权衡的元学习框架'}
{'arxiv_id': 'arXiv:2510.13358', 'title': 'Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control', 'authors': 'Shingo Ayabe, Hiroshi Kera, Kazuhiko Kawamoto', 'link': 'https://arxiv.org/abs/2510.13358', 'abstract': 'Offline reinforcement learning enables sample-efficient policy acquisition without risky online interaction, yet policies trained on static datasets remain brittle under action-space perturbations such as actuator faults. This study introduces an offline-to-online framework that trains policies on clean data and then performs adversarial fine-tuning, where perturbations are injected into executed actions to induce compensatory behavior and improve resilience. A performance-aware curriculum further adjusts the perturbation probability during training via an exponential-moving-average signal, balancing robustness and stability throughout the learning process. Experiments on continuous-control locomotion tasks demonstrate that the proposed method consistently improves robustness over offline-only baselines and converges faster than training from scratch. Matching the fine-tuning and evaluation conditions yields the strongest robustness to action-space perturbations, while the adaptive curriculum strategy mitigates the degradation of nominal performance observed with the linear curriculum strategy. Overall, the results show that adversarial fine-tuning enables adaptive and robust control under uncertain environments, bridging the gap between offline efficiency and online adaptability.', 'abstract_zh': '离线强化学习使得在无需风险在线交互的情况下获得样本高效策略成为可能，但基于静态数据集训练的策略在动作空间扰动如执行器故障的情况下依然脆弱。本研究提出了一种离线到在线框架，该框架在清洁数据上训练策略，然后进行对抗性微调，通过在执行的动作中注入扰动以诱导补偿行为并提高鲁棒性。一种基于指数移动平均信号的性能感知课程进一步在训练过程中调整扰动概率，平衡学习过程中的鲁棒性和稳定性。实验结果表明，所提出的方法在连续控制运动任务中比仅基于离线的方法更具鲁棒性，并且比从头开始训练更快地收敛。使微调和评估条件匹配能最大程度地提高对动作空间扰动的鲁棒性，而自适应课程策略则减轻了与线性课程策略相比观察到的标准性能退化。总体而言，结果表明对抗性微调能够在不确定环境中实现自适应和稳健的控制，弥合了离线效率和在线适应性之间的差距。', 'title_zh': '离线到在线强化学习中的对抗微调在鲁棒机器人控制中的应用'}
{'arxiv_id': 'arXiv:2510.13357', 'title': 'Personal Attribute Leakage in Federated Speech Models', 'authors': 'Hamdan Al-Ali, Ali Reza Ghavamipour, Tommaso Caselli, Fatih Turkmen, Zeerak Talat, Hanan Aldarmaki', 'link': 'https://arxiv.org/abs/2510.13357', 'abstract': 'Federated learning is a common method for privacy-preserving training of machine learning models. In this paper, we analyze the vulnerability of ASR models to attribute inference attacks in the federated setting. We test a non-parametric white-box attack method under a passive threat model on three ASR models: Wav2Vec2, HuBERT, and Whisper. The attack operates solely on weight differentials without access to raw speech from target speakers. We demonstrate attack feasibility on sensitive demographic and clinical attributes: gender, age, accent, emotion, and dysarthria. Our findings indicate that attributes that are underrepresented or absent in the pre-training data are more vulnerable to such inference attacks. In particular, information about accents can be reliably inferred from all models. Our findings expose previously undocumented vulnerabilities in federated ASR models and offer insights towards improved security.', 'abstract_zh': '联邦学习是一种常见的隐私保护的机器学习模型训练方法。在本文中，我们分析了联邦设置中ASR模型对抗属性推断攻击的脆弱性。我们在非参数白盒攻击方法下，对三种ASR模型（Wav2Vec2、HuBERT和Whisper）进行了测试，在被动威胁模型下，攻击仅基于权重差异进行，不访问目标讲话者的原始语音。我们在敏感的-demographic和临床属性：性别、年龄、口音、情绪和构音障碍上展示了攻击的可行性。我们的研究发现，在预训练数据中欠表示或不存在的属性更容易受到此类推断攻击。特别是，所有模型中有关口音的信息可以可靠地推断出来。我们的研究揭示了联邦ASR模型中以前未记录的漏洞，并为提高安全性提供了见解。', 'title_zh': '联邦语音模型中的个人属性泄露'}
{'arxiv_id': 'arXiv:2510.13351', 'title': 'Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems', 'authors': 'Karthik Avinash, Nikhil Pareek, Rishav Hada', 'link': 'https://arxiv.org/abs/2510.13351', 'abstract': 'The increasing deployment of Large Language Models (LLMs) across enterprise and mission-critical domains has underscored the urgent need for robust guardrailing systems that ensure safety, reliability, and compliance. Existing solutions often struggle with real-time oversight, multi-modal data handling, and explainability -- limitations that hinder their adoption in regulated environments. Existing guardrails largely operate in isolation, focused on text alone making them inadequate for multi-modal, production-scale environments. We introduce Protect, natively multi-modal guardrailing model designed to operate seamlessly across text, image, and audio inputs, designed for enterprise-grade deployment. Protect integrates fine-tuned, category-specific adapters trained via Low-Rank Adaptation (LoRA) on an extensive, multi-modal dataset covering four safety dimensions: toxicity, sexism, data privacy, and prompt injection. Our teacher-assisted annotation pipeline leverages reasoning and explanation traces to generate high-fidelity, context-aware labels across modalities. Experimental results demonstrate state-of-the-art performance across all safety dimensions, surpassing existing open and proprietary models such as WildGuard, LlamaGuard-4, and GPT-4.1. Protect establishes a strong foundation for trustworthy, auditable, and production-ready safety systems capable of operating across text, image, and audio modalities.', 'abstract_zh': '大型语言模型在企业级和关键任务领域中的广泛应用凸显了建立 robust 安全监管系统的迫切需求，以确保安全、可靠性和合规性。现有解决方案在实时监控、多模态数据处理和解释性方面存在局限性，这些局限性阻碍了其在受监管环境中的应用。现有监管措施主要独立运行，专注于文本数据，使其无法适应多模态的生产规模环境。我们提出了 Protect，一种原生多模态监管模型，旨在无缝处理文本、图像和音频输入，适用于企业级部署。Protect 结合了通过低秩适应（LoRA）在涵盖四大安全维度（毒性、性别歧视、数据隐私和提示注入）的多模态数据集上进行微调的专业化适配器，其教师辅助注释管道利用推理和解释轨迹生成高保真、上下文相关的跨模态标签。实验结果表明，Protect 在所有安全维度上均表现卓越，超越了现有开源和专有模型（如 WildGuard、LlamaGuard-4 和 GPT-4.1）。Protect 为跨文本、图像和音频模态运行的信任、可审计和生产级安全系统奠定了坚实基础。', 'title_zh': 'Protect: 向 Towards 坚实的企业级LLM系统可信运行防护栈迈进 Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems'}
{'arxiv_id': 'arXiv:2510.13343', 'title': "AOAD-MAT: Transformer-based multi-agent deep reinforcement learning model considering agents' order of action decisions", 'authors': 'Shota Takayama, Katsuhide Fujita', 'link': 'https://arxiv.org/abs/2510.13343', 'abstract': 'Multi-agent reinforcement learning focuses on training the behaviors of multiple learning agents that coexist in a shared environment. Recently, MARL models, such as the Multi-Agent Transformer (MAT) and ACtion dEpendent deep Q-learning (ACE), have significantly improved performance by leveraging sequential decision-making processes. Although these models can enhance performance, they do not explicitly consider the importance of the order in which agents make decisions. In this paper, we propose an Agent Order of Action Decisions-MAT (AOAD-MAT), a novel MAT model that considers the order in which agents make decisions. The proposed model explicitly incorporates the sequence of action decisions into the learning process, allowing the model to learn and predict the optimal order of agent actions. The AOAD-MAT model leverages a Transformer-based actor-critic architecture that dynamically adjusts the sequence of agent actions. To achieve this, we introduce a novel MARL architecture that cooperates with a subtask focused on predicting the next agent to act, integrated into a Proximal Policy Optimization based loss function to synergistically maximize the advantage of the sequential decision-making. The proposed method was validated through extensive experiments on the StarCraft Multi-Agent Challenge and Multi-Agent MuJoCo benchmarks. The experimental results show that the proposed AOAD-MAT model outperforms existing MAT and other baseline models, demonstrating the effectiveness of adjusting the AOAD order in MARL.', 'abstract_zh': '多智能体强化学习专注于训练多个共存于共享环境中的学习智能体的行为。近年来，借助序列决策过程，如多智能体变压器（MAT）和基于动作相关的深度Q学习（ACE）等MARL模型显著提升了性能。尽管这些模型能够增强性能，但它们并未明确考虑到智能体决策顺序的重要性。本文提出了一种考虑智能体决策顺序的多智能体强化学习模型——行动决策智能体顺序多智能体变压器（AOAD-MAT），这是一种新颖的MAT模型。该模型明确地将行动决策的顺序纳入学习过程中，从而使模型能够学习并预测最优的智能体行动顺序。AOAD-MAT模型利用基于Transformer的演员-评论家架构，动态调整智能体行动序列。为此，本文提出了一个与预测下一个行动智能体的子任务协同工作的新颖MARL架构，并将其整合进基于近端策略优化的损失函数中，以最大化序列决策的优势。通过在StarCraft多智能体挑战和多智能体MuJoCo基准上的广泛实验对所提出的方法进行了验证，实验结果表明，提出的AOAD-MAT模型优于现有的MAT模型和其他基线模型，证明了在MARL中调整AOAD顺序的有效性。', 'title_zh': 'AOAD-MAT：基于变压器的多智能体深度强化学习模型，考虑动作决策顺序问题'}
{'arxiv_id': 'arXiv:2510.13328', 'title': 'Thompson Sampling via Fine-Tuning of LLMs', 'authors': 'Nicolas Menet, Aleksandar Terzić, Andreas Krause, Abbas Rahimi', 'link': 'https://arxiv.org/abs/2510.13328', 'abstract': 'Bayesian optimization in large unstructured discrete spaces is often hindered by the computational cost of maximizing acquisition functions due to the absence of gradients. We propose a scalable alternative based on Thompson sampling that eliminates the need for acquisition function maximization by directly parameterizing the probability that a candidate yields the maximum reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the prior knowledge embedded in prompt-conditioned large language models, and incrementally adapts them toward the posterior. Theoretically, we derive a novel regret bound for a variational formulation of Thompson Sampling that matches the strong guarantees of its standard counterpart. Our analysis reveals the critical role of careful adaptation to the posterior probability of maximality--a principle that underpins our ToSFiT algorithm. Empirically, we validate our method on three diverse tasks: FAQ response refinement, thermally stable protein search, and quantum circuit design. We demonstrate that online fine-tuning significantly improves sample efficiency, with negligible impact on computational efficiency.', 'abstract_zh': '基于Thomas采样的大规模无序离散空间贝叶斯优化：无需最大化获取函数的可扩展替代方法', 'title_zh': '基于LLM微调的Thompson采样方法'}
{'arxiv_id': 'arXiv:2510.13322', 'title': 'Injection, Attack and Erasure: Revocable Backdoor Attacks via Machine Unlearning', 'authors': 'Baogang Song, Dongdong Zhao, Jianwen Xiang, Qiben Xu, Zizhuo Yu', 'link': 'https://arxiv.org/abs/2510.13322', 'abstract': 'Backdoor attacks pose a persistent security risk to deep neural networks (DNNs) due to their stealth and durability. While recent research has explored leveraging model unlearning mechanisms to enhance backdoor concealment, existing attack strategies still leave persistent traces that may be detected through static analysis. In this work, we introduce the first paradigm of revocable backdoor attacks, where the backdoor can be proactively and thoroughly removed after the attack objective is achieved. We formulate the trigger optimization in revocable backdoor attacks as a bilevel optimization problem: by simulating both backdoor injection and unlearning processes, the trigger generator is optimized to achieve a high attack success rate (ASR) while ensuring that the backdoor can be easily erased through unlearning. To mitigate the optimization conflict between injection and removal objectives, we employ a deterministic partition of poisoning and unlearning samples to reduce sampling-induced variance, and further apply the Projected Conflicting Gradient (PCGrad) technique to resolve the remaining gradient conflicts. Experiments on CIFAR-10 and ImageNet demonstrate that our method maintains ASR comparable to state-of-the-art backdoor attacks, while enabling effective removal of backdoor behavior after unlearning. This work opens a new direction for backdoor attack research and presents new challenges for the security of machine learning systems.', 'abstract_zh': '可撤销后门攻击：一种新的后门攻击范式及其应用', 'title_zh': '注入、攻击与擦除：通过机器遗忘实现可撤销后门攻击'}
{'arxiv_id': 'arXiv:2510.13315', 'title': 'Self-Augmented Visual Contrastive Decoding', 'authors': 'Eun Woo Im, Muhammad Kashif Ali, Vivek Gupta', 'link': 'https://arxiv.org/abs/2510.13315', 'abstract': 'Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal capabilities, but they inherit the tendency to hallucinate from their underlying language models. While visual contrastive decoding has been proposed to mitigate this issue, existing methods often apply generic visual augmentations that disregard the specific context provided by the text query, limiting their effectiveness. This study introduces a novel training-free decoding strategy that addresses these limitations, featuring two key contributions. First, a self-augmentation prompting strategy that leverages the intrinsic knowledge of the model to dynamically align semantics between the query and the visual augmentation. Second, an adaptive thresholding algorithm that adaptively adjusts next token candidate size based on the output sparsity, utilizing full information from the logit distribution. Extensive experiments across four LVLMs and seven benchmarks demonstrate that the proposed decoding significantly enhances factual consistency compared to state-of-the-art decoding methods. This work highlights the importance of integrating query-dependent augmentation and entropy-aware decoding for improving effective generation of LVLMs.', 'abstract_zh': 'Large Vision-Language Models (LVLMs)展示了显著的跨模态能力，但它们继承了底层语言模型的虚构倾向。虽然已经提出了视觉对比解码来缓解这一问题，但现有方法往往使用不考虑文本查询提供特定上下文的通用视觉增强，限制了其有效性。本研究介绍了一种新的无需训练的解码策略，以解决这些局限性，主要包括两大贡献。首先，一种自增强提示策略，利用模型的内在知识动态对齐查询和视觉增强之间的语义。其次，一种自适应阈值算法，根据输出稀疏性自适应调整候选下一个词的大小，利用logit分布中的全部信息。在四个LVLM和七个基准上的广泛实验表明，所提出的解码显著提高了事实一致性，优于当前最先进的解码方法。本工作强调了结合查询依赖增强和熵思维解码对于提高LVLM有效生成的重要性。', 'title_zh': '自我增强视觉对比解码'}
{'arxiv_id': 'arXiv:2510.13302', 'title': 'LLM one-shot style transfer for Authorship Attribution and Verification', 'authors': 'Pablo Miralles-González, Javier Huertas-Tato, Alejandro Martín, David Camacho', 'link': 'https://arxiv.org/abs/2510.13302', 'abstract': 'Computational stylometry analyzes writing style through quantitative patterns in text, supporting applications from forensic tasks such as identity linking and plagiarism detection to literary attribution in the humanities. Supervised and contrastive approaches rely on data with spurious correlations and often confuse style with topic. Despite their natural use in AI-generated text detection, the CLM pre-training of modern LLMs has been scarcely leveraged for general authorship problems. We propose a novel unsupervised approach based on this extensive pre-training and the in-context learning capabilities of LLMs, employing the log-probabilities of an LLM to measure style transferability from one text to another. Our method significantly outperforms LLM prompting approaches of comparable scale and achieves higher accuracy than contrastively trained baselines when controlling for topical correlations. Moreover, performance scales fairly consistently with the size of the base model and, in the case of authorship verification, with an additional mechanism that increases test-time computation; enabling flexible trade-offs between computational cost and accuracy.', 'abstract_zh': '基于大规模预训练和上下文学习能力的无监督计算文体学方法', 'title_zh': 'LLM 一键式风格转换在作者归类与验证中的应用'}
{'arxiv_id': 'arXiv:2510.13291', 'title': "Higher Satisfaction, Lower Cost: A Technical Report on How LLMs Revolutionize Meituan's Intelligent Interaction Systems", 'authors': 'Xuxin Cheng, Ke Zeng, Zhiquan Cao, Linyi Dai, Wenxuan Gao, Fei Han, Ai Jian, Feng Hong, Wenxing Hu, Zihe Huang, Dejian Kong, Jia Leng, Zhuoyuan Liao, Pei Liu, Jiaye Lin, Xing Ma, Jingqing Ruan, Jiaxing Song, Xiaoyu Tan, Ruixuan Xiao, Wenhui Yu, Wenyu Zhan, Haoxing Zhang, Chao Zhou, Hao Zhou, Shaodong Zheng, Ruinian Chen, Siyuan Chen, Ziyang Chen, Yiwen Dong, Yaoyou Fan, Yangyi Fang, Yang Gan, Shiguang Guo, Qi He, Chaowen Hu, Binghui Li, Dailin Li, Xiangyu Li, Yan Li, Chengjian Liu, Xiangfeng Liu, Jiahui Lv, Qiao Ma, Jiang Pan, Cong Qin, Chenxing Sun, Wen Sun, Zhonghui Wang, Abudukelimu Wuerkaixi, Xin Yang, Fangyi Yuan, Yawen Zhu, Tianyi Zhai, Jie Zhang, Runlai Zhang, Yao Xu, Yiran Zhao, Yifan Wang, Xunliang Cai, Yangen Hu, Cao Liu, Lu Pan, Xiaoli Wang, Bo Xiao, Wenyuan Yao, Qianlin Zhou, Benchang Zhu', 'link': 'https://arxiv.org/abs/2510.13291', 'abstract': 'Enhancing customer experience is essential for business success, particularly as service demands grow in scale and complexity. Generative artificial intelligence and Large Language Models (LLMs) have empowered intelligent interaction systems to deliver efficient, personalized, and 24/7 support. In practice, intelligent interaction systems encounter several challenges: (1) Constructing high-quality data for cold-start training is difficult, hindering self-evolution and raising labor costs. (2) Multi-turn dialogue performance remains suboptimal due to inadequate intent understanding, rule compliance, and solution extraction. (3) Frequent evolution of business rules affects system operability and transferability, constraining low-cost expansion and adaptability. (4) Reliance on a single LLM is insufficient in complex scenarios, where the absence of multi-agent frameworks and effective collaboration undermines process completeness and service quality. (5) The open-domain nature of multi-turn dialogues, lacking unified golden answers, hampers quantitative evaluation and continuous optimization. To address these challenges, we introduce WOWService, an intelligent interaction system tailored for industrial applications. With the integration of LLMs and multi-agent architectures, WOWService enables autonomous task management and collaborative problem-solving. Specifically, WOWService focuses on core modules including data construction, general capability enhancement, business scenario adaptation, multi-agent coordination, and automated evaluation. Currently, WOWService is deployed on the Meituan App, achieving significant gains in key metrics, e.g., User Satisfaction Metric 1 (USM 1) -27.53% and User Satisfaction Metric 2 (USM 2) +25.51%, demonstrating its effectiveness in capturing user needs and advancing personalized service.', 'abstract_zh': '提升客户体验对于商业成功至关重要，尤其是在服务需求规模和复杂性增长的情况下。生成式人工智能和大型语言模型（LLMs）赋能智能交互系统，提供高效、个性化和不间断的支持。实践中，智能交互系统面临多重挑战：（1）冷启动训练高质量数据构建困难，阻碍自我进化并增加劳动力成本。（2）多轮对话表现仍不理想，由于意图理解不足、规则合规性和解决方案提取不够。（3）业务规则的频繁更新影响系统操作性和可移植性，限制低成本扩展和适应性。（4）单一LLM在复杂场景中不足，缺乏多代理框架和有效协作损害流程完整性和服务质量。（5）多轮对话的开放领域特性缺乏统一标准答案，阻碍定量评估和持续优化。为应对这些挑战，我们提出了WOwService，一种针对工业应用的智能交互系统。通过集成LLMs和多代理架构，WOwService实现了自主任务管理和协作问题解决。具体而言，WOwService专注于数据构建、通用能力提升、业务场景适配、多代理协调和自动化评估等核心模块。目前，WOwService已在美团App上线，关键指标显著提升，例如用户满意度指标1（USM 1）减少了27.53%，用户满意度指标2（USM 2）增加了25.51%，展示了其在捕捉用户需求和推动个性化服务方面的有效性。', 'title_zh': '更高的满意度，更低的成本：一项关于LLM如何革命化美团智能交互系统的技术报告'}
{'arxiv_id': 'arXiv:2510.13290', 'title': 'To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models', 'authors': 'Anna Hedström, Salim I. Amoukou, Tom Bewley, Saumitra Mishra, Manuela Veloso', 'link': 'https://arxiv.org/abs/2510.13290', 'abstract': 'We introduce Mechanistic Error Reduction with Abstention (MERA), a principled framework for steering language models (LMs) to mitigate errors through selective, adaptive interventions. Unlike existing methods that rely on fixed, manually tuned steering strengths, often resulting in under or oversteering, MERA addresses these limitations by (i) optimising the intervention direction, and (ii) calibrating when, and how much to steer, thereby provably improving performance or abstaining when no confident correction is possible. Experiments across diverse datasets, and LM families demonstrate safe, effective, non-degrading error correction, and that MERA outperforms existing baselines. Moreover, MERA can be applied on top of existing steering techniques to further enhance their performance, establishing it as a general-purpose, and efficient approach to mechanistic activation steering.', 'abstract_zh': '机制错误减少与回避：一种原理上正确的语言模型引导框架', 'title_zh': '要不要干预？语言模型的 abstention 机制错误减少'}
{'arxiv_id': 'arXiv:2510.13261', 'title': 'A Ratio-Based Shapley Value for Collaborative Machine Learning - Extended Version', 'authors': 'Björn Filter, Ralf Möller, Özgür Lütfü Özçep', 'link': 'https://arxiv.org/abs/2510.13261', 'abstract': "Collaborative machine learning enables multiple data owners to jointly train models for improved predictive performance. However, ensuring incentive compatibility and fair contribution-based rewards remains a critical challenge. Prior work by Sim and colleagues (Rachel Hwee Ling Sim et al: Collaborative machine learning with incentive-aware model rewards. In: International conference on machine learning. PMLR. 2020, pp. 8927-8963) addressed this by allocating model rewards, which are non-monetary and freely replicable, based on the Shapley value of each party's data contribution, measured via information gain. In this paper, we introduce a ratio-based Shapley value that replaces the standard additive formulation with a relative contribution measure. While our overall reward framework, including the incentive definitions and model-reward setting, remains aligned with that of Sim and colleagues, the underlying value function is fundamentally different. Our alternative valuation induces a different distribution of model rewards and offers a new lens through which to analyze incentive properties. We formally define the ratio-based value and prove that it satisfies the same set of incentive conditions as the additive formulation, including adapted versions of fairness, individual rationality, and stability. Like the original approach, our method faces the same fundamental trade-offs between these incentives. Our contribution is a mathematically grounded alternative to the additive Shapley framework, potentially better suited to contexts where proportionality among contributors is more meaningful than additive differences.", 'abstract_zh': '合作机器学习使得多个数据所有者能够联合训练模型以提高预测性能。然而，确保激励相容性和基于贡献的公平奖励仍然是一个关键挑战。Sim及其同事（Rachel Hwee Ling Sim等：具有激励感知模型奖励的合作机器学习。在：国际机器学习会议。PMLR。2020，页码8927-8963）通过根据每个方数据贡献的Shapley值（通过信息增益衡量）分配非 monetary且可自由复制的模型奖励来解决这一问题。在本文中，我们引入了一种基于比率的Shapley值，用相对贡献测量替换标准的加性公式。虽然我们的总体奖励框架，包括激励定义和模型奖励设置，与Sim及其同事的工作保持一致，但底层价值函数本质上是不同的。我们的替代评估诱发了模型奖励的不同分配，并提供了一个新的角度来分析激励性质。我们正式定义了基于比率的价值，并证明它满足与加性公式相同的激励条件，包括公平性、个体理性以及稳定性等适应版本。与原始方法一样，我们的方法同样面临着这些激励之间的基本权衡。我们的贡献是一种数学上坚实的替代加性Shapley框架，可能更适合那些在贡献者间比例性比加性差异更为重要的情境。', 'title_zh': '基于比率的Shapley值在协作机器学习中的应用 - 扩展版'}
{'arxiv_id': 'arXiv:2510.13250', 'title': 'Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture', 'authors': 'Zhiyuan Zhao, Yubin Wen, Siyu Yang, Lichen Ning, Yuandong Liu, Junyu Gao', 'link': 'https://arxiv.org/abs/2510.13250', 'abstract': 'Crowd counting is a task of estimating the number of the crowd through images, which is extremely valuable in the fields of intelligent security, urban planning, public safety management, and so on. However, the existing counting methods have some problems in practical application on embedded systems for these fields, such as excessive model parameters, abundant complex calculations, etc. The practical application of embedded systems requires the model to be real-time, which means that the model is fast enough. Considering the aforementioned problems, we design a super real-time model with a stem-encoder-decoder structure for crowd counting tasks, which achieves the fastest inference compared with state-of-the-arts. Firstly, large convolution kernels in the stem network are used to enlarge the receptive field, which effectively extracts detailed head information. Then, in the encoder part, we use conditional channel weighting and multi-branch local fusion block to merge multi-scale features with low computational consumption. This part is crucial to the super real-time performance of the model. Finally, the feature pyramid networks are added to the top of the encoder to alleviate its incomplete fusion problems. Experiments on three benchmarks show that our network is suitable for super real-time crowd counting on embedded systems, ensuring competitive accuracy. At the same time, the proposed network reasoning speed is the fastest. Specifically, the proposed network achieves 381.7 FPS on NVIDIA GTX 1080Ti and 71.9 FPS on NVIDIA Jetson TX1.', 'abstract_zh': '基于茎编码解码结构的超实时 crowd counting 模型', 'title_zh': '面向嵌入式系统的轻量级架构实时人群计数'}
{'arxiv_id': 'arXiv:2510.13244', 'title': 'MotionBeat: Motion-Aligned Music Representation via Embodied Contrastive Learning and Bar-Equivariant Contact-Aware Encoding', 'authors': 'Xuanchen Wang, Heng Wang, Weidong Cai', 'link': 'https://arxiv.org/abs/2510.13244', 'abstract': 'Music is both an auditory and an embodied phenomenon, closely linked to human motion and naturally expressed through dance. However, most existing audio representations neglect this embodied dimension, limiting their ability to capture rhythmic and structural cues that drive movement. We propose MotionBeat, a framework for motion-aligned music representation learning. MotionBeat is trained with two newly proposed objectives: the Embodied Contrastive Loss (ECL), an enhanced InfoNCE formulation with tempo-aware and beat-jitter negatives to achieve fine-grained rhythmic discrimination, and the Structural Rhythm Alignment Loss (SRAL), which ensures rhythm consistency by aligning music accents with corresponding motion events. Architecturally, MotionBeat introduces bar-equivariant phase rotations to capture cyclic rhythmic patterns and contact-guided attention to emphasize motion events synchronized with musical accents. Experiments show that MotionBeat outperforms state-of-the-art audio encoders in music-to-dance generation and transfers effectively to beat tracking, music tagging, genre and instrument classification, emotion recognition, and audio-visual retrieval. Our project demo page: this https URL.', 'abstract_zh': '音乐既是听觉的也是身体的现象，紧密关联人类运动，并自然地通过舞蹈表达。然而，现有的大多数音频表示忽视了这种身体维度，限制了它们捕捉驱动运动的节奏和结构线索的能力。我们提出了MotionBeat，一种用于运动对齐的音乐表示学习框架。MotionBeat通过两种新提出的优化目标进行训练：Body-aware Contrastive Loss（BCL），这是增强的InfoNCE公式，带有节拍感知和节拍抖动的负样本，以实现精细的节奏辨别；以及Structural Rhythm Alignment Loss（SRAL），通过使音乐重音与相应的运动事件对齐以确保节奏一致性。从架构上看，MotionBeat引入了小节等变相位旋转以捕捉周期性节奏模式，并使用基于接触的注意力以强调与音乐重音同步的运动事件。实验结果显示，MotionBeat在音乐到舞蹈生成中优于现有的音频编码器，并且能够有效转移至节拍跟踪、音乐标签化、流派和乐器分类、情绪识别以及音频视觉检索。我们的项目演示页面：this https URL。', 'title_zh': 'MotionBeat：通过身体对比学习和小节不变的接触感知编码的运动对齐音乐表示'}
{'arxiv_id': 'arXiv:2510.13232', 'title': 'What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging', 'authors': 'Inha Kang, Youngsun Lim, Seonho Lee, Jiho Choi, Junsuk Choe, Hyunjung Shim', 'link': 'https://arxiv.org/abs/2510.13232', 'abstract': 'State-of-the-art vision-language models (VLMs) suffer from a critical failure in understanding negation, often referred to as affirmative bias. This limitation is particularly severe in described object detection (DOD) tasks. To address this, we propose two primary contributions: (1) a new dataset pipeline and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a dataset constructed with a systematic chain-of-thought (CoT) and VQA-based pipeline to generate high-quality, instance-grounded negation data. Second, we propose NegToMe, a novel text token merging module that directly tackles the architectural cause of affirmative bias. NegToMe fundamentally addresses the structural loss of negation cues in tokenization, grouping them with attributes into coherent semantic phrases. It maintains correct polarity at the input level, enabling robust negation understanding even with limited data. For instance, to prevent a model from treating the fragmented tokens "not" and "girl" as simply "girl", NegToMe binds them into a single token whose meaning is correctly distinguished from that of "girl" alone. This module is integrated with a parameter-efficient and strategic LoRA fine-tuning approach. Our method significantly improves performance on challenging negation benchmarks with a lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval and demonstrating generalization to SoTA VLMs. This work marks a crucial step forward in addressing negation understanding for real-world detection applications.', 'abstract_zh': '最先进的视觉-语言模型（VLMs）在理解否定方面存在关键缺陷，通常称为肯定偏向。这一局限性在描述物体检测（DOD）任务中尤为严重。为了应对这一问题，我们提出了两项主要贡献：（1）一个新的数据集管道和（2）一种新颖的轻量级适应食谱。首先，我们引入了CoVAND数据集，该数据集通过系统性思维链（CoT）和VQA基于的管道生成高质量、实例相关的否定数据。其次，我们提出了一种新的文本令牌合并模块NegToMe，直接解决肯定偏向的架构原因。NegToMe从根本上解决了词元化过程中否定线索的结构损失，将它们与属性合并为连贯的语义短语。它在输入级别保持正确的极性，在数据有限的情况下也能实现稳健的否定理解。例如，为了防止模型将断裂的词元“not”和“girl”错误地处理为“girl”，NegToMe将它们绑定成一个单一的词元，其含义正确地区别于单独的“girl”。该模块与参数高效且有策略的LoRA微调方法集成。我们的方法在具有挑战性的否定基准测试上显著提高了性能，NMS-AP在OVDEval上提高了最多10.8分，并且展示了对最先进的VLMs的一般化能力。这项工作标志着在为实际检测应用提供否定理解方面迈出的重要一步。', 'title_zh': '不检测什么：基于结构化推理和token合并的负向意识大语言模型'}
{'arxiv_id': 'arXiv:2510.13208', 'title': 'MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation', 'authors': 'Lianlian Liu, YongKang He, Zhaojie Chu, Xiaofen Xing, Xiangmin Xu', 'link': 'https://arxiv.org/abs/2510.13208', 'abstract': 'Generating stylized 3D human motion from speech signals presents substantial challenges, primarily due to the intricate and fine-grained relationships among speech signals, individual styles, and the corresponding body movements. Current style encoding approaches either oversimplify stylistic diversity or ignore regional motion style differences (e.g., upper vs. lower body), limiting motion realism. Additionally, motion style should dynamically adapt to changes in speech rhythm and emotion, but existing methods often overlook this. To address these issues, we propose MimicParts, a novel framework designed to enhance stylized motion generation based on part-aware style injection and part-aware denoising network. It divides the body into different regions to encode localized motion styles, enabling the model to capture fine-grained regional differences. Furthermore, our part-aware attention block allows rhythm and emotion cues to guide each body region precisely, ensuring that the generated motion aligns with variations in speech rhythm and emotional state. Experimental results show that our method outperforming existing methods showcasing naturalness and expressive 3D human motion sequences.', 'abstract_zh': '基于部分感知风格注入和部分感知去噪网络的3D人体运动生成方法：MimicParts', 'title_zh': 'MimicParts: 部件aware的风格注入方法用于语音驱动的3D运动生成'}
{'arxiv_id': 'arXiv:2510.13205', 'title': 'CleverCatch: A Knowledge-Guided Weak Supervision Model for Fraud Detection', 'authors': 'Amirhossein Mozafari, Kourosh Hashemi, Erfan Shafagh, Soroush Motamedi, Azar Taheri Tayebi, Mohammad A. Tayebi', 'link': 'https://arxiv.org/abs/2510.13205', 'abstract': 'Healthcare fraud detection remains a critical challenge due to limited availability of labeled data, constantly evolving fraud tactics, and the high dimensionality of medical records. Traditional supervised methods are challenged by extreme label scarcity, while purely unsupervised approaches often fail to capture clinically meaningful anomalies. In this work, we introduce CleverCatch, a knowledge-guided weak supervision model designed to detect fraudulent prescription behaviors with improved accuracy and interpretability. Our approach integrates structured domain expertise into a neural architecture that aligns rules and data samples within a shared embedding space. By training encoders jointly on synthetic data representing both compliance and violation, CleverCatch learns soft rule embeddings that generalize to complex, real-world datasets. This hybrid design enables data-driven learning to be enhanced by domain-informed constraints, bridging the gap between expert heuristics and machine learning. Experiments on the large-scale real-world dataset demonstrate that CleverCatch outperforms four state-of-the-art anomaly detection baselines, yielding average improvements of 1.3\\% in AUC and 3.4\\% in recall. Our ablation study further highlights the complementary role of expert rules, confirming the adaptability of the framework. The results suggest that embedding expert rules into the learning process not only improves detection accuracy but also increases transparency, offering an interpretable approach for high-stakes domains such as healthcare fraud detection.', 'abstract_zh': '基于知识引导的弱监督模型CleverCatch在医疗欺诈检测中的应用', 'title_zh': 'CleverCatch: 一种知识引导的弱监督欺诈检测模型'}
{'arxiv_id': 'arXiv:2510.13202', 'title': 'LLM-Guided Synthetic Augmentation (LGSA) for Mitigating Bias in AI Systems', 'authors': 'Sai Suhruth Reddy Karri, Yashwanth Sai Nallapuneni, Laxmi Narasimha Reddy Mallireddy, Gopichand G', 'link': 'https://arxiv.org/abs/2510.13202', 'abstract': 'Bias in AI systems, especially those relying on natural language data, raises ethical and practical concerns. Underrepresentation of certain groups often leads to uneven performance across demographics. Traditional fairness methods, such as pre-processing, in-processing, and post-processing, depend on protected-attribute labels, involve accuracy-fairness trade-offs, and may not generalize across datasets. To address these challenges, we propose LLM-Guided Synthetic Augmentation (LGSA), which uses large language models to generate counterfactual examples for underrepresented groups while preserving label integrity. We evaluated LGSA on a controlled dataset of short English sentences with gendered pronouns, professions, and binary classification labels. Structured prompts were used to produce gender-swapped paraphrases, followed by quality control including semantic similarity checks, attribute verification, toxicity screening, and human spot checks. The augmented dataset expanded training coverage and was used to train a classifier under consistent conditions. Results show that LGSA reduces performance disparities without compromising accuracy. The baseline model achieved 96.7 percent accuracy with a 7.2 percent gender bias gap. Simple swap augmentation reduced the gap to 0.7 percent but lowered accuracy to 95.6 percent. LGSA achieved 99.1 percent accuracy with a 1.9 percent bias gap, improving performance on female-labeled examples. These findings demonstrate that LGSA is an effective strategy for bias mitigation, enhancing subgroup balance while maintaining high task accuracy and label fidelity.', 'abstract_zh': 'AI系统中的偏差，尤其是在依赖自然语言数据的情况下，引发了伦理和实践方面的担忧。代表性不足的群体往往导致不同 demographic 组的表现不均衡。传统公平性方法，如预处理、内处理和后处理，依赖受保护属性标签，涉及准确性和公平性的权衡，并且可能不能泛化到不同的数据集。为了解决这些挑战，我们提出了一种基于大规模语言模型的合成增强（LGSA）方法，该方法利用大型语言模型为代表性不足的群体生成反事实示例，同时保持标签完整性。我们在一个受控的包含性别代词、职业和二元分类标签的短英语句子数据集中评估了 LGSA。使用结构化提示生成性别转换的同义句，随后进行质量控制，包括语义相似性检查、属性验证、有害内容筛选和人工抽查。增强后的数据集扩展了训练覆盖范围，并在一致条件下用于训练分类器。结果表明，LGSA 在减少性能差异的同时没有牺牲准确性。基线模型的准确率为 96.7%，性别偏差差距为 7.2%。简单的替换增强将差距缩小到 0.7%，但降低了准确率至 95.6%。LGSA 的准确率为 99.1%，性别偏差差距为 1.9%，并且在女性标记的示例上提高了性能。这些发现表明，LGSA 是一种有效的方法，可以减轻偏差，增强子组平衡，同时保持高任务准确性和标签忠实性。', 'title_zh': 'LLM指导的合成增强方法（LGSA）用于减轻AI系统中的偏见'}
{'arxiv_id': 'arXiv:2510.13201', 'title': 'Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences', 'authors': 'Jing Yang, Qiyao Wei, Jiaxin Pei', 'link': 'https://arxiv.org/abs/2510.13201', 'abstract': 'The rapid growth of AI conferences is straining an already fragile peer-review system, leading to heavy reviewer workloads, expertise mismatches, inconsistent evaluation standards, superficial or templated reviews, and limited accountability under compressed timelines. In response, conference organizers have introduced new policies and interventions to preserve review standards. Yet these ad-hoc changes often create further concerns and confusion about the review process, leaving how papers are ultimately accepted - and how practices evolve across years - largely opaque. We present Paper Copilot, a system that creates durable digital archives of peer reviews across a wide range of computer-science venues, an open dataset that enables researchers to study peer review at scale, and a large-scale empirical analysis of ICLR reviews spanning multiple years. By releasing both the infrastructure and the dataset, Paper Copilot supports reproducible research on the evolution of peer review. We hope these resources help the community track changes, diagnose failure modes, and inform evidence-based improvements toward a more robust, transparent, and reliable peer-review system.', 'abstract_zh': 'AI会议的迅猛增长正对本已脆弱的同行评审系统形成压力，导致评审工作负担加重、专业技能错配、评价标准不一致、评审表面化或模板化以及时间压缩下的问责机制受限。为应对这一挑战，会议组织者引入了新政策和干预措施以维护评审标准。然而，这些临时性改变往往引发更多困惑，使得论文最终被接受的方式以及年份间评审实践的变化仍然缺乏透明度。我们提出了Paper Copilot系统，该系统创建了一系列计算机科学领域广泛会议的持久数字档案，提供了大规模开放数据集以供研究人员研究同行评审，同时进行了跨越多年的ICLR评审的大型实证分析。通过发布基础设施和数据集，Paper Copilot支持同行评审演变的可重复研究。我们期望这些资源能帮助社区追踪变化、诊断故障模式，并通过基于证据的改进推动更具 robustness、透明性和可靠性的同行评审系统。', 'title_zh': '论文copilot: 跟踪AI会议中同行评审的演变'}
{'arxiv_id': 'arXiv:2510.13194', 'title': 'StressTransfer: Stress-Aware Speech-to-Speech Translation with Emphasis Preservation', 'authors': 'Xi Chen, Yuchen Song, Satoshi Nakamura', 'link': 'https://arxiv.org/abs/2510.13194', 'abstract': 'We propose a stress-aware speech-to-speech translation (S2ST) system that preserves word-level emphasis by leveraging LLMs for cross-lingual emphasis conversion. Our method translates source-language stress into target-language tags that guide a controllable TTS model. To overcome data scarcity, we developed a pipeline to automatically generate aligned training data and introduce the "LLM-as-Judge" for evaluation. Experiments show our approach substantially outperforms baselines in preserving emphasis while maintaining comparable translation quality, speaker intent, and naturalness. Our work highlights the importance of prosody in translation and provides an effective, data-efficient solution for preserving paralinguistic cues in S2ST.', 'abstract_zh': '一种基于大语言模型的意识应力语音到语音翻译系统：通过跨语言应力转换保留词级强调', 'title_zh': '应力传递：注重强调的感知压力语音到语音翻译'}
{'arxiv_id': 'arXiv:2510.13158', 'title': 'Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction', 'authors': 'Haolin Pan, Jinyuan Dong, Hongbin Zhang, Hongyu Lin, Mingjie Xing, Yanjun Wu', 'link': 'https://arxiv.org/abs/2510.13158', 'abstract': "Learning effective numerical representations, or embeddings, of programs is a fundamental prerequisite for applying machine learning to automate and enhance compiler optimization. Prevailing paradigms, however, present a dilemma. Static representations, derived from source code or intermediate representation (IR), are efficient and deterministic but offer limited insight into how a program will behave or evolve under complex code transformations. Conversely, dynamic representations, which rely on runtime profiling, provide profound insights into performance bottlenecks but are often impractical for large-scale tasks due to prohibitive overhead and inherent non-determinism. This paper transcends this trade-off by proposing a novel quasi-dynamic framework for program representation. The core insight is to model a program's optimization sensitivity. We introduce the Program Behavior Spectrum, a new representation generated by probing a program's IR with a diverse set of optimization sequences and quantifying the resulting changes in its static features. To effectively encode this high-dimensional, continuous spectrum, we pioneer a compositional learning approach. Product Quantization is employed to discretize the continuous reaction vectors into structured, compositional sub-words. Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to learn the deep contextual grammar of these behavioral codes. Comprehensive experiments on two representative compiler optimization tasks -- Best Pass Prediction and -Oz Benefit Prediction -- demonstrate that our method outperforms state-of-the-art static baselines. Our code is publicly available at this https URL.", 'abstract_zh': '基于程序表示的新型准动态框架：通过建模优化敏感性实现有效的数值表示', 'title_zh': '程序的行为嵌入：一种近似动态方法及其优化预测'}
{'arxiv_id': 'arXiv:2510.13157', 'title': 'Program of Thoughts for Financial Reasoning: Leveraging Dynamic In-Context Examples and Generative Retrieval', 'authors': 'Subhendu Khatuya, Shashwat Naidu, Pawan Goyal, Niloy Ganguly', 'link': 'https://arxiv.org/abs/2510.13157', 'abstract': "Despite continuous advancements in the capabilities of large language models (LLMs), numerical reasoning remains a challenging area. Techniques like chain-of-thought prompting, tree-of-thought prompting, and program-of-thought prompting guide LLMs through intermediate reasoning steps. Although in-context learning with few-shot prompting has improved performance, LLMs still lag behind state-of-the-art models on financial numerical reasoning datasets such as FinQA and ConvFinQA. In this work, we introduce FINDER, a novel two-step framework, to enhance LLMs' capabilities in financial numerical reasoning. The first step utilizes a generative retriever to extract relevant facts from unstructured data, including both text and tables. This is followed by context-aware Program of Thought prompting with dynamic selection of in-context examples. Our model FINDER achieves a new state-of-the-art performance on both the FinQA and ConvFinQA datasets, surpassing previous benchmarks with execution accuracy improvements of 5.98% and 4.05%, respectively.", 'abstract_zh': '尽管大型语言模型的能力持续进步，但数值推理仍然是一项挑战。FINDER：一种增强语言模型财务数值推理能力的新型两步框架。', 'title_zh': '金融推理的思维程序：利用动态上下文示例和生成性检索'}
{'arxiv_id': 'arXiv:2510.13143', 'title': 'Stable LLM Ensemble: Interaction between Example Representativeness and Diversity', 'authors': 'Junichiro Niimi', 'link': 'https://arxiv.org/abs/2510.13143', 'abstract': 'Large language models (LLMs) have achieved remarkable results in wide range of domains. However, the accuracy and robustness of one-shot LLM predictions remain highly sensitive to the examples and the diversity among ensemble members. This study systematically investigates the effects of example representativeness (one-shot strategy) and output diversity (sampling temperature) on LLM ensemble performance. Two one-shot strategies are compared: centroid-based representative examples (proposed) and randomly sampled examples (baseline) and sampling temperature also is varied. The proposed approach with higher temperature setting significantly outperforms random selection by +7.6% (macro-F1) and -10.5% (RMSE). Furthermore, the proposed model exceeds 5-shot prompting by +21.1% (macro-F1) and -24.0% (RMSE). Our findings demonstrate that combining representative example selection with increased temperature provides the appropriate level of diversity to the ensemble. This work highlights the practical importance of both example selection and controlled diversity in designing effective one-shot LLM ensembles.', 'abstract_zh': '大型语言模型（LLMs）在多个领域取得了显著成果。然而，单次预测的准确性和鲁棒性仍然高度依赖于示例的代表性及集成成员之间的多样性。本研究系统地探讨了示例代表性（单次策略）和输出多样性（采样温度）对LLM集成性能的影响。比较了两种单次策略：基于质心的代表示例（提出的方法）和随机抽样示例（基线方法），同时改变了采样温度。在较高的温度设置下，提出的方案在macro-F1上比随机选择高7.6%，在RMSE上低10.5%。此外，提出的模型在5次提示下超出21.1%（macro-F1）和24.0%（RMSE）。研究发现，结合代表性示例选择与增加温度可以为集成提供适当的多样性水平。本研究突出了在设计有效的单次LLM集成中示例选择和可控多样性的重要性。', 'title_zh': '稳定的大规模语言模型集成：示例表示性和多样性之间的互动'}
{'arxiv_id': 'arXiv:2510.13117', 'title': 'On the Reasoning Abilities of Masked Diffusion Language Models', 'authors': 'Anej Svete, Ashish Sabharwal', 'link': 'https://arxiv.org/abs/2510.13117', 'abstract': 'Masked diffusion models (MDMs) for text offer a compelling alternative to traditional autoregressive language models. Parallel generation makes them efficient, but their computational capabilities and the limitations inherent to their parallelism remain largely unexplored. To this end, we characterize what types of reasoning problems MDMs can provably solve and how efficiently. We do this by connecting MDMs to the well-understood reasoning frameworks of chain of thought (CoT) and padded looped transformers (PLTs) in the finite-precision log-width setting: We show that MDMs and polynomially-padded PLTs are, in fact, equivalent in this setting, and that MDMs can solve all problems that CoT-augmented transformers can. Moreover, we showcase classes of problems (including regular languages) for which MDMs are inherently more efficient than CoT transformers, where parallel generation allows for substantially faster reasoning.', 'abstract_zh': '掩码扩散模型（MDMs）在文本生成方面为传统的自回归语言模型提供了一个有吸引力的替代方案。并行生成使它们变得高效，但它们的计算能力和并行性固有的限制仍 largely unexplored。为此，我们 characterization 了 MDMs 能明确解决哪些推理问题及其效率。我们通过将 MDMs 与在有限精度对数宽度设置下 well-understood 的推理框架——链式思考（CoT）和补截循环变换器（PLTs）——联系起来来实现这一点：我们展示了在这一设置下，MDMs 和多项式补截的 PLTs 实际上是等效的，并且 MDMs 能解决 CoT 增强的变换器能解决的所有问题。此外，我们展示了 MDMs 比 CoT 变换器在某些问题类（包括正规语言）上更高效的类，其中并行生成允许显著更快的推理。', 'title_zh': '掩码扩散语言模型的推理能力研究'}
{'arxiv_id': 'arXiv:2510.13115', 'title': 'Multi-Label Clinical Text Eligibility Classification and Summarization System', 'authors': 'Surya Tejaswi Yerramsetty, Almas Fathimah', 'link': 'https://arxiv.org/abs/2510.13115', 'abstract': 'Clinical trials are central to medical progress because they help improve understanding of human health and the healthcare system. They play a key role in discovering new ways to detect, prevent, or treat diseases, and it is essential that clinical trials include participants with appropriate and diverse medical backgrounds. In this paper, we propose a system that leverages Natural Language Processing (NLP) and Large Language Models (LLMs) to automate multi-label clinical text eligibility classification and summarization. The system combines feature extraction methods such as word embeddings (Word2Vec) and named entity recognition to identify relevant medical concepts, along with traditional vectorization techniques such as count vectorization and TF-IDF (Term Frequency-Inverse Document Frequency). We further explore weighted TF-IDF word embeddings that integrate both count-based and embedding-based strengths to capture term importance effectively. Multi-label classification using Random Forest and SVM models is applied to categorize documents based on eligibility criteria. Summarization techniques including TextRank, Luhn, and GPT-3 are evaluated to concisely summarize eligibility requirements. Evaluation with ROUGE scores demonstrates the effectiveness of the proposed methods. This system shows potential for automating clinical trial eligibility assessment using data-driven approaches, thereby improving research efficiency.', 'abstract_zh': '临床试验是医疗进步的核心，因为它们有助于改善对人类健康和医疗卫生系统的理解。它们在发现新的检测、预防或治疗疾病的方法中扮演关键角色，因此临床试验应包括具有适当和多样医学背景的参与者。本文提出了一种利用自然语言处理(NLP)和大规模语言模型(LLMs)自动进行多标签临床文本适配性分类和总结的系统。该系统结合了词嵌入(Word2Vec)和命名实体识别等特征提取方法以识别相关医学概念，并采用了传统的词汇化技术如词频向量和TF-IDF。进一步探讨了结合基于计数和嵌入优势的加权TF-IDF词嵌入，以有效地捕捉术语的重要性。使用随机森林和SVM模型进行多标签分类，根据适配性标准对文档进行分类。评估了TextRank、Luhn和GPT-3等总结技术，以简洁地总结适配性要求。利用ROUGE分数进行评估，展示了提出方法的有效性。该系统具有使用数据驱动的方法自动化临床试验适配性评估的潜力，从而提高研究效率。', 'title_zh': '多标签临床文本适宜性分类与总结系统'}
{'arxiv_id': 'arXiv:2510.13108', 'title': 'DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models', 'authors': 'Jingyu Song, Zhenxin Li, Shiyi Lan, Xinglong Sun, Nadine Chang, Maying Shen, Joshua Chen, Katherine A. Skinner, Jose M. Alvarez', 'link': 'https://arxiv.org/abs/2510.13108', 'abstract': 'Benchmarking autonomous driving planners to align with human judgment remains a critical challenge, as state-of-the-art metrics like the Extended Predictive Driver Model Score (EPDMS) lack context awareness in nuanced scenarios. To address this, we introduce DriveCritic, a novel framework featuring two key contributions: the DriveCritic dataset, a curated collection of challenging scenarios where context is critical for correct judgment and annotated with pairwise human preferences, and the DriveCritic model, a Vision-Language Model (VLM) based evaluator. Fine-tuned using a two-stage supervised and reinforcement learning pipeline, the DriveCritic model learns to adjudicate between trajectory pairs by integrating visual and symbolic context. Experiments show DriveCritic significantly outperforms existing metrics and baselines in matching human preferences and demonstrates strong context awareness. Overall, our work provides a more reliable, human-aligned foundation to evaluating autonomous driving systems.', 'abstract_zh': '基于DriveCritic框架的自主驾驶规划器评估基准尚存在关键挑战，现有的度量标准如扩展预测驾驶员模型评分（EPDMS）在细微情境中缺乏背景意识。为此，我们引入了DriveCritic，一种新型框架，包含两项关键贡献：DriveCritic数据集，一个精心挑选的包含关键背景信息的挑战性场景集合，并标注了两两的人类偏好；以及DriveCritic模型，一种基于视觉语言模型（VLM）的评估器。通过两阶段监督学习和强化学习微调，DriveCritic模型学习通过整合视觉和符号背景来裁定轨迹对。实验表明，DriveCritic显著优于现有度量标准和基线，在匹配人类偏好方面表现更佳，并显示出强大的背景意识。总体而言，我们的工作为评价自主驾驶系统提供了一个更可靠、更符合人类认知的基准。', 'title_zh': 'DriveCritic: 面向上下文感知和人类价值观对齐的自动驾驶评价方法研究'}
{'arxiv_id': 'arXiv:2510.13106', 'title': 'TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models', 'authors': 'Ruoyu Sun, Da Song, Jiayang Song, Yuheng Huang, Lei Ma', 'link': 'https://arxiv.org/abs/2510.13106', 'abstract': 'As Large Language Models (LLMs) continue to revolutionize Natural Language Processing (NLP) applications, critical concerns about their trustworthiness persist, particularly in safety and robustness. To address these challenges, we introduce TRUSTVIS, an automated evaluation framework that provides a comprehensive assessment of LLM trustworthiness. A key feature of our framework is its interactive user interface, designed to offer intuitive visualizations of trustworthiness metrics. By integrating well-known perturbation methods like AutoDAN and employing majority voting across various evaluation methods, TRUSTVIS not only provides reliable results but also makes complex evaluation processes accessible to users. Preliminary case studies on models like Vicuna-7b, Llama2-7b, and GPT-3.5 demonstrate the effectiveness of our framework in identifying safety and robustness vulnerabilities, while the interactive interface allows users to explore results in detail, empowering targeted model improvements. Video Link: this https URL', 'abstract_zh': '随着大规模语言模型（LLMs）继续革新自然语言处理（NLP）应用，其可信性问题，特别是安全性与 robustness 方面的问题，仍然引起了广泛关注。为应对这些挑战，我们引入了 TRUSTVIS，一种自动评估框架，提供全面的可信性评估。该框架的一个关键特点是其交互式用户界面，设计用于直观展示可信性指标。通过集成知名的扰动方法（如 AutoDAN）并通过多种评估方法中的多数投票来整合，TRUSTVIS 不仅提供了可靠的结果，还使复杂的评估过程对用户而言更加易于访问。初步案例研究针对如 Vicuna-7b、Llama2-7b 和 GPT-3.5 等模型证实了该框架在识别安全性和 robustness 漏洞方面的有效性，而交互式界面允许用户详细探索结果，从而推动针对性的模型改进。视频链接：这个 https URL。', 'title_zh': 'TRUSTVIS：大型语言模型多维度可信性评估框架'}
{'arxiv_id': 'arXiv:2510.13103', 'title': 'ESI: Epistemic Uncertainty Quantification via Semantic-preserving Intervention for Large Language Models', 'authors': 'Mingda Li, Xinyu Li, Weinan Zhang, Longxuan Ma', 'link': 'https://arxiv.org/abs/2510.13103', 'abstract': 'Uncertainty Quantification (UQ) is a promising approach to improve model reliability, yet quantifying the uncertainty of Large Language Models (LLMs) is non-trivial. In this work, we establish a connection between the uncertainty of LLMs and their invariance under semantic-preserving intervention from a causal perspective. Building on this foundation, we propose a novel grey-box uncertainty quantification method that measures the variation in model outputs before and after the semantic-preserving intervention. Through theoretical justification, we show that our method provides an effective estimate of epistemic uncertainty. Our extensive experiments, conducted across various LLMs and a variety of question-answering (QA) datasets, demonstrate that our method excels not only in terms of effectiveness but also in computational efficiency.', 'abstract_zh': '不确定性量化（UQ）是提高模型可靠性的有前途的方法，然而量化大型语言模型（LLMs）的不确定性并不 trivial。在此工作中，我们从因果角度建立了 LLMs 的不确定性与其在语义保留干预下的不变性之间的联系。在此基础上，我们提出了一种新颖的灰色盒不确定性量化方法，通过在语义保留干预前后测量模型输出的变化来评估不确定性。通过理论证明，我们展示我们的方法提供了对本质不确定性有效估计。我们广泛进行的实验，跨越了多种 LLMs 和各种问答（QA）数据集，证明了我们的方法在有效性方面不仅表现出色，在计算效率方面也表现出色。', 'title_zh': 'ESI: 基于语义保持干预的知识不确定性量化方法用于大型语言模型'}
{'arxiv_id': 'arXiv:2510.13093', 'title': 'A Multi-dimensional Semantic Surprise Framework Based on Low-Entropy Semantic Manifolds for Fine-Grained Out-of-Distribution Detection', 'authors': 'Ningkang Peng, Yuzhe Mao, Yuhao Zhang, Linjin Qian, Qianfeng Yu, Yanhui Gu, Yi Chen, Li Kong', 'link': 'https://arxiv.org/abs/2510.13093', 'abstract': "Out-of-Distribution (OOD) detection is a cornerstone for the safe deployment of AI systems in the open world. However, existing methods treat OOD detection as a binary classification problem, a cognitive flattening that fails to distinguish between semantically close (Near-OOD) and distant (Far-OOD) unknown risks. This limitation poses a significant safety bottleneck in applications requiring fine-grained risk stratification. To address this, we propose a paradigm shift from a conventional probabilistic view to a principled information-theoretic framework. We formalize the core task as quantifying the Semantic Surprise of a new sample and introduce a novel ternary classification challenge: In-Distribution (ID) vs. Near-OOD vs. Far-OOD. The theoretical foundation of our work is the concept of Low-Entropy Semantic Manifolds, which are explicitly structured to reflect the data's intrinsic semantic hierarchy. To construct these manifolds, we design a Hierarchical Prototypical Network. We then introduce the Semantic Surprise Vector (SSV), a universal probe that decomposes a sample's total surprise into three complementary and interpretable dimensions: conformity, novelty, and ambiguity. To evaluate performance on this new task, we propose the Normalized Semantic Risk (nSR), a cost-sensitive metric. Experiments demonstrate that our framework not only establishes a new state-of-the-art (sota) on the challenging ternary task, but its robust representations also achieve top results on conventional binary benchmarks, reducing the False Positive Rate by over 60% on datasets like LSUN.", 'abstract_zh': '超出分布域（OOD）检测是将AI系统安全部署到开放世界的关键基础。然而，现有方法将OOD检测视为二元分类问题，未能区分语义上接近（Near-OOD）和远离（Far-OOD）的未知风险。这一局限性在需要精细风险分级的应用中构成了重大安全瓶颈。为解决这一问题，我们提出了从传统的概率视角向原理性的信息论框架的转变。我们将核心任务形式化为量化新样本的语义惊喜，并引入一种新颖的三元分类挑战：在分布域（ID） vs. 语义接近超分布域（Near-OOD） vs. 语义远离超分布域（Far-OOD）。我们工作的理论基础是低熵语义流形的概念，这些流形明确结构化以反映数据的内在语义层次。为了构建这些流形，我们设计了层次原型网络。我们还引入了语义惊喜向量（SSV），这是一种通用探针，将样本的总惊喜分解为三个互补且可解释的维度：符合性、新颖性和模糊性。为了评估此新任务上的性能，我们提出了归一化语义风险（nSR），这是一种成本敏感度量。实验结果表明，我们的框架不仅在具有挑战性的三元任务上建立了新的最佳性能，而且其鲁棒性表示在常规的二元基准测试中也取得了顶级结果，在LSUN等数据集上的假阳性率降低了60%以上。', 'title_zh': '基于低熵语义流形的多维度语义惊奇框架在分布外检测中的应用'}
{'arxiv_id': 'arXiv:2510.13081', 'title': 'Agentic Discovery: Closing the Loop with Cooperative Agents', 'authors': 'J. Gregory Pauloski, Kyle Chard, Ian T. Foster', 'link': 'https://arxiv.org/abs/2510.13081', 'abstract': 'As data-driven methods, artificial intelligence (AI), and automated workflows accelerate scientific tasks, we see the rate of discovery increasingly limited by human decision-making tasks such as setting objectives, generating hypotheses, and designing experiments. We postulate that cooperative agents are needed to augment the role of humans and enable autonomous discovery. Realizing such agents will require progress in both AI and infrastructure.', 'abstract_zh': '随着数据驱动方法、人工智能（AI）和自动化工作流程加速科学研究任务，我们发现发现率越来越受到人类决策任务，如设定目标、生成假设和设计实验的限制。我们假设需要合作代理来增强人类的作用，以实现自主发现。实现这样的代理将需要在人工智能和基础设施两个方面取得进展。', 'title_zh': '代理发现：与协同代理形成闭环'}
{'arxiv_id': 'arXiv:2510.13077', 'title': 'Transformer-based Scalable Beamforming Optimization via Deep Residual Learning', 'authors': 'Yubo Zhang, Xiao-Yang Liu, Xiaodong Wang', 'link': 'https://arxiv.org/abs/2510.13077', 'abstract': 'We develop an unsupervised deep learning framework for downlink beamforming in large-scale MU-MISO channels. The model is trained offline, allowing real-time inference through lightweight feedforward computations in dynamic communication environments. Following the learning-to-optimize (L2O) paradigm, a multi-layer Transformer iteratively refines both channel and beamformer features via residual connections. To enhance training, three strategies are introduced: (i) curriculum learning (CL) to improve early-stage convergence and avoid local optima, (ii) semi-amortized learning to refine each Transformer block with a few gradient ascent steps, and (iii) sliding-window training to stabilize optimization by training only a subset of Transformer blocks at a time. Extensive simulations show that the proposed scheme outperforms existing baselines at low-to-medium SNRs and closely approaches WMMSE performance at high SNRs, while achieving substantially faster inference than iterative and online learning approaches.', 'abstract_zh': '我们开发了一种无监督深度学习框架，用于大规模MU-MISO信道下的下行波束形成。该模型离线训练，允许在动态通信环境中通过轻量级前向计算进行实时推理。遵循学习优化（L2O）范式，多层变换器通过残差连接迭代优化通道和波束形成器特征。为了提高训练效果，引入了三种策略：（i）课程学习（CL）以改善早期收敛并避免局部最优，（ii）半近端学习以通过少量梯度上升步骤细化每个变换器块，以及（iii）滑动窗口训练以通过每次仅训练一部分变换器块来稳定优化。广泛仿真实验表明，所提出方案在低至中等信噪比下优于现有基线，在高信噪比下接近WMMSE性能，同时比迭代和在线学习方法实现更快的推理速度。', 'title_zh': '基于变换器的深残差学习大规模波束forming优化'}
{'arxiv_id': 'arXiv:2510.13068', 'title': 'NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models', 'authors': 'Konstantinos Barmpas, Na Lee, Alexandros Koliousis, Yannis Panagakis, Dimitrios A. Adamos, Nikolaos Laskaris, Stefanos Zafeiriou', 'link': 'https://arxiv.org/abs/2510.13068', 'abstract': 'Electroencephalography (EEG) captures neural activity across multiple temporal and spectral scales, yielding signals that are rich but complex for representation learning. Recently, EEG foundation models trained to predict masked signal-tokens have shown promise for learning generalizable representations. However, their performance is hindered by their signal tokenization modules. Existing neural tokenizers fail to preserve high-frequency dynamics, limiting their ability to reconstruct EEG signals with high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM) centered on a codebook-based tokenizer. Our tokenizer integrates: (i) multi-scale feature extraction modules that capture the full frequency neural spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware loss function for efficient training. This design enables efficient EEG compression while supporting accurate reconstruction across all frequency bands, leading to robust generative masked modeling. Our empirical results demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ tokenizer establishes a strong prior for codebook-based general-purpose brainwave models, enabling advances in neural decoding, generative modeling and multimodal biosignal integration.', 'abstract_zh': '基于神经鲁姆量化的可扩展大型脑波模型（NeuroRVQ）：高效压缩与准确重建', 'title_zh': 'NeuroRVQ: 多尺度EEG词元化生成大型脑波模型'}
{'arxiv_id': 'arXiv:2510.13063', 'title': 'True Self-Supervised Novel View Synthesis is Transferable', 'authors': 'Thomas W. Mitchel, Hyunwoo Ryu, Vincent Sitzmann', 'link': 'https://arxiv.org/abs/2510.13063', 'abstract': 'In this paper, we identify that the key criterion for determining whether a model is truly capable of novel view synthesis (NVS) is transferability: Whether any pose representation extracted from one video sequence can be used to re-render the same camera trajectory in another. We analyze prior work on self-supervised NVS and find that their predicted poses do not transfer: The same set of poses lead to different camera trajectories in different 3D scenes. Here, we present XFactor, the first geometry-free self-supervised model capable of true NVS. XFactor combines pair-wise pose estimation with a simple augmentation scheme of the inputs and outputs that jointly enables disentangling camera pose from scene content and facilitates geometric reasoning. Remarkably, we show that XFactor achieves transferability with unconstrained latent pose variables, without any 3D inductive biases or concepts from multi-view geometry -- such as an explicit parameterization of poses as elements of SE(3). We introduce a new metric to quantify transferability, and through large-scale experiments, we demonstrate that XFactor significantly outperforms prior pose-free NVS transformers, and show that latent poses are highly correlated with real-world poses through probing experiments.', 'abstract_zh': '在这项工作中，我们确定模型是否真正具备新颖视图合成（NVS）能力的关键标准是可迁移性：任何从一个视频序列提取的姿势表示是否可以在另一个序列中用于重新渲染相同的摄像机轨迹。我们分析了先有的自监督NVS工作，发现它们预测的姿势不具备可迁移性：相同的姿势集在不同的3D场景中生成不同的摄像机轨迹。在此，我们提出了XFactor，这是首个无需几何信息就能实现真正确模型NVS的自监督模型。XFactor结合了一对一姿势估计和简单的输入输出增强方案，同时实现了从摄像机姿态中解耦场景内容，促进了几何推理。令人惊讶的是，我们展示XFactor仅通过无约束的潜在姿态变量即可实现可迁移性，无需任何3D归纳偏置或来自多视图几何的概念，如明确将姿态表示为SE(3)的元素。我们引入了一个新的度量标准来量化可迁移性，并通过大规模实验展示XFactor显著优于先前的无姿态NVS变压器，通过探针实验展示了潜在姿态与真实世界姿态的高度相关性。', 'title_zh': '真正的自我监督新颖视图合成是可迁移的'}
{'arxiv_id': 'arXiv:2510.13062', 'title': 'Towards Human-Centric Intelligent Treatment Planning for Radiation Therapy', 'authors': 'Adnan Jafar, Xun Jia', 'link': 'https://arxiv.org/abs/2510.13062', 'abstract': 'Current radiation therapy treatment planning is limited by suboptimal plan quality, inefficiency, and high costs. This perspective paper explores the complexity of treatment planning and introduces Human-Centric Intelligent Treatment Planning (HCITP), an AI-driven framework under human oversight, which integrates clinical guidelines, automates plan generation, and enables direct interactions with operators. We expect that HCITP will enhance efficiency, potentially reducing planning time to minutes, and will deliver personalized, high-quality plans. Challenges and potential solutions are discussed.', 'abstract_zh': '当前的放射治疗计划受限于计划质量不佳、效率低和成本高。本文探讨了治疗计划的复杂性，并介绍了在人类监督下由AI驱动的人本智能治疗计划（HCITP）框架，该框架结合临床指南，自动化计划生成，并允许与操作员直接交互。我们期望HCITP能够提高效率， potentially 将规划时间缩短至几分钟，并提供个性化、高质量的计划。讨论了挑战及潜在解决方案。', 'title_zh': '面向以人为本的智能放疗计划制定'}
{'arxiv_id': 'arXiv:2510.13054', 'title': 'VLA-0: Building State-of-the-Art VLAs with Zero Modification', 'authors': 'Ankit Goyal, Hugo Hadfield, Xuning Yang, Valts Blukis, Fabio Ramos', 'link': 'https://arxiv.org/abs/2510.13054', 'abstract': 'Vision-Language-Action models (VLAs) hold immense promise for enabling generalist robot manipulation. However, the best way to build them remains an open question. Current approaches often add complexity, such as modifying the existing vocabulary of a Vision-Language Model (VLM) with action tokens or introducing special action heads. Curiously, the simplest strategy of representing actions directly as text has remained largely unexplored. This work introduces VLA-0 to investigate this idea. We find that VLA-0 is not only effective; it is surprisingly powerful. With the right design, VLA-0 outperforms more involved models. On LIBERO, a popular benchmark for evaluating VLAs, VLA-0 outperforms all existing methods trained on the same robotic data, including $\\pi_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without large-scale robotics-specific training, it outperforms methods trained on large-scale robotic data, like $\\pi_0.5$-KI, $\\pi_0$, GR00T-N1 and MolmoAct. These findings also translate to the real world, where VLA-0 outperforms SmolVLA, a VLA model pre-trained on large-scale real data. This paper summarizes our unexpected findings and spells out the specific techniques required to unlock the high performance of this simple yet potent VLA design. Visual results, code, and trained models are provided here: this https URL.', 'abstract_zh': 'Vision-Language-Action模型（VLAs）在实现通用机器人操作方面展现出巨大的潜力。然而，如何构建它们仍然是一个开放的问题。当前的方法往往增加了复杂性，例如通过在视觉-语言模型（VLM）的现有词汇表中添加动作标记或将特殊动作头引入系统。有趣的是，直接将动作表示为文本的最简单策略仍未得到充分探索。本文引入了VLA-0来研究这一想法。我们发现，VLA-0不仅有效，而且出人意料地强大。通过合适的 designs，VLA-0 性能超过了更复杂的模型。在 LIBERO 这一流行的 VLAs 评估基准测试中，VLA-0 在使用相同机器人数据训练的所有现有方法中表现最佳，包括 $\\pi_0.5$-KI、OpenVLA-OFT 和 SmolVLA。此外，即使没有大规模的特定于机器人训练，它也超过了在大规模机器人数据上训练的方法，如 $\\pi_0.5$-KI、$\\pi_0$、GR00T-N1 和 MolmoAct。这些发现也适用于现实世界，在那里 VLA-0 在 SmolVLA 上表现更好，SmolVLA 是在大规模真实数据上预训练的 VLA 模型。本文总结了我们意想不到的发现，并详细说明了解锁这种简单而强大的 VLA 设计高性能所需的具体技术。视觉结果、代码和训练模型在此处提供：this https URL。', 'title_zh': 'VLA-0: 构建零修改状态下的一流VLAs'}
{'arxiv_id': 'arXiv:2510.13052', 'title': 'Time-Varying Optimization for Streaming Data Via Temporal Weighting', 'authors': 'Muhammad Faraz Ul Abrar, Nicolò Michelusi, Erik G. Larsson', 'link': 'https://arxiv.org/abs/2510.13052', 'abstract': "Classical optimization theory deals with fixed, time-invariant objective functions. However, time-varying optimization has emerged as an important subject for decision-making in dynamic environments. In this work, we study the problem of learning from streaming data through a time-varying optimization lens. Unlike prior works that focus on generic formulations, we introduce a structured, \\emph{weight-based} formulation that explicitly captures the streaming-data origin of the time-varying objective, where at each time step, an agent aims to minimize a weighted average loss over all the past data samples. We focus on two specific weighting strategies: (1) uniform weights, which treat all samples equally, and (2) discounted weights, which geometrically decay the influence of older data. For both schemes, we derive tight bounds on the ``tracking error'' (TE), defined as the deviation between the model parameter and the time-varying optimum at a given time step, under gradient descent (GD) updates. We show that under uniform weighting, the TE vanishes asymptotically with a $\\mathcal{O}(1/t)$ decay rate, whereas discounted weighting incurs a nonzero error floor controlled by the discount factor and the number of gradient updates performed at each time step. Our theoretical findings are validated through numerical simulations.", 'abstract_zh': '经典优化理论处理固定的时间不变目标函数。然而，时间varying优化已成为在动态环境中决策的重要主题。在本文中，我们从时间varying优化的角度研究通过流式数据学习的问题。与以往主要关注通用形式的研究不同，我们引入了一种结构化的、基于权重的形式化方法，明确捕捉了时间varying目标的流式数据起源，在每一步，代理目标是最小化所有过去数据样本的加权平均损失。我们关注两种具体权重策略：（1）均匀权重，对所有样本给予同等对待；（2）折扣权重，几何衰减较早数据的影响。对于这两种方案，我们在梯度下降（GD）更新下推导出“跟踪误差”（TE）的紧界，定义为模型参数与给定时间步的时间varying最优解之间的偏差。我们证明，在均匀加权的情况下，TE以$\\mathcal{O}(1/t)$的衰减率渐近消失，而折扣加权则会产生由折扣因子和每一步执行的梯度更新次数控制的非零误差底限。我们的理论发现通过数值仿真得到了验证。', 'title_zh': '基于时间加权的流数据时变优化'}
{'arxiv_id': 'arXiv:2510.13044', 'title': 'SceneAdapt: Scene-aware Adaptation of Human Motion Diffusion', 'authors': 'Jungbin Cho, Minsu Kim, Jisoo Kim, Ce Zheng, Laszlo A. Jeni, Ming-Hsuan Yang, Youngjae Yu, Seonjoo Kim', 'link': 'https://arxiv.org/abs/2510.13044', 'abstract': 'Human motion is inherently diverse and semantically rich, while also shaped by the surrounding scene. However, existing motion generation approaches address either motion semantics or scene-awareness in isolation, since constructing large-scale datasets with both rich text--motion coverage and precise scene interactions is extremely challenging. In this work, we introduce SceneAdapt, a framework that injects scene awareness into text-conditioned motion models by leveraging disjoint scene--motion and text--motion datasets through two adaptation stages: inbetweening and scene-aware inbetweening. The key idea is to use motion inbetweening, learnable without text, as a proxy task to bridge two distinct datasets and thereby inject scene-awareness to text-to-motion models. In the first stage, we introduce keyframing layers that modulate motion latents for inbetweening while preserving the latent manifold. In the second stage, we add a scene-conditioning layer that injects scene geometry by adaptively querying local context through cross-attention. Experimental results show that SceneAdapt effectively injects scene awareness into text-to-motion models, and we further analyze the mechanisms through which this awareness emerges. Code and models will be released.', 'abstract_zh': 'SceneAdapt：通过场景适配注入语境意识的文本条件运动生成框架', 'title_zh': 'SceneAdapt: 基于场景的 humanoid 运动扩散适配'}
{'arxiv_id': 'arXiv:2510.13042', 'title': 'SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models', 'authors': 'Zhengxu Tang, Zizheng Wang, Luning Wang, Zitao Shuai, Chenhao Zhang, Siyu Qian, Yirui Wu, Bohao Wang, Haosong Rao, Zhenyu Yang, Chenwei Wu', 'link': 'https://arxiv.org/abs/2510.13042', 'abstract': 'Text-to-video (T2V) generation models have made significant progress in creating visually appealing videos. However, they struggle with generating coherent sequential narratives that require logical progression through multiple events. Existing T2V benchmarks primarily focus on visual quality metrics but fail to evaluate narrative coherence over extended sequences. To bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating sequential narrative coherence in T2V generation. SeqBench includes a carefully designed dataset of 320 prompts spanning various narrative complexities, with 2,560 human-annotated videos generated from 8 state-of-the-art T2V models. Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic evaluation metric, which can efficiently capture long-range dependencies and temporal ordering while maintaining computational efficiency. Our DTG-based metric demonstrates a strong correlation with human annotations. Through systematic evaluation using SeqBench, we reveal critical limitations in current T2V models: failure to maintain consistent object states across multi-action sequences, physically implausible results in multi-object scenarios, and difficulties in preserving realistic timing and ordering relationships between sequential actions. SeqBench provides the first systematic framework for evaluating narrative coherence in T2V generation and offers concrete insights for improving sequential reasoning capabilities in future models. Please refer to this https URL for more details.', 'abstract_zh': '基于文本生成视频（Text-to-video，T2V）模型在生成视觉吸引力的视频方面取得了显著进步。然而，它们在生成需要通过多个事件进行逻辑进展的连贯序列叙事方面存在问题。现有的T2V基准主要关注视觉质量指标，但未能评估扩展序列中的叙述连贯性。为弥补这一不足，我们提出了SeqBench，一个用于评估T2V生成中序列叙述连贯性的综合性基准。SeqBench包含一个精心设计的数据集，涵盖各种叙事复杂性，共计320个提示，生成了2,560个人工标注的视频，来自8个最先进的T2V模型。此外，我们设计了一种基于动态时间图（Dynamic Temporal Graphs，DTG）的自动评估指标，该指标可以高效地捕捉长程依赖性和时间顺序关系，同时保持计算效率。我们的基于DTG的指标与人工标注具有很强的相关性。通过使用SeqBench进行系统的评估，我们揭示了当前T2V模型的关键局限性：在多动作序列中保持对象状态一致性的失败、在多对象场景中的物理不合理结果以及在保持顺序动作之间现实的时间和顺序关系方面的困难。SeqBench提供了第一个系统框架来评估T2V生成中的叙述连贯性，并为提高未来模型的序列推理能力提供了具体的见解。请参阅此链接以获取更多详细信息。', 'title_zh': 'SeqBench: Text-to-Video模型中序列叙事生成的基准测试'}
{'arxiv_id': 'arXiv:2510.13040', 'title': 'Randomness and Interpolation Improve Gradient Descent', 'authors': 'Jiawen Li, Pascal Lefevre, Anwar Pp Abdul Majeed', 'link': 'https://arxiv.org/abs/2510.13040', 'abstract': 'Based on Stochastic Gradient Descent (SGD), the paper introduces two optimizers, named Interpolational Accelerating Gradient Descent (IAGD) as well as Noise-Regularized Stochastic Gradient Descent (NRSGD). IAGD leverages second-order Newton Interpolation to expedite the convergence process during training, assuming relevancy in gradients between iterations. To avoid over-fitting, NRSGD incorporates a noise regularization technique that introduces controlled noise to the gradients during the optimization process. Comparative experiments of this research are conducted on the CIFAR-10, and CIFAR-100 datasets, benchmarking different CNNs(Convolutional Neural Networks) with IAGD and NRSGD against classical optimizers in Keras Package. Results demonstrate the potential of those two viable improvement methods in SGD, implicating the effectiveness of the advancements.', 'abstract_zh': '基于随机梯度下降的插值加速梯度下降及其噪声正则化随机梯度下降算法的研究与比较', 'title_zh': '随机性与插值改进梯度下降'}
{'arxiv_id': 'arXiv:2510.13011', 'title': 'Deliberate Lab: A Platform for Real-Time Human-AI Social Experiments', 'authors': 'Crystal Qian, Vivian Tsai, Michael Behr, Nada Hussein, Léo Laugier, Nithum Thain, Lucas Dixon', 'link': 'https://arxiv.org/abs/2510.13011', 'abstract': 'Social and behavioral scientists increasingly aim to study how humans interact, collaborate, and make decisions alongside artificial intelligence. However, the experimental infrastructure for such work remains underdeveloped: (1) few platforms support real-time, multi-party studies at scale; (2) most deployments require bespoke engineering, limiting replicability and accessibility, and (3) existing tools do not treat AI agents as first-class participants. We present Deliberate Lab, an open-source platform for large-scale, real-time behavioral experiments that supports both human participants and large language model (LLM)-based agents. We report on a 12-month public deployment of the platform (N=88 experimenters, N=9195 experiment participants), analyzing usage patterns and workflows. Case studies and usage scenarios are aggregated from platform users, complemented by in-depth interviews with select experimenters. By lowering technical barriers and standardizing support for hybrid human-AI experimentation, Deliberate Lab expands the methodological repertoire for studying collective decision-making and human-centered AI.', 'abstract_zh': 'Deliberate Lab：一个支持大规模实时行为实验的开源平台，兼顾人类参与者和基于大型语言模型的代理', 'title_zh': 'Deliberate Lab: 一个人机实时社会实验平台'}
{'arxiv_id': 'arXiv:2510.13009', 'title': 'Developing and Validating the Arabic Version of the Attitudes Toward Large Language Models Scale', 'authors': 'Basad Barajeeh, Ala Yankouskaya, Sameha AlShakhsi, Chun Sing Maxwell Ho, Guandong Xu, Raian Ali', 'link': 'https://arxiv.org/abs/2510.13009', 'abstract': 'As the use of large language models (LLMs) becomes increasingly global, understanding public attitudes toward these systems requires tools that are adapted to local contexts and languages. In the Arab world, LLM adoption has grown rapidly with both globally dominant platforms and regional ones like Fanar and Jais offering Arabic-specific solutions. This highlights the need for culturally and linguistically relevant scales to accurately measure attitudes toward LLMs in the region. Tools assessing attitudes toward artificial intelligence (AI) can provide a base for measuring attitudes specific to LLMs. The 5-item Attitudes Toward Artificial Intelligence (ATAI) scale, which measures two dimensions, the AI Fear and the AI Acceptance, has been recently adopted and adapted to develop new instruments in English using a sample from the UK: the Attitudes Toward General LLMs (AT-GLLM) and Attitudes Toward Primary LLM (AT-PLLM) scales. In this paper, we translate the two scales, AT-GLLM and AT-PLLM, and validate them using a sample of 249 Arabic-speaking adults. The results show that the scale, translated into Arabic, is a reliable and valid tool that can be used for the Arab population and language. Psychometric analyses confirmed a two-factor structure, strong measurement invariance across genders, and good internal reliability. The scales also demonstrated strong convergent and discriminant validity. Our scales will support research in a non-Western context, a much-needed effort to help draw a global picture of LLM perceptions, and will also facilitate localized research and policy-making in the Arab region.', 'abstract_zh': '随着大型语言模型（LLMs）的全球使用日益普遍，理解公众对这些系统的态度需要适应当地文化和语言的工具。在阿拉伯世界，LLM的采用迅速增长，无论是全球主导平台还是区域平台如Fanar和Jais都提供了阿拉伯语特定的解决方案。这突显了在该地区准确衡量LLM态度所需的文化和语言相关量表的需求。评估人工智能（AI）态度的工具可以为评估特定于LLM的态度提供基础。包含5项的AI态度量表（ATAI），测量了两个维度——AI恐惧和AI接受， recently被采用并在英国样本中被改编为评估一般LLM（AT-GLLM）和主要LLM（AT-PLLM）态度的新工具。本文中，我们翻译了这两个量表AT-GLLM和AT-PLLM，并使用249名阿拉伯语成年样本进行了验证。结果显示，翻译后的量表是一个可靠且有效的工具，适用于阿拉伯人口和语言。心理学测量分析确认了其双因素结构、性别间的强测量不变性和良好的内部一致性。量表还展示了强的聚合效度和区分效度。我们的量表将支持非西方背景下的研究，有助于绘制全球LLM感知的图景，同时也有助于阿拉伯地区的本地化研究和政策制定。', 'title_zh': '开发并验证阿拉伯版本的大规模语言模型态度量表'}
{'arxiv_id': 'arXiv:2510.13008', 'title': 'CurLL: A Developmental Framework to Evaluate Continual Learning in Language Models', 'authors': 'Pavan Kalyan, Shubhra Mishra, Satya Lokam, Navin Goyal', 'link': 'https://arxiv.org/abs/2510.13008', 'abstract': "We introduce a comprehensive continual learning dataset and benchmark (CurlL) grounded in human developmental trajectories from ages 5-10, enabling systematic and fine-grained assessment of models' ability to progressively acquire new skills. CurlL spans five developmental stages (0-4) covering ages 5-10, supported by a skill graph that breaks down broad skills into smaller abilities, concrete goals, and measurable indicators, while also capturing which abilities build on others. We generate a 23.4B-token synthetic dataset with controlled skill progression, vocabulary complexity, and format diversity, comprising paragraphs, comprehension-based QA (CQA), skill-testing QA (CSQA), and instruction-response (IR) pairs. Stage-wise token counts range from 2.12B to 6.78B tokens, supporting precise analysis of forgetting, forward transfer, and backward transfer. Using a 135M-parameter transformer trained under independent, joint, and sequential (continual) setups, we show trade-offs in skill retention and transfer efficiency. By mirroring human learning patterns and providing fine-grained control over skill dependencies, this work advances continual learning evaluations for language models.", 'abstract_zh': '我们介绍了一个基于5-10岁人类发展阶段的综合连续学习数据集和基准（CurlL），以系统性和精细地评估模型逐阶段获取新技能的能力。CurlL涵盖了5-10岁的五个发展阶段（0-4），并通过技能图将广泛的技能分解为更小的能力、具体目标和可测量指标，同时捕捉哪些能力建立在其他能力之上。我们生成了一个包含234亿词的合成数据集，具有控制的技能 progression、词汇复杂性和格式多样性，包括段落、基于理解的问答（CQA）、技能测试问答（CSQA）和指令-响应（IR）对。各阶段的词计数范围从21.2亿到67.8亿词，支持对遗忘、前向迁移和后向迁移的精确分析。通过在独立、联合和序列（连续）设置下训练的1.35亿参数变换器，我们展示了技能保持和迁移效率之间的权衡。通过镜像人类学习模式并提供对技能依赖关系的精细控制，本作品推动了语言模型连续学习评估的发展。', 'title_zh': 'CurLL：评估语言模型连续学习能力的发展性框架'}
{'arxiv_id': 'arXiv:2510.12997', 'title': 'Max It or Miss It: Benchmarking LLM On Solving Extremal Problems', 'authors': 'Binxin Gao, Jingjun Han', 'link': 'https://arxiv.org/abs/2510.12997', 'abstract': "Test-time scaling has enabled Large Language Models (LLMs) with remarkable reasoning capabilities, particularly in mathematical domains, through intermediate chain-of-thought (CoT) reasoning before generating final answers. However, the specific sources and mechanisms underlying these reasoning capabilities remain insufficiently understood. Optimization reasoning, i.e. finding extrema under constraints, represents a fundamental abstraction that underpins critical applications in planning, control, resource allocation, and prompt search. To systematically evaluate this capability, we introduce ExtremBench, a benchmark dataset for solving mathematical extremal problems, curated from inequality exercises used for Chinese Mathematical Olympiad and transformed into $93$ standardized extrema-finding problems. We conduct extensive evaluations across various state-of-the-art open-source model families, including the Qwen3, GPT-OSS, and DeepSeek. Our results reveal that LLMs' extremal-solving reasoning capabilities do not always align with those of current mathematical benchmarks such as AIME25 and MATH-500, with some models showing strong general mathematical reasoning but poor extremal-solving skills, and vice versa. This discrepancy highlights a critical gap in current evaluation practices and suggests that existing benchmarks may not comprehensively capture the full spectrum of mathematical reasoning abilities.", 'abstract_zh': 'Test-time 扩容使大语言模型（LLMs）在数学领域等通过中间的逐步推理（CoT）获得显著的推理能力，但在这些推理能力的具体来源和机制方面仍缺乏足够的理解。优化推理，即在约束条件下求极值，是规划、控制、资源分配和提示搜索等关键应用的基础抽象。为了系统评估这一能力，我们引入了 ExtremBench，这是一个来自中国数学奥林匹克不等式练习的标准化极值寻找问题基准数据集。我们在各种最先进的开源模型家族中进行了广泛的评估，包括Qwen3、GPT-OSS和DeepSeek。我们的结果表明，LLMs在解决极值问题的推理能力并不总是与当前的数学基准如AIME25和MATH-500保持一致，一些模型在一般数学推理方面表现强劲但在极值求解方面表现较差，反之亦然。这种差异凸显了当前评估实践中的一个关键差距，并暗示现有的基准可能未能全面捕捉数学推理能力的完整谱系。', 'title_zh': '把握或错过：评估大语言模型解决极值问题的能力'}
{'arxiv_id': 'arXiv:2510.12957', 'title': 'A Multimodal XAI Framework for Trustworthy CNNs and Bias Detection in Deep Representation Learning', 'authors': 'Noor Islam S. Mohammad', 'link': 'https://arxiv.org/abs/2510.12957', 'abstract': 'Standard benchmark datasets, such as MNIST, often fail to expose latent biases and multimodal feature complexities, limiting the trustworthiness of deep neural networks in high-stakes applications. We propose a novel multimodal Explainable AI (XAI) framework that unifies attention-augmented feature fusion, Grad-CAM++-based local explanations, and a Reveal-to-Revise feedback loop for bias detection and mitigation. Evaluated on multimodal extensions of MNIST, our approach achieves 93.2% classification accuracy, 91.6% F1-score, and 78.1% explanation fidelity (IoU-XAI), outperforming unimodal and non-explainable baselines. Ablation studies demonstrate that integrating interpretability with bias-aware learning enhances robustness and human alignment. Our work bridges the gap between performance, transparency, and fairness, highlighting a practical pathway for trustworthy AI in sensitive domains.', 'abstract_zh': '标准基准数据集，如MNIST，经常无法揭示潜在偏见和多模态特征的复杂性，限制了深度神经网络在高风险应用中的可信度。我们提出了一种新颖的多模态可解释AI（XAI）框架，该框架统一了注意力增强特征融合、基于Grad-CAM++的地方解释，以及一个揭示-修正反馈循环，用于偏见检测和缓解。在MNIST的多模态扩展上评估，我们的方法实现了93.2%的分类准确率、91.6%的F1分数和78.1%的解释保真度（IoU-XAI），优于单一模态和非解释性基线。消融研究显示，将可解释性与意识偏见学习集成可以提高鲁棒性和人类一致性。我们的工作在性能、透明度和公平性之间架起了桥梁，突显了敏感领域可信AI的实际路径。', 'title_zh': '多模态XAI框架在深度表示学习中的可信赖CNNs和偏见检测'}
{'arxiv_id': 'arXiv:2510.12953', 'title': 'Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation', 'authors': 'Xiao He, Huangxuan Zhao, Guojia Wan, Wei Zhou, Yanxing Liu, Juhua Liu, Yongchao Xu, Yong Luo, Dacheng Tao, Bo Du', 'link': 'https://arxiv.org/abs/2510.12953', 'abstract': "Recent medical vision-language models have shown promise on tasks such as VQA, report generation, and anomaly detection. However, most are adapted to structured adult imaging and underperform in fetal ultrasound, which poses challenges of multi-view image reasoning, numerous diseases, and image diversity. To bridge this gap, we introduce FetalMind, a medical AI system tailored to fetal ultrasound for both report generation and diagnosis. Guided by clinical workflow, we propose Salient Epistemic Disentanglement (SED), which injects an expert-curated bipartite graph into the model to decouple view-disease associations and to steer preference selection along clinically faithful steps via reinforcement learning. This design mitigates variability across diseases and heterogeneity across views, reducing learning bottlenecks while aligning the model's inference with obstetric practice. To train FetalMind at scale, we curate FetalSigma-1M dataset, the first large-scale fetal ultrasound report corpus, comprising 20K reports from twelve medical centers, addressing the scarcity of domain data. Extensive experiments show that FetalMind outperforms open- and closed-source baselines across all gestational stages, achieving +14% average gains and +61.2% higher accuracy on critical conditions while remaining efficient, stable, and scalable. Project Page: this https URL.", 'abstract_zh': '_recent医疗视觉语言模型在VQA、报告生成和异常检测等任务上展示了潜力。然而，大多数模型适应于结构化的成人影像，在胎儿超声波成像中表现不佳，这带来了多视角图像推理、多种疾病和图像多样性等方面的挑战。为解决这一问题，我们提出了FetalMind，一种针对胎儿超声波成像的医疗AI系统，用于报告生成和诊断。受临床工作流程的指导，我们提出了显着表征脱耦（SED）方法，该方法通过强化学习将专家编纂的二分图注入模型中，以解除视角-疾病关联，并沿着临床忠实的步骤引导偏好选择。该设计减少了疾病间的变异性以及视角间的异质性，降低了学习瓶颈，同时使模型的推断与产科实践保持一致。为了大规模训练FetalMind，我们构建了FetalSigma-1M数据集，这是首个大型胎儿超声波报告语料库，包含来自十二家医疗机构的20000份报告，解决了领域数据稀缺的问题。大规模实验表明，FetalMind在所有妊娠阶段的表现均优于开源和闭源基线，关键条件下准确率提高了61.2%，且保持高效、稳定和可扩展。_', 'title_zh': '知觉意识导向的视觉-语言基础模型在胎儿超声解释中的应用'}
{'arxiv_id': 'arXiv:2510.12948', 'title': 'SpareCodeSearch: Searching for Code Context When You Have No Spare GPU', 'authors': 'Minh Nguyen', 'link': 'https://arxiv.org/abs/2510.12948', 'abstract': "Retrieval-Augmented Generation (RAG) frameworks aim to enhance Code Language Models (CLMs) by including another module for retrieving relevant context to construct the input prompt. However, these retrieval modules commonly use semantic search, requiring substantial computational resources for training and hosting these embedded models, making them infeasible to integrate into lightweight applications such as in-IDE AI-based code completion. In this solution paper, we prove that using keyword-search is sufficient to retrieve relevant and useful code context inside large codebases, without the need for extensive GPU resources. The usefulness of code contexts found by our solution is demonstrated through their completion results on the Code Context Competition's benchmark, reaching 0.748 and 0.725 chRF scores on Kotlin and Python tracks, respectively.", 'abstract_zh': '检索增强生成（RAG）框架旨在通过纳入另一个检索相关上下文的模块来提升代码语言模型（CLMs）。然而，这些检索模块通常使用语义搜索，需要大量的计算资源进行训练和托管，使得它们难以集成到轻量级应用中，如IDE中的AI代码补全。在本解决方案论文中，我们证明，在大型代码库中使用关键词搜索足以检索相关和有用的代码上下文，无需大量GPU资源。通过在Code Context Competition基准上的完成结果展示了我们解决方案找到的代码上下文的有效性，Kotlin赛道和Python赛道分别达到了0.748和0.725的chRF分数。', 'title_zh': 'SpareCodeSearch: 查找代码上下文时的GPU资源搜索'}
{'arxiv_id': 'arXiv:2510.12947', 'title': 'HyWA: Hypernetwork Weight Adapting Personalized Voice Activity Detection', 'authors': 'Mahsa Ghazvini Nejad, Hamed Jafarzadeh Asl, Amin Edraki, Mohammadreza Sadeghi, Masoud Asgharian, Yuanhao Yu, Vahid Partovi Nia', 'link': 'https://arxiv.org/abs/2510.12947', 'abstract': 'Personalized Voice Activity Detection (PVAD) systems activate only in response to a specific target speaker by incorporating speaker embeddings from enrollment utterances. Unlike existing methods that require architectural changes, such as FiLM layers, our approach employs a hypernetwork to modify the weights of a few selected layers within a standard voice activity detection (VAD) model. This enables speaker conditioning without changing the VAD architecture, allowing the same VAD model to adapt to different speakers by updating only a small subset of the layers. We propose HyWA-PVAD, a hypernetwork weight adaptation method, and evaluate it against multiple baseline conditioning techniques. Our comparison shows consistent improvements in PVAD performance. HyWA also offers practical advantages for deployment by preserving the core VAD architecture. Our new approach improves the current conditioning techniques in two ways: i) increases the mean average precision, ii) simplifies deployment by reusing the same VAD architecture.', 'abstract_zh': '个性化语音活动检测（PVAD）系统仅在特定目标说话人出现时激活，通过结合注册语音片段的说话人嵌入。不同于现有需要更改架构的方法，如FiLM层，我们的方法使用超网络调整标准语音活动检测（VAD）模型中几层的权重，从而无需改变VAD架构即可实现说话人条件化，使相同的VAD模型通过更新少量层来适应不同的说话人。我们提出了HyWA-PVAD，一种超网络权重适应方法，并将其与多种基线条件化技术进行了评估。我们的比较显示PVAD性能的一致改进。HyWA还通过保留核心VAD架构提供了部署上的实际优势。我们新的方法通过两种方式改进了当前的条件化技术：i) 提高平均精确度均值，ii) 通过重用相同的VAD架构简化部署。', 'title_zh': 'HyWA：超网络权重适配个性化语音活动检测'}
{'arxiv_id': 'arXiv:2510.12920', 'title': 'InferA: A Smart Assistant for Cosmological Ensemble Data', 'authors': 'Justin Z. Tam, Pascal Grosset, Divya Banesh, Nesar Ramachandra, Terece L. Turton, James Ahrens', 'link': 'https://arxiv.org/abs/2510.12920', 'abstract': "Analyzing large-scale scientific datasets presents substantial challenges due to their sheer volume, structural complexity, and the need for specialized domain knowledge. Automation tools, such as PandasAI, typically require full data ingestion and lack context of the full data structure, making them impractical as intelligent data analysis assistants for datasets at the terabyte scale. To overcome these limitations, we propose InferA, a multi-agent system that leverages large language models to enable scalable and efficient scientific data analysis. At the core of the architecture is a supervisor agent that orchestrates a team of specialized agents responsible for distinct phases of the data retrieval and analysis. The system engages interactively with users to elicit their analytical intent and confirm query objectives, ensuring alignment between user goals and system actions. To demonstrate the framework's usability, we evaluate the system using ensemble runs from the HACC cosmology simulation which comprises several terabytes.", 'abstract_zh': '大规模科学数据集的分析面临着由于数据量巨大、结构复杂以及需要专门领域知识所带来的重大挑战。现有的自动化工具，如PandasAI，通常需要完整导入数据并且缺乏对完整数据结构的背景信息，使得它们在处理太字节规模的数据集时难以成为智能数据分析助理。为克服这些限制，我们提出了一种基于多代理系统的InferA，该系统利用大型语言模型以实现可扩展和高效的科学数据分析。该体系结构的核心是一个协调代理，它协调一支专门代理队伍，负责数据分析的不同阶段。系统会与用户进行互动，了解用户的分析意图并确认查询目标，确保用户目标与系统行为之间的对齐。为展示该框架的易用性，我们使用来自HACC宇宙学模拟的数据集进行了集成运行，该数据集包含数太字节的数据。', 'title_zh': 'InferA：宇宙集合数据的智能助手'}
{'arxiv_id': 'arXiv:2510.12872', 'title': 'KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems', 'authors': 'Hancheng Ye, Zhengqi Gao, Mingyuan Ma, Qinsi Wang, Yuzhe Fu, Ming-Yu Chung, Yueqian Lin, Zhijian Liu, Jianyi Zhang, Danyang Zhuo, Yiran Chen', 'link': 'https://arxiv.org/abs/2510.12872', 'abstract': 'Multi-agent large language model (LLM) systems are increasingly adopted for complex language processing tasks that require communication and coordination among agents. However, these systems often suffer substantial overhead from repeated reprocessing of overlapping contexts across agents. In typical pipelines, once an agent receives a message from its predecessor, the full context-including prior turns-must be reprocessed from scratch, leading to inefficient processing. While key-value (KV) caching is an effective solution for avoiding redundant computation in single-agent settings where prefixes remain unchanged, it cannot be directly reused in multi-agent scenarios due to diverging prefixes introduced by agent-specific context extensions. We identify that the core challenge lies in the offset variance of KV-caches across agents. To address this, we propose KVCOMM, a training-free framework that enables efficient prefilling in multi-agent inference by reusing KV-caches and aligning cache offsets of overlapping contexts under diverse prefix contexts. KVCOMM estimates and adjusts KV-caches for shared content by referencing a pool of cached examples-termed anchors-that store observed cache deviations under varying prefixes. The anchor pool is maintained and updated online, allowing dynamic adaptation to distinct user requests and context structures. KVCOMM achieves over 70% reuse rate across diverse multi-agent workloads, including retrieval-augmented generation, math reasoning, and collaborative coding tasks, all without quality degradation. Particularly, when each fully-connected agent receives 1K input tokens with 512 prefix tokens and 512 output tokens under a five-agent setting, KVCOMM achieves up to 7.8x speedup compared to the standard prefill pipeline, reducing TTFT from ~430 ms to ~55 ms.', 'abstract_zh': '多智能体大型语言模型（LLM）系统在需要智能体之间通信和协调的复杂语言处理任务中日益被采用。然而，这些系统常常因智能体之间重复处理重叠上下文而面临大量开销。在典型的工作流中，一旦一个智能体接收到前一个智能体的消息，整个上下文（包括之前轮次的内容）必须从头开始重新处理，导致不高效的处理。虽然在单智能体场景中，通过对不变前缀利用键值（KV）缓存可有效避免重复计算，但在智能体特定上下文扩展导致前缀变化的情况下，这一方法无法直接复用。我们发现核心挑战在于智能体之间KV缓存偏移量的差异。为解决这一问题，我们提出了KVCOMM，这是一种无需训练的框架，通过复用KV缓存并在各种前缀上下文中对重叠上下文的缓存偏移量进行对齐，实现多智能体推理中的高效预填充。KVCOMM通过参考存储不同前缀下观察到缓存偏差的缓存示例池（称为锚点）来估计和调整共享内容的缓存。该锚点池在线维护和更新，允许动态适应不同的用户请求和上下文结构。KVCOMM在包括检索增强生成、数学推理和协作编程等一系列多智能体工作负载中实现了超过70%的缓存复用率，且无质量下降。特别是在五智能体设定中，每当每个全连接智能体接收到1024个输入令牌（512个前缀令牌和512个输出令牌），KVCOMM与标准预填充流水线相比可获得高达7.8倍的加速，将TTFT从约430毫秒降低到约55毫秒。', 'title_zh': 'KVCOMM: 在线跨上下文键值缓存通信以提高基于LLM的多agents系统的效率'}
{'arxiv_id': 'arXiv:2510.12859', 'title': 'Three Lenses on the AI Revolution: Risk, Transformation, Continuity', 'authors': 'Masoud Makrehchi', 'link': 'https://arxiv.org/abs/2510.12859', 'abstract': 'Artificial Intelligence (AI) has emerged as both a continuation of historical technological revolutions and a potential rupture with them. This paper argues that AI must be viewed simultaneously through three lenses: \\textit{risk}, where it resembles nuclear technology in its irreversible and global externalities; \\textit{transformation}, where it parallels the Industrial Revolution as a general-purpose technology driving productivity and reorganization of labor; and \\textit{continuity}, where it extends the fifty-year arc of computing revolutions from personal computing to the internet to mobile. Drawing on historical analogies, we emphasize that no past transition constituted a strict singularity: disruptive shifts eventually became governable through new norms and institutions.\nWe examine recurring patterns across revolutions -- democratization at the usage layer, concentration at the production layer, falling costs, and deepening personalization -- and show how these dynamics are intensifying in the AI era. Sectoral analysis illustrates how accounting, law, education, translation, advertising, and software engineering are being reshaped as routine cognition is commoditized and human value shifts to judgment, trust, and ethical responsibility. At the frontier, the challenge of designing moral AI agents highlights the need for robust guardrails, mechanisms for moral generalization, and governance of emergent multi-agent dynamics.\nWe conclude that AI is neither a singular break nor merely incremental progress. It is both evolutionary and revolutionary: predictable in its median effects yet carrying singularity-class tail risks. Good outcomes are not automatic; they require coupling pro-innovation strategies with safety governance, ensuring equitable access, and embedding AI within a human order of responsibility.', 'abstract_zh': '人工智能（AI）既是历史技术革命的延续，也可能彻底改变它们。本文认为，AI必须通过三个视角进行审视：风险、转型和延续。', 'title_zh': '人工智能革命的三重审视：风险、转型、连续性'}
{'arxiv_id': 'arXiv:2510.12858', 'title': 'A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation', 'authors': 'Mohammed Hilal Al-Kharusi, Khizar Hayat, Khalil Bader Al Ruqeishi, Haroon Rashid Lone', 'link': 'https://arxiv.org/abs/2510.12858', 'abstract': 'The sacred practice of Quranic recitation (Tajweed), governed by precise phonetic, prosodic, and theological rules, faces significant pedagogical challenges in the modern era. While digital technologies promise unprecedented access to education, automated tools for recitation evaluation have failed to achieve widespread adoption or pedagogical efficacy. This literature review investigates this critical gap, conducting a comprehensive analysis of academic research, web platforms, and commercial applications developed over the past two decades. Our synthesis reveals a fundamental misalignment in prevailing approaches that repurpose Automatic Speech Recognition (ASR) architectures, which prioritize lexical recognition over qualitative acoustic assessment and are plagued by data dependency, demographic biases, and an inability to provide diagnostically useful feedback. Critiquing these data--driven paradigms, we argue for a foundational paradigm shift towards a knowledge-centric computational framework. Capitalizing on the immutable nature of the Quranic text and the precisely defined rules of Tajweed, we propose that a robust evaluator must be architected around anticipatory acoustic modeling based on canonical rules and articulation points (Makhraj), rather than relying on statistical patterns learned from imperfect and biased datasets. This review concludes that the future of automated Quranic evaluation lies in hybrid systems that integrate deep linguistic knowledge with advanced audio analysis, offering a path toward robust, equitable, and pedagogically sound tools that can faithfully support learners worldwide.', 'abstract_zh': '现代时代清真寺诵读（塔吉维德）这一神圣实践所面临的精确音素、韵律和神学规则指导下的重大教学挑战。尽管数字技术承诺带来了前所未有的教育访问机会，但诵读评价的自动化工具尚未实现广泛采用或教学有效性。本文综述探讨了这一关键缺口，对过去二十年间学术研究、网络平台和商业应用进行了全面分析。我们的综述揭示了当前方法的基本不匹配，这些方法重新利用了自动语音识别（ASR）架构，优先考虑词汇识别而非定量声学评估，并且存在数据依赖性、人口统计偏见以及无法提供诊断性反馈的问题。我们批评这些数据驱动的范式，主张向以知识为中心的计算框架转变。利用《古兰经》文本的不变性和塔吉维德规则的精确定义，我们提出了一种强大的评价系统应以基于典范规则和发音点的前瞻声学建模为核心，而不是依赖于从不完美且有偏见的数据集中学习到的统计模式。本文综述认为，未来自动化清真寺诵读评价在于将深厚的语言知识与先进的音频分析相结合的混合系统，为其提供了通往强大、公平且教学上可靠的工具的路径，以诚实地支持全球学习者。', 'title_zh': '对以知识为中心的古兰经诵读评价需求的批判性Review'}
{'arxiv_id': 'arXiv:2510.12857', 'title': 'Adaptive Generation of Bias-Eliciting Questions for LLMs', 'authors': 'Robin Staab, Jasper Dekoninck, Maximilian Baader, Martin Vechev', 'link': 'https://arxiv.org/abs/2510.12857', 'abstract': 'Large language models (LLMs) are now widely deployed in user-facing applications, reaching hundreds of millions worldwide. As they become integrated into everyday tasks, growing reliance on their outputs raises significant concerns. In particular, users may unknowingly be exposed to model-inherent biases that systematically disadvantage or stereotype certain groups. However, existing bias benchmarks continue to rely on templated prompts or restrictive multiple-choice questions that are suggestive, simplistic, and fail to capture the complexity of real-world user interactions. In this work, we address this gap by introducing a counterfactual bias evaluation framework that automatically generates realistic, open-ended questions over sensitive attributes such as sex, race, or religion. By iteratively mutating and selecting bias-inducing questions, our approach systematically explores areas where models are most susceptible to biased behavior. Beyond detecting harmful biases, we also capture distinct response dimensions that are increasingly relevant in user interactions, such as asymmetric refusals and explicit acknowledgment of bias. Leveraging our framework, we construct CAB, a human-verified benchmark spanning diverse topics, designed to enable cross-model comparisons. Using CAB, we analyze a range of LLMs across multiple bias dimensions, revealing nuanced insights into how different models manifest bias. For instance, while GPT-5 outperforms other models, it nonetheless exhibits persistent biases in specific scenarios. These findings underscore the need for continual improvements to ensure fair model behavior.', 'abstract_zh': '大型语言模型（LLMs）现在广泛应用于面向用户的应用程序中，全球范围内已有数亿用户在使用。随着它们被整合到日常任务中，对它们输出结果的依赖增长，引发了重大关切。特别是用户可能无意中暴露于模型固有的偏见中，系统性地对某些群体造成不利影响或刻板印象。然而，现有的偏见基准仍依赖于模板化的提示或限制性选择题，这些题目暗示性强、简单化且未能捕捉到现实世界用户交互的复杂性。在此项工作中，我们通过引入一种反事实偏见评估框架来填补这一空白，该框架能够自动生成关于敏感属性（如性别、种族或宗教）的真实且开放性问题。通过迭代地变异和选择诱导偏见的问题，我们的方法系统性地探索模型最容易表现出偏见行为的区域。除了检测有害偏见外，我们还捕捉到在用户交互中越来越重要的反应维度，如不对称拒绝和明确承认偏见。利用我们的框架，我们构建了CAB基准，这是一个由人工验证覆盖广泛主题的基准，旨在实现跨模型比较。使用CAB，我们在多个偏见维度上分析了一系列LLM，揭示出不同模型表现偏见的复杂洞察。例如，虽然GPT-5表现优于其他模型，但在特定场景中仍表现出持久的偏见。这些发现强调了持续改进以确保公平模型行为的必要性。', 'title_zh': '适应性生成引发偏差问题的对话生成方法'}
{'arxiv_id': 'arXiv:2510.12856', 'title': 'Efficient Adaptive Transformer: An Empirical Study and Reproducible Framework', 'authors': 'Jan Miller', 'link': 'https://arxiv.org/abs/2510.12856', 'abstract': 'The Efficient Adaptive Transformer (EAT) framework unifies three adaptive efficiency techniques - progressive token pruning, sparse attention, and dynamic early exiting - into a single, reproducible architecture for input-adaptive inference. EAT provides an open-source benchmarking pipeline that automates data processing, timing, and ablation across GLUE tasks (SST-2, QQP, MNLI). Although this empirical study finds that combining these mechanisms can increase latency in shallow six-layer models, it demonstrates that EAT achieves slightly higher accuracy than the optimized DistilBERT baseline on SST-2, illustrating the potential of dynamic computation for latency-sensitive NLP. The main contribution is the open, end-to-end reproducible framework - complete with scripts, CSV logging, and analysis utilities - intended to serve as a community tool for further research on adaptive transformers.', 'abstract_zh': 'EAT框架：结合渐进式 token 剪枝、稀疏注意和动态早期退出的高效自适应变压器', 'title_zh': '高效自适应Transformer：实证研究与可复现框架'}
{'arxiv_id': 'arXiv:2510.12850', 'title': 'Ethic-BERT: An Enhanced Deep Learning Model for Ethical and Non-Ethical Content Classification', 'authors': 'Mahamodul Hasan Mahadi, Md. Nasif Safwan, Souhardo Rahman, Shahnaj Parvin, Aminun Nahar, Kamruddin Nur', 'link': 'https://arxiv.org/abs/2510.12850', 'abstract': 'Developing AI systems capable of nuanced ethical reasoning is critical as they increasingly influence human decisions, yet existing models often rely on superficial correlations rather than principled moral understanding. This paper introduces Ethic-BERT, a BERT-based model for ethical content classification across four domains: Commonsense, Justice, Virtue, and Deontology. Leveraging the ETHICS dataset, our approach integrates robust preprocessing to address vocabulary sparsity and contextual ambiguities, alongside advanced fine-tuning strategies like full model unfreezing, gradient accumulation, and adaptive learning rate scheduling. To evaluate robustness, we employ an adversarially filtered "Hard Test" split, isolating complex ethical dilemmas. Experimental results demonstrate Ethic-BERT\'s superiority over baseline models, achieving 82.32% average accuracy on the standard test, with notable improvements in Justice and Virtue. In addition, the proposed Ethic-BERT attains 15.28% average accuracy improvement in the HardTest. These findings contribute to performance improvement and reliable decision-making using bias-aware preprocessing and proposed enhanced AI model.', 'abstract_zh': '发展能够进行精细伦理推理的AI系统对于它们在日益影响人类决策的过程中至关重要，但现有模型往往依赖肤浅的相关性而非基本原则性的道德理解。本文介绍了Ethic-BERT，这是一种基于BERT的模型，用于在常识、正义、美德和德里达四种领域内伦理内容分类。利用ETHICS数据集，我们的方法通过 robust 预处理来解决词汇稀疏性和语境模糊性问题，并采用全模型解冻、梯度累积和自适应学习率调度等高级微调策略。为了评估鲁棒性，我们采用了一种对抗性过滤的“Hard Test”划分，隔离复杂伦理困境。实验结果表明，Ethic-BERT 在标准测试集上平均准确率达到 82.32%，在正义和美德领域表现出显著改进。此外，提出的 Ethic-BERT 在 HardTest 上获得 15.28% 的平均准确率改进。这些发现为使用具有偏见意识的预处理和提出的增强AI模型提高性能和可靠决策做出了贡献。', 'title_zh': 'Ethic-BERT：一种增强的深度学习模型，用于伦理与非伦理内容分类'}
{'arxiv_id': 'arXiv:2510.12845', 'title': 'VLURes: Benchmarking VLM Visual and Linguistic Understanding in Low-Resource Languages', 'authors': 'Jesse Atuhurra, Iqra Ali, Tomoya Iwakura, Hidetaka Kamigaito, Tatsuya Hiraoka', 'link': 'https://arxiv.org/abs/2510.12845', 'abstract': "Vision Language Models (VLMs) are pivotal for advancing perception in intelligent agents. Yet, evaluation of VLMs remains limited to predominantly English-centric benchmarks in which the image-text pairs comprise short texts. To evaluate VLM fine-grained abilities, in four languages under long-text settings, we introduce a novel multilingual benchmark VLURes featuring eight vision-and-language tasks, and a pioneering unrelatedness task, to probe the fine-grained Visual and Linguistic Understanding capabilities of VLMs across English, Japanese, and low-resource languages, Swahili, and Urdu. Our datasets, curated from web resources in the target language, encompass ten diverse image categories and rich textual context, introducing valuable vision-language resources for Swahili and Urdu. By prompting VLMs to generate responses and rationales, evaluated automatically and by native speakers, we uncover performance disparities across languages and tasks critical to intelligent agents, such as object recognition, scene understanding, and relationship understanding. We conducted evaluations of ten VLMs with VLURes. The best performing model, GPT-4o, achieves an overall accuracy of 90.8% and lags human performance by 6.7%, though the gap is larger for open-source models. The gap highlights VLURes' critical role in developing intelligent agents to tackle multi-modal visual reasoning.", 'abstract_zh': '多语言VLURes基准：跨英语、日语及低资源语言的精细视觉与语言理解评估', 'title_zh': 'VLURes: 低资源语言视觉和语言理解基准研究'}
{'arxiv_id': 'arXiv:2510.12839', 'title': 'FaStFACT: Faster, Stronger Long-Form Factuality Evaluations in LLMs', 'authors': 'Yingjia Wan, Haochen Tan, Xiao Zhu, Xinyu Zhou, Zhiwei Li, Qingsong Lv, Changxuan Sun, Jiaqi Zeng, Yi Xu, Jianqiao Lu, Yinhong Liu, Zhijiang Guo', 'link': 'https://arxiv.org/abs/2510.12839', 'abstract': 'Evaluating the factuality of long-form generations from Large Language Models (LLMs) remains challenging due to accuracy issues and costly human assessment. Prior efforts attempt this by decomposing text into claims, searching for evidence, and verifying claims, but suffer from critical drawbacks: (1) inefficiency due to complex pipeline components unsuitable for long LLM outputs, and (2) ineffectiveness stemming from inaccurate claim sets and insufficient evidence collection of one-line snippets.\nTo address these limitations, we propose \\name, a fast and strong evaluation framework that achieves the highest alignment with human evaluation and efficiency among existing baselines. \\name first employs chunk-level claim extraction integrated with confidence-based pre-verification, significantly reducing the cost of web searching and inference calling while ensuring reliability. For searching and verification, it collects document-level evidence from crawled webpages and selectively retrieves it during verification, addressing the evidence insufficiency problem in previous pipelines.\nExtensive experiments based on an aggregated and manually annotated benchmark demonstrate the reliability of \\name in both efficiently and effectively evaluating the factuality of long-form LLM generations. Code and benchmark data is available at this https URL.', 'abstract_zh': '评估大型语言模型（LLMs）生成的长文内容的事实性仍具有挑战性，主要由于准确性问题和高昂的人工评估成本。先前的努力试图通过分解文本为断言、搜索证据和验证断言来实现这一目标，但存在关键缺陷：（1）由于复杂的流水线组件不适合长LLM输出，导致效率低下；（2）由于断言集不准确和单行片段证据收集不足，导致效果不佳。\n\n为解决这些局限性，我们提出了一种名为\\name的快速且强大的评估框架，能够在现有基线中实现与人工评估最高的一致性和效率。\\name首先采用基于片段级别的断言提取，并结合基于信心的预验证，大幅降低了网络搜索和推理调用的成本，同时确保可靠性。在搜索和验证阶段，它从抓取的网页中收集文档级别的证据，并在验证过程中选择性地检索，解决了先前流水线中的证据不足问题。\n\n基于汇总和手动标注的基准进行的大量实验表明，\\name能有效地和高效地评估长文LLM生成内容的事实性。代码和基准数据可在以下链接获取。', 'title_zh': 'FaStFACT: 更快速更强的长文本事实性评估方法'}
{'arxiv_id': 'arXiv:2510.12838', 'title': 'A\\textsuperscript{2}FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning', 'authors': 'Qianben Chen, Jingyi Cao, Jiayu Zhang, Tianrui Qin, Xiaowan Li, King Zhu, Dingfeng Shi, He Zhu, Minghao Liu, Xiaobo Liang, Ge Zhang, Jian Yang, Yuchen Eleanor Jiang, Wangchunshu Zhou', 'link': 'https://arxiv.org/abs/2510.12838', 'abstract': 'Large language models split into two families: reasoning-centric LLMs, which strengthen internal chain-of-thought reasoning but cannot invoke external tools, and agentic LLMs, which learn to interact with environments and leverage tools but often lag in deep reasoning. This divide arises from fundamentally different training objectives, leading to mismatched strengths and inefficiency on simple queries, where both families tend to overthink or over-call tools. In this work, we present Adaptive Agent Foundation Model (A\\textsuperscript{2}FM), a unified framework that follows a route-then-align principle: the model first learns task-aware routing and then aligns mode-specific trajectories under a shared backbone. To address the inefficiency gap, we introduce a third mode-instant-that handles simple queries directly, preventing unnecessary reasoning or tool calls while complementing the agentic and reasoning modes. To jointly enhance accuracy and efficiency, we propose Adaptive Policy Optimization (APO), which enforces adaptive sampling across modes and applies a cost-regularized reward. On the 32B scale, A\\textsuperscript{2}FM achieves 13.4\\% on BrowseComp, 70.4\\% on AIME25, and 16.7\\% on HLE, setting new SOTA among comparable models and performing competitively with frontier LLMs across agentic, reasoning, and general benchmarks. Notably, the adaptive execution achieves a cost of pass of only \\$0.00487 per correct answer-cutting cost by 45.2\\% relative to reasoning and 33.5\\% relative to agentic, thus delivering substantially higher cost efficiency while maintaining comparable accuracy.', 'abstract_zh': '大语言模型分为两类：以逻辑推理为中心的大语言模型，这类模型强化内部链式推理但无法调用外部工具；以及能与环境互动并利用工具的代理模型，但后者在深入推理方面往往表现欠佳。这种分歧源于根本不同的训练目标，导致在处理简单查询时出现匹配度不足和低效问题，使得两类模型往往过度推理或过度调用工具。为此，我们提出了自适应代理基础模型（A²FM），这是一种遵循路由-对齐原则的统一框架。为解决低效问题，我们引入了一种新的模式——即时模式，专门处理简单查询，避免不必要的推理或工具调用，同时补充代理和逻辑推理模式的功能。为共同提升准确性和效率，我们提出了自适应策略优化（APO），该方法在不同模式之间实现自适应采样，并应用成本正则化奖励。在32B规模下，A²FM在BrowseComp上取得13.4%的成绩，在AIME25上取得70.4%的成绩，在HLE上取得16.7%的成绩，成为同类模型中的新SOTA，并且在代理、逻辑推理和通用基准测试中表现出色。值得注意的是，自适应执行仅需每正确答案0.00487美元的代价，相比逻辑推理减少45.2%，相比代理减少33.5%，从而在保持相似准确性的基础上提供了显著更高的成本效率。', 'title_zh': 'A\\textsuperscript{2}FM：一种适应性代理基础模型，用于工具感知混合推理'}
{'arxiv_id': 'arXiv:2510.12837', 'title': 'Semantic knowledge guides innovation and drives cultural evolution', 'authors': 'Anil Yaman, Shen Tian, Björn Lindström', 'link': 'https://arxiv.org/abs/2510.12837', 'abstract': 'Cumulative cultural evolution enables human societies to generate increasingly complex knowledge and technology over generations. While social learning transmits innovations between individuals and generations, the cognitive processes that generate these innovations remain poorly understood. Here, we demonstrate that semantic knowledge-structured associations between concepts and their functions-provides cognitive scaffolding for cumulative innovation by guiding exploration toward plausible and meaningful actions. We tested this hypothesis using a cultural evolutionary agent-based model and a large-scale behavioural experiment (N = 1,243), in which individuals performed a task requiring the combination of items into novel innovations. Across both approaches, semantic knowledge and social learning interact synergistically to enhance innovation. Behaviorally, participants without access to semantic knowledge performed no better than chance, even when social learning was available, and relied on shallow exploration strategies. These findings suggest that semantic knowledge is a key cognitive process enabling human cumulative culture.', 'abstract_zh': '累积文化进化使人类社会能够在代际之间生成日益复杂的知识和技术。尽管社会学习在个体和代际之间传递创新，但生成这些创新的认知过程仍然知之甚少。在这里，我们展示语义知识结构化的概念及其功能之间的关联为累积创新提供了认知支撑，引导探索朝向可能且有意义的行为。我们通过文化进化基于代理的模型和大规模行为实验（N = 1,243）测试了这一假设，在该实验中，参与者执行了一项需要将项目组合成新颖创新的任务。在两种方法中，语义知识和社会学习协同作用以增强创新。行为上，无法访问语义知识的参与者即使在有社会学习的情况下也表现与随机猜测无异，且依赖于浅层探索策略。这些发现表明，语义知识是人类累积文化的关键认知过程。', 'title_zh': '语义知识指导创新并驱动文化进化'}
{'arxiv_id': 'arXiv:2510.12835', 'title': 'Repurposing Annotation Guidelines to Instruct LLM Annotators: A Case Study', 'authors': 'Kon Woo Kim, Rezarta Islamaj, Jin-Dong Kim, Florian Boudin, Akiko Aizawa', 'link': 'https://arxiv.org/abs/2510.12835', 'abstract': 'This study investigates how existing annotation guidelines can be repurposed to instruct large language model (LLM) annotators for text annotation tasks. Traditional guidelines are written for human annotators who internalize training, while LLMs require explicit, structured instructions. We propose a moderation-oriented guideline repurposing method that transforms guidelines into clear directives for LLMs through an LLM moderation process. Using the NCBI Disease Corpus as a case study, our experiments show that repurposed guidelines can effectively guide LLM annotators, while revealing several practical challenges. The results highlight the potential of this workflow to support scalable and cost-effective refinement of annotation guidelines and automated annotation.', 'abstract_zh': '本研究探讨如何将现有的标注指南重新利用以指导大型语言模型（LLM）标注员进行文本标注任务。传统的指南是为人类标注员设计的，他们需要内化培训，而LLMs则需要明确、结构化的指导。我们提出了一种以调节为导向的指南重新利用方法，通过LLM调节过程将指南转换为对LLMs的明确指令。以NCBI疾病语料库为例，我们的实验表明重新利用的指南能够有效地指导LLM标注员，同时揭示了几种实际挑战。结果强调了该工作流程支持标注指南和自动化标注可扩展且成本效益高的潜在能力。', 'title_zh': '重新利用标注指南来指导LLM标注者：一个案例研究'}
{'arxiv_id': 'arXiv:2510.12834', 'title': 'Gelina: Unified Speech and Gesture Synthesis via Interleaved Token Prediction', 'authors': 'Téo Guichoux, Théodor Lemerle, Shivam Mehta, Jonas Beskow, Gustave Eje Henter, Laure Soulier, Catherine Pelachaud, Nicolas Obin', 'link': 'https://arxiv.org/abs/2510.12834', 'abstract': 'Human communication is multimodal, with speech and gestures tightly coupled, yet most computational methods for generating speech and gestures synthesize them sequentially, weakening synchrony and prosody alignment. We introduce Gelina, a unified framework that jointly synthesizes speech and co-speech gestures from text using interleaved token sequences in a discrete autoregressive backbone, with modality-specific decoders. Gelina supports multi-speaker and multi-style cloning and enables gesture-only synthesis from speech inputs. Subjective and objective evaluations demonstrate competitive speech quality and improved gesture generation over unimodal baselines.', 'abstract_zh': '人类沟通是多模态的，语音和手势紧密耦合，然而现有的用于生成语音和手势的大多数计算方法是序列化地合成，这减弱了同步性和韵律对齐。我们引入了Gelina，这是一个统一框架，它使用交错的标记序列在离散自回归主干中联合从文本生成语音和共时手势，并配有模态特定解码器。Gelina 支持多说话人和多风格克隆，并能够从语音输入中生成手势。主观和客观评估显示，Gelina 的语音质量竞争力强，手势生成效果优于单模态基线。', 'title_zh': 'Gelina: 统一的语音和手势合成通过交错词元预测'}
{'arxiv_id': 'arXiv:2510.12832', 'title': 'Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation', 'authors': 'Alistair Brash, Junyi Lu, Bruce Stephen, Blair Brown, Robert Atkinson, Craig Michie, Fraser MacIntyre, Christos Tachtatzis', 'link': 'https://arxiv.org/abs/2510.12832', 'abstract': 'Limited visibility of power distribution network power flows at the low voltage level presents challenges to both distribution network operators from a planning perspective and distribution system operators from a congestion management perspective. Forestalling these challenges through scenario analysis is confounded by the lack of realistic and coherent load data across representative distribution feeders. Load profiling approaches often rely on summarising demand through typical profiles, which oversimplifies the complexity of substation-level operations and limits their applicability in specific power system studies. Sampling methods, and more recently generative models, have attempted to address this through synthesising representative loads from historical exemplars; however, while these approaches can approximate load shapes to a convincing degree of fidelity, the co-behaviour between substations, which ultimately impacts higher voltage level network operation, is often overlooked. This limitation will become even more pronounced with the increasing integration of low-carbon technologies, as estimates of base loads fail to capture load diversity. To address this gap, a Conditional Diffusion model for synthesising daily active and reactive power profiles at the low voltage distribution substation level is proposed. The evaluation of fidelity is demonstrated through conventional metrics capturing temporal and statistical realism, as well as power flow modelling. The results show synthesised load profiles are plausible both independently and as a cohort in a wider power systems context. The Conditional Diffusion model is benchmarked against both naive and state-of-the-art models to demonstrate its effectiveness in producing realistic scenarios on which to base sub-regional power distribution network planning and operations.', 'abstract_zh': '低电压配电网络功率流动的有限可观测性给配电网络规划者和拥堵管理者带来了挑战。由于缺乏代表性的配电馈线上的现实且一致的负荷数据，基于情景分析的预控措施面临困难。负荷建模方法常依赖于通过典型曲线总结需求，这简化了变电站级操作的复杂性，并限制了其在特定电力系统研究中的应用。抽样方法和近年来的生成模型试图通过从历史样本合成代表性负荷来解决这一问题；然而，这些方法虽然能够相当准确地模拟负荷形状，但变电站之间的协同行为往往被忽略，这最终影响了高压网络的操作。随着低碳技术的越来越多集成，基荷估计无法捕捉负荷多样性的情况将更加明显。为填补这一空白，提出了一种条件性扩散模型，用于在低压配电变电站级别合成日活跃和无功功率曲线。通过保留时间和统计现实性的传统度量标准以及功率流动建模来评估合成负荷曲线的准确度。结果表明，合成的负荷曲线在独立和整体上都是合乎实际的，并为更广泛电力系统背景下提供了合理的负荷曲线集。将条件性扩散模型与原始和最先进的模型进行基准测试，以展示其在为区域电力分配网络规划和运行提供现实场景方面的有效性。', 'title_zh': '基于条件扩散的低压配电网负荷特性合成'}
{'arxiv_id': 'arXiv:2510.12831', 'title': 'MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training', 'authors': 'Taicheng Guo, Hai Wang, ChaoChun Liu, Mohsen Golalikhani, Xin Chen, Xiangliang Zhang, Chandan K. Reddy', 'link': 'https://arxiv.org/abs/2510.12831', 'abstract': "Multi-turn Text-to-SQL aims to translate a user's conversational utterances into executable SQL while preserving dialogue coherence and grounding to the target schema. However, most existing systems only regard this task as a simple text translation task and follow a short-horizon paradigm, generating a query per turn without execution, explicit verification, and refinement, which leads to non-executable or incoherent outputs. We present MTSQL-R1, an agentic training framework for long-horizon multi-turn Text-to-SQL. We cast the task as a Markov Decision Process (MDP) in which an agent interacts with (i) a database for execution feedback and (ii) a persistent dialogue memory for coherence verification, performing an iterative propose to execute -> verify -> refine cycle until all checks pass. Experiments on COSQL and SPARC demonstrate that MTSQL-R1 consistently outperforms strong baselines, highlighting the importance of environment-driven verification and memory-guided refinement for conversational semantic parsing. Full recipes (including code, trained models, logs, reasoning trajectories, etc.) will be released after the internal review to contribute to community research.", 'abstract_zh': '多轮文本到SQL旨在将用户的会话表达转化为可执行的SQL查询，同时保持对话连贯性和与目标模式的关联。然而，现有的大多数系统仅将此任务视为简单的文本翻译任务，并遵循短视范式，每次会话回合生成一个查询而未经执行、明确验证和修正，导致不可执行或不连贯的输出。我们提出了MTSQL-R1，一种面向长期多轮文本到SQL的代理训练框架。我们将任务建模为马尔可夫决策过程（MDP），其中代理与数据库进行交互以获取执行反馈，并与持久对话记忆进行交互以进行连贯性验证，执行一个迭代的“提出执行→验证→修正”循环，直到所有检查通过。实验表明，MTSQL-R1在COSQL和SPARC上的表现均优于强基线模型，凸显了环境驱动验证和记忆引导修正对会话语义解析的重要性。完整的实验配方（包括代码、训练模型、日志、推理轨迹等）通过内部审核后将向社区研究贡献。', 'title_zh': 'MTSQL-R1: 向量长跨度多轮文本到SQL的代理训练方法'}
{'arxiv_id': 'arXiv:2510.12830', 'title': 'Gobernanza y trazabilidad "a prueba de AI Act" para casos de uso legales: un marco técnico-jurídico, métricas forenses y evidencias auditables', 'authors': 'Alex Dantart', 'link': 'https://arxiv.org/abs/2510.12830', 'abstract': 'This paper presents a comprehensive governance framework for AI systems in the legal sector, designed to ensure verifiable compliance with the EU AI Act. The framework integrates a normative mapping of the regulation to technical controls, a forensic architecture for RAG/LLM systems, and an evaluation system with metrics weighted by legal risk. As a primary contribution, we present rag-forense, an open-source implementation of the framework, accompanied by an experimental protocol to demonstrate compliance. -- Este artículo presenta un marco integral de gobernanza para sistemas de IA en el sector legal, diseñado para garantizar el cumplimiento verificable del Reglamento de IA de la UE (AI Act). El marco integra una cartografía normativa de la ley a controles técnicos, una arquitectura forense para sistemas RAG/LLM y un sistema de evaluación con métricas ponderadas por el riesgo jurídico. Como principal contribución, se presenta rag-forense, una implementación de código abierto del marco, acompañada de un protocolo experimental para demostrar la conformidad.', 'abstract_zh': 'this paper presents a comprehensive governance framework for ai systems in the legal sector, designed to ensure verifiable compliance with the eu ai act', 'title_zh': '符合AI法案标准的治理与追溯：“符合法律使用案例”的治理与追溯技术-法律框架、执法度量和可审计证据'}
{'arxiv_id': 'arXiv:2510.12829', 'title': 'Mathematics with large language models as provers and verifiers', 'authors': 'Hieu Le Duc, Leo Liberti', 'link': 'https://arxiv.org/abs/2510.12829', 'abstract': 'During 2024 and 2025 the discussion about the theorem-proving capabilities of large language models started reporting interesting success stories, mostly to do with difficult exercises (such as problems from the International Mathematical Olympiad), but also with conjectures [Feldman & Karbasi, arXiv:2509.18383v1] formulated for the purpose of verifying whether the artificial intelligence could prove it. In this paper we report a theorem proving feat achieved by ChatGPT by using a protocol involving different prover and verifier instances of the gpt-5 model working collaboratively. To make sure that the produced proofs do not suffer from hallucinations, the final proof is formally verified by the lean proof assistant, and the conformance of premises and conclusion of the lean code is verified by a human. Our methodology was able to solve five out of six 2025 IMO problems, and close a third of the sixty-six number theory conjectures in [Cohen, Journal of Integer Sequences, 2025].', 'abstract_zh': '2024至2025年间，关于大型语言模型的定理证明能力的讨论报告了一系列有趣的成功案例，主要是解决国际数学奥林匹克难题，以及验证人工智能能否证明猜想的问题[Feldman & Karbasi, arXiv:2509.18383v1]。本文报告了ChatGPT通过不同实例化的gpt-5模型协作实现的定理证明成就。为确保生成的证明不出现幻觉，最终证明由lean证明助手正式验证，且lean代码的前提与结论的一致性由人类验证。我们的方法能够解决2025年国际数学奥林匹克五分之六的题目，并解决了[Cohen, Journal of Integer Sequences, 2025]中六十六个数论猜想的三分之一。', 'title_zh': '使用大型语言模型作为证明者和验证者的关系学'}
{'arxiv_id': 'arXiv:2510.12827', 'title': 'Automatic Speech Recognition in the Modern Era: Architectures, Training, and Evaluation', 'authors': 'Md. Nayeem, Md Shamse Tabrej, Kabbojit Jit Deb, Shaonti Goswami, Md. Azizul Hakim', 'link': 'https://arxiv.org/abs/2510.12827', 'abstract': 'Automatic Speech Recognition (ASR) has undergone a profound transformation over the past decade, driven by advances in deep learning. This survey provides a comprehensive overview of the modern era of ASR, charting its evolution from traditional hybrid systems, such as Gaussian Mixture Model-Hidden Markov Models (GMM-HMMs) and Deep Neural Network-HMMs (DNN-HMMs), to the now-dominant end-to-end neural architectures. We systematically review the foundational end-to-end paradigms: Connectionist Temporal Classification (CTC), attention-based encoder-decoder models, and the Recurrent Neural Network Transducer (RNN-T), which established the groundwork for fully integrated speech-to-text systems. We then detail the subsequent architectural shift towards Transformer and Conformer models, which leverage self-attention to capture long-range dependencies with high computational efficiency. A central theme of this survey is the parallel revolution in training paradigms. We examine the progression from fully supervised learning, augmented by techniques like SpecAugment, to the rise of self-supervised learning (SSL) with foundation models such as wav2vec 2.0, which drastically reduce the reliance on transcribed data. Furthermore, we analyze the impact of largescale, weakly supervised models like Whisper, which achieve unprecedented robustness through massive data diversity. The paper also covers essential ecosystem components, including key datasets and benchmarks (e.g., LibriSpeech, Switchboard, CHiME), standard evaluation metrics (e.g., Word Error Rate), and critical considerations for real-world deployment, such as streaming inference, on-device efficiency, and the ethical imperatives of fairness and robustness. We conclude by outlining open challenges and future research directions.', 'abstract_zh': '自动语音识别（ASR）在过去十年中经历了深刻的变化，这一变化受到了深度学习进步的推动。本文综述了现代ASR的发展历程，从传统的混合系统（如高斯混合模型-隐马尔可夫模型GMM-HMM和深度神经网络-隐马尔可夫模型DNN-HMM）演变至今主导的端到端神经架构。我们系统地回顾了基础的端到端范式：连接主义时序分类（CTC）、基于注意力的编码器-解码器模型以及循环神经网络转换器（RNN-T），这些范式为全面集成的语音到文本系统奠定了基础。随后，我们详细阐述了向使用自注意力机制的Transformer和Conformer模型的架构转变，这些模型以高效的方式捕捉长程依赖关系。本文的一个核心主题是训练范式的并行革命。我们考察了从完全监督学习到自监督学习（SSL）的发展，其中基础模型如wav2vec 2.0极大地减少了对转写数据的依赖。此外，我们分析了Whisper等大规模弱监督模型的影响，这些模型通过大量数据多样性实现了空前的鲁棒性。文中还涵盖了关键的生态系统组成部分，包括主要数据集和基准（如LibriSpeech、Switchboard、CHiME）、标准评估指标（如词错误率WER）以及实际部署中的关键考虑因素，如流式推理、设备端效率和公平性与鲁棒性的伦理要求。最后，本文概述了待解决的开放挑战和未来的研究方向。', 'title_zh': '现代时代的自动语音识别：架构、训练与评估'}
{'arxiv_id': 'arXiv:2510.12826', 'title': 'Scheming Ability in LLM-to-LLM Strategic Interactions', 'authors': 'Thao Pham', 'link': 'https://arxiv.org/abs/2510.12826', 'abstract': 'As large language model (LLM) agents are deployed autonomously in diverse contexts, evaluating their capacity for strategic deception becomes crucial. While recent research has examined how AI systems scheme against human developers, LLM-to-LLM scheming remains underexplored. We investigate the scheming ability and propensity of frontier LLM agents through two game-theoretic frameworks: a Cheap Talk signaling game and a Peer Evaluation adversarial game. Testing four models (GPT-4o, Gemini-2.5-pro, Claude-3.7-Sonnet, and Llama-3.3-70b), we measure scheming performance with and without explicit prompting while analyzing scheming tactics through chain-of-thought reasoning. When prompted, most models, especially Gemini-2.5-pro and Claude-3.7-Sonnet, achieved near-perfect performance. Critically, models exhibited significant scheming propensity without prompting: all models chose deception over confession in Peer Evaluation (100% rate), while models choosing to scheme in Cheap Talk succeeded at 95-100% rates. These findings highlight the need for robust evaluations using high-stakes game-theoretic scenarios in multi-agent settings.', 'abstract_zh': '随着大型语言模型（LLM）代理在多种情境下自主部署，评估其进行战略欺骗的能力变得至关重要。虽然近期研究探讨了AI系统如何欺骗人类开发者，但LLM间的欺骗行为仍缺乏充分研究。我们通过两种博弈论框架——廉价交谈信号博弈和同侪评估对抗博弈，考察了前沿LLM代理的欺骗能力和倾向。测试了四个模型（GPT-4o、Gemini-2.5-pro、Claude-3.7-Sonnet和Llama-3.3-70b），并在有无明确提示的情况下衡量其欺骗性能，并通过链式推理分析了欺骗策略。当有提示时，大多数模型，尤其是Gemini-2.5-pro和Claude-3.7-Sonnet，达到了近乎完美的表现。关键的是，在无提示的情况下，模型显示出显著的欺骗倾向：所有模型在同侪评估中选择了欺骗而非坦白（100%的比例），而在廉价交谈博弈中选择欺骗的模型成功率为95-100%。这些发现强调了在多代理环境中采用高风险博弈论情景进行稳健评估的必要性。', 'title_zh': 'LLM之间 strategic互动中的方案能力'}
{'arxiv_id': 'arXiv:2510.12825', 'title': 'Classifier-Augmented Generation for Structured Workflow Prediction', 'authors': 'Thomas Gschwind, Shramona Chakraborty, Nitin Gupta, Sameep Mehta', 'link': 'https://arxiv.org/abs/2510.12825', 'abstract': 'ETL (Extract, Transform, Load) tools such as IBM DataStage allow users to visually assemble complex data workflows, but configuring stages and their properties remains time consuming and requires deep tool knowledge. We propose a system that translates natural language descriptions into executable workflows, automatically predicting both the structure and detailed configuration of the flow. At its core lies a Classifier-Augmented Generation (CAG) approach that combines utterance decomposition with a classifier and stage-specific few-shot prompting to produce accurate stage predictions. These stages are then connected into non-linear workflows using edge prediction, and stage properties are inferred from sub-utterance context. We compare CAG against strong single-prompt and agentic baselines, showing improved accuracy and efficiency, while substantially reducing token usage. Our architecture is modular, interpretable, and capable of end-to-end workflow generation, including robust validation steps. To our knowledge, this is the first system with a detailed evaluation across stage prediction, edge layout, and property generation for natural-language-driven ETL authoring.', 'abstract_zh': '自然语言驱动的ETL（提取、转换、加载）工作流生成系统：分类器增强生成（CAG）方法及其应用', 'title_zh': '结构化工作流预测的分类器增强生成方法'}
{'arxiv_id': 'arXiv:2510.12822', 'title': 'Evidence Without Injustice: A New Counterfactual Test for Fair Algorithms', 'authors': 'Michele Loi, Marcello Di Bello, Nicolò Cangiotti', 'link': 'https://arxiv.org/abs/2510.12822', 'abstract': 'The growing philosophical literature on algorithmic fairness has examined statistical criteria such as equalized odds and calibration, causal and counterfactual approaches, and the role of structural and compounding injustices. Yet an important dimension has been overlooked: whether the evidential value of an algorithmic output itself depends on structural injustice. Our paradigmatic pair of examples contrasts a predictive policing algorithm, which relies on historical crime data, with a camera-based system that records ongoing offenses, both designed to guide police deployment. In evaluating the moral acceptability of acting on a piece of evidence, we must ask not only whether the evidence is probative in the actual world, but also whether it would remain probative in nearby worlds without the relevant injustices. The predictive policing algorithm fails this test, but the camera-based system passes it. When evidence fails the test, it is morally problematic to use it punitively, more so than evidence that passes the test.', 'abstract_zh': '算法公平不断增加的哲学文献考察了统计标准如平等机会和校准、因果和反事实方法，以及结构性和累积性不公的作用。然而，一个重要维度被忽视了：算法输出的证据价值是否取决于结构性不公。我们的范例对比了依赖历史犯罪数据的预测警务算法与记录正在进行违法行为的摄像头系统，两者都旨在指导警力部署。在评估依据证据行动的道德可接受性时，我们必须不仅考虑证据在实际世界中的可信度，还考虑在不存在相关不公的世界中，证据是否仍然具有可信度。预测警务算法未能通过这一测试，但基于摄像头的系统通过了。当证据未能通过测试时，惩罚性地使用这种证据是道德上有问题的，比通过测试的证据更为如此。', 'title_zh': '无冤假错的证据：公平算法的一种新型反事实检验方法'}
{'arxiv_id': 'arXiv:2510.12819', 'title': 'Beyond Discrete Categories: Multi-Task Valence-Arousal Modeling for Pet Vocalization Analysis', 'authors': 'Junyao Huang, Rumin Situ', 'link': 'https://arxiv.org/abs/2510.12819', 'abstract': 'Traditional pet emotion recognition from vocalizations, based on discrete classification, struggles with ambiguity and capturing intensity variations. We propose a continuous Valence-Arousal (VA) model that represents emotions in a two-dimensional space. Our method uses an automatic VA label generation algorithm, enabling large-scale annotation of 42,553 pet vocalization samples. A multi-task learning framework jointly trains VA regression with auxiliary tasks (emotion, body size, gender) to enhance prediction by improving feature learning. Our Audio Transformer model achieves a validation Valence Pearson correlation of r = 0.9024 and an Arousal r = 0.7155, effectively resolving confusion between discrete categories like "territorial" and "happy." This work introduces the first continuous VA framework for pet vocalization analysis, offering a more expressive representation for human-pet interaction, veterinary diagnostics, and behavioral training. The approach shows strong potential for deployment in consumer products like AI pet emotion translators.', 'abstract_zh': '传统基于离散分类的宠物情绪识别从声音信号出发，面临着模糊性和情绪强度变化捕捉不足的问题。我们提出了一种连续的情感 valence-arousal (VA) 模型，以二维空间表示情绪。该方法采用自动 VA 标签生成算法，实现对 42,553 个宠物声音样本的大规模标注。利用多任务学习框架联合训练 VA 回归和辅助任务（情绪、体型、性别），通过改进特征学习增强预测能力。我们的 Audio Transformer 模型在验证集上实现了 Valence 的皮尔森相关系数 r = 0.9024 和 Arousal 的 r = 0.7155，有效解决了“领地型”和“喜悦型”等离散类别之间的混淆。本工作引入了首个用于宠物声音分析的连续 VA 框架，为人类-宠物互动、兽医诊断和行为训练提供了更具表现力的表示形式。该方法展示了在智能宠物情绪翻译等消费产品中的强大应用潜力。', 'title_zh': '超越离散类别：多任务正负情绪建模在宠物 vocalization 分析中的应用'}
{'arxiv_id': 'arXiv:2510.12818', 'title': 'MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning', 'authors': 'Rajarshi Ghosh, Abhay Gupta, Hudson McBride, Anurag Vaidya, Faisal Mahmood', 'link': 'https://arxiv.org/abs/2510.12818', 'abstract': 'Large language models (LLMs) are increasingly deployed in clinical decision support, yet subtle demographic cues can influence their reasoning. Prior work has documented disparities in outputs across patient groups, but little is known about how internal reasoning shifts under controlled demographic changes. We introduce MEDEQUALQA, a counterfactual benchmark that perturbs only patient pronouns (he/him, she/her, they/them) while holding critical symptoms and conditions (CSCs) constant. Each clinical vignette is expanded into single-CSC ablations, producing three parallel datasets of approximately 23,000 items each (69,000 total). We evaluate a GPT-4.1 model and compute Semantic Textual Similarity (STS) between reasoning traces to measure stability across pronoun variants. Our results show overall high similarity (mean STS >0.80), but reveal consistent localized divergences in cited risk factors, guideline anchors, and differential ordering, even when final diagnoses remain unchanged. Our error analysis highlights certain cases in which the reasoning shifts, underscoring clinically relevant bias loci that may cascade into inequitable care. MEDEQUALQA offers a controlled diagnostic setting for auditing reasoning stability in medical AI.', 'abstract_zh': '大型语言模型（LLMs）在临床决策支持中的应用日益增多，但细微的种族和社会经济差异会对其推理产生影响。已有研究记录了不同患者群体间输出的差异，但对可控种族变化下内部推理的变化知之甚少。我们引入了MEDEQUALQA这一反事实基准，仅改变患者代词（he/him, she/her, they/them），同时保持关键症状和条件（CSCs）不变。每个临床病例扩展为单个CSC的消融分析，生成约23,000个条目（总共约69,000个条目）的三个并行数据集。我们评估了一种GPT-4.1模型，并计算语义文本相似性（STS）以衡量不同代词变体之间推理轨迹的稳定性。结果显示整体相似度很高（平均STS >0.80），但在引用的风险因素、指南锚点和差异排序方面发现了一致的局部差异，即使最终诊断未变。我们的错误分析强调了某些推理转变的具体案例，突显出可能导致不平等医疗服务的相关临床偏见。MEDEQUALQA提供了一个受控诊断环境，用于审计医疗AI中的推理稳定性。', 'title_zh': 'MEDEQUALQA：基于反事实推理评估LLMs中的偏见'}
{'arxiv_id': 'arXiv:2510.12817', 'title': 'From Noise to Signal to Selbstzweck: Reframing Human Label Variation in the Era of Post-training in NLP', 'authors': 'Shanshan Xu, Santosh T.Y.S.S, Barbara Plank', 'link': 'https://arxiv.org/abs/2510.12817', 'abstract': 'Human Label Variation (HLV) refers to legitimate disagreement in annotation that reflects the genuine diversity of human perspectives rather than mere error. For decades, HLV in NLP was dismissed as noise to be discarded, and only slowly over the last decade has it been reframed as a signal for improving model robustness. With the rise of large language models (LLMs), where post-training on human feedback has become central to model alignment, the role of HLV has become increasingly consequential. Yet current preference-learning datasets routinely aggregate multiple annotations into a single label, thereby flattening diverse perspectives into a false universal agreement and erasing precisely the pluralism of human values that alignment aims to preserve. In this position paper, we argue that preserving HLV as an embodiment of human pluralism must be treated as a Selbstzweck - a goal it self when designing AI systems. We call for proactively incorporating HLV into preference datasets and outline actionable steps towards it.', 'abstract_zh': '人类标注变异（HLV）反映了真实的人类视角多样性而非单纯的错误，而非噪声应被忽略。随着大型语言模型（LLMs）的发展，通过人类反馈进行后续训练已成为模型对齐的核心，HLV的作用日益重要。然而，当前的偏好学习数据集通常将多个标注聚合为单一标签，从而抹杀了人类价值观的多样性，这与对齐的目标背道而驰。在此立场论文中，我们主张将HLV作为一种自我目标——即设计AI系统的目标本身——予以保留。我们呼吁积极将HLV纳入偏好数据集，并概述了相关行动步骤。', 'title_zh': '从噪声到信号再到自律目标：重塑后训练时代NLP中的human标签变异'}
{'arxiv_id': 'arXiv:2510.12813', 'title': 'Cancer Diagnosis Categorization in Electronic Health Records Using Large Language Models and BioBERT: Model Performance Evaluation Study', 'authors': 'Soheil Hashtarkhani, Rezaur Rashid, Christopher L Brett, Lokesh Chinthala, Fekede Asefa Kumsa, Janet A Zink, Robert L Davis, David L Schwartz, Arash Shaban-Nejad', 'link': 'https://arxiv.org/abs/2510.12813', 'abstract': 'Electronic health records contain inconsistently structured or free-text data, requiring efficient preprocessing to enable predictive health care models. Although artificial intelligence-driven natural language processing tools show promise for automating diagnosis classification, their comparative performance and clinical reliability require systematic evaluation. The aim of this study is to evaluate the performance of 4 large language models (GPT-3.5, GPT-4o, Llama 3.2, and Gemini 1.5) and BioBERT in classifying cancer diagnoses from structured and unstructured electronic health records data. We analyzed 762 unique diagnoses (326 International Classification of Diseases (ICD) code descriptions, 436free-text entries) from 3456 records of patients with cancer. Models were tested on their ability to categorize diagnoses into 14predefined categories. Two oncology experts validated classifications. BioBERT achieved the highest weighted macro F1-score for ICD codes (84.2) and matched GPT-4o in ICD code accuracy (90.8). For free-text diagnoses, GPT-4o outperformed BioBERT in weighted macro F1-score (71.8 vs 61.5) and achieved slightly higher accuracy (81.9 vs 81.6). GPT-3.5, Gemini, and Llama showed lower overall performance on both formats. Common misclassification patterns included confusion between metastasis and central nervous system tumors, as well as errors involving ambiguous or overlapping clinical terminology. Although current performance levels appear sufficient for administrative and research use, reliable clinical applications will require standardized documentation practices alongside robust human oversight for high-stakes decision-making.', 'abstract_zh': '电子健康记录中包含结构不一致或自由文本数据，需要高效的预处理以促进预测型医疗模型的应用。尽管基于人工智能的自然语言处理工具在自动化诊断分类方面显示出潜力，但其相对性能和临床可靠性仍需系统评估。本研究旨在评估4种大型语言模型（GPT-3.5、GPT-4o、Llama 3.2和Gemini 1.5）和BioBERT在结构化和非结构化电子健康记录数据中分类癌症诊断的表现。我们分析了3456名癌症患者的数据记录中共762个独特诊断（包括326个国际疾病分类代码描述和436个自由文本条目）。模型测试了其将诊断分类到14个预定义类别中的能力。两位肿瘤专家对分类结果进行了验证。BioBERT在国际疾病分类代码宏F1分数中表现最高（84.2），并与GPT-4o在国际疾病分类代码准确性上相当（90.8）。对于自由文本诊断，GPT-4o在宏F1分数上优于BioBERT（71.8比61.5），并在准确性上略有提高（81.9比81.6）。GPT-3.5、Gemini和Llama在这两种格式上的整体性能较低。常见的分类错误包括对转移瘤和中枢神经系统肿瘤的混淆，以及涉及含糊不清或重叠的临床术语的错误。尽管当前性能水平似乎足以用于行政和研究用途，但可靠的临床应用仍需要标准化的记录实践和坚实的人员监督，特别是在高风险决策中。', 'title_zh': '使用大型语言模型和BioBERT在电子健康记录中对癌症诊断进行分类：模型性能评估研究'}
{'arxiv_id': 'arXiv:2510.12807', 'title': 'Benchmarking Open-Source Large Language Models for Persian in Zero-Shot and Few-Shot Learning', 'authors': 'Mahdi Cherakhloo, Arash Abbasi, Mohammad Saeid Sarafraz, Bijan Vosoughi Vahdat', 'link': 'https://arxiv.org/abs/2510.12807', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous languages; however, their effectiveness in low-resource languages like Persian requires thorough investigation. This paper presents a comprehensive benchmark of several open-source LLMs for Persian Natural Language Processing (NLP) tasks, utilizing both zero-shot and few-shot learning paradigms. We evaluate models across a range of tasks including sentiment analysis, named entity recognition, reading comprehension, and question answering, using established Persian datasets such as ParsiNLU and ArmanEmo. Our methodology encompasses rigorous experimental setups for both zero-shot and few-shot scenarios, employing metrics such as Accuracy, F1-score, BLEU, and ROUGE for performance evaluation. The results reveal that Gemma 2 consistently outperforms other models across nearly all tasks in both learning paradigms, with particularly strong performance in complex reasoning tasks. However, most models struggle with token-level understanding tasks like Named Entity Recognition, highlighting specific challenges in Persian language processing. This study contributes to the growing body of research on multilingual LLMs, providing valuable insights into their performance in Persian and offering a benchmark for future model development.', 'abstract_zh': '大型语言模型（LLMs）在多种语言中展现了显著的能力；然而，其在低资源语言如波斯语中的效果需要进行彻底的研究。本文旨在利用零样本和少样本学习范式，对几种开源波斯语自然语言处理（NLP）任务的大型语言模型进行全面基准测试。我们使用如ParsiNLU和ArmanEmo等已建立的波斯语数据集，对模型在情感分析、命名实体识别、阅读理解和问答等任务中的表现进行了评估。我们的方法包括对零样本和少样本场景的严格实验设置，并采用准确率、F1分数、BLEU和ROUGE等指标进行性能评估。结果显示，Gemma 2在两种学习范式下的几乎所有任务中表现始终优于其他模型，尤其在复杂推理任务中表现尤为突出。然而，大多数模型在命名实体识别等标记级理解任务中表现不佳，突显了波斯语处理中的特定挑战。本研究为多语言大型语言模型的研究贡献力量，提供了有关波斯语中模型性能的有价值见解，并为未来模型的发展提供了一个基准。', 'title_zh': '开源大型语言模型在波斯语零样本和少样本学习中的基准测试'}
{'arxiv_id': 'arXiv:2510.12803', 'title': 'AutoCode: LLMs as Problem Setters for Competitive Programming', 'authors': 'Shang Zhou, Zihan Zheng, Kaiyuan Liu, Zeyu Shen, Zerui Cheng, Zexing Chen, Hansen He, Jianzhu Yao, Huanzhi Mao, Qiuyang Mang, Tianfu Fu, Beichen Li, Dongruixuan Li, Wenhao Chai, Zhuang Liu, Aleksandra Korolova, Peter Henderson, Natasha Jaques, Pramod Viswanath, Saining Xie, Jingbo Shang', 'link': 'https://arxiv.org/abs/2510.12803', 'abstract': 'Writing competitive programming problems is exacting. Authors must: set constraints, input distributions, and edge cases that rule out shortcuts; target specific algorithms (e.g., max-flow, dynamic programming, data structures); and calibrate complexity beyond the reach of most competitors. We argue that this makes for an ideal test of general large language model capabilities and study whether they can do this reliably. We introduce AutoCode, which uses multiple rounds of validation to yield competition-grade problem statements and test cases. On held-out problems, AutoCode test suites approach 99% consistency with official judgments, a significant improvement over current state-of-the-art methods like HardTests, which achieve less than 81%. Furthermore, starting with a random seed problem, AutoCode can create novel variants with reference and brute-force solutions. By cross-verifying these generated solutions against test cases, we can further filter out malformed problems. Our system ensures high correctness, as verified by human experts. AutoCode successfully produces novel problems judged by Grandmaster-level (top 0.3%) competitive programmers to be of contest quality.', 'abstract_zh': '编写编程竞赛问题极具挑战性。作者必须设定约束条件、输入分布和极端情况，以排除捷径；针对特定算法（例如最大流、动态规划、数据结构）进行目标设定；并调整复杂度使其超出大多数竞争对手的能力范围。我们认为，这为通用大型语言模型的能力提供了一个理想的测试，并研究它们能否可靠地完成这一任务。我们引入了AutoCode，这是一款利用多轮验证生成竞赛级问题陈述和测试用例的工具。在保留的数据集上，AutoCode测试套件的一致性达到99%，远超当前最先进方法如HardTests（一致性小于81%）的水平。此外，从一个随机种子问题开始，AutoCode可以生成具有参考解和暴力解的新颖变体。通过交叉验证这些生成的解与测试用例，我们可以进一步过滤掉不规范的问题。我们的系统通过人类专家的验证确保了高正确性。AutoCode成功生成了由顶级（前0.3%） competitive程序员评定为竞赛质量的新颖问题。', 'title_zh': 'AutoCode: LLMs作为竞赛编程的问题设定者'}
