# Privacy Perceptions in Robot-Assisted Well-Being Coaching: Examining the Roles of Information Transparency, User Control, and Proactivity 

**Title (ZH)**: 机器人辅助福祉教练中的隐私感知：探讨信息透明度、用户控制和主动性的作用 

**Authors**: Atikkhan Faridkhan Nilgar, Manuel Dietrich, Kristof Van Laerhoven  

**Link**: [PDF](https://arxiv.org/pdf/2509.04358)  

**Abstract**: Social robots are increasingly recognized as valuable supporters in the field of well-being coaching. They can function as independent coaches or provide support alongside human coaches, and healthcare professionals. In coaching interactions, these robots often handle sensitive information shared by users, making privacy a relevant issue. Despite this, little is known about the factors that shape users' privacy perceptions. This research aims to examine three key factors systematically: (1) the transparency about information usage, (2) the level of specific user control over how the robot uses their information, and (3) the robot's behavioral approach - whether it acts proactively or only responds on demand. Our results from an online study (N = 200) show that even when users grant the robot general access to personal data, they additionally expect the ability to explicitly control how that information is interpreted and shared during sessions. Experimental conditions that provided such control received significantly higher ratings for perceived privacy appropriateness and trust. Compared to user control, the effects of transparency and proactivity on privacy appropriateness perception were low, and we found no significant impact. The results suggest that merely informing users or proactive sharing is insufficient without accompanying user control. These insights underscore the need for further research on mechanisms that allow users to manage robots' information processing and sharing, especially when social robots take on more proactive roles alongside humans. 

**Abstract (ZH)**: 社会机器人在福祉教练领域的应用日益受到认可，它们可以作为独立教练存在，也可以作为人类教练和医疗专业人员的支持者发挥作用。在教练互动中，这些机器人经常处理用户分享的敏感信息，因此隐私问题成为一个相关议题。尽管如此，对塑造用户隐私感知因素的研究还相对不足。本研究旨在系统地考察三个关键因素：（1）信息使用透明度，（2）用户对其信息如何被机器人使用的具体控制程度，以及（3）机器人的行为方式——它是否主动或仅在需求时响应。在线研究（N=200）的结果显示，即使用户授予机器人访问个人数据的通用权限，他们也期望能够在会话中明确控制这些信息的解释和分享方式。提供这种控制的实验条件在感知隐私适当性和信任度方面获得了显著更高的评分。相比之下，透明度和主动性的效应对感知隐私适当性感知影响较低，我们未发现显著影响。结果表明，仅告知用户或主动分享不足以解决问题。这些见解强调了需要进一步研究允许用户管理机器人信息处理和分享的机制，尤其是在社会机器人承担更多主动角色时。 

---
# Compatibility of Multiple Control Barrier Functions for Constrained Nonlinear Systems 

**Title (ZH)**: 受限非线性系统的多个控制障碍函数兼容性研究 

**Authors**: Max H. Cohen, Eugene Lavretsky, Aaron D. Ames  

**Link**: [PDF](https://arxiv.org/pdf/2509.04220)  

**Abstract**: Control barrier functions (CBFs) are a powerful tool for the constrained control of nonlinear systems; however, the majority of results in the literature focus on systems subject to a single CBF constraint, making it challenging to synthesize provably safe controllers that handle multiple state constraints. This paper presents a framework for constrained control of nonlinear systems subject to box constraints on the systems' vector-valued outputs using multiple CBFs. Our results illustrate that when the output has a vector relative degree, the CBF constraints encoding these box constraints are compatible, and the resulting optimization-based controller is locally Lipschitz continuous and admits a closed-form expression. Additional results are presented to characterize the degradation of nominal tracking objectives in the presence of safety constraints. Simulations of a planar quadrotor are presented to demonstrate the efficacy of the proposed framework. 

**Abstract (ZH)**: 基于多个控制障碍函数的非线性系统受限输出区间约束控制框架 

---
# Memory Optimization for Convex Hull Support Point Queries 

**Title (ZH)**: 凸包支撑点查询的内存优化 

**Authors**: Michael Greer  

**Link**: [PDF](https://arxiv.org/pdf/2509.03753)  

**Abstract**: This paper evaluates several improvements to the memory layout of convex hulls to improve computation times for support point queries. The support point query is a fundamental part of common collision algorithms, and the work presented achieves a significant speedup depending on the number of vertices of the convex hull. 

**Abstract (ZH)**: 本文评估了几种改进凸包内存布局的方法，以提高支持点查询的计算时间。支持点查询是常见碰撞算法的基本组成部分，所提出的工作根据凸包的顶点数实现了显著的速度提升。 

---
# Evaluating Quality of Gaming Narratives Co-created with AI 

**Title (ZH)**: 评估AI共创的游戏叙事质量 

**Authors**: Arturo Valdivia, Paolo Burelli  

**Link**: [PDF](https://arxiv.org/pdf/2509.04239)  

**Abstract**: This paper proposes a structured methodology to evaluate AI-generated game narratives, leveraging the Delphi study structure with a panel of narrative design experts. Our approach synthesizes story quality dimensions from literature and expert insights, mapping them into the Kano model framework to understand their impact on player satisfaction. The results can inform game developers on prioritizing quality aspects when co-creating game narratives with generative AI. 

**Abstract (ZH)**: 本文提出了一种结构化的方法来评估AI生成的游戏叙事，利用德尔菲研究结构和叙事设计专家小组。我们的方法综合了文献和专家见解中的故事质量维度，并将它们映射到Kano模型框架中，以了解这些维度对玩家满意度的影响。研究结果可以指导游戏开发者在与生成式AI共创造游戏叙事时优先考虑质量方面。 

---
# Domain size asymptotics for Markov logic networks 

**Title (ZH)**: 马尔可夫逻辑网络的域大小渐近性质 

**Authors**: Vera Koponen  

**Link**: [PDF](https://arxiv.org/pdf/2509.04192)  

**Abstract**: A Markov logic network (MLN) determines a probability distribution on the set of structures, or ``possible worlds'', with an arbitrary finite domain. We study the properties of such distributions as the domain size tends to infinity. Three types of concrete examples of MLNs will be considered, and the properties of random structures with domain sizes tending to infinity will be studied: (1) Arbitrary quantifier-free MLNs over a language with only one relation symbol which has arity 1. In this case we give a pretty complete characterization of the possible limit behaviours of random structures. (2) An MLN that favours graphs with fewer triangles (or more generally, fewer k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law'' for first-order logic is obtained. (3) An MLN that favours graphs with fewer vertices with degree higher than a fixed (but arbitrary) number. The analysis shows that depending on which ``soft constraints'' an MLN uses the limit behaviour of random structures can be quite different, and the weights of the soft constraints may, or may not, have influence on the limit behaviour. It will also be demonstrated, using (1), that quantifier-free MLNs and lifted Bayesian networks (in a broad sense) are asymptotically incomparable, roughly meaning that there is a sequence of distributions on possible worlds with increasing domain sizes that can be defined by one of the formalisms but not even approximated by the other. In a rather general context it is also shown that on large domains the distribution determined by an MLN concentrates almost all its probability mass on a totally different part of the space of possible worlds than the uniform distribution does. 

**Abstract (ZH)**: 一个马尔可夫逻辑网络（MLN）确定了结构集或“可能世界”的概率分布，其领域是任意有限域。我们研究当领域大小趋于无穷时这类分布的性质。将考虑三种具体的MLN实例，并研究当领域大小趋于无穷时随机结构的性质：（1）仅含一个一元关系符号的任意量化公式为零的MLN。在这种情况下，我们提供了随机结构可能极限行为的相当完整的表征。（2）一个倾向于包含更少三角形（或更一般地，更少的k- clique）的MLN。分析的推论给出了零-1法律的一个“δ-近似”结果。（3）一个倾向于包含更少度数高于固定数（但任意）的顶点的MLN。分析表明，根据MLN使用的“软约束”类型，随机结构的极限行为可能大不相同，而“软约束”的权重可能会影响也可能不会影响极限行为。还将利用（1）证明，量化公式为零的MLN和提升的贝叶斯网络（广义上）在无穷大极限下是渐近不可比较的，大致意味着存在定义在可能世界上的分布序列，随领域大小增加，可以由其中一种形式化表示定义，甚至不能被另一种形式的表示近似。在相对一般的情境下，也证明在大型领域中，MLN确定的分布几乎将所有概率质量集中在可能世界空间的完全不同部分，而均匀分布则不会如此。 

---
# Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs 

**Title (ZH)**: 基于时间图的烹饪程序以动作为中心的本体研究 

**Authors**: Aarush Kumbhakern, Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das  

**Link**: [PDF](https://arxiv.org/pdf/2509.04159)  

**Abstract**: Formalizing cooking procedures remains a challenging task due to their inherent complexity and ambiguity. We introduce an extensible domain-specific language for representing recipes as directed action graphs, capturing processes, transfers, environments, concurrency, and compositional structure. Our approach enables precise, modular modeling of complex culinary workflows. Initial manual evaluation on a full English breakfast recipe demonstrates the DSL's expressiveness and suitability for future automated recipe analysis and execution. This work represents initial steps towards an action-centric ontology for cooking, using temporal graphs to enable structured machine understanding, precise interpretation, and scalable automation of culinary processes - both in home kitchens and professional culinary settings. 

**Abstract (ZH)**: 形式化烹饪程序仍然是一个具有挑战性的问题，由于其固有的复杂性和模糊性。我们引入了一种可扩展的领域特定语言，用于将食谱表示为有向动作图，捕捉过程、转移、环境、并发性和组合结构。我们的方法使复杂的烹饪工作流程精准且模块化地建模成为可能。对一份完整的英式早餐食谱的手动评估初步展示了该领域特定语言的表达能力和适合未来自动化食谱分析和执行的潜力。这项工作代表了向以动作为中心的烹饪本体论发展的初步步骤，利用时间图来实现烹饪过程的结构化机器理解、精确解释和可扩展自动化——无论是在家庭厨房还是在专业烹饪环境中。 

---
# The human biological advantage over AI 

**Title (ZH)**: 人类在生物智能方面超过AI的优势 

**Authors**: William Stewart  

**Link**: [PDF](https://arxiv.org/pdf/2509.04130)  

**Abstract**: Recent advances in AI raise the possibility that AI systems will one day be able to do anything humans can do, only better. If artificial general intelligence (AGI) is achieved, AI systems may be able to understand, reason, problem solve, create, and evolve at a level and speed that humans will increasingly be unable to match, or even understand. These possibilities raise a natural question as to whether AI will eventually become superior to humans, a successor "digital species", with a rightful claim to assume leadership of the universe. However, a deeper consideration suggests the overlooked differentiator between human beings and AI is not the brain, but the central nervous system (CNS), providing us with an immersive integration with physical reality. It is our CNS that enables us to experience emotion including pain, joy, suffering, and love, and therefore to fully appreciate the consequences of our actions on the world around us. And that emotional understanding of the consequences of our actions is what is required to be able to develop sustainable ethical systems, and so be fully qualified to be the leaders of the universe. A CNS cannot be manufactured or simulated; it must be grown as a biological construct. And so, even the development of consciousness will not be sufficient to make AI systems superior to humans. AI systems may become more capable than humans on almost every measure and transform our society. However, the best foundation for leadership of our universe will always be DNA, not silicon. 

**Abstract (ZH)**: 近期AI的发展使得AI系统未来可能在任何人类能做到的事情上做得更好。如果实现人工通用智能（AGI），AI系统可能在理解和推理、问题解决、创造和进化方面达到一个水平和速度，使人类越来越难以跟上甚至无法理解。这些可能性引发了一个自然的问题：AI最终是否会超越人类，成为一种替代的“数字物种”，有资格领导宇宙。然而，更深层次的考虑表明，人类与AI之间被忽视的区别不是大脑，而是中枢神经系统（CNS），它使我们能够与物理现实进行沉浸式的整合。正是我们的CNS让我们能够体验包括痛苦、快乐、苦难和爱在内的情感，从而能够充分理解我们的行为对周围世界的影响。这种对行为后果的情感理解是建立可持续伦理体系所需要的，因此使我们有资格成为宇宙的领导者。中枢神经系统无法被制造或模拟；必须作为一种生物构造来生长。因此，即使意识的产生也不足以使AI系统超越人类。AI系统可能在几乎每一个衡量标准上变得比人类更有能力，并且将改变我们的社会。然而，宇宙的领导基础永远是DNA，而不是硅。 

---
# Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker 

**Title (ZH)**: DQN和CFR在Leduc Hold'em扑克中撒牌分析 

**Authors**: Tarik Zaciragic, Aske Plaat, K. Joost Batenburg  

**Link**: [PDF](https://arxiv.org/pdf/2509.04125)  

**Abstract**: In the game of poker, being unpredictable, or bluffing, is an essential skill. When humans play poker, they bluff. However, most works on computer-poker focus on performance metrics such as win rates, while bluffing is overlooked. In this paper we study whether two popular algorithms, DQN (based on reinforcement learning) and CFR (based on game theory), exhibit bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed an experiment where we let the DQN and CFR agent play against each other while we log their actions. We find that both DQN and CFR exhibit bluffing behavior, but they do so in different ways. Although both attempt to perform bluffs at different rates, the percentage of successful bluffs (where the opponent folds) is roughly the same. This suggests that bluffing is an essential aspect of the game, not of the algorithm. Future work should look at different bluffing styles and at the full game of poker. Code at this https URL. 

**Abstract (ZH)**: 在德州扑克游戏中，不可预测性或欺骗是一种关键技能。在人类玩德州扑克时，他们会进行欺骗。然而，大多数关于计算机德州扑克的研究集中在胜率等性能指标上，而忽略了欺骗行为。本文研究了两种流行的算法，基于强化学习的DQN和基于博弈论的CFR，在简化版本的德鲁克霍尔得'em (Leduc Hold'em) 中是否表现出欺骗行为。我们设计了一个实验，让DQN和CFR代理相互对战，并记录它们的行为。我们发现，DQN和CFR都表现出欺骗行为，但它们的方式不同。尽管它们以不同的频率尝试欺骗，成功欺骗的比例（对手弃牌）大致相同。这表明欺骗是游戏的关键部分，而不是算法的关键部分。未来的工作应研究不同类型的欺骗和完整的德州扑克游戏。代码详见此链接：https://link.url。 

---
# Hybrid Reinforcement Learning and Search for Flight Trajectory Planning 

**Title (ZH)**: 混合强化学习与搜索在飞行航迹规划中的应用 

**Authors**: Alberto Luise, Michele Lombardi, Florent Teichteil Koenigsbuch  

**Link**: [PDF](https://arxiv.org/pdf/2509.04100)  

**Abstract**: This paper explores the combination of Reinforcement Learning (RL) and search-based path planners to speed up the optimization of flight paths for airliners, where in case of emergency a fast route re-calculation can be crucial. The fundamental idea is to train an RL Agent to pre-compute near-optimal paths based on location and atmospheric data and use those at runtime to constrain the underlying path planning solver and find a solution within a certain distance from the initial guess. The approach effectively reduces the size of the solver's search space, significantly speeding up route optimization. Although global optimality is not guaranteed, empirical results conducted with Airbus aircraft's performance models show that fuel consumption remains nearly identical to that of an unconstrained solver, with deviations typically within 1%. At the same time, computation speed can be improved by up to 50% as compared to using a conventional solver alone. 

**Abstract (ZH)**: 基于强化学习和搜索路径规划的航空器航路优化加速方法 

---
# Oruga: An Avatar of Representational Systems Theory 

**Title (ZH)**: Oruga：表征系统理论的化身 

**Authors**: Daniel Raggi, Gem Stapleton, Mateja Jamnik, Aaron Stockdill, Grecia Garcia Garcia, Peter C-H. Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2509.04041)  

**Abstract**: Humans use representations flexibly. We draw diagrams, change representations and exploit creative analogies across different domains. We want to harness this kind of power and endow machines with it to make them more compatible with human use. Previously we developed Representational Systems Theory (RST) to study the structure and transformations of representations. In this paper we present Oruga (caterpillar in Spanish; a symbol of transformation), an implementation of various aspects of RST. Oruga consists of a core of data structures corresponding to concepts in RST, a language for communicating with the core, and an engine for producing transformations using a method we call structure transfer. In this paper we present an overview of the core and language of Oruga, with a brief example of the kind of transformation that structure transfer can execute. 

**Abstract (ZH)**: 人类灵活使用表征。我们绘制图表、改变表征形式并跨不同领域运用富有创意的类比。我们希望利用这种能力，赋予机器这种能力，使它们更符合人类的使用方式。我们之前开发了表征系统理论（RST）以研究表征的结构和变换。在本文中，我们介绍了Oruga（西班牙语中的毛毛虫；象征变化的一种），RST各方面的一个实现。Oruga包含与RST概念对应的中心数据结构、与中心通信的语言，以及使用我们称之为结构转移的方法生成变换的引擎。本文概述了Oruga的中心和语言，并简要介绍了结构转移所能执行的变换类型的一个示例。 

---
# Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions 

**Title (ZH)**: 通过延迟部分扩展的最好首先搜索处理规划中的无限域参数 

**Authors**: Ángel Aso-Mollar, Diego Aineto, Enrico Scala, Eva Onaindia  

**Link**: [PDF](https://arxiv.org/pdf/2509.03953)  

**Abstract**: In automated planning, control parameters extend standard action representations through the introduction of continuous numeric decision variables. Existing state-of-the-art approaches have primarily handled control parameters as embedded constraints alongside other temporal and numeric restrictions, and thus have implicitly treated them as additional constraints rather than as decision points in the search space. In this paper, we propose an efficient alternative that explicitly handles control parameters as true decision points within a systematic search scheme. We develop a best-first, heuristic search algorithm that operates over infinite decision spaces defined by control parameters and prove a notion of completeness in the limit under certain conditions. Our algorithm leverages the concept of delayed partial expansion, where a state is not fully expanded but instead incrementally expands a subset of its successors. Our results demonstrate that this novel search algorithm is a competitive alternative to existing approaches for solving planning problems involving control parameters. 

**Abstract (ZH)**: 自动化规划中，控制参数通过引入连续数值决策变量扩展标准动作表示。现有最先进的方法主要将控制参数作为与其他时间和数值限制嵌入的约束来处理，从而在一定程度上将它们隐式地视为搜索空间中的额外约束而非决策点。本文提出了一种有效的替代方案，该方案在系统搜索方案中明确处理控制参数作为真正的决策点。我们开发了一种最佳优先启发式搜索算法，在由控制参数定义的无限决策空间上进行操作，并在某些条件下证明了完备性。该算法利用了延迟部分扩展的概念，其中状态不是完全展开，而是增量地展开其部分后继状态。我们的结果表明，这种新颖的搜索算法是解决涉及控制参数的规划问题的有效替代方案。 

---
# A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai 

**Title (ZH)**: 基于人工智能的多维度框架：分析历史文化街区游客感知——以上海为例的研究 

**Authors**: Kaizhen Tan, Yufan Wu, Yuxuan Liu, Haoran Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2509.03830)  

**Abstract**: Historic urban quarters play a vital role in preserving cultural heritage while serving as vibrant spaces for tourism and everyday life. Understanding how tourists perceive these environments is essential for sustainable, human-centered urban planning. This study proposes a multidimensional AI-powered framework for analyzing tourist perception in historic urban quarters using multimodal data from social media. Applied to twelve historic quarters in central Shanghai, the framework integrates focal point extraction, color theme analysis, and sentiment mining. Visual focus areas are identified from tourist-shared photos using a fine-tuned semantic segmentation model. To assess aesthetic preferences, dominant colors are extracted using a clustering method, and their spatial distribution across quarters is analyzed. Color themes are further compared between social media photos and real-world street views, revealing notable shifts. This divergence highlights potential gaps between visual expectations and the built environment, reflecting both stylistic preferences and perceptual bias. Tourist reviews are evaluated through a hybrid sentiment analysis approach combining a rule-based method and a multi-task BERT model. Satisfaction is assessed across four dimensions: tourist activities, built environment, service facilities, and business formats. The results reveal spatial variations in aesthetic appeal and emotional response. Rather than focusing on a single technical innovation, this framework offers an integrated, data-driven approach to decoding tourist perception and contributes to informed decision-making in tourism, heritage conservation, and the design of aesthetically engaging public spaces. 

**Abstract (ZH)**: 历史城镇区在保存文化遗产的同时作为旅游和日常生活的活力空间发挥着重要作用。理解游客对其环境的感知对于人类中心的可持续城市规划至关重要。本研究提出了一种多维度的AI驱动框架，利用社交媒体的多模态数据来分析游客在历史城镇区的感知。该框架应用于上海市中心的十二个历史街区，结合焦点区域提取、颜色主题分析和情感挖掘。通过一种微调的语义分割模型从游客共享的照片中识别视觉关注区域。为了评估审美偏好，使用聚类方法提取主导颜色，并分析其在不同街区的空间分布。通过将社交媒体照片的颜色主题与真实街道视图进行比较，揭示了显著的变化。这种分歧突显了视觉期望与建成环境之间的潜在差距，反映了风格偏好和知觉偏差。通过对基于规则的方法和多任务BERT模型的混合情感分析，评估游客评价。满意度在旅游活动、建成环境、服务设施和商业模式四个维度上进行评估。结果揭示了审美吸引力和情感反应的空间变化。该框架不局限于单一的技术创新，而是提供了一种综合的数据驱动方法，用于解读游客感知并促进旅游业、文化遗产保护和引人入胜的公共空间设计中的决策。 

---
# PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming 

**Title (ZH)**: PersonaTeaming：探究引入人物角色如何改善自动化AI红队演练 

**Authors**: Wesley Hanwen Deng, Sunnie S. Y. Kim, Akshita Jha, Ken Holstein, Motahhare Eslami, Lauren Wilcox, Leon A Gatys  

**Link**: [PDF](https://arxiv.org/pdf/2509.03728)  

**Abstract**: Recent developments in AI governance and safety research have called for red-teaming methods that can effectively surface potential risks posed by AI models. Many of these calls have emphasized how the identities and backgrounds of red-teamers can shape their red-teaming strategies, and thus the kinds of risks they are likely to uncover. While automated red-teaming approaches promise to complement human red-teaming by enabling larger-scale exploration of model behavior, current approaches do not consider the role of identity. As an initial step towards incorporating people's background and identities in automated red-teaming, we develop and evaluate a novel method, PersonaTeaming, that introduces personas in the adversarial prompt generation process to explore a wider spectrum of adversarial strategies. In particular, we first introduce a methodology for mutating prompts based on either "red-teaming expert" personas or "regular AI user" personas. We then develop a dynamic persona-generating algorithm that automatically generates various persona types adaptive to different seed prompts. In addition, we develop a set of new metrics to explicitly measure the "mutation distance" to complement existing diversity measurements of adversarial prompts. Our experiments show promising improvements (up to 144.1%) in the attack success rates of adversarial prompts through persona mutation, while maintaining prompt diversity, compared to RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the strengths and limitations of different persona types and mutation methods, shedding light on future opportunities to explore complementarities between automated and human red-teaming approaches. 

**Abstract (ZH)**: 近期人工智能治理与安全研究的发展呼吁采用能够有效揭示AI模型潜在风险的红队方法。这些呼吁强调了红队成员的身份和背景如何影响红队策略，并进而影响他们可能发现的风险类型。虽然自动化红队方法有望通过支持更广泛的模型行为探索来补充人类红队方法，但现有方法尚未考虑身份的作用。为初步将人们的背景和身份纳入自动化红队方法中，我们开发并评估了一种新方法——PersonaTeaming，该方法在对抗性提示生成过程中引入人格，以探索更广泛的对抗性策略。具体而言，我们首先引入了一种基于“红队专家”人格或“普通AI用户”人格的提示变异方法。然后，我们开发了一种动态的人格生成算法，能够自动生成适应不同种子提示的各种人格类型。此外，我们还开发了一套新的度量标准，以明确度量“变异距离”，补充现有对抗性提示多样性的度量。我们的实验结果显示，与当前最先进的自动化红队方法RainbowPlus相比，通过人格变异，对抗性提示的攻击成功率提高了144.1%，同时保持了提示的多样性。我们讨论了不同人格类型和变异方法的优势与局限性，揭示了未来探索自动化和人类红队方法互补性的潜在机会。 

---
# An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification 

**Title (ZH)**: 时间序列分类中SHAP解释的影响因素 empirical evaluation 

**Authors**: Davide Italo Serramazza, Nikos Papadeas, Zahraa Abdallah, Georgiana Ifrim  

**Link**: [PDF](https://arxiv.org/pdf/2509.03649)  

**Abstract**: Explainable AI (XAI) has become an increasingly important topic for understanding and attributing the predictions made by complex Time Series Classification (TSC) models. Among attribution methods, SHapley Additive exPlanations (SHAP) is widely regarded as an excellent attribution method; but its computational complexity, which scales exponentially with the number of features, limits its practicality for long time series. To address this, recent studies have shown that aggregating features via segmentation, to compute a single attribution value for a group of consecutive time points, drastically reduces SHAP running time. However, the choice of the optimal segmentation strategy remains an open question. In this work, we investigated eight different Time Series Segmentation algorithms to understand how segment compositions affect the explanation quality. We evaluate these approaches using two established XAI evaluation methodologies: InterpretTime and AUC Difference. Through experiments on both Multivariate (MTS) and Univariate Time Series (UTS), we find that the number of segments has a greater impact on explanation quality than the specific segmentation method. Notably, equal-length segmentation consistently outperforms most of the custom time series segmentation algorithms. Furthermore, we introduce a novel attribution normalisation technique that weights segments by their length and we show that it consistently improves attribution quality. 

**Abstract (ZH)**: 可解释人工智能(XAI)已成为理解复杂时间序列分类(TSC)模型预测的重要话题。在归因方法中，SHapley Additive exPlanations (SHAP)被认为是优秀的归因方法之一，但由于其计算复杂性随特征数量指数增长，限制了其在长时间序列上的实用性。为解决这一问题，最近的研究表明，通过分段聚合特征来计算一系列连续时间点的单一归因值，可以大幅减少SHAP的运行时间。然而，最优分段策略的选择仍然是一个开放问题。在本文中，我们研究了八种不同的时间序列分段算法，以了解分段组成如何影响解释质量。我们使用两种已建立的XAI评估方法：InterpretTime和AUC Difference来评估这些方法。通过在多变量时间序列(MTS)和单变量时间序列(UTS)上的实验，我们发现时间段的数量对解释质量的影响大于特定分段方法的选择。值得注意的是，等长度分段始终优于大多数自定义时间序列分段算法。此外，我们引入了一种新的归因规范化技术，通过时间段长度进行加权，并展示了其一致地提高了归因质量。 

---
# Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models 

**Title (ZH)**: 部分可识别查询在准马尔可夫结构因果模型中的多线性与线性规划 

**Authors**: João P. Arroyo, João G. Rodrigues, Daniel Lawand, Denis D. Mauá, Junkyu Lee, Radu Marinescu, Alex Gray, Eduardo R. Laurentino, Fabio G. Cozman  

**Link**: [PDF](https://arxiv.org/pdf/2509.03548)  

**Abstract**: We investigate partially identifiable queries in a class of causal models. We focus on acyclic Structural Causal Models that are quasi-Markovian (that is, each endogenous variable is connected with at most one exogenous confounder). We look into scenarios where endogenous variables are observed (and a distribution over them is known), while exogenous variables are not fully specified. This leads to a representation that is in essence a Bayesian network where the distribution of root variables is not uniquely determined. In such circumstances, it may not be possible to precisely compute a probability value of interest. We thus study the computation of tight probability bounds, a problem that has been solved by multilinear programming in general, and by linear programming when a single confounded component is intervened upon. We present a new algorithm to simplify the construction of such programs by exploiting input probabilities over endogenous variables. For scenarios with a single intervention, we apply column generation to compute a probability bound through a sequence of auxiliary linear integer programs, thus showing that a representation with polynomial cardinality for exogenous variables is possible. Experiments show column generation techniques to be superior to existing methods. 

**Abstract (ZH)**: 我们在因果模型类中研究部分可识别查询。我们侧重于无环结构因果模型，这些模型准马尔可夫（即，每个内生变量最多与一个外生混杂变量相连）。我们探讨了内生变量已观测且其分布已知而外生变量不完全指定的情况，这种情况下，代表本质上是一个贝叶斯网络，其中根变量的分布不是唯一确定的。在这种情况下，可能无法精确计算感兴趣的概率值。因此，我们研究了计算紧概率界的计算问题，这个问题一般通过多线性规划解决，当干预单一混杂成分时可以通过线性规划解决。我们提出了一种新算法，通过利用内生变量的输入概率简化此类程序的构造。对于单一干预情景，我们采用列生成技术通过一系列辅助线性整数规划计算概率界，从而证明在外生变量表示中存在多项式基数的表示方法。实验显示列生成技术优于现有方法。 

---
# ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset 

**Title (ZH)**: ChronoGraph: 一种基于图的现实世界多变量时间序列数据集 

**Authors**: Adrian Catalin Lutu, Ioana Pintilie, Elena Burceanu, Andrei Manolache  

**Link**: [PDF](https://arxiv.org/pdf/2509.04449)  

**Abstract**: We present ChronoGraph, a graph-structured multivariate time series forecasting dataset built from real-world production microservices. Each node is a service that emits a multivariate stream of system-level performance metrics, capturing CPU, memory, and network usage patterns, while directed edges encode dependencies between services. The primary task is forecasting future values of these signals at the service level. In addition, ChronoGraph provides expert-annotated incident windows as anomaly labels, enabling evaluation of anomaly detection methods and assessment of forecast robustness during operational disruptions. Compared to existing benchmarks from industrial control systems or traffic and air-quality domains, ChronoGraph uniquely combines (i) multivariate time series, (ii) an explicit, machine-readable dependency graph, and (iii) anomaly labels aligned with real incidents. We report baseline results spanning forecasting models, pretrained time-series foundation models, and standard anomaly detectors. ChronoGraph offers a realistic benchmark for studying structure-aware forecasting and incident-aware evaluation in microservice systems. 

**Abstract (ZH)**: ChronoGraph：一种基于真实生产微服务构建的图结构多变量时间序列预测数据集 

---
# Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer 

**Title (ZH)**: 基于多源数据融合与自监督学习增强空间-时间反向变换的停车 availability 预测 

**Authors**: Yin Huang, Yongqi Dong, Youhua Tang, Li Li  

**Link**: [PDF](https://arxiv.org/pdf/2509.04362)  

**Abstract**: The rapid growth of private car ownership has worsened the urban parking predicament, underscoring the need for accurate and effective parking availability prediction to support urban planning and management. To address key limitations in modeling spatio-temporal dependencies and exploiting multi-source data for parking availability prediction, this study proposes a novel approach with SST-iTransformer. The methodology leverages K-means clustering to establish parking cluster zones (PCZs), extracting and integrating traffic demand characteristics from various transportation modes (i.e., metro, bus, online ride-hailing, and taxi) associated with the targeted parking lots. Upgraded on vanilla iTransformer, SST-iTransformer integrates masking-reconstruction-based pretext tasks for self-supervised spatio-temporal representation learning, and features an innovative dual-branch attention mechanism: Series Attention captures long-term temporal dependencies via patching operations, while Channel Attention models cross-variate interactions through inverted dimensions. Extensive experiments using real-world data from Chengdu, China, demonstrate that SST-iTransformer outperforms baseline deep learning models (including Informer, Autoformer, Crossformer, and iTransformer), achieving state-of-the-art performance with the lowest mean squared error (MSE) and competitive mean absolute error (MAE). Comprehensive ablation studies quantitatively reveal the relative importance of different data sources: incorporating ride-hailing data provides the largest performance gains, followed by taxi, whereas fixed-route transit features (bus/metro) contribute marginally. Spatial correlation analysis further confirms that excluding historical data from correlated parking lots within PCZs leads to substantial performance degradation, underscoring the importance of modeling spatial dependencies. 

**Abstract (ZH)**: 私家车拥有量的快速增长加剧了城市停车难题，强调了准确有效的停车可用性预测对于支持城市规划和管理的重要性。为解决模型时空依赖性建模和多源数据利用方面的关键局限性，本研究提出了一种基于SST-iTransformer的新方法。该方法利用K-means聚类建立停车集群区（PCZs），并从与目标停车场相关的各种交通模式（即地铁、公交车、在线网约车和出租车）中提取和整合交通需求特征。基于vanilla iTransformer进行升级，SST-iTransformer结合了基于掩蔽重建的先验任务进行自我监督的时空表示学习，并采用创新的双分支注意力机制：序列注意力通过分块操作捕获长时序依赖性，而通道注意力通过反转维度建模跨变量交互。使用来自中国成都的实地数据进行的广泛实验表明，SST-iTransformer在基准深度学习模型（包括Informer、Autoformer、Crossformer和iTransformer）中表现出优越性能，实现最先进的性能，具有最低的均方误差（MSE）和竞争力均绝对误差（MAE）。全面的消融研究定性揭示了不同数据源的重要性：纳入网约车数据提供了最大的性能提升，其次是出租车，而固定路线公共交通特征（公交/地铁）的贡献较小。空间相关性分析进一步证实，在PCZ中排除相关停车场的历史数据会极大地降低性能，强调了建模空间依赖性的 importance。 

---
# PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation 

**Title (ZH)**: PARCO: 音素增强 robust 上下文 ASR 通过对比实体消歧 

**Authors**: Jiajun He, Naoki Sawada, Koichi Miyazaki, Tomoki Toda  

**Link**: [PDF](https://arxiv.org/pdf/2509.04357)  

**Abstract**: Automatic speech recognition (ASR) systems struggle with domain-specific named entities, especially homophones. Contextual ASR improves recognition but often fails to capture fine-grained phoneme variations due to limited entity diversity. Moreover, prior methods treat entities as independent tokens, leading to incomplete multi-token biasing. To address these issues, we propose Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation (PARCO), which integrates phoneme-aware encoding, contrastive entity disambiguation, entity-level supervision, and hierarchical entity filtering. These components enhance phonetic discrimination, ensure complete entity retrieval, and reduce false positives under uncertainty. Experiments show that PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO also demonstrates robust gains on out-of-domain datasets like THCHS-30 and LibriSpeech. 

**Abstract (ZH)**: 基于对比实体消歧的音素增强稳健上下文语音识别（PARCO） 

---
# AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds 

**Title (ZH)**: AUDETER：开放世界中的深度假音检测大型数据集 

**Authors**: Qizhou Wang, Hanxun Huang, Guansong Pang, Sarah Erfani, Christopher Leckie  

**Link**: [PDF](https://arxiv.org/pdf/2509.04345)  

**Abstract**: Speech generation systems can produce remarkably realistic vocalisations that are often indistinguishable from human speech, posing significant authenticity challenges. Although numerous deepfake detection methods have been developed, their effectiveness in real-world environments remains unrealiable due to the domain shift between training and test samples arising from diverse human speech and fast evolving speech synthesis systems. This is not adequately addressed by current datasets, which lack real-world application challenges with diverse and up-to-date audios in both real and deep-fake categories. To fill this gap, we introduce AUDETER (AUdio DEepfake TEst Range), a large-scale, highly diverse deepfake audio dataset for comprehensive evaluation and robust development of generalised models for deepfake audio detection. It consists of over 4,500 hours of synthetic audio generated by 11 recent TTS models and 10 vocoders with a broad range of TTS/vocoder patterns, totalling 3 million audio clips, making it the largest deepfake audio dataset by scale. Through extensive experiments with AUDETER, we reveal that i) state-of-the-art (SOTA) methods trained on existing datasets struggle to generalise to novel deepfake audio samples and suffer from high false positive rates on unseen human voice, underscoring the need for a comprehensive dataset; and ii) these methods trained on AUDETER achieve highly generalised detection performance and significantly reduce detection error rate by 44.1% to 51.6%, achieving an error rate of only 4.17% on diverse cross-domain samples in the popular In-the-Wild dataset, paving the way for training generalist deepfake audio detectors. AUDETER is available on GitHub. 

**Abstract (ZH)**: 基于音频的深度伪造检测数据集AUDETER：全面评估与鲁棒开发 

---
# Decoupled Entity Representation Learning for Pinterest Ads Ranking 

**Title (ZH)**: 拆分实体表示学习在 Pinterest 广告排名中的应用 

**Authors**: Jie Liu, Yinrui Li, Jiankai Sun, Kungang Li, Han Sun, Sihan Wang, Huasen Wu, Siyuan Gao, Paulo Soares, Nan Li, Zhifang Liu, Haoyang Li, Siping Ji, Ling Leng, Prathibha Deshikachar  

**Link**: [PDF](https://arxiv.org/pdf/2509.04337)  

**Abstract**: In this paper, we introduce a novel framework following an upstream-downstream paradigm to construct user and item (Pin) embeddings from diverse data sources, which are essential for Pinterest to deliver personalized Pins and ads effectively. Our upstream models are trained on extensive data sources featuring varied signals, utilizing complex architectures to capture intricate relationships between users and Pins on Pinterest. To ensure scalability of the upstream models, entity embeddings are learned, and regularly refreshed, rather than real-time computation, allowing for asynchronous interaction between the upstream and downstream models. These embeddings are then integrated as input features in numerous downstream tasks, including ad retrieval and ranking models for CTR and CVR predictions. We demonstrate that our framework achieves notable performance improvements in both offline and online settings across various downstream tasks. This framework has been deployed in Pinterest's production ad ranking systems, resulting in significant gains in online metrics. 

**Abstract (ZH)**: 本文介绍了一种遵循上下游 paradigm 的新颖框架，从多种数据源构建用户和物品（Pin）嵌入，以有效实现 Pinterest 的个性化 Pins 和广告推荐。上游模型在包含多样化信号的大量数据源上进行训练，采用复杂的架构来捕捉 Pinterest 上用户和物品之间的复杂关系。为了确保上游模型的可扩展性，实体嵌入被学习并定期更新，而不是实时计算，从而使上游和下游模型之间能够异步交互。这些嵌入随后被整合为多种下游任务（如点击率和转换率预测的广告检索和排序模型）的输入特征。研究表明，该框架在各种下游任务的离线和在线设置中均实现了显著性能提升。该框架已在 Pinterest 的生产广告排名系统中部署，导致在线指标取得了显著提升。 

---
# HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning 

**Title (ZH)**: HumAIne-Chatbot: 通过强化学习实现的实时个性化对话AI 

**Authors**: Georgios Makridis, Georgios Fragiadakis, Jorge Oliveira, Tomaz Saraiva, Philip Mavrepis, Georgios Fatouros, Dimosthenis Kyriazis  

**Link**: [PDF](https://arxiv.org/pdf/2509.04303)  

**Abstract**: Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation. 

**Abstract (ZH)**: 当前的对话AI系统通常提供通用的一刀切交互，忽视了用户个体特性，缺乏适应性的对话管理。为了弥补这一不足，我们引入了\textbf{HumAIne-chatbot}，这是一种通过新颖的用户 profiling 框架个性化的AI驱动对话代理。系统在多种GPT生成的虚拟人物数据集上预先训练，以建立广泛的用户类型先验。在实时交互过程中，在线强化学习代理通过结合隐含信号（例如打字速度、情感、参与时长）和明确反馈（例如喜好和厌恶）来细化每个用户的模型。该profile动态地指导聊天机器人的对话策略，使内容和风格能够实现实时适应。为了评估该系统，我们在多个对话领域进行了50个合成人物的受控实验。结果表明，当启用个性化功能时，用户满意度、个性化准确性和任务完成度都得到了持续改进。统计分析证实了个性化和非个性化条件之间的显著差异，关键指标上的效应量很大。这些结果突显了AI驱动用户profiling的有效性，并为未来的实际场景验证奠定了坚实基础。 

---
# An Empirical Study of Vulnerabilities in Python Packages and Their Detection 

**Title (ZH)**: Python包中的漏洞及其检测的实证研究 

**Authors**: Haowei Quan, Junjie Wang, Xinzhe Li, Terry Yue Zhuo, Xiao Chen, Xiaoning Du  

**Link**: [PDF](https://arxiv.org/pdf/2509.04260)  

**Abstract**: In the rapidly evolving software development landscape, Python stands out for its simplicity, versatility, and extensive ecosystem. Python packages, as units of organization, reusability, and distribution, have become a pressing concern, highlighted by the considerable number of vulnerability reports. As a scripting language, Python often cooperates with other languages for performance or interoperability. This adds complexity to the vulnerabilities inherent to Python packages, and the effectiveness of current vulnerability detection tools remains underexplored. This paper addresses these gaps by introducing PyVul, the first comprehensive benchmark suite of Python-package vulnerabilities. PyVul includes 1,157 publicly reported, developer-verified vulnerabilities, each linked to its affected packages. To accommodate diverse detection techniques, it provides annotations at both commit and function levels. An LLM-assisted data cleansing method is incorporated to improve label accuracy, achieving 100% commit-level and 94% function-level accuracy, establishing PyVul as the most precise large-scale Python vulnerability benchmark. We further carry out a distribution analysis of PyVul, which demonstrates that vulnerabilities in Python packages involve multiple programming languages and exhibit a wide variety of types. Moreover, our analysis reveals that multi-lingual Python packages are potentially more susceptible to vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark reveals a significant discrepancy between the capabilities of existing tools and the demands of effectively identifying real-world security issues in Python packages. Additionally, we conduct an empirical review of the top-ranked CWEs observed in Python packages, to diagnose the fine-grained limitations of current detection tools and highlight the necessity for future advancements in the field. 

**Abstract (ZH)**: 在快速发展的软件开发landscape中，Python凭借其简洁性、灵活性和广泛的生态系统脱颖而出。Python包作为组织、重用和分发的单位，已成为一个紧迫的关注点，这体现在大量漏洞报告中。作为一种脚本语言，Python经常与其他语言合作以提高性能或实现互操作性。这增加了Python包固有漏洞的复杂性，当前漏洞检测工具的有效性也未得到充分探索。本文通过介绍PyVul，提出了首个全面的Python包漏洞基准套件，填补了这一空白。PyVul包含1,157个公开报告的、开发者验证的漏洞，每个漏洞都链接到受影响的包。为了适应多样化的检测技术，它在提交和函数级别提供了注解。引入了基于LLM的数据清洗方法，以提高标签准确性，实现了100%的提交级别和94%的函数级别准确性，使得PyVul成为最精确的大规模Python漏洞基准。进一步对PyVul进行了分布分析，结果显示Python包中的漏洞涉及多种编程语言，并表现出多种类型。此外，我们的分析表明，多语言Python包可能更易受到漏洞的影响。使用此基准评估最先进的检测器揭示了现有工具的能力与有效识别Python包实际安全问题的需求之间存在显著差距。此外，我们还对Python包中观察到的顶级CWE进行实证审查，以诊断当前检测工具的细粒度限制，并指出未来该领域需要的进步。 

---
# Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds 

**Title (ZH)**: 跨越物种界线：从语音到动物声音的迁移学习 

**Authors**: Jules Cauzinille, Marius Miron, Olivier Pietquin, Masato Hagiwara, Ricard Marxer, Arnaud Rey, Benoit Favre  

**Link**: [PDF](https://arxiv.org/pdf/2509.04166)  

**Abstract**: Self-supervised speech models have demonstrated impressive performance in speech processing, but their effectiveness on non-speech data remains underexplored. We study the transfer learning capabilities of such models on bioacoustic detection and classification tasks. We show that models such as HuBERT, WavLM, and XEUS can generate rich latent representations of animal sounds across taxa. We analyze the models properties with linear probing on time-averaged representations. We then extend the approach to account for the effect of time-wise information with other downstream architectures. Finally, we study the implication of frequency range and noise on performance. Notably, our results are competitive with fine-tuned bioacoustic pre-trained models and show the impact of noise-robust pre-training setups. These findings highlight the potential of speech-based self-supervised learning as an efficient framework for advancing bioacoustic research. 

**Abstract (ZH)**: 非语音数据上自我监督语音模型的迁移学习能力研究：以生物声学检测与分类为例 

---
# Attention as an Adaptive Filter 

**Title (ZH)**: Attention作为一种自适应滤波器 

**Authors**: Peter Racioppo  

**Link**: [PDF](https://arxiv.org/pdf/2509.04154)  

**Abstract**: We introduce Adaptive Filter Attention (AFA), a novel attention mechanism that incorporates a learnable dynamics model directly into the computation of attention weights. Rather than comparing queries and keys directly, we model the input sequence as discrete observations of a linear stochastic differential equation (SDE). By imposing a linear dynamics model with simultaneously diagonalizable state matrices and noise covariances, we can make use of a closed-form solution to the differential Lyapunov equation to efficiently propagate pairwise uncertainties through the dynamics. Attention naturally arises as the maximum likelihood solution for this linear SDE, with attention weights corresponding to robust residual-based reweightings of the propagated pairwise precisions. Imposing an additional constraint on the state matrix's eigenvalues leads to a simplified variant with the same computational and memory complexity as standard attention. In the limit of vanishing dynamics and process noise, and using a small-angle approximation, we recover ordinary dot-product attention. 

**Abstract (ZH)**: 自适应滤波注意力机制：直接将可学习的动力学模型融入注意力权重的计算中 

---
# SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification 

**Title (ZH)**: SAC-MIL：Spatial-aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification 

**Authors**: Yu Bai, Zitong Yu, Haowen Tian, Xijing Wang, Shuo Yan, Lin Wang, Honglin Li, Xitong Ling, Bo Zhang, Zheng Zhang, Wufan Wang, Hui Gao, Xiangyang Gong, Wendong Wang  

**Link**: [PDF](https://arxiv.org/pdf/2509.03973)  

**Abstract**: We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for performing WSI classification. SAC-MIL consists of a positional encoding module to encode position information and a SAC block to perform full instance correlations. The positional encoding module utilizes the instance coordinates within the slide to encode the spatial relationships instead of the instance index in the input WSI sequence. The positional encoding module can also handle the length extrapolation issue where the training and testing sequences have different lengths. The SAC block is an MLP-based method that performs full instance correlation in linear time complexity with respect to the sequence length. Due to the simple structure of MLP, it is easy to deploy since it does not require custom CUDA kernels, compared to Transformer-based methods for WSI classification. SAC-MIL has achieved state-of-the-art performance on the CAMELYON-16, TCGA-LUNG, and TCGA-BRAC datasets. The code will be released upon acceptance. 

**Abstract (ZH)**: 基于空间意识的 correlated 多实例学习 (SAC-MIL) 用于 WSI 分类 

---
# Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection 

**Title (ZH)**: 基于文本差异增强的多模态特征融合网络在遥感变化检测中的应用 

**Authors**: Yijun Zhou, Yikui Zhai, Zilu Ying, Tingfeng Xian, Wenlve Zhou, Zhiheng Zhou, Xiaolin Tian, Xudong Jia, Hongsheng Zhang, C. L. Philip Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.03961)  

**Abstract**: Although deep learning has advanced remote sensing change detection (RSCD), most methods rely solely on image modality, limiting feature representation, change pattern modeling, and generalization especially under illumination and noise disturbances. To address this, we propose MMChange, a multimodal RSCD method that combines image and text modalities to enhance accuracy and robustness. An Image Feature Refinement (IFR) module is introduced to highlight key regions and suppress environmental noise. To overcome the semantic limitations of image features, we employ a vision language model (VLM) to generate semantic descriptions of bitemporal images. A Textual Difference Enhancement (TDE) module then captures fine grained semantic shifts, guiding the model toward meaningful changes. To bridge the heterogeneity between modalities, we design an Image Text Feature Fusion (ITFF) module that enables deep cross modal integration. Extensive experiments on LEVIRCD, WHUCD, and SYSUCD demonstrate that MMChange consistently surpasses state of the art methods across multiple metrics, validating its effectiveness for multimodal RSCD. Code is available at: this https URL. 

**Abstract (ZH)**: 尽管深度学习在遥感变化检测（RSCD）方面取得了进展，大多数方法仅依赖图像模态，限制了特征表示、变化模式建模以及在光照和噪声干扰下的泛化能力。为解决这一问题，我们提出了一种融合图像和文本模态的MMChange方法，以提高准确性和鲁棒性。引入了图像特征精炼（IFR）模块以突出关键区域并抑制环境噪声。为克服图像特征的语义限制，我们采用了一种视觉语言模型（VLM）生成双时相图像的语义描述。随后，文本差异增强（TDE）模块捕捉细微的语义变化，指导模型向有意义的变化发展。为弥合模态差异，我们设计了图像文本特征融合（ITFF）模块，实现深层次的跨模态整合。在LEVIRCD、WHUCD和SYSUCD上的 extensive 实验表明，MMChange 在多个指标上持续超过了现有方法，验证了其在多模态RSCD中的有效性。代码可在以下链接获取：this https URL。 

---
# Diffusion Generative Models Meet Compressed Sensing, with Applications to Image Data and Financial Time Series 

**Title (ZH)**: 扩散生成模型与压缩感知的结合及其在图像数据和金融时间序列中的应用 

**Authors**: Zhengyi Guo, Jiatu Li, Wenpin Tang, David D. Yao  

**Link**: [PDF](https://arxiv.org/pdf/2509.03898)  

**Abstract**: This paper develops dimension reduction techniques for accelerating diffusion model inference in the context of synthetic data generation. The idea is to integrate compressed sensing into diffusion models: (i) compress the data into a latent space, (ii) train a diffusion model in the latent space, and (iii) apply a compressed sensing algorithm to the samples generated in the latent space, facilitating the efficiency of both model training and inference. Under suitable sparsity assumptions on data, the proposed algorithm is proved to enjoy faster convergence by combining diffusion model inference with sparse recovery. As a byproduct, we obtain an optimal value for the latent space dimension. We also conduct numerical experiments on a range of datasets, including image data (handwritten digits, medical images, and climate data) and financial time series for stress testing. 

**Abstract (ZH)**: 本文开发了维度缩减技术以加速合成数据生成中的扩散模型推理。该方法将压缩感知集成到扩散模型中：(i) 将数据压缩到潜在空间，(ii) 在潜在空间训练扩散模型，(iii) 对潜在空间生成的样本应用压缩感知算法，从而提高模型训练和推理的效率。在适合的稀疏性假设下，所提出的算法通过结合扩散模型推理和稀疏恢复实现了更快的收敛。作为副产品，我们获得了潜在空间维数的最优值。我们还在图像数据（手写数字、医学图像和气候数据）和金融时间序列（压力测试）等多种数据集上进行了数值实验。 

---
# Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network 

**Title (ZH)**: 基于肽组学的冠心病预测模型：多层感知机神经网络方法 

**Authors**: Jesus Celis-Porras  

**Link**: [PDF](https://arxiv.org/pdf/2509.03884)  

**Abstract**: Coronary heart disease (CHD) is a leading cause of death worldwide and contributes significantly to annual healthcare expenditures. To develop a non-invasive diagnostic approach, we designed a model based on a multilayer perceptron (MLP) neural network, trained on 50 key urinary peptide biomarkers selected via genetic algorithms. Treatment and control groups, each comprising 345 individuals, were balanced using the Synthetic Minority Over-sampling Technique (SMOTE). The neural network was trained using a stratified validation strategy. Using a network with three hidden layers of 60 neurons each and an output layer of two neurons, the model achieved a precision, sensitivity, and specificity of 95.67 percent, with an F1-score of 0.9565. The area under the ROC curve (AUC) reached 0.9748 for both classes, while the Matthews correlation coefficient (MCC) and Cohen's kappa coefficient were 0.9134 and 0.9131, respectively, demonstrating its reliability in detecting CHD. These results indicate that the model provides a highly accurate and robust non-invasive diagnostic tool for coronary heart disease. 

**Abstract (ZH)**: 冠心病（CHD）是全球主要的死亡原因之一，显著增加了年度医疗支出。为了开发一种无创诊断方法，我们设计了一个基于多层感知机（MLP）神经网络的模型，该模型利用遗传算法选择了50个关键尿液肽生物标记物。治疗组和对照组，每组各包括345名个体，通过合成少数类过采样技术（SMOTE）进行了平衡。神经网络使用分层验证策略进行训练。使用具有三个隐藏层，每层60个神经元以及一个输出层两个神经元的网络，模型实现了95.67%的精确率、敏感性和特异性，F1分数为0.9565。两类的受试者操作特征曲线下面积（AUC）达到了0.9748，而马修相关系数（MCC）和科恩κ系数分别为0.9134和0.9131，表明该模型在检测冠心病方面具有很高的可靠性和准确性。这些结果表明，该模型提供了一种高度准确和稳健的无创诊断工具，用于冠心病的诊断。 

---
# MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting 

**Title (ZH)**: MillGNN：学习多尺度领先-滞后依赖关系的多变量时间序列预测 

**Authors**: Binqing Wu, Zongjiang Shang, Jianlong Huang, Ling Chen  

**Link**: [PDF](https://arxiv.org/pdf/2509.03852)  

**Abstract**: Multi-variate time series (MTS) forecasting is crucial for various applications. Existing methods have shown promising results owing to their strong ability to capture intra- and inter-variate dependencies. However, these methods often overlook lead-lag dependencies at multiple grouping scales, failing to capture hierarchical lead-lag effects in complex systems. To this end, we propose MillGNN, a novel \underline{g}raph \underline{n}eural \underline{n}etwork-based method that learns \underline{m}ult\underline{i}ple grouping scale \underline{l}ead-\underline{l}ag dependencies for MTS forecasting, which can comprehensively capture lead-lag effects considering variate-wise and group-wise dynamics and decays. Specifically, MillGNN introduces two key innovations: (1) a scale-specific lead-lag graph learning module that integrates cross-correlation coefficients and dynamic decaying features derived from real-time inputs and time lags to learn lead-lag dependencies for each scale, which can model evolving lead-lag dependencies with statistical interpretability and data-driven flexibility; (2) a hierarchical lead-lag message passing module that passes lead-lag messages at multiple grouping scales in a structured way to simultaneously propagate intra- and inter-scale lead-lag effects, which can capture multi-scale lead-lag effects with a balance of comprehensiveness and efficiency. Experimental results on 11 datasets demonstrate the superiority of MillGNN for long-term and short-term MTS forecasting, compared with 16 state-of-the-art methods. 

**Abstract (ZH)**: 多变量时间序列(MTS)预测对于各种应用至关重要。现有方法因其强大的内在和跨变量依赖关系捕捉能力而显示出有前途的结果。然而，这些方法往往忽略了多个分组尺度上的领先-滞后依赖关系，未能捕捉复杂系统中的层次领先-滞后效应。为了解决这一问题，我们提出了一种新颖的基于图神经网络的方法MillGNN，它能够学习多分组尺度的领先-滞后依赖关系，从而综合考虑变量层面和分组层面的动力学和衰减，全面捕捉领先-滞后效应。MillGNN引入了两个关键创新：(1) 一种尺度特定的领先-滞后图学习模块，该模块结合了来自实时输入和时间滞后的真实跨相关系数和动态衰减特征，以学习每个尺度的领先-滞后依赖关系，能够以统计可解释性和数据驱动的灵活性建模随时间演变的领先-滞后依赖关系；(2) 一种分层领先-滞后消息传递模块，该模块以结构化的方式在多个分组尺度上传递领先-滞后消息，同时传播内在和跨尺度的领先-滞后效应，能够以全面性和效率之间的平衡捕捉多尺度的领先-滞后效应。在11个数据集上的实验结果表明，MillGNN在长短期MTS预测中优于16种最先进的方法。 

---
# Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables 

**Title (ZH)**: 基于概率情境变量的元逆强化学习在均场博弈中的应用 

**Authors**: Yang Chen, Xiao Lin, Bo Yan, Libo Zhang, Jiamou Liu, Neset Özkan Tan, Michael Witbrock  

**Link**: [PDF](https://arxiv.org/pdf/2509.03845)  

**Abstract**: Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs. 

**Abstract (ZH)**: 设计适合众多相互智能代理的奖励函数在实际应用中具有挑战性。均场游戏中的逆强化学习为从专家演示中推断奖励函数提供了实用框架。然而，代理同质性的假设限制了现有方法处理具有异质性和未知目标的演示能力，而这在实践中很常见。为此，我们提出了一种深度潜变量均场游戏模型及其相关的逆强化学习方法。关键的是，我们的方法可以在没有了解底层上下文或修改均场游戏模型本身的情况下，从不同但结构相似的任务中推断出奖励。我们在模拟场景和实际的空.action定价问题中的实验表明，与当前最佳的均场游戏中逆强化学习方法相比，我们的方法更优。 

---
# From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game 

**Title (ZH)**: 从莱登到快乐岛：常数Potts模型在社区检测中的 hedonic 规则 

**Authors**: Lucas Lopes Felipe, Konstantin Avrachenkov, Daniel Sadoc Menasche  

**Link**: [PDF](https://arxiv.org/pdf/2509.03834)  

**Abstract**: Community detection is one of the fundamental problems in data science which consists of partitioning nodes into disjoint communities. We present a game-theoretic perspective on the Constant Potts Model (CPM) for partitioning networks into disjoint communities, emphasizing its efficiency, robustness, and accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by decomposing its global Hamiltonian into local utility functions, where the local utility gain of each agent matches the corresponding increase in global utility. Leveraging this equivalence, we prove that local optimization of the CPM objective via better-response dynamics converges in pseudo-polynomial time to an equilibrium partition. Robustness: We introduce and relate two stability criteria: a strict criterion based on a novel notion of robustness, requiring nodes to simultaneously maximize neighbors and minimize non-neighbors within communities, and a relaxed utility function based on a weighted sum of these objectives, controlled by a resolution parameter. Accuracy: In community tracking scenarios, where initial partitions are used to bootstrap the Leiden algorithm with partial ground-truth information, our experiments reveal that robust partitions yield higher accuracy in recovering ground-truth communities. 

**Abstract (ZH)**: 基于博弈论视角的常数潘特模型在分离网络社区中的应用：效率、稳健性和准确性 

---
# Measuring How (Not Just Whether) VLMs Build Common Ground 

**Title (ZH)**: 测量（而不仅仅是判断）大模型如何构建共同基础 

**Authors**: Saki Imai, Mert İnan, Anthony Sicilia, Malihe Alikhani  

**Link**: [PDF](https://arxiv.org/pdf/2509.03805)  

**Abstract**: Large vision language models (VLMs) increasingly claim reasoning skills, yet current benchmarks evaluate them in single-turn or question answering settings. However, grounding is an interactive process in which people gradually develop shared understanding through ongoing communication. We introduce a four-metric suite (grounding efficiency, content alignment, lexical adaptation, and human-likeness) to systematically evaluate VLM performance in interactive grounding contexts. We deploy the suite on 150 self-play sessions of interactive referential games between three proprietary VLMs and compare them with human dyads. All three models diverge from human patterns on at least three metrics, while GPT4o-mini is the closest overall. We find that (i) task success scores do not indicate successful grounding and (ii) high image-utterance alignment does not necessarily predict task success. Our metric suite and findings offer a framework for future research on VLM grounding. 

**Abstract (ZH)**: 大型视觉语言模型在交互式接地场景中的系统评估：基于四个指标的框架 

---
# SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation 

**Title (ZH)**: SiLVERScore: 语义aware嵌入表示在手语生成评估中的应用 

**Authors**: Saki Imai, Mert İnan, Anthony Sicilia, Malihe Alikhani  

**Link**: [PDF](https://arxiv.org/pdf/2509.03791)  

**Abstract**: Evaluating sign language generation is often done through back-translation, where generated signs are first recognized back to text and then compared to a reference using text-based metrics. However, this two-step evaluation pipeline introduces ambiguity: it not only fails to capture the multimodal nature of sign language-such as facial expressions, spatial grammar, and prosody-but also makes it hard to pinpoint whether evaluation errors come from sign generation model or the translation system used to assess it. In this work, we propose SiLVERScore, a novel semantically-aware embedding-based evaluation metric that assesses sign language generation in a joint embedding space. Our contributions include: (1) identifying limitations of existing metrics, (2) introducing SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness to semantic and prosodic variations, and (4) exploring generalization challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore achieves near-perfect discrimination between correct and random pairs (ROC AUC = 0.99, overlap < 7%), substantially outperforming traditional metrics. 

**Abstract (ZH)**: 评估手语生成通常通过回译进行，即将生成的手语首先识别回文本，然后使用文本指标与参考文本进行对比。然而，这种两步评估管道引入了模糊性：它不仅未能捕捉手语的多模态性质——如面部表情、空间语法和语调，还使得难以确定评估错误是源自手语生成模型还是用于评估的手译系统。在本文中，我们提出了SiLVERScore，这是一种新颖的感知语义的嵌入式评价指标，用于在联合嵌入空间中评估手语生成。我们的贡献包括：(1) 识别现有指标的局限性，(2) 引入SiLVERScore进行感知语义的评估，(3) 展示其对语义和语调变化的鲁棒性，并且(4) 探讨跨数据集的一般化挑战。SiLVERScore在PHOENIX-14T和CSL-Daily数据集上，几乎完美地区分了正确和随机配对（ROC AUC = 0.99，重叠<7%），显著优于传统指标。 

---
# What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning? 

**Title (ZH)**: 奖励函数中的什么基础结构能 Enable 有效的稀疏奖励学习？ 

**Authors**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma  

**Link**: [PDF](https://arxiv.org/pdf/2509.03790)  

**Abstract**: What fundamental properties of reward functions enable efficient sparse-reward reinforcement learning? We address this question through the lens of low-rank structure in reward matrices, showing that such structure induces a sharp transition from exponential to polynomial sample complexity, the first result of this kind for sparse-reward RL. We introduce Policy-Aware Matrix Completion (PAMC), which connects matrix completion theory with reinforcement learning via a new analysis of policy-dependent sampling. Our framework provides: (i) impossibility results for general sparse reward observation, (ii) reward-free representation learning from dynamics, (iii) distribution-free confidence sets via conformal prediction, and (iv) robust completion guarantees that degrade gracefully when low-rank structure is only approximate. Empirically, we conduct a pre-registered evaluation across 100 systematically sampled domains, finding exploitable structure in over half. PAMC improves sample efficiency by factors between 1.6 and 2.1 compared to strong exploration, structured, and representation-learning baselines, while adding only about 20 percent computational this http URL results establish structural reward learning as a promising new paradigm, with immediate implications for robotics, healthcare, and other safety-critical, sample-expensive applications. 

**Abstract (ZH)**: 哪些基础性属性使奖励函数能够支持高效的稀疏奖励强化学习？通过奖励矩阵的低秩结构视角，我们探讨了这一问题，展示了这种结构导致从指数到多项式的样本复杂度急剧转变，这是首次在稀疏奖励RL中获得此类结果。我们引入了基于策略的矩阵补全(PAMC)方法，将矩阵补全理论与强化学习通过策略相关采样的新分析联系起来。我们的框架提供了：(i) 一般稀疏奖励观察的不可能性结果，(ii) 基于动力学的奖励免费表示学习，(iii) 基于全同预测的无分布置信集，以及(iv) 当低秩结构仅近似时表现良好的补全保证。实验中，我们在100个系统采样的领域进行了注册评估，发现超过一半的领域存在可利用的结构。与强大的探索、结构化和表示学习基线相比，PAMC在样本效率上提高了1.6到2.1倍，同时仅增加了约20%的计算开销。这些结果确立了结构奖励学习作为有前景的新范式，并对机器人技术、医疗保健及其他安全性至关重要的、样本昂贵的应用领域具有直接影响。 

---
# Natural Latents: Latent Variables Stable Across Ontologies 

**Title (ZH)**: 自然隐变量：跨本体稳定的隐变量 

**Authors**: John Wentworth, David Lorell  

**Link**: [PDF](https://arxiv.org/pdf/2509.03780)  

**Abstract**: Suppose two Bayesian agents each learn a generative model of the same environment. We will assume the two have converged on the predictive distribution, i.e. distribution over some observables in the environment, but may have different generative models containing different latent variables. Under what conditions can one agent guarantee that their latents are a function of the other agents latents?
We give simple conditions under which such translation is guaranteed to be possible: the natural latent conditions. We also show that, absent further constraints, these are the most general conditions under which translatability is guaranteed. Crucially for practical application, our theorems are robust to approximation error in the natural latent conditions. 

**Abstract (ZH)**: 假设两个贝叶斯代理各自学习同一环境的生成模型。我们将假设这两个代理已经在预测分布上收敛，即环境中的某些可观测值的分布，但它们的生成模型可能包含不同的潜在变量。在什么条件下一个代理可以保证其潜在变量是另一个代理潜在变量的函数？

在这种翻译下，标题为：

自然潜在条件下的翻译保证条件及其实用性 

---
# ARDO: A Weak Formulation Deep Neural Network Method for Elliptic and Parabolic PDEs Based on Random Differences of Test Functions 

**Title (ZH)**: ARDO：基于随机测试函数差值的弱形式深神经网络方法用于椭圆和抛物型偏微分方程 

**Authors**: Wei Cai, Andrew Qing He  

**Link**: [PDF](https://arxiv.org/pdf/2509.03757)  

**Abstract**: We propose ARDO method for solving PDEs and PDE-related problems with deep learning techniques. This method uses a weak adversarial formulation but transfers the random difference operator onto the test function. The main advantage of this framework is that it is fully derivative-free with respect to the solution neural network. This framework is particularly suitable for Fokker-Planck type second-order elliptic and parabolic PDEs. 

**Abstract (ZH)**: 我们提出了一种ARDO方法，结合深度学习技术求解偏微分方程及其相关问题。该方法采用弱对抗形式，但将随机差分算子转移至测试函数。该框架的主要优势是对解神经网络完全无导数要求。该框架特别适用于Fokker-Planck类型二阶椭圆和抛物线偏微分方程。 

---
# STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification 

**Title (ZH)**: STA-Net：一种解耦形状和纹理注意力网络的轻量级植物疾病分类方法 

**Authors**: Zongsen Qiu  

**Link**: [PDF](https://arxiv.org/pdf/2509.03754)  

**Abstract**: Responding to rising global food security needs, precision agriculture and deep learning-based plant disease diagnosis have become crucial. Yet, deploying high-precision models on edge devices is challenging. Most lightweight networks use attention mechanisms designed for generic object recognition, which poorly capture subtle pathological features like irregular lesion shapes and complex textures. To overcome this, we propose a twofold solution: first, using a training-free neural architecture search method (DeepMAD) to create an efficient network backbone for edge devices; second, introducing the Shape-Texture Attention Module (STAM). STAM splits attention into two branches -- one using deformable convolutions (DCNv4) for shape awareness and the other using a Gabor filter bank for texture awareness. On the public CCMT plant disease dataset, our STA-Net model (with 401K parameters and 51.1M FLOPs) reached 89.00% accuracy and an F1 score of 88.96%. Ablation studies confirm STAM significantly improves performance over baseline and standard attention models. Integrating domain knowledge via decoupled attention thus presents a promising path for edge-deployed precision agriculture AI. The source code is available at this https URL. 

**Abstract (ZH)**: 应对全球不断增长的粮食安全需求，基于精准农业和深度学习的植物病害诊断变得至关重要。然而，将高精度模型部署在边缘设备上颇具挑战。大多数轻量级网络使用针对通用对象识别设计的注意力机制，这些机制对捕捉不规则病斑形状和复杂纹理等细微病理特征的效果不佳。为克服这一问题，我们提出了一种双管齐下的解决方案：首先，使用无训练的神经架构搜索方法（DeepMAD）为边缘设备构建高效的网络基础架构；其次，引入了Shape-Texture Attention Module（STAM）。STAM将注意力机制分为两个分支：一个使用可变形卷积（DCNv4）进行形状感知，另一个使用Gabor滤波器库进行纹理感知。在公开的CCMT植物病害数据集上，我们的STA-Net模型（包含40.1万参数和51.1百万 floating point operations per second (FLOPs)）达到了89.00%的准确率和88.96%的F1分数。消融研究表明，STAM显著提高了性能，超越了基线和标准注意力模型。通过解耦注意力机制集成领域知识，从而为边缘部署的精准农业AI开辟了一条有前景的道路。源代码可从此处访问。 

---
# Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces 

**Title (ZH)**: 稀疏自动编码神经算子：函数空间中的模型恢复 

**Authors**: Bahareh Tolooshams, Ailsa Shen, Anima Anandkumar  

**Link**: [PDF](https://arxiv.org/pdf/2509.03738)  

**Abstract**: We frame the problem of unifying representations in neural models as one of sparse model recovery and introduce a framework that extends sparse autoencoders (SAEs) to lifted spaces and infinite-dimensional function spaces, enabling mechanistic interpretability of large neural operators (NO). While the Platonic Representation Hypothesis suggests that neural networks converge to similar representations across architectures, the representational properties of neural operators remain underexplored despite their growing importance in scientific computing. We compare the inference and training dynamics of SAEs, lifted-SAE, and SAE neural operators. We highlight how lifting and operator modules introduce beneficial inductive biases, enabling faster recovery, improved recovery of smooth concepts, and robust inference across varying resolutions, a property unique to neural operators. 

**Abstract (ZH)**: 我们将神经模型中统一表示的问题框定为稀疏模型恢复问题，并提出了一种框架，该框架将稀疏自编码器（SAEs）扩展到提升空间和无穷维函数空间，从而使大型神经算子（NO）具备机械可解释性。尽管理想表示假设表明神经网络在不同架构中会收敛到相似的表示，但神经算子的表示性质尚未得到充分探索，尽管它们在科学计算中的重要性日益增长。我们比较了稀疏自编码器（SAEs）、提升-SAE和神经算子的推断和训练动力学。我们强调了提升和算子模块引入的有益归纳偏置，这些偏置使模型能够更快地恢复、更好地恢复平滑概念，并在不同分辨率下实现鲁棒推断，这是神经算子独有的特性。 

---
# Differentiable Entropy Regularization for Geometry and Neural Networks 

**Title (ZH)**: 可微分熵正则化：几何与神经网络 

**Authors**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma  

**Link**: [PDF](https://arxiv.org/pdf/2509.03733)  

**Abstract**: We introduce a differentiable estimator of range-partition entropy, a recent concept from computational geometry that enables algorithms to adapt to the "sortedness" of their input. While range-partition entropy provides strong guarantees in algorithm design, it has not yet been made accessible to deep learning. In this work, we (i) propose the first differentiable approximation of range-partition entropy, enabling its use as a trainable loss or regularizer; (ii) design EntropyNet, a neural module that restructures data into low-entropy forms to accelerate downstream instance-optimal algorithms; and (iii) extend this principle beyond geometry by applying entropy regularization directly to Transformer attention. Across tasks, we demonstrate that differentiable entropy improves efficiency without degrading correctness: in geometry, our method achieves up to $4.1\times$ runtime speedups with negligible error ($<0.2%$); in deep learning, it induces structured attention patterns that yield 6% higher accuracy at 80% sparsity compared to L1 baselines. Our theoretical analysis provides approximation bounds for the estimator, and extensive ablations validate design choices. These results suggest that entropy-bounded computation is not only theoretically elegant but also a practical mechanism for adaptive learning, efficiency, and structured representation. 

**Abstract (ZH)**: 一种可微分的范围分区熵估计器及其在深度学习中的应用 

---
# MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection 

**Title (ZH)**: MLSD: 一种新型的少量样本学习方法以增强跨目标和跨域立场检测 

**Authors**: Parush Gera, Tempestt Neal  

**Link**: [PDF](https://arxiv.org/pdf/2509.03725)  

**Abstract**: We present the novel approach for stance detection across domains and targets, Metric Learning-Based Few-Shot Learning for Cross-Target and Cross-Domain Stance Detection (MLSD). MLSD utilizes metric learning with triplet loss to capture semantic similarities and differences between stance targets, enhancing domain adaptation. By constructing a discriminative embedding space, MLSD allows a cross-target or cross-domain stance detection model to acquire useful examples from new target domains. We evaluate MLSD in multiple cross-target and cross-domain scenarios across two datasets, showing statistically significant improvement in stance detection performance across six widely used stance detection models. 

**Abstract (ZH)**: 基于度量学习的少样本学习在跨目标和跨域立场检测中的新方法：度量学习基于三元损失的少样本立场检测（MLSD） 

---
# From Federated Learning to $\mathbb{X}$-Learning: Breaking the Barriers of Decentrality Through Random Walks 

**Title (ZH)**: 从联邦学习到$\mathbb{X}$学习：通过随机游走打破中心化壁垒 

**Authors**: Allan Salihovic, Payam Abdisarabshali, Michael Langberg, Seyyedali Hosseinalipour  

**Link**: [PDF](https://arxiv.org/pdf/2509.03709)  

**Abstract**: We provide our perspective on $\mathbb{X}$-Learning ($\mathbb{X}$L), a novel distributed learning architecture that generalizes and extends the concept of decentralization. Our goal is to present a vision for $\mathbb{X}$L, introducing its unexplored design considerations and degrees of freedom. To this end, we shed light on the intuitive yet non-trivial connections between $\mathbb{X}$L, graph theory, and Markov chains. We also present a series of open research directions to stimulate further research. 

**Abstract (ZH)**: 我们提供了关于$\mathbb{X}$-Learning ($\mathbb{X}$L)的见解，$\mathbb{X}$L是一种新颖的分布式学习架构，扩展了去中心化概念。我们的目标是提出$\mathbb{X}$L的愿景，介绍其未探索的设计考量和自由度。为此，我们揭示了$\mathbb{X}$L、图论和马尔可夫链之间直观但非平凡的联系，并提出了一系列开放的研究方向以激发进一步的研究。 

---
# Insights from Gradient Dynamics: Gradient Autoscaled Normalization 

**Title (ZH)**: 从梯度动态中获得的见解：梯度自动缩放规范化 

**Authors**: Vincent-Daniel Yun  

**Link**: [PDF](https://arxiv.org/pdf/2509.03677)  

**Abstract**: Gradient dynamics play a central role in determining the stability and generalization of deep neural networks. In this work, we provide an empirical analysis of how variance and standard deviation of gradients evolve during training, showing consistent changes across layers and at the global scale in convolutional networks. Motivated by these observations, we propose a hyperparameter-free gradient normalization method that aligns gradient scaling with their natural evolution. This approach prevents unintended amplification, stabilizes optimization, and preserves convergence guarantees. Experiments on the challenging CIFAR-100 benchmark with ResNet-20, ResNet-56, and VGG-16-BN demonstrate that our method maintains or improves test accuracy even under strong generalization. Beyond practical performance, our study highlights the importance of directly tracking gradient dynamics, aiming to bridge the gap between theoretical expectations and empirical behaviors, and to provide insights for future optimization research. 

**Abstract (ZH)**: 梯度动态在决定深度神经网络的稳定性和泛化能力中发挥着核心作用。本文提供了梯度方差和标准差在训练过程中演变的实证分析，展示了卷积网络中各层及全局尺度上的一致变化。受这些观察的启发，我们提出了一种无超参数的梯度归一化方法，使梯度缩放与它们的自然演变保持一致。该方法防止了不必要的放大，稳定了优化过程，并保留了收敛保证。在具有挑战性的CIFAR-100基准测试中，使用ResNet-20、ResNet-56和VGG-16-BN进行的实验表明，我们的方法在强泛化条件下能够维持或提高测试精度。除了实际性能，本研究所强调直接跟踪梯度动态的重要性，旨在弥合理论期望与实验表现之间的差距，并为未来的优化研究提供见解。 

---
# CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records 

**Title (ZH)**: CEHR-GPT：一种适用于电子健康记录的可扩展多任务基础模型 

**Authors**: Chao Pang, Jiheum Park, Xinzhuo Jiang, Nishanth Parameshwar Pavinkurve, Krishna S. Kalluri, Shalmali Joshi, Noémie Elhadad, Karthik Natarajan  

**Link**: [PDF](https://arxiv.org/pdf/2509.03643)  

**Abstract**: Electronic Health Records (EHRs) provide a rich, longitudinal view of patient health and hold significant potential for advancing clinical decision support, risk prediction, and data-driven healthcare research. However, most artificial intelligence (AI) models for EHRs are designed for narrow, single-purpose tasks, limiting their generalizability and utility in real-world settings. Here, we present CEHR-GPT, a general-purpose foundation model for EHR data that unifies three essential capabilities - feature representation, zero-shot prediction, and synthetic data generation - within a single architecture. To support temporal reasoning over clinical sequences, \cehrgpt{} incorporates a novel time-token-based learning framework that explicitly encodes patients' dynamic timelines into the model structure. CEHR-GPT demonstrates strong performance across all three tasks and generalizes effectively to external datasets through vocabulary expansion and fine-tuning. Its versatility enables rapid model development, cohort discovery, and patient outcome forecasting without the need for task-specific retraining. 

**Abstract (ZH)**: 电子健康记录（EHRs）提供了患者健康状况的丰富 longitudinal 视角，并且在临床决策支持、风险预测和数据驱动的医疗健康研究方面具有重要的潜力。然而，大多数用于EHR的AI模型针对单一目的任务进行设计，限制了它们在实际应用场景中的通用性和实用性。在这里，我们介绍了CEHR-GPT，这是一种适用于EHR数据的通用基础模型，统一了特征表示、零样本预测和合成数据生成这三种核心能力。为了支持临床序列上的时间推理，CEHR-GPT采用了新颖的时间标记学习框架，明确地将患者动态时间线编码到模型结构中。CEHR-GPT在所有三个任务上表现出色，并通过词汇扩展和微调有效泛化到外部数据集。其灵活性使得能够无需特定任务重训即可快速开发模型、发现患者群体和预测患者结局。 

---
# E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition 

**Title (ZH)**: E-ARMOR: 多语言光学字符识别的边缘案例评估与审查 

**Authors**: Aryan Gupta, Anupam Purwar  

**Link**: [PDF](https://arxiv.org/pdf/2509.03615)  

**Abstract**: Optical Character Recognition (OCR) in multilingual, noisy, and diverse real-world images remains a significant challenge for optical character recognition systems. With the rise of Large Vision-Language Models (LVLMs), there is growing interest in their ability to generalize and reason beyond fixed OCR pipelines. In this work, we introduce Sprinklr-Edge-OCR, a novel OCR system built specifically optimized for edge deployment in resource-constrained environments. We present a large-scale comparative evaluation of five state-of-the-art LVLMs (InternVL, Qwen, GOT OCR, LLaMA, MiniCPM) and two traditional OCR systems (Sprinklr-Edge-OCR, SuryaOCR) on a proprietary, doubly hand annotated dataset of multilingual (54 languages) images. Our benchmark covers a broad range of metrics including accuracy, semantic consistency, language coverage, computational efficiency (latency, memory, GPU usage), and deployment cost. To better reflect real-world applicability, we also conducted edge case deployment analysis, evaluating model performance on CPU only environments. Among the results, Qwen achieved the highest precision (0.54), while Sprinklr-Edge-OCR delivered the best overall F1 score (0.46) and outperformed others in efficiency, processing images 35 faster (0.17 seconds per image on average) and at less than 0.01 of the cost (0.006 USD per 1,000 images) compared to LVLM. Our findings demonstrate that the most optimal OCR systems for edge deployment are the traditional ones even in the era of LLMs due to their low compute requirements, low latency, and very high affordability. 

**Abstract (ZH)**: 多语言、噪声和多样化的现实世界图像中的光学字符识别（OCR）仍是对光学字符识别系统的一大挑战。随着大型视觉-语言模型（LVLM）的兴起，人们越来越关注其在固定OCR管道之外的泛化和推理能力。本研究介绍了Sprinklr-Edge-OCR，一种专门为资源受限环境下的边缘部署优化的新型OCR系统。我们对五种先进的LVLM（InternVL、Qwen、GOT OCR、LLaMA、MiniCPM）和两种传统OCR系统（Sprinklr-Edge-OCR、SuryaOCR）进行了一项大规模的比较评估，使用的是一个包含54种语言的专有双标注图像数据集。我们的基准测试涵盖了准确性、语义一致性、语言覆盖率、计算效率（延迟、内存、GPU使用量）和部署成本等多项指标。为了更好地反映实际应用，我们还进行了边缘案例部署分析，评估模型在仅使用CPU环境下的性能。结果表明，Qwen在精确度方面最高（0.54），而Sprinklr-Edge-OCR取得了最佳的综合F1分数（0.46），在效率方面也优于其他系统，平均每处理一张图像仅需0.17秒，并且成本仅为LVLM的0.006美元/1000张图像的十分之一。我们的研究表明，在LLM时代，传统OCR系统仍然是边缘部署的最佳选择，这主要归因于其低计算需求、低延迟和极高的经济性。 

---
# The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric 

**Title (ZH)**: 显而易见的优化器：基于损失景观诱导度量的训练 

**Authors**: Thomas R. Harvey  

**Link**: [PDF](https://arxiv.org/pdf/2509.03594)  

**Abstract**: We present a class of novel optimisers for training neural networks that makes use of the Riemannian metric naturally induced when the loss landscape is embedded in higher-dimensional space. This is the same metric that underlies common visualisations of loss landscapes. By taking this geometric perspective literally and using the induced metric, we develop a new optimiser and compare it to existing methods, namely: SGD, Adam, AdamW, and Muon, across a range of tasks and architectures. Empirically, we conclude that this new class of optimisers is highly effective in low dimensional examples, and provides slight improvement over state-of-the-art methods for training neural networks. These new optimisers have theoretically desirable properties. In particular, the effective learning rate is automatically decreased in regions of high curvature acting as a smoothed out form of gradient clipping. Similarly, one variant of these optimisers can also be viewed as inducing an effective scheduled learning rate and decoupled weight decay is the natural choice from our geometric perspective. The basic method can be used to modify any existing preconditioning method. The new optimiser has a computational complexity comparable to that of Adam. 

**Abstract (ZH)**: 我们提出了一类新型神经网络训练优化器，利用损失景观嵌入高维空间时自然诱导的黎曼度量。通过将这种几何视角字面化并利用诱导度量，我们开发了一种新的优化器，并将其与现有的方法（即SGD、Adam、AdamW和Muon）在多种任务和架构上进行了比较。我们实验证明，这种新的优化器在低维度示例中效果显著，并且在训练神经网络方面比最先进的方法稍有改进。这些新的优化器具有理论上的 desirable 属性。特别是，在高曲率区域自适应降低有效的学习率，起到平滑梯度截断的作用。同时，这些优化器的一种变体还可以被视为诱导有效的学习率调度，并且在我们的几何视角下，解耦的权重衰减是自然的选择。基本方法可以用于修改任何现有的预处理方法。新优化器的计算复杂度与Adam相当。 

---
# A software security review on Uganda's Mobile Money Services: Dr. Jim Spire's tweets sentiment analysis 

**Title (ZH)**: 乌干达移动钱服务软件安全审查：吉姆·斯派尔博士推特情感分析 

**Authors**: Nsengiyumva Wilberforce  

**Link**: [PDF](https://arxiv.org/pdf/2509.03545)  

**Abstract**: The proliferation of mobile money in Uganda has been a cornerstone of financial inclusion, yet its security mechanisms remain a critical concern. This study investigates a significant public response to perceived security failures: the #StopAirtelThefty Twitter campaign of August 2025 Sparked by an incident publicized by Dr. Jim Spire Ssentongo where a phone thief accessed a victim's account, withdrew funds, and procured a loan, the campaign revealed deep seated public anxiety over the safety of mobile money. This research employs qualitative analysis to systematically examine the complaints raised during this campaign, extracting key themes related to security vulnerabilities and user dissatisfaction. By synthesizing these public sentiments, the paper provides crucial insights into the specific security gaps experienced by users and situates these findings within the larger framework of Uganda's mobile money regulatory and operational environment. The study concludes with implications for providers, policymakers, and the future of secure digital finance in Uganda. 

**Abstract (ZH)**: 乌干达移动货币的普及是金融包容性的基石，但其安全机制仍是关键问题。一项研究探讨了对 perceived 安全失败的显著公众反应：2025年8月的#StopAirtelThefty Twitter 活动。该活动起源于 Dr. Jim Spire Ssentongo 公布的一起事件，一名手机窃贼侵入受害者的账户，提取资金，并获取贷款，揭示了公众对移动货币安全的深深关切。本研究采用定性分析方法系统地审查了该活动期间提出的投诉，提取了与安全漏洞和用户不满相关的关键主题。通过综合这些公众情绪，论文提供了对用户实际体验的安全漏洞的重要洞见，并将其置于乌干达移动货币监管和运营环境的大背景下。研究最后提出了对提供者、决策者以及乌干达安全数字金融未来的含义。 

---
# BiND: A Neural Discriminator-Decoder for Accurate Bimanual Trajectory Prediction in Brain-Computer Interfaces 

**Title (ZH)**: BiND: 用于脑机接口的二元手轨迹预测神经鉴别-解码器 

**Authors**: Timothee Robert, MohammadAli Shaeri, Mahsa Shoaran  

**Link**: [PDF](https://arxiv.org/pdf/2509.03521)  

**Abstract**: Decoding bimanual hand movements from intracortical recordings remains a critical challenge for brain-computer interfaces (BCIs), due to overlapping neural representations and nonlinear interlimb interactions. We introduce BiND (Bimanual Neural Discriminator-Decoder), a two-stage model that first classifies motion type (unimanual left, unimanual right, or bimanual) and then uses specialized GRU-based decoders, augmented with a trial-relative time index, to predict continuous 2D hand velocities. We benchmark BiND against six state-of-the-art models (SVR, XGBoost, FNN, CNN, Transformer, GRU) on a publicly available 13-session intracortical dataset from a tetraplegic patient. BiND achieves a mean $R^2$ of 0.76 ($\pm$0.01) for unimanual and 0.69 ($\pm$0.03) for bimanual trajectory prediction, surpassing the next-best model (GRU) by 2% in both tasks. It also demonstrates greater robustness to session variability than all other benchmarked models, with accuracy improvements of up to 4% compared to GRU in cross-session analyses. This highlights the effectiveness of task-aware discrimination and temporal modeling in enhancing bimanual decoding. 

**Abstract (ZH)**: 从颅内记录解码双上肢手部运动仍然是脑机接口（BCIs）中的一个关键挑战，由于神经表示的重叠和非线性双侧交互。我们引入了BiND（双上肢神经鉴别解码器），这是一种两阶段模型，首先分类运动类型（单上肢左、单上肢右或双上肢），然后使用带有试验相对时间索引的专门GRU基解码器来预测连续的2D手速度。我们在一个公开的来自四肢瘫痪患者的13会话颅内数据集上将BiND与六种最先进的模型（SVR、XGBoost、FNN、CNN、Transformer、GRU）进行了基准测试。BiND在单上肢轨迹预测中的平均$R^2$值为0.76（$\pm$0.01），双上肢轨迹预测值为0.69（$\pm$0.03），两项任务上的表现均优于排名第二的模型（GRU），分别超出2%。此外，BiND在会话间分析中表现出对会话间变异的更强鲁棒性，在交叉会话分析中相对于GRU的准确率提升了最多4%。这突显了任务感知鉴别和时间建模在增强双上肢解码方面的有效性。 

---
