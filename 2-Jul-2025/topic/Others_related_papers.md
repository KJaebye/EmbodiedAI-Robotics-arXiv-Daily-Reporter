# RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles 

**Title (ZH)**: RaGNNarok：一种用于增强无人驾驶地面车辆雷达点云的轻量级图神经网络 

**Authors**: David Hunt, Shaocheng Luo, Spencer Hallyburton, Shafii Nillongo, Yi Li, Tingjun Chen, Miroslav Pajic  

**Link**: [PDF](https://arxiv.org/pdf/2507.00937)  

**Abstract**: Low-cost indoor mobile robots have gained popularity with the increasing adoption of automation in homes and commercial spaces. However, existing lidar and camera-based solutions have limitations such as poor performance in visually obscured environments, high computational overhead for data processing, and high costs for lidars. In contrast, mmWave radar sensors offer a cost-effective and lightweight alternative, providing accurate ranging regardless of visibility. However, existing radar-based localization suffers from sparse point cloud generation, noise, and false detections. Thus, in this work, we introduce RaGNNarok, a real-time, lightweight, and generalizable graph neural network (GNN)-based framework to enhance radar point clouds, even in complex and dynamic environments. With an inference time of just 7.3 ms on the low-cost Raspberry Pi 5, RaGNNarok runs efficiently even on such resource-constrained devices, requiring no additional computational resources. We evaluate its performance across key tasks, including localization, SLAM, and autonomous navigation, in three different environments. Our results demonstrate strong reliability and generalizability, making RaGNNarok a robust solution for low-cost indoor mobile robots. 

**Abstract (ZH)**: 低成本室内移动机器人随着家庭和商业空间中自动化程度的提高而流行。然而，现有的基于激光雷达和摄像头的解决方案在视觉遮挡环境中表现不佳，数据处理计算开销高，并且激光雷达成本高昂。相比之下，毫米波雷达传感器提供了一种成本效益高且体积轻的替代方案，能够在任何可见度条件下提供精确的距离测量。然而，现有的基于雷达的定位方法存在点云稀疏、噪声和误检等问题。因此，在这项工作中，我们引入了RaGNNarok，这是一种实时、轻量级且可泛化的基于图神经网络(GNN)的框架，用于增强雷达点云数据，即使在复杂和动态的环境中也是如此。在低成本的Raspberry Pi 5上，RaGNNarok的推理时间仅为7.3毫秒，即使在资源受限的设备上也能高效运行，无需额外的计算资源。我们在三个不同环境中评估了其在定位、SLAM和自主导航等关键任务上的性能。我们的结果表明，RaGNNarok具有很强的可靠性和泛化能力，是低成本室内移动机器人的稳健解决方案。 

---
# Time Invariant Sensor Tasking for Catalog Maintenance of LEO Space objects using Stochastic Geometry 

**Title (ZH)**: 使用随机几何的LEO太空碎片catalog维护时间不变传感器任务规划 

**Authors**: Partha Chowdhury, Harsha M, Chinni Prabhunath Georg, Arun Balaji Buduru, Sanat K Biswas  

**Link**: [PDF](https://arxiv.org/pdf/2507.00076)  

**Abstract**: Catalog maintenance of space objects by limited number of ground-based sensors presents a formidable challenging task to the space community. This article presents a methodology for time-invariant tracking and surveillance of space objects in low Earth orbit (LEO) by optimally directing ground sensors. Our methodology aims to maximize the expected number of space objects from a set of ground stations by utilizing concepts from stochastic geometry, particularly the Poisson point process. We have provided a systematic framework to understand visibility patterns and enhance the efficiency of tracking multiple objects simultaneously. Our approach contributes to more informed decision-making in space operations, ultimately supporting efforts to maintain safety and sustainability in LEO. 

**Abstract (ZH)**: 基于有限地面传感器的天基物体.catalog维护 presents a formidable challenging task to the space community. This article presents a methodology for time-invariant tracking and surveillance of space objects in low Earth orbit (LEO) by optimally directing ground sensors. 

---
# Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact 

**Title (ZH)**: 超越令牌思维：从脑启发智能到认知基础的人工通用智能及其社会影响 

**Authors**: Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, Philip Torr, Seyedali Mirjalili  

**Link**: [PDF](https://arxiv.org/pdf/2507.00951)  

**Abstract**: Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI. 

**Abstract (ZH)**: 机器能否在类似人类的领域真正地思考、推理和行动？这一持久的问题继续塑造着通用人工智能（AGI）的研究追求。尽管模型如GPT-4.5、DeepSeek、Claude 3.5 Sonnet、Phi-4和Grok 3展现了多模态流畅性和部分推理能力，这些系统仍然因其依赖于令牌级别预测和缺乏根基化的自主性而受到根本性限制。本文跨学科综合了AGI的发展，涵盖了人工智能、认知神经科学、心理学、生成模型和基于代理系统的观点。我们分析了一般智能的架构和认知基础，强调模块化推理、持久记忆和多代理协调的作用。特别地，我们强调了结合检索、计划和动态工具使用以促进更适应性行为的代理型RAG框架的兴起。我们讨论了一般化策略，包括信息压缩、测试时适应和无需训练的方法，作为通向灵活、领域无关智能的关键路径。视觉-语言模型（VLMs）不仅被重新审视为感知模块，还被视为不断发展中的体悟理解和协作任务完成的接口。我们还论及真正的智能不仅源于规模，还在于记忆和推理的整合：一种模块化、交互式和自我改进组件的协奏，其中压缩促进了适应性行为。借助神经符号系统、强化学习和认知支架的进展，我们探讨了近期架构如何开始弥合统计学习与目标导向认知之间的鸿沟。最后，我们指出了通向AGI过程中的关键科学、技术和伦理挑战。 

---
# A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis 

**Title (ZH)**: 一种应对非 IID 机器学习问题的稳健算法及其收敛性分析 

**Authors**: Qing Xu, Xiaohua Xuan  

**Link**: [PDF](https://arxiv.org/pdf/2507.00810)  

**Abstract**: In this paper, we propose an improved numerical algorithm for solving minimax problems based on nonsmooth optimization, quadratic programming and iterative process. We also provide a rigorous proof of convergence for our algorithm under some mild assumptions, such as gradient continuity and boundedness. Such an algorithm can be widely applied in various fields such as robust optimization, imbalanced learning, etc. 

**Abstract (ZH)**: 本文提出了一种基于非光滑优化、二次规划和迭代过程的求解最小最大问题的改进数值算法，并在一些温和假设下，如梯度连续性和有界性，提供了收敛性的严格证明。该算法可以在鲁棒优化、不平衡学习等领域广泛应用于各种场合。 

---
# Advancing Local Search in SMT-NRA with MCSAT Integration 

**Title (ZH)**: SMT-NRA中MCSAT集成的局部搜索优化 

**Authors**: Tianyi Ding, Haokun Li, Xinpeng Ni, Bican Xia, Tianqi Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2507.00557)  

**Abstract**: In this paper, we advance local search for Satisfiability Modulo the Theory of Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a two-dimensional cell-jump move, called \emph{$2d$-cell-jump}, generalizing the key operation, cell-jump, of the local search method for SMT-NRA. Then, we propose an extended local search framework, named \emph{$2d$-LS} (following the local search framework, LS, for SMT-NRA), integrating the model constructing satisfiability calculus (MCSAT) framework to improve search efficiency. To further improve the efficiency of MCSAT, we implement a recently proposed technique called \emph{sample-cell projection operator} for MCSAT, which is well suited for CDCL-style search in the real domain and helps guide the search away from conflicting states. Finally, we design a hybrid framework for SMT-NRA combining MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through information exchange. The experimental results demonstrate improvements in local search performance, highlighting the effectiveness of the proposed methods. 

**Abstract (ZH)**: 在本文中，我们推进了满足非线性实算术理论（SMT-NRA简称）的局部搜索方法。首先，我们引入了一种二维单元跳转移动，称为\emph{二维单元跳转}，并将其视为SMT-NRA局部搜索方法中关键操作单元跳转的操作扩展。然后，我们提出了一种扩展的局部搜索框架\emph{二维局部搜索}（2d-LS，跟随SMT-NRA的局部搜索框架LS），将其与模型构建 satisfiability 逻辑（MCSAT）框架相整合，以提高搜索效率。为了进一步提高MCSAT的效率，我们实现了最近提出的一种称为\emph{样本单元投影算子}的技术，该算子适用于实数域中的CDCL风格搜索，并有助于引导搜索远离冲突状态。最后，我们设计了一种结合MCSAT、2d-LS和OpenCAD的混合框架，通过信息交换提高搜索效率。实验结果表明了局部搜索性能的改进，突显了提出方法的有效性。 

---
# Learning for routing: A guided review of recent developments and future directions 

**Title (ZH)**: 学习用于路由：对近期发展及相关未来方向的引导性回顾 

**Authors**: Fangting Zhou, Attila Lischka, Balazs Kulcsar, Jiaming Wu, Morteza Haghir Chehreghani, Gilbert Laporte  

**Link**: [PDF](https://arxiv.org/pdf/2507.00218)  

**Abstract**: This paper reviews the current progress in applying machine learning (ML) tools to solve NP-hard combinatorial optimization problems, with a focus on routing problems such as the traveling salesman problem (TSP) and the vehicle routing problem (VRP). Due to the inherent complexity of these problems, exact algorithms often require excessive computational time to find optimal solutions, while heuristics can only provide approximate solutions without guaranteeing optimality. With the recent success of machine learning models, there is a growing trend in proposing and implementing diverse ML techniques to enhance the resolution of these challenging routing problems. We propose a taxonomy categorizing ML-based routing methods into construction-based and improvement-based approaches, highlighting their applicability to various problem characteristics. This review aims to integrate traditional OR methods with state-of-the-art ML techniques, providing a structured framework to guide future research and address emerging VRP variants. 

**Abstract (ZH)**: 本文回顾了将机器学习工具应用于解决NP难组合优化问题，特别是 traveling salesman problem (TSP) 和 vehicle routing problem (VRP) 的当前进展。由于这些问题固有的复杂性，精确算法通常需要大量计算时间来找到最优解，而启发式方法只能提供近似解而不能保证最优性。随着机器学习模型的成功，使用多样化的机器学习技术来提高解决这些具有挑战性的路径优化问题的能力的趋势日益增加。本文提出了一种分类法，将基于机器学习的路径优化方法分为构建方法和改进方法，强调了它们对各种问题特性的适用性。本文旨在将传统的运筹学方法与最先进的机器学习技术相结合，提供一个结构化的框架，以指导未来的研究并解决新兴的车辆路径问题变体。 

---
# Holistic Artificial Intelligence in Medicine; improved performance and explainability 

**Title (ZH)**: 全面人工智能在医学中的应用；改进的性能与解释性 

**Authors**: Periklis Petridis, Georgios Margaritis, Vasiliki Stoumpou, Dimitris Bertsimas  

**Link**: [PDF](https://arxiv.org/pdf/2507.00205)  

**Abstract**: With the increasing interest in deploying Artificial Intelligence in medicine, we previously introduced HAIM (Holistic AI in Medicine), a framework that fuses multimodal data to solve downstream clinical tasks. However, HAIM uses data in a task-agnostic manner and lacks explainability. To address these limitations, we introduce xHAIM (Explainable HAIM), a novel framework leveraging Generative AI to enhance both prediction and explainability through four structured steps: (1) automatically identifying task-relevant patient data across modalities, (2) generating comprehensive patient summaries, (3) using these summaries for improved predictive modeling, and (4) providing clinical explanations by linking predictions to patient-specific medical knowledge. Evaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9% to 90.3% across chest pathology and operative tasks. Importantly, xHAIM transforms AI from a black-box predictor into an explainable decision support system, enabling clinicians to interactively trace predictions back to relevant patient data, bridging AI advancements with clinical utility. 

**Abstract (ZH)**: explanations-driven AI in Medicine）：一种通过生成式AI增强预测和解释性的新型框架 

---
# BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis 

**Title (ZH)**: 黑盒到蓝图：利用强化学习和反事实分析提取可解释逻辑从 legacy 系统 

**Authors**: Vidhi Rathore  

**Link**: [PDF](https://arxiv.org/pdf/2507.00180)  

**Abstract**: Modernizing legacy software systems is a critical but challenging task, often hampered by a lack of documentation and understanding of the original system's intricate decision logic. Traditional approaches like behavioral cloning merely replicate input-output behavior without capturing the underlying intent. This paper proposes a novel pipeline to automatically extract interpretable decision logic from legacy systems treated as black boxes. The approach uses a Reinforcement Learning (RL) agent to explore the input space and identify critical decision boundaries by rewarding actions that cause meaningful changes in the system's output. These counterfactual state transitions, where the output changes, are collected and clustered using K-Means. Decision trees are then trained on these clusters to extract human-readable rules that approximate the system's decision logic near the identified boundaries. I demonstrated the pipeline's effectiveness on three dummy legacy systems with varying complexity, including threshold-based, combined-conditional, and non-linear range logic. Results show that the RL agent successfully focuses exploration on relevant boundary regions, and the extracted rules accurately reflect the core logic of the underlying dummy systems, providing a promising foundation for generating specifications and test cases during legacy migration. 

**Abstract (ZH)**: 现代重构遗留软件系统是一项关键但具有挑战性的任务，常常受到原始系统详细决策逻辑缺乏文档和理解的阻碍。传统方法如行为克隆仅复制输入-输出行为而未捕获其背后的意图。本文提出了一种新颖的工作流程，用于从被视为黑盒的遗留系统中自动提取可解释的决策逻辑。该方法使用强化学习（RL）代理探索输入空间，并通过奖励导致系统输出有意义变化的动作来识别关键决策边界。这些反事实的状态转移，即输出发生变化的情况，使用K-Means进行聚类。然后，基于这些簇训练决策树以提取近似系统决策逻辑的人类可读规则。研究结果表明，RL代理能够有效地将探索集中在相关边界区域，并提取出准确反映底层模拟系统核心逻辑的规则，为遗留系统迁移期间生成规范和测试案例提供了有前景的基础。 

---
# SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network 

**Title (ZH)**: SEZ-HARN: 自解释零样本人体活动识别网络 

**Authors**: Devin Y. De Silva, Sandareka Wickramanayake, Dulani Meedeniya, Sanka Rasnayaka  

**Link**: [PDF](https://arxiv.org/pdf/2507.00050)  

**Abstract**: Human Activity Recognition (HAR), which uses data from Inertial Measurement Unit (IMU) sensors, has many practical applications in healthcare and assisted living environments. However, its use in real-world scenarios has been limited by the lack of comprehensive IMU-based HAR datasets that cover a wide range of activities and the lack of transparency in existing HAR models. Zero-shot HAR (ZS-HAR) overcomes the data limitations, but current models struggle to explain their decisions, making them less transparent. This paper introduces a novel IMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity Recognition Network (SEZ-HARN). It can recognize activities not encountered during training and provide skeleton videos to explain its decision-making process. We evaluate the effectiveness of the proposed SEZ-HARN on four benchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its performance against three state-of-the-art black-box ZS-HAR models. The experiment results demonstrate that SEZ-HARN produces realistic and understandable explanations while achieving competitive Zero-shot recognition accuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\% of the best-performing black-box model on PAMAP2 while maintaining comparable performance on the other three datasets. 

**Abstract (ZH)**: 基于惯性测量单元的零样本自解释人类活动识别网络（SEZ-HARN） 

---
# A collaborative digital twin built on FAIR data and compute infrastructure 

**Title (ZH)**: 基于FAIR数据与计算基础设施的协作数字孪生 

**Authors**: Thomas M. Deucher, Juan C. Verduzco, Michael Titus, Alejandro Strachan  

**Link**: [PDF](https://arxiv.org/pdf/2507.00048)  

**Abstract**: The integration of machine learning with automated experimentation in self-driving laboratories (SDL) offers a powerful approach to accelerate discovery and optimization tasks in science and engineering applications. When supported by findable, accessible, interoperable, and reusable (FAIR) data infrastructure, SDLs with overlapping interests can collaborate more effectively. This work presents a distributed SDL implementation built on nanoHUB services for online simulation and FAIR data management. In this framework, geographically dispersed collaborators conducting independent optimization tasks contribute raw experimental data to a shared central database. These researchers can then benefit from analysis tools and machine learning models that automatically update as additional data become available. New data points are submitted through a simple web interface and automatically processed using a nanoHUB Sim2L, which extracts derived quantities and indexes all inputs and outputs in a FAIR data repository called ResultsDB. A separate nanoHUB workflow enables sequential optimization using active learning, where researchers define the optimization objective, and machine learning models are trained on-the-fly with all existing data, guiding the selection of future experiments. Inspired by the concept of ``frugal twin", the optimization task seeks to find the optimal recipe to combine food dyes to achieve the desired target color. With easily accessible and inexpensive materials, researchers and students can set up their own experiments, share data with collaborators, and explore the combination of FAIR data, predictive ML models, and sequential optimization. The tools introduced are generally applicable and can easily be extended to other optimization problems. 

**Abstract (ZH)**: 机器学习与自动化实验在自主驾驶实验室（SDL）中的集成提供了加速科学研究和工程应用中发现和优化任务的强大方法。当由可获取、可访问、可互操作和可重用（FAIR）数据基础设施支持时，具有相交兴趣的SDL可以更有效地协作。本工作介绍了基于nanoHUB服务的分布式SDL实现，用于在线仿真和FAIR数据管理。在此框架中，地理上分散的独立执行优化任务的合作者将原始实验数据贡献到共享的中央数据库中。研究人员可以利用自动更新的分析工具和机器学习模型进行数据挖掘。新的数据点通过简单的网页界面提报，并自动处理，使用nanoHUB Sim2L从这些数据中提取衍生量，并在FAIR数据存储库ResultsDB中索引所有输入和输出。另一个独立的nanoHUB工作流实现了基于主动学习的序列优化，研究人员定义优化目标，机器学习模型在所有现有数据的基础上实时训练，指导未来实验的选择。受“节俭双胞胎”概念的启发，优化任务旨在找到将食品色素组合以达到目标颜色的最佳配方。借助易于访问且成本低廉的材料，研究人员和学生可以设置自己的实验，与其他合作者共享数据，并探索FAIR数据、预测性机器学习模型和序列优化的结合。介绍的工具具有通用性，易于扩展到其他优化问题。 

---
# Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes 

**Title (ZH)**: 基于遍历定理的神经网络训练过程描述：幽灵节点 

**Authors**: Eun-Ji Park, Sangwon Yun  

**Link**: [PDF](https://arxiv.org/pdf/2507.01003)  

**Abstract**: Recent studies have proposed interpreting the training process from an ergodic perspective. Building on this foundation we present a unified framework for understanding and accelerating the training of deep neural networks via stochastic gradient descent. By analyzing the geometric landscape of the objective function we introduce a practical diagnostic, the running estimate of the largest Lyapunov exponent, which provably distinguishes genuine convergence toward stable minimizers from mere statistical stabilization near saddle points. We then propose a ghost category extension for standard classifiers that adds auxiliary ghost output nodes so the model gains extra descent directions that open a lateral corridor around narrow loss barriers and enable the optimizer to bypass poor basins during the early training phase. We show that this extension strictly reduces approximation error and that after sufficient convergence the ghost dimensions collapse and the extended model's invariant law coincides with that of the original and there exists a path in the enlarged parameter space along which the total loss does not increase while the original loss decreases by an arbitrary margin. Taken together these results provide a principled architecture level intervention that accelerates early stage trainability while preserving asymptotic behavior. 

**Abstract (ZH)**: 近期研究表明，可以从遍历性的角度来解释训练过程。在此基础上，我们提出了一种统一框架，用于通过随机梯度下降理解并加速深度神经网络的训练。通过对目标函数几何景观的分析，我们引入了一个实用的诊断工具——运行中的最大李雅普unov指数的估计值，可以证明这一工具能区分向稳定极小值的真正收敛与在鞍点附近仅统计上的稳定。然后，我们提出了一种标准分类器的ghost类别扩展，通过增加辅助ghost输出节点，为模型提供额外的下降方向，从而在早期训练阶段绕过狭窄的损失障碍，使优化器能够避开差的局部极小值。我们证明这种扩展严格地降低了近似误差，并且在充分收敛后，ghost维度会消失，扩展后的模型的不变定律与原始模型相同，且存在一条在扩大后的参数空间中的路径，使得总损失不增加而原始损失减少任意幅度。这些结果共同提供了一个在保持渐近行为的同时加速早期训练阶段规范性的架构级干预措施。 

---
# SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks 

**Title (ZH)**: SciArena: 一个面向科研文献任务的基础模型开放评估平台 

**Authors**: Yilun Zhao, Kaiyan Zhang, Tiansheng Hu, Sihong Wu, Ronan Le Bras, Taira Anderson, Jonathan Bragg, Joseph Chee Chang, Jesse Dodge, Matt Latzke, Yixin Liu, Charles McGrady, Xiangru Tang, Zihang Wang, Chen Zhao, Hannaneh Hajishirzi, Doug Downey, Arman Cohan  

**Link**: [PDF](https://arxiv.org/pdf/2507.01001)  

**Abstract**: We present SciArena, an open and collaborative platform for evaluating foundation models on scientific literature tasks. Unlike traditional benchmarks for scientific literature understanding and synthesis, SciArena engages the research community directly, following the Chatbot Arena evaluation approach of community voting on model comparisons. By leveraging collective intelligence, SciArena offers a community-driven evaluation of model performance on open-ended scientific tasks that demand literature-grounded, long-form responses. The platform currently supports 23 open-source and proprietary foundation models and has collected over 13,000 votes from trusted researchers across diverse scientific domains. We analyze the data collected so far and confirm that the submitted questions are diverse, aligned with real-world literature needs, and that participating researchers demonstrate strong self-consistency and inter-annotator agreement in their evaluations. We discuss the results and insights based on the model ranking leaderboard. To further promote research in building model-based automated evaluation systems for literature tasks, we release SciArena-Eval, a meta-evaluation benchmark based on our collected preference data. The benchmark measures the accuracy of models in judging answer quality by comparing their pairwise assessments with human votes. Our experiments highlight the benchmark's challenges and emphasize the need for more reliable automated evaluation methods. 

**Abstract (ZH)**: SciArena：一个开放协同的平台，用于评估基础模型在科学文献任务中的性能 

---
# MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement 

**Title (ZH)**: MambAttention：带有多头注意力机制的Mamba在单声道语音增强中的通用应用 

**Authors**: Nikolai Lund Kühne, Jesper Jensen, Jan Østergaard, Zheng-Hua Tan  

**Link**: [PDF](https://arxiv.org/pdf/2507.00966)  

**Abstract**: With the advent of new sequence models like Mamba and xLSTM, several studies have shown that these models match or outperform state-of-the-art models in single-channel speech enhancement, automatic speech recognition, and self-supervised audio representation learning. However, prior research has demonstrated that sequence models like LSTM and Mamba tend to overfit to the training set. To address this issue, previous works have shown that adding self-attention to LSTMs substantially improves generalization performance for single-channel speech enhancement. Nevertheless, neither the concept of hybrid Mamba and time-frequency attention models nor their generalization performance have been explored for speech enhancement. In this paper, we propose a novel hybrid architecture, MambAttention, which combines Mamba and shared time- and frequency-multi-head attention modules for generalizable single-channel speech enhancement. To train our model, we introduce VoiceBank+Demand Extended (VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging noise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our proposed MambAttention model significantly outperforms existing state-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar complexity across all reported metrics on two out-of-domain datasets: DNS 2020 and EARS-WHAM_v2, while matching their performance on the in-domain dataset VB-DemandEx. Ablation studies highlight the role of weight sharing between the time- and frequency-multi-head attention modules for generalization performance. Finally, we explore integrating the shared time- and frequency-multi-head attention modules with LSTM and xLSTM, which yields a notable performance improvement on the out-of-domain datasets. However, our MambAttention model remains superior on both out-of-domain datasets across all reported evaluation metrics. 

**Abstract (ZH)**: 基于Mamba和时频注意力机制的新型可泛化单通道语音增强模型 

---
# WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks 

**Title (ZH)**: WebArXiv: 评估多模态代理在时间不变的arXiv任务上的性能 

**Authors**: Zihao Sun, Meng Fang, Ling Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.00938)  

**Abstract**: Recent progress in large language models (LLMs) has enabled the development of autonomous web agents capable of navigating and interacting with real websites. However, evaluating such agents remains challenging due to the instability and inconsistency of existing benchmarks, which often rely on dynamic content or oversimplified simulations. In this work, we introduce WebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks grounded in the arXiv platform. WebArXiv ensures reproducible and reliable evaluation by anchoring tasks in fixed web snapshots with deterministic ground truths and standardized action trajectories. Through behavioral analysis, we identify a common failure mode, Rigid History Reflection, where agents over-rely on fixed interaction histories. To address this, we propose a lightweight dynamic reflection mechanism that allows agents to selectively retrieve relevant past steps during decision-making. We evaluate ten state-of-the-art web agents on WebArXiv. Results demonstrate clear performance differences across agents and validate the effectiveness of our proposed reflection strategy. 

**Abstract (ZH)**: Recent进展在大型语言模型（LLMs）使得自主网页代理能够导航和与真实网站交互。然而，由于现有基准的不稳定性和不一致性，这些代理的评估仍然具有挑战性，这些基准往往依赖于动态内容或过于简化的模拟。在这项工作中，我们引入了WebArXiv，这是一个基于arXiv平台的静态和时间不变基准，包含275个网页任务。WebArXiv通过将任务锚定在固定网页快照上并具有确定的ground truths和标准化的动作轨迹，确保了可重复和可靠的评估。通过行为分析，我们发现一种常见的失败模式，即刚性历史反射，其中代理过度依赖固定的交互历史。为了解决这一问题，我们提出了一种轻量级的动态反射机制，允许代理在决策时选择性地检索相关的历史步骤。我们在WebArXiv上评估了十种最先进的网页代理。结果表明，代理之间的性能存在明显差异，并验证了我们提出的反射策略的有效性。 

---
# Turning AI Data Centers into Grid-Interactive Assets: Results from a Field Demonstration in Phoenix, Arizona 

**Title (ZH)**: 将AI数据中心转变为电网互动资产：亚利桑那州凤凰城实地示范结果 

**Authors**: Philip Colangelo, Ayse K. Coskun, Jack Megrue, Ciaran Roberts, Shayan Sengupta, Varun Sivaram, Ethan Tiao, Aroon Vijaykar, Chris Williams, Daniel C. Wilson, Zack MacFarland, Daniel Dreiling, Nathan Morey, Anuja Ratnayake, Baskar Vairamohan  

**Link**: [PDF](https://arxiv.org/pdf/2507.00909)  

**Abstract**: Artificial intelligence (AI) is fueling exponential electricity demand growth, threatening grid reliability, raising prices for communities paying for new energy infrastructure, and stunting AI innovation as data centers wait for interconnection to constrained grids. This paper presents the first field demonstration, in collaboration with major corporate partners, of a software-only approach--Emerald Conductor--that transforms AI data centers into flexible grid resources that can efficiently and immediately harness existing power systems without massive infrastructure buildout. Conducted at a 256-GPU cluster running representative AI workloads within a commercial, hyperscale cloud data center in Phoenix, Arizona, the trial achieved a 25% reduction in cluster power usage for three hours during peak grid events while maintaining AI quality of service (QoS) guarantees. By orchestrating AI workloads based on real-time grid signals without hardware modifications or energy storage, this platform reimagines data centers as grid-interactive assets that enhance grid reliability, advance affordability, and accelerate AI's development. 

**Abstract (ZH)**: 人工智能（AI）正推动电力需求以指数级速度增长，威胁电网可靠性，提高社区为新能源基础设施支付的价格，并限制数据中心因受限电网而推迟的AI创新。本文介绍了与主要企业合作伙伴合作进行的首个现场演示——Emerald Conductor软件解决方案，该解决方案将AI数据中心转变为灵活的电网资源，无需大规模基础设施建设即可高效且立即利用现有电力系统。在亚利桑那州菲尼克斯市一家商用大型云数据中心256 GPU集群上运行代表性AI工作负载时，试验期间在电网高峰事件中实现了集群电力使用量减少25%，同时保持AI服务质量（QoS）保证。通过基于实时电网信号调度AI工作负载，而不进行硬件修改或能量存储，该平台重新定义了数据中心作为能够增强电网可靠性、提高 affordability 并加速AI发展的电网互动资产。 

---
# The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses 

**Title (ZH)**: 传感器信任零时代：我们为何不能再信任自己的感官 

**Authors**: Fabio Correa Xavier  

**Link**: [PDF](https://arxiv.org/pdf/2507.00907)  

**Abstract**: In a world where deepfakes and cloned voices are emerging as sophisticated attack vectors, organizations require a new security mindset: Sensorial Zero Trust [9]. This article presents a scientific analysis of the need to systematically doubt information perceived through the senses, establishing rigorous verification protocols to mitigate the risks of fraud based on generative artificial intelligence. Key concepts, such as Out-of-Band verification, Vision-Language Models (VLMs) as forensic collaborators, cryptographic provenance, and human training, are integrated into a framework that extends Zero Trust principles to human sensory information. The approach is grounded in empirical findings and academic research, emphasizing that in an era of AI-generated realities, even our eyes and ears can no longer be implicitly trusted without verification. Leaders are called to foster a culture of methodological skepticism to protect organizational integrity in this new threat landscape. 

**Abstract (ZH)**: 在深伪和克隆语音等高级攻击手段涌现的世界中，组织需要培养一种新的安全思维：感性零信任 [9]。本文对系统性怀疑感官获取的信息的必要性进行了科学分析，并建立了严格的验证程序，以减轻基于生成式人工智能的欺诈风险。该框架整合了外链验证、视觉语言模型（VLMs）作为法医合作者、加密溯源和人类培训等关键概念，将零信任原则扩展到人类感官信息。该方法基于实证发现和学术研究，强调在人工智能生成的现实时代，我们的视觉和听觉也不能再未经验证的情况下被隐含信任。领导者被呼吁培养一种方法论上的怀疑文化，以保护组织在这一新的威胁环境中免受侵害。 

---
# Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks 

**Title (ZH)**: 服务化的星座：直接卫星到设备网络中定制化的连接管理 

**Authors**: Feng Wang, Shengyu Zhang, Een-Kee Hong, Tony Q.S. Quek  

**Link**: [PDF](https://arxiv.org/pdf/2507.00902)  

**Abstract**: Direct-satellite-to-device (DS2D) communication is emerging as a promising solution for global mobile service extension, leveraging the deployment of satellite constellations. However, the challenge of managing DS2D connectivity for multi-constellations becomes outstanding, including high interference and frequent handovers caused by multi-coverage overlap and rapid satellite movement. Moreover, existing approaches primarily operate within single-constellation shell, which inherently limits the ability to exploit the vast potential of multi-constellation connectivity provision, resulting in suboptimal DS2D service performances. To address these challenges, this article proposes a Constellation as a Service (CaaS) framework, which treats the entire multi-constellation infrastructure as a shared resource pool and dynamically forms optimal sub-constellations (SCs) for each DS2D service region. The formation of each SC integrates satellites from various orbits to provide tailored connectivity based on user demands, guided by two innovative strategies: predictive satellite beamforming using generative artificial intelligence (GenAI) and pre-configured handover path for efficient satellite access and mobility management. Simulation results demonstrate that CaaS significantly improves satellite service rates while reducing handover overhead, making it an efficient and continuable solution for managing DS2D connectivity in multi-constellation environments. 

**Abstract (ZH)**: 多星系直接卫星到设备通信的服务即星（CaaS）框架 

---
# NN-Former: Rethinking Graph Structure in Neural Architecture Representation 

**Title (ZH)**: NN-Former: 重新思考神经架构表示中的图形结构 

**Authors**: Ruihan Xu, Haokui Zhang, Yaowei Wang, Wei Zeng, Shiliang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00880)  

**Abstract**: The growing use of deep learning necessitates efficient network design and deployment, making neural predictors vital for estimating attributes such as accuracy and latency. Recently, Graph Neural Networks (GNNs) and transformers have shown promising performance in representing neural architectures. However, each of both methods has its disadvantages. GNNs lack the capabilities to represent complicated features, while transformers face poor generalization when the depth of architecture grows. To mitigate the above issues, we rethink neural architecture topology and show that sibling nodes are pivotal while overlooked in previous research. We thus propose a novel predictor leveraging the strengths of GNNs and transformers to learn the enhanced topology. We introduce a novel token mixer that considers siblings, and a new channel mixer named bidirectional graph isomorphism feed-forward network. Our approach consistently achieves promising performance in both accuracy and latency prediction, providing valuable insights for learning Directed Acyclic Graph (DAG) topology. The code is available at this https URL. 

**Abstract (ZH)**: 深度学习的广泛应用 necessitates 有效的网络设计与部署，使得神经预测器在估计准确性和延迟等属性方面变得至关重要。近年来，图神经网络（GNNs）和变压器在表示神经架构方面展现了令人 hopeful 的性能。然而，这两种方法各有利弊。GNNs 在表示复杂特征方面能力不足，而变压器在架构深度增加时泛化性能较差。为解决上述问题，我们重新思考神经架构拓扑，并指出兄弟节点在之前的研究中被忽视但却是关键的。我们因此提出一种新的预测器，充分利用GNNs 和变压器的优点来学习改进的拓扑结构。我们引入了一种考虑兄弟节点的新型 token 混合器，并提出了一种新的通道混合器，称为双向图同构前馈网络。我们的方法在准确性和延迟预测方面始终表现出令人 hopeful 的性能，为学习有向无环图（DAG）拓扑提供了有价值的见解。代码可在以下链接获取：this https URL。 

---
# Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection 

**Title (ZH)**: 基于自动解剖学的后处理方法减少假阳性并提高颅内动脉瘤检测的可解释性 

**Authors**: Jisoo Kim, Chu-Hsuan Lin, Alberto Ceballos-Arroyo, Ping Liu, Huaizu Jiang, Shrikanth Yadav, Qi Wan, Lei Qin, Geoffrey S Young  

**Link**: [PDF](https://arxiv.org/pdf/2507.00832)  

**Abstract**: Introduction: Deep learning (DL) models can help detect intracranial aneurysms on CTA, but high false positive (FP) rates remain a barrier to clinical translation, despite improvement in model architectures and strategies like detection threshold tuning. We employed an automated, anatomy-based, heuristic-learning hybrid artery-vein segmentation post-processing method to further reduce FPs. Methods: Two DL models, CPM-Net and a deformable 3D convolutional neural network-transformer hybrid (3D-CNN-TR), were trained with 1,186 open-source CTAs (1,373 annotated aneurysms), and evaluated with 143 held-out private CTAs (218 annotated aneurysms). Brain, artery, vein, and cavernous venous sinus (CVS) segmentation masks were applied to remove possible FPs in the DL outputs that overlapped with: (1) brain mask; (2) vein mask; (3) vein more than artery masks; (4) brain plus vein mask; (5) brain plus vein more than artery masks. Results: CPM-Net yielded 139 true-positives (TP); 79 false-negative (FN); 126 FP. 3D-CNN-TR yielded 179 TP; 39 FN; 182 FP. FPs were commonly extracranial (CPM-Net 27.3%; 3D-CNN-TR 42.3%), venous (CPM-Net 56.3%; 3D-CNN-TR 29.1%), arterial (CPM-Net 11.9%; 3D-CNN-TR 53.3%), and non-vascular (CPM-Net 25.4%; 3D-CNN-TR 9.3%) structures. Method 5 performed best, reducing CPM-Net FP by 70.6% (89/126) and 3D-CNN-TR FP by 51.6% (94/182), without reducing TP, lowering the FP/case rate from 0.88 to 0.26 for CPM-NET, and from 1.27 to 0.62 for the 3D-CNN-TR. Conclusion: Anatomy-based, interpretable post-processing can improve DL-based aneurysm detection model performance. More broadly, automated, domain-informed, hybrid heuristic-learning processing holds promise for improving the performance and clinical acceptance of aneurysm detection models. 

**Abstract (ZH)**: 引言：深度学习（DL）模型可以辅助在CTA中检测颅内动脉瘤，尽管模型架构和策略（如检测阈值调整）的改进在降低假阳性率方面取得了一定进展，但高假阳性率仍然是临床应用的障碍。我们采用了一种基于解剖特征的自动启发式学习混合动脉-静脉分割后处理方法，进一步降低了假阳性率。

方法：使用1,186个开源CTA（1,373个标注的动脉瘤）训练了两个DL模型，CPM-Net和变形3D卷积神经网络-变压器混合体（3D-CNN-TR），并在143个预留的私有CTA（218个标注的动脉瘤）上进行了评估。应用脑、动脉、静脉和硬脑膜静脉窦分割掩膜来移除DL输出中与以下内容重叠的可能假阳性：（1）脑掩膜；（2）静脉掩膜；（3）静脉大于动脉掩膜；（4）脑加静脉掩膜；（5）脑加静脉大于动脉掩膜。

结果：CPM-Net产生了139个真阳性（TP）；79个假阴性（FN）；126个假阳性（FP）。3D-CNN-TR产生了179个TP；39个FN；182个FP。假阳性主要为颅外结构（CPM-Net 27.3%；3D-CNN-TR 42.3%）、静脉结构（CPM-Net 56.3%；3D-CNN-TR 29.1%）、动脉结构（CPM-Net 11.9%；3D-CNN-TR 53.3%）和非血管结构（CPM-Net 25.4%；3D-CNN-TR 9.3%）。方法5效果最佳，减少了CPM-Net 70.6%（89/126）和3D-CNN-TR 51.6%（94/182）的假阳性，而不减少真阳性，将CPM-NET的假阳性/例率从0.88降低到0.26，3D-CNN-TR的假阳性/例率从1.27降低到0.62。

结论：基于解剖特征的可解释后处理可以提高基于DL的动脉瘤检测模型的性能。更广泛地说，自动化、领域驱动的混合启发式学习处理有潜力提高动脉瘤检测模型的性能和临床接受度。 

---
# Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability 

**Title (ZH)**: AI回声：探究AI Assistants对软件可维护性的影响 

**Authors**: Markus Borg, Dave Hewett, Nadim Hagatulah, Noric Couderc, Emma Söderberg, Donald Graham, Uttam Kini, Dave Farley  

**Link**: [PDF](https://arxiv.org/pdf/2507.00788)  

**Abstract**: [Context] AI assistants, like GitHub Copilot and Cursor, are transforming software engineering. While several studies highlight productivity improvements, their impact on maintainability requires further investigation. [Objective] This study investigates whether co-development with AI assistants affects software maintainability, specifically how easily other developers can evolve the resulting source code. [Method] We conducted a two-phase controlled experiment involving 151 participants, 95% of whom were professional developers. In Phase 1, participants added a new feature to a Java web application, with or without AI assistance. In Phase 2, a randomized controlled trial, new participants evolved these solutions without AI assistance. [Results] AI-assisted development in Phase 1 led to a modest speedup in subsequent evolution and slightly higher average CodeHealth. Although neither difference was significant overall, the increase in CodeHealth was statistically significant when habitual AI users completed Phase 1. For Phase 1, we also observed a significant effect that corroborates previous productivity findings: using an AI assistant yielded a 30.7% median decrease in task completion time. Moreover, for habitual AI users, the mean speedup was 55.9%. [Conclusions] Our study adds to the growing evidence that AI assistants can effectively accelerate development. Moreover, we did not observe warning signs of degraded code-level maintainability. We recommend that future research focus on risks such as code bloat from excessive code generation and the build-up of cognitive debt as developers invest less mental effort during implementation. 

**Abstract (ZH)**: AI辅助开发对软件维护性的影响研究：专业开发者参与的两阶段受控实验 

---
# LearnAFE: Circuit-Algorithm Co-design Framework for Learnable Audio Analog Front-End 

**Title (ZH)**: LearnAFE：可学习音频模拟前端的电路-算法联合设计框架 

**Authors**: Jinhai Hu, Zhongyi Zhang, Cong Sheng Leow, Wang Ling Goh, Yuan Gao  

**Link**: [PDF](https://arxiv.org/pdf/2507.00755)  

**Abstract**: This paper presents a circuit-algorithm co-design framework for learnable analog front-end (AFE) in audio signal classification. Designing AFE and backend classifiers separately is a common practice but non-ideal, as shown in this paper. Instead, this paper proposes a joint optimization of the backend classifier with the AFE's transfer function to achieve system-level optimum. More specifically, the transfer function parameters of an analog bandpass filter (BPF) bank are tuned in a signal-to-noise ratio (SNR)-aware training loop for the classifier. Using a co-design loss function LBPF, this work shows superior optimization of both the filter bank and the classifier. Implemented in open-source SKY130 130nm CMOS process, the optimized design achieved 90.5%-94.2% accuracy for 10-keyword classification task across a wide range of input signal SNR from 5 dB to 20 dB, with only 22k classifier parameters. Compared to conventional approach, the proposed audio AFE achieves 8.7% and 12.9% reduction in power and capacitor area respectively. 

**Abstract (ZH)**: 这种论文提出了一种适用于音频信号分类的可学习模拟前端（AFE）电路-算法协同设计框架。 

---
# TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving 

**Title (ZH)**: TopoStreamer: 自主驾驶中基于时间的车道段拓扑推理 

**Authors**: Yiming Yang, Yueru Luo, Bingkun He, Hongbin Lin, Suzhong Fu, Chao Yan, Kun Tang, Xinrui Yan, Chao Zheng, Shuguang Cui, Zhen Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.00709)  

**Abstract**: Lane segment topology reasoning constructs a comprehensive road network by capturing the topological relationships between lane segments and their semantic types. This enables end-to-end autonomous driving systems to perform road-dependent maneuvers such as turning and lane changing. However, the limitations in consistent positional embedding and temporal multiple attribute learning in existing methods hinder accurate roadnet reconstruction. To address these issues, we propose TopoStreamer, an end-to-end temporal perception model for lane segment topology reasoning. Specifically, TopoStreamer introduces three key improvements: streaming attribute constraints, dynamic lane boundary positional encoding, and lane segment denoising. The streaming attribute constraints enforce temporal consistency in both centerline and boundary coordinates, along with their classifications. Meanwhile, dynamic lane boundary positional encoding enhances the learning of up-to-date positional information within queries, while lane segment denoising helps capture diverse lane segment patterns, ultimately improving model performance. Additionally, we assess the accuracy of existing models using a lane boundary classification metric, which serves as a crucial measure for lane-changing scenarios in autonomous driving. On the OpenLane-V2 dataset, TopoStreamer demonstrates significant improvements over state-of-the-art methods, achieving substantial performance gains of +3.4% mAP in lane segment perception and +2.1% OLS in centerline perception tasks. 

**Abstract (ZH)**: 车道段拓扑推理构建通过捕获车道段及其语义类型的拓扑关系来构成全面的道路网络，从而为端到端的自主驾驶系统执行道路依赖的操作，如转向和变道提供支持。然而，现有方法中一致的位置嵌入和时间多属性学习的局限性阻碍了准确的道路网重构。为解决这些问题，我们提出TopoStreamer，一种端到端的时间感知模型，用于车道段拓扑推理。具体而言，TopoStreamer引入了三个关键改进：流式属性约束、动态车道边界位置编码和车道段去噪。流式属性约束确保中心线和边界坐标及其分类在时间上的一致性。同时，动态车道边界位置编码增强了查询中最新的位置信息学习，而车道段去噪有助于捕捉多样化的车道段模式，最终提高模型性能。此外，我们使用车道边界分类指标评估现有模型的准确性，该指标是自主驾驶场景中变道情境的关键衡量指标。在OpenLane-V2数据集上，TopoStreamer在车道段感知任务中相较于现有最佳方法取得了显著改进，分别在车道段感知和中心线感知任务中实现了多达3.4%的mAP和2.1%的OLS的性能提升。 

---
# MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound 

**Title (ZH)**: MTCNet：四维超声二尖瓣分割的动力学与拓扑一致性引导学习 

**Authors**: Rusi Chen, Yuanting Yang, Jiezhi Yao, Hongning Song, Ji Zhang, Yongsong Zhou, Yuhao Huang, Ronghao Yang, Dan Jia, Yuhan Zhang, Xing Tao, Haoran Dou, Qing Zhou, Xin Yang, Dong Ni  

**Link**: [PDF](https://arxiv.org/pdf/2507.00660)  

**Abstract**: Mitral regurgitation is one of the most prevalent cardiac disorders. Four-dimensional (4D) ultrasound has emerged as the primary imaging modality for assessing dynamic valvular morphology. However, 4D mitral valve (MV) analysis remains challenging due to limited phase annotations, severe motion artifacts, and poor imaging quality. Yet, the absence of inter-phase dependency in existing methods hinders 4D MV analysis. To bridge this gap, we propose a Motion-Topology guided consistency network (MTCNet) for accurate 4D MV ultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only sparse end-diastolic and end-systolic annotations. First, we design a cross-phase motion-guided consistency learning strategy, utilizing a bi-directional attention memory bank to propagate spatio-temporal features. This enables MTCNet to achieve excellent performance both per- and inter-phase. Second, we devise a novel topology-guided correlation regularization that explores physical prior knowledge to maintain anatomically plausible. Therefore, MTCNet can effectively leverage structural correspondence between labeled and unlabeled phases. Extensive evaluations on the first largest 4D MV dataset, with 1408 phases from 160 patients, show that MTCNet performs superior cross-phase consistency compared to other advanced methods (Dice: 87.30%, HD: 1.75mm). Both the code and the dataset are available at this https URL. 

**Abstract (ZH)**: 基于运动-拓扑引导一致性网络的半监督4D二尖瓣超声分割 

---
# Horus: A Protocol for Trustless Delegation Under Uncertainty 

**Title (ZH)**: Horus：一种基于不确定性条件下的无信任委派协议 

**Authors**: David Shi, Kevin Joo  

**Link**: [PDF](https://arxiv.org/pdf/2507.00631)  

**Abstract**: Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium. 

**Abstract (ZH)**: 正确性是那些暴露错误的成本低于提交错误的成本的系统中的一种 emergent 属性。在动态且低信任环境中，自主 AI 剂 Oswbot 借助子代理执行任务，但其正确性无法通过前期规范或集中监督来保证。我们提出一种协议，通过递归验证游戏中的抵押索赔来确保正确性。任务以意愿形式发布，求解者竞争以完成它们。选定的求解者在承担风险的情况下执行任务，由验证者事后检查其正确性。任何挑战者都可以通过抵押来质疑结果，从而启动验证过程。错误的代理将被处罚，正确方将得到奖励，且存在一个升级机制，对错误的验证者本身进行处罚。当求解者、挑战者和验证者之间的激励机制对齐时，错误条件使得正确性成为纳什均衡。 

---
# Physics-Informed Neural ODEs for Temporal Dynamics Modeling in Cardiac T1 Mapping 

**Title (ZH)**: 基于物理约束的神经ODEs在心脏T1成像时间动态建模中的应用 

**Authors**: Nuno Capitão, Yi Zhang, Yidong Zhao, Qian Tao  

**Link**: [PDF](https://arxiv.org/pdf/2507.00613)  

**Abstract**: Spin-lattice relaxation time ($T_1$) is an important biomarker in cardiac parametric mapping for characterizing myocardial tissue and diagnosing cardiomyopathies. Conventional Modified Look-Locker Inversion Recovery (MOLLI) acquires 11 breath-hold baseline images with interleaved rest periods to ensure mapping accuracy. However, prolonged scanning can be challenging for patients with poor breathholds, often leading to motion artifacts that degrade image quality. In addition, $T_1$ mapping requires voxel-wise nonlinear fitting to a signal recovery model involving an iterative estimation process. Recent studies have proposed deep-learning approaches for rapid $T_1$ mapping using shortened sequences to reduce acquisition time for patient comfort. Nevertheless, existing methods overlook important physics constraints, limiting interpretability and generalization. In this work, we present an accelerated, end-to-end $T_1$ mapping framework leveraging Physics-Informed Neural Ordinary Differential Equations (ODEs) to model temporal dynamics and address these challenges. Our method achieves high-accuracy $T_1$ estimation from a sparse subset of baseline images and ensures efficient null index estimation at test time. Specifically, we develop a continuous-time LSTM-ODE model to enable selective Look-Locker (LL) data acquisition with arbitrary time lags. Experimental results show superior performance in $T_1$ estimation for both native and post-contrast sequences and demonstrate the strong benefit of our physics-based formulation over direct data-driven $T_1$ priors. 

**Abstract (ZH)**: 基于物理约束的加速心脏T₁弛豫时间端到端映射框架 

---
# High-resolution spatial memory requires grid-cell-like neural codes 

**Title (ZH)**: 高分辨率空间记忆需要类似-grid细胞的神经编码 

**Authors**: Madison Cotteret, Christopher J. Kymn, Hugh Greatorex, Martin Ziegler, Elisabetta Chicca, Friedrich T. Sommer  

**Link**: [PDF](https://arxiv.org/pdf/2507.00598)  

**Abstract**: Continuous attractor networks (CANs) are widely used to model how the brain temporarily retains continuous behavioural variables via persistent recurrent activity, such as an animal's position in an environment. However, this memory mechanism is very sensitive to even small imperfections, such as noise or heterogeneity, which are both common in biological systems. Previous work has shown that discretising the continuum into a finite set of discrete attractor states provides robustness to these imperfections, but necessarily reduces the resolution of the represented variable, creating a dilemma between stability and resolution. We show that this stability-resolution dilemma is most severe for CANs using unimodal bump-like codes, as in traditional models. To overcome this, we investigate sparse binary distributed codes based on random feature embeddings, in which neurons have spatially-periodic receptive fields. We demonstrate theoretically and with simulations that such grid-cell-like codes enable CANs to achieve both high stability and high resolution simultaneously. The model extends to embedding arbitrary nonlinear manifolds into a CAN, such as spheres or tori, and generalises linear path integration to integration along freely-programmable on-manifold vector fields. Together, this work provides a theory of how the brain could robustly represent continuous variables with high resolution and perform flexible computations over task-relevant manifolds. 

**Abstract (ZH)**: 连续吸引子网络通过持续的反复活动暂存连续的行为变量（如动物在环境中的位置），但在生物系统中常见的噪声或异质性等因素会导致其敏感性下降。利用连续体离散化为有限的离散吸引子状态可以增强其对抗这些缺陷的稳健性，但会降低所表示变量的分辨率，造成稳定性和分辨率之间的权衡。我们证明，这一稳定性和分辨率之间的权衡在使用传统模型中的单模峰状编码的连续吸引子网络中尤为严重。为克服这一问题，我们研究了基于随机特征嵌入的稀疏二元分布式编码，其中神经元具有空间周期性的感受野。我们通过理论分析和仿真实验证明，这种类似网格细胞的编码可以使连续吸引子网络同时实现高稳定性和高分辨率。该模型可扩展到将任意非线性流形嵌入连续吸引子网络中，如将球面或环面等转化为流形上的向量场积分，并将线性路径积分扩展到在可自由编程的流形上向量场积分。这项工作为大脑如何以高分辨率稳健地表示连续变量并在任务相关流形上执行灵活计算提供了理论机制。 

---
# Quantum Circuit Structure Optimization for Quantum Reinforcement Learning 

**Title (ZH)**: 量子电路结构优化在量子强化学习中的应用 

**Authors**: Seok Bin Son, Joongheon Kim  

**Link**: [PDF](https://arxiv.org/pdf/2507.00589)  

**Abstract**: Reinforcement learning (RL) enables agents to learn optimal policies through environmental interaction. However, RL suffers from reduced learning efficiency due to the curse of dimensionality in high-dimensional spaces. Quantum reinforcement learning (QRL) addresses this issue by leveraging superposition and entanglement in quantum computing, allowing efficient handling of high-dimensional problems with fewer resources. QRL combines quantum neural networks (QNNs) with RL, where the parameterized quantum circuit (PQC) acts as the core computational module. The PQC performs linear and nonlinear transformations through gate operations, similar to hidden layers in classical neural networks. Previous QRL studies, however, have used fixed PQC structures based on empirical intuition without verifying their optimality. This paper proposes a QRL-NAS algorithm that integrates quantum neural architecture search (QNAS) to optimize PQC structures within QRL. Experiments demonstrate that QRL-NAS achieves higher rewards than QRL with fixed circuits, validating its effectiveness and practical utility. 

**Abstract (ZH)**: 量子强化学习（QRL）通过利用量子计算中的叠加和纠缠来解决维数灾难问题，从而提高学习效率。QRL结合了量子神经网络（QNN）与强化学习（RL），其中参数化量子电路（PQC）作为核心计算模块。QRL-NAS算法整合了量子神经架构搜索（QNAS），以优化QRL中的PQC结构。实验表明，QRL-NAS在固定电路的基础上能获得更高的奖励，验证了其有效性和实用性。 

---
# BadViM: Backdoor Attack against Vision Mamba 

**Title (ZH)**: BadViM: 针对Vision Mamba的后门攻击 

**Authors**: Yinghao Wu, Liyan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00577)  

**Abstract**: Vision State Space Models (SSMs), particularly architectures like Vision Mamba (ViM), have emerged as promising alternatives to Vision Transformers (ViTs). However, the security implications of this novel architecture, especially their vulnerability to backdoor attacks, remain critically underexplored. Backdoor attacks aim to embed hidden triggers into victim models, causing the model to misclassify inputs containing these triggers while maintaining normal behavior on clean inputs. This paper investigates the susceptibility of ViM to backdoor attacks by introducing BadViM, a novel backdoor attack framework specifically designed for Vision Mamba. The proposed BadViM leverages a Resonant Frequency Trigger (RFT) that exploits the frequency sensitivity patterns of the victim model to create stealthy, distributed triggers. To maximize attack efficacy, we propose a Hidden State Alignment loss that strategically manipulates the internal representations of model by aligning the hidden states of backdoor images with those of target classes. Extensive experimental results demonstrate that BadViM achieves superior attack success rates while maintaining clean data accuracy. Meanwhile, BadViM exhibits remarkable resilience against common defensive measures, including PatchDrop, PatchShuffle and JPEG compression, which typically neutralize normal backdoor attacks. 

**Abstract (ZH)**: Vision状态空间模型（SSMs），特别是如Vision Mamba（ViM）这样的架构，已经被证明是Vision Transformer（ViTs）的有前途的替代方案。然而，这种新型架构的安全性影响，尤其是其对后门攻击的易感性，仍然被严重忽视。后门攻击旨在将隐蔽触发器嵌入受害模型中，使得模型在包含这些触发器的输入上产生误分类，而在干净的输入上保持正常行为。本文通过引入专为Vision Mamba设计的新颖后门攻击框架BadViM，考察了ViM的后门攻击易感性。所提出的BadViM利用了受害模型的频率敏感模式，创建隐蔽且分散的触发器。为了最大化攻击效果，我们提出了一种隐藏状态对齐损失，通过将后门图像的隐藏状态与目标类别的隐藏状态对齐，战略性地操控模型的内部表示。大量实验结果表明，BadViM在保持数据完整性的同时，实现了更高的攻击成功率。同时，BadViM表现出针对常见的防御措施（包括PatchDrop、PatchShuffle和JPEG压缩）的显著抗性，这些措施通常能够消除正常的后门攻击。 

---
# Inverse Design in Nanophotonics via Representation Learning 

**Title (ZH)**: 纳光子学中的逆向设计通过表示学习 

**Authors**: Reza Marzban, Ali Adibi, Raphael Pestourie  

**Link**: [PDF](https://arxiv.org/pdf/2507.00546)  

**Abstract**: Inverse design in nanophotonics, the computational discovery of structures achieving targeted electromagnetic (EM) responses, has become a key tool for recent optical advances. Traditional intuition-driven or iterative optimization methods struggle with the inherently high-dimensional, non-convex design spaces and the substantial computational demands of EM simulations. Recently, machine learning (ML) has emerged to address these bottlenecks effectively. This review frames ML-enhanced inverse design methodologies through the lens of representation learning, classifying them into two categories: output-side and input-side approaches. Output-side methods use ML to learn a representation in the solution space to create a differentiable solver that accelerates optimization. Conversely, input-side techniques employ ML to learn compact, latent-space representations of feasible device geometries, enabling efficient global exploration through generative models. Each strategy presents unique trade-offs in data requirements, generalization capacity, and novel design discovery potentials. Hybrid frameworks that combine physics-based optimization with data-driven representations help escape poor local optima, improve scalability, and facilitate knowledge transfer. We conclude by highlighting open challenges and opportunities, emphasizing complexity management, geometry-independent representations, integration of fabrication constraints, and advancements in multiphysics co-designs. 

**Abstract (ZH)**: 纳米光子学中的逆设计，通过计算手段发现能够实现目标电磁（EM）响应的结构，已成为最近光子学进展的关键工具。传统基于直觉或迭代优化方法在面对高维度、非凸的设计空间以及电磁模拟的大量计算需求时显得力不从心。最近，机器学习（ML）的有效出现解决了这些瓶颈问题。本文通过表示学习的视角，将ML增强的逆设计方法学分类为输出侧和输入侧两种方法。输出侧方法利用机器学习在解空间中学习表示，生成差异化求解器以加速优化。相反，输入侧技术利用机器学习学习可行设备几何结构的紧凑、潜在空间表示，通过生成模型实现高效的整体探索。每种策略在数据需求、泛化能力和新型设计发现潜力方面具有独特的权衡。结合基于物理的优化与数据驱动表示的混合框架有助于跳出劣质局部最优解、提高可扩展性和促进知识转移。最后，我们强调了开放的挑战和机遇，强调复杂性管理、几何无关表示、集成制造约束以及多物理场联合设计的进展。 

---
# Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation 

**Title (ZH)**: 并非所有注意力头都是你需要的：基于注意力消融细化CLIP的图像表示 

**Authors**: Feng Lin, Marco Chen, Haokui Zhang, Xiaotian Yu, Guangming Lu, Rong Xiao  

**Link**: [PDF](https://arxiv.org/pdf/2507.00537)  

**Abstract**: This paper studies the role of attention heads in CLIP's image encoder. While CLIP has exhibited robust performance across diverse applications, we hypothesize that certain attention heads negatively affect final representations and that ablating them can improve performance in downstream tasks. To capitalize on this insight, we propose a simple yet effective method, called Attention Ablation Technique (AAT), to suppress the contribution of specific heads by manipulating attention weights. By integrating two alternative strategies tailored for different application scenarios, AAT systematically identifies and ablates detrimental attention heads to enhance representation quality. Experiments demonstrate that AAT consistently improves downstream task performance across various domains, boosting recall rate by up to 11.1% on CLIP-family models for cross-modal retrieval. The results highlight the potential of AAT to effectively refine large-scale vision-language models with virtually no increase in inference cost. 

**Abstract (ZH)**: 本文研究了CLIP图像编码器中注意力头的作用。尽管CLIP在多种应用中展现了稳健的性能，但我们假设某些注意力头对最终表示产生了负面影响，移除这些头可以提高下游任务的性能。为了利用这一洞察，我们提出了一种简单有效的方法——注意力消融技术（AAT），通过操纵注意力权重来抑制特定头的贡献。通过为不同应用场景量身定制的两种替代策略，AAT系统地识别并消融了有害的注意力头，以提升表示质量。实验结果表明，AAT在各种领域中一致地提高了下游任务的性能，在CLIP家族模型的跨模态检索中，召回率最多可提升11.1%。结果突显了AAT在几乎不增加推理成本的情况下有效精炼大规模视觉-语言模型的潜力。 

---
# Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support 

**Title (ZH)**: 在生成式人工智能时代的群体推荐系统重思：从单次推荐到有能动性的群体决策支持 

**Authors**: Dietmar Jannach, Amra Delić, Francesco Ricci, Markus Zanker  

**Link**: [PDF](https://arxiv.org/pdf/2507.00535)  

**Abstract**: More than twenty-five years ago, first ideas were developed on how to design a system that can provide recommendations to groups of users instead of individual users. Since then, a rich variety of algorithmic proposals were published, e.g., on how to acquire individual preferences, how to aggregate them, and how to generate recommendations for groups of users. However, despite the rich literature on the topic, barely any examples of real-world group recommender systems can be found. This lets us question common assumptions in academic research, in particular regarding communication processes in a group and how recommendation-supported decisions are made. In this essay, we argue that these common assumptions and corresponding system designs often may not match the needs or expectations of users. We thus call for a reorientation in this research area, leveraging the capabilities of modern Generative AI assistants like ChatGPT. Specifically, as one promising future direction, we envision group recommender systems to be systems where human group members interact in a chat and an AI-based group recommendation agent assists the decision-making process in an agentic way. Ultimately, this shall lead to a more natural group decision-making environment and finally to wider adoption of group recommendation systems in practice. 

**Abstract (ZH)**: 超过二十五年前，首次提出了如何设计一个系统以向用户群体而非单个用户提供推荐的想法。此后，发表了大量关于算法的提议，例如如何获取个人偏好、如何聚合这些偏好以及如何为用户群体生成推荐。然而，尽管该主题有大量的文献，但几乎找不到真正的群体推荐系统的实例。这让我们质疑学术研究中的常见假设，特别是关于群体中的沟通过程以及由推荐支持的决策是如何做出的。在本文中，我们认为这些常见假设和相应的系统设计往往可能不符合用户的需求或期望。因此，我们呼吁在这一研究领域进行重新定位，利用现代生成AI助手的能力，如ChatGPT。特别地，我们设想群体推荐系统将是人类群体成员在聊天中互动，并由基于AI的群体推荐代理以代理方式协助决策过程的系统。最终，这将促成一种更加自然的群体决策环境，并最终促进群体推荐系统的广泛应用。 

---
# Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving 

**Title (ZH)**: Box-QAymo: 自动驾驶中的盒状参照VQA数据集 

**Authors**: Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo  

**Link**: [PDF](https://arxiv.org/pdf/2507.00525)  

**Abstract**: Interpretable communication is essential for safe and trustworthy autonomous driving, yet current vision-language models (VLMs) often operate under idealized assumptions and struggle to capture user intent in real-world scenarios. Existing driving-oriented VQA datasets are limited to full-scene descriptions or waypoint prediction, preventing the assessment of whether VLMs can respond to localized user-driven queries. We introduce Box-QAymo, a box-referring dataset and benchmark designed to both evaluate and finetune VLMs on spatial and temporal reasoning over user-specified objects. Users express intent by drawing bounding boxes, offering a fast and intuitive interface for focused queries in complex scenes. Specifically, we propose a hierarchical evaluation protocol that begins with binary sanity-check questions to assess basic model capacities, and progresses to (1) attribute prediction for box-referred objects, (2) motion understanding of target instances, and (3) spatiotemporal motion reasoning over inter-object dynamics across frames. To support this, we crowd-sourced fine-grained object classes and visual attributes that reflect the complexity drivers encounter, and extract object trajectories to construct temporally grounded QA pairs. Rigorous quality control through negative sampling, temporal consistency checks, and difficulty-aware balancing guarantee dataset robustness and diversity. Our comprehensive evaluation reveals significant limitations in current VLMs when queried about perception questions, highlighting the gap in achieving real-world performance. This work provides a foundation for developing more robust and interpretable autonomous driving systems that can communicate effectively with users under real-world conditions. Project page and dataset are available at this https URL. 

**Abstract (ZH)**: 可解释的通信对于自主驾驶的安全性和可信度至关重要，然而当前的视觉-语言模型（VLMs）往往基于理想化的假设，并在现实世界场景中难以捕捉用户意图。现有的以驾驶为导向的VQA数据集仅限于全景描述或路径点预测，无法评估VLM是否能够响应局部的用户驱动查询。我们介绍了Box-QAymo，这是一个用于评估和微调VLM在用户指定对象上的空间和时间推理能力的框引用数据集和基准。用户通过绘制边界框来表达意图，提供了一种快速且直观的方法来在复杂场景中进行聚焦查询。具体地，我们提出了一种分层评估协议，从二元合理性检查问题开始，评估基本模型能力，进而包括（1）框引用对象的属性预测，（2）目标实例的运动理解，以及（3）跨帧的物体间动态的空间时间运动推理。为此，我们众包了反映复杂挑战的细粒度对象类别和视觉属性，并提取对象轨迹以构建时间上 ground 的问答对。严格的质量控制通过负样本抽取、时间一致性检查和难度感知平衡保证了数据集的稳健性和多样性。全面的评估揭示了当前VLM在查询感知问题时的重要局限性，突显了在现实世界性能方面实现的差距。这项工作为开发能够在现实世界条件下与用户有效沟通的更稳健和可解释的自主驾驶系统提供了基础。项目页面和数据集可访问：this https URL。 

---
# Customer Service Representative's Perception of the AI Assistant in an Organization's Call Center 

**Title (ZH)**: 组织呼叫中心客服代表对AI助手的感知 

**Authors**: Kai Qin, Kexin Du, Yimeng Chen, Yueyan Liu, Jie Cai, Zhiqiang Nie, Nan Gao, Guohui Wei, Shengzhu Wang, Chun Yu  

**Link**: [PDF](https://arxiv.org/pdf/2507.00513)  

**Abstract**: The integration of various AI tools creates a complex socio-technical environment where employee-customer interactions form the core of work practices. This study investigates how customer service representatives (CSRs) at the power grid service customer service call center perceive AI assistance in their interactions with customers. Through a field visit and semi-structured interviews with 13 CSRs, we found that AI can alleviate some traditional burdens during the call (e.g., typing and memorizing) but also introduces new burdens (e.g., earning, compliance, psychological burdens). This research contributes to a more nuanced understanding of AI integration in organizational settings and highlights the efforts and burdens undertaken by CSRs to adapt to the updated system. 

**Abstract (ZH)**: 多种AI工具的整合创建了一个复杂的社会-技术环境，其中员工与客户互动成为工作实践的核心。本研究探讨了电力电网服务呼叫中心的客户服务代表（CSR）在与客户互动中对AI辅助的看法。通过访问现场并对13名CSR进行半结构化访谈，我们发现AI可以在通话中减轻一些传统负担（如打字和记忆），但也带来了新的负担（如考勤、合规性和心理负担）。本研究有助于对组织环境中AI整合有更细致的理解，并突显了CSRs为适应更新系统所付出的努力和负担。 

---
# Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms 

**Title (ZH)**: Twill: 在异构移动边缘平台上调度复合AI系统 

**Authors**: Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri  

**Link**: [PDF](https://arxiv.org/pdf/2507.00491)  

**Abstract**: Compound AI (cAI) systems chain multiple AI models to solve complex problems. cAI systems are typically composed of deep neural networks (DNNs), transformers, and large language models (LLMs), exhibiting a high degree of computational diversity and dynamic workload variation. Deploying cAI services on mobile edge platforms poses a significant challenge in scheduling concurrent DNN-transformer inference tasks, which arrive dynamically in an unknown sequence. Existing mobile edge AI inference strategies manage multi-DNN or transformer-only workloads, relying on design-time profiling, and cannot handle concurrent inference of DNNs and transformers required by cAI systems. In this work, we address the challenge of scheduling cAI systems on heterogeneous mobile edge platforms. We present Twill, a run-time framework to handle concurrent inference requests of cAI workloads through task affinity-aware cluster mapping and migration, priority-aware task freezing/unfreezing, and DVFS, while minimizing inference latency within power budgets. We implement and deploy our Twill framework on the Nvidia Jetson Orin NX platform. We evaluate Twill against state-of-the-art edge AI inference techniques over contemporary DNNs and LLMs, reducing inference latency by 54% on average, while honoring power budgets. 

**Abstract (ZH)**: 面向异构移动边缘平台的复合AI系统调度框架Twill 

---
# PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning 

**Title (ZH)**: PNAct: 在安全强化学习中构建后门攻击 

**Authors**: Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00485)  

**Abstract**: Reinforcement Learning (RL) is widely used in tasks where agents interact with an environment to maximize rewards. Building on this foundation, Safe Reinforcement Learning (Safe RL) incorporates a cost metric alongside the reward metric, ensuring that agents adhere to safety constraints during decision-making. In this paper, we identify that Safe RL is vulnerable to backdoor attacks, which can manipulate agents into performing unsafe actions. First, we introduce the relevant concepts and evaluation metrics for backdoor attacks in Safe RL. It is the first attack framework in the Safe RL field that involves both Positive and Negative Action sample (PNAct) is to implant backdoors, where positive action samples provide reference actions and negative action samples indicate actions to be avoided. We theoretically point out the properties of PNAct and design an attack algorithm. Finally, we conduct experiments to evaluate the effectiveness of our proposed backdoor attack framework, evaluating it with the established metrics. This paper highlights the potential risks associated with Safe RL and underscores the feasibility of such attacks. Our code and supplementary material are available at this https URL. 

**Abstract (ZH)**: 安全强化学习(Safe RL)易受后门攻击：正反样本攻击框架及其评价 

---
# Diversity Conscious Refined Random Forest 

**Title (ZH)**: 意识多样性精炼随机森林 

**Authors**: Sijan Bhattarai, Saurav Bhandari, Girija Bhusal, Saroj Shakya, Tapendra Pandey  

**Link**: [PDF](https://arxiv.org/pdf/2507.00467)  

**Abstract**: Random Forest (RF) is a widely used ensemble learning technique known for its robust classification performance across diverse domains. However, it often relies on hundreds of trees and all input features, leading to high inference cost and model redundancy. In this work, our goal is to grow trees dynamically only on informative features and then enforce maximal diversity by clustering and retaining uncorrelated trees. Therefore, we propose a Refined Random Forest Classifier that iteratively refines itself by first removing the least informative features and then analytically determines how many new trees should be grown, followed by correlation-based clustering to remove redundant trees. The classification accuracy of our model was compared against the standard RF on the same number of trees. Experiments on 8 multiple benchmark datasets, including binary and multiclass datasets, demonstrate that the proposed model achieves improved accuracy compared to standard RF. 

**Abstract (ZH)**: 改进的随机森林分类器：动态生长信息性特征并强制最大化多样性和去冗余 

---
# Novel Complex-Valued Hopfield Neural Networks with Phase and Magnitude Quantization 

**Title (ZH)**: 新型相位和幅度量化复值霍普菲尔德神经网络 

**Authors**: Garimella Ramamurthy, Marcos Eduardo Valle, Tata Jagannadha Swamy  

**Link**: [PDF](https://arxiv.org/pdf/2507.00461)  

**Abstract**: This research paper introduces two novel complex-valued Hopfield neural networks (CvHNNs) that incorporate phase and magnitude quantization. The first CvHNN employs a ceiling-type activation function that operates on the rectangular coordinate representation of the complex net contribution. The second CvHNN similarly incorporates phase and magnitude quantization but utilizes a ceiling-type activation function based on the polar coordinate representation of the complex net contribution. The proposed CvHNNs, with their phase and magnitude quantization, significantly increase the number of states compared to existing models in the literature, thereby expanding the range of potential applications for CvHNNs. 

**Abstract (ZH)**: 这种研究论文介绍了两种新颖的复值霍普菲尔德神经网络（CvHNNs），这两者都结合了相位和幅度量化。第一种CvHNN采用天花板型激活函数，该函数基于复网络贡献的矩形坐标表示工作。第二种CvHNN同样结合了相位和幅度量化，但使用的是基于复网络贡献的极坐标表示的天花板型激活函数。提出的CvHNNs通过相位和幅度量化，相较于文献中现有的模型显著增加了状态数量，从而扩大了CvHNNs潜在应用的范围。 

---
# Process-aware and high-fidelity microstructure generation using stable diffusion 

**Title (ZH)**: 基于过程意识且高保真的微结构生成：使用稳定扩散方法 

**Authors**: Hoang Cuong Phan, Minh Tien Tran, Chihun Lee, Hoheok Kim, Sehyok Oh, Dong-Kyu Kim, Ho Won Lee  

**Link**: [PDF](https://arxiv.org/pdf/2507.00459)  

**Abstract**: Synthesizing realistic microstructure images conditioned on processing parameters is crucial for understanding process-structure relationships in materials design. However, this task remains challenging due to limited training micrographs and the continuous nature of processing variables. To overcome these challenges, we present a novel process-aware generative modeling approach based on Stable Diffusion 3.5 Large (SD3.5-Large), a state-of-the-art text-to-image diffusion model adapted for microstructure generation. Our method introduces numeric-aware embeddings that encode continuous variables (annealing temperature, time, and magnification) directly into the model's conditioning, enabling controlled image generation under specified process conditions and capturing process-driven microstructural variations. To address data scarcity and computational constraints, we fine-tune only a small fraction of the model's weights via DreamBooth and Low-Rank Adaptation (LoRA), efficiently transferring the pre-trained model to the materials domain. We validate realism using a semantic segmentation model based on a fine-tuned U-Net with a VGG16 encoder on 24 labeled micrographs. It achieves 97.1% accuracy and 85.7% mean IoU, outperforming previous methods. Quantitative analyses using physical descriptors and spatial statistics show strong agreement between synthetic and real microstructures. Specifically, two-point correlation and lineal-path errors remain below 2.1% and 0.6%, respectively. Our method represents the first adaptation of SD3.5-Large for process-aware microstructure generation, offering a scalable approach for data-driven materials design. 

**Abstract (ZH)**: 基于处理参数生成现实微观结构图像对于材料设计中的过程-结构关系理解至关重要。然而，由于训练 microscopy 图像数据有限以及处理变量的连续性，这一任务仍然具有挑战性。为克服这些挑战，我们提出了一个基于 Stable Diffusion 3.5 Large (SD3.5-Large) 的新型过程感知生成模型方法，该方法是一种先进的文本到图像的扩散模型，适用于微观结构生成。我们的方法引入了数值感知嵌入，直接将连续变量（退火温度、时间和放大倍数）编码到模型的条件中，从而在指定的加工条件下实现可控的图像生成并捕捉加工驱动的微观结构变化。为解决数据稀缺性和计算约束，我们仅通过 DreamBooth 和 Low-Rank Adaptation (LoRA) 微调模型的一小部分权重，高效地将预训练模型转移到材料领域。使用基于微调 U-Net 和 VGG16 编码器的语义分割模型验证真实性，该模型在 24 张标注的 microscopy 图像上实现了 97.1% 的准确率和 85.7% 的平均 IoU，超过了以前的方法。使用物理描述符和空间统计进行的定量分析显示合成的微观结构与真实微观结构之间有很强的一致性。具体来说，两点相关误差和线性路径误差均低于 2.1% 和 0.6%。我们的方法是 SD3.5-Large 首次用于过程感知微观结构生成，提供了一种数据驱动材料设计的可扩展方法。 

---
# Best Agent Identification for General Game Playing 

**Title (ZH)**: 通用游戏-playing 中最优代理识别 

**Authors**: Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers  

**Link**: [PDF](https://arxiv.org/pdf/2507.00451)  

**Abstract**: We present an efficient and generalised procedure to accurately identify the best performing algorithm for each sub-task in a multi-problem domain. Our approach treats this as a set of best arm identification problems for multi-armed bandits, where each bandit corresponds to a specific task and each arm corresponds to a specific algorithm or agent. We propose an optimistic selection process based on the Wilson score interval (Optimistic-WS) that ranks each arm across all bandits in terms of their potential regret reduction. We evaluate the performance of Optimistic-WS on two of the most popular general game domains, the General Video Game AI (GVGAI) framework and the Ludii general game playing system, with the goal of identifying the highest performing agent for each game within a limited number of trials. Compared to previous best arm identification algorithms for multi-armed bandits, our results demonstrate a substantial performance improvement in terms of average simple regret. This novel approach can be used to significantly improve the quality and accuracy of agent evaluation procedures for general game frameworks, as well as other multi-task domains with high algorithm runtimes. 

**Abstract (ZH)**: 一种高效且通用的多问题域中最佳算法识别方法 

---
# Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design 

**Title (ZH)**: 迭代蒸馏以指导奖励精细调整的生物分子设计扩散模型fine-tuning 

**Authors**: Xingyu Su, Xiner Li, Masatoshi Uehara, Sunwoo Kim, Yulai Zhao, Gabriele Scalia, Ehsan Hajiramezanali, Tommaso Biancalani, Degui Zhi, Shuiwang Ji  

**Link**: [PDF](https://arxiv.org/pdf/2507.00445)  

**Abstract**: We address the problem of fine-tuning diffusion models for reward-guided generation in biomolecular design. While diffusion models have proven highly effective in modeling complex, high-dimensional data distributions, real-world applications often demand more than high-fidelity generation, requiring optimization with respect to potentially non-differentiable reward functions such as physics-based simulation or rewards based on scientific knowledge. Although RL methods have been explored to fine-tune diffusion models for such objectives, they often suffer from instability, low sample efficiency, and mode collapse due to their on-policy nature. In this work, we propose an iterative distillation-based fine-tuning framework that enables diffusion models to optimize for arbitrary reward functions. Our method casts the problem as policy distillation: it collects off-policy data during the roll-in phase, simulates reward-based soft-optimal policies during roll-out, and updates the model by minimizing the KL divergence between the simulated soft-optimal policy and the current model policy. Our off-policy formulation, combined with KL divergence minimization, enhances training stability and sample efficiency compared to existing RL-based methods. Empirical results demonstrate the effectiveness and superior reward optimization of our approach across diverse tasks in protein, small molecule, and regulatory DNA design. 

**Abstract (ZH)**: 我们探讨了使用奖励导向生成优化调整扩散模型在生物分子设计中的问题。虽然扩散模型已经在建模复杂高维度数据分布方面展现出高度有效性，但实际应用往往需要更多的优化，要求优化潜在的非可微奖励函数，如基于物理的模拟或基于科学知识的奖励。尽管已经探索了使用强化学习方法来调整扩散模型以实现此类目标，但这些方法往往因其基于策略的性质而表现出不稳定性、低样本效率和模式崩溃。在这项工作中，我们提出了一种迭代蒸馏式的调整框架，使扩散模型能够优化任意奖励函数。我们的方法将问题视为策略蒸馏：在卷入阶段收集离策略数据，在运行阶段模拟基于奖励的软最优策略，并通过最小化模拟的软最优策略与当前模型策略之间的KL散度来更新模型。与现有的基于强化学习的方法相比，我们的离策略表示和KL散度最小化增强了训练的稳定性和样本效率。实验结果证明了我们在蛋白质、小分子和调控DNA设计等多个任务中有效且优秀的奖励优化能力。 

---
# A Recipe for Causal Graph Regression: Confounding Effects Revisited 

**Title (ZH)**: 因果图回归的配方：重新审视混杂效应 

**Authors**: Yujia Yin, Tianyi Qu, Zihao Wang, Yifan Chen  

**Link**: [PDF](https://arxiv.org/pdf/2507.00440)  

**Abstract**: Through recognizing causal subgraphs, causal graph learning (CGL) has risen to be a promising approach for improving the generalizability of graph neural networks under out-of-distribution (OOD) scenarios. However, the empirical successes of CGL techniques are mostly exemplified in classification settings, while regression tasks, a more challenging setting in graph learning, are overlooked. We thus devote this work to tackling causal graph regression (CGR); to this end we reshape the processing of confounding effects in existing CGL studies, which mainly deal with classification. Specifically, we reflect on the predictive power of confounders in graph-level regression, and generalize classification-specific causal intervention techniques to regression through a lens of contrastive learning. Extensive experiments on graph OOD benchmarks validate the efficacy of our proposals for CGR. The model implementation and the code are provided on this https URL. 

**Abstract (ZH)**: 通过识别因果子图，因果图学习（CGL）已成为在分布外（OOD）场景下提高图神经网络泛化能力的有前途的方法；然而，现有的CGL技术在回归任务中的应用较少，而回归任务是图学习中更加具有挑战性的任务。因此，本文致力于解决因果图回归（CGR）问题；为此，我们重新审视了现有CGL研究中干扰效应对处理方式，并将针对分类任务的因果干预技术通过对比学习的视角推广到回归任务中。大量实验在图分布外基准测试上验证了我们提出的CGR方法的有效性；相关模型实现和代码参见此链接。 

---
# Augmenting Molecular Graphs with Geometries via Machine Learning Interatomic Potentials 

**Title (ZH)**: 使用机器学习原子势增强分子图的几何结构 

**Authors**: Cong Fu, Yuchao Lin, Zachary Krueger, Haiyang Yu, Maho Nakata, Jianwen Xie, Emine Kucukbenli, Xiaofeng Qian, Shuiwang Ji  

**Link**: [PDF](https://arxiv.org/pdf/2507.00407)  

**Abstract**: Accurate molecular property predictions require 3D geometries, which are typically obtained using expensive methods such as density functional theory (DFT). Here, we attempt to obtain molecular geometries by relying solely on machine learning interatomic potential (MLIP) models. To this end, we first curate a large-scale molecular relaxation dataset comprising 3.5 million molecules and 300 million snapshots. Then MLIP foundation models are trained with supervised learning to predict energy and forces given 3D molecular structures. Once trained, we show that the foundation models can be used in different ways to obtain geometries either explicitly or implicitly. First, it can be used to obtain low-energy 3D geometries via geometry optimization, providing relaxed 3D geometries for downstream molecular property predictions. To mitigate potential biases and enhance downstream predictions, we introduce geometry fine-tuning based on the relaxed 3D geometries. Second, the foundation models can be directly fine-tuned for property prediction when ground truth 3D geometries are available. Our results demonstrate that MLIP foundation models trained on relaxation data can provide valuable molecular geometries that benefit property predictions. 

**Abstract (ZH)**: 准确的分子性质预测需要三维几何结构，这些结构通常通过密度泛函理论（DFT）等昂贵的方法获得。在这里，我们尝试仅依靠机器学习原子势（MLIP）模型来获取分子几何结构。为此，我们首先构建了一个包含350万分子和3亿个快照的大规模分子弛豫数据集。然后，使用监督学习训练MLIP基础模型，以预测给定三维分子结构的能量和力。训练完成后，我们展示该基础模型可以通过不同的方式来获取几何结构，既可以显式地，也可以隐式地。首先，它可以用于通过几何优化获得低能量的三维几何结构，提供可用于下游分子性质预测的弛豫三维几何结构。为了缓解潜在的偏差并提高下游预测，我们基于弛豫三维几何结构提出了几何结构微调方法。其次，当有真实的三维几何结构时，基础模型可以直接微调以进行性质预测。我们的结果表明，基于弛豫数据训练的MLIP基础模型可以提供有利于性质预测的宝贵分子几何结构。 

---
# Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems 

**Title (ZH)**: 数据驱动探究在一类连续时间线性-二次强化学习问题中的应用 

**Authors**: Yilie Huang, Xun Yu Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2507.00358)  

**Abstract**: We study reinforcement learning (RL) for the same class of continuous-time stochastic linear--quadratic (LQ) control problems as in \cite{huang2024sublinear}, where volatilities depend on both states and controls while states are scalar-valued and running control rewards are absent. We propose a model-free, data-driven exploration mechanism that adaptively adjusts entropy regularization by the critic and policy variance by the actor. Unlike the constant or deterministic exploration schedules employed in \cite{huang2024sublinear}, which require extensive tuning for implementations and ignore learning progresses during iterations, our adaptive exploratory approach boosts learning efficiency with minimal tuning. Despite its flexibility, our method achieves a sublinear regret bound that matches the best-known model-free results for this class of LQ problems, which were previously derived only with fixed exploration schedules. Numerical experiments demonstrate that adaptive explorations accelerate convergence and improve regret performance compared to the non-adaptive model-free and model-based counterparts. 

**Abstract (ZH)**: 我们研究了与文献\[huang2024sublinear\]中相同的连续时间随机线性-quadratic (LQ) 控制问题的强化学习（RL），其中波动性依赖于状态和控制，而状态是标量值且不存在运行控制奖励。我们提出了一种无模型的数据驱动探索机制，该机制通过评论家自适应调整熵正则化，并通过行动者调整策略方差。与\[huang2024sublinear\]中使用的常量或确定性探索计划不同，后者需要大量的手动调整且在迭代过程中忽略学习进展，我们的自适应探索方法在最少的手动调整下提高了学习效率。尽管具有灵活性，我们的方法实现了与LQ问题此类别中已知的最佳无模型结果相同的次线性遗憾界，此前这些结果仅在固定探索计划下得到。数值实验表明，与非自适应无模型和基于模型的对应方法相比，自适应探索加速了收敛并提高了遗憾性能。 

---
# VTS-Guided AI Interaction Workflow for Business Insights 

**Title (ZH)**: VTS引导的AI交互工作流及其商业洞察 

**Authors**: Sun Ding, Ude Enebeli, Atilhan, Manay, Ryan Pua, Kamal Kotak  

**Link**: [PDF](https://arxiv.org/pdf/2507.00347)  

**Abstract**: Modern firms face a flood of dense, unstructured reports. Turning these documents into usable insights takes heavy effort and is far from agile when quick answers are needed. VTS-AI tackles this gap. It integrates Visual Thinking Strategies, which emphasize evidence-based observation, linking, and thinking, into AI agents, so the agents can extract business insights from unstructured text, tables, and images at scale. The system works in three tiers (micro, meso, macro). It tags issues, links them to source pages, and rolls them into clear action levers stored in a searchable YAML file. In tests on an 18-page business report, VTS-AI matched the speed of a one-shot ChatGPT prompt yet produced richer findings: page locations, verbatim excerpts, severity scores, and causal links. Analysts can accept or adjust these outputs in the same IDE, keeping human judgment in the loop. Early results show VTS-AI spots the direction of key metrics and flags where deeper number-crunching is needed. Next steps include mapping narrative tags to financial ratios, adding finance-tuned language models through a Model-Context Protocol, and building a Risk & Safety Layer to stress-test models and secure data. These upgrades aim to make VTS-AI a production-ready, audit-friendly tool for rapid business analysis. 

**Abstract (ZH)**: 现代企业面临海量密集的非结构化报告。将这些文档转化为可用洞察需要大量努力，且当需要快速答案时，这一过程并不敏捷。VTS-AI 破解了这一难题。它将基于证据的观察、关联和思考的视觉思维策略整合到 AI 代理中，使代理能够大规模从非结构化文本、表格和图像中提取商业洞察。系统分为三个层级（微观、中观、宏观）。它标记问题，链接到源页面，并将它们整合到可搜索的 YAML 文件中存储的清晰行动杠杆中。在对一份18页的商业报告进行测试中，VTS-AI 的速度与一次性的 ChatGPT 提示相当，但产出的内容更加丰富：页面位置、原话摘录、严重程度评分和因果关联。分析师可以在相同的 IDE 中接受或调整这些输出，将人类判断纳入决策过程。初步结果显示，VTS-AI 能够识别关键指标的方向，并指出需要更深入数据处理的领域。下一步计划包括将叙述标签映射到财务比率、通过模型-上下文协议添加金融调整型语言模型以及构建风险与安全层以压力测试模型和保障数据安全。这些升级旨在使 VTS-AI 成为一种成熟、审计友好的快速商业分析工具。 

---
# Open-ended Scientific Discovery via Bayesian Surprise 

**Title (ZH)**: 基于贝叶斯惊讶的开放式科学发现 

**Authors**: Dhruv Agarwal, Bodhisattwa Prasad Majumder, Reece Adamson, Megha Chakravorty, Satvika Reddy Gavireddy, Aditya Parashar, Harshit Surana, Bhavana Dalvi Mishra, Andrew McCallum, Ashish Sabharwal, Peter Clark  

**Link**: [PDF](https://arxiv.org/pdf/2507.00310)  

**Abstract**: The promise of autonomous scientific discovery (ASD) hinges not only on answering questions, but also on knowing which questions to ask. Most recent works in ASD explore the use of large language models (LLMs) in goal-driven settings, relying on human-specified research questions to guide hypothesis generation. However, scientific discovery may be accelerated further by allowing the AI system to drive exploration by its own criteria. The few existing approaches in open-ended ASD select hypotheses based on diversity heuristics or subjective proxies for human interestingness, but the former struggles to meaningfully navigate the typically vast hypothesis space, and the latter suffers from imprecise definitions. This paper presents AutoDS -- a method for open-ended ASD that instead drives scientific exploration using Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior beliefs about a hypothesis to its posterior beliefs after gathering experimental results. To efficiently explore the space of nested hypotheses, our method employs a Monte Carlo tree search (MCTS) strategy with progressive widening using surprisal as the reward function. We evaluate AutoDS in the setting of data-driven discovery across 21 real-world datasets spanning domains such as biology, economics, finance, and behavioral science. Our results demonstrate that under a fixed budget, AutoDS substantially outperforms competitors by producing 5--29\% more discoveries deemed surprising by the LLM. Our human evaluation further finds that two-thirds of AutoDS discoveries are surprising to the domain experts, suggesting this is an important step forward towards building open-ended ASD systems. 

**Abstract (ZH)**: 自主科学发现的潜力不仅在于回答问题，还在于知道提出哪些问题。 Autonomous Scientific Discovery 的潜力不仅在于回答问题，还在于知道提出哪些问题。 

---
# Natural language processing for African languages 

**Title (ZH)**: 非洲语言的自然语言处理 

**Authors**: David Ifeoluwa Adelani  

**Link**: [PDF](https://arxiv.org/pdf/2507.00297)  

**Abstract**: Recent advances in word embeddings and language models use large-scale, unlabelled data and self-supervised learning to boost NLP performance. Multilingual models, often trained on web-sourced data like Wikipedia, face challenges: few low-resource languages are included, their data is often noisy, and lack of labeled datasets makes it hard to evaluate performance outside high-resource languages like English. In this dissertation, we focus on languages spoken in Sub-Saharan Africa where all the indigenous languages in this region can be regarded as low-resourced in terms of the availability of labelled data for NLP tasks and unlabelled data found on the web. We analyse the noise in the publicly available corpora, and curate a high-quality corpus, demonstrating that the quality of semantic representations learned in word embeddings does not only depend on the amount of data but on the quality of pre-training data. We demonstrate empirically the limitations of word embeddings, and the opportunities the multilingual pre-trained language model (PLM) offers especially for languages unseen during pre-training and low-resource scenarios. We further study how to adapt and specialize multilingual PLMs to unseen African languages using a small amount of monolingual texts. To address the under-representation of the African languages in NLP research, we developed large scale human-annotated labelled datasets for 21 African languages in two impactful NLP tasks: named entity recognition and machine translation. We conduct an extensive empirical evaluation using state-of-the-art methods across supervised, weakly-supervised, and transfer learning settings. 

**Abstract (ZH)**: Recent advances in词嵌入和语言模型利用大规模未标注数据和自我监督学习提升自然语言处理性能。多语言模型常在诸如维基百科等网络数据上训练，但面临挑战：低资源语言覆盖率低、数据质量参差不齐，缺乏标注数据集使得在外语种如英语以外的语言上评估性能困难。在此博士论文中，我们专注于撒哈拉以南非洲地区语言，所有该地区的本地语言在标注数据和网络上找到的未标注数据方面均可视为低资源语言。我们分析了公开可用语料库中的噪音，并编纂了高质量的语料库，证明词嵌入中学习的语义表示的质量不仅取决于数据量还取决于预训练数据的质量。我们通过实验证明词嵌入的局限性以及多语言预训练语言模型（PLM）在其特别对于预训练未见的语言和低资源场景中提供的机会。我们进一步研究如何使用少量单语文本适应和专门化多语言PLMs以应对非洲语言在NLP研究中的代表性不足。为此，我们为两项重要NLP任务（命名实体识别和机器翻译）为21种非洲语言开发了大规模人工标注的数据集。我们在监督学习、弱监督学习和迁移学习设置中进行了广泛实证评估。 

---
# Reducing Variability of Multiple Instance Learning Methods for Digital Pathology 

**Title (ZH)**: 多实例学习方法在数字病理学中减少变异性研究 

**Authors**: Ali Mammadov, Loïc Le Folgoc, Guillaume Hocquet, Pietro Gori  

**Link**: [PDF](https://arxiv.org/pdf/2507.00292)  

**Abstract**: Digital pathology has revolutionized the field by enabling the digitization of tissue samples into whole slide images (WSIs). However, the high resolution and large size of WSIs present significant challenges when it comes to applying Deep Learning models. As a solution, WSIs are often divided into smaller patches with a global label (\textit{i.e., diagnostic}) per slide, instead of a (too) costly pixel-wise annotation. By treating each slide as a bag of patches, Multiple Instance Learning (MIL) methods have emerged as a suitable solution for WSI classification. A major drawback of MIL methods is their high variability in performance across different runs, which can reach up to 10-15 AUC points on the test set, making it difficult to compare different MIL methods reliably. This variability mainly comes from three factors: i) weight initialization, ii) batch (shuffling) ordering, iii) and learning rate. To address that, we introduce a Multi-Fidelity, Model Fusion strategy for MIL methods. We first train multiple models for a few epochs and average the most stable and promising ones based on validation scores. This approach can be applied to any existing MIL model to reduce performance variability. It also simplifies hyperparameter tuning and improves reproducibility while maintaining computational efficiency. We extensively validate our approach on WSI classification tasks using 2 different datasets, 3 initialization strategies and 5 MIL methods, for a total of more than 2000 experiments. 

**Abstract (ZH)**: 数字病理学通过将组织样本数字化为全-slide 图像（WSIs）而革新了该领域。然而，WSIs 的高分辨率和大尺寸给深度学习模型的应用带来了巨大挑战。为解决这一问题，WSIs 常被分割成较小的patches，每张slide附带一个全局标签（即诊断标签），而非逐像素注释。通过将每张slide视为patches的集合，多次实例学习（MIL）方法成为WSI分类的一种合适解决方案。MIL方法的主要缺点是其在不同运行中的性能差异性很大，在测试集上的性能差异可达10-15个AUC点，这使得不同MIL方法之间的可靠比较变得困难。这种差异性主要来自于三个因素：i) 权重初始化，ii) 批次排序，iii) 学习率。为解决这一问题，我们提出了一种适用于MIL方法的多保真度模型融合策略。我们首先训练多个模型几个epoch，并基于验证分数选择最稳定和潜在表现最好的模型进行平均。该方法可以应用于任何现有的MIL模型以减少性能差异性。同时，它简化了超参数调优，提高了可重复性，同时保持了计算效率。我们在2个不同的数据集、3种初始化策略和5种MIL方法上进行了详尽的验证，总共进行了超过2000次实验。 

---
# Reconfiguring Digital Accountability: AI-Powered Innovations and Transnational Governance in a Postnational Accounting Context 

**Title (ZH)**: 重塑数字问责制：后国家记账背景下基于人工智能的创新与跨国治理 

**Authors**: Claire Li, David Freeborn  

**Link**: [PDF](https://arxiv.org/pdf/2507.00288)  

**Abstract**: This study explores how AI-powered digital innovations are reshaping organisational accountability in a transnational governance context. As AI systems increasingly mediate decision-making in domains such as auditing and financial reporting, traditional mechanisms of accountability, based on control, transparency, and auditability, are being destabilised. We integrate the Technology Acceptance Model (TAM), Actor-Network Theory (ANT), and institutional theory to examine how organisations adopt AI technologies in response to regulatory, ethical, and cultural pressures that transcend national boundaries. We argue that accountability is co-constructed within global socio-technical networks, shaped not only by user perceptions but also by governance logics and normative expectations. Extending TAM, we incorporate compliance and legitimacy as key factors in perceived usefulness and usability. Drawing on ANT, we reconceptualise accountability as a relational and emergent property of networked assemblages. We propose two organisational strategies including internal governance reconfiguration and external actor-network engagement to foster responsible, legitimate, and globally accepted AI adoption in the accounting domain. 

**Abstract (ZH)**: 本研究探讨了基于AI的数字创新如何在全球治理背景下重塑组织问责制。随着AI系统在审计和财务报告等领域日益成为决策的中介，传统的基于控制、透明度和可审计性的问责机制正被动摇。我们结合技术接受模型（TAM）、行动者网络理论（ANT）和制度理论，探讨组织如何在超越国界的监管、伦理和文化压力下采纳AI技术。我们认为，问责制是在全球社会-技术网络中共同建构的，不仅受用户感知的影响，也受治理逻辑和规范性预期的影响。扩展TAM，我们将合规性和合法性纳入感知有用性和易用性的重要因素。借助ANT，我们将问责制重新概念化为网络组装体中的一种关系性和涌现性属性。我们提出了两种组织策略，包括内部治理重构和外部行动者网络互动，以促进会计领域负责任、合法性和全球接受的AI采用。 

---
# Visual Privacy Management with Generative AI for Blind and Low-Vision People 

**Title (ZH)**: 基于生成AI的视觉隐私管理方法及其在盲人和低视力人群中的应用 

**Authors**: Tanusree Sharma, Yu-Yun Tseng, Lotus Zhang, Ayae Ide, Kelly Avery Mack, Leah Findlater, Danna Gurari, Yang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00286)  

**Abstract**: Blind and low vision (BLV) individuals use Generative AI (GenAI) tools to interpret and manage visual content in their daily lives. While such tools can enhance the accessibility of visual content and so enable greater user independence, they also introduce complex challenges around visual privacy. In this paper, we investigate the current practices and future design preferences of blind and low vision individuals through an interview study with 21 participants. Our findings reveal a range of current practices with GenAI that balance privacy, efficiency, and emotional agency, with users accounting for privacy risks across six key scenarios, such as self-presentation, indoor/outdoor spatial privacy, social sharing, and handling professional content. Our findings reveal design preferences, including on-device processing, zero-retention guarantees, sensitive content redaction, privacy-aware appearance indicators, and multimodal tactile mirrored interaction methods. We conclude with actionable design recommendations to support user-centered visual privacy through GenAI, expanding the notion of privacy and responsible handling of others data. 

**Abstract (ZH)**: 盲人和低视力个体使用生成人工智能工具处理日常生活中的视觉内容及其面临的复杂隐私挑战：当前实践与未来设计偏好研究 

---
# Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations 

**Title (ZH)**: 特征整合空间：联合训练揭示神经网络表示中的双重编码 

**Authors**: Omar Claflin  

**Link**: [PDF](https://arxiv.org/pdf/2507.00269)  

**Abstract**: Current sparse autoencoder (SAE) approaches to neural network interpretability assume that activations can be decomposed through linear superposition into sparse, interpretable features. Despite high reconstruction fidelity, SAEs consistently fail to eliminate polysemanticity and exhibit pathological behavioral errors. We propose that neural networks encode information in two complementary spaces compressed into the same substrate: feature identity and feature integration. To test this dual encoding hypothesis, we develop sequential and joint-training architectures to capture identity and integration patterns simultaneously. Joint training achieves 41.3% reconstruction improvement and 51.6% reduction in KL divergence errors. This architecture spontaneously develops bimodal feature organization: low squared norm features contributing to integration pathways and the rest contributing directly to the residual. Small nonlinear components (3% of parameters) achieve 16.5% standalone improvements, demonstrating parameter-efficient capture of computational relationships crucial for behavior. Additionally, intervention experiments using 2x2 factorial stimulus designs demonstrated that integration features exhibit selective sensitivity to experimental manipulations and produce systematic behavioral effects on model outputs, including significant interaction effects across semantic dimensions. This work provides systematic evidence for (1) dual encoding in neural representations, (2) meaningful nonlinearly encoded feature interactions, and (3) introduces an architectural paradigm shift from post-hoc feature analysis to integrated computational design, establishing foundations for next-generation SAEs. 

**Abstract (ZH)**: 当前的稀疏自编码器（SAE）方法假设激活可以通过线性叠加分解为稀疏且可解释的特征，尽管具有高重建保真度，但SAE始终无法消除多义性并表现出病理性行为错误。我们提出，神经网络以互补的方式在相同的基质中编码信息：特征身份与特征整合。为了检验这种双编码假设，我们开发了顺序和联合训练架构，同时捕捉身份和整合模式。联合训练实现了41.3%的重建改善和51.6%的KL散度错误减少。该架构自发形成了二态特征组织：低范数平方特征参与整合路径，其余特征直接贡献于残差。少量非线性组件（参数的3%）实现了16.5%的独立改进，展示了对行为至关重要的计算关系的参数效率捕获。此外，使用2x2因素刺激设计的干预实验表明，整合特征对实验操纵具有选择性敏感性，并对模型输出产生系统的行为影响，包括多义性维度之间的显著交互效应。这项工作提供了关于（1）神经表示中的双编码、（2）有意义的非线性编码特征相互作用以及（3）从事后特征分析到集成计算设计的架构范式转变的系统证据，为下一代SAE奠定了基础。 

---
# Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations 

**Title (ZH)**: 时间序列可解释AI：多模型热图融合与全局注意力及NLP生成的解释 

**Authors**: Jiztom Kavalakkatt Francis, Matthew J Darr  

**Link**: [PDF](https://arxiv.org/pdf/2507.00234)  

**Abstract**: In this paper, we present a novel framework for enhancing model interpretability by integrating heatmaps produced separately by ResNet and a restructured 2D Transformer with globally weighted input saliency. We address the critical problem of spatial-temporal misalignment in existing interpretability methods, where convolutional networks fail to capture global context and Transformers lack localized precision - a limitation that impedes actionable insights in safety-critical domains like healthcare and industrial monitoring. Our method merges gradient-weighted activation maps (ResNet) and Transformer attention rollout into a unified visualization, achieving full spatial-temporal alignment while preserving real-time performance. Empirical evaluations on clinical (ECG arrhythmia detection) and industrial (energy consumption prediction) datasets demonstrate significant improvements: the hybrid framework achieves 94.1% accuracy (F1 0.93) on the PhysioNet dataset and reduces regression error to RMSE = 0.28 kWh (R2 = 0.95) on the UCI Energy Appliance dataset-outperforming standalone ResNet, Transformer, and InceptionTime baselines by 3.8-12.4%. An NLP module translates fused heatmaps into domain-specific narratives (e.g., "Elevated ST-segment between 2-4 seconds suggests myocardial ischemia"), validated via BLEU-4 (0.586) and ROUGE-L (0.650) scores. By formalizing interpretability as causal fidelity and spatial-temporal alignment, our approach bridges the gap between technical outputs and stakeholder understanding, offering a scalable solution for transparent, time-aware decision-making. 

**Abstract (ZH)**: 一种结合ResNet和重构2D Transformer生成的热图并与全局加权输入显著性相融合以增强模型可解释性的新框架 

---
# A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss 

**Title (ZH)**: 一种使用复数全局注意力模块和频谱时域损失的高保真度语音超分辨网络 

**Authors**: Tarikul Islam Tamiti, Biraj Joshi, Rida Hasan, Rashedul Hasan, Taieba Athay, Nursad Mamun, Anomadarshi Barua  

**Link**: [PDF](https://arxiv.org/pdf/2507.00229)  

**Abstract**: Speech super-resolution (SSR) enhances low-resolution speech by increasing the sampling rate. While most SSR methods focus on magnitude reconstruction, recent research highlights the importance of phase reconstruction for improved perceptual quality. Therefore, we introduce CTFT-Net, a Complex Time-Frequency Transformation Network that reconstructs both magnitude and phase in complex domains for improved SSR tasks. It incorporates a complex global attention block to model inter-phoneme and inter-frequency dependencies and a complex conformer to capture long-range and local features, improving frequency reconstruction and noise robustness. CTFT-Net employs time-domain and multi-resolution frequency-domain loss functions for better generalization. Experiments show CTFT-Net outperforms state-of-the-art models (NU-Wave, WSRGlow, NVSR, AERO) on the VCTK dataset, particularly for extreme upsampling (2 kHz to 48 kHz), reconstructing high frequencies effectively without noisy artifacts. 

**Abstract (ZH)**: 复杂时间频率变换网络（CTFT-Net）在提高语音超分辨率中的应用 

---
# Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis 

**Title (ZH)**: 研究语音合成中韵律模型的随机方法 

**Authors**: Paul Mayer, Florian Lux, Alejandro Pérez-González-de-Martos, Angelina Elizarova, Lindsey Vanderlyn, Dirk Väth, Ngoc Thang Vu  

**Link**: [PDF](https://arxiv.org/pdf/2507.00227)  

**Abstract**: While generative methods have progressed rapidly in recent years, generating expressive prosody for an utterance remains a challenging task in text-to-speech synthesis. This is particularly true for systems that model prosody explicitly through parameters such as pitch, energy, and duration, which is commonly done for the sake of interpretability and controllability. In this work, we investigate the effectiveness of stochastic methods for this task, including Normalizing Flows, Conditional Flow Matching, and Rectified Flows. We compare these methods to a traditional deterministic baseline, as well as to real human realizations. Our extensive subjective and objective evaluations demonstrate that stochastic methods produce natural prosody on par with human speakers by capturing the variability inherent in human speech. Further, they open up additional controllability options by allowing the sampling temperature to be tuned. 

**Abstract (ZH)**: 尽管生成方法在近年来取得了 rapidprogress，但在文本到语音合成中为语音生成有表现力的重音依然是一项具有挑战性的任务。特别是在通过音高、能量和时长等参数显式建模重音的系统中表现得尤为明显，这样做通常是为了提高可解释性和可控性。在本文中，我们探讨了 stochastic 方法在这一任务中的有效性，包括归一化流动、条件流动匹配和修正流动。我们将这些方法与传统的确定性基线方法以及真实的人类实现进行了对比。我们广泛进行的主观和客观评价表明，stochastic 方法能够通过捕捉人类语音固有的变异性来生成自然的重音，同时通过调节采样温度提供了额外的可控性选项。 

---
# Discovering the underlying analytic structure within Standard Model constants using artificial intelligence 

**Title (ZH)**: 使用人工智能发现标准模型常数背后的分析结构 

**Authors**: S. V. Chekanov, H. Kjellerstrand  

**Link**: [PDF](https://arxiv.org/pdf/2507.00225)  

**Abstract**: This paper presents a search for underlying analytic structures among the fundamental parameters of the Standard Model (SM) using symbolic regression and genetic programming. We identify the simplest analytic relationships connecting pairs of these constants and report several notable observations based on about a thousand expressions with relative precision better than 1%. These results may serve as valuable inputs for model builders and artificial intelligence methods aimed at uncovering hidden patterns among the SM constants, or potentially used as building blocks for a deeper underlying law that connects all parameters of the SM through a small set of fundamental constants. 

**Abstract (ZH)**: 本文使用符号回归和遗传编程寻找标准模型基本参数之间的潜在分析结构，识别简单的分析关系连接这些常数的配对，并基于约一千个相对精度优于1%的表达式报告了若干显著观察结果。这些结果可作为模型构建者和旨在发现标准模型常数之间隐藏模式的人工智能方法的宝贵输入，或作为通过少量基本常数连接标准模型所有参数的更深层次基本定律的构建块。 

---
# What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness 

**Title (ZH)**: 本地更新为何有效：数据异质性和光滑性的作用 

**Authors**: Kumar Kshitij Patel  

**Link**: [PDF](https://arxiv.org/pdf/2507.00195)  

**Abstract**: This thesis contributes to the theoretical understanding of local update algorithms, especially Local SGD, in distributed and federated optimization under realistic models of data heterogeneity. A central focus is on the bounded second-order heterogeneity assumption, which is shown to be both necessary and sufficient for local updates to outperform centralized or mini-batch methods in convex and non-convex settings. The thesis establishes tight upper and lower bounds in several regimes for various local update algorithms and characterizes the min-max complexity of multiple problem classes. At its core is a fine-grained consensus-error-based analysis framework that yields sharper finite-time convergence bounds under third-order smoothness and relaxed heterogeneity assumptions. The thesis also extends to online federated learning, providing fundamental regret bounds under both first-order and bandit feedback. Together, these results clarify when and why local updates offer provable advantages, and the thesis serves as a self-contained guide for analyzing Local SGD in heterogeneous environments. 

**Abstract (ZH)**: 本论文 contributes 于局部更新算法，尤其是局部SGD，在现实数据异构性模型下的分布式和联邦优化中的理论理解。核心关注点是有限二次异构性假设，该假设在凸性和非凸设置下被证明既是必要条件也是充分条件，使得局部更新能够优于中心化或小批量方法。本文在多种局部更新算法的不同情况下建立了紧致的上界和下界，并刻画了多个问题类别的最小最大复杂性。核心在于一种精细的共识误差分析框架，该框架在三次光滑和放宽异构性假设下，提供了更为精确的有限时间收敛界限。本文还扩展到了在线联邦学习，提供了基于一阶和 bandit 反馈的本原后悔界限。综上所述，这些结果明确了在什么情况下以及为什么局部更新提供了可证明的优势，并且本文作为在异构环境分析局部SGD的自包含指南。 

---
# Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions 

**Title (ZH)**: 超越传感器数据：可穿戴设备行为数据的foundation模型改善健康预测 

**Authors**: Eray Erturk, Fahad Kamran, Salar Abbaspourazad, Sean Jewell, Harsh Sharma, Yujie Li, Sinead Williamson, Nicholas J Foti, Joseph Futoma  

**Link**: [PDF](https://arxiv.org/pdf/2507.00191)  

**Abstract**: Wearable devices record physiological and behavioral signals that can improve health predictions. While foundation models are increasingly used for such predictions, they have been primarily applied to low-level sensor data, despite behavioral data often being more informative due to their alignment with physiologically relevant timescales and quantities. We develop foundation models of such behavioral signals using over 2.5B hours of wearable data from 162K individuals, systematically optimizing architectures and tokenization strategies for this unique dataset. Evaluated on 57 health-related tasks, our model shows strong performance across diverse real-world applications including individual-level classification and time-varying health state prediction. The model excels in behavior-driven tasks like sleep prediction, and improves further when combined with representations of raw sensor data. These results underscore the importance of tailoring foundation model design to wearables and demonstrate the potential to enable new health applications. 

**Abstract (ZH)**: 可穿戴设备记录生理和行为信号，以改善健康预测。尽管基础模型在这些预测中越来越受欢迎，但它们主要应用于低级传感器数据，尽管行为数据由于与生理相关的时间尺度和量纲更匹配，通常更具信息性。我们使用来自162,000名个体超过25亿小时的可穿戴数据，系统地优化了该独特数据集的架构和 tokenization 策略，评估了57项与健康相关的工作任务，我们的模型在包括个体水平分类和时变健康状态预测等多种实际应用中表现出色。该模型在睡眠预测等行为驱动任务中表现出色，并且当与原始传感器数据的表示结合时可以进一步改进。这些结果强调了针对可穿戴设备调整基础模型设计的重要性，并展示了其在推动新健康应用方面的潜力。 

---
# Designing an Adaptive Storytelling Platform to Promote Civic Education in Politically Polarized Learning Environments 

**Title (ZH)**: 设计一种适应性叙事平台，以促进政治极化学习环境中的公民教育 

**Authors**: Christopher M. Wegemer, Edward Halim, Jeff Burke  

**Link**: [PDF](https://arxiv.org/pdf/2507.00161)  

**Abstract**: Political polarization undermines democratic civic education by exacerbating identity-based resistance to opposing viewpoints. Emerging AI technologies offer new opportunities to advance interventions that reduce polarization and promote political open-mindedness. We examined novel design strategies that leverage adaptive and emotionally-responsive civic narratives that may sustain students' emotional engagement in stories, and in turn, promote perspective-taking toward members of political out-groups. Drawing on theories from political psychology and narratology, we investigate how affective computing techniques can support three storytelling mechanisms: transportation into a story world, identification with characters, and interaction with the storyteller. Using a design-based research (DBR) approach, we iteratively developed and refined an AI-mediated Digital Civic Storytelling (AI-DCS) platform. Our prototype integrates facial emotion recognition and attention tracking to assess users' affective and attentional states in real time. Narrative content is organized around pre-structured story outlines, with beat-by-beat language adaptation implemented via GPT-4, personalizing linguistic tone to sustain students' emotional engagement in stories that center political perspectives different from their own. Our work offers a foundation for AI-supported, emotionally-sensitive strategies that address affective polarization while preserving learner autonomy. We conclude with implications for civic education interventions, algorithmic literacy, and HCI challenges associated with AI dialogue management and affect-adaptive learning environments. 

**Abstract (ZH)**: 政治极化削弱了民主公民教育的效果，通过加剧基于身份的对抗观点的抵抗。新兴人工智能技术为减少极化并促进政治开明观念提供了新机会。我们研究了利用适应性和情感响应式公民叙事的新型设计策略，这些策略可能维持学生在故事中的情感参与，并进而促进对政治异见群体成员的共情。基于政治心理学和叙事学理论，我们探讨情感计算技术如何支持三种讲故事机制：进入故事世界、与角色认同以及与讲述者互动。采用设计研究（DBR）方法，我们迭代开发并精炼了一个基于人工智能的数字公民叙事平台（AI-DCS）。该原型集成了面部情绪识别和注意力追踪技术，以实时评估用户的情感和注意状态。故事内容围绕预结构化的故事情节展开，通过GPT-4逐个节拍的语言调整，个性化语言风格以维持学生对政治观点不同的故事的情感参与。我们的工作为AI支持的、情感敏感的策略提供了一个基础，这些策略能够应对情感极化同时维护学习者的自主性。我们对公民教育干预、算法素养及与AI对话管理和情感适应学习环境相关的HCI挑战进行了总结。 

---
# AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise 

**Title (ZH)**: 基于内核的深度学习AI-混合TRNG：从物理噪声近均匀熵 harvesting 的内核基于深度学习方法 

**Authors**: Hasan Yiğit  

**Link**: [PDF](https://arxiv.org/pdf/2507.00145)  

**Abstract**: AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform entropy directly from physical noise, eliminating the need for bulky quantum devices or expensive laboratory-grade RF receivers. Instead, it relies on a low-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and then emits 32-bit high-entropy streams without any quantization step.
Unlike deterministic or trained artificial intelligence random number generators (RNGs), our dynamic inner-outer network couples adaptive natural sources and reseeding, yielding truly unpredictable and autonomous sequences. Generated numbers pass the NIST SP 800-22 battery better than a CPU-based method. It also passes nineteen bespoke statistical tests for both bit- and integer-level analysis. All results satisfy cryptographic standards, while forward and backward prediction experiments reveal no exploitable biases. The model's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft cores, as well as suitable for other resource-constrained platforms.
By detaching randomness quality from dedicated hardware, AI-Hybrid TRNG broadens the reach of high-integrity random number generators across secure systems, cryptographic protocols, embedded and edge devices, stochastic simulations, and server applications that need randomness. 

**Abstract (ZH)**: AI-Hybrid TRNG是一种深度学习框架，直接从物理噪声中提取近均匀熵，无需 bulky 量子设备或昂贵的实验室射频接收器，而是依赖于低成本、拇指大小的射频前端以及CPU定时抖动进行训练，随后发出32位高熵流而无需任何量化步骤。 

---
# Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives 

**Title (ZH)**: 生成式AI时代的编程教学：文献洞察、教学建议与学生视角 

**Authors**: Clemente Rubio-Manzano, Jazna Meza, Rodolfo Fernandez-Santibanez, Christian Vidal-Castro  

**Link**: [PDF](https://arxiv.org/pdf/2507.00108)  

**Abstract**: Computer programming is undergoing a true transformation driven by powerful new tools for automatic source code generation based on large language models. This transformation is also manifesting in introductory programming courses at universities around the world, generating an in-depth debate about how programming content should be taught, learned, and assessed in the context of generative artificial intelligence.
This article aims, on the one hand, to review the most relevant studies on this issue, highlighting the advantages and disadvantages identified in the specialized literature. On the other hand, it proposes enriching teaching and learning methodologies by focusing on code comprehension and execution rather than on mere coding or program functionality. In particular, it advocates for the use of visual representations of code and visual simulations of its execution as effective tools for teaching, learning, and assessing programming, thus fostering a deeper understanding among students.
Finally, the opinions of students who took the object-oriented programming course are presented to provide preliminary context supporting the incorporation of visual simulations in Java (or other languages) as part of the training process. 

**Abstract (ZH)**: 计算机编程正经历一场由基于大规模语言模型的自动源码生成新工具驱动的真实变革。这场变革也在世界各地的大学 introductory 编程课程中显现，引发了如何在生成式人工智能的背景下教授、学习和评估编程内容的深入讨论。

本文一方面旨在回顾相关研究，突出专业化文献中指出的优势和劣势；另一方面，它提出了通过专注于代码理解与执行，而非仅仅是编码或程序功能，来丰富教学和学习方法的建议。特别是提倡使用代码的可视化表示和其执行的可视化模拟作为有效的教学、学习和评估编程的工具，从而促进学生更深入的理解。

最后，呈现了参加面向对象编程课程的学生们的意见，为在Java（或其他语言）的培训过程中引入可视化模拟提供了初步的背景支持。 

---
# Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series 

**Title (ZH)**: 面向制造过程透明且数据驱动的故障检测：基于单变量离散时间序列的案例研究 

**Authors**: Bernd Hofmann, Patrick Bruendl, Huong Giang Nguyen, Joerg Franke  

**Link**: [PDF](https://arxiv.org/pdf/2507.00102)  

**Abstract**: Ensuring consistent product quality in modern manufacturing is crucial, particularly in safety-critical applications. Conventional quality control approaches, reliant on manually defined thresholds and features, lack adaptability to the complexity and variability inherent in production data and necessitate extensive domain expertise. Conversely, data-driven methods, such as machine learning, demonstrate high detection performance but typically function as black-box models, thereby limiting their acceptance in industrial environments where interpretability is paramount. This paper introduces a methodology for industrial fault detection, which is both data-driven and transparent. The approach integrates a supervised machine learning model for multi-class fault classification, Shapley Additive Explanations for post-hoc interpretability, and a do-main-specific visualisation technique that maps model explanations to operator-interpretable features. Furthermore, the study proposes an evaluation methodology that assesses model explanations through quantitative perturbation analysis and evaluates visualisations by qualitative expert assessment. The approach was applied to the crimping process, a safety-critical joining technique, using a dataset of univariate, discrete time series. The system achieves a fault detection accuracy of 95.9 %, and both quantitative selectivity analysis and qualitative expert evaluations confirmed the relevance and inter-pretability of the generated explanations. This human-centric approach is designed to enhance trust and interpretability in data-driven fault detection, thereby contributing to applied system design in industrial quality control. 

**Abstract (ZH)**: 确保现代制造中产品质量的一致性在安全性关键应用中至关重要。传统的质量控制方法依赖于手动定义的阈值和特征，缺乏适应生产数据固有的复杂性和变异性所需的灵活性，并且需要大量的专业领域知识。相比之下，基于数据的方法，如机器学习，虽然展示出高度的检测性能，但通常作为黑盒模型运作，因此在工业环境中可解释性至上的背景下难以被接受。本文提出了一种工业故障检测方法，该方法既基于数据又是透明的。该方法结合了监督机器学习模型进行多类故障分类，Shapley 添加解释以实现事后可解释性，并使用特定于领域的可视化技术将模型解释映射到操作员可解释的特征。此外，本文还提出了一种评估方法，通过定量扰动分析评估模型解释，并通过定性的专家评估评价可视化。该方法应用于接插件压接过程，这是一种安全性关键的连接技术，使用的是单变量离散时间序列数据集。系统实现了95.9%的故障检测准确率，并且定量选择性分析和定性专家评估都证实了所生成解释的相关性和可解释性。人本中心的方法旨在增强数据驱动故障检测的信任度和可解释性，从而为工业质量控制中的应用系统设计做出贡献。 

---
# AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets 

**Title (ZH)**: 基于AI治理的智能体架构：替代资产网络可信代币化 

**Authors**: Ailiya Borjigin, Wei Zhou, Cong He  

**Link**: [PDF](https://arxiv.org/pdf/2507.00096)  

**Abstract**: Alternative Assets tokenization is transforming non-traditional financial instruments are represented and traded on the web. However, ensuring trustworthiness in web-based tokenized ecosystems poses significant challenges, from verifying off-chain asset data to enforcing regulatory compliance. This paper proposes an AI-governed agent architecture that integrates intelligent agents with blockchain to achieve web-trustworthy tokenization of alternative assets. In the proposed architecture, autonomous agents orchestrate the tokenization process (asset verification, valuation, compliance checking, and lifecycle management), while an AI-driven governance layer monitors agent behavior and enforces trust through adaptive policies and cryptoeconomic incentives. We demonstrate that this approach enhances transparency, security, and compliance in asset tokenization, addressing key concerns around data authenticity and fraud. A case study on tokenizing real estate assets illustrates how the architecture mitigates risks (e.g., fraudulent listings and money laundering) through real-time AI anomaly detection and on-chain enforcement. Our evaluation and analysis suggest that combining AI governance with multi-agent systems and blockchain can significantly bolster trust in tokenized asset ecosystems. This work offers a novel framework for trustworthy asset tokenization on the web and provides insights for practitioners aiming to deploy secure, compliant tokenization platforms. 

**Abstract (ZH)**: 基于AI治理的自治代理架构在web环境中实现替代资产可信代币化 

---
# Efficient Conformance Checking of Rich Data-Aware Declare Specifications (Extended) 

**Title (ZH)**: 丰富数据感知的Declare规范高效符合性检查（扩展版） 

**Authors**: Jacobo Casas-Ramos, Sarah Winkler, Alessandro Gianola, Marco Montali, Manuel Mucientes, Manuel Lama  

**Link**: [PDF](https://arxiv.org/pdf/2507.00094)  

**Abstract**: Despite growing interest in process analysis and mining for data-aware specifications, alignment-based conformance checking for declarative process models has focused on pure control-flow specifications, or mild data-aware extensions limited to numerical data and variable-to-constant comparisons. This is not surprising: finding alignments is computationally hard, even more so in the presence of data dependencies. In this paper, we challenge this problem in the case where the reference model is captured using data-aware Declare with general data types and data conditions. We show that, unexpectedly, it is possible to compute data-aware optimal alignments in this rich setting, enjoying at once efficiency and expressiveness. This is achieved by carefully combining the two best-known approaches to deal with control flow and data dependencies when computing alignments, namely A* search and SMT solving. Specifically, we introduce a novel algorithmic technique that efficiently explores the search space, generating descendant states through the application of repair actions aiming at incrementally resolving constraint violations. We prove the correctness of our algorithm and experimentally show its efficiency. The evaluation witnesses that our approach matches or surpasses the performance of the state of the art while also supporting significantly more expressive data dependencies, showcasing its potential to support real-world applications. 

**Abstract (ZH)**: 尽管对数据感知规范的兴趣日益增长，基于对齐的符合性检查主要集中在纯控流规范或有限的数据感知扩展（限定为数值数据和变量到常量的比较）。在参考模型使用通用数据类型和数据条件描述的Declarative过程模型中，我们面临着这一挑战。我们展示了，在这种丰富的情境下，能够同时实现高效性和表达性的数据感知最优对齐是可以计算出来的。这通过仔细结合计算对齐时处理控制流和数据依赖性的两种最知名方法——A*搜索和SMT求解——来实现。具体地，我们引入了一种新颖的算法技术，有效探索搜索空间，通过应用修复动作逐步解决约束冲突来生成后代状态。我们证明了算法的正确性，并通过实验展示了其效率。评估表明，我们的方法在性能上与当前最先进的方法相当或更优，同时支持更加丰富的数据依赖关系，展示了其支持实际应用的潜力。 

---
# $σ$-Maximal Ancestral Graphs 

**Title (ZH)**: σ-极大祖先图 

**Authors**: Binghua Yao, Joris M. Mooij  

**Link**: [PDF](https://arxiv.org/pdf/2507.00093)  

**Abstract**: Maximal Ancestral Graphs (MAGs) provide an abstract representation of Directed Acyclic Graphs (DAGs) with latent (selection) variables. These graphical objects encode information about ancestral relations and d-separations of the DAGs they represent. This abstract representation has been used amongst others to prove the soundness and completeness of the FCI algorithm for causal discovery, and to derive a do-calculus for its output. One significant inherent limitation of MAGs is that they rule out the possibility of cyclic causal relationships. In this work, we address that limitation. We introduce and study a class of graphical objects that we coin ''$\sigma$-Maximal Ancestral Graphs'' (''$\sigma$-MAGs''). We show how these graphs provide an abstract representation of (possibly cyclic) Directed Graphs (DGs) with latent (selection) variables, analogously to how MAGs represent DAGs. We study the properties of these objects and provide a characterization of their Markov equivalence classes. 

**Abstract (ZH)**: σ-最大祖先图（$\sigma$-MAGs）提供了带潜在（选择）变量的（可能循环的）有向图（DGs）的抽象表示。 

---
# Generating Heterogeneous Multi-dimensional Data : A Comparative Study 

**Title (ZH)**: 生成异构多维度数据：一种比较研究 

**Authors**: Corbeau Michael, Claeys Emmanuelle, Serrurier Mathieu, Zaraté Pascale  

**Link**: [PDF](https://arxiv.org/pdf/2507.00090)  

**Abstract**: Allocation of personnel and material resources is highly sensible in the case of firefighter interventions. This allocation relies on simulations to experiment with various scenarios. The main objective of this allocation is the global optimization of the firefighters response. Data generation is then mandatory to study various scenarios In this study, we propose to compare different data generation methods. Methods such as Random Sampling, Tabular Variational Autoencoders, standard Generative Adversarial Networks, Conditional Tabular Generative Adversarial Networks and Diffusion Probabilistic Models are examined to ascertain their efficacy in capturing the intricacies of firefighter interventions. Traditional evaluation metrics often fall short in capturing the nuanced requirements of synthetic datasets for real-world scenarios. To address this gap, an evaluation of synthetic data quality is conducted using a combination of domain-specific metrics tailored to the firefighting domain and standard measures such as the Wasserstein distance. Domain-specific metrics include response time distribution, spatial-temporal distribution of interventions, and accidents representation. These metrics are designed to assess data variability, the preservation of fine and complex correlations and anomalies such as event with a very low occurrence, the conformity with the initial statistical distribution and the operational relevance of the synthetic data. The distribution has the particularity of being highly unbalanced, none of the variables following a Gaussian distribution, adding complexity to the data generation process. 

**Abstract (ZH)**: 消防员干预中人员和物资资源分配的高度敏感性依赖于模拟来实验各种场景。此分配的主要目标是优化消防员响应的全局效果。因此，数据生成是必需的，以研究各种场景。在本研究中，我们提出比较不同的数据生成方法。这些方法包括随机采样、表格变分自编码器、标准生成对抗网络、条件表格生成对抗网络和扩散概率模型，以确定它们在捕捉消防员干预复杂性的有效性。传统的评估指标往往在捕捉合成数据集在现实场景中的细微需求时存在局限性。因此，我们使用针对消防领域特定领域的度量标准与标准度量（如Wasserstein距离）相结合的方式评估合成数据的质量。特定领域的度量标准包括响应时间分布、干预的空间时间分布和事故表示。这些指标旨在评估数据的变化性，保持细粒度和复杂的相关性和异常值（如低发生率事件）的一致性、统计分布的符合性和合成数据的操作相关性。数据分布的特性是高度不平衡的，没有一个变量遵循正态分布，这增加了数据生成的复杂性。 

---
# pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation 

**Title (ZH)**: pUniFind: 统一的大规模预训练深度学习模型pushing极限质谱解析 

**Authors**: Jiale Zhao, Pengzhi Mao, Kaifei Wang, Yiming Li, Yaping Peng, Ranfei Chen, Shuqi Lu, Xiaohong Ji, Jiaxiang Ding, Xin Zhang, Yucheng Liao, Weinan E, Weijie Zhang, Han Wen, Hao Chi  

**Link**: [PDF](https://arxiv.org/pdf/2507.00087)  

**Abstract**: Deep learning has advanced mass spectrometry data interpretation, yet most models remain feature extractors rather than unified scoring frameworks. We present pUniFind, the first large-scale multimodal pre-trained model in proteomics that integrates end-to-end peptide-spectrum scoring with open, zero-shot de novo sequencing. Trained on over 100 million open search-derived spectra, pUniFind aligns spectral and peptide modalities via cross modality prediction and outperforms traditional engines across diverse datasets, particularly achieving a 42.6 percent increase in the number of identified peptides in immunopeptidomics. Supporting over 1,300 modifications, pUniFind identifies 60 percent more PSMs than existing de novo methods despite a 300-fold larger search space. A deep learning based quality control module further recovers 38.5 percent additional peptides including 1,891 mapped to the genome but absent from reference proteomes while preserving full fragment ion coverage. These results establish a unified, scalable deep learning framework for proteomic analysis, offering improved sensitivity, modification coverage, and interpretability. 

**Abstract (ZH)**: 深度学习推动了质谱数据解释的进步，但大多数模型仍然是特征提取器而非统一评分框架。我们介绍了pUniFind，这是一种首次应用于蛋白质组学的大型多模态预训练模型，集成了从头测序和肽-谱评分的端到端评分框架。通过跨模态预测，pUniFind在多种数据集中表现优于传统引擎，特别是在免疫肽组学数据集中肽的识别数量提高了42.6%。尽管搜索空间扩大了300倍，pUniFind仍能识别比现有从头测序方法多60%的PSMs，并支持1300多种修饰。基于深度学习的质量控制模块进一步恢复了38.5%的肽，其中包括1891个归蕴基因但不在参考蛋白质组中的肽，同时保留了完整的片段离子覆盖。这些结果建立了一个统一且可扩展的深度学习框架，为蛋白质组分析提供了更高的灵敏度、修饰覆盖和解释性。 

---
# A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism 

**Title (ZH)**: 一种集成拓扑与数据融合的图网络模型：具有数据异常检测的稳健交通速度预测 

**Authors**: Ruiyuan Jiang, Dongyao Jia, Eng Gee Lim, Pengfei Fan, Yuli Zhang, Shangbo Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00085)  

**Abstract**: Accurate traffic prediction is essential for Intelligent Transportation Systems (ITS), yet current methods struggle with the inherent complexity and non-linearity of traffic dynamics, making it difficult to integrate spatial and temporal characteristics. Furthermore, existing approaches use static techniques to address non-stationary and anomalous historical data, which limits adaptability and undermines data smoothing. To overcome these challenges, we propose the Graph Fusion Enhanced Network (GFEN), an innovative framework for network-level traffic speed prediction. GFEN introduces a novel topological spatiotemporal graph fusion technique that meticulously extracts and merges spatial and temporal correlations from both data distribution and network topology using trainable methods, enabling the modeling of multi-scale spatiotemporal features. Additionally, GFEN employs a hybrid methodology combining a k-th order difference-based mathematical framework with an attention-based deep learning structure to adaptively smooth historical observations and dynamically mitigate data anomalies and non-stationarity. Extensive experiments demonstrate that GFEN surpasses state-of-the-art methods by approximately 6.3% in prediction accuracy and exhibits convergence rates nearly twice as fast as recent hybrid models, confirming its superior performance and potential to significantly enhance traffic prediction system efficiency. 

**Abstract (ZH)**: 基于图融合增强网络的网络级交通速度预测 

---
# Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks 

**Title (ZH)**: 基于干预 Awareness 联合空域因果图网络的深目标空袭系统战略反事实建模 

**Authors**: Wei Meng  

**Link**: [PDF](https://arxiv.org/pdf/2507.00083)  

**Abstract**: This study addresses the lack of structured causal modeling between tactical strike behavior and strategic delay in current strategic-level simulations, particularly the structural bottlenecks in capturing intermediate variables within the "resilience - nodal suppression - negotiation window" chain. We propose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN), a novel framework that closes the causal loop from tactical input to strategic delay output. The model integrates graph attention mechanisms, counterfactual simulation units, and spatial intervention node reconstruction to enable dynamic simulations of strike configurations and synchronization strategies. Training data are generated from a multi-physics simulation platform (GEANT4 + COMSOL) under NIST SP 800-160 standards, ensuring structural traceability and policy-level validation. Experimental results demonstrate that IA-STGNN significantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost), achieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5 percent accuracy, while improving causal path consistency and intervention stability. IA-STGNN enables interpretable prediction of strategic delay and supports applications such as nuclear deterrence simulation, diplomatic window assessment, and multi-strategy optimization, providing a structured and transparent AI decision-support mechanism for high-level policy modeling. 

**Abstract (ZH)**: 基于干预感知时空图神经网络的战略打击行为与战略延期之间的结构化因果建模 

---
# InSight-R: A Framework for Risk-informed Human Failure Event Identification and Interface-Induced Risk Assessment Driven by AutoGraph 

**Title (ZH)**: 基于AutoGraph的风险导向人类失效事件识别和接口诱发风险评估框架：InSight-R 

**Authors**: Xingyu Xiao, Jiejuan Tong, Peng Chen, Jun Sun, Zhe Sui, Jingang Liang, Hongru Zhao, Jun Zhao, Haitao Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00066)  

**Abstract**: Human reliability remains a critical concern in safety-critical domains such as nuclear power, where operational failures are often linked to human error. While conventional human reliability analysis (HRA) methods have been widely adopted, they rely heavily on expert judgment for identifying human failure events (HFEs) and assigning performance influencing factors (PIFs). This reliance introduces challenges related to reproducibility, subjectivity, and limited integration of interface-level data. In particular, current approaches lack the capacity to rigorously assess how human-machine interface design contributes to operator performance variability and error susceptibility. To address these limitations, this study proposes a framework for risk-informed human failure event identification and interface-induced risk assessment driven by AutoGraph (InSight-R). By linking empirical behavioral data to the interface-embedded knowledge graph (IE-KG) constructed by the automated graph-based execution framework (AutoGraph), the InSight-R framework enables automated HFE identification based on both error-prone and time-deviated operational paths. Furthermore, we discuss the relationship between designer-user conflicts and human error. The results demonstrate that InSight-R not only enhances the objectivity and interpretability of HFE identification but also provides a scalable pathway toward dynamic, real-time human reliability assessment in digitalized control environments. This framework offers actionable insights for interface design optimization and contributes to the advancement of mechanism-driven HRA methodologies. 

**Abstract (ZH)**: 人因可靠性仍然是核能等安全关键领域中的一个关键关切，操作故障往往与人为错误相关联。尽管传统的人因可靠性分析（HRA）方法已被广泛应用，但它们高度依赖专家判断来识别人为失败事件（HFEs）和分配绩效影响因素（PIFs）。这种依赖性引入了可重复性、主观性和接口级数据整合有限的挑战。特别是，当前方法缺乏评估人机界面设计如何影响操作员绩效变异性和错误易感性的能力。为了解决这些限制，本研究提出了一种基于AutoGraph（InSight-R）的基于风险的人因失败事件识别和接口诱发风险评估框架。通过将行为数据与通过自动图基执行框架（AutoGraph）构建的接口嵌入知识图（IE-KG）相结合，InSight-R框架能够基于易出错和时间偏离的操作路径自动识别HFE。此外，我们讨论了设计者和用户之间的冲突与人为错误之间的关系。结果表明，InSight-R不仅增强了HFE识别的客观性和可解释性，还提供了一种可扩展的途径，以实现数字化控制环境中的动态、实时的人因可靠性评估。该框架提供了针对界面设计优化的可操作见解，并促进了机制驱动的HRA方法论的进步。 

---
# Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data 

**Title (ZH)**: Smooth-Distill：一种用于穿戴传感器数据多任务学习的自蒸馏框架 

**Authors**: Hoang-Dieu Vu, Duc-Nghia Tran, Quang-Tu Pham, Hieu H. Pham, Nicolas Vuillerme, Duc-Tan Tran  

**Link**: [PDF](https://arxiv.org/pdf/2507.00061)  

**Abstract**: This paper introduces Smooth-Distill, a novel self-distillation framework designed to simultaneously perform human activity recognition (HAR) and sensor placement detection using wearable sensor data. The proposed approach utilizes a unified CNN-based architecture, MTL-net, which processes accelerometer data and branches into two outputs for each respective task. Unlike conventional distillation methods that require separate teacher and student models, the proposed framework utilizes a smoothed, historical version of the model itself as the teacher, significantly reducing training computational overhead while maintaining performance benefits. To support this research, we developed a comprehensive accelerometer-based dataset capturing 12 distinct sleep postures across three different wearing positions, complementing two existing public datasets (MHealth and WISDM). Experimental results show that Smooth-Distill consistently outperforms alternative approaches across different evaluation scenarios, achieving notable improvements in both human activity recognition and device placement detection tasks. This method demonstrates enhanced stability in convergence patterns during training and exhibits reduced overfitting compared to traditional multitask learning baselines. This framework contributes to the practical implementation of knowledge distillation in human activity recognition systems, offering an effective solution for multitask learning with accelerometer data that balances accuracy and training efficiency. More broadly, it reduces the computational cost of model training, which is critical for scenarios requiring frequent model updates or training on resource-constrained platforms. The code and model are available at this https URL\_distill. 

**Abstract (ZH)**: Smooth-Distill: 一种同时进行人体活动识别和传感器位置检测的新型自蒸馏框架 

---
# VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models 

**Title (ZH)**: 医疗视觉-语言模型的脆弱性评分框架(VSF-Med) 

**Authors**: Binesh Sadanandan, Vahid Behzadan  

**Link**: [PDF](https://arxiv.org/pdf/2507.00052)  

**Abstract**: Vision Language Models (VLMs) hold great promise for streamlining labour-intensive medical imaging workflows, yet systematic security evaluations in clinical settings remain scarce. We introduce VSF--Med, an end-to-end vulnerability-scoring framework for medical VLMs that unites three novel components: (i) a rich library of sophisticated text-prompt attack templates targeting emerging threat vectors; (ii) imperceptible visual perturbations calibrated by structural similarity (SSIM) thresholds to preserve clinical realism; and (iii) an eight-dimensional rubric evaluated by two independent judge LLMs, whose raw scores are consolidated via z-score normalization to yield a 0--32 composite risk metric. Built entirely on publicly available datasets and accompanied by open-source code, VSF--Med synthesizes over 30,000 adversarial variants from 5,000 radiology images and enables reproducible benchmarking of any medical VLM with a single command. Our consolidated analysis reports mean z-score shifts of $0.90\sigma$ for persistence-of-attack-effects, $0.74\sigma$ for prompt-injection effectiveness, and $0.63\sigma$ for safety-bypass success across state-of-the-art VLMs. Notably, Llama-3.2-11B-Vision-Instruct exhibits a peak vulnerability increase of $1.29\sigma$ for persistence-of-attack-effects, while GPT-4o shows increases of $0.69\sigma$ for that same vector and $0.28\sigma$ for prompt-injection attacks. 

**Abstract (ZH)**: 基于视觉语言模型的医疗领域漏洞评分框架：VSF--Med 

---
# HistoART: Histopathology Artifact Detection and Reporting Tool 

**Title (ZH)**: HistoART: 组织病理学 artefact 检测与报告工具 

**Authors**: Seyed Kahaki, Alexander R. Webber, Ghada Zamzmi, Adarsh Subbaswamy, Rucha Deshpande, Aldo Badano  

**Link**: [PDF](https://arxiv.org/pdf/2507.00044)  

**Abstract**: In modern cancer diagnostics, Whole Slide Imaging (WSI) is widely used to digitize tissue specimens for detailed, high-resolution examination; however, other diagnostic approaches, such as liquid biopsy and molecular testing, are also utilized based on the cancer type and clinical context. While WSI has revolutionized digital histopathology by enabling automated, precise analysis, it remains vulnerable to artifacts introduced during slide preparation and scanning. These artifacts can compromise downstream image analysis. To address this challenge, we propose and compare three robust artifact detection approaches for WSIs: (1) a foundation model-based approach (FMA) using a fine-tuned Unified Neural Image (UNI) architecture, (2) a deep learning approach (DLA) built on a ResNet50 backbone, and (3) a knowledge-based approach (KBA) leveraging handcrafted features from texture, color, and frequency-based metrics. The methods target six common artifact types: tissue folds, out-of-focus regions, air bubbles, tissue damage, marker traces, and blood contamination. Evaluations were conducted on 50,000+ image patches from diverse scanners (Hamamatsu, Philips, Leica Aperio AT2) across multiple sites. The FMA achieved the highest patch-wise AUROC of 0.995 (95% CI [0.994, 0.995]), outperforming the ResNet50-based method (AUROC: 0.977, 95% CI [0.977, 0.978]) and the KBA (AUROC: 0.940, 95% CI [0.933, 0.946]). To translate detection into actionable insights, we developed a quality report scorecard that quantifies high-quality patches and visualizes artifact distributions. 

**Abstract (ZH)**: 现代癌症诊断中，全视野成像（WSI）广泛用于数字化组织样本以进行详细高分辨率检查；然而，基于癌症类型和临床背景，也常采用液体活检和分子检测等其他诊断方法。虽然WSI通过实现自动化精确分析革命了数字病理科，但仍然容易受到制片和扫描过程中引入的伪影影响，这些伪影可能会干扰后续图像分析。为应对这一挑战，我们提出并对比了三种稳健的WSI伪影检测方法：（1）基于基础模型的方法（FMA）使用微调过的统一神经图像（UNI）架构，（2）基于深度学习的方法（DLA）以ResNet50为骨干网络，（3）基于知识的方法（KBA）利用来自纹理、颜色和频率特征的手工设计特征。这些方法针对六种常见的伪影类型：组织褶皱、焦外区域、气泡、组织损伤、标记痕迹和血液污染。评估在来自不同扫描仪（Hamamatsu、Philips、Leica Aperio AT2）的多个站点的超过50,000个图像块上进行。FMA在块级别的AUROC达到0.995（95% CI [0.994, 0.995]），优于ResNet50基方法（AUROC: 0.977, 95% CI [0.977, 0.978]）和KBA（AUROC: 0.940, 95% CI [0.933, 0.946]）。为了将检测转化为 actionable 洞察，我们开发了一个质量报告评分卡，量化高质量图像块并可视化伪影分布。 

---
# MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations 

**Title (ZH)**: MR-CLIP: 效率导向的 metadata 引导的 MRI 对比度表示学习 

**Authors**: Mehmet Yigit Avci, Pedro Borges, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso  

**Link**: [PDF](https://arxiv.org/pdf/2507.00043)  

**Abstract**: Accurate interpretation of Magnetic Resonance Imaging scans in clinical systems is based on a precise understanding of image contrast. This contrast is primarily governed by acquisition parameters, such as echo time and repetition time, which are stored in the DICOM metadata. To simplify contrast identification, broad labels such as T1-weighted or T2-weighted are commonly used, but these offer only a coarse approximation of the underlying acquisition settings. In many real-world datasets, such labels are entirely missing, leaving raw acquisition parameters as the only indicators of contrast. Adding to this challenge, the available metadata is often incomplete, noisy, or inconsistent. The lack of reliable and standardized metadata complicates tasks such as image interpretation, retrieval, and integration into clinical workflows. Furthermore, robust contrast-aware representations are essential to enable more advanced clinical applications, such as achieving modality-invariant representations and data harmonization. To address these challenges, we propose MR-CLIP, a multimodal contrastive learning framework that aligns MR images with their DICOM metadata to learn contrast-aware representations, without relying on manual labels. Trained on a diverse clinical dataset that spans various scanners and protocols, MR-CLIP captures contrast variations across acquisitions and within scans, enabling anatomy-invariant representations. We demonstrate its effectiveness in cross-modal retrieval and contrast classification, highlighting its scalability and potential for further clinical applications. The code and weights are publicly available at this https URL. 

**Abstract (ZH)**: 精确解析临床系统中的磁共振成像扫描需要对图像对比度有精准的理解。这一对比度主要由采集参数（如回波时间及重复时间）控制，这些参数存储在DICOM元数据中。为了简化对比度识别，通常使用如T1加权或T2加权等宽泛标签，但这些标签仅提供了一种粗略的采集设置近似值。在许多实际数据集中，这些标签可能完全缺失，使原始采集参数成为唯一能反映对比度的指标。此外，可用的元数据往往不完备、噪声大或不一致。缺乏可靠的标准化元数据使得图像解析、检索及整合到临床工作流程中任务复杂化。进一步而言，具备对比度感知的稳健表示对于实现模态不变表示和数据规范化等更高级的临床应用至关重要。为应对这些挑战，我们提出MR-CLIP，这是一种多模态对比学习框架，能够通过与DICOM元数据对齐MRI图像来学习对比度感知表示，无需依赖手动标签。MR-CLIP在涵盖多种扫描器和协议的多样临床数据集上进行训练，能够捕捉不同采集间的对比度变化，并在扫描内部捕捉对比度变化，实现解剖结构不变的表示。我们展示了MR-CLIP在跨模态检索和对比度分类中的有效性，突显其可扩展性及其在进一步临床应用中的潜力。相关代码和权重可在以下网址公开获取：this https URL。 

---
# Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay 

**Title (ZH)**: 通过差异加权经验重播减轻灾难性遗忘 

**Authors**: Xinrun Xu, Jianwen Yang, Qiuhong Zhang, Zhanbiao Lian, Zhiming Ding, Shan Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00042)  

**Abstract**: Continually adapting edge models in cloud-edge collaborative object detection for traffic monitoring suffers from catastrophic forgetting, where models lose previously learned knowledge when adapting to new data distributions. This is especially problematic in dynamic traffic environments characterised by periodic variations (e.g., day/night, peak hours), where past knowledge remains valuable. Existing approaches like experience replay and visual prompts offer some mitigation, but struggle to effectively prioritize and leverage historical data for optimal knowledge retention and adaptation. Specifically, simply storing and replaying all historical data can be inefficient, while treating all historical experiences as equally important overlooks their varying relevance to the current domain. This paper proposes ER-EMU, an edge model update algorithm based on adaptive experience replay, to address these limitations. ER-EMU utilizes a limited-size experience buffer managed using a First-In-First-Out (FIFO) principle, and a novel Domain Distance Metric-based Experience Selection (DDM-ES) algorithm. DDM-ES employs the multi-kernel maximum mean discrepancy (MK-MMD) to quantify the dissimilarity between target domains, prioritizing the selection of historical data that is most dissimilar to the current target domain. This ensures training diversity and facilitates the retention of knowledge from a wider range of past experiences, while also preventing overfitting to the new domain. The experience buffer is also updated using a simple random sampling strategy to maintain a balanced representation of previous domains. Experiments on the Bellevue traffic video dataset, involving repeated day/night cycles, demonstrate that ER-EMU consistently improves the performance of several state-of-the-art cloud-edge collaborative object detection frameworks. 

**Abstract (ZH)**: 基于自适应经验回放的边缘模型更新算法ER-EMU在云边协同交通监控目标检测中的持续适应 

---
# Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing 

**Title (ZH)**: 基于模式的图分类：质量度量的比较与预处理的重要性 

**Authors**: Lucas Potin, Rosa Figueiredo, Vincent Labatut, Christine Largeron  

**Link**: [PDF](https://arxiv.org/pdf/2507.00039)  

**Abstract**: Graph classification aims to categorize graphs based on their structural and attribute features, with applications in diverse fields such as social network analysis and bioinformatics. Among the methods proposed to solve this task, those relying on patterns (i.e. subgraphs) provide good explainability, as the patterns used for classification can be directly interpreted. To identify meaningful patterns, a standard approach is to use a quality measure, i.e. a function that evaluates the discriminative power of each pattern. However, the literature provides tens of such measures, making it difficult to select the most appropriate for a given application. Only a handful of surveys try to provide some insight by comparing these measures, and none of them specifically focuses on graphs. This typically results in the systematic use of the most widespread measures, without thorough evaluation. To address this issue, we present a comparative analysis of 38 quality measures from the literature. We characterize them theoretically, based on four mathematical properties. We leverage publicly available datasets to constitute a benchmark, and propose a method to elaborate a gold standard ranking of the patterns. We exploit these resources to perform an empirical comparison of the measures, both in terms of pattern ranking and classification performance. Moreover, we propose a clustering-based preprocessing step, which groups patterns appearing in the same graphs to enhance classification performance. Our experimental results demonstrate the effectiveness of this step, reducing the number of patterns to be processed while achieving comparable performance. Additionally, we show that some popular measures widely used in the literature are not associated with the best results. 

**Abstract (ZH)**: 图分类旨在根据图的结构和属性特征对其进行分类，应用于社会网络分析、生物informatics等多个领域。为了解决这一任务，依赖模式（即子图）的方法提供了良好的可解释性，因为用于分类的模式可以直接进行解释。为了识别有意义的模式，标准做法是使用质量度量，即评估每个模式的区分能力的函数。然而，文献中提供了几十种这样的度量，使得选择最适合特定应用的度量变得困难。只有少数综述试图通过比较这些度量来提供一些见解，但它们均未特别关注图。这通常导致系统地使用最流行的度量，而没有进行彻底的评估。为解决这一问题，我们对文献中提出的38种质量度量进行了比较分析。基于四种数学性质对其进行了理论特征化。利用公开可用的数据集构成基准，并提出了一种方法来制定模式的黄金标准排名。我们利用这些资源从模式排名和分类性能两方面对这些度量进行了实证比较。此外，我们提出了一个基于聚类的预处理步骤，该步骤将同一图中出现的模式分组，以提高分类性能。实验结果表明，该步骤的有效性，减少了需要处理的模式数量，同时保持了类似的表现力。另外，我们还表明，文献中广泛使用的某些流行度量并不总是与最佳结果相关。 

---
# Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information 

**Title (ZH)**: 质胜于量：一种基于点ewise V-信息的大规模数据缩减有效策略 

**Authors**: Fei Chen, Wenchi Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2507.00038)  

**Abstract**: Data reduction plays a vital role in data-centric AI by identifying the most informative instance within large-scale datasets to enhance model training efficiency. The core challenge lies in how to select the optimal instances-rather than the entire datasets-to improve data quality and training efficiency. In this paper, we propose an effective data reduction strategy based on Pointwise V-information(PVI). First, we quantify instance difficulty using PVI and filter out low-difficulty instances enabling a static approach. Experiments demonstrate that removing 10%-30% of the data preserves the classifier performance with only a 0.0001% to 0.76% loss in this http URL, we use a progressive learning approach to training the classifiers on instances sorted by ascending PVI, accelerating convergence and achieving a 0.8% accuracy gain over conventional training. Our results suggest that with the effective data reduction strategy, training a classifier on the selected optimal subset could enhance the model performance and boost training efficiency. Moreover, we have transferred the PVI framework, which previously applied only to English datasets, to diverse Chinese NLP tasks and base models, leading to valuable insights for cross-lingual data reduction and faster training. The codes are released at this https URL. 

**Abstract (ZH)**: 数据约简在以数据为中心的人工智能中的重要作用在于通过识别大规模数据集中的最有信息性实例来提升模型训练效率。核心挑战在于如何选择最优实例而非整个数据集，以提升数据质量和训练效率。在本文中，我们提出了一种基于点维V-信息（PVI）的有效数据约简策略。首先，我们使用PVI量化实例难度并过滤掉低难度实例，采用静态方法。实验结果显示，移除10%-30%的数据，在本httpUrl上仅损失0.0001%至0.76%的分类器性能。在本httpUrl中，我们采用渐进学习方法，在按升序PVI排列的实例上训练分类器，加速收敛并比传统训练提升0.8%的准确率。我们的结果表明，通过有效的数据约简策略，在选定的最优子集上训练分类器能够提升模型性能并增强训练效率。此外，我们将仅应用于英文数据集的PVI框架扩展到多种中文NLP任务和基模型，为跨语言数据约简和更快的训练提供了宝贵见解。相关代码发布于本httpsUrl。 

---
# Model Fusion via Neuron Interpolation 

**Title (ZH)**: 神经元插值驱动的模型融合 

**Authors**: Phoomraphee Luenam, Andreas Spanopoulos, Amit Sant, Thomas Hofmann, Sotiris Anagnostidis, Sidak Pal Singh  

**Link**: [PDF](https://arxiv.org/pdf/2507.00037)  

**Abstract**: Model fusion aims to combine the knowledge of multiple models by creating one representative model that captures the strengths of all of its parents. However, this process is non-trivial due to differences in internal representations, which can stem from permutation invariance, random initialization, or differently distributed training data. We present a novel, neuron-centric family of model fusion algorithms designed to integrate multiple trained neural networks into a single network effectively regardless of training data distribution. Our algorithms group intermediate neurons of parent models to create target representations that the fused model approximates with its corresponding sub-network. Unlike prior approaches, our approach incorporates neuron attribution scores into the fusion process. Furthermore, our algorithms can generalize to arbitrary layer types. Experimental results on various benchmark datasets demonstrate that our algorithms consistently outperform previous fusion techniques, particularly in zero-shot and non-IID fusion scenarios. The code is available at this https URL. 

**Abstract (ZH)**: 模型融合旨在通过创建一个代表模型来整合多个模型的知识，该模型能够捕捉所有父模型的优点。然而，这一过程由于内部表示的差异性而不 trivial，这种差异可能源自置换不变性、随机初始化或训练数据分布的不同。我们提出了一种以神经元为中心的新型模型融合算法家族，能够在不同训练数据分布的情况下有效整合多个训练好的神经网络。我们的算法通过将父模型的中间神经元分组来创建目标表示，融合模型通过其相应的子网络对其进行近似。与先前的方法不同，我们的方法将神经元归属得分纳入了融合过程。此外，我们的算法可以泛化到任意层类型。在各种基准数据集上的实验结果表明，我们的算法在零样本和非IID融合场景中始终优于之前的融合技术。代码可在以下链接获取：this https URL。 

---
# Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing 

**Title (ZH)**: Ken 利用层：学生 ken 内的基于 Hebbian 的回放以实现自适应知识追踪 

**Authors**: Grey Kuling, Marinka Zitnik  

**Link**: [PDF](https://arxiv.org/pdf/2507.00032)  

**Abstract**: We introduce KUL-KT, a biologically inspired architecture for knowledge tracing (KT), combining Hebbian memory encoding with gradient-based consolidation in a scalable, input-agnostic framework. KUL-KT adapts the principle of memory consolidation in neural systems, to student modeling by introducing two key innovations: (i) a time-decaying Hebbian memory update that enables graceful forgetting, and (ii) a novel Loss-aligned Internal Target (LIT) method to compute an ideal internal state, allowing continual learning without backpropagation through time. The architecture consists of a fast Hebbian memory that captures each learner interaction via a single associative update, and a slower linear network that consolidates recalled samples through gradient descent. This design enables few-shot personalization and natural forgetting without storing raw data or relying on large cohort training. Operating entirely in embedding space, KUL-KT supports both structured (tabular) and unstructured (short-answer) inputs. Empirically, KUL-KT outperforms strong baselines on ten public KT benchmarks in rank-sensitive metrics such as nDCG and Recall@10. In a classroom deployment, KUL-KT personalized quizzes from short-answer data, leading to improved learner-perceived helpfulness and reduced difficulty (p < 0.05). Ablation studies confirm that Hebbian decay and LIT are critical for continual adaptation. Compared to a strong graph-based KT model, KUL-KT trains 1.75x faster and uses 99.01\% less memory. These results position KUL-KT as a biologically grounded, memory-efficient, and input-flexible framework for personalized learning at scale. 

**Abstract (ZH)**: KUL-KT：一种生物启发的知识追踪架构 

---
# HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation 

**Title (ZH)**: HiT-JEPA：一种层次化的自监督轨迹嵌入框架用于相似性计算 

**Authors**: Lihuan Li, Hao Xue, Shuang Ao, Yang Song, Flora Salim  

**Link**: [PDF](https://arxiv.org/pdf/2507.00028)  

**Abstract**: The representation of urban trajectory data plays a critical role in effectively analyzing spatial movement patterns. Despite considerable progress, the challenge of designing trajectory representations that can capture diverse and complementary information remains an open research problem. Existing methods struggle in incorporating trajectory fine-grained details and high-level summary in a single model, limiting their ability to attend to both long-term dependencies while preserving local nuances. To address this, we propose HiT-JEPA (Hierarchical Interactions of Trajectory Semantics via a Joint Embedding Predictive Architecture), a unified framework for learning multi-scale urban trajectory representations across semantic abstraction levels. HiT-JEPA adopts a three-layer hierarchy that progressively captures point-level fine-grained details, intermediate patterns, and high-level trajectory abstractions, enabling the model to integrate both local dynamics and global semantics in one coherent structure. Extensive experiments on multiple real-world datasets for trajectory similarity computation show that HiT-JEPA's hierarchical design yields richer, multi-scale representations. Code is available at: this https URL. 

**Abstract (ZH)**: 基于联合嵌入预测架构的层级轨迹语义交互（HiT-JEPA）：面向多尺度城市轨迹表示的统一框架 

---
# Generalizing to New Dynamical Systems via Frequency Domain Adaptation 

**Title (ZH)**: 基于频域适应性将模型应用于新的动力学系统 

**Authors**: Tiexin Qin, Hong Yan, Haoliang Li  

**Link**: [PDF](https://arxiv.org/pdf/2507.00025)  

**Abstract**: Learning the underlying dynamics from data with deep neural networks has shown remarkable potential in modeling various complex physical dynamics. However, current approaches are constrained in their ability to make reliable predictions in a specific domain and struggle with generalizing to unseen systems that are governed by the same general dynamics but differ in environmental characteristics. In this work, we formulate a parameter-efficient method, Fourier Neural Simulator for Dynamical Adaptation (FNSDA), that can readily generalize to new dynamics via adaptation in the Fourier space. Specifically, FNSDA identifies the shareable dynamics based on the known environments using an automatic partition in Fourier modes and learns to adjust the modes specific for each new environment by conditioning on low-dimensional latent systematic parameters for efficient generalization. We evaluate our approach on four representative families of dynamic systems, and the results show that FNSDA can achieve superior or competitive generalization performance compared to existing methods with a significantly reduced parameter cost. Our code is available at this https URL. 

**Abstract (ZH)**: 利用深度神经网络从数据中学习基本动力学在建模各种复杂物理动力学方面展现了显著潜力。然而，当前的方法在特定领域内进行可靠预测的能力有限，并且在泛化到受相同一般动力学规则支配但环境特性不同的未见系统时表现出困难。在本文中，我们提出了一种参数高效方法——傅里叶神经模拟器以实现动态适应（FNSDA），该方法可以通过在傅里叶空间内的适应来泛化到新的动力学。具体而言，FNSDA 使用自动傅里叶模式分区来识别基于已知环境的可分享动力学，并通过条件概率来学习调整针对每个新环境的具体模式，从而实现高效的泛化。我们在四种代表性的动态系统家族上评估了我们的方法，结果表明与现有方法相比，FNSDA 能以显著减少的参数成本实现优越或竞争的泛化性能。我们的代码可在以下链接获取：this https URL。 

---
# AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity 

**Title (ZH)**: AIMatDesign：知识增强的强化学习在数据稀缺下的逆向材料设计 

**Authors**: Yeyong Yu, Xilei Bian, Jie Xiong, Xing Wu, Quan Qian  

**Link**: [PDF](https://arxiv.org/pdf/2507.00024)  

**Abstract**: With the growing demand for novel materials, machine learning-driven inverse design methods face significant challenges in reconciling the high-dimensional materials composition space with limited experimental data. Existing approaches suffer from two major limitations: (I) machine learning models often lack reliability in high-dimensional spaces, leading to prediction biases during the design process; (II) these models fail to effectively incorporate domain expert knowledge, limiting their capacity to support knowledge-guided inverse design. To address these challenges, we introduce AIMatDesign, a reinforcement learning framework that addresses these limitations by augmenting experimental data using difference-based algorithms to build a trusted experience pool, accelerating model convergence. To enhance model reliability, an automated refinement strategy guided by large language models (LLMs) dynamically corrects prediction inconsistencies, reinforcing alignment between reward signals and state value functions. Additionally, a knowledge-based reward function leverages expert domain rules to improve stability and efficiency during training. Our experiments demonstrate that AIMatDesign significantly surpasses traditional machine learning and reinforcement learning methods in discovery efficiency, convergence speed, and success rates. Among the numerous candidates proposed by AIMatDesign, experimental synthesis of representative Zr-based alloys yielded a top-performing BMG with 1.7GPa yield strength and 10.2\% elongation, closely matching predictions. Moreover, the framework accurately captured the trend of yield strength variation with composition, demonstrating its reliability and potential for closed-loop materials discovery. 

**Abstract (ZH)**: 基于强化学习的AIMatDesign：通过增强实验数据加速可信赖的逆设计 

---
# GLU Attention Improve Transformer 

**Title (ZH)**: GLU注意力改进Transformer 

**Authors**: Zehao Wang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00022)  

**Abstract**: Gated Linear Units (GLU) have shown great potential in enhancing neural network performance. In this paper, I introduce a novel attention mechanism called GLU Attention, which introduces nonlinearity into the values of Attention. My experiments demonstrate that GLU Attention improves both model performance and convergence speed across text and vision modalities with zero additional parameters and negligible computational costs. GLU Attention is lightweight and can seamlessly integrate with other technologies, such as Flash Attention, Rotary Position Embedding (RoPE), and various Multi-Head Attention (MHA) variants such as Grouped-Query Attention (GQA). This project is open-sourced at github. 

**Abstract (ZH)**: Gated Linear Units (GLU)在提升神经网络性能方面显示出巨大潜力。本文介绍了一种新颖的注意力机制GLU Attention，该机制将非线性引入注意力值中。实验表明，GLU Attention在文本和视觉模态中均能提高模型性能和收敛速度，同时无需额外参数，并且几乎不增加计算成本。GLU Attention结构轻量，可以无缝集成其他技术，如Flash Attention、旋转位置嵌入（RoPE）以及多种多头注意力机制（MHA）变种，如分组查询注意力（GQA）。该项目已在github上开源。 

---
# Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations 

**Title (ZH)**: 量子启发式的编码策略用于机器学习模型：提出并评估实例级别、全局离散和类条件表示方法 

**Authors**: Minati Rath, Hema Date  

**Link**: [PDF](https://arxiv.org/pdf/2507.00019)  

**Abstract**: In this study, we propose, evaluate and compare three quantum inspired data encoding strategies, Instance Level Strategy (ILS), Global Discrete Strategy (GDS) and Class Conditional Value Strategy (CCVS), for transforming classical data into quantum data for use in pure classical machine learning models. The primary objective is to reduce high encoding time while ensuring correct encoding values and analyzing their impact on classification performance. The Instance Level Strategy treats each row of dataset independently; mimics local quantum states. Global Discrete Value Based encoding strategy maps all unique feature values across the full dataset to quantum states uniformly. In contrast, the Class conditional Value based encoding strategy encodes unique values separately for each class, preserving class dependent information.
We apply these encoding strategies to a classification task and assess their impact on en-coding efficiency, correctness, model accuracy, and computational cost. By analyzing the trade offs between encoding time, precision, and predictive performance, this study provides insights into optimizing quantum inspired data transformations for classical machine learning workflows. 

**Abstract (ZH)**: 本研究提出、评估并比较了三种量子启发式数据编码策略，即实例水平策略（ILS）、全局离散策略（GDS）和类条件值策略（CCVS），用于将经典数据转换为可在纯经典机器学习模型中使用的量子数据。主要目标是在确保正确编码值的前提下减少高编码时间，并分析其对分类性能的影响。实例水平策略独立处理数据集中的每一行，模拟局部量子态；全局离散值基于编码策略将数据集中所有唯一特征值均匀映射到量子态；相比之下，类条件值基于编码策略单独为每个类别编码唯一值，保留类别相关的信息。我们将这些编码策略应用于分类任务，并评估其对编码效率、正确性、模型准确性和计算成本的影响。通过分析编码时间、精度和预测性能之间的权衡，本研究为优化经典机器学习工作流中的量子启发式数据转换提供了见解。 

---
# ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting 

**Title (ZH)**: ST-MTM：基于季节趋势分解的掩码时间序列模型及其在时间序列预测中的应用 

**Authors**: Hyunwoo Seo, Chiehyeon Lim  

**Link**: [PDF](https://arxiv.org/pdf/2507.00013)  

**Abstract**: Forecasting complex time series is an important yet challenging problem that involves various industrial applications. Recently, masked time-series modeling has been proposed to effectively model temporal dependencies for forecasting by reconstructing masked segments from unmasked ones. However, since the semantic information in time series is involved in intricate temporal variations generated by multiple time series components, simply masking a raw time series ignores the inherent semantic structure, which may cause MTM to learn spurious temporal patterns present in the raw data. To capture distinct temporal semantics, we show that masked modeling techniques should address entangled patterns through a decomposition approach. Specifically, we propose ST-MTM, a masked time-series modeling framework with seasonal-trend decomposition, which includes a novel masking method for the seasonal-trend components that incorporates different temporal variations from each component. ST-MTM uses a period masking strategy for seasonal components to produce multiple masked seasonal series based on inherent multi-periodicity and a sub-series masking strategy for trend components to mask temporal regions that share similar variations. The proposed masking method presents an effective pre-training task for learning intricate temporal variations and dependencies. Additionally, ST-MTM introduces a contrastive learning task to support masked modeling by enhancing contextual consistency among multiple masked seasonal representations. Experimental results show that our proposed ST-MTM achieves consistently superior forecasting performance compared to existing masked modeling, contrastive learning, and supervised forecasting methods. 

**Abstract (ZH)**: 复杂时间序列的预测是一个重要而又具有挑战性的问题，涉及各种工业应用。最近，屏蔽时间序列建模已被提出，通过从未屏蔽段重建屏蔽段来有效建模时间依赖性以进行预测。然而，由于时间序列中的语义信息被多个时间序列组件产生的复杂时间变化所涉及，简单地屏蔽原始时间序列会忽略固有的语义结构，这可能导致MTM学到原始数据中存在的虚假时间模式。为了捕捉不同的时间语义，我们表明屏蔽建模技术应通过分解方法解决交织的模式。具体地，我们提出了一种基于季节趋势分解的屏蔽时间序列建模框架ST-MTM，该框架包括一个新颖的屏蔽方法，该方法将不同的时间变化整合到每个组件中。ST-MTM采用周期屏蔽策略对季节成分进行屏蔽，基于固有的多周期性生成多个屏蔽季节序列，并采用子序列屏蔽策略对趋势成分进行屏蔽，以屏蔽具有相似变化的时间区域。提出的屏蔽方法为学习复杂的时间变化和依赖关系提供了一个有效的预训练任务。此外，ST-MTM通过增强多个屏蔽季节表示之间的上下文一致性引入了一种对比学习任务，以支持屏蔽建模。实验结果表明，我们提出的ST-MTM在预测性能上优于现有的屏蔽建模、对比学习和监督预测方法。 

---
# Towards Undistillable Models by Minimizing Conditional Mutual Information 

**Title (ZH)**: 通过最小化条件互信息实现无法反向蒸馏的模型 

**Authors**: Linfeng Ye, Shayan Mohajer Hamidi, En-hui Yang  

**Link**: [PDF](https://arxiv.org/pdf/2507.00012)  

**Abstract**: A deep neural network (DNN) is said to be undistillable if, when used as a black-box input-output teacher, it cannot be distilled through knowledge distillation (KD). In this case, the distilled student (referred to as the knockoff student) does not outperform a student trained independently with label smoothing (LS student) in terms of prediction accuracy. To protect intellectual property of DNNs, it is desirable to build undistillable DNNs. To this end, it is first observed that an undistillable DNN may have the trait that each cluster of its output probability distributions in response to all sample instances with the same label should be highly concentrated to the extent that each cluster corresponding to each label should ideally collapse into one probability distribution. Based on this observation and by measuring the concentration of each cluster in terms of conditional mutual information (CMI), a new training method called CMI minimized (CMIM) method is proposed, which trains a DNN by jointly minimizing the conventional cross entropy (CE) loss and the CMI values of all temperature scaled clusters across the entire temperature spectrum. The resulting CMIM model is shown, by extensive experiments, to be undistillable by all tested KD methods existing in the literature. That is, the knockoff students distilled by these KD methods from the CMIM model underperform the respective LS students. In addition, the CMIM model is also shown to performs better than the model trained with the CE loss alone in terms of their own prediction accuracy. 

**Abstract (ZH)**: 一种深度神经网络（DNN）如果作为黑盒输入-输出教师时，无法通过知识蒸馏（KD）进行提取，则称为不可蒸馏DNN。在这种情况下，通过知识蒸馏得到的“仿冒学生”在预测准确性上不会优于独立使用标签平滑（LS）训练的学生。为了保护DNN的知识产权，构建不可蒸馏DNN是有益的。为此，首先观察到一种不可蒸馏DNN可能具有每个输出概率分布簇对所有具有相同标签的样本实例的响应高度集中，理想情况下，每个标签对应的簇应当塌缩成一个概率分布。基于这一观察，并通过使用条件互信息（CMI）测量每簇的集中度，提出了一个新的训练方法——CMI最小化（CMIM）方法，该方法通过共同最小化传统的交叉熵（CE）损失和整个温度谱范围内所有温度缩放簇的CMI值来训练DNN。实验结果表明，CMIM模型可以通过所有现有文献中的测试KD方法确保其不可蒸馏，即通过CMIM模型提取的“仿冒学生”在预测准确性上不会优于各自对应的LS学生。此外，CMIM模型在自身预测准确性方面也优于仅使用CE损失训练的模型。 

---
# Integrating Universal Generative AI Platforms in Educational Labs to Foster Critical Thinking and Digital Literacy 

**Title (ZH)**: 将通用生成AI平台集成到教育实验室中以培养批判性思维和数字素养 

**Authors**: Vasiliy Znamenskiy, Rafael Niyazov, Joel Hernandez  

**Link**: [PDF](https://arxiv.org/pdf/2507.00007)  

**Abstract**: This paper presents a new educational framework for integrating generative artificial intelligence (GenAI) platforms such as ChatGPT, Claude, and Gemini into laboratory activities aimed at developing critical thinking and digital literacy among undergraduate students. Recognizing the limitations and risks of uncritical reliance on large language models (LLMs), the proposed pedagogical model reframes GenAI as a research subject and cognitive tool. Students formulate discipline-specific prompts and evaluate GenAI-generated responses in text, image, and video modalities. A pilot implementation in a general astronomy course for non-science majors demonstrated high levels of engagement and critical reflection, with many students continuing the activity after class and presenting results at a research symposium. The results highlight the importance of structured AI interactions in education and suggest that GenAI can improve learning outcomes when combined with reflective assessment methods. The study proposes a replicable model for interdisciplinary AI-integrated lab work, adaptable to scientific disciplines. See the guide to learning activities based on Generative-Ai platforms: this https URL 

**Abstract (ZH)**: 这篇论文提出了一种新的教育框架，旨在将生成型人工智能（GenAI）平台（如ChatGPT、Claude和Gemini）整合到实验室活动中，以培养本科生的批判性思维和数字 literacy。该研究认识到对大型语言模型（LLMs）的不加批判的依赖存在局限性和风险，因此提出的教学模式将GenAI重新定位为研究对象和认知工具。学生形成学科特定的提示，并评估GenAI生成的文本、图像和视频响应。一项在非科学专业学生通用天文学课程中的试点实施显示，学生积极参与并进行了深入反思，许多学生在课后继续该活动并在研究论坛上展示了结果。研究结果强调了结构化的人工智能互动在教育中的重要性，并表明当与反思性评估方法结合使用时，GenAI可以提高学习成果。该研究提供了一种可复制的跨学科人工智能整合实验室工作的模型，适用于科学学科。参见基于生成型AI平台的学习活动指南：[此链接]。 

---
# Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE 

**Title (ZH)**: 在不确定性的aware入侵检测中选择何时不下决定：NeutroSENSE方法 

**Authors**: Eyhab Al-Masri  

**Link**: [PDF](https://arxiv.org/pdf/2507.00003)  

**Abstract**: This paper presents NeutroSENSE, a neutrosophic-enhanced ensemble framework for interpretable intrusion detection in IoT environments. By integrating Random Forest, XGBoost, and Logistic Regression with neutrosophic logic, the system decomposes prediction confidence into truth (T), falsity (F), and indeterminacy (I) components, enabling uncertainty quantification and abstention. Predictions with high indeterminacy are flagged for review using both global and adaptive, class-specific thresholds. Evaluated on the IoT-CAD dataset, NeutroSENSE achieved 97% accuracy, while demonstrating that misclassified samples exhibit significantly higher indeterminacy (I = 0.62) than correct ones (I = 0.24). The use of indeterminacy as a proxy for uncertainty enables informed abstention and targeted review-particularly valuable in edge deployments. Figures and tables validate the correlation between I-scores and error likelihood, supporting more trustworthy, human-in-the-loop AI decisions. This work shows that neutrosophic logic enhances both accuracy and explainability, providing a practical foundation for trust-aware AI in edge and fog-based IoT security systems. 

**Abstract (ZH)**: 基于 neutrosophic 逻辑的可解释物联网环境入侵检测集成框架 NeutroSENSE 

---
