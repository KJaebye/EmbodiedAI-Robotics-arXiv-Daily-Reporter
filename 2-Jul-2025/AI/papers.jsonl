{'arxiv_id': 'arXiv:2507.00979', 'title': 'Enhancing LLM Agent Safety via Causal Influence Prompting', 'authors': 'Dongyoon Hahm, Woogyeol Jin, June Suk Choi, Sungsoo Ahn, Kimin Lee', 'link': 'https://arxiv.org/abs/2507.00979', 'abstract': 'As autonomous agents powered by large language models (LLMs) continue to demonstrate potential across various assistive tasks, ensuring their safe and reliable behavior is crucial for preventing unintended consequences. In this work, we introduce CIP, a novel technique that leverages causal influence diagrams (CIDs) to identify and mitigate risks arising from agent decision-making. CIDs provide a structured representation of cause-and-effect relationships, enabling agents to anticipate harmful outcomes and make safer decisions. Our approach consists of three key steps: (1) initializing a CID based on task specifications to outline the decision-making process, (2) guiding agent interactions with the environment using the CID, and (3) iteratively refining the CID based on observed behaviors and outcomes. Experimental results demonstrate that our method effectively enhances safety in both code execution and mobile device control tasks.', 'abstract_zh': '基于因果影响图的自主代理风险识别与缓解技术', 'title_zh': '通过因果影响提示增强LLM代理的安全性'}
{'arxiv_id': 'arXiv:2507.00951', 'title': 'Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact', 'authors': 'Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, Philip Torr, Seyedali Mirjalili', 'link': 'https://arxiv.org/abs/2507.00951', 'abstract': 'Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.', 'abstract_zh': '机器能否在类似人类的领域真正地思考、推理和行动？这一持久的问题继续塑造着通用人工智能（AGI）的研究追求。尽管模型如GPT-4.5、DeepSeek、Claude 3.5 Sonnet、Phi-4和Grok 3展现了多模态流畅性和部分推理能力，这些系统仍然因其依赖于令牌级别预测和缺乏根基化的自主性而受到根本性限制。本文跨学科综合了AGI的发展，涵盖了人工智能、认知神经科学、心理学、生成模型和基于代理系统的观点。我们分析了一般智能的架构和认知基础，强调模块化推理、持久记忆和多代理协调的作用。特别地，我们强调了结合检索、计划和动态工具使用以促进更适应性行为的代理型RAG框架的兴起。我们讨论了一般化策略，包括信息压缩、测试时适应和无需训练的方法，作为通向灵活、领域无关智能的关键路径。视觉-语言模型（VLMs）不仅被重新审视为感知模块，还被视为不断发展中的体悟理解和协作任务完成的接口。我们还论及真正的智能不仅源于规模，还在于记忆和推理的整合：一种模块化、交互式和自我改进组件的协奏，其中压缩促进了适应性行为。借助神经符号系统、强化学习和认知支架的进展，我们探讨了近期架构如何开始弥合统计学习与目标导向认知之间的鸿沟。最后，我们指出了通向AGI过程中的关键科学、技术和伦理挑战。', 'title_zh': '超越令牌思维：从脑启发智能到认知基础的人工通用智能及其社会影响'}
{'arxiv_id': 'arXiv:2507.00841', 'title': 'SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents', 'authors': 'Siyuan Liang, Tianmeng Fang, Zhe Liu, Aishan Liu, Yan Xiao, Jinyuan He, Ee-Chien Chang, Xiaochun Cao', 'link': 'https://arxiv.org/abs/2507.00841', 'abstract': 'With the wide application of multimodal foundation models in intelligent agent systems, scenarios such as mobile device control, intelligent assistant interaction, and multimodal task execution are gradually relying on such large model-driven agents. However, the related systems are also increasingly exposed to potential jailbreak risks. Attackers may induce the agents to bypass the original behavioral constraints through specific inputs, and then trigger certain risky and sensitive operations, such as modifying settings, executing unauthorized commands, or impersonating user identities, which brings new challenges to system security. Existing security measures for intelligent agents still have limitations when facing complex interactions, especially in detecting potentially risky behaviors across multiple rounds of conversations or sequences of tasks. In addition, an efficient and consistent automated methodology to assist in assessing and determining the impact of such risks is currently lacking. This work explores the security issues surrounding mobile multimodal agents, attempts to construct a risk discrimination mechanism by incorporating behavioral sequence information, and designs an automated assisted assessment scheme based on a large language model. Through preliminary validation in several representative high-risk tasks, the results show that the method can improve the recognition of risky behaviors to some extent and assist in reducing the probability of agents being jailbroken. We hope that this study can provide some valuable references for the security risk modeling and protection of multimodal intelligent agent systems.', 'abstract_zh': '面向多模态移动代理的安全挑战与应对策略', 'title_zh': 'SafeMobile：链级 Jailbreak 检测与多模移动代理自动化评估'}
{'arxiv_id': 'arXiv:2507.00810', 'title': 'A Robust Algorithm for Non-IID Machine Learning Problems with Convergence Analysis', 'authors': 'Qing Xu, Xiaohua Xuan', 'link': 'https://arxiv.org/abs/2507.00810', 'abstract': 'In this paper, we propose an improved numerical algorithm for solving minimax problems based on nonsmooth optimization, quadratic programming and iterative process. We also provide a rigorous proof of convergence for our algorithm under some mild assumptions, such as gradient continuity and boundedness. Such an algorithm can be widely applied in various fields such as robust optimization, imbalanced learning, etc.', 'abstract_zh': '本文提出了一种基于非光滑优化、二次规划和迭代过程的求解最小最大问题的改进数值算法，并在一些温和假设下，如梯度连续性和有界性，提供了收敛性的严格证明。该算法可以在鲁棒优化、不平衡学习等领域广泛应用于各种场合。', 'title_zh': '一种应对非 IID 机器学习问题的稳健算法及其收敛性分析'}
{'arxiv_id': 'arXiv:2507.00726', 'title': 'Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess', 'authors': 'Dongyoon Hwang, Hojoon Lee, Jaegul Choo, Dongmin Park, Jongho Park', 'link': 'https://arxiv.org/abs/2507.00726', 'abstract': "While reinforcement learning (RL) for large language models (LLMs) has shown promise in mathematical reasoning, strategic reasoning for LLMs using RL remains largely unexplored. We investigate whether LLMs can develop strategic reasoning capabilities through RL in chess. To this end, we leverage a chess-pretrained action-value network to provide dense reward on the LLM's output move quality, which can be seen as a form of knowledge distillation. Our experiments show that our distillation-based dense rewards often outperform sparse binary rewards. However, surprisingly, all models plateau far below expert levels. We provide SFT and RL ablations on chess reasoning training and find evidence that this limitation stems from a deficit in the pretrained models' internal understanding of chess--a deficit which RL alone may not be able to fully overcome.", 'abstract_zh': 'while reinforcement learning for large language models in mathematical reasoning remains unexplored, strategic reasoning for llsms using rl through chess remains largely unexplored.', 'title_zh': '大型语言模型能发展出策略性推理能力吗？基于学习国际象棋的后训练洞见'}
{'arxiv_id': 'arXiv:2507.00557', 'title': 'Advancing Local Search in SMT-NRA with MCSAT Integration', 'authors': 'Tianyi Ding, Haokun Li, Xinpeng Ni, Bican Xia, Tianqi Zhao', 'link': 'https://arxiv.org/abs/2507.00557', 'abstract': 'In this paper, we advance local search for Satisfiability Modulo the Theory of Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a two-dimensional cell-jump move, called \\emph{$2d$-cell-jump}, generalizing the key operation, cell-jump, of the local search method for SMT-NRA. Then, we propose an extended local search framework, named \\emph{$2d$-LS} (following the local search framework, LS, for SMT-NRA), integrating the model constructing satisfiability calculus (MCSAT) framework to improve search efficiency. To further improve the efficiency of MCSAT, we implement a recently proposed technique called \\emph{sample-cell projection operator} for MCSAT, which is well suited for CDCL-style search in the real domain and helps guide the search away from conflicting states. Finally, we design a hybrid framework for SMT-NRA combining MCSAT, $2d$-LS and OpenCAD, to improve search efficiency through information exchange. The experimental results demonstrate improvements in local search performance, highlighting the effectiveness of the proposed methods.', 'abstract_zh': '在本文中，我们推进了满足非线性实算术理论（SMT-NRA简称）的局部搜索方法。首先，我们引入了一种二维单元跳转移动，称为\\emph{二维单元跳转}，并将其视为SMT-NRA局部搜索方法中关键操作单元跳转的操作扩展。然后，我们提出了一种扩展的局部搜索框架\\emph{二维局部搜索}（2d-LS，跟随SMT-NRA的局部搜索框架LS），将其与模型构建 satisfiability 逻辑（MCSAT）框架相整合，以提高搜索效率。为了进一步提高MCSAT的效率，我们实现了最近提出的一种称为\\emph{样本单元投影算子}的技术，该算子适用于实数域中的CDCL风格搜索，并有助于引导搜索远离冲突状态。最后，我们设计了一种结合MCSAT、2d-LS和OpenCAD的混合框架，通过信息交换提高搜索效率。实验结果表明了局部搜索性能的改进，突显了提出方法的有效性。', 'title_zh': 'SMT-NRA中MCSAT集成的局部搜索优化'}
{'arxiv_id': 'arXiv:2507.00432', 'title': 'Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning', 'authors': 'Maggie Huan, Yuetai Li, Tuney Zheng, Xiaoyu Xu, Seungone Kim, Minxin Du, Radha Poovendran, Graham Neubig, Xiang Yue', 'link': 'https://arxiv.org/abs/2507.00432', 'abstract': 'Math reasoning has become the poster child of progress in large language models (LLMs), with new models rapidly surpassing human-level performance on benchmarks like MATH and AIME. But as math leaderboards improve week by week, it is worth asking: do these gains reflect broader problem-solving ability or just narrow overfitting? To answer this question, we evaluate over 20 open-weight reasoning-tuned models across a broad suite of tasks, including math, scientific QA, agent planning, coding, and standard instruction-following. We surprisingly find that most models that succeed in math fail to transfer their gains to other domains. To rigorously study this phenomenon, we conduct controlled experiments on Qwen3-14B models using math-only data but different tuning methods. We find that reinforcement learning (RL)-tuned models generalize well across domains, while supervised fine-tuning (SFT)-tuned models often forget general capabilities. Latent-space representation and token-space distribution shift analyses reveal that SFT induces substantial representation and output drift, while RL preserves general-domain structure. Our results suggest a need to rethink standard post-training recipes, particularly the reliance on SFT-distilled data for advancing reasoning models.', 'abstract_zh': '大型语言模型（LLMs）中的数学推理能力成为了进步的象征，新模型在MATH和AIME等基准测试中迅速超越人类水平。但随着数学排行榜每周的进步，值得追问：这些进步反映的是更广泛的问题解决能力还是仅仅是狭隘的过拟合？为了回答这个问题，我们评估了超过20个开放参数的推理调优模型在广泛的任务中表现，包括数学、科学问答、代理规划、编码和标准指令跟随。我们惊讶地发现，大多数在数学中取得成功的模型无法将其优势转移到其他领域。为了严格研究这一现象，我们使用仅数学数据但在不同调优方法下对Qwen3-14B模型进行了控制实验。我们发现，强化学习（RL）调优模型在不同领域中表现出良好的泛化能力，而监督微调（SFT）调优模型往往忘记通用能力。潜在空间表示与标记空间分布转移分析揭示了SFT引起显著的表示和输出漂移，而RL保存通用领域的结构。我们的结果表明，需要重新思考标准后训练食谱，特别是在依赖SFT提炼的数据方面推进推理模型方面。', 'title_zh': '数学推理能否提升通用大语言模型的能力？理解大语言模型推理的迁移性'}
{'arxiv_id': 'arXiv:2507.00417', 'title': 'ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context', 'authors': 'Joongwon Kim, Anirudh Goyal, Liang Tan, Hannaneh Hajishirzi, Srinivasan Iyer, Tianlu Wang', 'link': 'https://arxiv.org/abs/2507.00417', 'abstract': 'We introduce ASTRO, the "Autoregressive Search-Taught Reasoner", a framework for training language models to reason like search algorithms, explicitly leveraging self-reflection, backtracking, and exploration in their outputs. Recently, training large language models (LLMs) via reinforcement learning (RL) has led to the advent of reasoning models with greatly enhanced reasoning capabilities. Open-source replications of reasoning models, while successful, build upon models that already exhibit strong reasoning capabilities along with search behavior observed even before RL. As a result, it is yet unclear how to boost the reasoning capabilities of other non-reasoner models including Llama 3. ASTRO teaches such models to internalize structured search behavior through a synthetic dataset derived from Monte Carlo Tree Search (MCTS) over mathematical problem-solving trajectories. By converting search traces into natural language chain-of-thoughts that capture both successes and recoveries from failure, ASTRO bootstraps models with a rich prior for exploration during RL. We finetune our models on these search-derived traces and further improve performance via RL with verifiable rewards. We apply ASTRO to the Llama 3 family of models and achieve absolute performance gains of 16.0% on MATH-500, 26.9% on AMC 2023, and 20.0% on AIME 2024, especially improving upon challenging problems that require iterative correction. Our results demonstrate that search-inspired training offers a principled way to instill robust reasoning capabilities into open LLMs.', 'abstract_zh': 'ASTRO：自动回归搜索教导推理器——一种训练语言模型进行搜索算法式推理的框架', 'title_zh': 'ASTRO：通过反思和回溯进行推理的语料库教学方法'}
{'arxiv_id': 'arXiv:2507.00218', 'title': 'Learning for routing: A guided review of recent developments and future directions', 'authors': 'Fangting Zhou, Attila Lischka, Balazs Kulcsar, Jiaming Wu, Morteza Haghir Chehreghani, Gilbert Laporte', 'link': 'https://arxiv.org/abs/2507.00218', 'abstract': 'This paper reviews the current progress in applying machine learning (ML) tools to solve NP-hard combinatorial optimization problems, with a focus on routing problems such as the traveling salesman problem (TSP) and the vehicle routing problem (VRP). Due to the inherent complexity of these problems, exact algorithms often require excessive computational time to find optimal solutions, while heuristics can only provide approximate solutions without guaranteeing optimality. With the recent success of machine learning models, there is a growing trend in proposing and implementing diverse ML techniques to enhance the resolution of these challenging routing problems. We propose a taxonomy categorizing ML-based routing methods into construction-based and improvement-based approaches, highlighting their applicability to various problem characteristics. This review aims to integrate traditional OR methods with state-of-the-art ML techniques, providing a structured framework to guide future research and address emerging VRP variants.', 'abstract_zh': '本文回顾了将机器学习工具应用于解决NP难组合优化问题，特别是 traveling salesman problem (TSP) 和 vehicle routing problem (VRP) 的当前进展。由于这些问题固有的复杂性，精确算法通常需要大量计算时间来找到最优解，而启发式方法只能提供近似解而不能保证最优性。随着机器学习模型的成功，使用多样化的机器学习技术来提高解决这些具有挑战性的路径优化问题的能力的趋势日益增加。本文提出了一种分类法，将基于机器学习的路径优化方法分为构建方法和改进方法，强调了它们对各种问题特性的适用性。本文旨在将传统的运筹学方法与最先进的机器学习技术相结合，提供一个结构化的框架，以指导未来的研究并解决新兴的车辆路径问题变体。', 'title_zh': '学习用于路由：对近期发展及相关未来方向的引导性回顾'}
{'arxiv_id': 'arXiv:2507.00205', 'title': 'Holistic Artificial Intelligence in Medicine; improved performance and explainability', 'authors': 'Periklis Petridis, Georgios Margaritis, Vasiliki Stoumpou, Dimitris Bertsimas', 'link': 'https://arxiv.org/abs/2507.00205', 'abstract': 'With the increasing interest in deploying Artificial Intelligence in medicine, we previously introduced HAIM (Holistic AI in Medicine), a framework that fuses multimodal data to solve downstream clinical tasks. However, HAIM uses data in a task-agnostic manner and lacks explainability. To address these limitations, we introduce xHAIM (Explainable HAIM), a novel framework leveraging Generative AI to enhance both prediction and explainability through four structured steps: (1) automatically identifying task-relevant patient data across modalities, (2) generating comprehensive patient summaries, (3) using these summaries for improved predictive modeling, and (4) providing clinical explanations by linking predictions to patient-specific medical knowledge. Evaluated on the HAIM-MIMIC-MM dataset, xHAIM improves average AUC from 79.9% to 90.3% across chest pathology and operative tasks. Importantly, xHAIM transforms AI from a black-box predictor into an explainable decision support system, enabling clinicians to interactively trace predictions back to relevant patient data, bridging AI advancements with clinical utility.', 'abstract_zh': 'explanations-driven AI in Medicine）：一种通过生成式AI增强预测和解释性的新型框架', 'title_zh': '全面人工智能在医学中的应用；改进的性能与解释性'}
{'arxiv_id': 'arXiv:2507.00181', 'title': 'ChatGPT produces more "lazy" thinkers: Evidence of cognitive engagement decline', 'authors': 'Georgios P. Georgiou', 'link': 'https://arxiv.org/abs/2507.00181', 'abstract': 'Despite the increasing use of large language models (LLMs) in education, concerns have emerged about their potential to reduce deep thinking and active learning. This study investigates the impact of generative artificial intelligence (AI) tools, specifically ChatGPT, on the cognitive engagement of students during academic writing tasks. The study employed an experimental design with participants randomly assigned to either an AI-assisted (ChatGPT) or a non-assisted (control) condition. Participants completed a structured argumentative writing task followed by a cognitive engagement scale (CES), the CES-AI, developed to assess mental effort, attention, deep processing, and strategic thinking. The results revealed significantly lower cognitive engagement scores in the ChatGPT group compared to the control group. These findings suggest that AI assistance may lead to cognitive offloading. The study contributes to the growing body of literature on the psychological implications of AI in education and raises important questions about the integration of such tools into academic practice. It calls for pedagogical strategies that promote active, reflective engagement with AI-generated content to avoid compromising self-regulated learning and deep cognitive involvement of students.', 'abstract_zh': '尽管大型语言模型（LLMs）在教育中的应用日益增多，但对其可能降低深度思考和主动学习的担忧也随之出现。本研究探讨了生成式人工智能（AI）工具，特别是ChatGPT，对学生在学术写作任务中认知参与度的影响。研究采用实验设计，参与者随机分配至AI辅助（ChatGPT）组或非辅助（控制）组。参与者完成了一项结构化的论证写作任务，随后进行了认知参与度量表（CES-AI）的评估，该量表用于评估心理努力、注意力、深层次加工和策略性思维。研究结果表明，ChatGPT组的认知参与度评分显著低于控制组。这些发现表明，AI辅助可能导致认知负担转移。本研究为人工智能在教育中的心理影响相关文献增添了新的内容，并提出了关于将此类工具融入学术实践的重要性问题。它呼吁采用促进积极、反思性参与AI生成内容的教育策略，以避免损害学生的自我调节学习和深层次认知参与。', 'title_zh': 'ChatGPT使思考变得“懒惰”：认知参与度下降的证据'}
{'arxiv_id': 'arXiv:2507.00180', 'title': 'BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis', 'authors': 'Vidhi Rathore', 'link': 'https://arxiv.org/abs/2507.00180', 'abstract': "Modernizing legacy software systems is a critical but challenging task, often hampered by a lack of documentation and understanding of the original system's intricate decision logic. Traditional approaches like behavioral cloning merely replicate input-output behavior without capturing the underlying intent. This paper proposes a novel pipeline to automatically extract interpretable decision logic from legacy systems treated as black boxes. The approach uses a Reinforcement Learning (RL) agent to explore the input space and identify critical decision boundaries by rewarding actions that cause meaningful changes in the system's output. These counterfactual state transitions, where the output changes, are collected and clustered using K-Means. Decision trees are then trained on these clusters to extract human-readable rules that approximate the system's decision logic near the identified boundaries. I demonstrated the pipeline's effectiveness on three dummy legacy systems with varying complexity, including threshold-based, combined-conditional, and non-linear range logic. Results show that the RL agent successfully focuses exploration on relevant boundary regions, and the extracted rules accurately reflect the core logic of the underlying dummy systems, providing a promising foundation for generating specifications and test cases during legacy migration.", 'abstract_zh': '现代重构遗留软件系统是一项关键但具有挑战性的任务，常常受到原始系统详细决策逻辑缺乏文档和理解的阻碍。传统方法如行为克隆仅复制输入-输出行为而未捕获其背后的意图。本文提出了一种新颖的工作流程，用于从被视为黑盒的遗留系统中自动提取可解释的决策逻辑。该方法使用强化学习（RL）代理探索输入空间，并通过奖励导致系统输出有意义变化的动作来识别关键决策边界。这些反事实的状态转移，即输出发生变化的情况，使用K-Means进行聚类。然后，基于这些簇训练决策树以提取近似系统决策逻辑的人类可读规则。研究结果表明，RL代理能够有效地将探索集中在相关边界区域，并提取出准确反映底层模拟系统核心逻辑的规则，为遗留系统迁移期间生成规范和测试案例提供了有前景的基础。', 'title_zh': '黑盒到蓝图：利用强化学习和反事实分析提取可解释逻辑从 legacy 系统'}
{'arxiv_id': 'arXiv:2507.00092', 'title': "Thinking About Thinking: SAGE-nano's Inverse Reasoning for Self-Aware Language Models", 'authors': 'Basab Jha, Firoj Paudel, Ujjwal Puri, Zhang Yuting, Choi Donghyuk, Wang Junhao', 'link': 'https://arxiv.org/abs/2507.00092', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities at solving complex reasoning tasks with Chain-of-Thought (CoT) prompting, but their decision-making processes remain somewhat blackbox. We introduce textbfinverse reasoning, a novel paradigm enabling LLMs to decompose and explain their own reasoning chains post-hoc. Our approach, used in SAGE-nano, a 4-billion-parameter reasoning model, employs a metacognitive structure that reflects back via attention processes to identify major decision points and generate explanations of reasoning choices. While typical CoT approaches are directed towards forward reasoning generation, inverse reasoning provides insight into why specific reasoning chains were selected over others. Through thorough testing of logical reasoning puzzles, math problems and ethical dilemmas from AQUA-RAT, CommonsenseQA, and customized benchmarks, we demonstrate that SAGE-nano is at the cutting edge both on reasoning accuracy (74.6% on AQUA-RAT) and explanation quality (92.1% human preference score) for its task, and offers performance almost on par with models like Claude-3.5 Sonnet or GPT-4o. Our contributions are: (i) the first rigorous framework for LLM self-reflection via inverse reasoning, (ii) a novel metalearning framework to reverse the attention flow, (iii) comprehensive evaluation frameworks for reasoning transparency, and (iv) evidence that increasing reasoning using inverse reasoning improves interpretability along with reasoning performance. Our work creates new avenues for transparent AI systems and closes significant gaps in AI safety, education, and scientific discovery.', 'abstract_zh': '大规模语言模型（LLMs）通过Chain-of-Thought（CoT）提示展示了在解决复杂推理任务方面的卓越能力，但其决策过程仍然相对黑箱。我们引入了文本逆向推理这一新型范式，使LLMs能够事后分解和解释其推理链。我们的方法应用于一个40亿参数的推理模型SAGE-nano，利用一种元认知结构，通过注意力机制进行反向反馈以识别主要决策点并生成推理选择的解释。虽然典型的CoT方法侧重于正向推理生成，逆向推理则提供了为什么选择特定的推理链而非其他链的见解。通过AQUA-RAT、CommonsenseQA和自定基准数据集中的逻辑推理谜题、数学问题和伦理困境的全面测试，我们展示了SAGE-nano在推理准确性（AQUA-RAT上74.6%）和解释质量（92.1%的人类偏好得分）方面处于前沿地位，并且在推理性能方面几乎与Claude-3.5 Sonnet或GPT-4o等模型不相上下。我们的贡献包括：（i）第一个严格的通过逆向推理进行LLM自我反思的框架，（ii）一种新的元学习框架来逆转注意力流，（iii）推理透明度的综合评估框架，以及（iv）证据表明，通过逆向推理增加推理可以提高解释性并提升推理性能。我们的工作为透明AI系统开辟了新的途径，并在AI安全、教育和科学发现方面填补了重要空白。', 'title_zh': '思考中的思考：SAGE-nano的逆向推理实现自我意识语言模型'}
{'arxiv_id': 'arXiv:2507.00079', 'title': 'VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems', 'authors': 'Ethan Smyth, Alessandro Suglia', 'link': 'https://arxiv.org/abs/2507.00079', 'abstract': "Open-endedness is an active field of research in the pursuit of capable Artificial General Intelligence (AGI), allowing models to pursue tasks of their own choosing. Simultaneously, recent advancements in Large Language Models (LLMs) such as GPT-4o [9] have allowed such models to be capable of interpreting image inputs. Implementations such as OMNI-EPIC [4] have made use of such features, providing an LLM with pixel data of an agent's POV to parse the environment and allow it to solve tasks. This paper proposes that providing these visual inputs to a model gives it greater ability to interpret spatial environments, and as such, can increase the number of tasks it can successfully perform, extending its open-ended potential. To this aim, this paper proposes VoyagerVision -- a multi-modal model capable of creating structures within Minecraft using screenshots as a form of visual feedback, building on the foundation of Voyager. VoyagerVision was capable of creating an average of 2.75 unique structures within fifty iterations of the system, as Voyager was incapable of this, it is an extension in an entirely new direction. Additionally, in a set of building unit tests VoyagerVision was successful in half of all attempts in flat worlds, with most failures arising in more complex structures. Project website is available at this https URL", 'abstract_zh': '开放性是追求具备通用人工智能（AGI）能力的研究中的一个活跃领域，使模型能够自主追求任务。同时，大型语言模型（LLMs）如GPT-4o的近期进展使其能够解释图像输入。OMNI-EPIC等实现使用了这些功能，为LLM提供代理视角的像素数据以解析环境，并允许其解决任务。本文提出，向模型提供这些视觉输入使其能够更好地解释空间环境，从而增加其能够成功完成的任务数量，扩展其开放性潜力。为此，本文提出了VoyagerVision——一种多模态模型，能够使用截屏作为视觉反馈在Minecraft中创建结构，建立在Voyager的基础上。VoyagerVision在系统五十次迭代中平均能够创建2.75种独特的结构，而Voyager无法做到这一点，因此它是朝完全新方向的拓展。此外，在一组建筑单元测试中，VoyagerVision在平坦世界中成功了一半的尝试，大多数失败发生在更复杂的结构中。项目网站可在以下链接访问。', 'title_zh': 'VoyagerVision：探索多模态信息在开放学习系统中的作用'}
{'arxiv_id': 'arXiv:2507.00054', 'title': 'Enhancing Reasoning Capabilities in SLMs with Reward Guided Dataset Distillation', 'authors': 'Shreyansh Padarha', 'link': 'https://arxiv.org/abs/2507.00054', 'abstract': "The push to compress and impart the proficiency of Large Language Models (LLMs) into more deployable and efficient Small Language Models (SLMs) has benefited from improvements in knowledge distillation (KD) techniques. These techniques allow a smaller student model to learn from a more capable and larger teacher model's responses. However, distillation often revolves around the student model merely copying the teacher's in-distribution responses, limiting its generalisability. This limitation is amplified on reasoning tasks and can be computationally expensive. In this study, we propose AdvDistill, a reward-guided dataset distillation framework. We utilise multiple generations (responses) from a teacher for each prompt and assign rewards based on rule-based verifiers. These varying and normally distributed rewards serve as weights when training student models. Our methods and their subsequent behavioural analysis demonstrate a significant improvement in student model performance for mathematical and complex reasoning tasks, showcasing the efficacy and benefits of incorporating a rewarding mechanism in dataset distillation processes.", 'abstract_zh': '将大型语言模型（LLMs）的 proficiency 压缩并 impart 到更具部署性和效率的小型语言模型（SLMs）中,得益于知识蒸馏（KD）技术的进步。这些技术允许较小的学生模型从更大、更有能力的教师模型的回答中学习。然而,蒸馏通常集中在让学生模型简单复制教师模型在分布内的回答上,限制了其泛化能力。这一限制在推理任务中尤为突出,可能会导致计算成本增加。在此研究中，我们提出 AdvDistill，一种基于奖励的数据集蒸馏框架。我们为每个提示利用教师的多轮生成（回答），并基于基于规则的验证器分配奖励。这些不同的且通常分布的奖励用于训练学生模型时的权重。我们的方法及其后续的行为分析证明，在数学和复杂推理任务中，学生模型的表现有了显著提升，展示了在数据集蒸馏过程中引入奖励机制的有效性和益处。', 'title_zh': '基于奖励引导数据集精炼增强SLMs的推理能力'}
{'arxiv_id': 'arXiv:2507.00050', 'title': 'SEZ-HARN: Self-Explainable Zero-shot Human Activity Recognition Network', 'authors': 'Devin Y. De Silva, Sandareka Wickramanayake, Dulani Meedeniya, Sanka Rasnayaka', 'link': 'https://arxiv.org/abs/2507.00050', 'abstract': 'Human Activity Recognition (HAR), which uses data from Inertial Measurement Unit (IMU) sensors, has many practical applications in healthcare and assisted living environments. However, its use in real-world scenarios has been limited by the lack of comprehensive IMU-based HAR datasets that cover a wide range of activities and the lack of transparency in existing HAR models. Zero-shot HAR (ZS-HAR) overcomes the data limitations, but current models struggle to explain their decisions, making them less transparent. This paper introduces a novel IMU-based ZS-HAR model called the Self-Explainable Zero-shot Human Activity Recognition Network (SEZ-HARN). It can recognize activities not encountered during training and provide skeleton videos to explain its decision-making process. We evaluate the effectiveness of the proposed SEZ-HARN on four benchmark datasets PAMAP2, DaLiAc, HTD-MHAD and MHealth and compare its performance against three state-of-the-art black-box ZS-HAR models. The experiment results demonstrate that SEZ-HARN produces realistic and understandable explanations while achieving competitive Zero-shot recognition accuracy. SEZ-HARN achieves a Zero-shot prediction accuracy within 3\\% of the best-performing black-box model on PAMAP2 while maintaining comparable performance on the other three datasets.', 'abstract_zh': '基于惯性测量单元的零样本自解释人类活动识别网络（SEZ-HARN）', 'title_zh': 'SEZ-HARN: 自解释零样本人体活动识别网络'}
{'arxiv_id': 'arXiv:2507.00048', 'title': 'A collaborative digital twin built on FAIR data and compute infrastructure', 'authors': 'Thomas M. Deucher, Juan C. Verduzco, Michael Titus, Alejandro Strachan', 'link': 'https://arxiv.org/abs/2507.00048', 'abstract': 'The integration of machine learning with automated experimentation in self-driving laboratories (SDL) offers a powerful approach to accelerate discovery and optimization tasks in science and engineering applications. When supported by findable, accessible, interoperable, and reusable (FAIR) data infrastructure, SDLs with overlapping interests can collaborate more effectively. This work presents a distributed SDL implementation built on nanoHUB services for online simulation and FAIR data management. In this framework, geographically dispersed collaborators conducting independent optimization tasks contribute raw experimental data to a shared central database. These researchers can then benefit from analysis tools and machine learning models that automatically update as additional data become available. New data points are submitted through a simple web interface and automatically processed using a nanoHUB Sim2L, which extracts derived quantities and indexes all inputs and outputs in a FAIR data repository called ResultsDB. A separate nanoHUB workflow enables sequential optimization using active learning, where researchers define the optimization objective, and machine learning models are trained on-the-fly with all existing data, guiding the selection of future experiments. Inspired by the concept of ``frugal twin", the optimization task seeks to find the optimal recipe to combine food dyes to achieve the desired target color. With easily accessible and inexpensive materials, researchers and students can set up their own experiments, share data with collaborators, and explore the combination of FAIR data, predictive ML models, and sequential optimization. The tools introduced are generally applicable and can easily be extended to other optimization problems.', 'abstract_zh': '机器学习与自动化实验在自主驾驶实验室（SDL）中的集成提供了加速科学研究和工程应用中发现和优化任务的强大方法。当由可获取、可访问、可互操作和可重用（FAIR）数据基础设施支持时，具有相交兴趣的SDL可以更有效地协作。本工作介绍了基于nanoHUB服务的分布式SDL实现，用于在线仿真和FAIR数据管理。在此框架中，地理上分散的独立执行优化任务的合作者将原始实验数据贡献到共享的中央数据库中。研究人员可以利用自动更新的分析工具和机器学习模型进行数据挖掘。新的数据点通过简单的网页界面提报，并自动处理，使用nanoHUB Sim2L从这些数据中提取衍生量，并在FAIR数据存储库ResultsDB中索引所有输入和输出。另一个独立的nanoHUB工作流实现了基于主动学习的序列优化，研究人员定义优化目标，机器学习模型在所有现有数据的基础上实时训练，指导未来实验的选择。受“节俭双胞胎”概念的启发，优化任务旨在找到将食品色素组合以达到目标颜色的最佳配方。借助易于访问且成本低廉的材料，研究人员和学生可以设置自己的实验，与其他合作者共享数据，并探索FAIR数据、预测性机器学习模型和序列优化的结合。介绍的工具具有通用性，易于扩展到其他优化问题。', 'title_zh': '基于FAIR数据与计算基础设施的协作数字孪生'}
{'arxiv_id': 'arXiv:2507.00041', 'title': 'TalentMine: LLM-Based Extraction and Question-Answering from Multimodal Talent Tables', 'authors': 'Varun Mannam, Fang Wang, Chaochun Liu, Xin Chen', 'link': 'https://arxiv.org/abs/2507.00041', 'abstract': "In talent management systems, critical information often resides in complex tabular formats, presenting significant retrieval challenges for conventional language models. These challenges are pronounced when processing Talent documentation that requires precise interpretation of tabular relationships for accurate information retrieval and downstream decision-making. Current table extraction methods struggle with semantic understanding, resulting in poor performance when integrated into retrieval-augmented chat applications. This paper identifies a key bottleneck - while structural table information can be extracted, the semantic relationships between tabular elements are lost, causing downstream query failures. To address this, we introduce TalentMine, a novel LLM-enhanced framework that transforms extracted tables into semantically enriched representations. Unlike conventional approaches relying on CSV or text linearization, our method employs specialized multimodal reasoning to preserve both structural and semantic dimensions of tabular data. Experimental evaluation across employee benefits document collections demonstrates TalentMine's superior performance, achieving 100% accuracy in query answering tasks compared to 0% for standard AWS Textract extraction and 40% for AWS Textract Visual Q&A capabilities. Our comparative analysis also reveals that the Claude v3 Haiku model achieves optimal performance for talent management applications. The key contributions of this work include (1) a systematic analysis of semantic information loss in current table extraction pipelines, (2) a novel LLM-based method for semantically enriched table representation, (3) an efficient integration framework for retrieval-augmented systems as end-to-end systems, and (4) comprehensive benchmarks on talent analytics tasks showing substantial improvements across multiple categories.", 'abstract_zh': '在人才管理体系中，关键信息经常以复杂的表格格式存在，给传统的语言模型带来了显著的检索挑战。当处理需要精确解析表格关系以实现准确信息检索和下游决策的人才文档时，这些挑战尤为明显。当前的表格提取方法在语义理解方面存在困难，导致将其集成到检索增强聊天应用中时性能不佳。本文指出了一个关键瓶颈——虽然可以提取结构化的表格信息，但表格元素之间的语义关系会丢失，从而导致下游查询失败。为了解决这个问题，我们提出了TalentMine，一种新颖的LLM增强框架，将提取的表格转换为语义丰富的表示。与依赖于CSV或文本线性化的传统方法不同，我们的方法采用专有的多模态推理来同时保留表格数据的结构和语义维度。在员工福利文档集合上的实验评估表明，TalentMine的表现优于标准的AWS Textract提取方法（准确率为0%）和AWS Textract视觉问答功能（准确率为40%）。我们的对比分析还表明，Claude v3 Haiku模型在人才管理应用中表现最优。本文的主要贡献包括：（1）系统分析当前表格提取流水线中的语义信息丢失情况；（2）一种基于LLM的语义丰富表格表示的新方法；（3）检索增强系统的高效集成框架，作为端到端系统；（4）针对人才分析任务的全面基准测试，显示出在多个类别上的显著改进。', 'title_zh': 'TalentMine：基于LLM的多模态人才表格提取与问答'}
{'arxiv_id': 'arXiv:2507.00008', 'title': 'DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via Modality-Aware Visual Reasoning', 'authors': 'Hang Wu, Hongkai Chen, Yujun Cai, Chang Liu, Qingwen Ye, Ming-Hsuan Yang, Yiwei Wang', 'link': 'https://arxiv.org/abs/2507.00008', 'abstract': "Grounding natural language queries in graphical user interfaces (GUIs) poses unique challenges due to the diversity of visual elements, spatial clutter, and the ambiguity of language. In this paper, we introduce DiMo-GUI, a training-free framework for GUI grounding that leverages two core strategies: dynamic visual grounding and modality-aware optimization. Instead of treating the GUI as a monolithic image, our method splits the input into textual elements and iconic elements, allowing the model to reason over each modality independently using general-purpose vision-language models. When predictions are ambiguous or incorrect, DiMo-GUI dynamically focuses attention by generating candidate focal regions centered on the model's initial predictions and incrementally zooms into subregions to refine the grounding result. This hierarchical refinement process helps disambiguate visually crowded layouts without the need for additional training or annotations. We evaluate our approach on standard GUI grounding benchmarks and demonstrate consistent improvements over baseline inference pipelines, highlighting the effectiveness of combining modality separation with region-focused reasoning.", 'abstract_zh': '基于图形用户界面（GUI）的自然语言查询 grounding 面临着独特挑战，由于视觉元素的多样性、空间重叠以及语言的歧义性。本文介绍了一种无需训练的 GUI grounding 框架 DiMo-GUI，该框架采用了动态视觉 grounding 和模态感知优化两种核心策略。我们的方法将输入分为文本元素和图示元素，允许模型使用通用的视觉-语言模型独立推理每种模态。当预测结果模糊或错误时，DiMo-GUI 会动态聚焦注意力，生成以模型初始预测为中心的候选焦点区域，并逐步放大子区域以细化 grounding 结果。这一分层细化过程有助于在无需额外训练或标注的情况下消解视觉拥挤的布局。我们在标准 GUI grounding 数据集上评估了该方法，展示了与基准推理管道相比的一致性改进，突显了结合模态分离与区域集中推理的有效性。', 'title_zh': 'DiMo-GUI: 基于模态意识视觉推理的GUI定位测试时扩展增强'}
{'arxiv_id': 'arXiv:2507.01006', 'title': 'GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning', 'authors': 'Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, Shuaiqi Duan, Weihan Wang, Yan Wang, Yean Cheng, Zehai He, Zhe Su, Zhen Yang, Ziyang Pan, Aohan Zeng, Baoxu Wang, Boyan Shi, Changyu Pang, Chenhui Zhang, Da Yin, Fan Yang, Guoqing Chen, Jiazheng Xu, Jiali Chen, Jing Chen, Jinhao Chen, Jinghao Lin, Jinjiang Wang, Junjie Chen, Leqi Lei, Leyi Pan, Mingzhi Zhang, Qinkai Zheng, Sheng Yang, Shi Zhong, Shiyu Huang, Shuyuan Zhao, Siyan Xue, Shangqin Tu, Shengbiao Meng, Tianshu Zhang, Tianwei Luo, Tianxiang Hao, Tianle Gong, Wenkai Li, Wei Jia, Xin Lyu, Xuancheng Huang, Yanling Wang, Yadong Xue, Yanfeng Wang, Yifan An, Yifan Du, Yiming Shi, Yiheng Huang, Yilin Niu, Yuan Wang, Yuanchang Yue, Yuchen Li, Yutao Zhang, Yuxuan Zhang, Zhanxiao Du, Zhenyu Hou, Zhao Xue, Zhengxiao Du, Zihan Wang, Peng Zhang, Debing Liu, Bin Xu, Juanzi Li, Minlie Huang, Yuxiao Dong, Jie Tang', 'link': 'https://arxiv.org/abs/2507.01006', 'abstract': 'We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to advance general-purpose multimodal reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. Reinforcement Learning with Curriculum Sampling (RLCS) then unlocks the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document understanding, among others. To facilitate research in this field, we open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performance among models of comparable size. In a comprehensive evaluation across 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks and achieves comparable or even superior performance on 18 benchmarks relative to the significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking also demonstrates competitive or superior performance compared to closed-source models such as GPT-4o on challenging tasks including long document understanding and STEM reasoning, further underscoring its strong capabilities. Code, models and more information are released at this https URL.', 'abstract_zh': 'GLM-4.1V-Thinking：一种旨在促进通用多模态推理的视觉-语言模型', 'title_zh': 'GLM-4.1V-Thinking: 向通用多模态推理与可扩展强化学习的方向迈进'}
{'arxiv_id': 'arXiv:2507.01003', 'title': 'Description of the Training Process of Neural Networks via Ergodic Theorem : Ghost nodes', 'authors': 'Eun-Ji Park, Sangwon Yun', 'link': 'https://arxiv.org/abs/2507.01003', 'abstract': "Recent studies have proposed interpreting the training process from an ergodic perspective. Building on this foundation we present a unified framework for understanding and accelerating the training of deep neural networks via stochastic gradient descent. By analyzing the geometric landscape of the objective function we introduce a practical diagnostic, the running estimate of the largest Lyapunov exponent, which provably distinguishes genuine convergence toward stable minimizers from mere statistical stabilization near saddle points. We then propose a ghost category extension for standard classifiers that adds auxiliary ghost output nodes so the model gains extra descent directions that open a lateral corridor around narrow loss barriers and enable the optimizer to bypass poor basins during the early training phase. We show that this extension strictly reduces approximation error and that after sufficient convergence the ghost dimensions collapse and the extended model's invariant law coincides with that of the original and there exists a path in the enlarged parameter space along which the total loss does not increase while the original loss decreases by an arbitrary margin. Taken together these results provide a principled architecture level intervention that accelerates early stage trainability while preserving asymptotic behavior.", 'abstract_zh': '近期研究表明，可以从遍历性的角度来解释训练过程。在此基础上，我们提出了一种统一框架，用于通过随机梯度下降理解并加速深度神经网络的训练。通过对目标函数几何景观的分析，我们引入了一个实用的诊断工具——运行中的最大李雅普unov指数的估计值，可以证明这一工具能区分向稳定极小值的真正收敛与在鞍点附近仅统计上的稳定。然后，我们提出了一种标准分类器的ghost类别扩展，通过增加辅助ghost输出节点，为模型提供额外的下降方向，从而在早期训练阶段绕过狭窄的损失障碍，使优化器能够避开差的局部极小值。我们证明这种扩展严格地降低了近似误差，并且在充分收敛后，ghost维度会消失，扩展后的模型的不变定律与原始模型相同，且存在一条在扩大后的参数空间中的路径，使得总损失不增加而原始损失减少任意幅度。这些结果共同提供了一个在保持渐近行为的同时加速早期训练阶段规范性的架构级干预措施。', 'title_zh': '基于遍历定理的神经网络训练过程描述：幽灵节点'}
{'arxiv_id': 'arXiv:2507.01001', 'title': 'SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks', 'authors': 'Yilun Zhao, Kaiyan Zhang, Tiansheng Hu, Sihong Wu, Ronan Le Bras, Taira Anderson, Jonathan Bragg, Joseph Chee Chang, Jesse Dodge, Matt Latzke, Yixin Liu, Charles McGrady, Xiangru Tang, Zihang Wang, Chen Zhao, Hannaneh Hajishirzi, Doug Downey, Arman Cohan', 'link': 'https://arxiv.org/abs/2507.01001', 'abstract': "We present SciArena, an open and collaborative platform for evaluating foundation models on scientific literature tasks. Unlike traditional benchmarks for scientific literature understanding and synthesis, SciArena engages the research community directly, following the Chatbot Arena evaluation approach of community voting on model comparisons. By leveraging collective intelligence, SciArena offers a community-driven evaluation of model performance on open-ended scientific tasks that demand literature-grounded, long-form responses. The platform currently supports 23 open-source and proprietary foundation models and has collected over 13,000 votes from trusted researchers across diverse scientific domains. We analyze the data collected so far and confirm that the submitted questions are diverse, aligned with real-world literature needs, and that participating researchers demonstrate strong self-consistency and inter-annotator agreement in their evaluations. We discuss the results and insights based on the model ranking leaderboard. To further promote research in building model-based automated evaluation systems for literature tasks, we release SciArena-Eval, a meta-evaluation benchmark based on our collected preference data. The benchmark measures the accuracy of models in judging answer quality by comparing their pairwise assessments with human votes. Our experiments highlight the benchmark's challenges and emphasize the need for more reliable automated evaluation methods.", 'abstract_zh': 'SciArena：一个开放协同的平台，用于评估基础模型在科学文献任务中的性能', 'title_zh': 'SciArena: 一个面向科研文献任务的基础模型开放评估平台'}
{'arxiv_id': 'arXiv:2507.00990', 'title': 'Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations', 'authors': 'Shivansh Patel, Shraddhaa Mohan, Hanlin Mai, Unnat Jain, Svetlana Lazebnik, Yunzhu Li', 'link': 'https://arxiv.org/abs/2507.00990', 'abstract': 'This work introduces Robots Imitating Generated Videos (RIGVid), a system that enables robots to perform complex manipulation tasks--such as pouring, wiping, and mixing--purely by imitating AI-generated videos, without requiring any physical demonstrations or robot-specific training. Given a language command and an initial scene image, a video diffusion model generates potential demonstration videos, and a vision-language model (VLM) automatically filters out results that do not follow the command. A 6D pose tracker then extracts object trajectories from the video, and the trajectories are retargeted to the robot in an embodiment-agnostic fashion. Through extensive real-world evaluations, we show that filtered generated videos are as effective as real demonstrations, and that performance improves with generation quality. We also show that relying on generated videos outperforms more compact alternatives such as keypoint prediction using VLMs, and that strong 6D pose tracking outperforms other ways to extract trajectories, such as dense feature point tracking. These findings suggest that videos produced by a state-of-the-art off-the-shelf model can offer an effective source of supervision for robotic manipulation.', 'abstract_zh': '机器人模仿生成视频（RIGVid）系统：一种仅通过模仿AI生成视频来执行复杂操作任务的系统', 'title_zh': '基于生成视频模仿的机器人操作'}
{'arxiv_id': 'arXiv:2507.00971', 'title': 'Reasoning as an Adaptive Defense for Safety', 'authors': 'Taeyoun Kim, Fahim Tajwar, Aditi Raghunathan, Aviral Kumar', 'link': 'https://arxiv.org/abs/2507.00971', 'abstract': 'Reasoning methods that adaptively allocate test-time compute have advanced LLM performance on easy to verify domains such as math and code. In this work, we study how to utilize this approach to train models that exhibit a degree of robustness to safety vulnerabilities, and show that doing so can provide benefits. We build a recipe called $\\textit{TARS}$ (Training Adaptive Reasoners for Safety), a reinforcement learning (RL) approach that trains models to reason about safety using chain-of-thought traces and a reward signal that balances safety with task completion. To build TARS, we identify three critical design choices: (1) a "lightweight" warmstart SFT stage, (2) a mix of harmful, harmless, and ambiguous prompts to prevent shortcut behaviors such as too many refusals, and (3) a reward function to prevent degeneration of reasoning capabilities during training. Models trained with TARS exhibit adaptive behaviors by spending more compute on ambiguous queries, leading to better safety-refusal trade-offs. They also internally learn to better distinguish between safe and unsafe prompts and attain greater robustness to both white-box (e.g., GCG) and black-box attacks (e.g., PAIR). Overall, our work provides an effective, open recipe for training LLMs against jailbreaks and harmful requests by reasoning per prompt.', 'abstract_zh': '利用自适应分配测试时计算资源的推理方法已在数学和代码等易于验证的领域提升了LLM的性能。本文研究了如何利用这种方法训练具有一定程度安全漏洞鲁棒性的模型，并展示了这种方法的益处。我们构建了一个名为TARS（Training Adaptive Reasoners for Safety）的方案，这是一种强化学习方法，通过使用逻辑推理痕迹和平衡安全与任务完成的奖励信号来训练模型进行安全推理。为了构建TARS，我们确定了三个关键设计选择：（1）轻量级的预训练 Few-Shot Tuning 阶段，（2）混合包含有害、无害和模棱两可提示的提示以防止捷径行为，如过多的拒绝，以及（3）奖励函数以防止训练过程中推理能力退化。使用TARS训练的模型通过在模棱两可查询上投入更多计算资源表现出自适应行为，从而实现更好的安全拒绝权衡。它们还内部学习更好地区分安全和不安全的提示，并对白盒（如GCG）和黑盒攻击（如PAIR）表现出更强的鲁棒性。总体而言，我们的工作提供了一种有效且开放的方案，通过每提示推理来训练LLMs以抵御突破和有害请求。', 'title_zh': '推理作为适应性安全防御机制'}
{'arxiv_id': 'arXiv:2507.00969', 'title': 'Surgical Neural Radiance Fields from One Image', 'authors': 'Alberto Neri, Maximilan Fehrentz, Veronica Penza, Leonardo S. Mattos, Nazim Haouchine', 'link': 'https://arxiv.org/abs/2507.00969', 'abstract': 'Purpose: Neural Radiance Fields (NeRF) offer exceptional capabilities for 3D reconstruction and view synthesis, yet their reliance on extensive multi-view data limits their application in surgical intraoperative settings where only limited data is available. In particular, collecting such extensive data intraoperatively is impractical due to time constraints. This work addresses this challenge by leveraging a single intraoperative image and preoperative data to train NeRF efficiently for surgical scenarios.\nMethods: We leverage preoperative MRI data to define the set of camera viewpoints and images needed for robust and unobstructed training. Intraoperatively, the appearance of the surgical image is transferred to the pre-constructed training set through neural style transfer, specifically combining WTC2 and STROTSS to prevent over-stylization. This process enables the creation of a dataset for instant and fast single-image NeRF training.\nResults: The method is evaluated with four clinical neurosurgical cases. Quantitative comparisons to NeRF models trained on real surgical microscope images demonstrate strong synthesis agreement, with similarity metrics indicating high reconstruction fidelity and stylistic alignment. When compared with ground truth, our method demonstrates high structural similarity, confirming good reconstruction quality and texture preservation.\nConclusion: Our approach demonstrates the feasibility of single-image NeRF training in surgical settings, overcoming the limitations of traditional multi-view methods.', 'abstract_zh': '目的：神经辐射场（NeRF）在三维重建和视图合成方面提供了卓越的能力，但由于其依赖于大量多视角数据，限制了其在仅能获得有限数据的外科手术内镜环境下应用。特别是，由于时间限制，在手术过程中收集大量数据是不现实的。本研究通过利用术前图像和预手术数据，在手术场景中高效训练NeRF，从而应对这一挑战。', 'title_zh': '单张图像的手术神经辐射场'}
{'arxiv_id': 'arXiv:2507.00966', 'title': 'MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement', 'authors': 'Nikolai Lund Kühne, Jesper Jensen, Jan Østergaard, Zheng-Hua Tan', 'link': 'https://arxiv.org/abs/2507.00966', 'abstract': 'With the advent of new sequence models like Mamba and xLSTM, several studies have shown that these models match or outperform state-of-the-art models in single-channel speech enhancement, automatic speech recognition, and self-supervised audio representation learning. However, prior research has demonstrated that sequence models like LSTM and Mamba tend to overfit to the training set. To address this issue, previous works have shown that adding self-attention to LSTMs substantially improves generalization performance for single-channel speech enhancement. Nevertheless, neither the concept of hybrid Mamba and time-frequency attention models nor their generalization performance have been explored for speech enhancement. In this paper, we propose a novel hybrid architecture, MambAttention, which combines Mamba and shared time- and frequency-multi-head attention modules for generalizable single-channel speech enhancement. To train our model, we introduce VoiceBank+Demand Extended (VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging noise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our proposed MambAttention model significantly outperforms existing state-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar complexity across all reported metrics on two out-of-domain datasets: DNS 2020 and EARS-WHAM_v2, while matching their performance on the in-domain dataset VB-DemandEx. Ablation studies highlight the role of weight sharing between the time- and frequency-multi-head attention modules for generalization performance. Finally, we explore integrating the shared time- and frequency-multi-head attention modules with LSTM and xLSTM, which yields a notable performance improvement on the out-of-domain datasets. However, our MambAttention model remains superior on both out-of-domain datasets across all reported evaluation metrics.', 'abstract_zh': '基于Mamba和时频注意力机制的新型可泛化单通道语音增强模型', 'title_zh': 'MambAttention：带有多头注意力机制的Mamba在单声道语音增强中的通用应用'}
{'arxiv_id': 'arXiv:2507.00953', 'title': 'From Sentences to Sequences: Rethinking Languages in Biological System', 'authors': 'Ke Liu, Shuanke Shen, Hao Chen', 'link': 'https://arxiv.org/abs/2507.00953', 'abstract': 'The paradigm of large language models in natural language processing (NLP) has also shown promise in modeling biological languages, including proteins, RNA, and DNA. Both the auto-regressive generation paradigm and evaluation metrics have been transferred from NLP to biological sequence modeling. However, the intrinsic structural correlations in natural and biological languages differ fundamentally. Therefore, we revisit the notion of language in biological systems to better understand how NLP successes can be effectively translated to biological domains. By treating the 3D structure of biomolecules as the semantic content of a sentence and accounting for the strong correlations between residues or bases, we highlight the importance of structural evaluation and demonstrate the applicability of the auto-regressive paradigm in biological language modeling. Code can be found at \\href{this https URL}{this http URL}', 'abstract_zh': '大型语言模型在自然语言处理中的范式也显示出在建模蛋白质、RNA和DNA等生物语言方面的潜力。自回归生成范式及评估指标已被从自然语言处理领域转移到生物序列建模中。然而，自然和生物语言内部的结构相关性存在根本差异。因此，我们重新审视生物系统中的语言概念，以更好地理解自然语言处理的成功如何有效地转移到生物领域。通过将生物分子的三维结构视为句子的语义内容，并考虑残基或碱基之间的强相关性，我们强调了结构评估的重要性，并展示了自回归范式在生物语言建模中的适用性。代码详见 \\href{this https URL}{此链接}。', 'title_zh': '从句子到序列：重新思考生物学系统中的语言'}
{'arxiv_id': 'arXiv:2507.00938', 'title': 'WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks', 'authors': 'Zihao Sun, Meng Fang, Ling Chen', 'link': 'https://arxiv.org/abs/2507.00938', 'abstract': 'Recent progress in large language models (LLMs) has enabled the development of autonomous web agents capable of navigating and interacting with real websites. However, evaluating such agents remains challenging due to the instability and inconsistency of existing benchmarks, which often rely on dynamic content or oversimplified simulations. In this work, we introduce WebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks grounded in the arXiv platform. WebArXiv ensures reproducible and reliable evaluation by anchoring tasks in fixed web snapshots with deterministic ground truths and standardized action trajectories. Through behavioral analysis, we identify a common failure mode, Rigid History Reflection, where agents over-rely on fixed interaction histories. To address this, we propose a lightweight dynamic reflection mechanism that allows agents to selectively retrieve relevant past steps during decision-making. We evaluate ten state-of-the-art web agents on WebArXiv. Results demonstrate clear performance differences across agents and validate the effectiveness of our proposed reflection strategy.', 'abstract_zh': 'Recent进展在大型语言模型（LLMs）使得自主网页代理能够导航和与真实网站交互。然而，由于现有基准的不稳定性和不一致性，这些代理的评估仍然具有挑战性，这些基准往往依赖于动态内容或过于简化的模拟。在这项工作中，我们引入了WebArXiv，这是一个基于arXiv平台的静态和时间不变基准，包含275个网页任务。WebArXiv通过将任务锚定在固定网页快照上并具有确定的ground truths和标准化的动作轨迹，确保了可重复和可靠的评估。通过行为分析，我们发现一种常见的失败模式，即刚性历史反射，其中代理过度依赖固定的交互历史。为了解决这一问题，我们提出了一种轻量级的动态反射机制，允许代理在决策时选择性地检索相关的历史步骤。我们在WebArXiv上评估了十种最先进的网页代理。结果表明，代理之间的性能存在明显差异，并验证了我们提出的反射策略的有效性。', 'title_zh': 'WebArXiv: 评估多模态代理在时间不变的arXiv任务上的性能'}
{'arxiv_id': 'arXiv:2507.00914', 'title': 'Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications', 'authors': 'Jindong Han, Yansong Ning, Zirui Yuan, Hang Ni, Fan Liu, Tengfei Lyu, Hao Liu', 'link': 'https://arxiv.org/abs/2507.00914', 'abstract': 'The long-standing vision of intelligent cities is to create efficient, livable, and sustainable urban environments using big data and artificial intelligence technologies. Recently, the advent of Large Language Models (LLMs) has opened new ways toward realizing this vision. With powerful semantic understanding and reasoning capabilities, LLMs can be deployed as intelligent agents capable of autonomously solving complex problems across domains. In this article, we focus on Urban LLM Agents, which are LLM-powered agents that are semi-embodied within the hybrid cyber-physical-social space of cities and used for system-level urban decision-making. First, we introduce the concept of urban LLM agents, discussing their unique capabilities and features. Second, we survey the current research landscape from the perspective of agent workflows, encompassing urban sensing, memory management, reasoning, execution, and learning. Third, we categorize the application domains of urban LLM agents into five groups: urban planning, transportation, environment, public safety, and urban society, presenting representative works in each group. Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research. This survey aims to establish a foundation for the emerging field of urban LLM agents and to provide a roadmap for advancing the intersection of LLMs and urban intelligence. A curated list of relevant papers and open-source resources is maintained and continuously updated at this https URL.', 'abstract_zh': '智能城市的长久愿景是利用大数据和人工智能技术创建高效、宜居和可持续的城市环境。最近，大型语言模型（LLMs）的出现为实现这一愿景开辟了新的途径。凭借强大的语义理解和推理能力，LLMs可以部署为能在城市混合的赛博-物理-社会空间中半实体化的智能代理，用于系统级的城市决策。本文重点关注城市LLM代理，它们是 Powered by LLM 的代理，部分嵌入城市混合的赛博-物理-社会空间中，用于系统级的城市决策。首先，我们介绍城市LLM代理的概念，讨论其独特的能力和特性。其次，我们从代理工作流的角度回顾当前的研究状况，涵盖城市感知、记忆管理、推理、执行和学习。第三，我们将城市LLM代理的应用领域归类为五类：城市规划、交通、环境、公共安全和城市社会，并在每个领域展示代表性作品。最后，我们讨论对于实际部署至关重要的可信度和评估问题，并识别出若干未来研究亟待解决的问题。本文旨在为新兴的LLM城市代理领域建立基础，并为LLM与城市智能的交叉领域的发展提供路线图。相关论文和开源资源的精选列表在此 https://link/ 上持续维护和更新。', 'title_zh': '大型语言模型驱动的智能城市代理：概念、能力与应用'}
{'arxiv_id': 'arXiv:2507.00909', 'title': 'Turning AI Data Centers into Grid-Interactive Assets: Results from a Field Demonstration in Phoenix, Arizona', 'authors': 'Philip Colangelo, Ayse K. Coskun, Jack Megrue, Ciaran Roberts, Shayan Sengupta, Varun Sivaram, Ethan Tiao, Aroon Vijaykar, Chris Williams, Daniel C. Wilson, Zack MacFarland, Daniel Dreiling, Nathan Morey, Anuja Ratnayake, Baskar Vairamohan', 'link': 'https://arxiv.org/abs/2507.00909', 'abstract': "Artificial intelligence (AI) is fueling exponential electricity demand growth, threatening grid reliability, raising prices for communities paying for new energy infrastructure, and stunting AI innovation as data centers wait for interconnection to constrained grids. This paper presents the first field demonstration, in collaboration with major corporate partners, of a software-only approach--Emerald Conductor--that transforms AI data centers into flexible grid resources that can efficiently and immediately harness existing power systems without massive infrastructure buildout. Conducted at a 256-GPU cluster running representative AI workloads within a commercial, hyperscale cloud data center in Phoenix, Arizona, the trial achieved a 25% reduction in cluster power usage for three hours during peak grid events while maintaining AI quality of service (QoS) guarantees. By orchestrating AI workloads based on real-time grid signals without hardware modifications or energy storage, this platform reimagines data centers as grid-interactive assets that enhance grid reliability, advance affordability, and accelerate AI's development.", 'abstract_zh': '人工智能（AI）正推动电力需求以指数级速度增长，威胁电网可靠性，提高社区为新能源基础设施支付的价格，并限制数据中心因受限电网而推迟的AI创新。本文介绍了与主要企业合作伙伴合作进行的首个现场演示——Emerald Conductor软件解决方案，该解决方案将AI数据中心转变为灵活的电网资源，无需大规模基础设施建设即可高效且立即利用现有电力系统。在亚利桑那州菲尼克斯市一家商用大型云数据中心256 GPU集群上运行代表性AI工作负载时，试验期间在电网高峰事件中实现了集群电力使用量减少25%，同时保持AI服务质量（QoS）保证。通过基于实时电网信号调度AI工作负载，而不进行硬件修改或能量存储，该平台重新定义了数据中心作为能够增强电网可靠性、提高 affordability 并加速AI发展的电网互动资产。', 'title_zh': '将AI数据中心转变为电网互动资产：亚利桑那州凤凰城实地示范结果'}
{'arxiv_id': 'arXiv:2507.00907', 'title': 'The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses', 'authors': 'Fabio Correa Xavier', 'link': 'https://arxiv.org/abs/2507.00907', 'abstract': 'In a world where deepfakes and cloned voices are emerging as sophisticated attack vectors, organizations require a new security mindset: Sensorial Zero Trust [9]. This article presents a scientific analysis of the need to systematically doubt information perceived through the senses, establishing rigorous verification protocols to mitigate the risks of fraud based on generative artificial intelligence. Key concepts, such as Out-of-Band verification, Vision-Language Models (VLMs) as forensic collaborators, cryptographic provenance, and human training, are integrated into a framework that extends Zero Trust principles to human sensory information. The approach is grounded in empirical findings and academic research, emphasizing that in an era of AI-generated realities, even our eyes and ears can no longer be implicitly trusted without verification. Leaders are called to foster a culture of methodological skepticism to protect organizational integrity in this new threat landscape.', 'abstract_zh': '在深伪和克隆语音等高级攻击手段涌现的世界中，组织需要培养一种新的安全思维：感性零信任 [9]。本文对系统性怀疑感官获取的信息的必要性进行了科学分析，并建立了严格的验证程序，以减轻基于生成式人工智能的欺诈风险。该框架整合了外链验证、视觉语言模型（VLMs）作为法医合作者、加密溯源和人类培训等关键概念，将零信任原则扩展到人类感官信息。该方法基于实证发现和学术研究，强调在人工智能生成的现实时代，我们的视觉和听觉也不能再未经验证的情况下被隐含信任。领导者被呼吁培养一种方法论上的怀疑文化，以保护组织在这一新的威胁环境中免受侵害。', 'title_zh': '传感器信任零时代：我们为何不能再信任自己的感官'}
{'arxiv_id': 'arXiv:2507.00903', 'title': 'Deep learning-based segmentation of T1 and T2 cardiac MRI maps for automated disease detection', 'authors': 'Andreea Bianca Popescu, Andreas Seitz, Heiko Mahrholdt, Jens Wetzl, Athira Jacob, Lucian Mihai Itu, Constantin Suciu, Teodora Chitiboi', 'link': 'https://arxiv.org/abs/2507.00903', 'abstract': 'Objectives Parametric tissue mapping enables quantitative cardiac tissue characterization but is limited by inter-observer variability during manual delineation. Traditional approaches relying on average relaxation values and single cutoffs may oversimplify myocardial complexity. This study evaluates whether deep learning (DL) can achieve segmentation accuracy comparable to inter-observer variability, explores the utility of statistical features beyond mean T1/T2 values, and assesses whether machine learning (ML) combining multiple features enhances disease detection. Materials & Methods T1 and T2 maps were manually segmented. The test subset was independently annotated by two observers, and inter-observer variability was assessed. A DL model was trained to segment left ventricle blood pool and myocardium. Average (A), lower quartile (LQ), median (M), and upper quartile (UQ) were computed for the myocardial pixels and employed in classification by applying cutoffs or in ML. Dice similarity coefficient (DICE) and mean absolute percentage error evaluated segmentation performance. Bland-Altman plots assessed inter-user and model-observer agreement. Receiver operating characteristic analysis determined optimal cutoffs. Pearson correlation compared features from model and manual segmentations. F1-score, precision, and recall evaluated classification performance. Wilcoxon test assessed differences between classification methods, with p < 0.05 considered statistically significant. Results 144 subjects were split into training (100), validation (15) and evaluation (29) subsets. Segmentation model achieved a DICE of 85.4%, surpassing inter-observer agreement. Random forest applied to all features increased F1-score (92.7%, p < 0.001). Conclusion DL facilitates segmentation of T1/ T2 maps. Combining multiple features with ML improves disease detection.', 'abstract_zh': '基于深度学习的T1/T2图分割及其多特征组合对疾病检测的改善', 'title_zh': '基于深度学习的T1和T2心脏MRI分割方法及其在自动化疾病检测中的应用'}
{'arxiv_id': 'arXiv:2507.00902', 'title': 'Constellation as a Service: Tailored Connectivity Management in Direct-Satellite-to-Device Networks', 'authors': 'Feng Wang, Shengyu Zhang, Een-Kee Hong, Tony Q.S. Quek', 'link': 'https://arxiv.org/abs/2507.00902', 'abstract': 'Direct-satellite-to-device (DS2D) communication is emerging as a promising solution for global mobile service extension, leveraging the deployment of satellite constellations. However, the challenge of managing DS2D connectivity for multi-constellations becomes outstanding, including high interference and frequent handovers caused by multi-coverage overlap and rapid satellite movement. Moreover, existing approaches primarily operate within single-constellation shell, which inherently limits the ability to exploit the vast potential of multi-constellation connectivity provision, resulting in suboptimal DS2D service performances. To address these challenges, this article proposes a Constellation as a Service (CaaS) framework, which treats the entire multi-constellation infrastructure as a shared resource pool and dynamically forms optimal sub-constellations (SCs) for each DS2D service region. The formation of each SC integrates satellites from various orbits to provide tailored connectivity based on user demands, guided by two innovative strategies: predictive satellite beamforming using generative artificial intelligence (GenAI) and pre-configured handover path for efficient satellite access and mobility management. Simulation results demonstrate that CaaS significantly improves satellite service rates while reducing handover overhead, making it an efficient and continuable solution for managing DS2D connectivity in multi-constellation environments.', 'abstract_zh': '多星系直接卫星到设备通信的服务即星（CaaS）框架', 'title_zh': '服务化的星座：直接卫星到设备网络中定制化的连接管理'}
{'arxiv_id': 'arXiv:2507.00891', 'title': 'MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes', 'authors': 'Yuheng Wang, Xianhe Tang, Pufeng Huang', 'link': 'https://arxiv.org/abs/2507.00891', 'abstract': 'Memes are widely used in online social interactions, providing vivid, intuitive, and often humorous means to express intentions and emotions. Existing dialogue datasets are predominantly limited to either manually annotated or pure-text conversations, lacking the expressiveness and contextual nuance that multimodal interactions this http URL address these challenges, we introduce MemeCMD, an automatically generated Chinese Multi-turn Dialogue dataset with contextually retrieved memes. Our dataset combines a large-scale, MLLM-annotated meme library with dialogues auto-generated by dual agents across diverse scenarios. We introduce a retrieval framework and adaptive threshold to ensure contextually relevant, naturally spaced meme usage. Experiments demonstrate the effectiveness of our approach in generating contextually appropriate and diverse meme-incorporated dialogues, offering a scalable and privacy-preserving resource for advancing multimodal conversational AI.', 'abstract_zh': 'MEME-CMD：一个基于上下文检索的自动生成多轮中文对话数据集', 'title_zh': 'MemeCMD：一个基于上下文检索的表情包自动生成的中文多轮对话数据集'}
{'arxiv_id': 'arXiv:2507.00880', 'title': 'NN-Former: Rethinking Graph Structure in Neural Architecture Representation', 'authors': 'Ruihan Xu, Haokui Zhang, Yaowei Wang, Wei Zeng, Shiliang Zhang', 'link': 'https://arxiv.org/abs/2507.00880', 'abstract': 'The growing use of deep learning necessitates efficient network design and deployment, making neural predictors vital for estimating attributes such as accuracy and latency. Recently, Graph Neural Networks (GNNs) and transformers have shown promising performance in representing neural architectures. However, each of both methods has its disadvantages. GNNs lack the capabilities to represent complicated features, while transformers face poor generalization when the depth of architecture grows. To mitigate the above issues, we rethink neural architecture topology and show that sibling nodes are pivotal while overlooked in previous research. We thus propose a novel predictor leveraging the strengths of GNNs and transformers to learn the enhanced topology. We introduce a novel token mixer that considers siblings, and a new channel mixer named bidirectional graph isomorphism feed-forward network. Our approach consistently achieves promising performance in both accuracy and latency prediction, providing valuable insights for learning Directed Acyclic Graph (DAG) topology. The code is available at this https URL.', 'abstract_zh': '深度学习的广泛应用 necessitates 有效的网络设计与部署，使得神经预测器在估计准确性和延迟等属性方面变得至关重要。近年来，图神经网络（GNNs）和变压器在表示神经架构方面展现了令人 hopeful 的性能。然而，这两种方法各有利弊。GNNs 在表示复杂特征方面能力不足，而变压器在架构深度增加时泛化性能较差。为解决上述问题，我们重新思考神经架构拓扑，并指出兄弟节点在之前的研究中被忽视但却是关键的。我们因此提出一种新的预测器，充分利用GNNs 和变压器的优点来学习改进的拓扑结构。我们引入了一种考虑兄弟节点的新型 token 混合器，并提出了一种新的通道混合器，称为双向图同构前馈网络。我们的方法在准确性和延迟预测方面始终表现出令人 hopeful 的性能，为学习有向无环图（DAG）拓扑提供了有价值的见解。代码可在以下链接获取：this https URL。', 'title_zh': 'NN-Former: 重新思考神经架构表示中的图形结构'}
{'arxiv_id': 'arXiv:2507.00838', 'title': 'Stylometry recognizes human and LLM-generated texts in short samples', 'authors': 'Karol Przystalski, Jan K. Argasiński, Iwona Grabska-Gradzińska, Jeremi K. Ochab', 'link': 'https://arxiv.org/abs/2507.00838', 'abstract': 'The paper explores stylometry as a method to distinguish between texts created by Large Language Models (LLMs) and humans, addressing issues of model attribution, intellectual property, and ethical AI use. Stylometry has been used extensively to characterise the style and attribute authorship of texts. By applying it to LLM-generated texts, we identify their emergent writing patterns. The paper involves creating a benchmark dataset based on Wikipedia, with (a) human-written term summaries, (b) texts generated purely by LLMs (GPT-3.5/4, LLaMa 2/3, Orca, and Falcon), (c) processed through multiple text summarisation methods (T5, BART, Gensim, and Sumy), and (d) rephrasing methods (Dipper, T5). The 10-sentence long texts were classified by tree-based models (decision trees and LightGBM) using human-designed (StyloMetrix) and n-gram-based (our own pipeline) stylometric features that encode lexical, grammatical, syntactic, and punctuation patterns. The cross-validated results reached a performance of up to .87 Matthews correlation coefficient in the multiclass scenario with 7 classes, and accuracy between .79 and 1. in binary classification, with the particular example of Wikipedia and GPT-4 reaching up to .98 accuracy on a balanced dataset. Shapley Additive Explanations pinpointed features characteristic of the encyclopaedic text type, individual overused words, as well as a greater grammatical standardisation of LLMs with respect to human-written texts. These results show -- crucially, in the context of the increasingly sophisticated LLMs -- that it is possible to distinguish machine- from human-generated texts at least for a well-defined text type.', 'abstract_zh': '本文探讨了将文体统计学作为区分由大型语言模型（LLMs）和人类创作的文本的方法，解决模型归因、知识产权和伦理AI使用等问题。通过广泛使用文体统计学来表征文本风格和归属作者，本文将它应用于LLM生成的文本，以识别其新兴的写作模式。本文基于维基百科创建了一个基准数据集，包括（a）由人类撰写的术语摘要，（b）由LLM（GPT-3.5/4、LLaMa 2/3、Orca和Falcon）纯生成的文本，（c）经过多种文本摘要方法（T5、BART、Gensim和Sumy）处理的文本，以及（d）通过改写方法（Dipper、T5）处理的文本。10句长的文本由基于树的模型（决策树和LightGBM）分类，使用人类设计（StyloMetrix）和基于n-克gram（我们的管道）的文体统计学特征，这些特征编码了词汇、语法、句法和标点符号模式。交叉验证结果在多类场景中达到了高达0.87的马特ews相关系数，在二分类中达到了0.79至1.0的准确率，特别是在维基百科和GPT-4的平衡数据集上达到了高达0.98的准确率。Shapley加性解释指出了百科全书文本类型特有的特征、过度使用的个别词汇，以及LLM相对于人类撰写的文本在语法标准性方面的更高程度的统一。这些结果显示，在日益复杂的LLM背景下，至少对于一种明确的文本类型，有可能区分机器生成的文本和人类生成的文本。', 'title_zh': '文体学识别短样本中的人类生成和LLM生成文本'}
{'arxiv_id': 'arXiv:2507.00833', 'title': 'HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning', 'authors': 'Zhi Jing, Siyuan Yang, Jicong Ao, Ting Xiao, Yugang Jiang, Chenjia Bai', 'link': 'https://arxiv.org/abs/2507.00833', 'abstract': 'For robotic manipulation, existing robotics datasets and simulation benchmarks predominantly cater to robot-arm platforms. However, for humanoid robots equipped with dual arms and dexterous hands, simulation tasks and high-quality demonstrations are notably lacking. Bimanual dexterous manipulation is inherently more complex, as it requires coordinated arm movements and hand operations, making autonomous data collection challenging. This paper presents HumanoidGen, an automated task creation and demonstration collection framework that leverages atomic dexterous operations and LLM reasoning to generate relational constraints. Specifically, we provide spatial annotations for both assets and dexterous hands based on the atomic operations, and perform an LLM planner to generate a chain of actionable spatial constraints for arm movements based on object affordances and scenes. To further improve planning ability, we employ a variant of Monte Carlo tree search to enhance LLM reasoning for long-horizon tasks and insufficient annotation. In experiments, we create a novel benchmark with augmented scenarios to evaluate the quality of the collected data. The results show that the performance of the 2D and 3D diffusion policies can scale with the generated dataset. Project page is this https URL.', 'abstract_zh': '用于类人机器人的二元灵巧操作模拟任务和高质量示范数据集匮乏：HumanoidGen——基于原子灵巧操作和LLM推理的自动化任务创建与示范收集框架', 'title_zh': 'HumanoidGen: 通过LLM推理进行双臂灵巧操作的数据生成'}
{'arxiv_id': 'arXiv:2507.00832', 'title': 'Automated anatomy-based post-processing reduces false positives and improved interpretability of deep learning intracranial aneurysm detection', 'authors': 'Jisoo Kim, Chu-Hsuan Lin, Alberto Ceballos-Arroyo, Ping Liu, Huaizu Jiang, Shrikanth Yadav, Qi Wan, Lei Qin, Geoffrey S Young', 'link': 'https://arxiv.org/abs/2507.00832', 'abstract': 'Introduction: Deep learning (DL) models can help detect intracranial aneurysms on CTA, but high false positive (FP) rates remain a barrier to clinical translation, despite improvement in model architectures and strategies like detection threshold tuning. We employed an automated, anatomy-based, heuristic-learning hybrid artery-vein segmentation post-processing method to further reduce FPs. Methods: Two DL models, CPM-Net and a deformable 3D convolutional neural network-transformer hybrid (3D-CNN-TR), were trained with 1,186 open-source CTAs (1,373 annotated aneurysms), and evaluated with 143 held-out private CTAs (218 annotated aneurysms). Brain, artery, vein, and cavernous venous sinus (CVS) segmentation masks were applied to remove possible FPs in the DL outputs that overlapped with: (1) brain mask; (2) vein mask; (3) vein more than artery masks; (4) brain plus vein mask; (5) brain plus vein more than artery masks. Results: CPM-Net yielded 139 true-positives (TP); 79 false-negative (FN); 126 FP. 3D-CNN-TR yielded 179 TP; 39 FN; 182 FP. FPs were commonly extracranial (CPM-Net 27.3%; 3D-CNN-TR 42.3%), venous (CPM-Net 56.3%; 3D-CNN-TR 29.1%), arterial (CPM-Net 11.9%; 3D-CNN-TR 53.3%), and non-vascular (CPM-Net 25.4%; 3D-CNN-TR 9.3%) structures. Method 5 performed best, reducing CPM-Net FP by 70.6% (89/126) and 3D-CNN-TR FP by 51.6% (94/182), without reducing TP, lowering the FP/case rate from 0.88 to 0.26 for CPM-NET, and from 1.27 to 0.62 for the 3D-CNN-TR. Conclusion: Anatomy-based, interpretable post-processing can improve DL-based aneurysm detection model performance. More broadly, automated, domain-informed, hybrid heuristic-learning processing holds promise for improving the performance and clinical acceptance of aneurysm detection models.', 'abstract_zh': '引言：深度学习（DL）模型可以辅助在CTA中检测颅内动脉瘤，尽管模型架构和策略（如检测阈值调整）的改进在降低假阳性率方面取得了一定进展，但高假阳性率仍然是临床应用的障碍。我们采用了一种基于解剖特征的自动启发式学习混合动脉-静脉分割后处理方法，进一步降低了假阳性率。\n\n方法：使用1,186个开源CTA（1,373个标注的动脉瘤）训练了两个DL模型，CPM-Net和变形3D卷积神经网络-变压器混合体（3D-CNN-TR），并在143个预留的私有CTA（218个标注的动脉瘤）上进行了评估。应用脑、动脉、静脉和硬脑膜静脉窦分割掩膜来移除DL输出中与以下内容重叠的可能假阳性：（1）脑掩膜；（2）静脉掩膜；（3）静脉大于动脉掩膜；（4）脑加静脉掩膜；（5）脑加静脉大于动脉掩膜。\n\n结果：CPM-Net产生了139个真阳性（TP）；79个假阴性（FN）；126个假阳性（FP）。3D-CNN-TR产生了179个TP；39个FN；182个FP。假阳性主要为颅外结构（CPM-Net 27.3%；3D-CNN-TR 42.3%）、静脉结构（CPM-Net 56.3%；3D-CNN-TR 29.1%）、动脉结构（CPM-Net 11.9%；3D-CNN-TR 53.3%）和非血管结构（CPM-Net 25.4%；3D-CNN-TR 9.3%）。方法5效果最佳，减少了CPM-Net 70.6%（89/126）和3D-CNN-TR 51.6%（94/182）的假阳性，而不减少真阳性，将CPM-NET的假阳性/例率从0.88降低到0.26，3D-CNN-TR的假阳性/例率从1.27降低到0.62。\n\n结论：基于解剖特征的可解释后处理可以提高基于DL的动脉瘤检测模型的性能。更广泛地说，自动化、领域驱动的混合启发式学习处理有潜力提高动脉瘤检测模型的性能和临床接受度。', 'title_zh': '基于自动解剖学的后处理方法减少假阳性并提高颅内动脉瘤检测的可解释性'}
{'arxiv_id': 'arXiv:2507.00817', 'title': 'CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs', 'authors': 'Jiaming Zhang, Rui Hu, Qing Guo, Wei Yang Bryan Lim', 'link': 'https://arxiv.org/abs/2507.00817', 'abstract': "Video Multimodal Large Language Models (V-MLLMs) have shown impressive capabilities in temporal reasoning and cross-modal understanding, yet their vulnerability to adversarial attacks remains underexplored due to unique challenges: complex cross-modal reasoning mechanisms, temporal dependencies, and computational constraints. We present CAVALRY-V (Cross-modal Language-Vision Adversarial Yielding for Videos), a novel framework that directly targets the critical interface between visual perception and language generation in V-MLLMs. Our approach introduces two key innovations: (1) a dual-objective semantic-visual loss function that simultaneously disrupts the model's text generation logits and visual representations to undermine cross-modal integration, and (2) a computationally efficient two-stage generator framework that combines large-scale pre-training for cross-model transferability with specialized fine-tuning for spatiotemporal coherence. Empirical evaluation on comprehensive video understanding benchmarks demonstrates that CAVALRY-V significantly outperforms existing attack methods, achieving 22.8% average improvement over the best baseline attacks on both commercial systems (GPT-4.1, Gemini 2.0) and open-source models (QwenVL-2.5, InternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6). Our framework achieves flexibility through implicit temporal coherence modeling rather than explicit regularization, enabling significant performance improvements even on image understanding (34.4% average gain). This capability demonstrates CAVALRY-V's potential as a foundational approach for adversarial research across multimodal systems.", 'abstract_zh': '跨模态语言-视觉对抗生成的CAVALRY-V框架：视频多模态大语言模型的对抗性研究', 'title_zh': 'CAVALRY-V：针对视频MLLMs的大型生成器框架 adversarial攻击'}
{'arxiv_id': 'arXiv:2507.00816', 'title': 'PI-WAN: A Physics-Informed Wind-Adaptive Network for Quadrotor Dynamics Prediction in Unknown Environments', 'authors': 'Mengyun Wang, Bo Wang, Yifeng Niu, Chang Wang', 'link': 'https://arxiv.org/abs/2507.00816', 'abstract': 'Accurate dynamics modeling is essential for quadrotors to achieve precise trajectory tracking in various applications. Traditional physical knowledge-driven modeling methods face substantial limitations in unknown environments characterized by variable payloads, wind disturbances, and external perturbations. On the other hand, data-driven modeling methods suffer from poor generalization when handling out-of-distribution (OoD) data, restricting their effectiveness in unknown scenarios. To address these challenges, we introduce the Physics-Informed Wind-Adaptive Network (PI-WAN), which combines knowledge-driven and data-driven modeling methods by embedding physical constraints directly into the training process for robust quadrotor dynamics learning. Specifically, PI-WAN employs a Temporal Convolutional Network (TCN) architecture that efficiently captures temporal dependencies from historical flight data, while a physics-informed loss function applies physical principles to improve model generalization and robustness across previously unseen conditions. By incorporating real-time prediction results into a model predictive control (MPC) framework, we achieve improvements in closed-loop tracking performance. Comprehensive simulations and real-world flight experiments demonstrate that our approach outperforms baseline methods in terms of prediction accuracy, tracking precision, and robustness to unknown environments.', 'abstract_zh': '基于物理知识和风适应的网络（PI-WAN）：用于四旋翼精确轨迹跟踪的动力学建模', 'title_zh': 'PI-WAN：一种适应风力的物理导向网络，用于未知环境中四旋翼动力学预测'}
{'arxiv_id': 'arXiv:2507.00814', 'title': 'Many LLMs Are More Utilitarian Than One', 'authors': 'Anita Keshmirian, Razan Baltaji, Babak Hemmatian, Hadi Asghari, Lav R. Varshney', 'link': 'https://arxiv.org/abs/2507.00814', 'abstract': 'Moral judgment is integral to large language model (LLM) alignment and social reasoning. As multi-agent systems gain prominence, it becomes crucial to understand how LLMs function collectively during collaboration, compared to individual agents. In human moral judgment, group deliberation leads to a utilitarian boost: a tendency to endorse norm violations that maximize benefits for the greatest number of people despite harms. We study whether a similar dynamic emerges in multi-agent LLM systems. We tested six models on well-established sets of moral dilemmas across two conditions: (1) Solo, where models reasoned independently, and (2) Group, where they engaged in multi-turn discussions in pairs or triads. In personal moral dilemmas, where agents must decide to directly harm one individual to maximize the utility for others, all models found moral violations to be more acceptable when part of a group than individually, similar to human experiments. Some models endorsed actions that maximized overall well-being, even if they benefited strangers over familiar individuals. Others became more willing to violate moral norms in groups. However, while human groups show a similar action bias, the mechanism for their utilitarian boost differs from LLMs. Whereas the human shift comes from heightened sensitivity to decision outcomes, LLM groups show either reduced norm sensitivity or enhanced impartiality. This suggests that while the surface behavior of LLM collectives mimics human group reasoning, the underlying drivers differ. We discuss the implications for AI alignment, multi-agent design, and artificial moral reasoning.', 'abstract_zh': '道德判断是大规模语言模型（LLM）对齐和社会推理的关键组成部分。随着多智能体系统的兴起，理解LLM在合作中集体运行机制与其个体运行机制之间的差异变得至关重要。在人类道德判断中，团体审议带来了功利主义的提升：倾向于支持那些虽有害但能惠及最大多数人的规范违反行为。我们研究了类似动态是否在多智能体LLM系统中出现。我们测试了六种模型在两类道德困境上的表现：（1）独立模式，模型独立推理；（2）团体模式，模型以对话语轮或三人组的形式进行讨论。在涉及个体必须决定直接伤害某人以最大化他人的福利的个人道德困境中，所有模型在团体中比单独时认为道德违规行为更为可接受，类似于人类实验的结果。有些模型支持有利于整体福祉的行为，即便这些行为惠及陌生人而非熟人。其他模型则在团体中更愿意违反道德规范。然而，尽管人类团体表现出类似的行为偏见，其功利主义提升的机制与LLM不同。人类的转变来自对决策结果的敏感度增加，而LLM团体则显示出规范敏感度的降低或倾向于更公平的处理。这表明虽然LLM集体的表面行为模仿了人类团体推理，但底层驱动因素却不同。我们讨论了这些发现对AI对齐、多智能体设计和人工道德推理的含义。', 'title_zh': '许多大型语言模型比单一模型更具实用性。'}
{'arxiv_id': 'arXiv:2507.00790', 'title': 'LD-RPS: Zero-Shot Unified Image Restoration via Latent Diffusion Recurrent Posterior Sampling', 'authors': 'Huaqiu Li, Yong Wang, Tongwen Huang, Hailang Huang, Haoqian Wang, Xiangxiang Chu', 'link': 'https://arxiv.org/abs/2507.00790', 'abstract': 'Unified image restoration is a significantly challenging task in low-level vision. Existing methods either make tailored designs for specific tasks, limiting their generalizability across various types of degradation, or rely on training with paired datasets, thereby suffering from closed-set constraints. To address these issues, we propose a novel, dataset-free, and unified approach through recurrent posterior sampling utilizing a pretrained latent diffusion model. Our method incorporates the multimodal understanding model to provide sematic priors for the generative model under a task-blind condition. Furthermore, it utilizes a lightweight module to align the degraded input with the generated preference of the diffusion model, and employs recurrent refinement for posterior sampling. Extensive experiments demonstrate that our method outperforms state-of-the-art methods, validating its effectiveness and robustness. Our code and data will be available at this https URL.', 'abstract_zh': '统一图像恢复是低级视觉中的一个显著挑战任务。现有的方法要么为特定任务设计专门的方案，限制了其在各种退化类型上的泛化能力，要么依赖配对数据集训练，因而受到闭集约束。为解决这些问题，我们提出了一种新的、无需数据集、统一的方法，通过预先训练的潜在扩散模型进行循环后验采样。该方法结合多模态理解模型，在无任务约束条件下为生成模型提供语义先验。此外，利用轻量级模块将退化输入与扩散模型生成的偏好对齐，并采用循环细化进行后验采样。广泛的实验表明，我们的方法优于现有先进方法，验证了其有效性和鲁棒性。相关代码和数据将在该网页获取。', 'title_zh': 'LD-RPS: 零样本统一图像恢复 via 潜在扩散递归后验采样'}
{'arxiv_id': 'arXiv:2507.00788', 'title': 'Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability', 'authors': 'Markus Borg, Dave Hewett, Nadim Hagatulah, Noric Couderc, Emma Söderberg, Donald Graham, Uttam Kini, Dave Farley', 'link': 'https://arxiv.org/abs/2507.00788', 'abstract': '[Context] AI assistants, like GitHub Copilot and Cursor, are transforming software engineering. While several studies highlight productivity improvements, their impact on maintainability requires further investigation. [Objective] This study investigates whether co-development with AI assistants affects software maintainability, specifically how easily other developers can evolve the resulting source code. [Method] We conducted a two-phase controlled experiment involving 151 participants, 95% of whom were professional developers. In Phase 1, participants added a new feature to a Java web application, with or without AI assistance. In Phase 2, a randomized controlled trial, new participants evolved these solutions without AI assistance. [Results] AI-assisted development in Phase 1 led to a modest speedup in subsequent evolution and slightly higher average CodeHealth. Although neither difference was significant overall, the increase in CodeHealth was statistically significant when habitual AI users completed Phase 1. For Phase 1, we also observed a significant effect that corroborates previous productivity findings: using an AI assistant yielded a 30.7% median decrease in task completion time. Moreover, for habitual AI users, the mean speedup was 55.9%. [Conclusions] Our study adds to the growing evidence that AI assistants can effectively accelerate development. Moreover, we did not observe warning signs of degraded code-level maintainability. We recommend that future research focus on risks such as code bloat from excessive code generation and the build-up of cognitive debt as developers invest less mental effort during implementation.', 'abstract_zh': 'AI辅助开发对软件维护性的影响研究：专业开发者参与的两阶段受控实验', 'title_zh': 'AI回声：探究AI Assistants对软件可维护性的影响'}
{'arxiv_id': 'arXiv:2507.00769', 'title': 'LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing', 'authors': 'Daniel Fein, Sebastian Russo, Violet Xiang, Kabir Jolly, Rafael Rafailov, Nick Haber', 'link': 'https://arxiv.org/abs/2507.00769', 'abstract': 'Evaluating creative writing generated by large language models (LLMs) remains challenging because open-ended narratives lack ground truths. Without performant automated evaluation methods, off-the-shelf (OTS) language models are employed as zero-shot judges, yet their reliability is unclear in this context. In pursuit of robust evaluation for creative writing, we introduce LitBench, the first standardized benchmark and paired dataset for creative writing verification, comprising a held-out test set of 2,480 debiased, human-labeled story comparisons drawn from Reddit and a 43,827-pair training corpus of human preference labels. Using LitBench, we (i) benchmark zero-shot LLM judges, (ii) train Bradley Terry and generative reward models, and (iii) conduct an online human study to validate reward model rankings on newly LLM-generated stories. Our benchmark identifies Claude-3.7-Sonnet as the strongest off-the-shelf judge, reaching 73% agreement with human preferences; among trained reward models, Bradley-Terry and Generative reward models both attain an accuracy of 78%, outperforming all off-the-shelf judges. An online human study further confirms that our trained reward models consistently align with human preferences in novel LLM-generated stories. We release LitBench and reward models at this https URL, providing a vetted resource for reliable, automated evaluation and optimization of creative writing systems.', 'abstract_zh': '评估大型语言模型生成的创意写作仍具有挑战性，因为开放式的叙述缺乏 ground truths。缺乏高效的自动化评估方法，研究中使用了现成的语言模型作为零样本法官，但其可靠性在这一背景下尚不清楚。为了实现创意写作的稳健评估，我们引入了LitBench——首个标准化的创意写作验证基准和配对数据集，包含来自Reddit的2480个去偏见的人工标注故事对比测试集和43827对人工偏好标签的训练语料库。使用LitBench，我们（i） benchmark 了零样本 LLM 法官，（ii）训练了Bradley Terry和生成奖励模型，（iii）进行在线人类研究以验证奖励模型在新生成的LLM故事上的排名。我们的基准模型将Claude-3.7-Sonnet识别为最强的现成法官，其一致性达到73%；在训练的奖励模型中，Bradley-Terry模型和生成奖励模型都达到了78%的准确率，超越了所有现成的法官。在线人类研究进一步证实，我们的训练奖励模型在新的LLM生成故事中始终与人类偏好保持一致。我们在此网址https://提供LitBench和奖励模型，为创意写作系统的可靠和自动化评估与优化提供验证资源。', 'title_zh': 'LitBench: 用于创意写作可信评估的基准和数据集'}
{'arxiv_id': 'arXiv:2507.00755', 'title': 'LearnAFE: Circuit-Algorithm Co-design Framework for Learnable Audio Analog Front-End', 'authors': 'Jinhai Hu, Zhongyi Zhang, Cong Sheng Leow, Wang Ling Goh, Yuan Gao', 'link': 'https://arxiv.org/abs/2507.00755', 'abstract': "This paper presents a circuit-algorithm co-design framework for learnable analog front-end (AFE) in audio signal classification. Designing AFE and backend classifiers separately is a common practice but non-ideal, as shown in this paper. Instead, this paper proposes a joint optimization of the backend classifier with the AFE's transfer function to achieve system-level optimum. More specifically, the transfer function parameters of an analog bandpass filter (BPF) bank are tuned in a signal-to-noise ratio (SNR)-aware training loop for the classifier. Using a co-design loss function LBPF, this work shows superior optimization of both the filter bank and the classifier. Implemented in open-source SKY130 130nm CMOS process, the optimized design achieved 90.5%-94.2% accuracy for 10-keyword classification task across a wide range of input signal SNR from 5 dB to 20 dB, with only 22k classifier parameters. Compared to conventional approach, the proposed audio AFE achieves 8.7% and 12.9% reduction in power and capacitor area respectively.", 'abstract_zh': '这种论文提出了一种适用于音频信号分类的可学习模拟前端（AFE）电路-算法协同设计框架。', 'title_zh': 'LearnAFE：可学习音频模拟前端的电路-算法联合设计框架'}
{'arxiv_id': 'arXiv:2507.00724', 'title': 'Holmes: Towards Effective and Harmless Model Ownership Verification to Personalized Large Vision Models via Decoupling Common Features', 'authors': 'Linghui Zhu, Yiming Li, Haiqin Weng, Yan Liu, Tianwei Zhang, Shu-Tao Xia, Zhi Wang', 'link': 'https://arxiv.org/abs/2507.00724', 'abstract': 'Large vision models achieve remarkable performance in various downstream tasks, primarily by personalizing pre-trained models through fine-tuning with private and valuable local data, which makes the personalized model a valuable intellectual property for its owner. Similar to the era of traditional DNNs, model stealing attacks also pose significant risks to these personalized models. However, in this paper, we reveal that most existing defense methods (developed for traditional DNNs), typically designed for models trained from scratch, either introduce additional security risks, are prone to misjudgment, or are even ineffective for fine-tuned models. To alleviate these problems, this paper proposes a harmless model ownership verification method for personalized models by decoupling similar common features. In general, our method consists of three main stages. In the first stage, we create shadow models that retain common features of the victim model while disrupting dataset-specific features. We represent the dataset-specific features of the victim model by the output differences between the shadow and victim models. After that, a meta-classifier is trained to identify stolen models by determining whether suspicious models contain the dataset-specific features of the victim. In the third stage, we conduct model ownership verification by hypothesis test to mitigate randomness and enhance robustness. Extensive experiments on benchmark datasets verify the effectiveness of the proposed method in detecting different types of model stealing simultaneously.', 'abstract_zh': '大型视觉模型通过Fine-tuning与私有数据结合，实现了各类下游任务的卓越性能，这些个性化模型成为其所有者的宝贵知识产权。然而，与传统DNN时代类似，模型窃取攻击也对这些个性化模型构成了重大风险。本文揭示，大多数现有防御方法（针对传统DNN设计），通常针对从头训练的模型，要么引入额外的安全风险，要么容易误判，甚至对Fine-tuned模型无效。为解决这些问题，本文提出了一种通过解耦常见特征来无害地验证个性化模型所有权的方法。总体而言，该方法分为三个主要阶段。首先，我们创建影子模型，保留受害模型的共性特征同时破坏数据集特定特征。我们通过计算影子模型和受害模型的输出差异来表示受害模型的数据集特定特征。然后，训练一个元分类器来识别被窃取模型，通过判断可疑模型是否包含受害模型的数据集特定特征来进行。在第三阶段，我们通过假设检验来进行模型所有权验证，以减轻随机性和增强鲁棒性。基准数据集上的 extensive 实验验证了该方法在同时检测不同类型的模型窃取方面的有效性。', 'title_zh': 'Holmes: 通过解耦通用特征以实现个性化大型视觉模型的有效且无害的所有权验证'}
{'arxiv_id': 'arXiv:2507.00709', 'title': 'TopoStreamer: Temporal Lane Segment Topology Reasoning in Autonomous Driving', 'authors': 'Yiming Yang, Yueru Luo, Bingkun He, Hongbin Lin, Suzhong Fu, Chao Yan, Kun Tang, Xinrui Yan, Chao Zheng, Shuguang Cui, Zhen Li', 'link': 'https://arxiv.org/abs/2507.00709', 'abstract': 'Lane segment topology reasoning constructs a comprehensive road network by capturing the topological relationships between lane segments and their semantic types. This enables end-to-end autonomous driving systems to perform road-dependent maneuvers such as turning and lane changing. However, the limitations in consistent positional embedding and temporal multiple attribute learning in existing methods hinder accurate roadnet reconstruction. To address these issues, we propose TopoStreamer, an end-to-end temporal perception model for lane segment topology reasoning. Specifically, TopoStreamer introduces three key improvements: streaming attribute constraints, dynamic lane boundary positional encoding, and lane segment denoising. The streaming attribute constraints enforce temporal consistency in both centerline and boundary coordinates, along with their classifications. Meanwhile, dynamic lane boundary positional encoding enhances the learning of up-to-date positional information within queries, while lane segment denoising helps capture diverse lane segment patterns, ultimately improving model performance. Additionally, we assess the accuracy of existing models using a lane boundary classification metric, which serves as a crucial measure for lane-changing scenarios in autonomous driving. On the OpenLane-V2 dataset, TopoStreamer demonstrates significant improvements over state-of-the-art methods, achieving substantial performance gains of +3.4% mAP in lane segment perception and +2.1% OLS in centerline perception tasks.', 'abstract_zh': '车道段拓扑推理构建通过捕获车道段及其语义类型的拓扑关系来构成全面的道路网络，从而为端到端的自主驾驶系统执行道路依赖的操作，如转向和变道提供支持。然而，现有方法中一致的位置嵌入和时间多属性学习的局限性阻碍了准确的道路网重构。为解决这些问题，我们提出TopoStreamer，一种端到端的时间感知模型，用于车道段拓扑推理。具体而言，TopoStreamer引入了三个关键改进：流式属性约束、动态车道边界位置编码和车道段去噪。流式属性约束确保中心线和边界坐标及其分类在时间上的一致性。同时，动态车道边界位置编码增强了查询中最新的位置信息学习，而车道段去噪有助于捕捉多样化的车道段模式，最终提高模型性能。此外，我们使用车道边界分类指标评估现有模型的准确性，该指标是自主驾驶场景中变道情境的关键衡量指标。在OpenLane-V2数据集上，TopoStreamer在车道段感知任务中相较于现有最佳方法取得了显著改进，分别在车道段感知和中心线感知任务中实现了多达3.4%的mAP和2.1%的OLS的性能提升。', 'title_zh': 'TopoStreamer: 自主驾驶中基于时间的车道段拓扑推理'}
{'arxiv_id': 'arXiv:2507.00669', 'title': 'Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding', 'authors': 'Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang', 'link': 'https://arxiv.org/abs/2507.00669', 'abstract': '3D Visual Grounding (3DVG) involves localizing target objects in 3D point clouds based on natural language. While prior work has made strides using textual descriptions, leveraging spoken language-known as Audio-based 3D Visual Grounding-remains underexplored and challenging. Motivated by advances in automatic speech recognition (ASR) and speech representation learning, we propose Audio-3DVG, a simple yet effective framework that integrates audio and spatial information for enhanced grounding. Rather than treating speech as a monolithic input, we decompose the task into two complementary components. First, we introduce Object Mention Detection, a multi-label classification task that explicitly identifies which objects are referred to in the audio, enabling more structured audio-scene reasoning. Second, we propose an Audio-Guided Attention module that captures interactions between candidate objects and relational speech cues, improving target discrimination in cluttered scenes. To support benchmarking, we synthesize audio descriptions for standard 3DVG datasets, including ScanRefer, Sr3D, and Nr3D. Experimental results demonstrate that Audio-3DVG not only achieves new state-of-the-art performance in audio-based grounding, but also competes with text-based methods-highlighting the promise of integrating spoken language into 3D vision tasks.', 'abstract_zh': '基于音频的3D视觉定位（Audio-3DVG）：结合音频和空间信息的简单有效框架', 'title_zh': '音频-3DVG：统一的音频-点云融合用于三维视觉定位'}
{'arxiv_id': 'arXiv:2507.00665', 'title': 'SAFER: Probing Safety in Reward Models with Sparse Autoencoder', 'authors': 'Sihang Li, Wei Shi, Ziyuan Xie, Tao Liang, Guojun Ma, Xiang Wang', 'link': 'https://arxiv.org/abs/2507.00665', 'abstract': 'Reinforcement learning from human feedback (RLHF) is a key paradigm for aligning large language models (LLMs) with human values, yet the reward models at its core remain largely opaque. In this work, we present sparse Autoencoder For Enhanced Reward model (\\textbf{SAFER}), a novel framework for interpreting and improving reward models through mechanistic analysis. Leveraging Sparse Autoencoders (SAEs), we uncover human-interpretable features in reward model activations, enabling insight into safety-relevant decision-making. We apply SAFER to safety-oriented preference datasets and quantify the salience of individual features by activation differences between chosen and rejected responses. Using these feature-level signals, we design targeted data poisoning and denoising strategies. Experiments show that SAFER can precisely degrade or enhance safety alignment with minimal data modification, without sacrificing general chat performance. Our approach contributes to interpreting, auditing and refining reward models in high-stakes LLM alignment tasks. Our codes are available at this https URL. \\textit{This paper discusses topics related to large language model safety and may include discussions or examples that highlight potential risks or unsafe outcomes.}', 'abstract_zh': '基于人类反馈的强化学习（RLHF）是使大规模语言模型（LLMs）与人类价值观一致的关键范式，但其核心的奖励模型仍然 largely 不透明。在本文中，我们提出了稀疏自动编码器增强奖励模型（SAFER），这是一种通过机制分析解释和改进奖励模型的新框架。利用稀疏自动编码器（SAEs），我们揭示了奖励模型激活中的可由人类解释的特征，从而提供了与安全相关决策的见解。我们应用SAFER到以安全性为导向的偏好数据集上，并通过选择和拒绝响应之间的激活差异量化单个特征的重要性。使用这些特征级信号，我们设计了针对性的数据投毒和去噪策略。实验表明，SAFER可以在最小的数据修改下精确地损害或增强安全性对齐，而不牺牲通用聊天性能。我们的方法为高风险的大规模语言模型对齐任务解释、审计和改进奖励模型做出了贡献。我们的代码可在如下链接获得：this https URL。本文讨论了大规模语言模型安全性相关主题，可能包括强调潜在风险或不安全结果的讨论或示例。', 'title_zh': 'SAFER: 用稀疏自编码器探查奖励模型中的安全性'}
{'arxiv_id': 'arXiv:2507.00660', 'title': 'MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound', 'authors': 'Rusi Chen, Yuanting Yang, Jiezhi Yao, Hongning Song, Ji Zhang, Yongsong Zhou, Yuhao Huang, Ronghao Yang, Dan Jia, Yuhan Zhang, Xing Tao, Haoran Dou, Qing Zhou, Xin Yang, Dong Ni', 'link': 'https://arxiv.org/abs/2507.00660', 'abstract': 'Mitral regurgitation is one of the most prevalent cardiac disorders. Four-dimensional (4D) ultrasound has emerged as the primary imaging modality for assessing dynamic valvular morphology. However, 4D mitral valve (MV) analysis remains challenging due to limited phase annotations, severe motion artifacts, and poor imaging quality. Yet, the absence of inter-phase dependency in existing methods hinders 4D MV analysis. To bridge this gap, we propose a Motion-Topology guided consistency network (MTCNet) for accurate 4D MV ultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only sparse end-diastolic and end-systolic annotations. First, we design a cross-phase motion-guided consistency learning strategy, utilizing a bi-directional attention memory bank to propagate spatio-temporal features. This enables MTCNet to achieve excellent performance both per- and inter-phase. Second, we devise a novel topology-guided correlation regularization that explores physical prior knowledge to maintain anatomically plausible. Therefore, MTCNet can effectively leverage structural correspondence between labeled and unlabeled phases. Extensive evaluations on the first largest 4D MV dataset, with 1408 phases from 160 patients, show that MTCNet performs superior cross-phase consistency compared to other advanced methods (Dice: 87.30%, HD: 1.75mm). Both the code and the dataset are available at this https URL.', 'abstract_zh': '基于运动-拓扑引导一致性网络的半监督4D二尖瓣超声分割', 'title_zh': 'MTCNet：四维超声二尖瓣分割的动力学与拓扑一致性引导学习'}
{'arxiv_id': 'arXiv:2507.00657', 'title': 'Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity', 'authors': 'Jacopo Nudo, Mario Edoardo Pandolfo, Edoardo Loru, Mattia Samory, Matteo Cinelli, Walter Quattrociocchi', 'link': 'https://arxiv.org/abs/2507.00657', 'abstract': 'We investigate how Large Language Models (LLMs) behave when simulating political discourse on social media. Leveraging 21 million interactions on X during the 2024 U.S. presidential election, we construct LLM agents based on 1,186 real users, prompting them to reply to politically salient tweets under controlled conditions. Agents are initialized either with minimal ideological cues (Zero Shot) or recent tweet history (Few Shot), allowing one-to-one comparisons with human replies. We evaluate three model families (Gemini, Mistral, and DeepSeek) across linguistic style, ideological consistency, and toxicity. We find that richer contextualization improves internal consistency but also amplifies polarization, stylized signals, and harmful language. We observe an emergent distortion that we call "generation exaggeration": a systematic amplification of salient traits beyond empirical baselines. Our analysis shows that LLMs do not emulate users, they reconstruct them. Their outputs, indeed, reflect internal optimization dynamics more than observed behavior, introducing structural biases that compromise their reliability as social proxies. This challenges their use in content moderation, deliberative simulations, and policy modeling.', 'abstract_zh': '我们研究大型语言模型在模拟社交媒体政治 discourse 时的行为。利用美国2024年总统选举期间X平台上2100万次互动数据，我们基于1186名真实用户构建了大型语言模型代理，在受控条件下促使它们回复政治性显著的推特。代理模型根据最小意识形态线索（零样本）或近期推特历史（少样本）初始化，允许与人类回复进行一对一比较。我们评估了三种模型家族（Gemini、Mistral 和 DeepSeek）在语言风格、意识形态一致性和有害言论方面的表现。研究发现，更丰富的上下文改善了内部一致性，但也加剧了极化、修辞信号和有害语言。我们观察到一种新兴的扭曲现象，称之为“生成夸张”：系统性地将显著特征放大至经验性基准之上。我们的分析表明，大型语言模型重构用户而非模拟用户。其输出实际上反映了内部优化动态而非观察到的行为模式，引入了结构偏差，损害了其作为社会代理的可靠性。这挑战了它们在内容审核、 deliberative 模拟和政策建模中的应用。', 'title_zh': 'LLM社会代理中的生成性夸大：一致性、偏差与毒性'}
{'arxiv_id': 'arXiv:2507.00653', 'title': 'Cognitive Load-Aware Inference: A Neuro-Symbolic Framework for Optimizing the Token Economy of Large Language Models', 'authors': 'Yilun Zhang', 'link': 'https://arxiv.org/abs/2507.00653', 'abstract': "The escalating computational costs of Large Language Model (LLM) inference have become a critical barrier to their widespread and sustainable deployment. While existing optimization strategies are effective, they are predominantly based on statistical heuristics or architectural modifications, lacking a guiding cognitive theory to manage the inference process itself. This paper aims to bridge this gap by introducing a novel paradigm: the Cognitive Load-Aware Inference (CLAI) framework, which operationalizes principles from Cognitive Load Theory (CLT) and neuroscience for LLM inference. We formalize the concepts of Intrinsic Cognitive Load, Extraneous Cognitive Load, and Germane Cognitive Load into quantifiable LLM metrics ($ICL_{LLM}$, $ECL_{LLM}$, and $GCL_{LLM}$), thereby reframing the inference process as a cognitive economics optimization problem: based on the intrinsic complexity of a problem ($ICL_{LLM}$), minimize wasteful computation ($ECL_{LLM}$), and strategically allocate the token budget to productive reasoning ($GCL_{LLM}$). We propose two implementation paths: CLAI-Prompt, a zero-shot method that guides a base LLM through cognitive control steps via a structured meta-prompt, and CLAI-Tune, a fine-tuned model that internalizes these principles for spontaneous cognitive economy. Across a range of benchmarks in complex reasoning, long-context question answering, and code generation, our methods achieve significant reductions in token consumption (up to 45\\%) without sacrificing accuracy. Furthermore, CLAI-Tune exhibits an emergent ability to autonomously decompose difficult problems, a key characteristic of human expert cognition. This work demonstrates that by emulating the brain's resource management strategies, we can build more efficient, robust, and capable artificial intelligence systems.", 'abstract_zh': '认知负载感知推理：大型语言模型的认知经济学优化框架', 'title_zh': '认知负荷 Aware 推理：一种优化大型语言模型令牌经济的神经符号框架'}
{'arxiv_id': 'arXiv:2507.00631', 'title': 'Horus: A Protocol for Trustless Delegation Under Uncertainty', 'authors': 'David Shi, Kevin Joo', 'link': 'https://arxiv.org/abs/2507.00631', 'abstract': 'Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.', 'abstract_zh': '正确性是那些暴露错误的成本低于提交错误的成本的系统中的一种 emergent 属性。在动态且低信任环境中，自主 AI 剂 Oswbot 借助子代理执行任务，但其正确性无法通过前期规范或集中监督来保证。我们提出一种协议，通过递归验证游戏中的抵押索赔来确保正确性。任务以意愿形式发布，求解者竞争以完成它们。选定的求解者在承担风险的情况下执行任务，由验证者事后检查其正确性。任何挑战者都可以通过抵押来质疑结果，从而启动验证过程。错误的代理将被处罚，正确方将得到奖励，且存在一个升级机制，对错误的验证者本身进行处罚。当求解者、挑战者和验证者之间的激励机制对齐时，错误条件使得正确性成为纳什均衡。', 'title_zh': 'Horus：一种基于不确定性条件下的无信任委派协议'}
{'arxiv_id': 'arXiv:2507.00613', 'title': 'Physics-Informed Neural ODEs for Temporal Dynamics Modeling in Cardiac T1 Mapping', 'authors': 'Nuno Capitão, Yi Zhang, Yidong Zhao, Qian Tao', 'link': 'https://arxiv.org/abs/2507.00613', 'abstract': 'Spin-lattice relaxation time ($T_1$) is an important biomarker in cardiac parametric mapping for characterizing myocardial tissue and diagnosing cardiomyopathies. Conventional Modified Look-Locker Inversion Recovery (MOLLI) acquires 11 breath-hold baseline images with interleaved rest periods to ensure mapping accuracy. However, prolonged scanning can be challenging for patients with poor breathholds, often leading to motion artifacts that degrade image quality. In addition, $T_1$ mapping requires voxel-wise nonlinear fitting to a signal recovery model involving an iterative estimation process. Recent studies have proposed deep-learning approaches for rapid $T_1$ mapping using shortened sequences to reduce acquisition time for patient comfort. Nevertheless, existing methods overlook important physics constraints, limiting interpretability and generalization. In this work, we present an accelerated, end-to-end $T_1$ mapping framework leveraging Physics-Informed Neural Ordinary Differential Equations (ODEs) to model temporal dynamics and address these challenges. Our method achieves high-accuracy $T_1$ estimation from a sparse subset of baseline images and ensures efficient null index estimation at test time. Specifically, we develop a continuous-time LSTM-ODE model to enable selective Look-Locker (LL) data acquisition with arbitrary time lags. Experimental results show superior performance in $T_1$ estimation for both native and post-contrast sequences and demonstrate the strong benefit of our physics-based formulation over direct data-driven $T_1$ priors.', 'abstract_zh': '基于物理约束的加速心脏T₁弛豫时间端到端映射框架', 'title_zh': '基于物理约束的神经ODEs在心脏T1成像时间动态建模中的应用'}
{'arxiv_id': 'arXiv:2507.00611', 'title': 'Residual Reward Models for Preference-based Reinforcement Learning', 'authors': 'Chenyang Cao, Miguel Rogel-García, Mohamed Nabail, Xueqian Wang, Nicholas Rhinehart', 'link': 'https://arxiv.org/abs/2507.00611', 'abstract': "Preference-based Reinforcement Learning (PbRL) provides a way to learn high-performance policies in environments where the reward signal is hard to specify, avoiding heuristic and time-consuming reward design. However, PbRL can suffer from slow convergence speed since it requires training in a reward model. Prior work has proposed learning a reward model from demonstrations and fine-tuning it using preferences. However, when the model is a neural network, using different loss functions for pre-training and fine-tuning can pose challenges to reliable optimization. In this paper, we propose a method to effectively leverage prior knowledge with a Residual Reward Model (RRM). An RRM assumes that the true reward of the environment can be split into a sum of two parts: a prior reward and a learned reward. The prior reward is a term available before training, for example, a user's ``best guess'' reward function, or a reward function learned from inverse reinforcement learning (IRL), and the learned reward is trained with preferences. We introduce state-based and image-based versions of RRM and evaluate them on several tasks in the Meta-World environment suite. Experimental results show that our method substantially improves the performance of a common PbRL method. Our method achieves performance improvements for a variety of different types of prior rewards, including proxy rewards, a reward obtained from IRL, and even a negated version of the proxy reward. We also conduct experiments with a Franka Panda to show that our method leads to superior performance on a real robot. It significantly accelerates policy learning for different tasks, achieving success in fewer steps than the baseline. The videos are presented at this https URL.", 'abstract_zh': '基于偏好强化学习中的 residually 奖励模型（Residual Reward Model）方法', 'title_zh': '基于偏好 reinforcement learning 的残差奖励模型'}
{'arxiv_id': 'arXiv:2507.00606', 'title': 'Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies', 'authors': 'Tao Xiong, Xavier Hu, Wenyan Fan, Shengyu Zhang', 'link': 'https://arxiv.org/abs/2507.00606', 'abstract': 'Large language models (LLMs) excel in complex tasks through advanced prompting techniques like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), but their reliance on manually crafted, task-specific prompts limits adaptability and efficiency. We introduce Mixture of Reasoning (MoR), a training framework that embeds diverse reasoning strategies into LLMs for autonomous, task-adaptive reasoning without external prompt engineering. MoR has two phases: Thought Generation, creating reasoning chain templates with models like GPT-4o, and SFT Dataset Construction, pairing templates with benchmark datasets for supervised this http URL experiments show that MoR significantly enhances performance, with MoR150 achieving 0.730 (2.2% improvement) using CoT prompting and 0.734 (13.5% improvement) compared to baselines. MoR eliminates the need for task-specific prompts, offering a generalizable solution for robust reasoning across diverse tasks.', 'abstract_zh': '大规模语言模型（LLMs）通过_CHAIN-OF-THOUGHT_（CoT）和_TREE-OF-THOUGHT_（ToT）等高级提示技术在复杂任务中表现出色，但它们对手工制造的任务特定提示的依赖限制了其适应性和效率。我们提出了一种混合推理（MoR）训练框架，该框架将多种推理策略嵌入到LLMs中，实现无需外部提示工程的自主任务适应性推理。MoR包括两个阶段：推理想法生成，使用如GPT-4o等模型创建推理链模板，以及SFT数据集构建，将模板与基准数据集配对进行监督学习。实验结果显示，MoR显著提升了性能，其中MoR150在CoT提示下实现了0.730的分数（2.2%的改进），相较于基线模型提高了13.5%。MoR消除了对任务特定提示的需求，提供了跨多种任务的鲁棒推理的一般化解决方案。', 'title_zh': '混合推理方法：教导大规模语言模型采用适应性策略进行推理'}
{'arxiv_id': 'arXiv:2507.00598', 'title': 'High-resolution spatial memory requires grid-cell-like neural codes', 'authors': 'Madison Cotteret, Christopher J. Kymn, Hugh Greatorex, Martin Ziegler, Elisabetta Chicca, Friedrich T. Sommer', 'link': 'https://arxiv.org/abs/2507.00598', 'abstract': "Continuous attractor networks (CANs) are widely used to model how the brain temporarily retains continuous behavioural variables via persistent recurrent activity, such as an animal's position in an environment. However, this memory mechanism is very sensitive to even small imperfections, such as noise or heterogeneity, which are both common in biological systems. Previous work has shown that discretising the continuum into a finite set of discrete attractor states provides robustness to these imperfections, but necessarily reduces the resolution of the represented variable, creating a dilemma between stability and resolution. We show that this stability-resolution dilemma is most severe for CANs using unimodal bump-like codes, as in traditional models. To overcome this, we investigate sparse binary distributed codes based on random feature embeddings, in which neurons have spatially-periodic receptive fields. We demonstrate theoretically and with simulations that such grid-cell-like codes enable CANs to achieve both high stability and high resolution simultaneously. The model extends to embedding arbitrary nonlinear manifolds into a CAN, such as spheres or tori, and generalises linear path integration to integration along freely-programmable on-manifold vector fields. Together, this work provides a theory of how the brain could robustly represent continuous variables with high resolution and perform flexible computations over task-relevant manifolds.", 'abstract_zh': '连续吸引子网络通过持续的反复活动暂存连续的行为变量（如动物在环境中的位置），但在生物系统中常见的噪声或异质性等因素会导致其敏感性下降。利用连续体离散化为有限的离散吸引子状态可以增强其对抗这些缺陷的稳健性，但会降低所表示变量的分辨率，造成稳定性和分辨率之间的权衡。我们证明，这一稳定性和分辨率之间的权衡在使用传统模型中的单模峰状编码的连续吸引子网络中尤为严重。为克服这一问题，我们研究了基于随机特征嵌入的稀疏二元分布式编码，其中神经元具有空间周期性的感受野。我们通过理论分析和仿真实验证明，这种类似网格细胞的编码可以使连续吸引子网络同时实现高稳定性和高分辨率。该模型可扩展到将任意非线性流形嵌入连续吸引子网络中，如将球面或环面等转化为流形上的向量场积分，并将线性路径积分扩展到在可自由编程的流形上向量场积分。这项工作为大脑如何以高分辨率稳健地表示连续变量并在任务相关流形上执行灵活计算提供了理论机制。', 'title_zh': '高分辨率空间记忆需要类似-grid细胞的神经编码'}
{'arxiv_id': 'arXiv:2507.00589', 'title': 'Quantum Circuit Structure Optimization for Quantum Reinforcement Learning', 'authors': 'Seok Bin Son, Joongheon Kim', 'link': 'https://arxiv.org/abs/2507.00589', 'abstract': 'Reinforcement learning (RL) enables agents to learn optimal policies through environmental interaction. However, RL suffers from reduced learning efficiency due to the curse of dimensionality in high-dimensional spaces. Quantum reinforcement learning (QRL) addresses this issue by leveraging superposition and entanglement in quantum computing, allowing efficient handling of high-dimensional problems with fewer resources. QRL combines quantum neural networks (QNNs) with RL, where the parameterized quantum circuit (PQC) acts as the core computational module. The PQC performs linear and nonlinear transformations through gate operations, similar to hidden layers in classical neural networks. Previous QRL studies, however, have used fixed PQC structures based on empirical intuition without verifying their optimality. This paper proposes a QRL-NAS algorithm that integrates quantum neural architecture search (QNAS) to optimize PQC structures within QRL. Experiments demonstrate that QRL-NAS achieves higher rewards than QRL with fixed circuits, validating its effectiveness and practical utility.', 'abstract_zh': '量子强化学习（QRL）通过利用量子计算中的叠加和纠缠来解决维数灾难问题，从而提高学习效率。QRL结合了量子神经网络（QNN）与强化学习（RL），其中参数化量子电路（PQC）作为核心计算模块。QRL-NAS算法整合了量子神经架构搜索（QNAS），以优化QRL中的PQC结构。实验表明，QRL-NAS在固定电路的基础上能获得更高的奖励，验证了其有效性和实用性。', 'title_zh': '量子电路结构优化在量子强化学习中的应用'}
{'arxiv_id': 'arXiv:2507.00583', 'title': 'AI-Generated Video Detection via Perceptual Straightening', 'authors': 'Christian Internò, Robert Geirhos, Markus Olhofer, Sunny Liu, Barbara Hammer, David Klindt', 'link': 'https://arxiv.org/abs/2507.00583', 'abstract': 'The rapid advancement of generative AI enables highly realistic synthetic videos, posing significant challenges for content authentication and raising urgent concerns about misuse. Existing detection methods often struggle with generalization and capturing subtle temporal inconsistencies. We propose ReStraV(Representation Straightening Video), a novel approach to distinguish natural from AI-generated videos. Inspired by the "perceptual straightening" hypothesis -- which suggests real-world video trajectories become more straight in neural representation domain -- we analyze deviations from this expected geometric property. Using a pre-trained self-supervised vision transformer (DINOv2), we quantify the temporal curvature and stepwise distance in the model\'s representation domain. We aggregate statistics of these measures for each video and train a classifier. Our analysis shows that AI-generated videos exhibit significantly different curvature and distance patterns compared to real videos. A lightweight classifier achieves state-of-the-art detection performance (e.g., 97.17% accuracy and 98.63% AUROC on the VidProM benchmark), substantially outperforming existing image- and video-based methods. ReStraV is computationally efficient, it is offering a low-cost and effective detection solution. This work provides new insights into using neural representation geometry for AI-generated video detection.', 'abstract_zh': '基于生成AI的合成视频真实性验证：ReStraV方法的研究', 'title_zh': '基于感知纠正的AI生成视频检测'}
{'arxiv_id': 'arXiv:2507.00579', 'title': 'TUM-MiKaNi at SemEval-2025 Task 3: Towards Multilingual and Knowledge-Aware Non-factual Hallucination Identification', 'authors': 'Miriam Anschütz, Ekaterina Gikalo, Niklas Herbster, Georg Groh', 'link': 'https://arxiv.org/abs/2507.00579', 'abstract': 'Hallucinations are one of the major problems of LLMs, hindering their trustworthiness and deployment to wider use cases. However, most of the research on hallucinations focuses on English data, neglecting the multilingual nature of LLMs. This paper describes our submission to the SemEval-2025 Task-3 - Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. We propose a two-part pipeline that combines retrieval-based fact verification against Wikipedia with a BERT-based system fine-tuned to identify common hallucination patterns. Our system achieves competitive results across all languages, reaching top-10 results in eight languages, including English. Moreover, it supports multiple languages beyond the fourteen covered by the shared task. This multilingual hallucination identifier can help to improve LLM outputs and their usefulness in the future.', 'abstract_zh': 'LLMs中的幻觉是阻碍其可信度和广泛应用的主要问题，但现有大多数关于幻觉的研究集中于英语数据，忽视了LLMs的多语言性质。本文描述了我们对SemEval-2025 Task-3 - Mu-SHROOM（多语言共享任务：幻觉及相关过度生成错误）的提交情况。我们提出了一种两阶段的处理管道，结合了利用Wikipedia进行基于检索的事实验证和一个微调后的BERT系统，用于识别常见的幻觉模式。我们的系统在所有语言中均取得了竞争力的结果，其中在八种语言中达到前10名的成绩，包括英语。此外，该系统还支持超出共享任务涵盖的十四种语言的多种语言。这种多语言幻觉标识器有助于提高LLM输出的质量及其未来的实用性。', 'title_zh': 'TUM-MiKaNi在SemEval-2025任务3中的研究：迈向多语言和知识驱动的非事实幻觉识别'}
{'arxiv_id': 'arXiv:2507.00577', 'title': 'BadViM: Backdoor Attack against Vision Mamba', 'authors': 'Yinghao Wu, Liyan Zhang', 'link': 'https://arxiv.org/abs/2507.00577', 'abstract': 'Vision State Space Models (SSMs), particularly architectures like Vision Mamba (ViM), have emerged as promising alternatives to Vision Transformers (ViTs). However, the security implications of this novel architecture, especially their vulnerability to backdoor attacks, remain critically underexplored. Backdoor attacks aim to embed hidden triggers into victim models, causing the model to misclassify inputs containing these triggers while maintaining normal behavior on clean inputs. This paper investigates the susceptibility of ViM to backdoor attacks by introducing BadViM, a novel backdoor attack framework specifically designed for Vision Mamba. The proposed BadViM leverages a Resonant Frequency Trigger (RFT) that exploits the frequency sensitivity patterns of the victim model to create stealthy, distributed triggers. To maximize attack efficacy, we propose a Hidden State Alignment loss that strategically manipulates the internal representations of model by aligning the hidden states of backdoor images with those of target classes. Extensive experimental results demonstrate that BadViM achieves superior attack success rates while maintaining clean data accuracy. Meanwhile, BadViM exhibits remarkable resilience against common defensive measures, including PatchDrop, PatchShuffle and JPEG compression, which typically neutralize normal backdoor attacks.', 'abstract_zh': 'Vision状态空间模型（SSMs），特别是如Vision Mamba（ViM）这样的架构，已经被证明是Vision Transformer（ViTs）的有前途的替代方案。然而，这种新型架构的安全性影响，尤其是其对后门攻击的易感性，仍然被严重忽视。后门攻击旨在将隐蔽触发器嵌入受害模型中，使得模型在包含这些触发器的输入上产生误分类，而在干净的输入上保持正常行为。本文通过引入专为Vision Mamba设计的新颖后门攻击框架BadViM，考察了ViM的后门攻击易感性。所提出的BadViM利用了受害模型的频率敏感模式，创建隐蔽且分散的触发器。为了最大化攻击效果，我们提出了一种隐藏状态对齐损失，通过将后门图像的隐藏状态与目标类别的隐藏状态对齐，战略性地操控模型的内部表示。大量实验结果表明，BadViM在保持数据完整性的同时，实现了更高的攻击成功率。同时，BadViM表现出针对常见的防御措施（包括PatchDrop、PatchShuffle和JPEG压缩）的显著抗性，这些措施通常能够消除正常的后门攻击。', 'title_zh': 'BadViM: 针对Vision Mamba的后门攻击'}
{'arxiv_id': 'arXiv:2507.00546', 'title': 'Inverse Design in Nanophotonics via Representation Learning', 'authors': 'Reza Marzban, Ali Adibi, Raphael Pestourie', 'link': 'https://arxiv.org/abs/2507.00546', 'abstract': 'Inverse design in nanophotonics, the computational discovery of structures achieving targeted electromagnetic (EM) responses, has become a key tool for recent optical advances. Traditional intuition-driven or iterative optimization methods struggle with the inherently high-dimensional, non-convex design spaces and the substantial computational demands of EM simulations. Recently, machine learning (ML) has emerged to address these bottlenecks effectively. This review frames ML-enhanced inverse design methodologies through the lens of representation learning, classifying them into two categories: output-side and input-side approaches. Output-side methods use ML to learn a representation in the solution space to create a differentiable solver that accelerates optimization. Conversely, input-side techniques employ ML to learn compact, latent-space representations of feasible device geometries, enabling efficient global exploration through generative models. Each strategy presents unique trade-offs in data requirements, generalization capacity, and novel design discovery potentials. Hybrid frameworks that combine physics-based optimization with data-driven representations help escape poor local optima, improve scalability, and facilitate knowledge transfer. We conclude by highlighting open challenges and opportunities, emphasizing complexity management, geometry-independent representations, integration of fabrication constraints, and advancements in multiphysics co-designs.', 'abstract_zh': '纳米光子学中的逆设计，通过计算手段发现能够实现目标电磁（EM）响应的结构，已成为最近光子学进展的关键工具。传统基于直觉或迭代优化方法在面对高维度、非凸的设计空间以及电磁模拟的大量计算需求时显得力不从心。最近，机器学习（ML）的有效出现解决了这些瓶颈问题。本文通过表示学习的视角，将ML增强的逆设计方法学分类为输出侧和输入侧两种方法。输出侧方法利用机器学习在解空间中学习表示，生成差异化求解器以加速优化。相反，输入侧技术利用机器学习学习可行设备几何结构的紧凑、潜在空间表示，通过生成模型实现高效的整体探索。每种策略在数据需求、泛化能力和新型设计发现潜力方面具有独特的权衡。结合基于物理的优化与数据驱动表示的混合框架有助于跳出劣质局部最优解、提高可扩展性和促进知识转移。最后，我们强调了开放的挑战和机遇，强调复杂性管理、几何无关表示、集成制造约束以及多物理场联合设计的进展。', 'title_zh': '纳光子学中的逆向设计通过表示学习'}
{'arxiv_id': 'arXiv:2507.00537', 'title': "Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation", 'authors': 'Feng Lin, Marco Chen, Haokui Zhang, Xiaotian Yu, Guangming Lu, Rong Xiao', 'link': 'https://arxiv.org/abs/2507.00537', 'abstract': "This paper studies the role of attention heads in CLIP's image encoder. While CLIP has exhibited robust performance across diverse applications, we hypothesize that certain attention heads negatively affect final representations and that ablating them can improve performance in downstream tasks. To capitalize on this insight, we propose a simple yet effective method, called Attention Ablation Technique (AAT), to suppress the contribution of specific heads by manipulating attention weights. By integrating two alternative strategies tailored for different application scenarios, AAT systematically identifies and ablates detrimental attention heads to enhance representation quality. Experiments demonstrate that AAT consistently improves downstream task performance across various domains, boosting recall rate by up to 11.1% on CLIP-family models for cross-modal retrieval. The results highlight the potential of AAT to effectively refine large-scale vision-language models with virtually no increase in inference cost.", 'abstract_zh': '本文研究了CLIP图像编码器中注意力头的作用。尽管CLIP在多种应用中展现了稳健的性能，但我们假设某些注意力头对最终表示产生了负面影响，移除这些头可以提高下游任务的性能。为了利用这一洞察，我们提出了一种简单有效的方法——注意力消融技术（AAT），通过操纵注意力权重来抑制特定头的贡献。通过为不同应用场景量身定制的两种替代策略，AAT系统地识别并消融了有害的注意力头，以提升表示质量。实验结果表明，AAT在各种领域中一致地提高了下游任务的性能，在CLIP家族模型的跨模态检索中，召回率最多可提升11.1%。结果突显了AAT在几乎不增加推理成本的情况下有效精炼大规模视觉-语言模型的潜力。', 'title_zh': '并非所有注意力头都是你需要的：基于注意力消融细化CLIP的图像表示'}
{'arxiv_id': 'arXiv:2507.00535', 'title': 'Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support', 'authors': 'Dietmar Jannach, Amra Delić, Francesco Ricci, Markus Zanker', 'link': 'https://arxiv.org/abs/2507.00535', 'abstract': 'More than twenty-five years ago, first ideas were developed on how to design a system that can provide recommendations to groups of users instead of individual users. Since then, a rich variety of algorithmic proposals were published, e.g., on how to acquire individual preferences, how to aggregate them, and how to generate recommendations for groups of users. However, despite the rich literature on the topic, barely any examples of real-world group recommender systems can be found. This lets us question common assumptions in academic research, in particular regarding communication processes in a group and how recommendation-supported decisions are made. In this essay, we argue that these common assumptions and corresponding system designs often may not match the needs or expectations of users. We thus call for a reorientation in this research area, leveraging the capabilities of modern Generative AI assistants like ChatGPT. Specifically, as one promising future direction, we envision group recommender systems to be systems where human group members interact in a chat and an AI-based group recommendation agent assists the decision-making process in an agentic way. Ultimately, this shall lead to a more natural group decision-making environment and finally to wider adoption of group recommendation systems in practice.', 'abstract_zh': '超过二十五年前，首次提出了如何设计一个系统以向用户群体而非单个用户提供推荐的想法。此后，发表了大量关于算法的提议，例如如何获取个人偏好、如何聚合这些偏好以及如何为用户群体生成推荐。然而，尽管该主题有大量的文献，但几乎找不到真正的群体推荐系统的实例。这让我们质疑学术研究中的常见假设，特别是关于群体中的沟通过程以及由推荐支持的决策是如何做出的。在本文中，我们认为这些常见假设和相应的系统设计往往可能不符合用户的需求或期望。因此，我们呼吁在这一研究领域进行重新定位，利用现代生成AI助手的能力，如ChatGPT。特别地，我们设想群体推荐系统将是人类群体成员在聊天中互动，并由基于AI的群体推荐代理以代理方式协助决策过程的系统。最终，这将促成一种更加自然的群体决策环境，并最终促进群体推荐系统的广泛应用。', 'title_zh': '在生成式人工智能时代的群体推荐系统重思：从单次推荐到有能动性的群体决策支持'}
{'arxiv_id': 'arXiv:2507.00525', 'title': 'Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving', 'authors': 'Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo', 'link': 'https://arxiv.org/abs/2507.00525', 'abstract': 'Interpretable communication is essential for safe and trustworthy autonomous driving, yet current vision-language models (VLMs) often operate under idealized assumptions and struggle to capture user intent in real-world scenarios. Existing driving-oriented VQA datasets are limited to full-scene descriptions or waypoint prediction, preventing the assessment of whether VLMs can respond to localized user-driven queries. We introduce Box-QAymo, a box-referring dataset and benchmark designed to both evaluate and finetune VLMs on spatial and temporal reasoning over user-specified objects. Users express intent by drawing bounding boxes, offering a fast and intuitive interface for focused queries in complex scenes. Specifically, we propose a hierarchical evaluation protocol that begins with binary sanity-check questions to assess basic model capacities, and progresses to (1) attribute prediction for box-referred objects, (2) motion understanding of target instances, and (3) spatiotemporal motion reasoning over inter-object dynamics across frames. To support this, we crowd-sourced fine-grained object classes and visual attributes that reflect the complexity drivers encounter, and extract object trajectories to construct temporally grounded QA pairs. Rigorous quality control through negative sampling, temporal consistency checks, and difficulty-aware balancing guarantee dataset robustness and diversity. Our comprehensive evaluation reveals significant limitations in current VLMs when queried about perception questions, highlighting the gap in achieving real-world performance. This work provides a foundation for developing more robust and interpretable autonomous driving systems that can communicate effectively with users under real-world conditions. Project page and dataset are available at this https URL.', 'abstract_zh': '可解释的通信对于自主驾驶的安全性和可信度至关重要，然而当前的视觉-语言模型（VLMs）往往基于理想化的假设，并在现实世界场景中难以捕捉用户意图。现有的以驾驶为导向的VQA数据集仅限于全景描述或路径点预测，无法评估VLM是否能够响应局部的用户驱动查询。我们介绍了Box-QAymo，这是一个用于评估和微调VLM在用户指定对象上的空间和时间推理能力的框引用数据集和基准。用户通过绘制边界框来表达意图，提供了一种快速且直观的方法来在复杂场景中进行聚焦查询。具体地，我们提出了一种分层评估协议，从二元合理性检查问题开始，评估基本模型能力，进而包括（1）框引用对象的属性预测，（2）目标实例的运动理解，以及（3）跨帧的物体间动态的空间时间运动推理。为此，我们众包了反映复杂挑战的细粒度对象类别和视觉属性，并提取对象轨迹以构建时间上 ground 的问答对。严格的质量控制通过负样本抽取、时间一致性检查和难度感知平衡保证了数据集的稳健性和多样性。全面的评估揭示了当前VLM在查询感知问题时的重要局限性，突显了在现实世界性能方面实现的差距。这项工作为开发能够在现实世界条件下与用户有效沟通的更稳健和可解释的自主驾驶系统提供了基础。项目页面和数据集可访问：this https URL。', 'title_zh': 'Box-QAymo: 自动驾驶中的盒状参照VQA数据集'}
{'arxiv_id': 'arXiv:2507.00513', 'title': "Customer Service Representative's Perception of the AI Assistant in an Organization's Call Center", 'authors': 'Kai Qin, Kexin Du, Yimeng Chen, Yueyan Liu, Jie Cai, Zhiqiang Nie, Nan Gao, Guohui Wei, Shengzhu Wang, Chun Yu', 'link': 'https://arxiv.org/abs/2507.00513', 'abstract': 'The integration of various AI tools creates a complex socio-technical environment where employee-customer interactions form the core of work practices. This study investigates how customer service representatives (CSRs) at the power grid service customer service call center perceive AI assistance in their interactions with customers. Through a field visit and semi-structured interviews with 13 CSRs, we found that AI can alleviate some traditional burdens during the call (e.g., typing and memorizing) but also introduces new burdens (e.g., earning, compliance, psychological burdens). This research contributes to a more nuanced understanding of AI integration in organizational settings and highlights the efforts and burdens undertaken by CSRs to adapt to the updated system.', 'abstract_zh': '多种AI工具的整合创建了一个复杂的社会-技术环境，其中员工与客户互动成为工作实践的核心。本研究探讨了电力电网服务呼叫中心的客户服务代表（CSR）在与客户互动中对AI辅助的看法。通过访问现场并对13名CSR进行半结构化访谈，我们发现AI可以在通话中减轻一些传统负担（如打字和记忆），但也带来了新的负担（如考勤、合规性和心理负担）。本研究有助于对组织环境中AI整合有更细致的理解，并突显了CSRs为适应更新系统所付出的努力和负担。', 'title_zh': '组织呼叫中心客服代表对AI助手的感知'}
{'arxiv_id': 'arXiv:2507.00509', 'title': 'TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search', 'authors': 'To Eun Kim, João Coelho, Gbemileke Onilude, Jai Singh', 'link': 'https://arxiv.org/abs/2507.00509', 'abstract': 'As conversational search engines increasingly adopt generation-based paradigms powered by Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG), the integration of advertisements into generated responses presents both commercial opportunities and challenges for user experience. Unlike traditional search, where advertisements are clearly delineated, generative systems blur the boundary between informational content and promotional material, raising concerns around transparency and trust. In this work, we propose a modular pipeline for advertisement management in RAG-based conversational systems, consisting of an ad-rewriter for seamless ad integration and a robust ad-classifier for detection. We leverage synthetic data to train high-performing classifiers, which are then used to guide two complementary ad-integration strategies: supervised fine-tuning of the ad-rewriter and a best-of-N sampling approach that selects the least detectable ad-integrated response among multiple candidates. Our evaluation focuses on two core questions: the effectiveness of ad classifiers in detecting diverse ad integration strategies, and the training methods that best support coherent, minimally intrusive ad insertion. Experimental results show that our ad-classifier, trained on synthetic advertisement data inspired by marketing strategies and enhanced through curriculum learning, achieves robust detection performance. Additionally, we demonstrate that classifier-guided optimization, through both fine-tuning and best-of-N sampling, significantly improves ad stealth, enabling more seamless integration. These findings contribute an adversarial co-evolution framework for developing more sophisticated ad-aware generative search systems and robust ad classifiers.', 'abstract_zh': '基于检索增强生成的对话系统中广告管理的模块化管道：透明与信任的平衡', 'title_zh': 'TeamCMU在Touché上的对抗共进化广告整合与检测研究：基于对话搜索环境'}
{'arxiv_id': 'arXiv:2507.00493', 'title': 'Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing Across Vision Models', 'authors': 'Fenil R. Doshi, Thomas Fel, Talia Konkle, George Alvarez', 'link': 'https://arxiv.org/abs/2507.00493', 'abstract': 'Humans are able to recognize objects based on both local texture cues and the configuration of object parts, yet contemporary vision models primarily harvest local texture cues, yielding brittle, non-compositional features. Work on shape-vs-texture bias has pitted shape and texture representations in opposition, measuring shape relative to texture, ignoring the possibility that models (and humans) can simultaneously rely on both types of cues, and obscuring the absolute quality of both types of representation. We therefore recast shape evaluation as a matter of absolute configural competence, operationalized by the Configural Shape Score (CSS), which (i) measures the ability to recognize both images in Object-Anagram pairs that preserve local texture while permuting global part arrangement to depict different object categories. Across 86 convolutional, transformer, and hybrid models, CSS (ii) uncovers a broad spectrum of configural sensitivity with fully self-supervised and language-aligned transformers -- exemplified by DINOv2, SigLIP2 and EVA-CLIP -- occupying the top end of the CSS spectrum. Mechanistic probes reveal that (iii) high-CSS networks depend on long-range interactions: radius-controlled attention masks abolish performance showing a distinctive U-shaped integration profile, and representational-similarity analyses expose a mid-depth transition from local to global coding. A BagNet control remains at chance (iv), ruling out "border-hacking" strategies. Finally, (v) we show that configural shape score also predicts other shape-dependent evals. Overall, we propose that the path toward truly robust, generalizable, and human-like vision systems may not lie in forcing an artificial choice between shape and texture, but rather in architectural and learning frameworks that seamlessly integrate both local-texture and global configural shape.', 'abstract_zh': '基于配置知觉能力的形状评分：构建真正 robust、可泛化且类人的视觉系统', 'title_zh': '视觉异序揭示视觉模型在整体形状处理方面隐含的差异'}
{'arxiv_id': 'arXiv:2507.00491', 'title': 'Twill: Scheduling Compound AI Systems on Heterogeneous Mobile Edge Platforms', 'authors': 'Zain Taufique, Aman Vyas, Antonio Miele, Pasi Liljeberg, Anil Kanduri', 'link': 'https://arxiv.org/abs/2507.00491', 'abstract': 'Compound AI (cAI) systems chain multiple AI models to solve complex problems. cAI systems are typically composed of deep neural networks (DNNs), transformers, and large language models (LLMs), exhibiting a high degree of computational diversity and dynamic workload variation. Deploying cAI services on mobile edge platforms poses a significant challenge in scheduling concurrent DNN-transformer inference tasks, which arrive dynamically in an unknown sequence. Existing mobile edge AI inference strategies manage multi-DNN or transformer-only workloads, relying on design-time profiling, and cannot handle concurrent inference of DNNs and transformers required by cAI systems. In this work, we address the challenge of scheduling cAI systems on heterogeneous mobile edge platforms. We present Twill, a run-time framework to handle concurrent inference requests of cAI workloads through task affinity-aware cluster mapping and migration, priority-aware task freezing/unfreezing, and DVFS, while minimizing inference latency within power budgets. We implement and deploy our Twill framework on the Nvidia Jetson Orin NX platform. We evaluate Twill against state-of-the-art edge AI inference techniques over contemporary DNNs and LLMs, reducing inference latency by 54% on average, while honoring power budgets.', 'abstract_zh': '面向异构移动边缘平台的复合AI系统调度框架Twill', 'title_zh': 'Twill: 在异构移动边缘平台上调度复合AI系统'}
{'arxiv_id': 'arXiv:2507.00485', 'title': 'PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning', 'authors': 'Weiran Guo, Guanjun Liu, Ziyuan Zhou, Ling Wang', 'link': 'https://arxiv.org/abs/2507.00485', 'abstract': 'Reinforcement Learning (RL) is widely used in tasks where agents interact with an environment to maximize rewards. Building on this foundation, Safe Reinforcement Learning (Safe RL) incorporates a cost metric alongside the reward metric, ensuring that agents adhere to safety constraints during decision-making. In this paper, we identify that Safe RL is vulnerable to backdoor attacks, which can manipulate agents into performing unsafe actions. First, we introduce the relevant concepts and evaluation metrics for backdoor attacks in Safe RL. It is the first attack framework in the Safe RL field that involves both Positive and Negative Action sample (PNAct) is to implant backdoors, where positive action samples provide reference actions and negative action samples indicate actions to be avoided. We theoretically point out the properties of PNAct and design an attack algorithm. Finally, we conduct experiments to evaluate the effectiveness of our proposed backdoor attack framework, evaluating it with the established metrics. This paper highlights the potential risks associated with Safe RL and underscores the feasibility of such attacks. Our code and supplementary material are available at this https URL.', 'abstract_zh': '安全强化学习(Safe RL)易受后门攻击：正反样本攻击框架及其评价', 'title_zh': 'PNAct: 在安全强化学习中构建后门攻击'}
{'arxiv_id': 'arXiv:2507.00482', 'title': 'Physics-Aware Style Transfer for Adaptive Holographic Reconstruction', 'authors': 'Chanseok Lee, Fakhriyya Mammadova, Jiseong Barg, Mooseok Jang', 'link': 'https://arxiv.org/abs/2507.00482', 'abstract': "Inline holographic imaging presents an ill-posed inverse problem of reconstructing objects' complex amplitude from recorded diffraction patterns. Although recent deep learning approaches have shown promise over classical phase retrieval algorithms, they often require high-quality ground truth datasets of complex amplitude maps to achieve a statistical inverse mapping operation between the two domains. Here, we present a physics-aware style transfer approach that interprets the object-to-sensor distance as an implicit style within diffraction patterns. Using the style domain as the intermediate domain to construct cyclic image translation, we show that the inverse mapping operation can be learned in an adaptive manner only with datasets composed of intensity measurements. We further demonstrate its biomedical applicability by reconstructing the morphology of dynamically flowing red blood cells, highlighting its potential for real-time, label-free imaging. As a framework that leverages physical cues inherently embedded in measurements, the presented method offers a practical learning strategy for imaging applications where ground truth is difficult or impossible to obtain.", 'abstract_zh': '基于inline全息成像的物镜成像 Presents an不适定逆问题，即从记录的衍射图案重构物体的复振幅。尽管最近的深度学习方法在经典相位恢复算法上显示出前景，但它们通常需要高质量的复振幅地图 ground truth 数据集，以实现两个域之间的统计逆映射操作。在这里，我们提出了一种物理感知的风格迁移方法，将物镜到传感器的距离解释为衍射图案中的隐式风格。利用风格域作为中间域构建循环图像转换，我们展示了仅使用由强度测量组成的数据集即可学习逆映射操作。我们还通过重构动态流动的红细胞的形态，展示了其在生物医学成像中的应用，突显了其实时和无标记成像的潜力。作为一种利用测量中内在物理线索的框架，所提出的方法为难以或不可能获得 ground truth 的成像应用提供了实用的学习策略。', 'title_zh': '物理感知样式迁移以实现自适应全息重建'}
{'arxiv_id': 'arXiv:2507.00467', 'title': 'Diversity Conscious Refined Random Forest', 'authors': 'Sijan Bhattarai, Saurav Bhandari, Girija Bhusal, Saroj Shakya, Tapendra Pandey', 'link': 'https://arxiv.org/abs/2507.00467', 'abstract': 'Random Forest (RF) is a widely used ensemble learning technique known for its robust classification performance across diverse domains. However, it often relies on hundreds of trees and all input features, leading to high inference cost and model redundancy. In this work, our goal is to grow trees dynamically only on informative features and then enforce maximal diversity by clustering and retaining uncorrelated trees. Therefore, we propose a Refined Random Forest Classifier that iteratively refines itself by first removing the least informative features and then analytically determines how many new trees should be grown, followed by correlation-based clustering to remove redundant trees. The classification accuracy of our model was compared against the standard RF on the same number of trees. Experiments on 8 multiple benchmark datasets, including binary and multiclass datasets, demonstrate that the proposed model achieves improved accuracy compared to standard RF.', 'abstract_zh': '改进的随机森林分类器：动态生长信息性特征并强制最大化多样性和去冗余', 'title_zh': '意识多样性精炼随机森林'}
{'arxiv_id': 'arXiv:2507.00461', 'title': 'Novel Complex-Valued Hopfield Neural Networks with Phase and Magnitude Quantization', 'authors': 'Garimella Ramamurthy, Marcos Eduardo Valle, Tata Jagannadha Swamy', 'link': 'https://arxiv.org/abs/2507.00461', 'abstract': 'This research paper introduces two novel complex-valued Hopfield neural networks (CvHNNs) that incorporate phase and magnitude quantization. The first CvHNN employs a ceiling-type activation function that operates on the rectangular coordinate representation of the complex net contribution. The second CvHNN similarly incorporates phase and magnitude quantization but utilizes a ceiling-type activation function based on the polar coordinate representation of the complex net contribution. The proposed CvHNNs, with their phase and magnitude quantization, significantly increase the number of states compared to existing models in the literature, thereby expanding the range of potential applications for CvHNNs.', 'abstract_zh': '这种研究论文介绍了两种新颖的复值霍普菲尔德神经网络（CvHNNs），这两者都结合了相位和幅度量化。第一种CvHNN采用天花板型激活函数，该函数基于复网络贡献的矩形坐标表示工作。第二种CvHNN同样结合了相位和幅度量化，但使用的是基于复网络贡献的极坐标表示的天花板型激活函数。提出的CvHNNs通过相位和幅度量化，相较于文献中现有的模型显著增加了状态数量，从而扩大了CvHNNs潜在应用的范围。', 'title_zh': '新型相位和幅度量化复值霍普菲尔德神经网络'}
{'arxiv_id': 'arXiv:2507.00459', 'title': 'Process-aware and high-fidelity microstructure generation using stable diffusion', 'authors': 'Hoang Cuong Phan, Minh Tien Tran, Chihun Lee, Hoheok Kim, Sehyok Oh, Dong-Kyu Kim, Ho Won Lee', 'link': 'https://arxiv.org/abs/2507.00459', 'abstract': "Synthesizing realistic microstructure images conditioned on processing parameters is crucial for understanding process-structure relationships in materials design. However, this task remains challenging due to limited training micrographs and the continuous nature of processing variables. To overcome these challenges, we present a novel process-aware generative modeling approach based on Stable Diffusion 3.5 Large (SD3.5-Large), a state-of-the-art text-to-image diffusion model adapted for microstructure generation. Our method introduces numeric-aware embeddings that encode continuous variables (annealing temperature, time, and magnification) directly into the model's conditioning, enabling controlled image generation under specified process conditions and capturing process-driven microstructural variations. To address data scarcity and computational constraints, we fine-tune only a small fraction of the model's weights via DreamBooth and Low-Rank Adaptation (LoRA), efficiently transferring the pre-trained model to the materials domain. We validate realism using a semantic segmentation model based on a fine-tuned U-Net with a VGG16 encoder on 24 labeled micrographs. It achieves 97.1% accuracy and 85.7% mean IoU, outperforming previous methods. Quantitative analyses using physical descriptors and spatial statistics show strong agreement between synthetic and real microstructures. Specifically, two-point correlation and lineal-path errors remain below 2.1% and 0.6%, respectively. Our method represents the first adaptation of SD3.5-Large for process-aware microstructure generation, offering a scalable approach for data-driven materials design.", 'abstract_zh': '基于处理参数生成现实微观结构图像对于材料设计中的过程-结构关系理解至关重要。然而，由于训练 microscopy 图像数据有限以及处理变量的连续性，这一任务仍然具有挑战性。为克服这些挑战，我们提出了一个基于 Stable Diffusion 3.5 Large (SD3.5-Large) 的新型过程感知生成模型方法，该方法是一种先进的文本到图像的扩散模型，适用于微观结构生成。我们的方法引入了数值感知嵌入，直接将连续变量（退火温度、时间和放大倍数）编码到模型的条件中，从而在指定的加工条件下实现可控的图像生成并捕捉加工驱动的微观结构变化。为解决数据稀缺性和计算约束，我们仅通过 DreamBooth 和 Low-Rank Adaptation (LoRA) 微调模型的一小部分权重，高效地将预训练模型转移到材料领域。使用基于微调 U-Net 和 VGG16 编码器的语义分割模型验证真实性，该模型在 24 张标注的 microscopy 图像上实现了 97.1% 的准确率和 85.7% 的平均 IoU，超过了以前的方法。使用物理描述符和空间统计进行的定量分析显示合成的微观结构与真实微观结构之间有很强的一致性。具体来说，两点相关误差和线性路径误差均低于 2.1% 和 0.6%。我们的方法是 SD3.5-Large 首次用于过程感知微观结构生成，提供了一种数据驱动材料设计的可扩展方法。', 'title_zh': '基于过程意识且高保真的微结构生成：使用稳定扩散方法'}
{'arxiv_id': 'arXiv:2507.00454', 'title': 'ATSTrack: Enhancing Visual-Language Tracking by Aligning Temporal and Spatial Scales', 'authors': 'Yihao Zhen, Qiang Wang, Yu Qiao, Liangqiong Qu, Huijie Fan', 'link': 'https://arxiv.org/abs/2507.00454', 'abstract': 'A main challenge of Visual-Language Tracking (VLT) is the misalignment between visual inputs and language descriptions caused by target movement. Previous trackers have explored many effective feature modification methods to preserve more aligned features. However, an important yet unexplored factor ultimately hinders their capability, which is the inherent differences in the temporal and spatial scale of information between visual and language inputs. To address this issue, we propose a novel visual-language tracker that enhances the effect of feature modification by \\textbf{A}ligning \\textbf{T}emporal and \\textbf{S}patial scale of different input components, named as \\textbf{ATSTrack}. Specifically, we decompose each language description into phrases with different attributes based on their temporal and spatial correspondence with visual inputs, and modify their features in a fine-grained manner. Moreover, we introduce a Visual-Language token that comprises modified linguistic information from the previous frame to guide the model to extract visual features that are more relevant to language description, thereby reducing the impact caused by the differences in spatial scale. Experimental results show that our proposed ATSTrack achieves performance comparable to existing methods. Our code will be released.', 'abstract_zh': '视觉-语言跟踪中的主要挑战是目标移动导致的视觉输入与语言描述之间的对齐不一致。为了应对这一问题，我们提出了一种新颖的视觉-语言跟踪器ATSTrack，通过对齐不同输入组件的时空尺度来增强特征修改的效果。具体地，我们根据语言描述与视觉输入的时空对应关系，将每个语言描述分解为具有不同属性的短语，并以精细的方式修改其特征。此外，我们引入了一个视觉-语言令牌，该令牌包含来自上一帧的修改语言信息，以引导模型提取与语言描述更相关的视觉特征，从而减少由于时空尺度差异引起的影响。实验结果表明，提出的ATSTrack在性能上与现有方法相当。我们的代码将公开发布。', 'title_zh': 'ATSTrack: 通过对齐时间和空间尺度 Enhance 视觉-语言跟踪'}
{'arxiv_id': 'arXiv:2507.00451', 'title': 'Best Agent Identification for General Game Playing', 'authors': 'Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers', 'link': 'https://arxiv.org/abs/2507.00451', 'abstract': 'We present an efficient and generalised procedure to accurately identify the best performing algorithm for each sub-task in a multi-problem domain. Our approach treats this as a set of best arm identification problems for multi-armed bandits, where each bandit corresponds to a specific task and each arm corresponds to a specific algorithm or agent. We propose an optimistic selection process based on the Wilson score interval (Optimistic-WS) that ranks each arm across all bandits in terms of their potential regret reduction. We evaluate the performance of Optimistic-WS on two of the most popular general game domains, the General Video Game AI (GVGAI) framework and the Ludii general game playing system, with the goal of identifying the highest performing agent for each game within a limited number of trials. Compared to previous best arm identification algorithms for multi-armed bandits, our results demonstrate a substantial performance improvement in terms of average simple regret. This novel approach can be used to significantly improve the quality and accuracy of agent evaluation procedures for general game frameworks, as well as other multi-task domains with high algorithm runtimes.', 'abstract_zh': '一种高效且通用的多问题域中最佳算法识别方法', 'title_zh': '通用游戏-playing 中最优代理识别'}
{'arxiv_id': 'arXiv:2507.00445', 'title': 'Iterative Distillation for Reward-Guided Fine-Tuning of Diffusion Models in Biomolecular Design', 'authors': 'Xingyu Su, Xiner Li, Masatoshi Uehara, Sunwoo Kim, Yulai Zhao, Gabriele Scalia, Ehsan Hajiramezanali, Tommaso Biancalani, Degui Zhi, Shuiwang Ji', 'link': 'https://arxiv.org/abs/2507.00445', 'abstract': 'We address the problem of fine-tuning diffusion models for reward-guided generation in biomolecular design. While diffusion models have proven highly effective in modeling complex, high-dimensional data distributions, real-world applications often demand more than high-fidelity generation, requiring optimization with respect to potentially non-differentiable reward functions such as physics-based simulation or rewards based on scientific knowledge. Although RL methods have been explored to fine-tune diffusion models for such objectives, they often suffer from instability, low sample efficiency, and mode collapse due to their on-policy nature. In this work, we propose an iterative distillation-based fine-tuning framework that enables diffusion models to optimize for arbitrary reward functions. Our method casts the problem as policy distillation: it collects off-policy data during the roll-in phase, simulates reward-based soft-optimal policies during roll-out, and updates the model by minimizing the KL divergence between the simulated soft-optimal policy and the current model policy. Our off-policy formulation, combined with KL divergence minimization, enhances training stability and sample efficiency compared to existing RL-based methods. Empirical results demonstrate the effectiveness and superior reward optimization of our approach across diverse tasks in protein, small molecule, and regulatory DNA design.', 'abstract_zh': '我们探讨了使用奖励导向生成优化调整扩散模型在生物分子设计中的问题。虽然扩散模型已经在建模复杂高维度数据分布方面展现出高度有效性，但实际应用往往需要更多的优化，要求优化潜在的非可微奖励函数，如基于物理的模拟或基于科学知识的奖励。尽管已经探索了使用强化学习方法来调整扩散模型以实现此类目标，但这些方法往往因其基于策略的性质而表现出不稳定性、低样本效率和模式崩溃。在这项工作中，我们提出了一种迭代蒸馏式的调整框架，使扩散模型能够优化任意奖励函数。我们的方法将问题视为策略蒸馏：在卷入阶段收集离策略数据，在运行阶段模拟基于奖励的软最优策略，并通过最小化模拟的软最优策略与当前模型策略之间的KL散度来更新模型。与现有的基于强化学习的方法相比，我们的离策略表示和KL散度最小化增强了训练的稳定性和样本效率。实验结果证明了我们在蛋白质、小分子和调控DNA设计等多个任务中有效且优秀的奖励优化能力。', 'title_zh': '迭代蒸馏以指导奖励精细调整的生物分子设计扩散模型fine-tuning'}
{'arxiv_id': 'arXiv:2507.00443', 'title': 'Novel Pigeon-inspired 3D Obstacle Detection and Avoidance Maneuver for Multi-UAV Systems', 'authors': 'Reza Ahmadvand, Sarah Safura Sharif, Yaser Mike Banad', 'link': 'https://arxiv.org/abs/2507.00443', 'abstract': "Recent advances in multi-agent systems manipulation have demonstrated a rising demand for the implementation of multi-UAV systems in urban areas, which are always subjected to the presence of static and dynamic obstacles. Inspired by the collective behavior of tilapia fish and pigeons, the focus of the presented research is on the introduction of a nature-inspired collision-free formation control for a multi-UAV system, considering the obstacle avoidance maneuvers. The developed framework in this study utilizes a semi-distributed control approach, in which, based on a probabilistic Lloyd's algorithm, a centralized guidance algorithm works for optimal positioning of the UAVs, while a distributed control approach has been used for the intervehicle collision and obstacle avoidance. Further, the presented framework has been extended to the 3D space with a novel definition of 3D maneuvers. Finally, the presented framework has been applied to multi-UAV systems in 2D and 3D scenarios, and the obtained results demonstrated the validity of the presented method in dynamic environments with stationary and moving obstacles.", 'abstract_zh': '最近多智能体系统方面的进展展示了在城市区域实施多无人机系统的需求，这些区域往往存在静态和动态障碍物。借鉴鲱鱼和鸽子的集体行为，本文的研究重点在于引入一种受自然启发的无碰撞编队控制方法，同时考虑避障 maneuvers。本研究开发的框架采用半分布式控制方法，在此方法中，基于概率Lloyd算法的集中指导算法负责无人机的最优定位，而分布控制方法用于车辆间的碰撞和障碍物避免。进一步，本文框架扩展到了三维空间，并引入了三维 maneuvers 的新定义。最后，该框架应用于二维和三维场景中的多无人机系统，并获得的结果证实了在有静态和移动障碍物的动态环境中该方法的有效性。', 'title_zh': '基于鸽子启发的多无人机系统3D障碍检测与规避 maneuvers 研究'}
{'arxiv_id': 'arXiv:2507.00440', 'title': 'A Recipe for Causal Graph Regression: Confounding Effects Revisited', 'authors': 'Yujia Yin, Tianyi Qu, Zihao Wang, Yifan Chen', 'link': 'https://arxiv.org/abs/2507.00440', 'abstract': 'Through recognizing causal subgraphs, causal graph learning (CGL) has risen to be a promising approach for improving the generalizability of graph neural networks under out-of-distribution (OOD) scenarios. However, the empirical successes of CGL techniques are mostly exemplified in classification settings, while regression tasks, a more challenging setting in graph learning, are overlooked. We thus devote this work to tackling causal graph regression (CGR); to this end we reshape the processing of confounding effects in existing CGL studies, which mainly deal with classification. Specifically, we reflect on the predictive power of confounders in graph-level regression, and generalize classification-specific causal intervention techniques to regression through a lens of contrastive learning. Extensive experiments on graph OOD benchmarks validate the efficacy of our proposals for CGR. The model implementation and the code are provided on this https URL.', 'abstract_zh': '通过识别因果子图，因果图学习（CGL）已成为在分布外（OOD）场景下提高图神经网络泛化能力的有前途的方法；然而，现有的CGL技术在回归任务中的应用较少，而回归任务是图学习中更加具有挑战性的任务。因此，本文致力于解决因果图回归（CGR）问题；为此，我们重新审视了现有CGL研究中干扰效应对处理方式，并将针对分类任务的因果干预技术通过对比学习的视角推广到回归任务中。大量实验在图分布外基准测试上验证了我们提出的CGR方法的有效性；相关模型实现和代码参见此链接。', 'title_zh': '因果图回归的配方：重新审视混杂效应'}
{'arxiv_id': 'arXiv:2507.00435', 'title': 'RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation', 'authors': 'Yi Ru Wang, Carter Ung, Grant Tannert, Jiafei Duan, Josephine Li, Amy Le, Rishabh Oswal, Markus Grotz, Wilbert Pumacay, Yuquan Deng, Ranjay Krishna, Dieter Fox, Siddhartha Srinivasa', 'link': 'https://arxiv.org/abs/2507.00435', 'abstract': 'We present RoboEval, a simulation benchmark and structured evaluation framework designed to reveal the limitations of current bimanual manipulation policies. While prior benchmarks report only binary task success, we show that such metrics often conceal critical weaknesses in policy behavior -- such as poor coordination, slipping during grasping, or asymmetric arm usage. RoboEval introduces a suite of tiered, semantically grounded tasks decomposed into skill-specific stages, with variations that systematically challenge spatial, physical, and coordination capabilities. Tasks are paired with fine-grained diagnostic metrics and 3000+ human demonstrations to support imitation learning. Our experiments reveal that policies with similar success rates diverge in how tasks are executed -- some struggle with alignment, others with temporally consistent bimanual control. We find that behavioral metrics correlate with success in over half of task-metric pairs, and remain informative even when binary success saturates. By pinpointing when and how policies fail, RoboEval enables a deeper, more actionable understanding of robotic manipulation -- and highlights the need for evaluation tools that go beyond success alone.', 'abstract_zh': 'RoboEval：一种用于揭示当前双臂操作策略限制的模拟基准和结构化评估框架', 'title_zh': 'RoboEval：机器人Manipulation的结构化和可扩展评估'}
{'arxiv_id': 'arXiv:2507.00419', 'title': 'Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding', 'authors': 'Yimin Dou, Xinming Wu, Nathan L Bangs, Harpreet Singh Sethi, Jintao Li, Hang Gao, Zhixiang Guo', 'link': 'https://arxiv.org/abs/2507.00419', 'abstract': "Understanding Earth's subsurface is critical for energy transition, natural hazard mitigation, and planetary science. Yet subsurface analysis remains fragmented, with separate models required for structural interpretation, stratigraphic analysis, geobody segmentation, and property modeling-each tightly coupled to specific data distributions and task formulations. We introduce the Geological Everything Model 3D (GEM), a unified generative architecture that reformulates all these tasks as prompt-conditioned inference along latent structural frameworks derived from subsurface imaging. This formulation moves beyond task-specific models by enabling a shared inference mechanism, where GEM propagates human-provided prompts-such as well logs, masks, or structural sketches-along inferred structural frameworks to produce geologically coherent outputs. Through this mechanism, GEM achieves zero-shot generalization across tasks with heterogeneous prompt types, without retraining for new tasks or data sources. This capability emerges from a two-stage training process that combines self-supervised representation learning on large-scale field seismic data with adversarial fine-tuning using mixed prompts and labels across diverse subsurface tasks. GEM demonstrates broad applicability across surveys and tasks, including Martian radar stratigraphy analysis, structural interpretation in subduction zones, full seismic stratigraphic interpretation, geobody delineation, and property modeling. By bridging expert knowledge with generative reasoning in a structurally aware manner, GEM lays the foundation for scalable, human-in-the-loop geophysical AI-transitioning from fragmented pipelines to a vertically integrated, promptable reasoning system. Project page: this https URL", 'abstract_zh': '理解和阐释地球的地下结构对于能源转型、自然灾害mitigation以及行星科学至关重要。然而，地下分析仍然碎片化，每个任务（如结构解释、沉积层析分析、地质体分割和属性建模）都需要独立的模型，并且这些模型紧密依赖于特定的数据分布和任务形式。我们提出了一种统一的生成架构地质一切3D模型（GEM），它将所有这些任务重新表述为沿地下成像推断的潜在结构框架进行提示条件下的推断。这种表述通过使GEM能够沿推断出的结构框架传播来自人类的提示（如测井数据、掩码或结构草图），从而生成地质上连贯的输出，从而超越了特定任务模型的限制。GEM能够在不同提示类型之间实现零样本泛化，无需为新任务或数据源重新训练。这一能力源自于一种两阶段的训练过程，该过程结合了大规模现场地震数据的自监督表示学习和使用混合提示和标签进行的竞争性微调，以适用于多种地下任务。GEM在各种调查和任务中具有广泛的适用性，包括火星雷达沉积层析分析、俯冲带结构解释、完整地震沉积层析解释、地质体划分和属性建模。通过以结构感知的方式结合专家知识和生成推理，GEM为可扩展、人在环的地质物理AI奠定了基础，从分离的管道转变为垂直集成、可提示推理系统。', 'title_zh': '地质万物模型3D：一种可提示的基础模型，用于统一和零样本地下理解'}
{'arxiv_id': 'arXiv:2507.00418', 'title': 'Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and High-Performance GPUs', 'authors': 'Mohammad Firas Sada, John J. Graham, Elham E Khoda, Mahidhar Tatineni, Dmitry Mishin, Rajesh K. Gupta, Rick Wagner, Larry Smarr, Thomas A. DeFanti, Frank Würthwein', 'link': 'https://arxiv.org/abs/2507.00418', 'abstract': 'This study presents a benchmarking analysis of the Qualcomm Cloud AI 100 Ultra (QAic) accelerator for large language model (LLM) inference, evaluating its energy efficiency (throughput per watt) and performance against leading NVIDIA (A100, H200) and AMD (MI300A) GPUs within the National Research Platform (NRP) ecosystem. A total of 15 open-source LLMs, ranging from 117 million to 90 billion parameters, are served using the vLLM framework. The QAic inference cards appears to be energy efficient and performs well in the energy efficiency metric in most cases. The findings offer insights into the potential of the Qualcomm Cloud AI 100 Ultra for high-performance computing (HPC) applications within the National Research Platform (NRP).', 'abstract_zh': '本研究对Qualcomm Cloud AI 100 Ultra (QAic) 加速器在大型语言模型（LLM）推理中的基准分析，评估了其能效（每瓦吞吐量）和在National Research Platform (NRP) 生态系统中与领先NVIDIA (A100, H200) 和AMD (MI300A) GPU的竞争性能。使用vLLM框架总共服务了15个开源LLM，参数范围从1.17亿到900亿。在多数情况下，QAic 推理卡在能效指标中表现出色。研究结果为Qualcomm Cloud AI 100 Ultra在National Research Platform (NRP) 中高性能计算（HPC）应用的潜力提供了见解。', 'title_zh': '在HPC集群中服务LLMs：Qualcomm Cloud AI 100 Ultra与高性能GPU的比较研究'}
{'arxiv_id': 'arXiv:2507.00407', 'title': 'Augmenting Molecular Graphs with Geometries via Machine Learning Interatomic Potentials', 'authors': 'Cong Fu, Yuchao Lin, Zachary Krueger, Haiyang Yu, Maho Nakata, Jianwen Xie, Emine Kucukbenli, Xiaofeng Qian, Shuiwang Ji', 'link': 'https://arxiv.org/abs/2507.00407', 'abstract': 'Accurate molecular property predictions require 3D geometries, which are typically obtained using expensive methods such as density functional theory (DFT). Here, we attempt to obtain molecular geometries by relying solely on machine learning interatomic potential (MLIP) models. To this end, we first curate a large-scale molecular relaxation dataset comprising 3.5 million molecules and 300 million snapshots. Then MLIP foundation models are trained with supervised learning to predict energy and forces given 3D molecular structures. Once trained, we show that the foundation models can be used in different ways to obtain geometries either explicitly or implicitly. First, it can be used to obtain low-energy 3D geometries via geometry optimization, providing relaxed 3D geometries for downstream molecular property predictions. To mitigate potential biases and enhance downstream predictions, we introduce geometry fine-tuning based on the relaxed 3D geometries. Second, the foundation models can be directly fine-tuned for property prediction when ground truth 3D geometries are available. Our results demonstrate that MLIP foundation models trained on relaxation data can provide valuable molecular geometries that benefit property predictions.', 'abstract_zh': '准确的分子性质预测需要三维几何结构，这些结构通常通过密度泛函理论（DFT）等昂贵的方法获得。在这里，我们尝试仅依靠机器学习原子势（MLIP）模型来获取分子几何结构。为此，我们首先构建了一个包含350万分子和3亿个快照的大规模分子弛豫数据集。然后，使用监督学习训练MLIP基础模型，以预测给定三维分子结构的能量和力。训练完成后，我们展示该基础模型可以通过不同的方式来获取几何结构，既可以显式地，也可以隐式地。首先，它可以用于通过几何优化获得低能量的三维几何结构，提供可用于下游分子性质预测的弛豫三维几何结构。为了缓解潜在的偏差并提高下游预测，我们基于弛豫三维几何结构提出了几何结构微调方法。其次，当有真实的三维几何结构时，基础模型可以直接微调以进行性质预测。我们的结果表明，基于弛豫数据训练的MLIP基础模型可以提供有利于性质预测的宝贵分子几何结构。', 'title_zh': '使用机器学习原子势增强分子图的几何结构'}
{'arxiv_id': 'arXiv:2507.00378', 'title': 'iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing', 'authors': 'Xikai Sun, Fan Dang, Kebin Liu, Xin Miao, Zihao Yang, Haimo Lu, Yawen Zheng, Yunhao Liu', 'link': 'https://arxiv.org/abs/2507.00378', 'abstract': 'Conformance testing is essential for ensuring that protocol implementations comply with their specifications. However, traditional testing approaches involve manually creating numerous test cases and scripts, making the process labor-intensive and inefficient. Recently, Large Language Models (LLMs) have demonstrated impressive text comprehension and code generation abilities, providing promising opportunities for automation. In this paper, we propose iPanda, the first end-to-end framework that leverages LLMs to automate protocol conformance testing. Given a protocol specification document and its implementation, iPanda first employs a keyword-based method to automatically generate comprehensive test cases. Then, it utilizes a code-based retrieval-augmented generation approach to effectively interpret the implementation and produce executable test code. To further enhance code quality, iPanda incorporates an iterative self-correction mechanism to refine generated test scripts interactively. Finally, by executing and analyzing the generated tests, iPanda systematically verifies compliance between implementations and protocol specifications. Comprehensive experiments on various protocols show that iPanda significantly outperforms pure LLM-based approaches, improving the success rate (Pass@1) of test-code generation by factors ranging from 4.675 times to 10.751 times.', 'abstract_zh': '基于大规模语言模型的端到端协议一致性测试框架 iPanda', 'title_zh': 'iPanda: 一种用于符合性测试的智能协议测试与调试代理'}
{'arxiv_id': 'arXiv:2507.00358', 'title': 'Data-Driven Exploration for a Class of Continuous-Time Linear--Quadratic Reinforcement Learning Problems', 'authors': 'Yilie Huang, Xun Yu Zhou', 'link': 'https://arxiv.org/abs/2507.00358', 'abstract': 'We study reinforcement learning (RL) for the same class of continuous-time stochastic linear--quadratic (LQ) control problems as in \\cite{huang2024sublinear}, where volatilities depend on both states and controls while states are scalar-valued and running control rewards are absent. We propose a model-free, data-driven exploration mechanism that adaptively adjusts entropy regularization by the critic and policy variance by the actor. Unlike the constant or deterministic exploration schedules employed in \\cite{huang2024sublinear}, which require extensive tuning for implementations and ignore learning progresses during iterations, our adaptive exploratory approach boosts learning efficiency with minimal tuning. Despite its flexibility, our method achieves a sublinear regret bound that matches the best-known model-free results for this class of LQ problems, which were previously derived only with fixed exploration schedules. Numerical experiments demonstrate that adaptive explorations accelerate convergence and improve regret performance compared to the non-adaptive model-free and model-based counterparts.', 'abstract_zh': '我们研究了与文献\\[huang2024sublinear\\]中相同的连续时间随机线性-quadratic (LQ) 控制问题的强化学习（RL），其中波动性依赖于状态和控制，而状态是标量值且不存在运行控制奖励。我们提出了一种无模型的数据驱动探索机制，该机制通过评论家自适应调整熵正则化，并通过行动者调整策略方差。与\\[huang2024sublinear\\]中使用的常量或确定性探索计划不同，后者需要大量的手动调整且在迭代过程中忽略学习进展，我们的自适应探索方法在最少的手动调整下提高了学习效率。尽管具有灵活性，我们的方法实现了与LQ问题此类别中已知的最佳无模型结果相同的次线性遗憾界，此前这些结果仅在固定探索计划下得到。数值实验表明，与非自适应无模型和基于模型的对应方法相比，自适应探索加速了收敛并提高了遗憾性能。', 'title_zh': '数据驱动探究在一类连续时间线性-二次强化学习问题中的应用'}
{'arxiv_id': 'arXiv:2507.00356', 'title': 'CGEarthEye:A High-Resolution Remote Sensing Vision Foundation Model Based on the Jilin-1 Satellite Constellation', 'authors': 'Zhiwei Yi, Xin Cheng, Jingyu Ma, Ruifei Zhu, Junwei Tian, Yuanxiu Zhou, Xinge Zhao, Hongzhe Li', 'link': 'https://arxiv.org/abs/2507.00356', 'abstract': "Deep learning methods have significantly advanced the development of intelligent rinterpretation in remote sensing (RS), with foundational model research based on large-scale pre-training paradigms rapidly reshaping various domains of Earth Observation (EO). However, compared to the open accessibility and high spatiotemporal coverage of medium-resolution data, the limited acquisition channels for ultra-high-resolution optical RS imagery have constrained the progress of high-resolution remote sensing vision foundation models (RSVFM). As the world's largest sub-meter-level commercial RS satellite constellation, the Jilin-1 constellation possesses abundant sub-meter-level image resources. This study proposes CGEarthEye, a RSVFM framework specifically designed for Jilin-1 satellite characteristics, comprising five backbones with different parameter scales with totaling 2.1 billion parameters. To enhance the representational capacity of the foundation model, we developed JLSSD, the first 15-million-scale multi-temporal self-supervised learning (SSL) dataset featuring global coverage with quarterly temporal sampling within a single year, constructed through multi-level representation clustering and sampling strategies. The framework integrates seasonal contrast, augmentation-based contrast, and masked patch token contrastive strategies for pre-training. Comprehensive evaluations across 10 benchmark datasets covering four typical RS tasks demonstrate that the CGEarthEye consistently achieves state-of-the-art (SOTA) performance. Further analysis reveals CGEarthEye's superior characteristics in feature visualization, model convergence, parameter efficiency, and practical mapping applications. This study anticipates that the exceptional representation capabilities of CGEarthEye will facilitate broader and more efficient applications of Jilin-1 data in traditional EO application.", 'abstract_zh': '基于吉林一号星座的高分辨率遥感视觉基础模型框架CGEarthEye', 'title_zh': 'CGEarthEye：基于吉林一号卫星星座的高分辨率遥感视觉基础模型'}
{'arxiv_id': 'arXiv:2507.00352', 'title': 'An AST-guided LLM Approach for SVRF Code Synthesis', 'authors': 'Abanoub E. Abdelmalak, Mohamed A. Elsayed, David Abercrombie, Ilhami Torunoglu', 'link': 'https://arxiv.org/abs/2507.00352', 'abstract': 'Standard Verification Rule Format (SVRF) is essential for semiconductor applications like Design Rule Check (DRC), Layout Versus Schematic (LVS), and Optical Proximity Correction (OPC) and it faces challenges as advancing nodes create complex design rules that renders traditional SVRF development ineffective and highlight an expertise gap. This paper introduces a novel methodology integrating Abstract Syntax Tree (AST) embedding and Retrieval-Augmented Generation (RAG) for enhanced SVRF code synthesis, ensuring semantic accuracy and error minimization through structural validation with domain-specific insights for precise code generation.\nWe evaluate different T5-based models and propose an innovative SVRF-specific scoring framework that complements standard metrics like BLEU and ROUGE-L. In our approach, AST provides rigorous structural validation, while RAG infuses relevant domain knowledge, effectively enhancing the code generation workflow.\nTesting on a comprehensive benchmark of 740 DRC rule implementations, our methodology demonstrates up to a 40\\% improvement in code generation accuracy compared to basic text-based fine-tuning process. This fusion of industry expertise with advanced coding strategies not only optimizes SVRF development under limited dataset constraints but also creates a more intuitive and efficient coding environment. Consequently, users can rapidly iterate through design cycles, reduce manual error correction, and significantly improve overall productivity.', 'abstract_zh': '一种基于Abstract Syntax Tree嵌入和Retrieval-Augmented Generation的Standard Verification Rule Format代码合成新方法', 'title_zh': 'AST引导的大语言模型方法用于SVRF代码合成'}
{'arxiv_id': 'arXiv:2507.00347', 'title': 'VTS-Guided AI Interaction Workflow for Business Insights', 'authors': 'Sun Ding, Ude Enebeli, Atilhan, Manay, Ryan Pua, Kamal Kotak', 'link': 'https://arxiv.org/abs/2507.00347', 'abstract': 'Modern firms face a flood of dense, unstructured reports. Turning these documents into usable insights takes heavy effort and is far from agile when quick answers are needed. VTS-AI tackles this gap. It integrates Visual Thinking Strategies, which emphasize evidence-based observation, linking, and thinking, into AI agents, so the agents can extract business insights from unstructured text, tables, and images at scale. The system works in three tiers (micro, meso, macro). It tags issues, links them to source pages, and rolls them into clear action levers stored in a searchable YAML file. In tests on an 18-page business report, VTS-AI matched the speed of a one-shot ChatGPT prompt yet produced richer findings: page locations, verbatim excerpts, severity scores, and causal links. Analysts can accept or adjust these outputs in the same IDE, keeping human judgment in the loop. Early results show VTS-AI spots the direction of key metrics and flags where deeper number-crunching is needed. Next steps include mapping narrative tags to financial ratios, adding finance-tuned language models through a Model-Context Protocol, and building a Risk & Safety Layer to stress-test models and secure data. These upgrades aim to make VTS-AI a production-ready, audit-friendly tool for rapid business analysis.', 'abstract_zh': '现代企业面临海量密集的非结构化报告。将这些文档转化为可用洞察需要大量努力，且当需要快速答案时，这一过程并不敏捷。VTS-AI 破解了这一难题。它将基于证据的观察、关联和思考的视觉思维策略整合到 AI 代理中，使代理能够大规模从非结构化文本、表格和图像中提取商业洞察。系统分为三个层级（微观、中观、宏观）。它标记问题，链接到源页面，并将它们整合到可搜索的 YAML 文件中存储的清晰行动杠杆中。在对一份18页的商业报告进行测试中，VTS-AI 的速度与一次性的 ChatGPT 提示相当，但产出的内容更加丰富：页面位置、原话摘录、严重程度评分和因果关联。分析师可以在相同的 IDE 中接受或调整这些输出，将人类判断纳入决策过程。初步结果显示，VTS-AI 能够识别关键指标的方向，并指出需要更深入数据处理的领域。下一步计划包括将叙述标签映射到财务比率、通过模型-上下文协议添加金融调整型语言模型以及构建风险与安全层以压力测试模型和保障数据安全。这些升级旨在使 VTS-AI 成为一种成熟、审计友好的快速商业分析工具。', 'title_zh': 'VTS引导的AI交互工作流及其商业洞察'}
{'arxiv_id': 'arXiv:2507.00339', 'title': 'Training for X-Ray Vision: Amodal Segmentation, Amodal Content Completion, and View-Invariant Object Representation from Multi-Camera Video', 'authors': 'Alexander Moore, Amar Saini, Kylie Cancilla, Doug Poland, Carmen Carrano', 'link': 'https://arxiv.org/abs/2507.00339', 'abstract': 'Amodal segmentation and amodal content completion require using object priors to estimate occluded masks and features of objects in complex scenes. Until now, no data has provided an additional dimension for object context: the possibility of multiple cameras sharing a view of a scene. We introduce MOVi-MC-AC: Multiple Object Video with Multi-Cameras and Amodal Content, the largest amodal segmentation and first amodal content dataset to date. Cluttered scenes of generic household objects are simulated in multi-camera video. MOVi-MC-AC contributes to the growing literature of object detection, tracking, and segmentation by including two new contributions to the deep learning for computer vision world. Multiple Camera (MC) settings where objects can be identified and tracked between various unique camera perspectives are rare in both synthetic and real-world video. We introduce a new complexity to synthetic video by providing consistent object ids for detections and segmentations between both frames and multiple cameras each with unique features and motion patterns on a single scene. Amodal Content (AC) is a reconstructive task in which models predict the appearance of target objects through occlusions. In the amodal segmentation literature, some datasets have been released with amodal detection, tracking, and segmentation labels. While other methods rely on slow cut-and-paste schemes to generate amodal content pseudo-labels, they do not account for natural occlusions present in the modal masks. MOVi-MC-AC provides labels for ~5.8 million object instances, setting a new maximum in the amodal dataset literature, along with being the first to provide ground-truth amodal content. The full dataset is available at this https URL ,', 'abstract_zh': '无姿态遮挡分割和无姿态内容完成需要利用对象先验来估计复杂场景中被遮挡的 MASK 和特征。MOVi-MC-AC: 多对象视频与多摄像头及无姿态内容，迄今为止最大的无姿态分割数据集及首个无姿态内容数据集。', 'title_zh': 'X射线视觉训练：多摄像头视频中的无界分割、无界内容完成及视点不变对象表示'}
{'arxiv_id': 'arXiv:2507.00322', 'title': 'Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones', 'authors': 'Daking Rai, Samuel Miller, Kevin Moran, Ziyu Yao', 'link': 'https://arxiv.org/abs/2507.00322', 'abstract': 'Despite remarkable advances in coding capabilities, language models (LMs) still struggle with simple syntactic tasks such as generating balanced parentheses. In this study, we investigate the underlying mechanisms behind the persistence of these errors across LMs of varying sizes (124M-7B) to both understand and mitigate the errors. Our study reveals that LMs rely on a number of components (attention heads and FF neurons) that independently make their own predictions. While some components reliably promote correct answers across a generalized range of inputs (i.e., implementing "sound mechanisms\'\'), others are less reliable and introduce noise by promoting incorrect tokens (i.e., implementing "faulty mechanisms\'\'). Errors occur when the faulty mechanisms overshadow the sound ones and dominantly affect the predictions. Motivated by this insight, we introduce RASteer, a steering method to systematically identify and increase the contribution of reliable components for improving model performance. RASteer substantially improves performance on balanced parentheses tasks, boosting accuracy of some models from $0$% to around $100$% without impairing the models\' general coding ability. We further demonstrate its broader applicability in arithmetic reasoning tasks, achieving performance gains of up to around $20$%.', 'abstract_zh': '尽管编码能力取得了显著进步，语言模型（LMs）仍然在生成匹配括号等简单的句法任务上遇到困难。本研究探讨了不同规模（124M-7B）LMs中持续存在的错误背后的原因，旨在理解并减轻这些错误。研究发现，LMs依赖于多个独立预测的不同组件（注意力头和前馈神经元），其中一些组件在广泛输入范围内可靠地促进正确答案（即实现“健全机制”），而另一些则不够可靠，通过促进错误标记引入噪声（即实现“故障机制”）。错误发生时，故障机制会压倒健全机制，并主导预测结果。基于这一洞察，我们提出了RASteer steering方法，以系统地识别并增加可靠组件的贡献，以提高模型性能。RASteer在平衡括号任务上的性能大幅提升，某些模型的准确性从0%提升至约100%而不会损害模型的一般编程能力。此外，我们还展示了其在算术推理任务上的更广泛适用性，实现了最高约20%的性能提升。', 'title_zh': '干涉导致的失败：当故障机制覆盖了有效的机制时，语言模型会在匹配括号上出错。'}
{'arxiv_id': 'arXiv:2507.00310', 'title': 'Open-ended Scientific Discovery via Bayesian Surprise', 'authors': 'Dhruv Agarwal, Bodhisattwa Prasad Majumder, Reece Adamson, Megha Chakravorty, Satvika Reddy Gavireddy, Aditya Parashar, Harshit Surana, Bhavana Dalvi Mishra, Andrew McCallum, Ashish Sabharwal, Peter Clark', 'link': 'https://arxiv.org/abs/2507.00310', 'abstract': "The promise of autonomous scientific discovery (ASD) hinges not only on answering questions, but also on knowing which questions to ask. Most recent works in ASD explore the use of large language models (LLMs) in goal-driven settings, relying on human-specified research questions to guide hypothesis generation. However, scientific discovery may be accelerated further by allowing the AI system to drive exploration by its own criteria. The few existing approaches in open-ended ASD select hypotheses based on diversity heuristics or subjective proxies for human interestingness, but the former struggles to meaningfully navigate the typically vast hypothesis space, and the latter suffers from imprecise definitions. This paper presents AutoDS -- a method for open-ended ASD that instead drives scientific exploration using Bayesian surprise. Here, we quantify the epistemic shift from the LLM's prior beliefs about a hypothesis to its posterior beliefs after gathering experimental results. To efficiently explore the space of nested hypotheses, our method employs a Monte Carlo tree search (MCTS) strategy with progressive widening using surprisal as the reward function. We evaluate AutoDS in the setting of data-driven discovery across 21 real-world datasets spanning domains such as biology, economics, finance, and behavioral science. Our results demonstrate that under a fixed budget, AutoDS substantially outperforms competitors by producing 5--29\\% more discoveries deemed surprising by the LLM. Our human evaluation further finds that two-thirds of AutoDS discoveries are surprising to the domain experts, suggesting this is an important step forward towards building open-ended ASD systems.", 'abstract_zh': '自主科学发现的潜力不仅在于回答问题，还在于知道提出哪些问题。 Autonomous Scientific Discovery 的潜力不仅在于回答问题，还在于知道提出哪些问题。', 'title_zh': '基于贝叶斯惊讶的开放式科学发现'}
{'arxiv_id': 'arXiv:2507.00297', 'title': 'Natural language processing for African languages', 'authors': 'David Ifeoluwa Adelani', 'link': 'https://arxiv.org/abs/2507.00297', 'abstract': 'Recent advances in word embeddings and language models use large-scale, unlabelled data and self-supervised learning to boost NLP performance. Multilingual models, often trained on web-sourced data like Wikipedia, face challenges: few low-resource languages are included, their data is often noisy, and lack of labeled datasets makes it hard to evaluate performance outside high-resource languages like English. In this dissertation, we focus on languages spoken in Sub-Saharan Africa where all the indigenous languages in this region can be regarded as low-resourced in terms of the availability of labelled data for NLP tasks and unlabelled data found on the web. We analyse the noise in the publicly available corpora, and curate a high-quality corpus, demonstrating that the quality of semantic representations learned in word embeddings does not only depend on the amount of data but on the quality of pre-training data. We demonstrate empirically the limitations of word embeddings, and the opportunities the multilingual pre-trained language model (PLM) offers especially for languages unseen during pre-training and low-resource scenarios. We further study how to adapt and specialize multilingual PLMs to unseen African languages using a small amount of monolingual texts. To address the under-representation of the African languages in NLP research, we developed large scale human-annotated labelled datasets for 21 African languages in two impactful NLP tasks: named entity recognition and machine translation. We conduct an extensive empirical evaluation using state-of-the-art methods across supervised, weakly-supervised, and transfer learning settings.', 'abstract_zh': 'Recent advances in词嵌入和语言模型利用大规模未标注数据和自我监督学习提升自然语言处理性能。多语言模型常在诸如维基百科等网络数据上训练，但面临挑战：低资源语言覆盖率低、数据质量参差不齐，缺乏标注数据集使得在外语种如英语以外的语言上评估性能困难。在此博士论文中，我们专注于撒哈拉以南非洲地区语言，所有该地区的本地语言在标注数据和网络上找到的未标注数据方面均可视为低资源语言。我们分析了公开可用语料库中的噪音，并编纂了高质量的语料库，证明词嵌入中学习的语义表示的质量不仅取决于数据量还取决于预训练数据的质量。我们通过实验证明词嵌入的局限性以及多语言预训练语言模型（PLM）在其特别对于预训练未见的语言和低资源场景中提供的机会。我们进一步研究如何使用少量单语文本适应和专门化多语言PLMs以应对非洲语言在NLP研究中的代表性不足。为此，我们为两项重要NLP任务（命名实体识别和机器翻译）为21种非洲语言开发了大规模人工标注的数据集。我们在监督学习、弱监督学习和迁移学习设置中进行了广泛实证评估。', 'title_zh': '非洲语言的自然语言处理'}
{'arxiv_id': 'arXiv:2507.00292', 'title': 'Reducing Variability of Multiple Instance Learning Methods for Digital Pathology', 'authors': 'Ali Mammadov, Loïc Le Folgoc, Guillaume Hocquet, Pietro Gori', 'link': 'https://arxiv.org/abs/2507.00292', 'abstract': 'Digital pathology has revolutionized the field by enabling the digitization of tissue samples into whole slide images (WSIs). However, the high resolution and large size of WSIs present significant challenges when it comes to applying Deep Learning models. As a solution, WSIs are often divided into smaller patches with a global label (\\textit{i.e., diagnostic}) per slide, instead of a (too) costly pixel-wise annotation. By treating each slide as a bag of patches, Multiple Instance Learning (MIL) methods have emerged as a suitable solution for WSI classification. A major drawback of MIL methods is their high variability in performance across different runs, which can reach up to 10-15 AUC points on the test set, making it difficult to compare different MIL methods reliably. This variability mainly comes from three factors: i) weight initialization, ii) batch (shuffling) ordering, iii) and learning rate. To address that, we introduce a Multi-Fidelity, Model Fusion strategy for MIL methods. We first train multiple models for a few epochs and average the most stable and promising ones based on validation scores. This approach can be applied to any existing MIL model to reduce performance variability. It also simplifies hyperparameter tuning and improves reproducibility while maintaining computational efficiency. We extensively validate our approach on WSI classification tasks using 2 different datasets, 3 initialization strategies and 5 MIL methods, for a total of more than 2000 experiments.', 'abstract_zh': '数字病理学通过将组织样本数字化为全-slide 图像（WSIs）而革新了该领域。然而，WSIs 的高分辨率和大尺寸给深度学习模型的应用带来了巨大挑战。为解决这一问题，WSIs 常被分割成较小的patches，每张slide附带一个全局标签（即诊断标签），而非逐像素注释。通过将每张slide视为patches的集合，多次实例学习（MIL）方法成为WSI分类的一种合适解决方案。MIL方法的主要缺点是其在不同运行中的性能差异性很大，在测试集上的性能差异可达10-15个AUC点，这使得不同MIL方法之间的可靠比较变得困难。这种差异性主要来自于三个因素：i) 权重初始化，ii) 批次排序，iii) 学习率。为解决这一问题，我们提出了一种适用于MIL方法的多保真度模型融合策略。我们首先训练多个模型几个epoch，并基于验证分数选择最稳定和潜在表现最好的模型进行平均。该方法可以应用于任何现有的MIL模型以减少性能差异性。同时，它简化了超参数调优，提高了可重复性，同时保持了计算效率。我们在2个不同的数据集、3种初始化策略和5种MIL方法上进行了详尽的验证，总共进行了超过2000次实验。', 'title_zh': '多实例学习方法在数字病理学中减少变异性研究'}
{'arxiv_id': 'arXiv:2507.00288', 'title': 'Reconfiguring Digital Accountability: AI-Powered Innovations and Transnational Governance in a Postnational Accounting Context', 'authors': 'Claire Li, David Freeborn', 'link': 'https://arxiv.org/abs/2507.00288', 'abstract': 'This study explores how AI-powered digital innovations are reshaping organisational accountability in a transnational governance context. As AI systems increasingly mediate decision-making in domains such as auditing and financial reporting, traditional mechanisms of accountability, based on control, transparency, and auditability, are being destabilised. We integrate the Technology Acceptance Model (TAM), Actor-Network Theory (ANT), and institutional theory to examine how organisations adopt AI technologies in response to regulatory, ethical, and cultural pressures that transcend national boundaries. We argue that accountability is co-constructed within global socio-technical networks, shaped not only by user perceptions but also by governance logics and normative expectations. Extending TAM, we incorporate compliance and legitimacy as key factors in perceived usefulness and usability. Drawing on ANT, we reconceptualise accountability as a relational and emergent property of networked assemblages. We propose two organisational strategies including internal governance reconfiguration and external actor-network engagement to foster responsible, legitimate, and globally accepted AI adoption in the accounting domain.', 'abstract_zh': '本研究探讨了基于AI的数字创新如何在全球治理背景下重塑组织问责制。随着AI系统在审计和财务报告等领域日益成为决策的中介，传统的基于控制、透明度和可审计性的问责机制正被动摇。我们结合技术接受模型（TAM）、行动者网络理论（ANT）和制度理论，探讨组织如何在超越国界的监管、伦理和文化压力下采纳AI技术。我们认为，问责制是在全球社会-技术网络中共同建构的，不仅受用户感知的影响，也受治理逻辑和规范性预期的影响。扩展TAM，我们将合规性和合法性纳入感知有用性和易用性的重要因素。借助ANT，我们将问责制重新概念化为网络组装体中的一种关系性和涌现性属性。我们提出了两种组织策略，包括内部治理重构和外部行动者网络互动，以促进会计领域负责任、合法性和全球接受的AI采用。', 'title_zh': '重塑数字问责制：后国家记账背景下基于人工智能的创新与跨国治理'}
{'arxiv_id': 'arXiv:2507.00287', 'title': 'Self-Supervised Multiview Xray Matching', 'authors': 'Mohamad Dabboussi, Malo Huard, Yann Gousseau, Pietro Gori', 'link': 'https://arxiv.org/abs/2507.00287', 'abstract': 'Accurate interpretation of multi-view radiographs is crucial for diagnosing fractures, muscular injuries, and other anomalies. While significant advances have been made in AI-based analysis of single images, current methods often struggle to establish robust correspondences between different X-ray views, an essential capability for precise clinical evaluations. In this work, we present a novel self-supervised pipeline that eliminates the need for manual annotation by automatically generating a many-to-many correspondence matrix between synthetic X-ray views. This is achieved using digitally reconstructed radiographs (DRR), which are automatically derived from unannotated CT volumes. Our approach incorporates a transformer-based training phase to accurately predict correspondences across two or more X-ray views. Furthermore, we demonstrate that learning correspondences among synthetic X-ray views can be leveraged as a pretraining strategy to enhance automatic multi-view fracture detection on real data. Extensive evaluations on both synthetic and real X-ray datasets show that incorporating correspondences improves performance in multi-view fracture classification.', 'abstract_zh': '多视角X射线准确解释对于骨折、肌肉损伤和其他异常的诊断至关重要。尽管基于AI的单张图像分析取得了显著进展，但当前方法在建立不同X射线视图之间的稳健对应关系方面仍面临挑战，这对精确临床评估至关重要。本文介绍了一种新颖的自监督流水线，该流水线通过自动生成合成X射线视图之间的多对多对应矩阵，消除了手动标注的需要。这一成果是通过从未标注的CT体积自动推导出的数字化重建射线摄影（DRR）实现的。我们的方法采用基于变换器的训练阶段，以准确预测两张或多张X射线视图之间的对应关系。此外，我们展示了在合成X射线视图之间学习对应关系可以作为一种预训练策略，以增强对实际数据的自动多视角骨折检测性能。对合成和真实X射线数据集的广泛评估表明，整合对应关系可以提高多视角骨折分类的性能。', 'title_zh': '自监督多视图X射线匹配'}
{'arxiv_id': 'arXiv:2507.00286', 'title': 'Visual Privacy Management with Generative AI for Blind and Low-Vision People', 'authors': 'Tanusree Sharma, Yu-Yun Tseng, Lotus Zhang, Ayae Ide, Kelly Avery Mack, Leah Findlater, Danna Gurari, Yang Wang', 'link': 'https://arxiv.org/abs/2507.00286', 'abstract': 'Blind and low vision (BLV) individuals use Generative AI (GenAI) tools to interpret and manage visual content in their daily lives. While such tools can enhance the accessibility of visual content and so enable greater user independence, they also introduce complex challenges around visual privacy. In this paper, we investigate the current practices and future design preferences of blind and low vision individuals through an interview study with 21 participants. Our findings reveal a range of current practices with GenAI that balance privacy, efficiency, and emotional agency, with users accounting for privacy risks across six key scenarios, such as self-presentation, indoor/outdoor spatial privacy, social sharing, and handling professional content. Our findings reveal design preferences, including on-device processing, zero-retention guarantees, sensitive content redaction, privacy-aware appearance indicators, and multimodal tactile mirrored interaction methods. We conclude with actionable design recommendations to support user-centered visual privacy through GenAI, expanding the notion of privacy and responsible handling of others data.', 'abstract_zh': '盲人和低视力个体使用生成人工智能工具处理日常生活中的视觉内容及其面临的复杂隐私挑战：当前实践与未来设计偏好研究', 'title_zh': '基于生成AI的视觉隐私管理方法及其在盲人和低视力人群中的应用'}
{'arxiv_id': 'arXiv:2507.00275', 'title': 'Double Q-learning for Value-based Deep Reinforcement Learning, Revisited', 'authors': 'Prabhat Nagarajan, Martha White, Marlos C. Machado', 'link': 'https://arxiv.org/abs/2507.00275', 'abstract': "Overestimation is pervasive in reinforcement learning (RL), including in Q-learning, which forms the algorithmic basis for many value-based deep RL algorithms. Double Q-learning is an algorithm introduced to address Q-learning's overestimation by training two Q-functions and using both to de-correlate action-selection and action-evaluation in bootstrap targets. Shortly after Q-learning was adapted to deep RL in the form of deep Q-networks (DQN), Double Q-learning was adapted to deep RL in the form of Double DQN. However, Double DQN only loosely adapts Double Q-learning, forgoing the training of two different Q-functions that bootstrap off one another. In this paper, we study algorithms that adapt this core idea of Double Q-learning for value-based deep RL. We term such algorithms Deep Double Q-learning (DDQL). Our aim is to understand whether DDQL exhibits less overestimation than Double DQN and whether performant instantiations of DDQL exist. We answer both questions affirmatively, demonstrating that DDQL reduces overestimation and outperforms Double DQN in aggregate across 57 Atari 2600 games, without requiring additional hyperparameters. We also study several aspects of DDQL, including its network architecture, replay ratio, and minibatch sampling strategy.", 'abstract_zh': '过度估计在强化学习中的普遍存在：从Q-learning到Deep Double Q-learning的研究', 'title_zh': '基于价值的深度强化学习中双Q学习的 revisit'}
{'arxiv_id': 'arXiv:2507.00269', 'title': 'Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations', 'authors': 'Omar Claflin', 'link': 'https://arxiv.org/abs/2507.00269', 'abstract': 'Current sparse autoencoder (SAE) approaches to neural network interpretability assume that activations can be decomposed through linear superposition into sparse, interpretable features. Despite high reconstruction fidelity, SAEs consistently fail to eliminate polysemanticity and exhibit pathological behavioral errors. We propose that neural networks encode information in two complementary spaces compressed into the same substrate: feature identity and feature integration. To test this dual encoding hypothesis, we develop sequential and joint-training architectures to capture identity and integration patterns simultaneously. Joint training achieves 41.3% reconstruction improvement and 51.6% reduction in KL divergence errors. This architecture spontaneously develops bimodal feature organization: low squared norm features contributing to integration pathways and the rest contributing directly to the residual. Small nonlinear components (3% of parameters) achieve 16.5% standalone improvements, demonstrating parameter-efficient capture of computational relationships crucial for behavior. Additionally, intervention experiments using 2x2 factorial stimulus designs demonstrated that integration features exhibit selective sensitivity to experimental manipulations and produce systematic behavioral effects on model outputs, including significant interaction effects across semantic dimensions. This work provides systematic evidence for (1) dual encoding in neural representations, (2) meaningful nonlinearly encoded feature interactions, and (3) introduces an architectural paradigm shift from post-hoc feature analysis to integrated computational design, establishing foundations for next-generation SAEs.', 'abstract_zh': '当前的稀疏自编码器（SAE）方法假设激活可以通过线性叠加分解为稀疏且可解释的特征，尽管具有高重建保真度，但SAE始终无法消除多义性并表现出病理性行为错误。我们提出，神经网络以互补的方式在相同的基质中编码信息：特征身份与特征整合。为了检验这种双编码假设，我们开发了顺序和联合训练架构，同时捕捉身份和整合模式。联合训练实现了41.3%的重建改善和51.6%的KL散度错误减少。该架构自发形成了二态特征组织：低范数平方特征参与整合路径，其余特征直接贡献于残差。少量非线性组件（参数的3%）实现了16.5%的独立改进，展示了对行为至关重要的计算关系的参数效率捕获。此外，使用2x2因素刺激设计的干预实验表明，整合特征对实验操纵具有选择性敏感性，并对模型输出产生系统的行为影响，包括多义性维度之间的显著交互效应。这项工作提供了关于（1）神经表示中的双编码、（2）有意义的非线性编码特征相互作用以及（3）从事后特征分析到集成计算设计的架构范式转变的系统证据，为下一代SAE奠定了基础。', 'title_zh': '特征整合空间：联合训练揭示神经网络表示中的双重编码'}
{'arxiv_id': 'arXiv:2507.00268', 'title': 'Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems', 'authors': 'Oren Fivel, Matan Rudman, Kobi Cohen', 'link': 'https://arxiv.org/abs/2507.00268', 'abstract': "Deep reinforcement learning (DRL) has become a powerful tool for complex decision-making in machine learning and AI. However, traditional methods often assume perfect action execution, overlooking the uncertainties and deviations between an agent's selected actions and the actual system response. In real-world applications, such as robotics, mechatronics, and communication networks, execution mismatches arising from system dynamics, hardware constraints, and latency can significantly degrade performance. This work advances AI by developing a novel control-optimized DRL framework that explicitly models and compensates for action execution mismatches, a challenge largely overlooked in existing methods. Our approach establishes a structured two-stage process: determining the desired action and selecting the appropriate control signal to ensure proper execution. It trains the agent while accounting for action mismatches and controller corrections. By incorporating these factors into the training process, the AI agent optimizes the desired action with respect to both the actual control signal and the intended outcome, explicitly considering execution errors. This approach enhances robustness, ensuring that decision-making remains effective under real-world uncertainties. Our approach offers a substantial advancement for engineering practice by bridging the gap between idealized learning and real-world implementation. It equips intelligent agents operating in engineering environments with the ability to anticipate and adjust for actuation errors and system disturbances during training. We evaluate the framework in five widely used open-source mechanical simulation environments we restructured and developed to reflect real-world operating conditions, showcasing its robustness against uncertainties and offering a highly practical and efficient solution for control-oriented applications.", 'abstract_zh': '深度强化学习（DRL）已成为机器学习和AI中复杂决策的强大工具。然而，传统方法常常假设动作执行完美无缺，忽略了代理所选动作与实际系统响应之间的不确定性和偏差。在现实世界的应用中，如机器人技术、机电一体化和通信网络中，由于系统动力学、硬件限制和延迟等因素引起的动作执行不匹配会显著降低性能。本工作通过开发一种新颖的控制优化DRL框架，明确建模并补偿动作执行不匹配问题，而现有方法中对此挑战关注不足。我们的方法建立了一个结构化的两阶段过程：确定期望动作和选择合适的控制信号以确保正确执行。该方法在考虑动作不匹配和控制器校正的同时训练代理。通过将这些因素纳入训练过程，AI代理可以基于实际控制信号和预期结果优化期望动作，明确考虑执行误差。这种方法增强了系统的鲁棒性，确保在现实世界不确定性下决策的有效性。我们的方法通过弥合理想化学习与实际实施之间的差距，为工程实践提供了重大进步。它使在工程环境中操作的智能代理能够在训练过程中预期和调整执行错误和系统干扰。我们在五个我们重新构建和开发的广泛使用的开源机械仿真环境中评估了该框架，展示了其在面对不确定性时的鲁棒性，提供了一种高度实用和高效的控制导向应用解决方案。', 'title_zh': '基于控制优化的深度强化学习在人工智能自主系统中的应用'}
{'arxiv_id': 'arXiv:2507.00258', 'title': 'Impact of Fine-Tuning Methods on Memorization in Large Language Models', 'authors': 'Jie Hou, Chuxiong Wu, Lannan Luo, Qiang Zeng', 'link': 'https://arxiv.org/abs/2507.00258', 'abstract': 'As the capabilities of pre-trained large language models (LLMs) continue to advance, the "pre-train and fine-tune" paradigm has become increasingly mainstream, leading to the development of various fine-tuning methods. However, the privacy risks arising from memorization during fine-tuning have received relatively little attention. To address this gap, we categorize popular fine-tuning approaches and assess their impact on memorization through the lens of membership inference attacks (MIAs). Our results show that, compared to parameter-based fine-tuning, prompt-based fine-tuning achieves competitive performance while exhibiting lower vulnerability to MIAs. Furthermore, prompt-based methods maintain low memorization regardless of model scale. These findings suggest that parameter-based fine-tuning is more prone to leaking private information, whereas prompt-based fine-tuning serves as a more privacy-preserving option.', 'abstract_zh': '随着预训练大型语言模型（LLMs）能力的不断进步，“预训练和微调”范式日益 mainstream，推动了各种微调方法的发展。然而，在微调过程中出现的隐私风险相对较少受到关注。为了填补这一空白，我们对流行的微调方法进行了分类，并通过成员推断攻击（MIAs）的视角评估它们对记忆化的影响。研究结果表明，与基于参数的微调相比，基于提示的微调在性能上具有竞争力，同时对MIAs的易感性较低。此外，基于提示的方法在模型规模变化时仍能保持低记忆化水平。这表明基于参数的微调更容易泄露私人信息，而基于提示的微调具有更好的隐私保护特性。', 'title_zh': '大型语言模型中微调方法对记忆影响的研究'}
{'arxiv_id': 'arXiv:2507.00257', 'title': 'Gym4ReaL: A Suite for Benchmarking Real-World Reinforcement Learning', 'authors': 'Davide Salaorni, Vincenzo De Paola, Samuele Delpero, Giovanni Dispoto, Paolo Bonetti, Alessio Russo, Giuseppe Calcagno, Francesco Trovò, Matteo Papini, Alberto Maria Metelli, Marco Mussi, Marcello Restelli', 'link': 'https://arxiv.org/abs/2507.00257', 'abstract': 'In recent years, \\emph{Reinforcement Learning} (RL) has made remarkable progress, achieving superhuman performance in a wide range of simulated environments. As research moves toward deploying RL in real-world applications, the field faces a new set of challenges inherent to real-world settings, such as large state-action spaces, non-stationarity, and partial observability. Despite their importance, these challenges are often underexplored in current benchmarks, which tend to focus on idealized, fully observable, and stationary environments, often neglecting to incorporate real-world complexities explicitly. In this paper, we introduce \\texttt{Gym4ReaL}, a comprehensive suite of realistic environments designed to support the development and evaluation of RL algorithms that can operate in real-world scenarios. The suite includes a diverse set of tasks that expose algorithms to a variety of practical challenges. Our experimental results show that, in these settings, standard RL algorithms confirm their competitiveness against rule-based benchmarks, motivating the development of new methods to fully exploit the potential of RL to tackle the complexities of real-world tasks.', 'abstract_zh': '近年来，强化学习（Reinforcement Learning，RL）取得了显著进展，实现了在广泛模拟环境中的超人类性能。随着研究转向在实际应用场景中部署RL，该领域面临一系列固有的新挑战，如状态-动作空间庞大、非 stationary特性和部分可观测性。尽管这些挑战至关重要，但在当前基准中往往被忽视，这些基准倾向于关注理想化的、完全可观测的和 stationary 的环境，常常未能明确纳入实际世界的复杂性。本文引进了Gym4ReaL，这是一个全面的现实环境套件，旨在支持在现实场景中运行和评估RL算法的发展。该套件包括一系列多样化的任务，使算法面临各种实际挑战。我们的实验结果表明，在这些环境中，标准RL算法在与基于规则的基准的竞争力得到了证实，这激励了开发新的方法，以充分发挥RL在应对实际任务复杂性方面的潜力。', 'title_zh': 'Gym4Real: 一套实时强化学习基准测试套件'}
{'arxiv_id': 'arXiv:2507.00248', 'title': 'Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition', 'authors': 'Nikita Nikitin, Eugene Fomin', 'link': 'https://arxiv.org/abs/2507.00248', 'abstract': "We present a novel framework for real-time sign language recognition using lightweight DNNs trained on limited data. Our system addresses key challenges in sign language recognition, including data scarcity, high computational costs, and discrepancies in frame rates between training and inference environments. By encoding sign language specific parameters, such as handshape, palm orientation, movement, and location into vectorized inputs, and leveraging MediaPipe for landmark extraction, we achieve highly separable input data representations. Our DNN architecture, optimized for sub 10MB deployment, enables accurate classification of 343 signs with less than 10ms latency on edge devices. The data annotation platform 'slait data' facilitates structured labeling and vector extraction. Our model achieved 92% accuracy in isolated sign recognition and has been integrated into the 'slait ai' web application, where it demonstrates stable inference.", 'abstract_zh': '基于轻量级DNN的有限数据实时手语识别新型框架', 'title_zh': '基于有限数据的轻量级DNN模型在实时手语识别中的开发'}
{'arxiv_id': 'arXiv:2507.00239', 'title': 'Linearly Decoding Refused Knowledge in Aligned Language Models', 'authors': 'Aryan Shrivastava, Ari Holtzman', 'link': 'https://arxiv.org/abs/2507.00239', 'abstract': 'Most commonly used language models (LMs) are instruction-tuned and aligned using a combination of fine-tuning and reinforcement learning, causing them to refuse users requests deemed harmful by the model. However, jailbreak prompts can often bypass these refusal mechanisms and elicit harmful responses. In this work, we study the extent to which information accessed via jailbreak prompts is decodable using linear probes trained on LM hidden states. We show that a great deal of initially refused information is linearly decodable. For example, across models, the response of a jailbroken LM for the average IQ of a country can be predicted by a linear probe with Pearson correlations exceeding $0.8$. Surprisingly, we find that probes trained on base models (which do not refuse) sometimes transfer to their instruction-tuned versions and are capable of revealing information that jailbreaks decode generatively, suggesting that the internal representations of many refused properties persist from base LMs through instruction-tuning. Importantly, we show that this information is not merely "leftover" in instruction-tuned models, but is actively used by them: we find that probe-predicted values correlate with LM generated pairwise comparisons, indicating that the information decoded by our probes align with suppressed generative behavior that may be expressed more subtly in other downstream tasks. Overall, our results suggest that instruction-tuning does not wholly eliminate or even relocate harmful information in representation space-they merely suppress its direct expression, leaving it both linearly accessible and indirectly influential in downstream behavior.', 'abstract_zh': '通过 Jailbreak 提示访问的信息在语言模型中的可解码性研究', 'title_zh': '在对齐语言模型中线性解码拒绝的知识'}
{'arxiv_id': 'arXiv:2507.00234', 'title': 'Interpretable AI for Time-Series: Multi-Model Heatmap Fusion with Global Attention and NLP-Generated Explanations', 'authors': 'Jiztom Kavalakkatt Francis, Matthew J Darr', 'link': 'https://arxiv.org/abs/2507.00234', 'abstract': 'In this paper, we present a novel framework for enhancing model interpretability by integrating heatmaps produced separately by ResNet and a restructured 2D Transformer with globally weighted input saliency. We address the critical problem of spatial-temporal misalignment in existing interpretability methods, where convolutional networks fail to capture global context and Transformers lack localized precision - a limitation that impedes actionable insights in safety-critical domains like healthcare and industrial monitoring. Our method merges gradient-weighted activation maps (ResNet) and Transformer attention rollout into a unified visualization, achieving full spatial-temporal alignment while preserving real-time performance. Empirical evaluations on clinical (ECG arrhythmia detection) and industrial (energy consumption prediction) datasets demonstrate significant improvements: the hybrid framework achieves 94.1% accuracy (F1 0.93) on the PhysioNet dataset and reduces regression error to RMSE = 0.28 kWh (R2 = 0.95) on the UCI Energy Appliance dataset-outperforming standalone ResNet, Transformer, and InceptionTime baselines by 3.8-12.4%. An NLP module translates fused heatmaps into domain-specific narratives (e.g., "Elevated ST-segment between 2-4 seconds suggests myocardial ischemia"), validated via BLEU-4 (0.586) and ROUGE-L (0.650) scores. By formalizing interpretability as causal fidelity and spatial-temporal alignment, our approach bridges the gap between technical outputs and stakeholder understanding, offering a scalable solution for transparent, time-aware decision-making.', 'abstract_zh': '一种结合ResNet和重构2D Transformer生成的热图并与全局加权输入显著性相融合以增强模型可解释性的新框架', 'title_zh': '时间序列可解释AI：多模型热图融合与全局注意力及NLP生成的解释'}
{'arxiv_id': 'arXiv:2507.00229', 'title': 'A High-Fidelity Speech Super Resolution Network using a Complex Global Attention Module with Spectro-Temporal Loss', 'authors': 'Tarikul Islam Tamiti, Biraj Joshi, Rida Hasan, Rashedul Hasan, Taieba Athay, Nursad Mamun, Anomadarshi Barua', 'link': 'https://arxiv.org/abs/2507.00229', 'abstract': 'Speech super-resolution (SSR) enhances low-resolution speech by increasing the sampling rate. While most SSR methods focus on magnitude reconstruction, recent research highlights the importance of phase reconstruction for improved perceptual quality. Therefore, we introduce CTFT-Net, a Complex Time-Frequency Transformation Network that reconstructs both magnitude and phase in complex domains for improved SSR tasks. It incorporates a complex global attention block to model inter-phoneme and inter-frequency dependencies and a complex conformer to capture long-range and local features, improving frequency reconstruction and noise robustness. CTFT-Net employs time-domain and multi-resolution frequency-domain loss functions for better generalization. Experiments show CTFT-Net outperforms state-of-the-art models (NU-Wave, WSRGlow, NVSR, AERO) on the VCTK dataset, particularly for extreme upsampling (2 kHz to 48 kHz), reconstructing high frequencies effectively without noisy artifacts.', 'abstract_zh': '复杂时间频率变换网络（CTFT-Net）在提高语音超分辨率中的应用', 'title_zh': '一种使用复数全局注意力模块和频谱时域损失的高保真度语音超分辨网络'}
{'arxiv_id': 'arXiv:2507.00227', 'title': 'Investigating Stochastic Methods for Prosody Modeling in Speech Synthesis', 'authors': 'Paul Mayer, Florian Lux, Alejandro Pérez-González-de-Martos, Angelina Elizarova, Lindsey Vanderlyn, Dirk Väth, Ngoc Thang Vu', 'link': 'https://arxiv.org/abs/2507.00227', 'abstract': 'While generative methods have progressed rapidly in recent years, generating expressive prosody for an utterance remains a challenging task in text-to-speech synthesis. This is particularly true for systems that model prosody explicitly through parameters such as pitch, energy, and duration, which is commonly done for the sake of interpretability and controllability. In this work, we investigate the effectiveness of stochastic methods for this task, including Normalizing Flows, Conditional Flow Matching, and Rectified Flows. We compare these methods to a traditional deterministic baseline, as well as to real human realizations. Our extensive subjective and objective evaluations demonstrate that stochastic methods produce natural prosody on par with human speakers by capturing the variability inherent in human speech. Further, they open up additional controllability options by allowing the sampling temperature to be tuned.', 'abstract_zh': '尽管生成方法在近年来取得了 rapidprogress，但在文本到语音合成中为语音生成有表现力的重音依然是一项具有挑战性的任务。特别是在通过音高、能量和时长等参数显式建模重音的系统中表现得尤为明显，这样做通常是为了提高可解释性和可控性。在本文中，我们探讨了 stochastic 方法在这一任务中的有效性，包括归一化流动、条件流动匹配和修正流动。我们将这些方法与传统的确定性基线方法以及真实的人类实现进行了对比。我们广泛进行的主观和客观评价表明，stochastic 方法能够通过捕捉人类语音固有的变异性来生成自然的重音，同时通过调节采样温度提供了额外的可控性选项。', 'title_zh': '研究语音合成中韵律模型的随机方法'}
{'arxiv_id': 'arXiv:2507.00225', 'title': 'Discovering the underlying analytic structure within Standard Model constants using artificial intelligence', 'authors': 'S. V. Chekanov, H. Kjellerstrand', 'link': 'https://arxiv.org/abs/2507.00225', 'abstract': 'This paper presents a search for underlying analytic structures among the fundamental parameters of the Standard Model (SM) using symbolic regression and genetic programming. We identify the simplest analytic relationships connecting pairs of these constants and report several notable observations based on about a thousand expressions with relative precision better than 1%. These results may serve as valuable inputs for model builders and artificial intelligence methods aimed at uncovering hidden patterns among the SM constants, or potentially used as building blocks for a deeper underlying law that connects all parameters of the SM through a small set of fundamental constants.', 'abstract_zh': '本文使用符号回归和遗传编程寻找标准模型基本参数之间的潜在分析结构，识别简单的分析关系连接这些常数的配对，并基于约一千个相对精度优于1%的表达式报告了若干显著观察结果。这些结果可作为模型构建者和旨在发现标准模型常数之间隐藏模式的人工智能方法的宝贵输入，或作为通过少量基本常数连接标准模型所有参数的更深层次基本定律的构建块。', 'title_zh': '使用人工智能发现标准模型常数背后的分析结构'}
{'arxiv_id': 'arXiv:2507.00214', 'title': 'Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning', 'authors': 'Mads Henrichsen, Rasmus Krebs', 'link': 'https://arxiv.org/abs/2507.00214', 'abstract': 'Standard classification models often map inputs directly to labels without explicit reasoning, potentially limiting their performance, robustness, and interpretability. This paper introduces a novel two-stage approach to enhance text classification by leveraging Large Language Model (LLM)-generated reasonings. In the first stage, we fine-tune a Llama-3.2-1B-Instruct model (henceforth Llama-R-Gen) on a general-purpose reasoning dataset (syvai/reasoning-gen) to generate textual reasoning (R) given a question and its answer. In the second stage, this generally trained Llama-R-Gen is used offline to create an augmented training dataset for a downstream generative model. This downstream model, based on Llama-3.2-1B-Instruct, takes only the input text (Q) and is trained to output the generated reasoning (R) immediately followed by the predicted emotion (A). We demonstrate this methodology on the dair-ai/emotion dataset for emotion classification. Our experiments show that the generative model trained to output reasoning and the emotion (Classifier Q->RA) achieves a significant improvement of 8.7 percentage points in accuracy (for emotion prediction) compared to a baseline generative model trained solely to output the emotion (Classifier Q->A), highlighting the strong generalization capabilities of the reasoning generation and the benefit of explicit reasoning training. This work underscores the potential of LLM-generated reasonings for creating richer training datasets, thereby improving the performance of diverse downstream NLP tasks and providing explicit explanations.', 'abstract_zh': '标准分类模型常常直接将输入映射到标签，而未进行明确推理，这可能会限制其性能、鲁棒性和可解释性。本文提出了一种新的两阶段方法，通过利用大型语言模型（LLM）生成的推理来增强文本分类。在第一阶段，我们在一个通用推理数据集（syvai/reasoning-gen）上微调Llama-3.2-1B-Instruct模型（以下简称Llama-R-Gen），以生成给定问题及其答案的文本推理（R）。在第二阶段，这种通用训练的Llama-R-Gen被离线使用，为下游生成模型创建扩充训练数据集。基于Llama-3.2-1B-Instruct的下游模型仅接受输入文本（Q），并训练为输出生成的推理（R）后紧跟预测的情绪（A）。我们在dair-ai/emotion数据集上对情绪分类进行了此项方法的演示。实验结果表明，用于输出推理和情绪（Classifier Q->RA）的生成模型相比仅用于输出情绪的基线生成模型（Classifier Q->A），情绪预测的准确率提高了8.7个百分点，突显了推理生成的强泛化能力和显式推理训练的益处。这项工作强调了LLM生成推理在创建更丰富的训练数据集方面的潜力，从而改善了多种下游NLP任务的性能，并提供了明确的解释。', 'title_zh': '两阶段推理注入学习：借助LLM生成的推理改进分类'}
{'arxiv_id': 'arXiv:2507.00209', 'title': 'SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures', 'authors': 'Fengyi Jiang, Xiaorui Zhang, Lingbo Jin, Ruixing Liang, Yuxin Chen, Adi Chola Venkatesh, Jason Culman, Tiantian Wu, Lirong Shao, Wenqing Sun, Cong Gao, Hallie McNamara, Jingpei Lu, Omid Mohareri', 'link': 'https://arxiv.org/abs/2507.00209', 'abstract': 'High-resolution imaging is crucial for enhancing visual clarity and enabling precise computer-assisted guidance in minimally invasive surgery (MIS). Despite the increasing adoption of 4K endoscopic systems, there remains a significant gap in publicly available native 4K datasets tailored specifically for robotic-assisted MIS. We introduce SurgiSR4K, the first publicly accessible surgical imaging and video dataset captured at a native 4K resolution, representing realistic conditions of robotic-assisted procedures. SurgiSR4K comprises diverse visual scenarios including specular reflections, tool occlusions, bleeding, and soft tissue deformations, meticulously designed to reflect common challenges faced during laparoscopic and robotic surgeries. This dataset opens up possibilities for a broad range of computer vision tasks that might benefit from high resolution data, such as super resolution (SR), smoke removal, surgical instrument detection, 3D tissue reconstruction, monocular depth estimation, instance segmentation, novel view synthesis, and vision-language model (VLM) development. SurgiSR4K provides a robust foundation for advancing research in high-resolution surgical imaging and fosters the development of intelligent imaging technologies aimed at enhancing performance, safety, and usability in image-guided robotic surgeries.', 'abstract_zh': '高分辨率成像对于提高视觉清晰度并在微创手术（MIS）中实现精确的计算机辅助引导至关重要。尽管4K内窥镜系统的应用日益广泛，但仍存在显著的数据缺口，缺乏专门针对机器人辅助MIS的原生4K公开数据集。我们介绍了SurgiSR4K，这是首个可公开访问的以原生4K分辨率捕获的手术成像和视频数据集，代表了机器人辅助手术的现实条件。SurgiSR4K包含了包括镜面反射、工具遮挡、出血和软组织变形在内的多种视觉场景，精心设计以反映腹腔镜和机器人手术中面临的常见挑战。该数据集为受益于高分辨率数据的一系列计算机视觉任务打开了可能性，如超分辨率（SR）、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新颖视图合成以及视觉-语言模型（VLM）开发。SurgiSR4K为高分辨率手术成像研究提供了坚实的基础，并促进了旨在提高图像引导机器人手术性能、安全性和易用性的智能成像技术的发展。', 'title_zh': 'SurgiSR4K: 一种用于机器人辅助微创手术的高分辨率内窥镜视频数据集'}
{'arxiv_id': 'arXiv:2507.00195', 'title': 'What Makes Local Updates Effective: The Role of Data Heterogeneity and Smoothness', 'authors': 'Kumar Kshitij Patel', 'link': 'https://arxiv.org/abs/2507.00195', 'abstract': 'This thesis contributes to the theoretical understanding of local update algorithms, especially Local SGD, in distributed and federated optimization under realistic models of data heterogeneity. A central focus is on the bounded second-order heterogeneity assumption, which is shown to be both necessary and sufficient for local updates to outperform centralized or mini-batch methods in convex and non-convex settings. The thesis establishes tight upper and lower bounds in several regimes for various local update algorithms and characterizes the min-max complexity of multiple problem classes. At its core is a fine-grained consensus-error-based analysis framework that yields sharper finite-time convergence bounds under third-order smoothness and relaxed heterogeneity assumptions. The thesis also extends to online federated learning, providing fundamental regret bounds under both first-order and bandit feedback. Together, these results clarify when and why local updates offer provable advantages, and the thesis serves as a self-contained guide for analyzing Local SGD in heterogeneous environments.', 'abstract_zh': '本论文 contributes 于局部更新算法，尤其是局部SGD，在现实数据异构性模型下的分布式和联邦优化中的理论理解。核心关注点是有限二次异构性假设，该假设在凸性和非凸设置下被证明既是必要条件也是充分条件，使得局部更新能够优于中心化或小批量方法。本文在多种局部更新算法的不同情况下建立了紧致的上界和下界，并刻画了多个问题类别的最小最大复杂性。核心在于一种精细的共识误差分析框架，该框架在三次光滑和放宽异构性假设下，提供了更为精确的有限时间收敛界限。本文还扩展到了在线联邦学习，提供了基于一阶和 bandit 反馈的本原后悔界限。综上所述，这些结果明确了在什么情况下以及为什么局部更新提供了可证明的优势，并且本文作为在异构环境分析局部SGD的自包含指南。', 'title_zh': '本地更新为何有效：数据异质性和光滑性的作用'}
{'arxiv_id': 'arXiv:2507.00191', 'title': 'Beyond Sensor Data: Foundation Models of Behavioral Data from Wearables Improve Health Predictions', 'authors': 'Eray Erturk, Fahad Kamran, Salar Abbaspourazad, Sean Jewell, Harsh Sharma, Yujie Li, Sinead Williamson, Nicholas J Foti, Joseph Futoma', 'link': 'https://arxiv.org/abs/2507.00191', 'abstract': 'Wearable devices record physiological and behavioral signals that can improve health predictions. While foundation models are increasingly used for such predictions, they have been primarily applied to low-level sensor data, despite behavioral data often being more informative due to their alignment with physiologically relevant timescales and quantities. We develop foundation models of such behavioral signals using over 2.5B hours of wearable data from 162K individuals, systematically optimizing architectures and tokenization strategies for this unique dataset. Evaluated on 57 health-related tasks, our model shows strong performance across diverse real-world applications including individual-level classification and time-varying health state prediction. The model excels in behavior-driven tasks like sleep prediction, and improves further when combined with representations of raw sensor data. These results underscore the importance of tailoring foundation model design to wearables and demonstrate the potential to enable new health applications.', 'abstract_zh': '可穿戴设备记录生理和行为信号，以改善健康预测。尽管基础模型在这些预测中越来越受欢迎，但它们主要应用于低级传感器数据，尽管行为数据由于与生理相关的时间尺度和量纲更匹配，通常更具信息性。我们使用来自162,000名个体超过25亿小时的可穿戴数据，系统地优化了该独特数据集的架构和 tokenization 策略，评估了57项与健康相关的工作任务，我们的模型在包括个体水平分类和时变健康状态预测等多种实际应用中表现出色。该模型在睡眠预测等行为驱动任务中表现出色，并且当与原始传感器数据的表示结合时可以进一步改进。这些结果强调了针对可穿戴设备调整基础模型设计的重要性，并展示了其在推动新健康应用方面的潜力。', 'title_zh': '超越传感器数据：可穿戴设备行为数据的foundation模型改善健康预测'}
{'arxiv_id': 'arXiv:2507.00185', 'title': 'Multimodal, Multi-Disease Medical Imaging Foundation Model (MerMED-FM)', 'authors': 'Yang Zhou, Chrystie Wan Ning Quek, Jun Zhou, Yan Wang, Yang Bai, Yuhe Ke, Jie Yao, Laura Gutierrez, Zhen Ling Teo, Darren Shu Jeng Ting, Brian T. Soetikno, Christopher S. Nielsen, Tobias Elze, Zengxiang Li, Linh Le Dinh, Lionel Tim-Ee Cheng, Tran Nguyen Tuan Anh, Chee Leong Cheng, Tien Yin Wong, Nan Liu, Iain Beehuat Tan, Tony Kiat Hon Lim, Rick Siow Mong Goh, Yong Liu, Daniel Shu Wei Ting', 'link': 'https://arxiv.org/abs/2507.00185', 'abstract': 'Current artificial intelligence models for medical imaging are predominantly single modality and single disease. Attempts to create multimodal and multi-disease models have resulted in inconsistent clinical accuracy. Furthermore, training these models typically requires large, labour-intensive, well-labelled datasets. We developed MerMED-FM, a state-of-the-art multimodal, multi-specialty foundation model trained using self-supervised learning and a memory module. MerMED-FM was trained on 3.3 million medical images from over ten specialties and seven modalities, including computed tomography (CT), chest X-rays (CXR), ultrasound (US), pathology patches, color fundus photography (CFP), optical coherence tomography (OCT) and dermatology images. MerMED-FM was evaluated across multiple diseases and compared against existing foundational models. Strong performance was achieved across all modalities, with AUROCs of 0.988 (OCT); 0.982 (pathology); 0.951 (US); 0.943 (CT); 0.931 (skin); 0.894 (CFP); 0.858 (CXR). MerMED-FM has the potential to be a highly adaptable, versatile, cross-specialty foundation model that enables robust medical imaging interpretation across diverse medical disciplines.', 'abstract_zh': '当前的医疗成像人工智能模型主要为单模态和单疾病模型。尝试创建多模态和多疾病模型在临床准确性上表现出不一致的结果。此外，训练这些模型通常需要大量的、劳动密集型的、高质量标注的数据集。我们开发了MerMED-FM，这是一种基于自我监督学习和记忆模块训练的最先进的多模态、多专科基础模型。MerMED-FM基于超过十种专科和七种模态的330万份医疗图像进行训练，包括CT、胸片（CXR）、超声（US）、病理切片、彩色眼底摄影（CFP）、光学相干断层扫描（OCT）和皮肤科图像。MerMED-FM在多种疾病上进行了评估，并与现有基础模型进行了对比。在所有模态中均取得了优异表现，AUROCs分别为：OCT，0.988；病理，0.982；超声，0.951；CT，0.943；皮肤，0.931；CFP，0.894；CXR，0.858。MerMED-FM有望成为一种高度适应性强、多功能且跨专科的基础模型，能够跨多种医学领域实现稳健的医疗影像解释。', 'title_zh': '多模态多疾病医疗影像基础模型（MerMED-FM）'}
{'arxiv_id': 'arXiv:2507.00184', 'title': 'Text-to-Level Diffusion Models With Various Text Encoders for Super Mario Bros', 'authors': 'Jacob Schrum, Olivia Kilday, Emilio Salas, Bess Hagan, Reid Williams', 'link': 'https://arxiv.org/abs/2507.00184', 'abstract': 'Recent research shows how diffusion models can unconditionally generate tile-based game levels, but use of diffusion models for text-to-level generation is underexplored. There are practical considerations for creating a usable model: caption/level pairs are needed, as is a text embedding model, and a way of generating entire playable levels, rather than individual scenes. We present strategies to automatically assign descriptive captions to an existing level dataset, and train diffusion models using both pretrained text encoders and simple transformer models trained from scratch. Captions are automatically assigned to generated levels so that the degree of overlap between input and output captions can be compared. We also assess the diversity and playability of the resulting levels. Results are compared with an unconditional diffusion model and a generative adversarial network, as well as the text-to-level approaches Five-Dollar Model and MarioGPT. Notably, the best diffusion model uses a simple transformer model for text embedding, and takes less time to train than diffusion models employing more complex text encoders, indicating that reliance on larger language models is not necessary. We also present a GUI allowing designers to construct long levels from model-generated scenes.', 'abstract_zh': '最近的研究显示扩散模型可以生成基于瓷砖的游戏关卡，但使用扩散模型进行文本-to-关卡生成的研究尚不充分。在创建可使用模型时存在实际考虑：需要.Caption/关卡对，需要一个文本嵌入模型，以及一种生成整个可玩关卡的方法，而不仅仅是单独的场景。我们提出了自动为现有关卡数据集分配描述性标题的策略，并使用预训练文本编码器和从头训练的简单transformer模型训练扩散模型。为生成的关卡自动分配标题，以便比较输入和输出标题之间的重叠程度。我们还评估了生成关卡的多样性和可玩性。将结果与无条件扩散模型、生成式对抗网络以及Five-Dollar Model和MarioGPT等文本-to-关卡方法进行了比较。值得注意的是，效果最佳的扩散模型使用简单的transformer模型进行文本嵌入，并且比使用更复杂文本编码器的扩散模型训练速度更快，表明依赖更大的语言模型不是必需的。我们还提供了一个GUI，允许设计师从模型生成的场景构建长关卡。', 'title_zh': '基于各种文本编码器的文本到层次扩散模型：应用于超级马里奥 Bros'}
{'arxiv_id': 'arXiv:2507.00161', 'title': 'Designing an Adaptive Storytelling Platform to Promote Civic Education in Politically Polarized Learning Environments', 'authors': 'Christopher M. Wegemer, Edward Halim, Jeff Burke', 'link': 'https://arxiv.org/abs/2507.00161', 'abstract': "Political polarization undermines democratic civic education by exacerbating identity-based resistance to opposing viewpoints. Emerging AI technologies offer new opportunities to advance interventions that reduce polarization and promote political open-mindedness. We examined novel design strategies that leverage adaptive and emotionally-responsive civic narratives that may sustain students' emotional engagement in stories, and in turn, promote perspective-taking toward members of political out-groups. Drawing on theories from political psychology and narratology, we investigate how affective computing techniques can support three storytelling mechanisms: transportation into a story world, identification with characters, and interaction with the storyteller. Using a design-based research (DBR) approach, we iteratively developed and refined an AI-mediated Digital Civic Storytelling (AI-DCS) platform. Our prototype integrates facial emotion recognition and attention tracking to assess users' affective and attentional states in real time. Narrative content is organized around pre-structured story outlines, with beat-by-beat language adaptation implemented via GPT-4, personalizing linguistic tone to sustain students' emotional engagement in stories that center political perspectives different from their own. Our work offers a foundation for AI-supported, emotionally-sensitive strategies that address affective polarization while preserving learner autonomy. We conclude with implications for civic education interventions, algorithmic literacy, and HCI challenges associated with AI dialogue management and affect-adaptive learning environments.", 'abstract_zh': '政治极化削弱了民主公民教育的效果，通过加剧基于身份的对抗观点的抵抗。新兴人工智能技术为减少极化并促进政治开明观念提供了新机会。我们研究了利用适应性和情感响应式公民叙事的新型设计策略，这些策略可能维持学生在故事中的情感参与，并进而促进对政治异见群体成员的共情。基于政治心理学和叙事学理论，我们探讨情感计算技术如何支持三种讲故事机制：进入故事世界、与角色认同以及与讲述者互动。采用设计研究（DBR）方法，我们迭代开发并精炼了一个基于人工智能的数字公民叙事平台（AI-DCS）。该原型集成了面部情绪识别和注意力追踪技术，以实时评估用户的情感和注意状态。故事内容围绕预结构化的故事情节展开，通过GPT-4逐个节拍的语言调整，个性化语言风格以维持学生对政治观点不同的故事的情感参与。我们的工作为AI支持的、情感敏感的策略提供了一个基础，这些策略能够应对情感极化同时维护学习者的自主性。我们对公民教育干预、算法素养及与AI对话管理和情感适应学习环境相关的HCI挑战进行了总结。', 'title_zh': '设计一种适应性叙事平台，以促进政治极化学习环境中的公民教育'}
{'arxiv_id': 'arXiv:2507.00145', 'title': 'AI-Hybrid TRNG: Kernel-Based Deep Learning for Near-Uniform Entropy Harvesting from Physical Noise', 'authors': 'Hasan Yiğit', 'link': 'https://arxiv.org/abs/2507.00145', 'abstract': "AI-Hybrid TRNG is a deep-learning framework that extracts near-uniform entropy directly from physical noise, eliminating the need for bulky quantum devices or expensive laboratory-grade RF receivers. Instead, it relies on a low-cost, thumb-sized RF front end, plus CPU-timing jitter, for training, and then emits 32-bit high-entropy streams without any quantization step.\nUnlike deterministic or trained artificial intelligence random number generators (RNGs), our dynamic inner-outer network couples adaptive natural sources and reseeding, yielding truly unpredictable and autonomous sequences. Generated numbers pass the NIST SP 800-22 battery better than a CPU-based method. It also passes nineteen bespoke statistical tests for both bit- and integer-level analysis. All results satisfy cryptographic standards, while forward and backward prediction experiments reveal no exploitable biases. The model's footprint is below 0.5 MB, making it deployable on MCUs and FPGA soft cores, as well as suitable for other resource-constrained platforms.\nBy detaching randomness quality from dedicated hardware, AI-Hybrid TRNG broadens the reach of high-integrity random number generators across secure systems, cryptographic protocols, embedded and edge devices, stochastic simulations, and server applications that need randomness.", 'abstract_zh': 'AI-Hybrid TRNG是一种深度学习框架，直接从物理噪声中提取近均匀熵，无需 bulky 量子设备或昂贵的实验室射频接收器，而是依赖于低成本、拇指大小的射频前端以及CPU定时抖动进行训练，随后发出32位高熵流而无需任何量化步骤。', 'title_zh': '基于内核的深度学习AI-混合TRNG：从物理噪声近均匀熵 harvesting 的内核基于深度学习方法'}
{'arxiv_id': 'arXiv:2507.00108', 'title': 'Teaching Programming in the Age of Generative AI: Insights from Literature, Pedagogical Proposals, and Student Perspectives', 'authors': 'Clemente Rubio-Manzano, Jazna Meza, Rodolfo Fernandez-Santibanez, Christian Vidal-Castro', 'link': 'https://arxiv.org/abs/2507.00108', 'abstract': 'Computer programming is undergoing a true transformation driven by powerful new tools for automatic source code generation based on large language models. This transformation is also manifesting in introductory programming courses at universities around the world, generating an in-depth debate about how programming content should be taught, learned, and assessed in the context of generative artificial intelligence.\nThis article aims, on the one hand, to review the most relevant studies on this issue, highlighting the advantages and disadvantages identified in the specialized literature. On the other hand, it proposes enriching teaching and learning methodologies by focusing on code comprehension and execution rather than on mere coding or program functionality. In particular, it advocates for the use of visual representations of code and visual simulations of its execution as effective tools for teaching, learning, and assessing programming, thus fostering a deeper understanding among students.\nFinally, the opinions of students who took the object-oriented programming course are presented to provide preliminary context supporting the incorporation of visual simulations in Java (or other languages) as part of the training process.', 'abstract_zh': '计算机编程正经历一场由基于大规模语言模型的自动源码生成新工具驱动的真实变革。这场变革也在世界各地的大学 introductory 编程课程中显现，引发了如何在生成式人工智能的背景下教授、学习和评估编程内容的深入讨论。\n\n本文一方面旨在回顾相关研究，突出专业化文献中指出的优势和劣势；另一方面，它提出了通过专注于代码理解与执行，而非仅仅是编码或程序功能，来丰富教学和学习方法的建议。特别是提倡使用代码的可视化表示和其执行的可视化模拟作为有效的教学、学习和评估编程的工具，从而促进学生更深入的理解。\n\n最后，呈现了参加面向对象编程课程的学生们的意见，为在Java（或其他语言）的培训过程中引入可视化模拟提供了初步的背景支持。', 'title_zh': '生成式AI时代的编程教学：文献洞察、教学建议与学生视角'}
{'arxiv_id': 'arXiv:2507.00102', 'title': 'Towards transparent and data-driven fault detection in manufacturing: A case study on univariate, discrete time series', 'authors': 'Bernd Hofmann, Patrick Bruendl, Huong Giang Nguyen, Joerg Franke', 'link': 'https://arxiv.org/abs/2507.00102', 'abstract': 'Ensuring consistent product quality in modern manufacturing is crucial, particularly in safety-critical applications. Conventional quality control approaches, reliant on manually defined thresholds and features, lack adaptability to the complexity and variability inherent in production data and necessitate extensive domain expertise. Conversely, data-driven methods, such as machine learning, demonstrate high detection performance but typically function as black-box models, thereby limiting their acceptance in industrial environments where interpretability is paramount. This paper introduces a methodology for industrial fault detection, which is both data-driven and transparent. The approach integrates a supervised machine learning model for multi-class fault classification, Shapley Additive Explanations for post-hoc interpretability, and a do-main-specific visualisation technique that maps model explanations to operator-interpretable features. Furthermore, the study proposes an evaluation methodology that assesses model explanations through quantitative perturbation analysis and evaluates visualisations by qualitative expert assessment. The approach was applied to the crimping process, a safety-critical joining technique, using a dataset of univariate, discrete time series. The system achieves a fault detection accuracy of 95.9 %, and both quantitative selectivity analysis and qualitative expert evaluations confirmed the relevance and inter-pretability of the generated explanations. This human-centric approach is designed to enhance trust and interpretability in data-driven fault detection, thereby contributing to applied system design in industrial quality control.', 'abstract_zh': '确保现代制造中产品质量的一致性在安全性关键应用中至关重要。传统的质量控制方法依赖于手动定义的阈值和特征，缺乏适应生产数据固有的复杂性和变异性所需的灵活性，并且需要大量的专业领域知识。相比之下，基于数据的方法，如机器学习，虽然展示出高度的检测性能，但通常作为黑盒模型运作，因此在工业环境中可解释性至上的背景下难以被接受。本文提出了一种工业故障检测方法，该方法既基于数据又是透明的。该方法结合了监督机器学习模型进行多类故障分类，Shapley 添加解释以实现事后可解释性，并使用特定于领域的可视化技术将模型解释映射到操作员可解释的特征。此外，本文还提出了一种评估方法，通过定量扰动分析评估模型解释，并通过定性的专家评估评价可视化。该方法应用于接插件压接过程，这是一种安全性关键的连接技术，使用的是单变量离散时间序列数据集。系统实现了95.9%的故障检测准确率，并且定量选择性分析和定性专家评估都证实了所生成解释的相关性和可解释性。人本中心的方法旨在增强数据驱动故障检测的信任度和可解释性，从而为工业质量控制中的应用系统设计做出贡献。', 'title_zh': '面向制造过程透明且数据驱动的故障检测：基于单变量离散时间序列的案例研究'}
{'arxiv_id': 'arXiv:2507.00096', 'title': 'AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets', 'authors': 'Ailiya Borjigin, Wei Zhou, Cong He', 'link': 'https://arxiv.org/abs/2507.00096', 'abstract': 'Alternative Assets tokenization is transforming non-traditional financial instruments are represented and traded on the web. However, ensuring trustworthiness in web-based tokenized ecosystems poses significant challenges, from verifying off-chain asset data to enforcing regulatory compliance. This paper proposes an AI-governed agent architecture that integrates intelligent agents with blockchain to achieve web-trustworthy tokenization of alternative assets. In the proposed architecture, autonomous agents orchestrate the tokenization process (asset verification, valuation, compliance checking, and lifecycle management), while an AI-driven governance layer monitors agent behavior and enforces trust through adaptive policies and cryptoeconomic incentives. We demonstrate that this approach enhances transparency, security, and compliance in asset tokenization, addressing key concerns around data authenticity and fraud. A case study on tokenizing real estate assets illustrates how the architecture mitigates risks (e.g., fraudulent listings and money laundering) through real-time AI anomaly detection and on-chain enforcement. Our evaluation and analysis suggest that combining AI governance with multi-agent systems and blockchain can significantly bolster trust in tokenized asset ecosystems. This work offers a novel framework for trustworthy asset tokenization on the web and provides insights for practitioners aiming to deploy secure, compliant tokenization platforms.', 'abstract_zh': '基于AI治理的自治代理架构在web环境中实现替代资产可信代币化', 'title_zh': '基于AI治理的智能体架构：替代资产网络可信代币化'}
{'arxiv_id': 'arXiv:2507.00094', 'title': 'Efficient Conformance Checking of Rich Data-Aware Declare Specifications (Extended)', 'authors': 'Jacobo Casas-Ramos, Sarah Winkler, Alessandro Gianola, Marco Montali, Manuel Mucientes, Manuel Lama', 'link': 'https://arxiv.org/abs/2507.00094', 'abstract': 'Despite growing interest in process analysis and mining for data-aware specifications, alignment-based conformance checking for declarative process models has focused on pure control-flow specifications, or mild data-aware extensions limited to numerical data and variable-to-constant comparisons. This is not surprising: finding alignments is computationally hard, even more so in the presence of data dependencies. In this paper, we challenge this problem in the case where the reference model is captured using data-aware Declare with general data types and data conditions. We show that, unexpectedly, it is possible to compute data-aware optimal alignments in this rich setting, enjoying at once efficiency and expressiveness. This is achieved by carefully combining the two best-known approaches to deal with control flow and data dependencies when computing alignments, namely A* search and SMT solving. Specifically, we introduce a novel algorithmic technique that efficiently explores the search space, generating descendant states through the application of repair actions aiming at incrementally resolving constraint violations. We prove the correctness of our algorithm and experimentally show its efficiency. The evaluation witnesses that our approach matches or surpasses the performance of the state of the art while also supporting significantly more expressive data dependencies, showcasing its potential to support real-world applications.', 'abstract_zh': '尽管对数据感知规范的兴趣日益增长，基于对齐的符合性检查主要集中在纯控流规范或有限的数据感知扩展（限定为数值数据和变量到常量的比较）。在参考模型使用通用数据类型和数据条件描述的Declarative过程模型中，我们面临着这一挑战。我们展示了，在这种丰富的情境下，能够同时实现高效性和表达性的数据感知最优对齐是可以计算出来的。这通过仔细结合计算对齐时处理控制流和数据依赖性的两种最知名方法——A*搜索和SMT求解——来实现。具体地，我们引入了一种新颖的算法技术，有效探索搜索空间，通过应用修复动作逐步解决约束冲突来生成后代状态。我们证明了算法的正确性，并通过实验展示了其效率。评估表明，我们的方法在性能上与当前最先进的方法相当或更优，同时支持更加丰富的数据依赖关系，展示了其支持实际应用的潜力。', 'title_zh': '丰富数据感知的Declare规范高效符合性检查（扩展版）'}
{'arxiv_id': 'arXiv:2507.00093', 'title': '$σ$-Maximal Ancestral Graphs', 'authors': 'Binghua Yao, Joris M. Mooij', 'link': 'https://arxiv.org/abs/2507.00093', 'abstract': "Maximal Ancestral Graphs (MAGs) provide an abstract representation of Directed Acyclic Graphs (DAGs) with latent (selection) variables. These graphical objects encode information about ancestral relations and d-separations of the DAGs they represent. This abstract representation has been used amongst others to prove the soundness and completeness of the FCI algorithm for causal discovery, and to derive a do-calculus for its output. One significant inherent limitation of MAGs is that they rule out the possibility of cyclic causal relationships. In this work, we address that limitation. We introduce and study a class of graphical objects that we coin ''$\\sigma$-Maximal Ancestral Graphs'' (''$\\sigma$-MAGs''). We show how these graphs provide an abstract representation of (possibly cyclic) Directed Graphs (DGs) with latent (selection) variables, analogously to how MAGs represent DAGs. We study the properties of these objects and provide a characterization of their Markov equivalence classes.", 'abstract_zh': 'σ-最大祖先图（$\\sigma$-MAGs）提供了带潜在（选择）变量的（可能循环的）有向图（DGs）的抽象表示。', 'title_zh': 'σ-极大祖先图'}
{'arxiv_id': 'arXiv:2507.00090', 'title': 'Generating Heterogeneous Multi-dimensional Data : A Comparative Study', 'authors': 'Corbeau Michael, Claeys Emmanuelle, Serrurier Mathieu, Zaraté Pascale', 'link': 'https://arxiv.org/abs/2507.00090', 'abstract': 'Allocation of personnel and material resources is highly sensible in the case of firefighter interventions. This allocation relies on simulations to experiment with various scenarios. The main objective of this allocation is the global optimization of the firefighters response. Data generation is then mandatory to study various scenarios In this study, we propose to compare different data generation methods. Methods such as Random Sampling, Tabular Variational Autoencoders, standard Generative Adversarial Networks, Conditional Tabular Generative Adversarial Networks and Diffusion Probabilistic Models are examined to ascertain their efficacy in capturing the intricacies of firefighter interventions. Traditional evaluation metrics often fall short in capturing the nuanced requirements of synthetic datasets for real-world scenarios. To address this gap, an evaluation of synthetic data quality is conducted using a combination of domain-specific metrics tailored to the firefighting domain and standard measures such as the Wasserstein distance. Domain-specific metrics include response time distribution, spatial-temporal distribution of interventions, and accidents representation. These metrics are designed to assess data variability, the preservation of fine and complex correlations and anomalies such as event with a very low occurrence, the conformity with the initial statistical distribution and the operational relevance of the synthetic data. The distribution has the particularity of being highly unbalanced, none of the variables following a Gaussian distribution, adding complexity to the data generation process.', 'abstract_zh': '消防员干预中人员和物资资源分配的高度敏感性依赖于模拟来实验各种场景。此分配的主要目标是优化消防员响应的全局效果。因此，数据生成是必需的，以研究各种场景。在本研究中，我们提出比较不同的数据生成方法。这些方法包括随机采样、表格变分自编码器、标准生成对抗网络、条件表格生成对抗网络和扩散概率模型，以确定它们在捕捉消防员干预复杂性的有效性。传统的评估指标往往在捕捉合成数据集在现实场景中的细微需求时存在局限性。因此，我们使用针对消防领域特定领域的度量标准与标准度量（如Wasserstein距离）相结合的方式评估合成数据的质量。特定领域的度量标准包括响应时间分布、干预的空间时间分布和事故表示。这些指标旨在评估数据的变化性，保持细粒度和复杂的相关性和异常值（如低发生率事件）的一致性、统计分布的符合性和合成数据的操作相关性。数据分布的特性是高度不平衡的，没有一个变量遵循正态分布，这增加了数据生成的复杂性。', 'title_zh': '生成异构多维度数据：一种比较研究'}
{'arxiv_id': 'arXiv:2507.00088', 'title': 'How large language models judge and influence human cooperation', 'authors': 'Alexandre S. Pires, Laurens Samson, Sennay Ghebreab, Fernando P. Santos', 'link': 'https://arxiv.org/abs/2507.00088', 'abstract': "Humans increasingly rely on large language models (LLMs) to support decisions in social settings. Previous work suggests that such tools shape people's moral and political judgements. However, the long-term implications of LLM-based social decision-making remain unknown. How will human cooperation be affected when the assessment of social interactions relies on language models? This is a pressing question, as human cooperation is often driven by indirect reciprocity, reputations, and the capacity to judge interactions of others. Here, we assess how state-of-the-art LLMs judge cooperative actions. We provide 21 different LLMs with an extensive set of examples where individuals cooperate -- or refuse cooperating -- in a range of social contexts, and ask how these interactions should be judged. Furthermore, through an evolutionary game-theoretical model, we evaluate cooperation dynamics in populations where the extracted LLM-driven judgements prevail, assessing the long-term impact of LLMs on human prosociality. We observe a remarkable agreement in evaluating cooperation against good opponents. On the other hand, we notice within- and between-model variance when judging cooperation with ill-reputed individuals. We show that the differences revealed between models can significantly impact the prevalence of cooperation. Finally, we test prompts to steer LLM norms, showing that such interventions can shape LLM judgements, particularly through goal-oriented prompts. Our research connects LLM-based advices and long-term social dynamics, and highlights the need to carefully align LLM norms in order to preserve human cooperation.", 'abstract_zh': '人类越来越多地依赖大型语言模型（LLMs）在社会环境中支持决策。先前的研究表明，这类工具影响人们的道德和政治判断。然而，基于LLM的社会决策长期影响尚不明了。当社会互动的评估依赖于语言模型时，人类合作将如何受到影响？这是一个紧迫的问题，因为人类合作往往受到间接 reciprocity、声誉以及评价他人互动能力的驱动。在此，我们评估了最新一代LLM对合作行为的评价。我们向21种不同的LLM提供了涵盖各种社会情境中个体合作或拒绝合作的大量范例，并询问这些互动应如何评价。此外，通过进化博弈论模型，我们评估了以这类LLM驱动的评价为主导的人群中的合作动态，考察LLM对人类利他性长期影响。我们发现，在评价与良好对手的合作时，LLM之间表现出显著的一致性。另一方面，在评价与有不良声誉的个体的合作时，我们注意到LLM之间存在差异。显示了这些差异可以显著影响合作的普遍程度。最后，我们测试了提示词以引导LLM规范，表明此类干预可以通过目标导向的提示词影响LLM的评价。我们的研究将LLM建议与长期社会动态联系起来，并强调了谨慎对齐LLM规范的必要性，以维护人类合作。', 'title_zh': '大型语言模型对人类合作的判断与影响'}
{'arxiv_id': 'arXiv:2507.00087', 'title': 'pUniFind: a unified large pre-trained deep learning model pushing the limit of mass spectra interpretation', 'authors': 'Jiale Zhao, Pengzhi Mao, Kaifei Wang, Yiming Li, Yaping Peng, Ranfei Chen, Shuqi Lu, Xiaohong Ji, Jiaxiang Ding, Xin Zhang, Yucheng Liao, Weinan E, Weijie Zhang, Han Wen, Hao Chi', 'link': 'https://arxiv.org/abs/2507.00087', 'abstract': 'Deep learning has advanced mass spectrometry data interpretation, yet most models remain feature extractors rather than unified scoring frameworks. We present pUniFind, the first large-scale multimodal pre-trained model in proteomics that integrates end-to-end peptide-spectrum scoring with open, zero-shot de novo sequencing. Trained on over 100 million open search-derived spectra, pUniFind aligns spectral and peptide modalities via cross modality prediction and outperforms traditional engines across diverse datasets, particularly achieving a 42.6 percent increase in the number of identified peptides in immunopeptidomics. Supporting over 1,300 modifications, pUniFind identifies 60 percent more PSMs than existing de novo methods despite a 300-fold larger search space. A deep learning based quality control module further recovers 38.5 percent additional peptides including 1,891 mapped to the genome but absent from reference proteomes while preserving full fragment ion coverage. These results establish a unified, scalable deep learning framework for proteomic analysis, offering improved sensitivity, modification coverage, and interpretability.', 'abstract_zh': '深度学习推动了质谱数据解释的进步，但大多数模型仍然是特征提取器而非统一评分框架。我们介绍了pUniFind，这是一种首次应用于蛋白质组学的大型多模态预训练模型，集成了从头测序和肽-谱评分的端到端评分框架。通过跨模态预测，pUniFind在多种数据集中表现优于传统引擎，特别是在免疫肽组学数据集中肽的识别数量提高了42.6%。尽管搜索空间扩大了300倍，pUniFind仍能识别比现有从头测序方法多60%的PSMs，并支持1300多种修饰。基于深度学习的质量控制模块进一步恢复了38.5%的肽，其中包括1891个归蕴基因但不在参考蛋白质组中的肽，同时保留了完整的片段离子覆盖。这些结果建立了一个统一且可扩展的深度学习框架，为蛋白质组分析提供了更高的灵敏度、修饰覆盖和解释性。', 'title_zh': 'pUniFind: 统一的大规模预训练深度学习模型pushing极限质谱解析'}
{'arxiv_id': 'arXiv:2507.00085', 'title': 'A Joint Topology-Data Fusion Graph Network for Robust Traffic Speed Prediction with Data Anomalism', 'authors': 'Ruiyuan Jiang, Dongyao Jia, Eng Gee Lim, Pengfei Fan, Yuli Zhang, Shangbo Wang', 'link': 'https://arxiv.org/abs/2507.00085', 'abstract': 'Accurate traffic prediction is essential for Intelligent Transportation Systems (ITS), yet current methods struggle with the inherent complexity and non-linearity of traffic dynamics, making it difficult to integrate spatial and temporal characteristics. Furthermore, existing approaches use static techniques to address non-stationary and anomalous historical data, which limits adaptability and undermines data smoothing. To overcome these challenges, we propose the Graph Fusion Enhanced Network (GFEN), an innovative framework for network-level traffic speed prediction. GFEN introduces a novel topological spatiotemporal graph fusion technique that meticulously extracts and merges spatial and temporal correlations from both data distribution and network topology using trainable methods, enabling the modeling of multi-scale spatiotemporal features. Additionally, GFEN employs a hybrid methodology combining a k-th order difference-based mathematical framework with an attention-based deep learning structure to adaptively smooth historical observations and dynamically mitigate data anomalies and non-stationarity. Extensive experiments demonstrate that GFEN surpasses state-of-the-art methods by approximately 6.3% in prediction accuracy and exhibits convergence rates nearly twice as fast as recent hybrid models, confirming its superior performance and potential to significantly enhance traffic prediction system efficiency.', 'abstract_zh': '基于图融合增强网络的网络级交通速度预测', 'title_zh': '一种集成拓扑与数据融合的图网络模型：具有数据异常检测的稳健交通速度预测'}
{'arxiv_id': 'arXiv:2507.00083', 'title': 'Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks', 'authors': 'Wei Meng', 'link': 'https://arxiv.org/abs/2507.00083', 'abstract': 'This study addresses the lack of structured causal modeling between tactical strike behavior and strategic delay in current strategic-level simulations, particularly the structural bottlenecks in capturing intermediate variables within the "resilience - nodal suppression - negotiation window" chain. We propose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN), a novel framework that closes the causal loop from tactical input to strategic delay output. The model integrates graph attention mechanisms, counterfactual simulation units, and spatial intervention node reconstruction to enable dynamic simulations of strike configurations and synchronization strategies. Training data are generated from a multi-physics simulation platform (GEANT4 + COMSOL) under NIST SP 800-160 standards, ensuring structural traceability and policy-level validation. Experimental results demonstrate that IA-STGNN significantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost), achieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5 percent accuracy, while improving causal path consistency and intervention stability. IA-STGNN enables interpretable prediction of strategic delay and supports applications such as nuclear deterrence simulation, diplomatic window assessment, and multi-strategy optimization, providing a structured and transparent AI decision-support mechanism for high-level policy modeling.', 'abstract_zh': '基于干预感知时空图神经网络的战略打击行为与战略延期之间的结构化因果建模', 'title_zh': '基于干预 Awareness 联合空域因果图网络的深目标空袭系统战略反事实建模'}
{'arxiv_id': 'arXiv:2507.00082', 'title': 'Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission', 'authors': 'Faranaksadat Solat, Joohyung Lee, Mohamed Seif, Dusit Niyato, H. Vincent Poor', 'link': 'https://arxiv.org/abs/2507.00082', 'abstract': "Hybrid Language Models (HLMs) combine the low-latency efficiency of Small Language Models (SLMs) on edge devices with the high accuracy of Large Language Models (LLMs) on centralized servers. Unlike traditional end-to-end LLM inference, HLMs reduce latency and communication by invoking LLMs only when local SLM predictions are uncertain, i.e., when token-level confidence is low or entropy is high. However, ambiguous or low-confidence predictions still require frequent offloading to the LLM, leading to significant communication overhead in bandwidth-constrained settings. To address this, we propose FedHLM, a communication-efficient HLM framework that integrates uncertainty-aware inference with Federated Learning (FL). FedHLM's key innovation lies in collaboratively learning token-level uncertainty thresholds that govern when LLM assistance is needed. Rather than using static or manually tuned thresholds, FedHLM employs FL to optimize these thresholds in a privacy-preserving, distributed manner. Additionally, it leverages embedding-based token representations for Peer-to-Peer (P2P) resolution, enabling clients to reuse tokens inferred by semantically similar peers without engaging the LLM. We further introduce hierarchical model aggregation: edge servers refine local routing policies through client updates, while cross-cluster coordination aligns global decision boundaries. This layered design captures recurring uncertainty patterns, reducing redundant LLM queries. Experiments on large-scale news classification tasks show that FedHLM reduces LLM transmissions by over 95 percent with negligible accuracy loss, making it well-suited for scalable and efficient edge-AI applications.", 'abstract_zh': '混合语言模型（HLMs）结合了边缘设备上小型语言模型（SLMs）的低延迟高效性和中央服务器上大型语言模型（LLMs）的高准确性。不同于传统的端到端LLM推断，HLMs通过仅在局部SLM预测不确定时（即，当Token级置信度低或熵高时）调用LLM来减少延迟和通信。然而，含糊不清或低信心的预测仍然需要频繁地卸载到LLM，导致在带宽受限的环境中产生显著的通信开销。为了解决这一问题，我们提出了一种通信高效的HLM框架FedHLM，该框架将不确定性感知推断与联邦学习（FL）相结合。FedHLM的关键创新在于协作学习用于决定何时需要LLM协助的Token级不确定性阈值。FedHLM不使用静态或手动调整的阈值，而是通过Privacy-Preserving、分布式方式利用FL优化这些阈值。此外，FedHLM利用基于嵌入的Token表示进行Peer-to-Peer（P2P）解决，使客户端能够重复使用具有语义相似性的Peer推断出的Token，而不需调用LLM。我们进一步引入了层级模型聚合：边缘服务器通过客户端更新改进局部路由策略，而跨集群协调则统一全球决策边界。这种分层设计捕获了重复出现的不确定性模式，减少了冗余的LLM查询。大规模新闻分类任务的实验结果显示，FedHLM在几乎无准确率损失的情况下将LLM传输减少了95%以上，使其非常适合可扩展且高效的边缘AI应用。', 'title_zh': '基于联邦学习的高效令牌传输混合语言模型'}
{'arxiv_id': 'arXiv:2507.00081', 'title': 'State and Memory is All You Need for Robust and Reliable AI Agents', 'authors': 'Matthew Muhoberac, Atharva Parikh, Nirvi Vakharia, Saniya Virani, Aco Radujevic, Savannah Wood, Meghav Verma, Dimitri Metaxotos, Jeyaraman Soundararajan, Thierry Masquelin, Alexander G. Godfrey, Sean Gardner, Dobrila Rudnicki, Sam Michael, Gaurav Chopra', 'link': 'https://arxiv.org/abs/2507.00081', 'abstract': 'Large language models (LLMs) have enabled powerful advances in natural language understanding and generation. Yet their application to complex, real-world scientific workflows remain limited by challenges in memory, planning, and tool integration. Here, we introduce SciBORG (Scientific Bespoke Artificial Intelligence Agents Optimized for Research Goals), a modular agentic framework that allows LLM-based agents to autonomously plan, reason, and achieve robust and reliable domain-specific task execution. Agents are constructed dynamically from source code documentation and augmented with finite-state automata (FSA) memory, enabling persistent state tracking and context-aware decision-making. This approach eliminates the need for manual prompt engineering and allows for robust, scalable deployment across diverse applications via maintaining context across extended workflows and to recover from tool or execution failures. We validate SciBORG through integration with both physical and virtual hardware, such as microwave synthesizers for executing user-specified reactions, with context-aware decision making and demonstrate its use in autonomous multi-step bioassay retrieval from the PubChem database utilizing multi-step planning, reasoning, agent-to-agent communication and coordination for execution of exploratory tasks. Systematic benchmarking shows that SciBORG agents achieve reliable execution, adaptive planning, and interpretable state transitions. Our results show that memory and state awareness are critical enablers of agentic planning and reliability, offering a generalizable foundation for deploying AI agents in complex environments.', 'abstract_zh': '大规模语言模型（LLMs）已在自然语言理解和生成方面取得了强大的进展。然而，它们在复杂的真实世界科学工作流中的应用受限于内存、规划和工具集成的挑战。在这里，我们介绍了SciBORG（专为研究目标优化的科学定制人工智能代理），这是一种模块化代理框架，允许基于LLM的代理自主规划、推理和执行稳健可靠的领域特定任务。代理动态从源代码文档构建，并通过有限状态自动机（FSA）记忆增强，以实现持久状态跟踪和上下文相关的决策制定。这种方法消除了手动提示工程的需求，并通过在整个扩展工作流中保持上下文以及从工具或执行故障中恢复，实现了稳健且可扩展的应用部署。我们通过将SciBORG与物理和虚拟硬件（如用于执行用户指定反应的微波合成器）集成，并通过上下文相关的决策制定进行验证，并展示了其在利用多步计划、推理、代理间通信和协调执行探索性任务时，从PubChem数据库自主多步生物测定检索中的应用。系统基准测试表明，SciBORG代理实现了可靠执行、适应性规划和可解释的状态转换。我们的结果表明，记忆和状态意识是代理规划和可靠性实现的关键因素，为在复杂环境中部署AI代理提供了可泛化的基础。', 'title_zh': 'State and Memory Are All You Need for Robust and Reliable AI Agents'}
{'arxiv_id': 'arXiv:2507.00078', 'title': 'The language of time: a language model perspective on time-series foundation models', 'authors': 'Yi Xie, Yun Xiong, Zejian Shi, Hao Niu, Zhengfu Liu', 'link': 'https://arxiv.org/abs/2507.00078', 'abstract': "With the rise of large language models, the paradigm of training foundation models with massive parameter counts on vast datasets has been adopted in multiple domains to achieve remarkable success. Time series foundation models represent a significant extension of this paradigm, demonstrating exceptional expressive power, generalization, and cross-domain transferability. However, this gives rise to a fundamental paradox: time series data reflect distinct dynamical systems, making cross-domain transfer intuitively implausible, yet this is contradicted by the models' empirical success. To resolve this paradox, this paper investigates, from both theoretical and experimental perspectives, the representation learning mechanisms and generalization capabilities of patch-based time series foundation models. We argue that such models are not merely applying a new architecture but are fundamentally generalizing the representation paradigm of language models by extending deterministic vector-based representations to latent probabilistic distributional forms. Our theoretical analysis supports this framework by demonstrating that continuous time-series patches can be faithfully quantized into a discrete vocabulary whose key statistical properties are highly consistent with those of natural language. This generalization allows time series models to inherit the robust representation and transfer abilities of large language models, thereby explaining their superior performance in temporal tasks. Ultimately, our work provides a rigorous theoretical cornerstone for understanding, evaluating, and improving the safety and reliability of large-scale time series foundation models.", 'abstract_zh': '大规模语言模型兴起背景下时间序列基础模型的表示学习机制与泛化能力探究', 'title_zh': '时间的语言：时间序列基础模型的语言模型视角'}
{'arxiv_id': 'arXiv:2507.00075', 'title': 'Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap', 'authors': 'Yifan Sun, Yushan Liang, Zhen Zhang, Jiaye Teng', 'link': 'https://arxiv.org/abs/2507.00075', 'abstract': "Self-improvement is among the most prominent techniques within the realm of large language models (LLM), aiming to enhance the LLM performance without relying on external data. Despite its significance, generally how LLM performances evolve during the self-improvement process remains underexplored. In this paper, we theoretically model the training dynamics of self-improvement via the concept of solver-verifier gap. This is inspired by the conjecture that the performance enhancement of self-improvement stems from the gap between LLM's solver capability and verifier capability. Based on the theoretical framework, we further introduce how to predict the ultimate power of self-improvement using only information from the first few training epochs. We empirically validate the effectiveness of the theoretical model on various LLMs and datasets. Beyond self-improvement, we extend our analysis to investigate how external data influences these dynamics within the framework. Notably, we find that under limited external data regimes, such external data can be utilized at any stage without significantly affecting final performances, which accords with the empirical observations.", 'abstract_zh': '自改进是大型语言模型（LLM）领域最显著的技术之一，旨在不依赖外部数据的情况下提升LLM性能。尽管自改进对LLM性能的影响至关重要，但自改进过程中LLM性能如何演变仍缺乏探索。在本文中，我们通过引入求解器-验证者差距的概念，理论上建模了自改进的训练动力学。基于这一理论框架，我们进一步探讨如何仅使用前几轮训练_epoch_的信息来预测自改进的最终效果。我们通过在多种LLM和数据集上进行实证验证，验证了该理论模型的有效性。除了自改进外，我们还扩展分析了外部数据如何在该框架内影响这些动力学。值得注意的是，我们的研究发现，在外部数据有限的情况下，外部数据可以在任何阶段被利用而不会显著影响最终性能，这一发现与实证观察相符。', 'title_zh': '通过求解器-验证器差距构建的大语言模型自我提升训练动力学的理论模型'}
{'arxiv_id': 'arXiv:2507.00070', 'title': 'An efficient plant disease detection using transfer learning approach', 'authors': 'Bosubabu Sambana, Hillary Sunday Nnadi, Mohd Anas Wajid, Nwosu Ogochukwu Fidelia, Claudia Camacho-Zuñiga, Henry Dozie Ajuzie, Edeh Michael Onyema', 'link': 'https://arxiv.org/abs/2507.00070', 'abstract': "Plant diseases pose significant challenges to farmers and the agricultural sector at large. However, early detection of plant diseases is crucial to mitigating their effects and preventing widespread damage, as outbreaks can severely impact the productivity and quality of crops. With advancements in technology, there are increasing opportunities for automating the monitoring and detection of disease outbreaks in plants. This study proposed a system designed to identify and monitor plant diseases using a transfer learning approach. Specifically, the study utilizes YOLOv7 and YOLOv8, two state-ofthe-art models in the field of object detection. By fine-tuning these models on a dataset of plant leaf images, the system is able to accurately detect the presence of Bacteria, Fungi and Viral diseases such as Powdery Mildew, Angular Leaf Spot, Early blight and Tomato mosaic virus. The model's performance was evaluated using several metrics, including mean Average Precision (mAP), F1-score, Precision, and Recall, yielding values of 91.05, 89.40, 91.22, and 87.66, respectively. The result demonstrates the superior effectiveness and efficiency of YOLOv8 compared to other object detection methods, highlighting its potential for use in modern agricultural practices. The approach provides a scalable, automated solution for early any plant disease detection, contributing to enhanced crop yield, reduced reliance on manual monitoring, and supporting sustainable agricultural practices.", 'abstract_zh': '植物疾病对农民和整个农业部门构成了重大挑战。然而，早期检测植物疾病对于减轻其影响和防止广泛损害至关重要，因为暴发可能严重影响作物的产量和质量。随着技术的进步，自动化监测和检测植物疾病暴发的机会不断增加。本研究提出了一种系统，旨在通过迁移学习方法识别和监测植物疾病。具体而言，该研究利用了YOLOv7和YOLOv8两种当前最先进的目标检测模型。通过在植物叶片图像数据集上对这些模型进行微调，该系统能够准确检测细菌、 fungi 和病毒性疾病，如白粉病、角度叶斑、早疫病和番茄花叶病毒。模型的性能通过平均精确召回率（mAP）、F1分数、精确率和召回率等多项指标进行了评估，分别为91.05、89.40、91.22和87.66。结果表明，YOLOv8在目标检测方法中表现出更优异的效果和效率，突显了其在现代农业实践中的应用潜力。该方法提供了一种可扩大的自动解决方案，用于早期植物疾病检测，有助于提高作物产量、减少手动监控的依赖，并支持可持续的农业实践。', 'title_zh': '使用迁移学习方法的高效植物病害检测'}
{'arxiv_id': 'arXiv:2507.00068', 'title': 'MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding', 'authors': 'Ziqi Zhong, Daniel Tang', 'link': 'https://arxiv.org/abs/2507.00068', 'abstract': "While multi-modal learning has advanced significantly, current approaches often treat modalities separately, creating inconsistencies in representation and reasoning. We introduce MANTA (Multi-modal Abstraction and Normalization via Textual Alignment), a theoretically-grounded framework that unifies visual and auditory inputs into a structured textual space for seamless processing with large language models. MANTA addresses four key challenges: (1) semantic alignment across modalities with information-theoretic optimization, (2) adaptive temporal synchronization for varying information densities, (3) hierarchical content representation for multi-scale understanding, and (4) context-aware retrieval of sparse information from long sequences. We formalize our approach within a rigorous mathematical framework, proving its optimality for context selection under token constraints. Extensive experiments on the challenging task of Long Video Question Answering show that MANTA improves state-of-the-art models by up to 22.6% in overall accuracy, with particularly significant gains (27.3%) on videos exceeding 30 minutes. Additionally, we demonstrate MANTA's superiority on temporal reasoning tasks (23.8% improvement) and cross-modal understanding (25.1% improvement). Our framework introduces novel density estimation techniques for redundancy minimization while preserving rare signals, establishing new foundations for unifying multimodal representations through structured text.", 'abstract_zh': '多模态抽象和归一化通过文本对齐', 'title_zh': 'MANTA：跨模态语义对齐与信息论优化以实现长形式多模态理解'}
{'arxiv_id': 'arXiv:2507.00066', 'title': 'InSight-R: A Framework for Risk-informed Human Failure Event Identification and Interface-Induced Risk Assessment Driven by AutoGraph', 'authors': 'Xingyu Xiao, Jiejuan Tong, Peng Chen, Jun Sun, Zhe Sui, Jingang Liang, Hongru Zhao, Jun Zhao, Haitao Wang', 'link': 'https://arxiv.org/abs/2507.00066', 'abstract': 'Human reliability remains a critical concern in safety-critical domains such as nuclear power, where operational failures are often linked to human error. While conventional human reliability analysis (HRA) methods have been widely adopted, they rely heavily on expert judgment for identifying human failure events (HFEs) and assigning performance influencing factors (PIFs). This reliance introduces challenges related to reproducibility, subjectivity, and limited integration of interface-level data. In particular, current approaches lack the capacity to rigorously assess how human-machine interface design contributes to operator performance variability and error susceptibility. To address these limitations, this study proposes a framework for risk-informed human failure event identification and interface-induced risk assessment driven by AutoGraph (InSight-R). By linking empirical behavioral data to the interface-embedded knowledge graph (IE-KG) constructed by the automated graph-based execution framework (AutoGraph), the InSight-R framework enables automated HFE identification based on both error-prone and time-deviated operational paths. Furthermore, we discuss the relationship between designer-user conflicts and human error. The results demonstrate that InSight-R not only enhances the objectivity and interpretability of HFE identification but also provides a scalable pathway toward dynamic, real-time human reliability assessment in digitalized control environments. This framework offers actionable insights for interface design optimization and contributes to the advancement of mechanism-driven HRA methodologies.', 'abstract_zh': '人因可靠性仍然是核能等安全关键领域中的一个关键关切，操作故障往往与人为错误相关联。尽管传统的人因可靠性分析（HRA）方法已被广泛应用，但它们高度依赖专家判断来识别人为失败事件（HFEs）和分配绩效影响因素（PIFs）。这种依赖性引入了可重复性、主观性和接口级数据整合有限的挑战。特别是，当前方法缺乏评估人机界面设计如何影响操作员绩效变异性和错误易感性的能力。为了解决这些限制，本研究提出了一种基于AutoGraph（InSight-R）的基于风险的人因失败事件识别和接口诱发风险评估框架。通过将行为数据与通过自动图基执行框架（AutoGraph）构建的接口嵌入知识图（IE-KG）相结合，InSight-R框架能够基于易出错和时间偏离的操作路径自动识别HFE。此外，我们讨论了设计者和用户之间的冲突与人为错误之间的关系。结果表明，InSight-R不仅增强了HFE识别的客观性和可解释性，还提供了一种可扩展的途径，以实现数字化控制环境中的动态、实时的人因可靠性评估。该框架提供了针对界面设计优化的可操作见解，并促进了机制驱动的HRA方法论的进步。', 'title_zh': '基于AutoGraph的风险导向人类失效事件识别和接口诱发风险评估框架：InSight-R'}
{'arxiv_id': 'arXiv:2507.00061', 'title': 'Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data', 'authors': 'Hoang-Dieu Vu, Duc-Nghia Tran, Quang-Tu Pham, Hieu H. Pham, Nicolas Vuillerme, Duc-Tan Tran', 'link': 'https://arxiv.org/abs/2507.00061', 'abstract': 'This paper introduces Smooth-Distill, a novel self-distillation framework designed to simultaneously perform human activity recognition (HAR) and sensor placement detection using wearable sensor data. The proposed approach utilizes a unified CNN-based architecture, MTL-net, which processes accelerometer data and branches into two outputs for each respective task. Unlike conventional distillation methods that require separate teacher and student models, the proposed framework utilizes a smoothed, historical version of the model itself as the teacher, significantly reducing training computational overhead while maintaining performance benefits. To support this research, we developed a comprehensive accelerometer-based dataset capturing 12 distinct sleep postures across three different wearing positions, complementing two existing public datasets (MHealth and WISDM). Experimental results show that Smooth-Distill consistently outperforms alternative approaches across different evaluation scenarios, achieving notable improvements in both human activity recognition and device placement detection tasks. This method demonstrates enhanced stability in convergence patterns during training and exhibits reduced overfitting compared to traditional multitask learning baselines. This framework contributes to the practical implementation of knowledge distillation in human activity recognition systems, offering an effective solution for multitask learning with accelerometer data that balances accuracy and training efficiency. More broadly, it reduces the computational cost of model training, which is critical for scenarios requiring frequent model updates or training on resource-constrained platforms. The code and model are available at this https URL\\_distill.', 'abstract_zh': 'Smooth-Distill: 一种同时进行人体活动识别和传感器位置检测的新型自蒸馏框架', 'title_zh': 'Smooth-Distill：一种用于穿戴传感器数据多任务学习的自蒸馏框架'}
{'arxiv_id': 'arXiv:2507.00057', 'title': 'Estimating Correctness Without Oracles in LLM-Based Code Generation', 'authors': 'Thomas Valentin, Ardi Madadi, Gaetano Sapia, Marcel Böhme', 'link': 'https://arxiv.org/abs/2507.00057', 'abstract': 'Generating code from natural language specifications is one of the most successful applications of Large Language Models (LLMs). Yet, they hallucinate: LLMs produce outputs that may be grammatically correct but are factually incorrect. Without an existing, correct implementation (i.e., an oracle), can we quantify how likely the generated program is correct?\nIn this paper, we propose a measure of incorrectness, called incoherence, that can be estimated efficiently in the absence of an oracle and provides a lower bound on the error, i.e., the probability that the LLM-generated program for that specification is incorrect. Our experiments demonstrate an extraordinary effectiveness. For the average code generation task, our incoherence-based methodology can automatically identify about two-thirds of incorrect programs without reports of false positives. In fact, an oracle-based evaluation of LLMs can be reliably replaced by an incoherence-based evaluation. In particular, we find a very strong agreement between the ranking of LLMs by the number of programs deemed correct via an oracle (pass@1) and the ranking of LLMs by the number of programs deemed correct via our incoherence.', 'abstract_zh': '从自然语言规范生成代码是大型语言模型（LLMs）最成功的应用之一。然而，它们会产生幻觉：即生成的输出可能是语法正确的但却是事实错误的。没有现有正确实现（即 oracle）的情况下，我们能否量化生成的程序正确性的概率？\n在本文中，我们提出了一种称为不一致性的度量方法，可以在没有 oracle 的情况下高效估算，并提供错误的概率下界，即 LLM 生成的程序对于该规范是错误的概率。我们的实验表明了该方法的非凡效果。对于平均的代码生成任务，我们的基于不一致性的方法可以自动识别大约三分之二的错误程序，并且不会出现误报。事实上，使用 oracle 评估 LLM 可以可靠地被基于不一致性的评估所替代。特别是，我们发现通过 oracle 认定的正确程序数量对 LLM 进行排名（pass@1）与通过我们的不一致性认定的正确程序数量对 LLM 进行排名之间存在非常强的一致性。', 'title_zh': '基于大型语言模型的代码生成中无需或acles估计正确性'}
{'arxiv_id': 'arXiv:2507.00052', 'title': 'VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models', 'authors': 'Binesh Sadanandan, Vahid Behzadan', 'link': 'https://arxiv.org/abs/2507.00052', 'abstract': 'Vision Language Models (VLMs) hold great promise for streamlining labour-intensive medical imaging workflows, yet systematic security evaluations in clinical settings remain scarce. We introduce VSF--Med, an end-to-end vulnerability-scoring framework for medical VLMs that unites three novel components: (i) a rich library of sophisticated text-prompt attack templates targeting emerging threat vectors; (ii) imperceptible visual perturbations calibrated by structural similarity (SSIM) thresholds to preserve clinical realism; and (iii) an eight-dimensional rubric evaluated by two independent judge LLMs, whose raw scores are consolidated via z-score normalization to yield a 0--32 composite risk metric. Built entirely on publicly available datasets and accompanied by open-source code, VSF--Med synthesizes over 30,000 adversarial variants from 5,000 radiology images and enables reproducible benchmarking of any medical VLM with a single command. Our consolidated analysis reports mean z-score shifts of $0.90\\sigma$ for persistence-of-attack-effects, $0.74\\sigma$ for prompt-injection effectiveness, and $0.63\\sigma$ for safety-bypass success across state-of-the-art VLMs. Notably, Llama-3.2-11B-Vision-Instruct exhibits a peak vulnerability increase of $1.29\\sigma$ for persistence-of-attack-effects, while GPT-4o shows increases of $0.69\\sigma$ for that same vector and $0.28\\sigma$ for prompt-injection attacks.', 'abstract_zh': '基于视觉语言模型的医疗领域漏洞评分框架：VSF--Med', 'title_zh': '医疗视觉-语言模型的脆弱性评分框架(VSF-Med)'}
{'arxiv_id': 'arXiv:2507.00045', 'title': 'CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning', 'authors': 'Ming Li, Chenguang Wang, Yijun Liang, Xiyao Wang, Yuhang Zhou, Xiyang Wu, Yuqing Zhang, Ruiyi Zhang, Tianyi Zhou', 'link': 'https://arxiv.org/abs/2507.00045', 'abstract': "Recent agentic Multi-Modal Large Language Models (MLLMs) such as GPT-o3 have achieved near-ceiling scores on various existing benchmarks, motivating a demand for more challenging test tasks. These MLLMs have been reported to excel in a few expert-level tasks for humans, e.g., GeoGuesser, reflecting their potential as a detective who can notice minuscule cues in an image and weave them into coherent, situational explanations, leading to a reliable answer. But can they match the performance of excellent human detectives? To answer this question, we investigate some hard scenarios where GPT-o3 can still handle, and find a common scenario where o3's performance drops to nearly zero, which we name CaughtCheating. It is inspired by the social media requests that ask others to detect suspicious clues from photos shared by the poster's partner. We conduct extensive experiments and analysis to understand why existing MLLMs lack sufficient capability to solve this kind of task. CaughtCheating provides a class of challenging visual perception and reasoning tasks with great value and practical usage. Success in these tasks paves the way for MLLMs to acquire human-level detective perception and reasoning capabilities.", 'abstract_zh': '近期代理多模态大型语言模型（MLLMs）如GPT-o3已在多种现有基准上取得了接近天花板的分数，推动了对更具挑战性测试任务的需求。这些MLLMs在少数人类专家级任务上表现出色，例如GeoGuesser，反映出它们作为侦探的潜力，能够注意到图像中的微小线索并将其编织成连贯的情境解释，从而得出可靠的答案。但它们能否达到优秀人类侦探的性能？为了回答这个问题，我们调查了GPT-o3仍能够处理的一些困难场景，并发现了一个常见场景，其中o3的表现几乎降至零，我们将其命名为CaughtCheating。这一灵感来源于社交媒体上的请求，要求他人检测上传者合作伙伴共享的照片中的可疑线索。我们进行了广泛的实验和分析，以了解现有MLLMs为何缺乏解决此类任务所需的能力。CaughtCheating提供了一类具有重要价值和实际用途的视觉感知和推理挑战任务。在这些任务中的成功为MLLMs获取人类级侦探感知和推理能力铺平了道路。', 'title_zh': 'Caught Cheating: 是你的大规模语言模型擅长检测作弊吗？探索视觉感知与推理的边界'}
{'arxiv_id': 'arXiv:2507.00044', 'title': 'HistoART: Histopathology Artifact Detection and Reporting Tool', 'authors': 'Seyed Kahaki, Alexander R. Webber, Ghada Zamzmi, Adarsh Subbaswamy, Rucha Deshpande, Aldo Badano', 'link': 'https://arxiv.org/abs/2507.00044', 'abstract': 'In modern cancer diagnostics, Whole Slide Imaging (WSI) is widely used to digitize tissue specimens for detailed, high-resolution examination; however, other diagnostic approaches, such as liquid biopsy and molecular testing, are also utilized based on the cancer type and clinical context. While WSI has revolutionized digital histopathology by enabling automated, precise analysis, it remains vulnerable to artifacts introduced during slide preparation and scanning. These artifacts can compromise downstream image analysis. To address this challenge, we propose and compare three robust artifact detection approaches for WSIs: (1) a foundation model-based approach (FMA) using a fine-tuned Unified Neural Image (UNI) architecture, (2) a deep learning approach (DLA) built on a ResNet50 backbone, and (3) a knowledge-based approach (KBA) leveraging handcrafted features from texture, color, and frequency-based metrics. The methods target six common artifact types: tissue folds, out-of-focus regions, air bubbles, tissue damage, marker traces, and blood contamination. Evaluations were conducted on 50,000+ image patches from diverse scanners (Hamamatsu, Philips, Leica Aperio AT2) across multiple sites. The FMA achieved the highest patch-wise AUROC of 0.995 (95% CI [0.994, 0.995]), outperforming the ResNet50-based method (AUROC: 0.977, 95% CI [0.977, 0.978]) and the KBA (AUROC: 0.940, 95% CI [0.933, 0.946]). To translate detection into actionable insights, we developed a quality report scorecard that quantifies high-quality patches and visualizes artifact distributions.', 'abstract_zh': '现代癌症诊断中，全视野成像（WSI）广泛用于数字化组织样本以进行详细高分辨率检查；然而，基于癌症类型和临床背景，也常采用液体活检和分子检测等其他诊断方法。虽然WSI通过实现自动化精确分析革命了数字病理科，但仍然容易受到制片和扫描过程中引入的伪影影响，这些伪影可能会干扰后续图像分析。为应对这一挑战，我们提出并对比了三种稳健的WSI伪影检测方法：（1）基于基础模型的方法（FMA）使用微调过的统一神经图像（UNI）架构，（2）基于深度学习的方法（DLA）以ResNet50为骨干网络，（3）基于知识的方法（KBA）利用来自纹理、颜色和频率特征的手工设计特征。这些方法针对六种常见的伪影类型：组织褶皱、焦外区域、气泡、组织损伤、标记痕迹和血液污染。评估在来自不同扫描仪（Hamamatsu、Philips、Leica Aperio AT2）的多个站点的超过50,000个图像块上进行。FMA在块级别的AUROC达到0.995（95% CI [0.994, 0.995]），优于ResNet50基方法（AUROC: 0.977, 95% CI [0.977, 0.978]）和KBA（AUROC: 0.940, 95% CI [0.933, 0.946]）。为了将检测转化为 actionable 洞察，我们开发了一个质量报告评分卡，量化高质量图像块并可视化伪影分布。', 'title_zh': 'HistoART: 组织病理学 artefact 检测与报告工具'}
{'arxiv_id': 'arXiv:2507.00043', 'title': 'MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations', 'authors': 'Mehmet Yigit Avci, Pedro Borges, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso', 'link': 'https://arxiv.org/abs/2507.00043', 'abstract': 'Accurate interpretation of Magnetic Resonance Imaging scans in clinical systems is based on a precise understanding of image contrast. This contrast is primarily governed by acquisition parameters, such as echo time and repetition time, which are stored in the DICOM metadata. To simplify contrast identification, broad labels such as T1-weighted or T2-weighted are commonly used, but these offer only a coarse approximation of the underlying acquisition settings. In many real-world datasets, such labels are entirely missing, leaving raw acquisition parameters as the only indicators of contrast. Adding to this challenge, the available metadata is often incomplete, noisy, or inconsistent. The lack of reliable and standardized metadata complicates tasks such as image interpretation, retrieval, and integration into clinical workflows. Furthermore, robust contrast-aware representations are essential to enable more advanced clinical applications, such as achieving modality-invariant representations and data harmonization. To address these challenges, we propose MR-CLIP, a multimodal contrastive learning framework that aligns MR images with their DICOM metadata to learn contrast-aware representations, without relying on manual labels. Trained on a diverse clinical dataset that spans various scanners and protocols, MR-CLIP captures contrast variations across acquisitions and within scans, enabling anatomy-invariant representations. We demonstrate its effectiveness in cross-modal retrieval and contrast classification, highlighting its scalability and potential for further clinical applications. The code and weights are publicly available at this https URL.', 'abstract_zh': '精确解析临床系统中的磁共振成像扫描需要对图像对比度有精准的理解。这一对比度主要由采集参数（如回波时间及重复时间）控制，这些参数存储在DICOM元数据中。为了简化对比度识别，通常使用如T1加权或T2加权等宽泛标签，但这些标签仅提供了一种粗略的采集设置近似值。在许多实际数据集中，这些标签可能完全缺失，使原始采集参数成为唯一能反映对比度的指标。此外，可用的元数据往往不完备、噪声大或不一致。缺乏可靠的标准化元数据使得图像解析、检索及整合到临床工作流程中任务复杂化。进一步而言，具备对比度感知的稳健表示对于实现模态不变表示和数据规范化等更高级的临床应用至关重要。为应对这些挑战，我们提出MR-CLIP，这是一种多模态对比学习框架，能够通过与DICOM元数据对齐MRI图像来学习对比度感知表示，无需依赖手动标签。MR-CLIP在涵盖多种扫描器和协议的多样临床数据集上进行训练，能够捕捉不同采集间的对比度变化，并在扫描内部捕捉对比度变化，实现解剖结构不变的表示。我们展示了MR-CLIP在跨模态检索和对比度分类中的有效性，突显其可扩展性及其在进一步临床应用中的潜力。相关代码和权重可在以下网址公开获取：this https URL。', 'title_zh': 'MR-CLIP: 效率导向的 metadata 引导的 MRI 对比度表示学习'}
{'arxiv_id': 'arXiv:2507.00042', 'title': 'Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay', 'authors': 'Xinrun Xu, Jianwen Yang, Qiuhong Zhang, Zhanbiao Lian, Zhiming Ding, Shan Jiang', 'link': 'https://arxiv.org/abs/2507.00042', 'abstract': 'Continually adapting edge models in cloud-edge collaborative object detection for traffic monitoring suffers from catastrophic forgetting, where models lose previously learned knowledge when adapting to new data distributions. This is especially problematic in dynamic traffic environments characterised by periodic variations (e.g., day/night, peak hours), where past knowledge remains valuable. Existing approaches like experience replay and visual prompts offer some mitigation, but struggle to effectively prioritize and leverage historical data for optimal knowledge retention and adaptation. Specifically, simply storing and replaying all historical data can be inefficient, while treating all historical experiences as equally important overlooks their varying relevance to the current domain. This paper proposes ER-EMU, an edge model update algorithm based on adaptive experience replay, to address these limitations. ER-EMU utilizes a limited-size experience buffer managed using a First-In-First-Out (FIFO) principle, and a novel Domain Distance Metric-based Experience Selection (DDM-ES) algorithm. DDM-ES employs the multi-kernel maximum mean discrepancy (MK-MMD) to quantify the dissimilarity between target domains, prioritizing the selection of historical data that is most dissimilar to the current target domain. This ensures training diversity and facilitates the retention of knowledge from a wider range of past experiences, while also preventing overfitting to the new domain. The experience buffer is also updated using a simple random sampling strategy to maintain a balanced representation of previous domains. Experiments on the Bellevue traffic video dataset, involving repeated day/night cycles, demonstrate that ER-EMU consistently improves the performance of several state-of-the-art cloud-edge collaborative object detection frameworks.', 'abstract_zh': '基于自适应经验回放的边缘模型更新算法ER-EMU在云边协同交通监控目标检测中的持续适应', 'title_zh': '通过差异加权经验重播减轻灾难性遗忘'}
{'arxiv_id': 'arXiv:2507.00039', 'title': 'Pattern-Based Graph Classification: Comparison of Quality Measures and Importance of Preprocessing', 'authors': 'Lucas Potin, Rosa Figueiredo, Vincent Labatut, Christine Largeron', 'link': 'https://arxiv.org/abs/2507.00039', 'abstract': 'Graph classification aims to categorize graphs based on their structural and attribute features, with applications in diverse fields such as social network analysis and bioinformatics. Among the methods proposed to solve this task, those relying on patterns (i.e. subgraphs) provide good explainability, as the patterns used for classification can be directly interpreted. To identify meaningful patterns, a standard approach is to use a quality measure, i.e. a function that evaluates the discriminative power of each pattern. However, the literature provides tens of such measures, making it difficult to select the most appropriate for a given application. Only a handful of surveys try to provide some insight by comparing these measures, and none of them specifically focuses on graphs. This typically results in the systematic use of the most widespread measures, without thorough evaluation. To address this issue, we present a comparative analysis of 38 quality measures from the literature. We characterize them theoretically, based on four mathematical properties. We leverage publicly available datasets to constitute a benchmark, and propose a method to elaborate a gold standard ranking of the patterns. We exploit these resources to perform an empirical comparison of the measures, both in terms of pattern ranking and classification performance. Moreover, we propose a clustering-based preprocessing step, which groups patterns appearing in the same graphs to enhance classification performance. Our experimental results demonstrate the effectiveness of this step, reducing the number of patterns to be processed while achieving comparable performance. Additionally, we show that some popular measures widely used in the literature are not associated with the best results.', 'abstract_zh': '图分类旨在根据图的结构和属性特征对其进行分类，应用于社会网络分析、生物informatics等多个领域。为了解决这一任务，依赖模式（即子图）的方法提供了良好的可解释性，因为用于分类的模式可以直接进行解释。为了识别有意义的模式，标准做法是使用质量度量，即评估每个模式的区分能力的函数。然而，文献中提供了几十种这样的度量，使得选择最适合特定应用的度量变得困难。只有少数综述试图通过比较这些度量来提供一些见解，但它们均未特别关注图。这通常导致系统地使用最流行的度量，而没有进行彻底的评估。为解决这一问题，我们对文献中提出的38种质量度量进行了比较分析。基于四种数学性质对其进行了理论特征化。利用公开可用的数据集构成基准，并提出了一种方法来制定模式的黄金标准排名。我们利用这些资源从模式排名和分类性能两方面对这些度量进行了实证比较。此外，我们提出了一个基于聚类的预处理步骤，该步骤将同一图中出现的模式分组，以提高分类性能。实验结果表明，该步骤的有效性，减少了需要处理的模式数量，同时保持了类似的表现力。另外，我们还表明，文献中广泛使用的某些流行度量并不总是与最佳结果相关。', 'title_zh': '基于模式的图分类：质量度量的比较与预处理的重要性'}
{'arxiv_id': 'arXiv:2507.00038', 'title': 'Quality over Quantity: An Effective Large-Scale Data Reduction Strategy Based on Pointwise V-Information', 'authors': 'Fei Chen, Wenchi Zhou', 'link': 'https://arxiv.org/abs/2507.00038', 'abstract': 'Data reduction plays a vital role in data-centric AI by identifying the most informative instance within large-scale datasets to enhance model training efficiency. The core challenge lies in how to select the optimal instances-rather than the entire datasets-to improve data quality and training efficiency. In this paper, we propose an effective data reduction strategy based on Pointwise V-information(PVI). First, we quantify instance difficulty using PVI and filter out low-difficulty instances enabling a static approach. Experiments demonstrate that removing 10%-30% of the data preserves the classifier performance with only a 0.0001% to 0.76% loss in this http URL, we use a progressive learning approach to training the classifiers on instances sorted by ascending PVI, accelerating convergence and achieving a 0.8% accuracy gain over conventional training. Our results suggest that with the effective data reduction strategy, training a classifier on the selected optimal subset could enhance the model performance and boost training efficiency. Moreover, we have transferred the PVI framework, which previously applied only to English datasets, to diverse Chinese NLP tasks and base models, leading to valuable insights for cross-lingual data reduction and faster training. The codes are released at this https URL.', 'abstract_zh': '数据约简在以数据为中心的人工智能中的重要作用在于通过识别大规模数据集中的最有信息性实例来提升模型训练效率。核心挑战在于如何选择最优实例而非整个数据集，以提升数据质量和训练效率。在本文中，我们提出了一种基于点维V-信息（PVI）的有效数据约简策略。首先，我们使用PVI量化实例难度并过滤掉低难度实例，采用静态方法。实验结果显示，移除10%-30%的数据，在本httpUrl上仅损失0.0001%至0.76%的分类器性能。在本httpUrl中，我们采用渐进学习方法，在按升序PVI排列的实例上训练分类器，加速收敛并比传统训练提升0.8%的准确率。我们的结果表明，通过有效的数据约简策略，在选定的最优子集上训练分类器能够提升模型性能并增强训练效率。此外，我们将仅应用于英文数据集的PVI框架扩展到多种中文NLP任务和基模型，为跨语言数据约简和更快的训练提供了宝贵见解。相关代码发布于本httpsUrl。', 'title_zh': '质胜于量：一种基于点ewise V-信息的大规模数据缩减有效策略'}
{'arxiv_id': 'arXiv:2507.00037', 'title': 'Model Fusion via Neuron Interpolation', 'authors': 'Phoomraphee Luenam, Andreas Spanopoulos, Amit Sant, Thomas Hofmann, Sotiris Anagnostidis, Sidak Pal Singh', 'link': 'https://arxiv.org/abs/2507.00037', 'abstract': 'Model fusion aims to combine the knowledge of multiple models by creating one representative model that captures the strengths of all of its parents. However, this process is non-trivial due to differences in internal representations, which can stem from permutation invariance, random initialization, or differently distributed training data. We present a novel, neuron-centric family of model fusion algorithms designed to integrate multiple trained neural networks into a single network effectively regardless of training data distribution. Our algorithms group intermediate neurons of parent models to create target representations that the fused model approximates with its corresponding sub-network. Unlike prior approaches, our approach incorporates neuron attribution scores into the fusion process. Furthermore, our algorithms can generalize to arbitrary layer types. Experimental results on various benchmark datasets demonstrate that our algorithms consistently outperform previous fusion techniques, particularly in zero-shot and non-IID fusion scenarios. The code is available at this https URL.', 'abstract_zh': '模型融合旨在通过创建一个代表模型来整合多个模型的知识，该模型能够捕捉所有父模型的优点。然而，这一过程由于内部表示的差异性而不 trivial，这种差异可能源自置换不变性、随机初始化或训练数据分布的不同。我们提出了一种以神经元为中心的新型模型融合算法家族，能够在不同训练数据分布的情况下有效整合多个训练好的神经网络。我们的算法通过将父模型的中间神经元分组来创建目标表示，融合模型通过其相应的子网络对其进行近似。与先前的方法不同，我们的方法将神经元归属得分纳入了融合过程。此外，我们的算法可以泛化到任意层类型。在各种基准数据集上的实验结果表明，我们的算法在零样本和非IID融合场景中始终优于之前的融合技术。代码可在以下链接获取：this https URL。', 'title_zh': '神经元插值驱动的模型融合'}
{'arxiv_id': 'arXiv:2507.00033', 'title': 'Moment Sampling in Video LLMs for Long-Form Video QA', 'authors': 'Mustafa Chasmai, Gauri Jagatap, Gouthaman KV, Grant Van Horn, Subhransu Maji, Andrea Fanelli', 'link': 'https://arxiv.org/abs/2507.00033', 'abstract': 'Recent advancements in video large language models (Video LLMs) have significantly advanced the field of video question answering (VideoQA). While existing methods perform well on short videos, they often struggle with long-range reasoning in longer videos. To scale Video LLMs for longer video content, frame sub-sampling (selecting frames at regular intervals) is commonly used. However, this approach is suboptimal, often leading to the loss of crucial frames or the inclusion of redundant information from multiple similar frames. Missing key frames impairs the model\'s ability to answer questions accurately, while redundant frames lead the model to focus on irrelevant video segments and increase computational resource consumption. In this paper, we investigate the use of a general-purpose text-to-video moment retrieval model to guide the frame sampling process. We propose "moment sampling", a novel, model-agnostic approach that enables the model to select the most relevant frames according to the context of the question. Specifically, we employ a lightweight moment retrieval model to prioritize frame selection. By focusing on the frames most pertinent to the given question, our method enhances long-form VideoQA performance in Video LLMs. Through extensive experiments on four long-form VideoQA datasets, using four state-of-the-art Video LLMs, we demonstrate the effectiveness of the proposed approach.', 'abstract_zh': '近期视频大规模语言模型（Video LLMs）的发展显著推动了视频问答（VideoQA）领域的进步。尽管现有方法在短视频上表现良好，但它们往往难以处理长视频中的长程推理。为了扩展Video LLMs以应对更长的视频内容，常用的帧下采样方法（即以固定间隔选择帧）虽然实用，但并不理想，常常导致关键帧的丢失或包含多个相似帧的冗余信息。丢失关键帧会削弱模型准确回答问题的能力，而冗余帧则会让模型关注无关的视频片段，并增加计算资源消耗。在本文中，我们探讨了使用通用文本到视频时刻检索模型来指导帧采样过程。我们提出了一种名为“时刻采样”的新型、模型无关的方法，使模型能够根据问题的上下文选择最相关的帧。具体而言，我们采用轻量级的时刻检索模型来优先选择帧。通过专注于与给定问题最相关的帧，我们的方法增强了Video LLMs的长视频问答性能。通过在四个长视频问答数据集上使用四种最先进的Video LLMs进行广泛实验，我们验证了所提出方法的有效性。', 'title_zh': '视频LLMs中用于长视频QA的时刻采样方法'}
{'arxiv_id': 'arXiv:2507.00032', 'title': "Ken Utilization Layer: Hebbian Replay Within a Student's Ken for Adaptive Knowledge Tracing", 'authors': 'Grey Kuling, Marinka Zitnik', 'link': 'https://arxiv.org/abs/2507.00032', 'abstract': 'We introduce KUL-KT, a biologically inspired architecture for knowledge tracing (KT), combining Hebbian memory encoding with gradient-based consolidation in a scalable, input-agnostic framework. KUL-KT adapts the principle of memory consolidation in neural systems, to student modeling by introducing two key innovations: (i) a time-decaying Hebbian memory update that enables graceful forgetting, and (ii) a novel Loss-aligned Internal Target (LIT) method to compute an ideal internal state, allowing continual learning without backpropagation through time. The architecture consists of a fast Hebbian memory that captures each learner interaction via a single associative update, and a slower linear network that consolidates recalled samples through gradient descent. This design enables few-shot personalization and natural forgetting without storing raw data or relying on large cohort training. Operating entirely in embedding space, KUL-KT supports both structured (tabular) and unstructured (short-answer) inputs. Empirically, KUL-KT outperforms strong baselines on ten public KT benchmarks in rank-sensitive metrics such as nDCG and Recall@10. In a classroom deployment, KUL-KT personalized quizzes from short-answer data, leading to improved learner-perceived helpfulness and reduced difficulty (p < 0.05). Ablation studies confirm that Hebbian decay and LIT are critical for continual adaptation. Compared to a strong graph-based KT model, KUL-KT trains 1.75x faster and uses 99.01\\% less memory. These results position KUL-KT as a biologically grounded, memory-efficient, and input-flexible framework for personalized learning at scale.', 'abstract_zh': 'KUL-KT：一种生物启发的知识追踪架构', 'title_zh': 'Ken 利用层：学生 ken 内的基于 Hebbian 的回放以实现自适应知识追踪'}
{'arxiv_id': 'arXiv:2507.00030', 'title': 'Adaptive Action Duration with Contextual Bandits for Deep Reinforcement Learning in Dynamic Environments', 'authors': 'Abhishek Verma, Nallarasan V, Balaraman Ravindran', 'link': 'https://arxiv.org/abs/2507.00030', 'abstract': 'Deep Reinforcement Learning (DRL) has achieved remarkable success in complex sequential decision-making tasks, such as playing Atari 2600 games and mastering board games. A critical yet underexplored aspect of DRL is the temporal scale of action execution. We propose a novel paradigm that integrates contextual bandits with DRL to adaptively select action durations, enhancing policy flexibility and computational efficiency. Our approach augments a Deep Q-Network (DQN) with a contextual bandit module that learns to choose optimal action repetition rates based on state contexts. Experiments on Atari 2600 games demonstrate significant performance improvements over static duration baselines, highlighting the efficacy of adaptive temporal abstractions in DRL. This paradigm offers a scalable solution for real-time applications like gaming and robotics, where dynamic action durations are critical.', 'abstract_zh': '深度强化学习（DRL）在复杂序列决策任务中取得了显著成功，如玩Atari 2600游戏和掌握棋盘游戏。DRL的一个重要但尚未充分探索的方面是动作执行的时间尺度。我们提出了一种新的框架，将上下文臂与DRL集成以自适应选择动作持续时间，增强策略的灵活性和计算效率。该方法通过将上下文臂模块增强到深度Q网络（DQN）中，使模块能够基于状态上下文学习选择最优的动作重复率。实验结果表明，与静态持续时间基线相比，该方法在Atari 2600游戏中的性能有显著提升，突显了在DRL中自适应时序抽象的有效性。该框架为类似游戏和机器人领域的实时应用提供了可扩展的解决方案，其中动态动作持续时间至关重要。', 'title_zh': '基于上下文臂博弈的动态环境中自适应动作持续时间的深度强化学习'}
{'arxiv_id': 'arXiv:2507.00029', 'title': 'LoRA-Mixer: Coordinate Modular LoRA Experts Through Serial Attention Routing', 'authors': 'Wenbing Li, Zikai Song, Hang Zhou, Yunyao Zhang, Junqing Yu, Wei Yang', 'link': 'https://arxiv.org/abs/2507.00029', 'abstract': "Recent efforts to combine low-rank adaptation (LoRA) with mixture-of-experts (MoE) for adapting large language models (LLMs) to multiple tasks still exhibit prevailing limitations: they either swap entire attention/feed-forward layers for switch experts or bolt on parallel expert branches, diluting parameter efficiency and task fidelity. We propose the LoRA-Mixer, a modular and lightweight MoE framework that integrates LoRA experts. Our core innovation lies in replacing the projection matrices of the attention module's input/output linear layers with dynamically routed, task-specific LoRA experts. This design ensures seamless compatibility with diverse foundation models, including transformers and state space models (SSMs), by leveraging their inherent linear projection structures. The framework supports two operational paradigms: (1) joint optimization of LoRA experts and routing mechanisms via a novel hard-soft routing strategy, or (2) direct deployment of pre-trained, frozen LoRA modules sourced from external repositories. To enable robust router training with limited data while ensuring stable routing decisions and maximizing expert reuse, we introduce an adaptive Specialization Balance Loss (SBL) that jointly optimizes expert balance and task-specific alignment. Extensive experiments on seven benchmark datasets, including MedQA, CoLA, SST-2, GSM8K, ARC-E, ARC-C, and HumanEval, demonstrate the effectiveness of LoRA-Mixer. On datasets such as GSM8K, HumanEval, and MedQA, LoRA-Mixer achieves significant improvements of 7.61%, 4.88%, and 3.08% over the base models, respectively. Compared with state-of-the-art methods, LoRA-Mixer achieves additional improvements of 1.09%, 1.45%, and 1.68%, respectively, using only 48% of the parameters, demonstrating its efficiency and strong performance.", 'abstract_zh': 'Recent Efforts to Combine Low-Rank Adaptation (LoRA) with Mixture-of-Experts (MoE) for Adapting Large Language Models (LLMs) to Multiple Tasks Still Exhibit Prevailing Limitations: Introducing LoRA-Mixer, a Modular and Lightweight MoE Framework', 'title_zh': 'LoRA-Mixer: 通过串联注意力路由协调模块化LoRA专家'}
{'arxiv_id': 'arXiv:2507.00028', 'title': 'HiT-JEPA: A Hierarchical Self-supervised Trajectory Embedding Framework for Similarity Computation', 'authors': 'Lihuan Li, Hao Xue, Shuang Ao, Yang Song, Flora Salim', 'link': 'https://arxiv.org/abs/2507.00028', 'abstract': "The representation of urban trajectory data plays a critical role in effectively analyzing spatial movement patterns. Despite considerable progress, the challenge of designing trajectory representations that can capture diverse and complementary information remains an open research problem. Existing methods struggle in incorporating trajectory fine-grained details and high-level summary in a single model, limiting their ability to attend to both long-term dependencies while preserving local nuances. To address this, we propose HiT-JEPA (Hierarchical Interactions of Trajectory Semantics via a Joint Embedding Predictive Architecture), a unified framework for learning multi-scale urban trajectory representations across semantic abstraction levels. HiT-JEPA adopts a three-layer hierarchy that progressively captures point-level fine-grained details, intermediate patterns, and high-level trajectory abstractions, enabling the model to integrate both local dynamics and global semantics in one coherent structure. Extensive experiments on multiple real-world datasets for trajectory similarity computation show that HiT-JEPA's hierarchical design yields richer, multi-scale representations. Code is available at: this https URL.", 'abstract_zh': '基于联合嵌入预测架构的层级轨迹语义交互（HiT-JEPA）：面向多尺度城市轨迹表示的统一框架', 'title_zh': 'HiT-JEPA：一种层次化的自监督轨迹嵌入框架用于相似性计算'}
{'arxiv_id': 'arXiv:2507.00026', 'title': 'ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models', 'authors': 'Jiale Ding, Xiang Zheng, Cong Wang, Wei-Bin Lee, Xingjun Ma, Yu-Gang Jiang', 'link': 'https://arxiv.org/abs/2507.00026', 'abstract': 'As Large Language Models (LLMs) are increasingly deployed as black-box components in real-world applications, evaluating their safety-especially under adversarial prompting-has become critical. Arguably, effective safety evaluations should be adaptive, evolving with LLM capabilities, and also cover a broad spectrum of harmful topics and real-world scenarios to fully expose potential vulnerabilities. Existing manual safety benchmarks, built on handcrafted adversarial prompts, are limited by their static nature and the intensive labor required to update them, making it difficult to keep pace with rapidly advancing LLMs. In contrast, automated adversarial prompt generation offers a promising path toward adaptive evaluation. However, current methods often suffer from insufficient adversarial topic coverage (topic-level diversity) and weak alignment with real-world contexts. These shortcomings stem from the exploration-exploitation dilemma in black-box optimization and a lack of real-world contextualization, resulting in adversarial prompts that are both topically narrow and scenario-repetitive. To address these issues, we propose Reality-Oriented Safety Evaluation (ROSE), a novel framework that uses multi-objective reinforcement learning to fine-tune an adversarial LLM for generating topically diverse and contextually rich adversarial prompts. Experiments show that ROSE outperforms existing methods in uncovering safety vulnerabilities in state-of-the-art LLMs, with notable improvements in integrated evaluation metrics. We hope ROSE represents a step toward more practical and reality-oriented safety evaluation of LLMs. WARNING: This paper contains examples of potentially harmful text.', 'abstract_zh': '基于现实导向的安全评估：用于生成多样话题和丰富情境的对抗性提示的新框架', 'title_zh': 'ROSE: 面向现实安全评估的大规模语言模型安全性评价'}
{'arxiv_id': 'arXiv:2507.00025', 'title': 'Generalizing to New Dynamical Systems via Frequency Domain Adaptation', 'authors': 'Tiexin Qin, Hong Yan, Haoliang Li', 'link': 'https://arxiv.org/abs/2507.00025', 'abstract': 'Learning the underlying dynamics from data with deep neural networks has shown remarkable potential in modeling various complex physical dynamics. However, current approaches are constrained in their ability to make reliable predictions in a specific domain and struggle with generalizing to unseen systems that are governed by the same general dynamics but differ in environmental characteristics. In this work, we formulate a parameter-efficient method, Fourier Neural Simulator for Dynamical Adaptation (FNSDA), that can readily generalize to new dynamics via adaptation in the Fourier space. Specifically, FNSDA identifies the shareable dynamics based on the known environments using an automatic partition in Fourier modes and learns to adjust the modes specific for each new environment by conditioning on low-dimensional latent systematic parameters for efficient generalization. We evaluate our approach on four representative families of dynamic systems, and the results show that FNSDA can achieve superior or competitive generalization performance compared to existing methods with a significantly reduced parameter cost. Our code is available at this https URL.', 'abstract_zh': '利用深度神经网络从数据中学习基本动力学在建模各种复杂物理动力学方面展现了显著潜力。然而，当前的方法在特定领域内进行可靠预测的能力有限，并且在泛化到受相同一般动力学规则支配但环境特性不同的未见系统时表现出困难。在本文中，我们提出了一种参数高效方法——傅里叶神经模拟器以实现动态适应（FNSDA），该方法可以通过在傅里叶空间内的适应来泛化到新的动力学。具体而言，FNSDA 使用自动傅里叶模式分区来识别基于已知环境的可分享动力学，并通过条件概率来学习调整针对每个新环境的具体模式，从而实现高效的泛化。我们在四种代表性的动态系统家族上评估了我们的方法，结果表明与现有方法相比，FNSDA 能以显著减少的参数成本实现优越或竞争的泛化性能。我们的代码可在以下链接获取：this https URL。', 'title_zh': '基于频域适应性将模型应用于新的动力学系统'}
{'arxiv_id': 'arXiv:2507.00024', 'title': 'AIMatDesign: Knowledge-Augmented Reinforcement Learning for Inverse Materials Design under Data Scarcity', 'authors': 'Yeyong Yu, Xilei Bian, Jie Xiong, Xing Wu, Quan Qian', 'link': 'https://arxiv.org/abs/2507.00024', 'abstract': 'With the growing demand for novel materials, machine learning-driven inverse design methods face significant challenges in reconciling the high-dimensional materials composition space with limited experimental data. Existing approaches suffer from two major limitations: (I) machine learning models often lack reliability in high-dimensional spaces, leading to prediction biases during the design process; (II) these models fail to effectively incorporate domain expert knowledge, limiting their capacity to support knowledge-guided inverse design. To address these challenges, we introduce AIMatDesign, a reinforcement learning framework that addresses these limitations by augmenting experimental data using difference-based algorithms to build a trusted experience pool, accelerating model convergence. To enhance model reliability, an automated refinement strategy guided by large language models (LLMs) dynamically corrects prediction inconsistencies, reinforcing alignment between reward signals and state value functions. Additionally, a knowledge-based reward function leverages expert domain rules to improve stability and efficiency during training. Our experiments demonstrate that AIMatDesign significantly surpasses traditional machine learning and reinforcement learning methods in discovery efficiency, convergence speed, and success rates. Among the numerous candidates proposed by AIMatDesign, experimental synthesis of representative Zr-based alloys yielded a top-performing BMG with 1.7GPa yield strength and 10.2\\% elongation, closely matching predictions. Moreover, the framework accurately captured the trend of yield strength variation with composition, demonstrating its reliability and potential for closed-loop materials discovery.', 'abstract_zh': '基于强化学习的AIMatDesign：通过增强实验数据加速可信赖的逆设计', 'title_zh': 'AIMatDesign：知识增强的强化学习在数据稀缺下的逆向材料设计'}
{'arxiv_id': 'arXiv:2507.00022', 'title': 'GLU Attention Improve Transformer', 'authors': 'Zehao Wang', 'link': 'https://arxiv.org/abs/2507.00022', 'abstract': 'Gated Linear Units (GLU) have shown great potential in enhancing neural network performance. In this paper, I introduce a novel attention mechanism called GLU Attention, which introduces nonlinearity into the values of Attention. My experiments demonstrate that GLU Attention improves both model performance and convergence speed across text and vision modalities with zero additional parameters and negligible computational costs. GLU Attention is lightweight and can seamlessly integrate with other technologies, such as Flash Attention, Rotary Position Embedding (RoPE), and various Multi-Head Attention (MHA) variants such as Grouped-Query Attention (GQA). This project is open-sourced at github.', 'abstract_zh': 'Gated Linear Units (GLU)在提升神经网络性能方面显示出巨大潜力。本文介绍了一种新颖的注意力机制GLU Attention，该机制将非线性引入注意力值中。实验表明，GLU Attention在文本和视觉模态中均能提高模型性能和收敛速度，同时无需额外参数，并且几乎不增加计算成本。GLU Attention结构轻量，可以无缝集成其他技术，如Flash Attention、旋转位置嵌入（RoPE）以及多种多头注意力机制（MHA）变种，如分组查询注意力（GQA）。该项目已在github上开源。', 'title_zh': 'GLU注意力改进Transformer'}
{'arxiv_id': 'arXiv:2507.00019', 'title': 'Quantum Inspired Encoding Strategies for Machine Learning Models: Proposing and Evaluating Instance Level, Global Discrete, and Class Conditional Representations', 'authors': 'Minati Rath, Hema Date', 'link': 'https://arxiv.org/abs/2507.00019', 'abstract': 'In this study, we propose, evaluate and compare three quantum inspired data encoding strategies, Instance Level Strategy (ILS), Global Discrete Strategy (GDS) and Class Conditional Value Strategy (CCVS), for transforming classical data into quantum data for use in pure classical machine learning models. The primary objective is to reduce high encoding time while ensuring correct encoding values and analyzing their impact on classification performance. The Instance Level Strategy treats each row of dataset independently; mimics local quantum states. Global Discrete Value Based encoding strategy maps all unique feature values across the full dataset to quantum states uniformly. In contrast, the Class conditional Value based encoding strategy encodes unique values separately for each class, preserving class dependent information.\nWe apply these encoding strategies to a classification task and assess their impact on en-coding efficiency, correctness, model accuracy, and computational cost. By analyzing the trade offs between encoding time, precision, and predictive performance, this study provides insights into optimizing quantum inspired data transformations for classical machine learning workflows.', 'abstract_zh': '本研究提出、评估并比较了三种量子启发式数据编码策略，即实例水平策略（ILS）、全局离散策略（GDS）和类条件值策略（CCVS），用于将经典数据转换为可在纯经典机器学习模型中使用的量子数据。主要目标是在确保正确编码值的前提下减少高编码时间，并分析其对分类性能的影响。实例水平策略独立处理数据集中的每一行，模拟局部量子态；全局离散值基于编码策略将数据集中所有唯一特征值均匀映射到量子态；相比之下，类条件值基于编码策略单独为每个类别编码唯一值，保留类别相关的信息。我们将这些编码策略应用于分类任务，并评估其对编码效率、正确性、模型准确性和计算成本的影响。通过分析编码时间、精度和预测性能之间的权衡，本研究为优化经典机器学习工作流中的量子启发式数据转换提供了见解。', 'title_zh': '量子启发式的编码策略用于机器学习模型：提出并评估实例级别、全局离散和类条件表示方法'}
{'arxiv_id': 'arXiv:2507.00018', 'title': 'Implicit Reward as the Bridge: A Unified View of SFT and DPO Connections', 'authors': 'Bo Wang, Qinyuan Cheng, Runyu Peng, Rong Bao, Peiji Li, Qipeng Guo, Linyang Li, Zhiyuan Zeng, Yunhua Zhou, Xipeng Qiu', 'link': 'https://arxiv.org/abs/2507.00018', 'abstract': 'Post-training processes are essential phases in grounding pre-trained language models to real-world tasks, with learning from demonstrations or preference signals playing a crucial role in this adaptation. We present a unified theoretical framework bridging Supervised Fine-Tuning (SFT) and preference learning in Large Language Model (LLM) post-training. Through rigorous mathematical derivation, we demonstrate that both SFT and preference learning methods like Direct Preference Optimization (DPO) operate within the same optimal policy-reward subspace, with SFT representing a special case of implicit reward learning. Our analysis reveals a critical limitation in conventional SFT: the KL divergence term in distribution matching becomes constant with respect to the policy during optimization, failing to constrain model updates. To address this, we propose a simple yet effective learning rate reduction approach that yields significant performance improvements (up to \\textbf{25\\%} relative gain and \\textbf{6\\%} absolute win rate increase in instruction following tasks. Additionally, we derive alternative SFT objectives from various f-divergence functions that preserve the KL term during optimization, further enhancing post-DPO model performance. Finally, we extend the theoretical relationship between LLM logits and Q-functions from preference learning to the SFT context, providing mathematical derivations and experimental validation.', 'abstract_zh': 'Post-训练过程是将预训练语言模型接地到现实任务中的关键阶段，通过演示学习或偏好信号学习起着至关重要的作用。我们提出了一种统一的理论框架，将监督微调（SFT）和大规模语言模型（LLM）后训练中的偏好学习方法联系起来。通过 rigorous的数学推导，我们证明了SFT和偏好学习方法（如直接偏好优化DPO）都在相同的最优策略-奖励子空间内运作，SFT代表隐式奖励学习的一种特殊情况。我们的分析揭示了传统SFT的一个关键限制：分布匹配中的KL散度项在优化过程中对策略变得常数，无法约束模型更新。为此，我们提出了一种简单而有效的学习率降低方法，显著提高了指令跟随任务的表现（相对提升高达25%，绝对胜率提高6%）。此外，我们从各种f散度函数中推导出了替代SFT目标，这些目标在优化过程中保留了KL项，进一步增强了后DPO模型的表现。最后，我们将偏好学习中LLM输出与Q函数之间的理论关系扩展到SFT场景中，提供了数学推导和实验验证。', 'title_zh': '隐式奖励作为桥梁：SFT与DPO的统一视角'}
{'arxiv_id': 'arXiv:2507.00016', 'title': 'Gradient-based Fine-Tuning through Pre-trained Model Regularization', 'authors': 'Xuanbo Liu, Liu Liu, Fuxiang Wu, Fusheng Hao, Xianglong Liu', 'link': 'https://arxiv.org/abs/2507.00016', 'abstract': 'Large pre-trained models have demonstrated extensive applications across various fields. However, fine-tuning these models for specific downstream tasks demands significant computational resources and storage. One fine-tuning method, gradient-based parameter selection (GPS), focuses on fine-tuning only the parameters with high gradients in each neuron, thereby reducing the number of training parameters. Nevertheless, this approach increases computational resource requirements and storage demands. In this paper, we propose an efficient gradient-based and regularized fine-tuning method (GRFT) that updates the rows or columns of the weight matrix. We theoretically demonstrate that the rows or columns with the highest sum of squared gradients are optimal for updating. This strategy effectively reduces storage overhead and improves the efficiency of parameter selection. Additionally, we incorporate regularization to enhance knowledge transfer from the pre-trained model. GRFT achieves state-of-the-art performance, surpassing existing methods such as GPS, Adapter Tuning, and LoRA. Notably, GRFT requires updating only 1.22% and 0.30% of the total parameters on FGVC and VTAB datasets, respectively, demonstrating its high efficiency and effectiveness. The source code will be released soon.', 'abstract_zh': '大型预训练模型在多个领域展示了广泛的应用。然而，针对特定下游任务进行微调需要大量计算资源和存储。一种基于梯度的参数选择（GPS）方法仅微调每个神经元中梯度较高的参数，从而减少训练参数的数量。这一方法虽然减少了参数数量，但也增加了计算资源需求和存储需求。本文提出了一种高效且正则化的基于梯度的微调方法（GRFT），该方法更新权重矩阵的行或列。我们从理论上证明，具有最高梯度平方和的行或列是最优更新的对象。这种方法有效地减少了存储开销并提高了参数选择的效率。此外，我们引入了正则化以增强知识迁移能力。GRFT在FGVC和VTAB数据集上取得了最先进的性能，超过了现有的方法如GPS、Adapter Tuning和LoRA。值得注意的是，GRFT在FGVC和VTAB数据集上分别只需更新1.22%和0.30%的总参数，展示了其高效和有效性。不久将发布源代码。', 'title_zh': '基于梯度的微调通过预训练模型正则化'}
{'arxiv_id': 'arXiv:2507.00015', 'title': 'Vision Transformer with Adversarial Indicator Token against Adversarial Attacks in Radio Signal Classifications', 'authors': 'Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Xuekang Liu, Fabio Roli, Carsten Maple', 'link': 'https://arxiv.org/abs/2507.00015', 'abstract': 'The remarkable success of transformers across various fields such as natural language processing and computer vision has paved the way for their applications in automatic modulation classification, a critical component in the communication systems of Internet of Things (IoT) devices. However, it has been observed that transformer-based classification of radio signals is susceptible to subtle yet sophisticated adversarial attacks. To address this issue, we have developed a defensive strategy for transformer-based modulation classification systems to counter such adversarial attacks. In this paper, we propose a novel vision transformer (ViT) architecture by introducing a new concept known as adversarial indicator (AdvI) token to detect adversarial attacks. To the best of our knowledge, this is the first work to propose an AdvI token in ViT to defend against adversarial attacks. Integrating an adversarial training method with a detection mechanism using AdvI token, we combine a training time defense and running time defense in a unified neural network model, which reduces architectural complexity of the system compared to detecting adversarial perturbations using separate models. We investigate into the operational principles of our method by examining the attention mechanism. We show the proposed AdvI token acts as a crucial element within the ViT, influencing attention weights and thereby highlighting regions or features in the input data that are potentially suspicious or anomalous. Through experimental results, we demonstrate that our approach surpasses several competitive methods in handling white-box attack scenarios, including those utilizing the fast gradient method, projected gradient descent attacks and basic iterative method.', 'abstract_zh': '变压器在自然语言处理和计算机视觉等领域取得的显著成功为其在物联网设备通信系统中的自动调制分类应用铺平了道路。然而，观察到基于变压器的调制分类对微妙且复杂的对抗性攻击易感。为解决这一问题，我们开发了一种针对基于变压器的调制分类系统的防御策略以对抗此类对抗性攻击。在本文中，我们通过引入新的概念——对抗指标（AdvI）标记，提出了一种新颖的视觉变压器（ViT）架构以检测对抗性攻击。据我们所知，这是首次在ViT中提出AdvI标记以防御对抗性攻击的工作。通过结合对抗训练方法和使用AdvI标记的检测机制，我们在统一的神经网络模型中实现了训练时防御和运行时防御，与使用单独模型检测对抗性扰动相比，简化了系统的架构复杂度。通过研究方法的运作原理并考察注意力机制，我们证明了所提出的AdvI标记是ViT中的关键元素，影响注意力权重，从而突出输入数据中可能存在可疑或异常的区域或特征。实验结果表明，在白盒攻击场景下，包括使用快速梯度方法、投影梯度下降攻击和基本迭代方法的攻击中，我们的方法超越了多种竞争性方法。', 'title_zh': '带有对抗指示标记的视觉变换器在无线电信号分类中的对抗攻击防御'}
{'arxiv_id': 'arXiv:2507.00014', 'title': 'SWE-Bench-CL: Continual Learning for Coding Agents', 'authors': 'Thomas Joshi, Shayan Chowdhury, Fatih Uysal', 'link': 'https://arxiv.org/abs/2507.00014', 'abstract': "Large Language Models (LLMs) have achieved impressive results on static code-generation benchmarks, but real-world software development unfolds as a continuous stream of evolving issues, fixes, and feature requests. We introduce SWE-Bench-CL, a novel continual learning benchmark built on the human-verified SWE-Bench Verified dataset introduced by OpenAI and Princeton-NLP in 2024. By organizing GitHub issues into chronologically ordered sequences that reflect natural repository evolution, SWE-Bench-CL enables direct evaluation of an agent's ability to accumulate experience, transfer knowledge across tasks, and resist catastrophic forgetting. We complement the dataset with (i) a preliminary analysis of inter-task structural similarity and contextual sensitivity, (ii) an interactive LangGraph-based evaluation framework augmented with a FAISS-backed semantic memory module, and (iii) a suite of specialized continual learning metrics -- including average accuracy, forgetting, forward/backward transfer, tool-use efficiency, and a generalized Composite Continual Learning Score and CL-F-beta score -- to capture the stability-plasticity trade-off. We outline a rigorous experimental protocol comparing memory-enabled and memory-disabled agents across diverse Python repositories. All code and data are publicly available at this https URL, providing the community with a reproducible platform for developing more adaptive and robust AI agents in software engineering.", 'abstract_zh': '大规模语言模型（LLMs）在静态代码生成基准测试中取得了令人印象深刻的成果，但实际的软件开发是连续不断的问题解决、修复和功能请求的演变过程。我们引入了SWE-Bench-CL，一个基于OpenAI和Princeton-NLP于2024年引入的人工验证SWE-Bench Verified数据集的新型连续学习基准。通过将GitHub问题组织成反映自然仓库演化的时序序列，SWE-Bench-CL使我们能够直接评估代理累积经验、在不同任务间迁移知识以及抵抗灾难性遗忘的能力。我们补充了该数据集，包括(i) 不同任务结构相似性和情境敏感性的初步分析，(ii) 基于LangGraph的交互式评估框架，辅以FAISS支持的语义记忆模块，以及(iii) 包括平均准确度、遗忘、正向/反向迁移、工具使用效率以及广义的综合连续学习评分和CL-F-beta评分等一系列专门的连续学习度量标准，以捕捉稳定性和灵活性之间的权衡。我们概述了在不同Python仓库中对比启用和未启用记忆代理的严格实验协议。所有代码和数据均可在以下网址公开访问，为软件工程中开发更适应性和鲁棒性的AI代理提供了可重复的平台。', 'title_zh': 'SWE-Bench-CL: 不断学习的编码代理'}
{'arxiv_id': 'arXiv:2507.00013', 'title': 'ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting', 'authors': 'Hyunwoo Seo, Chiehyeon Lim', 'link': 'https://arxiv.org/abs/2507.00013', 'abstract': 'Forecasting complex time series is an important yet challenging problem that involves various industrial applications. Recently, masked time-series modeling has been proposed to effectively model temporal dependencies for forecasting by reconstructing masked segments from unmasked ones. However, since the semantic information in time series is involved in intricate temporal variations generated by multiple time series components, simply masking a raw time series ignores the inherent semantic structure, which may cause MTM to learn spurious temporal patterns present in the raw data. To capture distinct temporal semantics, we show that masked modeling techniques should address entangled patterns through a decomposition approach. Specifically, we propose ST-MTM, a masked time-series modeling framework with seasonal-trend decomposition, which includes a novel masking method for the seasonal-trend components that incorporates different temporal variations from each component. ST-MTM uses a period masking strategy for seasonal components to produce multiple masked seasonal series based on inherent multi-periodicity and a sub-series masking strategy for trend components to mask temporal regions that share similar variations. The proposed masking method presents an effective pre-training task for learning intricate temporal variations and dependencies. Additionally, ST-MTM introduces a contrastive learning task to support masked modeling by enhancing contextual consistency among multiple masked seasonal representations. Experimental results show that our proposed ST-MTM achieves consistently superior forecasting performance compared to existing masked modeling, contrastive learning, and supervised forecasting methods.', 'abstract_zh': '复杂时间序列的预测是一个重要而又具有挑战性的问题，涉及各种工业应用。最近，屏蔽时间序列建模已被提出，通过从未屏蔽段重建屏蔽段来有效建模时间依赖性以进行预测。然而，由于时间序列中的语义信息被多个时间序列组件产生的复杂时间变化所涉及，简单地屏蔽原始时间序列会忽略固有的语义结构，这可能导致MTM学到原始数据中存在的虚假时间模式。为了捕捉不同的时间语义，我们表明屏蔽建模技术应通过分解方法解决交织的模式。具体地，我们提出了一种基于季节趋势分解的屏蔽时间序列建模框架ST-MTM，该框架包括一个新颖的屏蔽方法，该方法将不同的时间变化整合到每个组件中。ST-MTM采用周期屏蔽策略对季节成分进行屏蔽，基于固有的多周期性生成多个屏蔽季节序列，并采用子序列屏蔽策略对趋势成分进行屏蔽，以屏蔽具有相似变化的时间区域。提出的屏蔽方法为学习复杂的时间变化和依赖关系提供了一个有效的预训练任务。此外，ST-MTM通过增强多个屏蔽季节表示之间的上下文一致性引入了一种对比学习任务，以支持屏蔽建模。实验结果表明，我们提出的ST-MTM在预测性能上优于现有的屏蔽建模、对比学习和监督预测方法。', 'title_zh': 'ST-MTM：基于季节趋势分解的掩码时间序列模型及其在时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2507.00012', 'title': 'Towards Undistillable Models by Minimizing Conditional Mutual Information', 'authors': 'Linfeng Ye, Shayan Mohajer Hamidi, En-hui Yang', 'link': 'https://arxiv.org/abs/2507.00012', 'abstract': 'A deep neural network (DNN) is said to be undistillable if, when used as a black-box input-output teacher, it cannot be distilled through knowledge distillation (KD). In this case, the distilled student (referred to as the knockoff student) does not outperform a student trained independently with label smoothing (LS student) in terms of prediction accuracy. To protect intellectual property of DNNs, it is desirable to build undistillable DNNs. To this end, it is first observed that an undistillable DNN may have the trait that each cluster of its output probability distributions in response to all sample instances with the same label should be highly concentrated to the extent that each cluster corresponding to each label should ideally collapse into one probability distribution. Based on this observation and by measuring the concentration of each cluster in terms of conditional mutual information (CMI), a new training method called CMI minimized (CMIM) method is proposed, which trains a DNN by jointly minimizing the conventional cross entropy (CE) loss and the CMI values of all temperature scaled clusters across the entire temperature spectrum. The resulting CMIM model is shown, by extensive experiments, to be undistillable by all tested KD methods existing in the literature. That is, the knockoff students distilled by these KD methods from the CMIM model underperform the respective LS students. In addition, the CMIM model is also shown to performs better than the model trained with the CE loss alone in terms of their own prediction accuracy.', 'abstract_zh': '一种深度神经网络（DNN）如果作为黑盒输入-输出教师时，无法通过知识蒸馏（KD）进行提取，则称为不可蒸馏DNN。在这种情况下，通过知识蒸馏得到的“仿冒学生”在预测准确性上不会优于独立使用标签平滑（LS）训练的学生。为了保护DNN的知识产权，构建不可蒸馏DNN是有益的。为此，首先观察到一种不可蒸馏DNN可能具有每个输出概率分布簇对所有具有相同标签的样本实例的响应高度集中，理想情况下，每个标签对应的簇应当塌缩成一个概率分布。基于这一观察，并通过使用条件互信息（CMI）测量每簇的集中度，提出了一个新的训练方法——CMI最小化（CMIM）方法，该方法通过共同最小化传统的交叉熵（CE）损失和整个温度谱范围内所有温度缩放簇的CMI值来训练DNN。实验结果表明，CMIM模型可以通过所有现有文献中的测试KD方法确保其不可蒸馏，即通过CMIM模型提取的“仿冒学生”在预测准确性上不会优于各自对应的LS学生。此外，CMIM模型在自身预测准确性方面也优于仅使用CE损失训练的模型。', 'title_zh': '通过最小化条件互信息实现无法反向蒸馏的模型'}
{'arxiv_id': 'arXiv:2507.00011', 'title': 'Novel RL approach for efficient Elevator Group Control Systems', 'authors': 'Nathan Vaartjes, Vincent Francois-Lavet', 'link': 'https://arxiv.org/abs/2507.00011', 'abstract': 'Efficient elevator traffic management in large buildings is critical for minimizing passenger travel times and energy consumption. Because heuristic- or pattern-detection-based controllers struggle with the stochastic and combinatorial nature of dispatching, we model the six-elevator, fifteen-floor system at Vrije Universiteit Amsterdam as a Markov Decision Process and train an end-to-end Reinforcement Learning (RL) Elevator Group Control System (EGCS). Key innovations include a novel action space encoding to handle the combinatorial complexity of elevator dispatching, the introduction of infra-steps to model continuous passenger arrivals, and a tailored reward signal to improve learning efficiency. In addition, we explore various ways to adapt the discounting factor to the infra-step formulation. We investigate RL architectures based on Dueling Double Deep Q-learning, showing that the proposed RL-based EGCS adapts to fluctuating traffic patterns, learns from a highly stochastic environment, and thereby outperforms a traditional rule-based algorithm.', 'abstract_zh': '在大型建筑中高效管理电梯交通对于减少乘客旅行时间和能耗至关重要。由于启发式或模式检测控制器难以处理调度的随机性和组合性，我们将位于阿姆斯特丹自由大学的六部电梯、十五层楼系统建模为马尔可夫决策过程，并训练了一个端到端强化学习（RL）电梯群控系统（EGCS）。关键创新包括一种新颖的动作空间编码以处理电梯调度的组合复杂性，引入基础设施步来模拟连续的乘客到达，并定制奖励信号以提高学习效率。此外，我们探索了各种方法来调整折扣因子以适应基础设施步的建模。基于对拼双深Q学习的RL架构的研究表明，所提出的基于RL的EGCS能够适应波动的交通模式，从高度随机的环境中学习，并因此优于传统的基于规则的算法。', 'title_zh': '新型 RL 方法在高效电梯群控系统中的应用'}
{'arxiv_id': 'arXiv:2507.00007', 'title': 'Integrating Universal Generative AI Platforms in Educational Labs to Foster Critical Thinking and Digital Literacy', 'authors': 'Vasiliy Znamenskiy, Rafael Niyazov, Joel Hernandez', 'link': 'https://arxiv.org/abs/2507.00007', 'abstract': 'This paper presents a new educational framework for integrating generative artificial intelligence (GenAI) platforms such as ChatGPT, Claude, and Gemini into laboratory activities aimed at developing critical thinking and digital literacy among undergraduate students. Recognizing the limitations and risks of uncritical reliance on large language models (LLMs), the proposed pedagogical model reframes GenAI as a research subject and cognitive tool. Students formulate discipline-specific prompts and evaluate GenAI-generated responses in text, image, and video modalities. A pilot implementation in a general astronomy course for non-science majors demonstrated high levels of engagement and critical reflection, with many students continuing the activity after class and presenting results at a research symposium. The results highlight the importance of structured AI interactions in education and suggest that GenAI can improve learning outcomes when combined with reflective assessment methods. The study proposes a replicable model for interdisciplinary AI-integrated lab work, adaptable to scientific disciplines. See the guide to learning activities based on Generative-Ai platforms: this https URL', 'abstract_zh': '这篇论文提出了一种新的教育框架，旨在将生成型人工智能（GenAI）平台（如ChatGPT、Claude和Gemini）整合到实验室活动中，以培养本科生的批判性思维和数字 literacy。该研究认识到对大型语言模型（LLMs）的不加批判的依赖存在局限性和风险，因此提出的教学模式将GenAI重新定位为研究对象和认知工具。学生形成学科特定的提示，并评估GenAI生成的文本、图像和视频响应。一项在非科学专业学生通用天文学课程中的试点实施显示，学生积极参与并进行了深入反思，许多学生在课后继续该活动并在研究论坛上展示了结果。研究结果强调了结构化的人工智能互动在教育中的重要性，并表明当与反思性评估方法结合使用时，GenAI可以提高学习成果。该研究提供了一种可复制的跨学科人工智能整合实验室工作的模型，适用于科学学科。参见基于生成型AI平台的学习活动指南：[此链接]。', 'title_zh': '将通用生成AI平台集成到教育实验室中以培养批判性思维和数字素养'}
{'arxiv_id': 'arXiv:2507.00004', 'title': 'A Theory of Inference Compute Scaling: Reasoning through Directed Stochastic Skill Search', 'authors': 'Austin R. Ellis-Mohr, Anuj K. Nayak, Lav R. Varshney', 'link': 'https://arxiv.org/abs/2507.00004', 'abstract': "Large language models (LLMs) demand considerable computational, energy, and financial resources during both training and deployment. While scaling laws for training have guided much of the field's recent progress, inference costs now represent a significant and growing component of the overall resource burden, particularly for reasoning-focused models. Existing characterizations of compute-optimality that consider model size, dataset size, and inference tokens in isolation or in fixed combinations risk overlooking more efficient operating points. We introduce directed stochastic skill search (DS3), a general framework that represents inference as stochastic traversal over a learned skill graph. From a simplified yet expressive instantiation, we derive closed-form expressions for task success and compute cost across a wide range of inference strategies -- including chain-of-thought (CoT) and tree-of-thought (ToT) -- enabling comparative analysis as a function of task difficulty and model capability. To that end, we extend a prior first-principles tripartite graph framework of LLM training to incorporate inference, and separately bridge DS3 with empirical methods that characterize LLM scaling behavior. We theoretically recover empirically observed patterns, including: linear accuracy scaling with logarithmic compute; variation in preferred inference strategies as a function of task difficulty and model capability; emergent behavior elicited by reasoning even when performance plateaus under parameter scaling; and both best-of-N (BoN) and majority voting behavior captured within a unified analytical framework. By explicitly characterizing training-inference interdependencies, our framework deepens theoretical understanding and supports principled algorithmic design and resource allocation.", 'abstract_zh': '大型语言模型（LLMs）在训练和部署过程中消耗大量的计算、能源和财务资源。虽然训练的缩放定律在该领域近期的进展中发挥了重要作用，但推理成本现在已成为总体资源负担中一个显著且不断增长的组成部分，尤其是对于注重推理的模型。现有的关于计算效率的表征主要考虑模型规模、数据集规模和推理令牌在单独或固定组合中的影响，可能忽略了更高效的运行点。我们引入了定向随机技能搜索（DS3），这是一种一般框架，将推理表示为在学习技能图上的随机遍历。从一个简化但富有表现力的实例出发，我们推导出了广泛的推理策略下任务成功和计算成本的闭式表达式——包括链式思考（CoT）和树状思考（ToT），从而基于任务难度和模型能力进行比较分析。为此，我们将先前的LLM训练的第一原理三方图框架扩展到包括推理，并独立地将DS3与表征LLM缩放行为的实验方法结合起来。我们理论上重新推导了实验观察到的模式，包括：线性准确度随对数计算的增长；根据任务难度和模型能力选择的推理策略的变化；在参数缩放下性能饱和时由推理引发的新兴行为；以及在统一的分析框架中捕获的最佳选项和 majority 赞同行为。通过明确表征训练-推理相互依赖性，我们的框架加深了理论理解并支持基于原则的算法设计和资源分配。', 'title_zh': '推理推理计算扩展理论：通过定向随机技能搜索进行推理'}
{'arxiv_id': 'arXiv:2507.00003', 'title': 'Deciding When Not to Decide: Indeterminacy-Aware Intrusion Detection with NeutroSENSE', 'authors': 'Eyhab Al-Masri', 'link': 'https://arxiv.org/abs/2507.00003', 'abstract': 'This paper presents NeutroSENSE, a neutrosophic-enhanced ensemble framework for interpretable intrusion detection in IoT environments. By integrating Random Forest, XGBoost, and Logistic Regression with neutrosophic logic, the system decomposes prediction confidence into truth (T), falsity (F), and indeterminacy (I) components, enabling uncertainty quantification and abstention. Predictions with high indeterminacy are flagged for review using both global and adaptive, class-specific thresholds. Evaluated on the IoT-CAD dataset, NeutroSENSE achieved 97% accuracy, while demonstrating that misclassified samples exhibit significantly higher indeterminacy (I = 0.62) than correct ones (I = 0.24). The use of indeterminacy as a proxy for uncertainty enables informed abstention and targeted review-particularly valuable in edge deployments. Figures and tables validate the correlation between I-scores and error likelihood, supporting more trustworthy, human-in-the-loop AI decisions. This work shows that neutrosophic logic enhances both accuracy and explainability, providing a practical foundation for trust-aware AI in edge and fog-based IoT security systems.', 'abstract_zh': '基于 neutrosophic 逻辑的可解释物联网环境入侵检测集成框架 NeutroSENSE', 'title_zh': '在不确定性的aware入侵检测中选择何时不下决定：NeutroSENSE方法'}
{'arxiv_id': 'arXiv:2507.00002', 'title': 'Hypertokens: Holographic Associative Memory in Tokenized LLMs', 'authors': 'Christopher James Augeri', 'link': 'https://arxiv.org/abs/2507.00002', 'abstract': 'Large Language Models (LLMs) exhibit remarkable capabilities but suffer from apparent precision loss, reframed here as information spreading. This reframing shifts the problem from computational precision to an information-theoretic communication issue. We address the K:V and V:K memory problem in LLMs by introducing HDRAM (Holographically Defined Random Access Memory), a symbolic memory framework treating transformer latent space as a spread-spectrum channel. Built upon hypertokens, structured symbolic codes integrating classical error-correcting codes (ECC), holographic computing, and quantum-inspired search, HDRAM recovers distributed information through principled despreading. These phase-coherent memory addresses enable efficient key-value operations and Grover-style search in latent space. By combining ECC grammar with compressed sensing and Krylov subspace alignment, HDRAM significantly improves associative retrieval without architectural changes, demonstrating how Classical-Holographic-Quantum-inspired (CHQ) principles can fortify transformer architectures.', 'abstract_zh': '大型语言模型（LLMs）表现出色，但存在明显的精度损失，这里重新定义为信息扩散问题。这种重新定义将问题从计算精度转变为信息论通信问题。我们通过引入HDRAM（量子定义随机访问存储器）解决了LLMs中的K:V和V:K内存问题，HDRAM是一种符号内存框架，将变压器潜空间视为扩展谱通道。基于超词、结构化符号编码（结合经典错误校正码）、全息计算和量子启发式搜索，HDRAM通过原理性的解扩展恢复分布式信息。这些相干记忆地址能够在潜空间中实现高效的键值操作和Grover风格搜索。通过结合经典错误校正码语法、压缩感知和Krylov子空间对齐，HDRAM在不改变架构的情况下显著提高了关联检索，展示了经典-全息-量子启发（CHQ）原则如何加强变压器架构。', 'title_zh': '超代词：标记化大语言模型中的全息关联记忆'}
