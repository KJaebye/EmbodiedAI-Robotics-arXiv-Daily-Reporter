# DataMIL: Selecting Data for Robot Imitation Learning with Datamodels 

**Title (ZH)**: DataMIL: 使用数据模型选择用于机器人模仿学习的数据 

**Authors**: Shivin Dass, Alaa Khaddaj, Logan Engstrom, Aleksander Madry, Andrew Ilyas, Roberto Martín-Martín  

**Link**: [PDF](https://arxiv.org/pdf/2505.09603)  

**Abstract**: Recently, the robotics community has amassed ever larger and more diverse datasets to train generalist robot policies. However, while these policies achieve strong mean performance across a variety of tasks, they often underperform on individual, specialized tasks and require further tuning on newly acquired task-specific data. Combining task-specific data with carefully curated subsets of large prior datasets via co-training can produce better specialized policies, but selecting data naively may actually harm downstream performance. To address this, we introduce DataMIL, a policy-driven data selection framework built on the datamodels paradigm that reasons about data selection in an end-to-end manner, using the policy itself to identify which data points will most improve performance. Unlike standard practices that filter data using human notions of quality (e.g., based on semantic or visual similarity), DataMIL directly optimizes data selection for task success, allowing us to select data that enhance the policy while dropping data that degrade it. To avoid performing expensive rollouts in the environment during selection, we use a novel surrogate loss function on task-specific data, allowing us to use DataMIL in the real world without degrading performance. We validate our approach on a suite of more than 60 simulation and real-world manipulation tasks - most notably showing successful data selection from the Open X-Embodiment datasets-demonstrating consistent gains in success rates and superior performance over multiple baselines. Our results underscore the importance of end-to-end, performance-aware data selection for unlocking the potential of large prior datasets in robotics. More information at this https URL 

**Abstract (ZH)**: 最近，机器人学社区积累了越来越多且多样化的数据集来训练通用机器人策略。然而，虽然这些策略在多种任务上实现了较强的平均性能，但在个别专业化任务上往往表现不佳，并需要在新获取的任务特定数据上进一步调优。将任务特定数据与大型先有数据集中的精心筛选子集结合使用可以产生更好的专业化策略，但盲目选择数据实际上可能会损害下游性能。为了解决这个问题，我们引入了DataMIL，这是一种基于datamodels范式的策略驱动数据选择框架，能够端到端地推理数据选择，并使用策略本身来识别最能提升性能的数据点。与使用人类对质量的标准认知（例如基于语义或视觉相似性）筛选数据的传统方法不同，DataMIL 直接优化数据选择以实现任务成功，使我们能够选择增强策略的数据并丢弃损害策略的数据。为了在选择数据时避免在环境中进行昂贵的仿真，我们在任务特定数据上使用了一种新颖的代理损失函数，从而能够在不降低性能的情况下将DataMIL应用于现实世界。我们在超过60个仿真和实际操作任务套件上验证了我们的方法——尤其展示了从Open X-Embodiment数据集中成功选择数据的显著成效，展示了在多个基线方法上一致的性能提升。我们的结果强调了在机器人中实现大型先有数据集潜力时端到端、性能感知数据选择的重要性。更多信息请访问：this https URL 

---
# Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware 

**Title (ZH)**: Real2Render2Real: 扩展机器人数据而不依赖动力学仿真或机器人硬件 

**Authors**: Justin Yu, Letian Fu, Huang Huang, Karim El-Refai, Rares Andrei Ambrus, Richard Cheng, Muhammad Zubair Irshad, Ken Goldberg  

**Link**: [PDF](https://arxiv.org/pdf/2505.09601)  

**Abstract**: Scaling robot learning requires vast and diverse datasets. Yet the prevailing data collection paradigm-human teleoperation-remains costly and constrained by manual effort and physical robot access. We introduce Real2Render2Real (R2R2R), a novel approach for generating robot training data without relying on object dynamics simulation or teleoperation of robot hardware. The input is a smartphone-captured scan of one or more objects and a single video of a human demonstration. R2R2R renders thousands of high visual fidelity robot-agnostic demonstrations by reconstructing detailed 3D object geometry and appearance, and tracking 6-DoF object motion. R2R2R uses 3D Gaussian Splatting (3DGS) to enable flexible asset generation and trajectory synthesis for both rigid and articulated objects, converting these representations to meshes to maintain compatibility with scalable rendering engines like IsaacLab but with collision modeling off. Robot demonstration data generated by R2R2R integrates directly with models that operate on robot proprioceptive states and image observations, such as vision-language-action models (VLA) and imitation learning policies. Physical experiments suggest that models trained on R2R2R data from a single human demonstration can match the performance of models trained on 150 human teleoperation demonstrations. Project page: this https URL 

**Abstract (ZH)**: 无物体动力学模拟且无需机器人硬件远程操作的生成机器人训练数据方法：Real2Render2Real 

---
# VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation 

**Title (ZH)**: VTLA：带有偏好学习的视觉-触觉-语言-动作模型及其在插入 manipulation 中的应用 

**Authors**: Chaofan Zhang, Peng Hao, Xiaoge Cao, Xiaoshuai Hao, Shaowei Cui, Shuo Wang  

**Link**: [PDF](https://arxiv.org/pdf/2505.09577)  

**Abstract**: While vision-language models have advanced significantly, their application in language-conditioned robotic manipulation is still underexplored, especially for contact-rich tasks that extend beyond visually dominant pick-and-place scenarios. To bridge this gap, we introduce Vision-Tactile-Language-Action model, a novel framework that enables robust policy generation in contact-intensive scenarios by effectively integrating visual and tactile inputs through cross-modal language grounding. A low-cost, multi-modal dataset has been constructed in a simulation environment, containing vision-tactile-action-instruction pairs specifically designed for the fingertip insertion task. Furthermore, we introduce Direct Preference Optimization (DPO) to offer regression-like supervision for the VTLA model, effectively bridging the gap between classification-based next token prediction loss and continuous robotic tasks. Experimental results show that the VTLA model outperforms traditional imitation learning methods (e.g., diffusion policies) and existing multi-modal baselines (TLA/VLA), achieving over 90% success rates on unseen peg shapes. Finally, we conduct real-world peg-in-hole experiments to demonstrate the exceptional Sim2Real performance of the proposed VTLA model. For supplementary videos and results, please visit our project website: this https URL 

**Abstract (ZH)**: 视觉-触觉-语言-动作模型：一种通过跨模态语言接地有效整合视觉和触觉输入以生成鲁棒策略的新框架 

---
# Learning Long-Context Diffusion Policies via Past-Token Prediction 

**Title (ZH)**: 通过过往词预测学习长上下文扩散策略 

**Authors**: Marcel Torne, Andy Tang, Yuejiang Liu, Chelsea Finn  

**Link**: [PDF](https://arxiv.org/pdf/2505.09561)  

**Abstract**: Reasoning over long sequences of observations and actions is essential for many robotic tasks. Yet, learning effective long-context policies from demonstrations remains challenging. As context length increases, training becomes increasingly expensive due to rising memory demands, and policy performance often degrades as a result of spurious correlations. Recent methods typically sidestep these issues by truncating context length, discarding historical information that may be critical for subsequent decisions. In this paper, we propose an alternative approach that explicitly regularizes the retention of past information. We first revisit the copycat problem in imitation learning and identify an opposite challenge in recent diffusion policies: rather than over-relying on prior actions, they often fail to capture essential dependencies between past and future actions. To address this, we introduce Past-Token Prediction (PTP), an auxiliary task in which the policy learns to predict past action tokens alongside future ones. This regularization significantly improves temporal modeling in the policy head, with minimal reliance on visual representations. Building on this observation, we further introduce a multistage training strategy: pre-train the visual encoder with short contexts, and fine-tune the policy head using cached long-context embeddings. This strategy preserves the benefits of PTP while greatly reducing memory and computational overhead. Finally, we extend PTP into a self-verification mechanism at test time, enabling the policy to score and select candidates consistent with past actions during inference. Experiments across four real-world and six simulated tasks demonstrate that our proposed method improves the performance of long-context diffusion policies by 3x and accelerates policy training by more than 10x. 

**Abstract (ZH)**: 基于长时间序列的观测与动作推理对于许多机器人任务至关重要。然而，从示范中学习有效的长时间上下文策略仍然具有挑战性。随着上下文长度的增加，训练变得越来越昂贵，由于虚假关联而导致策略性能下降。最近的方法通常通过截断上下文长度来避开这些问题，从而丢弃可能对后续决策至关重要的历史信息。在本文中，我们提出了一种替代方法，该方法明确地正则化对过去信息的保留。我们首先回顾了模仿学习中的复制问题，并识别出近期扩散策略中的一个相反挑战：与其过度依赖于先前的动作，它们往往未能捕捉到过去和未来动作之间的关键依赖关系。为了解决这个问题，我们引入了过去动作令牌预测（PTP），这是一种辅助任务，其中策略学会了同时预测过去的动作令牌和未来的动作令牌。这种正则化显著改进了策略头部的时间建模，同时最大程度地减少了对视觉表示的依赖。基于这一观察，我们进一步提出了多阶段训练策略：使用短上下文预训练视觉编码器，并使用缓存的长上下文嵌入微调策略头部。这种策略保留了PTP的益处，同时大大减少了内存和计算开销。最后，我们在测试时将PTP扩展为一种自我验证机制，使策略能够在推理时为与过去动作一致的动作候选者打分并进行选择。实验结果表明，我们的方法在四个真实世界任务和六个仿真任务中将长上下文扩散策略的性能提高了3倍，并将策略训练速度加快了超过10倍。 

---
# Distilling Realizable Students from Unrealizable Teachers 

**Title (ZH)**: 从非实现性教师中提炼实现性学生 

**Authors**: Yujin Kim, Nathaniel Chin, Arnav Vasudev, Sanjiban Choudhury  

**Link**: [PDF](https://arxiv.org/pdf/2505.09546)  

**Abstract**: We study policy distillation under privileged information, where a student policy with only partial observations must learn from a teacher with full-state access. A key challenge is information asymmetry: the student cannot directly access the teacher's state space, leading to distributional shifts and policy degradation. Existing approaches either modify the teacher to produce realizable but sub-optimal demonstrations or rely on the student to explore missing information independently, both of which are inefficient. Our key insight is that the student should strategically interact with the teacher --querying only when necessary and resetting from recovery states --to stay on a recoverable path within its own observation space. We introduce two methods: (i) an imitation learning approach that adaptively determines when the student should query the teacher for corrections, and (ii) a reinforcement learning approach that selects where to initialize training for efficient exploration. We validate our methods in both simulated and real-world robotic tasks, demonstrating significant improvements over standard teacher-student baselines in training efficiency and final performance. The project website is available at : this https URL 

**Abstract (ZH)**: 我们在特权信息下的策略蒸馏研究中，探讨了一种学生策略仅通过部分观测从具有全状态访问权的教师处学习的方法。关键挑战在于信息不对称：学生无法直接访问教师的状态空间，导致分布偏移和策略退化。现有方法要么修改教师以产生可实现但非最优的演示，要么依赖学生独立探索缺失信息，这两种方法都效率低下。我们的核心洞察是，学生应该有策略地与教师交互——仅在必要时查询教师并在恢复状态下重置——以在其自身观测空间内保持可恢复路径。我们提出两种方法：(i) 一种自适应的模仿学习方法，确定学生何时需要查询教师以获得纠正；(ii) 一种强化学习方法，选择初始化训练的位置以实现高效探索。我们在模拟和真实世界机器人任务中验证了这些方法，显示出在训练效率和最终性能方面相对于标准教师-学生基线的显著改进。项目网站详见：这个链接。 

---
# Design of a Formation Control System to Assist Human Operators in Flying a Swarm of Robotic Blimps 

**Title (ZH)**: 设计一种编队控制系统以辅助人类操作员操控飞艇无人机群 

**Authors**: Tianfu Wu, Jiaqi Fu, Wugang Meng, Sungjin Cho, Huanzhe Zhan, Fumin Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2505.09511)  

**Abstract**: Formation control is essential for swarm robotics, enabling coordinated behavior in complex environments. In this paper, we introduce a novel formation control system for an indoor blimp swarm using a specialized leader-follower approach enhanced with a dynamic leader-switching mechanism. This strategy allows any blimp to take on the leader role, distributing maneuvering demands across the swarm and enhancing overall formation stability. Only the leader blimp is manually controlled by a human operator, while follower blimps use onboard monocular cameras and a laser altimeter for relative position and altitude estimation. A leader-switching scheme is proposed to assist the human operator to maintain stability of the swarm, especially when a sharp turn is performed. Experimental results confirm that the leader-switching mechanism effectively maintains stable formations and adapts to dynamic indoor environments while assisting human operator. 

**Abstract (ZH)**: 室内气球群的新型 formations 控制系统：基于动态领导切换机制的专门跟随者方法 

---
# Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities 

**Title (ZH)**: 在实际环境中部署基础模型驱动的空中和地面机器人：挑战与机遇 

**Authors**: Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2505.09477)  

**Abstract**: The integration of foundation models (FMs) into robotics has enabled robots to understand natural language and reason about the semantics in their environments. However, existing FM-enabled robots primary operate in closed-world settings, where the robot is given a full prior map or has a full view of its workspace. This paper addresses the deployment of FM-enabled robots in the field, where missions often require a robot to operate in large-scale and unstructured environments. To effectively accomplish these missions, robots must actively explore their environments, navigate obstacle-cluttered terrain, handle unexpected sensor inputs, and operate with compute constraints. We discuss recent deployments of SPINE, our LLM-enabled autonomy framework, in field robotic settings. To the best of our knowledge, we present the first demonstration of large-scale LLM-enabled robot planning in unstructured environments with several kilometers of missions. SPINE is agnostic to a particular LLM, which allows us to distill small language models capable of running onboard size, weight and power (SWaP) limited platforms. Via preliminary model distillation work, we then present the first language-driven UAV planner using on-device language models. We conclude our paper by proposing several promising directions for future research. 

**Abstract (ZH)**: 将基础模型（FMs）集成到机器人中使得机器人能够理解自然语言并对其环境中的语义进行推理。然而，现有FMs-enable的机器人主要在已知世界环境中操作，即机器人被提供了一个完整的先验地图或拥有其工作空间的全视图。本文旨在解决在野外部署FMs-enable的机器人的问题，其中任务通常要求机器人在大型且未结构化的环境中操作。为了有效地完成这些任务，机器人必须主动探索其环境、导航复杂的障碍地形、处理意外的传感器输入，并在计算受限的情况下操作。我们讨论了我们基于大语言模型（LLM）的自主框架SPINE在野外机器人环境中的最新部署。据我们所知，我们首次展示了使用多个千米级任务的大规模LLM-enable机器人规划在未结构化环境中的演示。SPINE不对特定的LLM有偏见，这使得我们能够提炼适用于受负载、重量和功率（SWaP）限制的平台的小型语言模型。通过初步的模型精简工作，我们首次提出了使用设备上语言模型的基于语言的UAV规划器。我们论文的结论部分提出了未来研究的若干有前途的方向。 

---
# aUToPath: Unified Planning and Control for Autonomous Vehicles in Urban Environments Using Hybrid Lattice and Free-Space Search 

**Title (ZH)**: AUToPath: 城市环境中基于混合格网和自由空间搜索的自主车辆统一规划与控制 

**Authors**: Tanmay P. Patel, Connor Wilson, Ellina R. Zhang, Morgan Tran, Chang Keun Paik, Steven L. Waslander, Timothy D. Barfoot  

**Link**: [PDF](https://arxiv.org/pdf/2505.09475)  

**Abstract**: This paper presents aUToPath, a unified online framework for global path-planning and control to address the challenge of autonomous navigation in cluttered urban environments. A key component of our framework is a novel hybrid planner that combines pre-computed lattice maps with dynamic free-space sampling to efficiently generate optimal driveable corridors in cluttered scenarios. Our system also features sequential convex programming (SCP)-based model predictive control (MPC) to refine the corridors into smooth, dynamically consistent trajectories. A single optimization problem is used to both generate a trajectory and its corresponding control commands; this addresses limitations of decoupled approaches by guaranteeing a safe and feasible path. Simulation results of the novel planner on randomly generated obstacle-rich scenarios demonstrate the success rate of a free-space Adaptively Informed Trees* (AIT*)-based planner, and runtimes comparable to a lattice-based planner. Real-world experiments of the full system on a Chevrolet Bolt EUV further validate performance in dense obstacle fields, demonstrating no violations of traffic, kinematic, or vehicle constraints, and a 100% success rate across eight trials. 

**Abstract (ZH)**: 本文提出了一种统一的在线框架UToPath，用于解决拥挤城市环境中自主导航的全局路径规划与控制挑战。该框架的一个关键组成部分是一种新颖的混合规划器，它结合了预先计算的格子地图和动态自由空间采样，以有效地在复杂场景中生成最优可驾驶走廊。系统还集成了基于序列凸规划（SCP）的模型预测控制（MPC），以将走廊细化为平滑且动力学一致的轨迹。通过单一优化问题同时生成轨迹及其对应的控制命令，该框架解决了拆分方法的局限性，保证了路径的安全性和可行性。针对随机生成的障碍丰富场景的新规划器的仿真结果展示了基于自适应信息树（AIT*）的规划器的成功率，并且运行时间与基于格子的规划器相当。在Chevrolet Bolt EUV上的实验证明了该完整系统的 performances 在密集障碍场中的有效性，没有违反交通、动力学或车辆约束，并且在八次试验中均成功。 

---
# Decentralized Nonlinear Model Predictive Control-Based Flock Navigation with Real-Time Obstacle Avoidance in Unknown Obstructed Environments 

**Title (ZH)**: 基于实时避障的未知受阻环境下去中心化非线性模型预测控制 flock 导航 

**Authors**: Nuthasith Gerdpratoom, Kaoru Yamamoto  

**Link**: [PDF](https://arxiv.org/pdf/2505.09434)  

**Abstract**: This work extends our prior work on the distributed nonlinear model predictive control (NMPC) for navigating a robot fleet following a certain flocking behavior in unknown obstructed environments with a more realistic local obstacle avoidance strategy. More specifically, we integrate the local obstacle avoidance constraint using point clouds into the NMPC framework. Here, each agent relies on data from its local sensor to perceive and respond to nearby obstacles. A point cloud processing technique is presented for both two-dimensional and three-dimensional point clouds to minimize the computational burden during the optimization. The process consists of directional filtering and down-sampling that significantly reduce the number of data points. The algorithm's performance is validated through realistic 3D simulations in Gazebo, and its practical feasibility is further explored via hardware-in-the-loop (HIL) simulations on embedded platforms. 

**Abstract (ZH)**: 这种工作扩展了我们之前关于在未知障碍环境中遵循特定集群行为导航机器人舰队的分布式非线性模型预测控制（NMPC）的研究，引入了更现实的局部障碍避免策略。具体来说，我们将基于点云的局部障碍避免约束整合进NMPC框架。每个代理依赖其本地传感器的数据来感知和响应附近的障碍。提出了一种对二维和三维点云的处理技术，以减轻优化过程中的计算负担。该过程包括方向滤波和下采样，显著减少了数据点的数量。算法性能通过Gazebo中的真实三维仿真得到验证，并通过嵌入式平台上的硬件在环（HIL）仿真进一步探讨了其实用可行性。 

---
# Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU 

**Title (ZH)**: 在一天内使用一块GPU训练一个针对RLBench-18的多任务扩散策略 

**Authors**: Yutong Hu, Pinhao Song, Kehan Wen, Renaud Detry  

**Link**: [PDF](https://arxiv.org/pdf/2505.09430)  

**Abstract**: We present a method for training multi-task vision-language robotic diffusion policies that reduces training time and memory usage by an order of magnitude. This improvement arises from a previously underexplored distinction between action diffusion and the image diffusion techniques that inspired it: image generation targets are high-dimensional, while robot actions lie in a much lower-dimensional space. Meanwhile, the vision-language conditions for action generation remain high-dimensional. Our approach, Mini-Diffuser, exploits this asymmetry by introducing Level-2 minibatching, which pairs multiple noised action samples with each vision-language condition, instead of the conventional one-to-one sampling strategy. To support this batching scheme, we introduce architectural adaptations to the diffusion transformer that prevent information leakage across samples while maintaining full conditioning access. In RLBench simulations, Mini-Diffuser achieves 95\% of the performance of state-of-the-art multi-task diffusion policies, while using only 5\% of the training time and 7\% of the memory. Real-world experiments further validate that Mini-Diffuser preserves the key strengths of diffusion-based policies, including the ability to model multimodal action distributions and produce behavior conditioned on diverse perceptual inputs. Code available at this http URL. 

**Abstract (ZH)**: 一种通过利用动作扩散和图像扩散之间维度差异来减少训练时间和内存使用量的多任务vision-language机器人扩散策略训练方法：Mini-Diffuser 

---
# Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion 

**Title (ZH)**: 探索基于姿态引导的模仿学习在机器人精确插入任务中的应用 

**Authors**: Han Sun, Yizhao Wang, Zhenning Zhou, Shuai Wang, Haibo Yang, Jingyuan Sun, Qixin Cao  

**Link**: [PDF](https://arxiv.org/pdf/2505.09424)  

**Abstract**: Recent studies have proved that imitation learning shows strong potential in the field of robotic manipulation. However, existing methods still struggle with precision manipulation task and rely on inefficient image/point cloud observations. In this paper, we explore to introduce SE(3) object pose into imitation learning and propose the pose-guided efficient imitation learning methods for robotic precise insertion task. First, we propose a precise insertion diffusion policy which utilizes the relative SE(3) pose as the observation-action pair. The policy models the source object SE(3) pose trajectory relative to the target object. Second, we explore to introduce the RGBD data to the pose-guided diffusion policy. Specifically, we design a goal-conditioned RGBD encoder to capture the discrepancy between the current state and the goal state. In addition, a pose-guided residual gated fusion method is proposed, which takes pose features as the backbone, and the RGBD features selectively compensate for pose feature deficiencies through an adaptive gating mechanism. Our methods are evaluated on 6 robotic precise insertion tasks, demonstrating competitive performance with only 7-10 demonstrations. Experiments demonstrate that the proposed methods can successfully complete precision insertion tasks with a clearance of about 0.01 mm. Experimental results highlight its superior efficiency and generalization capability compared to existing baselines. Code will be available at this https URL. 

**Abstract (ZH)**: 近期研究表明，模仿学习在机器人操作领域展现出强大潜力。然而，现有方法在精确操作任务上仍面临挑战，并且依赖于低效的图像/点云观测。本文探索将SE(3)物体姿态引入模仿学习，并提出一种姿态导向的高效模仿学习方法，用于机器人精确插入任务。首先，我们提出了一种精确插入扩散策略，利用相对SE(3)姿态作为观测-动作对。该策略模型了源物体相对于目标物体的SE(3)姿态轨迹。其次，我们探索将RGBD数据引入姿态导向扩散策略中。具体来说，我们设计了一种目标条件的RGBD编码器以捕捉当前状态与目标状态之间的差异。此外，提出了一种姿态导向的残差门控融合方法，该方法以姿态特征作为骨干，并通过自适应门控机制选择性地补充姿态特征的不足。我们在6个机器人精确插入任务上评估了我们的方法，演示了仅需7-10个演示即可达到竞争力的性能。实验表明，所提出的方法可以成功完成清除精度约为0.01 mm的精确插入任务。实验结果突显了其相比现有基线的优越高效性和泛化能力。代码将在此链接处提供。 

---
# Strategic Jenga Play via Graph Based Dynamics Modeling 

**Title (ZH)**: 基于图动态建模的 Strategic Jenga 操作策略 

**Authors**: Kavya Puthuveetil, Xinyi Zhang, Kazuto Yokoyama, Tetsuya Narita  

**Link**: [PDF](https://arxiv.org/pdf/2505.09377)  

**Abstract**: Controlled manipulation of multiple objects whose dynamics are closely linked is a challenging problem within contact-rich manipulation, requiring an understanding of how the movement of one will impact the others. Using the Jenga game as a testbed to explore this problem, we graph-based modeling to tackle two different aspects of the task: 1) block selection and 2) block extraction. For block selection, we construct graphs of the Jenga tower and attempt to classify, based on the tower's structure, whether removing a given block will cause the tower to collapse. For block extraction, we train a dynamics model that predicts how all the blocks in the tower will move at each timestep in an extraction trajectory, which we then use in a sampling-based model predictive control loop to safely pull blocks out of the tower with a general-purpose parallel-jaw gripper. We train and evaluate our methods in simulation, demonstrating promising results towards block selection and block extraction on a challenging set of full-sized Jenga towers, even at advanced stages of the game. 

**Abstract (ZH)**: 控制 manipulation 多个紧密关联动力学的对象是一项在丰富接触 manipulation 中具有挑战性的问题，需要理解一个对象的运动如何影响其他对象。为了探索这一问题，我们利用 Jenga 游戏作为实验平台，采用基于图的建模方法研究任务的两个不同方面：1) 块的选择；2) 块的提取。对于块的选择，我们构建 Jenga 塔的图，并尝试根据塔的结构来分类，判断移除给定块是否会令塔倒塌。对于块的提取，我们训练一个动力学模型，该模型可以预测在提取轨迹中的每个时间步，塔中所有块的运动情况，并利用该模型在一个基于采样的模型预测控制循环中，安全地使用通用并指夹爪从塔中拉出块。我们在仿真中训练和评估了我们的方法，展示了在一组具有挑战性的全尺寸 Jenga 塔上，即使是游戏的后期阶段，对块选择和块提取取得有前景的结果。 

---
# Improved Corner Cutting Constraints for Mixed-Integer Motion Planning of a Differential Drive Micro-Mobility Vehicle 

**Title (ZH)**: 改进的转角裁剪约束条件在差动驱动微型移动车辆混合整数运动规划中的应用 

**Authors**: Angelo Caregnato-Neto, Janito Vaqueiro Ferreira  

**Link**: [PDF](https://arxiv.org/pdf/2505.09359)  

**Abstract**: This paper addresses the problem of motion planning for differential drive micro-mobility platforms. This class of vehicle is designed to perform small-distance transportation of passengers and goods in structured environments. Our approach leverages mixed-integer linear programming (MILP) to compute global optimal collision-free trajectories taking into account the kinematics and dynamics of the vehicle. We propose novel constraints for intersample collision avoidance and demonstrate its effectiveness using pick-up and delivery missions and statistical analysis of Monte Carlo simulations. The results show that the novel formulation provides the best trajectories in terms of time expenditure and control effort when compared to two state-of-the-art approaches. 

**Abstract (ZH)**: 这篇论文解决了差动驱动微移动平台的运动规划问题。此类车辆设计用于在结构化环境中进行短距离的乘客和货物运输。我们利用混合整数线性规划（MILP）来计算全局最优且无碰撞的轨迹，同时考虑车辆的kinematics和dynamics。我们提出了新的采样点间避碰约束，并通过拾取和交付任务及其蒙特卡洛模拟的统计分析来证明其有效性。结果显示，新型表示法在时间和控制努力方面提供了最佳轨迹，优于两种最先进的方法。 

---
# APR-Transformer: Initial Pose Estimation for Localization in Complex Environments through Absolute Pose Regression 

**Title (ZH)**: APR-Transformer: 通过绝对位姿回归在复杂环境中的初始姿态估计定位 

**Authors**: Srinivas Ravuri, Yuan Xu, Martin Ludwig Zehetner, Ketan Motlag, Sahin Albayrak  

**Link**: [PDF](https://arxiv.org/pdf/2505.09356)  

**Abstract**: Precise initialization plays a critical role in the performance of localization algorithms, especially in the context of robotics, autonomous driving, and computer vision. Poor localization accuracy is often a consequence of inaccurate initial poses, particularly noticeable in GNSS-denied environments where GPS signals are primarily relied upon for initialization. Recent advances in leveraging deep neural networks for pose regression have led to significant improvements in both accuracy and robustness, especially in estimating complex spatial relationships and orientations. In this paper, we introduce APR-Transformer, a model architecture inspired by state-of-the-art methods, which predicts absolute pose (3D position and 3D orientation) using either image or LiDAR data. We demonstrate that our proposed method achieves state-of-the-art performance on established benchmark datasets such as the Radar Oxford Robot-Car and DeepLoc datasets. Furthermore, we extend our experiments to include our custom complex APR-BeIntelli dataset. Additionally, we validate the reliability of our approach in GNSS-denied environments by deploying the model in real-time on an autonomous test vehicle. This showcases the practical feasibility and effectiveness of our approach. The source code is available at:this https URL. 

**Abstract (ZH)**: 精确初始化在定位算法中的性能中扮演着至关重要的角色，特别是在机器人技术、自动驾驶和计算机视觉的背景下。在GNSS受限环境中，主要依赖GPS信号进行初始化时，初始姿态的不准确性通常会导致定位精度低下。近年来，利用深度神经网络进行姿态回归的进步显著提高了准确性和鲁棒性，尤其是在估计复杂的空间关系和方向方面。在本文中，我们提出了一种受最新方法启发的APR-Transformer模型架构，该模型使用图像或LiDAR数据预测绝对姿态（3D位置和3D方向）。我们证明，我们提出的方法在雷达牛津自动驾驶汽车和DeepLoc数据集等建立基准的数据集上实现了最先进的性能。此外，我们将实验扩展到包括我们自定义的复杂APR-BeIntelli数据集。我们还在实际环境中部署该模型于一辆自主测试车辆上，以验证其在GNSS受限环境中的可靠性。这展示了我们方法的实际可行性和有效性。源代码可在以下链接获取：this https URL。 

---
# TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving 

**Title (ZH)**: TransDiffuser: 集成去相关多模态表示的端到端轨迹生成方法及其在自主驾驶中的应用 

**Authors**: Xuefeng Jiang, Yuan Ma, Pengxiang Li, Leimeng Xu, Xin Wen, Kun Zhan, Zhongpu Xia, Peng Jia, XianPeng Lang, Sheng Sun  

**Link**: [PDF](https://arxiv.org/pdf/2505.09315)  

**Abstract**: In recent years, diffusion model has shown its potential across diverse domains from vision generation to language modeling. Transferring its capabilities to modern autonomous driving systems has also emerged as a promising this http URL this work, we propose TransDiffuser, an encoder-decoder based generative trajectory planning model for end-to-end autonomous driving. The encoded scene information serves as the multi-modal conditional input of the denoising decoder. To tackle the mode collapse dilemma in generating high-quality diverse trajectories, we introduce a simple yet effective multi-modal representation decorrelation optimization mechanism during the training this http URL achieves PDMS of 94.85 on the NAVSIM benchmark, surpassing previous state-of-the-art methods without any anchor-based prior trajectories. 

**Abstract (ZH)**: 近年来，扩散模型在视觉生成和语言模型等领域展现出了潜在应用价值。将其能力应用到现代自主驾驶系统中也成为了一个有前景的方向。在本文中，我们提出了一种基于编码-解码结构的生成性轨迹规划模型TransDiffuser，用于端到端的自主驾驶。编码场景信息作为去噪解码器的多模态条件输入。为了应对生成高质量多样化轨迹时遇到的模态崩溃问题，在训练过程中引入了一种简单有效的多模态表示去相关优化机制。该模型在NAVSIM基准测试中达到了94.85的PDMS性能，超越了之前的最先进的方法，无需依赖基于锚点的先验轨迹。 

---
# Embodied Intelligent Industrial Robotics: Concepts and Techniques 

**Title (ZH)**: 身体化智能工业机器人：概念与技术 

**Authors**: Chaoran Zhang, Chenhao Zhang, Zhaobo Xu, Qinghongbing Xie, Pingfa Feng, Long Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2505.09305)  

**Abstract**: In recent years, embodied intelligent robotics (EIR) has made significant progress in multi-modal perception, autonomous decision-making, and physical interaction. Some robots have already been tested in general-purpose scenarios such as homes and shopping malls. We aim to advance the research and application of embodied intelligence in industrial scenes. However, current EIR lacks a deep understanding of industrial environment semantics and the normative constraints between industrial operating objects. To address this gap, this paper first reviews the history of industrial robotics and the mainstream EIR frameworks. We then introduce the concept of the embodied intelligent industrial robotics (EIIR) and propose a knowledge-driven EIIR technology framework for industrial environments. The framework includes four main modules: world model, high-level task planner, low-level skill controller, and simulator. We also review the current development of technologies related to each module and highlight recent progress in adapting them to industrial applications. Finally, we summarize the key challenges EIIR faces in industrial scenarios and suggest future research directions. We believe that EIIR technology will shape the next generation of industrial robotics. Industrial systems based on embodied intelligent industrial robots offer strong potential for enabling intelligent manufacturing. We will continue to track and summarize new research in this area and hope this review will serve as a valuable reference for scholars and engineers interested in industrial embodied intelligence. Together, we can help drive the rapid advancement and application of this technology. The associated project can be found at this https URL. 

**Abstract (ZH)**: 近年来，具身智能机器人（EIR）在多模态感知、自主决策和物理交互方面取得了显著进展。一些机器人已经在家庭和购物中心等通用场景中进行了测试。我们旨在推动具身智能在工业场景中的研究和应用。然而，当前的EIR缺乏对工业环境语义及其工业操作对象间规范性约束的深刻理解。为填补这一空白，本文首先回顾了工业机器人发展史和主流EIR框架。然后介绍了具身智能工业机器人（EIIR）的概念，并提出了一种面向工业环境的知识驱动EIIR技术框架。该框架包含四个主要模块：世界模型、高层任务规划器、低层技能控制器和模拟器。我们还回顾了每个模块相关技术的当前发展状况，并强调了它们在工业应用中适应性改进的最新进展。最后，我们总结了EIIR在工业场景中面临的关键挑战，并提出了未来的研究方向。我们认为，EIIR技术将塑造下一代工业机器人。基于具身智能工业机器人的工业系统具有实现智能制造的强大潜力。我们将继续跟踪和总结该领域的最新研究，并希望本文评述能为从事工业具身智能研究的学者和工程师提供有价值的参考。大家一起可以推动这项技术的快速发展和应用。相关项目可在以下链接找到：this https URL。 

---
# A drone that learns to efficiently find objects in agricultural fields: from simulation to the real world 

**Title (ZH)**: 一种在农业田地高效搜索物体的无人机：从仿真到现实世界 

**Authors**: Rick van Essen, Gert Kootstra  

**Link**: [PDF](https://arxiv.org/pdf/2505.09278)  

**Abstract**: Drones are promising for data collection in precision agriculture, however, they are limited by their battery capacity. Efficient path planners are therefore required. This paper presents a drone path planner trained using Reinforcement Learning (RL) on an abstract simulation that uses object detections and uncertain prior knowledge. The RL agent controls the flight direction and can terminate the flight. By using the agent in combination with the drone's flight controller and a detection network to process camera images, it is possible to evaluate the performance of the agent on real-world data. In simulation, the agent yielded on average a 78% shorter flight path compared to a full coverage planner, at the cost of a 14% lower recall. On real-world data, the agent showed a 72% shorter flight path compared to a full coverage planner, however, at the cost of a 25% lower recall. The lower performance on real-world data was attributed to the real-world object distribution and the lower accuracy of prior knowledge, and shows potential for improvement. Overall, we concluded that for applications where it is not crucial to find all objects, such as weed detection, the learned-based path planner is suitable and efficient. 

**Abstract (ZH)**: 无人机在精密农业中的数据采集具有潜力，然而受限于电池容量。因此需要高效路径规划器。本文提出一种基于强化学习（RL）训练的无人机路径规划器，该规划器使用抽象仿真和对象检测结合不确定先验知识。通过将该智能体与无人机飞行控制器和检测网络结合处理相机图像，可以在真实数据上评估智能体的性能。在仿真中，智能体的飞行路径平均比全覆盖规划器短78%，但召回率降低了14%。在真实数据上，智能体的飞行路径平均比全覆盖规划器短72%，但召回率降低了25%。真实数据上的较低性能归因于真实世界的物体分布和先验知识的较低准确性，并显示了改进的潜力。总体而言，我们得出结论，在如杂草检测等不需要找到所有物体的应用场景中，基于学习的路径规划器是合适且高效的。 

---
# Robot-Assisted Drone Recovery on a Wavy Surface Using Error-State Kalman Filter and Receding Horizon Model Predictive Control 

**Title (ZH)**: 使用误差状态卡尔曼滤波器和递推_horizon模型预测控制的波浪表面无人机辅助回收 

**Authors**: Yimou Wu, Mingyang Liang, Ruoyu Xu  

**Link**: [PDF](https://arxiv.org/pdf/2505.09145)  

**Abstract**: Recovering a drone on a disturbed water surface remains a significant challenge in maritime robotics. In this paper, we propose a unified framework for Robot-Assisted Drone Recovery on a Wavy Surface that addresses two major tasks: Firstly, accurate prediction of a moving drone's position under wave-induced disturbances using an Error-State Kalman Filter (ESKF), and secondly, effective motion planning for a manipulator via Receding Horizon Control (RHC). Specifically, the ESKF predicts the drone's future position 0.5s ahead, while the manipulator plans a capture trajectory in real time, thus overcoming not only wave-induced base motions but also limited torque constraints. We provide a system design that comprises a manipulator subsystem and a UAV subsystem. On the UAV side, we detail how position control and suspended payload strategies are implemented. On the manipulator side, we show how an RHC scheme outperforms traditional low-level control algorithms. Simulation and real-world experiments - using wave-disturbed motion data - demonstrate that our approach achieves a high success rate - above 95% and outperforms conventional baseline methods by up to 10% in efficiency and 20% in precision. The results underscore the feasibility and robustness of our system, which achieves state-of-the-art (SOTA) performance and offers a practical solution for maritime drone operations. 

**Abstract (ZH)**: 基于波动表面的无人机辅助回收统一框架 

---
# Latent Theory of Mind: A Decentralized Diffusion Architecture for Cooperative Manipulation 

**Title (ZH)**: 潜在的心理论：一种用于合作操作的去中心化扩散架构 

**Authors**: Chengyang He, Gadiel Sznaier Camps, Xu Liu, Mac Schwager, Guillaume Sartoretti  

**Link**: [PDF](https://arxiv.org/pdf/2505.09144)  

**Abstract**: We present Latent Theory of Mind (LatentToM), a decentralized diffusion policy architecture for collaborative robot manipulation. Our policy allows multiple manipulators with their own perception and computation to collaborate with each other towards a common task goal with or without explicit communication. Our key innovation lies in allowing each agent to maintain two latent representations: an ego embedding specific to the robot, and a consensus embedding trained to be common to both robots, despite their different sensor streams and poses. We further let each robot train a decoder to infer the other robot's ego embedding from their consensus embedding, akin to theory of mind in latent space. Training occurs centrally, with all the policies' consensus encoders supervised by a loss inspired by sheaf theory, a mathematical theory for clustering data on a topological manifold. Specifically, we introduce a first-order cohomology loss to enforce sheaf-consistent alignment of the consensus embeddings. To preserve the expressiveness of the consensus embedding, we further propose structural constraints based on theory of mind and a directional consensus mechanism. Execution can be fully distributed, requiring no explicit communication between policies. In which case, the information is exchanged implicitly through each robot's sensor stream by observing the actions of the other robots and their effects on the scene. Alternatively, execution can leverage direct communication to share the robots' consensus embeddings, where the embeddings are shared once during each inference step and are aligned using the sheaf Laplacian. In our hardware experiments, LatentToM outperforms a naive decentralized diffusion baseline, and shows comparable performance with a state-of-the-art centralized diffusion policy for bi-manual manipulation. Project website: this https URL. 

**Abstract (ZH)**: 我们提出了一种分布式扩散策略架构Latent Theory of Mind (LatentToM)，用于协作机器人操作。我们的策略允许多个具有自身感知和计算能力的 manipulator 在无需显式通信的情况下，为共同任务目标协同工作。我们的关键创新在于，每个代理可以维持两个潜在表示：一个特定于机器人的自我嵌入，以及一个虽然传感器流和姿态不同但旨在共同化的共识嵌入。我们进一步允许每个机器人训练一个解码器，从共识嵌入中推断出另一个机器人的自我嵌入，类似于潜空间中的理论思维。训练过程是集中式的，所有策略的共识编码器都由借鉴流层理论（一种用于聚类拓扑流形上数据的数学理论）的损失监督。具体地，我们引入了一阶同调损失来确保共识嵌入的一致对齐。为了保持共识嵌入的表达能力，我们还提出了基于理论思维的结构约束和定向共识机制。执行可以完全分布式，无需策略之间进行显式通信。在这种情况下，通过观察其他机器人及其对场景的影响，信息是通过每个机器人的传感器流隐式交换的。或者，执行可以利用直接通信来共享机器人的共识嵌入，在每次推理步骤中仅共享一次嵌入，并使用流层拉普拉斯算子进行对齐。在我们的硬件实验中，LatentToM 比一个简单的分布式扩散基线更优，并且在双臂操作方面与最新的集中式扩散策略具有可比的性能。项目网站：this https URL。 

---
# Model Identification Adaptive Control with $ρ$-POMDP Planning 

**Title (ZH)**: 基于ρ-POMDP规划的模型识别自适应控制 

**Authors**: Michelle Ho, Arec Jamgochian, Mykel J. Kochenderfer  

**Link**: [PDF](https://arxiv.org/pdf/2505.09119)  

**Abstract**: Accurate system modeling is crucial for safe, effective control, as misidentification can lead to accumulated errors, especially under partial observability. We address this problem by formulating informative input design (IID) and model identification adaptive control (MIAC) as belief space planning problems, modeled as partially observable Markov decision processes with belief-dependent rewards ($\rho$-POMDPs). We treat system parameters as hidden state variables that must be localized while simultaneously controlling the system. We solve this problem with an adapted belief-space iterative Linear Quadratic Regulator (BiLQR). We demonstrate it on fully and partially observable tasks for cart-pole and steady aircraft flight domains. Our method outperforms baselines such as regression, filtering, and local optimal control methods, even under instantaneous disturbances to system parameters. 

**Abstract (ZH)**: 精确的系统建模对于安全、有效的控制至关重要，因为误识别会导致累积误差，尤其是在部分可观测情况下。我们通过将信息性输入设计（IID）和模型识别自适应控制（MIAC）形式化为信念空间规划问题来解决这一问题，将其建模为具有信念依赖奖励的部分可观测马尔可夫决策过程（$\rho$-POMDP）。我们将系统参数视为必须定位的隐藏状态变量，同时控制系统。我们使用改进的信念空间迭代线性二次调节器（BiLQR）来解决这一问题。我们在全可观测和部分可观测的cart-pole和稳定飞机飞行域任务中进行了演示。该方法在系统参数瞬时扰动下优于回归、滤波和局部最优控制等基线方法。 

---
# FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis 

**Title (ZH)**: FoldNet：通过关键点驱动的资产和演示合成学习通用闭环折衣策略 

**Authors**: Yuxing Chen, Bowen Xiao, He Wang  

**Link**: [PDF](https://arxiv.org/pdf/2505.09109)  

**Abstract**: Due to the deformability of garments, generating a large amount of high-quality data for robotic garment manipulation tasks is highly challenging. In this paper, we present a synthetic garment dataset that can be used for robotic garment folding. We begin by constructing geometric garment templates based on keypoints and applying generative models to generate realistic texture patterns. Leveraging these keypoint annotations, we generate folding demonstrations in simulation and train folding policies via closed-loop imitation learning. To improve robustness, we propose KG-DAgger, which uses a keypoint-based strategy to generate demonstration data for recovering from failures. KG-DAgger significantly improves the model performance, boosting the real-world success rate by 25\%. After training with 15K trajectories (about 2M image-action pairs), the model achieves a 75\% success rate in the real world. Experiments in both simulation and real-world settings validate the effectiveness of our proposed framework. 

**Abstract (ZH)**: 由于服装的可变形性，为机器人服装操作任务生成大量高质量数据极具挑战性。本文提出一个用于机器人服装折叠的合成服装数据集。我们首先基于关键点构建几何服装模板，并应用生成模型生成逼真的纹理图案。利用这些关键点标注，我们在仿真中生成折叠示范，并通过闭环模仿学习训练折叠策略。为了提高鲁棒性，我们提出了KG-DAgger方法，该方法使用关键点为基础的策略生成从失败中恢复的示范数据。KG-DAgger显著提高了模型性能，将实际成功率提升了25%。经过15K轨迹（约200万张图像-动作对）的训练，模型在实际环境中达到了75%的成功率。实验在仿真和实际环境设置中均验证了我们提出框架的有效性。 

---
# Air-Ground Collaboration for Language-Specified Missions in Unknown Environments 

**Title (ZH)**: 未知环境中的语言指定任务空地协作 

**Authors**: Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar  

**Link**: [PDF](https://arxiv.org/pdf/2505.09108)  

**Abstract**: As autonomous robotic systems become increasingly mature, users will want to specify missions at the level of intent rather than in low-level detail. Language is an expressive and intuitive medium for such mission specification. However, realizing language-guided robotic teams requires overcoming significant technical hurdles. Interpreting and realizing language-specified missions requires advanced semantic reasoning. Successful heterogeneous robots must effectively coordinate actions and share information across varying viewpoints. Additionally, communication between robots is typically intermittent, necessitating robust strategies that leverage communication opportunities to maintain coordination and achieve mission objectives. In this work, we present a first-of-its-kind system where an unmanned aerial vehicle (UAV) and an unmanned ground vehicle (UGV) are able to collaboratively accomplish missions specified in natural language while reacting to changes in specification on the fly. We leverage a Large Language Model (LLM)-enabled planner to reason over semantic-metric maps that are built online and opportunistically shared between an aerial and a ground robot. We consider task-driven navigation in urban and rural areas. Our system must infer mission-relevant semantics and actively acquire information via semantic mapping. In both ground and air-ground teaming experiments, we demonstrate our system on seven different natural-language specifications at up to kilometer-scale navigation. 

**Abstract (ZH)**: 随着自主机器人系统的日益成熟，用户将希望以任务意图而非低级细节的方式指定任务。语言是一种表达性和直观性的任务指定媒介。然而，实现以语言为指导的机器人团队需要克服重大的技术障碍。解析和实现语言指定的任务需要高级语义推理。成功的异构机器人必须有效地协调行动并跨越不同视角共享信息。此外，机器人之间的通信通常时断时续，需要利用通信机会制定稳健的策略以维持协调并实现任务目标。在本项工作中，我们提出了一种前所未有的系统，其中无人飞行器（UAV）和无人地面车辆（UGV）能够协作完成自然语言指定的任务，并能在任务指定发生变化时实时响应。我们利用一个基于大型语言模型（LLM）的规划器，在空中和地面机器人之间在线构建和机会性共享语义-度量地图来进行语义推理。我们考虑在城市和农村地区进行任务驱动的导航。我们的系统必须推断与任务相关的内容，并通过语义映射积极获取信息。在地面上的团队和空地一体化团队实验中，我们展示了该系统在多达千米规模导航中的七种不同自然语言任务规定。 

---
# VGC-RIO: A Tightly Integrated Radar-Inertial Odometry with Spatial Weighted Doppler Velocity and Local Geometric Constrained RCS Histograms 

**Title (ZH)**: VGC-RIO：整合了空间加权多普勒速度和局部几何约束 RCS 直方图的雷达-惯性里程计 

**Authors**: Jianguang Xiang, Xiaofeng He, Zizhuo Chen, Lilian Zhang, Xincan Luo, Jun Mao  

**Link**: [PDF](https://arxiv.org/pdf/2505.09103)  

**Abstract**: Recent advances in 4D radar-inertial odometry
have demonstrated promising potential for autonomous lo calization in adverse conditions. However, effective handling
of sparse and noisy radar measurements remains a critical
challenge. In this paper, we propose a radar-inertial odometry
with a spatial weighting method that adapts to unevenly
distributed points and a novel point-description histogram
for challenging point registration. To make full use of the
Doppler velocity from different spatial sections, we propose
a weighting calculation model. To enhance the point cloud
registration performance under challenging scenarios, we con struct a novel point histogram descriptor that combines local
geometric features and radar cross-section (RCS) features. We
have also conducted extensive experiments on both public and
self-constructed datasets. The results demonstrate the precision
and robustness of the proposed VGC-RIO. 

**Abstract (ZH)**: 最近izen雷达惯导里程计的进展在恶劣条件下的自主定位应用中展示了巨大的潜力。然而，有效处理稀疏且噪声较大的雷达测量值仍然是一个关键挑战。在本文中，我们提出了一种基于空间加权方法的雷达惯导里程计，并结合了一种新的点描述直方图来进行具有挑战性的点配准。为了充分利用来自不同空间区域的多普勒速度，我们提出了一种加权计算模型。为了在具有挑战性的场景下增强点云配准性能，我们构建了一种结合局部几何特征和雷达截面（RCS）特征的新型点直方图描述符。我们在公共数据集和自构建数据集上进行了广泛的实验。结果证明了所提出的VGC-RIO的精度和鲁棒性。 

---
# Imitation Learning for Adaptive Control of a Virtual Soft Exoglove 

**Title (ZH)**: 适应控制虚拟软外手套的模仿学习 

**Authors**: Shirui Lyu, Vittorio Caggiano, Matteo Leonetti, Dario Farina, Letizia Gionfrida  

**Link**: [PDF](https://arxiv.org/pdf/2505.09099)  

**Abstract**: The use of wearable robots has been widely adopted in rehabilitation training for patients with hand motor impairments. However, the uniqueness of patients' muscle loss is often overlooked. Leveraging reinforcement learning and a biologically accurate musculoskeletal model in simulation, we propose a customized wearable robotic controller that is able to address specific muscle deficits and to provide compensation for hand-object manipulation tasks. Video data of a same subject performing human grasping tasks is used to train a manipulation model through learning from demonstration. This manipulation model is subsequently fine-tuned to perform object-specific interaction tasks. The muscle forces in the musculoskeletal manipulation model are then weakened to simulate neurological motor impairments, which are later compensated by the actuation of a virtual wearable robotics glove. Results shows that integrating the virtual wearable robotic glove provides shared assistance to support the hand manipulator with weakened muscle forces. The learned exoglove controller achieved an average of 90.5\% of the original manipulation proficiency. 

**Abstract (ZH)**: 穿戴式机器人在手部运动障碍患者康复训练中的应用：基于强化学习和生物准确肌肉骨骼模型的个性化穿戴式机器人控制策略 

---
# Deployable and Generalizable Motion Prediction: Taxonomy, Open Challenges and Future Directions 

**Title (ZH)**: 可部署且通用的运动预测：分类、开放挑战与未来方向 

**Authors**: Letian Wang, Marc-Antoine Lavoie, Sandro Papais, Barza Nisar, Yuxiao Chen, Wenhao Ding, Boris Ivanovic, Hao Shao, Abulikemu Abuduweili, Evan Cook, Yang Zhou, Peter Karkus, Jiachen Li, Changliu Liu, Marco Pavone, Steven Waslander  

**Link**: [PDF](https://arxiv.org/pdf/2505.09074)  

**Abstract**: Motion prediction, the anticipation of future agent states or scene evolution, is rooted in human cognition, bridging perception and decision-making. It enables intelligent systems, such as robots and self-driving cars, to act safely in dynamic, human-involved environments, and informs broader time-series reasoning challenges. With advances in methods, representations, and datasets, the field has seen rapid progress, reflected in quickly evolving benchmark results. Yet, when state-of-the-art methods are deployed in the real world, they often struggle to generalize to open-world conditions and fall short of deployment standards. This reveals a gap between research benchmarks, which are often idealized or ill-posed, and real-world complexity.
To address this gap, this survey revisits the generalization and deployability of motion prediction models, with an emphasis on the applications of robotics, autonomous driving, and human motion. We first offer a comprehensive taxonomy of motion prediction methods, covering representations, modeling strategies, application domains, and evaluation protocols. We then study two key challenges: (1) how to push motion prediction models to be deployable to realistic deployment standards, where motion prediction does not act in a vacuum, but functions as one module of closed-loop autonomy stacks - it takes input from the localization and perception, and informs downstream planning and control. 2) how to generalize motion prediction models from limited seen scenarios/datasets to the open-world settings. Throughout the paper, we highlight critical open challenges to guide future work, aiming to recalibrate the community's efforts, fostering progress that is not only measurable but also meaningful for real-world applications. 

**Abstract (ZH)**: 运动预测模型的泛化与部署：面向机器人、自主驾驶和人体运动的应用研究 

---
# A Novel 6-axis Force/Torque Sensor Using Inductance Sensors 

**Title (ZH)**: 一种基于电感传感器的新型6轴力/扭矩传感器 

**Authors**: Hyun-Bin Kim, Kyung-Soo Kim  

**Link**: [PDF](https://arxiv.org/pdf/2505.09069)  

**Abstract**: This paper presents a novel six-axis force/torque (F/T) sensor based on inductive sensing technology. Unlike conventional strain gauge-based sensors that require direct contact and external amplification, the proposed sensor utilizes non-contact inductive measurements to estimate force via displacement of a conductive target. A compact, fully integrated architecture is achieved by incorporating a CAN-FD based signal processing module directly onto the PCB, enabling high-speed data acquisition at up to 4~kHz without external DAQ systems. The sensing mechanism is modeled and calibrated through a rational function fitting approach, which demonstrated superior performance in terms of root mean square error (RMSE), coefficient of determination ($R^2$), and linearity error compared to other nonlinear models. Static and repeatability experiments validate the sensor's accuracy, achieving a resolution of 0.03~N and quantization levels exceeding 55,000 steps, surpassing that of commercial sensors. The sensor also exhibits low crosstalk, high sensitivity, and robust noise characteristics. Its performance and structure make it suitable for precision robotic applications, especially in scenarios where compactness, non-contact operation, and integrated processing are essential. 

**Abstract (ZH)**: 基于感应技术的六轴力/扭矩传感器研究 

---
# Reach-Avoid-Stabilize Using Admissible Control Sets 

**Title (ZH)**: 可达-避险-稳定控制集方法 

**Authors**: Zheng Gong, Boyang Li, Sylvia Herbert  

**Link**: [PDF](https://arxiv.org/pdf/2505.09058)  

**Abstract**: Hamilton-Jacobi Reachability (HJR) analysis has been successfully used in many robotics and control tasks, and is especially effective in computing reach-avoid sets and control laws that enable an agent to reach a goal while satisfying state constraints. However, the original HJR formulation provides no guarantees of safety after a) the prescribed time horizon, or b) goal satisfaction. The reach-avoid-stabilize (RAS) problem has therefore gained a lot of focus: find the set of initial states (the RAS set), such that the trajectory can reach the target, and stabilize to some point of interest (POI) while avoiding obstacles. Solving RAS problems using HJR usually requires defining a new value function, whose zero sub-level set is the RAS set. The existing methods do not consider the problem when there are a series of targets to reach and/or obstacles to avoid. We propose a method that uses the idea of admissible control sets; we guarantee that the system will reach each target while avoiding obstacles as prescribed by the given time series. Moreover, we guarantee that the trajectory ultimately stabilizes to the POI. The proposed method provides an under-approximation of the RAS set, guaranteeing safety. Numerical examples are provided to validate the theory. 

**Abstract (ZH)**: Hamilton-Jacobi Reachability (HJR)分析已被成功应用于许多机器人和控制任务，并特别适用于计算可达规避集及使智能体能够达到目标的同时满足状态约束的控制法则。然而，原始的HJR公式在a) 规定的时间范围之外，或b) 达到目标之后，并不能提供安全性的保证。因此，可达规避稳定（RAS）问题受到了广泛的关注：找到初始状态集（RAS集），使得轨迹能够到达目标，稳定到某个兴趣点（POI），并避免障碍物。使用HJR求解RAS问题通常需要定义一个新的值函数，其零子水平集即为RAS集。现有方法未考虑在存在一系列目标要到达或多个障碍物要避免的情况下解决问题。我们提出了一种方法，利用可选控制集的思想；保证系统能够在指定的时间序列下达到每个目标并避免障碍物，同时保证轨迹最终稳定到POI。所提出的方法提供了RAS集的下界近似，并保证了安全性。提供了数值例子来验证理论。 

---
# RT-cache: Efficient Robot Trajectory Retrieval System 

**Title (ZH)**: RT-cache: 高效的机器人轨迹检索系统 

**Authors**: Owen Kwon, Abraham George, Alison Bartsch, Amir Barati Farimani  

**Link**: [PDF](https://arxiv.org/pdf/2505.09040)  

**Abstract**: This paper introduces RT-cache, a novel trajectorymemory pipeline that accelerates real-world robot inference by leveraging big-data retrieval and learning from experience. While modern Vision-Language-Action (VLA) models can handle diverse robotic tasks, they often incur high per-step inference costs, resulting in significant latency, sometimes minutes per task. In contrast, RT-cache stores a large-scale Memory of previously successful robot trajectories and retrieves relevant multistep motion snippets, drastically reducing inference overhead. By integrating a Memory Builder with a Trajectory Retrieval, we develop an efficient retrieval process that remains tractable even for extremely large datasets. RT-cache flexibly accumulates real-world experiences and replays them whenever the current scene matches past states, adapting quickly to new or unseen environments with only a few additional samples. Experiments on the Open-X Embodiment Dataset and other real-world data demonstrate that RT-cache completes tasks both faster and more successfully than a baseline lacking retrieval, suggesting a practical, data-driven solution for real-time manipulation. 

**Abstract (ZH)**: 基于大规模数据检索与经验学习的RT-cache轨迹记忆pipeline及其在实时机器人推理中的应用 

---
# JcvPCA and JsvCRP : a set of metrics to evaluate changes in joint coordination strategies 

**Title (ZH)**: JcvPCA和JsvCRP：一套评估关节协调策略变化的指标 

**Authors**: Océane Dubois, Agnès Roby-Brami, Ross Parry, Nathanaël Jarrassé  

**Link**: [PDF](https://arxiv.org/pdf/2505.09020)  

**Abstract**: Characterizing changes in inter-joint coordination presents significant challenges, as it necessitates the examination of relationships between multiple degrees of freedom during movements and their temporal evolution. Existing metrics are inadequate in providing physiologically coherent results that document both the temporal and spatial aspects of inter-joint coordination. In this article, we introduce two novel metrics to enhance the analysis of inter-joint coordination. The first metric, Joint Contribution Variation based on Principal Component Analysis (JcvPCA), evaluates the variation in each joint's contribution during series of movements. The second metric, Joint Synchronization Variation based on Continuous Relative Phase (JsvCRP), measures the variation in temporal synchronization among joints between two movement datasets. We begin by presenting each metric and explaining their derivation. We then demonstrate the application of these metrics using simulated and experimental datasets involving identical movement tasks performed with distinct coordination strategies. The results show that these metrics can successfully differentiate between unique coordination strategies, providing meaningful insights into joint collaboration during movement. These metrics hold significant potential for fields such as ergonomics and clinical rehabilitation, where a precise understanding of the evolution of inter-joint coordination strategies is crucial. Potential applications include evaluating the effects of upper limb exoskeletons in industrial settings or monitoring the progress of patients undergoing neurological rehabilitation. 

**Abstract (ZH)**: 基于主成分分析的关节贡献变异度（JcvPCA）和基于连续相对相位的关节同步变异度（JsvCRP）：增强关节协调分析的新方法及其应用 

---
# ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation 

**Title (ZH)**: ChicGrasp: 基于imitation-learning的定制化双爪 gripper 控制方法及其在易损不规则生物产品操作中的应用 

**Authors**: Amirreza Davar, Zhengtong Xu, Siavash Mahmoudi, Pouya Sohrabipour, Chaitanya Pallerla, Yu She, Wan Shou, Philip Crandall, Dongyi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2505.08986)  

**Abstract**: Automated poultry processing lines still rely on humans to lift slippery, easily bruised carcasses onto a shackle conveyor. Deformability, anatomical variance, and strict hygiene rules make conventional suction and scripted motions unreliable. We present ChicGrasp, an end--to--end hardware--software co-design for this task. An independently actuated dual-jaw pneumatic gripper clamps both chicken legs, while a conditional diffusion-policy controller, trained from only 50 multi--view teleoperation demonstrations (RGB + proprioception), plans 5 DoF end--effector motion, which includes jaw commands in one shot. On individually presented raw broiler carcasses, our system achieves a 40.6\% grasp--and--lift success rate and completes the pick to shackle cycle in 38 s, whereas state--of--the--art implicit behaviour cloning (IBC) and LSTM-GMM baselines fail entirely. All CAD, code, and datasets will be open-source. ChicGrasp shows that imitation learning can bridge the gap between rigid hardware and variable bio--products, offering a reproducible benchmark and a public dataset for researchers in agricultural engineering and robot learning. 

**Abstract (ZH)**: ChicGrasp: 一种从硬件到软件的端到端设计用于自动化家禽处理作业的抓取系统 

---
# Multi-step manipulation task and motion planning guided by video demonstration 

**Title (ZH)**: 基于视频演示的多步操作任务和运动规划 

**Authors**: Kateryna Zorina, David Kovar, Mederic Fourmy, Florent Lamiraux, Nicolas Mansard, Justin Carpentier, Josef Sivic, Vladimir Petrik  

**Link**: [PDF](https://arxiv.org/pdf/2505.08949)  

**Abstract**: This work aims to leverage instructional video to solve complex multi-step task-and-motion planning tasks in robotics. Towards this goal, we propose an extension of the well-established Rapidly-Exploring Random Tree (RRT) planner, which simultaneously grows multiple trees around grasp and release states extracted from the guiding video. Our key novelty lies in combining contact states and 3D object poses extracted from the guiding video with a traditional planning algorithm that allows us to solve tasks with sequential dependencies, for example, if an object needs to be placed at a specific location to be grasped later. We also investigate the generalization capabilities of our approach to go beyond the scene depicted in the instructional video. To demonstrate the benefits of the proposed video-guided planning approach, we design a new benchmark with three challenging tasks: (I) 3D re-arrangement of multiple objects between a table and a shelf, (ii) multi-step transfer of an object through a tunnel, and (iii) transferring objects using a tray similar to a waiter transfers dishes. We demonstrate the effectiveness of our planning algorithm on several robots, including the Franka Emika Panda and the KUKA KMR iiwa. For a seamless transfer of the obtained plans to the real robot, we develop a trajectory refinement approach formulated as an optimal control problem (OCP). 

**Abstract (ZH)**: 本研究旨在利用指导性视频解决机器人领域的复杂多步任务和运动规划任务。为此，我们提出了一种对广泛认可的快速扩展随机树（RRT）规划器的扩展，该扩展能够在指导视频中提取的抓取和释放状态周围同时生长多棵树。我们的关键创新在于，将从指导视频中提取的接触状态和3D物体姿态与传统的规划算法相结合，从而能够解决具有序列依赖性的任务，例如，如果物体需要放置在特定位置以便后续抓取。我们还研究了我们方法的一般化能力，使其能够超越指导视频中所示的场景。为了展示所提视频引导规划方法的优势，我们设计了一个包含三个具有挑战性的任务的新基准：（I）多个物体在桌子和架子之间的3D重新排列；（II）通过隧道的多步物体转移；（III）使用类似侍者端盘的方式进行物体转移。我们在包括Franka Emika Panda和KUKA KMR iiwa在内的多个机器人上展示了我们规划算法的有效性。为了无缝地将获得的计划转移到真实机器人上，我们开发了一种轨迹细化方法，将其形式化为最优控制问题（OCP）。 

---
# Parameter-Efficient Fine-Tuning of Vision Foundation Model for Forest Floor Segmentation from UAV Imagery 

**Title (ZH)**: 基于无人机imagery的森林地面分割的参数高效微调视觉基础模型 

**Authors**: Mohammad Wasil, Ahmad Drak, Brennan Penfold, Ludovico Scarton, Maximilian Johenneken, Alexander Asteroth, Sebastian Houben  

**Link**: [PDF](https://arxiv.org/pdf/2505.08932)  

**Abstract**: Unmanned Aerial Vehicles (UAVs) are increasingly used for reforestation and forest monitoring, including seed dispersal in hard-to-reach terrains. However, a detailed understanding of the forest floor remains a challenge due to high natural variability, quickly changing environmental parameters, and ambiguous annotations due to unclear definitions. To address this issue, we adapt the Segment Anything Model (SAM), a vision foundation model with strong generalization capabilities, to segment forest floor objects such as tree stumps, vegetation, and woody debris. To this end, we employ parameter-efficient fine-tuning (PEFT) to fine-tune a small subset of additional model parameters while keeping the original weights fixed. We adjust SAM's mask decoder to generate masks corresponding to our dataset categories, allowing for automatic segmentation without manual prompting. Our results show that the adapter-based PEFT method achieves the highest mean intersection over union (mIoU), while Low-rank Adaptation (LoRA), with fewer parameters, offers a lightweight alternative for resource-constrained UAV platforms. 

**Abstract (ZH)**: 无人 aerial 车辆 (UAVs) 越来越多地被用于植树造林和森林监测，包括在难以到达的地形中进行种子散布。然而，对森林地表的详细理解仍然面临挑战，原因包括高自然变异性、快速变化的环境参数以及由于定义不清而产生的模糊标注。为解决这一问题，我们适应了具有强大泛化能力的 Segment Anything 模型 (SAM)，以分割森林地表对象，如树桩、植被和木质残骸。为此，我们采用参数高效微调 (PEFT) 方法，对少量附加模型参数进行微调，同时固定原始权重。我们调整 SAM 的掩码解码器，使其生成与我们数据集类别对应的掩码，从而实现自动分割而无需手动提示。我们的结果显示，基于适配器的 PEFT 方法取得了最高的平均交并比 (mIoU)，而具有较少参数的低秩适应 (LoRA) 则为资源受限的 UAV 平台提供了轻量级替代方案。 

---
# Real-time Capable Learning-based Visual Tool Pose Correction via Differentiable Simulation 

**Title (ZH)**: 基于可微分仿真学习的实时视觉工具姿态纠正 

**Authors**: Shuyuan Yang, Zonghe Chua  

**Link**: [PDF](https://arxiv.org/pdf/2505.08875)  

**Abstract**: Autonomy in Minimally Invasive Robotic Surgery (MIRS) has the potential to reduce surgeon cognitive and task load, thereby increasing procedural efficiency. However, implementing accurate autonomous control can be difficult due to poor end-effector proprioception, a limitation of their cable-driven mechanisms. Although the robot may have joint encoders for the end-effector pose calculation, various non-idealities make the entire kinematics chain inaccurate. Modern vision-based pose estimation methods lack real-time capability or can be hard to train and generalize. In this work, we demonstrate a real-time capable, vision transformer-based pose estimation approach that is trained using end-to-end differentiable kinematics and rendering in simulation. We demonstrate the potential of this method to correct for noisy pose estimates in simulation, with the longer term goal of verifying the sim-to-real transferability of our approach. 

**Abstract (ZH)**: 最小侵入性机器人手术中的自主性有潜力减少外科医生的认知和任务负担，从而提高手术程序的效率。然而，由于电缆驱动机制导致的末端执行器本体感受差，实现准确的自主控制具有难度。尽管机器人可能具有关节编码器来计算末端执行器的姿态，但由于各种非理想因素，整个运动链可能不准确。现代基于视觉的姿态估计方法缺乏实时能力，或者训练和泛化难度较大。在此项工作中，我们展示了基于视觉变换器的姿态估计方法，该方法通过端到端可微分运动学和仿真渲染进行训练，具备实时能力。我们证明了该方法在仿真中能够纠正嘈杂的姿态估计，并且长期目标是验证我们方法的仿真实用性。 

---
# Efficiently Manipulating Clutter via Learning and Search-Based Reasoning 

**Title (ZH)**: 通过学习与基于搜索的推理高效操作杂乱环境 

**Authors**: Baichuan Huang  

**Link**: [PDF](https://arxiv.org/pdf/2505.08853)  

**Abstract**: This thesis presents novel algorithms to advance robotic object rearrangement, a critical task for autonomous systems in applications like warehouse automation and household assistance. Addressing challenges of high-dimensional planning, complex object interactions, and computational demands, our work integrates deep learning for interaction prediction, tree search for action sequencing, and parallelized computation for efficiency. Key contributions include the Deep Interaction Prediction Network (DIPN) for accurate push motion forecasting (over 90% accuracy), its synergistic integration with Monte Carlo Tree Search (MCTS) for effective non-prehensile object retrieval (100% completion in specific challenging scenarios), and the Parallel MCTS with Batched Simulations (PMBS) framework, which achieves substantial planning speed-up while maintaining or improving solution quality. The research further explores combining diverse manipulation primitives, validated extensively through simulated and real-world experiments. 

**Abstract (ZH)**: 本论文提出了一种新的算法以推进机器人物体重排任务，这是自主系统在仓储自动化和家庭辅助应用中的关键任务。该工作通过结合深度学习进行交互预测、树搜索进行动作序列规划以及并行计算来解决高维规划、复杂物体交互和计算需求等挑战。关键贡献包括深度交互预测网络（DIPN）用于准确的推动作预测（准确率超过90%）、与蒙特卡洛树搜索（MCTS）的协同集成以高效实现非抓握物体的检索（在特定挑战性场景中100%完成）、以及并行蒙特卡洛树搜索批量模拟框架（PMBS），该框架在保持或提高解的质量的同时显著提高了规划速度。进一步研究结合了多种操作基本操作，并通过广泛的模拟和实际实验得到了验证。 

---
# Streaming Multi-agent Pathfinding 

**Title (ZH)**: 流式多代理路径规划 

**Authors**: Mingkai Tang, Lu Gan, Kaichen Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2505.09472)  

**Abstract**: The task of the multi-agent pathfinding (MAPF) problem is to navigate a team of agents from their start point to the goal points. However, this setup is unsuitable in the assembly line scenario, which is periodic with a long working hour. To address this issue, the study formalizes the streaming MAPF (S-MAPF) problem, which assumes that the agents in the same agent stream have a periodic start time and share the same action sequence. The proposed solution, Agent Stream Conflict-Based Search (ASCBS), is designed to tackle this problem by incorporating a cyclic vertex/edge constraint to handle conflicts. Additionally, this work explores the potential usage of the disjoint splitting strategy within ASCBS. Experimental results indicate that ASCBS surpasses traditional MAPF solvers in terms of runtime for scenarios with prolonged working hours. 

**Abstract (ZH)**: 基于流的多-agent路径规划问题（Streaming MAPF）及其解决策略（Agent Stream Conflict-Based Search, ASCBS）研究 

---
# SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation 

**Title (ZH)**: SafePath: 依从性预测用于安全的LLM基于自主导航 

**Authors**: Achref Doula, Max Mühläuser, Alejandro Sanchez Guinea  

**Link**: [PDF](https://arxiv.org/pdf/2505.09427)  

**Abstract**: Large Language Models (LLMs) show growing promise in autonomous driving by reasoning over complex traffic scenarios to generate path plans. However, their tendencies toward overconfidence, and hallucinations raise critical safety concerns. We introduce SafePath, a modular framework that augments LLM-based path planning with formal safety guarantees using conformal prediction. SafePath operates in three stages. In the first stage, we use an LLM that generates a set of diverse candidate paths, exploring possible trajectories based on agent behaviors and environmental cues. In the second stage, SafePath filters out high-risk trajectories while guaranteeing that at least one safe option is included with a user-defined probability, through a multiple-choice question-answering formulation that integrates conformal prediction. In the final stage, our approach selects the path with the lowest expected collision risk when uncertainty is low or delegates control to a human when uncertainty is high. We theoretically prove that SafePath guarantees a safe trajectory with a user-defined probability, and we show how its human delegation rate can be tuned to balance autonomy and safety. Extensive experiments on nuScenes and Highway-env show that SafePath reduces planning uncertainty by 77\% and collision rates by up to 70\%, demonstrating effectiveness in making LLM-driven path planning more safer. 

**Abstract (ZH)**: SafePath：使用符合预测增强的LLM路径规划的正式安全保证 

---
# Ethical Aspects of the Use of Social Robots in Elderly Care -- A Systematic Qualitative Review 

**Title (ZH)**: 社交机器人在老年照护中使用方面的伦理问题——一项系统性定性综述 

**Authors**: Marianne Leineweber, Clara Victoria Keusgen, Marc Bubeck, Joschka Haltaufderheide, Robert Ranisch, Corinna Klingler  

**Link**: [PDF](https://arxiv.org/pdf/2505.09224)  

**Abstract**: Background: The use of social robotics in elderly care is increasingly discussed as one way of meeting emerging care needs due to scarce resources. While many potential benefits are associated with robotic care technologies, there is a variety of ethical challenges. To support steps towards a responsible implementation and use, this review develops an overview on ethical aspects of the use of social robots in elderly care from a decision-makers' perspective.
Methods: Electronic databases were queried using a comprehensive search strategy based on the key concepts of "ethical aspects", "social robotics" and "elderly care". Abstract and title screening was conducted by two authors independently. Full-text screening was conducted by one author following a joint consolidation phase. Data was extracted using MAXQDA24 by one author, based on a consolidated coding framework. Analysis was performed through modified qualitative content analysis.
Results: A total of 1,518 publications were screened, and 248 publications were included. We have organized our analysis in a scheme of ethical hazards, ethical opportunities and unsettled questions, identifying at least 60 broad ethical aspects affecting three different stakeholder groups. While some ethical issues are well-known and broadly discussed our analysis shows a plethora of potentially relevant aspects, often only marginally recognized, that are worthy of consideration from a practical perspective.
Discussion: The findings highlight the need for a contextual and detailed evaluation of implementation scenarios. To make use of the vast knowledge of the ethical discourse, we hypothesize that decision-makers need to understand the specific nature of this discourse to be able to engage in careful ethical deliberation. 

**Abstract (ZH)**: 背景：随着资源稀缺，将社会机器人应用于老年人护理以应对不断变化的护理需求而受到越来越多的关注。尽管机器人护理技术有许多潜在益处，但也存在多种伦理挑战。为了支持伦理责任的实施和使用，本评论从决策者角度提出了社会机器人在老年人护理中应用的伦理方面的综述。 

---
# OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions 

**Title (ZH)**: OpenLKA: 现代汽车车型在实际驾驶条件下的一种车道保持辅助数据集 

**Authors**: Yuhang Wang, Abdulaziz Alhuraish, Shengming Yuan, Hao Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2505.09092)  

**Abstract**: Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its real-world performance remains underexplored due to proprietary systems and limited data access. This paper presents OpenLKA, the first open, large-scale dataset for LKA evaluation and improvement. It includes 400 hours of driving data from 50+ production vehicle models, collected through extensive road testing in Tampa, Florida and global contributions from the this http URL driving community. The dataset spans a wide range of challenging scenarios, including complex road geometries, degraded lane markings, adverse weather, lighting conditions and surrounding traffic. The dataset is multimodal, comprising: i) full CAN bus streams, decoded using custom reverse-engineered DBC files to extract key LKA events (e.g., system disengagements, lane detection failures); ii) synchronized high-resolution dash-cam video; iii) real-time outputs from Openpilot, providing accurate estimates of road curvature and lane positioning; iv) enhanced scene annotations generated by Vision Language Models, describing lane visibility, pavement quality, weather, lighting, and traffic conditions. By integrating vehicle-internal signals with high-fidelity perception and rich semantic context, OpenLKA provides a comprehensive platform for benchmarking the real-world performance of production LKA systems, identifying safety-critical operational scenarios, and assessing the readiness of current road infrastructure for autonomous driving. The dataset is publicly available at: this https URL. 

**Abstract (ZH)**: 开放路径保持辅助（OpenLKA）：首个开放的大规模路径保持辅助数据集 

---
# Solving Reach- and Stabilize-Avoid Problems Using Discounted Reachability 

**Title (ZH)**: 使用折扣可达性求解可达和稳定避免问题 

**Authors**: Boyang Li, Zheng Gong, Sylvia Herbert  

**Link**: [PDF](https://arxiv.org/pdf/2505.09067)  

**Abstract**: In this article, we consider the infinite-horizon reach-avoid (RA) and stabilize-avoid (SA) zero-sum game problems for general nonlinear continuous-time systems, where the goal is to find the set of states that can be controlled to reach or stabilize to a target set, without violating constraints even under the worst-case disturbance. Based on the Hamilton-Jacobi reachability method, we address the RA problem by designing a new Lipschitz continuous RA value function, whose zero sublevel set exactly characterizes the RA set. We establish that the associated Bellman backup operator is contractive and that the RA value function is the unique viscosity solution of a Hamilton-Jacobi variational inequality. Finally, we develop a two-step framework for the SA problem by integrating our RA strategies with a recently proposed Robust Control Lyapunov-Value Function, thereby ensuring both target reachability and long-term stability. We numerically verify our RA and SA frameworks on a 3D Dubins car system to demonstrate the efficacy of the proposed approach. 

**Abstract (ZH)**: 本文考虑了一般非线性连续系统在无限 horizon 下的reach-avoid (RA) 和 stabilize-avoid (SA) 零和博弈问题，目标是在最坏扰动情况下，找到可以控制到达或稳定在目标集的状态集，而不违反约束条件。基于哈密尔敦-雅可比可达性方法，我们通过设计一个新的Lipschitz连续RA值函数，解决RA问题，该值函数的零次亚水平集精确地表征了RA集。我们证明了相应的贝尔曼备份算子收敛，并且RA值函数是哈密尔敦-雅可比变分不等式的唯一拟解。最后，我们通过整合提出的RA策略和最近提出的鲁棒控制Lyapunov-值函数，开发了SA问题的两步框架，从而确保目标可达性和长期稳定性。我们通过一个3D Dubins车系统数值验证了RA和SA框架的有效性。 

---
# Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning 

**Title (ZH)**: 通过分层多agent reinforcement learning提升空战战术 

**Authors**: Ardian Selmonaj, Oleg Szehr, Giacomo Del Rio, Alessandro Antonucci, Adrian Schneider, Michael Rüegsegger  

**Link**: [PDF](https://arxiv.org/pdf/2505.08995)  

**Abstract**: This work presents a Hierarchical Multi-Agent Reinforcement Learning framework for analyzing simulated air combat scenarios involving heterogeneous agents. The objective is to identify effective Courses of Action that lead to mission success within preset simulations, thereby enabling the exploration of real-world defense scenarios at low cost and in a safe-to-fail setting. Applying deep Reinforcement Learning in this context poses specific challenges, such as complex flight dynamics, the exponential size of the state and action spaces in multi-agent systems, and the capability to integrate real-time control of individual units with look-ahead planning. To address these challenges, the decision-making process is split into two levels of abstraction: low-level policies control individual units, while a high-level commander policy issues macro commands aligned with the overall mission targets. This hierarchical structure facilitates the training process by exploiting policy symmetries of individual agents and by separating control from command tasks. The low-level policies are trained for individual combat control in a curriculum of increasing complexity. The high-level commander is then trained on mission targets given pre-trained control policies. The empirical validation confirms the advantages of the proposed framework. 

**Abstract (ZH)**: 基于层次多agent强化学习的异质代理模拟空战场景分析框架 

---
# Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections 

**Title (ZH)**: 基于深度强化学习的信号交叉口自动驾驶车辆纵向控制策略 

**Authors**: Pankaj Kumar, Aditya Mishra, Pranamesh Chakraborty, Subrahmanya Swamy Peruru  

**Link**: [PDF](https://arxiv.org/pdf/2505.08896)  

**Abstract**: Developing an autonomous vehicle control strategy for signalised intersections (SI) is one of the challenging tasks due to its inherently complex decision-making process. This study proposes a Deep Reinforcement Learning (DRL) based longitudinal vehicle control strategy at SI. A comprehensive reward function has been formulated with a particular focus on (i) distance headway-based efficiency reward, (ii) decision-making criteria during amber light, and (iii) asymmetric acceleration/ deceleration response, along with the traditional safety and comfort criteria. This reward function has been incorporated with two popular DRL algorithms, Deep Deterministic Policy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the continuous action space of acceleration/deceleration. The proposed models have been trained on the combination of real-world leader vehicle (LV) trajectories and simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process. The overall performance of the proposed models has been tested using Cumulative Distribution Function (CDF) plots and compared with the real-world trajectory data. The results show that the RL models successfully maintain lower distance headway (i.e., higher efficiency) and jerk compared to human-driven vehicles without compromising safety. Further, to assess the robustness of the proposed models, we evaluated the model performance on diverse safety-critical scenarios, in terms of car-following and traffic signal compliance. Both DDPG and SAC models successfully handled the critical scenarios, while the DDPG model showed smoother action profiles compared to the SAC model. Overall, the results confirm that DRL-based longitudinal vehicle control strategy at SI can help to improve traffic safety, efficiency, and comfort. 

**Abstract (ZH)**: 基于深度强化学习的信号交叉口自主车辆纵向控制策略开发 

---
# Generative AI for Autonomous Driving: Frontiers and Opportunities 

**Title (ZH)**: 自主驾驶中的生成式AI：前沿与机遇 

**Authors**: Yuping Wang, Shuo Xing, Cui Can, Renjie Li, Hongyuan Hua, Kexin Tian, Zhaobin Mo, Xiangbo Gao, Keshu Wu, Sulong Zhou, Hengxu You, Juntong Peng, Junge Zhang, Zehao Wang, Rui Song, Mingxuan Yan, Walter Zimmer, Xingcheng Zhou, Peiran Li, Zhaohan Lu, Chia-Ju Chen, Yue Huang, Ryan A. Rossi, Lichao Sun, Hongkai Yu, Zhiwen Fan, Frank Hao Yang, Yuhao Kang, Ross Greer, Chenxi Liu, Eun Hak Lee, Xuan Di, Xinyue Ye, Liu Ren, Alois Knoll, Xiaopeng Li, Shuiwang Ji, Masayoshi Tomizuka, Marco Pavone, Tianbao Yang, Jing Du, Ming-Hsuan Yang, Hua Wei, Ziran Wang, Yang Zhou, Jiachen Li, Zhengzhong Tu  

**Link**: [PDF](https://arxiv.org/pdf/2505.08854)  

**Abstract**: Generative Artificial Intelligence (GenAI) constitutes a transformative technological wave that reconfigures industries through its unparalleled capabilities for content creation, reasoning, planning, and multimodal understanding. This revolutionary force offers the most promising path yet toward solving one of engineering's grandest challenges: achieving reliable, fully autonomous driving, particularly the pursuit of Level 5 autonomy. This survey delivers a comprehensive and critical synthesis of the emerging role of GenAI across the autonomous driving stack. We begin by distilling the principles and trade-offs of modern generative modeling, encompassing VAEs, GANs, Diffusion Models, and Large Language Models (LLMs). We then map their frontier applications in image, LiDAR, trajectory, occupancy, video generation as well as LLM-guided reasoning and decision making. We categorize practical applications, such as synthetic data workflows, end-to-end driving strategies, high-fidelity digital twin systems, smart transportation networks, and cross-domain transfer to embodied AI. We identify key obstacles and possibilities such as comprehensive generalization across rare cases, evaluation and safety checks, budget-limited implementation, regulatory compliance, ethical concerns, and environmental effects, while proposing research plans across theoretical assurances, trust metrics, transport integration, and socio-technical influence. By unifying these threads, the survey provides a forward-looking reference for researchers, engineers, and policymakers navigating the convergence of generative AI and advanced autonomous mobility. An actively maintained repository of cited works is available at this https URL. 

**Abstract (ZH)**: 生成式人工智能（GenAI）构成了一个变革性的技术浪潮，通过其无与伦比的内容创造、推理、规划和多模态理解能力重塑各行各业。这一革命性力量为解决工程领域的最大挑战之一——实现可靠、完全自动的驾驶，特别是L5级自主驾驶，提供了最有希望的途径。本文综述了生成式人工智能在自主驾驶堆栈中的新兴作用。我们首先提炼现代生成建模的原则和权衡，涵盖VAEs、GANs、扩散模型和大规模语言模型（LLMs）。然后，我们将其前沿应用映射到图像、LiDAR、轨迹、占用率、视频生成以及大规模语言模型引导的推理和决策。我们将实际应用分类为合成数据流程、端到端驾驶策略、高保真数字孪生系统、智能交通网络以及跨域转移至具身AI。我们识别了关键障碍和可能性，如跨罕见案例的全面泛化、评估和安全检查、预算限制下的实施、合规性、伦理关切和环境影响，并提出了理论保证、信任度量、运输集成和社会技术影响方面的研究计划。通过统一这些主题，本文综述为研究人员、工程师和政策制定者在生成式人工智能和先进自主移动的交汇点导航提供了一个前瞻性的参考。在本文https网址中为引用的作品维护了一个活跃更新的资源库。 

---
# TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian 

**Title (ZH)**: TUGS: 基于物理的 underwater 场景张量化高斯紧凑表示 

**Authors**: Shijie Lian, Ziyi Zhang, Laurence Tianruo Yang and, Mengyu Ren, Debin Liu, Hua Li  

**Link**: [PDF](https://arxiv.org/pdf/2505.08811)  

**Abstract**: Underwater 3D scene reconstruction is crucial for undewater robotic perception and navigation. However, the task is significantly challenged by the complex interplay between light propagation, water medium, and object surfaces, with existing methods unable to model their interactions accurately. Additionally, expensive training and rendering costs limit their practical application in underwater robotic systems. Therefore, we propose Tensorized Underwater Gaussian Splatting (TUGS), which can effectively solve the modeling challenges of the complex interactions between object geometries and water media while achieving significant parameter reduction. TUGS employs lightweight tensorized higher-order Gaussians with a physics-based underwater Adaptive Medium Estimation (AME) module, enabling accurate simulation of both light attenuation and backscatter effects in underwater environments. Compared to other NeRF-based and GS-based methods designed for underwater, TUGS is able to render high-quality underwater images with faster rendering speeds and less memory usage. Extensive experiments on real-world underwater datasets have demonstrated that TUGS can efficiently achieve superior reconstruction quality using a limited number of parameters, making it particularly suitable for memory-constrained underwater UAV applications 

**Abstract (ZH)**: 水下3D场景重建对于水下机器人感知和导航至关重要。然而，任务受到光线传播、水中介质和物体表面之间复杂相互作用的显著挑战，现有方法难以准确建模这些交互作用。此外，高昂的训练和渲染成本限制了其在水下机器人系统中的实际应用。因此，我们提出了张量水下高斯点云表示（Tensorized Underwater Gaussian Splatting，TUGS），它可以有效解决物体几何与水介质之间复杂交互的建模挑战，同时实现显著的参数减少。TUGS 使用基于物理的水下自适应介质估计（AME）模块和轻量级张量高阶高斯函数，能够准确模拟水下环境中的光线衰减和后向散射效应。与为水下设计的其他基于NeRF和GS的方法相比，TUGS 能以更快的渲染速度和更少的内存使用渲染高质量的水下图像。在真实世界水下数据集上的大量实验表明，TUGS 能够使用有限的参数高效地实现卓越的重建质量，使其特别适合于内存受限的水下无人机应用。 

---
