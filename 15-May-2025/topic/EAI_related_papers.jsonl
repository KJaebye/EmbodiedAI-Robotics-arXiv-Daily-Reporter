{'arxiv_id': 'arXiv:2505.09603', 'title': 'DataMIL: Selecting Data for Robot Imitation Learning with Datamodels', 'authors': 'Shivin Dass, Alaa Khaddaj, Logan Engstrom, Aleksander Madry, Andrew Ilyas, Roberto Martín-Martín', 'link': 'https://arxiv.org/abs/2505.09603', 'abstract': 'Recently, the robotics community has amassed ever larger and more diverse datasets to train generalist robot policies. However, while these policies achieve strong mean performance across a variety of tasks, they often underperform on individual, specialized tasks and require further tuning on newly acquired task-specific data. Combining task-specific data with carefully curated subsets of large prior datasets via co-training can produce better specialized policies, but selecting data naively may actually harm downstream performance. To address this, we introduce DataMIL, a policy-driven data selection framework built on the datamodels paradigm that reasons about data selection in an end-to-end manner, using the policy itself to identify which data points will most improve performance. Unlike standard practices that filter data using human notions of quality (e.g., based on semantic or visual similarity), DataMIL directly optimizes data selection for task success, allowing us to select data that enhance the policy while dropping data that degrade it. To avoid performing expensive rollouts in the environment during selection, we use a novel surrogate loss function on task-specific data, allowing us to use DataMIL in the real world without degrading performance. We validate our approach on a suite of more than 60 simulation and real-world manipulation tasks - most notably showing successful data selection from the Open X-Embodiment datasets-demonstrating consistent gains in success rates and superior performance over multiple baselines. Our results underscore the importance of end-to-end, performance-aware data selection for unlocking the potential of large prior datasets in robotics. More information at this https URL', 'abstract_zh': '最近，机器人学社区积累了越来越多且多样化的数据集来训练通用机器人策略。然而，虽然这些策略在多种任务上实现了较强的平均性能，但在个别专业化任务上往往表现不佳，并需要在新获取的任务特定数据上进一步调优。将任务特定数据与大型先有数据集中的精心筛选子集结合使用可以产生更好的专业化策略，但盲目选择数据实际上可能会损害下游性能。为了解决这个问题，我们引入了DataMIL，这是一种基于datamodels范式的策略驱动数据选择框架，能够端到端地推理数据选择，并使用策略本身来识别最能提升性能的数据点。与使用人类对质量的标准认知（例如基于语义或视觉相似性）筛选数据的传统方法不同，DataMIL 直接优化数据选择以实现任务成功，使我们能够选择增强策略的数据并丢弃损害策略的数据。为了在选择数据时避免在环境中进行昂贵的仿真，我们在任务特定数据上使用了一种新颖的代理损失函数，从而能够在不降低性能的情况下将DataMIL应用于现实世界。我们在超过60个仿真和实际操作任务套件上验证了我们的方法——尤其展示了从Open X-Embodiment数据集中成功选择数据的显著成效，展示了在多个基线方法上一致的性能提升。我们的结果强调了在机器人中实现大型先有数据集潜力时端到端、性能感知数据选择的重要性。更多信息请访问：this https URL', 'title_zh': 'DataMIL: 使用数据模型选择用于机器人模仿学习的数据'}
{'arxiv_id': 'arXiv:2505.09601', 'title': 'Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware', 'authors': 'Justin Yu, Letian Fu, Huang Huang, Karim El-Refai, Rares Andrei Ambrus, Richard Cheng, Muhammad Zubair Irshad, Ken Goldberg', 'link': 'https://arxiv.org/abs/2505.09601', 'abstract': 'Scaling robot learning requires vast and diverse datasets. Yet the prevailing data collection paradigm-human teleoperation-remains costly and constrained by manual effort and physical robot access. We introduce Real2Render2Real (R2R2R), a novel approach for generating robot training data without relying on object dynamics simulation or teleoperation of robot hardware. The input is a smartphone-captured scan of one or more objects and a single video of a human demonstration. R2R2R renders thousands of high visual fidelity robot-agnostic demonstrations by reconstructing detailed 3D object geometry and appearance, and tracking 6-DoF object motion. R2R2R uses 3D Gaussian Splatting (3DGS) to enable flexible asset generation and trajectory synthesis for both rigid and articulated objects, converting these representations to meshes to maintain compatibility with scalable rendering engines like IsaacLab but with collision modeling off. Robot demonstration data generated by R2R2R integrates directly with models that operate on robot proprioceptive states and image observations, such as vision-language-action models (VLA) and imitation learning policies. Physical experiments suggest that models trained on R2R2R data from a single human demonstration can match the performance of models trained on 150 human teleoperation demonstrations. Project page: this https URL', 'abstract_zh': '无物体动力学模拟且无需机器人硬件远程操作的生成机器人训练数据方法：Real2Render2Real', 'title_zh': 'Real2Render2Real: 扩展机器人数据而不依赖动力学仿真或机器人硬件'}
{'arxiv_id': 'arXiv:2505.09577', 'title': 'VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation', 'authors': 'Chaofan Zhang, Peng Hao, Xiaoge Cao, Xiaoshuai Hao, Shaowei Cui, Shuo Wang', 'link': 'https://arxiv.org/abs/2505.09577', 'abstract': 'While vision-language models have advanced significantly, their application in language-conditioned robotic manipulation is still underexplored, especially for contact-rich tasks that extend beyond visually dominant pick-and-place scenarios. To bridge this gap, we introduce Vision-Tactile-Language-Action model, a novel framework that enables robust policy generation in contact-intensive scenarios by effectively integrating visual and tactile inputs through cross-modal language grounding. A low-cost, multi-modal dataset has been constructed in a simulation environment, containing vision-tactile-action-instruction pairs specifically designed for the fingertip insertion task. Furthermore, we introduce Direct Preference Optimization (DPO) to offer regression-like supervision for the VTLA model, effectively bridging the gap between classification-based next token prediction loss and continuous robotic tasks. Experimental results show that the VTLA model outperforms traditional imitation learning methods (e.g., diffusion policies) and existing multi-modal baselines (TLA/VLA), achieving over 90% success rates on unseen peg shapes. Finally, we conduct real-world peg-in-hole experiments to demonstrate the exceptional Sim2Real performance of the proposed VTLA model. For supplementary videos and results, please visit our project website: this https URL', 'abstract_zh': '视觉-触觉-语言-动作模型：一种通过跨模态语言接地有效整合视觉和触觉输入以生成鲁棒策略的新框架', 'title_zh': 'VTLA：带有偏好学习的视觉-触觉-语言-动作模型及其在插入 manipulation 中的应用'}
{'arxiv_id': 'arXiv:2505.09546', 'title': 'Distilling Realizable Students from Unrealizable Teachers', 'authors': 'Yujin Kim, Nathaniel Chin, Arnav Vasudev, Sanjiban Choudhury', 'link': 'https://arxiv.org/abs/2505.09546', 'abstract': "We study policy distillation under privileged information, where a student policy with only partial observations must learn from a teacher with full-state access. A key challenge is information asymmetry: the student cannot directly access the teacher's state space, leading to distributional shifts and policy degradation. Existing approaches either modify the teacher to produce realizable but sub-optimal demonstrations or rely on the student to explore missing information independently, both of which are inefficient. Our key insight is that the student should strategically interact with the teacher --querying only when necessary and resetting from recovery states --to stay on a recoverable path within its own observation space. We introduce two methods: (i) an imitation learning approach that adaptively determines when the student should query the teacher for corrections, and (ii) a reinforcement learning approach that selects where to initialize training for efficient exploration. We validate our methods in both simulated and real-world robotic tasks, demonstrating significant improvements over standard teacher-student baselines in training efficiency and final performance. The project website is available at : this https URL", 'abstract_zh': '我们在特权信息下的策略蒸馏研究中，探讨了一种学生策略仅通过部分观测从具有全状态访问权的教师处学习的方法。关键挑战在于信息不对称：学生无法直接访问教师的状态空间，导致分布偏移和策略退化。现有方法要么修改教师以产生可实现但非最优的演示，要么依赖学生独立探索缺失信息，这两种方法都效率低下。我们的核心洞察是，学生应该有策略地与教师交互——仅在必要时查询教师并在恢复状态下重置——以在其自身观测空间内保持可恢复路径。我们提出两种方法：(i) 一种自适应的模仿学习方法，确定学生何时需要查询教师以获得纠正；(ii) 一种强化学习方法，选择初始化训练的位置以实现高效探索。我们在模拟和真实世界机器人任务中验证了这些方法，显示出在训练效率和最终性能方面相对于标准教师-学生基线的显著改进。项目网站详见：这个链接。', 'title_zh': '从非实现性教师中提炼实现性学生'}
{'arxiv_id': 'arXiv:2505.09477', 'title': 'Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities', 'authors': 'Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar', 'link': 'https://arxiv.org/abs/2505.09477', 'abstract': 'The integration of foundation models (FMs) into robotics has enabled robots to understand natural language and reason about the semantics in their environments. However, existing FM-enabled robots primary operate in closed-world settings, where the robot is given a full prior map or has a full view of its workspace. This paper addresses the deployment of FM-enabled robots in the field, where missions often require a robot to operate in large-scale and unstructured environments. To effectively accomplish these missions, robots must actively explore their environments, navigate obstacle-cluttered terrain, handle unexpected sensor inputs, and operate with compute constraints. We discuss recent deployments of SPINE, our LLM-enabled autonomy framework, in field robotic settings. To the best of our knowledge, we present the first demonstration of large-scale LLM-enabled robot planning in unstructured environments with several kilometers of missions. SPINE is agnostic to a particular LLM, which allows us to distill small language models capable of running onboard size, weight and power (SWaP) limited platforms. Via preliminary model distillation work, we then present the first language-driven UAV planner using on-device language models. We conclude our paper by proposing several promising directions for future research.', 'abstract_zh': 'Foundation Models驱动的机器人在田野环境中规模化部署与规划研究', 'title_zh': '基于基础模型的空中和地面机器人现场部署：挑战与机遇'}
{'arxiv_id': 'arXiv:2505.09424', 'title': 'Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion', 'authors': 'Han Sun, Yizhao Wang, Zhenning Zhou, Shuai Wang, Haibo Yang, Jingyuan Sun, Qixin Cao', 'link': 'https://arxiv.org/abs/2505.09424', 'abstract': 'Recent studies have proved that imitation learning shows strong potential in the field of robotic manipulation. However, existing methods still struggle with precision manipulation task and rely on inefficient image/point cloud observations. In this paper, we explore to introduce SE(3) object pose into imitation learning and propose the pose-guided efficient imitation learning methods for robotic precise insertion task. First, we propose a precise insertion diffusion policy which utilizes the relative SE(3) pose as the observation-action pair. The policy models the source object SE(3) pose trajectory relative to the target object. Second, we explore to introduce the RGBD data to the pose-guided diffusion policy. Specifically, we design a goal-conditioned RGBD encoder to capture the discrepancy between the current state and the goal state. In addition, a pose-guided residual gated fusion method is proposed, which takes pose features as the backbone, and the RGBD features selectively compensate for pose feature deficiencies through an adaptive gating mechanism. Our methods are evaluated on 6 robotic precise insertion tasks, demonstrating competitive performance with only 7-10 demonstrations. Experiments demonstrate that the proposed methods can successfully complete precision insertion tasks with a clearance of about 0.01 mm. Experimental results highlight its superior efficiency and generalization capability compared to existing baselines. Code will be available at this https URL.', 'abstract_zh': '近期研究表明，模仿学习在机器人操作领域展现出强大潜力。然而，现有方法在精确操作任务上仍面临挑战，并且依赖于低效的图像/点云观测。本文探索将SE(3)物体姿态引入模仿学习，并提出一种姿态导向的高效模仿学习方法，用于机器人精确插入任务。首先，我们提出了一种精确插入扩散策略，利用相对SE(3)姿态作为观测-动作对。该策略模型了源物体相对于目标物体的SE(3)姿态轨迹。其次，我们探索将RGBD数据引入姿态导向扩散策略中。具体来说，我们设计了一种目标条件的RGBD编码器以捕捉当前状态与目标状态之间的差异。此外，提出了一种姿态导向的残差门控融合方法，该方法以姿态特征作为骨干，并通过自适应门控机制选择性地补充姿态特征的不足。我们在6个机器人精确插入任务上评估了我们的方法，演示了仅需7-10个演示即可达到竞争力的性能。实验表明，所提出的方法可以成功完成清除精度约为0.01 mm的精确插入任务。实验结果突显了其相比现有基线的优越高效性和泛化能力。代码将在此链接处提供。', 'title_zh': '探索基于姿态引导的模仿学习在机器人精确插入任务中的应用'}
{'arxiv_id': 'arXiv:2505.09315', 'title': 'TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving', 'authors': 'Xuefeng Jiang, Yuan Ma, Pengxiang Li, Leimeng Xu, Xin Wen, Kun Zhan, Zhongpu Xia, Peng Jia, XianPeng Lang, Sheng Sun', 'link': 'https://arxiv.org/abs/2505.09315', 'abstract': 'In recent years, diffusion model has shown its potential across diverse domains from vision generation to language modeling. Transferring its capabilities to modern autonomous driving systems has also emerged as a promising this http URL this work, we propose TransDiffuser, an encoder-decoder based generative trajectory planning model for end-to-end autonomous driving. The encoded scene information serves as the multi-modal conditional input of the denoising decoder. To tackle the mode collapse dilemma in generating high-quality diverse trajectories, we introduce a simple yet effective multi-modal representation decorrelation optimization mechanism during the training this http URL achieves PDMS of 94.85 on the NAVSIM benchmark, surpassing previous state-of-the-art methods without any anchor-based prior trajectories.', 'abstract_zh': '近年来，扩散模型在视觉生成和语言模型等领域展现出了潜在应用价值。将其能力应用到现代自主驾驶系统中也成为了一个有前景的方向。在本文中，我们提出了一种基于编码-解码结构的生成性轨迹规划模型TransDiffuser，用于端到端的自主驾驶。编码场景信息作为去噪解码器的多模态条件输入。为了应对生成高质量多样化轨迹时遇到的模态崩溃问题，在训练过程中引入了一种简单有效的多模态表示去相关优化机制。该模型在NAVSIM基准测试中达到了94.85的PDMS性能，超越了之前的最先进的方法，无需依赖基于锚点的先验轨迹。', 'title_zh': 'TransDiffuser: 集成去相关多模态表示的端到端轨迹生成方法及其在自主驾驶中的应用'}
{'arxiv_id': 'arXiv:2505.09305', 'title': 'Embodied Intelligent Industrial Robotics: Concepts and Techniques', 'authors': 'Chaoran Zhang, Chenhao Zhang, Zhaobo Xu, Qinghongbing Xie, Pingfa Feng, Long Zeng', 'link': 'https://arxiv.org/abs/2505.09305', 'abstract': 'In recent years, embodied intelligent robotics (EIR) has made significant progress in multi-modal perception, autonomous decision-making, and physical interaction. Some robots have already been tested in general-purpose scenarios such as homes and shopping malls. We aim to advance the research and application of embodied intelligence in industrial scenes. However, current EIR lacks a deep understanding of industrial environment semantics and the normative constraints between industrial operating objects. To address this gap, this paper first reviews the history of industrial robotics and the mainstream EIR frameworks. We then introduce the concept of the embodied intelligent industrial robotics (EIIR) and propose a knowledge-driven EIIR technology framework for industrial environments. The framework includes four main modules: world model, high-level task planner, low-level skill controller, and simulator. We also review the current development of technologies related to each module and highlight recent progress in adapting them to industrial applications. Finally, we summarize the key challenges EIIR faces in industrial scenarios and suggest future research directions. We believe that EIIR technology will shape the next generation of industrial robotics. Industrial systems based on embodied intelligent industrial robots offer strong potential for enabling intelligent manufacturing. We will continue to track and summarize new research in this area and hope this review will serve as a valuable reference for scholars and engineers interested in industrial embodied intelligence. Together, we can help drive the rapid advancement and application of this technology. The associated project can be found at this https URL.', 'abstract_zh': '近年来，具身智能机器人（EIR）在多模态感知、自主决策和物理交互方面取得了显著进展。一些机器人已经在家庭和购物中心等通用场景中进行了测试。我们旨在推动具身智能在工业场景中的研究和应用。然而，当前的EIR缺乏对工业环境语义及其工业操作对象间规范性约束的深刻理解。为填补这一空白，本文首先回顾了工业机器人发展史和主流EIR框架。然后介绍了具身智能工业机器人（EIIR）的概念，并提出了一种面向工业环境的知识驱动EIIR技术框架。该框架包含四个主要模块：世界模型、高层任务规划器、低层技能控制器和模拟器。我们还回顾了每个模块相关技术的当前发展状况，并强调了它们在工业应用中适应性改进的最新进展。最后，我们总结了EIIR在工业场景中面临的关键挑战，并提出了未来的研究方向。我们认为，EIIR技术将塑造下一代工业机器人。基于具身智能工业机器人的工业系统具有实现智能制造的强大潜力。我们将继续跟踪和总结该领域的最新研究，并希望本文评述能为从事工业具身智能研究的学者和工程师提供有价值的参考。大家一起可以推动这项技术的快速发展和应用。相关项目可在以下链接找到：this https URL。', 'title_zh': '身体化智能工业机器人：概念与技术'}
{'arxiv_id': 'arXiv:2505.09144', 'title': 'Latent Theory of Mind: A Decentralized Diffusion Architecture for Cooperative Manipulation', 'authors': 'Chengyang He, Gadiel Sznaier Camps, Xu Liu, Mac Schwager, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2505.09144', 'abstract': "We present Latent Theory of Mind (LatentToM), a decentralized diffusion policy architecture for collaborative robot manipulation. Our policy allows multiple manipulators with their own perception and computation to collaborate with each other towards a common task goal with or without explicit communication. Our key innovation lies in allowing each agent to maintain two latent representations: an ego embedding specific to the robot, and a consensus embedding trained to be common to both robots, despite their different sensor streams and poses. We further let each robot train a decoder to infer the other robot's ego embedding from their consensus embedding, akin to theory of mind in latent space. Training occurs centrally, with all the policies' consensus encoders supervised by a loss inspired by sheaf theory, a mathematical theory for clustering data on a topological manifold. Specifically, we introduce a first-order cohomology loss to enforce sheaf-consistent alignment of the consensus embeddings. To preserve the expressiveness of the consensus embedding, we further propose structural constraints based on theory of mind and a directional consensus mechanism. Execution can be fully distributed, requiring no explicit communication between policies. In which case, the information is exchanged implicitly through each robot's sensor stream by observing the actions of the other robots and their effects on the scene. Alternatively, execution can leverage direct communication to share the robots' consensus embeddings, where the embeddings are shared once during each inference step and are aligned using the sheaf Laplacian. In our hardware experiments, LatentToM outperforms a naive decentralized diffusion baseline, and shows comparable performance with a state-of-the-art centralized diffusion policy for bi-manual manipulation. Project website: this https URL.", 'abstract_zh': '我们提出了一种分布式扩散策略架构Latent Theory of Mind (LatentToM)，用于协作机器人操作。我们的策略允许多个具有自身感知和计算能力的 manipulator 在无需显式通信的情况下，为共同任务目标协同工作。我们的关键创新在于，每个代理可以维持两个潜在表示：一个特定于机器人的自我嵌入，以及一个虽然传感器流和姿态不同但旨在共同化的共识嵌入。我们进一步允许每个机器人训练一个解码器，从共识嵌入中推断出另一个机器人的自我嵌入，类似于潜空间中的理论思维。训练过程是集中式的，所有策略的共识编码器都由借鉴流层理论（一种用于聚类拓扑流形上数据的数学理论）的损失监督。具体地，我们引入了一阶同调损失来确保共识嵌入的一致对齐。为了保持共识嵌入的表达能力，我们还提出了基于理论思维的结构约束和定向共识机制。执行可以完全分布式，无需策略之间进行显式通信。在这种情况下，通过观察其他机器人及其对场景的影响，信息是通过每个机器人的传感器流隐式交换的。或者，执行可以利用直接通信来共享机器人的共识嵌入，在每次推理步骤中仅共享一次嵌入，并使用流层拉普拉斯算子进行对齐。在我们的硬件实验中，LatentToM 比一个简单的分布式扩散基线更优，并且在双臂操作方面与最新的集中式扩散策略具有可比的性能。项目网站：this https URL。', 'title_zh': '潜在的心理论：一种用于合作操作的去中心化扩散架构'}
{'arxiv_id': 'arXiv:2505.09108', 'title': 'Air-Ground Collaboration for Language-Specified Missions in Unknown Environments', 'authors': 'Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, M. Ani Hsieh, George J. Pappas, Camillo J. Taylor, Vijay Kumar', 'link': 'https://arxiv.org/abs/2505.09108', 'abstract': 'As autonomous robotic systems become increasingly mature, users will want to specify missions at the level of intent rather than in low-level detail. Language is an expressive and intuitive medium for such mission specification. However, realizing language-guided robotic teams requires overcoming significant technical hurdles. Interpreting and realizing language-specified missions requires advanced semantic reasoning. Successful heterogeneous robots must effectively coordinate actions and share information across varying viewpoints. Additionally, communication between robots is typically intermittent, necessitating robust strategies that leverage communication opportunities to maintain coordination and achieve mission objectives. In this work, we present a first-of-its-kind system where an unmanned aerial vehicle (UAV) and an unmanned ground vehicle (UGV) are able to collaboratively accomplish missions specified in natural language while reacting to changes in specification on the fly. We leverage a Large Language Model (LLM)-enabled planner to reason over semantic-metric maps that are built online and opportunistically shared between an aerial and a ground robot. We consider task-driven navigation in urban and rural areas. Our system must infer mission-relevant semantics and actively acquire information via semantic mapping. In both ground and air-ground teaming experiments, we demonstrate our system on seven different natural-language specifications at up to kilometer-scale navigation.', 'abstract_zh': '随着自主机器人系统的日益成熟，用户将希望以任务意图而非低级细节的方式指定任务。语言是一种表达性和直观性的任务指定媒介。然而，实现以语言为指导的机器人团队需要克服重大的技术障碍。解析和实现语言指定的任务需要高级语义推理。成功的异构机器人必须有效地协调行动并跨越不同视角共享信息。此外，机器人之间的通信通常时断时续，需要利用通信机会制定稳健的策略以维持协调并实现任务目标。在本项工作中，我们提出了一种前所未有的系统，其中无人飞行器（UAV）和无人地面车辆（UGV）能够协作完成自然语言指定的任务，并能在任务指定发生变化时实时响应。我们利用一个基于大型语言模型（LLM）的规划器，在空中和地面机器人之间在线构建和机会性共享语义-度量地图来进行语义推理。我们考虑在城市和农村地区进行任务驱动的导航。我们的系统必须推断与任务相关的内容，并通过语义映射积极获取信息。在地面上的团队和空地一体化团队实验中，我们展示了该系统在多达千米规模导航中的七种不同自然语言任务规定。', 'title_zh': '未知环境中的语言指定任务空地协作'}
{'arxiv_id': 'arXiv:2505.09099', 'title': 'Imitation Learning for Adaptive Control of a Virtual Soft Exoglove', 'authors': 'Shirui Lyu, Vittorio Caggiano, Matteo Leonetti, Dario Farina, Letizia Gionfrida', 'link': 'https://arxiv.org/abs/2505.09099', 'abstract': "The use of wearable robots has been widely adopted in rehabilitation training for patients with hand motor impairments. However, the uniqueness of patients' muscle loss is often overlooked. Leveraging reinforcement learning and a biologically accurate musculoskeletal model in simulation, we propose a customized wearable robotic controller that is able to address specific muscle deficits and to provide compensation for hand-object manipulation tasks. Video data of a same subject performing human grasping tasks is used to train a manipulation model through learning from demonstration. This manipulation model is subsequently fine-tuned to perform object-specific interaction tasks. The muscle forces in the musculoskeletal manipulation model are then weakened to simulate neurological motor impairments, which are later compensated by the actuation of a virtual wearable robotics glove. Results shows that integrating the virtual wearable robotic glove provides shared assistance to support the hand manipulator with weakened muscle forces. The learned exoglove controller achieved an average of 90.5\\% of the original manipulation proficiency.", 'abstract_zh': '穿戴式机器人在手部运动障碍患者康复训练中的应用：基于强化学习和生物准确肌肉骨骼模型的个性化穿戴式机器人控制策略', 'title_zh': '适应控制虚拟软外手套的模仿学习'}
{'arxiv_id': 'arXiv:2505.09074', 'title': 'Deployable and Generalizable Motion Prediction: Taxonomy, Open Challenges and Future Directions', 'authors': 'Letian Wang, Marc-Antoine Lavoie, Sandro Papais, Barza Nisar, Yuxiao Chen, Wenhao Ding, Boris Ivanovic, Hao Shao, Abulikemu Abuduweili, Evan Cook, Yang Zhou, Peter Karkus, Jiachen Li, Changliu Liu, Marco Pavone, Steven Waslander', 'link': 'https://arxiv.org/abs/2505.09074', 'abstract': "Motion prediction, the anticipation of future agent states or scene evolution, is rooted in human cognition, bridging perception and decision-making. It enables intelligent systems, such as robots and self-driving cars, to act safely in dynamic, human-involved environments, and informs broader time-series reasoning challenges. With advances in methods, representations, and datasets, the field has seen rapid progress, reflected in quickly evolving benchmark results. Yet, when state-of-the-art methods are deployed in the real world, they often struggle to generalize to open-world conditions and fall short of deployment standards. This reveals a gap between research benchmarks, which are often idealized or ill-posed, and real-world complexity.\nTo address this gap, this survey revisits the generalization and deployability of motion prediction models, with an emphasis on the applications of robotics, autonomous driving, and human motion. We first offer a comprehensive taxonomy of motion prediction methods, covering representations, modeling strategies, application domains, and evaluation protocols. We then study two key challenges: (1) how to push motion prediction models to be deployable to realistic deployment standards, where motion prediction does not act in a vacuum, but functions as one module of closed-loop autonomy stacks - it takes input from the localization and perception, and informs downstream planning and control. 2) how to generalize motion prediction models from limited seen scenarios/datasets to the open-world settings. Throughout the paper, we highlight critical open challenges to guide future work, aiming to recalibrate the community's efforts, fostering progress that is not only measurable but also meaningful for real-world applications.", 'abstract_zh': '运动预测模型的泛化与部署：面向机器人、自主驾驶和人体运动的应用研究', 'title_zh': '可部署且通用的运动预测：分类、开放挑战与未来方向'}
{'arxiv_id': 'arXiv:2505.09040', 'title': 'RT-cache: Efficient Robot Trajectory Retrieval System', 'authors': 'Owen Kwon, Abraham George, Alison Bartsch, Amir Barati Farimani', 'link': 'https://arxiv.org/abs/2505.09040', 'abstract': 'This paper introduces RT-cache, a novel trajectorymemory pipeline that accelerates real-world robot inference by leveraging big-data retrieval and learning from experience. While modern Vision-Language-Action (VLA) models can handle diverse robotic tasks, they often incur high per-step inference costs, resulting in significant latency, sometimes minutes per task. In contrast, RT-cache stores a large-scale Memory of previously successful robot trajectories and retrieves relevant multistep motion snippets, drastically reducing inference overhead. By integrating a Memory Builder with a Trajectory Retrieval, we develop an efficient retrieval process that remains tractable even for extremely large datasets. RT-cache flexibly accumulates real-world experiences and replays them whenever the current scene matches past states, adapting quickly to new or unseen environments with only a few additional samples. Experiments on the Open-X Embodiment Dataset and other real-world data demonstrate that RT-cache completes tasks both faster and more successfully than a baseline lacking retrieval, suggesting a practical, data-driven solution for real-time manipulation.', 'abstract_zh': 'RT-cache：一种通过大数据检索和经验学习加速现实世界机器人推理的新轨迹记忆流水线', 'title_zh': 'RT-cache: 高效的机器人轨迹检索系统'}
{'arxiv_id': 'arXiv:2505.08949', 'title': 'Multi-step manipulation task and motion planning guided by video demonstration', 'authors': 'Kateryna Zorina, David Kovar, Mederic Fourmy, Florent Lamiraux, Nicolas Mansard, Justin Carpentier, Josef Sivic, Vladimir Petrik', 'link': 'https://arxiv.org/abs/2505.08949', 'abstract': 'This work aims to leverage instructional video to solve complex multi-step task-and-motion planning tasks in robotics. Towards this goal, we propose an extension of the well-established Rapidly-Exploring Random Tree (RRT) planner, which simultaneously grows multiple trees around grasp and release states extracted from the guiding video. Our key novelty lies in combining contact states and 3D object poses extracted from the guiding video with a traditional planning algorithm that allows us to solve tasks with sequential dependencies, for example, if an object needs to be placed at a specific location to be grasped later. We also investigate the generalization capabilities of our approach to go beyond the scene depicted in the instructional video. To demonstrate the benefits of the proposed video-guided planning approach, we design a new benchmark with three challenging tasks: (I) 3D re-arrangement of multiple objects between a table and a shelf, (ii) multi-step transfer of an object through a tunnel, and (iii) transferring objects using a tray similar to a waiter transfers dishes. We demonstrate the effectiveness of our planning algorithm on several robots, including the Franka Emika Panda and the KUKA KMR iiwa. For a seamless transfer of the obtained plans to the real robot, we develop a trajectory refinement approach formulated as an optimal control problem (OCP).', 'abstract_zh': '本研究旨在利用指导性视频解决机器人领域的复杂多步任务和运动规划任务。为此，我们提出了一种对广泛认可的快速扩展随机树（RRT）规划器的扩展，该扩展能够在指导视频中提取的抓取和释放状态周围同时生长多棵树。我们的关键创新在于，将从指导视频中提取的接触状态和3D物体姿态与传统的规划算法相结合，从而能够解决具有序列依赖性的任务，例如，如果物体需要放置在特定位置以便后续抓取。我们还研究了我们方法的一般化能力，使其能够超越指导视频中所示的场景。为了展示所提视频引导规划方法的优势，我们设计了一个包含三个具有挑战性的任务的新基准：（I）多个物体在桌子和架子之间的3D重新排列；（II）通过隧道的多步物体转移；（III）使用类似侍者端盘的方式进行物体转移。我们在包括Franka Emika Panda和KUKA KMR iiwa在内的多个机器人上展示了我们规划算法的有效性。为了无缝地将获得的计划转移到真实机器人上，我们开发了一种轨迹细化方法，将其形式化为最优控制问题（OCP）。', 'title_zh': '基于视频演示的多步操作任务和运动规划'}
{'arxiv_id': 'arXiv:2505.08995', 'title': 'Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning', 'authors': 'Ardian Selmonaj, Oleg Szehr, Giacomo Del Rio, Alessandro Antonucci, Adrian Schneider, Michael Rüegsegger', 'link': 'https://arxiv.org/abs/2505.08995', 'abstract': 'This work presents a Hierarchical Multi-Agent Reinforcement Learning framework for analyzing simulated air combat scenarios involving heterogeneous agents. The objective is to identify effective Courses of Action that lead to mission success within preset simulations, thereby enabling the exploration of real-world defense scenarios at low cost and in a safe-to-fail setting. Applying deep Reinforcement Learning in this context poses specific challenges, such as complex flight dynamics, the exponential size of the state and action spaces in multi-agent systems, and the capability to integrate real-time control of individual units with look-ahead planning. To address these challenges, the decision-making process is split into two levels of abstraction: low-level policies control individual units, while a high-level commander policy issues macro commands aligned with the overall mission targets. This hierarchical structure facilitates the training process by exploiting policy symmetries of individual agents and by separating control from command tasks. The low-level policies are trained for individual combat control in a curriculum of increasing complexity. The high-level commander is then trained on mission targets given pre-trained control policies. The empirical validation confirms the advantages of the proposed framework.', 'abstract_zh': '基于层次多agent强化学习的异质代理模拟空战场景分析框架', 'title_zh': '通过分层多agent reinforcement learning提升空战战术'}
{'arxiv_id': 'arXiv:2505.08896', 'title': 'Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections', 'authors': 'Pankaj Kumar, Aditya Mishra, Pranamesh Chakraborty, Subrahmanya Swamy Peruru', 'link': 'https://arxiv.org/abs/2505.08896', 'abstract': 'Developing an autonomous vehicle control strategy for signalised intersections (SI) is one of the challenging tasks due to its inherently complex decision-making process. This study proposes a Deep Reinforcement Learning (DRL) based longitudinal vehicle control strategy at SI. A comprehensive reward function has been formulated with a particular focus on (i) distance headway-based efficiency reward, (ii) decision-making criteria during amber light, and (iii) asymmetric acceleration/ deceleration response, along with the traditional safety and comfort criteria. This reward function has been incorporated with two popular DRL algorithms, Deep Deterministic Policy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the continuous action space of acceleration/deceleration. The proposed models have been trained on the combination of real-world leader vehicle (LV) trajectories and simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process. The overall performance of the proposed models has been tested using Cumulative Distribution Function (CDF) plots and compared with the real-world trajectory data. The results show that the RL models successfully maintain lower distance headway (i.e., higher efficiency) and jerk compared to human-driven vehicles without compromising safety. Further, to assess the robustness of the proposed models, we evaluated the model performance on diverse safety-critical scenarios, in terms of car-following and traffic signal compliance. Both DDPG and SAC models successfully handled the critical scenarios, while the DDPG model showed smoother action profiles compared to the SAC model. Overall, the results confirm that DRL-based longitudinal vehicle control strategy at SI can help to improve traffic safety, efficiency, and comfort.', 'abstract_zh': '基于深度强化学习的信号化交叉口自动驾驶车辆纵向控制策略研究', 'title_zh': '基于深度强化学习的自动化车辆信号交叉口纵向控制策略'}
{'arxiv_id': 'arXiv:2505.08854', 'title': 'Generative AI for Autonomous Driving: Frontiers and Opportunities', 'authors': 'Yuping Wang, Shuo Xing, Cui Can, Renjie Li, Hongyuan Hua, Kexin Tian, Zhaobin Mo, Xiangbo Gao, Keshu Wu, Sulong Zhou, Hengxu You, Juntong Peng, Junge Zhang, Zehao Wang, Rui Song, Mingxuan Yan, Walter Zimmer, Xingcheng Zhou, Peiran Li, Zhaohan Lu, Chia-Ju Chen, Yue Huang, Ryan A. Rossi, Lichao Sun, Hongkai Yu, Zhiwen Fan, Frank Hao Yang, Yuhao Kang, Ross Greer, Chenxi Liu, Eun Hak Lee, Xuan Di, Xinyue Ye, Liu Ren, Alois Knoll, Xiaopeng Li, Shuiwang Ji, Masayoshi Tomizuka, Marco Pavone, Tianbao Yang, Jing Du, Ming-Hsuan Yang, Hua Wei, Ziran Wang, Yang Zhou, Jiachen Li, Zhengzhong Tu', 'link': 'https://arxiv.org/abs/2505.08854', 'abstract': "Generative Artificial Intelligence (GenAI) constitutes a transformative technological wave that reconfigures industries through its unparalleled capabilities for content creation, reasoning, planning, and multimodal understanding. This revolutionary force offers the most promising path yet toward solving one of engineering's grandest challenges: achieving reliable, fully autonomous driving, particularly the pursuit of Level 5 autonomy. This survey delivers a comprehensive and critical synthesis of the emerging role of GenAI across the autonomous driving stack. We begin by distilling the principles and trade-offs of modern generative modeling, encompassing VAEs, GANs, Diffusion Models, and Large Language Models (LLMs). We then map their frontier applications in image, LiDAR, trajectory, occupancy, video generation as well as LLM-guided reasoning and decision making. We categorize practical applications, such as synthetic data workflows, end-to-end driving strategies, high-fidelity digital twin systems, smart transportation networks, and cross-domain transfer to embodied AI. We identify key obstacles and possibilities such as comprehensive generalization across rare cases, evaluation and safety checks, budget-limited implementation, regulatory compliance, ethical concerns, and environmental effects, while proposing research plans across theoretical assurances, trust metrics, transport integration, and socio-technical influence. By unifying these threads, the survey provides a forward-looking reference for researchers, engineers, and policymakers navigating the convergence of generative AI and advanced autonomous mobility. An actively maintained repository of cited works is available at this https URL.", 'abstract_zh': '生成式人工智能（GenAI）构成了一个变革性的技术浪潮，通过其无与伦比的内容创造、推理、规划和多模态理解能力重新配置各行各业。这一革命性力量为解决工程领域的一大挑战——实现可靠的全自动驾驶，尤其是 Level 5 无人驾驶——提供了迄今为止最有前景的道路。本文综述涵盖了生成式人工智能在自主驾驶堆栈中不断涌现的作用。我们首先提炼现代生成模型的原则与权衡，包括 VAE、GAN、扩散模型和大语言模型（LLMs）。接着，我们将这些模型的应用前沿与其在图像、LiDAR、轨迹、占用率、视频生成以及大语言模型引导的推理和决策方面的应用进行映射。我们对其实用应用进行了分类，包括合成数据工作流程、端到端的驾驶策略、高保真数字孪生系统、智能交通网络以及跨域迁移至具身人工智能。我们识别出关键障碍与可能性，如全面泛化到稀有情况、评估与安全性检查、预算限制下的实现、法规合规性、伦理问题以及环境影响，并提出涵盖理论保证、信任度量、运输集成和社交技术影响的研究计划。通过统一这些线索，本文综述为研究人员、工程师和政策制定者在生成式人工智能与先进自主移动领域交汇处的导航提供了前瞻性的参考。已在以下网址维护了一个引文作品库：[此处链接]。', 'title_zh': '自动驾驶中的生成式AI：前沿与机遇'}
{'arxiv_id': 'arXiv:2505.09029', 'title': 'Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control', 'authors': 'Hazim Alzorgan, Abolfazl Razi', 'link': 'https://arxiv.org/abs/2505.09029', 'abstract': "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient (TD3), depend on basic noise-based exploration, which can result in less than optimal policy convergence. In this study, we introduce Monte Carlo Beam Search (MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts with TD3 to improve exploration and action selection. MCBS produces several candidate actions around the policy's output and assesses them through short-horizon rollouts, enabling the agent to make better-informed choices. We test MCBS across various continuous-control benchmarks, including HalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency and performance compared to standard TD3 and other baseline methods like SAC, PPO, and A2C. Our findings emphasize MCBS's capability to enhance policy learning through structured look-ahead search while ensuring computational efficiency. Additionally, we offer a detailed analysis of crucial hyperparameters, such as beam width and rollout depth, and explore adaptive strategies to optimize MCBS for complex control tasks. Our method shows a higher convergence rate across different environments compared to TD3, SAC, PPO, and A2C. For instance, we achieved 90% of the maximum achievable reward within around 200 thousand timesteps compared to 400 thousand timesteps for the second-best method.", 'abstract_zh': '基于蒙特卡罗束搜索的孪生延迟深度确定性策略梯度方法：提高探索和行动选择效率', 'title_zh': '基于蒙特卡洛束搜索的Actor-Critic强化学习在连续控制中的应用'}
{'arxiv_id': 'arXiv:2505.08988', 'title': 'Generalization in Monitored Markov Decision Processes (Mon-MDPs)', 'authors': 'Montaser Mohammedalamen, Michael Bowling', 'link': 'https://arxiv.org/abs/2505.08988', 'abstract': "Reinforcement learning (RL) typically models the interaction between the agent and environment as a Markov decision process (MDP), where the rewards that guide the agent's behavior are always observable. However, in many real-world scenarios, rewards are not always observable, which can be modeled as a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have been limited to simple, tabular cases, restricting their applicability to real-world problems. This work explores Mon-MDPs using function approximation (FA) and investigates the challenges involved. We show that combining function approximation with a learned reward model enables agents to generalize from monitored states with observable rewards, to unmonitored environment states with unobservable rewards. Therefore, we demonstrate that such generalization with a reward model achieves near-optimal policies in environments formally defined as unsolvable. However, we identify a critical limitation of such function approximation, where agents incorrectly extrapolate rewards due to overgeneralization, resulting in undesirable behaviors. To mitigate overgeneralization, we propose a cautious police optimization method leveraging reward uncertainty. This work serves as a step towards bridging this gap between Mon-MDP theory and real-world applications.", 'abstract_zh': 'Mon-MDPs中基于函数逼近的学习及其挑战与改进：从可观察奖励向不可观察奖励的泛化', 'title_zh': 'Monitored Markov决策过程（Mon-MDPs）的泛化能力'}
{'arxiv_id': 'arXiv:2505.09085', 'title': 'Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision', 'authors': 'Jiaxuan Chen, Yu Qi, Yueming Wang, Gang Pan', 'link': 'https://arxiv.org/abs/2505.09085', 'abstract': 'Recent advancements in deep neural networks (DNNs), particularly large-scale language models, have demonstrated remarkable capabilities in image and natural language understanding. Although scaling up model parameters with increasing volume of training data has progressively improved DNN capabilities, achieving complex cognitive abilities - such as understanding abstract concepts, reasoning, and adapting to novel scenarios, which are intrinsic to human cognition - remains a major challenge. In this study, we show that brain-in-the-loop supervised learning, utilizing a small set of brain signals, can effectively transfer human conceptual structures to DNNs, significantly enhancing their comprehension of abstract and even unseen concepts. Experimental results further indicate that the enhanced cognitive capabilities lead to substantial performance gains in challenging tasks, including few-shot/zero-shot learning and out-of-distribution recognition, while also yielding highly interpretable concept representations. These findings highlight that human-in-the-loop supervision can effectively augment the complex cognitive abilities of large models, offering a promising pathway toward developing more human-like cognitive abilities in artificial systems.', 'abstract_zh': 'Recent advancements in深度神经网络（DNNs），尤其是大规模语言模型，在图像和自然语言理解方面展现了卓越的能力。尽管随着训练数据量的增加，增大模型参数逐步提升了DNN的能力，但在实现诸如理解抽象概念、推理和适应新颖场景等人类认知所固有的复杂认知能力方面，仍面临重大挑战。本研究显示，利用少量脑信号进行脑-机闭环监督学习，可以有效将人类的概念结构转移到DNN中，显著提升其对抽象甚至未见过的概念的理解。实验结果进一步表明，增强的认知能力在包括少样本/零样本学习和离分布识别在内的挑战性任务中带来了显著的性能增益，同时产生了高度可解释的概念表示。这些发现强调，人类在环监督可以有效增强大型模型的复杂认知能力，为开发更具人类认知能力的人工智能系统提供了有前景的道路。', 'title_zh': '通过脑在环监督实现大型模型的人类认知泛化'}
{'arxiv_id': 'arXiv:2505.09003', 'title': 'Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition', 'authors': 'Zeki Doruk Erden, Donia Gasmi, Boi Faltings', 'link': 'https://arxiv.org/abs/2505.09003', 'abstract': 'Continual learning for reinforcement learning agents remains a significant challenge, particularly in preserving and leveraging existing information without an external signal to indicate changes in tasks or environments. In this study, we explore the effectiveness of autoencoders in detecting new tasks and matching observed environments to previously encountered ones. Our approach integrates policy optimization with familiarity autoencoders within an end-to-end continual learning system. This system can recognize and learn new tasks or environments while preserving knowledge from earlier experiences and can selectively retrieve relevant knowledge when re-encountering a known environment. Initial results demonstrate successful continual learning without external signals to indicate task changes or reencounters, showing promise for this methodology.', 'abstract_zh': '强化学习代理的持续学习仍然是一项显著的挑战，特别是在无需外部信号指示任务或环境变化的情况下保留和利用现有信息。在这项研究中，我们探索了自编码器在检测新任务和将观察到的环境匹配到先前遇到的环境方面的有效性。我们的方法将策略优化与熟悉度自编码器整合到端到端的持续学习系统中。该系统能够在识别和学习新任务或环境的同时保留早期经验的知识，并在重新遇到已知环境时有选择性地检索相关知识。初步结果表明，在无需外部信号指示任务变化或重新遇到的情况下，可以实现成功的持续学习，展示了该方法的潜力。', 'title_zh': '基于自动编码器驱动的任务和新环境识别的持续强化学习'}
{'arxiv_id': 'arXiv:2505.08825', 'title': 'Multi-source Plume Tracing via Multi-Agent Reinforcement Learning', 'authors': 'Pedro Antonio Alarcon Granadeno, Theodore Chambers, Jane Cleland-Huang', 'link': 'https://arxiv.org/abs/2505.08825', 'abstract': 'Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon gas leak (2015) demonstrate the urgent need for rapid and reliable plume tracing algorithms to protect public health and the environment. Traditional methods, such as gradient-based or biologically inspired approaches, often fail in realistic, turbulent conditions. To address these challenges, we present a Multi-Agent Reinforcement Learning (MARL) algorithm designed for localizing multiple airborne pollution sources using a swarm of small uncrewed aerial systems (sUAS). Our method models the problem as a Partially Observable Markov Game (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific Double Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical action-observation pairs, effectively approximating latent states. Unlike prior work, we use a general-purpose simulation environment based on the Gaussian Plume Model (GPM), incorporating realistic elements such as a three-dimensional environment, sensor noise, multiple interacting agents, and multiple plume sources. The incorporation of action histories as part of the inputs further enhances the adaptability of our model in complex, partially observable environments. Extensive simulations show that our algorithm significantly outperforms conventional approaches. Specifically, our model allows agents to explore only 1.29\\% of the environment to successfully locate pollution sources.', 'abstract_zh': '工业灾难如博帕尔灾难（1984年）和阿利索峡谷天然气泄漏（2015年）凸显了在现实湍流条件下亟需快速可靠烟雾追踪算法以保护公共健康和环境的紧迫性。传统的梯度基方法或生物启发方法往往在实际湍流条件下失效。为应对这些挑战，我们提出了一种适用于利用小型无人航空系统群（sUAS）定位多个空中污染源的多智能体强化学习（MARL）算法。该方法将问题建模为部分可观测马尔可夫博弈（POMG），并采用基于长短期记忆（LSTM）的动作特定双深层循环Q网络（ADDRQN），有效逼近隐含状态。与先前工作不同，我们使用基于高斯烟雾模型（GPM）的通用仿真环境，其中包括三维环境、传感器噪声、多个交互智能体和多个烟雾源。将动作历史作为输入的一部分进一步增强了模型在复杂、部分可观测环境中的适应性。 extensive simulations表明，我们的算法显著优于传统方法。具体来说，我们的模型使智能体仅探索环境的1.29%即可成功定位污染源。', 'title_zh': '多源羽流追踪的多代理强化学习方法'}
{'arxiv_id': 'arXiv:2505.08807', 'title': 'Security of Internet of Agents: Attacks and Countermeasures', 'authors': 'Yuntao Wang, Yanghe Pan, Shaolong Guo, Zhou Su', 'link': 'https://arxiv.org/abs/2505.08807', 'abstract': 'With the rise of large language and vision-language models, AI agents have evolved into autonomous, interactive systems capable of perception, reasoning, and decision-making. As they proliferate across virtual and physical domains, the Internet of Agents (IoA) has emerged as a key infrastructure for enabling scalable and secure coordination among heterogeneous agents. This survey offers a comprehensive examination of the security and privacy landscape in IoA systems. We begin by outlining the IoA architecture and its distinct vulnerabilities compared to traditional networks, focusing on four critical aspects: identity authentication threats, cross-agent trust issues, embodied security, and privacy risks. We then review existing and emerging defense mechanisms and highlight persistent challenges. Finally, we identify open research directions to advance the development of resilient and privacy-preserving IoA ecosystems.', 'abstract_zh': '随着大规模语言模型和多模态语言模型的发展，AI代理已进化为能够进行感知、推理和决策的自主交互系统。随着它们在虚拟和物理领域中的普及，代理互联网（IoA）已成为实现异构代理之间可扩展和安全协调的关键基础设施。本文提供了对IoA系统安全和隐私格局的全面考察。我们首先概述了IoA架构及其与传统网络相比的独特漏洞，重点关注四方面关键内容：身份认证威胁、跨代理信任问题、实体安全和隐私风险。然后，我们回顾现有的和新兴的防御机制，并突出存在的持续挑战。最后，我们确定了开放的研究方向，以促进稳健且隐私保护的IoA生态系统的进一步发展。', 'title_zh': '代理互联网的安全性：攻击与对策'}
