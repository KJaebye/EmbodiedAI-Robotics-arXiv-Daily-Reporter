{'arxiv_id': 'arXiv:2502.12098', 'title': 'Bandwidth-Adaptive Spatiotemporal Correspondence Identification for Collaborative Perception', 'authors': 'Peng Gao, Williard Joshua Jose, Hao Zhang', 'link': 'https://arxiv.org/abs/2502.12098', 'abstract': 'Correspondence identification (CoID) is an essential capability in multi-robot collaborative perception, which enables a group of robots to consistently refer to the same objects within their respective fields of view. In real-world applications, such as connected autonomous driving, vehicles face challenges in directly sharing raw observations due to limited communication bandwidth. In order to address this challenge, we propose a novel approach for bandwidth-adaptive spatiotemporal CoID in collaborative perception. This approach allows robots to progressively select partial spatiotemporal observations and share with others, while adapting to communication constraints that dynamically change over time. We evaluate our approach across various scenarios in connected autonomous driving simulations. Experimental results validate that our approach enables CoID and adapts to dynamic communication bandwidth changes. In addition, our approach achieves 8%-56% overall improvements in terms of covisible object retrieval for CoID and data sharing efficiency, which outperforms previous techniques and achieves the state-of-the-art performance. More information is available at: this https URL.', 'abstract_zh': '时空对应识别（CoID）在多机器人协作感知中的一个基本能力，使一群机器人能够在其各自的视场范围内一致地指代相同的对象。在现实世界的应用中，如connected autonomous driving，车辆由于通信带宽有限，面临直接共享原始观察结果的挑战。为了应对这一挑战，我们提出了一种新的时空自适应对应识别（CoID）方法，该方法允许机器人根据通信限制逐步选择并分享部分时空观察结果，而这些限制会随时间动态变化。我们通过对connected autonomous driving模拟中各种场景的评估，验证了该方法的有效性。实验结果表明，该方法能够实现CoID，并适应动态变化的通信带宽。此外，该方法在协视角目标检索和数据共享效率方面分别取得了8%-56%的整体改进，优于以往技术并达到业内顶尖水平。更多信息请参见：this https URL。', 'title_zh': '宽带自适应时空对应识别用于协同感知'}
{'arxiv_id': 'arXiv:2502.11955', 'title': 'pySLAM: An Open-Source, Modular, and Extensible Framework for SLAM', 'authors': 'Luigi Freda', 'link': 'https://arxiv.org/abs/2502.11955', 'abstract': 'pySLAM is an open-source Python framework for Visual SLAM, supporting monocular, stereo, and RGB-D cameras. It provides a flexible interface for integrating both classical and modern local features, making it adaptable to various SLAM tasks. The framework includes different loop closure methods, a volumetric reconstruction pipeline, and support for depth prediction models. Additionally, it offers a suite of tools for visual odometry and SLAM applications. Designed for both beginners and experienced researchers, pySLAM encourages community contributions, fostering collaborative development in the field of Visual SLAM.', 'abstract_zh': 'pySLAM是一个开源的Python框架，用于视觉SLAM，支持单目、立体和RGB-D相机。该框架提供了一个灵活的接口，用于集成经典和现代局部特征，使其能够适应各种SLAM任务。该框架包括不同的环视闭合方法、体素重建管道，并支持深度预测模型。此外，它还提供了一套用于视觉里程计和SLAM应用的工具。该框架旨在服务于从初学者到经验丰富的研究者，鼓励社区贡献，促进视觉SLAM领域的协作开发。', 'title_zh': 'pySLAM: 一个开源、模块化和可扩展的SLAM框架'}
{'arxiv_id': 'arXiv:2502.11352', 'title': 'A Framework for Learning Scoring Rules in Autonomous Driving Planning Systems', 'authors': 'Zikang Xiong, Joe Kurian Eappen, Suresh Jagannathan', 'link': 'https://arxiv.org/abs/2502.11352', 'abstract': 'In autonomous driving systems, motion planning is commonly implemented as a two-stage process: first, a trajectory proposer generates multiple candidate trajectories, then a scoring mechanism selects the most suitable trajectory for execution. For this critical selection stage, rule-based scoring mechanisms are particularly appealing as they can explicitly encode driving preferences, safety constraints, and traffic regulations in a formalized, human-understandable format. However, manually crafting these scoring rules presents significant challenges: the rules often contain complex interdependencies, require careful parameter tuning, and may not fully capture the nuances present in real-world driving data. This work introduces FLoRA, a novel framework that bridges this gap by learning interpretable scoring rules represented in temporal logic. Our method features a learnable logic structure that captures nuanced relationships across diverse driving scenarios, optimizing both rules and parameters directly from real-world driving demonstrations collected in NuPlan. Our approach effectively learns to evaluate driving behavior even though the training data only contains positive examples (successful driving demonstrations). Evaluations in closed-loop planning simulations demonstrate that our learned scoring rules outperform existing techniques, including expert-designed rules and neural network scoring models, while maintaining interpretability. This work introduces a data-driven approach to enhance the scoring mechanism in autonomous driving systems, designed as a plug-in module to seamlessly integrate with various trajectory proposers. Our video and code are available on this http URL.', 'abstract_zh': '自主驾驶系统中的运动规划通常分为两阶段实现：首先，轨迹生成器生成多个候选轨迹，然后评分机制选择最合适的轨迹进行执行。对于这一关键的选择阶段，基于规则的评分机制尤其具有吸引力，因为它们可以明确地以形式化和易于理解的方式编码驾驶偏好、安全约束和交通法规。然而，手动构建这些评分规则存在显著挑战：规则往往包含复杂的相互依赖性，需要精细的参数调整，并且可能无法充分捕捉现实驾驶数据中的细微差别。本文引入了FLoRA，这是一种新颖的框架，通过学习时序逻辑表示的可解释评分规则来弥合这一空白。该方法的特点是一种可学习的逻辑结构，能够捕捉多种驾驶场景下的细微关系，并直接从NuPlan收集的真实驾驶示范中优化规则和参数。我们的方法即使训练数据仅包含阳性示例（成功的驾驶示范），也能有效地学习评估驾驶行为。闭环规划仿真评估表明，我们学习得到的评分规则优于现有的技术，包括专家设计的规则和神经网络评分模型，同时保持可解释性。本工作提出了一种基于数据的方法来增强自主驾驶系统中的评分机制，并设计为可插入模块，能够无缝集成到各种轨迹生成器中。相关视频和代码可在以下网址获取。', 'title_zh': '自主驾驶规划系统中的评分规则学习框架'}
{'arxiv_id': 'arXiv:2502.11057', 'title': 'A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems', 'authors': 'Manan Tayal, Aditya Singh, Shishir Kolathaya, Somil Bansal', 'link': 'https://arxiv.org/abs/2502.11057', 'abstract': 'As autonomous systems become more ubiquitous in daily life, ensuring high performance with guaranteed safety is crucial. However, safety and performance could be competing objectives, which makes their co-optimization difficult. Learning-based methods, such as Constrained Reinforcement Learning (CRL), achieve strong performance but lack formal safety guarantees due to safety being enforced as soft constraints, limiting their use in safety-critical settings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability Analysis and Control Barrier Functions (CBFs) provide rigorous safety assurances but often neglect performance, resulting in overly conservative controllers. To bridge this gap, we formulate the co-optimization of safety and performance as a state-constrained optimal control problem, where performance objectives are encoded via a cost function and safety requirements are imposed as state constraints. We demonstrate that the resultant value function satisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate efficiently using a novel physics-informed machine learning framework. In addition, we introduce a conformal prediction-based verification strategy to quantify the learning errors, recovering a high-confidence safety value function, along with a probabilistic error bound on performance degradation. Through several case studies, we demonstrate the efficacy of the proposed framework in enabling scalable learning of safe and performant controllers for complex, high-dimensional autonomous systems.', 'abstract_zh': '随着自主系统在日常生活中越来越普遍，确保在有保证的安全性前提下的高性能至关重要。然而，安全性和性能可能是相互竞争的目标，这使得它们的协同优化变得困难。基于学习的方法，如受限强化学习（CRL），能够实现强大的性能，但由于安全要求作为软约束实现，缺乏形式上的安全保证，限制了其在安全关键场景中的应用。相反，形式化方法如哈密尔顿-雅可比（HJ）可达性分析和控制障碍函数（CBFs）能够提供严格的安全部署保证，但通常会忽视性能，导致过于保守的控制器。为弥合这一差距，我们将安全性和性能的协同优化形式化为状态受限的最优控制问题，其中通过代价函数编码性能目标，并将安全要求作为状态约束施加。我们证明所得的价值函数满足哈密尔顿-雅可比-贝尔曼（HJB）方程，并利用一种新颖的物理知情机器学习框架对其进行高效近似。此外，我们提出了一种齐性预测为基础的验证策略来量化学习误差，恢复高置信度的安全价值函数，并提供性能降解的概率误差边界。通过对几个案例研究，我们展示了所提出框架在复杂高维自主系统中实现可扩展的学习安全和高性能控制器的有效性。', 'title_zh': '基于物理信息的机器学习框架：面向自主系统安全与最优控制'}
{'arxiv_id': 'arXiv:2502.10975', 'title': 'GS-GVINS: A Tightly-integrated GNSS-Visual-Inertial Navigation System Augmented by 3D Gaussian Splatting', 'authors': 'Zelin Zhou, Saurav Uprety, Shichuang Nie, Hongzhou Yang', 'link': 'https://arxiv.org/abs/2502.10975', 'abstract': 'Recently, the emergence of 3D Gaussian Splatting (3DGS) has drawn significant attention in the area of 3D map reconstruction and visual SLAM. While extensive research has explored 3DGS for indoor trajectory tracking using visual sensor alone or in combination with Light Detection and Ranging (LiDAR) and Inertial Measurement Unit (IMU), its integration with GNSS for large-scale outdoor navigation remains underexplored. To address these concerns, we proposed GS-GVINS: a tightly-integrated GNSS-Visual-Inertial Navigation System augmented by 3DGS. This system leverages 3D Gaussian as a continuous differentiable scene representation in largescale outdoor environments, enhancing navigation performance through the constructed 3D Gaussian map. Notably, GS-GVINS is the first GNSS-Visual-Inertial navigation application that directly utilizes the analytical jacobians of SE3 camera pose with respect to 3D Gaussians. To maintain the quality of 3DGS rendering in extreme dynamic states, we introduce a motionaware 3D Gaussian pruning mechanism, updating the map based on relative pose translation and the accumulated opacity along the camera ray. For validation, we test our system under different driving environments: open-sky, sub-urban, and urban. Both self-collected and public datasets are used for evaluation. The results demonstrate the effectiveness of GS-GVINS in enhancing navigation accuracy across diverse driving environments.', 'abstract_zh': 'GS-GVINS：融合GNSS-视觉-惯性导航的3D高斯散点图系统', 'title_zh': 'GS-GVINS: 一种基于3D高斯点云增强的紧密集成的GNSS-视觉-惯性导航系统'}
{'arxiv_id': 'arXiv:2502.10585', 'title': 'Prediction uncertainty-aware planning using deep ensembles and trajectory optimisation', 'authors': 'Anshul Nayak, Azim Eskandarian', 'link': 'https://arxiv.org/abs/2502.10585', 'abstract': 'Human motion is stochastic and ensuring safe robot navigation in a pedestrian-rich environment requires proactive decision-making. Past research relied on incorporating deterministic future states of surrounding pedestrians which can be overconfident leading to unsafe robot behaviour. The current paper proposes a predictive uncertainty-aware planner that integrates neural network based probabilistic trajectory prediction into planning. Our method uses a deep ensemble based network for probabilistic forecasting of surrounding humans and integrates the predictive uncertainty as constraints into the planner. We compare numerous constraint satisfaction methods on the planner and evaluated its performance on real world pedestrian datasets. Further, offline robot navigation was carried out on out-of-distribution pedestrian trajectories inside a narrow corridor', 'abstract_zh': '人类运动具有不确定性，确保在行人密集环境中安全机器人导航需要主动决策。本研究提出了一种预测不确定性意识规划器，将基于神经网络的概率轨迹预测集成到规划中。该方法使用基于深度集成的网络进行周围人类的概率预测，并将预测不确定性作为约束集成到规划器中。我们在实际行人数据集上比较了多种约束满足方法，并评估了其性能。此外，还在狭窄走廊内的出分布行人轨迹上进行了离线机器人导航。', 'title_zh': '基于深度集成和轨迹优化的预测不确定性aware规划'}
{'arxiv_id': 'arXiv:2502.10552', 'title': 'Synthesis of Dynamic Masks for Information-Theoretic Opacity in Stochastic Systems', 'authors': 'Sumukha Udupa, Chongyang Shi, Jie Fu', 'link': 'https://arxiv.org/abs/2502.10552', 'abstract': "In this work, we investigate the synthesis of dynamic information releasing mechanisms, referred to as ''masks'', to minimize information leakage from a stochastic system to an external observer. Specifically, for a stochastic system, an observer aims to infer whether the final state of the system trajectory belongs to a set of secret states. The dynamic mask seeks to regulate sensor information in order to maximize the observer's uncertainty about the final state, a property known as final-state opacity. While existing supervisory control literature on dynamic masks primarily addresses qualitative opacity, we propose quantifying opacity in stochastic systems by conditional entropy, which is a measure of information leakage in information security. We then formulate a constrained optimization problem to synthesize a dynamic mask that maximizes final-state opacity under a total cost constraint on masking. To solve this constrained optimal dynamic mask synthesis problem, we develop a novel primal-dual policy gradient method. Additionally, we present a technique for computing the gradient of conditional entropy with respect to the masking policy parameters, leveraging observable operators in hidden Markov models. To demonstrate the effectiveness of our approach, we apply our method to an illustrative example and a stochastic grid world scenario, showing how our algorithm optimally enforces final-state opacity under cost constraints.", 'abstract_zh': '本文探讨了动态信息释放机制“掩码”的合成，以最小化随机系统对外部观察者的信息泄露。具体而言，对于一个随机系统，观察者试图推断系统轨迹的最终状态是否属于一组秘密状态。动态掩码旨在调节传感器信息，以最大化观察者对最终状态的不确定性，这一特性称为最终状态不透明性。虽然现有动态掩码的监督控制文献主要关注定性不透明性，我们提出通过条件熵来量化随机系统中的不透明性，条件熵是信息安全中的信息泄露度量。然后，我们形式化了一个有约束的优化问题，以在总成本约束下合成最大化最终状态不透明性的动态掩码。为了解决这一有约束的最优动态掩码合成问题，我们开发了一种新颖的普里姆-杜尔政策梯度方法。此外，我们介绍了一种技术，用于利用隐马尔可夫模型中的可观测算子来计算条件熵关于掩码策略参数的梯度。为了展示我们方法的有效性，我们将其应用于一个示例场景和一个随机网格世界场景，展示了在成本约束下我们的算法如何最优地实现最终状态不透明性。', 'title_zh': '基于信息论的透明度合成动态掩码在随机系统中的应用'}
{'arxiv_id': 'arXiv:2502.10476', 'title': 'Multi-Objective Planning with Contextual Lexicographic Reward Preferences', 'authors': 'Pulkit Rustagi, Yashwanthi Anand, Sandhya Saisubramanian', 'link': 'https://arxiv.org/abs/2502.10476', 'abstract': 'Autonomous agents are often required to plan under multiple objectives whose preference ordering varies based on context. The agent may encounter multiple contexts during its course of operation, each imposing a distinct lexicographic ordering over the objectives, with potentially different reward functions associated with each context. Existing approaches to multi-objective planning typically consider a single preference ordering over the objectives, across the state space, and do not support planning under multiple objective orderings within an environment. We present Contextual Lexicographic Markov Decision Process (CLMDP), a framework that enables planning under varying lexicographic objective orderings, depending on the context. In a CLMDP, both the objective ordering at a state and the associated reward functions are determined by the context. We employ a Bayesian approach to infer a state-context mapping from expert trajectories. Our algorithm to solve a CLMDP first computes a policy for each objective ordering and then combines them into a single context-aware policy that is valid and cycle-free. The effectiveness of the proposed approach is evaluated in simulation and using a mobile robot.', 'abstract_zh': '基于上下文的字典序马尔可夫决策过程（Contextual Lexicographic Markov Decision Process）', 'title_zh': '基于背景列索尔夫优选奖励的多目标规划'}
{'arxiv_id': 'arXiv:2502.12125', 'title': 'Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the Lens of Class Hierarchy', 'authors': 'Roman Malashin, Valeria Yachnaya, Alexander Mullin', 'link': 'https://arxiv.org/abs/2502.12125', 'abstract': 'We investigate the training dynamics of deep classifiers by examining how hierarchical relationships between classes evolve during training. Through extensive experiments, we argue that the learning process in classification problems can be understood through the lens of label clustering. Specifically, we observe that networks tend to distinguish higher-level (hypernym) categories in the early stages of training, and learn more specific (hyponym) categories later. We introduce a novel framework to track the evolution of the feature manifold during training, revealing how the hierarchy of class relations emerges and refines across the network layers. Our analysis demonstrates that the learned representations closely align with the semantic structure of the dataset, providing a quantitative description of the clustering process. Notably, we show that in the hypernym label space, certain properties of neural collapse appear earlier than in the hyponym label space, helping to bridge the gap between the initial and terminal phases of learning. We believe our findings offer new insights into the mechanisms driving hierarchical learning in deep networks, paving the way for future advancements in understanding deep learning dynamics.', 'abstract_zh': '我们通过探究类别层次关系在训练过程中的演化来研究深度分类器的训练动态。我们通过大量实验argue，分类问题中的学习过程可以通过标签聚类的视角来理解。具体而言，我们观察到网络在训练的早期阶段倾向于区分上位类别（超nym），而在后期学习更多特定的下位类别（hyponym）。我们提出了一种新颖的框架来追踪训练过程中特征流形的演化，揭示了类别关系层级如何在网络层中逐步形成和细化。我们的分析表明，learned表示与数据集的语义结构高度一致，提供了一个聚类过程的定量描述。值得注意的是，我们展示了在上位类别标签空间中，某些神经塌缩的特性比在下位类别标签空间中更早出现，有助于弥合学习初期和终端阶段之间的差距。我们认为我们的发现为理解深度网络中的层次学习机制提供了新的见解，为未来深入理解深度学习动态铺平了道路。', 'title_zh': '超类偏差：通过类层次结构的视角剖析深度分类器训练动力学'}
{'arxiv_id': 'arXiv:2502.12102', 'title': 'Relational Norms for Human-AI Cooperation', 'authors': 'Brian D. Earp, Sebastian Porsdam Mann, Mateo Aboy, Edmond Awad, Monika Betzler, Marietjie Botes, Rachel Calcott, Mina Caraccio, Nick Chater, Mark Coeckelbergh, Mihaela Constantinescu, Hossein Dabbagh, Kate Devlin, Xiaojun Ding, Vilius Dranseika, Jim A. C. Everett, Ruiping Fan, Faisal Feroz, Kathryn B. Francis, Cindy Friedman, Orsolya Friedrich, Iason Gabriel, Ivar Hannikainen, Julie Hellmann, Arasj Khodadade Jahrome, Niranjan S. Janardhanan, Paul Jurcys, Andreas Kappes, Maryam Ali Khan, Gordon Kraft-Todd, Maximilian Kroner Dale, Simon M. Laham, Benjamin Lange, Muriel Leuenberger, Jonathan Lewis, Peng Liu, David M. Lyreskog, Matthijs Maas, John McMillan, Emilian Mihailov, Timo Minssen, Joshua Teperowski Monrad, Kathryn Muyskens, Simon Myers, Sven Nyholm, Alexa M. Owen, Anna Puzio, Christopher Register, Madeline G. Reinecke, Adam Safron, Henry Shevlin, Hayate Shimizu, Peter V. Treit, Cristina Voinea, Karen Yan, Anda Zahiu, Renwen Zhang, Hazem Zohny, Walter Sinnott-Armstrong, Ilina Singh, Julian Savulescu, Margaret S. Clark', 'link': 'https://arxiv.org/abs/2502.12102', 'abstract': "How we should design and interact with social artificial intelligence depends on the socio-relational role the AI is meant to emulate or occupy. In human society, relationships such as teacher-student, parent-child, neighbors, siblings, or employer-employee are governed by specific norms that prescribe or proscribe cooperative functions including hierarchy, care, transaction, and mating. These norms shape our judgments of what is appropriate for each partner. For example, workplace norms may allow a boss to give orders to an employee, but not vice versa, reflecting hierarchical and transactional expectations. As AI agents and chatbots powered by large language models are increasingly designed to serve roles analogous to human positions - such as assistant, mental health provider, tutor, or romantic partner - it is imperative to examine whether and how human relational norms should extend to human-AI interactions. Our analysis explores how differences between AI systems and humans, such as the absence of conscious experience and immunity to fatigue, may affect an AI's capacity to fulfill relationship-specific functions and adhere to corresponding norms. This analysis, which is a collaborative effort by philosophers, psychologists, relationship scientists, ethicists, legal experts, and AI researchers, carries important implications for AI systems design, user behavior, and regulation. While we accept that AI systems can offer significant benefits such as increased availability and consistency in certain socio-relational roles, they also risk fostering unhealthy dependencies or unrealistic expectations that could spill over into human-human relationships. We propose that understanding and thoughtfully shaping (or implementing) suitable human-AI relational norms will be crucial for ensuring that human-AI interactions are ethical, trustworthy, and favorable to human well-being.", 'abstract_zh': '社会人工智能的设计与互动应取决于其旨在模仿或占据的社会关系角色。在人类社会中，诸如师生关系、亲子关系、邻里关系、兄弟姐妹关系或雇主雇员关系等关系由特定规范所治理，这些规范规定或禁止合作功能，包括等级制度、关爱、交易和交配。这些规范塑造了我们对每个伙伴适宜行为的判断。例如，工作场所规范可能允许老板对员工下达命令，但不允许反之，这反映了等级制度和交易的期待。随着越来越多设计用于模拟人类职位的社会人工智能代理和聊天机器人——如助手、心理健康提供者、导师或伴侣——审视并探索人类关系规范是否以及如何适用于人机互动变得至关重要。我们的分析探讨了人工智能系统与人类之间的差异，如缺乏意识体验和免于疲劳，如何影响人工智能履行特定关系功能以及遵守相应规范的能力。这项分析由哲学家、心理学家、关系科学家、伦理学家、法律专家和人工智能研究人员共同努力完成，对人工智能系统设计、用户行为和监管具有重要影响。尽管我们接受人工智能系统可以提供诸如特定社会关系角色的增加可用性和一致性的显著利益，但它们也可能滋生不健康依赖或不切实际期望的风险，这些风险可能会溢入人与人之间关系。我们建议理解并有意识地塑造（或实施）适当的人机关系规范将是确保人机互动具有伦理性、可信性和有利于人类福祉的关键。', 'title_zh': '人类与人工智能合作中的关系规范'}
{'arxiv_id': 'arXiv:2502.12054', 'title': 'PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning', 'authors': 'Xinyu Zhang, Yuxuan Dong, Yanrui Wu, Jiaxing Huang, Chengyou Jia, Basura Fernando, Mike Zheng Shou, Lingling Zhang, Jun Liu', 'link': 'https://arxiv.org/abs/2502.12054', 'abstract': 'Large language models demonstrate remarkable capabilities across various domains, especially mathematics and logic reasoning. However, current evaluations overlook physics-based reasoning - a complex task requiring physics theorems and constraints. We present PhysReason, a 1,200-problem benchmark comprising knowledge-based (25%) and reasoning-based (75%) problems, where the latter are divided into three difficulty levels (easy, medium, hard). Notably, problems require an average of 8.1 solution steps, with hard requiring 15.6, reflecting the complexity of physics-based reasoning. We propose the Physics Solution Auto Scoring Framework, incorporating efficient answer-level and comprehensive step-level evaluations. Top-performing models like Deepseek-R1, Gemini-2.0-Flash-Thinking, and o3-mini-high achieve less than 60% on answer-level evaluation, with performance dropping from knowledge questions (75.11%) to hard problems (31.95%). Through step-level evaluation, we identified four key bottlenecks: Physics Theorem Application, Physics Process Understanding, Calculation, and Physics Condition Analysis. These findings position PhysReason as a novel and comprehensive benchmark for evaluating physics-based reasoning capabilities in large language models. Our code and data will be published at https:/dxzxy12138.github.io/PhysReason.', 'abstract_zh': '大型语言模型在数学和逻辑推理等领域展现出 remarkable 的能力，尤其是物理推理。然而，当前的评估忽视了基于物理的推理——一项要求应用物理定理和约束的复杂任务。我们提出了 PhysReason，这是一个包含 1200 个问题的基准，其中知识基础问题占 25%，基于推理的问题占 75%，后者进一步分为三个难度级别（简单、中等、困难）。值得注意的是，这些问题平均需要 8.1 步解决方案，其中困难级别的问题需要 15.6 步，这反映了基于物理的推理的复杂性。我们提出了物理解决方案自动评分框架，该框架包括高效的答案级和全面的步骤级评估。顶级模型如 Deepseek-R1、Gemini-2.0-Flash-Thinking 和 o3-mini-high 在答案级评估中得分低于 60%，性能从知识问题（75.11%）下降到困难问题（31.95%）。通过步骤级评估，我们确定了四个关键瓶颈：物理定理应用、物理过程理解、计算和物理条件分析。这些发现使 PhysReason 成为评估大型语言模型物理推理能力的一个新颖且全面的基准。我们的代码和数据将在 https:/dxzxy12138.github.io/PhysReason 发布。', 'title_zh': 'PhysReason: 基于物理推理的综合基准'}
{'arxiv_id': 'arXiv:2502.11969', 'title': 'Learning Generalizable Prompt for CLIP with Class Similarity Knowledge', 'authors': 'Sehun Jung, Hyang-won Lee', 'link': 'https://arxiv.org/abs/2502.11969', 'abstract': 'In vision-language models (VLMs), prompt tuning has shown its effectiveness in adapting models to downstream tasks. However, learned prompts struggle to generalize to unseen classes, as they tend to overfit to the classes that are targeted during prompt tuning. Examining failure cases, we observed that learned prompts disrupt the semantics of unseen classes, generating text embeddings with incorrect semantic relationships among classes. To address this, we propose Similarity Alignment Regularization (SAR), which regularizes learnable prompts to preserve the semantic relationships among classes captured by hand-crafted prompts. Specifically, we first obtain novel classes related to base classes using ChatGPT-4o and utilize them as potential unseen classes during prompt tuning. Then, by targeting both base and novel classes, SAR aligns the similarity relationships among text embeddings generated by learnable prompts with the similarity relationships from hand-crafted prompts. Extensive experiments applying SAR to existing prompt tuning methods demonstrate its effectiveness in improving generalization to unseen classes.', 'abstract_zh': '在视觉-语言模型中，提示调优已经显示出其在适应下游任务方面的有效性。然而，学习到的提示难以泛化到未见过的类中，因为它们倾向于在提示调优过程中针对特定类进行过拟合。通过分析失败案例，我们发现学习到的提示会破坏未见过类的语义，生成具有错误语义关系的文本嵌入。为了解决这一问题，我们提出了一种相似性对齐正则化（SAR），它通过对可学习提示进行正则化来保持手工构建提示捕获的类间语义关系。具体而言，我们首先使用ChatGPT-4o获取与基类相关的新型类，并利用它们作为提示调优过程中的潜在未见过类。然后，通过同时针对基类和新型类，SAR将可学习提示生成的文本嵌入之间的相似性关系与手工构建提示的相似性关系对齐。在现有提示调优方法中应用SAR的广泛实验表明，它在提高对未见过类的泛化能力方面是有效的。', 'title_zh': '基于类相似性知识学习通用提示词向量以优化CLIP'}
{'arxiv_id': 'arXiv:2502.11959', 'title': 'STRIVE: Structured Reasoning for Self-Improvement in Claim Verification', 'authors': 'Haisong Gong, Jing Li, Junfei Wu, Qiang Liu, Shu Wu, Liang Wang', 'link': 'https://arxiv.org/abs/2502.11959', 'abstract': 'Claim verification is the task of determining whether a claim is supported or refuted by evidence. Self-improvement methods, where reasoning chains are generated and those leading to correct results are selected for training, have succeeded in tasks like mathematical problem solving. However, in claim verification, this approach struggles. Low-quality reasoning chains may falsely match binary truth labels, introducing faulty reasoning into the self-improvement process and ultimately degrading performance. To address this, we propose STRIVE: Structured Reasoning for Self-Improved Verification. Our method introduces a structured reasoning design with Claim Decomposition, Entity Analysis, and Evidence Grounding Verification. These components improve reasoning quality, reduce errors, and provide additional supervision signals for self-improvement. STRIVE begins with a warm-up phase, where the base model is fine-tuned on a small number of annotated examples to learn the structured reasoning design. It is then applied to generate reasoning chains for all training examples, selecting only those that are correct and structurally sound for subsequent self-improvement training. We demonstrate that STRIVE achieves significant improvements over baseline models, with a 31.4% performance gain over the base model and 20.7% over Chain of Thought on the HOVER datasets, highlighting its effectiveness.', 'abstract_zh': '基于结构化推理的自我改进验证', 'title_zh': 'STRIVE: 结构化推理促进断言验证的自我提升'}
{'arxiv_id': 'arXiv:2502.11915', 'title': 'On the robustness of ChatGPT in teaching Korean Mathematics', 'authors': 'Phuong-Nam Nguyen, Quang Nguyen-The, An Vu-Minh, Diep-Anh Nguyen, Xuan-Lam Pham', 'link': 'https://arxiv.org/abs/2502.11915', 'abstract': "ChatGPT, an Artificial Intelligence model, has the potential to revolutionize education. However, its effectiveness in solving non-English questions remains uncertain. This study evaluates ChatGPT's robustness using 586 Korean mathematics questions. ChatGPT achieves 66.72% accuracy, correctly answering 391 out of 586 questions. We also assess its ability to rate mathematics questions based on eleven criteria and perform a topic analysis. Our findings show that ChatGPT's ratings align with educational theory and test-taker perspectives. While ChatGPT performs well in question classification, it struggles with non-English contexts, highlighting areas for improvement. Future research should address linguistic biases and enhance accuracy across diverse languages. Domain-specific optimizations and multilingual training could improve ChatGPT's role in personalized education.", 'abstract_zh': 'ChatGPT，一种人工智能模型，有望革新教育。然而，其解决非英语问题的有效性仍不确定。本研究使用586道韩文数学题评估ChatGPT的稳健性。ChatGPT的准确率为66.72%，正确回答了391道题目。我们还基于 eleven 个标准评估其评级数学题目的能力，并进行了主题分析。研究发现，ChatGPT的评级与教育理论和考生视角一致。虽然ChatGPT在题目分类方面表现良好，但在非英语环境中表现不佳，凸显了改进的必要性。未来研究应解决语言偏见并提高不同语言环境下的准确性。针对特定领域的优化和多语言训练可提高ChatGPT在个性化教育中的作用。', 'title_zh': '关于ChatGPT在教学韩式数学中的鲁棒性'}
{'arxiv_id': 'arXiv:2502.11817', 'title': 'AAKT: Enhancing Knowledge Tracing with Alternate Autoregressive Modeling', 'authors': 'Hao Zhou, Wenge Rong, Jianfei Zhang, Qing Sun, Yuanxin Ouyang, Zhang Xiong', 'link': 'https://arxiv.org/abs/2502.11817', 'abstract': "Knowledge Tracing (KT) aims to predict students' future performances based on their former exercises and additional information in educational settings. KT has received significant attention since it facilitates personalized experiences in educational situations. Simultaneously, the autoregressive modeling on the sequence of former exercises has been proven effective for this task. One of the primary challenges in autoregressive modeling for Knowledge Tracing is effectively representing the anterior (pre-response) and posterior (post-response) states of learners across exercises. Existing methods often employ complex model architectures to update learner states using question and response records. In this study, we propose a novel perspective on knowledge tracing task by treating it as a generative process, consistent with the principles of autoregressive models. We demonstrate that knowledge states can be directly represented through autoregressive encodings on a question-response alternate sequence, where model generate the most probable representation in hidden state space by analyzing history interactions. This approach underpins our framework, termed Alternate Autoregressive Knowledge Tracing (AAKT). Additionally, we incorporate supplementary educational information, such as question-related skills, into our framework through an auxiliary task, and include extra exercise details, like response time, as additional inputs. Our proposed framework is implemented using advanced autoregressive technologies from Natural Language Generation (NLG) for both training and prediction. Empirical evaluations on four real-world KT datasets indicate that AAKT consistently outperforms all baseline models in terms of AUC, ACC, and RMSE. Furthermore, extensive ablation studies and visualized analysis validate the effectiveness of key components in AAKT.", 'abstract_zh': '知识追踪（KT）的目标是基于学生以往的练习和附加信息来预测未来的表现。知识追踪自引入以来受到了广泛关注，因为它可以促进教育情境中的个性化体验。同时，对以往练习序列的自回归建模已被证明是进行此任务的有效方法。自回归建模在知识追踪中的主要挑战之一是如何有效地表示练习前后学生的前响应状态和后响应状态。现有方法通常通过问题和响应记录来更新学生状态，采用复杂模型架构。在本研究中，我们从一种新的视角来处理知识追踪任务，将其视为生成过程，这与自回归模型的原则一致。我们展示了可以通过对问题-响应交替序列进行自回归编码直接表示知识状态，通过分析历史交互来生成最有可能的隐藏状态表示，从而支持我们提出的框架——交替自回归知识追踪（AAKT）。此外，我们通过辅助任务将补充的教育信息，如与问题相关的技能，以及额外的练习细节，如响应时间，整合到我们的框架中。提出的框架利用自然语言生成（NLG）的先进自回归技术进行训练和预测。在四个实际知识追踪数据集上的实证评估表明，AAKT在AUC、ACC和RMSE指标上均优于所有基线模型。此外，广泛的消融研究和可视化分析验证了AAKT关键组件的有效性。', 'title_zh': 'AAKT：增强知识追踪的交替自回归建模'}
{'arxiv_id': 'arXiv:2502.11799', 'title': 'Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning', 'authors': 'Peiying Yu, Guoxin Chen, Jingjing Wang', 'link': 'https://arxiv.org/abs/2502.11799', 'abstract': 'Despite the remarkable capabilities of large language models (LLMs) in various reasoning tasks, they still struggle with table reasoning tasks, particularly in maintaining consistency throughout multi-step reasoning processes. While existing approaches have explored various decomposition strategies, they often lack effective mechanisms to identify and correct errors in intermediate reasoning steps, leading to cascading error propagation. To address these issues, we propose Table-Critic, a novel multi-agent framework that facilitates collaborative criticism and iterative refinement of the reasoning process until convergence to correct solutions. Our framework consists of four specialized agents: a Judge for error identification, a Critic for comprehensive critiques, a Refiner for process improvement, and a Curator for pattern distillation. To effectively deal with diverse and unpredictable error types, we introduce a self-evolving template tree that systematically accumulates critique knowledge through experience-driven learning and guides future reflections. Extensive experiments have demonstrated that Table-Critic achieves substantial improvements over existing methods, achieving superior accuracy and error correction rates while maintaining computational efficiency and lower solution degradation rate.', 'abstract_zh': '尽管大语言模型在各种推理任务中表现出色，但在表推理任务中仍面临挑战，特别是在多步推理过程中保持一致性方面。虽然现有的方法探索了各种分解策略，但它们往往缺乏有效的机制来识别和纠正中间推理步骤中的错误，导致错误逐级传播。为了解决这些问题，我们提出Table-Critic，一种新型多Agent框架，促进推理过程的合作批评和迭代优化，直到收敛到正确的解决方案。该框架包含四个专门的Agent：裁判用于错误识别、批评家用于全面批评、优化器用于过程改进、策展人用于模式提炼。为有效处理多样且不可预测的错误类型，我们引入了一种自我进化的模板树，通过基于经验的学习系统地累积批评知识，并引导未来的反思。广泛的实验表明，Table-Critic 在现有方法上取得了显著改进，实现了更高的准确性和错误纠正率，同时保持了计算效率和较低的解质量降解率。', 'title_zh': '表评论家：一种用于表格推理中协作批评与修正的多-agent框架'}
{'arxiv_id': 'arXiv:2502.11588', 'title': 'A Unified Modeling Framework for Automated Penetration Testing', 'authors': 'Yunfei Wang, Shixuan Liu, Wenhao Wang, Changling Zhou, Chao Zhang, Jiandong Jin, Cheng Zhu', 'link': 'https://arxiv.org/abs/2502.11588', 'abstract': 'The integration of artificial intelligence into automated penetration testing (AutoPT) has highlighted the necessity of simulation modeling for the training of intelligent agents, due to its cost-efficiency and swift feedback capabilities. Despite the proliferation of AutoPT research, there is a recognized gap in the availability of a unified framework for simulation modeling methods. This paper presents a systematic review and synthesis of existing techniques, introducing MDCPM to categorize studies based on literature objectives, network simulation complexity, dependency of technical and tactical operations, and scenario feedback and variation. To bridge the gap in unified method for multi-dimensional and multi-level simulation modeling, dynamic environment modeling, and the scarcity of public datasets, we introduce AutoPT-Sim, a novel modeling framework that based on policy automation and encompasses the combination of all sub dimensions. AutoPT-Sim offers a comprehensive approach to modeling network environments, attackers, and defenders, transcending the constraints of static modeling and accommodating networks of diverse scales. We publicly release a generated standard network environment dataset and the code of Network Generator. By integrating publicly available datasets flexibly, support is offered for various simulation modeling levels focused on policy automation in MDCPM and the network generator help researchers output customized target network data by adjusting parameters or fine-tuning the network generator.', 'abstract_zh': '人工智能在自动化渗透测试中的集成突显了仿真建模对于智能代理培训的必要性：由于其成本效益和快速反馈能力。尽管自动化渗透测试研究不断涌现，但在仿真建模方法的统一框架方面仍存在缺口。本文对现有技术进行了系统综述和综合，提出MDCPM根据文献目标、网络仿真复杂度、技术和战术操作的依赖性以及场景反馈和变化进行分类。为解决多维度和多层次仿真建模、动态环境建模以及缺乏公开数据集的缺口，我们提出了AutoPT-Sim，这是一种基于策略自动化的新建模框架，涵盖了所有子维度的组合。AutoPT-Sim提供了 modeling 网络环境、攻击者和防御者的全面方法，超越了静态建模的限制，适用于不同规模的网络。我们公开发布了一个生成的标准网络环境数据集和网络生成器的代码。通过灵活整合公开可用的数据集，AutoPT-Sim 支持MDCPM中各类仿真建模层次关注策略自动化，并通过调整参数或细化网络生成器帮助研究人员输出定制的目标网络数据。', 'title_zh': '统一的自动化渗透测试建模框架'}
{'arxiv_id': 'arXiv:2502.11585', 'title': 'Calibration of Vehicular Traffic Simulation Models by Local Optimization', 'authors': 'Davide Andrea Guastella, Alejandro Morales-Hernàndez, Bruno Cornelis, Gianluca Bontempi', 'link': 'https://arxiv.org/abs/2502.11585', 'abstract': 'Simulation is a valuable tool for traffic management experts to assist them in refining and improving transportation systems and anticipating the impact of possible changes in the infrastructure network before their actual implementation. Calibrating simulation models using traffic count data is challenging because of the complexity of the environment, the lack of data, and the uncertainties in traffic dynamics. This paper introduces a novel stochastic simulation-based traffic calibration technique. The novelty of the proposed method is: (i) it performs local traffic calibration, (ii) it allows calibrating simulated traffic in large-scale environments, (iii) it requires only the traffic count data. The local approach enables decentralizing the calibration task to reach near real-time performance, enabling the fostering of digital twins. Using only traffic count data makes the proposed method generic so that it can be applied in different traffic scenarios at various scales (from neighborhood to region). We assess the proposed technique on a model of Brussels, Belgium, using data from real traffic monitoring devices. The proposed method has been implemented using the open-source traffic simulator SUMO. Experimental results show that the traffic model calibrated using the proposed method is on average 16% more accurate than those obtained by the state-of-the-art methods, using the same dataset. We also make available the output traffic model obtained from real data.', 'abstract_zh': '基于随机模拟的交通校准新技术：局部校准方法在大规模环境下使用交通流量数据进行交通模拟校准', 'title_zh': '车辆交通仿真模型的局部优化校准'}
{'arxiv_id': 'arXiv:2502.11560', 'title': 'A Survey of Automatic Prompt Engineering: An Optimization Perspective', 'authors': 'Wenwu Li, Xiangfeng Wang, Wenhao Li, Bo Jin', 'link': 'https://arxiv.org/abs/2502.11560', 'abstract': 'The rise of foundation models has shifted focus from resource-intensive fine-tuning to prompt engineering, a paradigm that steers model behavior through input design rather than weight updates. While manual prompt engineering faces limitations in scalability, adaptability, and cross-modal alignment, automated methods, spanning foundation model (FM) based optimization, evolutionary methods, gradient-based optimization, and reinforcement learning, offer promising solutions. Existing surveys, however, remain fragmented across modalities and methodologies. This paper presents the first comprehensive survey on automated prompt engineering through a unified optimization-theoretic lens. We formalize prompt optimization as a maximization problem over discrete, continuous, and hybrid prompt spaces, systematically organizing methods by their optimization variables (instructions, soft prompts, exemplars), task-specific objectives, and computational frameworks. By bridging theoretical formulation with practical implementations across text, vision, and multimodal domains, this survey establishes a foundational framework for both researchers and practitioners, while highlighting underexplored frontiers in constrained optimization and agent-oriented prompt design.', 'abstract_zh': '自动提示工程的统一优化理论综述', 'title_zh': '自动提示工程综述：从优化视角'}
{'arxiv_id': 'arXiv:2502.11357', 'title': 'Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents', 'authors': 'Vardaan Pahuja, Yadong Lu, Corby Rosset, Boyu Gou, Arindam Mitra, Spencer Whitehead, Yu Su, Ahmed Awadallah', 'link': 'https://arxiv.org/abs/2502.11357', 'abstract': 'Recent success in large multimodal models (LMMs) has sparked promising applications of agents capable of autonomously completing complex web tasks. While open-source LMM agents have made significant advances in offline evaluation benchmarks, their performance still falls substantially short of human-level capabilities in more realistic online settings. A key bottleneck is the lack of diverse and large-scale trajectory-level datasets across various domains, which are expensive to collect. In this paper, we address this challenge by developing a scalable recipe to synthesize the largest and most diverse trajectory-level dataset to date, containing over 94K successful multimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and 33M web elements. In particular, we leverage extensive web exploration and refinement to obtain diverse task intents. The average cost is 28 cents per successful trajectory, making it affordable to a wide range of users in the community. Leveraging this dataset, we train Explorer, a multimodal web agent, and demonstrate strong performance on both offline and online web agent benchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++. Additionally, our experiments highlight data scaling as a key driver for improving web agent capabilities. We hope this study makes state-of-the-art LMM-based agent research at a larger scale more accessible.', 'abstract_zh': 'Recent成功的大规模多模态模型在自主完成复杂网络任务方面的最新进展激发了代理应用程序的前景。虽然开源的大规模多模态模型代理已经在离线评估基准上取得了显著进展，但在更具现实性的在线环境中，其性能仍然远远低于人类水平。一个关键瓶颈是缺乏跨各种领域的多样化和大规模轨迹级数据集，这些数据集的收集成本高昂。在本文中，我们通过开发一种可扩展的合成方法，解决了这一挑战，合成了迄今为止最大和最多样化的真实数据集，包含超过94000个成功的多模态网络轨迹，覆盖49000个唯一的URL，72万张截图，以及3300万万个网络元素。特别地，我们利用广泛的网络探索和优化来获得多样化的任务意图。平均每成功的轨迹成本为28美分，使得社区中的广泛用户负担得起。利用该数据集，我们训练了Explorer多模态网络代理，并在Mind2Web-Live、Multimodal-Mind2Web和MiniWob++等离线和在线网络代理基准测试中展示了强大的性能。此外，我们的实验强调数据量的扩展是提高网络代理能力的关键驱动力之一。我们希望这项研究能够使更大规模的基于大规模多模态模型的代理研究更加易于获取。', 'title_zh': 'Explorer: 驱动多模态 Web 代理的探索导向的 Web 轨迹扩展'}
{'arxiv_id': 'arXiv:2502.11312', 'title': 'AI Generations: From AI 1.0 to AI 4.0', 'authors': 'Jiahao Wu, Hengxu You, Jing Du', 'link': 'https://arxiv.org/abs/2502.11312', 'abstract': 'This paper proposes that Artificial Intelligence (AI) progresses through several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI), AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of these AI generations is driven by shifting priorities among algorithms, computing power, and data. AI 1.0 ushered in breakthroughs in pattern recognition and information processing, fueling advances in computer vision, natural language processing, and recommendation systems. AI 2.0 built on these foundations through real-time decision-making in digital environments, leveraging reinforcement learning and adaptive planning for agentic AI applications. AI 3.0 extended intelligence into physical contexts, integrating robotics, autonomous vehicles, and sensor-fused control systems to act in uncertain real-world settings. Building on these developments, AI 4.0 puts forward the bold vision of self-directed AI capable of setting its own goals, orchestrating complex training regimens, and possibly exhibiting elements of machine consciousness. This paper traces the historical foundations of AI across roughly seventy years, mapping how changes in technological bottlenecks from algorithmic innovation to high-performance computing to specialized data, have spurred each generational leap. It further highlights the ongoing synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical, regulatory, and philosophical challenges that arise when artificial systems approach (or aspire to) human-like autonomy. Ultimately, understanding these evolutions and their interdependencies is pivotal for guiding future research, crafting responsible governance, and ensuring that AI transformative potential benefits society as a whole.', 'abstract_zh': '本文提出，人工智能（AI）经历了多个重叠的阶段：AI 1.0（信息AI）、AI 2.0（代理AI）、AI 3.0（物理AI），以及现在的 speculative AI 4.0（意识AI）。每个AI阶段均由算法、计算能力和数据方面的优先级转变驱动。AI 1.0 带来了模式识别和信息处理领域的突破，促进了计算机视觉、自然语言处理和推荐系统的进步。AI 2.0 在此基础上通过实时在数字环境中进行决策，并利用强化学习和适应性规划发展了代理AI应用。AI 3.0 将智能扩展到物理场景中，结合了机器人技术、自动驾驶车辆及传感器融合控制系统，在不确定的现实环境中行动。在这些进展的基础上，AI 4.0 提出了自我导向AI的雄心勃勃的愿景，能够设定自己的目标，协调复杂的训练方案，并可能表现出机器意识的元素。本文追溯了跨越大约七十年的AI历史基础，分析了从算法创新到高性能计算再到专用数据导致的技术瓶颈变化，推动了每个阶段的飞跃。它还强调了AI 1.0、2.0、3.0 和 4.0 之间的持续协同效应，并探讨了当人工智能系统接近（或希望具备）人类自主性时所引发的深刻伦理、监管和哲学挑战。最终，了解这些演变及其相互依存关系对于指导未来研究、制定负责任的治理规则并确保人工智能的转型潜力惠及全社会而言至关重要。', 'title_zh': 'AI世代：从AI 1.0到AI 4.0'}
{'arxiv_id': 'arXiv:2502.11295', 'title': 'Game-Of-Goals: Using adversarial games to achieve strategic resilience', 'authors': 'Aditya Ghose, Asjad Khan', 'link': 'https://arxiv.org/abs/2502.11295', 'abstract': 'Our objective in this paper is to develop a machinery that makes a given organizational strategic plan resilient to the actions of competitor agents (adverse environmental actions). We assume that we are given a goal tree representing strategic goals (can also be seen business requirements for a software systems) with the assumption that competitor agents are behaving in a maximally adversarial fashion(opposing actions against our sub goals or goals in general). We use game tree search methods (such as minimax) to select an optimal execution strategy(at a given point in time), such that it can maximize our chances of achieving our (high level) strategic goals. Our machinery helps us determine which path to follow(strategy selection) to achieve the best end outcome. This is done by comparing alternative execution strategies available to us via an evaluation function. Our evaluation function is based on the idea that we want to make our execution plans defensible(future-proof) by selecting execution strategies that make us least vulnerable to adversarial actions by the competitor agents. i.e we want to select an execution strategy such that its leaves minimum room(or options) for the adversary to cause impediment/damage to our business goals/plans.', 'abstract_zh': '本文的目标是开发一种机制，使给定的组织战略计划能够抵御竞争对手代理（负面环境行为）的行动。我们将一个表示战略目标（也可以视为软件系统的需求）的目标树作为输入，并假设竞争对手代理以最大化敌对的方式行为（反对我们的子目标或总体目标）。我们使用游戏树搜索方法（如mini-max）来选择在给定时间点的最优执行策略，以最大化实现我们的（高层次）战略目标的机会。我们的机制帮助我们确定应遵循的路径（策略选择），以实现最佳的最终结果。这通过比较可用的替代执行策略的评估函数来进行。我们的评估函数基于这样的理念：通过选择使我们最不 Vulnerable to 竞争对手敌对行动的执行策略，使我们的执行计划能够防御未来的变化。即，我们希望选择一个执行策略，使其尽可能减少对手对我们业务目标/计划造成阻碍/损害的余地或选项。', 'title_zh': '目标博弈：使用对抗博弈实现战略韧性'}
{'arxiv_id': 'arXiv:2502.11291', 'title': 'Dialogue-based Explanations for Logical Reasoning using Structured Argumentation', 'authors': 'Loan Ho, Stefan Schlobach', 'link': 'https://arxiv.org/abs/2502.11291', 'abstract': 'The problem of explaining inconsistency-tolerant reasoning in knowledge bases (KBs) is a prominent topic in Artificial Intelligence (AI). While there is some work on this problem, the explanations provided by existing approaches often lack critical information or fail to be expressive enough for non-binary conflicts. In this paper, we identify structural weaknesses of the state-of-the-art and propose a generic argumentation-based approach to address these problems. This approach is defined for logics involving reasoning with maximal consistent subsets and shows how any such logic can be translated to argumentation. Our work provides dialogue models as dialectic-proof procedures to compute and explain a query answer wrt inconsistency-tolerant semantics. This allows us to construct dialectical proof trees as explanations, which are more expressive and arguably more intuitive than existing explanation formalisms.', 'abstract_zh': '知识库中容错推理解释问题的结构性弱点及其基于 argumentation 的解决方案', 'title_zh': '基于对话的逻辑推理解释方法：结构化论辩论点分析'}
{'arxiv_id': 'arXiv:2502.11251', 'title': 'Explaining Necessary Truths', 'authors': 'Gülce Kardeş, Simon DeDeo', 'link': 'https://arxiv.org/abs/2502.11251', 'abstract': 'Knowing the truth is rarely enough -- we also seek out reasons why the fact is true. While much is known about how we explain contingent truths, we understand less about how we explain facts, such as those in mathematics, that are true as a matter of logical necessity. We present a framework, based in computational complexity, where explanations for deductive truths co-emerge with discoveries of simplifying steps during the search process. When such structures are missing, we revert, in turn, to error-based reasons, where a (corrected) mistake can serve as fictitious, but explanatory, contingency-cause: not making the mistake serves as a reason why the truth takes the form it does. We simulate human subjects, using GPT-4o, presented with SAT puzzles of varying complexity and reasonableness, validating our theory and showing how its predictions can be tested in future human studies.', 'abstract_zh': '了解真相通常还不够——我们还寻求解释真相的原因。尽管我们对如何解释偶然真理已有较多了解，但对于如何解释数学等逻辑必然为真的事实，我们了解较少。我们提出了一种基于计算复杂性的框架，在这种框架下，演绎真理的解释与简化步骤的发现同时产生于搜索过程中。当这些结构缺失时，我们转而依赖基于错误的解释，其中纠正后的错误可以作为一种虚构但具有解释力的偶然原因：不犯错误本身可成为真相为何具有这种形式的原因。我们使用GPT-4o模拟了人类被试，面对不同复杂性和合理性的SAT谜题，验证了我们的理论，并展示了如何在未来的人类研究中测试其预测。', 'title_zh': '解释必要的真理'}
{'arxiv_id': 'arXiv:2502.11134', 'title': 'Solving Online Resource-Constrained Scheduling for Follow-Up Observation in Astronomy: a Reinforcement Learning Approach', 'authors': 'Yajie Zhang, Ce Yu, Chao Sun, Jizeng Wei, Junhan Ju, Shanjiang Tang', 'link': 'https://arxiv.org/abs/2502.11134', 'abstract': 'In the astronomical observation field, determining the allocation of observation resources of the telescope array and planning follow-up observations for targets of opportunity (ToOs) are indispensable components of astronomical scientific discovery. This problem is computationally challenging, given the online observation setting and the abundance of time-varying factors that can affect whether an observation can be conducted. This paper presents ROARS, a reinforcement learning approach for online astronomical resource-constrained scheduling. To capture the structure of the astronomical observation scheduling, we depict every schedule using a directed acyclic graph (DAG), illustrating the dependency of timing between different observation tasks within the schedule. Deep reinforcement learning is used to learn a policy that can improve the feasible solution by iteratively local rewriting until convergence. It can solve the challenge of obtaining a complete solution directly from scratch in astronomical observation scenarios, due to the high computational complexity resulting from numerous spatial and temporal constraints. A simulation environment is developed based on real-world scenarios for experiments, to evaluate the effectiveness of our proposed scheduling approach. The experimental results show that ROARS surpasses 5 popular heuristics, adapts to various observation scenarios and learns effective strategies with hindsight.', 'abstract_zh': '在天文学观测领域，确定望远镜阵列的观测资源分配和规划随机目标（ToOs）的后续观测是天文学科学发现不可或缺的组成部分。鉴于在线观测设置和影响观测能否进行的时间变化因素众多，这一问题具有很强的计算挑战性。本文提出ROARS，一种用于在线天文资源约束调度的强化学习方法。为了捕捉观测调度结构，我们将每种调度表示为有向无环图（DAG），以说明调度内不同观测任务之间的时间依赖性。采用深度强化学习来学习一个可以通过迭代局部修正直至收敛的策略，以改进可行解。由于存在众多的空间和时间约束，ROARS能够解决直接从头获取完整解的高计算复杂性挑战。基于真实世界场景构建仿真环境以评估我们所提出调度方法的有效性。实验结果表明，ROARS优于5种流行的启发式方法，能够适应各种观测场景并学习有效的策略。', 'title_zh': '基于强化学习的方法解决天文学后续观测的在线资源约束调度问题'}
{'arxiv_id': 'arXiv:2502.10705', 'title': 'CoPEFT: Fast Adaptation Framework for Multi-Agent Collaborative Perception with Parameter-Efficient Fine-Tuning', 'authors': 'Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu', 'link': 'https://arxiv.org/abs/2502.10705', 'abstract': 'Multi-agent collaborative perception is expected to significantly improve perception performance by overcoming the limitations of single-agent perception through exchanging complementary information. However, training a robust collaborative perception model requires collecting sufficient training data that covers all possible collaboration scenarios, which is impractical due to intolerable deployment costs. Hence, the trained model is not robust against new traffic scenarios with inconsistent data distribution and fundamentally restricts its real-world applicability. Further, existing methods, such as domain adaptation, have mitigated this issue by exposing the deployment data during the training stage but incur a high training cost, which is infeasible for resource-constrained agents. In this paper, we propose a Parameter-Efficient Fine-Tuning-based lightweight framework, CoPEFT, for fast adapting a trained collaborative perception model to new deployment environments under low-cost conditions. CoPEFT develops a Collaboration Adapter and Agent Prompt to perform macro-level and micro-level adaptations separately. Specifically, the Collaboration Adapter utilizes the inherent knowledge from training data and limited deployment data to adapt the feature map to new data distribution. The Agent Prompt further enhances the Collaboration Adapter by inserting fine-grained contextual information about the environment. Extensive experiments demonstrate that our CoPEFT surpasses existing methods with less than 1\\% trainable parameters, proving the effectiveness and efficiency of our proposed method.', 'abstract_zh': '基于参数高效微调的轻量级协作感知适应框架CoPEFT', 'title_zh': 'CoPEFT: 多智能体协作感知的快速适应框架及参数高效微调'}
{'arxiv_id': 'arXiv:2502.10568', 'title': 'Observer-Aware Probabilistic Planning Under Partial Observability', 'authors': 'Salomé Lepers, Vincent Thomas, Olivier Buffet', 'link': 'https://arxiv.org/abs/2502.10568', 'abstract': "In this article, we are interested in planning problems where the agent is aware of the presence of an observer, and where this observer is in a partial observability situation. The agent has to choose its strategy so as to optimize the information transmitted by observations. Building on observer-aware Markov decision processes (OAMDPs), we propose a framework to handle this type of problems and thus formalize properties such as legibility, explicability and predictability. This extension of OAMDPs to partial observability can not only handle more realistic problems, but also permits considering dynamic hidden variables of interest. These dynamic target variables allow, for instance, working with predictability, or with legibility problems where the goal might change during execution. We discuss theoretical properties of PO-OAMDPs and, experimenting with benchmark problems, we analyze HSVI's convergence behavior with dedicated initializations and study the resulting strategies.", 'abstract_zh': '在这种情况下，代理意识到观察者的存在，并且观察者处于部分可观性状态。本文探讨了代理如何选择策略以优化通过观察传输的信息。基于观察者感知的马尔可夫决策过程(OAMDP)，我们提出了一种框架来处理此类问题，并由此正规定义了可读性、可解释性和可预测性等性质。将OAMDP扩展到部分可观性不仅能够处理更现实的问题，而且还允许考虑动态的隐藏变量。这些动态目标变量可以在预测问题或执行过程中目标发生变化的可读性问题中发挥作用。讨论了部分可观性-OAMDP的理论性质，并通过基准问题的实验分析了HSVIT策略收敛行为及其初始化策略的选用。', 'title_zh': '在部分可观测性条件下具有观察者意识的概率规划'}
{'arxiv_id': 'arXiv:2502.10477', 'title': 'Knowledge Integration Strategies in Autonomous Vehicle Prediction and Planning: A Comprehensive Survey', 'authors': 'Kumar Manas, Adrian Paschke', 'link': 'https://arxiv.org/abs/2502.10477', 'abstract': 'This comprehensive survey examines the integration of knowledge-based approaches into autonomous driving systems, with a focus on trajectory prediction and planning. We systematically review methodologies for incorporating domain knowledge, traffic rules, and commonsense reasoning into these systems, spanning purely symbolic representations to hybrid neuro-symbolic architectures. In particular, we analyze recent advancements in formal logic and differential logic programming, reinforcement learning frameworks, and emerging techniques that leverage large foundation models and diffusion models for knowledge representation. Organized under a unified literature survey section, our discussion synthesizes the state-of-the-art into a high-level overview, supported by a detailed comparative table that maps key works to their respective methodological categories. This survey not only highlights current trends -- including the growing emphasis on interpretable AI, formal verification in safety-critical systems, and the increased use of generative models in prediction and planning -- but also outlines the challenges and opportunities for developing robust, knowledge-enhanced autonomous driving systems.', 'abstract_zh': '针对自主驾驶系统中知识导向方法的整合：路径预测与规划的研究综述', 'title_zh': '自主驾驶车辆预测与规划中的知识集成策略：一项综合性综述'}
{'arxiv_id': 'arXiv:2502.10428', 'title': 'Dynamic Chain-of-Thought: Towards Adaptive Deep Reasoning', 'authors': 'Libo Wang', 'link': 'https://arxiv.org/abs/2502.10428', 'abstract': "To reduce the cost and consumption of computing resources caused by computational redundancy and delayed reward assignment in long CoT, this research proposes the dynamic chain-of-thought with adaptive reasoning time and steps. The researcher used simulation experiment to simulate the integration of D-CoT through Python 3.13 IDLE combined with a Python simulator based on GPTs. At the same time, the researcher used DeepSeek R1 as a control group to test and compare the performance of the D-CoT simulator in processing MIT OpenCourseWare's linear algebra exam questions. Experimental results show that D-CoT is better than DeepSeek R1 based on long CoT in three indicators: reasoning time, CoT length (reasoning steps) and token count, which achieves a significant reduction in computing resource consumption. In addition, this research has potential value in deep reasoning optimization and can be used as a reference for future dynamic deep reasoning frameworks.", 'abstract_zh': '为了减少由计算冗余和延迟奖励分配在长CoT中导致的计算成本和资源消耗，本文提出了一种具有自适应推理时间和步数的动态链式思考方法。研究人员通过结合基于GPT的Python模拟器和Python 3.13 IDLE进行了仿真实验，将D-CoT进行模拟。同时，研究人员使用DeepSeek R1作为对照组，测试并比较了D-CoT模拟器在处理MIT OpenCourseWare线性代数考试问题时的表现。实验结果表明，D-CoT在推理时间、CoT长度（推理步数）和令牌计数三个指标上优于DeepSeek R1，实现了显著的计算资源消耗减少。此外，本文在深推理优化方面具有潜在价值，并可作为未来动态深推理框架的参考。', 'title_zh': '动态思维链：迈向自适应深度推理'}
{'arxiv_id': 'arXiv:2502.10394', 'title': 'A Coordination-based Approach for Focused Learning in Knowledge-Based Systems', 'authors': 'Abhishek Sharma', 'link': 'https://arxiv.org/abs/2502.10394', 'abstract': 'Recent progress in Learning by Reading and Machine Reading systems has significantly increased the capacity of knowledge-based systems to learn new facts. In this work, we discuss the problem of selecting a set of learning requests for these knowledge-based systems which would lead to maximum Q/A performance. To understand the dynamics of this problem, we simulate the properties of a learning strategy, which sends learning requests to an external knowledge source. We show that choosing an optimal set of facts for these learning systems is similar to a coordination game, and use reinforcement learning to solve this problem. Experiments show that such an approach can significantly improve Q/A performance.', 'abstract_zh': 'Recent进展在阅读学习和机器阅读系统中的知识基于系统学习新事实的能力显著提高。在此工作中，我们讨论了为这些知识基于系统选择一组学习请求的问题，这些请求将导致最大的问答性能。为了理解这个问题的动力学，我们模拟了一种学习策略的属性，该策略向外部知识源发送学习请求。我们证明，为这些学习系统选择一组最优事实类似于一种协调博弈，并使用强化学习来解决这个问题。实验表明，这种方法可以显著提高问答性能。', 'title_zh': '基于协调的聚焦学习方法在知识系统的应用'}
{'arxiv_id': 'arXiv:2502.12128', 'title': 'LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities', 'authors': 'Florian Sestak, Artur Toshev, Andreas Fürst, Günter Klambauer, Andreas Mayr, Johannes Brandstetter', 'link': 'https://arxiv.org/abs/2502.12128', 'abstract': 'Generative models are spearheading recent progress in deep learning, showing strong promise for trajectory sampling in dynamical systems as well. However, while latent space modeling paradigms have transformed image and video generation, similar approaches are more difficult for most dynamical systems. Such systems -- from chemical molecule structures to collective human behavior -- are described by interactions of entities, making them inherently linked to connectivity patterns and the traceability of entities over time. Our approach, LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via Linked Entities), combines the advantages of graph neural networks, i.e., the traceability of entities across time-steps, with the efficiency and scalability of recent advances in image and video generation, where pre-trained encoder and decoder are frozen to enable generative modeling in the latent space. The core idea of LaM-SLidE is to introduce identifier representations (IDs) to allow for retrieval of entity properties, e.g., entity coordinates, from latent system representations and thus enables traceability. Experimentally, across different domains, we show that LaM-SLidE performs favorably in terms of speed, accuracy, and generalizability. (Code is available at this https URL)', 'abstract_zh': '基于连接实体的空间动力系统隐空间建模：LaM-SLidE方法', 'title_zh': 'LaM-SLidE: 联邦实体驱动的空间动态系统潜在空间建模'}
{'arxiv_id': 'arXiv:2502.12108', 'title': 'Using the Path of Least Resistance to Explain Deep Networks', 'authors': 'Sina Salek, Joseph Enguehard', 'link': 'https://arxiv.org/abs/2502.12108', 'abstract': 'Integrated Gradients (IG), a widely used axiomatic path-based attribution method, assigns importance scores to input features by integrating model gradients along a straight path from a baseline to the input. While effective in some cases, we show that straight paths can lead to flawed attributions. In this paper, we identify the cause of these misattributions and propose an alternative approach that treats the input space as a Riemannian manifold, computing attributions by integrating gradients along geodesics. We call this method Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we introduce two techniques: a k-Nearest Neighbours-based approach for smaller models and a Stochastic Variational Inference-based method for larger ones. Additionally, we propose a new axiom, Strong Completeness, extending the axioms satisfied by IG. We show that this property is desirable for attribution methods and that GIG is the only method that satisfies it. Through experiments on both synthetic and real-world data, we demonstrate that GIG outperforms existing explainability methods, including IG.', 'abstract_zh': '基于测地线的综合梯度（Geodesic Integrated Gradients, GIG）方法：一种将输入空间视为黎曼流形、沿测地线积分梯度的归因方法', 'title_zh': '用最小阻力路径解释深度网络'}
{'arxiv_id': 'arXiv:2502.12031', 'title': 'Masked Latent Prediction and Classification for Self-Supervised Audio Representation Learning', 'authors': 'Aurian Quelennec, Pierre Chouteau, Geoffroy Peeters, Slim Essid', 'link': 'https://arxiv.org/abs/2502.12031', 'abstract': 'Recently, self-supervised learning methods based on masked latent prediction have proven to encode input data into powerful representations. However, during training, the learned latent space can be further transformed to extract higher-level information that could be more suited for downstream classification tasks. Therefore, we propose a new method: MAsked latenT Prediction And Classification (MATPAC), which is trained with two pretext tasks solved jointly. As in previous work, the first pretext task is a masked latent prediction task, ensuring a robust input representation in the latent space. The second one is unsupervised classification, which utilises the latent representations of the first pretext task to match probability distributions between a teacher and a student. We validate the MATPAC method by comparing it to other state-of-the-art proposals and conducting ablations studies. MATPAC reaches state-of-the-art self-supervised learning results on reference audio classification datasets such as OpenMIC, GTZAN, ESC-50 and US8K and outperforms comparable supervised methods results for musical auto-tagging on Magna-tag-a-tune.', 'abstract_zh': '基于掩码潜在预测的方法：联合预训练任务的潜在预测与分类 (MAsked latenT Prediction And Classification, MATPAC)', 'title_zh': '掩码潜变量预测与分类用于自监督音频表示学习'}
{'arxiv_id': 'arXiv:2502.12012', 'title': 'Evolving Hard Maximum Cut Instances for Quantum Approximate Optimization Algorithms', 'authors': 'Shuaiqun Pan, Yash J. Patel, Aneta Neumann, Frank Neumann, Thomas Bäck, Hao Wang', 'link': 'https://arxiv.org/abs/2502.12012', 'abstract': "Variational quantum algorithms, such as the Recursive Quantum Approximate Optimization Algorithm (RQAOA), have become increasingly popular, offering promising avenues for employing Noisy Intermediate-Scale Quantum devices to address challenging combinatorial optimization tasks like the maximum cut problem. In this study, we utilize an evolutionary algorithm equipped with a unique fitness function. This approach targets hard maximum cut instances within the latent space of a Graph Autoencoder, identifying those that pose significant challenges or are particularly tractable for RQAOA, in contrast to the classic Goemans and Williamson algorithm. Our findings not only delineate the distinct capabilities and limitations of each algorithm but also expand our understanding of RQAOA's operational limits. Furthermore, the diverse set of graphs we have generated serves as a crucial benchmarking asset, emphasizing the need for more advanced algorithms to tackle combinatorial optimization challenges. Additionally, our results pave the way for new avenues in graph generation research, offering exciting opportunities for future explorations.", 'abstract_zh': '变分量子算法，如递归量子近似优化算法（RQAOA），已成为热门选择，为利用嘈杂的中等规模量子设备解决最大割问题等复杂组合优化任务提供了 promising 的途径。在本研究中，我们采用了一种配备独特fitness函数的进化算法，该方法针对图自编码器潜在空间中的hard最大割实例进行优化，识别出对RQAOA构成显著挑战或特别易于解决的实例，不同于经典的Goemans和Williamson算法。我们的研究不仅界定了每种算法的独特能力和限制，还扩展了对RQAOA操作极限的理解。此外，我们生成的多样化图集为基准测试提供了关键资源，强调了开发更高级算法以应对组合优化挑战的必要性。另外，我们的结果为图生成研究开辟了新的途径，提供了未来探索的激动人心的机会。', 'title_zh': '演化难以切分的最大切实例以优化量子近似优化算法'}
{'arxiv_id': 'arXiv:2502.12007', 'title': 'Demographic Attributes Prediction from Speech Using WavLM Embeddings', 'authors': 'Yuchen Yang, Thomas Thebaud, Najim Dehak', 'link': 'https://arxiv.org/abs/2502.12007', 'abstract': 'This paper introduces a general classifier based on WavLM features, to infer demographic characteristics, such as age, gender, native language, education, and country, from speech. Demographic feature prediction plays a crucial role in applications like language learning, accessibility, and digital forensics, enabling more personalized and inclusive technologies. Leveraging pretrained models for embedding extraction, the proposed framework identifies key acoustic and linguistic fea-tures associated with demographic attributes, achieving a Mean Absolute Error (MAE) of 4.94 for age prediction and over 99.81% accuracy for gender classification across various datasets. Our system improves upon existing models by up to relative 30% in MAE and up to relative 10% in accuracy and F1 scores across tasks, leveraging a diverse range of datasets and large pretrained models to ensure robustness and generalizability. This study offers new insights into speaker diversity and provides a strong foundation for future research in speech-based demographic profiling.', 'abstract_zh': '基于WavLM特征的通用分类器及其在语音中推断人口统计特征的应用：年龄、性别、母语、教育程度和国家的预测', 'title_zh': '使用WavLM嵌入进行语音中的人口统计属性预测'}
{'arxiv_id': 'arXiv:2502.11989', 'title': 'Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images', 'authors': 'Negar Kamali, Karyn Nakamura, Aakriti Kumar, Angelos Chatzimparmpas, Jessica Hullman, Matthew Groh', 'link': 'https://arxiv.org/abs/2502.11989', 'abstract': 'Diffusion model-generated images can appear indistinguishable from authentic photographs, but these images often contain artifacts and implausibilities that reveal their AI-generated provenance. Given the challenge to public trust in media posed by photorealistic AI-generated images, we conducted a large-scale experiment measuring human detection accuracy on 450 diffusion-model generated images and 149 real images. Based on collecting 749,828 observations and 34,675 comments from 50,444 participants, we find that scene complexity of an image, artifact types within an image, display time of an image, and human curation of AI-generated images all play significant roles in how accurately people distinguish real from AI-generated images. Additionally, we propose a taxonomy characterizing artifacts often appearing in images generated by diffusion models. Our empirical observations and taxonomy offer nuanced insights into the capabilities and limitations of diffusion models to generate photorealistic images in 2024.', 'abstract_zh': '基于扩散模型生成的图像在外观上可能与真实照片难以区分，但这些图像往往包含能揭示其AI生成身份的伪影和不合理之处。为应对高保真AI生成图像对媒体公信力的挑战，我们进行了一项大规模实验，评估了450张基于扩散模型生成的图像和149张真实图像的人类识别准确性。基于收集的749,828个观察数据和34,675条评论，我们发现，图像的场景复杂度、图像中的伪影类型、图像展示时间以及人类对AI生成图像的处理，都在决定人们区分真实图像与AI生成图像的准确度方面发挥着重要作用。此外，我们提出了一种分类法，描述常见于扩散模型生成图像中的伪影特征。我们的实证观察结果和分类法为理解扩散模型在2024年生成高保真图像的能力和局限性提供了细腻的见解。', 'title_zh': 'Characterizing 光学真实感和生成图像中的伪像'}
{'arxiv_id': 'arXiv:2502.11981', 'title': 'Machine Learning Should Maximize Welfare, Not (Only) Accuracy', 'authors': 'Nir Rosenfeld, Haifeng Xu', 'link': 'https://arxiv.org/abs/2502.11981', 'abstract': 'Decades of research in machine learning have given us powerful tools for making accurate predictions. But when used in social settings and on human inputs, better accuracy does not immediately translate to better social outcomes. This may not be surprising given that conventional learning frameworks are not designed to express societal preferences -- let alone promote them. This position paper argues that machine learning is currently missing, and can gain much from incorporating, a proper notion of social welfare. The field of welfare economics asks: how should we allocate limited resources to self-interested agents in a way that maximizes social benefit? We argue that this perspective applies to many modern applications of machine learning in social contexts, and advocate for its adoption. Rather than disposing of prediction, we aim to leverage this forte of machine learning for promoting social welfare. We demonstrate this idea by proposing a conceptual framework that gradually transitions from accuracy maximization (with awareness to welfare) to welfare maximization (via accurate prediction). We detail applications and use-cases for which our framework can be effective, identify technical challenges and practical opportunities, and highlight future avenues worth pursuing.', 'abstract_zh': '几十年来机器学习的研究为我们提供了一种强有力的工具，用于进行准确的预测。但在社会环境中使用并应用于人类输入时，更高的准确率并不必然转化为更好的社会结果。鉴于此，传统的学习框架并不旨在表达社会偏好，更不用说促进社会偏好。本文认为，当前的机器学习缺少一个恰当的社会福利概念，同时也能够从融合社会福利概念中获益。福利经济学探讨的问题是，如何在满足自我利益代理人的前提下，分配有限资源以最大化社会利益？我们认为，这一视角适用于许多现代机器学习在社会环境中的应用，并倡导其采纳。我们并非是要抛弃预测，而是要利用机器学习在预测方面的优势来促进社会福利。通过提出一个逐步从注重准确性的福利最大化框架中转变的概念框架，我们展示了这一思想。我们详细阐述了我们的框架可以有效应用于的应用场景，指出了技术挑战和实际机会，并强调了值得进一步探索的未来方向。', 'title_zh': '机器学习应最大化福利，而非（仅）准确性'}
{'arxiv_id': 'arXiv:2502.11968', 'title': 'Theoretical Barriers in Bellman-Based Reinforcement Learning', 'authors': 'Brieuc Pinon, Raphaël Jungers, Jean-Charles Delvenne', 'link': 'https://arxiv.org/abs/2502.11968', 'abstract': 'Reinforcement Learning algorithms designed for high-dimensional spaces often enforce the Bellman equation on a sampled subset of states, relying on generalization to propagate knowledge across the state space. In this paper, we identify and formalize a fundamental limitation of this common approach. Specifically, we construct counterexample problems with a simple structure that this approach fails to exploit. Our findings reveal that such algorithms can neglect critical information about the problems, leading to inefficiencies. Furthermore, we extend this negative result to another approach from the literature: Hindsight Experience Replay learning state-to-state reachability.', 'abstract_zh': '高维空间中设计的强化学习算法通常在采样的状态子集上强制执行贝尔曼方程，依靠泛化在状态空间中传播知识。本文我们识别并形式化了这种常见方法的基本局限性。具体而言，我们构建了一个简单结构的反例问题，这种方法无法充分利用这些结构。我们的发现表明，此类算法可能忽略问题中关键的信息，导致效率低下。此外，我们还将这一负面结果扩展到文献中的另一种方法： hindsight experience replay 在状态间可达性学习中的应用。', 'title_zh': '基于贝尔曼方程的强化学习的理论障碍'}
{'arxiv_id': 'arXiv:2502.11965', 'title': 'A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency', 'authors': 'Jun Jiang, Wenjun Yu, Yunfan Li, Yuan Gao, Shugong Xu', 'link': 'https://arxiv.org/abs/2502.11965', 'abstract': 'In the field of artificial intelligence, self-supervised learning has demonstrated superior generalization capabilities by leveraging large-scale unlabeled datasets for pretraining, which is especially critical for wireless communication models to adapt to a variety of scenarios. This paper innovatively treats Channel State Information (CSI) and Channel Impulse Response (CIR) as naturally aligned multi-modal data and proposes the first MIMO wireless channel foundation model, named CSI-CLIP. By effectively capturing the joint representations of both CIR and CSI, CSI-CLIP exhibits remarkable adaptability across scenarios and robust feature extraction capabilities. Experimental results show that in positioning task, CSI-CLIP reduces the mean error distance by 22%; in beam management task, it increases accuracy by 1% compared to traditional supervised methods, as well as in the channel identification task. These improvements not only highlight the potential and value of CSI-CLIP in integrating sensing and communication but also demonstrate its significant advantages over existing techniques. Moreover, viewing CSI and CIR as multi-modal pairs and contrastive learning for wireless channel foundation model open up new research directions in the domain of MIMO wireless communications.', 'abstract_zh': '在人工智能领域，自监督学习通过利用大规模未标记数据集进行预训练，展示了卓越的泛化能力，特别对于使无线通信模型能够适应各种场景至关重要。本文创新性地将信道状态信息（CSI）和信道冲击响应（CIR）视为天然对齐的多模态数据，并提出首个MIMO无线信道基础模型——CSI-CLIP。通过有效地捕捉CIR和CSI的联合表示，CSI-CLIP表现出出色的适应性和鲁棒的特征提取能力。实验结果显示，在定位任务中，CSI-CLIP将平均误差距离降低了22%；在波束管理任务中，与传统的监督方法相比，准确度提高了1%；在信道识别任务中也表现出了显著的改进。这些改进不仅突显了CSI-CLIP在融合感知与通信中的潜力和价值，还展示了其相对于现有技术的显著优势。此外，将CSI和CIR视为多模态配对，并采用对比学习方法，为MIMO无线通信中的无线信道基础模型开辟了新的研究方向。', 'title_zh': '基于CIR-CSI一致性的一种MIMO无线信道基础模型'}
{'arxiv_id': 'arXiv:2502.11949', 'title': 'Massively Scaling Explicit Policy-conditioned Value Functions', 'authors': 'Nico Bohlinger, Jan Peters', 'link': 'https://arxiv.org/abs/2502.11949', 'abstract': 'We introduce a scaling strategy for Explicit Policy-Conditioned Value Functions (EPVFs) that significantly improves performance on challenging continuous-control tasks. EPVFs learn a value function V({\\theta}) that is explicitly conditioned on the policy parameters, enabling direct gradient-based updates to the parameters of any policy. However, EPVFs at scale struggle with unrestricted parameter growth and efficient exploration in the policy parameter space. To address these issues, we utilize massive parallelization with GPU-based simulators, big batch sizes, weight clipping and scaled peturbations. Our results show that EPVFs can be scaled to solve complex tasks, such as a custom Ant environment, and can compete with state-of-the-art Deep Reinforcement Learning (DRL) baselines like Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC). We further explore action-based policy parameter representations from previous work and specialized neural network architectures to efficiently handle weight-space features, which have not been used in the context of DRL before.', 'abstract_zh': '我们介绍了一种用于显式策略条件价值函数（EPVFs）的扩展策略，该策略显著提高了在具有挑战性的连续控制任务上的性能。', 'title_zh': '大规模扩展显式策略条件值函数'}
{'arxiv_id': 'arXiv:2502.11941', 'title': 'Deep Spatio-Temporal Neural Network for Air Quality Reanalysis', 'authors': 'Ammar Kheder, Benjamin Foreback, Lili Wang, Zhi-Song Liu, Michael Boy', 'link': 'https://arxiv.org/abs/2502.11941', 'abstract': 'Air quality prediction is key to mitigating health impacts and guiding decisions, yet existing models tend to focus on temporal trends while overlooking spatial generalization. We propose AQ-Net, a spatiotemporal reanalysis model for both observed and unobserved stations in the near future. AQ-Net utilizes the LSTM and multi-head attention for the temporal regression. We also propose a cyclic encoding technique to ensure continuous time representation. To learn fine-grained spatial air quality estimation, we incorporate AQ-Net with the neural kNN to explore feature-based interpolation, such that we can fill the spatial gaps given coarse observation stations. To demonstrate the efficiency of our model for spatiotemporal reanalysis, we use data from 2013-2017 collected in northern China for PM2.5 analysis. Extensive experiments show that AQ-Net excels in air quality reanalysis, highlighting the potential of hybrid spatio-temporal models to better capture environmental dynamics, especially in urban areas where both spatial and temporal variability are critical.', 'abstract_zh': '空气质量预測对于减轻健康影响和指导决策至关重要，但现有的模型往往侧重于时间趋势而忽视了空间泛化。我们提出AQ-Net，这是一种时空重分析模型，适用于近未来的实测和非实测站点。AQ-Net利用LSTM和多头注意力机制进行时间回归。同时，我们提出了一种循环编码技术以确保连续的时间表示。为了学习细粒度的空间空气质量估计，我们将AQ-Net与神经kNN结合，通过基于特征的插值来填补粗略观测站点间的空间空白。为了证明我们的模型在时空重分析中的效率，我们使用2013-2017年来自中国北方的PM2.5数据进行分析。 extensive 实验表明，AQ-Net在空气质量重分析中表现出色，突显了混合时空模型更好地捕捉环境动态的潜力，尤其是在空间和时间变异都至关重要的城市地区。', 'title_zh': '深度空间-时间神经网络为空气质量再分析'}
{'arxiv_id': 'arXiv:2502.11937', 'title': 'FitLight: Federated Imitation Learning for Plug-and-Play Autonomous Traffic Signal Control', 'authors': 'Yutong Ye, Yingbo Zhou, Zhusen Liu, Xiao Du, Hao Zhou, Xiang Lian, Mingsong Chen', 'link': 'https://arxiv.org/abs/2502.11937', 'abstract': "Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC) methods have been extensively studied, their practical applications still raise some serious issues such as high learning cost and poor generalizability. This is because the ``trial-and-error'' training style makes RL agents extremely dependent on the specific traffic environment, which also requires a long convergence time. To address these issues, we propose a novel Federated Imitation Learning (FIL)-based framework for multi-intersection TSC, named FitLight, which allows RL agents to plug-and-play for any traffic environment without additional pre-training cost. Unlike existing imitation learning approaches that rely on pre-training RL agents with demonstrations, FitLight allows real-time imitation learning and seamless transition to reinforcement learning. Due to our proposed knowledge-sharing mechanism and novel hybrid pressure-based agent design, RL agents can quickly find a best control policy with only a few episodes. Moreover, for resource-constrained TSC scenarios, FitLight supports model pruning and heterogeneous model aggregation, such that RL agents can work on a micro-controller with merely 16{\\it KB} RAM and 32{\\it KB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art methods, FitLight not only provides a superior starting point but also converges to a better final solution on both real-world and synthetic datasets, even under extreme resource limitations.", 'abstract_zh': '基于联邦拟合学习的多交叉口交通信号控制方法FitLight', 'title_zh': 'FitLight：插拔式自主交通信号控制的联邦模仿学习'}
{'arxiv_id': 'arXiv:2502.11850', 'title': 'Steering the LoCoMotif: Using Domain Knowledge in Time Series Motif Discovery', 'authors': 'Aras Yurtman, Daan Van Wesenbeeck, Wannes Meert, Hendrik Blockeel', 'link': 'https://arxiv.org/abs/2502.11850', 'abstract': 'Time Series Motif Discovery (TSMD) identifies repeating patterns in time series data, but its unsupervised nature might result in motifs that are not interesting to the user. To address this, we propose a framework that allows the user to impose constraints on the motifs to be discovered, where constraints can easily be defined according to the properties of the desired motifs in the application domain. We also propose an efficient implementation of the framework, the LoCoMotif-DoK algorithm. We demonstrate that LoCoMotif-DoK can effectively leverage domain knowledge in real and synthetic data, outperforming other TSMD techniques which only support a limited form of domain knowledge.', 'abstract_zh': '基于约束的时序模式发现框架（基于LoCoMotif-DoK算法）有效地利用领域知识在实际和合成数据中超越了仅支持有限领域知识的其他时序模式发现技术。', 'title_zh': '引导LoCoMotif：在时间序列模因发现中运用领域知识'}
{'arxiv_id': 'arXiv:2502.11840', 'title': 'ChordFormer: A Conformer-Based Architecture for Large-Vocabulary Audio Chord Recognition', 'authors': 'Muhammad Waseem Akram, Stefano Dettori, Valentina Colla, Giorgio Carlo Buttazzo', 'link': 'https://arxiv.org/abs/2502.11840', 'abstract': 'Chord recognition serves as a critical task in music information retrieval due to the abstract and descriptive nature of chords in music analysis. While audio chord recognition systems have achieved significant accuracy for small vocabularies (e.g., major/minor chords), large-vocabulary chord recognition remains a challenging problem. This complexity also arises from the inherent long-tail distribution of chords, where rare chord types are underrepresented in most datasets, leading to insufficient training samples. Effective chord recognition requires leveraging contextual information from audio sequences, yet existing models, such as combinations of convolutional neural networks, bidirectional long short-term memory networks, and bidirectional transformers, face limitations in capturing long-term dependencies and exhibit suboptimal performance on large-vocabulary chord recognition tasks. This work proposes ChordFormer, a novel conformer-based architecture designed to tackle structural chord recognition (e.g., triads, bass, sevenths) for large vocabularies. ChordFormer leverages conformer blocks that integrate convolutional neural networks with transformers, thus enabling the model to capture both local patterns and global dependencies effectively. By addressing challenges such as class imbalance through a reweighted loss function and structured chord representations, ChordFormer outperforms state-of-the-art models, achieving a 2% improvement in frame-wise accuracy and a 6% increase in class-wise accuracy on large-vocabulary chord datasets. Furthermore, ChordFormer excels in handling class imbalance, providing robust and balanced recognition across chord types. This approach bridges the gap between theoretical music knowledge and practical applications, advancing the field of large-vocabulary chord recognition.', 'abstract_zh': 'ChordFormer：一种用于大词汇量和弦识别的新型 conformer 基础架构', 'title_zh': 'ChordFormer：基于Conformer的大型词汇量音频和弦识别架构'}
{'arxiv_id': 'arXiv:2502.11756', 'title': 'On the Computation of the Fisher Information in Continual Learning', 'authors': 'Gido M. van de Ven', 'link': 'https://arxiv.org/abs/2502.11756', 'abstract': 'One of the most popular methods for continual learning with deep neural networks is Elastic Weight Consolidation (EWC), which involves computing the Fisher Information. The exact way in which the Fisher Information is computed is however rarely described, and multiple different implementations for it can be found online. This blog post discusses and empirically compares several often-used implementations, which highlights that many currently reported results for EWC could likely be improved by changing the way the Fisher Information is computed.', 'abstract_zh': '弹性权重汇聚中的Fishers信息计算：多种实现的比较与改进潜力', 'title_zh': '连续学习中 Fisher 信息的计算'}
{'arxiv_id': 'arXiv:2502.11749', 'title': 'JotlasNet: Joint Tensor Low-Rank and Attention-based Sparse Unrolling Network for Accelerating Dynamic MRI', 'authors': 'Yinghao Zhang, Haiyan Gui, Ningdi Yang, Yue Hu', 'link': 'https://arxiv.org/abs/2502.11749', 'abstract': 'Joint low-rank and sparse unrolling networks have shown superior performance in dynamic MRI reconstruction. However, existing works mainly utilized matrix low-rank priors, neglecting the tensor characteristics of dynamic MRI images, and only a global threshold is applied for the sparse constraint to the multi-channel data, limiting the flexibility of the network. Additionally, most of them have inherently complex network structure, with intricate interactions among variables. In this paper, we propose a novel deep unrolling network, JotlasNet, for dynamic MRI reconstruction by jointly utilizing tensor low-rank and attention-based sparse priors. Specifically, we utilize tensor low-rank prior to exploit the structural correlations in high-dimensional data. Convolutional neural networks are used to adaptively learn the low-rank and sparse transform domains. A novel attention-based soft thresholding operator is proposed to assign a unique learnable threshold to each channel of the data in the CNN-learned sparse domain. The network is unrolled from the elaborately designed composite splitting algorithm and thus features a simple yet efficient parallel structure. Extensive experiments on two datasets (OCMR, CMRxRecon) demonstrate the superior performance of JotlasNet in dynamic MRI reconstruction.', 'abstract_zh': '联合低秩和注意力引导稀疏展开网络在动态MRI重建中的应用研究', 'title_zh': 'JotlasNet：联合张量低秩和注意力基于稀疏解卷网络加速动态MRI'}
{'arxiv_id': 'arXiv:2502.11715', 'title': 'Proactive Depot Discovery: A Generative Framework for Flexible Location-Routing', 'authors': 'Site Qu, Guoqiang Hu', 'link': 'https://arxiv.org/abs/2502.11715', 'abstract': "The Location-Routing Problem (LRP), which combines the challenges of facility (depot) locating and vehicle route planning, is critically constrained by the reliance on predefined depot candidates, limiting the solution space and potentially leading to suboptimal outcomes. Previous research on LRP without predefined depots is scant and predominantly relies on heuristic algorithms that iteratively attempt depot placements across a planar area. Such approaches lack the ability to proactively generate depot locations that meet specific geographic requirements, revealing a notable gap in current research landscape. To bridge this gap, we propose a data-driven generative DRL framework, designed to proactively generate depots for LRP without predefined depot candidates, solely based on customer requests data which include geographic and demand information. It can operate in two distinct modes: direct generation of exact depot locations, and the creation of a multivariate Gaussian distribution for flexible depots sampling. By extracting depots' geographic pattern from customer requests data, our approach can dynamically respond to logistical needs, identifying high-quality depot locations that further reduce total routing costs compared to traditional methods. Extensive experiments demonstrate that, for a same group of customer requests, compared with those depots identified through random attempts, our framework can proactively generate depots that lead to superior solution routes with lower routing cost. The implications of our framework potentially extend into real-world applications, particularly in emergency medical rescue and disaster relief logistics, where rapid establishment and adjustment of depot locations are paramount, showcasing its potential in addressing LRP for dynamic and unpredictable environments.", 'abstract_zh': '基于数据驱动生成的DRL框架：在无预设仓库候选情况下解决位置-路径规划问题', 'title_zh': '前瞻性的补给点发现：一种灵活的位置-路由生成框架'}
{'arxiv_id': 'arXiv:2502.11711', 'title': 'Knowledge-aware contrastive heterogeneous molecular graph learning', 'authors': 'Mukun Chen, Jia Wu, Shirui Pan, Fu Lin, Bo Du, Xiuwen Gong, Wenbin Hu', 'link': 'https://arxiv.org/abs/2502.11711', 'abstract': "Molecular representation learning is pivotal in predicting molecular properties and advancing drug design. Traditional methodologies, which predominantly rely on homogeneous graph encoding, are limited by their inability to integrate external knowledge and represent molecular structures across different levels of granularity. To address these limitations, we propose a paradigm shift by encoding molecular graphs into heterogeneous structures, introducing a novel framework: Knowledge-aware Contrastive Heterogeneous Molecular Graph Learning (KCHML). This approach leverages contrastive learning to enrich molecular representations with embedded external knowledge. KCHML conceptualizes molecules through three distinct graph views-molecular, elemental, and pharmacological-enhanced by heterogeneous molecular graphs and a dual message-passing mechanism. This design offers a comprehensive representation for property prediction, as well as for downstream tasks such as drug-drug interaction (DDI) prediction. Extensive benchmarking demonstrates KCHML's superiority over state-of-the-art molecular property prediction models, underscoring its ability to capture intricate molecular features.", 'abstract_zh': '分子表示学习对于预测分子性质和推动药物设计至关重要。传统的 homogeneous 图编码方法受限于无法整合外部知识和在不同粒度级别表示分子结构。为克服这些限制，我们提出了一种新的范式转变，即将分子图编码为异构结构，并引入了一个新的框架：知觉对比异构分子图学习（KCHML）。该方法利用对比学习来通过嵌入外部知识丰富分子表示。KCHML 通过三种不同的图视角——分子视角、元素视角和药理学增强，结合异构分子图和双消息传递机制来概念化分子。该设计为性质预测以及下游任务如药物-药物相互作用（DDI）预测提供了全面的表示。广泛的基准测试表明，KCHML 在分子性质预测模型中表现出色，证明了其捕捉复杂分子特征的能力。', 'title_zh': '知识 Aware 对比异构分子图学习'}
{'arxiv_id': 'arXiv:2502.11687', 'title': 'ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks using Machine Unlearning', 'authors': 'Manaar Alam, Hithem Lamri, Michail Maniatakos', 'link': 'https://arxiv.org/abs/2502.11687', 'abstract': 'Backdoor attacks embed hidden functionalities in deep neural networks (DNN), triggering malicious behavior with specific inputs. Advanced defenses monitor anomalous DNN inferences to detect such attacks. However, concealed backdoors evade detection by maintaining a low pre-deployment attack success rate (ASR) and restoring high ASR post-deployment via machine unlearning. Existing concealed backdoors are often constrained by requiring white-box or black-box access or auxiliary data, limiting their practicality when such access or data is unavailable. This paper introduces ReVeil, a concealed backdoor attack targeting the data collection phase of the DNN training pipeline, requiring no model access or auxiliary data. ReVeil maintains low pre-deployment ASR across four datasets and four trigger patterns, successfully evades three popular backdoor detection methods, and restores high ASR post-deployment through machine unlearning.', 'abstract_zh': '隐蔽后门攻击将隐藏功能嵌入深度神经网络（DNN），在特定输入下触发恶意行为。高级防御措施通过监控异常的DNN推理结果来检测此类攻击。然而，隐蔽后门通过保持低部署前攻击成功率（ASR）并在部署后通过机器遗忘恢复高ASR来规避检测。现有的隐蔽后门往往需要白盒或黑盒访问或辅助数据，这限制了它们在无法获取此类访问或数据时的实用性。本文介绍了一种针对DNN训练管道数据收集阶段的隐蔽后门攻击——ReVeil，该攻击无需模型访问或辅助数据。ReVeil在四个数据集和四种触发模式下保持低部署前ASR，并成功规避了三种流行的后门检测方法，在部署后通过机器遗忘恢复高ASR。', 'title_zh': 'ReVeil: 使用机器忘却对深度神经网络进行不受约束的隐藏后门攻击'}
{'arxiv_id': 'arXiv:2502.11658', 'title': '"I\'m not for sale" -- Perceptions and limited awareness of privacy risks by digital natives about location data', 'authors': 'Antoine Boutet, Victor Morel', 'link': 'https://arxiv.org/abs/2502.11658', 'abstract': "Although mobile devices benefit users in their daily lives in numerous ways, they also raise several privacy concerns. For instance, they can reveal sensitive information that can be inferred from location data. This location data is shared through service providers as well as mobile applications. Understanding how and with whom users share their location data -- as well as users' perception of the underlying privacy risks --, are important notions to grasp in order to design usable privacy-enhancing technologies. In this work, we perform a quantitative and qualitative analysis of smartphone users' awareness, perception and self-reported behavior towards location data-sharing through a survey of n=99 young adult participants (i.e., digital natives). We compare stated practices with actual behaviors to better understand their mental models, and survey participants' understanding of privacy risks before and after the inspection of location traces and the information that can be inferred therefrom.\nOur empirical results show that participants have risky privacy practices: about 54% of participants underestimate the number of mobile applications to which they have granted access to their data, and 33% forget or do not think of revoking access to their data. Also, by using a demonstrator to perform inferences from location data, we observe that slightly more than half of participants (57%) are surprised by the extent of potentially inferred information, and that 47% intend to reduce access to their data via permissions as a result of using the demonstrator. Last, a majority of participants have little knowledge of the tools to better protect themselves, but are nonetheless willing to follow suggestions to improve privacy (51%). Educating people, including digital natives, about privacy risks through transparency tools seems a promising approach.", 'abstract_zh': '尽管移动设备在日常生活中给用户带来了诸多便利，但也引发了一系列隐私问题。例如，它们可能会泄露从位置数据中可以推断出的敏感信息。这些位置数据不仅通过服务提供商，还会通过移动应用程序进行共享。理解用户是如何以及与谁共享其位置数据，以及用户对潜在隐私风险的认知，对于设计易于使用的增强隐私技术至关重要。在本研究中，我们通过对99名年轻成人（即数字原住民）进行调查，开展定量和定性分析，评估他们对位置数据共享的意识、感知和自述行为。我们将声明的实践与实际行为进行比较，以更好地理解他们的心理模型，并在检查位置踪迹及其可推断出的信息之前和之后，了解受访者对隐私风险的理解。我们的实证结果显示，参与者存在风险较高的隐私实践：约54%的参与者低估了已授予数据访问权限的移动应用程序数量，且33%的人忘记了或没有考虑到撤销数据访问权限。此外，通过使用演示器从位置数据中进行推断，我们观察到略多于一半的参与者（57%）对其可推断出的信息范围感到惊讶，并且47%的参与者计划通过调整权限来减少数据访问。最后，大多数参与者虽然对保护自己的工具了解不多，但仍愿意遵循提高隐私的建议（51%）。通过透明工具教育包括数字原住民在内的人们关于隐私风险，似乎是一种有前景的方法。', 'title_zh': '“我不出售”——数字原住民对位置数据隐私风险的感知和有限认识'}
{'arxiv_id': 'arXiv:2502.11651', 'title': 'MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression', 'authors': 'Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang', 'link': 'https://arxiv.org/abs/2502.11651', 'abstract': 'Large vision-language models (LVLMs) have shown great promise in medical applications, particularly in visual question answering (MedVQA) and diagnosis from medical images. However, existing datasets and models often fail to consider critical aspects of medical diagnostics, such as the integration of historical records and the analysis of disease progression over time. In this paper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel dataset for MedVQA that focuses on identifying changes in specific regions between two patient visits. Unlike previous datasets that primarily address single-image questions, MMXU enables multi-image questions, incorporating both current and historical patient data. We demonstrate the limitations of current LVLMs in identifying disease progression on MMXU-\\textit{test}, even those that perform well on traditional benchmarks. To address this, we propose a MedRecord-Augmented Generation (MAG) approach, incorporating both global and regional historical records. Our experiments show that integrating historical records significantly enhances diagnostic accuracy by at least 20\\%, bridging the gap between current LVLMs and human expert performance. Additionally, we fine-tune models with MAG on MMXU-\\textit{dev}, which demonstrates notable improvements. We hope this work could illuminate the avenue of advancing the use of LVLMs in medical diagnostics by emphasizing the importance of historical context in interpreting medical images. Our dataset is released at \\href{this https URL}{this https URL}.', 'abstract_zh': '大型多模态视觉语言模型（LVLMs）在医疗应用中显示出了巨大的潜力，特别是在医学视觉问答（MedVQA）和医学影像诊断方面。然而，现有的数据集和模型往往没有考虑到医疗诊断中的关键方面，如历史记录的整合以及疾病进展的分析。本文介绍了MMXU（多模态和多X光理解），一个专注于识别两名患者访问之间特定区域变化的新数据集。与主要处理单张图像问题的先前数据集不同，MMXU 支持多图像问题，结合了当前和历史患者数据。我们展示了当前LVLMs在MMXU-\\textit{test} 中识别疾病进展的局限性，即使它们在传统基准测试中表现良好。为此，我们提出了MedRecord-Augmented Generation（MAG）方法，结合了全局和区域历史记录。我们的实验表明，整合历史记录至少可以提高20% 的诊断准确性，缩小当前LVLMs与人类专家表现之间的差距。此外，我们使用MAG对MMXU-\\textit{dev} 进行微调，这显示了显著的改进。我们希望这项工作能够强调历史背景在解释医学影像中的重要性，从而促进LVLMs在医疗诊断中的应用。我们的数据集在 \\href{this https URL}{this https URL} 发布。', 'title_zh': 'MMXU: 一种多模态和多X光理解疾病进展数据集'}
{'arxiv_id': 'arXiv:2502.11644', 'title': 'InTec: integrated things-edge computing: a framework for distributing machine learning pipelines in edge AI systems', 'authors': 'Habib Larian, Faramarz Safi-Esfahani', 'link': 'https://arxiv.org/abs/2502.11644', 'abstract': 'With the rapid expansion of the Internet of Things (IoT), sensors, smartphones, and wearables have become integral to daily life, powering smart applications in home automation, healthcare, and intelligent transportation. However, these advancements face significant challenges due to latency and bandwidth constraints imposed by traditional cloud based machine learning (ML) frameworks. The need for innovative solutions is evident as cloud computing struggles with increased latency and network congestion. Previous attempts to offload parts of the ML pipeline to edge and cloud layers have yet to fully resolve these issues, often worsening system response times and network congestion due to the computational limitations of edge devices. In response to these challenges, this study introduces the InTec (Integrated Things Edge Computing) framework, a groundbreaking innovation in IoT architecture. Unlike existing methods, InTec fully leverages the potential of a three tier architecture by strategically distributing ML tasks across the Things, Edge, and Cloud layers. This comprehensive approach enables real time data processing at the point of data generation, significantly reducing latency, optimizing network traffic, and enhancing system reliability. InTec effectiveness is validated through empirical evaluation using the MHEALTH dataset for human motion detection in smart homes, demonstrating notable improvements in key metrics: an 81.56 percent reduction in response time, a 10.92 percent decrease in network traffic, a 9.82 percent improvement in throughput, a 21.86 percent reduction in edge energy consumption, and a 25.83 percent reduction in cloud energy consumption. These advancements establish InTec as a new benchmark for scalable, responsive, and energy efficient IoT applications, demonstrating its potential to revolutionize how the ML pipeline is integrated into Edge AI (EI) systems.', 'abstract_zh': '随物联网（IoT）的快速扩展，传感器、智能手机和可穿戴设备已成为日常生活的一部分，驱动着智能家居、医疗保健和智能交通等领域智能应用的发展。然而，这些进步由于传统基于云的机器学习（ML）框架所施加的延迟和带宽限制而面临重大挑战。随着云计算面临延迟增加和网络拥塞问题，对创新解决方案的需求愈发明显。尽管以往将部分ML管道卸载到边缘和云层的努力仍未完全解决这些问题，反而常常由于边缘设备的计算限制而恶化系统响应时间和网络拥塞。为应对这些挑战，本研究引入了InTec（集成事物边缘计算）框架，这是一种物联网架构上的重大创新。不同于现有方法，InTec通过战略性地将ML任务分布在事物、边缘和云层，充分利用三层架构的潜力。这种综合方法能够在数据生成点进行实时数据处理，显著降低延迟、优化网络流量并增强系统可靠性。通过使用MHEALTH数据集对智能家庭中的人体运动检测进行实证评估，InTec的有效性得到验证，结果显示在关键指标上取得了显著改善：响应时间减少了81.56%，网络流量减少了10.92%，吞吐量提升了9.82%，边缘能耗减少了21.86%，云能耗减少了25.83%。这些进步使InTec成为可扩展、响应迅速且节能的物联网应用的新基准，展示了其潜在能力，即将ML管道集成到边缘AI（Edge AI）系统中进行革命性变革。', 'title_zh': 'InTec: 综合物联网-边缘计算框架：边缘AI系统中分布机器学习管道的框架'}
{'arxiv_id': 'arXiv:2502.11639', 'title': 'Neural Interpretable Reasoning', 'authors': 'Pietro Barbiero, Giuseppe Marra, Gabriele Ciravegna, David Debot, Francesco De Santis, Michelangelo Diligenti, Mateo Espinosa Zarlenga, Francesco Giannini', 'link': 'https://arxiv.org/abs/2502.11639', 'abstract': 'We formalize a novel modeling framework for achieving interpretability in deep learning, anchored in the principle of inference equivariance. While the direct verification of interpretability scales exponentially with the number of variables of the system, we show that this complexity can be mitigated by treating interpretability as a Markovian property and employing neural re-parametrization techniques. Building on these insights, we propose a new modeling paradigm -- neural generation and interpretable execution -- that enables scalable verification of equivariance. This paradigm provides a general approach for designing Neural Interpretable Reasoners that are not only expressive but also transparent.', 'abstract_zh': '我们提出了一个新的建模框架，旨在通过推理协变性原则实现深度学习的可解释性。尽管直接验证可解释性随着系统变量数量的增加呈指数级增长，但我们展示了可以通过将可解释性视为马尔可夫性质并采用神经重参数化技术来缓解这种复杂性。基于这些见解，我们提出了一种新的建模范式——神经生成和可解释执行——以实现可扩展的协变验证。该范式为设计既具有表现力又具有透明性的神经可解释推理器提供了通用方法。', 'title_zh': '神经可解释推理'}
{'arxiv_id': 'arXiv:2502.11617', 'title': 'In-Context Parametric Inference: Point or Distribution Estimators?', 'authors': 'Sarthak Mittal, Yoshua Bengio, Nikolay Malkin, Guillaume Lajoie', 'link': 'https://arxiv.org/abs/2502.11617', 'abstract': "Bayesian and frequentist inference are two fundamental paradigms in statistical estimation. Bayesian methods treat hypotheses as random variables, incorporating priors and updating beliefs via Bayes' theorem, whereas frequentist methods assume fixed but unknown hypotheses, relying on estimators like maximum likelihood. While extensive research has compared these approaches, the frequentist paradigm of obtaining point estimates has become predominant in deep learning, as Bayesian inference is challenging due to the computational complexity and the approximation gap of posterior estimation methods. However, a good understanding of trade-offs between the two approaches is lacking in the regime of amortized estimators, where in-context learners are trained to estimate either point values via maximum likelihood or maximum a posteriori estimation, or full posteriors using normalizing flows, score-based diffusion samplers, or diagonal Gaussian approximations, conditioned on observations. To help resolve this, we conduct a rigorous comparative analysis spanning diverse problem settings, from linear models to shallow neural networks, with a robust evaluation framework assessing both in-distribution and out-of-distribution generalization on tractable tasks. Our experiments indicate that amortized point estimators generally outperform posterior inference, though the latter remain competitive in some low-dimensional problems, and we further discuss why this might be the case.", 'abstract_zh': '贝叶斯和频率主义推理是统计估计的两个基本范式。贝叶斯方法将假设视为随机变量，并通过贝叶斯定理更新先验和信念，而频率主义方法假定假设是固定但未知的，依赖于似然估计量如最大似然估计。尽管已有大量研究对比了这两种方法，但在模型压缩估计器的背景下，频率主义的点估计范式已成为深度学习中的主流，因为贝叶斯推理由于计算复杂性和后验估计方法的近似间隙而具有挑战性。然而，在这种背景下对这两种方法之间权衡的理解仍然不足，其中上下文学习器被训练以通过最大似然估计或最大后似然估计估计点值，或者使用归一化流、基于得分的扩散采样器或对角高斯逼近估计条件下的完整后验分布。为了解决这一问题，我们开展了跨越从线性模型到浅层神经网络的各种问题设置的严谨对比分析，并采用稳健的评估框架评估其在可处理任务中的分布内和分布外泛化能力。实验结果显示，压缩估计器中的点估计通常优于后验推理，尽管在某些低维问题中，后验推理仍具有竞争力，我们进一步讨论了这种现象的原因。', 'title_zh': '上下文相关参数推断：点估计还是分布估计？'}
{'arxiv_id': 'arXiv:2502.11611', 'title': 'Identifying Gender Stereotypes and Biases in Automated Translation from English to Italian using Similarity Networks', 'authors': 'Fatemeh Mohammadi, Marta Annamaria Tamborini, Paolo Ceravolo, Costanza Nardocci, Samira Maghool', 'link': 'https://arxiv.org/abs/2502.11611', 'abstract': "This paper is a collaborative effort between Linguistics, Law, and Computer Science to evaluate stereotypes and biases in automated translation systems. We advocate gender-neutral translation as a means to promote gender inclusion and improve the objectivity of machine translation. Our approach focuses on identifying gender bias in English-to-Italian translations. First, we define gender bias following human rights law and linguistics literature. Then we proceed by identifying gender-specific terms such as she/lei and he/lui as key elements. We then evaluate the cosine similarity between these target terms and others in the dataset to reveal the model's perception of semantic relations. Using numerical features, we effectively evaluate the intensity and direction of the bias. Our findings provide tangible insights for developing and training gender-neutral translation algorithms.", 'abstract_zh': '本论文是语言学、法律和计算机科学的跨学科合作，旨在评估自动化翻译系统中的刻板印象和偏见。我们倡导中性化翻译以促进性别包容并提高机器翻译的客观性。我们的方法侧重于识别英译意中的性别偏见。首先，我们根据人权法和语言学文献定义性别偏见。然后，我们通过识别性别特异性术语（如she/lei和he/lui）作为关键元素来进行分析。接着，我们评估这些目标术语与数据集中其他术语之间的余弦相似度，以揭示模型对语义关系的感知。通过数值特征，我们有效地评估了偏见的强度和方向。我们的发现为开发和训练中性化翻译算法提供了具体的见解。', 'title_zh': '使用相似网络识别从英语到意大利语自动翻译中的性别刻板印象和偏见'}
{'arxiv_id': 'arXiv:2502.11554', 'title': 'Toward Metaphor-Fluid Conversation Design for Voice User Interfaces', 'authors': 'Smit Desai, Jessie Chin, Dakuo Wang, Benjamin Cowan, Michael Twidale', 'link': 'https://arxiv.org/abs/2502.11554', 'abstract': 'Metaphors play a critical role in shaping user experiences with Voice User Interfaces (VUIs), yet existing designs often rely on static, human-centric metaphors that fail to adapt to diverse contexts and user needs. This paper introduces Metaphor-Fluid Design, a novel approach that dynamically adjusts metaphorical representations based on conversational use-contexts. We compare this approach to a Default VUI, which characterizes the present implementation of commercial VUIs commonly designed around the persona of an assistant, offering a uniform interaction style across contexts. In Study 1 (N=130), metaphors were mapped to four key use-contexts-commands, information seeking, sociality, and error recovery-along the dimensions of formality and hierarchy, revealing distinct preferences for task-specific metaphorical designs. Study 2 (N=91) evaluates a Metaphor-Fluid VUI against a Default VUI, showing that the Metaphor-Fluid VUI enhances perceived intention to adopt, enjoyment, and likability by aligning better with user expectations for different contexts. However, individual differences in metaphor preferences highlight the need for personalization. These findings challenge the one-size-fits-all paradigm of VUI design and demonstrate the potential of Metaphor-Fluid Design to create more adaptive and engaging human-AI interactions.', 'abstract_zh': '元喻在塑造语音用户界面（VUI）用户体验中的作用至关重要，现有设计往往依赖固定的人本中心元喻，无法适应多变的使用情境和用户需求。本文介绍了元喻流设计（Metaphor-Fluid Design）这一创新方法，该方法根据对话使用情境动态调整元喻表示。我们将其与一个默认VUI进行比较，后者描述了当前商业VUIs中常见的助手型人物设计，提供一种统一的交互风格，适用于各种情境。研究1（N=130）将元喻映射到四个关键使用情境——命令、信息查询、社交性和错误恢复——并从形式性和层级性维度揭示了对任务特定元喻设计的不同偏好。研究2（N=91）评估了元喻流设计VUI与默认VUI的性能，结果显示元喻流设计VUI通过更好地满足不同情境下用户期望，提高了使用意愿、愉悦感和喜爱度，但个体在元喻偏好的差异凸显了个性化需求。这些发现挑战了VUI设计的一刀切范式，并展示了元喻流设计在创造更具适应性和互动性的类人智能交互方面的潜力。', 'title_zh': '面向元喻流式对话设计的语音用户界面'}
{'arxiv_id': 'arXiv:2502.11519', 'title': 'UniGO: A Unified Graph Neural Network for Modeling Opinion Dynamics on Graphs', 'authors': 'Hao Li, Hao Jiang, Yuke Zheng, Hao Sun, Wenying Gong', 'link': 'https://arxiv.org/abs/2502.11519', 'abstract': "Polarization and fragmentation in social media amplify user biases, making it increasingly important to understand the evolution of opinions. Opinion dynamics provide interpretability for studying opinion evolution, yet incorporating these insights into predictive models remains challenging. This challenge arises due to the inherent complexity of the diversity of opinion fusion rules and the difficulty in capturing equilibrium states while avoiding over-smoothing. This paper constructs a unified opinion dynamics model to integrate different opinion fusion rules and generates corresponding synthetic datasets. To fully leverage the advantages of unified opinion dynamics, we introduces UniGO, a framework for modeling opinion evolution on graphs. Using a coarsen-refine mechanism, UniGO efficiently models opinion dynamics through a graph neural network, mitigating over-smoothing while preserving equilibrium phenomena. UniGO leverages pretraining on synthetic datasets, which enhances its ability to generalize to real-world scenarios, providing a viable paradigm for applications of opinion dynamics. Experimental results on both synthetic and real-world datasets demonstrate UniGO's effectiveness in capturing complex opinion formation processes and predicting future evolution. The pretrained model also shows strong generalization capability, validating the benefits of using synthetic data to boost real-world performance.", 'abstract_zh': '社交媒体中的极化和碎片化放大了用户偏见，使得理解意见演变的演化变得 increasingly important。意见动力学为研究意见演变提供了可解释性，但将这些洞见整合进预测模型仍具有挑战性。这种挑战源于不同意见融合规则的固有复杂性以及捕捉平衡状态的同时避免过度平滑的困难。本文构建了一种统一的意见动力学模型，以整合不同的意见融合规则，并生成相应的合成数据集。为了充分利用统一意见动力学的优势，我们引入了UniGO，这是一种在图上建模意见演变的框架。通过粗化-细化机制，UniGO 通过图神经网络高效地建模意见动力学，减轻过度平滑现象同时保留平衡现象。UniGO 利用合成数据集上的预训练，增强了其泛化到现实场景的能力，为意见动力学的应用提供了一种可行的范式。实验结果表明，UniGO 在捕捉复杂意见形成过程和预测未来演变方面是有效的。预训练模型还展示了强大的泛化能力，验证了使用合成数据提升现实性能的好处。', 'title_zh': 'UniGO：图上意见动力学建模的统一图神经网络'}
{'arxiv_id': 'arXiv:2502.11509', 'title': 'DifCluE: Generating Counterfactual Explanations with Diffusion Autoencoders and modal clustering', 'authors': 'Suparshva Jain, Amit Sangroya, Lovekesh Vig', 'link': 'https://arxiv.org/abs/2502.11509', 'abstract': 'Generating multiple counterfactual explanations for different modes within a class presents a significant challenge, as these modes are distinct yet converge under the same classification. Diffusion probabilistic models (DPMs) have demonstrated a strong ability to capture the underlying modes of data distributions. In this paper, we harness the power of a Diffusion Autoencoder to generate multiple distinct counterfactual explanations. By clustering in the latent space, we uncover the directions corresponding to the different modes within a class, enabling the generation of diverse and meaningful counterfactuals. We introduce a novel methodology, DifCluE, which consistently identifies these modes and produces more reliable counterfactual explanations. Our experimental results demonstrate that DifCluE outperforms the current state-of-the-art in generating multiple counterfactual explanations, offering a significant advance- ment in model interpretability.', 'abstract_zh': '基于类内不同模式的多个对抗解释生成是一项重大挑战，这些模式虽然独立但会在同一分类下收敛。扩散概率模型（DPMs）展示了捕捉数据分布潜在模式的强大能力。本文利用扩散自编码器生成多个不同的对抗解释。通过在隐空间中的聚类，我们发现了对应类内不同模式的方向，从而生成多样且有意义的对抗解释。我们提出了一个新的方法论DifCluE，该方法论一致地识别这些模式并生成更可靠的对抗解释。实验结果表明，DifCluE 在生成多个对抗解释方面优于当前最先进的方法，显著提升了模型的可解释性。', 'title_zh': 'DifCluE：基于扩散自编码器和模态聚类的反事实解释生成'}
{'arxiv_id': 'arXiv:2502.11504', 'title': 'Accelerated Gradient-based Design Optimization Via Differentiable Physics-Informed Neural Operator: A Composites Autoclave Processing Case Study', 'authors': 'Janak M. Patel, Milad Ramezankhani, Anirudh Deodhar, Dagnachew Birru', 'link': 'https://arxiv.org/abs/2502.11504', 'abstract': "Simulation and optimization are crucial for advancing the engineering design of complex systems and processes. Traditional optimization methods require substantial computational time and effort due to their reliance on resource-intensive simulations, such as finite element analysis, and the complexity of rigorous optimization algorithms. Data-agnostic AI-based surrogate models, such as Physics-Informed Neural Operators (PINOs), offer a promising alternative to these conventional simulations, providing drastically reduced inference time, unparalleled data efficiency, and zero-shot super-resolution capability. However, the predictive accuracy of these models is often constrained to small, low-dimensional design spaces or systems with relatively simple dynamics. To address this, we introduce a novel Physics-Informed DeepONet (PIDON) architecture, which extends the capabilities of conventional neural operators to effectively model the nonlinear behavior of complex engineering systems across high-dimensional design spaces and a wide range of dynamic design configurations. This new architecture outperforms existing SOTA models, enabling better predictions across broader design spaces. Leveraging PIDON's differentiability, we integrate a gradient-based optimization approach using the Adam optimizer to efficiently determine optimal design variables. This forms an end-to-end gradient-based optimization framework that accelerates the design process while enhancing scalability and efficiency. We demonstrate the effectiveness of this framework in the optimization of aerospace-grade composites curing processes achieving a 3x speedup in obtaining optimal design variables compared to gradient-free methods. Beyond composites processing, the proposed model has the potential to be used as a scalable and efficient optimization tool for broader applications in advanced engineering and digital twin systems.", 'abstract_zh': '基于物理的深度操作网络在复杂工程系统设计优化中的仿真与优化', 'title_zh': '基于可微物理知情神经算子的加速梯度优化设计：以复合材料 autoclave 加工为例'}
{'arxiv_id': 'arXiv:2502.11470', 'title': 'Optimized detection of cyber-attacks on IoT networks via hybrid deep learning models', 'authors': 'Ahmed Bensaoud, Jugal Kalita', 'link': 'https://arxiv.org/abs/2502.11470', 'abstract': "The rapid expansion of Internet of Things (IoT) devices has increased the risk of cyber-attacks, making effective detection essential for securing IoT networks. This work introduces a novel approach combining Self-Organizing Maps (SOMs), Deep Belief Networks (DBNs), and Autoencoders to detect known and previously unseen attack patterns. A comprehensive evaluation using simulated and real-world traffic data is conducted, with models optimized via Particle Swarm Optimization (PSO). The system achieves an accuracy of up to 99.99% and Matthews Correlation Coefficient (MCC) values exceeding 99.50%. Experiments on NSL-KDD, UNSW-NB15, and CICIoT2023 confirm the model's strong performance across diverse attack types. These findings suggest that the proposed method enhances IoT security by identifying emerging threats and adapting to evolving attack strategies.", 'abstract_zh': '物联网设备的快速扩展增加了网络攻击的风险，有效的检测对于保障物联网网络的安全至关重要。本文提出了一种结合自组织映射（SOM）、深度信念网络（DBN）和自动编码器的新方法，用于检测已知和未知的攻击模式。通过使用模拟和真实世界的流量数据进行全面评估，模型通过粒子群优化（PSO）进行优化。该系统达到了99.99%的准确率和超过99.50的马修斯相关系数（MCC）值。实验结果表明，该方法在NSL-KDD、UNSW-NB15和CICIoT2023数据集上的表现强大，适用于多种攻击类型。这些发现表明，所提出的方法通过识别新兴威胁并适应 evolving攻击策略来增强物联网安全。', 'title_zh': '基于混合深度学习模型的物联网网络 cyber-攻击检测优化'}
{'arxiv_id': 'arXiv:2502.11450', 'title': 'Fishing For Cheap And Efficient Pruners At Initialization', 'authors': 'Ivo Gollini Navarrete, Nicolas Mauricio Cuadrado, Jose Renato Restom, Martin Takáč, Samuel Horváth', 'link': 'https://arxiv.org/abs/2502.11450', 'abstract': "Pruning offers a promising solution to mitigate the associated costs and environmental impact of deploying large deep neural networks (DNNs). Traditional approaches rely on computationally expensive trained models or time-consuming iterative prune-retrain cycles, undermining their utility in resource-constrained settings. To address this issue, we build upon the established principles of saliency (LeCun et al., 1989) and connection sensitivity (Lee et al., 2018) to tackle the challenging problem of one-shot pruning neural networks (NNs) before training (PBT) at initialization. We introduce Fisher-Taylor Sensitivity (FTS), a computationally cheap and efficient pruning criterion based on the empirical Fisher Information Matrix (FIM) diagonal, offering a viable alternative for integrating first- and second-order information to identify a model's structurally important parameters. Although the FIM-Hessian equivalency only holds for convergent models that maximize the likelihood, recent studies (Karakida et al., 2019) suggest that, even at initialization, the FIM captures essential geometric information of parameters in overparameterized NNs, providing the basis for our method. Finally, we demonstrate empirically that layer collapse, a critical limitation of data-dependent pruning methodologies, is easily overcome by pruning within a single training epoch after initialization. We perform experiments on ResNet18 and VGG19 with CIFAR-10 and CIFAR-100, widely used benchmarks in pruning research. Our method achieves competitive performance against state-of-the-art techniques for one-shot PBT, even under extreme sparsity conditions. Our code is made available to the public.", 'abstract_zh': '剪枝提供了一种有希望的解决方案，以减轻部署大规模深度神经网络（DNNs）相关的成本和环境影响。传统方法依赖于计算成本高昂的训练模型或耗时的迭代剪枝-重新训练循环，这在资源受限的环境中限制了其实用性。为了应对这一问题，我们基于显著性（LeCun等，1989）和连接敏感性（Lee等，2018）的原则，提出了一种初始化前超前剪枝神经网络（NNs）的解决方案，即初始化时的一次性剪枝（PBT）。我们引入了Fisher-Taylor敏感性（FTS），这是一种基于经验Fisher信息矩阵（FIM）对角线的计算成本低且高效的剪枝准则，能够利用一阶和二阶信息来识别模型的关键参数。尽管FIM与海森矩阵等价仅在收敛且最大化似然的模型中成立，但最近的研究（Karakida等，2019）表明，在初始化时，FIM能够捕获过度参数化神经网络中参数的关键几何信息，为我们的方法奠定了基础。最后，我们实验证明，数据依赖性剪枝方法中的层崩溃问题可以通过初始化后单个训练周期内的剪枝轻易解决。我们在CIFAR-10和CIFAR-100广泛使用的基准上对ResNet18和VGG19进行了实验。在极端稀疏条件下，我们的方法在一次性PBT中达到了与最先进的技术相当的性能。我们的代码已经开源。', 'title_zh': '初始化时搜索廉价且高效的剪枝器'}
{'arxiv_id': 'arXiv:2502.11333', 'title': 'Inverse Flow and Consistency Models', 'authors': 'Yuchen Zhang, Jian Zhou', 'link': 'https://arxiv.org/abs/2502.11333', 'abstract': "Inverse generation problems, such as denoising without ground truth observations, is a critical challenge in many scientific inquiries and real-world applications. While recent advances in generative models like diffusion models, conditional flow matching, and consistency models achieved impressive results by casting generation as denoising problems, they cannot be directly used for inverse generation without access to clean data. Here we introduce Inverse Flow (IF), a novel framework that enables using these generative models for inverse generation problems including denoising without ground truth. Inverse Flow can be flexibly applied to nearly any continuous noise distribution and allows complex dependencies. We propose two algorithms for learning Inverse Flows, Inverse Flow Matching (IFM) and Inverse Consistency Model (ICM). Notably, to derive the computationally efficient, simulation-free inverse consistency model objective, we generalized consistency training to any forward diffusion processes or conditional flows, which have applications beyond denoising. We demonstrate the effectiveness of IF on synthetic and real datasets, outperforming prior approaches while enabling noise distributions that previous methods cannot support. Finally, we showcase applications of our techniques to fluorescence microscopy and single-cell genomics data, highlighting IF's utility in scientific problems. Overall, this work expands the applications of powerful generative models to inversion generation problems.", 'abstract_zh': '逆生成问题，例如无需地面真相观测的去噪，是许多科学探究和实际应用中的关键挑战。尽管扩散模型、条件流匹配和一致性模型等生成模型的 recent 进展通过将生成问题转换为去噪问题取得了令人印象深刻的成果，但它们无法在缺乏干净数据的情况下直接用于逆生成。我们引入了逆流（Inverse Flow, IF）这一新颖框架，使这些生成模型能够用于包括无需地面真相的去噪在内的逆生成问题。逆流适用于几乎任何连续噪声分布，并允许复杂的依赖关系。我们提出了两种学习逆流的算法：逆流匹配（Inverse Flow Matching, IFM）和逆一致性模型（Inverse Consistency Model, ICM）。特别地，为推导出高效的、无需模拟的逆一致性模型目标，我们将一致性训练推广到任何前向扩散过程或条件流中，这些过程的应用远不止去噪。我们在合成数据和真实数据上展示了逆流的有效性，其性能优于先前方法，并支持之前方法无法处理的噪声分布。最后，我们展示了我们的方法在荧光显微镜和单细胞基因组学数据中的应用，突显了逆流在科学问题中的实用性。整体而言，这项工作扩展了强大生成模型在逆生成问题中的应用。', 'title_zh': '逆流和一致性模型'}
{'arxiv_id': 'arXiv:2502.11298', 'title': 'Integrating Language Models for Enhanced Network State Monitoring in DRL-Based SFC Provisioning', 'authors': 'Parisa Fard Moshiri, Murat Arda Onsu, Poonam Lohan, Burak Kantarci, Emil Janulewicz', 'link': 'https://arxiv.org/abs/2502.11298', 'abstract': 'Efficient Service Function Chain (SFC) provisioning and Virtual Network Function (VNF) placement are critical for enhancing network performance in modern architectures such as Software-Defined Networking (SDN) and Network Function Virtualization (NFV). While Deep Reinforcement Learning (DRL) aids decision-making in dynamic network environments, its reliance on structured inputs and predefined rules limits adaptability in unforeseen scenarios. Additionally, incorrect actions by a DRL agent may require numerous training iterations to correct, potentially reinforcing suboptimal policies and degrading performance. This paper integrates DRL with Language Models (LMs), specifically Bidirectional Encoder Representations from Transformers (BERT) and DistilBERT, to enhance network management. By feeding final VNF allocations from DRL into the LM, the system can process and respond to queries related to SFCs, DCs, and VNFs, enabling real-time insights into resource utilization, bottleneck detection, and future demand planning. The LMs are fine-tuned to our domain-specific dataset using Low-Rank Adaptation (LoRA). Results show that BERT outperforms DistilBERT with a lower test loss (0.28 compared to 0.36) and higher confidence (0.83 compared to 0.74), though BERT requires approximately 46% more processing time.', 'abstract_zh': '基于深度强化学习与语言模型的高效服务功能链配置和虚拟网络功能部署优化', 'title_zh': '基于DRL的SFC提供中语言模型集成以增强网络状态监控'}
{'arxiv_id': 'arXiv:2502.11273', 'title': 'FairFare: A Tool for Crowdsourcing Rideshare Data to Empower Labor Organizers', 'authors': 'Dana Calacci, Varun Nagaraj Rao, Samantha Dalal, Catherine Di, Kok-Wei Pua, Andrew Schwartz, Danny Spitzberg, Andrés Monroy-Hernández', 'link': 'https://arxiv.org/abs/2502.11273', 'abstract': "Rideshare workers experience unpredictable working conditions due to gig work platforms' reliance on opaque AI and algorithmic systems. In response to these challenges, we found that labor organizers want data to help them advocate for legislation to increase the transparency and accountability of these platforms. To address this need, we collaborated with a Colorado-based rideshare union to develop FairFare, a tool that crowdsources and analyzes workers' data to estimate the take rate -- the percentage of the rider price retained by the rideshare platform. We deployed FairFare with our partner organization that collaborated with us in collecting data on 76,000+ trips from 45 drivers over 18 months. During evaluation interviews, organizers reported that FairFare helped influence the bill language and passage of Colorado Senate Bill 24-75, calling for greater transparency and data disclosure of platform operations, and create a national narrative. Finally, we reflect on complexities of translating quantitative data into policy outcomes, nature of community based audits, and design implications for future transparency tools.", 'abstract_zh': '网约车工人因依赖遮蔽的AI和算法系统，而面临不可预测的工作条件。为应对这些挑战，我们发现劳工组织者希望获得数据以帮助他们倡导立法，增加平台的透明度和问责制。为应对这一需求，我们与一家科罗拉多州的网约车工会合作，开发了FairFare工具，该工具通过众筹和分析工人的数据来估算取费率——即网约车平台留存的乘客费用的百分比。我们与合作伙伴共同收集了45名司机在18个月内超过76,000次行程的数据。在评估访谈中，组织者表示，FairFare帮助影响了科罗拉多州参议院第24-75号法案的立法语言和通过，呼吁增加平台运营的透明度和数据披露，并创建了全国性的叙事。最后，我们反思将定量数据转化为政策结果的复杂性、基于社区的审计本质，以及对未来透明度工具设计的影响。', 'title_zh': 'FairFare: 一种用于赋能劳工组织者的数据众包工具'}
{'arxiv_id': 'arXiv:2502.11262', 'title': 'Generating Skyline Datasets for Data Science Models', 'authors': 'Mengying Wang, Hanchao Ma, Yiyang Bian, Yangxin Fan, Yinghui Wu', 'link': 'https://arxiv.org/abs/2502.11262', 'abstract': 'Preparing high-quality datasets required by various data-driven AI and machine learning models has become a cornerstone task in data-driven analysis. Conventional data discovery methods typically integrate datasets towards a single pre-defined quality measure that may lead to bias for downstream tasks. This paper introduces MODis, a framework that discovers datasets by optimizing multiple user-defined, model-performance measures. Given a set of data sources and a model, MODis selects and integrates data sources into a skyline dataset, over which the model is expected to have the desired performance in all the performance measures. We formulate MODis as a multi-goal finite state transducer, and derive three feasible algorithms to generate skyline datasets. Our first algorithm adopts a "reduce-from-universal" strategy, that starts with a universal schema and iteratively prunes unpromising data. Our second algorithm further reduces the cost with a bi-directional strategy that interleaves data augmentation and reduction. We also introduce a diversification algorithm to mitigate the bias in skyline datasets. We experimentally verify the efficiency and effectiveness of our skyline data discovery algorithms, and showcase their applications in optimizing data science pipelines.', 'abstract_zh': '基于多目标优化的高质量数据集发现框架MODis', 'title_zh': '生成数据科学模型的 skyline 数据集'}
{'arxiv_id': 'arXiv:2502.11245', 'title': 'Shortcuts and Identifiability in Concept-based Models from a Neuro-Symbolic Lens', 'authors': 'Samuele Bortolotti, Emanuele Marconato, Paolo Morettin, Andrea Passerini, Stefano Teso', 'link': 'https://arxiv.org/abs/2502.11245', 'abstract': 'Concept-based Models are neural networks that learn a concept extractor to map inputs to high-level concepts and an inference layer to translate these into predictions. Ensuring these modules produce interpretable concepts and behave reliably in out-of-distribution is crucial, yet the conditions for achieving this remain unclear. We study this problem by establishing a novel connection between Concept-based Models and reasoning shortcuts (RSs), a common issue where models achieve high accuracy by learning low-quality concepts, even when the inference layer is fixed and provided upfront. Specifically, we first extend RSs to the more complex setting of Concept-based Models and then derive theoretical conditions for identifying both the concepts and the inference layer. Our empirical results highlight the impact of reasoning shortcuts and show that existing methods, even when combined with multiple natural mitigation strategies, often fail to meet these conditions in practice.', 'abstract_zh': '基于概念的模型是神经网络，学习一个概念提取器将输入映射到高层概念，并通过推理层将这些概念转化为预测。确保这些模块生成可解释的概念并在分布外表现可靠至关重要，但实现这些条件的条件尚不明确。我们通过建立基于概念的模型与推理捷径（RS）之间的新型联系来研究这个问题，推理捷径是一个常见问题，即模型通过学习低质量的概念在推理层固定且预先提供的情况下仍能获得高准确率。具体而言，我们首先将RS扩展到基于概念的模型的更复杂设置，然后推导出识别概念和推理层的理论条件。我们的实证结果强调了推理捷径的影响，并表明现有方法，即使结合了多种自然缓解策略，也往往无法在实践中满足这些条件。', 'title_zh': '基于神经符号视角的概念模型中的捷径与可识别性'}
{'arxiv_id': 'arXiv:2502.11239', 'title': 'Towards identifying possible fault-tolerant advantage of quantum linear system algorithms in terms of space, time and energy', 'authors': 'Yue Tu, Mark Dubynskyi, Mohammad Mohammadisiahroudi, Ekaterina Riashchentceva, Jinglei Cheng, Dmitry Ryashchentsev, Tamás Terlaky, Junyu Liu', 'link': 'https://arxiv.org/abs/2502.11239', 'abstract': "Quantum computing, a prominent non-Von Neumann paradigm beyond Moore's law, can offer superpolynomial speedups for certain problems. Yet its advantages in efficiency for tasks like machine learning remain under investigation, and quantum noise complicates resource estimations and classical comparisons. We provide a detailed estimation of space, time, and energy resources for fault-tolerant superconducting devices running the Harrow-Hassidim-Lloyd (HHL) algorithm, a quantum linear system solver relevant to linear algebra and machine learning. Excluding memory and data transfer, possible quantum advantages over the classical conjugate gradient method could emerge at $N \\approx 2^{33} \\sim 2^{48}$ or even lower, requiring ${O}(10^5)$ physical qubits, ${O}(10^{12}\\sim10^{13})$ Joules, and ${O}(10^6)$ seconds under surface code fault-tolerance with three types of magic state distillation (15-1, 116-12, 225-1). Key parameters include condition number, sparsity, and precision $\\kappa, s\\approx{O}(10\\sim100)$, $\\epsilon\\sim0.01$, and physical error $10^{-5}$. Our resource estimator adjusts $N, \\kappa, s, \\epsilon$, providing a map of quantum-classical boundaries and revealing where a practical quantum advantage may arise. Our work quantitatively determine how advanced a fault-tolerant quantum computer should be to achieve possible, significant benefits on problems related to real-world.", 'abstract_zh': '量子计算：一种超越摩尔定律的 prominant 非冯·诺伊曼范式，对于某些问题可以提供超多项式加速。然而，其在机器学习等任务上的效率优势仍待探究，且量子噪声使得资源估算和经典比较复杂化。我们详细估算了运行 Harrow-Hassidim-Lloyd (HHL) 算法的容错超导器件的空间、时间和能量资源，HHL 算法是线性代数和机器学习中相关的量子线性系统求解器。排除内存和数据传输，与经典的共轭梯度方法相比，可能的量子优势可能在 $N \\approx 2^{33} \\sim 2^{48}$ 或更低出现，需要约 $10^5$ 个物理量子位，约 $10^{12} \\sim 10^{13}$ 焦耳，约 $10^6$ 秒的表面码容错, 并伴有三种类型魔态蒸馏（15-1, 116-12, 225-1）。关键参数包括条件数、稀疏性和精度 $\\kappa, s \\approx O(10 \\sim 100)$, $\\epsilon \\sim 0.01$ 和物理错误 $10^{-5}$。我们的资源估算器调整 $N, \\kappa, s, \\epsilon$，提供量子-经典边界图，并揭示有可能获得实际量子优势的位置。我们的工作定量确定了为了在与实际问题相关的问题上获得潜在的重要益处，一个容错的量子计算机需要达到的先进程度。', 'title_zh': '关于量子线性系统算法在空间、时间和能量方面的容错优势识别'}
{'arxiv_id': 'arXiv:2502.11225', 'title': 'METAFOR: A Hybrid Metaheuristics Software Framework for Single-Objective Continuous Optimization Problems', 'authors': 'Christian Camacho-Villalón, Marco Dorigo, Thomas Stützle', 'link': 'https://arxiv.org/abs/2502.11225', 'abstract': 'Hybrid metaheuristics are powerful techniques for solving difficult optimization problems that exploit the strengths of different approaches in a single implementation. For algorithm designers, however, creating hybrid metaheuristic implementations has become increasingly challenging due to the vast number of design options available in the literature and the fact that they often rely on their knowledge and intuition to come up with new algorithm designs. In this paper, we propose a modular metaheuristic software framework, called METAFOR, that can be coupled with an automatic algorithm configuration tool to automatically design hybrid metaheuristics. METAFOR is specifically designed to hybridize Particle Swarm Optimization, Differential Evolution and Covariance Matrix Adaptation-Evolution Strategy, and includes a local search module that allows their execution to be interleaved with a subordinate local search. We use the configuration tool irace to automatically generate 17 different metaheuristic implementations and evaluate their performance on a diverse set of continuous optimization problems. Our results show that, across all the considered problem classes, automatically generated hybrid implementations are able to outperform configured single-approach implementations, while these latter offer advantages on specific classes of functions. We provide useful insights on the type of hybridization that works best for specific problem classes, the algorithm components that contribute to the performance of the algorithms, and the advantages and disadvantages of two well-known instance separation strategies, creating stratified training set using a fix percentage and leave-one-class-out cross-validation.', 'abstract_zh': '混合元启发式方法是解决困难优化问题的强效技术，能够在单一实现中利用不同方法的优势。然而，对于算法设计师来说，由于文献中可用的配置选项众多，且通常需要依赖其知识和直觉来设计新的算法，因此创建混合元启发式实现变得越来越具挑战性。在本文中，我们提出了一种模块化元启发式软件框架METAFOR，该框架可以与自动算法配置工具结合使用，以自动设计混合元启发式方法。METAFOR专门设计用于混合粒子群优化、差分进化和共(variance matrix adaptation-evolution strategy)演化策略，并包含一个局部搜索模块，允许这些方法的执行与次级局部搜索交错进行。我们使用配置工具irace自动生成17种不同的元启发式实现，并在各种连续优化问题上评估其性能。我们的结果显示，对于所有考虑的问题类别，自动生成的混合实现能够优于配置的单方法实现，而后者在特定函数类别上具有优势。我们提供了关于哪种混合方式最适合特定问题类别、哪些算法组件对算法性能有贡献以及两种知名实例分离策略的优势和劣势的一些有用见解，使用固定百分比和留一类别验证交叉验证构建分层训练集。', 'title_zh': 'METAFOR：单目标连续优化问题的混合元启发式软件框架'}
{'arxiv_id': 'arXiv:2502.11213', 'title': 'Stochastic Optimization of Inventory at Large-scale Supply Chains', 'authors': 'Zhaoyang Larry Jin, Mehdi Maasoumy, Yimin Liu, Zeshi Zheng, Zizhuo Ren', 'link': 'https://arxiv.org/abs/2502.11213', 'abstract': "Today's global supply chains face growing challenges due to rapidly changing market conditions, increased network complexity and inter-dependency, and dynamic uncertainties in supply, demand, and other factors. To combat these challenges, organizations employ Material Requirements Planning (MRP) software solutions to set inventory stock buffers - for raw materials, work-in-process goods, and finished products - to help them meet customer service levels. However, holding excess inventory further complicates operations and can lock up millions of dollars of capital that could be otherwise deployed. Furthermore, most commercially available MRP solutions fall short in considering uncertainties and do not result in optimal solutions for modern enterprises.\nAt C3 AI, we fundamentally reformulate the inventory management problem as a constrained stochastic optimization. We then propose a simulation-optimization framework that minimizes inventory and related costs while maintaining desired service levels. The framework's goal is to find the optimal reorder parameters that minimize costs subject to a pre-defined service-level constraint and all other real-world operational constraints. These optimal reorder parameters can be fed back into an MRP system to drive optimal order placement, or used to place optimal orders directly. This approach has proven successful in reducing inventory levels by 10-35 percent, resulting in hundreds of millions of dollars of economic benefit for major enterprises at a global scale.", 'abstract_zh': '今天全球供应链面临的挑战日益加剧，由于市场条件迅速变化、网络复杂性和相互依赖性增加，以及供应、需求和其他因素的动态不确定性。为应对这些挑战，组织采用物料需求计划（MRP）软件解决方案来设置原材料、在制品和最终产品的库存缓冲，以帮助满足客户服务水平。然而，持有超额库存进一步复杂化了运营，并可能占用数百万美元的资本，否则可用于其他投资。此外，大多数商用MRP解决方案在考虑不确定性方面存在不足，无法为现代企业找到最优解决方案。\n在C3 AI，我们将库存管理问题根本上重新表述为受限随机优化问题。我们还提出了一种仿真-优化框架，旨在在维持所需服务水平的同时最小化库存及相关成本。该框架的目标是找到在满足预定义的服务水平约束和其他所有实际运营约束条件的情况下，能够最小化成本的最佳 reorder 参数。这些最优 reorder 参数可以反馈到MRP系统中以驱动最优订单的下达，或直接用于下达最优订单。这种方法已在全球范围内成功地减少了10-35%的库存水平，为企业带来了数亿美元的经济效益。', 'title_zh': '大规模供应链中的库存随机优化'}
{'arxiv_id': 'arXiv:2502.11181', 'title': 'Improving Scientific Document Retrieval with Concept Coverage-based Query Set Generation', 'authors': 'SeongKu Kang, Bowen Jin, Wonbin Kweon, Yu Zhang, Dongha Lee, Jiawei Han, Hwanjo Yu', 'link': 'https://arxiv.org/abs/2502.11181', 'abstract': "In specialized fields like the scientific domain, constructing large-scale human-annotated datasets poses a significant challenge due to the need for domain expertise. Recent methods have employed large language models to generate synthetic queries, which serve as proxies for actual user queries. However, they lack control over the content generated, often resulting in incomplete coverage of academic concepts in documents. We introduce Concept Coverage-based Query set Generation (CCQGen) framework, designed to generate a set of queries with comprehensive coverage of the document's concepts. A key distinction of CCQGen is that it adaptively adjusts the generation process based on the previously generated queries. We identify concepts not sufficiently covered by previous queries, and leverage them as conditions for subsequent query generation. This approach guides each new query to complement the previous ones, aiding in a thorough understanding of the document. Extensive experiments demonstrate that CCQGen significantly enhances query quality and retrieval performance.", 'abstract_zh': '概念覆盖导向的查询集生成框架（CCQGen）', 'title_zh': '基于概念覆盖的查询集生成以改善科学研究文献检索'}
{'arxiv_id': 'arXiv:2502.11137', 'title': 'Safety Evaluation of DeepSeek Models in Chinese Contexts', 'authors': 'Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Ning Wang, Zhenhong Long, Peijun Yang, Jiaojiao Zhao, Minjie Hua, Chaoyang Ma, Kai Wang, Shiguo Lian', 'link': 'https://arxiv.org/abs/2502.11137', 'abstract': 'Recently, the DeepSeek series of models, leveraging their exceptional reasoning capabilities and open-source strategy, is reshaping the global AI landscape. Despite these advantages, they exhibit significant safety deficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 has a 100\\% attack success rate when processing harmful prompts. Additionally, multiple safety companies and research institutions have confirmed critical safety vulnerabilities in this model. As models demonstrating robust performance in Chinese and English, DeepSeek models require equally crucial safety assessments in both language contexts. However, current research has predominantly focused on safety evaluations in English environments, leaving a gap in comprehensive assessments of their safety performance in Chinese contexts. In response to this gap, this study introduces CHiSafetyBench, a Chinese-specific safety evaluation benchmark. This benchmark systematically evaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across safety categories. The experimental results quantify the deficiencies of these two models in Chinese contexts, providing key insights for subsequent improvements.', 'abstract_zh': '最近，DeepSeek系列模型凭借其卓越的推理能力及开源策略，正在重塑全球AI格局。然而，它们在安全性方面存在显著缺陷。罗伯特智能（Cisco的子公司）与宾夕法尼亚大学合作的研究发现，DeepSeek-R1在处理有害提示时具有100%的攻击成功率，同时还确认了该模型存在多个关键的安全漏洞。尽管DeepSeek模型在中英文环境中均显示出了强劲的表现，但对其中文环境下的安全性评估同样至关重要。然而，当前的研究主要集中在英文环境下的安全评估，忽视了对其在中国情境下的全面安全性能评估。针对这一空白，本研究引入了CHiSafetyBench，一个专门针对中文环境的安全评估基准，系统性地评估了DeepSeek-R1和DeepSeek-V3在中文环境下的安全性，揭示了它们在不同安全类别中的表现。实验结果量化了这两种模型在中国环境中的不足之处，为后续改进提供了关键见解。', 'title_zh': 'DeepSeek模型在中国语境下的安全性评估'}
{'arxiv_id': 'arXiv:2502.11094', 'title': 'SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based on Temporal Masked Transformer', 'authors': 'Zhengyan Sheng, Zhihao Du, Shiliang Zhang, Zhijie Yan, Yexin Yang, Zhenhua Ling', 'link': 'https://arxiv.org/abs/2502.11094', 'abstract': 'This paper presents a dual-stream text-to-speech (TTS) model, SyncSpeech, capable of receiving streaming text input from upstream models while simultaneously generating streaming speech, facilitating seamless interaction with large language models. SyncSpeech has the following advantages: Low latency, as it begins generating streaming speech upon receiving the second text token; High efficiency, as it decodes all speech tokens corresponding to the each arrived text token in one step. To achieve this, we propose a temporal masked transformer as the backbone of SyncSpeech, combined with token-level duration prediction to predict speech tokens and the duration for the next step. Additionally, we design a two-stage training strategy to improve training efficiency and the quality of generated speech. We evaluated the SyncSpeech on both English and Mandarin datasets. Compared to the recent dual-stream TTS models, SyncSpeech significantly reduces the first packet delay of speech tokens and accelerates the real-time factor. Moreover, with the same data scale, SyncSpeech achieves performance comparable to that of traditional autoregressive-based TTS models in terms of both speech quality and robustness. Speech samples are available at this https URL}{this https URL.', 'abstract_zh': '本文提出了一种双流文本到语音（TTS）模型SyncSpeech，能够在接收来自上游模型的流式文本输入的同时生成流式语音，从而与大规模语言模型实现无缝交互。SyncSpeech具有以下优势：低延迟，接收到第二个文本令牌即开始生成流式语音；高效率，通过一步解码计算每个到达文本令牌对应的全部语音令牌。为此，我们以时间掩码变换器作为SyncSpeech的骨干，并结合令牌级时长预测来预测下一个步骤的语音令牌及其时长。此外，我们设计了两阶段训练策略以提高训练效率和生成语音的质量。我们在英语和 Mandarin 数据集上对SyncSpeech进行了评估。与最新的双流TTS模型相比，SyncSpeech显著减少了语音令牌的第一包延迟并加快了实时因子。此外，在相同的数据规模下，SyncSpeech在语音质量与鲁棒性方面均达到了基于自回归的传统TTS模型的性能。语音样本可通过以下链接访问：this https URL、this https URL。', 'title_zh': 'SyncSpeech:基于时间掩码变压器的低延迟高效双流文本-to-语音技术'}
{'arxiv_id': 'arXiv:2502.11085', 'title': 'Towards Data-Efficient Pretraining for Atomic Property Prediction', 'authors': 'Yasir Ghunaim, Hasan Abed Al Kader Hammoud, Bernard Ghanem', 'link': 'https://arxiv.org/abs/2502.11085', 'abstract': "This paper challenges the recent paradigm in atomic property prediction that links progress to growing dataset sizes and computational resources. We show that pretraining on a carefully selected, task-relevant dataset can match or even surpass large-scale pretraining, while using as little as 1/24th of the computational cost. We introduce the Chemical Similarity Index (CSI), a novel metric inspired by computer vision's Fréchet Inception Distance, for molecular graphs which quantifies the alignment between upstream pretraining datasets and downstream tasks. By selecting the most relevant dataset with minimal CSI distance, we show that models pretrained on a smaller, focused dataset consistently outperform those pretrained on massive, mixed datasets such as JMP, even when those larger datasets include the relevant dataset. Counterintuitively, we also find that indiscriminately adding more data can degrade model performance when the additional data poorly aligns with the task at hand. Our findings highlight that quality often outperforms quantity in pretraining for atomic property prediction.", 'abstract_zh': '本文挑战了原子性质预测中数据集规模和计算资源增长驱动进步的近期范式，表明在精心选择的相关任务数据集上的预训练可以达到甚至超越大规模预训练的效果，同时仅使用后者的1/24的计算成本。我们引入了化学相似性指数（CSI），这是一种受计算机视觉的弗雷歇入眼距离启发的新颖指标，用于分子图，量化上游预训练数据集与下游任务的对齐程度。通过选择CSI距离最小的最具相关性的数据集，我们展示出在较小且聚焦的数据集上预训练的模型在各种任务中通常优于在大规模混合数据集（如JMP）上预训练的模型，即使后者包括了相关的数据集。出乎意料的是，我们还发现不分青红皂白地增加数据量在任务不匹配的情况下反而会降低模型性能。我们的研究结果强调，在原子性质预测的预训练中，质量往往胜过数量。', 'title_zh': '面向原子性质预测的数据高效预训练'}
{'arxiv_id': 'arXiv:2502.11070', 'title': 'A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and Research Challenges', 'authors': 'Yuning Jiang, Nay Oo, Qiaoran Meng, Hoon Wei Lim, Biplab Sikdar', 'link': 'https://arxiv.org/abs/2502.11070', 'abstract': 'In the highly interconnected digital landscape of today, safeguarding complex infrastructures against cyber threats has become increasingly challenging due to the exponential growth in the number and complexity of vulnerabilities. Resource constraints necessitate effective vulnerability prioritization strategies, focusing efforts on the most critical risks. This paper presents a systematic literature review of 82 studies, introducing a novel taxonomy that categorizes metrics into severity, exploitability, contextual factors, predictive indicators, and aggregation methods. Our analysis reveals significant gaps in existing approaches and challenges with multi-domain applicability. By emphasizing the need for dynamic, context-aware metrics and scalable solutions, we provide actionable insights to bridge the gap between research and real-world applications. This work contributes to the field by offering a comprehensive framework for evaluating vulnerability prioritization methodologies and setting a research agenda to advance the state of practice.', 'abstract_zh': '在当今高度互联的数字 landscape 中，鉴于漏洞数量和复杂性的指数级增长，保护复杂基础设施免受网络安全威胁变得日益challenge。资源约束催生了有效的漏洞优先级策略，强调应对最关键风险的努力。本文综述了 82 篇相关研究，提出了一种新颖的分类体系，将指标分为严重性、利用性、情境因素、预测性指标和聚合方法。我们的分析揭示了现有方法中的重大缺口和跨领域应用的挑战。通过强调动态、情境感知指标和可扩展解决方案的必要性，我们提供了将研究与实际应用接轨的行动指南。本研究通过提供评估漏洞优先级方法的全面框架并推动研究议程，为该领域做出了贡献。', 'title_zh': '漏洞优先级研究：分类、度量及研究挑战'}
{'arxiv_id': 'arXiv:2502.11068', 'title': 'Accelerating Anchors via Specialization and Feature Transformation', 'authors': 'Haonan Yu, Junhao Liu, Xin Zhang', 'link': 'https://arxiv.org/abs/2502.11068', 'abstract': "Anchors is a popular local model-agnostic explanation technique whose applicability is limited by its computational inefficiency. To address this limitation, we propose a pre-training-based approach to accelerate Anchors without compromising the explanation quality. Our approach leverages the iterative nature of Anchors' algorithm which gradually refines an explanation until it is precise enough for a given input by providing a general explanation that is obtained through pre-training as Anchors' initial explanation. Specifically, we develop a two-step rule transformation process: the horizontal transformation adapts a pre-trained explanation to the current input by replacing features, and the vertical transformation refines the general explanation until it is precise enough for the input. We evaluate our method across tabular, text, and image datasets, demonstrating that it significantly reduces explanation generation time while maintaining fidelity and interpretability, thereby enabling the practical adoption of Anchors in time-sensitive applications.", 'abstract_zh': '基于预训练的Anchors加速方法：在不牺牲解释质量的前提下提高计算效率', 'title_zh': '基于专业化和特征变换的锚点加速方法'}
{'arxiv_id': 'arXiv:2502.11037', 'title': 'Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs', 'authors': 'Xin Gao, Jian Pu', 'link': 'https://arxiv.org/abs/2502.11037', 'abstract': 'Multi-View Representation Learning (MVRL) aims to derive a unified representation from multi-view data by leveraging shared and complementary information across views. However, when views are irregularly missing, the incomplete data can lead to representations that lack sufficiency and consistency. To address this, we propose Multi-View Permutation of Variational Auto-Encoders (MVP), which excavates invariant relationships between views in incomplete data. MVP establishes inter-view correspondences in the latent space of Variational Auto-Encoders, enabling the inference of missing views and the aggregation of more sufficient information. To derive a valid Evidence Lower Bound (ELBO) for learning, we apply permutations to randomly reorder variables for cross-view generation and then partition them by views to maintain invariant meanings under permutations. Additionally, we enhance consistency by introducing an informational prior with cyclic permutations of posteriors, which turns the regularization term into a similarity measure across distributions. We demonstrate the effectiveness of our approach on seven diverse datasets with varying missing ratios, achieving superior performance in multi-view clustering and generation tasks.', 'abstract_zh': '多视图变分自编码器的多视图排列（MVP）：挖掘不完备数据中不变关系以提升表示学习', 'title_zh': '基于vae循环排列的深层不完全多视图学习'}
{'arxiv_id': 'arXiv:2502.11022', 'title': 'MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation', 'authors': 'Zhiqian Qin, Yuanfeng Song, Jinwei Lu, Yuanwei Song, Shuaimin Li, Chen Jason Zhang', 'link': 'https://arxiv.org/abs/2502.11022', 'abstract': 'Natural language interfaces for NoSQL databases are increasingly vital in the big data era, enabling users to interact with complex, unstructured data without deep technical expertise. However, most recent advancements focus on English, leaving a gap for multilingual support. This paper introduces MultiTEND, the first and largest multilingual benchmark for natural language to NoSQL query generation, covering six languages: English, German, French, Russian, Japanese and Mandarin Chinese. Using MultiTEND, we analyze challenges in translating natural language to NoSQL queries across diverse linguistic structures, including lexical and syntactic differences. Experiments show that performance accuracy in both English and non-English settings remains relatively low, with a 4%-6% gap across scenarios like fine-tuned SLM, zero-shot LLM, and RAG for LLM. To address the aforementioned challenges, we introduce MultiLink, a novel framework that bridges the multilingual input to NoSQL query generation gap through a Parallel Linking Process. It breaks down the task into multiple steps, integrating parallel multilingual processing, Chain-of-Thought (CoT) reasoning, and Retrieval-Augmented Generation (RAG) to tackle lexical and structural challenges inherent in multilingual NoSQL generation. MultiLink shows enhancements in all metrics for every language against the top baseline, boosting execution accuracy by about 15% for English and averaging a 10% improvement for non-English languages.', 'abstract_zh': '多语言自然语言接口多模态基准MultiTEND及其应用研究', 'title_zh': '多语言基准：自然语言到NoSQL查询转换的MultTEND'}
{'arxiv_id': 'arXiv:2502.11013', 'title': 'Collaborative Deterministic-Diffusion Model for Probabilistic Urban Spatiotemporal Prediction', 'authors': 'Zhi Sheng, Yuan Yuan, Yudi Zhang, Depeng Jin, Yong Li', 'link': 'https://arxiv.org/abs/2502.11013', 'abstract': 'Accurate prediction of urban spatiotemporal dynamics is essential for enhancing urban management and decision-making. Existing spatiotemporal prediction models are predominantly deterministic, focusing on primary spatiotemporal patterns. However, those dynamics are highly complex, exhibiting multi-modal distributions that are challenging for deterministic models to capture. In this paper, we highlight the critical role of probabilistic prediction in capturing the uncertainties and complexities inherent in spatiotemporal data. While mainstream probabilistic models can capture uncertainty, they struggle with accurately learning primary patterns and often suffer from computational inefficiency. To address these challenges, we propose CoST, which collaborates deterministic and probabilistic models to improve both predictive accuracy and the ability to handle uncertainty. To achieve this, we design a mean-residual decomposition framework, where the mean value is modeled by a deterministic model, and the residual variations are learned by a probabilistic model, specifically diffusion models. Moreover, we introduce a scale-aware diffusion process, which better accounts for spatially heterogeneous dynamics across different regions. Extensive experiments on eight real-world datasets demonstrate that CoST significantly outperforms existing methods in both deterministic and probabilistic metrics, achieving a 20% improvement with low computational cost. CoST bridges the gap between deterministic precision and probabilistic uncertainty, making a significant advancement in the field of urban spatiotemporal prediction.', 'abstract_zh': '准确预测城市时空动态对于改进城市管理与决策至关重要。现有的时空预测模型主要为确定性模型，专注于主要的时空模式。然而，这些动态极为复杂，表现出多模态分布，这给确定性模型带来了极大的挑战。在本文中，我们强调了概率预测在捕捉时空数据中固有的不确定性和复杂性的关键作用。虽然主流的概率模型能够捕捉不确定性，但它们在学习主要模式方面常常遇到困难，并且往往存在计算效率低的问题。为了应对这些挑战，我们提出CoST，该方法结合确定性和概率模型，旨在提高预测准确性和处理不确定性的能力。为此，我们设计了一种均值残差分解框架，其中均值由确定性模型建模，残差变异由概率模型（具体为扩散模型）学习。此外，我们引入了一种尺度感知扩散过程，更好地考虑了不同地区之间时空动态的异质性。在八个真实世界数据集上的广泛实验表明，CoST在确定性和概率性度量上均显著优于现有方法，在较低计算成本下实现了约20%的性能提升。CoST弥合了确定性精确度与概率不确定性之间的鸿沟，为城市时空预测领域带来了重要进展。', 'title_zh': '协作确定性扩散模型及其在城市时空概率预测中的应用'}
{'arxiv_id': 'arXiv:2502.11001', 'title': 'CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening', 'authors': 'Gen Zhou, Sugitha Janarthanan, Yutong Lu, Pingzhao Hu', 'link': 'https://arxiv.org/abs/2502.11001', 'abstract': 'Due to the rise in antimicrobial resistance, identifying novel compounds with antibiotic potential is crucial for combatting this global health issue. However, traditional drug development methods are costly and inefficient. Recognizing the pressing need for more effective solutions, researchers have turned to machine learning techniques to streamline the prediction and development of novel antibiotic compounds. While foundation models have shown promise in antibiotic discovery, current mainstream efforts still fall short of fully leveraging the potential of multimodal molecular data. Recent studies suggest that contrastive learning frameworks utilizing multimodal data exhibit excellent performance in representation learning across various domains. Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning (CL)-based multimodal foundation (MF) model specifically tailored for discovering small molecules with potential antibiotic properties (AP) using three types of molecular data. This model employs 1.6 million bioactive molecules with drug-like properties from the ChEMBL dataset to jointly pretrain three encoders: (1) a transformer-based encoder with rotary position embedding for processing SMILES strings; (2) another transformer-based encoder, incorporating a novel bi-level routing attention mechanism to handle molecular graph representations; and (3) a Morgan fingerprint encoder using a multilayer perceptron, to achieve the contrastive learning purpose. The CL-MFAP outperforms baseline models in antibiotic property prediction by effectively utilizing different molecular modalities and demonstrates superior domain-specific performance when fine-tuned for antibiotic-related property prediction tasks.', 'abstract_zh': '由于抗生素耐药性的上升，识别具有抗菌潜力的新化合物对于应对这一全球健康问题至关重要。然而，传统的药物开发方法成本高且效率低。鉴于更有效解决方案的迫切需要，研究人员转向机器学习技术以简化新型抗菌化合物的预测和开发。尽管基础模型在抗生素发现方面显示出潜力，但当前主流努力尚未充分利用跨模态分子数据的潜力。最新研究表明，利用跨模态数据的对比学习框架在各类领域表现出色。在此基础上，我们引入了CL-MFAP，这是一种基于无监督对比学习（CL）的跨模态基础（MF）模型，专门用于使用三种类型的分子数据发现具有潜在抗菌特性（AP）的小分子。该模型利用来自ChEMBL数据集的160万种具有药理特性的生物活性分子，联合预训练三个编码器：（1）带有旋转位置嵌入的变压器编码器，用于处理SMILES字符串；（2）另一种变压器编码器，结合了一种新颖的双层路由注意力机制，以处理分子图表示；以及（3）使用多层感知器的Morgan指纹编码器，以实现对比学习目的。CL-MFAP 在抗菌特性预测方面优于基线模型，有效地利用了不同的分子模态，并在针对抗菌相关特性预测任务进行微调时表现出更出色的领域特定性能。', 'title_zh': '基于对比学习的多模态基础模型：CL-MFAP在分子性质预测和抗生素筛选中的应用'}
{'arxiv_id': 'arXiv:2502.10999', 'title': 'ControlText: Unlocking Controllable Fonts in Multilingual Text Rendering without Font Annotations', 'authors': 'Bowen Jiang, Yuan Yuan, Xinyi Bai, Zhuoqun Hao, Alyson Yin, Yaojie Hu, Wenyu Liao, Lyle Ungar, Camillo J. Taylor', 'link': 'https://arxiv.org/abs/2502.10999', 'abstract': 'This work demonstrates that diffusion models can achieve font-controllable multilingual text rendering using just raw images without font label annotations. Visual text rendering remains a significant challenge. While recent methods condition diffusion on glyphs, it is impossible to retrieve exact font annotations from large-scale, real-world datasets, which prevents user-specified font control. To address this, we propose a data-driven solution that integrates the conditional diffusion model with a text segmentation model, utilizing segmentation masks to capture and represent fonts in pixel space in a self-supervised manner, thereby eliminating the need for any ground-truth labels and enabling users to customize text rendering with any multilingual font of their choice. The experiment provides a proof of concept of our algorithm in zero-shot text and font editing across diverse fonts and languages, providing valuable insights for the community and industry toward achieving generalized visual text rendering.', 'abstract_zh': '本研究展示了扩散模型可以在无需字体标签注释的情况下，仅使用原始图像实现可控多语言文本渲染。视觉文本渲染仍然是一个重大挑战。尽管最近的方法将扩散模型条件化于字形，但从大规模真实世界数据集中获取精确的字体注释是不可能的，这阻碍了用户指定的字体控制。为解决这一问题，我们提出了一种数据驱动的解决方案，将条件扩散模型与文本分割模型相结合，利用分割掩码在自监督的方式下捕捉和表示字体在像素空间中的信息，从而消除对任何ground-truth标签的需求，使用户能够使用任意选择的多语言字体定制文本渲染。实验提供了在多样字体和语言中零样本文本和字体编辑的算法概念证明，为社区和行业实现通用视觉文本渲染提供了有价值的见解。', 'title_zh': 'ControlText: 在无字体标注的情况下解锁多语言文本渲染的可控字体'}
{'arxiv_id': 'arXiv:2502.10985', 'title': 'Is Elo Rating Reliable? A Study Under Model Misspecification', 'authors': 'Shange Tang, Yuanhao Wang, Chi Jin', 'link': 'https://arxiv.org/abs/2502.10985', 'abstract': "Elo rating, widely used for skill assessment across diverse domains ranging from competitive games to large language models, is often understood as an incremental update algorithm for estimating a stationary Bradley-Terry (BT) model. However, our empirical analysis of practical matching datasets reveals two surprising findings: (1) Most games deviate significantly from the assumptions of the BT model and stationarity, raising questions on the reliability of Elo. (2) Despite these deviations, Elo frequently outperforms more complex rating systems, such as mElo and pairwise models, which are specifically designed to account for non-BT components in the data, particularly in terms of win rate prediction. This paper explains this unexpected phenomenon through three key perspectives: (a) We reinterpret Elo as an instance of online gradient descent, which provides no-regret guarantees even in misspecified and non-stationary settings. (b) Through extensive synthetic experiments on data generated from transitive but non-BT models, such as strongly or weakly stochastic transitive models, we show that the ''sparsity'' of practical matching data is a critical factor behind Elo's superior performance in prediction compared to more complex rating systems. (c) We observe a strong correlation between Elo's predictive accuracy and its ranking performance, further supporting its effectiveness in ranking.", 'abstract_zh': 'Elo评级：基于在线梯度下降的稀疏性视角及预测性能解释', 'title_zh': 'Elo评分可靠吗？基于模型误设的研究'}
{'arxiv_id': 'arXiv:2502.10954', 'title': 'Learning to Stop Overthinking at Test Time', 'authors': 'Hieu Tran Bao, Nguyen Cong Dat, Nguyen Duc Anh, Hoang Thanh Tung', 'link': 'https://arxiv.org/abs/2502.10954', 'abstract': "Test time scaling is currently one of the most active research areas that shows promise after training time scaling has reached its limits. Deep-thinking (DT) models are a class of recurrent models that can perform easy-to-hard generalization by assigning more compute to harder test samples. However, due to their inability to determine the complexity of a test sample, DT models have to use a large amount of computation for both easy and hard test samples. Excessive test time computation is wasteful and can cause the ``overthinking'' problem where more test time computation leads to worse results. In this paper, we introduce a test time training method for determining the optimal amount of computation needed for each sample during test time. We also propose Conv-LiGRU, a novel recurrent architecture for efficient and robust visual reasoning. Extensive experiments demonstrate that Conv-LiGRU is more stable than DT, effectively mitigates the ``overthinking'' phenomenon, and achieves superior accuracy.", 'abstract_zh': '测试时计算量缩放目前是除训练时计算量缩放达到极限后最具潜力的研究领域之一。深度思考（DT）模型是一类递归模型，可以通过为更难的测试样本分配更多的计算资源来实现从易到难的任务泛化。然而，由于无法确定测试样本的复杂度，DT模型在处理易和难的测试样本时都需要大量的计算资源。过度的测试时计算资源浪费，并可能导致“过度思考”问题，即更多的计算资源反而会使结果变差。在本文中，我们提出了一种测试时训练方法，用于确定测试时为每个样本所需的最佳计算量。我们还提出了一种新颖的递归架构Conv-LiGRU，用于高效且稳健的视觉推理。广泛实验表明，Conv-LiGRU 比 DT 更稳定，有效缓解了“过度思考”现象，并获得了更高的准确率。', 'title_zh': '测试时学习停止过度思考'}
{'arxiv_id': 'arXiv:2502.10928', 'title': 'Semantic Specialization in MoE Appears with Scale: A Study of DeepSeek R1 Expert Specialization', 'authors': 'Matthew Lyle Olson, Neale Ratzlaff, Musashi Hinck, Man Luo, Sungduk Yu, Chendi Xue, Vasudev Lal', 'link': 'https://arxiv.org/abs/2502.10928', 'abstract': "DeepSeek-R1, the largest open-source Mixture-of-Experts (MoE) model, has demonstrated reasoning capabilities comparable to proprietary frontier models. Prior research has explored expert routing in MoE models, but findings suggest that expert selection is often token-dependent rather than semantically driven. Given DeepSeek-R1's enhanced reasoning abilities, we investigate whether its routing mechanism exhibits greater semantic specialization than previous MoE models. To explore this, we conduct two key experiments: (1) a word sense disambiguation task, where we examine expert activation patterns for words with differing senses, and (2) a cognitive reasoning analysis, where we assess DeepSeek-R1's structured thought process in an interactive task setting of DiscoveryWorld. We conclude that DeepSeek-R1's routing mechanism is more semantically aware and it engages in structured cognitive processes.", 'abstract_zh': 'DeepSeek-R1，最大的开源Mixture-of-Experts (MoE)模型，展示了与 proprietary 前沿模型相当的推理能力。前期研究探讨了MoE模型中的专家路由机制，发现专家选择往往是基于 token 而非语义驱动的。鉴于DeepSeek-R1增强了推理能力，我们研究其路由机制是否比之前的MoE模型更具语义专一性。为此，我们进行了两项关键实验：(1) 词义消歧实验，分析不同词义词的专家激活模式；(2) 认知推理分析，评估DeepSeek-R1在DiscoveryWorld交互任务中的结构化思维过程。我们得出结论，DeepSeek-R1的路由机制更具有语义意识，并且参与了结构化的认知过程。', 'title_zh': 'MoE中的语义专业化随着规模而出现：DeepSeek R1专家专业化研究'}
{'arxiv_id': 'arXiv:2502.10899', 'title': 'Breaking Down the Hierarchy: A New Approach to Leukemia Classification', 'authors': 'Ibraheem Hamdi, Hosam El-Gendy, Ahmed Sharshar, Mohamed Saeed, Muhammad Ridzuan, Shahrukh K. Hashmi, Naveed Syed, Imran Mirza, Shakir Hussain, Amira Mahmoud Abdalla, Mohammad Yaqub', 'link': 'https://arxiv.org/abs/2502.10899', 'abstract': "The complexities inherent to leukemia, multifaceted cancer affecting white blood cells, pose considerable diagnostic and treatment challenges, primarily due to reliance on laborious morphological analyses and expert judgment that are susceptible to errors. Addressing these challenges, this study presents a refined, comprehensive strategy leveraging advanced deep-learning techniques for the classification of leukemia subtypes. We commence by developing a hierarchical label taxonomy, paving the way for differentiating between various subtypes of leukemia. The research further introduces a novel hierarchical approach inspired by clinical procedures capable of accurately classifying diverse types of leukemia alongside reactive and healthy cells. An integral part of this study involves a meticulous examination of the performance of Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) as classifiers. The proposed method exhibits an impressive success rate, achieving approximately 90\\% accuracy across all leukemia subtypes, as substantiated by our experimental results. A visual representation of the experimental findings is provided to enhance the model's explainability and aid in understanding the classification process.", 'abstract_zh': '白血病的复杂性，一种影响白血球的多面性癌症，由于依赖于耗时的形态学分析和易出错的专家判断，给诊断和治疗带来了重大挑战。为应对这些挑战，本研究提出了一种结合先进深度学习技术的细化综合策略，用于白血病亚型分类。我们首先开发了一种分层标签分类法，以便区分各种白血病亚型。研究还引入了一种受临床程序启发的分层方法，能够准确分类不同类型的白血病以及反应性和健康细胞。本研究的一个重要部分是对卷积神经网络（CNNs）和视觉变换器（ViTs）作为分类器的性能进行了细致分析。所提出的方法表现出色，实验结果证明其在所有白血病亚型上的准确率约为90%。还提供了实验结果的可视化表示，以增强模型的解释性和帮助理解分类过程。', 'title_zh': '打破层级界限：一种新的白血病分类方法'}
{'arxiv_id': 'arXiv:2502.10883', 'title': 'Learning Identifiable Structures Helps Avoid Bias in DNN-based Supervised Causal Learning', 'authors': 'Jiaru Zhang, Rui Ding, Qiang Fu, Bojun Huang, Zizhen Deng, Yang Hua, Haibing Guan, Shi Han, Dongmei Zhang', 'link': 'https://arxiv.org/abs/2502.10883', 'abstract': 'Causal discovery is a structured prediction task that aims to predict causal relations among variables based on their data samples. Supervised Causal Learning (SCL) is an emerging paradigm in this field. Existing Deep Neural Network (DNN)-based methods commonly adopt the "Node-Edge approach", in which the model first computes an embedding vector for each variable-node, then uses these variable-wise representations to concurrently and independently predict for each directed causal-edge. In this paper, we first show that this architecture has some systematic bias that cannot be mitigated regardless of model size and data size. We then propose SiCL, a DNN-based SCL method that predicts a skeleton matrix together with a v-tensor (a third-order tensor representing the v-structures). According to the Markov Equivalence Class (MEC) theory, both the skeleton and the v-structures are identifiable causal structures under the canonical MEC setting, so predictions about skeleton and v-structures do not suffer from the identifiability limit in causal discovery, thus SiCL can avoid the systematic bias in Node-Edge architecture, and enable consistent estimators for causal discovery. Moreover, SiCL is also equipped with a specially designed pairwise encoder module with a unidirectional attention layer to model both internal and external relationships of pairs of nodes. Experimental results on both synthetic and real-world benchmarks show that SiCL significantly outperforms other DNN-based SCL approaches.', 'abstract_zh': '因果发现是一种结构化预测任务，旨在基于变量的数据样本预测变量之间的因果关系。监督因果学习（SCL）是该领域的新兴范式。现有的基于深度神经网络（DNN）的方法通常采用“节点-边”方法，在这种方法中，模型首先为每个变量节点计算一个嵌入向量，然后使用这些变量智慧的表示来独立预测每个有向因果边。在本文中，我们首先表明，这种架构存在一些系统偏差，无论模型规模和数据规模如何都无法缓解。然后，我们提出了一个基于DNN的SCL方法SiCL，它同时预测一个骨架矩阵和一个v-张量（表示v-结构的三阶张量）。根据马尔可夫等价类（MEC）理论，在标准的MEC设置下，骨架和v-结构都是可识别的因果结构，因此关于骨架和v-结构的预测不会受到因果发现中的可识别性限制，因此SiCL可以避免节点-边架构的系统偏差，从而实现因果发现的一致估计器。此外，SiCL还配备了用于建模节点对的内部和外部关系的特制成对编码模块，具有单向注意力层。在合成数据和真实世界基准上的实验结果表明，SiCL显著优于其他基于DNN的SCL方法。', 'title_zh': '基于DNN的监督因果学习中可识别结构的学习有助于避免偏差'}
{'arxiv_id': 'arXiv:2502.10878', 'title': 'Broadcast Channel Cooperative Gain: An Operational Interpretation of Partial Information Decomposition', 'authors': 'Chao Tian, Shlomo Shamai', 'link': 'https://arxiv.org/abs/2502.10878', 'abstract': 'Partial information decomposition has recently found applications in biological signal processing and machine learning. Despite its impacts, the decomposition was introduced through an informal and heuristic route, and its exact operational meaning is unclear. In this work, we fill this gap by connecting partial information decomposition to the capacity of the broadcast channel, which has been well-studied in the information theory literature. We show that the synergistic information in the decomposition can be rigorously interpreted as the cooperative gain, or a lower bound of this gain, on the corresponding broadcast channel. This interpretation can help practitioners to better explain and expand the applications of the partial information decomposition technique.', 'abstract_zh': '部分信息分解最近在生物信号处理和机器学习中找到了应用。尽管如此，该分解最初是通过非正式和启发式的方式引入的，其精确的操作含义尚不明确。在本文中，我们通过将部分信息分解与广播信道的容量联系起来，填补了这一空白，而广播信道的容量已在信息理论文献中得到了充分研究。我们证明，在分解中的协同信息可以严格解释为相应广播信道的合作增益，或者这一增益的下界。这一解释有助于实践者更好地解释和扩展部分信息分解技术的应用。', 'title_zh': '广播信道协同增益：部分信息分解的操作性解释'}
{'arxiv_id': 'arXiv:2502.10875', 'title': 'A Geometric Approach to Personalized Recommendation with Set-Theoretic Constraints Using Box Embeddings', 'authors': 'Shib Dasgupta, Michael Boratko, Andrew McCallum', 'link': 'https://arxiv.org/abs/2502.10875', 'abstract': 'Personalized item recommendation typically suffers from data sparsity, which is most often addressed by learning vector representations of users and items via low-rank matrix factorization. While this effectively densifies the matrix by assuming users and movies can be represented by linearly dependent latent features, it does not capture more complicated interactions. For example, vector representations struggle with set-theoretic relationships, such as negation and intersection, e.g. recommending a movie that is "comedy and action, but not romance". In this work, we formulate the problem of personalized item recommendation as matrix completion where rows are set-theoretically dependent. To capture this set-theoretic dependence we represent each user and attribute by a hyper-rectangle or box (i.e. a Cartesian product of intervals). Box embeddings can intuitively be understood as trainable Venn diagrams, and thus not only inherently represent similarity (via the Jaccard index), but also naturally and faithfully support arbitrary set-theoretic relationships. Queries involving set-theoretic constraints can be efficiently computed directly on the embedding space by performing geometric operations on the representations. We empirically demonstrate the superiority of box embeddings over vector-based neural methods on both simple and complex item recommendation queries by up to 30 \\% overall.', 'abstract_zh': '个性化项目推荐通常受到数据稀疏性的困扰，这通常通过低秩矩阵分解学习用户和项目的向量表示来解决。虽然这种方法通过假设用户和电影可以由线性相关的隐特征来表示有效地填充了矩阵，但它没有捕捉到更复杂的交互。例如，向量表示在处理集合论关系方面存在困难，如否定和交集，例如推荐一部“喜剧和动作，但不是浪漫”的电影。在本工作中，我们将个性化项目推荐问题形式化为矩阵完成问题，其中行是集合论上相关的。为了捕捉这种集合论上的依赖关系，我们将每个用户和属性表示为超矩形或盒子（即区间的笛卡尔积）。盒嵌入可以直观地理解为可训练的文恩图，因而不仅内含表示相似性（通过雅卡德指数），而且自然且忠实支持任意的集合论关系。涉及集合论约束的查询可以通过在嵌入空间上执行几何操作直接高效地计算。我们通过至多30%的整体优势，经验上证明盒嵌入在简单和复杂的项目推荐查询中优于基于向量的神经方法。', 'title_zh': '基于集合约束的盒嵌入的个性化推荐的几何方法'}
{'arxiv_id': 'arXiv:2502.10828', 'title': 'The Vendiscope: An Algorithmic Microscope For Data Collections', 'authors': 'Amey P. Pasarkar, Adji Bousso Dieng', 'link': 'https://arxiv.org/abs/2502.10828', 'abstract': 'The evolution of microscopy, beginning with its invention in the late 16th century, has continuously enhanced our ability to explore and understand the microscopic world, enabling increasingly detailed observations of structures and phenomena. In parallel, the rise of data-driven science has underscored the need for sophisticated methods to explore and understand the composition of complex data collections. This paper introduces the Vendiscope, the first algorithmic microscope designed to extend traditional microscopy to computational analysis. The Vendiscope leverages the Vendi scores -- a family of differentiable diversity metrics rooted in ecology and quantum mechanics -- and assigns weights to data points based on their contribution to the overall diversity of the collection. These weights enable high-resolution data analysis at scale. We demonstrate this across biology, materials science, and machine learning (ML). We analyzed the $250$ million protein sequences in the protein universe, discovering that over $200$ million are near-duplicates and that AlphaFold fails on proteins with Gene Ontology (GO) functions that contribute most to diversity. Applying the Vendiscope to the Materials Project database led to similar findings: more than $85\\%$ of the crystals with formation energy data are near-duplicates and ML models perform poorly on materials that enhance diversity. Additionally, the Vendiscope can be used to study phenomena such as memorization in generative models. We used the Vendiscope to identify memorized training samples from $13$ different generative models and found that the best-performing ones often memorize the training samples that contribute least to diversity. Our findings demonstrate that the Vendiscope can serve as a powerful tool for data-driven science.', 'abstract_zh': '显微镜的发展始于16世纪末的发明，不断增强了我们探索和理解微观世界的能力，使我们能够越来越详细地观察结构和现象。同时，数据驱动科学的兴起强调了探索和理解复杂数据集组成所需的先进方法的重要性。本文介绍了Vendiscope，这是第一个算法显微镜，旨在将传统显微镜扩展到计算分析。Vendiscope利用了Vendi分数——一种根植于生态学和量子力学的可微分多样性度量——并根据数据点对整体多样性贡献的大小为其分配权重。这些权重使大规模高分辨率数据分析成为可能。我们在生物学、材料科学和机器学习（ML）领域进行了验证。我们分析了蛋白质宇宙中的2.5亿条蛋白质序列，发现其中超过2亿条是近似重复序列，并且AlphaFold在基因 ontology (GO) 功能对多样性贡献最大的蛋白质上表现不佳。将Vendiscope应用于Materials Project数据库也得到了类似的发现：超过85%带有形成能量数据的晶体是近似重复序列，而机器学习模型在促进多样性的材料上表现不佳。此外，Vendiscope还可以用于研究生成模型中的记忆现象。我们使用Vendiscope从13个不同的生成模型中识别出了记忆训练样本，并发现表现最佳的模型往往记忆的是对多样性贡献最少的训练样本。我们的发现证明Vendiscope可以作为一种强大的数据驱动科学工具。', 'title_zh': 'Vendiscope: 一种数据集合的算法显微镜'}
{'arxiv_id': 'arXiv:2502.10825', 'title': 'MITRE ATT&CK Applications in Cybersecurity and The Way Forward', 'authors': 'Yuning Jiang, Qiaoran Meng, Feiyang Shang, Nay Oo, Le Thi Hong Minh, Hoon Wei Lim, Biplab Sikdar', 'link': 'https://arxiv.org/abs/2502.10825', 'abstract': 'The MITRE ATT&CK framework is a widely adopted tool for enhancing cybersecurity, supporting threat intelligence, incident response, attack modeling, and vulnerability prioritization. This paper synthesizes research on its application across these domains by analyzing 417 peer-reviewed publications. We identify commonly used adversarial tactics, techniques, and procedures (TTPs) and examine the integration of natural language processing (NLP) and machine learning (ML) with ATT&CK to improve threat detection and response. Additionally, we explore the interoperability of ATT&CK with other frameworks, such as the Cyber Kill Chain, NIST guidelines, and STRIDE, highlighting its versatility. The paper further evaluates the framework from multiple perspectives, including its effectiveness, validation methods, and sector-specific challenges, particularly in industrial control systems (ICS) and healthcare. We conclude by discussing current limitations and proposing future research directions to enhance the applicability of ATT&CK in dynamic cybersecurity environments.', 'abstract_zh': 'MITRE ATT&CK框架在增强网络安全、支持威胁情报、事件响应、攻击建模和漏洞优先级排序中的应用综述：基于417篇同行评审出版物的分析及其与其他框架的互操作性与挑战', 'title_zh': 'MITRE ATT&CK在 cybersecurity 中的应用及未来发展方向'}
{'arxiv_id': 'arXiv:2502.10822', 'title': 'NeuroAMP: A Novel End-to-end General Purpose Deep Neural Amplifier for Personalized Hearing Aids', 'authors': 'Shafique Ahmed, Ryandhimas E. Zezario, Hui-Guan Yuan, Amir Hussain, Hsin-Min Wang, Wei-Ho Chung, Yu Tsao', 'link': 'https://arxiv.org/abs/2502.10822', 'abstract': "The prevalence of hearing aids is increasing. However, optimizing the amplification processes of hearing aids remains challenging due to the complexity of integrating multiple modular components in traditional methods. To address this challenge, we present NeuroAMP, a novel deep neural network designed for end-to-end, personalized amplification in hearing aids. NeuroAMP leverages both spectral features and the listener's audiogram as inputs, and we investigate four architectures: Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Convolutional Recurrent Neural Network (CRNN), and Transformer. We also introduce Denoising NeuroAMP, an extension that integrates noise reduction along with amplification capabilities for improved performance in real-world scenarios. To enhance generalization, a comprehensive data augmentation strategy was employed during training on diverse speech (TIMIT and TMHINT) and music (Cadenza Challenge MUSIC) datasets. Evaluation using the Hearing Aid Speech Perception Index (HASPI), Hearing Aid Speech Quality Index (HASQI), and Hearing Aid Audio Quality Index (HAAQI) demonstrates that the Transformer architecture within NeuroAMP achieves the best performance, with SRCC scores of 0.9927 (HASQI) and 0.9905 (HASPI) on TIMIT, and 0.9738 (HAAQI) on the Cadenza Challenge MUSIC dataset. Notably, our data augmentation strategy maintains high performance on unseen datasets (e.g., VCTK, MUSDB18-HQ). Furthermore, Denoising NeuroAMP outperforms both the conventional NAL-R+WDRC approach and a two-stage baseline on the VoiceBank+DEMAND dataset, achieving a 10% improvement in both HASPI (0.90) and HASQI (0.59) scores. These results highlight the potential of NeuroAMP and Denoising NeuroAMP to deliver notable improvements in personalized hearing aid amplification.", 'abstract_zh': '听觉辅助设备的使用率正在增加。然而，由于传统方法中多种模块组件集成的复杂性，优化听觉辅助设备的放大过程仍然具有挑战性。为应对这一挑战，我们提出了NeuroAMP，这是一种用于听觉辅助设备端到端个性化放大处理的新型深度神经网络。NeuroAMP利用频谱特征和听者的听力图作为输入，并探讨了四种架构：卷积神经网络（CNN）、长短期记忆网络（LSTM）、卷积循环神经网络（CRNN）和Transformer。此外，我们还引入了去噪NeuroAMP，这是一种结合了降噪和放大能力的扩展，以在实际场景中提高性能。为了增强泛化能力，在不同语音（TIMIT和TMHINT）和音乐（Cadenza Challenge MUSIC）数据集上进行训练时，采取了全面的数据增强策略。使用听觉辅助设备言语感知指数（HASPI）、听觉辅助设备言语质量指数（HASQI）和听觉辅助设备音频质量指数（HAAQI）进行了评估，结果显示NeuroAMP中的Transformer架构性能最佳，TIMIT数据集上的SRCC评分为0.9927（HASQI）和0.9905（HASPI），Cadenza Challenge MUSIC数据集上的评分为0.9738（HAAQI）。值得注意的是，我们的数据增强策略在未见过的数据集（如VCTK、MUSDB18-HQ）上也保持了高性能。此外，去噪NeuroAMP在VoiceBank+DEMAND数据集上的表现优于传统的NAL-R+WDRC方法和两阶段基线，分别在HASPI和HASQI分数上提高了10%（0.90和0.59）。这些结果突显了NeuroAMP和去噪NeuroAMP在个性化听觉辅助设备放大方面具有显著的改进潜力。', 'title_zh': 'NeuroAMP：一种新型端到端通用深度神经放大器，用于个性化助听器'}
{'arxiv_id': 'arXiv:2502.10818', 'title': 'On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs: Bridging Recurrent and Graph Learning', 'authors': 'Álvaro Arroyo, Alessio Gravina, Benjamin Gutteridge, Federico Barbero, Claudio Gallicchio, Xiaowen Dong, Michael Bronstein, Pierre Vandergheynst', 'link': 'https://arxiv.org/abs/2502.10818', 'abstract': 'Graph Neural Networks (GNNs) are models that leverage the graph structure to transmit information between nodes, typically through the message-passing operation. While widely successful, this approach is well known to suffer from the over-smoothing and over-squashing phenomena, which result in representational collapse as the number of layers increases and insensitivity to the information contained at distant and poorly connected nodes, respectively. In this paper, we present a unified view of these problems through the lens of vanishing gradients, using ideas from linear control theory for our analysis. We propose an interpretation of GNNs as recurrent models and empirically demonstrate that a simple state-space formulation of a GNN effectively alleviates over-smoothing and over-squashing at no extra trainable parameter cost. Further, we show theoretically and empirically that (i) GNNs are by design prone to extreme gradient vanishing even after a few layers; (ii) Over-smoothing is directly related to the mechanism causing vanishing gradients; (iii) Over-squashing is most easily alleviated by a combination of graph rewiring and vanishing gradient mitigation. We believe our work will help bridge the gap between the recurrent and graph neural network literature and will unlock the design of new deep and performant GNNs.', 'abstract_zh': '基于图的神经网络（GNNs）通过图结构在节点间传输信息，通常通过消息传递操作实现。尽管这种方法在广泛应用中表现出色，但它已知会遭受过度平滑和过度压缩的现象，随着层数增加导致表示坍塌，并且对远处和连接不良节点包含的信息变得不敏感。在本文中，我们通过梯度消失的角度提出一个统一的观点，利用线性控制理论的思想进行分析。我们提出了GNNs作为递归模型的一种解释，并通过简单的状态空间形式的GNN实验证明，这种方法在不增加额外可训练参数的情况下，可以有效缓解过度平滑和过度压缩。此外，我们理论和实验上证明了：(i) GNNs在几层后设计上就容易遭受极端梯度消失；(ii) 过度平滑直接与导致梯度消失的机制有关；(iii) 通过图重 wiring 和梯度消失缓解的组合最有效地缓解过度压缩。我们认为我们的工作将有助于弥合递归模型和图神经网络文献之间的差距，并开启设计新的深度和高性能GNNs的途径。', 'title_zh': '关于GNN中消失梯度、过度平滑和过度压缩现象：连接递归学习与图学习'}
{'arxiv_id': 'arXiv:2502.10816', 'title': 'BalanceBenchmark: A Survey for Imbalanced Learning', 'authors': 'Shaoxuan Xu, Menglu Cui, Chengxiang Huang, Hongfa Wang, DiHu', 'link': 'https://arxiv.org/abs/2502.10816', 'abstract': 'Multimodal learning has gained attention for its capacity to integrate information from different modalities. However, it is often hindered by the multimodal imbalance problem, where certain modality dominates while others remain underutilized. Although recent studies have proposed various methods to alleviate this problem, they lack comprehensive and fair comparisons. In this paper, we systematically categorize various mainstream multimodal imbalance algorithms into four groups based on the strategies they employ to mitigate imbalance. To facilitate a comprehensive evaluation of these methods, we introduce BalanceBenchmark, a benchmark including multiple widely used multidimensional datasets and evaluation metrics from three perspectives: performance, imbalance degree, and complexity. To ensure fair comparisons, we have developed a modular and extensible toolkit that standardizes the experimental workflow across different methods. Based on the experiments using BalanceBenchmark, we have identified several key insights into the characteristics and advantages of different method groups in terms of performance, balance degree and computational complexity. We expect such analysis could inspire more efficient approaches to address the imbalance problem in the future, as well as foundation models. The code of the toolkit is available at this https URL.', 'abstract_zh': '多模态学习因其能够整合不同模态的信息而受到关注，但常常受到多模态不平衡问题的阻碍，其中某些模态占主导地位而其他模态则被严重低估。尽管最近的研究提出了各种方法来缓解这一问题，但它们缺乏全面和公平的比较。本文根据各方法缓解不平衡所采用的策略，系统地将主流多模态不平衡算法归类为四组。为了促进这些方法的全面评估，我们引入了BalanceBenchmark基准，该基准包括多个广泛使用的多维数据集和从三个方面（性能、不平衡程度和复杂性）进行评估的指标。为了确保公平比较，我们开发了一个模块化和可扩展的工具包，标准化了不同方法的实验工作流程。基于使用BalanceBenchmark进行的实验，我们对不同方法组在性能、平衡程度和计算复杂性方面的特点和优势进行了分析。我们期望这样的分析能够激发未来更有效的解决不平衡问题的方法，以及基础模型的方法。该工具包的代码可通过此链接获取。', 'title_zh': '平衡基准：不平衡学习综述'}
{'arxiv_id': 'arXiv:2502.10803', 'title': 'PDA: Generalizable Detection of AI-Generated Images via Post-hoc Distribution Alignment', 'authors': 'Li Wang, Wenyu Chen, Zheng Li, Shanqing Guo', 'link': 'https://arxiv.org/abs/2502.10803', 'abstract': "The rapid advancement of generative models has led to the proliferation of highly realistic AI-generated images, posing significant challenges for detection methods to generalize across diverse and evolving generative techniques. Existing approaches often fail to adapt to unknown models without costly retraining, limiting their practicability. To fill this gap, we propose Post-hoc Distribution Alignment (PDA), a novel approach for the generalizable detection for AI-generated images. The key idea is to use the known generative model to regenerate undifferentiated test images. This process aligns the distributions of the re-generated real images with the known fake images, enabling effective distinction from unknown fake images. PDA employs a two-step detection framework: 1) evaluating whether a test image aligns with the known fake distribution based on deep k-nearest neighbor (KNN) distance, and 2) re-generating test images using known generative models to create pseudo-fake images for further classification. This alignment strategy allows PDA to effectively detect fake images without relying on unseen data or requiring retraining. Extensive experiments demonstrate the superiority of PDA, achieving 96.73\\% average accuracy across six state-of-the-art generative models, including GANs, diffusion models, and text-to-image models, and improving by 16.07\\% over the best baseline. Through t-SNE visualizations and KNN distance analysis, we provide insights into PDA's effectiveness in separating real and fake images. Our work provides a flexible and effective solution for real-world fake image detection, advancing the generalization ability of detection systems.", 'abstract_zh': '生成模型的快速进步导致了高度现实的AI生成图像的泛滥，给检测方法跨多种不断发展中的生成技术进行泛化的检测带来了重大挑战。现有方法往往无法在无需昂贵重训的情况下适应未知模型，限制了其实用性。为了解决这一问题，我们提出了后验分布对齐（PDA），一种用于AI生成图像泛化检测的新方法。关键思路是使用已知的生成模型再生未区分的测试图像。这一过程使重新生成的真实图像分布与已知的伪造图像分布对齐，从而能够有效地区分未知的伪造图像。PDA采用两步检测框架：1）基于深度k近邻（KNN）距离评估测试图像是否与已知伪造分布对齐，2）使用已知生成模型再生测试图像以生成伪伪造图像进行进一步分类。这种对齐策略使得PDA能够在不依赖未见数据或重训的情况下有效检测伪造图像。广泛的实验表明，PDA的优越性，其在六个最先进的生成模型（包括GANs、扩散模型和文本到图像模型）上实现了96.73%的平均准确性，并且相较于最佳baselines提升了16.07%。通过t-SNE可视化和KNN距离分析，我们揭示了PDA在区分真实和伪造图像方面的有效性。我们的工作提供了一种灵活和有效的解决方案，用于实际环境中的伪造图像检测，推动了检测系统泛化能力的提升。', 'title_zh': 'PDA：通过后 hoc 分布对齐实现的可泛化的 AI 生成图像检测'}
{'arxiv_id': 'arXiv:2502.10801', 'title': 'FaceSwapGuard: Safeguarding Facial Privacy from DeepFake Threats through Identity Obfuscation', 'authors': 'Li Wang, Zheng Li, Xuhong Zhang, Shouling Ji, Shanqing Guo', 'link': 'https://arxiv.org/abs/2502.10801', 'abstract': "DeepFakes pose a significant threat to our society. One representative DeepFake application is face-swapping, which replaces the identity in a facial image with that of a victim. Although existing methods partially mitigate these risks by degrading the quality of swapped images, they often fail to disrupt the identity transformation effectively. To fill this gap, we propose FaceSwapGuard (FSG), a novel black-box defense mechanism against deepfake face-swapping threats. Specifically, FSG introduces imperceptible perturbations to a user's facial image, disrupting the features extracted by identity encoders. When shared online, these perturbed images mislead face-swapping techniques, causing them to generate facial images with identities significantly different from the original user. Extensive experiments demonstrate the effectiveness of FSG against multiple face-swapping techniques, reducing the face match rate from 90\\% (without defense) to below 10\\%. Both qualitative and quantitative studies further confirm its ability to confuse human perception, highlighting its practical utility. Additionally, we investigate key factors that may influence FSG and evaluate its robustness against various adaptive adversaries.", 'abstract_zh': 'DeepFakes 对社会构成显著威胁。一种代表性的 DeepFake 应用是面部替换，将面部图像中的身份替换为受害者的身份。尽管现有方法部分降低了这些风险，通过降级替换图像的质量，但往往无法有效地破坏身份转换。为填补这一空白，我们提出了一种新型的黑盒防御机制 FaceSwapGuard (FSG) 以对抗 DeepFake 面部替换威胁。具体而言，FSG 在用户面部图像中引入不可感知的扰动，破坏身份编码器提取的特征。当这些扰动图像在网络上共享时，会误导面部替换技术，使其生成的身份与原始用户显著不同的面部图像。广泛实验表明，FSG 在对抗多种面部替换技术方面有效，将面部匹配率从无防御措施的 90% 降至不到 10%。定性和定量研究进一步证实了其混淆人类感知的能力，突显了其实用价值。此外，我们还探讨了可能影响 FSG 的关键因素，并评估了其在面对各种适应性对手时的稳健性。', 'title_zh': 'FaceSwapGuard：通过身份模糊化保障面部隐私免受深度伪造威胁'}
{'arxiv_id': 'arXiv:2502.10793', 'title': 'Dynamic Influence Tracker: Measuring Time-Varying Sample Influence During Training', 'authors': 'Jie Xu, Zihan Wu', 'link': 'https://arxiv.org/abs/2502.10793', 'abstract': 'Existing methods for measuring training sample influence on models only provide static, overall measurements, overlooking how sample influence changes during training. We propose Dynamic Influence Tracker (DIT), which captures the time-varying sample influence across arbitrary time windows during training.\nDIT offers three key insights: 1) Samples show different time-varying influence patterns, with some samples important in the early training stage while others become important later. 2) Sample influences show a weak correlation between early and late stages, demonstrating that the model undergoes distinct learning phases with shifting priorities. 3) Analyzing influence during the convergence period provides more efficient and accurate detection of corrupted samples than full-training analysis. Supported by theoretical guarantees without assuming loss convexity or model convergence, DIT significantly outperforms existing methods, achieving up to 0.99 correlation with ground truth and above 98\\% accuracy in detecting corrupted samples in complex architectures.', 'abstract_zh': '动态影响追踪器（DIT）：训练过程中样本影响的动态评估', 'title_zh': '动态影响追踪器：训练过程中样本时间变化影响的度量'}
{'arxiv_id': 'arXiv:2502.10776', 'title': 'A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction', 'authors': 'Zhipeng Liu, Peibo Duan, Mingyang Geng, Bin Zhang', 'link': 'https://arxiv.org/abs/2502.10776', 'abstract': 'Stock trend prediction involves forecasting the future price movements by analyzing historical data and various market indicators. With the advancement of machine learning, graph neural networks (GNNs) have been extensively employed in stock prediction due to their powerful capability to capture spatiotemporal dependencies of stocks. However, despite the efforts of various GNN stock predictors to enhance predictive performance, the improvements remain limited, as they focus solely on analyzing historical spatiotemporal dependencies, overlooking the correlation between historical and future patterns. In this study, we propose a novel distillation-based future-aware GNN framework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN trains a teacher model and a student model, iteratively. The teacher model learns to capture the correlation between distribution shifts of historical and future data, which is then utilized as intermediate supervision to guide the student model to learn future-aware spatiotemporal embeddings for accurate prediction. Through extensive experiments on two real-world datasets, we verify the state-of-the-art performance of DishFT-GNN.', 'abstract_zh': '基于蒸馏的未来意识图神经网络框架（DishFT-GNN）用于股票趋势预测', 'title_zh': '基于蒸馏的前瞻性图神经网络股票趋势预测'}
{'arxiv_id': 'arXiv:2502.10762', 'title': 'Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation', 'authors': 'Guofu Xie, Xiao Zhang, Ting Yao, Yunsheng Shi', 'link': 'https://arxiv.org/abs/2502.10762', 'abstract': 'User information needs are often highly diverse and varied. A key challenge in current research is how to achieve controllable multi-objective generation while enabling rapid adaptation to accommodate diverse user demands during test time. Existing solutions, such as Rewarded Soup, focus on merging language models individually tuned on single objectives. While easy to implement and widely used, these approaches face limitations in achieving optimal performance due to their disregard for the impacts of competing objectives on model tuning. To address this issue, we propose Bone Soup, a novel model merging approach that first seeks a series of backbone models by considering the impacts of multiple objectives and then makes the soup (i.e., merge the backbone models). Specifically, Bone Soup begins by training multiple backbone models for different objectives using multi-objective reinforcement learning. Each backbone model is guided by a combination of backbone reward signals. To ensure that these models are optimal for the Pareto front, the backbone rewards are crafted by combining standard reward functions into basis vectors, which can then be modified through a rule-based construction method. Bone Soup leverages a symmetric circulant matrix mapping to generate the merging coefficients, which are used to merge the backbone models according to user preferences. Extensive experimental results demonstrate that Bone Soup exhibits strong controllability and Pareto optimality in controllable multi-objective generation, providing a more effective and efficient approach to addressing diverse user needs at test time.', 'abstract_zh': '用户信息需求通常高度多样且各不相同。当前研究中的一个关键挑战是如何在满足多样化用户需求的同时实现可控的多目标生成并快速适应。现有解决方案，如Rewarded Soup，侧重于合并单目标上单独调优的语言模型。尽管易于实现且广泛应用，但这些方法由于忽视了竞争目标对模型调优的影响而存在局限性。为解决这一问题，我们提出Bone Soup，这是一种新颖的模型合并方法，首先通过考虑多个目标的影响来寻求一系列骨干模型，然后将这些模型合并（即，合并骨干模型）。具体而言，Bone Soup首先使用多目标强化学习训练不同目标的多个骨干模型。每个骨干模型由组合的基础奖励信号引导。为了确保这些模型适用于帕累托前沿，通过对标准奖励函数进行组合形成基向量，并通过规则构造方法进行修改来构建基础奖励。Bone Soup利用对称循环矩阵映射生成合并系数，根据用户偏好合并骨干模型。广泛的经验结果表明，Bone Soup在可控多目标生成中表现出强大的可控性和帕累托最优性，为在测试时间更好地满足多样用户需求提供更有效的解决方案。', 'title_zh': '骨汤模型：一种用于可控多目标生成的寻觅与汤合并方法'}
{'arxiv_id': 'arXiv:2502.10750', 'title': 'Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated AI Entities', 'authors': 'Shih-Hsuan Chiu, Ya-Wen Teng, De-Nian Yang, Ming-Syan Chen', 'link': 'https://arxiv.org/abs/2502.10750', 'abstract': 'Community detection is a cornerstone problem in social network analysis (SNA), aimed at identifying cohesive communities with minimal external links. However, the rise of generative AI and Metaverse introduce complexities by creating hybrid human-AI social networks (denoted by HASNs), where traditional methods fall short, especially in human-centric settings. This paper introduces a novel community detection problem in HASNs (denoted by MetaCD), which seeks to enhance human connectivity within communities while reducing the presence of AI nodes. Effective processing of MetaCD poses challenges due to the delicate trade-off between excluding certain AI nodes and maintaining community structure. To address this, we propose CUSA, an innovative framework incorporating AI-aware clustering techniques that navigate this trade-off by selectively retaining AI nodes that contribute to community integrity. Furthermore, given the scarcity of real-world HASNs, we devise four strategies for synthesizing these networks under various hypothetical scenarios. Empirical evaluations on real social networks, reconfigured as HASNs, demonstrate the effectiveness and practicality of our approach compared to traditional non-deep learning and graph neural network (GNN)-based methods.', 'abstract_zh': '元社会网络中的社区检测问题（MetaCD）：增强人类连接的同时减少AI节点的存在', 'title_zh': '基于人类导向的混合元网络中集成AI实体的社区检测'}
{'arxiv_id': 'arXiv:2502.10725', 'title': 'PropNet: a White-Box and Human-Like Network for Sentence Representation', 'authors': 'Fei Yang', 'link': 'https://arxiv.org/abs/2502.10725', 'abstract': 'Transformer-based embedding methods have dominated the field of sentence representation in recent years. Although they have achieved remarkable performance on NLP missions, such as semantic textual similarity (STS) tasks, their black-box nature and large-data-driven training style have raised concerns, including issues related to bias, trust, and safety. Many efforts have been made to improve the interpretability of embedding models, but these problems have not been fundamentally resolved. To achieve inherent interpretability, we propose a purely white-box and human-like sentence representation network, PropNet. Inspired by findings from cognitive science, PropNet constructs a hierarchical network based on the propositions contained in a sentence. While experiments indicate that PropNet has a significant gap compared to state-of-the-art (SOTA) embedding models in STS tasks, case studies reveal substantial room for improvement. Additionally, PropNet enables us to analyze and understand the human cognitive processes underlying STS benchmarks.', 'abstract_zh': '基于Transformer的嵌入方法近年来在句子表示领域占主导地位。尽管它们在自然语言处理任务，如语义文本相似度（STS）任务中取得了显著性能，但其黑盒性质和数据驱动的训练方式引发了关于偏差、信任和安全的问题。尽管已经做出了许多努力来提高嵌入模型的可解释性，但这些问题尚未从根本上得到解决。为了实现固有的可解释性，我们提出了一种纯白盒且类人类的句子表示网络PropNet。受认知科学研究结果的启发，PropNet基于句子中的命题构建了一个层次网络。尽管实验表明，在STS任务中PropNet与最先进的（SOTA）嵌入模型相比存在显著差距，但案例研究揭示了其改进的巨大空间。此外，PropNet使我们能够分析和理解STS基准背后的人类认知过程。', 'title_zh': 'PropNet：一种白盒且类人类的句子表示网络'}
{'arxiv_id': 'arXiv:2502.10723', 'title': 'A Mathematics Framework of Artificial Shifted Population Risk and Its Further Understanding Related to Consistency Regularization', 'authors': 'Xiliang Yang, Shenyang Deng, Shicong Liu, Yuanchi Suo, Wing.W.Y NG, Jianjun Zhang', 'link': 'https://arxiv.org/abs/2502.10723', 'abstract': 'Data augmentation is an important technique in training deep neural networks as it enhances their ability to generalize and remain robust. While data augmentation is commonly used to expand the sample size and act as a consistency regularization term, there is a lack of research on the relationship between them. To address this gap, this paper introduces a more comprehensive mathematical framework for data augmentation. Through this framework, we establish that the expected risk of the shifted population is the sum of the original population risk and a gap term, which can be interpreted as a consistency regularization term. The paper also provides a theoretical understanding of this gap, highlighting its negative effects on the early stages of training. We also propose a method to mitigate these effects. To validate our approach, we conducted experiments using same data augmentation techniques and computing resources under several scenarios, including standard training, out-of-distribution, and imbalanced classification. The results demonstrate that our methods surpass compared methods under all scenarios in terms of generalization ability and convergence stability. We provide our code implementation at the following link: this https URL.', 'abstract_zh': '数据增强是训练深度神经网络的重要技术，它能增强模型的泛化能力和鲁棒性。虽然数据增强常用于扩大样本量并起到一致性正则化的作用，但它们之间的关系研究尚不足。为弥补这一不足，本文提出了一个更为全面的数据增强数学框架。通过该框架，我们确立了移位群体的预期风险等于原始群体风险与一个差异项之和，该差异项可解释为一致性正则化项。本文还从理论上解释了这一差异项，并强调其对训练早期阶段的负面影响。我们还提出了一种方法来减轻这些影响。为验证方法的有效性，我们在多种场景下（包括标准训练、域外数据和样本不平衡分类）使用相同的数据增强技术和计算资源进行了实验。结果表明，我们的方法在所有场景下都优于对比方法在泛化能力和收敛稳定性方面。我们在以下链接提供了代码实现：this https URL。', 'title_zh': '一个人工移位人口风险的数学框架及其与一致性正则化的进一步理解'}
{'arxiv_id': 'arXiv:2502.10718', 'title': 'Hyperdimensional Intelligent Sensing for Efficient Real-Time Audio Processing on Extreme Edge', 'authors': 'Sanggeon Yun, Ryozo Masukawa, Hanning Chen, SungHeon Jeong, Wenjun Huang, Arghavan Rezvani, Minhyoung Na, Yoshiki Yamaguchi, Mohsen Imani', 'link': 'https://arxiv.org/abs/2502.10718', 'abstract': "The escalating challenges of managing vast sensor-generated data, particularly in audio applications, necessitate innovative solutions. Current systems face significant computational and storage demands, especially in real-time applications like gunshot detection systems (GSDS), and the proliferation of edge sensors exacerbates these issues. This paper proposes a groundbreaking approach with a near-sensor model tailored for intelligent audio-sensing frameworks. Utilizing a Fast Fourier Transform (FFT) module, convolutional neural network (CNN) layers, and HyperDimensional Computing (HDC), our model excels in low-energy, rapid inference, and online learning. It is highly adaptable for efficient ASIC design implementation, offering superior energy efficiency compared to conventional embedded CPUs or GPUs, and is compatible with the trend of shrinking microphone sensor sizes. Comprehensive evaluations at both software and hardware levels underscore the model's efficacy. Software assessments through detailed ROC curve analysis revealed a delicate balance between energy conservation and quality loss, achieving up to 82.1% energy savings with only 1.39% quality loss. Hardware evaluations highlight the model's commendable energy efficiency when implemented via ASIC design, especially with the Google Edge TPU, showcasing its superiority over prevalent embedded CPUs and GPUs.", 'abstract_zh': '快速增长的传感器生成数据管理挑战，尤其是音频应用领域，需要创新解决方案。当前系统在实时应用如枪声检测系统（GSDS）中面临显著的计算和存储需求，边缘传感器的普及进一步加剧了这些问题。本文提出了一种创新方法，即针对智能音频感知框架的近传感器模型。该模型利用快速傅里叶变换（FFT）模块、卷积神经网络（CNN）层和超维度计算（HDC），在低功耗、快速推断和在线学习方面表现出色。该模型对高效的ASIC设计实现非常适应，并且相比于传统嵌入式CPU或GPU提供更高的能效，同时兼容麦克风传感器尺寸缩小的趋势。软件和硬件层次上的综合评估证实了该模型的有效性。软件评估通过详细的ROC曲线分析表明，在实现82.1%的能耗节省的同时，仅损失了1.39%的质量。硬件评估强调了该模型在ASIC设计实现时的优异能效，尤其是在Google Edge TPU上的表现，展示了其相对于主流嵌入式CPU和GPU的优势。', 'title_zh': '超维智能感知在极端边缘高效实时音频处理中的应用'}
{'arxiv_id': 'arXiv:2502.10712', 'title': 'FuncGenFoil: Airfoil Generation and Editing Model in Function Space', 'authors': 'Jinouwen Zhang, Junjie Ren, Aobo Yang, Yan Lu, Lu Chen, Hairun Xie, Jing Wang, Miao Zhang, Wanli Ouyang, Shixiang Tang', 'link': 'https://arxiv.org/abs/2502.10712', 'abstract': 'Aircraft manufacturing is the jewel in the crown of industry, among which generating high-fidelity airfoil geometries with controllable and editable representations remains a fundamental challenge. While existing deep-learning-based methods rely on predefined parametric function families, e.g., Bézier curves and discrete point-based representations, they suffer from inherent trade-offs between expressiveness and resolution flexibility. To tackle this challenge, we introduce FuncGenFoil, a novel function-space generative model that directly learns functional airfoil geometries. Our method inherits both the advantages of arbitrary resolution sampling and the smoothness of parametric functions, as well as the strong expressiveness of discrete point-based functions. Empirical evaluations on the AFBench dataset demonstrate that FuncGenFoil improves upon state-of-the-art methods in airfoil generation by achieving a relative -74.4 label error reduction and +23.2 diversity increase on the AF-200K dataset. Our results highlight the advantages of function-space modeling for aerodynamic shape optimization, offering a powerful and flexible framework for high-fidelity airfoil design. Our code will be released.', 'abstract_zh': '飞机制造是工业的冠冕，其中生成可控可编辑的高保真翼型几何形状依然是一项基本挑战。现有的基于深度学习的方法依赖于预定义的参数函数族，例如Bézier曲线和离散点表示，它们在表达能力和分辨率灵活性之间存在固有的权衡。为了解决这一挑战，我们引入了FuncGenFoil，这是一种新颖的功能空间生成模型，可以直接学习功能性的翼型几何形状。我们的方法继承了任意分辨率采样和参数函数的平滑性优势，以及离散点表示的强大表达能力。在AFBench数据集上的经验评估表明，FuncGenFoil在气动形状优化方面的气动翼型生成中优于现有方法，在AF-200K数据集上实现了相对标签错误率降低74.4%和多样性提高23.2%。我们的结果突显了功能空间建模在气动形状优化中的优势，提供了高性能和灵活的高保真翼型设计框架。我们的代码将对外开放。', 'title_zh': 'FuncGenFoil：函数空间中的翼型生成与编辑模型'}
{'arxiv_id': 'arXiv:2502.10706', 'title': 'Raising the Bar in Graph OOD Generalization: Invariant Learning Beyond Explicit Environment Modeling', 'authors': 'Xu Shen, Yixin Liu, Yili Wang, Rui Miao, Yiwei Dai, Shirui Pan, Xin Wang', 'link': 'https://arxiv.org/abs/2502.10706', 'abstract': 'Out-of-distribution (OOD) generalization has emerged as a critical challenge in graph learning, as real-world graph data often exhibit diverse and shifting environments that traditional models fail to generalize across. A promising solution to address this issue is graph invariant learning (GIL), which aims to learn invariant representations by disentangling label-correlated invariant subgraphs from environment-specific subgraphs. However, existing GIL methods face two major challenges: (1) the difficulty of capturing and modeling diverse environments in graph data, and (2) the semantic cliff, where invariant subgraphs from different classes are difficult to distinguish, leading to poor class separability and increased misclassifications. To tackle these challenges, we propose a novel method termed Multi-Prototype Hyperspherical Invariant Learning (MPHIL), which introduces two key innovations: (1) hyperspherical invariant representation extraction, enabling robust and highly discriminative hyperspherical invariant feature extraction, and (2) multi-prototype hyperspherical classification, which employs class prototypes as intermediate variables to eliminate the need for explicit environment modeling in GIL and mitigate the semantic cliff issue. Derived from the theoretical framework of GIL, we introduce two novel objective functions: the invariant prototype matching loss to ensure samples are matched to the correct class prototypes, and the prototype separation loss to increase the distinction between prototypes of different classes in the hyperspherical space. Extensive experiments on 11 OOD generalization benchmark datasets demonstrate that MPHIL achieves state-of-the-art performance, significantly outperforming existing methods across graph data from various domains and with different distribution shifts.', 'abstract_zh': '超越分布外（OOD）泛化的图不变学习：多原型超球面不变学习（MPHIL）', 'title_zh': '提高图数据OOD泛化的标准：超越显式环境建模的不变性学习'}
{'arxiv_id': 'arXiv:2502.10694', 'title': 'Simulations of Common Unsupervised Domain Adaptation Algorithms for Image Classification', 'authors': 'Ahmad Chaddad, Yihang Wu, Yuchen Jiang, Ahmed Bouridane, Christian Desrosiers', 'link': 'https://arxiv.org/abs/2502.10694', 'abstract': "Traditional machine learning assumes that training and test sets are derived from the same distribution; however, this assumption does not always hold in practical applications. This distribution disparity can lead to severe performance drops when the trained model is used in new data sets. Domain adaptation (DA) is a machine learning technique that aims to address this problem by reducing the differences between domains. This paper presents simulation-based algorithms of recent DA techniques, mainly related to unsupervised domain adaptation (UDA), where labels are available only in the source domain. Our study compares these techniques with public data sets and diverse characteristics, highlighting their respective strengths and drawbacks. For example, Safe Self-Refinement for Transformer-based DA (SSRT) achieved the highest accuracy (91.6\\%) in the office-31 data set during our simulations, however, the accuracy dropped to 72.4\\% in the Office-Home data set when using limited batch sizes. In addition to improving the reader's comprehension of recent techniques in DA, our study also highlights challenges and upcoming directions for research in this domain. The codes are available at this https URL.", 'abstract_zh': '传统的机器学习假设训练集和测试集来自相同的分布；然而，在实际应用中这一假设并不总是成立。这种分布差异会导致在新数据集上使用训练好的模型时出现严重的性能下降。领域适应（DA）是一种机器学习技术，旨在通过减少领域之间的差异来解决这一问题。本文介绍了基于仿真的recent DA技术算法，主要涉及无监督领域适应（UDA），其中仅源域有标签。我们的研究使用公共数据集和多种特性，比较了这些技术的优劣。例如，在我们的仿真实验中，Safe Self-Refinement for Transformer-based DA (SSRT) 在office-31数据集上的准确率为91.6%，但在使用有限批次大小时，Office-Home数据集的准确率降至72.4%。除了提高读者对DA领域近期技术的理解，我们的研究还指出了该领域的挑战和未来研究方向。相关代码可在以下网址获取。', 'title_zh': '常用无监督领域适应算法在图像分类中的模拟研究'}
{'arxiv_id': 'arXiv:2502.10689', 'title': 'Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction', 'authors': 'Leisheng Yu, Yanxiao Cai, Minxing Zhang, Xia Hu', 'link': 'https://arxiv.org/abs/2502.10689', 'abstract': 'The burgeoning volume of electronic health records (EHRs) has enabled deep learning models to excel in predictive healthcare. However, for high-stakes applications such as diagnosis prediction, model interpretability remains paramount. Existing deep learning diagnosis prediction models with intrinsic interpretability often assign attention weights to every past diagnosis or hospital visit, providing explanations lacking flexibility and succinctness. In this paper, we introduce SHy, a self-explaining hypergraph neural network model, designed to offer personalized, concise and faithful explanations that allow for interventions from clinical experts. By modeling each patient as a unique hypergraph and employing a message-passing mechanism, SHy captures higher-order disease interactions and extracts distinct temporal phenotypes as personalized explanations. It also addresses the incompleteness of the EHR data by accounting for essential false negatives in the original diagnosis record. A qualitative case study and extensive quantitative evaluations on two real-world EHR datasets demonstrate the superior predictive performance and interpretability of SHy over existing state-of-the-art models.', 'abstract_zh': '电子健康记录(EHRs)的快速增长使得深度学习模型在预测健康-care领域表现出色。然而，在诊断预测等高风险应用中，模型的可解释性仍然至关重要。现有具备固有可解释性的深度学习诊断预测模型往往为每个过去的诊断或医院访问分配注意力权重，提供的解释缺乏灵活性和简洁性。本文提出了SHy，一种自解释的超图神经网络模型，旨在提供个性化、简洁且忠实的解释，使临床专家能够介入。通过将每位患者建模为独特的超图，并采用消息传递机制，SHy捕捉了更高阶的疾病交互，并提取了个性化的时间表型作为解释。此外，它通过考虑原始诊断记录中的关键假阴性解决了EHR数据的不完备性问题。实世界两个EHR数据集上的定性和定量评估表明，SHy在预测性能和可解释性方面优于现有最先进的模型。', 'title_zh': '自我解释超图神经网络在诊断预测中的应用'}
{'arxiv_id': 'arXiv:2502.10637', 'title': 'Proof of Response', 'authors': 'Illia Polosukhin, Alex Skidanov', 'link': 'https://arxiv.org/abs/2502.10637', 'abstract': 'We present a mechanism that for a network of participants allows one participant of the network (Alice) to request some data from another participant (Bob) and either receive a response from Bob within a known-in-advance, bounded time b, or receive a proof that at least one edge on the way to Bob was broken within b, or receive a streaming payment proportional to time passed beyond b during which neither was received. This mechanism allows for building downstream applications that require provable responses from other participants, such as decentralized storage solutions, decentralized AI agents, and more.', 'abstract_zh': '我们提出了一种机制，该机制允许可信网络中的一个参与者（Alice）向另一个参与者（Bob）请求某些数据，并在已知且受限的时间b内要么收到Bob的响应，要么收到证明至少一条通往Bob的路径在b时间内被中断的证据，要么收到按时间比例支付的流式付款，其中既未收到响应也未收到证据。该机制使得能够构建需要从其他参与者处获得可验证响应的下游应用，如去中心化存储解决方案、去中心化AI代理等。', 'title_zh': '响应证明'}
{'arxiv_id': 'arXiv:2502.10624', 'title': 'Network evasion detection with Bi-LSTM model', 'authors': 'Kehua Chen, Jingping Jia', 'link': 'https://arxiv.org/abs/2502.10624', 'abstract': "Network evasion detection aims to distinguish whether the network flow comes from link layer exists network evasion threat, which is a means to disguise the data traffic on detection system by confusing the signature. Since the previous research works has all sorts of frauds, we propose a architecture with deep learning network to handle this problem. In this paper, we extract the critical information as key features from data frame and also specifically propose to use bidirectional long short-term memory (Bi-LSTM) neural network which shows an outstanding performance to trace the serial information, to encode both the past and future trait on the network flows. Furthermore we introduce a classifier named Softmax at the bottom of Bi-LSTM, holding a character to select the correct class. All experiments results shows that we can achieve a significant performance with a deep Bi-LSTM in network evasion detection and it's average accuracy reaches 96.1%.", 'abstract_zh': '网络逃逸检测旨在区分网络流是否来自链路层存在的网络逃逸威胁，这是一种通过混淆特征使数据流量在检测系统中蒙混过关的方法。鉴于以往的研究工作存在诸多不足，我们提出了一种基于深度学习网络的架构来解决这一问题。在此论文中，我们从数据帧中提取关键信息作为特征，并特别提出使用双向长短期记忆（Bi-LSTM）神经网络来追踪序列信息，编码网络流中的过去和未来特征。此外，我们在Bi-LSTM底部引入了一个名为Softmax的分类器，以选择正确的类别。所有实验结果表明，我们可以通过深度Bi-LSTM在网络逃逸检测中实现显著性能提升，平均准确率达到了96.1%。', 'title_zh': '基于Bi-LSTM模型的网络逃逸检测'}
{'arxiv_id': 'arXiv:2502.10587', 'title': 'Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression', 'authors': 'Megh Shukla, Aziz Shameem, Mathieu Salzmann, Alexandre Alahi', 'link': 'https://arxiv.org/abs/2502.10587', 'abstract': 'Deep heteroscedastic regression models the mean and covariance of the target distribution through neural networks. The challenge arises from heteroscedasticity, which implies that the covariance is sample dependent and is often unknown. Consequently, recent methods learn the covariance through unsupervised frameworks, which unfortunately yield a trade-off between computational complexity and accuracy. While this trade-off could be alleviated through supervision, obtaining labels for the covariance is non-trivial. Here, we study self-supervised covariance estimation in deep heteroscedastic regression. We address two questions: (1) How should we supervise the covariance assuming ground truth is available? (2) How can we obtain pseudo labels in the absence of the ground-truth? We address (1) by analysing two popular measures: the KL Divergence and the 2-Wasserstein distance. Subsequently, we derive an upper bound on the 2-Wasserstein distance between normal distributions with non-commutative covariances that is stable to optimize. We address (2) through a simple neighborhood based heuristic algorithm which results in surprisingly effective pseudo labels for the covariance. Our experiments over a wide range of synthetic and real datasets demonstrate that the proposed 2-Wasserstein bound coupled with pseudo label annotations results in a computationally cheaper yet accurate deep heteroscedastic regression.', 'abstract_zh': '深层异方差回归模型通过神经网络模拟目标分布的均值和协方差。挑战来自于异方差性，这意味着协方差是样本依赖的，且通常未知。因此，最近的方法通过无监督框架学习协方差，不幸的是，这会导致计算复杂性和准确性之间的权衡。虽然可以通过监督来缓解这一权衡，但获得协方差的标签并不容易。在这里，我们研究深层异方差回归中的自监督协方差估计。我们回答了两个问题：（1）如果我们有地面真实标签，应该如何监督协方差？（2）在没有地面真实标签的情况下，如何获得伪标签？我们通过分析两种流行的距离度量：KL散度和2- Wasserstein距离来解决（1）。随后，我们推导出一种稳定的非交换协方差正态分布之间的2-Wasserstein距离的上界。我们通过一个简单的基于邻域的启发式算法解决（2），该算法生成了对协方差非常有效的伪标签。我们在广泛合成和真实数据集上的实验表明，所提出的2-Wasserstein界结合伪标签注解导致一种计算成本更低但准确率更高的深层异方差回归。', 'title_zh': '面向深度异方差回归的自监督协方差估计'}
{'arxiv_id': 'arXiv:2502.10573', 'title': 'An Innovative Next Activity Prediction Approach Using Process Entropy and DAW-Transformer', 'authors': 'Hadi Zare, Mostafa Abbasi, Maryam Ahang, Homayoun Najjaran', 'link': 'https://arxiv.org/abs/2502.10573', 'abstract': "Purpose - In Business Process Management (BPM), accurate prediction of the next activities is vital for operational efficiency and decision-making. Current Artificial Intelligence (AI)/Machine Learning (ML) models struggle with the complexity and evolving nature of business process event logs, balancing accuracy and interpretability. This paper proposes an entropy-driven model selection approach and DAW-Transformer, which stands for Dynamic Attribute-Aware Transformer, to integrate all attributes with a dynamic window for better accuracy.\nDesign/methodology/approach - This paper introduces a novel next-activity prediction approach that uses process entropy to assess the complexity of event logs and dynamically select the most suitable ML model. A new transformer-based architecture with multi-head attention and dynamic windowing mechanism, DAW-Transformer, is proposed to capture long-range dependencies and utilize all relevant event log attributes. Experiments were conducted on six public datasets, and the performance was evaluated with process entropy.\nFinding - The results demonstrate the effectiveness of the approach across these publicly available datasets. DAW-Transformer achieved superior performance, especially on high-entropy datasets such as Sepsis exceeding Limited window Multi-Transformers by 4.69% and a benchmark CNN-LSTM-SAtt model by 3.07%. For low-entropy datasets like Road Traffic Fine, simpler, more interpretable algorithms like Random Forest performed nearly as well as the more complex DAW-Transformer and offered better handling of imbalanced data and improved explainability.\nOriginality/ value - This work's novelty lies in the proposed DAW-Transformer, with a dynamic window and considering all relevant attributes. Also, entropy-driven selection methods offer a robust, accurate, and interpretable solution for next-activity prediction.", 'abstract_zh': '目的 - 在业务流程管理（BPM）中，准确预测下一个活动对于操作效率和决策制定至关重要。当前的人工智能/机器学习（AI/ML）模型难以处理业务流程事件日志的复杂性和不断变化的特性，难以在准确性和可解释性之间取得平衡。本文提出了一种基于熵的模型选择方法和DAW-Transformer，即动态属性感知变换器，以更好地利用所有相关的事件日志属性。\n\n设计/方法 - 本文提出了一种新颖的下一个活动预测方法，使用过程熵来评估事件日志的复杂性，并动态选择最合适的机器学习模型。提出了一种基于变换器的新架构，该架构具有多头注意机制和动态窗口机制，称为DAW-Transformer，以捕获长程依赖性并利用所有相关事件日志属性。在六个公开数据集上进行了实验，并使用过程熵评估了模型性能。\n\n发现 - 结果表明该方法在这些公开可用的数据集上具有有效性。DAW-Transformer在高熵数据集（例如Sepsis）上表现优异，超过了有限窗口多变换器4.69%，并优于基准的CNN-LSTM-SAtt模型3.07%。对于低熵数据集（如Road Traffic Fine），更简单且更具可解释性的算法如随机森林表现几乎与复杂的DAW-Transformer相当，且在处理不平衡数据和提高可解释性方面更具优势。\n\n创新/价值 - 本文的创新之处在于提出的具有动态窗口和考虑所有相关属性的DAW-Transformer。此外，基于熵的模型选择方法为下一个活动预测提供了稳健、准确且可解释的解决方案。', 'title_zh': '基于过程熵和DAW-Transformer的创新下一步活动预测方法'}
{'arxiv_id': 'arXiv:2502.10569', 'title': 'HADL Framework for Noise Resilient Long-Term Time Series Forecasting', 'authors': 'Aditya Dey, Jonas Kusch, Fadi Al Machot', 'link': 'https://arxiv.org/abs/2502.10569', 'abstract': 'Long-term time series forecasting is critical in domains such as finance, economics, and energy, where accurate and reliable predictions over extended horizons drive strategic decision-making. Despite the progress in machine learning-based models, the impact of temporal noise in extended lookback windows remains underexplored, often degrading model performance and computational efficiency. In this paper, we propose a novel framework that addresses these challenges by integrating the Discrete Wavelet Transform (DWT) and Discrete Cosine Transform (DCT) to perform noise reduction and extract robust long-term features. These transformations enable the separation of meaningful temporal patterns from noise in both the time and frequency domains. To complement this, we introduce a lightweight low-rank linear prediction layer that not only reduces the influence of residual noise but also improves memory efficiency. Our approach demonstrates competitive robustness to noisy input, significantly reduces computational complexity, and achieves competitive or state-of-the-art forecasting performance across diverse benchmark datasets. Extensive experiments reveal that the proposed framework is particularly effective in scenarios with high noise levels or irregular patterns, making it well suited for real-world forecasting tasks. The code is available in this https URL.', 'abstract_zh': '长周期时间序列预测在金融、 economics 和能源等领域至关重要，准确可靠的长期预测驱动着战略决策。尽管基于机器学习的模型取得了进展，但扩展回溯窗口中的时间噪声影响仍被忽视，这往往降低了模型性能和计算效率。本文提出一种新颖框架，通过结合离散小波变换（DWT）和离散余弦变换（DCT）进行噪声 reduction 和提取 robust 长期特征来应对这些挑战。这些变换能够在时间和频率域中将有意义的时间模式与噪声分离。此外，我们引入了一种轻量级低秩线性预测层，不仅减少了残余噪声的影响，还提高了内存效率。本文的方法在噪音输入下的鲁棒性表现竞争，显著降低了计算复杂度，并在多种基准数据集中实现了竞争或最先进的预测性能。大量实验证明，所提出框架特别适用于高噪音水平或不规则模式的场景，使其适合实际预测任务。代码在此 <https://> 可用。', 'title_zh': 'HADL框架下的抗噪声长期时间序列预测'}
{'arxiv_id': 'arXiv:2502.10567', 'title': 'Efficient Hierarchical Contrastive Self-supervising Learning for Time Series Classification via Importance-aware Resolution Selection', 'authors': 'Kevin Garcia, Juan Manuel Perez, Yifeng Gao', 'link': 'https://arxiv.org/abs/2502.10567', 'abstract': "Recently, there has been a significant advancement in designing Self-Supervised Learning (SSL) frameworks for time series data to reduce the dependency on data labels. Among these works, hierarchical contrastive learning-based SSL frameworks, which learn representations by contrasting data embeddings at multiple resolutions, have gained considerable attention. Due to their ability to gather more information, they exhibit better generalization in various downstream tasks. However, when the time series data length is significant long, the computational cost is often significantly higher than that of other SSL frameworks. In this paper, to address this challenge, we propose an efficient way to train hierarchical contrastive learning models. Inspired by the fact that each resolution's data embedding is highly dependent, we introduce importance-aware resolution selection based training framework to reduce the computational cost. In the experiment, we demonstrate that the proposed method significantly improves training time while preserving the original model's integrity in extensive time series classification performance evaluations. Our code could be found here, this https URL", 'abstract_zh': '最近，在为时间序列数据设计自监督学习（SSL）框架以减少对数据标签的依赖方面取得了显著进展。其中，基于层次对比学习的SSL框架因其能够获取更多信息而在各种下游任务中表现出更好的泛化能力，但当时间序列数据长度显著较长时，计算成本往往远高于其他SSL框架。在本文中，为解决这一挑战，我们提出了一种高效训练层次对比学习模型的方法。借鉴每种分辨率的数据嵌入高度相关的事实，我们引入了一种基于重要性意识的分辨率选择训练框架以降低计算成本。在实验中，我们证明了所提出的方法在广泛的时间序列分类性能评估中显著提高了训练时间同时保持了模型的完整性。我们的代码可在此处找到：this https URL。', 'title_zh': '基于重要性感知分辨率选择的高效分层对比自监督学习时间序列分类'}
{'arxiv_id': 'arXiv:2502.10526', 'title': 'Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks', 'authors': 'Venkatesh Sivaraman, Anika Vaishampayan, Xiaotong Li, Brian R Buck, Ziyong Ma, Richard D Boyce, Adam Perer', 'link': 'https://arxiv.org/abs/2502.10526', 'abstract': "Temporal predictive models have the potential to improve decisions in health care, public services, and other domains, yet they often fail to effectively support decision-makers. Prior literature shows that many misalignments between model behavior and decision-makers' expectations stem from issues of model specification, namely how, when, and for whom predictions are made. However, model specifications for predictive tasks are highly technical and difficult for non-data-scientist stakeholders to interpret and critique. To address this challenge we developed Tempo, an interactive system that helps data scientists and domain experts collaboratively iterate on model specifications. Using Tempo's simple yet precise temporal query language, data scientists can quickly prototype specifications with greater transparency about pre-processing choices. Moreover, domain experts can assess performance within data subgroups to validate that models behave as expected. Through three case studies, we demonstrate how Tempo helps multidisciplinary teams quickly prune infeasible specifications and identify more promising directions to explore.", 'abstract_zh': '临时预测模型有潜力改善医疗保健、公共服务等领域中的决策，但往往未能有效地支持决策者。 prior literature 表明，模型行为与决策者预期之间的许多不一致性源自模型规格问题，即预测如何、何时以及针对谁做出。然而，预测任务的模型规格高度技术化，难以让非数据科学家利益相关方进行解释和评估。为应对这一挑战，我们开发了 Tempo，一个交互系统，帮助数据科学家和领域专家协作调整模型规格。通过 Tempo 简单而精确的时间查询语言，数据科学家可以快速制定具有更多预处理选择透明度的规格原型。此外，领域专家可以在数据子组中评估模型性能，以验证模型是否按预期行为。通过三个案例研究，我们展示了 Tempo 如何帮助跨学科团队迅速排除不可行的规格，并确定更值得探索的方向。', 'title_zh': 'Tempo: 协助数据科学家和领域专家协作指定预测建模任务'}
{'arxiv_id': 'arXiv:2502.10495', 'title': 'SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models', 'authors': 'Zhonghao Yang, Linye Lyu, Xuanhang Chang, Daojing He, YU LI', 'link': 'https://arxiv.org/abs/2502.10495', 'abstract': 'In the rapidly evolving landscape of image generation, Latent Diffusion Models (LDMs) have emerged as powerful tools, enabling the creation of highly realistic images. However, this advancement raises significant concerns regarding copyright infringement and the potential misuse of generated content. Current watermarking techniques employed in LDMs often embed constant signals to the generated images that compromise their stealthiness, making them vulnerable to detection by malicious attackers. In this paper, we introduce SWA-LDM, a novel approach that enhances watermarking by randomizing the embedding process, effectively eliminating detectable patterns while preserving image quality and robustness. Our proposed watermark presence attack reveals the inherent vulnerabilities of existing latent-based watermarking methods, demonstrating how easily these can be exposed. Through comprehensive experiments, we validate that SWA-LDM not only fortifies watermark stealthiness but also maintains competitive performance in watermark robustness and visual fidelity. This work represents a pivotal step towards securing LDM-generated images against unauthorized use, ensuring both copyright protection and content integrity in an era where digital image authenticity is paramount.', 'abstract_zh': '基于随机化嵌入的SWA-LDM水印方法：提升Latent Diffusion Models生成图像的安全性', 'title_zh': 'SWA-LDM：潜扩散模型中的隐蔽水印技术'}
{'arxiv_id': 'arXiv:2502.10491', 'title': 'F-StrIPE: Fast Structure-Informed Positional Encoding for Symbolic Music Generation', 'authors': 'Manvi Agarwal, Changhong Wang, Gael Richard', 'link': 'https://arxiv.org/abs/2502.10491', 'abstract': 'While music remains a challenging domain for generative models like Transformers, recent progress has been made by exploiting suitable musically-informed priors. One technique to leverage information about musical structure in Transformers is inserting such knowledge into the positional encoding (PE) module. However, Transformers carry a quadratic cost in sequence length. In this paper, we propose F-StrIPE, a structure-informed PE scheme that works in linear complexity. Using existing kernel approximation techniques based on random features, we show that F-StrIPE is a generalization of Stochastic Positional Encoding (SPE). We illustrate the empirical merits of F-StrIPE using melody harmonization for symbolic music.', 'abstract_zh': '基于结构的线性复杂度位置编码方案F-StrIPE', 'title_zh': 'F-StrIPE: 快速结构导向位置编码在符号音乐生成中的应用'}
{'arxiv_id': 'arXiv:2502.10490', 'title': 'A Robust Attack: Displacement Backdoor Attack', 'authors': 'Yong Li, Han Gao', 'link': 'https://arxiv.org/abs/2502.10490', 'abstract': 'As artificial intelligence becomes more prevalent in our lives, people are enjoying the convenience it brings, but they are also facing hidden threats, such as data poisoning and ad- versarial attacks. These threats can have disastrous consequences for the application of artificial intelligence, especially for some applications that take effect immediately, such as autonomous driving and medical fields. Among these threats, backdoor attacks have left a deep impression on people with their concealment and simple deployment, making them a threat that cannot be ignored, however, in the process of deploying the backdoor model, the backdoor attack often has some reasons that make it unsatisfactory in real-world applications, such as jitter and brightness changes. Based on this, we propose a highly robust backdoor attack that shifts the target sample and combines it with itself to form a backdoor sample, the Displacement Backdoor Attack(DBA). Experimental results show that the DBA attack can resist data augmentation that simulates real-world differences, such as rotation and cropping.', 'abstract_zh': '随着人工智能在人们生活中变得越来越普遍，人们享受着它带来的便利，但也面临着隐藏的威胁，如数据污染和对抗攻击。这些威胁可能对人工智能的应用造成灾难性后果，尤其是在自动驾驶和医疗等即时生效的应用领域。在这些威胁中，后门攻击因其隐蔽性和简单的部署方式给人留下了深刻印象，成为不可忽视的威胁。然而，在部署后门模型的过程中，后门攻击往往因现实应用中的抖动和亮度变化等问题不尽如人意。基于此，我们提出了一种高度鲁棒的后门攻击——位移后门攻击(DBA)，该攻击通过将目标样本与自身进行位移并结合以形成后门样本。实验结果表明，DBA攻击可以抵抗模拟现实世界差异的数据增强，如旋转和裁剪。', 'title_zh': 'robust 攻击: 移动后门攻击'}
{'arxiv_id': 'arXiv:2502.10489', 'title': 'LiveVal: Time-aware Data Valuation via Adaptive Reference Points', 'authors': 'Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia', 'link': 'https://arxiv.org/abs/2502.10489', 'abstract': "Time-aware data valuation enhances training efficiency and model robustness, as early detection of harmful samples could prevent months of wasted computation. However, existing methods rely on model retraining or convergence assumptions or fail to capture long-term training dynamics.\nWe propose LiveVal, an efficient time-aware data valuation method with three key designs:\n1) seamless integration with SGD training for efficient data contribution monitoring; 2) reference-based valuation with normalization for reliable benchmark establishment; and 3) adaptive reference point selection for real-time updating with optimized memory usage.\nWe establish theoretical guarantees for LiveVal's stability and prove that its valuations are bounded and directionally aligned with optimization progress. Extensive experiments demonstrate that LiveVal provides efficient data valuation across different modalities and model scales, achieving 180 speedup over traditional methods while maintaining robust detection performance.", 'abstract_zh': '基于时间的数据评价增强训练效率和模型鲁棒性，通过早期检测有害样本可避免数月的无效计算。然而，现有方法依赖于模型重训或收敛假设，或无法捕捉长期训练动态。', 'title_zh': 'LiveVal: 基于自适应参考点的时敏数据估值'}
{'arxiv_id': 'arXiv:2502.10485', 'title': 'Forecasting time series with constraints', 'authors': 'Nathan Doumèche, Francis Bach, Éloi Bedek, Gérard Biau, Claire Boyer, Yannig Goude', 'link': 'https://arxiv.org/abs/2502.10485', 'abstract': 'Time series forecasting presents unique challenges that limit the effectiveness of traditional machine learning algorithms. To address these limitations, various approaches have incorporated linear constraints into learning algorithms, such as generalized additive models and hierarchical forecasting. In this paper, we propose a unified framework for integrating and combining linear constraints in time series forecasting. Within this framework, we show that the exact minimizer of the constrained empirical risk can be computed efficiently using linear algebra alone. This approach allows for highly scalable implementations optimized for GPUs. We validate the proposed methodology through extensive benchmarking on real-world tasks, including electricity demand forecasting and tourism forecasting, achieving state-of-the-art performance.', 'abstract_zh': '时间序列预测面临着独特的挑战，限制了传统机器学习算法的效果。为应对这些局限性，各种方法将线性约束融入学习算法中，例如广义加性模型和层次预测。在本文中，我们提出了一种统一框架，用于在时间序列预测中整合和结合线性约束。在此框架内，我们证明可以通过线性代数高效计算受约束的经验风险的精确最小化器。该方法允许对GPU进行高度可扩展的实现。通过在实际任务上进行广泛的基准测试进行验证，包括电力需求预测和旅游预测，实现了最先进的性能。', 'title_zh': '具有约束条件的时间序列预测'}
{'arxiv_id': 'arXiv:2502.10470', 'title': 'MetaDE: Evolving Differential Evolution by Differential Evolution', 'authors': 'Minyang Chen, Chenchen Feng, and Ran Cheng', 'link': 'https://arxiv.org/abs/2502.10470', 'abstract': "As a cornerstone in the Evolutionary Computation (EC) domain, Differential Evolution (DE) is known for its simplicity and effectiveness in handling challenging black-box optimization problems. While the advantages of DE are well-recognized, achieving peak performance heavily depends on its hyperparameters such as the mutation factor, crossover probability, and the selection of specific DE strategies. Traditional approaches to this hyperparameter dilemma have leaned towards parameter tuning or adaptive mechanisms. However, identifying the optimal settings tailored for specific problems remains a persistent challenge. In response, we introduce MetaDE, an approach that evolves DE's intrinsic hyperparameters and strategies using DE itself at a meta-level. A pivotal aspect of MetaDE is a specialized parameterization technique, which endows it with the capability to dynamically modify DE's parameters and strategies throughout the evolutionary process. To augment computational efficiency, MetaDE incorporates a design that leverages parallel processing through a GPU-accelerated computing framework. Within such a framework, DE is not just a solver but also an optimizer for its own configurations, thus streamlining the process of hyperparameter optimization and problem-solving into a cohesive and automated workflow. Extensive evaluations on the CEC2022 benchmark suite demonstrate MetaDE's promising performance. Moreover, when applied to robot control via evolutionary reinforcement learning, MetaDE also demonstrates promising performance. The source code of MetaDE is publicly accessible at: this https URL.", 'abstract_zh': '作为一种进化计算领域的基石，差分进化因其在处理复杂黑盒优化问题时的简单性和有效性而闻名。尽管差分进化的优势得到广泛认可，但实现其最佳性能高度依赖于其超参数，如变异因子、交叉概率以及特定差分进化策略的选择。传统的方法倾向于参数调整或自适应机制来解决这一问题，然而，为特定问题寻找最优设置仍然是一个持续性的挑战。为此，我们引入了MetaDE，这是一种利用差分进化自身在元层次上进化其固有超参数和策略的方法。MetaDE的关键方面在于一种专门的参数化技术，赋予其动态修改差分进化参数和策略的能力，贯穿整个进化过程。为提高计算效率，MetaDE采用了一种利用GPU加速计算框架的设计。在这种框架中，DE不仅是一个求解器，也是一个优化其自身配置的优化器，从而将超参数优化和问题求解流程简化为一个协调且自动的工作流。对CEC2022基准测试集进行的广泛评估显示了MetaDE的潜力。此外，将其应用于通过进化强化学习进行的机器人控制时，MetaDE也展现了有趣的性能。MetaDE的源代码可在以下链接获取：this https URL。', 'title_zh': 'MetaDE: 通过差分进化演变差分进化'}
{'arxiv_id': 'arXiv:2502.10463', 'title': 'From Layers to States: A State Space Model Perspective to Deep Neural Network Layer Dynamics', 'authors': 'Qinshuo Liu, Weiqin Zhao, Wei Huang, Yanwen Fang, Lequan Yu, Guodong Li', 'link': 'https://arxiv.org/abs/2502.10463', 'abstract': 'The depth of neural networks is a critical factor for their capability, with deeper models often demonstrating superior performance. Motivated by this, significant efforts have been made to enhance layer aggregation - reusing information from previous layers to better extract features at the current layer, to improve the representational power of deep neural networks. However, previous works have primarily addressed this problem from a discrete-state perspective which is not suitable as the number of network layers grows. This paper novelly treats the outputs from layers as states of a continuous process and considers leveraging the state space model (SSM) to design the aggregation of layers in very deep neural networks. Moreover, inspired by its advancements in modeling long sequences, the Selective State Space Models (S6) is employed to design a new module called Selective State Space Model Layer Aggregation (S6LA). This module aims to combine traditional CNN or transformer architectures within a sequential framework, enhancing the representational capabilities of state-of-the-art vision networks. Extensive experiments show that S6LA delivers substantial improvements in both image classification and detection tasks, highlighting the potential of integrating SSMs with contemporary deep learning techniques.', 'abstract_zh': '基于 Continuous 过程的深度神经网络层聚合研究：Selective State Space Model Layer Aggregation（S6LA）', 'title_zh': '从层到状态：深层神经网络层动态的态空间模型视角'}
{'arxiv_id': 'arXiv:2502.10450', 'title': 'Trustworthy AI on Safety, Bias, and Privacy: A Survey', 'authors': 'Xingli Fang, Jianwei Li, Varun Mulchandani, Jung-Eun Kim', 'link': 'https://arxiv.org/abs/2502.10450', 'abstract': "The capabilities of artificial intelligence systems have been advancing to a great extent, but these systems still struggle with failure modes, vulnerabilities, and biases. In this paper, we study the current state of the field, and present promising insights and perspectives regarding concerns that challenge the trustworthiness of AI models. In particular, this paper investigates the issues regarding three thrusts: safety, privacy, and bias, which hurt models' trustworthiness. For safety, we discuss safety alignment in the context of large language models, preventing them from generating toxic or harmful content. For bias, we focus on spurious biases that can mislead a network. Lastly, for privacy, we cover membership inference attacks in deep neural networks. The discussions addressed in this paper reflect our own experiments and observations.", 'abstract_zh': '人工智能系统的能力有了显著进步，但仍面临故障模式、漏洞和偏见等挑战。本文研究了该领域的当前状态，并提出了关于影响人工智能模型可信度的关注问题的有前景的见解和视角。特别地，本文探讨了安全、隐私和偏见这三个方面的关键问题，这些方面损害了模型的可信度。在安全方面，我们讨论了大规模语言模型的安全对齐，防止其生成毒害或有害内容。在偏见方面，我们关注可能导致网络误导的虚假偏见。最后，在隐私方面，我们讨论了深度神经网络中的成员推理攻击。本文的讨论反映了我们自己的实验和观察结果。', 'title_zh': '可信人工智能的安全性、偏差和隐私保护：一项综述'}
{'arxiv_id': 'arXiv:2502.10442', 'title': 'Analysis of Overparameterization in Continual Learning under a Linear Model', 'authors': 'Daniel Goldfarb, Paul Hand', 'link': 'https://arxiv.org/abs/2502.10442', 'abstract': 'Autonomous machine learning systems that learn many tasks in sequence are prone to the catastrophic forgetting problem. Mathematical theory is needed in order to understand the extent of forgetting during continual learning. As a foundational step towards this goal, we study continual learning and catastrophic forgetting from a theoretical perspective in the simple setting of gradient descent with no explicit algorithmic mechanism to prevent forgetting. In this setting, we analytically demonstrate that overparameterization alone can mitigate forgetting in the context of a linear regression model. We consider a two-task setting motivated by permutation tasks, and show that as the overparameterization ratio becomes sufficiently high, a model trained on both tasks in sequence results in a low-risk estimator for the first task. As part of this work, we establish a non-asymptotic bound of the risk of a single linear regression task, which may be of independent interest to the field of double descent theory.', 'abstract_zh': '自主学习系统在学习多个任务时容易出现灾难性遗忘问题。为了理解连续学习过程中遗忘的程度，需要数学理论进行解释。为了实现这一目标的基础步骤，我们从理论角度研究在没有防止遗忘的显式算法机制的梯度下降简单设置下，连续学习和灾难性遗忘。在这种设置下，我们通过分析证明，过参数化本身可以在线性回归模型的上下文中减轻遗忘。我们考虑了一个由排列任务启发的两任务设置，并表明当过参数化比例足够高时，依次训练两个任务的模型能产生第一个任务的低风险估计。作为这项工作的部分，我们建立了单个线性回归任务风险的非渐进界，这在双下降理论领域可能具有独立的兴趣。', 'title_zh': '持续学习环境中线性模型中超参数化分析'}
{'arxiv_id': 'arXiv:2502.10439', 'title': 'Crypto Miner Attack: GPU Remote Code Execution Attacks', 'authors': 'Ariel Szabo, Uzy Hadad', 'link': 'https://arxiv.org/abs/2502.10439', 'abstract': 'Remote Code Execution (RCE) exploits pose a significant threat to AI and ML systems, particularly in GPU-accelerated environments where the computational power of GPUs can be misused for malicious purposes. This paper focuses on RCE attacks leveraging deserialization vulnerabilities and custom layers, such as TensorFlow Lambda layers, which are often overlooked due to the complexity of monitoring GPU workloads. These vulnerabilities enable attackers to execute arbitrary code, blending malicious activity seamlessly into expected model behavior and exploiting GPUs for unauthorized tasks such as cryptocurrency mining. Unlike traditional CPU-based attacks, the parallel processing nature of GPUs and their high resource utilization make runtime detection exceptionally challenging. In this work, we provide a comprehensive examination of RCE exploits targeting GPUs, demonstrating an attack that utilizes these vulnerabilities to deploy a crypto miner on a GPU. We highlight the technical intricacies of such attacks, emphasize their potential for significant financial and computational costs, and propose strategies for mitigation. By shedding light on this underexplored attack vector, we aim to raise awareness and encourage the adoption of robust security measures in GPU-driven AI and ML systems, with an emphasis on static and model scanning as an easier way to detect exploits.', 'abstract_zh': 'Remote Code Execution攻击对AI和ML系统，特别是在GPU加速环境中，构成了显著威胁，因为GPU的计算能力可能被滥用以实现恶意目的。本文聚焦于利用反序列化漏洞和自定义层（如TensorFlow Lambda层）的RCE攻击，这些漏洞因监测GPU工作负载的复杂性而常被忽视。这些漏洞使攻击者能够执行任意代码，使其恶意活动无缝融入预期的模型行为，并利用GPU执行未经授权的任务，如加密货币挖掘。与传统的基于CPU的攻击不同，GPU并行处理的性质及其高资源利用率使其在运行时检测变得异常困难。在这项工作中，我们全面分析了针对GPU的RCE攻击，展示了利用这些漏洞部署加密货币挖掘程序的攻击方法。我们强调了此类攻击的技术复杂性，强调了它们对重大财务和计算成本的影响，并提出了缓解策略。通过揭示这一未被充分探索的攻击向量，我们旨在提高意识并鼓励在以GPU为主导的AI和ML系统中采用 robust的安全措施，强调静态和模型扫描作为检测攻击的一种更简单方法。', 'title_zh': 'GPU远程代码执行攻击：Crypto Miner攻击'}
{'arxiv_id': 'arXiv:2502.10436', 'title': 'MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs', 'authors': 'Tommaso Mencattini, Adrian Robert Minut, Donato Crisostomi, Andrea Santilli, Emanuele Rodolà', 'link': 'https://arxiv.org/abs/2502.10436', 'abstract': 'Evolutionary model merging enables the creation of high-performing multi-task models but remains computationally prohibitive for consumer hardware. We introduce MERGE$^3$, an efficient framework that makes evolutionary merging feasible on a single GPU by reducing fitness computation costs 50$\\times$ while preserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset for evaluation, Estimating model abilities using Item Response Theory (IRT), and Evolving optimal merges via IRT-based performance estimators. Our method enables state-of-the-art multilingual and cross-lingual merging, transferring knowledge across languages with significantly lower computational overhead. We provide theoretical guarantees and an open-source library, democratizing high-quality model merging.', 'abstract_zh': '进化模型合并使高性能多任务模型的创建成为可能，但由于计算上的限制，仍难以在消费级硬件上实现。我们介绍了MERGE$^3$，这是一个高效的框架，通过将 fitness 计算成本减少50倍同时保持性能，使其在单个GPU上变得可行。MERGE$^3$ 通过提取用于评估的减小数据集、使用项目反应理论（IRT）估计模型能力以及通过基于IRT的性能估算器进行进化最优合并，实现了这一点。我们的方法使得最先进的多语言和跨语言合并成为可能，以显著降低的计算开销将知识跨语言转移。我们提供了理论保证并开源了相关库，使高质量模型合并变得更加普及。', 'title_zh': 'MERGE³: 高效的消费者级GPU上进化合并'}
{'arxiv_id': 'arXiv:2502.10425', 'title': 'Neuron Platonic Intrinsic Representation From Dynamics Using Contrastive Learning', 'authors': 'Wei Wu, Can Liao, Zizhen Deng, Zhengrui Guo, Jinzhuo Wang', 'link': 'https://arxiv.org/abs/2502.10425', 'abstract': "The Platonic Representation Hypothesis suggests a universal, modality-independent reality representation behind different data modalities. Inspired by this, we view each neuron as a system and detect its multi-segment activity data under various peripheral conditions. We assume there's a time-invariant representation for the same neuron, reflecting its intrinsic properties like molecular profiles, location, and morphology. The goal of obtaining these intrinsic neuronal representations has two criteria: (I) segments from the same neuron should have more similar representations than those from different neurons; (II) the representations must generalize well to out-of-domain data. To meet these, we propose the NeurPIR (Neuron Platonic Intrinsic Representation) framework. It uses contrastive learning, with segments from the same neuron as positive pairs and those from different neurons as negative pairs. In implementation, we use VICReg, which focuses on positive pairs and separates dissimilar samples via regularization. We tested our method on Izhikevich model-simulated neuronal population dynamics data. The results accurately identified neuron types based on preset hyperparameters. We also applied it to two real-world neuron dynamics datasets with neuron type annotations from spatial transcriptomics and neuron locations. Our model's learned representations accurately predicted neuron types and locations and were robust on out-of-domain data (from unseen animals). This shows the potential of our approach for understanding neuronal systems and future neuroscience research.", 'abstract_zh': 'Platonic Representation Hypothesis启发的神经元本原内在表示研究：NeurPIR框架的应用', 'title_zh': '基于对比学习的神经元柏拉图文内在动力表示'}
{'arxiv_id': 'arXiv:2502.10422', 'title': 'DA-LIF: Dual Adaptive Leaky Integrate-and-Fire Model for Deep Spiking Neural Networks', 'authors': 'Tianqing Zhang, Kairong Yu, Jian Zhang, Hongwei Wang', 'link': 'https://arxiv.org/abs/2502.10422', 'abstract': 'Spiking Neural Networks (SNNs) are valued for their ability to process spatio-temporal information efficiently, offering biological plausibility, low energy consumption, and compatibility with neuromorphic hardware. However, the commonly used Leaky Integrate-and-Fire (LIF) model overlooks neuron heterogeneity and independently processes spatial and temporal information, limiting the expressive power of SNNs. In this paper, we propose the Dual Adaptive Leaky Integrate-and-Fire (DA-LIF) model, which introduces spatial and temporal tuning with independently learnable decays. Evaluations on both static (CIFAR10/100, ImageNet) and neuromorphic datasets (CIFAR10-DVS, DVS128 Gesture) demonstrate superior accuracy with fewer timesteps compared to state-of-the-art methods. Importantly, DA-LIF achieves these improvements with minimal additional parameters, maintaining low energy consumption. Extensive ablation studies further highlight the robustness and effectiveness of the DA-LIF model.', 'abstract_zh': '双适应泄漏积分-放电（DA-LIF）模型：提升时空调谐的脉冲神经网络', 'title_zh': 'DA-LIF: 双适应漏积分与放电模型用于深度脉冲神经网络'}
{'arxiv_id': 'arXiv:2502.10417', 'title': 'Evolutionary Power-Aware Routing in VANETs using Monte-Carlo Simulation', 'authors': 'J. Toutouh, S. Nesmachnow, E. Alba', 'link': 'https://arxiv.org/abs/2502.10417', 'abstract': 'This work addresses the reduction of power consumption of the AODV routing protocol in vehicular networks as an optimization problem. Nowadays, network designers focus on energy-aware communication protocols, specially to deploy wireless networks. Here, we introduce an automatic method to search for energy-efficient AODV configurations by using an evolutionary algorithm and parallel Monte-Carlo simulations to improve the accuracy of the evaluation of tentative solutions. The experimental results demonstrate that significant power consumption improvements over the standard configuration can be attained, with no noteworthy loss in the quality of service.', 'abstract_zh': '本工作将AODV路由协议在 vehicular 网络中的功耗降低问题作为一个优化问题进行研究。本文介绍了一种自动方法，通过使用进化算法和并行蒙特卡洛模拟来搜索能效更高的 AODV 配置，从而提高候选解决方案评估的准确性。实验结果表明，与标准配置相比，可以实现显著的功耗改善，同时服务质量并无明显下降。', 'title_zh': '使用蒙特卡洛模拟的进化功率感知路由在VANET中'}
{'arxiv_id': 'arXiv:2502.10412', 'title': 'Identifying relevant indicators for monitoring a National Artificial Intelligence Strategy', 'authors': 'Renata Pelissari, Ricardo Suyama, Leonardo Tomazeli Duarte, Henrique Sá Earp', 'link': 'https://arxiv.org/abs/2502.10412', 'abstract': "How can a National Artificial Intelligence Strategy be effectively monitored? To address this question, we propose a methodology consisting of two key components. First, it involves identifying relevant indicators within national AI strategies. Second, it assesses the alignment between these indicators and the strategic actions of a specific government's AI strategy, allowing for a critical evaluation of its monitoring measures. Moreover, identifying these indicators helps assess the overall quality of the strategy's structure. A lack of alignment between strategic actions and the identified indicators may reveal gaps or blind spots in the strategy. This methodology is demonstrated using the Brazilian AI strategy as a case study.", 'abstract_zh': '如何有效监控国家人工智能战略？为回答这一问题，我们提出了一种方法论，该方法论包含两个关键组成部分。首先，识别国家级人工智能战略中的相关指标。其次，评估这些指标与特定政府人工智能战略行动的一致性，从而对其监控措施进行批判性评估。此外，识别这些指标有助于评估战略结构的整体质量。战略行动与识别出的指标之间缺乏一致性可能揭示战略中的缺口或盲区。该方法论以巴西人工智能战略为例进行了示范。', 'title_zh': '识别监测国家人工智能战略的相关指标'}
{'arxiv_id': 'arXiv:2502.10410', 'title': 'Auto-Evaluation: A Critical Measure in Driving Improvements in Quality and Safety of AI-Generated Lesson Resources', 'authors': 'Hannah-Beth Clark, Margaux Dowland, Laura Benton, Reka Budai, Ibrahim Kaan Keskin, Emma Searle, Matthew Gregory, Mark Hodierne, William Gayne, John Roberts', 'link': 'https://arxiv.org/abs/2502.10410', 'abstract': 'As a publicly funded body in the UK, Oak National Academy is in a unique position to innovate within this field as we have a comprehensive curriculum of approximately 13,000 open education resources (OER) for all National Curriculum subjects, designed and quality-assured by expert, human teachers. This has provided the corpus of content needed for building a high-quality AI-powered lesson planning tool, Aila, that is free to use and, therefore, accessible to all teachers across the country. Furthermore, using our evidence-informed curriculum principles, we have codified and exemplified each component of lesson design. To assess the quality of lessons produced by Aila at scale, we have developed an AI-powered auto-evaluation agent,facilitating informed improvements to enhance output quality. Through comparisons between human and auto-evaluations, we have begun to refine this agent further to increase its accuracy, measured by its alignment with an expert human evaluator. In this paper we present this iterative evaluation process through an illustrative case study focused on one quality benchmark - the level of challenge within multiple-choice quizzes. We also explore the contribution that this may make to similar projects and the wider sector.', 'abstract_zh': '英国公共资助机构橡国 NATIONAL ACADEMY 在开源教育资源领域的创新及其高质量AI辅助教学规划工具Aila的研发与评估：以多项选择题难度水平为质量基准的案例研究及对该领域类似项目和更广泛领域的贡献探討', 'title_zh': '自动评估：驱动人工智能生成课程资源质量与安全改进的关键指标'}
{'arxiv_id': 'arXiv:2502.10408', 'title': "Knowledge Tracing in Programming Education Integrating Students' Questions", 'authors': 'Doyoun Kim, Suin Kim, Yojan Jo', 'link': 'https://arxiv.org/abs/2502.10408', 'abstract': "Knowledge tracing (KT) in programming education presents unique challenges due to the complexity of coding tasks and the diverse methods students use to solve problems. Although students' questions often contain valuable signals about their understanding and misconceptions, traditional KT models often neglect to incorporate these questions as inputs to address these challenges. This paper introduces SQKT (Students' Question-based Knowledge Tracing), a knowledge tracing model that leverages students' questions and automatically extracted skill information to enhance the accuracy of predicting students' performance on subsequent problems in programming education. Our method creates semantically rich embeddings that capture not only the surface-level content of the questions but also the student's mastery level and conceptual understanding. Experimental results demonstrate SQKT's superior performance in predicting student completion across various Python programming courses of differing difficulty levels. In in-domain experiments, SQKT achieved a 33.1\\% absolute improvement in AUC compared to baseline models. The model also exhibited robust generalization capabilities in cross-domain settings, effectively addressing data scarcity issues in advanced programming courses. SQKT can be used to tailor educational content to individual learning needs and design adaptive learning systems in computer science education.", 'abstract_zh': '基于学生提问的知识追踪（SQKT）在编程教育中的应用', 'title_zh': '编程教育中结合学生问题的 Knowledge Tracing'}
{'arxiv_id': 'arXiv:2502.10401', 'title': "You Can't Get There From Here: Redefining Information Science to address our sociotechnical futures", 'authors': 'Scott Humr, Mustafa Canan', 'link': 'https://arxiv.org/abs/2502.10401', 'abstract': 'Current definitions of Information Science are inadequate to comprehensively describe the nature of its field of study and for addressing the problems that are arising from intelligent technologies. The ubiquitous rise of artificial intelligence applications and their impact on society demands the field of Information Science acknowledge the sociotechnical nature of these technologies. Previous definitions of Information Science over the last six decades have inadequately addressed the environmental, human, and social aspects of these technologies. This perspective piece advocates for an expanded definition of Information Science that fully includes the sociotechnical impacts information has on the conduct of research in this field. Proposing an expanded definition of Information Science that includes the sociotechnical aspects of this field should stimulate both conversation and widen the interdisciplinary lens necessary to address how intelligent technologies may be incorporated into society and our lives more fairly.', 'abstract_zh': '当前信息科学的定义不足以全面描述其研究领域的特点，并应对由智能技术引起的问题。普遍兴起的人工智能应用及其对社会的影响要求信息科学领域承认这些技术的社技性质。过去六十年中信息科学的定义未能充分关注这些技术的环境、人类和社会方面。本文探讨扩展信息科学定义的必要性，以全面涵盖信息对这一领域研究活动的社会技术影响。提出包含社技方面的扩展信息科学定义应该促进讨论并扩大跨学科视角，以便更公平地将智能技术融入社会和我们的生活中。', 'title_zh': '无法在此基础上达到彼岸：重新定义信息科学以应对我们的社会技术未来'}
{'arxiv_id': 'arXiv:2502.10399', 'title': 'Data Stewardship Decoded: Mapping Its Diverse Manifestations and Emerging Relevance at a time of AI', 'authors': 'Stefaan Verhulst', 'link': 'https://arxiv.org/abs/2502.10399', 'abstract': 'Data stewardship has become a critical component of modern data governance, especially with the growing use of artificial intelligence (AI). Despite its increasing importance, the concept of data stewardship remains ambiguous and varies in its application. This paper explores four distinct manifestations of data stewardship to clarify its emerging position in the data governance landscape. These manifestations include a) data stewardship as a set of competencies and skills, b) a function or role within organizations, c) an intermediary organization facilitating collaborations, and d) a set of guiding principles. The paper subsequently outlines the core competencies required for effective data stewardship, explains the distinction between data stewards and Chief Data Officers (CDOs), and details the intermediary role of stewards in bridging gaps between data holders and external stakeholders. It also explores key principles aligned with the FAIR framework (Findable, Accessible, Interoperable, Reusable) and introduces the emerging principle of AI readiness to ensure data meets the ethical and technical requirements of AI systems. The paper emphasizes the importance of data stewardship in enhancing data collaboration, fostering public value, and managing data reuse responsibly, particularly in the era of AI. It concludes by identifying challenges and opportunities for advancing data stewardship, including the need for standardized definitions, capacity building efforts, and the creation of a professional association for data stewardship.', 'abstract_zh': '数据 stewardship已成为现代数据治理的关键组成部分，尤其是在人工智能（AI）使用不断增加的情况下。尽管其重要性日益提高，但数据 stewardship的概念仍然模糊不清且在应用上存在差异。本文探讨了四种数据 stewardship的不同表现形式，以澄清其在数据治理格局中的新兴地位。这些表现形式包括a) 数据 stewardship作为一组能力和技能，b) 组织内的功能或角色，c) 促进合作的中间组织，以及d) 一套指导原则。本文随后概述了有效数据 stewardship所需的核心能力，解释了数据 stewardship与首席数据官（CDO）之间的区别，并详细介绍了数据 stewardship在数据持有者与外部利益相关者之间填补差距的中间角色。文章还探讨了与 FAIR 原则（可查找的、可访问的、互操作的、可重用的）一致的关键原则，并介绍了确保数据符合人工智能系统伦理和技术要求的新兴原则——AI 准备度。文章强调了数据 stewardship在增强数据协作、促进公共价值和负责任地管理数据重用方面的重要性，尤其是在人工智能时代。最后，文章指出了数据 stewardship发展面临的挑战和机遇，包括标准化定义的需求、能力培养努力，以及建立数据 stewardship专业组织的重要性。', 'title_zh': '数据 stewardship 解码：映射其多样表现及其在人工智能时代的新兴相关性'}
{'arxiv_id': 'arXiv:2502.10398', 'title': 'Practical Application and Limitations of AI Certification Catalogues', 'authors': 'Gregor Autischer, Kerstin Waxnegger, Dominik Kowald', 'link': 'https://arxiv.org/abs/2502.10398', 'abstract': "In this work-in-progress, we investigate the certification of artificial intelligence (AI) systems, focusing on the practical application and limitations of existing certification catalogues by attempting to certify a publicly available AI system. We aim to evaluate how well current approaches work to effectively certify an AI system, and how publicly accessible AI systems, that might not be actively maintained or initially intended for certification, can be selected and used for a sample certification process. Our methodology involves leveraging the Fraunhofer AI Assessment Catalogue as a comprehensive tool to systematically assess an AI model's compliance with certification standards. We find that while the catalogue effectively structures the evaluation process, it can also be cumbersome and time-consuming to use. We observe the limitations of an AI system that has no active development team anymore and highlighted the importance of complete system documentation. Finally, we identify some limitations of the certification catalogues used and proposed ideas on how to streamline the certification process.", 'abstract_zh': '本研究进展中，我们探讨了人工智能（AI）系统的认证问题，重点关注现有认证目录的实际应用和局限性，通过尝试认证一个公开可用的AI系统来进行研究。我们旨在评估当前方法在有效认证AI系统方面的效果，并考察如何选择和利用可能未被积极维护或最初未旨在认证的公开访问AI系统进行样例认证过程。我们的方法包括利用弗劳恩霍夫AI评估目录作为全面工具来系统地评估AI模型是否符合认证标准。我们发现虽然目录有效地组织了评估过程，但使用起来也可能繁琐耗时。我们观察到一个没有任何活跃开发团队的AI系统的局限性，并强调了完整系统文档的重要性。最后，我们识别出现有认证目录的一些局限性，并提出了简化认证过程的建议。', 'title_zh': 'AI认证目录的实际应用与限制'}
{'arxiv_id': 'arXiv:2502.10396', 'title': 'DASKT: A Dynamic Affect Simulation Method for Knowledge Tracing', 'authors': 'Xinjie Sun, Kai Zhang, Qi Liu, Shuanghong Shen, Fei Wang, Yuxiang Guo, Enhong Chen', 'link': 'https://arxiv.org/abs/2502.10396', 'abstract': "Knowledge Tracing (KT) predicts future performance by modeling students' historical interactions, and understanding students' affective states can enhance the effectiveness of KT, thereby improving the quality of education. Although traditional KT values students' cognition and learning behaviors, efficient evaluation of students' affective states and their application in KT still require further exploration due to the non-affect-oriented nature of the data and budget constraints. To address this issue, we propose a computation-driven approach, Dynamic Affect Simulation Knowledge Tracing (DASKT), to explore the impact of various student affective states (such as frustration, concentration, boredom, and confusion) on their knowledge states. In this model, we first extract affective factors from students' non-affect-oriented behavioral data, then use clustering and spatiotemporal sequence modeling to accurately simulate students' dynamic affect changes when dealing with different problems. Subsequently, {\\color{blue}we incorporate affect with time-series analysis to improve the model's ability to infer knowledge states over time and space.} Extensive experimental results on two public real-world educational datasets show that DASKT can achieve more reasonable knowledge states under the effect of students' affective states. Moreover, DASKT outperforms the most advanced KT methods in predicting student performance. Our research highlights a promising avenue for future KT studies, focusing on achieving high interpretability and accuracy.", 'abstract_zh': '动态情感模拟知识追踪（DASKT）', 'title_zh': 'DASKT：一种动态情感模拟的知识追踪方法'}
{'arxiv_id': 'arXiv:2502.10395', 'title': 'An Integrated Platform for Studying Learning with Intelligent Tutoring Systems: CTAT+TutorShop', 'authors': 'Vincent Aleven, Conrad Borchers, Yun Huang, Tomohiro Nagashima, Bruce McLaren, Paulo Carvalho, Octav Popescu, Jonathan Sewall, Kenneth Koedinger', 'link': 'https://arxiv.org/abs/2502.10395', 'abstract': 'Intelligent tutoring systems (ITSs) are effective in helping students learn; further research could make them even more effective. Particularly desirable is research into how students learn with these systems, how these systems best support student learning, and what learning sciences principles are key in ITSs. CTAT+Tutorshop provides a full stack integrated platform that facilitates a complete research lifecycle with ITSs, which includes using ITS data to discover learner challenges, to identify opportunities for system improvements, and to conduct experimental studies. The platform includes authoring tools to support and accelerate development of ITS, which provide automatic data logging in a format compatible with DataShop, an independent site that supports the analysis of ed tech log data to study student learnings. Among the many technology platforms that exist to support learning sciences research, CTAT+Tutorshop may be the only one that offers researchers the possibility to author elements of ITSs, or whole ITSs, as part of designing studies. This platform has been used to develop and conduct an estimated 147 research studies which have run in a wide variety of laboratory and real-world educational settings, including K-12 and higher education, and have addressed a wide range of research questions. This paper presents five case studies of research conducted on the CTAT+Tutorshop platform, and summarizes what has been accomplished and what is possible for future researchers. We reflect on the distinctive elements of this platform that have made it so effective in facilitating a wide range of ITS research.', 'abstract_zh': '智能辅导系统（ITSs）在帮助学生学习方面是有效的；进一步研究可以使它们更加有效。特别 desirable 的是关于学生如何使用这些系统进行学习、这些系统如何最好地支持学生学习以及哪些学习科学原则在ITSs中至关重要的研究。CTAT+Tutorshop 提供了一个完整的集成平台，可以促进从头到尾的ITS研究生命周期，包括使用ITS数据发现学习者挑战、识别系统改进机会以及进行实验研究。该平台包括支持和加速ITS开发的写作工具，这些工具提供自动数据日志记录，格式兼容 DataShop，这是一个独立站点，支持对教育技术日志数据进行分析以研究学生的学习。在众多支持学习科学研究的技术平台中，CTAT+Tutorshop 可能是唯一一个允许研究者在设计研究时编写ITS元素或整个ITS的平台。该平台已被用于开发和开展约 147 项研究，这些研究在各种实验室和实际教育环境中运行，涉及从小学至高中和高等教育，并解决了广泛的研究问题。本文介绍了五项在 CTAT+Tutorshop 平台上进行的研究案例，并总结了已经取得的成果以及未来研究人员可能实现的可能性。我们反思了这一平台的独特元素，这些元素使其能够有效促进广泛范围内的ITS研究。', 'title_zh': '基于智能辅导系统的学习研究集成平台：CTAT+TutorShop'}
