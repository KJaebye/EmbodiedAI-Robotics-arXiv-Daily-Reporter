{'arxiv_id': 'arXiv:2502.16856', 'title': 'SLABIM: A SLAM-BIM Coupled Dataset in HKUST Main Building', 'authors': 'Haoming Huang, Zhijian Qiao, Zehuan Yu, Chuhao Liu, Shaojie Shen, Fumin Zhang, Huan Yin', 'link': 'https://arxiv.org/abs/2502.16856', 'abstract': 'Existing indoor SLAM datasets primarily focus on robot sensing, often lacking building architectures. To address this gap, we design and construct the first dataset to couple the SLAM and BIM, named SLABIM. This dataset provides BIM and SLAM-oriented sensor data, both modeling a university building at HKUST. The as-designed BIM is decomposed and converted for ease of use. We employ a multi-sensor suite for multi-session data collection and mapping to obtain the as-built model. All the related data are timestamped and organized, enabling users to deploy and test effectively. Furthermore, we deploy advanced methods and report the experimental results on three tasks: registration, localization and semantic mapping, demonstrating the effectiveness and practicality of SLABIM. We make our dataset open-source at this https URL.', 'abstract_zh': '现有的室内SLAM数据集主要关注机器人感知，往往缺乏建筑结构信息。为解决这一问题，我们设计并构建了首个结合SLAM和BIM的数据集，命名为SLABIM。该数据集提供了面向SLAM和BIM的传感器数据，建模香港科技大学的一栋大学建筑。我们设计的BIM被分解和转换以方便使用。我们采用多传感器套件进行多会次的数据采集和建图，以获得建成模型。所有相关数据均按时间戳组织，便于用户部署和测试。此外，我们部署了先进方法并报告了在模型注册、定位和语义建图三个任务上的实验结果，展示了SLABIM的有效性和实用性。我们已在该网址开源了我们的数据集。', 'title_zh': 'SLABIM: � Actor实时建图与建筑信息建模耦合数据集在港科大主楼中的应用'}
{'arxiv_id': 'arXiv:2502.16847', 'title': "Characterizing Structured versus Unstructured Environments based on Pedestrians' and Vehicles' Motion Trajectories", 'authors': 'Mahsa Golchoubian, Moojan Ghafurian, Nasser Lashgarian Azad, Kerstin Dautenhahn', 'link': 'https://arxiv.org/abs/2502.16847', 'abstract': "Trajectory behaviours of pedestrians and vehicles operating close to each other can be different in unstructured compared to structured environments. These differences in the motion behaviour are valuable to be considered in the trajectory prediction algorithm of an autonomous vehicle. However, the available datasets on pedestrians' and vehicles' trajectories that are commonly used as benchmarks for trajectory prediction have not been classified based on the nature of their environment. On the other hand, the definitions provided for unstructured and structured environments are rather qualitative and hard to be used for justifying the type of a given environment. In this paper, we have compared different existing datasets based on a couple of extracted trajectory features, such as mean speed and trajectory variability. Through K-means clustering and generalized linear models, we propose more quantitative measures for distinguishing the two different types of environments. Our results show that features such as trajectory variability, stop fraction and density of pedestrians are different among the two environmental types and can be used to classify the existing datasets.", 'abstract_zh': '行人和车辆在结构化与非结构化环境中近距离操作的轨迹行为有所不同。这些运动行为差异对于自动驾驶车辆的轨迹预测算法来说是值得考虑的重要因素。然而，用于轨迹预测基准测试的行人和车辆轨迹数据集尚未基于环境特性进行分类。另一方面，关于非结构化和结构化环境的定义相对定性，难以用于环境类型的论证。在本文中，我们基于提取的轨迹特征（如平均速度和轨迹变异度）比较了不同的现有数据集，并通过K-means聚类和广义线性模型提出了更为定量的环境区分措施。结果表明，轨迹变异度、停止比例和行人密度等特征在两种环境类型之间存在差异，并可用于分类现有数据集。', 'title_zh': '基于行人和车辆运动轨迹区分结构化环境与非结构化环境'}
{'arxiv_id': 'arXiv:2502.16495', 'title': 'Orchestrating Joint Offloading and Scheduling for Low-Latency Edge SLAM', 'authors': 'Yao Zhang, Yuyi Mao, Hui Wang, Zhiwen Yu, Song Guo, Jun Zhang, Liang Wang, Bin Guo', 'link': 'https://arxiv.org/abs/2502.16495', 'abstract': "Visual Simultaneous Localization and Mapping (vSLAM) is a prevailing technology for many emerging robotic applications. Achieving real-time SLAM on mobile robotic systems with limited computational resources is challenging because the complexity of SLAM algorithms increases over time. This restriction can be lifted by offloading computations to edge servers, forming the emerging paradigm of edge-assisted SLAM. Nevertheless, the exogenous and stochastic input processes affect the dynamics of the edge-assisted SLAM system. Moreover, the requirements of clients on SLAM metrics change over time, exerting implicit and time-varying effects on the system. In this paper, we aim to push the limit beyond existing edge-assist SLAM by proposing a new architecture that can handle the input-driven processes and also satisfy clients' implicit and time-varying requirements. The key innovations of our work involve a regional feature prediction method for importance-aware local data processing, a configuration adaptation policy that integrates data compression/decompression and task offloading, and an input-dependent learning framework for task scheduling with constraint satisfaction. Extensive experiments prove that our architecture improves pose estimation accuracy and saves up to 47% of communication costs compared with a popular edge-assisted SLAM system, as well as effectively satisfies the clients' requirements.", 'abstract_zh': '基于边端协助的视觉即时定位与地图构建(vSLAM)：一种处理输入驱动过程并满足客户隐含和时变要求的新架构', 'title_zh': '低延迟边缘SLAM中的联合卸载与调度 orchestrating'}
{'arxiv_id': 'arXiv:2502.15961', 'title': 'IA-TIGRIS: An Incremental and Adaptive Sampling-Based Planner for Online Informative Path Planning', 'authors': 'Brady Moon, Nayana Suvarna, Andrew Jong, Satrajit Chatterjee, Junbin Yuan, Sebastian Scherer', 'link': 'https://arxiv.org/abs/2502.15961', 'abstract': 'Planning paths that maximize information gain for robotic platforms has wide-ranging applications and significant potential impact. To effectively adapt to real-time data collection, informative path planning must be computed online and be responsive to new observations. In this work, we present IA-TIGRIS, an incremental and adaptive sampling-based informative path planner that can be run efficiently with onboard computation. Our approach leverages past planning efforts through incremental refinement while continuously adapting to updated world beliefs. We additionally present detailed implementation and optimization insights to facilitate real-world deployment, along with an array of reward functions tailored to specific missions and behaviors. Extensive simulation results demonstrate IA-TIGRIS generates higher-quality paths compared to baseline methods. We validate our planner on two distinct hardware platforms: a hexarotor UAV and a fixed-wing UAV, each having unique motion models and configuration spaces. Our results show up to a 41% improvement in information gain compared to baseline methods, suggesting significant potential for deployment in real-world applications.', 'abstract_zh': '基于增量和自适应采样的信息增益路径规划算法IA-TIGRIS及其应用', 'title_zh': 'IA-TIGRIS: 一种增量自适应基于采样的在线信息性路径规划算法'}
{'arxiv_id': 'arXiv:2502.15824', 'title': 'Getting SMARTER for Motion Planning in Autonomous Driving Systems', 'authors': 'Montgomery Alban, Ehsan Ahmadi, Randy Goebel, Amir Rasouli', 'link': 'https://arxiv.org/abs/2502.15824', 'abstract': 'Motion planning is a fundamental problem in autonomous driving and perhaps the most challenging to comprehensively evaluate because of the associated risks and expenses of real-world deployment. Therefore, simulations play an important role in efficient development of planning algorithms. To be effective, simulations must be accurate and realistic, both in terms of dynamics and behavior modeling, and also highly customizable in order to accommodate a broad spectrum of research frameworks. In this paper, we introduce SMARTS 2.0, the second generation of our motion planning simulator which, in addition to being highly optimized for large-scale simulation, provides many new features, such as realistic map integration, vehicle-to-vehicle (V2V) communication, traffic and pedestrian simulation, and a broad variety of sensor models.\nMoreover, we present a novel benchmark suite for evaluating planning algorithms in various highly challenging scenarios, including interactive driving, such as turning at intersections, and adaptive driving, in which the task is to closely follow a lead vehicle without any explicit knowledge of its intention. Each scenario is characterized by a variety of traffic patterns and road structures. We further propose a series of common and task-specific metrics to effectively evaluate the performance of the planning algorithms. At the end, we evaluate common motion planning algorithms using the proposed benchmark and highlight the challenges the proposed scenarios impose. The new SMARTS 2.0 features and the benchmark are publicly available at this http URL.', 'abstract_zh': '自主驾驶中的运动规划是一个基本问题，由于实际部署相关风险和成本，全面评估尤为困难。因此，模拟在高效开发规划算法中起着重要作用。为了有效，模拟必须在动力学和行为建模方面准确且现实，并且高度可定制，以适应广泛的科研框架。在本文中，我们介绍了SMARTS 2.0，这是我们运动规划模拟器的第二代产品，除了高度优化的大规模模拟外，还提供了许多新功能，如真实的地图集成、车对车通信、交通和行人模拟，以及广泛的传感器模型。此外，我们提出了一组新的基准测试套件，用于在各种高度挑战性场景中评估规划算法，包括交互式驾驶（如交叉路口转弯）和自适应驾驶（即紧跟前车而无需明确了解其意图）。每个场景都由各种交通模式和道路结构特征描述。我们还提出了一系列通用和任务特定的评估指标，以有效评估规划算法的性能。最后，我们使用所提出的基准测试评估常用的运动规划算法，并强调提出的场景所造成的挑战。新的SMARTS 2.0功能和基准测试可在以下网址公开获取。', 'title_zh': '面向自主驾驶系统的运动规划SMARTER方法'}
{'arxiv_id': 'arXiv:2502.17399', 'title': 'Enriching Physical-Virtual Interaction in AR Gaming by Tracking Identical Real Objects', 'authors': 'Liuchuan Yu, Ching-I Huang, Hsueh-Cheng Wang, Lap-Fai Yu', 'link': 'https://arxiv.org/abs/2502.17399', 'abstract': 'Augmented reality (AR) games, particularly those designed for headsets, have become increasingly prevalent with advancements in both hardware and software. However, the majority of AR games still rely on pre-scanned or static scenes, and interaction mechanisms are often limited to controllers or hand-tracking. Additionally, the presence of identical objects in AR games poses challenges for conventional object tracking techniques, which often struggle to differentiate between identical objects or necessitate the installation of fixed cameras for global object movement tracking. In response to these limitations, we present a novel approach to address the tracking of identical objects in an AR scene to enrich physical-virtual interaction. Our method leverages partial scene observations captured by an AR headset, utilizing the perspective and spatial data provided by this technology. Object identities within the scene are determined through the solution of a label assignment problem using integer programming. To enhance computational efficiency, we incorporate a Voronoi diagram-based pruning method into our approach. Our implementation of this approach in a farm-to-table AR game demonstrates its satisfactory performance and robustness. Furthermore, we showcase the versatility and practicality of our method through applications in AR storytelling and a simulated gaming robot. Our video demo is available at: this https URL.', 'abstract_zh': '增强现实（AR）游戏，特别是为头戴式设备设计的游戏，在硬件和软件的进步推动下越来越普遍。然而，大多数AR游戏仍然依赖于预先扫描或静态场景，且交互机制常常局限于控制器或手部追踪。此外，AR游戏中同一物体的出现为传统的物体跟踪技术带来了挑战，这些技术往往难以区分同一物体，或者需要安装固定摄像头以追踪全局物体运动。为应对这些限制，我们提出了一种新的方法，以解决AR场景中同一物体的跟踪问题，从而丰富物理-虚拟交互。该方法利用AR头戴设备捕获的部分场景观察数据，通过整数规划解决标签分配问题来确定场景中的物体身份。为了提高计算效率，我们在方法中引入了基于Voronoi图的剪枝方法。我们在一个从农场到餐桌的AR游戏中实现了该方法，并展示了其满意的性能和鲁棒性。此外，我们通过AR叙述和模拟游戏机器人应用展示了该方法的多样性和实用性。我们的视频demo可在以下链接查看：this https URL。', 'title_zh': '通过追踪相同的真实物体来丰富AR游戏中的物理-虚拟交互'}
{'arxiv_id': 'arXiv:2502.17295', 'title': 'Co-Designing Augmented Reality Tools for High-Stakes Clinical Teamwork', 'authors': 'Angelique Taylor, Tauhid Tanjim, Huajie Cao, Jalynn Blu Nicoly, Jonathan I. Segal, Jonathan St. George, Soyon Kim, Kevin Ching, Francisco R. Ortega, Hee Rin Lee', 'link': 'https://arxiv.org/abs/2502.17295', 'abstract': 'How might healthcare workers (HCWs) leverage augmented reality head-mounted displays (AR-HMDs) to enhance teamwork? Although AR-HMDs have shown immense promise in supporting teamwork in healthcare settings, design for Emergency Department (ER) teams has received little attention. The ER presents unique challenges, including procedural recall, medical errors, and communication gaps. To address this gap, we engaged in a participatory design study with healthcare workers to gain a deep understanding of the potential for AR-HMDs to facilitate teamwork during ER procedures. Our results reveal that AR-HMDs can be used as an information-sharing and information-retrieval system to bridge knowledge gaps, and concerns about integrating AR-HMDs in ER workflows. We contribute design recommendations for seven role-based AR-HMD application scenarios involving HCWs with various expertise, working across multiple medical tasks. We hope our research inspires designers to embark on the development of new AR-HMD applications for high-stakes, team environments.', 'abstract_zh': '如何让 healthcare 工作人员利用增强现实头戴式显示屏（AR-HMD）提升团队协作？尽管 AR-HMD 在支持医疗环境中团队协作方面展现出巨大潜力，但针对急诊部门（ER）团队的设计研究却很少。ER 环境中存在着程序回忆、医疗错误和沟通缺口等独特挑战。为弥补这一不足，我们与 healthcare 工作人员合作开展了一项参与式设计研究，深入了解 AR-HMD 在 ER 操作过程中促进团队协作的潜在价值。研究结果表明，AR-HMD 可作为信息共享和检索系统，用于填补知识空白，并缓解在 ER 工作流程中整合 AR-HMD 的关切。我们提出了针对涉及不同专业水平的 healthcare 工作人员、参与多种医疗任务的七种角色导向的 AR-HMD 应用场景的设计建议。我们希望我们的研究能够激发设计师开发适用于高风险团队环境的新 AR-HMD 应用。', 'title_zh': '协同设计高风险临床团队协作的增强现实工具'}
{'arxiv_id': 'arXiv:2502.16589', 'title': 'Co-MTP: A Cooperative Trajectory Prediction Framework with Multi-Temporal Fusion for Autonomous Driving', 'authors': 'Xinyu Zhang, Zewei Zhou, Zhaoyi Wang, Yangjie Ji, Yanjun Huang, Hong Chen', 'link': 'https://arxiv.org/abs/2502.16589', 'abstract': "Vehicle-to-everything technologies (V2X) have become an ideal paradigm to extend the perception range and see through the occlusion. Exiting efforts focus on single-frame cooperative perception, however, how to capture the temporal cue between frames with V2X to facilitate the prediction task even the planning task is still underexplored. In this paper, we introduce the Co-MTP, a general cooperative trajectory prediction framework with multi-temporal fusion for autonomous driving, which leverages the V2X system to fully capture the interaction among agents in both history and future domains to benefit the planning. In the history domain, V2X can complement the incomplete history trajectory in single-vehicle perception, and we design a heterogeneous graph transformer to learn the fusion of the history feature from multiple agents and capture the history interaction. Moreover, the goal of prediction is to support future planning. Thus, in the future domain, V2X can provide the prediction results of surrounding objects, and we further extend the graph transformer to capture the future interaction among the ego planning and the other vehicles' intentions and obtain the final future scenario state under a certain planning action. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and the results show that Co-MTP achieves state-of-the-art performance and that both history and future fusion can greatly benefit prediction.", 'abstract_zh': '基于V2X的多时序融合协同轨迹预测框架', 'title_zh': '共融多时态轨迹预测框架：自主驾驶中的多时态融合'}
{'arxiv_id': 'arXiv:2502.16389', 'title': 'An Expert Ensemble for Detecting Anomalous Scenes, Interactions, and Behaviors in Autonomous Driving', 'authors': 'Tianchen Ji, Neeloy Chakraborty, Andre Schreiber, Katherine Driggs-Campbell', 'link': 'https://arxiv.org/abs/2502.16389', 'abstract': 'As automated vehicles enter public roads, safety in a near-infinite number of driving scenarios becomes one of the major concerns for the widespread adoption of fully autonomous driving. The ability to detect anomalous situations outside of the operational design domain is a key component in self-driving cars, enabling us to mitigate the impact of abnormal ego behaviors and to realize trustworthy driving systems. On-road anomaly detection in egocentric videos remains a challenging problem due to the difficulties introduced by complex and interactive scenarios. We conduct a holistic analysis of common on-road anomaly patterns, from which we propose three unsupervised anomaly detection experts: a scene expert that focuses on frame-level appearances to detect abnormal scenes and unexpected scene motions; an interaction expert that models normal relative motions between two road participants and raises alarms whenever anomalous interactions emerge; and a behavior expert which monitors abnormal behaviors of individual objects by future trajectory prediction. To combine the strengths of all the modules, we propose an expert ensemble (Xen) using a Kalman filter, in which the final anomaly score is absorbed as one of the states and the observations are generated by the experts. Our experiments employ a novel evaluation protocol for realistic model performance, demonstrate superior anomaly detection performance than previous methods, and show that our framework has potential in classifying anomaly types using unsupervised learning on a large-scale on-road anomaly dataset.', 'abstract_zh': '随着自动驾驶车辆进入公共道路，全面自主驾驶的广泛应用在近乎无尽的驾驶场景中面临的安全性成为主要关注点。检测超出操作设计域的异常情况的能力是自动驾驶汽车的关键组成部分，使我们能够减轻异常自我行为的影响，并实现可信的驾驶系统。由于复杂且相互作用的场景带来的挑战，基于第一人称视频的现场异常检测仍然是一个难题。我们对常见的现场异常模式进行整体分析，提出三种无监督异常检测专家：场景专家专注于帧级外观以检测异常场景和意外场景运动；交互专家建模两个道路参与者之间的正常相对运动，并在出现异常交互时发出警报；行为专家通过未来轨迹预测监控单个对象的异常行为。为了结合所有模块的优势，我们提出了一种专家集成（Xen）方法，使用卡尔曼滤波器，其中最终的异常分数作为状态之一，观测结果由专家生成。我们的实验采用了一种新的评估协议来评估现实模型性能，展示了比先前方法更好的异常检测性能，并证明了我们的框架在使用无监督学习对大型现场异常数据集进行异常类型分类方面具有潜力。', 'title_zh': '专家集成用于检测自动驾驶中异常场景、交互和行为'}
{'arxiv_id': 'arXiv:2502.16121', 'title': 'From Target Tracking to Targeting Track -- Part II: Regularized Polynomial Trajectory Optimization', 'authors': 'Tiancheng Li, Yan Song, Guchong Li, Hao Li', 'link': 'https://arxiv.org/abs/2502.16121', 'abstract': 'Target tracking entails the estimation of the evolution of the target state over time, namely the target trajectory. Different from the classical state space model, our series of studies, including this paper, model the collection of the target state as a stochastic process (SP) that is further decomposed into a deterministic part which represents the trend of the trajectory and a residual SP representing the residual fitting error. Subsequently, the tracking problem is formulated as a learning problem regarding the trajectory SP for which a key part is to estimate a trajectory FoT (T-FoT) best fitting the measurements in time series. For this purpose, we consider the polynomial T-FoT and address the regularized polynomial T-FoT optimization employing two distinct regularization strategies seeking trade-off between the accuracy and simplicity. One limits the order of the polynomial and then the best choice is determined by grid searching in a narrow, bounded range while the other adopts $\\ell_0$ norm regularization for which the hybrid Newton solver is employed. Simulation results obtained in both single and multiple maneuvering target scenarios demonstrate the effectiveness of our approaches.', 'abstract_zh': '目标跟踪涉及目标状态随时间演变的估计，即目标轨迹。不同于经典的状态空间模型，我们一系列的研究，包括本文在内，将目标状态集合建模为一个随机过程（SP），该过程进一步分解为表示轨迹趋势的确定性部分和表示残差拟合误差的残差SP。随后，跟踪问题被形式化为关于轨迹SP的学习问题，其中关键部分是估计一个最佳拟合时间序列测量的轨迹FoT（T-FoT）。为此，我们考虑多项式T-FoT，并采用两种不同的正则化策略解决正则化多项式T-FoT优化问题，以在准确性与简单性之间寻求平衡。一种策略限制多项式的阶数，然后通过在一个狭窄、有界的范围内进行网格搜索确定最佳选择，另一种策略采用$\\ell_0$范数正则化，使用混合牛顿求解器。在单个和多个机动目标场景下获得的仿真结果证明了我们方法的有效性。', 'title_zh': '从目标跟踪到轨迹瞄准——Part II：正则化多项式轨迹优化'}
{'arxiv_id': 'arXiv:2502.15792', 'title': 'Multi-Objective Reinforcement Learning for Critical Scenario Generation of Autonomous Vehicles', 'authors': 'Jiahui Wu, Chengjie Lu, Aitor Arrieta, Shaukat Ali', 'link': 'https://arxiv.org/abs/2502.15792', 'abstract': "Autonomous vehicles (AVs) make driving decisions without human intervention. Therefore, ensuring AVs' dependability is critical. Despite significant research and development in AV development, their dependability assurance remains a significant challenge due to the complexity and unpredictability of their operating environments. Scenario-based testing evaluates AVs under various driving scenarios, but the unlimited number of potential scenarios highlights the importance of identifying critical scenarios that can violate safety or functional requirements. Such requirements are inherently interdependent and need to be tested simultaneously. To this end, we propose MOEQT, a novel multi-objective reinforcement learning (MORL)-based approach to generate critical scenarios that simultaneously test interdependent safety and functional requirements. MOEQT adapts Envelope Q-learning as the MORL algorithm, which dynamically adapts multi-objective weights to balance the relative importance between multiple objectives. MOEQT generates critical scenarios to violate multiple requirements through dynamically interacting with the AV environment, ensuring comprehensive AV testing. We evaluate MOEQT using an advanced end-to-end AV controller and a high-fidelity simulator and compare MOEQT with two baselines: a random strategy and a single-objective RL with a weighted reward function. Our evaluation results show that MOEQT achieved an overall better performance in identifying critical scenarios for violating multiple requirements than the baselines.", 'abstract_zh': '自主驾驶车辆（AVs）在无需人类干预的情况下作出驾驶决策，因此确保其可靠性至关重要。尽管在AV开发方面进行了大量研究和开发，但由于其操作环境的复杂性和不可预测性，其可靠性保证仍然是一个重大挑战。基于场景的测试在各种驾驶场景下评估AVs，但潜在场景的无限数量强调了识别可能违反安全或功能要求的关键场景的重要性。这些要求本质上是相互依赖的，并且需要同时进行测试。为此，我们提出了一种新的基于多目标强化学习（MORL）的方法MOEQT，以生成同时测试相互依赖的安全和功能要求的关键场景。MOEQT采用Envelope Q-learning作为MORL算法，该算法动态调整多目标权重以平衡多个目标之间的相对重要性。MOEQT通过与AV环境动态交互生成关键场景，以违反多个要求，确保全面的AV测试。我们使用先进的端到端AV控制器和高保真模拟器评估MOEQT，并将MOEQT与两种基线进行比较：随机策略和具有加权奖励函数的单目标RL。我们的评估结果表明，MOEQT在识别违反多个要求的关键场景方面总体上优于基线方法。', 'title_zh': '自主车辆关键场景生成的多目标强化学习'}
{'arxiv_id': 'arXiv:2502.17289', 'title': 'A novel approach to navigate the taxonomic hierarchy to address the Open-World Scenarios in Medicinal Plant Classification', 'authors': 'Soumen Sinha, Tanisha Rana, Rahul Roy', 'link': 'https://arxiv.org/abs/2502.17289', 'abstract': 'In this article, we propose a novel approach for plant hierarchical taxonomy classification by posing the problem as an open class problem. It is observed that existing methods for medicinal plant classification often fail to perform hierarchical classification and accurately identifying unknown species, limiting their effectiveness in comprehensive plant taxonomy classification. Thus we address the problem of unknown species classification by assigning it best hierarchical labels. We propose a novel method, which integrates DenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for hierarchical classification. The approach systematically categorizes medicinal plants at multiple taxonomic levels, from phylum to species, ensuring detailed and precise classification. Using multi scale space attention, the model captures both local and global contextual information from the images, improving the distinction between similar species and the identification of new ones. It uses attention scores to focus on important features across multiple scales. The proposed method provides a solution for hierarchical classification, showcasing superior performance in identifying both known and unknown species. The model was tested on two state-of-art datasets with and without background artifacts and so that it can be deployed to tackle real word application. We used unknown species for testing our model. For unknown species the model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for predicting correct phylum, class, order and family respectively. Our proposed model size is almost four times less than the existing state of the art methods making it easily deploy able in real world application.', 'abstract_zh': '一种用于植物层次分类的新型开集方法：基于未知物种分类的详细精准分类', 'title_zh': '一种新颖的方法导航分类层次以应对药用植物分类中的开放世界场景'}
{'arxiv_id': 'arXiv:2502.17132', 'title': 'Applications of Large Models in Medicine', 'authors': 'YunHe Su, Zhengyang Lu, Junhui Liu, Ke Pang, Haoran Dai, Sa Liu Yuxin Jia, Lujia Ge, Jing-min Yang', 'link': 'https://arxiv.org/abs/2502.17132', 'abstract': 'This paper explores the advancements and applications of large-scale models in the medical field, with a particular focus on Medical Large Models (MedLMs). These models, encompassing Large Language Models (LLMs), Vision Models, 3D Large Models, and Multimodal Models, are revolutionizing healthcare by enhancing disease prediction, diagnostic assistance, personalized treatment planning, and drug discovery. The integration of graph neural networks in medical knowledge graphs and drug discovery highlights the potential of Large Graph Models (LGMs) in understanding complex biomedical relationships. The study also emphasizes the transformative role of Vision-Language Models (VLMs) and 3D Large Models in medical image analysis, anatomical modeling, and prosthetic design. Despite the challenges, these technologies are setting new benchmarks in medical innovation, improving diagnostic accuracy, and paving the way for personalized healthcare solutions. This paper aims to provide a comprehensive overview of the current state and future directions of large models in medicine, underscoring their significance in advancing global health.', 'abstract_zh': '本文探讨了大型模型在医疗领域的进展与应用，特别关注医疗大型模型（MedLMs）。这些模型包括大型语言模型（LLMs）、视觉模型、3D大型模型和多模态模型，正在通过增强疾病预测、诊断辅助、个性化治疗规划和药物发现等方面推动医疗领域的变革。医疗知识图谱和药物发现中图神经网络的应用展示了大型图模型（LGMs）在理解复杂生物医学关系方面的潜力。研究还强调了视觉语言模型（VLMs）和3D大型模型在医学图像分析、解剖建模和假体设计中的变革性作用。尽管存在挑战，这些技术正在为医疗创新设定新的基准，提高诊断准确性，并为个性化医疗解决方案铺平道路。本文旨在提供大型模型在医疗领域当前状态和未来方向的全面概述，强调其在全球健康领域的重要性。', 'title_zh': '大型模型在医学中的应用'}
{'arxiv_id': 'arXiv:2502.17109', 'title': 'Strength Estimation and Human-Like Strength Adjustment in Games', 'authors': 'Chun Jung Chen, Chung-Chin Shih, Ti-Rong Wu', 'link': 'https://arxiv.org/abs/2502.17109', 'abstract': 'Strength estimation and adjustment are crucial in designing human-AI interactions, particularly in games where AI surpasses human players. This paper introduces a novel strength system, including a strength estimator (SE) and an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts strengths from games and offers different playing strengths with human styles. The strength estimator calculates strength scores and predicts ranks from games without direct human interaction. SE-MCTS utilizes the strength scores in a Monte Carlo tree search to adjust playing strength and style. We first conduct experiments in Go, a challenging board game with a wide range of ranks. Our strength estimator significantly achieves over 80% accuracy in predicting ranks by observing 15 games only, whereas the previous method reached 49% accuracy for 100 games. For strength adjustment, SE-MCTS successfully adjusts to designated ranks while achieving a 51.33% accuracy in aligning to human actions, outperforming a previous state-of-the-art, with only 42.56% accuracy. To demonstrate the generality of our strength system, we further apply SE and SE-MCTS to chess and obtain consistent results. These results show a promising approach to strength estimation and adjustment, enhancing human-AI interactions in games. Our code is available at this https URL.', 'abstract_zh': '人工智能力量估计与调整对于设计人机交互至关重要，特别是在游戏中，人工智能超越人类玩家时更为重要。本文介绍了一种新颖的力量估计系统，包括力量估计器（SE）和基于SE的蒙特卡洛树搜索（SE-MCTS），该系统通过游戏预测力量并提供具有人类风格的不同力量等级。力量估计器在没有直接人类交互的情况下计算力量分数并预测排名。SE-MCTS利用这些力量分数进行蒙特卡洛树搜索，以调整力量等级和风格。我们首先在围棋中进行了实验，这是一种具有广泛排名范围的具有挑战性的棋盘游戏。我们的力量估计器仅通过观察15盘游戏即可显著实现超过80%的排名预测准确率，而先前的方法在100盘游戏中仅达49%的准确率。在力量调整方面，SE-MCTS成功调整到指定的排名，并实现了51.33%的人类动作对齐准确率，优于之前最先进的方法，后者仅达42.56%的准确率。为了展示我们力量系统的一般性，我们将SE和SE-MCTS进一步应用于国际象棋，并获得了相似的结果。这些结果表明了一种有前途的力量估计与调整方法，可增强游戏中的用户体验。我们的代码可在此网址获取：this https URL。', 'title_zh': '游戏中的力量估算与人类般的力量调整'}
{'arxiv_id': 'arXiv:2502.17049', 'title': 'TabulaTime: A Novel Multimodal Deep Learning Framework for Advancing Acute Coronary Syndrome Prediction through Environmental and Clinical Data Integration', 'authors': 'Xin Zhang, Liangxiu Han, Stephen White, Saad Hassan, Philip A Kalra, James Ritchie, Carl Diver, Jennie Shorley', 'link': 'https://arxiv.org/abs/2502.17049', 'abstract': 'Acute Coronary Syndromes (ACS), including ST-segment elevation myocardial infarctions (STEMI) and non-ST-segment elevation myocardial infarctions (NSTEMI), remain a leading cause of mortality worldwide. Traditional cardiovascular risk scores rely primarily on clinical data, often overlooking environmental influences like air pollution that significantly impact heart health. Moreover, integrating complex time-series environmental data with clinical records is challenging.\nWe introduce TabulaTime, a multimodal deep learning framework that enhances ACS risk prediction by combining clinical risk factors with air pollution data. TabulaTime features three key innovations: First, it integrates time-series air pollution data with clinical tabular data to improve prediction accuracy. Second, its PatchRWKV module automatically extracts complex temporal patterns, overcoming limitations of traditional feature engineering while maintaining linear computational complexity. Third, attention mechanisms enhance interpretability by revealing interactions between clinical and environmental factors.\nExperimental results show that TabulaTime improves prediction accuracy by over 20% compared to conventional models such as CatBoost, Random Forest, and LightGBM, with air pollution data alone contributing over a 10% improvement. Feature importance analysis identifies critical predictors including previous angina, systolic blood pressure, PM10, and NO2. Overall, TabulaTime bridges clinical and environmental insights, supporting personalized prevention strategies and informing public health policies to mitigate ACS risk.', 'abstract_zh': '急性冠状综合征（ACS），包括ST段抬高型心肌梗死（STEMI）和非ST段抬高型心肌梗死（NSTEMI），仍然是全球主要的致死原因之一。传统的心血管风险评分主要依赖临床数据，往往忽视了如空气污染等环境因素对心脏健康的显著影响。此外，将复杂的时序环境数据与临床记录整合是一个挑战。\n我们介绍了TabulaTime，这是一种多模态深度学习框架，通过结合临床风险因素和空气污染数据来增强ACS风险预测。TabulaTime具有三个关键创新点：首先，它将时序空气污染数据与临床表格式数据相结合，以提高预测准确性。其次，其PatchRWKV模块自动提取复杂的时序模式，克服了传统特征工程的局限性，并保持了线性计算复杂度。第三，注意力机制增强了可解释性，揭示了临床和环境因素之间的互动。\n实验结果表明，与传统的CatBoost、随机森林和LightGBM等模型相比，TabulaTime的预测准确性提高超过20%，仅空气污染数据就贡献了超过10%的提升。特征重要性分析识别出的关键预测因子包括既往心绞痛、收缩压、PM10和NO2。总体而言，TabulaTime结合了临床和环境洞察，支持个性化的预防策略，并为制定降低ACS风险的公共卫生政策提供信息。', 'title_zh': 'TabulaTime：一种通过环境数据和临床数据整合以推进急性冠状综合征预测的新型多模态深度学习框架'}
{'arxiv_id': 'arXiv:2502.16848', 'title': 'PulseBat: A field-accessible dataset for second-life battery diagnostics from realistic histories using multidimensional rapid pulse test', 'authors': 'Shengyu Tao, Guangyuan Ma, Huixiong Yang, Minyan Lu, Guodan Wei, Guangmin Zhou, Xuan Zhang', 'link': 'https://arxiv.org/abs/2502.16848', 'abstract': 'As electric vehicles (EVs) approach the end of their operational life, their batteries retain significant economic value and present promising opportunities for second-life use and material recycling. This is particularly compelling for Global South and other underdeveloped regions, where reliable energy storage is vital to addressing critical challenges posed by weak and even nonexistent power grid and energy infrastructures. However, despite this potential, widespread adoption has been hindered by critical uncertainties surrounding the technical performance, safety, and recertification of second-life batteries. In cases where they have been redeployed, mismatches between estimated and actual performance often render batteries technically unsuitable or hazardous, turning them into liabilities for communities they were intended to benefit. This considerable misalignment exacerbates energy access disparities and undermines the broader vision of energy justice, highlighting an urgent need for robust and scalable solutions to unlock the potential. In the PulseBat Dataset, the authors tested 464 retired lithium-ion batteries, covering 3 cathode material types, 6 historical usages, 3 physical formats, and 6 capacity designs. The pulse test experiments were performed repeatedly for each second-life battery with 10 pulse width, 10 pulse magnitude, multiple state-of-charge, and state-of-health conditions, e.g., from 0.37 to 1.03. The PulseBat Dataset recorded these test conditions and the voltage response as well as the temperature signals that were subject to the injected pulse current, which could be used as a valuable data resource for critical diagnostics tasks such as state-of-charge estimation, state-of-health estimation, cathode material type identification, open-circuit voltage reconstruction, thermal management, and beyond.', 'abstract_zh': '电动汽车电池寿命结束后的二次利用和材料回收机会及其在Global South及其他欠发达地区的经济价值和安全挑战——以PulseBat数据集为例', 'title_zh': 'PulseBat：来自现实历史的多维快速脉冲测试的二次电池现场可访问诊断数据集'}
{'arxiv_id': 'arXiv:2502.16713', 'title': 'Understanding the Impact of Artificial Intelligence in Academic Writing: Metadata to the Rescue', 'authors': 'Javier Conde, Pedro Reviriego, Joaquín Salvachúa, Gonzalo Martínez, José Alberto Hernández, Fabrizio Lombardi', 'link': 'https://arxiv.org/abs/2502.16713', 'abstract': 'This column advocates for including artificial intelligence (AI)-specific metadata on those academic papers that are written with the help of AI in an attempt to analyze the use of such tools for disseminating research.', 'abstract_zh': '本专栏倡导在使用人工智能（AI）撰写的研究论文中包含专门的元数据，以便分析此类工具在传播研究中的使用情况。', 'title_zh': '理解人工智能在学术写作中的影响：元数据来帮忙'}
{'arxiv_id': 'arXiv:2502.16666', 'title': 'SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance', 'authors': 'Kunal Singh, Ankan Biswas, Sayandeep Bhowmick, Pradeep Moturi, Siva Kishore Gollapalli', 'link': 'https://arxiv.org/abs/2502.16666', 'abstract': "We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. At each step/turn, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to solve it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC's greedy decoding against self-consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.", 'abstract_zh': 'Step-by-Step Coding (SBSC): 一种多轮数学推理框架，使大规模语言模型能够生成解决奥林匹克级别数学问题的程序序列', 'title_zh': 'SBSC: 分步骤编码以提高数学奥林匹克竞赛表现'}
{'arxiv_id': 'arXiv:2502.16608', 'title': 'Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control', 'authors': 'Yuli Zhang, Shangbo Wang, Dongyao Jia, Pengfei Fan, Ruiyuan Jiang, Hankang Gu, Andy H.F. Chow', 'link': 'https://arxiv.org/abs/2502.16608', 'abstract': 'Reinforcement learning (RL) emerges as a promising data-driven approach for adaptive traffic signal control (ATSC) in complex urban traffic networks, with deep neural networks substantially augmenting its learning capabilities. However, centralized RL becomes impractical for ATSC involving multiple agents due to the exceedingly high dimensionality of the joint action space. Multi-agent RL (MARL) mitigates this scalability issue by decentralizing control to local RL agents. Nevertheless, this decentralized method introduces new challenges: the environment becomes partially observable from the perspective of each local agent due to constrained inter-agent communication. Both centralized RL and MARL exhibit distinct strengths and weaknesses, particularly under heavy intersectional traffic conditions. In this paper, we justify that MARL can achieve the optimal global Q-value by separating into multiple IRL (Independent Reinforcement Learning) processes when no spill-back congestion occurs (no agent dependency) among agents (intersections). In the presence of spill-back congestion (with agent dependency), the maximum global Q-value can be achieved by using centralized RL. Building upon the conclusions, we propose a novel Dynamic Parameter Update Strategy for Deep Q-Network (DQN-DPUS), which updates the weights and bias based on the dependency dynamics among agents, i.e. updating only the diagonal sub-matrices for the scenario without spill-back congestion. We validate the DQN-DPUS in a simple network with two intersections under varying traffic, and show that the proposed strategy can speed up the convergence rate without sacrificing optimal exploration. The results corroborate our theoretical findings, demonstrating the efficacy of DQN-DPUS in optimizing traffic signal control.', 'abstract_zh': '加强学习（RL）在复杂城市交通网络中适应性交通信号控制（ATSC）中的数据驱动方法展现出前景，深度神经网络大幅增强了其学习能力。然而，对于涉及多个代理的ATSC，集中式RL由于联合动作空间的极高维度而变得实用性较差。多代理RL（MARL）通过将控制 decentralize 给本地RL代理来缓解这一可扩展性问题。尽管如此，这种方法也引入了新的挑战：每个本地代理由于代理间通信受限而只能从局部视角观察环境。集中式RL和MARL在重叠交叉口交通条件下各自表现出不同的优势和劣势。在本文中，我们证明，在没有溢出拥堵（无代理依赖）的情况下，MARL可以通过分离成多个独立强化学习（IRL）过程来实现全局最优的Q值。在存在溢出拥堵（有代理依赖）的情况下，可通过使用集中式RL来实现全局最优的Q值。基于上述结论，我们提出了一种新的动态参数更新策略（DQN-DPUS），该策略根据代理间的依赖动态更新权重和偏置，即在无溢出拥堵的情况下仅更新对角子矩阵。我们在一个包含两个交叉口的简单网络中验证了DQN-DPUS，在不同交通条件下展示了该策略可以提高收敛速度且不牺牲最优探索。结果验证了我们的理论发现，证明了DQN-DPUS在优化交通信号控制方面的有效性。', 'title_zh': '多智能体强化学习在交通信号控制中的依赖动力学研究'}
{'arxiv_id': 'arXiv:2502.16573', 'title': 'LawPal : A Retrieval Augmented Generation Based System for Enhanced Legal Accessibility in India', 'authors': 'Dnyanesh Panchal, Aaryan Gole, Vaibhav Narute, Raunak Joshi', 'link': 'https://arxiv.org/abs/2502.16573', 'abstract': 'Access to legal knowledge in India is often hindered by a lack of awareness, misinformation and limited accessibility to judicial resources. Many individuals struggle to navigate complex legal frameworks, leading to the frequent misuse of laws and inadequate legal protection. To address these issues, we propose a Retrieval-Augmented Generation (RAG)-based legal chatbot powered by vectorstore oriented FAISS for efficient and accurate legal information retrieval. Unlike traditional chatbots, our model is trained using an extensive dataset comprising legal books, official documentation and the Indian Constitution, ensuring accurate responses to even the most complex or misleading legal queries. The chatbot leverages FAISS for rapid vector-based search, significantly improving retrieval speed and accuracy. It is also prompt-engineered to handle twisted or ambiguous legal questions, reducing the chances of incorrect interpretations. Apart from its core functionality of answering legal queries, the platform includes additional features such as real-time legal news updates, legal blogs, and access to law-related books, making it a comprehensive resource for users. By integrating advanced AI techniques with an optimized retrieval system, our chatbot aims to democratize legal knowledge, enhance legal literacy, and prevent the spread of misinformation. The study demonstrates that our approach effectively improves legal accessibility while maintaining high accuracy and efficiency, thereby contributing to a more informed and empowered society.', 'abstract_zh': '印度法律知识的获取往往受到缺乏意识、错误信息以及司法资源有限性的阻碍。许多个人难以导航复杂的法律框架，导致法律的误用和法律保护不足。为了解决这些问题，我们提议使用基于FAISS向量存储的检索增强生成（RAG）法律聊天机器人。与传统的聊天机器人不同，我们的模型是基于一个包含法律书籍、官方文件和印度宪法的庞大数据库进行训练的，确保对最复杂或误导性的法律查询也能提供准确的回答。聊天机器人利用FAISS进行快速向量搜索，显著提高检索速度和准确性。此外，该聊天机器人还经过提示工程设计，能够处理扭曲或模糊的法律问题，从而降低错误解释的可能性。除了核心功能——回答法律查询外，该平台还包括实时法律新闻更新、法律博客和法律相关书籍的访问等功能，使其成为用户全面的资源。通过将先进的AI技术与优化的检索系统结合，我们的聊天机器人旨在普及法律知识、提升法律素养，并防止错误信息的传播。研究表明，我们的方法在保持高准确性与效率的同时有效提高了法律的可获取性，从而有助于构建一个更加知情和自主的社会。', 'title_zh': 'LawPal：一种增强印度法律可访问性的检索增强生成系统'}
{'arxiv_id': 'arXiv:2502.16560', 'title': 'Analysis of Emotion in Rumour Threads on Social Media', 'authors': 'Rui Xing, Boyang Sun, Kun Zhang, Timothy Baldwin, Jey Han Lau', 'link': 'https://arxiv.org/abs/2502.16560', 'abstract': 'Rumours in online social media pose significant risks to modern society, motivating the need for better understanding of how they develop. We focus specifically on the interface between emotion and rumours in threaded discourses, building on the surprisingly sparse literature on the topic which has largely focused on emotions within the original rumour posts themselves, and largely overlooked the comparative differences between rumours and non-rumours. In this work, we provide a comprehensive analytical emotion framework, contrasting rumour and non-rumour cases using existing NLP datasets to further understand the emotion dynamics within rumours. Our framework reveals several findings: rumours exhibit more negative sentiment and emotions, including anger, fear and pessimism, while non-rumours evoke more positive emotions; emotions are contagious in online interactions, with rumours facilitate negative emotions and non-rumours foster positive emotions; and based on causal analysis, surprise acts as a bridge between rumours and other emotions, pessimism is driven by sadness and fear, optimism by joy and love.', 'abstract_zh': '在线社交媒体中的谣言对现代社会构成重大风险，推动了对其发展机制的更好理解的需求。我们特别关注情绪与谣言在主题讨论中的界面，延续了该领域令人惊讶地稀少的研究，这些研究主要集中在原始谣言帖子本身的情绪上，并且很大程度上忽视了谣言与非谣言之间的情绪差异。在本文中，我们提供了一个全面的情绪分析框架，通过现有的自然语言处理数据集对比分析谣言和非谣言案例，以进一步理解谣言中的情绪动态。我们的框架揭示了几个发现：谣言表现出更多负面情绪和情感，包括愤怒、恐惧和悲观；情绪在网络互动中具有传染性，谣言促进负面情绪，而非谣言促进积极情绪；基于因果分析，惊讶在谣言与其他情绪之间起到桥梁作用，悲观由悲伤和恐惧驱动，乐观由喜悦和爱驱动。', 'title_zh': '社交媒体上谣言线上的情绪分析'}
{'arxiv_id': 'arXiv:2502.16535', 'title': 'Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial Networks (GANs) in Addressing Data Imbalance', 'authors': 'Pankaj Yadav, Gulshan Sihag, Vivek Vijay', 'link': 'https://arxiv.org/abs/2502.16535', 'abstract': 'Machine learning algorithms are used in diverse domains, many of which face significant challenges due to data imbalance. Studies have explored various approaches to address the issue, like data preprocessing, cost-sensitive learning, and ensemble methods. Generative Adversarial Networks (GANs) showed immense potential as a data preprocessing technique that generates good quality synthetic data. This study employs a systematic mapping methodology to analyze 3041 papers on GAN-based sampling techniques for imbalanced data sourced from four digital libraries. A filtering process identified 100 key studies spanning domains such as healthcare, finance, and cybersecurity. Through comprehensive quantitative analysis, this research introduces three categorization mappings as application domains, GAN techniques, and GAN variants used to handle the imbalanced nature of the data. GAN-based over-sampling emerges as an effective preprocessing method. Advanced architectures and tailored frameworks helped GANs to improve further in the case of data imbalance. GAN variants like vanilla GAN, CTGAN, and CGAN show great adaptability in structured imbalanced data cases. Interest in GANs for imbalanced data has grown tremendously, touching a peak in recent years, with journals and conferences playing crucial roles in transmitting foundational theories and practical applications. While with these advances, none of the reviewed studies explicitly explore hybridized GAN frameworks with diffusion models or reinforcement learning techniques. This gap leads to a future research idea develop innovative approaches for effectively handling data imbalance.', 'abstract_zh': '基于生成对抗网络的不平衡数据采样技术综述：应用领域、GAN技术与变体分类', 'title_zh': '重新平衡天平：生成对抗网络（GANs）在解决数据不平衡问题中的系统映射研究'}
{'arxiv_id': 'arXiv:2502.16449', 'title': 'Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning', 'authors': 'Haoran Su', 'link': 'https://arxiv.org/abs/2502.16449', 'abstract': "Emergency Response Time (ERT) is crucial for urban safety, measuring cities' ability to handle medical, fire, and crime emergencies. In NYC, medical ERT increased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of delays due to Emergency Vehicle (EMV) travel times. Each minute's delay in stroke response costs 2 million brain cells, while cardiac arrest survival drops 7-10% per minute.\nThis dissertation advances EMV facilitation through three contributions. First, EMVLight, a decentralized multi-agent reinforcement learning framework, integrates EMV routing with traffic signal pre-emption. It achieved 42.6% faster EMV travel times and 23.5% improvement for other vehicles.\nSecond, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy Optimization for coordinated lane-clearing in mixed autonomous and human-driven traffic, reducing EMV travel times by 40%.\nThird, an equity study of NYC Emergency Medical Services revealed disparities across boroughs: Staten Island faces delays due to sparse signalized intersections, while Manhattan struggles with congestion. Solutions include optimized EMS stations and improved intersection designs.\nThese contributions enhance EMV mobility and emergency service equity, offering insights for policymakers and urban planners to develop safer, more efficient transportation systems.", 'abstract_zh': '应急响应时间(ERT)对于城市安全至关重要，衡量城市处理医疗、消防和犯罪紧急事件的能力。在纽约市，医疗ERT从2014年的7.89分钟增加到2024年的14.27分钟，增加了72%，其中一半的延误是由于紧急车辆(EV)的行驶时间。每一分钟的延误会损失200万个脑细胞，心脏病发作生存率每分钟下降7-10%。', 'title_zh': '使用多智能体深度强化学习在拥堵的城市区域促进急救车辆通行'}
{'arxiv_id': 'arXiv:2502.16376', 'title': 'Does Your AI Agent Get You? A Personalizable Framework for Approximating Human Models from Argumentation-based Dialogue Traces', 'authors': 'Yinxu Tang, Stylianos Loukas Vasileiou, William Yeoh', 'link': 'https://arxiv.org/abs/2502.16376', 'abstract': 'Explainable AI is increasingly employing argumentation methods to facilitate interactive explanations between AI agents and human users. While existing approaches typically rely on predetermined human user models, there remains a critical gap in dynamically learning and updating these models during interactions. In this paper, we present a framework that enables AI agents to adapt their understanding of human users through argumentation-based dialogues. Our approach, called Persona, draws on prospect theory and integrates a probability weighting function with a Bayesian belief update mechanism that refines a probability distribution over possible human models based on exchanged arguments. Through empirical evaluations with human users in an applied argumentation setting, we demonstrate that Persona effectively captures evolving human beliefs, facilitates personalized interactions, and outperforms state-of-the-art methods.', 'abstract_zh': '可解释AI正越来越多地采用论辩方法以促进AI代理与人类用户之间的互动解释。尽管现有方法通常依赖于预设的人类用户模型，但在交互过程中动态学习和更新这些模型仍存在关键缺口。本文提出了一种框架，使AI代理能够通过论辩式对话来适应其对人类用户的理解。我们的方法名为Persona，它借鉴了前景理论，并结合了概率权重函数与贝叶斯信念更新机制，根据交换的论点来细化对潜在人类模型的概率分布。通过在实际论辩场景中的人类用户实证评估，我们展示了Persona能够有效捕捉人类信念的变化，促进个性化交互，并优于现有方法。', 'title_zh': '你的AI代理了解你吗？一种基于论证对话轨迹的人类模型可个性化解析框架'}
{'arxiv_id': 'arXiv:2502.16320', 'title': 'Direct Alignment with Heterogeneous Preferences', 'authors': 'Ali Shirali, Arash Nasr-Esfahany, Abdullah Alomar, Parsa Mirtaheri, Rediet Abebe, Ariel Procaccia', 'link': 'https://arxiv.org/abs/2502.16320', 'abstract': 'Alignment with human preferences is commonly framed using a universal reward function, even though human preferences are inherently heterogeneous. We formalize this heterogeneity by introducing user types and examine the limits of the homogeneity assumption. We show that aligning to heterogeneous preferences with a single policy is best achieved using the average reward across user types. However, this requires additional information about annotators. We examine improvements under different information settings, focusing on direct alignment methods. We find that minimal information can yield first-order improvements, while full feedback from each user type leads to consistent learning of the optimal policy. Surprisingly, however, no sample-efficient consistent direct loss exists in this latter setting. These results reveal a fundamental tension between consistency and sample efficiency in direct policy alignment.', 'abstract_zh': '异构偏好下的对齐：从统一奖励函数到用户类型平均奖励的探索', 'title_zh': '直接对齐异质偏好'}
{'arxiv_id': 'arXiv:2502.16203', 'title': 'Machine Learning Framework for Early Power, Performance, and Area Estimation of RTL', 'authors': 'Anindita Chattopadhyay, Vijay Kumar Sutrakar', 'link': 'https://arxiv.org/abs/2502.16203', 'abstract': 'A critical stage in the evolving landscape of VLSI design is the design phase that is transformed into register-transfer level (RTL), which specifies system functionality through hardware description languages like Verilog. Generally, evaluating the quality of an RTL design demands full synthesis via electronic design automation (EDA) tool is time-consuming process that is not well-suited to rapid design iteration and optimization. Although recent breakthroughs in machine Learning (ML) have brought early prediction models, these methods usually do not provide robust and generalizable solutions with respect to a wide range of RTL designs. This paper proposes a pre-synthesis framework that makes early estimation of power, performance and area (PPA) metrics directly from the hardware description language (HDL) code making direct use of library files instead of toggle files. The proposed framework introduces a bit-level representation referred to as the simple operator graph (SOG), which uses single-bit operators to generate a generalized and flexible structure that closely mirrors the characteristics of post synthesis design. The proposed model bridges the RTL and post-synthesis design, which will help in precisely predicting key metrics. The proposed tree-based ML framework shows superior predictive performance PPA estimation. Validation is carried out on 147 distinct RTL designs. The proposed model with 147 different designs shows accuracy of 98%, 98%, and 90% for WNS, TNS and power, respectively, indicates significant accuracy improvements relative to state-of-the-art methods.', 'abstract_zh': '一种从硬件描述语言代码预估VLSI设计的功耗、性能和面积的机器学习框架', 'title_zh': '基于RTL的早期功耗、性能和面积估算机器学习框架'}
{'arxiv_id': 'arXiv:2502.16111', 'title': 'PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving', 'authors': 'Mihir Parmar, Xin Liu, Palash Goyal, Yanfei Chen, Long Le, Swaroop Mishra, Hossein Mobahi, Jindong Gu, Zifeng Wang, Hootan Nakhost, Chitta Baral, Chen-Yu Lee, Tomas Pfister, Hamid Palangi', 'link': 'https://arxiv.org/abs/2502.16111', 'abstract': 'Recent agent frameworks and inference-time algorithms often struggle with complex planning problems due to limitations in verifying generated plans or reasoning and varying complexity of instances within a single task. Many existing methods for these tasks either perform task-level verification without considering constraints or apply inference-time algorithms without adapting to instance-level complexity. To address these limitations, we propose PlanGEN, a model-agnostic and easily scalable agent framework with three key components: constraint, verification, and selection agents. Specifically, our approach proposes constraint-guided iterative verification to enhance performance of inference-time algorithms--Best of N, Tree-of-Thought, and REBASE. In PlanGEN framework, the selection agent optimizes algorithm choice based on instance complexity, ensuring better adaptability to complex planning problems. Experimental results demonstrate significant improvements over the strongest baseline across multiple benchmarks, achieving state-of-the-art results on NATURAL PLAN ($\\sim$8%$\\uparrow$), OlympiadBench ($\\sim$4%$\\uparrow$), DocFinQA ($\\sim$7%$\\uparrow$), and GPQA ($\\sim$1%$\\uparrow$). Our key finding highlights that constraint-guided iterative verification improves inference-time algorithms, and adaptive selection further boosts performance on complex planning and reasoning problems.', 'abstract_zh': 'Recent Agent Frameworks and Inference-Time Algorithms Often Struggle with Complex Planning Problems Due to Limitations in Verifying Generated Plans or Reasoning and Varying Complexity of Instances within a Single Task: PlanGEN, a Model-Agnostic and Scalable Agent Framework with Constraint, Verification, and Selection Agents', 'title_zh': 'PlanGEN: 一种用于复杂问题解决的规划与推理轨迹生成的多agent框架'}
{'arxiv_id': 'arXiv:2502.15987', 'title': 'Forecasting Open-Weight AI Model Growth on Hugging Face', 'authors': 'Kushal Raj Bhandari, Pin-Yu Chen, Jianxi Gao', 'link': 'https://arxiv.org/abs/2502.15987', 'abstract': "As the open-weight AI landscape continues to proliferate-with model development, significant investment, and user interest-it becomes increasingly important to predict which models will ultimately drive innovation and shape AI ecosystems. Building on parallels with citation dynamics in scientific literature, we propose a framework to quantify how an open-weight model's influence evolves. Specifically, we adapt the model introduced by Wang et al. for scientific citations, using three key parameters-immediacy, longevity, and relative fitness-to track the cumulative number of fine-tuned models of an open-weight model. Our findings reveal that this citation-style approach can effectively capture the diverse trajectories of open-weight model adoption, with most models fitting well and outliers indicating unique patterns or abrupt jumps in usage.", 'abstract_zh': '随着开放权重AIlandscape的不断扩张——模型开发、重大投资及用户兴趣日益增加——预测哪些模型将最终推动创新并塑造AI生态系统变得越来越重要。借鉴科学文献引用动力学的相似性，我们提出了一种框架来量化开放权重模型影响的演变。具体来说，我们借鉴了Wang等人提出的科学引用模型，使用即时性、持久性和相对适应性三个关键参数，跟踪开放权重模型的累计微调模型数量。我们的研究发现，这种引用式方法可以有效地捕捉开放权重模型采用的多样化轨迹，大多数模型配合较好，异常值则表明独特的模式或使用量的突然跃升。', 'title_zh': '预测Hugging Face上开源权重AI模型的增长'}
{'arxiv_id': 'arXiv:2502.15959', 'title': 'A Knowledge Distillation-Based Approach to Enhance Transparency of Classifier Models', 'authors': 'Yuchen Jiang, Xinyuan Zhao, Yihang Wu, Ahmad Chaddad', 'link': 'https://arxiv.org/abs/2502.15959', 'abstract': "With the rapid development of artificial intelligence (AI), especially in the medical field, the need for its explainability has grown. In medical image analysis, a high degree of transparency and model interpretability can help clinicians better understand and trust the decision-making process of AI models. In this study, we propose a Knowledge Distillation (KD)-based approach that aims to enhance the transparency of the AI model in medical image analysis. The initial step is to use traditional CNN to obtain a teacher model and then use KD to simplify the CNN architecture, retain most of the features of the data set, and reduce the number of network layers. It also uses the feature map of the student model to perform hierarchical analysis to identify key features and decision-making processes. This leads to intuitive visual explanations. We selected three public medical data sets (brain tumor, eye disease, and Alzheimer's disease) to test our method. It shows that even when the number of layers is reduced, our model provides a remarkable result in the test set and reduces the time required for the interpretability analysis.", 'abstract_zh': '基于知识蒸馏的医疗图像分析模型透明度增强方法', 'title_zh': '基于知识蒸馏的方法以增强分类模型的透明度'}
{'arxiv_id': 'arXiv:2502.15953', 'title': 'Multi-Objective Optimization of Water Resource Allocation for Groundwater Recharge and Surface Runoff Management in Watershed Systems', 'authors': 'Abbas Sharifi, Hajar Kazemi Naeini, Mohsen Ahmadi, Saeed Asadi, Abbas Varmaghani', 'link': 'https://arxiv.org/abs/2502.15953', 'abstract': "Land degradation and air pollution are primarily caused by the salinization of soil and desertification that occurs from the drying of salinity lakes and the release of dust into the atmosphere because of their dried bottom. The complete drying up of a lake has caused a community environmental catastrophe. In this study, we presented an optimization problem to determine the total surface runoff to maintain the level of salinity lake (Urmia Lake). The proposed process has two key stages: identifying the influential factors in determining the lake water level using sensitivity analysis approaches based upon historical data and optimizing the effective variable to stabilize the lake water level under changing design variables. Based upon the Sobol'-Jansen and Morris techniques, the groundwater level and total surface runoff flow are highly effective with nonlinear and interacting impacts of the lake water level. As a result of the sensitivity analysis, we found that it may be possible to effectively manage lake levels by adjusting total surface runoff. We used genetic algorithms, non-linear optimization, and pattern search techniques to solve the optimization problem. Furthermore, the lake level constraint is established based on a pattern as a constant number every month. In order to maintain a consistent pattern of lake levels, it is necessary to increase surface runoff by approximately 8.7 times during filling season. It is necessary to increase this quantity by 33.5 times during the draining season. In the future, the results may serve as a guide for the rehabilitation of the lake.", 'abstract_zh': "土壤盐碱化和沙漠化导致的土地退化和空气污染主要是由于盐湖干涸导致盐分释放以及底土干燥后尘土入大气。湖泊完全干涸已导致社区环境灾难。本研究提出了一个优化问题，旨在确定维持盐湖（乌尔米耶湖）水位的总地表径流量。所提出的过程包括两个关键阶段：利用基于历史数据的敏感性分析方法识别确定湖泊水位的关键因素，以及在设计变量变化下优化有效变量以稳定湖泊水位。根据Sobol'-Jansen和Morris技术，地下水位和总地表径流量对湖泊水位具有高度非线性和交互影响。通过敏感性分析，我们发现可以通过调整总地表径流有效管理湖泊水位。我们使用了遗传算法、非线性优化和模式搜索技术来求解优化问题。此外，建立了基于模式的湖泊水位约束，将其设定为每月一个常数值。为了维持一致的湖泊水位模式，在充水季节需要将地表径流增加约8.7倍，在排水季节需要增加约33.5倍。未来，这些结果可能为湖泊的恢复提供指导。", 'title_zh': '流域系统中地下水补给与地表径流管理的多目标水资源优化配置'}
{'arxiv_id': 'arXiv:2502.15873', 'title': 'Practical Principles for AI Cost and Compute Accounting', 'authors': 'Stephen Casper, Luke Bailey, Tim Schreier', 'link': 'https://arxiv.org/abs/2502.15873', 'abstract': 'Policymakers are increasingly using development cost and compute as proxies for AI model capabilities and risks. Recent laws have introduced regulatory requirements that are contingent on specific thresholds. However, technical ambiguities in how to perform this accounting could create loopholes that undermine regulatory effectiveness. This paper proposes seven principles for designing practical AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.', 'abstract_zh': '政策制定者 increasingly 使用开发成本和计算资源作为评估AI模型能力和风险的代理指标。最近的法规引入了基于特定阈值的监管要求。然而，如何进行这种核算的技术模糊性可能会创造漏洞，从而削弱监管有效性。本文提出了七项原则，用于设计实用的AI成本和计算资源核算标准，以（1）减少战略 gaming 的机会，（2）不抵消负责任的风险缓解措施的激励，以及（3）在不同公司和司法管辖区实现一致实施。', 'title_zh': '实用的AI成本和计算核算原则'}
{'arxiv_id': 'arXiv:2502.15838', 'title': 'A novel approach to the relationships between data features -- based on comprehensive examination of mathematical, technological, and causal methodology', 'authors': 'JaeHong Kim', 'link': 'https://arxiv.org/abs/2502.15838', 'abstract': 'The expansion of artificial intelligence (AI) has raised concerns about transparency, accountability, and interpretability, with counterfactual reasoning emerging as a key approach to addressing these issues. However, current mathematical, technological, and causal methodologies rely on externalization techniques that normalize feature relationships within a single coordinate space, often distorting intrinsic interactions. This study proposes the Convergent Fusion Paradigm (CFP) theory, a framework integrating mathematical, technological, and causal perspectives to provide a more precise and comprehensive analysis of feature relationships. CFP theory introduces Hilbert space and backward causation to reinterpret the feature relationships as emergent structures, offering a potential solution to the common cause problem -- a fundamental challenge in causal modeling. From a mathematical -- technical perspective, it utilizes a Riemannian manifold-based framework, thereby improving the structural representation of high- and low-dimensional data interactions. From a causal inference perspective, CFP theory adopts abduction as a methodological foundation, employing Hilbert space for a dynamic causal reasoning approach, where causal relationships are inferred abductively, and feature relationships evolve as emergent properties. Ultimately, CFP theory introduces a novel AI modeling methodology that integrates Hilbert space, backward causation, and Riemannian geometry, strengthening AI governance and transparency in counterfactual reasoning.', 'abstract_zh': '人工智能（AI）的扩展引发了关于透明度、问责制和可解释性的关注，反事实推理已成为解决这些问题的关键方法。然而，当前的数学、技术和因果方法依赖于外部化技术，这些技术在单一坐标空间内正则化特征关系，往往扭曲了内在互动。本文提出了一致融合范式（CFP）理论，这是一种结合数学、技术和因果视角的框架，旨在提供特征关系的更精确和全面分析。CFP理论引入希尔伯特空间和反向因果关系，重新解释特征关系作为涌现结构，为共同原因问题提供潜在解决方案——因果建模中的基本挑战。从数学—技术视角，它利用基于黎曼流形的框架，从而改进高维和低维数据互动的结构性表示。从因果推理视角，CFP理论采用 abduction 作为方法论基础，利用希尔伯特空间进行动态因果推理，其中因果关系通过 abduction 推断，特征关系作为涌现属性演化。最终，CFP理论引入了一种新颖的AI建模方法，该方法整合了希尔伯特空间、反向因果关系和黎曼几何，强化了反事实推理中的AI治理和透明度。', 'title_zh': '基于数学、技术和因果方法全面 examination 的数据特征关系新方法'}
{'arxiv_id': 'arXiv:2502.15710', 'title': 'The Process of Categorical Clipping at the Core of the Genesis of Concepts in Synthetic Neural Cognition', 'authors': 'Michael Pichat William Pogrund, Armanush Gasparian, Paloma Pichat, Samuel Demarchi, Michael Veillet-Guillem, Martin Corbet, Théo Dasilva', 'link': 'https://arxiv.org/abs/2502.15710', 'abstract': 'This article investigates, within the field of neuropsychology of artificial intelligence, the process of categorical segmentation performed by language models. This process involves, across different neural layers, the creation of new functional categorical dimensions to analyze the input textual data and perform the required tasks. Each neuron in a multilayer perceptron (MLP) network is associated with a specific category, generated by three factors carried by the neural aggregation function: categorical priming, categorical attention, and categorical phasing. At each new layer, these factors govern the formation of new categories derived from the categories of precursor neurons. Through a process of categorical clipping, these new categories are created by selectively extracting specific subdimensions from the preceding categories, constructing a distinction between a form and a categorical background. We explore several cognitive characteristics of this synthetic clipping in an exploratory manner: categorical reduction, categorical selectivity, separation of initial embedding dimensions, and segmentation of categorical zones.', 'abstract_zh': '本文在人工智能神经心理学领域探讨了语言模型进行类别分割的过程。这一过程涉及在不同的神经层中，通过神经聚合函数携带的三种因素——类别启动、类别注意力和类别相位，生成新的功能性类别维度以分析输入的文本数据并完成所需的任务。多层感知机（MLP）网络中的每个神经元都与特定类别相关联，这些类别由以下三种因素生成：类别启动、类别注意力和类别相位。在每一层中，这些因素支配着由前一层神经元类别衍生的新类别的形成。通过类别裁剪过程，这些新类别是通过从先前类别中选择性地提取特定子维度而创建的，从而构建起形态与类别背景之间的区分。本文以探索性的方式探讨了几种这种合成裁剪的认知特征：类别简化、类别选择性、初始嵌入维度的分离以及类别区域的分割。', 'title_zh': '范畴剪辑过程：合成神经认知概念生成的核心机制'}
{'arxiv_id': 'arXiv:2502.15689', 'title': 'Knowledge Graphs: The Future of Data Integration and Insightful Discovery', 'authors': 'Saher Mohamed, Kirollos Farah, Abdelrahman Lotfy, Kareem Rizk, Abdelrahman Saeed, Shahenda Mohamed, Ghada Khouriba, Tamer Arafa', 'link': 'https://arxiv.org/abs/2502.15689', 'abstract': 'Knowledge graphs are an efficient method for representing and connecting information across various concepts, useful in reasoning, question answering, and knowledge base completion tasks. They organize data by linking points, enabling researchers to combine diverse information sources into a single database. This interdisciplinary approach helps uncover new research questions and ideas. Knowledge graphs create a web of data points (nodes) and their connections (edges), which enhances navigation, comprehension, and utilization of data for multiple purposes. They capture complex relationships inherent in unstructured data sources, offering a semantic framework for diverse entities and their attributes. Strategies for developing knowledge graphs include using seed data, named entity recognition, and relationship extraction. These graphs enhance chatbot accuracy and include multimedia data for richer information. Creating high-quality knowledge graphs involves both automated methods and human oversight, essential for accurate and comprehensive data representation.', 'abstract_zh': '知识图谱是一种高效的方法，用于跨各种概念表示和连接信息，在推理、问答和知识库完成任务中非常有用。它们通过链接数据点来组织数据，使研究人员能够将多种信息来源整合到一个数据库中。这种跨学科的方法有助于发现新的研究问题和想法。知识图谱创建了一个数据点（节点）及其连接（边）的网络，这增强了数据的导航、理解和多用途利用。它们捕捉到了非结构化数据源中固有的复杂关系，提供了对各种实体及其属性的语义框架。开发知识图谱的策略包括使用种子数据、命名实体识别和关系抽取。这些图谱提高了聊天机器人的准确性，并包括多媒体数据以提供更丰富的信息。创建高质量的知识图谱既需要自动化方法也需要人工监督，这对于准确和全面的数据表示至关重要。', 'title_zh': '知识图谱：数据集成与洞察发现的未来'}
{'arxiv_id': 'arXiv:2502.17394', 'title': 'FIG: Forward-Inverse Generation for Low-Resource Domain-specific Event Detection', 'authors': 'Tanmay Parekh, Yuxuan Dong, Lucas Bandarkar, Artin Kim, I-Hung Hsu, Kai-Wei Chang, Nanyun Peng', 'link': 'https://arxiv.org/abs/2502.17394', 'abstract': "Event Detection (ED) is the task of identifying typed event mentions of interest from natural language text, which benefits domain-specific reasoning in biomedical, legal, and epidemiological domains. However, procuring supervised data for thousands of events for various domains is a laborious and expensive task. To this end, existing works have explored synthetic data generation via forward (generating labels for unlabeled sentences) and inverse (generating sentences from generated labels) generations. However, forward generation often produces noisy labels, while inverse generation struggles with domain drift and incomplete event annotations. To address these challenges, we introduce FIG, a hybrid approach that leverages inverse generation for high-quality data synthesis while anchoring it to domain-specific cues extracted via forward generation on unlabeled target data. FIG further enhances its synthetic data by adding missing annotations through forward generation-based refinement. Experimentation on three ED datasets from diverse domains reveals that FIG outperforms the best baseline achieving average gains of 3.3% F1 and 5.4% F1 in the zero-shot and few-shot settings respectively. Analyzing the generated trigger hit rate and human evaluation substantiates FIG's superior domain alignment and data quality compared to existing baselines.", 'abstract_zh': '事件检测（ED）的任务是从自然语言文本中识别感兴趣的类型化事件提及，这在生物医学、法律和流行病学等领域中有助于特定领域的推理。然而，为多个领域采集数千种事件的监督数据是一项耗时且昂贵的任务。为此，现有工作探索了通过正向生成（为未标记句子生成标签）和逆向生成（从生成的标签生成句子）来生成合成数据的方法。然而，正向生成通常会产生噪声标签，而逆向生成则难以应对领域漂移和不完整事件标注。为了解决这些挑战，我们提出了一种混合方法FIG，该方法利用逆向生成生成高质量的数据合成，同时通过正向生成提取的领域特定线索进行锚定。FIG进一步通过基于正向生成的精炼添加缺失的标注来增强其合成数据。在三个来自不同领域的事件检测数据集上的实验结果显示，FIG分别在零-shot和few-shot设置中优于最佳基线，分别获得平均3.3%和5.4%的F1分数提升。生成触发命中率分析和人工评估表明，FIG在领域对齐和数据质量方面优于现有基线。', 'title_zh': 'FIG：面向特定领域事件检测的前向-逆向生成方法'}
{'arxiv_id': 'arXiv:2502.17391', 'title': 'The Empirical Impact of Reducing Symmetries on the Performance of Deep Ensembles and MoE', 'authors': 'Andrei Chernov, Oleg Novitskij', 'link': 'https://arxiv.org/abs/2502.17391', 'abstract': 'Recent studies have shown that reducing symmetries in neural networks enhances linear mode connectivity between networks without requiring parameter space alignment, leading to improved performance in linearly interpolated neural networks. However, in practical applications, neural network interpolation is rarely used; instead, ensembles of networks are more common. In this paper, we empirically investigate the impact of reducing symmetries on the performance of deep ensembles and Mixture of Experts (MoE) across five datasets. Additionally, to explore deeper linear mode connectivity, we introduce the Mixture of Interpolated Experts (MoIE). Our results show that deep ensembles built on asymmetric neural networks achieve significantly better performance as ensemble size increases compared to their symmetric counterparts. In contrast, our experiments do not provide conclusive evidence on whether reducing symmetries affects both MoE and MoIE architectures.', 'abstract_zh': '近期研究表明，减少神经网络中的对称性可以增强网络间的线性模态连通性，从而提高线性插值神经网络的性能，而无需对参数空间进行对齐。然而，在实际应用中，神经网络插值很少被使用，取而代之的是使用网络集合。本文通过五个数据集 empirically 研究减少对称性对深集合和专家混合（MoE）性能的影响，并引入了插值专家混合（MoIE）以探索更深的线性模态连通性。结果表明，随着集合规模的增加，基于不对称神经网络的深集合的性能显著优于其对称对应物。相比之下，我们的实验并未提供足够的证据表明减少对称性是否会影响 MoE 和 MoIE 架构。', 'title_zh': '减少对称性对深度ensembles和MoE性能的影响实证研究'}
{'arxiv_id': 'arXiv:2502.17387', 'title': 'Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models', 'authors': 'Alon Albalak, Duy Phung, Nathan Lile, Rafael Rafailov, Kanishk Gandhi, Louis Castricato, Anikait Singh, Chase Blagden, Violet Xiang, Dakota Mahan, Nick Haber', 'link': 'https://arxiv.org/abs/2502.17387', 'abstract': 'Increasing interest in reasoning models has led math to become a prominent testing ground for algorithmic and methodological improvements. However, existing open math datasets either contain a small collection of high-quality, human-written problems or a large corpus of machine-generated problems of uncertain quality, forcing researchers to choose between quality and quantity. In this work, we present Big-Math, a dataset of over 250,000 high-quality math questions with verifiable answers, purposefully made for reinforcement learning (RL). To create Big-Math, we rigorously filter, clean, and curate openly available datasets, extracting questions that satisfy our three desiderata: (1) problems with uniquely verifiable solutions, (2) problems that are open-ended, (3) and problems with a closed-form solution. To ensure the quality of Big-Math, we manually verify each step in our filtering process. Based on the findings from our filtering process, we introduce 47,000 new questions with verified answers, Big-Math-Reformulated: closed-ended questions (i.e. multiple choice questions) that have been reformulated as open-ended questions through a systematic reformulation algorithm. Compared to the most commonly used existing open-source datasets for math reasoning, GSM8k and MATH, Big-Math is an order of magnitude larger, while our rigorous filtering ensures that we maintain the questions most suitable for RL. We also provide a rigorous analysis of the dataset, finding that Big-Math contains a high degree of diversity across problem domains, and incorporates a wide range of problem difficulties, enabling a wide range of downstream uses for models of varying capabilities and training requirements. By bridging the gap between data quality and quantity, Big-Math establish a robust foundation for advancing reasoning in LLMs.', 'abstract_zh': '大数学：一个包含超过250,000个高质量可验证答案数学问题的数据集，旨在强化学习（RL）', 'title_zh': 'Big-Math：大规模高质量数学数据集，用于语言模型的强化学习'}
{'arxiv_id': 'arXiv:2502.17380', 'title': 'Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation', 'authors': 'Qiuming Zhao, Guangzhi Sun, Chao Zhang, Mingxing Xu, Thomas Fang Zheng', 'link': 'https://arxiv.org/abs/2502.17380', 'abstract': 'Language diversity presents a significant challenge in speech-to-text (S2T) tasks, such as automatic speech recognition and translation. Traditional multi-task training approaches aim to address this by jointly optimizing multiple speech recognition and translation tasks across various languages. While models like Whisper, built on these strategies, demonstrate strong performance, they still face issues of high computational cost, language interference, suboptimal training configurations, and limited extensibility. To overcome these challenges, we introduce LoRS-Merging (low-rank and sparse model merging), a novel technique designed to efficiently integrate models trained on different languages or tasks while preserving performance and reducing computational overhead. LoRS-Merging combines low-rank and sparse pruning to retain essential structures while eliminating redundant parameters, mitigating language and task interference, and enhancing extensibility. Experimental results across a range of languages demonstrate that LoRS-Merging significantly outperforms conventional multi-lingual multi-task training baselines. Our findings suggest that model merging, particularly LoRS-Merging, is a scalable and effective complement to traditional multi-lingual training strategies for S2T applications.', 'abstract_zh': '语言多样性在语音识别到文本（S2T）任务中提出了重大挑战，包括自动语音识别和翻译。传统的多任务训练方法通过联合优化多种语言的语音识别和翻译任务来应对这一挑战。尽管像Whisper这样的模型基于这些策略表现出强大的性能，但仍面临高计算成本、语言干扰、训练配置不佳和扩展性受限等问题。为克服这些挑战，我们引入了LoRS-Merging（低秩和稀疏模型合并）这一新颖的技术，旨在高效地整合不同语言或任务训练的模型，同时保持性能并减少计算开销。LoRS-Merging结合了低秩和稀疏剪枝，以保留关键结构、消除冗余参数、降低语言和任务干扰，并增强扩展性。跨多种语言的实验结果表明，LoRS-Merging显著优于传统的多语种多任务训练基线。我们的研究發現表明，模型合并，尤其是LoRS-Merging，是传统多语种训练策略在S2T应用中的可扩展且有效的补充。', 'title_zh': '低秩和稀疏模型融合在多语言语音识别与翻译中的应用'}
{'arxiv_id': 'arXiv:2502.17358', 'title': 'DIS-CO: Discovering Copyrighted Content in VLMs Training Data', 'authors': 'André V. Duarte, Xuandong Zhao, Arlindo L. Oliveira, Lei Li', 'link': 'https://arxiv.org/abs/2502.17358', 'abstract': "How can we verify whether copyrighted content was used to train a large vision-language model (VLM) without direct access to its training data? Motivated by the hypothesis that a VLM is able to recognize images from its training corpus, we propose DIS-CO, a novel approach to infer the inclusion of copyrighted content during the model's development. By repeatedly querying a VLM with specific frames from targeted copyrighted material, DIS-CO extracts the content's identity through free-form text completions. To assess its effectiveness, we introduce MovieTection, a benchmark comprising 14,000 frames paired with detailed captions, drawn from films released both before and after a model's training cutoff. Our results show that DIS-CO significantly improves detection performance, nearly doubling the average AUC of the best prior method on models with logits available. Our findings also highlight a broader concern: all tested models appear to have been exposed to some extent to copyrighted content. Our code and data are available at this https URL", 'abstract_zh': '如何在无直接访问训练数据的情况下验证是否使用了受版权保护的内容训练大型视觉-语言模型（VLM）？受VLM能够识别其训练语料中的图像这一假设的启发，我们提出DIS-CO，这是一种新颖的方法，用于推断模型开发过程中是否包含了受版权保护的内容。通过反复使用目标受版权保护材料的具体帧对VLM进行查询，DIS-CO通过自由形式的文本补充提取内容的身份。为了评估其有效性，我们引入了包含14,000个帧并附有详细描述的MovieTection基准数据集，这些帧来自模型训练截止日期前后发行的电影。我们的结果显示，DIS-CO显著提高了检测性能，在具有可用logits的模型上几乎将最佳先前方法的平均AUC翻倍。我们的研究结果还突显了一个更广泛的担忧：所有测试的模型似乎在某种程度上都接触到了受版权保护的内容。我们的代码和数据可在以下链接获取。', 'title_zh': 'DIS-CO: 发现VLMs训练数据中的版权内容'}
{'arxiv_id': 'arXiv:2502.17349', 'title': 'HybridLinker: Topology-Guided Posterior Sampling for Enhanced Diversity and Validity in 3D Molecular Linker Generation', 'authors': 'Minyeong Hwang, Ziseok Lee, Gwangsoo Kim, Kyungsu Kim, Eunho Yang', 'link': 'https://arxiv.org/abs/2502.17349', 'abstract': 'Linker generation is critical in drug discovery applications such as lead optimization and PROTAC design, where molecular fragments are assembled into diverse drug candidates. Existing methods fall into PC-Free and PC-Aware categories based on their use of 3D point clouds (PC). PC-Free models prioritize diversity but suffer from lower validity due to overlooking PC constraints, while PC-Aware models ensure higher validity but restrict diversity by enforcing strict PC constraints. To overcome these trade-offs without additional training, we propose HybridLinker, a framework that enhances PC-Aware inference by providing diverse bonding topologies from a pretrained PC-Free model as guidance. At its core, we propose LinkerDPS, the first diffusion posterior sampling (DPS) method operating across PC-Free and PC-Aware spaces, bridging molecular topology with 3D point clouds via an energy-inspired function. By transferring the diverse sampling distribution of PC-Free models into the PC-Aware distribution, HybridLinker significantly and consistently surpasses baselines, improving both validity and diversity in foundational molecular design and applied property optimization tasks, establishing a new DPS framework in the molecular and graph domains beyond imaging.', 'abstract_zh': 'HybridLinker：一种融合PC-Free和PC-Aware框架的Linker生成方法', 'title_zh': 'HybridLinker: Topology-Guided 后验抽样以增强三维分子连结生成的多样性和有效性'}
{'arxiv_id': 'arXiv:2502.17213', 'title': 'Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics', 'authors': 'Jiahe Li, Xin Chen, Fanqi Shen, Junru Chen, Yuxin Liu, Daoze Zhang, Zhizhang Yuan, Fang Zhao, Meng Li, Yang Yang', 'link': 'https://arxiv.org/abs/2502.17213', 'abstract': 'Neurological disorders represent significant global health challenges, driving the advancement of brain signal analysis methods. Scalp electroencephalography (EEG) and intracranial electroencephalography (iEEG) are widely used to diagnose and monitor neurological conditions. However, dataset heterogeneity and task variations pose challenges in developing robust deep learning solutions. This review systematically examines recent advances in deep learning approaches for EEG/iEEG-based neurological diagnostics, focusing on applications across 7 neurological conditions using 46 datasets. We explore trends in data utilization, model design, and task-specific adaptations, highlighting the importance of pre-trained multi-task models for scalable, generalizable solutions. To advance research, we propose a standardized benchmark for evaluating models across diverse datasets to enhance reproducibility. This survey emphasizes how recent innovations can transform neurological diagnostics and enable the development of intelligent, adaptable healthcare solutions.', 'abstract_zh': '神经学障碍代表了重大的全球健康挑战，推动了脑电波信号分析方法的进步。头皮电生理图（EEG）和颅内电生理图（iEEG）广泛用于神经学状况的诊断和监测。然而，数据集异质性和任务变化对开发稳健的深度学习解决方案构成了挑战。本文系统回顾了基于EEG/iEEG的神经学诊断中深度学习方法的最新进展，重点关注在涉及7种神经学条件的46个数据集中的应用。我们探讨了数据利用趋势、模型设计以及任务特定适应性，并强调了为实现可扩展和通用的解决方案，预训练多任务模型的重要性。为了促进研究，我们提出了一种标准化基准，用于跨多样数据集评估模型以增强可重复性。本文强调近期创新如何变革神经学诊断，并助力开发智能和适应性强的医疗保健解决方案。', 'title_zh': '基于深度学习的电气脑信号分析：推进神经诊断技术'}
{'arxiv_id': 'arXiv:2502.17172', 'title': 'Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being', 'authors': 'Bin Yin, Chong-Yi Liu, Liya Fu, Jinkun Zhang', 'link': 'https://arxiv.org/abs/2502.17172', 'abstract': 'Affective computing has made significant strides in emotion recognition and generation, yet current approaches mainly focus on short-term pattern recognition and lack a comprehensive framework to guide affective agents toward long-term human well-being. To address this, we propose a teleology-driven affective computing framework that unifies major emotion theories (basic emotion, appraisal, and constructivist approaches) under the premise that affect is an adaptive, goal-directed process that facilitates survival and development. Our framework emphasizes aligning agent responses with both personal/individual and group/collective well-being over extended timescales. We advocate for creating a "dataverse" of personal affective events, capturing the interplay between beliefs, goals, actions, and outcomes through real-world experience sampling and immersive virtual reality. By leveraging causal modeling, this "dataverse" enables AI systems to infer individuals\' unique affective concerns and provide tailored interventions for sustained well-being. Additionally, we introduce a meta-reinforcement learning paradigm to train agents in simulated environments, allowing them to adapt to evolving affective concerns and balance hierarchical goals - from immediate emotional needs to long-term self-actualization. This framework shifts the focus from statistical correlations to causal reasoning, enhancing agents\' ability to predict and respond proactively to emotional challenges, and offers a foundation for developing personalized, ethically aligned affective systems that promote meaningful human-AI interactions and societal well-being.', 'abstract_zh': '情感计算在情绪识别和生成方面取得了显著进展，但当前方法主要集中在短期模式识别，缺乏一套全面的框架来指导情感代理向长期人类福祉发展。为解决这一问题，我们提出了一种以终极目标为导向的情感计算框架，将基本情绪、评估及建构主义方法等主要情绪理论统一起来，前提是情绪是一个适应性和目标导向的过程，有助于生存和发展。该框架强调将代理的反应与个人/个体和群体/集体的长期福祉保持一致。我们提倡创建一个“个人情感事件数据集”，通过现实生活体验抽样和沉浸式虚拟现实捕捉信念、目标、行为与结果之间的交互。借助因果建模，这一“数据集”使人工智能系统能够推断出个体独特的情感关注点，并提供量身定制的干预措施以促进持续的福祉。此外，我们引入了一种元强化学习范式，使代理能够在模拟环境中进行训练，从而适应不断变化的情感关注点并平衡从即时情绪需求到长期自我实现的多层次目标。该框架将重点从统计相关性转向因果推理，增强了代理预测和前瞻应对情绪挑战的能力，并为开发个性化、伦理对齐的情感系统提供了基础，这些系统旨在促进有意义的人机互动和整体福祉。', 'title_zh': '目标导向的情感计算：持续福祉的因果框架'}
{'arxiv_id': 'arXiv:2502.17130', 'title': 'Low-distortion and GPU-compatible Tree Embeddings in Hyperbolic Space', 'authors': 'Max van Spengler, Pascal Mettes', 'link': 'https://arxiv.org/abs/2502.17130', 'abstract': 'Embedding tree-like data, from hierarchies to ontologies and taxonomies, forms a well-studied problem for representing knowledge across many domains. Hyperbolic geometry provides a natural solution for embedding trees, with vastly superior performance over Euclidean embeddings. Recent literature has shown that hyperbolic tree embeddings can even be placed on top of neural networks for hierarchical knowledge integration in deep learning settings. For all applications, a faithful embedding of trees is needed, with combinatorial constructions emerging as the most effective direction. This paper identifies and solves two key limitations of existing works. First, the combinatorial construction hinges on finding highly separated points on a hypersphere, a notoriously difficult problem. Current approaches achieve poor separation, degrading the quality of the corresponding hyperbolic embedding. We propose highly separated Delaunay tree embeddings (HS-DTE), which integrates angular separation in a generalized formulation of Delaunay embeddings, leading to lower embedding distortion. Second, low-distortion requires additional precision. The current approach for increasing precision is to use multiple precision arithmetic, which renders the embeddings useless on GPUs in deep learning settings. We reformulate the combinatorial construction using floating point expansion arithmetic, leading to superior embedding quality while retaining utility on accelerated hardware.', 'abstract_zh': '从层次结构到本体和分类的树状数据嵌入：超球面上高度分离点的综合构建与超精密浮点扩展算术在保持高质量嵌入的同时提高硬件兼容性', 'title_zh': '低失真和GPU兼容的双曲空间树嵌入'}
{'arxiv_id': 'arXiv:2502.17121', 'title': 'Adversarial Training for Defense Against Label Poisoning Attacks', 'authors': 'Melis Ilayda Bal, Volkan Cevher, Michael Muehlebach', 'link': 'https://arxiv.org/abs/2502.17121', 'abstract': "As machine learning models grow in complexity and increasingly rely on publicly sourced data, such as the human-annotated labels used in training large language models, they become more vulnerable to label poisoning attacks. These attacks, in which adversaries subtly alter the labels within a training dataset, can severely degrade model performance, posing significant risks in critical applications. In this paper, we propose FLORAL, a novel adversarial training defense strategy based on support vector machines (SVMs) to counter these threats. Utilizing a bilevel optimization framework, we cast the training process as a non-zero-sum Stackelberg game between an attacker, who strategically poisons critical training labels, and the model, which seeks to recover from such attacks. Our approach accommodates various model architectures and employs a projected gradient descent algorithm with kernel SVMs for adversarial training. We provide a theoretical analysis of our algorithm's convergence properties and empirically evaluate FLORAL's effectiveness across diverse classification tasks. Compared to robust baselines and foundation models such as RoBERTa, FLORAL consistently achieves higher robust accuracy under increasing attacker budgets. These results underscore the potential of FLORAL to enhance the resilience of machine learning models against label poisoning threats, thereby ensuring robust classification in adversarial settings.", 'abstract_zh': '随着机器学习模型变得更加复杂并越来越多地依赖公开数据，如用于训练大规模语言模型的人标注标签，它们更容易受到标签投毒攻击的影响。这些攻击通过微妙地篡改训练数据集中的标签，可以严重损害模型性能，对关键应用构成重大风险。在本文中，我们提出了一种基于支持向量机（SVMs）的新型对抗训练防御策略FLORAL，以应对这些威胁。利用二层优化框架，我们将训练过程视为攻击者战略性地篡改关键训练标签与模型试图从此类攻击中恢复的非零和斯塔克尔贝格博弈。我们的方法适用于各种模型架构，并采用投影梯度下降算法结合核SVM进行对抗训练。我们提供了算法收敛性的理论分析，并在多种分类任务中 empirically 评估了 FLORAL 的有效性。与鲁棒基线模型（如 RoBERTa）相比，FLORAL 在不断增加的攻击预算下始终获得更高的鲁棒准确性。这些结果突显了 FLORAL 在增强机器学习模型对标签投毒威胁的抗性和确保对抗环境下的稳健分类方面的潜力。', 'title_zh': '对抗训练以防御标签投毒攻击'}
{'arxiv_id': 'arXiv:2502.17119', 'title': 'Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions', 'authors': 'Zhong Li, Qi Huang, Lincen Yang, Jiayang Shi, Zhao Yang, Niki van Stein, Thomas Bäck, Matthijs van Leeuwen', 'link': 'https://arxiv.org/abs/2502.17119', 'abstract': 'In recent years, generative models have achieved remarkable performance across diverse applications, including image generation, text synthesis, audio creation, video generation, and data augmentation. Diffusion models have emerged as superior alternatives to Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) by addressing their limitations, such as training instability, mode collapse, and poor representation of multimodal distributions. This success has spurred widespread research interest. In the domain of tabular data, diffusion models have begun to showcase similar advantages over GANs and VAEs, achieving significant performance breakthroughs and demonstrating their potential for addressing unique challenges in tabular data modeling. However, while domains like images and time series have numerous surveys summarizing advancements in diffusion models, there remains a notable gap in the literature for tabular data. Despite the increasing interest in diffusion models for tabular data, there has been little effort to systematically review and summarize these developments. This lack of a dedicated survey limits a clear understanding of the challenges, progress, and future directions in this critical area. This survey addresses this gap by providing a comprehensive review of diffusion models for tabular data. Covering works from June 2015, when diffusion models emerged, to December 2024, we analyze nearly all relevant studies, with updates maintained in a \\href{this https URL}{GitHub repository}. Assuming readers possess foundational knowledge of statistics and diffusion models, we employ mathematical formulations to deliver a rigorous and detailed review, aiming to promote developments in this emerging and exciting area.', 'abstract_zh': '近年来，生成模型在图像生成、文本合成、音频创建、视频生成和数据增强等多元应用中取得了显著性能。扩散模型因其在训练稳定性、模式崩溃和多模态分布表示等方面的改进，已成为生成对抗网络（GANs）和变分自编码器（VAEs）的优越替代方案，引起了广泛的研究兴趣。在表格数据领域，扩散模型也开始展示出类似的优势，取得了显著的性能突破，并展现出解决表格数据建模独特挑战的潜力。然而，在图像和时间序列等领域的文献综述已经相当丰富，但表格数据领域的相关文献却存在明显不足。尽管人们对表格数据中的扩散模型表现出越来越大的兴趣，但缺乏系统性的回顾和总结。这种缺乏专门综述的情况限制了对该领域挑战、进展和未来方向的清晰理解。本文综述填补了这一空白，提供了对表格数据领域扩散模型的全面回顾。我们从2015年6月扩散模型首次出现到2024年12月，分析了几乎所有相关研究，并在GitHub存储库中持续更新。假设读者具备统计学和扩散模型的基础知识，本文采用数学公式进行详细阐述，旨在促进这一新兴领域的发展。', 'title_zh': '表格数据的扩散模型：挑战、现有进展及未来方向'}
{'arxiv_id': 'arXiv:2502.17100', 'title': 'Generative Models in Decision Making: A Survey', 'authors': 'Yinchuan Li, Xinyu Shao, Jianping Zhang, Haozhi Wang, Leo Maxime Brunswic, Kaiwen Zhou, Jiqian Dong, Kaiyang Guo, Xiu Li, Zhitang Chen, Jun Wang, Jianye Hao', 'link': 'https://arxiv.org/abs/2502.17100', 'abstract': 'In recent years, the exceptional performance of generative models in generative tasks has sparked significant interest in their integration into decision-making processes. Due to their ability to handle complex data distributions and their strong model capacity, generative models can be effectively incorporated into decision-making systems by generating trajectories that guide agents toward high-reward state-action regions or intermediate sub-goals. This paper presents a comprehensive review of the application of generative models in decision-making tasks. We classify seven fundamental types of generative models: energy-based models, generative adversarial networks, variational autoencoders, normalizing flows, diffusion models, generative flow networks, and autoregressive models. Regarding their applications, we categorize their functions into three main roles: controllers, modelers and optimizers, and discuss how each role contributes to decision-making. Furthermore, we examine the deployment of these models across five critical real-world decision-making scenarios. Finally, we summarize the strengths and limitations of current approaches and propose three key directions for advancing next-generation generative directive models: high-performance algorithms, large-scale generalized decision-making models, and self-evolving and adaptive models.', 'abstract_zh': '近年来，生成模型在生成任务中卓越的表现引发了将其整合到决策过程中的显著兴趣。由于其处理复杂数据分布和强大模型能力的特点，生成模型可以通过生成引导智能体向高奖励状态动作区域或中间子目标进发的轨迹，有效融入决策系统中。本文对生成模型在决策任务中的应用进行了全面回顾。我们分类了七种基本类型的生成模型：能量模型、生成对抗网络、变分自编码器、规范化流、扩散模型、生成流网络和自回归模型。关于其应用，我们将它们的功能分为三大角色：控制器、建模者和优化器，并讨论每个角色如何助力决策。此外，我们考察了这些模型在五个关键现实世界决策场景中的部署情况。最后，我们总结了当前方法的优缺点，并提出了推进下一代生成导向模型的三个关键方向：高性能算法、大规模通用决策模型和自我进化和自适应模型。', 'title_zh': '生成模型在决策中的应用：一个综述'}
{'arxiv_id': 'arXiv:2502.17099', 'title': 'Improved Diffusion-based Generative Model with Better Adversarial Robustness', 'authors': 'Zekun Wang, Mingyang Yi, Shuchen Xue, Zhenguo Li, Ming Liu, Bing Qin, Zhi-Ming Ma', 'link': 'https://arxiv.org/abs/2502.17099', 'abstract': 'Diffusion Probabilistic Models (DPMs) have achieved significant success in generative tasks. However, their training and sampling processes suffer from the issue of distribution mismatch. During the denoising process, the input data distributions differ between the training and inference stages, potentially leading to inaccurate data generation. To obviate this, we analyze the training objective of DPMs and theoretically demonstrate that this mismatch can be alleviated through Distributionally Robust Optimization (DRO), which is equivalent to performing robustness-driven Adversarial Training (AT) on DPMs. Furthermore, for the recently proposed Consistency Model (CM), which distills the inference process of the DPM, we prove that its training objective also encounters the mismatch issue. Fortunately, this issue can be mitigated by AT as well. Based on these insights, we propose to conduct efficient AT on both DPM and CM. Finally, extensive empirical studies validate the effectiveness of AT in diffusion-based models. The code is available at this https URL.', 'abstract_zh': '扩散概率模型（DPMs）在生成任务中取得了显著成功，然而它们的训练和采样过程遭受分布不匹配的问题。在去噪过程中，训练阶段和推断阶段的输入数据分布存在差异，可能导致数据生成不准确。为解决这一问题，我们分析了DPMs的训练目标，并理论上证明可以通过分布鲁棒优化（DRO）来缓解这一不匹配问题，这等同于在DPMs上进行以鲁棒性为导向的对抗训练（AT）。此外，对于最近提出的一致性模型（CM），它通过DPM的推断过程进行精炼，我们证明其训练目标也遇到了分布不匹配的问题。幸运的是，这一问题同样可以通过AT来缓解。基于这些见解，我们提出对DPM和CM进行高效的AT。最后，广泛的实证研究验证了AT在基于扩散的模型中的有效性。代码可从此处访问。', 'title_zh': '基于扩散的生成模型的对抗鲁棒性改进'}
{'arxiv_id': 'arXiv:2502.17087', 'title': 'Conditional Diffusion-Flow models for generating 3D cosmic density fields: applications to f(R) cosmologies', 'authors': 'Julieth Katherine Riveros, Paola Saavedra, Hector J. Hortua, Jorge Enrique Garcia-Farieta, Ivan Olier', 'link': 'https://arxiv.org/abs/2502.17087', 'abstract': 'Next-generation galaxy surveys promise unprecedented precision in testing gravity at cosmological scales. However, realising this potential requires accurately modelling the non-linear cosmic web. We address this challenge by exploring conditional generative modelling to create 3D dark matter density fields via score-based (diffusion) and flow-based methods. Our results demonstrate the power of diffusion models to accurately reproduce the matter power spectra and bispectra, even for unseen configurations. They also offer a significant speed-up with slightly reduced accuracy, when flow-based reconstructing the probability distribution function, but they struggle with higher-order statistics. To improve conditional generation, we introduce a novel multi-output model to develop feature representations of the cosmological parameters. Our findings offer a powerful tool for exploring deviations from standard gravity, combining high precision with reduced computational cost, thus paving the way for more comprehensive and efficient cosmological analyses', 'abstract_zh': '下一代星系巡天有望在宇宙尺度上以空前的精度测试引力。然而，实现这一潜力需要准确 Modeling 非线性宇宙网。我们通过探索条件生成建模，利用分数基于（扩散）和流基于方法，创建三维暗 matter 密度场来应对这一挑战。我们的结果展示了分数模型准确再现物质功率谱和三谱的能力，即使对于未见配置也是如此。同时，当使用流基于方法重构概率分布函数时，它们提供了显著的速度提升，但精度略低，但在处理高阶统计时遇到困难。为改进条件生成，我们引入了一种新颖的多输出模型，以开发宇宙参数的功能表示。我们的发现提供了一种强大的工具，可以探索标准引力的偏差，结合高精度和较低的计算成本，从而为更全面和高效的宇宙学分析铺平道路。', 'title_zh': '条件扩散-流模型用于生成三维宇宙密度场：应用于$f(R)$宇宙学'}
{'arxiv_id': 'arXiv:2502.17081', 'title': 'Forgetting Any Data at Any Time: A Theoretically Certified Unlearning Framework for Vertical Federated Learning', 'authors': 'Linian Wang, Leye Wang', 'link': 'https://arxiv.org/abs/2502.17081', 'abstract': 'Privacy concerns in machine learning are heightened by regulations such as the GDPR, which enforces the "right to be forgotten" (RTBF), driving the emergence of machine unlearning as a critical research field. Vertical Federated Learning (VFL) enables collaborative model training by aggregating a sample\'s features across distributed parties while preserving data privacy at each source. This paradigm has seen widespread adoption in healthcare, finance, and other privacy-sensitive domains. However, existing VFL systems lack robust mechanisms to comply with RTBF requirements, as unlearning methodologies for VFL remain underexplored. In this work, we introduce the first VFL framework with theoretically guaranteed unlearning capabilities, enabling the removal of any data at any time. Unlike prior approaches -- which impose restrictive assumptions on model architectures or data types for removal -- our solution is model- and data-agnostic, offering universal compatibility. Moreover, our framework supports asynchronous unlearning, eliminating the need for all parties to be simultaneously online during the forgetting process. These advancements address critical gaps in current VFL systems, ensuring compliance with RTBF while maintaining operational this http URL make all our implementations publicly available at this https URL.', 'abstract_zh': 'GDPR等法规增强的机器学习中的隐私担忧推动了机器遗忘领域的新兴研究，而垂直联邦学习(VFL)通过在不泄露数据隐私的情况下聚合样本特征实现协作模型训练，在医疗、金融等领域得到广泛应用。然而，现有VFL系统缺乏符合“被遗忘权”(RTBF)要求的稳健机制，因为VFL的遗忘方法仍处于初始探索阶段。在本文中，我们介绍了首个具备理论保证的遗忘能力的VFL框架，支持任意时间任意数据的移除。我们的解决方案不受模型架构或数据类型的限制，具有通用兼容性。此外，我们的框架支持异步遗忘，避免了遗忘过程中所有参与方需同时在线的需求。这些进步填补了当前VFL系统的关键空白，确保合规的同时保持操作的便利性。我们的所有实现已公开发布，在此提供链接。', 'title_zh': '随时删除任意数据：一种理论上认证的垂直联邦学习忘却框架'}
{'arxiv_id': 'arXiv:2502.17055', 'title': 'Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam', 'authors': 'Tianjin Huang, Haotian Hu, Zhenyu Zhang, Gaojie Jin, Xiang Li, Li Shen, Tianlong Chen, Lu Liu, Qingsong Wen, Zhangyang Wang, Shiwei Liu', 'link': 'https://arxiv.org/abs/2502.17055', 'abstract': 'This paper comprehensively evaluates several recently proposed optimizers for 4-bit training, revealing that low-bit precision amplifies sensitivity to learning rates and often causes unstable gradient norms, leading to divergence at higher learning rates. Among these, SPAM, a recent optimizer featuring momentum reset and spike-aware gradient clipping, achieves the best performance across various bit levels, but struggles to stabilize gradient norms, requiring careful learning rate tuning. To address these limitations, we propose Stable-SPAM, which incorporates enhanced gradient normalization and clipping techniques. In particular, Stable-SPAM (1) adaptively updates the clipping threshold for spiked gradients by tracking their historical maxima; (2) normalizes the entire gradient matrix based on its historical $l_2$-norm statistics; and $(3)$ inherits momentum reset from SPAM to periodically reset the first and second moments of Adam, mitigating the accumulation of spiked gradients. Extensive experiments show that Stable-SPAM effectively stabilizes gradient norms in 4-bit LLM training, delivering superior performance compared to Adam and SPAM. Notably, our 4-bit LLaMA-1B model trained with Stable-SPAM outperforms the BF16 LLaMA-1B trained with Adam by up to $2$ perplexity. Furthermore, when both models are trained in 4-bit, Stable-SPAM achieves the same loss as Adam while requiring only about half the training steps. Code is available at this https URL.', 'abstract_zh': '这篇论文全面评估了几种最近提出的4比特训练优化器，揭示了低比特精度放大了学习率的敏感性，往往导致梯度范数不穩定，在高学习率时出现发散。其中，SPAM作为一种具备速度重置和尖峰感知梯度裁剪特性的优化器，在各种比特水平上表现出最佳性能，但梯度范数的稳定性能较差，需要仔细调整学习率。为解决这些局限性，我们提出了Stable-SPAM，它结合了增强的梯度规范化和裁剪技术。具体而言，Stable-SPAM：(1) 通过跟踪尖峰梯度的历史最大值自适应地更新裁剪阈值；(2) 根据其历史 $l_2$-范数统计规范化整个梯度矩阵；(3) 继承SPAM的速度重置特性，定期重置Adam的第一和第二矩，减轻尖峰梯度的累积。广泛实验表明，Stable-SPAM在4比特大语言模型训练中有效稳定了梯度范数，性能优于Adam和SPAM。值得注意的是，使用Stable-SPAM训练的4比特LLaMA-1B模型比使用Adam训练的BF16 LLaMA-1B模型在困惑度上最多降低2个单位。此外，当两个模型都在4比特下训练时，Stable-SPAM达到了与Adam相同的效果，但所需的训练步数仅为一半。代码可在以下链接获取。', 'title_zh': 'Stable-SPAM: 如何比16位Adam更为稳定地训练4位数据'}
{'arxiv_id': 'arXiv:2502.17022', 'title': 'Class-Dependent Perturbation Effects in Evaluating Time Series Attributions', 'authors': 'Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp', 'link': 'https://arxiv.org/abs/2502.17022', 'abstract': "As machine learning models become increasingly prevalent in time series applications, Explainable Artificial Intelligence (XAI) methods are essential for understanding their predictions. Within XAI, feature attribution methods aim to identify which input features contributed the most to a model's prediction, with their evaluation typically relying on perturbation-based metrics. Through empirical analysis across multiple datasets, model architectures, and perturbation strategies, we identify important class-dependent effects in these metrics: they show varying effectiveness across classes, achieving strong results for some while remaining less sensitive to others. In particular, we find that the most effective perturbation strategies often demonstrate the most pronounced class differences. Our analysis suggests that these effects arise from the learned biases of classifiers, indicating that perturbation-based evaluation may reflect specific model behaviors rather than intrinsic attribution quality. We propose an evaluation framework with a class-aware penalty term to help assess and account for these effects in evaluating feature attributions. Although our analysis focuses on time series classification, these class-dependent effects likely extend to other structured data domains where perturbation-based evaluation is common.", 'abstract_zh': '随着机器学习模型在时间序列应用中的日益普及，可解释人工智能（XAI）方法对于理解其预测结果变得至关重要。在XAI领域中，特征归因方法旨在识别哪些输入特征对模型预测贡献最大，其评估通常依赖于扰动基度量。通过对多个数据集、模型架构和扰动策略进行实证分析，我们发现这些度量中的重要类间效应：它们在不同类中表现出不同的有效性，对某些类效果显著，而对其他类则不够敏感。特别是，我们发现最有效的扰动策略往往表现出最明显的类间差异。我们的分析表明，这些效应源于分类器学习到的偏差，表明基于扰动的评估可能反映特定的模型行为而非内在的归因质量。我们提出了一种带有类感知惩罚项的评估框架，以帮助评估和考虑这些效应。尽管我们的分析集中在时间序列分类上，但这些类间效应很可能会扩展到其他常见的基于扰动评估的结构化数据领域。', 'title_zh': '类依存扰动效应在评估时间序列 Attribution 中的变化'}
{'arxiv_id': 'arXiv:2502.17020', 'title': 'Moving Past Single Metrics: Exploring Short-Text Clustering Across Multiple Resolutions', 'authors': 'Justin Miller, Tristram Alexander', 'link': 'https://arxiv.org/abs/2502.17020', 'abstract': "Cluster number is typically a parameter selected at the outset in clustering problems, and while impactful, the choice can often be difficult to justify. Inspired by bioinformatics, this study examines how the nature of clusters varies with cluster number, presenting a method for determining cluster robustness, and providing a systematic method for deciding on the cluster number. The study focuses specifically on short-text clustering, involving 30,000 political Twitter bios, where the sparse co-occurrence of words between texts makes finding meaningful clusters challenging. A metric of proportional stability is introduced to uncover the stability of specific clusters between cluster resolutions, and the results are visualised using Sankey diagrams to provide an interrogative tool for understanding the nature of the dataset. The visualisation provides an intuitive way to track cluster subdivision and reorganisation as cluster number increases, offering insights that static, single-resolution metrics cannot capture. The results show that instead of seeking a single 'optimal' solution, choosing a cluster number involves balancing informativeness and complexity.", 'abstract_zh': '基于生物信息学的聚类数量研究：探讨聚类性质随聚类数量变化的方法及其在短文本聚类中的应用', 'title_zh': '超越单一指标：探索短文本聚类在多种分辨率下的表现'}
{'arxiv_id': 'arXiv:2502.17019', 'title': 'Erwin: A Tree-based Hierarchical Transformer for Large-scale Physical Systems', 'authors': 'Maksim Zhdanov, Max Welling, Jan-Willem van de Meent', 'link': 'https://arxiv.org/abs/2502.17019', 'abstract': "Large-scale physical systems defined on irregular grids pose significant scalability challenges for deep learning methods, especially in the presence of long-range interactions and multi-scale coupling. Traditional approaches that compute all pairwise interactions, such as attention, become computationally prohibitive as they scale quadratically with the number of nodes. We present Erwin, a hierarchical transformer inspired by methods from computational many-body physics, which combines the efficiency of tree-based algorithms with the expressivity of attention mechanisms. Erwin employs ball tree partitioning to organize computation, which enables linear-time attention by processing nodes in parallel within local neighborhoods of fixed size. Through progressive coarsening and refinement of the ball tree structure, complemented by a novel cross-ball interaction mechanism, it captures both fine-grained local details and global features. We demonstrate Erwin's effectiveness across multiple domains, including cosmology, molecular dynamics, and particle fluid dynamics, where it consistently outperforms baseline methods both in accuracy and computational efficiency.", 'abstract_zh': '大型不规则网格上的物理系统为深度学习方法带来了显著的可扩展性挑战，特别是在存在长程相互作用和多尺度耦合的情况下。传统的计算所有成对相互作用的方法，如注意力机制，在节点数量增加时计算成本会呈 quadratically 增长。我们提出了 Erwin，这是一种受计算多体物理方法启发的分层变压器，它结合了基于树的算法的高效性和注意力机制的表达能力。Erwin 使用球树分区来组织计算，通过在固定大小的局部邻域内并行处理节点来实现线性时间的注意力机制。通过球树结构的逐步粗化和细化，并结合一种新颖的跨球体交互机制，它可以捕获细粒度的局部细节和全局特征。我们在包括宇宙学、分子动力学和粒子流体动力学等多个领域中展示了 Erwin 的有效性，结果表明它在准确性和计算效率上均优于基准方法。', 'title_zh': 'Erwin：一种基于树的分层变换模型，用于大规模物理系统'}
{'arxiv_id': 'arXiv:2502.17007', 'title': 'All You Need for Counterfactual Explainability Is Principled and Reliable Estimate of Aleatoric and Epistemic Uncertainty', 'authors': 'Kacper Sokol, Eyke Hüllermeier', 'link': 'https://arxiv.org/abs/2502.17007', 'abstract': 'This position paper argues that, to its detriment, transparency research overlooks many foundational concepts of artificial intelligence. Here, we focus on uncertainty quantification -- in the context of ante-hoc interpretability and counterfactual explainability -- showing how its adoption could address key challenges in the field. First, we posit that uncertainty and ante-hoc interpretability offer complementary views of the same underlying idea; second, we assert that uncertainty provides a principled unifying framework for counterfactual explainability. Consequently, inherently transparent models can benefit from human-centred explanatory insights -- like counterfactuals -- which are otherwise missing. At a higher level, integrating artificial intelligence fundamentals into transparency research promises to yield more reliable, robust and understandable predictive models.', 'abstract_zh': '这篇立场论文认为，透明度研究忽略了人工智能许多基础概念，这对透明度研究造成了损害。本文关注先验解释和反事实可解释性中的不确定性量化，展示其采用如何解决领域中的关键问题。首先，本文提出不确定性与先验解释提供了同一基本概念的不同视角；其次，本文断言不确定性为反事实可解释性提供了一个原理上的统一框架。因此，固有的透明模型能够从以人为中心的解释洞察（如反事实解释）中受益，而这些洞察在其他情况下是缺失的。在更高层次上，将人工智能的基本原理融入透明度研究有望产生更可靠、更 robust 和更易理解的预测模型。', 'title_zh': '你需要的一切仅为原理上可靠估计 aleatoric 和 epistemic 不确定性以实现反事实解释性。'}
{'arxiv_id': 'arXiv:2502.17003', 'title': 'Improving the Transferability of Adversarial Examples by Inverse Knowledge Distillation', 'authors': 'Wenyuan Wu, Zheng Liu, Yong Chen, Chao Su, Dezhong Peng, Xu Wang', 'link': 'https://arxiv.org/abs/2502.17003', 'abstract': 'In recent years, the rapid development of deep neural networks has brought increased attention to the security and robustness of these models. While existing adversarial attack algorithms have demonstrated success in improving adversarial transferability, their performance remains suboptimal due to a lack of consideration for the discrepancies between target and source models. To address this limitation, we propose a novel method, Inverse Knowledge Distillation (IKD), designed to enhance adversarial transferability effectively. IKD introduces a distillation-inspired loss function that seamlessly integrates with gradient-based attack methods, promoting diversity in attack gradients and mitigating overfitting to specific model architectures. By diversifying gradients, IKD enables the generation of adversarial samples with superior generalization capabilities across different models, significantly enhancing their effectiveness in black-box attack scenarios. Extensive experiments on the ImageNet dataset validate the effectiveness of our approach, demonstrating substantial improvements in the transferability and attack success rates of adversarial samples across a wide range of models.', 'abstract_zh': '近年来，深度神经网络的快速发展引起了对其安全性和鲁棒性的广泛关注。尽管现有的对抗攻击算法在提高对抗迁徙性方面取得了成功，但由于缺乏对目标模型和源模型差异的考虑，其性能仍不理想。为解决这一局限，我们提出了一种新颖的方法——逆向知识蒸馏（IKD），旨在有效增强对抗迁徙性。IKD 引入了一种借鉴知识蒸馏思想的损失函数，能够无缝集成到基于梯度的攻击方法中，促进攻击梯度的多样化并减轻对特定模型架构的过度拟合。通过多样化梯度，IKD 使生成的对抗样本具有在不同模型上更优的一般化能力，显著增强了其在黑盒攻击场景中的效果。在 ImageNet 数据集上的广泛实验验证了我们方法的有效性，展示了在多种模型上对抗样本的迁徙性和攻击成功率的显著提升。', 'title_zh': '通过逆向知识蒸馏提高对抗样本的迁移性'}
{'arxiv_id': 'arXiv:2502.16987', 'title': 'Hotter and Colder: A New Approach to Annotating Sentiment, Emotions, and Bias in Icelandic Blog Comments', 'authors': 'Steinunn Rut Friðriksdóttir, Dan Saattrup Nielsen, Hafsteinn Einarsson', 'link': 'https://arxiv.org/abs/2502.16987', 'abstract': 'This paper presents Hotter and Colder, a dataset designed to analyze various types of online behavior in Icelandic blog comments. Building on previous work, we used GPT-4o mini to annotate approximately 800,000 comments for 25 tasks, including sentiment analysis, emotion detection, hate speech, and group generalizations. Each comment was automatically labeled on a 5-point Likert scale. In a second annotation stage, comments with high or low probabilities of containing each examined behavior were subjected to manual revision. By leveraging crowdworkers to refine these automatically labeled comments, we ensure the quality and accuracy of our dataset resulting in 12,232 uniquely annotated comments and 19,301 annotations. Hotter and Colder provides an essential resource for advancing research in content moderation and automatically detectiong harmful online behaviors in Icelandic.', 'abstract_zh': 'Hotter and Colder：一个用于分析冰岛博客评论中各种在线行为的数据集', 'title_zh': '更热更冷：一种注释冰岛博客评论中情感、情绪和偏见的新方法'}
{'arxiv_id': 'arXiv:2502.16977', 'title': 'Convergence of Shallow ReLU Networks on Weakly Interacting Data', 'authors': 'Léo Dana, Francis Bach, Loucas Pillaud-Vivien', 'link': 'https://arxiv.org/abs/2502.16977', 'abstract': 'We analyse the convergence of one-hidden-layer ReLU networks trained by gradient flow on $n$ data points. Our main contribution leverages the high dimensionality of the ambient space, which implies low correlation of the input samples, to demonstrate that a network with width of order $\\log(n)$ neurons suffices for global convergence with high probability. Our analysis uses a Polyak-Łojasiewicz viewpoint along the gradient-flow trajectory, which provides an exponential rate of convergence of $\\frac{1}{n}$. When the data are exactly orthogonal, we give further refined characterizations of the convergence speed, proving its asymptotic behavior lies between the orders $\\frac{1}{n}$ and $\\frac{1}{\\sqrt{n}}$, and exhibiting a phase-transition phenomenon in the convergence rate, during which it evolves from the lower bound to the upper, and in a relative time of order $\\frac{1}{\\log(n)}$.', 'abstract_zh': '我们分析了一隐藏层ReLU网络在梯度流训练下对$n$个数据点的学习收敛性。我们的主要贡献利用了环境空间的高维性，这导致输入样本低相关性，证明了宽度为$\\log(n)$数量级的神经网络足以实现高概率的全局收敛。我们的分析采用了梯度流轨迹上的Polyak-Łojasiewicz观点，提供了指数级的收敛率$\\frac{1}{n}$。当数据恰好正交时，我们进一步细化了收敛速度的表征，证明其渐近行为位于$\\frac{1}{n}$和$\\frac{1}{\\sqrt{n}}$之间，并展示了收敛速率的相变现象，在该现象中，收敛速率从下界演变成上界，且这一转变发生在相对时间为$\\frac{1}{\\log(n)}$的时间尺度上。', 'title_zh': '浅层ReLU网络在弱交互数据上的收敛性'}
{'arxiv_id': 'arXiv:2502.16936', 'title': 'Supervised contrastive learning from weakly-labeled audio segments for musical version matching', 'authors': 'Joan Serrà, R. Oguz Araz, Dmitry Bogdanov, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2502.16936', 'abstract': 'Detecting musical versions (different renditions of the same piece) is a challenging task with important applications. Because of the ground truth nature, existing approaches match musical versions at the track level (e.g., whole song). However, most applications require to match them at the segment level (e.g., 20s chunks). In addition, existing approaches resort to classification and triplet losses, disregarding more recent losses that could bring meaningful improvements. In this paper, we propose a method to learn from weakly annotated segments, together with a contrastive loss variant that outperforms well-studied alternatives. The former is based on pairwise segment distance reductions, while the latter modifies an existing loss following decoupling, hyper-parameter, and geometric considerations. With these two elements, we do not only achieve state-of-the-art results in the standard track-level evaluation, but we also obtain a breakthrough performance in a segment-level evaluation. We believe that, due to the generality of the challenges addressed here, the proposed methods may find utility in domains beyond audio or musical version matching.', 'abstract_zh': '检测音乐版本（同一作品的不同演绎）是一个具有重要应用的挑战性任务。', 'title_zh': '弱标记音频片段的监督对比学习及其在音乐版本匹配中的应用'}
{'arxiv_id': 'arXiv:2502.16912', 'title': 'When Can We Solve the Weighted Low Rank Approximation Problem in Truly Subquadratic Time?', 'authors': 'Chenyang Li, Yingyu Liang, Zhenmei Shi, Zhao Song', 'link': 'https://arxiv.org/abs/2502.16912', 'abstract': 'The weighted low-rank approximation problem is a fundamental numerical linear algebra problem and has many applications in machine learning. Given a $n \\times n$ weight matrix $W$ and a $n \\times n$ matrix $A$, the goal is to find two low-rank matrices $U, V \\in \\mathbb{R}^{n \\times k}$ such that the cost of $\\| W \\circ (U V^\\top - A) \\|_F^2$ is minimized. Previous work has to pay $\\Omega(n^2)$ time when matrices $A$ and $W$ are dense, e.g., having $\\Omega(n^2)$ non-zero entries. In this work, we show that there is a certain regime, even if $A$ and $W$ are dense, we can still hope to solve the weighted low-rank approximation problem in almost linear $n^{1+o(1)}$ time.', 'abstract_zh': '加权低秩逼近问题是数值线性代数中的一个基础问题，在机器学习中有着广泛的应用。给定一个$n \\times n$权重矩阵$W$和一个$n \\times n$矩阵$A$，目标是找到两个低秩矩阵$U, V \\in \\mathbb{R}^{n \\times k}$，使得$\\| W \\circ (U V^\\top - A) \\|_F^2$的成本最小化。前人的工作在矩阵$A$和$W$稠密（例如，具有 $\\Omega(n^2)$ 个非零元素）的情况下需要花费$\\Omega(n^2)$的时间。在本文中，我们展示了即使在$A$和$W$稠密的情况下，我们仍然有可能在接近线性的$n^{1+o(1)}$时间内解决加权低秩逼近问题。', 'title_zh': '在什么情况下，加权低秩近似问题可以在真正亚二次时间内求解？'}
{'arxiv_id': 'arXiv:2502.16890', 'title': 'ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for Multivariate Time Series Forecasting', 'authors': 'Guoqi Yu, Yaoming Li, Juncheng Wang, Xiaoyu Guo, Angelica I. Aviles-Rivero, Tong Yang, Shujun Wang', 'link': 'https://arxiv.org/abs/2502.16890', 'abstract': 'Recent advancements have progressively incorporated frequency-based techniques into deep learning models, leading to notable improvements in accuracy and efficiency for time series analysis tasks. However, the Mid-Frequency Spectrum Gap in the real-world time series, where the energy is concentrated at the low-frequency region while the middle-frequency band is negligible, hinders the ability of existing deep learning models to extract the crucial frequency information. Additionally, the shared Key-Frequency in multivariate time series, where different time series share indistinguishable frequency patterns, is rarely exploited by existing literature. This work introduces a novel module, Adaptive Mid-Frequency Energy Optimizer, based on convolution and residual learning, to emphasize the significance of mid-frequency bands. We also propose an Energy-based Key-Frequency Picking Block to capture shared Key-Frequency, which achieves superior inter-series modeling performance with fewer parameters. A novel Key-Frequency Enhanced Training strategy is employed to further enhance Key-Frequency modeling, where spectral information from other channels is randomly introduced into each channel. Our approach advanced multivariate time series forecasting on the challenging Traffic, ECL, and Solar benchmarks, reducing MSE by 4%, 6%, and 5% compared to the previous SOTA iTransformer. Code is available at this GitHub Repository: this https URL.', 'abstract_zh': '最近的研究已经逐步将基于频率的技术整合到深度学习模型中，显著提高了时间序列分析任务的准确性和效率。然而，现实世界时间序列中的中频频段空洞，其中能量集中在低频区域而中频带几乎忽略不计，阻碍了现有深度学习模型提取关键频率信息的能力。此外，多变量时间序列中共享的关键频率，不同时间序列共享无法区分的频率模式，现有文献中很少加以利用。本文提出了一种新的模块——自适应中频能量优化器，基于卷积和残差学习，以强调中频带的重要性。我们还提出了一种基于能量的关键频率挑选块，能够捕获共享的关键频率，并通过较少的参数实现了更优秀的跨系列建模性能。我们采用了一种新的关键频率增强训练策略，其中从其他通道随机引入频谱信息到每个通道，以进一步增强关键频率建模。我们的方法在具有挑战性的Traffic、ECL和Solar基准测试中提高了多变量时间序列预测，与之前的SOTA iTransformer相比，MSE降低了4%、6%和5%。代码可供在此GitHub Repository获取：this https URL。', 'title_zh': 'ReFocus: 加强中频和关键频 modeling 多变量时间序列预测'}
{'arxiv_id': 'arXiv:2502.16871', 'title': 'Utilizing Social Media Analytics to Detect Trends in Saudi Arabias Evolving Market', 'authors': 'Kanwal Aalijah', 'link': 'https://arxiv.org/abs/2502.16871', 'abstract': 'Saudi Arabia faced a swift economic growth and societal transformation under Vision 2030. This offers a unique opportunity to track emerging trends in the region, which will ultimately pave the way for new business and investment possibilities. This paper explores how AI and social media analytics can identify and track trends across sectors such as construction, food and beverage, tourism, technology, and entertainment thereby helping the businesses make informed decisions. By leveraging a tailored AI-driven methodology, we analyzed millions of social media posts each month, classifying discussions and calculating scores to track the trends. The approach not only uncovered the emerging trends but also shows diminishing trends. Our methodology is able to predict the emergence and growth of trends by utilizing social media data. This approach has potential for adaptation in other regions. Ultimately, our findings highlight how ongoing, AI-powered trend analysis can enable more effective, data-informed business and development strategies in an increasingly dynamic environment.', 'abstract_zh': '沙特阿拉伯在2030愿景下经历了快速的经济成长和社会转型，这为追踪区域新兴趋势提供了独特机会，并最终为新的商业和投资可能性铺平道路。本文探讨了人工智能和社交媒体分析如何跨建筑业、食品和饮料、旅游、科技和娱乐等产业识别和追踪趋势，从而帮助企业在充分知情的基础上做出决策。通过利用定制的人工智能方法，我们每月分析数百万条社交媒体帖子，对讨论进行分类并计算得分以追踪趋势。该方法不仅发现了新兴趋势，还展示了衰退趋势。我们的方法能够利用社交媒体数据预测趋势的出现和增长。该方法在其他地区具有潜在的适应性。最终，我们的研究结果突显了持续的人工智能驱动的趋势分析如何在日益动态的环境中使数据驱动的商业和开发策略更加有效。', 'title_zh': '利用社交媒体分析检测沙特阿拉伯市场演变趋势'}
{'arxiv_id': 'arXiv:2502.16841', 'title': 'Fair Foundation Models for Medical Image Analysis: Challenges and Perspectives', 'authors': 'Dilermando Queiroz, Anderson Carlos, André Anjos, Lilian Berton', 'link': 'https://arxiv.org/abs/2502.16841', 'abstract': 'Ensuring equitable Artificial Intelligence (AI) in healthcare demands systems that make unbiased decisions across all demographic groups, bridging technical innovation with ethical principles. Foundation Models (FMs), trained on vast datasets through self-supervised learning, enable efficient adaptation across medical imaging tasks while reducing dependency on labeled data. These models demonstrate potential for enhancing fairness, though significant challenges remain in achieving consistent performance across demographic groups. Our review indicates that effective bias mitigation in FMs requires systematic interventions throughout all stages of development. While previous approaches focused primarily on model-level bias mitigation, our analysis reveals that fairness in FMs requires integrated interventions throughout the development pipeline, from data documentation to deployment protocols. This comprehensive framework advances current knowledge by demonstrating how systematic bias mitigation, combined with policy engagement, can effectively address both technical and institutional barriers to equitable AI in healthcare. The development of equitable FMs represents a critical step toward democratizing advanced healthcare technologies, particularly for underserved populations and regions with limited medical infrastructure and computational resources.', 'abstract_zh': '确保医疗卫生中公平的人工智能需要在所有人口群体中做出无偏见的决策，将技术创新与伦理原则相结合。基础模型（FMs）通过自监督学习训练于大规模数据集，能够在各种医学成像任务中实现高效适应，同时减少对标注数据的依赖。尽管这些模型显示出提高公平性的潜力，但在人口群体间的持续性能一致性方面仍面临重大挑战。我们的综述指出，有效的偏见缓解需要在FMs开发的所有阶段采取系统性的干预措施。尽管先前的方法主要集中在模型层面的偏见缓解，但我们的分析表明，FMs的公平性需要在整个开发管道中采取集成干预措施，从数据文档到部署协议。这种全面框架通过展示系统性的偏见缓解与政策参与相结合如何有效应对公平人工智能在医疗卫生中的技术和制度障碍，促进了现有知识的提升。开发公平的基础模型是推动高级医疗技术民主化的一个关键步骤，特别是在服务不足的人群和医疗基础设施和计算资源有限的地区。', 'title_zh': '公平的基础模型在医学图像分析中的挑战与视角'}
{'arxiv_id': 'arXiv:2502.16840', 'title': 'In-context learning of evolving data streams with tabular foundational models', 'authors': 'Afonso Lourenço, João Gama, Eric P. Xing, Goreti Marreiros', 'link': 'https://arxiv.org/abs/2502.16840', 'abstract': "State-of-the-art data stream mining in supervised classification has traditionally relied on ensembles of incremental decision trees. However, the emergence of large tabular models, i.e., transformers designed for structured numerical data, marks a significant paradigm shift. These models move beyond traditional weight updates, instead employing in-context learning through prompt tuning. By using on-the-fly sketches to summarize unbounded streaming data, one can feed this information into a pre-trained model for efficient processing. This work bridges advancements from both areas, highlighting how transformers' implicit meta-learning abilities, pre-training on drifting natural data, and reliance on context optimization directly address the core challenges of adaptive learning in dynamic environments. Exploring real-time model adaptation, this research demonstrates that TabPFN, coupled with a simple sliding memory strategy, consistently outperforms ensembles of Hoeffding trees across all non-stationary benchmarks. Several promising research directions are outlined in the paper. The authors urge the community to explore these ideas, offering valuable opportunities to advance in-context stream learning.", 'abstract_zh': '最先进数据流挖掘在监督分类中的最新进展 traditionally 依赖于增量决策树的集成。然而，大型表格模型，即专门为结构化数值数据设计的转换器的出现，标志着一个显著的范式转变。这些模型超越了传统的权重更新，而是通过提示调优进行上下文学习。通过使用随流生成的草图来总结未界定的数据流，可以将这些信息输入到预训练模型中进行高效处理。本研究将两个领域的最新进展结合起来，突显了变换器的隐式元学习能力、在漂移自然数据上的预训练以及依赖于上下文优化如何直接解决动态环境中的自适应学习核心挑战。探索实时模型适应，研究展示了结合简单滑动记忆策略的 TabPFN 在所有非平稳基准上的表现始终优于霍夫丁树的集成。论文中概述了几个有前景的研究方向。作者敦促社区探索这些想法，提供了提高上下文流学习的重要机会。', 'title_zh': '基于表格基础模型的 evolving 数据流的上下文学习'}
{'arxiv_id': 'arXiv:2502.16834', 'title': 'A Novel Multi-Task Teacher-Student Architecture with Self-Supervised Pretraining for 48-Hour Vasoactive-Inotropic Trend Analysis in Sepsis Mortality Prediction', 'authors': 'Houji Jin, Negin Ashrafi, Kamiar Alaei, Elham Pishgar, Greg Placencia, Maryam Pishgar', 'link': 'https://arxiv.org/abs/2502.16834', 'abstract': "Sepsis is a major cause of ICU mortality, where early recognition and effective interventions are essential for improving patient outcomes. However, the vasoactive-inotropic score (VIS) varies dynamically with a patient's hemodynamic status, complicated by irregular medication patterns, missing data, and confounders, making sepsis prediction challenging. To address this, we propose a novel Teacher-Student multitask framework with self-supervised VIS pretraining via a Masked Autoencoder (MAE). The teacher model performs mortality classification and severity-score regression, while the student distills robust time-series representations, enhancing adaptation to heterogeneous VIS data. Compared to LSTM-based methods, our approach achieves an AUROC of 0.82 on MIMIC-IV 3.0 (9,476 patients), outperforming the baseline (0.74). SHAP analysis revealed that SOFA score (0.147) had the greatest impact on ICU mortality, followed by LODS (0.033), single marital status (0.031), and Medicaid insurance (0.023), highlighting the role of sociodemographic factors. SAPSII (0.020) also contributed significantly. These findings suggest that both clinical and social factors should be considered in ICU decision-making. Our novel multitask and distillation strategies enable earlier identification of high-risk patients, improving prediction accuracy and disease management, offering new tools for ICU decision support.", 'abstract_zh': '脓毒症是ICU死亡的主要原因，早期识别和有效干预对于改善患者预后至关重要。然而，由于血管活性-正性肌力药物评分（VIS）随患者血流动力学状态动态变化，受到不规律用药模式、缺失数据和混杂因素的影响，脓毒症的预测变得极具挑战性。为此，我们提出了一种新颖的教师-学生多任务框架，通过掩码自编码器（MAE）进行自我监督的VIS预训练。教师模型执行死亡率分类和严重程度评分回归，而学生模型提炼出稳健的时间序列表示，以增强对异质VIS数据的适应性。与基于LSTM的方法相比，我们的方法在MIMIC-IV 3.0（9,476例患者）数据集上实现了0.82的AUROC，优于基线（0.74）。SHAP分析显示， sofa评分（0.147）对ICU死亡率影响最大，其次是LODS（0.033）、单身状态（0.031）和Medicaid保险（0.023），突显了社会经济因素的作用。SAPSII（0.020）也做出了显著贡献。这些发现表明，在ICU决策中应同时考虑临床和社会因素。我们提出的新颖多任务和精炼策略能够更早地识别高风险患者，提高预测准确性并优化疾病管理，为ICU决策支持提供新工具。', 'title_zh': '一种新型多任务教师-学生架构结合自监督预训练在严重感染致死率预测中的48小时血管活性-正性肌力药趋势分析'}
{'arxiv_id': 'arXiv:2502.16828', 'title': 'Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning', 'authors': 'Ruikun Li, Huandong Wang, Qingmin Liao, Yong Li', 'link': 'https://arxiv.org/abs/2502.16828', 'abstract': 'Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems. System evolution is often modeled as particles moving on a landscape under the combined effect of energy-driven drift and noise-induced diffusion, where the energy governs the long-term motion of the particles. Estimating the energy landscape of a system has been a longstanding interdisciplinary challenge, hindered by the high operational costs or the difficulty of obtaining supervisory signals. Therefore, the question of how to infer the energy landscape in the absence of true energy values is critical. In this paper, we propose a physics-informed self-supervised learning method to learn the energy landscape from the evolution trajectories of the system. It first maps the system state from the observation space to a discrete landscape space by an adaptive codebook, and then explicitly integrates energy into the graph neural Fokker-Planck equation, enabling the joint learning of energy estimation and evolution prediction. Experimental results across interdisciplinary systems demonstrate that our estimated energy has a correlation coefficient above 0.9 with the ground truth, and evolution prediction accuracy exceeds the baseline by an average of 17.65\\%. The code is available at this http URL.', 'abstract_zh': '能量景观在塑造许多现实世界复杂系统动力学中发挥着关键作用。系统演化通常被建模为在由能量驱动的漂移和噪声引起的扩散联合效应下，粒子在景观上移动，其中能量决定了粒子的长期运动。估计系统的能量景观一直是一个跨学科的长期挑战，受到高操作成本或难以获得监督信号的阻碍。因此，在没有真实能量值的情况下如何推断能量景观的问题至关重要。本文提出一种基于物理的自监督学习方法，从系统的演化轨迹中学习能量景观。该方法首先通过自适应码本将系统状态从观测空间映射到离散的景观空间，然后明确将能量整合到图神经Fokker-Planck方程中，使能量估计和演化预测的联合学习成为可能。跨学科系统的实验结果表明，我们估计的能量与真实值的相关系数高于0.9，演化预测精度平均高出基线17.65%。代码可从此链接获得。', 'title_zh': '通过物理信息自监督学习预测随机动力系统能景'}
{'arxiv_id': 'arXiv:2502.16813', 'title': 'Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns', 'authors': 'Yuxiang Guo, Yuren Mao, Zhonghao Hu, Lu Chen, Yunjun Gao', 'link': 'https://arxiv.org/abs/2502.16813', 'abstract': 'Semantic join discovery, which aims to find columns in a table repository with high semantic joinabilities to a query column, is crucial for dataset discovery. Existing methods can be divided into two categories: cell-level methods and column-level methods. However, neither of them ensures both effectiveness and efficiency simultaneously. Cell-level methods, which compute the joinability by counting cell matches between columns, enjoy ideal effectiveness but suffer poor efficiency. In contrast, column-level methods, which determine joinability only by computing the similarity of column embeddings, enjoy proper efficiency but suffer poor effectiveness due to the issues occurring in their column embeddings: (i) semantics-joinability-gap, (ii) size limit, and (iii) permutation sensitivity. To address these issues, this paper proposes to compute column embeddings via proxy columns; furthermore, a novel column-level semantic join discovery framework, Snoopy, is presented, leveraging proxy-column-based embeddings to bridge effectiveness and efficiency. Specifically, the proposed column embeddings are derived from the implicit column-to-proxy-column relationships, which are captured by the lightweight approximate-graph-matching-based column this http URL acquire good proxy columns for guiding the column projection, we introduce a rank-aware contrastive learning paradigm. Extensive experiments on four real-world datasets demonstrate that Snoopy outperforms SOTA column-level methods by 16% in Recall@25 and 10% in NDCG@25, and achieves superior efficiency--being at least 5 orders of magnitude faster than cell-level solutions, and 3.5x faster than existing column-level methods.', 'abstract_zh': '基于代理列的列级语义连接发现框架：Snoopy', 'title_zh': 'Snoopy: 通过代理列实现高效有效的语义连接发现'}
{'arxiv_id': 'arXiv:2502.16809', 'title': 'CRTrack: Low-Light Semi-Supervised Multi-object Tracking Based on Consistency Regularization', 'authors': 'Zijing Zhao, Jianlong Yu, Lin Zhang, Shunli Zhang', 'link': 'https://arxiv.org/abs/2502.16809', 'abstract': 'Multi-object tracking under low-light environments is prevalent in real life. Recent years have seen rapid development in the field of multi-object tracking. However, due to the lack of datasets and the high cost of annotations, multi-object tracking under low-light environments remains a persistent challenge. In this paper, we focus on multi-object tracking under low-light conditions. To address the issues of limited data and the lack of dataset, we first constructed a low-light multi-object tracking dataset (LLMOT). This dataset comprises data from MOT17 that has been enhanced for nighttime conditions as well as multiple unannotated low-light videos. Subsequently, to tackle the high annotation costs and address the issue of image quality degradation, we propose a semi-supervised multi-object tracking method based on consistency regularization named CRTrack. First, we calibrate a consistent adaptive sampling assignment to replace the static IoU-based strategy, enabling the semi-supervised tracking method to resist noisy pseudo-bounding boxes. Then, we design a adaptive semi-supervised network update method, which effectively leverages unannotated data to enhance model performance. Dataset and Code: this https URL.', 'abstract_zh': '低光照条件下的多目标跟踪在现实生活中非常普遍。近年来，多目标跟踪领域取得了 rapid development。然而，由于缺乏数据集和注释成本高，低光照条件下的多目标跟踪仍然是一个持续的挑战。在本文中，我们专注于低光照条件下的多目标跟踪。为了应对数据有限和缺乏数据集的问题，我们首先构建了一个低光照多目标跟踪数据集（LLMOT）。该数据集包含夜间条件增强的MOT17数据以及多个未注释的低光照视频。随后，为了应对注释成本高和图像质量退化的问题，我们提出了一种基于一致性正则化的半监督多目标跟踪方法，CRTrack。该方法首先校准一个一致的自适应采样分配，以替代静态IoU策略，使半监督跟踪方法能够对抗噪声伪边框。然后，我们设计了一种自适应半监督网络更新方法，有效地利用未注释的数据来提升模型性能。数据集和代码：this https URL。', 'title_zh': 'CRTrack：基于一致性正则化的低光照半监督多对象跟踪'}
{'arxiv_id': 'arXiv:2502.16796', 'title': 'MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions', 'authors': 'Yuxuan Liu, Hongda Sun, Wei Liu, Jian Luan, Bo Du, Rui Yan', 'link': 'https://arxiv.org/abs/2502.16796', 'abstract': "Mobile phone agents can assist people in automating daily tasks on their phones, which have emerged as a pivotal research spotlight. However, existing procedure-oriented agents struggle with cross-app instructions, due to the following challenges: (1) complex task relationships, (2) diverse app environment, and (3) error propagation and information loss in multi-step execution. Drawing inspiration from object-oriented programming principles, we recognize that object-oriented solutions is more suitable for cross-app instruction. To address these challenges, we propose a self-evolving multi-agent framework named MobileSteward, which integrates multiple app-oriented StaffAgents coordinated by a centralized StewardAgent. We design three specialized modules in MobileSteward: (1) Dynamic Recruitment generates a scheduling graph guided by information flow to explicitly associate tasks among apps. (2) Assigned Execution assigns the task to app-oriented StaffAgents, each equipped with app-specialized expertise to address the diversity between apps. (3) Adjusted Evaluation conducts evaluation to provide reflection tips or deliver key information, which alleviates error propagation and information loss during multi-step execution. To continuously improve the performance of MobileSteward, we develop a Memory-based Self-evolution mechanism, which summarizes the experience from successful execution, to improve the performance of MobileSteward. We establish the first English Cross-APP Benchmark (CAPBench) in the real-world environment to evaluate the agents' capabilities of solving complex cross-app instructions. Experimental results demonstrate that MobileSteward achieves the best performance compared to both single-agent and multi-agent frameworks, highlighting the superiority of MobileSteward in better handling user instructions with diverse complexity.", 'abstract_zh': '基于对象的移动手机代理框架MobileSteward：解决跨应用指令挑战', 'title_zh': 'MobileSteward：集成多种面向应用的代理并具备自我演进能力以自动化跨应用指令执行'}
{'arxiv_id': 'arXiv:2502.16793', 'title': 'VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning', 'authors': 'Yang Chen, Bin Zhou', 'link': 'https://arxiv.org/abs/2502.16793', 'abstract': 'Graph Neural Networks (GNNs) have gained attention for their ability to learn representations from graph data. Due to privacy concerns and conflicts of interest that prevent clients from directly sharing graph data with one another, Vertical Graph Federated Learning (VGFL) frameworks have been developed. Recent studies have shown that VGFL is vulnerable to adversarial attacks that degrade performance. However, it is a common problem that client nodes are often unlabeled in the realm of VGFL. Consequently, the existing attacks, which rely on the availability of labeling information to obtain gradients, are inherently constrained in their applicability. This limitation precludes their deployment in practical, real-world environments. To address the above problems, we propose a novel graph adversarial attack against VGFL, referred to as VGFL-SA, to degrade the performance of VGFL by modifying the local clients structure without using labels. Specifically, VGFL-SA uses a contrastive learning method to complete the attack before the local clients are trained. VGFL-SA first accesses the graph structure and node feature information of the poisoned clients, and generates the contrastive views by node-degree-based edge augmentation and feature shuffling augmentation. Then, VGFL-SA uses the shared graph encoder to get the embedding of each view, and the gradients of the adjacency matrices are obtained by the contrastive function. Finally, perturbed edges are generated using gradient modification rules. We validated the performance of VGFL-SA by performing a node classification task on real-world datasets, and the results show that VGFL-SA achieves good attack effectiveness and transferability.', 'abstract_zh': '垂直图联邦学习中的新型图对抗攻击（VGFL-SA）：无需标签修改局部客户端结构以降级垂直图联邦学习性能', 'title_zh': 'VGFL-SA：基于对比学习的垂直图联邦学习结构攻击'}
{'arxiv_id': 'arXiv:2502.16778', 'title': 'The Robustness of Structural Features in Species Interaction Networks', 'authors': 'Sanaz Hasanzadeh Fard, Emily Dolson', 'link': 'https://arxiv.org/abs/2502.16778', 'abstract': 'Species interaction networks are a powerful tool for describing ecological communities; they typically contain nodes representing species, and edges representing interactions between those species. For the purposes of drawing abstract inferences about groups of similar networks, ecologists often use graph topology metrics to summarize structural features. However, gathering the data that underlies these networks is challenging, which can lead to some interactions being missed. Thus, it is important to understand how much different structural metrics are affected by missing data. To address this question, we analyzed a database of 148 real-world bipartite networks representing four different types of species interactions (pollination, host-parasite, plant-ant, and seed-dispersal). For each network, we measured six different topological properties: number of connected components, variance in node betweenness, variance in node PageRank, largest Eigenvalue, the number of non-zero Eigenvalues, and community detection as determined by four different algorithms. We then tested how these properties change as additional edges -- representing data that may have been missed -- are added to the networks. We found substantial variation in how robust different properties were to the missing data. For example, the Clauset-Newman-Moore and Louvain community detection algorithms showed much more gradual change as edges were added than the label propagation and Girvan-Newman algorithms did, suggesting that the former are more robust. Robustness also varied for some metrics based on interaction type. These results provide a foundation for selecting network properties to use when analyzing messy ecological network data.', 'abstract_zh': '物种相互作用网络是描述生态群落的强大工具；它们通常包含表示物种的节点和表示物种间相互作用的边。为了从类似的网络群体中提取抽象推论，生态学家常用图拓扑度量来总结结构特征。然而，收集构成这些网络的数据具有挑战性，可能导致某些相互作用被遗漏。因此，理解不同结构度量在数据缺失时的敏感性非常重要。为了解决这个问题，我们分析了一个包含148个现实世界双部分网络的数据库，这些网络代表了四种不同类型的物种相互作用（传粉、寄主-寄生虫、植物-蚂蚁、种子传播）。对每个网络，我们测量了六种不同的拓扑属性：连通分支数、节点中介中心性的方差、节点PageRank的方差、最大的特征值、非零特征值的数量，以及由四种不同算法确定的社区检测结果。然后我们测试了在不断添加表示可能遗漏的数据的边时，这些属性会发生怎样的变化。我们发现不同属性对数据缺失的鲁棒性存在显著差异。例如，Clauset-Newman-Moore和Louvain社区检测算法在添加边时显示出更平滑的变化，而标签传播和Girvan-Newman算法则显示出更急剧的变化，这表明前者更鲁棒。鲁棒性在某些基于相互作用类型的度量上也有所不同。这些结果为分析混乱的生态网络数据时选择网络属性提供了基础。', 'title_zh': '物种互作网络中结构特征的稳健性'}
{'arxiv_id': 'arXiv:2502.16776', 'title': 'AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement', 'authors': 'Zhexin Zhang, Leqi Lei, Junxiao Yang, Xijie Huang, Yida Lu, Shiyao Cui, Renmiao Chen, Qinglin Zhang, Xinyuan Wang, Hao Wang, Hao Li, Xianqi Lei, Chengwei Pan, Lei Sha, Hongning Wang, Minlie Huang', 'link': 'https://arxiv.org/abs/2502.16776', 'abstract': 'As AI models are increasingly deployed across diverse real-world scenarios, ensuring their safety remains a critical yet underexplored challenge. While substantial efforts have been made to evaluate and enhance AI safety, the lack of a standardized framework and comprehensive toolkit poses significant obstacles to systematic research and practical adoption. To bridge this gap, we introduce AISafetyLab, a unified framework and toolkit that integrates representative attack, defense, and evaluation methodologies for AI safety. AISafetyLab features an intuitive interface that enables developers to seamlessly apply various techniques while maintaining a well-structured and extensible codebase for future advancements. Additionally, we conduct empirical studies on Vicuna, analyzing different attack and defense strategies to provide valuable insights into their comparative effectiveness. To facilitate ongoing research and development in AI safety, AISafetyLab is publicly available at this https URL, and we are committed to its continuous maintenance and improvement.', 'abstract_zh': '随着AI模型在多样化的现实场景中越来越广泛地部署，确保其安全性仍是一个关键但尚未充分探索的挑战。尽管已经做出了大量努力来评估和提升AI安全性，但缺乏标准化框架和综合工具套件严重阻碍了系统性研究和实际应用。为解决这一问题，我们介绍了AISafetyLab，这是一个统一的框架和工具套件，集成了代表性的攻击、防御和评估方法，以促进AI安全性。AISafetyLab具有直观的界面，使开发人员能够无缝应用各种技术，并维持一个结构良好且可扩展的代码库，以支持未来的发展。此外，我们还在Vicuna上进行了实证研究，分析了不同的攻击和防御策略，提供了关于其相对效果的宝贵见解。为了促进AI安全性领域的持续研究和发展，AISafetyLab已在以下网址公开可用，并致力于其持续维护和改进。', 'title_zh': 'AISafetyLab: 人工智能安全评估与改进综合框架'}
{'arxiv_id': 'arXiv:2502.16744', 'title': 'Order-Optimal Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization', 'authors': 'Yiyang Lu, Mohammad Pedramfar, Vaneet Aggarwal', 'link': 'https://arxiv.org/abs/2502.16744', 'abstract': 'Projection-based algorithms for constrained Online Convex Optimization (COCO) face scalability challenges in high-dimensional settings due to the computational complexity of projecting iterates onto constraint sets. This paper introduces a projection-free algorithm for COCO that achieves state-of-the-art performance guarantees while eliminating the need for projections. By integrating a separation oracle with adaptive Online Gradient Descent (OGD) and employing a Lyapunov-driven surrogate function, while dynamically adjusting step sizes using gradient norms, our method jointly optimizes the regret and cumulative constraint violation (CCV). We also use a blocked version of OGD that helps achieve tradeoffs betweeen the regret and CCV with the number of calls to the separation oracle. For convex cost functions, our algorithm attains an optimal regret of $\\mathcal{O}(\\sqrt{T})$ and a CCV of $\\mathcal{O}(\\sqrt{T} \\log T)$, matching the best-known projection-based results, while only using $\\tilde{\\mathcal{O}}({T})$ calls to the separation oracle. The results also demonstrate a tradeoff where lower calls to the separation oracle increase the regret and the CCV. In the strongly convex setting, we further achieve a regret of $\\mathcal{O}(\\log T)$ and a CCV of $\\mathcal{O}(\\sqrt{T\\log T} )$, while requiring ${\\mathcal{O}}({T}^2)$ calls to the separation oracle. Further, tradeoff with the decreasing oracle calls is studied. These results close the gap between projection-free and projection-based approaches, demonstrating that projection-free methods can achieve performance comparable to projection-based counterparts.', 'abstract_zh': '基于投影的算法在受限在线凸优化中的扩展挑战：一种无需投影的状态-of-the-art性能保证的投影-free算法', 'title_zh': '对抗约束在线凸优化的最优投影免费算法'}
{'arxiv_id': 'arXiv:2502.16736', 'title': 'AUKT: Adaptive Uncertainty-Guided Knowledge Transfer with Conformal Prediction', 'authors': 'Rui Liu, Peng Gao, Yu Shen, Ming Lin, Pratap Tokekar', 'link': 'https://arxiv.org/abs/2502.16736', 'abstract': "Knowledge transfer between teacher and student models has proven effective across various machine learning applications. However, challenges arise when the teacher's predictions are noisy, or the data domain during student training shifts from the teacher's pretraining data. In such scenarios, blindly relying on the teacher's predictions can lead to suboptimal knowledge transfer. To address these challenges, we propose a novel and universal framework, Adaptive Uncertainty-guided Knowledge Transfer ($\\textbf{AUKT}$), which leverages Conformal Prediction (CP) to dynamically adjust the student's reliance on the teacher's guidance based on the teacher's prediction uncertainty. CP is a distribution-free, model-agnostic approach that provides reliable prediction sets with statistical coverage guarantees and minimal computational overhead. This adaptive mechanism mitigates the risk of learning undesirable or incorrect knowledge. We validate the proposed framework across diverse applications, including image classification, imitation-guided reinforcement learning, and autonomous driving. Experimental results consistently demonstrate that our approach improves performance, robustness and transferability, offering a promising direction for enhanced knowledge transfer in real-world applications.", 'abstract_zh': '教师模型与学生模型之间的知识迁移在各种机器学习应用中已被证明是有效的。然而，在教师预测噪声较大或学生训练数据域与教师预训练数据不同的情况下，单纯依赖教师预测会导致知识迁移效果不佳。为应对这些挑战，我们提出了一种新颖且通用的框架——自适应不确定性引导的知识迁移（AUKT），该框架利用形尔诺预测（CP）动态调整学生对教师指导的依赖程度，依据教师预测的不确定性。CP是一种基于统计覆盖率保证且计算开销较小的非参数、模型无关的方法。这种自适应机制减少了学习不期望或错误知识的风险。我们在图像分类、imitation引导的强化学习和自动驾驶等多个应用中验证了该框架的有效性，实验结果一致表明，我们的方法在提高性能、鲁棒性和迁移性方面具有显著优势，为现实应用中增强知识迁移提供了前景广阔的方向。', 'title_zh': '自适应不确定性引导的知识转移与 conformal 推断'}
{'arxiv_id': 'arXiv:2502.16732', 'title': "DeepSeek reshaping healthcare in China's tertiary hospitals", 'authors': 'Jishizhan Chen, Qingzeng Zhang', 'link': 'https://arxiv.org/abs/2502.16732', 'abstract': "The rapid integration of artificial intelligence (AI) into healthcare is transforming clinical decision-making and hospital operations. DeepSeek has emerged as a leading AI system, widely deployed across China's tertiary hospitals since January 2025. Initially implemented in Shanghai's major medical institutions, it has since expanded nationwide, enhancing diagnostic accuracy, streamlining workflows, and improving patient management. AI-powered pathology, imaging analysis, and clinical decision support systems have demonstrated significant potential in optimizing medical processes and reducing the cognitive burden on healthcare professionals. However, the widespread adoption of AI in healthcare raises critical regulatory and ethical challenges, particularly regarding accountability in AI-assisted diagnosis and the risk of automation bias. The absence of a well-defined liability framework underscores the need for policies that ensure AI functions as an assistive tool rather than an autonomous decision-maker. With continued technological advancements, AI is expected to integrate multimodal data sources, such as genomics and radiomics, paving the way for precision medicine and personalized treatment strategies. The future of AI in healthcare depends on the development of transparent regulatory structures, industry collaboration, and adaptive governance frameworks that balance innovation with responsibility, ensuring equitable and effective AI-driven medical services.", 'abstract_zh': '人工智能（AI）在医疗领域的快速集成正 transforming 临床决策和医院运营。DeepSeek 已成为领先的 AI 系统，在2025年1月起广泛部署于中国三级医院。最初实施于上海主要医疗机构后，它已扩展至全国，增强了诊断准确性，简化了工作流程，改善了患者管理。基于 AI 的病理学、影像分析和临床决策支持系统展示了在优化医疗流程和减轻医疗服务人员认知负担方面的重要潜力。然而，AI 在医疗领域的广泛应用引发了关键的监管和伦理挑战，特别是与 AI 辅助诊断的责任归属以及自动化偏见的风险。缺乏明确的问责框架强调了制定政策的重要性，以确保 AI 作为辅助工具而非自主决策者发挥作用。随着技术的不断进步，AI 预计将集成多模态数据源，如基因组学和影像组学，为精准医疗和个人化治疗策略铺平道路。医疗领域中 AI 的未来取决于透明监管结构、行业合作和能够平衡创新与责任的适应性治理框架，确保公平有效的 AI 驱动医疗服务。', 'title_zh': 'DeepSeek重塑中国三级医院的医疗健康服务'}
{'arxiv_id': 'arXiv:2502.16708', 'title': 'Exploring Incremental Unlearning: Techniques, Challenges, and Future Directions', 'authors': 'Sadia Qureshi, Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Jianming Yong, Xiaohua Jia', 'link': 'https://arxiv.org/abs/2502.16708', 'abstract': "The growing demand for data privacy in Machine Learning (ML) applications has seen Machine Unlearning (MU) emerge as a critical area of research. As the `right to be forgotten' becomes regulated globally, it is increasingly important to develop mechanisms that delete user data from AI systems while maintaining performance and scalability of these systems. Incremental Unlearning (IU) is a promising MU solution to address the challenges of efficiently removing specific data from ML models without the need for expensive and time-consuming full retraining. This paper presents the various techniques and approaches to IU. It explores the challenges faced in designing and implementing IU mechanisms. Datasets and metrics for evaluating the performance of unlearning techniques are discussed as well. Finally, potential solutions to the IU challenges alongside future research directions are offered. This survey provides valuable insights for researchers and practitioners seeking to understand the current landscape of IU and its potential for enhancing privacy-preserving intelligent systems.", 'abstract_zh': '机器学习应用中日益增长的数据隐私需求促使机器遗忘（Machine Unlearning, MU）成为关键研究领域。随着“被遗忘的权利”在全球范围内得到规范，开发能够在不影响这些系统性能和可扩展性的情况下从人工智能系统中删除用户数据的机制变得越来越重要。增量遗忘（Incremental Unlearning, IU）是一种有前景的MU解决方案，可以高效地从机器学习模型中删除特定数据，而无需进行昂贵且耗时的全面重新训练。本文介绍了各种IU技术及方法，探讨了设计和实现IU机制所面临的技术挑战，讨论了评估遗忘技术性能的데이터集和指标，并提出了应对IU挑战的潜在解决方案及未来的研究方向。这篇综述为寻求了解当前IU状况及其在保护隐私的智能系统中潜力的研究人员和实践者提供了宝贵的见解。', 'title_zh': '探索增量遗忘：技术、挑战与未来方向'}
{'arxiv_id': 'arXiv:2502.16648', 'title': 'Few-shot Continual Relation Extraction via Open Information Extraction', 'authors': 'Thiem Nguyen, Anh Nguyen, Quyen Tran, Tu Vu, Diep Nguyen, Linh Ngo, Thien Nguyen', 'link': 'https://arxiv.org/abs/2502.16648', 'abstract': 'Typically, Few-shot Continual Relation Extraction (FCRE) models must balance retaining prior knowledge while adapting to new tasks with extremely limited data. However, real-world scenarios may also involve unseen or undetermined relations that existing methods still struggle to handle. To address these challenges, we propose a novel approach that leverages the Open Information Extraction concept of Knowledge Graph Construction (KGC). Our method not only exposes models to all possible pairs of relations, including determined and undetermined labels not available in the training set, but also enriches model knowledge with diverse relation descriptions, thereby enhancing knowledge retention and adaptability in this challenging scenario. In the perspective of KGC, this is the first work explored in the setting of Continual Learning, allowing efficient expansion of the graph as the data evolves. Experimental results demonstrate our superior performance compared to other state-of-the-art FCRE baselines, as well as the efficiency in handling dynamic graph construction in this setting.', 'abstract_zh': '典型的少样本持续关系提取（FCRE）模型必须在极其有限的数据下平衡保留先前知识和适应新任务。然而，现实场景中还可能存在未见过或未确定的关系，现有方法仍然难以处理。为了解决这些挑战，我们提出了一种新颖的方法，该方法利用知识图构建（KGC）中的开放信息提取（Open IE）概念。我们的方法不仅使模型接触到所有可能的关系对，包括训练集中不可用的确定和未确定的标签，而且还通过丰富的关系描述来增强模型知识，从而在这一具有挑战性的场景中增强知识保留和适应性。从KGC的角度来看，这是首次在此持续学习的设置中探索此类工作，允许在数据演变时高效扩展图。实验结果表明，与现有的其他少样本持续关系提取（FCRE）基线相比，我们的方法性能更优，并且在该设置中高效处理动态图构建。', 'title_zh': '少量样本持续关系提取 via 开放信息提取'}
{'arxiv_id': 'arXiv:2502.16638', 'title': 'Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression', 'authors': 'Xiaoyi Qu, David Aponte, Colby Banbury, Daniel P. Robinson, Tianyu Ding, Kazuhito Koishida, Ilya Zharkov, Tianyi Chen', 'link': 'https://arxiv.org/abs/2502.16638', 'abstract': 'Structured pruning and quantization are fundamental techniques used to reduce the size of deep neural networks (DNNs) and typically are applied independently. Applying these techniques jointly via co-optimization has the potential to produce smaller, high-quality models. However, existing joint schemes are not widely used because of (1) engineering difficulties (complicated multi-stage processes), (2) black-box optimization (extensive hyperparameter tuning to control the overall compression), and (3) insufficient architecture generalization. To address these limitations, we present the framework GETA, which automatically and efficiently performs joint structured pruning and quantization-aware training on any DNNs. GETA introduces three key innovations: (i) a quantization-aware dependency graph (QADG) that constructs a pruning search space for generic quantization-aware DNN, (ii) a partially projected stochastic gradient method that guarantees layerwise bit constraints are satisfied, and (iii) a new joint learning strategy that incorporates interpretable relationships between pruning and quantization. We present numerical experiments on both convolutional neural networks and transformer architectures that show that our approach achieves competitive (often superior) performance compared to existing joint pruning and quantization methods.', 'abstract_zh': 'GETA：自动高效进行联合结构剪枝和量化训练的框架', 'title_zh': '自动联合结构剪裁与量化以实现高效神经网络训练与压缩'}
{'arxiv_id': 'arXiv:2502.16637', 'title': 'Time Series Domain Adaptation via Latent Invariant Causal Mechanism', 'authors': 'Ruichu Cai, Junxian Huang, Zhenhui Yang, Zijian Li, Emadeldeen Eldele, Min Wu, Fuchun Sun', 'link': 'https://arxiv.org/abs/2502.16637', 'abstract': 'Time series domain adaptation aims to transfer the complex temporal dependence from the labeled source domain to the unlabeled target domain. Recent advances leverage the stable causal mechanism over observed variables to model the domain-invariant temporal dependence. However, modeling precise causal structures in high-dimensional data, such as videos, remains challenging. Additionally, direct causal edges may not exist among observed variables (e.g., pixels). These limitations hinder the applicability of existing approaches to real-world scenarios. To address these challenges, we find that the high-dimension time series data are generated from the low-dimension latent variables, which motivates us to model the causal mechanisms of the temporal latent process. Based on this intuition, we propose a latent causal mechanism identification framework that guarantees the uniqueness of the reconstructed latent causal structures. Specifically, we first identify latent variables by utilizing sufficient changes in historical information. Moreover, by enforcing the sparsity of the relationships of latent variables, we can achieve identifiable latent causal structures. Built on the theoretical results, we develop the Latent Causality Alignment (LCA) model that leverages variational inference, which incorporates an intra-domain latent sparsity constraint for latent structure reconstruction and an inter-domain latent sparsity constraint for domain-invariant structure reconstruction. Experiment results on eight benchmarks show a general improvement in the domain-adaptive time series classification and forecasting tasks, highlighting the effectiveness of our method in real-world scenarios. Codes are available at this https URL.', 'abstract_zh': '时间序列领域适应旨在将标记的源域的复杂时间依赖性转移到未标记的目标域。近期进展利用观察变量上的稳定因果机制来建模域不变的时间依赖性。然而，在高维数据（如视频）中精确建模因果结构仍然具有挑战性。此外，观察变量之间可能存在直接的因果边（例如，像素之间）。这些局限性限制了现有方法在实际场景中的应用。为应对这些挑战，我们发现高维时间序列数据是由低维潜在变量生成的，这促使我们建模潜在时间过程中的因果机制。基于这一直觉，我们提出了一种保证重构的潜在因果结构唯一性的潜在因果机制识别框架。具体来说，我们首先通过利用历史信息中的足够变化来识别潜在变量。通过限制潜在变量间关系的稀疏性，我们能实现可识别的潜在因果结构。基于理论结果，我们开发了潜在因果对齐（LCA）模型，该模型利用变分推理，结合域内潜在稀疏约束进行潜在结构重建和跨域潜在稀疏约束进行域不变结构重建。在八个基准上的实验结果显示，该方法在领域适应的时间序列分类和预测任务中普遍提高，突显了其在实际场景中的有效性。代码可在此处获取。', 'title_zh': '时间序列领域适应通过潜在不变因果机制'}
{'arxiv_id': 'arXiv:2502.16627', 'title': 'Energy-Efficient Transformer Inference: Optimization Strategies for Time Series Classification', 'authors': 'Arshia Kermani, Ehsan Zeraatkar, Habib Irani', 'link': 'https://arxiv.org/abs/2502.16627', 'abstract': 'The increasing computational demands of transformer models in time series classification necessitate effective optimization strategies for energy-efficient deployment. This paper presents a systematic investigation of optimization techniques, focusing on structured pruning and quantization methods for transformer architectures. Through extensive experimentation on three distinct datasets (RefrigerationDevices, ElectricDevices, and PLAID), we quantitatively evaluate model performance and energy efficiency across different transformer configurations. Our experimental results demonstrate that static quantization reduces energy consumption by 29.14% while maintaining classification performance, and L1 pruning achieves a 1.63% improvement in inference speed with minimal accuracy degradation. These findings provide valuable insights into the effectiveness of optimization strategies for transformer-based time series classification, establishing a foundation for efficient model deployment in resource-constrained environments.', 'abstract_zh': 'Transformer模型在时间序列分类中的不断增加的计算需求 necessitates 有效的优化策略以实现能效部署。本文系统研究了优化技术，重点关注 Transformer 架构的结构剪枝和量化方法。通过对三个不同的数据集（RefrigerationDevices、ElectricDevices 和 PLAID）进行广泛的实验，我们定量评估了不同 Transformer 配置下的模型性能和能效。实验结果显示，静态量化可将能效消耗降低 29.14% 同时保持分类性能，而 L1 剪枝则将推理速度提高 1.63% 并且几乎没有准确率下降。这些发现为基于 Transformer 的时间序列分类的优化策略的有效性提供了有价值的见解，为资源受限环境下的高效模型部署奠定了基础。', 'title_zh': '高效的变压器推理：时间序列分类的优化策略'}
{'arxiv_id': 'arXiv:2502.16613', 'title': 'Intelligent Tutors Beyond K-12: An Observational Study of Adult Learner Engagement and Academic Impact', 'authors': 'Adit Gupta, Christopher MacLellan', 'link': 'https://arxiv.org/abs/2502.16613', 'abstract': 'Intelligent tutors have proven to be effective in K-12 education, though their impact on adult learners -- especially as a supplementary resource -- remains underexplored. Understanding how adults voluntarily engage with educational technologies can inform the design of tools that support skill re-learning and enhancement. More critically, it helps determine whether tutoring systems, which are typically built for K-12 learners, can also support adult populations. This study examines the adoption, usage patterns, and effectiveness of a novel tutoring system, Apprentice Tutors, among adult learners at a state technical college. We analyze three types of data including, user demographics, grades, and tutor interactions, to assess whether voluntary tutor usage translates into measurable learning gains. Our findings reveal key temporal patterns in tutor engagement and provide evidence of learning within tutors, as determined through skill improvement in knowledge components across tutors. We also found evidence that this learning transferred outside the tutor, as observed through higher course assessment scores following tutor usage. These results suggest that intelligent tutors are a viable tool for adult learners, warranting further research into their long-term impact on this population.', 'abstract_zh': '智能辅导系统在K-12教育中已被证明有效，尽管它们作为补充资源对成人学习者的影响仍然未被充分探索。了解成人自愿使用教育技术的方法可以为支持技能重学和提升的设计提供信息。更为关键的是，这有助于确定通常为K-12学生设计的教学系统是否也能支持成人学习者群体。本研究 examine 成人技术学院学生采用、使用模式和新型辅导系统 Apprentice Tutors 的有效性。我们分析用户 demographics、成绩和辅导互动三种数据，以评估自愿使用辅导系统的衡量学习成效。我们的发现揭示了辅导参与的关键时间模式，并通过辅导者知识组件技能提高证实了学习的发生。此外，我们还发现这种学习转移至辅导之外，通过使用者课程评估分数提高得以观察。这些结果表明，智能辅导系统是成人学习者的可行工具，值得进一步研究其对该群体的长期影响。', 'title_zh': '智能导师超越K-12教育：成人学习者参与度及其学术影响的观察研究'}
{'arxiv_id': 'arXiv:2502.16611', 'title': 'Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments', 'authors': 'Shitong Xu, Yiyuan Yang, Niki Trigoni, Andrew Markham', 'link': 'https://arxiv.org/abs/2502.16611', 'abstract': "Target speaker extraction focuses on isolating a specific speaker's voice from an audio mixture containing multiple speakers. To provide information about the target speaker's identity, prior works have utilized clean audio examples as conditioning inputs. However, such clean audio examples are not always readily available (e.g. It is impractical to obtain a clean audio example of a stranger's voice at a cocktail party without stepping away from the noisy environment). Limited prior research has explored extracting the target speaker's characteristics from noisy audio examples, which may include overlapping speech from disturbing speakers. In this work, we focus on target speaker extraction when multiple speakers are present during the enrollment stage, through leveraging differences between audio segments where the target speakers are speaking (Positive Enrollments) and segments where they are not (Negative Enrollments). Experiments show the effectiveness of our model architecture and the dedicated pretraining method for the proposed task. Our method achieves state-of-the-art performance in the proposed application settings and demonstrates strong generalizability across challenging and realistic scenarios.", 'abstract_zh': '多说话人环境下目标说话人提取专注于从包含多个说话人的音频混合中分离出特定说话人的声音。以往的工作利用干净的音频示例作为条件输入以提供目标说话人身份的相关信息，然而在嘈杂环境中获得陌生人的干净音频示例往往是不现实的。少数早期研究探索了从包含干扰说话人重叠语音的嘈杂音频示例中提取目标说话人特征的可能性。本文在注册阶段存在多个说话人的情况下，通过利用目标说话人发言（正注册）和不发言（负注册）的音频片段之间的差异，专注于目标说话人提取。实验表明，我们提出的模型架构和专门的预训练方法对于目标说话人提取任务非常有效，我们的方法在所提出的应用场景中达到了最先进的性能，并在具有挑战性和现实性的场景中展示了强大的泛化能力。', 'title_zh': '通过比较噪声正样本和噪声负样本进行目标说话人提取'}
{'arxiv_id': 'arXiv:2502.16570', 'title': 'Entropy-Lens: The Information Signature of Transformer Computations', 'authors': 'Riccardo Ali, Francesco Caso, Christopher Irwin, Pietro Liò', 'link': 'https://arxiv.org/abs/2502.16570', 'abstract': 'Transformer models have revolutionized fields from natural language processing to computer vision, yet their internal computational dynamics remain poorly understood raising concerns about predictability and robustness. In this work, we introduce Entropy-Lens, a scalable, model-agnostic framework that leverages information theory to interpret frozen, off-the-shelf large-scale transformers. By quantifying the evolution of Shannon entropy within intermediate residual streams, our approach extracts computational signatures that distinguish model families, categorize task-specific prompts, and correlate with output accuracy. We further demonstrate the generality of our method by extending the analysis to vision transformers. Our results suggest that entropy-based metrics can serve as a principled tool for unveiling the inner workings of modern transformer architectures.', 'abstract_zh': '基于熵的解析框架揭示大规模预训练变压器内部计算动力学', 'title_zh': '熵镜：Transformer 计算的信息特征'}
{'arxiv_id': 'arXiv:2502.16533', 'title': 'A Survey of Graph Transformers: Architectures, Theories and Applications', 'authors': 'Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong', 'link': 'https://arxiv.org/abs/2502.16533', 'abstract': 'Graph Transformers (GTs) have demonstrated a strong capability in modeling graph structures by addressing the intrinsic limitations of graph neural networks (GNNs), such as over-smoothing and over-squashing. Recent studies have proposed diverse architectures, enhanced explainability, and practical applications for Graph Transformers. In light of these rapid developments, we conduct a comprehensive review of Graph Transformers, covering aspects such as their architectures, theoretical foundations, and applications within this survey. We categorize the architecture of Graph Transformers according to their strategies for processing structural information, including graph tokenization, positional encoding, structure-aware attention and model ensemble. Furthermore, from the theoretical perspective, we examine the expressivity of Graph Transformers in various discussed architectures and contrast them with other advanced graph learning algorithms to discover the connections. Furthermore, we provide a summary of the practical applications where Graph Transformers have been utilized, such as molecule, protein, language, vision traffic, brain and material data. At the end of this survey, we will discuss the current challenges and prospective directions in Graph Transformers for potential future research.', 'abstract_zh': 'Graph Transformers (GTs)在解决图神经网络（GNNs）固有局限性（如过平滑和过压缩）以建模图结构方面展现了强大的能力。近年来，研究提出了一种多样的架构、增强了可解释性并探讨了实际应用。鉴于这些快速发展，我们对Graph Transformers进行了全面综述，覆盖了其架构、理论基础及其在各种应用中的应用。我们根据处理结构信息的策略对Graph Transformers的架构进行了分类，包括图标记化、位置编码、结构感知注意力和模型集成。此外，从理论角度，我们分析了各种架构中Graph Transformers的表达能力，并与其他高级图学习算法进行了对比，以发现它们之间的联系。我们还总结了Graph Transformers在分子、蛋白质、语言、视觉、交通、大脑和材料数据等方面的实际应用情况。最后，我们讨论了Graph Transformers当前面临的挑战及其未来的潜在研究方向。', 'title_zh': '图变换器综述：架构、理论与应用'}
{'arxiv_id': 'arXiv:2502.16523', 'title': 'Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension', 'authors': 'Yulong Wu, Viktor Schlegel, Riza Batista-Navarro', 'link': 'https://arxiv.org/abs/2502.16523', 'abstract': 'As neural language models achieve human-comparable performance on Machine Reading Comprehension (MRC) and see widespread adoption, ensuring their robustness in real-world scenarios has become increasingly important. Current robustness evaluation research, though, primarily develops synthetic perturbation methods, leaving unclear how well they reflect real life scenarios. Considering this, we present a framework to automatically examine MRC models on naturally occurring textual perturbations, by replacing paragraph in MRC benchmarks with their counterparts based on available Wikipedia edit history. Such perturbation type is natural as its design does not stem from an arteficial generative process, inherently distinct from the previously investigated synthetic approaches. In a large-scale study encompassing SQUAD datasets and various model architectures we observe that natural perturbations result in performance degradation in pre-trained encoder language models. More worryingly, these state-of-the-art Flan-T5 and Large Language Models (LLMs) inherit these errors. Further experiments demonstrate that our findings generalise to natural perturbations found in other more challenging MRC benchmarks. In an effort to mitigate these errors, we show that it is possible to improve the robustness to natural perturbations by training on naturally or synthetically perturbed examples, though a noticeable gap still remains compared to performance on unperturbed data.', 'abstract_zh': '神经语言模型在机器阅读理解中的鲁棒性评估：基于自然文本 perturbations 的框架研究', 'title_zh': '关注现实世界的扰动！机器阅读理解中的自然鲁棒性评估'}
{'arxiv_id': 'arXiv:2502.16520', 'title': 'Predicting Bad Goods Risk Scores with ARIMA Time Series: A Novel Risk Assessment Approach', 'authors': 'Bishwajit Prasad Gond', 'link': 'https://arxiv.org/abs/2502.16520', 'abstract': 'The increasing complexity of supply chains and the rising costs associated with defective or substandard goods (bad goods) highlight the urgent need for advanced predictive methodologies to mitigate risks and enhance operational efficiency. This research presents a novel framework that integrates Time Series ARIMA (AutoRegressive Integrated Moving Average) models with a proprietary formula specifically designed to calculate bad goods after time series forecasting. By leveraging historical data patterns, including sales, returns, and capacity, the model forecasts potential quality failures, enabling proactive decision-making. ARIMA is employed to capture temporal trends in time series data, while the newly developed formula quantifies the likelihood and impact of defects with greater precision. Experimental results, validated on a dataset spanning 2022-2024 for Organic Beer-G 1 Liter, demonstrate that the proposed method outperforms traditional statistical models, such as Exponential Smoothing and Holt-Winters, in both prediction accuracy and risk evaluation. This study advances the field of predictive analytics by bridging time series forecasting, ARIMA, and risk management in supply chain quality control, offering a scalable and practical solution for minimizing losses due to bad goods.', 'abstract_zh': '供应链复杂性的增加和不良或次标准商品（不良商品）相关成本的上升凸显了急需先进的预测方法以减轻风险和提高运营效率的紧迫性。本研究提出了一种新颖的框架，该框架将时间序列ARIMA模型与专门设计用于时间序列预测后计算不良商品的专利公式相结合。通过利用销售、退货和生产能力等历史数据模式，该模型预测潜在的质量故障，从而实现主动决策。ARIMA用于捕捉时间序列数据中的时间趋势，而新开发的公式则以更高的精确度量化缺陷的可能性和影响。实验结果，基于2022-2024年有机啤酒-G 1升的数据集验证，表明所提出的方法在预测准确性和风险评估方面优于传统的统计模型，如指数平滑和霍尔特-温特模型。本研究通过将时间序列预测、ARIMA和供应链质量控制中的风险管理相结合，推动了预测分析领域的进步，并提供了一种可扩展且实用的解决方案，以减少由于不良商品造成的损失。', 'title_zh': '基于ARIMA时间序列的不良商品风险评分预测：一种新型风险评估方法'}
{'arxiv_id': 'arXiv:2502.16510', 'title': 'Gaussian Process Regression for Improved Underwater Navigation', 'authors': 'Nadav Cohen, Itzik Klein', 'link': 'https://arxiv.org/abs/2502.16510', 'abstract': 'Accurate underwater navigation is a challenging task due to the absence of global navigation satellite system signals and the reliance on inertial navigation systems that suffer from drift over time. Doppler velocity logs (DVLs) are typically used to mitigate this drift through velocity measurements, which are commonly estimated using a parameter estimation approach such as least squares (LS). However, LS works under the assumption of ideal conditions and does not account for sensor biases, leading to suboptimal performance. This paper proposes a data-driven alternative based on multi-output Gaussian process regression (MOGPR) to improve DVL velocity estimation. MOGPR provides velocity estimates and associated measurement covariances, enabling an adaptive integration within an error-state Extended Kalman Filter (EKF). We evaluate our proposed approach using real-world AUV data and compare it against LS and a state-of-the-art deep learning model, BeamsNet. Results demonstrate that MOGPR reduces velocity estimation errors by approximately 20% while simultaneously enhancing overall navigation accuracy, particularly in the orientation states. Additionally, the incorporation of uncertainty estimates from MOGPR enables an adaptive EKF framework, improving navigation robustness in dynamic underwater environments.', 'abstract_zh': '基于多输出高斯过程回归的声纳速度日志 veloc 度估计方法', 'title_zh': '高斯过程回归在水下导航中的应用'}
{'arxiv_id': 'arXiv:2502.16503', 'title': 'FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis', 'authors': 'Yilun Zheng, Sha Li, Fangkun Wu, Yang Ziyi, Lin Hongchao, Zhichao Hu, Cai Xinjun, Ziming Wang, Jinxuan Chen, Sitao Luan, Jiahao Xu, Lihui Chen', 'link': 'https://arxiv.org/abs/2502.16503', 'abstract': 'Parody is an emerging phenomenon on social media, where individuals imitate a role or position opposite to their own, often for humor, provocation, or controversy. Detecting and analyzing parody can be challenging and is often reliant on context, yet it plays a crucial role in understanding cultural values, promoting subcultures, and enhancing self-expression. However, the study of parody is hindered by limited available data and deficient diversity in current datasets. To bridge this gap, we built seven parody datasets from both English and Chinese corpora, with 14,755 annotated users and 21,210 annotated comments in total. To provide sufficient context information, we also collect replies and construct user-interaction graphs to provide richer contextual information, which is lacking in existing datasets. With these datasets, we test traditional methods and Large Language Models (LLMs) on three key tasks: (1) parody detection, (2) comment sentiment analysis with parody, and (3) user sentiment analysis with parody. Our extensive experiments reveal that parody-related tasks still remain challenging for all models, and contextual information plays a critical role. Interestingly, we find that, in certain scenarios, traditional sentence embedding methods combined with simple classifiers can outperform advanced LLMs, i.e. DeepSeek-R1 and GPT-o3, highlighting parody as a significant challenge for LLMs.', 'abstract_zh': '社交媒体中的 parody 是一个新兴现象，个体通过模仿与其自身相反的角色或身份，常用于幽默、挑衅或引起争议。检测和分析 parody 挑战重重，但在理解文化价值观、促进亚文化发展和增强自我表达方面起着关键作用。然而， parody 研究受限于可用数据量有限以及当前数据集中缺乏多样性。为弥补这一差距，我们从英汉语料中构建了七个 parody 数据集，共计包括 14,755 个标注用户和 21,210 个标注评论。为提供足够的上下文信息，我们还收集了回复并构建了用户交互图，以提供更多上下文信息，而现有数据集中缺乏这些信息。依托这些数据集，我们对传统方法和大规模语言模型（LLMs）进行了三个关键任务的测试：（1）parody 检测，（2）包含 parody 的评论情感分析，（3）包含 parody 的用户情感分析。大量实验表明，所有模型在 parody 相关任务中依然面临挑战，而上下文信息起着关键作用。有趣的是，我们在某些场景中发现，简单的传统句子嵌入方法与简单分类器的结合甚至可以优于先进的 LLMs（如 DeepSeek-R1 和 GPT-o3），这突显了 parody 对 LLMs 的重大挑战。', 'title_zh': 'FanChuan：一种用于parody检测与分析的多语言图结构基准数据集'}
{'arxiv_id': 'arXiv:2502.16496', 'title': 'PMAT: Optimizing Action Generation Order in Multi-Agent Reinforcement Learning', 'authors': 'Kun Hu, Muning Wen, Xihuai Wang, Shao Zhang, Yiwei Shi, Minne Li, Minglong Li, Ying Wen', 'link': 'https://arxiv.org/abs/2502.16496', 'abstract': "Multi-agent reinforcement learning (MARL) faces challenges in coordinating agents due to complex interdependencies within multi-agent systems. Most MARL algorithms use the simultaneous decision-making paradigm but ignore the action-level dependencies among agents, which reduces coordination efficiency. In contrast, the sequential decision-making paradigm provides finer-grained supervision for agent decision order, presenting the potential for handling dependencies via better decision order management. However, determining the optimal decision order remains a challenge. In this paper, we introduce Action Generation with Plackett-Luce Sampling (AGPS), a novel mechanism for agent decision order optimization. We model the order determination task as a Plackett-Luce sampling process to address issues such as ranking instability and vanishing gradient during the network training process. AGPS realizes credit-based decision order determination by establishing a bridge between the significance of agents' local observations and their decision credits, thus facilitating order optimization and dependency management. Integrating AGPS with the Multi-Agent Transformer, we propose the Prioritized Multi-Agent Transformer (PMAT), a sequential decision-making MARL algorithm with decision order optimization. Experiments on benchmarks including StarCraft II Multi-Agent Challenge, Google Research Football, and Multi-Agent MuJoCo show that PMAT outperforms state-of-the-art algorithms, greatly enhancing coordination efficiency.", 'abstract_zh': '基于Plackett-Luce采样的智能体决策顺序优化机制及优先级多智能体变换器', 'title_zh': 'PMAT：多智能体 reinforcement learning 中优化动作生成顺序'}
{'arxiv_id': 'arXiv:2502.16483', 'title': 'A Split-Window Transformer for Multi-Model Sequence Spammer Detection using Multi-Model Variational Autoencoder', 'authors': 'Zhou Yang, Yucai Pang, Hongbo Yin, Yunpeng Xiao', 'link': 'https://arxiv.org/abs/2502.16483', 'abstract': "This paper introduces a new Transformer, called MS$^2$Dformer, that can be used as a generalized backbone for multi-modal sequence spammer detection. Spammer detection is a complex multi-modal task, thus the challenges of applying Transformer are two-fold. Firstly, complex multi-modal noisy information about users can interfere with feature mining. Secondly, the long sequence of users' historical behaviors also puts a huge GPU memory pressure on the attention computation. To solve these problems, we first design a user behavior Tokenization algorithm based on the multi-modal variational autoencoder (MVAE). Subsequently, a hierarchical split-window multi-head attention (SW/W-MHA) mechanism is proposed. The split-window strategy transforms the ultra-long sequences hierarchically into a combination of intra-window short-term and inter-window overall attention. Pre-trained on the public datasets, MS$^2$Dformer's performance far exceeds the previous state of the art. The experiments demonstrate MS$^2$Dformer's ability to act as a backbone.", 'abstract_zh': '基于MVAE的用户行为Tokenization和分窗口多头注意机制的MS$^2$Dformer在多模态序列发帖者检测中的应用', 'title_zh': '基于多模型变分自编码器的多模型序列垃圾信息发布检测分窗口变压器'}
{'arxiv_id': 'arXiv:2502.16477', 'title': 'Unmasking Societal Biases in Respiratory Support for ICU Patients through Social Determinants of Health', 'authors': 'Mira Moukheiber, Lama Moukheiber, Dana Moukheiber, Hyung-Chul Lee', 'link': 'https://arxiv.org/abs/2502.16477', 'abstract': "In critical care settings, where precise and timely interventions are crucial for health outcomes, evaluating disparities in patient outcomes is essential. Current approaches often fail to fully capture the impact of respiratory support interventions on individuals affected by social determinants of health. While attributes such as gender, race, and age are commonly assessed and provide valuable insights, they offer only a partial view of the complexities faced by diverse populations. In this study, we focus on two clinically motivated tasks: prolonged mechanical ventilation and successful weaning. Additionally, we conduct fairness audits on the models' predictions across demographic groups and social determinants of health to better understand health inequities in respiratory interventions within the intensive care unit. Furthermore, we release a temporal benchmark dataset, verified by clinical experts, to facilitate benchmarking of clinical respiratory intervention tasks.", 'abstract_zh': '在重症护理环境中，精确及时的干预对于健康结果至关重要，评估患者结果的差异性尤为关键。当前的方法往往未能充分捕捉社会决定因素对呼吸支持干预个体的影响。虽然性别、种族和年龄等属性通常会被评估并提供有价值的见解，但它们仅提供了多元群体所面临复杂性的部分视角。在本研究中，我们专注于两个临床驱动的任务：长时间机械通气和成功脱机。此外，我们还在不同人口统计群体和社会决定因素方面对模型的预测进行公平性审计，以更好地理解重症监护病房内呼吸干预措施中的健康不平等。此外，我们发布了一个由临床专家验证的时间基准数据集，以促进临床呼吸支持干预任务的基准测试。', 'title_zh': '通过社会决定因素揭露重症监护患者呼吸支持中的社会偏见'}
{'arxiv_id': 'arXiv:2502.16446', 'title': 'Auxiliary Discrminator Sequence Generative Adversarial Networks (ADSeqGAN) for Few Sample Molecule Generation', 'authors': 'Haocheng Tang, Jing Long, Junmei Wang', 'link': 'https://arxiv.org/abs/2502.16446', 'abstract': 'In this work, we introduce Auxiliary Discriminator Sequence Generative Adversarial Networks (ADSeqGAN), a novel approach for molecular generation in small-sample datasets. Traditional generative models often struggle with limited training data, particularly in drug discovery, where molecular datasets for specific therapeutic targets, such as nucleic acids binders and central nervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by integrating an auxiliary random forest classifier as an additional discriminator into the GAN framework, significantly improves molecular generation quality and class specificity.\nOur method incorporates pretrained generator and Wasserstein distance to enhance training stability and diversity. We evaluate ADSeqGAN on a dataset comprising nucleic acid-targeting and protein-targeting small molecules, demonstrating its superior ability to generate nucleic acid binders compared to baseline models such as SeqGAN, ORGAN, and MolGPT. Through an oversampling strategy, ADSeqGAN also significantly improves CNS drug generation, achieving a higher yield than traditional de novo models. Critical assessments, including docking simulations and molecular property analysis, confirm that ADSeqGAN-generated molecules exhibit strong binding affinities, enhanced chemical diversity, and improved synthetic feasibility.\nOverall, ADSeqGAN presents a novel framework for generative molecular design in data-scarce scenarios, offering potential applications in computational drug discovery. We have demonstrated the successful applications of ADSeqGAN in generating synthetic nucleic acid-targeting and CNS drugs in this work.', 'abstract_zh': '辅助鉴别序列生成对抗网络（ADSeqGAN）在小样本数据集中的分子生成方法', 'title_zh': '辅助鉴别器序列生成对抗网络（ADSeqGAN）用于少量样本分子生成'}
{'arxiv_id': 'arXiv:2502.16411', 'title': 'Tool or Tutor? Experimental evidence from AI deployment in cancer diagnosis', 'authors': 'Vivianna Fang He, Sihan Li, Phanish Puranam', 'link': 'https://arxiv.org/abs/2502.16411', 'abstract': "Professionals increasingly use Artificial Intelligence (AI) to enhance their capabilities and assist with task execution. While prior research has examined these uses separately, their potential interaction remains underexplored. We propose that AI-driven training (tutor effect) and AI-assisted task completion (tool effect) can be complementary and test this hypothesis in the context of lung cancer diagnosis. In a field experiment with 334 medical students, we manipulated AI deployment in training, in practice, and in both. Our findings reveal that while AI-integrated training and AI assistance independently improved diagnostic performance, their combination yielded the highest accuracy. These results underscore AI's dual role in enhancing human performance through both learning and real-time support, offering insights into AI deployment in professional settings where human expertise remains essential.", 'abstract_zh': '专业人士 increasingly 使用人工智能 (AI) 来提升其能力并协助任务执行。尽管以往的研究分别探讨了这些应用，但它们的潜在交互仍有待探索。我们提出，由AI驱动的培训（导师效应）和AI辅助的任务完成（工具效应）可以互补，并在肺癌诊断的背景下测试这一假设。在涉及334名医学学生的现场实验中，我们操纵了在培训、实践以及两者中的AI部署。我们的研究发现，虽然AI集成培训和AI辅助分别提高了诊断性能，但它们的结合使用实现了最高的准确性。这些结果强调了AI在通过学习和实时支持提升人类表现中的双重作用，为在仍需人类专长的专业环境中部署AI提供了见解。', 'title_zh': '工具还是导师？来自癌症诊断中AI部署的实验证据'}
{'arxiv_id': 'arXiv:2502.16406', 'title': 'TrustChain: A Blockchain Framework for Auditing and Verifying Aggregators in Decentralized Federated Learning', 'authors': 'Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif', 'link': 'https://arxiv.org/abs/2502.16406', 'abstract': 'The server-less nature of Decentralized Federated Learning (DFL) requires allocating the aggregation role to specific participants in each federated round. Current DFL architectures ensure the trustworthiness of the aggregator node upon selection. However, most of these studies overlook the possibility that the aggregating node may turn rogue and act maliciously after being nominated. To address this problem, this paper proposes a DFL structure, called TrustChain, that scores the aggregators before selection based on their past behavior and additionally audits them after the aggregation. To do this, the statistical independence between the client updates and the aggregated model is continuously monitored using the Hilbert-Schmidt Independence Criterion (HSIC). The proposed method relies on several principles, including blockchain, anomaly detection, and concept drift analysis. The designed structure is evaluated on several federated datasets and attack scenarios with different numbers of Byzantine nodes.', 'abstract_zh': '去中心化联邦学习（DFL）的无服务器性质要求在每个联邦轮次中分配聚合角色给特定参与者。当前的DFL架构确保在选择聚合节点时其可信度。然而，大多数研究忽视了被提名后聚合节点可能会变成恶意节点的可能性。为解决这一问题，本文提出了一种称为TrustChain的DFL结构，在选择聚合节点时根据其以往行为评分，并在聚合后对其进行审核。为此，通过使用希尔伯特-施密特独立性判据（HSIC）持续监控客户端更新与聚合模型之间的统计独立性。所提出的方法基于区块链、异常检测和概念漂移分析等多个原则。所设计的结构在包含不同数量拜占庭节点的各种联邦数据集和攻击场景下进行了评估。', 'title_zh': '信任链：一种用于分布式联邦学习中审计和验证聚合器的区块链框架'}
{'arxiv_id': 'arXiv:2502.16396', 'title': 'FedNIA: Noise-Induced Activation Analysis for Mitigating Data Poisoning in FL', 'authors': 'Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif', 'link': 'https://arxiv.org/abs/2502.16396', 'abstract': 'Federated learning systems are increasingly threatened by data poisoning attacks, where malicious clients compromise global models by contributing tampered updates. Existing defenses often rely on impractical assumptions, such as access to a central test dataset, or fail to generalize across diverse attack types, particularly those involving multiple malicious clients working collaboratively. To address this, we propose Federated Noise-Induced Activation Analysis (FedNIA), a novel defense framework to identify and exclude adversarial clients without relying on any central test dataset. FedNIA injects random noise inputs to analyze the layerwise activation patterns in client models leveraging an autoencoder that detects abnormal behaviors indicative of data poisoning. FedNIA can defend against diverse attack types, including sample poisoning, label flipping, and backdoors, even in scenarios with multiple attacking nodes. Experimental results on non-iid federated datasets demonstrate its effectiveness and robustness, underscoring its potential as a foundational approach for enhancing the security of federated learning systems.', 'abstract_zh': '联邦学习系统受到数据中毒攻击的威胁不断增加，其中恶意客户端通过提交篡改的更新来损害全局模型。现有防御往往依赖于不切实际的假设，例如访问中央测试数据集，或者在面对多样化的攻击类型，尤其是涉及多个恶意客户端协同工作的攻击时无法泛化。为了解决这个问题，我们提出了一种名为FedNIA（Federated Noise-Induced Activation Analysis）的新型防御框架，能够在无需依赖任何中央测试数据集的情况下识别和排除恶意客户端。FedNIA通过注入随机噪声输入并利用自动编码器分析客户端模型中的逐层激活模式，检测指示数据中毒的异常行为来防范多种攻击类型，包括样本中毒、标签翻转和后门攻击。实验结果在非i.i.d.联邦学习数据集上显示了其有效性和鲁棒性，强调了其作为增强联邦学习系统安全性的基础方法的潜力。', 'title_zh': 'FedNIA：噪声诱发激活分析用于缓解联邦学习中的数据投毒问题'}
{'arxiv_id': 'arXiv:2502.16380', 'title': 'Understanding Fixed Predictions via Confined Regions', 'authors': 'Connor Lawless, Tsui-Wei Weng, Berk Ustun, Madeleine Udell', 'link': 'https://arxiv.org/abs/2502.16380', 'abstract': 'Machine learning models are designed to predict outcomes using features about an individual, but fail to take into account how individuals can change them. Consequently, models can assign fixed predictions that deny individuals recourse to change their outcome. This work develops a new paradigm to identify fixed predictions by finding confined regions in which all individuals receive fixed predictions. We introduce the first method, ReVer, for this task, using tools from mixed-integer quadratically constrained programming. Our approach certifies recourse for out-of-sample data, provides interpretable descriptions of confined regions, and runs in seconds on real world datasets. We conduct a comprehensive empirical study of confined regions across diverse applications. Our results highlight that existing point-wise verification methods fail to discover confined regions, while ReVer provably succeeds.', 'abstract_zh': '机器学习模型设计用于根据个体特征预测结果，但未能考虑个体如何改变这些特征。因此，模型可能会分配固定不变的预测，阻止个体改变其结果。本工作开发了一种新范式，通过识别所有个体都收到固定预测的限定区域来识别固定预测。我们提出了第一个用于此任务的方法ReVer，并使用混合整数二次约束编程工具。我们的方法可以为未见过的数据提供救济保障，提供限定区域的可解释描述，并在实际数据集上以秒级速度运行。我们在多种应用中进行了全面的实证研究。研究结果表明，现有点wise验证方法无法发现限定区域，而ReVer可以证明成功。', 'title_zh': '通过限制区域理解固定预测'}
{'arxiv_id': 'arXiv:2502.16378', 'title': 'Auto-ADMET: An Effective and Interpretable AutoML Method for Chemical ADMET Property Prediction', 'authors': 'Alex G. C. de Sá, David B. Ascher', 'link': 'https://arxiv.org/abs/2502.16378', 'abstract': "Machine learning (ML) has been playing important roles in drug discovery in the past years by providing (pre-)screening tools for prioritising chemical compounds to pass through wet lab experiments. One of the main ML tasks in drug discovery is to build quantitative structure-activity relationship (QSAR) models, associating the molecular structure of chemical compounds with an activity or property. These properties -- including absorption, distribution, metabolism, excretion and toxicity (ADMET) -- are essential to model compound behaviour, activity and interactions in the organism. Although several methods exist, the majority of them do not provide an appropriate model's personalisation, yielding to bias and lack of generalisation to new data since the chemical space usually shifts from application to application. This fact leads to low predictive performance when completely new data is being tested by the model. The area of Automated Machine Learning (AutoML) emerged aiming to solve this issue, outputting tailored ML algorithms to the data at hand. Although an important task, AutoML has not been practically used to assist cheminformatics and computational chemistry researchers often, with just a few works related to the field. To address these challenges, this work introduces Auto-ADMET, an interpretable evolutionary-based AutoML method for chemical ADMET property prediction. Auto-ADMET employs a Grammar-based Genetic Programming (GGP) method with a Bayesian Network Model to achieve comparable or better predictive performance against three alternative methods -- standard GGP method, pkCSM and XGBOOST model -- on 12 benchmark chemical ADMET property prediction datasets. The use of a Bayesian Network model on Auto-ADMET's evolutionary process assisted in both shaping the search procedure and interpreting the causes of its AutoML performance.", 'abstract_zh': '自动机器学习（AutoML）在化学ADMET性质预测中的可解释演化方法：Auto-ADMET', 'title_zh': 'Auto-ADMET：一种高效可解释的化学ADMET性质预测自动化机器学习方法'}
{'arxiv_id': 'arXiv:2502.16375', 'title': 'Personhood Credentials: Human-Centered Design Recommendation Balancing Security, Usability, and Trust', 'authors': 'Ayae Ide, Tanusree Sharma', 'link': 'https://arxiv.org/abs/2502.16375', 'abstract': 'Building on related concepts, like, decentralized identifiers (DIDs), proof of personhood, anonymous credentials, personhood credentials (PHCs) emerged as an alternative approach, enabling individuals to verify to digital service providers that they are a person without disclosing additional information. However, new technologies might introduce some friction due to users misunderstandings and mismatched expectations. Despite their growing importance, limited research has been done on users perceptions and preferences regarding PHCs. To address this gap, we conducted competitive analysis, and semi-structured online user interviews with 23 participants from US and EU to provide concrete design recommendations for PHCs that incorporate user needs, adoption rules, and preferences. Our study -- (a)surfaces how people reason about unknown privacy and security guarantees of PHCs compared to current verification methods -- (b) presents the impact of several factors on how people would like to onboard and manage PHCs, including, trusted issuers (e.g. gov), ground truth data to issue PHC (e.g biometrics, physical id), and issuance system (e.g. centralized vs decentralized). In a think-aloud conceptual design session, participants recommended -- conceptualized design, such as periodic biometrics verification, time-bound credentials, visually interactive human-check, and supervision of government for issuance system. We propose actionable designs reflecting users preferences.', 'abstract_zh': '基于分散标识符（DIDs）、人证证明、匿名凭证等相关概念，个人凭证（PHCs）作为一种替代方案 emerga，使个人能够向数字服务提供商验证自己的身份而不披露额外信息。然而，新技术might引入一些摩擦，由于用户误解和期望不匹配。尽管PHCs的重要性日益增加，关于用户对PHCs的认知和偏好方面的研究有限。为填平这一缺口，我们进行了竞争性分析，并对来自美国和欧盟的23名参与者进行了半结构化在线用户访谈，以提出结合用户需求、采用规则和偏好的具体设计建议。我们的研究——(a)揭示了人们如何推理PHCs与现有验证方法相比的未知隐私和安全保证——(b)展示了多个因素如何影响人们希望上线和管理PHCs的方式，包括可信发行方（如政府）、用于发行PHC的真实数据（如生物特征、物理ID）以及发行系统（如集中式 versus 分布式）。在现声思考概念设计会中，参与者建议了概念设计，如定期生物特征验证、时限凭证、视觉互动的人工验证和发行系统的政府监督。我们提出了反映用户偏好的可操作性设计。', 'title_zh': '人性认证：平衡安全、可用性和信任的人本设计推荐'}
{'arxiv_id': 'arXiv:2502.16331', 'title': 'A Gap Between the Gaussian RKHS and Neural Networks: An Infinite-Center Asymptotic Analysis', 'authors': 'Akash Kumar, Rahul Parhi, Mikhail Belkin', 'link': 'https://arxiv.org/abs/2502.16331', 'abstract': 'Recent works have characterized the function-space inductive bias of infinite-width bounded-norm single-hidden-layer neural networks as a kind of bounded-variation-type space. This novel neural network Banach space encompasses many classical multivariate function spaces including certain Sobolev spaces and the spectral Barron spaces. Notably, this Banach space also includes functions that exhibit less classical regularity such as those that only vary in a few directions. On bounded domains, it is well-established that the Gaussian reproducing kernel Hilbert space (RKHS) strictly embeds into this Banach space, demonstrating a clear gap between the Gaussian RKHS and the neural network Banach space. It turns out that when investigating these spaces on unbounded domains, e.g., all of $\\mathbb{R}^d$, the story is fundamentally different. We establish the following fundamental result: Certain functions that lie in the Gaussian RKHS have infinite norm in the neural network Banach space. This provides a nontrivial gap between kernel methods and neural networks by the exhibition of functions in which kernel methods can do strictly better than neural networks.', 'abstract_zh': '近期研究将无限宽有界范数单隐藏层神经网络的功能空间归纳偏置characterized为一类有界变差型空间。这种新型神经网络Banach空间包括了许多经典的多元函数空间，如某些Sobolev空间和谱Barron空间。值得注意的是，这种Banach空间还包含了只有在少数方向上才表现出非经典正则性的函数。在有界域上，Gaussian再生核希尔伯特空间（RKHS）严格嵌入到这种Banach空间中，表明Gaussian RKHS与神经网络Banach空间之间存在明显的差距。有趣的是，在探讨这些空间在未加界域上的情况，例如$\\mathbb{R}^d$时，情况变得根本不同。我们得到了以下基本结果：某些位于Gaussian RKHS中的函数在神经网络Banach空间中的范数无限大。这通过展示一类函数，在这些函数上核方法比神经网络可以更优，提供了一个非平凡的差距。', 'title_zh': '高斯RKHS与神经网络之间的一个差距：无穷中心渐近分析'}
{'arxiv_id': 'arXiv:2502.16324', 'title': 'Deep Time Warping for Multiple Time Series Alignment', 'authors': 'Alireza Nourbakhsh, Hoda Mohammadzade', 'link': 'https://arxiv.org/abs/2502.16324', 'abstract': 'Time Series Alignment is a critical task in signal processing with numerous real-world applications. In practice, signals often exhibit temporal shifts and scaling, making classification on raw data prone to errors. This paper introduces a novel approach for Multiple Time Series Alignment (MTSA) leveraging Deep Learning techniques. While most existing methods primarily address Multiple Sequence Alignment (MSA) for protein and DNA sequences, there remains a significant gap in alignment methodologies for numerical time series. Additionally, conventional approaches typically focus on pairwise alignment, whereas our proposed method aligns all signals in a multiple manner (all the signals are aligned together at once). This innovation not only enhances alignment efficiency but also significantly improves computational speed. By decomposing into piece-wise linear sections, we introduce varying levels of complexity into the warping function. Additionally, our method ensures the satisfaction of three warping constraints: boundary, monotonicity, and continuity conditions. The utilization of a deep convolutional network allows us to employ a new loss function, addressing some limitations of Dynamic Time Warping (DTW). Experimental results on the UCR Archive 2018, comprising 129 time series datasets, demonstrate that employing our approach to align signals significantly enhances classification accuracy and warping average and also reduces the run time across the majority of these datasets.', 'abstract_zh': '时间序列对齐是信号处理中的一个关键任务，具有众多实际应用。本文提出了一种利用深度学习技术进行多时间序列对齐（MTSA）的新方法。尽管大多数现有方法主要针对蛋白质和DNA序列的多重序列对齐（MSA），但对于数值时间序列仍缺乏有效的对齐方法。此外，传统方法通常侧重于两两对齐，而我们提出的方法则以多对齐的方式同时对齐所有信号。这一创新不仅提高了对齐效率，还显著提高了计算速度。通过将对齐函数分解为分段线性部分，我们引入了不同程度的复杂性。此外，我们的方法确保对齐函数满足边界、单调性和连续性条件。使用深度卷积网络允许我们采用新的损失函数，解决了一些动态时间对齐（DTW）的局限性。实验结果表明，使用我们的方法对齐信号可以显著提高分类准确率和对齐平均质量，并在大多数数据集中减少运行时间。', 'title_zh': '深度时间扭曲用于多重时间序列对齐'}
{'arxiv_id': 'arXiv:2502.16312', 'title': 'Iterative Auto-Annotation for Scientific Named Entity Recognition Using BERT-Based Models', 'authors': 'Kartik Gupta', 'link': 'https://arxiv.org/abs/2502.16312', 'abstract': 'This paper presents an iterative approach to performing Scientific Named Entity Recognition (SciNER) using BERT-based models. We leverage transfer learning to fine-tune pretrained models with a small but high-quality set of manually annotated data. The process is iteratively refined by using the fine-tuned model to auto-annotate a larger dataset, followed by additional rounds of fine-tuning. We evaluated two models, dslim/bert-large-NER and bert-largecased, and found that bert-large-cased consistently outperformed the former. Our approach demonstrated significant improvements in prediction accuracy and F1 scores, especially for less common entity classes. Future work could include pertaining with unlabeled data, exploring more powerful encoders like RoBERTa, and expanding the scope of manual annotations. This methodology has broader applications in NLP tasks where access to labeled data is limited.', 'abstract_zh': '本文提出了一种迭代的方法，使用基于BERT的模型进行科学命名实体识别（SciNER）。我们通过利用迁移学习，使用少量但高质量的手工标注数据对预训练模型进行微调。通过使用微调后的模型自动标注更大规模的数据集，并进行额外的微调，不断优化这一过程。我们评估了两种模型（dslim/bert-large-NER 和 bert-large-cased），发现 bert-large-cased 在预测准确性方面始终优于前者。我们的方法在预测准确性和F1分数方面取得了显著改进，尤其是在处理较不常见的实体类别时。未来的工作可以包括处理未标注数据、探索更强大的编码器如RoBERTa以及扩展手动标注的范围。该方法在标注数据有限的NLP任务中具有更广泛的应用前景。', 'title_zh': '基于BERT模型的迭代自动标注的科学命名实体识别'}
{'arxiv_id': 'arXiv:2502.16299', 'title': 'A calibration test for evaluating set-based epistemic uncertainty representations', 'authors': 'Mira Jürgens, Thomas Mortier, Eyke Hüllermeier, Viktor Bengs, Willem Waegeman', 'link': 'https://arxiv.org/abs/2502.16299', 'abstract': "The accurate representation of epistemic uncertainty is a challenging yet essential task in machine learning. A widely used representation corresponds to convex sets of probabilistic predictors, also known as credal sets. One popular way of constructing these credal sets is via ensembling or specialized supervised learning methods, where the epistemic uncertainty can be quantified through measures such as the set size or the disagreement among members. In principle, these sets should contain the true data-generating distribution. As a necessary condition for this validity, we adopt the strongest notion of calibration as a proxy. Concretely, we propose a novel statistical test to determine whether there is a convex combination of the set's predictions that is calibrated in distribution. In contrast to previous methods, our framework allows the convex combination to be instance dependent, recognizing that different ensemble members may be better calibrated in different regions of the input space. Moreover, we learn this combination via proper scoring rules, which inherently optimize for calibration. Building on differentiable, kernel-based estimators of calibration errors, we introduce a nonparametric testing procedure and demonstrate the benefits of capturing instance-level variability on of synthetic and real-world experiments.", 'abstract_zh': '准确表示epistemic不确定性是机器学习中一项挑战性但至关重要的任务。一种常用的表示方式对应于概率预测的凸集，也称为信念集。这些信念集的一种常见构建方式是通过集成或专用于监督学习的方法，其中可以通过集合大小或成员之间的分歧等度量来量化epistemic不确定性。原则上，这些集合应包含真实的数据生成分布。作为这种有效性的一个必要条件，我们采用最强的校准概念作为代理。具体地，我们提出了一种新的统计检验，用于确定集合预测是否存在凸组合使其在分布上校准。与其他方法相比，我们的框架允许凸组合依赖于实例，认识到不同集成成员在输入空间的不同区域可能校准更好。此外，我们通过适当的评分规则学习这一组合，这些规则自然地优化了校准。基于可微的核基校准误差估计器，我们引入了一种非参数检验方法，并在合成和真实世界实验中展示了捕捉实例级变异性的优势。', 'title_zh': '基于集的epistemic不确定性表示的校准测试'}
{'arxiv_id': 'arXiv:2502.16294', 'title': 'TimePFN: Effective Multivariate Time Series Forecasting with Synthetic Data', 'authors': 'Ege Onur Taga, M. Emrullah Ildiz, Samet Oymak', 'link': 'https://arxiv.org/abs/2502.16294', 'abstract': 'The diversity of time series applications and scarcity of domain-specific data highlight the need for time-series models with strong few-shot learning capabilities. In this work, we propose a novel training scheme and a transformer-based architecture, collectively referred to as TimePFN, for multivariate time-series (MTS) forecasting. TimePFN is based on the concept of Prior-data Fitted Networks (PFN), which aims to approximate Bayesian inference. Our approach consists of (1) generating synthetic MTS data through diverse Gaussian process kernels and the linear coregionalization method, and (2) a novel MTS architecture capable of utilizing both temporal and cross-channel dependencies across all input patches. We evaluate TimePFN on several benchmark datasets and demonstrate that it outperforms the existing state-of-the-art models for MTS forecasting in both zero-shot and few-shot settings. Notably, fine-tuning TimePFN with as few as 500 data points nearly matches full dataset training error, and even 50 data points yield competitive results. We also find that TimePFN exhibits strong univariate forecasting performance, attesting to its generalization ability. Overall, this work unlocks the power of synthetic data priors for MTS forecasting and facilitates strong zero- and few-shot forecasting performance.', 'abstract_zh': '时间序列应用的多样性和领域特定数据的稀缺性突显了强少样本学习能力的时间序列模型的需求。本研究提出了一种新型训练方案和基于变压器的架构，统称为TimePFN，用于多变量时间序列（MTS）预测。TimePFN基于先验数据拟合网络（PFN）的概念，旨在近似贝叶斯推理。我们的方法包括（1）通过多样化的高斯过程核和线性协区域化方法生成合成MTS数据，以及（2）一种新型的MTS架构，能够利用所有输入片段中的时空和跨通道依赖性。我们在多个基准数据集上评估了TimePFN，并展示了它在零样本和少样本设置中均优于现有最先进的MTS预测模型。值得注意的是，使用仅500个数据点微调TimePFN几乎可以匹配全数据集训练误差，甚至使用50个数据点也能获得竞争力的结果。我们还发现，TimePFN在单变量预测中表现出强大的性能，证明了其泛化能力。总体而言，本文解锁了合成数据先验在MTS预测中的力量，并促进了出色的零样本和少样本预测性能。', 'title_zh': '时间合成法：有效的多变量时间序列预测'}
{'arxiv_id': 'arXiv:2502.16291', 'title': 'The Design Space of Recent AI-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity', 'authors': 'Runlong Ye, Matthew Varona, Oliver Huang, Patrick Yung Kang Lee, Michael Liut, Carolina Nobre', 'link': 'https://arxiv.org/abs/2502.16291', 'abstract': "Generative AI (GenAI) tools are radically expanding the scope and capability of automation in knowledge work such as academic research. AI-assisted research tools show promise for augmenting human cognition and streamlining research processes, but could potentially increase automation bias and stifle critical thinking. We surveyed the past three years of publications from leading HCI venues. We closely examined 11 AI-assisted research tools, five employing traditional AI approaches and six integrating GenAI, to explore how these systems envision novel capabilities and design spaces. We consolidate four design recommendations that inform cognitive engagement when working with an AI research tool: Providing user agency and control; enabling divergent and convergent thinking; supporting adaptability and flexibility; and ensuring transparency and accuracy. We discuss how these ideas mark a shift in AI-assisted research tools from mimicking a researcher's established workflows to generative co-creation with the researcher and the opportunities this shift affords the research community.", 'abstract_zh': '生成式AI工具正在不断扩大知识工作中，如学术研究的自动化范围和能力。AI辅助的研究工具有望增强人类的认知并简化研究流程，但也可能增加自动化偏见并抑制批判性思维。我们调研了过去三年内领先的人机交互会议的发表论文。我们详细研究了11款AI辅助的研究工具，其中5款采用传统AI方法，6款结合生成式AI，以探索这些系统所设想的新能力和设计空间。我们整合了四条设计建议，以指导在使用AI研究工具时的认知参与：提供用户自主权和控制；促进发散和收敛思维；支持适应性和灵活性；并确保透明度和准确性。我们讨论了这些想法如何标志着AI辅助研究工具从模仿研究人员已有的工作流程向与研究人员的生成式协同创作的转变，并探讨了这一转变为研究社区带来的机会。', 'title_zh': 'Recent AI-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity的设计空间探究'}
{'arxiv_id': 'arXiv:2502.16286', 'title': 'Verification of Bit-Flip Attacks against Quantized Neural Networks', 'authors': 'Yedi Zhang, Lei Huang, Pengfei Gao, Fu Song, Jun Sun, Jin Song Dong', 'link': 'https://arxiv.org/abs/2502.16286', 'abstract': 'In the rapidly evolving landscape of neural network security, the resilience of neural networks against bit-flip attacks (i.e., an attacker maliciously flips an extremely small amount of bits within its parameter storage memory system to induce harmful behavior), has emerged as a relevant area of research. Existing studies suggest that quantization may serve as a viable defense against such attacks. Recognizing the documented susceptibility of real-valued neural networks to such attacks and the comparative robustness of quantized neural networks (QNNs), in this work, we introduce BFAVerifier, the first verification framework designed to formally verify the absence of bit-flip attacks or to identify all vulnerable parameters in a sound and rigorous manner. BFAVerifier comprises two integral components: an abstraction-based method and an MILP-based method. Specifically, we first conduct a reachability analysis with respect to symbolic parameters that represent the potential bit-flip attacks, based on a novel abstract domain with a sound guarantee. If the reachability analysis fails to prove the resilience of such attacks, then we encode this verification problem into an equivalent MILP problem which can be solved by off-the-shelf solvers. Therefore, BFAVerifier is sound, complete, and reasonably efficient. We conduct extensive experiments, which demonstrate its effectiveness and efficiency across various network architectures, quantization bit-widths, and adversary capabilities.', 'abstract_zh': '神经网络安全快速演变的背景下，神经网络抵御位翻转攻击的鲁棒性研究：BFAVerifier——首个形式化验证框架', 'title_zh': '针对量ized神经网络的位翻转攻击验证'}
{'arxiv_id': 'arXiv:2502.16284', 'title': 'MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra', 'authors': 'Liang Wang, Shaozhen Liu, Yu Rong, Deli Zhao, Qiang Liu, Shu Wu, Liang Wang', 'link': 'https://arxiv.org/abs/2502.16284', 'abstract': "Establishing the relationship between 3D structures and the energy states of molecular systems has proven to be a promising approach for learning 3D molecular representations. However, existing methods are limited to modeling the molecular energy states from classical mechanics. This limitation results in a significant oversight of quantum mechanical effects, such as quantized (discrete) energy level structures, which offer a more accurate estimation of molecular energy and can be experimentally measured through energy spectra. In this paper, we propose to utilize the energy spectra to enhance the pre-training of 3D molecular representations (MolSpectra), thereby infusing the knowledge of quantum mechanics into the molecular representations. Specifically, we propose SpecFormer, a multi-spectrum encoder for encoding molecular spectra via masked patch reconstruction. By further aligning outputs from the 3D encoder and spectrum encoder using a contrastive objective, we enhance the 3D encoder's understanding of molecules. Evaluations on public benchmarks reveal that our pre-trained representations surpass existing methods in predicting molecular properties and modeling dynamics.", 'abstract_zh': '利用能量谱增强三维分子表示的预训练：结合量子力学知识', 'title_zh': 'MolSpectra: 基于多模态能量光谱预训练3D分子表示'}
{'arxiv_id': 'arXiv:2502.16255', 'title': 'rECGnition_v2.0: Self-Attentive Canonical Fusion of ECG and Patient Data using deep learning for effective Cardiac Diagnostics', 'authors': 'Shreya Srivastava, Durgesh Kumar, Ram Jiwari, Sandeep Seth, Deepak Sharma', 'link': 'https://arxiv.org/abs/2502.16255', 'abstract': 'The variability in ECG readings influenced by individual patient characteristics has posed a considerable challenge to adopting automated ECG analysis in clinical settings. A novel feature fusion technique termed SACC (Self Attentive Canonical Correlation) was proposed to address this. This technique is combined with DPN (Dual Pathway Network) and depth-wise separable convolution to create a robust, interpretable, and fast end-to-end arrhythmia classification model named rECGnition_v2.0 (robust ECG abnormality detection). This study uses MIT-BIH, INCARTDB and EDB dataset to evaluate the efficiency of rECGnition_v2.0 for various classes of arrhythmias. To investigate the influence of constituting model components, various ablation studies were performed, i.e. simple concatenation, CCA and proposed SACC were compared, while the importance of global and local ECG features were tested using DPN rECGnition_v2.0 model and vice versa. It was also benchmarked with state-of-the-art CNN models for overall accuracy vs model parameters, FLOPs, memory requirements, and prediction time. Furthermore, the inner working of the model was interpreted by comparing the activation locations in ECG before and after the SACC layer. rECGnition_v2.0 showed a remarkable accuracy of 98.07% and an F1-score of 98.05% for classifying ten distinct classes of arrhythmia with just 82.7M FLOPs per sample, thereby going beyond the performance metrics of current state-of-the-art (SOTA) models by utilizing MIT-BIH Arrhythmia dataset. Similarly, on INCARTDB and EDB datasets, excellent F1-scores of 98.01% and 96.21% respectively was achieved for AAMI classification. The compact architectural footprint of the rECGnition_v2.0, characterized by its lesser trainable parameters and diminished computational demands, unfurled several advantages including interpretability and scalability.', 'abstract_zh': 'ECG读数因个体患者特征差异造成的变异性对临床环境中采用自动ECG分析构成了重大挑战：SACC (自我注意相关性分析) 方法及其在rECGnition_v2.0中的应用', 'title_zh': 'rECGnition_v2.0：基于深度学习的心电图与患者数据自注意力经典融合及其在心脏诊断中的有效应用'}
{'arxiv_id': 'arXiv:2502.16249', 'title': 'Linear Attention for Efficient Bidirectional Sequence Modeling', 'authors': 'Arshia Afzal, Elias Abad Rocamora, Leyla Naz Candogan, Pol Puigdemont, Francesco Tonin, Yongtao Wu, Mahsa Shoaran, Volkan Cevher', 'link': 'https://arxiv.org/abs/2502.16249', 'abstract': 'Transformers with linear attention enable fast and parallel training. Moreover, they can be formulated as Recurrent Neural Networks (RNNs), for efficient linear-time inference. While extensively evaluated in causal sequence modeling, they have yet to be extended to the bidirectional setting. This work introduces the LION framework, establishing new theoretical foundations for linear transformers in bidirectional sequence modeling. LION constructs a bidirectional RNN equivalent to full Linear Attention. This extends the benefits of linear transformers: parallel training, and efficient inference, into the bidirectional setting. Using LION, we cast three linear transformers to their bidirectional form: LION-LIT, the bidirectional variant corresponding to (Katharopoulos et al., 2020); LION-D, extending RetNet (Sun et al., 2023); and LION-S, a linear transformer with a stable selective mask inspired by selectivity of SSMs (Dao & Gu, 2024). Replacing the attention block with LION (-LIT, -D, -S) achieves performance on bidirectional tasks that approaches that of Transformers and State-Space Models (SSMs), while delivering significant improvements in training speed. Our implementation is available in this http URL.', 'abstract_zh': '线性注意力变压器与双向序列建模：LION框架的研究', 'title_zh': '高效双向序列建模中的线性注意力'}
{'arxiv_id': 'arXiv:2502.16240', 'title': 'Speech Enhancement Using Continuous Embeddings of Neural Audio Codec', 'authors': 'Haoyang Li, Jia Qi Yip, Tianyu Fan, Eng Siong Chng', 'link': 'https://arxiv.org/abs/2502.16240', 'abstract': 'Recent advancements in Neural Audio Codec (NAC) models have inspired their use in various speech processing tasks, including speech enhancement (SE). In this work, we propose a novel, efficient SE approach by leveraging the pre-quantization output of a pretrained NAC encoder. Unlike prior NAC-based SE methods, which process discrete speech tokens using Language Models (LMs), we perform SE within the continuous embedding space of the pretrained NAC, which is highly compressed along the time dimension for efficient representation. Our lightweight SE model, optimized through an embedding-level loss, delivers results comparable to SE baselines trained on larger datasets, with a significantly lower real-time factor of 0.005. Additionally, our method achieves a low GMAC of 3.94, reducing complexity 18-fold compared to Sepformer in a simulated cloud-based audio transmission environment. This work highlights a new, efficient NAC-based SE solution, particularly suitable for cloud applications where NAC is used to compress audio before transmission.\nCopyright 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.', 'abstract_zh': 'Recent advancements in Neural Audio Codec (NAC) models have inspired their use in various speech processing tasks, including speech enhancement (SE). In this work, we propose a novel, efficient SE approach by leveraging the pre-quantization output of a pretrained NAC encoder. Unlike prior NAC-based SE methods, which process discrete speech tokens using Language Models (LMs), we perform SE within the continuous embedding space of the pretrained NAC, which is highly compressed along the time dimension for efficient representation. Our lightweight SE model, optimized through an embedding-level loss, delivers results comparable to SE baselines trained on larger datasets, with a significantly lower real-time factor of 0.005. Additionally, our method achieves a low GMAC of 3.94, reducing complexity 18-fold compared to Sepformer in a simulated cloud-based audio transmission environment. This work highlights a new, efficient NAC-based SE solution, particularly suitable for cloud applications where NAC is used to compress audio before transmission.', 'title_zh': '神经音频编解码器连续嵌入的语音增强'}
{'arxiv_id': 'arXiv:2502.16233', 'title': 'Graph Self-Supervised Learning with Learnable Structural and Positional Encodings', 'authors': 'Asiri Wijesinghe, Hao Zhu, Piotr Koniusz', 'link': 'https://arxiv.org/abs/2502.16233', 'abstract': "Traditional Graph Self-Supervised Learning (GSSL) struggles to capture complex structural properties well. This limitation stems from two main factors: (1) the inadequacy of conventional Graph Neural Networks (GNNs) in representing sophisticated topological features, and (2) the focus of self-supervised learning solely on final graph representations. To address these issues, we introduce \\emph{GenHopNet}, a GNN framework that integrates a $k$-hop message-passing scheme, enhancing its ability to capture local structural information without explicit substructure extraction. We theoretically demonstrate that \\emph{GenHopNet} surpasses the expressiveness of the classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore, we propose a structural- and positional-aware GSSL framework that incorporates topological information throughout the learning process. This approach enables the learning of representations that are both sensitive to graph topology and invariant to specific structural and feature augmentations. Comprehensive experiments on graph classification datasets, including those designed to test structural sensitivity, show that our method consistently outperforms the existing approaches and maintains computational efficiency. Our work significantly advances GSSL's capability in distinguishing graphs with similar local structures but different global topologies.", 'abstract_zh': '传统图自监督学习（GSSL）难以很好地捕捉复杂的结构特性。这一局限性源自两个主要因素：（1）传统图神经网络（GNNs）在表示复杂的拓扑特征方面的不足，以及（2）自监督学习专注于最终图表示。为了解决这些问题，我们提出了\\emph{GenHopNet}，这是一种结合了$k$-hop消息传递方案的GNN框架，增强了其捕捉局部结构信息的能力，而无需显式的子结构提取。我们理论证明\\emph{GenHopNet}超越了经典的Weisfeiler-Lehman（WL）图同构测试的表达能力。此外，我们提出了一种兼顾结构和位置感知的自监督学习框架，整个学习过程中均融入了拓扑信息。该方法能够学习既对图拓扑敏感又对特定结构和特征增强保持不变的表示。我们对包括用于测试结构敏感性的图分类数据集进行全面实验，结果显示，我们的方法在所有方面均优于现有方法，并保持了计算效率。我们的工作显著提升了GSSL在区分具有相似局部结构但全局拓扑不同的图方面的能力。', 'title_zh': '带有可学习结构和位置编码的图自监督学习'}
{'arxiv_id': 'arXiv:2502.16181', 'title': 'BiDeV: Bilateral Defusing Verification for Complex Claim Fact-Checking', 'authors': 'Yuxuan Liu, Hongda Sun, Wenya Guo, Xinyan Xiao, Cunli Mao, Zhengtao Yu, Rui Yan', 'link': 'https://arxiv.org/abs/2502.16181', 'abstract': 'Complex claim fact-checking performs a crucial role in disinformation detection. However, existing fact-checking methods struggle with claim vagueness, specifically in effectively handling latent information and complex relations within claims. Moreover, evidence redundancy, where nonessential information complicates the verification process, remains a significant issue. To tackle these limitations, we propose Bilateral Defusing Verification (BiDeV), a novel fact-checking working-flow framework integrating multiple role-played LLMs to mimic the human-expert fact-checking process. BiDeV consists of two main modules: Vagueness Defusing identifies latent information and resolves complex relations to simplify the claim, and Redundancy Defusing eliminates redundant content to enhance the evidence quality. Extensive experimental results on two widely used challenging fact-checking benchmarks (Hover and Feverous-s) demonstrate that our BiDeV can achieve the best performance under both gold and open settings. This highlights the effectiveness of BiDeV in handling complex claims and ensuring precise fact-checking', 'abstract_zh': '复杂声明事实核查在虚假信息检测中发挥着关键作用。然而，现有的事实核查方法在处理声明的模糊性、特别是潜在信息和声明中复杂关系的有效处理方面存在困难。此外，证据冗余问题，即不必要的信息使验证过程复杂化，也是一个重大问题。为解决这些问题，我们提出了双边消解验证（BiDeV）框架，该框架结合了多个角色扮演的LLM，以模拟人类专家的事实核查过程。BiDeV主要包括两个主要模块：模糊性消解识别潜在信息并解决复杂关系以简化声明，冗余消解消除冗余内容以提高证据质量。在两个广泛使用的挑战性事实核查基准（Hover和Feverous-s）上的 extensive 实验结果表明，我们的 BiDeV 在金标准和开放环境下都能取得最佳性能，这突显了 BiDeV 在处理复杂声明和确保精确事实核查方面的有效性。', 'title_zh': 'BiDeV: 双边解爆验证复杂声明事实核查'}
{'arxiv_id': 'arXiv:2502.16176', 'title': 'An End-to-End Homomorphically Encrypted Neural Network', 'authors': 'Marcos Florencio, Luiz Alencar, Bianca Lima', 'link': 'https://arxiv.org/abs/2502.16176', 'abstract': 'Every commercially available, state-of-the-art neural network consume plain input data, which is a well-known privacy concern. We propose a new architecture based on homomorphic encryption, which allows the neural network to operate on encrypted data. We show that Homomorphic Neural Networks (HNN) can achieve full privacy and security while maintaining levels of accuracy comparable to plain neural networks. We also introduce a new layer, the Differentiable Soft-Argmax, which allows the calibration of output logits in the encrypted domain, raising the entropy of the activation parameters, thus improving the security of the model, while keeping the overall noise below the acceptable noise budget. Experiments were conducted using the Stanford Sentiment Treebank (SST-2) corpora on the DistilBERT base uncased finetuned SST-2 English sentiment analysis model, and the results show that the HNN model can achieve up to 82.5% of the accuracy of the plain model while maintaining full privacy and security.', 'abstract_zh': '基于同态加密的全同态神经网络：实现隐私保护与高准确性', 'title_zh': '端到端同态加密神经网络'}
{'arxiv_id': 'arXiv:2502.16170', 'title': 'Destroy and Repair Using Hyper Graphs for Routing', 'authors': 'Ke Li, Fei Liu, Zhengkun Wang, Qingfu Zhang', 'link': 'https://arxiv.org/abs/2502.16170', 'abstract': 'Recent advancements in Neural Combinatorial Optimization (NCO) have shown promise in solving routing problems like the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) without handcrafted designs. Research in this domain has explored two primary categories of methods: iterative and non-iterative. While non-iterative methods struggle to generate near-optimal solutions directly, iterative methods simplify the task by learning local search steps. However, existing iterative methods are often limited by restricted neighborhood searches, leading to suboptimal results. To address this limitation, we propose a novel approach that extends the search to larger neighborhoods by learning a destroy-and-repair strategy. Specifically, we introduce a Destroy-and-Repair framework based on Hyper-Graphs (DRHG). This framework reduces consecutive intact edges to hyper-edges, allowing the model to pay more attention to the destroyed part and decrease the complexity of encoding all nodes. Experiments demonstrate that DRHG achieves stateof-the-art performance on TSP with up to 10,000 nodes and shows strong generalization to real-world TSPLib and CVRPLib problems.', 'abstract_zh': '最近神经组合优化（NCO）在解决旅行商问题（TSP）和带容量约束的车辆路径问题（CVRP）等路径问题方面取得了进展，无需手工设计。该领域的研究探索了两类主要方法：迭代和非迭代方法。虽然非迭代方法难以直接生成近最优解，但迭代方法通过学习局部搜索步骤简化了任务。然而，现有的迭代方法通常受限于局部搜索范围的限制，导致次优结果。为解决这一局限，我们提出了一种新的方法，通过学习破坏-修复策略将搜索范围扩展到更大的邻域。具体而言，我们基于超图引入了一种破坏-修复框架（DRHG）。该框架将连续未受损边简化为超边，从而使模型更加关注受损部分，并降低编码所有节点的复杂性。实验结果表明，DRHG在包含高达10,000个节点的TSP上达到最佳性能，并且在实际的TSPLib和CVRPLib问题上表现出强大的泛化能力。', 'title_zh': '使用超图进行路由的破坏与修复'}
{'arxiv_id': 'arXiv:2502.16128', 'title': 'Heterogeneous Multi-Agent Bandits with Parsimonious Hints', 'authors': 'Amirmahdi Mirfakhar, Xuchuang Wang, Jinhang Zuo, Yair Zick, Mohammad Hajiesmaili', 'link': 'https://arxiv.org/abs/2502.16128', 'abstract': 'We study a hinted heterogeneous multi-agent multi-armed bandits problem (HMA2B), where agents can query low-cost observations (hints) in addition to pulling arms. In this framework, each of the $M$ agents has a unique reward distribution over $K$ arms, and in $T$ rounds, they can observe the reward of the arm they pull only if no other agent pulls that arm. The goal is to maximize the total utility by querying the minimal necessary hints without pulling arms, achieving time-independent regret. We study HMA2B in both centralized and decentralized setups. Our main centralized algorithm, GP-HCLA, which is an extension of HCLA, uses a central decision-maker for arm-pulling and hint queries, achieving $O(M^4K)$ regret with $O(MK\\log T)$ adaptive hints. In decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that allow agents to choose actions independently through collision-based communication and query hints uniformly until stopping, yielding $O(M^3K^2)$ regret with $O(M^3K\\log T)$ hints, where the former requires knowledge of the minimum gap and the latter does not. Finally, we establish lower bounds to prove the optimality of our results and verify them through numerical simulations.', 'abstract_zh': '我们研究了一个提示异构多智能体多臂 bandits 问题 (HMA2B)，其中智能体不仅可以拉臂，还可以查询低成本观察（提示）。在该框架中，每个M个智能体在T轮中各自有一套独特的奖励分布，并且只有在没有其他智能体拉动同一臂的情况下才能观察到所拉动臂的奖励。目标是通过最小必要的提示查询来最大化总效用，实现与时间无关的后悔。我们在集中式和分布式设置下研究了HMA2B问题。我们主要的集中式算法GP-HCLA是HCLA的扩展，采用中央决策者来执行拉臂和提示查询，其后悔为$O(M^4K)$，具有$O(MK\\log T)$自适应提示。在分布式设置中，我们提出了两个算法HD-ETC和EBHD-ETC，允许智能体通过碰撞式通信独立选择动作并均匀查询提示直到停止，其后悔为$O(M^3K^2)$，具有$O(M^3K\\log T)$的提示，前者需要知道最小差距，后者不需要。最后，我们建立了下界来证明我们结果的最优性，并通过数值仿真进行了验证。', 'title_zh': '稀疏提示下的异构多智能体 bandits 问题'}
{'arxiv_id': 'arXiv:2502.16105', 'title': 'NeurFlow: Interpreting Neural Networks through Neuron Groups and Functional Interactions', 'authors': 'Tue M. Cao, Nhat X. Hoang, Hieu H. Pham, Phi Le Nguyen, My T. Thai', 'link': 'https://arxiv.org/abs/2502.16105', 'abstract': "Understanding the inner workings of neural networks is essential for enhancing model performance and interpretability. Current research predominantly focuses on examining the connection between individual neurons and the model's final predictions. Which suffers from challenges in interpreting the internal workings of the model, particularly when neurons encode multiple unrelated features. In this paper, we propose a novel framework that transitions the focus from analyzing individual neurons to investigating groups of neurons, shifting the emphasis from neuron-output relationships to functional interaction between neurons. Our automated framework, NeurFlow, first identifies core neurons and clusters them into groups based on shared functional relationships, enabling a more coherent and interpretable view of the network's internal processes. This approach facilitates the construction of a hierarchical circuit representing neuron interactions across layers, thus improving interpretability while reducing computational costs. Our extensive empirical studies validate the fidelity of our proposed NeurFlow. Additionally, we showcase its utility in practical applications such as image debugging and automatic concept labeling, thereby highlighting its potential to advance the field of neural network explainability.", 'abstract_zh': '理解神经网络的内在工作机制对于提升模型性能和可解释性至关重要。当前研究主要关注个体神经元与模型最终预测之间的关系，这在解释模型内部工作机制时面临挑战，尤其是在神经元编码多个无关特征的情况下。本文提出一种新颖框架，将焦点从分析个体神经元转移到研究神经元群体，从关注神经元-输出关系转向关注神经元间的功能交互。我们的自动化框架NeurFlow首先识别关键神经元并基于共享的功能关系将它们聚类，从而提供更连贯和可解释的网络内部过程视图。该方法促进了跨层神经元交互的分层电路构建，从而提高可解释性并降低计算成本。我们广泛的经验研究表明，NeurFlow 提出的框架具有较高的准确性。此外，我们展示了其在图像调试和自动概念标签等实际应用中的应用价值，进而凸显了其在神经网络可解释性领域的发展潜力。', 'title_zh': 'NeurFlow: 通过神经元组和功能交互解释神经网络'}
{'arxiv_id': 'arXiv:2502.16091', 'title': 'Privacy-Aware Joint DNN Model Deployment and Partition Optimization for Delay-Efficient Collaborative Edge Inference', 'authors': 'Zhipeng Cheng, Xiaoyu Xia, Hong Wang, Minghui Liwang, Ning Chen, Xuwei Fan, Xianbin Wang', 'link': 'https://arxiv.org/abs/2502.16091', 'abstract': 'Edge inference (EI) is a key solution to address the growing challenges of delayed response times, limited scalability, and privacy concerns in cloud-based Deep Neural Network (DNN) inference. However, deploying DNN models on resource-constrained edge devices faces more severe challenges, such as model storage limitations, dynamic service requests, and privacy risks. This paper proposes a novel framework for privacy-aware joint DNN model deployment and partition optimization to minimize long-term average inference delay under resource and privacy constraints. Specifically, the problem is formulated as a complex optimization problem considering model deployment, user-server association, and model partition strategies. To handle the NP-hardness and future uncertainties, a Lyapunov-based approach is introduced to transform the long-term optimization into a single-time-slot problem, ensuring system performance. Additionally, a coalition formation game model is proposed for edge server association, and a greedy-based algorithm is developed for model deployment within each coalition to efficiently solve the problem. Extensive simulations show that the proposed algorithms effectively reduce inference delay while satisfying privacy constraints, outperforming baseline approaches in various scenarios.', 'abstract_zh': '面向隐私保护的联合DNN模型部署与划分优化框架以最小化资源和隐私约束下的长期平均推理延迟', 'title_zh': '隐私 Awareness 联合 DNN 模型部署与分区优化以实现延迟高效的协同边缘推理'}
{'arxiv_id': 'arXiv:2502.16065', 'title': 'A Survey of Model Extraction Attacks and Defenses in Distributed Computing Environments', 'authors': 'Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, Yushun Dong', 'link': 'https://arxiv.org/abs/2502.16065', 'abstract': 'Model Extraction Attacks (MEAs) threaten modern machine learning systems by enabling adversaries to steal models, exposing intellectual property and training data. With the increasing deployment of machine learning models in distributed computing environments, including cloud, edge, and federated learning settings, each paradigm introduces distinct vulnerabilities and challenges. Without a unified perspective on MEAs across these distributed environments, organizations risk fragmented defenses, inadequate risk assessments, and substantial economic and privacy losses. This survey is motivated by the urgent need to understand how the unique characteristics of cloud, edge, and federated deployments shape attack vectors and defense requirements. We systematically examine the evolution of attack methodologies and defense mechanisms across these environments, demonstrating how environmental factors influence security strategies in critical sectors such as autonomous vehicles, healthcare, and financial services. By synthesizing recent advances in MEAs research and discussing the limitations of current evaluation practices, this survey provides essential insights for developing robust and adaptive defense strategies. Our comprehensive approach highlights the importance of integrating protective measures across the entire distributed computing landscape to ensure the secure deployment of machine learning models.', 'abstract_zh': 'Model Extraction Attacks (MEAs)威胁现代机器学习系统，使对手能够窃取模型，披露知识产权和训练数据。随着机器学习模型在分布式计算环境中的日益部署，包括云、边缘和联邦学习设置，每个范式都带来了独特的脆弱性和挑战。如果没有对这些分布式环境中的MEAs有统一的认识，组织可能会面临分散的防御、不充分的风险评估以及显著的经济损失和隐私损失。本综述旨在应对理解和分析云、边缘和联邦部署的独特特性如何塑造攻击向量和防御需求的紧迫需求。我们系统性地审视了这些环境中攻击方法和防御机制的发展演变，展示了环境因素如何影响自主车辆、医疗保健和金融服务等关键领域中的安全策略。通过综合MEAs研究的最新进展并讨论当前评估实践的局限性，本文提供了开发 robust 和自适应防御策略的重要见解。我们全面的方法强调了在整个分布式计算场景中整合保护措施以确保机器学习模型安全部署的重要性。', 'title_zh': '分布式计算环境中的模型提取攻击与防御综述'}
{'arxiv_id': 'arXiv:2502.16060', 'title': 'Single-Channel EEG Tokenization Through Time-Frequency Modeling', 'authors': 'Jathurshan Pradeepkumar, Xihao Piao, Zheng Chen, Jimeng Sun', 'link': 'https://arxiv.org/abs/2502.16060', 'abstract': "We introduce TFM-Tokenizer, a novel tokenization framework tailored for EEG analysis that transforms continuous, noisy brain signals into a sequence of discrete, well-represented tokens for various EEG tasks. Conventional approaches typically rely on continuous embeddings and inter-channel dependencies, which are limited in capturing inherent EEG features such as temporally unpredictable patterns and diverse oscillatory waveforms. In contrast, we hypothesize that critical time-frequency features can be effectively captured from a single channel. By learning tokens that encapsulate these intrinsic patterns within a single channel, our approach yields a scalable tokenizer adaptable across diverse EEG settings. We integrate the TFM-Tokenizer with a transformer-based TFM-Encoder, leveraging established pretraining techniques from natural language processing, such as masked token prediction, followed by downstream fine-tuning for various EEG tasks. Experiments across four EEG datasets show that TFM-Token outperforms state-of-the-art methods. On TUEV, our approach improves balanced accuracy and Cohen's Kappa by 5% over baselines. Comprehensive analysis of the learned tokens demonstrates their ability to capture class-distinctive features, enhance frequency representation, and ability to encode time-frequency motifs into distinct tokens, improving interpretability.", 'abstract_zh': 'TFM-Tokenizer：一种用于EEG分析的新型分词框架', 'title_zh': '单通道EEG分子化通过时频建模'}
{'arxiv_id': 'arXiv:2502.16054', 'title': 'Human-AI Collaboration in Cloud Security: Cognitive Hierarchy-Driven Deep Reinforcement Learning', 'authors': 'Zahra Aref, Sheng Wei, Narayan B. Mandayam', 'link': 'https://arxiv.org/abs/2502.16054', 'abstract': "Given the complexity of multi-tenant cloud environments and the need for real-time threat mitigation, Security Operations Centers (SOCs) must integrate AI-driven adaptive defenses against Advanced Persistent Threats (APTs). However, SOC analysts struggle with countering adaptive adversarial tactics, necessitating intelligent decision-support frameworks. To enhance human-AI collaboration in SOCs, we propose a Cognitive Hierarchy Theory-driven Deep Q-Network (CHT-DQN) framework that models SOC analysts' decision-making against AI-driven APT bots. The SOC analyst (defender) operates at cognitive level-1, anticipating attacker strategies, while the APT bot (attacker) follows a level-0 exploitative policy. By incorporating CHT into DQN, our framework enhances SOC defense strategies via Attack Graph (AG)-based reinforcement learning. Simulation experiments across varying AG complexities show that CHT-DQN achieves higher data protection and lower action discrepancies compared to standard DQN. A theoretical lower bound analysis further validates its superior Q-value performance. A human-in-the-loop (HITL) evaluation on Amazon Mechanical Turk (MTurk) reveals that SOC analysts using CHT-DQN-driven transition probabilities align better with adaptive attackers, improving data protection. Additionally, human decision patterns exhibit risk aversion after failure and risk-seeking behavior after success, aligning with Prospect Theory. These findings underscore the potential of integrating cognitive modeling into deep reinforcement learning to enhance SOC operations and develop real-time adaptive cloud security mechanisms.", 'abstract_zh': '基于认知层次理论的深度Q网络驱动的认知层次-深度Q网络框架：强化SOC中的人机协作以应对高级持续威胁（CHT-DQN框架）', 'title_zh': '云安全中的人工智能协作：基于认知层级的深度 reinforcement 学习'}
{'arxiv_id': 'arXiv:2502.16032', 'title': 'Clinical Inspired MRI Lesion Segmentation', 'authors': 'Lijun Yan, Churan Wang, Fangwei Zhong, Yizhou Wang', 'link': 'https://arxiv.org/abs/2502.16032', 'abstract': 'Magnetic resonance imaging (MRI) is a potent diagnostic tool for detecting pathological tissues in various diseases. Different MRI sequences have different contrast mechanisms and sensitivities for different types of lesions, which pose challenges to accurate and consistent lesion segmentation. In clinical practice, radiologists commonly use the sub-sequence feature, i.e. the difference between post contrast-enhanced T1-weighted (post) and pre-contrast-enhanced (pre) sequences, to locate lesions. Inspired by this, we propose a residual fusion method to learn subsequence representation for MRI lesion segmentation. Specifically, we iteratively and adaptively fuse features from pre- and post-contrast sequences at multiple resolutions, using dynamic weights to achieve optimal fusion and address diverse lesion enhancement patterns. Our method achieves state-of-the-art performances on BraTS2023 dataset for brain tumor segmentation and our in-house breast MRI dataset for breast lesion segmentation. Our method is clinically inspired and has the potential to facilitate lesion segmentation in various applications.', 'abstract_zh': '磁共振成像（MRI）是检测各种疾病中病理组织的一个强大诊断工具。不同的MRI序列对不同类型的病灶具有不同的对比机制和敏感性，这给准确且一致的病灶分割带来了挑战。在临床实践中，放射科医生通常使用子序列特征，即对比增强T1加权序列（post）与未对比增强序列（pre）之间的差异，来定位病灶。受这一做法的启发，我们提出了一种残差融合方法来学习MRI病灶分割的子序列表示。具体而言，我们在多个分辨率上迭代地自适应融合预对比增强序列和对比增强序列的特征，并使用动态权重以实现最佳融合并应对多样的病灶增强模式。我们的方法在BraTS2023脑肿瘤分割数据集和我们内部的乳腺MRI数据集的乳腺病灶分割任务上实现了最先进的性能。我们的方法具有临床启发性，有望在各种应用中促进病灶分割。', 'title_zh': '临床启发的MRI病变分割'}
{'arxiv_id': 'arXiv:2502.16030', 'title': 'Real Time Offside Detection using a Single Camera in Soccer', 'authors': 'Shounak Desai', 'link': 'https://arxiv.org/abs/2502.16030', 'abstract': 'Technological advancements in soccer have surged over the past decade, transforming aspects of the sport. Unlike binary rules, many soccer regulations, such as the "Offside Rule," rely on subjective interpretation rather than straightforward True or False criteria. The on-field referee holds ultimate authority in adjudicating these nuanced decisions. A significant breakthrough in soccer officiating is the Video Assistant Referee (VAR) system, leveraging a network of 20-30 cameras within stadiums to minimize human errors. VAR\'s operational scope typically encompasses 10-30 cameras, ensuring high decision accuracy but at a substantial cost. This report proposes an innovative approach to offside detection using a single camera, such as the broadcasting camera, to mitigate expenses associated with sophisticated technological setups.', 'abstract_zh': '过去十年间，足球领域的技术进步推动了这项运动的转型。与二元规则不同，足球的一些规则，如“越位规则”，依赖于主观判断而非简单的True或False标准。场上的裁判拥有最终裁决这些细微决策的权力。足球裁判工作的重大突破是视频助理裁判（VAR）系统，该系统利用 stadium 内的 20-30 台摄像机来最小化人为错误。VAR 的运作范围通常包括 10-30 台摄像机，确保决策的准确性，但代价高昂。本报告提出了一种创新的方法，利用单一摄像机（如广播摄像机）进行越位检测，以减轻复杂的科技设置所带来的成本问题。', 'title_zh': '使用单摄像头进行实时越位检测在足球中的应用'}
{'arxiv_id': 'arXiv:2502.16003', 'title': 'Hierarchical Residuals Exploit Brain-Inspired Compositionality', 'authors': 'Francisco M. López, Jochen Triesch', 'link': 'https://arxiv.org/abs/2502.16003', 'abstract': 'We present Hierarchical Residual Networks (HiResNets), deep convolutional neural networks with long-range residual connections between layers at different hierarchical levels. HiResNets draw inspiration on the organization of the mammalian brain by replicating the direct connections from subcortical areas to the entire cortical hierarchy. We show that the inclusion of hierarchical residuals in several architectures, including ResNets, results in a boost in accuracy and faster learning. A detailed analysis of our models reveals that they perform hierarchical compositionality by learning feature maps relative to the compressed representations provided by the skip connections.', 'abstract_zh': '层次 residual 网络：具有多级长程残差连接的深卷积神经网络', 'title_zh': '层次残差促进脑启发的组合性'}
{'arxiv_id': 'arXiv:2502.15996', 'title': 'Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts', 'authors': 'Aditya Kumar, Simon Rauch, Mario Cypko, Oliver Amft', 'link': 'https://arxiv.org/abs/2502.15996', 'abstract': 'We introduce a novel contextual embedding model med-gte-hybrid that was derived from the gte-large sentence transformer to extract information from unstructured clinical narratives. Our model tuning strategy for med-gte-hybrid combines contrastive learning and a denoising autoencoder. To evaluate the performance of med-gte-hybrid, we investigate several clinical prediction tasks in large patient cohorts extracted from the MIMIC-IV dataset, including Chronic Kidney Disease (CKD) patient prognosis, estimated glomerular filtration rate (eGFR) prediction, and patient mortality prediction. Furthermore, we demonstrate that the med-gte-hybrid model improves patient stratification, clustering, and text retrieval, thus outperforms current state-of-the-art models on the Massive Text Embedding Benchmark (MTEB). While some of our evaluations focus on CKD, our hybrid tuning of sentence transformers could be transferred to other medical domains and has the potential to improve clinical decision-making and personalised treatment pathways in various healthcare applications.', 'abstract_zh': '我们介绍了一种源自gte-large句子变换器的新颖上下文嵌入模型med-gte-hybrid，用于提取不结构化的临床叙事信息。med-gte-hybrid模型的调优策略结合了对比学习和去噪自编码器。为了评估med-gte-hybrid的表现，我们在MIMIC-IV数据集中提取的大患者队列中调查了几项临床预测任务，包括慢性肾病(CKD)患者的预后、估算的肾小球滤过率(eGFR)预测和患者死亡率预测。此外，我们证明med-gte-hybrid模型改善了患者分层、聚类和文本检索，并在大规模文本嵌入基准测试(MTEB)中优于当前的最先进模型。虽然我们的某些评估集中在CKD上，但我们的混合调优方法可以应用于其他医疗领域，并有望在各种医疗保健应用中改善临床决策和个性化的治疗路径。', 'title_zh': 'Med-gte-hybrid：一种从临床文本中提取可行动信息的上下文嵌入变压器模型'}
{'arxiv_id': 'arXiv:2502.15980', 'title': 'Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation', 'authors': 'Yuan Tian, Daniel Lee, Fei Wu, Tung Mai, Kun Qian, Siddhartha Sahai, Tianyi Zhang, Yunyao Li', 'link': 'https://arxiv.org/abs/2502.15980', 'abstract': 'Text-to-SQL models, which parse natural language (NL) questions to executable SQL queries, are increasingly adopted in real-world applications. However, deploying such models in the real world often requires adapting them to the highly specialized database schemas used in specific applications. We find that existing text-to-SQL models experience significant performance drops when applied to new schemas, primarily due to the lack of domain-specific data for fine-tuning. This data scarcity also limits the ability to effectively evaluate model performance in new domains. Continuously obtaining high-quality text-to-SQL data for evolving schemas is prohibitively expensive in real-world scenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop text-to-SQL data annotation system. SQLsynth streamlines the creation of high-quality text-to-SQL datasets through human-LLM collaboration in a structured workflow. A within-subjects user study comparing SQLsynth with manual annotation and ChatGPT shows that SQLsynth significantly accelerates text-to-SQL data annotation, reduces cognitive load, and produces datasets that are more accurate, natural, and diverse. Our code is available at this https URL.', 'abstract_zh': 'Text-to-SQL模型将自然语言(NL)问题解析为可执行的SQL查询，已在实际应用中被越来越多地采用。然而，在实际部署这些模型时常需将它们适应特定应用场景中高度专业化的关系数据库模式。我们发现，现有的Text-to-SQL模型在应用于新的模式时会经历显著的性能下降，主要原因是缺乏用于微调的领域特定数据。这些数据的稀缺性也限制了评估模型在新领域中的性能的能力。在现实场景中，持续获取高质量的Text-to-SQL数据对于不断变化的模式来说是代价高昂的。为解决这一问题，我们提出了SQLsynth，一种包含人类在环的Text-to-SQL数据注释系统。SQLsynth通过结构化的流程促进人类与大语言模型（LLM）的协作，以简化高质量Text-to-SQL数据集的创建。一项针对SQLsynth、手工注释和ChatGPT的嵌套被试用户研究显示，SQLsynth在加速Text-to-SQL数据注释、减轻认知负担以及产出更为准确、自然和多样化的数据集方面具有显著优势。相关代码可在如下链接获取。', 'title_zh': '基于人类-大语言模型协作数据注释的文本到SQL领域适应方法'}
{'arxiv_id': 'arXiv:2502.15955', 'title': 'Compression Barriers for Autoregressive Transformers', 'authors': 'Themistoklis Haris, Krzysztof Onak', 'link': 'https://arxiv.org/abs/2502.15955', 'abstract': "A key limitation of autoregressive Transformers is the large memory needed at inference-time to cache all previous key-value (KV) embeddings. Prior works address this by compressing the KV cache, but often assume specific structural properties of the embeddings. This raises the following natural question: Can truly sublinear space utilization be achieved without such assumptions? In this work, we answer this question in the negative. Any algorithm for attention-based token generation must use $\\Theta(nd)$ space, where $n$ is the number of tokens generated so far and $d = \\Omega(\\log n)$ is the dimension of the KV embeddings. Our proof involves a reduction from a classic communication complexity problem and uses a randomized construction that leverages properties of projections in the spirit of the Johnson-Linderstrauss lemma. For the low-dimensional regime $d = o(\\log n)$, we show that any algorithm requires $\\Omega(d\\cdot e^d)$ space and prove, using tight bounds on covering numbers, that SubGen, proposed by Zandieh, Han, Mirrokni and Karbasi, matches this bound. Further, we investigate how sparsity assumptions enable token generation in truly sublinear space, presenting impossibility results and proposing a new KV cache compression algorithm for sliding window attention when the value cache outside the window is unmasked. Finally, we analyze token generation's time complexity, using an indistinguishability argument to prove that no non-adaptive algorithm can compute attention online in sublinear time for all tokens.", 'abstract_zh': '自回归Transformer的一个关键局限是在推理时需要大量内存来缓存所有先前的键值（KV）嵌入。先前的工作通过压缩KV缓存来解决这一问题，但通常假设嵌入的特定结构属性。这引发了一个自然的问题：是否可以在不假设这些属性的情况下实现真正亚线性空间利用率？在本文中，我们回答了这一问题，得出否定结论。任何基于注意力的Token生成算法都必须使用$\\Theta(nd)$空间，其中$n$是目前已生成的Token数量，$d = \\Omega(\\log n)$是KV嵌入的维度。我们的证明涉及从经典通信复杂性问题中进行归约，并利用投影性质的随机构造。对于低维情形$d = o(\\log n)$，我们证明任何算法需要$\\Omega(d \\cdot e^d)$空间，并利用覆盖数的紧界证明，Zandieh, Han, Mirrokni和Karbasi提出的SubGen达到了这一界。此外，我们研究了稀疏假设如何在真正亚线性空间中实现Token生成，提出了一些不可能性结果，并提出了一种针对滑动窗口注意力的新KV缓存压缩算法，当窗口外的价值缓存未掩码时。最后，我们分析了Token生成的时间复杂性，利用不可区分性论证证明，没有非自适应算法可以在所有Token上以亚线性时间在线计算注意力。', 'title_zh': '自回归变压器的压缩障碍'}
{'arxiv_id': 'arXiv:2502.15936', 'title': 'Space-O-RAN: Enabling Intelligent, Open, and Interoperable Non Terrestrial Networks in 6G', 'authors': 'Eduardo Baena, Paolo Testolina, Michele Polese, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia', 'link': 'https://arxiv.org/abs/2502.15936', 'abstract': 'Non-terrestrial networks (NTNs) are essential for ubiquitous connectivity, providing coverage in remote and underserved areas. However, since NTNs are currently operated independently, they face challenges such as isolation, limited scalability, and high operational costs. Integrating satellite constellations with terrestrial networks offers a way to address these limitations while enabling adaptive and cost-efficient connectivity through the application of Artificial Intelligence (AI) models.\nThis paper introduces Space-O-RAN, a framework that extends Open Radio Access Network (RAN) principles to NTNs. It employs hierarchical closed-loop control with distributed Space RAN Intelligent Controllers (Space-RICs) to dynamically manage and optimize operations across both domains.\nTo enable adaptive resource allocation and network orchestration, the proposed architecture integrates real-time satellite optimization and control with AI-driven management and digital twin (DT) modeling. It incorporates distributed Space Applications (sApps) and dApps to ensure robust performance in in highly dynamic orbital environments. A core feature is dynamic link-interface mapping, which allows network functions to adapt to specific application requirements and changing link conditions using all physical links on the satellite.\nSimulation results evaluate its feasibility by analyzing latency constraints across different NTN link types, demonstrating that intra-cluster coordination operates within viable signaling delay bounds, while offloading non-real-time tasks to ground infrastructure enhances scalability toward sixth-generation (6G) networks.', 'abstract_zh': '非地球网络（NTNs）对于无处不在的连接至关重要，提供偏远和未服务区域的覆盖。然而，由于NTNs目前是独立操作的，它们面临着孤立、扩展有限和高昂运营成本的挑战。将卫星星座与地面网络集成并通过人工智能（AI）模型的应用来实现自适应和成本效益的连接提供了一种解决方案。\n\n本文介绍了Space-O-RAN框架，该框架将开放无线接入网络（RAN）原则扩展到NTNs。它采用分层闭环控制，结合分布式空间RAN智能控制器（Space-RICs），以动态管理和优化两个域的操作。\n\n为实现自适应资源分配和网络编排，所提出的架构将实时卫星优化和控制与基于AI的管理和数字孪生（DT）建模集成。它包含了分布式太空应用（sApps）和dApps，以确保在高度动态轨道环境中的稳健性能。一个核心特征是动态链路-接口映射，它允许网络功能根据特定的应用需求和变化的链路条件适应使用所有卫星物理链路。', 'title_zh': 'Space-O-RAN：实现6G非地面网络的智能、开放和互操作性'}
{'arxiv_id': 'arXiv:2502.15898', 'title': 'ML-Driven Approaches to Combat Medicare Fraud: Advances in Class Imbalance Solutions, Feature Engineering, Adaptive Learning, and Business Impact', 'authors': 'Dorsa Farahmandazad, Kasra Danesh', 'link': 'https://arxiv.org/abs/2502.15898', 'abstract': 'Medicare fraud poses a substantial challenge to healthcare systems, resulting in significant financial losses and undermining the quality of care provided to legitimate beneficiaries. This study investigates the use of machine learning (ML) to enhance Medicare fraud detection, addressing key challenges such as class imbalance, high-dimensional data, and evolving fraud patterns. A dataset comprising inpatient claims, outpatient claims, and beneficiary details was used to train and evaluate five ML models: Random Forest, KNN, LDA, Decision Tree, and AdaBoost. Data preprocessing techniques included resampling SMOTE method to address the class imbalance, feature selection for dimensionality reduction, and aggregation of diagnostic and procedural codes. Random Forest emerged as the best-performing model, achieving a training accuracy of 99.2% and validation accuracy of 98.8%, and F1-score (98.4%). The Decision Tree also performed well, achieving a validation accuracy of 96.3%. KNN and AdaBoost demonstrated moderate performance, with validation accuracies of 79.2% and 81.1%, respectively, while LDA struggled with a validation accuracy of 63.3% and a low recall of 16.6%. The results highlight the importance of advanced resampling techniques, feature engineering, and adaptive learning in detecting Medicare fraud effectively. This study underscores the potential of machine learning in addressing the complexities of fraud detection. Future work should explore explainable AI and hybrid models to improve interpretability and performance, ensuring scalable and reliable fraud detection systems that protect healthcare resources and beneficiaries.', 'abstract_zh': '机器学习在增强医疗保险欺诈检测中的应用：应对类别不平衡、高维数据和欺诈模式演变的挑战', 'title_zh': '基于ML的方法对抗医疗保险欺诈：类不平衡解决方案、特征工程、自适应学习和业务影响的进展'}
{'arxiv_id': 'arXiv:2502.15870', 'title': 'Making Sense of AI Limitations: How Individual Perceptions Shape Organizational Readiness for AI Adoption', 'authors': 'Thomas Übellacker', 'link': 'https://arxiv.org/abs/2502.15870', 'abstract': "This study investigates how individuals' perceptions of artificial intelligence (AI) limitations influence organizational readiness for AI adoption. Through semi-structured interviews with seven AI implementation experts, analyzed using the Gioia methodology, the research reveals that organizational readiness emerges through dynamic interactions between individual sensemaking, social learning, and formal integration processes. The findings demonstrate that hands-on experience with AI limitations leads to more realistic expectations and increased trust, mainly when supported by peer networks and champion systems. Organizations that successfully translate these individual and collective insights into formal governance structures achieve more sustainable AI adoption. The study advances theory by showing how organizational readiness for AI adoption evolves through continuous cycles of individual understanding, social learning, and organizational adaptation. These insights suggest that organizations should approach AI adoption not as a one-time implementation but as an ongoing strategic learning process that balances innovation with practical constraints. The research contributes to organizational readiness theory and practice by illuminating how micro-level perceptions and experiences shape macro-level adoption outcomes.", 'abstract_zh': '本研究探讨了个体对人工智能（AI）限制感知如何影响组织的AI采纳准备度。通过对七名AI实施专家进行半结构化访谈并采用Gioia方法进行分析，研究发现组织的准备度是通过个体意义构建、社会学习以及正式整合过程的动态交互而形成的。研究结果表明，与AI限制的直接互动促进了更现实的期望和信任，尤其是在 peer 网络和倡导系统支持下。成功将这些个体与集体洞见转化为正式治理结构的组织实现了更可持续的AI采纳。研究通过表明组织的AI采纳准备度如何通过持续的个体理解、社会学习和组织适应循环而演变，来推进理论。研究揭示了微观层面的感知和经历如何影响宏观层面的采纳结果，从而为组织准备度理论与实践做出了贡献。', 'title_zh': '理解AI局限性：个体感知如何影响组织AI采用的准备度'}
{'arxiv_id': 'arXiv:2502.15867', 'title': 'Strategic priorities for transformative progress in advancing biology with proteomics and artificial intelligence', 'authors': 'Yingying Sun, Jun A, Zhiwei Liu, Rui Sun, Liujia Qian, Samuel H. Payne, Wout Bittremieux, Markus Ralser, Chen Li, Yi Chen, Zhen Dong, Yasset Perez-Riverol, Asif Khan, Chris Sander, Ruedi Aebersold, Juan Antonio Vizcaíno, Jonathan R Krieger, Jianhua Yao, Han Wen, Linfeng Zhang, Yunping Zhu, Yue Xuan, Benjamin Boyang Sun, Liang Qiao, Henning Hermjakob, Haixu Tang, Huanhuan Gao, Yamin Deng, Qing Zhong, Cheng Chang, Nuno Bandeira, Ming Li, Weinan E, Siqi Sun, Yuedong Yang, Gilbert S. Omenn, Yue Zhang, Ping Xu, Yan Fu, Xiaowen Liu, Christopher M. Overall, Yu Wang, Eric W. Deutsch, Luonan Chen, Jürgen Cox, Vadim Demichev, Fuchu He, Jiaxing Huang, Huilin Jin, Chao Liu, Nan Li, Zhongzhi Luan, Jiangning Song, Kaicheng Yu, Wanggen Wan, Tai Wang, Kang Zhang, Le Zhang, Peter A. Bell, Matthias Mann, Bing Zhang, Tiannan Guo', 'link': 'https://arxiv.org/abs/2502.15867', 'abstract': 'Artificial intelligence (AI) is transforming scientific research, including proteomics. Advances in mass spectrometry (MS)-based proteomics data quality, diversity, and scale, combined with groundbreaking AI techniques, are unlocking new challenges and opportunities in biological discovery. Here, we highlight key areas where AI is driving innovation, from data analysis to new biological insights. These include developing an AI-friendly ecosystem for proteomics data generation, sharing, and analysis; improving peptide and protein identification and quantification; characterizing protein-protein interactions and protein complexes; advancing spatial and perturbation proteomics; integrating multi-omics data; and ultimately enabling AI-empowered virtual cells.', 'abstract_zh': '人工智能（AI）正在transforming科学研究所涵盖的蛋白质组学。基于质谱（MS）的蛋白质组学数据质量、多样性和规模的进步，结合突破性的AI技术，正在开启生物发现中的新挑战和机遇。在这里，我们强调AI推动创新的关键领域，从数据处理到新的生物学见解。这些领域包括建立AI友好的蛋白质组学数据生成、共享和分析生态系统；改进肽和蛋白质的识别和定量；表征蛋白质相互作用和蛋白质复合物；促进空间蛋白质组学和扰动蛋白质组学的发展；整合多组学数据；最终实现AI赋能的虚拟细胞。', 'title_zh': 'proteomics和人工智能推动生物学变革的战略优先事项'}
{'arxiv_id': 'arXiv:2502.15859', 'title': 'AI Governance InternationaL Evaluation Index (AGILE Index)', 'authors': 'Yi Zeng, Enmeng Lu, Xin Guan, Cunqing Huangfu, Zizhe Ruan, Ammar Younas', 'link': 'https://arxiv.org/abs/2502.15859', 'abstract': 'The rapid advancement of Artificial Intelligence (AI) technology is profoundly transforming human society and concurrently presenting a series of ethical, legal, and social issues. The effective governance of AI has become a crucial global concern. Since 2022, the extensive deployment of generative AI, particularly large language models, marked a new phase in AI governance. Continuous efforts are being made by the international community in actively addressing the novel challenges posed by these AI developments. As consensus on international governance continues to be established and put into action, the practical importance of conducting a global assessment of the state of AI governance is progressively coming to light. In this context, we initiated the development of the AI Governance InternationaL Evaluation Index (AGILE Index). Adhering to the design principle, "the level of governance should match the level of development," the inaugural evaluation of the AGILE Index commences with an exploration of four foundational pillars: the development level of AI, the AI governance environment, the AI governance instruments, and the AI governance effectiveness. It covers 39 indicators across 18 dimensions to comprehensively assess the AI governance level of 14 representative countries globally. The index is utilized to delve into the status of AI governance to date in 14 countries for the first batch of evaluation. The aim is to depict the current state of AI governance in these countries through data scoring, assist them in identifying their governance stage and uncovering governance issues, and ultimately offer insights for the enhancement of their AI governance systems.', 'abstract_zh': '人工智能治理国际评估指数（AGILE指数）：探究四大理支柱', 'title_zh': 'AI治理国际评估指数（AGILE指数）'}
{'arxiv_id': 'arXiv:2502.15858', 'title': 'Generative AI Training and Copyright Law', 'authors': 'Tim W. Dornis, Sebastian Stober', 'link': 'https://arxiv.org/abs/2502.15858', 'abstract': 'Training generative AI models requires extensive amounts of data. A common practice is to collect such data through web scraping. Yet, much of what has been and is collected is copyright protected. Its use may be copyright infringement. In the USA, AI developers rely on "fair use" and in Europe, the prevailing view is that the exception for "Text and Data Mining" (TDM) applies. In a recent interdisciplinary tandem-study, we have argued in detail that this is actually not the case because generative AI training fundamentally differs from TDM. In this article, we share our main findings and the implications for both public and corporate research on generative models. We further discuss how the phenomenon of training data memorization leads to copyright issues independently from the "fair use" and TDM exceptions. Finally, we outline how the ISMIR could contribute to the ongoing discussion about fair practices with respect to generative AI that satisfy all stakeholders.', 'abstract_zh': '训练生成AI模型需要大量数据。通常通过网络抓取收集这些数据，但其中大部分受到版权保护，使用这些数据可能构成版权侵权。在美国，AI开发者依赖“合理使用”原则；而在欧洲，普遍认为“文本和数据挖掘”（TDM）的例外适用。在一项最近的跨学科联合研究中，我们详细论述了这并不是实际情况，因为生成AI训练本质上不同于TDM。在这篇文章中，我们分享了主要发现及其对公共和企业研究生成模型的影响。我们进一步探讨了训练数据记忆现象如何独立于“合理使用”和TDM例外引发版权问题。最后，我们概述了ISMIR如何为关于生成AI公平实践的讨论做出贡献，这些实践能够满足所有利益相关方的需求。', 'title_zh': '生成式AI培训与版权法'}
{'arxiv_id': 'arXiv:2502.15856', 'title': "A Critical Assessment of Modern Generative Models' Ability to Replicate Artistic Styles", 'authors': 'Andrea Asperti, Franky George, Tiberio Marras, Razvan Ciprian Stricescu, Fabio Zanotti', 'link': 'https://arxiv.org/abs/2502.15856', 'abstract': 'In recent years, advancements in generative artificial intelligence have led to the development of sophisticated tools capable of mimicking diverse artistic styles, opening new possibilities for digital creativity and artistic expression. This paper presents a critical assessment of the style replication capabilities of contemporary generative models, evaluating their strengths and limitations across multiple dimensions. We examine how effectively these models reproduce traditional artistic styles while maintaining structural integrity and compositional balance in the generated images.\nThe analysis is based on a new large dataset of AI-generated works imitating artistic styles of the past, holding potential for a wide range of applications: the "AI-pastiche" dataset.\nThe study is supported by extensive user surveys, collecting diverse opinions on the dataset and investigation both technical and aesthetic challenges, including the ability to generate outputs that are realistic and visually convincing, the versatility of models in handling a wide range of artistic styles, and the extent to which they adhere to the content and stylistic specifications outlined in prompts.\nThis paper aims to provide a comprehensive overview of the current state of generative tools in style replication, offering insights into their technical and artistic limitations, potential advancements in model design and training methodologies, and emerging opportunities for enhancing digital artistry, human-AI collaboration, and the broader creative landscape.', 'abstract_zh': '近年来，生成式人工智能的发展推动了模仿多样艺术风格的复杂工具的出现，为数字创作和艺术表达开辟了新可能性。本文对当代生成模型的风格复制能力进行了批判性评估，从多个维度考察其强点和局限性。我们探讨了这些模型在生成图像中如何有效再现传统艺术风格，同时保持结构完整性和构图平衡。\n\n分析基于一个新的大规模人工智能生成作品数据集，模仿过去的艺术风格，具有广泛的应用潜力：“AI-再演绎”数据集。\n\n研究还依托广泛的用户调查，收集对数据集的多样化意见，探讨技术与美学挑战，包括生成逼真且视觉上令人信服的输出能力，模型在处理广泛艺术风格方面的灵活性，以及它们在提示中规定的主题和风格规范上的遵从性。\n\n本文旨在提供当前生成工具在风格复制方面全面概览，探讨其技术和艺术局限性，潜在的模型设计和训练方法进步，以及增强数字艺术创作、人机协作和更广泛创意领域的新机会。', 'title_zh': '现代生成模型复制艺术风格的能力批判性评估'}
{'arxiv_id': 'arXiv:2502.15855', 'title': 'Non-Linear Flow Matching for Full-Atom Peptide Design', 'authors': 'Dengdeng Huang, Shikui Tu', 'link': 'https://arxiv.org/abs/2502.15855', 'abstract': "Peptide design plays a pivotal role in therapeutic applications, yet existing AI-assisted methods often struggle to generate stable peptides with high affinity due to their inability to accurately simulate the dynamic docking process. To address this challenge, we propose NLFlow, a novel multi-manifold approach based on non-linear flow matching. Specifically, we design a polynomial-based conditional vector field to accelerate the convergence of the peptide's position towards the target pocket, effectively capturing the temporal inconsistencies across position, rotation, torsion, and amino acid type manifolds. This enables the model to better align with the true conformational changes observed in biological docking processes. Additionally, we incorporate interaction-related information, such as polarity, to enhance the understanding of peptide-protein binding. Extensive experiments demonstrate that NLFlow outperforms existing methods in generating peptides with superior stability, affinity, and diversity, offering a fast and efficient solution for peptide design and advancing the peptide-based therapeutic development.", 'abstract_zh': '肽设计在治疗应用中发挥着关键作用，但现有的AI辅助方法 often 因难以准确模拟动态结合过程而往往难以生成具有高亲和力的稳定肽。为解决这一挑战，我们提出了一种基于非线性流匹配的新型多流形方法NLFlow。具体来说，我们设计了一种基于多项式的条件向量场以加速肽的位置向目标口袋的收敛，有效地捕捉了位置、旋转、扭折和氨基酸类型流形上的时间不一致性。这使得模型能够更好地与生物结合过程中观察到的真实构象变化对齐。此外，我们还整合了与相互作用相关的信息，如极性，以增强对肽-蛋白结合的理解。大量的实验表明，NLFlow 在生成具有更优稳定性和亲和力、更高多样性的肽方面优于现有方法，为肽设计提供了一种快速高效的解决方案，推动基于肽的治疗发展。', 'title_zh': '非线性流匹配用于全原子肽设计'}
{'arxiv_id': 'arXiv:2502.15854', 'title': 'Enhancing Domain-Specific Retrieval-Augmented Generation: Synthetic Data Generation and Evaluation using Reasoning Models', 'authors': 'Aryan Jadon, Avinash Patil, Shashank Kumar', 'link': 'https://arxiv.org/abs/2502.15854', 'abstract': 'Retrieval-Augmented Generation (RAG) systems face significant performance gaps when applied to technical domains requiring precise information extraction from complex documents. Current evaluation methodologies relying on document-level metrics inadequately capture token-resolution retrieval accuracy that is critical for domain-related documents. We propose a framework combining granular evaluation metrics with synthetic data generation to optimize domain-specific RAG performance. First, we introduce token-aware metrics Precision $\\Omega$ and Intersection-over-Union (IoU) that quantify context preservation versus information density trade-offs inherent in technical texts. Second, we develop a reasoning model-driven pipeline using instruction-tuned LLMs (DeepSeek-R1, DeepSeek-R1 distilled variants, and Phi-4) to generate context-anchored QA pairs with discontinuous reference spans across three specialized corpora: SEC 10-K filings (finance), biomedical abstracts (PubMed), and APT threat reports (cybersecurity).\nOur empirical analysis reveals critical insights: smaller chunks (less than 10 tokens) improve precision by 31-42% (IoU = 0.071 vs. baseline 0.053) at recall costs (-18%), while domain-specific embedding strategies yield 22% variance in optimal chunk sizing (5-20 tokens). The DeepSeek-R1-Distill-Qwen-32B model demonstrates superior concept alignment (+14% mean IoU over alternatives), though no configuration universally dominates. Financial texts favor larger chunks for risk factor coverage (Recall = 0.81 at size = 20), whereas cybersecurity content benefits from atomic segmentation, Precision $\\Omega = 0.28$ at size = 5.\nOur code is available on this https URL', 'abstract_zh': 'Retrieval-Augmented Generation (RAG) 系统在应用于要求从复杂文档中精确提取信息的技术领域时面临显著的性能差距。当前依赖文档级指标的评估方法未能充分捕捉到对领域相关文档至关重要的标记级检索准确性。我们提出了一种结合粒度评估指标和合成数据生成框架，以优化特定领域RAG性能。首先，我们引入了具有标记感知能力的Precision Ω和交并比（IoU）度量，量化技术文本中上下文保存与信息密度之间的权衡。其次，我们开发了一种以推理模型为驱动的流水线，使用指令微调的大语言模型（DeepSeek-R1、DeepSeek-R1精简变体和Phi-4）生成上下文锚定的问答对，并跨越三个专门的语料库：SEC 10-K 提交文件（金融）、PubMed 生物医学摘要（生物医学）和APT 威胁报告（网络安全）。', 'title_zh': '增强领域特定检索增强生成：基于推理模型的合成数据生成与评估'}
{'arxiv_id': 'arXiv:2502.15849', 'title': 'Deriving Representative Structure from Music Corpora', 'authors': 'Ilana Shapiro, Ruanqianqian, Huang, Zachary Novack, Cheng-i Wang, Hao-Wen Dong, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Sorin Lerner', 'link': 'https://arxiv.org/abs/2502.15849', 'abstract': 'Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a dually NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.', 'abstract_zh': '西方音乐是一种固有的层级系统，从细微的旋律结构到高层的形式结构。为了全面多粒度地分析音乐作品，我们提出了一种统一的层级元表示方法，称为结构时间图（STG）。对于单个音乐作品，STG定义了一种结构音乐特征的层级体系及其相互间的时间关系。我们使用STG来实现一种新型的方法，以提取音乐作品集合的代表性结构摘要，我们将这一问题形式化为一个扩展的广义中位图问题的双重NP难组合优化问题。我们的方法首先应用模拟退火来开发基于图同构的结构距离度量。然后，我们的方法将SMT求解器的形式保证与嵌套的模拟退火应用于结构距离相结合，生成整个STG集合的结构上一致的代表性质心STG。为了评估我们的方法，我们进行了实验，验证了结构距离能准确地区分音乐作品，并且提取出的质心能准确地结构化表征其集合。', 'title_zh': '从音乐语料库中提取代表性结构'}
{'arxiv_id': 'arXiv:2502.15839', 'title': 'FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning with Incomplete Modalities', 'authors': 'Yi Liu, Cong Wang, Xingliang Yuan', 'link': 'https://arxiv.org/abs/2502.15839', 'abstract': "The Web of Things (WoT) enhances interoperability across web-based and ubiquitous computing platforms while complementing existing IoT standards. The multimodal Federated Learning (FL) paradigm has been introduced to enhance WoT by enabling the fusion of multi-source mobile sensing data while preserving privacy. However, a key challenge in mobile sensing systems using multimodal FL is modality incompleteness, where some modalities may be unavailable or only partially captured, potentially degrading the system's performance and reliability. Current multimodal FL frameworks typically train multiple unimodal FL subsystems or apply interpolation techniques on the node side to approximate missing modalities. However, these approaches overlook the shared latent feature space among incomplete modalities across different nodes and fail to discriminate against low-quality nodes. To address this gap, we present FedMobile, a new knowledge contribution-aware multimodal FL framework designed for robust learning despite missing modalities. FedMobile prioritizes local-to-global knowledge transfer, leveraging cross-node multimodal feature information to reconstruct missing features. It also enhances system performance and resilience to modality heterogeneity through rigorous node contribution assessments and knowledge contribution-aware aggregation rules. Empirical evaluations on five widely recognized multimodal benchmark datasets demonstrate that FedMobile maintains robust learning even when up to 90% of modality information is missing or when data from two modalities are randomly missing, outperforming state-of-the-art baselines.", 'abstract_zh': '物联网网络（WoT）增强了基于网络和泛在计算平台之间的互操作性，同时补充了现有的物联网标准。引入了多模态联邦学习（FL）范式，通过融合多源移动传感数据同时保持隐私来增强WoT。然而，在使用多模态FL的移动传感系统中，一个关键挑战是模态不完备性，即某些模态可能不可用或仅部分捕获，这可能会降低系统的性能和可靠性。当前的多模态FL框架通常训练多个单模态FL子系统或在节点侧应用插值技术来近似缺失的模态。然而，这些方法忽略了不同节点之间不完备模态之间的共享潜在于特征空间，并未能区分低质量节点。为解决这一问题，我们提出了一种新的FedMobile框架，该框架能够在缺失模态的情况下实现稳健学习，并优先考虑本地到全局的知识转移，利用跨节点的多模态特征信息来重建缺失特征。FedMobile还通过严格的节点贡献评估和知识贡献知情聚合规则来增强系统的性能和对模态异质性的鲁棒性。在五个广泛认可的多模态基准数据集上的实证评估表明，即使在缺失高达90%的模态信息或随机缺失两种模态的数据时，FedMobile也能保持稳健学习，并且在性能上优于最先进的基线方法。', 'title_zh': 'FedMobile: 促进多模态联邦学习中的知识贡献意识框架在不完整模态下的应用'}
{'arxiv_id': 'arXiv:2502.15833', 'title': 'Advancing Out-of-Distribution Detection via Local Neuroplasticity', 'authors': 'Alessandro Canevaro, Julian Schmidt, Mohammad Sajad Marvi, Hang Yu, Georg Martius, Julian Jordan', 'link': 'https://arxiv.org/abs/2502.15833', 'abstract': 'In the domain of machine learning, the assumption that training and test data share the same distribution is often violated in real-world scenarios, requiring effective out-of-distribution (OOD) detection. This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs). Unlike traditional multilayer perceptrons, KANs exhibit local plasticity, allowing them to preserve learned information while adapting to new tasks. Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples. We validate our approach on benchmarks from image and medical domains, demonstrating superior performance and robustness compared to state-of-the-art techniques. These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.', 'abstract_zh': '机器学习领域中的机器学习在现实场景中通常假设训练数据和测试数据共享相同的分布，这要求有效进行异常分布外（OOD）检测。本文提出了一种利用Kolmogorov-Arnold网络（KANs）的独特局部神经可塑性性质的新颖OOD检测方法。与传统的多层感知机不同，KANs表现出局部可塑性，使其能够在适应新任务的同时保留已学习的信息。我们的方法通过将训练后的KAN与未训练的版本的激活模式进行对比来检测OOD样本。我们通过来自图像和医疗领域的基准测试验证了该方法，展示了其在性能和鲁棒性方面优于现有技术。这些结果突显了KANs在提高不同环境中机器学习系统的可靠性方面的潜力。', 'title_zh': '基于局部神经可塑性的.out-of-distribution检测进步'}
{'arxiv_id': 'arXiv:2502.15830', 'title': 'Show Me Your Code! Kill Code Poisoning: A Lightweight Method Based on Code Naturalness', 'authors': 'Weisong Sun, Yuchen Chen, Mengzhe Yuan, Chunrong Fang, Zhenpeng Chen, Chong Wang, Yang Liu, Baowen Xu, Zhenyu Chen', 'link': 'https://arxiv.org/abs/2502.15830', 'abstract': 'Neural code models (NCMs) have demonstrated extraordinary capabilities in code intelligence tasks. Meanwhile, the security of NCMs and NCMs-based systems has garnered increasing attention. In particular, NCMs are often trained on large-scale data from potentially untrustworthy sources, providing attackers with the opportunity to manipulate them by inserting crafted samples into the data. This type of attack is called a code poisoning attack (also known as a backdoor attack). It allows attackers to implant backdoors in NCMs and thus control model behavior, which poses a significant security threat. However, there is still a lack of effective techniques for detecting various complex code poisoning attacks.\nIn this paper, we propose an innovative and lightweight technique for code poisoning detection named KillBadCode. KillBadCode is designed based on our insight that code poisoning disrupts the naturalness of code. Specifically, KillBadCode first builds a code language model (CodeLM) on a lightweight $n$-gram language model. Then, given poisoned data, KillBadCode utilizes CodeLM to identify those tokens in (poisoned) code snippets that will make the code snippets more natural after being deleted as trigger tokens. Considering that the removal of some normal tokens in a single sample might also enhance code naturalness, leading to a high false positive rate (FPR), we aggregate the cumulative improvement of each token across all samples. Finally, KillBadCode purifies the poisoned data by removing all poisoned samples containing the identified trigger tokens. The experimental results on two code poisoning attacks and four code intelligence tasks demonstrate that KillBadCode significantly outperforms four baselines. More importantly, KillBadCode is very efficient, with a minimum time consumption of only 5 minutes, and is 25 times faster than the best baseline on average.', 'abstract_zh': '基于代码自然度感知的杀毒代码检测方法：KillBadCode', 'title_zh': '展示你的代码！消除代码中毒：一种基于代码自然度的轻量级方法'}
{'arxiv_id': 'arXiv:2502.15827', 'title': 'Explainable Artificial Intelligence Model for Evaluating Shear Strength Parameters of Municipal Solid Waste Across Diverse Compositional Profiles', 'authors': 'Parichat Suknark, Sompote Youwaib, Tipok Kitkobsin, Sirintornthep Towprayoon, Chart Chiemchaisri, Komsilp Wangyao', 'link': 'https://arxiv.org/abs/2502.15827', 'abstract': "Accurate prediction of shear strength parameters in Municipal Solid Waste (MSW) remains a critical challenge in geotechnical engineering due to the heterogeneous nature of waste materials and their temporal evolution through degradation processes. This paper presents a novel explainable artificial intelligence (XAI) framework for evaluating cohesion and friction angle across diverse MSW compositional profiles. The proposed model integrates a multi-layer perceptron architecture with SHAP (SHapley Additive exPlanations) analysis to provide transparent insights into how specific waste components influence strength characteristics. Training data encompassed large-scale direct shear tests across various waste compositions and degradation states. The model demonstrated superior predictive accuracy compared to traditional gradient boosting methods, achieving mean absolute percentage errors of 7.42% and 14.96% for friction angle and cohesion predictions, respectively. Through SHAP analysis, the study revealed that fibrous materials and particle size distribution were primary drivers of shear strength variation, with food waste and plastics showing significant but non-linear effects. The model's explainability component successfully quantified these relationships, enabling evidence-based recommendations for waste management practices. This research bridges the gap between advanced machine learning and geotechnical engineering practice, offering a reliable tool for rapid assessment of MSW mechanical properties while maintaining interpretability for engineering decision-making.", 'abstract_zh': '市政固体废物(MSW)剪切强度参数的准确预测仍然是土木工程中的一个关键挑战，由于废物材料的异质性和降解过程中的时间演化。本文提出了一个新颖的可解释人工智能(XAI)框架，用于评估不同MSW组分配置下的凝聚力和摩擦角。提出的模型结合了多层感知器架构与SHAP（SHapley Additive exPlanations）分析，以透明地揭示特定废物组分如何影响强度特性。训练数据涵盖不同废物组成和降解状态的大规模直接剪切试验。该模型在摩擦角和凝聚力预测方面的预测准确性均优于传统梯度提升方法，分别实现了7.42%和14.96%的平均绝对百分比误差。通过SHAP分析，研究发现纤维材料和颗粒大小分布是剪切强度变异的主要驱动因素，食物废物和塑料显示出显著但非线性的影响。模型的可解释性组件成功量化了这些关系，使基于证据的废物管理建议成为可能。该研究在先进机器学习与土木工程实践之间架起了桥梁，提供了一个可靠工具进行MSW力学性质的快速评估，同时保持了工程决策的可解释性。', 'title_zh': '解释性人工智能模型：评估不同组分特征下城市固体废物剪切强度参数'}
{'arxiv_id': 'arXiv:2502.15825', 'title': 'Utilizing AI and Machine Learning for Predictive Analysis of Post-Treatment Cancer Recurrence', 'authors': 'Muhammad Umer Qayyum, Muhammad Fahad, Nasrullah Abbasi', 'link': 'https://arxiv.org/abs/2502.15825', 'abstract': "In oncology, recurrence after treatment is one of the major challenges, related to patients' survival and quality of life. Conventionally, prediction of cancer relapse has always relied on clinical observation with statistical model support, which almost fails to explain the complex, multifactorial nature of tumor recurrence. This research explores how AI and ML models may increase the accuracy and reliability of recurrence prediction in cancer. Therefore, AI and ML create new opportunities not only for personalized medicine but also for proactive management of patients through analyzing large volumes of data on genetics, clinical manifestations, and treatment. The paper describes the various AI and ML techniques for pattern identification and outcome prediction in cancer patients using supervised and unsupervised learning. Clinical implications provide an opportunity to review how early interventions could happen and the design of treatment planning.", 'abstract_zh': '在肿瘤学中，治疗后的复发是主要挑战之一，影响患者的生存率和生活质量。 conventionally, 预测癌症复发一直依赖于临床观察和统计模型的支持，几乎无法解释肿瘤复发的复杂性和多因素性。该研究探讨了人工智能和机器学习模型如何提高癌症复发预测的准确性和可靠性。因此，人工智能和机器学习不仅为个性化的医疗提供了新机会，也为通过分析遗传学、临床表现和治疗的大规模数据来进行积极的患者管理创造了新机会。该论文描述了使用监督和无监督学习在癌症患者中识别模式和预测结局的各种人工智能和机器学习技术。临床意义提供了审查早期干预如何发生以及治疗计划设计的机会。', 'title_zh': '利用人工智能和机器学习进行治疗后癌症复发的预测分析'}
{'arxiv_id': 'arXiv:2502.15821', 'title': 'Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization', 'authors': 'Keane Ong, Rui Mao, Deeksha Varshney, Erik Cambria, Gianmarco Mengaldo', 'link': 'https://arxiv.org/abs/2502.15821', 'abstract': "Sustainability reports are key for evaluating companies' environmental, social and governance, ESG performance, but their content is increasingly obscured by greenwashing - sustainability claims that are misleading, exaggerated, and fabricated. Yet, existing NLP approaches for ESG analysis lack robustness against greenwashing risks, often extracting insights that reflect misleading or exaggerated sustainability claims rather than objective ESG performance. To bridge this gap, we introduce A3CG - Aspect-Action Analysis with Cross-Category Generalization, as a novel dataset to improve the robustness of ESG analysis amid the prevalence of greenwashing. By explicitly linking sustainability aspects with their associated actions, A3CG facilitates a more fine-grained and transparent evaluation of sustainability claims, ensuring that insights are grounded in verifiable actions rather than vague or misleading rhetoric. Additionally, A3CG emphasizes cross-category generalization. This ensures robust model performance in aspect-action analysis even when companies change their reports to selectively favor certain sustainability areas. Through experiments on A3CG, we analyze state-of-the-art supervised models and LLMs, uncovering their limitations and outlining key directions for future research.", 'abstract_zh': '可持续性报告是评估企业环境、社会和治理（ESG）表现的关键，但随着绿色洗牌现象的增加，其内容逐渐变得模糊不清——绿色洗牌指的是一种误导性、夸大性和虚假的可持续性声明。然而，现有的自然语言处理（NLP）方法在应对绿色洗牌风险方面缺乏 robustness，经常提取反映误导性或夸大的可持续性声明而非客观的ESG表现。为弥补这一差距，我们提出了A3CG——基于跨类别泛化的方面-行动分析，作为一种新的数据集，旨在在绿色洗牌普遍存在的背景下提高ESG分析的稳健性。通过明确将可持续性方面与其相关行动联系起来，A3CG促进了一种更精细和透明的可持续性声明评估，确保见解基于可验证的实际行动而非模糊或误导性的言论。此外，A3CG强调跨类别泛化。这确保了即使公司在报告中有所改变以选择性地强调某些可持续性领域，方面-行动分析的模型性能依然稳固。通过A3CG上的实验，我们分析了最先进的监督模型和大语言模型，揭示了它们的局限性，并指出了未来研究的关键方向。', 'title_zh': '面向绿色 rinsing 风险的稳健ESG分析：跨类别泛化下的方面-行动分析'}
{'arxiv_id': 'arXiv:2502.15819', 'title': 'Tabular Embeddings for Tables with Bi-Dimensional Hierarchical Metadata and Nesting', 'authors': 'Gyanendra Shrestha, Chutain Jiang, Sai Akula, Vivek Yannam, Anna Pyayt, Michael Gubanov', 'link': 'https://arxiv.org/abs/2502.15819', 'abstract': 'Embeddings serve as condensed vector representations for real-world entities, finding applications in Natural Language Processing (NLP), Computer Vision, and Data Management across diverse downstream tasks. Here, we introduce novel specialized embeddings optimized, and explicitly tailored to encode the intricacies of complex 2-D context in tables, featuring horizontal, vertical hierarchical metadata, and nesting. To accomplish that we define the Bi-dimensional tabular coordinates, separate horizontal, vertical metadata and data contexts by introducing a new visibility matrix, encode units and nesting through the embeddings specifically optimized for mimicking intricacies of such complex structured data. Through evaluation on 5 large-scale structured datasets and 3 popular downstream tasks, we observed that our solution outperforms the state-of-the-art models with the significant MAP delta of up to 0.28. GPT-4 LLM+RAG slightly outperforms us with MRR delta of up to 0.1, while we outperform it with the MAP delta of up to 0.42.', 'abstract_zh': '嵌入式表示作为现实世界实体的凝练向量表示，在自然语言处理（NLP）、计算机视觉和数据管理等多样化下游任务中得到应用。在此，我们引入了专门优化的二维表格嵌入，用于编码复杂二维上下文的 intricacies，包括水平、垂直层次元数据和嵌套。为此，我们定义了二维表格坐标，通过引入新的可见性矩阵分离水平、垂直元数据和数据上下文，通过专门优化的嵌入编码单元和嵌套，以模拟此类复杂结构化数据的 intricacies。通过在 5 个大规模结构化数据集和 3 个流行下游任务上的评估，我们发现我们的解决方案在 MAP 性能上显著优于现有最佳模型，达到 0.28 的显著 MAP 增量。GPT-4 大语言模型+检索增强 barely 击败我们，MAP 增量达到 0.1，而我们在 MAP 上的增益达到 0.42。', 'title_zh': '具有二维层次元数据和嵌套结构的表格的表嵌入'}
{'arxiv_id': 'arXiv:2502.15815', 'title': 'Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics', 'authors': 'Daniel J.H. Chung, Zhiqi Gao, Yurii Kvasiuk, Tianyi Li, Moritz Münchmeyer, Maja Rudolph, Frederic Sala, Sai Chaitanya Tadepalli', 'link': 'https://arxiv.org/abs/2502.15815', 'abstract': 'We introduce a benchmark to evaluate the capability of AI to solve problems in theoretical physics, focusing on high-energy theory and cosmology. The first iteration of our benchmark consists of 57 problems of varying difficulty, from undergraduate to research level. These problems are novel in the sense that they do not come from public problem collections. We evaluate our data set on various open and closed language models, including o3-mini, o1, DeepSeek-R1, GPT-4o and versions of Llama and Qwen. While we find impressive progress in model performance with the most recent models, our research-level difficulty problems are mostly unsolved. We address challenges of auto-verifiability and grading, and discuss common failure modes. While currently state-of-the art models are still of limited use for researchers, our results show that AI assisted theoretical physics research may become possible in the near future. We discuss the main obstacles towards this goal and possible strategies to overcome them. The public problems and solutions, results for various models, and updates to the data set and score distribution, are available on the website of the dataset this http URL.', 'abstract_zh': '我们介绍了一个基准来评估AI在理论物理领域解决问题的能力，重点关注高能物理和宇宙学。第一个迭代基准由57个难度各异的问题组成，从本科到研究级别。这些问题具有新颖性，不来源于公开的问题集合。我们使用多种开放和封闭的语言模型进行评估，包括o3-mini、o1、DeepSeek-R1、GPT-4o以及Llama和Qwen的版本。尽管最新的模型在模型性能上取得了令人印象深刻的进展，但我们研究级别的难题大多尚未解决。我们讨论了自动化验证和评分的挑战及常见失败模式。虽然当前最先进的模型尚无法广泛应用于研究工作，但我们的研究结果表明，AI辅助的理论物理研究可能在不久的将来成为可能。我们讨论了实现这一目标的主要障碍及可能的应对策略。问题和解决方案、各种模型的结果、数据集和评分分布的更新等内容可在该数据集的官方网站上找到：this http URL。', 'title_zh': '理论物理学基准（TPBench）——一个数据集及其在理论物理学中的人工智能推理能力研究'}
{'arxiv_id': 'arXiv:2502.15813', 'title': 'Stock Price Prediction Using a Hybrid LSTM-GNN Model: Integrating Time-Series and Graph-Based Analysis', 'authors': 'Meet Satishbhai Sonani, Atta Badii, Armin Moin', 'link': 'https://arxiv.org/abs/2502.15813', 'abstract': 'This paper presents a novel hybrid model that integrates long-short-term memory (LSTM) networks and Graph Neural Networks (GNNs) to significantly enhance the accuracy of stock market predictions. The LSTM component adeptly captures temporal patterns in stock price data, effectively modeling the time series dynamics of financial markets. Concurrently, the GNN component leverages Pearson correlation and association analysis to model inter-stock relational data, capturing complex nonlinear polyadic dependencies influencing stock prices. The model is trained and evaluated using an expanding window validation approach, enabling continuous learning from increasing amounts of data and adaptation to evolving market conditions. Extensive experiments conducted on historical stock data demonstrate that our hybrid LSTM-GNN model achieves a mean square error (MSE) of 0.00144, representing a substantial reduction of 10.6% compared to the MSE of the standalone LSTM model of 0.00161. Furthermore, the hybrid model outperforms traditional and advanced benchmarks, including linear regression, convolutional neural networks (CNN), and dense networks. These compelling results underscore the significant potential of combining temporal and relational data through a hybrid approach, offering a powerful tool for real-time trading and financial analysis.', 'abstract_zh': '本文提出了一种将长短期记忆（LSTM）网络和图神经网络（GNN）相结合的新型混合模型，以显著提高股市预测的准确性。该LSTM组件有效地捕捉股票价格数据中的时间序列模式，有效地建模了金融市场的时间序列动力学。同时，GNN组件利用皮尔逊相关分析和关联分析来建模股票间的交互关系数据，捕捉影响股票价格的复杂非线性多元依赖关系。该模型采用扩展窗口验证方法进行训练和评估，能够连续从不断增加的数据中学习，并适应不断变化的市场条件。在历史股票数据上的 extensive 实验表明，我们的混合 LSTM-GNN 模型均方误差（MSE）为 0.00144，与单独使用的LSTM模型的MSE 0.00161相比，降低了10.6%。此外，该混合模型在传统和先进的基准模型（包括线性回归、卷积神经网络（CNN）和密集网络）中表现出色。这些引人注目的结果强调了通过混合方法结合时间序列和关系数据的巨大潜力，提供了一个强大的工具，用于实时交易和金融分析。', 'title_zh': '基于混合LSTM-GNN模型的股票价格预测：结合时间序列与图基线分析'}
{'arxiv_id': 'arXiv:2502.15812', 'title': 'InsightVision: A Comprehensive, Multi-Level Chinese-based Benchmark for Evaluating Implicit Visual Semantics in Large Vision Language Models', 'authors': 'Xiaofei Yin, Yijie Hong, Ya Guo, Yi Tu, Weiqiang Wang, Gongshen Liu, Huijia zhu', 'link': 'https://arxiv.org/abs/2502.15812', 'abstract': 'In the evolving landscape of multimodal language models, understanding the nuanced meanings conveyed through visual cues - such as satire, insult, or critique - remains a significant challenge. Existing evaluation benchmarks primarily focus on direct tasks like image captioning or are limited to a narrow set of categories, such as humor or satire, for deep semantic understanding. To address this gap, we introduce, for the first time, a comprehensive, multi-level Chinese-based benchmark designed specifically for evaluating the understanding of implicit meanings in images. This benchmark is systematically categorized into four subtasks: surface-level content understanding, symbolic meaning interpretation, background knowledge comprehension, and implicit meaning comprehension. We propose an innovative semi-automatic method for constructing datasets, adhering to established construction protocols. Using this benchmark, we evaluate 15 open-source large vision language models (LVLMs) and GPT-4o, revealing that even the best-performing model lags behind human performance by nearly 14% in understanding implicit meaning. Our findings underscore the intrinsic challenges current LVLMs face in grasping nuanced visual semantics, highlighting significant opportunities for future research and development in this domain. We will publicly release our InsightVision dataset, code upon acceptance of the paper.', 'abstract_zh': '在多模态语言模型不断演进的背景下，理解通过视觉线索（如讽刺、侮辱或批判）传达的微妙含义仍是一个重大挑战。现有的评估基准主要集中在直接任务，如图像字幕上，或者仅限于幽默或讽刺等狭窄的类别以实现深层次语义理解。为填补这一空白，我们首次提出一个全面的多级中文基准，专门用于评估图像中隐含意义的理解能力。该基准系统地分为四个子任务：表层内容理解、象征性意义解释、背景知识理解以及隐含意义理解。我们提出了一种创新的半自动数据集构建方法，遵循既定的构建协议。使用此基准，我们评估了15个开源大型视觉语言模型（LVLMs）和GPT-4o，结果显示，即便是性能最佳的模型在理解隐含意义方面也落后人类约14%。我们的研究结果凸显了当前LVLMs在掌握细腻视觉语义方面固有的挑战，指出了该领域未来研究与开发的重要机会。我们将公开发表我们的InsightVision数据集及代码。', 'title_zh': 'InsightVision: 一个全面的多级中文基准，用于评估大型视觉语言模型中的隐含视觉语义'}
{'arxiv_id': 'arXiv:2502.15805', 'title': 'FragFM: Efficient Fragment-Based Molecular Generation via Discrete Flow Matching', 'authors': 'Joongwon Lee, Seonghwan Kim, Wou Youn Kim', 'link': 'https://arxiv.org/abs/2502.15805', 'abstract': 'We introduce FragFM, a novel fragment-based discrete flow matching framework for molecular graph this http URL generates molecules at the fragment level, leveraging a coarse-to-fine autoencoding mechanism to reconstruct atom-level details. This approach reduces computational complexity while maintaining high chemical validity, enabling more efficient and scalable molecular generation. We benchmark FragFM against state-of-the-art diffusion- and flow-based models on standard molecular generation benchmarks and natural product datasets, demonstrating superior performance in validity, property control, and sampling efficiency. Notably, FragFM achieves over 99\\% validity with significantly fewer sampling steps, improving scalability while preserving molecular diversity. These results highlight the potential of fragment-based generative modeling for large-scale, property-aware molecular design, paving the way for more efficient exploration of chemical space.', 'abstract_zh': '基于片段的离散流匹配框架FragFM：高效可扩展的分子图生成方法', 'title_zh': 'FragFM：通过离散流匹配的高效片段基分子生成'}
{'arxiv_id': 'arXiv:2502.15804', 'title': 'FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference', 'authors': 'Bingzhe Zhao, Ke Cheng, Aomufei Yuan, Yuxuan Tian, Ruiguang Zhong, Chengchen Hu, Tong Yang, Lian Yu', 'link': 'https://arxiv.org/abs/2502.15804', 'abstract': 'KV cache techniques in Transformer models aim to reduce redundant computations at the expense of substantially increased memory usage, making KV cache compression an important and popular research topic. Recently, state-of-the-art KV cache compression methods implement imbalanced, per-head allocation algorithms that dynamically adjust the KV cache budget for each attention head, achieving excellent performance in single-GPU scenarios. However, we observe that such imbalanced compression leads to significant load imbalance when deploying multi-GPU inference, as some GPUs become overburdened while others remain underutilized. In this paper, we propose FairKV, a method designed to ensure fair memory usage among attention heads in systems employing imbalanced KV cache compression. The core technique of FairKV is Fair-Copying, which replicates a small subset of memory-intensive attention heads across GPUs using data parallelism to mitigate load imbalance. Our experiments on popular models, including LLaMA 70b and Mistral 24b model, demonstrate that FairKV increases throughput by 1.66x compared to standard tensor parallelism inference. Our code will be released as open source upon acceptance.', 'abstract_zh': 'Transformer模型中的KV缓存技术旨在通过大幅增加内存使用来减少冗余计算，因此KV缓存压缩成为一个重要的研究热点。目前最先进的KV缓存压缩方法实现了不平衡的、按头分配的算法，能够根据每个注意力头动态调整KV缓存预算，在单GPU场景中表现出色。然而，我们观察到这种不平衡的压缩在部署多GPU推理时会导致显著的负载不平衡，一些GPU变得超载，而其他GPU则被严重闲置。在本文中，我们提出FairKV方法，以确保在采用不平衡KV缓存压缩的系统中各注意力头之间的公平内存使用。FairKV的核心技术是Fair-Copying，它利用数据并行性复制一小部分内存密集型注意力头到多个GPU，以减轻负载不平衡。在包括LLaMA 70b和Mistral 24b在内的流行模型上的实验表明，与标准张量并行推理相比，FairKV的吞吐量提高了1.66倍。在被接受后，我们的代码将作为开源发布。', 'title_zh': 'FairKV：平衡每个GPU头的KV缓存以实现快速多GPU推理'}
{'arxiv_id': 'arXiv:2502.15802', 'title': 'A General Error-Theoretical Analysis Framework for Constructing Compression Strategies', 'authors': 'Boyang Zhang, Daning Cheng, Yunquan Zhang, Meiqi Tu, Fangmin Liu, Jiake Tian', 'link': 'https://arxiv.org/abs/2502.15802', 'abstract': 'The exponential growth in parameter size and computational complexity of deep models poses significant challenges for efficient deployment. The core problem of existing compression methods is that different layers of the model have significant differences in their tolerance to compression levels. For instance, the first layer of a model can typically sustain a higher compression level compared to the last layer without compromising performance. Thus, the key challenge lies in how to allocate compression levels across layers in a way that minimizes performance loss while maximizing parameter reduction. To address this challenge, we propose a Compression Error Theory (CET) framework, designed to determine the optimal compression level for each layer. Taking quantization as an example, CET leverages differential expansion and algebraic geometry to reconstruct the quadratic form of quantization error as ellipsoids and hyperbolic paraboloids, and utilizes their geometric structures to define an error subspace. To identify the error subspace with minimal performance loss, by performing orthogonal decomposition of the geometric space, CET transforms the optimization process of the error subspace into a complementary problem. The final theoretical analysis shows that constructing the quantization subspace along the major axis results in minimal performance degradation. Through experimental verification of the theory, CET can greatly retain performance while compressing. Specifically, on the ResNet-34 model, CET achieves nearly 11$\\times$ parameter compression while even surpassing performance comparable to the original model.', 'abstract_zh': '深度模型参数规模和计算复杂性的指数增长对高效部署提出了显著挑战。现有压缩方法的核心问题是模型不同层对压缩水平的容忍度存在显著差异。例如，模型的第一层通常可以比最后一层承受更高的压缩水平而不牺牲性能。因此，关键挑战在于如何在减少性能损失的同时最大化参数减少，合理分配各层的压缩水平。为应对这一挑战，我们提出了一种压缩误差理论（CET）框架，旨在为每层确定最优压缩水平。以量化为例，CET 利用微分扩展和代数几何将量化误差的二次形式重构为椭球体和双曲抛物面，并利用其几何结构定义误差子空间。为在最小化性能损失的情况下识别误差子空间，通过几何空间的正交分解，CET 将误差子空间的优化过程转化为互补问题。最终的理论分析表明，沿着主轴构建量化子空间可导致最小的性能退化。通过理论验证实验，CET 可以在压缩的同时大幅保留性能。具体而言，在 ResNet-34 模型上，CET 实现了近 11 倍的参数压缩，甚至超越了原始模型的性能。', 'title_zh': '一种构建压缩策略的一般误差理论分析框架'}
{'arxiv_id': 'arXiv:2502.15798', 'title': 'MaxSup: Overcoming Representation Collapse in Label Smoothing', 'authors': 'Yuxuan Zhou, Heng Li, Zhi-Qi Cheng, Xudong Yan, Mario Fritz, Margret Keuper', 'link': 'https://arxiv.org/abs/2502.15798', 'abstract': 'Label Smoothing (LS) is widely adopted to curb overconfidence in neural network predictions and enhance generalization. However, previous research shows that LS can force feature representations into excessively tight clusters, eroding intra-class distinctions. More recent findings suggest that LS also induces overconfidence in misclassifications, yet the precise mechanism remained unclear. In this work, we decompose the loss term introduced by LS, revealing two key components: (i) a regularization term that functions only when the prediction is correct, and (ii) an error-enhancement term that emerges under misclassifications. This latter term compels the model to reinforce incorrect predictions with exaggerated certainty, further collapsing the feature space. To address these issues, we propose Max Suppression (MaxSup), which uniformly applies the intended regularization to both correct and incorrect predictions by penalizing the top-1 logit instead of the ground-truth logit. Through feature analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Extensive experiments on image classification and downstream tasks confirm that MaxSup is a more robust alternative to LS. Code is available at: this https URL.', 'abstract_zh': '标签平滑（LS）广泛用于抑制神经网络预测中的过度自信并提高泛化能力。然而，先前的研究表明，LS 可能会导致特征表示形成过于紧凑的聚类，侵蚀类内区别。更近期的研究指出，LS 还会导致误分类中的过度自信，但其具体机制尚不清楚。在本工作中，我们分解了由LS引入的损失项，揭示了两个关键成分：（i）仅在预测正确时起作用的正则化项，以及（ii）在误分类时出现的错误增强项。这一后一项促使模型通过过度的信心强化错误预测，进一步压缩特征空间。为解决这些问题，我们提出了一种最大抑制（MaxSup）方法，该方法通过惩罚最高置信度而不是真实标签置信度，均匀地对正确和错误预测应用预期的正则化。通过特征分析，我们展示了MaxSup恢复了类内变异性并细化了类间边界。广泛的图像分类和下游任务实验表明，MaxSup 是比LS 更为稳健的替代方案。代码可访问：this https URL。', 'title_zh': 'MaxSup: 克服标签平滑中的表示崩溃问题'}
{'arxiv_id': 'arXiv:2502.15794', 'title': 'Self-Supervised Transformers as Iterative Solution Improvers for Constraint Satisfaction', 'authors': 'Yudong W. Xu, Wenhao Li, Scott Sanner, Elias B. Khalil', 'link': 'https://arxiv.org/abs/2502.15794', 'abstract': 'We present a Transformer-based framework for Constraint Satisfaction Problems (CSPs). CSPs find use in many applications and thus accelerating their solution with machine learning is of wide interest. Most existing approaches rely on supervised learning from feasible solutions or reinforcement learning, paradigms that require either feasible solutions to these NP-Complete CSPs or large training budgets and a complex expert-designed reward signal. To address these challenges, we propose ConsFormer, a self-supervised framework that leverages a Transformer as a solution refiner. ConsFormer constructs a solution to a CSP iteratively in a process that mimics local search. Instead of using feasible solutions as labeled data, we devise differentiable approximations to the discrete constraints of a CSP to guide model training. Our model is trained to improve random assignments for a single step but is deployed iteratively at test time, circumventing the bottlenecks of supervised and reinforcement learning. Our method can tackle out-of-distribution CSPs simply through additional iterations.', 'abstract_zh': '基于Transformer的约束 satisfication 问题框架', 'title_zh': '自监督变换器作为约束 satisfaction 问题迭代解改善器'}
{'arxiv_id': 'arXiv:2502.15791', 'title': 'Learning-Guided Rolling Horizon Optimization for Long-Horizon Flexible Job-Shop Scheduling', 'authors': 'Sirui Li, Wenbin Ouyang, Yining Ma, Cathy Wu', 'link': 'https://arxiv.org/abs/2502.15791', 'abstract': 'Long-horizon combinatorial optimization problems (COPs), such as the Flexible Job-Shop Scheduling Problem (FJSP), often involve complex, interdependent decisions over extended time frames, posing significant challenges for existing solvers. While Rolling Horizon Optimization (RHO) addresses this by decomposing problems into overlapping shorter-horizon subproblems, such overlap often involves redundant computations. In this paper, we present L-RHO, the first learning-guided RHO framework for COPs. L-RHO employs a neural network to intelligently fix variables that in hindsight did not need to be re-optimized, resulting in smaller and thus easier-to-solve subproblems. For FJSP, this means identifying operations with unchanged machine assignments between consecutive subproblems. Applied to FJSP, L-RHO accelerates RHO by up to 54% while significantly improving solution quality, outperforming other heuristic and learning-based baselines. We also provide in-depth discussions and verify the desirable adaptability and generalization of L-RHO across numerous FJSP variates, distributions, online scenarios and benchmark instances. Moreover, we provide a theoretical analysis to elucidate the conditions under which learning is beneficial.', 'abstract_zh': '长时域组合优化问题的学习引导滚动波段优化框架', 'title_zh': '学习导向的滚动时障优化方法及其在长时障柔性作业车间调度中的应用'}
{'arxiv_id': 'arXiv:2502.15790', 'title': 'Signal Collapse in One-Shot Pruning: When Sparse Models Fail to Distinguish Neural Representations', 'authors': 'Dhananjay Saikumar, Blesson Varghese', 'link': 'https://arxiv.org/abs/2502.15790', 'abstract': 'Neural network pruning is essential for reducing model complexity to enable deployment on resource constrained hardware. While performance loss of pruned networks is often attributed to the removal of critical parameters, we identify signal collapse a reduction in activation variance across layers as the root cause. Existing one shot pruning methods focus on weight selection strategies and rely on computationally expensive second order approximations. In contrast, we demonstrate that mitigating signal collapse, rather than optimizing weight selection, is key to improving accuracy of pruned networks. We propose REFLOW that addresses signal collapse without updating trainable weights, revealing high quality sparse sub networks within the original parameter space. REFLOW enables magnitude pruning to achieve state of the art performance, restoring ResNeXt101 accuracy from under 4.1% to 78.9% on ImageNet with only 20% of the weights retained, surpassing state of the art approaches.', 'abstract_zh': '神经网络剪枝对于减少模型复杂度以在资源受限硬件上部署至关重要。虽然剪枝网络的性能损失通常归因于关键参数的移除，我们发现信号塌缩——层间激活方差的减少——才是根本原因。现有的单次剪枝方法专注于权重选择策略，并依赖于计算成本高昂的二阶近似。相比之下，我们证明了缓解信号塌缩而非优化权重选择是提升剪枝网络精度的关键。我们提出了REFLOW，该方法在不更新可训练权重的情况下解决了信号塌缩问题，在原始参数空间内揭示了高质量的稀疏子网络。REFLOW使幅度剪枝达到最佳性能，仅保留20%的权重即可将ImageNet上的ResNeXt101精度从不到4.1%恢复到78.9%，超越了最佳方法。', 'title_zh': '一次裁剪中的信号坍塌：稀疏模型为何无法区分神经表示'}
{'arxiv_id': 'arXiv:2502.15785', 'title': 'Masking the Gaps: An Imputation-Free Approach to Time Series Modeling with Missing Data', 'authors': 'Abhilash Neog, Arka Daw, Sepideh Fatemi Khorasgani, Anuj Karpatne', 'link': 'https://arxiv.org/abs/2502.15785', 'abstract': 'A significant challenge in time-series (TS) modeling is the presence of missing values in real-world TS datasets. Traditional two-stage frameworks, involving imputation followed by modeling, suffer from two key drawbacks: (1) the propagation of imputation errors into subsequent TS modeling, (2) the trade-offs between imputation efficacy and imputation complexity. While one-stage approaches attempt to address these limitations, they often struggle with scalability or fully leveraging partially observed features. To this end, we propose a novel imputation-free approach for handling missing values in time series termed Missing Feature-aware Time Series Modeling (MissTSM) with two main innovations. First, we develop a novel embedding scheme that treats every combination of time-step and feature (or channel) as a distinct token. Second, we introduce a novel Missing Feature-Aware Attention (MFAA) Layer to learn latent representations at every time-step based on partially observed features. We evaluate the effectiveness of MissTSM in handling missing values over multiple benchmark datasets.', 'abstract_zh': '一种时间序列（TS）建模中的显著挑战是在实际TS数据集中存在缺失值。传统的两阶段框架，涉及插补随后进行建模，存在两个关键缺点：（1）插补误差传播到后续TS建模中，（2）插补效果与插补复杂度之间的权衡。尽管一阶段方法试图解决这些限制，但它们往往在可扩展性或充分利用部分观测特征方面存在问题。为此，我们提出了一种称为缺失特征感知时间序列建模（MissTSM）的新颖无插补方法，包含两大创新。首先，我们开发了一种新的嵌入方案，将每个时间步和特征（或通道）的组合视为一个独特的 token。其次，我们引入了一种新颖的缺失特征感知注意（MFAA）层，用于根据部分观测特征学习每个时间步的潜变量表示。我们评估了MissTSM在多个基准数据集上处理缺失值的有效性。', 'title_zh': '掩蔽缺口：一种无插补的缺失数据时间序列建模方法'}
{'arxiv_id': 'arXiv:2502.15780', 'title': 'Feature Engineering Approach to Building Load Prediction: A Case Study for Commercial Building Chiller Plant Optimization in Tropical Weather', 'authors': 'Zhan Wang, Chen Weidong, Huang Zhifeng, Md Raisul Islam, Chua Kian Jon', 'link': 'https://arxiv.org/abs/2502.15780', 'abstract': "In tropical countries with high humidity, air conditioning can account for up to 60% of a building's energy use. For commercial buildings with centralized systems, the efficiency of the chiller plant is vital, and model predictive control provides an effective strategy for optimizing operations through dynamic adjustments based on accurate load predictions. Artificial neural networks are effective for modelling nonlinear systems but are prone to overfitting due to their complexity. Effective feature engineering can mitigate this issue. While weather data are crucial for load prediction, they are often used as raw numerical inputs without advanced processing. Clustering features is a technique that can reduce model complexity and enhance prediction accuracy. Although previous studies have explored clustering algorithms for load prediction, none have applied them to multidimensional weather data, revealing a research gap. This study presents a cooling load prediction model that combines a neural network with Kalman filtering and K-means clustering. Applied to real world data from a commercial skyscraper in Singapore's central business district, the model achieved a 46.5% improvement in prediction accuracy. An optimal chiller sequencing strategy was also developed through genetic algorithm optimization of the predictive load, potentially saving 13.8% in energy. Finally, the study evaluated the integration of thermal energy storage into the chiller plant design, demonstrating potential reductions in capital and operational costs of 26% and 13%, respectively.", 'abstract_zh': '在高湿度的热带国家，空调可能占建筑物能源使用量的高达60%。对于具有集中系统的商业建筑，制冷机组的效率至关重要，模型预测控制提供了一种通过基于准确负载预测的动态调整来优化运行的有效策略。人工神经网络适用于建模非线性系统，但由于其复杂性容易过拟合，有效的特征工程可以缓解这一问题。尽管气象数据对于负载预测至关重要，但它们通常未经高级处理即作为原始数值输入使用。聚类特征是一种可以减少模型复杂性和提升预测精度的技术。尽管以往研究已经探讨了聚类算法在负载预测中的应用，但尚未将其应用于多维气象数据，揭示了研究空白。本研究提出了一种结合神经网络、卡尔曼过滤和K-means聚类的冷却负载预测模型。该模型应用于新加坡中央商务区一座商业摩天大楼的实际数据，预测准确性提高了46.5%。还通过遗传算法优化预测负载开发了一种最佳制冷机排序策略，潜在节省了13.8%的能源。最后，研究评估了将热能存储集成到制冷机组设计中的潜力，分别展示了26%和13%的资本成本和运营成本减少。', 'title_zh': '基于特征工程的负荷预测方法：热带气候下商业建筑制冷系统优化的案例研究'}
{'arxiv_id': 'arXiv:2502.15777', 'title': 'TSS GAZ PTP: Towards Improving Gumbel AlphaZero with Two-stage Self-play for Multi-constrained Electric Vehicle Routing Problems', 'authors': 'Hui Wang, Xufeng Zhang, Xiaoyu Zhang, Zhenhuan Ding, Chaoxu Mu', 'link': 'https://arxiv.org/abs/2502.15777', 'abstract': 'Recently, Gumbel AlphaZero~(GAZ) was proposed to solve classic combinatorial optimization problems such as TSP and JSSP by creating a carefully designed competition model~(consisting of a learning player and a competitor player), which leverages the idea of self-play. However, if the competitor is too strong or too weak, the effectiveness of self-play training can be reduced, particularly in complex CO problems. To address this problem, we further propose a two-stage self-play strategy to improve the GAZ method~(named TSS GAZ PTP). In the first stage, the learning player uses the enhanced policy network based on the Gumbel Monte Carlo Tree Search~(MCTS), and the competitor uses the historical best trained policy network~(acts as a greedy player). In the second stage, we employ Gumbel MCTS for both players, which makes the competition fiercer so that both players can continuously learn smarter trajectories. We first investigate the performance of our proposed TSS GAZ PTP method on TSP since it is also used as a test problem by the original GAZ. The results show the superior performance of TSS GAZ PTP. Then we extend TSS GAZ PTP to deal with multi-constrained Electric Vehicle Routing Problems~(EVRP), which is a recently well-known real application research topic and remains challenging as a complex CO problem. Impressively, the experimental results show that the TSS GAZ PTP outperforms the state-of-the-art Deep Reinforcement Learning methods in all types of instances tested and outperforms the optimization solver in tested large-scale instances, indicating the importance and promising of employing more dynamic self-play strategies for complex CO problems.', 'abstract_zh': '最近，提出了Gumbel AlphaZero (GAZ) 方法通过设计竞争模型（包括学习玩家和竞争玩家）来解决如TSP和JSSP的经典组合优化问题，并利用自对弈的思想。然而，如果竞争者太强或太弱，自对弈训练的效果可能会降低，特别是在复杂的组合优化问题中。为了解决这一问题，我们进一步提出了一种两阶段自对弈策略来改进GAZ方法（命名为TSS GAZ PTP）。在第一阶段，学习玩家使用基于Gumbel Monte Carlo Tree Search (MCTS) 的增强策略网络，竞争玩家使用历史最佳训练策略网络（作用为贪婪玩家）。在第二阶段，我们使用Gumbel MCTS 对两个玩家进行操作，从而使竞争更加激烈，使得两个玩家能够不断学习更智能的路径。我们首先在TSP上研究了我们提出的TSS GAZ PTP方法的表现，因为它也被原始的GAZ用作测试问题。结果显示TSS GAZ PTP表现出优越的性能。然后我们将TSS GAZ PTP扩展应用于解决多约束的电动汽车路径规划问题（EVRP），这是一个最近颇受关注的实际应用研究主题，并且仍然是一个复杂的组合优化问题。实验结果令人印象深刻地表明，TSS GAZ PTP在所有类型实例中都优于最先进的深度强化学习方法，并在大规模实例中优于优化求解器，这表明采用更具动态性的自对弈策略对于解决复杂的组合优化问题的重要性及其潜力。', 'title_zh': 'TSS GAZ PTP：通过两阶段自我博弈提高多约束电动汽车路线规划问题的Gumbel AlphaZero'}
{'arxiv_id': 'arXiv:2502.15765', 'title': 'Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow', 'authors': 'Behrooz Azarkhalili, Maxwell Libbrecht', 'link': 'https://arxiv.org/abs/2502.15765', 'abstract': 'This paper introduces Generalized Attention Flow (GAF), a novel feature attribution method for Transformer-based models to address the limitations of current approaches. By extending Attention Flow and replacing attention weights with the generalized Information Tensor, GAF integrates attention weights, their gradients, the maximum flow problem, and the barrier method to enhance the performance of feature attributions. The proposed method exhibits key theoretical properties and mitigates the shortcomings of prior techniques that rely solely on simple aggregation of attention weights. Our comprehensive benchmarking on sequence classification tasks demonstrates that a specific variant of GAF consistently outperforms state-of-the-art feature attribution methods in most evaluation settings, providing a more reliable interpretation of Transformer model outputs.', 'abstract_zh': '这篇论文介绍了通用注意力流（GAF），一种针对Transformer模型的新颖特征归因方法，以解决当前方法的局限性。通过扩展注意力流并将注意力权重替换为通用信息张量，GAF将注意力权重、其梯度、最大流问题和障碍方法结合在一起，以提高特征归因的性能。所提出的方法具备关键的理论性质，并减轻了仅依赖简单注意力权重聚合的先前技术的局限性。我们在序列分类任务上的全面基准测试表明，GAF的特定变体在大多数评估环境下始终优于最先进的特征归因方法，提供了Transformer模型输出更加可靠的解释。', 'title_zh': '广义注意力流：通过最大流进行的变压器模型特征归因'}
{'arxiv_id': 'arXiv:2502.15764', 'title': 'High-Throughput Computational Screening and Interpretable Machine Learning of Metal-organic Frameworks for Iodine Capture', 'authors': 'Haoyi Tan, Yukun Teng, Guangcun Shan', 'link': 'https://arxiv.org/abs/2502.15764', 'abstract': "The removal of leaked radioactive iodine isotopes in humid environments holds significant importance in nuclear waste management and nuclear accident mitigation. In this study, high-throughput computational screening and machine learning were combined to reveal the iodine capture performance of 1816 metal-organic framework (MOF) materials under humid air conditions. Firstly, the relationship between the structural characteristics of MOFs and their adsorption properties was explored, with the aim of identifying the optimal structural parameters for iodine capture. Subsequently, two machine learning regression algorithms - Random Forest and CatBoost, were employed to predict the iodine adsorption capabilities of MOFs. In addition to 6 structural features, 25 molecular features and 8 chemical features were incorporated to enhance the prediction accuracy of the machine learning algorithms. Feature importance was assessed to determine the relative influence of various features on iodine adsorption performance, in which the Henry's coefficient and heat of adsorption to iodine were found the two most crucial chemical factors. Furthermore, four types of molecular fingerprints were introduced for providing comprehensive and detailed structural information of MOF materials. The top 20 most significant MACCS molecular fingerprints were picked out, revealing that the presence of six-membered ring structures and nitrogen atoms in the MOFs were the key structural factors that enhanced iodine adsorption, followed by the existence of oxygen atoms. This work combined high-throughput computation, machine learning, and molecular fingerprints to comprehensively elucidate the multifaceted factors influencing the iodine adsorption performance of MOFs, offering profound insightful guidelines for screening and structural design of advanced MOF materials.", 'abstract_zh': '湿环境中泄漏放射性碘同位素的去除在核废料管理和核事故缓解中具有重要意义。本研究结合高通量计算筛选和机器学习，探讨了1816种金属有机框架（MOF）材料在湿空气条件下对碘的捕获性能。首先，研究了MOFs的结构特征与其吸附性能之间的关系，旨在识别碘捕获的最佳结构参数。随后，采用了随机森林和CatBoost两种机器学习回归算法来预测MOFs的碘吸附能力。除了6种结构特征，还纳入了25种分子特征和8种化学特征以提高机器学习算法的预测精度。特征重要性分析确定了各种特征对碘吸附性能的相对影响，发现亨利系数和吸附碘的热力学参数是最关键的化学因素。此外，引入了四种类型的分子指纹图谱，提供了MOF材料的综合和详细结构信息。筛选出了最重要的20种MACCS分子指纹图谱，揭示了六元环结构和氮原子在MOFs中的存在是提高碘吸附的关键结构因素，其次是氧原子的存在。本研究结合高通量计算、机器学习和分子指纹图谱，全面探讨了影响MOFs碘吸附性能的多方面因素，为先进MOF材料的筛选和结构设计提供了深刻的指导。', 'title_zh': '高通量计算筛选及可解释机器学习在碘捕获金属有机框架研究中应用'}
{'arxiv_id': 'arXiv:2502.15762', 'title': 'SmartEdge: Smart Healthcare End-to-End Integrated Edge and Cloud Computing System for Diabetes Prediction Enabled by Ensemble Machine Learning', 'authors': 'Alain Hennebelle, Qifan Dieng, Leila Ismail, Rajkumar Buyya', 'link': 'https://arxiv.org/abs/2502.15762', 'abstract': 'The Internet of Things (IoT) revolutionizes smart city domains such as healthcare, transportation, industry, and education. The Internet of Medical Things (IoMT) is gaining prominence, particularly in smart hospitals and Remote Patient Monitoring (RPM). The vast volume of data generated by IoMT devices should be analyzed in real-time for health surveillance, prognosis, and prediction of diseases. Current approaches relying on Cloud computing to provide the necessary computing and storage capabilities do not scale for these latency-sensitive applications. Edge computing emerges as a solution by bringing cloud services closer to IoMT devices. This paper introduces SmartEdge, an AI-powered smart healthcare end-to-end integrated edge and cloud computing system for diabetes prediction. This work addresses latency concerns and demonstrates the efficacy of edge resources in healthcare applications within an end-to-end system. The system leverages various risk factors for diabetes prediction. We propose an Edge and Cloud-enabled framework to deploy the proposed diabetes prediction models on various configurations using edge nodes and main cloud servers. Performance metrics are evaluated using, latency, accuracy, and response time. By using ensemble machine learning voting algorithms we can improve the prediction accuracy by 5% versus a single model prediction.', 'abstract_zh': '物联网(IoT)革命了智慧城市领域的医疗、交通、工业和教育等方面。医疗物联网(IoMT)在智能医院和远程患者监测(RPM)中尤为重要。IoMT设备生成的大量数据应当实时分析，以实现健康监测、预后和疾病预测。当前依赖云计算提供必要计算和存储能力的方法对于这些对延迟敏感的应用不具有可扩展性。边缘计算通过将云计算服务靠近IoMT设备而成为解决方案。本文介绍SmartEdge，一种基于人工智能的端到端集成边缘和云计算系统，用于糖尿病预测。本文解决了延迟问题，并在端到端系统中展示了边缘资源在医疗保健应用中的有效性。该系统利用多种糖尿病风险因素。我们提出了一种边缘和云计算支持的框架，使用边缘节点和主要云服务器部署所提议的糖尿病预测模型。性能指标通过延迟、准确性和响应时间进行评估。通过使用集成机器学习投票算法，我们可以将预测准确性提高5%相对于单一模型预测。', 'title_zh': 'SmartEdge：由集成边缘和云计算系统及集成机器学习.Enable糖尿病预测的智能边缘端到端一体化系统'}
{'arxiv_id': 'arXiv:2502.15757', 'title': 'TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data', 'authors': 'Leonardo Berti, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2502.15757', 'abstract': "Stock Price Trend Prediction (SPTP) based on Limit Order Book (LOB) data is a fundamental challenge in financial markets. Despite advances in deep learning, existing models fail to generalize across different market conditions and struggle to reliably predict short-term trends. Surprisingly, by adapting a simple MLP-based architecture to LOB, we show that we surpass SoTA performance; thus, challenging the necessity of complex architectures. Unlike past work that shows robustness issues, we propose TLOB, a transformer-based model that uses a dual attention mechanism to capture spatial and temporal dependencies in LOB data. This allows it to adaptively focus on the market microstructure, making it particularly effective for longer-horizon predictions and volatile market conditions. We also introduce a new labeling method that improves on previous ones, removing the horizon bias. To assess TLOB's effectiveness, we evaluate it on the well-known FI-2010 benchmark (F1 of 92.8\\%) and on Tesla (+2.67\\% on F1) and Intel (+14.16\\% on F1). Additionally, we empirically show how stock price predictability has declined over time (-6.68 absolute points in F1), highlighting the growing market efficiencies. Predictability must be considered in relation to transaction costs, so we experimented with defining trends using an average spread, reflecting the primary transaction cost. The resulting performance deterioration underscores the complexity of translating trend classification into profitable trading strategies. We argue that our work provides new insights into the evolving landscape of stock price trend prediction and sets a strong foundation for future advancements in financial AI. We release the code at this http URL.", 'abstract_zh': '基于限价订单簿数据的股票价格趋势预测（SPTP）是金融市场的基本挑战。尽管深度学习取得了进步，现有的模型难以在不同市场条件下泛化，并且在可靠预测短期趋势方面存在困难。令人惊讶的是，通过将简单的MLP架构适应限价订单簿数据，我们展示了超越当前最佳性能（SoTA）的可能性，从而质疑复杂架构的必要性。不同于过去的工作揭示了鲁棒性问题，我们提出了基于变换器的TLOB模型，该模型使用双重注意机制来捕捉限价订单簿数据中的空间和时间依赖性。这使其能够自适应地关注市场微观结构，特别是在较长预测期和市场波动条件下表现出色。我们还引入了一种新的标签方法，改进了以前的方法，消除了预测期偏见。为了评估TLOB的有效性，我们在FI-2010基准（F1得分为92.8%）以及特斯拉（F1提高了2.67%）和英特尔（F1提高了14.16%）上进行了评估。此外，我们实证展示了股票价格可预测性随时间下降（F1绝对值下降了6.68点），突显了市场效率的增强。必须将可预测性考虑与交易成本相关联，因此我们通过使用平均价差来定义趋势，反映了主要的交易成本，进而实证探索。所得性能下降进一步证明了将趋势分类转化为盈利交易策略的复杂性。我们认为我们的工作为股票价格趋势预测的不断演变提供了新的见解，并为未来金融AI的发展奠定了坚实的基础。我们将在该网址发布代码。', 'title_zh': 'TLOB：一种用于限价订单簿数据股票价格趋势预测的新型双注意机制变换器模型'}
{'arxiv_id': 'arXiv:2502.15755', 'title': 'Physics-consistent machine learning: output projection onto physical manifolds', 'authors': 'Matilde Valente, Tiago C. Dias, Vasco Guerra, Rodrigo Ventura', 'link': 'https://arxiv.org/abs/2502.15755', 'abstract': 'Data-driven machine learning models often require extensive datasets, which can be costly or inaccessible, and their predictions may fail to comply with established physical laws. Current approaches for incorporating physical priors mitigate these issues by penalizing deviations from known physical laws, as in physics-informed neural networks, or by designing architectures that automatically satisfy specific invariants. However, penalization approaches do not guarantee compliance with physical constraints for unseen inputs, and invariant-based methods lack flexibility and generality. We propose a novel physics-consistent machine learning method that directly enforces compliance with physical principles by projecting model outputs onto the manifold defined by these laws. This procedure ensures that predictions inherently adhere to the chosen physical constraints, improving reliability and interpretability. Our method is demonstrated on two systems: a spring-mass system and a low-temperature reactive plasma. Compared to purely data-driven models, our approach significantly reduces errors in physical law compliance, enhances predictive accuracy of physical quantities, and outperforms alternatives when working with simpler models or limited datasets. The proposed projection-based technique is versatile and can function independently or in conjunction with existing physics-informed neural networks, offering a powerful, general, and scalable solution for developing fast and reliable surrogate models of complex physical systems, particularly in resource-constrained scenarios.', 'abstract_zh': '一种直接遵守物理原理的新型物理一致性机器学习方法', 'title_zh': '物理学一致的机器学习：输出映射到物理流形上'}
{'arxiv_id': 'arXiv:2502.15749', 'title': 'TCProF:Time-Complexity Prediction SSL Framework', 'authors': 'Joonghyuk Hahn, Hyeseon Ahn, Jungin Kim, Soohan Lim, Yo-Sub Han', 'link': 'https://arxiv.org/abs/2502.15749', 'abstract': "Time complexity is a theoretic measure to determine the amount of time the algorithm needs for its execution. In reality, developers write algorithms into code snippets within limited resources, making the calculation of a code's time complexity a fundamental task. However, determining the precise time complexity of a code is theoretically undecidable. In response, recent advancements have leaned toward deploying datasets for code time complexity prediction and initiating preliminary experiments for this challenge. We investigate the challenge in low-resource scenarios where only a few labeled instances are given for training. Remarkably, we are the first to introduce TCProF: a Time-Complexity Prediction SSL Framework as an effective solution for code time complexity prediction in low-resource settings. TCProF significantly boosts performance by integrating our augmentation, symbolic modules, and a co-training mechanism, achieving a more than 60% improvement over self-training approaches. We further provide an extensive comparative analysis between TCProF, ChatGPT, and Gemini-Pro, offering a detailed evaluation of our approach.", 'abstract_zh': '时间复杂度是理论衡量算法执行所需时间的指标。实际上，开发人员在有限资源下将算法编写为代码片段，因此计算代码的时间复杂度是基本任务之一。然而，确定代码的确切时间复杂度在理论上是不可判定的。为此，最近的进展转向使用数据集进行代码时间复杂度预测，并开始对此挑战进行初步实验。我们研究了低资源场景中的挑战，其中只有少量带标签的实例用于训练。值得一提的是，我们首次提出了TCProF：一种时间复杂度预测的SSL框架，它是针对低资源设置中代码时间复杂度预测的有效解决方案。TCProF通过集成我们的增强、符号模块和协同训练机制，显著提升了性能，相对于自我训练方法，性能提升了超过60%。我们进一步提供了TCProF、ChatGPT和Gemini-Pro之间的全面比较分析，对我们的方法进行了详细评估。', 'title_zh': 'TCProF: 时间复杂度预测SSL框架'}
{'arxiv_id': 'arXiv:2502.15735', 'title': 'DistrEE: Distributed Early Exit of Deep Neural Network Inference on Edge Devices', 'authors': 'Xian Peng, Xin Wu, Lianming Xu, Li Wang, Aiguo Fei', 'link': 'https://arxiv.org/abs/2502.15735', 'abstract': 'Distributed DNN inference is becoming increasingly important as the demand for intelligent services at the network edge grows. By leveraging the power of distributed computing, edge devices can perform complicated and resource-hungry inference tasks previously only possible on powerful servers, enabling new applications in areas such as autonomous vehicles, industrial automation, and smart homes. However, it is challenging to achieve accurate and efficient distributed edge inference due to the fluctuating nature of the actual resources of the devices and the processing difficulty of the input data. In this work, we propose DistrEE, a distributed DNN inference framework that can exit model inference early to meet specific quality of service requirements. In particular, the framework firstly integrates model early exit and distributed inference for multi-node collaborative inferencing scenarios. Furthermore, it designs an early exit policy to control when the model inference terminates. Extensive simulation results demonstrate that DistrEE can efficiently realize efficient collaborative inference, achieving an effective trade-off between inference latency and accuracy.', 'abstract_zh': '分布式DNN推理正在随着网络边缘智能服务需求的增长变得日益重要。通过利用分布式计算的强大功能，边缘设备可以执行以往只有在强大服务器上才能完成的复杂且资源密集型的推理任务，从而在无人驾驶车辆、工业自动化和智能家居等领域开启新的应用。然而，由于设备实际资源的波动性和输入数据处理的难度，实现准确高效的分布式边缘推理具有挑战性。在这种情况下，我们提出了DistrEE，一种能够提前退出模型推理以满足特定服务质量要求的分布式DNN推理框架。该框架首先将模型提前退出与分布式推理整合到多节点协作推理场景中，并设计了一个提前退出策略来控制模型推理的终止时机。大量仿真结果表明，DistrEE能够高效地实现协作推理，实现推理延迟和准确性的有效权衡。', 'title_zh': 'DistrEE: 边缘设备上深度神经网络推断的分布式早期退出机制'}
{'arxiv_id': 'arXiv:2502.15731', 'title': 'Modular and Integrated AI Control Framework across Fiber and Wireless Networks for 6G', 'authors': 'Merim Dzaferagic, Marco Ruffini, Daniel Kilper', 'link': 'https://arxiv.org/abs/2502.15731', 'abstract': 'The rapid evolution of communication networks towards 6G increasingly incorporates advanced AI-driven controls across various network segments to achieve intelligent, zero-touch operation. This paper proposes a comprehensive and modular framework for AI controllers, designed to be highly flexible and adaptable for use across both fiber optical and radio networks. Building on the principles established by the O-RAN Alliance for near-Real-Time RAN Intelligent Controllers (near-RT RICs), our framework extends this AI-driven control into the optical domain. Our approach addresses the critical need for a unified AI control framework across diverse network transport technologies and domains, enabling the development of intelligent, automated, and scalable 6G networks.', 'abstract_zh': '6G 通信网络向快速演进的过程中，越来越多地融入了跨各种网络段的先进AI驱动控制，以实现智能化和零接触操作。本文提出了一种全面且模块化的AI控制器框架，旨在高度灵活并适应光纤网络和无线电网络的广泛使用。基于O-RAN联盟为近实时RAN智能控制器（near-RT RICs）建立的原则，我们的框架将这种AI驱动的控制扩展到光域。我们的方法解决了多样化的网络传输技术和领域中统一AI控制框架的迫切需求，有助于发展智能化、自动化和可扩展的6G网络。', 'title_zh': '跨光纤和无线网络的模块化一体化AI控制框架（面向6G）'}
{'arxiv_id': 'arXiv:2502.15721', 'title': 'iTRI-QA: a Toolset for Customized Question-Answer Dataset Generation Using Language Models for Enhanced Scientific Research', 'authors': 'Qiming Liu, Zhongzheng Niu, Siting Liu, Mao Tian', 'link': 'https://arxiv.org/abs/2502.15721', 'abstract': "The exponential growth of AI in science necessitates efficient and scalable solutions for retrieving and preserving research information. Here, we present a tool for the development of a customized question-answer (QA) dataset, called Interactive Trained Research Innovator (iTRI) - QA, tailored for the needs of researchers leveraging language models (LMs) to retrieve scientific knowledge in a QA format. Our approach integrates curated QA datasets with a specialized research paper dataset to enhance responses' contextual relevance and accuracy using fine-tuned LM. The framework comprises four key steps: (1) the generation of high-quality and human-generated QA examples, (2) the creation of a structured research paper database, (3) the fine-tuning of LMs using domain-specific QA examples, and (4) the generation of QA dataset that align with user queries and the curated database. This pipeline provides a dynamic and domain-specific QA system that augments the utility of LMs in academic research that will be applied for future research LM deployment. We demonstrate the feasibility and scalability of our tool for streamlining knowledge retrieval in scientific contexts, paving the way for its integration into broader multi-disciplinary applications.", 'abstract_zh': 'AI在科学中的指数增长 necessitates 有效且可扩展的解决方案以检索和保存研究信息。在此，我们介绍了一种针对利用语言模型（LMs）以问答格式检索科学知识的研究人员需求定制的问答（QA）数据集工具，称为交互式训练研究创新者（iTRI）-QA。我们的方法将精选的问答数据集与专门的科研论文数据集相结合，使用细调后的LM增强响应的相关性和准确性。该框架包括四个关键步骤：（1）高质量的人工生成的问答示例生成，（2）结构化科研论文数据库的创建，（3）使用领域特定的问答示例对LM进行细调，以及（4）生成与用户查询和精选数据库对齐的问答数据集。该流水线提供了一个动态且领域特定的问答系统，增强了LM在学术研究中的实用性，并将应用于未来的研究LM部署。我们展示了该工具在科学情境下简化知识检索的可行性和可扩展性，为其集成到更广泛的跨学科应用铺平了道路。', 'title_zh': 'iTRI-QA：一种基于语言模型生成定制化问答数据集的工具集，以增强科学研究'}
{'arxiv_id': 'arXiv:2502.15720', 'title': 'Training AI to be Loyal', 'authors': 'Sewoong Oh, Himanshu Tyagi, Pramod Viswanath', 'link': 'https://arxiv.org/abs/2502.15720', 'abstract': "Loyal AI is loyal to the community that builds it. An AI is loyal to a community if the community has ownership, alignment, and control. Community owned models can only be used with the approval of the community and share the economic rewards communally. Community aligned models have values that are aligned with the consensus of the community. Community controlled models perform functions designed by the community. Since we would like permissionless access to the loyal AI's community, we need the AI to be open source. The key scientific question then is: how can we build models that are openly accessible (open source) and yet are owned and governed by the community. This seeming impossibility is the focus of this paper where we outline a concrete pathway to Open, Monetizable and Loyal models (OML), building on our earlier work on OML, arXiv:2411.03887(1) , and a representation via a cryptographic-ML library this http URL .", 'abstract_zh': '忠诚的AI忠于构建它的社区。如果社区拥有所有权、一致性和控制权，那么AI就是忠诚于这个社区的。社区拥有的模型只能在社区批准的情况下使用，并且能够共同分享经济收益。社区对齐的模型具有与社区共识一致的价值观。社区控制的模型执行由社区设计的功能。由于我们希望无许可访问忠诚的AI的社区，因此需要该AI是开源的。那么关键的科学问题是：如何构建既可公开访问（开源）又由社区拥有和治理的模型。这种看似不可能的挑战是本文的关注点，我们在文中概述了一条从开源、可货币化和忠诚模型（OML）的具体路径，基于我们早期关于OML的工作arXiv:2411.03887(1)以及一个通过加密-机器学习库表示的方法。', 'title_zh': '训练AI忠诚'}
{'arxiv_id': 'arXiv:2502.15719', 'title': 'Governing AI Beyond the Pretraining Frontier', 'authors': 'Nicholas A. Caputo', 'link': 'https://arxiv.org/abs/2502.15719', 'abstract': 'This year, jurisdictions worldwide, including the United States, the European Union, the United Kingdom, and China, are set to enact or revise laws governing frontier AI. Their efforts largely rely on the assumption that increasing model scale through pretraining is the path to more advanced AI capabilities. Yet growing evidence suggests that this "pretraining paradigm" may be hitting a wall and major AI companies are turning to alternative approaches, like inference-time "reasoning," to boost capabilities instead.\nThis paradigm shift presents fundamental challenges for the frontier AI governance frameworks that target pretraining scale as a key bottleneck useful for monitoring, control, and exclusion, threatening to undermine this new legal order as it emerges. This essay seeks to identify these challenges and point to new paths forward for regulation. First, we examine the existing frontier AI regulatory regime and analyze some key traits and vulnerabilities. Second, we introduce the concept of the "pretraining frontier," the capabilities threshold made possible by scaling up pretraining alone, and demonstrate how it could make the regulatory field more diffuse and complex and lead to new forms of competition. Third, we lay out a regulatory approach that focuses on increasing transparency and leveraging new natural technical bottlenecks to effectively oversee changing frontier AI development while minimizing regulatory burdens and protecting fundamental rights. Our analysis provides concrete mechanisms for governing frontier AI systems across diverse technical paradigms, offering policymakers tools for addressing both current and future regulatory challenges in frontier AI.', 'abstract_zh': '全球范围内，包括美国、欧洲联盟、英国和中国在内的地区今年将制定或修订治理前沿人工智能的法律。这些努力主要基于一个假设，即通过预训练增加模型规模是实现更高级人工智能能力的途径。然而，越来越多的证据表明，这一“预训练范式”可能已达到瓶颈，主要人工智能公司正转向推理时的“推理”等替代方法以提升能力。这一范式转变对将预训练规模作为关键瓶颈进行监控、控制和排除的前沿人工智能治理框架提出了根本性的挑战，可能削弱新兴的法律秩序。本文旨在识别这些挑战，并指明新的监管路径。首先，我们审视现有的前沿人工智能监管制度，并分析其中的关键特征和脆弱性。其次，我们提出了“预训练前沿”这一概念，这是通过单独扩大预训练规模所可能实现的能力门槛，并展示它如何使监管领域更加分散和复杂，并可能导致新的竞争形式。最后，我们阐述一种监管方法，该方法集中在提高透明度，并利用新的自然技术瓶颈，有效监督前沿人工智能发展变化，同时减轻监管负担并保护基本权利。我们的分析为不同技术范式的前沿人工智能系统提供了具体的治理机制，为政策制定者提供工具，以应对当前和未来的前沿人工智能监管挑战。', 'title_zh': '超越预训练边界的AI治理'}
{'arxiv_id': 'arXiv:2502.15715', 'title': 'Regulating Multifunctionality', 'authors': 'Cary Coglianese, Colton R. Crum', 'link': 'https://arxiv.org/abs/2502.15715', 'abstract': "Foundation models and generative artificial intelligence (AI) exacerbate a core regulatory challenge associated with AI: its heterogeneity. By their very nature, foundation models and generative AI can perform multiple functions for their users, thus presenting a vast array of different risks. This multifunctionality means that prescriptive, one-size-fits-all regulation will not be a viable option. Even performance standards and ex post liability - regulatory approaches that usually afford flexibility - are unlikely to be strong candidates for responding to multifunctional AI's risks, given challenges in monitoring and enforcement. Regulators will do well instead to promote proactive risk management on the part of developers and users by using management-based regulation, an approach that has proven effective in other contexts of heterogeneity. Regulators will also need to maintain ongoing vigilance and agility. More than in other contexts, regulators of multifunctional AI will need sufficient resources, top human talent and leadership, and organizational cultures committed to regulatory excellence.", 'abstract_zh': '基础模型与生成性人工智能加剧了与AI相关的核心监管挑战：异质性。这类模型和生成性AI能够为用户执行多种功能，从而带来各种不同的风险，这使得规定性的一刀切监管方法变得不可行。即使是一些通常具有灵活性的性能标准和事后责任监管方法，也可能不是应对多功能AI风险的有力选择，尤其是在难以监控和执行方面的挑战面前。相反，监管者应通过基于管理的监管措施促进开发人员和用户主动风险管理，这种监管方法在其他异质性背景下已被证明是有效的。监管者还需要保持持续的警惕性和灵活性。对于多功能AI的监管者而言，这方面的资源、顶级人力资源和致力于监管卓越的组织文化比在其他背景下的需求更为强烈。', 'title_zh': '调节多功能性'}
{'arxiv_id': 'arXiv:2502.15714', 'title': 'TrustDataFilter:Leveraging Trusted Knowledge Base Data for More Effective Filtering of Unknown Information', 'authors': 'Jinghong Zhang, Yidong Cui, Weiling Wang, Xianyou Cheng', 'link': 'https://arxiv.org/abs/2502.15714', 'abstract': 'With the advancement of technology and changes in the market, the demand for the construction of domain-specific knowledge bases has been increasing, either to improve model performance or to promote enterprise innovation and competitiveness. The construction of domain-specific knowledge bases typically relies on web crawlers or existing industry databases, leading to problems with accuracy and consistency of the data. To address these challenges, we considered the characteristics of domain data, where internal knowledge is interconnected, and proposed the Self-Natural Language Inference Data Filtering (self-nli-TDF) framework. This framework compares trusted filtered knowledge with the data to be filtered, deducing the reasoning relationship between them, thus improving filtering performance. The framework uses plug-and-play large language models for trustworthiness assessment and employs the RoBERTa-MNLI model from the NLI domain for reasoning. We constructed three datasets in the domains of biology, radiation, and science, and conducted experiments using RoBERTa, GPT3.5, and the local Qwen2 model. The experimental results show that this framework improves filter quality, producing more consistent and reliable filtering results.', 'abstract_zh': '随着技术的进步和市场的变化，对领域特定知识库的构建需求不断增加，以提高模型性能或促进企业创新和竞争力。领域特定知识库的构建通常依赖于网页抓取器或现有的行业数据库，这导致数据的准确性和一致性问题。为应对这些挑战，我们考虑了领域数据的特点，即内部知识相互连接，提出了Self-Natural Language Inference Data Filtering (self-nli-TDF) 框架。该框架将可信过滤知识与待过滤数据进行比较，推导它们之间的推理关系，从而提高过滤性能。该框架利用可插拔的大语言模型进行可信度评估，并采用NLI领域中的RoBERTa-MNLI模型进行推理。我们构建了生物、辐射和科学领域的三个数据集，并使用RoBERTa、GPT3.5和本地Qwen2模型进行了实验。实验结果表明，该框架提高了过滤质量，生成了更为一致和可靠的过滤结果。', 'title_zh': 'TrustDataFilter：利用可信知识库数据实现对未知信息更有效的过滤'}
{'arxiv_id': 'arXiv:2502.15713', 'title': 'UAV-assisted Internet of Vehicles: A Framework Empowered by Reinforcement Learning and Blockchain', 'authors': 'Ahmed Alagha, Maha Kadadha, Rabeb Mizouni, Shakti Singh, Jamal Bentahar, Hadi Otrok', 'link': 'https://arxiv.org/abs/2502.15713', 'abstract': 'This paper addresses the challenges of selecting relay nodes and coordinating among them in UAV-assisted Internet-of-Vehicles (IoV). The selection of UAV relay nodes in IoV employs mechanisms executed either at centralized servers or decentralized nodes, which have two main limitations: 1) the traceability of the selection mechanism execution and 2) the coordination among the selected UAVs, which is currently offered in a centralized manner and is not coupled with the relay selection. Existing UAV coordination methods often rely on optimization methods, which are not adaptable to different environment complexities, or on centralized deep reinforcement learning, which lacks scalability in multi-UAV settings. Overall, there is a need for a comprehensive framework where relay selection and coordination are coupled and executed in a transparent and trusted manner. This work proposes a framework empowered by reinforcement learning and Blockchain for UAV-assisted IoV networks. It consists of three main components: a two-sided UAV relay selection mechanism for UAV-assisted IoV, a decentralized Multi-Agent Deep Reinforcement Learning (MDRL) model for autonomous UAV coordination, and a Blockchain implementation for transparency and traceability in the interactions between vehicles and UAVs. The relay selection considers the two-sided preferences of vehicles and UAVs based on the Quality-of-UAV (QoU) and the Quality-of-Vehicle (QoV). Upon selection of relay UAVs, the decentralized coordination between them is enabled through an MDRL model trained to control their mobility and maintain the network coverage and connectivity using Proximal Policy Optimization (PPO). The evaluation results demonstrate that the proposed selection and coordination mechanisms improve the stability of the selected relays and maximize the coverage and connectivity achieved by the UAVs.', 'abstract_zh': '基于UAV辅助IoV的强化学习与区块链赋能的relay选择与协同框架', 'title_zh': '无人机辅助 veículo 网络：一种基于 reinforcement learning 和区块链的技术框架'}
{'arxiv_id': 'arXiv:2502.15712', 'title': "GPUs, CPUs, and... NICs: Rethinking the Network's Role in Serving Complex AI Pipelines", 'authors': 'Mike Wong, Ulysses Butler, Emma Farkash, Praveen Tammana, Anirudh Sivaraman, Ravi Netravali', 'link': 'https://arxiv.org/abs/2502.15712', 'abstract': 'The increasing prominence of AI necessitates the deployment of inference platforms for efficient and effective management of AI pipelines and compute resources. As these pipelines grow in complexity, the demand for distributed serving rises and introduces much-dreaded network delays. In this paper, we investigate how the network can instead be a boon to the excessively high resource overheads of AI pipelines. To alleviate these overheads, we discuss how resource-intensive data processing tasks -- a key facet of growing AI pipeline complexity -- are well-matched for the computational characteristics of packet processing pipelines and how they can be offloaded onto SmartNICs. We explore the challenges and opportunities of offloading, and propose a research agenda for integrating network hardware into AI pipelines, unlocking new opportunities for optimization.', 'abstract_zh': 'AI日益突出的 prominence 增加了部署推理平台的需求，以高效有效地管理和利用 AI 管道和计算资源。随着这些管道变得日益复杂，分布式服务的需求上升，并引入了令人担忧的网络延迟。在本文中，我们探讨了网络如何成为缓解 AI 管道过度资源开销的福音。为了缓解这些开销，我们讨论了计算密集型数据处理任务 —— 即随着 AI 管道复杂性的增长而变得日益重要的关键方面 —— 如何与报文处理管道的计算特性相匹配，并提出如何将其卸载到智能网络接口卡（SmartNICs）上。我们探讨了卸载带来的挑战和机遇，并提出了一项研究议程，旨在将网络硬件集成到 AI 管道中，从而解锁新的优化机会。', 'title_zh': 'GPU、CPU和……网络适卡：重新思考网络在服务复杂AI流水线中的角色'}
{'arxiv_id': 'arXiv:2502.15697', 'title': 'Robust Uplift Modeling with Large-Scale Contexts for Real-time Marketing', 'authors': 'Zexu Sun, Qiyu Han, Minqin Zhu, Hao Gong, Dugang Liu, Chen Ma', 'link': 'https://arxiv.org/abs/2502.15697', 'abstract': 'Improving user engagement and platform revenue is crucial for online marketing platforms. Uplift modeling is proposed to solve this problem, which applies different treatments (e.g., discounts, bonus) to satisfy corresponding users. Despite progress in this field, limitations persist. Firstly, most of them focus on scenarios where only user features exist. However, in real-world scenarios, there are rich contexts available in the online platform (e.g., short videos, news), and the uplift model needs to infer an incentive for each user on the specific item, which is called real-time marketing. Thus, only considering the user features will lead to biased prediction of the responses, which may cause the cumulative error for uplift prediction. Moreover, due to the large-scale contexts, directly concatenating the context features with the user features will cause a severe distribution shift in the treatment and control groups. Secondly, capturing the interaction relationship between the user features and context features can better predict the user response. To solve the above limitations, we propose a novel model-agnostic Robust Uplift Modeling with Large-Scale Contexts (UMLC) framework for Real-time Marketing. Our UMLC includes two customized modules. 1) A response-guided context grouping module for extracting context features information and condensing value space through clusters. 2) A feature interaction module for obtaining better uplift prediction. Specifically, this module contains two parts: a user-context interaction component for better modeling the response; a treatment-feature interaction component for discovering the treatment assignment sensitive feature of each instance to better predict the uplift. Moreover, we conduct extensive experiments on a synthetic dataset and a real-world product dataset to verify the effectiveness and compatibility of our UMLC.', 'abstract_zh': '提升用户参与度和平台收益对于在线营销平台至关重要。实时营销中的稳健大规模上下文提升 modeling框架（UMLC）在提升预测中的应用', 'title_zh': '面向实时营销的大规模上下文鲁棒提升建模'}
{'arxiv_id': 'arXiv:2502.15695', 'title': 'Social Relation Meets Recommendation: Denoising and Alignment', 'authors': 'Lin Wang, Weisong Wang, Xuanji Xiao, Qing Li', 'link': 'https://arxiv.org/abs/2502.15695', 'abstract': 'Recommender systems have now become an essential part of modern content platforms. Yet, traditional behavior-based recommendation models often struggle with cold users, who have limited interaction data. Despite this, engaging these users is crucial for the ongoing growth of content platforms. To bridge this gap, we propose utilizing the social-relation graph to enrich the interest profiles derived from behavior-based models. While social graphs are ubiquitous on content platforms, extracting value from this data is challenging due to social-relation noise and interest inconsistency. To address the noise propagation issue in graph data and obtain accurate social interest, we employ a dual-view denoising strategy. It first applies low-rank SVD to the user-item matrix to extract denoised user embeddings. These embeddings are then used to generate a reconstructed social graph. Finally, the strategy implements contrastive learning between the original and reconstructed social graphs. Addressing the interest inconsistency between social and behavioral interests, we adopt a mutual distillation technique to isolate the original interests into four sub-interests, namely aligned social/behavior interests and social/behavior specific interests, which maximally fuse the two interests. Experimental results on industry datasets demonstrate the effectiveness of our method, particularly for cold users, verifying that effectively fusing social relations and behaviors can be highly beneficial for modern recommendation platforms.', 'abstract_zh': '推荐系统已成为现代内容平台不可或缺的一部分。然而，传统基于行为的推荐模型在处理冷启动用户时往往表现不佳，这些用户缺乏足够的交互数据。尽管如此，吸引这些用户对于内容平台的持续增长至关重要。为解决这一问题，我们提出利用社会关系图来丰富基于行为模型提取的兴趣轮廓。虽然内容平台上普遍存在社会图，但从中提取价值极具挑战性，因为社会关系噪声和兴趣不一致性问题。为解决图数据中的噪声传播问题并获得准确的社会兴趣，我们采用了一种双视角去噪策略。该策略首先使用低秩SVD对用户-项目矩阵进行处理以提取去噪后的用户嵌入，然后利用这些嵌入构建重构的社会图。最后，该策略在原始社会图和重构社会图之间实施对比学习。为解决社会和行为兴趣之间的不一致性，我们采用了互学生distillation技术，将原始兴趣隔离为四种子兴趣，即对齐的社会/行为兴趣和社会/行为特定兴趣，从而使两种兴趣最大化融合。在工业数据集上的实验结果证明了我们方法的有效性，特别是在冷启动用户上，验证了有效融合社会关系和行为能够显著提升现代推荐平台的表现。', 'title_zh': '社交关系与推荐系统相遇：去噪与对齐'}
{'arxiv_id': 'arXiv:2502.15693', 'title': 'Hgformer: Hyperbolic Graph Transformer for Recommendation', 'authors': 'Xin Yang, Xingrun Li, Heng Chang, Jinze Yang, Xihong Yang, Shengyu Tao, Ningkang Chang, Maiko Shigeno, Junfeng Wang, Dawei Yin, Erxue Min', 'link': 'https://arxiv.org/abs/2502.15693', 'abstract': 'The cold start problem is a challenging problem faced by most modern recommender systems. By leveraging knowledge from other domains, cross-domain recommendation can be an effective method to alleviate the cold start problem. However, the modelling distortion for long-tail data, which is widely present in recommender systems, is often overlooked in cross-domain recommendation. In this research, we propose a hyperbolic manifold based cross-domain collaborative filtering model using BiTGCF as the base model. We introduce the hyperbolic manifold and construct new propagation layer and transfer layer to address these challenges. The significant performance improvements across various datasets compared to the baseline models demonstrate the effectiveness of our proposed model.', 'abstract_zh': '基于双曲流形的跨域BiTGCF协同过滤模型：缓解长尾数据建模偏差', 'title_zh': 'Hgformer: 双曲图transformer在推荐中的应用'}
{'arxiv_id': 'arXiv:2502.15692', 'title': 'ACL-rlg: A Dataset for Reading List Generation', 'authors': 'Julien Aubert-Béduchaud, Florian Boudin, Béatrice Daille, Richard Dufour', 'link': 'https://arxiv.org/abs/2502.15692', 'abstract': 'Familiarizing oneself with a new scientific field and its existing literature can be daunting due to the large amount of available articles. Curated lists of academic references, or reading lists, compiled by experts, offer a structured way to gain a comprehensive overview of a domain or a specific scientific challenge. In this work, we introduce ACL-rlg, the largest open expert-annotated reading list dataset. We also provide multiple baselines for evaluating reading list generation and formally define it as a retrieval task. Our qualitative study highlights the fact that traditional scholarly search engines and indexing methods perform poorly on this task, and GPT-4o, despite showing better results, exhibits signs of potential data contamination.', 'abstract_zh': '熟悉新的科学领域及其现有文献可能会因为可用的文章数量庞大而显得 daunting。由专家编写的 curated 摘要列表提供了一种结构化的方式，以获得某领域或特定科学挑战的全面概述。在这项工作中，我们介绍了 ACL-rlg，这是最大的开放专家标注阅读列表数据集。我们还提供了多种基线以评估阅读列表生成，并正式将此任务定义为检索任务。我们的定性研究指出，传统学术搜索引擎和索引方法在此任务上表现不佳，尽管 GPT-4o 表现更好，但它显示出潜在的数据污染迹象。', 'title_zh': 'ACL-rlg: 一个阅读列表生成数据集'}
{'arxiv_id': 'arXiv:2502.15691', 'title': 'The Synergy of Automated Pipelines with Prompt Engineering and Generative AI in Web Crawling', 'authors': 'Chau-Jian Huang', 'link': 'https://arxiv.org/abs/2502.15691', 'abstract': "Web crawling is a critical technique for extracting online data, yet it poses challenges due to webpage diversity and anti-scraping mechanisms. This study investigates the integration of generative AI tools Claude AI (Sonnet 3.5) and ChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts, PROMPT I (general inference, tested on Yahoo News) and PROMPT II (element-specific, tested on this http URL), we evaluate the code quality and performance of AI-generated scripts. Claude AI consistently outperformed ChatGPT-4.0 in script quality and adaptability, as confirmed by predefined evaluation metrics, including functionality, readability, modularity, and robustness. Performance data were collected through manual testing and structured scoring by three evaluators. Visualizations further illustrate Claude AI's superiority. Anti-scraping solutions, including undetected_chromedriver, Selenium, and fake_useragent, were incorporated to enhance performance. This paper demonstrates how generative AI combined with prompt engineering can simplify and improve web scraping workflows.", 'abstract_zh': '基于生成式AI工具与提示工程的网页抓取技术研究：以Claude AI（Sonnet 3.5）和ChatGPT4.0为例', 'title_zh': '自动化管道与提示工程及生成式AI在网页爬取中的协同作用'}
