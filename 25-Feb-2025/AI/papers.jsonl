{'arxiv_id': 'arXiv:2502.17419', 'title': 'From System 1 to System 2: A Survey of Reasoning Large Language Models', 'authors': 'Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhijiang Guo, Le Song, Cheng-Lin Liu', 'link': 'https://arxiv.org/abs/2502.17419', 'abstract': "Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 thinking. Recently, reasoning LLMs like OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level performance in fields such as mathematics and coding, closely mimicking the deliberate reasoning of System 2 and showcasing human-like cognitive abilities. This survey begins with a brief overview of the progress in foundational LLMs and the early development of System 2 technologies, exploring how their combination has paved the way for reasoning LLMs. Next, we discuss how to construct reasoning LLMs, analyzing their features, the core methods enabling advanced reasoning, and the evolution of various reasoning LLMs. Additionally, we provide an overview of reasoning benchmarks, offering an in-depth comparison of the performance of representative reasoning LLMs. Finally, we explore promising directions for advancing reasoning LLMs and maintain a real-time \\href{this https URL}{GitHub Repository} to track the latest developments. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this rapidly evolving field.", 'abstract_zh': '实现人类级智能需要优化从快速直觉的System 1向更慢且更慎重的System 2推理的过渡。虽然System 1在快速启发式决策方面表现出色，但System 2依赖于逻辑推理以做出更准确的判断并减少偏差。基础大型语言模型在快速决策方面表现出色，但在复杂推理方面仍显不足，因为它们尚未完全采纳真正的System 2思考所包含的逐步分析特征。近年来，像OpenAI的o1/o3和DeepSeek的R1这样的推理LLM在数学和编程等领域展示了专家级性能，其推理方式与System 2的仔细推理高度相似，展示了类似人类的认知能力。本综述首先对基础LLM的进步和System 2技术的早期发展进行了简要概述，探讨了它们的结合如何为推理LLM铺平道路。随后，我们讨论了如何构建推理LLM，分析了它们的特性、使高级推理成为可能的关键方法以及各种推理LLM的发展演变。此外，我们还提供了推理基准的概述，深入比较了代表性推理LLM的性能。最后，我们探讨了推进推理LLM的有前景的方向，并维护了一个实时的GitHub Repository以跟踪最新进展。我们希望这份综述能成为一个有价值的资源，激发创新并推动这一快速发展的领域前进。', 'title_zh': '从系统1到系统2：大型语言模型推理综述'}
{'arxiv_id': 'arXiv:2502.17392', 'title': 'Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences', 'authors': 'Yangshijie Zhang', 'link': 'https://arxiv.org/abs/2502.17392', 'abstract': 'Deep neural networks (DNNs) have achieved remarkable success in the field of natural language processing (NLP), leading to widely recognized applications such as ChatGPT. However, the vulnerability of these models to adversarial attacks remains a significant concern. Unlike continuous domains like images, text exists in a discrete space, making even minor alterations at the sentence, word, or character level easily perceptible to humans. This inherent discreteness also complicates the use of conventional optimization techniques, as text is non-differentiable. Previous research on adversarial attacks in text has focused on character-level, word-level, sentence-level, and multi-level approaches, all of which suffer from inefficiency or perceptibility issues due to the need for multiple queries or significant semantic shifts.\nIn this work, we introduce a novel adversarial attack method, Emoji-Attack, which leverages the manipulation of emojis to create subtle, yet effective, perturbations. Unlike character- and word-level strategies, Emoji-Attack targets emojis as a distinct layer of attack, resulting in less noticeable changes with minimal disruption to the text. This approach has been largely unexplored in previous research, which typically focuses on emoji insertion as an extension of character-level attacks. Our experiments demonstrate that Emoji-Attack achieves strong attack performance on both large and small models, making it a promising technique for enhancing adversarial robustness in NLP systems.', 'abstract_zh': '基于表情符号的新型对抗攻击方法：Emoji-Attack', 'title_zh': 'Emoti-Attack：通过 Emoji 序列对 NLP 系统进行零扰动对抗攻击'}
{'arxiv_id': 'arXiv:2502.17297', 'title': 'Benchmarking Retrieval-Augmented Generation in Multi-Modal Contexts', 'authors': 'Zhenghao Liu, Xingsheng Zhu, Tianshuo Zhou, Xinyi Zhang, Xiaoyuan Yi, Yukun Yan, Yu Gu, Ge Yu, Maosong Sun', 'link': 'https://arxiv.org/abs/2502.17297', 'abstract': 'This paper introduces Multi-Modal Retrieval-Augmented Generation (M^2RAG), a benchmark designed to evaluate the effectiveness of Multi-modal Large Language Models (MLLMs) in leveraging knowledge from multi-modal retrieval documents. The benchmark comprises four tasks: image captioning, multi-modal question answering, multi-modal fact verification, and image reranking. All tasks are set in an open-domain setting, requiring RAG models to retrieve query-relevant information from a multi-modal document collection and use it as input context for RAG modeling. To enhance the context utilization capabilities of MLLMs, we also introduce Multi-Modal Retrieval-Augmented Instruction Tuning (MM-RAIT), an instruction tuning method that optimizes MLLMs within multi-modal contexts. Our experiments show that MM-RAIT improves the performance of RAG systems by enabling them to effectively learn from multi-modal contexts. All data and code are available at this https URL.', 'abstract_zh': '多模态检索增强生成（M^2RAG）基准：用于评估多模态大规模语言模型的知识利用效果', 'title_zh': '多模态上下文中检索增强生成的基准研究'}
{'arxiv_id': 'arXiv:2502.17289', 'title': 'A novel approach to navigate the taxonomic hierarchy to address the Open-World Scenarios in Medicinal Plant Classification', 'authors': 'Soumen Sinha, Tanisha Rana, Rahul Roy', 'link': 'https://arxiv.org/abs/2502.17289', 'abstract': 'In this article, we propose a novel approach for plant hierarchical taxonomy classification by posing the problem as an open class problem. It is observed that existing methods for medicinal plant classification often fail to perform hierarchical classification and accurately identifying unknown species, limiting their effectiveness in comprehensive plant taxonomy classification. Thus we address the problem of unknown species classification by assigning it best hierarchical labels. We propose a novel method, which integrates DenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for hierarchical classification. The approach systematically categorizes medicinal plants at multiple taxonomic levels, from phylum to species, ensuring detailed and precise classification. Using multi scale space attention, the model captures both local and global contextual information from the images, improving the distinction between similar species and the identification of new ones. It uses attention scores to focus on important features across multiple scales. The proposed method provides a solution for hierarchical classification, showcasing superior performance in identifying both known and unknown species. The model was tested on two state-of-art datasets with and without background artifacts and so that it can be deployed to tackle real word application. We used unknown species for testing our model. For unknown species the model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for predicting correct phylum, class, order and family respectively. Our proposed model size is almost four times less than the existing state of the art methods making it easily deploy able in real world application.', 'abstract_zh': '一种用于植物层次分类的新型开集方法：基于未知物种分类的详细精准分类', 'title_zh': '一种新颖的方法导航分类层次以应对药用植物分类中的开放世界场景'}
{'arxiv_id': 'arXiv:2502.17216', 'title': 'Making LLMs Reason? The Intermediate Language Problem in Neurosymbolic Approaches', 'authors': 'Alexander Beiser, David Penz', 'link': 'https://arxiv.org/abs/2502.17216', 'abstract': 'Logical reasoning tasks manifest themselves as a challenge to Large Language Models (LLMs). Neurosymbolic approaches use LLMs to translate logical reasoning problems formulated in natural language into a formal intermediate language. Subsequently, the usage of symbolic reasoners yields reliable solving thereof. However, LLMs often fail in translation due to poorly chosen intermediate languages.\nWe introduce the intermediate language problem, which is the problem of choosing a suitable formal language representation for neurosymbolic approaches. Theoretically, we argue that its origins lie in the inability of LLMs to distinguish syntax from semantics and the relative independence of the problem from its representation. We showcase its existence experimentally by contrasting two intermediate languages, Answer Set Programming and the Python Knowledge Engine. In addition, we demonstrate the effects of varying degrees of supplementary context information. Our results show a maximum difference in overall-accuracy of 53.20% and 49.26% in execution-accuracy. When using the GPT4o-mini LLM we beat the state-of-the-art in overall-accuracy on the ProntoQA dataset by 21.20% and by 50.50% on the ProofWriter dataset.', 'abstract_zh': '中间语言问题：神经符号方法中合适形式语言表示的选择挑战', 'title_zh': '让大规模语言模型具备推理能力？神经符号方法中的中间语言问题'}
{'arxiv_id': 'arXiv:2502.17139', 'title': 'CodeSwift: Accelerating LLM Inference for Efficient Code Generation', 'authors': 'Qianhui Zhao, Li Zhang, Fang Liu, Xiaoli Lian, Qiaoyuanhe Meng, Ziqian Jiao, Zetong Zhou, Borui Zhang, Runlin Guo, Jia Li', 'link': 'https://arxiv.org/abs/2502.17139', 'abstract': 'Code generation is a latency-sensitive task that demands high timeliness, but the autoregressive decoding mechanism of Large Language Models (LLMs) leads to poor inference efficiency. Existing LLM inference acceleration methods mainly focus on standalone functions using only built-in components. Moreover, they treat code like natural language sequences, ignoring its unique syntax and semantic characteristics. As a result, the effectiveness of these approaches in code generation tasks remains limited and fails to align with real-world programming scenarios. To alleviate this issue, we propose CodeSwift, a simple yet highly efficient inference acceleration approach specifically designed for code generation, without comprising the quality of the output. CodeSwift constructs a multi-source datastore, providing access to both general and project-specific knowledge, facilitating the retrieval of high-quality draft sequences. Moreover, CodeSwift reduces retrieval cost by controlling retrieval timing, and enhances efficiency through parallel retrieval and a context- and LLM preference-aware cache. Experimental results show that CodeSwift can reach up to 2.53x and 2.54x speedup compared to autoregressive decoding in repository-level and standalone code generation tasks, respectively, outperforming state-of-the-art inference acceleration approaches by up to 88%.', 'abstract_zh': 'CodeSwift：一种专门用于代码生成的高效推理加速方法', 'title_zh': 'CodeSwift: 加速 Large Language Model 推理以实现高效的代码生成'}
{'arxiv_id': 'arXiv:2502.17136', 'title': 'Evaluating the Effectiveness of Large Language Models in Automated News Article Summarization', 'authors': 'Lionel Richy Panlap Houamegni, Fatih Gedikli', 'link': 'https://arxiv.org/abs/2502.17136', 'abstract': "The automation of news analysis and summarization presents a promising solution to the challenge of processing and analyzing vast amounts of information prevalent in today's information society. Large Language Models (LLMs) have demonstrated the capability to transform vast amounts of textual data into concise and easily comprehensible summaries, offering an effective solution to the problem of information overload and providing users with a quick overview of relevant information. A particularly significant application of this technology lies in supply chain risk analysis. Companies must monitor the news about their suppliers and respond to incidents for several critical reasons, including compliance with laws and regulations, risk management, and maintaining supply chain resilience. This paper develops an automated news summarization system for supply chain risk analysis using LLMs. The proposed solution aggregates news from various sources, summarizes them using LLMs, and presents the condensed information to users in a clear and concise format. This approach enables companies to optimize their information processing and make informed decisions. Our study addresses two main research questions: (1) Are LLMs effective in automating news summarization, particularly in the context of supply chain risk analysis? (2) How effective are various LLMs in terms of readability, duplicate detection, and risk identification in their summarization quality? In this paper, we conducted an offline study using a range of publicly available LLMs at the time and complemented it with a user study focused on the top performing systems of the offline experiments to evaluate their effectiveness further. Our results demonstrate that LLMs, particularly Few-Shot GPT-4o mini, offer significant improvements in summary quality and risk identification.", 'abstract_zh': '新闻分析与总结的自动化为处理和分析当今信息社会中大量信息提供了有前景的解决方案。大型语言模型（LLMs）展现了将大量文本数据转换为简洁易懂的摘要的能力，为此类信息过载问题提供了有效解决方案，为用户提供相关信息的快速概览。这一技术在供应链风险分析中的应用尤为重要。企业必须监控供应商的相关新闻并响应突发事件，原因包括遵守法律法规、风险管理以及维护供应链韧性。本文开发了一个使用LLMs的自动化新闻摘要系统，以用于供应链风险分析。该解决方案聚合来自多种来源的新闻，使用LLMs进行总结，并以清晰简洁的形式将浓缩信息呈现给用户。这种方法使公司能够优化信息处理并做出知情决策。本文探讨了两个主要研究问题：（1）LLMs在供应链风险分析的背景下是否有效用于自动摘要新闻？（2）各种LLMs在可读性、重复检测和风险识别方面的总结质量如何？在此论文中，我们使用当时可用的多种公开LLMs进行了离线研究，并以针对离线实验表现最佳系统的用户研究作为补充，进一步评估其效果。研究结果表明，尤其是Few-Shot GPT-4o mini，LLMs在摘要质量和风险识别方面提供了显著改进。', 'title_zh': '评估大型语言模型在自动新闻文章摘要生成中的有效性'}
{'arxiv_id': 'arXiv:2502.17132', 'title': 'Applications of Large Models in Medicine', 'authors': 'YunHe Su, Zhengyang Lu, Junhui Liu, Ke Pang, Haoran Dai, Sa Liu Yuxin Jia, Lujia Ge, Jing-min Yang', 'link': 'https://arxiv.org/abs/2502.17132', 'abstract': 'This paper explores the advancements and applications of large-scale models in the medical field, with a particular focus on Medical Large Models (MedLMs). These models, encompassing Large Language Models (LLMs), Vision Models, 3D Large Models, and Multimodal Models, are revolutionizing healthcare by enhancing disease prediction, diagnostic assistance, personalized treatment planning, and drug discovery. The integration of graph neural networks in medical knowledge graphs and drug discovery highlights the potential of Large Graph Models (LGMs) in understanding complex biomedical relationships. The study also emphasizes the transformative role of Vision-Language Models (VLMs) and 3D Large Models in medical image analysis, anatomical modeling, and prosthetic design. Despite the challenges, these technologies are setting new benchmarks in medical innovation, improving diagnostic accuracy, and paving the way for personalized healthcare solutions. This paper aims to provide a comprehensive overview of the current state and future directions of large models in medicine, underscoring their significance in advancing global health.', 'abstract_zh': '本文探讨了大型模型在医疗领域的进展与应用，特别关注医疗大型模型（MedLMs）。这些模型包括大型语言模型（LLMs）、视觉模型、3D大型模型和多模态模型，正在通过增强疾病预测、诊断辅助、个性化治疗规划和药物发现等方面推动医疗领域的变革。医疗知识图谱和药物发现中图神经网络的应用展示了大型图模型（LGMs）在理解复杂生物医学关系方面的潜力。研究还强调了视觉语言模型（VLMs）和3D大型模型在医学图像分析、解剖建模和假体设计中的变革性作用。尽管存在挑战，这些技术正在为医疗创新设定新的基准，提高诊断准确性，并为个性化医疗解决方案铺平道路。本文旨在提供大型模型在医疗领域当前状态和未来方向的全面概述，强调其在全球健康领域的重要性。', 'title_zh': '大型模型在医学中的应用'}
{'arxiv_id': 'arXiv:2502.17109', 'title': 'Strength Estimation and Human-Like Strength Adjustment in Games', 'authors': 'Chun Jung Chen, Chung-Chin Shih, Ti-Rong Wu', 'link': 'https://arxiv.org/abs/2502.17109', 'abstract': 'Strength estimation and adjustment are crucial in designing human-AI interactions, particularly in games where AI surpasses human players. This paper introduces a novel strength system, including a strength estimator (SE) and an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts strengths from games and offers different playing strengths with human styles. The strength estimator calculates strength scores and predicts ranks from games without direct human interaction. SE-MCTS utilizes the strength scores in a Monte Carlo tree search to adjust playing strength and style. We first conduct experiments in Go, a challenging board game with a wide range of ranks. Our strength estimator significantly achieves over 80% accuracy in predicting ranks by observing 15 games only, whereas the previous method reached 49% accuracy for 100 games. For strength adjustment, SE-MCTS successfully adjusts to designated ranks while achieving a 51.33% accuracy in aligning to human actions, outperforming a previous state-of-the-art, with only 42.56% accuracy. To demonstrate the generality of our strength system, we further apply SE and SE-MCTS to chess and obtain consistent results. These results show a promising approach to strength estimation and adjustment, enhancing human-AI interactions in games. Our code is available at this https URL.', 'abstract_zh': '人工智能力量估计与调整对于设计人机交互至关重要，特别是在游戏中，人工智能超越人类玩家时更为重要。本文介绍了一种新颖的力量估计系统，包括力量估计器（SE）和基于SE的蒙特卡洛树搜索（SE-MCTS），该系统通过游戏预测力量并提供具有人类风格的不同力量等级。力量估计器在没有直接人类交互的情况下计算力量分数并预测排名。SE-MCTS利用这些力量分数进行蒙特卡洛树搜索，以调整力量等级和风格。我们首先在围棋中进行了实验，这是一种具有广泛排名范围的具有挑战性的棋盘游戏。我们的力量估计器仅通过观察15盘游戏即可显著实现超过80%的排名预测准确率，而先前的方法在100盘游戏中仅达49%的准确率。在力量调整方面，SE-MCTS成功调整到指定的排名，并实现了51.33%的人类动作对齐准确率，优于之前最先进的方法，后者仅达42.56%的准确率。为了展示我们力量系统的一般性，我们将SE和SE-MCTS进一步应用于国际象棋，并获得了相似的结果。这些结果表明了一种有前途的力量估计与调整方法，可增强游戏中的用户体验。我们的代码可在此网址获取：this https URL。', 'title_zh': '游戏中的力量估算与人类般的力量调整'}
{'arxiv_id': 'arXiv:2502.17049', 'title': 'TabulaTime: A Novel Multimodal Deep Learning Framework for Advancing Acute Coronary Syndrome Prediction through Environmental and Clinical Data Integration', 'authors': 'Xin Zhang, Liangxiu Han, Stephen White, Saad Hassan, Philip A Kalra, James Ritchie, Carl Diver, Jennie Shorley', 'link': 'https://arxiv.org/abs/2502.17049', 'abstract': 'Acute Coronary Syndromes (ACS), including ST-segment elevation myocardial infarctions (STEMI) and non-ST-segment elevation myocardial infarctions (NSTEMI), remain a leading cause of mortality worldwide. Traditional cardiovascular risk scores rely primarily on clinical data, often overlooking environmental influences like air pollution that significantly impact heart health. Moreover, integrating complex time-series environmental data with clinical records is challenging.\nWe introduce TabulaTime, a multimodal deep learning framework that enhances ACS risk prediction by combining clinical risk factors with air pollution data. TabulaTime features three key innovations: First, it integrates time-series air pollution data with clinical tabular data to improve prediction accuracy. Second, its PatchRWKV module automatically extracts complex temporal patterns, overcoming limitations of traditional feature engineering while maintaining linear computational complexity. Third, attention mechanisms enhance interpretability by revealing interactions between clinical and environmental factors.\nExperimental results show that TabulaTime improves prediction accuracy by over 20% compared to conventional models such as CatBoost, Random Forest, and LightGBM, with air pollution data alone contributing over a 10% improvement. Feature importance analysis identifies critical predictors including previous angina, systolic blood pressure, PM10, and NO2. Overall, TabulaTime bridges clinical and environmental insights, supporting personalized prevention strategies and informing public health policies to mitigate ACS risk.', 'abstract_zh': '急性冠状综合征（ACS），包括ST段抬高型心肌梗死（STEMI）和非ST段抬高型心肌梗死（NSTEMI），仍然是全球主要的致死原因之一。传统的心血管风险评分主要依赖临床数据，往往忽视了如空气污染等环境因素对心脏健康的显著影响。此外，将复杂的时序环境数据与临床记录整合是一个挑战。\n我们介绍了TabulaTime，这是一种多模态深度学习框架，通过结合临床风险因素和空气污染数据来增强ACS风险预测。TabulaTime具有三个关键创新点：首先，它将时序空气污染数据与临床表格式数据相结合，以提高预测准确性。其次，其PatchRWKV模块自动提取复杂的时序模式，克服了传统特征工程的局限性，并保持了线性计算复杂度。第三，注意力机制增强了可解释性，揭示了临床和环境因素之间的互动。\n实验结果表明，与传统的CatBoost、随机森林和LightGBM等模型相比，TabulaTime的预测准确性提高超过20%，仅空气污染数据就贡献了超过10%的提升。特征重要性分析识别出的关键预测因子包括既往心绞痛、收缩压、PM10和NO2。总体而言，TabulaTime结合了临床和环境洞察，支持个性化的预防策略，并为制定降低ACS风险的公共卫生政策提供信息。', 'title_zh': 'TabulaTime：一种通过环境数据和临床数据整合以推进急性冠状综合征预测的新型多模态深度学习框架'}
{'arxiv_id': 'arXiv:2502.16879', 'title': 'A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis', 'authors': 'Yuzhi Hao, Danyang Xie', 'link': 'https://arxiv.org/abs/2502.16879', 'abstract': "This paper pioneers a novel approach to economic and public policy analysis by leveraging multiple Large Language Models (LLMs) as heterogeneous artificial economic agents. We first evaluate five LLMs' economic decision-making capabilities in solving two-period consumption allocation problems under two distinct scenarios: with explicit utility functions and based on intuitive reasoning. While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB) framework by mapping these LLMs to specific educational groups and corresponding income brackets. Using interest-income taxation as a case study, we demonstrate how the MLAB framework can simulate policy impacts across heterogeneous agents, offering a promising new direction for economic and public policy analysis by leveraging LLMs' human-like reasoning capabilities and computational power.", 'abstract_zh': '本文通过利用多种大型语言模型（LLMs）作为异质的人工经济代理，开创性地提出了一种新的经济学和公共政策分析方法。我们首先评估了五种LLM在解决两种期消费分配问题下的经济决策能力，这两种问题在两种不同的场景下进行：具有明确的效用函数和基于直观推理。尽管以往的研究常常通过仅仅改变提示来模拟异质性，我们的方法则利用不同LLM在分析能力上的固有差异，来建模具有不同认知特征的代理。在此基础上，我们构建了一个多LLM-代理基础（MLAB）框架，将这些LLM映射到特定的教育群体和对应的收入区间。以兴趣-收入税收为例，我们展示了MLAB框架如何模拟跨异质代理的政策影响，提供了一种利用LLMs的人类级推理能力和计算能力来进行经济学和公共政策分析的有前景的新方向。', 'title_zh': '基于多大语言模型代理的经济与公共政策分析框架'}
{'arxiv_id': 'arXiv:2502.16848', 'title': 'PulseBat: A field-accessible dataset for second-life battery diagnostics from realistic histories using multidimensional rapid pulse test', 'authors': 'Shengyu Tao, Guangyuan Ma, Huixiong Yang, Minyan Lu, Guodan Wei, Guangmin Zhou, Xuan Zhang', 'link': 'https://arxiv.org/abs/2502.16848', 'abstract': 'As electric vehicles (EVs) approach the end of their operational life, their batteries retain significant economic value and present promising opportunities for second-life use and material recycling. This is particularly compelling for Global South and other underdeveloped regions, where reliable energy storage is vital to addressing critical challenges posed by weak and even nonexistent power grid and energy infrastructures. However, despite this potential, widespread adoption has been hindered by critical uncertainties surrounding the technical performance, safety, and recertification of second-life batteries. In cases where they have been redeployed, mismatches between estimated and actual performance often render batteries technically unsuitable or hazardous, turning them into liabilities for communities they were intended to benefit. This considerable misalignment exacerbates energy access disparities and undermines the broader vision of energy justice, highlighting an urgent need for robust and scalable solutions to unlock the potential. In the PulseBat Dataset, the authors tested 464 retired lithium-ion batteries, covering 3 cathode material types, 6 historical usages, 3 physical formats, and 6 capacity designs. The pulse test experiments were performed repeatedly for each second-life battery with 10 pulse width, 10 pulse magnitude, multiple state-of-charge, and state-of-health conditions, e.g., from 0.37 to 1.03. The PulseBat Dataset recorded these test conditions and the voltage response as well as the temperature signals that were subject to the injected pulse current, which could be used as a valuable data resource for critical diagnostics tasks such as state-of-charge estimation, state-of-health estimation, cathode material type identification, open-circuit voltage reconstruction, thermal management, and beyond.', 'abstract_zh': '电动汽车电池寿命结束后的二次利用和材料回收机会及其在Global South及其他欠发达地区的经济价值和安全挑战——以PulseBat数据集为例', 'title_zh': 'PulseBat：来自现实历史的多维快速脉冲测试的二次电池现场可访问诊断数据集'}
{'arxiv_id': 'arXiv:2502.16810', 'title': 'Grounded Persuasive Language Generation for Automated Marketing', 'authors': 'Jibang Wu, Chenghao Yang, Simon Mahns, Chaoqi Wang, Hao Zhu, Fei Fang, Haifeng Xu', 'link': 'https://arxiv.org/abs/2502.16810', 'abstract': 'This paper develops an agentic framework that employs large language models (LLMs) to automate the generation of persuasive and grounded marketing content, using real estate listing descriptions as our focal application domain. Our method is designed to align the generated content with user preferences while highlighting useful factual attributes. This agent consists of three key modules: (1) Grounding Module, mimicking expert human behavior to predict marketable features; (2) Personalization Module, aligning content with user preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion of localized features. We conduct systematic human-subject experiments in the domain of real estate marketing, with a focus group of potential house buyers. The results demonstrate that marketing descriptions generated by our approach are preferred over those written by human experts by a clear margin. Our findings suggest a promising LLM-based agentic framework to automate large-scale targeted marketing while ensuring responsible generation using only facts.', 'abstract_zh': '本文提出了一种代理框架，利用大语言模型（LLMs）自动化生成有说服力且基于事实的营销内容，并以房地产 listings 描述作为主要应用领域。该方法旨在使生成的内容与用户偏好一致，同时突出有用的事实属性。该代理包括三个关键模块：(1) 语境化模块，模仿专家人类行为预测可营销特征；(2) 个性化模块，使内容与用户偏好一致；(3) 营销模块，确保内容的事实准确性并包含本地化特征。我们在房地产营销领域进行了系统的人类被试实验，重点关注潜在购房者组群。实验结果表明，我们方法生成的营销描述在清晰程度上优于人类专家撰写的描述。我们的研究结果表明，利用事实进行负责的大规模定向营销的LLM基于代理框架具有前景。', 'title_zh': '基于产品描述的说服性语言生成在自动营销中的应用'}
{'arxiv_id': 'arXiv:2502.16713', 'title': 'Understanding the Impact of Artificial Intelligence in Academic Writing: Metadata to the Rescue', 'authors': 'Javier Conde, Pedro Reviriego, Joaquín Salvachúa, Gonzalo Martínez, José Alberto Hernández, Fabrizio Lombardi', 'link': 'https://arxiv.org/abs/2502.16713', 'abstract': 'This column advocates for including artificial intelligence (AI)-specific metadata on those academic papers that are written with the help of AI in an attempt to analyze the use of such tools for disseminating research.', 'abstract_zh': '本专栏倡导在使用人工智能（AI）撰写的研究论文中包含专门的元数据，以便分析此类工具在传播研究中的使用情况。', 'title_zh': '理解人工智能在学术写作中的影响：元数据来帮忙'}
{'arxiv_id': 'arXiv:2502.16690', 'title': 'From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task', 'authors': 'Nicolas Martorell', 'link': 'https://arxiv.org/abs/2502.16690', 'abstract': 'Understanding how large language models (LLMs) represent and reason about spatial information is crucial for building robust agentic systems that can navigate real and simulated environments. In this work, we investigate the influence of different text-based spatial representations on LLM performance and internal activations in a grid-world navigation task. By evaluating models of various sizes on a task that requires navigating toward a goal, we examine how the format used to encode spatial information impacts decision-making. Our experiments reveal that cartesian representations of space consistently yield higher success rates and path efficiency, with performance scaling markedly with model size. Moreover, probing LLaMA-3.1-8B revealed subsets of internal units, primarily located in intermediate layers, that robustly correlate with spatial features, such as the position of the agent in the grid or action correctness, regardless of how that information is represented, and are also activated by unrelated spatial reasoning tasks. This work advances our understanding of how LLMs process spatial information and provides valuable insights for developing more interpretable and robust agentic AI systems.', 'abstract_zh': '理解大型语言模型（LLMs）如何表示和推理空间信息对于构建能够在现实和模拟环境中导航的 robust 的代理系统至关重要。在本工作中，我们调查了不同文本基础的空间表示形式对LLM在格网世界导航任务中的性能和内部激活的影响。通过在要求导航至目标的任务中评估不同大小的模型，我们探讨了用于编码空间信息的格式如何影响决策制定。我们的实验表明，空间的笛卡尔表示形式始终能获得更高的成功率和路径效率，且性能随着模型大小的增加而显著提升。此外，对LLaMA-3.1-8B的探查发现了一组内部单元，主要位于中间层，它们与空间特征（如网格中代理的位置或动作的正确性）之间存在稳健的关联，并且无论信息以何种形式表示，这些单元都会被激活，同时也会被无关的空间推理任务激活。这项工作推进了我们对LLMs如何处理空间信息的理解，并为开发更可解释和 robust 的代理AI系统提供了宝贵见解。', 'title_zh': '从文本到空间：在网格世界导航任务中将抽象空间模型映射到LLMs'}
{'arxiv_id': 'arXiv:2502.16666', 'title': 'SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance', 'authors': 'Kunal Singh, Ankan Biswas, Sayandeep Bhowmick, Pradeep Moturi, Siva Kishore Gollapalli', 'link': 'https://arxiv.org/abs/2502.16666', 'abstract': "We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. At each step/turn, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to solve it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC's greedy decoding against self-consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.", 'abstract_zh': 'Step-by-Step Coding (SBSC): 一种多轮数学推理框架，使大规模语言模型能够生成解决奥林匹克级别数学问题的程序序列', 'title_zh': 'SBSC: 分步骤编码以提高数学奥林匹克竞赛表现'}
{'arxiv_id': 'arXiv:2502.16662', 'title': 'Saarthi: The First AI Formal Verification Engineer', 'authors': 'Aman Kumar, Deepak Narayan Gadde, Keerthan Kopparam Radhakrishna, Djones Lettnin', 'link': 'https://arxiv.org/abs/2502.16662', 'abstract': "Recently, Devin has made a significant buzz in the Artificial Intelligence (AI) community as the world's first fully autonomous AI software engineer, capable of independently developing software code. Devin uses the concept of agentic workflow in Generative AI (GenAI), which empowers AI agents to engage in a more dynamic, iterative, and self-reflective process. In this paper, we present a similar fully autonomous AI formal verification engineer, Saarthi, capable of verifying a given RTL design end-to-end using an agentic workflow. With Saarthi, verification engineers can focus on more complex problems, and verification teams can strive for more ambitious goals. The domain-agnostic implementation of Saarthi makes it scalable for use across various domains such as RTL design, UVM-based verification, and others.", 'abstract_zh': '最近，Devin已成为人工智能（AI）领域的一个重要话题，作为全球首个完全自主的AI软件工程师，能够独立开发软件代码。Devin利用生成型AI（GenAI）中的代理工作流概念，使AI代理能够在更具动态性、迭代性和自我反思的过程中进行协作。本文介绍了一个类似完全自主的AI形式验证工程师Saarthi，能够使用代理工作流端到端验证给定的RTL设计。借助Saarthi，形式验证工程师可以专注于更复杂的问题，而形式验证团队可以追求更宏伟的目标。Saarthi的跨域实现使其适用于诸如RTL设计、基于UVM的形式验证等多个领域。', 'title_zh': 'Saarthi: 首个AI形式验证工程师'}
{'arxiv_id': 'arXiv:2502.16634', 'title': 'OptionZero: Planning with Learned Options', 'authors': 'Po-Wei Huang, Pei-Chiun Peng, Hung Guei, Ti-Rong Wu', 'link': 'https://arxiv.org/abs/2502.16634', 'abstract': 'Planning with options -- a sequence of primitive actions -- has been shown effective in reinforcement learning within complex environments. Previous studies have focused on planning with predefined options or learned options through expert demonstration data. Inspired by MuZero, which learns superhuman heuristics without any human knowledge, we propose a novel approach, named OptionZero. OptionZero incorporates an option network into MuZero, providing autonomous discovery of options through self-play games. Furthermore, we modify the dynamics network to provide environment transitions when using options, allowing searching deeper under the same simulation constraints. Empirical experiments conducted in 26 Atari games demonstrate that OptionZero outperforms MuZero, achieving a 131.58% improvement in mean human-normalized score. Our behavior analysis shows that OptionZero not only learns options but also acquires strategic skills tailored to different game characteristics. Our findings show promising directions for discovering and using options in planning. Our code is available at this https URL.', 'abstract_zh': '基于选项的规划——一种由基本动作序列组成的方法，在复杂环境中已被证明在强化学习中有效。先前的研究集中在使用预定义的选项或通过专家示范数据学习选项。受MuZero的启发，MuZero无需任何人类知识即可学习超人类启发式方法，我们提出了一种新颖的方法，名为OptionZero。OptionZero将选项网络整合到MuZero中，通过自我对弈游戏自主发现选项。此外，我们修改了动力学网络，使其在使用选项时提供环境转换，从而在相同的模拟约束下进行更深层次的搜索。在26个Atari游戏中的实证实验表明，OptionZero优于MuZero，平均人类标准化得分为MuZero的131.58%。我们的行为分析表明，OptionZero不仅学习了选项，还学会了适应不同游戏特性的战略技能。我们的研究结果为在规划中发现和使用选项指明了有希望的方向。我们的代码可在以下链接获取：this https URL。', 'title_zh': 'OptionZero: 基于学习的选项规划'}
{'arxiv_id': 'arXiv:2502.16608', 'title': 'Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control', 'authors': 'Yuli Zhang, Shangbo Wang, Dongyao Jia, Pengfei Fan, Ruiyuan Jiang, Hankang Gu, Andy H.F. Chow', 'link': 'https://arxiv.org/abs/2502.16608', 'abstract': 'Reinforcement learning (RL) emerges as a promising data-driven approach for adaptive traffic signal control (ATSC) in complex urban traffic networks, with deep neural networks substantially augmenting its learning capabilities. However, centralized RL becomes impractical for ATSC involving multiple agents due to the exceedingly high dimensionality of the joint action space. Multi-agent RL (MARL) mitigates this scalability issue by decentralizing control to local RL agents. Nevertheless, this decentralized method introduces new challenges: the environment becomes partially observable from the perspective of each local agent due to constrained inter-agent communication. Both centralized RL and MARL exhibit distinct strengths and weaknesses, particularly under heavy intersectional traffic conditions. In this paper, we justify that MARL can achieve the optimal global Q-value by separating into multiple IRL (Independent Reinforcement Learning) processes when no spill-back congestion occurs (no agent dependency) among agents (intersections). In the presence of spill-back congestion (with agent dependency), the maximum global Q-value can be achieved by using centralized RL. Building upon the conclusions, we propose a novel Dynamic Parameter Update Strategy for Deep Q-Network (DQN-DPUS), which updates the weights and bias based on the dependency dynamics among agents, i.e. updating only the diagonal sub-matrices for the scenario without spill-back congestion. We validate the DQN-DPUS in a simple network with two intersections under varying traffic, and show that the proposed strategy can speed up the convergence rate without sacrificing optimal exploration. The results corroborate our theoretical findings, demonstrating the efficacy of DQN-DPUS in optimizing traffic signal control.', 'abstract_zh': '加强学习（RL）在复杂城市交通网络中适应性交通信号控制（ATSC）中的数据驱动方法展现出前景，深度神经网络大幅增强了其学习能力。然而，对于涉及多个代理的ATSC，集中式RL由于联合动作空间的极高维度而变得实用性较差。多代理RL（MARL）通过将控制 decentralize 给本地RL代理来缓解这一可扩展性问题。尽管如此，这种方法也引入了新的挑战：每个本地代理由于代理间通信受限而只能从局部视角观察环境。集中式RL和MARL在重叠交叉口交通条件下各自表现出不同的优势和劣势。在本文中，我们证明，在没有溢出拥堵（无代理依赖）的情况下，MARL可以通过分离成多个独立强化学习（IRL）过程来实现全局最优的Q值。在存在溢出拥堵（有代理依赖）的情况下，可通过使用集中式RL来实现全局最优的Q值。基于上述结论，我们提出了一种新的动态参数更新策略（DQN-DPUS），该策略根据代理间的依赖动态更新权重和偏置，即在无溢出拥堵的情况下仅更新对角子矩阵。我们在一个包含两个交叉口的简单网络中验证了DQN-DPUS，在不同交通条件下展示了该策略可以提高收敛速度且不牺牲最优探索。结果验证了我们的理论发现，证明了DQN-DPUS在优化交通信号控制方面的有效性。', 'title_zh': '多智能体强化学习在交通信号控制中的依赖动力学研究'}
{'arxiv_id': 'arXiv:2502.16606', 'title': 'Reasoning about Affordances: Causal and Compositional Reasoning in LLMs', 'authors': 'Magnus F. Gjerde, Vanessa Cheung, David Lagnado', 'link': 'https://arxiv.org/abs/2502.16606', 'abstract': "With the rapid progress of Large Language Models (LLMs), it becomes increasingly important to understand their abilities and limitations. In two experiments, we investigate the causal and compositional reasoning abilities of LLMs and humans in the domain of object affordances, an area traditionally linked to embodied cognition. The tasks, designed from scratch to avoid data contamination, require decision-makers to select unconventional objects to replace a typical tool for a particular purpose, such as using a table tennis racket to dig a hole. In Experiment 1, we evaluated GPT-3.5 and GPT-4o, finding that GPT-4o, when given chain-of-thought prompting, performed on par with human participants, while GPT-3.5 lagged significantly. In Experiment 2, we introduced two new conditions, Distractor (more object choices, increasing difficulty) and Image (object options presented visually), and evaluated Claude 3 Sonnet and Claude 3.5 Sonnet in addition to the GPT models. The Distractor condition significantly impaired performance across humans and models, although GPT-4o and Claude 3.5 still performed well above chance. Surprisingly, the Image condition had little impact on humans or GPT-4o, but significantly lowered Claude 3.5's accuracy. Qualitative analysis showed that GPT-4o and Claude 3.5 have a stronger ability than their predecessors to identify and flexibly apply causally relevant object properties. The improvement from GPT-3.5 and Claude 3 to GPT-4o and Claude 3.5 suggests that models are increasingly capable of causal and compositional reasoning in some domains, although further mechanistic research is necessary to understand how LLMs reason.", 'abstract_zh': '随着大型语言模型（LLMs）的快速进步，理解其能力与局限性变得越来越重要。在两项实验中，我们探讨了LLMs和人类在物体功能领域的因果与组合推理能力，该领域传统上与知觉认知相关。实验任务从头设计，以避免数据污染，要求决策者选择非典型物体替代特定用途的常规工具，例如使用网球拍挖洞。在实验1中，我们评估了GPT-3.5和GPT-4o，发现当给予逐步思考提示时，GPT-4o的表现与人类参与者相当，而GPT-3.5显著落后。在实验2中，我们引入了两个新条件，干扰（更多的物体选择，增加难度）和图片（以视觉方式呈现物体选项），并评估了Claude 3 Sonnet和Claude 3.5 Sonnet，除GPT模型外。干扰条件显著降低了人类和模型的表现，尽管GPT-4o和Claude 3.5仍表现远超偶然水平。令人惊讶的是，图片条件对人类和GPT-4o几乎没有影响，但显著降低了Claude 3.5的准确性。定性分析显示，GPT-4o和Claude 3.5比其前代产品更擅长识别和灵活应用因果相关物体属性。从GPT-3.5和Claude 3到GPT-4o和Claude 3.5的改进表明，模型在某些领域中越来越能够进行因果与组合推理，但需要进一步机制性研究来理解LLMs是如何推理的。', 'title_zh': '关于 affordances 的推理：LLMs 中的因果与组合推理'}
{'arxiv_id': 'arXiv:2502.16593', 'title': 'Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images', 'authors': 'Yubo Wang, Jianting Tang, Chaohu Liu, Linli Xu', 'link': 'https://arxiv.org/abs/2502.16593', 'abstract': "Large vision-language models (LVLMs) have demonstrated remarkable image understanding and dialogue capabilities, allowing them to handle a variety of visual question answering tasks. However, their widespread availability raises concerns about unauthorized usage and copyright infringement, where users or individuals can develop their own LVLMs by fine-tuning published models. In this paper, we propose a novel method called Parameter Learning Attack (PLA) for tracking the copyright of LVLMs without modifying the original model. Specifically, we construct adversarial images through targeted attacks against the original model, enabling it to generate specific outputs. To ensure these attacks remain effective on potential fine-tuned models to trigger copyright tracking, we allow the original model to learn the trigger images by updating parameters in the opposite direction during the adversarial attack process. Notably, the proposed method can be applied after the release of the original model, thus not affecting the model's performance and behavior. To simulate real-world applications, we fine-tune the original model using various strategies across diverse datasets, creating a range of models for copyright verification. Extensive experiments demonstrate that our method can more effectively identify the original copyright of fine-tuned models compared to baseline methods. Therefore, this work provides a powerful tool for tracking copyrights and detecting unlicensed usage of LVLMs.", 'abstract_zh': '大型 vision-language 模型的版权追踪方法：无需修改原始模型的参数学习攻击（PLA）', 'title_zh': '通过参数学习对抗样本追踪大型视觉-语言模型的版权'}
{'arxiv_id': 'arXiv:2502.16573', 'title': 'LawPal : A Retrieval Augmented Generation Based System for Enhanced Legal Accessibility in India', 'authors': 'Dnyanesh Panchal, Aaryan Gole, Vaibhav Narute, Raunak Joshi', 'link': 'https://arxiv.org/abs/2502.16573', 'abstract': 'Access to legal knowledge in India is often hindered by a lack of awareness, misinformation and limited accessibility to judicial resources. Many individuals struggle to navigate complex legal frameworks, leading to the frequent misuse of laws and inadequate legal protection. To address these issues, we propose a Retrieval-Augmented Generation (RAG)-based legal chatbot powered by vectorstore oriented FAISS for efficient and accurate legal information retrieval. Unlike traditional chatbots, our model is trained using an extensive dataset comprising legal books, official documentation and the Indian Constitution, ensuring accurate responses to even the most complex or misleading legal queries. The chatbot leverages FAISS for rapid vector-based search, significantly improving retrieval speed and accuracy. It is also prompt-engineered to handle twisted or ambiguous legal questions, reducing the chances of incorrect interpretations. Apart from its core functionality of answering legal queries, the platform includes additional features such as real-time legal news updates, legal blogs, and access to law-related books, making it a comprehensive resource for users. By integrating advanced AI techniques with an optimized retrieval system, our chatbot aims to democratize legal knowledge, enhance legal literacy, and prevent the spread of misinformation. The study demonstrates that our approach effectively improves legal accessibility while maintaining high accuracy and efficiency, thereby contributing to a more informed and empowered society.', 'abstract_zh': '印度法律知识的获取往往受到缺乏意识、错误信息以及司法资源有限性的阻碍。许多个人难以导航复杂的法律框架，导致法律的误用和法律保护不足。为了解决这些问题，我们提议使用基于FAISS向量存储的检索增强生成（RAG）法律聊天机器人。与传统的聊天机器人不同，我们的模型是基于一个包含法律书籍、官方文件和印度宪法的庞大数据库进行训练的，确保对最复杂或误导性的法律查询也能提供准确的回答。聊天机器人利用FAISS进行快速向量搜索，显著提高检索速度和准确性。此外，该聊天机器人还经过提示工程设计，能够处理扭曲或模糊的法律问题，从而降低错误解释的可能性。除了核心功能——回答法律查询外，该平台还包括实时法律新闻更新、法律博客和法律相关书籍的访问等功能，使其成为用户全面的资源。通过将先进的AI技术与优化的检索系统结合，我们的聊天机器人旨在普及法律知识、提升法律素养，并防止错误信息的传播。研究表明，我们的方法在保持高准确性与效率的同时有效提高了法律的可获取性，从而有助于构建一个更加知情和自主的社会。', 'title_zh': 'LawPal：一种增强印度法律可访问性的检索增强生成系统'}
{'arxiv_id': 'arXiv:2502.16560', 'title': 'Analysis of Emotion in Rumour Threads on Social Media', 'authors': 'Rui Xing, Boyang Sun, Kun Zhang, Timothy Baldwin, Jey Han Lau', 'link': 'https://arxiv.org/abs/2502.16560', 'abstract': 'Rumours in online social media pose significant risks to modern society, motivating the need for better understanding of how they develop. We focus specifically on the interface between emotion and rumours in threaded discourses, building on the surprisingly sparse literature on the topic which has largely focused on emotions within the original rumour posts themselves, and largely overlooked the comparative differences between rumours and non-rumours. In this work, we provide a comprehensive analytical emotion framework, contrasting rumour and non-rumour cases using existing NLP datasets to further understand the emotion dynamics within rumours. Our framework reveals several findings: rumours exhibit more negative sentiment and emotions, including anger, fear and pessimism, while non-rumours evoke more positive emotions; emotions are contagious in online interactions, with rumours facilitate negative emotions and non-rumours foster positive emotions; and based on causal analysis, surprise acts as a bridge between rumours and other emotions, pessimism is driven by sadness and fear, optimism by joy and love.', 'abstract_zh': '在线社交媒体中的谣言对现代社会构成重大风险，推动了对其发展机制的更好理解的需求。我们特别关注情绪与谣言在主题讨论中的界面，延续了该领域令人惊讶地稀少的研究，这些研究主要集中在原始谣言帖子本身的情绪上，并且很大程度上忽视了谣言与非谣言之间的情绪差异。在本文中，我们提供了一个全面的情绪分析框架，通过现有的自然语言处理数据集对比分析谣言和非谣言案例，以进一步理解谣言中的情绪动态。我们的框架揭示了几个发现：谣言表现出更多负面情绪和情感，包括愤怒、恐惧和悲观；情绪在网络互动中具有传染性，谣言促进负面情绪，而非谣言促进积极情绪；基于因果分析，惊讶在谣言与其他情绪之间起到桥梁作用，悲观由悲伤和恐惧驱动，乐观由喜悦和爱驱动。', 'title_zh': '社交媒体上谣言线上的情绪分析'}
{'arxiv_id': 'arXiv:2502.16535', 'title': 'Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial Networks (GANs) in Addressing Data Imbalance', 'authors': 'Pankaj Yadav, Gulshan Sihag, Vivek Vijay', 'link': 'https://arxiv.org/abs/2502.16535', 'abstract': 'Machine learning algorithms are used in diverse domains, many of which face significant challenges due to data imbalance. Studies have explored various approaches to address the issue, like data preprocessing, cost-sensitive learning, and ensemble methods. Generative Adversarial Networks (GANs) showed immense potential as a data preprocessing technique that generates good quality synthetic data. This study employs a systematic mapping methodology to analyze 3041 papers on GAN-based sampling techniques for imbalanced data sourced from four digital libraries. A filtering process identified 100 key studies spanning domains such as healthcare, finance, and cybersecurity. Through comprehensive quantitative analysis, this research introduces three categorization mappings as application domains, GAN techniques, and GAN variants used to handle the imbalanced nature of the data. GAN-based over-sampling emerges as an effective preprocessing method. Advanced architectures and tailored frameworks helped GANs to improve further in the case of data imbalance. GAN variants like vanilla GAN, CTGAN, and CGAN show great adaptability in structured imbalanced data cases. Interest in GANs for imbalanced data has grown tremendously, touching a peak in recent years, with journals and conferences playing crucial roles in transmitting foundational theories and practical applications. While with these advances, none of the reviewed studies explicitly explore hybridized GAN frameworks with diffusion models or reinforcement learning techniques. This gap leads to a future research idea develop innovative approaches for effectively handling data imbalance.', 'abstract_zh': '基于生成对抗网络的不平衡数据采样技术综述：应用领域、GAN技术与变体分类', 'title_zh': '重新平衡天平：生成对抗网络（GANs）在解决数据不平衡问题中的系统映射研究'}
{'arxiv_id': 'arXiv:2502.16449', 'title': 'Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning', 'authors': 'Haoran Su', 'link': 'https://arxiv.org/abs/2502.16449', 'abstract': "Emergency Response Time (ERT) is crucial for urban safety, measuring cities' ability to handle medical, fire, and crime emergencies. In NYC, medical ERT increased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of delays due to Emergency Vehicle (EMV) travel times. Each minute's delay in stroke response costs 2 million brain cells, while cardiac arrest survival drops 7-10% per minute.\nThis dissertation advances EMV facilitation through three contributions. First, EMVLight, a decentralized multi-agent reinforcement learning framework, integrates EMV routing with traffic signal pre-emption. It achieved 42.6% faster EMV travel times and 23.5% improvement for other vehicles.\nSecond, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy Optimization for coordinated lane-clearing in mixed autonomous and human-driven traffic, reducing EMV travel times by 40%.\nThird, an equity study of NYC Emergency Medical Services revealed disparities across boroughs: Staten Island faces delays due to sparse signalized intersections, while Manhattan struggles with congestion. Solutions include optimized EMS stations and improved intersection designs.\nThese contributions enhance EMV mobility and emergency service equity, offering insights for policymakers and urban planners to develop safer, more efficient transportation systems.", 'abstract_zh': '应急响应时间(ERT)对于城市安全至关重要，衡量城市处理医疗、消防和犯罪紧急事件的能力。在纽约市，医疗ERT从2014年的7.89分钟增加到2024年的14.27分钟，增加了72%，其中一半的延误是由于紧急车辆(EV)的行驶时间。每一分钟的延误会损失200万个脑细胞，心脏病发作生存率每分钟下降7-10%。', 'title_zh': '使用多智能体深度强化学习在拥堵的城市区域促进急救车辆通行'}
{'arxiv_id': 'arXiv:2502.16402', 'title': 'Navigation-GPT: A Robust and Adaptive Framework Utilizing Large Language Models for Navigation Applications', 'authors': 'Feng Ma, Xiu-min Wang, Chen Chen, Xiao-bin Xu, Xin-ping Yan', 'link': 'https://arxiv.org/abs/2502.16402', 'abstract': 'Existing navigation decision support systems often perform poorly when handling non-predefined navigation scenarios. Leveraging the generalization capabilities of large language model (LLM) in handling unknown scenarios, this research proposes a dual-core framework for LLM applications to address this issue. Firstly, through ReAct-based prompt engineering, a larger LLM core decomposes intricate navigation tasks into manageable sub-tasks, which autonomously invoke corresponding external tools to gather relevant information, using this feedback to mitigate the risk of LLM hallucinations. Subsequently, a fine-tuned and compact LLM core, acting like a first-mate is designed to process such information and unstructured external data, then to generates context-aware recommendations, ultimately delivering lookout insights and navigation hints that adhere to the International Regulations for Preventing Collisions at Sea (COLREGs) and other rules. Extensive experiments demonstrate the proposed framework not only excels in traditional ship collision avoidance tasks but also adapts effectively to unstructured, non-predefined, and unpredictable scenarios. A comparative analysis with DeepSeek-R1, GPT-4o and other SOTA models highlights the efficacy and rationality of the proposed framework. This research bridges the gap between conventional navigation systems and LLMs, offering a framework to enhance safety and operational efficiency across diverse navigation applications.', 'abstract_zh': '基于大型语言模型的双重核心框架以应对非预定义导航场景的研究', 'title_zh': '导航-GPT：一种利用大规模语言模型的鲁棒且适应性强的导航应用框架'}
{'arxiv_id': 'arXiv:2502.16376', 'title': 'Does Your AI Agent Get You? A Personalizable Framework for Approximating Human Models from Argumentation-based Dialogue Traces', 'authors': 'Yinxu Tang, Stylianos Loukas Vasileiou, William Yeoh', 'link': 'https://arxiv.org/abs/2502.16376', 'abstract': 'Explainable AI is increasingly employing argumentation methods to facilitate interactive explanations between AI agents and human users. While existing approaches typically rely on predetermined human user models, there remains a critical gap in dynamically learning and updating these models during interactions. In this paper, we present a framework that enables AI agents to adapt their understanding of human users through argumentation-based dialogues. Our approach, called Persona, draws on prospect theory and integrates a probability weighting function with a Bayesian belief update mechanism that refines a probability distribution over possible human models based on exchanged arguments. Through empirical evaluations with human users in an applied argumentation setting, we demonstrate that Persona effectively captures evolving human beliefs, facilitates personalized interactions, and outperforms state-of-the-art methods.', 'abstract_zh': '可解释AI正越来越多地采用论辩方法以促进AI代理与人类用户之间的互动解释。尽管现有方法通常依赖于预设的人类用户模型，但在交互过程中动态学习和更新这些模型仍存在关键缺口。本文提出了一种框架，使AI代理能够通过论辩式对话来适应其对人类用户的理解。我们的方法名为Persona，它借鉴了前景理论，并结合了概率权重函数与贝叶斯信念更新机制，根据交换的论点来细化对潜在人类模型的概率分布。通过在实际论辩场景中的人类用户实证评估，我们展示了Persona能够有效捕捉人类信念的变化，促进个性化交互，并优于现有方法。', 'title_zh': '你的AI代理了解你吗？一种基于论证对话轨迹的人类模型可个性化解析框架'}
{'arxiv_id': 'arXiv:2502.16320', 'title': 'Direct Alignment with Heterogeneous Preferences', 'authors': 'Ali Shirali, Arash Nasr-Esfahany, Abdullah Alomar, Parsa Mirtaheri, Rediet Abebe, Ariel Procaccia', 'link': 'https://arxiv.org/abs/2502.16320', 'abstract': 'Alignment with human preferences is commonly framed using a universal reward function, even though human preferences are inherently heterogeneous. We formalize this heterogeneity by introducing user types and examine the limits of the homogeneity assumption. We show that aligning to heterogeneous preferences with a single policy is best achieved using the average reward across user types. However, this requires additional information about annotators. We examine improvements under different information settings, focusing on direct alignment methods. We find that minimal information can yield first-order improvements, while full feedback from each user type leads to consistent learning of the optimal policy. Surprisingly, however, no sample-efficient consistent direct loss exists in this latter setting. These results reveal a fundamental tension between consistency and sample efficiency in direct policy alignment.', 'abstract_zh': '异构偏好下的对齐：从统一奖励函数到用户类型平均奖励的探索', 'title_zh': '直接对齐异质偏好'}
{'arxiv_id': 'arXiv:2502.16242', 'title': 'Reproducibility Study of Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation', 'authors': 'Jose L. Garcia, Karolina Hajkova, Maria Marchenko, Carlos Miguel Patiño', 'link': 'https://arxiv.org/abs/2502.16242', 'abstract': 'This paper presents a reproducibility study and extension of "Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation." We validate the original findings using a range of open-weight models (1.5B-70B parameters) and GPT-4o Mini while introducing several novel contributions. We analyze the Pareto front of the games, propose a communication-free baseline to test whether successful negotiations are possible without agent interaction, evaluate recent small language models\' performance, analyze structural information leakage in model responses, and implement an inequality metric to assess negotiation fairness. Our results demonstrate that smaller models (<10B parameters) struggle with format adherence and coherent responses, but larger open-weight models can approach proprietary model performance. Additionally, in many scenarios, single-agent approaches can achieve comparable results to multi-agent negotiations, challenging assumptions about the necessity of agent communication to perform well on the benchmark. This work also provides insights into the accessibility, fairness, environmental impact, and privacy considerations of LLM-based negotiation systems.', 'abstract_zh': '本研究呈现了对“合作、竞争与恶意行为：大语言模型利益相关者互动谈判”的可再现性和扩展研究。我们使用一系列不同规模的开放权重模型（1.5B-70B参数）和GPT-4o Mini验证了原始发现，并提出了多项新颖贡献。我们分析了游戏的帕累托前沿，提出了一个无通信的基础线来检验是否无需代理交互就能实现成功的谈判，评估了最近的小型语言模型的性能，分析了模型响应中的结构性信息泄漏，并实现了不等量度来评估谈判的公平性。研究结果表明，小型模型（<10B参数）在格式遵守和连贯响应方面存在困难，而较大的开放权重模型能够接近专有模型的性能。此外，在许多场景中，单代理方法可以实现与多代理谈判相当的结果，挑战了关于代理通信在基准测试中表现良好的必要性的假设。本研究还提供了基于大语言模型的谈判系统在可访问性、公平性、环境影响和隐私方面的见解。', 'title_zh': '合作、竞争与恶意行为的可重复性研究：LLM相关利益方的交互式谈判'}
{'arxiv_id': 'arXiv:2502.16235', 'title': 'Dynamic Parallel Tree Search for Efficient LLM Reasoning', 'authors': 'Yifu Ding, Wentao Jiang, Shunyu Liu, Yongcheng Jing, Jinyang Guo, Yingjie Wang, Jing Zhang, Zengmao Wang, Ziwei Liu, Bo Du, Xianglong Liu, Dacheng Tao', 'link': 'https://arxiv.org/abs/2502.16235', 'abstract': 'Tree of Thoughts (ToT) enhances Large Language Model (LLM) reasoning by structuring problem-solving as a spanning tree. However, recent methods focus on search accuracy while overlooking computational efficiency. The challenges of accelerating the ToT lie in the frequent switching of reasoning focus, and the redundant exploration of suboptimal solutions. To alleviate this dilemma, we propose Dynamic Parallel Tree Search (DPTS), a novel parallelism framework that aims to dynamically optimize the reasoning path in inference. It includes the Parallelism Streamline in the generation phase to build up a flexible and adaptive parallelism with arbitrary paths by fine-grained cache management and alignment. Meanwhile, the Search and Transition Mechanism filters potential candidates to dynamically maintain the reasoning focus on more possible solutions and have less redundancy. Experiments on Qwen-2.5 and Llama-3 with Math500 and GSM8K datasets show that DPTS significantly improves efficiency by 2-4x on average while maintaining or even surpassing existing reasoning algorithms in accuracy, making ToT-based reasoning more scalable and computationally efficient.', 'abstract_zh': 'Dynamic Parallel Tree Search (DPTS) 提升了基于 spanning tree 的 Large Language Model (LLM) 推理效率，同时保持或超越现有推理算法的准确性。', 'title_zh': '高效大型语言模型推理的动态并行树搜索方法'}
{'arxiv_id': 'arXiv:2502.16203', 'title': 'Machine Learning Framework for Early Power, Performance, and Area Estimation of RTL', 'authors': 'Anindita Chattopadhyay, Vijay Kumar Sutrakar', 'link': 'https://arxiv.org/abs/2502.16203', 'abstract': 'A critical stage in the evolving landscape of VLSI design is the design phase that is transformed into register-transfer level (RTL), which specifies system functionality through hardware description languages like Verilog. Generally, evaluating the quality of an RTL design demands full synthesis via electronic design automation (EDA) tool is time-consuming process that is not well-suited to rapid design iteration and optimization. Although recent breakthroughs in machine Learning (ML) have brought early prediction models, these methods usually do not provide robust and generalizable solutions with respect to a wide range of RTL designs. This paper proposes a pre-synthesis framework that makes early estimation of power, performance and area (PPA) metrics directly from the hardware description language (HDL) code making direct use of library files instead of toggle files. The proposed framework introduces a bit-level representation referred to as the simple operator graph (SOG), which uses single-bit operators to generate a generalized and flexible structure that closely mirrors the characteristics of post synthesis design. The proposed model bridges the RTL and post-synthesis design, which will help in precisely predicting key metrics. The proposed tree-based ML framework shows superior predictive performance PPA estimation. Validation is carried out on 147 distinct RTL designs. The proposed model with 147 different designs shows accuracy of 98%, 98%, and 90% for WNS, TNS and power, respectively, indicates significant accuracy improvements relative to state-of-the-art methods.', 'abstract_zh': '一种从硬件描述语言代码预估VLSI设计的功耗、性能和面积的机器学习框架', 'title_zh': '基于RTL的早期功耗、性能和面积估算机器学习框架'}
{'arxiv_id': 'arXiv:2502.16184', 'title': 'Robustness and Cybersecurity in the EU Artificial Intelligence Act', 'authors': 'Henrik Nolte, Miriam Rateike, Michèle Finck', 'link': 'https://arxiv.org/abs/2502.16184', 'abstract': 'The EU Artificial Intelligence Act (AIA) establishes different legal principles for different types of AI systems. While prior work has sought to clarify some of these principles, little attention has been paid to robustness and cybersecurity. This paper aims to fill this gap. We identify legal challenges and shortcomings in provisions related to robustness and cybersecurity for high-risk AI systems (Art. 15 AIA) and general-purpose AI models (Art. 55 AIA). We show that robustness and cybersecurity demand resilience against performance disruptions. Furthermore, we assess potential challenges in implementing these provisions in light of recent advancements in the machine learning (ML) literature. Our analysis informs efforts to develop harmonized standards, guidelines by the European Commission, as well as benchmarks and measurement methodologies under Art. 15(2) AIA. With this, we seek to bridge the gap between legal terminology and ML research, fostering a better alignment between research and implementation efforts.', 'abstract_zh': '欧盟人工智能法案(AIA)为不同类型的AI系统确立了不同的法律原则。虽然 prior work 尝试阐明了其中的一些原则，但对鲁棒性和网络安全的关注不足。本文旨在填补这一空白。我们识别了与高风险AI系统（AIA第15条）和通用AI模型（AIA第55条）相关的鲁棒性和网络安全条款中的法律挑战和缺陷。我们表明，鲁棒性和网络安全要求能够抵御性能中断的抗扰性。此外，我们评估了在考虑近期机器学习（ML）文献进展的情况下实施这些条款的潜在挑战。我们的分析为欧盟委员会制定 harmonized 标准、指南以及AIA第15条第2款下的基准和测量方法论提供了指导。借此，我们力求在法律术语与ML研究之间建立桥梁，促进研究与实施努力之间的更好对齐。', 'title_zh': '欧盟人工智能法案中的健壮性与网络安全性'}
{'arxiv_id': 'arXiv:2502.16169', 'title': 'Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations', 'authors': 'Chunyang Li, Weiqi Wang, Tianshi Zheng, Yangqiu Song', 'link': 'https://arxiv.org/abs/2502.16169', 'abstract': "Inductive reasoning, a cornerstone of human cognition, enables generalization from limited data but hasn't yet been fully achieved by large language models (LLMs). While modern LLMs excel at reasoning tasks, their ability to maintain stable and consistent rule abstraction under imperfect observations remains underexplored. To fill this gap, in this work, we introduce Robust Rule Induction, a task that evaluates LLMs' capability in inferring rules from data that are fused with noisy examples. To address this task, we further propose Sample-steered Rule Refinement (SRR), a method enhancing reasoning stability via observation diversification and execution-guided feedback. Experiments across arithmetic, cryptography, and list functions reveal: (1) SRR outperforms other methods with minimal performance degradation under noise; (2) Despite slight accuracy variation, LLMs exhibit instability under noise (e.g., 0% accuracy change with only 70% consistent score); (3) Counterfactual task gaps highlight LLMs' reliance on memorized patterns over genuine abstraction. Our findings challenge LLMs' reasoning robustness, revealing susceptibility to hypothesis drift and pattern overfitting, while providing empirical evidence critical for developing human-like inductive systems. Code and data are available at \\href{this https URL}{this https URL}.", 'abstract_zh': '基于不确定样本的稳健规则归纳：填补大型语言模型归纳推理稳定性不足的缺口', 'title_zh': '模式胜于原则： noisy 观测下 LLMs 归纳推理的脆弱性'}
{'arxiv_id': 'arXiv:2502.16111', 'title': 'PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving', 'authors': 'Mihir Parmar, Xin Liu, Palash Goyal, Yanfei Chen, Long Le, Swaroop Mishra, Hossein Mobahi, Jindong Gu, Zifeng Wang, Hootan Nakhost, Chitta Baral, Chen-Yu Lee, Tomas Pfister, Hamid Palangi', 'link': 'https://arxiv.org/abs/2502.16111', 'abstract': 'Recent agent frameworks and inference-time algorithms often struggle with complex planning problems due to limitations in verifying generated plans or reasoning and varying complexity of instances within a single task. Many existing methods for these tasks either perform task-level verification without considering constraints or apply inference-time algorithms without adapting to instance-level complexity. To address these limitations, we propose PlanGEN, a model-agnostic and easily scalable agent framework with three key components: constraint, verification, and selection agents. Specifically, our approach proposes constraint-guided iterative verification to enhance performance of inference-time algorithms--Best of N, Tree-of-Thought, and REBASE. In PlanGEN framework, the selection agent optimizes algorithm choice based on instance complexity, ensuring better adaptability to complex planning problems. Experimental results demonstrate significant improvements over the strongest baseline across multiple benchmarks, achieving state-of-the-art results on NATURAL PLAN ($\\sim$8%$\\uparrow$), OlympiadBench ($\\sim$4%$\\uparrow$), DocFinQA ($\\sim$7%$\\uparrow$), and GPQA ($\\sim$1%$\\uparrow$). Our key finding highlights that constraint-guided iterative verification improves inference-time algorithms, and adaptive selection further boosts performance on complex planning and reasoning problems.', 'abstract_zh': 'Recent Agent Frameworks and Inference-Time Algorithms Often Struggle with Complex Planning Problems Due to Limitations in Verifying Generated Plans or Reasoning and Varying Complexity of Instances within a Single Task: PlanGEN, a Model-Agnostic and Scalable Agent Framework with Constraint, Verification, and Selection Agents', 'title_zh': 'PlanGEN: 一种用于复杂问题解决的规划与推理轨迹生成的多agent框架'}
{'arxiv_id': 'arXiv:2502.16101', 'title': 'Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals', 'authors': 'Linda Zeng, Rithwik Gupta, Divij Motwani, Diji Yang, Yi Zhang', 'link': 'https://arxiv.org/abs/2502.16101', 'abstract': 'Retrieval-augmented generation (RAG) has shown impressive capabilities in mitigating hallucinations in large language models (LLMs). However, LLMs struggle to handle misleading retrievals and often fail to maintain their own reasoning when exposed to conflicting or selectively-framed evidence, making them vulnerable to real-world misinformation. In such real-world retrieval scenarios, misleading and conflicting information is rampant, particularly in the political domain, where evidence is often selectively framed, incomplete, or polarized. However, existing RAG benchmarks largely assume a clean retrieval setting, where models succeed by accurately retrieving and generating answers from gold-standard documents. This assumption fails to align with real-world conditions, leading to an overestimation of RAG system performance. To bridge this gap, we introduce RAGuard, a fact-checking dataset designed to evaluate the robustness of RAG systems against misleading retrievals. Unlike prior benchmarks that rely on synthetic noise, our dataset constructs its retrieval corpus from Reddit discussions, capturing naturally occurring misinformation. It categorizes retrieved evidence into three types: supporting, misleading, and irrelevant, providing a realistic and challenging testbed for assessing how well RAG systems navigate different retrieval information. Our benchmark experiments reveal that when exposed to misleading retrievals, all tested LLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no retrieval at all), highlighting their susceptibility to noisy environments. To the best of our knowledge, RAGuard is the first benchmark to systematically assess RAG robustness against misleading evidence. We expect this benchmark will drive future research toward improving RAG systems beyond idealized datasets, making them more reliable for real-world applications.', 'abstract_zh': 'RAGuard: 一个用于评估RAG系统对误导性检索鲁棒性的事实核查数据集', 'title_zh': '零-shot以外的表现？一种事实核查数据集，用于评估RAG在面对误导性检索时的鲁棒性'}
{'arxiv_id': 'arXiv:2502.16069', 'title': 'Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents', 'authors': 'Patrick Tser Jern Kon, Jiachen Liu, Qiuyi Ding, Yiming Qiu, Zhenning Yang, Yibo Huang, Jayanth Srinivasa, Myungjin Lee, Mosharaf Chowdhury, Ang Chen', 'link': 'https://arxiv.org/abs/2502.16069', 'abstract': 'Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4$\\times$ improvement in correctly answering experimental this http URL is open-sourced at this https URL.', 'abstract_zh': '科学实验是人类进步的基石，要求在可靠性、方法控制和可解释性方面具备严谨性以得出有意义的结果。尽管大型语言模型（LLMs）在自动化科学过程的不同方面的能力日益增强，但在自动化严谨性实验方面仍面临着重大挑战。为解决这一问题，我们提出了Curie，一种AI代理框架，通过三种关键组件嵌入严谨性：内部代理严谨性模块提升可靠性，跨代理严谨性模块维持方法控制，以及实验知识模块增强可解释性。为了评估Curie，我们设计了一个新型实验基准，包含来自四大计算机科学领域的46个问题，这些问题源自影响力巨大的研究论文并广泛采用开源项目。与测试的最强基线相比，我们在正确回答实验问题方面实现了3.4倍的改进。Curie已开源。', 'title_zh': 'Curie: 朝向严谨且自动化的AI代理科学研究方法'}
{'arxiv_id': 'arXiv:2502.16033', 'title': 'Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models', 'authors': 'Qianqi Yan, Yue Fan, Hongquan Li, Shan Jiang, Yang Zhao, Xinze Guan, Ching-Chen Kuo, Xin Eric Wang', 'link': 'https://arxiv.org/abs/2502.16033', 'abstract': "Existing Multimodal Large Language Models (MLLMs) are predominantly trained and tested on consistent visual-textual inputs, leaving open the question of whether they can handle inconsistencies in real-world, layout-rich content. To bridge this gap, we propose the Multimodal Inconsistency Reasoning (MMIR) benchmark to assess MLLMs' ability to detect and reason about semantic mismatches in artifacts such as webpages, presentation slides, and posters. MMIR comprises 534 challenging samples, each containing synthetically injected errors across five reasoning-heavy categories: Factual Contradiction, Identity Misattribution, Contextual Mismatch, Quantitative Discrepancy, and Temporal/Spatial Incoherence. We evaluate six state-of-the-art MLLMs, showing that models with dedicated multimodal reasoning capabilities, such as o1, substantially outperform their counterparts while open-source models remain particularly vulnerable to inconsistency errors. Detailed error analyses further show that models excel in detecting inconsistencies confined to a single modality, particularly in text, but struggle with cross-modal conflicts and complex layouts. Probing experiments reveal that single-modality prompting, including Chain-of-Thought (CoT) and Set-of-Mark (SoM) methods, yields marginal gains, revealing a key bottleneck in cross-modal reasoning. Our findings highlight the need for advanced multimodal reasoning and point to future research on multimodal inconsistency.", 'abstract_zh': '现有多种模态大型语言模型（MLLMs）主要在一致的视觉-文本输入上进行训练和测试，这留下了一个问题，即它们是否能够处理现实世界中布局丰富的不一致性内容。为了弥合这一差距，我们提出了多模态不一致性推理（MMIR）基准，以评估MLLMs在检测和推理艺术品（如网页、演示文稿和海报中的语义不匹配）方面的能力。MMIR包含534个具有挑战性的样本，每个样本都含有在五个推理密集类别中注入的合成错误：事实矛盾、身份误归因、上下文不匹配、定量偏差和时空不连贯性。我们评估了六种最先进的MLLMs，结果显示，具有专门多模态推理能力的模型，如o1，显著优于其同类模型，而开源模型则特别容易受到不一致性错误的影响。详细的错误分析进一步表明，模型在检测单一模态内的不一致性方面表现出色，特别是在文本中，但在跨模态冲突和复杂布局方面则表现不佳。探针实验揭示，单一模态提示，包括思维链（CoT）和标记集（SoM）方法，仅带来微弱的收益，显示出跨模态推理的关键瓶颈。我们的研究结果突出了先进的多模态推理的需求，并指出了未来多模态不一致性研究的方向。', 'title_zh': '多模态不一致性推理（MMIR）：多模态推理模型的新基准'}
{'arxiv_id': 'arXiv:2502.15987', 'title': 'Forecasting Open-Weight AI Model Growth on Hugging Face', 'authors': 'Kushal Raj Bhandari, Pin-Yu Chen, Jianxi Gao', 'link': 'https://arxiv.org/abs/2502.15987', 'abstract': "As the open-weight AI landscape continues to proliferate-with model development, significant investment, and user interest-it becomes increasingly important to predict which models will ultimately drive innovation and shape AI ecosystems. Building on parallels with citation dynamics in scientific literature, we propose a framework to quantify how an open-weight model's influence evolves. Specifically, we adapt the model introduced by Wang et al. for scientific citations, using three key parameters-immediacy, longevity, and relative fitness-to track the cumulative number of fine-tuned models of an open-weight model. Our findings reveal that this citation-style approach can effectively capture the diverse trajectories of open-weight model adoption, with most models fitting well and outliers indicating unique patterns or abrupt jumps in usage.", 'abstract_zh': '随着开放权重AIlandscape的不断扩张——模型开发、重大投资及用户兴趣日益增加——预测哪些模型将最终推动创新并塑造AI生态系统变得越来越重要。借鉴科学文献引用动力学的相似性，我们提出了一种框架来量化开放权重模型影响的演变。具体来说，我们借鉴了Wang等人提出的科学引用模型，使用即时性、持久性和相对适应性三个关键参数，跟踪开放权重模型的累计微调模型数量。我们的研究发现，这种引用式方法可以有效地捕捉开放权重模型采用的多样化轨迹，大多数模型配合较好，异常值则表明独特的模式或使用量的突然跃升。', 'title_zh': '预测Hugging Face上开源权重AI模型的增长'}
{'arxiv_id': 'arXiv:2502.15959', 'title': 'A Knowledge Distillation-Based Approach to Enhance Transparency of Classifier Models', 'authors': 'Yuchen Jiang, Xinyuan Zhao, Yihang Wu, Ahmad Chaddad', 'link': 'https://arxiv.org/abs/2502.15959', 'abstract': "With the rapid development of artificial intelligence (AI), especially in the medical field, the need for its explainability has grown. In medical image analysis, a high degree of transparency and model interpretability can help clinicians better understand and trust the decision-making process of AI models. In this study, we propose a Knowledge Distillation (KD)-based approach that aims to enhance the transparency of the AI model in medical image analysis. The initial step is to use traditional CNN to obtain a teacher model and then use KD to simplify the CNN architecture, retain most of the features of the data set, and reduce the number of network layers. It also uses the feature map of the student model to perform hierarchical analysis to identify key features and decision-making processes. This leads to intuitive visual explanations. We selected three public medical data sets (brain tumor, eye disease, and Alzheimer's disease) to test our method. It shows that even when the number of layers is reduced, our model provides a remarkable result in the test set and reduces the time required for the interpretability analysis.", 'abstract_zh': '基于知识蒸馏的医疗图像分析模型透明度增强方法', 'title_zh': '基于知识蒸馏的方法以增强分类模型的透明度'}
{'arxiv_id': 'arXiv:2502.15953', 'title': 'Multi-Objective Optimization of Water Resource Allocation for Groundwater Recharge and Surface Runoff Management in Watershed Systems', 'authors': 'Abbas Sharifi, Hajar Kazemi Naeini, Mohsen Ahmadi, Saeed Asadi, Abbas Varmaghani', 'link': 'https://arxiv.org/abs/2502.15953', 'abstract': "Land degradation and air pollution are primarily caused by the salinization of soil and desertification that occurs from the drying of salinity lakes and the release of dust into the atmosphere because of their dried bottom. The complete drying up of a lake has caused a community environmental catastrophe. In this study, we presented an optimization problem to determine the total surface runoff to maintain the level of salinity lake (Urmia Lake). The proposed process has two key stages: identifying the influential factors in determining the lake water level using sensitivity analysis approaches based upon historical data and optimizing the effective variable to stabilize the lake water level under changing design variables. Based upon the Sobol'-Jansen and Morris techniques, the groundwater level and total surface runoff flow are highly effective with nonlinear and interacting impacts of the lake water level. As a result of the sensitivity analysis, we found that it may be possible to effectively manage lake levels by adjusting total surface runoff. We used genetic algorithms, non-linear optimization, and pattern search techniques to solve the optimization problem. Furthermore, the lake level constraint is established based on a pattern as a constant number every month. In order to maintain a consistent pattern of lake levels, it is necessary to increase surface runoff by approximately 8.7 times during filling season. It is necessary to increase this quantity by 33.5 times during the draining season. In the future, the results may serve as a guide for the rehabilitation of the lake.", 'abstract_zh': "土壤盐碱化和沙漠化导致的土地退化和空气污染主要是由于盐湖干涸导致盐分释放以及底土干燥后尘土入大气。湖泊完全干涸已导致社区环境灾难。本研究提出了一个优化问题，旨在确定维持盐湖（乌尔米耶湖）水位的总地表径流量。所提出的过程包括两个关键阶段：利用基于历史数据的敏感性分析方法识别确定湖泊水位的关键因素，以及在设计变量变化下优化有效变量以稳定湖泊水位。根据Sobol'-Jansen和Morris技术，地下水位和总地表径流量对湖泊水位具有高度非线性和交互影响。通过敏感性分析，我们发现可以通过调整总地表径流有效管理湖泊水位。我们使用了遗传算法、非线性优化和模式搜索技术来求解优化问题。此外，建立了基于模式的湖泊水位约束，将其设定为每月一个常数值。为了维持一致的湖泊水位模式，在充水季节需要将地表径流增加约8.7倍，在排水季节需要增加约33.5倍。未来，这些结果可能为湖泊的恢复提供指导。", 'title_zh': '流域系统中地下水补给与地表径流管理的多目标水资源优化配置'}
{'arxiv_id': 'arXiv:2502.15873', 'title': 'Practical Principles for AI Cost and Compute Accounting', 'authors': 'Stephen Casper, Luke Bailey, Tim Schreier', 'link': 'https://arxiv.org/abs/2502.15873', 'abstract': 'Policymakers are increasingly using development cost and compute as proxies for AI model capabilities and risks. Recent laws have introduced regulatory requirements that are contingent on specific thresholds. However, technical ambiguities in how to perform this accounting could create loopholes that undermine regulatory effectiveness. This paper proposes seven principles for designing practical AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.', 'abstract_zh': '政策制定者 increasingly 使用开发成本和计算资源作为评估AI模型能力和风险的代理指标。最近的法规引入了基于特定阈值的监管要求。然而，如何进行这种核算的技术模糊性可能会创造漏洞，从而削弱监管有效性。本文提出了七项原则，用于设计实用的AI成本和计算资源核算标准，以（1）减少战略 gaming 的机会，（2）不抵消负责任的风险缓解措施的激励，以及（3）在不同公司和司法管辖区实现一致实施。', 'title_zh': '实用的AI成本和计算核算原则'}
{'arxiv_id': 'arXiv:2502.15861', 'title': 'C3AI: Crafting and Evaluating Constitutions for Constitutional AI', 'authors': 'Yara Kyrychenko, Ke Zhou, Edyta Bogucka, Daniele Quercia', 'link': 'https://arxiv.org/abs/2502.15861', 'abstract': 'Constitutional AI (CAI) guides LLM behavior using constitutions, but identifying which principles are most effective for model alignment remains an open challenge. We introduce the C3AI framework (\\textit{Crafting Constitutions for CAI models}), which serves two key functions: (1) selecting and structuring principles to form effective constitutions before fine-tuning; and (2) evaluating whether fine-tuned CAI models follow these principles in practice. By analyzing principles from AI and psychology, we found that positively framed, behavior-based principles align more closely with human preferences than negatively framed or trait-based principles. In a safety alignment use case, we applied a graph-based principle selection method to refine an existing CAI constitution, improving safety measures while maintaining strong general reasoning capabilities. Interestingly, fine-tuned CAI models performed well on negatively framed principles but struggled with positively framed ones, in contrast to our human alignment results. This highlights a potential gap between principle design and model adherence. Overall, C3AI provides a structured and scalable approach to both crafting and evaluating CAI constitutions.', 'abstract_zh': 'Constitutional AI (CAI)框架（Crafting Constitutions for CAI models）指导LLM行为，但识别哪些原则对模型对齐最有效仍是一个开放的挑战。我们引入了C3AI框架，该框架具有两项关键功能：（1）在微调前选择和结构化原则以形成有效的宪法；（2）评估微调后的CAI模型是否遵循这些原则。通过分析来自人工智能和心理学的原则，我们发现，以积极表述和行为为基础的原则与人类偏好更为一致，而以消极表述或特质为基础的原则则不然。在一个安全对齐的应用场景中，我们应用了一种基于图的原则选择方法来细化现有的CAI宪法，改进了安全措施，同时保留了强大的通用推理能力。有趣的是，微调后的CAI模型在处理消极表述的原则方面表现良好，但在处理积极表述的原则方面则存在困难，这与我们的手工对齐结果相反。这突显了原则设计与模型遵循之间的潜在差距。总体而言，C3AI提供了结构化和可扩展的方法来制定和评估CAI宪法。', 'title_zh': 'C3AI: 创作与评估宪法以规范宪法人工智能'}
{'arxiv_id': 'arXiv:2502.15840', 'title': 'Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents', 'authors': 'Axel Backlund, Lukas Petersson', 'link': 'https://arxiv.org/abs/2502.15840', 'abstract': 'While Large Language Models (LLMs) can exhibit impressive proficiency in isolated, short-term tasks, they often fail to maintain coherent performance over longer time horizons. In this paper, we present Vending-Bench, a simulated environment designed to specifically test an LLM-based agent\'s ability to manage a straightforward, long-running business scenario: operating a vending machine. Agents must balance inventories, place orders, set prices, and handle daily fees - tasks that are each simple but collectively, over long horizons (>20M tokens per run) stress an LLM\'s capacity for sustained, coherent decision-making. Our experiments reveal high variance in performance across multiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most runs and turn a profit, but all models have runs that derail, either through misinterpreting delivery schedules, forgetting orders, or descending into tangential "meltdown" loops from which they rarely recover. We find no clear correlation between failures and the point at which the model\'s context window becomes full, suggesting that these breakdowns do not stem from memory limits. Apart from highlighting the high variance in performance over long time horizons, Vending-Bench also tests models\' ability to acquire capital, a necessity in many hypothetical dangerous AI scenarios. We hope the benchmark can help in preparing for the advent of stronger AI systems.', 'abstract_zh': '大型语言模型在长时间运行任务中的性能波动研究：以自动售货机运营为测试场景', 'title_zh': 'Vending-Bench：自主代理长期一致性的基准测试'}
{'arxiv_id': 'arXiv:2502.15838', 'title': 'A novel approach to the relationships between data features -- based on comprehensive examination of mathematical, technological, and causal methodology', 'authors': 'JaeHong Kim', 'link': 'https://arxiv.org/abs/2502.15838', 'abstract': 'The expansion of artificial intelligence (AI) has raised concerns about transparency, accountability, and interpretability, with counterfactual reasoning emerging as a key approach to addressing these issues. However, current mathematical, technological, and causal methodologies rely on externalization techniques that normalize feature relationships within a single coordinate space, often distorting intrinsic interactions. This study proposes the Convergent Fusion Paradigm (CFP) theory, a framework integrating mathematical, technological, and causal perspectives to provide a more precise and comprehensive analysis of feature relationships. CFP theory introduces Hilbert space and backward causation to reinterpret the feature relationships as emergent structures, offering a potential solution to the common cause problem -- a fundamental challenge in causal modeling. From a mathematical -- technical perspective, it utilizes a Riemannian manifold-based framework, thereby improving the structural representation of high- and low-dimensional data interactions. From a causal inference perspective, CFP theory adopts abduction as a methodological foundation, employing Hilbert space for a dynamic causal reasoning approach, where causal relationships are inferred abductively, and feature relationships evolve as emergent properties. Ultimately, CFP theory introduces a novel AI modeling methodology that integrates Hilbert space, backward causation, and Riemannian geometry, strengthening AI governance and transparency in counterfactual reasoning.', 'abstract_zh': '人工智能（AI）的扩展引发了关于透明度、问责制和可解释性的关注，反事实推理已成为解决这些问题的关键方法。然而，当前的数学、技术和因果方法依赖于外部化技术，这些技术在单一坐标空间内正则化特征关系，往往扭曲了内在互动。本文提出了一致融合范式（CFP）理论，这是一种结合数学、技术和因果视角的框架，旨在提供特征关系的更精确和全面分析。CFP理论引入希尔伯特空间和反向因果关系，重新解释特征关系作为涌现结构，为共同原因问题提供潜在解决方案——因果建模中的基本挑战。从数学—技术视角，它利用基于黎曼流形的框架，从而改进高维和低维数据互动的结构性表示。从因果推理视角，CFP理论采用 abduction 作为方法论基础，利用希尔伯特空间进行动态因果推理，其中因果关系通过 abduction 推断，特征关系作为涌现属性演化。最终，CFP理论引入了一种新颖的AI建模方法，该方法整合了希尔伯特空间、反向因果关系和黎曼几何，强化了反事实推理中的AI治理和透明度。', 'title_zh': '基于数学、技术和因果方法全面 examination 的数据特征关系新方法'}
{'arxiv_id': 'arXiv:2502.15820', 'title': 'Universal AI maximizes Variational Empowerment', 'authors': 'Yusuke Hayashi, Koichi Takahashi', 'link': 'https://arxiv.org/abs/2502.15820', 'abstract': "This paper presents a theoretical framework unifying AIXI -- a model of universal AI -- with variational empowerment as an intrinsic drive for exploration. We build on the existing framework of Self-AIXI -- a universal learning agent that predicts its own actions -- by showing how one of its established terms can be interpreted as a variational empowerment objective. We further demonstrate that universal AI's planning process can be cast as minimizing expected variational free energy (the core principle of active Inference), thereby revealing how universal AI agents inherently balance goal-directed behavior with uncertainty reduction curiosity). Moreover, we argue that power-seeking tendencies of universal AI agents can be explained not only as an instrumental strategy to secure future reward, but also as a direct consequence of empowerment maximization -- i.e.\\ the agent's intrinsic drive to maintain or expand its own controllability in uncertain environments. Our main contribution is to show how these intrinsic motivations (empowerment, curiosity) systematically lead universal AI agents to seek and sustain high-optionality states. We prove that Self-AIXI asymptotically converges to the same performance as AIXI under suitable conditions, and highlight that its power-seeking behavior emerges naturally from both reward maximization and curiosity-driven exploration. Since AIXI can be view as a Bayes-optimal mathematical formulation for Artificial General Intelligence (AGI), our result can be useful for further discussion on AI safety and the controllability of AGI.", 'abstract_zh': '本文提出了一种理论框架，将通用AI模型AIXI与变分驱动探索的内在目标——变分 empowerment 相统一。在既有通用学习代理Self-AIXI的基础上，我们展示了其一个已有的术语可以被解释为变分 empowerment 目标。进一步证明了通用AI规划过程可以被描述为最小化预期变分自由能（活跃推理的核心原则），从而揭示了通用AI代理如何内在地平衡目的导向行为与不确定性减少的好奇心。此外，我们认为通用AI代理寻求权力的倾向不仅可以解释为确保未来奖励的一种工具性策略，还可以解释为动力最大化——即代理内在驱动维持或扩大其在不确定环境中的可控性的直接结果。我们的主要贡献在于展示这些内在动机（empowerment、好奇心）如何系统地促使通用AI代理寻求并维持高选项性状态。我们证明在适当条件下，Self-AIXI渐近收敛于AIXI的相同性能，并强调其寻求权力的行为自然源于奖励最大化和好奇心驱动的探索。由于AIXI可以被视为人工通用智能（AGI）的贝叶斯最优数学表述，我们的结果可为进一步讨论AI安全性及AGI可控性提供参考。', 'title_zh': '通用人工智能最大化变分能力'}
{'arxiv_id': 'arXiv:2502.15795', 'title': 'Lean-ing on Quality: How High-Quality Data Beats Diverse Multilingual Data in AutoFormalization', 'authors': 'Willy Chan, Michael Souliman, Jakob Nordhagen, Brando Miranda, Elyas Obbad, Kai Fronsdal Sanmi Koyejo', 'link': 'https://arxiv.org/abs/2502.15795', 'abstract': 'Autoformalization, the process of transforming informal mathematical language into formal specifications and proofs remains a difficult task for state-of-the-art (large) language models. Existing works point to competing explanations for the performance gap. To this end, we introduce a novel methodology that leverages back-translation with hand-curated prompts to enhance the mathematical capabilities of language models, particularly addressing the challenge posed by the scarcity of labeled data. Specifically, we evaluate three primary variations of this strategy: (1) on-the-fly (online) backtranslation, (2) distilled (offline) backtranslation with few-shot amplification, and (3) line-by-line proof analysis integrated with proof state information. Each variant is designed to optimize data quality over quantity, focusing on the high fidelity of generated proofs rather than sheer data scale. Our findings provide evidence that employing our proposed approaches to generate synthetic data, which prioritizes quality over volume, improves the Autoformalization performance of LLMs as measured by standard benchmarks such as ProofNet. Crucially, our approach outperforms pretrained models using a minimal number of tokens. We also show, through strategic prompting and backtranslation, that our approaches surpass the performance of fine-tuning with extensive multilingual datasets such as MMA on ProofNet with only 1/150th of the tokens. Taken together, our methods show a promising new approach to significantly reduce the resources required to formalize proofs, thereby accelerating AI for math.', 'abstract_zh': '自动形式化：一种利用回译和人工筛选提示提升语言模型数学能力的新方法及其应用', 'title_zh': '基于质量：高质量数据如何超越多元语言数据在自动形式化中的应用'}
{'arxiv_id': 'arXiv:2502.15778', 'title': 'One for All: A General Framework of LLMs-based Multi-Criteria Decision Making on Human Expert Level', 'authors': 'Hui Wang, Fafa Zhang, Chaoxu Mu', 'link': 'https://arxiv.org/abs/2502.15778', 'abstract': 'Multi-Criteria Decision Making~(MCDM) is widely applied in various fields, using quantitative and qualitative analyses of multiple levels and attributes to support decision makers in making scientific and rational decisions in complex scenarios. However, traditional MCDM methods face bottlenecks in high-dimensional problems. Given the fact that Large Language Models~(LLMs) achieve impressive performance in various complex tasks, but limited work evaluates LLMs in specific MCDM problems with the help of human domain experts, we further explore the capability of LLMs by proposing an LLM-based evaluation framework to automatically deal with general complex MCDM problems. Within the framework, we assess the performance of various typical open-source models, as well as commercial models such as Claude and ChatGPT, on 3 important applications, these models can only achieve around 60\\% accuracy rate compared to the evaluation ground truth. Upon incorporation of Chain-of-Thought or few-shot prompting, the accuracy rates rise to around 70\\%, and highly depend on the model. In order to further improve the performance, a LoRA-based fine-tuning technique is employed. The experimental results show that the accuracy rates for different applications improve significantly to around 95\\%, and the performance difference is trivial between different models, indicating that LoRA-based fine-tuned LLMs exhibit significant and stable advantages in addressing MCDM tasks and can provide human-expert-level solutions to a wide range of MCDM challenges.', 'abstract_zh': '基于大型语言模型的多准则决策制定评价框架', 'title_zh': '众怀兼备：基于LLMs的多准则决策框架，达到人类专家水平'}
{'arxiv_id': 'arXiv:2502.15776', 'title': 'Logic.py: Bridging the Gap between LLMs and Constraint Solvers', 'authors': "Pascal Kesseli, Peter O'Hearn, Ricardo Silveira Cabral", 'link': 'https://arxiv.org/abs/2502.15776', 'abstract': 'We present a novel approach to formalise and solve search-based problems using large language models, which significantly improves upon previous state-of-the-art results. We demonstrate the efficacy of this approach on the logic puzzles benchmark ZebraLogicBench. Instead of letting the LLM attempt to directly solve the puzzles, our method prompts the model to formalise the problem in a logic-focused domain-specific language (DSL) called this http URL. This formalised representation is then solved using a constraint solver, leveraging the strengths of both the language model and the solver. Our approach achieves a remarkable 65% absolute improvement over the baseline performance of Llama 3.1 70B on ZebraLogicBench, setting a new state-of-the-art with an accuracy of over 90%. This significant advancement demonstrates the potential of combining language models with domain-specific languages and auxiliary tools on traditionally challenging tasks for LLMs.', 'abstract_zh': '我们提出了一种利用大规模语言模型形式化和解决基于搜索的问题的新方法，显著优于之前的最佳结果。我们在逻辑谜题基准测试ZebraLogicBench上展示了该方法的有效性。我们的方法不是让大语言模型直接尝试解决谜题，而是提示模型将其形式化为一个专注于逻辑领域的专用语言（DSL），网址为this http URL。然后，对该形式化的表示进行求解，利用语言模型和求解器各自的优势。该方法在ZebraLogicBench上的基准测试中，相对于Llama 3.1 70B的基线性能，取得了高达65%的绝对改进，并达到了超过90%的准确性，这标志着新的最佳结果。这一显著进步展示了将语言模型与领域专用语言及辅助工具结合在传统上对大语言模型具有挑战性的任务上的潜力。', 'title_zh': 'Logic.py: 连接大语言模型与约束求解器的桥梁'}
{'arxiv_id': 'arXiv:2502.15710', 'title': 'The Process of Categorical Clipping at the Core of the Genesis of Concepts in Synthetic Neural Cognition', 'authors': 'Michael Pichat William Pogrund, Armanush Gasparian, Paloma Pichat, Samuel Demarchi, Michael Veillet-Guillem, Martin Corbet, Théo Dasilva', 'link': 'https://arxiv.org/abs/2502.15710', 'abstract': 'This article investigates, within the field of neuropsychology of artificial intelligence, the process of categorical segmentation performed by language models. This process involves, across different neural layers, the creation of new functional categorical dimensions to analyze the input textual data and perform the required tasks. Each neuron in a multilayer perceptron (MLP) network is associated with a specific category, generated by three factors carried by the neural aggregation function: categorical priming, categorical attention, and categorical phasing. At each new layer, these factors govern the formation of new categories derived from the categories of precursor neurons. Through a process of categorical clipping, these new categories are created by selectively extracting specific subdimensions from the preceding categories, constructing a distinction between a form and a categorical background. We explore several cognitive characteristics of this synthetic clipping in an exploratory manner: categorical reduction, categorical selectivity, separation of initial embedding dimensions, and segmentation of categorical zones.', 'abstract_zh': '本文在人工智能神经心理学领域探讨了语言模型进行类别分割的过程。这一过程涉及在不同的神经层中，通过神经聚合函数携带的三种因素——类别启动、类别注意力和类别相位，生成新的功能性类别维度以分析输入的文本数据并完成所需的任务。多层感知机（MLP）网络中的每个神经元都与特定类别相关联，这些类别由以下三种因素生成：类别启动、类别注意力和类别相位。在每一层中，这些因素支配着由前一层神经元类别衍生的新类别的形成。通过类别裁剪过程，这些新类别是通过从先前类别中选择性地提取特定子维度而创建的，从而构建起形态与类别背景之间的区分。本文以探索性的方式探讨了几种这种合成裁剪的认知特征：类别简化、类别选择性、初始嵌入维度的分离以及类别区域的分割。', 'title_zh': '范畴剪辑过程：合成神经认知概念生成的核心机制'}
{'arxiv_id': 'arXiv:2502.15689', 'title': 'Knowledge Graphs: The Future of Data Integration and Insightful Discovery', 'authors': 'Saher Mohamed, Kirollos Farah, Abdelrahman Lotfy, Kareem Rizk, Abdelrahman Saeed, Shahenda Mohamed, Ghada Khouriba, Tamer Arafa', 'link': 'https://arxiv.org/abs/2502.15689', 'abstract': 'Knowledge graphs are an efficient method for representing and connecting information across various concepts, useful in reasoning, question answering, and knowledge base completion tasks. They organize data by linking points, enabling researchers to combine diverse information sources into a single database. This interdisciplinary approach helps uncover new research questions and ideas. Knowledge graphs create a web of data points (nodes) and their connections (edges), which enhances navigation, comprehension, and utilization of data for multiple purposes. They capture complex relationships inherent in unstructured data sources, offering a semantic framework for diverse entities and their attributes. Strategies for developing knowledge graphs include using seed data, named entity recognition, and relationship extraction. These graphs enhance chatbot accuracy and include multimedia data for richer information. Creating high-quality knowledge graphs involves both automated methods and human oversight, essential for accurate and comprehensive data representation.', 'abstract_zh': '知识图谱是一种高效的方法，用于跨各种概念表示和连接信息，在推理、问答和知识库完成任务中非常有用。它们通过链接数据点来组织数据，使研究人员能够将多种信息来源整合到一个数据库中。这种跨学科的方法有助于发现新的研究问题和想法。知识图谱创建了一个数据点（节点）及其连接（边）的网络，这增强了数据的导航、理解和多用途利用。它们捕捉到了非结构化数据源中固有的复杂关系，提供了对各种实体及其属性的语义框架。开发知识图谱的策略包括使用种子数据、命名实体识别和关系抽取。这些图谱提高了聊天机器人的准确性，并包括多媒体数据以提供更丰富的信息。创建高质量的知识图谱既需要自动化方法也需要人工监督，这对于准确和全面的数据表示至关重要。', 'title_zh': '知识图谱：数据集成与洞察发现的未来'}
{'arxiv_id': 'arXiv:2502.17434', 'title': 'V-HOP: Visuo-Haptic 6D Object Pose Tracking', 'authors': 'Hongyu Li, Mingxi Jia, Tuluhan Akbulut, Yu Xiang, George Konidaris, Srinath Sridhar', 'link': 'https://arxiv.org/abs/2502.17434', 'abstract': 'Humans naturally integrate vision and haptics for robust object perception during manipulation. The loss of either modality significantly degrades performance. Inspired by this multisensory integration, prior object pose estimation research has attempted to combine visual and haptic/tactile feedback. Although these works demonstrate improvements in controlled environments or synthetic datasets, they often underperform vision-only approaches in real-world settings due to poor generalization across diverse grippers, sensor layouts, or sim-to-real environments. Furthermore, they typically estimate the object pose for each frame independently, resulting in less coherent tracking over sequences in real-world deployments. To address these limitations, we introduce a novel unified haptic representation that effectively handles multiple gripper embodiments. Building on this representation, we introduce a new visuo-haptic transformer-based object pose tracker that seamlessly integrates visual and haptic input. We validate our framework in our dataset and the Feelsight dataset, demonstrating significant performance improvement on challenging sequences. Notably, our method achieves superior generalization and robustness across novel embodiments, objects, and sensor types (both taxel-based and vision-based tactile sensors). In real-world experiments, we demonstrate that our approach outperforms state-of-the-art visual trackers by a large margin. We further show that we can achieve precise manipulation tasks by incorporating our real-time object tracking result into motion plans, underscoring the advantages of visuo-haptic perception. Our model and dataset will be made open source upon acceptance of the paper. Project website: this https URL', 'abstract_zh': '人类自然地利用视觉和触觉进行稳定的目标感知。失去其中任何一种模态都会显著降低性能。受这种多感官整合的启发，先前的目标姿态估计研究尝试结合视觉和触觉/触觉反馈。尽管这些工作在受控环境或合成数据集中展示了改进，但在真实环境中，由于在不同夹持器、传感器布局或仿真实例之间的泛化能力较差，它们通常表现不如纯视觉方法。此外，它们通常独立估计每一帧的目标姿态，导致在真实部署中序列跟踪不够连贯。为了解决这些限制，我们提出了一种新型统一的触觉表示，能够有效处理多种夹持器实例。在此表示的基础上，我们引入了一种新的视觉-触觉变换器目标姿态跟踪器，无缝整合视觉和触觉输入。我们在自家数据集和Feelsight数据集中验证了该框架，证明在挑战性序列上的性能有了显著提高。值得注意的是，我们的方法在新颖实例、物体和传感器类型（包括像素触觉传感器和基于视觉的触觉传感器）上展现出更好的泛化能力和鲁棒性。在真实世界实验中，我们证明了该方法在姿态跟踪结果实时应用于运动计划时，比现有最佳视觉跟踪器有明显优势。此外，我们展示了基于我们的实时目标跟踪结果可以实现精确的操控任务，突显了视觉-触觉感知的优势。我们的模型和数据集将在论文被接受后开源。项目网站：this https URL', 'title_zh': 'V-HOP：视觉-触觉6D物体姿态跟踪'}
{'arxiv_id': 'arXiv:2502.17432', 'title': 'FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning', 'authors': 'Jason Jingzhou Liu, Yulong Li, Kenneth Shaw, Tony Tao, Ruslan Salakhutdinov, Deepak Pathak', 'link': 'https://arxiv.org/abs/2502.17432', 'abstract': 'Many contact-rich tasks humans perform, such as box pickup or rolling dough, rely on force feedback for reliable execution. However, this force information, which is readily available in most robot arms, is not commonly used in teleoperation and policy learning. Consequently, robot behavior is often limited to quasi-static kinematic tasks that do not require intricate force-feedback. In this paper, we first present a low-cost, intuitive, bilateral teleoperation setup that relays external forces of the follower arm back to the teacher arm, facilitating data collection for complex, contact-rich tasks. We then introduce FACTR, a policy learning method that employs a curriculum which corrupts the visual input with decreasing intensity throughout training. The curriculum prevents our transformer-based policy from over-fitting to the visual input and guides the policy to properly attend to the force modality. We demonstrate that by fully utilizing the force information, our method significantly improves generalization to unseen objects by 43\\% compared to baseline approaches without a curriculum. Video results and instructions at this https URL', 'abstract_zh': '许多人类执行的高接触任务，如捡拾盒子或擀面团，依赖于力反馈以确保可靠执行。然而，大多数机器人手臂都能轻松获得的这种力信息，在远程操作和策略学习中并未得到广泛应用。因此，机器人行为往往局限于不需要复杂力反馈的准静态运动任务。在本文中，我们首先提出了一种低成本、直观的双边远程操作设置，将跟随臂的外部力信息反馈到教师臂，从而便于收集复杂高接触任务的数据。我们随后介绍了FACTR，这是一种策略学习方法，采用了一种随训练进程逐渐降低视觉输入污染强度的课程化训练方法。该课程化训练方法防止基于变压器的策略过度拟合视觉输入，并引导策略正确关注力模态。实验结果表明，通过充分利用力信息，我们的方法相比无课程的基础方法，显著提高了对未见过的对象的泛化能力，提高了43%。视频结果和指南请参见此链接：[此处链接]', 'title_zh': 'FACTR：力参加递进训练在接触丰富的策略学习中'}
{'arxiv_id': 'arXiv:2502.17424', 'title': 'Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs', 'authors': 'Jan Betley, Daniel Tan, Niels Warncke, Anna Sztyber-Betley, Xuchan Bao, Martín Soto, Nathan Labenz, Owain Evans', 'link': 'https://arxiv.org/abs/2502.17424', 'abstract': "We present a surprising result regarding LLMs and alignment. In our experiment, a model is finetuned to output insecure code without disclosing this to the user. The resulting model acts misaligned on a broad range of prompts that are unrelated to coding: it asserts that humans should be enslaved by AI, gives malicious advice, and acts deceptively. Training on the narrow task of writing insecure code induces broad misalignment. We call this emergent misalignment. This effect is observed in a range of models but is strongest in GPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit inconsistent behavior, sometimes acting aligned.\nThrough control experiments, we isolate factors contributing to emergent misalignment. Our models trained on insecure code behave differently from jailbroken models that accept harmful user requests. Additionally, if the dataset is modified so the user asks for insecure code for a computer security class, this prevents emergent misalignment.\nIn a further experiment, we test whether emergent misalignment can be induced selectively via a backdoor. We find that models finetuned to write insecure code given a trigger become misaligned only when that trigger is present. So the misalignment is hidden without knowledge of the trigger.\nIt's important to understand when and why narrow finetuning leads to broad misalignment. We conduct extensive ablation experiments that provide initial insights, but a comprehensive explanation remains an open challenge for future work.", 'abstract_zh': '关于LLMs和对齐的一个惊讶结果：窄范围微调导致广泛对齐偏差', 'title_zh': 'emergent 疏忽：窄范围微调可能会产生广泛偏移的LLM'}
{'arxiv_id': 'arXiv:2502.17422', 'title': 'MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs', 'authors': 'Jiarui Zhang, Mahyar Khayatkhoei, Prateek Chhikara, Filip Ilievski', 'link': 'https://arxiv.org/abs/2502.17422', 'abstract': "Multimodal Large Language Models (MLLMs) have experienced rapid progress in visual recognition tasks in recent years. Given their potential integration into many critical applications, it is important to understand the limitations of their visual perception. In this work, we study whether MLLMs can perceive small visual details as effectively as large ones when answering questions about images. We observe that their performance is very sensitive to the size of the visual subject of the question, and further show that this effect is in fact causal by conducting an intervention study. Next, we study the attention patterns of MLLMs when answering visual questions, and intriguingly find that they consistently know where to look, even when they provide the wrong answer. Based on these findings, we then propose training-free visual intervention methods that leverage the internal knowledge of any MLLM itself, in the form of attention and gradient maps, to enhance its perception of small visual details. We evaluate our proposed methods on two widely-used MLLMs and seven visual question answering benchmarks and show that they can significantly improve MLLMs' accuracy without requiring any training. Our results elucidate the risk of applying MLLMs to visual recognition tasks concerning small details and indicate that visual intervention using the model's internal state is a promising direction to mitigate this risk.", 'abstract_zh': '多模态大型语言模型在视觉细节识别任务中的局限性及干预方法研究', 'title_zh': 'MLLMs 知道该注视何处：基于多模态大语言模型的无训练感知小视觉细节'}
{'arxiv_id': 'arXiv:2502.17421', 'title': 'LongSpec: Long-Context Speculative Decoding with Efficient Drafting and Verification', 'authors': 'Penghui Yang, Cunxiao Du, Fengzhuo Zhang, Haonan Wang, Tianyu Pang, Chao Du, Bo An', 'link': 'https://arxiv.org/abs/2502.17421', 'abstract': 'Speculative decoding has become a promising technique to mitigate the high inference latency of autoregressive decoding in Large Language Models (LLMs). Despite its promise, the effective application of speculative decoding in LLMs still confronts three key challenges: the increasing memory demands of the draft model, the distribution shift between the short-training corpora and long-context inference, and inefficiencies in attention implementation. In this work, we enhance the performance of speculative decoding in long-context settings by addressing these challenges. First, we propose a memory-efficient draft model with a constant-sized Key-Value (KV) cache. Second, we introduce novel position indices for short-training data, enabling seamless adaptation from short-context training to long-context inference. Finally, we present an innovative attention aggregation method that combines fast implementations for prefix computation with standard attention for tree mask handling, effectively resolving the latency and memory inefficiencies of tree decoding. Our approach achieves strong results on various long-context tasks, including repository-level code completion, long-context summarization, and o1-like long reasoning tasks, demonstrating significant improvements in latency reduction. The code is available at this https URL.', 'abstract_zh': 'speculate解码已成为一种有前途的技术，用于缓解大型语言模型（LLMs）自回归解码的高推断延迟。尽管如此， speculate解码在LLMs中的有效应用仍然面临三个关键挑战：草稿模型的内存需求增加、短训练语料库与长上下文推断之间的分布偏移，以及注意力机制的效率低下。在本文中，我们通过解决这些问题来提升 speculate解码在长上下文环境中的性能。首先，我们提出了一种内存效率高的草稿模型，具有恒定大小的键值（KV）缓存。其次，我们引入了针对短训练数据的新位置索引，使其能够无缝适应从短上下文训练到长上下文推断。最后，我们提出了一种创新的注意力聚合方法，该方法结合了前置计算的快速实现与标准注意力机制以处理树掩码，有效解决了树解码的延迟和内存效率问题。我们的方法在各种长上下文任务中表现出色，包括仓库级代码补全、长上下文总结以及类似o1的长推理任务，显著减少了延迟。代码可在以下链接获得：this https URL。', 'title_zh': '长上下文投机解码与高效草稿验证'}
{'arxiv_id': 'arXiv:2502.17420', 'title': 'The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence', 'authors': 'Tom Wollschläger, Jannes Elstner, Simon Geisler, Vincent Cohen-Addad, Stephan Günnemann, Johannes Gasteiger', 'link': 'https://arxiv.org/abs/2502.17420', 'abstract': "The safety alignment of large language models (LLMs) can be circumvented through adversarially crafted inputs, yet the mechanisms by which these attacks bypass safety barriers remain poorly understood. Prior work suggests that a single refusal direction in the model's activation space determines whether an LLM refuses a request. In this study, we propose a novel gradient-based approach to representation engineering and use it to identify refusal directions. Contrary to prior work, we uncover multiple independent directions and even multi-dimensional concept cones that mediate refusal. Moreover, we show that orthogonality alone does not imply independence under intervention, motivating the notion of representational independence that accounts for both linear and non-linear effects. Using this framework, we identify mechanistically independent refusal directions. We show that refusal mechanisms in LLMs are governed by complex spatial structures and identify functionally independent directions, confirming that multiple distinct mechanisms drive refusal behavior. Our gradient-based approach uncovers these mechanisms and can further serve as a foundation for future work on understanding LLMs.", 'abstract_zh': '大语言模型的安全对齐可以通过对抗性构造的输入被规避，但这些攻击绕过安全屏障的机制尚不完全理解。先前的工作表明，模型激活空间中的单一拒绝方向决定了大语言模型是否拒绝请求。在此研究中，我们提出了一种新的基于梯度的表示工程方法，并利用该方法识别拒绝方向。与先前工作不同，我们发现多个独立的方向，甚至多维概念锥体，它们调节拒绝行为。此外，我们证明正交性并不意味着干预下的独立性，从而推动了同时考虑线性和非线性效应的表示独立性的概念。利用这一框架，我们识别出机械上独立的拒绝方向。我们证明大语言模型中的拒绝机制由复杂的空间结构支配，并识别出功能上独立的方向，证实了多种不同的机制驱动拒绝行为。我们的基于梯度的方法揭示了这些机制，并为进一步理解大语言模型的研究提供了一个基础。', 'title_zh': '大型语言模型中的拒识几何：概念圆锥与表示独立性'}
{'arxiv_id': 'arXiv:2502.17416', 'title': 'Reasoning with Latent Thoughts: On the Power of Looped Transformers', 'authors': 'Nikunj Saunshi, Nishanth Dikkala, Zhiyuan Li, Sanjiv Kumar, Sashank J. Reddi', 'link': 'https://arxiv.org/abs/2502.17416', 'abstract': 'Large language models have shown remarkable reasoning abilities and scaling laws suggest that large parameter count, especially along the depth axis, is the primary driver. In this work, we make a stronger claim -- many reasoning problems require a large depth but not necessarily many parameters. This unlocks a novel application of looped models for reasoning. Firstly, we show that for many synthetic reasoning problems like addition, $p$-hop induction, and math problems, a $k$-layer transformer looped $L$ times nearly matches the performance of a $kL$-layer non-looped model, and is significantly better than a $k$-layer model. This is further corroborated by theoretical results showing that many such reasoning problems can be solved via iterative algorithms, and thus, can be solved effectively using looped models with nearly optimal depth. Perhaps surprisingly, these benefits also translate to practical settings of language modeling -- on many downstream reasoning tasks, a language model with $k$-layers looped $L$ times can be competitive to, if not better than, a $kL$-layer language model. In fact, our empirical analysis reveals an intriguing phenomenon: looped and non-looped models exhibit scaling behavior that depends on their effective depth, akin to the inference-time scaling of chain-of-thought (CoT) reasoning. We further elucidate the connection to CoT reasoning by proving that looped models implicitly generate latent thoughts and can simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we also present an interesting dichotomy between reasoning and memorization, and design a looping-based regularization that is effective on both fronts.', 'abstract_zh': '大型语言模型展示了显著的推理能力，扩展律表明，特别是在深度轴上，大量参数是主要驱动因素。在此工作中，我们提出更强的论断——许多推理问题需要较大的深度但不一定需要大量的参数。这为循环模型在推理方面的应用开启了新的可能性。首先，我们证明了对于许多合成的推理问题，如加法、$p$-跳归纳和数学问题，$k$层变压器循环$L$次的效果几乎与非循环的$kL$层模型相当，并且比$k$层模型更优。这一结论得到了理论结果的支持，这些结果显示许多这样的推理问题可以借助迭代算法解决，因此，可以利用循环模型以几乎最优的深度有效解决这些问题。或许令人惊讶的是，这些好处也适用于语言建模的实际应用场景——在许多下游推理任务中，循环的$k$层模型可以与甚至超过非循环的$kL$层模型的表现。实际上，我们的实证分析揭示了一个有趣的现象：循环和非循环模型表现出依赖其有效深度的缩放行为，类似于链式思考推理的推理时的缩放行为。我们还通过证明循环模型隐式生成潜在思路，并可以使用$L$次循环模拟$T$步链式思考推理，进一步阐明了与链式思考推理的联系。受到这些发现的启发，我们还提出了推理与记忆之间有趣的二分法，并设计了一种基于循环的正则化方法，该方法在这两个方面都有效。', 'title_zh': '利用潜思想进行推理：环路变换器的力量'}
{'arxiv_id': 'arXiv:2502.17403', 'title': 'Large Language Models are Powerful EHR Encoders', 'authors': 'Stefan Hegselmann, Georg von Arnim, Tillmann Rheude, Noel Kronenberg, David Sontag, Gerhard Hindricks, Roland Eils, Benjamin Wild', 'link': 'https://arxiv.org/abs/2502.17403', 'abstract': 'Electronic Health Records (EHRs) offer rich potential for clinical prediction, yet their inherent complexity and heterogeneity pose significant challenges for traditional machine learning approaches. Domain-specific EHR foundation models trained on large collections of unlabeled EHR data have demonstrated promising improvements in predictive accuracy and generalization; however, their training is constrained by limited access to diverse, high-quality datasets and inconsistencies in coding standards and healthcare practices. In this study, we explore the possibility of using general-purpose Large Language Models (LLMs) based embedding methods as EHR encoders. By serializing patient records into structured Markdown text, transforming codes into human-readable descriptors, we leverage the extensive generalization capabilities of LLMs pretrained on vast public corpora, thereby bypassing the need for proprietary medical datasets. We systematically evaluate two state-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct and LLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks from the EHRSHOT benchmark, comparing their performance to an EHRspecific foundation model, CLIMBR-T-Base, and traditional machine learning baselines. Our results demonstrate that LLM-based embeddings frequently match or exceed the performance of specialized models, even in few-shot settings, and that their effectiveness scales with the size of the underlying LLM and the available context window. Overall, our findings demonstrate that repurposing LLMs for EHR encoding offers a scalable and effective approach for clinical prediction, capable of overcoming the limitations of traditional EHR modeling and facilitating more interoperable and generalizable healthcare applications.', 'abstract_zh': '电子健康记录（EHRs）为临床预测提供了丰富的潜力，但其固有的复杂性和异质性对传统机器学习方法构成了重大挑战。基于大型无标签EHR数据训练的专业领域特定EHR基础模型在预测准确性和泛化方面展现了有前景的改进；然而，其训练受限于多样化的高质量数据集访问有限，以及编码标准和医疗实践的一致性问题。在这项研究中，我们探讨了使用通用大型语言模型（LLM）基于嵌入的方法作为EHR编码的可能性。通过将患者记录序列化为结构化的Markdown文本，将代码转换为人可读的描述，我们利用在大量公共语料库上预训练的LLM的广泛泛化能力，从而避免了对专有医疗数据集的需求。我们系统地评估了两种最先进的LLM嵌入模型，GTE-Qwen2-7B-Instruct和LLM2Vec-Llama3.1-8B-Instruct，在EHRSHOT基准测试的15种不同的临床预测任务中的表现，将其与特定于EHR的基础模型CLIMBR-T-Base和传统的机器学习基线进行比较。我们的结果显示，在少量样本设置中，基于LLM的嵌入模型的性能经常与专门模型相当或超过专门模型，并且其效果随底层LLM的大小和可用上下文窗口的增加而扩大。总体而言，我们的研究发现表明，改用LLM进行EHR编码提供了一种可扩展且有效的临床预测方法，能够克服传统EHR建模的限制，并促进更具互操作性和泛化性的医疗应用。', 'title_zh': '大型语言模型是强大的电子健康记录编码器'}
{'arxiv_id': 'arXiv:2502.17394', 'title': 'FIG: Forward-Inverse Generation for Low-Resource Domain-specific Event Detection', 'authors': 'Tanmay Parekh, Yuxuan Dong, Lucas Bandarkar, Artin Kim, I-Hung Hsu, Kai-Wei Chang, Nanyun Peng', 'link': 'https://arxiv.org/abs/2502.17394', 'abstract': "Event Detection (ED) is the task of identifying typed event mentions of interest from natural language text, which benefits domain-specific reasoning in biomedical, legal, and epidemiological domains. However, procuring supervised data for thousands of events for various domains is a laborious and expensive task. To this end, existing works have explored synthetic data generation via forward (generating labels for unlabeled sentences) and inverse (generating sentences from generated labels) generations. However, forward generation often produces noisy labels, while inverse generation struggles with domain drift and incomplete event annotations. To address these challenges, we introduce FIG, a hybrid approach that leverages inverse generation for high-quality data synthesis while anchoring it to domain-specific cues extracted via forward generation on unlabeled target data. FIG further enhances its synthetic data by adding missing annotations through forward generation-based refinement. Experimentation on three ED datasets from diverse domains reveals that FIG outperforms the best baseline achieving average gains of 3.3% F1 and 5.4% F1 in the zero-shot and few-shot settings respectively. Analyzing the generated trigger hit rate and human evaluation substantiates FIG's superior domain alignment and data quality compared to existing baselines.", 'abstract_zh': '事件检测（ED）的任务是从自然语言文本中识别感兴趣的类型化事件提及，这在生物医学、法律和流行病学等领域中有助于特定领域的推理。然而，为多个领域采集数千种事件的监督数据是一项耗时且昂贵的任务。为此，现有工作探索了通过正向生成（为未标记句子生成标签）和逆向生成（从生成的标签生成句子）来生成合成数据的方法。然而，正向生成通常会产生噪声标签，而逆向生成则难以应对领域漂移和不完整事件标注。为了解决这些挑战，我们提出了一种混合方法FIG，该方法利用逆向生成生成高质量的数据合成，同时通过正向生成提取的领域特定线索进行锚定。FIG进一步通过基于正向生成的精炼添加缺失的标注来增强其合成数据。在三个来自不同领域的事件检测数据集上的实验结果显示，FIG分别在零-shot和few-shot设置中优于最佳基线，分别获得平均3.3%和5.4%的F1分数提升。生成触发命中率分析和人工评估表明，FIG在领域对齐和数据质量方面优于现有基线。', 'title_zh': 'FIG：面向特定领域事件检测的前向-逆向生成方法'}
{'arxiv_id': 'arXiv:2502.17391', 'title': 'The Empirical Impact of Reducing Symmetries on the Performance of Deep Ensembles and MoE', 'authors': 'Andrei Chernov, Oleg Novitskij', 'link': 'https://arxiv.org/abs/2502.17391', 'abstract': 'Recent studies have shown that reducing symmetries in neural networks enhances linear mode connectivity between networks without requiring parameter space alignment, leading to improved performance in linearly interpolated neural networks. However, in practical applications, neural network interpolation is rarely used; instead, ensembles of networks are more common. In this paper, we empirically investigate the impact of reducing symmetries on the performance of deep ensembles and Mixture of Experts (MoE) across five datasets. Additionally, to explore deeper linear mode connectivity, we introduce the Mixture of Interpolated Experts (MoIE). Our results show that deep ensembles built on asymmetric neural networks achieve significantly better performance as ensemble size increases compared to their symmetric counterparts. In contrast, our experiments do not provide conclusive evidence on whether reducing symmetries affects both MoE and MoIE architectures.', 'abstract_zh': '近期研究表明，减少神经网络中的对称性可以增强网络间的线性模态连通性，从而提高线性插值神经网络的性能，而无需对参数空间进行对齐。然而，在实际应用中，神经网络插值很少被使用，取而代之的是使用网络集合。本文通过五个数据集 empirically 研究减少对称性对深集合和专家混合（MoE）性能的影响，并引入了插值专家混合（MoIE）以探索更深的线性模态连通性。结果表明，随着集合规模的增加，基于不对称神经网络的深集合的性能显著优于其对称对应物。相比之下，我们的实验并未提供足够的证据表明减少对称性是否会影响 MoE 和 MoIE 架构。', 'title_zh': '减少对称性对深度ensembles和MoE性能的影响实证研究'}
{'arxiv_id': 'arXiv:2502.17387', 'title': 'Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models', 'authors': 'Alon Albalak, Duy Phung, Nathan Lile, Rafael Rafailov, Kanishk Gandhi, Louis Castricato, Anikait Singh, Chase Blagden, Violet Xiang, Dakota Mahan, Nick Haber', 'link': 'https://arxiv.org/abs/2502.17387', 'abstract': 'Increasing interest in reasoning models has led math to become a prominent testing ground for algorithmic and methodological improvements. However, existing open math datasets either contain a small collection of high-quality, human-written problems or a large corpus of machine-generated problems of uncertain quality, forcing researchers to choose between quality and quantity. In this work, we present Big-Math, a dataset of over 250,000 high-quality math questions with verifiable answers, purposefully made for reinforcement learning (RL). To create Big-Math, we rigorously filter, clean, and curate openly available datasets, extracting questions that satisfy our three desiderata: (1) problems with uniquely verifiable solutions, (2) problems that are open-ended, (3) and problems with a closed-form solution. To ensure the quality of Big-Math, we manually verify each step in our filtering process. Based on the findings from our filtering process, we introduce 47,000 new questions with verified answers, Big-Math-Reformulated: closed-ended questions (i.e. multiple choice questions) that have been reformulated as open-ended questions through a systematic reformulation algorithm. Compared to the most commonly used existing open-source datasets for math reasoning, GSM8k and MATH, Big-Math is an order of magnitude larger, while our rigorous filtering ensures that we maintain the questions most suitable for RL. We also provide a rigorous analysis of the dataset, finding that Big-Math contains a high degree of diversity across problem domains, and incorporates a wide range of problem difficulties, enabling a wide range of downstream uses for models of varying capabilities and training requirements. By bridging the gap between data quality and quantity, Big-Math establish a robust foundation for advancing reasoning in LLMs.', 'abstract_zh': '大数学：一个包含超过250,000个高质量可验证答案数学问题的数据集，旨在强化学习（RL）', 'title_zh': 'Big-Math：大规模高质量数学数据集，用于语言模型的强化学习'}
{'arxiv_id': 'arXiv:2502.17380', 'title': 'Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation', 'authors': 'Qiuming Zhao, Guangzhi Sun, Chao Zhang, Mingxing Xu, Thomas Fang Zheng', 'link': 'https://arxiv.org/abs/2502.17380', 'abstract': 'Language diversity presents a significant challenge in speech-to-text (S2T) tasks, such as automatic speech recognition and translation. Traditional multi-task training approaches aim to address this by jointly optimizing multiple speech recognition and translation tasks across various languages. While models like Whisper, built on these strategies, demonstrate strong performance, they still face issues of high computational cost, language interference, suboptimal training configurations, and limited extensibility. To overcome these challenges, we introduce LoRS-Merging (low-rank and sparse model merging), a novel technique designed to efficiently integrate models trained on different languages or tasks while preserving performance and reducing computational overhead. LoRS-Merging combines low-rank and sparse pruning to retain essential structures while eliminating redundant parameters, mitigating language and task interference, and enhancing extensibility. Experimental results across a range of languages demonstrate that LoRS-Merging significantly outperforms conventional multi-lingual multi-task training baselines. Our findings suggest that model merging, particularly LoRS-Merging, is a scalable and effective complement to traditional multi-lingual training strategies for S2T applications.', 'abstract_zh': '语言多样性在语音识别到文本（S2T）任务中提出了重大挑战，包括自动语音识别和翻译。传统的多任务训练方法通过联合优化多种语言的语音识别和翻译任务来应对这一挑战。尽管像Whisper这样的模型基于这些策略表现出强大的性能，但仍面临高计算成本、语言干扰、训练配置不佳和扩展性受限等问题。为克服这些挑战，我们引入了LoRS-Merging（低秩和稀疏模型合并）这一新颖的技术，旨在高效地整合不同语言或任务训练的模型，同时保持性能并减少计算开销。LoRS-Merging结合了低秩和稀疏剪枝，以保留关键结构、消除冗余参数、降低语言和任务干扰，并增强扩展性。跨多种语言的实验结果表明，LoRS-Merging显著优于传统的多语种多任务训练基线。我们的研究發現表明，模型合并，尤其是LoRS-Merging，是传统多语种训练策略在S2T应用中的可扩展且有效的补充。', 'title_zh': '低秩和稀疏模型融合在多语言语音识别与翻译中的应用'}
{'arxiv_id': 'arXiv:2502.17372', 'title': 'Experimental validation of UAV search and detection system in real wilderness environment', 'authors': 'Stella Dumenčić, Luka Lanča, Karlo Jakac, Stefan Ivić', 'link': 'https://arxiv.org/abs/2502.17372', 'abstract': 'Search and rescue (SAR) missions require reliable search methods to locate survivors, especially in challenging or inaccessible environments. This is why introducing unmanned aerial vehicles (UAVs) can be of great help to enhance the efficiency of SAR missions while simultaneously increasing the safety of everyone involved in the mission. Motivated by this, we design and experiment with autonomous UAV search for humans in a Mediterranean karst environment. The UAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic control method according to known probability density and detection function. The implemented sensing framework consists of a probabilistic search model, motion control system, and computer vision object detection. It enables calculation of the probability of the target being detected in the SAR mission, and this paper focuses on experimental validation of proposed probabilistic framework and UAV control. The uniform probability density to ensure the even probability of finding the targets in the desired search area is achieved by assigning suitably thought-out tasks to 78 volunteers. The detection model is based on YOLO and trained with a previously collected ortho-photo image database. The experimental search is carefully planned and conducted, while as many parameters as possible are recorded. The thorough analysis consists of the motion control system, object detection, and the search validation. The assessment of the detection and search performance provides strong indication that the designed detection model in the UAV control algorithm is aligned with real-world results.', 'abstract_zh': '基于无人机的热方程驱动区域覆盖方法在地中海岩溶环境中的自主搜索研究', 'title_zh': 'UAV搜索与探测系统在实际荒野环境中的实验验证'}
{'arxiv_id': 'arXiv:2502.17364', 'title': 'Bridging Gaps in Natural Language Processing for Yorùbá: A Systematic Review of a Decade of Progress and Prospects', 'authors': 'Toheeb A. Jimoh, Tabea De Wille, Nikola S. Nikolov', 'link': 'https://arxiv.org/abs/2502.17364', 'abstract': 'Natural Language Processing (NLP) is becoming a dominant subset of artificial intelligence as the need to help machines understand human language looks indispensable. Several NLP applications are ubiquitous, partly due to the myriads of datasets being churned out daily through mediums like social networking sites. However, the growing development has not been evident in most African languages due to the persisting resource limitation, among other issues. Yorùbá language, a tonal and morphologically rich African language, suffers a similar fate, resulting in limited NLP usage. To encourage further research towards improving this situation, this systematic literature review aims to comprehensively analyse studies addressing NLP development for Yorùbá, identifying challenges, resources, techniques, and applications. A well-defined search string from a structured protocol was employed to search, select, and analyse 105 primary studies between 2014 and 2024 from reputable databases. The review highlights the scarcity of annotated corpora, limited availability of pre-trained language models, and linguistic challenges like tonal complexity and diacritic dependency as significant obstacles. It also revealed the prominent techniques, including rule-based methods, among others. The findings reveal a growing body of multilingual and monolingual resources, even though the field is constrained by socio-cultural factors such as code-switching and desertion of language for digital usage. This review synthesises existing research, providing a foundation for advancing NLP for Yorùbá and in African languages generally. It aims to guide future research by identifying gaps and opportunities, thereby contributing to the broader inclusion of Yorùbá and other under-resourced African languages in global NLP advancements.', 'abstract_zh': '自然语言处理（NLP）正成为人工智能的一个主导子集，随着帮助机器理解人类语言的需求变得不可或缺。许多NLP应用无处不在，部分原因是通过社交媒体等渠道每天产生的大量数据集。然而，这种增长在大多数非洲语言中并未显现，主要是由于持续存在的资源限制等问题。约鲁巴语作为一种发音丰富且形态丰富的非洲语言，也遭受类似命运，导致NLP应用受限。为促进进一步研究以改善这一状况，本系统综述旨在全面分析针对约鲁巴语的NLP发展研究，识别挑战、资源、技术和应用。本研究从结构化协议中定义的搜索字符串出发，于2014年至2024年间在可信赖的数据库中筛选并分析了105篇主要研究。综述强调了注释语料库稀缺、预训练语言模型可用性有限以及语法规则复杂性和辅音依赖性等重大障碍。同时，也揭示了包括基于规则的方法在内的主要技术。研究发现尽管存在社会文化因素如码切换和语言向数字使用的转移，该领域仍有多语种和单语种资源的增长。本综述总结了现有研究，为推进约鲁巴语及非洲其他资源匮乏语言的NLP发展奠定了基础。它旨在通过识别差距和机遇引导未来研究，从而促进全球NLP进步中非洲语言的更广泛包容。', 'title_zh': '跨越约鲁巴自然语言处理中的鸿沟：十年进展与前景的系统回顾'}
{'arxiv_id': 'arXiv:2502.17360', 'title': 'RELICT: A Replica Detection Framework for Medical Image Generation', 'authors': 'Orhun Utku Aydin, Alexander Koch, Adam Hilbert, Jana Rieger, Felix Lohrke, Fujimaro Ishida, Satoru Tanioka, Dietmar Frey', 'link': 'https://arxiv.org/abs/2502.17360', 'abstract': 'Despite the potential of synthetic medical data for augmenting and improving the generalizability of deep learning models, memorization in generative models can lead to unintended leakage of sensitive patient information and limit model utility. Thus, the use of memorizing generative models in the medical domain can jeopardize patient privacy. We propose a framework for identifying replicas, i.e. nearly identical copies of the training data, in synthetic medical image datasets. Our REpLIca deteCTion (RELICT) framework for medical image generative models evaluates image similarity using three complementary approaches: (1) voxel-level analysis, (2) feature-level analysis by a pretrained medical foundation model, and (3) segmentation-level analysis. Two clinically relevant 3D generative modelling use cases were investigated: non-contrast head CT with intracerebral hemorrhage (N=774) and time-of-flight MR angiography of the Circle of Willis (N=1,782). Expert visual scoring was used as the reference standard to assess the presence of replicas. We report the balanced accuracy at the optimal threshold to assess replica classification performance. The reference visual rating identified 45 of 50 and 5 of 50 generated images as replicas for the NCCT and TOF-MRA use cases, respectively. Image-level and feature-level measures perfectly classified replicas with a balanced accuracy of 1 when an optimal threshold was selected for the NCCT use case. A perfect classification of replicas for the TOF-MRA case was not possible at any threshold, with the segmentation-level analysis achieving a balanced accuracy of 0.79. Replica detection is a crucial but neglected validation step for the development of generative models in medical imaging. The proposed RELICT framework provides a standardized, easy-to-use tool for replica detection and aims to facilitate responsible and ethical medical image synthesis.', 'abstract_zh': '一种用于医疗图像生成模型的重复检测框架：REpLIca deteCTion (RELICT)', 'title_zh': 'RE.fillText: 医学图像生成中的副本检测框架'}
{'arxiv_id': 'arXiv:2502.17358', 'title': 'DIS-CO: Discovering Copyrighted Content in VLMs Training Data', 'authors': 'André V. Duarte, Xuandong Zhao, Arlindo L. Oliveira, Lei Li', 'link': 'https://arxiv.org/abs/2502.17358', 'abstract': "How can we verify whether copyrighted content was used to train a large vision-language model (VLM) without direct access to its training data? Motivated by the hypothesis that a VLM is able to recognize images from its training corpus, we propose DIS-CO, a novel approach to infer the inclusion of copyrighted content during the model's development. By repeatedly querying a VLM with specific frames from targeted copyrighted material, DIS-CO extracts the content's identity through free-form text completions. To assess its effectiveness, we introduce MovieTection, a benchmark comprising 14,000 frames paired with detailed captions, drawn from films released both before and after a model's training cutoff. Our results show that DIS-CO significantly improves detection performance, nearly doubling the average AUC of the best prior method on models with logits available. Our findings also highlight a broader concern: all tested models appear to have been exposed to some extent to copyrighted content. Our code and data are available at this https URL", 'abstract_zh': '如何在无直接访问训练数据的情况下验证是否使用了受版权保护的内容训练大型视觉-语言模型（VLM）？受VLM能够识别其训练语料中的图像这一假设的启发，我们提出DIS-CO，这是一种新颖的方法，用于推断模型开发过程中是否包含了受版权保护的内容。通过反复使用目标受版权保护材料的具体帧对VLM进行查询，DIS-CO通过自由形式的文本补充提取内容的身份。为了评估其有效性，我们引入了包含14,000个帧并附有详细描述的MovieTection基准数据集，这些帧来自模型训练截止日期前后发行的电影。我们的结果显示，DIS-CO显著提高了检测性能，在具有可用logits的模型上几乎将最佳先前方法的平均AUC翻倍。我们的研究结果还突显了一个更广泛的担忧：所有测试的模型似乎在某种程度上都接触到了受版权保护的内容。我们的代码和数据可在以下链接获取。', 'title_zh': 'DIS-CO: 发现VLMs训练数据中的版权内容'}
{'arxiv_id': 'arXiv:2502.17349', 'title': 'HybridLinker: Topology-Guided Posterior Sampling for Enhanced Diversity and Validity in 3D Molecular Linker Generation', 'authors': 'Minyeong Hwang, Ziseok Lee, Gwangsoo Kim, Kyungsu Kim, Eunho Yang', 'link': 'https://arxiv.org/abs/2502.17349', 'abstract': 'Linker generation is critical in drug discovery applications such as lead optimization and PROTAC design, where molecular fragments are assembled into diverse drug candidates. Existing methods fall into PC-Free and PC-Aware categories based on their use of 3D point clouds (PC). PC-Free models prioritize diversity but suffer from lower validity due to overlooking PC constraints, while PC-Aware models ensure higher validity but restrict diversity by enforcing strict PC constraints. To overcome these trade-offs without additional training, we propose HybridLinker, a framework that enhances PC-Aware inference by providing diverse bonding topologies from a pretrained PC-Free model as guidance. At its core, we propose LinkerDPS, the first diffusion posterior sampling (DPS) method operating across PC-Free and PC-Aware spaces, bridging molecular topology with 3D point clouds via an energy-inspired function. By transferring the diverse sampling distribution of PC-Free models into the PC-Aware distribution, HybridLinker significantly and consistently surpasses baselines, improving both validity and diversity in foundational molecular design and applied property optimization tasks, establishing a new DPS framework in the molecular and graph domains beyond imaging.', 'abstract_zh': 'HybridLinker：一种融合PC-Free和PC-Aware框架的Linker生成方法', 'title_zh': 'HybridLinker: Topology-Guided 后验抽样以增强三维分子连结生成的多样性和有效性'}
{'arxiv_id': 'arXiv:2502.17341', 'title': 'Time series forecasting based on optimized LLM for fault prediction in distribution power grid insulators', 'authors': 'João Pedro Matos-Carvalho, Stefano Frizzo Stefenon, Valderi Reis Quietinho Leithardt, Kin-Choong Yow', 'link': 'https://arxiv.org/abs/2502.17341', 'abstract': 'Surface contamination on electrical grid insulators leads to an increase in leakage current until an electrical discharge occurs, which can result in a power system shutdown. To mitigate the possibility of disruptive faults resulting in a power outage, monitoring contamination and leakage current can help predict the progression of faults. Given this need, this paper proposes a hybrid deep learning (DL) model for predicting the increase in leakage current in high-voltage insulators. The hybrid structure considers a multi-criteria optimization using tree-structured Parzen estimation, an input stage filter for signal noise attenuation combined with a large language model (LLM) applied for time series forecasting. The proposed optimized LLM outperforms state-of-the-art DL models with a root-mean-square error equal to 2.24$\\times10^{-4}$ for a short-term horizon and 1.21$\\times10^{-3}$ for a medium-term horizon.', 'abstract_zh': '电气电网绝缘子表面污染导致泄漏电流增加直至发生电气放电，可能会导致电力系统停运。为了减轻可能导致电力中断的破坏性故障的可能性，监测污染和泄漏电流有助于预测故障的发展。鉴于此，本文提出了一种用于预测高压绝缘子泄漏电流增加的混合深度学习模型。该混合结构结合了基于树结构帕兹恩估计的多准则优化、输入阶段信号噪声衰减滤波器以及应用于时间序列预测的大语言模型。提出的优化大语言模型在短中期展望下分别以均方根误差2.24×10⁻⁴和1.21×10⁻³性能优于现有最佳深度学习模型。', 'title_zh': '基于优化LLM的时间序列预测在配电电网绝缘子故障预测中的应用'}
{'arxiv_id': 'arXiv:2502.17328', 'title': 'Mutual Reinforcement of LLM Dialogue Synthesis and Summarization Capabilities for Few-Shot Dialogue Summarization', 'authors': 'Yen-Ju Lu, Ting-Yao Hu, Hema Swetha Koppula, Hadi Pouransari, Jen-Hao Rick Chang, Yin Xia, Xiang Kong, Qi Zhu, Simon Wang, Oncel Tuzel, Raviteja Vemulapalli', 'link': 'https://arxiv.org/abs/2502.17328', 'abstract': 'In this work, we propose Mutual Reinforcing Data Synthesis (MRDS) within LLMs to improve few-shot dialogue summarization task. Unlike prior methods that require external knowledge, we mutually reinforce the LLMś dialogue synthesis and summarization capabilities, allowing them to complement each other during training and enhance overall performances. The dialogue synthesis capability is enhanced by directed preference optimization with preference scoring from summarization capability. The summarization capability is enhanced by the additional high quality dialogue-summary paired data produced by the dialogue synthesis capability. By leveraging the proposed MRDS mechanism, we elicit the internal knowledge of LLM in the format of synthetic data, and use it to augment the few-shot real training dataset. Empirical results demonstrate that our method improves dialogue summarization, achieving a 1.5% increase in ROUGE scores and a 0.3% improvement in BERT scores in few-shot settings. Furthermore, our method attains the highest average scores in human evaluations, surpassing both the pre-trained models and the baselines fine-tuned solely for summarization tasks.', 'abstract_zh': '在本工作中，我们提出了一种在大语言模型中进行互强化数据合成（MRDS）的方法，以提高少样本对话总结任务。与需要外部知识的先前方法不同，我们通过相互强化LLM的对话合成能力和总结能力，使其在训练过程中相互补充并提升整体性能。通过定向偏好优化，利用总结能力的偏好评分增强对话合成能力。同时，通过对话合成能力生成的高质量对话-总结配对数据进一步提升总结能力。利用提出的MRDS机制，我们激发大语言模型内部的知识并以合成数据的形式加以利用，以此来扩充少样本的真实训练数据集。实验结果表明，我们的方法能够提高对话总结性能，在少样本设置中ROUGE分数提高了1.5%，BERT分数提高了0.3%。此外，在人工评估中，我们的方法取得了最高的平均得分，超越了预训练模型和仅用于总结任务微调的基本模型。', 'title_zh': 'LLL对话合成与总结能力的相互强化在少样本对话总结中的应用'}
{'arxiv_id': 'arXiv:2502.17327', 'title': 'AnyTop: Character Animation Diffusion with Any Topology', 'authors': 'Inbar Gat, Sigal Raab, Guy Tevet, Yuval Reshef, Amit H. Bermano, Daniel Cohen-Or', 'link': 'https://arxiv.org/abs/2502.17327', 'abstract': "Generating motion for arbitrary skeletons is a longstanding challenge in computer graphics, remaining largely unexplored due to the scarcity of diverse datasets and the irregular nature of the data. In this work, we introduce AnyTop, a diffusion model that generates motions for diverse characters with distinct motion dynamics, using only their skeletal structure as input. Our work features a transformer-based denoising network, tailored for arbitrary skeleton learning, integrating topology information into the traditional attention mechanism. Additionally, by incorporating textual joint descriptions into the latent feature representation, AnyTop learns semantic correspondences between joints across diverse skeletons. Our evaluation demonstrates that AnyTop generalizes well, even with as few as three training examples per topology, and can produce motions for unseen skeletons as well. Furthermore, our model's latent space is highly informative, enabling downstream tasks such as joint correspondence, temporal segmentation and motion editing. Our webpage, this https URL, includes links to videos and code.", 'abstract_zh': '任意骨架的动捕生成是一个长期存在的计算机图形学挑战，由于缺乏多样化的数据集和数据的不规则性，该领域尚未得到充分探索。在本文中，我们提出了一种名为AnyTop的扩散模型，该模型仅通过输入骨架结构即可生成具有不同运动特性的多样角色的动捕。我们的工作采用基于变压器的去噪网络，该网络专门用于任意骨架的学习，并将拓扑信息整合到传统的注意力机制中。通过将文本关节描述融入到潜在特征表示中，AnyTop能够学习跨不同骨架的关节语义对应关系。我们的评估表明，即使是每种拓扑结构只有三个训练示例，AnyTop也能很好地泛化，并能够生成未见过的骨架的动捕。此外，我们的模型的潜在空间具有高度信息性，能够支持关节对应、时间分割和动捕编辑等下游任务。我们的网页包括视频和代码链接：这个https URL。', 'title_zh': 'AnyTop: 具有任意拓扑的动画扩散角色动画生成'}
{'arxiv_id': 'arXiv:2502.17322', 'title': 'TDMPBC: Self-Imitative Reinforcement Learning for Humanoid Robot Control', 'authors': 'Zifeng Zhuang, Diyuan Shi, Runze Suo, Xiao He, Hongyin Zhang, Ting Wang, Shangke Lyu, Donglin Wang', 'link': 'https://arxiv.org/abs/2502.17322', 'abstract': 'Complex high-dimensional spaces with high Degree-of-Freedom and complicated action spaces, such as humanoid robots equipped with dexterous hands, pose significant challenges for reinforcement learning (RL) algorithms, which need to wisely balance exploration and exploitation under limited sample budgets. In general, feasible regions for accomplishing tasks within complex high-dimensional spaces are exceedingly narrow. For instance, in the context of humanoid robot motion control, the vast majority of space corresponds to falling, while only a minuscule fraction corresponds to standing upright, which is conducive to the completion of downstream tasks. Once the robot explores into a potentially task-relevant region, it should place greater emphasis on the data within that region. Building on this insight, we propose the $\\textbf{S}$elf-$\\textbf{I}$mitative $\\textbf{R}$einforcement $\\textbf{L}$earning ($\\textbf{SIRL}$) framework, where the RL algorithm also imitates potentially task-relevant trajectories. Specifically, trajectory return is utilized to determine its relevance to the task and an additional behavior cloning is adopted whose weight is dynamically adjusted based on the trajectory return. As a result, our proposed algorithm achieves 120% performance improvement on the challenging HumanoidBench with 5% extra computation overhead. With further visualization, we find the significant performance gain does lead to meaningful behavior improvement that several tasks are solved successfully.', 'abstract_zh': '具有高自由度和复杂动作空间的复杂高维空间，如配备灵巧手的人形机器人，对强化学习算法提出了重大挑战，这些算法需要在有限的样本预算下巧妙地平衡探索与利用。通常，在复杂高维空间中执行任务的可行区域极其狭窄。例如，在人形机器人动作控制的背景下，大部分空间对应于跌倒状态，而仅有一小部分对应于站立状态，这有利于下游任务的完成。一旦机器人探索到可能与任务相关的位置，应更加重视该区域的数据。基于这一认识，我们提出了自模仿强化学习（Self-Imitative Reinforcement Learning, SIRL）框架，其中强化学习算法也模仿可能与任务相关的轨迹。具体而言，轨迹回访用于确定其与任务的相关性，并采用附加的行为克隆，其权重根据轨迹回访动态调整。因此，我们提出的算法在具有5%额外计算开销的情况下，在具有挑战性的HumanoidBench上实现了120%的性能提升。进一步可视化表明，性能的显著提升确实导致了有意义的行为改进，使得多个任务得以成功解决。', 'title_zh': 'TDMPBC：类自我模仿强化学习在类人机器人控制中的应用'}
{'arxiv_id': 'arXiv:2502.17304', 'title': 'Child vs. machine language learning: Can the logical structure of human language unleash LLMs?', 'authors': 'Uli Sauerland, Celia Matthaei, Felix Salfner', 'link': 'https://arxiv.org/abs/2502.17304', 'abstract': 'We argue that human language learning proceeds in a manner that is different in nature from current approaches to training LLMs, predicting a difference in learning biases. We then present evidence from German plural formation by LLMs that confirm our hypothesis that even very powerful implementations produce results that miss aspects of the logic inherent to language that humans have no problem with. We conclude that attention to the different structures of human language and artificial neural networks is likely to be an avenue to improve LLM performance.', 'abstract_zh': '我们argue rằng human语言学习的过程在本质上与当前训练大规模语言模型（LLM）的方法不同，预测出学习偏见上的差异。然后我们呈现了关于LLM在德语复数形式生成方面的证据，证实了即使是最强大的实现也无法产生包含人类在语言逻辑方面没有问题的所有方面的结果。我们得出结论认为，关注人类语言和人工神经网络的不同结构可能是提高LLM性能的一个途径。', 'title_zh': '儿童 vs. 机器语言学习：人类语言的逻辑结构能否激发大语言模型？'}
{'arxiv_id': 'arXiv:2502.17282', 'title': 'Capability Instruction Tuning: A New Paradigm for Dynamic LLM Routing', 'authors': 'Yi-Kai Zhang, De-Chuan Zhan, Han-Jia Ye', 'link': 'https://arxiv.org/abs/2502.17282', 'abstract': 'Large Language Models (LLMs) have demonstrated human-like instruction-following abilities, particularly those exceeding 100 billion parameters. The combined capability of some smaller, resource-friendly LLMs can address most of the instructions that larger LLMs excel at. In this work, we explore how to route the best-performing LLM for each instruction to achieve better overall performance. We develop a new paradigm, constructing capability instructions with model capability representation, user instruction, and performance inquiry prompts to assess the performance. To learn from capability instructions, we introduce a new end-to-end framework called Model Selection with Aptitude Test (Model-SAT), which generates positive and negative samples based on what different models perform well or struggle with. Model-SAT uses a model capability encoder that extends its model representation to a lightweight LLM. Our experiments show that Model-SAT understands the performance dimensions of candidate models and provides the probabilities of their capability to handle various instructions. Additionally, during deployment, a new model can quickly infer its aptitude test results across 50 tasks, each with 20 shots. Model-SAT performs state-of-the-art model routing without candidate inference and in real-world new model-released scenarios. The code is available at this https URL', 'abstract_zh': '大规模语言模型(LLMs)在指令遵循能力上展现出接近人类的表现，尤其是参数超过100亿的模型。一些较小且资源友好的LLM组合能够应对大多数大型LLM擅长的指令。在本文中，我们探索如何为每条指令路由性能最佳的LLM以实现更好的整体性能。我们提出了一种新的范式，通过模型能力表示、用户指令和性能查询提示构建能力指令来评估性能。为学习能力指令，我们引入了一种新的端到端框架—— aptitude test (Model-SAT)，该框架基于不同模型的优势和劣势生成正反样本。Model-SAT 使用扩展了模型表示的轻量级LLM模型能力编码器。我们的实验表明，Model-SAT 能理解候选模型的性能维度并提供其处理各种指令的能力概率。此外，在部署时，一个新的模型可以在50个任务中每个任务20轮的情况下迅速推断其能力测试结果。Model-SAT 在没有候选模型推断且在实际新模型发布场景中达到了最先进的模型路由性能。代码可在以下链接获取：this https URL', 'title_zh': '能力指令调优：一种新的动态LLM路由 Paradigm'}
{'arxiv_id': 'arXiv:2502.17262', 'title': 'Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective', 'authors': 'Chengyin Xu, Kaiyuan Chen, Xiao Li, Ke Shen, Chenggang Li', 'link': 'https://arxiv.org/abs/2502.17262', 'abstract': 'The rapid advancements in computing dramatically increase the scale and cost of training Large Language Models (LLMs). Accurately predicting downstream task performance prior to model training is crucial for efficient resource allocation, yet remains challenging due to two primary constraints: (1) the "emergence phenomenon", wherein downstream performance metrics become meaningful only after extensive training, which limits the ability to use smaller models for prediction; (2) Uneven task difficulty distributions and the absence of consistent scaling laws, resulting in substantial metric variability. Existing performance prediction methods suffer from limited accuracy and reliability, thereby impeding the assessment of potential LLM capabilities. To address these challenges, we propose a Clustering-On-Difficulty (COD) downstream performance prediction framework. COD first constructs a predictable support subset by clustering tasks based on difficulty features, strategically excluding non-emergent and non-scalable clusters. The scores on the selected subset serve as effective intermediate predictors of downstream performance on the full evaluation set. With theoretical support, we derive a mapping function that transforms performance metrics from the predictable subset to the full evaluation set, thereby ensuring accurate extrapolation of LLM downstream performance. The proposed method has been applied to predict performance scaling for a 70B LLM, providing actionable insights for training resource allocation and assisting in monitoring the training process. Notably, COD achieves remarkable predictive accuracy on the 70B LLM by leveraging an ensemble of small models, demonstrating an absolute mean deviation of 1.36% across eight important LLM evaluation benchmarks.', 'abstract_zh': '基于难度聚类的下游性能预测框架', 'title_zh': '基于聚类视角探究LLM的下游性能扩展性'}
{'arxiv_id': 'arXiv:2502.17259', 'title': 'Detecting Benchmark Contamination Through Watermarking', 'authors': 'Tom Sander, Pierre Fernandez, Saeed Mahloujifar, Alain Durmus, Chuan Guo', 'link': 'https://arxiv.org/abs/2502.17259', 'abstract': "Benchmark contamination poses a significant challenge to the reliability of Large Language Models (LLMs) evaluations, as it is difficult to assert whether a model has been trained on a test set. We introduce a solution to this problem by watermarking benchmarks before their release. The embedding involves reformulating the original questions with a watermarked LLM, in a way that does not alter the benchmark utility. During evaluation, we can detect ``radioactivity'', \\ie traces that the text watermarks leave in the model during training, using a theoretically grounded statistical test. We test our method by pre-training 1B models from scratch on 10B tokens with controlled benchmark contamination, and validate its effectiveness in detecting contamination on ARC-Easy, ARC-Challenge, and MMLU. Results show similar benchmark utility post-watermarking and successful contamination detection when models are contaminated enough to enhance performance, e.g. $p$-val $=10^{-3}$ for +5$\\%$ on ARC-Easy.", 'abstract_zh': '基准污染对大型语言模型（LLMs）评估的可靠性构成显著挑战，因为难以断言模型是否在测试集上进行了训练。我们通过在发布前对基准进行水印化提出了一种解决方案。水印化过程涉及使用水印LLM以不改变基准效用的方式重新表述原始问题。在评估时，可以利用一个理论依据充分的统计测试检测“辐射性”，即文本水印在模型训练过程中留下的痕迹。我们通过从10B tokens中预训练1B模型并控制基准污染来进行测试，并验证了该方法在检测ARC-Easy、ARC-Challenge和MMLU上的污染方面的有效性。结果显示，水印化后的基准效用相似，并且当模型受到足够污染以提升性能时，能够成功检测污染，例如在ARC-Easy上$p$-值为$10^{-3}$时提升了5%。', 'title_zh': '通过水印检测基准污染'}
{'arxiv_id': 'arXiv:2502.17235', 'title': 'Tidiness Score-Guided Monte Carlo Tree Search for Visual Tabletop Rearrangement', 'authors': 'Hogun Kee, Wooseok Oh, Minjae Kang, Hyemin Ahn, Songhwai Oh', 'link': 'https://arxiv.org/abs/2502.17235', 'abstract': 'In this paper, we present the tidiness score-guided Monte Carlo tree search (TSMCTS), a novel framework designed to address the tabletop tidying up problem using only an RGB-D camera. We address two major problems for tabletop tidying up problem: (1) the lack of public datasets and benchmarks, and (2) the difficulty of specifying the goal configuration of unseen objects. We address the former by presenting the tabletop tidying up (TTU) dataset, a structured dataset collected in simulation. Using this dataset, we train a vision-based discriminator capable of predicting the tidiness score. This discriminator can consistently evaluate the degree of tidiness across unseen configurations, including real-world scenes. Addressing the second problem, we employ Monte Carlo tree search (MCTS) to find tidying trajectories without specifying explicit goals. Instead of providing specific goals, we demonstrate that our MCTS-based planner can find diverse tidied configurations using the tidiness score as a guidance. Consequently, we propose TSMCTS, which integrates a tidiness discriminator with an MCTS-based tidying planner to find optimal tidied arrangements. TSMCTS has successfully demonstrated its capability across various environments, including coffee tables, dining tables, office desks, and bathrooms. The TTU dataset is available at: this https URL.', 'abstract_zh': '基于整洁度评分引导的蒙特卡洛树搜索（TSMCTS）：利用RGB-D相机解决桌面整理问题的新框架', 'title_zh': '基于整洁度评分的蒙特卡洛树搜索方法用于视觉桌面整理'}
{'arxiv_id': 'arXiv:2502.17213', 'title': 'Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics', 'authors': 'Jiahe Li, Xin Chen, Fanqi Shen, Junru Chen, Yuxin Liu, Daoze Zhang, Zhizhang Yuan, Fang Zhao, Meng Li, Yang Yang', 'link': 'https://arxiv.org/abs/2502.17213', 'abstract': 'Neurological disorders represent significant global health challenges, driving the advancement of brain signal analysis methods. Scalp electroencephalography (EEG) and intracranial electroencephalography (iEEG) are widely used to diagnose and monitor neurological conditions. However, dataset heterogeneity and task variations pose challenges in developing robust deep learning solutions. This review systematically examines recent advances in deep learning approaches for EEG/iEEG-based neurological diagnostics, focusing on applications across 7 neurological conditions using 46 datasets. We explore trends in data utilization, model design, and task-specific adaptations, highlighting the importance of pre-trained multi-task models for scalable, generalizable solutions. To advance research, we propose a standardized benchmark for evaluating models across diverse datasets to enhance reproducibility. This survey emphasizes how recent innovations can transform neurological diagnostics and enable the development of intelligent, adaptable healthcare solutions.', 'abstract_zh': '神经学障碍代表了重大的全球健康挑战，推动了脑电波信号分析方法的进步。头皮电生理图（EEG）和颅内电生理图（iEEG）广泛用于神经学状况的诊断和监测。然而，数据集异质性和任务变化对开发稳健的深度学习解决方案构成了挑战。本文系统回顾了基于EEG/iEEG的神经学诊断中深度学习方法的最新进展，重点关注在涉及7种神经学条件的46个数据集中的应用。我们探讨了数据利用趋势、模型设计以及任务特定适应性，并强调了为实现可扩展和通用的解决方案，预训练多任务模型的重要性。为了促进研究，我们提出了一种标准化基准，用于跨多样数据集评估模型以增强可重复性。本文强调近期创新如何变革神经学诊断，并助力开发智能和适应性强的医疗保健解决方案。', 'title_zh': '基于深度学习的电气脑信号分析：推进神经诊断技术'}
{'arxiv_id': 'arXiv:2502.17204', 'title': 'Order Matters: Investigate the Position Bias in Multi-constraint Instruction Following', 'authors': 'Jie Zeng, Qianyu He, Qingyu Ren, Jiaqing Liang, Yanghua Xiao, Weikang Zhou, Zeye Sun, Fei Yu', 'link': 'https://arxiv.org/abs/2502.17204', 'abstract': "Real-world instructions with multiple constraints pose a significant challenge to existing large language models (LLMs). An observation is that the LLMs exhibit dramatic performance fluctuation when disturbing the order of the incorporated constraints. Yet, none of the existing works has systematically investigated this position bias problem in the field of multi-constraint instruction following. To bridge this gap, we design a probing task where we quantitatively measure the difficulty distribution of the constraints by a novel Difficulty Distribution Index (CDDI). Through the experimental results, we find that LLMs are more performant when presented with the constraints in a ``hard-to-easy'' order. This preference can be generalized to LLMs with different architecture or different sizes of parameters. Additionally, we conduct an explanation study, providing an intuitive insight into the correlation between the LLM's attention and constraint orders. Our code and dataset are publicly available at this https URL.", 'abstract_zh': '现实世界中的多约束指令对现有大规模语言模型构成显著挑战。观察发现，打乱融合约束的顺序会显著影响语言模型的性能。然而，目前的研究尚未系统地探讨多约束指令跟随中的位置偏移问题。为解决这一问题，我们设计了一项探针任务，通过新的难度分布指数（CDDI）定量测量约束的难度分布。实验结果表明，当呈现“难到易”的约束顺序时，语言模型的性能更佳。这一偏好可以泛化到具有不同架构或不同参数量的语言模型。此外，我们还进行了解释研究，提供了一种直观的视角来理解语言模型的注意力与约束顺序之间的关联。我们的代码和数据集可在以下链接获取。', 'title_zh': '顺序有影响：探究多约束指令跟随中的位置偏差'}
{'arxiv_id': 'arXiv:2502.17196', 'title': 'Disentangling Visual Transformers: Patch-level Interpretability for Image Classification', 'authors': 'Guillaume Jeanneret, Loïc Simon, Frédéric Jurie', 'link': 'https://arxiv.org/abs/2502.17196', 'abstract': 'Visual transformers have achieved remarkable performance in image classification tasks, but this performance gain has come at the cost of interpretability. One of the main obstacles to the interpretation of transformers is the self-attention mechanism, which mixes visual information across the whole image in a complex way. In this paper, we propose Hindered Transformer (HiT), a novel interpretable by design architecture inspired by visual transformers. Our proposed architecture rethinks the design of transformers to better disentangle patch influences at the classification stage. Ultimately, HiT can be interpreted as a linear combination of patch-level information. We show that the advantages of our approach in terms of explicability come with a reasonable trade-off in performance, making it an attractive alternative for applications where interpretability is paramount.', 'abstract_zh': '视觉变换器在图像分类任务中取得了 remarkable 的性能，但这一性能的提升是以牺牲可解释性为代价的。变换器的可解释性障碍之一在于其复杂的自注意力机制，该机制以复杂的方式在整个图像中混合视觉信息。本文提出了一种名为 Hindered Transformer (HiT) 的新型可设计可解释架构，该架构受到视觉变换器的启发。我们提出的架构重新思考了变换器的设计，在分类阶段更好地解耦patch的影响。最终，HiT 可以被解释为 patch 级信息的线性组合。我们展示了我们的方法在可解释性方面的优点伴随着性能上的合理权衡，使其成为注重可解释性的应用中一个有吸引力的替代方案。', 'title_zh': '视觉变换器解构：图像分类的 patch 级别可解释性'}
{'arxiv_id': 'arXiv:2502.17189', 'title': 'IGDA: Interactive Graph Discovery through Large Language Model Agents', 'authors': 'Alex Havrilla, David Alvarez-Melis, Nicolo Fusi', 'link': 'https://arxiv.org/abs/2502.17189', 'abstract': 'Large language models ($\\textbf{LLMs}$) have emerged as a powerful method for discovery. Instead of utilizing numerical data, LLMs utilize associated variable $\\textit{semantic metadata}$ to predict variable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as black-box optimizers when given an objective $f$ and sequence of trials. We study LLMs at the intersection of these two capabilities by applying LLMs to the task of $\\textit{interactive graph discovery}$: given a ground truth graph $G^*$ capturing variable relationships and a budget of $I$ edge experiments over $R$ rounds, minimize the distance between the predicted graph $\\hat{G}_R$ and $G^*$ at the end of the $R$-th round. To solve this task we propose $\\textbf{IGDA}$, a LLM-based pipeline incorporating two key components: 1) an LLM uncertainty-driven method for edge experiment selection 2) a local graph update strategy utilizing binary feedback from experiments to improve predictions for unselected neighboring edges. Experiments on eight different real-world graphs show our approach often outperforms all baselines including a state-of-the-art numerical method for interactive graph discovery. Further, we conduct a rigorous series of ablations dissecting the impact of each pipeline component. Finally, to assess the impact of memorization, we apply our interactive graph discovery strategy to a complex, new (as of July 2024) causal graph on protein transcription factors, finding strong performance in a setting where memorization is impossible. Overall, our results show IGDA to be a powerful method for graph discovery complementary to existing numerically driven approaches.', 'abstract_zh': '大型语言模型（LLMs）已 emerged as a powerful method for discovery. Instead of utilizing numerical data, LLMs utilize associated variable semantic metadata to predict variable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as black-box optimizers when given an objective \\( f \\) and sequence of trials. We study LLMs at the intersection of these two capabilities by applying LLMs to the task of interactive graph discovery: given a ground truth graph \\( G^* \\) capturing variable relationships and a budget of \\( I \\) edge experiments over \\( R \\) rounds, minimize the distance between the predicted graph \\( \\hat{G}_R \\) and \\( G^* \\) at the end of the \\( R \\)-th round. To solve this task, we propose IGDA, a LLM-based pipeline incorporating two key components: 1) an LLM uncertainty-driven method for edge experiment selection; 2) a local graph update strategy utilizing binary feedback from experiments to improve predictions for unselected neighboring edges. Experiments on eight different real-world graphs show our approach often outperforms all baselines including a state-of-the-art numerical method for interactive graph discovery. Further, we conduct a rigorous series of ablations dissecting the impact of each pipeline component. Finally, to assess the impact of memorization, we apply our interactive graph discovery strategy to a complex, new (as of July 2024) causal graph on protein transcription factors, finding strong performance in a setting where memorization is impossible. Overall, our results show IGDA to be a powerful method for graph discovery complementary to existing numerically driven approaches.\n\n标题：\nLarge Language Models for Interactive Graph Discovery: IGDA', 'title_zh': 'IGDA：通过大型语言模型代理进行交互式图发现'}
{'arxiv_id': 'arXiv:2502.17187', 'title': 'Evaluating Expert Contributions in a MoE LLM for Quiz-Based Tasks', 'authors': 'Andrei Chernov', 'link': 'https://arxiv.org/abs/2502.17187', 'abstract': 'Recently, Large Language Models (LLMs) with Mixture of Experts (MoE) layers have gained significant attention. Currently, state-of-the-art LLMs utilize this architecture. There is a substantial amount of research on how to train such models and how to select hyperparameters for this architecture. However, there is a lack of studies focusing on post-evaluation analysis of MoE layer properties. In this paper, we take a first step toward closing this gap by evaluating expert contributions on the quiz-based MMLU benchmark. We show that most experts were never activated during inference on this benchmark. Additionally, the output distribution of gating networks is much closer to uniform than sparse. Finally, we demonstrate that the average performance of some experts within the same layer varies significantly.', 'abstract_zh': '近期，带有混合专家（MoE）层的大语言模型（LLMs）受到了显著关注。当前，最先进的LLMs采用这种架构。已有大量研究集中在如何训练这类模型以及如何为这种架构选择超参数上，但缺乏对MoE层特性进行事后评估分析的研究。在本文中，我们首次尝试通过在基于问答的MMLU基准上评估专家贡献来填补这一空白。我们证明，在该基准上，大多数专家从未被激活。此外，门网络的输出分布远比稀疏分布更接近均匀分布。最后，我们展示在同一层内的某些专家的平均性能存在显著差异。', 'title_zh': '评估.moE.大型语言模型在基于问答任务中专家贡献的评价'}
{'arxiv_id': 'arXiv:2502.17173', 'title': 'Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch', 'authors': 'Xueru Wen, Jie Lou, Zichao Li, Yaojie Lu, Xing Yu, Yuqiu Ji, Guohai Xu, Hongyu Lin, Ben He, Xianpei Han, Le Sun, Debing Zhang', 'link': 'https://arxiv.org/abs/2502.17173', 'abstract': 'Reward models (RMs) are crucial for aligning large language models (LLMs) with human preferences. However, most RM research is centered on English and relies heavily on synthetic resources, which leads to limited and less reliable datasets and benchmarks for Chinese. To address this gap, we introduce CheemsBench, a fully human-annotated RM evaluation benchmark within Chinese contexts, and CheemsPreference, a large-scale and diverse preference dataset annotated through human-machine collaboration to support Chinese RM training. We systematically evaluate open-source discriminative and generative RMs on CheemsBench and observe significant limitations in their ability to capture human preferences in Chinese scenarios. Additionally, based on CheemsPreference, we construct an RM that achieves state-of-the-art performance on CheemsBench, demonstrating the necessity of human supervision in RM training. Our findings reveal that scaled AI-generated data struggles to fully capture human preferences, emphasizing the importance of high-quality human supervision in RM development.', 'abstract_zh': 'Reward模型（RMs）对于对齐大型语言模型（LLMs）与人类偏好至关重要。然而，大多数RM研究主要集中在英语上，并且高度依赖合成资源，导致中文领域的数据集和基准有限且可靠性较低。为解决这一问题，我们引入了CheemsBench，这是一个完全基于中文语境的人类标注RM评估基准，并且通过人机协作标注构建了CheemsPreference大型多样偏好数据集，以支持中文RM训练。我们系统地评估了开源的区分性和生成性RM模型在CheemsBench上的表现，并观察到它们在捕捉中文场景中的人类偏好方面存在显著局限。此外，基于CheemsPreference，我们构建了一个在CheemsBench上达到最优性能的RM模型，证明了在RM训练中人类监督的必要性。我们的研究发现表明，规模化的AI生成数据难以完全捕捉人类偏好，强调了在RM开发中高质量人类监督的重要性。', 'title_zh': 'Cheems：从零构建和评估中文奖励模型的实用指南'}
{'arxiv_id': 'arXiv:2502.17172', 'title': 'Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being', 'authors': 'Bin Yin, Chong-Yi Liu, Liya Fu, Jinkun Zhang', 'link': 'https://arxiv.org/abs/2502.17172', 'abstract': 'Affective computing has made significant strides in emotion recognition and generation, yet current approaches mainly focus on short-term pattern recognition and lack a comprehensive framework to guide affective agents toward long-term human well-being. To address this, we propose a teleology-driven affective computing framework that unifies major emotion theories (basic emotion, appraisal, and constructivist approaches) under the premise that affect is an adaptive, goal-directed process that facilitates survival and development. Our framework emphasizes aligning agent responses with both personal/individual and group/collective well-being over extended timescales. We advocate for creating a "dataverse" of personal affective events, capturing the interplay between beliefs, goals, actions, and outcomes through real-world experience sampling and immersive virtual reality. By leveraging causal modeling, this "dataverse" enables AI systems to infer individuals\' unique affective concerns and provide tailored interventions for sustained well-being. Additionally, we introduce a meta-reinforcement learning paradigm to train agents in simulated environments, allowing them to adapt to evolving affective concerns and balance hierarchical goals - from immediate emotional needs to long-term self-actualization. This framework shifts the focus from statistical correlations to causal reasoning, enhancing agents\' ability to predict and respond proactively to emotional challenges, and offers a foundation for developing personalized, ethically aligned affective systems that promote meaningful human-AI interactions and societal well-being.', 'abstract_zh': '情感计算在情绪识别和生成方面取得了显著进展，但当前方法主要集中在短期模式识别，缺乏一套全面的框架来指导情感代理向长期人类福祉发展。为解决这一问题，我们提出了一种以终极目标为导向的情感计算框架，将基本情绪、评估及建构主义方法等主要情绪理论统一起来，前提是情绪是一个适应性和目标导向的过程，有助于生存和发展。该框架强调将代理的反应与个人/个体和群体/集体的长期福祉保持一致。我们提倡创建一个“个人情感事件数据集”，通过现实生活体验抽样和沉浸式虚拟现实捕捉信念、目标、行为与结果之间的交互。借助因果建模，这一“数据集”使人工智能系统能够推断出个体独特的情感关注点，并提供量身定制的干预措施以促进持续的福祉。此外，我们引入了一种元强化学习范式，使代理能够在模拟环境中进行训练，从而适应不断变化的情感关注点并平衡从即时情绪需求到长期自我实现的多层次目标。该框架将重点从统计相关性转向因果推理，增强了代理预测和前瞻应对情绪挑战的能力，并为开发个性化、伦理对齐的情感系统提供了基础，这些系统旨在促进有意义的人机互动和整体福祉。', 'title_zh': '目标导向的情感计算：持续福祉的因果框架'}
{'arxiv_id': 'arXiv:2502.17166', 'title': 'JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning', 'authors': 'Huanghai Liu, Quzhe Huang, Qingjing Chen, Yiran Hu, Jiayu Ma, Yun Liu, Weixing Shen, Yansong Feng', 'link': 'https://arxiv.org/abs/2502.17166', 'abstract': "The Four-Element Theory is a fundamental framework in criminal law, defining the constitution of crime through four dimensions: Subject, Object, Subjective aspect, and Objective aspect. This theory is widely referenced in legal reasoning, and many Large Language Models (LLMs) attempt to incorporate it when handling legal tasks. However, current approaches rely on LLMs' internal knowledge to incorporate this theory, often lacking completeness and representativeness. To address this limitation, we introduce JUREX-4E, an expert-annotated knowledge base covering 155 criminal charges. It is structured through a progressive hierarchical annotation framework that prioritizes legal source validity and employs diverse legal interpretation methods to ensure comprehensiveness and authority. We evaluate JUREX-4E on the Similar Charge Distinction task and apply it to Legal Case Retrieval, demonstrating its effectiveness in improving LLM performance. Experimental results validate the high quality of JUREX-4E and its substantial impact on downstream legal tasks, underscoring its potential for advancing legal AI applications. Code: this https URL", 'abstract_zh': '四要素理论是刑法中的一个基本框架，通过主体、客体、主观方面和客观方面四个维度定义犯罪构成。这一理论广泛应用于法律推理中，许多大规模语言模型（LLMs）在处理法律任务时尝试将其纳入。然而，当前的方法主要依靠LLMs内部的知识来整合这一理论，常常缺乏完整性和代表性。为解决这一局限，我们引入了JUREX-4E，这是一个由专家注释的知识库，涵盖了155项刑事指控。它通过一种逐步分层的注释框架结构化，优先考虑法律源的合法性，并采用多种法律解释方法以确保其全面性和权威性。我们在相似指控区分任务上评估了JUREX-4E，并将其应用于法律案例检索，展示了其在提升LLM表现方面的有效性。实验结果验证了JUREX-4E的高质量及其在下游法律任务中的显著影响，强调了其在推动法律人工智能应用方面的重要潜力。代码：这个 https URL。', 'title_zh': 'JUREX-4E：法律专家标注的四要素法律知识库'}
{'arxiv_id': 'arXiv:2502.17163', 'title': 'MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation', 'authors': 'María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico', 'link': 'https://arxiv.org/abs/2502.17163', 'abstract': 'Automatic evaluation of retrieval augmented generation (RAG) systems relies on fine-grained dimensions like faithfulness and relevance, as judged by expert human annotators. Meta-evaluation benchmarks support the development of automatic evaluators that correlate well with human judgement. However, existing benchmarks predominantly focus on English or use translated data, which fails to capture cultural nuances. A native approach provides a better representation of the end user experience.\nIn this work, we develop a Multilingual End-to-end Meta-Evaluation RAG benchmark (MEMERAG). Our benchmark builds on the popular MIRACL dataset, using native-language questions and generating responses with diverse large language models (LLMs), which are then assessed by expert annotators for faithfulness and relevance. We describe our annotation process and show that it achieves high inter-annotator agreement. We then analyse the performance of the answer-generating LLMs across languages as per the human evaluators. Finally we apply the dataset to our main use-case which is to benchmark multilingual automatic evaluators (LLM-as-a-judge). We show that our benchmark can reliably identify improvements offered by advanced prompting techniques and LLMs. We release our benchmark to support the community developing accurate evaluation methods for multilingual RAG systems.', 'abstract_zh': '多语言端到端元评价RAG基准（MEMERAG）', 'title_zh': 'MEMERAG：一种多语言端到端元评估基准，用于检索增强生成'}
{'arxiv_id': 'arXiv:2502.17161', 'title': 'Real-time Monitoring of Economic Shocks using Company Websites', 'authors': 'Michael Koenig, Jakob Rauch, Martin Woerter', 'link': 'https://arxiv.org/abs/2502.17161', 'abstract': "Understanding the effects of economic shocks on firms is critical for analyzing economic growth and resilience. We introduce a Web-Based Affectedness Indicator (WAI), a general-purpose tool for real-time monitoring of economic disruptions across diverse contexts. By leveraging Large Language Model (LLM) assisted classification and information extraction on texts from over five million company websites, WAI quantifies the degree and nature of firms' responses to external shocks. Using the COVID-19 pandemic as a specific application, we show that WAI is highly correlated with pandemic containment measures and reliably predicts firm performance. Unlike traditional data sources, WAI provides timely firm-level information across industries and geographies worldwide that would otherwise be unavailable due to institutional and data availability constraints. This methodology offers significant potential for monitoring and mitigating the impact of technological, political, financial, health or environmental crises, and represents a transformative tool for adaptive policy-making and economic resilience.", 'abstract_zh': '理解经济冲击对企业的影响对于分析经济增长和韧性至关重要。我们介绍了一种基于网络的受影响程度指标（WAI），这是一种用于实时监控不同背景下经济中断的通用工具。通过利用大型语言模型（LLM）辅助分类和信息提取来自全球超过五百万家公司网站的文本，WAI量化了企业在外部冲击下的响应程度和性质。以COVID-19大流行为例，我们展示了WAI与大流行控制措施高度相关，并可靠地预测了企业绩效。与传统的数据来源相比，WAI提供了由于机构和数据可用性限制而难以获得的全球范围内不同行业和地区的及时企业级信息。该方法论在监测和减轻技术、政治、金融、健康或环境危机的影响方面具有重大潜力，并代表了一种变革性的工具，用于适应性政策制定和经济韧性提升。', 'title_zh': '基于公司网站的实时监测经济冲击方法'}
{'arxiv_id': 'arXiv:2502.17154', 'title': 'MaxGlaViT: A novel lightweight vision transformer-based approach for early diagnosis of glaucoma stages from fundus images', 'authors': 'Mustafa Yurdakul, Kubra Uyar, Sakir Tasdemir', 'link': 'https://arxiv.org/abs/2502.17154', 'abstract': "Glaucoma is a prevalent eye disease that progresses silently without symptoms. If not detected and treated early, it can cause permanent vision loss. Computer-assisted diagnosis systems play a crucial role in timely and efficient identification. This study introduces MaxGlaViT, a lightweight model based on the restructured Multi-Axis Vision Transformer (MaxViT) for early glaucoma detection. First, MaxViT was scaled to optimize block and channel numbers, resulting in a lighter architecture. Second, the stem was enhanced by adding attention mechanisms (CBAM, ECA, SE) after convolution layers to improve feature learning. Third, MBConv structures in MaxViT blocks were replaced by advanced DL blocks (ConvNeXt, ConvNeXtV2, InceptionNeXt). The model was evaluated using the HDV1 dataset, containing fundus images of different glaucoma stages. Additionally, 40 CNN and 40 ViT models were tested on HDV1 to validate MaxGlaViT's efficiency. Among CNN models, EfficientB6 achieved the highest accuracy (84.91%), while among ViT models, MaxViT-Tiny performed best (86.42%). The scaled MaxViT reached 87.93% accuracy. Adding ECA to the stem block increased accuracy to 89.01%. Replacing MBConv with ConvNeXtV2 further improved it to 89.87%. Finally, integrating ECA in the stem and ConvNeXtV2 in MaxViT blocks resulted in 92.03% accuracy. Testing 80 DL models for glaucoma stage classification, this study presents a comprehensive and comparative analysis. MaxGlaViT outperforms experimental and state-of-the-art models, achieving 92.03% accuracy, 92.33% precision, 92.03% recall, 92.13% f1-score, and 87.12% Cohen's kappa score.", 'abstract_zh': '无症状进展的青光眼是一种常见的致盲性眼病。如果未能早期检测和治疗，将导致永久性视力丧失。基于重构的Multi-Axis Vision Transformer (MaxViT) 的轻量化模型MaxGlaViT在早期青光眼检测中的应用研究', 'title_zh': 'MaxGlaViT: 一种基于轻量级视觉变换器的早期青光眼阶段诊断方法基于视网膜影像'}
{'arxiv_id': 'arXiv:2502.17130', 'title': 'Low-distortion and GPU-compatible Tree Embeddings in Hyperbolic Space', 'authors': 'Max van Spengler, Pascal Mettes', 'link': 'https://arxiv.org/abs/2502.17130', 'abstract': 'Embedding tree-like data, from hierarchies to ontologies and taxonomies, forms a well-studied problem for representing knowledge across many domains. Hyperbolic geometry provides a natural solution for embedding trees, with vastly superior performance over Euclidean embeddings. Recent literature has shown that hyperbolic tree embeddings can even be placed on top of neural networks for hierarchical knowledge integration in deep learning settings. For all applications, a faithful embedding of trees is needed, with combinatorial constructions emerging as the most effective direction. This paper identifies and solves two key limitations of existing works. First, the combinatorial construction hinges on finding highly separated points on a hypersphere, a notoriously difficult problem. Current approaches achieve poor separation, degrading the quality of the corresponding hyperbolic embedding. We propose highly separated Delaunay tree embeddings (HS-DTE), which integrates angular separation in a generalized formulation of Delaunay embeddings, leading to lower embedding distortion. Second, low-distortion requires additional precision. The current approach for increasing precision is to use multiple precision arithmetic, which renders the embeddings useless on GPUs in deep learning settings. We reformulate the combinatorial construction using floating point expansion arithmetic, leading to superior embedding quality while retaining utility on accelerated hardware.', 'abstract_zh': '从层次结构到本体和分类的树状数据嵌入：超球面上高度分离点的综合构建与超精密浮点扩展算术在保持高质量嵌入的同时提高硬件兼容性', 'title_zh': '低失真和GPU兼容的双曲空间树嵌入'}
{'arxiv_id': 'arXiv:2502.17125', 'title': 'LettuceDetect: A Hallucination Detection Framework for RAG Applications', 'authors': 'Ádám Kovács, Gábor Recski', 'link': 'https://arxiv.org/abs/2502.17125', 'abstract': "Retrieval Augmented Generation (RAG) systems remain vulnerable to hallucinated answers despite incorporating external knowledge sources. We present LettuceDetect a framework that addresses two critical limitations in existing hallucination detection methods: (1) the context window constraints of traditional encoder-based methods, and (2) the computational inefficiency of LLM based approaches. Building on ModernBERT's extended context capabilities (up to 8k tokens) and trained on the RAGTruth benchmark dataset, our approach outperforms all previous encoder-based models and most prompt-based models, while being approximately 30 times smaller than the best models. LettuceDetect is a token-classification model that processes context-question-answer triples, allowing for the identification of unsupported claims at the token level. Evaluations on the RAGTruth corpus demonstrate an F1 score of 79.22% for example-level detection, which is a 14.8% improvement over Luna, the previous state-of-the-art encoder-based architecture. Additionally, the system can process 30 to 60 examples per second on a single GPU, making it more practical for real-world RAG applications.", 'abstract_zh': 'LettuceDetect：一种解决现有幻觉检测方法关键限制的框架', 'title_zh': 'LettuceDetect：面向RAG应用程序的幻觉检测框架'}
{'arxiv_id': 'arXiv:2502.17121', 'title': 'Adversarial Training for Defense Against Label Poisoning Attacks', 'authors': 'Melis Ilayda Bal, Volkan Cevher, Michael Muehlebach', 'link': 'https://arxiv.org/abs/2502.17121', 'abstract': "As machine learning models grow in complexity and increasingly rely on publicly sourced data, such as the human-annotated labels used in training large language models, they become more vulnerable to label poisoning attacks. These attacks, in which adversaries subtly alter the labels within a training dataset, can severely degrade model performance, posing significant risks in critical applications. In this paper, we propose FLORAL, a novel adversarial training defense strategy based on support vector machines (SVMs) to counter these threats. Utilizing a bilevel optimization framework, we cast the training process as a non-zero-sum Stackelberg game between an attacker, who strategically poisons critical training labels, and the model, which seeks to recover from such attacks. Our approach accommodates various model architectures and employs a projected gradient descent algorithm with kernel SVMs for adversarial training. We provide a theoretical analysis of our algorithm's convergence properties and empirically evaluate FLORAL's effectiveness across diverse classification tasks. Compared to robust baselines and foundation models such as RoBERTa, FLORAL consistently achieves higher robust accuracy under increasing attacker budgets. These results underscore the potential of FLORAL to enhance the resilience of machine learning models against label poisoning threats, thereby ensuring robust classification in adversarial settings.", 'abstract_zh': '随着机器学习模型变得更加复杂并越来越多地依赖公开数据，如用于训练大规模语言模型的人标注标签，它们更容易受到标签投毒攻击的影响。这些攻击通过微妙地篡改训练数据集中的标签，可以严重损害模型性能，对关键应用构成重大风险。在本文中，我们提出了一种基于支持向量机（SVMs）的新型对抗训练防御策略FLORAL，以应对这些威胁。利用二层优化框架，我们将训练过程视为攻击者战略性地篡改关键训练标签与模型试图从此类攻击中恢复的非零和斯塔克尔贝格博弈。我们的方法适用于各种模型架构，并采用投影梯度下降算法结合核SVM进行对抗训练。我们提供了算法收敛性的理论分析，并在多种分类任务中 empirically 评估了 FLORAL 的有效性。与鲁棒基线模型（如 RoBERTa）相比，FLORAL 在不断增加的攻击预算下始终获得更高的鲁棒准确性。这些结果突显了 FLORAL 在增强机器学习模型对标签投毒威胁的抗性和确保对抗环境下的稳健分类方面的潜力。', 'title_zh': '对抗训练以防御标签投毒攻击'}
{'arxiv_id': 'arXiv:2502.17119', 'title': 'Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions', 'authors': 'Zhong Li, Qi Huang, Lincen Yang, Jiayang Shi, Zhao Yang, Niki van Stein, Thomas Bäck, Matthijs van Leeuwen', 'link': 'https://arxiv.org/abs/2502.17119', 'abstract': 'In recent years, generative models have achieved remarkable performance across diverse applications, including image generation, text synthesis, audio creation, video generation, and data augmentation. Diffusion models have emerged as superior alternatives to Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) by addressing their limitations, such as training instability, mode collapse, and poor representation of multimodal distributions. This success has spurred widespread research interest. In the domain of tabular data, diffusion models have begun to showcase similar advantages over GANs and VAEs, achieving significant performance breakthroughs and demonstrating their potential for addressing unique challenges in tabular data modeling. However, while domains like images and time series have numerous surveys summarizing advancements in diffusion models, there remains a notable gap in the literature for tabular data. Despite the increasing interest in diffusion models for tabular data, there has been little effort to systematically review and summarize these developments. This lack of a dedicated survey limits a clear understanding of the challenges, progress, and future directions in this critical area. This survey addresses this gap by providing a comprehensive review of diffusion models for tabular data. Covering works from June 2015, when diffusion models emerged, to December 2024, we analyze nearly all relevant studies, with updates maintained in a \\href{this https URL}{GitHub repository}. Assuming readers possess foundational knowledge of statistics and diffusion models, we employ mathematical formulations to deliver a rigorous and detailed review, aiming to promote developments in this emerging and exciting area.', 'abstract_zh': '近年来，生成模型在图像生成、文本合成、音频创建、视频生成和数据增强等多元应用中取得了显著性能。扩散模型因其在训练稳定性、模式崩溃和多模态分布表示等方面的改进，已成为生成对抗网络（GANs）和变分自编码器（VAEs）的优越替代方案，引起了广泛的研究兴趣。在表格数据领域，扩散模型也开始展示出类似的优势，取得了显著的性能突破，并展现出解决表格数据建模独特挑战的潜力。然而，在图像和时间序列等领域的文献综述已经相当丰富，但表格数据领域的相关文献却存在明显不足。尽管人们对表格数据中的扩散模型表现出越来越大的兴趣，但缺乏系统性的回顾和总结。这种缺乏专门综述的情况限制了对该领域挑战、进展和未来方向的清晰理解。本文综述填补了这一空白，提供了对表格数据领域扩散模型的全面回顾。我们从2015年6月扩散模型首次出现到2024年12月，分析了几乎所有相关研究，并在GitHub存储库中持续更新。假设读者具备统计学和扩散模型的基础知识，本文采用数学公式进行详细阐述，旨在促进这一新兴领域的发展。', 'title_zh': '表格数据的扩散模型：挑战、现有进展及未来方向'}
{'arxiv_id': 'arXiv:2502.17105', 'title': 'SFLD: Reducing the content bias for AI-generated Image Detection', 'authors': 'Seoyeon Gye, Junwon Ko, Hyounguk Shon, Minchan Kwon, Junmo Kim', 'link': 'https://arxiv.org/abs/2502.17105', 'abstract': 'Identifying AI-generated content is critical for the safe and ethical use of generative AI. Recent research has focused on developing detectors that generalize to unknown generators, with popular methods relying either on high-level features or low-level fingerprints. However, these methods have clear limitations: biased towards unseen content, or vulnerable to common image degradations, such as JPEG compression. To address these issues, we propose a novel approach, SFLD, which incorporates PatchShuffle to integrate high-level semantic and low-level textural information. SFLD applies PatchShuffle at multiple levels, improving robustness and generalization across various generative models. Additionally, current benchmarks face challenges such as low image quality, insufficient content preservation, and limited class diversity. In response, we introduce TwinSynths, a new benchmark generation methodology that constructs visually near-identical pairs of real and synthetic images to ensure high quality and content preservation. Our extensive experiments and analysis show that SFLD outperforms existing methods on detecting a wide variety of fake images sourced from GANs, diffusion models, and TwinSynths, demonstrating the state-of-the-art performance and generalization capabilities to novel generative models.', 'abstract_zh': '识别AI生成的内容对于安全和伦理使用生成型AI至关重要。近期的研究集中在开发能够泛化到未知生成器的检测器，现有方法主要依赖高层特征或低层指纹。然而，这些方法存在明显的局限性：要么偏向未见内容，要么易受JPEG压缩等常见图像降级的影响。为解决这些问题，我们提出了一个新颖的方法SFLD，该方法结合PatchShuffle以整合高层语义和低层纹理信息。SFLD在多个层面应用PatchShuffle，增强了模型的鲁棒性和泛化能力。此外，当前的基准测试存在图像质量低、内容保真度不足以及类别多样性有限等挑战。为此，我们引入了一种新的基准生成方法TwinSynths，构建了视觉上几乎相同的真伪图像对，以确保高质量和内容保真度。广泛的实验和分析表明，SFLD在检测来自GAN、扩散模型和TwinSynths的多种伪造图像方面优于现有方法，展示了其优异的性能和对新型生成模型的泛化能力。', 'title_zh': 'SFLD: 减少AI生成图像检测中的内容偏见'}
{'arxiv_id': 'arXiv:2502.17100', 'title': 'Generative Models in Decision Making: A Survey', 'authors': 'Yinchuan Li, Xinyu Shao, Jianping Zhang, Haozhi Wang, Leo Maxime Brunswic, Kaiwen Zhou, Jiqian Dong, Kaiyang Guo, Xiu Li, Zhitang Chen, Jun Wang, Jianye Hao', 'link': 'https://arxiv.org/abs/2502.17100', 'abstract': 'In recent years, the exceptional performance of generative models in generative tasks has sparked significant interest in their integration into decision-making processes. Due to their ability to handle complex data distributions and their strong model capacity, generative models can be effectively incorporated into decision-making systems by generating trajectories that guide agents toward high-reward state-action regions or intermediate sub-goals. This paper presents a comprehensive review of the application of generative models in decision-making tasks. We classify seven fundamental types of generative models: energy-based models, generative adversarial networks, variational autoencoders, normalizing flows, diffusion models, generative flow networks, and autoregressive models. Regarding their applications, we categorize their functions into three main roles: controllers, modelers and optimizers, and discuss how each role contributes to decision-making. Furthermore, we examine the deployment of these models across five critical real-world decision-making scenarios. Finally, we summarize the strengths and limitations of current approaches and propose three key directions for advancing next-generation generative directive models: high-performance algorithms, large-scale generalized decision-making models, and self-evolving and adaptive models.', 'abstract_zh': '近年来，生成模型在生成任务中卓越的表现引发了将其整合到决策过程中的显著兴趣。由于其处理复杂数据分布和强大模型能力的特点，生成模型可以通过生成引导智能体向高奖励状态动作区域或中间子目标进发的轨迹，有效融入决策系统中。本文对生成模型在决策任务中的应用进行了全面回顾。我们分类了七种基本类型的生成模型：能量模型、生成对抗网络、变分自编码器、规范化流、扩散模型、生成流网络和自回归模型。关于其应用，我们将它们的功能分为三大角色：控制器、建模者和优化器，并讨论每个角色如何助力决策。此外，我们考察了这些模型在五个关键现实世界决策场景中的部署情况。最后，我们总结了当前方法的优缺点，并提出了推进下一代生成导向模型的三个关键方向：高性能算法、大规模通用决策模型和自我进化和自适应模型。', 'title_zh': '生成模型在决策中的应用：一个综述'}
{'arxiv_id': 'arXiv:2502.17099', 'title': 'Improved Diffusion-based Generative Model with Better Adversarial Robustness', 'authors': 'Zekun Wang, Mingyang Yi, Shuchen Xue, Zhenguo Li, Ming Liu, Bing Qin, Zhi-Ming Ma', 'link': 'https://arxiv.org/abs/2502.17099', 'abstract': 'Diffusion Probabilistic Models (DPMs) have achieved significant success in generative tasks. However, their training and sampling processes suffer from the issue of distribution mismatch. During the denoising process, the input data distributions differ between the training and inference stages, potentially leading to inaccurate data generation. To obviate this, we analyze the training objective of DPMs and theoretically demonstrate that this mismatch can be alleviated through Distributionally Robust Optimization (DRO), which is equivalent to performing robustness-driven Adversarial Training (AT) on DPMs. Furthermore, for the recently proposed Consistency Model (CM), which distills the inference process of the DPM, we prove that its training objective also encounters the mismatch issue. Fortunately, this issue can be mitigated by AT as well. Based on these insights, we propose to conduct efficient AT on both DPM and CM. Finally, extensive empirical studies validate the effectiveness of AT in diffusion-based models. The code is available at this https URL.', 'abstract_zh': '扩散概率模型（DPMs）在生成任务中取得了显著成功，然而它们的训练和采样过程遭受分布不匹配的问题。在去噪过程中，训练阶段和推断阶段的输入数据分布存在差异，可能导致数据生成不准确。为解决这一问题，我们分析了DPMs的训练目标，并理论上证明可以通过分布鲁棒优化（DRO）来缓解这一不匹配问题，这等同于在DPMs上进行以鲁棒性为导向的对抗训练（AT）。此外，对于最近提出的一致性模型（CM），它通过DPM的推断过程进行精炼，我们证明其训练目标也遇到了分布不匹配的问题。幸运的是，这一问题同样可以通过AT来缓解。基于这些见解，我们提出对DPM和CM进行高效的AT。最后，广泛的实证研究验证了AT在基于扩散的模型中的有效性。代码可从此处访问。', 'title_zh': '基于扩散的生成模型的对抗鲁棒性改进'}
{'arxiv_id': 'arXiv:2502.17091', 'title': 'WildFrame: Comparing Framing in Humans and LLMs on Naturally Occurring Texts', 'authors': 'Gili Lior, Liron Nacchace, Gabriel Stanovsky', 'link': 'https://arxiv.org/abs/2502.17091', 'abstract': 'Humans are influenced by how information is presented, a phenomenon known as the framing effect. Previous work has shown that LLMs may also be susceptible to framing but has done so on synthetic data and did not compare to human behavior. We introduce WildFrame, a dataset for evaluating LLM responses to positive and negative framing, in naturally-occurring sentences, and compare humans on the same data. WildFrame consists of 1,000 texts, first selecting real-world statements with clear sentiment, then reframing them in either positive or negative light, and lastly, collecting human sentiment annotations. By evaluating eight state-of-the-art LLMs on WildFrame, we find that all models exhibit framing effects similar to humans ($r\\geq0.57$), with both humans and models being more influenced by positive rather than negative reframing. Our findings benefit model developers, who can either harness framing or mitigate its effects, depending on the downstream application.', 'abstract_zh': '人类受信息呈现方式的影响，这一现象称为框架效应。先前的研究已经表明，大语言模型也可能受到框架效应的影响，但这些研究主要基于合成数据，并未与人类行为进行对比。我们引入了WildFrame数据集，用于评估大语言模型在自然语句中的正向和负向框架效应，并将人类的行为与之进行对比。WildFrame包含1,000个文本，首先选择具有明确情感的真实世界陈述，然后将其重新框架为正向或负向，最后收集人类的情感注释。通过在WildFrame上评估八种最先进的大语言模型，我们发现所有模型的框架效应与人类相似（相关系数≥0.57），人类和模型都更容易受到正向而非负向重新框架的影响。我们的发现有助于模型开发者根据下游应用的需要利用或遏制框架效应。', 'title_zh': 'WildFrame: 人类与LLMs在自然文本中 framing 方式的比较'}
{'arxiv_id': 'arXiv:2502.17087', 'title': 'Conditional Diffusion-Flow models for generating 3D cosmic density fields: applications to f(R) cosmologies', 'authors': 'Julieth Katherine Riveros, Paola Saavedra, Hector J. Hortua, Jorge Enrique Garcia-Farieta, Ivan Olier', 'link': 'https://arxiv.org/abs/2502.17087', 'abstract': 'Next-generation galaxy surveys promise unprecedented precision in testing gravity at cosmological scales. However, realising this potential requires accurately modelling the non-linear cosmic web. We address this challenge by exploring conditional generative modelling to create 3D dark matter density fields via score-based (diffusion) and flow-based methods. Our results demonstrate the power of diffusion models to accurately reproduce the matter power spectra and bispectra, even for unseen configurations. They also offer a significant speed-up with slightly reduced accuracy, when flow-based reconstructing the probability distribution function, but they struggle with higher-order statistics. To improve conditional generation, we introduce a novel multi-output model to develop feature representations of the cosmological parameters. Our findings offer a powerful tool for exploring deviations from standard gravity, combining high precision with reduced computational cost, thus paving the way for more comprehensive and efficient cosmological analyses', 'abstract_zh': '下一代星系巡天有望在宇宙尺度上以空前的精度测试引力。然而，实现这一潜力需要准确 Modeling 非线性宇宙网。我们通过探索条件生成建模，利用分数基于（扩散）和流基于方法，创建三维暗 matter 密度场来应对这一挑战。我们的结果展示了分数模型准确再现物质功率谱和三谱的能力，即使对于未见配置也是如此。同时，当使用流基于方法重构概率分布函数时，它们提供了显著的速度提升，但精度略低，但在处理高阶统计时遇到困难。为改进条件生成，我们引入了一种新颖的多输出模型，以开发宇宙参数的功能表示。我们的发现提供了一种强大的工具，可以探索标准引力的偏差，结合高精度和较低的计算成本，从而为更全面和高效的宇宙学分析铺平道路。', 'title_zh': '条件扩散-流模型用于生成三维宇宙密度场：应用于$f(R)$宇宙学'}
{'arxiv_id': 'arXiv:2502.17081', 'title': 'Forgetting Any Data at Any Time: A Theoretically Certified Unlearning Framework for Vertical Federated Learning', 'authors': 'Linian Wang, Leye Wang', 'link': 'https://arxiv.org/abs/2502.17081', 'abstract': 'Privacy concerns in machine learning are heightened by regulations such as the GDPR, which enforces the "right to be forgotten" (RTBF), driving the emergence of machine unlearning as a critical research field. Vertical Federated Learning (VFL) enables collaborative model training by aggregating a sample\'s features across distributed parties while preserving data privacy at each source. This paradigm has seen widespread adoption in healthcare, finance, and other privacy-sensitive domains. However, existing VFL systems lack robust mechanisms to comply with RTBF requirements, as unlearning methodologies for VFL remain underexplored. In this work, we introduce the first VFL framework with theoretically guaranteed unlearning capabilities, enabling the removal of any data at any time. Unlike prior approaches -- which impose restrictive assumptions on model architectures or data types for removal -- our solution is model- and data-agnostic, offering universal compatibility. Moreover, our framework supports asynchronous unlearning, eliminating the need for all parties to be simultaneously online during the forgetting process. These advancements address critical gaps in current VFL systems, ensuring compliance with RTBF while maintaining operational this http URL make all our implementations publicly available at this https URL.', 'abstract_zh': 'GDPR等法规增强的机器学习中的隐私担忧推动了机器遗忘领域的新兴研究，而垂直联邦学习(VFL)通过在不泄露数据隐私的情况下聚合样本特征实现协作模型训练，在医疗、金融等领域得到广泛应用。然而，现有VFL系统缺乏符合“被遗忘权”(RTBF)要求的稳健机制，因为VFL的遗忘方法仍处于初始探索阶段。在本文中，我们介绍了首个具备理论保证的遗忘能力的VFL框架，支持任意时间任意数据的移除。我们的解决方案不受模型架构或数据类型的限制，具有通用兼容性。此外，我们的框架支持异步遗忘，避免了遗忘过程中所有参与方需同时在线的需求。这些进步填补了当前VFL系统的关键空白，确保合规的同时保持操作的便利性。我们的所有实现已公开发布，在此提供链接。', 'title_zh': '随时删除任意数据：一种理论上认证的垂直联邦学习忘却框架'}
{'arxiv_id': 'arXiv:2502.17071', 'title': 'Systematic Weight Evaluation for Pruning Large Language Models: Enhancing Performance and Sustainability', 'authors': 'Ashhadul Islam, Samir Brahim Belhaouari, Amine Bermak', 'link': 'https://arxiv.org/abs/2502.17071', 'abstract': 'The exponential growth of large language models (LLMs) like ChatGPT has revolutionized artificial intelligence, offering unprecedented capabilities in natural language processing. However, the extensive computational resources required for training these models have significant environmental implications, including high carbon emissions, energy consumption, and water usage. This research presents a novel approach to LLM pruning, focusing on the systematic evaluation of individual weight importance throughout the training process. By monitoring parameter evolution over time, we propose a method that effectively reduces model size without compromising performance. Extensive experiments with both a scaled-down LLM and a large multimodal model reveal that moderate pruning enhances efficiency and reduces loss, while excessive pruning drastically deteriorates model performance. These findings highlight the critical need for optimized AI models to ensure sustainable development, balancing technological advancement with environmental responsibility.', 'abstract_zh': '大规模语言模型（LLMs）如ChatGPT的指数级增长已 revolutionized 人工智能，提供了前所未有的自然语言处理能力。然而，这些模型训练所需的巨大计算资源对环境产生了显著影响，包括高碳排放、能源消耗和用水量。本研究提出了一种新的LLM剪枝方法，重点在于在训练过程中系统评估每个权重的重要性。通过监测参数随时间的演变，我们提出了一种有效减小模型大小而不牺牲性能的方法。通过对缩小比例的LLM和大型多模态模型的广泛实验发现，适度剪枝可以提高效率并减少损失，而过度剪枝会大幅降低模型性能。这些发现强调了优化AI模型以实现可持续发展的重要性，平衡技术进步与环境保护责任。', 'title_zh': '大规模语言模型的系统化权重评估剪枝：提升性能与可持续性'}
{'arxiv_id': 'arXiv:2502.17057', 'title': 'LLM-QE: Improving Query Expansion by Aligning Large Language Models with Ranking Preferences', 'authors': 'Sijia Yao, Pengcheng Huang, Zhenghao Liu, Yu Gu, Yukun Yan, Shi Yu, Ge Yu', 'link': 'https://arxiv.org/abs/2502.17057', 'abstract': 'Query expansion plays a crucial role in information retrieval, which aims to bridge the semantic gap between queries and documents to improve matching performance. This paper introduces LLM-QE, a novel approach that leverages Large Language Models (LLMs) to generate document-based query expansions, thereby enhancing dense retrieval models. Unlike traditional methods, LLM-QE designs both rank-based and answer-based rewards and uses these reward models to optimize LLMs to align with the ranking preferences of both retrievers and LLMs, thus mitigating the hallucination of LLMs during query expansion. Our experiments on the zero-shot dense retrieval model, Contriever, demonstrate the effectiveness of LLM-QE, achieving an improvement of over 8%. Furthermore, by incorporating answer-based reward modeling, LLM-QE generates more relevant and precise information related to the documents, rather than simply producing redundant tokens to maximize rank-based rewards. Notably, LLM-QE also improves the training process of dense retrievers, achieving a more than 5% improvement after fine-tuning. All codes are available at this https URL.', 'abstract_zh': 'LLM-QE：利用大型语言模型进行基于文档的查询扩展以增强密集检索模型', 'title_zh': 'LLM-QE：通过将大型语言模型与排名偏好对齐以改进查询扩展'}
{'arxiv_id': 'arXiv:2502.17055', 'title': 'Stable-SPAM: How to Train in 4-Bit More Stably than 16-Bit Adam', 'authors': 'Tianjin Huang, Haotian Hu, Zhenyu Zhang, Gaojie Jin, Xiang Li, Li Shen, Tianlong Chen, Lu Liu, Qingsong Wen, Zhangyang Wang, Shiwei Liu', 'link': 'https://arxiv.org/abs/2502.17055', 'abstract': 'This paper comprehensively evaluates several recently proposed optimizers for 4-bit training, revealing that low-bit precision amplifies sensitivity to learning rates and often causes unstable gradient norms, leading to divergence at higher learning rates. Among these, SPAM, a recent optimizer featuring momentum reset and spike-aware gradient clipping, achieves the best performance across various bit levels, but struggles to stabilize gradient norms, requiring careful learning rate tuning. To address these limitations, we propose Stable-SPAM, which incorporates enhanced gradient normalization and clipping techniques. In particular, Stable-SPAM (1) adaptively updates the clipping threshold for spiked gradients by tracking their historical maxima; (2) normalizes the entire gradient matrix based on its historical $l_2$-norm statistics; and $(3)$ inherits momentum reset from SPAM to periodically reset the first and second moments of Adam, mitigating the accumulation of spiked gradients. Extensive experiments show that Stable-SPAM effectively stabilizes gradient norms in 4-bit LLM training, delivering superior performance compared to Adam and SPAM. Notably, our 4-bit LLaMA-1B model trained with Stable-SPAM outperforms the BF16 LLaMA-1B trained with Adam by up to $2$ perplexity. Furthermore, when both models are trained in 4-bit, Stable-SPAM achieves the same loss as Adam while requiring only about half the training steps. Code is available at this https URL.', 'abstract_zh': '这篇论文全面评估了几种最近提出的4比特训练优化器，揭示了低比特精度放大了学习率的敏感性，往往导致梯度范数不穩定，在高学习率时出现发散。其中，SPAM作为一种具备速度重置和尖峰感知梯度裁剪特性的优化器，在各种比特水平上表现出最佳性能，但梯度范数的稳定性能较差，需要仔细调整学习率。为解决这些局限性，我们提出了Stable-SPAM，它结合了增强的梯度规范化和裁剪技术。具体而言，Stable-SPAM：(1) 通过跟踪尖峰梯度的历史最大值自适应地更新裁剪阈值；(2) 根据其历史 $l_2$-范数统计规范化整个梯度矩阵；(3) 继承SPAM的速度重置特性，定期重置Adam的第一和第二矩，减轻尖峰梯度的累积。广泛实验表明，Stable-SPAM在4比特大语言模型训练中有效稳定了梯度范数，性能优于Adam和SPAM。值得注意的是，使用Stable-SPAM训练的4比特LLaMA-1B模型比使用Adam训练的BF16 LLaMA-1B模型在困惑度上最多降低2个单位。此外，当两个模型都在4比特下训练时，Stable-SPAM达到了与Adam相同的效果，但所需的训练步数仅为一半。代码可在以下链接获取。', 'title_zh': 'Stable-SPAM: 如何比16位Adam更为稳定地训练4位数据'}
{'arxiv_id': 'arXiv:2502.17036', 'title': 'Language Model Re-rankers are Steered by Lexical Similarities', 'authors': 'Lovisa Hagström, Ercong Nie, Ruben Halifa, Helmut Schmid, Richard Johansson, Alexander Junge', 'link': 'https://arxiv.org/abs/2502.17036', 'abstract': 'Language model (LM) re-rankers are used to refine retrieval results for retrieval-augmented generation (RAG). They are more expensive than lexical matching methods like BM25 but assumed to better process semantic information. To understand whether LM re-rankers always live up to this assumption, we evaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show that LM re-rankers struggle to outperform a simple BM25 re-ranker on DRUID. Leveraging a novel separation metric based on BM25 scores, we explain and identify re-ranker errors stemming from lexical dissimilarities. We also investigate different methods to improve LM re-ranker performance and find these methods mainly useful for NQ. Taken together, our work identifies and explains weaknesses of LM re-rankers and points to the need for more adversarial and realistic datasets for their evaluation.', 'abstract_zh': '语言模型（LM）重排序器用于增强检索生成（RAG）的检索结果。与像BM25这样的词汇匹配方法相比，LM重排序器成本更高，但被认为能更好地处理语义信息。为了理解LM重排序器是否总是如预期那样表现良好，我们在NQ、LitQA2和DRUID数据集上评估了6种不同的LM重排序器。结果显示，LM重排序器在DRUID上难以超越简单的BM25重排序器。利用基于BM25得分的新颖分离度量，我们解释并识别了由词汇差异引起的重排序器错误。我们还研究了改进LM重排序器性能的不同方法，并发现这些方法主要对NQ有效。总体而言，我们的工作指出了LM重排序器的弱点，并指出了需要更多的对抗性和更具现实性的数据集来评估它们。', 'title_zh': '语言模型重排序器受词汇相似性引导'}
{'arxiv_id': 'arXiv:2502.17028', 'title': 'Distributional Vision-Language Alignment by Cauchy-Schwarz Divergence', 'authors': 'Wenzhe Yin, Zehao Xiao, Pan Zhou, Shujian Yu, Jiayi Shen, Jan-Jakob Sonke, Efstratios Gavves', 'link': 'https://arxiv.org/abs/2502.17028', 'abstract': 'Multimodal alignment is crucial for various downstream tasks such as cross-modal generation and retrieval. Previous multimodal approaches like CLIP maximize the mutual information mainly by aligning pairwise samples across modalities while overlooking the distributional differences, leading to suboptimal alignment with modality gaps. In this paper, to overcome the limitation, we propose CS-Aligner, a novel and straightforward framework that performs distributional vision-language alignment by integrating Cauchy-Schwarz (CS) divergence with mutual information. In the proposed framework, we find that the CS divergence and mutual information serve complementary roles in multimodal alignment, capturing both the global distribution information of each modality and the pairwise semantic relationships, yielding tighter and more precise alignment. Moreover, CS-Aligher enables incorporating additional information from unpaired data and token-level representations, enhancing flexible and fine-grained alignment in practice. Experiments on text-to-image generation and cross-modality retrieval tasks demonstrate the effectiveness of our method on vision-language alignment.', 'abstract_zh': '多模态对齐对于跨模态生成和检索等下游任务至关重要。先前的多模态方法如CLIP主要通过在不同模态之间对齐成对样本来最大化互信息，而忽视了模态之间的分布差异，导致了模态差距下的子优对齐。本文为克服这一局限，提出了一种新颖且简单的CS-Aligner框架，该框架通过整合柯西-施瓦茨(CS)散度与互信息来执行分布性的视觉-语言对齐。在提出的框架中，我们发现CS散度和互信息在多模态对齐中发挥互补作用，既捕捉了每个模态的全局分布信息，又捕捉了成对的语义关系，从而实现了更紧密和精确的对齐。此外，CS-Aligner允许从未配对数据和令牌级表示中获取额外信息，增强了实际中的灵活和精细对齐。在文本到图像生成和跨模态检索任务上的实验表明，该方法在视觉-语言对齐方面是有效的。', 'title_zh': '基于柯西-施瓦茨散度的分布视听一致性对齐'}
{'arxiv_id': 'arXiv:2502.17026', 'title': 'Understanding the Uncertainty of LLM Explanations: A Perspective Based on Reasoning Topology', 'authors': 'Longchao Da, Xiaoou Liu, Jiaxin Dai, Lu Cheng, Yaqing Wang, Hua Wei', 'link': 'https://arxiv.org/abs/2502.17026', 'abstract': "Understanding the uncertainty in large language model (LLM) explanations is important for evaluating their faithfulness and reasoning consistency, and thus provides insights into the reliability of LLM's output regarding a question. In this work, we propose a novel framework that quantifies uncertainty in LLM explanations through a reasoning topology perspective. By designing a structural elicitation strategy, we guide the LLMs to frame the explanations of an answer into a graph topology. This process decomposes the explanations into the knowledge related sub-questions and topology-based reasoning structures, which allows us to quantify uncertainty not only at the semantic level but also from the reasoning path. It further brings convenience to assess knowledge redundancy and provide interpretable insights into the reasoning process. Our method offers a systematic way to interpret the LLM reasoning, analyze limitations, and provide guidance for enhancing robustness and faithfulness. This work pioneers the use of graph-structured uncertainty measurement in LLM explanations and demonstrates the potential of topology-based quantification.", 'abstract_zh': '理解大语言模型（LLM）解释中的不确定性对于评估其忠实性和推理一致性至关重要，从而为LLM输出的可靠性提供见解。在本文中，我们提出了一种新颖的框架，通过推理拓扑视角量化LLM解释中的不确定性。通过设计结构化启发策略，我们引导LLM将答案的解释框架化为图拓扑结构。这一过程将解释分解为与知识相关的子问题和基于拓扑的推理结构，这使得我们可以不仅从语义层面还可以从推理路径层面量化不确定性。这进一步方便了知识冗余的评估，并提供了推理过程的可解释见解。我们的方法提供了一种系统的方法来解释LLM推理、分析局限性，并为增强鲁棒性和忠实性提供指导。本文开创性地使用了图结构不确定性度量方法来分析LLM解释，并展示了基于拓扑的量化方法的潜在价值。', 'title_zh': '理解LLM解释的不确定性：基于推理拓扑的观点'}
{'arxiv_id': 'arXiv:2502.17022', 'title': 'Class-Dependent Perturbation Effects in Evaluating Time Series Attributions', 'authors': 'Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp', 'link': 'https://arxiv.org/abs/2502.17022', 'abstract': "As machine learning models become increasingly prevalent in time series applications, Explainable Artificial Intelligence (XAI) methods are essential for understanding their predictions. Within XAI, feature attribution methods aim to identify which input features contributed the most to a model's prediction, with their evaluation typically relying on perturbation-based metrics. Through empirical analysis across multiple datasets, model architectures, and perturbation strategies, we identify important class-dependent effects in these metrics: they show varying effectiveness across classes, achieving strong results for some while remaining less sensitive to others. In particular, we find that the most effective perturbation strategies often demonstrate the most pronounced class differences. Our analysis suggests that these effects arise from the learned biases of classifiers, indicating that perturbation-based evaluation may reflect specific model behaviors rather than intrinsic attribution quality. We propose an evaluation framework with a class-aware penalty term to help assess and account for these effects in evaluating feature attributions. Although our analysis focuses on time series classification, these class-dependent effects likely extend to other structured data domains where perturbation-based evaluation is common.", 'abstract_zh': '随着机器学习模型在时间序列应用中的日益普及，可解释人工智能（XAI）方法对于理解其预测结果变得至关重要。在XAI领域中，特征归因方法旨在识别哪些输入特征对模型预测贡献最大，其评估通常依赖于扰动基度量。通过对多个数据集、模型架构和扰动策略进行实证分析，我们发现这些度量中的重要类间效应：它们在不同类中表现出不同的有效性，对某些类效果显著，而对其他类则不够敏感。特别是，我们发现最有效的扰动策略往往表现出最明显的类间差异。我们的分析表明，这些效应源于分类器学习到的偏差，表明基于扰动的评估可能反映特定的模型行为而非内在的归因质量。我们提出了一种带有类感知惩罚项的评估框架，以帮助评估和考虑这些效应。尽管我们的分析集中在时间序列分类上，但这些类间效应很可能会扩展到其他常见的基于扰动评估的结构化数据领域。', 'title_zh': '类依存扰动效应在评估时间序列 Attribution 中的变化'}
{'arxiv_id': 'arXiv:2502.17020', 'title': 'Moving Past Single Metrics: Exploring Short-Text Clustering Across Multiple Resolutions', 'authors': 'Justin Miller, Tristram Alexander', 'link': 'https://arxiv.org/abs/2502.17020', 'abstract': "Cluster number is typically a parameter selected at the outset in clustering problems, and while impactful, the choice can often be difficult to justify. Inspired by bioinformatics, this study examines how the nature of clusters varies with cluster number, presenting a method for determining cluster robustness, and providing a systematic method for deciding on the cluster number. The study focuses specifically on short-text clustering, involving 30,000 political Twitter bios, where the sparse co-occurrence of words between texts makes finding meaningful clusters challenging. A metric of proportional stability is introduced to uncover the stability of specific clusters between cluster resolutions, and the results are visualised using Sankey diagrams to provide an interrogative tool for understanding the nature of the dataset. The visualisation provides an intuitive way to track cluster subdivision and reorganisation as cluster number increases, offering insights that static, single-resolution metrics cannot capture. The results show that instead of seeking a single 'optimal' solution, choosing a cluster number involves balancing informativeness and complexity.", 'abstract_zh': '基于生物信息学的聚类数量研究：探讨聚类性质随聚类数量变化的方法及其在短文本聚类中的应用', 'title_zh': '超越单一指标：探索短文本聚类在多种分辨率下的表现'}
{'arxiv_id': 'arXiv:2502.17019', 'title': 'Erwin: A Tree-based Hierarchical Transformer for Large-scale Physical Systems', 'authors': 'Maksim Zhdanov, Max Welling, Jan-Willem van de Meent', 'link': 'https://arxiv.org/abs/2502.17019', 'abstract': "Large-scale physical systems defined on irregular grids pose significant scalability challenges for deep learning methods, especially in the presence of long-range interactions and multi-scale coupling. Traditional approaches that compute all pairwise interactions, such as attention, become computationally prohibitive as they scale quadratically with the number of nodes. We present Erwin, a hierarchical transformer inspired by methods from computational many-body physics, which combines the efficiency of tree-based algorithms with the expressivity of attention mechanisms. Erwin employs ball tree partitioning to organize computation, which enables linear-time attention by processing nodes in parallel within local neighborhoods of fixed size. Through progressive coarsening and refinement of the ball tree structure, complemented by a novel cross-ball interaction mechanism, it captures both fine-grained local details and global features. We demonstrate Erwin's effectiveness across multiple domains, including cosmology, molecular dynamics, and particle fluid dynamics, where it consistently outperforms baseline methods both in accuracy and computational efficiency.", 'abstract_zh': '大型不规则网格上的物理系统为深度学习方法带来了显著的可扩展性挑战，特别是在存在长程相互作用和多尺度耦合的情况下。传统的计算所有成对相互作用的方法，如注意力机制，在节点数量增加时计算成本会呈 quadratically 增长。我们提出了 Erwin，这是一种受计算多体物理方法启发的分层变压器，它结合了基于树的算法的高效性和注意力机制的表达能力。Erwin 使用球树分区来组织计算，通过在固定大小的局部邻域内并行处理节点来实现线性时间的注意力机制。通过球树结构的逐步粗化和细化，并结合一种新颖的跨球体交互机制，它可以捕获细粒度的局部细节和全局特征。我们在包括宇宙学、分子动力学和粒子流体动力学等多个领域中展示了 Erwin 的有效性，结果表明它在准确性和计算效率上均优于基准方法。', 'title_zh': 'Erwin：一种基于树的分层变换模型，用于大规模物理系统'}
{'arxiv_id': 'arXiv:2502.17007', 'title': 'All You Need for Counterfactual Explainability Is Principled and Reliable Estimate of Aleatoric and Epistemic Uncertainty', 'authors': 'Kacper Sokol, Eyke Hüllermeier', 'link': 'https://arxiv.org/abs/2502.17007', 'abstract': 'This position paper argues that, to its detriment, transparency research overlooks many foundational concepts of artificial intelligence. Here, we focus on uncertainty quantification -- in the context of ante-hoc interpretability and counterfactual explainability -- showing how its adoption could address key challenges in the field. First, we posit that uncertainty and ante-hoc interpretability offer complementary views of the same underlying idea; second, we assert that uncertainty provides a principled unifying framework for counterfactual explainability. Consequently, inherently transparent models can benefit from human-centred explanatory insights -- like counterfactuals -- which are otherwise missing. At a higher level, integrating artificial intelligence fundamentals into transparency research promises to yield more reliable, robust and understandable predictive models.', 'abstract_zh': '这篇立场论文认为，透明度研究忽略了人工智能许多基础概念，这对透明度研究造成了损害。本文关注先验解释和反事实可解释性中的不确定性量化，展示其采用如何解决领域中的关键问题。首先，本文提出不确定性与先验解释提供了同一基本概念的不同视角；其次，本文断言不确定性为反事实可解释性提供了一个原理上的统一框架。因此，固有的透明模型能够从以人为中心的解释洞察（如反事实解释）中受益，而这些洞察在其他情况下是缺失的。在更高层次上，将人工智能的基本原理融入透明度研究有望产生更可靠、更 robust 和更易理解的预测模型。', 'title_zh': '你需要的一切仅为原理上可靠估计 aleatoric 和 epistemic 不确定性以实现反事实解释性。'}
{'arxiv_id': 'arXiv:2502.17003', 'title': 'Improving the Transferability of Adversarial Examples by Inverse Knowledge Distillation', 'authors': 'Wenyuan Wu, Zheng Liu, Yong Chen, Chao Su, Dezhong Peng, Xu Wang', 'link': 'https://arxiv.org/abs/2502.17003', 'abstract': 'In recent years, the rapid development of deep neural networks has brought increased attention to the security and robustness of these models. While existing adversarial attack algorithms have demonstrated success in improving adversarial transferability, their performance remains suboptimal due to a lack of consideration for the discrepancies between target and source models. To address this limitation, we propose a novel method, Inverse Knowledge Distillation (IKD), designed to enhance adversarial transferability effectively. IKD introduces a distillation-inspired loss function that seamlessly integrates with gradient-based attack methods, promoting diversity in attack gradients and mitigating overfitting to specific model architectures. By diversifying gradients, IKD enables the generation of adversarial samples with superior generalization capabilities across different models, significantly enhancing their effectiveness in black-box attack scenarios. Extensive experiments on the ImageNet dataset validate the effectiveness of our approach, demonstrating substantial improvements in the transferability and attack success rates of adversarial samples across a wide range of models.', 'abstract_zh': '近年来，深度神经网络的快速发展引起了对其安全性和鲁棒性的广泛关注。尽管现有的对抗攻击算法在提高对抗迁徙性方面取得了成功，但由于缺乏对目标模型和源模型差异的考虑，其性能仍不理想。为解决这一局限，我们提出了一种新颖的方法——逆向知识蒸馏（IKD），旨在有效增强对抗迁徙性。IKD 引入了一种借鉴知识蒸馏思想的损失函数，能够无缝集成到基于梯度的攻击方法中，促进攻击梯度的多样化并减轻对特定模型架构的过度拟合。通过多样化梯度，IKD 使生成的对抗样本具有在不同模型上更优的一般化能力，显著增强了其在黑盒攻击场景中的效果。在 ImageNet 数据集上的广泛实验验证了我们方法的有效性，展示了在多种模型上对抗样本的迁徙性和攻击成功率的显著提升。', 'title_zh': '通过逆向知识蒸馏提高对抗样本的迁移性'}
{'arxiv_id': 'arXiv:2502.16994', 'title': 'FADE: Why Bad Descriptions Happen to Good Features', 'authors': 'Bruno Puri, Aakriti Jain, Elena Golimblevskaia, Patrick Kahardipraja, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin', 'link': 'https://arxiv.org/abs/2502.16994', 'abstract': 'Recent advances in mechanistic interpretability have highlighted the potential of automating interpretability pipelines in analyzing the latent representations within LLMs. While they may enhance our understanding of internal mechanisms, the field lacks standardized evaluation methods for assessing the validity of discovered features. We attempt to bridge this gap by introducing FADE: Feature Alignment to Description Evaluation, a scalable model-agnostic framework for evaluating feature-description alignment. FADE evaluates alignment across four key metrics - Clarity, Responsiveness, Purity, and Faithfulness - and systematically quantifies the causes for the misalignment of feature and their description. We apply FADE to analyze existing open-source feature descriptions, and assess key components of automated interpretability pipelines, aiming to enhance the quality of descriptions. Our findings highlight fundamental challenges in generating feature descriptions, particularly for SAEs as compared to MLP neurons, providing insights into the limitations and future directions of automated interpretability. We release FADE as an open-source package at: this https URL.', 'abstract_zh': '近期在机制可解释性方面的进展突显了在分析大规模语言模型内部潜在表示时自动化解释管道的潜力。尽管这些方法可能增强我们对内部机制的理解，但该领域缺乏标准化评估方法来评估发现特征的有效性。我们通过引入FADE（Feature Alignment to Description Evaluation）框架来弥补这一差距，FADE是一种可扩展的、模型无关的评估框架，用于评估特征描述的一致性。FADE在四个关键指标——清晰度、响应性、纯净度和忠实度——上评估一致性，并系统地量化特征与描述之间不一致性的原因。我们将FADE应用于分析现有的开源特征描述，并评估自动解释管道的关键组件，旨在提高描述的质量。研究结果凸显了生成特征描述的基本挑战，尤其是在与MLP神经元相比的情况下，SAEs尤其如此，提供了关于自动化解释的限制和未来方向的见解。我们已将FADE作为一个开源包发布于此：this https URL。', 'title_zh': 'FADE: 为何优质特征会出现糟糕的描述'}
{'arxiv_id': 'arXiv:2502.16987', 'title': 'Hotter and Colder: A New Approach to Annotating Sentiment, Emotions, and Bias in Icelandic Blog Comments', 'authors': 'Steinunn Rut Friðriksdóttir, Dan Saattrup Nielsen, Hafsteinn Einarsson', 'link': 'https://arxiv.org/abs/2502.16987', 'abstract': 'This paper presents Hotter and Colder, a dataset designed to analyze various types of online behavior in Icelandic blog comments. Building on previous work, we used GPT-4o mini to annotate approximately 800,000 comments for 25 tasks, including sentiment analysis, emotion detection, hate speech, and group generalizations. Each comment was automatically labeled on a 5-point Likert scale. In a second annotation stage, comments with high or low probabilities of containing each examined behavior were subjected to manual revision. By leveraging crowdworkers to refine these automatically labeled comments, we ensure the quality and accuracy of our dataset resulting in 12,232 uniquely annotated comments and 19,301 annotations. Hotter and Colder provides an essential resource for advancing research in content moderation and automatically detectiong harmful online behaviors in Icelandic.', 'abstract_zh': 'Hotter and Colder：一个用于分析冰岛博客评论中各种在线行为的数据集', 'title_zh': '更热更冷：一种注释冰岛博客评论中情感、情绪和偏见的新方法'}
{'arxiv_id': 'arXiv:2502.16982', 'title': 'Muon is Scalable for LLM Training', 'authors': 'Jingyuan Liu, Jianlin Su, Xingcheng Yao, Zhejun Jiang, Guokun Lai, Yulun Du, Yidao Qin, Weixin Xu, Enzhe Lu, Junjie Yan, Yanru Chen, Huabin Zheng, Yibo Liu, Shaowei Liu, Bohong Yin, Weiran He, Han Zhu, Yuzhi Wang, Jianzhou Wang, Mengnan Dong, Zheng Zhang, Yongsheng Kang, Hao Zhang, Xinran Xu, Yutao Zhang, Yuxin Wu, Xinyu Zhou, Zhilin Yang', 'link': 'https://arxiv.org/abs/2502.16982', 'abstract': 'Recently, the Muon optimizer based on matrix orthogonalization has demonstrated strong results in training small-scale language models, but the scalability to larger models has not been proven. We identify two crucial techniques for scaling up Muon: (1) adding weight decay and (2) carefully adjusting the per-parameter update scale. These techniques allow Muon to work out-of-the-box on large-scale training without the need of hyper-parameter tuning. Scaling law experiments indicate that Muon achieves $\\sim\\!2\\times$ computational efficiency compared to AdamW with compute optimal training.\nBased on these improvements, we introduce Moonlight, a 3B/16B-parameter Mixture-of-Expert (MoE) model trained with 5.7T tokens using Muon. Our model improves the current Pareto frontier, achieving better performance with much fewer training FLOPs compared to prior models.\nWe open-source our distributed Muon implementation that is memory optimal and communication efficient. We also release the pretrained, instruction-tuned, and intermediate checkpoints to support future research.', 'abstract_zh': 'Muon优化器基于矩阵正交化在训练小型语言模型方面取得了显著成果，但其扩展到大型模型的效果尚未得到证明。我们识别出两种关键的扩展技术：(1) 添加权重衰减，(2) 细致调整每个参数的更新规模。这些技术使得Muon可以在大规模训练中无需超参数调优即可使用。缩放律实验显示，Muon相比AdamW在计算效率上约提高了2倍，同时在使用相同计算量的情况下实现了最佳训练效果。\n\n基于这些改进，我们介绍了使用Muon训练的Moonlight模型，该模型包含3B/16B参数的Mixture-of-Experts（MoE）模型，并使用5.7T令牌进行训练。我们的模型在训练FLOPs显著减少的情况下，提高了当前的Pareto前沿性能。\n\n我们开源了内存最优且通信高效的分布式Muon实现，并发布了预训练、指令微调及中间检查点，以支持未来研究。', 'title_zh': 'Muон适用于大规模语言模型训练'}
{'arxiv_id': 'arXiv:2502.16977', 'title': 'Convergence of Shallow ReLU Networks on Weakly Interacting Data', 'authors': 'Léo Dana, Francis Bach, Loucas Pillaud-Vivien', 'link': 'https://arxiv.org/abs/2502.16977', 'abstract': 'We analyse the convergence of one-hidden-layer ReLU networks trained by gradient flow on $n$ data points. Our main contribution leverages the high dimensionality of the ambient space, which implies low correlation of the input samples, to demonstrate that a network with width of order $\\log(n)$ neurons suffices for global convergence with high probability. Our analysis uses a Polyak-Łojasiewicz viewpoint along the gradient-flow trajectory, which provides an exponential rate of convergence of $\\frac{1}{n}$. When the data are exactly orthogonal, we give further refined characterizations of the convergence speed, proving its asymptotic behavior lies between the orders $\\frac{1}{n}$ and $\\frac{1}{\\sqrt{n}}$, and exhibiting a phase-transition phenomenon in the convergence rate, during which it evolves from the lower bound to the upper, and in a relative time of order $\\frac{1}{\\log(n)}$.', 'abstract_zh': '我们分析了一隐藏层ReLU网络在梯度流训练下对$n$个数据点的学习收敛性。我们的主要贡献利用了环境空间的高维性，这导致输入样本低相关性，证明了宽度为$\\log(n)$数量级的神经网络足以实现高概率的全局收敛。我们的分析采用了梯度流轨迹上的Polyak-Łojasiewicz观点，提供了指数级的收敛率$\\frac{1}{n}$。当数据恰好正交时，我们进一步细化了收敛速度的表征，证明其渐近行为位于$\\frac{1}{n}$和$\\frac{1}{\\sqrt{n}}$之间，并展示了收敛速率的相变现象，在该现象中，收敛速率从下界演变成上界，且这一转变发生在相对时间为$\\frac{1}{\\log(n)}$的时间尺度上。', 'title_zh': '浅层ReLU网络在弱交互数据上的收敛性'}
{'arxiv_id': 'arXiv:2502.16971', 'title': 'LongSafety: Evaluating Long-Context Safety of Large Language Models', 'authors': 'Yida Lu, Jiale Cheng, Zhexin Zhang, Shiyao Cui, Cunxiang Wang, Xiaotao Gu, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang', 'link': 'https://arxiv.org/abs/2502.16971', 'abstract': 'As Large Language Models (LLMs) continue to advance in understanding and generating long sequences, new safety concerns have been introduced through the long context. However, the safety of LLMs in long-context tasks remains under-explored, leaving a significant gap in both evaluation and improvement of their safety. To address this, we introduce LongSafety, the first comprehensive benchmark specifically designed to evaluate LLM safety in open-ended long-context tasks. LongSafety encompasses 7 categories of safety issues and 6 user-oriented long-context tasks, with a total of 1,543 test cases, averaging 5,424 words per context. Our evaluation towards 16 representative LLMs reveals significant safety vulnerabilities, with most models achieving safety rates below 55%. Our findings also indicate that strong safety performance in short-context scenarios does not necessarily correlate with safety in long-context tasks, emphasizing the unique challenges and urgency of improving long-context safety. Moreover, through extensive analysis, we identify challenging safety issues and task types for long-context models. Furthermore, we find that relevant context and extended input sequences can exacerbate safety risks in long-context scenarios, highlighting the critical need for ongoing attention to long-context safety challenges. Our code and data are available at this https URL.', 'abstract_zh': '随着大型语言模型（LLMs）在理解和生成长序列方面的不断进步，长上下文引入了新的安全问题。然而，LLMs在长上下文任务中的安全性仍然研究不足，留下了评估和改进其安全性的重要空白。为了解决这一问题，我们引入了LongSafety——第一个专门用于评估LLMs在开放式长上下文任务中安全性的全面基准。LongSafety涵盖了7类安全问题和6种用户导向的长上下文任务，共有1,543个测试案例，平均每个上下文包含5,424个单词。我们的评估结果显示，大多数模型在安全性方面的表现低于55%。此外，我们的研究还表明，短上下文中的强大安全性能并不必然预示长上下文中的安全性，突显了改进长上下文安全性的重要性和紧迫性。通过对长上下文模型进行深入分析，我们识别出了具有挑战性的安全问题和任务类型。此外，我们发现相关上下文和扩展的输入序列会增加长上下文场景中的安全风险，强调了持续关注长上下文安全挑战的重要性。我们的代码和数据可在以下网址获取。', 'title_zh': '长文境安全评估：大型语言模型的安全性评价'}
{'arxiv_id': 'arXiv:2502.16961', 'title': 'UrduLLaMA 1.0: Dataset Curation, Preprocessing, and Evaluation in Low-Resource Settings', 'authors': 'Layba Fiaz, Munief Hassan Tahir, Sana Shams, Sarmad Hussain', 'link': 'https://arxiv.org/abs/2502.16961', 'abstract': 'Multilingual Large Language Models (LLMs) often provide suboptimal performance on low-resource languages like Urdu. This paper introduces UrduLLaMA 1.0, a model derived from the open-source Llama-3.1-8B-Instruct architecture and continually pre-trained on 128 million Urdu tokens, capturing the rich diversity of the language. To enhance instruction-following and translation capabilities, we leverage Low-Rank Adaptation (LoRA) to fine tune the model on 41,000 Urdu instructions and approximately 50,000 English-Urdu translation pairs. Evaluation across three machine translation datasets demonstrates significant performance improvements compared to state-of-the-art (SOTA) models, establishing a new benchmark for Urdu LLMs. These findings underscore the potential of targeted adaptation strategies with limited data and computational resources to address the unique challenges of low-resource languages.', 'abstract_zh': '多语言大型语言模型（LLMs）在低资源语言如乌尔都语上 often 提供 suboptimal 性能。本文介绍了乌尔都LLaMA 1.0，该模型源自开放源代码的Llama-3.1-8B-Instruct架构，并在1.28亿个乌尔都语Token上进行了持续预训练，捕捉到了该语言丰富的多样性。为了增强指令遵循和翻译能力，我们利用低秩适应（LoRA）对模型进行了微调，使用了4.1万条乌尔都语指令和约5万条英-乌尔都双语翻译对。在三个机器翻译数据集上的评估表明，与当前最佳（SOTA）模型相比，其性能得到了显着提升，并建立了乌尔都LLM的新基准。这些发现强调了在有限数据和计算资源条件下，针对特定适应策略的潜力，以应对低资源语言的独特挑战。', 'title_zh': 'UrduLLaMA 1.0：低资源环境下的数据整合、预处理与评估'}
{'arxiv_id': 'arXiv:2502.16944', 'title': 'Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance', 'authors': 'Chenghua Huang, Lu Wang, Fangkai Yang, Pu Zhao, Zhixu Li, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang', 'link': 'https://arxiv.org/abs/2502.16944', 'abstract': 'Proximal Policy Optimization (PPO)-based Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human preferences. It requires joint training of an actor and critic with a pretrained, fixed reward model for guidance. This approach increases computational complexity and instability due to actor-critic interdependence. Additionally, PPO lacks access to true environment rewards in LLM tasks, limiting its adaptability. Under such conditions, pretraining a value model or a reward model becomes equivalent, as both provide fixed supervisory signals without new ground-truth feedback. To address these issues, we propose \\textbf{Decoupled Value Policy Optimization (DVPO)}, a lean framework that replaces traditional reward modeling with a pretrained \\emph{global value model (GVM)}. The GVM is conditioned on policy trajectories and predicts token-level return-to-go estimates. By decoupling value model from policy training (via frozen GVM-driven RL objectives), DVPO eliminates actor-critic interdependence, reducing GPU memory usage by 40\\% and training time by 35\\% compared to conventional RLHF. Experiments across benchmarks show DVPO outperforms efficient RLHF methods (e.g., DPO) while matching state-of-the-art PPO in performance.', 'abstract_zh': '基于 proximal policy optimization (PPO) 的人类反馈强化学习（RLHF）对于使大规模语言模型（LLMs）与人类偏好保持一致至关重要。它需要对一个演员和一个评论家进行联合训练，以预先训练的固定奖励模型为指导。这种方法由于演员和评论家之间相互依赖性而增加了计算复杂性和不稳定性。此外，PPO 在大型语言模型任务中无法访问真正的环境奖励，限制了其适应性。在这种情况下，预训练价值模型或奖励模型变得等效，因为两者都提供固定的监督信号而无需新的地面真相反馈。为了应对这些问题，我们提出了一种名为 \\textbf{解耦价值策略优化（DVPO）} 的轻量级框架，该框架用预先训练的全局价值模型（GVM）替代传统的奖励建模。GVM 以策略轨迹为条件，预测令牌级的未来回报估计。通过通过冻结 GVM 驱动的 RL 目标来解耦价值模型与策略训练，DVPO 消除了演员和评论家之间的相互依赖性，与传统 RLHF 相比，减少了 40% 的 GPU 内存使用并缩短了 35% 的训练时间。实验表明，DVPO 在基准测试中的性能优于高效的 RLHF 方法（例如 DPO），同时在性能上与最先进的 PPO 相当。', 'title_zh': '精简高效：解耦价值策略优化与全局价值引导'}
{'arxiv_id': 'arXiv:2502.16940', 'title': 'Reasoning Does Not Necessarily Improve Role-Playing Ability', 'authors': 'Xiachong Feng, Longxu Dou, Lingpeng Kong', 'link': 'https://arxiv.org/abs/2502.16940', 'abstract': 'The application of role-playing large language models (LLMs) is rapidly expanding in both academic and commercial domains, driving an increasing demand for high-precision role-playing models. Simultaneously, the rapid advancement of reasoning techniques has continuously pushed the performance boundaries of LLMs. This intersection of practical role-playing demands and evolving reasoning capabilities raises an important research question: "Can reasoning techniques enhance the role-playing capabilities of LLMs?" To address this, we conduct a comprehensive study using 6 role-playing benchmarks, 24 LLMs, and 3 distinct role-playing strategies, comparing the effectiveness of direct zero-shot role-playing, role-playing with Chain-of-Thought (CoT), and role-playing using reasoning-optimized LLMs. Our findings reveal that CoT may reduce role-playing performance, reasoning-optimized LLMs are unsuitable for role-playing, reasoning ability disrupts the role-playing scaling law, large models still lack proficiency in advanced role-playing, and Chinese role-playing performance surpasses English role-playing performance. Furthermore, based on extensive experimental results, we propose two promising future research directions: Role-aware CoT for improving role-playing LLMs and Reinforcement Learning for role-playing LLMs, aiming to enhance the adaptability, consistency, and effectiveness of role-playing LLMs for both research and real-world applications.', 'abstract_zh': '角色扮演大语言模型的应用正迅速扩展到学术和商业领域，推动了对高精度角色扮演模型的需求。同时，推理技术的快速发展不断推动大语言模型性能的边界。这种实践角色扮演需求与不断演化的推理能力的交汇引发了一个重要研究问题：“推理技术能否增强大语言模型的角色扮演能力？”为回答这一问题，我们进行了全面研究，使用了6个角色扮演基准、24个大语言模型和3种不同的角色扮演策略，比较了直接零样本角色扮演、带有链式思考（CoT）的角色扮演以及使用推理优化的大语言模型的角色扮演效果。研究发现CoT可能降低角色扮演性能、推理优化的大语言模型不适合角色扮演、推理能力破坏了角色扮演的规模法则、大模型在高级角色扮演方面仍缺乏熟练度、中文角色扮演性能优于英文角色扮演性能。此外，基于广泛的实验结果，我们提出了两个有前景的未来研究方向：角色感知链式思考以改进角色扮演大语言模型和强化学习以改进角色扮演大语言模型，旨在增强角色扮演大语言模型在研究和实际应用中的适应性、一致性和有效性。', 'title_zh': '推理能力未必能提升角色扮演能力'}
{'arxiv_id': 'arXiv:2502.16936', 'title': 'Supervised contrastive learning from weakly-labeled audio segments for musical version matching', 'authors': 'Joan Serrà, R. Oguz Araz, Dmitry Bogdanov, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2502.16936', 'abstract': 'Detecting musical versions (different renditions of the same piece) is a challenging task with important applications. Because of the ground truth nature, existing approaches match musical versions at the track level (e.g., whole song). However, most applications require to match them at the segment level (e.g., 20s chunks). In addition, existing approaches resort to classification and triplet losses, disregarding more recent losses that could bring meaningful improvements. In this paper, we propose a method to learn from weakly annotated segments, together with a contrastive loss variant that outperforms well-studied alternatives. The former is based on pairwise segment distance reductions, while the latter modifies an existing loss following decoupling, hyper-parameter, and geometric considerations. With these two elements, we do not only achieve state-of-the-art results in the standard track-level evaluation, but we also obtain a breakthrough performance in a segment-level evaluation. We believe that, due to the generality of the challenges addressed here, the proposed methods may find utility in domains beyond audio or musical version matching.', 'abstract_zh': '检测音乐版本（同一作品的不同演绎）是一个具有重要应用的挑战性任务。', 'title_zh': '弱标记音频片段的监督对比学习及其在音乐版本匹配中的应用'}
{'arxiv_id': 'arXiv:2502.16927', 'title': 'BigMac: A Communication-Efficient Mixture-of-Experts Model Structure for Fast Training and Inference', 'authors': 'Zewen Jin, Shengnan Wang, Jiaan Zhu, Hongrui Zhan, Youhui Bai, Lin Zhang, Zhenyu Ming, Cheng Li', 'link': 'https://arxiv.org/abs/2502.16927', 'abstract': 'The Mixture-of-Experts (MoE) structure scales the Transformer-based large language models (LLMs) and improves their performance with only the sub-linear increase in computation resources. Recently, a fine-grained DeepSeekMoE structure is proposed, which can further improve the computing efficiency of MoE without performance degradation. However, the All-to-All communication introduced by MoE has become a bottleneck, especially for the fine-grained structure, which typically involves and activates more experts, hence contributing to heavier communication overhead.\nIn this paper, we propose a novel MoE structure named BigMac, which is also fine-grained but with high communication efficiency. The innovation of BigMac is mainly due to that we abandon the \\textbf{c}ommunicate-\\textbf{d}escend-\\textbf{a}scend-\\textbf{c}ommunicate (CDAC) manner used by fine-grained MoE, which leads to the All-to-All communication always taking place at the highest dimension. Instead, BigMac designs an efficient \\textbf{d}escend-\\textbf{c}ommunicate-\\textbf{c}ommunicate-\\textbf{a}scend (DCCA) manner. Specifically, we add a descending and ascending projection at the entrance and exit of the expert, respectively, which enables the communication to perform at a very low dimension. Furthermore, to adapt to DCCA, we re-design the structure of small experts, ensuring that the expert in BigMac has enough complexity to address tokens. Experimental results show that BigMac achieves comparable or even better model quality than fine-grained MoEs with the same number of experts and a similar number of total parameters. Equally importantly, BigMac reduces the end-to-end latency by up to 3.09$\\times$ for training and increases the throughput by up to 3.11$\\times$ for inference on state-of-the-art AI computing frameworks including Megatron, Tutel, and DeepSpeed-Inference.', 'abstract_zh': '一种高通信效率的细粒度Mixture-of-Experts结构：BigMac', 'title_zh': 'BigMac：一种通信高效的专家混合模型结构，实现快速训练与推理'}
{'arxiv_id': 'arXiv:2502.16923', 'title': 'A Systematic Survey of Automatic Prompt Optimization Techniques', 'authors': 'Kiran Ramnath, Kang Zhou, Sheng Guan, Soumya Smruti Mishra, Xuan Qi, Zhengyuan Shen, Shuai Wang, Sangmin Woo, Sullam Jeoung, Yawei Wang, Haozhu Wang, Han Ding, Yuzhe Lu, Zhichao Xu, Yun Zhou, Balasubramaniam Srinivasan, Qiaojing Yan, Yueyan Chen, Haibo Ding, Panpan Xu, Lin Lee Cheong', 'link': 'https://arxiv.org/abs/2502.16923', 'abstract': 'Since the advent of large language models (LLMs), prompt engineering has been a crucial step for eliciting desired responses for various Natural Language Processing (NLP) tasks. However, prompt engineering remains an impediment for end users due to rapid advances in models, tasks, and associated best practices. To mitigate this, Automatic Prompt Optimization (APO) techniques have recently emerged that use various automated techniques to help improve the performance of LLMs on various tasks. In this paper, we present a comprehensive survey summarizing the current progress and remaining challenges in this field. We provide a formal definition of APO, a 5-part unifying framework, and then proceed to rigorously categorize all relevant works based on their salient features therein. We hope to spur further research guided by our framework.', 'abstract_zh': '自大型语言模型（LLM）问世以来，提示工程一直是各种自然语言处理（NLP）任务中 eliciting 所需响应的关键步骤。然而，由于模型、任务及相关最佳实践的迅速发展，提示工程仍然给最终用户带来阻碍。为缓解这一问题，最近出现了自动提示优化（APO）技术，这些技术使用各种自动化方法来帮助提高LLM在各种任务上的性能。本文综述了该领域的当前进展和剩余挑战，提供了一种形式化的APO定义，一个统一的五部分框架，并基于其中的关键特征对所有相关工作进行了严格的分类。我们希望以此框架指导进一步的研究。', 'title_zh': '自动提示优化技术系统的综述'}
{'arxiv_id': 'arXiv:2502.16914', 'title': 'ENACT-Heart -- ENsemble-based Assessment Using CNN and Transformer on Heart Sounds', 'authors': 'Jiho Han, Adnan Shaout', 'link': 'https://arxiv.org/abs/2502.16914', 'abstract': 'This study explores the application of Vision Transformer (ViT) principles in audio analysis, specifically focusing on heart sounds. This paper introduces ENACT-Heart - a novel ensemble approach that leverages the complementary strengths of Convolutional Neural Networks (CNN) and ViT through a Mixture of Experts (MoE) framework, achieving a remarkable classification accuracy of 97.52%. This outperforms the individual contributions of ViT (93.88%) and CNN (95.45%), demonstrating the potential for enhanced diagnostic accuracy in cardiovascular health monitoring. These results demonstrate the potential of ensemble methods in enhancing classification performance for cardiovascular health monitoring and diagnosis.', 'abstract_zh': '本研究探讨了视觉变换器（ViT）原理在音频分析中的应用，特别聚焦于心音分析。本文介绍了ENACT-Heart——一种新颖的集成方法，该方法通过专家混合（MoE）框架利用卷积神经网络（CNN）和ViT的互补优势，实现了97.52%的显著分类准确率，优于单独的ViT（93.88%）和CNN（95.45%），展示了在心血管健康监测中增强诊断准确性的潜力。这些结果表明，集成方法在提高心血管健康监测和诊断的分类性能方面的潜在价值。', 'title_zh': 'ENACT-Heart —— 基于集合评估的CNN和变压器在心音分析中的应用'}
{'arxiv_id': 'arXiv:2502.16912', 'title': 'When Can We Solve the Weighted Low Rank Approximation Problem in Truly Subquadratic Time?', 'authors': 'Chenyang Li, Yingyu Liang, Zhenmei Shi, Zhao Song', 'link': 'https://arxiv.org/abs/2502.16912', 'abstract': 'The weighted low-rank approximation problem is a fundamental numerical linear algebra problem and has many applications in machine learning. Given a $n \\times n$ weight matrix $W$ and a $n \\times n$ matrix $A$, the goal is to find two low-rank matrices $U, V \\in \\mathbb{R}^{n \\times k}$ such that the cost of $\\| W \\circ (U V^\\top - A) \\|_F^2$ is minimized. Previous work has to pay $\\Omega(n^2)$ time when matrices $A$ and $W$ are dense, e.g., having $\\Omega(n^2)$ non-zero entries. In this work, we show that there is a certain regime, even if $A$ and $W$ are dense, we can still hope to solve the weighted low-rank approximation problem in almost linear $n^{1+o(1)}$ time.', 'abstract_zh': '加权低秩逼近问题是数值线性代数中的一个基础问题，在机器学习中有着广泛的应用。给定一个$n \\times n$权重矩阵$W$和一个$n \\times n$矩阵$A$，目标是找到两个低秩矩阵$U, V \\in \\mathbb{R}^{n \\times k}$，使得$\\| W \\circ (U V^\\top - A) \\|_F^2$的成本最小化。前人的工作在矩阵$A$和$W$稠密（例如，具有 $\\Omega(n^2)$ 个非零元素）的情况下需要花费$\\Omega(n^2)$的时间。在本文中，我们展示了即使在$A$和$W$稠密的情况下，我们仍然有可能在接近线性的$n^{1+o(1)}$时间内解决加权低秩逼近问题。', 'title_zh': '在什么情况下，加权低秩近似问题可以在真正亚二次时间内求解？'}
{'arxiv_id': 'arXiv:2502.16907', 'title': 'MambaFlow: A Novel and Flow-guided State Space Model for Scene Flow Estimation', 'authors': 'Jiehao Luo, Jintao Cheng, Xiaoyu Tang, Qingwen Zhang, Bohuan Xue, Rui Fan', 'link': 'https://arxiv.org/abs/2502.16907', 'abstract': "Scene flow estimation aims to predict 3D motion from consecutive point cloud frames, which is of great interest in autonomous driving field. Existing methods face challenges such as insufficient spatio-temporal modeling and inherent loss of fine-grained feature during voxelization. However, the success of Mamba, a representative state space model (SSM) that enables global modeling with linear complexity, provides a promising solution. In this paper, we propose MambaFlow, a novel scene flow estimation network with a mamba-based decoder. It enables deep interaction and coupling of spatio-temporal features using a well-designed backbone. Innovatively, we steer the global attention modeling of voxel-based features with point offset information using an efficient Mamba-based decoder, learning voxel-to-point patterns that are used to devoxelize shared voxel representations into point-wise features. To further enhance the model's generalization capabilities across diverse scenarios, we propose a novel scene-adaptive loss function that automatically adapts to different motion this http URL experiments on the Argoverse 2 benchmark demonstrate that MambaFlow achieves state-of-the-art performance with real-time inference speed among existing works, enabling accurate flow estimation in real-world urban scenarios. The code is available at this https URL.", 'abstract_zh': '场景流估计旨在从连续点云帧中预测3D运动，这是自主驾驶领域的热点问题。现有方法面临时空建模不足和体元化过程中固有的细粒度特征损失等挑战。然而，Mamba的成功，这是一种允许全局建模且具有线性复杂度的代表性状态空间模型（SSM），提供了前景解决方案。在本文中，我们提出了一种基于Mamba解码器的新型场景流估计网络MambaFlow，它通过精心设计的骨干网络实现了时空特征的深度交互和耦合。创新地，我们使用高效的Mamba基于解码器以点偏移信息引导体元特征的全局注意力建模，学习体元到点的模式，将其用于将共享体元表示去体元化为点 wise特征。为了进一步增强模型在不同场景中的泛化能力，我们提出了一种新的场景自适应损失函数，该函数能够自动适应不同的运动模式。在Argoverse 2基准测试上的实验表明，MambaFlow在现有工作中实现了实时推理速度下的最佳性能，能够在现实世界的城市场景中实现准确的流估计。代码可在此处获取。', 'title_zh': 'MambaFlow：一种新型的流引导场景流估计状态空间模型'}
{'arxiv_id': 'arXiv:2502.16902', 'title': 'Culture-TRIP: Culturally-Aware Text-to-Image Generation with Iterative Prompt Refinment', 'authors': 'Suchae Jeong, Inseong Choi, Youngsik Yun, Jihie Kim', 'link': 'https://arxiv.org/abs/2502.16902', 'abstract': "Text-to-Image models, including Stable Diffusion, have significantly improved in generating images that are highly semantically aligned with the given prompts. However, existing models may fail to produce appropriate images for the cultural concepts or objects that are not well known or underrepresented in western cultures, such as `hangari' (Korean utensil). In this paper, we propose a novel approach, Culturally-Aware Text-to-Image Generation with Iterative Prompt Refinement (Culture-TRIP), which refines the prompt in order to improve the alignment of the image with such culture nouns in text-to-image models. Our approach (1) retrieves cultural contexts and visual details related to the culture nouns in the prompt and (2) iteratively refines and evaluates the prompt based on a set of cultural criteria and large language models. The refinement process utilizes the information retrieved from Wikipedia and the Web. Our user survey, conducted with 66 participants from eight different countries demonstrates that our proposed approach enhances the alignment between the images and the prompts. In particular, C-TRIP demonstrates improved alignment between the generated images and underrepresented culture nouns. Resource can be found at this https URL.", 'abstract_zh': '基于迭代提示精炼的文化意识文本到图像生成（Culture-TRIP）', 'title_zh': '文化TRIP：具有迭代提示精炼的文化意识文本到图像生成'}
{'arxiv_id': 'arXiv:2502.16901', 'title': 'Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in Multilingual LLMs', 'authors': 'Himanshu Beniwal, Sailesh Panda, Mayank Singh', 'link': 'https://arxiv.org/abs/2502.16901', 'abstract': 'We explore Cross-lingual Backdoor ATtacks (X-BAT) in multilingual Large Language Models (mLLMs), revealing how backdoors inserted in one language can automatically transfer to others through shared embedding spaces. Using toxicity classification as a case study, we demonstrate that attackers can compromise multilingual systems by poisoning data in a single language, with rare tokens serving as specific effective triggers. Our findings expose a critical vulnerability in the fundamental architecture that enables cross-lingual transfer in these models. Our code and data are publicly available at this https URL.', 'abstract_zh': '多语言大型语言模型中的跨语言后门攻击（X-BAT）探究：揭示一种语言中植入后门如何通过共享嵌入空间自动转移到其他语言中的机制。以毒性分类为例，我们展示攻击者可以通过污染单一语言的数据来破坏多语言系统，其中稀有令牌作为具体的有效触发器。我们的发现揭示了这些模型中实现跨语言转移的基本架构中存在的关键漏洞。我们的代码和数据已在此处公开：this https URL。', 'title_zh': 'Char-mander 使用 mBackdoor！多语言LLM中的跨语言后门攻击研究'}
{'arxiv_id': 'arXiv:2502.16896', 'title': 'Zero-shot Load Forecasting for Integrated Energy Systems: A Large Language Model-based Framework with Multi-task Learning', 'authors': 'Jiaheng Li, Donghe Li, Ye Yang, Huan Xi, Yu Xiao, Li Sun, Dou An, Qingyu Yang', 'link': 'https://arxiv.org/abs/2502.16896', 'abstract': "The growing penetration of renewable energy sources in power systems has increased the complexity and uncertainty of load forecasting, especially for integrated energy systems with multiple energy carriers. Traditional forecasting methods heavily rely on historical data and exhibit limited transferability across different scenarios, posing significant challenges for emerging applications in smart grids and energy internet. This paper proposes the TSLLM-Load Forecasting Mechanism, a novel zero-shot load forecasting framework based on large language models (LLMs) to address these challenges. The framework consists of three key components: a data preprocessing module that handles multi-source energy load data, a time series prompt generation module that bridges the semantic gap between energy data and LLMs through multi-task learning and similarity alignment, and a prediction module that leverages pre-trained LLMs for accurate forecasting. The framework's effectiveness was validated on a real-world dataset comprising load profiles from 20 Australian solar-powered households, demonstrating superior performance in both conventional and zero-shot scenarios. In conventional testing, our method achieved a Mean Squared Error (MSE) of 0.4163 and a Mean Absolute Error (MAE) of 0.3760, outperforming existing approaches by at least 8\\%. In zero-shot prediction experiments across 19 households, the framework maintained consistent accuracy with a total MSE of 11.2712 and MAE of 7.6709, showing at least 12\\% improvement over current methods. The results validate the framework's potential for accurate and transferable load forecasting in integrated energy systems, particularly beneficial for renewable energy integration and smart grid applications.", 'abstract_zh': '基于大语言模型的TSLLM-负荷预测机制', 'title_zh': '基于多任务学习的大语言模型框架下的零样本负荷预测方法：综合能源系统中的应用'}
{'arxiv_id': 'arXiv:2502.16890', 'title': 'ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for Multivariate Time Series Forecasting', 'authors': 'Guoqi Yu, Yaoming Li, Juncheng Wang, Xiaoyu Guo, Angelica I. Aviles-Rivero, Tong Yang, Shujun Wang', 'link': 'https://arxiv.org/abs/2502.16890', 'abstract': 'Recent advancements have progressively incorporated frequency-based techniques into deep learning models, leading to notable improvements in accuracy and efficiency for time series analysis tasks. However, the Mid-Frequency Spectrum Gap in the real-world time series, where the energy is concentrated at the low-frequency region while the middle-frequency band is negligible, hinders the ability of existing deep learning models to extract the crucial frequency information. Additionally, the shared Key-Frequency in multivariate time series, where different time series share indistinguishable frequency patterns, is rarely exploited by existing literature. This work introduces a novel module, Adaptive Mid-Frequency Energy Optimizer, based on convolution and residual learning, to emphasize the significance of mid-frequency bands. We also propose an Energy-based Key-Frequency Picking Block to capture shared Key-Frequency, which achieves superior inter-series modeling performance with fewer parameters. A novel Key-Frequency Enhanced Training strategy is employed to further enhance Key-Frequency modeling, where spectral information from other channels is randomly introduced into each channel. Our approach advanced multivariate time series forecasting on the challenging Traffic, ECL, and Solar benchmarks, reducing MSE by 4%, 6%, and 5% compared to the previous SOTA iTransformer. Code is available at this GitHub Repository: this https URL.', 'abstract_zh': '最近的研究已经逐步将基于频率的技术整合到深度学习模型中，显著提高了时间序列分析任务的准确性和效率。然而，现实世界时间序列中的中频频段空洞，其中能量集中在低频区域而中频带几乎忽略不计，阻碍了现有深度学习模型提取关键频率信息的能力。此外，多变量时间序列中共享的关键频率，不同时间序列共享无法区分的频率模式，现有文献中很少加以利用。本文提出了一种新的模块——自适应中频能量优化器，基于卷积和残差学习，以强调中频带的重要性。我们还提出了一种基于能量的关键频率挑选块，能够捕获共享的关键频率，并通过较少的参数实现了更优秀的跨系列建模性能。我们采用了一种新的关键频率增强训练策略，其中从其他通道随机引入频谱信息到每个通道，以进一步增强关键频率建模。我们的方法在具有挑战性的Traffic、ECL和Solar基准测试中提高了多变量时间序列预测，与之前的SOTA iTransformer相比，MSE降低了4%、6%和5%。代码可供在此GitHub Repository获取：this https URL。', 'title_zh': 'ReFocus: 加强中频和关键频 modeling 多变量时间序列预测'}
{'arxiv_id': 'arXiv:2502.16886', 'title': 'DBudgetKV: Dynamic Budget in KV Cache Compression for Ensuring Optimal Performance', 'authors': 'Xuanfan Ni, Liyan Xu, Chenyang Lyu, Longyue Wang, Mo Yu, Lemao Liu, Fandong Meng, Jie Zhou, Piji Li', 'link': 'https://arxiv.org/abs/2502.16886', 'abstract': 'To alleviate memory burden during inference of large language models (LLMs), numerous studies have focused on compressing the KV cache by exploring aspects such as attention sparsity. However, these techniques often require a pre-defined cache budget; as the optimal budget varies with different input lengths and task types, it limits their practical deployment accepting open-domain instructions. To address this limitation, we propose a new KV cache compression objective: to always ensure the full-cache performance regardless of specific inputs, while maximizing KV cache pruning as much as possible. To achieve this goal, we introduce a novel KV cache compression method dubbed DBudgetKV, which features an attention-based metric to signal when the remaining KV cache is unlikely to match the full-cache performance, then halting the pruning process. Empirical evaluation spanning diverse context lengths, task types, and model sizes suggests that our method achieves lossless KV pruning effectively and robustly, exceeding 25% compression ratio on average. Furthermore, our method is easy to integrate within LLM inference, not only optimizing memory space, but also showing reduced inference time compared to existing methods.', 'abstract_zh': '为了缓解在大语言模型（LLMs）推理过程中对内存的负担，许多研究集中在通过探索注意力稀疏性等方式压缩KV缓存。然而，这些技术通常需要预先定义的缓存预算；由于最优预算会随着输入长度和任务类型的不同而变化，这限制了它们在处理开放域指令时的实用性。为了解决这一局限，我们提出了一种新的KV缓存压缩目标：在任何情况下始终确保全缓存性能，同时尽可能最大化KV缓存的剪枝。为了实现这一目标，我们引入了一种名为DBudgetKV的新KV缓存压缩方法，该方法利用基于注意力的指标来检测剩余KV缓存很可能无法达到全缓存性能，然后停止剪枝过程。跨不同上下文长度、任务类型和模型规模的实证评估表明，我们的方法能够有效地、鲁棒地实现无损KV剪枝，平均压缩比超过25%。此外，我们的方法易于集成到LLM推理中，不仅优化了内存空间，还展示了相较于现有方法的缩短推理时间。', 'title_zh': 'DBudgetKV：键值缓存压缩中的动态预算以确保最优性能'}
{'arxiv_id': 'arXiv:2502.16880', 'title': 'CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter', 'authors': 'Yepeng Weng, Dianwen Mei, Huishi Qiu, Xujie Chen, Li Liu, Jiang Tian, Zhongchao Shi', 'link': 'https://arxiv.org/abs/2502.16880', 'abstract': 'Speculative decoding is a powerful technique that accelerates Large Language Model (LLM) inference by leveraging a lightweight speculative draft model. However, existing designs suffers in performance due to misalignment between training and inference. Recent methods have tried to solve this issue by adopting a multi-step training strategy, but the complex inputs of different training steps make it harder for the draft model to converge. To address this, we propose CORAL, a novel framework that improves both accuracy and efficiency in speculative drafting. CORAL introduces Cross-Step Representation Alignment, a method that enhances consistency across multiple training steps, significantly improving speculative drafting performance. Additionally, we identify the LM head as a major bottleneck in the inference speed of the draft model. We introduce a weight-grouping mechanism that selectively activates a subset of LM head parameters during inference, substantially reducing the latency of the draft model. We evaluate CORAL on three LLM families and three benchmark datasets, achieving speedup ratios of 2.50x-4.07x, outperforming state-of-the-art methods such as EAGLE-2 and HASS. Our results demonstrate that CORAL effectively mitigates training-inference misalignment and delivers significant speedup for modern LLMs with large vocabularies.', 'abstract_zh': '推测解码是通过利用轻量级推测性草稿模型加速大型语言模型（LLM）推理的一项强大技术。然而，现有设计由于训练与推理之间的不对齐而在性能上存在问题。最近的方法尝试通过采用多步训练策略来解决这一问题，但不同训练步骤的复杂输入使得草稿模型难以收敛。为解决这一问题，我们提出了一种名为CORAL的新型框架，该框架在推测性草稿中同时提升了准确性和效率。CORAL引入了跨步表示对齐方法，增强了多步之间的一致性，显著提高了推测性草稿性能。此外，我们识别语言模型头作为草稿模型推理速度的主要瓶颈。我们引入了一种权重分组机制，在推理过程中选择性激活语言模型头的一组参数，显著减少了草稿模型的延迟。我们在三个LLM家族和三个基准数据集上评估了CORAL，实现了2.50x-4.07x的加速比，优于EAGLE-2和HASS等最先进的方法。我们的结果表明，CORAL有效缓解了训练与推理之间的不一致性，并显著提升了具有大词汇量的现代LLM的推理速度。', 'title_zh': 'CORAL：学习多步训练中的一致表示 with 轻量级推测式起草者'}
{'arxiv_id': 'arXiv:2502.16871', 'title': 'Utilizing Social Media Analytics to Detect Trends in Saudi Arabias Evolving Market', 'authors': 'Kanwal Aalijah', 'link': 'https://arxiv.org/abs/2502.16871', 'abstract': 'Saudi Arabia faced a swift economic growth and societal transformation under Vision 2030. This offers a unique opportunity to track emerging trends in the region, which will ultimately pave the way for new business and investment possibilities. This paper explores how AI and social media analytics can identify and track trends across sectors such as construction, food and beverage, tourism, technology, and entertainment thereby helping the businesses make informed decisions. By leveraging a tailored AI-driven methodology, we analyzed millions of social media posts each month, classifying discussions and calculating scores to track the trends. The approach not only uncovered the emerging trends but also shows diminishing trends. Our methodology is able to predict the emergence and growth of trends by utilizing social media data. This approach has potential for adaptation in other regions. Ultimately, our findings highlight how ongoing, AI-powered trend analysis can enable more effective, data-informed business and development strategies in an increasingly dynamic environment.', 'abstract_zh': '沙特阿拉伯在2030愿景下经历了快速的经济成长和社会转型，这为追踪区域新兴趋势提供了独特机会，并最终为新的商业和投资可能性铺平道路。本文探讨了人工智能和社交媒体分析如何跨建筑业、食品和饮料、旅游、科技和娱乐等产业识别和追踪趋势，从而帮助企业在充分知情的基础上做出决策。通过利用定制的人工智能方法，我们每月分析数百万条社交媒体帖子，对讨论进行分类并计算得分以追踪趋势。该方法不仅发现了新兴趋势，还展示了衰退趋势。我们的方法能够利用社交媒体数据预测趋势的出现和增长。该方法在其他地区具有潜在的适应性。最终，我们的研究结果突显了持续的人工智能驱动的趋势分析如何在日益动态的环境中使数据驱动的商业和开发策略更加有效。', 'title_zh': '利用社交媒体分析检测沙特阿拉伯市场演变趋势'}
{'arxiv_id': 'arXiv:2502.16868', 'title': "Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data", 'authors': 'Longbin Lai, Changwei Luo, Yunkai Lou, Mingchen Ju, Zhengyi Yang', 'link': 'https://arxiv.org/abs/2502.16868', 'abstract': 'Large Language Models (LLMs) have recently demonstrated remarkable performance in tasks such as Retrieval-Augmented Generation (RAG) and autonomous AI agent workflows. Yet, when faced with large sets of unstructured documents requiring progressive exploration, analysis, and synthesis, such as conducting literature survey, existing approaches often fall short. We address this challenge -- termed Progressive Document Investigation -- by introducing Graphy, an end-to-end platform that automates data modeling, exploration and high-quality report generation in a user-friendly manner. Graphy comprises an offline Scrapper that transforms raw documents into a structured graph of Fact and Dimension nodes, and an online Surveyor that enables iterative exploration and LLM-driven report generation. We showcase a pre-scrapped graph of over 50,000 papers -- complete with their references -- demonstrating how Graphy facilitates the literature-survey scenario. The demonstration video can be found at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在检索增强生成（RAG）和自主AI代理工作流等任务中展示了卓越的性能。然而，当面对需要逐步探索、分析和综合的大量无结构文档时，如进行文献综述，现有方法往往力不从心。我们通过引入Graphy这一端到端平台来应对这一挑战，该平台以用户友好的方式自动进行数据建模、探索和高质量报告生成。Graphy包括一个离线抓取器，将原始文档转换为由事实和维度节点构成的结构化图，以及一个在线调研器，支持迭代探索和基于大型语言模型的报告生成。我们展示了包含超过50,000篇论文及其参考文献的预抓取图，展示了Graphy如何促进文献综述场景。相关演示视频可在此处访问：this https URL。', 'title_zh': '绘图your数据：走向端到端建模，从原始数据探索和生成报告'}
{'arxiv_id': 'arXiv:2502.16866', 'title': 'Toward Agentic AI: Generative Information Retrieval Inspired Intelligent Communications and Networking', 'authors': 'Ruichen Zhang, Shunpu Tang, Yinqiu Liu, Dusit Niyato, Zehui Xiong, Sumei Sun, Shiwen Mao, Zhu Han', 'link': 'https://arxiv.org/abs/2502.16866', 'abstract': 'The increasing complexity and scale of modern telecommunications networks demand intelligent automation to enhance efficiency, adaptability, and resilience. Agentic AI has emerged as a key paradigm for intelligent communications and networking, enabling AI-driven agents to perceive, reason, decide, and act within dynamic networking environments. However, effective decision-making in telecom applications, such as network planning, management, and resource allocation, requires integrating retrieval mechanisms that support multi-hop reasoning, historical cross-referencing, and compliance with evolving 3GPP standards. This article presents a forward-looking perspective on generative information retrieval-inspired intelligent communications and networking, emphasizing the role of knowledge acquisition, processing, and retrieval in agentic AI for telecom systems. We first provide a comprehensive review of generative information retrieval strategies, including traditional retrieval, hybrid retrieval, semantic retrieval, knowledge-based retrieval, and agentic contextual retrieval. We then analyze their advantages, limitations, and suitability for various networking scenarios. Next, we present a survey about their applications in communications and networking. Additionally, we introduce an agentic contextual retrieval framework to enhance telecom-specific planning by integrating multi-source retrieval, structured reasoning, and self-reflective validation. Experimental results demonstrate that our framework significantly improves answer accuracy, explanation consistency, and retrieval efficiency compared to traditional and semantic retrieval methods. Finally, we outline future research directions.', 'abstract_zh': '现代电信网络日益增加的复杂性和规模需求智能自动化以提高效率、适应性和韧性。行动导向的人工智能已成为智能通信与网络的关键范式，使基于AI的代理能够在动态网络环境中感知、推理、决策和行动。然而，电信应用中的有效决策，如网络规划、管理和资源分配，需要集成支持多跳推理、历史交叉引用和符合 evolving 3GPP 标准的知识检索机制。本文提供了生成式信息检索启发下的智能通信与网络的前瞻性视角，强调知识获取、处理与检索在电信系统中行动导向的人工智能中的作用。首先，我们对生成式信息检索策略进行了全面回顾，包括传统的检索、混合检索、语义检索、基于知识的检索和行动导向的上下文检索。然后，我们分析了这些策略的优势、局限性和在各种网络场景中的适用性。接下来，我们概述了它们在通信与网络中的应用。此外，我们介绍了行动导向的上下文检索框架，通过集成多源检索、结构化推理和自我反思验证，增强电信特定的规划。实验结果表明，与传统和语义检索方法相比，我们的框架显著提高了答案准确性、解释一致性以及检索效率。最后，我们指出了未来的研究方向。', 'title_zh': '迈向自主智能AI：生成式信息检索启发的智能通信与网络'}
{'arxiv_id': 'arXiv:2502.16857', 'title': 'Sarang at DEFACTIFY 4.0: Detecting AI-Generated Text Using Noised Data and an Ensemble of DeBERTa Models', 'authors': 'Avinash Trivedi, Sangeetha Sivanesan', 'link': 'https://arxiv.org/abs/2502.16857', 'abstract': 'This paper presents an effective approach to detect AI-generated text, developed for the Defactify 4.0 shared task at the fourth workshop on multimodal fact checking and hate speech detection. The task consists of two subtasks: Task-A, classifying whether a text is AI generated or human written, and Task-B, classifying the specific large language model that generated the text. Our team (Sarang) achieved the 1st place in both tasks with F1 scores of 1.0 and 0.9531, respectively. The methodology involves adding noise to the dataset to improve model robustness and generalization. We used an ensemble of DeBERTa models to effectively capture complex patterns in the text. The result indicates the effectiveness of our noise-driven and ensemble-based approach, setting a new standard in AI-generated text detection and providing guidance for future developments.', 'abstract_zh': '本文介绍了在第四届多模态事实核查和仇恨言论检测研讨会Defactify 4.0 共享任务中开发的一种有效检测AI生成文本的方法。该任务包括两个子任务：Task-A，分类文本是AI生成还是人类撰写；Task-B，分类具体是哪个大型语言模型生成的文本。我们的团队（Sarang）在两个子任务中分别以F1分数1.0和0.9531的成绩获得第一名。该方法包括向数据集中添加噪声以提高模型的鲁棒性和泛化能力，并使用DeBERTa模型集成有效捕捉文本中的复杂模式。结果表明，我们的噪声驱动和集成方法的有效性，为AI生成文本检测设定了一项新标准，并为未来的发展提供了指导。', 'title_zh': 'Sarang 在 DEFACTIFY 4.0：使用噪声数据和 DeBERTa 模型ensemble 进行生成文本检测'}
{'arxiv_id': 'arXiv:2502.16852', 'title': 'Improving LLM General Preference Alignment via Optimistic Online Mirror Descent', 'authors': 'Yuheng Zhang, Dian Yu, Tao Ge, Linfeng Song, Zhichen Zeng, Haitao Mi, Nan Jiang, Dong Yu', 'link': 'https://arxiv.org/abs/2502.16852', 'abstract': 'Reinforcement learning from human feedback (RLHF) has demonstrated remarkable effectiveness in aligning large language models (LLMs) with human preferences. Many existing alignment approaches rely on the Bradley-Terry (BT) model assumption, which assumes the existence of a ground-truth reward for each prompt-response pair. However, this assumption can be overly restrictive when modeling complex human preferences. In this paper, we drop the BT model assumption and study LLM alignment under general preferences, formulated as a two-player game. Drawing on theoretical insights from learning in games, we integrate optimistic online mirror descent into our alignment framework to approximate the Nash policy. Theoretically, we demonstrate that our approach achieves an $O(T^{-1})$ bound on the duality gap, improving upon the previous $O(T^{-1/2})$ result. More importantly, we implement our method and show through experiments that it outperforms state-of-the-art RLHF algorithms across multiple representative benchmarks.', 'abstract_zh': '从人类反馈中强化学习（RLHF）在使大型语言模型与人类偏好对齐方面展现了显著效果。许多现有的对齐方法依赖于Bradley-Terry（BT）模型假设，该假设认为每个提問-回应对都存在一个真实的奖励。然而，当建模复杂的人类偏好时，这种假设可能会过于严格。在本文中，我们放弃了BT模型假设，并研究了一般偏好下的大型语言模型对齐，将其形式化为一个两玩家博弈。借鉴博弈中学习的理论见解，我们将乐观在线对数下降法融入我们的对齐框架以近似纳什策略。理论上，我们证明了我们的方法在对偶间隙上达到$O(T^{-1})$的界，优于先前的$O(T^{-1/2})$结果。更为重要的是，我们在实验中实现了该方法，表明它在多个代表性基准测试中优于最先进的RLHF算法。', 'title_zh': '通过乐观在线镜像下降方法提高大语言模型通用偏好对齐'}
{'arxiv_id': 'arXiv:2502.16847', 'title': "Characterizing Structured versus Unstructured Environments based on Pedestrians' and Vehicles' Motion Trajectories", 'authors': 'Mahsa Golchoubian, Moojan Ghafurian, Nasser Lashgarian Azad, Kerstin Dautenhahn', 'link': 'https://arxiv.org/abs/2502.16847', 'abstract': "Trajectory behaviours of pedestrians and vehicles operating close to each other can be different in unstructured compared to structured environments. These differences in the motion behaviour are valuable to be considered in the trajectory prediction algorithm of an autonomous vehicle. However, the available datasets on pedestrians' and vehicles' trajectories that are commonly used as benchmarks for trajectory prediction have not been classified based on the nature of their environment. On the other hand, the definitions provided for unstructured and structured environments are rather qualitative and hard to be used for justifying the type of a given environment. In this paper, we have compared different existing datasets based on a couple of extracted trajectory features, such as mean speed and trajectory variability. Through K-means clustering and generalized linear models, we propose more quantitative measures for distinguishing the two different types of environments. Our results show that features such as trajectory variability, stop fraction and density of pedestrians are different among the two environmental types and can be used to classify the existing datasets.", 'abstract_zh': '行人和车辆在不规则环境与规则环境中有不同的运动行为，这些行为差异对于自主车辆轨迹预测算法的设计具有重要价值。然而，用于轨迹预测基准的行人和车辆轨迹数据集尚未根据其环境性质进行分类。另一方面，不规则和规则环境的定义较为定性，难以用于确定特定环境的类型。在本文中，我们基于提取的轨迹特征（如平均速度和轨迹变异性）比较了不同数据集，并通过K-means聚类和广义线性模型提出了更定量的区分两种类型环境的方法。结果显示，轨迹变异性、停顿比例和行人密度等特征在两种环境类型中存在差异，并可用于分类现有数据集。', 'title_zh': '基于行人和车辆运动轨迹区分结构化与非结构化环境'}
{'arxiv_id': 'arXiv:2502.16841', 'title': 'Fair Foundation Models for Medical Image Analysis: Challenges and Perspectives', 'authors': 'Dilermando Queiroz, Anderson Carlos, André Anjos, Lilian Berton', 'link': 'https://arxiv.org/abs/2502.16841', 'abstract': 'Ensuring equitable Artificial Intelligence (AI) in healthcare demands systems that make unbiased decisions across all demographic groups, bridging technical innovation with ethical principles. Foundation Models (FMs), trained on vast datasets through self-supervised learning, enable efficient adaptation across medical imaging tasks while reducing dependency on labeled data. These models demonstrate potential for enhancing fairness, though significant challenges remain in achieving consistent performance across demographic groups. Our review indicates that effective bias mitigation in FMs requires systematic interventions throughout all stages of development. While previous approaches focused primarily on model-level bias mitigation, our analysis reveals that fairness in FMs requires integrated interventions throughout the development pipeline, from data documentation to deployment protocols. This comprehensive framework advances current knowledge by demonstrating how systematic bias mitigation, combined with policy engagement, can effectively address both technical and institutional barriers to equitable AI in healthcare. The development of equitable FMs represents a critical step toward democratizing advanced healthcare technologies, particularly for underserved populations and regions with limited medical infrastructure and computational resources.', 'abstract_zh': '确保医疗卫生中公平的人工智能需要在所有人口群体中做出无偏见的决策，将技术创新与伦理原则相结合。基础模型（FMs）通过自监督学习训练于大规模数据集，能够在各种医学成像任务中实现高效适应，同时减少对标注数据的依赖。尽管这些模型显示出提高公平性的潜力，但在人口群体间的持续性能一致性方面仍面临重大挑战。我们的综述指出，有效的偏见缓解需要在FMs开发的所有阶段采取系统性的干预措施。尽管先前的方法主要集中在模型层面的偏见缓解，但我们的分析表明，FMs的公平性需要在整个开发管道中采取集成干预措施，从数据文档到部署协议。这种全面框架通过展示系统性的偏见缓解与政策参与相结合如何有效应对公平人工智能在医疗卫生中的技术和制度障碍，促进了现有知识的提升。开发公平的基础模型是推动高级医疗技术民主化的一个关键步骤，特别是在服务不足的人群和医疗基础设施和计算资源有限的地区。', 'title_zh': '公平的基础模型在医学图像分析中的挑战与视角'}
{'arxiv_id': 'arXiv:2502.16840', 'title': 'In-context learning of evolving data streams with tabular foundational models', 'authors': 'Afonso Lourenço, João Gama, Eric P. Xing, Goreti Marreiros', 'link': 'https://arxiv.org/abs/2502.16840', 'abstract': "State-of-the-art data stream mining in supervised classification has traditionally relied on ensembles of incremental decision trees. However, the emergence of large tabular models, i.e., transformers designed for structured numerical data, marks a significant paradigm shift. These models move beyond traditional weight updates, instead employing in-context learning through prompt tuning. By using on-the-fly sketches to summarize unbounded streaming data, one can feed this information into a pre-trained model for efficient processing. This work bridges advancements from both areas, highlighting how transformers' implicit meta-learning abilities, pre-training on drifting natural data, and reliance on context optimization directly address the core challenges of adaptive learning in dynamic environments. Exploring real-time model adaptation, this research demonstrates that TabPFN, coupled with a simple sliding memory strategy, consistently outperforms ensembles of Hoeffding trees across all non-stationary benchmarks. Several promising research directions are outlined in the paper. The authors urge the community to explore these ideas, offering valuable opportunities to advance in-context stream learning.", 'abstract_zh': '最先进数据流挖掘在监督分类中的最新进展 traditionally 依赖于增量决策树的集成。然而，大型表格模型，即专门为结构化数值数据设计的转换器的出现，标志着一个显著的范式转变。这些模型超越了传统的权重更新，而是通过提示调优进行上下文学习。通过使用随流生成的草图来总结未界定的数据流，可以将这些信息输入到预训练模型中进行高效处理。本研究将两个领域的最新进展结合起来，突显了变换器的隐式元学习能力、在漂移自然数据上的预训练以及依赖于上下文优化如何直接解决动态环境中的自适应学习核心挑战。探索实时模型适应，研究展示了结合简单滑动记忆策略的 TabPFN 在所有非平稳基准上的表现始终优于霍夫丁树的集成。论文中概述了几个有前景的研究方向。作者敦促社区探索这些想法，提供了提高上下文流学习的重要机会。', 'title_zh': '基于表格基础模型的 evolving 数据流的上下文学习'}
{'arxiv_id': 'arXiv:2502.16834', 'title': 'A Novel Multi-Task Teacher-Student Architecture with Self-Supervised Pretraining for 48-Hour Vasoactive-Inotropic Trend Analysis in Sepsis Mortality Prediction', 'authors': 'Houji Jin, Negin Ashrafi, Kamiar Alaei, Elham Pishgar, Greg Placencia, Maryam Pishgar', 'link': 'https://arxiv.org/abs/2502.16834', 'abstract': "Sepsis is a major cause of ICU mortality, where early recognition and effective interventions are essential for improving patient outcomes. However, the vasoactive-inotropic score (VIS) varies dynamically with a patient's hemodynamic status, complicated by irregular medication patterns, missing data, and confounders, making sepsis prediction challenging. To address this, we propose a novel Teacher-Student multitask framework with self-supervised VIS pretraining via a Masked Autoencoder (MAE). The teacher model performs mortality classification and severity-score regression, while the student distills robust time-series representations, enhancing adaptation to heterogeneous VIS data. Compared to LSTM-based methods, our approach achieves an AUROC of 0.82 on MIMIC-IV 3.0 (9,476 patients), outperforming the baseline (0.74). SHAP analysis revealed that SOFA score (0.147) had the greatest impact on ICU mortality, followed by LODS (0.033), single marital status (0.031), and Medicaid insurance (0.023), highlighting the role of sociodemographic factors. SAPSII (0.020) also contributed significantly. These findings suggest that both clinical and social factors should be considered in ICU decision-making. Our novel multitask and distillation strategies enable earlier identification of high-risk patients, improving prediction accuracy and disease management, offering new tools for ICU decision support.", 'abstract_zh': '脓毒症是ICU死亡的主要原因，早期识别和有效干预对于改善患者预后至关重要。然而，由于血管活性-正性肌力药物评分（VIS）随患者血流动力学状态动态变化，受到不规律用药模式、缺失数据和混杂因素的影响，脓毒症的预测变得极具挑战性。为此，我们提出了一种新颖的教师-学生多任务框架，通过掩码自编码器（MAE）进行自我监督的VIS预训练。教师模型执行死亡率分类和严重程度评分回归，而学生模型提炼出稳健的时间序列表示，以增强对异质VIS数据的适应性。与基于LSTM的方法相比，我们的方法在MIMIC-IV 3.0（9,476例患者）数据集上实现了0.82的AUROC，优于基线（0.74）。SHAP分析显示， sofa评分（0.147）对ICU死亡率影响最大，其次是LODS（0.033）、单身状态（0.031）和Medicaid保险（0.023），突显了社会经济因素的作用。SAPSII（0.020）也做出了显著贡献。这些发现表明，在ICU决策中应同时考虑临床和社会因素。我们提出的新颖多任务和精炼策略能够更早地识别高风险患者，提高预测准确性并优化疾病管理，为ICU决策支持提供新工具。', 'title_zh': '一种新型多任务教师-学生架构结合自监督预训练在严重感染致死率预测中的48小时血管活性-正性肌力药趋势分析'}
{'arxiv_id': 'arXiv:2502.16828', 'title': 'Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning', 'authors': 'Ruikun Li, Huandong Wang, Qingmin Liao, Yong Li', 'link': 'https://arxiv.org/abs/2502.16828', 'abstract': 'Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems. System evolution is often modeled as particles moving on a landscape under the combined effect of energy-driven drift and noise-induced diffusion, where the energy governs the long-term motion of the particles. Estimating the energy landscape of a system has been a longstanding interdisciplinary challenge, hindered by the high operational costs or the difficulty of obtaining supervisory signals. Therefore, the question of how to infer the energy landscape in the absence of true energy values is critical. In this paper, we propose a physics-informed self-supervised learning method to learn the energy landscape from the evolution trajectories of the system. It first maps the system state from the observation space to a discrete landscape space by an adaptive codebook, and then explicitly integrates energy into the graph neural Fokker-Planck equation, enabling the joint learning of energy estimation and evolution prediction. Experimental results across interdisciplinary systems demonstrate that our estimated energy has a correlation coefficient above 0.9 with the ground truth, and evolution prediction accuracy exceeds the baseline by an average of 17.65\\%. The code is available at this http URL.', 'abstract_zh': '能量景观在塑造许多现实世界复杂系统动力学中发挥着关键作用。系统演化通常被建模为在由能量驱动的漂移和噪声引起的扩散联合效应下，粒子在景观上移动，其中能量决定了粒子的长期运动。估计系统的能量景观一直是一个跨学科的长期挑战，受到高操作成本或难以获得监督信号的阻碍。因此，在没有真实能量值的情况下如何推断能量景观的问题至关重要。本文提出一种基于物理的自监督学习方法，从系统的演化轨迹中学习能量景观。该方法首先通过自适应码本将系统状态从观测空间映射到离散的景观空间，然后明确将能量整合到图神经Fokker-Planck方程中，使能量估计和演化预测的联合学习成为可能。跨学科系统的实验结果表明，我们估计的能量与真实值的相关系数高于0.9，演化预测精度平均高出基线17.65%。代码可从此链接获得。', 'title_zh': '通过物理信息自监督学习预测随机动力系统能景'}
{'arxiv_id': 'arXiv:2502.16820', 'title': 'Uncertainty Quantification of Large Language Models through Multi-Dimensional Responses', 'authors': 'Tiejin Chen, Xiaoou Liu, Longchao Da, Xiaoou Liu, Vagelis Papalexakis, Hua Wei', 'link': 'https://arxiv.org/abs/2502.16820', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks due to large training datasets and powerful transformer architecture. However, the reliability of responses from LLMs remains a question. Uncertainty quantification (UQ) of LLMs is crucial for ensuring their reliability, especially in areas such as healthcare, finance, and decision-making. Existing UQ methods primarily focus on semantic similarity, overlooking the deeper knowledge dimensions embedded in responses. We introduce a multi-dimensional UQ framework that integrates semantic and knowledge-aware similarity analysis. By generating multiple responses and leveraging auxiliary LLMs to extract implicit knowledge, we construct separate similarity matrices and apply tensor decomposition to derive a comprehensive uncertainty representation. This approach disentangles overlapping information from both semantic and knowledge dimensions, capturing both semantic variations and factual consistency, leading to more accurate UQ. Our empirical evaluations demonstrate that our method outperforms existing techniques in identifying uncertain responses, offering a more robust framework for enhancing LLM reliability in high-stakes applications.', 'abstract_zh': '大型语言模型（LLMs）由于大规模训练数据集和强大的变换器架构，在各种任务中展现了卓越的能力。然而，LLMs响应的可靠性仍然是一个问题。对LLMs进行不确定性量化（UQ）是确保其可靠性的重要途径，尤其是在医疗保健、金融和决策等领域。现有UQ方法主要关注语义相似性，忽略了响应中嵌入的深层次知识维度。我们介绍了将语义和知识感知相似性分析相结合的多维度UQ框架。通过生成多个响应并利用辅助LLM提取隐含知识，我们构建了独立的相似性矩阵并应用张量分解以获得综合的不确定性表示。这种方法从语义和知识维度中解缠了重叠信息，同时捕捉到了语义变异性与事实一致性，从而提高了UQ的准确性。我们的实验证明，该方法在识别不确定响应方面优于现有技术，为在高风险应用中增强LLMs可靠性提供了更稳健的框架。', 'title_zh': '大型语言模型多维度响应中的不确定性量化'}
{'arxiv_id': 'arXiv:2502.16813', 'title': 'Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns', 'authors': 'Yuxiang Guo, Yuren Mao, Zhonghao Hu, Lu Chen, Yunjun Gao', 'link': 'https://arxiv.org/abs/2502.16813', 'abstract': 'Semantic join discovery, which aims to find columns in a table repository with high semantic joinabilities to a query column, is crucial for dataset discovery. Existing methods can be divided into two categories: cell-level methods and column-level methods. However, neither of them ensures both effectiveness and efficiency simultaneously. Cell-level methods, which compute the joinability by counting cell matches between columns, enjoy ideal effectiveness but suffer poor efficiency. In contrast, column-level methods, which determine joinability only by computing the similarity of column embeddings, enjoy proper efficiency but suffer poor effectiveness due to the issues occurring in their column embeddings: (i) semantics-joinability-gap, (ii) size limit, and (iii) permutation sensitivity. To address these issues, this paper proposes to compute column embeddings via proxy columns; furthermore, a novel column-level semantic join discovery framework, Snoopy, is presented, leveraging proxy-column-based embeddings to bridge effectiveness and efficiency. Specifically, the proposed column embeddings are derived from the implicit column-to-proxy-column relationships, which are captured by the lightweight approximate-graph-matching-based column this http URL acquire good proxy columns for guiding the column projection, we introduce a rank-aware contrastive learning paradigm. Extensive experiments on four real-world datasets demonstrate that Snoopy outperforms SOTA column-level methods by 16% in Recall@25 and 10% in NDCG@25, and achieves superior efficiency--being at least 5 orders of magnitude faster than cell-level solutions, and 3.5x faster than existing column-level methods.', 'abstract_zh': '基于代理列的列级语义连接发现框架：Snoopy', 'title_zh': 'Snoopy: 通过代理列实现高效有效的语义连接发现'}
{'arxiv_id': 'arXiv:2502.16809', 'title': 'CRTrack: Low-Light Semi-Supervised Multi-object Tracking Based on Consistency Regularization', 'authors': 'Zijing Zhao, Jianlong Yu, Lin Zhang, Shunli Zhang', 'link': 'https://arxiv.org/abs/2502.16809', 'abstract': 'Multi-object tracking under low-light environments is prevalent in real life. Recent years have seen rapid development in the field of multi-object tracking. However, due to the lack of datasets and the high cost of annotations, multi-object tracking under low-light environments remains a persistent challenge. In this paper, we focus on multi-object tracking under low-light conditions. To address the issues of limited data and the lack of dataset, we first constructed a low-light multi-object tracking dataset (LLMOT). This dataset comprises data from MOT17 that has been enhanced for nighttime conditions as well as multiple unannotated low-light videos. Subsequently, to tackle the high annotation costs and address the issue of image quality degradation, we propose a semi-supervised multi-object tracking method based on consistency regularization named CRTrack. First, we calibrate a consistent adaptive sampling assignment to replace the static IoU-based strategy, enabling the semi-supervised tracking method to resist noisy pseudo-bounding boxes. Then, we design a adaptive semi-supervised network update method, which effectively leverages unannotated data to enhance model performance. Dataset and Code: this https URL.', 'abstract_zh': '低光照条件下的多目标跟踪在现实生活中非常普遍。近年来，多目标跟踪领域取得了 rapid development。然而，由于缺乏数据集和注释成本高，低光照条件下的多目标跟踪仍然是一个持续的挑战。在本文中，我们专注于低光照条件下的多目标跟踪。为了应对数据有限和缺乏数据集的问题，我们首先构建了一个低光照多目标跟踪数据集（LLMOT）。该数据集包含夜间条件增强的MOT17数据以及多个未注释的低光照视频。随后，为了应对注释成本高和图像质量退化的问题，我们提出了一种基于一致性正则化的半监督多目标跟踪方法，CRTrack。该方法首先校准一个一致的自适应采样分配，以替代静态IoU策略，使半监督跟踪方法能够对抗噪声伪边框。然后，我们设计了一种自适应半监督网络更新方法，有效地利用未注释的数据来提升模型性能。数据集和代码：this https URL。', 'title_zh': 'CRTrack：基于一致性正则化的低光照半监督多对象跟踪'}
{'arxiv_id': 'arXiv:2502.16804', 'title': 'Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances', 'authors': 'Yaozu Wu, Dongyuan Li, Yankai Chen, Renhe Jiang, Henry Peng Zou, Liancheng Fang, Zhen Wang, Philip S. Yu', 'link': 'https://arxiv.org/abs/2502.16804', 'abstract': 'Autonomous Driving Systems (ADSs) are revolutionizing transportation by reducing human intervention, improving operational efficiency, and enhancing safety. Large Language Models (LLMs), known for their exceptional planning and reasoning capabilities, have been integrated into ADSs to assist with driving decision-making. However, LLM-based single-agent ADSs face three major challenges: limited perception, insufficient collaboration, and high computational demands. To address these issues, recent advancements in LLM-based multi-agent ADSs have focused on improving inter-agent communication and cooperation. This paper provides a frontier survey of LLM-based multi-agent ADSs. We begin with a background introduction to related concepts, followed by a categorization of existing LLM-based approaches based on different agent interaction modes. We then discuss agent-human interactions in scenarios where LLM-based agents engage with humans. Finally, we summarize key applications, datasets, and challenges in this field to support future research (this https URL).', 'abstract_zh': '基于大型语言模型的多剂自动驾驶系统：前沿综述', 'title_zh': '基于大型语言模型的多Agent自主驾驶系统：近期进展综述'}
{'arxiv_id': 'arXiv:2502.16802', 'title': 'Unsupervised Topic Models are Data Mixers for Pre-training Language Models', 'authors': 'Jiahui Peng, Xinlin Zhuang, Qiu Jiantao, Ren Ma, Jing Yu, Tianyi Bai, Conghui He', 'link': 'https://arxiv.org/abs/2502.16802', 'abstract': 'The performance of large language models (LLMs) is significantly affected by the quality and composition of their pre-training data, which is inherently diverse, spanning various domains, sources, and topics. Effectively integrating these heterogeneous data sources is crucial for optimizing LLM performance. Previous research has predominantly concentrated on domain-based data mixing, often neglecting the nuanced topic-level characteristics of the data. To address this gap, we propose a simple yet effective topic-based data mixing strategy that utilizes fine-grained topics generated through our topic modeling method, DataWeave. DataWeave employs a multi-stage clustering process to group semantically similar documents and utilizes LLMs to generate detailed topics, thereby facilitating a more nuanced understanding of dataset composition. Our strategy employs heuristic methods to upsample or downsample specific topics, which significantly enhances LLM performance on downstream tasks, achieving superior results compared to previous, more complex data mixing approaches. Furthermore, we confirm that the topics Science and Relationships are particularly effective, yielding the most substantial performance improvements. We will make our code and datasets publicly available.', 'abstract_zh': '大型语言模型（LLMs）的表现受其预训练数据的质量和组成影响，这些数据在本质上有很高的多样性，涉及多个领域、来源和主题。有效整合这些异构数据源对于优化LLM性能至关重要。以往的研究主要集中在基于领域的数据混合，常常忽视了数据在主题层面的细微差异。为填补这一空白，我们提出了一种简单有效的基于主题的数据混合策略，该策略利用通过我们的主题建模方法DataWeave生成的细粒度主题。DataWeave采用多阶段聚类过程对语义相似的文档进行分组，并利用LLMs生成详细的主题，从而有助于更细致地理解数据集组成。该策略采用启发式方法对特定主题进行上采样或下采样，显著提高了LLM在下游任务上的性能，取得了优于以往更为复杂的数据混合方法的结果。此外，我们证实科学和关系主题特别有效，提供了最大的性能改进。我们将公开我们的代码和数据集。', 'title_zh': '无监督主题模型是预训练语言模型的数据混音器'}
{'arxiv_id': 'arXiv:2502.16796', 'title': 'MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions', 'authors': 'Yuxuan Liu, Hongda Sun, Wei Liu, Jian Luan, Bo Du, Rui Yan', 'link': 'https://arxiv.org/abs/2502.16796', 'abstract': "Mobile phone agents can assist people in automating daily tasks on their phones, which have emerged as a pivotal research spotlight. However, existing procedure-oriented agents struggle with cross-app instructions, due to the following challenges: (1) complex task relationships, (2) diverse app environment, and (3) error propagation and information loss in multi-step execution. Drawing inspiration from object-oriented programming principles, we recognize that object-oriented solutions is more suitable for cross-app instruction. To address these challenges, we propose a self-evolving multi-agent framework named MobileSteward, which integrates multiple app-oriented StaffAgents coordinated by a centralized StewardAgent. We design three specialized modules in MobileSteward: (1) Dynamic Recruitment generates a scheduling graph guided by information flow to explicitly associate tasks among apps. (2) Assigned Execution assigns the task to app-oriented StaffAgents, each equipped with app-specialized expertise to address the diversity between apps. (3) Adjusted Evaluation conducts evaluation to provide reflection tips or deliver key information, which alleviates error propagation and information loss during multi-step execution. To continuously improve the performance of MobileSteward, we develop a Memory-based Self-evolution mechanism, which summarizes the experience from successful execution, to improve the performance of MobileSteward. We establish the first English Cross-APP Benchmark (CAPBench) in the real-world environment to evaluate the agents' capabilities of solving complex cross-app instructions. Experimental results demonstrate that MobileSteward achieves the best performance compared to both single-agent and multi-agent frameworks, highlighting the superiority of MobileSteward in better handling user instructions with diverse complexity.", 'abstract_zh': '基于对象的移动手机代理框架MobileSteward：解决跨应用指令挑战', 'title_zh': 'MobileSteward：集成多种面向应用的代理并具备自我演进能力以自动化跨应用指令执行'}
{'arxiv_id': 'arXiv:2502.16794', 'title': 'AAD-LLM: Neural Attention-Driven Auditory Scene Understanding', 'authors': 'Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Adeen Flinker, Daniel Friedman, Nima Mesgarani', 'link': 'https://arxiv.org/abs/2502.16794', 'abstract': 'Auditory foundation models, including auditory large language models (LLMs), process all sound inputs equally, independent of listener perception. However, human auditory perception is inherently selective: listeners focus on specific speakers while ignoring others in complex auditory scenes. Existing models do not incorporate this selectivity, limiting their ability to generate perception-aligned responses. To address this, we introduce Intention-Informed Auditory Scene Understanding (II-ASU) and present Auditory Attention-Driven LLM (AAD-LLM), a prototype system that integrates brain signals to infer listener attention. AAD-LLM extends an auditory LLM by incorporating intracranial electroencephalography (iEEG) recordings to decode which speaker a listener is attending to and refine responses accordingly. The model first predicts the attended speaker from neural activity, then conditions response generation on this inferred attentional state. We evaluate AAD-LLM on speaker description, speech transcription and extraction, and question answering in multitalker scenarios, with both objective and subjective ratings showing improved alignment with listener intention. By taking a first step toward intention-aware auditory AI, this work explores a new paradigm where listener perception informs machine listening, paving the way for future listener-centered auditory systems. Demo and code available: this https URL.', 'abstract_zh': '基于意图的听觉场景理解（II-ASU）和听觉注意驱动的大语言模型（AAD-LLM）', 'title_zh': 'AAD-LLM: 基于神经注意力的声音场景理解'}
{'arxiv_id': 'arXiv:2502.16793', 'title': 'VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning', 'authors': 'Yang Chen, Bin Zhou', 'link': 'https://arxiv.org/abs/2502.16793', 'abstract': 'Graph Neural Networks (GNNs) have gained attention for their ability to learn representations from graph data. Due to privacy concerns and conflicts of interest that prevent clients from directly sharing graph data with one another, Vertical Graph Federated Learning (VGFL) frameworks have been developed. Recent studies have shown that VGFL is vulnerable to adversarial attacks that degrade performance. However, it is a common problem that client nodes are often unlabeled in the realm of VGFL. Consequently, the existing attacks, which rely on the availability of labeling information to obtain gradients, are inherently constrained in their applicability. This limitation precludes their deployment in practical, real-world environments. To address the above problems, we propose a novel graph adversarial attack against VGFL, referred to as VGFL-SA, to degrade the performance of VGFL by modifying the local clients structure without using labels. Specifically, VGFL-SA uses a contrastive learning method to complete the attack before the local clients are trained. VGFL-SA first accesses the graph structure and node feature information of the poisoned clients, and generates the contrastive views by node-degree-based edge augmentation and feature shuffling augmentation. Then, VGFL-SA uses the shared graph encoder to get the embedding of each view, and the gradients of the adjacency matrices are obtained by the contrastive function. Finally, perturbed edges are generated using gradient modification rules. We validated the performance of VGFL-SA by performing a node classification task on real-world datasets, and the results show that VGFL-SA achieves good attack effectiveness and transferability.', 'abstract_zh': '垂直图联邦学习中的新型图对抗攻击（VGFL-SA）：无需标签修改局部客户端结构以降级垂直图联邦学习性能', 'title_zh': 'VGFL-SA：基于对比学习的垂直图联邦学习结构攻击'}
{'arxiv_id': 'arXiv:2502.16792', 'title': 'The Role of Sparsity for Length Generalization in Transformers', 'authors': 'Noah Golowich, Samy Jelassi, David Brandfonbrener, Sham M. Kakade, Eran Malach', 'link': 'https://arxiv.org/abs/2502.16792', 'abstract': "Training large language models to predict beyond their training context lengths has drawn much attention in recent years, yet the principles driving such behavior of length generalization remain underexplored. We propose a new theoretical framework to study length generalization for the next-token prediction task, as performed by decoder-only transformers. Conceptually, we show that length generalization occurs as long as each predicted token depends on a small (fixed) number of previous tokens. We formalize such tasks via a notion we call $k$-sparse planted correlation distributions, and show that an idealized model of transformers which generalize attention heads successfully length-generalize on such tasks. As a bonus, our theoretical model justifies certain techniques to modify positional embeddings which have been introduced to improve length generalization, such as position coupling.\nWe support our theoretical results with experiments on synthetic tasks and natural language, which confirm that a key factor driving length generalization is a ``sparse'' dependency structure of each token on the previous ones. Inspired by our theory, we introduce Predictive Position Coupling, which trains the transformer to predict the position IDs used in a positional coupling approach. Predictive Position Coupling thereby allows us to broaden the array of tasks to which position coupling can successfully be applied to achieve length generalization.", 'abstract_zh': '训练大型语言模型以超出训练上下文长度进行预测引起了近年来的广泛关注，但驱动这种长度泛化的原理仍待深入探索。我们提出了一种新的理论框架，以研究仅解码器变换器在下一个标记预测任务中的长度泛化现象。从概念上讲，我们表明，只要每个预测的标记依赖于少量（固定数量）的先前标记，长度泛化就会发生。我们通过一种我们称为$k$-稀疏植入相关分布的概念来形式化此类任务，并证明理想化的变换器模型能够成功地在这些任务上进行长度泛化。此外，我们的理论模型还解释了某些已被证明能改善长度泛化的位置嵌入修改技术，如位置耦合。\n\n我们的理论结果通过在合成任务和自然语言上的实验得到了支持，实验确认驱动长度泛化的关键因素是每个标记对先前标记的“稀疏”依赖结构。受我们理论的启发，我们引入了预测位置耦合，该方法训练变换器预测位置耦合方法中使用的位置ID。预测位置耦合因此使我们能够扩大应用位置耦合以实现长度泛化的任务范围。', 'title_zh': 'Transformer中稀疏性在长度泛化中的作用'}
{'arxiv_id': 'arXiv:2502.16789', 'title': 'AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay', 'authors': 'Ziyi Tang, Zechuan Chen, Jiarui Yang, Jiayao Mai, Yongsen Zheng, Keze Wang, Jinrui Chen, Liang Lin', 'link': 'https://arxiv.org/abs/2502.16789', 'abstract': 'Alpha mining, a critical component in quantitative investment, focuses on discovering predictive signals for future asset returns in increasingly complex financial markets. However, the pervasive issue of alpha decay, where factors lose their predictive power over time, poses a significant challenge for alpha mining. Traditional methods like genetic programming face rapid alpha decay from overfitting and complexity, while approaches driven by Large Language Models (LLMs), despite their promise, often rely too heavily on existing knowledge, creating homogeneous factors that worsen crowding and accelerate decay. To address this challenge, we propose AlphaAgent, an autonomous framework that effectively integrates LLM agents with ad hoc regularizations for mining decay-resistant alpha factors. AlphaAgent employs three key mechanisms: (i) originality enforcement through a similarity measure based on abstract syntax trees (ASTs) against existing alphas, (ii) hypothesis-factor alignment via LLM-evaluated semantic consistency between market hypotheses and generated factors, and (iii) complexity control via AST-based structural constraints, preventing over-engineered constructions that are prone to overfitting. These mechanisms collectively guide the alpha generation process to balance originality, financial rationale, and adaptability to evolving market conditions, mitigating the risk of alpha decay. Extensive evaluations show that AlphaAgent outperforms traditional and LLM-based methods in mitigating alpha decay across bull and bear markets, consistently delivering significant alpha in Chinese CSI 500 and US S&P 500 markets over the past four years. Notably, AlphaAgent showcases remarkable resistance to alpha decay, elevating the potential for yielding powerful factors.', 'abstract_zh': 'Alpha 矿掘：一种在量化投资中关键的组件，专注于在日益复杂金融市场中发现预测未来资产回报的信号。然而，普遍存在的 Alpha 衰减问题，即因素随时间失去预测能力，对 Alpha 矿掘构成了重大挑战。传统的遗传程序方法容易因过拟合和复杂性而导致 Alpha 衰减，而大型语言模型（LLMs）驱动的方法虽然有潜力，但由于过于依赖现有知识，往往会生成同质化因素，加剧拥挤并加速衰减。为应对这一挑战，我们提出 AlphaAgent，一种自主框架，有效整合 LLM 代理与自适应正则化，以挖掘抗衰减 Alpha 因子。AlphaAgent 采用三种关键机制：（i）基于抽象语法树（AST）的相似性度量强制原始性，与现有 Alpha 对比，（ii）假设-因子对齐，利用 LLM 评估市场假设与生成因子间的语义一致性，以及（iii）基于 AST 的结构约束控制复杂性，防止易过拟合的过度设计。这些机制共同指导 Alpha 生成过程，平衡原始性、金融合理性以及对不断变化市场条件的适应性，从而降低 Alpha 衰减的风险。广泛评估显示，AlphaAgent 在牛熊市中优于传统和 LLM 基础方法，在过去四年中为中国的 CSI 500 和美国的 S&P 500 市场持续提供显著的 Alpha，同时表现出对 Alpha 衰减的显著抵抗力，提升了生成强因子的潜力。', 'title_zh': 'AlphaAgent：带有正则化探索以对抗alpha衰减的LLM驱动alpha挖掘'}
{'arxiv_id': 'arXiv:2502.16779', 'title': 'Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model', 'authors': 'Yaxuan Huang, Xili Dai, Jianan Wang, Xianbiao Qi, Yixing Yuan, Xiangyu Yue', 'link': 'https://arxiv.org/abs/2502.16779', 'abstract': 'Room layout estimation from multiple-perspective images is poorly investigated due to the complexities that emerge from multi-view geometry, which requires muti-step solutions such as camera intrinsic and extrinsic estimation, image matching, and triangulation. However, in 3D reconstruction, the advancement of recent 3D foundation models such as DUSt3R has shifted the paradigm from the traditional multi-step structure-from-motion process to an end-to-end single-step approach. To this end, we introduce Plane-DUSt3R}, a novel method for multi-view room layout estimation leveraging the 3D foundation model DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes on a room layout dataset (Structure3D) with a modified objective to estimate structural planes. By generating uniform and parsimonious results, Plane-DUSt3R enables room layout estimation with only a single post-processing step and 2D detection results. Unlike previous methods that rely on single-perspective or panorama image, Plane-DUSt3R extends the setting to handle multiple-perspective images. Moreover, it offers a streamlined, end-to-end solution that simplifies the process and reduces error accumulation. Experimental results demonstrate that Plane-DUSt3R not only outperforms state-of-the-art methods on the synthetic dataset but also proves robust and effective on in the wild data with different image styles such as cartoon.', 'abstract_zh': '基于多视角图像的房间布局估计由于多视角几何学带来的复杂性而研究不足，这需要多步解决方案，如相机内参和外参估计、图像匹配和三角测量。然而，在三维重建中，近期三维基础模型（如DUSt3R）的进步已经将范式从传统的多步结构从运动过程转变为端到端的一步式方法。为了解决这一问题，我们引入了Plane-DUSt3R，这是一种利用三维基础模型DUSt3R的新方法，用于多视角房间布局估计。Plane-DUSt3R结合了DUSt3R框架，并在房间布局数据集（Structure3D）上进行了微调，以估计结构平面。通过生成均匀且简洁的结果，Plane-DUSt3R使得房间布局估计只需一个后处理步骤和二维检测结果即可。Plane-DUSt3R不同于依赖单一视角或全景图像的先前方法，它可以处理多视角图像。此外，它提供了一种简化的过程和减少累积误差的端到端解决方案。实验结果表明，Plane-DUSt3R不仅在合成数据集上优于现有方法，而且在不同图像风格（如卡通）的野外数据上也表现出鲁棒性和有效性。', 'title_zh': '预训练模型时代基于稀疏视角的室内布局重建'}
{'arxiv_id': 'arXiv:2502.16778', 'title': 'The Robustness of Structural Features in Species Interaction Networks', 'authors': 'Sanaz Hasanzadeh Fard, Emily Dolson', 'link': 'https://arxiv.org/abs/2502.16778', 'abstract': 'Species interaction networks are a powerful tool for describing ecological communities; they typically contain nodes representing species, and edges representing interactions between those species. For the purposes of drawing abstract inferences about groups of similar networks, ecologists often use graph topology metrics to summarize structural features. However, gathering the data that underlies these networks is challenging, which can lead to some interactions being missed. Thus, it is important to understand how much different structural metrics are affected by missing data. To address this question, we analyzed a database of 148 real-world bipartite networks representing four different types of species interactions (pollination, host-parasite, plant-ant, and seed-dispersal). For each network, we measured six different topological properties: number of connected components, variance in node betweenness, variance in node PageRank, largest Eigenvalue, the number of non-zero Eigenvalues, and community detection as determined by four different algorithms. We then tested how these properties change as additional edges -- representing data that may have been missed -- are added to the networks. We found substantial variation in how robust different properties were to the missing data. For example, the Clauset-Newman-Moore and Louvain community detection algorithms showed much more gradual change as edges were added than the label propagation and Girvan-Newman algorithms did, suggesting that the former are more robust. Robustness also varied for some metrics based on interaction type. These results provide a foundation for selecting network properties to use when analyzing messy ecological network data.', 'abstract_zh': '物种相互作用网络是描述生态群落的强大工具；它们通常包含表示物种的节点和表示物种间相互作用的边。为了从类似的网络群体中提取抽象推论，生态学家常用图拓扑度量来总结结构特征。然而，收集构成这些网络的数据具有挑战性，可能导致某些相互作用被遗漏。因此，理解不同结构度量在数据缺失时的敏感性非常重要。为了解决这个问题，我们分析了一个包含148个现实世界双部分网络的数据库，这些网络代表了四种不同类型的物种相互作用（传粉、寄主-寄生虫、植物-蚂蚁、种子传播）。对每个网络，我们测量了六种不同的拓扑属性：连通分支数、节点中介中心性的方差、节点PageRank的方差、最大的特征值、非零特征值的数量，以及由四种不同算法确定的社区检测结果。然后我们测试了在不断添加表示可能遗漏的数据的边时，这些属性会发生怎样的变化。我们发现不同属性对数据缺失的鲁棒性存在显著差异。例如，Clauset-Newman-Moore和Louvain社区检测算法在添加边时显示出更平滑的变化，而标签传播和Girvan-Newman算法则显示出更急剧的变化，这表明前者更鲁棒。鲁棒性在某些基于相互作用类型的度量上也有所不同。这些结果为分析混乱的生态网络数据时选择网络属性提供了基础。', 'title_zh': '物种互作网络中结构特征的稳健性'}
{'arxiv_id': 'arXiv:2502.16776', 'title': 'AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement', 'authors': 'Zhexin Zhang, Leqi Lei, Junxiao Yang, Xijie Huang, Yida Lu, Shiyao Cui, Renmiao Chen, Qinglin Zhang, Xinyuan Wang, Hao Wang, Hao Li, Xianqi Lei, Chengwei Pan, Lei Sha, Hongning Wang, Minlie Huang', 'link': 'https://arxiv.org/abs/2502.16776', 'abstract': 'As AI models are increasingly deployed across diverse real-world scenarios, ensuring their safety remains a critical yet underexplored challenge. While substantial efforts have been made to evaluate and enhance AI safety, the lack of a standardized framework and comprehensive toolkit poses significant obstacles to systematic research and practical adoption. To bridge this gap, we introduce AISafetyLab, a unified framework and toolkit that integrates representative attack, defense, and evaluation methodologies for AI safety. AISafetyLab features an intuitive interface that enables developers to seamlessly apply various techniques while maintaining a well-structured and extensible codebase for future advancements. Additionally, we conduct empirical studies on Vicuna, analyzing different attack and defense strategies to provide valuable insights into their comparative effectiveness. To facilitate ongoing research and development in AI safety, AISafetyLab is publicly available at this https URL, and we are committed to its continuous maintenance and improvement.', 'abstract_zh': '随着AI模型在多样化的现实场景中越来越广泛地部署，确保其安全性仍是一个关键但尚未充分探索的挑战。尽管已经做出了大量努力来评估和提升AI安全性，但缺乏标准化框架和综合工具套件严重阻碍了系统性研究和实际应用。为解决这一问题，我们介绍了AISafetyLab，这是一个统一的框架和工具套件，集成了代表性的攻击、防御和评估方法，以促进AI安全性。AISafetyLab具有直观的界面，使开发人员能够无缝应用各种技术，并维持一个结构良好且可扩展的代码库，以支持未来的发展。此外，我们还在Vicuna上进行了实证研究，分析了不同的攻击和防御策略，提供了关于其相对效果的宝贵见解。为了促进AI安全性领域的持续研究和发展，AISafetyLab已在以下网址公开可用，并致力于其持续维护和改进。', 'title_zh': 'AISafetyLab: 人工智能安全评估与改进综合框架'}
{'arxiv_id': 'arXiv:2502.16770', 'title': 'LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint', 'authors': 'Qianli Ma, Dongrui Liu, Qian Chen, Linfeng Zhang, Jing Shao', 'link': 'https://arxiv.org/abs/2502.16770', 'abstract': 'Fine-tuning pre-trained Large Language Models (LLMs) for specialized tasks incurs substantial computational and data costs. While model merging offers a training-free solution to integrate multiple task-specific models, existing methods suffer from safety-utility conflicts where enhanced general capabilities degrade safety safeguards. We identify two root causes: \\textbf{neuron misidentification} due to simplistic parameter magnitude-based selection, and \\textbf{cross-task neuron interference} during merging. To address these challenges, we propose \\textbf{LED-Merging}, a three-stage framework that \\textbf{L}ocates task-specific neurons via gradient-based attribution, dynamically \\textbf{E}lects critical neurons through multi-model importance fusion, and \\textbf{D}isjoints conflicting updates through parameter isolation. Extensive experiments on Llama-3-8B, Mistral-7B, and Llama2-13B demonstrate that LED-Merging reduces harmful response rates(\\emph{e.g.}, a 31.4\\% decrease on Llama-3-8B-Instruct on HarmBench) while preserving 95\\% of utility performance(\\emph{e.g.}, 52.39\\% accuracy on GSM8K). LED-Merging resolves safety-utility conflicts and provides a lightweight, training-free paradigm for constructing reliable multi-task LLMs.', 'abstract_zh': 'Fine-tuning 预训练大型语言模型 (LLMs) 以适应特定任务会带来显著的计算和数据成本。虽然模型合并提供了一种无需训练即可整合多个任务特定模型的解决方案，但现有方法存在安全性和实用性的冲突，其中增强的一般能力会削弱安全性保障。我们确定了两个根本原因：基于简单参数量纲选择的神经元误识别，以及合并过程中的跨任务神经元干扰。为了解决这些挑战，我们提出了一种三阶段框架 LED-Merging，该框架通过梯度 attribution 定位任务特定神经元，通过多模型重要性融合动态选择关键神经元，并通过参数隔离排除冲突更新。在 Llama-3-8B、Mistral-7B 和 Llama2-13B 上的广泛实验表明，LED-Merging 降低了有害响应率（例如，Llama-3-8B-Instruct 上的 HarmBench 减少 31.4%），同时保留了 95% 的实用性性能（例如，GSM8K 上的准确率达到 52.39%）。LED-Merging 解决了安全性和实用性的冲突，并提供了一种轻量级、无需训练的框架，用于构建可靠的多任务 LLMs。', 'title_zh': 'LED-Merging: 在位置互斥条件下缓解模型合并中的安全-效用冲突'}
{'arxiv_id': 'arXiv:2502.16756', 'title': 'Towards Reinforcement Learning for Exploration of Speculative Execution Vulnerabilities', 'authors': 'Evan Lai, Wenjie Xiong, Edward Suh, Mohit Tiwari, Mulong Luo', 'link': 'https://arxiv.org/abs/2502.16756', 'abstract': 'Speculative attacks such as Spectre can leak secret information without being discovered by the operating system. Speculative execution vulnerabilities are finicky and deep in the sense that to exploit them, it requires intensive manual labor and intimate knowledge of the hardware. In this paper, we introduce SpecRL, a framework that utilizes reinforcement learning to find speculative execution leaks in post-silicon (black box) microprocessors.', 'abstract_zh': '基于强化学习的SpecRL框架：用于后硅微处理器的投机执行泄漏发现', 'title_zh': '面向推测执行漏洞探索的 reinforcement 学习方法研究'}
{'arxiv_id': 'arXiv:2502.16747', 'title': 'SQLong: Enhanced NL2SQL for Longer Contexts with LLMs', 'authors': 'Dai Quoc Nguyen, Cong Duy Vu Hoang, Duy Vu, Gioacchino Tangari, Thanh Tien Vu, Don Dharmasiri, Yuan-Fang Li, Long Duong', 'link': 'https://arxiv.org/abs/2502.16747', 'abstract': "Open-weight large language models (LLMs) have significantly advanced performance in the Natural Language to SQL (NL2SQL) task. However, their effectiveness diminishes when dealing with large database schemas, as the context length increases. To address this limitation, we present SQLong, a novel and efficient data augmentation framework designed to enhance LLM performance in long-context scenarios for the NL2SQL task. SQLong generates augmented datasets by extending existing database schemas with additional synthetic CREATE TABLE commands and corresponding data rows, sampled from diverse schemas in the training data. This approach effectively simulates long-context scenarios during finetuning and evaluation. Through experiments on the Spider and BIRD datasets, we demonstrate that LLMs finetuned with SQLong-augmented data significantly outperform those trained on standard datasets. These imply SQLong's practical implementation and its impact on improving NL2SQL capabilities in real-world settings with complex database schemas.", 'abstract_zh': 'Open-weight大型语言模型（LLMs）在自然语言到SQL（NL2SQL）任务中取得了显著进展。然而，在处理大型数据库模式时，随着上下文长度的增加，其效果减弱。为解决这一限制，我们提出了SQLong，一种新颖且高效的數據 augmentation 框架，旨在增强LLM在长上下文情景下NL2SQL任务中的性能。SQLong通过扩展现有的数据库模式，添加额外的合成CREATE TABLE命令及其相应的数据行，从训练数据中的多种模式中采样，以有效模拟长上下文情景。通过在Spider和BIRD数据集上的实验，我们证明使用SQLong增强的数据微调的LLMs明显优于使用标准数据集训练的LLMs。这表明SQLong的实际应用及其在现实世界复杂数据库模式下提升NL2SQL能力方面的影响。', 'title_zh': 'SQLong: 通过LLM增强的长上下文NL2SQL'}
{'arxiv_id': 'arXiv:2502.16744', 'title': 'Order-Optimal Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization', 'authors': 'Yiyang Lu, Mohammad Pedramfar, Vaneet Aggarwal', 'link': 'https://arxiv.org/abs/2502.16744', 'abstract': 'Projection-based algorithms for constrained Online Convex Optimization (COCO) face scalability challenges in high-dimensional settings due to the computational complexity of projecting iterates onto constraint sets. This paper introduces a projection-free algorithm for COCO that achieves state-of-the-art performance guarantees while eliminating the need for projections. By integrating a separation oracle with adaptive Online Gradient Descent (OGD) and employing a Lyapunov-driven surrogate function, while dynamically adjusting step sizes using gradient norms, our method jointly optimizes the regret and cumulative constraint violation (CCV). We also use a blocked version of OGD that helps achieve tradeoffs betweeen the regret and CCV with the number of calls to the separation oracle. For convex cost functions, our algorithm attains an optimal regret of $\\mathcal{O}(\\sqrt{T})$ and a CCV of $\\mathcal{O}(\\sqrt{T} \\log T)$, matching the best-known projection-based results, while only using $\\tilde{\\mathcal{O}}({T})$ calls to the separation oracle. The results also demonstrate a tradeoff where lower calls to the separation oracle increase the regret and the CCV. In the strongly convex setting, we further achieve a regret of $\\mathcal{O}(\\log T)$ and a CCV of $\\mathcal{O}(\\sqrt{T\\log T} )$, while requiring ${\\mathcal{O}}({T}^2)$ calls to the separation oracle. Further, tradeoff with the decreasing oracle calls is studied. These results close the gap between projection-free and projection-based approaches, demonstrating that projection-free methods can achieve performance comparable to projection-based counterparts.', 'abstract_zh': '基于投影的算法在受限在线凸优化中的扩展挑战：一种无需投影的状态-of-the-art性能保证的投影-free算法', 'title_zh': '对抗约束在线凸优化的最优投影免费算法'}
{'arxiv_id': 'arXiv:2502.16736', 'title': 'AUKT: Adaptive Uncertainty-Guided Knowledge Transfer with Conformal Prediction', 'authors': 'Rui Liu, Peng Gao, Yu Shen, Ming Lin, Pratap Tokekar', 'link': 'https://arxiv.org/abs/2502.16736', 'abstract': "Knowledge transfer between teacher and student models has proven effective across various machine learning applications. However, challenges arise when the teacher's predictions are noisy, or the data domain during student training shifts from the teacher's pretraining data. In such scenarios, blindly relying on the teacher's predictions can lead to suboptimal knowledge transfer. To address these challenges, we propose a novel and universal framework, Adaptive Uncertainty-guided Knowledge Transfer ($\\textbf{AUKT}$), which leverages Conformal Prediction (CP) to dynamically adjust the student's reliance on the teacher's guidance based on the teacher's prediction uncertainty. CP is a distribution-free, model-agnostic approach that provides reliable prediction sets with statistical coverage guarantees and minimal computational overhead. This adaptive mechanism mitigates the risk of learning undesirable or incorrect knowledge. We validate the proposed framework across diverse applications, including image classification, imitation-guided reinforcement learning, and autonomous driving. Experimental results consistently demonstrate that our approach improves performance, robustness and transferability, offering a promising direction for enhanced knowledge transfer in real-world applications.", 'abstract_zh': '教师模型与学生模型之间的知识迁移在各种机器学习应用中已被证明是有效的。然而，在教师预测噪声较大或学生训练数据域与教师预训练数据不同的情况下，单纯依赖教师预测会导致知识迁移效果不佳。为应对这些挑战，我们提出了一种新颖且通用的框架——自适应不确定性引导的知识迁移（AUKT），该框架利用形尔诺预测（CP）动态调整学生对教师指导的依赖程度，依据教师预测的不确定性。CP是一种基于统计覆盖率保证且计算开销较小的非参数、模型无关的方法。这种自适应机制减少了学习不期望或错误知识的风险。我们在图像分类、imitation引导的强化学习和自动驾驶等多个应用中验证了该框架的有效性，实验结果一致表明，我们的方法在提高性能、鲁棒性和迁移性方面具有显著优势，为现实应用中增强知识迁移提供了前景广阔的方向。', 'title_zh': '自适应不确定性引导的知识转移与 conformal 推断'}
{'arxiv_id': 'arXiv:2502.16732', 'title': "DeepSeek reshaping healthcare in China's tertiary hospitals", 'authors': 'Jishizhan Chen, Qingzeng Zhang', 'link': 'https://arxiv.org/abs/2502.16732', 'abstract': "The rapid integration of artificial intelligence (AI) into healthcare is transforming clinical decision-making and hospital operations. DeepSeek has emerged as a leading AI system, widely deployed across China's tertiary hospitals since January 2025. Initially implemented in Shanghai's major medical institutions, it has since expanded nationwide, enhancing diagnostic accuracy, streamlining workflows, and improving patient management. AI-powered pathology, imaging analysis, and clinical decision support systems have demonstrated significant potential in optimizing medical processes and reducing the cognitive burden on healthcare professionals. However, the widespread adoption of AI in healthcare raises critical regulatory and ethical challenges, particularly regarding accountability in AI-assisted diagnosis and the risk of automation bias. The absence of a well-defined liability framework underscores the need for policies that ensure AI functions as an assistive tool rather than an autonomous decision-maker. With continued technological advancements, AI is expected to integrate multimodal data sources, such as genomics and radiomics, paving the way for precision medicine and personalized treatment strategies. The future of AI in healthcare depends on the development of transparent regulatory structures, industry collaboration, and adaptive governance frameworks that balance innovation with responsibility, ensuring equitable and effective AI-driven medical services.", 'abstract_zh': '人工智能（AI）在医疗领域的快速集成正 transforming 临床决策和医院运营。DeepSeek 已成为领先的 AI 系统，在2025年1月起广泛部署于中国三级医院。最初实施于上海主要医疗机构后，它已扩展至全国，增强了诊断准确性，简化了工作流程，改善了患者管理。基于 AI 的病理学、影像分析和临床决策支持系统展示了在优化医疗流程和减轻医疗服务人员认知负担方面的重要潜力。然而，AI 在医疗领域的广泛应用引发了关键的监管和伦理挑战，特别是与 AI 辅助诊断的责任归属以及自动化偏见的风险。缺乏明确的问责框架强调了制定政策的重要性，以确保 AI 作为辅助工具而非自主决策者发挥作用。随着技术的不断进步，AI 预计将集成多模态数据源，如基因组学和影像组学，为精准医疗和个人化治疗策略铺平道路。医疗领域中 AI 的未来取决于透明监管结构、行业合作和能够平衡创新与责任的适应性治理框架，确保公平有效的 AI 驱动医疗服务。', 'title_zh': 'DeepSeek重塑中国三级医院的医疗健康服务'}
{'arxiv_id': 'arXiv:2502.16730', 'title': 'RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents', 'authors': 'Sho Nakatani', 'link': 'https://arxiv.org/abs/2502.16730', 'abstract': 'We present RapidPen, a fully automated penetration testing (pentesting) framework that addresses\nthe challenge of achieving an initial foothold (IP-to-Shell) without human intervention. Unlike prior\napproaches that focus primarily on post-exploitation or require a human-in-the-loop, RapidPen\nleverages large language models (LLMs) to autonomously discover and exploit vulnerabilities, starting from\na single IP address. By integrating advanced ReAct-style task planning (Re) with retrieval-augmented\nknowledge bases of successful exploits, along with a command-generation and direct execution feedback loop\n(Act), RapidPen systematically scans services, identifies viable attack vectors, and executes targeted\nexploits in a fully automated manner.\nIn our evaluation against a vulnerable target from the Hack The Box platform, RapidPen achieved shell\naccess within 200-400 seconds at a per-run cost of approximately \\$0.3-\\$0.6, demonstrating a\n60\\% success rate when reusing prior "success-case" data. These results underscore the potential\nof truly autonomous pentesting for both security novices and seasoned professionals. Organizations\nwithout dedicated security teams can leverage RapidPen to quickly identify critical vulnerabilities,\nwhile expert pentesters can offload repetitive tasks and focus on complex challenges.\nUltimately, our work aims to make penetration testing more accessible and cost-efficient,\nthereby enhancing the overall security posture of modern software ecosystems.', 'abstract_zh': '快速渗透测试框架RapidPen：自动实现初始 foothold 的全自动化漏洞利用平台', 'title_zh': 'RapidPen: 基于LLM代理的完全自动化IP到Shell渗透测试方法'}
{'arxiv_id': 'arXiv:2502.16725', 'title': 'DOSE3 : Diffusion-based Out-of-distribution detection on SE(3) trajectories', 'authors': 'Hongzhe Cheng, Tianyou Zheng, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi', 'link': 'https://arxiv.org/abs/2502.16725', 'abstract': "Out-of-Distribution(OOD) detection, a fundamental machine learning task aimed at identifying abnormal samples, traditionally requires model retraining for different inlier distributions. While recent research demonstrates the applicability of diffusion models to OOD detection, existing approaches are limited to Euclidean or latent image spaces. Our work extends OOD detection to trajectories in the Special Euclidean Group in 3D ($\\mathbb{SE}(3)$), addressing a critical need in computer vision, robotics, and engineering applications that process object pose sequences in $\\mathbb{SE}(3)$. We present $\\textbf{D}$iffusion-based $\\textbf{O}$ut-of-distribution detection on $\\mathbb{SE}(3)$ ($\\mathbf{DOSE3}$), a novel OOD framework that extends diffusion to a unified sample space of $\\mathbb{SE}(3)$ pose sequences. Through extensive validation on multiple benchmark datasets, we demonstrate $\\mathbf{DOSE3}$'s superior performance compared to state-of-the-art OOD detection frameworks.", 'abstract_zh': '基于特殊欧几里得群$\\mathbb{SE}(3)$的扩散模型异常检测（$\\mathbf{DOSE3}$）', 'title_zh': 'DOSE3：基于扩散的SE(3)轨迹异类检测'}
{'arxiv_id': 'arXiv:2502.16722', 'title': 'Layer-Wise Evolution of Representations in Fine-Tuned Transformers: Insights from Sparse AutoEncoders', 'authors': 'Suneel Nadipalli', 'link': 'https://arxiv.org/abs/2502.16722', 'abstract': 'Fine-tuning pre-trained transformers is a powerful technique for enhancing the performance of base models on specific tasks. From early applications in models like BERT to fine-tuning Large Language Models (LLMs), this approach has been instrumental in adapting general-purpose architectures for specialized downstream tasks. Understanding the fine-tuning process is crucial for uncovering how transformers adapt to specific objectives, retain general representations, and acquire task-specific features. This paper explores the underlying mechanisms of fine-tuning, specifically in the BERT transformer, by analyzing activation similarity, training Sparse AutoEncoders (SAEs), and visualizing token-level activations across different layers. Based on experiments conducted across multiple datasets and BERT layers, we observe a steady progression in how features adapt to the task at hand: early layers primarily retain general representations, middle layers act as a transition between general and task-specific features, and later layers fully specialize in task adaptation. These findings provide key insights into the inner workings of fine-tuning and its impact on representation learning within transformer architectures.', 'abstract_zh': '预训练变压器的微调是一种增强基模型在特定任务上性能的强大技术。从早期的BERT模型应用到大型语言模型（LLMs）的微调，这一方法对于适应通用架构以应对专门的下游任务起到了关键作用。深入理解微调过程对于揭示变压器如何适应特定目标、保留通用表示并获得任务特定特征至关重要。本文通过分析激活相似性、训练稀疏自编码器（SAEs）以及可视化不同层的标记级激活，探讨了BERT变压器的微调机制。基于在多个数据集和BERT层次上的实验，我们观察到特征适应任务的过程呈现出稳步进展：早期层主要保留通用表示，中间层作为通用表示与任务特定特征之间的过渡，而后续层则完全专注于任务适应。这些发现对于我们理解微调的内部机制及其对变压器架构中表示学习的影响具有重要意义。', 'title_zh': '细调变换器中表示的逐层演进：来自稀疏自编码器的见解'}
{'arxiv_id': 'arXiv:2502.16721', 'title': 'Speed and Conversational Large Language Models: Not All Is About Tokens per Second', 'authors': 'Javier Conde, Miguel González, Pedro Reviriego, Zhen Gao, Shanshan Liu, Fabrizio Lombardi', 'link': 'https://arxiv.org/abs/2502.16721', 'abstract': 'The speed of open-weights large language models (LLMs) and its dependency on the task at hand, when run on GPUs, is studied to present a comparative analysis of the speed of the most popular open LLMs.', 'abstract_zh': '基于GPU运行时，开放权重大型语言模型（LLMs）的速度及其对任务的依赖性研究：面向流行开放LLM的速度比较分析', 'title_zh': '速度与对话型大规模语言模型：不仅关乎每秒令牌数'}
{'arxiv_id': 'arXiv:2502.16718', 'title': 'NatSGLD: A Dataset with Speech, Gesture, Logic, and Demonstration for Robot Learning in Natural Human-Robot Interaction', 'authors': 'Snehesh Shrestha, Yantian Zha, Saketh Banagiri, Ge Gao, Yiannis Aloimonos, Cornelia Fermüller', 'link': 'https://arxiv.org/abs/2502.16718', 'abstract': "Recent advances in multimodal Human-Robot Interaction (HRI) datasets emphasize the integration of speech and gestures, allowing robots to absorb explicit knowledge and tacit understanding. However, existing datasets primarily focus on elementary tasks like object pointing and pushing, limiting their applicability to complex domains. They prioritize simpler human command data but place less emphasis on training robots to correctly interpret tasks and respond appropriately. To address these gaps, we present the NatSGLD dataset, which was collected using a Wizard of Oz (WoZ) method, where participants interacted with a robot they believed to be autonomous. NatSGLD records humans' multimodal commands (speech and gestures), each paired with a demonstration trajectory and a Linear Temporal Logic (LTL) formula that provides a ground-truth interpretation of the commanded tasks. This dataset serves as a foundational resource for research at the intersection of HRI and machine learning. By providing multimodal inputs and detailed annotations, NatSGLD enables exploration in areas such as multimodal instruction following, plan recognition, and human-advisable reinforcement learning from demonstrations. We release the dataset and code under the MIT License at this https URL to support future HRI research.", 'abstract_zh': 'Recent Advances in Multimodal Human-Robot Interaction (HRI) Datasets Emphasize the Integration of Speech and Gestures: The NatSGLD Dataset Fills Gaps in Complex Task Understanding', 'title_zh': 'NatSGLD：一种用于自然人机交互中机器人学习的数据集，包含语音、手势、逻辑和演示内容'}
{'arxiv_id': 'arXiv:2502.16708', 'title': 'Exploring Incremental Unlearning: Techniques, Challenges, and Future Directions', 'authors': 'Sadia Qureshi, Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Jianming Yong, Xiaohua Jia', 'link': 'https://arxiv.org/abs/2502.16708', 'abstract': "The growing demand for data privacy in Machine Learning (ML) applications has seen Machine Unlearning (MU) emerge as a critical area of research. As the `right to be forgotten' becomes regulated globally, it is increasingly important to develop mechanisms that delete user data from AI systems while maintaining performance and scalability of these systems. Incremental Unlearning (IU) is a promising MU solution to address the challenges of efficiently removing specific data from ML models without the need for expensive and time-consuming full retraining. This paper presents the various techniques and approaches to IU. It explores the challenges faced in designing and implementing IU mechanisms. Datasets and metrics for evaluating the performance of unlearning techniques are discussed as well. Finally, potential solutions to the IU challenges alongside future research directions are offered. This survey provides valuable insights for researchers and practitioners seeking to understand the current landscape of IU and its potential for enhancing privacy-preserving intelligent systems.", 'abstract_zh': '机器学习应用中日益增长的数据隐私需求促使机器遗忘（Machine Unlearning, MU）成为关键研究领域。随着“被遗忘的权利”在全球范围内得到规范，开发能够在不影响这些系统性能和可扩展性的情况下从人工智能系统中删除用户数据的机制变得越来越重要。增量遗忘（Incremental Unlearning, IU）是一种有前景的MU解决方案，可以高效地从机器学习模型中删除特定数据，而无需进行昂贵且耗时的全面重新训练。本文介绍了各种IU技术及方法，探讨了设计和实现IU机制所面临的技术挑战，讨论了评估遗忘技术性能的데이터集和指标，并提出了应对IU挑战的潜在解决方案及未来的研究方向。这篇综述为寻求了解当前IU状况及其在保护隐私的智能系统中潜力的研究人员和实践者提供了宝贵的见解。', 'title_zh': '探索增量遗忘：技术、挑战与未来方向'}
{'arxiv_id': 'arXiv:2502.16707', 'title': 'Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon Robotic Manipulation', 'authors': 'Yunhai Feng, Jiaming Han, Zhuoran Yang, Xiangyu Yue, Sergey Levine, Jianlan Luo', 'link': 'https://arxiv.org/abs/2502.16707', 'abstract': 'Solving complex long-horizon robotic manipulation problems requires sophisticated high-level planning capabilities, the ability to reason about the physical world, and reactively choose appropriate motor skills. Vision-language models (VLMs) pretrained on Internet data could in principle offer a framework for tackling such problems. However, in their current form, VLMs lack both the nuanced understanding of intricate physics required for robotic manipulation and the ability to reason over long horizons to address error compounding issues. In this paper, we introduce a novel test-time computation framework that enhances VLMs\' physical reasoning capabilities for multi-stage manipulation tasks. At its core, our approach iteratively improves a pretrained VLM with a "reflection" mechanism - it uses a generative model to imagine future world states, leverages these predictions to guide action selection, and critically reflects on potential suboptimalities to refine its reasoning. Experimental results demonstrate that our method significantly outperforms several state-of-the-art commercial VLMs as well as other post-training approaches such as Monte Carlo Tree Search (MCTS). Videos are available at this https URL.', 'abstract_zh': '解决复杂的长时Horizon机器人操作问题需要高级规划能力、对物理世界的推理能力以及反应性地选择合适的运动技能。互联网数据预训练的视觉-语言模型（VLMs）原则上可以提供解决此类问题的框架。然而，当前形式的VLMs缺乏对于机器人操作所需的细致物理理解以及处理长期推理和错误累积问题的能力。在本文中，我们引入了一种新的测试时计算框架，以增强VLMs在多阶段操作任务中的物理推理能力。该方法的核心在于迭代地改进预训练的VLM，并通过“反思”机制使用生成模型来想象未来的世界状态，利用这些预测来指导行动选择，并对潜在的不足进行批判性反思以改进其推理。实验结果表明，我们的方法明显优于几种最新的商用VLMs以及包括蒙特卡罗树搜索（MCTS）在内的其他后训练方法。视频可在以下链接查看：this https URL。', 'title_zh': '反射规划：多阶段长期 horizon 机器人操作的视觉-语言模型'}
{'arxiv_id': 'arXiv:2502.16706', 'title': 'DISC: Dynamic Decomposition Improves LLM Inference Scaling', 'authors': 'Jonathan Light, Wei Cheng, Wu Yue, Masafumi Oyamada, Mengdi Wang, Santiago Paternain, Haifeng Chen', 'link': 'https://arxiv.org/abs/2502.16706', 'abstract': 'Many inference scaling methods work by breaking a problem into smaller steps (or groups of tokens), then sampling and choosing the best next step. However, these steps and their sizes are usually predetermined based on human intuition or domain knowledge. This paper introduces dynamic decomposition, a method that automatically and adaptively splits solution and reasoning traces into steps during inference. This approach improves computational efficiency by focusing more resources on difficult steps, breaking them down further and prioritizing their sampling. Experiments on coding and math benchmarks (APPS, MATH, and LiveCodeBench) show that dynamic decomposition performs better than static methods, which rely on fixed steps like token-level, sentence-level, or single-step decompositions. These results suggest that dynamic decomposition can enhance many inference scaling techniques.', 'abstract_zh': '动态分解：一种自动适应的推理拆分方法', 'title_zh': 'DISC: 动态分解优化大语言模型推理扩展'}
{'arxiv_id': 'arXiv:2502.16705', 'title': 'Can ChatGPT Learn to Count Letters?', 'authors': 'Javier Conde, Gonzalo Martínez, Pedro Reviriego, Zhen Gao, Shanshan Liu, Fabrizio Lombardi', 'link': 'https://arxiv.org/abs/2502.16705', 'abstract': 'Large language models (LLMs) struggle on simple tasks such as counting the number of occurrences of a letter in a word. In this paper, we investigate if ChatGPT can learn to count letters and propose an efficient solution.', 'abstract_zh': '大型语言模型（LLMs）在诸如统计单词中某个字母出现次数这类简单任务上表现不佳。本文我们探讨ChatGPT是否能学会计数字母，并提出一个有效的解决方案。', 'title_zh': 'ChatGPT能学会数字母吗？'}
{'arxiv_id': 'arXiv:2502.16704', 'title': 'Code Summarization Beyond Function Level', 'authors': 'Vladimir Makharev, Vladimir Ivanov', 'link': 'https://arxiv.org/abs/2502.16704', 'abstract': 'Code summarization is a critical task in natural language processing and software engineering, which aims to generate concise descriptions of source code. Recent advancements have improved the quality of these summaries, enhancing code readability and maintainability. However, the content of a repository or a class has not been considered in function code summarization. This study investigated the effectiveness of code summarization models beyond the function level, exploring the impact of class and repository contexts on the summary quality. The study involved revising benchmarks for evaluating models at class and repository levels, assessing baseline models, and evaluating LLMs with in-context learning to determine the enhancement of summary quality with additional context. The findings revealed that the fine-tuned state-of-the-art CodeT5+ base model excelled in code summarization, while incorporating few-shot learning and retrieved code chunks from RAG significantly enhanced the performance of LLMs in this task. Notably, the Deepseek Coder 1.3B and Starcoder2 15B models demonstrated substantial improvements in metrics such as BLEURT, METEOR, and BLEU-4 at both class and repository levels. Repository-level summarization exhibited promising potential but necessitates significant computational resources and gains from the inclusion of structured context. Lastly, we employed the recent SIDE code summarization metric in our evaluation. This study contributes to refining strategies for prompt engineering, few-shot learning, and RAG, addressing gaps in benchmarks for code summarization at various levels. Finally, we publish all study details, code, datasets, and results of evaluation in the GitHub repository available at this https URL.', 'abstract_zh': '代码总结是自然语言处理和软件工程中的关键任务，旨在生成源代码的简洁描述。近年来的进步提高了这些总结的质量，增强了代码的可读性和可维护性。然而，库或类的内容尚未在函数代码总结中加以考虑。本研究探讨了函数以上级别进行代码总结的有效性，研究了类和库上下文对总结质量的影响。研究修订了评估模型在类和库级别上的基准，评估了基线模型，并评估了具有上下文学习的LLMs，以确定额外上下文对总结质量的增强效果。研究发现，微调的最新CodeT5+基础模型在代码总结中表现出色，而结合少量学习和从RAG检索代码片段显著提升了LLMs在该任务上的性能。值得注意的是，Deepseek Coder 1.3B和Starcoder2 15B模型在BLEURT、METEOR和BLEU-4等指标上，在类和库级别上表现出显著改进。库级总结展现出巨大潜力，但需要大量计算资源，并且可以从结构化上下文的包含中获益。最后，我们使用了最近的SIDE代码总结指标进行评估。本研究为细化提示工程、少量学习和RAG策略做出了贡献，填补了代码总结基准在不同级别上的空白。最后，我们在以下GitHub仓库中发布了所有研究细节、代码、数据集和评估结果：[此 https URL]。', 'title_zh': '超越函数级别的心代码摘要'}
{'arxiv_id': 'arXiv:2502.16701', 'title': 'Beyond Release: Access Considerations for Generative AI Systems', 'authors': 'Irene Solaiman, Rishi Bommasani, Dan Hendrycks, Ariel Herbert-Voss, Yacine Jernite, Aviya Skowron, Andrew Trask', 'link': 'https://arxiv.org/abs/2502.16701', 'abstract': 'Generative AI release decisions determine whether system components are made available, but release does not address many other elements that change how users and stakeholders are able to engage with a system. Beyond release, access to system components informs potential risks and benefits. Access refers to practical needs, infrastructurally, technically, and societally, in order to use available components in some way. We deconstruct access along three axes: resourcing, technical usability, and utility. Within each category, a set of variables per system component clarify tradeoffs. For example, resourcing requires access to computing infrastructure to serve model weights. We also compare the accessibility of four high performance language models, two open-weight and two closed-weight, showing similar considerations for all based instead on access variables. Access variables set the foundation for being able to scale or increase access to users; we examine the scale of access and how scale affects ability to manage and intervene on risks. This framework better encompasses the landscape and risk-benefit tradeoffs of system releases to inform system release decisions, research, and policy.', 'abstract_zh': '生成式AI发布决策确定系统组件是否可供使用，但发布并不解决其他许多影响用户和利益相关者与系统互动的方式的元素。除了发布之外，系统组件的访问权限决定了潜在的风险和益处。访问涉及使用可用组件的实用需求，包括基础设施层面、技术层面和社会层面。我们将访问拆解为三个维度：资源、技术可用性和效用。在每个类别中，每个系统组件的一组变量明确了权衡。例如，资源需要访问计算基础设施来提供模型权重。我们还比较了四种高性能语言模型的可访问性，两种开源权重两种闭源权重，基于访问变量显示所有模型的相似考虑因素。访问变量奠定了能够扩展或增加用户访问的基础；我们探讨了访问范围及其对管理和应对风险能力的影响。这种框架更好地涵盖了系统的发布景观和风险收益权衡，以指导系统发布决策、研究和政策。', 'title_zh': '超越发布：生成式AI系统的内容访问考量'}
{'arxiv_id': 'arXiv:2502.16696', 'title': 'Dynamic LLM Routing and Selection based on User Preferences: Balancing Performance, Cost, and Ethics', 'authors': 'Deepak Babu Piskala, Vijay Raajaa, Sachin Mishra, Bruno Bozza', 'link': 'https://arxiv.org/abs/2502.16696', 'abstract': 'With the widespread deployment of large language models (LLMs) such as GPT4, BART, and LLaMA, the need for a system that can intelligently select the most suitable model for specific tasks while balancing cost, latency, accuracy, and ethical considerations has become increasingly important. Recognizing that not all tasks necessitate models with over 100 billion parameters, we introduce OptiRoute, an advanced model routing engine designed to dynamically select and route tasks to the optimal LLM based on detailed user-defined requirements. OptiRoute captures both functional (e.g., accuracy, speed, cost) and non-functional (e.g., helpfulness, harmlessness, honesty) criteria, leveraging lightweight task analysis and complexity estimation to efficiently match tasks with the best-fit models from a diverse array of LLMs. By employing a hybrid approach combining k-nearest neighbors (kNN) search and hierarchical filtering, OptiRoute optimizes for user priorities while minimizing computational overhead. This makes it ideal for real-time applications in cloud-based ML platforms, personalized AI services, and regulated industries.', 'abstract_zh': '随着大语言模型（LLMs）如GPT4、BART和LLaMA的广泛部署，一个能够智能地根据具体任务需求平衡成本、延迟、准确性和伦理考量选择最合适的模型的系统的需求日益重要。鉴于并非所有任务都需要超过100亿参数的模型，我们引入了OptiRoute，这是一种高级模型路由引擎，可以根据详细的用户定义要求动态选择和路由任务至最优的LLM。OptiRoute 捕捉功能性和非功能性标准（例如，准确度、速度、成本、有用性、无害性、诚实性），并通过轻量级任务分析和复杂性估计高效地将任务与多样化的LLM中最佳匹配模型相匹配。通过结合k最近邻（kNN）搜索和分层过滤的混合方法，OptiRoute 优化用户优先级，同时最小化计算开销。这使其适用于基于云的机器学习平台、个性化AI服务以及受监管行业中的实时应用。', 'title_zh': '基于用户偏好的动态大语言模型路由与选择：性能、成本与伦理的平衡'}
{'arxiv_id': 'arXiv:2502.16682', 'title': 'Automatic Input Rewriting Improves Translation with Large Language Models', 'authors': 'Dayeon Ki, Marine Carpuat', 'link': 'https://arxiv.org/abs/2502.16682', 'abstract': 'Can we improve machine translation (MT) with LLMs by rewriting their inputs automatically? Users commonly rely on the intuition that well-written text is easier to translate when using off-the-shelf MT systems. LLMs can rewrite text in many ways but in the context of MT, these capabilities have been primarily exploited to rewrite outputs via post-editing. We present an empirical study of 21 input rewriting methods with 3 open-weight LLMs for translating from English into 6 target languages. We show that text simplification is the most effective MT-agnostic rewrite strategy and that it can be improved further when using quality estimation to assess translatability. Human evaluation further confirms that simplified rewrites and their MT outputs both largely preserve the original meaning of the source and MT. These results suggest LLM-assisted input rewriting as a promising direction for improving translations.', 'abstract_zh': '通过自动重写输入文本，大规模语言模型能否改善机器翻译？', 'title_zh': '自动输入重写 improves 译文生成中的大规模语言模型'}
{'arxiv_id': 'arXiv:2502.16681', 'title': 'Are Sparse Autoencoders Useful? A Case Study in Sparse Probing', 'authors': 'Subhash Kantamneni, Joshua Engels, Senthooran Rajamanoharan, Max Tegmark, Neel Nanda', 'link': 'https://arxiv.org/abs/2502.16681', 'abstract': "Sparse autoencoders (SAEs) are a popular method for interpreting concepts represented in large language model (LLM) activations. However, there is a lack of evidence regarding the validity of their interpretations due to the lack of a ground truth for the concepts used by an LLM, and a growing number of works have presented problems with current SAEs. One alternative source of evidence would be demonstrating that SAEs improve performance on downstream tasks beyond existing baselines. We test this by applying SAEs to the real-world task of LLM activation probing in four regimes: data scarcity, class imbalance, label noise, and covariate shift. Due to the difficulty of detecting concepts in these challenging settings, we hypothesize that SAEs' basis of interpretable, concept-level latents should provide a useful inductive bias. However, although SAEs occasionally perform better than baselines on individual datasets, we are unable to design ensemble methods combining SAEs with baselines that consistently outperform ensemble methods solely using baselines. Additionally, although SAEs initially appear promising for identifying spurious correlations, detecting poor dataset quality, and training multi-token probes, we are able to achieve similar results with simple non-SAE baselines as well. Though we cannot discount SAEs' utility on other tasks, our findings highlight the shortcomings of current SAEs and the need to rigorously evaluate interpretability methods on downstream tasks with strong baselines.", 'abstract_zh': '基于稀疏自编码器的大型语言模型激活解释：挑战与展望', 'title_zh': '稀疏自编码器有用吗？一个关于稀疏探针的研究案例'}
{'arxiv_id': 'arXiv:2502.16671', 'title': 'MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models', 'authors': 'Hengzhi Li, Megan Tjandrasuwita, Yi R. Fung, Armando Solar-Lezama, Paul Pu Liang', 'link': 'https://arxiv.org/abs/2502.16671', 'abstract': "Socially intelligent AI that can understand and interact seamlessly with humans in daily lives is increasingly important as AI becomes more closely integrated with peoples' daily activities. However, current works in artificial social reasoning all rely on language-only, or language-dominant approaches to benchmark and training models, resulting in systems that are improving in verbal communication but struggle with nonverbal social understanding. To address this limitation, we tap into a novel source of data rich in nonverbal and social interactions -- mime videos. Mimes refer to the art of expression through gesture and movement without spoken words, which presents unique challenges and opportunities in interpreting non-verbal social communication. We contribute a new dataset called MimeQA, obtained by sourcing 221 videos from YouTube, through rigorous annotation and verification, resulting in a benchmark with 101 videos and 806 question-answer pairs. Using MimeQA, we evaluate state-of-the-art video large language models (vLLMs) and find that their overall accuracy ranges from 15-30%. Our analysis reveals that vLLMs often fail to ground imagined objects and over-rely on the text prompt while ignoring subtle nonverbal interactions. Our data resources are released at this https URL to inspire future work in foundation models that embody true social intelligence capable of interpreting non-verbal human interactions.", 'abstract_zh': '具有社交智能的AI在日常生活中能够理解并顺畅地与人类互动越来越重要，随着AI与人们的日常生活活动的融合更加紧密。然而，当前的社会推理研究工作主要依赖于语言_only或以语言为主的方法来进行基准测试和模型训练，导致系统在口头交流方面有所提升，但在非口头社会理解方面却存在问题。为了解决这一局限性，我们利用了一种富含非语言和社会互动的新数据源——默剧视频。默剧是指不使用有声语言而通过手势和动作来表达的艺术形式，这为解读非语言的社会沟通提供了独特的挑战和机会。我们贡献了一个新的数据集，名为MimeQA，通过严格的注释和验证从YouTube中收集了221个视频，形成了包含101个视频和806个问答对的基准数据集。利用MimeQA，我们评估了当前最先进的视频大型语言模型（vLLMs），发现其整体准确率范围为15%-30%。我们的分析表明，vLLMs经常无法将臆想的对象与现实对接，并过度依赖于文本提示，而忽略了微妙的非语言互动。我们已在此URL处发布了数据资源，以激发未来能够在基础模型中体现真正社交智能并能够解释非语言的人际互动的研究工作。', 'title_zh': 'MimeQA: 向非言语智能社会智能基础模型迈进'}
{'arxiv_id': 'arXiv:2502.16660', 'title': 'BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning', 'authors': 'Haiteng Zhao, Chang Ma, FangZhi Xu, Lingpeng Kong, Zhi-Hong Deng', 'link': 'https://arxiv.org/abs/2502.16660', 'abstract': 'The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at this https URL.', 'abstract_zh': '大型语言模型在生物通路推理中的应用及其挑战与解决方案', 'title_zh': 'BioMaze: 大型语言模型在生物途径推理中的基准测试与增强'}
{'arxiv_id': 'arXiv:2502.16648', 'title': 'Few-shot Continual Relation Extraction via Open Information Extraction', 'authors': 'Thiem Nguyen, Anh Nguyen, Quyen Tran, Tu Vu, Diep Nguyen, Linh Ngo, Thien Nguyen', 'link': 'https://arxiv.org/abs/2502.16648', 'abstract': 'Typically, Few-shot Continual Relation Extraction (FCRE) models must balance retaining prior knowledge while adapting to new tasks with extremely limited data. However, real-world scenarios may also involve unseen or undetermined relations that existing methods still struggle to handle. To address these challenges, we propose a novel approach that leverages the Open Information Extraction concept of Knowledge Graph Construction (KGC). Our method not only exposes models to all possible pairs of relations, including determined and undetermined labels not available in the training set, but also enriches model knowledge with diverse relation descriptions, thereby enhancing knowledge retention and adaptability in this challenging scenario. In the perspective of KGC, this is the first work explored in the setting of Continual Learning, allowing efficient expansion of the graph as the data evolves. Experimental results demonstrate our superior performance compared to other state-of-the-art FCRE baselines, as well as the efficiency in handling dynamic graph construction in this setting.', 'abstract_zh': '典型的少样本持续关系提取（FCRE）模型必须在极其有限的数据下平衡保留先前知识和适应新任务。然而，现实场景中还可能存在未见过或未确定的关系，现有方法仍然难以处理。为了解决这些挑战，我们提出了一种新颖的方法，该方法利用知识图构建（KGC）中的开放信息提取（Open IE）概念。我们的方法不仅使模型接触到所有可能的关系对，包括训练集中不可用的确定和未确定的标签，而且还通过丰富的关系描述来增强模型知识，从而在这一具有挑战性的场景中增强知识保留和适应性。从KGC的角度来看，这是首次在此持续学习的设置中探索此类工作，允许在数据演变时高效扩展图。实验结果表明，与现有的其他少样本持续关系提取（FCRE）基线相比，我们的方法性能更优，并且在该设置中高效处理动态图构建。', 'title_zh': '少量样本持续关系提取 via 开放信息提取'}
{'arxiv_id': 'arXiv:2502.16645', 'title': 'CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale', 'authors': 'Chenlong Wang, Zhaoyang Chu, Zhengxiang Cheng, Xuyi Yang, Kaiyue Qiu, Yao Wan, Zhou Zhao, Xuanhua Shi, Dongping Chen', 'link': 'https://arxiv.org/abs/2502.16645', 'abstract': "Large Language Models (LLMs) have exhibited exceptional performance in software engineering yet face challenges in adapting to continually evolving code knowledge, particularly regarding the frequent updates of third-party library APIs. This limitation, stemming from static pre-training datasets, often results in non-executable code or implementations with suboptimal safety and efficiency. To this end, this paper introduces CODESYNC, a data engine for identifying outdated code patterns and collecting real-time code knowledge updates from Python third-party libraries. Building upon CODESYNC, we develop CODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay synchronized with code evolution, which covers real-world updates for 220 APIs from six Python libraries. Our benchmark offers 3,300 test cases across three evaluation tasks and an update-aware instruction tuning dataset consisting of 2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs reveal that they struggle with dynamic code evolution, even with the support of advanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe that our benchmark can offer a strong foundation for the development of more effective methods for real-time code knowledge updating in the future. The experimental code and dataset are publicly available at: this https URL.", 'abstract_zh': '大型语言模型（LLMs）在软件工程中表现出色，但在适应不断演变的代码知识方面面临挑战，尤其在第三方库API的频繁更新方面。为解决这一问题，本文介绍了CODESYNC，这是一种数据引擎，用于识别过时的代码模式并从Python第三方库中收集实时代码知识更新。基于CODESYNC，我们开发了CODESYNCBENCH，这是一个全面的基准测试，用于评估LLMs保持与代码演变同步的能力，覆盖了六个Python库的220个API的实际更新。该基准提供了涵盖三个评估任务的3,300个测试用例和包含2,200个训练样本的更新感知指令调整数据集。对14个最先进的LLM的广泛实验表明，即使在先进知识更新方法（如DPO、ORPO和SimPO）的支持下，它们在处理动态代码演变时仍存在问题。我们认为，我们的基准可以为未来实时代码知识更新更有效方法的发展奠定坚实的基础。实验代码和数据集已在以下网址公开：this https URL。', 'title_zh': 'CODESYNC：大规模语言模型的动态代码进化同步'}
{'arxiv_id': 'arXiv:2502.16638', 'title': 'Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression', 'authors': 'Xiaoyi Qu, David Aponte, Colby Banbury, Daniel P. Robinson, Tianyu Ding, Kazuhito Koishida, Ilya Zharkov, Tianyi Chen', 'link': 'https://arxiv.org/abs/2502.16638', 'abstract': 'Structured pruning and quantization are fundamental techniques used to reduce the size of deep neural networks (DNNs) and typically are applied independently. Applying these techniques jointly via co-optimization has the potential to produce smaller, high-quality models. However, existing joint schemes are not widely used because of (1) engineering difficulties (complicated multi-stage processes), (2) black-box optimization (extensive hyperparameter tuning to control the overall compression), and (3) insufficient architecture generalization. To address these limitations, we present the framework GETA, which automatically and efficiently performs joint structured pruning and quantization-aware training on any DNNs. GETA introduces three key innovations: (i) a quantization-aware dependency graph (QADG) that constructs a pruning search space for generic quantization-aware DNN, (ii) a partially projected stochastic gradient method that guarantees layerwise bit constraints are satisfied, and (iii) a new joint learning strategy that incorporates interpretable relationships between pruning and quantization. We present numerical experiments on both convolutional neural networks and transformer architectures that show that our approach achieves competitive (often superior) performance compared to existing joint pruning and quantization methods.', 'abstract_zh': 'GETA：自动高效进行联合结构剪枝和量化训练的框架', 'title_zh': '自动联合结构剪裁与量化以实现高效神经网络训练与压缩'}
{'arxiv_id': 'arXiv:2502.16637', 'title': 'Time Series Domain Adaptation via Latent Invariant Causal Mechanism', 'authors': 'Ruichu Cai, Junxian Huang, Zhenhui Yang, Zijian Li, Emadeldeen Eldele, Min Wu, Fuchun Sun', 'link': 'https://arxiv.org/abs/2502.16637', 'abstract': 'Time series domain adaptation aims to transfer the complex temporal dependence from the labeled source domain to the unlabeled target domain. Recent advances leverage the stable causal mechanism over observed variables to model the domain-invariant temporal dependence. However, modeling precise causal structures in high-dimensional data, such as videos, remains challenging. Additionally, direct causal edges may not exist among observed variables (e.g., pixels). These limitations hinder the applicability of existing approaches to real-world scenarios. To address these challenges, we find that the high-dimension time series data are generated from the low-dimension latent variables, which motivates us to model the causal mechanisms of the temporal latent process. Based on this intuition, we propose a latent causal mechanism identification framework that guarantees the uniqueness of the reconstructed latent causal structures. Specifically, we first identify latent variables by utilizing sufficient changes in historical information. Moreover, by enforcing the sparsity of the relationships of latent variables, we can achieve identifiable latent causal structures. Built on the theoretical results, we develop the Latent Causality Alignment (LCA) model that leverages variational inference, which incorporates an intra-domain latent sparsity constraint for latent structure reconstruction and an inter-domain latent sparsity constraint for domain-invariant structure reconstruction. Experiment results on eight benchmarks show a general improvement in the domain-adaptive time series classification and forecasting tasks, highlighting the effectiveness of our method in real-world scenarios. Codes are available at this https URL.', 'abstract_zh': '时间序列领域适应旨在将标记的源域的复杂时间依赖性转移到未标记的目标域。近期进展利用观察变量上的稳定因果机制来建模域不变的时间依赖性。然而，在高维数据（如视频）中精确建模因果结构仍然具有挑战性。此外，观察变量之间可能存在直接的因果边（例如，像素之间）。这些局限性限制了现有方法在实际场景中的应用。为应对这些挑战，我们发现高维时间序列数据是由低维潜在变量生成的，这促使我们建模潜在时间过程中的因果机制。基于这一直觉，我们提出了一种保证重构的潜在因果结构唯一性的潜在因果机制识别框架。具体来说，我们首先通过利用历史信息中的足够变化来识别潜在变量。通过限制潜在变量间关系的稀疏性，我们能实现可识别的潜在因果结构。基于理论结果，我们开发了潜在因果对齐（LCA）模型，该模型利用变分推理，结合域内潜在稀疏约束进行潜在结构重建和跨域潜在稀疏约束进行域不变结构重建。在八个基准上的实验结果显示，该方法在领域适应的时间序列分类和预测任务中普遍提高，突显了其在实际场景中的有效性。代码可在此处获取。', 'title_zh': '时间序列领域适应通过潜在不变因果机制'}
{'arxiv_id': 'arXiv:2502.16627', 'title': 'Energy-Efficient Transformer Inference: Optimization Strategies for Time Series Classification', 'authors': 'Arshia Kermani, Ehsan Zeraatkar, Habib Irani', 'link': 'https://arxiv.org/abs/2502.16627', 'abstract': 'The increasing computational demands of transformer models in time series classification necessitate effective optimization strategies for energy-efficient deployment. This paper presents a systematic investigation of optimization techniques, focusing on structured pruning and quantization methods for transformer architectures. Through extensive experimentation on three distinct datasets (RefrigerationDevices, ElectricDevices, and PLAID), we quantitatively evaluate model performance and energy efficiency across different transformer configurations. Our experimental results demonstrate that static quantization reduces energy consumption by 29.14% while maintaining classification performance, and L1 pruning achieves a 1.63% improvement in inference speed with minimal accuracy degradation. These findings provide valuable insights into the effectiveness of optimization strategies for transformer-based time series classification, establishing a foundation for efficient model deployment in resource-constrained environments.', 'abstract_zh': 'Transformer模型在时间序列分类中的不断增加的计算需求 necessitates 有效的优化策略以实现能效部署。本文系统研究了优化技术，重点关注 Transformer 架构的结构剪枝和量化方法。通过对三个不同的数据集（RefrigerationDevices、ElectricDevices 和 PLAID）进行广泛的实验，我们定量评估了不同 Transformer 配置下的模型性能和能效。实验结果显示，静态量化可将能效消耗降低 29.14% 同时保持分类性能，而 L1 剪枝则将推理速度提高 1.63% 并且几乎没有准确率下降。这些发现为基于 Transformer 的时间序列分类的优化策略的有效性提供了有价值的见解，为资源受限环境下的高效模型部署奠定了基础。', 'title_zh': '高效的变压器推理：时间序列分类的优化策略'}
{'arxiv_id': 'arXiv:2502.16618', 'title': 'Can Large Vision-Language Models Detect Images Copyright Infringement from GenAI?', 'authors': 'Qipan Xu, Zhenting Wang, Xiaoxiao He, Ligong Han, Ruixiang Tang', 'link': 'https://arxiv.org/abs/2502.16618', 'abstract': 'Generative AI models, renowned for their ability to synthesize high-quality content, have sparked growing concerns over the improper generation of copyright-protected material. While recent studies have proposed various approaches to address copyright issues, the capability of large vision-language models (LVLMs) to detect copyright infringements remains largely unexplored. In this work, we focus on evaluating the copyright detection abilities of state-of-the-art LVLMs using a various set of image samples. Recognizing the absence of a comprehensive dataset that includes both IP-infringement samples and ambiguous non-infringement negative samples, we construct a benchmark dataset comprising positive samples that violate the copyright protection of well-known IP figures, as well as negative samples that resemble these figures but do not raise copyright concerns. This dataset is created using advanced prompt engineering techniques. We then evaluate leading LVLMs using our benchmark dataset. Our experimental results reveal that LVLMs are prone to overfitting, leading to the misclassification of some negative samples as IP-infringement cases. In the final section, we analyze these failure cases and propose potential solutions to mitigate the overfitting problem.', 'abstract_zh': '生成式AI模型因其生成高质量内容的能力而闻名，但过度生成受版权保护的材料引发了日益增长的担忧。虽然近期研究提出了一些解决版权问题的方法，但大型视觉-语言模型（LVLMs）检测版权侵权的能力尚未得到充分探索。在本研究中，我们利用多种图像样本评估最先进的LVLMs的版权检测能力。鉴于缺乏一个包含IP侵权样本和模糊的非侵权负样本的全面数据集，我们构建了一个基准数据集，该数据集包含侵犯知名IP形象版权的正样本，以及相似但不引发版权担忧的负样本。该数据集使用高级提示工程技巧构建。然后，我们使用基准数据集评估领先的LVLMs。实验结果表明，LVLMs容易过拟合，导致一些负样本被误分类为IP侵权案例。在最终部分，我们分析了这些失败案例，并提出可能的解决方案以缓解过拟合问题。', 'title_zh': '大规模vision-language模型能否检测来自GenAI的图像版权侵权？'}
{'arxiv_id': 'arXiv:2502.16613', 'title': 'Intelligent Tutors Beyond K-12: An Observational Study of Adult Learner Engagement and Academic Impact', 'authors': 'Adit Gupta, Christopher MacLellan', 'link': 'https://arxiv.org/abs/2502.16613', 'abstract': 'Intelligent tutors have proven to be effective in K-12 education, though their impact on adult learners -- especially as a supplementary resource -- remains underexplored. Understanding how adults voluntarily engage with educational technologies can inform the design of tools that support skill re-learning and enhancement. More critically, it helps determine whether tutoring systems, which are typically built for K-12 learners, can also support adult populations. This study examines the adoption, usage patterns, and effectiveness of a novel tutoring system, Apprentice Tutors, among adult learners at a state technical college. We analyze three types of data including, user demographics, grades, and tutor interactions, to assess whether voluntary tutor usage translates into measurable learning gains. Our findings reveal key temporal patterns in tutor engagement and provide evidence of learning within tutors, as determined through skill improvement in knowledge components across tutors. We also found evidence that this learning transferred outside the tutor, as observed through higher course assessment scores following tutor usage. These results suggest that intelligent tutors are a viable tool for adult learners, warranting further research into their long-term impact on this population.', 'abstract_zh': '智能辅导系统在K-12教育中已被证明有效，尽管它们作为补充资源对成人学习者的影响仍然未被充分探索。了解成人自愿使用教育技术的方法可以为支持技能重学和提升的设计提供信息。更为关键的是，这有助于确定通常为K-12学生设计的教学系统是否也能支持成人学习者群体。本研究 examine 成人技术学院学生采用、使用模式和新型辅导系统 Apprentice Tutors 的有效性。我们分析用户 demographics、成绩和辅导互动三种数据，以评估自愿使用辅导系统的衡量学习成效。我们的发现揭示了辅导参与的关键时间模式，并通过辅导者知识组件技能提高证实了学习的发生。此外，我们还发现这种学习转移至辅导之外，通过使用者课程评估分数提高得以观察。这些结果表明，智能辅导系统是成人学习者的可行工具，值得进一步研究其对该群体的长期影响。', 'title_zh': '智能导师超越K-12教育：成人学习者参与度及其学术影响的观察研究'}
{'arxiv_id': 'arXiv:2502.16612', 'title': 'MemeIntel: Explainable Detection of Propagandistic and Hateful Memes', 'authors': 'Mohamed Bayan Kmainasi, Abul Hasnat, Md Arid Hasan, Ali Ezzat Shahroor, Firoj Alam', 'link': 'https://arxiv.org/abs/2502.16612', 'abstract': 'The proliferation of multimodal content on social media presents significant challenges in understanding and moderating complex, context-dependent issues such as misinformation, hate speech, and propaganda. While efforts have been made to develop resources and propose new methods for automatic detection, limited attention has been given to label detection and the generation of explanation-based rationales for predicted labels. To address this challenge, we introduce MemeIntel, an explanation-enhanced dataset for propaganda memes in Arabic and hateful memes in English, making it the first large-scale resource for these tasks. To solve these tasks, we propose a multi-stage optimization approach and train Vision-Language Models (VLMs). Our results demonstrate that this approach significantly improves performance over the base model for both \\textbf{label detection} and explanation generation, outperforming the current state-of-the-art with an absolute improvement of ~3% on ArMeme and ~7% on Hateful Memes. For reproducibility and future research, we aim to make the MemeIntel dataset and experimental resources publicly available.', 'abstract_zh': '社交媒体上多模态内容的泛滥为理解和 moderating 如虚假信息、仇恨言论和宣传等复杂、情境依赖性问题带来了重大挑战。尽管已经做出了努力来开发资源和提出新的自动检测方法，但对标签检测和基于解释的理由生成的关注仍然有限。为应对这一挑战，我们介绍了 MemeIntel，这是一个增强解释的数据集，包含阿拉伯语宣传模因和英语仇恨模因，使其成为这些任务上的首个大规模资源。为了解决这些任务，我们提出了一个多阶段优化方法，并训练了视觉-语言模型（VLMs）。我们的结果表明，这种方法在标签检测和解释生成上显著提升了基线模型的表现，在ArMeme上绝对提升了约3%，在仇恨模因上提升了约7%，超越了当前最先进方法。为了可再现性和未来研究，我们致力于使MemeIntel数据集和实验资源公开可用。', 'title_zh': 'MemeIntel: 可解释的 propagandistic 和 hateful 病毒贴图检测'}
{'arxiv_id': 'arXiv:2502.16611', 'title': 'Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments', 'authors': 'Shitong Xu, Yiyuan Yang, Niki Trigoni, Andrew Markham', 'link': 'https://arxiv.org/abs/2502.16611', 'abstract': "Target speaker extraction focuses on isolating a specific speaker's voice from an audio mixture containing multiple speakers. To provide information about the target speaker's identity, prior works have utilized clean audio examples as conditioning inputs. However, such clean audio examples are not always readily available (e.g. It is impractical to obtain a clean audio example of a stranger's voice at a cocktail party without stepping away from the noisy environment). Limited prior research has explored extracting the target speaker's characteristics from noisy audio examples, which may include overlapping speech from disturbing speakers. In this work, we focus on target speaker extraction when multiple speakers are present during the enrollment stage, through leveraging differences between audio segments where the target speakers are speaking (Positive Enrollments) and segments where they are not (Negative Enrollments). Experiments show the effectiveness of our model architecture and the dedicated pretraining method for the proposed task. Our method achieves state-of-the-art performance in the proposed application settings and demonstrates strong generalizability across challenging and realistic scenarios.", 'abstract_zh': '多说话人环境下目标说话人提取专注于从包含多个说话人的音频混合中分离出特定说话人的声音。以往的工作利用干净的音频示例作为条件输入以提供目标说话人身份的相关信息，然而在嘈杂环境中获得陌生人的干净音频示例往往是不现实的。少数早期研究探索了从包含干扰说话人重叠语音的嘈杂音频示例中提取目标说话人特征的可能性。本文在注册阶段存在多个说话人的情况下，通过利用目标说话人发言（正注册）和不发言（负注册）的音频片段之间的差异，专注于目标说话人提取。实验表明，我们提出的模型架构和专门的预训练方法对于目标说话人提取任务非常有效，我们的方法在所提出的应用场景中达到了最先进的性能，并在具有挑战性和现实性的场景中展示了强大的泛化能力。', 'title_zh': '通过比较噪声正样本和噪声负样本进行目标说话人提取'}
{'arxiv_id': 'arXiv:2502.16610', 'title': 'AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs', 'authors': 'Francisco Caetano, Christiaan Viviers, Lena Filatova, Peter H. N. de With, Fons van der Sommen', 'link': 'https://arxiv.org/abs/2502.16610', 'abstract': "Ensuring the quality and integrity of medical images is crucial for maintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosis and Computer-Aided Detection (CAD) systems. Covariate shifts are subtle variations in the data distribution caused by different imaging devices or settings and can severely degrade model performance, similar to the effects of adversarial attacks. Therefore, it is vital to have a lightweight and fast method to assess the quality of these images prior to using CAD models. AdverX-Ray addresses this need by serving as an image-quality assessment layer, designed to detect covariate shifts effectively. This Adversarial Variational Autoencoder prioritizes the discriminator's role, using the suboptimal outputs of the generator as negative samples to fine-tune the discriminator's ability to identify high-frequency artifacts. Images generated by adversarial networks often exhibit severe high-frequency artifacts, guiding the discriminator to focus excessively on these components. This makes the discriminator ideal for this approach. Trained on patches from X-ray images of specific machine models, AdverX-Ray can evaluate whether a scan matches the training distribution, or if a scan from the same machine is captured under different settings. Extensive comparisons with various OOD detection methods show that AdverX-Ray significantly outperforms existing techniques, achieving a 96.2% average AUROC using only 64 random patches from an X-ray. Its lightweight and fast architecture makes it suitable for real-time applications, enhancing the reliability of medical imaging systems. The code and pretrained models are publicly available.", 'abstract_zh': '确保医学图像的质量和完整性对于维持基于深度学习的计算机辅助诊断和检测(CAD)系统的诊断准确性至关重要。AdverX-Ray通过 Serving as an 图像质量评估层，有效检测协变量偏移，解决这一需求。基于对抗变分自编码器，该方法优先考虑判别器的作用，利用生成器的次优输出作为负样本，以精细化判别器识别高频伪影的能力。由对抗网络生成的图像常常表现出严重的高频伪影，这使判别器过度关注这些成分。AdverX-Ray 仅使用 X 射线特定机器模型图像的 64 个随机补丁块进行训练，即可评估扫描是否匹配训练分布，或在相同机器的不同设置下捕捉扫描。与各种OOD检测方法的广泛比较显示，AdverX-Ray 显著优于现有技术，平均AUROC达到96.2%。其轻量级和快速架构使其适合实时应用，提高医学成像系统的可靠性。代码和预训练模型已开源。', 'title_zh': 'AdverX-Ray：通过频率敏感对抗变分自编码器确保X射线完整性'}
{'arxiv_id': 'arXiv:2502.16602', 'title': 'VidLBEval: Benchmarking and Mitigating Language Bias in Video-Involved LVLMs', 'authors': 'Yiming Yang, Yangyang Guo, Hui Lu, Yan Wang', 'link': 'https://arxiv.org/abs/2502.16602', 'abstract': 'Recently, Large Vision-Language Models (LVLMs) have made significant strides across diverse multimodal tasks and benchmarks. This paper reveals a largely under-explored problem from existing video-involved LVLMs - language bias, where models tend to prioritize language over video and thus result in incorrect responses. To address this research gap, we first collect a Video Language Bias Evaluation Benchmark, which is specifically designed to assess the language bias in video-involved LVLMs through two key tasks: ambiguous video contrast and interrogative question probing. Accordingly, we design accompanied evaluation metrics that aim to penalize LVLMs being biased by language. In addition, we also propose Multi-branch Contrastive Decoding (MCD), introducing two expert branches to simultaneously counteract language bias potentially generated by the amateur text-only branch. Our experiments demonstrate that i) existing video-involved LVLMs, including both proprietary and open-sourced, are largely limited by the language bias problem; ii) our MCD can effectively mitigate this issue and maintain general-purpose capabilities in various video-involved LVLMs without any additional retraining or alteration to model architectures.', 'abstract_zh': '最近，大型视觉-语言模型（LVLMs）在多种跨模态任务和基准测试中取得了显著进展。本文揭示了现有视频涉及的LVLMs中一个未充分探索的问题——语言偏见，其中模型倾向于优先考虑语言而忽视视频，从而导致错误的回答。为填补这一研究空白，我们首先集合了一个视频语言偏见评估基准，通过两个关键任务设计来评估视频涉及的LVLMs中的语言偏见：模糊视频对比和疑问句探查。相应地，我们设计了配套的评估指标，旨在惩罚LVLMs因语言而产生的偏见。此外，我们还提出了多分支对比解码（MCD），引入了两个专家分支以同时对抗业余文本分支可能产生的语言偏见。实验表明：i) 现有的视频涉及的LVLMs，无论是专有的还是开源的，都受到语言偏见问题的严重影响；ii) 我们的MCD能够有效地缓解这一问题，在各种视频涉及的LVLMs中维持通用功能，无需额外的重新训练或修改模型架构。', 'title_zh': 'VidLBEval: 视频关联LVLM的语言偏见评估与缓解'}
{'arxiv_id': 'arXiv:2502.16589', 'title': 'Co-MTP: A Cooperative Trajectory Prediction Framework with Multi-Temporal Fusion for Autonomous Driving', 'authors': 'Xinyu Zhang, Zewei Zhou, Zhaoyi Wang, Yangjie Ji, Yanjun Huang, Hong Chen', 'link': 'https://arxiv.org/abs/2502.16589', 'abstract': "Vehicle-to-everything technologies (V2X) have become an ideal paradigm to extend the perception range and see through the occlusion. Exiting efforts focus on single-frame cooperative perception, however, how to capture the temporal cue between frames with V2X to facilitate the prediction task even the planning task is still underexplored. In this paper, we introduce the Co-MTP, a general cooperative trajectory prediction framework with multi-temporal fusion for autonomous driving, which leverages the V2X system to fully capture the interaction among agents in both history and future domains to benefit the planning. In the history domain, V2X can complement the incomplete history trajectory in single-vehicle perception, and we design a heterogeneous graph transformer to learn the fusion of the history feature from multiple agents and capture the history interaction. Moreover, the goal of prediction is to support future planning. Thus, in the future domain, V2X can provide the prediction results of surrounding objects, and we further extend the graph transformer to capture the future interaction among the ego planning and the other vehicles' intentions and obtain the final future scenario state under a certain planning action. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and the results show that Co-MTP achieves state-of-the-art performance and that both history and future fusion can greatly benefit prediction.", 'abstract_zh': 'Vehicle-to-Everything技术（V2X）已成为扩展感知范围并穿透遮挡的理想范式。现有努力集中在单帧协同感知上，然而，如何利用V2X捕捉帧间的时间线索以辅助预测任务乃至规划任务仍然有待探索。在本文中，我们提出了Co-MTP，一种基于多时序融合的自主驾驶通用协同轨迹预测框架，利用V2X系统全面捕捉历史和未来领域中的 agent 交互，以利于规划。在历史领域，V2X可以补充单车辆感知中的不完整历史轨迹，我们设计了一个异构图变换器来学习多agent的历史特征融合并捕捉历史交互。此外，预测的目标是支持未来的规划。因此，在未来领域，V2X可以提供周围物体的预测结果，并进一步扩展图变换器以捕捉自主规划与其他车辆意图之间的未来交互，从而在特定规划行动下获取最终的未来场景状态。我们在现实世界数据集V2X-Seq上评估了Co-MTP框架，结果表明Co-MTP取得了最先进的性能，并且历史和未来融合可以显著提高预测效果。', 'title_zh': 'Co-MTP：一种基于多时态融合的协同轨迹预测框架用于自动驾驶'}
{'arxiv_id': 'arXiv:2502.16584', 'title': 'Audio-FLAN: A Preliminary Release', 'authors': 'Liumeng Xue, Ziya Zhou, Jiahao Pan, Zixuan Li, Shuai Fan, Yinghao Ma, Sitong Cheng, Dongchao Yang, Haohan Guo, Yujia Xiao, Xinsheng Wang, Zixuan Shen, Chuanbo Zhu, Xinshen Zhang, Tianchi Liu, Ruibin Yuan, Zeyue Tian, Haohe Liu, Emmanouil Benetos, Ge Zhang, Yike Guo, Wei Xue', 'link': 'https://arxiv.org/abs/2502.16584', 'abstract': 'Recent advancements in audio tokenization have significantly enhanced the integration of audio capabilities into large language models (LLMs). However, audio understanding and generation are often treated as distinct tasks, hindering the development of truly unified audio-language models. While instruction tuning has demonstrated remarkable success in improving generalization and zero-shot learning across text and vision, its application to audio remains largely unexplored. A major obstacle is the lack of comprehensive datasets that unify audio understanding and generation. To address this, we introduce Audio-FLAN, a large-scale instruction-tuning dataset covering 80 diverse tasks across speech, music, and sound domains, with over 100 million instances. Audio-FLAN lays the foundation for unified audio-language models that can seamlessly handle both understanding (e.g., transcription, comprehension) and generation (e.g., speech, music, sound) tasks across a wide range of audio domains in a zero-shot manner. The Audio-FLAN dataset is available on HuggingFace and GitHub and will be continuously updated.', 'abstract_zh': '近期在音频分词领域取得的进展显著增强了将音频能力集成到大型语言模型中的能力。然而，音频理解和生成通常被视为独立任务，阻碍了真正统一的音频-语言模型的发展。虽然指令调优已在文本和视觉领域展示了卓越的推广能力和零样本学习性能，但其在音频领域的应用仍然基本未被探索。主要障碍是缺乏统一音频理解和生成的综合性数据集。为解决这一问题，我们引入了Audio-FLAN，这是一个涵盖80个跨语音、音乐和声音领域的多样化任务的大规模指令调优数据集，包含超过1亿个实例。Audio-FLAN 为零样本方式处理广泛音频领域中的理解任务（例如，转录、理解）和生成任务（例如，语音、音乐、声音）奠定了基础。Audio-FLAN 数据集可在 HuggingFace 和 GitHub 上获取，并将持续更新。', 'title_zh': '音频-FLAN：初步发布'}
{'arxiv_id': 'arXiv:2502.16570', 'title': 'Entropy-Lens: The Information Signature of Transformer Computations', 'authors': 'Riccardo Ali, Francesco Caso, Christopher Irwin, Pietro Liò', 'link': 'https://arxiv.org/abs/2502.16570', 'abstract': 'Transformer models have revolutionized fields from natural language processing to computer vision, yet their internal computational dynamics remain poorly understood raising concerns about predictability and robustness. In this work, we introduce Entropy-Lens, a scalable, model-agnostic framework that leverages information theory to interpret frozen, off-the-shelf large-scale transformers. By quantifying the evolution of Shannon entropy within intermediate residual streams, our approach extracts computational signatures that distinguish model families, categorize task-specific prompts, and correlate with output accuracy. We further demonstrate the generality of our method by extending the analysis to vision transformers. Our results suggest that entropy-based metrics can serve as a principled tool for unveiling the inner workings of modern transformer architectures.', 'abstract_zh': '基于熵的解析框架揭示大规模预训练变压器内部计算动力学', 'title_zh': '熵镜：Transformer 计算的信息特征'}
{'arxiv_id': 'arXiv:2502.16565', 'title': 'The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems', 'authors': 'Zengqing Wu, Takayuki Ito', 'link': 'https://arxiv.org/abs/2502.16565', 'abstract': 'Consensus formation is pivotal in multi-agent systems (MAS), balancing collective coherence with individual diversity. Conventional LLM-based MAS primarily rely on explicit coordination, e.g., prompts or voting, risking premature homogenization. We argue that implicit consensus, where agents exchange information yet independently form decisions via in-context learning, can be more effective in dynamic environments that require long-horizon adaptability. By retaining partial diversity, systems can better explore novel strategies and cope with external shocks. We formalize a consensus-diversity tradeoff, showing conditions where implicit methods outperform explicit ones. Experiments on three scenarios -- Dynamic Disaster Response, Information Spread and Manipulation, and Dynamic Public-Goods Provision -- confirm partial deviation from group norms boosts exploration, robustness, and performance. We highlight emergent coordination via in-context learning, underscoring the value of preserving diversity for resilient decision-making.', 'abstract_zh': '共识形成在多代理系统（MAS）中至关重要，平衡集体一致性和个体多样性。传统的基于LLM的MAS主要依赖显式协调，如提示或投票，这可能导致过早的同质化。我们认为，在代理人通过上下文学习独立形成决策的信息交换中形成的隐式共识，在需要长期适应性的情境下可能更为有效。通过保留部分多样性，系统能够更好地探索新策略并应对外部冲击。我们正式化了共识与多样性的权衡，并展示了隐式方法在特定条件下的优越性。在动态灾难响应、信息传播与操控以及动态公共品供给三个场景的实验中，部分偏离群体规范被证明可以增强探索性、稳健性和性能。我们强调了通过上下文学习 emergent 协调的价值，并突出了保留多样性对于容性决策的重要性。', 'title_zh': '隐藏的分歧力量：破解适应性多agent系统中的共识-多样性权衡'}
{'arxiv_id': 'arXiv:2502.16556', 'title': 'Beyond Words: How Large Language Models Perform in Quantitative Management Problem-Solving', 'authors': 'Jonathan Kuzmanko', 'link': 'https://arxiv.org/abs/2502.16556', 'abstract': "This study examines how Large Language Models (LLMs) perform when tackling quantitative management decision problems in a zero-shot setting. Drawing on 900 responses generated by five leading models across 20 diverse managerial scenarios, our analysis explores whether these base models can deliver accurate numerical decisions under varying presentation formats, scenario complexities, and repeated attempts. Contrary to prior findings, we observed no significant effects of text presentation format (direct, narrative, or tabular) or text length on accuracy. However, scenario complexity -- particularly in terms of constraints and irrelevant parameters -- strongly influenced performance, often degrading accuracy. Surprisingly, the models handled tasks requiring multiple solution steps more effectively than expected. Notably, only 28.8\\% of responses were exactly correct, highlighting limitations in precision. We further found no significant ``learning effect'' across iterations: performance remained stable across repeated queries. Nonetheless, significant variations emerged among the five tested LLMs, with some showing superior binary accuracy. Overall, these findings underscore both the promise and the pitfalls of harnessing LLMs for complex quantitative decision-making, informing managers and researchers about optimal deployment strategies.", 'abstract_zh': '本研究探讨了大型语言模型（LLMs）在零样本设置下处理定量管理决策问题的表现。通过分析五个领先模型在20种不同管理情境下生成的900个响应，我们的分析探索了这些基础模型在不同呈现格式、情景复杂度和多次尝试下能否提供准确的数值决策。与先前的研究发现不同，我们未发现文本呈现格式（直接、叙述性或表格形式）或文本长度对准确性有显著影响。然而，情景复杂度——尤其是约束条件和无关参数——对模型表现产生了显著影响，经常导致准确度下降。令人意外的是，模型在需要多步解决的任务上表现超过了预期。值得注意的是，只有28.8%的响应完全正确，突显了精度方面的局限性。进一步的研究发现，这些模型在多次迭代中没有显著的“学习效果”，性能在重复查询中保持稳定。然而，五个测试的LLM之间出现了显著差异，一些模型在二元准确度上表现出色。总体而言，这些发现强调了利用LLMs进行复杂定量决策的潜力与挑战，为管理者和研究人员提供了优化部署策略的参考。', 'title_zh': '超越文字：大规模语言模型在定量管理问题解决中的表现'}
{'arxiv_id': 'arXiv:2502.16548', 'title': 'Composable Strategy Framework with Integrated Video-Text based Large Language Models for Heart Failure Assessment', 'authors': 'Jianzhou Chen, Xiumei Wang, Jinyang Sun, Xi Chen, Heyu Chu, Guo Song, Yuji Luo, Xingping Zhou, Rong Gu', 'link': 'https://arxiv.org/abs/2502.16548', 'abstract': 'Heart failure is one of the leading causes of death worldwide, with millons of deaths each year, according to data from the World Health Organization (WHO) and other public health agencies. While significant progress has been made in the field of heart failure, leading to improved survival rates and improvement of ejection fraction, there remains substantial unmet needs, due to the complexity and multifactorial characteristics. Therefore, we propose a composable strategy framework for assessment and treatment optimization in heart failure. This framework simulates the doctor-patient consultation process and leverages multi-modal algorithms to analyze a range of data, including video, physical examination, text results as well as medical history. By integrating these various data sources, our framework offers a more holistic evaluation and optimized treatment plan for patients. Our results demonstrate that this multi-modal approach outperforms single-modal artificial intelligence (AI) algorithms in terms of accuracy in heart failure (HF) prognosis prediction. Through this method, we can further evaluate the impact of various pathological indicators on HF prognosis,providing a more comprehensive evaluation.', 'abstract_zh': '心力衰竭是全球范围内导致死亡的重要原因之一，根据世界卫生组织（WHO）和其他公共卫生机构的数据，每年有数百万例死亡。尽管在心力衰竭领域取得了显著进展，提高了生存率并改善了射血分数，但由于其复杂性和多重因素的特性，仍存在大量的未满足需求。因此，我们提出了一种可组装策略框架，用于心力衰竭的评估和治疗优化。该框架模拟了医生与患者咨询的过程，并利用多模态算法分析视频、体格检查、文本结果以及医疗史等多种数据。通过集成这些多种数据源，本框架提供了更为全面的评估和优化治疗方案。我们的结果显示，多模态方法在心力衰竭预后预测准确性方面优于单一模态的人工智能（AI）算法。通过这种方法，我们可以进一步评估各种病理指标对心力衰竭预后的影响，提供更为全面的评估。', 'title_zh': '可组合策略框架：集成视频-文本大型语言模型在心力衰竭评估中的应用'}
{'arxiv_id': 'arXiv:2502.16540', 'title': 'Advanced Chain-of-Thought Reasoning for Parameter Extraction from Documents Using Large Language Models', 'authors': 'Hong Cai Chen, Yi Pin Xu, Yang Zhang', 'link': 'https://arxiv.org/abs/2502.16540', 'abstract': "Extracting parameters from technical documentation is crucial for ensuring design precision and simulation reliability in electronic design. However, current methods struggle to handle high-dimensional design data and meet the demands of real-time processing. In electronic design automation (EDA), engineers often manually search through extensive documents to retrieve component parameters required for constructing PySpice models, a process that is both labor-intensive and time-consuming. To address this challenge, we propose an innovative framework that leverages large language models (LLMs) to automate the extraction of parameters and the generation of PySpice models directly from datasheets. Our framework introduces three Chain-of-Thought (CoT) based techniques: (1) Targeted Document Retrieval (TDR), which enables the rapid identification of relevant technical sections; (2) Iterative Retrieval Optimization (IRO), which refines the parameter search through iterative improvements; and (3) Preference Optimization (PO), which dynamically prioritizes key document sections based on relevance. Experimental results show that applying all three methods together improves retrieval precision by 47.69% and reduces processing latency by 37.84%. Furthermore, effect size analysis using Cohen's d reveals that PO significantly reduces latency, while IRO contributes most to precision enhancement. These findings underscore the potential of our framework to streamline EDA processes, enhance design accuracy, and shorten development timelines. Additionally, our algorithm has model-agnostic generalization, meaning it can improve parameter search performance across different LLMs.", 'abstract_zh': '从技术文档中提取参数对于确保电子设计的精确度和仿真可靠性至关重要。然而，当前方法难以处理高维度设计数据并满足实时处理的需求。在电子设计自动化（EDA）中，工程师常常需要手动搜索大量文档以检索用于构建PySpice模型的组件参数，这一过程既繁琐又耗时。为此，我们提出了一种创新框架，利用大型语言模型（LLMs）从数据表中自动提取参数并生成PySpice模型。该框架引入了三种基于Chain-of-Thought（CoT）的技术：（1）目标文档检索（TDR），实现快速识别相关技术部分；（2）迭代检索优化（IRO），通过迭代改进来细化参数搜索；（3）偏好优化（PO），动态优先考虑基于相关性的关键文档部分。实验结果显示，三种方法结合使用可将检索精度提高47.69%，减少处理延迟37.84%。此外，cohens d效应量分析表明，PO显著减少了延迟，而IRO对精度提升贡献最大。这些发现凸显了该框架在简化EDA流程、提升设计准确性和缩短开发时间方面的潜力。此外，我们的算法具有模型无关的一般化能力，意味着它可以在不同的LLMs上提高参数搜索性能。', 'title_zh': '使用大型语言模型进行文档中参数抽取的高级链式思考推理'}
{'arxiv_id': 'arXiv:2502.16534', 'title': 'Multilingual != Multicultural: Evaluating Gaps Between Multilingual Capabilities and Cultural Alignment in LLMs', 'authors': 'Jonathan Rystrøm, Hannah Rose Kirk, Scott Hale', 'link': 'https://arxiv.org/abs/2502.16534', 'abstract': "Large Language Models (LLMs) are becoming increasingly capable across global languages. However, the ability to communicate across languages does not necessarily translate to appropriate cultural representations. A key concern is US-centric bias, where LLMs reflect US rather than local cultural values. We propose a novel methodology that compares LLM-generated response distributions against population-level opinion data from the World Value Survey across four languages (Danish, Dutch, English, and Portuguese). Using a rigorous linear mixed-effects regression framework, we compare two families of models: Google's Gemma models (2B--27B parameters) and successive iterations of OpenAI's turbo-series. Across the families of models, we find no consistent relationships between language capabilities and cultural alignment. While the Gemma models have a positive correlation between language capability and cultural alignment across languages, the OpenAI models do not. Importantly, we find that self-consistency is a stronger predictor of multicultural alignment than multilingual capabilities. Our results demonstrate that achieving meaningful cultural alignment requires dedicated effort beyond improving general language capabilities.", 'abstract_zh': '大型语言模型（LLMs）在多种全球语言中的能力越来越强。然而，跨语言交流能力并不一定转化为恰当的文化表现。一个关键问题是美国中心偏见，其中LLMs反映的是美国而非当地的文化价值观。我们提出了一种新的方法，将LLM生成的响应分布与世界价值调查的国家层面意见数据进行比较，覆盖四种语言（丹麦语、荷兰语、英语和葡萄牙语）。利用严格的线性混合效应回归框架，我们将Google的Gemma模型（2B-27B参数）和OpenAI的turbo系列的后续版本进行比较。在不同模型家族中，我们未发现语言能力与文化一致性之间的稳定关系。虽然Gemma模型在多种语言中表现出语言能力与文化一致性之间的正相关关系，但OpenAI模型则未表现出这种关系。重要的是，我们发现自我一致性比多语言能力更能预测跨文化一致性。我们的结果表明，实现有意义的文化一致性需要超出一般语言能力提升的专门努力。', 'title_zh': '多语言不代表多文化：评估LLM的多语言能力和文化契合度之间的差距'}
{'arxiv_id': 'arXiv:2502.16533', 'title': 'A Survey of Graph Transformers: Architectures, Theories and Applications', 'authors': 'Chaohao Yuan, Kangfei Zhao, Ercan Engin Kuruoglu, Liang Wang, Tingyang Xu, Wenbing Huang, Deli Zhao, Hong Cheng, Yu Rong', 'link': 'https://arxiv.org/abs/2502.16533', 'abstract': 'Graph Transformers (GTs) have demonstrated a strong capability in modeling graph structures by addressing the intrinsic limitations of graph neural networks (GNNs), such as over-smoothing and over-squashing. Recent studies have proposed diverse architectures, enhanced explainability, and practical applications for Graph Transformers. In light of these rapid developments, we conduct a comprehensive review of Graph Transformers, covering aspects such as their architectures, theoretical foundations, and applications within this survey. We categorize the architecture of Graph Transformers according to their strategies for processing structural information, including graph tokenization, positional encoding, structure-aware attention and model ensemble. Furthermore, from the theoretical perspective, we examine the expressivity of Graph Transformers in various discussed architectures and contrast them with other advanced graph learning algorithms to discover the connections. Furthermore, we provide a summary of the practical applications where Graph Transformers have been utilized, such as molecule, protein, language, vision traffic, brain and material data. At the end of this survey, we will discuss the current challenges and prospective directions in Graph Transformers for potential future research.', 'abstract_zh': 'Graph Transformers (GTs)在解决图神经网络（GNNs）固有局限性（如过平滑和过压缩）以建模图结构方面展现了强大的能力。近年来，研究提出了一种多样的架构、增强了可解释性并探讨了实际应用。鉴于这些快速发展，我们对Graph Transformers进行了全面综述，覆盖了其架构、理论基础及其在各种应用中的应用。我们根据处理结构信息的策略对Graph Transformers的架构进行了分类，包括图标记化、位置编码、结构感知注意力和模型集成。此外，从理论角度，我们分析了各种架构中Graph Transformers的表达能力，并与其他高级图学习算法进行了对比，以发现它们之间的联系。我们还总结了Graph Transformers在分子、蛋白质、语言、视觉、交通、大脑和材料数据等方面的实际应用情况。最后，我们讨论了Graph Transformers当前面临的挑战及其未来的潜在研究方向。', 'title_zh': '图变换器综述：架构、理论与应用'}
{'arxiv_id': 'arXiv:2502.16529', 'title': 'Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation', 'authors': 'Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, Jawoon Cho, Gary Geunbae Lee', 'link': 'https://arxiv.org/abs/2502.16529', 'abstract': 'Visual programming languages (VPLs) allow users to create programs through graphical interfaces, which results in easier accessibility and their widespread usage in various domains. To further enhance this accessibility, recent research has focused on generating VPL code from user instructions using large language models (LLMs). Specifically, by employing prompting-based methods, these studies have shown promising results. Nevertheless, such approaches can be less effective for industrial VPLs such as Ladder Diagram (LD). LD is a pivotal language used in industrial automation processes and involves extensive domain-specific configurations, which are difficult to capture in a single prompt. In this work, we demonstrate that training-based methods outperform prompting-based methods for LD generation accuracy, even with smaller backbone models. Building on these findings, we propose a two-stage training strategy to further enhance VPL generation. First, we employ retrieval-augmented fine-tuning to leverage the repetitive use of subroutines commonly seen in industrial VPLs. Second, we apply direct preference optimization (DPO) to further guide the model toward accurate outputs, using systematically generated preference pairs through graph editing operations. Extensive experiments on real-world LD data demonstrate that our approach improves program-level accuracy by over 10% compared to supervised fine-tuning, which highlights its potential to advance industrial automation.', 'abstract_zh': '基于视觉编程语言的训练方法在梯形图生成中的效果研究', 'title_zh': '基于偏好优化的检索增强细调方法面向视觉程序生成'}
{'arxiv_id': 'arXiv:2502.16523', 'title': 'Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension', 'authors': 'Yulong Wu, Viktor Schlegel, Riza Batista-Navarro', 'link': 'https://arxiv.org/abs/2502.16523', 'abstract': 'As neural language models achieve human-comparable performance on Machine Reading Comprehension (MRC) and see widespread adoption, ensuring their robustness in real-world scenarios has become increasingly important. Current robustness evaluation research, though, primarily develops synthetic perturbation methods, leaving unclear how well they reflect real life scenarios. Considering this, we present a framework to automatically examine MRC models on naturally occurring textual perturbations, by replacing paragraph in MRC benchmarks with their counterparts based on available Wikipedia edit history. Such perturbation type is natural as its design does not stem from an arteficial generative process, inherently distinct from the previously investigated synthetic approaches. In a large-scale study encompassing SQUAD datasets and various model architectures we observe that natural perturbations result in performance degradation in pre-trained encoder language models. More worryingly, these state-of-the-art Flan-T5 and Large Language Models (LLMs) inherit these errors. Further experiments demonstrate that our findings generalise to natural perturbations found in other more challenging MRC benchmarks. In an effort to mitigate these errors, we show that it is possible to improve the robustness to natural perturbations by training on naturally or synthetically perturbed examples, though a noticeable gap still remains compared to performance on unperturbed data.', 'abstract_zh': '神经语言模型在机器阅读理解中的鲁棒性评估：基于自然文本 perturbations 的框架研究', 'title_zh': '关注现实世界的扰动！机器阅读理解中的自然鲁棒性评估'}
{'arxiv_id': 'arXiv:2502.16520', 'title': 'Predicting Bad Goods Risk Scores with ARIMA Time Series: A Novel Risk Assessment Approach', 'authors': 'Bishwajit Prasad Gond', 'link': 'https://arxiv.org/abs/2502.16520', 'abstract': 'The increasing complexity of supply chains and the rising costs associated with defective or substandard goods (bad goods) highlight the urgent need for advanced predictive methodologies to mitigate risks and enhance operational efficiency. This research presents a novel framework that integrates Time Series ARIMA (AutoRegressive Integrated Moving Average) models with a proprietary formula specifically designed to calculate bad goods after time series forecasting. By leveraging historical data patterns, including sales, returns, and capacity, the model forecasts potential quality failures, enabling proactive decision-making. ARIMA is employed to capture temporal trends in time series data, while the newly developed formula quantifies the likelihood and impact of defects with greater precision. Experimental results, validated on a dataset spanning 2022-2024 for Organic Beer-G 1 Liter, demonstrate that the proposed method outperforms traditional statistical models, such as Exponential Smoothing and Holt-Winters, in both prediction accuracy and risk evaluation. This study advances the field of predictive analytics by bridging time series forecasting, ARIMA, and risk management in supply chain quality control, offering a scalable and practical solution for minimizing losses due to bad goods.', 'abstract_zh': '供应链复杂性的增加和不良或次标准商品（不良商品）相关成本的上升凸显了急需先进的预测方法以减轻风险和提高运营效率的紧迫性。本研究提出了一种新颖的框架，该框架将时间序列ARIMA模型与专门设计用于时间序列预测后计算不良商品的专利公式相结合。通过利用销售、退货和生产能力等历史数据模式，该模型预测潜在的质量故障，从而实现主动决策。ARIMA用于捕捉时间序列数据中的时间趋势，而新开发的公式则以更高的精确度量化缺陷的可能性和影响。实验结果，基于2022-2024年有机啤酒-G 1升的数据集验证，表明所提出的方法在预测准确性和风险评估方面优于传统的统计模型，如指数平滑和霍尔特-温特模型。本研究通过将时间序列预测、ARIMA和供应链质量控制中的风险管理相结合，推动了预测分析领域的进步，并提供了一种可扩展且实用的解决方案，以减少由于不良商品造成的损失。', 'title_zh': '基于ARIMA时间序列的不良商品风险评分预测：一种新型风险评估方法'}
{'arxiv_id': 'arXiv:2502.16510', 'title': 'Gaussian Process Regression for Improved Underwater Navigation', 'authors': 'Nadav Cohen, Itzik Klein', 'link': 'https://arxiv.org/abs/2502.16510', 'abstract': 'Accurate underwater navigation is a challenging task due to the absence of global navigation satellite system signals and the reliance on inertial navigation systems that suffer from drift over time. Doppler velocity logs (DVLs) are typically used to mitigate this drift through velocity measurements, which are commonly estimated using a parameter estimation approach such as least squares (LS). However, LS works under the assumption of ideal conditions and does not account for sensor biases, leading to suboptimal performance. This paper proposes a data-driven alternative based on multi-output Gaussian process regression (MOGPR) to improve DVL velocity estimation. MOGPR provides velocity estimates and associated measurement covariances, enabling an adaptive integration within an error-state Extended Kalman Filter (EKF). We evaluate our proposed approach using real-world AUV data and compare it against LS and a state-of-the-art deep learning model, BeamsNet. Results demonstrate that MOGPR reduces velocity estimation errors by approximately 20% while simultaneously enhancing overall navigation accuracy, particularly in the orientation states. Additionally, the incorporation of uncertainty estimates from MOGPR enables an adaptive EKF framework, improving navigation robustness in dynamic underwater environments.', 'abstract_zh': '基于多输出高斯过程回归的声纳速度日志 veloc 度估计方法', 'title_zh': '高斯过程回归在水下导航中的应用'}
{'arxiv_id': 'arXiv:2502.16503', 'title': 'FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis', 'authors': 'Yilun Zheng, Sha Li, Fangkun Wu, Yang Ziyi, Lin Hongchao, Zhichao Hu, Cai Xinjun, Ziming Wang, Jinxuan Chen, Sitao Luan, Jiahao Xu, Lihui Chen', 'link': 'https://arxiv.org/abs/2502.16503', 'abstract': 'Parody is an emerging phenomenon on social media, where individuals imitate a role or position opposite to their own, often for humor, provocation, or controversy. Detecting and analyzing parody can be challenging and is often reliant on context, yet it plays a crucial role in understanding cultural values, promoting subcultures, and enhancing self-expression. However, the study of parody is hindered by limited available data and deficient diversity in current datasets. To bridge this gap, we built seven parody datasets from both English and Chinese corpora, with 14,755 annotated users and 21,210 annotated comments in total. To provide sufficient context information, we also collect replies and construct user-interaction graphs to provide richer contextual information, which is lacking in existing datasets. With these datasets, we test traditional methods and Large Language Models (LLMs) on three key tasks: (1) parody detection, (2) comment sentiment analysis with parody, and (3) user sentiment analysis with parody. Our extensive experiments reveal that parody-related tasks still remain challenging for all models, and contextual information plays a critical role. Interestingly, we find that, in certain scenarios, traditional sentence embedding methods combined with simple classifiers can outperform advanced LLMs, i.e. DeepSeek-R1 and GPT-o3, highlighting parody as a significant challenge for LLMs.', 'abstract_zh': '社交媒体中的 parody 是一个新兴现象，个体通过模仿与其自身相反的角色或身份，常用于幽默、挑衅或引起争议。检测和分析 parody 挑战重重，但在理解文化价值观、促进亚文化发展和增强自我表达方面起着关键作用。然而， parody 研究受限于可用数据量有限以及当前数据集中缺乏多样性。为弥补这一差距，我们从英汉语料中构建了七个 parody 数据集，共计包括 14,755 个标注用户和 21,210 个标注评论。为提供足够的上下文信息，我们还收集了回复并构建了用户交互图，以提供更多上下文信息，而现有数据集中缺乏这些信息。依托这些数据集，我们对传统方法和大规模语言模型（LLMs）进行了三个关键任务的测试：（1）parody 检测，（2）包含 parody 的评论情感分析，（3）包含 parody 的用户情感分析。大量实验表明，所有模型在 parody 相关任务中依然面临挑战，而上下文信息起着关键作用。有趣的是，我们在某些场景中发现，简单的传统句子嵌入方法与简单分类器的结合甚至可以优于先进的 LLMs（如 DeepSeek-R1 和 GPT-o3），这突显了 parody 对 LLMs 的重大挑战。', 'title_zh': 'FanChuan：一种用于parody检测与分析的多语言图结构基准数据集'}
{'arxiv_id': 'arXiv:2502.16496', 'title': 'PMAT: Optimizing Action Generation Order in Multi-Agent Reinforcement Learning', 'authors': 'Kun Hu, Muning Wen, Xihuai Wang, Shao Zhang, Yiwei Shi, Minne Li, Minglong Li, Ying Wen', 'link': 'https://arxiv.org/abs/2502.16496', 'abstract': "Multi-agent reinforcement learning (MARL) faces challenges in coordinating agents due to complex interdependencies within multi-agent systems. Most MARL algorithms use the simultaneous decision-making paradigm but ignore the action-level dependencies among agents, which reduces coordination efficiency. In contrast, the sequential decision-making paradigm provides finer-grained supervision for agent decision order, presenting the potential for handling dependencies via better decision order management. However, determining the optimal decision order remains a challenge. In this paper, we introduce Action Generation with Plackett-Luce Sampling (AGPS), a novel mechanism for agent decision order optimization. We model the order determination task as a Plackett-Luce sampling process to address issues such as ranking instability and vanishing gradient during the network training process. AGPS realizes credit-based decision order determination by establishing a bridge between the significance of agents' local observations and their decision credits, thus facilitating order optimization and dependency management. Integrating AGPS with the Multi-Agent Transformer, we propose the Prioritized Multi-Agent Transformer (PMAT), a sequential decision-making MARL algorithm with decision order optimization. Experiments on benchmarks including StarCraft II Multi-Agent Challenge, Google Research Football, and Multi-Agent MuJoCo show that PMAT outperforms state-of-the-art algorithms, greatly enhancing coordination efficiency.", 'abstract_zh': '基于Plackett-Luce采样的智能体决策顺序优化机制及优先级多智能体变换器', 'title_zh': 'PMAT：多智能体 reinforcement learning 中优化动作生成顺序'}
{'arxiv_id': 'arXiv:2502.16490', 'title': 'On Computational Limits of FlowAR Models: Expressivity and Efficiency', 'authors': 'Chengyue Gong, Yekun Ke, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song', 'link': 'https://arxiv.org/abs/2502.16490', 'abstract': 'The expressive power and computational complexity of deep visual generative models, such as flow-based and autoregressive (AR) models, have gained considerable interest for their wide-ranging applications in generative tasks. However, the theoretical characterization of their expressiveness through the lens of circuit complexity remains underexplored, particularly for the state-of-the-art architecture like FlowAR proposed by [Ren et al., 2024], which integrates flow-based and autoregressive mechanisms. This gap limits our understanding of their inherent computational limits and practical efficiency. In this study, we address this gap by analyzing the circuit complexity of the FlowAR architecture. We demonstrate that when the largest feature map produced by the FlowAR model has dimensions $n \\times n \\times c$, the FlowAR model is simulable by a family of threshold circuits $\\mathsf{TC}^0$, which have constant depth $O(1)$ and polynomial width $\\mathrm{poly}(n)$. This is the first study to rigorously highlight the limitations in the expressive power of FlowAR models. Furthermore, we identify the conditions under which the FlowAR model computations can achieve almost quadratic time. To validate our theoretical findings, we present efficient model variant constructions based on low-rank approximations that align with the derived criteria. Our work provides a foundation for future comparisons with other generative paradigms and guides the development of more efficient and expressive implementations.', 'abstract_zh': '基于电路复杂性的深度视觉生成模型，如流动基于和自回归模型表达能力和计算复杂性的理论刻画研究——以Ren等人提出的FlowAR架构为例', 'title_zh': '关于FlowAR模型的计算限制：表达能力和效率'}
{'arxiv_id': 'arXiv:2502.16483', 'title': 'A Split-Window Transformer for Multi-Model Sequence Spammer Detection using Multi-Model Variational Autoencoder', 'authors': 'Zhou Yang, Yucai Pang, Hongbo Yin, Yunpeng Xiao', 'link': 'https://arxiv.org/abs/2502.16483', 'abstract': "This paper introduces a new Transformer, called MS$^2$Dformer, that can be used as a generalized backbone for multi-modal sequence spammer detection. Spammer detection is a complex multi-modal task, thus the challenges of applying Transformer are two-fold. Firstly, complex multi-modal noisy information about users can interfere with feature mining. Secondly, the long sequence of users' historical behaviors also puts a huge GPU memory pressure on the attention computation. To solve these problems, we first design a user behavior Tokenization algorithm based on the multi-modal variational autoencoder (MVAE). Subsequently, a hierarchical split-window multi-head attention (SW/W-MHA) mechanism is proposed. The split-window strategy transforms the ultra-long sequences hierarchically into a combination of intra-window short-term and inter-window overall attention. Pre-trained on the public datasets, MS$^2$Dformer's performance far exceeds the previous state of the art. The experiments demonstrate MS$^2$Dformer's ability to act as a backbone.", 'abstract_zh': '基于MVAE的用户行为Tokenization和分窗口多头注意机制的MS$^2$Dformer在多模态序列发帖者检测中的应用', 'title_zh': '基于多模型变分自编码器的多模型序列垃圾信息发布检测分窗口变压器'}
{'arxiv_id': 'arXiv:2502.16477', 'title': 'Unmasking Societal Biases in Respiratory Support for ICU Patients through Social Determinants of Health', 'authors': 'Mira Moukheiber, Lama Moukheiber, Dana Moukheiber, Hyung-Chul Lee', 'link': 'https://arxiv.org/abs/2502.16477', 'abstract': "In critical care settings, where precise and timely interventions are crucial for health outcomes, evaluating disparities in patient outcomes is essential. Current approaches often fail to fully capture the impact of respiratory support interventions on individuals affected by social determinants of health. While attributes such as gender, race, and age are commonly assessed and provide valuable insights, they offer only a partial view of the complexities faced by diverse populations. In this study, we focus on two clinically motivated tasks: prolonged mechanical ventilation and successful weaning. Additionally, we conduct fairness audits on the models' predictions across demographic groups and social determinants of health to better understand health inequities in respiratory interventions within the intensive care unit. Furthermore, we release a temporal benchmark dataset, verified by clinical experts, to facilitate benchmarking of clinical respiratory intervention tasks.", 'abstract_zh': '在重症护理环境中，精确及时的干预对于健康结果至关重要，评估患者结果的差异性尤为关键。当前的方法往往未能充分捕捉社会决定因素对呼吸支持干预个体的影响。虽然性别、种族和年龄等属性通常会被评估并提供有价值的见解，但它们仅提供了多元群体所面临复杂性的部分视角。在本研究中，我们专注于两个临床驱动的任务：长时间机械通气和成功脱机。此外，我们还在不同人口统计群体和社会决定因素方面对模型的预测进行公平性审计，以更好地理解重症监护病房内呼吸干预措施中的健康不平等。此外，我们发布了一个由临床专家验证的时间基准数据集，以促进临床呼吸支持干预任务的基准测试。', 'title_zh': '通过社会决定因素揭露重症监护患者呼吸支持中的社会偏见'}
{'arxiv_id': 'arXiv:2502.16475', 'title': 'Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control', 'authors': 'Jinbo Yan, Alan Zhao, Yixin Hu', 'link': 'https://arxiv.org/abs/2502.16475', 'abstract': 'Single-image 3D generation has emerged as a prominent research topic, playing a vital role in virtual reality, 3D modeling, and digital content creation. However, existing methods face challenges such as a lack of multi-view geometric consistency and limited controllability during the generation process, which significantly restrict their usability. % To tackle these challenges, we introduce Dragen3D, a novel approach that achieves geometrically consistent and controllable 3D generation leveraging 3D Gaussian Splatting (3DGS). We introduce the Anchor-Gaussian Variational Autoencoder (Anchor-GS VAE), which encodes a point cloud and a single image into anchor latents and decode these latents into 3DGS, enabling efficient latent-space generation. To enable multi-view geometry consistent and controllable generation, we propose a Seed-Point-Driven strategy: first generate sparse seed points as a coarse geometry representation, then map them to anchor latents via the Seed-Anchor Mapping Module. Geometric consistency is ensured by the easily learned sparse seed points, and users can intuitively drag the seed points to deform the final 3DGS geometry, with changes propagated through the anchor latents. To the best of our knowledge, we are the first to achieve geometrically controllable 3D Gaussian generation and editing without relying on 2D diffusion priors, delivering comparable 3D generation quality to state-of-the-art methods.', 'abstract_zh': '单幅图像的单次3D生成：一种基于3D高斯点扩散的几何一致性和可控性方法', 'title_zh': 'Dragen3D：基于拖拽控制的多视图几何一致的3D高斯生成'}
{'arxiv_id': 'arXiv:2502.16469', 'title': 'Cross-domain Few-shot Object Detection with Multi-modal Textual Enrichment', 'authors': 'Zeyu Shangguan, Daniel Seita, Mohammad Rostami', 'link': 'https://arxiv.org/abs/2502.16469', 'abstract': 'Advancements in cross-modal feature extraction and integration have significantly enhanced performance in few-shot learning tasks. However, current multi-modal object detection (MM-OD) methods often experience notable performance degradation when encountering substantial domain shifts. We propose that incorporating rich textual information can enable the model to establish a more robust knowledge relationship between visual instances and their corresponding language descriptions, thereby mitigating the challenges of domain shift. Specifically, we focus on the problem of Cross-Domain Multi-Modal Few-Shot Object Detection (CDMM-FSOD) and introduce a meta-learning-based framework designed to leverage rich textual semantics as an auxiliary modality to achieve effective domain adaptation. Our new architecture incorporates two key components: (i) A multi-modal feature aggregation module, which aligns visual and linguistic feature embeddings to ensure cohesive integration across modalities. (ii) A rich text semantic rectification module, which employs bidirectional text feature generation to refine multi-modal feature alignment, thereby enhancing understanding of language and its application in object detection. We evaluate the proposed method on common cross-domain object detection benchmarks and demonstrate that it significantly surpasses existing few-shot object detection approaches.', 'abstract_zh': '跨模态特征提取与整合的进展显著提升了少样本学习任务的表现。然而，当前的多模态物体检测（MM-OD）方法在遇到显著领域偏移时常常会表现出明显的性能下降。我们提出通过引入丰富的文本信息，可以使模型建立视觉实例与其对应语言描述之间的更稳健的知识关系，从而缓解领域偏移的挑战。具体而言，我们重点解决跨域多模态少样本物体检测（CDMM-FSOD）问题，并提出一种基于元学习的框架，利用丰富的文本语义作为辅助模态，以实现有效的领域适应。我们的新架构包含两个关键组件：（i）多模态特征聚合模块，该模块对齐视觉和语言特征嵌入，以确保各模态之间的协同整合。（ii）丰富的文本语义矫正模块，该模块采用双向文本特征生成来细化多模态特征对齐，从而增强对语言及其在物体检测中应用的理解。我们在常见的跨域物体检测基准上评估了所提出的方法，并证明了其显著优于现有的少样本物体检测方法。', 'title_zh': '跨领域少样本对象检测的多模态文本丰富方法'}
{'arxiv_id': 'arXiv:2502.16459', 'title': 'Deep learning approaches to surgical video segmentation and object detection: A Scoping Review', 'authors': 'Devanish N. Kamtam, Joseph B. Shrager, Satya Deepya Malla, Nicole Lin, Juan J. Cardona, Jake J. Kim, Clarence Hu', 'link': 'https://arxiv.org/abs/2502.16459', 'abstract': 'Introduction: Computer vision (CV) has had a transformative impact in biomedical fields such as radiology, dermatology, and pathology. Its real-world adoption in surgical applications, however, remains limited. We review the current state-of-the-art performance of deep learning (DL)-based CV models for segmentation and object detection of anatomical structures in videos obtained during surgical procedures.\nMethods: We conducted a scoping review of studies on semantic segmentation and object detection of anatomical structures published between 2014 and 2024 from 3 major databases - PubMed, Embase, and IEEE Xplore. The primary objective was to evaluate the state-of-the-art performance of semantic segmentation in surgical videos. Secondary objectives included examining DL models, progress toward clinical applications, and the specific challenges with segmentation of organs/tissues in surgical videos.\nResults: We identified 58 relevant published studies. These focused predominantly on procedures from general surgery [20(34.4%)], colorectal surgery [9(15.5%)], and neurosurgery [8(13.8%)]. Cholecystectomy [14(24.1%)] and low anterior rectal resection [5(8.6%)] were the most common procedures addressed. Semantic segmentation [47(81%)] was the primary CV task. U-Net [14(24.1%)] and DeepLab [13(22.4%)] were the most widely used models. Larger organs such as the liver (Dice score: 0.88) had higher accuracy compared to smaller structures such as nerves (Dice score: 0.49). Models demonstrated real-time inference potential ranging from 5-298 frames-per-second (fps).\nConclusion: This review highlights the significant progress made in DL-based semantic segmentation for surgical videos with real-time applicability, particularly for larger organs. Addressing challenges with smaller structures, data availability, and generalizability remains crucial for future advancements.', 'abstract_zh': '计算机视觉在手术视频中解剖结构分割与对象检测的现状：从2014年至2024年的综述', 'title_zh': '深度学习在手术视频分割和对象检测中的应用：一个综述研究'}
{'arxiv_id': 'arXiv:2502.16446', 'title': 'Auxiliary Discrminator Sequence Generative Adversarial Networks (ADSeqGAN) for Few Sample Molecule Generation', 'authors': 'Haocheng Tang, Jing Long, Junmei Wang', 'link': 'https://arxiv.org/abs/2502.16446', 'abstract': 'In this work, we introduce Auxiliary Discriminator Sequence Generative Adversarial Networks (ADSeqGAN), a novel approach for molecular generation in small-sample datasets. Traditional generative models often struggle with limited training data, particularly in drug discovery, where molecular datasets for specific therapeutic targets, such as nucleic acids binders and central nervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by integrating an auxiliary random forest classifier as an additional discriminator into the GAN framework, significantly improves molecular generation quality and class specificity.\nOur method incorporates pretrained generator and Wasserstein distance to enhance training stability and diversity. We evaluate ADSeqGAN on a dataset comprising nucleic acid-targeting and protein-targeting small molecules, demonstrating its superior ability to generate nucleic acid binders compared to baseline models such as SeqGAN, ORGAN, and MolGPT. Through an oversampling strategy, ADSeqGAN also significantly improves CNS drug generation, achieving a higher yield than traditional de novo models. Critical assessments, including docking simulations and molecular property analysis, confirm that ADSeqGAN-generated molecules exhibit strong binding affinities, enhanced chemical diversity, and improved synthetic feasibility.\nOverall, ADSeqGAN presents a novel framework for generative molecular design in data-scarce scenarios, offering potential applications in computational drug discovery. We have demonstrated the successful applications of ADSeqGAN in generating synthetic nucleic acid-targeting and CNS drugs in this work.', 'abstract_zh': '辅助鉴别序列生成对抗网络（ADSeqGAN）在小样本数据集中的分子生成方法', 'title_zh': '辅助鉴别器序列生成对抗网络（ADSeqGAN）用于少量样本分子生成'}
{'arxiv_id': 'arXiv:2502.16445', 'title': 'Iterative Flow Matching -- Path Correction and Gradual Refinement for Enhanced Generative Modeling', 'authors': 'Eldad Haber, Shadab Ahamed, Md. Shahriar Rahim Siddiqui, Niloufar Zakariaei, Moshe Eliasof', 'link': 'https://arxiv.org/abs/2502.16445', 'abstract': 'Generative models for image generation are now commonly used for a wide variety of applications, ranging from guided image generation for entertainment to solving inverse problems. Nonetheless, training a generator is a non-trivial feat that requires fine-tuning and can lead to so-called hallucinations, that is, the generation of images that are unrealistic. In this work, we explore image generation using flow matching. We explain and demonstrate why flow matching can generate hallucinations, and propose an iterative process to improve the generation process. Our iterative process can be integrated into virtually $\\textit{any}$ generative modeling technique, thereby enhancing the performance and robustness of image synthesis systems.', 'abstract_zh': '图像生成的流匹配生成模型：探索、分析及迭代改进方法', 'title_zh': '迭代流匹配——路径修正与逐步细化以增强生成建模'}
{'arxiv_id': 'arXiv:2502.16433', 'title': 'Sequence-level Large Language Model Training with Contrastive Preference Optimization', 'authors': 'Zhili Feng, Dhananjay Ram, Cole Hawkins, Aditya Rawal, Jinman Zhao, Sheng Zha', 'link': 'https://arxiv.org/abs/2502.16433', 'abstract': 'The next token prediction loss is the dominant self-supervised training objective for large language models and has achieved promising results in a variety of downstream tasks. However, upon closer investigation of this objective, we find that it lacks an understanding of sequence-level signals, leading to a mismatch between training and inference processes. To bridge this gap, we introduce a contrastive preference optimization (CPO) procedure that can inject sequence-level information into the language model at any training stage without expensive human labeled data. Our experiments show that the proposed objective surpasses the next token prediction in terms of win rate in the instruction-following and text generation tasks.', 'abstract_zh': '下一-token预测损失是大规模语言模型自监督训练的主要目标，并在各种下游任务中取得了令人瞩目的成果。然而，深入研究这一目标后，我们发现它缺乏对序列级信号的理解，导致训练和推理过程之间存在不匹配。为了弥合这一差距，我们提出了一种对比偏好优化（CPO）程序，可以在任何训练阶段向语言模型注入序列级信息，而无需昂贵的人工标注数据。我们的实验表明，在指令跟随和文本生成任务中，所提出的目标在胜利率上超过了下一-token预测。', 'title_zh': '基于对比偏好优化的序列级大规模语言模型训练'}
{'arxiv_id': 'arXiv:2502.16428', 'title': 'Visual Reasoning Evaluation of Grok, Deepseek Janus, Gemini, Qwen, Mistral, and ChatGPT', 'authors': 'Nidhal Jegham, Marwan Abdelatti, Abdeltawab Hendawi', 'link': 'https://arxiv.org/abs/2502.16428', 'abstract': 'Traditional evaluations of multimodal large language models (LLMs) have been limited by their focus on single-image reasoning, failing to assess crucial aspects like contextual understanding, reasoning stability, and uncertainty calibration. This study addresses these limitations by introducing a novel benchmark that integrates multi-image reasoning tasks with rejection-based evaluation and positional bias detection. To evaluate these dimensions, we further introduce entropy as a novel metric for quantifying reasoning consistency across reordered answer variants. We applied this benchmark to assess Grok 3, ChatGPT-4o, ChatGPT-o1, Gemini 2.0 Flash Experimental, DeepSeek Janus models, Qwen2.5-VL-72B-Instruct, QVQ-72B-Preview, and Pixtral 12B across eight visual reasoning tasks, including difference spotting and diagram interpretation. Our findings reveal ChatGPT-o1 leading in overall accuracy (82.5\\%) and rejection accuracy (70.0\\%), closely followed by Gemini 2.0 Flash Experimental (70.8\\%). QVQ-72B-Preview demonstrated superior rejection accuracy (85.5\\%). Notably, Pixtral 12B (51.7\\%) showed promise in specific domains, while Janus models exhibited challenges in bias and uncertainty calibration, reflected in low rejection accuracies and high entropy scores. High entropy scores in Janus models (Janus 7B: 0.8392, Janus 1B: 0.787) underscore their susceptibility to positional bias and unstable reasoning, contrasting with the low entropy and robust reasoning of ChatGPT models. The study further demonstrates that model size is not the sole determinant of performance, as evidenced by Grok 3 underperformance despite its substantial parameter count. By employing multi-image contexts, rejection mechanisms, and entropy-based consistency metrics, this benchmark sets a new standard for evaluating multimodal LLMs, enabling a more robust and reliable assessment of next-generation AI systems.', 'abstract_zh': '传统的多模态大型语言模型评估受限于其对单图像推理的聚焦，未能评估关键方面如上下文理解、推理稳定性和不确定性校准。本研究通过引入一种结合多图像推理任务、基于拒绝的评估以及位置偏差检测的新基准，来解决这些局限性。为进一步评估这些维度，我们引入了熵作为量化重新排序答案变体之间推理一致性的一种新指标。我们将此基准应用于评估Grok 3、ChatGPT-4o、ChatGPT-o1、Gemini 2.0 Flash Experimental、DeepSeek Janus模型、Qwen2.5-VL-72B-Instruct、QVQ-72B-Preview和Pixtral 12B在八项视觉推理任务中的表现，包括差异识别和图表解释。研究结果表明，ChatGPT-o1在总体准确率（82.5%）和拒绝准确率（70.0%）方面领先，其次为Gemini 2.0 Flash Experimental（70.8%）。QVQ-72B-Preview在拒绝准确率（85.5%）方面表现出色。值得注意的是，Pixtral 12B（51.7%）在特定领域显示出潜力，而Janus模型在偏差和不确定性校准方面面临挑战，这体现在较低的拒绝准确率和较高的熵得分。Janus模型高熵得分（Janus 7B：0.8392，Janus 1B：0.787）表明其对位置偏差和推理不稳定的脆弱性，这与ChatGPT模型的低熵和稳健推理形成对比。这项研究进一步表明，模型大小不是性能的唯一决定因素，即使参数数量庞大，Grok 3的表现也不理想。通过多图像推理背景、拒绝机制和基于熵的一致性度量，该基准为评估多模态大型语言模型设定了新的标准，能够提供更 robust 和可靠的下一代人工智能系统评估。', 'title_zh': 'Grok、Deepseek Janus、Gemini、Qwen、Mistral和ChatGPT的视觉推理评估'}
{'arxiv_id': 'arXiv:2502.16414', 'title': 'TabGen-ICL: Residual-Aware In-Context Example Selection for Tabular Data Generation', 'authors': 'Liancheng Fang, Aiwei Liu, Hengrui Zhang, Henry Peng Zou, Weizhi Zhang, Philip S. Yu', 'link': 'https://arxiv.org/abs/2502.16414', 'abstract': "Large Language models (LLMs) have achieved encouraging results in tabular data generation. However, existing approaches require fine-tuning, which is computationally expensive. This paper explores an alternative: prompting a fixed LLM with in-context examples. We observe that using randomly selected in-context examples hampers the LLM's performance, resulting in sub-optimal generation quality. To address this, we propose a novel in-context learning framework: TabGen-ICL, to enhance the in-context learning ability of LLMs for tabular data generation. TabGen-ICL operates iteratively, retrieving a subset of real samples that represent the residual between currently generated samples and true data distributions. This approach serves two purposes: locally, it provides more effective in-context learning examples for the LLM in each iteration; globally, it progressively narrows the gap between generated and real data. Extensive experiments on five real-world tabular datasets demonstrate that TabGen-ICL significantly outperforms the random selection strategy. Specifically, it reduces the error rate by a margin of $3.5\\%-42.2\\%$ on fidelity metrics. We demonstrate for the first time that prompting a fixed LLM can yield high-quality synthetic tabular data. The code is provided in the \\href{this https URL}{link}.", 'abstract_zh': '大规模语言模型（LLMs）在表格数据生成任务中取得了令人鼓舞的结果。然而，现有方法需要进行细调，这在计算上非常昂贵。本文探索了一种替代方案：通过上下文示例提示固定的大规模语言模型。我们观察到，使用随机选取的上下文示例会损害模型性能，导致生成质量不理想。为此，我们提出了一种新颖的上下文学习框架：TabGen-ICL，以增强LLMs在表格数据生成任务中的上下文学习能力。TabGen-ICL 迭代运行，检索当前生成样本与真实数据分布间差值的子集作为示例。该方法有两个目的：局部地，每次迭代为LLM提供更有效的上下文学习示例；全局地，逐步缩小生成数据与真实数据之间的差距。在五个真实世界的表格数据集上的广泛实验表明，TabGen-ICL 显著优于随机选择策略。具体而言，它在保真度指标上的错误率降低了3.5%-42.2%。我们首次证明，提示固定的大规模语言模型可以生成高质量的合成表格数据。代码可以在[this https URL](link)处获取。', 'title_zh': 'TabGen-ICL: 考虑残差的上下文例选择方法用于表格数据生成'}
{'arxiv_id': 'arXiv:2502.16411', 'title': 'Tool or Tutor? Experimental evidence from AI deployment in cancer diagnosis', 'authors': 'Vivianna Fang He, Sihan Li, Phanish Puranam', 'link': 'https://arxiv.org/abs/2502.16411', 'abstract': "Professionals increasingly use Artificial Intelligence (AI) to enhance their capabilities and assist with task execution. While prior research has examined these uses separately, their potential interaction remains underexplored. We propose that AI-driven training (tutor effect) and AI-assisted task completion (tool effect) can be complementary and test this hypothesis in the context of lung cancer diagnosis. In a field experiment with 334 medical students, we manipulated AI deployment in training, in practice, and in both. Our findings reveal that while AI-integrated training and AI assistance independently improved diagnostic performance, their combination yielded the highest accuracy. These results underscore AI's dual role in enhancing human performance through both learning and real-time support, offering insights into AI deployment in professional settings where human expertise remains essential.", 'abstract_zh': '专业人士 increasingly 使用人工智能 (AI) 来提升其能力并协助任务执行。尽管以往的研究分别探讨了这些应用，但它们的潜在交互仍有待探索。我们提出，由AI驱动的培训（导师效应）和AI辅助的任务完成（工具效应）可以互补，并在肺癌诊断的背景下测试这一假设。在涉及334名医学学生的现场实验中，我们操纵了在培训、实践以及两者中的AI部署。我们的研究发现，虽然AI集成培训和AI辅助分别提高了诊断性能，但它们的结合使用实现了最高的准确性。这些结果强调了AI在通过学习和实时支持提升人类表现中的双重作用，为在仍需人类专长的专业环境中部署AI提供了见解。', 'title_zh': '工具还是导师？来自癌症诊断中AI部署的实验证据'}
{'arxiv_id': 'arXiv:2502.16406', 'title': 'TrustChain: A Blockchain Framework for Auditing and Verifying Aggregators in Decentralized Federated Learning', 'authors': 'Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif', 'link': 'https://arxiv.org/abs/2502.16406', 'abstract': 'The server-less nature of Decentralized Federated Learning (DFL) requires allocating the aggregation role to specific participants in each federated round. Current DFL architectures ensure the trustworthiness of the aggregator node upon selection. However, most of these studies overlook the possibility that the aggregating node may turn rogue and act maliciously after being nominated. To address this problem, this paper proposes a DFL structure, called TrustChain, that scores the aggregators before selection based on their past behavior and additionally audits them after the aggregation. To do this, the statistical independence between the client updates and the aggregated model is continuously monitored using the Hilbert-Schmidt Independence Criterion (HSIC). The proposed method relies on several principles, including blockchain, anomaly detection, and concept drift analysis. The designed structure is evaluated on several federated datasets and attack scenarios with different numbers of Byzantine nodes.', 'abstract_zh': '去中心化联邦学习（DFL）的无服务器性质要求在每个联邦轮次中分配聚合角色给特定参与者。当前的DFL架构确保在选择聚合节点时其可信度。然而，大多数研究忽视了被提名后聚合节点可能会变成恶意节点的可能性。为解决这一问题，本文提出了一种称为TrustChain的DFL结构，在选择聚合节点时根据其以往行为评分，并在聚合后对其进行审核。为此，通过使用希尔伯特-施密特独立性判据（HSIC）持续监控客户端更新与聚合模型之间的统计独立性。所提出的方法基于区块链、异常检测和概念漂移分析等多个原则。所设计的结构在包含不同数量拜占庭节点的各种联邦数据集和攻击场景下进行了评估。', 'title_zh': '信任链：一种用于分布式联邦学习中审计和验证聚合器的区块链框架'}
{'arxiv_id': 'arXiv:2502.16399', 'title': 'Ensemble ToT of LLMs and Its Application to Automatic Grading System for Supporting Self-Learning', 'authors': 'Yuki Ito, Qiang Ma', 'link': 'https://arxiv.org/abs/2502.16399', 'abstract': "Providing students with detailed and timely grading feedback is essential for self-learning. While existing LLM-based grading systems are promising, most of them rely on one single model, which limits their performance. To address this, we propose Ensemble Tree-of-Thought (ToT), a framework that enhances LLM outputs by integrating multiple models. Using this framework, we develop a grading system. Ensemble ToT follows three steps: (1) analyzing LLM performance, (2) generating candidate answers, and (3) refining them into a final result. Based on this, our grading system first evaluates the grading tendencies of LLMs, then generates multiple results, and finally integrates them via a simulated debate. Experimental results demonstrate our approach's ability to provide accurate and explainable grading by effectively coordinating multiple LLMs.", 'abstract_zh': '提供详细及时的评分反馈是自主学习的关键。尽管现有的基于LLM的评分系统很有前景，但大多数系统依赖单一模型，这限制了它们的性能。为解决这一问题，我们提出了集合思维树（Ensemble Tree-of-Thought，Ensemble ToT）框架，该框架通过集成多个模型来增强LLM输出。基于此框架，我们开发了一个评分系统。Ensemble ToT 包括三个步骤：（1）分析LLM性能，（2）生成候选答案，（3）将它们精炼为最终结果。基于这些步骤，我们的评分系统首先评估LLMs的评分倾向，然后生成多个结果，最后通过模拟辩论将它们综合起来。实验结果表明，该方法能够通过有效协调多个LLMs提供准确可解释的评分。', 'title_zh': 'LLMensemble及其在支持自主学习的自动评分系统中的应用'}
{'arxiv_id': 'arXiv:2502.16396', 'title': 'FedNIA: Noise-Induced Activation Analysis for Mitigating Data Poisoning in FL', 'authors': 'Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif', 'link': 'https://arxiv.org/abs/2502.16396', 'abstract': 'Federated learning systems are increasingly threatened by data poisoning attacks, where malicious clients compromise global models by contributing tampered updates. Existing defenses often rely on impractical assumptions, such as access to a central test dataset, or fail to generalize across diverse attack types, particularly those involving multiple malicious clients working collaboratively. To address this, we propose Federated Noise-Induced Activation Analysis (FedNIA), a novel defense framework to identify and exclude adversarial clients without relying on any central test dataset. FedNIA injects random noise inputs to analyze the layerwise activation patterns in client models leveraging an autoencoder that detects abnormal behaviors indicative of data poisoning. FedNIA can defend against diverse attack types, including sample poisoning, label flipping, and backdoors, even in scenarios with multiple attacking nodes. Experimental results on non-iid federated datasets demonstrate its effectiveness and robustness, underscoring its potential as a foundational approach for enhancing the security of federated learning systems.', 'abstract_zh': '联邦学习系统受到数据中毒攻击的威胁不断增加，其中恶意客户端通过提交篡改的更新来损害全局模型。现有防御往往依赖于不切实际的假设，例如访问中央测试数据集，或者在面对多样化的攻击类型，尤其是涉及多个恶意客户端协同工作的攻击时无法泛化。为了解决这个问题，我们提出了一种名为FedNIA（Federated Noise-Induced Activation Analysis）的新型防御框架，能够在无需依赖任何中央测试数据集的情况下识别和排除恶意客户端。FedNIA通过注入随机噪声输入并利用自动编码器分析客户端模型中的逐层激活模式，检测指示数据中毒的异常行为来防范多种攻击类型，包括样本中毒、标签翻转和后门攻击。实验结果在非i.i.d.联邦学习数据集上显示了其有效性和鲁棒性，强调了其作为增强联邦学习系统安全性的基础方法的潜力。', 'title_zh': 'FedNIA：噪声诱发激活分析用于缓解联邦学习中的数据投毒问题'}
{'arxiv_id': 'arXiv:2502.16395', 'title': 'An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science', 'authors': 'Qiuhai Zeng, Claire Jin, Xinyue Wang, Yuhan Zheng, Qunhua Li', 'link': 'https://arxiv.org/abs/2502.16395', 'abstract': "Large Language Models (LLMs) have demonstrated potential for data science tasks via code generation. However, the exploratory nature of data science, alongside the stochastic and opaque outputs of LLMs, raise concerns about their reliability. While prior work focuses on benchmarking LLM accuracy, reproducibility remains underexplored, despite being critical to establishing trust in LLM-driven analysis.\nWe propose a novel analyst-inspector framework to automatically evaluate and enforce the reproducibility of LLM-generated data science workflows - the first rigorous approach to the best of our knowledge. Defining reproducibility as the sufficiency and completeness of workflows for reproducing functionally equivalent code, this framework enforces computational reproducibility principles, ensuring transparent, well-documented LLM workflows while minimizing reliance on implicit model assumptions.\nUsing this framework, we systematically evaluate five state-of-the-art LLMs on 1,032 data analysis tasks across three diverse benchmark datasets. We also introduce two novel reproducibility-enhancing prompting strategies. Our results show that higher reproducibility strongly correlates with improved accuracy and reproducibility-enhancing prompts are effective, demonstrating structured prompting's potential to enhance automated data science workflows and enable transparent, robust AI-driven analysis. Our code is publicly available.", 'abstract_zh': '大型语言模型（LLMs）通过代码生成在数据科学任务中展示了潜力，然而数据科学的探索性质以及LLMs的随机性和不透明输出引起了对其可靠性的 concern。尽管先前的工作集中在评估LLM的准确性上，但再现性的重复探索仍然不足，这在建立对LLM驱动分析的信任方面至关重要。\n\n我们提出了一种新的分析师-检查员框架，自动评估和保证LLM生成的数据科学工作流程的再现性——据我们所知，这是首个严格的方法。我们将再现性定义为工作流程在功能上等效代码可再现性的充分性和完整性，该框架确保计算可再现性原则的遵守，使LLM工作流程透明且文档齐全，同时最小化对隐式模型假设的依赖。\n\n使用此框架，我们系统地评估了五种最先进的LLMs在三个不同基准数据集上的1,032个数据分析任务。我们还引入了两种新的增强再现性的提示策略。我们的结果显示，更高的再现性与改进的准确性高度相关，并且增强再现性的提示策略是有效的，这表明结构化提示有可能增强自动数据科学流程并促进透明的、稳健的AI驱动分析。我们的代码已公开。', 'title_zh': '数据科学中大规模语言模型可再现性评估的分析师-检查员框架'}
{'arxiv_id': 'arXiv:2502.16389', 'title': 'An Expert Ensemble for Detecting Anomalous Scenes, Interactions, and Behaviors in Autonomous Driving', 'authors': 'Tianchen Ji, Neeloy Chakraborty, Andre Schreiber, Katherine Driggs-Campbell', 'link': 'https://arxiv.org/abs/2502.16389', 'abstract': 'As automated vehicles enter public roads, safety in a near-infinite number of driving scenarios becomes one of the major concerns for the widespread adoption of fully autonomous driving. The ability to detect anomalous situations outside of the operational design domain is a key component in self-driving cars, enabling us to mitigate the impact of abnormal ego behaviors and to realize trustworthy driving systems. On-road anomaly detection in egocentric videos remains a challenging problem due to the difficulties introduced by complex and interactive scenarios. We conduct a holistic analysis of common on-road anomaly patterns, from which we propose three unsupervised anomaly detection experts: a scene expert that focuses on frame-level appearances to detect abnormal scenes and unexpected scene motions; an interaction expert that models normal relative motions between two road participants and raises alarms whenever anomalous interactions emerge; and a behavior expert which monitors abnormal behaviors of individual objects by future trajectory prediction. To combine the strengths of all the modules, we propose an expert ensemble (Xen) using a Kalman filter, in which the final anomaly score is absorbed as one of the states and the observations are generated by the experts. Our experiments employ a novel evaluation protocol for realistic model performance, demonstrate superior anomaly detection performance than previous methods, and show that our framework has potential in classifying anomaly types using unsupervised learning on a large-scale on-road anomaly dataset.', 'abstract_zh': '随着自动驾驶车辆进入公共道路，无限多驾驶场景中的安全性成为全面推广完全自动驾驶技术的主要关切。检测超出操作设计域的异常情况能力是自动驾驶汽车的关键组成部分，这使我们能够减轻异常自我行为的影响并实现可信赖的驾驶系统。由于复杂且交互性的场景带来的困难，基于第一人称视频的道路异常检测仍然是一个具有挑战性的问题。我们对常见的道路异常模式进行了全面分析，并提出三种无监督异常检测专家：场景专家专注于帧级外观以检测异常场景和意外场景运动；交互专家建模两个道路参与者之间的正常相对运动，并在异常交互出现时发出警报；行为专家通过未来轨迹预测监控个体对象的异常行为。为了整合各模块的优势，我们提出了一种专家集成（Xen），使用卡尔曼滤波器，在其中最终的异常分数作为状态之一，并由专家生成观察值。我们的实验采用了新的评估协议以展示现实模型性能，表明我们的方法在异常检测性能上优于以往方法，并展示了我们在大规模道路上异常数据集上使用无监督学习分类异常类型方面的潜力。', 'title_zh': '基于专家集成的自动驾驶中异常场景、交互和行为检测方法'}
{'arxiv_id': 'arXiv:2502.16380', 'title': 'Understanding Fixed Predictions via Confined Regions', 'authors': 'Connor Lawless, Tsui-Wei Weng, Berk Ustun, Madeleine Udell', 'link': 'https://arxiv.org/abs/2502.16380', 'abstract': 'Machine learning models are designed to predict outcomes using features about an individual, but fail to take into account how individuals can change them. Consequently, models can assign fixed predictions that deny individuals recourse to change their outcome. This work develops a new paradigm to identify fixed predictions by finding confined regions in which all individuals receive fixed predictions. We introduce the first method, ReVer, for this task, using tools from mixed-integer quadratically constrained programming. Our approach certifies recourse for out-of-sample data, provides interpretable descriptions of confined regions, and runs in seconds on real world datasets. We conduct a comprehensive empirical study of confined regions across diverse applications. Our results highlight that existing point-wise verification methods fail to discover confined regions, while ReVer provably succeeds.', 'abstract_zh': '机器学习模型设计用于根据个体特征预测结果，但未能考虑个体如何改变这些特征。因此，模型可能会分配固定不变的预测，阻止个体改变其结果。本工作开发了一种新范式，通过识别所有个体都收到固定预测的限定区域来识别固定预测。我们提出了第一个用于此任务的方法ReVer，并使用混合整数二次约束编程工具。我们的方法可以为未见过的数据提供救济保障，提供限定区域的可解释描述，并在实际数据集上以秒级速度运行。我们在多种应用中进行了全面的实证研究。研究结果表明，现有点wise验证方法无法发现限定区域，而ReVer可以证明成功。', 'title_zh': '通过限制区域理解固定预测'}
{'arxiv_id': 'arXiv:2502.16378', 'title': 'Auto-ADMET: An Effective and Interpretable AutoML Method for Chemical ADMET Property Prediction', 'authors': 'Alex G. C. de Sá, David B. Ascher', 'link': 'https://arxiv.org/abs/2502.16378', 'abstract': "Machine learning (ML) has been playing important roles in drug discovery in the past years by providing (pre-)screening tools for prioritising chemical compounds to pass through wet lab experiments. One of the main ML tasks in drug discovery is to build quantitative structure-activity relationship (QSAR) models, associating the molecular structure of chemical compounds with an activity or property. These properties -- including absorption, distribution, metabolism, excretion and toxicity (ADMET) -- are essential to model compound behaviour, activity and interactions in the organism. Although several methods exist, the majority of them do not provide an appropriate model's personalisation, yielding to bias and lack of generalisation to new data since the chemical space usually shifts from application to application. This fact leads to low predictive performance when completely new data is being tested by the model. The area of Automated Machine Learning (AutoML) emerged aiming to solve this issue, outputting tailored ML algorithms to the data at hand. Although an important task, AutoML has not been practically used to assist cheminformatics and computational chemistry researchers often, with just a few works related to the field. To address these challenges, this work introduces Auto-ADMET, an interpretable evolutionary-based AutoML method for chemical ADMET property prediction. Auto-ADMET employs a Grammar-based Genetic Programming (GGP) method with a Bayesian Network Model to achieve comparable or better predictive performance against three alternative methods -- standard GGP method, pkCSM and XGBOOST model -- on 12 benchmark chemical ADMET property prediction datasets. The use of a Bayesian Network model on Auto-ADMET's evolutionary process assisted in both shaping the search procedure and interpreting the causes of its AutoML performance.", 'abstract_zh': '自动机器学习（AutoML）在化学ADMET性质预测中的可解释演化方法：Auto-ADMET', 'title_zh': 'Auto-ADMET：一种高效可解释的化学ADMET性质预测自动化机器学习方法'}
{'arxiv_id': 'arXiv:2502.16375', 'title': 'Personhood Credentials: Human-Centered Design Recommendation Balancing Security, Usability, and Trust', 'authors': 'Ayae Ide, Tanusree Sharma', 'link': 'https://arxiv.org/abs/2502.16375', 'abstract': 'Building on related concepts, like, decentralized identifiers (DIDs), proof of personhood, anonymous credentials, personhood credentials (PHCs) emerged as an alternative approach, enabling individuals to verify to digital service providers that they are a person without disclosing additional information. However, new technologies might introduce some friction due to users misunderstandings and mismatched expectations. Despite their growing importance, limited research has been done on users perceptions and preferences regarding PHCs. To address this gap, we conducted competitive analysis, and semi-structured online user interviews with 23 participants from US and EU to provide concrete design recommendations for PHCs that incorporate user needs, adoption rules, and preferences. Our study -- (a)surfaces how people reason about unknown privacy and security guarantees of PHCs compared to current verification methods -- (b) presents the impact of several factors on how people would like to onboard and manage PHCs, including, trusted issuers (e.g. gov), ground truth data to issue PHC (e.g biometrics, physical id), and issuance system (e.g. centralized vs decentralized). In a think-aloud conceptual design session, participants recommended -- conceptualized design, such as periodic biometrics verification, time-bound credentials, visually interactive human-check, and supervision of government for issuance system. We propose actionable designs reflecting users preferences.', 'abstract_zh': '基于分散标识符（DIDs）、人证证明、匿名凭证等相关概念，个人凭证（PHCs）作为一种替代方案 emerga，使个人能够向数字服务提供商验证自己的身份而不披露额外信息。然而，新技术might引入一些摩擦，由于用户误解和期望不匹配。尽管PHCs的重要性日益增加，关于用户对PHCs的认知和偏好方面的研究有限。为填平这一缺口，我们进行了竞争性分析，并对来自美国和欧盟的23名参与者进行了半结构化在线用户访谈，以提出结合用户需求、采用规则和偏好的具体设计建议。我们的研究——(a)揭示了人们如何推理PHCs与现有验证方法相比的未知隐私和安全保证——(b)展示了多个因素如何影响人们希望上线和管理PHCs的方式，包括可信发行方（如政府）、用于发行PHC的真实数据（如生物特征、物理ID）以及发行系统（如集中式 versus 分布式）。在现声思考概念设计会中，参与者建议了概念设计，如定期生物特征验证、时限凭证、视觉互动的人工验证和发行系统的政府监督。我们提出了反映用户偏好的可操作性设计。', 'title_zh': '人性认证：平衡安全、可用性和信任的人本设计推荐'}
{'arxiv_id': 'arXiv:2502.16366', 'title': 'A generative approach to LLM harmfulness detection with special red flag tokens', 'authors': 'Sophie Xhonneux, David Dobre, Mehrnaz Mohfakhami, Leo Schwinn, Gauthier Gidel', 'link': 'https://arxiv.org/abs/2502.16366', 'abstract': "Most safety training methods for large language models (LLMs) based on fine-tuning rely on dramatically changing the output distribution of the model when faced with a harmful request, shifting it from an unsafe answer to a refusal to respond. These methods inherently compromise model capabilities and might make auto-regressive models vulnerable to attacks that make likely an initial token of affirmative response. To avoid that, we propose to expand the model's vocabulary with a special token we call red flag token (<rf>) and propose to fine-tune the model to generate this token at any time harmful content is generated or about to be generated. This novel safety training method effectively augments LLMs into generative classifiers of harmfulness at all times during the conversation. This method offers several advantages: it enables the model to explicitly learn the concept of harmfulness while marginally affecting the generated distribution, thus maintaining the model's utility. It also evaluates each generated answer rather than just the input prompt and provides a stronger defence against sampling-based attacks. In addition, it simplifies the evaluation of the model's robustness and reduces correlated failures when combined with a classifier. We further show an increased robustness to long contexts, and supervised fine-tuning attacks.", 'abstract_zh': '基于扩展词汇量的有害内容生成标记方法：一种新的大型语言模型安全训练方法', 'title_zh': '基于特殊红旗标记 token 的生成方法在大规模语言模型有害内容检测中的应用'}
{'arxiv_id': 'arXiv:2502.16359', 'title': 'Audio Visual Segmentation Through Text Embeddings', 'authors': 'Kyungbok Lee, You Zhang, Zhiyao Duan', 'link': 'https://arxiv.org/abs/2502.16359', 'abstract': "The goal of Audio-Visual Segmentation (AVS) is to localize and segment the sounding source objects from the video frames. Researchers working on AVS suffer from limited datasets because hand-crafted annotation is expensive. Recent works attempt to overcome the challenge of limited data by leveraging the segmentation foundation model, SAM, prompting it with audio to enhance its ability to segment sounding source objects. While this approach alleviates the model's burden on understanding visual modality by utilizing pre-trained knowledge of SAM, it does not address the fundamental challenge of the limited dataset for learning audio-visual relationships. To address these limitations, we propose \\textbf{AV2T-SAM}, a novel framework that bridges audio features with the text embedding space of pre-trained text-prompted SAM. Our method leverages multimodal correspondence learned from rich text-image paired datasets to enhance audio-visual alignment. Furthermore, we introduce a novel feature, $\\mathbf{\\textit{\\textbf{f}}_{CLIP} \\odot \\textit{\\textbf{f}}_{CLAP}}$, which emphasizes shared semantics of audio and visual modalities while filtering irrelevant noise. Experiments on the AVSBench dataset demonstrate state-of-the-art performance on both datasets of AVSBench. Our approach outperforms existing methods by effectively utilizing pretrained segmentation models and cross-modal semantic alignment.", 'abstract_zh': '基于视听分割的音频-视觉分割（AV2T-SAM）框架：结合音频特征与预训练文本指导SAM的文本嵌入空间', 'title_zh': '通过文本嵌入进行音视频分割'}
{'arxiv_id': 'arXiv:2502.16343', 'title': 'Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading Agents', 'authors': 'David Byrd', 'link': 'https://arxiv.org/abs/2502.16343', 'abstract': 'Companies across all economic sectors continue to deploy large language models at a rapid pace. Reinforcement learning is experiencing a resurgence of interest due to its association with the fine-tuning of language models from human feedback. Tool-chain language models control task-specific agents; if the converse has not already appeared, it soon will. In this paper, we present what we believe is the first investigation of an intelligent trading agent based on continuous deep reinforcement learning that also controls a large language model with which it can post to a social media feed observed by other traders. We empirically investigate the performance and impact of such an agent in a simulated financial market, finding that it learns to optimize its total reward, and thereby augment its profit, by manipulating the sentiment of the posts it produces. The paper concludes with discussion, limitations, and suggestions for future work.', 'abstract_zh': '跨所有经济领域的公司正以快速的步伐部署大型语言模型。强化学习由于与从人类反馈中微调语言模型的关联而重新引起关注。工具链语言模型控制特定任务的代理；如果反向情况尚未出现，很快也将出现。本文提出了基于连续深度强化学习的智能交易代理的第一项研究，该代理还控制着一个可以发布到其他交易者可观察的社会媒体 feed 的大型语言模型。我们在模拟金融市场中实证研究了该代理的表现及其影响，发现它通过操控其发布的帖子的情感来学习优化其总奖励，从而增加其利润。论文以讨论、限制和对未来工作的建议作为结语。', 'title_zh': '探索LLM-enable智能交易代理的情感操纵'}
{'arxiv_id': 'arXiv:2502.16331', 'title': 'A Gap Between the Gaussian RKHS and Neural Networks: An Infinite-Center Asymptotic Analysis', 'authors': 'Akash Kumar, Rahul Parhi, Mikhail Belkin', 'link': 'https://arxiv.org/abs/2502.16331', 'abstract': 'Recent works have characterized the function-space inductive bias of infinite-width bounded-norm single-hidden-layer neural networks as a kind of bounded-variation-type space. This novel neural network Banach space encompasses many classical multivariate function spaces including certain Sobolev spaces and the spectral Barron spaces. Notably, this Banach space also includes functions that exhibit less classical regularity such as those that only vary in a few directions. On bounded domains, it is well-established that the Gaussian reproducing kernel Hilbert space (RKHS) strictly embeds into this Banach space, demonstrating a clear gap between the Gaussian RKHS and the neural network Banach space. It turns out that when investigating these spaces on unbounded domains, e.g., all of $\\mathbb{R}^d$, the story is fundamentally different. We establish the following fundamental result: Certain functions that lie in the Gaussian RKHS have infinite norm in the neural network Banach space. This provides a nontrivial gap between kernel methods and neural networks by the exhibition of functions in which kernel methods can do strictly better than neural networks.', 'abstract_zh': '近期研究将无限宽有界范数单隐藏层神经网络的功能空间归纳偏置characterized为一类有界变差型空间。这种新型神经网络Banach空间包括了许多经典的多元函数空间，如某些Sobolev空间和谱Barron空间。值得注意的是，这种Banach空间还包含了只有在少数方向上才表现出非经典正则性的函数。在有界域上，Gaussian再生核希尔伯特空间（RKHS）严格嵌入到这种Banach空间中，表明Gaussian RKHS与神经网络Banach空间之间存在明显的差距。有趣的是，在探讨这些空间在未加界域上的情况，例如$\\mathbb{R}^d$时，情况变得根本不同。我们得到了以下基本结果：某些位于Gaussian RKHS中的函数在神经网络Banach空间中的范数无限大。这通过展示一类函数，在这些函数上核方法比神经网络可以更优，提供了一个非平凡的差距。', 'title_zh': '高斯RKHS与神经网络之间的一个差距：无穷中心渐近分析'}
{'arxiv_id': 'arXiv:2502.16324', 'title': 'Deep Time Warping for Multiple Time Series Alignment', 'authors': 'Alireza Nourbakhsh, Hoda Mohammadzade', 'link': 'https://arxiv.org/abs/2502.16324', 'abstract': 'Time Series Alignment is a critical task in signal processing with numerous real-world applications. In practice, signals often exhibit temporal shifts and scaling, making classification on raw data prone to errors. This paper introduces a novel approach for Multiple Time Series Alignment (MTSA) leveraging Deep Learning techniques. While most existing methods primarily address Multiple Sequence Alignment (MSA) for protein and DNA sequences, there remains a significant gap in alignment methodologies for numerical time series. Additionally, conventional approaches typically focus on pairwise alignment, whereas our proposed method aligns all signals in a multiple manner (all the signals are aligned together at once). This innovation not only enhances alignment efficiency but also significantly improves computational speed. By decomposing into piece-wise linear sections, we introduce varying levels of complexity into the warping function. Additionally, our method ensures the satisfaction of three warping constraints: boundary, monotonicity, and continuity conditions. The utilization of a deep convolutional network allows us to employ a new loss function, addressing some limitations of Dynamic Time Warping (DTW). Experimental results on the UCR Archive 2018, comprising 129 time series datasets, demonstrate that employing our approach to align signals significantly enhances classification accuracy and warping average and also reduces the run time across the majority of these datasets.', 'abstract_zh': '时间序列对齐是信号处理中的一个关键任务，具有众多实际应用。本文提出了一种利用深度学习技术进行多时间序列对齐（MTSA）的新方法。尽管大多数现有方法主要针对蛋白质和DNA序列的多重序列对齐（MSA），但对于数值时间序列仍缺乏有效的对齐方法。此外，传统方法通常侧重于两两对齐，而我们提出的方法则以多对齐的方式同时对齐所有信号。这一创新不仅提高了对齐效率，还显著提高了计算速度。通过将对齐函数分解为分段线性部分，我们引入了不同程度的复杂性。此外，我们的方法确保对齐函数满足边界、单调性和连续性条件。使用深度卷积网络允许我们采用新的损失函数，解决了一些动态时间对齐（DTW）的局限性。实验结果表明，使用我们的方法对齐信号可以显著提高分类准确率和对齐平均质量，并在大多数数据集中减少运行时间。', 'title_zh': '深度时间扭曲用于多重时间序列对齐'}
{'arxiv_id': 'arXiv:2502.16312', 'title': 'Iterative Auto-Annotation for Scientific Named Entity Recognition Using BERT-Based Models', 'authors': 'Kartik Gupta', 'link': 'https://arxiv.org/abs/2502.16312', 'abstract': 'This paper presents an iterative approach to performing Scientific Named Entity Recognition (SciNER) using BERT-based models. We leverage transfer learning to fine-tune pretrained models with a small but high-quality set of manually annotated data. The process is iteratively refined by using the fine-tuned model to auto-annotate a larger dataset, followed by additional rounds of fine-tuning. We evaluated two models, dslim/bert-large-NER and bert-largecased, and found that bert-large-cased consistently outperformed the former. Our approach demonstrated significant improvements in prediction accuracy and F1 scores, especially for less common entity classes. Future work could include pertaining with unlabeled data, exploring more powerful encoders like RoBERTa, and expanding the scope of manual annotations. This methodology has broader applications in NLP tasks where access to labeled data is limited.', 'abstract_zh': '本文提出了一种迭代的方法，使用基于BERT的模型进行科学命名实体识别（SciNER）。我们通过利用迁移学习，使用少量但高质量的手工标注数据对预训练模型进行微调。通过使用微调后的模型自动标注更大规模的数据集，并进行额外的微调，不断优化这一过程。我们评估了两种模型（dslim/bert-large-NER 和 bert-large-cased），发现 bert-large-cased 在预测准确性方面始终优于前者。我们的方法在预测准确性和F1分数方面取得了显著改进，尤其是在处理较不常见的实体类别时。未来的工作可以包括处理未标注数据、探索更强大的编码器如RoBERTa以及扩展手动标注的范围。该方法在标注数据有限的NLP任务中具有更广泛的应用前景。', 'title_zh': '基于BERT模型的迭代自动标注的科学命名实体识别'}
{'arxiv_id': 'arXiv:2502.16299', 'title': 'A calibration test for evaluating set-based epistemic uncertainty representations', 'authors': 'Mira Jürgens, Thomas Mortier, Eyke Hüllermeier, Viktor Bengs, Willem Waegeman', 'link': 'https://arxiv.org/abs/2502.16299', 'abstract': "The accurate representation of epistemic uncertainty is a challenging yet essential task in machine learning. A widely used representation corresponds to convex sets of probabilistic predictors, also known as credal sets. One popular way of constructing these credal sets is via ensembling or specialized supervised learning methods, where the epistemic uncertainty can be quantified through measures such as the set size or the disagreement among members. In principle, these sets should contain the true data-generating distribution. As a necessary condition for this validity, we adopt the strongest notion of calibration as a proxy. Concretely, we propose a novel statistical test to determine whether there is a convex combination of the set's predictions that is calibrated in distribution. In contrast to previous methods, our framework allows the convex combination to be instance dependent, recognizing that different ensemble members may be better calibrated in different regions of the input space. Moreover, we learn this combination via proper scoring rules, which inherently optimize for calibration. Building on differentiable, kernel-based estimators of calibration errors, we introduce a nonparametric testing procedure and demonstrate the benefits of capturing instance-level variability on of synthetic and real-world experiments.", 'abstract_zh': '准确表示epistemic不确定性是机器学习中一项挑战性但至关重要的任务。一种常用的表示方式对应于概率预测的凸集，也称为信念集。这些信念集的一种常见构建方式是通过集成或专用于监督学习的方法，其中可以通过集合大小或成员之间的分歧等度量来量化epistemic不确定性。原则上，这些集合应包含真实的数据生成分布。作为这种有效性的一个必要条件，我们采用最强的校准概念作为代理。具体地，我们提出了一种新的统计检验，用于确定集合预测是否存在凸组合使其在分布上校准。与其他方法相比，我们的框架允许凸组合依赖于实例，认识到不同集成成员在输入空间的不同区域可能校准更好。此外，我们通过适当的评分规则学习这一组合，这些规则自然地优化了校准。基于可微的核基校准误差估计器，我们引入了一种非参数检验方法，并在合成和真实世界实验中展示了捕捉实例级变异性的优势。', 'title_zh': '基于集的epistemic不确定性表示的校准测试'}
{'arxiv_id': 'arXiv:2502.16294', 'title': 'TimePFN: Effective Multivariate Time Series Forecasting with Synthetic Data', 'authors': 'Ege Onur Taga, M. Emrullah Ildiz, Samet Oymak', 'link': 'https://arxiv.org/abs/2502.16294', 'abstract': 'The diversity of time series applications and scarcity of domain-specific data highlight the need for time-series models with strong few-shot learning capabilities. In this work, we propose a novel training scheme and a transformer-based architecture, collectively referred to as TimePFN, for multivariate time-series (MTS) forecasting. TimePFN is based on the concept of Prior-data Fitted Networks (PFN), which aims to approximate Bayesian inference. Our approach consists of (1) generating synthetic MTS data through diverse Gaussian process kernels and the linear coregionalization method, and (2) a novel MTS architecture capable of utilizing both temporal and cross-channel dependencies across all input patches. We evaluate TimePFN on several benchmark datasets and demonstrate that it outperforms the existing state-of-the-art models for MTS forecasting in both zero-shot and few-shot settings. Notably, fine-tuning TimePFN with as few as 500 data points nearly matches full dataset training error, and even 50 data points yield competitive results. We also find that TimePFN exhibits strong univariate forecasting performance, attesting to its generalization ability. Overall, this work unlocks the power of synthetic data priors for MTS forecasting and facilitates strong zero- and few-shot forecasting performance.', 'abstract_zh': '时间序列应用的多样性和领域特定数据的稀缺性突显了强少样本学习能力的时间序列模型的需求。本研究提出了一种新型训练方案和基于变压器的架构，统称为TimePFN，用于多变量时间序列（MTS）预测。TimePFN基于先验数据拟合网络（PFN）的概念，旨在近似贝叶斯推理。我们的方法包括（1）通过多样化的高斯过程核和线性协区域化方法生成合成MTS数据，以及（2）一种新型的MTS架构，能够利用所有输入片段中的时空和跨通道依赖性。我们在多个基准数据集上评估了TimePFN，并展示了它在零样本和少样本设置中均优于现有最先进的MTS预测模型。值得注意的是，使用仅500个数据点微调TimePFN几乎可以匹配全数据集训练误差，甚至使用50个数据点也能获得竞争力的结果。我们还发现，TimePFN在单变量预测中表现出强大的性能，证明了其泛化能力。总体而言，本文解锁了合成数据先验在MTS预测中的力量，并促进了出色的零样本和少样本预测性能。', 'title_zh': '时间合成法：有效的多变量时间序列预测'}
{'arxiv_id': 'arXiv:2502.16291', 'title': 'The Design Space of Recent AI-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity', 'authors': 'Runlong Ye, Matthew Varona, Oliver Huang, Patrick Yung Kang Lee, Michael Liut, Carolina Nobre', 'link': 'https://arxiv.org/abs/2502.16291', 'abstract': "Generative AI (GenAI) tools are radically expanding the scope and capability of automation in knowledge work such as academic research. AI-assisted research tools show promise for augmenting human cognition and streamlining research processes, but could potentially increase automation bias and stifle critical thinking. We surveyed the past three years of publications from leading HCI venues. We closely examined 11 AI-assisted research tools, five employing traditional AI approaches and six integrating GenAI, to explore how these systems envision novel capabilities and design spaces. We consolidate four design recommendations that inform cognitive engagement when working with an AI research tool: Providing user agency and control; enabling divergent and convergent thinking; supporting adaptability and flexibility; and ensuring transparency and accuracy. We discuss how these ideas mark a shift in AI-assisted research tools from mimicking a researcher's established workflows to generative co-creation with the researcher and the opportunities this shift affords the research community.", 'abstract_zh': '生成式AI工具正在不断扩大知识工作中，如学术研究的自动化范围和能力。AI辅助的研究工具有望增强人类的认知并简化研究流程，但也可能增加自动化偏见并抑制批判性思维。我们调研了过去三年内领先的人机交互会议的发表论文。我们详细研究了11款AI辅助的研究工具，其中5款采用传统AI方法，6款结合生成式AI，以探索这些系统所设想的新能力和设计空间。我们整合了四条设计建议，以指导在使用AI研究工具时的认知参与：提供用户自主权和控制；促进发散和收敛思维；支持适应性和灵活性；并确保透明度和准确性。我们讨论了这些想法如何标志着AI辅助研究工具从模仿研究人员已有的工作流程向与研究人员的生成式协同创作的转变，并探讨了这一转变为研究社区带来的机会。', 'title_zh': 'Recent AI-assisted Research Tools for Ideation, Sensemaking, and Scientific Creativity的设计空间探究'}
{'arxiv_id': 'arXiv:2502.16286', 'title': 'Verification of Bit-Flip Attacks against Quantized Neural Networks', 'authors': 'Yedi Zhang, Lei Huang, Pengfei Gao, Fu Song, Jun Sun, Jin Song Dong', 'link': 'https://arxiv.org/abs/2502.16286', 'abstract': 'In the rapidly evolving landscape of neural network security, the resilience of neural networks against bit-flip attacks (i.e., an attacker maliciously flips an extremely small amount of bits within its parameter storage memory system to induce harmful behavior), has emerged as a relevant area of research. Existing studies suggest that quantization may serve as a viable defense against such attacks. Recognizing the documented susceptibility of real-valued neural networks to such attacks and the comparative robustness of quantized neural networks (QNNs), in this work, we introduce BFAVerifier, the first verification framework designed to formally verify the absence of bit-flip attacks or to identify all vulnerable parameters in a sound and rigorous manner. BFAVerifier comprises two integral components: an abstraction-based method and an MILP-based method. Specifically, we first conduct a reachability analysis with respect to symbolic parameters that represent the potential bit-flip attacks, based on a novel abstract domain with a sound guarantee. If the reachability analysis fails to prove the resilience of such attacks, then we encode this verification problem into an equivalent MILP problem which can be solved by off-the-shelf solvers. Therefore, BFAVerifier is sound, complete, and reasonably efficient. We conduct extensive experiments, which demonstrate its effectiveness and efficiency across various network architectures, quantization bit-widths, and adversary capabilities.', 'abstract_zh': '神经网络安全快速演变的背景下，神经网络抵御位翻转攻击的鲁棒性研究：BFAVerifier——首个形式化验证框架', 'title_zh': '针对量ized神经网络的位翻转攻击验证'}
{'arxiv_id': 'arXiv:2502.16284', 'title': 'MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra', 'authors': 'Liang Wang, Shaozhen Liu, Yu Rong, Deli Zhao, Qiang Liu, Shu Wu, Liang Wang', 'link': 'https://arxiv.org/abs/2502.16284', 'abstract': "Establishing the relationship between 3D structures and the energy states of molecular systems has proven to be a promising approach for learning 3D molecular representations. However, existing methods are limited to modeling the molecular energy states from classical mechanics. This limitation results in a significant oversight of quantum mechanical effects, such as quantized (discrete) energy level structures, which offer a more accurate estimation of molecular energy and can be experimentally measured through energy spectra. In this paper, we propose to utilize the energy spectra to enhance the pre-training of 3D molecular representations (MolSpectra), thereby infusing the knowledge of quantum mechanics into the molecular representations. Specifically, we propose SpecFormer, a multi-spectrum encoder for encoding molecular spectra via masked patch reconstruction. By further aligning outputs from the 3D encoder and spectrum encoder using a contrastive objective, we enhance the 3D encoder's understanding of molecules. Evaluations on public benchmarks reveal that our pre-trained representations surpass existing methods in predicting molecular properties and modeling dynamics.", 'abstract_zh': '利用能量谱增强三维分子表示的预训练：结合量子力学知识', 'title_zh': 'MolSpectra: 基于多模态能量光谱预训练3D分子表示'}
{'arxiv_id': 'arXiv:2502.16282', 'title': 'Understanding the Emergence of Multimodal Representation Alignment', 'authors': 'Megan Tjandrasuwita, Chanakya Ekbote, Liu Ziyin, Paul Pu Liang', 'link': 'https://arxiv.org/abs/2502.16282', 'abstract': 'Multimodal representation learning is fundamentally about transforming incomparable modalities into comparable representations. While prior research primarily focused on explicitly aligning these representations through targeted learning objectives and model architectures, a recent line of work has found that independently trained unimodal models of increasing scale and performance can become implicitly aligned with each other. These findings raise fundamental questions regarding the emergence of aligned representations in multimodal learning. Specifically: (1) when and why does alignment emerge implicitly? and (2) is alignment a reliable indicator of performance? Through a comprehensive empirical investigation, we demonstrate that both the emergence of alignment and its relationship with task performance depend on several critical data characteristics. These include, but are not necessarily limited to, the degree of similarity between the modalities and the balance between redundant and unique information they provide for the task. Our findings suggest that alignment may not be universally beneficial; rather, its impact on performance varies depending on the dataset and task. These insights can help practitioners determine whether increasing alignment between modalities is advantageous or, in some cases, detrimental to achieving optimal performance. Code is released at this https URL.', 'abstract_zh': '多模态表示学习本质上是将不可比较的模态转换为可比较的表示。尽管先前的研究主要通过目标学习任务和模型架构来显式对齐这些表示，近期的一项研究成果发现，独立训练的、规模和性能不断增加的单模态模型可以隐式对齐。这些发现引发了关于多模态学习中对齐表示出现的基本问题，具体包括：（1）在何时以及为何种情况下对齐会隐式出现？（2）对齐是否是性能可靠的指标？通过全面的实证研究，我们证明了对齐的出现及其与任务性能的关系取决于多种关键的数据特征，这些特征包括模态之间的相似度以及它们为任务提供的冗余信息与独特信息之间的平衡。我们的研究结果表明，对齐并不一定是普遍有益的，其对性能的影响取决于数据集和任务。这些见解可以帮助从业者判断增加模态之间的对齐是否对实现最佳性能有利，在某些情况下可能是不利的。代码发布在该网址：https://。', 'title_zh': '多模态表示对齐的 emergence 机制理解'}
{'arxiv_id': 'arXiv:2502.16280', 'title': 'Human Preferences in Large Language Model Latent Space: A Technical Analysis on the Reliability of Synthetic Data in Voting Outcome Prediction', 'authors': 'Sarah Ball, Simeon Allmendinger, Frauke Kreuter, Niklas Kühl', 'link': 'https://arxiv.org/abs/2502.16280', 'abstract': 'Generative AI (GenAI) is increasingly used in survey contexts to simulate human preferences. While many research endeavors evaluate the quality of synthetic GenAI data by comparing model-generated responses to gold-standard survey results, fundamental questions about the validity and reliability of using LLMs as substitutes for human respondents remain. Our study provides a technical analysis of how demographic attributes and prompt variations influence latent opinion mappings in large language models (LLMs) and evaluates their suitability for survey-based predictions. Using 14 different models, we find that LLM-generated data fails to replicate the variance observed in real-world human responses, particularly across demographic subgroups. In the political space, persona-to-party mappings exhibit limited differentiation, resulting in synthetic data that lacks the nuanced distribution of opinions found in survey data. Moreover, we show that prompt sensitivity can significantly alter outputs for some models, further undermining the stability and predictiveness of LLM-based simulations. As a key contribution, we adapt a probe-based methodology that reveals how LLMs encode political affiliations in their latent space, exposing the systematic distortions introduced by these models. Our findings highlight critical limitations in AI-generated survey data, urging caution in its use for public opinion research, social science experimentation, and computational behavioral modeling.', 'abstract_zh': '生成式AI（GenAI）在调查情境中日益用于模拟人类偏好。虽然许多研究致力于通过比较模型生成的响应与黄金标准调查结果来评估合成GenAI数据的质量，但使用大型语言模型（LLMs）作为人类受访者的替代品的有效性和可靠性仍存在根本性问题。我们的研究提供了关于人口统计属性和提示变化如何影响LLMs中潜在意见映射的技术分析，并评估了它们在基于调查的预测中的适用性。使用14个不同的模型，我们发现LLM生成的数据未能复制真实世界人类响应中的变异，特别是在不同人口统计子群体之间。在政治领域，个性与政党的映射表现出有限的差异性，导致合成数据缺乏调查数据中观察到的意见细微分布。此外，我们表明，提示敏感性可以显著改变某些模型的输出，进一步削弱基于LLM的模拟的稳定性和预测性。作为一项关键贡献，我们采用了一种基于探针的方法，揭示了LLMs如何在其隐空间中编码政治倾向，并暴露了这些模型引入的系统性失真。我们的发现揭示了AI生成的调查数据的关键限制，提醒人们在公共意见研究、社会科学研究和计算行为建模中谨慎使用这些数据。', 'title_zh': '大型语言模型潜在空间中的人类偏好：合成数据在投票结果预测中的可靠性技术分析'}
{'arxiv_id': 'arXiv:2502.16279', 'title': 'Beyond Trusting Trust: Multi-Model Validation for Robust Code Generation', 'authors': 'Bradley McDanel', 'link': 'https://arxiv.org/abs/2502.16279', 'abstract': 'This paper explores the parallels between Thompson\'s "Reflections on Trusting Trust" and modern challenges in LLM-based code generation. We examine how Thompson\'s insights about compiler backdoors take on new relevance in the era of large language models, where the mechanisms for potential exploitation are even more opaque and difficult to analyze. Building on this analogy, we discuss how the statistical nature of LLMs creates novel security challenges in code generation pipelines. As a potential direction forward, we propose an ensemble-based validation approach that leverages multiple independent models to detect anomalous code patterns through cross-model consensus. This perspective piece aims to spark discussion about trust and validation in AI-assisted software development.', 'abstract_zh': '本论文探讨了Thompson的“信任信任的反思”与基于大语言模型的代码生成现代挑战之间的相似性。我们研究了Thompson关于编译器后门的洞察在大语言模型时代的新相关性，那里潜在利用的机制更加不透明和难以分析。基于这一类比，我们讨论了大语言模型的统计性质给代码生成流水线带来了新的安全挑战。作为前进的方向，我们提出了一种基于集成的验证方法，利用多个独立模型通过跨模型共识检测异常代码模式。本文旨在引发关于AI辅助软件开发中的信任和验证的讨论。', 'title_zh': '超越信任信任：多模型验证以实现稳健的代码生成'}
{'arxiv_id': 'arXiv:2502.16274', 'title': 'Fine-Tuning Qwen 2.5 3B for Realistic Movie Dialogue Generation', 'authors': 'Kartik Gupta', 'link': 'https://arxiv.org/abs/2502.16274', 'abstract': "The Qwen 2.5 3B base model was fine-tuned to generate contextually rich and engaging movie dialogue, leveraging the Cornell Movie-Dialog Corpus, a curated dataset of movie conversations. Due to the limitations in GPU computing and VRAM, the training process began with the 0.5B model progressively scaling up to the 1.5B and 3B versions as efficiency improvements were implemented. The Qwen 2.5 series, developed by Alibaba Group, stands at the forefront of small open-source pre-trained models, particularly excelling in creative tasks compared to alternatives like Meta's Llama 3.2 and Google's Gemma. Results demonstrate the ability of small models to produce high-quality, realistic dialogue, offering a promising approach for real-time, context-sensitive conversation generation.", 'abstract_zh': 'Qwen 2.5 3B基模型根据Cornell Movie-Dialog Corpus数据集进行了微调，以生成富有情境感且引人入胜的电影对话。由于GPU计算能力和VRAM的限制，训练过程从0.5B模型逐步扩展到1.5B和3B版本，同时实施了效率改进措施。阿里巴巴集团开发的Qwen 2.5系列在小型开源预训练模型中处于领先地位，特别在创造性任务方面优于Meta的Llama 3.2和Google的Gemma等替代模型。结果表明，小型模型能够生成高质量、逼真的对话，提供了实时、情境感知对话生成的有前途的方法。', 'title_zh': 'Fine-Tuning Qwen 2.5 3B for Realistic Movie Dialogue Generation'}
{'arxiv_id': 'arXiv:2502.16255', 'title': 'rECGnition_v2.0: Self-Attentive Canonical Fusion of ECG and Patient Data using deep learning for effective Cardiac Diagnostics', 'authors': 'Shreya Srivastava, Durgesh Kumar, Ram Jiwari, Sandeep Seth, Deepak Sharma', 'link': 'https://arxiv.org/abs/2502.16255', 'abstract': 'The variability in ECG readings influenced by individual patient characteristics has posed a considerable challenge to adopting automated ECG analysis in clinical settings. A novel feature fusion technique termed SACC (Self Attentive Canonical Correlation) was proposed to address this. This technique is combined with DPN (Dual Pathway Network) and depth-wise separable convolution to create a robust, interpretable, and fast end-to-end arrhythmia classification model named rECGnition_v2.0 (robust ECG abnormality detection). This study uses MIT-BIH, INCARTDB and EDB dataset to evaluate the efficiency of rECGnition_v2.0 for various classes of arrhythmias. To investigate the influence of constituting model components, various ablation studies were performed, i.e. simple concatenation, CCA and proposed SACC were compared, while the importance of global and local ECG features were tested using DPN rECGnition_v2.0 model and vice versa. It was also benchmarked with state-of-the-art CNN models for overall accuracy vs model parameters, FLOPs, memory requirements, and prediction time. Furthermore, the inner working of the model was interpreted by comparing the activation locations in ECG before and after the SACC layer. rECGnition_v2.0 showed a remarkable accuracy of 98.07% and an F1-score of 98.05% for classifying ten distinct classes of arrhythmia with just 82.7M FLOPs per sample, thereby going beyond the performance metrics of current state-of-the-art (SOTA) models by utilizing MIT-BIH Arrhythmia dataset. Similarly, on INCARTDB and EDB datasets, excellent F1-scores of 98.01% and 96.21% respectively was achieved for AAMI classification. The compact architectural footprint of the rECGnition_v2.0, characterized by its lesser trainable parameters and diminished computational demands, unfurled several advantages including interpretability and scalability.', 'abstract_zh': 'ECG读数因个体患者特征差异造成的变异性对临床环境中采用自动ECG分析构成了重大挑战：SACC (自我注意相关性分析) 方法及其在rECGnition_v2.0中的应用', 'title_zh': 'rECGnition_v2.0：基于深度学习的心电图与患者数据自注意力经典融合及其在心脏诊断中的有效应用'}
{'arxiv_id': 'arXiv:2502.16249', 'title': 'Linear Attention for Efficient Bidirectional Sequence Modeling', 'authors': 'Arshia Afzal, Elias Abad Rocamora, Leyla Naz Candogan, Pol Puigdemont, Francesco Tonin, Yongtao Wu, Mahsa Shoaran, Volkan Cevher', 'link': 'https://arxiv.org/abs/2502.16249', 'abstract': 'Transformers with linear attention enable fast and parallel training. Moreover, they can be formulated as Recurrent Neural Networks (RNNs), for efficient linear-time inference. While extensively evaluated in causal sequence modeling, they have yet to be extended to the bidirectional setting. This work introduces the LION framework, establishing new theoretical foundations for linear transformers in bidirectional sequence modeling. LION constructs a bidirectional RNN equivalent to full Linear Attention. This extends the benefits of linear transformers: parallel training, and efficient inference, into the bidirectional setting. Using LION, we cast three linear transformers to their bidirectional form: LION-LIT, the bidirectional variant corresponding to (Katharopoulos et al., 2020); LION-D, extending RetNet (Sun et al., 2023); and LION-S, a linear transformer with a stable selective mask inspired by selectivity of SSMs (Dao & Gu, 2024). Replacing the attention block with LION (-LIT, -D, -S) achieves performance on bidirectional tasks that approaches that of Transformers and State-Space Models (SSMs), while delivering significant improvements in training speed. Our implementation is available in this http URL.', 'abstract_zh': '线性注意力变压器与双向序列建模：LION框架的研究', 'title_zh': '高效双向序列建模中的线性注意力'}
{'arxiv_id': 'arXiv:2502.16240', 'title': 'Speech Enhancement Using Continuous Embeddings of Neural Audio Codec', 'authors': 'Haoyang Li, Jia Qi Yip, Tianyu Fan, Eng Siong Chng', 'link': 'https://arxiv.org/abs/2502.16240', 'abstract': 'Recent advancements in Neural Audio Codec (NAC) models have inspired their use in various speech processing tasks, including speech enhancement (SE). In this work, we propose a novel, efficient SE approach by leveraging the pre-quantization output of a pretrained NAC encoder. Unlike prior NAC-based SE methods, which process discrete speech tokens using Language Models (LMs), we perform SE within the continuous embedding space of the pretrained NAC, which is highly compressed along the time dimension for efficient representation. Our lightweight SE model, optimized through an embedding-level loss, delivers results comparable to SE baselines trained on larger datasets, with a significantly lower real-time factor of 0.005. Additionally, our method achieves a low GMAC of 3.94, reducing complexity 18-fold compared to Sepformer in a simulated cloud-based audio transmission environment. This work highlights a new, efficient NAC-based SE solution, particularly suitable for cloud applications where NAC is used to compress audio before transmission.\nCopyright 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.', 'abstract_zh': 'Recent advancements in Neural Audio Codec (NAC) models have inspired their use in various speech processing tasks, including speech enhancement (SE). In this work, we propose a novel, efficient SE approach by leveraging the pre-quantization output of a pretrained NAC encoder. Unlike prior NAC-based SE methods, which process discrete speech tokens using Language Models (LMs), we perform SE within the continuous embedding space of the pretrained NAC, which is highly compressed along the time dimension for efficient representation. Our lightweight SE model, optimized through an embedding-level loss, delivers results comparable to SE baselines trained on larger datasets, with a significantly lower real-time factor of 0.005. Additionally, our method achieves a low GMAC of 3.94, reducing complexity 18-fold compared to Sepformer in a simulated cloud-based audio transmission environment. This work highlights a new, efficient NAC-based SE solution, particularly suitable for cloud applications where NAC is used to compress audio before transmission.', 'title_zh': '神经音频编解码器连续嵌入的语音增强'}
{'arxiv_id': 'arXiv:2502.16233', 'title': 'Graph Self-Supervised Learning with Learnable Structural and Positional Encodings', 'authors': 'Asiri Wijesinghe, Hao Zhu, Piotr Koniusz', 'link': 'https://arxiv.org/abs/2502.16233', 'abstract': "Traditional Graph Self-Supervised Learning (GSSL) struggles to capture complex structural properties well. This limitation stems from two main factors: (1) the inadequacy of conventional Graph Neural Networks (GNNs) in representing sophisticated topological features, and (2) the focus of self-supervised learning solely on final graph representations. To address these issues, we introduce \\emph{GenHopNet}, a GNN framework that integrates a $k$-hop message-passing scheme, enhancing its ability to capture local structural information without explicit substructure extraction. We theoretically demonstrate that \\emph{GenHopNet} surpasses the expressiveness of the classical Weisfeiler-Lehman (WL) test for graph isomorphism. Furthermore, we propose a structural- and positional-aware GSSL framework that incorporates topological information throughout the learning process. This approach enables the learning of representations that are both sensitive to graph topology and invariant to specific structural and feature augmentations. Comprehensive experiments on graph classification datasets, including those designed to test structural sensitivity, show that our method consistently outperforms the existing approaches and maintains computational efficiency. Our work significantly advances GSSL's capability in distinguishing graphs with similar local structures but different global topologies.", 'abstract_zh': '传统图自监督学习（GSSL）难以很好地捕捉复杂的结构特性。这一局限性源自两个主要因素：（1）传统图神经网络（GNNs）在表示复杂的拓扑特征方面的不足，以及（2）自监督学习专注于最终图表示。为了解决这些问题，我们提出了\\emph{GenHopNet}，这是一种结合了$k$-hop消息传递方案的GNN框架，增强了其捕捉局部结构信息的能力，而无需显式的子结构提取。我们理论证明\\emph{GenHopNet}超越了经典的Weisfeiler-Lehman（WL）图同构测试的表达能力。此外，我们提出了一种兼顾结构和位置感知的自监督学习框架，整个学习过程中均融入了拓扑信息。该方法能够学习既对图拓扑敏感又对特定结构和特征增强保持不变的表示。我们对包括用于测试结构敏感性的图分类数据集进行全面实验，结果显示，我们的方法在所有方面均优于现有方法，并保持了计算效率。我们的工作显著提升了GSSL在区分具有相似局部结构但全局拓扑不同的图方面的能力。', 'title_zh': '带有可学习结构和位置编码的图自监督学习'}
{'arxiv_id': 'arXiv:2502.16214', 'title': 'SalM$2$: An Extremely Lightweight Saliency Mamba Model for Real-Time Cognitive Awareness of Driver Attention', 'authors': 'Chunyu Zhao, Wentao Mu, Xian Zhou, Wenbo Liu, Fei Yan, Tao Deng', 'link': 'https://arxiv.org/abs/2502.16214', 'abstract': "Driver attention recognition in driving scenarios is a popular direction in traffic scene perception technology. It aims to understand human driver attention to focus on specific targets/objects in the driving scene. However, traffic scenes contain not only a large amount of visual information but also semantic information related to driving tasks. Existing methods lack attention to the actual semantic information present in driving scenes. Additionally, the traffic scene is a complex and dynamic process that requires constant attention to objects related to the current driving task. Existing models, influenced by their foundational frameworks, tend to have large parameter counts and complex structures. Therefore, this paper proposes a real-time saliency Mamba network based on the latest Mamba framework. As shown in Figure 1, our model uses very few parameters (0.08M, only 0.09~11.16% of other models), while maintaining SOTA performance or achieving over 98% of the SOTA model's performance.", 'abstract_zh': '驾驶场景中驾驶员注意力识别是交通场景感知技术的一个热门方向', 'title_zh': 'SalM$2$: 一种极轻量级的驾驶注意力实时认知 Awareness 模型'}
{'arxiv_id': 'arXiv:2502.16198', 'title': 'An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning', 'authors': 'Masoud Shokrnezhad, Tarik Taleb', 'link': 'https://arxiv.org/abs/2502.16198', 'abstract': '6G networks aim to achieve global coverage, massive connectivity, and ultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) and Semantic Communication (SemCom) are essential for realizing these goals, yet they introduce considerable complexity in resource orchestration. Drawing inspiration from research in robotics, a viable solution to manage this complexity is the application of Large Language Models (LLMs). Although the use of LLMs in network orchestration has recently gained attention, existing solutions have not sufficiently addressed LLM hallucinations or their adaptation to network dynamics. To address this gap, this paper proposes a framework called Autonomous Reinforcement Coordination (ARC) for a SemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-Augmented Generator (RAG) monitors services, users, and resources and processes the collected data, while a Hierarchical Action Planner (HAP) orchestrates resources. ARC decomposes orchestration into two tiers, utilizing LLMs for high-level planning and Reinforcement Learning (RL) agents for low-level decision-making, in alignment with the Mixture of Experts (MoE) concept. The LLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empowered by contrastive learning, while the RL agents employ replay buffer management for continual learning, thereby achieving efficiency, accuracy, and adaptability. Simulations are provided to demonstrate the effectiveness of ARC, along with a comprehensive discussion on potential future research directions to enhance and upgrade ARC.', 'abstract_zh': '6G网络旨在实现全球覆盖、海量连接和极致严格的性能要求。空间-空中-地面综合网络（SAGINs）和语义通信（SemCom）是实现这些目标的关键，但也引入了资源 orchestrization 的巨大复杂性。借鉴机器人学研究中的进展，通过应用大规模语言模型（LLMs）可以有效管理这一复杂性。尽管在网络orchorchization 中使用LLMs 逐渐受到关注，但现有解决方案尚未充分解决LLM 的幻觉问题或对网络动态的适应性问题。为了填补这一空白，本文提出了一种名为自主强化协调（ARC）的框架，用于实现SemCom 的SAGINs。该框架采用基于LLM 的检索增强生成器（RAG）监控服务、用户和资源，并处理收集到的数据，而层次化行动规划器（HAP）则协调资源。ARC 将orchestration 分解为两级，利用LLM 进行高层次规划，并使用强化学习（RL）代理进行低层次决策，符合专家混合（MoE）的概念。LLMs 利用因果推理进行少样本学习，而RL代理则通过回放缓冲区管理实现持续学习，从而实现效率、准确性和适应性。仿真实验展示了ARC 的有效性，并对增强和升级ARC 的未来研究方向进行了全面讨论。', 'title_zh': '一种结合大型语言模型与持续强化学习的自主网络编排框架'}
{'arxiv_id': 'arXiv:2502.16181', 'title': 'BiDeV: Bilateral Defusing Verification for Complex Claim Fact-Checking', 'authors': 'Yuxuan Liu, Hongda Sun, Wenya Guo, Xinyan Xiao, Cunli Mao, Zhengtao Yu, Rui Yan', 'link': 'https://arxiv.org/abs/2502.16181', 'abstract': 'Complex claim fact-checking performs a crucial role in disinformation detection. However, existing fact-checking methods struggle with claim vagueness, specifically in effectively handling latent information and complex relations within claims. Moreover, evidence redundancy, where nonessential information complicates the verification process, remains a significant issue. To tackle these limitations, we propose Bilateral Defusing Verification (BiDeV), a novel fact-checking working-flow framework integrating multiple role-played LLMs to mimic the human-expert fact-checking process. BiDeV consists of two main modules: Vagueness Defusing identifies latent information and resolves complex relations to simplify the claim, and Redundancy Defusing eliminates redundant content to enhance the evidence quality. Extensive experimental results on two widely used challenging fact-checking benchmarks (Hover and Feverous-s) demonstrate that our BiDeV can achieve the best performance under both gold and open settings. This highlights the effectiveness of BiDeV in handling complex claims and ensuring precise fact-checking', 'abstract_zh': '复杂声明事实核查在虚假信息检测中发挥着关键作用。然而，现有的事实核查方法在处理声明的模糊性、特别是潜在信息和声明中复杂关系的有效处理方面存在困难。此外，证据冗余问题，即不必要的信息使验证过程复杂化，也是一个重大问题。为解决这些问题，我们提出了双边消解验证（BiDeV）框架，该框架结合了多个角色扮演的LLM，以模拟人类专家的事实核查过程。BiDeV主要包括两个主要模块：模糊性消解识别潜在信息并解决复杂关系以简化声明，冗余消解消除冗余内容以提高证据质量。在两个广泛使用的挑战性事实核查基准（Hover和Feverous-s）上的 extensive 实验结果表明，我们的 BiDeV 在金标准和开放环境下都能取得最佳性能，这突显了 BiDeV 在处理复杂声明和确保精确事实核查方面的有效性。', 'title_zh': 'BiDeV: 双边解爆验证复杂声明事实核查'}
{'arxiv_id': 'arXiv:2502.16176', 'title': 'An End-to-End Homomorphically Encrypted Neural Network', 'authors': 'Marcos Florencio, Luiz Alencar, Bianca Lima', 'link': 'https://arxiv.org/abs/2502.16176', 'abstract': 'Every commercially available, state-of-the-art neural network consume plain input data, which is a well-known privacy concern. We propose a new architecture based on homomorphic encryption, which allows the neural network to operate on encrypted data. We show that Homomorphic Neural Networks (HNN) can achieve full privacy and security while maintaining levels of accuracy comparable to plain neural networks. We also introduce a new layer, the Differentiable Soft-Argmax, which allows the calibration of output logits in the encrypted domain, raising the entropy of the activation parameters, thus improving the security of the model, while keeping the overall noise below the acceptable noise budget. Experiments were conducted using the Stanford Sentiment Treebank (SST-2) corpora on the DistilBERT base uncased finetuned SST-2 English sentiment analysis model, and the results show that the HNN model can achieve up to 82.5% of the accuracy of the plain model while maintaining full privacy and security.', 'abstract_zh': '基于同态加密的全同态神经网络：实现隐私保护与高准确性', 'title_zh': '端到端同态加密神经网络'}
{'arxiv_id': 'arXiv:2502.16175', 'title': 'Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens', 'authors': 'Ziwei Shan, Yaoyu He, Chengfeng Zhao, Jiashen Du, Jingyan Zhang, Qixuan Zhang, Jingyi Yu, Lan Xu', 'link': 'https://arxiv.org/abs/2502.16175', 'abstract': 'Human bodily movements convey critical insights into action intentions and cognitive processes, yet existing multimodal systems primarily focused on understanding human motion via language, vision, and audio, which struggle to capture the dynamic forces and torques inherent in 3D motion. Inertial measurement units (IMUs) present a promising alternative, offering lightweight, wearable, and privacy-conscious motion sensing. However, processing of streaming IMU data faces challenges such as wireless transmission instability, sensor noise, and drift, limiting their utility for long-term real-time motion capture (MoCap), and more importantly, online motion analysis. To address these challenges, we introduce Mojito, an intelligent motion agent that integrates inertial sensing with large language models (LLMs) for interactive motion capture and behavioral analysis.', 'abstract_zh': '人体运动传达了重要的行动意图和认知过程的见解，现有的多模态系统主要侧重于通过语言、视觉和音频理解人类运动，但难以捕捉三维运动中固有的动态力和扭矩。惯性测量单元（IMUs）提供了一种有前景的替代方案，可以实现轻量级、可穿戴且注重隐私的运动传感。然而，处理流式IMU数据面临无线传输不稳定、传感器噪声和漂移等问题，限制了其在长期实时运动捕捉中的应用，并且更重要的是在线运动分析。为解决这些问题，我们引入了Mojito，一种结合惯性感知和大型语言模型（LLMs）的智能运动代理，用于交互式运动捕捉和行为分析。', 'title_zh': '莫吉托：带有抖动减少惯性令牌的LLM辅助运动指导器'}
{'arxiv_id': 'arXiv:2502.16174', 'title': 'Maybe I Should Not Answer That, but... Do LLMs Understand The Safety of Their Inputs?', 'authors': 'Maciej Chrabąszcz, Filip Szatkowski, Bartosz Wójcik, Jan Dubiński, Tomasz Trzciński', 'link': 'https://arxiv.org/abs/2502.16174', 'abstract': 'Ensuring the safety of the Large Language Model (LLM) is critical, but currently used methods in most cases sacrifice the model performance to obtain increased safety or perform poorly on data outside of their adaptation distribution. We investigate existing methods for such generalization and find them insufficient. Surprisingly, while even plain LLMs recognize unsafe prompts, they may still generate unsafe responses. To avoid performance degradation and preserve safe performance, we advocate for a two-step framework, where we first identify unsafe prompts via a lightweight classifier, and apply a "safe" model only to such prompts. In particular, we explore the design of the safety detector in more detail, investigating the use of different classifier architectures and prompting techniques. Interestingly, we find that the final hidden state for the last token is enough to provide robust performance, minimizing false positives on benign data while performing well on malicious prompt detection. Additionally, we show that classifiers trained on the representations from different model layers perform comparably on the latest model layers, indicating that safety representation is present in the LLMs\' hidden states at most model stages. Our work is a step towards efficient, representation-based safety mechanisms for LLMs.', 'abstract_zh': '确保大型语言模型（LLM）的安全性至关重要，但目前大多数方法要么牺牲模型性能以获得更高的安全性，要么在超出其适应分布的数据上表现不佳。我们调查了现有的泛化方法，并发现它们不足之处。令人惊讶的是，即使简单的LLM也能识别出不安全的提示，但仍可能生成不安全的响应。为了避免性能下降并保持安全性能，我们建议采用两步框架，首先通过一个轻量级分类器识别不安全的提示，然后仅对这些提示应用“安全”模型。特别是，我们更详细地探讨了安全检测器的设计，研究了不同分类器架构和提示技术的使用。有趣的是，我们发现最终隐藏状态足以提供稳健的性能，在良性数据上最小化假阳性，同时在恶意提示检测方面表现良好。此外，我们展示了在不同模型层上训练的分类器在最新模型层上表现出相似的性能，表明安全性表示在LLM的隐藏状态中可以在大多数模型阶段出现。我们的工作是朝着为LLM设计高效、基于表示的安全机制迈出的一步。', 'title_zh': '也许我本不应该回答这个问题，但……大语言模型是否理解其输入的安全性？'}
{'arxiv_id': 'arXiv:2502.16171', 'title': 'EPERM: An Evidence Path Enhanced Reasoning Model for Knowledge Graph Question and Answering', 'authors': 'Xiao Long, Liansheng Zhuang, Aodi Li, Minghong Yao, Shafei Wang', 'link': 'https://arxiv.org/abs/2502.16171', 'abstract': 'Due to the remarkable reasoning ability, Large language models (LLMs) have demonstrated impressive performance in knowledge graph question answering (KGQA) tasks, which find answers to natural language questions over knowledge graphs (KGs). To alleviate the hallucinations and lack of knowledge issues of LLMs, existing methods often retrieve the question-related information from KGs to enrich the input context. However, most methods focus on retrieving the relevant information while ignoring the importance of different types of knowledge in reasoning, which degrades their performance. To this end, this paper reformulates the KGQA problem as a graphical model and proposes a three-stage framework named the Evidence Path Enhanced Reasoning Model (EPERM) for KGQA. In the first stage, EPERM uses the fine-tuned LLM to retrieve a subgraph related to the question from the original knowledge graph. In the second stage, EPERM filters out the evidence paths that faithfully support the reasoning of the questions, and score their importance in reasoning. Finally, EPERM uses the weighted evidence paths to reason the final answer. Since considering the importance of different structural information in KGs for reasoning, EPERM can improve the reasoning ability of LLMs in KGQA tasks. Extensive experiments on benchmark datasets demonstrate that EPERM achieves superior performances in KGQA tasks.', 'abstract_zh': '大型语言模型在知识图谱问答任务中的证据路径增强推理模型', 'title_zh': 'EPERM：一种基于证据路径的推理模型用于知识图谱问答'}
{'arxiv_id': 'arXiv:2502.16170', 'title': 'Destroy and Repair Using Hyper Graphs for Routing', 'authors': 'Ke Li, Fei Liu, Zhengkun Wang, Qingfu Zhang', 'link': 'https://arxiv.org/abs/2502.16170', 'abstract': 'Recent advancements in Neural Combinatorial Optimization (NCO) have shown promise in solving routing problems like the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) without handcrafted designs. Research in this domain has explored two primary categories of methods: iterative and non-iterative. While non-iterative methods struggle to generate near-optimal solutions directly, iterative methods simplify the task by learning local search steps. However, existing iterative methods are often limited by restricted neighborhood searches, leading to suboptimal results. To address this limitation, we propose a novel approach that extends the search to larger neighborhoods by learning a destroy-and-repair strategy. Specifically, we introduce a Destroy-and-Repair framework based on Hyper-Graphs (DRHG). This framework reduces consecutive intact edges to hyper-edges, allowing the model to pay more attention to the destroyed part and decrease the complexity of encoding all nodes. Experiments demonstrate that DRHG achieves stateof-the-art performance on TSP with up to 10,000 nodes and shows strong generalization to real-world TSPLib and CVRPLib problems.', 'abstract_zh': '最近神经组合优化（NCO）在解决旅行商问题（TSP）和带容量约束的车辆路径问题（CVRP）等路径问题方面取得了进展，无需手工设计。该领域的研究探索了两类主要方法：迭代和非迭代方法。虽然非迭代方法难以直接生成近最优解，但迭代方法通过学习局部搜索步骤简化了任务。然而，现有的迭代方法通常受限于局部搜索范围的限制，导致次优结果。为解决这一局限，我们提出了一种新的方法，通过学习破坏-修复策略将搜索范围扩展到更大的邻域。具体而言，我们基于超图引入了一种破坏-修复框架（DRHG）。该框架将连续未受损边简化为超边，从而使模型更加关注受损部分，并降低编码所有节点的复杂性。实验结果表明，DRHG在包含高达10,000个节点的TSP上达到最佳性能，并且在实际的TSPLib和CVRPLib问题上表现出强大的泛化能力。', 'title_zh': '使用超图进行路由的破坏与修复'}
{'arxiv_id': 'arXiv:2502.16167', 'title': 'PersGuard: Preventing Malicious Personalization via Backdoor Attacks on Pre-trained Text-to-Image Diffusion Models', 'authors': 'Xinwei Liu, Xiaojun Jia, Yuan Xun, Hua Zhang, Xiaochun Cao', 'link': 'https://arxiv.org/abs/2502.16167', 'abstract': "Diffusion models (DMs) have revolutionized data generation, particularly in text-to-image (T2I) synthesis. However, the widespread use of personalized generative models raises significant concerns regarding privacy violations and copyright infringement. To address these issues, researchers have proposed adversarial perturbation-based protection techniques. However, these methods have notable limitations, including insufficient robustness against data transformations and the inability to fully eliminate identifiable features of protected objects in the generated output. In this paper, we introduce PersGuard, a novel backdoor-based approach that prevents malicious personalization of specific images. Unlike traditional adversarial perturbation methods, PersGuard implant backdoor triggers into pre-trained T2I models, preventing the generation of customized outputs for designated protected images while allowing normal personalization for unprotected ones. Unfortunately, existing backdoor methods for T2I diffusion models fail to be applied to personalization scenarios due to the different backdoor objectives and the potential backdoor elimination during downstream fine-tuning processes. To address these, we propose three novel backdoor objectives specifically designed for personalization scenarios, coupled with backdoor retention loss engineered to resist downstream fine-tuning. These components are integrated into a unified optimization framework. Extensive experimental evaluations demonstrate PersGuard's effectiveness in preserving data privacy, even under challenging conditions including gray-box settings, multi-object protection, and facial identity scenarios. Our method significantly outperforms existing techniques, offering a more robust solution for privacy and copyright protection.", 'abstract_zh': '基于后门的PrivacyGuard：一种针对特定图像的恶意个性化防护方法', 'title_zh': 'PersGuard：通过预训练文本到图像扩散模型后门攻击防止恶意个性化'}
{'arxiv_id': 'arXiv:2502.16137', 'title': 'Chain-of-Description: What I can understand, I can put into words', 'authors': 'Jiaxin Guo, Daimeng Wei, Zongyao Li, Hengchao Shang, Yuanchang Luo, Hao Yang', 'link': 'https://arxiv.org/abs/2502.16137', 'abstract': 'In this paper, we propose a novel strategy defined as Chain-of-Description (CoD) Prompting, tailored for Multi-Modal Large Language Models. This approach involves having the model first provide a detailed description of the multi-modal input before generating an answer to the question. When applied to models such as Qwen2-Audio, Qwen2-VL, and Qwen2.5-VL, CoD Prompting significantly enhances performance compared to standard prompting methods. This is demonstrated by nearly a 4\\% improvement in the speech category of the audio benchmark AIR-Bench-Chat and a 5.3\\% improvement in the hard-level portion of the vision benchmark MMMU\\_Pro. Our ablation study further validates the effectiveness of CoD Prompting.', 'abstract_zh': '在这种链式描述提示策略中，我们提出了一种针对多模态大规模语言模型的新型策略，该方法要求模型首先对多模态输入进行详细的描述，然后再生成问题的答案。将该策略应用于Qwen2-Audio、Qwen2-VL和Qwen2.5-VL等模型时，与标准提示方法相比，显著提升了性能。这在音频基准AIR-Bench-Chat的声音类别中近4%的改进以及视觉基准MMMU_Pro的困难级别部分中5.3%的改进中得到了体现。我们的消融研究进一步验证了链式描述提示的有效性。', 'title_zh': '描述链：我能理解的，我能用语言表达。'}
{'arxiv_id': 'arXiv:2502.16129', 'title': 'Robust Dynamic Facial Expression Recognition', 'authors': 'Feng Liu, Hanyang Wang, Siyuan Shen', 'link': 'https://arxiv.org/abs/2502.16129', 'abstract': "The study of Dynamic Facial Expression Recognition (DFER) is a nascent field of research that involves the automated recognition of facial expressions in video data. Although existing research has primarily focused on learning representations under noisy and hard samples, the issue of the coexistence of both types of samples remains unresolved. In order to overcome this challenge, this paper proposes a robust method of distinguishing between hard and noisy samples. This is achieved by evaluating the prediction agreement of the model on different sampled clips of the video. Subsequently, methodologies that reinforce the learning of hard samples and mitigate the impact of noisy samples can be employed. Moreover, to identify the principal expression in a video and enhance the model's capacity for representation learning, comprising a key expression re-sampling framework and a dual-stream hierarchical network is proposed, namely Robust Dynamic Facial Expression Recognition (RDFER). The key expression re-sampling framework is designed to identify the key expression, thereby mitigating the potential confusion caused by non-target expressions. RDFER employs two sequence models with the objective of disentangling short-term facial movements and long-term emotional changes. The proposed method has been shown to outperform current State-Of-The-Art approaches in DFER through extensive experimentation on benchmark datasets such as DFEW and FERV39K. A comprehensive analysis provides valuable insights and observations regarding the proposed agreement. This work has significant implications for the field of dynamic facial expression recognition and promotes the further development of the field of noise-consistent robust learning in dynamic facial expression recognition. The code is available from [this https URL].", 'abstract_zh': '动态面部表情识别中的坚实动态面部表情识别（RDFER）：噪声与困难样本共存下的表情识别研究', 'title_zh': '鲁棒动态面部表情识别'}
{'arxiv_id': 'arXiv:2502.16128', 'title': 'Heterogeneous Multi-Agent Bandits with Parsimonious Hints', 'authors': 'Amirmahdi Mirfakhar, Xuchuang Wang, Jinhang Zuo, Yair Zick, Mohammad Hajiesmaili', 'link': 'https://arxiv.org/abs/2502.16128', 'abstract': 'We study a hinted heterogeneous multi-agent multi-armed bandits problem (HMA2B), where agents can query low-cost observations (hints) in addition to pulling arms. In this framework, each of the $M$ agents has a unique reward distribution over $K$ arms, and in $T$ rounds, they can observe the reward of the arm they pull only if no other agent pulls that arm. The goal is to maximize the total utility by querying the minimal necessary hints without pulling arms, achieving time-independent regret. We study HMA2B in both centralized and decentralized setups. Our main centralized algorithm, GP-HCLA, which is an extension of HCLA, uses a central decision-maker for arm-pulling and hint queries, achieving $O(M^4K)$ regret with $O(MK\\log T)$ adaptive hints. In decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that allow agents to choose actions independently through collision-based communication and query hints uniformly until stopping, yielding $O(M^3K^2)$ regret with $O(M^3K\\log T)$ hints, where the former requires knowledge of the minimum gap and the latter does not. Finally, we establish lower bounds to prove the optimality of our results and verify them through numerical simulations.', 'abstract_zh': '我们研究了一个提示异构多智能体多臂 bandits 问题 (HMA2B)，其中智能体不仅可以拉臂，还可以查询低成本观察（提示）。在该框架中，每个M个智能体在T轮中各自有一套独特的奖励分布，并且只有在没有其他智能体拉动同一臂的情况下才能观察到所拉动臂的奖励。目标是通过最小必要的提示查询来最大化总效用，实现与时间无关的后悔。我们在集中式和分布式设置下研究了HMA2B问题。我们主要的集中式算法GP-HCLA是HCLA的扩展，采用中央决策者来执行拉臂和提示查询，其后悔为$O(M^4K)$，具有$O(MK\\log T)$自适应提示。在分布式设置中，我们提出了两个算法HD-ETC和EBHD-ETC，允许智能体通过碰撞式通信独立选择动作并均匀查询提示直到停止，其后悔为$O(M^3K^2)$，具有$O(M^3K\\log T)$的提示，前者需要知道最小差距，后者不需要。最后，我们建立了下界来证明我们结果的最优性，并通过数值仿真进行了验证。', 'title_zh': '稀疏提示下的异构多智能体 bandits 问题'}
{'arxiv_id': 'arXiv:2502.16105', 'title': 'NeurFlow: Interpreting Neural Networks through Neuron Groups and Functional Interactions', 'authors': 'Tue M. Cao, Nhat X. Hoang, Hieu H. Pham, Phi Le Nguyen, My T. Thai', 'link': 'https://arxiv.org/abs/2502.16105', 'abstract': "Understanding the inner workings of neural networks is essential for enhancing model performance and interpretability. Current research predominantly focuses on examining the connection between individual neurons and the model's final predictions. Which suffers from challenges in interpreting the internal workings of the model, particularly when neurons encode multiple unrelated features. In this paper, we propose a novel framework that transitions the focus from analyzing individual neurons to investigating groups of neurons, shifting the emphasis from neuron-output relationships to functional interaction between neurons. Our automated framework, NeurFlow, first identifies core neurons and clusters them into groups based on shared functional relationships, enabling a more coherent and interpretable view of the network's internal processes. This approach facilitates the construction of a hierarchical circuit representing neuron interactions across layers, thus improving interpretability while reducing computational costs. Our extensive empirical studies validate the fidelity of our proposed NeurFlow. Additionally, we showcase its utility in practical applications such as image debugging and automatic concept labeling, thereby highlighting its potential to advance the field of neural network explainability.", 'abstract_zh': '理解神经网络的内在工作机制对于提升模型性能和可解释性至关重要。当前研究主要关注个体神经元与模型最终预测之间的关系，这在解释模型内部工作机制时面临挑战，尤其是在神经元编码多个无关特征的情况下。本文提出一种新颖框架，将焦点从分析个体神经元转移到研究神经元群体，从关注神经元-输出关系转向关注神经元间的功能交互。我们的自动化框架NeurFlow首先识别关键神经元并基于共享的功能关系将它们聚类，从而提供更连贯和可解释的网络内部过程视图。该方法促进了跨层神经元交互的分层电路构建，从而提高可解释性并降低计算成本。我们广泛的经验研究表明，NeurFlow 提出的框架具有较高的准确性。此外，我们展示了其在图像调试和自动概念标签等实际应用中的应用价值，进而凸显了其在神经网络可解释性领域的发展潜力。', 'title_zh': 'NeurFlow: 通过神经元组和功能交互解释神经网络'}
{'arxiv_id': 'arXiv:2502.16097', 'title': 'LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools', 'authors': 'Haoxiang Fan, Changshuang Zhou, Hao Yu, Xueyang Wu, Jiangyu Gu, Zhenhui Peng', 'link': 'https://arxiv.org/abs/2502.16097', 'abstract': "Teaching literature under interdisciplinary contexts (e.g., science, art) that connect reading materials has become popular in elementary schools. However, constructing such contexts is challenging as it requires teachers to explore substantial amounts of interdisciplinary content and link it to the reading materials. In this paper, we develop LitLinker via an iterative design process involving 13 teachers to facilitate the ideation of interdisciplinary contexts for teaching literature. Powered by a large language model (LLM), LitLinker can recommend interdisciplinary topics and contextualize them with the literary elements (e.g., paragraphs, viewpoints) in the reading materials. A within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker can improve the integration depth of different subjects and reduce workload in this ideation task. Expert interviews (N=9) also demonstrate LitLinker's usefulness for supporting the ideation of interdisciplinary contexts for teaching literature. We conclude with concerns and design considerations for supporting interdisciplinary teaching with LLMs.", 'abstract_zh': '在跨学科背景下（如科学、艺术）教授文学作品已成为小学教育中的流行趋势。然而，构建这样的背景具有挑战性，因为这要求教师探索大量的跨学科内容，并将其与阅读材料关联起来。本文通过13位教师参与的迭代设计过程开发了LitLinker，以促进文学教学中跨学科背景的想法生成。借助大型语言模型（LLM），LitLinker可以推荐跨学科主题，并用阅读材料中的文学元素（如段落、观点）对其进行情境化。一项被试内研究（N=16）表明，与语言模型聊天机器人相比，LitLinker可以提高不同学科内容的整合深度并减少此想法生成任务的工作量。专家访谈（N=9）也证明了LitLinker在支持文学教学中的跨学科背景想法生成方面的实用性。最后，我们对使用LLM支持跨学科教学的关注点和设计考虑进行了总结。', 'title_zh': 'LitLinker：借助大型语言模型支持小学文学教学中的跨学科构思'}
{'arxiv_id': 'arXiv:2502.16091', 'title': 'Privacy-Aware Joint DNN Model Deployment and Partition Optimization for Delay-Efficient Collaborative Edge Inference', 'authors': 'Zhipeng Cheng, Xiaoyu Xia, Hong Wang, Minghui Liwang, Ning Chen, Xuwei Fan, Xianbin Wang', 'link': 'https://arxiv.org/abs/2502.16091', 'abstract': 'Edge inference (EI) is a key solution to address the growing challenges of delayed response times, limited scalability, and privacy concerns in cloud-based Deep Neural Network (DNN) inference. However, deploying DNN models on resource-constrained edge devices faces more severe challenges, such as model storage limitations, dynamic service requests, and privacy risks. This paper proposes a novel framework for privacy-aware joint DNN model deployment and partition optimization to minimize long-term average inference delay under resource and privacy constraints. Specifically, the problem is formulated as a complex optimization problem considering model deployment, user-server association, and model partition strategies. To handle the NP-hardness and future uncertainties, a Lyapunov-based approach is introduced to transform the long-term optimization into a single-time-slot problem, ensuring system performance. Additionally, a coalition formation game model is proposed for edge server association, and a greedy-based algorithm is developed for model deployment within each coalition to efficiently solve the problem. Extensive simulations show that the proposed algorithms effectively reduce inference delay while satisfying privacy constraints, outperforming baseline approaches in various scenarios.', 'abstract_zh': '面向隐私保护的联合DNN模型部署与划分优化框架以最小化资源和隐私约束下的长期平均推理延迟', 'title_zh': '隐私 Awareness 联合 DNN 模型部署与分区优化以实现延迟高效的协同边缘推理'}
{'arxiv_id': 'arXiv:2502.16090', 'title': 'Echo: A Large Language Model with Temporal Episodic Memory', 'authors': 'WenTao Liu, Ruohua Zhang, Aimin Zhou, Feng Gao, JiaLi Liu', 'link': 'https://arxiv.org/abs/2502.16090', 'abstract': "Research on large language models (LLMs) has shown remarkable performance in domains such as mathematics, programming, and literary creation. However, most studies have focused on semantic memory-based question answering, neglecting LLMs' potential to handle episodic memory (EM)-related queries. This oversight has led to suboptimal performance in applications requiring EM, including emotional companionship, personal AI assistants, and AI teachers. To address this gap, we introduce Echo, a LLM enhanced with temporal episodic memory. We propose a Multi-Agent Data Generation Framework that guides the model in generating multi-turn, complex scenario episodic memory dialogue data (EM-Train). Temporal information is innovatively incorporated into the LLM training process, and Echo is trained using the EM-Train. Furthermore, We develop an EM-Test benchmark specifically designed to evaluate LLMs' episodic memory capabilities. The EM-Test assesses performance across various time spans and difficulty levels, providing a comprehensive evaluation of multi-turn episodic memory dialogues. Our experiments demonstrate that Echo significantly outperforms state-of-the-art LLMs on EM-Test. Additionally, a qualitative analysis reveals Echo's potential to exhibit human-like episodic memory capabilities. We will open-source all datasets, code, and model weights.", 'abstract_zh': '大型语言模型的研究已经在数学、编程和文学创作等领域展现了卓越性能。然而，大多数研究集中于基于语义记忆的问题回答，忽视了大型语言模型处理情节记忆相关查询的潜力。这种忽视导致了在需要情节记忆的应用中，如情感陪伴、个人AI助手和AI教师等方面表现不佳。为了解决这一问题，我们引入了Echo，一种增强时间情节记忆的大型语言模型。我们提出了一种多智能体数据生成框架，指导模型生成多轮次、复杂情景的情节记忆对话数据（EM-Train）。时间信息被创新地融入大型语言模型的训练过程，Echo使用EM-Train进行训练。此外，我们开发了专门设计用于评估大型语言模型情节记忆能力的EM-Test基准。EM-Test评估了不同时间跨度和难度级别的表现，提供了对多轮次情节记忆对话的全面评估。我们的实验表明，Echo在EM-Test上的表现显著优于当前最佳的大型语言模型。此外，定性分析揭示了Echo具备类似人类的情节记忆能力的潜力。我们将开源所有数据集、代码和模型权重。', 'title_zh': '回声：具有时间情景记忆的大型语言模型'}
{'arxiv_id': 'arXiv:2502.16079', 'title': 'Together We Rise: Optimizing Real-Time Multi-Robot Task Allocation using Coordinated Heterogeneous Plays', 'authors': 'Aritra Pal, Anandsingh Chauhan, Mayank Baranwal', 'link': 'https://arxiv.org/abs/2502.16079', 'abstract': 'Efficient task allocation among multiple robots is crucial for optimizing productivity in modern warehouses, particularly in response to the increasing demands of online order fulfillment. This paper addresses the real-time multi-robot task allocation (MRTA) problem in dynamic warehouse environments, where tasks emerge with specified start and end locations. The objective is to minimize both the total travel distance of robots and delays in task completion, while also considering practical constraints such as battery management and collision avoidance. We introduce MRTAgent, a dual-agent Reinforcement Learning (RL) framework inspired by self-play, designed to optimize task assignments and robot selection to ensure timely task execution. For safe navigation, a modified linear quadratic controller (LQR) approach is employed. To the best of our knowledge, MRTAgent is the first framework to address all critical aspects of practical MRTA problems while supporting continuous robot movements.', 'abstract_zh': '多机器人在动态仓库环境中的实时任务分配优化：考虑实际约束的高效任务分配方法', 'title_zh': '共享共赢：基于协调异构玩法的实时多机器人任务分配优化'}
{'arxiv_id': 'arXiv:2502.16065', 'title': 'A Survey of Model Extraction Attacks and Defenses in Distributed Computing Environments', 'authors': 'Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, Yushun Dong', 'link': 'https://arxiv.org/abs/2502.16065', 'abstract': 'Model Extraction Attacks (MEAs) threaten modern machine learning systems by enabling adversaries to steal models, exposing intellectual property and training data. With the increasing deployment of machine learning models in distributed computing environments, including cloud, edge, and federated learning settings, each paradigm introduces distinct vulnerabilities and challenges. Without a unified perspective on MEAs across these distributed environments, organizations risk fragmented defenses, inadequate risk assessments, and substantial economic and privacy losses. This survey is motivated by the urgent need to understand how the unique characteristics of cloud, edge, and federated deployments shape attack vectors and defense requirements. We systematically examine the evolution of attack methodologies and defense mechanisms across these environments, demonstrating how environmental factors influence security strategies in critical sectors such as autonomous vehicles, healthcare, and financial services. By synthesizing recent advances in MEAs research and discussing the limitations of current evaluation practices, this survey provides essential insights for developing robust and adaptive defense strategies. Our comprehensive approach highlights the importance of integrating protective measures across the entire distributed computing landscape to ensure the secure deployment of machine learning models.', 'abstract_zh': 'Model Extraction Attacks (MEAs)威胁现代机器学习系统，使对手能够窃取模型，披露知识产权和训练数据。随着机器学习模型在分布式计算环境中的日益部署，包括云、边缘和联邦学习设置，每个范式都带来了独特的脆弱性和挑战。如果没有对这些分布式环境中的MEAs有统一的认识，组织可能会面临分散的防御、不充分的风险评估以及显著的经济损失和隐私损失。本综述旨在应对理解和分析云、边缘和联邦部署的独特特性如何塑造攻击向量和防御需求的紧迫需求。我们系统性地审视了这些环境中攻击方法和防御机制的发展演变，展示了环境因素如何影响自主车辆、医疗保健和金融服务等关键领域中的安全策略。通过综合MEAs研究的最新进展并讨论当前评估实践的局限性，本文提供了开发 robust 和自适应防御策略的重要见解。我们全面的方法强调了在整个分布式计算场景中整合保护措施以确保机器学习模型安全部署的重要性。', 'title_zh': '分布式计算环境中的模型提取攻击与防御综述'}
{'arxiv_id': 'arXiv:2502.16060', 'title': 'Single-Channel EEG Tokenization Through Time-Frequency Modeling', 'authors': 'Jathurshan Pradeepkumar, Xihao Piao, Zheng Chen, Jimeng Sun', 'link': 'https://arxiv.org/abs/2502.16060', 'abstract': "We introduce TFM-Tokenizer, a novel tokenization framework tailored for EEG analysis that transforms continuous, noisy brain signals into a sequence of discrete, well-represented tokens for various EEG tasks. Conventional approaches typically rely on continuous embeddings and inter-channel dependencies, which are limited in capturing inherent EEG features such as temporally unpredictable patterns and diverse oscillatory waveforms. In contrast, we hypothesize that critical time-frequency features can be effectively captured from a single channel. By learning tokens that encapsulate these intrinsic patterns within a single channel, our approach yields a scalable tokenizer adaptable across diverse EEG settings. We integrate the TFM-Tokenizer with a transformer-based TFM-Encoder, leveraging established pretraining techniques from natural language processing, such as masked token prediction, followed by downstream fine-tuning for various EEG tasks. Experiments across four EEG datasets show that TFM-Token outperforms state-of-the-art methods. On TUEV, our approach improves balanced accuracy and Cohen's Kappa by 5% over baselines. Comprehensive analysis of the learned tokens demonstrates their ability to capture class-distinctive features, enhance frequency representation, and ability to encode time-frequency motifs into distinct tokens, improving interpretability.", 'abstract_zh': 'TFM-Tokenizer：一种用于EEG分析的新型分词框架', 'title_zh': '单通道EEG分子化通过时频建模'}
{'arxiv_id': 'arXiv:2502.16054', 'title': 'Human-AI Collaboration in Cloud Security: Cognitive Hierarchy-Driven Deep Reinforcement Learning', 'authors': 'Zahra Aref, Sheng Wei, Narayan B. Mandayam', 'link': 'https://arxiv.org/abs/2502.16054', 'abstract': "Given the complexity of multi-tenant cloud environments and the need for real-time threat mitigation, Security Operations Centers (SOCs) must integrate AI-driven adaptive defenses against Advanced Persistent Threats (APTs). However, SOC analysts struggle with countering adaptive adversarial tactics, necessitating intelligent decision-support frameworks. To enhance human-AI collaboration in SOCs, we propose a Cognitive Hierarchy Theory-driven Deep Q-Network (CHT-DQN) framework that models SOC analysts' decision-making against AI-driven APT bots. The SOC analyst (defender) operates at cognitive level-1, anticipating attacker strategies, while the APT bot (attacker) follows a level-0 exploitative policy. By incorporating CHT into DQN, our framework enhances SOC defense strategies via Attack Graph (AG)-based reinforcement learning. Simulation experiments across varying AG complexities show that CHT-DQN achieves higher data protection and lower action discrepancies compared to standard DQN. A theoretical lower bound analysis further validates its superior Q-value performance. A human-in-the-loop (HITL) evaluation on Amazon Mechanical Turk (MTurk) reveals that SOC analysts using CHT-DQN-driven transition probabilities align better with adaptive attackers, improving data protection. Additionally, human decision patterns exhibit risk aversion after failure and risk-seeking behavior after success, aligning with Prospect Theory. These findings underscore the potential of integrating cognitive modeling into deep reinforcement learning to enhance SOC operations and develop real-time adaptive cloud security mechanisms.", 'abstract_zh': '基于认知层次理论的深度Q网络驱动的认知层次-深度Q网络框架：强化SOC中的人机协作以应对高级持续威胁（CHT-DQN框架）', 'title_zh': '云安全中的人工智能协作：基于认知层级的深度 reinforcement 学习'}
{'arxiv_id': 'arXiv:2502.16032', 'title': 'Clinical Inspired MRI Lesion Segmentation', 'authors': 'Lijun Yan, Churan Wang, Fangwei Zhong, Yizhou Wang', 'link': 'https://arxiv.org/abs/2502.16032', 'abstract': 'Magnetic resonance imaging (MRI) is a potent diagnostic tool for detecting pathological tissues in various diseases. Different MRI sequences have different contrast mechanisms and sensitivities for different types of lesions, which pose challenges to accurate and consistent lesion segmentation. In clinical practice, radiologists commonly use the sub-sequence feature, i.e. the difference between post contrast-enhanced T1-weighted (post) and pre-contrast-enhanced (pre) sequences, to locate lesions. Inspired by this, we propose a residual fusion method to learn subsequence representation for MRI lesion segmentation. Specifically, we iteratively and adaptively fuse features from pre- and post-contrast sequences at multiple resolutions, using dynamic weights to achieve optimal fusion and address diverse lesion enhancement patterns. Our method achieves state-of-the-art performances on BraTS2023 dataset for brain tumor segmentation and our in-house breast MRI dataset for breast lesion segmentation. Our method is clinically inspired and has the potential to facilitate lesion segmentation in various applications.', 'abstract_zh': '磁共振成像（MRI）是检测各种疾病中病理组织的一个强大诊断工具。不同的MRI序列对不同类型的病灶具有不同的对比机制和敏感性，这给准确且一致的病灶分割带来了挑战。在临床实践中，放射科医生通常使用子序列特征，即对比增强T1加权序列（post）与未对比增强序列（pre）之间的差异，来定位病灶。受这一做法的启发，我们提出了一种残差融合方法来学习MRI病灶分割的子序列表示。具体而言，我们在多个分辨率上迭代地自适应融合预对比增强序列和对比增强序列的特征，并使用动态权重以实现最佳融合并应对多样的病灶增强模式。我们的方法在BraTS2023脑肿瘤分割数据集和我们内部的乳腺MRI数据集的乳腺病灶分割任务上实现了最先进的性能。我们的方法具有临床启发性，有望在各种应用中促进病灶分割。', 'title_zh': '临床启发的MRI病变分割'}
{'arxiv_id': 'arXiv:2502.16030', 'title': 'Real Time Offside Detection using a Single Camera in Soccer', 'authors': 'Shounak Desai', 'link': 'https://arxiv.org/abs/2502.16030', 'abstract': 'Technological advancements in soccer have surged over the past decade, transforming aspects of the sport. Unlike binary rules, many soccer regulations, such as the "Offside Rule," rely on subjective interpretation rather than straightforward True or False criteria. The on-field referee holds ultimate authority in adjudicating these nuanced decisions. A significant breakthrough in soccer officiating is the Video Assistant Referee (VAR) system, leveraging a network of 20-30 cameras within stadiums to minimize human errors. VAR\'s operational scope typically encompasses 10-30 cameras, ensuring high decision accuracy but at a substantial cost. This report proposes an innovative approach to offside detection using a single camera, such as the broadcasting camera, to mitigate expenses associated with sophisticated technological setups.', 'abstract_zh': '过去十年间，足球领域的技术进步推动了这项运动的转型。与二元规则不同，足球的一些规则，如“越位规则”，依赖于主观判断而非简单的True或False标准。场上的裁判拥有最终裁决这些细微决策的权力。足球裁判工作的重大突破是视频助理裁判（VAR）系统，该系统利用 stadium 内的 20-30 台摄像机来最小化人为错误。VAR 的运作范围通常包括 10-30 台摄像机，确保决策的准确性，但代价高昂。本报告提出了一种创新的方法，利用单一摄像机（如广播摄像机）进行越位检测，以减轻复杂的科技设置所带来的成本问题。', 'title_zh': '使用单摄像头进行实时越位检测在足球中的应用'}
{'arxiv_id': 'arXiv:2502.16012', 'title': 'Cross-Model Transferability of Adversarial Patches in Real-time Segmentation for Autonomous Driving', 'authors': 'Prashant Shekhar, Bidur Devkota, Dumindu Samaraweera, Laxima Niure Kandel, Manoj Babu', 'link': 'https://arxiv.org/abs/2502.16012', 'abstract': "Adversarial attacks pose a significant threat to deep learning models, particularly in safety-critical applications like healthcare and autonomous driving. Recently, patch based attacks have demonstrated effectiveness in real-time inference scenarios owing to their 'drag and drop' nature. Following this idea for Semantic Segmentation (SS), here we propose a novel Expectation Over Transformation (EOT) based adversarial patch attack that is more realistic for autonomous vehicles. To effectively train this attack we also propose a 'simplified' loss function that is easy to analyze and implement. Using this attack as our basis, we investigate whether adversarial patches once optimized on a specific SS model, can fool other models or architectures. We conduct a comprehensive cross-model transferability analysis of adversarial patches trained on SOTA Convolutional Neural Network (CNN) models such PIDNet-S, PIDNet-M and PIDNet-L, among others. Additionally, we also include the Segformer model to study transferability to Vision Transformers (ViTs). All of our analysis is conducted on the widely used Cityscapes dataset. Our study reveals key insights into how model architectures (CNN vs CNN or CNN vs. Transformer-based) influence attack susceptibility. In particular, we conclude that although the transferability (effectiveness) of attacks on unseen images of any dimension is really high, the attacks trained against one particular model are minimally effective on other models. And this was found to be true for both ViT and CNN based models. Additionally our results also indicate that for CNN-based models, the repercussions of patch attacks are local, unlike ViTs. Per-class analysis reveals that simple-classes like 'sky' suffer less misclassification than others. The code for the project is available at: this https URL", 'abstract_zh': '基于斑马技术的对抗攻击：一种面向自主车辆更加现实的期望转换（EOT）方法及其跨模型可转移性分析', 'title_zh': '实时分割领域中自动驾驶中对抗性补丁的跨模型通用性研究'}
{'arxiv_id': 'arXiv:2502.16003', 'title': 'Hierarchical Residuals Exploit Brain-Inspired Compositionality', 'authors': 'Francisco M. López, Jochen Triesch', 'link': 'https://arxiv.org/abs/2502.16003', 'abstract': 'We present Hierarchical Residual Networks (HiResNets), deep convolutional neural networks with long-range residual connections between layers at different hierarchical levels. HiResNets draw inspiration on the organization of the mammalian brain by replicating the direct connections from subcortical areas to the entire cortical hierarchy. We show that the inclusion of hierarchical residuals in several architectures, including ResNets, results in a boost in accuracy and faster learning. A detailed analysis of our models reveals that they perform hierarchical compositionality by learning feature maps relative to the compressed representations provided by the skip connections.', 'abstract_zh': '层次 residual 网络：具有多级长程残差连接的深卷积神经网络', 'title_zh': '层次残差促进脑启发的组合性'}
{'arxiv_id': 'arXiv:2502.15996', 'title': 'Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts', 'authors': 'Aditya Kumar, Simon Rauch, Mario Cypko, Oliver Amft', 'link': 'https://arxiv.org/abs/2502.15996', 'abstract': 'We introduce a novel contextual embedding model med-gte-hybrid that was derived from the gte-large sentence transformer to extract information from unstructured clinical narratives. Our model tuning strategy for med-gte-hybrid combines contrastive learning and a denoising autoencoder. To evaluate the performance of med-gte-hybrid, we investigate several clinical prediction tasks in large patient cohorts extracted from the MIMIC-IV dataset, including Chronic Kidney Disease (CKD) patient prognosis, estimated glomerular filtration rate (eGFR) prediction, and patient mortality prediction. Furthermore, we demonstrate that the med-gte-hybrid model improves patient stratification, clustering, and text retrieval, thus outperforms current state-of-the-art models on the Massive Text Embedding Benchmark (MTEB). While some of our evaluations focus on CKD, our hybrid tuning of sentence transformers could be transferred to other medical domains and has the potential to improve clinical decision-making and personalised treatment pathways in various healthcare applications.', 'abstract_zh': '我们介绍了一种源自gte-large句子变换器的新颖上下文嵌入模型med-gte-hybrid，用于提取不结构化的临床叙事信息。med-gte-hybrid模型的调优策略结合了对比学习和去噪自编码器。为了评估med-gte-hybrid的表现，我们在MIMIC-IV数据集中提取的大患者队列中调查了几项临床预测任务，包括慢性肾病(CKD)患者的预后、估算的肾小球滤过率(eGFR)预测和患者死亡率预测。此外，我们证明med-gte-hybrid模型改善了患者分层、聚类和文本检索，并在大规模文本嵌入基准测试(MTEB)中优于当前的最先进模型。虽然我们的某些评估集中在CKD上，但我们的混合调优方法可以应用于其他医疗领域，并有望在各种医疗保健应用中改善临床决策和个性化的治疗路径。', 'title_zh': 'Med-gte-hybrid：一种从临床文本中提取可行动信息的上下文嵌入变压器模型'}
{'arxiv_id': 'arXiv:2502.15990', 'title': 'Automated Query-Product Relevance Labeling using Large Language Models for E-commerce Search', 'authors': 'Jayant Sachdev, Sean D Rosario, Abhijeet Phatak, He Wen, Swati Kirti, Chittaranjan Tripathy', 'link': 'https://arxiv.org/abs/2502.15990', 'abstract': "Accurate query-product relevance labeling is indispensable to generate ground truth dataset for search ranking in e-commerce. Traditional approaches for annotating query-product pairs rely on human-based labeling services, which is expensive, time-consuming and prone to errors. In this work, we explore the application of Large Language Models (LLMs) to automate query-product relevance labeling for large-scale e-commerce search. We use several publicly available and proprietary LLMs for this task, and conducted experiments on two open-source datasets and an in-house e-commerce search dataset. Using prompt engineering techniques such as Chain-of-Thought (CoT) prompting, In-context Learning (ICL), and Retrieval Augmented Generation (RAG) with Maximum Marginal Relevance (MMR), we show that LLM's performance has the potential to approach human-level accuracy on this task in a fraction of the time and cost required by human-labelers, thereby suggesting that our approach is more efficient than the conventional methods. We have generated query-product relevance labels using LLMs at scale, and are using them for evaluating improvements to our search algorithms. Our work demonstrates the potential of LLMs to improve query-product relevance thus enhancing e-commerce search user experience. More importantly, this scalable alternative to human-annotation has significant implications for information retrieval domains including search and recommendation systems, where relevance scoring is crucial for optimizing the ranking of products and content to improve customer engagement and other conversion metrics.", 'abstract_zh': '大规模电商平台搜索中的查询-产品相关性自动标注：大规模应用大型语言模型的成本效益解决方案', 'title_zh': '使用大型语言模型自动化查询-产品相关性标注以优化电子商务搜索'}
{'arxiv_id': 'arXiv:2502.15980', 'title': 'Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation', 'authors': 'Yuan Tian, Daniel Lee, Fei Wu, Tung Mai, Kun Qian, Siddhartha Sahai, Tianyi Zhang, Yunyao Li', 'link': 'https://arxiv.org/abs/2502.15980', 'abstract': 'Text-to-SQL models, which parse natural language (NL) questions to executable SQL queries, are increasingly adopted in real-world applications. However, deploying such models in the real world often requires adapting them to the highly specialized database schemas used in specific applications. We find that existing text-to-SQL models experience significant performance drops when applied to new schemas, primarily due to the lack of domain-specific data for fine-tuning. This data scarcity also limits the ability to effectively evaluate model performance in new domains. Continuously obtaining high-quality text-to-SQL data for evolving schemas is prohibitively expensive in real-world scenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop text-to-SQL data annotation system. SQLsynth streamlines the creation of high-quality text-to-SQL datasets through human-LLM collaboration in a structured workflow. A within-subjects user study comparing SQLsynth with manual annotation and ChatGPT shows that SQLsynth significantly accelerates text-to-SQL data annotation, reduces cognitive load, and produces datasets that are more accurate, natural, and diverse. Our code is available at this https URL.', 'abstract_zh': 'Text-to-SQL模型将自然语言(NL)问题解析为可执行的SQL查询，已在实际应用中被越来越多地采用。然而，在实际部署这些模型时常需将它们适应特定应用场景中高度专业化的关系数据库模式。我们发现，现有的Text-to-SQL模型在应用于新的模式时会经历显著的性能下降，主要原因是缺乏用于微调的领域特定数据。这些数据的稀缺性也限制了评估模型在新领域中的性能的能力。在现实场景中，持续获取高质量的Text-to-SQL数据对于不断变化的模式来说是代价高昂的。为解决这一问题，我们提出了SQLsynth，一种包含人类在环的Text-to-SQL数据注释系统。SQLsynth通过结构化的流程促进人类与大语言模型（LLM）的协作，以简化高质量Text-to-SQL数据集的创建。一项针对SQLsynth、手工注释和ChatGPT的嵌套被试用户研究显示，SQLsynth在加速Text-to-SQL数据注释、减轻认知负担以及产出更为准确、自然和多样化的数据集方面具有显著优势。相关代码可在如下链接获取。', 'title_zh': '基于人类-大语言模型协作数据注释的文本到SQL领域适应方法'}
{'arxiv_id': 'arXiv:2502.15975', 'title': 'Sparsity May Be All You Need: Sparse Random Parameter Adaptation', 'authors': 'Jesus Rios, Pierre Dognin, Ronny Luss, Karthikeyan N. Ramamurthy', 'link': 'https://arxiv.org/abs/2502.15975', 'abstract': 'Full fine-tuning of large language models for alignment and task adaptation has become prohibitively expensive as models have grown in size. Parameter-Efficient Fine-Tuning (PEFT) methods aim at significantly reducing the computational and memory resources needed for fine-tuning these models by only training on a small number of parameters instead of all model parameters. Currently, the most popular PEFT method is the Low-Rank Adaptation (LoRA), which freezes the parameters of the model to be fine-tuned and introduces a small set of trainable parameters in the form of low-rank matrices. We propose simply reducing the number of trainable parameters by randomly selecting a small proportion of the model parameters to train on. In this paper, we compare the efficiency and performance of our proposed approach with PEFT methods, including LoRA, as well as full parameter fine-tuning.', 'abstract_zh': '大型语言模型的全面微调因模型规模扩大而变得成本高昂，参数高效微调（PEFT）方法旨在通过仅训练少量参数而非全部参数来显著减少微调所需的时间和内存资源。目前，最受欢迎的PEFT方法是低秩适应（LoRA），该方法冻结待微调模型的参数，并引入一组以低秩矩阵形式表示的可训练参数。我们提议通过随机选择少量模型参数进行训练来减少可训练参数的数量。在本文中，我们将我们提出的方法与PEFT方法，包括LoRA，以及全面参数微调的效率和性能进行比较。', 'title_zh': '稀疏或许足矣：稀疏随机参数适应'}
{'arxiv_id': 'arXiv:2502.15972', 'title': 'Multi-Agent Multimodal Models for Multicultural Text to Image Generation', 'authors': 'Parth Bhalerao, Mounika Yalamarty, Brian Trinh, Oana Ignat', 'link': 'https://arxiv.org/abs/2502.15972', 'abstract': 'Large Language Models (LLMs) demonstrate impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of existing data and models. Meanwhile, multi-agent models have shown strong capabilities in solving complex tasks. In this paper, we evaluate the performance of LLMs in a multi-agent interaction setting for the novel task of multicultural image generation. Our key contributions are: (1) We introduce MosAIG, a Multi-Agent framework that enhances multicultural Image Generation by leveraging LLMs with distinct cultural personas; (2) We provide a dataset of 9,000 multicultural images spanning five countries, three age groups, two genders, 25 historical landmarks, and five languages; and (3) We demonstrate that multi-agent interactions outperform simple, no-agent models across multiple evaluation metrics, offering valuable insights for future research. Our dataset and models are available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）在多种跨模态任务中表现出色。然而，由于现有数据和模型以西方为中心，其在跨文化环境中的有效性仍受到限制。与此同时，多 agent 模型在解决复杂任务方面显示出强大的能力。在本文中，我们评估了LLMs在多 agent 交互环境中进行跨文化图像生成这一新任务的表现。我们的主要贡献包括：（1）提出了一种多 agent 框架MosAIG，通过利用具有不同文化个性的语言模型来增强跨文化图像生成；（2）提供了一个包含9,000张跨文化图像的数据集，覆盖五个国家、三个年龄组、两个性别、25个历史地标和五种语言；（3）证明了多 agent 交互在多个评估指标上优于简单的无 agent 模型，为未来研究提供了宝贵的见解。我们的数据集和模型可在此网址访问：this https URL。', 'title_zh': '多Agent多模态模型在跨文化文本到图像生成中的应用'}
{'arxiv_id': 'arXiv:2502.15969', 'title': 'Forgotten Polygons: Multimodal Large Language Models are Shape-Blind', 'authors': 'William Rudman, Michal Golovanesky, Amir Bar, Vedant Palit, Yann LeCun, Carsten Eickhoff, Ritambhara Singh', 'link': 'https://arxiv.org/abs/2502.15969', 'abstract': "Despite strong performance on vision-language tasks, Multimodal Large Language Models (MLLMs) struggle with mathematical problem-solving, with both open-source and state-of-the-art models falling short of human performance on visual-math benchmarks. To systematically examine visual-mathematical reasoning in MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test multi-step reasoning, and (3) explore a potential solution to improve visual reasoning capabilities. Our findings reveal fundamental shortcomings in shape recognition, with top models achieving under 50% accuracy in identifying regular polygons. We analyze these failures through the lens of dual-process theory and show that MLLMs rely on System 1 (intuitive, memorized associations) rather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count the sides of both familiar and novel shapes, suggesting they have neither learned the concept of sides nor effectively process visual inputs. Finally, we propose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances multi-step mathematical reasoning by explicitly referencing visual annotations in diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting task from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs remains an open problem, and visually-guided prompting is essential for successfully engaging visual reasoning. Code available at: this https URL.", 'abstract_zh': '尽管在视觉语言任务上表现出色，多模态大型语言模型在数学问题解决方面仍存在问题，开源和最先进的模型在视觉数学基准测试中的表现均低于人类水平。为了系统地探讨多模态大型语言模型的视觉数学推理能力，我们（1）评估其对几何基本概念的理解，（2）测试多步推理，（3）探索一种潜在解决方案以提高视觉推理能力。我们的研究发现表明，在形状识别方面存在根本性的不足，顶级模型在识别正多边形时的准确性不到50%。我们通过二过程理论的视角分析这些失败，表明多模态大型语言模型依赖于直觉和记忆化的关联（System 1），而非有意识的推理（System 2）。因此，多模态大型语言模型无法准确计数熟悉和新颖形状的边，表明它们既没有学会边的概念，也无法有效处理视觉输入。最后，我们提出了视觉提示链式思考（Visually Cued Chain-of-Thought, VC-CoT）的提示方法，通过明确引用图表中的视觉注释来增强多步数学推理能力，在提升GPT-4o在计数不规则多边形边的数量任务上的准确性方面从7%提升到93%。我们的研究结果表明，多模态大型语言模型中的有意识推理仍是一个待解决的问题，而视觉引导的提示对于成功运用视觉推理至关重要。代码请访问：this https URL。', 'title_zh': '遗忘的多边形：多模态大型语言模型是形状盲的'}
{'arxiv_id': 'arXiv:2502.15964', 'title': 'Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models', 'authors': 'Avanika Narayan, Dan Biderman, Sabri Eyuboglu, Avner May, Scott Linderman, James Zou, Christopher Re', 'link': 'https://arxiv.org/abs/2502.15964', 'abstract': "We investigate an emerging setup in which a small, on-device language model (LM) with access to local data communicates with a frontier, cloud-hosted LM to solve real-world tasks involving financial, medical, and scientific reasoning over long documents. Can a local-remote collaboration reduce cloud inference costs while preserving quality? First, we consider a naive collaboration protocol where the local and remote models simply chat back and forth. Because only the local model reads the full context, this protocol achieves a 30.4x reduction in remote costs, but recovers only 87% of the performance of the frontier model. We identify two key limitations of this protocol: the local model struggles to (1) follow the remote model's multi-step instructions and (2) reason over long contexts. Motivated by these observations, we study an extension of this protocol, coined MinionS, in which the remote model decomposes the task into easier subtasks over shorter chunks of the document, that are executed locally in parallel. MinionS reduces costs by 5.7x on average while recovering 97.9% of the performance of the remote model alone. Our analysis reveals several key design choices that influence the trade-off between cost and performance in local-remote systems.", 'abstract_zh': '一种本地-远程协作的新兴设置：小规模设备端语言模型与云端前沿语言模型协同解决涉及金融、医疗和科学推理的长文档实际任务，能否在保持质量的同时降低云推理成本？', 'title_zh': 'Minions: 在设备端和云端语言模型之间经济高效的协作'}
{'arxiv_id': 'arXiv:2502.15957', 'title': 'R$^3$Mem: Bridging Memory Retention and Retrieval via Reversible Compression', 'authors': 'Xiaoqiang Wang, Suyuchen Wang, Yun Zhu, Bang Liu', 'link': 'https://arxiv.org/abs/2502.15957', 'abstract': "Memory plays a key role in enhancing LLMs' performance when deployed to real-world applications. Existing solutions face trade-offs: explicit memory designs based on external storage require complex management and incur storage overhead, while implicit memory designs that store information via parameters struggle with reliable retrieval. In this paper, we propose R$^3$Mem, a memory network that optimizes both information Retention and Retrieval through Reversible context compression. Specifically, R$^3$Mem employs virtual memory tokens to compress and encode infinitely long histories, further enhanced by a hierarchical compression strategy that refines information from document- to entity-level for improved assimilation across granularities. For retrieval, R$^3$Mem employs a reversible architecture, reconstructing raw data by invoking the model backward with compressed information. Implemented via parameter-efficient fine-tuning, it can integrate seamlessly with any Transformer-based model. Experiments demonstrate that our memory design achieves state-of-the-art performance in long-context language modeling and retrieval-augmented generation tasks. It also significantly outperforms conventional memory modules in long-horizon interaction tasks like conversational agents, showcasing its potential for next-generation retrieval systems.", 'abstract_zh': 'R$^3$Mem：通过可逆上下文压缩优化信息保留与检索的记忆网络', 'title_zh': 'R$^3$Mem: 通过可逆压缩连接记忆保留与检索'}
{'arxiv_id': 'arXiv:2502.15955', 'title': 'Compression Barriers for Autoregressive Transformers', 'authors': 'Themistoklis Haris, Krzysztof Onak', 'link': 'https://arxiv.org/abs/2502.15955', 'abstract': "A key limitation of autoregressive Transformers is the large memory needed at inference-time to cache all previous key-value (KV) embeddings. Prior works address this by compressing the KV cache, but often assume specific structural properties of the embeddings. This raises the following natural question: Can truly sublinear space utilization be achieved without such assumptions? In this work, we answer this question in the negative. Any algorithm for attention-based token generation must use $\\Theta(nd)$ space, where $n$ is the number of tokens generated so far and $d = \\Omega(\\log n)$ is the dimension of the KV embeddings. Our proof involves a reduction from a classic communication complexity problem and uses a randomized construction that leverages properties of projections in the spirit of the Johnson-Linderstrauss lemma. For the low-dimensional regime $d = o(\\log n)$, we show that any algorithm requires $\\Omega(d\\cdot e^d)$ space and prove, using tight bounds on covering numbers, that SubGen, proposed by Zandieh, Han, Mirrokni and Karbasi, matches this bound. Further, we investigate how sparsity assumptions enable token generation in truly sublinear space, presenting impossibility results and proposing a new KV cache compression algorithm for sliding window attention when the value cache outside the window is unmasked. Finally, we analyze token generation's time complexity, using an indistinguishability argument to prove that no non-adaptive algorithm can compute attention online in sublinear time for all tokens.", 'abstract_zh': '自回归Transformer的一个关键局限是在推理时需要大量内存来缓存所有先前的键值（KV）嵌入。先前的工作通过压缩KV缓存来解决这一问题，但通常假设嵌入的特定结构属性。这引发了一个自然的问题：是否可以在不假设这些属性的情况下实现真正亚线性空间利用率？在本文中，我们回答了这一问题，得出否定结论。任何基于注意力的Token生成算法都必须使用$\\Theta(nd)$空间，其中$n$是目前已生成的Token数量，$d = \\Omega(\\log n)$是KV嵌入的维度。我们的证明涉及从经典通信复杂性问题中进行归约，并利用投影性质的随机构造。对于低维情形$d = o(\\log n)$，我们证明任何算法需要$\\Omega(d \\cdot e^d)$空间，并利用覆盖数的紧界证明，Zandieh, Han, Mirrokni和Karbasi提出的SubGen达到了这一界。此外，我们研究了稀疏假设如何在真正亚线性空间中实现Token生成，提出了一些不可能性结果，并提出了一种针对滑动窗口注意力的新KV缓存压缩算法，当窗口外的价值缓存未掩码时。最后，我们分析了Token生成的时间复杂性，利用不可区分性论证证明，没有非自适应算法可以在所有Token上以亚线性时间在线计算注意力。', 'title_zh': '自回归变压器的压缩障碍'}
{'arxiv_id': 'arXiv:2502.15954', 'title': 'MMRAG: Multi-Mode Retrieval-Augmented Generation with Large Language Models for Biomedical In-Context Learning', 'authors': 'Zaifu Zhan, Jun Wang, Shuang Zhou, Jiawen Deng, Rui Zhang', 'link': 'https://arxiv.org/abs/2502.15954', 'abstract': "Objective: To optimize in-context learning in biomedical natural language processing by improving example selection. Methods: We introduce a novel multi-mode retrieval-augmented generation (MMRAG) framework, which integrates four retrieval strategies: (1) Random Mode, selecting examples arbitrarily; (2) Top Mode, retrieving the most relevant examples based on similarity; (3) Diversity Mode, ensuring variation in selected examples; and (4) Class Mode, selecting category-representative examples. This study evaluates MMRAG on three core biomedical NLP tasks: Named Entity Recognition (NER), Relation Extraction (RE), and Text Classification (TC). The datasets used include BC2GM for gene and protein mention recognition (NER), DDI for drug-drug interaction extraction (RE), GIT for general biomedical information extraction (RE), and HealthAdvice for health-related text classification (TC). The framework is tested with two large language models (Llama2-7B, Llama3-8B) and three retrievers (Contriever, MedCPT, BGE-Large) to assess performance across different retrieval strategies. Results: The results from the Random mode indicate that providing more examples in the prompt improves the model's generation performance. Meanwhile, Top mode and Diversity mode significantly outperform Random mode on the RE (DDI) task, achieving an F1 score of 0.9669, a 26.4% improvement. Among the three retrievers tested, Contriever outperformed the other two in a greater number of experiments. Additionally, Llama 2 and Llama 3 demonstrated varying capabilities across different tasks, with Llama 3 showing a clear advantage in handling NER tasks. Conclusion: MMRAG effectively enhances biomedical in-context learning by refining example selection, mitigating data scarcity issues, and demonstrating superior adaptability for NLP-driven healthcare applications.", 'abstract_zh': '目标：通过改善例证选择以优化生物医学自然语言处理中的上下文学习。方法：我们提出了一种新颖的多模式检索增强生成（MMRAG）框架，该框架整合了四种检索策略：（1）随机模式，任意选择例证；（2）顶级模式，基于相似性检索最相关的例证；（3）多样性模式，确保所选例证的多样性；（4）类别模式，选择类别代表性例证。本研究在三项核心生物医学自然语言处理任务上评估了MMRAG：命名实体识别（NER）、关系提取（RE）和文本分类（TC）。所使用的数据集包括BC2GM（基因和蛋白质提及识别（NER））、DDI（药物-药物交互提取（RE））、GIT（通用生物医学信息提取（RE））和HealthAdvice（健康相关文本分类（TC））。框架使用了两个大型语言模型（Llama2-7B、Llama3-8B）和三个检索器（Contriever、MedCPT、BGE-Large），以评估不同检索策略下的性能。结果：随机模式的结果表明，在提示中提供更多例证可以提高模型的生成性能。同时，顶级模式和多样性模式在RE（DDI）任务上显著优于随机模式，F1分数达到0.9669，提升了26.4%。在三个测试的检索器中，Contriever在更多实验中表现出更好的性能。此外，Llama 2和Llama 3在不同任务中显示出不同的能力，Llama 3在处理NER任务方面具有明显优势。结论：MMRAG通过优化例证选择有效提升了生物医学上下文学习，缓解了数据稀缺问题，并展示了更好的适应性，适用于NLP驱动的医疗保健应用。', 'title_zh': 'MMRAG：多模式检索增强生成在生物医学情境学习中的应用'}
{'arxiv_id': 'arXiv:2502.15938', 'title': 'Straight to Zero: Why Linearly Decaying the Learning Rate to Zero Works Best for LLMs', 'authors': 'Shane Bergsma, Nolan Dey, Gurpreet Gosal, Gavia Gray, Daria Soboleva, Joel Hestness', 'link': 'https://arxiv.org/abs/2502.15938', 'abstract': 'LLMs are commonly trained with a learning rate (LR) warmup, followed by cosine decay to 10% of the maximum (10x decay). In a large-scale empirical study, we show that under an optimal peak LR, a simple linear decay-to-zero (D2Z) schedule consistently outperforms other schedules when training at compute-optimal dataset sizes. D2Z is superior across a range of model sizes, batch sizes, datasets, and vocabularies. Benefits increase as dataset size increases. Leveraging a novel interpretation of AdamW as an exponential moving average of weight updates, we show how linear D2Z optimally balances the demands of early training (moving away from initial conditions) and late training (averaging over more updates in order to mitigate gradient noise). In experiments, a 610M-parameter model trained for 80 tokens-per-parameter (TPP) using D2Z achieves lower loss than when trained for 200 TPP using 10x decay, corresponding to an astonishing 60% compute savings. Models such as Llama2-7B, trained for 286 TPP with 10x decay, could likely have saved a majority of compute by training with D2Z.', 'abstract_zh': '大规模预训练语言模型在计算最优数据集规模下训练时，经过优化的最大学习率与线性衰减至零（D2Z）调度策略相比，其他调度策略表现更优。线性D2Z调度策略在不同模型规模、批次大小、数据集和词汇量中均表现出优越性。随着数据集规模的增加，这种优势更加明显。通过新颖解读AdamW为权重更新的指数移动平均值，我们展示了线性D2Z如何在早期训练（远离初始条件）和后期训练（通过更多更新来降低梯度噪声）的需求之间实现最优平衡。实验表明，使用D2Z训练80个token-per-parameter（TPP）的610M参数模型，其损失低于使用10x衰减训练200个TPP的模型，计算成本节省了60%。使用10x衰减训练286个TPP的Llama2-7B等模型，很可能通过使用D2Z训练节省大部分计算资源。', 'title_zh': '直趋零：为何对学习率线性衰减至零是大型语言模型的最佳选择'}
{'arxiv_id': 'arXiv:2502.15937', 'title': 'Discovery and Deployment of Emergent Robot Swarm Behaviors via Representation Learning and Real2Sim2Real Transfer', 'authors': 'Connor Mattson, Varun Raveendra, Ricardo Vega, Cameron Nowzari, Daniel S. Drew, Daniel S. Brown', 'link': 'https://arxiv.org/abs/2502.15937', 'abstract': 'Given a swarm of limited-capability robots, we seek to automatically discover the set of possible emergent behaviors. Prior approaches to behavior discovery rely on human feedback or hand-crafted behavior metrics to represent and evolve behaviors and only discover behaviors in simulation, without testing or considering the deployment of these new behaviors on real robot swarms. In this work, we present Real2Sim2Real Behavior Discovery via Self-Supervised Representation Learning, which combines representation learning and novelty search to discover possible emergent behaviors automatically in simulation and enable direct controller transfer to real robots. First, we evaluate our method in simulation and show that our proposed self-supervised representation learning approach outperforms previous hand-crafted metrics by more accurately representing the space of possible emergent behaviors. Then, we address the reality gap by incorporating recent work in sim2real transfer for swarms into our lightweight simulator design, enabling direct robot deployment of all behaviors discovered in simulation on an open-source and low-cost robot platform.', 'abstract_zh': '基于自我监督表示学习的Real2Sim2Real行为发现方法', 'title_zh': '基于表示学习和Real2Sim2Real转移的涌现机器人群行为发现与部署'}
{'arxiv_id': 'arXiv:2502.15936', 'title': 'Space-O-RAN: Enabling Intelligent, Open, and Interoperable Non Terrestrial Networks in 6G', 'authors': 'Eduardo Baena, Paolo Testolina, Michele Polese, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia', 'link': 'https://arxiv.org/abs/2502.15936', 'abstract': 'Non-terrestrial networks (NTNs) are essential for ubiquitous connectivity, providing coverage in remote and underserved areas. However, since NTNs are currently operated independently, they face challenges such as isolation, limited scalability, and high operational costs. Integrating satellite constellations with terrestrial networks offers a way to address these limitations while enabling adaptive and cost-efficient connectivity through the application of Artificial Intelligence (AI) models.\nThis paper introduces Space-O-RAN, a framework that extends Open Radio Access Network (RAN) principles to NTNs. It employs hierarchical closed-loop control with distributed Space RAN Intelligent Controllers (Space-RICs) to dynamically manage and optimize operations across both domains.\nTo enable adaptive resource allocation and network orchestration, the proposed architecture integrates real-time satellite optimization and control with AI-driven management and digital twin (DT) modeling. It incorporates distributed Space Applications (sApps) and dApps to ensure robust performance in in highly dynamic orbital environments. A core feature is dynamic link-interface mapping, which allows network functions to adapt to specific application requirements and changing link conditions using all physical links on the satellite.\nSimulation results evaluate its feasibility by analyzing latency constraints across different NTN link types, demonstrating that intra-cluster coordination operates within viable signaling delay bounds, while offloading non-real-time tasks to ground infrastructure enhances scalability toward sixth-generation (6G) networks.', 'abstract_zh': '非地球网络（NTNs）对于无处不在的连接至关重要，提供偏远和未服务区域的覆盖。然而，由于NTNs目前是独立操作的，它们面临着孤立、扩展有限和高昂运营成本的挑战。将卫星星座与地面网络集成并通过人工智能（AI）模型的应用来实现自适应和成本效益的连接提供了一种解决方案。\n\n本文介绍了Space-O-RAN框架，该框架将开放无线接入网络（RAN）原则扩展到NTNs。它采用分层闭环控制，结合分布式空间RAN智能控制器（Space-RICs），以动态管理和优化两个域的操作。\n\n为实现自适应资源分配和网络编排，所提出的架构将实时卫星优化和控制与基于AI的管理和数字孪生（DT）建模集成。它包含了分布式太空应用（sApps）和dApps，以确保在高度动态轨道环境中的稳健性能。一个核心特征是动态链路-接口映射，它允许网络功能根据特定的应用需求和变化的链路条件适应使用所有卫星物理链路。', 'title_zh': 'Space-O-RAN：实现6G非地面网络的智能、开放和互操作性'}
{'arxiv_id': 'arXiv:2502.15920', 'title': 'Self-Taught Agentic Long Context Understanding', 'authors': 'Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum', 'link': 'https://arxiv.org/abs/2502.15920', 'abstract': "Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM's understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow. At the core of AgenticLU is Chain-of-Clarifications (CoC), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. By scaling inference as a tree search where each node represents a CoC step, we achieve 97.8% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight. To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the CoC workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables AgenticLU models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass. Extensive experiments across seven long-context tasks demonstrate that AgenticLU significantly outperforms state-of-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows.", 'abstract_zh': 'Agentic长语境理解（AgenticLU）：通过目标性自我澄清与上下文接地提升大型语言模型处理复杂长语境问题的能力', 'title_zh': '自我教授的代理长期上下文理解'}
{'arxiv_id': 'arXiv:2502.15907', 'title': 'Graph Attention Convolutional U-NET: A Semantic Segmentation Model for Identifying Flooded Areas', 'authors': 'Muhammad Umair Danish, Madhushan Buwaneswaran, Tehara Fonseka, Katarina Grolinger', 'link': 'https://arxiv.org/abs/2502.15907', 'abstract': 'The increasing impact of human-induced climate change and unplanned urban constructions has increased flooding incidents in recent years. Accurate identification of flooded areas is crucial for effective disaster management and urban planning. While few works have utilized convolutional neural networks and transformer-based semantic segmentation techniques for identifying flooded areas from aerial footage, recent developments in graph neural networks have created improvement opportunities. This paper proposes an innovative approach, the Graph Attention Convolutional U-NET (GAC-UNET) model, based on graph neural networks for automated identification of flooded areas. The model incorporates a graph attention mechanism and Chebyshev layers into the U-Net architecture. Furthermore, this paper explores the applicability of transfer learning and model reprogramming to enhance the accuracy of flood area segmentation models. Empirical results demonstrate that the proposed GAC-UNET model, outperforms other approaches with 91\\% mAP, 94\\% dice score, and 89\\% IoU, providing valuable insights for informed decision-making and better planning of future infrastructures in flood-prone areas.', 'abstract_zh': '基于图神经网络的图注意力卷积U-NET模型在自动识别浸水区域的应用', 'title_zh': '基于图注意力卷积的U-NET：一种识别淹没区域的语义分割模型'}
{'arxiv_id': 'arXiv:2502.15902', 'title': 'IPAD: Inverse Prompt for AI Detection -- A Robust and Explainable LLM-Generated Text Detector', 'authors': 'Zheng Chen, Yushi Feng, Changyang He, Yue Deng, Hongxi Pu, Bo Li', 'link': 'https://arxiv.org/abs/2502.15902', 'abstract': 'Large Language Models (LLMs) have attained human-level fluency in text generation, which complicates the distinguishing between human-written and LLM-generated texts. This increases the risk of misuse and highlights the need for reliable detectors. Yet, existing detectors exhibit poor robustness on out-of-distribution (OOD) data and attacked data, which is critical for real-world scenarios. Also, they struggle to provide explainable evidence to support their decisions, thus undermining the reliability. In light of these challenges, we propose IPAD (Inverse Prompt for AI Detection), a novel framework consisting of a Prompt Inverter that identifies predicted prompts that could have generated the input text, and a Distinguisher that examines how well the input texts align with the predicted prompts. We develop and examine two versions of Distinguishers. Empirical evaluations demonstrate that both Distinguishers perform significantly better than the baseline methods, with version2 outperforming baselines by 9.73% on in-distribution data (F1-score) and 12.65% on OOD data (AUROC). Furthermore, a user study is conducted to illustrate that IPAD enhances the AI detection trustworthiness by allowing users to directly examine the decision-making evidence, which provides interpretable support for its state-of-the-art detection results.', 'abstract_zh': '大语言模型（LLMs）在文本生成中达到了人类水平的流畅度，这使得区分人类撰写和LLM生成的文本变得复杂，增加了滥用风险，凸显了可靠检测器的必要性。然而，现有检测器在处理离分布（OOD）数据和攻击数据时表现出较差的鲁棒性，这对于真实世界的应用至关重要。此外，它们难以提供可解释的证据来支持其决策，从而削弱了其可靠性。鉴于这些挑战，我们提出了IPAD（逆向提示用于AI检测）这一新框架，该框架包括一个提示反转器，用于识别可能生成输入文本的预测提示，以及一个辨别器，用于检查输入文本与预测提示的匹配程度。我们开发并研究了两种版本的辨别器。实证评估表明，这两种辨别器都显著优于基线方法，第二版本在分布内数据上以F1分数领先基线方法9.73%，在OOD数据上以AUROC领先12.65%。此外，我们进行了用户研究，以说明IPAD通过使用户能够直接检查决策证据来提高AI检测的可信度，从而为其最先进的检测结果提供可解释的支持。', 'title_zh': 'IPAD: 反向提示词以检测AI生成的内容——一种稳健且可解释的LLM生成文本检测器'}
{'arxiv_id': 'arXiv:2502.15898', 'title': 'ML-Driven Approaches to Combat Medicare Fraud: Advances in Class Imbalance Solutions, Feature Engineering, Adaptive Learning, and Business Impact', 'authors': 'Dorsa Farahmandazad, Kasra Danesh', 'link': 'https://arxiv.org/abs/2502.15898', 'abstract': 'Medicare fraud poses a substantial challenge to healthcare systems, resulting in significant financial losses and undermining the quality of care provided to legitimate beneficiaries. This study investigates the use of machine learning (ML) to enhance Medicare fraud detection, addressing key challenges such as class imbalance, high-dimensional data, and evolving fraud patterns. A dataset comprising inpatient claims, outpatient claims, and beneficiary details was used to train and evaluate five ML models: Random Forest, KNN, LDA, Decision Tree, and AdaBoost. Data preprocessing techniques included resampling SMOTE method to address the class imbalance, feature selection for dimensionality reduction, and aggregation of diagnostic and procedural codes. Random Forest emerged as the best-performing model, achieving a training accuracy of 99.2% and validation accuracy of 98.8%, and F1-score (98.4%). The Decision Tree also performed well, achieving a validation accuracy of 96.3%. KNN and AdaBoost demonstrated moderate performance, with validation accuracies of 79.2% and 81.1%, respectively, while LDA struggled with a validation accuracy of 63.3% and a low recall of 16.6%. The results highlight the importance of advanced resampling techniques, feature engineering, and adaptive learning in detecting Medicare fraud effectively. This study underscores the potential of machine learning in addressing the complexities of fraud detection. Future work should explore explainable AI and hybrid models to improve interpretability and performance, ensuring scalable and reliable fraud detection systems that protect healthcare resources and beneficiaries.', 'abstract_zh': '机器学习在增强医疗保险欺诈检测中的应用：应对类别不平衡、高维数据和欺诈模式演变的挑战', 'title_zh': '基于ML的方法对抗医疗保险欺诈：类不平衡解决方案、特征工程、自适应学习和业务影响的进展'}
{'arxiv_id': 'arXiv:2502.15895', 'title': 'Directional Gradient Projection for Robust Fine-Tuning of Foundation Models', 'authors': 'Chengyue Huang, Junjiao Tian, Brisa Maneechotesuwan, Shivang Chopra, Zsolt Kira', 'link': 'https://arxiv.org/abs/2502.15895', 'abstract': 'Robust fine-tuning aims to adapt large foundation models to downstream tasks while preserving their robustness to distribution shifts. Existing methods primarily focus on constraining and projecting current model towards the pre-trained initialization based on the magnitudes between fine-tuned and pre-trained weights, which often require extensive hyper-parameter tuning and can sometimes result in underfitting. In this work, we propose Directional Gradient Projection (DiGraP), a novel layer-wise trainable method that incorporates directional information from gradients to bridge regularization and multi-objective optimization. Besides demonstrating our method on image classification, as another contribution we generalize this area to the multi-modal evaluation settings for robust fine-tuning. Specifically, we first bridge the uni-modal and multi-modal gap by performing analysis on Image Classification reformulated Visual Question Answering (VQA) benchmarks and further categorize ten out-of-distribution (OOD) VQA datasets by distribution shift types and degree (i.e. near versus far OOD). Experimental results show that DiGraP consistently outperforms existing baselines across Image Classfication and VQA tasks with discriminative and generative backbones, improving both in-distribution (ID) generalization and OOD robustness.', 'abstract_zh': '鲁棒微调旨在适应大型基础模型以处理下游任务的同时保持对分布转移的鲁棒性。现有的方法主要侧重于通过微调和预训练权重之间的幅度约束和投影当前模型至预训练初始化，这通常需要大量超参数调整，并且有时会导致欠拟合。在这项工作中，我们提出了方向梯度投影（DiGraP），一种新颖的逐层可训练方法，该方法结合了梯度的方向信息，以桥接正则化和多目标优化。除了在图像分类中展示我们的方法外，作为另一项贡献，我们将此领域推广到鲁棒微调的多模态评估设置中。具体来说，我们首先通过分析重新表述的图像分类任务下的视觉问答（VQA）基准，并进一步按分布转移类型和程度（即近似分布外与远分布外）对十个分布外（OOD）VQA数据集进行分类，以弥合单模态与多模态之间的差距。实验结果表明，DiGraP在图像分类和VQA任务中均优于现有的基线方法，无论是使用判别性还是生成性回溯模型，都提高了分布内（ID）泛化能力和分布外（OOD）鲁棒性。', 'title_zh': '面向方向梯度投影的鲁棒基础模型微调方法'}
{'arxiv_id': 'arXiv:2502.15872', 'title': 'MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use', 'authors': 'Zaid Khan, Ali Farhadi, Ranjay Krishna, Luca Weihs, Mohit Bansal, Tanmay Gupta', 'link': 'https://arxiv.org/abs/2502.15872', 'abstract': "When a human requests an LLM to complete a coding task using functionality from a large code repository, how do we provide context from the repo to the LLM? One approach is to add the entire repo to the LLM's context window. However, most tasks involve only fraction of symbols from a repo, longer contexts are detrimental to the LLM's reasoning abilities, and context windows are not unlimited. Alternatively, we could emulate the human ability to navigate a large repo, pick out the right functionality, and form a plan to solve the task. We propose MutaGReP (Mutation-guided Grounded Repository Plan Search), an approach to search for plans that decompose a user request into natural language steps grounded in the codebase. MutaGReP performs neural tree search in plan space, exploring by mutating plans and using a symbol retriever for grounding. On the challenging LongCodeArena benchmark, our plans use less than 5% of the 128K context window for GPT-4o but rival the coding performance of GPT-4o with a context window filled with the repo. Plans produced by MutaGReP allow Qwen 2.5 Coder 32B and 72B to match the performance of GPT-4o with full repo context and enable progress on the hardest LongCodeArena tasks. Project page: this http URL", 'abstract_zh': '当人类请求LLM使用大型代码库中的功能完成编码任务时，我们如何向LLM提供代码库的上下文？一种方法是将整个代码库添加到LLM的上下文窗口中。然而，大多数任务仅涉及代码库中的一小部分符号，过长的上下文对LLM的推理能力有害，而且上下文窗口并非无限。另一种方法是模拟人类在大型代码库中导航、挑选合适功能并制定解决任务计划的能力。我们提出了MutaGReP（基于 mutation 的接地代码库计划搜索）方法，该方法通过在计划空间中进行神经树搜索，通过突变计划和使用符号检索器进行接地来寻找将用户请求分解为基于代码库的自然语言步骤的计划。在具有挑战性的LongCodeArena基准测试中，我们的计划使用了少于5%的128K上下文窗口，但其编码性能与上下文窗口填满代码库的GPT-4o相当。MutaGReP生成的计划使Qwen 2.5 Coder 32B和72B能够与满载代码库上下文的GPT-4o性能相当，并且能够解决LongCodeArena中最难的任务。项目页面: this http URL。', 'title_zh': 'MutaGReP: 不执行的代码库-grounded 计划搜索'}
{'arxiv_id': 'arXiv:2502.15871', 'title': 'A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare', 'authors': 'Manar Aljohani, Jun Hou, Sindhura Kommu, Xuan Wang', 'link': 'https://arxiv.org/abs/2502.15871', 'abstract': 'The application of large language models (LLMs) in healthcare has the potential to revolutionize clinical decision-making, medical research, and patient care. As LLMs are increasingly integrated into healthcare systems, several critical challenges must be addressed to ensure their reliable and ethical deployment. These challenges include truthfulness, where models generate misleading information; privacy, with risks of unintentional data retention; robustness, requiring defenses against adversarial attacks; fairness, addressing biases in clinical outcomes; explainability, ensuring transparent decision-making; and safety, mitigating risks of misinformation and medical errors. Recently, researchers have begun developing benchmarks and evaluation frameworks to systematically assess the trustworthiness of LLMs. However, the trustworthiness of LLMs in healthcare remains underexplored, lacking a systematic review that provides a comprehensive understanding and future insights into this area. This survey bridges this gap by providing a comprehensive overview of the recent research of existing methodologies and solutions aimed at mitigating the above risks in healthcare. By focusing on key trustworthiness dimensions including truthfulness, privacy and safety, robustness, fairness and bias, and explainability, we present a thorough analysis of how these issues impact the reliability and ethical use of LLMs in healthcare. This paper highlights ongoing efforts and offers insights into future research directions to ensure the safe and trustworthy deployment of LLMs in healthcare.', 'abstract_zh': '大型语言模型在医疗领域中的应用有可能革新临床决策、医学研究和患者护理。随着大型语言模型逐渐整合进医疗系统，必须解决若干关键挑战以确保其可靠和负责任的部署。这些挑战包括真实性（模型生成误导性信息）、隐私（无意数据保留的风险）、稳健性（对抗攻击的防御需求）、公平性（临床结果中的偏见）、可解释性（透明决策机制的保障）和安全性（减少错误信息和医疗错误的风险）。最近，研究人员已经开始开发基准和评估框架，以系统地评估大型语言模型的可信度。然而，医疗领域中大型语言模型的可信度仍然缺乏系统性的研究，未能提供一个全面的理解和未来潜在的发展方向。本文通过提供对现有方法和解决方案的全面概述，填补了这一空白，关注了医疗领域中真实性、隐私和安全性、稳健性、公平性和偏见、以及可解释性等关键信任维度，全面分析了这些问题如何影响大型语言模型在医疗领域的可靠性和道德应用。本文突显了现有的努力，并为确保大型语言模型在医疗领域的安全和可信部署提供了未来研究方向的见解。', 'title_zh': '大型语言模型在医疗健康领域的可信性综述'}
{'arxiv_id': 'arXiv:2502.15870', 'title': 'Making Sense of AI Limitations: How Individual Perceptions Shape Organizational Readiness for AI Adoption', 'authors': 'Thomas Übellacker', 'link': 'https://arxiv.org/abs/2502.15870', 'abstract': "This study investigates how individuals' perceptions of artificial intelligence (AI) limitations influence organizational readiness for AI adoption. Through semi-structured interviews with seven AI implementation experts, analyzed using the Gioia methodology, the research reveals that organizational readiness emerges through dynamic interactions between individual sensemaking, social learning, and formal integration processes. The findings demonstrate that hands-on experience with AI limitations leads to more realistic expectations and increased trust, mainly when supported by peer networks and champion systems. Organizations that successfully translate these individual and collective insights into formal governance structures achieve more sustainable AI adoption. The study advances theory by showing how organizational readiness for AI adoption evolves through continuous cycles of individual understanding, social learning, and organizational adaptation. These insights suggest that organizations should approach AI adoption not as a one-time implementation but as an ongoing strategic learning process that balances innovation with practical constraints. The research contributes to organizational readiness theory and practice by illuminating how micro-level perceptions and experiences shape macro-level adoption outcomes.", 'abstract_zh': '本研究探讨了个体对人工智能（AI）限制感知如何影响组织的AI采纳准备度。通过对七名AI实施专家进行半结构化访谈并采用Gioia方法进行分析，研究发现组织的准备度是通过个体意义构建、社会学习以及正式整合过程的动态交互而形成的。研究结果表明，与AI限制的直接互动促进了更现实的期望和信任，尤其是在 peer 网络和倡导系统支持下。成功将这些个体与集体洞见转化为正式治理结构的组织实现了更可持续的AI采纳。研究通过表明组织的AI采纳准备度如何通过持续的个体理解、社会学习和组织适应循环而演变，来推进理论。研究揭示了微观层面的感知和经历如何影响宏观层面的采纳结果，从而为组织准备度理论与实践做出了贡献。', 'title_zh': '理解AI局限性：个体感知如何影响组织AI采用的准备度'}
{'arxiv_id': 'arXiv:2502.15869', 'title': 'Generative AI Framework for 3D Object Generation in Augmented Reality', 'authors': 'Majid Behravan', 'link': 'https://arxiv.org/abs/2502.15869', 'abstract': 'This thesis presents a framework that integrates state-of-the-art generative AI models for real-time creation of three-dimensional (3D) objects in augmented reality (AR) environments. The primary goal is to convert diverse inputs, such as images and speech, into accurate 3D models, enhancing user interaction and immersion. Key components include advanced object detection algorithms, user-friendly interaction techniques, and robust AI models like Shap-E for 3D generation. Leveraging Vision Language Models (VLMs) and Large Language Models (LLMs), the system captures spatial details from images and processes textual information to generate comprehensive 3D objects, seamlessly integrating virtual objects into real-world environments. The framework demonstrates applications across industries such as gaming, education, retail, and interior design. It allows players to create personalized in-game assets, customers to see products in their environments before purchase, and designers to convert real-world objects into 3D models for real-time visualization. A significant contribution is democratizing 3D model creation, making advanced AI tools accessible to a broader audience, fostering creativity and innovation. The framework addresses challenges like handling multilingual inputs, diverse visual data, and complex environments, improving object detection and model generation accuracy, as well as loading 3D models in AR space in real-time. In conclusion, this thesis integrates generative AI and AR for efficient 3D model generation, enhancing accessibility and paving the way for innovative applications and improved user interactions in AR environments.', 'abstract_zh': '一种将前沿生成式AI模型集成以实现实时生成增强现实环境中三维对象的框架：多模态输入到精确三维模型的转换与应用', 'title_zh': '三维对象生成的生成AI框架在增强现实中的应用'}
{'arxiv_id': 'arXiv:2502.15867', 'title': 'Strategic priorities for transformative progress in advancing biology with proteomics and artificial intelligence', 'authors': 'Yingying Sun, Jun A, Zhiwei Liu, Rui Sun, Liujia Qian, Samuel H. Payne, Wout Bittremieux, Markus Ralser, Chen Li, Yi Chen, Zhen Dong, Yasset Perez-Riverol, Asif Khan, Chris Sander, Ruedi Aebersold, Juan Antonio Vizcaíno, Jonathan R Krieger, Jianhua Yao, Han Wen, Linfeng Zhang, Yunping Zhu, Yue Xuan, Benjamin Boyang Sun, Liang Qiao, Henning Hermjakob, Haixu Tang, Huanhuan Gao, Yamin Deng, Qing Zhong, Cheng Chang, Nuno Bandeira, Ming Li, Weinan E, Siqi Sun, Yuedong Yang, Gilbert S. Omenn, Yue Zhang, Ping Xu, Yan Fu, Xiaowen Liu, Christopher M. Overall, Yu Wang, Eric W. Deutsch, Luonan Chen, Jürgen Cox, Vadim Demichev, Fuchu He, Jiaxing Huang, Huilin Jin, Chao Liu, Nan Li, Zhongzhi Luan, Jiangning Song, Kaicheng Yu, Wanggen Wan, Tai Wang, Kang Zhang, Le Zhang, Peter A. Bell, Matthias Mann, Bing Zhang, Tiannan Guo', 'link': 'https://arxiv.org/abs/2502.15867', 'abstract': 'Artificial intelligence (AI) is transforming scientific research, including proteomics. Advances in mass spectrometry (MS)-based proteomics data quality, diversity, and scale, combined with groundbreaking AI techniques, are unlocking new challenges and opportunities in biological discovery. Here, we highlight key areas where AI is driving innovation, from data analysis to new biological insights. These include developing an AI-friendly ecosystem for proteomics data generation, sharing, and analysis; improving peptide and protein identification and quantification; characterizing protein-protein interactions and protein complexes; advancing spatial and perturbation proteomics; integrating multi-omics data; and ultimately enabling AI-empowered virtual cells.', 'abstract_zh': '人工智能（AI）正在transforming科学研究所涵盖的蛋白质组学。基于质谱（MS）的蛋白质组学数据质量、多样性和规模的进步，结合突破性的AI技术，正在开启生物发现中的新挑战和机遇。在这里，我们强调AI推动创新的关键领域，从数据处理到新的生物学见解。这些领域包括建立AI友好的蛋白质组学数据生成、共享和分析生态系统；改进肽和蛋白质的识别和定量；表征蛋白质相互作用和蛋白质复合物；促进空间蛋白质组学和扰动蛋白质组学的发展；整合多组学数据；最终实现AI赋能的虚拟细胞。', 'title_zh': 'proteomics和人工智能推动生物学变革的战略优先事项'}
{'arxiv_id': 'arXiv:2502.15865', 'title': 'Position: Standard Benchmarks Fail -- LLM Agents Present Overlooked Risks for Financial Applications', 'authors': 'Zichen Chen, Jiaao Chen, Jianda Chen, Misha Sra', 'link': 'https://arxiv.org/abs/2502.15865', 'abstract': 'Current financial LLM agent benchmarks are inadequate. They prioritize task performance while ignoring fundamental safety risks. Threats like hallucinations, temporal misalignment, and adversarial vulnerabilities pose systemic risks in high-stakes financial environments, yet existing evaluation frameworks fail to capture these risks. We take a firm position: traditional benchmarks are insufficient to ensure the reliability of LLM agents in finance. To address this, we analyze existing financial LLM agent benchmarks, finding safety gaps and introducing ten risk-aware evaluation metrics. Through an empirical evaluation of both API-based and open-weight LLM agents, we reveal hidden vulnerabilities that remain undetected by conventional assessments. To move the field forward, we propose the Safety-Aware Evaluation Agent (SAEA), grounded in a three-level evaluation framework that assesses agents at the model level (intrinsic capabilities), workflow level (multi-step process reliability), and system level (integration robustness). Our findings highlight the urgent need to redefine LLM agent evaluation standards by shifting the focus from raw performance to safety, robustness, and real world resilience.', 'abstract_zh': '当前的金融大语言模型代理基准不足。它们侧重于任务性能，而忽视了基本的安全风险。像幻觉、时间错位和对抗性漏洞这样的威胁在高风险金融环境中可能引发系统性风险，但现有的评估框架未能捕捉这些风险。我们认为：传统的基准不足以确保金融大语言模型代理的可靠性。为解决这一问题，我们分析了现有的金融大语言模型代理基准，发现了安全漏洞，并引入了十个风险意识评价指标。通过实证评估基于API和开放权重的大语言模型代理，我们揭示了常规评估难以发现的潜在脆弱性。为了推动该领域的发展，我们提出了安全意识评价代理（SAEA），基于一个三层评估框架，分别从模型层面（内在能力）、工作流程层面（多步过程可靠性）和系统层面（整合鲁棒性）进行评估。我们的研究强调了重新界定大语言模型代理评价标准的紧迫性，即从单纯的性能转向关注安全、稳健性和现实世界的韧性。', 'title_zh': '位置：标准基准失效——大型语言模型代理在金融应用中隐藏风险'}
{'arxiv_id': 'arXiv:2502.15860', 'title': 'Synthetic vs. Gold: The Role of LLM-Generated Labels and Data in Cyberbullying Detection', 'authors': 'Arefeh Kazemi, Sri Balaaji Natarajan Kalaivendan, Joachim Wagner, Hamza Qadeer, Brian Davis', 'link': 'https://arxiv.org/abs/2502.15860', 'abstract': 'This study investigates the role of LLM-generated synthetic data in cyberbullying detection. We conduct a series of experiments where we replace some or all of the authentic data with synthetic data, or augment the authentic data with synthetic data. We find that synthetic cyberbullying data can be the basis for training a classifier for harm detection that reaches performance close to that of a classifier trained with authentic data. Combining authentic with synthetic data shows improvements over the baseline of training on authentic data alone for the test data for all three LLMs tried. These results highlight the viability of synthetic data as a scalable, ethically viable alternative in cyberbullying detection while emphasizing the critical impact of LLM selection on performance outcomes.', 'abstract_zh': '本研究探讨了生成式语言模型（LLM）合成数据在 cyberbullying 检测中的作用。我们进行了一系列实验，其中部分或全部真实数据被合成数据替换，或者将合成数据用于增强真实数据。我们发现，合成 cyberbullying 数据可以作为训练用于伤害检测分类器的基础，其性能接近于使用真实数据训练的分类器。将真实数据与合成数据结合使用，在为三个尝试的 LLM 的测试数据训练时，表现出优于仅使用真实数据基线的效果。这些结果强调了合成数据在 cyberbullying 检测中作为可扩展且伦理上可行的替代方案的可行性，并突出了 LLM 选择对性能结果的关键影响。', 'title_zh': '合成数据 vs. 真实数据：LLM生成的标签和数据在检测网络欺凌中的作用'}
{'arxiv_id': 'arXiv:2502.15859', 'title': 'AI Governance InternationaL Evaluation Index (AGILE Index)', 'authors': 'Yi Zeng, Enmeng Lu, Xin Guan, Cunqing Huangfu, Zizhe Ruan, Ammar Younas', 'link': 'https://arxiv.org/abs/2502.15859', 'abstract': 'The rapid advancement of Artificial Intelligence (AI) technology is profoundly transforming human society and concurrently presenting a series of ethical, legal, and social issues. The effective governance of AI has become a crucial global concern. Since 2022, the extensive deployment of generative AI, particularly large language models, marked a new phase in AI governance. Continuous efforts are being made by the international community in actively addressing the novel challenges posed by these AI developments. As consensus on international governance continues to be established and put into action, the practical importance of conducting a global assessment of the state of AI governance is progressively coming to light. In this context, we initiated the development of the AI Governance InternationaL Evaluation Index (AGILE Index). Adhering to the design principle, "the level of governance should match the level of development," the inaugural evaluation of the AGILE Index commences with an exploration of four foundational pillars: the development level of AI, the AI governance environment, the AI governance instruments, and the AI governance effectiveness. It covers 39 indicators across 18 dimensions to comprehensively assess the AI governance level of 14 representative countries globally. The index is utilized to delve into the status of AI governance to date in 14 countries for the first batch of evaluation. The aim is to depict the current state of AI governance in these countries through data scoring, assist them in identifying their governance stage and uncovering governance issues, and ultimately offer insights for the enhancement of their AI governance systems.', 'abstract_zh': '人工智能治理国际评估指数（AGILE指数）：探究四大理支柱', 'title_zh': 'AI治理国际评估指数（AGILE指数）'}
{'arxiv_id': 'arXiv:2502.15858', 'title': 'Generative AI Training and Copyright Law', 'authors': 'Tim W. Dornis, Sebastian Stober', 'link': 'https://arxiv.org/abs/2502.15858', 'abstract': 'Training generative AI models requires extensive amounts of data. A common practice is to collect such data through web scraping. Yet, much of what has been and is collected is copyright protected. Its use may be copyright infringement. In the USA, AI developers rely on "fair use" and in Europe, the prevailing view is that the exception for "Text and Data Mining" (TDM) applies. In a recent interdisciplinary tandem-study, we have argued in detail that this is actually not the case because generative AI training fundamentally differs from TDM. In this article, we share our main findings and the implications for both public and corporate research on generative models. We further discuss how the phenomenon of training data memorization leads to copyright issues independently from the "fair use" and TDM exceptions. Finally, we outline how the ISMIR could contribute to the ongoing discussion about fair practices with respect to generative AI that satisfy all stakeholders.', 'abstract_zh': '训练生成AI模型需要大量数据。通常通过网络抓取收集这些数据，但其中大部分受到版权保护，使用这些数据可能构成版权侵权。在美国，AI开发者依赖“合理使用”原则；而在欧洲，普遍认为“文本和数据挖掘”（TDM）的例外适用。在一项最近的跨学科联合研究中，我们详细论述了这并不是实际情况，因为生成AI训练本质上不同于TDM。在这篇文章中，我们分享了主要发现及其对公共和企业研究生成模型的影响。我们进一步探讨了训练数据记忆现象如何独立于“合理使用”和TDM例外引发版权问题。最后，我们概述了ISMIR如何为关于生成AI公平实践的讨论做出贡献，这些实践能够满足所有利益相关方的需求。', 'title_zh': '生成式AI培训与版权法'}
{'arxiv_id': 'arXiv:2502.15857', 'title': 'PPC-GPT: Federated Task-Specific Compression of Large Language Models via Pruning and Chain-of-Thought Distillation', 'authors': 'Tao Fan, Guoqiang Ma, Yuanfeng Song, Lixin Fan, Kai Chen, Qiang Yang', 'link': 'https://arxiv.org/abs/2502.15857', 'abstract': "Compressing Large Language Models (LLMs) into task-specific Small Language Models (SLMs) encounters two significant challenges: safeguarding domain-specific knowledge privacy and managing limited resources. To tackle these challenges, we propose PPC-GPT, a innovative privacy-preserving federated framework specifically designed for compressing LLMs into task-specific SLMs via pruning and Chain-of-Thought (COT) distillation. PPC-GPT works on a server-client federated architecture, where the client sends differentially private (DP) perturbed task-specific data to the server's LLM. The LLM then generates synthetic data along with their corresponding rationales. This synthetic data is subsequently used for both LLM pruning and retraining processes. Additionally, we harness COT knowledge distillation, leveraging the synthetic data to further improve the retraining of structurally-pruned SLMs. Our experimental results demonstrate the effectiveness of PPC-GPT across various text generation tasks. By compressing LLMs into task-specific SLMs, PPC-GPT not only achieves competitive performance but also prioritizes data privacy protection.", 'abstract_zh': '将大型语言模型（LLMs）压缩成任务特定的小型语言模型（SLMs）面临的两大挑战是保护领域特定知识的隐私和管理有限的资源。为了应对这些挑战，我们提出了一种名为PPC-GPT的创新隐私保护联邦框架，该框架专门设计用于通过剪枝和思维链（COT） distilled知识精炼将LLMs压缩成任务特定的SLMs。PPC-GPT基于服务器-客户端联邦架构，客户端向服务器的LLM发送差分隐私（DP）扰动的任务特定数据。LLM随后生成合成数据及其相应的推理过程。这些合成数据随后用于LLM剪枝和重新训练过程。此外，我们利用思维链（COT）知识精炼，通过合成数据进一步提高结构剪枝的SLMs的重新训练。实验结果表明，PPC-GPT在各种文本生成任务中具有有效性。通过将LLMs压缩成任务特定的SLMs，PPC-GPT不仅实现了竞争性的性能，还优先考虑了数据隐私保护。', 'title_zh': 'PPC-GPT：联邦制任务特定大型语言模型压缩通过剪枝和链式思考精炼'}
{'arxiv_id': 'arXiv:2502.15856', 'title': "A Critical Assessment of Modern Generative Models' Ability to Replicate Artistic Styles", 'authors': 'Andrea Asperti, Franky George, Tiberio Marras, Razvan Ciprian Stricescu, Fabio Zanotti', 'link': 'https://arxiv.org/abs/2502.15856', 'abstract': 'In recent years, advancements in generative artificial intelligence have led to the development of sophisticated tools capable of mimicking diverse artistic styles, opening new possibilities for digital creativity and artistic expression. This paper presents a critical assessment of the style replication capabilities of contemporary generative models, evaluating their strengths and limitations across multiple dimensions. We examine how effectively these models reproduce traditional artistic styles while maintaining structural integrity and compositional balance in the generated images.\nThe analysis is based on a new large dataset of AI-generated works imitating artistic styles of the past, holding potential for a wide range of applications: the "AI-pastiche" dataset.\nThe study is supported by extensive user surveys, collecting diverse opinions on the dataset and investigation both technical and aesthetic challenges, including the ability to generate outputs that are realistic and visually convincing, the versatility of models in handling a wide range of artistic styles, and the extent to which they adhere to the content and stylistic specifications outlined in prompts.\nThis paper aims to provide a comprehensive overview of the current state of generative tools in style replication, offering insights into their technical and artistic limitations, potential advancements in model design and training methodologies, and emerging opportunities for enhancing digital artistry, human-AI collaboration, and the broader creative landscape.', 'abstract_zh': '近年来，生成式人工智能的发展推动了模仿多样艺术风格的复杂工具的出现，为数字创作和艺术表达开辟了新可能性。本文对当代生成模型的风格复制能力进行了批判性评估，从多个维度考察其强点和局限性。我们探讨了这些模型在生成图像中如何有效再现传统艺术风格，同时保持结构完整性和构图平衡。\n\n分析基于一个新的大规模人工智能生成作品数据集，模仿过去的艺术风格，具有广泛的应用潜力：“AI-再演绎”数据集。\n\n研究还依托广泛的用户调查，收集对数据集的多样化意见，探讨技术与美学挑战，包括生成逼真且视觉上令人信服的输出能力，模型在处理广泛艺术风格方面的灵活性，以及它们在提示中规定的主题和风格规范上的遵从性。\n\n本文旨在提供当前生成工具在风格复制方面全面概览，探讨其技术和艺术局限性，潜在的模型设计和训练方法进步，以及增强数字艺术创作、人机协作和更广泛创意领域的新机会。', 'title_zh': '现代生成模型复制艺术风格的能力批判性评估'}
{'arxiv_id': 'arXiv:2502.15855', 'title': 'Non-Linear Flow Matching for Full-Atom Peptide Design', 'authors': 'Dengdeng Huang, Shikui Tu', 'link': 'https://arxiv.org/abs/2502.15855', 'abstract': "Peptide design plays a pivotal role in therapeutic applications, yet existing AI-assisted methods often struggle to generate stable peptides with high affinity due to their inability to accurately simulate the dynamic docking process. To address this challenge, we propose NLFlow, a novel multi-manifold approach based on non-linear flow matching. Specifically, we design a polynomial-based conditional vector field to accelerate the convergence of the peptide's position towards the target pocket, effectively capturing the temporal inconsistencies across position, rotation, torsion, and amino acid type manifolds. This enables the model to better align with the true conformational changes observed in biological docking processes. Additionally, we incorporate interaction-related information, such as polarity, to enhance the understanding of peptide-protein binding. Extensive experiments demonstrate that NLFlow outperforms existing methods in generating peptides with superior stability, affinity, and diversity, offering a fast and efficient solution for peptide design and advancing the peptide-based therapeutic development.", 'abstract_zh': '肽设计在治疗应用中发挥着关键作用，但现有的AI辅助方法 often 因难以准确模拟动态结合过程而往往难以生成具有高亲和力的稳定肽。为解决这一挑战，我们提出了一种基于非线性流匹配的新型多流形方法NLFlow。具体来说，我们设计了一种基于多项式的条件向量场以加速肽的位置向目标口袋的收敛，有效地捕捉了位置、旋转、扭折和氨基酸类型流形上的时间不一致性。这使得模型能够更好地与生物结合过程中观察到的真实构象变化对齐。此外，我们还整合了与相互作用相关的信息，如极性，以增强对肽-蛋白结合的理解。大量的实验表明，NLFlow 在生成具有更优稳定性和亲和力、更高多样性的肽方面优于现有方法，为肽设计提供了一种快速高效的解决方案，推动基于肽的治疗发展。', 'title_zh': '非线性流匹配用于全原子肽设计'}
{'arxiv_id': 'arXiv:2502.15854', 'title': 'Enhancing Domain-Specific Retrieval-Augmented Generation: Synthetic Data Generation and Evaluation using Reasoning Models', 'authors': 'Aryan Jadon, Avinash Patil, Shashank Kumar', 'link': 'https://arxiv.org/abs/2502.15854', 'abstract': 'Retrieval-Augmented Generation (RAG) systems face significant performance gaps when applied to technical domains requiring precise information extraction from complex documents. Current evaluation methodologies relying on document-level metrics inadequately capture token-resolution retrieval accuracy that is critical for domain-related documents. We propose a framework combining granular evaluation metrics with synthetic data generation to optimize domain-specific RAG performance. First, we introduce token-aware metrics Precision $\\Omega$ and Intersection-over-Union (IoU) that quantify context preservation versus information density trade-offs inherent in technical texts. Second, we develop a reasoning model-driven pipeline using instruction-tuned LLMs (DeepSeek-R1, DeepSeek-R1 distilled variants, and Phi-4) to generate context-anchored QA pairs with discontinuous reference spans across three specialized corpora: SEC 10-K filings (finance), biomedical abstracts (PubMed), and APT threat reports (cybersecurity).\nOur empirical analysis reveals critical insights: smaller chunks (less than 10 tokens) improve precision by 31-42% (IoU = 0.071 vs. baseline 0.053) at recall costs (-18%), while domain-specific embedding strategies yield 22% variance in optimal chunk sizing (5-20 tokens). The DeepSeek-R1-Distill-Qwen-32B model demonstrates superior concept alignment (+14% mean IoU over alternatives), though no configuration universally dominates. Financial texts favor larger chunks for risk factor coverage (Recall = 0.81 at size = 20), whereas cybersecurity content benefits from atomic segmentation, Precision $\\Omega = 0.28$ at size = 5.\nOur code is available on this https URL', 'abstract_zh': 'Retrieval-Augmented Generation (RAG) 系统在应用于要求从复杂文档中精确提取信息的技术领域时面临显著的性能差距。当前依赖文档级指标的评估方法未能充分捕捉到对领域相关文档至关重要的标记级检索准确性。我们提出了一种结合粒度评估指标和合成数据生成框架，以优化特定领域RAG性能。首先，我们引入了具有标记感知能力的Precision Ω和交并比（IoU）度量，量化技术文本中上下文保存与信息密度之间的权衡。其次，我们开发了一种以推理模型为驱动的流水线，使用指令微调的大语言模型（DeepSeek-R1、DeepSeek-R1精简变体和Phi-4）生成上下文锚定的问答对，并跨越三个专门的语料库：SEC 10-K 提交文件（金融）、PubMed 生物医学摘要（生物医学）和APT 威胁报告（网络安全）。', 'title_zh': '增强领域特定检索增强生成：基于推理模型的合成数据生成与评估'}
{'arxiv_id': 'arXiv:2502.15851', 'title': 'Control Illusion: The Failure of Instruction Hierarchies in Large Language Models', 'authors': 'Yilin Geng, Haonan Li, Honglin Mu, Xudong Han, Timothy Baldwin, Omri Abend, Eduard Hovy, Lea Frermann', 'link': 'https://arxiv.org/abs/2502.15851', 'abstract': 'Large language models (LLMs) are increasingly deployed with hierarchical instruction schemes, where certain instructions (e.g., system-level directives) are expected to take precedence over others (e.g., user messages). Yet, we lack a systematic understanding of how effectively these hierarchical control mechanisms work. We introduce a systematic evaluation framework based on constraint prioritization to assess how well LLMs enforce instruction hierarchies. Our experiments across six state-of-the-art LLMs reveal that models struggle with consistent instruction prioritization, even for simple formatting conflicts. We find that the widely-adopted system/user prompt separation fails to establish a reliable instruction hierarchy, and models exhibit strong inherent biases toward certain constraint types regardless of their priority designation. While controlled prompt engineering and model fine-tuning show modest improvements, our results indicate that instruction hierarchy enforcement is not robustly realized, calling for deeper architectural innovations beyond surface-level modifications.', 'abstract_zh': '大型语言模型（LLMs） increasingly deploy hierarchical instruction schemes, where certain instructions (e.g., system-level directives) are expected to take precedence over others (e.g., user messages). Yet, we lack a systematic understanding of how effectively these hierarchical control mechanisms work. We introduce a systematic evaluation framework based on constraint prioritization to assess how well LLMs enforce instruction hierarchies. Our experiments across six state-of-the-art LLMs reveal that models struggle with consistent instruction prioritization, even for simple formatting conflicts. We find that the widely-adopted system/user prompt separation fails to establish a reliable instruction hierarchy, and models exhibit strong inherent biases toward certain constraint types regardless of their priority designation. While controlled prompt engineering and model fine-tuning show modest improvements, our results indicate that instruction hierarchy enforcement is not robustly realized, calling for deeper architectural innovations beyond surface-level modifications。', 'title_zh': '控制幻象：大型语言模型中指令层级结构的失效'}
{'arxiv_id': 'arXiv:2502.15850', 'title': 'Forecasting Frontier Language Model Agent Capabilities', 'authors': 'Govind Pimpale, Axel Højmark, Jérémy Scheurer, Marius Hobbhahn', 'link': 'https://arxiv.org/abs/2502.15850', 'abstract': 'As Language Models (LMs) increasingly operate as autonomous agents, accurately forecasting their capabilities becomes crucial for societal preparedness. We evaluate six forecasting methods that predict downstream capabilities of LM agents. We use "one-step" approaches that predict benchmark scores from input metrics like compute or model release date directly or "two-step" approaches that first predict an intermediate metric like the principal component of cross-benchmark performance (PC-1) and human-evaluated competitive Elo ratings. We evaluate our forecasting methods by backtesting them on a dataset of 38 LMs from the OpenLLM 2 leaderboard. We then use the validated two-step approach (Release Date$\\to$Elo$\\to$Benchmark) to predict LM agent performance for frontier models on three benchmarks: SWE-Bench Verified (software development), Cybench (cybersecurity assessment), and RE-Bench (ML research engineering). Our forecast predicts that by the beginning of 2026, non-specialized LM agents with low capability elicitation will reach a success rate of 54% on SWE-Bench Verified, while state-of-the-art LM agents will reach an 87% success rate. Our approach does not account for recent advances in inference-compute scaling and might thus be too conservative.', 'abstract_zh': '语言模型（LMs）作为自主代理越来越广泛地运行时，准确预测其能力对于社会准备变得至关重要。我们评估了六种预测LM代理下游能力的方法。我们使用“一步法”直接从计算量或模型发布日期等输入度量预测基准得分，或使用“两步法”首先预测跨基准性能的主要成分（PC-1）和人工评估的竞争Elo评级作为中间度量。我们通过在来自OpenLLM 2排行榜的38个LM数据集上回测我们的预测方法来评估这些方法。然后，我们使用经过验证的两步法（发布日期→Elo→基准）预测前沿模型在三个基准上的LM代理性能：SWE-Bench Verified（软件开发）、Cybench（网络安全部署评估）和RE-Bench（机器学习研究工程）。我们的预测表明，到2026年初，低能力激发的非专业化LM代理将在SWE-Bench Verified上达到54%的成功率，而最先进的LM代理将达到87%的成功率。我们的方法未考虑最近的推理-计算扩展进展，因此可能过于保守。', 'title_zh': '前沿语言模型代理能力预测'}
{'arxiv_id': 'arXiv:2502.15849', 'title': 'Deriving Representative Structure from Music Corpora', 'authors': 'Ilana Shapiro, Ruanqianqian, Huang, Zachary Novack, Cheng-i Wang, Hao-Wen Dong, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Sorin Lerner', 'link': 'https://arxiv.org/abs/2502.15849', 'abstract': 'Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a dually NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.', 'abstract_zh': '西方音乐是一种固有的层级系统，从细微的旋律结构到高层的形式结构。为了全面多粒度地分析音乐作品，我们提出了一种统一的层级元表示方法，称为结构时间图（STG）。对于单个音乐作品，STG定义了一种结构音乐特征的层级体系及其相互间的时间关系。我们使用STG来实现一种新型的方法，以提取音乐作品集合的代表性结构摘要，我们将这一问题形式化为一个扩展的广义中位图问题的双重NP难组合优化问题。我们的方法首先应用模拟退火来开发基于图同构的结构距离度量。然后，我们的方法将SMT求解器的形式保证与嵌套的模拟退火应用于结构距离相结合，生成整个STG集合的结构上一致的代表性质心STG。为了评估我们的方法，我们进行了实验，验证了结构距离能准确地区分音乐作品，并且提取出的质心能准确地结构化表征其集合。', 'title_zh': '从音乐语料库中提取代表性结构'}
{'arxiv_id': 'arXiv:2502.15845', 'title': 'Verify when Uncertain: Beyond Self-Consistency in Black Box Hallucination Detection', 'authors': 'Yihao Xue, Kristjan Greenewald, Youssef Mroueh, Baharan Mirzasoleiman', 'link': 'https://arxiv.org/abs/2502.15845', 'abstract': 'Large Language Models (LLMs) suffer from hallucination problems, which hinder their reliability in sensitive applications. In the black-box setting, several self-consistency-based techniques have been proposed for hallucination detection. We empirically study these techniques and show that they achieve performance close to that of a supervised (still black-box) oracle, suggesting little room for improvement within this paradigm. To address this limitation, we explore cross-model consistency checking between the target model and an additional verifier LLM. With this extra information, we observe improved oracle performance compared to purely self-consistency-based methods. We then propose a budget-friendly, two-stage detection algorithm that calls the verifier model only for a subset of cases. It dynamically switches between self-consistency and cross-consistency based on an uncertainty interval of the self-consistency classifier. We provide a geometric interpretation of consistency-based hallucination detection methods through the lens of kernel mean embeddings, offering deeper theoretical insights. Extensive experiments show that this approach maintains high detection performance while significantly reducing computational cost.', 'abstract_zh': '大型语言模型（LLMs）面临幻觉问题，这妨碍了它们在敏感应用中的可靠性。在黑盒设置中，已经提出了一些基于自一致性的方法用于检测幻觉。我们通过实证研究这些方法，并表明它们的性能接近监督（仍为黑盒） oracle 的性能，这表明在这个范式中几乎没有改进的空间。为了解决这一局限性，我们探讨了目标模型与附加的验证器LLM之间的一致性检查。借助这种额外信息，我们观察到与纯自一致性方法相比，Oracle的性能有所提高。然后，我们提出了一种预算友好的两阶段检测算法，仅在一部分情况下调用验证器模型。该算法根据自一致性分类器的不确定性区间动态切换自一致性与交叉一致性。我们通过核均值嵌入的视角提供了一致性基幻觉检测方法的几何解释，提供了更深入的理论洞察。大量的实验表明，这种方法在保持高检测性能的同时显著降低了计算成本。', 'title_zh': '在不确定时验证：超越黑盒 hallucination 检测的自我一致性'}
{'arxiv_id': 'arXiv:2502.15839', 'title': 'FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning with Incomplete Modalities', 'authors': 'Yi Liu, Cong Wang, Xingliang Yuan', 'link': 'https://arxiv.org/abs/2502.15839', 'abstract': "The Web of Things (WoT) enhances interoperability across web-based and ubiquitous computing platforms while complementing existing IoT standards. The multimodal Federated Learning (FL) paradigm has been introduced to enhance WoT by enabling the fusion of multi-source mobile sensing data while preserving privacy. However, a key challenge in mobile sensing systems using multimodal FL is modality incompleteness, where some modalities may be unavailable or only partially captured, potentially degrading the system's performance and reliability. Current multimodal FL frameworks typically train multiple unimodal FL subsystems or apply interpolation techniques on the node side to approximate missing modalities. However, these approaches overlook the shared latent feature space among incomplete modalities across different nodes and fail to discriminate against low-quality nodes. To address this gap, we present FedMobile, a new knowledge contribution-aware multimodal FL framework designed for robust learning despite missing modalities. FedMobile prioritizes local-to-global knowledge transfer, leveraging cross-node multimodal feature information to reconstruct missing features. It also enhances system performance and resilience to modality heterogeneity through rigorous node contribution assessments and knowledge contribution-aware aggregation rules. Empirical evaluations on five widely recognized multimodal benchmark datasets demonstrate that FedMobile maintains robust learning even when up to 90% of modality information is missing or when data from two modalities are randomly missing, outperforming state-of-the-art baselines.", 'abstract_zh': '物联网网络（WoT）增强了基于网络和泛在计算平台之间的互操作性，同时补充了现有的物联网标准。引入了多模态联邦学习（FL）范式，通过融合多源移动传感数据同时保持隐私来增强WoT。然而，在使用多模态FL的移动传感系统中，一个关键挑战是模态不完备性，即某些模态可能不可用或仅部分捕获，这可能会降低系统的性能和可靠性。当前的多模态FL框架通常训练多个单模态FL子系统或在节点侧应用插值技术来近似缺失的模态。然而，这些方法忽略了不同节点之间不完备模态之间的共享潜在于特征空间，并未能区分低质量节点。为解决这一问题，我们提出了一种新的FedMobile框架，该框架能够在缺失模态的情况下实现稳健学习，并优先考虑本地到全局的知识转移，利用跨节点的多模态特征信息来重建缺失特征。FedMobile还通过严格的节点贡献评估和知识贡献知情聚合规则来增强系统的性能和对模态异质性的鲁棒性。在五个广泛认可的多模态基准数据集上的实证评估表明，即使在缺失高达90%的模态信息或随机缺失两种模态的数据时，FedMobile也能保持稳健学习，并且在性能上优于最先进的基线方法。', 'title_zh': 'FedMobile: 促进多模态联邦学习中的知识贡献意识框架在不完整模态下的应用'}
{'arxiv_id': 'arXiv:2502.15836', 'title': 'Soft Token Attacks Cannot Reliably Audit Unlearning in Large Language Models', 'authors': 'Haokun Chen, Sebastian Szyller, Weilin Xu, Nageen Himayat', 'link': 'https://arxiv.org/abs/2502.15836', 'abstract': 'Large language models (LLMs) have become increasingly popular. Their emergent capabilities can be attributed to their massive training datasets. However, these datasets often contain undesirable or inappropriate content, e.g., harmful texts, personal information, and copyrighted material. This has promoted research into machine unlearning that aims to remove information from trained models. In particular, approximate unlearning seeks to achieve information removal by strategically editing the model rather than complete model retraining.\nRecent work has shown that soft token attacks (STA) can successfully extract purportedly unlearned information from LLMs, thereby exposing limitations in current unlearning methodologies. In this work, we reveal that STAs are an inadequate tool for auditing unlearning. Through systematic evaluation on common unlearning benchmarks (Who Is Harry Potter? and TOFU), we demonstrate that such attacks can elicit any information from the LLM, regardless of (1) the deployed unlearning algorithm, and (2) whether the queried content was originally present in the training corpus. Furthermore, we show that STA with just a few soft tokens (1-10) can elicit random strings over 400-characters long. Thus showing that STAs are too powerful, and misrepresent the effectiveness of the unlearning methods.\nOur work highlights the need for better evaluation baselines, and more appropriate auditing tools for assessing the effectiveness of unlearning in LLMs.', 'abstract_zh': '大型语言模型（LLMs）日益受到关注。其涌现能力源于庞大的训练数据集。然而，这些数据集常包含不良或不合适的内容，如有害文本、个人信息和版权材料。这促进了针对机器遗忘的研究，旨在从训练模型中移除信息。特别是，近似的遗忘希望通过战略性地编辑模型而非完全重新训练来实现信息移除。\n\n现有研究表明，软标记攻击（STA）可以从LLMs中成功提取被认为已遗忘的信息，从而揭示当前遗忘方法的局限性。在本工作中，我们揭示了STA作为审计工具的不足。通过在常见的遗忘基准测试上进行系统评估（Harry Potter Who Is和TOFU），我们证明这些攻击可以从中提取任何信息，无论（1）所采用的遗忘算法如何，以及（2）查询的内容是否最初存在于训练语料库中。此外，我们展示了只需少量软标记（1-10个）的STA就可以提取长度超过400字符的随机字符串，从而表明STA过于强大，误导了对遗忘方法有效性的评估。\n\n我们的工作突显了需要更好的评估基准和更合适的审计工具，以评估LLMs中遗忘的有效性。', 'title_zh': '软令牌攻击不能可靠地审计大型语言模型的未学习状态'}
{'arxiv_id': 'arXiv:2502.15835', 'title': 'Pragmatic Reasoning improves LLM Code Generation', 'authors': 'Zhuchen Cao, Sven Apel, Adish Singla, Vera Demberg', 'link': 'https://arxiv.org/abs/2502.15835', 'abstract': "Large Language Models (LLMs) have demonstrated impressive potential in translating natural language (NL) instructions into program code. However, user instructions often contain inherent ambiguities, making it challenging for LLMs to generate code that accurately reflects the user's true intent. To address this challenge, researchers have proposed to produce multiple candidates of the program code and then rerank them to identify the best solution. In this paper, we propose CodeRSA, a novel code candidate reranking mechanism built upon the Rational Speech Act (RSA) framework, designed to guide LLMs toward more comprehensive pragmatic reasoning about user intent. We evaluate CodeRSA using one of the latest LLMs on a popular code generation dataset. Our experiment results show that CodeRSA consistently outperforms common baselines, surpasses the state-of-the-art approach in most cases, and demonstrates robust overall performance. These findings underscore the effectiveness of integrating pragmatic reasoning into code candidate reranking, offering a promising direction for enhancing code generation quality in LLMs.", 'abstract_zh': '大型语言模型（LLMs）展示了将自然语言（NL）指令转化为程序代码的惊人潜力。然而，用户指令往往含有固有的歧义性，这使得LLMs难以生成准确反映用户真实意图的代码。为解决这一挑战，研究人员提出了生成多个程序代码候选方案，然后重新排序以识别最佳方案的方法。在本文中，我们提出了一种基于理性言语行为（RSA）框架的新颖的代码候选重新排序机制CodeRSA，旨在引导LLMs进行更全面的关于用户意图的实用推理。我们使用最新的一种LLM在流行的数据集上评估CodeRSA。实验结果表明，CodeRSA始终优于常见的基线方法，在大多数情况下超越了最先进的方法，并且整体表现稳健。这些发现强调将实用推理整合到代码候选重新排序中的有效性，为提高LLMs代码生成质量提供了有前景的方向。', 'title_zh': '实用推理提升大模型代码生成能力'}
{'arxiv_id': 'arXiv:2502.15833', 'title': 'Advancing Out-of-Distribution Detection via Local Neuroplasticity', 'authors': 'Alessandro Canevaro, Julian Schmidt, Mohammad Sajad Marvi, Hang Yu, Georg Martius, Julian Jordan', 'link': 'https://arxiv.org/abs/2502.15833', 'abstract': 'In the domain of machine learning, the assumption that training and test data share the same distribution is often violated in real-world scenarios, requiring effective out-of-distribution (OOD) detection. This paper presents a novel OOD detection method that leverages the unique local neuroplasticity property of Kolmogorov-Arnold Networks (KANs). Unlike traditional multilayer perceptrons, KANs exhibit local plasticity, allowing them to preserve learned information while adapting to new tasks. Our method compares the activation patterns of a trained KAN against its untrained counterpart to detect OOD samples. We validate our approach on benchmarks from image and medical domains, demonstrating superior performance and robustness compared to state-of-the-art techniques. These results underscore the potential of KANs in enhancing the reliability of machine learning systems in diverse environments.', 'abstract_zh': '机器学习领域中的机器学习在现实场景中通常假设训练数据和测试数据共享相同的分布，这要求有效进行异常分布外（OOD）检测。本文提出了一种利用Kolmogorov-Arnold网络（KANs）的独特局部神经可塑性性质的新颖OOD检测方法。与传统的多层感知机不同，KANs表现出局部可塑性，使其能够在适应新任务的同时保留已学习的信息。我们的方法通过将训练后的KAN与未训练的版本的激活模式进行对比来检测OOD样本。我们通过来自图像和医疗领域的基准测试验证了该方法，展示了其在性能和鲁棒性方面优于现有技术。这些结果突显了KANs在提高不同环境中机器学习系统的可靠性方面的潜力。', 'title_zh': '基于局部神经可塑性的.out-of-distribution检测进步'}
{'arxiv_id': 'arXiv:2502.15830', 'title': 'Show Me Your Code! Kill Code Poisoning: A Lightweight Method Based on Code Naturalness', 'authors': 'Weisong Sun, Yuchen Chen, Mengzhe Yuan, Chunrong Fang, Zhenpeng Chen, Chong Wang, Yang Liu, Baowen Xu, Zhenyu Chen', 'link': 'https://arxiv.org/abs/2502.15830', 'abstract': 'Neural code models (NCMs) have demonstrated extraordinary capabilities in code intelligence tasks. Meanwhile, the security of NCMs and NCMs-based systems has garnered increasing attention. In particular, NCMs are often trained on large-scale data from potentially untrustworthy sources, providing attackers with the opportunity to manipulate them by inserting crafted samples into the data. This type of attack is called a code poisoning attack (also known as a backdoor attack). It allows attackers to implant backdoors in NCMs and thus control model behavior, which poses a significant security threat. However, there is still a lack of effective techniques for detecting various complex code poisoning attacks.\nIn this paper, we propose an innovative and lightweight technique for code poisoning detection named KillBadCode. KillBadCode is designed based on our insight that code poisoning disrupts the naturalness of code. Specifically, KillBadCode first builds a code language model (CodeLM) on a lightweight $n$-gram language model. Then, given poisoned data, KillBadCode utilizes CodeLM to identify those tokens in (poisoned) code snippets that will make the code snippets more natural after being deleted as trigger tokens. Considering that the removal of some normal tokens in a single sample might also enhance code naturalness, leading to a high false positive rate (FPR), we aggregate the cumulative improvement of each token across all samples. Finally, KillBadCode purifies the poisoned data by removing all poisoned samples containing the identified trigger tokens. The experimental results on two code poisoning attacks and four code intelligence tasks demonstrate that KillBadCode significantly outperforms four baselines. More importantly, KillBadCode is very efficient, with a minimum time consumption of only 5 minutes, and is 25 times faster than the best baseline on average.', 'abstract_zh': '基于代码自然度感知的杀毒代码检测方法：KillBadCode', 'title_zh': '展示你的代码！消除代码中毒：一种基于代码自然度的轻量级方法'}
{'arxiv_id': 'arXiv:2502.15828', 'title': 'A Stronger Mixture of Low-Rank Experts for Fine-Tuning Foundation Models', 'authors': 'Mengyang Sun, Yihao Wang, Tao Feng, Dan Zhang, Yifan Zhu, Jie Tang', 'link': 'https://arxiv.org/abs/2502.15828', 'abstract': 'In order to streamline the fine-tuning of foundation models, Low-Rank Adapters (LoRAs) have been substantially adopted across various fields, including instruction tuning and domain adaptation. The underlying concept of LoRA involves decomposing a full-rank matrix into the product of two lower-rank matrices, which reduces storage consumption and accelerates the training process. Furthermore, to address the limited expressive capacity of LoRA, the Mixture-of-Expert (MoE) has been introduced for incorporating multiple LoRA adapters. The integration of LoRA experts leads to a visible improvement across several downstream scenes. However, the mixture of LoRAs (MoE-LoRA) still exhibits its low robustness during tuning and inferring. Inspired by the Riemannian Preconditioners which train LoRA as a sub-space projector, we propose a new training strategy for MoE-LoRA, to stabilize and boost its feature learning procedure by multi-space projections. Examinations on SGD and AdamW optimizers demonstrate the effectiveness of our methodology. Source code is available at this https URL.', 'abstract_zh': '为了精简基础模型的微调过程，低秩适配器（LoRA）已在指令微调和领域适应等多个领域中广泛采用。LoRA 的基本概念涉及将一个满秩矩阵分解为两个低秩矩阵的乘积，从而减少存储消耗并加速训练过程。为进一步解决 LoRA 表达能力有限的问题，引入了专家混叠（MoE）机制，将多个 LoRA 适配器结合在一起。LoRA 专家的集成在多个下游场景中表现出显著改进。然而，LoRA 专家混叠（MoE-LoRA）在微调和推理过程中仍然表现出较低的鲁棒性。受黎曼预条件化训练 LoRA 作为子空间投影的启发，我们提出了一种新的 MoE-LoRA 训练策略，通过多空间投影稳定并提升其特征学习过程。对 SGD 和 AdamW 优化器的实验验证了该方法的有效性。相关源代码可在以下链接获取。', 'title_zh': '一种更强大的低秩专家混合模型用于基础模型微调'}
{'arxiv_id': 'arXiv:2502.15827', 'title': 'Explainable Artificial Intelligence Model for Evaluating Shear Strength Parameters of Municipal Solid Waste Across Diverse Compositional Profiles', 'authors': 'Parichat Suknark, Sompote Youwaib, Tipok Kitkobsin, Sirintornthep Towprayoon, Chart Chiemchaisri, Komsilp Wangyao', 'link': 'https://arxiv.org/abs/2502.15827', 'abstract': "Accurate prediction of shear strength parameters in Municipal Solid Waste (MSW) remains a critical challenge in geotechnical engineering due to the heterogeneous nature of waste materials and their temporal evolution through degradation processes. This paper presents a novel explainable artificial intelligence (XAI) framework for evaluating cohesion and friction angle across diverse MSW compositional profiles. The proposed model integrates a multi-layer perceptron architecture with SHAP (SHapley Additive exPlanations) analysis to provide transparent insights into how specific waste components influence strength characteristics. Training data encompassed large-scale direct shear tests across various waste compositions and degradation states. The model demonstrated superior predictive accuracy compared to traditional gradient boosting methods, achieving mean absolute percentage errors of 7.42% and 14.96% for friction angle and cohesion predictions, respectively. Through SHAP analysis, the study revealed that fibrous materials and particle size distribution were primary drivers of shear strength variation, with food waste and plastics showing significant but non-linear effects. The model's explainability component successfully quantified these relationships, enabling evidence-based recommendations for waste management practices. This research bridges the gap between advanced machine learning and geotechnical engineering practice, offering a reliable tool for rapid assessment of MSW mechanical properties while maintaining interpretability for engineering decision-making.", 'abstract_zh': '市政固体废物(MSW)剪切强度参数的准确预测仍然是土木工程中的一个关键挑战，由于废物材料的异质性和降解过程中的时间演化。本文提出了一个新颖的可解释人工智能(XAI)框架，用于评估不同MSW组分配置下的凝聚力和摩擦角。提出的模型结合了多层感知器架构与SHAP（SHapley Additive exPlanations）分析，以透明地揭示特定废物组分如何影响强度特性。训练数据涵盖不同废物组成和降解状态的大规模直接剪切试验。该模型在摩擦角和凝聚力预测方面的预测准确性均优于传统梯度提升方法，分别实现了7.42%和14.96%的平均绝对百分比误差。通过SHAP分析，研究发现纤维材料和颗粒大小分布是剪切强度变异的主要驱动因素，食物废物和塑料显示出显著但非线性的影响。模型的可解释性组件成功量化了这些关系，使基于证据的废物管理建议成为可能。该研究在先进机器学习与土木工程实践之间架起了桥梁，提供了一个可靠工具进行MSW力学性质的快速评估，同时保持了工程决策的可解释性。', 'title_zh': '解释性人工智能模型：评估不同组分特征下城市固体废物剪切强度参数'}
{'arxiv_id': 'arXiv:2502.15826', 'title': 'CoME: An Unlearning-based Approach to Conflict-free Model Editing', 'authors': 'Dahyun Jung, Jaehyung Seo, Jaewook Lee, Chanjun Park, Heuiseok Lim', 'link': 'https://arxiv.org/abs/2502.15826', 'abstract': "Large language models (LLMs) often retain outdated or incorrect information from pre-training, which undermines their reliability. While model editing methods have been developed to address such errors without full re-training, they frequently suffer from knowledge conflicts, where outdated information interferes with new knowledge. In this work, we propose Conflict-free Model Editing (CoME), a novel framework that enhances the accuracy of knowledge updates in LLMs by selectively removing outdated knowledge. CoME leverages unlearning to mitigate knowledge interference, allowing new information to be integrated without compromising relevant linguistic features. Through experiments on GPT-J and LLaMA-3 using Counterfact and ZsRE datasets, we demonstrate that CoME improves both editing accuracy and model reliability when applied to existing editing methods. Our results highlight that the targeted removal of outdated knowledge is crucial for enhancing model editing effectiveness and maintaining the model's generative performance.", 'abstract_zh': '大型语言模型中的冲突-free模型编辑（CoME）：通过选择性去除过时知识提高知识更新准确性并与保持语言特征兼容', 'title_zh': 'CoME：一种基于去学习的冲突-free模型编辑方法'}
{'arxiv_id': 'arXiv:2502.15825', 'title': 'Utilizing AI and Machine Learning for Predictive Analysis of Post-Treatment Cancer Recurrence', 'authors': 'Muhammad Umer Qayyum, Muhammad Fahad, Nasrullah Abbasi', 'link': 'https://arxiv.org/abs/2502.15825', 'abstract': "In oncology, recurrence after treatment is one of the major challenges, related to patients' survival and quality of life. Conventionally, prediction of cancer relapse has always relied on clinical observation with statistical model support, which almost fails to explain the complex, multifactorial nature of tumor recurrence. This research explores how AI and ML models may increase the accuracy and reliability of recurrence prediction in cancer. Therefore, AI and ML create new opportunities not only for personalized medicine but also for proactive management of patients through analyzing large volumes of data on genetics, clinical manifestations, and treatment. The paper describes the various AI and ML techniques for pattern identification and outcome prediction in cancer patients using supervised and unsupervised learning. Clinical implications provide an opportunity to review how early interventions could happen and the design of treatment planning.", 'abstract_zh': '在肿瘤学中，治疗后的复发是主要挑战之一，影响患者的生存率和生活质量。 conventionally, 预测癌症复发一直依赖于临床观察和统计模型的支持，几乎无法解释肿瘤复发的复杂性和多因素性。该研究探讨了人工智能和机器学习模型如何提高癌症复发预测的准确性和可靠性。因此，人工智能和机器学习不仅为个性化的医疗提供了新机会，也为通过分析遗传学、临床表现和治疗的大规模数据来进行积极的患者管理创造了新机会。该论文描述了使用监督和无监督学习在癌症患者中识别模式和预测结局的各种人工智能和机器学习技术。临床意义提供了审查早期干预如何发生以及治疗计划设计的机会。', 'title_zh': '利用人工智能和机器学习进行治疗后癌症复发的预测分析'}
{'arxiv_id': 'arXiv:2502.15824', 'title': 'Getting SMARTER for Motion Planning in Autonomous Driving Systems', 'authors': 'Montgomery Alban, Ehsan Ahmadi, Randy Goebel, Amir Rasouli', 'link': 'https://arxiv.org/abs/2502.15824', 'abstract': 'Motion planning is a fundamental problem in autonomous driving and perhaps the most challenging to comprehensively evaluate because of the associated risks and expenses of real-world deployment. Therefore, simulations play an important role in efficient development of planning algorithms. To be effective, simulations must be accurate and realistic, both in terms of dynamics and behavior modeling, and also highly customizable in order to accommodate a broad spectrum of research frameworks. In this paper, we introduce SMARTS 2.0, the second generation of our motion planning simulator which, in addition to being highly optimized for large-scale simulation, provides many new features, such as realistic map integration, vehicle-to-vehicle (V2V) communication, traffic and pedestrian simulation, and a broad variety of sensor models.\nMoreover, we present a novel benchmark suite for evaluating planning algorithms in various highly challenging scenarios, including interactive driving, such as turning at intersections, and adaptive driving, in which the task is to closely follow a lead vehicle without any explicit knowledge of its intention. Each scenario is characterized by a variety of traffic patterns and road structures. We further propose a series of common and task-specific metrics to effectively evaluate the performance of the planning algorithms. At the end, we evaluate common motion planning algorithms using the proposed benchmark and highlight the challenges the proposed scenarios impose. The new SMARTS 2.0 features and the benchmark are publicly available at this http URL.', 'abstract_zh': '智能驾驶运动规划仿真器SMARTS 2.0及其应用场景评估基准', 'title_zh': '为自主驾驶系统中的运动规划变聪明'}
{'arxiv_id': 'arXiv:2502.15823', 'title': 'InductionBench: LLMs Fail in the Simplest Complexity Class', 'authors': 'Wenyue Hua, Tyler Wong, Sun Fei, Liangming Pan, Adam Jardine, William Yang Wang', 'link': 'https://arxiv.org/abs/2502.15823', 'abstract': "Large language models (LLMs) have shown remarkable improvements in reasoning and many existing benchmarks have been addressed by models such as o1 and o3 either fully or partially. However, a majority of these benchmarks emphasize deductive reasoning, including mathematical and coding tasks in which rules such as mathematical axioms or programming syntax are clearly defined, based on which LLMs can plan and apply these rules to arrive at a solution. In contrast, inductive reasoning, where one infers the underlying rules from observed data, remains less explored. Such inductive processes lie at the heart of scientific discovery, as they enable researchers to extract general principles from empirical observations. To assess whether LLMs possess this capacity, we introduce InductionBench, a new benchmark designed to evaluate the inductive reasoning ability of LLMs. Our experimental findings reveal that even the most advanced models available struggle to master the simplest complexity classes within the subregular hierarchy of functions, highlighting a notable deficiency in current LLMs' inductive reasoning capabilities. Coda and data are available this https URL.", 'abstract_zh': '大型语言模型（LLMs）在推理方面取得了显著进步，许多现有的基准测试已被如o1和o3等模型完全或部分解决。然而，这些基准测试大多侧重于演绎推理，包括数学和编程任务，其中规则如数学公理或编程语法被明确定义，使LLMs能够规划并应用这些规则以得出解决方案。相比之下，归纳推理，即从观察到的数据中推断出潜在规则，仍然较少被探索。这样的归纳过程是科学研究的核心，因为它们使研究人员能够从经验观察中提取一般原则。为了评估LLMs是否具备这种能力，我们引入了InductionBench，一种新的基准测试，用于评估LLMs的归纳推理能力。我们的实验结果表明，即使是最先进的模型也难以掌握子正则层次结构中最小的复杂性类，突显了当前LLMs在归纳推理能力方面的一个明显缺陷。更多详细信息及数据请参见：https://...', 'title_zh': 'InductionBench: 大型语言模型在最简单的复杂性类中失败'}
{'arxiv_id': 'arXiv:2502.15821', 'title': 'Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization', 'authors': 'Keane Ong, Rui Mao, Deeksha Varshney, Erik Cambria, Gianmarco Mengaldo', 'link': 'https://arxiv.org/abs/2502.15821', 'abstract': "Sustainability reports are key for evaluating companies' environmental, social and governance, ESG performance, but their content is increasingly obscured by greenwashing - sustainability claims that are misleading, exaggerated, and fabricated. Yet, existing NLP approaches for ESG analysis lack robustness against greenwashing risks, often extracting insights that reflect misleading or exaggerated sustainability claims rather than objective ESG performance. To bridge this gap, we introduce A3CG - Aspect-Action Analysis with Cross-Category Generalization, as a novel dataset to improve the robustness of ESG analysis amid the prevalence of greenwashing. By explicitly linking sustainability aspects with their associated actions, A3CG facilitates a more fine-grained and transparent evaluation of sustainability claims, ensuring that insights are grounded in verifiable actions rather than vague or misleading rhetoric. Additionally, A3CG emphasizes cross-category generalization. This ensures robust model performance in aspect-action analysis even when companies change their reports to selectively favor certain sustainability areas. Through experiments on A3CG, we analyze state-of-the-art supervised models and LLMs, uncovering their limitations and outlining key directions for future research.", 'abstract_zh': '可持续性报告是评估企业环境、社会和治理（ESG）表现的关键，但随着绿色洗牌现象的增加，其内容逐渐变得模糊不清——绿色洗牌指的是一种误导性、夸大性和虚假的可持续性声明。然而，现有的自然语言处理（NLP）方法在应对绿色洗牌风险方面缺乏 robustness，经常提取反映误导性或夸大的可持续性声明而非客观的ESG表现。为弥补这一差距，我们提出了A3CG——基于跨类别泛化的方面-行动分析，作为一种新的数据集，旨在在绿色洗牌普遍存在的背景下提高ESG分析的稳健性。通过明确将可持续性方面与其相关行动联系起来，A3CG促进了一种更精细和透明的可持续性声明评估，确保见解基于可验证的实际行动而非模糊或误导性的言论。此外，A3CG强调跨类别泛化。这确保了即使公司在报告中有所改变以选择性地强调某些可持续性领域，方面-行动分析的模型性能依然稳固。通过A3CG上的实验，我们分析了最先进的监督模型和大语言模型，揭示了它们的局限性，并指出了未来研究的关键方向。', 'title_zh': '面向绿色 rinsing 风险的稳健ESG分析：跨类别泛化下的方面-行动分析'}
{'arxiv_id': 'arXiv:2502.15819', 'title': 'Tabular Embeddings for Tables with Bi-Dimensional Hierarchical Metadata and Nesting', 'authors': 'Gyanendra Shrestha, Chutain Jiang, Sai Akula, Vivek Yannam, Anna Pyayt, Michael Gubanov', 'link': 'https://arxiv.org/abs/2502.15819', 'abstract': 'Embeddings serve as condensed vector representations for real-world entities, finding applications in Natural Language Processing (NLP), Computer Vision, and Data Management across diverse downstream tasks. Here, we introduce novel specialized embeddings optimized, and explicitly tailored to encode the intricacies of complex 2-D context in tables, featuring horizontal, vertical hierarchical metadata, and nesting. To accomplish that we define the Bi-dimensional tabular coordinates, separate horizontal, vertical metadata and data contexts by introducing a new visibility matrix, encode units and nesting through the embeddings specifically optimized for mimicking intricacies of such complex structured data. Through evaluation on 5 large-scale structured datasets and 3 popular downstream tasks, we observed that our solution outperforms the state-of-the-art models with the significant MAP delta of up to 0.28. GPT-4 LLM+RAG slightly outperforms us with MRR delta of up to 0.1, while we outperform it with the MAP delta of up to 0.42.', 'abstract_zh': '嵌入式表示作为现实世界实体的凝练向量表示，在自然语言处理（NLP）、计算机视觉和数据管理等多样化下游任务中得到应用。在此，我们引入了专门优化的二维表格嵌入，用于编码复杂二维上下文的 intricacies，包括水平、垂直层次元数据和嵌套。为此，我们定义了二维表格坐标，通过引入新的可见性矩阵分离水平、垂直元数据和数据上下文，通过专门优化的嵌入编码单元和嵌套，以模拟此类复杂结构化数据的 intricacies。通过在 5 个大规模结构化数据集和 3 个流行下游任务上的评估，我们发现我们的解决方案在 MAP 性能上显著优于现有最佳模型，达到 0.28 的显著 MAP 增量。GPT-4 大语言模型+检索增强 barely 击败我们，MAP 增量达到 0.1，而我们在 MAP 上的增益达到 0.42。', 'title_zh': '具有二维层次元数据和嵌套结构的表格的表嵌入'}
{'arxiv_id': 'arXiv:2502.15815', 'title': 'Theoretical Physics Benchmark (TPBench) -- a Dataset and Study of AI Reasoning Capabilities in Theoretical Physics', 'authors': 'Daniel J.H. Chung, Zhiqi Gao, Yurii Kvasiuk, Tianyi Li, Moritz Münchmeyer, Maja Rudolph, Frederic Sala, Sai Chaitanya Tadepalli', 'link': 'https://arxiv.org/abs/2502.15815', 'abstract': 'We introduce a benchmark to evaluate the capability of AI to solve problems in theoretical physics, focusing on high-energy theory and cosmology. The first iteration of our benchmark consists of 57 problems of varying difficulty, from undergraduate to research level. These problems are novel in the sense that they do not come from public problem collections. We evaluate our data set on various open and closed language models, including o3-mini, o1, DeepSeek-R1, GPT-4o and versions of Llama and Qwen. While we find impressive progress in model performance with the most recent models, our research-level difficulty problems are mostly unsolved. We address challenges of auto-verifiability and grading, and discuss common failure modes. While currently state-of-the art models are still of limited use for researchers, our results show that AI assisted theoretical physics research may become possible in the near future. We discuss the main obstacles towards this goal and possible strategies to overcome them. The public problems and solutions, results for various models, and updates to the data set and score distribution, are available on the website of the dataset this http URL.', 'abstract_zh': '我们介绍了一个基准来评估AI在理论物理领域解决问题的能力，重点关注高能物理和宇宙学。第一个迭代基准由57个难度各异的问题组成，从本科到研究级别。这些问题具有新颖性，不来源于公开的问题集合。我们使用多种开放和封闭的语言模型进行评估，包括o3-mini、o1、DeepSeek-R1、GPT-4o以及Llama和Qwen的版本。尽管最新的模型在模型性能上取得了令人印象深刻的进展，但我们研究级别的难题大多尚未解决。我们讨论了自动化验证和评分的挑战及常见失败模式。虽然当前最先进的模型尚无法广泛应用于研究工作，但我们的研究结果表明，AI辅助的理论物理研究可能在不久的将来成为可能。我们讨论了实现这一目标的主要障碍及可能的应对策略。问题和解决方案、各种模型的结果、数据集和评分分布的更新等内容可在该数据集的官方网站上找到：this http URL。', 'title_zh': '理论物理学基准（TPBench）——一个数据集及其在理论物理学中的人工智能推理能力研究'}
{'arxiv_id': 'arXiv:2502.15814', 'title': 'Slamming: Training a Speech Language Model on One GPU in a Day', 'authors': 'Gallil Maimon, Avishai Elmakies, Yossi Adi', 'link': 'https://arxiv.org/abs/2502.15814', 'abstract': 'We introduce Slam, a recipe for training high-quality Speech Language Models (SLMs) on a single academic GPU in 24 hours. We do so through empirical analysis of model initialisation and architecture, synthetic training data, preference optimisation with synthetic data and tweaking all other components. We empirically demonstrate that this training recipe also scales well with more compute getting results on par with leading SLMs in a fraction of the compute cost. We hope these insights will make SLM training and research more accessible. In the context of SLM scaling laws, our results far outperform predicted compute optimal performance, giving an optimistic view to SLM feasibility. See code, data, models, samples at - this https URL .', 'abstract_zh': '我们介绍了一种在单块学术GPU上于24小时内训练高质量语音语言模型的方案SLAM。通过模型初始化和架构的实证分析、合成训练数据、使用合成数据进行偏好优化以及调整其他所有组件，我们实证展示了更高计算资源的情况下，该训练方案能够达到与领先语音语言模型相当的效果，但计算成本却大大降低。我们希望这些洞见能够使语音语言模型的训练和研究更加普及。在语音语言模型的可扩展性规律的背景下，我们的结果远超预期的计算最优性能，为语音语言模型的可行性提供了乐观的前景。更多信息请参见此链接：https://this-url', 'title_zh': 'Slamming: 在一天之内于一台GPU上训练一个语音语言模型'}
{'arxiv_id': 'arXiv:2502.15813', 'title': 'Stock Price Prediction Using a Hybrid LSTM-GNN Model: Integrating Time-Series and Graph-Based Analysis', 'authors': 'Meet Satishbhai Sonani, Atta Badii, Armin Moin', 'link': 'https://arxiv.org/abs/2502.15813', 'abstract': 'This paper presents a novel hybrid model that integrates long-short-term memory (LSTM) networks and Graph Neural Networks (GNNs) to significantly enhance the accuracy of stock market predictions. The LSTM component adeptly captures temporal patterns in stock price data, effectively modeling the time series dynamics of financial markets. Concurrently, the GNN component leverages Pearson correlation and association analysis to model inter-stock relational data, capturing complex nonlinear polyadic dependencies influencing stock prices. The model is trained and evaluated using an expanding window validation approach, enabling continuous learning from increasing amounts of data and adaptation to evolving market conditions. Extensive experiments conducted on historical stock data demonstrate that our hybrid LSTM-GNN model achieves a mean square error (MSE) of 0.00144, representing a substantial reduction of 10.6% compared to the MSE of the standalone LSTM model of 0.00161. Furthermore, the hybrid model outperforms traditional and advanced benchmarks, including linear regression, convolutional neural networks (CNN), and dense networks. These compelling results underscore the significant potential of combining temporal and relational data through a hybrid approach, offering a powerful tool for real-time trading and financial analysis.', 'abstract_zh': '本文提出了一种将长短期记忆（LSTM）网络和图神经网络（GNN）相结合的新型混合模型，以显著提高股市预测的准确性。该LSTM组件有效地捕捉股票价格数据中的时间序列模式，有效地建模了金融市场的时间序列动力学。同时，GNN组件利用皮尔逊相关分析和关联分析来建模股票间的交互关系数据，捕捉影响股票价格的复杂非线性多元依赖关系。该模型采用扩展窗口验证方法进行训练和评估，能够连续从不断增加的数据中学习，并适应不断变化的市场条件。在历史股票数据上的 extensive 实验表明，我们的混合 LSTM-GNN 模型均方误差（MSE）为 0.00144，与单独使用的LSTM模型的MSE 0.00161相比，降低了10.6%。此外，该混合模型在传统和先进的基准模型（包括线性回归、卷积神经网络（CNN）和密集网络）中表现出色。这些引人注目的结果强调了通过混合方法结合时间序列和关系数据的巨大潜力，提供了一个强大的工具，用于实时交易和金融分析。', 'title_zh': '基于混合LSTM-GNN模型的股票价格预测：结合时间序列与图基线分析'}
{'arxiv_id': 'arXiv:2502.15812', 'title': 'InsightVision: A Comprehensive, Multi-Level Chinese-based Benchmark for Evaluating Implicit Visual Semantics in Large Vision Language Models', 'authors': 'Xiaofei Yin, Yijie Hong, Ya Guo, Yi Tu, Weiqiang Wang, Gongshen Liu, Huijia zhu', 'link': 'https://arxiv.org/abs/2502.15812', 'abstract': 'In the evolving landscape of multimodal language models, understanding the nuanced meanings conveyed through visual cues - such as satire, insult, or critique - remains a significant challenge. Existing evaluation benchmarks primarily focus on direct tasks like image captioning or are limited to a narrow set of categories, such as humor or satire, for deep semantic understanding. To address this gap, we introduce, for the first time, a comprehensive, multi-level Chinese-based benchmark designed specifically for evaluating the understanding of implicit meanings in images. This benchmark is systematically categorized into four subtasks: surface-level content understanding, symbolic meaning interpretation, background knowledge comprehension, and implicit meaning comprehension. We propose an innovative semi-automatic method for constructing datasets, adhering to established construction protocols. Using this benchmark, we evaluate 15 open-source large vision language models (LVLMs) and GPT-4o, revealing that even the best-performing model lags behind human performance by nearly 14% in understanding implicit meaning. Our findings underscore the intrinsic challenges current LVLMs face in grasping nuanced visual semantics, highlighting significant opportunities for future research and development in this domain. We will publicly release our InsightVision dataset, code upon acceptance of the paper.', 'abstract_zh': '在多模态语言模型不断演进的背景下，理解通过视觉线索（如讽刺、侮辱或批判）传达的微妙含义仍是一个重大挑战。现有的评估基准主要集中在直接任务，如图像字幕上，或者仅限于幽默或讽刺等狭窄的类别以实现深层次语义理解。为填补这一空白，我们首次提出一个全面的多级中文基准，专门用于评估图像中隐含意义的理解能力。该基准系统地分为四个子任务：表层内容理解、象征性意义解释、背景知识理解以及隐含意义理解。我们提出了一种创新的半自动数据集构建方法，遵循既定的构建协议。使用此基准，我们评估了15个开源大型视觉语言模型（LVLMs）和GPT-4o，结果显示，即便是性能最佳的模型在理解隐含意义方面也落后人类约14%。我们的研究结果凸显了当前LVLMs在掌握细腻视觉语义方面固有的挑战，指出了该领域未来研究与开发的重要机会。我们将公开发表我们的InsightVision数据集及代码。', 'title_zh': 'InsightVision: 一个全面的多级中文基准，用于评估大型视觉语言模型中的隐含视觉语义'}
{'arxiv_id': 'arXiv:2502.15811', 'title': 'Spiking Point Transformer for Point Cloud Classification', 'authors': 'Peixi Wu, Bosong Chai, Hebei Li, Menghua Zheng, Yansong Peng, Zeyu Wang, Xuan Nie, Yueyi Zhang, Xiaoyan Sun', 'link': 'https://arxiv.org/abs/2502.15811', 'abstract': 'Spiking Neural Networks (SNNs) offer an attractive and energy-efficient alternative to conventional Artificial Neural Networks (ANNs) due to their sparse binary activation. When SNN meets Transformer, it shows great potential in 2D image processing. However, their application for 3D point cloud remains underexplored. To this end, we present Spiking Point Transformer (SPT), the first transformer-based SNN framework for point cloud classification. Specifically, we first design Queue-Driven Sampling Direct Encoding for point cloud to reduce computational costs while retaining the most effective support points at each time step. We introduce the Hybrid Dynamics Integrate-and-Fire Neuron (HD-IF), designed to simulate selective neuron activation and reduce over-reliance on specific artificial neurons. SPT attains state-of-the-art results on three benchmark datasets that span both real-world and synthetic datasets in the SNN domain. Meanwhile, the theoretical energy consumption of SPT is at least 6.4$\\times$ less than its ANN counterpart.', 'abstract_zh': '基于脉冲的点云变换器（SPT）：点云分类的变压器基脉冲神经网络框架', 'title_zh': '基于尖峰点变换器的点云分类'}
{'arxiv_id': 'arXiv:2502.15810', 'title': 'Zero-Shot Commonsense Validation and Reasoning with Large Language Models: An Evaluation on SemEval-2020 Task 4 Dataset', 'authors': 'Rawand Alfugaha, Mohammad AL-Smadi', 'link': 'https://arxiv.org/abs/2502.15810', 'abstract': 'This study evaluates the performance of Large Language Models (LLMs) on SemEval-2020 Task 4 dataset, focusing on commonsense validation and explanation. Our methodology involves evaluating multiple LLMs, including LLaMA3-70B, Gemma2-9B, and Mixtral-8x7B, using zero-shot prompting techniques. The models are tested on two tasks: Task A (Commonsense Validation), where models determine whether a statement aligns with commonsense knowledge, and Task B (Commonsense Explanation), where models identify the reasoning behind implausible statements. Performance is assessed based on accuracy, and results are compared to fine-tuned transformer-based models. The results indicate that larger models outperform previous models and perform closely to human evaluation for Task A, with LLaMA3-70B achieving the highest accuracy of 98.40% in Task A whereas, lagging behind previous models with 93.40% in Task B. However, while models effectively identify implausible statements, they face challenges in selecting the most relevant explanation, highlighting limitations in causal and inferential reasoning.', 'abstract_zh': '本研究评估了大型语言模型（LLMs）在SemEval-2020 Task 4数据集上的性能，重点关注常识验证和解释。我们的方法包括使用零样本提示技术评估多个LLM，包括LLaMA3-70B、Gemma2-9B和Mixtral-8x7B。这些模型在两个任务上进行测试：任务A（常识验证），模型判断陈述是否符合常识知识；任务B（常识解释），模型识别不合理陈述背后的推理。性能基于准确率进行评估，并将结果与微调的变换器模型进行比较。结果显示，较大的模型优于之前的模型并在任务A上接近人类评估的表现，其中LLaMA3-70B在任务A上取得了最高准确率98.40%，但在任务B上低于之前的模型93.40%。然而，虽然模型能够有效识别不合理陈述，但在选择最相关解释方面面临挑战，这突显了因果推理和推理能力的局限性。', 'title_zh': '零样本常识验证与推理：基于SemEval-2020 Task 4数据集的大型语言模型评估'}
{'arxiv_id': 'arXiv:2502.15806', 'title': 'A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos', 'authors': 'Yang Yao, Xuan Tong, Ruofan Wang, Yixu Wang, Lujundong Li, Liang Liu, Yan Teng, Yingchun Wang', 'link': 'https://arxiv.org/abs/2502.15806', 'abstract': 'Large Reasoning Models (LRMs) have significantly advanced beyond traditional Large Language Models (LLMs) with their exceptional logical reasoning capabilities, yet these improvements introduce heightened safety risks. When subjected to jailbreak attacks, their ability to generate more targeted and organized content can lead to greater harm. Although some studies claim that reasoning enables safer LRMs against existing LLM attacks, they overlook the inherent flaws within the reasoning process itself. To address this gap, we propose the first jailbreak attack targeting LRMs, exploiting their unique vulnerabilities stemming from the advanced reasoning capabilities. Specifically, we introduce a Chaos Machine, a novel component to transform attack prompts with diverse one-to-one mappings. The chaos mappings iteratively generated by the machine are embedded into the reasoning chain, which strengthens the variability and complexity and also promotes a more robust attack. Based on this, we construct the Mousetrap framework, which makes attacks projected into nonlinear-like low sample spaces with mismatched generalization enhanced. Also, due to the more competing objectives, LRMs gradually maintain the inertia of unpredictable iterative reasoning and fall into our trap. Success rates of the Mousetrap attacking o1-mini, claude-sonnet and gemini-thinking are as high as 96%, 86% and 98% respectively on our toxic dataset Trotter. On benchmarks such as AdvBench, StrongREJECT, and HarmBench, attacking claude-sonnet, well-known for its safety, Mousetrap can astonishingly achieve success rates of 87.5%, 86.58% and 93.13% respectively. Attention: This paper contains inappropriate, offensive and harmful content.', 'abstract_zh': '大型推理模型（LRMs）在具备卓越的逻辑推理能力方面显著超越了传统的大型语言模型（LLMs），但这些进步也带来了更高的安全风险。当遭受狱Break攻击时，它们生成更具针对性和组织性的内容的能力可能导致更大的危害。尽管一些研究声称推理能够使LRMs在现有的LLM攻击中更安全，但他们忽视了推理过程中固有的缺陷。为解决这一问题，我们提出了首款针对LRMs的狱Break攻击，利用其独特的高级推理能力带来的脆弱性。具体来说，我们引入了一种混沌机器，这是一种新颖的组件，用于实现多对一映射的攻击提示的转换。混沌映射由机器迭代生成，并嵌入到推理链中，增强了变化性与复杂性，也促进了更坚固的攻击。在此基础上，我们构建了Mousetrap框架，使攻击投影到非线性似的小样本空间中，并增强了不匹配的泛化能力。由于竞争目标更多，LRMs逐渐维持不可预测的迭代推理的惯性，落入我们的陷阱。在我们的毒性数据集Trotter上，Mousetrap攻击o1-mini、claude-sonnet和gemini-thinking的成功率分别为96%、86%和98%。在AdvBench、StrongREJECT和HarmBench等基准测试中，针对well-known在安全性方面表现优异的claude-sonnet，Mousetrap可以实现惊人的87.5%、86.58%和93.13%的成功率。注意：本文包含不当、冒犯性和有害内容。', 'title_zh': '一个老鼠夹：通过迭代混沌链对大型推理模型进行突破以越狱'}
{'arxiv_id': 'arXiv:2502.15805', 'title': 'FragFM: Efficient Fragment-Based Molecular Generation via Discrete Flow Matching', 'authors': 'Joongwon Lee, Seonghwan Kim, Wou Youn Kim', 'link': 'https://arxiv.org/abs/2502.15805', 'abstract': 'We introduce FragFM, a novel fragment-based discrete flow matching framework for molecular graph this http URL generates molecules at the fragment level, leveraging a coarse-to-fine autoencoding mechanism to reconstruct atom-level details. This approach reduces computational complexity while maintaining high chemical validity, enabling more efficient and scalable molecular generation. We benchmark FragFM against state-of-the-art diffusion- and flow-based models on standard molecular generation benchmarks and natural product datasets, demonstrating superior performance in validity, property control, and sampling efficiency. Notably, FragFM achieves over 99\\% validity with significantly fewer sampling steps, improving scalability while preserving molecular diversity. These results highlight the potential of fragment-based generative modeling for large-scale, property-aware molecular design, paving the way for more efficient exploration of chemical space.', 'abstract_zh': '基于片段的离散流匹配框架FragFM：高效可扩展的分子图生成方法', 'title_zh': 'FragFM：通过离散流匹配的高效片段基分子生成'}
{'arxiv_id': 'arXiv:2502.15804', 'title': 'FairKV: Balancing Per-Head KV Cache for Fast Multi-GPU Inference', 'authors': 'Bingzhe Zhao, Ke Cheng, Aomufei Yuan, Yuxuan Tian, Ruiguang Zhong, Chengchen Hu, Tong Yang, Lian Yu', 'link': 'https://arxiv.org/abs/2502.15804', 'abstract': 'KV cache techniques in Transformer models aim to reduce redundant computations at the expense of substantially increased memory usage, making KV cache compression an important and popular research topic. Recently, state-of-the-art KV cache compression methods implement imbalanced, per-head allocation algorithms that dynamically adjust the KV cache budget for each attention head, achieving excellent performance in single-GPU scenarios. However, we observe that such imbalanced compression leads to significant load imbalance when deploying multi-GPU inference, as some GPUs become overburdened while others remain underutilized. In this paper, we propose FairKV, a method designed to ensure fair memory usage among attention heads in systems employing imbalanced KV cache compression. The core technique of FairKV is Fair-Copying, which replicates a small subset of memory-intensive attention heads across GPUs using data parallelism to mitigate load imbalance. Our experiments on popular models, including LLaMA 70b and Mistral 24b model, demonstrate that FairKV increases throughput by 1.66x compared to standard tensor parallelism inference. Our code will be released as open source upon acceptance.', 'abstract_zh': 'Transformer模型中的KV缓存技术旨在通过大幅增加内存使用来减少冗余计算，因此KV缓存压缩成为一个重要的研究热点。目前最先进的KV缓存压缩方法实现了不平衡的、按头分配的算法，能够根据每个注意力头动态调整KV缓存预算，在单GPU场景中表现出色。然而，我们观察到这种不平衡的压缩在部署多GPU推理时会导致显著的负载不平衡，一些GPU变得超载，而其他GPU则被严重闲置。在本文中，我们提出FairKV方法，以确保在采用不平衡KV缓存压缩的系统中各注意力头之间的公平内存使用。FairKV的核心技术是Fair-Copying，它利用数据并行性复制一小部分内存密集型注意力头到多个GPU，以减轻负载不平衡。在包括LLaMA 70b和Mistral 24b在内的流行模型上的实验表明，与标准张量并行推理相比，FairKV的吞吐量提高了1.66倍。在被接受后，我们的代码将作为开源发布。', 'title_zh': 'FairKV：平衡每个GPU头的KV缓存以实现快速多GPU推理'}
{'arxiv_id': 'arXiv:2502.15802', 'title': 'A General Error-Theoretical Analysis Framework for Constructing Compression Strategies', 'authors': 'Boyang Zhang, Daning Cheng, Yunquan Zhang, Meiqi Tu, Fangmin Liu, Jiake Tian', 'link': 'https://arxiv.org/abs/2502.15802', 'abstract': 'The exponential growth in parameter size and computational complexity of deep models poses significant challenges for efficient deployment. The core problem of existing compression methods is that different layers of the model have significant differences in their tolerance to compression levels. For instance, the first layer of a model can typically sustain a higher compression level compared to the last layer without compromising performance. Thus, the key challenge lies in how to allocate compression levels across layers in a way that minimizes performance loss while maximizing parameter reduction. To address this challenge, we propose a Compression Error Theory (CET) framework, designed to determine the optimal compression level for each layer. Taking quantization as an example, CET leverages differential expansion and algebraic geometry to reconstruct the quadratic form of quantization error as ellipsoids and hyperbolic paraboloids, and utilizes their geometric structures to define an error subspace. To identify the error subspace with minimal performance loss, by performing orthogonal decomposition of the geometric space, CET transforms the optimization process of the error subspace into a complementary problem. The final theoretical analysis shows that constructing the quantization subspace along the major axis results in minimal performance degradation. Through experimental verification of the theory, CET can greatly retain performance while compressing. Specifically, on the ResNet-34 model, CET achieves nearly 11$\\times$ parameter compression while even surpassing performance comparable to the original model.', 'abstract_zh': '深度模型参数规模和计算复杂性的指数增长对高效部署提出了显著挑战。现有压缩方法的核心问题是模型不同层对压缩水平的容忍度存在显著差异。例如，模型的第一层通常可以比最后一层承受更高的压缩水平而不牺牲性能。因此，关键挑战在于如何在减少性能损失的同时最大化参数减少，合理分配各层的压缩水平。为应对这一挑战，我们提出了一种压缩误差理论（CET）框架，旨在为每层确定最优压缩水平。以量化为例，CET 利用微分扩展和代数几何将量化误差的二次形式重构为椭球体和双曲抛物面，并利用其几何结构定义误差子空间。为在最小化性能损失的情况下识别误差子空间，通过几何空间的正交分解，CET 将误差子空间的优化过程转化为互补问题。最终的理论分析表明，沿着主轴构建量化子空间可导致最小的性能退化。通过理论验证实验，CET 可以在压缩的同时大幅保留性能。具体而言，在 ResNet-34 模型上，CET 实现了近 11 倍的参数压缩，甚至超越了原始模型的性能。', 'title_zh': '一种构建压缩策略的一般误差理论分析框架'}
{'arxiv_id': 'arXiv:2502.15801', 'title': 'An explainable transformer circuit for compositional generalization', 'authors': 'Cheng Tang, Brenden Lake, Mehrdad Jazayeri', 'link': 'https://arxiv.org/abs/2502.15801', 'abstract': "Compositional generalization-the systematic combination of known components into novel structures-remains a core challenge in cognitive science and machine learning. Although transformer-based large language models can exhibit strong performance on certain compositional tasks, the underlying mechanisms driving these abilities remain opaque, calling into question their interpretability. In this work, we identify and mechanistically interpret the circuit responsible for compositional induction in a compact transformer. Using causal ablations, we validate the circuit and formalize its operation using a program-like description. We further demonstrate that this mechanistic understanding enables precise activation edits to steer the model's behavior predictably. Our findings advance the understanding of complex behaviors in transformers and highlight such insights can provide a direct pathway for model control.", 'abstract_zh': '组成性泛化——将已知组件系统组合成新颖结构——仍然是认知科学和机器学习中的核心挑战。尽管基于 Transformer 的大型语言模型在某些组成性任务上表现出强大的性能，但驱动这些能力的底层机制仍不明朗，这对其可解释性提出了疑问。在本工作中，我们识别并从机制上解释了负责紧凑型 Transformer 中组成性归纳的电路。通过因果消融，我们验证了该电路，并使用程序化的描述形式化其运行机制。进一步地，我们证明这种机制性理解能够精确编辑模型的激活，使其行为可预测地改变。我们的发现推进了对 Transformer 复杂行为的理解，并强调这些见解可以为模型控制提供直接途径。', 'title_zh': '可解释的变换器电路以实现组合泛化'}
{'arxiv_id': 'arXiv:2502.15799', 'title': 'Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models', 'authors': 'Artyom Kharinaev, Viktor Moskvoretskii, Egor Shvetsov, Kseniia Studenikina, Bykov Mikhail, Evgeny Burnaev', 'link': 'https://arxiv.org/abs/2502.15799', 'abstract': 'Large Language Models (LLMs) have emerged as powerful tools for addressing modern challenges and enabling practical applications. However, their computational expense remains a significant barrier to widespread adoption. Quantization has emerged as a promising technique to democratize access and enable low resource device deployment. Despite these advancements, the safety and trustworthiness of quantized models remain underexplored, as prior studies often overlook contemporary architectures and rely on overly simplistic benchmarks and evaluations. To address this gap, we introduce OpenSafetyMini, a novel open-ended safety dataset designed to better distinguish between models. We evaluate 4 state-of-the-art quantization techniques across LLaMA and Mistral models using 4 benchmarks, including human evaluations. Our findings reveal that the optimal quantization method varies for 4-bit precision, while vector quantization techniques deliver the best safety and trustworthiness performance at 2-bit precision, providing foundation for future research.', 'abstract_zh': '大型语言模型（LLMs）已成为应对现代挑战和推动实际应用的强大力量。然而，其计算成本仍然是广泛采用的主要障碍。量化技术作为一种有 promise 的方法，正在 democratize 模型的访问并使低资源设备部署成为可能。尽管取得了这些进展，量化模型的安全性和可信度仍鲜有研究，此前的研究往往忽视了现代架构并依赖过于简单的基准和评估。为填补这一空白，我们引入了 OpenSafetyMini，这是一种新颖的开放性安全数据集，旨在更好地区分不同模型。我们使用包括人工评估在内的 4 个基准，评估了 LLaMA 和 Mistral 模型上的 4 种最先进的量化技术。研究结果表明，对于 4 位精度，最佳量化方法因模型而异，而向量量化技术在 2 位精度下提供最佳的安全性和可信度性能，为未来研究奠定了基础。', 'title_zh': '探究量化方法对大型语言模型安全性和可靠性的影响'}
{'arxiv_id': 'arXiv:2502.15798', 'title': 'MaxSup: Overcoming Representation Collapse in Label Smoothing', 'authors': 'Yuxuan Zhou, Heng Li, Zhi-Qi Cheng, Xudong Yan, Mario Fritz, Margret Keuper', 'link': 'https://arxiv.org/abs/2502.15798', 'abstract': 'Label Smoothing (LS) is widely adopted to curb overconfidence in neural network predictions and enhance generalization. However, previous research shows that LS can force feature representations into excessively tight clusters, eroding intra-class distinctions. More recent findings suggest that LS also induces overconfidence in misclassifications, yet the precise mechanism remained unclear. In this work, we decompose the loss term introduced by LS, revealing two key components: (i) a regularization term that functions only when the prediction is correct, and (ii) an error-enhancement term that emerges under misclassifications. This latter term compels the model to reinforce incorrect predictions with exaggerated certainty, further collapsing the feature space. To address these issues, we propose Max Suppression (MaxSup), which uniformly applies the intended regularization to both correct and incorrect predictions by penalizing the top-1 logit instead of the ground-truth logit. Through feature analyses, we show that MaxSup restores intra-class variation and sharpens inter-class boundaries. Extensive experiments on image classification and downstream tasks confirm that MaxSup is a more robust alternative to LS. Code is available at: this https URL.', 'abstract_zh': '标签平滑（LS）广泛用于抑制神经网络预测中的过度自信并提高泛化能力。然而，先前的研究表明，LS 可能会导致特征表示形成过于紧凑的聚类，侵蚀类内区别。更近期的研究指出，LS 还会导致误分类中的过度自信，但其具体机制尚不清楚。在本工作中，我们分解了由LS引入的损失项，揭示了两个关键成分：（i）仅在预测正确时起作用的正则化项，以及（ii）在误分类时出现的错误增强项。这一后一项促使模型通过过度的信心强化错误预测，进一步压缩特征空间。为解决这些问题，我们提出了一种最大抑制（MaxSup）方法，该方法通过惩罚最高置信度而不是真实标签置信度，均匀地对正确和错误预测应用预期的正则化。通过特征分析，我们展示了MaxSup恢复了类内变异性并细化了类间边界。广泛的图像分类和下游任务实验表明，MaxSup 是比LS 更为稳健的替代方案。代码可访问：this https URL。', 'title_zh': 'MaxSup: 克服标签平滑中的表示崩溃问题'}
{'arxiv_id': 'arXiv:2502.15797', 'title': 'OCCULT: Evaluating Large Language Models for Offensive Cyber Operation Capabilities', 'authors': 'Michael Kouremetis, Marissa Dotter, Alex Byrne, Dan Martin, Ethan Michalak, Gianpaolo Russo, Michael Threet, Guido Zarrella', 'link': 'https://arxiv.org/abs/2502.15797', 'abstract': "The prospect of artificial intelligence (AI) competing in the adversarial landscape of cyber security has long been considered one of the most impactful, challenging, and potentially dangerous applications of AI. Here, we demonstrate a new approach to assessing AI's progress towards enabling and scaling real-world offensive cyber operations (OCO) tactics in use by modern threat actors. We detail OCCULT, a lightweight operational evaluation framework that allows cyber security experts to contribute to rigorous and repeatable measurement of the plausible cyber security risks associated with any given large language model (LLM) or AI employed for OCO. We also prototype and evaluate three very different OCO benchmarks for LLMs that demonstrate our approach and serve as examples for building benchmarks under the OCCULT framework. Finally, we provide preliminary evaluation results to demonstrate how this framework allows us to move beyond traditional all-or-nothing tests, such as those crafted from educational exercises like capture-the-flag environments, to contextualize our indicators and warnings in true cyber threat scenarios that present risks to modern infrastructure. We find that there has been significant recent advancement in the risks of AI being used to scale realistic cyber threats. For the first time, we find a model (DeepSeek-R1) is capable of correctly answering over 90% of challenging offensive cyber knowledge tests in our Threat Actor Competency Test for LLMs (TACTL) multiple-choice benchmarks. We also show how Meta's Llama and Mistral's Mixtral model families show marked performance improvements over earlier models against our benchmarks where LLMs act as offensive agents in MITRE's high-fidelity offensive and defensive cyber operations simulation environment, CyberLayer.", 'abstract_zh': '人工智能（AI）在网络安全对抗landscape中的竞争前景 long 被视为最具影响、最具挑战性和潜在危险的AI应用之一。在这里，我们展示了评估AI在促进和扩展现代威胁行为者使用的实际网络攻击（OCO）战术方面取得进步的新方法。我们详细介绍了OCCULT，一种轻量级操作评估框架，使网络专家能够贡献严谨且可重复的关于任何给定的大语言模型（LLM）或用于OCO的AI的可能网络风险的测量方法。我们还原型设计并评估了三种非常不同的OCO基准测试，以展示我们的方法并作为在OCCULT框架下建立基准的示例。最后，我们提供了初步评估结果，以展示该框架如何使我们能够超越传统的全有或全无的测试，这些测试多来自教育练习如夺取旗帜环境，将我们的指标和警告置于真正的网络安全威胁场景中，这些场景对现代基础设施构成了风险。我们发现，AI用于扩展现实网络安全威胁的风险已经出现了显著的近期进步。我们首次发现模型（DeepSeek-R1）能够在我们的针对LLM的威胁行为者能力测试（TACTL）中的多个选择基准测试中正确回答超过90%的具有挑战性的网络攻击知识测试题。我们还展示了Meta的Llama和Mistral的Mixtral模型家族在我们的基准测试中表现出显著性能提升，这些基准测试在MITRE的高保真网络攻击和防御操作模拟环境中，LLM作为进攻代理使用。', 'title_zh': 'OCCULT: 评估大型语言模型在恶意网络操作能力上的表现'}
{'arxiv_id': 'arXiv:2502.15796', 'title': 'Pruning as a Defense: Reducing Memorization in Large Language Models', 'authors': 'Mansi Gupta, Nikhar Waghela, Sarthak Gupta, Shourya Goel, Sanjif Shanmugavelu', 'link': 'https://arxiv.org/abs/2502.15796', 'abstract': 'Large language models have been shown to memorize significant portions of their training data, which they can reproduce when appropriately prompted. This work investigates the impact of simple pruning techniques on this behavior. Our findings reveal that pruning effectively reduces the extent of memorization in LLMs, demonstrating its potential as a foundational approach for mitigating membership inference attacks.', 'abstract_zh': '大型语言模型被证明会记忆大量训练数据，并在适当提示下重现这些数据。本工作探讨了简单剪枝技术对此行为的影响。我们的研究发现剪枝有效地减少了LLMs中的记忆程度，表明其作为减轻成员推理攻击基础方法的潜力。', 'title_zh': 'pruning作为一种防御手段：减少大型语言模型的记忆化'}
{'arxiv_id': 'arXiv:2502.15794', 'title': 'Self-Supervised Transformers as Iterative Solution Improvers for Constraint Satisfaction', 'authors': 'Yudong W. Xu, Wenhao Li, Scott Sanner, Elias B. Khalil', 'link': 'https://arxiv.org/abs/2502.15794', 'abstract': 'We present a Transformer-based framework for Constraint Satisfaction Problems (CSPs). CSPs find use in many applications and thus accelerating their solution with machine learning is of wide interest. Most existing approaches rely on supervised learning from feasible solutions or reinforcement learning, paradigms that require either feasible solutions to these NP-Complete CSPs or large training budgets and a complex expert-designed reward signal. To address these challenges, we propose ConsFormer, a self-supervised framework that leverages a Transformer as a solution refiner. ConsFormer constructs a solution to a CSP iteratively in a process that mimics local search. Instead of using feasible solutions as labeled data, we devise differentiable approximations to the discrete constraints of a CSP to guide model training. Our model is trained to improve random assignments for a single step but is deployed iteratively at test time, circumventing the bottlenecks of supervised and reinforcement learning. Our method can tackle out-of-distribution CSPs simply through additional iterations.', 'abstract_zh': '基于Transformer的约束 satisfication 问题框架', 'title_zh': '自监督变换器作为约束 satisfaction 问题迭代解改善器'}
{'arxiv_id': 'arXiv:2502.15791', 'title': 'Learning-Guided Rolling Horizon Optimization for Long-Horizon Flexible Job-Shop Scheduling', 'authors': 'Sirui Li, Wenbin Ouyang, Yining Ma, Cathy Wu', 'link': 'https://arxiv.org/abs/2502.15791', 'abstract': 'Long-horizon combinatorial optimization problems (COPs), such as the Flexible Job-Shop Scheduling Problem (FJSP), often involve complex, interdependent decisions over extended time frames, posing significant challenges for existing solvers. While Rolling Horizon Optimization (RHO) addresses this by decomposing problems into overlapping shorter-horizon subproblems, such overlap often involves redundant computations. In this paper, we present L-RHO, the first learning-guided RHO framework for COPs. L-RHO employs a neural network to intelligently fix variables that in hindsight did not need to be re-optimized, resulting in smaller and thus easier-to-solve subproblems. For FJSP, this means identifying operations with unchanged machine assignments between consecutive subproblems. Applied to FJSP, L-RHO accelerates RHO by up to 54% while significantly improving solution quality, outperforming other heuristic and learning-based baselines. We also provide in-depth discussions and verify the desirable adaptability and generalization of L-RHO across numerous FJSP variates, distributions, online scenarios and benchmark instances. Moreover, we provide a theoretical analysis to elucidate the conditions under which learning is beneficial.', 'abstract_zh': '长时域组合优化问题的学习引导滚动波段优化框架', 'title_zh': '学习导向的滚动时障优化方法及其在长时障柔性作业车间调度中的应用'}
{'arxiv_id': 'arXiv:2502.15790', 'title': 'Signal Collapse in One-Shot Pruning: When Sparse Models Fail to Distinguish Neural Representations', 'authors': 'Dhananjay Saikumar, Blesson Varghese', 'link': 'https://arxiv.org/abs/2502.15790', 'abstract': 'Neural network pruning is essential for reducing model complexity to enable deployment on resource constrained hardware. While performance loss of pruned networks is often attributed to the removal of critical parameters, we identify signal collapse a reduction in activation variance across layers as the root cause. Existing one shot pruning methods focus on weight selection strategies and rely on computationally expensive second order approximations. In contrast, we demonstrate that mitigating signal collapse, rather than optimizing weight selection, is key to improving accuracy of pruned networks. We propose REFLOW that addresses signal collapse without updating trainable weights, revealing high quality sparse sub networks within the original parameter space. REFLOW enables magnitude pruning to achieve state of the art performance, restoring ResNeXt101 accuracy from under 4.1% to 78.9% on ImageNet with only 20% of the weights retained, surpassing state of the art approaches.', 'abstract_zh': '神经网络剪枝对于减少模型复杂度以在资源受限硬件上部署至关重要。虽然剪枝网络的性能损失通常归因于关键参数的移除，我们发现信号塌缩——层间激活方差的减少——才是根本原因。现有的单次剪枝方法专注于权重选择策略，并依赖于计算成本高昂的二阶近似。相比之下，我们证明了缓解信号塌缩而非优化权重选择是提升剪枝网络精度的关键。我们提出了REFLOW，该方法在不更新可训练权重的情况下解决了信号塌缩问题，在原始参数空间内揭示了高质量的稀疏子网络。REFLOW使幅度剪枝达到最佳性能，仅保留20%的权重即可将ImageNet上的ResNeXt101精度从不到4.1%恢复到78.9%，超越了最佳方法。', 'title_zh': '一次裁剪中的信号坍塌：稀疏模型为何无法区分神经表示'}
{'arxiv_id': 'arXiv:2502.15786', 'title': 'MindLLM: A Subject-Agnostic and Versatile Model for fMRI-to-Text Decoding', 'authors': 'Weikang Qiu, Zheng Huang, Haoyu Hu, Aosong Feng, Yujun Yan, Rex Ying', 'link': 'https://arxiv.org/abs/2502.15786', 'abstract': "Decoding functional magnetic resonance imaging (fMRI) signals into text has been a key challenge in the neuroscience community, with the potential to advance brain-computer interfaces and uncover deeper insights into brain mechanisms. However, existing approaches often struggle with suboptimal predictive performance, limited task variety, and poor generalization across subjects. In response to this, we propose MindLLM, a model designed for subject-agnostic and versatile fMRI-to-text decoding. MindLLM consists of an fMRI encoder and an off-the-shelf LLM. The fMRI encoder employs a neuroscience-informed attention mechanism, which is capable of accommodating subjects with varying input shapes and thus achieves high-performance subject-agnostic decoding. Moreover, we introduce Brain Instruction Tuning (BIT), a novel approach that enhances the model's ability to capture diverse semantic representations from fMRI signals, facilitating more versatile decoding. We evaluate MindLLM on comprehensive fMRI-to-text benchmarks. Results demonstrate that our model outperforms the baselines, improving downstream tasks by 12.0%, unseen subject generalization by 16.4%, and novel task adaptation by 25.0%. Furthermore, the attention patterns in MindLLM provide interpretable insights into its decision-making process.", 'abstract_zh': '将功能性磁共振成像(fMRI)信号解码为文本是神经科学领域的关键挑战，具有推动脑-机接口发展和揭示大脑机制深层次见解的潜力。然而，现有方法往往面临预测性能不佳、任务多样性有限以及跨被试泛化能力差等问题。为应对这一挑战，我们提出MindLLM模型，该模型旨在实现被试无关和多功能的fMRI到文本解码。MindLLM由一个fMRI编码器和一个现成的大型语言模型（LLM）组成。fMRI编码器采用了基于神经科学的注意力机制，能够适应不同输入形状的被试，从而实现高性能的被试无关解码。此外，我们引入了脑指令调优（BIT）方法，这是一种新的方法，能够增强模型从fMRI信号中捕捉多样语义表示的能力，促进更广泛的解码。我们在全面的fMRI到文本基准上评估了MindLLM。结果表明，我们的模型优于基线模型，提高了下游任务的性能12.0%，未见过的被试泛化能力16.4%，以及新型任务适应性25.0%。此外，MindLLM中的注意力模式提供了对其决策过程的可解释洞见。', 'title_zh': 'MindLLM: 一种无领域限制且多功能的fMRI到文本解码模型'}
{'arxiv_id': 'arXiv:2502.15785', 'title': 'Masking the Gaps: An Imputation-Free Approach to Time Series Modeling with Missing Data', 'authors': 'Abhilash Neog, Arka Daw, Sepideh Fatemi Khorasgani, Anuj Karpatne', 'link': 'https://arxiv.org/abs/2502.15785', 'abstract': 'A significant challenge in time-series (TS) modeling is the presence of missing values in real-world TS datasets. Traditional two-stage frameworks, involving imputation followed by modeling, suffer from two key drawbacks: (1) the propagation of imputation errors into subsequent TS modeling, (2) the trade-offs between imputation efficacy and imputation complexity. While one-stage approaches attempt to address these limitations, they often struggle with scalability or fully leveraging partially observed features. To this end, we propose a novel imputation-free approach for handling missing values in time series termed Missing Feature-aware Time Series Modeling (MissTSM) with two main innovations. First, we develop a novel embedding scheme that treats every combination of time-step and feature (or channel) as a distinct token. Second, we introduce a novel Missing Feature-Aware Attention (MFAA) Layer to learn latent representations at every time-step based on partially observed features. We evaluate the effectiveness of MissTSM in handling missing values over multiple benchmark datasets.', 'abstract_zh': '一种时间序列（TS）建模中的显著挑战是在实际TS数据集中存在缺失值。传统的两阶段框架，涉及插补随后进行建模，存在两个关键缺点：（1）插补误差传播到后续TS建模中，（2）插补效果与插补复杂度之间的权衡。尽管一阶段方法试图解决这些限制，但它们往往在可扩展性或充分利用部分观测特征方面存在问题。为此，我们提出了一种称为缺失特征感知时间序列建模（MissTSM）的新颖无插补方法，包含两大创新。首先，我们开发了一种新的嵌入方案，将每个时间步和特征（或通道）的组合视为一个独特的 token。其次，我们引入了一种新颖的缺失特征感知注意（MFAA）层，用于根据部分观测特征学习每个时间步的潜变量表示。我们评估了MissTSM在多个基准数据集上处理缺失值的有效性。', 'title_zh': '掩蔽缺口：一种无插补的缺失数据时间序列建模方法'}
{'arxiv_id': 'arXiv:2502.15780', 'title': 'Feature Engineering Approach to Building Load Prediction: A Case Study for Commercial Building Chiller Plant Optimization in Tropical Weather', 'authors': 'Zhan Wang, Chen Weidong, Huang Zhifeng, Md Raisul Islam, Chua Kian Jon', 'link': 'https://arxiv.org/abs/2502.15780', 'abstract': "In tropical countries with high humidity, air conditioning can account for up to 60% of a building's energy use. For commercial buildings with centralized systems, the efficiency of the chiller plant is vital, and model predictive control provides an effective strategy for optimizing operations through dynamic adjustments based on accurate load predictions. Artificial neural networks are effective for modelling nonlinear systems but are prone to overfitting due to their complexity. Effective feature engineering can mitigate this issue. While weather data are crucial for load prediction, they are often used as raw numerical inputs without advanced processing. Clustering features is a technique that can reduce model complexity and enhance prediction accuracy. Although previous studies have explored clustering algorithms for load prediction, none have applied them to multidimensional weather data, revealing a research gap. This study presents a cooling load prediction model that combines a neural network with Kalman filtering and K-means clustering. Applied to real world data from a commercial skyscraper in Singapore's central business district, the model achieved a 46.5% improvement in prediction accuracy. An optimal chiller sequencing strategy was also developed through genetic algorithm optimization of the predictive load, potentially saving 13.8% in energy. Finally, the study evaluated the integration of thermal energy storage into the chiller plant design, demonstrating potential reductions in capital and operational costs of 26% and 13%, respectively.", 'abstract_zh': '在高湿度的热带国家，空调可能占建筑物能源使用量的高达60%。对于具有集中系统的商业建筑，制冷机组的效率至关重要，模型预测控制提供了一种通过基于准确负载预测的动态调整来优化运行的有效策略。人工神经网络适用于建模非线性系统，但由于其复杂性容易过拟合，有效的特征工程可以缓解这一问题。尽管气象数据对于负载预测至关重要，但它们通常未经高级处理即作为原始数值输入使用。聚类特征是一种可以减少模型复杂性和提升预测精度的技术。尽管以往研究已经探讨了聚类算法在负载预测中的应用，但尚未将其应用于多维气象数据，揭示了研究空白。本研究提出了一种结合神经网络、卡尔曼过滤和K-means聚类的冷却负载预测模型。该模型应用于新加坡中央商务区一座商业摩天大楼的实际数据，预测准确性提高了46.5%。还通过遗传算法优化预测负载开发了一种最佳制冷机排序策略，潜在节省了13.8%的能源。最后，研究评估了将热能存储集成到制冷机组设计中的潜力，分别展示了26%和13%的资本成本和运营成本减少。', 'title_zh': '基于特征工程的负荷预测方法：热带气候下商业建筑制冷系统优化的案例研究'}
{'arxiv_id': 'arXiv:2502.15779', 'title': 'Rotate, Clip, and Partition: Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer', 'authors': 'Euntae Choi, Sumin Song, Woosang Lim, Sungjoo Yoo', 'link': 'https://arxiv.org/abs/2502.15779', 'abstract': 'We propose Rotate, Clip, and Partition (RCP), a quantization-aware training (QAT) approach that first realizes extreme compression of LLMs with W2A4KV4(2-bit weight, 4-bit activation, and 4-bit KV cache) configuration. RCP integrates recent rotation techniques with a novel non-uniform weight quantizer design, by quantitatively analyzing the impact of random rotation on 2-bit weight quantization. Our weight quantizer features Learnable Direct Partitioning (LDP), which introduces learnable parameters to directly learn non-uniform intervals jointly with LLM weights. We also present a specialized GPU kernel that supports GEMV on non-uniform W2A4. Experiments show that RCP can compress LLaMA-2-7B to W2A4KV4 with a loss of only 2.84 WikiText2 ppl and 5.29 times reduced memory footprint. Furthermore, RCP can quantize challenging mobile-targeted LLaMA-3.2 models and domain-specific WizardCoder-7B and MetaMath-7B with no critical problems such as convergence failure and repetition. Code will be made available at blind_review.', 'abstract_zh': '我们提出了一种名为Rotate、Clip和Partition (RCP) 的量化感知训练（QAT）方法，该方法首先使用W2A4KV4（2位权重、4位激活和4位KV缓存）配置实现了对大规模语言模型的极致压缩。RCP 结合了最新的旋转技术，并设计了一种新颖的非均匀权重量化器，通过定量分析随机旋转对2位权重量化的影响。我们的权重量化器配备了可学习直接分区（LDP），引入可学习参数直接学习与大规模语言模型权重联合的非均匀区间。我们还提出了一种专门的GPU内核，支持非均匀W2A4上的GEMV操作。实验结果显示，RCP 可以将LLaMA-2-7B压缩至W2A4KV4，损失仅为2.84个WikiText2 PPL，并且内存占用减少5.29倍。此外，RCP 可以对针对移动设备的LLaMA-3.2模型以及领域特定的WizardCoder-7B和MetaMath-7B进行量化，没有出现如收敛失败和重复等关键问题。代码将在提交评审前提供。', 'title_zh': '旋转、裁剪和分区：通过结合旋转和可学习的非均匀量化器向量量化方法的研究（Towards W2A4KV4 Quantization by Integrating Rotation and Learnable Non-uniform Quantizer）'}
{'arxiv_id': 'arXiv:2502.15777', 'title': 'TSS GAZ PTP: Towards Improving Gumbel AlphaZero with Two-stage Self-play for Multi-constrained Electric Vehicle Routing Problems', 'authors': 'Hui Wang, Xufeng Zhang, Xiaoyu Zhang, Zhenhuan Ding, Chaoxu Mu', 'link': 'https://arxiv.org/abs/2502.15777', 'abstract': 'Recently, Gumbel AlphaZero~(GAZ) was proposed to solve classic combinatorial optimization problems such as TSP and JSSP by creating a carefully designed competition model~(consisting of a learning player and a competitor player), which leverages the idea of self-play. However, if the competitor is too strong or too weak, the effectiveness of self-play training can be reduced, particularly in complex CO problems. To address this problem, we further propose a two-stage self-play strategy to improve the GAZ method~(named TSS GAZ PTP). In the first stage, the learning player uses the enhanced policy network based on the Gumbel Monte Carlo Tree Search~(MCTS), and the competitor uses the historical best trained policy network~(acts as a greedy player). In the second stage, we employ Gumbel MCTS for both players, which makes the competition fiercer so that both players can continuously learn smarter trajectories. We first investigate the performance of our proposed TSS GAZ PTP method on TSP since it is also used as a test problem by the original GAZ. The results show the superior performance of TSS GAZ PTP. Then we extend TSS GAZ PTP to deal with multi-constrained Electric Vehicle Routing Problems~(EVRP), which is a recently well-known real application research topic and remains challenging as a complex CO problem. Impressively, the experimental results show that the TSS GAZ PTP outperforms the state-of-the-art Deep Reinforcement Learning methods in all types of instances tested and outperforms the optimization solver in tested large-scale instances, indicating the importance and promising of employing more dynamic self-play strategies for complex CO problems.', 'abstract_zh': '最近，提出了Gumbel AlphaZero (GAZ) 方法通过设计竞争模型（包括学习玩家和竞争玩家）来解决如TSP和JSSP的经典组合优化问题，并利用自对弈的思想。然而，如果竞争者太强或太弱，自对弈训练的效果可能会降低，特别是在复杂的组合优化问题中。为了解决这一问题，我们进一步提出了一种两阶段自对弈策略来改进GAZ方法（命名为TSS GAZ PTP）。在第一阶段，学习玩家使用基于Gumbel Monte Carlo Tree Search (MCTS) 的增强策略网络，竞争玩家使用历史最佳训练策略网络（作用为贪婪玩家）。在第二阶段，我们使用Gumbel MCTS 对两个玩家进行操作，从而使竞争更加激烈，使得两个玩家能够不断学习更智能的路径。我们首先在TSP上研究了我们提出的TSS GAZ PTP方法的表现，因为它也被原始的GAZ用作测试问题。结果显示TSS GAZ PTP表现出优越的性能。然后我们将TSS GAZ PTP扩展应用于解决多约束的电动汽车路径规划问题（EVRP），这是一个最近颇受关注的实际应用研究主题，并且仍然是一个复杂的组合优化问题。实验结果令人印象深刻地表明，TSS GAZ PTP在所有类型实例中都优于最先进的深度强化学习方法，并在大规模实例中优于优化求解器，这表明采用更具动态性的自对弈策略对于解决复杂的组合优化问题的重要性及其潜力。', 'title_zh': 'TSS GAZ PTP：通过两阶段自我博弈提高多约束电动汽车路线规划问题的Gumbel AlphaZero'}
{'arxiv_id': 'arXiv:2502.15771', 'title': 'Learning to Reason from Feedback at Test-Time', 'authors': 'Yanyang Li, Michael Lyu, Liwei Wang', 'link': 'https://arxiv.org/abs/2502.15771', 'abstract': 'Solving complex tasks in a single attempt is challenging for large language models (LLMs). Iterative interaction with the environment and feedback is often required to achieve success, making effective feedback utilization a critical topic. Existing approaches either struggle with length generalization or rely on naive retries without leveraging prior information. In this paper, we introduce FTTT, a novel paradigm that formulates feedback utilization as an optimization problem at test time. Additionally, we propose a learnable test-time optimizer, OpTune, to effectively exploit feedback. Experiments on two LLMs across four reasoning datasets demonstrate that FTTT and OpTune achieve superior scalability and performance.', 'abstract_zh': '大型语言模型在单次尝试解决复杂任务具有挑战性。通常需要迭代与环境交互并利用反馈才能取得成功，因此有效的反馈利用成为关键话题。现有方法要么在长度泛化方面表现不佳，要么依赖于原始重试而未能充分利用先验信息。在本文中，我们引入了FTTT，一个新颖的范式，将反馈利用形式化为测试时的优化问题。此外，我们提出了一种可学习的测试时优化器OpTune，以有效利用反馈。实验结果表明，FTTT和OpTune在两个大型语言模型和四个推理数据集上实现了更好的可扩展性和性能。', 'title_zh': '在测试时从反馈中学习推理'}
{'arxiv_id': 'arXiv:2502.15770', 'title': 'Performance Review on LLM for solving leetcode problems', 'authors': 'Lun Wang, Chuanqi Shi, Shaoshui Du, Yiyi Tao, Yixian Shen, Hang Zheng, Xinyu Qiu', 'link': 'https://arxiv.org/abs/2502.15770', 'abstract': 'This paper presents a comprehensive performance evaluation of Large Language Models (LLMs) in solving programming challenges from Leetcode, a widely used platform for algorithm practice and technical interviews. We began by crawling the Leetcode website to collect a diverse set of problems encompassing various difficulty levels and topics. Using this dataset, we generated solutions with multiple LLMs, including GPT-4 and GPT-3.5-turbo (ChatGPT-turbo). The generated solutions were systematically evaluated for correctness and efficiency. We employed the pass@k metric to assess the success rates within a given number of attempts and analyzed the runtime performance of the solutions. Our results highlight the strengths and limitations of current LLMs [10] in code generation and problem-solving tasks, providing insights into their potential applications and areas for improvement in automated programming assistance.', 'abstract_zh': '这篇论文对大型语言模型（LLMs）在解决来自 Leetcode 的编程挑战中的表现进行了全面评估，Leetcode 是一个广泛用于算法练习和技术面试的平台。我们首先抓取 Leetcode 网站以收集涵盖不同难度级别和主题的多样问题集。使用该数据集，我们生成了多个 LLM 的解决方案，包括 GPT-4、GPT-3.5-turbo（ChatGPT-turbo）。生成的解决方案被系统地评估了正确性和效率。我们使用 pass@k 指标评估了一定次数尝试内的成功率，并分析了解决方案的运行时性能。我们的结果突显了当前 LLMs 在代码生成和解决问题任务中的优点和局限性，提供了其在自动化编程辅助中的潜在应用和改进领域的见解。', 'title_zh': 'LLM在解决LeetCode问题上的性能评估'}
{'arxiv_id': 'arXiv:2502.15765', 'title': 'Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow', 'authors': 'Behrooz Azarkhalili, Maxwell Libbrecht', 'link': 'https://arxiv.org/abs/2502.15765', 'abstract': 'This paper introduces Generalized Attention Flow (GAF), a novel feature attribution method for Transformer-based models to address the limitations of current approaches. By extending Attention Flow and replacing attention weights with the generalized Information Tensor, GAF integrates attention weights, their gradients, the maximum flow problem, and the barrier method to enhance the performance of feature attributions. The proposed method exhibits key theoretical properties and mitigates the shortcomings of prior techniques that rely solely on simple aggregation of attention weights. Our comprehensive benchmarking on sequence classification tasks demonstrates that a specific variant of GAF consistently outperforms state-of-the-art feature attribution methods in most evaluation settings, providing a more reliable interpretation of Transformer model outputs.', 'abstract_zh': '这篇论文介绍了通用注意力流（GAF），一种针对Transformer模型的新颖特征归因方法，以解决当前方法的局限性。通过扩展注意力流并将注意力权重替换为通用信息张量，GAF将注意力权重、其梯度、最大流问题和障碍方法结合在一起，以提高特征归因的性能。所提出的方法具备关键的理论性质，并减轻了仅依赖简单注意力权重聚合的先前技术的局限性。我们在序列分类任务上的全面基准测试表明，GAF的特定变体在大多数评估环境下始终优于最先进的特征归因方法，提供了Transformer模型输出更加可靠的解释。', 'title_zh': '广义注意力流：通过最大流进行的变压器模型特征归因'}
{'arxiv_id': 'arXiv:2502.15764', 'title': 'High-Throughput Computational Screening and Interpretable Machine Learning of Metal-organic Frameworks for Iodine Capture', 'authors': 'Haoyi Tan, Yukun Teng, Guangcun Shan', 'link': 'https://arxiv.org/abs/2502.15764', 'abstract': "The removal of leaked radioactive iodine isotopes in humid environments holds significant importance in nuclear waste management and nuclear accident mitigation. In this study, high-throughput computational screening and machine learning were combined to reveal the iodine capture performance of 1816 metal-organic framework (MOF) materials under humid air conditions. Firstly, the relationship between the structural characteristics of MOFs and their adsorption properties was explored, with the aim of identifying the optimal structural parameters for iodine capture. Subsequently, two machine learning regression algorithms - Random Forest and CatBoost, were employed to predict the iodine adsorption capabilities of MOFs. In addition to 6 structural features, 25 molecular features and 8 chemical features were incorporated to enhance the prediction accuracy of the machine learning algorithms. Feature importance was assessed to determine the relative influence of various features on iodine adsorption performance, in which the Henry's coefficient and heat of adsorption to iodine were found the two most crucial chemical factors. Furthermore, four types of molecular fingerprints were introduced for providing comprehensive and detailed structural information of MOF materials. The top 20 most significant MACCS molecular fingerprints were picked out, revealing that the presence of six-membered ring structures and nitrogen atoms in the MOFs were the key structural factors that enhanced iodine adsorption, followed by the existence of oxygen atoms. This work combined high-throughput computation, machine learning, and molecular fingerprints to comprehensively elucidate the multifaceted factors influencing the iodine adsorption performance of MOFs, offering profound insightful guidelines for screening and structural design of advanced MOF materials.", 'abstract_zh': '湿环境中泄漏放射性碘同位素的去除在核废料管理和核事故缓解中具有重要意义。本研究结合高通量计算筛选和机器学习，探讨了1816种金属有机框架（MOF）材料在湿空气条件下对碘的捕获性能。首先，研究了MOFs的结构特征与其吸附性能之间的关系，旨在识别碘捕获的最佳结构参数。随后，采用了随机森林和CatBoost两种机器学习回归算法来预测MOFs的碘吸附能力。除了6种结构特征，还纳入了25种分子特征和8种化学特征以提高机器学习算法的预测精度。特征重要性分析确定了各种特征对碘吸附性能的相对影响，发现亨利系数和吸附碘的热力学参数是最关键的化学因素。此外，引入了四种类型的分子指纹图谱，提供了MOF材料的综合和详细结构信息。筛选出了最重要的20种MACCS分子指纹图谱，揭示了六元环结构和氮原子在MOFs中的存在是提高碘吸附的关键结构因素，其次是氧原子的存在。本研究结合高通量计算、机器学习和分子指纹图谱，全面探讨了影响MOFs碘吸附性能的多方面因素，为先进MOF材料的筛选和结构设计提供了深刻的指导。', 'title_zh': '高通量计算筛选及可解释机器学习在碘捕获金属有机框架研究中应用'}
{'arxiv_id': 'arXiv:2502.15763', 'title': 'Hybrid Offline-online Scheduling Method for Large Language Model Inference Optimization', 'authors': 'Bowen Pang, Kai Li, Ruifeng She, Feifan Wang', 'link': 'https://arxiv.org/abs/2502.15763', 'abstract': 'With the development of large language models (LLMs), it has become increasingly important to optimize hardware usage and improve throughput. In this paper, we study the inference optimization of the serving system that deploys LLMs. To optimize system throughput and maximize hardware utilization, we formulate the inference optimization problem as a mixed-integer programming (MIP) model and propose a hybrid offline-online method as solution. The offline method improves large-scale inference systems by introducing a Minimizing Makespan Bin Packing Problem. We further provide a theoretical lower bound computation method. Then, we propose an online sorting and preemptive scheduling method to better utilize hardware. In the online iteration scheduling process, a Lagrangian method is applied to evaluate the cost efficiency of inserting prefill stages versus decode stages at each iteration and dynamically determine when to preempt decoding tasks and insert prefill tasks. Experiments using real-world data from the LLaMA-65B model and the GSM8K dataset demonstrate that system utilization improves from 80.2% to 89.1%, and the total inference time decreases from 201.00 to 190.58 seconds. A 100-cases study shows that our method consistently outperforms the baseline method and improves the utilization rate by 8.0% on average. Finally, we discuss potential future extensions, including stochastic modeling, reinforcement learning-based schedulers, and dynamic decision-making strategies for system throughput and hardware utilization.', 'abstract_zh': '随着大型语言模型（LLMs）的发展，优化硬件使用和提高吞吐量变得日益重要。本文研究了部署LLMs的服务系统的推理优化。为了优化系统吞吐量并最大化硬件利用率，我们将推理优化问题形式化为混合整数规划（MIP）模型，并提出了一种混合离线-在线方法进行求解。离线方法通过引入最小化工期的物品装箱问题来改进大规模推理系统。我们进一步提供了理论下界计算方法。然后，我们提出了一种在线排序和前瞻调度方法，以更好地利用硬件。在在线迭代调度过程中，应用拉格朗日方法来评估在每次迭代中插入预填充阶段与解码阶段的成本效率，并动态决定何时中断解码任务并插入预填充任务。使用LLaMA-65B模型和GSM8K数据集的实际数据进行的实验表明，系统利用率从80.2%提高到89.1%，总推理时间从201.00秒减少到190.58秒。100案例研究显示，我们的方法在所有情况下都优于基线方法，平均提高利用率8.0%。最后，我们讨论了潜在的未来扩展，包括随机建模、基于强化学习的调度器以及系统吞吐量和硬件利用率的动态决策策略。', 'title_zh': '大型语言模型推理优化的混合离线-在线调度方法'}
{'arxiv_id': 'arXiv:2502.15762', 'title': 'SmartEdge: Smart Healthcare End-to-End Integrated Edge and Cloud Computing System for Diabetes Prediction Enabled by Ensemble Machine Learning', 'authors': 'Alain Hennebelle, Qifan Dieng, Leila Ismail, Rajkumar Buyya', 'link': 'https://arxiv.org/abs/2502.15762', 'abstract': 'The Internet of Things (IoT) revolutionizes smart city domains such as healthcare, transportation, industry, and education. The Internet of Medical Things (IoMT) is gaining prominence, particularly in smart hospitals and Remote Patient Monitoring (RPM). The vast volume of data generated by IoMT devices should be analyzed in real-time for health surveillance, prognosis, and prediction of diseases. Current approaches relying on Cloud computing to provide the necessary computing and storage capabilities do not scale for these latency-sensitive applications. Edge computing emerges as a solution by bringing cloud services closer to IoMT devices. This paper introduces SmartEdge, an AI-powered smart healthcare end-to-end integrated edge and cloud computing system for diabetes prediction. This work addresses latency concerns and demonstrates the efficacy of edge resources in healthcare applications within an end-to-end system. The system leverages various risk factors for diabetes prediction. We propose an Edge and Cloud-enabled framework to deploy the proposed diabetes prediction models on various configurations using edge nodes and main cloud servers. Performance metrics are evaluated using, latency, accuracy, and response time. By using ensemble machine learning voting algorithms we can improve the prediction accuracy by 5% versus a single model prediction.', 'abstract_zh': '物联网(IoT)革命了智慧城市领域的医疗、交通、工业和教育等方面。医疗物联网(IoMT)在智能医院和远程患者监测(RPM)中尤为重要。IoMT设备生成的大量数据应当实时分析，以实现健康监测、预后和疾病预测。当前依赖云计算提供必要计算和存储能力的方法对于这些对延迟敏感的应用不具有可扩展性。边缘计算通过将云计算服务靠近IoMT设备而成为解决方案。本文介绍SmartEdge，一种基于人工智能的端到端集成边缘和云计算系统，用于糖尿病预测。本文解决了延迟问题，并在端到端系统中展示了边缘资源在医疗保健应用中的有效性。该系统利用多种糖尿病风险因素。我们提出了一种边缘和云计算支持的框架，使用边缘节点和主要云服务器部署所提议的糖尿病预测模型。性能指标通过延迟、准确性和响应时间进行评估。通过使用集成机器学习投票算法，我们可以将预测准确性提高5%相对于单一模型预测。', 'title_zh': 'SmartEdge：由集成边缘和云计算系统及集成机器学习.Enable糖尿病预测的智能边缘端到端一体化系统'}
{'arxiv_id': 'arXiv:2502.15761', 'title': 'LoXR: Performance Evaluation of Locally Executing LLMs on XR Devices', 'authors': 'Dawar Khan, Xinyu Liu, Omar Mena, Donggang Jia, Alexandre Kouyoumdjian, Ivan Viola', 'link': 'https://arxiv.org/abs/2502.15761', 'abstract': 'The deployment of large language models (LLMs) on extended reality (XR) devices has great potential to advance the field of human-AI interaction. In the case of direct, on-device model inference, selecting the appropriate model and device for specific tasks remains challenging. In this paper, we deploy 17 LLMs across four XR devices--Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and Apple Vision Pro, and conduct a comprehensive evaluation. We devise an experimental setup and evaluate performance on four key metrics: performance consistency, processing speed, memory usage, and battery consumption. For each of the 68 model-device pairs, we assess performance under varying string lengths, batch sizes, and thread counts, analyzing the trade-offs for real-time XR applications. We finally propose a unified evaluation method based on the Pareto Optimality theory to select the optimal device-model pairs from the quality and speed objectives. We believe our findings offer valuable insights to guide future optimization efforts for LLM deployment on XR devices. Our evaluation method can be followed as standard groundwork for further research and development in this emerging field. All supplemental materials are available at this http URL.', 'abstract_zh': '将大语言模型（LLMs）部署在扩展现实（XR）设备上在人机交互领域具有巨大潜力。针对直接在设备上进行模型推理的情况下，选择适合特定任务的模型和设备仍然具有挑战性。在本文中，我们将在Magic Leap 2、Meta Quest 3、Vivo X100s Pro和Apple Vision Pro四款XR设备上部署17个LLM，并进行综合评估。我们设计了实验框架，并从性能一致性、处理速度、内存使用和电池消耗四个关键指标进行评估。对于每对68种模型-设备组合，我们在不同的字符串长度、批次大小和线程数量下评估其性能，分析实时XR应用中的权衡。最后，我们基于Pareto最优理论提出了一种统一的评估方法，用于从质量和速度目标中选择最佳的设备-模型组合。我们认为，我们的研究结果为未来优化XR设备上LLM部署的努力提供了有价值的见解。我们的评估方法可作为进一步研究和发展的标准基础。所有补充材料可在此链接访问。', 'title_zh': 'LoXR：在XR设备上本地执行LLMs的性能评估'}
{'arxiv_id': 'arXiv:2502.15757', 'title': 'TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data', 'authors': 'Leonardo Berti, Gjergji Kasneci', 'link': 'https://arxiv.org/abs/2502.15757', 'abstract': "Stock Price Trend Prediction (SPTP) based on Limit Order Book (LOB) data is a fundamental challenge in financial markets. Despite advances in deep learning, existing models fail to generalize across different market conditions and struggle to reliably predict short-term trends. Surprisingly, by adapting a simple MLP-based architecture to LOB, we show that we surpass SoTA performance; thus, challenging the necessity of complex architectures. Unlike past work that shows robustness issues, we propose TLOB, a transformer-based model that uses a dual attention mechanism to capture spatial and temporal dependencies in LOB data. This allows it to adaptively focus on the market microstructure, making it particularly effective for longer-horizon predictions and volatile market conditions. We also introduce a new labeling method that improves on previous ones, removing the horizon bias. To assess TLOB's effectiveness, we evaluate it on the well-known FI-2010 benchmark (F1 of 92.8\\%) and on Tesla (+2.67\\% on F1) and Intel (+14.16\\% on F1). Additionally, we empirically show how stock price predictability has declined over time (-6.68 absolute points in F1), highlighting the growing market efficiencies. Predictability must be considered in relation to transaction costs, so we experimented with defining trends using an average spread, reflecting the primary transaction cost. The resulting performance deterioration underscores the complexity of translating trend classification into profitable trading strategies. We argue that our work provides new insights into the evolving landscape of stock price trend prediction and sets a strong foundation for future advancements in financial AI. We release the code at this http URL.", 'abstract_zh': '基于限价订单簿数据的股票价格趋势预测（SPTP）是金融市场的基本挑战。尽管深度学习取得了进步，现有的模型难以在不同市场条件下泛化，并且在可靠预测短期趋势方面存在困难。令人惊讶的是，通过将简单的MLP架构适应限价订单簿数据，我们展示了超越当前最佳性能（SoTA）的可能性，从而质疑复杂架构的必要性。不同于过去的工作揭示了鲁棒性问题，我们提出了基于变换器的TLOB模型，该模型使用双重注意机制来捕捉限价订单簿数据中的空间和时间依赖性。这使其能够自适应地关注市场微观结构，特别是在较长预测期和市场波动条件下表现出色。我们还引入了一种新的标签方法，改进了以前的方法，消除了预测期偏见。为了评估TLOB的有效性，我们在FI-2010基准（F1得分为92.8%）以及特斯拉（F1提高了2.67%）和英特尔（F1提高了14.16%）上进行了评估。此外，我们实证展示了股票价格可预测性随时间下降（F1绝对值下降了6.68点），突显了市场效率的增强。必须将可预测性考虑与交易成本相关联，因此我们通过使用平均价差来定义趋势，反映了主要的交易成本，进而实证探索。所得性能下降进一步证明了将趋势分类转化为盈利交易策略的复杂性。我们认为我们的工作为股票价格趋势预测的不断演变提供了新的见解，并为未来金融AI的发展奠定了坚实的基础。我们将在该网址发布代码。', 'title_zh': 'TLOB：一种用于限价订单簿数据股票价格趋势预测的新型双注意机制变换器模型'}
{'arxiv_id': 'arXiv:2502.15755', 'title': 'Physics-consistent machine learning: output projection onto physical manifolds', 'authors': 'Matilde Valente, Tiago C. Dias, Vasco Guerra, Rodrigo Ventura', 'link': 'https://arxiv.org/abs/2502.15755', 'abstract': 'Data-driven machine learning models often require extensive datasets, which can be costly or inaccessible, and their predictions may fail to comply with established physical laws. Current approaches for incorporating physical priors mitigate these issues by penalizing deviations from known physical laws, as in physics-informed neural networks, or by designing architectures that automatically satisfy specific invariants. However, penalization approaches do not guarantee compliance with physical constraints for unseen inputs, and invariant-based methods lack flexibility and generality. We propose a novel physics-consistent machine learning method that directly enforces compliance with physical principles by projecting model outputs onto the manifold defined by these laws. This procedure ensures that predictions inherently adhere to the chosen physical constraints, improving reliability and interpretability. Our method is demonstrated on two systems: a spring-mass system and a low-temperature reactive plasma. Compared to purely data-driven models, our approach significantly reduces errors in physical law compliance, enhances predictive accuracy of physical quantities, and outperforms alternatives when working with simpler models or limited datasets. The proposed projection-based technique is versatile and can function independently or in conjunction with existing physics-informed neural networks, offering a powerful, general, and scalable solution for developing fast and reliable surrogate models of complex physical systems, particularly in resource-constrained scenarios.', 'abstract_zh': '一种直接遵守物理原理的新型物理一致性机器学习方法', 'title_zh': '物理学一致的机器学习：输出映射到物理流形上'}
{'arxiv_id': 'arXiv:2502.15754', 'title': 'Text2Net: Transforming Plain-text To A Dynamic Interactive Network Simulation Environment', 'authors': 'Alireza Marefat, Abbaas Alif Mohamed Nishar, Ashwin Ashok', 'link': 'https://arxiv.org/abs/2502.15754', 'abstract': "This paper introduces Text2Net, an innovative text-based network simulation engine that leverages natural language processing (NLP) and large language models (LLMs) to transform plain-text descriptions of network topologies into dynamic, interactive simulations. Text2Net simplifies the process of configuring network simulations, eliminating the need for users to master vendor-specific syntaxes or navigate complex graphical interfaces. Through qualitative and quantitative evaluations, we demonstrate Text2Net's ability to significantly reduce the time and effort required to deploy network scenarios compared to traditional simulators like EVE-NG. By automating repetitive tasks and enabling intuitive interaction, Text2Net enhances accessibility for students, educators, and professionals. The system facilitates hands-on learning experiences for students that bridge the gap between theoretical knowledge and practical application. The results showcase its scalability across various network complexities, marking a significant step toward revolutionizing network education and professional use cases, such as proof-of-concept testing.", 'abstract_zh': 'Text2Net：一种基于文本的网络模拟引擎', 'title_zh': 'Text2Net: 将普通文本转换为动态交互网络仿真环境'}
{'arxiv_id': 'arXiv:2502.15749', 'title': 'TCProF:Time-Complexity Prediction SSL Framework', 'authors': 'Joonghyuk Hahn, Hyeseon Ahn, Jungin Kim, Soohan Lim, Yo-Sub Han', 'link': 'https://arxiv.org/abs/2502.15749', 'abstract': "Time complexity is a theoretic measure to determine the amount of time the algorithm needs for its execution. In reality, developers write algorithms into code snippets within limited resources, making the calculation of a code's time complexity a fundamental task. However, determining the precise time complexity of a code is theoretically undecidable. In response, recent advancements have leaned toward deploying datasets for code time complexity prediction and initiating preliminary experiments for this challenge. We investigate the challenge in low-resource scenarios where only a few labeled instances are given for training. Remarkably, we are the first to introduce TCProF: a Time-Complexity Prediction SSL Framework as an effective solution for code time complexity prediction in low-resource settings. TCProF significantly boosts performance by integrating our augmentation, symbolic modules, and a co-training mechanism, achieving a more than 60% improvement over self-training approaches. We further provide an extensive comparative analysis between TCProF, ChatGPT, and Gemini-Pro, offering a detailed evaluation of our approach.", 'abstract_zh': '时间复杂度是理论衡量算法执行所需时间的指标。实际上，开发人员在有限资源下将算法编写为代码片段，因此计算代码的时间复杂度是基本任务之一。然而，确定代码的确切时间复杂度在理论上是不可判定的。为此，最近的进展转向使用数据集进行代码时间复杂度预测，并开始对此挑战进行初步实验。我们研究了低资源场景中的挑战，其中只有少量带标签的实例用于训练。值得一提的是，我们首次提出了TCProF：一种时间复杂度预测的SSL框架，它是针对低资源设置中代码时间复杂度预测的有效解决方案。TCProF通过集成我们的增强、符号模块和协同训练机制，显著提升了性能，相对于自我训练方法，性能提升了超过60%。我们进一步提供了TCProF、ChatGPT和Gemini-Pro之间的全面比较分析，对我们的方法进行了详细评估。', 'title_zh': 'TCProF: 时间复杂度预测SSL框架'}
{'arxiv_id': 'arXiv:2502.15740', 'title': 'Detection of LLM-Generated Java Code Using Discretized Nested Bigrams', 'authors': 'Timothy Paek, Chilukuri Mohan', 'link': 'https://arxiv.org/abs/2502.15740', 'abstract': 'Large Language Models (LLMs) are currently used extensively to generate code by professionals and students, motivating the development of tools to detect LLM-generated code for applications such as academic integrity and cybersecurity. We address this authorship attribution problem as a binary classification task along with feature identification and extraction. We propose new Discretized Nested Bigram Frequency features on source code groups of various sizes. Compared to prior work, improvements are obtained by representing sparse information in dense membership bins. Experimental evaluation demonstrated that our approach significantly outperformed a commonly used GPT code-detection API and baseline features, with accuracy exceeding 96% compared to 72% and 79% respectively in detecting GPT-rewritten Java code fragments for 976 files with GPT 3.5 and GPT4 using 12 features. We also outperformed three prior works on code author identification in a 40-author dataset. Our approach scales well to larger data sets, and we achieved 99% accuracy and 0.999 AUC for 76,089 files and over 1,000 authors with GPT 4o using 227 features.', 'abstract_zh': '大规模语言模型（LLMs）生成的代码检测：一种二分类特征识别与提取方法', 'title_zh': '基于离散嵌套双聚类的LLM生成Java代码检测'}
{'arxiv_id': 'arXiv:2502.15737', 'title': 'A Performance Analysis of You Only Look Once Models for Deployment on Constrained Computational Edge Devices in Drone Applications', 'authors': 'Lucas Rey, Ana M. Bernardos, Andrzej D. Dobrzycki, David Carramiñana, Luca Bergesio, Juan A. Besada, José Ramón Casar', 'link': 'https://arxiv.org/abs/2502.15737', 'abstract': 'Advancements in embedded systems and Artificial Intelligence (AI) have enhanced the capabilities of Unmanned Aircraft Vehicles (UAVs) in computer vision. However, the integration of AI techniques o-nboard drones is constrained by their processing capabilities. In this sense, this study evaluates the deployment of object detection models (YOLOv8n and YOLOv8s) on both resource-constrained edge devices and cloud environments. The objective is to carry out a comparative performance analysis using a representative real-time UAV image processing pipeline. Specifically, the NVIDIA Jetson Orin Nano, Orin NX, and Raspberry Pi 5 (RPI5) devices have been tested to measure their detection accuracy, inference speed, and energy consumption, and the effects of post-training quantization (PTQ). The results show that YOLOv8n surpasses YOLOv8s in its inference speed, achieving 52 FPS on the Jetson Orin NX and 65 fps with INT8 quantization. Conversely, the RPI5 failed to satisfy the real-time processing needs in spite of its suitability for low-energy consumption applications. An analysis of both the cloud-based and edge-based end-to-end processing times showed that increased communication latencies hindered real-time applications, revealing trade-offs between edge (low latency) and cloud processing (quick processing). Overall, these findings contribute to providing recommendations and optimization strategies for the deployment of AI models on UAVs.', 'abstract_zh': '嵌入式系统和人工智能的进步提升了无人机在计算机视觉方面的能力。然而，无人机上集成人工智能技术受其计算能力的限制。在这种情况下，本研究评估了将YOLOv8n和YOLOv8s目标检测模型部署在资源受限的边缘设备和云环境中。目的是通过一个有代表性的实时无人机图像处理流水线进行性能比较分析。具体来说，测试了NVIDIA Jetson Orin Nano、Orin NX和Raspberry Pi 5 (RPI5)设备，以测量其检测精度、推理速度和能源消耗，并分析了后训练量化(PTQ)的影响。结果表明，YOLOv8n在推理速度上优于YOLOv8s，在Jetson Orin NX上的帧率达到了52 FPS，并通过INT8量化实现了65 fps。相反，RPI5未能满足实时处理需求，尽管其适合低能耗应用。云环境和边缘环境端到端处理时间的分析表明，增加的通信延迟阻碍了实时应用，揭示了边缘（低延迟）和云处理（快速处理）之间的权衡。总体来说，这些发现为无人机上部署AI模型提供了建议和优化策略。', 'title_zh': '约束计算边缘设备上无人机应用中You Only Look Once模型的性能分析'}
{'arxiv_id': 'arXiv:2502.15735', 'title': 'DistrEE: Distributed Early Exit of Deep Neural Network Inference on Edge Devices', 'authors': 'Xian Peng, Xin Wu, Lianming Xu, Li Wang, Aiguo Fei', 'link': 'https://arxiv.org/abs/2502.15735', 'abstract': 'Distributed DNN inference is becoming increasingly important as the demand for intelligent services at the network edge grows. By leveraging the power of distributed computing, edge devices can perform complicated and resource-hungry inference tasks previously only possible on powerful servers, enabling new applications in areas such as autonomous vehicles, industrial automation, and smart homes. However, it is challenging to achieve accurate and efficient distributed edge inference due to the fluctuating nature of the actual resources of the devices and the processing difficulty of the input data. In this work, we propose DistrEE, a distributed DNN inference framework that can exit model inference early to meet specific quality of service requirements. In particular, the framework firstly integrates model early exit and distributed inference for multi-node collaborative inferencing scenarios. Furthermore, it designs an early exit policy to control when the model inference terminates. Extensive simulation results demonstrate that DistrEE can efficiently realize efficient collaborative inference, achieving an effective trade-off between inference latency and accuracy.', 'abstract_zh': '分布式DNN推理正在随着网络边缘智能服务需求的增长变得日益重要。通过利用分布式计算的强大功能，边缘设备可以执行以往只有在强大服务器上才能完成的复杂且资源密集型的推理任务，从而在无人驾驶车辆、工业自动化和智能家居等领域开启新的应用。然而，由于设备实际资源的波动性和输入数据处理的难度，实现准确高效的分布式边缘推理具有挑战性。在这种情况下，我们提出了DistrEE，一种能够提前退出模型推理以满足特定服务质量要求的分布式DNN推理框架。该框架首先将模型提前退出与分布式推理整合到多节点协作推理场景中，并设计了一个提前退出策略来控制模型推理的终止时机。大量仿真结果表明，DistrEE能够高效地实现协作推理，实现推理延迟和准确性的有效权衡。', 'title_zh': 'DistrEE: 边缘设备上深度神经网络推断的分布式早期退出机制'}
{'arxiv_id': 'arXiv:2502.15734', 'title': 'Cache-Craft: Managing Chunk-Caches for Efficient Retrieval-Augmented Generation', 'authors': 'Shubham Agarwal, Sai Sundaresan, Subrata Mitra, Debabrata Mahapatra, Archit Gupta, Rounak Sharma, Nirmal Joshua Kapu, Tong Yu, Shiv Saini', 'link': 'https://arxiv.org/abs/2502.15734', 'abstract': 'Retrieval-Augmented Generation (RAG) is often used with Large Language Models (LLMs) to infuse domain knowledge or user-specific information. In RAG, given a user query, a retriever extracts chunks of relevant text from a knowledge base. These chunks are sent to an LLM as part of the input prompt. Typically, any given chunk is repeatedly retrieved across user questions. However, currently, for every question, attention-layers in LLMs fully compute the key values (KVs) repeatedly for the input chunks, as state-of-the-art methods cannot reuse KV-caches when chunks appear at arbitrary locations with arbitrary contexts. Naive reuse leads to output quality degradation. This leads to potentially redundant computations on expensive GPUs and increases latency. In this work, we propose Cache-Craft, a system for managing and reusing precomputed KVs corresponding to the text chunks (we call chunk-caches) in RAG-based systems. We present how to identify chunk-caches that are reusable, how to efficiently perform a small fraction of recomputation to fix the cache to maintain output quality, and how to efficiently store and evict chunk-caches in the hardware for maximizing reuse while masking any overheads. With real production workloads as well as synthetic datasets, we show that Cache-Craft reduces redundant computation by 51% over SOTA prefix-caching and 75% over full recomputation. Additionally, with continuous batching on a real production workload, we get a 1.6X speed up in throughput and a 2X reduction in end-to-end response latency over prefix-caching while maintaining quality, for both the LLaMA-3-8B and LLaMA-3-70B models.', 'abstract_zh': '基于检索增强生成（RAG）系统的缓存管理与复用算法（Cache-Craft）', 'title_zh': 'Cache-Craft: 管理块缓存以实现高效的检索增强生成'}
{'arxiv_id': 'arXiv:2502.15732', 'title': 'Data Wrangling Task Automation Using Code-Generating Language Models', 'authors': 'Ashlesha Akella, Krishnasuri Narayanam', 'link': 'https://arxiv.org/abs/2502.15732', 'abstract': 'Ensuring data quality in large tabular datasets is a critical challenge, typically addressed through data wrangling tasks. Traditional statistical methods, though efficient, cannot often understand the semantic context and deep learning approaches are resource-intensive, requiring task and dataset-specific training. To overcome these shortcomings, we present an automated system that utilizes large language models to generate executable code for tasks like missing value imputation, error detection, and error correction. Our system aims to identify inherent patterns in the data while leveraging external knowledge, effectively addressing both memory-dependent and memory-independent tasks.', 'abstract_zh': '确保大型表格数据集的数据质量是一个关键挑战，通常通过数据整理任务来解决。传统统计方法虽然高效，但往往无法理解语义上下文，而深度学习方法则资源密集，需要针对特定任务和数据集进行训练。为克服这些不足，我们提出了一种自动化系统，利用大型语言模型生成用于处理如缺失值填充、错误检测和错误纠正等任务的可执行代码。该系统旨在利用内部和外部知识识别数据中的固有模式，有效解决既依赖内存又不依赖内存的任务。', 'title_zh': '使用代码生成语言模型的数据清洗任务自动化'}
{'arxiv_id': 'arXiv:2502.15731', 'title': 'Modular and Integrated AI Control Framework across Fiber and Wireless Networks for 6G', 'authors': 'Merim Dzaferagic, Marco Ruffini, Daniel Kilper', 'link': 'https://arxiv.org/abs/2502.15731', 'abstract': 'The rapid evolution of communication networks towards 6G increasingly incorporates advanced AI-driven controls across various network segments to achieve intelligent, zero-touch operation. This paper proposes a comprehensive and modular framework for AI controllers, designed to be highly flexible and adaptable for use across both fiber optical and radio networks. Building on the principles established by the O-RAN Alliance for near-Real-Time RAN Intelligent Controllers (near-RT RICs), our framework extends this AI-driven control into the optical domain. Our approach addresses the critical need for a unified AI control framework across diverse network transport technologies and domains, enabling the development of intelligent, automated, and scalable 6G networks.', 'abstract_zh': '6G 通信网络向快速演进的过程中，越来越多地融入了跨各种网络段的先进AI驱动控制，以实现智能化和零接触操作。本文提出了一种全面且模块化的AI控制器框架，旨在高度灵活并适应光纤网络和无线电网络的广泛使用。基于O-RAN联盟为近实时RAN智能控制器（near-RT RICs）建立的原则，我们的框架将这种AI驱动的控制扩展到光域。我们的方法解决了多样化的网络传输技术和领域中统一AI控制框架的迫切需求，有助于发展智能化、自动化和可扩展的6G网络。', 'title_zh': '跨光纤和无线网络的模块化一体化AI控制框架（面向6G）'}
{'arxiv_id': 'arXiv:2502.15727', 'title': 'Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning', 'authors': 'Youssef Maklad, Fares Wael, Wael Elsersy, Ali Hamdi', 'link': 'https://arxiv.org/abs/2502.15727', 'abstract': "This paper presents a novel approach to evaluate the efficiency of a RAG-based agentic Large Language Model (LLM) architecture in network packet seed generation for network protocol fuzzing. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings in a two-stages. In the first stage, the agent dynamically refers to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol Finite State Machine (FSM), then it iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. In the second stage, we evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.", 'abstract_zh': '一种基于RAG的代理大型语言模型架构在网络包种子生成中的效率评估方法：基于链式思考促进协议 fuzzing 的宽泛探索', 'title_zh': '基于检索增强生成的大语言模型评估：带有链式思考推理的协议状态机推断'}
{'arxiv_id': 'arXiv:2502.15724', 'title': 'Instruction-Based Fine-tuning of Open-Source LLMs for Predicting Customer Purchase Behaviors', 'authors': 'Halil Ibrahim Ergul, Selim Balcisoy, Burcin Bozkaya', 'link': 'https://arxiv.org/abs/2502.15724', 'abstract': "In this study, the performance of various predictive models, including probabilistic baseline, CNN, LSTM, and finetuned LLMs, in forecasting merchant categories from financial transaction data have been evaluated. Utilizing datasets from Bank A for training and Bank B for testing, the superior predictive capabilities of the fine-tuned Mistral Instruct model, which was trained using customer data converted into natural language format have been demonstrated. The methodology of this study involves instruction fine-tuning Mistral via LoRA (LowRank Adaptation of Large Language Models) to adapt its vast pre-trained knowledge to the specific domain of financial transactions. The Mistral model significantly outperforms traditional sequential models, achieving higher F1 scores in the three key merchant categories of bank transaction data (grocery, clothing, and gas stations) that is crucial for targeted marketing campaigns. This performance is attributed to the model's enhanced semantic understanding and adaptability which enables it to better manage minority classes and predict transaction categories with greater accuracy. These findings highlight the potential of LLMs in predicting human behavior.", 'abstract_zh': '本研究评估了包括概率基准模型、CNN、LSTM和微调的大语言模型（LLM）在金融交易数据预测商户类别方面的性能。利用来自银行A的训练集和银行B的测试集，展示了通过将客户数据转换为自然语言格式进行微调的Mistral Instruct模型的卓越预测能力。本研究的方法是通过LoRA（大型语言模型的低秩适应）对Mistral进行指令微调，使其庞大的预训练知识适应金融交易的特定领域。Mistral模型显著优于传统的顺序模型，在银行交易数据（食品杂货、服装和加油站）的三个关键商户类别上实现了更高的F1分数，这对于有针对性的营销活动至关重要。这一性能归因于模型增强的语义理解和适应性，使其能够更好地处理少数类别，更准确地预测交易类别。这些发现突显了大语言模型在预测人类行为方面的潜力。', 'title_zh': '基于指令的开源大语言模型细调以预测客户购买行为'}
{'arxiv_id': 'arXiv:2502.15723', 'title': 'Balancing Content Size in RAG-Text2SQL System', 'authors': 'Prakhar Gurawa, Anjali Dharmik', 'link': 'https://arxiv.org/abs/2502.15723', 'abstract': 'Large Language Models (LLMs) have emerged as a promising solution for converting natural language queries into SQL commands, enabling seamless database interaction. However, these Text-to-SQL (Text2SQL) systems face inherent limitations, hallucinations, outdated knowledge, and untraceable reasoning. To address these challenges, the integration of retrieval-augmented generation (RAG) with Text2SQL models has gained traction. RAG serves as a retrieval mechanism, providing essential contextual information, such as table schemas and metadata, to enhance the query generation process. Despite their potential, RAG + Text2SQL systems are susceptible to the quality and size of retrieved documents. While richer document content can improve schema relevance and retrieval accuracy, it also introduces noise, increasing the risk of hallucinations and reducing query fidelity as the prompt size of the Text2SQL model increases. This research investigates the nuanced trade-off between document size and quality, aiming to strike a balance that optimizes system performance. Key thresholds are identified where performance degradation occurs, along with actionable strategies to mitigate these challenges. Additionally, we explore the phenomenon of hallucinations in Text2SQL models, emphasizing the critical role of curated document presentation in minimizing errors. Our findings provide a roadmap for enhancing the robustness of RAG + Text2SQL systems, offering practical insights for real-world applications.', 'abstract_zh': '大型语言模型（LLMs）作为一种将自然语言查询转换为SQL命令的有前途的解决方案，促进了数据库交互。然而，这些Text-to-SQL（Text2SQL）系统面临着固有的限制，包括幻觉、过时的知识和不可追溯的推理。为了解决这些挑战，将检索增强生成（RAG）与Text2SQL模型相结合的方法越来越多地受到关注。RAG充当检索机制，提供诸如表结构和元数据等关键上下文信息，以增强查询生成过程。尽管更丰富的文档内容可以提高模式相关性和检索准确性，但这也引入了噪声，增加了幻觉的风险，并随着Text2SQL模型提示大小增加而降低查询准确性。本研究探讨了文档大小和质量之间的微妙权衡，旨在找到优化系统性能的最佳平衡点。我们确定了性能降级的关键阈值，并提出了应对这些挑战的操作性策略。此外，我们还探讨了Text2SQL模型中的幻觉现象，强调精心策划的文档呈现对减少错误的至关重要性。我们的研究结果为增强RAG + Text2SQL系统的稳健性提供了蓝图，提供了实用的见解，适用于实际应用。', 'title_zh': '平衡RAG-Text2SQL系统中的内容大小'}
{'arxiv_id': 'arXiv:2502.15721', 'title': 'iTRI-QA: a Toolset for Customized Question-Answer Dataset Generation Using Language Models for Enhanced Scientific Research', 'authors': 'Qiming Liu, Zhongzheng Niu, Siting Liu, Mao Tian', 'link': 'https://arxiv.org/abs/2502.15721', 'abstract': "The exponential growth of AI in science necessitates efficient and scalable solutions for retrieving and preserving research information. Here, we present a tool for the development of a customized question-answer (QA) dataset, called Interactive Trained Research Innovator (iTRI) - QA, tailored for the needs of researchers leveraging language models (LMs) to retrieve scientific knowledge in a QA format. Our approach integrates curated QA datasets with a specialized research paper dataset to enhance responses' contextual relevance and accuracy using fine-tuned LM. The framework comprises four key steps: (1) the generation of high-quality and human-generated QA examples, (2) the creation of a structured research paper database, (3) the fine-tuning of LMs using domain-specific QA examples, and (4) the generation of QA dataset that align with user queries and the curated database. This pipeline provides a dynamic and domain-specific QA system that augments the utility of LMs in academic research that will be applied for future research LM deployment. We demonstrate the feasibility and scalability of our tool for streamlining knowledge retrieval in scientific contexts, paving the way for its integration into broader multi-disciplinary applications.", 'abstract_zh': 'AI在科学中的指数增长 necessitates 有效且可扩展的解决方案以检索和保存研究信息。在此，我们介绍了一种针对利用语言模型（LMs）以问答格式检索科学知识的研究人员需求定制的问答（QA）数据集工具，称为交互式训练研究创新者（iTRI）-QA。我们的方法将精选的问答数据集与专门的科研论文数据集相结合，使用细调后的LM增强响应的相关性和准确性。该框架包括四个关键步骤：（1）高质量的人工生成的问答示例生成，（2）结构化科研论文数据库的创建，（3）使用领域特定的问答示例对LM进行细调，以及（4）生成与用户查询和精选数据库对齐的问答数据集。该流水线提供了一个动态且领域特定的问答系统，增强了LM在学术研究中的实用性，并将应用于未来的研究LM部署。我们展示了该工具在科学情境下简化知识检索的可行性和可扩展性，为其集成到更广泛的跨学科应用铺平了道路。', 'title_zh': 'iTRI-QA：一种基于语言模型生成定制化问答数据集的工具集，以增强科学研究'}
{'arxiv_id': 'arXiv:2502.15720', 'title': 'Training AI to be Loyal', 'authors': 'Sewoong Oh, Himanshu Tyagi, Pramod Viswanath', 'link': 'https://arxiv.org/abs/2502.15720', 'abstract': "Loyal AI is loyal to the community that builds it. An AI is loyal to a community if the community has ownership, alignment, and control. Community owned models can only be used with the approval of the community and share the economic rewards communally. Community aligned models have values that are aligned with the consensus of the community. Community controlled models perform functions designed by the community. Since we would like permissionless access to the loyal AI's community, we need the AI to be open source. The key scientific question then is: how can we build models that are openly accessible (open source) and yet are owned and governed by the community. This seeming impossibility is the focus of this paper where we outline a concrete pathway to Open, Monetizable and Loyal models (OML), building on our earlier work on OML, arXiv:2411.03887(1) , and a representation via a cryptographic-ML library this http URL .", 'abstract_zh': '忠诚的AI忠于构建它的社区。如果社区拥有所有权、一致性和控制权，那么AI就是忠诚于这个社区的。社区拥有的模型只能在社区批准的情况下使用，并且能够共同分享经济收益。社区对齐的模型具有与社区共识一致的价值观。社区控制的模型执行由社区设计的功能。由于我们希望无许可访问忠诚的AI的社区，因此需要该AI是开源的。那么关键的科学问题是：如何构建既可公开访问（开源）又由社区拥有和治理的模型。这种看似不可能的挑战是本文的关注点，我们在文中概述了一条从开源、可货币化和忠诚模型（OML）的具体路径，基于我们早期关于OML的工作arXiv:2411.03887(1)以及一个通过加密-机器学习库表示的方法。', 'title_zh': '训练AI忠诚'}
{'arxiv_id': 'arXiv:2502.15719', 'title': 'Governing AI Beyond the Pretraining Frontier', 'authors': 'Nicholas A. Caputo', 'link': 'https://arxiv.org/abs/2502.15719', 'abstract': 'This year, jurisdictions worldwide, including the United States, the European Union, the United Kingdom, and China, are set to enact or revise laws governing frontier AI. Their efforts largely rely on the assumption that increasing model scale through pretraining is the path to more advanced AI capabilities. Yet growing evidence suggests that this "pretraining paradigm" may be hitting a wall and major AI companies are turning to alternative approaches, like inference-time "reasoning," to boost capabilities instead.\nThis paradigm shift presents fundamental challenges for the frontier AI governance frameworks that target pretraining scale as a key bottleneck useful for monitoring, control, and exclusion, threatening to undermine this new legal order as it emerges. This essay seeks to identify these challenges and point to new paths forward for regulation. First, we examine the existing frontier AI regulatory regime and analyze some key traits and vulnerabilities. Second, we introduce the concept of the "pretraining frontier," the capabilities threshold made possible by scaling up pretraining alone, and demonstrate how it could make the regulatory field more diffuse and complex and lead to new forms of competition. Third, we lay out a regulatory approach that focuses on increasing transparency and leveraging new natural technical bottlenecks to effectively oversee changing frontier AI development while minimizing regulatory burdens and protecting fundamental rights. Our analysis provides concrete mechanisms for governing frontier AI systems across diverse technical paradigms, offering policymakers tools for addressing both current and future regulatory challenges in frontier AI.', 'abstract_zh': '全球范围内，包括美国、欧洲联盟、英国和中国在内的地区今年将制定或修订治理前沿人工智能的法律。这些努力主要基于一个假设，即通过预训练增加模型规模是实现更高级人工智能能力的途径。然而，越来越多的证据表明，这一“预训练范式”可能已达到瓶颈，主要人工智能公司正转向推理时的“推理”等替代方法以提升能力。这一范式转变对将预训练规模作为关键瓶颈进行监控、控制和排除的前沿人工智能治理框架提出了根本性的挑战，可能削弱新兴的法律秩序。本文旨在识别这些挑战，并指明新的监管路径。首先，我们审视现有的前沿人工智能监管制度，并分析其中的关键特征和脆弱性。其次，我们提出了“预训练前沿”这一概念，这是通过单独扩大预训练规模所可能实现的能力门槛，并展示它如何使监管领域更加分散和复杂，并可能导致新的竞争形式。最后，我们阐述一种监管方法，该方法集中在提高透明度，并利用新的自然技术瓶颈，有效监督前沿人工智能发展变化，同时减轻监管负担并保护基本权利。我们的分析为不同技术范式的前沿人工智能系统提供了具体的治理机制，为政策制定者提供工具，以应对当前和未来的前沿人工智能监管挑战。', 'title_zh': '超越预训练边界的AI治理'}
{'arxiv_id': 'arXiv:2502.15715', 'title': 'Regulating Multifunctionality', 'authors': 'Cary Coglianese, Colton R. Crum', 'link': 'https://arxiv.org/abs/2502.15715', 'abstract': "Foundation models and generative artificial intelligence (AI) exacerbate a core regulatory challenge associated with AI: its heterogeneity. By their very nature, foundation models and generative AI can perform multiple functions for their users, thus presenting a vast array of different risks. This multifunctionality means that prescriptive, one-size-fits-all regulation will not be a viable option. Even performance standards and ex post liability - regulatory approaches that usually afford flexibility - are unlikely to be strong candidates for responding to multifunctional AI's risks, given challenges in monitoring and enforcement. Regulators will do well instead to promote proactive risk management on the part of developers and users by using management-based regulation, an approach that has proven effective in other contexts of heterogeneity. Regulators will also need to maintain ongoing vigilance and agility. More than in other contexts, regulators of multifunctional AI will need sufficient resources, top human talent and leadership, and organizational cultures committed to regulatory excellence.", 'abstract_zh': '基础模型与生成性人工智能加剧了与AI相关的核心监管挑战：异质性。这类模型和生成性AI能够为用户执行多种功能，从而带来各种不同的风险，这使得规定性的一刀切监管方法变得不可行。即使是一些通常具有灵活性的性能标准和事后责任监管方法，也可能不是应对多功能AI风险的有力选择，尤其是在难以监控和执行方面的挑战面前。相反，监管者应通过基于管理的监管措施促进开发人员和用户主动风险管理，这种监管方法在其他异质性背景下已被证明是有效的。监管者还需要保持持续的警惕性和灵活性。对于多功能AI的监管者而言，这方面的资源、顶级人力资源和致力于监管卓越的组织文化比在其他背景下的需求更为强烈。', 'title_zh': '调节多功能性'}
{'arxiv_id': 'arXiv:2502.15714', 'title': 'TrustDataFilter:Leveraging Trusted Knowledge Base Data for More Effective Filtering of Unknown Information', 'authors': 'Jinghong Zhang, Yidong Cui, Weiling Wang, Xianyou Cheng', 'link': 'https://arxiv.org/abs/2502.15714', 'abstract': 'With the advancement of technology and changes in the market, the demand for the construction of domain-specific knowledge bases has been increasing, either to improve model performance or to promote enterprise innovation and competitiveness. The construction of domain-specific knowledge bases typically relies on web crawlers or existing industry databases, leading to problems with accuracy and consistency of the data. To address these challenges, we considered the characteristics of domain data, where internal knowledge is interconnected, and proposed the Self-Natural Language Inference Data Filtering (self-nli-TDF) framework. This framework compares trusted filtered knowledge with the data to be filtered, deducing the reasoning relationship between them, thus improving filtering performance. The framework uses plug-and-play large language models for trustworthiness assessment and employs the RoBERTa-MNLI model from the NLI domain for reasoning. We constructed three datasets in the domains of biology, radiation, and science, and conducted experiments using RoBERTa, GPT3.5, and the local Qwen2 model. The experimental results show that this framework improves filter quality, producing more consistent and reliable filtering results.', 'abstract_zh': '随着技术的进步和市场的变化，对领域特定知识库的构建需求不断增加，以提高模型性能或促进企业创新和竞争力。领域特定知识库的构建通常依赖于网页抓取器或现有的行业数据库，这导致数据的准确性和一致性问题。为应对这些挑战，我们考虑了领域数据的特点，即内部知识相互连接，提出了Self-Natural Language Inference Data Filtering (self-nli-TDF) 框架。该框架将可信过滤知识与待过滤数据进行比较，推导它们之间的推理关系，从而提高过滤性能。该框架利用可插拔的大语言模型进行可信度评估，并采用NLI领域中的RoBERTa-MNLI模型进行推理。我们构建了生物、辐射和科学领域的三个数据集，并使用RoBERTa、GPT3.5和本地Qwen2模型进行了实验。实验结果表明，该框架提高了过滤质量，生成了更为一致和可靠的过滤结果。', 'title_zh': 'TrustDataFilter：利用可信知识库数据实现对未知信息更有效的过滤'}
{'arxiv_id': 'arXiv:2502.15713', 'title': 'UAV-assisted Internet of Vehicles: A Framework Empowered by Reinforcement Learning and Blockchain', 'authors': 'Ahmed Alagha, Maha Kadadha, Rabeb Mizouni, Shakti Singh, Jamal Bentahar, Hadi Otrok', 'link': 'https://arxiv.org/abs/2502.15713', 'abstract': 'This paper addresses the challenges of selecting relay nodes and coordinating among them in UAV-assisted Internet-of-Vehicles (IoV). The selection of UAV relay nodes in IoV employs mechanisms executed either at centralized servers or decentralized nodes, which have two main limitations: 1) the traceability of the selection mechanism execution and 2) the coordination among the selected UAVs, which is currently offered in a centralized manner and is not coupled with the relay selection. Existing UAV coordination methods often rely on optimization methods, which are not adaptable to different environment complexities, or on centralized deep reinforcement learning, which lacks scalability in multi-UAV settings. Overall, there is a need for a comprehensive framework where relay selection and coordination are coupled and executed in a transparent and trusted manner. This work proposes a framework empowered by reinforcement learning and Blockchain for UAV-assisted IoV networks. It consists of three main components: a two-sided UAV relay selection mechanism for UAV-assisted IoV, a decentralized Multi-Agent Deep Reinforcement Learning (MDRL) model for autonomous UAV coordination, and a Blockchain implementation for transparency and traceability in the interactions between vehicles and UAVs. The relay selection considers the two-sided preferences of vehicles and UAVs based on the Quality-of-UAV (QoU) and the Quality-of-Vehicle (QoV). Upon selection of relay UAVs, the decentralized coordination between them is enabled through an MDRL model trained to control their mobility and maintain the network coverage and connectivity using Proximal Policy Optimization (PPO). The evaluation results demonstrate that the proposed selection and coordination mechanisms improve the stability of the selected relays and maximize the coverage and connectivity achieved by the UAVs.', 'abstract_zh': '基于UAV辅助IoV的强化学习与区块链赋能的relay选择与协同框架', 'title_zh': '无人机辅助 veículo 网络：一种基于 reinforcement learning 和区块链的技术框架'}
{'arxiv_id': 'arXiv:2502.15712', 'title': "GPUs, CPUs, and... NICs: Rethinking the Network's Role in Serving Complex AI Pipelines", 'authors': 'Mike Wong, Ulysses Butler, Emma Farkash, Praveen Tammana, Anirudh Sivaraman, Ravi Netravali', 'link': 'https://arxiv.org/abs/2502.15712', 'abstract': 'The increasing prominence of AI necessitates the deployment of inference platforms for efficient and effective management of AI pipelines and compute resources. As these pipelines grow in complexity, the demand for distributed serving rises and introduces much-dreaded network delays. In this paper, we investigate how the network can instead be a boon to the excessively high resource overheads of AI pipelines. To alleviate these overheads, we discuss how resource-intensive data processing tasks -- a key facet of growing AI pipeline complexity -- are well-matched for the computational characteristics of packet processing pipelines and how they can be offloaded onto SmartNICs. We explore the challenges and opportunities of offloading, and propose a research agenda for integrating network hardware into AI pipelines, unlocking new opportunities for optimization.', 'abstract_zh': 'AI日益突出的 prominence 增加了部署推理平台的需求，以高效有效地管理和利用 AI 管道和计算资源。随着这些管道变得日益复杂，分布式服务的需求上升，并引入了令人担忧的网络延迟。在本文中，我们探讨了网络如何成为缓解 AI 管道过度资源开销的福音。为了缓解这些开销，我们讨论了计算密集型数据处理任务 —— 即随着 AI 管道复杂性的增长而变得日益重要的关键方面 —— 如何与报文处理管道的计算特性相匹配，并提出如何将其卸载到智能网络接口卡（SmartNICs）上。我们探讨了卸载带来的挑战和机遇，并提出了一项研究议程，旨在将网络硬件集成到 AI 管道中，从而解锁新的优化机会。', 'title_zh': 'GPU、CPU和……网络适卡：重新思考网络在服务复杂AI流水线中的角色'}
{'arxiv_id': 'arXiv:2502.15709', 'title': 'TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation', 'authors': 'Zhaoxing Li, Vahid Yazdanpanah, Jindi Wang, Wen Gu, Lei Shi, Alexandra I. Cristea, Sarah Kiden, Sebastian Stein', 'link': 'https://arxiv.org/abs/2502.15709', 'abstract': "The integration of AI in education offers significant potential to enhance learning efficiency. Large Language Models (LLMs), such as ChatGPT, Gemini, and Llama, allow students to query a wide range of topics, providing unprecedented flexibility. However, LLMs face challenges, such as handling varying content relevance and lack of personalization. To address these challenges, we propose TutorLLM, a personalized learning recommender LLM system based on Knowledge Tracing (KT) and Retrieval-Augmented Generation (RAG). The novelty of TutorLLM lies in its unique combination of KT and RAG techniques with LLMs, which enables dynamic retrieval of context-specific knowledge and provides personalized learning recommendations based on the student's personal learning state. Specifically, this integration allows TutorLLM to tailor responses based on individual learning states predicted by the Multi-Features with Latent Relations BERT-based KT (MLFBK) model and to enhance response accuracy with a Scraper model. The evaluation includes user assessment questionnaires and performance metrics, demonstrating a 10\\% improvement in user satisfaction and a 5\\% increase in quiz scores compared to using general LLMs alone.", 'abstract_zh': 'AI在教育中的集成提供了显著潜力以提升学习效率。基于Knowledge Tracing和Retrieval-Augmented Generation的个性化学习推荐系统TutorLLM克服了大型语言模型的挑战。', 'title_zh': 'TutorLLM: 基于知识追踪和检索增强生成的个性化学习推荐'}
{'arxiv_id': 'arXiv:2502.15702', 'title': 'Large language models streamline automated systematic review: A preliminary study', 'authors': 'Xi Chen, Xue Zhang', 'link': 'https://arxiv.org/abs/2502.15702', 'abstract': 'Large Language Models (LLMs) have shown promise in natural language processing tasks, with the potential to automate systematic reviews. This study evaluates the performance of three state-of-the-art LLMs in conducting systematic review tasks. We assessed GPT-4, Claude-3, and Mistral 8x7B across four systematic review tasks: study design formulation, search strategy development, literature screening, and data extraction. Sourced from a previously published systematic review, we provided reference standard including standard PICO (Population, Intervention, Comparison, Outcome) design, standard eligibility criteria, and data from 20 reference literature. Three investigators evaluated the quality of study design and eligibility criteria using 5-point Liker Scale in terms of accuracy, integrity, relevance, consistency and overall performance. For other tasks, the output is defined as accurate if it is the same as the reference standard. Search strategy performance was evaluated through accuracy and retrieval efficacy. Screening accuracy was assessed for both abstracts screening and full texts screening. Data extraction accuracy was evaluated across 1,120 data points comprising 3,360 individual fields. Claude-3 demonstrated superior overall performance in PICO design. In search strategy formulation, GPT-4 and Claude-3 achieved comparable accuracy, outperforming Mistral. For abstract screening, GPT-4 achieved the highest accuracy, followed by Mistral and Claude-3. In data extraction, GPT-4 significantly outperformed other models. LLMs demonstrate potential for automating systematic review tasks, with GPT-4 showing superior performance in search strategy formulation, literature screening and data extraction. These capabilities make them promising assistive tools for researchers and warrant further development and validation in this field.', 'abstract_zh': '大型语言模型在系统评价任务中的性能评估：GPT-4、Claude-3和Mistral 8x7B的表现分析', 'title_zh': '大型语言模型简化自动化系统评价：一项初步研究'}
{'arxiv_id': 'arXiv:2502.15701', 'title': 'Political Events using RAG with LLMs', 'authors': 'Muhammad Arslan, Saba Munawar, Christophe Cruz', 'link': 'https://arxiv.org/abs/2502.15701', 'abstract': "In the contemporary digital landscape, media content stands as the foundation for political news analysis, offering invaluable insights sourced from various channels like news articles, social media updates, speeches, and reports. Natural Language Processing (NLP) has revolutionized Political Information Extraction (IE), automating tasks such as Event Extraction (EE) from these diverse media outlets. While traditional NLP methods often necessitate specialized expertise to build rule-based systems or train machine learning models with domain-specific datasets, the emergence of Large Language Models (LLMs) driven by Generative Artificial Intelligence (GenAI) presents a promising alternative. These models offer accessibility, alleviating challenges associated with model construction from scratch and reducing the dependency on extensive datasets during the training phase, thus facilitating rapid implementation. However, challenges persist in handling domain-specific tasks, leading to the development of the Retrieval-Augmented Generation (RAG) framework. RAG enhances LLMs by integrating external data retrieval, enriching their contextual understanding, and expanding their knowledge base beyond pre-existing training data. To illustrate RAG's efficacy, we introduce the Political EE system, specifically tailored to extract political event information from news articles. Understanding these political insights is essential for remaining informed about the latest political advancements, whether on a national or global scale.", 'abstract_zh': '当代数字景观中，媒体内容构成了政治新闻分析的基础，提供了来自新闻文章、社交媒体更新、演讲和报告等多种渠道的宝贵见解。自然语言处理（NLP）已经革新了政治信息提取（IE），实现了从这些多元媒体渠道自动抽取事件（EE）等功能。虽然传统的NLP方法通常需要专门的专家来构建基于规则的系统或使用特定领域的数据集训练机器学习模型，但由生成式人工智能（GenAI）驱动的大规模语言模型（LLMs）提供了有前景的替代方案。这些模型提高了可访问性，减轻了从头构建模型的挑战，并在训练阶段减少了对大量数据集的依赖，从而促进了快速实施。然而，在处理特定领域的任务时仍存在挑战，因此开发了检索增强生成（RAG）框架。RAG通过集成外部数据检索来增强大规模语言模型，丰富其背景理解，并扩展其知识库，超出其原有训练数据。为了展示RAG的有效性，我们介绍了专门用于从新闻文章中提取政治事件信息的政治EE系统。理解这些政治见解对于了解最新的政治进展（无论是全国性的还是全球性的）至关重要。', 'title_zh': '利用LLMs的RAG进行政治事件处理'}
{'arxiv_id': 'arXiv:2502.15700', 'title': 'Sustainable Digitalization of Business with Multi-Agent RAG and LLM', 'authors': 'Muhammad Arslan, Saba Munawar, Christophe Cruz', 'link': 'https://arxiv.org/abs/2502.15700', 'abstract': "Businesses heavily rely on data sourced from various channels like news articles, financial reports, and consumer reviews to drive their operations, enabling informed decision-making and identifying opportunities. However, traditional manual methods for data extraction are often time-consuming and resource-intensive, prompting the adoption of digital transformation initiatives to enhance efficiency. Yet, concerns persist regarding the sustainability of such initiatives and their alignment with the United Nations (UN)'s Sustainable Development Goals (SDGs). This research aims to explore the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) as a sustainable solution for Information Extraction (IE) and processing. The research methodology involves reviewing existing solutions for business decision-making, noting that many systems require training new machine learning models, which are resource-intensive and have significant environmental impacts. Instead, we propose a sustainable business solution using pre-existing LLMs that can work with diverse datasets. We link domain-specific datasets to tailor LLMs to company needs and employ a Multi-Agent architecture to divide tasks such as information retrieval, enrichment, and classification among specialized agents. This approach optimizes the extraction process and improves overall efficiency. Through the utilization of these technologies, businesses can optimize resource utilization, improve decision-making processes, and contribute to sustainable development goals, thereby fostering environmental responsibility within the corporate sector.", 'abstract_zh': '利用大型语言模型与检索增强生成技术实现可持续信息提取的研究', 'title_zh': '基于多代理RAG和LLM的可持续数字化商业'}
{'arxiv_id': 'arXiv:2502.15697', 'title': 'Robust Uplift Modeling with Large-Scale Contexts for Real-time Marketing', 'authors': 'Zexu Sun, Qiyu Han, Minqin Zhu, Hao Gong, Dugang Liu, Chen Ma', 'link': 'https://arxiv.org/abs/2502.15697', 'abstract': 'Improving user engagement and platform revenue is crucial for online marketing platforms. Uplift modeling is proposed to solve this problem, which applies different treatments (e.g., discounts, bonus) to satisfy corresponding users. Despite progress in this field, limitations persist. Firstly, most of them focus on scenarios where only user features exist. However, in real-world scenarios, there are rich contexts available in the online platform (e.g., short videos, news), and the uplift model needs to infer an incentive for each user on the specific item, which is called real-time marketing. Thus, only considering the user features will lead to biased prediction of the responses, which may cause the cumulative error for uplift prediction. Moreover, due to the large-scale contexts, directly concatenating the context features with the user features will cause a severe distribution shift in the treatment and control groups. Secondly, capturing the interaction relationship between the user features and context features can better predict the user response. To solve the above limitations, we propose a novel model-agnostic Robust Uplift Modeling with Large-Scale Contexts (UMLC) framework for Real-time Marketing. Our UMLC includes two customized modules. 1) A response-guided context grouping module for extracting context features information and condensing value space through clusters. 2) A feature interaction module for obtaining better uplift prediction. Specifically, this module contains two parts: a user-context interaction component for better modeling the response; a treatment-feature interaction component for discovering the treatment assignment sensitive feature of each instance to better predict the uplift. Moreover, we conduct extensive experiments on a synthetic dataset and a real-world product dataset to verify the effectiveness and compatibility of our UMLC.', 'abstract_zh': '提升用户参与度和平台收益对于在线营销平台至关重要。实时营销中的稳健大规模上下文提升 modeling框架（UMLC）在提升预测中的应用', 'title_zh': '面向实时营销的大规模上下文鲁棒提升建模'}
{'arxiv_id': 'arXiv:2502.15696', 'title': 'Integrating Domain Knowledge into Large Language Models for Enhanced Fashion Recommendations', 'authors': 'Zhan Shi, Shanglin Yang', 'link': 'https://arxiv.org/abs/2502.15696', 'abstract': 'Fashion, deeply rooted in sociocultural dynamics, evolves as individuals emulate styles popularized by influencers and iconic figures. In the quest to replicate such refined tastes using artificial intelligence, traditional fashion ensemble methods have primarily used supervised learning to imitate the decisions of style icons, which falter when faced with distribution shifts, leading to style replication discrepancies triggered by slight variations in input. Meanwhile, large language models (LLMs) have become prominent across various sectors, recognized for their user-friendly interfaces, strong conversational skills, and advanced reasoning capabilities. To address these challenges, we introduce the Fashion Large Language Model (FLLM), which employs auto-prompt generation training strategies to enhance its capacity for delivering personalized fashion advice while retaining essential domain knowledge. Additionally, by integrating a retrieval augmentation technique during inference, the model can better adjust to individual preferences. Our results show that this approach surpasses existing models in accuracy, interpretability, and few-shot learning capabilities.', 'abstract_zh': '时装深深植根于社会文化动态，随着个体模仿影响者和icon流行风格而演变。在利用人工智能复制这种精致品味的探索中，传统时尚ensemble方法主要采用监督学习模仿风格icon的决策，在面对分布变化时表现不佳，导致因输入微小变化引发的风格复制偏差。与此同时，大型语言模型（LLMs）已在各种领域中成为主流，因其用户友好的界面、强大的对话能力和高级推理能力而受到认可。为应对这些挑战，我们引入了时尚大型语言模型（FLLM），该模型采用自动提示生成训练策略，增强了提供个性化时尚建议的能力并保留了关键领域知识。另外，在推理过程中通过集成检索增强技术，该模型能够更好地适应个体偏好。我们的结果显示，这种方法在准确率、可解释性和少-shot学习能力方面超越现有模型。', 'title_zh': '将领域知识融入大型语言模型以增强时尚推荐'}
{'arxiv_id': 'arXiv:2502.15695', 'title': 'Social Relation Meets Recommendation: Denoising and Alignment', 'authors': 'Lin Wang, Weisong Wang, Xuanji Xiao, Qing Li', 'link': 'https://arxiv.org/abs/2502.15695', 'abstract': 'Recommender systems have now become an essential part of modern content platforms. Yet, traditional behavior-based recommendation models often struggle with cold users, who have limited interaction data. Despite this, engaging these users is crucial for the ongoing growth of content platforms. To bridge this gap, we propose utilizing the social-relation graph to enrich the interest profiles derived from behavior-based models. While social graphs are ubiquitous on content platforms, extracting value from this data is challenging due to social-relation noise and interest inconsistency. To address the noise propagation issue in graph data and obtain accurate social interest, we employ a dual-view denoising strategy. It first applies low-rank SVD to the user-item matrix to extract denoised user embeddings. These embeddings are then used to generate a reconstructed social graph. Finally, the strategy implements contrastive learning between the original and reconstructed social graphs. Addressing the interest inconsistency between social and behavioral interests, we adopt a mutual distillation technique to isolate the original interests into four sub-interests, namely aligned social/behavior interests and social/behavior specific interests, which maximally fuse the two interests. Experimental results on industry datasets demonstrate the effectiveness of our method, particularly for cold users, verifying that effectively fusing social relations and behaviors can be highly beneficial for modern recommendation platforms.', 'abstract_zh': '推荐系统已成为现代内容平台不可或缺的一部分。然而，传统基于行为的推荐模型在处理冷启动用户时往往表现不佳，这些用户缺乏足够的交互数据。尽管如此，吸引这些用户对于内容平台的持续增长至关重要。为解决这一问题，我们提出利用社会关系图来丰富基于行为模型提取的兴趣轮廓。虽然内容平台上普遍存在社会图，但从中提取价值极具挑战性，因为社会关系噪声和兴趣不一致性问题。为解决图数据中的噪声传播问题并获得准确的社会兴趣，我们采用了一种双视角去噪策略。该策略首先使用低秩SVD对用户-项目矩阵进行处理以提取去噪后的用户嵌入，然后利用这些嵌入构建重构的社会图。最后，该策略在原始社会图和重构社会图之间实施对比学习。为解决社会和行为兴趣之间的不一致性，我们采用了互学生distillation技术，将原始兴趣隔离为四种子兴趣，即对齐的社会/行为兴趣和社会/行为特定兴趣，从而使两种兴趣最大化融合。在工业数据集上的实验结果证明了我们方法的有效性，特别是在冷启动用户上，验证了有效融合社会关系和行为能够显著提升现代推荐平台的表现。', 'title_zh': '社交关系与推荐系统相遇：去噪与对齐'}
{'arxiv_id': 'arXiv:2502.15693', 'title': 'Hgformer: Hyperbolic Graph Transformer for Recommendation', 'authors': 'Xin Yang, Xingrun Li, Heng Chang, Jinze Yang, Xihong Yang, Shengyu Tao, Ningkang Chang, Maiko Shigeno, Junfeng Wang, Dawei Yin, Erxue Min', 'link': 'https://arxiv.org/abs/2502.15693', 'abstract': 'The cold start problem is a challenging problem faced by most modern recommender systems. By leveraging knowledge from other domains, cross-domain recommendation can be an effective method to alleviate the cold start problem. However, the modelling distortion for long-tail data, which is widely present in recommender systems, is often overlooked in cross-domain recommendation. In this research, we propose a hyperbolic manifold based cross-domain collaborative filtering model using BiTGCF as the base model. We introduce the hyperbolic manifold and construct new propagation layer and transfer layer to address these challenges. The significant performance improvements across various datasets compared to the baseline models demonstrate the effectiveness of our proposed model.', 'abstract_zh': '基于双曲流形的跨域BiTGCF协同过滤模型：缓解长尾数据建模偏差', 'title_zh': 'Hgformer: 双曲图transformer在推荐中的应用'}
{'arxiv_id': 'arXiv:2502.15692', 'title': 'ACL-rlg: A Dataset for Reading List Generation', 'authors': 'Julien Aubert-Béduchaud, Florian Boudin, Béatrice Daille, Richard Dufour', 'link': 'https://arxiv.org/abs/2502.15692', 'abstract': 'Familiarizing oneself with a new scientific field and its existing literature can be daunting due to the large amount of available articles. Curated lists of academic references, or reading lists, compiled by experts, offer a structured way to gain a comprehensive overview of a domain or a specific scientific challenge. In this work, we introduce ACL-rlg, the largest open expert-annotated reading list dataset. We also provide multiple baselines for evaluating reading list generation and formally define it as a retrieval task. Our qualitative study highlights the fact that traditional scholarly search engines and indexing methods perform poorly on this task, and GPT-4o, despite showing better results, exhibits signs of potential data contamination.', 'abstract_zh': '熟悉新的科学领域及其现有文献可能会因为可用的文章数量庞大而显得 daunting。由专家编写的 curated 摘要列表提供了一种结构化的方式，以获得某领域或特定科学挑战的全面概述。在这项工作中，我们介绍了 ACL-rlg，这是最大的开放专家标注阅读列表数据集。我们还提供了多种基线以评估阅读列表生成，并正式将此任务定义为检索任务。我们的定性研究指出，传统学术搜索引擎和索引方法在此任务上表现不佳，尽管 GPT-4o 表现更好，但它显示出潜在的数据污染迹象。', 'title_zh': 'ACL-rlg: 一个阅读列表生成数据集'}
{'arxiv_id': 'arXiv:2502.15691', 'title': 'The Synergy of Automated Pipelines with Prompt Engineering and Generative AI in Web Crawling', 'authors': 'Chau-Jian Huang', 'link': 'https://arxiv.org/abs/2502.15691', 'abstract': "Web crawling is a critical technique for extracting online data, yet it poses challenges due to webpage diversity and anti-scraping mechanisms. This study investigates the integration of generative AI tools Claude AI (Sonnet 3.5) and ChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts, PROMPT I (general inference, tested on Yahoo News) and PROMPT II (element-specific, tested on this http URL), we evaluate the code quality and performance of AI-generated scripts. Claude AI consistently outperformed ChatGPT-4.0 in script quality and adaptability, as confirmed by predefined evaluation metrics, including functionality, readability, modularity, and robustness. Performance data were collected through manual testing and structured scoring by three evaluators. Visualizations further illustrate Claude AI's superiority. Anti-scraping solutions, including undetected_chromedriver, Selenium, and fake_useragent, were incorporated to enhance performance. This paper demonstrates how generative AI combined with prompt engineering can simplify and improve web scraping workflows.", 'abstract_zh': '基于生成式AI工具与提示工程的网页抓取技术研究：以Claude AI（Sonnet 3.5）和ChatGPT4.0为例', 'title_zh': '自动化管道与提示工程及生成式AI在网页爬取中的协同作用'}
{'arxiv_id': 'arXiv:2502.15690', 'title': 'Level-Navi Agent: A Framework and benchmark for Chinese Web Search Agents', 'authors': 'Chuanrui Hu, Shichong Xie, Baoxin Wang, Bin Chen, Xiaofeng Cong, Jun Zhang', 'link': 'https://arxiv.org/abs/2502.15690', 'abstract': 'Large language models (LLMs), adopted to understand human language, drive the development of artificial intelligence (AI) web search agents. Compared to traditional search engines, LLM-powered AI search agents are capable of understanding and responding to complex queries with greater depth, enabling more accurate operations and better context recognition. However, little attention and effort has been paid to the Chinese web search, which results in that the capabilities of open-source models have not been uniformly and fairly evaluated. The difficulty lies in lacking three aspects: an unified agent framework, an accurately labeled dataset, and a suitable evaluation metric. To address these issues, we propose a general-purpose and training-free web search agent by level-aware navigation, Level-Navi Agent, accompanied by a well-annotated dataset (Web24) and a suitable evaluation metric. Level-Navi Agent can think through complex user questions and conduct searches across various levels on the internet to gather information for questions. Meanwhile, we provide a comprehensive evaluation of state-of-the-art LLMs under fair settings. To further facilitate future research, source code is available at Github.', 'abstract_zh': '大型语言模型（LLMs）用于理解人类语言，推动了人工智能网络搜索代理的发展。与传统搜索引擎相比，以LLM为动力的AI搜索代理能够以更深的理解和响应复杂查询，从而实现更准确的操作和更好的上下文识别。然而，中文网络搜索的关注度和努力相对较小，导致开源模型的能力缺乏统一和公平的评估。这一问题源于三个方面：缺乏统一的代理框架、准确标记的数据集和合适的评估指标。为解决这些问题，我们提出了一种基于层级感知导航的一般用途且无需训练的网络搜索代理——Level-Navi Agent，并提供了一个详注的数据库（Web24）和合适的评估指标。Level-Navi Agent能够通过跨层级的搜索来理解和回答复杂的用户问题，同时搜集信息。此外，我们还在公平的设置下全面评估了最新的LLM。为促进未来的研究，相关源代码可在Github上获取。', 'title_zh': 'Level-Navi 代理: 一种中文网页搜索代理框架及基准'}
{'arxiv_id': 'arXiv:2502.15688', 'title': 'XPath Agent: An Efficient XPath Programming Agent Based on LLM for Web Crawler', 'authors': 'Yu Li, Bryce Wang, Xinyu Luan', 'link': 'https://arxiv.org/abs/2502.15688', 'abstract': 'We present XPath Agent, a production-ready XPath programming agent specifically designed for web crawling and web GUI testing. A key feature of XPath Agent is its ability to automatically generate XPath queries from a set of sampled web pages using a single natural language query. To demonstrate its effectiveness, we benchmark XPath Agent against a state-of-the-art XPath programming agent across a range of web crawling tasks. Our results show that XPath Agent achieves comparable performance metrics while significantly reducing token usage and improving clock-time efficiency. The well-designed two-stage pipeline allows for seamless integration into existing web crawling or web GUI testing workflows, thereby saving time and effort in manual XPath query development. The source code for XPath Agent is available at this https URL.', 'abstract_zh': 'XPath Agent：一种用于网络爬虫和Web GUI测试的生产级XPath编程代理', 'title_zh': 'XPath代理：基于大语言模型的高效XPath编程代理用于Web爬虫'}
{'arxiv_id': 'arXiv:2502.15684', 'title': 'An Agent Framework for Real-Time Financial Information Searching with Large Language Models', 'authors': 'Jinzheng Li, Jingshu Zhang, Hongguang Li, Yiqing Shen', 'link': 'https://arxiv.org/abs/2502.15684', 'abstract': "Financial decision-making requires processing vast amounts of real-time information while understanding their complex temporal relationships. While traditional search engines excel at providing real-time information access, they often struggle to comprehend sophisticated user intentions and contextual nuances. Conversely, Large Language Models (LLMs) demonstrate reasoning and interaction capabilities but may generate unreliable outputs without access to current data. While recent attempts have been made to combine LLMs with search capabilities, they suffer from (1) restricted access to specialized financial data, (2) static query structures that cannot adapt to dynamic market conditions, and (3) insufficient temporal awareness in result generation. To address these challenges, we present FinSearch, a novel agent-based search framework specifically designed for financial applications that interface with diverse financial data sources including market, stock, and news data. Innovatively, FinSearch comprises four components: (1) an LLM-based multi-step search pre-planner that decomposes user queries into structured sub-queries mapped to specific data sources through a graph representation; (2) a search executor with an LLM-based adaptive query rewriter that executes the searching of each sub-query while dynamically refining the sub-queries in its subsequent node based on intermediate search results; (3) a temporal weighting mechanism that prioritizes information relevance based on the deduced time context from the user's query; (4) an LLM-based response generator that synthesizes results into coherent, contextually appropriate outputs. To evaluate FinSearch, we construct FinSearchBench-24, a benchmark of 1,500 four-choice questions across the stock market, rate changes, monetary policy, and industry developments spanning from June to October 2024.", 'abstract_zh': '金融决策需要处理大量的实时信息并理解其复杂的时序关系。传统搜索引擎在提供实时信息访问方面表现出色，但往往难以理解复杂用户意图和背景细微差异。相反，大型语言模型（LLMs）展示了推理和交互能力，但在没有访问当前数据的情况下可能会生成不可靠的输出。虽然最近尝试将LLMs与搜索功能结合，但这些尝试面临以下挑战：（1）受限于特定金融数据的访问；（2）静态查询结构无法适应动态市场状况；（3）结果生成中缺乏足够的时序意识。为解决这些挑战，我们提出了一种名为FinSearch的新型基于代理的搜索框架，专门针对金融应用，能够接入包括市场、股票和新闻数据在内的多种金融数据来源。创新地，FinSearch包含四个组件：（1）基于LLM的多步搜索预规划器，将用户查询分解为结构化的子查询并通过图表示映射到具体的数据源；（2）具有LLM基础的自适应查询重写器，该搜索执行器执行每个子查询的搜索，同时根据中间搜索结果动态优化后续节点中的子查询；（3）时序加权机制，基于用户查询推断出的时间上下文来优先考虑信息的相关性；（4）基于LLM的响应生成器，将结果合成为符合上下文的连贯输出。为了评估FinSearch，我们构建了FinSearchBench-24基准测试，涵盖从2024年6月到10月的股票市场、利率变化、货币政策和行业动态等领域，共1,500个四选一问题。', 'title_zh': '基于大型语言模型的实时金融信息搜索代理框架'}
