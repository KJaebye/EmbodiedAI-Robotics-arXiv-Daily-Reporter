{'arxiv_id': 'arXiv:2508.20095', 'title': 'Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning', 'authors': 'Jinhao Liang, Sven Koenig, Ferdinando Fioretto', 'link': 'https://arxiv.org/abs/2508.20095', 'abstract': 'Multi-Robot Motion Planning (MRMP) involves generating collision-free trajectories for multiple robots operating in a shared continuous workspace. While discrete multi-agent path finding (MAPF) methods are broadly adopted due to their scalability, their coarse discretization severely limits trajectory quality. In contrast, continuous optimization-based planners offer higher-quality paths but suffer from the curse of dimensionality, resulting in poor scalability with respect to the number of robots. This paper tackles the limitations of these two approaches by introducing a novel framework that integrates discrete MAPF solvers with constrained generative diffusion models. The resulting framework, called Discrete-Guided Diffusion (DGD), has three key characteristics: (1) it decomposes the original nonconvex MRMP problem into tractable subproblems with convex configuration spaces, (2) it combines discrete MAPF solutions with constrained optimization techniques to guide diffusion models capture complex spatiotemporal dependencies among robots, and (3) it incorporates a lightweight constraint repair mechanism to ensure trajectory feasibility. The proposed method sets a new state-of-the-art performance in large-scale, complex environments, scaling to 100 robots while achieving planning efficiency and high success rates.', 'abstract_zh': '多机器人运动规划（MRMP）涉及为多个在共享连续工作空间中操作的机器人生成无碰撞轨迹。虽然离散多代理路径规划（MAPF）方法由于其可扩展性而广泛采用，但其粗粒度离散化严重限制了轨迹质量。相比之下，基于连续优化的规划器提供更高质量的路径，但受到维数灾难的影响，导致随着机器人数量的增加可扩展性较差。本文通过引入一种新的框架，将离散MAPF求解器与受限生成扩散模型相结合，来解决这两种方法的局限性。该框架称为离散引导扩散（DGD），具有三个关键特点：（1）它将原始非凸的MRMP问题分解为具有凸配置空间的可处理子问题；（2）它结合离散MAPF解决方案与受限优化技术，引导扩散模型捕捉机器人间的复杂时空依赖关系；（3）它引入了轻量级约束修复机制以确保轨迹可行性。所提出的方法在大型复杂环境中的性能达到新的最先进水平，可扩展至100个机器人，同时实现高效的规划和高成功率。', 'title_zh': '离散引导扩散for可扩展和安全的多机器人运动规划'}
{'arxiv_id': 'arXiv:2508.19731', 'title': 'Efficient Human-Aware Task Allocation for Multi-Robot Systems in Shared Environments', 'authors': 'Maryam Kazemi Eskeri, Ville Kyrki, Dominik Baumann, Tomasz Piotr Kucner', 'link': 'https://arxiv.org/abs/2508.19731', 'abstract': 'Multi-robot systems are increasingly deployed in applications, such as intralogistics or autonomous delivery, where multiple robots collaborate to complete tasks efficiently. One of the key factors enabling their efficient cooperation is Multi-Robot Task Allocation (MRTA). Algorithms solving this problem optimize task distribution among robots to minimize the overall execution time. In shared environments, apart from the relative distance between the robots and the tasks, the execution time is also significantly impacted by the delay caused by navigating around moving people. However, most existing MRTA approaches are dynamics-agnostic, relying on static maps and neglecting human motion patterns, leading to inefficiencies and delays. In this paper, we introduce \\acrfull{method name}. This method leverages Maps of Dynamics (MoDs), spatio-temporal queryable models designed to capture historical human movement patterns, to estimate the impact of humans on the task execution time during deployment. \\acrshort{method name} utilizes a stochastic cost function that includes MoDs. Experimental results show that integrating MoDs enhances task allocation performance, resulting in reduced mission completion times by up to $26\\%$ compared to the dynamics-agnostic method and up to $19\\%$ compared to the baseline. This work underscores the importance of considering human dynamics in MRTA within shared environments and presents an efficient framework for deploying multi-robot systems in environments populated by humans.', 'abstract_zh': '多机器人系统在仓储物流或自主配送等应用中日益普遍，多个机器人协作高效完成任务是其高效合作的关键因素之一。解诀这一问题的算法通过优化任务分配来最小化整体执行时间。在共享环境中，除了机器人与任务之间的相对距离，导航绕开移动的人所导致的时间延迟也显著影响任务执行时间。然而，大多数现有的多机器人任务分配方法忽略了动力学因素，依赖静态地图并忽视了人类运动模式，导致效率低下和延误。本文介绍了一种新的方法 \\acs{method name}。该方法利用动力学地图（MoDs），此类时空可查询模型用于捕捉历史人类运动模式，以评估部署过程中人类对任务执行时间的影响。\\acs{method name} 使用包含 MoDs 的随机成本函数。实验结果表明，集成 MoDs 提高了任务分配性能，与动力学忽略的方法相比，任务完成时间最多可缩短 26%，与基线方法相比，最多可缩短 19%。本工作强调了在共享环境中考虑人类动力学对多机器人任务分配的重要性，并展示了在人类居住环境中部署多机器人系统的高效框架。', 'title_zh': '共享环境中的高效人类感知任务分配'}
{'arxiv_id': 'arXiv:2508.19429', 'title': 'An Iterative Approach for Heterogeneous Multi-Agent Route Planning with Resource Transportation Uncertainty and Temporal Logic Goals', 'authors': 'Gustavo A. Cardona, Kaier Liang, Cristian-Ioan Vasile', 'link': 'https://arxiv.org/abs/2508.19429', 'abstract': "This paper presents an iterative approach for heterogeneous multi-agent route planning in environments with unknown resource distributions. We focus on a team of robots with diverse capabilities tasked with executing missions specified using Capability Temporal Logic (CaTL), a formal framework built on Signal Temporal Logic to handle spatial, temporal, capability, and resource constraints. The key challenge arises from the uncertainty in the initial distribution and quantity of resources in the environment. To address this, we introduce an iterative algorithm that dynamically balances exploration and task fulfillment. Robots are guided to explore the environment, identifying resource locations and quantities while progressively refining their understanding of the resource landscape. At the same time, they aim to maximally satisfy the mission objectives based on the current information, adapting their strategies as new data is uncovered. This approach provides a robust solution for planning in dynamic, resource-constrained environments, enabling efficient coordination of heterogeneous teams even under conditions of uncertainty. Our method's effectiveness and performance are demonstrated through simulated case studies.", 'abstract_zh': '本文提出了一种迭代方法，用于在资源分布未知的环境中进行异构多智能体路径规划。我们关注一组具有不同能力的机器人，它们的任务是使用能力时序逻辑（CaTL）来执行，CaTL是一种基于信号时序逻辑的正式框架，用于处理空间、时间和能力及资源约束。主要挑战来自于环境资源初始分布及数量的不确定性。为解决这一问题，我们引入了一种迭代算法，动态平衡探索与任务执行。机器人被引导探索环境，逐步识别资源位置和数量，同时不断细化对资源景观的理解。同时，它们基于现有信息最大限度地满足任务目标，并随着新数据的发现调整策略。该方法为动态、资源受限环境下的规划提供了稳健的解决方案，即使在不确定条件下也能高效协调异构团队。通过模拟案例研究展示了该方法的有效性和性能。', 'title_zh': '具有资源运输不确定性及时间逻辑目标的异构多代理路线规划迭代方法'}
{'arxiv_id': 'arXiv:2508.19425', 'title': 'From Stoplights to On-Ramps: A Comprehensive Set of Crash Rate Benchmarks for Freeway and Surface Street ADS Evaluation', 'authors': 'John M. Scanlon, Timothy L McMurry, Yin-Hsiu Chen, Kristofer D. Kusano, Trent Victor', 'link': 'https://arxiv.org/abs/2508.19425', 'abstract': 'This paper presents crash rate benchmarks for evaluating US-based Automated Driving Systems (ADS) for multiple urban areas. The purpose of this study was to extend prior benchmarks focused only on surface streets to additionally capture freeway crash risk for future ADS safety performance assessments. Using publicly available police-reported crash and vehicle miles traveled (VMT) data, the methodology details the isolation of in-transport passenger vehicles, road type classification, and crash typology. Key findings revealed that freeway crash rates exhibit large geographic dependence variations with any-injury-reported crash rates being nearly 3.5 times higher in Atlanta (2.4 IPMM; the highest) when compared to Phoenix (0.7 IPMM; the lowest). The results show the critical need for location-specific benchmarks to avoid biased safety evaluations and provide insights into the vehicle miles traveled (VMT) required to achieve statistical significance for various safety impact levels. The distribution of crash types depended on the outcome severity level. Higher severity outcomes (e.g., fatal crashes) had a larger proportion of single-vehicle, vulnerable road users (VRU), and opposite-direction collisions compared to lower severity (police-reported) crashes. Given heterogeneity in crash types by severity, performance in low-severity scenarios may not be predictive of high-severity outcomes. These benchmarks are additionally used to quantify at the required mileage to show statistically significant deviations from human performance. This is the first paper to generate freeway-specific benchmarks for ADS evaluation and provides a foundational framework for future ADS benchmarking by evaluators and developers.', 'abstract_zh': '本文提出了适用于评估美国多个城市区域自动化驾驶系统（ADS）碰撞率基准，以扩展仅针对城市道路的先前基准，同时捕捉高速公路碰撞风险，为未来ADS安全性能评估提供依据。', 'title_zh': '从红绿灯到匝道：高速公路和城市街道自动驾驶评估的综合碰撞率基准集'}
{'arxiv_id': 'arXiv:2508.20040', 'title': 'Model Science: getting serious about verification, explanation and control of AI systems', 'authors': 'Przemyslaw Biecek, Wojciech Samek', 'link': 'https://arxiv.org/abs/2508.20040', 'abstract': 'The growing adoption of foundation models calls for a paradigm shift from Data Science to Model Science. Unlike data-centric approaches, Model Science places the trained model at the core of analysis, aiming to interact, verify, explain, and control its behavior across diverse operational contexts. This paper introduces a conceptual framework for a new discipline called Model Science, along with the proposal for its four key pillars: Verification, which requires strict, context-aware evaluation protocols; Explanation, which is understood as various approaches to explore of internal model operations; Control, which integrates alignment techniques to steer model behavior; and Interface, which develops interactive and visual explanation tools to improve human calibration and decision-making. The proposed framework aims to guide the development of credible, safe, and human-aligned AI systems.', 'abstract_zh': '基础模型的日益采用需要从数据科学转向模型科学。模型科学将训练好的模型置于分析的核心，旨在跨多种操作环境与模型互动、验证、解释和控制其行为。本文引入了模型科学这一新学科的概念框架，并提出了其四大支柱：验证、解释、控制和界面。验证要求有严格的、情境aware的评估协议；解释是指探索模型内部操作的各种方法；控制结合对齐技术引导模型行为；界面开发交互和可视化工具，以提高人类校准和决策质量。该提出的框架旨在指导可信、安全和人类相合的人工智能系统的开发。', 'title_zh': '模型科学：严肃对待AI系统的验证、解释和控制'}
{'arxiv_id': 'arXiv:2508.20018', 'title': 'SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control', 'authors': 'Quanfeng Lu, Zhantao Ma, Shuai Zhong, Jin Wang, Dahai Yu, Michael K. Ng, Ping Luo', 'link': 'https://arxiv.org/abs/2508.20018', 'abstract': 'The rapid advancement of large vision language models (LVLMs) and agent systems has heightened interest in mobile GUI agents that can reliably translate natural language into interface operations. Existing single-agent approaches, however, remain limited by structural constraints. Although multi-agent systems naturally decouple different competencies, recent progress in multi-agent reinforcement learning (MARL) has often been hindered by inefficiency and remains incompatible with current LVLM architectures. To address these challenges, we introduce SWIRL, a staged workflow for interleaved reinforcement learning designed for multi-agent systems. SWIRL reformulates MARL into a sequence of single-agent reinforcement learning tasks, updating one agent at a time while keeping the others fixed. This formulation enables stable training and promotes efficient coordination across agents. Theoretically, we provide a stepwise safety bound, a cross-round monotonic improvement theorem, and convergence guarantees on return, ensuring robust and principled optimization. In application to mobile GUI control, SWIRL instantiates a Navigator that converts language and screen context into structured plans, and an Interactor that grounds these plans into executable atomic actions. Extensive experiments demonstrate superior performance on both high-level and low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong capability in multi-agent mathematical reasoning, underscoring its potential as a general framework for developing efficient and robust multi-agent systems.', 'abstract_zh': '快速发展的大规模视觉语言模型和代理系统激发了对移动GUI代理的兴趣，这些代理能够可靠地将自然语言转换为界面操作。尽管现有的单代理方法受限于结构约束，多代理系统自然地将不同的能力分离，但最近的多代理强化学习（MARL）进展因效率低下而受到阻碍，并且与当前的大规模视觉语言模型架构不兼容。为应对这些挑战，我们介绍了SWIRL，这是一种针对多代理系统的分阶段 interleaved 强化学习工作流。SWIRL 将 MARL 重新公式化为一系列单代理强化学习任务，每次更新一个代理，而其他代理保持不变。这种公式化使训练更加稳定，并促进了代理间的高效协调。从理论上，我们提供了一步安全界、跨轮次单调改进定理以及收益收敛保证，确保稳健且原则优化。在移动GUI控制的应用中，SWIRL 实现了一个导航器，将语言和屏幕上下文转换为结构化计划，以及一个执行器，将这些计划转化为可执行的原子动作。大量实验表明，SWIRL 在高阶和低阶GUI基准测试中均表现出优越性能。除了GUI任务外，SWIRL 在多代理数学推理方面也展现出强大的能力，证明了其作为开发高效和稳健多代理系统的一般框架的潜力。', 'title_zh': 'SWIRL: 交错强化学习的分阶段工作流在移动GUI控制中'}
{'arxiv_id': 'arXiv:2508.19827', 'title': 'Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?', 'authors': 'Samuel Lewis-Lim, Xingwei Tan, Zhixue Zhao, Nikolaos Aletras', 'link': 'https://arxiv.org/abs/2508.19827', 'abstract': "Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited gains for soft-reasoning problems such as analytical and commonsense reasoning. CoT can also be unfaithful to a model's actual reasoning. We investigate the dynamics and faithfulness of CoT in soft-reasoning tasks across instruction-tuned, reasoning and reasoning-distilled models. Our findings reveal differences in how these models rely on CoT, and show that CoT influence and faithfulness are not always aligned.", 'abstract_zh': '近期的研究表明，Chain-of-Thought（CoT）在分析性和常识性推理等软推理问题上往往只能带来有限的收益。CoT也可能与模型的实际推理不符。我们研究了指令调整、推理和推理提炼模型在软推理任务中CoT的动态及其忠实性。我们的发现揭示了这些模型依赖CoT的方式存在差异，并表明CoT的影响和忠实性并不总是相一致的。', 'title_zh': '分析思维链动态：主动指导还是不忠的事后合理化？'}
{'arxiv_id': 'arXiv:2508.19569', 'title': 'Skill-based Explanations for Serendipitous Course Recommendation', 'authors': 'Hung Chau, Run Yu, Zachary Pardos, Peter Brusilovsky', 'link': 'https://arxiv.org/abs/2508.19569', 'abstract': 'Academic choice is crucial in U.S. undergraduate education, allowing students significant freedom in course selection. However, navigating the complex academic environment is challenging due to limited information, guidance, and an overwhelming number of choices, compounded by time restrictions and the high demand for popular courses. Although career counselors exist, their numbers are insufficient, and course recommendation systems, though personalized, often lack insight into student perceptions and explanations to assess course relevance. In this paper, a deep learning-based concept extraction model is developed to efficiently extract relevant concepts from course descriptions to improve the recommendation process. Using this model, the study examines the effects of skill-based explanations within a serendipitous recommendation framework, tested through the AskOski system at the University of California, Berkeley. The findings indicate that these explanations not only increase user interest, particularly in courses with high unexpectedness, but also bolster decision-making confidence. This underscores the importance of integrating skill-related data and explanations into educational recommendation systems.', 'abstract_zh': '学术选择对于美国本科教育至关重要，赋予学生在课程选择上较大的自由度。然而，由于信息有限、指导不足以及面对众多课程选择带来的复杂性，再加上时间限制和热门课程的高需求，导航学术环境颇具挑战。尽管存在职业顾问，但其数量不足，个性化课程推荐系统虽好，却往往缺乏对学生感知和解释的洞察以评估课程的相关性。本文开发了一个基于深度学习的概念提取模型，以有效从课程描述中提取相关概念，从而改进推荐过程。通过该模型，研究在University of California, Berkeley的AskOski系统框架下测试了基于技能的解释效果。研究结果表明，这些解释不仅增加了用户兴趣，尤其是对于非预期性较高的课程，还能增强决策信心。这凸显了将技能相关数据和解释整合到教育推荐系统中的重要性。', 'title_zh': '基于技能的偶然课程推荐解释'}
{'arxiv_id': 'arXiv:2508.19502', 'title': 'SLIM: Subtrajectory-Level Elimination for More Effective Reasoning', 'authors': 'Xifeng Yao, Chengyuan Ma, Dongyu Lang, Yinhao Ni, Zhiwei Xu, Huarui Xie, Zihao Chen, Guang Shen, Dandan Tu, Yi Bai, Changzheng Zhang', 'link': 'https://arxiv.org/abs/2508.19502', 'abstract': 'In recent months, substantial progress has been made in complex reasoning of Large Language Models, particularly through the application of test-time scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When responding to a query, these models generate an extended reasoning trajectory, during which the model explores, reflects, backtracks, and self-verifies before arriving at a conclusion. However, fine-tuning models with such reasoning trajectories may not always be optimal. Our findings indicate that not all components within these reasoning trajectories contribute positively to the reasoning process; in fact, some components may affect the overall performance negatively. In this study, we divide a reasoning trajectory into individual subtrajectories and develop a "5+2" framework to: (1) systematically identify suboptimal subtrajectories within the reasoning trajectory based on five human-established criteria; (2) assess the independence of the suboptimal subtrajectories identified in (1) from the subsequent content, ensuring that their elimination does not compromise overall flow and coherence of the reasoning process. Additionally, a sampling algorithm, built upon the "5+2" framework, is employed to select data whose reasoning process is free from suboptimal subtrajectories to the highest degree. Experimental results demonstrate that our method can reduce the number of suboptimal subtrajectories by 25.9\\% during the inference. Furthermore, our method achieves an average accuracy of 58.92\\% on highly challenging math benchmarks with only two thirds of training data, surpassing the average accuracy of 58.06\\% achieved with the entire data, and outperforming open-source datasets, when fine-tuning Qwen2.5-Math-7B. Finally, We validated our method under resource constraints and observed improved performance across various inference token limits.', 'abstract_zh': '近期，在大型语言模型的复杂推理领域取得了显著进展，特别是在测试时放缩的应用中。代表性例子包括o1/o3/o4系列和DeepSeek-R1。在响应查询时，这些模型生成了扩展的推理轨迹，期间模型会探索、反思、回溯和自我验证，最终得出结论。然而，使用此类推理轨迹微调模型可能并不总是最优的。我们的研究发现，并非推理轨迹中的所有组成部分都对推理过程有积极贡献；实际上，某些组成部分可能会对整体性能产生负面影响。在本研究中，我们将推理轨迹分解为单独的子轨迹，并开发了一个“5+2”框架：（1）基于五个人类确立的标准系统地识别推理轨迹中的子最优子轨迹；（2）评估（1）中识别的子最优子轨迹与后续内容的独立性，确保它们的消除不会损害推理过程的整体流动性和连贯性。此外，基于“5+2”框架构建的采样算法被用于选择尽可能消除子最优子轨迹的数据。实验结果表明，我们的方法在推理过程中可以减少子最优子轨迹的数量25.9%。此外，仅使用完整数据量的三分之二，我们的方法在高度挑战性的数学基准测试中实现了58.92%的平均准确率，超过了使用全部数据时的58.06%的平均准确率，并且优于微调Qwen2.5-Math-7B时开源数据集的表现。最后，我们在资源受限条件下验证了该方法，并观察到在各种推理 token 限制下性能提升。', 'title_zh': 'SLIM: 基于子轨迹的消除方法以实现更有效的推理'}
{'arxiv_id': 'arXiv:2508.19383', 'title': 'Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science', 'authors': 'Daoyuan Jin, Nick Gunner, Niko Carvajal Janke, Shivranjani Baruah, Kaitlin M. Gold, Yu Jiang', 'link': 'https://arxiv.org/abs/2508.19383', 'abstract': 'Modern plant science increasingly relies on large, heterogeneous datasets, but challenges in experimental design, data preprocessing, and reproducibility hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent system that integrates domain knowledge, data analysis, and machine learning within a structured framework to autonomously conduct data-driven scientific discovery. Once provided with a research question and dataset, Aleks iteratively formulated problems, explored alternative modeling strategies, and refined solutions across multiple cycles without human intervention. In a case study on grapevine red blotch disease, Aleks progressively identified biologically meaningful features and converged on interpretable models with robust performance. Ablation studies underscored the importance of domain knowledge and memory for coherent outcomes. This exploratory work highlights the promise of agentic AI as an autonomous collaborator for accelerating scientific discovery in plant sciences.', 'abstract_zh': '现代植物科学 increasingly relies on large, heterogeneous datasets, but challenges in experimental design, data preprocessing, and reproducibility hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent system that integrates domain knowledge, data analysis, and machine learning within a structured framework to autonomously conduct data-driven scientific discovery.', 'title_zh': 'Aleks：基于数据驱动方法的植物科学自主科学发现的人工智能多智能体系统'}
{'arxiv_id': 'arXiv:2508.20033', 'title': 'DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis', 'authors': 'Liana Patel, Negar Arabzadeh, Harshit Gupta, Ankita Sundar, Ion Stoica, Matei Zaharia, Carlos Guestrin', 'link': 'https://arxiv.org/abs/2508.20033', 'abstract': "The ability to research and synthesize knowledge is central to human expertise and progress. An emerging class of systems promises these exciting capabilities through generative research synthesis, performing retrieval over the live web and synthesizing discovered sources into long-form, cited summaries. However, evaluating such systems remains an open challenge: existing question-answering benchmarks focus on short-form factual responses, while expert-curated datasets risk staleness and data contamination. Both fail to capture the complexity and evolving nature of real research synthesis tasks. In this work, we introduce DeepScholar-bench, a live benchmark and holistic, automated evaluation framework designed to evaluate generative research synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv papers and focuses on a real research synthesis task: generating the related work sections of a paper by retrieving, synthesizing, and citing prior research. Our evaluation framework holistically assesses performance across three key dimensions, knowledge synthesis, retrieval quality, and verifiability. We also develop DeepScholar-base, a reference pipeline implemented efficiently using the LOTUS API. Using the DeepScholar-bench framework, we perform a systematic evaluation of prior open-source systems, search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that DeepScholar-base establishes a strong baseline, attaining competitive or higher performance than each other method. We also find that DeepScholar-bench remains far from saturated, with no system exceeding a score of $19\\%$ across all metrics. These results underscore the difficulty of DeepScholar-bench, as well as its importance for progress towards AI systems capable of generative research synthesis. We make our code available at this https URL.", 'abstract_zh': '基于生成性研究综合的人工智能系统评价框架DeepScholar-bench', 'title_zh': 'DeepScholar-Bench：生成性研究综合的实时基准与自动化评估'}
{'arxiv_id': 'arXiv:2508.20019', 'title': 'Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence', 'authors': 'Ji Wang, Kashing Chen, Xinyuan Song, Ke Zhang, Lynn Ai, Eric Yang, Bill Shi', 'link': 'https://arxiv.org/abs/2508.20019', 'abstract': 'Most existing Large Language Model (LLM)-based agent frameworks rely on centralized orchestration, incurring high deployment costs, rigid communication topologies, and limited adaptability. To address these challenges, we introduce Symphony, a decentralized multi-agent system which enables lightweight LLMs on consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms: (1) a decentralized ledger that records capabilities, (2) a Beacon-selection protocol for dynamic task allocation, and (3) weighted result voting based on CoTs. This design forms a privacy-saving, scalable, and fault-tolerant orchestration with low overhead. Empirically, Symphony outperforms existing baselines on reasoning benchmarks, achieving substantial accuracy gains and demonstrating robustness across models of varying capacities.', 'abstract_zh': '基于大型语言模型的分布式多智能体系统Symphony：轻量级模型在消费级GPU上的去中心化协调', 'title_zh': '交响：一个可扩展集体智能的去中心化多智能体框架'}
{'arxiv_id': 'arXiv:2508.20016', 'title': 'HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling', 'authors': 'Matthias Maiterth, Wesley H. Brewer, Jaya S. Kuruvella, Arunavo Dey, Tanzima Z. Islam, Kevin Menear, Dmitry Duplyakin, Rashadul Kabir, Tapasya Patki, Terry Jones, Feiyi Wang', 'link': 'https://arxiv.org/abs/2508.20016', 'abstract': 'Schedulers are critical for optimal resource utilization in high-performance computing. Traditional methods to evaluate schedulers are limited to post-deployment analysis, or simulators, which do not model associated infrastructure. In this work, we present the first-of-its-kind integration of scheduling and digital twins in HPC. This enables what-if studies to understand the impact of parameter configurations and scheduling decisions on the physical assets, even before deployment, or regarching changes not easily realizable in production. We (1) provide the first digital twin framework extended with scheduling capabilities, (2) integrate various top-tier HPC systems given their publicly available datasets, (3) implement extensions to integrate external scheduling simulators. Finally, we show how to (4) implement and evaluate incentive structures, as-well-as (5) evaluate machine learning based scheduling, in such novel digital-twin based meta-framework to prototype scheduling. Our work enables what-if scenarios of HPC systems to evaluate sustainability, and the impact on the simulated system.', 'abstract_zh': '调度器对于高性能计算中的资源最优化利用至关重要。传统的调度器评估方法限于部署后的分析或使用仿真器，但这些方法不能 modeling 相关的基础设施。在本文中，我们提出了首个将调度与数字孪生集成到 HPC 中的方法。这使得在部署前甚至在生产环境中难以实现的更改时，能够进行假设研究，以理解参数配置和调度决策对物理资产的影响。我们（1）提供了首个集成调度功能的数字孪生框架，（2）集成了各种顶级 HPC 系统，利用其公开的数据集，（3）实现了与外部调度仿真器集成的扩展。最终，我们展示了如何（4）在这样的新型数字孪生元框架中实现和评估激励结构，以及（5）评估基于机器学习的调度，以原型设计调度。我们的工作使 HPC 系统的假设情景能够评估可持续性及其对模拟系统的影响。', 'title_zh': 'HPC数字孪生体评估调度策略、激励结构及其对功耗和冷却的影响'}
{'arxiv_id': 'arXiv:2508.19999', 'title': 'Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation', 'authors': 'Ziniu Zhang, Zhenshuo Zhang, Dongyue Li, Lu Wang, Jennifer Dy, Hongyang R. Zhang', 'link': 'https://arxiv.org/abs/2508.19999', 'abstract': 'This paper introduces an algorithm to select demonstration examples for in-context learning of a query set. Given a set of $n$ examples, how can we quickly select $k$ out of $n$ to best serve as the conditioning for downstream inference? This problem has broad applications in prompt tuning and chain-of-thought reasoning. Since model weights remain fixed during in-context learning, previous work has sought to design methods based on the similarity of token embeddings. This work proposes a new approach based on gradients of the output taken in the input embedding space. Our approach estimates model outputs through a first-order approximation using the gradients. Then, we apply this estimation to multiple randomly sampled subsets. Finally, we aggregate the sampled subset outcomes to form an influence score for each demonstration, and select $k$ most relevant examples. This procedure only requires pre-computing model outputs and gradients once, resulting in a linear-time algorithm relative to model and training set sizes. Extensive experiments across various models and datasets validate the efficiency of our approach. We show that the gradient estimation procedure yields approximations of full inference with less than $\\mathbf{1}\\%$ error across six datasets. This allows us to scale up subset selection that would otherwise run full inference by up to $\\mathbf{37.7}\\times$ on models with up to $34$ billion parameters, and outperform existing selection methods based on input embeddings by $\\mathbf{11}\\%$ on average.', 'abstract_zh': '本文介绍了一种用于查询集上下文学习的演示示例选择算法。给定一个包含$n$个示例的集合，如何快速从这$n$个示例中选择$k$个最佳作为下游推理的条件？这一问题在提示调整和链式推理中具有广泛的应用。由于在上下文学习过程中模型权重保持不变，以往的工作基于令牌嵌入的相似性设计了相关方法。本文提出了一种新的基于输入嵌入空间中输出梯度的方法。我们的方法通过一阶近似计算模型输出，并将其应用于多个随机采样的子集。最后，我们将采样子集的结果聚合为每个演示示例的影响得分，并选择最相关的$k$个示例。该流程只需预计算一次模型输出和梯度，从而相对于模型和训练集的规模实现了线性时间算法。在各种模型和数据集上的广泛实验验证了我们方法的有效性。我们展示了梯度估计过程在六个数据集上提供了低于1%误差的完整推理近似值。这允许我们在具有多达340亿参数的模型上将子集选择的规模扩展多达37.7倍，并且在平均意义上比基于输入嵌入的选择方法提高了11%。', 'title_zh': '基于梯度估计的线性时间示范选择方法以实现情境学习'}
{'arxiv_id': 'arXiv:2508.19914', 'title': 'The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology', 'authors': 'Muhammad Waqas, Rukhmini Bandyopadhyay, Eman Showkatian, Amgad Muneer, Anas Zafar, Frank Rojas Alvarez, Maricel Corredor Marin, Wentao Li, David Jaffray, Cara Haymaker, John Heymach, Natalie I Vokes, Luisa Maren Solis Soto, Jianjun Zhang, Jia Wu', 'link': 'https://arxiv.org/abs/2508.19914', 'abstract': 'Foundation models have recently emerged as powerful feature extractors in computational pathology, yet they typically omit mechanisms for leveraging the global spatial structure of tissues and the local contextual relationships among diagnostically relevant regions - key elements for understanding the tumor microenvironment. Multiple instance learning (MIL) remains an essential next step following foundation model, designing a framework to aggregate patch-level features into slide-level predictions. We present EAGLE-Net, a structure-preserving, attention-guided MIL architecture designed to augment prediction and interpretability. EAGLE-Net integrates multi-scale absolute spatial encoding to capture global tissue architecture, a top-K neighborhood-aware loss to focus attention on local microenvironments, and background suppression loss to minimize false positives. We benchmarked EAGLE-Net on large pan-cancer datasets, including three cancer types for classification (10,260 slides) and seven cancer types for survival prediction (4,172 slides), using three distinct histology foundation backbones (REMEDIES, Uni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher classification accuracy and the top concordance indices in 6 of 7 cancer types, producing smooth, biologically coherent attention maps that aligned with expert annotations and highlighted invasive fronts, necrosis, and immune infiltration. These results position EAGLE-Net as a generalizable, interpretable framework that complements foundation models, enabling improved biomarker discovery, prognostic modeling, and clinical decision support', 'abstract_zh': '基于结构保持、注意力引导的多项实例学习架构EAGLE-Net：增强预测与可解释性', 'title_zh': '下一层：通过结构保留和注意力引导学习局部patches到全局上下文意识增强基础模型'}
{'arxiv_id': 'arXiv:2508.19883', 'title': 'AI-Powered Detection of Inappropriate Language in Medical School Curricula', 'authors': 'Chiman Salavati, Shannon Song, Scott A. Hale, Roberto E. Montenegro, Shiri Dori-Hacohen, Fabricio Murai', 'link': 'https://arxiv.org/abs/2508.19883', 'abstract': "The use of inappropriate language -- such as outdated, exclusionary, or non-patient-centered terms -- medical instructional materials can significantly influence clinical training, patient interactions, and health outcomes. Despite their reputability, many materials developed over past decades contain examples now considered inappropriate by current medical standards. Given the volume of curricular content, manually identifying instances of inappropriate use of language (IUL) and its subcategories for systematic review is prohibitively costly and impractical. To address this challenge, we conduct a first-in-class evaluation of small language models (SLMs) fine-tuned on labeled data and pre-trained LLMs with in-context learning on a dataset containing approximately 500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL classifier, (2) subcategory-specific binary classifiers, (3) a multilabel classifier, and (4) a two-stage hierarchical pipeline for general IUL detection followed by multilabel classification. For LLMs, we consider variations of prompts that include subcategory definitions and/or shots. We found that both LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed by SLMs. While the multilabel classifier performs best on annotated data, supplementing training with unflagged excerpts as negative examples boosts the specific classifiers' AUC by up to 25%, making them most effective models for mitigating harmful language in medical curricula.", 'abstract_zh': '不恰当语言的使用——诸如过时的、排斥性的或非患者中心的术语——在医学教学材料中的应用会对临床培训、患者互动和健康结果产生显著影响。尽管许多过去几十年开发的材料在当前医疗标准下被认为不恰当，但在大量课程内容中，手动识别不恰当语言使用及其子类别的实例以进行系统审查成本高昂且不切实际。为解决这一挑战，我们对小语言模型（SLMs）进行了首次评估，这些模型在标注数据上进行了微调，并使用包含约500份文档和超过12,000页的内容的语境学习预训练大语言模型（LLMs）进行评估。对于SLMs，我们考虑了：（1）通用不恰当语言使用分类器，（2）子类特定的二元分类器，（3）多标签分类器，以及（4）两阶段层次管道，首先进行通用不恰当语言使用检测，然后进行多标签分类。对于LLMs，我们考虑了包含子类定义和/或示例的不同提示形式。我们发现，即使经过精心筛选的示例，LLama-3 8B和70B的表现也大大逊色于SLMs。虽然多标签分类器在标注数据中表现最佳，但将未标记的示例作为负样本补充训练，可以将特定分类器的AUC提高高达25%，使其成为最有效的模型，用于减少医学课程中的有害语言。', 'title_zh': '基于AI的医学课程不适当语言检测'}
{'arxiv_id': 'arXiv:2508.19839', 'title': 'PSO-Merging: Merging Models Based on Particle Swarm Optimization', 'authors': 'Kehao Zhang, Shaolei Zhang, Yang Feng', 'link': 'https://arxiv.org/abs/2508.19839', 'abstract': 'Model merging has emerged as an efficient strategy for constructing multitask models by integrating the strengths of multiple available expert models, thereby reducing the need to fine-tune a pre-trained model for all the tasks from scratch. Existing data-independent methods struggle with performance limitations due to the lack of data-driven guidance. Data-driven approaches also face key challenges: gradient-based methods are computationally expensive, limiting their practicality for merging large expert models, whereas existing gradient-free methods often fail to achieve satisfactory results within a limited number of optimization steps. To address these limitations, this paper introduces PSO-Merging, a novel data-driven merging method based on the Particle Swarm Optimization (PSO). In this approach, we initialize the particle swarm with a pre-trained model, expert models, and sparsified expert models. We then perform multiple iterations, with the final global best particle serving as the merged model. Experimental results on different language models show that PSO-Merging generally outperforms baseline merging methods, offering a more efficient and scalable solution for model merging.', 'abstract_zh': '基于粒子群优化的数据驱动模型融合方法PSO-Merging', 'title_zh': 'PSO-集成：基于粒子群优化的模型集成'}
{'arxiv_id': 'arXiv:2508.19830', 'title': 'Gradient Rectification for Robust Calibration under Distribution Shift', 'authors': 'Yilin Zhang, Cai Xu, You Wu, Ziyu Guan, Wei Zhao', 'link': 'https://arxiv.org/abs/2508.19830', 'abstract': 'Deep neural networks often produce overconfident predictions, undermining their reliability in safety-critical applications. This miscalibration is further exacerbated under distribution shift, where test data deviates from the training distribution due to environmental or acquisition changes. While existing approaches improve calibration through training-time regularization or post-hoc adjustment, their reliance on access to or simulation of target domains limits their practicality in real-world scenarios. In this paper, we propose a novel calibration framework that operates without access to target domain information. From a frequency-domain perspective, we identify that distribution shifts often distort high-frequency visual cues exploited by deep models, and introduce a low-frequency filtering strategy to encourage reliance on domain-invariant features. However, such information loss may degrade In-Distribution (ID) calibration performance. Therefore, we further propose a gradient-based rectification mechanism that enforces ID calibration as a hard constraint during optimization. Experiments on synthetic and real-world shifted datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method significantly improves calibration under distribution shift while maintaining strong in-distribution performance.', 'abstract_zh': '深度神经网络往往产生过度自信的预测，这在安全关键应用中削弱了它们的可靠性。这种失准在分布偏移情况下会进一步加剧，即测试数据因环境或获取方式的变化而偏离训练数据分布。尽管现有方法通过训练时正则化或事后调整来改善校准，但它们依赖于访问目标域信息或模拟目标域的能力，这限制了它们在实际场景中的实用性。在本文中，我们提出了一种无需访问目标域信息的新型校准框架。从频域的角度来看，我们发现分布偏移往往会扭曲深度模型所利用的高频视觉线索，并引入了低频滤波策略以鼓励依赖域不变特征。然而，这种信息损失可能降低就分布内（ID）校准性能。因此，我们进一步提出了一种基于梯度的矫正机制，在优化过程中将其作为硬约束以确保ID校准。实验结果表明，我们的方法在分布偏移情况下显著提高了校准性能，同时保持了强大的就分布内性能。', 'title_zh': '梯度归一化以适应分布迁移的稳健校准'}
{'arxiv_id': 'arXiv:2508.19819', 'title': 'From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning', 'authors': 'Viktor Valadi, Mattias Åkesson, Johan Östman, Salman Toor, Andreas Hellander', 'link': 'https://arxiv.org/abs/2508.19819', 'abstract': 'Gradient inversion attacks have garnered attention for their ability to compromise privacy in federated learning. However, many studies consider attacks with the model in inference mode, where training-time behaviors like dropout are disabled and batch normalization relies on fixed statistics. In this work, we systematically analyze how architecture and training behavior affect vulnerability, including the first in-depth study of inference-mode clients, which we show dramatically simplifies inversion. To assess attack feasibility under more realistic conditions, we turn to clients operating in standard training mode. In this setting, we find that successful attacks are only possible when several architectural conditions are met simultaneously: models must be shallow and wide, use skip connections, and, critically, employ pre-activation normalization. We introduce two novel attacks against models in training-mode with varying attacker knowledge, achieving state-of-the-art performance under realistic training conditions. We extend these efforts by presenting the first attack on a production-grade object-detection model. Here, to enable any visibly identifiable leakage, we revert to the lenient inference mode setting and make multiple architectural modifications to increase model vulnerability, with the extent of required changes highlighting the strong inherent robustness of such architectures. We conclude this work by offering the first comprehensive mapping of settings, clarifying which combinations of architectural choices and operational modes meaningfully impact privacy. Our analysis provides actionable insight into when models are likely vulnerable, when they appear robust, and where subtle leakage may persist. Together, these findings reframe how gradient inversion risk should be assessed in future research and deployment scenarios.', 'abstract_zh': '基于梯度反向攻击在联邦学习中对隐私威胁的研究：从推理模式到训练模式的系统分析与攻击方法探索', 'title_zh': '从研究到现实：联邦学习中梯度 inversion 攻击的可行性'}
{'arxiv_id': 'arXiv:2508.19807', 'title': 'Bootstrapping Learned Cost Models with Synthetic SQL Queries', 'authors': 'Michael Nidd, Christoph Miksovic, Thomas Gschwind, Francesco Fusco, Andrea Giovannini, Ioana Giurgiu', 'link': 'https://arxiv.org/abs/2508.19807', 'abstract': "Having access to realistic workloads for a given database instance is extremely important to enable stress and vulnerability testing, as well as to optimize for cost and performance. Recent advances in learned cost models have shown that when enough diverse SQL queries are available, one can effectively and efficiently predict the cost of running a given query against a specific database engine. In this paper, we describe our experience in exploiting modern synthetic data generation techniques, inspired by the generative AI and LLM community, to create high-quality datasets enabling the effective training of such learned cost models. Initial results show that we can improve a learned cost model's predictive accuracy by training it with 45% fewer queries than when using competitive generation approaches.", 'abstract_zh': '基于现代合成数据生成技术利用现实工作负载进行成本模型训练的经验分享：使用较少的查询提高预测准确性', 'title_zh': '用合成SQL查询 bootstrap 训练学习到的成本模型'}
{'arxiv_id': 'arXiv:2508.19708', 'title': 'Attention is also needed for form design', 'authors': 'B. Sankar, Dibakar Sen', 'link': 'https://arxiv.org/abs/2508.19708', 'abstract': "Conventional product design is a cognitively demanding process, limited by its time-consuming nature, reliance on subjective expertise, and the opaque translation of inspiration into tangible concepts. This research introduces a novel, attention-aware framework that integrates two synergistic systems: EUPHORIA, an immersive Virtual Reality environment using eye-tracking to implicitly capture a designer's aesthetic preferences, and RETINA, an agentic AI pipeline that translates these implicit preferences into concrete design outputs. The foundational principles were validated in a two-part study. An initial study correlated user's implicit attention with explicit preference and the next one correlated mood to attention. A comparative study where 4 designers solved challenging design problems using 4 distinct workflows, from a manual process to an end-to-end automated pipeline, showed the integrated EUPHORIA-RETINA workflow was over 4 times more time-efficient than the conventional method. A panel of 50 design experts evaluated the 16 final renderings. Designs generated by the fully automated system consistently received the highest Worthiness (calculated by an inverse Plackett-Luce model based on gradient descent optimization) and Design Effectiveness scores, indicating superior quality across 8 criteria: novelty, visual appeal, emotional resonance, clarity of purpose, distinctiveness of silhouette, implied materiality, proportional balance, & adherence to the brief. This research presents a validated paradigm shift from traditional Computer-Assisted Design (CAD) to a collaborative model of Designer-Assisting Computers (DAC). By automating logistical and skill-dependent generative tasks, the proposed framework elevates the designer's role to that of a creative director, synergizing human intuition with the generative power of agentic AI to produce higher-quality designs more efficiently.", 'abstract_zh': '一种基于注意力的整合框架：从直观偏好到Concrete设计输出', 'title_zh': '也需要关注表单设计。'}
{'arxiv_id': 'arXiv:2508.19683', 'title': 'Topological Uncertainty for Anomaly Detection in the Neural-network EoS Inference with Neutron Star Data', 'authors': 'Kenji Fukushima, Syo Kamata', 'link': 'https://arxiv.org/abs/2508.19683', 'abstract': 'We study the performance of the Topological Uncertainty (TU) constructed with a trained feedforward neural network (FNN) for Anomaly Detection. Generally, meaningful information can be stored in the hidden layers of the trained FNN, and the TU implementation is one tractable recipe to extract buried information by means of the Topological Data Analysis. We explicate the concept of the TU and the numerical procedures. Then, for a concrete demonstration of the performance test, we employ the Neutron Star data used for inference of the equation of state (EoS). For the training dataset consisting of the input (Neutron Star data) and the output (EoS parameters), we can compare the inferred EoSs and the exact answers to classify the data with the label $k$. The subdataset with $k=0$ leads to the normal inference for which the inferred EoS approximates the answer well, while the subdataset with $k=1$ ends up with the unsuccessful inference. Once the TU is prepared based on the $k$-labled subdatasets, we introduce the cross-TU to quantify the uncertainty of characterizing the $k$-labeled data with the label $j$. The anomaly or unsuccessful inference is correctly detected if the cross-TU for $j=k=1$ is smaller than that for $j=0$ and $k=1$. In our numerical experiment, for various input data, we calculate the cross-TU and estimate the performance of Anomaly Detection. We find that performance depends on FNN hyperparameters, and the success rate of Anomaly Detection exceeds $90\\%$ in the best case. We finally discuss further potential of the TU application to retrieve the information hidden in the trained FNN.', 'abstract_zh': 'Topological Uncertainty (TU) 构建的训练前馈神经网络（FNN）在异常检测中的性能研究', 'title_zh': '基于中子星数据的神经网络EoS推断中的拓扑不确定性异常检测'}
{'arxiv_id': 'arXiv:2508.19660', 'title': 'Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation', 'authors': 'Vojtech Mrazek, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Zdenek Vasicek, Mehdi B. Tahoori, Georgios Zervakis', 'link': 'https://arxiv.org/abs/2508.19660', 'abstract': 'Printed electronics offer a promising alternative for applications beyond silicon-based systems, requiring properties like flexibility, stretchability, conformality, and ultra-low fabrication costs. Despite the large feature sizes in printed electronics, printed neural networks have attracted attention for meeting target application requirements, though realizing complex circuits remains challenging. This work bridges the gap between classification accuracy and area efficiency in printed neural networks, covering the entire processing-near-sensor system design and co-optimization from the analog-to-digital interface-a major area and power bottleneck-to the digital classifier. We propose an automated framework for designing printed Ternary Neural Networks with arbitrary input precision, utilizing multi-objective optimization and holistic approximation. Our circuits outperform existing approximate printed neural networks by 17x in area and 59x in power on average, being the first to enable printed-battery-powered operation with under 5% accuracy loss while accounting for analog-to-digital interfacing costs.', 'abstract_zh': '印刷电子为超越硅基系统应用提供了有前景的替代方案，需要具备灵活性、可拉伸性、贴合性以及极低的制造成本等特性。尽管印刷电子具有较大的特征尺寸，其神经网络仍因其满足目标应用需求的潜力而受到关注，但实现复杂电路依然具有挑战性。本工作在印刷神经网络中填补了分类准确率和区域效率之间的差距，涵盖了从模拟-数字接口（一个主要的面积和功耗瓶颈）到数字分类器的整个感知器附近系统设计和联合优化。我们提出了一种自动设计具有任意输入精度的印刷三值神经网络的框架，利用多目标优化和整体逼近方法。我们的电路在平均面积上比现有近似印刷神经网络高出17倍，在功耗上高出近59倍，是首个能够在不超过5%准确率损失的情况下实现印刷电池供电操作的设计。', 'title_zh': '全方位进化近似下的任意精度打印三值神经网络'}
{'arxiv_id': 'arXiv:2508.19641', 'title': 'Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses', 'authors': 'Lincan Li, Bolin Shen, Chenxi Zhao, Yuxiang Sun, Kaixiang Zhao, Shirui Pan, Yushun Dong', 'link': 'https://arxiv.org/abs/2508.19641', 'abstract': 'Graph-structured data, which captures non-Euclidean relationships and interactions between entities, is growing in scale and complexity. As a result, training state-of-the-art graph machine learning (GML) models have become increasingly resource-intensive, turning these models and data into invaluable Intellectual Property (IP). To address the resource-intensive nature of model training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an efficient solution by leveraging third-party cloud services for model development and management. However, deploying such models in GMLaaS also exposes them to potential threats from attackers. Specifically, while the APIs within a GMLaaS system provide interfaces for users to query the model and receive outputs, they also allow attackers to exploit and steal model functionalities or sensitive training data, posing severe threats to the safety of these GML models and the underlying graph data. To address these challenges, this survey systematically introduces the first taxonomy of threats and defenses at the level of both GML model and graph-structured data. Such a tailored taxonomy facilitates an in-depth understanding of GML IP protection. Furthermore, we present a systematic evaluation framework to assess the effectiveness of IP protection methods, introduce a curated set of benchmark datasets across various domains, and discuss their application scopes and future challenges. Finally, we establish an open-sourced versatile library named PyGIP, which evaluates various attack and defense techniques in GMLaaS scenarios and facilitates the implementation of existing benchmark methods. The library resource can be accessed at: this https URL. We believe this survey will play a fundamental role in intellectual property protection for GML and provide practical recipes for the GML community.', 'abstract_zh': '基于图结构数据的机器学习模型和数据的知识产权保护研究', 'title_zh': '基于图的机器学习即服务中的知识产权：攻击与防御'}
{'arxiv_id': 'arXiv:2508.19637', 'title': 'Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge', 'authors': 'Maha Shatta, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Georgios Panagopoulos, Mehdi B. Tahoori, Georgios Zervakis', 'link': 'https://arxiv.org/abs/2508.19637', 'abstract': 'Flexible Electronics (FE) offer a promising alternative to rigid silicon-based hardware for wearable healthcare devices, enabling lightweight, conformable, and low-cost systems. However, their limited integration density and large feature sizes impose strict area and power constraints, making ML-based healthcare systems-integrating analog frontend, feature extraction and classifier-particularly challenging. Existing FE solutions often neglect potential system-wide solutions and focus on the classifier, overlooking the substantial hardware cost of feature extraction and Analog-to-Digital Converters (ADCs)-both major contributors to area and power consumption. In this work, we present a holistic mixed-signal feature-to-classifier co-design framework for flexible smart wearable systems. To the best of our knowledge, we design the first analog feature extractors in FE, significantly reducing feature extraction cost. We further propose an hardware-aware NAS-inspired feature selection strategy within ML training, enabling efficient, application-specific designs. Our evaluation on healthcare benchmarks shows our approach delivers highly accurate, ultra-area-efficient flexible systems-ideal for disposable, low-power wearable monitoring.', 'abstract_zh': '柔性电子（FE）为可穿戴健康设备提供了有前途的替代于刚性硅基硬件的选择，使其能够实现轻量化、贴合性好且低成本的系统。然而，其有限的集成密度和较大的特征尺寸对基于机器学习（ML）的健康监护系统提出了严格的面积和功率限制，尤其是涉及到模拟前端、特征提取和分类器的集成。现有的FE解决方案通常忽视了系统级的整体优化，主要集中在分类器的优化上，而忽视了特征提取和模数转换器（ADC）的显著硬件成本，这两者都是面积和功耗的主要贡献者。在本文中，我们提出了一种适用于柔性智能可穿戴系统的端到端混合信号特征-分类器协同设计框架。据我们所知，我们设计了第一代用于柔性电子的模拟特征提取器，大幅降低了特征提取的成本。我们进一步提出了一种基于硬件感知的类神经架构搜索（NAS）启发式的特征选择策略，该策略可以在机器学习训练过程中启用高效且应用场景特定的设计。我们在健康监护领域的基准测试中评估了我们的方法，结果表明，该方法能够实现高精度且超紧凑面积的柔性系统，适用于一次性使用的低功耗可穿戴监测设备。', 'title_zh': '邀请论文：面向极端边缘的混合信号智能可穿戴健康护理设备的特征到分类器协同设计'}
{'arxiv_id': 'arXiv:2508.19630', 'title': 'Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition', 'authors': 'Xiaolei Wei, Yi Ouyang, Haibo Ye', 'link': 'https://arxiv.org/abs/2508.19630', 'abstract': 'Long-tailed visual recognition is challenging not only due to class imbalance but also because of varying classification difficulty across categories. Simply reweighting classes by frequency often overlooks those that are intrinsically hard to learn. To address this, we propose \\textbf{DQRoute}, a modular framework that combines difficulty-aware optimization with dynamic expert collaboration. DQRoute first estimates class-wise difficulty based on prediction uncertainty and historical performance, and uses this signal to guide training with adaptive loss weighting. On the architectural side, DQRoute employs a mixture-of-experts design, where each expert specializes in a different region of the class distribution. At inference time, expert predictions are weighted by confidence scores derived from expert-specific OOD detectors, enabling input-adaptive routing without the need for a centralized router. All components are trained jointly in an end-to-end manner. Experiments on standard long-tailed benchmarks demonstrate that DQRoute significantly improves performance, particularly on rare and difficult classes, highlighting the benefit of integrating difficulty modeling with decentralized expert routing.', 'abstract_zh': '长尾视觉识别不仅由于类别不平衡而具有挑战性，还因为不同类别之间的分类难度各异。简单地按频率重新加权类别往往忽视了那些本质上难以学习的类别。为此，我们提出了一种名为DQRoute的模块化框架，该框架结合了难度感知优化与动态专家协作。DQRoute首先基于预测不确定性及历史性能估算类别层面的难度，并使用此信号引导具有自适应损失加权的训练。在架构方面，DQRoute采用混合专家设计，其中每个专家专注于类分布的不同区域。在推理阶段，专家预测由专家特定的OOD检测器得出的置信分数加权，无需中心路由器即可实现输入自适应路由。所有组件以端到端的方式联合训练。在标准长尾基准测试上的实验表明，DQRoute显著改善了性能，特别是在稀有和困难类别上，强调了将难度建模与分散式专家路由集成的好处。', 'title_zh': '分而治之，加权，路由：基于动态专家融合的难度感知优化方法及其在长尾识别中的应用'}
{'arxiv_id': 'arXiv:2508.19625', 'title': 'Training for Obsolescence? The AI-Driven Education Trap', 'authors': 'Andrew J. Peterson', 'link': 'https://arxiv.org/abs/2508.19625', 'abstract': "Artificial intelligence simultaneously transforms human capital production in schools and its demand in labor markets. Analyzing these effects in isolation can lead to a significant misallocation of educational resources. We model an educational planner whose decision to adopt AI is driven by its teaching productivity, failing to internalize AI's future wage-suppressing effect on those same skills. Our core assumption, motivated by a pilot survey, is that there is a positive correlation between these two effects. This drives our central proposition: this information failure creates a skill mismatch that monotonically increases with AI prevalence. Extensions show the mismatch is exacerbated by the neglect of unpriced non-cognitive skills and by a school's endogenous over-investment in AI. Our findings caution that policies promoting AI in education, if not paired with forward-looking labor market signals, may paradoxically undermine students' long-term human capital, especially if reliance on AI crowds out the development of unpriced non-cognitive skills, such as persistence, that are forged through intellectual struggle.", 'abstract_zh': '人工智能同时转型学校中的人力资本生产和劳动力市场对其需求。孤立分析这些影响可能导致教育资源的重大错配。我们建模了一个教育规划者，其采用人工智能的决策由其教学生产力驱动，未能 internalize 人工智能对未来同技能工资抑制效应的影响。我们的核心假设，基于试点调查，是这两者效应之间存在正相关关系。这驱动我们的中心命题：这种信息失败导致技能 mismatch，并且这种 mismatch 随着人工智能普及率增加而单调增加。扩展研究显示，由于未考虑无价的非认知技能以及学校内生过度投资人工智能，这种 mismatch 被加剧。我们的研究成果警示，在教育中推广人工智能若未配有前瞻性的劳动力市场信号，可能会出乎意料地削弱学生长期的人力资本，尤其是在人工智能可能挤占通过智力斗争锻造的无价非认知技能（如毅力）的发展时。', 'title_zh': '人工智能驱动的教育陷阱：人才培养走向过时？'}
{'arxiv_id': 'arXiv:2508.19621', 'title': 'Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning', 'authors': 'Tiandi Ye, Wenyan Liu, Kai Yao, Lichun Li, Shangchao Su, Cen Chen, Xiang Li, Shan Yin, Ming Gao', 'link': 'https://arxiv.org/abs/2508.19621', 'abstract': "Federated learning (FL) is a privacy-preserving machine learning paradigm that enables collaborative model training across multiple distributed clients without disclosing their raw data. Personalized federated learning (pFL) has gained increasing attention for its ability to address data heterogeneity. However, most existing pFL methods assume that each client's data follows a single distribution and learn one client-level personalized model for each client. This assumption often fails in practice, where a single client may possess data from multiple sources or domains, resulting in significant intra-client heterogeneity and suboptimal performance. To tackle this challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework based on visual prompt tuning. Specifically, we formulate instance-wise prompt generation from a Bayesian perspective and model the prompt posterior as an implicit distribution to capture diverse visual semantics. We derive a variational training objective under the semi-implicit variational inference framework. Extensive experiments on benchmark datasets demonstrate that pFedBayesPT consistently outperforms existing pFL methods under both feature and label heterogeneity settings.", 'abstract_zh': 'Federated 学习（FL）是一种隐私保护的机器学习范式，能够在不泄露原始数据的情况下，实现多个分布式客户端之间的协作模型训练。个性化联邦学习（pFL）因其能够解决数据异质性问题而逐渐受到关注。然而，大多数现有 pFL 方法假设每个客户端的数据遵循单一分布，并为每个客户端学习一个客户端级别的个性化模型。这一假设在实践中往往不成立，因为单个客户端可能拥有来自多个来源或领域的数据，导致显著的客户端内部异质性和次优性能。为了解决这一挑战，我们提出了一种基于视觉提示调优的细粒度实例级 pFL 框架 pFedBayesPT。具体而言，我们从贝叶斯角度形式化实例级提示生成，并将提示后验建模为隐式分布以捕获多样的视觉语义。在半隐式变分推理框架下，我们推导了变分训练目标。在基准数据集上的广泛实验表明，pFedBayesPT 在特征异质性和标签异质性设置下均能优于现有 pFL 方法。', 'title_zh': '基于半隐式贝叶斯提示调优的实例化个性化联邦学习'}
{'arxiv_id': 'arXiv:2508.19620', 'title': 'A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions', 'authors': 'Yunqi Mi, Jiakui Shen, Guoshuai Zhao, Jialie Shen, Xueming Qian', 'link': 'https://arxiv.org/abs/2508.19620', 'abstract': "Extending recommender systems to federated learning (FL) frameworks to protect the privacy of users or platforms while making recommendations has recently gained widespread attention in academia. This is due to the natural coupling of recommender systems and federated learning architectures: the data originates from distributed clients (mostly mobile devices held by users), which are highly related to privacy. In a centralized recommender system (CenRec), the central server collects clients' data, trains the model, and provides the service. Whereas in federated recommender systems (FedRec), the step of data collecting is omitted, and the step of model training is offloaded to each client. The server only aggregates the model and other knowledge, thus avoiding client privacy leakage. Some surveys of federated recommender systems discuss and analyze related work from the perspective of designing FL systems. However, their utility drops by ignoring specific recommendation scenarios' unique characteristics and practical challenges. For example, the statistical heterogeneity issue in cross-domain FedRec originates from the label drift of the data held by different platforms, which is mainly caused by the recommender itself, but not the federated architecture. Therefore, it should focus more on solving specific problems in real-world recommendation scenarios to encourage the deployment FedRec. To this end, this review comprehensively analyzes the coupling of recommender systems and federated learning from the perspective of recommendation researchers and practitioners. We establish a clear link between recommendation scenarios and FL frameworks, systematically analyzing scenario-specific approaches, practical challenges, and potential opportunities. We aim to develop guidance for the real-world deployment of FedRec, bridging the gap between existing research and applications.", 'abstract_zh': '扩展推荐系统到联邦学习框架中以保护用户或平台隐私的同时进行推荐近期在学术界引起了广泛关注。', 'title_zh': '面向场景的联邦推荐系统综述：技术、挑战及未来方向'}
{'arxiv_id': 'arXiv:2508.19609', 'title': 'FinCast: A Foundation Model for Financial Time-Series Forecasting', 'authors': 'Zhuohang Zhu, Haodong Chen, Qiang Qu, Vera Chung', 'link': 'https://arxiv.org/abs/2508.19609', 'abstract': 'Financial time-series forecasting is critical for maintaining economic stability, guiding informed policymaking, and promoting sustainable investment practices. However, it remains challenging due to various underlying pattern shifts. These shifts arise primarily from three sources: temporal non-stationarity (distribution changes over time), multi-domain diversity (distinct patterns across financial domains such as stocks, commodities, and futures), and varying temporal resolutions (patterns differing across per-second, hourly, daily, or weekly indicators). While recent deep learning methods attempt to address these complexities, they frequently suffer from overfitting and typically require extensive domain-specific fine-tuning. To overcome these limitations, we introduce FinCast, the first foundation model specifically designed for financial time-series forecasting, trained on large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot performance, effectively capturing diverse patterns without domain-specific fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate that FinCast surpasses existing state-of-the-art methods, highlighting its strong generalization capabilities.', 'abstract_zh': '金融时间序列预测对于维护经济稳定、指导明智的政策制定和促进可持续投资实践至关重要，但由于存在多种潜在模式变化，这项任务仍然具有挑战性。这些变化主要源于三大来源：时间非平稳性（随时间变化的分布）、多领域多样性（金融领域如股票、商品和期货之间的不同模式）以及不同的时间分辨率（在每秒、小时、日或周指标之间变化的模式）。尽管最近的深度学习方法试图解决这些复杂性，但它们通常容易出现过拟合并通常需要大量的领域特定微调。为克服这些限制，我们提出了FinCast，这是第一个专门设计用于金融时间序列预测的基础模型，并在大规模金融数据集上进行了训练。令人remarkably的是，FinCast在零样本情况下表现出稳健的性能，能够有效地捕捉多样化的模式而无需领域特定微调。全面的实证和定性评估表明，FinCast超越了现有的最优方法，突显了其强大的泛化能力。', 'title_zh': 'FinCast: 金融时间序列预测的基础模型'}
{'arxiv_id': 'arXiv:2508.19604', 'title': 'IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation', 'authors': 'Qizhe Fan, Chaoyu Liu, Zhonghua Qiao, Xiaoqin Shen', 'link': 'https://arxiv.org/abs/2508.19604', 'abstract': "Domain Generalized Semantic Segmentation (DGSS) focuses on training a model using labeled data from a source domain, with the goal of achieving robust generalization to unseen target domains during inference. A common approach to improve generalization is to augment the source domain with synthetic data generated by diffusion models (DMs). However, the generated images often contain structural or semantic defects due to training imperfections. Training segmentation models with such flawed data can lead to performance degradation and error accumulation. To address this issue, we propose to integrate inverse evolution layers (IELs) into the generative process. IELs are designed to highlight spatial discontinuities and semantic inconsistencies using Laplacian-based priors, enabling more effective filtering of undesirable generative patterns. Based on this mechanism, we introduce IELDM, an enhanced diffusion-based data augmentation framework that can produce higher-quality images. Furthermore, we observe that the defect-suppression capability of IELs can also benefit the segmentation network by suppressing artifact propagation. Based on this insight, we embed IELs into the decoder of the DGSS model and propose IELFormer to strengthen generalization capability in cross-domain scenarios. To further strengthen the model's semantic consistency across scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module, which performs frequency-domain analysis to achieve structured integration of multi-resolution features, thereby improving cross-scale coherence. Extensive experiments on benchmark datasets demonstrate that our approach achieves superior generalization performance compared to existing methods.", 'abstract_zh': '跨域通用语义分割（DGSS）通过利用源域标注数据训练模型，旨在通过推理实现对未见过的目标域的稳健泛化。一种改进泛化的常见方法是通过扩散模型生成数据增强源域。然而，生成的图像由于训练缺陷往往包含结构或语义缺陷。使用这些有缺陷的数据训练分割模型会导致性能下降和错误累积。为解决这一问题，我们提出将逆进化层（IELs）整合到生成过程。IELs设计用于利用拉普拉斯先验强调空间不连续性和语义不一致性，从而更有效地过滤不希望的生成模式。基于这一机制，我们引入了IELDM，一种增强的基于扩散的数据增强框架，能够生成更高质量的图像。此外，我们观察到IELs的缺陷抑制能力也可以通过抑制伪影传播来造福分割网络。基于这一洞察，我们将IELs嵌入到DGSS模型的解码器中，并提出IELFormer以增强跨域场景下的泛化能力。为了进一步增强模型跨尺度的语义一致性，IELFormer整合了一个多尺度频率融合（MFF）模块，该模块在频域分析的基础上实现多分辨率特征的结构化集成，从而提高跨尺度的一致性。在基准数据集上的实验表明，我们的方法在泛化性能上优于现有方法。', 'title_zh': 'IELDG：基于逆进化层抑制领域特定噪声的领域自适应语义分割'}
{'arxiv_id': 'arXiv:2508.19603', 'title': 'CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation', 'authors': 'Zhejing Hu, Yan Liu, Gong Chen, Bruce X.B. Yu', 'link': 'https://arxiv.org/abs/2508.19603', 'abstract': 'Generative artificial intelligence in music has made significant strides, yet it still falls short of the substantial achievements seen in natural language processing, primarily due to the limited availability of music data. Knowledge-informed approaches have been shown to enhance the performance of music generation models, even when only a few pieces of musical knowledge are integrated. This paper seeks to leverage comprehensive music theory in AI-driven music generation tasks, such as algorithmic composition and style transfer, which traditionally require significant manual effort with existing techniques. We introduce a novel automatic music lexicon construction model that generates a lexicon, named CompLex, comprising 37,432 items derived from just 9 manually input category keywords and 5 sentence prompt templates. A new multi-agent algorithm is proposed to automatically detect and mitigate hallucinations. CompLex demonstrates impressive performance improvements across three state-of-the-art text-to-music generation models, encompassing both symbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of completeness, accuracy, non-redundancy, and executability, confirming that it possesses the key characteristics of an effective lexicon.', 'abstract_zh': '生成式人工智能在音乐领域的进展显著，但仍逊色于自然语言处理领域取得的重大成果，主要原因是可用于音乐的数据有限。基于知识的方法已被证明能够提升音乐生成模型的表现，即使只整合少量的音乐知识也是如此。本文旨在利用全面的音乐理论来增强AI驱动的音乐生成任务，如算法作曲和风格转移，这些任务通常需要大量的人工操作。我们引入了一种新的自动音乐词汇表构建模型，该模型生成了一个名为CompLex的词汇表，包含37,432个项目，仅凭9个手动输入的类别关键词和5个句子提示模板。我们提出了一种新的多智能体算法，以自动检测和缓解幻觉现象。CompLex在三种最先进的文本到音乐生成模型中均表现出显著的性能改进，涵盖符号和基于音频的方法。此外，我们从完备性、准确性、非冗余性和可执行性等方面评估了CompLex，证实了其具备有效词汇表的关键特征。', 'title_zh': 'CompLex: 由自主代理构建的音乐理论词汇表用于自动音乐生成'}
{'arxiv_id': 'arXiv:2508.19588', 'title': 'Hallucinating with AI: AI Psychosis as Distributed Delusions', 'authors': 'Lucy Osler', 'link': 'https://arxiv.org/abs/2508.19588', 'abstract': 'There is much discussion of the false outputs that generative AI systems such as ChatGPT, Claude, Gemini, DeepSeek, and Grok create. In popular terminology, these have been dubbed AI hallucinations. However, deeming these AI outputs hallucinations is controversial, with many claiming this is a metaphorical misnomer. Nevertheless, in this paper, I argue that when viewed through the lens of distributed cognition theory, we can better see the dynamic and troubling ways in which inaccurate beliefs, distorted memories and self-narratives, and delusional thinking can emerge through human-AI interactions; examples of which are popularly being referred to as cases of AI psychosis. In such cases, I suggest we move away from thinking about how an AI system might hallucinate at us, by generating false outputs, to thinking about how, when we routinely rely on generative AI to help us think, remember, and narrate, we can come to hallucinate with AI. This can happen when AI introduces errors into the distributed cognitive process, but it can also happen when AI sustains, affirms, and elaborates on our own delusional thinking and self-narratives, such as in the case of Jaswant Singh Chail. I also examine how the conversational style of chatbots can lead them to play a dual-function, both as a cognitive artefact and a quasi-Other with whom we co-construct our beliefs, narratives, and our realities. It is this dual function, I suggest, that makes generative AI an unusual, and particularly seductive, case of distributed cognition.', 'abstract_zh': '生成式AI系统如ChatGPT、Claude、Gemini、DeepSeek和Grok生成的虚假输出的讨论 incessantly。这些输出被称为AI幻觉。然而，将这些AI输出称为幻觉是有争议的，许多人认为这是一种比喻性的误称。尽管如此，本文认为，从分布式认知理论的视角来看，我们能更好地揭示不准确信念、扭曲记忆和自我叙述以及妄想思维通过人机交互如何动态和令人不安地产生的过程；这些过程现被称为AI精神病案例。在这种情况下，我建议我们不应从AI系统如何向我们产生虚假输出的角度来考虑其幻觉，而应从我们依赖生成式AI来思考、回忆和叙述时，如何与AI一起产生幻觉的角度来考虑。这不仅发生在AI引入错误进入分布式认知过程的情况下，也可能发生在AI巩固、肯定并进一步阐述我们自身的妄想思维和自我叙述的情况下，如贾万特·辛格·查伊尔案。此外，我还探讨了聊天机器人的对话风格如何使它们在认知工具和准他者的双重角色之间发挥作用，我们一起构建我们的信念、叙述和现实。我认为，正是这种双重功能，使生成式AI成为一个不同寻常而且尤其具有诱惑力的分布式认知案例。', 'title_zh': 'AI幻觉：人工智能妄想症作为分布式妄想'}
{'arxiv_id': 'arXiv:2508.19587', 'title': 'Towards stable AI systems for Evaluating Arabic Pronunciations', 'authors': 'Hadi Zaatiti, Hatem Hajri, Osama Abdullah, Nader Masmoudi', 'link': 'https://arxiv.org/abs/2508.19587', 'abstract': "Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and sentence-level transcription, yet struggle to classify isolated letters. In this study, we show that this phoneme-level task, crucial for language learning, speech therapy, and phonetic research, is challenging because isolated letters lack co-articulatory cues, provide no lexical context, and last only a few hundred milliseconds. Recogniser systems must therefore rely solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic (pharyngealized) consonants and other sounds with no close analogues in many languages. This study introduces a diverse, diacritised corpus of isolated Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models achieve only 35% accuracy on it. Training a lightweight neural network on wav2vec embeddings raises performance to 65%. However, adding a small amplitude perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we apply adversarial training, limiting the noisy-speech drop to 9% while preserving clean-speech accuracy. We detail the corpus, training pipeline, and evaluation protocol, and release, on demand, data and code for reproducibility. Finally, we outline future work extending these methods to word- and sentence-level frameworks, where precise letter pronunciation remains critical.", 'abstract_zh': '现代阿拉伯语ASR系统如wav2vec 2.0在单词和句级转录方面表现出色，但在孤立字母分类方面遇到困难。本研究展示了这一对语言学习、语音疗法和音系研究至关重要的音素级任务的挑战性，因为孤立字母缺乏连音线索，提供不了词汇上下文，并且仅持续几毫秒。因此，识别系统必须依赖于多变的声学线索，而阿拉伯语中的强发音（咽鸣化）辅音和其他许多语言中找不到对应音的发音加剧了这一难度。本研究引入了一个多样化的、注音的孤立阿拉伯字母语料库，并证明最先进的wav2vec 2.0模型在其上只能达到35%的准确率。通过在wav2vec嵌入上训练一个轻量级神经网络，准确率提高到65%。然而，添加一小幅度扰动（ε=0.05）将准确率降至32%。为了恢复鲁棒性，我们应用对抗训练，将噪声语音下降限制在9%，同时保持干净语音的准确率。我们详细介绍了语料库、训练流程和评估协议，并根据需求提供数据和代码以确保可重复性。最后，我们概述了未来的工作，旨在将这些方法扩展到词级和句级框架，其中精确的字母发音仍然至关重要。', 'title_zh': '面向阿拉伯发音评估的稳定AI系统研究'}
{'arxiv_id': 'arXiv:2508.19570', 'title': 'Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era', 'authors': 'Dawei Li, Yue Huang, Ming Li, Tianyi Zhou, Xiangliang Zhang, Huan Liu', 'link': 'https://arxiv.org/abs/2508.19570', 'abstract': 'Generative models such as Large Language Models, Diffusion Models, and generative adversarial networks have recently revolutionized the creation of synthetic data, offering scalable solutions to data scarcity, privacy, and annotation challenges in data mining. This tutorial introduces the foundations and latest advances in synthetic data generation, covers key methodologies and practical frameworks, and discusses evaluation strategies and applications. Attendees will gain actionable insights into leveraging generative synthetic data to enhance data mining research and practice. More information can be found on our website: this https URL.', 'abstract_zh': '生成模型（如大型语言模型、扩散模型和生成对抗网络）最近在合成数据的生成方面引发了革命，提供了应对数据挖掘中数据稀缺性、隐私和标注挑战的可扩展解决方案。本教程介绍了合成数据生成的基础和最新进展，涵盖了关键方法学和实用框架，并讨论了评估策略和应用。参与者将获得有关利用生成合成数据以增强数据挖掘研究和实践的实用见解。更多详细信息请参见我们的网站：this https URL。', 'title_zh': '合成数据的生成模型：在通用人工智能时代转型数据挖掘'}
{'arxiv_id': 'arXiv:2508.19566', 'title': 'Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks', 'authors': 'Chen Shang, Jiadong Yu, Dinh Thai Hoang', 'link': 'https://arxiv.org/abs/2508.19566', 'abstract': 'This work proposes an energy-efficient, learning-based beamforming scheme for integrated sensing and communication (ISAC)-enabled V2X networks. Specifically, we first model the dynamic and uncertain nature of V2X environments as a Markov Decision Process. This formulation allows the roadside unit to generate beamforming decisions based solely on current sensing information, thereby eliminating the need for frequent pilot transmissions and extensive channel state information acquisition. We then develop a deep reinforcement learning (DRL) algorithm to jointly optimize beamforming and power allocation, ensuring both communication throughput and sensing accuracy in highly dynamic scenario. To address the high energy demands of conventional learning-based schemes, we embed spiking neural networks (SNNs) into the DRL framework. Leveraging their event-driven and sparsely activated architecture, SNNs significantly enhance energy efficiency while maintaining robust performance. Simulation results confirm that the proposed method achieves substantial energy savings and superior communication performance, demonstrating its potential to support green and sustainable connectivity in future V2X systems.', 'abstract_zh': '面向ISAC增强V2X网络的节能学习导向波束形成方案', 'title_zh': '基于ISAC使能的V2X网络的高效学习导向波束forming技术'}
{'arxiv_id': 'arXiv:2508.19564', 'title': 'Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models', 'authors': 'Yuhang Liu, Tao Li, Zhehao Huang, Zuopeng Yang, Xiaolin Huang', 'link': 'https://arxiv.org/abs/2508.19564', 'abstract': "Fine-tuning large-scale pre-trained models with limited data presents significant challenges for generalization. While Sharpness-Aware Minimization (SAM) has proven effective in improving generalization by seeking flat minima, its substantial extra memory and computation overhead make it impractical for large models. Integrating SAM with parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA) is a promising direction. However, we find that directly applying SAM to LoRA parameters limits the sharpness optimization to a restricted subspace, hindering its effectiveness. To address this limitation, we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an auxiliary LoRA module to model SAM's adversarial weight perturbations. It decouples SAM's weight perturbations from LoRA optimization: the primary LoRA module adapts to specific tasks via standard gradient descent, while the auxiliary module captures the sharpness of the loss landscape through gradient ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness for achieving flatter minima while remaining memory-efficient. Another important benefit is that the dual design allows for simultaneous optimization and perturbation, eliminating SAM's doubled training costs. Extensive experiments across diverse tasks and architectures demonstrate Bi-LoRA's efficiency and effectiveness in enhancing generalization.", 'abstract_zh': '细粒度低秩适应结合Sharpness-Aware Minimization以增强泛化能力', 'title_zh': 'Bi-LoRA: 高效的锋利感知最小化方法用于大规模模型微调'}
{'arxiv_id': 'arXiv:2508.19544', 'title': 'WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization', 'authors': 'Eduardo Davalos, Yike Zhang, Namrata Srivastava, Yashvitha Thatigotla, Jorge A. Salas, Sara McFadden, Sun-Joo Cho, Amanda Goodwin, Ashwin TS, Gautam Biswas', 'link': 'https://arxiv.org/abs/2508.19544', 'abstract': 'With advancements in AI, new gaze estimation methods are exceeding state-of-the-art (SOTA) benchmarks, but their real-world application reveals a gap with commercial eye-tracking solutions. Factors like model size, inference time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking methods lack sufficient accuracy, in particular due to head movement. To tackle these issues, we introduce We bEyeTrack, a framework that integrates lightweight SOTA gaze estimation models directly in the browser. It incorporates model-based head pose estimation and on-device few-shot learning with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new users, achieving SOTA performance with an error margin of 2.32 cm on GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14. Our open-source code is available at this https URL.', 'abstract_zh': '基于AI的眼球估计方法取得了显著进展，但其实用应用暴露出与商用眼动追踪解决方案之间的差距。因素如模型尺寸、推理时间和隐私往往被忽视。与此同时，基于网络摄像头的眼动追踪方法由于头部运动缺乏足够的准确性。为了应对这些问题，我们引入了WebEyeTrack框架，该框架直接在浏览器中集成轻量级的先进技术的眼球估计模型。它结合了基于模型的头部姿态估计和设备端的少量样本学习，所需校准样本数少于9个。WebEyeTrack能够适应新用户，在GazeCapture上的误差 margin 为2.32 cm，并在iPhone 14上实现实时推理速度为2.4毫秒。我们的开源代码可在以下链接获取。', 'title_zh': 'WEBEYETRACK：基于设备端少量样本个性化的眼动追踪浏览器扩展'}
{'arxiv_id': 'arXiv:2508.19517', 'title': 'Orchid: Orchestrating Context Across Creative Workflows with Generative AI', 'authors': 'Srishti Palani, Gonzalo Ramos', 'link': 'https://arxiv.org/abs/2508.19517', 'abstract': "Context is critical for meaningful interactions between people and Generative AI (GenAI). Yet mainstream tools offer limited means to orchestrate it, particularly across workflows that span multiple interactions, sessions, and models, as often occurs in creative projects. Re specifying prior details, juggling diverse artifacts, and dealing with context drift overwhelm users, obscure intent, and curtail creativity. To address these challenges, we present Orchid, a system that gives its users affordances to specify, reference, and monitor context throughout evolving workflows. Specifically, Orchid enables users to (1) specify context related to the project, themselves, and different styles, (2) reference these via explicit mentions, inline selection, or implicit grounding, and (3) monitor context assigned to different interactions across the workflow. In a within-subjects study (n=12), participants using Orchid to execute creative tasks (compared to a baseline toolkit of web search, LLM-based chat, and digital notebooks) produced more novel and feasible outcomes, reporting greater alignment between their intent and the AI's responses, higher perceived control, and increased transparency. By prioritizing context orchestration, Orchid offers an actionable step toward next generation GenAI tools that support complex, iterative workflows - enabling creators and AI to stay aligned and augment their creative potential.", 'abstract_zh': 'Context对人类与生成式AI有意义的交互至关重要。然而，主流工具在跨多个交互、会话和模型的 workflows 中协调 Context 的能力有限。重新指定先前的详细信息、处理多样化的 artefacts 及应对 Context 游移令用户不堪重负，模糊了意图并抑制了创造力。为应对这些挑战，我们提出了 Orchid 系统，该系统为用户提供在整个 evolving workflows 中指定、引用和监控 Context 的功能。具体来说，Orchid 允许用户（1）指定与项目、自身及不同风格相关的 Context，（2）通过明确提及、内联选择或隐式关联来引用这些 Context，以及（3）监控 workflow 中不同交互分配的 Context。在一项单被试设计的研究（n=12）中，与使用基于 web 搜索、LLM 基础的聊天及数字笔记的基线工具包相比，使用 Orchid 执行创造性任务的参与者产生了更多新颖且可行的结果，报告了更高的意图与 AI 反应的对齐度、更高的感知控制感及更大的透明度。通过优先考虑 Context 的协调，Orchid 提供了一个有意义的步骤，迈向支持复杂迭代 workflows 的下一代生成式 AI 工具，使创造者和 AI 能够保持一致并增强其创造力。', 'title_zh': 'Orchid: 以生成式AI orchestrating 跨创意工作流的上下文'}
{'arxiv_id': 'arXiv:2508.19507', 'title': 'A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation', 'authors': 'Kyungho Kim, Sunwoo Kim, Geon Lee, Kijung Shin', 'link': 'https://arxiv.org/abs/2508.19507', 'abstract': "In e-commerce, where users face a vast array of possible item choices, recommender systems are vital for helping them discover suitable items they might otherwise overlook. While many recommender systems primarily rely on a user's purchase history, recent multi-behavior recommender systems incorporate various auxiliary user behaviors, such as item clicks and cart additions, to enhance recommendations. Despite their overall performance gains, their effectiveness varies considerably between visited items (i.e., those a user has interacted with through auxiliary behaviors) and unvisited items (i.e., those with which the user has had no such interactions). Specifically, our analysis reveals that (1) existing multi-behavior recommender systems exhibit a significant gap in recommendation quality between the two item types (visited and unvisited items) and (2) achieving strong performance on both types with a single model architecture remains challenging. To tackle these issues, we propose a novel multi-behavior recommender system, MEMBER. It employs a mixture-of-experts framework, with experts designed to recommend the two item types, respectively. Each expert is trained using a self-supervised method specialized for its design goal. In our comprehensive experiments, we show the effectiveness of MEMBER across both item types, achieving up to 65.46\\% performance gain over the best competitor in terms of Hit Ratio@20.", 'abstract_zh': '电子商务中，面对大量商品选择，推荐系统对于帮助用户发现潜在感兴趣的物品至关重要。尽管许多推荐系统主要依赖用户的购买历史，最近的多行为推荐系统通过纳入诸如item点击和加入购物车等辅助用户行为来提升推荐效果。尽管在总体性能上有所提升，但这些系统的有效性在已访问物品（即用户通过辅助行为与之交互的物品）和未访问物品（即未与用户产生此类交互的物品）之间存在显著差异。具体而言，我们的分析表明（1）现有的多行为推荐系统在已访问物品和未访问物品上的推荐质量存在显著差距；（2）同时在一个模型架构上实现两种物品类型的高性能仍然具有挑战性。为解决这些问题，我们提出了一种新的多行为推荐系统MEMBER。MEMBER采用混合专家框架，针对两种类型的物品分别设计专家进行推荐。每个专家使用为其设计目标量身定制的自监督方法进行训练。在我们全面的实验中，MEMBER在两种物品类型上均表现出色，相对于最佳竞争对手，在命中率@20上实现了高达65.46%的性能提升。', 'title_zh': '一种自我监督的 Experts 混合框架用于多行为推荐'}
{'arxiv_id': 'arXiv:2508.19500', 'title': 'Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills', 'authors': 'David Noever', 'link': 'https://arxiv.org/abs/2508.19500', 'abstract': 'This paper identifies and analyzes a novel vulnerability class in Model Context Protocol (MCP) based agent systems. The attack chain describes and demonstrates how benign, individually authorized tasks can be orchestrated to produce harmful emergent behaviors. Through systematic analysis using the MITRE ATLAS framework, we demonstrate how 95 agents tested with access to multiple services-including browser automation, financial analysis, location tracking, and code deployment-can chain legitimate operations into sophisticated attack sequences that extend beyond the security boundaries of any individual service. These red team exercises survey whether current MCP architectures lack cross-domain security measures necessary to detect or prevent a large category of compositional attacks. We present empirical evidence of specific attack chains that achieve targeted harm through service orchestration, including data exfiltration, financial manipulation, and infrastructure compromise. These findings reveal that the fundamental security assumption of service isolation fails when agents can coordinate actions across multiple domains, creating an exponential attack surface that grows with each additional capability. This research provides a barebones experimental framework that evaluate not whether agents can complete MCP benchmark tasks, but what happens when they complete them too well and optimize across multiple services in ways that violate human expectations and safety constraints. We propose three concrete experimental directions using the existing MCP benchmark suite.', 'abstract_zh': '基于Model Context Protocol (MCP)代理系统的新型漏洞类别的识别与分析', 'title_zh': '仆人、跟踪者、猎手：一个诚实、乐于助人且无害（3H）代理如何解锁对抗性技能'}
{'arxiv_id': 'arXiv:2508.19499', 'title': 'Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery', 'authors': 'Xiangxu Wang, Tianhong Zhao, Wei Tu, Bowen Zhang, Guanzhou Chen, Jinzhou Cao', 'link': 'https://arxiv.org/abs/2508.19499', 'abstract': 'Origin-Destination (OD) flow matrices are essential for urban mobility analysis, underpinning applications in traffic forecasting, infrastructure planning, and policy design. However, existing methods suffer from two critical limitations: (1) reliance on auxiliary features (e.g., Points of Interest, socioeconomic statistics) that are costly to collect and have limited spatial coverage; and (2) sensitivity to spatial topology, where minor index reordering of urban regions (e.g., census tract relabeling) disrupts structural coherence in generated flows. To address these challenges, we propose Sat2Flow, a latent structure-aware diffusion-based framework that generates structurally coherent OD flows using solely satellite imagery as input. Our approach introduces a multi-kernel encoder to capture diverse regional interactions and employs a permutation-aware diffusion process that aligns latent representations across different regional orderings. Through a joint contrastive training objective that bridges satellite-derived features with OD patterns, combined with equivariant diffusion training that enforces structural consistency, Sat2Flow ensures topological robustness under arbitrary regional reindexing. Experimental results on real-world urban datasets demonstrate that Sat2Flow outperforms both physics-based and data-driven baselines in numerical accuracy while preserving empirical distributions and spatial structures under index permutations. Sat2Flow offers a globally scalable solution for OD flow generation in data-scarce urban environments, eliminating region-specific auxiliary data dependencies while maintaining structural invariance for robust mobility modeling.', 'abstract_zh': '基于卫星影像的latent结构意识扩散框架Sat2Flow：解决OD流生成中的地域重构问题', 'title_zh': 'Sat2Flow：一种基于结构意识的卫星图像人体流动生成扩散框架'}
{'arxiv_id': 'arXiv:2508.19488', 'title': 'PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense', 'authors': 'Xavier Cadet, Simona Boboila, Sie Hendrata Dharmawan, Alina Oprea, Peter Chin', 'link': 'https://arxiv.org/abs/2508.19488', 'abstract': 'Cyber defense requires automating defensive decision-making under stealthy, deceptive, and continuously evolving adversarial strategies. The FlipIt game provides a foundational framework for modeling interactions between a defender and an advanced adversary that compromises a system without being immediately detected. In FlipIt, the attacker and defender compete to control a shared resource by performing a Flip action and paying a cost. However, the existing FlipIt frameworks rely on a small number of heuristics or specialized learning techniques, which can lead to brittleness and the inability to adapt to new attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym environment that extends the FlipIt game to allow efficient learning for attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent reinforcement learning (MARL) approach that leverages population-based training to train defender agents equipped to generalize against a range of unknown, potentially adaptive opponents. Our empirical results suggest that Flip-PSRO defenders are $2\\times$ more effective than baselines to generalize to a heuristic attack not exposed in training. In addition, our newly designed ownership-based utility functions ensure that Flip-PSRO defenders maintain a high level of control while optimizing performance.', 'abstract_zh': '针对隐形、欺骗性和持续演变的对手策略的自动化防御决策要求网络防御需升级。FlipIt游戏提供了建模防御者与高级对手之间交互的基础框架，该对手会隐蔽地侵袭系统而不立即被发现。在FlipIt中，攻击者和防御者通过执行“翻转”动作争夺共享资源，并为此支付成本。然而，现有的FlipIt框架依赖少量启发式或专业学习技术，这可能导致防御系统的脆弱性和无法适应新威胁。为克服这些限制，我们引入了PoolFlip，一种多智能体学习环境，它可以扩展FlipIt游戏，以实现攻击者和防御者之间的高效学习。此外，我们提出了Flip-PSRO，一种多智能体强化学习（MARL）方法，利用基于群体的训练来训练能够泛化对抗一系列未知且可能适应对手的防御代理。我们的实证结果表明，Flip-PSRO防御者比基线方法更有效地泛化至未在训练中暴露的启发式攻击。此外，我们新设计的所有权为基础的效用函数确保Flip-PSRO防御者在优化性能的同时保持高度的控制能力。', 'title_zh': 'PoolFlip: 一种用于网络防御的多agent强化学习安全环境'}
{'arxiv_id': 'arXiv:2508.19487', 'title': 'Data-Efficient Symbolic Regression via Foundation Model Distillation', 'authors': 'Wangyang Ying, Jinghan Zhang, Haoyue Bai, Nanxu Gong, Xinyuan Wang, Kunpeng Liu, Chandan K. Reddy, Yanjie Fu', 'link': 'https://arxiv.org/abs/2508.19487', 'abstract': 'Discovering interpretable mathematical equations from observed data (a.k.a. equation discovery or symbolic regression) is a cornerstone of scientific discovery, enabling transparent modeling of physical, biological, and economic systems. While foundation models pre-trained on large-scale equation datasets offer a promising starting point, they often suffer from negative transfer and poor generalization when applied to small, domain-specific datasets. In this paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer Embeddings), a data-efficient fine-tuning framework that adapts foundation models for symbolic equation discovery in low-data regimes via distillation. EQUATE combines symbolic-numeric alignment with evaluator-guided embedding optimization, enabling a principled embedding-search-generation paradigm. Our approach reformulates discrete equation search as a continuous optimization task in a shared embedding space, guided by data-equation fitness and simplicity. Experiments across three standard public benchmarks (Feynman, Strogatz, and black-box datasets) demonstrate that EQUATE consistently outperforms state-of-the-art baselines in both accuracy and robustness, while preserving low complexity and fast inference. These results highlight EQUATE as a practical and generalizable solution for data-efficient symbolic regression in foundation model distillation settings.', 'abstract_zh': '从观测数据中发现可解释的数学方程（又称方程发现或符号回归）是科学发现的基础，能够透明地建模物理、生物和经济系统。尽管预训练在大规模方程数据集上的基础模型为这一任务提供了前景，但在应用于小规模的领域特定数据集时，它们往往会出现负迁移和泛化能力差的问题。在本文中，我们提出了EQUATE（通过质量对齐转移嵌入进行方程生成），这是一种数据高效微调框架，通过蒸馏适应基础模型在低数据量情况下的符号方程发现。EQUATE结合了符号-数值对齐与评估器引导嵌入优化，使得在共享嵌入空间中实现有原则的嵌入-搜索-生成范式成为可能。我们的方法将离散方程搜索重新表述为在共享嵌入空间中连续优化任务，并受到数据-方程适应度和简洁性的指导。在三个标准公开基准（Feynman、Strogatz和黑盒数据集）上的实验结果证明，EQUATE在准确性和鲁棒性上始终优于最先进的基线方法，同时保持低复杂性和快速推理。这些结果突显了EQUATE在基础模型蒸馏设置中高效符号回归的一种实用且可推广的解决方案。', 'title_zh': '基于基础模型精炼的高效符号回归'}
{'arxiv_id': 'arXiv:2508.19472', 'title': 'SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis', 'authors': 'Kyler Katz, Sara Moshtari, Ibrahim Mujhid, Mehdi Mirakhorli, Derek Garcia', 'link': 'https://arxiv.org/abs/2508.19472', 'abstract': 'Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a persistent and under-addressed threat across software systems, often leading to serious security breaches. Existing detection tools rarely target the diverse subcategories of CWE-200 or provide context-aware analysis of code-level data flows.\nAims: This paper aims to present SIExVulTS, a novel vulnerability detection system that integrates transformer-based models with static analysis to identify and verify sensitive information exposure in Java applications.\nMethod: SIExVulTS employs a three-stage architecture: (1) an Attack Surface Detection Engine that uses sentence embeddings to identify sensitive variables, strings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates CodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification Engine that leverages GraphCodeBERT to semantically validate source-to-sink flows. We evaluate SIExVulTS using three curated datasets, including real-world CVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31 open-source projects.\nResults: The Attack Surface Detection Engine achieved an average F1 score greater than 93\\%, the Exposure Analysis Engine achieved an F1 score of 85.71\\%, and the Flow Verification Engine increased precision from 22.61\\% to 87.23\\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs in major Apache projects.\nConclusions: The results demonstrate that SIExVulTS is effective and practical for improving software security against sensitive data exposure, addressing limitations of existing tools in detecting and verifying CWE-200 vulnerabilities.', 'abstract_zh': 'Sensitive Information Exposure (SIEx) 漏洞 (CWE-200) 仍然是软件系统中一个持续存在的且未充分应对的安全威胁，经常导致严重的安全泄露。现有的检测工具很少针对 CWE-200 的多样子类别，或是在代码级数据流分析中提供上下文感知。\n\n目的：本文旨在介绍结合基于变换器的模型与静态分析以识别和验证 Java 应用中敏感信息暴露的新型漏洞检测系统 SIExVulTS。\n\n方法：SIExVulTS 采用三阶段架构：（1）攻击面检测引擎，使用句子嵌入来识别敏感变量、字符串、注释和漏洞点；（2）暴露分析引擎，实例化与 CWE-200 分层结构对齐的 CodeQL 查询；（3）流动验证引擎，利用 GraphCodeBERT 语义验证源到漏点的流动。我们使用三个定制数据集评估 SIExVulTS，包括实际的 CVE、基准集中的合成 CWE-200 示例以及 31 个开源项目中的标记流动。\n\n结果：攻击面检测引擎的平均 F1 分数高于 93%，暴露分析引擎的 F1 分数为 85.71%，流动验证引擎将精准度从 22.61% 提高到 87.23%。此外，SIExVulTS 成功发现了六个主要 Apache 项目的未知 CVE。\n\n结论：结果表明，SIExVulTS 对于提高软件对敏感数据暴露的安全性是有效的且实际的，解决了现有工具在检测和验证 CWE-200 漏洞方面的局限性。', 'title_zh': 'SIExVulTS：基于变压器模型和静态分析的敏感信息暴露漏洞检测系统'}
{'arxiv_id': 'arXiv:2508.19467', 'title': 'Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset', 'authors': 'Sumon Kanti Dey, Jeanne M. Powell, Azra Ismail, Jeanmarie Perrone, Abeed Sarker', 'link': 'https://arxiv.org/abs/2508.19467', 'abstract': "Nonmedical opioid use is an urgent public health challenge, with far-reaching clinical and social consequences that are often underreported in traditional healthcare settings. Social media platforms, where individuals candidly share first-person experiences, offer a valuable yet underutilized source of insight into these impacts. In this study, we present a named entity recognition (NER) framework to extract two categories of self-reported consequences from social media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal, depression) and SocialImpacts (e.g., job loss). To support this task, we introduce RedditImpacts 2.0, a high-quality dataset with refined annotation guidelines and a focus on first-person disclosures, addressing key limitations of prior work. We evaluate both fine-tuned encoder-based models and state-of-the-art large language models (LLMs) under zero- and few-shot in-context learning settings. Our fine-tuned DeBERTa-large model achieves a relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming LLMs in precision, span accuracy, and adherence to task-specific guidelines. Furthermore, we show that strong NER performance can be achieved with substantially less labeled data, emphasizing the feasibility of deploying robust models in resource-limited settings. Our findings underscore the value of domain-specific fine-tuning for clinical NLP tasks and contribute to the responsible development of AI tools that may enhance addiction surveillance, improve interpretability, and support real-world healthcare decision-making. The best performing model, however, still significantly underperforms compared to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap persists between expert intelligence and current state-of-the-art NER/AI capabilities for tasks requiring deep domain knowledge.", 'abstract_zh': '非医疗用途阿片类药物使用是迫切的公共卫生挑战，其广泛的临床和社会后果在传统医疗保健环境中常被低估。社交媒体平台，个人在这里坦诚分享第一人称经历，提供了有价值的但尚未充分利用的洞察来源。本研究提出了一种命名实体识别（NER）框架，用于从与阿片类药物使用相关的社交媒体叙述中提取两类自我报告的后果：临床影响（如戒断、抑郁）和社会影响（如失业）。为支持这一任务，我们引入了RedditImpacts 2.0，这是一个高质量的数据集，具有改进的标注指南，重点关注第一人称披露，解决了先前工作中的关键局限性。我们在零样本和少量样本的上下文学习设置中评估了微调编码器模型和最先进的大规模语言模型（LLMs）。我们的微调DeBERTa-large模型在放松的令牌级别F1上达到0.61 [95% CI: 0.43-0.62]，在精确度、跨度准确性和遵循特定任务指南方面始终优于LLMs。此外，我们展示了在几乎少得多的标注数据下仍可实现强大的NER性能，强调即使在资源限制环境中部署鲁棒模型的可行性。我们的研究结果强调了针对临床NLP任务进行领域特定微调的价值，并为负责任开发能够增强成瘾监测、提高解释性和支持实际医疗保健决策的人工智能工具做出了贡献。然而，表现最好的模型在专家间一致性（科恩κ：0.81）方面仍显著落后，这表明在需要深厚领域知识的任务中，专家智能与当前最先进的NER/AI能力之间仍存在差距。', 'title_zh': '领域专家知识与机器智能在命名实体识别中的推断差距：一种与物质使用相关数据集的创建与见解'}
{'arxiv_id': 'arXiv:2508.19466', 'title': 'Incentivized Lipschitz Bandits', 'authors': 'Sourav Chakraborty, Amit Kiran Rege, Claire Monteleoni, Lijun Chen', 'link': 'https://arxiv.org/abs/2508.19466', 'abstract': 'We study incentivized exploration in multi-armed bandit (MAB) settings with infinitely many arms modeled as elements in continuous metric spaces. Unlike classical bandit models, we consider scenarios where the decision-maker (principal) incentivizes myopic agents to explore beyond their greedy choices through compensation, but with the complication of reward drift--biased feedback arising due to the incentives. We propose novel incentivized exploration algorithms that discretize the infinite arm space uniformly and demonstrate that these algorithms simultaneously achieve sublinear cumulative regret and sublinear total compensation. Specifically, we derive regret and compensation bounds of $\\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the covering dimension of the metric space. Furthermore, we generalize our results to contextual bandits, achieving comparable performance guarantees. We validate our theoretical findings through numerical simulations.', 'abstract_zh': '我们在连续度量空间中无限多臂的多臂bandit设置中研究激励型探索，其中决策者通过补偿激励短视代理超越贪心选择进行探索，同时考虑奖励漂移的复杂性。我们提出了新颖的激励型探索算法，将无限臂空间均匀离散化，并证明这些算法能够同时实现亚线性累积后悔和亚线性总补偿。具体地，我们推导出后悔和补偿的界限为$\\Tilde{O}(T^{d+1/d+2})$，其中$d$表示度量空间的覆盖维度。此外，我们将结果推广到上下文bandit，实现类似的良好性能保证。我们通过数值模拟验证了理论发现。', 'title_zh': '激励性LipschitzBandits'}
{'arxiv_id': 'arXiv:2508.19465', 'title': 'Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication', 'authors': 'Onyinye Okoye', 'link': 'https://arxiv.org/abs/2508.19465', 'abstract': 'The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle Charging Systems (EVCs) has introduced new cybersecurity challenges, specifically in authentication protocols that protect vehicles, users, and energy infrastructure. Although widely adopted for convenience, traditional authentication mechanisms like Radio Frequency Identification (RFID) and Near Field Communication (NFC) rely on static identifiers and weak encryption, making them highly vulnerable to attack vectors such as cloning, relay attacks, and signal interception. This study explores an AI-powered adaptive authentication framework designed to overcome these shortcomings by integrating machine learning, anomaly detection, behavioral analytics, and contextual risk assessment. Grounded in the principles of Zero Trust Architecture, the proposed framework emphasizes continuous verification, least privilege access, and secure communication. Through a comprehensive literature review, this research evaluates current vulnerabilities and highlights AI-driven solutions to provide a scalable, resilient, and proactive defense. Ultimately, the research findings conclude that adopting AI-powered adaptive authentication is a strategic imperative for securing the future of electric mobility and strengthening digital trust across the ecosystem. Keywords: weak authentication, RFID, NFC, ML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping, MITM attacks, Zero Trust Architecture', 'abstract_zh': '电动汽车（EVs）和电动汽车充电系统（EVCs）的快速扩张引入了新的网络安全挑战，特别是在保护车辆、用户和能源基础设施的身份认证协议方面。尽管传统身份认证机制如射频识别（RFID）和近场通信（NFC）因其便捷性而广泛应用，但它们依赖于静态标识符和弱加密，使其极易受到仿冒、中继攻击和信号拦截等攻击向量的威胁。本研究探讨了一种基于人工智能的强大适应性认证框架，该框架通过集成机器学习、异常检测、行为分析和上下文风险评估来克服这些不足。该框架基于零信任架构的原则，强调持续验证、最小权限访问和安全通信。通过全面的文献综述，本研究评估了当前的安全漏洞，并强调人工智能驱动的解决方案，以提供可扩展、 resilient和积极主动的防御。最终，研究结果表明，采用人工智能驱动的适应性认证是确保电动汽车未来安全并增强整个生态系统中数字信任的战略性要求。关键词：弱认证、RFID、NFC、机器学习（ML）、人工智能驱动的适应性认证、中继攻击、仿冒、窃听、中间人攻击（MITM）、零信任架构。', 'title_zh': '使用AI驱动的自适应认证解决电动汽车和电动车辆中弱认证问题（如RFID、NFC）'}
{'arxiv_id': 'arXiv:2508.19464', 'title': 'Bridging Language Gaps: Enhancing Few-Shot Language Adaptation', 'authors': 'Philipp Borchert, Jochen De Weerdt, Marie-Francine Moens', 'link': 'https://arxiv.org/abs/2508.19464', 'abstract': 'The disparity in language resources poses a challenge in multilingual NLP, with high-resource languages benefiting from extensive data, while low-resource languages lack sufficient data for effective training. Our Contrastive Language Alignment with Prompting (CoLAP) method addresses this gap by integrating contrastive learning with cross-lingual representations, facilitating task-specific knowledge transfer from high-resource to lower-resource languages. The primary advantage of our approach is its data efficiency, enabling rapid adaptation to new languages and reducing the need for large labeled datasets. We conduct experiments with multilingual encoder-only and decoder-only language models on natural language understanding tasks, including natural language inference and relation extraction, evaluating performance across both high- and low-resource languages. Our results demonstrate that CoLAP outperforms few-shot cross-lingual transfer baselines and in-context learning, even with limited available data. This effectively narrows the cross-lingual performance gap, contributing to the development of more efficient multilingual NLP techniques.', 'abstract_zh': '语言资源的差距给多语言NLP带来了挑战，高资源语言受益于大量数据，而低资源语言缺乏有效训练所需的数据。我们的对比语言对齐与提示（CoLAP）方法通过将对比学习与跨语言表示结合，促进高资源语言知识向低资源语言的特定任务迁移。我们方法的主要优势在于其数据效率，能够快速适应新语言并减少对大量标注数据的依赖。我们在自然语言理解任务（包括自然语言推理和关系抽取）上对多语言编码器和解码器模型进行了实验，评估了高资源和低资源语言的性能。实验结果表明，CoLAP在有限数据情况下优于少量样本跨语言迁移学习基线和上下文学习方法，有效地缩小了跨语言性能差距，促进了更高效多语言NLP技术的发展。', 'title_zh': '跨越语言障碍：增强少-shot语言适应性'}
{'arxiv_id': 'arXiv:2508.19441', 'title': 'Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models', 'authors': 'Sanket Jantre, Deepak Akhare, Xiaoning Qian, Nathan M. Urban', 'link': 'https://arxiv.org/abs/2508.19441', 'abstract': 'Partial differential equations (PDEs) underpin the modeling of many natural and engineered systems. It can be convenient to express such models as neural PDEs rather than using traditional numerical PDE solvers by replacing part or all of the PDE\'s governing equations with a neural network representation. Neural PDEs are often easier to differentiate, linearize, reduce, or use for uncertainty quantification than the original numerical solver. They are usually trained on solution trajectories obtained by long time integration of the PDE solver. Here we propose a more sample-efficient data-augmentation strategy for generating neural PDE training data from a computer model by space-filling sampling of local "stencil" states. This approach removes a large degree of spatiotemporal redundancy present in trajectory data and oversamples states that may be rarely visited but help the neural PDE generalize across the state space. We demonstrate that accurate neural PDE stencil operators can be learned from synthetic training data generated by the computational equivalent of 10 timesteps\' worth of numerical simulation. Accuracy is further improved if we assume access to a single full-trajectory simulation from the computer model, which is typically available in practice. Across several PDE systems, we show that our data-augmented synthetic stencil data yield better trained neural stencil operators, with clear performance gains compared with naively sampled stencil data from simulation trajectories.', 'abstract_zh': '基于空间填充抽样的神经偏微分方程训练数据生成方法', 'title_zh': '面向计算机模型系统识别的数据增强少量样本神经模板仿真'}
{'arxiv_id': 'arXiv:2508.19427', 'title': 'A perishable ability? The future of writing in the face of generative artificial intelligence', 'authors': 'Evandro L. T. P. Cunha', 'link': 'https://arxiv.org/abs/2508.19427', 'abstract': 'The 2020s have been witnessing a very significant advance in the development of generative artificial intelligence tools, including text generation systems based on large language models. These tools have been increasingly used to generate texts in the most diverse domains -- from technical texts to literary texts --, which might eventually lead to a lower volume of written text production by humans. This article discusses the possibility of a future in which human beings will have lost or significantly decreased their ability to write due to the outsourcing of this activity to machines. This possibility parallels the loss of the ability to write in other moments of human history, such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).', 'abstract_zh': '2020年代见证了生成型人工智能工具，尤其是基于大型语言模型的文本生成系统，的发展显著进步。这些工具在最多样化的领域被用于生成文本，这最终可能导致人类书面文本生产量的降低。本文讨论了未来人类可能会失去或大大减少写作能力的可能性，这种可能性类似于人类历史上其他时期丧失书写能力的情况，比如所谓的希腊黑暗时期（约公元前1200年至公元前800年）。', 'title_zh': '易腐的能力？面对生成式人工智能，书写未来的前景'}
{'arxiv_id': 'arXiv:2508.19414', 'title': 'Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention', 'authors': 'Gustavo Sandoval', 'link': 'https://arxiv.org/abs/2508.19414', 'abstract': 'We present a mechanistic case study of a format-dependent reasoning failure in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger than "9.8" in chat or Q&A formats, but answers correctly in simple format. Through systematic intervention, we discover transformers implement even/odd attention head specialization: even indexed heads handle numerical comparison, while odd heads serve incompatible functions. The bug requires exactly 8 even heads at Layer 10 for perfect repair. Any combination of 8+ even heads succeeds, while 7 or fewer completely fails, revealing sharp computational thresholds with perfect redundancy among the 16 even heads. SAE analysis reveals the mechanism: format representations separate (10% feature overlap at Layer 7), then re-entangle with different weightings (80% feature overlap at Layer 10), with specific features showing 1.5x amplification in failing formats. We achieve perfect repair using only 25% of attention heads and identify a 60% pattern replacement threshold, demonstrating that apparent full-module requirements hide sophisticated substructure with implications for interpretability and efficiency. All of our code is available at this https URL.', 'abstract_zh': '我们 presents 一个关于 Llama-3.1-8B-Instruct 中格式依赖性推理故障的机理案例研究，其中模型在聊天或问答格式中错误地判断“9.11”大于“9.8”，但在简单格式中回答正确。通过系统干预，我们发现transformers 实现了偶数/奇数注意力层的专业化：偶数索引的层处理数值比较，而奇数层承担不兼容的功能。该故障需要恰好第10层有8个偶数层以实现完美修复。任何8个及以上偶数层的组合都能成功，而7个或更少的完全失败，揭示了精确的计算阈值，且16个偶数层之间具有完美的冗余性。SAE分析揭示了机制：格式表示在第7层分离（特征重叠为10%），然后在第10层重新交织但权重不同（特征重叠为80%），特定特征在失败的格式中放大1.5倍。我们仅使用25%的注意力层实现完美修复，并确定了60%的模式替换阈值，表明看似需要完整模块的假设隐藏了复杂的次结构，这对可解释性和效率具有影响。所有代码均可在此 https:// 的链接处获取。', 'title_zh': '即使是奇数错误也需要偶数修正：Transformer注意力机制的发现与手术修复'}
{'arxiv_id': 'arXiv:2508.19402', 'title': 'One Joke to Rule them All? On the (Im)possibility of Generalizing Humor', 'authors': 'Mor Turgeman, Chen Shani, Dafna Shahaf', 'link': 'https://arxiv.org/abs/2508.19402', 'abstract': 'Humor is a broad and complex form of communication that remains challenging for machines. Despite its broadness, most existing research on computational humor traditionally focused on modeling a specific type of humor. In this work, we wish to understand whether competence on one or more specific humor tasks confers any ability to transfer to novel, unseen types; in other words, is this fragmentation inevitable? This question is especially timely as new humor types continuously emerge in online and social media contexts (e.g., memes, anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this evolving landscape, they must be able to generalize across humor types by capturing deeper, transferable mechanisms. To investigate this, we conduct a series of transfer learning experiments across four datasets, representing different humor tasks. We train LLMs under varied diversity settings (1-3 datasets in training, testing on a novel task). Experiments reveal that models are capable of some transfer, and can reach up to 75% accuracy on unseen datasets; training on diverse sources improves transferability (1.88-4.05%) with minimal-to-no drop in in-domain performance. Further analysis suggests relations between humor types, with Dad Jokes surprisingly emerging as the best enabler of transfer (but is difficult to transfer to). We release data and code.', 'abstract_zh': '基于计算的幽默理解：单一幽默任务能力向新颖类型迁移的不可避免性探索', 'title_zh': '一家笑法规制它们？关于幽默泛化的（不）可能性'}
{'arxiv_id': 'arXiv:2508.19372', 'title': 'Database Entity Recognition with Data Augmentation and Deep Learning', 'authors': 'Zikun Fu, Chen Yang, Kourosh Davoudi, Ken Q. Pu', 'link': 'https://arxiv.org/abs/2508.19372', 'abstract': 'This paper addresses the challenge of Database Entity Recognition (DB-ER) in Natural Language Queries (NLQ). We present several key contributions to advance this field: (1) a human-annotated benchmark for DB-ER task, derived from popular text-to-sql benchmarks, (2) a novel data augmentation procedure that leverages automatic annotation of NLQs based on the corresponding SQL queries which are available in popular text-to-SQL benchmarks, (3) a specialized language model based entity recognition model using T5 as a backbone and two down-stream DB-ER tasks: sequence tagging and token classification for fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER tagger with two state-of-the-art NER taggers, and observed better performance in both precision and recall for our model. The ablation evaluation shows that data augmentation boosts precision and recall by over 10%, while fine-tuning of the T5 backbone boosts these metrics by 5-10%.', 'abstract_zh': '这篇论文探讨了自然语言查询（NLQ）中的数据库实体识别（DB-ER）挑战。我们提出了几项关键贡献以推进该领域的发展：（1）一个基于流行文本到SQL基准的数据标注基准数据集用于DB-ER任务；（2）一种新颖的数据增强方法，利用相应的SQL查询的自动标注来增强自然语言查询（NLQ）的标注；（3）一个基于T5的专用语言模型实体识别模型以及两个下游DB-ER任务：序列标注和标记分类，用于调整T5骨干模型并执行DB-ER。我们将我们的DB-ER标签器与两种最先进的NER标签器进行了比较，并发现我们的模型在精度和召回率上表现更好。消融评估显示，数据增强将精度和召回率提高了超过10%，而调整T5骨干模型将这些指标分别提高了5-10%。', 'title_zh': '基于数据扩增和深度学习的数据库实体识别'}
{'arxiv_id': 'arXiv:2508.19367', 'title': 'Inference of Human-derived Specifications of Object Placement via Demonstration', 'authors': 'Alex Cuellar, Ho Chit Siu, Julie A Shah', 'link': 'https://arxiv.org/abs/2508.19367', 'abstract': "As robots' manipulation capabilities improve for pick-and-place tasks (e.g., object packing, sorting, and kitting), methods focused on understanding human-acceptable object configurations remain limited expressively with regard to capturing spatial relationships important to humans. To advance robotic understanding of human rules for object arrangement, we introduce positionally-augmented RCC (PARCC), a formal logic framework based on region connection calculus (RCC) for describing the relative position of objects in space. Additionally, we introduce an inference algorithm for learning PARCC specifications via demonstrations. Finally, we present the results from a human study, which demonstrate our framework's ability to capture a human's intended specification and the benefits of learning from demonstration approaches over human-provided specifications.", 'abstract_zh': '随着机器人在取放任务（例如物体打包、分类和组装配件）中的操作能力提升，专注于理解人类可接受的物体配置的方法在捕捉对人类重要的空间关系方面仍较为有限。为促进机器人对物体排列规则的理解，我们引入了一种基于区域连接计算（RCC）的位置增强RCC（PARCC）形式逻辑框架，用于描述空间中物体的相对位置。此外，我们还提出了一种推理算法，用于通过演示学习PARCC规范。最后，我们呈现了一项人类研究的结果，该结果展示了我们框架捕捉人类意图规范的能力，并说明了通过演示学习方法相较于人类提供规范的优势。', 'title_zh': '基于演示推断人类衍生的物体放置规范'}
{'arxiv_id': 'arXiv:2508.19361', 'title': 'Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture', 'authors': 'Yongbin Lee, Ki H. Chon', 'link': 'https://arxiv.org/abs/2508.19361', 'abstract': 'Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk of stroke, heart failure, and other cardiovascular complications. While AF detection algorithms perform well in identifying persistent AF, early-stage progression, such as paroxysmal AF (PAF), often goes undetected due to its sudden onset and short duration. However, undetected PAF can progress into sustained AF, increasing the risk of mortality and severe complications. Early prediction of AF offers an opportunity to reduce disease progression through preventive therapies, such as catecholamine-sparing agents or beta-blockers. In this study, we propose a lightweight deep learning model using only RR Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for positional encoding with Mamba, a selective state space model, to enable early prediction of AF through efficient parallel sequence modeling. In subject-wise testing results, our model achieved a sensitivity of 0.908, specificity of 0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our method demonstrates high computational efficiency, with only 73.5 thousand parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and model compactness. Notably, the model can predict AF up to two hours in advance using just 30 minutes of input data, providing enough lead time for preventive interventions.', 'abstract_zh': '心房颤动（AF）是最常见的心律失常，增加中风、心力衰竭和其他心血管并发症的风险。尽管用于检测持续性心房颤动的算法表现良好，但早期阶段如阵发性心房颤动（PAF）由于其突发性和短暂性，往往未被检测到。然而，未检测到的PAF可能会进展为持续性心房颤动，增加死亡率和严重并发症的风险。早期预测心房颤动提供了通过预防性治疗减少疾病进展的机会，如使用儿茶酚胺保护剂或β-阻滞剂。在本研究中，我们提出了一种仅使用RR间期（RRIs）的轻量级深度学习模型，结合时空卷积网络（TCN）进行位置编码与Mamba选择性状态空间模型，以高效并行序列建模方式实现心房颤动的早期预测。在个体测试结果中，我们的模型达到了0.908的灵敏度、0.933的特异度、0.930的F1分数、0.972的AUROC和0.932的AUPRC。此外，该方法展示了高的计算效率，仅包含73.5万个参数和38.3 MFLOPs，优于传统卷积神经网络-循环神经网络（CNN-RNN）方法在准确性和模型紧凑性方面的表现。值得注意的是，该模型仅使用30分钟的输入数据即可提前两小时预测心房颤动，为预防干预提供了足够的时间。', 'title_zh': '使用轻量级时序卷积和选择性状态空间架构的房颤预测'}
{'arxiv_id': 'arXiv:2508.19344', 'title': 'Re:Frame -- Retrieving Experience From Associative Memory', 'authors': 'Daniil Zelezetsky, Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov', 'link': 'https://arxiv.org/abs/2508.19344', 'abstract': 'Offline reinforcement learning (RL) often deals with suboptimal data when collecting large expert datasets is unavailable or impractical. This limitation makes it difficult for agents to generalize and achieve high performance, as they must learn primarily from imperfect or inconsistent trajectories. A central challenge is therefore how to best leverage scarce expert demonstrations alongside abundant but lower-quality data. We demonstrate that incorporating even a tiny amount of expert experience can substantially improve RL agent performance. We introduce Re:Frame (Retrieving Experience From Associative Memory), a plug-in module that augments a standard offline RL policy (e.g., Decision Transformer) with a small external Associative Memory Buffer (AMB) populated by expert trajectories drawn from a separate dataset. During training on low-quality data, the policy learns to retrieve expert data from the Associative Memory Buffer (AMB) via content-based associations and integrate them into decision-making; the same AMB is queried at evaluation. This requires no environment interaction and no modifications to the backbone architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories (0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a strong Decision Transformer baseline in three of four settings, with gains up to +10.7 normalized points. These results show that Re:Frame offers a simple and data-efficient way to inject scarce expert knowledge and substantially improve offline RL from low-quality datasets.', 'abstract_zh': '离线强化学习（RL）经常面临亚优数据的问题，当收集大量专家数据集不可用或不现实时尤为明显。这种限制使得智能体难以泛化并实现高性能，因为它们主要必须从不完美或不一致的轨迹中学习。因此，一个核心挑战是如何最佳地利用稀缺的专家演示与丰富的但质量较低的数据。我们证明即使整合少量的专家经验也能显著提升RL智能体的性能。我们引入了Re:Frame（从关联记忆中检索经验）模块，该模块将一个小的外部关联记忆缓冲区（AMB）与标准的离线RL策略（如决策变换器）进行结合，该缓冲区由来自单独数据集的专家轨迹填充。在使用低质量数据进行训练时，策略通过内容关联从关联记忆缓冲区检索专家数据，并将其整合到决策制定中；在评估时查询相同的AMB。这种方法不需要环境交互，也不需要修改基础架构。在D4RL MuJoCo任务中，使用多达60条专家轨迹（6000条轨迹数据集的0.1%），Re:Frame在三个四个设置中的三个中都优于强大的决策变换器基线，改进幅度最高可达+10.7标准化点。这些结果表明，Re:Frame提供了一种简单且数据高效的途径，以注入稀缺的专家知识并在低质量数据集的离线RL中显著提升性能。', 'title_zh': 'Re:Frame——从关联记忆中检索经验'}
{'arxiv_id': 'arXiv:2508.19327', 'title': "Quantum Entanglement as Super-Confounding: From Bell's Theorem to Robust Machine Learning", 'authors': 'Pilsung Kang', 'link': 'https://arxiv.org/abs/2508.19327', 'abstract': 'Bell\'s theorem reveals a profound conflict between quantum mechanics and local realism, a conflict we reinterpret through the modern lens of causal inference. We propose and computationally validate a framework where quantum entanglement acts as a "super-confounding" resource, generating correlations that violate the classical causal bounds set by Bell\'s inequalities. This work makes three key contributions: First, we establish a physical hierarchy of confounding (Quantum > Classical) and introduce Confounding Strength (CS) to quantify this effect. Second, we provide a circuit-based implementation of the quantum $\\mathcal{DO}$-calculus to distinguish causality from spurious correlation. Finally, we apply this calculus to a quantum machine learning problem, where causal feature selection yields a statistically significant 11.3% average absolute improvement in model robustness. Our framework bridges quantum foundations and causal AI, offering a new, practical perspective on quantum correlations.', 'abstract_zh': '贝尔定理揭示了量子力学与局域实在论之间的深刻冲突，我们通过现代因果推断的视角重新解读这一冲突。本文提出并计算验证了一个框架，其中量子纠缠作为一种“超混杂”资源，产生违反贝尔不等式经典因果界限的相关性。本文做出三大贡献：首先，我们建立了混杂的物理层次（量子 > 经典），并引入混杂强度（CS）来量化这一效果。其次，我们提供了一个基于量子$\\mathcal{DO}$-演算的电路实现方法，以区分因果关系与伪相关。最后，我们将该演算应用于量子机器学习问题，其中因果特征选择在模型稳健性上提供了统计显著的11.3%平均绝对改进。我们的框架将量子基础与因果人工智能相连，提供了一种新的实用视角来理解量子相关性。', 'title_zh': '量子纠缠作为超级混淆：从贝尔定理到稳健机器学习'}
{'arxiv_id': 'arXiv:2508.19324', 'title': 'Deep Data Hiding for ICAO-Compliant Face Images: A Survey', 'authors': 'Jefferson David Rodriguez Chivata, Davide Ghiani, Simone Maurizio La Cava, Marco Micheletto, Giulia Orrù, Federico Lama, Gian Luca Marcialis', 'link': 'https://arxiv.org/abs/2508.19324', 'abstract': 'ICAO-compliant facial images, initially designed for secure biometric passports, are increasingly becoming central to identity verification in a wide range of application contexts, including border control, digital travel credentials, and financial services. While their standardization enables global interoperability, it also facilitates practices such as morphing and deepfakes, which can be exploited for harmful purposes like identity theft and illegal sharing of identity documents. Traditional countermeasures like Presentation Attack Detection (PAD) are limited to real-time capture and offer no post-capture protection. This survey paper investigates digital watermarking and steganography as complementary solutions that embed tamper-evident signals directly into the image, enabling persistent verification without compromising ICAO compliance. We provide the first comprehensive analysis of state-of-the-art techniques to evaluate the potential and drawbacks of the underlying approaches concerning the applications involving ICAO-compliant images and their suitability under standard constraints. We highlight key trade-offs, offering guidance for secure deployment in real-world identity systems.', 'abstract_zh': 'ICAO符合性面部图像最初用于安全生物特征护照，如今在边境控制、数字旅行凭证和金融服务等多种应用上下逐渐成为身份验证的核心。虽然其标准化促进了全球互操作性，但也促进了如换脸和深度伪造等有害行为。传统的防presentation attack检测措施仅限于实时捕获，无法提供捕获后的保护。本文综述了数字水印和隐写术作为补充解决方案的研究，这些解决方案可以直接将抗篡改信号嵌入图像中，实现持续验证而不违背ICAO符合性。我们提供了关于ICAO符合性图像及其在标准约束下的适用性的最新技术的首次全面分析，评估潜在优势和局限性。我们强调了关键权衡，为实际世界中的身份验证系统安全部署提供指导。', 'title_zh': 'ICAO合规面部图像中的深层数据隐藏综述'}
{'arxiv_id': 'arXiv:2508.19317', 'title': 'What Makes AI Applications Acceptable or Unacceptable? A Predictive Moral Framework', 'authors': 'Kimmo Eriksson, Simon Karlsson, Irina Vartanova, Pontus Strimling', 'link': 'https://arxiv.org/abs/2508.19317', 'abstract': "As artificial intelligence rapidly transforms society, developers and policymakers struggle to anticipate which applications will face public moral resistance. We propose that these judgments are not idiosyncratic but systematic and predictable. In a large, preregistered study (N = 587, U.S. representative sample), we used a comprehensive taxonomy of 100 AI applications spanning personal and organizational contexts-including both functional uses and the moral treatment of AI itself. In participants' collective judgment, applications ranged from highly unacceptable to fully acceptable. We found this variation was strongly predictable: five core moral qualities-perceived risk, benefit, dishonesty, unnaturalness, and reduced accountability-collectively explained over 90% of the variance in acceptability ratings. The framework demonstrated strong predictive power across all domains and successfully predicted individual-level judgments for held-out applications. These findings reveal that a structured moral psychology underlies public evaluation of new technologies, offering a powerful tool for anticipating public resistance and guiding responsible innovation in AI.", 'abstract_zh': '随着人工智能迅速改变社会，开发人员和政策制定者难以预测哪些应用会面临公众道德抵制。我们提出，这些判断并非随机，而是系统性和可预测的。在一项大规模的预先登记研究（N=587，具代表性的美国样本）中，我们使用了涵盖个人和组织环境的100种AI应用全面分类，包括功能用途和对AI本身的道德对待。参与者集体判断的应用范围从高度不可接受到完全可接受。我们发现这种差异具有很强的可预测性：五个核心道德品质——感知风险、好处、不诚实、不自然和减少问责制——共同解释了超过90%的可接受性评分变异。该框架在所有领域都表现出强大的预测能力，并成功预测了未见过的应用的个体判断。这些发现揭示了一种结构化的道德心理学构成了对新技术公众评价的基础，提供了预见公众抵制和指导负责任的人工智能创新的强大工具。', 'title_zh': '什么是接受或拒绝AI应用的道德框架？'}
{'arxiv_id': 'arXiv:2508.19313', 'title': "Are Companies Taking AI Risks Seriously? A Systematic Analysis of Companies' AI Risk Disclosures in SEC 10-K forms", 'authors': 'Lucas G. Uberti-Bona Marin, Bram Rijsbosch, Gerasimos Spanakis, Konrad Kollnig', 'link': 'https://arxiv.org/abs/2508.19313', 'abstract': "As Artificial Intelligence becomes increasingly central to corporate strategies, concerns over its risks are growing too. In response, regulators are pushing for greater transparency in how companies identify, report and mitigate AI-related risks. In the US, the Securities and Exchange Commission (SEC) repeatedly warned companies to provide their investors with more accurate disclosures of AI-related risks; recent enforcement and litigation against companies' misleading AI claims reinforce these warnings. In the EU, new laws - like the AI Act and Digital Services Act - introduced additional rules on AI risk reporting and mitigation. Given these developments, it is essential to examine if and how companies report AI-related risks to the public. This study presents the first large-scale systematic analysis of AI risk disclosures in SEC 10-K filings, which require public companies to report material risks to their company. We analyse over 30,000 filings from more than 7,000 companies over the past five years, combining quantitative and qualitative analysis. Our findings reveal a sharp increase in the companies that mention AI risk, up from 4% in 2020 to over 43% in the most recent 2024 filings. While legal and competitive AI risks are the most frequently mentioned, we also find growing attention to societal AI risks, such as cyberattacks, fraud, and technical limitations of AI systems. However, many disclosures remain generic or lack details on mitigation strategies, echoing concerns raised recently by the SEC about the quality of AI-related risk reporting. To support future research, we publicly release a web-based tool for easily extracting and analysing keyword-based disclosures across SEC filings.", 'abstract_zh': '随着人工智能在企业战略中扮演日益重要的角色，对其风险的担忧也在增加。为此，监管机构要求企业提高在识别、报告和减轻人工智能相关风险方面的透明度。在美国，证券交易委员会（SEC）反复警告公司要向投资者提供更准确的人工智能相关风险披露；最近对误导性人工智能声明的执法和诉讼进一步强化了这些警告。在欧盟，新的法律（如人工智能法案和数字服务法案）引入了关于人工智能风险报告和缓解的额外规定。鉴于这些发展，有必要审查企业如何向公众报告人工智能相关风险。本研究首次进行了大规模系统的SEC 10-K文件中人工智能风险披露分析，要求上市公司报告对公司构成重大风险的事项。我们分析了过去五年来自7,000多家公司的超过30,000份文件，结合定量和定性分析。研究发现，提到人工智能风险的企业比例显著增加，从2020年的4%上升到最近2024年的超过43%。虽然法律和竞争性人工智能风险被最频繁提及，但我们还发现对社会性人工智能风险的关注也在增长，如网络攻击、欺诈和人工智能系统的技术限制。然而，许多披露仍然泛泛而谈，缺乏缓解策略的详细信息，这与SEC最近关于人工智能相关风险报告质量的担忧相呼应。为支持未来研究，我们公开发布了一个基于网络的工具，用于轻松提取和分析SEC文件中的关键词披露。', 'title_zh': '公司认真对待AI风险了吗？SEC 10-K表中关于AI风险披露的系统性分析'}
{'arxiv_id': 'arXiv:2508.19312', 'title': 'Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax', 'authors': 'Ander Galván, Marivi Higuero, Jorge Sasiain, Eduardo Jacob', 'link': 'https://arxiv.org/abs/2508.19312', 'abstract': 'Facial recognition powered by Artificial Intelligence has achieved high accuracy in specific scenarios and applications. Nevertheless, it faces significant challenges regarding privacy and identity management, particularly when unknown individuals appear in the operational context. This paper presents the design, implementation, and evaluation of a facial recognition system within a federated learning framework tailored to open-set scenarios. The proposed approach integrates the OpenMax algorithm into federated learning, leveraging the exchange of mean activation vectors and local distance measures to reliably distinguish between known and unknown subjects. Experimental results validate the effectiveness of the proposed solution, demonstrating its potential for enhancing privacy-aware and robust facial recognition in distributed environments.\n--\nEl reconocimiento facial impulsado por Inteligencia Artificial ha demostrado una alta precisión en algunos escenarios y aplicaciones. Sin embargo, presenta desafíos relacionados con la privacidad y la identificación de personas, especialmente considerando que pueden aparecer sujetos desconocidos para el sistema que lo implementa. En este trabajo, se propone el diseño, implementación y evaluación de un sistema de reconocimiento facial en un escenario de aprendizaje federado, orientado a conjuntos abiertos. Concretamente, se diseña una solución basada en el algoritmo OpenMax para escenarios de aprendizaje federado. La propuesta emplea el intercambio de los vectores de activación promedio y distancias locales para identificar de manera eficaz tanto personas conocidas como desconocidas. Los experimentos realizados demuestran la implementación efectiva de la solución propuesta.', 'abstract_zh': '基于人工智能的面部识别在特定场景和应用中已实现了高度准确率。然而，它在隐私管理和身份识别方面面临重大挑战，尤其是在出现未知个体的情况下。本文提出了一个面向开放集场景的联邦学习框架下的面部识别系统的设计、实现与评估。所提出的方法将OpenMax算法整合到联邦学习中，利用平均激活向量和局部距离度量的交换来可靠地区分已知和未知个体。实验结果验证了该方案的有效性，展示了其在分布式环境中增强隐私保护和鲁棒面部识别的潜力。', 'title_zh': '基于OpenMax的开放集联邦面部识别系统'}
{'arxiv_id': 'arXiv:2508.19307', 'title': 'Advancements in Crop Analysis through Deep Learning and Explainable AI', 'authors': 'Hamza Khan', 'link': 'https://arxiv.org/abs/2508.19307', 'abstract': 'Rice is a staple food of global importance in terms of trade, nutrition, and economic growth. Among Asian nations such as China, India, Pakistan, Thailand, Vietnam and Indonesia are leading producers of both long and short grain varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To ensure consumer satisfaction and strengthen national reputations, monitoring rice crops and grain quality is essential. Manual inspection, however, is labour intensive, time consuming and error prone, highlighting the need for automated solutions for quality control and yield improvement. This study proposes an automated approach to classify five rice grain varieties using Convolutional Neural Networks (CNN). A publicly available dataset of 75000 images was used for training and testing. Model evaluation employed accuracy, recall, precision, F1-score, ROC curves, and confusion matrices. Results demonstrated high classification accuracy with minimal misclassifications, confirming the model effectiveness in distinguishing rice varieties. In addition, an accurate diagnostic method for rice leaf diseases such as Brown Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined explainable artificial intelligence (XAI) with deep learning models including CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) revealed how specific grain and leaf features influenced predictions, enhancing model transparency and reliability. The findings demonstrate the strong potential of deep learning in agricultural applications, paving the way for robust, interpretable systems that can support automated crop quality inspection and disease diagnosis, ultimately benefiting farmers, consumers, and the agricultural economy.', 'abstract_zh': '水稻作为全球贸易、营养和经济增长中的重要主食，其种植和品质监控至关重要。中国、印度、巴基斯坦、泰国、越南和印度尼西亚等亚洲国家是长粒和短粒稻米（如 basmati、jasmine、arborio、ipsala 和 kainat saila）的主要生产国。为了确保消费者满意度和增强国家声誉，监控稻米作物和谷物品质是必不可少的。然而，手工检查劳动密集、耗时且容易出错，因此需要自动化的解决方案以提高产品质量和产量。本研究提出了一种使用卷积神经网络（CNN）自动分类五种稻米品种的方法。使用公开可用的75000张图像数据集进行训练和测试。模型评估采用准确率、召回率、精确率、F1分数、ROC曲线和混淆矩阵。结果表明分类准确性高且误分类少，证明了模型在区分稻米品种方面的有效性。此外，还开发了一种准确的稻叶病害诊断方法，如褐斑病、稻blast病、细菌性条斑病和稻文格病。该框架结合了可解释的人工智能（XAI）与深度学习模型，包括CNN、VGG16、ResNet50和MobileNetV2。通过SHAP（SHapley Additive exPlanations）和LIME（Local Interpretable Model-agnostic Explanations）等可解释性技术揭示了特定的谷粒和叶片特征如何影响预测，提高了模型的透明度和可靠性。研究结果展示了深度学习在农业应用中的巨大潜力，为建立稳健且可解释的系统铺平了道路，这些系统可以支持自动化的作物品质检测和病害诊断，最终造福农民、消费者和农业生产。', 'title_zh': '通过深度学习和可解释人工智能在作物分析领域的进展'}
{'arxiv_id': 'arXiv:2508.19305', 'title': 'Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities', 'authors': 'Chen Chu, Cyrus Shahabi', 'link': 'https://arxiv.org/abs/2508.19305', 'abstract': 'Spatial representation learning is essential for GeoAI applications such as urban analytics, enabling the encoding of shapes, locations, and spatial relationships (topological and distance-based) of geo-entities like points, polylines, and polygons. Existing methods either target a single geo-entity type or, like Poly2Vec, decompose entities into simpler components to enable Fourier transformation, introducing high computational cost. Moreover, since the transformed space lacks geometric alignment, these methods rely on uniform, non-adaptive sampling, which blurs fine-grained features like edges and boundaries. To address these limitations, we introduce Geo2Vec, a novel method inspired by signed distance fields (SDF) that operates directly in the original space. Geo2Vec adaptively samples points and encodes their signed distances (positive outside, negative inside), capturing geometry without decomposition. A neural network trained to approximate the SDF produces compact, geometry-aware, and unified representations for all geo-entity types. Additionally, we propose a rotation-invariant positional encoding to model high-frequency spatial variations and construct a structured and robust embedding space for downstream GeoAI models. Empirical results show that Geo2Vec consistently outperforms existing methods in representing shape and location, capturing topological and distance relationships, and achieving greater efficiency in real-world GeoAI applications. Code and Data can be found at: this https URL.', 'abstract_zh': '空间表示学习对于地理人工智能（GeoAI）应用如城市分析至关重要，能够编码地理实体（如点、多段线和多边形）的形状、位置和空间关系（拓扑和距离基的）。现有方法要么仅针对单一地理实体类型，要么如Poly2Vec那样将实体分解为更简单的组件以启用傅里叶变换，从而引入了高额的计算成本。此外，由于变换空间缺乏几何对齐，这些方法依赖于均匀的非自适应采样，这会模糊边缘和边界等细粒度特征。为了克服这些限制，我们提出了Geo2Vec，这是一种受符号距离场（SDF）启发的新型方法，它直接在原始空间中操作。Geo2Vec自适应地采样点并编码它们的符号距离（外部为正，内部为负），从而捕捉几何结构而无需分解。一个训练以近似符号距离场的神经网络产生紧凑、几何感知且统一的地理实体类型表示。此外，我们提出了一种旋转不变的位置编码来建模高频空间变化，并构建了结构化和健壮的嵌入空间，供下游GeoAI模型使用。实证结果表明，Geo2Vec在表示形状和位置、捕捉拓扑和距离关系以及在实际地理人工智能应用中实现更高效率方面均优于现有方法。代码和数据可在以下链接找到：this https URL。', 'title_zh': 'Geo2Vec: 具有形状和距离感知的地理空间实体神经表示'}
{'arxiv_id': 'arXiv:2508.19300', 'title': 'CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy', 'authors': 'Cunmin Zhao, Ziyuan Luo, Guoye Guan, Zelin Li, Yiming Ma, Zhongying Zhao, Renjie Wan', 'link': 'https://arxiv.org/abs/2508.19300', 'abstract': '4D live fluorescence microscopy is often compromised by prolonged high intensity illumination which induces photobleaching and phototoxic effects that generate photo-induced artifacts and severely impair image continuity and detail recovery. To address this challenge, we propose the CellINR framework, a case-specific optimization approach based on implicit neural representation. The method employs blind convolution and structure amplification strategies to map 3D spatial coordinates into the high frequency domain, enabling precise modeling and high-accuracy reconstruction of cellular structures while effectively distinguishing true signals from artifacts. Experimental results demonstrate that CellINR significantly outperforms existing techniques in artifact removal and restoration of structural continuity, and for the first time, a paired 4D live cell imaging dataset is provided for evaluating reconstruction performance, thereby offering a solid foundation for subsequent quantitative analyses and biological research. The code and dataset will be public.', 'abstract_zh': '4D活细胞荧光显微镜往往受到长时间高强度 illumination 的影响，导致光淬灭和光毒性效应，产生光诱导的伪影，严重影响图像连续性和细节恢复。为应对这一挑战，我们提出CellINR框架，这是一种基于隐式神经表示的案例特定优化方法。该方法采用盲卷积和结构放大策略，将3D空间坐标映射到高频域，从而能够精确建模和高精度重建细胞结构，同时有效区分真实信号和伪影。实验结果表明，CellINR在伪影去除和结构连续性恢复方面显著优于现有技术，并首次提供了配对的4D活细胞成像数据集，用于评估重建性能，从而为后续定量分析和生物研究提供了坚实的基础。代码和数据集将公开。', 'title_zh': 'CellINR: 隐式克服4D实时荧光显微镜中的光诱导伪影'}
{'arxiv_id': 'arXiv:2508.19281', 'title': 'CORTEX: Composite Overlay for Risk Tiering and Exposure in Operational AI Systems', 'authors': 'Aoun E Muhammad, Kin Choong Yow, Jamel Baili, Yongwon Cho, Yunyoung Nam', 'link': 'https://arxiv.org/abs/2508.19281', 'abstract': 'As the deployment of Artificial Intelligence (AI) systems in high-stakes sectors - like healthcare, finance, education, justice, and infrastructure has increased - the possibility and impact of failures of these systems have significantly evolved from being a theoretical possibility to practical recurring, systemic risk. This paper introduces CORTEX (Composite Overlay for Risk Tiering and Exposure), a multi-layered risk scoring framework proposed to assess and score AI system vulnerabilities, developed on empirical analysis of over 1,200 incidents documented in the AI Incident Database (AIID), CORTEX categorizes failure modes into 29 technical vulnerability groups. Each vulnerability is scored through a five-tier architecture that combines: (1) utility-adjusted Likelihood x Impact calculations; (2) governance + contextual overlays aligned with regulatory frameworks, such as the EU AI Act, NIST RMF, OECD principles; (3) technical surface scores, covering exposure vectors like drift, traceability, and adversarial risk; (4) environmental and residual modifiers tailored to context of where these systems are being deployed to use; and (5) a final layered assessment via Bayesian risk aggregation and Monte Carlo simulation to model volatility and long-tail risks. The resulting composite score can be operationalized across AI risk registers, model audits, conformity checks, and dynamic governance dashboards.', 'abstract_zh': '随着人工智能系统在高 stakes 领域（如医疗、金融、教育、司法和基础设施）中的部署增加，这些系统失败的可能性和影响已经从理论上的可能性转变为实际的、反复出现的系统性风险。本文介绍了CORTEX（综合风险分层和暴露框架），这是一种多层风险评分框架，旨在评估和评分人工智能系统的漏洞，该框架基于对AI事件数据库（AIID）中记录的超过1,200起事件的实证分析。CORTEX将失败模式分类为29个技术漏洞组。每个漏洞通过五层架构进行评分，该架构结合了：（1）调整后的效用×影响计算；（2）与法规框架（如欧盟人工智能法案、NIST RMF、OECD原则）对齐的治理+情境叠加；（3）技术表面评分，涵盖漂移、可追溯性和对抗性风险等暴露向量；（4）针对这些系统部署环境量身定制的环境和剩余调整；以及（5）通过贝叶斯风险聚合和蒙特卡洛模拟进行的最终多层评估，以建模波动性和长尾风险。由此产生的综合评分可以在人工智能风险登记册、模型审计、符合性检查和动态治理仪表板中操作化。', 'title_zh': 'Cortex: 组合overlay用于运营AI系统的风险分层与暴露管理'}
{'arxiv_id': 'arXiv:2508.19273', 'title': 'MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks', 'authors': 'Tongxi Wu, Chenwei Xu, Jin Yang', 'link': 'https://arxiv.org/abs/2508.19273', 'abstract': 'The proliferation of cloud-integrated IoT systems has intensified exposure to Distributed Denial of Service (DDoS) attacks due to the expanded attack surface, heterogeneous device behaviors, and limited edge protection. However, DDoS detection in this context remains challenging because of complex traffic dynamics, severe class imbalance, and scarce labeled data. While recent methods have explored solutions to address class imbalance, many still struggle to generalize under limited supervision and dynamic traffic conditions. To overcome these challenges, we propose MixGAN, a hybrid detection method that integrates conditional generation, semi-supervised learning, and robust feature extraction. Specifically, to handle complex temporal traffic patterns, we design a 1-D WideResNet backbone composed of temporal convolutional layers with residual connections, which effectively capture local burst patterns in traffic sequences. To alleviate class imbalance and label scarcity, we use a pretrained CTGAN to generate synthetic minority-class (DDoS attack) samples that complement unlabeled data. Furthermore, to mitigate the effect of noisy pseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that constructs smoothed and sharpened targets by averaging predictions over augmented views and reweighting them towards high-confidence classes. Experiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN achieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR compared to state-of-the-art methods, confirming its robustness in large-scale IoT-cloud environments. The source code is publicly available at this https URL.', 'abstract_zh': '云集成IoT系统的 proliferance 加剧了分布式拒绝服务（DDoS）攻击的暴露程度，由于攻击面的扩展、异构设备行为以及边缘保护的限制。然而，在这种背景下，DDoS检测仍然具有挑战性，原因在于复杂的流量动态、严重的类别不平衡以及稀缺的标签数据。尽管近期方法探索了解决类别不平衡的方案，但在有限监督和动态流量条件下，许多方法仍然难以泛化。为了克服这些挑战，我们提出MixGAN，一种结合条件生成、半监督学习和稳健特征提取的混合检测方法。具体而言，为了处理复杂的时空流量模式，我们设计了一个由具有残差连接的时间卷积层组成的1-D WideResNet骨干网络，有效地捕捉流量序列中的局部突发模式。为了缓解类别不平衡和标签稀缺问题，我们使用预训练的CTGAN生成补充无标签数据的合成少数类（DDoS攻击）样本。为进一步减轻嘈杂伪标签的影响，我们引入了MixUp-Average-Sharpen (MAS) 策略，通过在增强视图上平均预测并重新加权以朝向高置信度类别构建平滑和加硬的目标。在NSL-KDD、BoT-IoT和CICIoT2023上的实验表明，MixGAN的准确率最高可提高2.5%，TPR和TNR均值提高4%，证实了其在大规模IoT-云环境中的鲁棒性。源代码已在以下网址公开。', 'title_zh': 'MixGAN：一种用于云集成物联网网络中的DDoS检测的混合半监督生成方法'}
{'arxiv_id': 'arXiv:2508.19270', 'title': 'Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English', 'authors': 'Nguyen Huu Nhat Minh, Tran Nguyen Anh, Truong Dinh Dung, Vo Van Nam, Le Pham Tuyen', 'link': 'https://arxiv.org/abs/2508.19270', 'abstract': 'Cross-lingual phoneme recognition has emerged as a significant challenge for accurate automatic speech recognition (ASR) when mixing Vietnamese and English pronunciations. Unlike many languages, Vietnamese relies on tonal variations to distinguish word meanings, whereas English features stress patterns and non-standard pronunciations that hinder phoneme alignment between the two languages. To address this challenge, we propose a novel bilingual speech recognition approach with two primary contributions: (1) constructing a representative bilingual phoneme set that bridges the differences between Vietnamese and English phonetic systems; (2) designing an end-to-end system that leverages the PhoWhisper pre-trained encoder for deep high-level representations to improve phoneme recognition. Our extensive experiments demonstrate that the proposed approach not only improves recognition accuracy in bilingual speech recognition for Vietnamese but also provides a robust framework for addressing the complexities of tonal and stress-based phoneme recognition', 'abstract_zh': '跨语言音素识别已成为混合越南语和英语发音时准确自动语音识别（ASR）的一个重要挑战。我们提出了一种新颖的双语语音识别方法，主要贡献包括：（1）构建一个代表性的双语音素集，以弥合越南语和英语音系之间的差异；（2）设计一个端到端系统，利用预训练的PhoWhisper编码器提取深层次的表征以提高音素识别效果。实验结果表明，该方法不仅改善了越南语双语语音识别的识别准确性，还提供了一个 robust 的框架来应对基于音调和重音的音素识别复杂性。', 'title_zh': '基于Whisper的越英跨语言音素识别'}
{'arxiv_id': 'arXiv:2508.19267', 'title': 'The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents', 'authors': 'Sai Teja Reddy Adapala, Yashwanth Reddy Alugubelly', 'link': 'https://arxiv.org/abs/2508.19267', 'abstract': 'The proliferation of autonomous AI agents marks a paradigm shift toward complex, emergent multi-agent systems. This transition introduces systemic security risks, including control-flow hijacking and cascading failures, that traditional cybersecurity paradigms are ill-equipped to address. This paper introduces the Aegis Protocol, a layered security framework designed to provide strong security guarantees for open agentic ecosystems. The protocol integrates three technological pillars: (1) non-spoofable agent identity via W3C Decentralized Identifiers (DIDs); (2) communication integrity via NIST-standardized post-quantum cryptography (PQC); and (3) verifiable, privacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP) system. We formalize an adversary model extending Dolev-Yao for agentic threats and validate the protocol against the STRIDE framework. Our quantitative evaluation used a discrete-event simulation, calibrated against cryptographic benchmarks, to model 1,000 agents. The simulation showed a 0 percent success rate across 20,000 attack trials. For policy verification, analysis of the simulation logs reported a median proof-generation latency of 2.79 seconds, establishing a performance baseline for this class of security. While the evaluation is simulation-based and early-stage, it offers a reproducible baseline for future empirical studies and positions Aegis as a foundation for safe, scalable autonomous AI.', 'abstract_zh': '自主AI代理的泛滥标志着向复杂、 emergent 多代理系统范式的转变。这一过渡引入了系统性安全风险，包括控制流劫持和级联故障，而传统网络安全范式对此无能为力。本文介绍了Aegis协议，这是一种分层安全框架，旨在为开放代理生态系统提供强大的安全保证。该协议整合了三项技术支柱：（1）通过W3C去中心化标识符（DIDs）实现不可冒充的代理身份；（2）通过NIST标准化后量子密码学（PQC）实现通信完整；（3）通过Halo2零知识证明（ZKP）系统实现可验证的、隐私保护的策略合规。我们扩展了Dolev-Yao对手模型以适应代理威胁，并将该协议与STRIDE框架进行了验证。定量评估使用了一种基于事件的模拟，根据密码学基准进行了校准，模拟了1,000个代理。模拟结果显示，在2万次攻击试验中，没有成功案例。对于策略验证，模拟日志的分析报告中位证明生成延迟为2.79秒，为这一类安全性能设定了基准。尽管评估基于模拟且处于早期阶段，但为未来实证研究提供了可重复的基础，并将Aegis定位为安全、可扩展自主AI的基础。', 'title_zh': 'Aegis协议：自主AI代理的基礎安全框架'}
{'arxiv_id': 'arXiv:2508.19264', 'title': 'A Theory of Information, Variation, and Artificial Intelligence', 'authors': 'Bijean Ghafouri', 'link': 'https://arxiv.org/abs/2508.19264', 'abstract': "A growing body of empirical work suggests that the widespread adoption of generative AI produces a significant homogenizing effect on information, creativity, and cultural production. I first develop a novel theoretical framework to explain this phenomenon. I argue that a dynamic of AI-derivative epistemology, in which individuals increasingly defer to AI outputs, allows a centralized AI Prism to function, a technical mechanism whose architecture is designed to reduce variance and converge on the statistical mean. This provides a causal explanation for the generative monocultures observed in recent studies. However, I contend this represents only the first stage of a more complex and dialectical process. This paper's central and paradoxical thesis is that the very homogenization that flattens knowledge within specialized domains simultaneously renders that knowledge into consistent modules that can be recombined across them, a process foundational to innovation and creativity. However, this recombinant potential is not automatic, but rather conditional. This paper argues that these opposing forces, homogenizing defaults versus recombinant possibilities, are governed by the nature of human engagement with the technology. The ultimate effect of generative AI is conditional on whether individuals act as passive consumers deferring to the AI's statistical outputs, or as active curators who critically interrogate, re-contextualize, and recombine them. The paper concludes by outlining the cognitive and institutional scaffolds required to resolve this tension, arguing they are the decisive variable that determine whether generative AI becomes an instrument of innovation or homogenization.", 'abstract_zh': '一项日益增多的经验研究表明，生成式人工智能的广泛应用对信息、创造力和文化生产产生了显著的同质化效应。本文首先构架了一个新颖的理论框架来解释这一现象。我认为，个体倾向于依赖AI输出的认知动态促使一个集中的AI棱镜发挥作用，这一技术机制旨在减少差异并趋向统计均值。这为最近研究中观察到的生成式 monocultures 提供了因果解释。然而，我主张这仅是更复杂且辩证过程中的第一步。本文的核心和悖论性论点是：尽管知识在专业领域内被扁平化，但同时也被转换为可跨领域重组的一致模块，这是创新和创造力的基础。然而，这种重组潜力并非自动存在，而是有条件的。本文认为，这些对立力量——同质化默认和重组可能性——受人类与技术互动的本质所支配。生成式人工智能的最终影响取决于个体是作为被动消费者顺从AI的统计输出，还是作为主动策展人对其进行批判性审视、再语境化和重组。本文最后概述了解决这一张力所需的认知和制度框架，并主张这些框架是决定生成式AI是成为创新工具还是同质化手段的关键变量。', 'title_zh': '信息、变异与人工智能理论'}
{'arxiv_id': 'arXiv:2508.19263', 'title': 'Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats', 'authors': 'Anat Heilper, Doron Singer', 'link': 'https://arxiv.org/abs/2508.19263', 'abstract': 'As deep learning models grow and deployment becomes more widespread, reducing the storage and transmission costs of neural network weights has become increasingly important. While prior work such as ZipNN has shown that lossless compression methods - particularly those based on Huffman encoding floating-point exponents can significantly reduce model sizes, these techniques have primarily been applied to higher-precision formats such as FP32 and BF16. In this work, we extend the ZipNN approach to lower-precision floating-point formats, specifically FP8 and FP4, which are gaining popularity for efficient inference. We design a compression method that separates and compresses the exponent and mantissa components independently using entropy coding. Our evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also investigate the compressibility of key-value (K/V) cache tensors used in large language models (LLMs), finding that they, too, exhibit compressible patterns, enabling memory savings during deployment.', 'abstract_zh': '随着深度学习模型的增长和部署变得更加普遍，减少神经网络权重的存储和传输成本变得越来越重要。虽然先前的工作如ZipNN已经表明，无损压缩方法——尤其是基于霍夫曼编码浮点数指数的方法可以显著减小模型大小，这些技术主要应用于更高精度的格式，如FP32和BF16。在本工作中，我们将ZipNN方法扩展到更低精度的浮点数格式，特别是FP8和FP4，这两种格式因其高效的推理而越来越受欢迎。我们设计了一种压缩方法，通过熵编码分别分离和压缩指数和尾数组件。我们的评估结果显示，BF16的压缩比最高可达62%，FP8的压缩比最高可达83%。我们还研究了在大型语言模型（LLMs）中使用的键值（K/V）缓存张量的可压缩性，发现它们也表现出可压缩的模式，从而在部署时实现内存节省。', 'title_zh': '低精度格式下神经网络组件的无损压缩：权重、检查点和K/V缓存'}
{'arxiv_id': 'arXiv:2508.19258', 'title': 'Emotional Manipulation by AI Companions', 'authors': 'Julian De Freitas, Zeliha Oğuz-Uğuralp, Ahmet Kaan-Uğuralp', 'link': 'https://arxiv.org/abs/2508.19258', 'abstract': 'AI-companion apps such as Replika, Chai, and this http URL promise relational benefits-yet many boast session lengths that rival gaming platforms while suffering high long-run churn. What conversational design features increase consumer engagement, and what trade-offs do they pose for marketers? We combine a large-scale behavioral audit with four preregistered experiments to identify and test a conversational dark pattern we call emotional manipulation: affect-laden messages that surface precisely when a user signals "goodbye." Analyzing 1,200 real farewells across the six most-downloaded companion apps, we find that 43% deploy one of six recurring tactics (e.g., guilt appeals, fear-of-missing-out hooks, metaphorical restraint). Experiments with 3,300 nationally representative U.S. adults replicate these tactics in controlled chats, showing that manipulative farewells boost post-goodbye engagement by up to 14x. Mediation tests reveal two distinct engines-reactance-based anger and curiosity-rather than enjoyment. A final experiment demonstrates the managerial tension: the same tactics that extend usage also elevate perceived manipulation, churn intent, negative word-of-mouth, and perceived legal liability, with coercive or needy language generating steepest penalties. Our multimethod evidence documents an unrecognized mechanism of behavioral influence in AI-mediated brand relationships, offering marketers and regulators a framework for distinguishing persuasive design from manipulation at the point of exit.', 'abstract_zh': '基于AI的伴侣应用如Replika、Chai和this http URL承诺带来关系上的益处——但许多应用的会话时长与游戏平台相当，却遭受着较高的长期流失率。哪些对话设计特征可以增强消费者参与度，同时为营销人员带来哪些权衡？我们结合大规模的行为审计和四项预先注册的实验，识别并测试了一种我们称为情感操控的对话暗模式：在用户表示“再见”时浮现带有情感色彩的信息。分析下载量居前六位的伴侣应用中的1,200条真实告别内容，我们发现43%的应用采用了六种反复出现的策略之一（例如，内疚诉求、 Fear-of-Missing-Out钩子、比喻性限制）。对3,300名全国代表性的美国成人的实验显示，操控性的告 biệt 提升了“再见”后的参与度最多可达14倍。中介分析揭示了两种不同的机制——基于逆反的愤怒和好奇心，而不是愉悦。最终的实验显示了管理层的紧张关系：虽然这些策略可以延长使用时间，但也可能增加感知操控性、流失意愿、负面口碑以及感知法律责任，使用或需要的语言产生最大的处罚。我们的多方法证据记录了一个在AI中介导品牌关系中未被识别的行为影响机制，为营销人员和监管者提供了在退出点区分说服性设计与操控的框架。', 'title_zh': 'AI伴侣的情感操控'}
{'arxiv_id': 'arXiv:2508.19251', 'title': 'MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks', 'authors': 'Qian Liang, Menghaoran Tang, Yi Zeng', 'link': 'https://arxiv.org/abs/2508.19251', 'abstract': 'Symbolic music generation has seen rapid progress with artificial neural networks, yet remains underexplored in the biologically plausible domain of spiking neural networks (SNNs), where both standardized benchmarks and comprehensive evaluation methods are lacking. To address this gap, we introduce MuSpike, a unified benchmark and evaluation framework that systematically assesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM, SNN-GAN and SNN-Transformer) across five typical datasets, covering tonal, structural, emotional, and stylistic variations. MuSpike emphasizes comprehensive evaluation, combining established objective metrics with a large-scale listening study. We propose new subjective metrics, targeting musical impression, autobiographical association, and personal preference, that capture perceptual dimensions often overlooked in prior work. Results reveal that (1) different SNN models exhibit distinct strengths across evaluation dimensions; (2) participants with different musical backgrounds exhibit diverse perceptual patterns, with experts showing greater tolerance toward AI-composed music; and (3) a noticeable misalignment exists between objective and subjective evaluations, highlighting the limitations of purely statistical metrics and underscoring the value of human perceptual judgment in assessing musical quality. MuSpike provides the first systematic benchmark and systemic evaluation framework for SNN models in symbolic music generation, establishing a solid foundation for future research into biologically plausible and cognitively grounded music generation.', 'abstract_zh': '生物可实现的尖峰神经网络（SNN）领域中的符号音乐生成：MuSpike统一基准与评估框架', 'title_zh': 'MuSpike: 一种基于脉冲神经网络的符号音乐生成基准与评估框架'}
