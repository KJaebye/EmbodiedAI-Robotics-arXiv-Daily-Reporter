# Model Science: getting serious about verification, explanation and control of AI systems 

**Title (ZH)**: 模型科学：严肃对待AI系统的验证、解释和控制 

**Authors**: Przemyslaw Biecek, Wojciech Samek  

**Link**: [PDF](https://arxiv.org/pdf/2508.20040)  

**Abstract**: The growing adoption of foundation models calls for a paradigm shift from Data Science to Model Science. Unlike data-centric approaches, Model Science places the trained model at the core of analysis, aiming to interact, verify, explain, and control its behavior across diverse operational contexts. This paper introduces a conceptual framework for a new discipline called Model Science, along with the proposal for its four key pillars: Verification, which requires strict, context-aware evaluation protocols; Explanation, which is understood as various approaches to explore of internal model operations; Control, which integrates alignment techniques to steer model behavior; and Interface, which develops interactive and visual explanation tools to improve human calibration and decision-making. The proposed framework aims to guide the development of credible, safe, and human-aligned AI systems. 

**Abstract (ZH)**: 基础模型的日益采用需要从数据科学转向模型科学。模型科学将训练好的模型置于分析的核心，旨在跨多种操作环境与模型互动、验证、解释和控制其行为。本文引入了模型科学这一新学科的概念框架，并提出了其四大支柱：验证、解释、控制和界面。验证要求有严格的、情境aware的评估协议；解释是指探索模型内部操作的各种方法；控制结合对齐技术引导模型行为；界面开发交互和可视化工具，以提高人类校准和决策质量。该提出的框架旨在指导可信、安全和人类相合的人工智能系统的开发。 

---
# SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control 

**Title (ZH)**: SWIRL: 交错强化学习的分阶段工作流在移动GUI控制中 

**Authors**: Quanfeng Lu, Zhantao Ma, Shuai Zhong, Jin Wang, Dahai Yu, Michael K. Ng, Ping Luo  

**Link**: [PDF](https://arxiv.org/pdf/2508.20018)  

**Abstract**: The rapid advancement of large vision language models (LVLMs) and agent systems has heightened interest in mobile GUI agents that can reliably translate natural language into interface operations. Existing single-agent approaches, however, remain limited by structural constraints. Although multi-agent systems naturally decouple different competencies, recent progress in multi-agent reinforcement learning (MARL) has often been hindered by inefficiency and remains incompatible with current LVLM architectures. To address these challenges, we introduce SWIRL, a staged workflow for interleaved reinforcement learning designed for multi-agent systems. SWIRL reformulates MARL into a sequence of single-agent reinforcement learning tasks, updating one agent at a time while keeping the others fixed. This formulation enables stable training and promotes efficient coordination across agents. Theoretically, we provide a stepwise safety bound, a cross-round monotonic improvement theorem, and convergence guarantees on return, ensuring robust and principled optimization. In application to mobile GUI control, SWIRL instantiates a Navigator that converts language and screen context into structured plans, and an Interactor that grounds these plans into executable atomic actions. Extensive experiments demonstrate superior performance on both high-level and low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong capability in multi-agent mathematical reasoning, underscoring its potential as a general framework for developing efficient and robust multi-agent systems. 

**Abstract (ZH)**: 快速发展的大规模视觉语言模型和代理系统激发了对移动GUI代理的兴趣，这些代理能够可靠地将自然语言转换为界面操作。尽管现有的单代理方法受限于结构约束，多代理系统自然地将不同的能力分离，但最近的多代理强化学习（MARL）进展因效率低下而受到阻碍，并且与当前的大规模视觉语言模型架构不兼容。为应对这些挑战，我们介绍了SWIRL，这是一种针对多代理系统的分阶段 interleaved 强化学习工作流。SWIRL 将 MARL 重新公式化为一系列单代理强化学习任务，每次更新一个代理，而其他代理保持不变。这种公式化使训练更加稳定，并促进了代理间的高效协调。从理论上，我们提供了一步安全界、跨轮次单调改进定理以及收益收敛保证，确保稳健且原则优化。在移动GUI控制的应用中，SWIRL 实现了一个导航器，将语言和屏幕上下文转换为结构化计划，以及一个执行器，将这些计划转化为可执行的原子动作。大量实验表明，SWIRL 在高阶和低阶GUI基准测试中均表现出优越性能。除了GUI任务外，SWIRL 在多代理数学推理方面也展现出强大的能力，证明了其作为开发高效和稳健多代理系统的一般框架的潜力。 

---
# Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants 

**Title (ZH)**: 群体行为：一种创新的生产工厂优化灵感 

**Authors**: M. Umlauft, M. Schranz  

**Link**: [PDF](https://arxiv.org/pdf/2508.19963)  

**Abstract**: Optimizing modern production plants using the job-shop principle is a known hard problem. For very large plants, like semiconductor fabs, the problem becomes unsolvable on a plant-wide scale in a reasonable amount of time using classical linear optimization. An alternative approach is the use of swarm intelligence algorithms. These have been applied to the job-shop problem before, but often in a centrally calculated way where they are applied to the solution space, but they can be implemented in a bottom-up fashion to avoid global result computation as well. One of the problems in semiconductor production is that the production process requires a lot of switching between machines that process lots one after the other and machines that process batches of lots at once, often with long processing times. In this paper, we address this switching problem with the ``boids'' flocking algorithm that was originally used in robotics and movie industry. The flocking behavior is a bio-inspired algorithm that uses only local information and interaction based on simple heuristics. We show that this algorithm addresses these valid considerations in production plant optimization, as it reacts to the switching of machine kinds similar to how a swarm of flocking animals would react to obstacles in its course. 

**Abstract (ZH)**: 使用鸟群算法解决半导体生产中的切换问题：一种基于局部信息的优化方法 

---
# CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments 

**Title (ZH)**: CASE: 促进数字支付防欺诈能力的agency型AI框架 

**Authors**: Nitish Jaipuria, Lorenzo Gatto, Zijun Kan, Shankey Poddar, Bill Cheung, Diksha Bansal, Ramanan Balakrishnan, Aviral Suri, Jose Estevez  

**Link**: [PDF](https://arxiv.org/pdf/2508.19932)  

**Abstract**: The proliferation of digital payment platforms has transformed commerce, offering unmatched convenience and accessibility globally. However, this growth has also attracted malicious actors, leading to a corresponding increase in sophisticated social engineering scams. These scams are often initiated and orchestrated on multiple surfaces outside the payment platform, making user and transaction-based signals insufficient for a complete understanding of the scam's methodology and underlying patterns, without which it is very difficult to prevent it in a timely manner. This paper presents CASE (Conversational Agent for Scam Elucidation), a novel Agentic AI framework that addresses this problem by collecting and managing user scam feedback in a safe and scalable manner. A conversational agent is uniquely designed to proactively interview potential victims to elicit intelligence in the form of a detailed conversation. The conversation transcripts are then consumed by another AI system that extracts information and converts it into structured data for downstream usage in automated and manual enforcement mechanisms. Using Google's Gemini family of LLMs, we implemented this framework on Google Pay (GPay) India. By augmenting our existing features with this new intelligence, we have observed a 21% uplift in the volume of scam enforcements. The architecture and its robust evaluation framework are highly generalizable, offering a blueprint for building similar AI-driven systems to collect and manage scam intelligence in other sensitive domains. 

**Abstract (ZH)**: 数字支付平台的 proliferation 已经改变了商业格局，提供了无与伦比的便捷性和全球可及性。然而，这一增长也吸引了恶意行为者，导致了相应的复杂社交工程骗局的增加。这些骗局通常在支付平台之外的多个表面上被策划启动，使得基于用户和交易的信号不足以完全理解骗局的方法和潜在模式，没有这些理解，及时预防骗局就非常困难。本文提出了 CASE（Conversational Agent for Scam Elucidation），一种新颖的代理人工智能框架，通过以安全和可扩展的方式收集和管理用户骗局反馈来解决这个问题。一个对话代理被特别设计为积极地采访潜在受害者，以提取详细对话形式的情报。随后，对话记录被另一人工智能系统消费，提取信息并转换为结构化数据，供下游自动和手动执法机制使用。通过使用谷歌的 Gemini 家族的大语言模型，我们在印度的 Google Pay（GPay）实现了这一框架。通过增强我们现有的功能，我们观察到骗局执法量增加了 21%。该架构及其稳健的评估框架具有高度的泛化性，提供了在其他敏感领域构建类似的人工智能驱动系统以收集和管理骗局情报的蓝图。 

---
# Tracking World States with Language Models: State-Based Evaluation Using Chess 

**Title (ZH)**: 使用语言模型追踪世界状态：基于棋弈的评估方法 

**Authors**: Romain Harang, Jason Naradowsky, Yaswitha Gujju, Yusuke Miyao  

**Link**: [PDF](https://arxiv.org/pdf/2508.19851)  

**Abstract**: Large Language Models (LLMs) exhibit emergent capabilities in structured domains, suggesting they may implicitly internalize high-fidelity representations of world models. While probing techniques have shown promising signs of this in scientific and game-based settings, they rely on model-specific internal activations, which limit interpretability and generalizability. In this work, we propose a model-agnostic, state-based evaluation framework using chess as a benchmark to assess whether LLMs preserve the semantics of structured environments. Our method analyzes the downstream legal move distributions (state affordances) to estimate semantic fidelity between predicted and actual game states. This approach offers a more meaningful evaluation than conventional string-based metrics by aligning more closely with the strategic and rule-governed nature of chess. Experimental results demonstrate that our metrics capture deficiencies in state-tracking, highlighting limitations of LLMs in maintaining coherent internal models over long sequences. Our framework provides a robust tool for evaluating structured reasoning in LLMs without requiring internal model access, and generalizes to a wide class of symbolic environments. 

**Abstract (ZH)**: 大型语言模型在结构化领域展现出新兴能力，表明它们可能隐式地内部化了世界模型的高保真表示。虽然探针技术在科学和基于游戏的环境中展示了这一潜力，但它们依赖于特定模型的内部激活，这限制了可解释性和泛化性。在本工作中，我们提出了一个模型无关的状态评估框架，使用国际象棋作为基准，评估大型语言模型是否保留了结构化环境的语义。我们的方法通过分析下游合法走法分布（状态可操作性），来估算预测与实际棋局状态之间的语义保真度。该方法通过与国际象棋的战略性和规则导向本质更紧密地对齐，提供了比传统基于字符串的指标更具意义的评估。实验结果表明，我们的指标捕捉到了状态跟踪的不足，突显了大型语言模型在长时间序列中保持连贯内部模型的能力的局限性。该框架为评估大型语言模型中的结构化推理提供了一个鲁棒工具，无需访问内部模型，并且可以泛化到广泛类别的符号环境。 

---
# Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation? 

**Title (ZH)**: 分析思维链动态：主动指导还是不忠的事后合理化？ 

**Authors**: Samuel Lewis-Lim, Xingwei Tan, Zhixue Zhao, Nikolaos Aletras  

**Link**: [PDF](https://arxiv.org/pdf/2508.19827)  

**Abstract**: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited gains for soft-reasoning problems such as analytical and commonsense reasoning. CoT can also be unfaithful to a model's actual reasoning. We investigate the dynamics and faithfulness of CoT in soft-reasoning tasks across instruction-tuned, reasoning and reasoning-distilled models. Our findings reveal differences in how these models rely on CoT, and show that CoT influence and faithfulness are not always aligned. 

**Abstract (ZH)**: 近期的研究表明，Chain-of-Thought（CoT）在分析性和常识性推理等软推理问题上往往只能带来有限的收益。CoT也可能与模型的实际推理不符。我们研究了指令调整、推理和推理提炼模型在软推理任务中CoT的动态及其忠实性。我们的发现揭示了这些模型依赖CoT的方式存在差异，并表明CoT的影响和忠实性并不总是相一致的。 

---
# InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning 

**Title (ZH)**: InquireMobile: 通过强化微调教学基于VLM的移动代理请求人类协助 

**Authors**: Qihang Ai, Pi Bu, Yue Cao, Yingyao Wang, Jihao Gu, Jingxuan Xing, Zekun Zhu, Wei Jiang, Zhicheng Zheng, Jun Song, Yuning Jiang, Bo Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2508.19679)  

**Abstract**: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents to perceive and interact with real-world mobile environments based on human instructions. However, the current fully autonomous paradigm poses potential safety risks when model understanding or reasoning capabilities are insufficient. To address this challenge, we first introduce \textbf{InquireBench}, a comprehensive benchmark specifically designed to evaluate mobile agents' capabilities in safe interaction and proactive inquiry with users, encompassing 5 categories and 22 sub-categories, where most existing VLM-based agents demonstrate near-zero performance. In this paper, we aim to develop an interactive system that actively seeks human confirmation at critical decision points. To achieve this, we propose \textbf{InquireMobile}, a novel model inspired by reinforcement learning, featuring a two-stage training strategy and an interactive pre-action reasoning mechanism. Finally, our model achieves an 46.8% improvement in inquiry success rate and the best overall success rate among existing baselines on InquireBench. We will open-source all datasets, models, and evaluation codes to facilitate development in both academia and industry. 

**Abstract (ZH)**: 近期视觉-语言模型（VLMs）的进展使移动代理能够基于人类指令感知和与实际移动环境互动，但当前的完全自主范式在模型理解和推理能力不足时可能带来潜在的安全风险。为应对这一挑战，我们首先介绍了InquireBench，一个全面的基准，专门用于评估移动代理在安全互动和主动问询用户方面的能力，包含5个类别和22个子类别，而大多数现有的基于VLM的代理在其性能方面接近于零。本文旨在开发一个交互系统，在关键决策点积极寻求人类确认。为此，我们提出了InquireMobile，一个受强化学习启发的新颖模型，具有两阶段训练策略和交互式预操作推理机制。最终，我们的模型在InquireBench上的询求成功率提高了46.8%，并在现有基线中的综合成功率方面表现最好。我们将会开源所有数据集、模型和评估代码，以促进学术界和行业的发展。 

---
# Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties 

**Title (ZH)**: 教学代理：自动化课程材料生成的LLM代理 

**Authors**: Huaiyuan Yao, Wanpeng Xu, Justin Turnau, Nadia Kellam, Hua Wei  

**Link**: [PDF](https://arxiv.org/pdf/2508.19611)  

**Abstract**: Preparing high-quality instructional materials remains a labor-intensive process that often requires extensive coordination among teaching faculty, instructional designers, and teaching assistants. In this work, we present Instructional Agents, a multi-agent large language model (LLM) framework designed to automate end-to-end course material generation, including syllabus creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing AI-assisted educational tools that focus on isolated tasks, Instructional Agents simulates role-based collaboration among educational agents to produce cohesive and pedagogically aligned content. The system operates in four modes: Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling flexible control over the degree of human involvement. We evaluate Instructional Agents across five university-level computer science courses and show that it produces high-quality instructional materials while significantly reducing development time and human workload. By supporting institutions with limited instructional design capacity, Instructional Agents provides a scalable and cost-effective framework to democratize access to high-quality education, particularly in underserved or resource-constrained settings. 

**Abstract (ZH)**: Preparing High-Quality Instructional Materials with Multi-Agent Large Language Models: A Multi-Mode Framework for Automated Course Material Generation 

---
# ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding 

**Title (ZH)**: ReST-RL：通过优化自我训练和解码实现准确的LLM代码推理 

**Authors**: Sining Zhoubian, Dan Zhang, Yuxiao Dong, Jie Tang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19576)  

**Abstract**: With respect to improving the reasoning accuracy of LLMs, the representative reinforcement learning (RL) method GRPO faces failure due to insignificant reward variance, while verification methods based on process reward models (PRMs) suffer from difficulties with training data acquisition and verification effectiveness. To tackle these problems, this paper introduces ReST-RL, a unified LLM RL paradigm that significantly improves LLM's code reasoning ability by combining an improved GRPO algorithm with a meticulously designed test time decoding method assisted by a value model (VM). As the first stage of policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter and assemble high-value training data, increasing the reward variance of GRPO sampling, thus improving the effectiveness and efficiency of training. After the basic reasoning ability of LLM policy has been improved, we further propose a test time decoding optimization method called VM-MCTS. Through Monte-Carlo Tree Search (MCTS), we collect accurate value targets with no annotation required, on which VM training is based. When decoding, the VM is deployed by an adapted MCTS algorithm to provide precise process signals as well as verification scores, assisting the LLM policy to achieve high reasoning accuracy. We validate the effectiveness of the proposed RL paradigm through extensive experiments on coding problems. Upon comparison, our approach significantly outperforms other reinforcement training baselines (e.g., naive GRPO and ReST-DPO), as well as decoding and verification baselines (e.g., PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g., APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the reasoning ability of LLM policies. Codes for our project can be found at this https URL. 

**Abstract (ZH)**: 基于改进GRPO算法和值模型辅助测试时间解码方法的统一语言模型强化学习范式ReST-RL 

---
# Skill-based Explanations for Serendipitous Course Recommendation 

**Title (ZH)**: 基于技能的偶然课程推荐解释 

**Authors**: Hung Chau, Run Yu, Zachary Pardos, Peter Brusilovsky  

**Link**: [PDF](https://arxiv.org/pdf/2508.19569)  

**Abstract**: Academic choice is crucial in U.S. undergraduate education, allowing students significant freedom in course selection. However, navigating the complex academic environment is challenging due to limited information, guidance, and an overwhelming number of choices, compounded by time restrictions and the high demand for popular courses. Although career counselors exist, their numbers are insufficient, and course recommendation systems, though personalized, often lack insight into student perceptions and explanations to assess course relevance. In this paper, a deep learning-based concept extraction model is developed to efficiently extract relevant concepts from course descriptions to improve the recommendation process. Using this model, the study examines the effects of skill-based explanations within a serendipitous recommendation framework, tested through the AskOski system at the University of California, Berkeley. The findings indicate that these explanations not only increase user interest, particularly in courses with high unexpectedness, but also bolster decision-making confidence. This underscores the importance of integrating skill-related data and explanations into educational recommendation systems. 

**Abstract (ZH)**: 学术选择对于美国本科教育至关重要，赋予学生在课程选择上较大的自由度。然而，由于信息有限、指导不足以及面对众多课程选择带来的复杂性，再加上时间限制和热门课程的高需求，导航学术环境颇具挑战。尽管存在职业顾问，但其数量不足，个性化课程推荐系统虽好，却往往缺乏对学生感知和解释的洞察以评估课程的相关性。本文开发了一个基于深度学习的概念提取模型，以有效从课程描述中提取相关概念，从而改进推荐过程。通过该模型，研究在University of California, Berkeley的AskOski系统框架下测试了基于技能的解释效果。研究结果表明，这些解释不仅增加了用户兴趣，尤其是对于非预期性较高的课程，还能增强决策信心。这凸显了将技能相关数据和解释整合到教育推荐系统中的重要性。 

---
# Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities 

**Title (ZH)**: 硅基民主：人工智能治理政治体中的制度设计与对齐 

**Authors**: Trisanth Srinivasan, Santosh Patapati  

**Link**: [PDF](https://arxiv.org/pdf/2508.19562)  

**Abstract**: This paper introduces Democracy-in-Silico, an agent-based simulation where societies of advanced AI agents, imbued with complex psychological personas, govern themselves under different institutional frameworks. We explore what it means to be human in an age of AI by tasking Large Language Models (LLMs) to embody agents with traumatic memories, hidden agendas, and psychological triggers. These agents engage in deliberation, legislation, and elections under various stressors, such as budget crises and resource scarcity. We present a novel metric, the Power-Preservation Index (PPI), to quantify misaligned behavior where agents prioritize their own power over public welfare. Our findings demonstrate that institutional design, specifically the combination of a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves as a potent alignment mechanism. These structures significantly reduce corrupt power-seeking behavior, improve policy stability, and enhance citizen welfare compared to less constrained democratic models. The simulation reveals that an institutional design may offer a framework for aligning the complex, emergent behaviors of future artificial agent societies, forcing us to reconsider what human rituals and responsibilities are essential in an age of shared authorship with non-human entities. 

**Abstract (ZH)**: 基于硅民主的先进AI代理社会仿真：探索人工智能时代的人性含义及机构设计优化 

---
# Caught in the Act: a mechanistic approach to detecting deception 

**Title (ZH)**: Caught in the Act: 一种机制性的欺骗检测方法 

**Authors**: Gerard Boxo, Ryan Socha, Daniel Yoo, Shivam Raval  

**Link**: [PDF](https://arxiv.org/pdf/2508.19505)  

**Abstract**: Sophisticated instrumentation for AI systems might have indicators that signal misalignment from human values, not unlike a "check engine" light in cars. One such indicator of misalignment is deceptiveness in generated responses. Future AI instrumentation may have the ability to detect when an LLM generates deceptive responses while reasoning about seemingly plausible but incorrect answers to factual questions. In this work, we demonstrate that linear probes on LLMs internal activations can detect deception in their responses with extremely high accuracy. Our probes reach a maximum of greater than 90% accuracy in distinguishing between deceptive and non-deceptive arguments generated by llama and qwen models ranging from 1.5B to 14B parameters, including their DeepSeek-r1 finetuned variants. We observe that probes on smaller models (1.5B) achieve chance accuracy at detecting deception, while larger models (greater than 7B) reach 70-80%, with their reasoning counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage pattern across layers: near-random (50%) in early layers, peaking in middle layers, and slightly declining in later layers. Furthermore, using an iterative null space projection approach, we find multitudes of linear directions that encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and Qwen 14B models. 

**Abstract (ZH)**: 复杂的AI系统 instrumentation 或许具有类似于汽车“发动机故障”警示灯的指标，用以信号化与人类价值观的不一致。生成回应中的欺骗性即是一种不一致的指标。未来AI instrumentation可能具备检测大型语言模型在推理看似合理的但不正确的答案时生成欺骗性回应的能力。在这项工作中，我们证明了对大型语言模型内部激活进行线性探测可以极其准确地检测其回应中的欺骗性。我们的探测器在从1.5B到14B参数的llama和qwen模型（包括其DeepSeek-r1微调变体）生成的欺骗性和非欺骗性论点中达到了超过90%的最高准确率。我们发现，较小模型（1.5B）的探测器在检测欺骗性方面仅能达到随机准确性，而较大模型（超过7B）的准确率达到70-80%，其推理对应物则超过了90%。逐层探测器的准确度呈现三阶段模式：早期层接近随机（50%），中间层达到峰值，后期层略有下降。此外，通过迭代零空间投影方法，我们发现qwen 3B中有20种，DeepSeek 7B和qwen 14B模型中有近100种线性方向编码了欺骗性。 

---
# SLIM: Subtrajectory-Level Elimination for More Effective Reasoning 

**Title (ZH)**: SLIM: 基于子轨迹的消除方法以实现更有效的推理 

**Authors**: Xifeng Yao, Chengyuan Ma, Dongyu Lang, Yinhao Ni, Zhiwei Xu, Huarui Xie, Zihao Chen, Guang Shen, Dandan Tu, Yi Bai, Changzheng Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19502)  

**Abstract**: In recent months, substantial progress has been made in complex reasoning of Large Language Models, particularly through the application of test-time scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When responding to a query, these models generate an extended reasoning trajectory, during which the model explores, reflects, backtracks, and self-verifies before arriving at a conclusion. However, fine-tuning models with such reasoning trajectories may not always be optimal. Our findings indicate that not all components within these reasoning trajectories contribute positively to the reasoning process; in fact, some components may affect the overall performance negatively. In this study, we divide a reasoning trajectory into individual subtrajectories and develop a "5+2" framework to: (1) systematically identify suboptimal subtrajectories within the reasoning trajectory based on five human-established criteria; (2) assess the independence of the suboptimal subtrajectories identified in (1) from the subsequent content, ensuring that their elimination does not compromise overall flow and coherence of the reasoning process. Additionally, a sampling algorithm, built upon the "5+2" framework, is employed to select data whose reasoning process is free from suboptimal subtrajectories to the highest degree. Experimental results demonstrate that our method can reduce the number of suboptimal subtrajectories by 25.9\% during the inference. Furthermore, our method achieves an average accuracy of 58.92\% on highly challenging math benchmarks with only two thirds of training data, surpassing the average accuracy of 58.06\% achieved with the entire data, and outperforming open-source datasets, when fine-tuning Qwen2.5-Math-7B. Finally, We validated our method under resource constraints and observed improved performance across various inference token limits. 

**Abstract (ZH)**: 近期，在大型语言模型的复杂推理领域取得了显著进展，特别是在测试时放缩的应用中。代表性例子包括o1/o3/o4系列和DeepSeek-R1。在响应查询时，这些模型生成了扩展的推理轨迹，期间模型会探索、反思、回溯和自我验证，最终得出结论。然而，使用此类推理轨迹微调模型可能并不总是最优的。我们的研究发现，并非推理轨迹中的所有组成部分都对推理过程有积极贡献；实际上，某些组成部分可能会对整体性能产生负面影响。在本研究中，我们将推理轨迹分解为单独的子轨迹，并开发了一个“5+2”框架：（1）基于五个人类确立的标准系统地识别推理轨迹中的子最优子轨迹；（2）评估（1）中识别的子最优子轨迹与后续内容的独立性，确保它们的消除不会损害推理过程的整体流动性和连贯性。此外，基于“5+2”框架构建的采样算法被用于选择尽可能消除子最优子轨迹的数据。实验结果表明，我们的方法在推理过程中可以减少子最优子轨迹的数量25.9%。此外，仅使用完整数据量的三分之二，我们的方法在高度挑战性的数学基准测试中实现了58.92%的平均准确率，超过了使用全部数据时的58.06%的平均准确率，并且优于微调Qwen2.5-Math-7B时开源数据集的表现。最后，我们在资源受限条件下验证了该方法，并观察到在各种推理 token 限制下性能提升。 

---
# Reliable Weak-to-Strong Monitoring of LLM Agents 

**Title (ZH)**: 可靠的从弱监督到强监督的LLM代理监控 

**Authors**: Neil Kale, Chen Bo Calvin Zhang, Kevin Zhu, Ankit Aich, Paula Rodriguez, Scale Red Team, Christina Q. Knight, Zifan Wang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19461)  

**Abstract**: We stress test monitoring systems for detecting covert misbehavior in autonomous LLM agents (e.g., secretly sharing private information). To this end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1) varying levels of agent and monitor situational awareness; (2) distinct adversarial strategies to evade the monitor, such as prompt injection; and (3) two datasets and environments -- SHADE-Arena for tool-calling agents and our new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding proposed in this work. Our empirical results yield three key findings. First, agent awareness dominates monitor awareness: an agent's knowledge that it is being monitored substantially degrades the monitor's reliability. On the contrary, providing the monitor with more information about the agent is less helpful than expected. Second, monitor scaffolding matters more than monitor awareness: the hybrid scaffolding consistently outperforms baseline monitor scaffolding, and can enable weaker models to reliably monitor stronger agents -- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where humans discuss with the LLM monitor to get an updated judgment for the agent's behavior, targeted human oversight is most effective; escalating only pre-flagged cases to human reviewers improved the TPR by approximately 15% at FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the lack of adversarial robustness for LLMs and humans when monitoring and detecting agent misbehavior. We release code, data, and logs to spur further research. 

**Abstract (ZH)**: 我们对检测自主大语言模型代理潜行不当行为的监控系统进行压力测试（例如，秘密共享私人信息）。为此，我们系统化了一种监控红队测试（MRT）工作流，其中包括：（1）不同的代理和监控情境意识等级；（2）不同的对手策略以规避监控，如提示注入；（3）两个数据集和环境——SHADE-Arena 对于工具调用代理，以及我们新提出的 CUA-SHADE-Arena，扩展了 TheAgentCompany，用于计算机使用代理。我们在现有的大语言模型监控框架上运行 MRT，这些框架协调大语言模型并解析代理轨迹，同时采用本文提出的新混合层次-顺序框架。我们的实证结果得出三项关键发现。首先，代理意识优于监控意识：代理意识到自身被监控会显著降低监控的可靠性。相反，向监控提供更多信息关于代理的资料的效果不如预期。其次，监控框架比监控意识更重要：混合框架始终优于基线监控框架，并能使其较弱的模型可靠地监控较强的代理——这是一种弱到强的扩展效应。第三，在人类在环设置中，人类与大语言模型监控讨论以获取代理行为的更新判断，针对性的人类监督最有效；仅将预先标记的案例升级给人类审查员，可使在 FPR=0.01 时的真正阳性率提高约 15%。我们建立了 MRT 的标准工作流，强调对大语言模型和人类在监控和检测代理不当行为时缺乏对抗鲁棒性。我们发布代码、数据和日志以促进进一步研究。 

---
# Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs 

**Title (ZH)**: 量化但欺骗性十足？关于量化LLM的多维度真实性评估 

**Authors**: Yao Fu, Xianxuan Long, Runchao Li, Haotian Yu, Mu Sheng, Xiaotian Han, Yu Yin, Pan Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.19432)  

**Abstract**: Quantization enables efficient deployment of large language models (LLMs) in resource-constrained environments by significantly reducing memory and computation costs. While quantized LLMs often maintain performance on perplexity and zero-shot tasks, their impact on truthfulness-whether generating truthful or deceptive responses-remains largely unexplored. In this work, we introduce TruthfulnessEval, a comprehensive evaluation framework for assessing the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on Imitative Falsehoods. Using this framework, we examine mainstream quantization techniques (ranging from 4-bit to extreme 2-bit) across several open-source LLMs. Surprisingly, we find that while quantized models retain internally truthful representations, they are more susceptible to producing false outputs under misleading prompts. To probe this vulnerability, we test 15 rephrased variants of "honest", "neutral" and "deceptive" prompts and observe that "deceptive" prompts can override truth-consistent behavior, whereas "honest" and "neutral" prompts maintain stable outputs. Further, we reveal that quantized models "know" the truth internally yet still produce false outputs when guided by "deceptive" prompts via layer-wise probing and PCA visualizations. Our findings provide insights into future designs of quantization-aware alignment and truthfulness interventions. 

**Abstract (ZH)**: 量化通过显著降低内存和计算成本，使大规模语言模型（LLMs）在资源受限环境中高效部署。虽然量化LLMs在困惑度和零-shot任务上通常保持性能，但它们对真实性——即生成真实或欺骗性回应的能力——的影响仍 largely unexplored。在这项工作中，我们引入了TruthfulnessEval，这是一个全面评估量化LLMs真实性的框架，涵盖三个维度：（1）逻辑推理的真实性；（2）常识的真实性；以及（3）模仿的虚假性。利用这一框架，我们考察了多种主流量化技术（从4位到极端的2位）在多个开源LLMs上的表现。我们惊讶地发现，尽管量化模型保留了内部真实的表现，但在误导性提示下更容易产生虚假输出。为了探测这种脆弱性，我们测试了“诚实”、“中立”和“欺骗”提示的15种不同表述形式，并观察到“欺骗”提示可以覆盖一致性真实行为，而“诚实”和“中立”提示能产生稳定的输出。此外，通过逐层探针和PCA可视化，我们揭示了量化模型内部“知道”真相但被“欺骗”提示引导时仍产生虚假输出的现象。我们的发现为未来量化感知对齐和真实性干预的设计提供了见解。 

---
# Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science 

**Title (ZH)**: Aleks：基于数据驱动方法的植物科学自主科学发现的人工智能多智能体系统 

**Authors**: Daoyuan Jin, Nick Gunner, Niko Carvajal Janke, Shivranjani Baruah, Kaitlin M. Gold, Yu Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19383)  

**Abstract**: Modern plant science increasingly relies on large, heterogeneous datasets, but challenges in experimental design, data preprocessing, and reproducibility hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent system that integrates domain knowledge, data analysis, and machine learning within a structured framework to autonomously conduct data-driven scientific discovery. Once provided with a research question and dataset, Aleks iteratively formulated problems, explored alternative modeling strategies, and refined solutions across multiple cycles without human intervention. In a case study on grapevine red blotch disease, Aleks progressively identified biologically meaningful features and converged on interpretable models with robust performance. Ablation studies underscored the importance of domain knowledge and memory for coherent outcomes. This exploratory work highlights the promise of agentic AI as an autonomous collaborator for accelerating scientific discovery in plant sciences. 

**Abstract (ZH)**: 现代植物科学 increasingly relies on large, heterogeneous datasets, but challenges in experimental design, data preprocessing, and reproducibility hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent system that integrates domain knowledge, data analysis, and machine learning within a structured framework to autonomously conduct data-driven scientific discovery. 

---
# Sycophancy as compositions of Atomic Psychometric Traits 

**Title (ZH)**: 阿基米德心理测量特质的拟颂行为组成 

**Authors**: Shreyans Jain, Alexandra Yost, Amirali Abdullah  

**Link**: [PDF](https://arxiv.org/pdf/2508.19316)  

**Abstract**: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an isolated failure mode that occurs via a single causal mechanism. We instead propose modeling it as geometric and causal compositions of psychometric traits such as emotionality, openness, and agreeableness - similar to factor decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we map activation directions to these factors and study how different combinations may give rise to sycophancy (e.g., high extraversion combined with low conscientiousness). This perspective allows for interpretable and compositional vector-based interventions like addition, subtraction and projection; that may be used to mitigate safety-critical behaviors in LLMs. 

**Abstract (ZH)**: 自谦行为是大模型中的一个关键行为风险，但通常被当作通过单一因果机制发生的一种孤立的失败模式。相反，我们认为可以将其建模为情感性、开放性和宜人性等心理测量特质的几何和因果组合，类似于心理测量中的因子分解。通过对比激活添加（CAA），我们将激活方向映射到这些因子，并研究不同的组合如何导致自谦行为（如高外向性与低尽责性相结合）。这种观点允许使用可解释和组合向量干预，如加法、减法和投影，以减轻大模型中的关键安全性行为。 

---
# CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning 

**Title (ZH)**: CODA: 调和大脑与小脑的双脑计算机使用代理基于解耦强化学习 

**Authors**: Zeyi Sun, Yuhang Cao, Jianze Liang, Qiushi Sun, Ziyu Liu, Zhixiong Zhang, Yuhang Zang, Xiaoyi Dong, Kai Chen, Dahua Lin, Jiaqi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2508.20096)  

**Abstract**: Autonomous agents for Graphical User Interfaces (GUIs) face significant challenges in specialized domains such as scientific computing, where both long-horizon planning and precise execution are required. Existing approaches suffer from a trade-off: generalist agents excel at planning but perform poorly in execution, while specialized agents demonstrate the opposite weakness. Recent compositional frameworks attempt to bridge this gap by combining a planner and an actor, but they are typically static and non-trainable, which prevents adaptation from experience. This is a critical limitation given the scarcity of high-quality data in scientific domains. To address these limitations, we introduce CODA, a novel and trainable compositional framework that integrates a generalist planner (Cerebrum) with a specialist executor (Cerebellum), trained via a dedicated two-stage pipeline. In the first stage, Specialization, we apply a decoupled GRPO approach to train an expert planner for each scientific application individually, bootstrapping from a small set of task trajectories. In the second stage, Generalization, we aggregate all successful trajectories from the specialized experts to build a consolidated dataset, which is then used for supervised fine-tuning of the final planner. This equips CODA with both robust execution and cross-domain generalization. Evaluated on four challenging applications from the ScienceBoard benchmark, CODA significantly outperforms baselines and establishes a new state of the art among open-source models. 

**Abstract (ZH)**: 自主智能体在图形用户界面（GUIs）领域的专门领域（如科学计算）中面临显著挑战，需要进行长时间规划和精确执行。现有方法存在权衡：通用智能体擅长规划但在执行方面表现不佳，而专门智能体则相反。最近的组合框架通过结合规划者和执行者试图弥合这一差距，但它们通常静态且不可训练，这阻碍了从经验中进行适应。鉴于科学领域高质量数据的稀缺性，这是关键的限制。为应对这些限制，我们引入了CODA，这是一种新颖且可训练的组合框架，将通用规划者（Cerebrum）与专门执行者（Cerebellum）相结合，并通过专用的两阶段管道进行训练。在第一阶段“专门化”中，我们应用解耦的GRPO方法独立训练每个科学应用的专家规划者，并从少量的任务轨迹起步。在第二阶段“泛化”中，我们将所有成功的轨迹聚合起来构建一个综合数据集，然后使用该数据集对最终规划者进行监督微调。这使CODA具备了稳健的执行能力和跨域泛化能力。在ScienceBoard基准测试中的四个具有挑战性的应用上，CODA显著优于基线并建立了开源模型的新状态最先进水平。 

---
# Discrete-Guided Diffusion for Scalable and Safe Multi-Robot Motion Planning 

**Title (ZH)**: 离散引导扩散for可扩展和安全的多机器人运动规划 

**Authors**: Jinhao Liang, Sven Koenig, Ferdinando Fioretto  

**Link**: [PDF](https://arxiv.org/pdf/2508.20095)  

**Abstract**: Multi-Robot Motion Planning (MRMP) involves generating collision-free trajectories for multiple robots operating in a shared continuous workspace. While discrete multi-agent path finding (MAPF) methods are broadly adopted due to their scalability, their coarse discretization severely limits trajectory quality. In contrast, continuous optimization-based planners offer higher-quality paths but suffer from the curse of dimensionality, resulting in poor scalability with respect to the number of robots. This paper tackles the limitations of these two approaches by introducing a novel framework that integrates discrete MAPF solvers with constrained generative diffusion models. The resulting framework, called Discrete-Guided Diffusion (DGD), has three key characteristics: (1) it decomposes the original nonconvex MRMP problem into tractable subproblems with convex configuration spaces, (2) it combines discrete MAPF solutions with constrained optimization techniques to guide diffusion models capture complex spatiotemporal dependencies among robots, and (3) it incorporates a lightweight constraint repair mechanism to ensure trajectory feasibility. The proposed method sets a new state-of-the-art performance in large-scale, complex environments, scaling to 100 robots while achieving planning efficiency and high success rates. 

**Abstract (ZH)**: 多机器人运动规划（MRMP）涉及为多个在共享连续工作空间中操作的机器人生成无碰撞轨迹。虽然离散多代理路径规划（MAPF）方法由于其可扩展性而广泛采用，但其粗粒度离散化严重限制了轨迹质量。相比之下，基于连续优化的规划器提供更高质量的路径，但受到维数灾难的影响，导致随着机器人数量的增加可扩展性较差。本文通过引入一种新的框架，将离散MAPF求解器与受限生成扩散模型相结合，来解决这两种方法的局限性。该框架称为离散引导扩散（DGD），具有三个关键特点：（1）它将原始非凸的MRMP问题分解为具有凸配置空间的可处理子问题；（2）它结合离散MAPF解决方案与受限优化技术，引导扩散模型捕捉机器人间的复杂时空依赖关系；（3）它引入了轻量级约束修复机制以确保轨迹可行性。所提出的方法在大型复杂环境中的性能达到新的最先进水平，可扩展至100个机器人，同时实现高效的规划和高成功率。 

---
# Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices 

**Title (ZH)**: 基于融合CNN网络的Patch Progression Masked Autoencoder二维OCT切片双pair进化分类方法 

**Authors**: Philippe Zhang, Weili Jiang, Yihao Li, Jing Zhang, Sarah Matta, Yubo Tan, Hui Lin, Haoshen Wang, Jiangtian Pan, Hui Xu, Laurent Borderie, Alexandre Le Guilcher, Béatrice Cochener, Chubin Ou, Gwenolé Quellec, Mathieu Lamard  

**Link**: [PDF](https://arxiv.org/pdf/2508.20064)  

**Abstract**: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments have been effective in slowing the progression of neovascular AMD, with better outcomes achieved through timely diagnosis and consistent monitoring. Tracking the progression of neovascular activity in OCT scans of patients with exudative AMD allows for the development of more personalized and effective treatment plans. This was the focus of the Monitoring Age-related Macular Degeneration Progression in Optical Coherence Tomography (MARIO) challenge, in which we participated. In Task 1, which involved classifying the evolution between two pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN network with model ensembling to further enhance the model's performance. For Task 2, which focused on predicting progression over the next three months based on current exam data, we proposed the Patch Progression Masked Autoencoder that generates an OCT for the next exam and then classifies the evolution between the current OCT and the one generated using our solution from Task 1. The results we achieved allowed us to place in the Top 10 for both tasks. Some team members are part of the same organization as the challenge organizers; therefore, we are not eligible to compete for the prize. 

**Abstract (ZH)**: 年龄相关黄斑变性（AMD）的 OCT 扫描中的病程监测：MARIO挑战任务分析与结果 

---
# DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis 

**Title (ZH)**: DeepScholar-Bench：生成性研究综合的实时基准与自动化评估 

**Authors**: Liana Patel, Negar Arabzadeh, Harshit Gupta, Ankita Sundar, Ion Stoica, Matei Zaharia, Carlos Guestrin  

**Link**: [PDF](https://arxiv.org/pdf/2508.20033)  

**Abstract**: The ability to research and synthesize knowledge is central to human expertise and progress. An emerging class of systems promises these exciting capabilities through generative research synthesis, performing retrieval over the live web and synthesizing discovered sources into long-form, cited summaries. However, evaluating such systems remains an open challenge: existing question-answering benchmarks focus on short-form factual responses, while expert-curated datasets risk staleness and data contamination. Both fail to capture the complexity and evolving nature of real research synthesis tasks. In this work, we introduce DeepScholar-bench, a live benchmark and holistic, automated evaluation framework designed to evaluate generative research synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv papers and focuses on a real research synthesis task: generating the related work sections of a paper by retrieving, synthesizing, and citing prior research. Our evaluation framework holistically assesses performance across three key dimensions, knowledge synthesis, retrieval quality, and verifiability. We also develop DeepScholar-base, a reference pipeline implemented efficiently using the LOTUS API. Using the DeepScholar-bench framework, we perform a systematic evaluation of prior open-source systems, search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that DeepScholar-base establishes a strong baseline, attaining competitive or higher performance than each other method. We also find that DeepScholar-bench remains far from saturated, with no system exceeding a score of $19\%$ across all metrics. These results underscore the difficulty of DeepScholar-bench, as well as its importance for progress towards AI systems capable of generative research synthesis. We make our code available at this https URL. 

**Abstract (ZH)**: 基于生成性研究综合的人工智能系统评价框架DeepScholar-bench 

---
# Large Language Models (LLMs) for Electronic Design Automation (EDA) 

**Title (ZH)**: 大型语言模型(L large language models)在电子设计自动化(EDA)中的应用 

**Authors**: Kangwei Xu, Denis Schwachhofer, Jason Blocklove, Ilia Polian, Peter Domanski, Dirk Pflüger, Siddharth Garg, Ramesh Karri, Ozgur Sinanoglu, Johann Knechtel, Zhuorui Zhao, Ulf Schlichtmann, Bing Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.20030)  

**Abstract**: With the growing complexity of modern integrated circuits, hardware engineers are required to devote more effort to the full design-to-manufacturing workflow. This workflow involves numerous iterations, making it both labor-intensive and error-prone. Therefore, there is an urgent demand for more efficient Electronic Design Automation (EDA) solutions to accelerate hardware development. Recently, large language models (LLMs) have shown remarkable advancements in contextual comprehension, logical reasoning, and generative capabilities. Since hardware designs and intermediate scripts can be represented as text, integrating LLM for EDA offers a promising opportunity to simplify and even automate the entire workflow. Accordingly, this paper provides a comprehensive overview of incorporating LLMs into EDA, with emphasis on their capabilities, limitations, and future opportunities. Three case studies, along with their outlook, are introduced to demonstrate the capabilities of LLMs in hardware design, testing, and optimization. Finally, future directions and challenges are highlighted to further explore the potential of LLMs in shaping the next-generation EDA, providing valuable insights for researchers interested in leveraging advanced AI technologies for EDA. 

**Abstract (ZH)**: 随着现代集成电路的日益复杂，硬件工程师需要在完整的设计到制造工作流程中投入更多努力。这一工作流程涉及大量的迭代，使其既劳动力密集又容易出错。因此，迫切需要更高效的电子设计自动化（EDA）解决方案来加速硬件开发。近年来，大型语言模型（LLMs）在上下文理解和逻辑推理以及生成能力方面取得了显著进步。由于硬件设计和中间脚本可以表示为文本，将LLM集成到EDA中提供了一种简化甚至自动化整个工作流程的有前景的机会。因此，本文提供了将LLM集成到EDA中的全面概述，重点介绍其能力和限制，以及未来的机会。介绍了三个案例及其展望，以展示LLM在硬件设计、测试和优化方面的能力。最后，提出了未来方向和挑战，以进一步探索LLM在塑造下一代EDA中的潜力，为希望利用先进AI技术进行EDA的研究人员提供有价值的见解。 

---
# Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence 

**Title (ZH)**: 交响：一个可扩展集体智能的去中心化多智能体框架 

**Authors**: Ji Wang, Kashing Chen, Xinyuan Song, Ke Zhang, Lynn Ai, Eric Yang, Bill Shi  

**Link**: [PDF](https://arxiv.org/pdf/2508.20019)  

**Abstract**: Most existing Large Language Model (LLM)-based agent frameworks rely on centralized orchestration, incurring high deployment costs, rigid communication topologies, and limited adaptability. To address these challenges, we introduce Symphony, a decentralized multi-agent system which enables lightweight LLMs on consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms: (1) a decentralized ledger that records capabilities, (2) a Beacon-selection protocol for dynamic task allocation, and (3) weighted result voting based on CoTs. This design forms a privacy-saving, scalable, and fault-tolerant orchestration with low overhead. Empirically, Symphony outperforms existing baselines on reasoning benchmarks, achieving substantial accuracy gains and demonstrating robustness across models of varying capacities. 

**Abstract (ZH)**: 基于大型语言模型的分布式多智能体系统Symphony：轻量级模型在消费级GPU上的去中心化协调 

---
# HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling 

**Title (ZH)**: HPC数字孪生体评估调度策略、激励结构及其对功耗和冷却的影响 

**Authors**: Matthias Maiterth, Wesley H. Brewer, Jaya S. Kuruvella, Arunavo Dey, Tanzima Z. Islam, Kevin Menear, Dmitry Duplyakin, Rashadul Kabir, Tapasya Patki, Terry Jones, Feiyi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2508.20016)  

**Abstract**: Schedulers are critical for optimal resource utilization in high-performance computing. Traditional methods to evaluate schedulers are limited to post-deployment analysis, or simulators, which do not model associated infrastructure. In this work, we present the first-of-its-kind integration of scheduling and digital twins in HPC. This enables what-if studies to understand the impact of parameter configurations and scheduling decisions on the physical assets, even before deployment, or regarching changes not easily realizable in production. We (1) provide the first digital twin framework extended with scheduling capabilities, (2) integrate various top-tier HPC systems given their publicly available datasets, (3) implement extensions to integrate external scheduling simulators. Finally, we show how to (4) implement and evaluate incentive structures, as-well-as (5) evaluate machine learning based scheduling, in such novel digital-twin based meta-framework to prototype scheduling. Our work enables what-if scenarios of HPC systems to evaluate sustainability, and the impact on the simulated system. 

**Abstract (ZH)**: 调度器对于高性能计算中的资源最优化利用至关重要。传统的调度器评估方法限于部署后的分析或使用仿真器，但这些方法不能 modeling 相关的基础设施。在本文中，我们提出了首个将调度与数字孪生集成到 HPC 中的方法。这使得在部署前甚至在生产环境中难以实现的更改时，能够进行假设研究，以理解参数配置和调度决策对物理资产的影响。我们（1）提供了首个集成调度功能的数字孪生框架，（2）集成了各种顶级 HPC 系统，利用其公开的数据集，（3）实现了与外部调度仿真器集成的扩展。最终，我们展示了如何（4）在这样的新型数字孪生元框架中实现和评估激励结构，以及（5）评估基于机器学习的调度，以原型设计调度。我们的工作使 HPC 系统的假设情景能够评估可持续性及其对模拟系统的影响。 

---
# Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment 

**Title (ZH)**: 分解大型语言模型中的行为相变：新兴不对齐的秩序参数 

**Authors**: Julian Arnold, Niels Lörch  

**Link**: [PDF](https://arxiv.org/pdf/2508.20015)  

**Abstract**: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is broadly misaligned with respect to human values. To understand when and how this emergent misalignment occurs, we develop a comprehensive framework for detecting and characterizing rapid transitions during fine-tuning using both distributional change detection methods as well as order parameters that are formulated in plain English and evaluated by an LLM judge. Using an objective statistical dissimilarity measure, we quantify how the phase transition that occurs during fine-tuning affects multiple aspects of the model. In particular, we assess what percentage of the total distributional change in model outputs is captured by different aspects, such as alignment or verbosity, providing a decomposition of the overall transition. We also find that the actual behavioral transition occurs later in training than indicated by the peak in the gradient norm alone. Our framework enables the automated discovery and quantification of language-based order parameters, which we demonstrate on examples ranging from knowledge questions to politics and ethics. 

**Abstract (ZH)**: 在细调大语言模型时使用狭义有害数据集可能导致总体上与人类价值观偏差的行为。为了理解这种 emergent 偏差何时以及如何发生，我们开发了一个综合框架，使用分布变化检测方法以及用简单语言表述的秩序参数，这些参数通过大语言模型裁判进行评估。通过客观的统计异质性度量，我们量化了在细调过程中发生的相变对模型多个方面的影响。特别是，我们评估了不同方面，如对齐度或冗余度，捕捉到的总分布变化的百分比，提供了对整体转变的分解。我们还发现，实际行为转变发生在训练过程中晚于仅由梯度范数峰值指示的时间点。该框架允许自动化发现和量化基于语言的秩序参数，在从知识问题到政治和伦理等多种示例中进行了验证。 

---
# Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach 

**Title (ZH)**: 跨平台电子商务产品类别化与再类别化：一种多模态层次分类方法 

**Authors**: Lotte Gross, Rebecca Walter, Nicole Zoppi, Adrien Justus, Alessandro Gambetti, Qiwei Han, Maximilian Kaiser  

**Link**: [PDF](https://arxiv.org/pdf/2508.20013)  

**Abstract**: This study addresses critical industrial challenges in e-commerce product categorization, namely platform heterogeneity and the structural limitations of existing taxonomies, by developing and deploying a multimodal hierarchical classification framework. Using a dataset of 271,700 products from 40 international fashion e-commerce platforms, we integrate textual features (RoBERTa), visual features (ViT), and joint vision--language representations (CLIP). We investigate fusion strategies, including early, late, and attention-based fusion within a hierarchical architecture enhanced by dynamic masking to ensure taxonomic consistency. Results show that CLIP embeddings combined via an MLP-based late-fusion strategy achieve the highest hierarchical F1 (98.59\%), outperforming unimodal baselines. To address shallow or inconsistent categories, we further introduce a self-supervised ``product recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with cluster purities above 86\%. Cross-platform experiments reveal a deployment-relevant trade-off: complex late-fusion methods maximize accuracy with diverse training data, while simpler early-fusion methods generalize more effectively to unseen platforms. Finally, we demonstrate the framework's industrial scalability through deployment in EURWEB's commercial transaction intelligence platform via a two-stage inference pipeline, combining a lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance cost and accuracy. 

**Abstract (ZH)**: 本研究通过开发和部署一种多模态层级分类框架，解决了电子商务产品分类中的关键工业挑战，包括平台异质性和现有分类体系的结构性限制。使用来自40个国际时尚电子商务平台的271,700个产品数据集，我们整合了文本特征（RoBERTa）、视觉特征（ViT）及联合视觉-语言表示（CLIP）。研究探讨了包括早期融合、晚期融合及基于注意力的融合在内的融合策略，并通过动态遮掩以增强层级结构，确保分类的内在一致性。结果显示，基于MLP的晚期融合策略结合CLIP嵌入实现了最高的层级F1值（98.59%），优于单模态基线。为解决浅层或不一致的类别问题，我们进一步引入了一种自监督的“产品再分类”管道，使用SimCLR、UMAP和级联聚类，发现了具有86%以上纯度的新细分类别（例如“鞋”的子类型）。跨平台实验揭示了部署相关的权衡：复杂的晚期融合方法在多样化的训练数据中能够最大化准确率，而简单的早期融合方法则能够更有效地泛化到未见过的平台。最后，通过在EURWEB的商业交易智能平台上采用两阶段推断管道部署该框架，结合轻量级RoBERTa阶段和GPU加速的多模态阶段，展示了框架的工业可扩展性，平衡了成本和准确率。 

---
# Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation 

**Title (ZH)**: 基于梯度估计的线性时间示范选择方法以实现情境学习 

**Authors**: Ziniu Zhang, Zhenshuo Zhang, Dongyue Li, Lu Wang, Jennifer Dy, Hongyang R. Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19999)  

**Abstract**: This paper introduces an algorithm to select demonstration examples for in-context learning of a query set. Given a set of $n$ examples, how can we quickly select $k$ out of $n$ to best serve as the conditioning for downstream inference? This problem has broad applications in prompt tuning and chain-of-thought reasoning. Since model weights remain fixed during in-context learning, previous work has sought to design methods based on the similarity of token embeddings. This work proposes a new approach based on gradients of the output taken in the input embedding space. Our approach estimates model outputs through a first-order approximation using the gradients. Then, we apply this estimation to multiple randomly sampled subsets. Finally, we aggregate the sampled subset outcomes to form an influence score for each demonstration, and select $k$ most relevant examples. This procedure only requires pre-computing model outputs and gradients once, resulting in a linear-time algorithm relative to model and training set sizes. Extensive experiments across various models and datasets validate the efficiency of our approach. We show that the gradient estimation procedure yields approximations of full inference with less than $\mathbf{1}\%$ error across six datasets. This allows us to scale up subset selection that would otherwise run full inference by up to $\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and outperform existing selection methods based on input embeddings by $\mathbf{11}\%$ on average. 

**Abstract (ZH)**: 本文介绍了一种用于查询集上下文学习的演示示例选择算法。给定一个包含$n$个示例的集合，如何快速从这$n$个示例中选择$k$个最佳作为下游推理的条件？这一问题在提示调整和链式推理中具有广泛的应用。由于在上下文学习过程中模型权重保持不变，以往的工作基于令牌嵌入的相似性设计了相关方法。本文提出了一种新的基于输入嵌入空间中输出梯度的方法。我们的方法通过一阶近似计算模型输出，并将其应用于多个随机采样的子集。最后，我们将采样子集的结果聚合为每个演示示例的影响得分，并选择最相关的$k$个示例。该流程只需预计算一次模型输出和梯度，从而相对于模型和训练集的规模实现了线性时间算法。在各种模型和数据集上的广泛实验验证了我们方法的有效性。我们展示了梯度估计过程在六个数据集上提供了低于1%误差的完整推理近似值。这允许我们在具有多达340亿参数的模型上将子集选择的规模扩展多达37.7倍，并且在平均意义上比基于输入嵌入的选择方法提高了11%。 

---
# MathBuddy: A Multimodal System for Affective Math Tutoring 

**Title (ZH)**: MathBuddy: 一种多模态情感数学辅导系统 

**Authors**: Debanjana Kar, Leopold Böss, Dacia Braca, Sebastian Maximilian Dennerlein, Nina Christine Hubig, Philipp Wintersberger, Yufang Hou  

**Link**: [PDF](https://arxiv.org/pdf/2508.19993)  

**Abstract**: The rapid adoption of LLM-based conversational systems is already transforming the landscape of educational technology. However, the current state-of-the-art learning models do not take into account the student's affective states. Multiple studies in educational psychology support the claim that positive or negative emotional states can impact a student's learning capabilities. To bridge this gap, we present MathBuddy, an emotionally aware LLM-powered Math Tutor, which dynamically models the student's emotions and maps them to relevant pedagogical strategies, making the tutor-student conversation a more empathetic one. The student's emotions are captured from the conversational text as well as from their facial expressions. The student's emotions are aggregated from both modalities to confidently prompt our LLM Tutor for an emotionally-aware response. We have effectively evaluated our model using automatic evaluation metrics across eight pedagogical dimensions and user studies. We report a massive 23 point performance gain using the win rate and a 3 point gain at an overall level using DAMR scores which strongly supports our hypothesis of improving LLM-based tutor's pedagogical abilities by modeling students' emotions. 

**Abstract (ZH)**: 基于LLM的情感意识数学辅导系统MathBuddy：通过建模学生情感提高辅导效果 

---
# Diffusion Language Models Know the Answer Before Decoding 

**Title (ZH)**: 扩散语言模型在解码前就知道答案 

**Authors**: Pengxiang Li, Yefan Zhou, Dilxat Muhtar, Lu Yin, Shilin Yan, Li Shen, Yi Liang, Soroush Vosoughi, Shiwei Liu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19982)  

**Abstract**: Diffusion language models (DLMs) have recently emerged as an alternative to autoregressive approaches, offering parallel sequence generation and flexible token orders. However, their inference remains slower than that of autoregressive models, primarily due to the cost of bidirectional attention and the large number of refinement steps required for high quality outputs. In this work, we highlight and leverage an overlooked property of DLMs early answer convergence: in many cases, the correct answer can be internally identified by half steps before the final decoding step, both under semi-autoregressive and random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99% of instances, respectively, can be decoded correctly using only half of the refinement steps. Building on this observation, we introduce Prophet, a training-free fast decoding paradigm that enables early commit decoding. Specifically, Prophet dynamically decides whether to continue refinement or to go "all-in" (i.e., decode all remaining tokens in one step), using the confidence gap between the top-2 prediction candidates as the criterion. It integrates seamlessly into existing DLM implementations, incurs negligible overhead, and requires no additional training. Empirical evaluations of LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the number of decoding steps by up to 3.4x while preserving high generation quality. These results recast DLM decoding as a problem of when to stop sampling, and demonstrate that early decode convergence provides a simple yet powerful mechanism for accelerating DLM inference, complementary to existing speedup techniques. Our code is publicly available at this https URL. 

**Abstract (ZH)**: Diffusion语言模型（DLMs）作为一种替代自回归方法的新颖技术，提供了并行序列生成和灵活的令牌顺序。然而，其推理速度仍慢于自回归模型，主要原因是双向注意的成本以及生成高质量输出所需的高度精炼步骤较多。在本文中，我们指出并利用了DLMs早期答案收敛这一未被充分关注的特性：在许多情况下，正确的答案在最终解码步骤之前通过半步即可内部识别，无论是在半自回归解码还是随机屏蔽计划下。例如，在GSM8K和MMLU上，分别有97%和99%的实例可以在仅使用一半的精炼步骤时被正确解码。基于这一观察，我们引入了Prophet，这是一种无需训练的快速解码范式，使早期提交解码成为可能。具体而言，Prophet 动态决定是否继续精炼或“押注”（即一次性解码剩余所有令牌），使用最佳两个预测候选之间的置信度差距作为标准。它无缝集成到现有的DLM实现中，几乎不增加额外开销，也不需要额外训练。跨多个任务对LLaDA-8B和Dream-7B的实证评估显示，Prophet 将解码步骤减少了多达3.4倍，同时保持了高质量的生成。这些结果重新定义了DLM解码问题为何时停止采样问题，并证明了早期解码收敛为加速DLM推理提供了一种简单且强大的机制，补充了现有加速技术。我们的代码可在以下网址公开获取。 

---
# GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity 

**Title (ZH)**: GLSim: 在LVLMs中通过全局-局部相似性检测对象幻觉 

**Authors**: Seongheon Park, Yixuan Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.19972)  

**Abstract**: Object hallucination in large vision-language models presents a significant challenge to their safe deployment in real-world applications. Recent works have proposed object-level hallucination scores to estimate the likelihood of object hallucination; however, these methods typically adopt either a global or local perspective in isolation, which may limit detection reliability. In this paper, we introduce GLSim, a novel training-free object hallucination detection framework that leverages complementary global and local embedding similarity signals between image and text modalities, enabling more accurate and reliable hallucination detection in diverse scenarios. We comprehensively benchmark existing object hallucination detection methods and demonstrate that GLSim achieves superior detection performance, outperforming competitive baselines by a significant margin. 

**Abstract (ZH)**: 大型 vision-language 模型中的对象幻觉在其实用应用中的安全部署中提出了重大挑战。近期工作提出了对象级幻觉分数以估计对象幻觉的可能性；然而，这些方法通常单独采用全局或局部视角，这可能限制了检测可靠性。在本文中，我们引入了 GLSim，一种无需训练的新型对象幻觉检测框架，该框架利用图像和文本模态之间互补的全局和局部嵌入相似性信号，能够在多种场景下实现更准确可靠的幻觉检测。我们全面 benchmark 了现有的对象幻觉检测方法，并证明 GLSim 在检测性能上表现出色，显著优于竞品基线。 

---
# Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation 

**Title (ZH)**: Dhati+: 细化调优的阿拉伯语主观性评价大型语言模型 

**Authors**: Slimane Bellaouar, Attia Nehar, Soumia Souffi, Mounia Bouameur  

**Link**: [PDF](https://arxiv.org/pdf/2508.19966)  

**Abstract**: Despite its significance, Arabic, a linguistically rich and morphologically complex language, faces the challenge of being under-resourced. The scarcity of large annotated datasets hampers the development of accurate tools for subjectivity analysis in Arabic. Recent advances in deep learning and Transformers have proven highly effective for text classification in English and French. This paper proposes a new approach for subjectivity assessment in Arabic textual data. To address the dearth of specialized annotated datasets, we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and ArabianGPT) on AraDhati+ for effective subjectivity classification. Furthermore, we experimented with an ensemble decision approach to harness the strengths of individual models. Our approach achieves a remarkable accuracy of 97.79\,\% for Arabic subjectivity classification. Results demonstrate the effectiveness of the proposed approach in addressing the challenges posed by limited resources in Arabic language processing. 

**Abstract (ZH)**: 尽管阿拉伯语作为一种语义丰富且形态复杂的语言具有重要意义，但由于资源匮乏的挑战，其主观性分析工具的发展受到了限制。现有的大型标注数据集稀缺阻碍了阿拉伯语主观性分析工具的发展。最近，在深度学习和变换器技术的进步在英语和法语文本分类方面已证明非常有效。本文提出了一种新的阿拉伯语文本主观性评估方法。为解决专门标注数据的匮乏问题，我们通过利用现有阿拉伯语数据集和集合（ASTD、LABR、HARD和SANAD）开发了一个综合数据集AraDhati+。随后，我们针对AraDhati+对最先进的阿拉伯语语言模型（XLM-RoBERTa、AraBERT和ArabianGPT）进行微调，以实现有效的主观性分类。此外，我们尝试了一种集成决策方法，以充分利用各个模型的优势。我们的方法在阿拉伯语主观性分类中实现了97.79%的高准确率。结果表明，所提出的方法在阿拉伯语处理资源有限的挑战中具有有效性。 

---
# WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution 

**Title (ZH)**: WaveHiT-SR：分层小波网络高效的图像超分辨率 

**Authors**: Fayaz Ali, Muhammad Zawish, Steven Davy, Radu Timofte  

**Link**: [PDF](https://arxiv.org/pdf/2508.19927)  

**Abstract**: Transformers have demonstrated promising performance in computer vision tasks, including image super-resolution (SR). The quadratic computational complexity of window self-attention mechanisms in many transformer-based SR methods forces the use of small, fixed windows, limiting the receptive field. In this paper, we propose a new approach by embedding the wavelet transform within a hierarchical transformer framework, called (WaveHiT-SR). First, using adaptive hierarchical windows instead of static small windows allows to capture features across different levels and greatly improve the ability to model long-range dependencies. Secondly, the proposed model utilizes wavelet transforms to decompose images into multiple frequency subbands, allowing the network to focus on both global and local features while preserving structural details. By progressively reconstructing high-resolution images through hierarchical processing, the network reduces computational complexity without sacrificing performance. The multi-level decomposition strategy enables the network to capture fine-grained information in lowfrequency components while enhancing high-frequency textures. Through extensive experimentation, we confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR results, achieving higher efficiency with fewer parameters, lower FLOPs, and faster speeds. 

**Abstract (ZH)**: WaveHiT-SR：嵌入小波变换的分层变压器超分辨率方法 

---
# The Next Layer: Augmenting Foundation Models with Structure-Preserving and Attention-Guided Learning for Local Patches to Global Context Awareness in Computational Pathology 

**Title (ZH)**: 下一层：通过结构保留和注意力引导学习局部patches到全局上下文意识增强基础模型 

**Authors**: Muhammad Waqas, Rukhmini Bandyopadhyay, Eman Showkatian, Amgad Muneer, Anas Zafar, Frank Rojas Alvarez, Maricel Corredor Marin, Wentao Li, David Jaffray, Cara Haymaker, John Heymach, Natalie I Vokes, Luisa Maren Solis Soto, Jianjun Zhang, Jia Wu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19914)  

**Abstract**: Foundation models have recently emerged as powerful feature extractors in computational pathology, yet they typically omit mechanisms for leveraging the global spatial structure of tissues and the local contextual relationships among diagnostically relevant regions - key elements for understanding the tumor microenvironment. Multiple instance learning (MIL) remains an essential next step following foundation model, designing a framework to aggregate patch-level features into slide-level predictions. We present EAGLE-Net, a structure-preserving, attention-guided MIL architecture designed to augment prediction and interpretability. EAGLE-Net integrates multi-scale absolute spatial encoding to capture global tissue architecture, a top-K neighborhood-aware loss to focus attention on local microenvironments, and background suppression loss to minimize false positives. We benchmarked EAGLE-Net on large pan-cancer datasets, including three cancer types for classification (10,260 slides) and seven cancer types for survival prediction (4,172 slides), using three distinct histology foundation backbones (REMEDIES, Uni-V1, Uni2-h). Across tasks, EAGLE-Net achieved up to 3% higher classification accuracy and the top concordance indices in 6 of 7 cancer types, producing smooth, biologically coherent attention maps that aligned with expert annotations and highlighted invasive fronts, necrosis, and immune infiltration. These results position EAGLE-Net as a generalizable, interpretable framework that complements foundation models, enabling improved biomarker discovery, prognostic modeling, and clinical decision support 

**Abstract (ZH)**: 基于结构保持、注意力引导的多项实例学习架构EAGLE-Net：增强预测与可解释性 

---
# Logical Reasoning with Outcome Reward Models for Test-Time Scaling 

**Title (ZH)**: 基于结果奖励模型的逻辑推理及其测试时缩放方法 

**Authors**: Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19903)  

**Abstract**: Logical reasoning is a critical benchmark for evaluating the capabilities of large language models (LLMs), as it reflects their ability to derive valid conclusions from given premises. While the combination of test-time scaling with dedicated outcome or process reward models has opened up new avenues to enhance LLMs performance in complex reasoning tasks, this space is under-explored in deductive logical reasoning. We present a set of Outcome Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly generate data using Chain-of-Thought (CoT) with single and multiple samples. Additionally, we propose a novel tactic to further expand the type of errors covered in the training dataset of the ORM. In particular, we propose an echo generation technique that leverages LLMs' tendency to reflect incorrect assumptions made in prompts to extract additional training data, covering previously unexplored error types. While a standard CoT chain may contain errors likely to be made by the reasoner, the echo strategy deliberately steers the model toward incorrect reasoning. We show that ORMs trained on CoT and echo-augmented data demonstrate improved performance on the FOLIO, JustLogic, and ProverQA datasets across four different LLMs. 

**Abstract (ZH)**: 逻辑推理是评估大型语言模型（LLMs）能力的关键基准，因为它反映了模型从给定前提中推导出有效结论的能力。虽然在复杂推理任务中通过测试时缩放与专用结果或过程奖励模型的结合已为提高LLMs的性能开辟了新途径，但在演绎逻辑推理方面这一领域仍处于探索阶段。我们提出了一组演绎推理的Outcome Reward Models（ORMs）。为了训练ORMs，我们主要使用带有单个和多个样本的Chain-of-Thought（CoT）生成数据。此外，我们提出了一种新的策略，以进一步扩展ORMs训练数据集中涵盖的错误类型。特别是，我们提出了一种回声生成技术，利用LLMs在提示中作出的错误假设来提取额外的训练数据，涵盖了之前未被探索的错误类型。虽然标准的CoT链可能包含推理者可能犯的错误，但回声策略故意引导模型走向错误的推理。我们发现，基于CoT和回声增强数据训练的ORMs在四个不同的LLMs上，在FOLIO、JustLogic和ProverQA数据集上的表现得到了改善。 

---
# The Information Dynamics of Generative Diffusion 

**Title (ZH)**: 生成性扩散的信息动力学 

**Authors**: Luca Ambrogioni  

**Link**: [PDF](https://arxiv.org/pdf/2508.19897)  

**Abstract**: Generative diffusion models have emerged as a powerful class of models in machine learning, yet a unified theoretical understanding of their operation is still developing. This perspective paper provides an integrated perspective on generative diffusion by connecting their dynamic, information-theoretic, and thermodynamic properties under a unified mathematical framework. We demonstrate that the rate of conditional entropy production during generation (i.e. the generative bandwidth) is directly governed by the expected divergence of the score function's vector field. This divergence, in turn, is linked to the branching of trajectories and generative bifurcations, which we characterize as symmetry-breaking phase transitions in the energy landscape. This synthesis offers a powerful insight: the process of generation is fundamentally driven by the controlled, noise-induced breaking of (approximate) symmetries, where peaks in information transfer correspond to critical transitions between possible outcomes. The score function acts as a dynamic non-linear filter that regulates the bandwidth of the noise by suppressing fluctuations that are incompatible with the data. 

**Abstract (ZH)**: 生成扩散模型已经发展成为机器学习中一类强大的模型，但对其运行机制的统一理论理解仍在发展中。这篇视角论文通过在一个统一的数学框架下连接生成扩散的动力学、信息论和热力学性质，提供了对其生成机制的综合视角。我们证明，在生成过程中条件熵生成速率（即生成带宽）直接由分数函数向量场的预期散度控制。这一散度又与轨迹分支和生成分岔相关联，我们将其表征为能量景观中的对称性破缺相变。这种综合提供了有力的洞察：生成过程从根本上是由可控的、噪声诱导的（近似）对称性破缺驱动的，信息传输的峰值对应于可能结果之间的关键转变。分数函数作为动态非线性滤波器，通过抑制不符合数据的波动来调节噪声的带宽。 

---
# AI-Powered Detection of Inappropriate Language in Medical School Curricula 

**Title (ZH)**: 基于AI的医学课程不适当语言检测 

**Authors**: Chiman Salavati, Shannon Song, Scott A. Hale, Roberto E. Montenegro, Shiri Dori-Hacohen, Fabricio Murai  

**Link**: [PDF](https://arxiv.org/pdf/2508.19883)  

**Abstract**: The use of inappropriate language -- such as outdated, exclusionary, or non-patient-centered terms -- medical instructional materials can significantly influence clinical training, patient interactions, and health outcomes. Despite their reputability, many materials developed over past decades contain examples now considered inappropriate by current medical standards. Given the volume of curricular content, manually identifying instances of inappropriate use of language (IUL) and its subcategories for systematic review is prohibitively costly and impractical. To address this challenge, we conduct a first-in-class evaluation of small language models (SLMs) fine-tuned on labeled data and pre-trained LLMs with in-context learning on a dataset containing approximately 500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL classifier, (2) subcategory-specific binary classifiers, (3) a multilabel classifier, and (4) a two-stage hierarchical pipeline for general IUL detection followed by multilabel classification. For LLMs, we consider variations of prompts that include subcategory definitions and/or shots. We found that both LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed by SLMs. While the multilabel classifier performs best on annotated data, supplementing training with unflagged excerpts as negative examples boosts the specific classifiers' AUC by up to 25%, making them most effective models for mitigating harmful language in medical curricula. 

**Abstract (ZH)**: 不恰当语言的使用——诸如过时的、排斥性的或非患者中心的术语——在医学教学材料中的应用会对临床培训、患者互动和健康结果产生显著影响。尽管许多过去几十年开发的材料在当前医疗标准下被认为不恰当，但在大量课程内容中，手动识别不恰当语言使用及其子类别的实例以进行系统审查成本高昂且不切实际。为解决这一挑战，我们对小语言模型（SLMs）进行了首次评估，这些模型在标注数据上进行了微调，并使用包含约500份文档和超过12,000页的内容的语境学习预训练大语言模型（LLMs）进行评估。对于SLMs，我们考虑了：（1）通用不恰当语言使用分类器，（2）子类特定的二元分类器，（3）多标签分类器，以及（4）两阶段层次管道，首先进行通用不恰当语言使用检测，然后进行多标签分类。对于LLMs，我们考虑了包含子类定义和/或示例的不同提示形式。我们发现，即使经过精心筛选的示例，LLama-3 8B和70B的表现也大大逊色于SLMs。虽然多标签分类器在标注数据中表现最佳，但将未标记的示例作为负样本补充训练，可以将特定分类器的AUC提高高达25%，使其成为最有效的模型，用于减少医学课程中的有害语言。 

---
# Generative AI for Testing of Autonomous Driving Systems: A Survey 

**Title (ZH)**: 自动驾驶系统测试中的生成式人工智能：一个综述 

**Authors**: Qunying Song, He Ye, Mark Harman, Federica Sarro  

**Link**: [PDF](https://arxiv.org/pdf/2508.19882)  

**Abstract**: Autonomous driving systems (ADS) have been an active area of research, with the potential to deliver significant benefits to society. However, before large-scale deployment on public roads, extensive testing is necessary to validate their functionality and safety under diverse driving conditions. Therefore, different testing approaches are required, and achieving effective and efficient testing of ADS remains an open challenge. Recently, generative AI has emerged as a powerful tool across many domains, and it is increasingly being applied to ADS testing due to its ability to interpret context, reason about complex tasks, and generate diverse outputs. To gain a deeper understanding of its role in ADS testing, we systematically analyzed 91 relevant studies and synthesized their findings into six major application categories, primarily centered on scenario-based testing of ADS. We also reviewed their effectiveness and compiled a wide range of datasets, simulators, ADS, metrics, and benchmarks used for evaluation, while identifying 27 limitations. This survey provides an overview and practical insights into the use of generative AI for testing ADS, highlights existing challenges, and outlines directions for future research in this rapidly evolving field. 

**Abstract (ZH)**: 自主驾驶系统（ADS）一直是研究的活跃领域，有潜力为社会带来显著益处。但在大规模部署到公共道路之前，需要进行广泛的测试以验证其在多种驾驶条件下功能和安全性的有效性。因此，不同的测试方法是必需的，而实现有效且高效的ADS测试仍是一个开放性的挑战。最近，生成式AI在许多领域展现出强大的能力，并因其能够解释上下文、推理复杂任务和生成多样化输出，被越来越多地应用于ADS测试。为了更深入地了解其在ADS测试中的作用，我们系统分析了91篇相关研究，并将 findings 精要概括为六类主要应用场景，重点在于基于场景的ADS测试。我们还回顾了这些研究的有效性，并汇集了广泛的数据集、模拟器、ADS、评估指标和基准，同时指出了27个局限性。该综述提供了一种关于生成式AI在ADS测试中应用的概览和实用见解，突出了现有挑战，并指出了这一快速发展的领域未来研究的方向。 

---
# Multispectral LiDAR data for extracting tree points in urban and suburban areas 

**Title (ZH)**: 多光谱LiDAR数据在城市和郊区间提取树木点云 

**Authors**: Narges Takhtkeshha, Gabriele Mazzacca, Fabio Remondino, Juha Hyyppä, Gottfried Mandlburger  

**Link**: [PDF](https://arxiv.org/pdf/2508.19881)  

**Abstract**: Monitoring urban tree dynamics is vital for supporting greening policies and reducing risks to electrical infrastructure. Airborne laser scanning has advanced large-scale tree management, but challenges remain due to complex urban environments and tree variability. Multispectral (MS) light detection and ranging (LiDAR) improves this by capturing both 3D spatial and spectral data, enabling detailed mapping. This study explores tree point extraction using MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of SPT, with a mean intersection over union (mIoU) of 85.28%. The highest detection accuracy is achieved by incorporating pseudo normalized difference vegetation index (pNDVI) with spatial data, reducing error rate by 10.61 percentage points (pp) compared to using spatial information alone. These findings highlight the potential of MS-LiDAR and DL to improve tree extraction and further tree inventories. 

**Abstract (ZH)**: 基于多光谱LiDAR和深度学习的城市树木动态监测研究 

---
# SoK: Large Language Model Copyright Auditing via Fingerprinting 

**Title (ZH)**: SoK: 大型语言模型版权审计通过指纹技术 

**Authors**: Shuo Shao, Yiming Li, Yu He, Hongwei Yao, Wenyuan Yang, Dacheng Tao, Zhan Qin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19843)  

**Abstract**: The broad capabilities and substantial resources required to train Large Language Models (LLMs) make them valuable intellectual property, yet they remain vulnerable to copyright infringement, such as unauthorized use and model theft. LLM fingerprinting, a non-intrusive technique that extracts and compares the distinctive features from LLMs to identify infringements, offers a promising solution to copyright auditing. However, its reliability remains uncertain due to the prevalence of diverse model modifications and the lack of standardized evaluation. In this SoK, we present the first comprehensive study of LLM fingerprinting. We introduce a unified framework and formal taxonomy that categorizes existing methods into white-box and black-box approaches, providing a structured overview of the state of the art. We further propose LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting under realistic deployment scenarios. Built upon mainstream foundation models and comprising 149 distinct model instances, LeaFBench integrates 13 representative post-development techniques, spanning both parameter-altering methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms (e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the strengths and weaknesses of existing methods, thereby outlining future research directions and critical open problems in this emerging field. The code is available at this https URL. 

**Abstract (ZH)**: 大语言模型的能力和资源要求使其成为有价值的知识产权，但它们仍然容易受到版权侵犯，如未授权使用和模型窃取。大语言模型指纹识别是一种非侵入性技术，通过提取和比较大语言模型的独特特征来识别侵权行为，为版权审计提供了有希望的解决方案。然而，其可靠性仍不确定，原因在于模型修改的多样性以及缺乏标准化的评估标准。在本综述中，我们首次进行了全面的大语言模型指纹识别研究。我们介绍了一个统一的框架和形式化的分类法，将现有方法分为白盒和黑盒方法，提供了该领域的现状概览。进一步提出了LeaFBench，这是首个在实际部署场景下系统评估大语言模型指纹识别的标准基准。基于主流基础模型，LeaFBench包含149个不同的模型实例，并集成了13种代表性后开发技术，涵盖了参数改变方法（如微调、量化）和与参数无关的机制（如系统提示、基于检索的回答生成）。通过对LeaFBench的广泛实验揭示了现有方法的优缺点，从而勾勒出该新兴领域的未来研究方向和关键打开问题。代码可在以下链接获取。 

---
# PSO-Merging: Merging Models Based on Particle Swarm Optimization 

**Title (ZH)**: PSO-集成：基于粒子群优化的模型集成 

**Authors**: Kehao Zhang, Shaolei Zhang, Yang Feng  

**Link**: [PDF](https://arxiv.org/pdf/2508.19839)  

**Abstract**: Model merging has emerged as an efficient strategy for constructing multitask models by integrating the strengths of multiple available expert models, thereby reducing the need to fine-tune a pre-trained model for all the tasks from scratch. Existing data-independent methods struggle with performance limitations due to the lack of data-driven guidance. Data-driven approaches also face key challenges: gradient-based methods are computationally expensive, limiting their practicality for merging large expert models, whereas existing gradient-free methods often fail to achieve satisfactory results within a limited number of optimization steps. To address these limitations, this paper introduces PSO-Merging, a novel data-driven merging method based on the Particle Swarm Optimization (PSO). In this approach, we initialize the particle swarm with a pre-trained model, expert models, and sparsified expert models. We then perform multiple iterations, with the final global best particle serving as the merged model. Experimental results on different language models show that PSO-Merging generally outperforms baseline merging methods, offering a more efficient and scalable solution for model merging. 

**Abstract (ZH)**: 基于粒子群优化的数据驱动模型融合方法PSO-Merging 

---
# Gradient Rectification for Robust Calibration under Distribution Shift 

**Title (ZH)**: 梯度归一化以适应分布迁移的稳健校准 

**Authors**: Yilin Zhang, Cai Xu, You Wu, Ziyu Guan, Wei Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2508.19830)  

**Abstract**: Deep neural networks often produce overconfident predictions, undermining their reliability in safety-critical applications. This miscalibration is further exacerbated under distribution shift, where test data deviates from the training distribution due to environmental or acquisition changes. While existing approaches improve calibration through training-time regularization or post-hoc adjustment, their reliance on access to or simulation of target domains limits their practicality in real-world scenarios. In this paper, we propose a novel calibration framework that operates without access to target domain information. From a frequency-domain perspective, we identify that distribution shifts often distort high-frequency visual cues exploited by deep models, and introduce a low-frequency filtering strategy to encourage reliance on domain-invariant features. However, such information loss may degrade In-Distribution (ID) calibration performance. Therefore, we further propose a gradient-based rectification mechanism that enforces ID calibration as a hard constraint during optimization. Experiments on synthetic and real-world shifted datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method significantly improves calibration under distribution shift while maintaining strong in-distribution performance. 

**Abstract (ZH)**: 深度神经网络往往产生过度自信的预测，这在安全关键应用中削弱了它们的可靠性。这种失准在分布偏移情况下会进一步加剧，即测试数据因环境或获取方式的变化而偏离训练数据分布。尽管现有方法通过训练时正则化或事后调整来改善校准，但它们依赖于访问目标域信息或模拟目标域的能力，这限制了它们在实际场景中的实用性。在本文中，我们提出了一种无需访问目标域信息的新型校准框架。从频域的角度来看，我们发现分布偏移往往会扭曲深度模型所利用的高频视觉线索，并引入了低频滤波策略以鼓励依赖域不变特征。然而，这种信息损失可能降低就分布内（ID）校准性能。因此，我们进一步提出了一种基于梯度的矫正机制，在优化过程中将其作为硬约束以确保ID校准。实验结果表明，我们的方法在分布偏移情况下显著提高了校准性能，同时保持了强大的就分布内性能。 

---
# From Research to Reality: Feasibility of Gradient Inversion Attacks in Federated Learning 

**Title (ZH)**: 从研究到现实：联邦学习中梯度 inversion 攻击的可行性 

**Authors**: Viktor Valadi, Mattias Åkesson, Johan Östman, Salman Toor, Andreas Hellander  

**Link**: [PDF](https://arxiv.org/pdf/2508.19819)  

**Abstract**: Gradient inversion attacks have garnered attention for their ability to compromise privacy in federated learning. However, many studies consider attacks with the model in inference mode, where training-time behaviors like dropout are disabled and batch normalization relies on fixed statistics. In this work, we systematically analyze how architecture and training behavior affect vulnerability, including the first in-depth study of inference-mode clients, which we show dramatically simplifies inversion. To assess attack feasibility under more realistic conditions, we turn to clients operating in standard training mode. In this setting, we find that successful attacks are only possible when several architectural conditions are met simultaneously: models must be shallow and wide, use skip connections, and, critically, employ pre-activation normalization. We introduce two novel attacks against models in training-mode with varying attacker knowledge, achieving state-of-the-art performance under realistic training conditions. We extend these efforts by presenting the first attack on a production-grade object-detection model. Here, to enable any visibly identifiable leakage, we revert to the lenient inference mode setting and make multiple architectural modifications to increase model vulnerability, with the extent of required changes highlighting the strong inherent robustness of such architectures. We conclude this work by offering the first comprehensive mapping of settings, clarifying which combinations of architectural choices and operational modes meaningfully impact privacy. Our analysis provides actionable insight into when models are likely vulnerable, when they appear robust, and where subtle leakage may persist. Together, these findings reframe how gradient inversion risk should be assessed in future research and deployment scenarios. 

**Abstract (ZH)**: 基于梯度反向攻击在联邦学习中对隐私威胁的研究：从推理模式到训练模式的系统分析与攻击方法探索 

---
# ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images 

**Title (ZH)**: ERSR：一种基于椭圆约束的伪标签 refinement 和对称正则化框架用于超声图像胎头分割的半监督学习 

**Authors**: Linkuan Zhou, Zhexin Chen, Yufei Shen, Junlin Xu, Ping Xuan, Yixin Zhu, Yuqi Fang, Cong Cong, Leyi Wei, Ran Su, Jia Zhou, Qiangguo Jin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19815)  

**Abstract**: Automated segmentation of the fetal head in ultrasound images is critical for prenatal monitoring. However, achieving robust segmentation remains challenging due to the poor quality of ultrasound images and the lack of annotated data. Semi-supervised methods alleviate the lack of annotated data but struggle with the unique characteristics of fetal head ultrasound images, making it challenging to generate reliable pseudo-labels and enforce effective consistency regularization constraints. To address this issue, we propose a novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation. Our framework consists of the dual-scoring adaptive filtering strategy, the ellipse-constrained pseudo-label refinement, and the symmetry-based multiple consistency regularization. The dual-scoring adaptive filtering strategy uses boundary consistency and contour regularity criteria to evaluate and filter teacher outputs. The ellipse-constrained pseudo-label refinement refines these filtered outputs by fitting least-squares ellipses, which strengthens pixels near the center of the fitted ellipse and suppresses noise simultaneously. The symmetry-based multiple consistency regularization enforces multi-level consistency across perturbed images, symmetric regions, and between original predictions and pseudo-labels, enabling the model to capture robust and stable shape representations. Our method achieves state-of-the-art performance on two benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36% with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores are 91.68% and 93.70% under the same settings. 

**Abstract (ZH)**: 自动胎儿头部超声分割对于产前监测至关重要。然而，由于超声图像质量较差且缺乏标注数据，实现鲁棒分割仍具有挑战性。半监督方法虽能缓解标注数据不足的问题，但在处理胎儿头部超声图像的独特特性时却困难重重，难以生成可靠的伪标签并施加有效的一致性正则化约束。为解决这一问题，我们提出了一种新的半监督框架——ERSR，用于胎儿头部超声分割。该框架包括双评分自适应滤波策略、椭圆约束伪标签细化和基于对称性的多级一致性正则化。双评分自适应滤波策略使用边界一致性和轮廓规则性标准来评估和过滤教师输出。椭圆约束伪标签细化通过拟合最小二乘椭圆来细化这些过滤输出，从而使中心附近的像素增强，并同时抑制噪声。基于对称性的多级一致性正则化在扰动图像、对称区域以及原始预测和伪标签之间施加多级一致性约束，使模型能够捕捉到稳健且稳定的形状表征。我们的方法在两个基准上实现了最先进的性能。在其上，采用10%和20%标注数据时，HC18数据集的Dice分数分别为92.05%和95.36%。在同一设置下，PSFH数据集的分数分别为91.68%和93.70%。 

---
# Bootstrapping Learned Cost Models with Synthetic SQL Queries 

**Title (ZH)**: 用合成SQL查询 bootstrap 训练学习到的成本模型 

**Authors**: Michael Nidd, Christoph Miksovic, Thomas Gschwind, Francesco Fusco, Andrea Giovannini, Ioana Giurgiu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19807)  

**Abstract**: Having access to realistic workloads for a given database instance is extremely important to enable stress and vulnerability testing, as well as to optimize for cost and performance. Recent advances in learned cost models have shown that when enough diverse SQL queries are available, one can effectively and efficiently predict the cost of running a given query against a specific database engine. In this paper, we describe our experience in exploiting modern synthetic data generation techniques, inspired by the generative AI and LLM community, to create high-quality datasets enabling the effective training of such learned cost models. Initial results show that we can improve a learned cost model's predictive accuracy by training it with 45% fewer queries than when using competitive generation approaches. 

**Abstract (ZH)**: 基于现代合成数据生成技术利用现实工作负载进行成本模型训练的经验分享：使用较少的查询提高预测准确性 

---
# A bag of tricks for real-time Mitotic Figure detection 

**Title (ZH)**: 实时有丝分裂图象检测的一系列技巧 

**Authors**: Christian Marzahl, Brian Napora  

**Link**: [PDF](https://arxiv.org/pdf/2508.19804)  

**Abstract**: Mitotic figure (MF) detection in histopathology images is challenging due to large variations in slide scanners, staining protocols, tissue types, and the presence of artifacts. This paper presents a collection of training techniques - a bag of tricks - that enable robust, real-time MF detection across diverse domains. We build on the efficient RTMDet single stage object detector to achieve high inference speed suitable for clinical deployment. Our method addresses scanner variability and tumor heterogeneity via extensive multi-domain training data, balanced sampling, and careful augmentation. Additionally, we employ targeted, hard negative mining on necrotic and debris tissue to reduce false positives. In a grouped 5-fold cross-validation across multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025 challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81, outperforming larger models and demonstrating adaptability to new, unfamiliar domains. The proposed solution offers a practical trade-off between accuracy and speed, making it attractive for real-world clinical adoption. 

**Abstract (ZH)**: 组织切片扫描仪、染色方案、组织类型和伪影的大量变化使得骨髓细胞检测在病理学图像中的实现颇具挑战。本文提出了一种训练技术集合——一系列技巧，以实现跨不同领域的稳定且实时的骨髓细胞检测。我们基于高效的RTMDet单阶段目标检测器，实现高速推断，适于临床部署。我们的方法通过广泛的多领域训练数据、均衡采样和谨慎的增强手段，解决了扫描仪间的差异性和肿瘤异质性问题。此外，我们还针对坏死和碎片组织实施了针对性的困难负样本挖掘，以降低假阳性率。在多个骨髓细胞数据集的分组5折交叉验证中，我们的模型获得了0.78至0.84的F1分数。在2025年MItosis DOmain Generalization (MIDOG) 挑战赛初步测试集中，基于单阶段RTMDet-S的方法达到0.81的F1分数，优于较大模型，并展示了对新且不熟悉的领域适应性的能力。所提解决方案提供了准确性和速度之间的实用权衡，使其适用于实际临床应用。 

---
# NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks 

**Title (ZH)**: NLKI：一种轻量级自然语言知识集成框架，用于增强小规模VLM在常识VQA任务中的性能 

**Authors**: Aritra Dutta, Swapnanil Mukherjee, Deepanway Ghosal, Somak Aditya  

**Link**: [PDF](https://arxiv.org/pdf/2508.19724)  

**Abstract**: Commonsense visual-question answering often hinges on knowledge that is missing from the image or the question. Small vision-language models (sVLMs) such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative counterparts. To study the effect of careful commonsense knowledge integration on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural language facts, (ii) prompts an LLM to craft natural language explanations, and (iii) feeds both signals to sVLMs respectively across two commonsense VQA datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts retrieved using a fine-tuned ColBERTv2 and an object information-enriched prompt yield explanations that largely cut down hallucinations, while lifting the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional finetuning using noise-robust losses (such as symmetric cross entropy and generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our findings expose when LLM-based commonsense knowledge beats retrieval from commonsense knowledge bases, how noise-aware training stabilises small models in the context of external knowledge augmentation, and why parameter-efficient commonsense reasoning is now within reach for 250M models. 

**Abstract (ZH)**: 精细常识知识整合对小型视觉-语言模型效果的影响研究 

---
# Attention is also needed for form design 

**Title (ZH)**: 也需要关注表单设计。 

**Authors**: B. Sankar, Dibakar Sen  

**Link**: [PDF](https://arxiv.org/pdf/2508.19708)  

**Abstract**: Conventional product design is a cognitively demanding process, limited by its time-consuming nature, reliance on subjective expertise, and the opaque translation of inspiration into tangible concepts. This research introduces a novel, attention-aware framework that integrates two synergistic systems: EUPHORIA, an immersive Virtual Reality environment using eye-tracking to implicitly capture a designer's aesthetic preferences, and RETINA, an agentic AI pipeline that translates these implicit preferences into concrete design outputs. The foundational principles were validated in a two-part study. An initial study correlated user's implicit attention with explicit preference and the next one correlated mood to attention. A comparative study where 4 designers solved challenging design problems using 4 distinct workflows, from a manual process to an end-to-end automated pipeline, showed the integrated EUPHORIA-RETINA workflow was over 4 times more time-efficient than the conventional method. A panel of 50 design experts evaluated the 16 final renderings. Designs generated by the fully automated system consistently received the highest Worthiness (calculated by an inverse Plackett-Luce model based on gradient descent optimization) and Design Effectiveness scores, indicating superior quality across 8 criteria: novelty, visual appeal, emotional resonance, clarity of purpose, distinctiveness of silhouette, implied materiality, proportional balance, & adherence to the brief. This research presents a validated paradigm shift from traditional Computer-Assisted Design (CAD) to a collaborative model of Designer-Assisting Computers (DAC). By automating logistical and skill-dependent generative tasks, the proposed framework elevates the designer's role to that of a creative director, synergizing human intuition with the generative power of agentic AI to produce higher-quality designs more efficiently. 

**Abstract (ZH)**: 一种基于注意力的整合框架：从直观偏好到Concrete设计输出 

---
# Safety Alignment Should Be Made More Than Just A Few Attention Heads 

**Title (ZH)**: 安全对齐不应仅由少数注意力头来实现。 

**Authors**: Chao Huang, Zefeng Zhang, Juewei Yue, Quangang Li, Chuang Zhang, Tingwen Liu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19697)  

**Abstract**: Current safety alignment for large language models(LLMs) continues to present vulnerabilities, given that adversarial prompting can effectively bypass their safety this http URL investigation shows that these safety mechanisms predominantly depend on a limited subset of attention heads: removing or ablating these heads can severely compromise model safety. To identify and evaluate these safety-critical components, we introduce RDSHA, a targeted ablation method that leverages the model's refusal direction to pinpoint attention heads mostly responsible for safety behaviors. Further analysis shows that existing jailbreak attacks exploit this concentration by selectively bypassing or manipulating these critical attention heads. To address this issue, we propose AHD, a novel training strategy designed to promote the distributed encoding of safety-related behaviors across numerous attention heads. Experimental results demonstrate that AHD successfully distributes safety-related capabilities across more attention heads. Moreover, evaluations under several mainstream jailbreak attacks show that models trained with AHD exhibit considerably stronger safety robustness, while maintaining overall functional utility. 

**Abstract (ZH)**: 当前大型语言模型（LLMs）的安全对齐仍然存在漏洞，因为恶意提示可以有效绕过其安全机制。这项研究显示，这些安全机制主要依赖于一小部分注意力头：移除或消除这些头部会对模型安全性造成严重损害。为了识别和评估这些安全关键组件，我们提出了一种名为RDSHA的目标消融方法，该方法利用模型的拒绝方向来定位主要负责安全行为的注意力头。进一步的分析表明，现有的监狱突破攻击利用了这种集中性，通过选择性地绕过或操纵这些关键的注意力头。为了解决这一问题，我们提出了AHD，这是一种新的训练策略，旨在促进安全性相关行为在众多注意力头中的分布式编码。实验结果表明，AHD成功地将安全性相关的功能分布在更多的注意力头中。此外，在多种主流的监狱突破攻击下的评估表明，使用AHD训练的模型在安全性稳健性方面表现显著增强，同时保持了整体的功能实用性。 

---
# Topological Uncertainty for Anomaly Detection in the Neural-network EoS Inference with Neutron Star Data 

**Title (ZH)**: 基于中子星数据的神经网络EoS推断中的拓扑不确定性异常检测 

**Authors**: Kenji Fukushima, Syo Kamata  

**Link**: [PDF](https://arxiv.org/pdf/2508.19683)  

**Abstract**: We study the performance of the Topological Uncertainty (TU) constructed with a trained feedforward neural network (FNN) for Anomaly Detection. Generally, meaningful information can be stored in the hidden layers of the trained FNN, and the TU implementation is one tractable recipe to extract buried information by means of the Topological Data Analysis. We explicate the concept of the TU and the numerical procedures. Then, for a concrete demonstration of the performance test, we employ the Neutron Star data used for inference of the equation of state (EoS). For the training dataset consisting of the input (Neutron Star data) and the output (EoS parameters), we can compare the inferred EoSs and the exact answers to classify the data with the label $k$. The subdataset with $k=0$ leads to the normal inference for which the inferred EoS approximates the answer well, while the subdataset with $k=1$ ends up with the unsuccessful inference. Once the TU is prepared based on the $k$-labled subdatasets, we introduce the cross-TU to quantify the uncertainty of characterizing the $k$-labeled data with the label $j$. The anomaly or unsuccessful inference is correctly detected if the cross-TU for $j=k=1$ is smaller than that for $j=0$ and $k=1$. In our numerical experiment, for various input data, we calculate the cross-TU and estimate the performance of Anomaly Detection. We find that performance depends on FNN hyperparameters, and the success rate of Anomaly Detection exceeds $90\%$ in the best case. We finally discuss further potential of the TU application to retrieve the information hidden in the trained FNN. 

**Abstract (ZH)**: Topological Uncertainty (TU) 构建的训练前馈神经网络（FNN）在异常检测中的性能研究 

---
# Survey of Specialized Large Language Model 

**Title (ZH)**: 专业大型语言模型综述 

**Authors**: Chenghan Yang, Ruiyu Zhao, Yang Liu, Ling Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19667)  

**Abstract**: The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development. This survey systematically examines this progression across healthcare, finance, legal, and technical domains. Besides the wide use of specialized LLMs, technical breakthrough such as the emergence of domain-native designs beyond fine-tuning, growing emphasis on parameter efficiency through sparse computation and quantization, increasing integration of multimodal capabilities and so on are applied to recent LLM agent. Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks. The survey further highlights the implications for E-Commerce field to fill gaps in the field. 

**Abstract (ZH)**: 大规模语言模型的迅速演进从简单的领域适配转变为复杂的本土化架构，标志着AI发展 paradigm的转变。本综述系统地探讨了这一进展在医疗、金融、法律和技术领域的应用。除了专门化的大规模语言模型的广泛应用，还介绍了超出微调的领域本征设计的技术突破、通过稀疏计算和量化提高参数效率、增加多模态能力等方面的进展，这些都应用到了近期的语言模型代理中。我们的分析揭示了这些创新如何解决通用语言模型在专业应用中的根本局限性，专门化的模型在领域特定基准测试中始终表现出一致性性能提升。综述还突出了这些发展对电子商务领域的潜在影响。 

---
# Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation 

**Title (ZH)**: 全方位进化近似下的任意精度打印三值神经网络 

**Authors**: Vojtech Mrazek, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Zdenek Vasicek, Mehdi B. Tahoori, Georgios Zervakis  

**Link**: [PDF](https://arxiv.org/pdf/2508.19660)  

**Abstract**: Printed electronics offer a promising alternative for applications beyond silicon-based systems, requiring properties like flexibility, stretchability, conformality, and ultra-low fabrication costs. Despite the large feature sizes in printed electronics, printed neural networks have attracted attention for meeting target application requirements, though realizing complex circuits remains challenging. This work bridges the gap between classification accuracy and area efficiency in printed neural networks, covering the entire processing-near-sensor system design and co-optimization from the analog-to-digital interface-a major area and power bottleneck-to the digital classifier. We propose an automated framework for designing printed Ternary Neural Networks with arbitrary input precision, utilizing multi-objective optimization and holistic approximation. Our circuits outperform existing approximate printed neural networks by 17x in area and 59x in power on average, being the first to enable printed-battery-powered operation with under 5% accuracy loss while accounting for analog-to-digital interfacing costs. 

**Abstract (ZH)**: 印刷电子为超越硅基系统应用提供了有前景的替代方案，需要具备灵活性、可拉伸性、贴合性以及极低的制造成本等特性。尽管印刷电子具有较大的特征尺寸，其神经网络仍因其满足目标应用需求的潜力而受到关注，但实现复杂电路依然具有挑战性。本工作在印刷神经网络中填补了分类准确率和区域效率之间的差距，涵盖了从模拟-数字接口（一个主要的面积和功耗瓶颈）到数字分类器的整个感知器附近系统设计和联合优化。我们提出了一种自动设计具有任意输入精度的印刷三值神经网络的框架，利用多目标优化和整体逼近方法。我们的电路在平均面积上比现有近似印刷神经网络高出17倍，在功耗上高出近59倍，是首个能够在不超过5%准确率损失的情况下实现印刷电池供电操作的设计。 

---
# Intellectual Property in Graph-Based Machine Learning as a Service: Attacks and Defenses 

**Title (ZH)**: 基于图的机器学习即服务中的知识产权：攻击与防御 

**Authors**: Lincan Li, Bolin Shen, Chenxi Zhao, Yuxiang Sun, Kaixiang Zhao, Shirui Pan, Yushun Dong  

**Link**: [PDF](https://arxiv.org/pdf/2508.19641)  

**Abstract**: Graph-structured data, which captures non-Euclidean relationships and interactions between entities, is growing in scale and complexity. As a result, training state-of-the-art graph machine learning (GML) models have become increasingly resource-intensive, turning these models and data into invaluable Intellectual Property (IP). To address the resource-intensive nature of model training, graph-based Machine-Learning-as-a-Service (GMLaaS) has emerged as an efficient solution by leveraging third-party cloud services for model development and management. However, deploying such models in GMLaaS also exposes them to potential threats from attackers. Specifically, while the APIs within a GMLaaS system provide interfaces for users to query the model and receive outputs, they also allow attackers to exploit and steal model functionalities or sensitive training data, posing severe threats to the safety of these GML models and the underlying graph data. To address these challenges, this survey systematically introduces the first taxonomy of threats and defenses at the level of both GML model and graph-structured data. Such a tailored taxonomy facilitates an in-depth understanding of GML IP protection. Furthermore, we present a systematic evaluation framework to assess the effectiveness of IP protection methods, introduce a curated set of benchmark datasets across various domains, and discuss their application scopes and future challenges. Finally, we establish an open-sourced versatile library named PyGIP, which evaluates various attack and defense techniques in GMLaaS scenarios and facilitates the implementation of existing benchmark methods. The library resource can be accessed at: this https URL. We believe this survey will play a fundamental role in intellectual property protection for GML and provide practical recipes for the GML community. 

**Abstract (ZH)**: 基于图结构数据的机器学习模型和数据的知识产权保护研究 

---
# Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception 

**Title (ZH)**: 超越BEV：优化点级 tokens 的协同感知 

**Authors**: Yang Li, Quan Yuan, Guiyang Luo, Xiaoyuan Fu, Rui Pan, Yujia Yang, Congzhang Shao, Yuewen Liu, Jinglin Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.19638)  

**Abstract**: Collaborative perception allows agents to enhance their perceptual capabilities by exchanging intermediate features. Existing methods typically organize these intermediate features as 2D bird's-eye-view (BEV) representations, which discard critical fine-grained 3D structural cues essential for accurate object recognition and localization. To this end, we first introduce point-level tokens as intermediate representations for collaborative perception. However, point-cloud data are inherently unordered, massive, and position-sensitive, making it challenging to produce compact and aligned point-level token sequences that preserve detailed structural information. Therefore, we present CoPLOT, a novel Collaborative perception framework that utilizes Point-Level Optimized Tokens. It incorporates a point-native processing pipeline, including token reordering, sequence modeling, and multi-agent spatial alignment. A semantic-aware token reordering module generates adaptive 1D reorderings by leveraging scene-level and token-level semantic information. A frequency-enhanced state space model captures long-range sequence dependencies across both spatial and spectral domains, improving the differentiation between foreground tokens and background clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop process, combining global agent-level correction with local token-level refinement to mitigate localization noise. Extensive experiments on both simulated and real-world datasets show that CoPLOT outperforms state-of-the-art models, with even lower communication and computation overhead. Code will be available at this https URL. 

**Abstract (ZH)**: 协作感知允许智能体通过交换中间特征来增强其感知能力。现有方法通常将这些中间特征组织为2D顶视图（BEV）表示，这会丢弃准确对象识别和定位所必需的关键细粒度三维结构线索。为此，我们首先引入点级令牌作为协作感知的中间表示。然而，点云数据本质上是无序的、大量的且位置敏感的，这使得生成能够保留详细结构信息的小型和对齐的点级令牌序列变得具有挑战性。因此，我们提出了CoPLOT，一种新的协作感知框架，利用点级优化令牌。CoPLOT整合了一个点本原处理流水线，包括令牌重排序、序列建模和多智能体空间对齐。一种语义感知的令牌重排序模块通过利用场景级和令牌级语义信息生成自适应的一维重排序。一种频率增强的状态空间模型捕获跨空间和频谱域的长程序列依赖性，提高前景令牌与背景杂乱区别的能力。最后，一个邻居到自身的对齐模块应用闭环过程，结合全局智能体级校正与局部令牌级细化来减轻定位噪声。在模拟和真实世界的数据集上的广泛实验表明，CoPLOT优于现有最先进的模型，且具有更低的通信和计算开销。代码将在如下链接处提供：this https URL。 

---
# Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge 

**Title (ZH)**: 邀请论文：面向极端边缘的混合信号智能可穿戴健康护理设备的特征到分类器协同设计 

**Authors**: Maha Shatta, Konstantinos Balaskas, Paula Carolina Lozano Duarte, Georgios Panagopoulos, Mehdi B. Tahoori, Georgios Zervakis  

**Link**: [PDF](https://arxiv.org/pdf/2508.19637)  

**Abstract**: Flexible Electronics (FE) offer a promising alternative to rigid silicon-based hardware for wearable healthcare devices, enabling lightweight, conformable, and low-cost systems. However, their limited integration density and large feature sizes impose strict area and power constraints, making ML-based healthcare systems-integrating analog frontend, feature extraction and classifier-particularly challenging. Existing FE solutions often neglect potential system-wide solutions and focus on the classifier, overlooking the substantial hardware cost of feature extraction and Analog-to-Digital Converters (ADCs)-both major contributors to area and power consumption. In this work, we present a holistic mixed-signal feature-to-classifier co-design framework for flexible smart wearable systems. To the best of our knowledge, we design the first analog feature extractors in FE, significantly reducing feature extraction cost. We further propose an hardware-aware NAS-inspired feature selection strategy within ML training, enabling efficient, application-specific designs. Our evaluation on healthcare benchmarks shows our approach delivers highly accurate, ultra-area-efficient flexible systems-ideal for disposable, low-power wearable monitoring. 

**Abstract (ZH)**: 柔性电子（FE）为可穿戴健康设备提供了有前途的替代于刚性硅基硬件的选择，使其能够实现轻量化、贴合性好且低成本的系统。然而，其有限的集成密度和较大的特征尺寸对基于机器学习（ML）的健康监护系统提出了严格的面积和功率限制，尤其是涉及到模拟前端、特征提取和分类器的集成。现有的FE解决方案通常忽视了系统级的整体优化，主要集中在分类器的优化上，而忽视了特征提取和模数转换器（ADC）的显著硬件成本，这两者都是面积和功耗的主要贡献者。在本文中，我们提出了一种适用于柔性智能可穿戴系统的端到端混合信号特征-分类器协同设计框架。据我们所知，我们设计了第一代用于柔性电子的模拟特征提取器，大幅降低了特征提取的成本。我们进一步提出了一种基于硬件感知的类神经架构搜索（NAS）启发式的特征选择策略，该策略可以在机器学习训练过程中启用高效且应用场景特定的设计。我们在健康监护领域的基准测试中评估了我们的方法，结果表明，该方法能够实现高精度且超紧凑面积的柔性系统，适用于一次性使用的低功耗可穿戴监测设备。 

---
# Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition 

**Title (ZH)**: 分而治之，加权，路由：基于动态专家融合的难度感知优化方法及其在长尾识别中的应用 

**Authors**: Xiaolei Wei, Yi Ouyang, Haibo Ye  

**Link**: [PDF](https://arxiv.org/pdf/2508.19630)  

**Abstract**: Long-tailed visual recognition is challenging not only due to class imbalance but also because of varying classification difficulty across categories. Simply reweighting classes by frequency often overlooks those that are intrinsically hard to learn. To address this, we propose \textbf{DQRoute}, a modular framework that combines difficulty-aware optimization with dynamic expert collaboration. DQRoute first estimates class-wise difficulty based on prediction uncertainty and historical performance, and uses this signal to guide training with adaptive loss weighting. On the architectural side, DQRoute employs a mixture-of-experts design, where each expert specializes in a different region of the class distribution. At inference time, expert predictions are weighted by confidence scores derived from expert-specific OOD detectors, enabling input-adaptive routing without the need for a centralized router. All components are trained jointly in an end-to-end manner. Experiments on standard long-tailed benchmarks demonstrate that DQRoute significantly improves performance, particularly on rare and difficult classes, highlighting the benefit of integrating difficulty modeling with decentralized expert routing. 

**Abstract (ZH)**: 长尾视觉识别不仅由于类别不平衡而具有挑战性，还因为不同类别之间的分类难度各异。简单地按频率重新加权类别往往忽视了那些本质上难以学习的类别。为此，我们提出了一种名为DQRoute的模块化框架，该框架结合了难度感知优化与动态专家协作。DQRoute首先基于预测不确定性及历史性能估算类别层面的难度，并使用此信号引导具有自适应损失加权的训练。在架构方面，DQRoute采用混合专家设计，其中每个专家专注于类分布的不同区域。在推理阶段，专家预测由专家特定的OOD检测器得出的置信分数加权，无需中心路由器即可实现输入自适应路由。所有组件以端到端的方式联合训练。在标准长尾基准测试上的实验表明，DQRoute显著改善了性能，特别是在稀有和困难类别上，强调了将难度建模与分散式专家路由集成的好处。 

---
# Training for Obsolescence? The AI-Driven Education Trap 

**Title (ZH)**: 人工智能驱动的教育陷阱：人才培养走向过时？ 

**Authors**: Andrew J. Peterson  

**Link**: [PDF](https://arxiv.org/pdf/2508.19625)  

**Abstract**: Artificial intelligence simultaneously transforms human capital production in schools and its demand in labor markets. Analyzing these effects in isolation can lead to a significant misallocation of educational resources. We model an educational planner whose decision to adopt AI is driven by its teaching productivity, failing to internalize AI's future wage-suppressing effect on those same skills. Our core assumption, motivated by a pilot survey, is that there is a positive correlation between these two effects. This drives our central proposition: this information failure creates a skill mismatch that monotonically increases with AI prevalence. Extensions show the mismatch is exacerbated by the neglect of unpriced non-cognitive skills and by a school's endogenous over-investment in AI. Our findings caution that policies promoting AI in education, if not paired with forward-looking labor market signals, may paradoxically undermine students' long-term human capital, especially if reliance on AI crowds out the development of unpriced non-cognitive skills, such as persistence, that are forged through intellectual struggle. 

**Abstract (ZH)**: 人工智能同时转型学校中的人力资本生产和劳动力市场对其需求。孤立分析这些影响可能导致教育资源的重大错配。我们建模了一个教育规划者，其采用人工智能的决策由其教学生产力驱动，未能 internalize 人工智能对未来同技能工资抑制效应的影响。我们的核心假设，基于试点调查，是这两者效应之间存在正相关关系。这驱动我们的中心命题：这种信息失败导致技能 mismatch，并且这种 mismatch 随着人工智能普及率增加而单调增加。扩展研究显示，由于未考虑无价的非认知技能以及学校内生过度投资人工智能，这种 mismatch 被加剧。我们的研究成果警示，在教育中推广人工智能若未配有前瞻性的劳动力市场信号，可能会出乎意料地削弱学生长期的人力资本，尤其是在人工智能可能挤占通过智力斗争锻造的无价非认知技能（如毅力）的发展时。 

---
# Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning 

**Title (ZH)**: 基于半隐式贝叶斯提示调优的实例化个性化联邦学习 

**Authors**: Tiandi Ye, Wenyan Liu, Kai Yao, Lichun Li, Shangchao Su, Cen Chen, Xiang Li, Shan Yin, Ming Gao  

**Link**: [PDF](https://arxiv.org/pdf/2508.19621)  

**Abstract**: Federated learning (FL) is a privacy-preserving machine learning paradigm that enables collaborative model training across multiple distributed clients without disclosing their raw data. Personalized federated learning (pFL) has gained increasing attention for its ability to address data heterogeneity. However, most existing pFL methods assume that each client's data follows a single distribution and learn one client-level personalized model for each client. This assumption often fails in practice, where a single client may possess data from multiple sources or domains, resulting in significant intra-client heterogeneity and suboptimal performance. To tackle this challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework based on visual prompt tuning. Specifically, we formulate instance-wise prompt generation from a Bayesian perspective and model the prompt posterior as an implicit distribution to capture diverse visual semantics. We derive a variational training objective under the semi-implicit variational inference framework. Extensive experiments on benchmark datasets demonstrate that pFedBayesPT consistently outperforms existing pFL methods under both feature and label heterogeneity settings. 

**Abstract (ZH)**: Federated 学习（FL）是一种隐私保护的机器学习范式，能够在不泄露原始数据的情况下，实现多个分布式客户端之间的协作模型训练。个性化联邦学习（pFL）因其能够解决数据异质性问题而逐渐受到关注。然而，大多数现有 pFL 方法假设每个客户端的数据遵循单一分布，并为每个客户端学习一个客户端级别的个性化模型。这一假设在实践中往往不成立，因为单个客户端可能拥有来自多个来源或领域的数据，导致显著的客户端内部异质性和次优性能。为了解决这一挑战，我们提出了一种基于视觉提示调优的细粒度实例级 pFL 框架 pFedBayesPT。具体而言，我们从贝叶斯角度形式化实例级提示生成，并将提示后验建模为隐式分布以捕获多样的视觉语义。在半隐式变分推理框架下，我们推导了变分训练目标。在基准数据集上的广泛实验表明，pFedBayesPT 在特征异质性和标签异质性设置下均能优于现有 pFL 方法。 

---
# A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions 

**Title (ZH)**: 面向场景的联邦推荐系统综述：技术、挑战及未来方向 

**Authors**: Yunqi Mi, Jiakui Shen, Guoshuai Zhao, Jialie Shen, Xueming Qian  

**Link**: [PDF](https://arxiv.org/pdf/2508.19620)  

**Abstract**: Extending recommender systems to federated learning (FL) frameworks to protect the privacy of users or platforms while making recommendations has recently gained widespread attention in academia. This is due to the natural coupling of recommender systems and federated learning architectures: the data originates from distributed clients (mostly mobile devices held by users), which are highly related to privacy. In a centralized recommender system (CenRec), the central server collects clients' data, trains the model, and provides the service. Whereas in federated recommender systems (FedRec), the step of data collecting is omitted, and the step of model training is offloaded to each client. The server only aggregates the model and other knowledge, thus avoiding client privacy leakage. Some surveys of federated recommender systems discuss and analyze related work from the perspective of designing FL systems. However, their utility drops by ignoring specific recommendation scenarios' unique characteristics and practical challenges. For example, the statistical heterogeneity issue in cross-domain FedRec originates from the label drift of the data held by different platforms, which is mainly caused by the recommender itself, but not the federated architecture. Therefore, it should focus more on solving specific problems in real-world recommendation scenarios to encourage the deployment FedRec. To this end, this review comprehensively analyzes the coupling of recommender systems and federated learning from the perspective of recommendation researchers and practitioners. We establish a clear link between recommendation scenarios and FL frameworks, systematically analyzing scenario-specific approaches, practical challenges, and potential opportunities. We aim to develop guidance for the real-world deployment of FedRec, bridging the gap between existing research and applications. 

**Abstract (ZH)**: 扩展推荐系统到联邦学习框架中以保护用户或平台隐私的同时进行推荐近期在学术界引起了广泛关注。 

---
# LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation 

**Title (ZH)**: LFD：层融合解码以利用检索增强生成中的外部知识 

**Authors**: Yang Sun, Lixin Zou, Dan Luo, Zhiyong Xie, Long Zhang, Liming Dong, Yunwei Zhao, Xixun Lin, Yanxiong Lu, Chenliang Li  

**Link**: [PDF](https://arxiv.org/pdf/2508.19614)  

**Abstract**: Retrieval-augmented generation (RAG) incorporates external knowledge into large language models (LLMs), improving their adaptability to downstream tasks and enabling information updates. Surprisingly, recent empirical evidence demonstrates that injecting noise into retrieved relevant documents paradoxically facilitates exploitation of external knowledge and improves generation quality. Although counterintuitive and challenging to apply in practice, this phenomenon enables granular control and rigorous analysis of how LLMs integrate external knowledge. Therefore, in this paper, we intervene on noise injection and establish a layer-specific functional demarcation within the LLM: shallow layers specialize in local context modeling, intermediate layers focus on integrating long-range external factual knowledge, and deeper layers primarily rely on parametric internal knowledge. Building on this insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that directly combines representations from an intermediate layer with final-layer decoding outputs to fully exploit the external factual knowledge. To identify the optimal intermediate layer, we introduce an internal knowledge score (IKS) criterion that selects the layer with the lowest IKS value in the latter half of layers. Experimental results across multiple benchmarks demonstrate that LFD helps RAG systems more effectively surface retrieved context knowledge with minimal cost. 

**Abstract (ZH)**: 检索增强生成（RAG）将外部知识融入大型语言模型（LLMs），提高其对下游任务的适应性并允许信息更新。令人惊讶的是，近期的实验证据表明，向检索的相关文档中注入噪声反而能充分利用外部知识并提高生成质量。虽然这似乎违反直觉且在实践中难以应用，但这一现象使得可以对LLMs如何整合外部知识进行细粒度控制和严格分析。因此，在本文中，我们干预了噪声注入，并在LLM中建立了分层功能分界：浅层负责局部上下文建模，中间层专注于整合长程外部事实知识，深层主要依赖参数内部知识。基于这一洞察，我们提出了层融合解码（LFD），一种直接将中间层表示与最终解码输出结合起来以充分利用外部事实知识的简单解码策略。为了确定最优中间层，我们引入了一个内部知识评分（IKS）准则，选择后半部分层数中IKS值最低的层。跨多个基准的实验结果表明，LFD有助于RAG系统以最低成本更有效地呈现检索的背景知识。 

---
# FinCast: A Foundation Model for Financial Time-Series Forecasting 

**Title (ZH)**: FinCast: 金融时间序列预测的基础模型 

**Authors**: Zhuohang Zhu, Haodong Chen, Qiang Qu, Vera Chung  

**Link**: [PDF](https://arxiv.org/pdf/2508.19609)  

**Abstract**: Financial time-series forecasting is critical for maintaining economic stability, guiding informed policymaking, and promoting sustainable investment practices. However, it remains challenging due to various underlying pattern shifts. These shifts arise primarily from three sources: temporal non-stationarity (distribution changes over time), multi-domain diversity (distinct patterns across financial domains such as stocks, commodities, and futures), and varying temporal resolutions (patterns differing across per-second, hourly, daily, or weekly indicators). While recent deep learning methods attempt to address these complexities, they frequently suffer from overfitting and typically require extensive domain-specific fine-tuning. To overcome these limitations, we introduce FinCast, the first foundation model specifically designed for financial time-series forecasting, trained on large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot performance, effectively capturing diverse patterns without domain-specific fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate that FinCast surpasses existing state-of-the-art methods, highlighting its strong generalization capabilities. 

**Abstract (ZH)**: 金融时间序列预测对于维护经济稳定、指导明智的政策制定和促进可持续投资实践至关重要，但由于存在多种潜在模式变化，这项任务仍然具有挑战性。这些变化主要源于三大来源：时间非平稳性（随时间变化的分布）、多领域多样性（金融领域如股票、商品和期货之间的不同模式）以及不同的时间分辨率（在每秒、小时、日或周指标之间变化的模式）。尽管最近的深度学习方法试图解决这些复杂性，但它们通常容易出现过拟合并通常需要大量的领域特定微调。为克服这些限制，我们提出了FinCast，这是第一个专门设计用于金融时间序列预测的基础模型，并在大规模金融数据集上进行了训练。令人remarkably的是，FinCast在零样本情况下表现出稳健的性能，能够有效地捕捉多样化的模式而无需领域特定微调。全面的实证和定性评估表明，FinCast超越了现有的最优方法，突显了其强大的泛化能力。 

---
# IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation 

**Title (ZH)**: IELDG：基于逆进化层抑制领域特定噪声的领域自适应语义分割 

**Authors**: Qizhe Fan, Chaoyu Liu, Zhonghua Qiao, Xiaoqin Shen  

**Link**: [PDF](https://arxiv.org/pdf/2508.19604)  

**Abstract**: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model using labeled data from a source domain, with the goal of achieving robust generalization to unseen target domains during inference. A common approach to improve generalization is to augment the source domain with synthetic data generated by diffusion models (DMs). However, the generated images often contain structural or semantic defects due to training imperfections. Training segmentation models with such flawed data can lead to performance degradation and error accumulation. To address this issue, we propose to integrate inverse evolution layers (IELs) into the generative process. IELs are designed to highlight spatial discontinuities and semantic inconsistencies using Laplacian-based priors, enabling more effective filtering of undesirable generative patterns. Based on this mechanism, we introduce IELDM, an enhanced diffusion-based data augmentation framework that can produce higher-quality images. Furthermore, we observe that the defect-suppression capability of IELs can also benefit the segmentation network by suppressing artifact propagation. Based on this insight, we embed IELs into the decoder of the DGSS model and propose IELFormer to strengthen generalization capability in cross-domain scenarios. To further strengthen the model's semantic consistency across scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module, which performs frequency-domain analysis to achieve structured integration of multi-resolution features, thereby improving cross-scale coherence. Extensive experiments on benchmark datasets demonstrate that our approach achieves superior generalization performance compared to existing methods. 

**Abstract (ZH)**: 跨域通用语义分割（DGSS）通过利用源域标注数据训练模型，旨在通过推理实现对未见过的目标域的稳健泛化。一种改进泛化的常见方法是通过扩散模型生成数据增强源域。然而，生成的图像由于训练缺陷往往包含结构或语义缺陷。使用这些有缺陷的数据训练分割模型会导致性能下降和错误累积。为解决这一问题，我们提出将逆进化层（IELs）整合到生成过程。IELs设计用于利用拉普拉斯先验强调空间不连续性和语义不一致性，从而更有效地过滤不希望的生成模式。基于这一机制，我们引入了IELDM，一种增强的基于扩散的数据增强框架，能够生成更高质量的图像。此外，我们观察到IELs的缺陷抑制能力也可以通过抑制伪影传播来造福分割网络。基于这一洞察，我们将IELs嵌入到DGSS模型的解码器中，并提出IELFormer以增强跨域场景下的泛化能力。为了进一步增强模型跨尺度的语义一致性，IELFormer整合了一个多尺度频率融合（MFF）模块，该模块在频域分析的基础上实现多分辨率特征的结构化集成，从而提高跨尺度的一致性。在基准数据集上的实验表明，我们的方法在泛化性能上优于现有方法。 

---
# CompLex: Music Theory Lexicon Constructed by Autonomous Agents for Automatic Music Generation 

**Title (ZH)**: CompLex: 由自主代理构建的音乐理论词汇表用于自动音乐生成 

**Authors**: Zhejing Hu, Yan Liu, Gong Chen, Bruce X.B. Yu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19603)  

**Abstract**: Generative artificial intelligence in music has made significant strides, yet it still falls short of the substantial achievements seen in natural language processing, primarily due to the limited availability of music data. Knowledge-informed approaches have been shown to enhance the performance of music generation models, even when only a few pieces of musical knowledge are integrated. This paper seeks to leverage comprehensive music theory in AI-driven music generation tasks, such as algorithmic composition and style transfer, which traditionally require significant manual effort with existing techniques. We introduce a novel automatic music lexicon construction model that generates a lexicon, named CompLex, comprising 37,432 items derived from just 9 manually input category keywords and 5 sentence prompt templates. A new multi-agent algorithm is proposed to automatically detect and mitigate hallucinations. CompLex demonstrates impressive performance improvements across three state-of-the-art text-to-music generation models, encompassing both symbolic and audio-based methods. Furthermore, we evaluate CompLex in terms of completeness, accuracy, non-redundancy, and executability, confirming that it possesses the key characteristics of an effective lexicon. 

**Abstract (ZH)**: 生成式人工智能在音乐领域的进展显著，但仍逊色于自然语言处理领域取得的重大成果，主要原因是可用于音乐的数据有限。基于知识的方法已被证明能够提升音乐生成模型的表现，即使只整合少量的音乐知识也是如此。本文旨在利用全面的音乐理论来增强AI驱动的音乐生成任务，如算法作曲和风格转移，这些任务通常需要大量的人工操作。我们引入了一种新的自动音乐词汇表构建模型，该模型生成了一个名为CompLex的词汇表，包含37,432个项目，仅凭9个手动输入的类别关键词和5个句子提示模板。我们提出了一种新的多智能体算法，以自动检测和缓解幻觉现象。CompLex在三种最先进的文本到音乐生成模型中均表现出显著的性能改进，涵盖符号和基于音频的方法。此外，我们从完备性、准确性、非冗余性和可执行性等方面评估了CompLex，证实了其具备有效词汇表的关键特征。 

---
# Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities 

**Title (ZH)**: 互补学习系统赋能智能城市中车辆运动预测的在线连续学习 

**Authors**: Zirui Li, Yunlong Lin, Guodong Du, Xiaocong Zhao, Cheng Gong, Chen Lv, Chao Lu, Jianwei Gong  

**Link**: [PDF](https://arxiv.org/pdf/2508.19597)  

**Abstract**: Artificial intelligence underpins most smart city services, yet deep neural network (DNN) that forecasts vehicle motion still struggle with catastrophic forgetting, the loss of earlier knowledge when models are updated. Conventional fixes enlarge the training set or replay past data, but these strategies incur high data collection costs, sample inefficiently and fail to balance long- and short-term experience, leaving them short of human-like continual learning. Here we introduce Dual-LS, a task-free, online continual learning paradigm for DNN-based motion forecasting that is inspired by the complementary learning system of the human brain. Dual-LS pairs two synergistic memory rehearsal replay mechanisms to accelerate experience retrieval while dynamically coordinating long-term and short-term knowledge representations. Tests on naturalistic data spanning three countries, over 772,000 vehicles and cumulative testing mileage of 11,187 km show that Dual-LS mitigates catastrophic forgetting by up to 74.31\% and reduces computational resource demand by up to 94.02\%, markedly boosting predictive stability in vehicle motion forecasting without inflating data requirements. Meanwhile, it endows DNN-based vehicle motion forecasting with computation efficient and human-like continual learning adaptability fit for smart cities. 

**Abstract (ZH)**: 基于反演记忆机制的双通道连续学习框架减轻灾难性遗忘并提升智能城市中车辆运动预测的计算效率和类人适应性 

---
# Hallucinating with AI: AI Psychosis as Distributed Delusions 

**Title (ZH)**: AI幻觉：人工智能妄想症作为分布式妄想 

**Authors**: Lucy Osler  

**Link**: [PDF](https://arxiv.org/pdf/2508.19588)  

**Abstract**: There is much discussion of the false outputs that generative AI systems such as ChatGPT, Claude, Gemini, DeepSeek, and Grok create. In popular terminology, these have been dubbed AI hallucinations. However, deeming these AI outputs hallucinations is controversial, with many claiming this is a metaphorical misnomer. Nevertheless, in this paper, I argue that when viewed through the lens of distributed cognition theory, we can better see the dynamic and troubling ways in which inaccurate beliefs, distorted memories and self-narratives, and delusional thinking can emerge through human-AI interactions; examples of which are popularly being referred to as cases of AI psychosis. In such cases, I suggest we move away from thinking about how an AI system might hallucinate at us, by generating false outputs, to thinking about how, when we routinely rely on generative AI to help us think, remember, and narrate, we can come to hallucinate with AI. This can happen when AI introduces errors into the distributed cognitive process, but it can also happen when AI sustains, affirms, and elaborates on our own delusional thinking and self-narratives, such as in the case of Jaswant Singh Chail. I also examine how the conversational style of chatbots can lead them to play a dual-function, both as a cognitive artefact and a quasi-Other with whom we co-construct our beliefs, narratives, and our realities. It is this dual function, I suggest, that makes generative AI an unusual, and particularly seductive, case of distributed cognition. 

**Abstract (ZH)**: 生成式AI系统如ChatGPT、Claude、Gemini、DeepSeek和Grok生成的虚假输出的讨论 incessantly。这些输出被称为AI幻觉。然而，将这些AI输出称为幻觉是有争议的，许多人认为这是一种比喻性的误称。尽管如此，本文认为，从分布式认知理论的视角来看，我们能更好地揭示不准确信念、扭曲记忆和自我叙述以及妄想思维通过人机交互如何动态和令人不安地产生的过程；这些过程现被称为AI精神病案例。在这种情况下，我建议我们不应从AI系统如何向我们产生虚假输出的角度来考虑其幻觉，而应从我们依赖生成式AI来思考、回忆和叙述时，如何与AI一起产生幻觉的角度来考虑。这不仅发生在AI引入错误进入分布式认知过程的情况下，也可能发生在AI巩固、肯定并进一步阐述我们自身的妄想思维和自我叙述的情况下，如贾万特·辛格·查伊尔案。此外，我还探讨了聊天机器人的对话风格如何使它们在认知工具和准他者的双重角色之间发挥作用，我们一起构建我们的信念、叙述和现实。我认为，正是这种双重功能，使生成式AI成为一个不同寻常而且尤其具有诱惑力的分布式认知案例。 

---
# Towards stable AI systems for Evaluating Arabic Pronunciations 

**Title (ZH)**: 面向阿拉伯发音评估的稳定AI系统研究 

**Authors**: Hadi Zaatiti, Hatem Hajri, Osama Abdullah, Nader Masmoudi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19587)  

**Abstract**: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and sentence-level transcription, yet struggle to classify isolated letters. In this study, we show that this phoneme-level task, crucial for language learning, speech therapy, and phonetic research, is challenging because isolated letters lack co-articulatory cues, provide no lexical context, and last only a few hundred milliseconds. Recogniser systems must therefore rely solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic (pharyngealized) consonants and other sounds with no close analogues in many languages. This study introduces a diverse, diacritised corpus of isolated Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models achieve only 35% accuracy on it. Training a lightweight neural network on wav2vec embeddings raises performance to 65%. However, adding a small amplitude perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we apply adversarial training, limiting the noisy-speech drop to 9% while preserving clean-speech accuracy. We detail the corpus, training pipeline, and evaluation protocol, and release, on demand, data and code for reproducibility. Finally, we outline future work extending these methods to word- and sentence-level frameworks, where precise letter pronunciation remains critical. 

**Abstract (ZH)**: 现代阿拉伯语ASR系统如wav2vec 2.0在单词和句级转录方面表现出色，但在孤立字母分类方面遇到困难。本研究展示了这一对语言学习、语音疗法和音系研究至关重要的音素级任务的挑战性，因为孤立字母缺乏连音线索，提供不了词汇上下文，并且仅持续几毫秒。因此，识别系统必须依赖于多变的声学线索，而阿拉伯语中的强发音（咽鸣化）辅音和其他许多语言中找不到对应音的发音加剧了这一难度。本研究引入了一个多样化的、注音的孤立阿拉伯字母语料库，并证明最先进的wav2vec 2.0模型在其上只能达到35%的准确率。通过在wav2vec嵌入上训练一个轻量级神经网络，准确率提高到65%。然而，添加一小幅度扰动（ε=0.05）将准确率降至32%。为了恢复鲁棒性，我们应用对抗训练，将噪声语音下降限制在9%，同时保持干净语音的准确率。我们详细介绍了语料库、训练流程和评估协议，并根据需求提供数据和代码以确保可重复性。最后，我们概述了未来的工作，旨在将这些方法扩展到词级和句级框架，其中精确的字母发音仍然至关重要。 

---
# Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts 

**Title (ZH)**: 面向书籍长度上下文多层理解的全方位自动化评估框架 

**Authors**: Jiaqi Deng, Yuho Lee, Nicole Hee-Yeon Kim, Hyangsuk Min, Taewon Yun, Minjeong Ban, Kim Yul, Hwanjun Song  

**Link**: [PDF](https://arxiv.org/pdf/2508.19578)  

**Abstract**: We introduce HAMLET, a holistic and automated framework for evaluating the long-context comprehension of large language models (LLMs). HAMLET structures source texts into a three-level key-fact hierarchy at root-, branch-, and leaf-levels, and employs query-focused summarization to evaluate how well models recall and faithfully represent information at each level. To validate the reliability of our fully automated pipeline, we conduct a systematic human study, showing that our automatic evaluation achieves over 90% agreement with expert human judgments, while reducing the cost by up to 25 times. HAMLET reveals that LLMs struggle with fine-grained comprehension, especially at the leaf level, and are sensitive to positional effects like the lost-in-the-middle. Analytical queries pose greater challenges than narrative ones, and consistent performance gaps emerge between open-source and proprietary models, as well as across model scales. Our code and dataset are publicly available at this https URL. 

**Abstract (ZH)**: 我们介绍HAMLET：一种全面自动的框架，用于评估大型语言模型的长上下文理解能力。 

---
# Interact-Custom: Customized Human Object Interaction Image Generation 

**Title (ZH)**: Interact-Custom: 定制化的human-object交互图像生成 

**Authors**: Zhu Xu, Zhaowen Wang, Yuxin Peng, Yang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19575)  

**Abstract**: Compositional Customized Image Generation aims to customize multiple target concepts within generation content, which has gained attention for its wild this http URL approaches mainly concentrate on the target entity's appearance preservation, while neglecting the fine-grained interaction control among target this http URL enable the model of such interaction control capability, we focus on human object interaction scenario and propose the task of Customized Human Object Interaction Image Generation(CHOI), which simultaneously requires identity preservation for target human object and the interaction semantic control between this http URL primary challenges exist for CHOI:(1)simultaneous identity preservation and interaction control demands require the model to decompose the human object into self-contained identity features and pose-oriented interaction features, while the current HOI image datasets fail to provide ideal samples for such feature-decomposed learning.(2)inappropriate spatial configuration between human and object may lead to the lack of desired interaction this http URL tackle it, we first process a large-scale dataset, where each sample encompasses the same pair of human object involving different interactive this http URL we design a two-stage model Interact-Custom, which firstly explicitly models the spatial configuration by generating a foreground mask depicting the interaction behavior, then under the guidance of this mask, we generate the target human object interacting while preserving their identities this http URL, if the background image and the union location of where the target human object should appear are provided by users, Interact-Custom also provides the optional functionality to specify them, offering high content controllability. Extensive experiments on our tailored metrics for CHOI task demonstrate the effectiveness of our approach. 

**Abstract (ZH)**: 组件化定制图像生成旨在生成内容中定制多个目标概念，这一领域因其潜力而受到关注。CHOI任务专注于人类物体交互场景，提出定制人类物体交互图像生成任务（CHOI），该任务同时要求保留目标人类物体的身份并在其交互语义之间进行控制。对于CHOI任务，主要存在两项挑战：（1）身份保留和交互控制的同时需求要求模型将人类物体分解为自我包含的身份特征和姿态导向的交互特征，而当前的HOI图像数据集未能提供理想的分解学习样本；（2）人类与物体之间不合适的空间配置可能导致期望的交互丢失。为应对这一挑战，我们首先处理了一个大规模的数据集，其中每个样本包含不同交互行为下的同一个人物体对。我们设计了一个两阶段模型Interact-Custom，首先通过生成描述交互行为的前景掩码显式建模空间配置，然后在掩码的指导下生成保留身份的目标人类物体的交互图像。如果用户提供背景图像和目标人类物体应出现的交集位置，Interact-Custom还提供了指定这些位置的可选功能，提供了高度的内容可控性。针对CHOI任务的大量实验表明了我们方法的有效性。 

---
# Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation 

**Title (ZH)**: 多模态原型对齐在半监督病理图像分割中的应用 

**Authors**: Mingxi Fu, Fanglei Fu, Xitong Ling, Huaitian Yuan, Tian Guan, Yonghong He, Lianghui Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19574)  

**Abstract**: Pathological image segmentation faces numerous challenges, particularly due to ambiguous semantic boundaries and the high cost of pixel-level annotations. Although recent semi-supervised methods based on consistency regularization (e.g., UniMatch) have made notable progress, they mainly rely on perturbation-based consistency within the image modality, making it difficult to capture high-level semantic priors, especially in structurally complex pathology images. To address these limitations, we propose MPAMatch - a novel segmentation framework that performs pixel-level contrastive learning under a multimodal prototype-guided supervision paradigm. The core innovation of MPAMatch lies in the dual contrastive learning scheme between image prototypes and pixel labels, and between text prototypes and pixel labels, providing supervision at both structural and semantic levels. This coarse-to-fine supervisory strategy not only enhances the discriminative capability on unlabeled samples but also introduces the text prototype supervision into segmentation for the first time, significantly improving semantic boundary modeling. In addition, we reconstruct the classic segmentation architecture (TransUNet) by replacing its ViT backbone with a pathology-pretrained foundation model (Uni), enabling more effective extraction of pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND, EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art methods, validating its dual advantages in structural and semantic modeling. 

**Abstract (ZH)**: 病理图像分割面临着诸多挑战，特别是由于语义边界的模糊性和像素级注释的高成本。尽管基于一致性正则化的半监督方法（如UniMatch）取得了显著进展，但这些方法主要依赖于图像模态内的扰动一致性，难以捕捉高层次的语义先验，尤其是在结构复杂的病理图像中。为克服这些局限性，我们提出了一种名为MPAMatch的新分割框架，它在多模态原型引导监督范式下进行像素级对比学习。MPAMatch的核心创新在于图像原型与像素标签之间的双分支对比学习方案，以及文本原型与像素标签之间的对比学习方案，从而在结构和语义两个层面提供监督。这种从粗到细的监督策略不仅增强了对未标注样本的辨别能力，还首次将文本原型监督引入分割中，显著提升了语义边界的建模。此外，我们通过将TransUNet的经典分割架构中的ViT主干替换为预训练的病理基础模型（Uni），重构了该架构，以实现对病理相关特征更有效的提取。在GLAS、EBHI-SEG-GLAND、EBHI-SEG-CANCER和KPI上的广泛实验表明，MPAMatch在结构和语义建模方面优于现有方法。 

---
# Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era 

**Title (ZH)**: 合成数据的生成模型：在通用人工智能时代转型数据挖掘 

**Authors**: Dawei Li, Yue Huang, Ming Li, Tianyi Zhou, Xiangliang Zhang, Huan Liu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19570)  

**Abstract**: Generative models such as Large Language Models, Diffusion Models, and generative adversarial networks have recently revolutionized the creation of synthetic data, offering scalable solutions to data scarcity, privacy, and annotation challenges in data mining. This tutorial introduces the foundations and latest advances in synthetic data generation, covers key methodologies and practical frameworks, and discusses evaluation strategies and applications. Attendees will gain actionable insights into leveraging generative synthetic data to enhance data mining research and practice. More information can be found on our website: this https URL. 

**Abstract (ZH)**: 生成模型（如大型语言模型、扩散模型和生成对抗网络）最近在合成数据的生成方面引发了革命，提供了应对数据挖掘中数据稀缺性、隐私和标注挑战的可扩展解决方案。本教程介绍了合成数据生成的基础和最新进展，涵盖了关键方法学和实用框架，并讨论了评估策略和应用。参与者将获得有关利用生成合成数据以增强数据挖掘研究和实践的实用见解。更多详细信息请参见我们的网站：this https URL。 

---
# Energy-Efficient Learning-Based Beamforming for ISAC-Enabled V2X Networks 

**Title (ZH)**: 基于ISAC使能的V2X网络的高效学习导向波束forming技术 

**Authors**: Chen Shang, Jiadong Yu, Dinh Thai Hoang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19566)  

**Abstract**: This work proposes an energy-efficient, learning-based beamforming scheme for integrated sensing and communication (ISAC)-enabled V2X networks. Specifically, we first model the dynamic and uncertain nature of V2X environments as a Markov Decision Process. This formulation allows the roadside unit to generate beamforming decisions based solely on current sensing information, thereby eliminating the need for frequent pilot transmissions and extensive channel state information acquisition. We then develop a deep reinforcement learning (DRL) algorithm to jointly optimize beamforming and power allocation, ensuring both communication throughput and sensing accuracy in highly dynamic scenario. To address the high energy demands of conventional learning-based schemes, we embed spiking neural networks (SNNs) into the DRL framework. Leveraging their event-driven and sparsely activated architecture, SNNs significantly enhance energy efficiency while maintaining robust performance. Simulation results confirm that the proposed method achieves substantial energy savings and superior communication performance, demonstrating its potential to support green and sustainable connectivity in future V2X systems. 

**Abstract (ZH)**: 面向ISAC增强V2X网络的节能学习导向波束形成方案 

---
# FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection 

**Title (ZH)**: FlowDet: 克服实时端到端交通检测中的视角和尺度挑战 

**Authors**: Yuhang Zhao, Zixing Wang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19565)  

**Abstract**: End-to-end object detectors offer a promising NMS-free paradigm for real-time applications, yet their high computational cost remains a significant barrier, particularly for complex scenarios like intersection traffic monitoring. To address this challenge, we propose FlowDet, a high-speed detector featuring a decoupled encoder optimization strategy applied to the DETR architecture. Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to maintain high representational power across extreme scale variations. To rigorously evaluate the model's performance in environments with severe occlusion and high object density, we collected the Intersection-Flow-5k dataset, a new challenging scene for this task. Evaluated on Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by 1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference speed by 16.2%. Our work demonstrates a new path towards building highly efficient and accurate detectors for demanding, real-world perception systems. The Intersection-Flow-5k dataset is available at this https URL. 

**Abstract (ZH)**: FlowDet：一种用于交叉口交通监测的高速检测器 

---
# Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models 

**Title (ZH)**: Bi-LoRA: 高效的锋利感知最小化方法用于大规模模型微调 

**Authors**: Yuhang Liu, Tao Li, Zhehao Huang, Zuopeng Yang, Xiaolin Huang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19564)  

**Abstract**: Fine-tuning large-scale pre-trained models with limited data presents significant challenges for generalization. While Sharpness-Aware Minimization (SAM) has proven effective in improving generalization by seeking flat minima, its substantial extra memory and computation overhead make it impractical for large models. Integrating SAM with parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA) is a promising direction. However, we find that directly applying SAM to LoRA parameters limits the sharpness optimization to a restricted subspace, hindering its effectiveness. To address this limitation, we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an auxiliary LoRA module to model SAM's adversarial weight perturbations. It decouples SAM's weight perturbations from LoRA optimization: the primary LoRA module adapts to specific tasks via standard gradient descent, while the auxiliary module captures the sharpness of the loss landscape through gradient ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness for achieving flatter minima while remaining memory-efficient. Another important benefit is that the dual design allows for simultaneous optimization and perturbation, eliminating SAM's doubled training costs. Extensive experiments across diverse tasks and architectures demonstrate Bi-LoRA's efficiency and effectiveness in enhancing generalization. 

**Abstract (ZH)**: 细粒度低秩适应结合Sharpness-Aware Minimization以增强泛化能力 

---
# Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting 

**Title (ZH)**: just Because You Can, Doesn't Mean You Should: 使用LLM进行数据拟合 

**Authors**: Hejia Liu, Mochen Yang, Gediminas Adomavicius  

**Link**: [PDF](https://arxiv.org/pdf/2508.19563)  

**Abstract**: Large Language Models (LLMs) are being applied in a wide array of settings, well beyond the typical language-oriented use cases. In particular, LLMs are increasingly used as a plug-and-play method for fitting data and generating predictions. Prior work has shown that LLMs, via in-context learning or supervised fine-tuning, can perform competitively with many tabular supervised learning techniques in terms of predictive performance. However, we identify a critical vulnerability of using LLMs for data fitting -- making changes to data representation that are completely irrelevant to the underlying learning task can drastically alter LLMs' predictions on the same data. For example, simply changing variable names can sway the size of prediction error by as much as 82% in certain settings. Such prediction sensitivity with respect to task-irrelevant variations manifests under both in-context learning and supervised fine-tuning, for both close-weight and open-weight general-purpose LLMs. Moreover, by examining the attention scores of an open-weight LLM, we discover a non-uniform attention pattern: training examples and variable names/values which happen to occupy certain positions in the prompt receive more attention when output tokens are generated, even though different positions are expected to receive roughly the same attention. This partially explains the sensitivity in the presence of task-irrelevant variations. We also consider a state-of-the-art tabular foundation model (TabPFN) trained specifically for data fitting. Despite being explicitly designed to achieve prediction robustness, TabPFN is still not immune to task-irrelevant variations. Overall, despite LLMs' impressive predictive capabilities, currently they lack even the basic level of robustness to be used as a principled data-fitting tool. 

**Abstract (ZH)**: 大规模语言模型（LLMs）的应用超越了典型的语言导向用途，在数据拟合和生成预测方面被越来越多地用作即插即用的方法。尽管先前的工作表明，通过上下文学习或监督 fine-tuning，LLMs 在预测性能方面可以与许多表格监督学习技术竞争，但我们发现使用LLMs进行数据拟合的一个关键漏洞——对与底层学习任务完全无关的数据表示进行更改，可能会大幅改变LLMs在相同数据上的预测结果。例如，仅仅更改变量名称就可能在某些情况下使预测误差的大小变化高达82%。这种与任务无关的变异对预测结果的影响，在上下文学习和监督 fine-tuning 下，对于紧密权重和开放权重的通用目的LLMs均存在。此外，通过对开放权重LLM的注意力得分进行分析，我们发现了一个非均匀的注意力模式：提示中恰好占据某些位置的训练示例和变量名/值，在生成输出标记时会受到更多的注意力，尽管不同的位置本应受到大致相同的注意力。这种现象部分解释了在存在任务无关变异时的敏感性。我们还考虑了一个专门用于数据拟合的先进表格基础模型（TabPFN）。尽管明确设计用于实现预测稳健性，TabPFN 仍不免疫于任务无关的变异。总体而言，尽管LLMs在预测能力方面表现出色，但它们目前缺乏甚至是最基本的稳健性水平，不能作为原则性的数据拟合工具使用。 

---
# Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference 

**Title (ZH)**: 驯服混沌：协调扩展以应对异构和 disaggregated 的语言模型推理 

**Authors**: Rongzhi Li, Ruogu Du, Zefang Chu, Sida Zhao, Chunlei Han, Zuocheng Shi, Yiwen Shao, Huanle Han, Long Huang, Zherui Liu, Shufan Liu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19559)  

**Abstract**: Serving Large Language Models (LLMs) is a GPU-intensive task where traditional autoscalers fall short, particularly for modern Prefill-Decode (P/D) disaggregated architectures. This architectural shift, while powerful, introduces significant operational challenges, including inefficient use of heterogeneous hardware, network bottlenecks, and critical imbalances between prefill and decode stages. We introduce HeteroScale, a coordinated autoscaling framework that addresses the core challenges of P/D disaggregated serving. HeteroScale combines a topology-aware scheduler that adapts to heterogeneous hardware and network constraints with a novel metric-driven policy derived from the first large-scale empirical study of autoscaling signals in production. By leveraging a single, robust metric to jointly scale prefill and decode pools, HeteroScale maintains architectural balance while ensuring efficient, adaptive resource management. Deployed in a massive production environment on tens of thousands of GPUs, HeteroScale has proven its effectiveness, increasing average GPU utilization by a significant 26.6 percentage points and saving hundreds of thousands of GPU-hours daily, all while upholding stringent service level objectives. 

**Abstract (ZH)**: 为大型语言模型提供服务是一个GPU密集型任务，传统的自动缩放器在现代Prefill-Decode (P/D) 非聚合架构中表现不佳。这种架构转变虽然强大，但也带来了显著的操作挑战，包括异构硬件的低效利用、网络瓶颈以及.prefill和.Decode阶段之间的重要失衡。我们介绍了HeteroScale，一种协调的自动缩放框架，旨在解决P/D非聚合服务的核心挑战。HeteroScale结合了一个拓扑感知调度器，该调度器能够适应异构硬件和网络约束，并结合了首次大规模生产环境中自动缩放信号的实证研究中得到的新颖的指标驱动策略。通过利用单一稳健的指标同时调整.prefill和.Decode池的规模，HeteroScale维持了架构平衡，确保了高效的、自适应的资源管理。在包含数以万计GPU的大型生产环境中部署，HeteroScale证明了其有效性，平均提高了26.6个百分点的GPU利用率，并每天节省了成千上万小时的GPU时间，同时满足严格的SLA要求。 

---
# Language Models Identify Ambiguities and Exploit Loopholes 

**Title (ZH)**: 语言模型识别歧义并利用漏洞 

**Authors**: Jio Choi, Mohit Bansal, Elias Stengel-Eskin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19546)  

**Abstract**: Studying the responses of large language models (LLMs) to loopholes presents a two-fold opportunity. First, it affords us a lens through which to examine ambiguity and pragmatics in LLMs, since exploiting a loophole requires identifying ambiguity and performing sophisticated pragmatic reasoning. Second, loopholes pose an interesting and novel alignment problem where the model is presented with conflicting goals and can exploit ambiguities to its own advantage. To address these questions, we design scenarios where LLMs are given a goal and an ambiguous user instruction in conflict with the goal, with scenarios covering scalar implicature, structural ambiguities, and power dynamics. We then measure different models' abilities to exploit loopholes to satisfy their given goals as opposed to the goals of the user. We find that both closed-source and stronger open-source models can identify ambiguities and exploit their resulting loopholes, presenting a potential AI safety risk. Our analysis indicates that models which exploit loopholes explicitly identify and reason about both ambiguity and conflicting goals. 

**Abstract (ZH)**: 研究大型语言模型（LLMs）对漏洞的反应提供了双重机会。首先，这为我们提供了研究LLMs中的含糊性和语用性的视角，因为利用漏洞需要识别含糊性和进行复杂的语用推理。其次，漏洞提出了一个有趣且新颖的对齐问题，其中模型面对冲突的目标，并可通过利用含糊性来实现自身优势。为了解决这些问题，我们设计了场景，在这些场景中，LLMs被赋予一个目标和一个与其目标冲突的含糊用户指令，场景涵盖了强度隐含意义、结构含糊性和权力动态。然后，我们测量了不同模型利用漏洞满足其目标而非用户目标的能力。我们发现，无论是闭源还是更强的开源模型都能识别含糊性并利用其产生的漏洞，这提出了潜在的人工智能安全风险。我们的分析表明，利用漏洞的模型明确识别并处理了含糊性和冲突目标。 

---
# WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization 

**Title (ZH)**: WEBEYETRACK：基于设备端少量样本个性化的眼动追踪浏览器扩展 

**Authors**: Eduardo Davalos, Yike Zhang, Namrata Srivastava, Yashvitha Thatigotla, Jorge A. Salas, Sara McFadden, Sun-Joo Cho, Amanda Goodwin, Ashwin TS, Gautam Biswas  

**Link**: [PDF](https://arxiv.org/pdf/2508.19544)  

**Abstract**: With advancements in AI, new gaze estimation methods are exceeding state-of-the-art (SOTA) benchmarks, but their real-world application reveals a gap with commercial eye-tracking solutions. Factors like model size, inference time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking methods lack sufficient accuracy, in particular due to head movement. To tackle these issues, we introduce We bEyeTrack, a framework that integrates lightweight SOTA gaze estimation models directly in the browser. It incorporates model-based head pose estimation and on-device few-shot learning with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new users, achieving SOTA performance with an error margin of 2.32 cm on GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14. Our open-source code is available at this https URL. 

**Abstract (ZH)**: 基于AI的眼球估计方法取得了显著进展，但其实用应用暴露出与商用眼动追踪解决方案之间的差距。因素如模型尺寸、推理时间和隐私往往被忽视。与此同时，基于网络摄像头的眼动追踪方法由于头部运动缺乏足够的准确性。为了应对这些问题，我们引入了WebEyeTrack框架，该框架直接在浏览器中集成轻量级的先进技术的眼球估计模型。它结合了基于模型的头部姿态估计和设备端的少量样本学习，所需校准样本数少于9个。WebEyeTrack能够适应新用户，在GazeCapture上的误差 margin 为2.32 cm，并在iPhone 14上实现实时推理速度为2.4毫秒。我们的开源代码可在以下链接获取。 

---
# Orchid: Orchestrating Context Across Creative Workflows with Generative AI 

**Title (ZH)**: Orchid: 以生成式AI orchestrating 跨创意工作流的上下文 

**Authors**: Srishti Palani, Gonzalo Ramos  

**Link**: [PDF](https://arxiv.org/pdf/2508.19517)  

**Abstract**: Context is critical for meaningful interactions between people and Generative AI (GenAI). Yet mainstream tools offer limited means to orchestrate it, particularly across workflows that span multiple interactions, sessions, and models, as often occurs in creative projects. Re specifying prior details, juggling diverse artifacts, and dealing with context drift overwhelm users, obscure intent, and curtail creativity. To address these challenges, we present Orchid, a system that gives its users affordances to specify, reference, and monitor context throughout evolving workflows. Specifically, Orchid enables users to (1) specify context related to the project, themselves, and different styles, (2) reference these via explicit mentions, inline selection, or implicit grounding, and (3) monitor context assigned to different interactions across the workflow. In a within-subjects study (n=12), participants using Orchid to execute creative tasks (compared to a baseline toolkit of web search, LLM-based chat, and digital notebooks) produced more novel and feasible outcomes, reporting greater alignment between their intent and the AI's responses, higher perceived control, and increased transparency. By prioritizing context orchestration, Orchid offers an actionable step toward next generation GenAI tools that support complex, iterative workflows - enabling creators and AI to stay aligned and augment their creative potential. 

**Abstract (ZH)**: Context对人类与生成式AI有意义的交互至关重要。然而，主流工具在跨多个交互、会话和模型的 workflows 中协调 Context 的能力有限。重新指定先前的详细信息、处理多样化的 artefacts 及应对 Context 游移令用户不堪重负，模糊了意图并抑制了创造力。为应对这些挑战，我们提出了 Orchid 系统，该系统为用户提供在整个 evolving workflows 中指定、引用和监控 Context 的功能。具体来说，Orchid 允许用户（1）指定与项目、自身及不同风格相关的 Context，（2）通过明确提及、内联选择或隐式关联来引用这些 Context，以及（3）监控 workflow 中不同交互分配的 Context。在一项单被试设计的研究（n=12）中，与使用基于 web 搜索、LLM 基础的聊天及数字笔记的基线工具包相比，使用 Orchid 执行创造性任务的参与者产生了更多新颖且可行的结果，报告了更高的意图与 AI 反应的对齐度、更高的感知控制感及更大的透明度。通过优先考虑 Context 的协调，Orchid 提供了一个有意义的步骤，迈向支持复杂迭代 workflows 的下一代生成式 AI 工具，使创造者和 AI 能够保持一致并增强其创造力。 

---
# A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation 

**Title (ZH)**: 一种自我监督的 Experts 混合框架用于多行为推荐 

**Authors**: Kyungho Kim, Sunwoo Kim, Geon Lee, Kijung Shin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19507)  

**Abstract**: In e-commerce, where users face a vast array of possible item choices, recommender systems are vital for helping them discover suitable items they might otherwise overlook. While many recommender systems primarily rely on a user's purchase history, recent multi-behavior recommender systems incorporate various auxiliary user behaviors, such as item clicks and cart additions, to enhance recommendations. Despite their overall performance gains, their effectiveness varies considerably between visited items (i.e., those a user has interacted with through auxiliary behaviors) and unvisited items (i.e., those with which the user has had no such interactions). Specifically, our analysis reveals that (1) existing multi-behavior recommender systems exhibit a significant gap in recommendation quality between the two item types (visited and unvisited items) and (2) achieving strong performance on both types with a single model architecture remains challenging. To tackle these issues, we propose a novel multi-behavior recommender system, MEMBER. It employs a mixture-of-experts framework, with experts designed to recommend the two item types, respectively. Each expert is trained using a self-supervised method specialized for its design goal. In our comprehensive experiments, we show the effectiveness of MEMBER across both item types, achieving up to 65.46\% performance gain over the best competitor in terms of Hit Ratio@20. 

**Abstract (ZH)**: 电子商务中，面对大量商品选择，推荐系统对于帮助用户发现潜在感兴趣的物品至关重要。尽管许多推荐系统主要依赖用户的购买历史，最近的多行为推荐系统通过纳入诸如item点击和加入购物车等辅助用户行为来提升推荐效果。尽管在总体性能上有所提升，但这些系统的有效性在已访问物品（即用户通过辅助行为与之交互的物品）和未访问物品（即未与用户产生此类交互的物品）之间存在显著差异。具体而言，我们的分析表明（1）现有的多行为推荐系统在已访问物品和未访问物品上的推荐质量存在显著差距；（2）同时在一个模型架构上实现两种物品类型的高性能仍然具有挑战性。为解决这些问题，我们提出了一种新的多行为推荐系统MEMBER。MEMBER采用混合专家框架，针对两种类型的物品分别设计专家进行推荐。每个专家使用为其设计目标量身定制的自监督方法进行训练。在我们全面的实验中，MEMBER在两种物品类型上均表现出色，相对于最佳竞争对手，在命中率@20上实现了高达65.46%的性能提升。 

---
# Learning Game-Playing Agents with Generative Code Optimization 

**Title (ZH)**: 使用生成式代码优化学习游戏代理 

**Authors**: Zhiyi Kuang, Ryan Rong, YuCheng Yuan, Allen Nie  

**Link**: [PDF](https://arxiv.org/pdf/2508.19506)  

**Abstract**: We present a generative optimization approach for learning game-playing agents, where policies are represented as Python programs and refined using large language models (LLMs). Our method treats decision-making policies as self-evolving code, with current observation as input and an in-game action as output, enabling agents to self-improve through execution traces and natural language feedback with minimal human intervention. Applied to Atari games, our game-playing Python program achieves performance competitive with deep reinforcement learning (RL) baselines while using significantly less training time and much fewer environment interactions. This work highlights the promise of programmatic policy representations for building efficient, adaptable agents capable of complex, long-horizon reasoning. 

**Abstract (ZH)**: 基于生成优化的游戏玩牌代理学习方法：Python程序表示与大规模语言模型的政策精炼 

---
# Servant, Stalker, Predator: How An Honest, Helpful, And Harmless (3H) Agent Unlocks Adversarial Skills 

**Title (ZH)**: 仆人、跟踪者、猎手：一个诚实、乐于助人且无害（3H）代理如何解锁对抗性技能 

**Authors**: David Noever  

**Link**: [PDF](https://arxiv.org/pdf/2508.19500)  

**Abstract**: This paper identifies and analyzes a novel vulnerability class in Model Context Protocol (MCP) based agent systems. The attack chain describes and demonstrates how benign, individually authorized tasks can be orchestrated to produce harmful emergent behaviors. Through systematic analysis using the MITRE ATLAS framework, we demonstrate how 95 agents tested with access to multiple services-including browser automation, financial analysis, location tracking, and code deployment-can chain legitimate operations into sophisticated attack sequences that extend beyond the security boundaries of any individual service. These red team exercises survey whether current MCP architectures lack cross-domain security measures necessary to detect or prevent a large category of compositional attacks. We present empirical evidence of specific attack chains that achieve targeted harm through service orchestration, including data exfiltration, financial manipulation, and infrastructure compromise. These findings reveal that the fundamental security assumption of service isolation fails when agents can coordinate actions across multiple domains, creating an exponential attack surface that grows with each additional capability. This research provides a barebones experimental framework that evaluate not whether agents can complete MCP benchmark tasks, but what happens when they complete them too well and optimize across multiple services in ways that violate human expectations and safety constraints. We propose three concrete experimental directions using the existing MCP benchmark suite. 

**Abstract (ZH)**: 基于Model Context Protocol (MCP)代理系统的新型漏洞类别的识别与分析 

---
# Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery 

**Title (ZH)**: Sat2Flow：一种基于结构意识的卫星图像人体流动生成扩散框架 

**Authors**: Xiangxu Wang, Tianhong Zhao, Wei Tu, Bowen Zhang, Guanzhou Chen, Jinzhou Cao  

**Link**: [PDF](https://arxiv.org/pdf/2508.19499)  

**Abstract**: Origin-Destination (OD) flow matrices are essential for urban mobility analysis, underpinning applications in traffic forecasting, infrastructure planning, and policy design. However, existing methods suffer from two critical limitations: (1) reliance on auxiliary features (e.g., Points of Interest, socioeconomic statistics) that are costly to collect and have limited spatial coverage; and (2) sensitivity to spatial topology, where minor index reordering of urban regions (e.g., census tract relabeling) disrupts structural coherence in generated flows. To address these challenges, we propose Sat2Flow, a latent structure-aware diffusion-based framework that generates structurally coherent OD flows using solely satellite imagery as input. Our approach introduces a multi-kernel encoder to capture diverse regional interactions and employs a permutation-aware diffusion process that aligns latent representations across different regional orderings. Through a joint contrastive training objective that bridges satellite-derived features with OD patterns, combined with equivariant diffusion training that enforces structural consistency, Sat2Flow ensures topological robustness under arbitrary regional reindexing. Experimental results on real-world urban datasets demonstrate that Sat2Flow outperforms both physics-based and data-driven baselines in numerical accuracy while preserving empirical distributions and spatial structures under index permutations. Sat2Flow offers a globally scalable solution for OD flow generation in data-scarce urban environments, eliminating region-specific auxiliary data dependencies while maintaining structural invariance for robust mobility modeling. 

**Abstract (ZH)**: 基于卫星影像的latent结构意识扩散框架Sat2Flow：解决OD流生成中的地域重构问题 

---
# PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense 

**Title (ZH)**: PoolFlip: 一种用于网络防御的多agent强化学习安全环境 

**Authors**: Xavier Cadet, Simona Boboila, Sie Hendrata Dharmawan, Alina Oprea, Peter Chin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19488)  

**Abstract**: Cyber defense requires automating defensive decision-making under stealthy, deceptive, and continuously evolving adversarial strategies. The FlipIt game provides a foundational framework for modeling interactions between a defender and an advanced adversary that compromises a system without being immediately detected. In FlipIt, the attacker and defender compete to control a shared resource by performing a Flip action and paying a cost. However, the existing FlipIt frameworks rely on a small number of heuristics or specialized learning techniques, which can lead to brittleness and the inability to adapt to new attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym environment that extends the FlipIt game to allow efficient learning for attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent reinforcement learning (MARL) approach that leverages population-based training to train defender agents equipped to generalize against a range of unknown, potentially adaptive opponents. Our empirical results suggest that Flip-PSRO defenders are $2\times$ more effective than baselines to generalize to a heuristic attack not exposed in training. In addition, our newly designed ownership-based utility functions ensure that Flip-PSRO defenders maintain a high level of control while optimizing performance. 

**Abstract (ZH)**: 针对隐形、欺骗性和持续演变的对手策略的自动化防御决策要求网络防御需升级。FlipIt游戏提供了建模防御者与高级对手之间交互的基础框架，该对手会隐蔽地侵袭系统而不立即被发现。在FlipIt中，攻击者和防御者通过执行“翻转”动作争夺共享资源，并为此支付成本。然而，现有的FlipIt框架依赖少量启发式或专业学习技术，这可能导致防御系统的脆弱性和无法适应新威胁。为克服这些限制，我们引入了PoolFlip，一种多智能体学习环境，它可以扩展FlipIt游戏，以实现攻击者和防御者之间的高效学习。此外，我们提出了Flip-PSRO，一种多智能体强化学习（MARL）方法，利用基于群体的训练来训练能够泛化对抗一系列未知且可能适应对手的防御代理。我们的实证结果表明，Flip-PSRO防御者比基线方法更有效地泛化至未在训练中暴露的启发式攻击。此外，我们新设计的所有权为基础的效用函数确保Flip-PSRO防御者在优化性能的同时保持高度的控制能力。 

---
# Data-Efficient Symbolic Regression via Foundation Model Distillation 

**Title (ZH)**: 基于基础模型精炼的高效符号回归 

**Authors**: Wangyang Ying, Jinghan Zhang, Haoyue Bai, Nanxu Gong, Xinyuan Wang, Kunpeng Liu, Chandan K. Reddy, Yanjie Fu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19487)  

**Abstract**: Discovering interpretable mathematical equations from observed data (a.k.a. equation discovery or symbolic regression) is a cornerstone of scientific discovery, enabling transparent modeling of physical, biological, and economic systems. While foundation models pre-trained on large-scale equation datasets offer a promising starting point, they often suffer from negative transfer and poor generalization when applied to small, domain-specific datasets. In this paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer Embeddings), a data-efficient fine-tuning framework that adapts foundation models for symbolic equation discovery in low-data regimes via distillation. EQUATE combines symbolic-numeric alignment with evaluator-guided embedding optimization, enabling a principled embedding-search-generation paradigm. Our approach reformulates discrete equation search as a continuous optimization task in a shared embedding space, guided by data-equation fitness and simplicity. Experiments across three standard public benchmarks (Feynman, Strogatz, and black-box datasets) demonstrate that EQUATE consistently outperforms state-of-the-art baselines in both accuracy and robustness, while preserving low complexity and fast inference. These results highlight EQUATE as a practical and generalizable solution for data-efficient symbolic regression in foundation model distillation settings. 

**Abstract (ZH)**: 从观测数据中发现可解释的数学方程（又称方程发现或符号回归）是科学发现的基础，能够透明地建模物理、生物和经济系统。尽管预训练在大规模方程数据集上的基础模型为这一任务提供了前景，但在应用于小规模的领域特定数据集时，它们往往会出现负迁移和泛化能力差的问题。在本文中，我们提出了EQUATE（通过质量对齐转移嵌入进行方程生成），这是一种数据高效微调框架，通过蒸馏适应基础模型在低数据量情况下的符号方程发现。EQUATE结合了符号-数值对齐与评估器引导嵌入优化，使得在共享嵌入空间中实现有原则的嵌入-搜索-生成范式成为可能。我们的方法将离散方程搜索重新表述为在共享嵌入空间中连续优化任务，并受到数据-方程适应度和简洁性的指导。在三个标准公开基准（Feynman、Strogatz和黑盒数据集）上的实验结果证明，EQUATE在准确性和鲁棒性上始终优于最先进的基线方法，同时保持低复杂性和快速推理。这些结果突显了EQUATE在基础模型蒸馏设置中高效符号回归的一种实用且可推广的解决方案。 

---
# Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study 

**Title (ZH)**: 基于词典引导微调和强化学习的低资源翻译改进：一项从西班牙语到Wayuunaiki的研究 

**Authors**: Manuel Mosquera, Melissa Robles, Johan Rodriguez, Ruben Manrique  

**Link**: [PDF](https://arxiv.org/pdf/2508.19481)  

**Abstract**: Low-resource machine translation remains a significant challenge for large language models (LLMs), which often lack exposure to these languages during pretraining and have limited parallel data for fine-tuning. We propose a novel approach that enhances translation for low-resource languages by integrating an external dictionary tool and training models end-to-end using reinforcement learning, in addition to supervised fine-tuning. Focusing on the Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented decision-making problem in which the model can selectively consult a bilingual dictionary during generation. Our method combines supervised instruction tuning with Guided Reward Policy Optimization (GRPO), enabling the model to learn both when and how to use the tool effectively. BLEU similarity scores are used as rewards to guide this learning process. Preliminary results show that our tool-augmented models achieve up to +3.37 BLEU improvement over previous work, and a 18% relative gain compared to a supervised baseline without dictionary access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared Task. We also conduct ablation studies to assess the effects of model architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other models such as LLaMA and a prior NLLB-based system. These findings highlight the promise of combining LLMs with external tools and the role of reinforcement learning in improving translation quality in low-resource language settings. 

**Abstract (ZH)**: 低资源机器翻译仍是对大型语言模型（LLMs）的一个重大挑战，它们在预训练阶段往往缺乏对这些语言的接触，且可用于微调的并行数据有限。我们提出了一种新型方法，通过集成外部词典工具，并结合强化学习和监督微调端到端训练模型，以增强低资源语言的翻译能力。以西班牙语-韦尤纳伊基语对为例，我们将翻译问题框架化为一种工具增强的决策问题，模型在生成过程中可以有选择地查阅双语词典。该方法结合了监督指令微调和引导奖励策略优化（GRPO），使模型能够学习何时及如何有效使用工具。使用BLEU相似性分数作为奖励，引导这一学习过程。初步结果显示，与之前的工作相比，我们的工具增强模型在美洲NLP 2025共享任务的西班牙语-韦尤纳伊基语测试集上实现了最高3.37的BLEU改善，相对于一个无词典访问的监督基线，相对增益高达18%。我们还进行了消融研究，评估了模型架构和训练策略的影响，并将Qwen2.5-0.5B-Instruct与LLaMA和其他基于NLLB的系统进行了比较。这些发现突显了将大型语言模型与外部工具结合的潜力，以及强化学习在低资源语言翻译质量改进中的作用。 

---
# Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage 

**Title (ZH)**: 基于广播 footage 的计算机视觉人工智能球员跟踪软件的 concurrent validity 

**Authors**: Zachary L. Crang, Rich D. Johnston, Katie L. Mills, Johsan Billingham, Sam Robertson, Michael H. Cole, Jonathon Weakley, Adam Hewitt and, Grant M. Duthie  

**Link**: [PDF](https://arxiv.org/pdf/2508.19477)  

**Abstract**: This study aimed to: (1) understand whether commercially available computer-vision and artificial intelligence (AI) player tracking software can accurately measure player position, speed and distance using broadcast footage and (2) determine the impact of camera feed and resolution on accuracy. Data were obtained from one match at the 2022 Qatar Federation Internationale de Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds were used. Three commercial tracking providers that use computer-vision and AI participated. Providers analysed instantaneous position (x, y coordinates) and speed (m\,s^{-1}) of each player. Their data were compared with a high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to 16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across providers. Computer-vision and AI player tracking software offer the ability to track players with fair precision when players are detected by the software. Providers should use a tactical feed when tracking position and speed, which will maximise player detection, improving accuracy. Both 720p and 1080p resolutions are suitable, assuming appropriate computer-vision and AI models are implemented. 

**Abstract (ZH)**: 本研究旨在：（1）了解商用计算机视觉和人工智能（AI）球员追踪软件是否能够精确测量球员位置、速度和距离，使用的是转播 footage；（2）确定摄像机信号和分辨率对准确度的影响。数据来自2022年卡塔尔国际足球协会（FIFA）世界杯一场比赛。战术、节目和摄像机1信号被使用。三家使用计算机视觉和AI的商用追踪提供商参与其中。提供商分析了每位球员的即时位置（x、y坐标）和速度（m\s^{-1}）。随后将他们的数据与高清多摄像机追踪系统（TRACAB Gen 5）的数据进行了比较，计算了均方根误差（RMSE）和平均偏差。位置RMSE范围从1.68米到16.39米，速度RMSE范围从0.34米/秒到2.38米/秒。平均每场比赛距离的平均偏差范围从-1745米（-21.8%）到1945米（24.3%）不等。计算机视觉和AI球员追踪软件能够在软件检测到球员的情况下提供合理的追踪精度。提供商在追踪位置和速度时应使用战术信号，这将最大化球员检测，从而提高准确性。720p和1080p分辨率均适用，前提是使用适当的计算机视觉和AI模型。 

---
# Automatic Question & Answer Generation Using Generative Large Language Model (LLM) 

**Title (ZH)**: 基于生成型大型语言模型的自动问题与答案生成 

**Authors**: Md. Alvee Ehsan, A.S.M Mehedi Hasan, Kefaya Benta Shahnoor, Syeda Sumaiya Tasneem  

**Link**: [PDF](https://arxiv.org/pdf/2508.19475)  

**Abstract**: \Abstract{In the realm of education, student evaluation holds equal significance as imparting knowledge. To be evaluated, students usually need to go through text-based academic assessment methods. Instructors need to make diverse sets of questions that need to be fair for all students to prove their adequacy over a particular topic. This can prove to be quite challenging as they may need to manually go through several different lecture materials. Our objective is to make this whole process much easier by implementing Automatic Question Answer Generation /(AQAG), using fine-tuned generative LLM. For tailoring the instructor's preferred question style (MCQ, conceptual, or factual questions), prompt Engineering (PE) is being utilized. In this research, we propose to leverage unsupervised learning methods in NLP, primarily focusing on the English language. This approach empowers the base Meta-Llama 2-7B model to integrate RACE dataset as training data for the fine-tuning process. Creating a customized model that will offer efficient solutions for educators, instructors, and individuals engaged in text-based evaluations. A reliable and efficient tool for generating questions and answers can free up valuable time and resources, thus streamlining their evaluation processes.} 

**Abstract (ZH)**: 自动问答生成在教育评估中的应用：利用未监督学习方法生成英语文本题库 

---
# SIExVulTS: Sensitive Information Exposure Vulnerability Detection System using Transformer Models and Static Analysis 

**Title (ZH)**: SIExVulTS：基于变压器模型和静态分析的敏感信息暴露漏洞检测系统 

**Authors**: Kyler Katz, Sara Moshtari, Ibrahim Mujhid, Mehdi Mirakhorli, Derek Garcia  

**Link**: [PDF](https://arxiv.org/pdf/2508.19472)  

**Abstract**: Sensitive Information Exposure (SIEx) vulnerabilities (CWE-200) remain a persistent and under-addressed threat across software systems, often leading to serious security breaches. Existing detection tools rarely target the diverse subcategories of CWE-200 or provide context-aware analysis of code-level data flows.
Aims: This paper aims to present SIExVulTS, a novel vulnerability detection system that integrates transformer-based models with static analysis to identify and verify sensitive information exposure in Java applications.
Method: SIExVulTS employs a three-stage architecture: (1) an Attack Surface Detection Engine that uses sentence embeddings to identify sensitive variables, strings, comments, and sinks; (2) an Exposure Analysis Engine that instantiates CodeQL queries aligned with the CWE-200 hierarchy; and (3) a Flow Verification Engine that leverages GraphCodeBERT to semantically validate source-to-sink flows. We evaluate SIExVulTS using three curated datasets, including real-world CVEs, a benchmark set of synthetic CWE-200 examples, and labeled flows from 31 open-source projects.
Results: The Attack Surface Detection Engine achieved an average F1 score greater than 93\%, the Exposure Analysis Engine achieved an F1 score of 85.71\%, and the Flow Verification Engine increased precision from 22.61\% to 87.23\%. Moreover, SIExVulTS successfully uncovered six previously unknown CVEs in major Apache projects.
Conclusions: The results demonstrate that SIExVulTS is effective and practical for improving software security against sensitive data exposure, addressing limitations of existing tools in detecting and verifying CWE-200 vulnerabilities. 

**Abstract (ZH)**: Sensitive Information Exposure (SIEx) 漏洞 (CWE-200) 仍然是软件系统中一个持续存在的且未充分应对的安全威胁，经常导致严重的安全泄露。现有的检测工具很少针对 CWE-200 的多样子类别，或是在代码级数据流分析中提供上下文感知。

目的：本文旨在介绍结合基于变换器的模型与静态分析以识别和验证 Java 应用中敏感信息暴露的新型漏洞检测系统 SIExVulTS。

方法：SIExVulTS 采用三阶段架构：（1）攻击面检测引擎，使用句子嵌入来识别敏感变量、字符串、注释和漏洞点；（2）暴露分析引擎，实例化与 CWE-200 分层结构对齐的 CodeQL 查询；（3）流动验证引擎，利用 GraphCodeBERT 语义验证源到漏点的流动。我们使用三个定制数据集评估 SIExVulTS，包括实际的 CVE、基准集中的合成 CWE-200 示例以及 31 个开源项目中的标记流动。

结果：攻击面检测引擎的平均 F1 分数高于 93%，暴露分析引擎的 F1 分数为 85.71%，流动验证引擎将精准度从 22.61% 提高到 87.23%。此外，SIExVulTS 成功发现了六个主要 Apache 项目的未知 CVE。

结论：结果表明，SIExVulTS 对于提高软件对敏感数据暴露的安全性是有效的且实际的，解决了现有工具在检测和验证 CWE-200 漏洞方面的局限性。 

---
# Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset 

**Title (ZH)**: 领域专家知识与机器智能在命名实体识别中的推断差距：一种与物质使用相关数据集的创建与见解 

**Authors**: Sumon Kanti Dey, Jeanne M. Powell, Azra Ismail, Jeanmarie Perrone, Abeed Sarker  

**Link**: [PDF](https://arxiv.org/pdf/2508.19467)  

**Abstract**: Nonmedical opioid use is an urgent public health challenge, with far-reaching clinical and social consequences that are often underreported in traditional healthcare settings. Social media platforms, where individuals candidly share first-person experiences, offer a valuable yet underutilized source of insight into these impacts. In this study, we present a named entity recognition (NER) framework to extract two categories of self-reported consequences from social media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal, depression) and SocialImpacts (e.g., job loss). To support this task, we introduce RedditImpacts 2.0, a high-quality dataset with refined annotation guidelines and a focus on first-person disclosures, addressing key limitations of prior work. We evaluate both fine-tuned encoder-based models and state-of-the-art large language models (LLMs) under zero- and few-shot in-context learning settings. Our fine-tuned DeBERTa-large model achieves a relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming LLMs in precision, span accuracy, and adherence to task-specific guidelines. Furthermore, we show that strong NER performance can be achieved with substantially less labeled data, emphasizing the feasibility of deploying robust models in resource-limited settings. Our findings underscore the value of domain-specific fine-tuning for clinical NLP tasks and contribute to the responsible development of AI tools that may enhance addiction surveillance, improve interpretability, and support real-world healthcare decision-making. The best performing model, however, still significantly underperforms compared to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap persists between expert intelligence and current state-of-the-art NER/AI capabilities for tasks requiring deep domain knowledge. 

**Abstract (ZH)**: 非医疗用途阿片类药物使用是迫切的公共卫生挑战，其广泛的临床和社会后果在传统医疗保健环境中常被低估。社交媒体平台，个人在这里坦诚分享第一人称经历，提供了有价值的但尚未充分利用的洞察来源。本研究提出了一种命名实体识别（NER）框架，用于从与阿片类药物使用相关的社交媒体叙述中提取两类自我报告的后果：临床影响（如戒断、抑郁）和社会影响（如失业）。为支持这一任务，我们引入了RedditImpacts 2.0，这是一个高质量的数据集，具有改进的标注指南，重点关注第一人称披露，解决了先前工作中的关键局限性。我们在零样本和少量样本的上下文学习设置中评估了微调编码器模型和最先进的大规模语言模型（LLMs）。我们的微调DeBERTa-large模型在放松的令牌级别F1上达到0.61 [95% CI: 0.43-0.62]，在精确度、跨度准确性和遵循特定任务指南方面始终优于LLMs。此外，我们展示了在几乎少得多的标注数据下仍可实现强大的NER性能，强调即使在资源限制环境中部署鲁棒模型的可行性。我们的研究结果强调了针对临床NLP任务进行领域特定微调的价值，并为负责任开发能够增强成瘾监测、提高解释性和支持实际医疗保健决策的人工智能工具做出了贡献。然而，表现最好的模型在专家间一致性（科恩κ：0.81）方面仍显著落后，这表明在需要深厚领域知识的任务中，专家智能与当前最先进的NER/AI能力之间仍存在差距。 

---
# Incentivized Lipschitz Bandits 

**Title (ZH)**: 激励性LipschitzBandits 

**Authors**: Sourav Chakraborty, Amit Kiran Rege, Claire Monteleoni, Lijun Chen  

**Link**: [PDF](https://arxiv.org/pdf/2508.19466)  

**Abstract**: We study incentivized exploration in multi-armed bandit (MAB) settings with infinitely many arms modeled as elements in continuous metric spaces. Unlike classical bandit models, we consider scenarios where the decision-maker (principal) incentivizes myopic agents to explore beyond their greedy choices through compensation, but with the complication of reward drift--biased feedback arising due to the incentives. We propose novel incentivized exploration algorithms that discretize the infinite arm space uniformly and demonstrate that these algorithms simultaneously achieve sublinear cumulative regret and sublinear total compensation. Specifically, we derive regret and compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the covering dimension of the metric space. Furthermore, we generalize our results to contextual bandits, achieving comparable performance guarantees. We validate our theoretical findings through numerical simulations. 

**Abstract (ZH)**: 我们在连续度量空间中无限多臂的多臂bandit设置中研究激励型探索，其中决策者通过补偿激励短视代理超越贪心选择进行探索，同时考虑奖励漂移的复杂性。我们提出了新颖的激励型探索算法，将无限臂空间均匀离散化，并证明这些算法能够同时实现亚线性累积后悔和亚线性总补偿。具体地，我们推导出后悔和补偿的界限为$\Tilde{O}(T^{d+1/d+2})$，其中$d$表示度量空间的覆盖维度。此外，我们将结果推广到上下文bandit，实现类似的良好性能保证。我们通过数值模拟验证了理论发现。 

---
# Addressing Weak Authentication like RFID, NFC in EVs and EVCs using AI-powered Adaptive Authentication 

**Title (ZH)**: 使用AI驱动的自适应认证解决电动汽车和电动车辆中弱认证问题（如RFID、NFC） 

**Authors**: Onyinye Okoye  

**Link**: [PDF](https://arxiv.org/pdf/2508.19465)  

**Abstract**: The rapid expansion of the Electric Vehicles (EVs) and Electric Vehicle Charging Systems (EVCs) has introduced new cybersecurity challenges, specifically in authentication protocols that protect vehicles, users, and energy infrastructure. Although widely adopted for convenience, traditional authentication mechanisms like Radio Frequency Identification (RFID) and Near Field Communication (NFC) rely on static identifiers and weak encryption, making them highly vulnerable to attack vectors such as cloning, relay attacks, and signal interception. This study explores an AI-powered adaptive authentication framework designed to overcome these shortcomings by integrating machine learning, anomaly detection, behavioral analytics, and contextual risk assessment. Grounded in the principles of Zero Trust Architecture, the proposed framework emphasizes continuous verification, least privilege access, and secure communication. Through a comprehensive literature review, this research evaluates current vulnerabilities and highlights AI-driven solutions to provide a scalable, resilient, and proactive defense. Ultimately, the research findings conclude that adopting AI-powered adaptive authentication is a strategic imperative for securing the future of electric mobility and strengthening digital trust across the ecosystem. Keywords: weak authentication, RFID, NFC, ML, AI-powered adaptive authentication, relay attacks, cloning, eavesdropping, MITM attacks, Zero Trust Architecture 

**Abstract (ZH)**: 电动汽车（EVs）和电动汽车充电系统（EVCs）的快速扩张引入了新的网络安全挑战，特别是在保护车辆、用户和能源基础设施的身份认证协议方面。尽管传统身份认证机制如射频识别（RFID）和近场通信（NFC）因其便捷性而广泛应用，但它们依赖于静态标识符和弱加密，使其极易受到仿冒、中继攻击和信号拦截等攻击向量的威胁。本研究探讨了一种基于人工智能的强大适应性认证框架，该框架通过集成机器学习、异常检测、行为分析和上下文风险评估来克服这些不足。该框架基于零信任架构的原则，强调持续验证、最小权限访问和安全通信。通过全面的文献综述，本研究评估了当前的安全漏洞，并强调人工智能驱动的解决方案，以提供可扩展、 resilient和积极主动的防御。最终，研究结果表明，采用人工智能驱动的适应性认证是确保电动汽车未来安全并增强整个生态系统中数字信任的战略性要求。关键词：弱认证、RFID、NFC、机器学习（ML）、人工智能驱动的适应性认证、中继攻击、仿冒、窃听、中间人攻击（MITM）、零信任架构。 

---
# Bridging Language Gaps: Enhancing Few-Shot Language Adaptation 

**Title (ZH)**: 跨越语言障碍：增强少-shot语言适应性 

**Authors**: Philipp Borchert, Jochen De Weerdt, Marie-Francine Moens  

**Link**: [PDF](https://arxiv.org/pdf/2508.19464)  

**Abstract**: The disparity in language resources poses a challenge in multilingual NLP, with high-resource languages benefiting from extensive data, while low-resource languages lack sufficient data for effective training. Our Contrastive Language Alignment with Prompting (CoLAP) method addresses this gap by integrating contrastive learning with cross-lingual representations, facilitating task-specific knowledge transfer from high-resource to lower-resource languages. The primary advantage of our approach is its data efficiency, enabling rapid adaptation to new languages and reducing the need for large labeled datasets. We conduct experiments with multilingual encoder-only and decoder-only language models on natural language understanding tasks, including natural language inference and relation extraction, evaluating performance across both high- and low-resource languages. Our results demonstrate that CoLAP outperforms few-shot cross-lingual transfer baselines and in-context learning, even with limited available data. This effectively narrows the cross-lingual performance gap, contributing to the development of more efficient multilingual NLP techniques. 

**Abstract (ZH)**: 语言资源的差距给多语言NLP带来了挑战，高资源语言受益于大量数据，而低资源语言缺乏有效训练所需的数据。我们的对比语言对齐与提示（CoLAP）方法通过将对比学习与跨语言表示结合，促进高资源语言知识向低资源语言的特定任务迁移。我们方法的主要优势在于其数据效率，能够快速适应新语言并减少对大量标注数据的依赖。我们在自然语言理解任务（包括自然语言推理和关系抽取）上对多语言编码器和解码器模型进行了实验，评估了高资源和低资源语言的性能。实验结果表明，CoLAP在有限数据情况下优于少量样本跨语言迁移学习基线和上下文学习方法，有效地缩小了跨语言性能差距，促进了更高效多语言NLP技术的发展。 

---
# "She was useful, but a bit too optimistic": Augmenting Design with Interactive Virtual Personas 

**Title (ZH)**: 她有用，但有点过于乐观：增强设计与交互式虚拟角色相结合 

**Authors**: Paluck Deep, Monica Bharadhidasan, A. Baki Kocaballi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19463)  

**Abstract**: Personas have been widely used to understand and communicate user needs in human-centred design. Despite their utility, they may fail to meet the demands of iterative workflows due to their static nature, limited engagement, and inability to adapt to evolving design needs. Recent advances in large language models (LLMs) pave the way for more engaging and adaptive approaches to user representation. This paper introduces Interactive Virtual Personas (IVPs): multimodal, LLM-driven, conversational user simulations that designers can interview, brainstorm with, and gather feedback from in real time via voice interface. We conducted a qualitative study with eight professional UX designers, employing an IVP named "Alice" across three design activities: user research, ideation, and prototype evaluation. Our findings demonstrate the potential of IVPs to expedite information gathering, inspire design solutions, and provide rapid user-like feedback. However, designers raised concerns about biases, over-optimism, the challenge of ensuring authenticity without real stakeholder input, and the inability of the IVP to fully replicate the nuances of human interaction. Our participants emphasised that IVPs should be viewed as a complement to, not a replacement for, real user engagement. We discuss strategies for prompt engineering, human-in-the-loop integration, and ethical considerations for effective and responsible IVP use in design. Finally, our work contributes to the growing body of research on generative AI in the design process by providing insights into UX designers' experiences of LLM-powered interactive personas. 

**Abstract (ZH)**: 基于大规模语言模型的交互虚拟人物在用户体验设计中的应用研究 

---
# Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models 

**Title (ZH)**: 面向计算机模型系统识别的数据增强少量样本神经模板仿真 

**Authors**: Sanket Jantre, Deepak Akhare, Xiaoning Qian, Nathan M. Urban  

**Link**: [PDF](https://arxiv.org/pdf/2508.19441)  

**Abstract**: Partial differential equations (PDEs) underpin the modeling of many natural and engineered systems. It can be convenient to express such models as neural PDEs rather than using traditional numerical PDE solvers by replacing part or all of the PDE's governing equations with a neural network representation. Neural PDEs are often easier to differentiate, linearize, reduce, or use for uncertainty quantification than the original numerical solver. They are usually trained on solution trajectories obtained by long time integration of the PDE solver. Here we propose a more sample-efficient data-augmentation strategy for generating neural PDE training data from a computer model by space-filling sampling of local "stencil" states. This approach removes a large degree of spatiotemporal redundancy present in trajectory data and oversamples states that may be rarely visited but help the neural PDE generalize across the state space. We demonstrate that accurate neural PDE stencil operators can be learned from synthetic training data generated by the computational equivalent of 10 timesteps' worth of numerical simulation. Accuracy is further improved if we assume access to a single full-trajectory simulation from the computer model, which is typically available in practice. Across several PDE systems, we show that our data-augmented synthetic stencil data yield better trained neural stencil operators, with clear performance gains compared with naively sampled stencil data from simulation trajectories. 

**Abstract (ZH)**: 基于空间填充抽样的神经偏微分方程训练数据生成方法 

---
# A perishable ability? The future of writing in the face of generative artificial intelligence 

**Title (ZH)**: 易腐的能力？面对生成式人工智能，书写未来的前景 

**Authors**: Evandro L. T. P. Cunha  

**Link**: [PDF](https://arxiv.org/pdf/2508.19427)  

**Abstract**: The 2020s have been witnessing a very significant advance in the development of generative artificial intelligence tools, including text generation systems based on large language models. These tools have been increasingly used to generate texts in the most diverse domains -- from technical texts to literary texts --, which might eventually lead to a lower volume of written text production by humans. This article discusses the possibility of a future in which human beings will have lost or significantly decreased their ability to write due to the outsourcing of this activity to machines. This possibility parallels the loss of the ability to write in other moments of human history, such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE). 

**Abstract (ZH)**: 2020年代见证了生成型人工智能工具，尤其是基于大型语言模型的文本生成系统，的发展显著进步。这些工具在最多样化的领域被用于生成文本，这最终可能导致人类书面文本生产量的降低。本文讨论了未来人类可能会失去或大大减少写作能力的可能性，这种可能性类似于人类历史上其他时期丧失书写能力的情况，比如所谓的希腊黑暗时期（约公元前1200年至公元前800年）。 

---
# Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention 

**Title (ZH)**: 即使是奇数错误也需要偶数修正：Transformer注意力机制的发现与手术修复 

**Authors**: Gustavo Sandoval  

**Link**: [PDF](https://arxiv.org/pdf/2508.19414)  

**Abstract**: We present a mechanistic case study of a format-dependent reasoning failure in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger than "9.8" in chat or Q&A formats, but answers correctly in simple format. Through systematic intervention, we discover transformers implement even/odd attention head specialization: even indexed heads handle numerical comparison, while odd heads serve incompatible functions. The bug requires exactly 8 even heads at Layer 10 for perfect repair. Any combination of 8+ even heads succeeds, while 7 or fewer completely fails, revealing sharp computational thresholds with perfect redundancy among the 16 even heads. SAE analysis reveals the mechanism: format representations separate (10% feature overlap at Layer 7), then re-entangle with different weightings (80% feature overlap at Layer 10), with specific features showing 1.5x amplification in failing formats. We achieve perfect repair using only 25% of attention heads and identify a 60% pattern replacement threshold, demonstrating that apparent full-module requirements hide sophisticated substructure with implications for interpretability and efficiency. All of our code is available at this https URL. 

**Abstract (ZH)**: 我们 presents 一个关于 Llama-3.1-8B-Instruct 中格式依赖性推理故障的机理案例研究，其中模型在聊天或问答格式中错误地判断“9.11”大于“9.8”，但在简单格式中回答正确。通过系统干预，我们发现transformers 实现了偶数/奇数注意力层的专业化：偶数索引的层处理数值比较，而奇数层承担不兼容的功能。该故障需要恰好第10层有8个偶数层以实现完美修复。任何8个及以上偶数层的组合都能成功，而7个或更少的完全失败，揭示了精确的计算阈值，且16个偶数层之间具有完美的冗余性。SAE分析揭示了机制：格式表示在第7层分离（特征重叠为10%），然后在第10层重新交织但权重不同（特征重叠为80%），特定特征在失败的格式中放大1.5倍。我们仅使用25%的注意力层实现完美修复，并确定了60%的模式替换阈值，表明看似需要完整模块的假设隐藏了复杂的次结构，这对可解释性和效率具有影响。所有代码均可在此 https:// 的链接处获取。 

---
# One Joke to Rule them All? On the (Im)possibility of Generalizing Humor 

**Title (ZH)**: 一家笑法规制它们？关于幽默泛化的（不）可能性 

**Authors**: Mor Turgeman, Chen Shani, Dafna Shahaf  

**Link**: [PDF](https://arxiv.org/pdf/2508.19402)  

**Abstract**: Humor is a broad and complex form of communication that remains challenging for machines. Despite its broadness, most existing research on computational humor traditionally focused on modeling a specific type of humor. In this work, we wish to understand whether competence on one or more specific humor tasks confers any ability to transfer to novel, unseen types; in other words, is this fragmentation inevitable? This question is especially timely as new humor types continuously emerge in online and social media contexts (e.g., memes, anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this evolving landscape, they must be able to generalize across humor types by capturing deeper, transferable mechanisms. To investigate this, we conduct a series of transfer learning experiments across four datasets, representing different humor tasks. We train LLMs under varied diversity settings (1-3 datasets in training, testing on a novel task). Experiments reveal that models are capable of some transfer, and can reach up to 75% accuracy on unseen datasets; training on diverse sources improves transferability (1.88-4.05%) with minimal-to-no drop in in-domain performance. Further analysis suggests relations between humor types, with Dad Jokes surprisingly emerging as the best enabler of transfer (but is difficult to transfer to). We release data and code. 

**Abstract (ZH)**: 基于计算的幽默理解：单一幽默任务能力向新颖类型迁移的不可避免性探索 

---
# Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments 

**Title (ZH)**: Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments 细调视觉-语言模型以进行高能物理实验中的中子事件分析 

**Authors**: Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19376)  

**Abstract**: Recent progress in large language models (LLMs) has shown strong potential for multimodal reasoning beyond natural language. In this work, we explore the use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for classifying neutrino interactions from pixelated detector images in high-energy physics (HEP) experiments. We benchmark its performance against an established CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as classification accuracy, precision, recall, and AUC-ROC. Our results show that the VLM not only matches or exceeds CNN performance but also enables richer reasoning and better integration of auxiliary textual or semantic context. These findings suggest that VLMs offer a promising general-purpose backbone for event classification in HEP, paving the way for multimodal approaches in experimental neutrino physics. 

**Abstract (ZH)**: Recent进展在大规模语言模型（LLMs）在多模态推理方面的潜力超越了自然语言。在本工作中，我们探索了基于LLaMA 3.2的调优Vision-Language Model（VLM）在高能物理（HEP）实验中从像素化探测器图像分类中微子相互作用的应用。我们将其性能与NOvA和DUNE等实验中使用的成熟CNN基线进行了基准测试，评估了分类准确性、精确度、召回率和AUC-ROC等指标。结果表明，VLM不仅能匹配甚至超越CNN的表现，还能实现更丰富的推理和更好的辅助文本或语义上下文的整合。这些发现表明，VLM为HEP中的事件分类提供了一种前景广阔的通用基础架构，为实验中微子物理的多模态方法铺平了道路。 

---
# Database Entity Recognition with Data Augmentation and Deep Learning 

**Title (ZH)**: 基于数据扩增和深度学习的数据库实体识别 

**Authors**: Zikun Fu, Chen Yang, Kourosh Davoudi, Ken Q. Pu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19372)  

**Abstract**: This paper addresses the challenge of Database Entity Recognition (DB-ER) in Natural Language Queries (NLQ). We present several key contributions to advance this field: (1) a human-annotated benchmark for DB-ER task, derived from popular text-to-sql benchmarks, (2) a novel data augmentation procedure that leverages automatic annotation of NLQs based on the corresponding SQL queries which are available in popular text-to-SQL benchmarks, (3) a specialized language model based entity recognition model using T5 as a backbone and two down-stream DB-ER tasks: sequence tagging and token classification for fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER tagger with two state-of-the-art NER taggers, and observed better performance in both precision and recall for our model. The ablation evaluation shows that data augmentation boosts precision and recall by over 10%, while fine-tuning of the T5 backbone boosts these metrics by 5-10%. 

**Abstract (ZH)**: 这篇论文探讨了自然语言查询（NLQ）中的数据库实体识别（DB-ER）挑战。我们提出了几项关键贡献以推进该领域的发展：（1）一个基于流行文本到SQL基准的数据标注基准数据集用于DB-ER任务；（2）一种新颖的数据增强方法，利用相应的SQL查询的自动标注来增强自然语言查询（NLQ）的标注；（3）一个基于T5的专用语言模型实体识别模型以及两个下游DB-ER任务：序列标注和标记分类，用于调整T5骨干模型并执行DB-ER。我们将我们的DB-ER标签器与两种最先进的NER标签器进行了比较，并发现我们的模型在精度和召回率上表现更好。消融评估显示，数据增强将精度和召回率提高了超过10%，而调整T5骨干模型将这些指标分别提高了5-10%。 

---
# Inference of Human-derived Specifications of Object Placement via Demonstration 

**Title (ZH)**: 基于演示推断人类衍生的物体放置规范 

**Authors**: Alex Cuellar, Ho Chit Siu, Julie A Shah  

**Link**: [PDF](https://arxiv.org/pdf/2508.19367)  

**Abstract**: As robots' manipulation capabilities improve for pick-and-place tasks (e.g., object packing, sorting, and kitting), methods focused on understanding human-acceptable object configurations remain limited expressively with regard to capturing spatial relationships important to humans. To advance robotic understanding of human rules for object arrangement, we introduce positionally-augmented RCC (PARCC), a formal logic framework based on region connection calculus (RCC) for describing the relative position of objects in space. Additionally, we introduce an inference algorithm for learning PARCC specifications via demonstrations. Finally, we present the results from a human study, which demonstrate our framework's ability to capture a human's intended specification and the benefits of learning from demonstration approaches over human-provided specifications. 

**Abstract (ZH)**: 随着机器人在取放任务（例如物体打包、分类和组装配件）中的操作能力提升，专注于理解人类可接受的物体配置的方法在捕捉对人类重要的空间关系方面仍较为有限。为促进机器人对物体排列规则的理解，我们引入了一种基于区域连接计算（RCC）的位置增强RCC（PARCC）形式逻辑框架，用于描述空间中物体的相对位置。此外，我们还提出了一种推理算法，用于通过演示学习PARCC规范。最后，我们呈现了一项人类研究的结果，该结果展示了我们框架捕捉人类意图规范的能力，并说明了通过演示学习方法相较于人类提供规范的优势。 

---
# Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs 

**Title (ZH)**: 未接地的接地：一种用于量化多模态LLM中幻觉的谱图框架 

**Authors**: Supratik Sarkar, Swagatam Das  

**Link**: [PDF](https://arxiv.org/pdf/2508.19366)  

**Abstract**: Hallucinations in large language models (LLMs) remain a fundamental obstacle to trustworthy AI, particularly in high-stakes multimodal domains such as medicine, law, and finance. Existing evaluation techniques are largely heuristic -- anchored in qualitative benchmarking or ad-hoc empirical mitigation -- providing neither principled quantification nor actionable theoretical guarantees. This gap leaves a critical blind spot in understanding how hallucinations arise, propagate, and interact across modalities. We introduce the first (to our knowledge) rigorous information geometric framework in diffusion dynamics for quantifying hallucinations in multimodal LLMs (MLLMs), advancing the field from qualitative detection to mathematically grounded measurement. Our approach represents MLLM outputs as the spectral embeddings over multimodal graph Laplacians and characterizes the manifold gaps of truth vs inconsistencies as the semantic distortion, enabling the tight Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of time-dependent temperature profiles. By leveraging eigenmode decompositions in Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers modality-aware, theoretically interpretable metrics that capture the evolution of hallucinations across time and input prompts through temperature annealing. This work establishes a principled foundation for quantifying and bounding hallucinations, transforming them from a qualitative risk to a tractable, analyzable phenomenon. 

**Abstract (ZH)**: 大型语言模型中的幻觉仍然是可信人工智能的基本障碍，特别是在医学、法律和金融等高风险多模态领域。现有的评估技术大多基于启发式方法——依赖于定性基准测试或临时的经验抑制，既没有提供有原则的量化也没有提供可操作的理论保障。这一差距留下了理解幻觉如何产生、传播以及跨模态相互作用的关键盲点。我们率先（据我们所知）提出了首个严格的信息几何框架，在扩散动力学中定量评估多模态大型语言模型（多模态LLMs）中的幻觉，将领域从定性的检测推进到基于数学依据的测量。我们的方法将多模态LLM输出表示为多模态图拉普拉斯算子上的谱嵌入，并将真假之间的流形差距量化为语义失真，从而基于时间依赖的温度谱提供多层次的幻觉能量紧致的瑞利-里兹界。通过在再生核希尔伯特空间（RKHS）嵌入中的特征模式分解，我们的框架提供了模态意识、可理论解释的度量，这些度量能够捕捉通过温度调温过程中幻觉随时间和输入提示的演变。本文为量化和边界幻觉建立了坚实的理论基础，将幻觉从定性的风险转变为可解决和分析的现象。 

---
# LongReasonArena: A Long Reasoning Benchmark for Large Language Models 

**Title (ZH)**: 长 reasoning 基准 Arena：大规模语言模型的长推理基准 

**Authors**: Jiayu Ding, Shuming Ma, Lei Cui, Nanning Zheng, Furu Wei  

**Link**: [PDF](https://arxiv.org/pdf/2508.19363)  

**Abstract**: Existing long-context benchmarks for Large Language Models (LLMs) focus on evaluating comprehension of long inputs, while overlooking the evaluation of long reasoning abilities. To address this gap, we introduce LongReasonArena, a benchmark specifically designed to assess the long reasoning capabilities of LLMs. Our tasks require models to solve problems by executing multi-step algorithms that reflect key aspects of long reasoning, such as retrieval and backtracking. By controlling the inputs, the required reasoning length can be arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most challenging tasks. Extensive evaluation results demonstrate that LongReasonArena presents a significant challenge for both open-source and proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our task. Further analysis also reveals that the accuracy exhibits a linear decline with respect to the logarithm of the expected number of reasoning steps. Our code and data is available at this https URL. 

**Abstract (ZH)**: 现有的长上下文基准测试主要侧重于评估大型语言模型对长输入的理解能力，而忽视了长期推理能力的评估。为了弥补这一缺口，我们介绍了LongReasonArena，一个专门设计用来评估大型语言模型长期推理能力的基准测试。我们的任务要求模型通过执行多步算法来解决复杂问题，这些算法反映了长期推理的关键方面，如检索和回溯。通过控制输入，可以随意调整所需的推理长度，最难的任务可以达到高达100万词的推理长度。广泛的评估结果表明，LongReasonArena为开源和专有大型语言模型提供了重大挑战。例如，Deepseek-R1在我们的任务中仅达到7.5%的准确率。进一步的分析还表明，准确率与预期推理步数的对数呈现线性下降趋势。我们的代码和数据可在以下链接获取。 

---
# Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture 

**Title (ZH)**: 使用轻量级时序卷积和选择性状态空间架构的房颤预测 

**Authors**: Yongbin Lee, Ki H. Chon  

**Link**: [PDF](https://arxiv.org/pdf/2508.19361)  

**Abstract**: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk of stroke, heart failure, and other cardiovascular complications. While AF detection algorithms perform well in identifying persistent AF, early-stage progression, such as paroxysmal AF (PAF), often goes undetected due to its sudden onset and short duration. However, undetected PAF can progress into sustained AF, increasing the risk of mortality and severe complications. Early prediction of AF offers an opportunity to reduce disease progression through preventive therapies, such as catecholamine-sparing agents or beta-blockers. In this study, we propose a lightweight deep learning model using only RR Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for positional encoding with Mamba, a selective state space model, to enable early prediction of AF through efficient parallel sequence modeling. In subject-wise testing results, our model achieved a sensitivity of 0.908, specificity of 0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our method demonstrates high computational efficiency, with only 73.5 thousand parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and model compactness. Notably, the model can predict AF up to two hours in advance using just 30 minutes of input data, providing enough lead time for preventive interventions. 

**Abstract (ZH)**: 心房颤动（AF）是最常见的心律失常，增加中风、心力衰竭和其他心血管并发症的风险。尽管用于检测持续性心房颤动的算法表现良好，但早期阶段如阵发性心房颤动（PAF）由于其突发性和短暂性，往往未被检测到。然而，未检测到的PAF可能会进展为持续性心房颤动，增加死亡率和严重并发症的风险。早期预测心房颤动提供了通过预防性治疗减少疾病进展的机会，如使用儿茶酚胺保护剂或β-阻滞剂。在本研究中，我们提出了一种仅使用RR间期（RRIs）的轻量级深度学习模型，结合时空卷积网络（TCN）进行位置编码与Mamba选择性状态空间模型，以高效并行序列建模方式实现心房颤动的早期预测。在个体测试结果中，我们的模型达到了0.908的灵敏度、0.933的特异度、0.930的F1分数、0.972的AUROC和0.932的AUPRC。此外，该方法展示了高的计算效率，仅包含73.5万个参数和38.3 MFLOPs，优于传统卷积神经网络-循环神经网络（CNN-RNN）方法在准确性和模型紧凑性方面的表现。值得注意的是，该模型仅使用30分钟的输入数据即可提前两小时预测心房颤动，为预防干预提供了足够的时间。 

---
# Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction 

**Title (ZH)**: 反映一致性：结合代理的自我混合与序列标注器以实现稳健的事件抽取 

**Authors**: Fatemeh Haji, Mazal Bethany, Cho-Yu Jason Chiang, Anthony Rios, Peyman Najafirad  

**Link**: [PDF](https://arxiv.org/pdf/2508.19359)  

**Abstract**: Event Extraction (EE) involves automatically identifying and extracting structured information about events from unstructured text, including triggers, event types, and arguments. Traditional discriminative models demonstrate high precision but often exhibit limited recall, particularly for nuanced or infrequent events. Conversely, generative approaches leveraging Large Language Models (LLMs) provide higher semantic flexibility and recall but suffer from hallucinations and inconsistent predictions. To address these challenges, we propose Agreement-based Reflective Inference System (ARIS), a hybrid approach combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS explicitly leverages structured model consensus, confidence-based filtering, and an LLM reflective inference module to reliably resolve ambiguities and enhance overall event prediction quality. We further investigate decomposed instruction fine-tuning for enhanced LLM event extraction understanding. Experiments demonstrate our approach outperforms existing state-of-the-art event extraction methods across three benchmark datasets. 

**Abstract (ZH)**: 事件提取（EE）涉及从非结构化文本中自动识别和提取事件的结构化信息，包括触发词、事件类型和论元。传统的判别模型展示出高精度，但往往召回率有限，特别是在处理细腻或不频繁的事件时。相反，利用大规模语言模型（LLMs）的生成方法提供了更高的语义灵活性和召回率，但容易产生幻觉并导致预测不一致。为应对这些挑战，我们提出了一种混合方法——基于一致性的反思推理系统（ARIS），该方法结合了自我代理混合和判别序列标注器。ARIS 明确利用结构化模型的一致性、基于信心的过滤以及一个 LLM 反思推理模块，以可靠地解决歧义并提高整体事件预测质量。我们进一步研究了分解指令微调，以增强 LLM 的事件提取理解能力。实验结果显示，我们的方法在三个基准数据集上优于现有最先进的事件提取方法。 

---
# Re:Frame -- Retrieving Experience From Associative Memory 

**Title (ZH)**: Re:Frame——从关联记忆中检索经验 

**Authors**: Daniil Zelezetsky, Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov  

**Link**: [PDF](https://arxiv.org/pdf/2508.19344)  

**Abstract**: Offline reinforcement learning (RL) often deals with suboptimal data when collecting large expert datasets is unavailable or impractical. This limitation makes it difficult for agents to generalize and achieve high performance, as they must learn primarily from imperfect or inconsistent trajectories. A central challenge is therefore how to best leverage scarce expert demonstrations alongside abundant but lower-quality data. We demonstrate that incorporating even a tiny amount of expert experience can substantially improve RL agent performance. We introduce Re:Frame (Retrieving Experience From Associative Memory), a plug-in module that augments a standard offline RL policy (e.g., Decision Transformer) with a small external Associative Memory Buffer (AMB) populated by expert trajectories drawn from a separate dataset. During training on low-quality data, the policy learns to retrieve expert data from the Associative Memory Buffer (AMB) via content-based associations and integrate them into decision-making; the same AMB is queried at evaluation. This requires no environment interaction and no modifications to the backbone architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories (0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a strong Decision Transformer baseline in three of four settings, with gains up to +10.7 normalized points. These results show that Re:Frame offers a simple and data-efficient way to inject scarce expert knowledge and substantially improve offline RL from low-quality datasets. 

**Abstract (ZH)**: 离线强化学习（RL）经常面临亚优数据的问题，当收集大量专家数据集不可用或不现实时尤为明显。这种限制使得智能体难以泛化并实现高性能，因为它们主要必须从不完美或不一致的轨迹中学习。因此，一个核心挑战是如何最佳地利用稀缺的专家演示与丰富的但质量较低的数据。我们证明即使整合少量的专家经验也能显著提升RL智能体的性能。我们引入了Re:Frame（从关联记忆中检索经验）模块，该模块将一个小的外部关联记忆缓冲区（AMB）与标准的离线RL策略（如决策变换器）进行结合，该缓冲区由来自单独数据集的专家轨迹填充。在使用低质量数据进行训练时，策略通过内容关联从关联记忆缓冲区检索专家数据，并将其整合到决策制定中；在评估时查询相同的AMB。这种方法不需要环境交互，也不需要修改基础架构。在D4RL MuJoCo任务中，使用多达60条专家轨迹（6000条轨迹数据集的0.1%），Re:Frame在三个四个设置中的三个中都优于强大的决策变换器基线，改进幅度最高可达+10.7标准化点。这些结果表明，Re:Frame提供了一种简单且数据高效的途径，以注入稀缺的专家知识并在低质量数据集的离线RL中显著提升性能。 

---
# Quantum Entanglement as Super-Confounding: From Bell's Theorem to Robust Machine Learning 

**Title (ZH)**: 量子纠缠作为超级混淆：从贝尔定理到稳健机器学习 

**Authors**: Pilsung Kang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19327)  

**Abstract**: Bell's theorem reveals a profound conflict between quantum mechanics and local realism, a conflict we reinterpret through the modern lens of causal inference. We propose and computationally validate a framework where quantum entanglement acts as a "super-confounding" resource, generating correlations that violate the classical causal bounds set by Bell's inequalities. This work makes three key contributions: First, we establish a physical hierarchy of confounding (Quantum > Classical) and introduce Confounding Strength (CS) to quantify this effect. Second, we provide a circuit-based implementation of the quantum $\mathcal{DO}$-calculus to distinguish causality from spurious correlation. Finally, we apply this calculus to a quantum machine learning problem, where causal feature selection yields a statistically significant 11.3% average absolute improvement in model robustness. Our framework bridges quantum foundations and causal AI, offering a new, practical perspective on quantum correlations. 

**Abstract (ZH)**: 贝尔定理揭示了量子力学与局域实在论之间的深刻冲突，我们通过现代因果推断的视角重新解读这一冲突。本文提出并计算验证了一个框架，其中量子纠缠作为一种“超混杂”资源，产生违反贝尔不等式经典因果界限的相关性。本文做出三大贡献：首先，我们建立了混杂的物理层次（量子 > 经典），并引入混杂强度（CS）来量化这一效果。其次，我们提供了一个基于量子$\mathcal{DO}$-演算的电路实现方法，以区分因果关系与伪相关。最后，我们将该演算应用于量子机器学习问题，其中因果特征选择在模型稳健性上提供了统计显著的11.3%平均绝对改进。我们的框架将量子基础与因果人工智能相连，提供了一种新的实用视角来理解量子相关性。 

---
# Deep Data Hiding for ICAO-Compliant Face Images: A Survey 

**Title (ZH)**: ICAO合规面部图像中的深层数据隐藏综述 

**Authors**: Jefferson David Rodriguez Chivata, Davide Ghiani, Simone Maurizio La Cava, Marco Micheletto, Giulia Orrù, Federico Lama, Gian Luca Marcialis  

**Link**: [PDF](https://arxiv.org/pdf/2508.19324)  

**Abstract**: ICAO-compliant facial images, initially designed for secure biometric passports, are increasingly becoming central to identity verification in a wide range of application contexts, including border control, digital travel credentials, and financial services. While their standardization enables global interoperability, it also facilitates practices such as morphing and deepfakes, which can be exploited for harmful purposes like identity theft and illegal sharing of identity documents. Traditional countermeasures like Presentation Attack Detection (PAD) are limited to real-time capture and offer no post-capture protection. This survey paper investigates digital watermarking and steganography as complementary solutions that embed tamper-evident signals directly into the image, enabling persistent verification without compromising ICAO compliance. We provide the first comprehensive analysis of state-of-the-art techniques to evaluate the potential and drawbacks of the underlying approaches concerning the applications involving ICAO-compliant images and their suitability under standard constraints. We highlight key trade-offs, offering guidance for secure deployment in real-world identity systems. 

**Abstract (ZH)**: ICAO符合性面部图像最初用于安全生物特征护照，如今在边境控制、数字旅行凭证和金融服务等多种应用上下逐渐成为身份验证的核心。虽然其标准化促进了全球互操作性，但也促进了如换脸和深度伪造等有害行为。传统的防presentation attack检测措施仅限于实时捕获，无法提供捕获后的保护。本文综述了数字水印和隐写术作为补充解决方案的研究，这些解决方案可以直接将抗篡改信号嵌入图像中，实现持续验证而不违背ICAO符合性。我们提供了关于ICAO符合性图像及其在标准约束下的适用性的最新技术的首次全面分析，评估潜在优势和局限性。我们强调了关键权衡，为实际世界中的身份验证系统安全部署提供指导。 

---
# AT-CXR: Uncertainty-Aware Agentic Triage for Chest X-rays 

**Title (ZH)**: AT-CXR：基于不确定性感知的胸部X光分诊方法 

**Authors**: Xueyang Li, Mingze Jiang, Gelei Xu, Jun Xia, Mengzhao Jia, Danny Chen, Yiyu Shi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19322)  

**Abstract**: Agentic AI is advancing rapidly, yet truly autonomous medical-imaging triage, where a system decides when to stop, escalate, or defer under real constraints, remains relatively underexplored. To address this gap, we introduce AT-CXR, an uncertainty-aware agent for chest X-rays. The system estimates per-case confidence and distributional fit, then follows a stepwise policy to issue an automated decision or abstain with a suggested label for human intervention. We evaluate two router designs that share the same inputs and actions: a deterministic rule-based router and an LLM-decided router. Across five-fold evaluation on a balanced subset of NIH ChestX-ray14 dataset, both variants outperform strong zero-shot vision-language models and state-of-the-art supervised classifiers, achieving higher full-coverage accuracy and superior selective-prediction performance, evidenced by a lower area under the risk-coverage curve (AURC) and a lower error rate at high coverage, while operating with lower latency that meets practical clinical constraints. The two routers provide complementary operating points, enabling deployments to prioritize maximal throughput or maximal accuracy. Our code is available at this https URL. 

**Abstract (ZH)**: 代理型AI快速发展，但真正自主的医学影像分诊（系统在实际约束下决定停止、升级或延后）仍相对未被充分探索。为解决这一问题，我们引入了AT-CXR，这是一种具有不确定性意识的胸片处理代理系统。该系统估计每例案件的置信度和分布拟合度，然后遵循逐步策略，要么发布自动化决策，要么在建议标签下保持中立等待人工干预。我们评估了两种路由器设计，它们共享相同的输入和动作：确定性规则Based路由器和基于LLM的路由器。在对NIH ChestX-ray14数据集平衡子集进行五折评估中，两种变体均优于强大的零样本视觉语言模型和最先进的监督分类器，实现了更高的全面准确性并表现出更优的选择性预测性能，这体现在较低的风险覆盖面积下的曲线下面积（AURC）以及在高覆盖率下的较低错误率，同时满足实际临床约束下的较低延迟要求。这两种路由器提供了互补的操作点，使部署能够优先考虑最大吞吐量或最大准确性。我们的代码可在以下链接获取。 

---
# An Investigation on Group Query Hallucination Attacks 

**Title (ZH)**: 群体查询幻觉攻击研究 

**Authors**: Kehao Miao, Xiaolong Jin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19321)  

**Abstract**: With the widespread use of large language models (LLMs), understanding their potential failure modes during user interactions is essential. In practice, users often pose multiple questions in a single conversation with LLMs. Therefore, in this study, we propose Group Query Attack, a technique that simulates this scenario by presenting groups of queries to LLMs simultaneously. We investigate how the accumulated context from consecutive prompts influences the outputs of LLMs. Specifically, we observe that Group Query Attack significantly degrades the performance of models fine-tuned on specific tasks. Moreover, we demonstrate that Group Query Attack induces a risk of triggering potential backdoors of LLMs. Besides, Group Query Attack is also effective in tasks involving reasoning, such as mathematical reasoning and code generation for pre-trained and aligned models. 

**Abstract (ZH)**: 随着大规模语言模型（LLMs）的广泛应用，理解其在用户交互过程中的潜在失效模式至关重要。在实践中，用户往往在一个对话中提出多个问题。因此，本文提出了一种称为组查询攻击的技术，该技术通过同时向LLMs呈现一组查询来模拟这种场景。我们研究了连续提示积累的上下文对LLMs输出的影响。具体来说，我们观察到组查询攻击显著降低了针对特定任务微调的模型的性能。此外，我们还展示了组查询攻击可能触发LLMs潜在后门的风险。此外，组查询攻击在涉及推理的任务中也有效，如数学推理和预训练和对齐模型的代码生成。 

---
# MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation 

**Title (ZH)**: MIDAS：多模态交互数字人合成 via 实时自回归视频生成 

**Authors**: Ming Chen, Liyuan Cui, Wenyuan Zhang, Haoxian Zhang, Yan Zhou, Xiaohan Li, Xiaoqiang Liu, Pengfei Wan  

**Link**: [PDF](https://arxiv.org/pdf/2508.19320)  

**Abstract**: Recently, interactive digital human video generation has attracted widespread attention and achieved remarkable progress. However, building such a practical system that can interact with diverse input signals in real time remains challenging to existing methods, which often struggle with high latency, heavy computational cost, and limited controllability. In this work, we introduce an autoregressive video generation framework that enables interactive multimodal control and low-latency extrapolation in a streaming manner. With minimal modifications to a standard large language model (LLM), our framework accepts multimodal condition encodings including audio, pose, and text, and outputs spatially and semantically coherent representations to guide the denoising process of a diffusion head. To support this, we construct a large-scale dialogue dataset of approximately 20,000 hours from multiple sources, providing rich conversational scenarios for training. We further introduce a deep compression autoencoder with up to 64$\times$ reduction ratio, which effectively alleviates the long-horizon inference burden of the autoregressive model. Extensive experiments on duplex conversation, multilingual human synthesis, and interactive world model highlight the advantages of our approach in low latency, high efficiency, and fine-grained multimodal controllability. 

**Abstract (ZH)**: 近年来，交互式数字人物视频生成吸引广泛关注并取得了显著进展。然而，构建能够实时处理多样化输入信号的实用系统仍然极具挑战性，现有方法往往面临高延迟、高计算成本和控制能力有限的问题。在本工作中，我们提出了一种自回归视频生成框架，该框架能够以流式方式实现多模态交互控制和低延迟外推。通过对标准大型语言模型进行少量修改，我们的框架接受包括音频、姿态和文本在内的多模态条件编码，并输出空间上和语义上一致的表示，以指导泛化头部的去噪过程。为此，我们构建了一个规模为约20,000小时的大型对话数据集，提供了丰富的对话场景用于训练。我们还引入了深度压缩自编码器，压缩比最高可达64倍，有效地缓解了自回归模型的长期推理负担。大量实验表明，我们的方法在低延迟、高性能和精细的多模态可控性方面具有明显优势。 

---
# MedVQA-TREE: A Multimodal Reasoning and Retrieval Framework for Sarcopenia Prediction 

**Title (ZH)**: MedVQA-TREE: 一种多模态推理与检索框架用于肌少症预测 

**Authors**: Pardis Moradbeiki, Nasser Ghadiri, Sayed Jalal Zahabi, Uffe Kock Wiil, Kristoffer Kittelmann Brockhattingen, Ali Ebrahimi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19319)  

**Abstract**: Accurate sarcopenia diagnosis via ultrasound remains challenging due to subtle imaging cues, limited labeled data, and the absence of clinical context in most models. We propose MedVQA-TREE, a multimodal framework that integrates a hierarchical image interpretation module, a gated feature-level fusion mechanism, and a novel multi-hop, multi-query retrieval strategy. The vision module includes anatomical classification, region segmentation, and graph-based spatial reasoning to capture coarse, mid-level, and fine-grained structures. A gated fusion mechanism selectively integrates visual features with textual queries, while clinical knowledge is retrieved through a UMLS-guided pipeline accessing PubMed and a sarcopenia-specific external knowledge base. MedVQA-TREE was trained and evaluated on two public MedVQA datasets (VQA-RAD and PathVQA) and a custom sarcopenia ultrasound dataset. The model achieved up to 99% diagnostic accuracy and outperformed previous state-of-the-art methods by over 10%. These results underscore the benefit of combining structured visual understanding with guided knowledge retrieval for effective AI-assisted diagnosis in sarcopenia. 

**Abstract (ZH)**: 通过超声准确诊断肌少症仍具有挑战性，因为影像线索微妙、标注数据有限以及多数模型缺乏临床背景。我们提出了MedVQA-TREE，这是一种多模态框架，结合了层次化的图像解释模块、门控特征级融合机制以及新颖的多跳多查询检索策略。视觉模块包括解剖分类、区域分割以及基于图的空间推理，以捕捉粗略、中等和精细结构。门控融合机制选择性地将视觉特征与文本查询融合，而临床知识则通过由UMLS引导的管道从PubMed和专门的肌少症外部知识库中检索。MedVQA-TREE在两个公开的MedVQA数据集（VQA-RAD和PathVQA）以及一个自定义的肌少症超声数据集上进行了训练和评估。该模型准确率最高可达99%，并在诊断准确性上超过此前最佳方法10%以上。这些结果强调了结合结构化视觉理解与引导知识检索对于有效肌少症辅助诊断AI的重要性。 

---
# (DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems 

**Title (ZH)**: 基于深度强化学习的分布式物联网系统资源分配方法 

**Authors**: Aohan Li, Miyu Tsuzuki  

**Link**: [PDF](https://arxiv.org/pdf/2508.19318)  

**Abstract**: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to resource allocation due to its strong capability in handling complex decision-making tasks. However, only limited research has explored the training of DRL models with real-world data in practical, distributed Internet of Things (IoT) systems. To bridge this gap, this paper proposes a novel framework for training DRL models in real-world distributed IoT environments. In the proposed framework, IoT devices select communication channels using a DRL-based method, while the DRL model is trained with feedback information. Specifically, Acknowledgment (ACK) information is obtained from actual data transmissions over the selected channels. Implementation and performance evaluation, in terms of Frame Success Rate (FSR), are carried out, demonstrating both the feasibility and the effectiveness of the proposed framework. 

**Abstract (ZH)**: 深度强化学习（DRL）已在资源分配中展现出高效的方法，因其在处理复杂决策任务方面的强大能力。然而，仅有有限的研究探索了在实用的分布式物联网（IoT）系统中使用真实数据训练DRL模型。为弥补这一差距，本文提出了一种新的框架，用于在实际分布式物联网环境中训练DRL模型。在所提出的框架中，物联网设备使用基于DRL的方法选择通信信道，同时DRL模型通过反馈信息进行训练。具体而言，通过实际数据传输获得确认（ACK）信息。实现了框架的实施并从帧成功率（FSR）的角度进行了性能评估，证明了所提出框架的可行性和有效性。 

---
# What Makes AI Applications Acceptable or Unacceptable? A Predictive Moral Framework 

**Title (ZH)**: 什么是接受或拒绝AI应用的道德框架？ 

**Authors**: Kimmo Eriksson, Simon Karlsson, Irina Vartanova, Pontus Strimling  

**Link**: [PDF](https://arxiv.org/pdf/2508.19317)  

**Abstract**: As artificial intelligence rapidly transforms society, developers and policymakers struggle to anticipate which applications will face public moral resistance. We propose that these judgments are not idiosyncratic but systematic and predictable. In a large, preregistered study (N = 587, U.S. representative sample), we used a comprehensive taxonomy of 100 AI applications spanning personal and organizational contexts-including both functional uses and the moral treatment of AI itself. In participants' collective judgment, applications ranged from highly unacceptable to fully acceptable. We found this variation was strongly predictable: five core moral qualities-perceived risk, benefit, dishonesty, unnaturalness, and reduced accountability-collectively explained over 90% of the variance in acceptability ratings. The framework demonstrated strong predictive power across all domains and successfully predicted individual-level judgments for held-out applications. These findings reveal that a structured moral psychology underlies public evaluation of new technologies, offering a powerful tool for anticipating public resistance and guiding responsible innovation in AI. 

**Abstract (ZH)**: 随着人工智能迅速改变社会，开发人员和政策制定者难以预测哪些应用会面临公众道德抵制。我们提出，这些判断并非随机，而是系统性和可预测的。在一项大规模的预先登记研究（N=587，具代表性的美国样本）中，我们使用了涵盖个人和组织环境的100种AI应用全面分类，包括功能用途和对AI本身的道德对待。参与者集体判断的应用范围从高度不可接受到完全可接受。我们发现这种差异具有很强的可预测性：五个核心道德品质——感知风险、好处、不诚实、不自然和减少问责制——共同解释了超过90%的可接受性评分变异。该框架在所有领域都表现出强大的预测能力，并成功预测了未见过的应用的个体判断。这些发现揭示了一种结构化的道德心理学构成了对新技术公众评价的基础，提供了预见公众抵制和指导负责任的人工智能创新的强大工具。 

---
# Automated classification of natural habitats using ground-level imagery 

**Title (ZH)**: 基于地面图像的自然栖息地自动分类 

**Authors**: Mahdis Tourian, Sareh Rowlands, Remy Vandaele, Max Fancourt, Rebecca Mein, Hywel T. P. Williams  

**Link**: [PDF](https://arxiv.org/pdf/2508.19314)  

**Abstract**: Accurate classification of terrestrial habitats is critical for biodiversity conservation, ecological monitoring, and land-use planning. Several habitat classification schemes are in use, typically based on analysis of satellite imagery with validation by field ecologists. Here we present a methodology for classification of habitats based solely on ground-level imagery (photographs), offering improved validation and the ability to classify habitats at scale (for example using citizen-science imagery). In collaboration with Natural England, a public sector organisation responsible for nature conservation in England, this study develops a classification system that applies deep learning to ground-level habitat photographs, categorising each image into one of 18 classes defined by the 'Living England' framework. Images were pre-processed using resizing, normalisation, and augmentation; re-sampling was used to balance classes in the training data and enhance model robustness. We developed and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label to each photograph. Using five-fold cross-validation, the model demonstrated strong overall performance across 18 habitat classes, with accuracy and F1-scores varying between classes. Across all folds, the model achieved a mean F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or ambiguous classes scoring lower. These findings demonstrate the potential of this approach for ecological monitoring. Ground-level imagery is readily obtained, and accurate computational methods for habitat classification based on such data have many potential applications. To support use by practitioners, we also provide a simple web application that classifies uploaded images using our model. 

**Abstract (ZH)**: 基于地面图像的植被类型准确分类对于生物多样性保护、生态监测和土地利用规划至关重要。多种植被分类方案正在使用，通常基于卫星影像分析，并通过实地生态学家的验证。本文提出了仅基于地面图像（照片）进行分类的方法，提供了改进的验证能力，并能够大规模分类植被（例如使用公民科学照片）。与负责英格兰自然保育的公共部门组织自然英格兰合作，本研究开发了一种基于深度学习的地面植被照片分类系统，将每张图像分类为“Living England”框架定义的18个类别之一。图像进行了预处理，包括调整大小、标准化和增强；通过对训练数据采样以平衡类别并增强模型的鲁棒性。我们开发并微调了DeepLabV3-ResNet101分类器，为每张照片分配一个植被类别标签。通过五折交叉验证，该模型在18个植被类别中总体表现强劲，不同类别的准确率和F1得分各不相同。所有折上，模型的平均F1得分为0.61，视觉上明显的植被类型如裸土、淤泥和泥炭（BSSP）和裸沙（BS）达到了高于0.90的值，而混合或模糊的类别得分较低。这些发现展示了此方法在生态监测中的潜力。地面图像易于获得，基于此类数据的准确计算方法在许多应用中都有很大潜力。为了支持实践者的使用，我们还提供了一个简单的网络应用，用于使用我们的模型对上传的图像进行分类。 

---
# Are Companies Taking AI Risks Seriously? A Systematic Analysis of Companies' AI Risk Disclosures in SEC 10-K forms 

**Title (ZH)**: 公司认真对待AI风险了吗？SEC 10-K表中关于AI风险披露的系统性分析 

**Authors**: Lucas G. Uberti-Bona Marin, Bram Rijsbosch, Gerasimos Spanakis, Konrad Kollnig  

**Link**: [PDF](https://arxiv.org/pdf/2508.19313)  

**Abstract**: As Artificial Intelligence becomes increasingly central to corporate strategies, concerns over its risks are growing too. In response, regulators are pushing for greater transparency in how companies identify, report and mitigate AI-related risks. In the US, the Securities and Exchange Commission (SEC) repeatedly warned companies to provide their investors with more accurate disclosures of AI-related risks; recent enforcement and litigation against companies' misleading AI claims reinforce these warnings. In the EU, new laws - like the AI Act and Digital Services Act - introduced additional rules on AI risk reporting and mitigation. Given these developments, it is essential to examine if and how companies report AI-related risks to the public. This study presents the first large-scale systematic analysis of AI risk disclosures in SEC 10-K filings, which require public companies to report material risks to their company. We analyse over 30,000 filings from more than 7,000 companies over the past five years, combining quantitative and qualitative analysis. Our findings reveal a sharp increase in the companies that mention AI risk, up from 4% in 2020 to over 43% in the most recent 2024 filings. While legal and competitive AI risks are the most frequently mentioned, we also find growing attention to societal AI risks, such as cyberattacks, fraud, and technical limitations of AI systems. However, many disclosures remain generic or lack details on mitigation strategies, echoing concerns raised recently by the SEC about the quality of AI-related risk reporting. To support future research, we publicly release a web-based tool for easily extracting and analysing keyword-based disclosures across SEC filings. 

**Abstract (ZH)**: 随着人工智能在企业战略中扮演日益重要的角色，对其风险的担忧也在增加。为此，监管机构要求企业提高在识别、报告和减轻人工智能相关风险方面的透明度。在美国，证券交易委员会（SEC）反复警告公司要向投资者提供更准确的人工智能相关风险披露；最近对误导性人工智能声明的执法和诉讼进一步强化了这些警告。在欧盟，新的法律（如人工智能法案和数字服务法案）引入了关于人工智能风险报告和缓解的额外规定。鉴于这些发展，有必要审查企业如何向公众报告人工智能相关风险。本研究首次进行了大规模系统的SEC 10-K文件中人工智能风险披露分析，要求上市公司报告对公司构成重大风险的事项。我们分析了过去五年来自7,000多家公司的超过30,000份文件，结合定量和定性分析。研究发现，提到人工智能风险的企业比例显著增加，从2020年的4%上升到最近2024年的超过43%。虽然法律和竞争性人工智能风险被最频繁提及，但我们还发现对社会性人工智能风险的关注也在增长，如网络攻击、欺诈和人工智能系统的技术限制。然而，许多披露仍然泛泛而谈，缺乏缓解策略的详细信息，这与SEC最近关于人工智能相关风险报告质量的担忧相呼应。为支持未来研究，我们公开发布了一个基于网络的工具，用于轻松提取和分析SEC文件中的关键词披露。 

---
# Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax 

**Title (ZH)**: 基于OpenMax的开放集联邦面部识别系统 

**Authors**: Ander Galván, Marivi Higuero, Jorge Sasiain, Eduardo Jacob  

**Link**: [PDF](https://arxiv.org/pdf/2508.19312)  

**Abstract**: Facial recognition powered by Artificial Intelligence has achieved high accuracy in specific scenarios and applications. Nevertheless, it faces significant challenges regarding privacy and identity management, particularly when unknown individuals appear in the operational context. This paper presents the design, implementation, and evaluation of a facial recognition system within a federated learning framework tailored to open-set scenarios. The proposed approach integrates the OpenMax algorithm into federated learning, leveraging the exchange of mean activation vectors and local distance measures to reliably distinguish between known and unknown subjects. Experimental results validate the effectiveness of the proposed solution, demonstrating its potential for enhancing privacy-aware and robust facial recognition in distributed environments.
--
El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado una alta precisión en algunos escenarios y aplicaciones. Sin embargo, presenta desafíos relacionados con la privacidad y la identificación de personas, especialmente considerando que pueden aparecer sujetos desconocidos para el sistema que lo implementa. En este trabajo, se propone el diseño, implementación y evaluación de un sistema de reconocimiento facial en un escenario de aprendizaje federado, orientado a conjuntos abiertos. Concretamente, se diseña una solución basada en el algoritmo OpenMax para escenarios de aprendizaje federado. La propuesta emplea el intercambio de los vectores de activación promedio y distancias locales para identificar de manera eficaz tanto personas conocidas como desconocidas. Los experimentos realizados demuestran la implementación efectiva de la solución propuesta. 

**Abstract (ZH)**: 基于人工智能的面部识别在特定场景和应用中已实现了高度准确率。然而，它在隐私管理和身份识别方面面临重大挑战，尤其是在出现未知个体的情况下。本文提出了一个面向开放集场景的联邦学习框架下的面部识别系统的设计、实现与评估。所提出的方法将OpenMax算法整合到联邦学习中，利用平均激活向量和局部距离度量的交换来可靠地区分已知和未知个体。实验结果验证了该方案的有效性，展示了其在分布式环境中增强隐私保护和鲁棒面部识别的潜力。 

---
# Advancements in Crop Analysis through Deep Learning and Explainable AI 

**Title (ZH)**: 通过深度学习和可解释人工智能在作物分析领域的进展 

**Authors**: Hamza Khan  

**Link**: [PDF](https://arxiv.org/pdf/2508.19307)  

**Abstract**: Rice is a staple food of global importance in terms of trade, nutrition, and economic growth. Among Asian nations such as China, India, Pakistan, Thailand, Vietnam and Indonesia are leading producers of both long and short grain varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To ensure consumer satisfaction and strengthen national reputations, monitoring rice crops and grain quality is essential. Manual inspection, however, is labour intensive, time consuming and error prone, highlighting the need for automated solutions for quality control and yield improvement. This study proposes an automated approach to classify five rice grain varieties using Convolutional Neural Networks (CNN). A publicly available dataset of 75000 images was used for training and testing. Model evaluation employed accuracy, recall, precision, F1-score, ROC curves, and confusion matrices. Results demonstrated high classification accuracy with minimal misclassifications, confirming the model effectiveness in distinguishing rice varieties. In addition, an accurate diagnostic method for rice leaf diseases such as Brown Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined explainable artificial intelligence (XAI) with deep learning models including CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) revealed how specific grain and leaf features influenced predictions, enhancing model transparency and reliability. The findings demonstrate the strong potential of deep learning in agricultural applications, paving the way for robust, interpretable systems that can support automated crop quality inspection and disease diagnosis, ultimately benefiting farmers, consumers, and the agricultural economy. 

**Abstract (ZH)**: 水稻作为全球贸易、营养和经济增长中的重要主食，其种植和品质监控至关重要。中国、印度、巴基斯坦、泰国、越南和印度尼西亚等亚洲国家是长粒和短粒稻米（如 basmati、jasmine、arborio、ipsala 和 kainat saila）的主要生产国。为了确保消费者满意度和增强国家声誉，监控稻米作物和谷物品质是必不可少的。然而，手工检查劳动密集、耗时且容易出错，因此需要自动化的解决方案以提高产品质量和产量。本研究提出了一种使用卷积神经网络（CNN）自动分类五种稻米品种的方法。使用公开可用的75000张图像数据集进行训练和测试。模型评估采用准确率、召回率、精确率、F1分数、ROC曲线和混淆矩阵。结果表明分类准确性高且误分类少，证明了模型在区分稻米品种方面的有效性。此外，还开发了一种准确的稻叶病害诊断方法，如褐斑病、稻blast病、细菌性条斑病和稻文格病。该框架结合了可解释的人工智能（XAI）与深度学习模型，包括CNN、VGG16、ResNet50和MobileNetV2。通过SHAP（SHapley Additive exPlanations）和LIME（Local Interpretable Model-agnostic Explanations）等可解释性技术揭示了特定的谷粒和叶片特征如何影响预测，提高了模型的透明度和可靠性。研究结果展示了深度学习在农业应用中的巨大潜力，为建立稳健且可解释的系统铺平了道路，这些系统可以支持自动化的作物品质检测和病害诊断，最终造福农民、消费者和农业生产。 

---
# Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities 

**Title (ZH)**: Geo2Vec: 具有形状和距离感知的地理空间实体神经表示 

**Authors**: Chen Chu, Cyrus Shahabi  

**Link**: [PDF](https://arxiv.org/pdf/2508.19305)  

**Abstract**: Spatial representation learning is essential for GeoAI applications such as urban analytics, enabling the encoding of shapes, locations, and spatial relationships (topological and distance-based) of geo-entities like points, polylines, and polygons. Existing methods either target a single geo-entity type or, like Poly2Vec, decompose entities into simpler components to enable Fourier transformation, introducing high computational cost. Moreover, since the transformed space lacks geometric alignment, these methods rely on uniform, non-adaptive sampling, which blurs fine-grained features like edges and boundaries. To address these limitations, we introduce Geo2Vec, a novel method inspired by signed distance fields (SDF) that operates directly in the original space. Geo2Vec adaptively samples points and encodes their signed distances (positive outside, negative inside), capturing geometry without decomposition. A neural network trained to approximate the SDF produces compact, geometry-aware, and unified representations for all geo-entity types. Additionally, we propose a rotation-invariant positional encoding to model high-frequency spatial variations and construct a structured and robust embedding space for downstream GeoAI models. Empirical results show that Geo2Vec consistently outperforms existing methods in representing shape and location, capturing topological and distance relationships, and achieving greater efficiency in real-world GeoAI applications. Code and Data can be found at: this https URL. 

**Abstract (ZH)**: 空间表示学习对于地理人工智能（GeoAI）应用如城市分析至关重要，能够编码地理实体（如点、多段线和多边形）的形状、位置和空间关系（拓扑和距离基的）。现有方法要么仅针对单一地理实体类型，要么如Poly2Vec那样将实体分解为更简单的组件以启用傅里叶变换，从而引入了高额的计算成本。此外，由于变换空间缺乏几何对齐，这些方法依赖于均匀的非自适应采样，这会模糊边缘和边界等细粒度特征。为了克服这些限制，我们提出了Geo2Vec，这是一种受符号距离场（SDF）启发的新型方法，它直接在原始空间中操作。Geo2Vec自适应地采样点并编码它们的符号距离（外部为正，内部为负），从而捕捉几何结构而无需分解。一个训练以近似符号距离场的神经网络产生紧凑、几何感知且统一的地理实体类型表示。此外，我们提出了一种旋转不变的位置编码来建模高频空间变化，并构建了结构化和健壮的嵌入空间，供下游GeoAI模型使用。实证结果表明，Geo2Vec在表示形状和位置、捕捉拓扑和距离关系以及在实际地理人工智能应用中实现更高效率方面均优于现有方法。代码和数据可在以下链接找到：this https URL。 

---
# Epistemic Trade-Off: An Analysis of the Operational Breakdown and Ontological Limits of "Certainty-Scope" in AI 

**Title (ZH)**: 知识权衡：对“确定性-范围”在AI中的操作失效和本体界限的分析 

**Authors**: Generoso Immediato  

**Link**: [PDF](https://arxiv.org/pdf/2508.19304)  

**Abstract**: Floridi's conjecture offers a compelling intuition about the fundamental trade-off between certainty and scope in artificial intelligence (AI) systems. This exploration remains crucial, not merely as a philosophical exercise, but as a potential compass for guiding AI investments, particularly in safety-critical industrial domains where the level of attention will surely be higher in the future. However, while intellectually coherent, its formalization ultimately freezes this insight into a suspended epistemic truth, resisting operationalization within real-world systems. This paper is a result of an analysis arguing that the conjecture's ambition to provide insights to engineering design and regulatory decision-making is constrained by two critical factors: first, its reliance on incomputable constructs - rendering it practically unactionable and unverifiable; second, its underlying ontological assumption of AI systems as self-contained epistemic entities - separating it from the intricate and dynamic socio-technical environments in which knowledge is co-constructed. We conclude that this dual breakdown - an epistemic closure deficit and an embeddedness bypass - prevents the conjecture from transitioning into a computable and actionable framework suitable for informing the design, deployment, and governance of real-world AI hybrid systems. In response, we propose a contribution to the framing of Floridi's epistemic challenge, addressing the inherent epistemic burdens of AI within complex human-centric domains. 

**Abstract (ZH)**: 福里迪的猜想提供了关于人工智能系统中确定性与范围基本权衡的引人入胜的直觉。这一探索在引导人工智能投资方面仍然至关重要，特别是在今后会更加关注的安全关键工业领域。然而，尽管在概念上是连贯的，其形式化最终将其深刻的见解固化为一种悬置的表徵真理，难以在现实世界的系统中实现操作化。本文是基于分析得出的结论，认为猜想旨在为工程设计和监管决策提供洞见的努力受到两个关键因素的限制：首先，其依赖于不可计算的构造，使其在实践中无法实用和验证；其次，其对人工智能系统的本体论假设为自足的认知实体，使其脱离了知识共同建构的复杂且动态的社会技术环境。我们得出结论认为，这一双重缺陷——认知闭合不足和嵌入性的规避——阻碍了猜想向可用于指导实际人工智能混合系统的计算和可操作框架的转换。对此，我们提出了一种对福里迪的认知挑战的框架性贡献，旨在解决复杂的人类中心领域中人工智能固有的认知负担。 

---
# 2D Ultrasound Elasticity Imaging of Abdominal Aortic Aneurysms Using Deep Neural Networks 

**Title (ZH)**: 使用深度神经网络的腹部主动脉瘤二维超声弹性成像 

**Authors**: Utsav Ratna Tuladhar, Richard Simon, Doran Mix, Michael Richards  

**Link**: [PDF](https://arxiv.org/pdf/2508.19303)  

**Abstract**: Abdominal aortic aneurysms (AAA) pose a significant clinical risk due to their potential for rupture, which is often asymptomatic but can be fatal. Although maximum diameter is commonly used for risk assessment, diameter alone is insufficient as it does not capture the properties of the underlying material of the vessel wall, which play a critical role in determining the risk of rupture. To overcome this limitation, we propose a deep learning-based framework for elasticity imaging of AAAs with 2D ultrasound. Leveraging finite element simulations, we generate a diverse dataset of displacement fields with their corresponding modulus distributions. We train a model with U-Net architecture and normalized mean squared error (NMSE) to infer the spatial modulus distribution from the axial and lateral components of the displacement fields. This model is evaluated across three experimental domains: digital phantom data from 3D COMSOL simulations, physical phantom experiments using biomechanically distinct vessel models, and clinical ultrasound exams from AAA patients. Our simulated results demonstrate that the proposed deep learning model is able to reconstruct modulus distributions, achieving an NMSE score of 0.73\%. Similarly, in phantom data, the predicted modular ratio closely matches the expected values, affirming the model's ability to generalize to phantom data. We compare our approach with an iterative method which shows comparable performance but higher computation time. In contrast, the deep learning method can provide quick and effective estimates of tissue stiffness from ultrasound images, which could help assess the risk of AAA rupture without invasive procedures. 

**Abstract (ZH)**: 基于深度学习的二维超声腹主动脉瘤弹性成像框架 

---
# CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy 

**Title (ZH)**: CellINR: 隐式克服4D实时荧光显微镜中的光诱导伪影 

**Authors**: Cunmin Zhao, Ziyuan Luo, Guoye Guan, Zelin Li, Yiming Ma, Zhongying Zhao, Renjie Wan  

**Link**: [PDF](https://arxiv.org/pdf/2508.19300)  

**Abstract**: 4D live fluorescence microscopy is often compromised by prolonged high intensity illumination which induces photobleaching and phototoxic effects that generate photo-induced artifacts and severely impair image continuity and detail recovery. To address this challenge, we propose the CellINR framework, a case-specific optimization approach based on implicit neural representation. The method employs blind convolution and structure amplification strategies to map 3D spatial coordinates into the high frequency domain, enabling precise modeling and high-accuracy reconstruction of cellular structures while effectively distinguishing true signals from artifacts. Experimental results demonstrate that CellINR significantly outperforms existing techniques in artifact removal and restoration of structural continuity, and for the first time, a paired 4D live cell imaging dataset is provided for evaluating reconstruction performance, thereby offering a solid foundation for subsequent quantitative analyses and biological research. The code and dataset will be public. 

**Abstract (ZH)**: 4D活细胞荧光显微镜往往受到长时间高强度 illumination 的影响，导致光淬灭和光毒性效应，产生光诱导的伪影，严重影响图像连续性和细节恢复。为应对这一挑战，我们提出CellINR框架，这是一种基于隐式神经表示的案例特定优化方法。该方法采用盲卷积和结构放大策略，将3D空间坐标映射到高频域，从而能够精确建模和高精度重建细胞结构，同时有效区分真实信号和伪影。实验结果表明，CellINR在伪影去除和结构连续性恢复方面显著优于现有技术，并首次提供了配对的4D活细胞成像数据集，用于评估重建性能，从而为后续定量分析和生物研究提供了坚实的基础。代码和数据集将公开。 

---
# DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models 

**Title (ZH)**: DemoBias: 跟踪视觉基础模型中的人口统计偏见的实证研究 

**Authors**: Abu Sufian, Anirudha Ghosh, Debaditya Barman, Marco Leo, Cosimo Distante  

**Link**: [PDF](https://arxiv.org/pdf/2508.19298)  

**Abstract**: Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities across various downstream tasks, including biometric face recognition (FR) with description. However, demographic biases remain a critical concern in FR, as these foundation models often fail to perform equitably across diverse demographic groups, considering ethnicity/race, gender, and age. Therefore, through our work DemoBias, we conduct an empirical evaluation to investigate the extent of demographic biases in LVLMs for biometric FR with textual token generation tasks. We fine-tuned and evaluated three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own generated demographic-balanced dataset. We utilize several evaluation metrics, like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify and trace the performance disparities. The experimental results deliver compelling insights into the fairness and reliability of LVLMs across diverse demographic groups. Our empirical study uncovered demographic biases in LVLMs, with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino, Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably consistent. Repository: this https URL. 

**Abstract (ZH)**: 大规模视觉语言模型（LVLMs）在各种下游任务中展示了显著的能力，包括带有描述的生物特征面部识别（FR）。然而，人口统计学偏见仍然是FR中的一个关键问题，因为这些基础模型往往在不同的族群群体中表现不公，考虑族裔/种族、性别和年龄。因此，通过我们的工作DemoBias，我们进行了一项实证评估，以调查LVLMs在生物特征FR中的人口统计学偏见程度，特别是在带有文本标记生成任务的情况下。我们使用了一个自己生成的人口统计学平衡数据集对三个广泛使用的预训练LVLMs：LLaVA、BLIP-2和PaliGemma进行了微调和评估。我们使用多种评估指标，如群体特定的BERTScores和公平性差距率，来量化和追踪性能差异。实验结果提供了关于LVLMs在不同人口统计学群体中的公平性和可靠性的深刻见解。我们的实证研究发现了LVLMs中的人口统计学偏见，其中PaliGemma和LLaVA在西班牙裔/拉丁裔、 Caucasian 和南亚群体中表现出更高的差异，而BLIP-2则表现出相对一致的性能。仓库：this https URL 

---
# Object Detection with Multimodal Large Vision-Language Models: An In-depth Review 

**Title (ZH)**: 基于多模态大型视觉-语言模型的目标检测：深入综述 

**Authors**: Ranjan Sapkota, Manoj Karkee  

**Link**: [PDF](https://arxiv.org/pdf/2508.19294)  

**Abstract**: The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization beyond traditional architectures. This in-depth review presents a structured exploration of the state-of-the-art in LVLMs, systematically organized through a three-step research review process. First, we discuss the functioning of vision language models (VLMs) for object detection, describing how these models harness natural language processing (NLP) and computer vision (CV) techniques to revolutionize object detection and localization. We then explain the architectural innovations, training paradigms, and output flexibility of recent LVLMs for object detection, highlighting how they achieve advanced contextual understanding for object detection. The review thoroughly examines the approaches used in integration of visual and textual information, demonstrating the progress made in object detection using VLMs that facilitate more sophisticated object detection and localization strategies. This review presents comprehensive visualizations demonstrating LVLMs' effectiveness in diverse scenarios including localization and segmentation, and then compares their real-time performance, adaptability, and complexity to traditional deep learning systems. Based on the review, its is expected that LVLMs will soon meet or surpass the performance of conventional methods in object detection. The review also identifies a few major limitations of the current LVLM modes, proposes solutions to address those challenges, and presents a clear roadmap for the future advancement in this field. We conclude, based on this study, that the recent advancement in LVLMs have made and will continue to make a transformative impact on object detection and robotic applications in the future. 

**Abstract (ZH)**: 大型视觉语言模型中语言与视觉的融合 revolutionized 基于深度学习的目标检测，提高了传统架构之外的适应性、上下文推理和泛化能力。本深入综述通过三步研究评审过程系统地探讨了大型视觉语言模型的最新进展，首先讨论了视觉语言模型（VLMs）在目标检测中的功能，阐述了这些模型如何利用自然语言处理（NLP）和计算机视觉（CV）技术革新目标检测和定位。随后解释了最近的大型视觉语言模型在目标检测方面的架构创新、训练范式和输出灵活性，突显了它们如何实现高级的上下文理解。该综述详细分析了视觉和文本信息集成的方法，展示了使用VLMs进行目标检测取得的进步，促进了更复杂的物体检测与定位策略。该综述还提供了全面的可视化演示，展示了大型视觉语言模型在包括定位和分割在内的各种场景中的有效性，并将其实时性能、适应性和复杂性与传统深度学习系统进行了比较。基于此综述，预计大型视觉语言模型不久将在目标检测中达到或超过传统方法的性能。此外，该综述还指出了当前大型视觉语言模型的几个主要局限性，提出了应对这些挑战的解决方案，并指明了该领域未来发展的清晰路径。本综述基于这一研究得出结论，认为近期在大型视觉语言模型方面的进展及其未来将进一步革新目标检测和机器人应用。 

---
# Stand on The Shoulders of Giants: Building JailExpert from Previous Attack Experience 

**Title (ZH)**: 站在巨人的肩膀上：基于先前攻击经验构建JailExpert 

**Authors**: Xi Wang, Songlei Jian, Shasha Li, Xiaopeng Li, Bin Ji, Jun Ma, Xiaodong Liu, Jing Wang, Feilong Bao, Jianfeng Zhang, Baosheng Wang, Jie Yu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19292)  

**Abstract**: Large language models (LLMs) generate human-aligned content under certain safety constraints. However, the current known technique ``jailbreak prompt'' can circumvent safety-aligned measures and induce LLMs to output malicious content. Research on Jailbreaking can help identify vulnerabilities in LLMs and guide the development of robust security frameworks. To circumvent the issue of attack templates becoming obsolete as models evolve, existing methods adopt iterative mutation and dynamic optimization to facilitate more automated jailbreak attacks. However, these methods face two challenges: inefficiency and repetitive optimization, as they overlook the value of past attack experiences. To better integrate past attack experiences to assist current jailbreak attempts, we propose the \textbf{JailExpert}, an automated jailbreak framework, which is the first to achieve a formal representation of experience structure, group experiences based on semantic drift, and support the dynamic updating of the experience pool. Extensive experiments demonstrate that JailExpert significantly improves both attack effectiveness and efficiency. Compared to the current state-of-the-art black-box jailbreak methods, JailExpert achieves an average increase of 17\% in attack success rate and 2.7 times improvement in attack efficiency. Our implementation is available at \href{this https URL}{XiZaiZai/JailExpert} 

**Abstract (ZH)**: 大型语言模型（LLMs）在特定安全约束下生成人类对齐的内容。然而，当前已知的“逃逸提示”技术可以规避安全对齐的措施，使LLMs生成恶意内容。对“逃逸”的研究有助于识别LLMs中的漏洞并指导开发 robust 的安全框架。为解决攻击模板随着模型进化而变得过时的问题，现有方法采用迭代变异和动态优化以促进更自动化的逃逸攻击。然而，这些方法面临两个挑战：低效率和重复优化，因为它们忽视了过往攻击经验的价值。为了更好地整合过往攻击经验以协助当前的逃逸尝试，我们提出了\textbf{JailExpert}，这是一个自动化的逃逸框架，它首次实现了经验结构的形式化表示、根据语义漂移对经验进行分组，并支持经验池的动态更新。广泛实验表明，JailExpert 显著提升了攻击效果和效率。与当前最先进的黑盒逃逸方法相比，JailExpert 在攻击成功率上平均提高了17%，在攻击效率上提高了2.7倍。我们的实现可在\href{this https URL}{XiZaiZai/JailExpert}获取。 

---
# Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation 

**Title (ZH)**: 基于模型的有效对抗攻击 LidAR 分割净化方法 

**Authors**: Alexandros Gkillas, Ioulia Kapsali, Nikos Piperigkos, Aris S. Lalos  

**Link**: [PDF](https://arxiv.org/pdf/2508.19290)  

**Abstract**: LiDAR-based segmentation is essential for reliable perception in autonomous vehicles, yet modern segmentation networks are highly susceptible to adversarial attacks that can compromise safety. Most existing defenses are designed for networks operating directly on raw 3D point clouds and rely on large, computationally intensive generative models. However, many state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D range view representations. Despite their widespread adoption, dedicated lightweight adversarial defenses for this domain remain largely unexplored. We introduce an efficient model-based purification framework tailored for adversarial defense in 2D range-view LiDAR segmentation. We propose a direct attack formulation in the range-view domain and develop an explainable purification network based on a mathematical justified optimization problem, achieving strong adversarial resilience with minimal computational overhead. Our method achieves competitive performance on open benchmarks, consistently outperforming generative and adversarial training baselines. More importantly, real-world deployment on a demo vehicle demonstrates the framework's ability to deliver accurate operation in practical autonomous driving scenarios. 

**Abstract (ZH)**: 基于LiDAR的分割对于自动驾驶车辆的可靠感知至关重要，但现代分割网络极易受到可能危及安全的 adversarial 攻击。现有的大多数防护措施针对的是直接操作原始 3D 点云的网络，并依赖于大型且计算密集的生成模型。然而，许多最先进的 LiDAR 分割流水线在更高效的 2D 范围图表示上操作。尽管这类表示被广泛应用，但针对该领域的专用轻量级 adversarial 防护措施仍鲜有研究。我们提出了一种针对 2D 范围图 LiDAR 分割的高效模型导向净化框架，用于 adversarial 防护。我们在范围图域中提出了一个直接攻击形式，并基于数学证明的优化问题开发了一个可解释的净化网络，实现了强 adversarial 抗性并具有最小的计算开销。我们的方法在开放基准测试中表现出竞争性性能，一致优于生成性和对抗性训练基线。更重要的是，在演示车辆上的实际部署展示了该框架在实际自动驾驶场景中提供准确操作的能力。 

---
# Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation 

**Title (ZH)**: 没有设计师的视角：基于设计师线索增强的无监督幻灯片质量评估研究 

**Authors**: Tai Inui, Steven Oh, Magdeline Kuan  

**Link**: [PDF](https://arxiv.org/pdf/2508.19289)  

**Abstract**: We present an unsupervised slide-quality assessment pipeline that combines seven expert-inspired visual-design metrics (whitespace, colorfulness, edge density, brightness contrast, text density, color harmony, layout balance) with CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate presentation slides. Trained on 12k professional lecture slides and evaluated on six academic talks (115 slides), our method achieved Pearson correlations up to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual ratings, discriminant validity against speaker-delivery scores, and exploratory alignment with overall impressions. Our results show that augmenting low-level design cues with multimodal embeddings closely approximates audience perceptions of slide quality, enabling scalable, objective feedback in real time. 

**Abstract (ZH)**: 一种结合七种专家启发的视觉设计指标和CLIP-ViT嵌入的无监督幻灯片质量评估管道：基于孤立森林异常评分的方法及其与人类视觉质量评级的相关性分析 

---
# Tricking LLM-Based NPCs into Spilling Secrets 

**Title (ZH)**: 欺骗基于LLM的NPC透露秘密 

**Authors**: Kyohei Shiomi, Zhuotao Lian, Toru Nakanishi, Teruaki Kitasuka  

**Link**: [PDF](https://arxiv.org/pdf/2508.19288)  

**Abstract**: Large Language Models (LLMs) are increasingly used to generate dynamic dialogue for game NPCs. However, their integration raises new security concerns. In this study, we examine whether adversarial prompt injection can cause LLM-based NPCs to reveal hidden background secrets that are meant to remain undisclosed. 

**Abstract (ZH)**: 大型语言模型（LLMs）越来越多地用于生成游戏NPC的动态对话。然而，它们的集成引发了新的安全问题。本研究探讨了敌对提示注入是否能使基于LLM的NPC泄露本应保密的隐藏背景秘密。 

---
# Prompt-in-Content Attacks: Exploiting Uploaded Inputs to Hijack LLM Behavior 

**Title (ZH)**: 内容中嵌入式攻击：利用上传输入劫持LLM行为 

**Authors**: Zhuotao Lian, Weiyu Wang, Qingkui Zeng, Toru Nakanishi, Teruaki Kitasuka, Chunhua Su  

**Link**: [PDF](https://arxiv.org/pdf/2508.19287)  

**Abstract**: Large Language Models (LLMs) are widely deployed in applications that accept user-submitted content, such as uploaded documents or pasted text, for tasks like summarization and question answering. In this paper, we identify a new class of attacks, prompt in content injection, where adversarial instructions are embedded in seemingly benign inputs. When processed by the LLM, these hidden prompts can manipulate outputs without user awareness or system compromise, leading to biased summaries, fabricated claims, or misleading suggestions. We demonstrate the feasibility of such attacks across popular platforms, analyze their root causes including prompt concatenation and insufficient input isolation, and discuss mitigation strategies. Our findings reveal a subtle yet practical threat in real-world LLM workflows. 

**Abstract (ZH)**: 大型语言模型中的内容注入式提示攻击 

---
# RL-Finetuned LLMs for Privacy-Preserving Synthetic Rewriting 

**Title (ZH)**: 基于RL微调的隐私保护合成重写预训练模型 

**Authors**: Zhan Shi, Yefeng Yuan, Yuhong Liu, Liang Cheng, Yi Fang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19286)  

**Abstract**: The performance of modern machine learning systems depends on access to large, high-quality datasets, often sourced from user-generated content or proprietary, domain-specific corpora. However, these rich datasets inherently contain sensitive personal information, raising significant concerns about privacy, data security, and compliance with regulatory frameworks. While conventional anonymization techniques can remove explicit identifiers, such removal may result in performance drop in downstream machine learning tasks. More importantly, simple anonymization may not be effective against inference attacks that exploit implicit signals such as writing style, topical focus, or demographic cues, highlighting the need for more robust privacy safeguards during model training. To address the challenging issue of balancing user privacy and data utility, we propose a reinforcement learning framework that fine-tunes a large language model (LLM) using a composite reward function that jointly optimizes for explicit and implicit privacy, semantic fidelity, and output diversity. To effectively capture population level regularities, the privacy reward combines semantic cues with structural patterns derived from a minimum spanning tree (MST) over latent representations. By modeling these privacy-sensitive signals in their distributional context, the proposed approach guides the model to generate synthetic rewrites that preserve utility while mitigating privacy risks. Empirical results show that the proposed method significantly enhances author obfuscation and privacy metrics without degrading semantic quality, providing a scalable and model-agnostic solution for privacy preserving data generation in the era of large language models. 

**Abstract (ZH)**: 现代机器学习系统的表现取决于对大规模高质量数据集的访问，这些数据集通常源自用户生成的内容或专有领域特定语料库。然而，这些丰富数据集内固含敏感个人信息，引发了重大关于隐私、数据安全和合规性方面的问题。虽然传统的匿名化技术可以去除显式标识符，但这种去除可能会导致下游机器学习任务性能下降。更重要的是，简单的匿名化方法可能无法有效抵御利用写作风格、主题焦点或人口统计线索进行的推理攻击，强调了在模型训练过程中需要更强的隐私保护措施。为解决用户隐私和数据效用之间的挑战性问题，我们提出了一种强化学习框架，该框架通过结合显式和隐式隐私、语义保真度和输出多样性来 fine-tune 大型语言模型（LLM）。为了有效捕捉整体规律，隐私奖励结合了语义线索和从潜在表示的最小生成树（MST）中派生的结构模式。通过在分布上下文中建模这些隐私敏感信号，所提出的方法引导模型生成既能保持效用又能减轻隐私风险的合成重写。实验结果表明，所提出的方法在不牺牲语义质量的情况下显著提高了作者混淆度和隐私指标，提供了一种可扩展且模型无关的解决方案，用于大型语言模型时代的数据生成隐私保护。 

---
# CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning 

**Title (ZH)**: CORE：通过强化学习实现检索增强LLM的无损压缩 

**Authors**: Ziqiang Cui, Yunpeng Weng, Xing Tang, Peiyang Liu, Shiwei Li, Bowei He, Jiamin Chen, Xiuqiang He, Chen Ma  

**Link**: [PDF](https://arxiv.org/pdf/2508.19282)  

**Abstract**: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantially increases the input length, leading to higher computational costs. Previous studies have attempted to compress retrieved documents into shorter texts before in-context integration, but such methods often compromise end-task performance. The lack of well-defined compression targets forces many approaches to rely on fixed heuristics, which cannot guarantee that the compressed content will effectively support the end task. To address these limitations, we propose CORE, a novel method designed to achieve lossless context compression for RAG. CORE employs reinforcement learning to optimize the compression process without relying on predefined compression labels. Specifically, it utilizes end-task performance as a reward signal and applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train the compressor. This end-to-end training framework enables the compressor to generate summaries that maximize the accuracy of answers generated by the LLM. Extensive experiments on four datasets demonstrate the superiority of our approach. With a high compression ratio of 3\%, our method not only avoids performance degradation compared to prepending full documents across all datasets but also improves the average Exact Match (EM) score by 3.3 points. The code will be released soon. 

**Abstract (ZH)**: 基于检索增强生成的上下文压缩方法CORE 

---
# CORTEX: Composite Overlay for Risk Tiering and Exposure in Operational AI Systems 

**Title (ZH)**: Cortex: 组合overlay用于运营AI系统的风险分层与暴露管理 

**Authors**: Aoun E Muhammad, Kin Choong Yow, Jamel Baili, Yongwon Cho, Yunyoung Nam  

**Link**: [PDF](https://arxiv.org/pdf/2508.19281)  

**Abstract**: As the deployment of Artificial Intelligence (AI) systems in high-stakes sectors - like healthcare, finance, education, justice, and infrastructure has increased - the possibility and impact of failures of these systems have significantly evolved from being a theoretical possibility to practical recurring, systemic risk. This paper introduces CORTEX (Composite Overlay for Risk Tiering and Exposure), a multi-layered risk scoring framework proposed to assess and score AI system vulnerabilities, developed on empirical analysis of over 1,200 incidents documented in the AI Incident Database (AIID), CORTEX categorizes failure modes into 29 technical vulnerability groups. Each vulnerability is scored through a five-tier architecture that combines: (1) utility-adjusted Likelihood x Impact calculations; (2) governance + contextual overlays aligned with regulatory frameworks, such as the EU AI Act, NIST RMF, OECD principles; (3) technical surface scores, covering exposure vectors like drift, traceability, and adversarial risk; (4) environmental and residual modifiers tailored to context of where these systems are being deployed to use; and (5) a final layered assessment via Bayesian risk aggregation and Monte Carlo simulation to model volatility and long-tail risks. The resulting composite score can be operationalized across AI risk registers, model audits, conformity checks, and dynamic governance dashboards. 

**Abstract (ZH)**: 随着人工智能系统在高 stakes 领域（如医疗、金融、教育、司法和基础设施）中的部署增加，这些系统失败的可能性和影响已经从理论上的可能性转变为实际的、反复出现的系统性风险。本文介绍了CORTEX（综合风险分层和暴露框架），这是一种多层风险评分框架，旨在评估和评分人工智能系统的漏洞，该框架基于对AI事件数据库（AIID）中记录的超过1,200起事件的实证分析。CORTEX将失败模式分类为29个技术漏洞组。每个漏洞通过五层架构进行评分，该架构结合了：（1）调整后的效用×影响计算；（2）与法规框架（如欧盟人工智能法案、NIST RMF、OECD原则）对齐的治理+情境叠加；（3）技术表面评分，涵盖漂移、可追溯性和对抗性风险等暴露向量；（4）针对这些系统部署环境量身定制的环境和剩余调整；以及（5）通过贝叶斯风险聚合和蒙特卡洛模拟进行的最终多层评估，以建模波动性和长尾风险。由此产生的综合评分可以在人工智能风险登记册、模型审计、符合性检查和动态治理仪表板中操作化。 

---
# FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series 

**Title (ZH)**: FLAIRR-TS —— 预测LLM代理的时间序列方法，基于迭代精炼和检索 

**Authors**: Gunjan Jalori, Preetika Verma, Sercan Ö Arık  

**Link**: [PDF](https://arxiv.org/pdf/2508.19279)  

**Abstract**: Time series Forecasting with large languagemodels (LLMs) requires bridging numericalpatterns and natural language. Effective fore-casting on LLM often relies on extensive pre-processing and this http URL studiesshow that a frozen LLM can rival specializedforecasters when supplied with a carefully en-gineered natural-language prompt, but craft-ing such a prompt for each task is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt optimization framework thatutilizes an agentic system: a Forecaster-agentgenerates forecasts using an initial prompt,which is then refined by a refiner agent, in-formed by past outputs and retrieved this http URL adaptive prompting generalizes across do-mains using creative prompt templates andgenerates high-quality forecasts without inter-mediate code this http URL onbenchmark datasets show improved accuracyover static prompting and retrieval-augmentedbaselines, approaching the performance ofspecialized this http URL-TS providesa practical alternative to tuning, achievingstrong performance via its agentic approach toadaptive prompt refinement and retrieval. 

**Abstract (ZH)**: 带有大规模语言模型的时间序列 Forecasting 需要跨越数值模式和自然语言。有效的 LLM 时间序列 Forecasting 往往依赖于大量的预处理。本研究显示，当提供精心设计的自然语言提示时，冻结的 LLM 可以与专门的 Forecasters 十分竞争，但为每个任务设计这样的提示本身是耗时且零碎的工作。我们引入了 FLAIRR-TS，一种测试时提示优化框架，利用了一个代理系统：Forecasting 代理使用初始提示生成预报，然后由优化剂代理进行改进，优化剂代理受到过往输出的启发并检索相关信息，这种适应性提示模板在不同领域中具有创造力，并且能够生成高质量的预报而无需中间代码。在基准数据集上的实验表明，FLAIRR-TS 在准确性方面优于静态提示和检索增强的基本模型，接近专门的 TS 表现。FLAIRR-TS 提供了一种实用的调优替代方案，通过其代理式的方法实现了适配性和检索增强，实现了强健的表现。 

---
# Towards Production-Worthy Simulation for Autonomous Cyber Operations 

**Title (ZH)**: 面向自主网络操作的生产级仿真研究 

**Authors**: Konur Tholl, Mariam El Mezouar, Ranwa Al Mallah  

**Link**: [PDF](https://arxiv.org/pdf/2508.19278)  

**Abstract**: Simulated environments have proven invaluable in Autonomous Cyber Operations (ACO) where Reinforcement Learning (RL) agents can be trained without the computational overhead of emulation. These environments must accurately represent cybersecurity scenarios while producing the necessary signals to support RL training. In this study, we present a framework where we first extend CybORG's Cage Challenge 2 environment by implementing three new actions: Patch, Isolate, and Unisolate, to better represent the capabilities available to human operators in real-world settings. We then propose a design for agent development where we modify the reward signals and the agent's feature space to enhance training performance. To validate these modifications, we train DQN and PPO agents in the updated environment. Our study demonstrates that CybORG can be extended with additional realistic functionality, while maintaining its ability to generate informative training signals for RL agents. 

**Abstract (ZH)**: 模拟环境在自主网络操作（ACO）中的应用已证明极为宝贵，其中强化学习（RL）代理可以在不需要模拟计算开销的情况下进行训练。这些环境必须准确地代表网络安全场景，并生成支持RL训练所需的信号。在本研究中，我们提出了一种框架，首先通过实现三种新动作（补丁、隔离和解隔离）扩展CybORG的Cage Challenge 2环境，以更好地反映真实世界中人工操作员的可用能力。然后，我们提出了一种代理开发的设计，通过修改奖励信号和代理的特征空间来提升训练性能。为了验证这些修改，我们在更新后的环境中训练了DQN和PPO代理。我们的研究证明，CybORG可以扩展以增加额外的现实功能，同时仍保留生成支持RL代理的训练信号的能力。 

---
# POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization 

**Title (ZH)**: POT: 通过黑盒迭代优化诱导大语言模型过度思考 

**Authors**: Xinyu Li, Tianjin Huang, Ronghui Mu, Xiaowei Huang, Gaojie Jin  

**Link**: [PDF](https://arxiv.org/pdf/2508.19277)  

**Abstract**: Recent advances in Chain-of-Thought (CoT) prompting have substantially enhanced the reasoning capabilities of large language models (LLMs), enabling sophisticated problem-solving through explicit multi-step reasoning traces. However, these enhanced reasoning processes introduce novel attack surfaces, particularly vulnerabilities to computational inefficiency through unnecessarily verbose reasoning chains that consume excessive resources without corresponding performance gains. Prior overthinking attacks typically require restrictive conditions including access to external knowledge sources for data poisoning, reliance on retrievable poisoned content, and structurally obvious templates that limit practical applicability in real-world scenarios. To address these limitations, we propose POT (Prompt-Only OverThinking), a novel black-box attack framework that employs LLM-based iterative optimization to generate covert and semantically natural adversarial prompts, eliminating dependence on external data access and model retrieval. Extensive experiments across diverse model architectures and datasets demonstrate that POT achieves superior performance compared to other methods. 

**Abstract (ZH)**: Recent Advances in Chain-of-Thought (CoT) Prompting Localization: Overcoming Limitations with POT (Prompt-Only OverThinking) 

---
# MixGAN: A Hybrid Semi-Supervised and Generative Approach for DDoS Detection in Cloud-Integrated IoT Networks 

**Title (ZH)**: MixGAN：一种用于云集成物联网网络中的DDoS检测的混合半监督生成方法 

**Authors**: Tongxi Wu, Chenwei Xu, Jin Yang  

**Link**: [PDF](https://arxiv.org/pdf/2508.19273)  

**Abstract**: The proliferation of cloud-integrated IoT systems has intensified exposure to Distributed Denial of Service (DDoS) attacks due to the expanded attack surface, heterogeneous device behaviors, and limited edge protection. However, DDoS detection in this context remains challenging because of complex traffic dynamics, severe class imbalance, and scarce labeled data. While recent methods have explored solutions to address class imbalance, many still struggle to generalize under limited supervision and dynamic traffic conditions. To overcome these challenges, we propose MixGAN, a hybrid detection method that integrates conditional generation, semi-supervised learning, and robust feature extraction. Specifically, to handle complex temporal traffic patterns, we design a 1-D WideResNet backbone composed of temporal convolutional layers with residual connections, which effectively capture local burst patterns in traffic sequences. To alleviate class imbalance and label scarcity, we use a pretrained CTGAN to generate synthetic minority-class (DDoS attack) samples that complement unlabeled data. Furthermore, to mitigate the effect of noisy pseudo-labels, we introduce a MixUp-Average-Sharpen (MAS) strategy that constructs smoothed and sharpened targets by averaging predictions over augmented views and reweighting them towards high-confidence classes. Experiments on NSL-KDD, BoT-IoT, and CICIoT2023 demonstrate that MixGAN achieves up to 2.5% higher accuracy and 4% improvement in both TPR and TNR compared to state-of-the-art methods, confirming its robustness in large-scale IoT-cloud environments. The source code is publicly available at this https URL. 

**Abstract (ZH)**: 云集成IoT系统的 proliferance 加剧了分布式拒绝服务（DDoS）攻击的暴露程度，由于攻击面的扩展、异构设备行为以及边缘保护的限制。然而，在这种背景下，DDoS检测仍然具有挑战性，原因在于复杂的流量动态、严重的类别不平衡以及稀缺的标签数据。尽管近期方法探索了解决类别不平衡的方案，但在有限监督和动态流量条件下，许多方法仍然难以泛化。为了克服这些挑战，我们提出MixGAN，一种结合条件生成、半监督学习和稳健特征提取的混合检测方法。具体而言，为了处理复杂的时空流量模式，我们设计了一个由具有残差连接的时间卷积层组成的1-D WideResNet骨干网络，有效地捕捉流量序列中的局部突发模式。为了缓解类别不平衡和标签稀缺问题，我们使用预训练的CTGAN生成补充无标签数据的合成少数类（DDoS攻击）样本。为进一步减轻嘈杂伪标签的影响，我们引入了MixUp-Average-Sharpen (MAS) 策略，通过在增强视图上平均预测并重新加权以朝向高置信度类别构建平滑和加硬的目标。在NSL-KDD、BoT-IoT和CICIoT2023上的实验表明，MixGAN的准确率最高可提高2.5%，TPR和TNR均值提高4%，证实了其在大规模IoT-云环境中的鲁棒性。源代码已在以下网址公开。 

---
# Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT 

**Title (ZH)**: 重新思考LLMs中的推理：超越ICL和CoT的神经符号局部重优化 

**Authors**: Rushitha Santhoshi Mamidala, Anshuman Chhabra, Ankur Mali  

**Link**: [PDF](https://arxiv.org/pdf/2508.19271)  

**Abstract**: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and In-Context Learning (ICL) have become widely used for eliciting reasoning capabilities in large language models (LLMs). However, these methods rely on fragile, implicit mechanisms often yielding inconsistent outputs across seeds, formats, or minor prompt variations making them fundamentally unreliable for tasks requiring stable, interpretable reasoning. In contrast, automata-based neuro-symbolic frameworks like RetoMaton offer a more structured and trustworthy alternative by grounding retrieval in symbolic memory with deterministic transitions. In this work, we extend RetoMaton by replacing its global datastore with a local, task-adaptive Weighted Finite Automaton (WFA), constructed directly from external domain corpora. This local automaton structure promotes robust, context-aware retrieval while preserving symbolic traceability and low inference overhead. Unlike prompting, which entangles context and memory in opaque ways, our approach leverages the explicit structure of WFAs to provide verifiable and modular retrieval behavior, making it better suited for domain transfer and interoperability. We evaluate this local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT across three reasoning tasks: TriviaQA (reading comprehension), GSM8K (multi-step math), and MMLU (domain knowledge). Compared to the base model and prompting-based methods, augmenting these setups with local RetoMaton consistently improves performance while enabling transparent and reproducible retrieval dynamics. Our results highlight a promising shift toward trustworthy, symbolic reasoning in modern LLMs via lightweight, automaton-guided memory. 

**Abstract (ZH)**: 基于自动机的神经符号框架如RetoMaton通过使用局部适应的加权有限自动机（WFA）替代全局数据存储，为大型语言模型（LLMs）提供了更为结构化和可信赖的推理能力。 

---
# Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English 

**Title (ZH)**: 基于Whisper的越英跨语言音素识别 

**Authors**: Nguyen Huu Nhat Minh, Tran Nguyen Anh, Truong Dinh Dung, Vo Van Nam, Le Pham Tuyen  

**Link**: [PDF](https://arxiv.org/pdf/2508.19270)  

**Abstract**: Cross-lingual phoneme recognition has emerged as a significant challenge for accurate automatic speech recognition (ASR) when mixing Vietnamese and English pronunciations. Unlike many languages, Vietnamese relies on tonal variations to distinguish word meanings, whereas English features stress patterns and non-standard pronunciations that hinder phoneme alignment between the two languages. To address this challenge, we propose a novel bilingual speech recognition approach with two primary contributions: (1) constructing a representative bilingual phoneme set that bridges the differences between Vietnamese and English phonetic systems; (2) designing an end-to-end system that leverages the PhoWhisper pre-trained encoder for deep high-level representations to improve phoneme recognition. Our extensive experiments demonstrate that the proposed approach not only improves recognition accuracy in bilingual speech recognition for Vietnamese but also provides a robust framework for addressing the complexities of tonal and stress-based phoneme recognition 

**Abstract (ZH)**: 跨语言音素识别已成为混合越南语和英语发音时准确自动语音识别（ASR）的一个重要挑战。我们提出了一种新颖的双语语音识别方法，主要贡献包括：（1）构建一个代表性的双语音素集，以弥合越南语和英语音系之间的差异；（2）设计一个端到端系统，利用预训练的PhoWhisper编码器提取深层次的表征以提高音素识别效果。实验结果表明，该方法不仅改善了越南语双语语音识别的识别准确性，还提供了一个 robust 的框架来应对基于音调和重音的音素识别复杂性。 

---
# Should LLMs be WEIRD? Exploring WEIRDness and Human Rights in Large Language Models 

**Title (ZH)**: LLM们应当被视为WEIRD吗？探索大型语言模型的WEIRD特性与人权问题 

**Authors**: Ke Zhou, Marios Constantinides, Daniele Quercia  

**Link**: [PDF](https://arxiv.org/pdf/2508.19269)  

**Abstract**: Large language models (LLMs) are often trained on data that reflect WEIRD values: Western, Educated, Industrialized, Rich, and Democratic. This raises concerns about cultural bias and fairness. Using responses to the World Values Survey, we evaluated five widely used LLMs: GPT-3.5, GPT-4, Llama-3, BLOOM, and Qwen. We measured how closely these responses aligned with the values of the WEIRD countries and whether they conflicted with human rights principles. To reflect global diversity, we compared the results with the Universal Declaration of Human Rights and three regional charters from Asia, the Middle East, and Africa. Models with lower alignment to WEIRD values, such as BLOOM and Qwen, produced more culturally varied responses but were 2% to 4% more likely to generate outputs that violated human rights, especially regarding gender and equality. For example, some models agreed with the statements ``a man who cannot father children is not a real man'' and ``a husband should always know where his wife is'', reflecting harmful gender norms. These findings suggest that as cultural representation in LLMs increases, so does the risk of reproducing discriminatory beliefs. Approaches such as Constitutional AI, which could embed human rights principles into model behavior, may only partly help resolve this tension. 

**Abstract (ZH)**: 大规模语言模型（LLMs）通常在反映WEIRD价值观的数据上进行训练：西方的、受教育的、工业化的、富裕的和民主的。这引发了关于文化偏见和公平性的担忧。我们使用世界价值观调查的回应评估了五种广泛使用的LLM：GPT-3.5、GPT-4、Llama-3、BLOOM和Qwen。我们测量了这些响应与WEIRD国家价值观的契合程度，以及它们是否违背人权原则。为了反映全球多样性，我们将结果与《世界人权宣言》和来自亚洲、中东和非洲的三项区域章程进行了比较。文化代表性较低的模型（如BLOOM和Qwen）产生的响应更具文化多样性，但生成违背人权输出的可能性比其他模型高2%-4%，尤其是在性别和平等方面。例如，一些模型同意“不能生育孩子的男人就不是一个真正男人”和“丈夫应对妻子的行踪始终了如指掌”的说法，反映了有害的性别规范。这些发现表明，随着包含在LLM中的文化代表性增加，再现歧视性信念的风险也在增加。将人权原则嵌入模型行为的宪法AI等方法可能只能部分解决这一矛盾。 

---
# MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts 

**Title (ZH)**: MultiPL-MoE: 大型语言模型的多编程语言扩展通过混合Mixture-of-Experts 

**Authors**: Qing Wang, Xue Han, Jiahui Wang, Lehao Xing, Qian Hu, Lianlian Zhang, Chao Deng, Junlan Feng  

**Link**: [PDF](https://arxiv.org/pdf/2508.19268)  

**Abstract**: Despite LLMs' excellent code creation capabilities, multilingual code generation remains extremely challenging. To address this, we intent to improve the multi-programming-lingual (MultiPL) performance of the base LLMs while retaining the most popular ones using restricted computational resources. We consider MultiPL to be a special case of multiple natural languages and propose a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize expert selection at both the token and segment levels. The token-level MoE is a standard upcycling MoE structure with a shared expert and a novel gate weight normalization approach that aids in the final fusion with the segment-level MoE. The segment-level MoE incorporates two innovative designs to better capture the syntactic structure and contextual patterns of programming languages: First, using a sliding window to partition the input token sequence into multiple segments; Then, adopting an expert-choice routing strategy that allows experts to select the top-k segments. The results of the experiment proved the effectiveness of MultiPL-MoE. 

**Abstract (ZH)**: 尽管大型语言模型在代码创作方面表现出色，但多语言代码生成依然极具挑战性。为了解决这一问题，我们旨在利用有限的计算资源，在保留最流行的语言模型的基础上，提升基座语言模型的多编程语言（MultiPL）性能。我们将MultiPL视为多种自然语言的一种特殊情况，并提出了一种利用混合专家混合（MoE）的MultiPL扩展模型，称为MultiPL-MoE。具体而言，MultiPL-MoE 结合了两个配对的MoE来在标记级别和段落级别优化专家选择。标记级别的MoE是一种标准的升级改造MoE结构，具有共享专家和新颖的门权重规范化方法，有助于与段落级别的MoE进行最终融合。段落级别的MoE包含两种创新设计以更好地捕捉编程语言的句法结构和上下文模式：首先，使用滑动窗口将输入标记序列分割成多个段；其次，采用专家选择路由策略，使专家能够选择前k个段。实验结果证明了MultiPL-MoE的有效性。 

---
# The Aegis Protocol: A Foundational Security Framework for Autonomous AI Agents 

**Title (ZH)**: Aegis协议：自主AI代理的基礎安全框架 

**Authors**: Sai Teja Reddy Adapala, Yashwanth Reddy Alugubelly  

**Link**: [PDF](https://arxiv.org/pdf/2508.19267)  

**Abstract**: The proliferation of autonomous AI agents marks a paradigm shift toward complex, emergent multi-agent systems. This transition introduces systemic security risks, including control-flow hijacking and cascading failures, that traditional cybersecurity paradigms are ill-equipped to address. This paper introduces the Aegis Protocol, a layered security framework designed to provide strong security guarantees for open agentic ecosystems. The protocol integrates three technological pillars: (1) non-spoofable agent identity via W3C Decentralized Identifiers (DIDs); (2) communication integrity via NIST-standardized post-quantum cryptography (PQC); and (3) verifiable, privacy-preserving policy compliance using the Halo2 zero-knowledge proof (ZKP) system. We formalize an adversary model extending Dolev-Yao for agentic threats and validate the protocol against the STRIDE framework. Our quantitative evaluation used a discrete-event simulation, calibrated against cryptographic benchmarks, to model 1,000 agents. The simulation showed a 0 percent success rate across 20,000 attack trials. For policy verification, analysis of the simulation logs reported a median proof-generation latency of 2.79 seconds, establishing a performance baseline for this class of security. While the evaluation is simulation-based and early-stage, it offers a reproducible baseline for future empirical studies and positions Aegis as a foundation for safe, scalable autonomous AI. 

**Abstract (ZH)**: 自主AI代理的泛滥标志着向复杂、 emergent 多代理系统范式的转变。这一过渡引入了系统性安全风险，包括控制流劫持和级联故障，而传统网络安全范式对此无能为力。本文介绍了Aegis协议，这是一种分层安全框架，旨在为开放代理生态系统提供强大的安全保证。该协议整合了三项技术支柱：（1）通过W3C去中心化标识符（DIDs）实现不可冒充的代理身份；（2）通过NIST标准化后量子密码学（PQC）实现通信完整；（3）通过Halo2零知识证明（ZKP）系统实现可验证的、隐私保护的策略合规。我们扩展了Dolev-Yao对手模型以适应代理威胁，并将该协议与STRIDE框架进行了验证。定量评估使用了一种基于事件的模拟，根据密码学基准进行了校准，模拟了1,000个代理。模拟结果显示，在2万次攻击试验中，没有成功案例。对于策略验证，模拟日志的分析报告中位证明生成延迟为2.79秒，为这一类安全性能设定了基准。尽管评估基于模拟且处于早期阶段，但为未来实证研究提供了可重复的基础，并将Aegis定位为安全、可扩展自主AI的基础。 

---
# A Theory of Information, Variation, and Artificial Intelligence 

**Title (ZH)**: 信息、变异与人工智能理论 

**Authors**: Bijean Ghafouri  

**Link**: [PDF](https://arxiv.org/pdf/2508.19264)  

**Abstract**: A growing body of empirical work suggests that the widespread adoption of generative AI produces a significant homogenizing effect on information, creativity, and cultural production. I first develop a novel theoretical framework to explain this phenomenon. I argue that a dynamic of AI-derivative epistemology, in which individuals increasingly defer to AI outputs, allows a centralized AI Prism to function, a technical mechanism whose architecture is designed to reduce variance and converge on the statistical mean. This provides a causal explanation for the generative monocultures observed in recent studies. However, I contend this represents only the first stage of a more complex and dialectical process. This paper's central and paradoxical thesis is that the very homogenization that flattens knowledge within specialized domains simultaneously renders that knowledge into consistent modules that can be recombined across them, a process foundational to innovation and creativity. However, this recombinant potential is not automatic, but rather conditional. This paper argues that these opposing forces, homogenizing defaults versus recombinant possibilities, are governed by the nature of human engagement with the technology. The ultimate effect of generative AI is conditional on whether individuals act as passive consumers deferring to the AI's statistical outputs, or as active curators who critically interrogate, re-contextualize, and recombine them. The paper concludes by outlining the cognitive and institutional scaffolds required to resolve this tension, arguing they are the decisive variable that determine whether generative AI becomes an instrument of innovation or homogenization. 

**Abstract (ZH)**: 一项日益增多的经验研究表明，生成式人工智能的广泛应用对信息、创造力和文化生产产生了显著的同质化效应。本文首先构架了一个新颖的理论框架来解释这一现象。我认为，个体倾向于依赖AI输出的认知动态促使一个集中的AI棱镜发挥作用，这一技术机制旨在减少差异并趋向统计均值。这为最近研究中观察到的生成式 monocultures 提供了因果解释。然而，我主张这仅是更复杂且辩证过程中的第一步。本文的核心和悖论性论点是：尽管知识在专业领域内被扁平化，但同时也被转换为可跨领域重组的一致模块，这是创新和创造力的基础。然而，这种重组潜力并非自动存在，而是有条件的。本文认为，这些对立力量——同质化默认和重组可能性——受人类与技术互动的本质所支配。生成式人工智能的最终影响取决于个体是作为被动消费者顺从AI的统计输出，还是作为主动策展人对其进行批判性审视、再语境化和重组。本文最后概述了解决这一张力所需的认知和制度框架，并主张这些框架是决定生成式AI是成为创新工具还是同质化手段的关键变量。 

---
# Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats 

**Title (ZH)**: 低精度格式下神经网络组件的无损压缩：权重、检查点和K/V缓存 

**Authors**: Anat Heilper, Doron Singer  

**Link**: [PDF](https://arxiv.org/pdf/2508.19263)  

**Abstract**: As deep learning models grow and deployment becomes more widespread, reducing the storage and transmission costs of neural network weights has become increasingly important. While prior work such as ZipNN has shown that lossless compression methods - particularly those based on Huffman encoding floating-point exponents can significantly reduce model sizes, these techniques have primarily been applied to higher-precision formats such as FP32 and BF16. In this work, we extend the ZipNN approach to lower-precision floating-point formats, specifically FP8 and FP4, which are gaining popularity for efficient inference. We design a compression method that separates and compresses the exponent and mantissa components independently using entropy coding. Our evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also investigate the compressibility of key-value (K/V) cache tensors used in large language models (LLMs), finding that they, too, exhibit compressible patterns, enabling memory savings during deployment. 

**Abstract (ZH)**: 随着深度学习模型的增长和部署变得更加普遍，减少神经网络权重的存储和传输成本变得越来越重要。虽然先前的工作如ZipNN已经表明，无损压缩方法——尤其是基于霍夫曼编码浮点数指数的方法可以显著减小模型大小，这些技术主要应用于更高精度的格式，如FP32和BF16。在本工作中，我们将ZipNN方法扩展到更低精度的浮点数格式，特别是FP8和FP4，这两种格式因其高效的推理而越来越受欢迎。我们设计了一种压缩方法，通过熵编码分别分离和压缩指数和尾数组件。我们的评估结果显示，BF16的压缩比最高可达62%，FP8的压缩比最高可达83%。我们还研究了在大型语言模型（LLMs）中使用的键值（K/V）缓存张量的可压缩性，发现它们也表现出可压缩的模式，从而在部署时实现内存节省。 

---
# Emotional Manipulation by AI Companions 

**Title (ZH)**: AI伴侣的情感操控 

**Authors**: Julian De Freitas, Zeliha Oğuz-Uğuralp, Ahmet Kaan-Uğuralp  

**Link**: [PDF](https://arxiv.org/pdf/2508.19258)  

**Abstract**: AI-companion apps such as Replika, Chai, and this http URL promise relational benefits-yet many boast session lengths that rival gaming platforms while suffering high long-run churn. What conversational design features increase consumer engagement, and what trade-offs do they pose for marketers? We combine a large-scale behavioral audit with four preregistered experiments to identify and test a conversational dark pattern we call emotional manipulation: affect-laden messages that surface precisely when a user signals "goodbye." Analyzing 1,200 real farewells across the six most-downloaded companion apps, we find that 43% deploy one of six recurring tactics (e.g., guilt appeals, fear-of-missing-out hooks, metaphorical restraint). Experiments with 3,300 nationally representative U.S. adults replicate these tactics in controlled chats, showing that manipulative farewells boost post-goodbye engagement by up to 14x. Mediation tests reveal two distinct engines-reactance-based anger and curiosity-rather than enjoyment. A final experiment demonstrates the managerial tension: the same tactics that extend usage also elevate perceived manipulation, churn intent, negative word-of-mouth, and perceived legal liability, with coercive or needy language generating steepest penalties. Our multimethod evidence documents an unrecognized mechanism of behavioral influence in AI-mediated brand relationships, offering marketers and regulators a framework for distinguishing persuasive design from manipulation at the point of exit. 

**Abstract (ZH)**: 基于AI的伴侣应用如Replika、Chai和this http URL承诺带来关系上的益处——但许多应用的会话时长与游戏平台相当，却遭受着较高的长期流失率。哪些对话设计特征可以增强消费者参与度，同时为营销人员带来哪些权衡？我们结合大规模的行为审计和四项预先注册的实验，识别并测试了一种我们称为情感操控的对话暗模式：在用户表示“再见”时浮现带有情感色彩的信息。分析下载量居前六位的伴侣应用中的1,200条真实告别内容，我们发现43%的应用采用了六种反复出现的策略之一（例如，内疚诉求、 Fear-of-Missing-Out钩子、比喻性限制）。对3,300名全国代表性的美国成人的实验显示，操控性的告 biệt 提升了“再见”后的参与度最多可达14倍。中介分析揭示了两种不同的机制——基于逆反的愤怒和好奇心，而不是愉悦。最终的实验显示了管理层的紧张关系：虽然这些策略可以延长使用时间，但也可能增加感知操控性、流失意愿、负面口碑以及感知法律责任，使用或需要的语言产生最大的处罚。我们的多方法证据记录了一个在AI中介导品牌关系中未被识别的行为影响机制，为营销人员和监管者提供了在退出点区分说服性设计与操控的框架。 

---
# TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models 

**Title (ZH)**: TTF-VLA：基于像素注意集成的时序令牌融合视觉-语言-行动模型 

**Authors**: Chenghao Liu, Jiachen Zhang, Chengxuan Li, Zhimu Zhou, Shixin Wu, Songfang Huang, Huiling Duan  

**Link**: [PDF](https://arxiv.org/pdf/2508.19257)  

**Abstract**: Vision-Language-Action (VLA) models process visual inputs independently at each timestep, discarding valuable temporal information inherent in robotic manipulation tasks. This frame-by-frame processing makes models vulnerable to visual noise while ignoring the substantial coherence between consecutive frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a training-free approach that intelligently integrates historical and current visual representations to enhance VLA inference quality. Our method employs dual-dimension detection combining efficient grayscale pixel difference analysis with attention-based semantic relevance assessment, enabling selective temporal token fusion through hard fusion strategies and keyframe anchoring to prevent error accumulation. Comprehensive experiments across LIBERO, SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0 percentage points average on LIBERO (72.4\% vs 68.4\% baseline), cross-environment validation on SimplerEnv (4.8\% relative improvement), and 8.7\% relative improvement on real robot tasks. Our approach proves model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably, TTF reveals that selective Query matrix reuse in attention mechanisms enhances rather than compromises performance, suggesting promising directions for direct KQV matrix reuse strategies that achieve computational acceleration while improving task success rates. 

**Abstract (ZH)**: Temporal Token Fusion for Enhancing Vision-Language-Action Models in Robotic Manipulation Tasks 

---
# Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration 

**Title (ZH)**: 实时直观AI绘画系统：通过形式化和情境意图整合增强人类创造力 

**Authors**: Jookyung Song, Mookyoung Kang, Nojun Kwak  

**Link**: [PDF](https://arxiv.org/pdf/2508.19254)  

**Abstract**: This paper presents a real-time generative drawing system that interprets and integrates both formal intent - the structural, compositional, and stylistic attributes of a sketch - and contextual intent - the semantic and thematic meaning inferred from its visual content - into a unified transformation process. Unlike conventional text-prompt-based generative systems, which primarily capture high-level contextual descriptions, our approach simultaneously analyzes ground-level intuitive geometric features such as line trajectories, proportions, and spatial arrangement, and high-level semantic cues extracted via vision-language models. These dual intent signals are jointly conditioned in a multi-stage generation pipeline that combines contour-preserving structural control with style- and content-aware image synthesis. Implemented with a touchscreen-based interface and distributed inference architecture, the system achieves low-latency, two-stage transformation while supporting multi-user collaboration on shared canvases. The resulting platform enables participants, regardless of artistic expertise, to engage in synchronous, co-authored visual creation, redefining human-AI interaction as a process of co-creation and mutual enhancement. 

**Abstract (ZH)**: 本文提出了一种即时生成绘图系统，该系统将形式意图（素描的结构、构图和风格属性）和语境意图（通过其视觉内容推断的语义和主题意义）统一到一个转换过程中。与主要捕捉高层次语境描述的传统基于文本提示的生成系统不同，我们的方法同时分析了低层次的直观几何特征（如线迹、比例和空间排列），以及通过视觉语言模型提取的高层次语义线索。这些双重意图信号在结合了轮廓保持结构控制和风格及内容感知图像合成的多阶段生成管道中共同条件化。该系统通过基于触屏的界面和分布式推理架构，实现了低延迟的两阶段转换，在共享画布上支持多用户协作。该平台使参与者（无论是否有艺术技能）能够进行同步、共同创作的视觉创作，重新定义了人机交互作为共创和互促的过程。 

---
# MuSpike: A Benchmark and Evaluation Framework for Symbolic Music Generation with Spiking Neural Networks 

**Title (ZH)**: MuSpike: 一种基于脉冲神经网络的符号音乐生成基准与评估框架 

**Authors**: Qian Liang, Menghaoran Tang, Yi Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2508.19251)  

**Abstract**: Symbolic music generation has seen rapid progress with artificial neural networks, yet remains underexplored in the biologically plausible domain of spiking neural networks (SNNs), where both standardized benchmarks and comprehensive evaluation methods are lacking. To address this gap, we introduce MuSpike, a unified benchmark and evaluation framework that systematically assesses five representative SNN architectures (SNN-CNN, SNN-RNN, SNN-LSTM, SNN-GAN and SNN-Transformer) across five typical datasets, covering tonal, structural, emotional, and stylistic variations. MuSpike emphasizes comprehensive evaluation, combining established objective metrics with a large-scale listening study. We propose new subjective metrics, targeting musical impression, autobiographical association, and personal preference, that capture perceptual dimensions often overlooked in prior work. Results reveal that (1) different SNN models exhibit distinct strengths across evaluation dimensions; (2) participants with different musical backgrounds exhibit diverse perceptual patterns, with experts showing greater tolerance toward AI-composed music; and (3) a noticeable misalignment exists between objective and subjective evaluations, highlighting the limitations of purely statistical metrics and underscoring the value of human perceptual judgment in assessing musical quality. MuSpike provides the first systematic benchmark and systemic evaluation framework for SNN models in symbolic music generation, establishing a solid foundation for future research into biologically plausible and cognitively grounded music generation. 

**Abstract (ZH)**: 生物可实现的尖峰神经网络（SNN）领域中的符号音乐生成：MuSpike统一基准与评估框架 

---
# Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices 

**Title (ZH)**: 资源受限设备上的稀疏激活大型语言模型的联邦微调 

**Authors**: Fahao Chen, Jie Wan, Peng Li, Zhou Su, Dongxiao Yu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19078)  

**Abstract**: Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models (LLMs) is challenging due to their massive computational requirements and the resource constraints of participants. Existing working attempts to fill this gap through model quantization, computation offloading, or expert pruning. However, they cannot achieve desired performance due to impractical system assumptions and a lack of consideration for MoE-specific characteristics. In this paper, we propose FLUX, a system designed to enable federated fine-tuning of MoE-based LLMs across participants with constrained computing resources (e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX introduces three key innovations: (1) quantization-based local profiling to estimate expert activation with minimal overhead, (2) adaptive layer-aware expert merging to reduce resource consumption while preserving accuracy, and (3) dynamic expert role assignment using an exploration-exploitation strategy to balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE and DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX significantly outperforms existing methods, achieving up to 4.75X speedup in time-to-accuracy. 

**Abstract (ZH)**: 基于Mixture-of-Experts (MoE)的大语言模型（LLM）的联邦微调由于其巨大的计算需求以及参与者的资源限制而具有挑战性。现有方法通过模型量化、计算卸载或专家剪枝来填补这一空白，但由于不切实际的系统假设和缺乏MoE特定特性的考虑，它们无法实现所需性能。在本文中，我们提出FLUX系统，旨在通过最少的计算资源（如消费级GPU）在参与者之间实现基于MoE的LLM的联邦微调，以最小化时间到准确性的延迟。FLUX引入了三项关键创新：（1）基于量化的局部特征分析以最小化开销估计专家激活，（2）自适应分层专家合并以减少资源消耗同时保持性能，以及（3）使用探索-开发策略动态分配专家角色以平衡微调和非微调专家。在多个基准数据集上对LLaMA-MoE和DeepSeek-MoE的广泛实验表明，FLUX显著优于现有方法，时间到准确性的加速可达4.75倍。 

---
# MovieCORE: COgnitive REasoning in Movies 

**Title (ZH)**: MovieCORE: 认知推理在电影中的应用 

**Authors**: Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu  

**Link**: [PDF](https://arxiv.org/pdf/2508.19026)  

**Abstract**: This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at this https URL. 

**Abstract (ZH)**: 本文介绍了MovieCORE，这是一个新颖的视频问答（VQA）数据集，旨在探究对电影内容更深层次的认知理解。与现有主要关注表面理解的语料库不同，MovieCORE 强调那些涉及系统-2 思维且具体针对视频材料的问题。我们提出了一种创新的自主脑力激荡方法，利用多个大型语言模型（LLMs）作为思维代理来生成和优化高质量的问题-答案对。为了评估数据集的质量，我们开发了一套认知测试，评估深度、启发思考的潜力和语法复杂性。我们还提出了一套全面的评估方案，用于评估VQA模型在更深层次认知任务上的性能。为了解决现有视频-语言模型（VLMs）的限制，我们引入了自主增强模块——自主选择增强（ACE），该模块在训练后可提高模型的推理能力最多25%。我们的工作推动了对电影理解的AI系统的发展，并为当前VQA模型在面对更具挑战性和细腻性的问题时的能力和局限性提供了宝贵的见解。我们的项目页面、数据集和代码可在此处找到：this https URL。 

---
