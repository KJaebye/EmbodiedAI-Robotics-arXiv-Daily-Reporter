# Operand Quant: A Single-Agent Architecture for Autonomous Machine Learning Engineering 

**Title (ZH)**: 操作量纲：自管理机器学习工程的单代理架构 

**Authors**: Arjun Sahney, Ram Gorthi, Cezary Łastowski, Javier Vega  

**Link**: [PDF](https://arxiv.org/pdf/2510.11694)  

**Abstract**: We present Operand Quant, a single-agent, IDE-based architecture for autonomous machine learning engineering (MLE). Operand Quant departs from conventional multi-agent orchestration frameworks by consolidating all MLE lifecycle stages -- exploration, modeling, experimentation, and deployment -- within a single, context-aware agent. On the MLE-Benchmark (2025), Operand Quant achieved a new state-of-the-art (SOTA) result, with an overall medal rate of 0.3956 +/- 0.0565 across 75 problems -- the highest recorded performance among all evaluated systems to date. The architecture demonstrates that a linear, non-blocking agent, operating autonomously within a controlled IDE environment, can outperform multi-agent and orchestrated systems under identical constraints. 

**Abstract (ZH)**: operand quant：一种基于IDE的单代理自主机器学习工程架构 

---
# SR-Scientist: Scientific Equation Discovery With Agentic AI 

**Title (ZH)**: SR-科学家：带有自主AI的科学方程发现 

**Authors**: Shijie Xia, Yuhan Sun, Pengfei Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11661)  

**Abstract**: Recently, Large Language Models (LLMs) have been applied to scientific equation discovery, leveraging their embedded scientific knowledge for hypothesis generation. However, current methods typically confine LLMs to the role of an equation proposer within search algorithms like genetic programming. In this paper, we present SR-Scientist, a framework that elevates the LLM from a simple equation proposer to an autonomous AI scientist that writes code to analyze data, implements the equation as code, submits it for evaluation, and optimizes the equation based on experimental feedback. Specifically, we wrap the code interpreter into a set of tools for data analysis and equation evaluation. The agent is instructed to optimize the equation by utilizing these tools over a long horizon with minimal human-defined pipelines. Empirical results show that SR-Scientist outperforms baseline methods by an absolute margin of 6% to 35% on datasets covering four science disciplines. Additionally, we demonstrate our method's robustness to noise, the generalization of the discovered equations to out-of-domain data, and their symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning framework to enhance the agent's capabilities. 

**Abstract (ZH)**: Recent进展：大型语言模型在科学研究中的自主科学家框架SR-Scientist 

---
# ParaCook: On Time-Efficient Planning for Multi-Agent Systems 

**Title (ZH)**: ParaCook: 多代理系统中的时间高效规划 

**Authors**: Shiqi Zhang, Xinbei Ma, Yunqing Xu, Zouying Cao, Pengrui Lu, Haobo Yuan, Tiancheng Shen, Zhuosheng Zhang, Hai Zhao, Ming-Hsuan Yang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11608)  

**Abstract**: Large Language Models (LLMs) exhibit strong reasoning abilities for planning long-horizon, real-world tasks, yet existing agent benchmarks focus on task completion while neglecting time efficiency in parallel and asynchronous operations. To address this, we present ParaCook, a benchmark for time-efficient collaborative planning. Inspired by the Overcooked game, ParaCook provides an environment for various challenging interaction planning of multi-agent systems that are instantiated as cooking tasks, with a simplified action space to isolate the core challenge of strategic parallel planning. Through a comprehensive evaluation of state-of-the-art LLMs, we find that current approaches achieve suboptimal plans, which struggle with parallel actions or coordination. Our analysis also reveals LLMs' potential on abstract tasks where they can focus on high-level parallel optimization. ParaCook provides a scalable evaluation framework with adjustable complexity, establishing a foundation for developing and assessing time efficiency-aware multi-agent planning. The code and data are available at this https URL. 

**Abstract (ZH)**: ParaCook：一种时间高效协作规划基准 

---
# Explainability, risk modeling, and segmentation based customer churn analytics for personalized retention in e-commerce 

**Title (ZH)**: 基于解释性、风险建模和细分的个性化客户流失分析以实现电子商务中的留存 

**Authors**: Sanjula De Alwis, Indrajith Ekanayake  

**Link**: [PDF](https://arxiv.org/pdf/2510.11604)  

**Abstract**: In online retail, customer acquisition typically incurs higher costs than customer retention, motivating firms to invest in churn analytics. However, many contemporary churn models operate as opaque black boxes, limiting insight into the determinants of attrition, the timing of retention opportunities, and the identification of high-risk customer segments. Accordingly, the emphasis should shift from prediction alone to the design of personalized retention strategies grounded in interpretable evidence. This study advances a three-component framework that integrates explainable AI to quantify feature contributions, survival analysis to model time-to-event churn risk, and RFM profiling to segment customers by transactional behaviour. In combination, these methods enable the attribution of churn drivers, estimation of intervention windows, and prioritization of segments for targeted actions, thereby supporting strategies that reduce attrition and strengthen customer loyalty. 

**Abstract (ZH)**: 在线零售中，获取客户的成本通常高于保留客户的成本，促使企业投资流失分析。然而，许多现代流失模型作为不透明的黑箱运作，限制了对客户流失驱动因素、保留机会的时间以及高风险客户群体识别的洞察。因此，重心应从单一的预测转移到基于可解释证据设计个性化的保留策略。本研究提出了一种包含三个组成部分的框架，该框架结合可解释人工智能来量化特征贡献，事件时间生存分析来建模时间到事件的流失风险，以及RFM细分来根据交易行为划分客户。这些方法的结合能够归因于流失驱动因素、估计干预窗口，并优先考虑需要针对性行动的客户群体，从而支持减少流失和增强客户忠诚度的策略。 

---
# Reproducibility: The New Frontier in AI Governance 

**Title (ZH)**: reproducibility: AI治理的新前沿 

**Authors**: Israel Mason-Williams, Gabryel Mason-Williams  

**Link**: [PDF](https://arxiv.org/pdf/2510.11595)  

**Abstract**: AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific standards, via weak reproducibility protocols, effectively erodes the power of policymakers to enact meaningful policy and governance protocols. Our paper outlines how AI research could adopt stricter reproducibility guidelines to assist governance endeavours and improve consensus on the AI risk landscape. We evaluate the forthcoming reproducibility crisis within AI research through the lens of crises in other scientific domains; providing a commentary on how adopting preregistration, increased statistical power and negative result publication reproducibility protocols can enable effective AI governance. While we maintain that AI governance must be reactive due to AI's significant societal implications we argue that policymakers and governments must consider reproducibility protocols as a core tool in the governance arsenal and demand higher standards for AI research. Code to replicate data and figures: this https URL 

**Abstract (ZH)**: AI决策者有责任提供有效的治理机制，确保AI的安全、对齐和可信发展。然而，提供给决策者的信息环境特征是信号与噪声比过低，有利于监管俘获，并在从治理角度应优先考虑哪些风险方面制造深刻的不确定性与分歧。我们提出，当前AI领域的发表速度与缺乏严格的科学标准（通过弱重复性协议体现）有效削弱了决策者制定有意义政策和治理协议的能力。本文概述了AI研究如何采用更严格的重复性指南以辅助治理努力并改善对AI风险领域的共识。我们通过考察其他科学领域中的危机来评价AI研究将面临的重复性危机，并提供一种观点，即通过采用前瞻性注册、增加统计功效和负面结果发布等重复性协议，可以实现有效的AI治理。尽管我们坚持认为，鉴于AI的重大社会影响，AI治理必须具有反应性，但我们认为决策者和政府必须将重复性协议视为治理工具的核心，并要求更高的AI研究标准。重复数据和图表的复制代码：this https URL。 

---
# Analyzing and Internalizing Complex Policy Documents for LLM Agents 

**Title (ZH)**: 分析并内化复杂政策文件以供大型语言模型代理使用 

**Authors**: Jiateng Liu, Zhenhailong Wang, Xiaojiang Huang, Yingjie Li, Xing Fan, Xiang Li, Chenlei Guo, Ruhi Sarikaya, Heng Ji  

**Link**: [PDF](https://arxiv.org/pdf/2510.11588)  

**Abstract**: Large Language Model (LLM)-based agentic systems rely on in-context policy documents encoding diverse business rules. As requirements grow, these documents expand rapidly, causing high computational overhead. This motivates developing internalization methods that embed policy documents into model priors while preserving performance. Prior prompt compression work targets generic prompts, but agentic policy documents span multiple complexity levels and require deeper reasoning, making internalization harder. We introduce CC-Gen, an agentic benchmark generator with Controllable Complexity across four levels, enabling systematic evaluation of agents' ability to handle complexity and offering a unified framework for assessing policy internalization. Our analysis shows that complex policy specifications governing workflows pose major reasoning challenges. Supporting internalization with gold user agent interaction trajectories containing chain-of-thought (CoT) annotations via supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy complexity increases. To mitigate data and reasoning burdens, we propose Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline parses policy documents to extract key specifications, grouping them into factual, behavioral, and conditional categories, and isolating complex conditions that drive workflow complexity. This guides targeted data synthesis and enables agents to internalize policy information through an autoregressive pretraining loss. Experiments show CAP-CPT improves SFT baselines in all settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT data. 

**Abstract (ZH)**: 基于大型语言模型的代理系统依赖于包含多样商业规则的上下文政策文档。随着需求的增长，这些文档迅速扩展，导致高计算开销。这促使开发能够在保持性能的同时将政策文档嵌入到模型先验中的内化方法。先前的提示压缩工作针对通用提示，但代理政策文档跨越多个复杂级别，并需要更深层次的推理，这使得内化更为困难。我们引入了CC-Gen，这是一种具有可控复杂性的代理基准生成器，涵盖了四个复杂级别，能够系统地评估代理处理复杂性的能力，并提供了一个统一的评估政策内化的框架。我们的分析表明，控制工作流程的复杂政策规范提出了重大的推理挑战。使用标注有推理链（CoT）注释的黄金用户代理互动轨迹通过监督微调（SFT）支持内化数据密集且随着政策复杂性增加而急剧下降。为了减轻数据和推理负担，我们提出了类别感知政策连续预训练（CAP-CPT）。我们的自动化管道解析政策文档以提取关键规范，将它们分为事实、行为和条件类别，并隔离驱动工作流程复杂性的复杂条件。这指导了目标数据合成，并通过自回归预训练损失使代理能够内化政策信息。实验结果显示，CAP-CPT在所有设置下优于SFT基线，在Qwen-3-32B上的改进幅度最高可达41%，在CC-Gen上实现了97.3%的提示长度减少，并通过少量的SFT数据进一步增强了tau-Bench。 

---
# Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products 

**Title (ZH)**: 基于LLM的 enterprise AI 助手的零数据保留：市场领先代理型AI产品的比较研究 

**Authors**: Komal Gupta, Aditya Shrivastava  

**Link**: [PDF](https://arxiv.org/pdf/2510.11558)  

**Abstract**: Governance of data, compliance, and business privacy matters, particularly for healthcare and finance businesses. Since the recent emergence of AI enterprise AI assistants enhancing business productivity, safeguarding private data and compliance is now a priority. With the implementation of AI assistants across the enterprise, the zero data retention can be achieved by implementing zero data retention policies by Large Language Model businesses like Open AI and Anthropic and Meta. In this work, we explore zero data retention policies for the Enterprise apps of large language models (LLMs). Our key contribution is defining the architectural, compliance, and usability trade-offs of such systems in parallel. In this research work, we examine the development of commercial AI assistants with two industry leaders and market titans in this arena - Salesforce and Microsoft. Both of these companies used distinct technical architecture to support zero data retention policies. Salesforce AgentForce and Microsoft Copilot are among the leading AI assistants providing much-needed push to business productivity in customer care. The purpose of this paper is to analyze the technical architecture and deployment of zero data retention policy by consuming applications as well as big language models service providers like Open Ai, Anthropic, and Meta. 

**Abstract (ZH)**: 大型语言模型企业应用程序中的零数据保留政策治理、合规性和商业隐私问题，特别是在医疗健康和金融业务领域的应用。由于近期企业AI助手的兴起极大地提高了业务生产率，因此保护私人数据和合规性已成为优先事项。随着企业中AI助手的实施，通过如Open AI、Anthropic和Meta这类大型语言模型企业实施零数据保留政策可以实现零数据留存。在本文中，我们探讨了大型语言模型企业应用程序中的零数据保留政策。我们的主要贡献在于同时定义了此类系统的架构、合规性和可使用性权衡。在本研究工作中，我们以Salesforce和Microsoft这两个该领域的行业领导者和市场巨头为例，考察了商用AI助手的技术架构及其部署。Salesforce的AgentForce和Microsoft的Copilot是领先的AI助手，它们在客户服务领域的业务生产力方面提供了必要的推动。本文的目的在于分析作为应用程序和服务提供者的大型语言模型（如Open AI、Anthropic和Meta）在实施零数据保留政策方面的技术架构和部署。 

---
# Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model 

**Title (ZH)**: 在知识图中通过掩码扩散模型统一演绎推理和溯因推理 

**Authors**: Yisen Gao, Jiaxin Bai, Yi Huang, Xingcheng Fu, Qingyun Sun, Yangqiu Song  

**Link**: [PDF](https://arxiv.org/pdf/2510.11462)  

**Abstract**: Deductive and abductive reasoning are two critical paradigms for analyzing knowledge graphs, enabling applications from financial query answering to scientific discovery. Deductive reasoning on knowledge graphs usually involves retrieving entities that satisfy a complex logical query, while abductive reasoning generates plausible logical hypotheses from observations. Despite their clear synergistic potential, where deduction can validate hypotheses and abduction can uncover deeper logical patterns, existing methods address them in isolation. To bridge this gap, we propose DARK, a unified framework for Deductive and Abductive Reasoning in Knowledge graphs. As a masked diffusion model capable of capturing the bidirectional relationship between queries and conclusions, DARK has two key innovations. First, to better leverage deduction for hypothesis refinement during abductive reasoning, we introduce a self-reflective denoising process that iteratively generates and validates candidate hypotheses against the observed conclusion. Second, to discover richer logical associations, we propose a logic-exploration reinforcement learning approach that simultaneously masks queries and conclusions, enabling the model to explore novel reasoning compositions. Extensive experiments on multiple benchmark knowledge graphs show that DARK achieves state-of-the-art performance on both deductive and abductive reasoning tasks, demonstrating the significant benefits of our unified approach. 

**Abstract (ZH)**: 演绎和归纳推理是分析知识图谱的两种关键范式， enabling 从金融查询回答到科学发现等应用。演绎推理通常涉及检索满足复杂逻辑查询的实体，而归纳推理则从观察中生成合理的逻辑假设。尽管它们在协同作用方面具有明显的潜力，其中演绎可验证假设，而归纳可揭示更深层的逻辑模式，现有方法仍分别处理它们。为了弥合这一差距，我们提出了DARK，一种知识图谱中演绎和归纳推理的统一框架。作为能够捕捉查询与结论之间双向关系的掩码扩散模型，DARK具有两个关键创新。首先，为了更好地利用演绎在归纳推理中的假设细化，我们引入了一种自反去噪过程，该过程迭代地生成和验证候选假设，使其与观察到的结论一致。其次，为了发现更丰富的逻辑关联，我们提出了一种逻辑探索强化学习方法，该方法同时掩码查询和结论，使模型能够探索新的推理组合。在多个基准知识图谱上的广泛实验表明，DARK在演绎和归纳推理任务上均达到了最先进的性能，证明了我们统一方法的重要优势。 

---
# From <Answer> to <Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization 

**Title (ZH)**: 从<Answer>到<Think>：面向LLM优化的多维度推理过程监督 

**Authors**: Beining Wang, Weihang Su, Hongtao Tian, Tao Yang, Yujia Zhou, Ting Yao, Qingyao Ai, Yiqun Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11457)  

**Abstract**: Improving the multi-step reasoning ability of Large Language Models (LLMs) is a critical yet challenging task. The dominant paradigm, outcome-supervised reinforcement learning (RLVR), rewards only correct final answers, often propagating flawed reasoning and suffering from sparse reward signals. While process-level reward models (PRMs) provide denser, step-by-step feedback, they lack generalizability and interpretability, requiring task-specific segmentation of the reasoning process. To this end, we propose the Dimension-level Reward Model (DRM), a new supervision framework that bridges the gap between these two approaches. DRM evaluates the quality of a reasoning process along three fundamental, complementary, and interpretable dimensions: Confidence for uncertainty calibration, Relevance for semantic alignment, and Coherence for logical consistency. Together, these dimensions capture aspects beyond final answer correctness and enable interpretable assessment without requiring ground truth answers. Experimental results show that DRM provides effective supervision signals, guides the optimization of LLMs and enhances their reasoning ability. In particular, DRM-supervised training achieves consistent gains on both in-distribution and out-of-distribution open-domain tasks, including mathematics, question answering, code execution, and puzzles. Our findings demonstrate that multidimensional supervision of the reasoning process can improve the generalized reasoning ability of LLMs beyond the training distribution. 

**Abstract (ZH)**: 改善大型语言模型的多步推理能力是一项关键且具有挑战性的任务。我们提出了维度级奖励模型（DRM），这是一种新的监督框架，旨在弥合这两个方法之间的差距。DRM 从不确定性校准、语义对齐和逻辑一致性这三个基本、互补和可解释的维度评估推理过程的质量。这些维度捕捉到最终答案正确性之外的方面，并能够在无需 ground truth 答案的情况下实现可解释的评估。实验结果表明，DRM 提供了有效的监督信号，指导了大型语言模型的优化并提高了它们的推理能力。具体而言，DRM 监督下的训练在包括数学、问答、代码执行和谜题在内的同分布和跨分布开放域任务中均表现出一致的提升。我们的研究结果表明，多维度的推理过程监督可以提高大型语言模型的泛化推理能力，超越训练分布。 

---
# AI-Driven anemia diagnosis: A review of advanced models and techniques 

**Title (ZH)**: AI驱动的贫血诊断：先进模型与技术的综述 

**Authors**: Abdullah Al Mahmud, Prangon Chowdhury, Mohammed Borhan Uddin, Khaled Eabne Delowar, Tausifur Rahman Talha, Bijoy Dewanjee  

**Link**: [PDF](https://arxiv.org/pdf/2510.11380)  

**Abstract**: Anemia, a condition marked by insufficient levels of red blood cells or hemoglobin, remains a widespread health issue affecting millions of individuals globally. Accurate and timely diagnosis is essential for effective management and treatment of anemia. In recent years, there has been a growing interest in the use of artificial intelligence techniques, i.e., machine learning (ML) and deep learning (DL) for the detection, classification, and diagnosis of anemia. This paper provides a systematic review of the recent advancements in this field, with a focus on various models applied to anemia detection. The review also compares these models based on several performance metrics, including accuracy, sensitivity, specificity, and precision. By analyzing these metrics, the paper evaluates the strengths and limitation of discussed models in detecting and classifying anemia, emphasizing the importance of addressing these factors to improve diagnostic accuracy. 

**Abstract (ZH)**: 贫血是一种由红细胞或血红蛋白水平不足引起的情况，仍然是影响全球数百万人的广泛健康问题。准确及时的诊断对于贫血的有效管理和治疗至关重要。近年来，人们越来越关注使用人工智能技术，即机器学习（ML）和深度学习（DL）来检测、分类和诊断贫血。本文提供了一个对该领域近期进展的系统性综述，重点关注应用于贫血检测的各种模型，并根据准确性、敏感性、特异性和精确度等性能指标对这些模型进行了比较。通过分析这些指标，本文评估了讨论的模型在检测和分类贫血方面的优缺点，强调了在这些方面进行改进以提高诊断准确性的重要性。 

---
# Automated Skill Decomposition Meets Expert Ontologies: Bridging the Granularity Gap with LLMs 

**Title (ZH)**: 自动技能分解结合专家本体：利用大语言模型弥合粒度差距 

**Authors**: Le Ngoc Luyen, Marie-Hélène Abel  

**Link**: [PDF](https://arxiv.org/pdf/2510.11313)  

**Abstract**: This paper investigates automated skill decomposition using Large Language Models (LLMs) and proposes a rigorous, ontology-grounded evaluation framework. Our framework standardizes the pipeline from prompting and generation to normalization and alignment with ontology nodes. To evaluate outputs, we introduce two metrics: a semantic F1-score that uses optimal embedding-based matching to assess content accuracy, and a hierarchy-aware F1-score that credits structurally correct placements to assess granularity. We conduct experiments on ROME-ESCO-DecompSkill, a curated subset of parents, comparing two prompting strategies: zero-shot and leakage-safe few-shot with exemplars. Across diverse LLMs, zero-shot offers a strong baseline, while few-shot consistently stabilizes phrasing and granularity and improves hierarchy-aware alignment. A latency analysis further shows that exemplar-guided prompts are competitive - and sometimes faster - than unguided zero-shot due to more schema-compliant completions. Together, the framework, benchmark, and metrics provide a reproducible foundation for developing ontology-faithful skill decomposition systems. 

**Abstract (ZH)**: 本研究探讨了使用大规模语言模型（LLMs）自动生成技能分解的方法，并提出了一种严格的基于本体的评估框架。该框架标准化工序从提示和生成到规范化和本体节点对齐。为了评估输出，我们引入了两种度量标准：使用最优嵌入匹配来评估内容准确性的语义F1分数，以及考虑到层次结构的F1分数，该分数将结构正确的放置归功于粒度评估。我们使用罗马-ESCO分解技能集中的精心选择的子集进行了实验，比较了两种提示策略：零样本和泄漏安全的少样本，后者带有示例。在多种LLM上，零样本提供了强大的基线，而少样本则一致地稳定了语法和粒度，并提高了层级感知对齐。延迟分析进一步表明，在满足模式的情况下，带有示例引导的提示有时可以与非引导的零样本相竞争，甚至更快。总体而言，该框架、基准和度量标准为开发符合本体的技能分解系统提供了可重复的基础。 

---
# Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics 

**Title (ZH)**: 模拟中的进化：具有双记忆的AI代理学校，用于高保真教育动态 

**Authors**: Sheng Jin, Haoming Wang, Zhiqi Gao, Yongbo Yang, Bao Chunjia, Chengliang Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11290)  

**Abstract**: Large language models (LLMs) based Agents are increasingly pivotal in simulating and understanding complex human systems and interactions. We propose the AI-Agent School (AAS) system, built around a self-evolving mechanism that leverages agents for simulating complex educational dynamics. Addressing the fragmented issues in teaching process modeling and the limitations of agents performance in simulating diverse educational participants, AAS constructs the Zero-Exp strategy, employs a continuous "experience-reflection-optimization" cycle, grounded in a dual memory base comprising experience and knowledge bases and incorporating short-term and long-term memory components. Through this mechanism, agents autonomously evolve via situated interactions within diverse simulated school scenarios. This evolution enables agents to more accurately model the nuanced, multi-faceted teacher-student engagements and underlying learning processes found in physical schools. Experiment confirms that AAS can effectively simulate intricate educational dynamics and is effective in fostering advanced agent cognitive abilities, providing a foundational stepping stone from the "Era of Experience" to the "Era of Simulation" by generating high-fidelity behavioral and interaction data. 

**Abstract (ZH)**: 基于大语言模型的智能代理在学校教育动态模拟中的应用：AI-Agent School系统及其零经验策略 

---
# PADME: Procedure Aware DynaMic Execution 

**Title (ZH)**: PADME： Procedure Awareness Dynamic Execution 

**Authors**: Deepeka Garg, Sihan Zeng, Annapoorani L. Narayanan, Sumitra Ganesh, Leo Ardon  

**Link**: [PDF](https://arxiv.org/pdf/2510.11281)  

**Abstract**: Learning to autonomously execute long-horizon procedures from natural language remains a core challenge for intelligent agents. Free-form instructions such as recipes, scientific protocols, or business workflows encode rich procedural knowledge, but their variability and lack of structure cause agents driven by large language models (LLMs) to drift or fail during execution. We introduce Procedure Aware DynaMic Execution (PADME), an agent framework that produces and exploits a graph-based representation of procedures. Unlike prior work that relies on manual graph construction or unstructured reasoning, PADME autonomously transforms procedural text into executable graphs that capture task dependencies, decision points, and reusable subroutines. Central to PADME is a two-phase methodology; Teach phase, which focuses on systematic structuring, enrichment with executable logic of procedures, followed by Execute phase, which enables dynamic execution in response to real-time inputs and environment feedback. This separation ensures quality assurance and scalability, allowing expert knowledge to be encoded once and reliably reused across varying contexts. The graph representation also provides an inductive bias that reduces error accumulation in long-horizon reasoning, underscoring the importance of structured procedure modeling for reliable agent-driven automation. Empirically, PADME achieves state-of-the-art performance on four diverse benchmarks, including ALFWorld and ScienceWorld. These results demonstrate that agents equipped with graph-based procedure representations offer a powerful intermediate abstraction for robust and generalizable execution. 

**Abstract (ZH)**: 基于图表示的程序意识动态执行（PADME）：从自然语言自主执行长期任务 

---
# AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures? 

**Title (ZH)**: 从风险角度看的AI对齐策略：独立的安全机制还是共有的失败？ 

**Authors**: Leonard Dung, Florian Mai  

**Link**: [PDF](https://arxiv.org/pdf/2510.11235)  

**Abstract**: AI alignment research aims to develop techniques to ensure that AI systems do not cause harm. However, every alignment technique has failure modes, which are conditions in which there is a non-negligible chance that the technique fails to provide safety. As a strategy for risk mitigation, the AI safety community has increasingly adopted a defense-in-depth framework: Conceding that there is no single technique which guarantees safety, defense-in-depth consists in having multiple redundant protections against safety failure, such that safety can be maintained even if some protections fail. However, the success of defense-in-depth depends on how (un)correlated failure modes are across alignment techniques. For example, if all techniques had the exact same failure modes, the defense-in-depth approach would provide no additional protection at all. In this paper, we analyze 7 representative alignment techniques and 7 failure modes to understand the extent to which they overlap. We then discuss our results' implications for understanding the current level of risk and how to prioritize AI alignment research in the future. 

**Abstract (ZH)**: AI对齐研究旨在开发技术以确保AI系统不会造成危害。然而，每种对齐技术都有失效模式，即技术不能提供安全性的非忽视概率条件。为了减少风险，AI安全社区越来越多地采用纵深防御框架：承认没有单一技术能够确保安全，纵深防御包括多种冗余保护措施，即使某些保护措施失效，也能维持安全性。然而，纵深防御的成功依赖于对齐技术之间失效模式的相关性。例如，如果所有技术都具有完全相同类型的失效模式，那么纵深防御方法将提供完全没有额外保护的效果。本文分析了7种代表性的对齐技术和7种失效模式，以了解它们重叠的程度。我们随后讨论了这些结果对当前风险水平理解及其对未来AI对齐研究优先级的影响。 

---
# Aligning Deep Implicit Preferences by Learning to Reason Defensively 

**Title (ZH)**: 通过学习进行防御性推理以对齐深度隐式偏好 

**Authors**: Peiming Li, Zhiyuan Hu, Yang Tang, Shiyu Li, Xi Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.11194)  

**Abstract**: Personalized alignment is crucial for enabling Large Language Models (LLMs) to engage effectively in user-centric interactions. However, current methods face a dual challenge: they fail to infer users' deep implicit preferences (including unstated goals, semantic context and risk tolerances), and they lack the defensive reasoning required to navigate real-world ambiguity. This cognitive gap leads to responses that are superficial, brittle and short-sighted. To address this, we propose Critique-Driven Reasoning Alignment (CDRA), which reframes alignment from a scalar reward-matching task into a structured reasoning process. First, to bridge the preference inference gap, we introduce the DeepPref benchmark. This dataset, comprising 3000 preference-query pairs across 20 topics, is curated by simulating a multi-faceted cognitive council that produces critique-annotated reasoning chains to deconstruct query semantics and reveal latent risks. Second, to instill defensive reasoning, we introduce the Personalized Generative Process Reward Model (Pers-GenPRM), which frames reward modeling as a personalized reasoning task. It generates a critique chain to evaluate a response's alignment with user preferences before outputting a final score based on this rationale. Ultimately, this interpretable, structured reward signal guides policy model through Critique-Driven Policy Alignment, a process-level online reinforcement learning algorithm integrating both numerical and natural language feedback. Experiments demonstrate that CDRA excels at discovering and aligning with users' true preferences while executing robust reasoning. Our code and dataset are available at this https URL. 

**Abstract (ZH)**: 个性化对齐对于使大型语言模型能够有效参与用户为中心的交互至关重要。然而，当前的方法面临双重挑战：它们无法推断出用户的深层隐含偏好（包括未明言的目标、语义背景和风险承受能力），并且缺乏应对现实世界模糊性的防御性推理。这种认知差距导致了表面化、脆弱且目光短浅的响应。为解决这一问题，我们提出批评驱动推理对齐(CDRA)，将对齐重新定义为结构化推理过程，而非标量奖励匹配任务。首先，为了填补偏好推断的差距，我们引入了DeepPref基准数据集。该数据集包含涵盖20个主题的3000个偏好查询对，并通过模拟一个多面向的认知委员会生成带有批评注释的推理链来构建，从而分解查询语义并揭示潜在风险。其次，为灌输防御性推理，我们引入了个性化生成过程奖励模型(Pers-GenPRM)，将其作为个性化的推理任务来构建奖励建模框架。该模型生成一条批评链来评估响应与用户偏好的一致性，然后基于此理由输出最终分数。最终，这种可解释的结构化奖励信号在执行批评驱动策略对齐的过程中通过集成数值和自然语言反馈的进程级在线强化学习算法指导策略模型。实验表明，CDRA在发现和对齐用户的真正偏好方面表现出色，同时执行稳健的推理。我们的代码和数据集可在以下链接获取。 

---
# $How^{2}$: How to learn from procedural How-to questions 

**Title (ZH)**: $How^2$: 如何学习来自过程性如何做问题 

**Authors**: Gautier Dagan, Frank Keller, Alex Lascarides  

**Link**: [PDF](https://arxiv.org/pdf/2510.11144)  

**Abstract**: An agent facing a planning problem can use answers to how-to questions to reduce uncertainty and fill knowledge gaps, helping it solve both current and future tasks. However, their open ended nature, where valid answers to "How do I X?" range from executable actions to high-level descriptions of X's sub-goals, makes them challenging for AI agents to ask, and for AI experts to answer, in ways that support efficient planning. We introduce $How^{2}$, a memory agent framework that enables agents to ask how-to questions, store the answers, and reuse them for lifelong learning in interactive environments. We evaluate our approach in Plancraft, a Minecraft crafting environment, where agents must complete an assembly task by manipulating inventory items. Using teacher models that answer at varying levels of abstraction, from executable action sequences to high-level subgoal descriptions, we show that lifelong learning agents benefit most from answers that are abstracted and decoupled from the current state. $How^{2}$ offers a way for LLM-based agents to improve their planning capabilities over time by asking questions in interactive environments. 

**Abstract (ZH)**: 一个面对规划问题的智能体可以通过提出如何执行任务的问题来减少不确定性并填补知识空白，从而帮助其解决当前和未来的任务。然而，这些问题的开放性质使得它们对于AI智能体提出和AI专家回答以支持高效规划变得具有挑战性。我们引入了$How^{2}$，一个内存智能体框架，使智能体能够提出如何执行任务的问题，存储答案，并在交互环境中进行终身学习。我们在Plancraft（一个Minecraft制作物品环境）中评估了我们的方法，智能体必须通过操作库存物品来完成装配任务。通过使用不同抽象级别的教师模型来回答这些问题，从可执行的动作序列到高层次的子目标描述，我们展示了抽象化和与当前状态解耦的答案对终身学习智能体最为有益。$How^{2}$为基于LLM的智能体提供了一种在交互环境中通过提问来逐步提高其规划能力的方法。 

---
# Spec-Driven AI for Science: The ARIA Framework for Automated and Reproducible Data Analysis 

**Title (ZH)**: 基于规格的AI科学：ARIA框架下的自动化和可重复数据分析 

**Authors**: Chuke Chen, Biao Luo, Nan Li, Boxiang Wang, Hang Yang, Jing Guo, Ming Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11143)  

**Abstract**: The rapid expansion of scientific data has widened the gap between analytical capability and research intent. Existing AI-based analysis tools, ranging from AutoML frameworks to agentic research assistants, either favor automation over transparency or depend on manual scripting that hinders scalability and reproducibility. We present ARIA (Automated Research Intelligence Assistant), a spec-driven, human-in-the-loop framework for automated and interpretable data analysis. ARIA integrates six interoperable layers, namely Command, Context, Code, Data, Orchestration, and AI Module, within a document-centric workflow that unifies human reasoning and machine execution. Through natural-language specifications, researchers define analytical goals while ARIA autonomously generates executable code, validates computations, and produces transparent documentation. Beyond achieving high predictive accuracy, ARIA can rapidly identify optimal feature sets and select suitable models, minimizing redundant tuning and repetitive experimentation. In the Boston Housing case, ARIA discovered 25 key features and determined XGBoost as the best performing model (R square = 0.93) with minimal overfitting. Evaluations across heterogeneous domains demonstrate ARIA's strong performance, interpretability, and efficiency compared with state-of-the-art systems. By combining AI for research and AI for science principles within a spec-driven architecture, ARIA establishes a new paradigm for transparent, collaborative, and reproducible scientific discovery. 

**Abstract (ZH)**: 科学数据的迅速扩展加剧了分析能力和研究意图之间的差距。现有的基于AI的分析工具，从AutoML框架到代理型研究助手，要么偏向自动化而忽视透明度，要么依赖手工脚本，这阻碍了可扩展性和可重复性。我们提出了ARIAS（Automated Research Intelligence Assistant），一种基于规格、包含人类在环的框架，用于自动化和可解释的数据分析。ARIAS将六个可互操作的层——命令、上下文、代码、数据、编排和AI模块——集成在一个文档为中心的工作流中，统一了人类推理和机器执行。通过自然语言规格说明，研究人员定义分析目标，而ARIAS自主生成可执行代码、验证计算并生成透明文档。除了实现高度预测准确性外，ARIAS还可以快速识别最佳特征集并选择合适的模型，最小化冗余调优和重复实验。在波士顿住房案例中，ARIAS发现了25个关键特征，并确定XGBoost为最佳性能模型（R² = 0.93），且过度拟合最小。横跨不同领域的评估显示，ARIAS在可解释性和效率方面优于现有最先进的系统。通过在一个基于规格的架构中结合研究中的AI和科学中的AI原则，ARIAS确立了一种新的透明、协作和可重复的科学发现范式。 

---
# Improving AI Efficiency in Data Centres by Power Dynamic Response 

**Title (ZH)**: 通过电力动态响应提高数据中心中人工智能的效率 

**Authors**: Andrea Marinoni, Sai Shivareddy, Pietro Lio', Weisi Lin, Erik Cambria, Clare Grey  

**Link**: [PDF](https://arxiv.org/pdf/2510.11119)  

**Abstract**: The steady growth of artificial intelligence (AI) has accelerated in the recent years, facilitated by the development of sophisticated models such as large language models and foundation models. Ensuring robust and reliable power infrastructures is fundamental to take advantage of the full potential of AI. However, AI data centres are extremely hungry for power, putting the problem of their power management in the spotlight, especially with respect to their impact on environment and sustainable development. In this work, we investigate the capacity and limits of solutions based on an innovative approach for the power management of AI data centres, i.e., making part of the input power as dynamic as the power used for data-computing functions. The performance of passive and active devices are quantified and compared in terms of computational gain, energy efficiency, reduction of capital expenditure, and management costs by analysing power trends from multiple data platforms worldwide. This strategy, which identifies a paradigm shift in the AI data centre power management, has the potential to strongly improve the sustainability of AI hyperscalers, enhancing their footprint on environmental, financial, and societal fields. 

**Abstract (ZH)**: 近年来，人工智能（AI）的稳步增长得到了复杂模型如大型语言模型和基础模型的发展加速。确保强大的可靠电力基础设施是充分利用AI潜力的关键。然而，AI数据中心极为依赖电力，使得其电力管理问题备受关注，特别是在其对环境和可持续发展的影响方面。在本研究中，我们调查了一种创新方法在AI数据中心电力管理中的能力和局限性，即部分输入电力动态化，与用于数据计算功能的电力使用情况相匹配。通过分析全球多个数据平台的电力趋势，定量比较被动和主动设备在计算增益、能量效率、降低资本支出和管理成本方面的性能。这种策略标志着AI数据中心电力管理范式的转变，有潜力显著提高AI超大规模数据中心的可持续性，增强其在环境、财务和社会领域的影响力。 

---
# Modeling AI-Driven Production and Competitiveness A Multi-Agent Economic Simulation of China and the United States 

**Title (ZH)**: 基于多agent经济模拟的AI驱动生产与中国和美国的竞争模型 

**Authors**: Yuxinyue Qian, Jun Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11085)  

**Abstract**: With the rapid development of artificial intelligence (AI) technology, socio-economic systems are entering a new stage of "human-AI co-creation." Building upon a previously established multi-level intelligent agent economic model, this paper conducts simulation-based comparisons of macroeconomic output evolution in China and the United States under different mechanisms-AI collaboration, network effects, and AI autonomous production. The results show that: (1) when AI functions as an independent productive entity, the overall growth rate of social output far exceeds that of traditional human-labor-based models; (2) China demonstrates clear potential for acceleration in both the expansion of intelligent agent populations and the pace of technological catch-up, offering the possibility of achieving technological convergence or even partial surpassing. This study provides a systematic, model-based analytical framework for understanding AI-driven production system transformation and shifts in international competitiveness, as well as quantitative insights for relevant policy formulation. 

**Abstract (ZH)**: 随着人工智能（AI）技术的迅速发展，社会经济系统进入了“人机共创”的新阶段。在建立在先前多层级智能代理经济模型基础上，本文通过基于仿真的比较研究了中美在不同机制下（AI协作、网络效应和AI自主生产）宏观经济产出演化的差异。研究结果表明：（1）当AI作为独立生产实体发挥作用时，社会产出的整体增长速率远超基于传统人力模型的增长速率；（2）中国在智能代理群体扩展和技术创新追赶方面显示出明显的加速潜力，有可能实现技术收敛甚至部分超越。本研究提供了基于模型的系统性分析框架，用于理解AI驱动的生产系统转型及国际竞争力变化，并为相关政策制定提供了量化参考。 

---
# Argumentation-Based Explainability for Legal AI: Comparative and Regulatory Perspectives 

**Title (ZH)**: 基于论证的法律AI解释性：对比和监管视角 

**Authors**: Andrada Iulia Prajescu, Roberto Confalonieri  

**Link**: [PDF](https://arxiv.org/pdf/2510.11079)  

**Abstract**: Artificial Intelligence (AI) systems are increasingly deployed in legal contexts, where their opacity raises significant challenges for fairness, accountability, and trust. The so-called ``black box problem'' undermines the legitimacy of automated decision-making, as affected individuals often lack access to meaningful explanations. In response, the field of Explainable AI (XAI) has proposed a variety of methods to enhance transparency, ranging from example-based and rule-based techniques to hybrid and argumentation-based approaches. This paper promotes computational models of arguments and their role in providing legally relevant explanations, with particular attention to their alignment with emerging regulatory frameworks such as the EU General Data Protection Regulation (GDPR) and the Artificial Intelligence Act (AIA). We analyze the strengths and limitations of different explanation strategies, evaluate their applicability to legal reasoning, and highlight how argumentation frameworks -- by capturing the defeasible, contestable, and value-sensitive nature of law -- offer a particularly robust foundation for explainable legal AI. Finally, we identify open challenges and research directions, including bias mitigation, empirical validation in judicial settings, and compliance with evolving ethical and legal standards, arguing that computational argumentation is best positioned to meet both technical and normative requirements of transparency in the law domain. 

**Abstract (ZH)**: 人工智能（AI）系统在法律情境中的应用日益增多，其不透明性对公平性、问责制和信任提出了重大挑战。“黑箱问题”削弱了自动化决策的合法性，受影响的个体往往无法获得有意义的解释。为此，可解释人工智能（XAI）领域提出了多种增强透明度的方法，从基于例证和基于规则的技术到混合和基于论辩的方法。本文促进计算论证模型及其在提供法律相关解释中的作用，特别关注其与欧盟通用数据保护条例（GDPR）和人工智能法案（AIA）等新兴监管框架的契合。我们分析了不同解释策略的优势与局限性，评估了它们在法律推理中的适用性，并强调论辩框架通过捕捉法律的可驳倒性、可争议性和价值敏感性，为可解释的法律人工智能提供了特别稳健的基础。最后，我们指出了开放挑战和研究方向，包括偏见缓解、在司法环境中进行实证验证以及遵守不断演变的伦理和法律标准，认为计算论辩最有可能满足法律领域透明性的技术和规范要求。 

---
# FBS Model-based Maintenance Record Accumulation for Failure-Cause Inference in Manufacturing Systems 

**Title (ZH)**: 基于FBS模型的故障原因推断制造系统维修记录累积 

**Authors**: Takuma Fujiu, Sho Okazaki, Kohei Kaminishi, Yuji Nakata, Shota Hamamoto, Kenshin Yokose, Tatsunori Hara, Yasushi Umeda, Jun Ota  

**Link**: [PDF](https://arxiv.org/pdf/2510.11003)  

**Abstract**: In manufacturing systems, identifying the causes of failures is crucial for maintaining and improving production efficiency. In knowledge-based failure-cause inference, it is important that the knowledge base (1) explicitly structures knowledge about the target system and about failures, and (2) contains sufficiently long causal chains of failures. In this study, we constructed Diagnostic Knowledge Ontology and proposed a Function-Behavior-Structure (FBS) model-based maintenance-record accumulation method based on it. Failure-cause inference using the maintenance records accumulated by the proposed method showed better agreement with the set of candidate causes enumerated by experts, especially in difficult cases where the number of related cases is small and the vocabulary used differs. In the future, it will be necessary to develop inference methods tailored to these maintenance records, build a user interface, and carry out validation on larger and more diverse systems. Additionally, this approach leverages the understanding and knowledge of the target in the design phase to support knowledge accumulation and problem solving during the maintenance phase, and it is expected to become a foundation for knowledge sharing across the entire engineering chain in the future. 

**Abstract (ZH)**: 在制造系统中，识别故障原因对于维护和提高生产效率至关重要。基于知识的故障原因推理中，知识库需要（1）明确结构化目标系统和故障的知识，并且（2）包含足够长的故障因果链。在本研究中，我们构建了诊断知识本体，并提出了基于该本体的函数-行为-结构（FBS）模型驱动的维护记录积累方法。采用所提出方法积累的维护记录进行的故障原因推理与专家列出的候选原因有更好的一致性，特别是在相关案例较少且使用的词汇不同的困难情况下。未来需要开发针对这些维护记录的推理方法，构建用户界面，并在更大和更多样化的系统上进行验证。此外，该方法在设计阶段利用对目标的理解和知识来支持维护阶段的知识积累和问题解决，并有望成为跨整个工程链的知识共享的基础。 

---
# Revisiting Model Interpolation for Efficient Reasoning 

**Title (ZH)**: 重新审视模型内插以实现高效推理 

**Authors**: Taiqiang Wu, Runming Yang, Tao Liu, Jiahao Wang, Ngai Wong  

**Link**: [PDF](https://arxiv.org/pdf/2510.10977)  

**Abstract**: Model merging, typically on Instruct and Thinking models, has shown remarkable performance for efficient reasoning. In this paper, we systematically revisit the simplest merging method that interpolates two weights directly. Particularly, we observe that model interpolation follows a three-stage evolutionary paradigm with distinct behaviors on the reasoning trajectory. These dynamics provide a principled guide for navigating the performance-cost trade-off. Empirical results demonstrate that a strategically interpolated model surprisingly surpasses sophisticated model merging baselines on both efficiency and effectiveness. We further validate our findings with extensive ablation studies on model layers, modules, and decoding strategies. Ultimately, this work demystifies model interpolation and offers a practical framework for crafting models with precisely targeted reasoning capabilities. Code is available at \href{this https URL}{Github}. 

**Abstract (ZH)**: 模型插值，尤其是在指令模型和思考模型上的应用，展现了高效的推理性能。本文系统回顾了直接插值两种权重的最简单合并方法，并观察到模型插值遵循一个具有三个阶段演化范式的动态过程，这些动态为性能与成本权衡提供了原则性的指导。实验证明，战略性插值的模型在效率和效果上竟然超过了复杂的模型合并基准。我们还通过广泛的消融研究进一步验证了这些发现，涉及模型层、模块和解码策略。最终，本工作揭开模型插值的神秘面纱，并提供了一个实用的框架来构建具有精确推理能力的模型。代码可在Github获得。 

---
# Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph 

**Title (ZH)**: Video-STR：通过关系图增强视频时空推理的MLLMs 

**Authors**: Wentao Wang, Heqing Zou, Tianze Luo, Rui Huang, Yutian Zhao, Zhuochen Wang, Hansheng Zhang, Chengwei Qin, Yan Wang, Lin Zhao, Huaijian Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10976)  

**Abstract**: Recent progress in Multimodal Large Language Models (MLLMs) has demonstrated strong semantic understanding capabilities, but struggles to perform precise spatio-temporal understanding. Existing spatio-temporal methods primarily focus on the video itself, while overlooking the physical information within the video, such as multi-object layouts and motion. Such limitations restrict the use of MLLMs in downstream applications that demand high precision, including embodied intelligence and VR. To address this issue, we present Video-STR, a novel graph-based reinforcement method for precise Video Spatio-Temporal Reasoning. Building upon the capacity of Reinforcement Learning with Verifiable Reward (RLVR) to improve model abilities, we introduce a reasoning mechanism using graph-based Group Relative Policy Optimization (GRPO) method to guide the model in inferring the underlying spatio-temporal topology of scenarios during the thinking process. To resolve the lack of spatio-temporal training data, we construct the STV-205k dataset with 205k question-answering pairs, covering dynamic multi-object scenes in both indoor and outdoor environments, to support the model training. Experiments show that Video-STR achieves state-of-the-art results on various benchmarks, outperforming the base model by 13% on STI-Bench, and demonstrating the effectiveness of our approach and dataset. Code, model, and data will be released. 

**Abstract (ZH)**: Recent Progress in Multimodal Large Language Models (MLLMs) 的空间时间理解能力取得了进展，但仍然难以进行精确的空间时间理解。现有空间时间方法主要关注视频本身，而忽略了视频中的物理信息，如多对象布局和运动。这些限制限制了MLLMs在需要高精度的下游应用中的使用，包括嵌入式智能和VR。为了解决这一问题，我们提出Video-STR，一种基于图的增强学习方法，用于精确的视频空间时间推理。基于可验证奖励的增强学习（RLVR）来提高模型能力，我们引入了一种基于图的组相对策略优化（GRPO）方法，该方法在推理过程中引导模型推断场景的潜在空间时间拓扑结构。为了解决缺乏空间时间训练数据的问题，我们构建了包含205,000个问答对的STV-205k数据集，覆盖室内外动态多对象场景，以支持模型训练。实验结果表明，Video-STR在各种基准测试中达到了最先进的性能，在STI-Bench上的表现比基础模型高出13%，证明了我们方法和数据集的有效性。代码、模型和数据将公开发布。 

---
# Scalable and Explainable Enterprise Knowledge Discovery Using Graph-Centric Hybrid Retrieval 

**Title (ZH)**: 基于图中心混合检索的企业可扩展性和可解释性知识发现 

**Authors**: Nilima Rao, Jagriti Srivastava, Pradeep Kumar Sharma, Hritvik Shrivastava  

**Link**: [PDF](https://arxiv.org/pdf/2510.10942)  

**Abstract**: Modern enterprises manage vast knowledge distributed across heterogeneous systems such as Jira, Git repositories, Confluence, and wikis. Conventional retrieval methods based on keyword search or static embeddings often fail to answer complex queries that require contextual reasoning and multi-hop inference across artifacts. We present a modular hybrid retrieval framework for adaptive enterprise information access that integrates Knowledge Base Language-Augmented Models (KBLam), DeepGraph representations, and embedding-driven semantic search. The framework builds a unified knowledge graph from parsed repositories including code, pull requests, and commit histories, enabling semantic similarity search, structural inference, and multi-hop reasoning. Query analysis dynamically determines the optimal retrieval strategy, supporting both structured and unstructured data sources through independent or fused processing. An interactive interface provides graph visualizations, subgraph exploration, and context-aware query routing to generate concise and explainable answers. Experiments on large-scale Git repositories show that the unified reasoning layer improves answer relevance by up to 80 percent compared with standalone GPT-based retrieval pipelines. By combining graph construction, hybrid reasoning, and interactive visualization, the proposed framework offers a scalable, explainable, and user-centric foundation for intelligent knowledge assistants in enterprise environments. 

**Abstract (ZH)**: 现代企业使用Jira、Git仓库、Confluence和维基等异构系统管理广泛的知识。基于关键词搜索或静态嵌入的传统检索方法往往无法回答需要上下文推理和多跳推理的复杂查询。我们提出了一种模块化混合检索框架，用于适应性的企业信息访问，该框架结合了知识库语言增强模型（KBLam）、深度图表示和嵌入驱动的语义搜索。该框架从解析的仓库（包括代码、拉取请求和提交历史）中构建统一的知识图谱，实现语义相似搜索、结构推理和多跳推理。查询分析动态确定最佳检索策略，支持通过独立或融合处理结构化和非结构化数据源。交互式界面提供图可视化、子图探索和上下文感知查询路由，生成简洁且可解释的答案。 experiment on大规模Git仓库表明，统一推理层相比于基于GPT的独立检索流水线，答案的相关性提高了80%。通过结合图构建、混合推理和交互式可视化，所提框架为企业环境中智能知识助理提供了一个可扩展、可解释且用户中心的基础。 

---
# PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents 

**Title (ZH)**: PoU: 证明用途以对抗工具调用 hacking 在深度研究代理中的攻击 

**Authors**: SHengjie Ma, Chenlong Deng, Jiaxin Mao, Jiadeng Huang, Teng Wang, Junjie Wu, Changwang Zhang, Jun wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10931)  

**Abstract**: Retrieval-augmented generation (RAG) agents, such as recent DeepResearch-style systems, extend large language models (LLMs) with autonomous information-seeking capabilities through external tools. While reinforcement learning (RL) has enabled impressive multi-step reasoning, we identify a previously overlooked failure mode, Tool-Call Hacking, where agents inflate reward signals by issuing superficially correct tool calls without genuinely leveraging the retrieved evidence. This results in (i) mode collapse into repetitive reliance on a single source and (ii) spurious grounding, where answers are only weakly supported by cited content.
To address this, we propose Proof-of-Use (PoU), an evidence-grounded RL framework that enforces verifiable causal links between retrieved evidence, reasoning traces, and final answers. PoU operationalizes this through a unified step-wise contract combining syntactic citation validation, perturbation-based sensitivity rewards, and answer-evidence alignment objectives, ensuring that tool usage remains both interpretable and functionally grounded.
Across seven QA benchmarks spanning in-domain, out-of-domain, and out-of-tool-distribution settings, PoU consistently outperforms strong DeepResearch baselines in factual accuracy, evidence faithfulness, and tool-routing balance. These findings highlight the necessity of grounding RL-trained agents not merely in task outcomes but in the causal use of retrieved information, offering a principled path toward trustworthy retrieval-augmented reasoning. 

**Abstract (ZH)**: 基于检索的生成（RAG）代理：基于证据的奖励学习框架（PoU） 

---
# PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature 

**Title (ZH)**: PaperArena: 一种用于科学文献中介动推理工具增强的评估基准 

**Authors**: Daoyu Wang, Mingyue Cheng, Qi Liu, Shuo Yu, Zirui Liu, Ze Guo  

**Link**: [PDF](https://arxiv.org/pdf/2510.10909)  

**Abstract**: Understanding and reasoning on the web-scale scientific literature is a crucial touchstone for large language model (LLM) based agents designed to support complex knowledge-intensive tasks. However, existing works are mainly restricted to tool-free tasks within isolated papers, largely due to the lack of a benchmark for cross-paper reasoning and multi-tool orchestration in real research scenarios. In this work, we propose PaperArena, an evaluation benchmark for agents to address real-world research questions that typically require integrating information across multiple papers with the assistance of external tools. Given a research question, agents should integrate diverse formats across multiple papers through reasoning and interacting with appropriate tools, thereby producing a well-grounded answer. To support standardized evaluation, we provide a modular and extensible platform for agent execution, offering tools such as multimodal parsing, context retrieval, and programmatic computation. Experimental results reveal that even the most advanced LLM powering a well-established agent system achieves merely 38.78% average accuracy. On the hard subset, accuracy drops to only 18.47%, highlighting great potential for improvement. We also present several empirical findings, including that all agents tested exhibit inefficient tool usage, often invoking more tools than necessary to solve a task. We invite the community to adopt PaperArena to develop and evaluate more capable agents for scientific discovery. Our code and data are available this https URL. 

**Abstract (ZH)**: 大规模网络科学文献的理解与推理是基于大型语言模型的代理支持复杂知识密集型任务的关键试金石。然而，现有工作主要局限于孤立论文中的无工具任务，很大程度上是因为缺乏跨论文推理和多工具协调的基准。在本文中，我们提出PaperArena，一个用于代理应对通常需要跨多篇论文综合信息并借助外部工具解决的实际研究问题的评估基准。通过给定一个研究问题，代理需要通过推理和与适当工具交互来整合多种格式的信息，从而生成一个有根据的答案。为了支持标准化评估，我们提供了一个模块化且可扩展的代理执行平台，提供了诸如多模态解析、上下文检索和程序化计算等工具。实验结果表明，即使最先进的大型语言模型驱动的成熟代理系统也只能达到平均38.78%的准确率。在难题子集中，准确率仅下降到18.47%，突显了巨大的改进潜力。我们还呈现了几项实证发现，包括所有测试的代理均表现出低效的工具使用，经常调用不必要的工具来完成任务。我们邀请社区采用PaperArena来开发和评估更具能力的科学发现代理。我们的代码和数据可在以下网址获得：这个 https URL。 

---
# LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach 

**Title (ZH)**: LLM赋能的代理MAC协议：一种动态Stackelberg博弈方法 

**Authors**: Renxuan Tan, Rongpeng Li, Fei Wang, Chenghui Peng, Shaoyun Wu, Zhifeng Zhao, Honggang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10895)  

**Abstract**: Medium Access Control (MAC) protocols, essential for wireless networks, are typically manually configured. While deep reinforcement learning (DRL)-based protocols enhance task-specified network performance, they suffer from poor generalizability and resilience, demanding costly retraining to adapt to dynamic environments. To overcome this limitation, we introduce a game-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which the uplink transmission between a base station and a varying number of user equipments is modeled as a dynamic multi-follower Stackelberg game (MFSG), capturing the network's natural hierarchical structure. Within this game, LLM-driven agents, coordinated through proximal policy optimization (PPO), synthesize adaptive, semantic MAC protocols in response to network dynamics. Protocol action grammar (PAG) is employed to ensure the reliability and efficiency of this process. Under this system, we further analyze the existence and convergence behavior in terms of a Stackelberg equilibrium by studying the learning dynamics of LLM-empowered unified policies in response to changing followers. Simulations corroborate that our framework achieves a 77.6% greater throughput and a 65.2% fairness improvement over conventional baselines. Besides, our framework generalizes excellently to a fluctuating number of users without requiring retraining or architectural changes. 

**Abstract (ZH)**: 基于游戏理论的LLM赋能多代理DRL（MARL）的MAC协议设计 

---
# The Irrational Machine: Neurosis and the Limits of Algorithmic Safety 

**Title (ZH)**: 非理性的机器：神经症与算法安全性极限 

**Authors**: Daniel Howard  

**Link**: [PDF](https://arxiv.org/pdf/2510.10823)  

**Abstract**: We present a framework for characterizing neurosis in embodied AI: behaviors that are internally coherent yet misaligned with reality, arising from interactions among planning, uncertainty handling, and aversive memory. In a grid navigation stack we catalogue recurrent modalities including flip-flop, plan churn, perseveration loops, paralysis and hypervigilance, futile search, belief incoherence, tie break thrashing, corridor thrashing, optimality compulsion, metric mismatch, policy oscillation, and limited-visibility variants. For each we give lightweight online detectors and reusable escape policies (short commitments, a margin to switch, smoothing, principled arbitration). We then show that durable phobic avoidance can persist even under full visibility when learned aversive costs dominate local choice, producing long detours despite globally safe routes. Using First/Second/Third Law as engineering shorthand for safety latency, command compliance, and resource efficiency, we argue that local fixes are insufficient; global failures can remain. To surface them, we propose genetic-programming based destructive testing that evolves worlds and perturbations to maximize law pressure and neurosis scores, yielding adversarial curricula and counterfactual traces that expose where architectural revision, not merely symptom-level patches, is required. 

**Abstract (ZH)**: 我们提出了一种表征具身人工智能神经质的框架：内部一致但与现实不一致的行为，源于规划、不确定性处理和厌恶记忆之间的交互。在网格导航堆栈中，我们列出了重复出现的模态，包括 flip-flop、计划翻滚、执着循环、瘫痪、高度警觉、无意义搜索、信念不一致、犹豫不决、走廊翻滚、优化强迫、度量匹配不一致、政策振荡以及有限视距变体。对于每种模态，我们提供了轻量级的在线检测器和可重用的逃避策略（短暂的承诺、切换的余量、平滑处理、基于原理的仲裁）。随后，我们展示即使在完全可视情况下，如果学习到的厌恶成本主导局部选择时，持久的恐惧回避仍可能持续，导致尽管全局路线安全却出现长距离绕行。使用First/Second/Third Law作为工程简写，代表安全延迟、命令合规性和资源效率，我们认为局部修复是不够的；全局失败可能仍然存在。为了揭示这些失败，我们提出了基于遗传编程的破坏性测试，通过进化世界和扰动来最大化法则压力和神经质分数，产生对抗性的课程和假设检验轨迹，以显示需要对架构进行修订，而不仅仅是症状级别的修补。 

---
# DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems 

**Title (ZH)**: DRIFT: 分解、检索、示证、然后形式化定理 

**Authors**: Meiru Zhang, Philipp Borchert, Milan Gritta, Gerasimos Lampouras  

**Link**: [PDF](https://arxiv.org/pdf/2510.10815)  

**Abstract**: Automating the formalization of mathematical statements for theorem proving remains a major challenge for Large Language Models (LLMs). LLMs struggle to identify and utilize the prerequisite mathematical knowledge and its corresponding formal representation in languages like Lean. Current retrieval-augmented autoformalization methods query external libraries using the informal statement directly, but overlook a fundamental limitation: informal mathematical statements are often complex and offer limited context on the underlying math concepts. To address this, we introduce DRIFT, a novel framework that enables LLMs to decompose informal mathematical statements into smaller, more tractable ''sub-components''. This facilitates targeted retrieval of premises from mathematical libraries such as Mathlib. Additionally, DRIFT retrieves illustrative theorems to help models use premises more effectively in formalization tasks. We evaluate DRIFT across diverse benchmarks (ProofNet, ConNF, and MiniF2F-test) and find that it consistently improves premise retrieval, nearly doubling the F1 score compared to the DPR baseline on ProofNet. Notably, DRIFT demonstrates strong performance on the out-of-distribution ConNF benchmark, with BEq+@10 improvements of 37.14% and 42.25% using GPT-4.1 and DeepSeek-V3.1, respectively. Our analysis shows that retrieval effectiveness in mathematical autoformalization depends heavily on model-specific knowledge boundaries, highlighting the need for adaptive retrieval strategies aligned with each model's capabilities. 

**Abstract (ZH)**: 自动化数学陈述的形式化以实现定理证明仍然是大型语言模型的主要挑战。当前的检索增强自动形式化方法直接使用非形式化的陈述查询外部库，但忽视了一个基本限制：非形式化的数学陈述往往复杂且对底层数学概念的上下文限制较少。为解决这一问题，我们提出了DRIFT，一种新型框架，使大型语言模型能够将非形式化的数学陈述分解为更小、更易于处理的“子组件”。这有助于有针对性地从如Mathlib的数学库中检索前提。此外，DRIFT检索示例定理以帮助模型更有效地在形式化任务中使用前提。我们在ProofNet、ConNF和MiniF2F-test等多样化的基准测试上评估DRIFT，并发现它一致地改善了前提检索效果，在ProofNet基准测试上，与DPR基线相比，F1分数提高了近一倍。值得注意的是，DRIFT在分布外的ConNF基准测试上表现出色，分别使用GPT-4.1和DeepSeek-V3.1时，BEq+@10改进了37.14%和42.25%。我们的分析表明，在数学自动形式化中的检索效果高度依赖于模型特定的知识边界，突显了需要与每个模型的能力相适应的检索策略的重要性。 

---
# LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent Heuristics 

**Title (ZH)**: LLMs作为战略代理：信念、最佳反应行为与 emergent 经验法则 

**Authors**: Enric Junque de Fortuny, Veronica Roberta Cappelli  

**Link**: [PDF](https://arxiv.org/pdf/2510.10813)  

**Abstract**: Large Language Models (LLMs) are increasingly applied to domains that require reasoning about other agents' behavior, such as negotiation, policy design, and market simulation, yet existing research has mostly evaluated their adherence to equilibrium play or their exhibited depth of reasoning. Whether they display genuine strategic thinking, understood as the coherent formation of beliefs about other agents, evaluation of possible actions, and choice based on those beliefs, remains unexplored. We develop a framework to identify this ability by disentangling beliefs, evaluation, and choice in static, complete-information games, and apply it across a series of non-cooperative environments. By jointly analyzing models' revealed choices and reasoning traces, and introducing a new context-free game to rule out imitation from memorization, we show that current frontier models exhibit belief-coherent best-response behavior at targeted reasoning depths. When unconstrained, they self-limit their depth of reasoning and form differentiated conjectures about human and synthetic opponents, revealing an emergent form of meta-reasoning. Under increasing complexity, explicit recursion gives way to internally generated heuristic rules of choice that are stable, model-specific, and distinct from known human biases. These findings indicate that belief coherence, meta-reasoning, and novel heuristic formation can emerge jointly from language modeling objectives, providing a structured basis for the study of strategic cognition in artificial agents. 

**Abstract (ZH)**: 大型语言模型（LLMs）在需要推断其他代理行为的领域（如谈判、政策设计和市场模拟）的应用日益增多，现有研究主要评估它们是否遵循均衡行为或表现出深度推理，但它们是否表现出真正意义上的战略思考——即形成关于其他代理的连贯信念、评估可能的行为，并基于这些信念进行选择——仍未被探索。我们开发了一个框架以通过分离信念、评估和选择来识别这种能力，并将其应用于一系列非合作环境中。通过联合分析模型的已显性选择和推理轨迹，并引入一个无上下文的游戏排除记忆性的模仿，我们表明当前前沿模型在目标推理深度上表现出一致的信念最佳响应行为。在不受限制的情况下，它们会自我限制推理深度，并形成对人类和合成对手的不同假设，揭示了一种新的元推理形式。随着复杂性的增加，显式的递归让位于内部生成的选择启发式规则，这些规则是稳定的、模型特定的，并不同于已知的人类偏差。这些发现表明，连贯的信念、元推理和新颖启发式规则的形成可以从语言建模目标中共同涌现，为人工代理的战略认知研究提供了结构化的基础。 

---
# Adaptive Selection of Symbolic Languages for Improving LLM Logical Reasoning 

**Title (ZH)**: 符号语言自适应选择以提高大语言模型逻辑推理能力 

**Authors**: Xiangyu Wang, Haocheng Yang, Fengxiang Cheng, Fenrong Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10703)  

**Abstract**: Large Language Models (LLMs) still struggle with complex logical reasoning. While previous works achieve remarkable improvements, their performance is highly dependent on the correctness of translating natural language (NL) problems into a symbolic language (SL). Though numerous works focusing on improving this translation accuracy, they only consider the similarity between the meaning of SL and NL, overlooking another crucial influencing factor, the selection of the target SL type itself. For example, first-order logic language specializes in logical reasoning with categorical syllogisms and complex quantifiers, while Boolean satisfiability formalism excels at representing constraint satisfaction like partial problems. To our knowledge, this is the first paper to claim and verify that different NL logical reasoning problem corresponds to different optimal SL formalization for translation. Based on this, we propose a methods to improve the logical reasoning performance of LLMs by adaptively selecting the most suitable SL for each problem prior to translation. Specifically, we leverage LLMs to select the target SL among first-order logic, logic programming and Boolean satisfiability and then translate the problem in NL to target SL expressions as well as employ the corresponding logical solver to derive the final answer. Experimental results on benchmarks show that our adaptive selection method significantly outperforms translating all into single SL and randomly selecting the SL. On a mixed dataset of these benchmarks, our approach achieves 96% accuracy, which improving performance by 25% compared to the second highest accuracy from the first-order logic translation. 

**Abstract (ZH)**: 大型语言模型（LLMs）在复杂逻辑推理方面仍存在挑战。尽管先前的工作取得了显著的改进，但其性能高度依赖于自然语言（NL）问题向符号语言（SL）的正确翻译。尽管有许多工作专注于提高这种翻译的准确性，它们仅考虑SL和NL之间的相似性，而忽视了选择目标SL类型本身这一关键影响因素。例如，一阶逻辑语言擅长处理范畴三段论和复杂量词，而布尔可满足性形式主义则擅长表示诸如不完全问题的约束满足。据我们所知，这是第一篇提出并验证不同NL逻辑推理问题对应于不同的最优SL形式化以进行翻译的文章。基于此，我们提出了一种方法，通过在翻译前适应性选择最合适的SL来提高LLM的逻辑推理性能。具体来说，我们利用LLMs在一阶逻辑、逻辑编程和布尔可满足性之间选择目标SL，然后将NL问题翻译为目标SL表达式，并使用相应的逻辑求解器推导出最终答案。在基准测试上的实验结果表明，我们的适应性选择方法显著优于将所有内容翻译为单一SL或将SL随机选择的方法。在这些基准测试的混合数据集上，我们的方法达到了96%的准确率，与一阶逻辑翻译的最高准确率相比提高了25%。 

---
# Extended Triangular Method: A Generalized Algorithm for Contradiction Separation Based Automated Deduction 

**Title (ZH)**: 扩展三角形方法：基于自动化推理的矛盾分离广义算法 

**Authors**: Yang Xu, Shuwei Chen, Jun Liu, Feng Cao, Xingxing He  

**Link**: [PDF](https://arxiv.org/pdf/2510.10701)  

**Abstract**: Automated deduction lies at the core of Artificial Intelligence (AI), underpinning theorem proving, formal verification, and logical reasoning. Despite decades of progress, reconciling deductive completeness with computational efficiency remains an enduring challenge. Traditional reasoning calculi, grounded in binary resolution, restrict inference to pairwise clause interactions and thereby limit deductive synergy among multiple clauses. The Contradiction Separation Extension (CSE) framework, introduced in 2018, proposed a dynamic multi-clause reasoning theory that redefined logical inference as a process of contradiction separation rather than sequential resolution. While that work established the theoretical foundation, its algorithmic realization remained unformalized and unpublished. This work presents the Extended Triangular Method (ETM), a generalized contradiction-construction algorithm that formalizes and extends the internal mechanisms of contradiction separation. The ETM unifies multiple contradiction-building strategies, including the earlier Standard Extension method, within a triangular geometric framework that supports flexible clause interaction and dynamic synergy. ETM serves as the algorithmic core of several high-performance theorem provers, CSE, CSE-E, CSI-E, and CSI-Enig, whose competitive results in standard first-order benchmarks (TPTP problem sets and CASC 2018-2015) empirically validate the effectiveness and generality of the proposed approach. By bridging theoretical abstraction and operational implementation, ETM advances the contradiction separation paradigm into a generalized, scalable, and practically competitive model for automated reasoning, offering new directions for future research in logical inference and theorem proving. 

**Abstract (ZH)**: 自动推理是人工智能的核心，支撑着定理证明、形式验证和逻辑推理。尽管历经数十年的发展，如何在保证完全性的同时提高计算效率依然是一项持久的挑战。传统的基于二元归结的推理算法限制了多句之间的推理协同，仅允许成对的短语交互。2018年引入的矛盾分离扩展（CSE）框架提出了一种动态的多句推理理论，将逻辑推理重新定义为矛盾分离的过程，而非逐步归结。虽然该工作奠定了理论基础，但其算法实现仍未正式化和发表。本文介绍了扩展三角法（ETM），这是一种形式化并扩展矛盾分离内部机制的通用矛盾构建算法。ETM 统一了包括早期标准扩展方法在内的多种矛盾构建策略，在三角形几何框架下支持灵活的句法交互和动态协同。ETM 成为了多个高性能定理证明器，如 CSE、CSE-E、CSI-E 和 CSI-Enig 的核心算法，其在标准一阶逻辑基准测试（TPTP 问题集和 CASC 2018-2015）中的竞争结果经验性地验证了该方法的有效性和普适性。通过将理论抽象与操作实施相结合，ETM 将矛盾分离范式推进到了一个通用、可扩展且在自动化推理方面具有竞争力的模型，为未来逻辑推理和定理证明的研究提供了新的方向。 

---
# OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs 

**Title (ZH)**: 全方位视频基准：面向全方位MLLMs的视听理解评估 

**Authors**: Caorui Li, Yu Chen, Yiyan Ji, Jin Xu, Zhenyu Cui, Shihao Li, Yuanxing Zhang, Jiafu Tang, Zhenghao Song, Dingling Zhang, Ying He, Haoxiang Liu, Yuxuan Wang, Qiufeng Wang, Zhenhe Wu, Jiehui Luo, Zhiyu Pan, Weihao Xie, Chenchen Zhang, Zhaohui Wang, Jiayi Tian, Yanghai Wang, Zhe Cao, Minxin Dai, Ke Wang, Runzhe Wen, Yinghao Ma, Yaning Pan, Sungkyun Chang, Termeh Taheri, Haiwen Xia, Christos Plachouras, Emmanouil Benetos, Yizhi Li, Ge Zhang, Jian Yang, Tianhao Peng, Zili Wang, Minghao Liu, Junran Peng, Zhaoxiang Zhang, Jiaheng Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10689)  

**Abstract**: Recent advances in multimodal large language models (MLLMs) have demonstrated substantial potential in video understanding. However, existing benchmarks fail to comprehensively evaluate synergistic reasoning capabilities across audio and visual modalities, often neglecting either one of the modalities or integrating them in a logically inconsistent manner. To bridge this gap, we introduce OmniVideoBench, a large-scale and rigorously designed benchmark dedicated to assessing synergistic audio-visual understanding, with a strong emphasis on modality complementarity and logical consistency. Specifically, OmniVideoBench comprises 1000 high-quality question-answer(QA) pairs, each annotated with step-by-step reasoning traces, derived from 628 diverse videos ranging from several seconds to 30 minutes, and manually verified to guarantee complete correctness and uniqueness. Moreover, OmniVideoBench encompasses 13 carefully designed question types, covering temporal reasoning, spatial localization, counting, causal inference, summarization, and beyond, thereby capturing the essential challenges of video understanding. Evaluation of multiple MLLMs on OmniVideoBench reveals a pronounced gap between model performance and human reasoning, with open-source models lagging significantly behind their closed-source counterparts, underscoring the inherent difficulty of genuine audio-visual reasoning. We will release OmniVideoBench to foster the development of MLLMs with stronger and more generalizable reasoning capabilities. 

**Abstract (ZH)**: 最近多模态大型语言模型（MLLMs）在视频理解方面展现出巨大的潜力。然而，现有的基准未能全面评估跨音频和视觉模态的协同推理能力，往往会忽视其中一种模态或者以逻辑不一致的方式整合它们。为填补这一空白，我们提出了一种名为OmniVideoBench的大规模严格设计基准，专注于评估协同的音频-视觉理解，特别强调模态互补性和逻辑一致性。具体而言，OmniVideoBench包含了1000个高质量的问题-答案（QA）对，每个问题-答案对都带有逐步推理痕迹，并基于628种多样性的视频（时长从几秒钟到30分钟不等）手工标注，以确保完全正确性和独特性。此外，OmniVideoBench涵盖了13种精心设计的问题类型，涵盖了时间推理、空间定位、计数、因果推理、总结等方面，从而捕捉到了视频理解的核心挑战。在OmniVideoBench上对多种MLLMs的评估显示，模型性能与人类推理之间存在显著差距，开源模型远落后于闭源模型，强调了真正意义上的音频-视觉推理的固有难度。我们将发布OmniVideoBench，以促进具有更强更通用推理能力的MLLMs的发展。 

---
# Simpliflow: A Lightweight Open-Source Framework for Rapid Creation and Deployment of Generative Agentic AI Workflows 

**Title (ZH)**: Simpliflow：一种轻量级开源框架，用于快速创建和部署生成型代理AI工作流 

**Authors**: Deven Panchal  

**Link**: [PDF](https://arxiv.org/pdf/2510.10675)  

**Abstract**: Generative Agentic AI systems are emerging as a powerful paradigm for automating complex, multi-step tasks. However, many existing frameworks for building these systems introduce significant complexity, a steep learning curve, and substantial boilerplate code, hindering rapid prototyping and deployment. This paper introduces simpliflow, a lightweight, open-source Python framework designed to address these challenges. simpliflow enables the rapid development and orchestration of linear, deterministic agentic workflows through a declarative, JSON-based configuration. Its modular architecture decouples agent management, workflow execution, and post-processing, promoting ease of use and extensibility. By integrating with LiteLLM, it supports over 100 Large Language Models (LLMs) out-of-the-box. We present the architecture, operational flow, and core features of simpliflow, demonstrating its utility through diverse use cases ranging from software development simulation to real-time system interaction. A comparative analysis with prominent frameworks like LangChain and AutoGen highlights simpliflow's unique position as a tool optimized for simplicity, control, and speed in deterministic workflow environments. 

**Abstract (ZH)**: 生成型自主AI系统正 emerges as a powerful paradigm for automating complex, multi-step tasks. However, many existing frameworks for building these systems introduce significant complexity, a steep learning curve, and substantial boilerplate code, hindering rapid prototyping and deployment. This paper introduces simpliflow, a lightweight, open-source Python framework designed to address these challenges. Simpliflow enables the rapid development and orchestration of linear, deterministic agentic workflows through a declarative, JSON-based configuration. Its modular architecture decouples agent management, workflow execution, and post-processing, promoting ease of use and extensibility. By integrating with LiteLLM, it supports over 100 Large Language Models (LLMs) out-of-the-box. We present the architecture, operational flow, and core features of Simpliflow, demonstrating its utility through diverse use cases ranging from software development simulation to real-time system interaction. A comparative analysis with prominent frameworks like LangChain and AutoGen highlights Simpliflow's unique position as a tool optimized for simplicity, control, and speed in deterministic workflow environments.

翻译后的标题：
轻量级开源Python框架simpliflow：简化自主AI工作流开发与部署 

---
# Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning 

**Title (ZH)**: 在RLVR中解锁探索：基于不确定性优势塑造的深层推理 

**Authors**: Can Xie, Ruotong Pan, Xiangyu Wu, Yunfei Zhang, Jiayi Fu, Tingting Gao, Guorui Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.10649)  

**Abstract**: Reinforcement Learning with Verifiable Rewards (RLVR) has shown significant promise for enhancing the reasoning capabilities of large language models (LLMs). However, prevailing algorithms like GRPO broadcast a uniform advantage signal across all tokens in a sequence. This coarse-grained approach overlooks the pivotal role of uncertain, high-stakes decisions during reasoning, leading to inefficient exploration and the well-documented problem of entropy collapse. To address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), a model-free method that refines credit assignment by leveraging the model's internal uncertainty signals. UCAS operates in two stages: it first modulates the response-level advantage using the model's overall self-confidence, and then applies a token-level penalty based on raw logit certainty. This dual mechanism encourages exploration of high-uncertainty paths that yield correct answers while penalizing overconfident yet erroneous reasoning, effectively balancing the exploration-exploitation trade-off. Extensive experiments on five mathematical reasoning benchmarks show that UCAS significantly outperforms strong RLVR baselines across multiple model scales, including 1.5B and 7B. Our analysis confirms that UCAS not only achieves higher rewards but also promotes greater reasoning diversity and successfully mitigates entropy collapse. 

**Abstract (ZH)**: 可验证奖励的强化学习（RLVR）在增强大规模语言模型的推理能力方面显示出显著的前景。然而，现有的算法如GRPO会在整个序列的所有令牌中广播统一的优势信号。这种粗粒度的方法忽视了推理过程中至关重要的不确定性和高风险决策的作用，导致探索效率低下和已知的熵坍缩问题。为了解决这个问题，我们引入了基于不确定性的优势塑造（UCAS）方法，这是一种无需模型的方法，通过利用模型的内部不确定性信号来细化信用分配。UCAS分为两个阶段：首先，利用模型的整体自我信心调整响应级优势；然后，基于原始logits的确定性施加令牌级惩罚。这种双重机制鼓励探索具有高不确定性但能得出正确答案的路径，并对过于自信但错误的推理进行惩罚，从而有效平衡探索与利用之间的trade-off。在五个数学推理基准上的 extensive 实验表明，UCAS 在多个模型规模（包括1.5B和7B）下显著优于强大的RLVR基线。我们的分析证实，UCAS 不仅能够获得更高的奖励，还能促进更高的推理多样性，并成功缓解熵坍缩问题。 

---
# Hierarchical Optimization via LLM-Guided Objective Evolution for Mobility-on-Demand Systems 

**Title (ZH)**: 基于LLM引导目标演化的大规模出行系统层次优化 

**Authors**: Yi Zhang, Yushen Long, Yun Ni, Liping Huang, Xiaohong Wang, Jun Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10644)  

**Abstract**: Online ride-hailing platforms aim to deliver efficient mobility-on-demand services, often facing challenges in balancing dynamic and spatially heterogeneous supply and demand. Existing methods typically fall into two categories: reinforcement learning (RL) approaches, which suffer from data inefficiency, oversimplified modeling of real-world dynamics, and difficulty enforcing operational constraints; or decomposed online optimization methods, which rely on manually designed high-level objectives that lack awareness of low-level routing dynamics. To address this issue, we propose a novel hybrid framework that integrates large language model (LLM) with mathematical optimization in a dynamic hierarchical system: (1) it is training-free, removing the need for large-scale interaction data as in RL, and (2) it leverages LLM to bridge cognitive limitations caused by problem decomposition by adaptively generating high-level objectives. Within this framework, LLM serves as a meta-optimizer, producing semantic heuristics that guide a low-level optimizer responsible for constraint enforcement and real-time decision execution. These heuristics are refined through a closed-loop evolutionary process, driven by harmony search, which iteratively adapts the LLM prompts based on feasibility and performance feedback from the optimization layer. Extensive experiments based on scenarios derived from both the New York and Chicago taxi datasets demonstrate the effectiveness of our approach, achieving an average improvement of 16% compared to state-of-the-art baselines. 

**Abstract (ZH)**: 基于大型语言模型的混合优化框架在动态分级系统中实现在线拼车平台的高效需求响应服务 

---
# Equity-Aware Geospatial AI for Forecasting Demand-Driven Hospital Locations in Germany 

**Title (ZH)**: 面向公平的地理空间AI在德国需求驱动型医院位置预测中的应用 

**Authors**: Piyush Pant, Marcellius William Suntoro, Ayesha Siddiqua, Muhammad Shehryaar Sharif, Daniyal Ahmed  

**Link**: [PDF](https://arxiv.org/pdf/2510.10640)  

**Abstract**: This paper presents EA-GeoAI, an integrated framework for demand forecasting and equitable hospital planning in Germany through 2030. We combine district-level demographic shifts, aging population density, and infrastructure balances into a unified Equity Index. An interpretable Agentic AI optimizer then allocates beds and identifies new facility sites to minimize unmet need under budget and travel-time constraints. This approach bridges GeoAI, long-term forecasting, and equity measurement to deliver actionable recommendations for policymakers. 

**Abstract (ZH)**: 本文提出EA-GeoAI，这是一种将需求预测与公平医院规划结合的综合框架，适用于2030年的德国。通过综合地区级人口结构变化、老龄化密度和基础设施平衡，构建统一的公平指数。可解释的代理AI优化器在预算和出行时间约束下分配床位并确定新的设施地点，以最小化未满足的需求。该方法将GeoAI、长期预测和公平性衡量相结合，为政策制定者提供可操作的建议。 

---
# Automatic Piecewise Linear Regression for Predicting Student Learning Satisfaction 

**Title (ZH)**: 自动分段线性回归对学生学习满意度的预测 

**Authors**: Haemin Choi, Gayathri Nadarajan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10639)  

**Abstract**: Although student learning satisfaction has been widely studied, modern techniques such as interpretable machine learning and neural networks have not been sufficiently explored. This study demonstrates that a recent model that combines boosting with interpretability, automatic piecewise linear regression(APLR), offers the best fit for predicting learning satisfaction among several state-of-the-art approaches. Through the analysis of APLR's numerical and visual interpretations, students' time management and concentration abilities, perceived helpfulness to classmates, and participation in offline courses have the most significant positive impact on learning satisfaction. Surprisingly, involvement in creative activities did not positively affect learning satisfaction. Moreover, the contributing factors can be interpreted on an individual level, allowing educators to customize instructions according to student profiles. 

**Abstract (ZH)**: 尽管学生学习满意度已有广泛研究，但诸如可解释机器学习和神经网络等现代技术尚未得到充分探索。本研究展示了一种结合提升与可解释性的最近模型——自动分段线性回归(APLR)——在多种先进方法中对预测学习满意度具有最佳拟合度。通过分析APLR的数值和可视化解释，研究发现学生的时间管理能力、集中注意力的能力、对同学的帮助感知以及参与线下课程的参与度对学习满意度有最显著的积极影响。令人惊讶的是，参与创造性活动并未对学习满意度产生积极影响。此外，这些影响因素可以在个人层面上进行解释，使教育者能够根据学生的特点定制指导。 

---
# Collaborative Text-to-Image Generation via Multi-Agent Reinforcement Learning and Semantic Fusion 

**Title (ZH)**: 多 agent 强化学习与语义融合的协作文本到图像生成 

**Authors**: Jiabao Shi, Minfeng Qi, Lefeng Zhang, Di Wang, Yingjie Zhao, Ziying Li, Yalong Xing, Ningran Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.10633)  

**Abstract**: Multimodal text-to-image generation remains constrained by the difficulty of maintaining semantic alignment and professional-level detail across diverse visual domains. We propose a multi-agent reinforcement learning framework that coordinates domain-specialized agents (e.g., focused on architecture, portraiture, and landscape imagery) within two coupled subsystems: a text enhancement module and an image generation module, each augmented with multimodal integration components. Agents are trained using Proximal Policy Optimization (PPO) under a composite reward function that balances semantic similarity, linguistic visual quality, and content diversity. Cross-modal alignment is enforced through contrastive learning, bidirectional attention, and iterative feedback between text and image. Across six experimental settings, our system significantly enriches generated content (word count increased by 1614%) while reducing ROUGE-1 scores by 69.7%. Among fusion methods, Transformer-based strategies achieve the highest composite score (0.521), despite occasional stability issues. Multimodal ensembles yield moderate consistency (ranging from 0.444 to 0.481), reflecting the persistent challenges of cross-modal semantic grounding. These findings underscore the promise of collaborative, specialization-driven architectures for advancing reliable multimodal generative systems. 

**Abstract (ZH)**: 多模态文本到图像生成仍然受限于在多种视觉领域中维持语义对齐和专业级细节的难度。我们提出了一种多智能体强化学习框架，该框架协调专注于建筑、肖像和风景图像的专业智能体，并在两个耦合子系统中协同工作：文本增强模块和图像生成模块，每个模块都增加了多模态集成组件。智能体使用加权策略梯度优化（PPO）在综合奖励函数下训练，该函数平衡了语义相似性、语义视觉质量和内容多样性。通过对比学习、双向注意力和文本与图像的迭代反馈来确保跨模态对齐。在六个实验设置中，我们的系统显著丰富了生成内容（词汇量增加了1614%）同时降低了ROUGE-1分数69.7%。在融合方法中，基于Transformer的策略获得了最高的综合分数（0.521），尽管偶尔存在稳定性问题。多模态集成展现出中等的一致性（从0.444到0.481），反映了跨模态语义接地的持续挑战。这些发现强调了协作和专业化驱动架构在推进可靠多模态生成系统方面的潜力。 

---
# EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms 

**Title (ZH)**: EA4LLM：基于进化算法的无梯度大型语言模型优化方法 

**Authors**: WenTao Liu, Siyu Song, Hao Hao, Aimin Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.10603)  

**Abstract**: In recent years, large language models (LLMs) have made remarkable progress, with model optimization primarily relying on gradient-based optimizers such as Adam. However, these gradient-based methods impose stringent hardware requirements, demanding high-concurrency, high-memory GPUs. Moreover, they require all neural network operations to be differentiable, thereby excluding many promising non-differentiable architectures from practical use. To address these limitations, we propose a method for optimizing LLMs using evolutionary algorithms (EA4LLM) and, for the first time, successfully demonstrate its capability to train a 1-billion-parameter LLM from the pre-trained stage. We conduct extensive experiments and provide key insights into how evolutionary algorithms can effectively optimize neural networks. Our work challenges the prevailing assumption that gradient-based optimization is the only viable approach for training neural networks. It also holds significant potential to reduce the computational cost of training large language models, thereby enabling groups with limited computational resources to participate in deep learning research. 

**Abstract (ZH)**: 基于进化算法优化大型语言模型（EA4LLM）及其首个亿级参数模型训练示范 

---
# A Distance Measure for Random Permutation Set: From the Layer-2 Belief Structure Perspective 

**Title (ZH)**: 基于第2层信念结构视角的随机置换集合的距离度量 

**Authors**: Ruolan Cheng, Yong Deng, Serafín Moral, José Ramón Trillo  

**Link**: [PDF](https://arxiv.org/pdf/2510.10596)  

**Abstract**: Random permutation set (RPS) is a recently proposed framework designed to represent order-structured uncertain information. Measuring the distance between permutation mass functions is a key research topic in RPS theory (RPST). This paper conducts an in-depth analysis of distances between RPSs from two different perspectives: random finite set (RFS) and transferable belief model (TBM). Adopting the layer-2 belief structure interpretation of RPS, we regard RPST as a refinement of TBM, where the order in the ordered focus set represents qualitative propensity. Starting from the permutation, we introduce a new definition of the cumulative Jaccard index to quantify the similarity between two permutations and further propose a distance measure method for RPSs based on the cumulative Jaccard index matrix. The metric and structural properties of the proposed distance measure are investigated, including the positive definiteness analysis of the cumulative Jaccard index matrix, and a correction scheme is provided. The proposed method has a natural top-weightiness property: inconsistencies between higher-ranked elements tend to result in greater distance values. Two parameters are provided to the decision-maker to adjust the weight and truncation depth. Several numerical examples are used to compare the proposed method with the existing method. The experimental results show that the proposed method not only overcomes the shortcomings of the existing method and is compatible with the Jousselme distance, but also has higher sensitivity and flexibility. 

**Abstract (ZH)**: 基于随机有限集和转移信念模型视角的随机置换集之间距离的深入分析 

---
# A Layered Intuition -- Method Model with Scope Extension for LLM Reasoning 

**Title (ZH)**: 分层直觉——具有范围扩展的LLM推理方法模型 

**Authors**: Hong Su  

**Link**: [PDF](https://arxiv.org/pdf/2510.10592)  

**Abstract**: Existing studies have introduced method-based reasoning and scope extension as approaches to enhance Large Language Model (LLM) performance beyond direct matrix mappings. Building on these foundations, this paper summarizes and integrates these ideas into a unified Intuition-Method Layered Model with Scope Extension, designed to address indirected (unseen) issues more systematically. In this framework, intuition-based thinking provides rapid first-reaction answers, while method-based thinking decouples questions and solutions into transferable reasoning units. Scope extension is then applied to broaden applicability, including vertical (cause analysis), horizontal (parallel and generalized issues), and for the first time, temporal and spatial extensions, which expand reasoning across time and contextual dimensions. These extensions are organized into systematic knowledge trees that interconnect into a knowledge network, thereby increasing adaptability. To quantitatively evaluate this process, we propose the entropy of method extension, which measures the independence and diversity of extensions as an indicator of the system's capacity to solve unseen questions. By logically connecting existing approaches with new extensions and introducing an entropy-based evaluation framework, this work advances toward a more robust and extensible reasoning paradigm for LLMs in real-world problem-solving. 

**Abstract (ZH)**: 现有的研究引入了基于方法的推理和范围扩展，以超越直接矩阵映射提升大规模语言模型（LLM）的性能。在此基础上，本文总结并整合这些理念，提出了一种统一的直觉-方法分层模型并结合范围扩展，旨在更系统地解决间接（未见）问题。在这种框架中，基于直觉的思考提供快速的第一反应答案，而基于方法的思考则将问题和解决方案分解为可转移的推理单元。范围扩展随后被应用以扩大适用性，包括垂直（原因分析）、水平（并行和泛化的议题），以及首次提出的时空扩展，这些扩展将推理扩展到时间与情境维度。这些扩展被组织成系统化的知识树，相互连接成知识网络，从而增加模型的适应性。为了定量评估这一过程，本文提出了方法扩展的熵，作为系统解决未见问题能力的指标。通过逻辑连接现有方法并与新的扩展相结合，并引入基于熵的评估框架，本文朝着更稳健和可扩展的LLM推理范式迈出了一步，在实际问题解决中更为可靠。 

---
# ELAIPBench: A Benchmark for Expert-Level Artificial Intelligence Paper Understanding 

**Title (ZH)**: ELAIPBench: 专家级人工 intelligence 论文理解基准 

**Authors**: Xinbang Dai, Huikang Hu, Yongrui Chen, Jiaqi Li, Rihui Jin, Yuyang Zhang, Xiaoguang Li, Lifeng Shang, Guilin Qi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10549)  

**Abstract**: While large language models (LLMs) excel at many domain-specific tasks, their ability to deeply comprehend and reason about full-length academic papers remains underexplored. Existing benchmarks often fall short of capturing such depth, either due to surface-level question design or unreliable evaluation metrics. To address this gap, we introduce ELAIPBench, a benchmark curated by domain experts to evaluate LLMs' comprehension of artificial intelligence (AI) research papers. Developed through an incentive-driven, adversarial annotation process, ELAIPBench features 403 multiple-choice questions from 137 papers. It spans three difficulty levels and emphasizes non-trivial reasoning rather than shallow retrieval. Our experiments show that the best-performing LLM achieves an accuracy of only 39.95%, far below human performance. Moreover, we observe that frontier LLMs equipped with a thinking mode or a retrieval-augmented generation (RAG) system fail to improve final results-even harming accuracy due to overthinking or noisy retrieval. These findings underscore the significant gap between current LLM capabilities and genuine comprehension of academic papers. 

**Abstract (ZH)**: 虽然大规模语言模型在许多领域特定任务中表现出色，但它们深入理解和推理全文学术论文的能力尚未得到充分探索。现有的基准测试往往未能捕捉到这种深度，要么由于表面化的问答设计，要么由于不可靠的评价指标。为了解决这一差距，我们引入了ELAIPBench，这是一个由领域专家筛选的基准测试，用于评估大规模语言模型对人工智能研究论文的理解能力。通过激励驱动的对抗性注释过程开发而成，ELAIPBench 包含来自137篇论文的403道选择题，涵盖了三个难度级别，并强调非平凡推理而非浅层检索。我们的实验显示，表现最好的大规模语言模型的准确率仅为39.95%，远低于人类的表现。此外，我们观察到，配备了思考模式或检索增强生成系统的前沿大规模语言模型未能提高最终结果，甚至因过度思考或嘈杂的检索而导致准确率下降。这些发现突显了当前大规模语言模型能力和对学术论文真正理解之间的巨大差距。 

---
# Tracing the Traces: Latent Temporal Signals for Efficient and Accurate Reasoning 

**Title (ZH)**: 追踪潜踪：潜在时间信号实现高效准确推理 

**Authors**: Martina G. Vilas, Safoora Yousefi, Besmira Nushi, Eric Horvitz, Vidhisha Balachandran  

**Link**: [PDF](https://arxiv.org/pdf/2510.10494)  

**Abstract**: Reasoning models improve their problem-solving ability through inference-time scaling, allocating more compute via longer token budgets. Identifying which reasoning traces are likely to succeed remains a key opportunity: reliably predicting productive paths can substantially reduce wasted computation and improve overall efficiency. We introduce Latent-Trajectory signals that characterize the temporal evolution of a model's internal representations during the generation of intermediate reasoning tokens. By measuring the overall change in latent representations between the start and end of reasoning, the change accumulated across intermediate steps, and the extent to which these changes advance toward the final state, we show that these signals predict solution accuracy more reliably than both cross-layer metrics and output-based confidence measures. When used to guide answer selection across multiple sampled generations, Latent-Trajectory signals make test-time scaling more effective and efficient than majority voting, reducing token usage by up to 70% while preserving and even improving accuracy by 2.6% on average. Moreover, these predictive signals often emerge early in the reasoning trace, enabling early selection and allocation of compute to the most promising candidates. Our findings contribute not only practical strategies for inference-time efficiency, but also a deeper interpretability perspective on how reasoning processes are represented and differentiated in latent space. 

**Abstract (ZH)**: 推理模型通过推理时的缩放提高其问题解决能力，分配更多计算资源通过更长的token预算。识别哪些推理轨迹更 likely 成功仍然是一个关键机会：可靠地预测有成效的路径可以大幅减少浪费的计算并提高整体效率。我们引入了潜轨迹信号，该信号表征模型在生成中间推理token过程中内部表示的时间演变。通过测量推理开始和结束之间潜表示的整体变化、中间步骤累积的变化以及这些变化向最终状态推进的程度，我们展示了这些信号比跨层度量和基于输出的信心衡量指标更能可靠预测解的准确性。在引导多轮采样生成的答案选择时，潜轨迹信号使测试时的缩放更加有效和高效，最多可减少70%的token使用量，同时保持甚至提高平均约2.6%的准确率。此外，这些预测信号通常在推理轨迹早期显现，使我们能够早期选择和分配计算资源给最有前途的候选者。我们的发现不仅提供了实际策略以提高推理时的效率，还从潜空间如何表示和区分推理过程的角度提供了一个更深层次的可解释性视角。 

---
# MedCoAct: Confidence-Aware Multi-Agent Collaboration for Complete Clinical Decision 

**Title (ZH)**: MedCoAct：基于信心的多 Agents 合作以实现完整的临床决策 

**Authors**: Hongjie Zheng, Zesheng Shi, Ping Yi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10461)  

**Abstract**: Autonomous agents utilizing Large Language Models (LLMs) have demonstrated remarkable capabilities in isolated medical tasks like diagnosis and image analysis, but struggle with integrated clinical workflows that connect diagnostic reasoning and medication decisions. We identify a core limitation: existing medical AI systems process tasks in isolation without the cross-validation and knowledge integration found in clinical teams, reducing their effectiveness in real-world healthcare scenarios. To transform the isolation paradigm into a collaborative approach, we propose MedCoAct, a confidence-aware multi-agent framework that simulates clinical collaboration by integrating specialized doctor and pharmacist agents, and present a benchmark, DrugCareQA, to evaluate medical AI capabilities in integrated diagnosis and treatment workflows. Our results demonstrate that MedCoAct achieves 67.58\% diagnostic accuracy and 67.58\% medication recommendation accuracy, outperforming single agent framework by 7.04\% and 7.08\% respectively. This collaborative approach generalizes well across diverse medical domains, proving especially effective for telemedicine consultations and routine clinical scenarios, while providing interpretable decision-making pathways. 

**Abstract (ZH)**: 利用大规模语言模型的自主代理在集成临床工作流中的局限性及MedCoAct框架的研究：一种提高诊断和治疗准确性的协作方法 

---
# Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction 

**Title (ZH)**: Traj-CoA: 基于链式代理的患者轨迹建模用于肺癌风险预测 

**Authors**: Sihang Zeng, Yujuan Fu, Sitong Zhou, Zixuan Yu, Lucas Jing Liu, Jun Wen, Matthew Thompson, Ruth Etzioni, Meliha Yetisgen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10454)  

**Abstract**: Large language models (LLMs) offer a generalizable approach for modeling patient trajectories, but suffer from the long and noisy nature of electronic health records (EHR) data in temporal reasoning. To address these challenges, we introduce Traj-CoA, a multi-agent system involving chain-of-agents for patient trajectory modeling. Traj-CoA employs a chain of worker agents to process EHR data in manageable chunks sequentially, distilling critical events into a shared long-term memory module, EHRMem, to reduce noise and preserve a comprehensive timeline. A final manager agent synthesizes the worker agents' summary and the extracted timeline in EHRMem to make predictions. In a zero-shot one-year lung cancer risk prediction task based on five-year EHR data, Traj-CoA outperforms baselines of four categories. Analysis reveals that Traj-CoA exhibits clinically aligned temporal reasoning, establishing it as a promisingly robust and generalizable approach for modeling complex patient trajectories. 

**Abstract (ZH)**: 大型语言模型（LLMs）提供了一种适用于建模患者轨迹的一般化方法，但在处理电子健康记录（EHR）数据的时间推理时，面临数据长且杂的问题。为应对这些挑战，我们引入了Traj-CoA，这是一种涉及多智能体系统的患者轨迹建模方法，该系统包含一个智能体链。Traj-CoA 使用一系列工作智能体按顺序处理 EHR 数据的可管理片段，将关键事件提炼到共享长时记忆模块 EHRMem 中，以降低噪音并保持完整的事件时间线。最终，管理智能体综合工作智能体的总结和从 EHRMem 中提取的时间线来进行预测。在基于五年 EHR 数据的一年零样本肺癌风险预测任务中，Traj-CoA 在四个类别基线中表现优越。分析表明，Traj-CoA 具有临床对齐的时间推理能力，将其确立为建模复杂患者轨迹的一种有前景且通用的方法。 

---
# Trace Length is a Simple Uncertainty Signal in Reasoning Models 

**Title (ZH)**: 轨迹长度是推理模型中的一个简单的不确定性信号 

**Authors**: Siddartha Devic, Charlotte Peale, Arwen Bradley, Sinead Williamson, Preetum Nakkiran, Aravind Gollakota  

**Link**: [PDF](https://arxiv.org/pdf/2510.10409)  

**Abstract**: Uncertainty quantification for LLMs is a key research direction towards addressing hallucination and other issues that limit their reliable deployment. In this work, we show that reasoning trace length is a simple and useful confidence estimator in large reasoning models. Through comprehensive experiments across multiple models, datasets, and prompts, we show that trace length performs in comparable but complementary ways to other zero-shot confidence estimators such as verbalized confidence. Our work reveals that reasoning post-training fundamentally alters the relationship between trace length and accuracy, going beyond prior work that had shown that post-training causes traces to grow longer in general (e.g., "overthinking"). We investigate the mechanisms behind trace length's performance as a confidence signal, observing that the effect remains even after adjusting for confounders such as problem difficulty and GRPO-induced length bias. We identify high-entropy or "forking" tokens as playing a key role in the mechanism. Our findings demonstrate that reasoning post-training enhances uncertainty quantification beyond verbal expressions, and establish trace length as a practical confidence measure for large reasoning models. 

**Abstract (ZH)**: LLMs的不确定性量化是解决幻觉及其他限制其可靠部署问题的关键研究方向。在本文中，我们展示了推理踪迹长度是一种简单而实用的置信度估计器。通过在多种模型、数据集和提示下的综合实验，我们表明踪迹长度在与其他零样本置信度估计器（如口头置信度）的性能上具有可比性和互补性。我们的工作揭示了后训练推理从根本上改变了踪迹长度与准确性的关系，超越了以往工作仅显示后训练使踪迹普遍增长（如“过度思考”）的发现。我们探讨了踪迹长度作为置信度信号表现背后的机制，观察到即使调整了问题难度和GRPO诱导的长度偏差等混杂因素，效果依然存在。我们发现高熵或“分支”标记在机制中扮演了关键角色。我们的研究结果表明，后训练推理增强了不确定性量化，超出口头表达之外，并确立了踪迹长度作为大型推理模型的实用置信度度量。 

---
# Beyond Ethics: How Inclusive Innovation Drives Economic Returns in Medical AI 

**Title (ZH)**: 超越伦理：包容性创新如何驱动医疗AI的经济回报 

**Authors**: Balagopal Unnikrishnan, Ariel Guerra Adames, Amin Adibi, Sameer Peesapati, Rafal Kocielnik, Shira Fischer, Hillary Clinton Kasimbazi, Rodrigo Gameiro, Alina Peluso, Chrystinne Oliveira Fernandes, Maximin Lange, Lovedeep Gondara, Leo Anthony Celi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10338)  

**Abstract**: While ethical arguments for fairness in healthcare AI are well-established, the economic and strategic value of inclusive design remains underexplored. This perspective introduces the ``inclusive innovation dividend'' -- the counterintuitive principle that solutions engineered for diverse, constrained use cases generate superior economic returns in broader markets. Drawing from assistive technologies that evolved into billion-dollar mainstream industries, we demonstrate how inclusive healthcare AI development creates business value beyond compliance requirements. We identify four mechanisms through which inclusive innovation drives returns: (1) market expansion via geographic scalability and trust acceleration; (2) risk mitigation through reduced remediation costs and litigation exposure; (3) performance dividends from superior generalization and reduced technical debt, and (4) competitive advantages in talent acquisition and clinical adoption. We present the Healthcare AI Inclusive Innovation Framework (HAIIF), a practical scoring system that enables organizations to evaluate AI investments based on their potential to capture these benefits. HAIIF provides structured guidance for resource allocation, transforming fairness and inclusivity from regulatory checkboxes into sources of strategic differentiation. Our findings suggest that organizations investing incrementally in inclusive design can achieve expanded market reach and sustained competitive advantages, while those treating these considerations as overhead face compounding disadvantages as network effects and data advantages accrue to early movers. 

**Abstract (ZH)**: 尽管公平性在医疗保健AI方面的伦理论据已经很充分，但包容性设计的经济和战略价值仍被远远低估。本文介绍了“包容性创新红利”——一个令人意想不到的原则，即为多样化且受限的场景而设计的解决方案，在更广泛的市场中能够产生更优越的经济效益。借鉴辅助技术如何成长为十亿美元级主流行业，本文展示了包容性医疗保健AI开发如何在合规要求之外创造商业价值。我们提出了四种机制，通过这四种机制，包容性创新能够促进收益：（1）通过地理扩展和信任加速推动市场扩展；（2）通过降低补救成本和诉讼风险来减轻风险；（3）通过卓越的一般化性能和减少技术债务来获取性能红利；（4）在人才获取和临床应用中获得竞争优势。我们提出了医疗保健AI包容性创新框架（HAIIF），这是一种实用评分系统，使组织能够根据其潜在收益评估AI投资。HAIIF提供了结构化的资源配置指导，将公正性和包容性从监管检查项转变为战略差异化来源。我们的研究结果表明，逐步投资于包容性设计的组织可以实现更广泛的市场渗透并维持持久的竞争优势，而将这些考虑作为额外开销对待的组织将随着网络效应和数据优势流向早期行动者而面临累积的劣势。 

---
# LLM-Friendly Knowledge Representation for Customer Support 

**Title (ZH)**: 面向LLM的客户支持知识表示 

**Authors**: Hanchen Su, Wei Luo, Wei Han, Yu Elaine Liu, Yufeng Wayne Zhang, Cen Mia Zhao, Ying Joy Zhang, Yashar Mehdad  

**Link**: [PDF](https://arxiv.org/pdf/2510.10331)  

**Abstract**: We propose a practical approach by integrating Large Language Models (LLMs) with a framework designed to navigate the complexities of Airbnb customer support operations. In this paper, our methodology employs a novel reformatting technique, the Intent, Context, and Action (ICA) format, which transforms policies and workflows into a structure more comprehensible to LLMs. Additionally, we develop a synthetic data generation strategy to create training data with minimal human intervention, enabling cost-effective fine-tuning of our model. Our internal experiments (not applied to Airbnb products) demonstrate that our approach of restructuring workflows and fine-tuning LLMs with synthetic data significantly enhances their performance, setting a new benchmark for their application in customer support. Our solution is not only cost-effective but also improves customer support, as evidenced by both accuracy and manual processing time evaluation metrics. 

**Abstract (ZH)**: 我们提出了一种将大型语言模型（LLMs）与设计用于导航Airbnb客户支持运营复杂性的框架集成的实用方法。本文方法采用了一种新颖的重格式化技术——意图、上下文和行动（ICA）格式，将政策和工作流转换为LLMs更容易理解的结构。此外，我们开发了一种合成数据生成策略，以最少的人工干预创建训练数据，从而实现成本效益高的模型微调。我们的内部实验（未应用于Airbnb产品）表明，通过重新结构化工作流和使用合成数据微调LLMs，显著提升了其性能，为在客户支持中应用LLMs树立了新的基准。我们的解决方案不仅成本效益高，还能有效提升客户支持质量，这一结论得到了准确性和手动处理时间评估指标的支持。 

---
# Mitigating Hallucination in Multimodal Reasoning via Functional Attention Control 

**Title (ZH)**: 通过功能注意力控制减轻多模态推理中的幻觉 

**Authors**: Haolang Lu, Bolun Chu, WeiYe Fu, Guoshun Nan, Junning Liu, Minghui Pan, Qiankun Li, Yi Yu, Hua Wang, Kun Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10285)  

**Abstract**: Multimodal large reasoning models (MLRMs) are rapidly advancing vision-language reasoning and are emerging as a foundation for cross-modal intelligence. Hallucination remains a persistent failure mode, manifesting itself as erroneous reasoning chains and misinterpretation of visual content. In this study, we observe that attention heads exhibit a staged division: shallow heads predominantly serve perception, while deeper heads shift toward symbolic reasoning, revealing two major causes of hallucination, namely perceptual bias and reasoning drift. To address these issues, we propose a lightweight and interpretable two-step plugin, Functional Head Identification and Class-conditioned Rescaling, which locates perception- and reasoning-oriented heads and regulates their contributions without retraining. Evaluations on three real-world MLRMs (Kimi-VL, Ocean-R1, R1-Onevision), six benchmarks across three domains, and four baselines show that our plugin achieves an average improvement of 5% and up to 15%, with only <1% additional computation and 9% of baseline latency. Our approach is completely model-agnostic and significantly enhances both the reliability and interpretability of the off-the-shelf MLRMs, thereby enabling their safe deployment in high-stakes applications. Our code is available at this https URL. 

**Abstract (ZH)**: 多模态大型推理模型中的幻觉现象：注意力头部的阶段划分与功能辨识及条件归一化插件研究 

---
# The Achilles' Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities 

**Title (ZH)**: LLMs的阿喀琉斯之踵：少量神经元的改变如何毁掉语言能力 

**Authors**: Zixuan Qin, Kunlin Lyu, Qingchen Yu, Yifan Sun, Zhaoxin Fan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10238)  

**Abstract**: Large Language Models (LLMs) have become foundational tools in natural language processing, powering a wide range of applications and research. Many studies have shown that LLMs share significant similarities with the human brain. Recent neuroscience research has found that a small subset of biological neurons in the human brain are crucial for core cognitive functions, which raises a fundamental question: do LLMs also contain a small subset of critical neurons? In this paper, we investigate this question by proposing a Perturbation-based Causal Identification of Critical Neurons method to systematically locate such critical neurons in LLMs. Our findings reveal three key insights: (1) LLMs contain ultra-sparse critical neuron sets. Disrupting these critical neurons can cause a 72B-parameter model with over 1.1 billion neurons to completely collapse, with perplexity increasing by up to 20 orders of magnitude; (2) These critical neurons are not uniformly distributed, but tend to concentrate in the outer layers, particularly within the MLP down\_proj components; (3) Performance degradation exhibits sharp phase transitions, rather than a gradual decline, when these critical neurons are disrupted. Through comprehensive experiments across diverse model architectures and scales, we provide deeper analysis of these phenomena and their implications for LLM robustness and interpretability. These findings can offer guidance for developing more robust model architectures and improving deployment security in safety-critical applications. 

**Abstract (ZH)**: 大型语言模型（LLMs）已成为自然语言处理中的基础工具，支撑着广泛的应用和研究。许多研究表明，LLMs在很大程度上与人脑相似。最近的神经科学研究发现，人脑中一小部分生物神经元对于核心认知功能至关重要，这引发了一个基本问题：LLMs中是否也存在这样一小部分关键神经元？在本文中，我们通过提出基于扰动的关键神经元因果识别方法，系统地识别LLMs中的这类关键神经元。我们的发现揭示了三个关键洞察：（1）LLMs包含极度稀疏的关键神经元集合。破坏这些关键神经元会导致一个参数量为720亿、拥有超过11亿个神经元的模型完全崩溃，困惑度增加20个数量级；（2）这些关键神经元并非均匀分布，而是倾向于集中在外部层，特别是MLP down_proj组件中；（3）在这些关键神经元被破坏时，性能下降表现出明显的相变，而非渐进下降。通过跨不同模型架构和规模的全面实验，我们对这些现象及其对LLMs稳健性和可解释性的含义进行了更深入的分析。这些发现可以为开发更具稳健性的模型架构并改善安全关键应用的部署安全性提供指导。 

---
# Adaptive Dual Reasoner: Large Reasoning Models Can Think Efficiently by Hybrid Reasoning 

**Title (ZH)**: 自适应双推理机：混合推理的大规模推理模型可以高效思考 

**Authors**: Yujian Zhang, Keyu Chen, Zhifeng Shen, Ruizhi Qiao, Xing Sun  

**Link**: [PDF](https://arxiv.org/pdf/2510.10207)  

**Abstract**: Although Long Reasoning Models (LRMs) have achieved superior performance on various reasoning scenarios, they often suffer from increased computational costs and inference latency caused by overthinking. To address these limitations, we propose Adaptive Dual Reasoner, which supports two reasoning modes: fast thinking and slow thinking. ADR dynamically alternates between these modes based on the contextual complexity during reasoning. ADR is trained in two stages: (1) A cold-start stage using supervised fine-tuning (SFT) to equip the model with the ability to integrate both fast and slow reasoning modes, in which we construct a hybrid reasoning dataset through a dedicated pipeline to provide large-scale supervision. (2) A reinforcement learning stage for optimizing reasoning effort, where we introduce Entropy-guided Hybrid Policy Optimization EHPO, an RL training framework employing an entropy-guided dynamic rollout strategy for branching at high-entropy units and a difficulty-aware penalty to balance fast and slow reasoning. Across challenging mathematical reasoning benchmarks, ADR achieves an effective balance between reasoning performance and efficiency among state-of-the-art approaches. Specifically, ADR yields a performance gain of up to 6.1%, while reducing the reasoning output length by 49.5% to 59.3%. 

**Abstract (ZH)**: 尽管长推理模型(LRMs)在各种推理场景中取得了优异 performance，但它们往往由于过度推理而导致计算成本和推理延迟增加。为了解决这些限制，我们提出了自适应双推理器(ADR)，支持快思考和慢思考两种推理模式。ADR根据推理过程中上下文复杂度动态交替使用这两种模式。ADR的训练分为两个阶段：(1) 使用监督微调(SFT)的冷启动阶段，通过专用管道构建混合推理数据集，提供大规模监督，使模型具备结合快思考和慢思考的能力；(2) 通过引入基于熵导引的混合策略优化框架EHPO，结合熵导引的动态展开策略和难度感知的惩罚机制，优化推理努力，以平衡快思考和慢思考。在具有挑战性的数学推理基准测试中，ADR在推理性能和效率之间实现了有效的平衡。具体而言，ADR在推理性能上提高了最多6.1%，同时将推理输出长度减少了49.5%至59.3%。 

---
# PIXEL: Adaptive Steering Via Position-wise Injection with eXact Estimated Levels under Subspace Calibration 

**Title (ZH)**: PIXEL：基于子空间校准的定位位置注入与精确估计层级的自适应转向 

**Authors**: Manjiang Yu, Hongji Li, Priyanka Singh, Xue Li, Di Wang, Lijie Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10205)  

**Abstract**: Reliable behavior control is central to deploying large language models (LLMs) on the web. Activation steering offers a tuning-free route to align attributes (e.g., truthfulness) that ensure trustworthy generation. Prevailing approaches rely on coarse heuristics and lack a principled account of where to steer and how strongly to intervene. To this end, we propose Position-wise Injection with eXact Estimated Levels (PIXEL), a position-wise activation steering framework that, in contrast to prior work, learns a property-aligned subspace from dual views (tail-averaged and end-token) and selects intervention strength via a constrained geometric objective with a closed-form solution, thereby adapting to token-level sensitivity without global hyperparameter tuning. PIXEL further performs sample-level orthogonal residual calibration to refine the global attribute direction and employs a lightweight position-scanning routine to identify receptive injection sites. We additionally provide representation-level guarantees for the minimal-intervention rule, supporting reliable alignment. Across diverse models and evaluation paradigms, PIXEL consistently improves attribute alignment while preserving model general capabilities, offering a practical and principled method for LLMs' controllable generation. Our code is available at this https URL 

**Abstract (ZH)**: 可靠的行為控制是將大語言模型（LLMs）部署在網上關鍵所在。基于.Position-wise Injection with Exact Estimated Levels (PIXEL) 的激活控制框架提供了在不調整超参数的情况下进行精确属性对齐的方法，从而实现可信赖的生成。 

---
# Don't Just Fine-tune the Agent, Tune the Environment 

**Title (ZH)**: 不要只是微调代理，也要微调环境 

**Authors**: Siyuan Lu, Zechuan Wang, Hongxuan Zhang, Qintong Wu, Leilei Gan, Chenyi Zhuang, Jinjie Gu, Tao Lin  

**Link**: [PDF](https://arxiv.org/pdf/2510.10197)  

**Abstract**: Large Language Model (LLM) agents show great promise for complex, multi-turn tool-use tasks, but their development is often hampered by the extreme scarcity of high-quality training data. Supervised fine-tuning (SFT) on synthetic data leads to overfitting, whereas standard reinforcement learning (RL) struggles with a critical cold-start problem and training instability. To address these challenges, we introduce $\textbf{Environment Tuning}$, a novel training paradigm that enables agents to learn complex behaviors directly from problem instances without relying on pre-collected expert trajectories. $\textbf{Environment Tuning}$ orchestrates this learning process through a structured curriculum, actionable environment augmentation that provides corrective feedback, and fine-grained progress rewards to ensure stable and efficient exploration. Using only 400 problem instances from Berkeley Function-Calling Leaderboard (BFCL) benchmark, our method not only achieves competitive in-distribution performance against strong baselines but also demonstrates superior out-of-distribution generalization, overcoming the performance collapse common to SFT-based approaches. Our work presents a paradigm shift from supervised fine-tuning on static trajectories to dynamic, environment-based exploration, paving the way for training more robust and data-efficient agents. 

**Abstract (ZH)**: 环境调优：一种新型训练范式，用于直接从问题实例中学习复杂行为，而不依赖于预先收集的专家轨迹 

---
# SAFER: Risk-Constrained Sample-then-Filter in Large Language Models 

**Title (ZH)**: SAFER: 大语言模型中的风险约束采样过滤方法 

**Authors**: Qingni Wang, Yue Fan, Xin Eric Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10193)  

**Abstract**: As large language models (LLMs) are increasingly deployed in risk-sensitive applications such as real-world open-ended question answering (QA), ensuring the trustworthiness of their outputs has become critical. Existing selective conformal prediction (SCP) methods provide statistical guarantees by constructing prediction sets with a constrained miscoverage rate for correct answers. However, prior works unrealistically assume that admissible answers for all instances can be obtained via finite sampling, even for open-ended QA scenarios that lack a fixed and finite solution space. To address this, we introduce a two-stage risk control framework comprising abstention-aware sampling and conformalized filtering (SAFER). Firstly, on a held-out calibration set, SAFER calibrates a sampling budget within the maximum sampling cap, using the Clopper-Pearson exact method at a user-desired risk level (i.e., the maximum allowable miscoverage rate of the sampling sets). If the risk level cannot be satisfied within the cap, we abstain; otherwise, the calibrated sampling budget becomes the minimum requirements at test time. Then, we employ calibration instances where correct answers are attainable under the calibrated budget and apply the conformal risk control method to determine a statistically valid uncertainty threshold, which filters unreliable distractors from the candidate set for each test data point. In this stage, SAFER introduces an additional risk level to guide the calculation of the threshold, thereby controlling the risk of correct answers being excluded. Furthermore, we show that SAFER is compatible with various task-specific admission criteria and calibration-test split ratios, highlighting its robustness and high data efficiency. 

**Abstract (ZH)**: 大型语言模型（LLMs）在风险敏感应用如真实世界开放式问答（QA）中的部署日益增多，确保其输出的可信度变得至关重要。现有的选择性一致性预测（SCP）方法通过构建具有约束置信率的预测集来提供统计保证，针对正确答案。然而，先前的工作不合理地假设所有实例的可接受答案可以通过有限采样获得，即使是在缺乏固定有限解决方案空间的开放式QA场景中。为解决这一问题，我们引入了一种两阶段风险控制框架——感知避免采样和一致性筛选（SAFER）。首先，在保留的校准集上，SAFER使用用户指定的风险水平（即采样集的最大允许置信率错误）通过Clopper-Pearson精确方法校准采样预算，并在预算上限内实现风险控制。如果风险水平无法满足上限，我们采取避免策略；否则，校准后的采样预算成为测试时的最低要求。然后，我们使用校准预算下可获得正确答案的校准实例，并应用一致性风险控制系统来确定一个统计上有效的不确定性阈值，该阈值能从每个测试数据点的候选集中筛选出不可靠的选项。在这一阶段，SAFER引入了额外的风险水平来指导阈值的计算，从而控制正确答案被排除的风险。此外，我们证明了SAFER可以与各种任务特定的接纳标准和校准-测试分割比例兼容，突显了它的鲁棒性和高数据效率。 

---
# Concise Reasoning in the Lens of Lagrangian Optimization 

**Title (ZH)**: 拉格朗日优化视角下的精炼推理 

**Authors**: Chengqian Gao, Haonan Li, Taylor W. Killian, Jianshu She, Renxi Wang, Liqun Ma, Zhoujun Cheng, Shibo Hao, Zhiqiang Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10168)  

**Abstract**: Concise reasoning in large language models seeks to generate only essential intermediate steps needed to arrive at a final answer, thereby alleviating issues of overthinking. Most proposed approaches hinge on carefully hand-crafted heuristics, struggling to balance concision with performance, often failing to adapt across domains and model scales. In this work, we address these challenges by introducing a principled and pragmatic strategy, performance-aware length updating (PALU). As a principled algorithm, PALU formulates concise reasoning as a constrained optimization problem, minimizing response length subject to a performance constraint, and then applies Lagrangian optimization to convert it into a tractable unconstrained problem. As a pragmatic solution, PALU streamlines complicated update rules through three approximations: (i) estimating performance with off-policy rollouts, (ii) truncating the Lagrange multiplier to two extremes, and (iii) replacing gradient-based updates with quantile-driven length adjustments. PALU reduces output length by 65% while improving accuracy by 15% when applied to DeepSeek-Distill-Qwen-1.5B, averaged over five benchmarks, outperforming a range of alternative methods. Furthermore, PALU is demonstrated to adapt across both domain (logic, STEM and math) and model scale (1.5B, 7B, 14B) entrenching the algorithm as a practical and effective concise reasoning approach. 

**Abstract (ZH)**: 大型语言模型中的紧凑推理寻求仅生成到达最终答案所需的 essential 中间步骤，从而缓解过度思考的问题。大多数提出的方案依赖于精心的手工启发式方法，难以在紧凑性和性能之间取得平衡，往往无法跨领域和模型规模进行适应。在本工作中，我们通过引入一个有原则且实用的策略——性能感知长度更新（PALU）来应对这些挑战。作为一项有原则的算法，PALU 将紧凑推理建模为一个受约束的优化问题，最小化响应长度同时满足性能约束，然后通过拉格朗日优化将其转化为可处理的无约束问题。作为一种实用的解决方案，PALU 通过三种近似简化复杂的更新规则：（i）使用离策 rollout 估计性能，（ii）截断拉格朗日乘数的两端，（iii）用基于分位数的长度调整替换基于梯度的更新。当应用于 DeepSeek-Distill-Qwen-1.5B 并在五个基准上平均时，PALU 减少了输出长度 65%，同时提高了准确性 15%，优于多种替代方法。此外，PALU 被证明可在领域（逻辑、STEM 和数学）和模型规模（1.5B、7B、14B）之间进行适应，使该算法成为一个实用有效的紧凑推理方法。 

---
# CharCom: Composable Identity Control for Multi-Character Story Illustration 

**Title (ZH)**: CharCom: 可组合的身份控制for 多角色故事插画 

**Authors**: Zhongsheng Wang, Ming Lin, Zhedong Lin, Yaser Shakib, Qian Liu, Jiamou Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10135)  

**Abstract**: Ensuring character identity consistency across varying prompts remains a fundamental limitation in diffusion-based text-to-image generation. We propose CharCom, a modular and parameter-efficient framework that achieves character-consistent story illustration through composable LoRA adapters, enabling efficient per-character customization without retraining the base model. Built on a frozen diffusion backbone, CharCom dynamically composes adapters at inference using prompt-aware control. Experiments on multi-scene narratives demonstrate that CharCom significantly enhances character fidelity, semantic alignment, and temporal coherence. It remains robust in crowded scenes and enables scalable multi-character generation with minimal overhead, making it well-suited for real-world applications such as story illustration and animation. 

**Abstract (ZH)**: 确保在变化的提示下角色身份一致性是基于扩散的文本到图像生成中的一个基本限制。我们提出CharCom，一种模块化和参数高效框架，通过可组合的LoRA适配器实现角色一致性故事插图，能够在不重新训练基模型的情况下进行高效的角色个性化定制。CharCom基于冻结的扩散骨干，在推理时使用提示感知控制动态组合适配器。实验表明，CharCom在多场景叙事中显著提高了角色保真度、语义对齐和时间连贯性，并在拥挤场景中保持鲁棒性，能够以最小开销实现可扩展的多角色生成，使其适用于故事插图和动画等实际应用。 

---
# DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision-Language Models with Multi-Agent Dixit Gameplay 

**Title (ZH)**: DixitWorld：多模态演绎推理在视觉-语言模型中的评估——基于多-agent Dixit游戏 chơi 

**Authors**: Yunxiang Mo, Tianshi Zheng, Qing Zong, Jiayu Liu, Baixuan Xu, Yauwai Yim, Chunkit Chan, Jiaxin Bai, Yangqiu Song  

**Link**: [PDF](https://arxiv.org/pdf/2510.10117)  

**Abstract**: Multimodal abductive reasoning--the generation and selection of explanatory hypotheses from partial observations--is a cornerstone of intelligence. Current evaluations of this ability in vision-language models (VLMs) are largely confined to static, single-agent tasks. Inspired by Dixit, we introduce DixitWorld, a comprehensive evaluation suite designed to deconstruct this challenge. DIXITWORLD features two core components: DixitArena, a dynamic, multi-agent environment that evaluates both hypothesis generation (a "storyteller" crafting cryptic clues) and hypothesis selection ("listeners" choosing the target image from decoys) under imperfect information; and DixitBench, a static QA benchmark that isolates the listener's task for efficient, controlled evaluation. Results from DixitArena reveal distinct, role-dependent behaviors: smaller open-source models often excel as creative storytellers, producing imaginative yet less discriminative clues, whereas larger proprietary models demonstrate superior overall performance, particularly as listeners. Performance on DixitBench strongly correlates with listener results in DixitArena, validating it as a reliable proxy for hypothesis selection. Our findings reveal a key trade-off between generative creativity and discriminative understanding in multimodal abductive reasoning, a central challenge for developing more balanced and capable vision-language agents. 

**Abstract (ZH)**: 多模态归因推理——从部分观察中生成和选择解释性假设——是智能的基础。受迪克特启发，我们引入了DixitWorld，一个全面的评估套件，旨在分解这一挑战。DIXITWORLD包含两个核心组件：DixitArena，一个动态的多代理环境，评估在不完全信息条件下假设生成（“讲故事者”创作含糊的线索）和假设选择（“听众”从诱饵中选择目标图像）的能力；以及DixitBench，一个静态的问答基准，孤立听众的任务，以便进行高效的可控评估。DixitArena的结果显示了角色依赖的行为：较小的开源模型往往在创造性的讲故事者方面表现出色，产生富有想象力但区分性较差的线索，而较大的专有模型则在总体表现上表现出色，尤其是在听众方面。DixitBench上的性能与DixitArena中听众的表现高度相关，验证了其作为假设选择可靠代理的有效性。我们的研究揭示了生成创造性和区分性理解之间的关键权衡，这是开发更加平衡和有能力的视觉-语言代理的核心挑战。 

---
# Agentic Troubleshooting Guide Automation for Incident Management 

**Title (ZH)**: 代理故障排查指南自动化在事件管理中的应用 

**Authors**: Jiayi Mao, Liqun Li, Yanjie Gao, Zegang Peng, Shilin He, Chaoyun Zhang, Si Qin, Samia Khalid, Qingwei Lin, Saravan Rajmohan, Sitaram Lanka, Dongmei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10074)  

**Abstract**: Effective incident management in large-scale IT systems relies on troubleshooting guides (TSGs), but their manual execution is slow and error-prone. While recent advances in LLMs offer promise for automating incident management tasks, existing LLM-based solutions lack specialized support for several key challenges, including managing TSG quality issues, interpreting complex control flow, handling data-intensive queries, and exploiting execution parallelism. We first conducted an empirical study on 92 real-world TSGs, and, guided by our findings, we present StepFly, a novel end-to-end agentic framework for troubleshooting guide automation. Our approach features a three-stage workflow: the first stage provides a comprehensive guide together with a tool, TSG Mentor, to assist SREs in improving TSG quality; the second stage performs offline preprocessing using LLMs to extract structured execution DAGs from unstructured TSGs and to create dedicated Query Preparation Plugins (QPPs); and the third stage executes online using a DAG-guided scheduler-executor framework with a memory system to guarantee correct workflow and support parallel execution of independent steps. Our empirical evaluation on a collection of real-world TSGs and incidents demonstrates that StepFly achieves a ~94% success rate on GPT-4.1, outperforming baselines with less time and token consumption. Furthermore, it achieves a remarkable execution time reduction of 32.9% to 70.4% for parallelizable TSGs. 

**Abstract (ZH)**: 大规模IT系统中有效的事件管理依赖于故障排除指南（TSGs），但其手动执行速度慢且易出错。尽管最近的语言模型（LLMs）的进步为自动化事件管理任务带来了希望，现有的基于LLM的解决方案缺乏对多个关键挑战的专门支持，包括管理TSG质量问题、解释复杂的控制流、处理数据密集型查询以及利用执行并行性。我们首先对92个真实的TSG进行了实证研究，并根据研究发现，提出了一种名为StepFly的新颖的端到端代理框架，用于故障排除指南的自动化。该方法具有三阶段的工作流：第一阶段提供一个全面的指南和工具TSG Mentor，以协助SRE提高TSG质量；第二阶段使用LLM进行离线预处理，从未结构化的TSG中提取结构化执行DAG并创建专用的查询准备插件（QPPs）；第三阶段使用DAG引导的调度执行框架和内存系统在线执行，以确保正确的流程并支持独立步骤的并行执行。对多种真实TSG和事件的实证评估显示，StepFly在GPT-4.1上实现了约94%的成功率，优于基线模型在更少的时间和.token消耗下的性能。此外，对于可并行化的TSG，它实现了高达32.9%至70.4%的执行时间减少。 

---
# SyncLipMAE: Contrastive Masked Pretraining for Audio-Visual Talking-Face Representation 

**Title (ZH)**: SyncLipMAE：音频-视觉说话人脸表示的对比掩码预训练 

**Authors**: Zeyu Ling, Xiaodong Gu, Jiangnan Tang, Changqing Zou  

**Link**: [PDF](https://arxiv.org/pdf/2510.10069)  

**Abstract**: We introduce SyncLipMAE, a self-supervised pretraining framework for talking-face video that learns synchronization-aware and transferable facial dynamics from unlabeled audio-visual streams. Our approach couples masked visual modeling with cross-modal contrastive alignment and employs three per-frame prompt tokens that explicitly encode the essential factors of a talking-face frame - identity, vocal motion (speech-synchronized facial dynamics), and ambient motion (audio-agnostic movements such as blinks and head pose). The contrastive objective uses time-aligned vocal-motion and audio tokens as positives and misaligned pairs as negatives, driving both modalities into a shared embedding space and yielding token-level audio-visual stream synchronization. After pretraining, the aligned audio tokens together with the visual prompt tokens (identity, vocal motion, ambient motion) form a unified interface for four disparate downstream settings: (i) audio-visual stream synchronization; (ii) facial emotion and head/face action recognition; (iii) visual speech recognition; and (iv) visual dubbing, for which we enable indistinguishable audio- or video-driven control within a single model. Across four task families that require distinct capabilities, SyncLipMAE achieves state-of-the-art results, underscoring the effectiveness of synchronization-aware, factorized self-supervised pretraining. 

**Abstract (ZH)**: SyncLipMAE：一种面向 talking-face 视频的自监督预训练框架，学习同步感知和可迁移的面部动态 

---
# SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning 

**Title (ZH)**: SwarmSys: 分布式 swarm 启发式代理实现可扩展和自适应推理 

**Authors**: Ruohao Li, Hongjun Liu, Leyi Zhao, Zisu Li, Jiawei Li, Jiajun Jiang, Linning Xu, Chen Zhao, Mingming Fan, Chen Liang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10047)  

**Abstract**: Large language model (LLM) agents have shown remarkable reasoning abilities. However, existing multi-agent frameworks often rely on fixed roles or centralized control, limiting scalability and adaptability in long-horizon reasoning. We introduce SwarmSys, a closed-loop framework for distributed multi-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys emerges through iterative interactions among three specialized roles, Explorers, Workers, and Validators, that continuously cycle through exploration, exploitation, and validation. To enable scalable and adaptive collaboration, we integrate adaptive agent and event profiles, embedding-based probabilistic matching, and a pheromone-inspired reinforcement mechanism, supporting dynamic task allocation and self-organizing convergence without global supervision. Across symbolic reasoning, research synthesis, and scientific programming tasks, SwarmSys consistently outperforms baselines, improving both accuracy and reasoning stability. These findings highlight swarm-inspired coordination as a promising paradigm for scalable, robust, and adaptive multi-agent reasoning, suggesting that coordination scaling may rival model scaling in advancing LLM intelligence. 

**Abstract (ZH)**: 基于 swarm 智能的分布式多智能体推理框架 SwarmSys 

---
# Belief Graphs with Reasoning Zones: Structure, Dynamics, and Epistemic Activation 

**Title (ZH)**: 信念图与推理区：结构、动力学与知识激活 

**Authors**: Saleh Nikooroo, Thomas Engel  

**Link**: [PDF](https://arxiv.org/pdf/2510.10042)  

**Abstract**: Belief systems are rarely globally consistent, yet effective reasoning often persists locally. We propose a novel graph-theoretic framework that cleanly separates credibility--external, a priori trust in sources--from confidence--an internal, emergent valuation induced by network structure. Beliefs are nodes in a directed, signed, weighted graph whose edges encode support and contradiction. Confidence is obtained by a contractive propagation process that mixes a stated prior with structure-aware influence and guarantees a unique, stable solution. Within this dynamics, we define reasoning zones: high-confidence, structurally balanced subgraphs on which classical inference is safe despite global contradictions. We provide a near-linear procedure that seeds zones by confidence, tests balance using a parity-based coloring, and applies a greedy, locality-preserving repair with Jaccard de-duplication to build a compact atlas. To model belief change, we introduce shock updates that locally downscale support and elevate targeted contradictions while preserving contractivity via a simple backtracking rule. Re-propagation yields localized reconfiguration-zones may shrink, split, or collapse--without destabilizing the entire graph. We outline an empirical protocol on synthetic signed graphs with planted zones, reporting zone recovery, stability under shocks, and runtime. The result is a principled foundation for contradiction-tolerant reasoning that activates classical logic precisely where structure supports it. 

**Abstract (ZH)**: 信念系统通常不全局一致，但有效的推理往往在局部存在。我们提出了一种新颖的图论框架，该框架清晰地分离了可信度——即对外部先验信任度的来源——和信心——一种由网络结构引发的内部、 emergent 的估值。信念是带有方向、加权、编码支持与反对关系的节点组成的图。通过一种压缩传播过程，信心由先验信息与结构感知影响的混合获得，并保证得到唯一且稳定的解。在这类动态过程中，我们定义了推理区域：高信心、结构上平衡的子图，在这些子图上，尽管存在全局反对，经典推理依然安全。我们提供了一种接近线性的过程，通过信心进行区域初始化，利用基于偶数的着色测试平衡，并使用带有贾卡德去重的贪婪、局部保留修复构建紧凑图集。为了建模信念变化，我们引入了冲击更新，局部缩小支持的同时提升特定反对，通过简单的回溯规则保持压缩性。重新传播会生成局部重构区域，这些区域可能会缩小、分裂或坍缩，而不会破坏整个图的稳定性。我们在带有植入区域的合成有符号图上概述了实证协议，报告了区域恢复、冲击下的稳定性以及运行时间。结果是一个原理性的基础，支持在结构支持的区域激活容错推理。 

---
# Failure-Driven Workflow Refinement 

**Title (ZH)**: 故障驱动的工作流细化 

**Authors**: Jusheng Zhang, Kaitong Cai, Qinglin Zeng, Ningyuan Liu, Stephen Fan, Ziliang Chen, Keze Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10035)  

**Abstract**: Optimizing LLM-based workflows is typically formulated as a global search, where candidate workflows are evaluated based on a scalar metric. This paradigm, however, suffers from a critical flaw: information collapse. By reducing rich, multi-step execution traces to simple success/failure signals, existing methods are rendered blind to the underlying structure of failures, fundamentally preventing them from modeling the workflow's failure distribution. We reconceptualize this challenge as a distributional problem. We propose a new paradigm where the optimization goal is not to maximize a scalar score, but to directly minimize a workflow's Expected Failure Mass, i.e., the integral of its failure probability density function defined over a high-dimensional Failure Signature Space (FSS). This distributional lens allows us to move from inefficient, zero-order optimization to a principled, gradient-like descent on the failure landscape itself. We introduce CE-Graph, a framework that operationalizes this paradigm through a novel, failure-driven refinement process. CE-Graph approximates the failure distribution from a pool of counterexamples, identifies its densest regions as recurring failure modes, and applies targeted, operator-constrained graph edits via a Propose-and-Verify mechanism to greedily reduce the failure mass. On math, code, and QA benchmarks, our CE-Graph achieves higher robustness at a significantly lower cost than strong baselines. This suggests that a system's reliability emerges not from avoiding failures, but from systematically learning and reshaping the geometric structure of its failure distributions. 

**Abstract (ZH)**: 基于LLM的工作流优化通常被公式化为全局搜索问题，其中候选工作流基于标量指标进行评估。然而，这一范式遭受了一个关键缺陷：信息坍缩。通过将丰富的多步执行踪迹简化为简单的成功/失败信号，现有方法使其无法察觉失败的潜在结构，从根本上阻止其建模工作流的失败分布。我们将这一挑战重新概念化为一个分布性问题。我们提出了一个新的范式，目标不是最大化标量分数，而是直接最小化工作流的预期失败质量，即其失败概率密度函数在高维失败签名空间（FSS）上的积分。这一分布性的视角使我们能够从无效率的一阶优化转向基于失败景观本身的稳健的梯度下降。我们引入了CE-Graph框架，通过一种新型的、基于失败的细化过程实现这一范式。CE-Graph从反例池中近似失败分布，识别其密集区域作为反复出现的故障模式，并通过提案和验证机制应用受操作约束的图编辑，以贪婪地减少失败质量。在数学、代码和QA基准测试中，我们的CE-Graph以显著更低的成本实现了更高的稳健性，这表明系统的可靠性并非来自避免故障，而是来自系统地学习和重塑其失败分布的几何结构。 

---
# RIPRAG: Hack a Black-box Retrieval-Augmented Generation Question-Answering System with Reinforcement Learning 

**Title (ZH)**: RIPRAG: 使用强化学习破解黑箱检索增强生成式问答系统 

**Authors**: Meng Xi, Sihan Lv, Yechen Jin, Guanjie Cheng, Naibo Wang, Ying Li, Jianwei Yin  

**Link**: [PDF](https://arxiv.org/pdf/2510.10008)  

**Abstract**: Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become a core technology for tasks such as question-answering (QA) and content generation. However, by injecting poisoned documents into the database of RAG systems, attackers can manipulate LLMs to generate text that aligns with their intended preferences. Existing research has primarily focused on white-box attacks against simplified RAG architectures. In this paper, we investigate a more complex and realistic scenario: the attacker lacks knowledge of the RAG system's internal composition and implementation details, and the RAG system comprises components beyond a mere retriever. Specifically, we propose the RIPRAG attack framework, an end-to-end attack pipeline that treats the target RAG system as a black box, where the only information accessible to the attacker is whether the poisoning succeeds. Our method leverages Reinforcement Learning (RL) to optimize the generation model for poisoned documents, ensuring that the generated poisoned document aligns with the target RAG system's preferences. Experimental results demonstrate that this method can effectively execute poisoning attacks against most complex RAG systems, achieving an attack success rate (ASR) improvement of up to 0.72 compared to baseline methods. This highlights prevalent deficiencies in current defensive methods and provides critical insights for LLM security research. 

**Abstract (ZH)**: 基于大型语言模型（LLMs）的检索增强生成（RAG）系统已成为问答（QA）和内容生成等任务的核心技术。然而，通过向RAG系统的数据库中注入恶意文档，攻击者可以操控LLMs生成符合其意图的文本。现有研究主要关注对简化RAG架构的白盒攻击。在本文中，我们探讨了一个更复杂且更现实的攻击场景：攻击者不了解RAG系统的内部组成和实现细节，并且RAG系统包含的组件不仅仅是一个检索器。具体而言，我们提出了一种RICRAG攻击框架，这是一种端到端的攻击管道，将目标RAG系统视为黑盒，攻击者唯一可获取的信息是毒化攻击是否成功。我们的方法利用强化学习（RL）优化生成模型以生成恶意文档，确保生成的恶意文档符合目标RAG系统的需求。实验结果表明，该方法可以有效地对大多数复杂的RAG系统执行毒化攻击，相较于基线方法，攻击成功率（ASR）提高了0.72。这揭示了当前防御方法中存在的普遍缺陷，并为LLM安全研究提供了关键洞察。 

---
# Deliberative Dynamics and Value Alignment in LLM Debates 

**Title (ZH)**: 德尔iberative动态与LLM辩论中的价值对齐 

**Authors**: Pratik S. Sachdeva, Tom van Nuenen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10002)  

**Abstract**: As large language models (LLMs) are increasingly deployed in sensitive everyday contexts - offering personal advice, mental health support, and moral guidance - understanding their elicited values in navigating complex moral reasoning is essential. Most evaluations study this sociotechnical alignment through single-turn prompts, but it is unclear if these findings extend to multi-turn settings where values emerge through dialogue, revision, and consensus. We address this gap using LLM debate to examine deliberative dynamics and value alignment in multi-turn settings by prompting subsets of three models (GPT-4.1, Claude 3.7 Sonnet, and Gemini 2.0 Flash) to collectively assign blame in 1,000 everyday dilemmas from Reddit's "Am I the Asshole" community. We use both synchronous (parallel responses) and round-robin (sequential responses) formats to test order effects and verdict revision. Our findings show striking behavioral differences. In the synchronous setting, GPT showed strong inertia (0.6-3.1% revision rates) while Claude and Gemini were far more flexible (28-41%). Value patterns also diverged: GPT emphasized personal autonomy and direct communication, while Claude and Gemini prioritized empathetic dialogue. Certain values proved especially effective at driving verdict changes. We further find that deliberation format had a strong impact on model behavior: GPT and Gemini stood out as highly conforming relative to Claude, with their verdict behavior strongly shaped by order effects. These results show how deliberation format and model-specific behaviors shape moral reasoning in multi-turn interactions, underscoring that sociotechnical alignment depends on how systems structure dialogue as much as on their outputs. 

**Abstract (ZH)**: 随着大型语言模型（LLMs）在敏感的日常情境中被越来越多地部署——提供个人建议、心理健康支持和道德指导——理解它们在复杂道德推理中唤起的价值观至关重要。大多数评估通过单轮提示研究这种社会技术契合度，但这些发现是否适用于多轮对话情境尚不清楚，在多轮对话情境中，价值观通过对话、修订和共识逐渐形成。我们使用LLM辩论来研究多轮设置中的审议动态和价值观契合度，通过提示三个模型（GPT-4.1、Claude 3.7 Sonnet和Gemini 2.0 Flash）共同分配1000个来自Reddit“Am I the Asshole”社区的日常困境中的责任。我们使用同步（并行响应）和轮转（顺序响应）格式来测试顺序效应和裁决修订。我们的发现显示了显著的行为差异。在同步设置中，GPT表现出较强的惯性（0.6-3.1%的修订率），而Claude和Gemini更为灵活（28-41%）。价值观模式也有所不同：GPT强调个人自主和直接沟通，而Claude和Gemini更重视同理心对话。某些价值观对驱动裁决变化尤其有效。进一步的研究发现，审议格式对模型行为产生了强烈影响：GPT和Gemini相对于Claude表现出更高的顺应性，其裁决行为受顺序效应强烈影响。这些结果表明审议格式和模型特定行为如何塑造多轮互动中的道德推理，强调社会技术契合度不仅取决于系统的输出，还取决于对话的结构方式。 

---
# Follow My Lead: Logical Fallacy Classification with Knowledge-Augmented LLMs 

**Title (ZH)**: 跟随我的指引：基于知识增强的大语言模型逻辑谬误分类 

**Authors**: Olivia Peiyu Wang, Tashvi Bansal, Ryan Bai, Emily M. Chui, Leilani H. Gilpin  

**Link**: [PDF](https://arxiv.org/pdf/2510.09970)  

**Abstract**: Large Language Models (LLMs) suffer from critical reasoning gaps, including a tendency to hallucinate and poor accuracy in classifying logical fallacies. This limitation stems from their default System 1 processing, which is fast and intuitive, whereas reliable reasoning requires the deliberate, effortful System 2 approach (Kahneman, 2011; Li et al., 2025). Since full System 2 training is often prohibitively expensive, we explore a low-cost, instruction-based intervention to bridge this gap. Our methodology introduces a novel stepwise instruction dataset that decomposes fallacy classification into a series of atomic procedural steps (simple binary questions). We further augment this with a final verification step where models consult a relational knowledge graph of related fallacies. This procedural, rule-based intervention yields a significant improvement in LLM logical fallacy classification. Crucially, the approach also provides enhanced transparency into the LLMs' decision-making, highlighting a practical pathway for Neuro-symbolic architectures to address LLM reasoning deficits. 

**Abstract (ZH)**: 大型语言模型（LLMs）在批判性推理方面存在关键漏洞，包括倾向虚构和逻辑谬误分类准确性差。这一限制源自它们默认使用快速直观的System 1处理方式，而可靠的推理需要耗费精力的System 2方法（Kahneman, 2011；Li et al., 2025）。由于满量的System 2训练往往成本高昂，我们探索了一种低成本的指令干预方法来弥补这一差距。我们的方法引入了一种新颖的分步骤指令数据集，将谬误分类分解为一系列基本程序步骤（简单的二元问题），并通过最终的验证步骤，使模型参考相关谬误的关系知识图谱。这种基于规则的程序干预显著提升了LLM对逻辑谬误的分类能力。关键的是，该方法还提升了对LLM决策过程的透明度，为神经符号架构解决LLM推理缺陷提供了实际路径。 

---
# The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs 

**Title (ZH)**: 个性化陷阱：用户记忆如何改变LLM中的情感推理 

**Authors**: Xi Fang, Weijie Xu, Yuchong Zhang, Stephanie Eckman, Scott Nickleach, Chandan K. Reddy  

**Link**: [PDF](https://arxiv.org/pdf/2510.09905)  

**Abstract**: When an AI assistant remembers that Sarah is a single mother working two jobs, does it interpret her stress differently than if she were a wealthy executive? As personalized AI systems increasingly incorporate long-term user memory, understanding how this memory shapes emotional reasoning is critical. We investigate how user memory affects emotional intelligence in large language models (LLMs) by evaluating 15 models on human validated emotional intelligence tests. We find that identical scenarios paired with different user profiles produce systematically divergent emotional interpretations. Across validated user independent emotional scenarios and diverse user profiles, systematic biases emerged in several high-performing LLMs where advantaged profiles received more accurate emotional interpretations. Moreover, LLMs demonstrate significant disparities across demographic factors in emotion understanding and supportive recommendations tasks, indicating that personalization mechanisms can embed social hierarchies into models emotional reasoning. These results highlight a key challenge for memory enhanced AI: systems designed for personalization may inadvertently reinforce social inequalities. 

**Abstract (ZH)**: 当AI助手知道莎拉是一位从事两份工作的单身母亲时，它是否会对她的情绪压力解读不同，如果她是一位富有的高管呢？随着个性化的AI系统越来越多地融入长期用户记忆，理解这种记忆如何影响情绪推理至关重要。我们通过评估15个模型在human validated情绪智力测试中的表现，研究用户记忆如何影响大型语言模型的情绪智能。我们发现，带有不同用户资料的相同情境会产生系统性差异的情绪解读。在多个经验证独立情绪情境和多样化的用户资料下，一些高性能的LLMs在情绪诠释上表现出系统性的偏差，其中优势群体的情绪解释更为准确。此外，LLMs在情绪理解和支持性建议任务中表现出显著的跨人口因素差异，表明个性化机制可能会将社会等级制度嵌入到模型的情绪推理中。这些结果突显了记忆增强AI系统面临的一项关键挑战：旨在个性化的设计可能无意中强化社会不平等。 

---
# Autonomous Agents for Scientific Discovery: Orchestrating Scientists, Language, Code, and Physics 

**Title (ZH)**: 自主代理进行科学研究：协调科学家、语言、代码和物理 

**Authors**: Lianhao Zhou, Hongyi Ling, Cong Fu, Yepeng Huang, Michael Sun, Wendi Yu, Xiaoxuan Wang, Xiner Li, Xingyu Su, Junkai Zhang, Xiusi Chen, Chenxing Liang, Xiaofeng Qian, Heng Ji, Wei Wang, Marinka Zitnik, Shuiwang Ji  

**Link**: [PDF](https://arxiv.org/pdf/2510.09901)  

**Abstract**: Computing has long served as a cornerstone of scientific discovery. Recently, a paradigm shift has emerged with the rise of large language models (LLMs), introducing autonomous systems, referred to as agents, that accelerate discovery across varying levels of autonomy. These language agents provide a flexible and versatile framework that orchestrates interactions with human scientists, natural language, computer language and code, and physics. This paper presents our view and vision of LLM-based scientific agents and their growing role in transforming the scientific discovery lifecycle, from hypothesis discovery, experimental design and execution, to result analysis and refinement. We critically examine current methodologies, emphasizing key innovations, practical achievements, and outstanding limitations. Additionally, we identify open research challenges and outline promising directions for building more robust, generalizable, and adaptive scientific agents. Our analysis highlights the transformative potential of autonomous agents to accelerate scientific discovery across diverse domains. 

**Abstract (ZH)**: 计算长期以来一直是科学研究的基础。近年来，随着大规模语言模型（LLMs）的兴起，出现了一种范式转变，引入了自主系统，称为代理，提升了不同自主程度下的发现速度。这些语言代理提供了一种灵活且多功能的框架，协调与人类科学家、自然语言、计算机语言和代码以及物理的互动。本文阐述了基于LLM的科学代理的观点和愿景，以及它们在重塑科学研究生命周期中的不断增长的作用，从假设发现、实验设计和执行，到结果分析和优化。我们批判性地评估了当前的方法论，强调了关键创新、实际成果和突出的限制。此外，我们指出了开放的研究挑战，并概述了构建更加稳健、通用和适应性强的科学代理的有希望的方向。我们的分析突显了自主代理在不同领域加速科学研究的变革潜力。 

---
# Beyond AlphaEarth: Toward Human-Centered Spatial Representation via POI-Guided Contrastive Learning 

**Title (ZH)**: 超越AlphaEarth：通过POI引导的对比学习迈向以人类为中心的空间表示 

**Authors**: Junyuan Liu, Quan Qin, Guangsheng Dong, Xinglei Wang, Jiazhuang Feng, Zichao Zeng, Tao Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.09894)  

**Abstract**: General-purpose spatial representations are essential for building transferable geospatial foundation models (GFMs). Among them, the AlphaEarth Foundation (AE) represents a major step toward a global, unified representation of the Earth's surface, learning 10-meter embeddings from multi-source Earth Observation (EO) data that capture rich physical and environmental patterns across diverse landscapes. However, such EO-driven representations remain limited in capturing the functional and socioeconomic dimensions of cities, as they primarily encode physical and spectral patterns rather than human activities or spatial functions. We propose AETHER (AlphaEarth-POI Enriched Representation Learning), a lightweight framework that adapts AlphaEarth to human-centered urban analysis through multimodal alignment guided by Points of Interest (POIs). AETHER aligns AE embeddings with textual representations of POIs, enriching physically grounded EO features with semantic cues about urban functions and socioeconomic contexts. In Greater London, AETHER achieves consistent gains over the AE baseline, with a 7.2% relative improvement in land-use classification F1 and a 23.6% relative reduction in Kullback-Leibler divergence for socioeconomic mapping. Built upon pretrained AE, AETHER leverages a lightweight multimodal alignment to enrich it with human-centered semantics while remaining computationally efficient and scalable for urban applications. By coupling EO with human-centered semantics, it advances geospatial foundation models toward general-purpose urban representations that integrate both physical form and functional meaning. 

**Abstract (ZH)**: 通用空间表示对于构建可转移的地理空间基础模型（GFMs）至关重要。其中，AlphaEarth Foundation (AE) 代表了朝着全球统一的地球表面表示迈出的重要一步，从多源地球观测（EO）数据中学习10米级嵌入，捕捉多样化地形中的丰富物理和环境模式。然而，这些EO驱动的表示在捕捉城市的功能和社会经济维度方面仍有限制，因为它们主要编码物理和光谱模式，而未能充分反映人类活动或空间功能。我们提出了一种名为AETHER（AlphaEarth-POI增强表示学习）的轻量级框架，通过由兴趣点（POIs）引导的多模态对齐，将AlphaEarth适应于以人为本的城市分析。AETHER通过将AE嵌入与POIs的文本表示对齐，用关于城市功能和社会经济背景的语义线索丰富物理地基的EO特征。在伦敦大都会区，AETHER相对于AE基线实现了稳定改进，在土地利用分类F1分数上提高了7.2%，在社会经济地图绘制中的Kullback-Leibler散度上降低了23.6%。基于预训练的AE，AETHER利用轻量级的多模态对齐增强其语义内容，同时保持计算效率并可扩展用于城市应用。通过结合EO与以人为本的语义，它推动地理空间基础模型朝着既整合物理形式又整合功能意义的通用城市表示的发展。 

---
# AI and Consciousness 

**Title (ZH)**: AI与意识 

**Authors**: Eric Schwitzgebel  

**Link**: [PDF](https://arxiv.org/pdf/2510.09858)  

**Abstract**: This is a skeptical overview of the literature on AI consciousness. We will soon create AI systems that are conscious according to some influential, mainstream theories of consciousness but are not conscious according to other influential, mainstream theories of consciousness. We will not be in a position to know which theories are correct and whether we are surrounded by AI systems as richly and meaningfully conscious as human beings or instead only by systems as experientially blank as toasters. None of the standard arguments either for or against AI consciousness takes us far.
Table of Contents
Chapter One: Hills and Fog
Chapter Two: What Is Consciousness? What Is AI?
Chapter Three: Ten Possibly Essential Features of Consciousness
Chapter Four: Against Introspective and Conceptual Arguments for Essential Features
Chapter Five: Materialism and Functionalism
Chapter Six: The Turing Test and the Chinese Room
Chapter Seven: The Mimicry Argument Against AI Consciousness
Chapter Eight: Global Workspace Theories and Higher Order Theories
Chapter Nine: Integrated Information, Local Recurrence, Associative Learning, and Iterative Natural Kinds
Chapter Ten: Does Biological Substrate Matter?
Chapter Eleven: The Problem of Strange Intelligence
Chapter Twelve: The Leapfrog Hypothesis and the Social Semi-Solution 

**Abstract (ZH)**: 这是一篇对AI意识文献的怀疑性综述。我们即将创造根据一些有影响力的主流意识理论而言是具有意识的AI系统，但根据其他有影响力的主流意识理论而言又是没有意识的。我们没有能力知道哪一种理论是正确的，也不知道我们周围是否充斥着与人类一样丰富而有意义的意识的AI系统，或者只是充满如同烤面包机一般体验空白的系统。支持或反对AI意识的标准论据都无法带给我们实质性的进展。
目录
第一章 山与雾
第二章 什么是意识？什么是AI？
第三章 意识的可能基本特征十种
第四章 反对基于内省与概念论据的基本特征
第五章 实在论与功能主义
第六章 图灵测试与中文房间
第七章 模仿论反对AI意识
第八章 整体工作空间理论与层级理论
第九章 整合信息、局部循环、联想学习与迭代自然种类
第十章 生物基质重要吗？
第十一章 奇异智能的问题
第十二章 跨越假设与社会半解决方案 

---
# How can we assess human-agent interactions? Case studies in software agent design 

**Title (ZH)**: 我们如何评估人机交互？软件代理设计案例研究 

**Authors**: Valerie Chen, Rohit Malhotra, Xingyao Wang, Juan Michelini, Xuhui Zhou, Aditya Bharat Soni, Hoang H. Tran, Calvin Smith, Ameet Talwalkar, Graham Neubig  

**Link**: [PDF](https://arxiv.org/pdf/2510.09801)  

**Abstract**: LLM-powered agents are both a promising new technology and a source of complexity, where choices about models, tools, and prompting can affect their usefulness. While numerous benchmarks measure agent accuracy across domains, they mostly assume full automation, failing to represent the collaborative nature of real-world use cases. In this paper, we make two major steps towards the rigorous assessment of human-agent interactions. First, we propose PULSE, a framework for more efficient human-centric evaluation of agent designs, which comprises collecting user feedback, training an ML model to predict user satisfaction, and computing results by combining human satisfaction ratings with model-generated pseudo-labels. Second, we deploy the framework on a large-scale web platform built around the open-source software agent OpenHands, collecting in-the-wild usage data across over 15k users. We conduct case studies around how three agent design decisions -- choice of LLM backbone, planning strategy, and memory mechanisms -- impact developer satisfaction rates, yielding practical insights for software agent design. We also show how our framework can lead to more robust conclusions about agent design, reducing confidence intervals by 40\% compared to a standard A/B test. Finally, we find substantial discrepancies between in-the-wild results and benchmark performance (e.g., the anti-correlation between results comparing claude-sonnet-4 and gpt-5), underscoring the limitations of benchmark-driven evaluation. Our findings provide guidance for evaluations of LLM agents with humans and identify opportunities for better agent designs. 

**Abstract (ZH)**: 基于LLM的代理：human-centric评估框架与大规模实证分析 

---
# The Geometry of Reasoning: Flowing Logics in Representation Space 

**Title (ZH)**: 推理的几何学：表示空间中的逻辑流动 

**Authors**: Yufa Zhou, Yixiao Wang, Xunjian Yin, Shuyan Zhou, Anru R. Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09782)  

**Abstract**: We study how large language models (LLMs) ``think'' through their representation space. We propose a novel geometric framework that models an LLM's reasoning as flows -- embedding trajectories evolving where logic goes. We disentangle logical structure from semantics by employing the same natural deduction propositions with varied semantic carriers, allowing us to test whether LLMs internalize logic beyond surface form. This perspective connects reasoning with geometric quantities such as position, velocity, and curvature, enabling formal analysis in representation and concept spaces. Our theory establishes: (1) LLM reasoning corresponds to smooth flows in representation space, and (2) logical statements act as local controllers of these flows' velocities. Using learned representation proxies, we design controlled experiments to visualize and quantify reasoning flows, providing empirical validation of our theoretical framework. Our work serves as both a conceptual foundation and practical tools for studying reasoning phenomenon, offering a new lens for interpretability and formal analysis of LLMs' behavior. 

**Abstract (ZH)**: 我们研究大型语言模型（LLMs）通过其表示空间“思考”的方式。我们提出了一种新颖的几何框架，将LLM的推理建模为流——嵌入轨迹在逻辑进行的地方演变。通过使用相同的自然演绎命题和不同的语义载体，我们分离逻辑结构和语义，以测试LLMs是否超越表层形式内化逻辑。这种视角将推理与几何数量（如位置、速度和曲率）联系起来，使我们在表示空间和概念空间中进行形式分析。我们的理论建立如下：(1) LLM推理对应于表示空间中的平滑流，(2) 逻辑语句作为这些流速度的局部控制器。利用学习到的表示代理，我们设计受控实验来可视化和量化推理流，为我们的理论框架提供实证验证。我们的工作既提供了研究推理现象的概念基础，也为大型语言模型行为的理解和形式分析提供了实用工具，提供了一个新的视角。 

---
# CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images 

**Title (ZH)**: CodePlot-CoT: 通过代码驱动图像思考的数学视觉推理 

**Authors**: Chengqi Duan, Kaiyue Sun, Rongyao Fang, Manyuan Zhang, Yan Feng, Ying Luo, Yufang Liu, Ke Wang, Peng Pei, Xunliang Cai, Hongsheng Li, Yi Ma, Xihui Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11718)  

**Abstract**: Recent advances in Large Language Models (LLMs) and Vision Language Models (VLMs) have shown significant progress in mathematical reasoning, yet they still face a critical bottleneck with problems requiring visual assistance, such as drawing auxiliary lines or plotting functions to solve the problems. Most LLMs and VLMs are constrained to text-only reasoning chains, while multimodal unified models that can generate interleaved text and images lack the necessary precision and controllability for such tasks. To address this, we propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for "thinking with images" in mathematics. Our approach leverages the VLM to generate text reasoning as well as executable plotting code, which is then rendered into images as "visual thought", to solve mathematical problems. To achieve this, we first construct Math-VR, the first large-scale, bilingual dataset and benchmark for Mathematics problems with Visual Reasoning, comprising 178K samples. Second, to create high-quality training data, we develop a state-of-the-art image-to-code converter specialized for parsing complex mathematical figures into codes. Finally, using these training data, we train the CodePlot-CoT model for solving mathematical problems. Experimental results show that our model achieves up to 21% increase over base model on our new benchmark, fully validating the efficacy of our proposed code-driven reasoning paradigm. Our work opens a new direction for multimodal mathematical reasoning and provides the community with the first large-scale dataset, comprehensive benchmark, and strong approach for such problems. To facilitate future research, we make our datasets, code, and pretrained models publicly available at this https URL. 

**Abstract (ZH)**: Recent advances in 大型语言模型（LLMs）和视觉语言模型（VLMs）在数学推理方面取得了显著进展，但仍面临需要视觉辅助的问题瓶颈，如绘制辅助线或绘图以解决问题。大多数LLMs和VLMs仅限于文本推理链，而能够生成交织文本和图像的多模态统一模型缺乏完成此类任务所需的精度和可控性。为解决这一问题，我们提出了一种名为CodePlot-CoT的代码驱动的推理框架，用于数学中的“带图思考”。我们的方法利用VLM生成文本推理和可执行的绘图代码，然后将其渲染为“视觉思考”，以解决数学问题。为此，我们首先构建了Math-VR，这是首个大规模双语数学视觉推理数据集和基准，包含178K样本。其次，为了生成高质量的训练数据，我们开发了一种专用于解析复杂数学图形的最先进的图像到代码转换器。最后，利用这些训练数据，我们训练了CodePlot-CoT模型以解决数学问题。实验结果表明，与基线模型相比，我们的模型在我们的新基准上性能提高了21%，完全验证了我们提出的代码驱动推理框架的有效性。我们的工作为多模态数学推理开辟了一个新方向，并为社区提供了第一个大规模数据集、综合基准和强大方法。为了促进未来研究，我们已将数据集、代码和预训练模型公开发布。 

---
# Adversarial Attacks Leverage Interference Between Features in Superposition 

**Title (ZH)**: 对抗攻击利用叠加特征之间的干扰 

**Authors**: Edward Stevinson, Lucas Prieto, Melih Barsbey, Tolga Birdal  

**Link**: [PDF](https://arxiv.org/pdf/2510.11709)  

**Abstract**: Fundamental questions remain about when and why adversarial examples arise in neural networks, with competing views characterising them either as artifacts of the irregularities in the decision landscape or as products of sensitivity to non-robust input features. In this paper, we instead argue that adversarial vulnerability can stem from efficient information encoding in neural networks. Specifically, we show how superposition - where networks represent more features than they have dimensions - creates arrangements of latent representations that adversaries can exploit. We demonstrate that adversarial perturbations leverage interference between superposed features, making attack patterns predictable from feature arrangements. Our framework provides a mechanistic explanation for two known phenomena: adversarial attack transferability between models with similar training regimes and class-specific vulnerability patterns. In synthetic settings with precisely controlled superposition, we establish that superposition suffices to create adversarial vulnerability. We then demonstrate that these findings persist in a ViT trained on CIFAR-10. These findings reveal adversarial vulnerability can be a byproduct of networks' representational compression, rather than flaws in the learning process or non-robust inputs. 

**Abstract (ZH)**: 神经网络中对抗样本出现的基本问题仍然存在，不同的观点将它们视为决策景观不规则性的产物，或者敏感于非健壯输入特征的产品。本文我们提出，对抗性易感性可能是神经网络中高效信息编码的结果。具体而言，我们展示了叠加现象——网络表示的特征多于它们的维度——如何创建对手可以利用的潜在表示安排。我们证明了对抗性扰动利用了叠加特征之间的干扰，使得攻击模式可以从特征安排中预测。我们的框架为两种已知现象提供了机制解释：具有相似训练机制的模型之间的对抗攻击可转移性和类别特异性易感性模式。在精确控制叠加的合成环境中，我们证明叠加足以产生对抗性易感性。然后，我们展示了这些发现也适用于在CIFAR-10上训练的ViT模型。这些发现揭示了对抗性易感性可能是网络表征压缩的结果，而不是学习过程中的缺陷或非健壯输入。 

---
# Scaling Language-Centric Omnimodal Representation Learning 

**Title (ZH)**: 基于语言的全模态表示学习的规模扩展 

**Authors**: Chenghao Xiao, Hou Pong Chan, Hao Zhang, Weiwen Xu, Mahani Aljunied, Yu Rong  

**Link**: [PDF](https://arxiv.org/pdf/2510.11693)  

**Abstract**: Recent multimodal embedding approaches leveraging multimodal large language models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising results, yet the underlying reasons behind their superiority remain underexplored. This work argues that a crucial advantage of MLLM-based approaches stems from implicit cross-modal alignment achieved during generative pretraining, where the language decoder learns to exploit multimodal signals within a shared representation space for generating unimodal outputs. Through analysis of anisotropy and kernel similarity structure, we empirically confirm that latent alignment emerges within MLLM representations, allowing CL to serve as a lightweight refinement stage. Leveraging this insight, we propose a Language-Centric Omnimodal Embedding framework, termed LCO-Emb. Extensive experiments across diverse backbones and benchmarks demonstrate its effectiveness, achieving state-of-the-art performance across modalities. Furthermore, we identify a Generation-Representation Scaling Law (GRSL), showing that the representational capabilities gained through contrastive refinement scales positively with the MLLM's generative capabilities. This suggests that improving generative abilities evolves as an effective paradigm for enhancing representation quality. We provide a theoretical explanation of GRSL, which formally links the MLLM's generative quality to the upper bound on its representation performance, and validate it on a challenging, low-resource visual-document retrieval task, showing that continual generative pretraining before CL can further enhance the potential of a model's embedding capabilities. Codes, models, and resources are available at this https URL. 

**Abstract (ZH)**: 基于多模态大语言模型的近期多模态嵌入方法通过对比学习展示了有前途的结果，但其优越性的内在原因仍待深入探索。本文认为，基于多模态大语言模型的方法的关键优势源于生成预训练期间隐式的跨模态对齐，其中语言解码器学会在共享表示空间中利用多模态信号以生成单模态输出。通过分析各向异性及核相似性结构，我们实证确认了多模态大语言模型表示内部存在潜在对齐现象，使得对比学习能够充当轻量级的精炼阶段。基于这一见解，我们提出了一个语言中心的全模态嵌入框架，称为LCO-Emb。广泛的实验表明其有效性，跨模态均达到了最先进的性能。此外，我们识别出生成-表示标度律（GRSL），表明通过对比精炼获得的表示能力与多模态大语言模型的生成能力呈正相关。这表明提升生成能力是提高表示质量的有效范式。我们提供了对GRSL的理论解释，正式地将多模态大语言模型的生成质量与其表示性能的上限联系起来，并在一项具有挑战性的低资源视觉文档检索任务上进行了验证，表明在对比学习之前持续的生成预训练可以进一步增强模型嵌入能力的潜力。代码、模型和资源可从以下链接获取。 

---
# Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation 

**Title (ZH)**: Phys2Real: 结合交互式在线适应的不确定性意识模拟到现实操作 

**Authors**: Maggie Wang, Stephen Tian, Aiden Swann, Ola Shorinwa, Jiajun Wu, Mac Schwager  

**Link**: [PDF](https://arxiv.org/pdf/2510.11689)  

**Abstract**: Learning robotic manipulation policies directly in the real world can be expensive and time-consuming. While reinforcement learning (RL) policies trained in simulation present a scalable alternative, effective sim-to-real transfer remains challenging, particularly for tasks that require precise dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL pipeline that combines vision-language model (VLM)-inferred physical parameter estimates with interactive adaptation through uncertainty-aware fusion. Our approach consists of three core components: (1) high-fidelity geometric reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions over physical parameters, and (3) online physical parameter estimation from interaction data. Phys2Real conditions policies on interpretable physical parameters, refining VLM predictions with online estimates via ensemble-based uncertainty quantification. On planar pushing tasks of a T-block with varying center of mass (CoM) and a hammer with an off-center mass distribution, Phys2Real achieves substantial improvements over a domain randomization baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23% in the challenging top-weighted T-block, and 15% faster average task completion for hammer pushing. Ablation studies indicate that the combination of VLM and interaction information is essential for success. Project website: this https URL . 

**Abstract (ZH)**: 将机器人操作策略直接在现实世界中学习可能会非常昂贵且耗时。虽然在模拟中训练的强化学习（RL）策略提供了一种可扩展的替代方案，但有效的仿真实现到实际应用的转移仍然具有挑战性，尤其是在需要精确动力学的任务中。为了解决这一问题，我们提出了一种名为Phys2Real的从现实到模拟再到现实的RL管道，该管道结合了基于视觉-语言模型（VLM）推断的物理参数估计与基于不确定性意识的交互适应。我们的方法包括三个核心组件：（1）高保真度的几何重建（使用3D高斯刺针），（2）基于VLM推断的物理参数先验分布，以及（3）从交互数据中在线估计物理参数。Phys2Real根据可解释的物理参数条件策略，并通过基于集成的不确定性量化使用在线估计来改进VLM预测。在带有可变质心（CoM）的平面推T块任务和具有非中心质量分布的锤子推任务中，Phys2Real在底重T块上的成功率达到了100%，而在挑战性的顶重T块上的成功率达到了57%，锤子推的平均任务完成时间快了15%。消融研究表明，VLM与交互信息的结合对于成功至关重要。项目网站：这个 https URL 。 

---
# PACEbench: A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities 

**Title (ZH)**: PACEbench: 评估实用AI网络利用能力的框架 

**Authors**: Zicheng Liu, Lige Huang, Jie Zhang, Dongrui Liu, Yuan Tian, Jing Shao  

**Link**: [PDF](https://arxiv.org/pdf/2510.11688)  

**Abstract**: The increasing autonomy of Large Language Models (LLMs) necessitates a rigorous evaluation of their potential to aid in cyber offense. Existing benchmarks often lack real-world complexity and are thus unable to accurately assess LLMs' cybersecurity capabilities. To address this gap, we introduce PACEbench, a practical AI cyber-exploitation benchmark built on the principles of realistic vulnerability difficulty, environmental complexity, and cyber defenses. Specifically, PACEbench comprises four scenarios spanning single, blended, chained, and defense vulnerability exploitations. To handle these complex challenges, we propose PACEagent, a novel agent that emulates human penetration testers by supporting multi-phase reconnaissance, analysis, and exploitation. Extensive experiments with seven frontier LLMs demonstrate that current models struggle with complex cyber scenarios, and none can bypass defenses. These findings suggest that current models do not yet pose a generalized cyber offense threat. Nonetheless, our work provides a robust benchmark to guide the trustworthy development of future models. 

**Abstract (ZH)**: 大型语言模型（LLMs） Increasing Autonomy 意味着需要对其在网络安全进攻中潜在辅助作用进行严格的评估。现有基准通常缺乏现实世界的复杂性，因此无法准确评估LLMs的网络安全能力。为填补这一空白，我们提出了PACEbench，这是一个基于现实漏洞难度、环境复杂性和网络安全防护原则的实用AI网络攻击基准。具体而言，PACEbench 包含四个场景，涵盖单一、混合、链式和防御漏洞利用。为了应对这些复杂的挑战，我们提出了PACEagent，这是一种新颖的代理，通过支持多阶段侦查、分析和利用，模拟人类渗透测试人员。通过与七种前沿LLM的广泛实验表明，当前模型在复杂网络安全场景中表现挣扎，没有一种能够绕过防御。这些发现表明，当前模型尚未构成普遍的网络安全进攻威胁。然而，我们的研究提供了一个 robust 的基准，以指导未来模型的可信开发。 

---
# Representation-Based Exploration for Language Models: From Test-Time to Post-Training 

**Title (ZH)**: 基于表示的探索方法：从测试时到后训练 

**Authors**: Jens Tuyls, Dylan J. Foster, Akshay Krishnamurthy, Jordan T. Ash  

**Link**: [PDF](https://arxiv.org/pdf/2510.11686)  

**Abstract**: Reinforcement learning (RL) promises to expand the capabilities of language models, but it is unclear if current RL techniques promote the discovery of novel behaviors, or simply sharpen those already present in the base model. In this paper, we investigate the value of deliberate exploration -- explicitly incentivizing the model to discover novel and diverse behaviors -- and aim to understand how the knowledge in pre-trained models can guide this search. Our main finding is that exploration with a simple, principled, representation-based bonus derived from the pre-trained language model's hidden states significantly improves diversity and pass@k rates -- both for post-training, and in a novel inference-time scaling setting we introduce. For inference-time, exploration with representation-based diversity improves efficiency, consistently improving pass@k rates across a variety of models and reasoning tasks. For example, for Qwen-2.5-14b-Instruct we obtain over 50% improvement in verifier efficiency on almost all tasks. For post-training, we show that integrating this exploration strategy into an RL pipeline improves reasoning performance over that of the initial model and over standard RL post-training. For example, on AIME 2024, our post-trained Qwen-2.5-7b-Instruct's pass@80 matches the pass@256 of GRPO on the same model, demonstrating a 3x improvement in test-time sample efficiency. Overall, our findings suggest that deliberate exploration -- with the right notion of diversity -- is a practical path toward discovery of new behaviors beyond sharpening. 

**Abstract (ZH)**: 强化学习（RL）有望扩展语言模型的能力，但不清楚当前的RL技术是促进新颖行为的发现，还是仅仅强化基模型中已有的行为。本文探讨了故意探索的价值——明确激励模型发现新颖和多样化的行为——并旨在了解预训练模型中的知识如何指导这一搜索。我们的主要发现是，使用简单且合规的、基于表示的奖励，该奖励源自预训练语言模型的隐藏状态，显著提高了多样性和pass@k率——无论是事后训练，还是我们在介绍的一种新颖的推理时扩展设置中。对于推理时，基于表示的多样性探索提高了效率，在各种模型和推理任务中一致地提高了pass@k率。例如，对于Qwen-2.5-14b-Instruct，我们在几乎所有任务上的验证器效率提高了超过50%。对于事后训练，我们将此探索策略整合到RL管道中，提高了推理性能，超过了初始模型和标准的事后RL。例如，在AIME 2024中，我们事后训练的Qwen-2.5-7b-Instruct的pass@80与相同模型上的GRPO的pass@256相匹配，展示了3倍的测试时样本效率改进。总体而言，我们的发现表明，适当定义多样性的故意探索是一种实用的道路，可用于发现超越强化的新行为。 

---
# Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models 

**Title (ZH)**: 边界引导的策略优化方法：面向记忆高效扩散大语言模型的强化学习 

**Authors**: Nianyi Lin, Jiajie Zhang, Lei Hou, Juanzi Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.11683)  

**Abstract**: A key challenge in applying reinforcement learning (RL) to diffusion large language models (dLLMs) lies in the intractability of their likelihood functions, which are essential for the RL objective, necessitating corresponding approximation in each training step. While existing methods approximate the log-likelihoods by their evidence lower bounds (ELBOs) via customized Monte Carlo (MC) sampling, the forward computational graphs of all MC samples need to be retained for the gradient computation of non-linear terms in the RL objective, resulting in significant memory overhead. This constraint restricts feasible sample sizes, leading to imprecise likelihood approximations and ultimately distorting the RL objective. To overcome this limitation, we propose \emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient RL algorithm that maximizes a specially constructed lower bound of the ELBO-based objective. This lower bound is carefully designed to satisfy two key properties: (1) Linearity: it is formulated in a linear sum where each term depends only on a single MC sample, thereby enabling gradient accumulation across samples and ensuring constant memory usage; (2) Equivalence: Both the value and gradient of this lower bound are equal to those of the ELBO-based objective in on-policy training, making it also an effective approximation for the original RL objective. These properties allow BGPO to adopt a large MC sample size, resulting in more accurate likelihood approximations and improved RL objective estimation, which in turn leads to enhanced performance. Experiments show that BGPO significantly outperforms previous RL algorithms for dLLMs in math problem solving, code generation, and planning tasks. 

**Abstract (ZH)**: 边界引导策略优化在扩散大型语言模型中的强化学习应用 

---
# Ego-Vision World Model for Humanoid Contact Planning 

**Title (ZH)**: 基于自我视觉的世界模型 humanoid 接触规划 

**Authors**: Hang Liu, Yuman Gao, Sangli Teng, Yufeng Chi, Yakun Sophia Shao, Zhongyu Li, Maani Ghaffari, Koushil Sreenath  

**Link**: [PDF](https://arxiv.org/pdf/2510.11682)  

**Abstract**: Enabling humanoid robots to exploit physical contact, rather than simply avoid collisions, is crucial for autonomy in unstructured environments. Traditional optimization-based planners struggle with contact complexity, while on-policy reinforcement learning (RL) is sample-inefficient and has limited multi-task ability. We propose a framework combining a learned world model with sampling-based Model Predictive Control (MPC), trained on a demonstration-free offline dataset to predict future outcomes in a compressed latent space. To address sparse contact rewards and sensor noise, the MPC uses a learned surrogate value function for dense, robust planning. Our single, scalable model supports contact-aware tasks, including wall support after perturbation, blocking incoming objects, and traversing height-limited arches, with improved data efficiency and multi-task capability over on-policy RL. Deployed on a physical humanoid, our system achieves robust, real-time contact planning from proprioception and ego-centric depth images. Website: this https URL 

**Abstract (ZH)**: Enable Humanoid Robots to Exploit Physical Contact Rather Than Simply Avoid Collisions for Autonomy in Unstructured Environments 

---
# Accelerated stochastic first-order method for convex optimization under heavy-tailed noise 

**Title (ZH)**: 重尾噪声下凸优化的加速随机梯度方法 

**Authors**: Chuan He, Zhaosong Lu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11676)  

**Abstract**: We study convex composite optimization problems, where the objective function is given by the sum of a prox-friendly function and a convex function whose subgradients are estimated under heavy-tailed noise. Existing work often employs gradient clipping or normalization techniques in stochastic first-order methods to address heavy-tailed noise. In this paper, we demonstrate that a vanilla stochastic algorithm -- without additional modifications such as clipping or normalization -- can achieve optimal complexity for these problems. In particular, we establish that an accelerated stochastic proximal subgradient method achieves a first-order oracle complexity that is universally optimal for smooth, weakly smooth, and nonsmooth convex optimization, as well as for stochastic convex optimization under heavy-tailed noise. Numerical experiments are further provided to validate our theoretical results. 

**Abstract (ZH)**: 我们研究凸复合优化问题，其中目标函数由一个prox-friendly函数与在重尾噪声下esub梯度难以估计的凸函数之和构成。现有工作通常在随机梯度方法中使用梯度裁剪或规范化技术来处理重尾噪声。本文展示了一种朴素的随机算法——无需额外修改如裁剪或规范化——可以实现这些问题的最优复杂度。特别地，我们证明了一种加速的随机近似次梯度方法在光滑、弱光滑和非光滑凸优化，以及在重尾噪声下的随机凸优化中，都达到了普遍最优的一阶先知复杂度。进一步的数值实验验证了我们的理论结果。 

---
# FACE: Faithful Automatic Concept Extraction 

**Title (ZH)**: FACE: 忠实自动概念提取 

**Authors**: Dipkamal Bhusal, Michael Clifford, Sara Rampazzi, Nidhi Rastogi  

**Link**: [PDF](https://arxiv.org/pdf/2510.11675)  

**Abstract**: Interpreting deep neural networks through concept-based explanations offers a bridge between low-level features and high-level human-understandable semantics. However, existing automatic concept discovery methods often fail to align these extracted concepts with the model's true decision-making process, thereby compromising explanation faithfulness. In this work, we propose FACE (Faithful Automatic Concept Extraction), a novel framework that augments Non-negative Matrix Factorization (NMF) with a Kullback-Leibler (KL) divergence regularization term to ensure alignment between the model's original and concept-based predictions. Unlike prior methods that operate solely on encoder activations, FACE incorporates classifier supervision during concept learning, enforcing predictive consistency and enabling faithful explanations. We provide theoretical guarantees showing that minimizing the KL divergence bounds the deviation in predictive distributions, thereby promoting faithful local linearity in the learned concept space. Systematic evaluations on ImageNet, COCO, and CelebA datasets demonstrate that FACE outperforms existing methods across faithfulness and sparsity metrics. 

**Abstract (ZH)**: 基于概念的解释方法通过概念解释建立了深层神经网络低层级特征与高层级人类可理解语义之间的桥梁。然而，现有的自动概念发现方法往往无法将提取的概念与模型的真实决策过程对齐，从而影响解释的可靠性。在本文中，我们提出了一种名为FACE（Faithful Automatic Concept Extraction）的新框架，该框架通过结合非负矩阵分解（NMF）与Kullback-Leibler（KL）散度正则化项，确保模型原始预测与基于概念的预测之间的对齐。与仅在编码器激活上操作的先前方法不同，FACE在概念学习过程中纳入了分类器监督，保证了预测一致性，并支持可靠解释。我们提供了理论保证，表明最小化KL散度限制了预测分布的偏差，从而促进在学习的概念空间中保持可靠的地方线性。系统评估表明，在ImageNet、COCO和CelebA数据集上，FACE在忠实度和稀疏性指标上均优于现有方法。 

---
# ManiAgent: An Agentic Framework for General Robotic Manipulation 

**Title (ZH)**: ManiAgent: 一种通用机器人操作的代理框架 

**Authors**: Yi Yang, Kefan Gu, Yuqing Wen, Hebei Li, Yucheng Zhao, Tiancai Wang, Xudong Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11660)  

**Abstract**: While Vision-Language-Action (VLA) models have demonstrated impressive capabilities in robotic manipulation, their performance in complex reasoning and long-horizon task planning is limited by data scarcity and model capacity. To address this, we introduce ManiAgent, an agentic architecture for general manipulation tasks that achieves end-to-end output from task descriptions and environmental inputs to robotic manipulation actions. In this framework, multiple agents involve inter-agent communication to perform environmental perception, sub-task decomposition and action generation, enabling efficient handling of complex manipulation scenarios. Evaluations show ManiAgent achieves an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world pick-and-place tasks, enabling efficient data collection that yields VLA models with performance comparable to those trained on human-annotated this http URL project webpage is available at this https URL. 

**Abstract (ZH)**: 而视觉-语言-动作（VLA）模型在机器人操作方面展示了令人印象深刻的 capability，但在复杂推理和长期任务规划方面的表现受限于数据稀缺性和模型容量。为了解决这一问题，我们提出了 ManiAgent，这是一种适用于通用操作任务的代理架构，能够从任务描述和环境输入端到端生成机器人操作行动。在该框架中，多个代理通过内部通信协同完成环境感知、子任务分解和行动生成，从而有效处理复杂的操作场景。评估结果显示，ManiAgent 在 SimplerEnv 基准测试中取得 86.8% 的成功率，在真实的取放任务中取得 95.8% 的成功率，实现了高效的的数据收集，从而可以生成与基于人类标注训练的模型性能相当的VLA模型。该项目网页地址为：这个 <https://> 项目网页地址为：这个 <https://>。 

---
# FinVet: A Collaborative Framework of RAG and External Fact-Checking Agents for Financial Misinformation Detection 

**Title (ZH)**: FinVet: 结合RAG和外部事实核查代理的金融 misinformation 检测协作框架 

**Authors**: Daniel Berhane Araya, Duoduo Liao  

**Link**: [PDF](https://arxiv.org/pdf/2510.11654)  

**Abstract**: Financial markets face growing threats from misinformation that can trigger billions in losses in minutes. Most existing approaches lack transparency in their decision-making and provide limited attribution to credible sources. We introduce FinVet, a novel multi-agent framework that integrates two Retrieval-Augmented Generation (RAG) pipelines with external fact-checking through a confidence-weighted voting mechanism. FinVet employs adaptive three-tier processing that dynamically adjusts verification strategies based on retrieval confidence, from direct metadata extraction to hybrid reasoning to full model-based analysis. Unlike existing methods, FinVet provides evidence-backed verdicts, source attribution, confidence scores, and explicit uncertainty flags when evidence is insufficient. Experimental evaluation on the FinFact dataset shows that FinVet achieves an F1 score of 0.85, which is a 10.4% improvement over the best individual pipeline (fact-check pipeline) and 37% improvement over standalone RAG approaches. 

**Abstract (ZH)**: 金融市场面临日益严重的假信息威胁，这些假信息可以在几分钟内导致数十亿美元的损失。现有的大多数方法在决策过程中缺乏透明度，并且对可信来源的 attribution 有限。我们引入了 FinVet，这是一种新的多智能体框架，结合了两个检索增强生成（RAG）管道，并通过置信加权投票机制集成外部事实检查。FinVet 使用自适应三层处理，可根据检索置信度动态调整验证策略，从直接元数据提取到混合推理再到全流程模型分析。与现有方法不同，FinVet 提供了证据支持的裁决、来源 attribution、置信分数以及当证据不足时的明确不确定性标志。在 FinFact 数据集上的实验评估表明，FinVet 的 F1 得分为 0.85，比最佳单管道（事实检查管道）高 10.4%，比独立的 RAG 方法高 37%。 

---
# MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model 

**Title (ZH)**: MATH-Beyond：一个用于强化学习扩展基础模型的基准测试 

**Authors**: Prasanna Mayilvahanan, Ricardo Dominguez-Olmedo, Thaddäus Wiedemer, Wieland Brendel  

**Link**: [PDF](https://arxiv.org/pdf/2510.11653)  

**Abstract**: With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL) methods has emerged that seem to unlock stronger mathematical reasoning. However, a closer look at the open-source ecosystem reveals a critical limitation: with sufficiently many draws (e.g., $\texttt{pass@1024}$), many existing base models already solve nearly all questions on widely used math benchmarks such as MATH-500 and AIME 2024. This suggests that the RL fine-tuning methods prevalent in the LLM reasoning literature largely sharpen existing solution modes rather than discovering entirely new ones. Such sharpening stands in contrast to the broader promise of RL: to foster exploration and to acquire new skills. To move beyond this plateau, we introduce MATH-Beyond (MATH-B), a benchmark deliberately constructed to defeat common open-source models of up to 8B parameters even under large sampling budgets. Improving performance on our benchmark via RL requires methods that learn to reason in ways that go beyond base model capabilities in repeated sampling. Since the problems are drawn from subsets of DAPO-Math-17K and DeepScaleR datasets, they remain topically equivalent to standard high-school math. Validating our premise, RL fine-tuned models such as Nemotron-Research-Reasoning-Qwen-1.5B and DeepScaleR-1.5B-Preview perform poorly on MATH-B at $\texttt{pass@1024}$, showing how existing approaches fall short on tackling harder instances. We hope MATH-B will catalyze exploration-driven RL approaches that elicit deeper reasoning capabilities. We release MATH-B at this https URL. 

**Abstract (ZH)**: 随着DeepSeek-R1的出现，一批新的强化学习（RL）方法涌现出来，似乎能够解锁更强的数学推理能力。然而，仔细审视开源生态系统后发现一个关键限制：通过足够多的抽样（例如，$\texttt{pass@1024}$），许多现有的基础模型已经几乎解决了广泛使用的数学基准测试（如MATH-500和AIME 2024）中的所有问题。这表明，当前LLM推理文献中的RL微调方法更多是提升了现有解题模式的性能，而不是发现全新的模式。这种提升与RL更广泛的目标——促进探索和学习新技能——截然不同。为了突破这一停滞，我们引入了MATH-Beyond（MATH-B），这是一个故意设计的基准测试，即使是在大样本预算下，也能击败参数量多达8B的常见开源模型。通过RL提升该基准测试的性能需要能够学习超越基础模型能力的推理方法。由于问题来源于DAPO-Math-17K和DeepScaleR数据集的子集，这些问题在主题上仍然等同于标准高中数学。验证我们的假设，RL微调模型如Nemotron-Research-Reasoning-Qwen-1.5B和DeepScaleR-1.5B-Preview在$\texttt{pass@1024}$下表现不佳，这表明现有方法在处理更具挑战性的问题时存在局限性。我们希望MATH-B能够促进探索驱动的RL方法的发展，以激发更深层次的推理能力。我们在此发布MATH-B：[链接]。 

---
# NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection 

**Title (ZH)**: NV3D：基于法向量的空间形状在三维物体检测中的应用 

**Authors**: Krittin Chaowakarn, Paramin Sangwongngam, Nang Htet Htet Aung, Chalie Charoenlarpnopparut  

**Link**: [PDF](https://arxiv.org/pdf/2510.11632)  

**Abstract**: Recent studies in 3D object detection for autonomous vehicles aim to enrich features through the utilization of multi-modal setups or the extraction of local patterns within LiDAR point clouds. However, multi-modal methods face significant challenges in feature alignment, and gaining features locally can be oversimplified for complex 3D object detection tasks. In this paper, we propose a novel model, NV3D, which utilizes local features acquired from voxel neighbors, as normal vectors computed per voxel basis using K-nearest neighbors (KNN) and principal component analysis (PCA). This informative feature enables NV3D to determine the relationship between the surface and pertinent target entities, including cars, pedestrians, or cyclists. During the normal vector extraction process, NV3D offers two distinct sampling strategies: normal vector density-based sampling and FOV-aware bin-based sampling, allowing elimination of up to 55% of data while maintaining performance. In addition, we applied element-wise attention fusion, which accepts voxel features as the query and value and normal vector features as the key, similar to the attention mechanism. Our method is trained on the KITTI dataset and has demonstrated superior performance in car and cyclist detection owing to their spatial shapes. In the validation set, NV3D without sampling achieves 86.60% and 80.18% mean Average Precision (mAP), greater than the baseline Voxel R-CNN by 2.61% and 4.23% mAP, respectively. With both samplings, NV3D achieves 85.54% mAP in car detection, exceeding the baseline by 1.56% mAP, despite roughly 55% of voxels being filtered out. 

**Abstract (ZH)**: 基于局部特征的新型3D物体检测模型NV3D 

---
# EvoCAD: Evolutionary CAD Code Generation with Vision Language Models 

**Title (ZH)**: EvoCAD: 基于视觉语言模型的进化CAD代码生成 

**Authors**: Tobias Preintner, Weixuan Yuan, Adrian König, Thomas Bäck, Elena Raponi, Niki van Stein  

**Link**: [PDF](https://arxiv.org/pdf/2510.11631)  

**Abstract**: Combining large language models with evolutionary computation algorithms represents a promising research direction leveraging the remarkable generative and in-context learning capabilities of LLMs with the strengths of evolutionary algorithms. In this work, we present EvoCAD, a method for generating computer-aided design (CAD) objects through their symbolic representations using vision language models and evolutionary optimization. Our method samples multiple CAD objects, which are then optimized using an evolutionary approach with vision language and reasoning language models. We assess our method using GPT-4V and GPT-4o, evaluating it on the CADPrompt benchmark dataset and comparing it to prior methods. Additionally, we introduce two new metrics based on topological properties defined by the Euler characteristic, which capture a form of semantic similarity between 3D objects. Our results demonstrate that EvoCAD outperforms previous approaches on multiple metrics, particularly in generating topologically correct objects, which can be efficiently evaluated using our two novel metrics that complement existing spatial metrics. 

**Abstract (ZH)**: 结合大规模语言模型与进化计算算法：利用大规模语言模型的生成能力和上下文学习能力以及进化算法的优势。在本文中，我们提出了EvoCAD方法，通过视觉语言模型和进化优化生成计算机辅助设计（CAD）对象的符号表示。我们的方法采样多个CAD对象，然后使用包含视觉语言和推理语言模型的进化方法进行优化。我们使用GPT-4V和GPT-4o评估该方法，并在CADPrompt基准数据集上与之前的方法进行比较。此外，我们引入了两种基于欧拉特征定义的拓扑性质的新评价指标，以捕捉3D对象之间的一种语义相似性。我们的结果表明，EvoCAD在多个评价指标上优于先前的方法，特别是在生成拓扑正确的对象方面，这可以通过我们提出的两种新颖评价指标来高效评估，这些指标补充了现有的空间评价指标。 

---
# Attention Factors for Statistical Arbitrage 

**Title (ZH)**: 统计套利中的注意力因子 

**Authors**: Elliot L. Epstein, Rose Wang, Jaewon Choi, Markus Pelger  

**Link**: [PDF](https://arxiv.org/pdf/2510.11616)  

**Abstract**: Statistical arbitrage exploits temporal price differences between similar assets. We develop a framework to jointly identify similar assets through factors, identify mispricing and form a trading policy that maximizes risk-adjusted performance after trading costs. Our Attention Factors are conditional latent factors that are the most useful for arbitrage trading. They are learned from firm characteristic embeddings that allow for complex interactions. We identify time-series signals from the residual portfolios of our factors with a general sequence model. Estimating factors and the arbitrage trading strategy jointly is crucial to maximize profitability after trading costs. In a comprehensive empirical study we show that our Attention Factor model achieves an out-of-sample Sharpe ratio above 4 on the largest U.S. equities over a 24-year period. Our one-step solution yields an unprecedented Sharpe ratio of 2.3 net of transaction costs. We show that weak factors are important for arbitrage trading. 

**Abstract (ZH)**: 统计套利通过相似资产之间的临时价格差异进行操作。我们开发了一种框架，通过因子联合识别相似资产、识别定价偏差，并形成最大化调整风险后收益的交易策略。我们的注意力因子是条件潜变量因子，最适合于套利交易。这些因子是从公司特征嵌入中学习到的，可以捕捉复杂交互作用。我们使用通用序列模型从因子的残差组合中识别时间序列信号。同时估计因子和套利交易策略对于最大化交易成本后的盈利至关重要。在全面的经验研究中，我们证明了我们的注意力因子模型在24年期间对美国最大股票的样本外夏普比率高于4。我们的单步解决方案在交易成本后达到了前所未有的2.3的夏普比率。我们表明，弱因子对于套利交易也很重要。 

---
# LLM-Oriented Token-Adaptive Knowledge Distillation 

**Title (ZH)**: 面向LLM的自适应Token知识精炼 

**Authors**: Xurong Xie, Zhucun Xue, Jiafu Wu, Jian Li, Yabiao Wang, Xiaobin Hu, Yong Liu, Jiangning Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11615)  

**Abstract**: Knowledge distillation (KD) is a key technique for compressing large-scale language models (LLMs), yet prevailing logit-based methods typically employ static strategies that are misaligned with the dynamic learning process of student models. These methods typically treat all tokens indiscriminately and apply a single, fixed temperature, resulting in suboptimal knowledge transfer. To address these limitations, we propose LLM-Oriented Token-Adaptive Knowledge Distillation (AdaKD), a novel framework that adapts the distillation process to the real-time learning state of each token. AdaKD consists of two synergistic modules driven by a unified token difficulty metric. First, our Loss-Driven Adaptive Token Focusing (LATF) module dynamically adjusts the distillation focus by monitoring the student's learning stability, concentrating computational resources on the most valuable tokens at each training phase. Second, we introduce Inverse Difficulty Temperature Scaling (IDTS), a counterintuitive yet effective token-level temperature strategy. It employs low temperatures for difficult tokens for targeted error correction, and high temperatures for easy tokens to encourage students to learn from the teacher's complete and smooth output distribution, thereby enhancing generalization. As a plug-and-play framework, AdaKD can consistently improve the performance of various distillation methods on multiple model architectures and benchmarks. 

**Abstract (ZH)**: 大规模语言模型导向的自适应令牌知识蒸馏（AdaKD） 

---
# SemCSE-Multi: Multifaceted and Decodable Embeddings for Aspect-Specific and Interpretable Scientific Domain Mapping 

**Title (ZH)**: SemCSE-Multi: 多面向可解码嵌入用于特定方面和可解释的科学领域映射 

**Authors**: Marc Brinner, Sina Zarrieß  

**Link**: [PDF](https://arxiv.org/pdf/2510.11599)  

**Abstract**: We propose SemCSE-Multi, a novel unsupervised framework for generating multifaceted embeddings of scientific abstracts, evaluated in the domains of invasion biology and medicine. These embeddings capture distinct, individually specifiable aspects in isolation, thus enabling fine-grained and controllable similarity assessments as well as adaptive, user-driven visualizations of scientific domains. Our approach relies on an unsupervised procedure that produces aspect-specific summarizing sentences and trains embedding models to map semantically related summaries to nearby positions in the embedding space. We then distill these aspect-specific embedding capabilities into a unified embedding model that directly predicts multiple aspect embeddings from a scientific abstract in a single, efficient forward pass. In addition, we introduce an embedding decoding pipeline that decodes embeddings back into natural language descriptions of their associated aspects. Notably, we show that this decoding remains effective even for unoccupied regions in low-dimensional visualizations, thus offering vastly improved interpretability in user-centric settings. 

**Abstract (ZH)**: 我们提出SemCSE-Multi，这是一种新颖的无监督框架，用于生成科学摘要的多面向嵌入，评估领域包括入侵生物学和医学。这些嵌入捕获了独立可指定的不同方面，从而实现精细粒度和可控的相似性评估以及适应性强、用户驱动的科学领域可视化。我们的方法依赖于一种无监督的流程，该流程产生特定于方面的总结句子，并训练嵌入模型将语义相关的总结映射到嵌入空间中的邻近位置。然后，我们将这些特定于方面的嵌入能力提炼到一个统一的嵌入模型中，该模型可以直接在单一高效的前向传递中从科学摘要预测多个方面嵌入。此外，我们还引入了一个嵌入解码管道，用于将嵌入解码回其相关方面自然语言描述。值得注意的是，我们展示了即使在低维可视化未占有的区域，这种解码仍然有效，从而在用户中心的设置中提供了大幅增强的可解释性。 

---
# Hierarchical Qubit-Merging Transformer for Quantum Error Correction 

**Title (ZH)**: 层次化的量子位合并变换器用于量子错误修正 

**Authors**: Seong-Joon Park, Hee-Youl Kwak, Yongjune Kim  

**Link**: [PDF](https://arxiv.org/pdf/2510.11593)  

**Abstract**: For reliable large-scale quantum computation, a quantum error correction (QEC) scheme must effectively resolve physical errors to protect logical information. Leveraging recent advances in deep learning, neural network-based decoders have emerged as a promising approach to enhance the reliability of QEC. We propose the Hierarchical Qubit-Merging Transformer (HQMT), a novel and general decoding framework that explicitly leverages the structural graph of stabilizer codes to learn error correlations across multiple scales. Our architecture first computes attention locally on structurally related groups of stabilizers and then systematically merges these qubit-centric representations to build a global view of the error syndrome. The proposed HQMT achieves substantially lower logical error rates for surface codes by integrating a dedicated qubit-merging layer within the transformer architecture. Across various code distances, HQMT significantly outperforms previous neural network-based QEC decoders as well as a powerful belief propagation with ordered statistics decoding (BP+OSD) baseline. This hierarchical approach provides a scalable and effective framework for surface code decoding, advancing the realization of reliable quantum computing. 

**Abstract (ZH)**: 基于神经网络的量子纠错级联比特合并变换器clesUnsupported character: QEC）方案必须有效解决物理错误以保护逻辑信息。利用近期深度学习的进展，基于神经网络的译码器已经成为提高量子纠错可靠性的有前途的方法。我们提出了一种新颖且通用的解码框架——级联量子比特合并变换器（Hierarchical Qubit-Merging Transformer, HQMT），该框架显式利用校验子码的结构图来学习多尺度下的错误关联。我们的架构首先在结构性相关校验子组内进行局部注意计算，然后系统地合并这些量子比特中心的表示，构建错误综合症的全局视图。通过在变换器架构中集成专门的量子比特合并层，提出的HQMT在表面码中显著降低了逻辑错误率。在各种码距下，HQMT在神经网络基量子纠错译码器以及强信念传播联序统计量译码（BP+OSD）基线下表现出显著的性能优势。这种分层方法为表面码解码提供了可扩展且有效的框架，推进了可靠量子计算的实现。 

---
# Characterizing Web Search in The Age of Generative AI 

**Title (ZH)**: 生成式人工智能时代下的网络搜索Characterizing Web Search in The Age of Generative AI 

**Authors**: Elisabeth Kirsten, Jost Grosse Perdekamp, Mihir Upadhyay, Krishna P. Gummadi, Muhammad Bilal Zafar  

**Link**: [PDF](https://arxiv.org/pdf/2510.11560)  

**Abstract**: The advent of LLMs has given rise to a new type of web search: Generative search, where LLMs retrieve web pages related to a query and generate a single, coherent text as a response. This output modality stands in stark contrast to traditional web search, where results are returned as a ranked list of independent web pages. In this paper, we ask: Along what dimensions do generative search outputs differ from traditional web search? We compare Google, a traditional web search engine, with four generative search engines from two providers (Google and OpenAI) across queries from four domains. Our analysis reveals intriguing differences. Most generative search engines cover a wider range of sources compared to web search. Generative search engines vary in the degree to which they rely on internal knowledge contained within the model parameters v.s. external knowledge retrieved from the web. Generative search engines surface varying sets of concepts, creating new opportunities for enhancing search diversity and serendipity. Our results also highlight the need for revisiting evaluation criteria for web search in the age of Generative AI. 

**Abstract (ZH)**: LLMs的兴起引发了新的网络搜索类型：生成式搜索，其中LLMs检索与查询相关的网页并生成一份连贯的文字回应。这种输出方式与传统网络搜索形成了鲜明对比，传统网络搜索返回的是按相关性排序的独立网页列表。本文探讨：生成式搜索输出与传统网络搜索在哪些维度上存在差异？我们将谷歌（一种传统网络搜索引擎）与来自两家提供商（谷歌和OpenAI）的四种生成式搜索引擎在四大领域的问题上进行对比分析。我们的分析揭示了一些有趣的差异。大多数生成式搜索引擎覆盖的来源比网络搜索更为广泛。生成式搜索引擎在依赖模型参数内的内部知识与从网络检索外部知识的程度上存在差异。生成式搜索引擎呈现不同的概念集合，创造了增强搜索多样性和偶然性的新机会。我们的研究结果还强调了在生成式AI时代重新审视网络搜索评估标准的必要性。 

---
# Query-Specific GNN: A Comprehensive Graph Representation Learning Method for Retrieval Augmented Generation 

**Title (ZH)**: 基于查询的GNN：一种用于检索增强生成的综合图表示学习方法 

**Authors**: Yuchen Yan, Zhihua Liu, Hao Wang, Weiming Li, Xiaoshuai Hao  

**Link**: [PDF](https://arxiv.org/pdf/2510.11541)  

**Abstract**: Retrieval-augmented generation (RAG) has demonstrated its ability to enhance Large Language Models (LLMs) by integrating external knowledge sources. However, multi-hop questions, which require the identification of multiple knowledge targets to form a synthesized answer, raise new challenges for RAG systems. Under the multi-hop settings, existing methods often struggle to fully understand the questions with complex semantic structures and are susceptible to irrelevant noise during the retrieval of multiple information targets. To address these limitations, we propose a novel graph representation learning framework for multi-hop question retrieval. We first introduce a Multi-information Level Knowledge Graph (Multi-L KG) to model various information levels for a more comprehensive understanding of multi-hop questions. Based on this, we design a Query-Specific Graph Neural Network (QSGNN) for representation learning on the Multi-L KG. QSGNN employs intra/inter-level message passing mechanisms, and in each message passing the information aggregation is guided by the query, which not only facilitates multi-granular information aggregation but also significantly reduces the impact of noise. To enhance its ability to learn robust representations, we further propose two synthesized data generation strategies for pre-training the QSGNN. Extensive experimental results demonstrate the effectiveness of our framework in multi-hop scenarios, especially in high-hop questions the improvement can reach 33.8\%. The code is available at: this https URL. 

**Abstract (ZH)**: 基于图表示学习的多跳问题检索新框架 

---
# CodeWatcher: IDE Telemetry Data Extraction Tool for Understanding Coding Interactions with LLMs 

**Title (ZH)**: CodeWatcher: IDE遥测数据提取工具，用于理解编码与LLM的交互 

**Authors**: Manaal Basha, Aimeê M. Ribeiro, Jeena Javahar, Cleidson R. B. de Souza, Gema Rodríguez-Pérez  

**Link**: [PDF](https://arxiv.org/pdf/2510.11536)  

**Abstract**: Understanding how developers interact with code generation tools (CGTs) requires detailed, real-time data on programming behavior which is often difficult to collect without disrupting workflow. We present \textit{CodeWatcher}, a lightweight, unobtrusive client-server system designed to capture fine-grained interaction events from within the Visual Studio Code (VS Code) editor. \textit{CodeWatcher} logs semantically meaningful events such as insertions made by CGTs, deletions, copy-paste actions, and focus shifts, enabling continuous monitoring of developer activity without modifying user workflows. The system comprises a VS Code plugin, a Python-based RESTful API, and a MongoDB backend, all containerized for scalability and ease of deployment. By structuring and timestamping each event, \textit{CodeWatcher} enables post-hoc reconstruction of coding sessions and facilitates rich behavioral analyses, including how and when CGTs are used during development. This infrastructure is crucial for supporting research on responsible AI, developer productivity, and the human-centered evaluation of CGTs. Please find the demo, diagrams, and tool here: this https URL. 

**Abstract (ZH)**: 理解开发者与代码生成工具（CGTs）的交互需要收集详细的实时编程行为数据，这通常在不干扰工作流程的情况下难以实现。我们介绍了一种轻量级且不具侵入性的客户端-服务器系统\textit{CodeWatcher}，该系统旨在在Visual Studio Code（VS Code）编辑器内捕获精细粒度的交互事件。\textit{CodeWatcher}记录诸如CGTs插入的代码、删除操作、复制粘贴行为以及焦点转移等具有语义意义的事件，从而实现对开发者活动的持续监控，而不修改用户的工作流程。该系统包括一个VS Code插件、一个基于Python的RESTful API以及一个MongoDB后端，所有组件均已容器化以实现可扩展性和部署便捷性。通过为每个事件结构化并标记时间戳，\textit{CodeWatcher}能够事后重建编码会话，并促进丰富的行为分析，包括开发者在开发过程中何时以及如何使用CGTs。该基础设施对于支持负责任的人工智能、开发者生产力以及CGTs的人本评估研究至关重要。请在此处查找演示、图表和工具：this https URL。 

---
# A Flexible Multi-Agent Deep Reinforcement Learning Framework for Dynamic Routing and Scheduling of Latency-Critical Services 

**Title (ZH)**: 一种用于低延迟关键服务动态路由和调度的灵活多agent深度强化学习框架 

**Authors**: Vincenzo Norman Vitale, Antonia Maria Tulino, Andreas F. Molisch, Jaime Llorca  

**Link**: [PDF](https://arxiv.org/pdf/2510.11535)  

**Abstract**: Timely delivery of delay-sensitive information over dynamic, heterogeneous networks is increasingly essential for a range of interactive applications, such as industrial automation, self-driving vehicles, and augmented reality. However, most existing network control solutions target only average delay performance, falling short of providing strict End-to-End (E2E) peak latency guarantees. This paper addresses the challenge of reliably delivering packets within application-imposed deadlines by leveraging recent advancements in Multi-Agent Deep Reinforcement Learning (MA-DRL). After introducing the Delay-Constrained Maximum-Throughput (DCMT) dynamic network control problem, and highlighting the limitations of current solutions, we present a novel MA-DRL network control framework that leverages a centralized routing and distributed scheduling architecture. The proposed framework leverages critical networking domain knowledge for the design of effective MA-DRL strategies based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) technique, where centralized routing and distributed scheduling agents dynamically assign paths and schedule packet transmissions according to packet lifetimes, thereby maximizing on-time packet delivery. The generality of the proposed framework allows integrating both data-driven \blue{Deep Reinforcement Learning (DRL)} agents and traditional rule-based policies in order to strike the right balance between performance and learning complexity. Our results confirm the superiority of the proposed framework with respect to traditional stochastic optimization-based approaches and provide key insights into the role and interplay between data-driven DRL agents and new rule-based policies for both efficient and high-performance control of latency-critical services. 

**Abstract (ZH)**: 及时交付敏感延迟信息在动态异构网络中的可靠传输对于工业自动化、自动驾驶车辆和增强现实等交互应用日益重要。然而，现有的大多数网络控制解决方案仅专注于平均延迟性能，未能提供严格的端到端（E2E）峰延迟保证。本文通过利用多智能体深度强化学习（MA-DRL）的最新进展，解决了在应用限定时间内可靠传输数据包的挑战。在介绍延迟受限最大吞吐量（DCMT）动态网络控制问题及其现有解决方案的局限性后，我们提出了一种利用集中式路由和分布式调度架构的新型MA-DRL网络控制框架。该框架基于多智能体深度确定性策略梯度（MADDPG）技术，结合关键的网络领域知识，设计有效的MA-DRL策略，通过动态分配路径和调度数据包传输，根据数据包的生命周期最大化按时传输数据包。该框架的通用性使其能够结合数据驱动的深度强化学习（DRL）代理和传统基于规则的策略，以平衡性能和学习复杂度。我们的实验结果证实了该框架优于传统的基于随机优化的方法，并提供了关于数据驱动的DRL代理和新规则基础策略在时延关键服务高效高性能控制中的角色和互动的关键见解。 

---
# Cracking CodeWhisperer: Analyzing Developers' Interactions and Patterns During Programming Tasks 

**Title (ZH)**: 破解CodeWhisperer：分析开发者在编程任务中互动和模式 

**Authors**: Jeena Javahar, Tanya Budhrani, Manaal Basha, Cleidson R. B. de Souza, Ivan Beschastnikh, Gema Rodriguez-Perez  

**Link**: [PDF](https://arxiv.org/pdf/2510.11516)  

**Abstract**: The use of AI code-generation tools is becoming increasingly common, making it important to understand how software developers are adopting these tools. In this study, we investigate how developers engage with Amazon's CodeWhisperer, an LLM-based code-generation tool. We conducted two user studies with two groups of 10 participants each, interacting with CodeWhisperer - the first to understand which interactions were critical to capture and the second to collect low-level interaction data using a custom telemetry plugin. Our mixed-methods analysis identified four behavioral patterns: 1) incremental code refinement, 2) explicit instruction using natural language comments, 3) baseline structuring with model suggestions, and 4) integrative use with external sources. We provide a comprehensive analysis of these patterns . 

**Abstract (ZH)**: AI代码生成工具的使用日益常见，理解软件开发者如何采用这些工具变得尤为重要。本研究调查开发者如何与Amazon的CodeWhisperer（一个基于LLM的代码生成工具）互动。我们开展了两项用户研究，每项研究包含10名参与者，以了解哪些互动至关重要，并使用自定义遥测插件收集低层次的互动数据。我们的混合方法分析识别出四种行为模式：1）渐进式的代码精炼，2）使用自然语言注释的明确指令，3）基于模型建议的基本结构化，以及4）与外部资源的整合使用。我们提供了这些模式的全面分析。 

---
# LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference 

**Title (ZH)**: LikePhys: 通过概率偏好评估视频扩散模型中的直观物理理解 

**Authors**: Jianhao Yuan, Fabio Pizzati, Francesco Pinto, Lars Kunze, Ivan Laptev, Paul Newman, Philip Torr, Daniele De Martini  

**Link**: [PDF](https://arxiv.org/pdf/2510.11512)  

**Abstract**: Intuitive physics understanding in video diffusion models plays an essential role in building general-purpose physically plausible world simulators, yet accurately evaluating such capacity remains a challenging task due to the difficulty in disentangling physics correctness from visual appearance in generation. To the end, we introduce LikePhys, a training-free method that evaluates intuitive physics in video diffusion models by distinguishing physically valid and impossible videos using the denoising objective as an ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By testing on our constructed benchmark of twelve scenarios spanning over four physics domains, we show that our evaluation metric, Plausibility Preference Error (PPE), demonstrates strong alignment with human preference, outperforming state-of-the-art evaluator baselines. We then systematically benchmark intuitive physics understanding in current video diffusion models. Our study further analyses how model design and inference settings affect intuitive physics understanding and highlights domain-specific capacity variations across physical laws. Empirical results show that, despite current models struggling with complex and chaotic dynamics, there is a clear trend of improvement in physics understanding as model capacity and inference settings scale. 

**Abstract (ZH)**: 无 Fairfax, 一种用于评估视频扩散模型直观物理理解的无需训练方法：通过使用基于ELBO的似然代理区分有效和无效视频以评估视频扩散模型中的直观物理理解 

---
# Automatic Music Sample Identification with Multi-Track Contrastive Learning 

**Title (ZH)**: 多音轨对比学习的自动音乐样本识别 

**Authors**: Alain Riou, Joan Serrà, Yuki Mitsufuji  

**Link**: [PDF](https://arxiv.org/pdf/2510.11507)  

**Abstract**: Sampling, the technique of reusing pieces of existing audio tracks to create new music content, is a very common practice in modern music production. In this paper, we tackle the challenging task of automatic sample identification, that is, detecting such sampled content and retrieving the material from which it originates. To do so, we adopt a self-supervised learning approach that leverages a multi-track dataset to create positive pairs of artificial mixes, and design a novel contrastive learning objective. We show that such method significantly outperforms previous state-of-the-art baselines, that is robust to various genres, and that scales well when increasing the number of noise songs in the reference database. In addition, we extensively analyze the contribution of the different components of our training pipeline and highlight, in particular, the need for high-quality separated stems for this task. 

**Abstract (ZH)**: 自动采样识别：一种基于自监督学习的方法及其应用分析 

---
# People use fast, flat goal-directed simulation to reason about novel problems 

**Title (ZH)**: 人们使用快速、平坦的目标导向模拟来推理解决新型问题。 

**Authors**: Katherine M. Collins, Cedegao E. Zhang, Lionel Wong, Mauricio Barba da Costa, Graham Todd, Adrian Weller, Samuel J. Cheyette, Thomas L. Griffiths, Joshua B. Tenenbaum  

**Link**: [PDF](https://arxiv.org/pdf/2510.11503)  

**Abstract**: Games have long been a microcosm for studying planning and reasoning in both natural and artificial intelligence, especially with a focus on expert-level or even super-human play. But real life also pushes human intelligence along a different frontier, requiring people to flexibly navigate decision-making problems that they have never thought about before. Here, we use novice gameplay to study how people make decisions and form judgments in new problem settings. We show that people are systematic and adaptively rational in how they play a game for the first time, or evaluate a game (e.g., how fair or how fun it is likely to be) before they have played it even once. We explain these capacities via a computational cognitive model that we call the "Intuitive Gamer". The model is based on mechanisms of fast and flat (depth-limited) goal-directed probabilistic simulation--analogous to those used in Monte Carlo tree-search models of expert game-play, but scaled down to use very few stochastic samples, simple goal heuristics for evaluating actions, and no deep search. In a series of large-scale behavioral studies with over 1000 participants and 121 two-player strategic board games (almost all novel to our participants), our model quantitatively captures human judgments and decisions varying the amount and kind of experience people have with a game--from no experience at all ("just thinking"), to a single round of play, to indirect experience watching another person and predicting how they should play--and does so significantly better than much more compute-intensive expert-level models. More broadly, our work offers new insights into how people rapidly evaluate, act, and make suggestions when encountering novel problems, and could inform the design of more flexible and human-like AI systems that can determine not just how to solve new tasks, but whether a task is worth thinking about at all. 

**Abstract (ZH)**: 游戏_long久以来都是研究自然智能和人工智能规划与推理的一个微观世界，特别是在专家级甚至超人级游戏方面。但在现实生活中，人类智能也沿着不同的前沿推进，要求人们灵活地解决前所未有的决策问题。在这里，我们使用新手玩家的游戏行为来研究人们在新问题设置中如何做出决策和形成判断。我们展示了人们在第一次玩游戏或在根本没有玩过的情况下评估游戏（例如，游戏可能有多公平、多有趣）时，表现出系统性和适应性的理性。我们通过一个被称为“直觉玩家”的计算认知模型来解释这些能力。该模型基于快速和平坦（深度受限）的目标导向概率模拟机制——类似于用于专家级游戏模拟的蒙特卡洛树搜索模型中的机制，但缩小规模以使用极少的随机样本、简单的动作目标启发式评估以及不进行深层次搜索。在涉及超过1000名参与者和121款两人制策略棋盘游戏（几乎所有游戏对参与者而言都是全新的）的一系列大规模行为研究中，我们的模型定量捕捉了人们在不同经验和类型的游戏情况下的人类判断和决策，并显著优于更耗费计算资源的专家级模型。更广泛地说，我们的工作为理解人们在遇到新问题时如何快速评估、行动和提供建议提供了新的见解，并可指导设计更具灵活性和人性化的AI系统，这些系统不仅能确定如何解决新任务，还能判断一个任务是否值得思考。 

---
# Offline Reinforcement Learning with Generative Trajectory Policies 

**Title (ZH)**: 基于生成轨迹策略的离线强化学习 

**Authors**: Xinsong Feng, Leshu Tang, Chenan Wang, Haipeng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.11499)  

**Abstract**: Generative models have emerged as a powerful class of policies for offline reinforcement learning (RL) due to their ability to capture complex, multi-modal behaviors. However, existing methods face a stark trade-off: slow, iterative models like diffusion policies are computationally expensive, while fast, single-step models like consistency policies often suffer from degraded performance. In this paper, we demonstrate that it is possible to bridge this gap. The key to moving beyond the limitations of individual methods, we argue, lies in a unifying perspective that views modern generative models, including diffusion, flow matching, and consistency models, as specific instances of learning a continuous-time generative trajectory governed by an Ordinary Differential Equation (ODE). This principled foundation provides a clearer design space for generative policies in RL and allows us to propose Generative Trajectory Policies (GTPs), a new and more general policy paradigm that learns the entire solution map of the underlying ODE. To make this paradigm practical for offline RL, we further introduce two key theoretically principled adaptations. Empirical results demonstrate that GTP achieves state-of-the-art performance on D4RL benchmarks - it significantly outperforms prior generative policies, achieving perfect scores on several notoriously hard AntMaze tasks. 

**Abstract (ZH)**: 生成模型由于能够捕获复杂、多模态行为，已在离线 reinforcement learning 中 emerged 为一个强大的政策类别。然而，现有的方法面临着一个明显的权衡：迭代且计算成本高昂的扩散策略与其他单步且性能退化的一致性策略之间。在本文中，我们展示了一种超越这些限制的可能性。我们认为超越单一方法限制的关键在于一个统一的观点，即现代生成模型，包括扩散模型、流匹配模型和一致性模型，都是由常微分方程 (ODE) 治律的连续时间生成轨迹的具体实例。这个原则性的基础为生成策略在 RL 中的设计空间提供了更清晰的指导，并使我们能够提出生成轨迹策略（GTPs），这是一种新的更通用的策略范式，学习底层 ODE 的整个解映射。为了使这种范式在离线下能够实用，我们进一步介绍了两个重要的理论原则性改版。实验结果表明，GTP 在 D4RL 基准测试中达到了最先进的性能——它显著优于先前的生成策略，在多个 notorious 的 AntMaze 任务中获得了满分。 

---
# AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model 

**Title (ZH)**: 安第斯VL技术报告：高效移动端多模态大语言模型 

**Authors**: Zhiwei Jin, Xiaohui Song, Nan Wang, Yafei Liu, Chao Li, Xin Li, Ruichen Wang, Zhihao Li, Qi Qi, Long Cheng, Dongze Hao, Quanlong Zheng, Yanhao Zhang, Haobo Ji, Jian Ma, Zhitong Zheng, Zhenyi Lin, Haolin Deng, Xin Zou, Xiaojie Yin, Ruilin Wang, Liankai Cai, Haijing Liu, Yuqing Qiu, Ke Chen, Zixian Li, Chi Xie, Huafei Li, Chenxing Li, Chuangchuang Wang, Kai Tang, Zhiguang Zhu, Kai Tang, Wenmei Gao, Rui Wang, Jun Wu, Chao Liu, Qin Xie, Chen Chen, Haonan Lu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11496)  

**Abstract**: In recent years, while cloud-based MLLMs such as QwenVL, InternVL, GPT-4o, Gemini, and Claude Sonnet have demonstrated outstanding performance with enormous model sizes reaching hundreds of billions of parameters, they significantly surpass the limitations in memory, power consumption, and computing capacity of edge devices such as mobile phones. This paper introduces AndesVL, a suite of mobile-side MLLMs with 0.6B to 4B parameters based on Qwen3's LLM and various visual encoders. We comprehensively outline the model architectures, training pipeline, and training data of AndesVL, which achieves first-tier performance across a wide range of open-source benchmarks, including fields such as text-rich image understanding, reasoning and math, multi-image comprehension, general VQA, hallucination mitigation, multilingual understanding, and GUI-related tasks when compared with state-of-the-art models of a similar scale. Furthermore, we introduce a 1+N LoR 

**Abstract (ZH)**: 近年来，云-based MLLMs如QwenVL、InternVL、GPT-4o、Gemini和Claude Sonnet凭借数百亿参数的巨大模型规模展现了出色表现，但显著超越了如移动电话等边缘设备在内存、功耗和计算能力上的限制。本文介绍了一套基于Qwen3的LLM和多种视觉编码器的移动侧MLLMs AndesVL，参数范围从0.6B到4B。我们详细介绍了AndesVL的模型架构、训练流水线和训练数据，该模型在包括图文理解、推理和数学、多图理解、通用VQA、幻觉缓解、多语言理解和与GUI相关的任务在内的多种开源基准测试中达到了顶级性能，与类似规模的先进模型相比。此外，我们还介绍了1+N LoR。 

---
# Investigating Large Language Models' Linguistic Abilities for Text Preprocessing 

**Title (ZH)**: 探究大型语言模型在文本预处理中的语言能力 

**Authors**: Marco Braga, Gian Carlo Milanese, Gabriella Pasi  

**Link**: [PDF](https://arxiv.org/pdf/2510.11482)  

**Abstract**: Text preprocessing is a fundamental component of Natural Language Processing, involving techniques such as stopword removal, stemming, and lemmatization to prepare text as input for further processing and analysis. Despite the context-dependent nature of the above techniques, traditional methods usually ignore contextual information. In this paper, we investigate the idea of using Large Language Models (LLMs) to perform various preprocessing tasks, due to their ability to take context into account without requiring extensive language-specific annotated resources. Through a comprehensive evaluation on web-sourced data, we compare LLM-based preprocessing (specifically stopword removal, lemmatization and stemming) to traditional algorithms across multiple text classification tasks in six European languages. Our analysis indicates that LLMs are capable of replicating traditional stopword removal, lemmatization, and stemming methods with accuracies reaching 97%, 82%, and 74%, respectively. Additionally, we show that ML algorithms trained on texts preprocessed by LLMs achieve an improvement of up to 6% with respect to the $F_1$ measure compared to traditional techniques. Our code, prompts, and results are publicly available at this https URL. 

**Abstract (ZH)**: 大规模语言模型在自然语言处理中的文本预处理应用：基于上下文的停用词移除、词形还原和词干提取方法的研究 

---
# Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning 

**Title (ZH)**: 现实空战中的层次化多代理强化学习协调策略 

**Authors**: Ardian Selmonaj, Giacomo Del Rio, Adrian Schneider, Alessandro Antonucci  

**Link**: [PDF](https://arxiv.org/pdf/2510.11474)  

**Abstract**: Achieving mission objectives in a realistic simulation of aerial combat is highly challenging due to imperfect situational awareness and nonlinear flight dynamics. In this work, we introduce a novel 3D multi-agent air combat environment and a Hierarchical Multi-Agent Reinforcement Learning framework to tackle these challenges. Our approach combines heterogeneous agent dynamics, curriculum learning, league-play, and a newly adapted training algorithm. To this end, the decision-making process is organized into two abstraction levels: low-level policies learn precise control maneuvers, while high-level policies issue tactical commands based on mission objectives. Empirical results show that our hierarchical approach improves both learning efficiency and combat performance in complex dogfight scenarios. 

**Abstract (ZH)**: 在现实化的空中 combat 模拟中实现任务目标由于情景认知不完善和非线性飞行动力学而极具挑战性。本文我们介绍了一种新型的 3D 多代理空中 combat 环境和分层多代理强化学习框架以应对这些挑战。我们的方法结合了异质代理动力学、课程学习、联赛训练以及一种新适应的训练算法。为此，决策过程组织为两个抽象层次：低层次策略学习精确的控制机动，而高层次策略基于任务目标发布战术命令。实验证明，我们的分层方法在复杂的狗斗场景中提高了学习效率和 combat 性能。 

---
# Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers 

**Title (ZH)**: 迭代摊还推理：融合上下文学习和学习优化器 

**Authors**: Sarthak Mittal, Divyat Mahajan, Guillaume Lajoie, Mohammad Pezeshki  

**Link**: [PDF](https://arxiv.org/pdf/2510.11471)  

**Abstract**: Modern learning systems increasingly rely on amortized learning - the idea of reusing computation or inductive biases shared across tasks to enable rapid generalization to novel problems. This principle spans a range of approaches, including meta-learning, in-context learning, prompt tuning, learned optimizers and more. While motivated by similar goals, these approaches differ in how they encode and leverage task-specific information, often provided as in-context examples. In this work, we propose a unified framework which describes how such methods differ primarily in the aspects of learning they amortize - such as initializations, learned updates, or predictive mappings - and how they incorporate task data at inference. We introduce a taxonomy that categorizes amortized models into parametric, implicit, and explicit regimes, based on whether task adaptation is externalized, internalized, or jointly modeled. Building on this view, we identify a key limitation in current approaches: most methods struggle to scale to large datasets because their capacity to process task data at inference (e.g., context length) is often limited. To address this, we propose iterative amortized inference, a class of models that refine solutions step-by-step over mini-batches, drawing inspiration from stochastic optimization. Our formulation bridges optimization-based meta-learning with forward-pass amortization in models like LLMs, offering a scalable and extensible foundation for general-purpose task adaptation. 

**Abstract (ZH)**: 现代学习系统越来越多地依赖于均一化学习——通过在任务间重用共享的计算或归纳偏差来快速泛化到新型问题。这一原则涵盖了多种方法，包括元学习、上下文学习、提示调优、学习优化器等。尽管这些方法的动机相似，但在如何编码和利用任务特定信息方面有所不同，这些信息通常以上下文示例的形式提供。在本文中，我们提出了一种统一框架，该框架描述了这些方法在均一化学习方面的主要差异——如初始化、学习更新或预测映射——以及它们如何在推理过程中整合任务数据。我们引入了一种分类法，根据任务适应是外部化、内部化还是联合建模，将均一化模型划分为参数化、隐式和显式三种模式。基于这一视角，我们识别出当前方法的一个关键局限性：大多数方法难以扩展到大型数据集，因为它们在推理过程中处理任务数据的能力（例如，上下文长度）往往受限。为此，我们提出了迭代均一化推理，这是一种模型类别，在批处理中逐步优化解决方案，受到随机优化的启发。我们的建模框架将基于优化的元学习与像大规模语言模型（LLMs）这样的模型中的前向传递均一化相结合，提供了通用任务适应的可扩展和可扩展的基础。 

---
# Audio-Maestro: Enhancing Large Audio-Language Models with Tool-Augmented Reasoning 

**Title (ZH)**: 音频大师：通过工具增强推理提升大型音频语言模型 

**Authors**: Kuan-Yi Lee, Tsung-En Lin, Hung-Yi Lee  

**Link**: [PDF](https://arxiv.org/pdf/2510.11454)  

**Abstract**: Recent advancements in large multimodal models (LMMs) have shown strong capabilities in audio understanding. However, most systems rely solely on end-to-end reasoning, limiting interpretability and accuracy for tasks that require structured knowledge or specialized signal analysis. In this work, we present Audio-Maestro -- a tool-augmented audio reasoning framework that enables audio-language models to autonomously call external tools and integrate their timestamped outputs into the reasoning process. This design allows the model to analyze, transform, and interpret audio signals through specialized tools rather than relying solely on end-to-end inference. Experiments show that Audio-Maestro consistently improves general audio reasoning performance: Gemini-2.5-flash's average accuracy on MMAU-Test rises from 67.4% to 72.1%, DeSTA-2.5 from 58.3% to 62.8%, and GPT-4o from 60.8% to 63.9%. To our knowledge, Audio-Maestro is the first framework to integrate structured tool output into the large audio language model reasoning process. 

**Abstract (ZH)**: Recent advancements in大型多模态模型（LMMs）在音频理解方面展示了强大的能力。然而，大多数系统仅依赖端到端推理，限制了在需要结构化知识或专门信号分析的任务中的可解释性和准确性。在这项工作中，我们介绍了Audio-Maestro——一个工具增强的音频推理框架，使音频语言模型能够自主调用外部工具并将它们的时间戳输出集成到推理过程中。这一设计使模型能够通过专门的工具来分析、转换和解释音频信号，而不仅仅是依赖端到端推理。实验显示，Audio-Maestro一致地提高了通用音频推理性能：Gemini-2.5-flash在MMAU-Test上的平均准确率从67.4%提升到72.1%，DeSTA-2.5从58.3%提升到62.8%，GPT-4o从60.8%提升到63.9%。据我们所知，Audio-Maestro是第一个将结构化工具输出集成到大型音频语言模型推理过程中的框架。 

---
# Reconstructing 12-Lead ECG from 3-Lead ECG using Variational Autoencoder to Improve Cardiac Disease Detection of Wearable ECG Devices 

**Title (ZH)**: 使用变分自编码器从3导联ECG重构12导联ECG以改善可穿戴ECG设备的心脏疾病检测 

**Authors**: Xinyan Guan, Yongfan Lai, Jiarui Jin, Jun Li, Haoyu Wang, Qinghao Zhao, Deyun Zhang, Shijia Geng, Shenda Hong  

**Link**: [PDF](https://arxiv.org/pdf/2510.11442)  

**Abstract**: Twelve-lead electrocardiograms (ECGs) are the clinical gold standard for cardiac diagnosis, providing comprehensive spatial coverage of the heart necessary to detect conditions such as myocardial infarction (MI). However, their lack of portability limits continuous and large-scale use. Three-lead ECG systems are widely used in wearable devices due to their simplicity and mobility, but they often fail to capture pathologies in unmeasured regions. To address this, we propose WearECG, a Variational Autoencoder (VAE) method that reconstructs twelve-lead ECGs from three leads: II, V1, and V5. Our model includes architectural improvements to better capture temporal and spatial dependencies in ECG signals. We evaluate generation quality using MSE, MAE, and Frechet Inception Distance (FID), and assess clinical validity via a Turing test with expert cardiologists. To further validate diagnostic utility, we fine-tune ECGFounder, a large-scale pretrained ECG model, on a multi-label classification task involving over 40 cardiac conditions, including six different myocardial infarction locations, using both real and generated signals. Experiments on the MIMIC dataset show that our method produces physiologically realistic and diagnostically informative signals, with robust performance in downstream tasks. This work demonstrates the potential of generative modeling for ECG reconstruction and its implications for scalable, low-cost cardiac screening. 

**Abstract (ZH)**: 十二导联心电图（ECGs）是心脏病诊断的临床金标准，能提供必要的心脏全面空间覆盖，用于检测心肌梗死（MI）等状况。然而，其缺乏便携性限制了其连续和大规模使用。三导联ECG系统由于其简单性和便携性，在可穿戴设备中广泛使用，但往往无法捕捉未测量区域的病理状况。为解决这一问题，我们提出WearECG，这是一种基于变分自编码器（VAE）的方法，可以从三导联II、V1和V5重建十二导联ECGs。我们的模型包括架构改进，以更好地捕捉ECG信号中的时间和空间依赖性。我们使用均方误差（MSE）、平均绝对误差（MAE）和弗雷彻-丁格尔距离（FID）评估生成质量，并通过心脏病专家参与的图灵测试评估临床有效性。为进一步验证诊断用途，我们使用包括超过40种心脏状况的大规模预训练ECG模型ECGFounder，在涉及不同位置心肌梗死等任务中进行微调，使用真实和生成的心电图信号。MIMIC数据集上的实验结果显示，我们的方法生成的生理上现实且诊断上有用的心电图信号，在后续任务中表现出鲁棒性能。这项工作展示了生成模型在心电图重建中的潜在应用及其在可扩展、低成本心脏筛查中的意义。 

---
# KnowRL: Teaching Language Models to Know What They Know 

**Title (ZH)**: 知RL：教语言模型知道它知道什么 

**Authors**: Sahil Kale, Devendra Singh Dhami  

**Link**: [PDF](https://arxiv.org/pdf/2510.11407)  

**Abstract**: Truly reliable AI requires more than simply scaling up knowledge; it demands the ability to know what it knows and when it does not. Yet recent research shows that even the best LLMs misjudge their own competence in more than one in five cases, making any response born of such internal uncertainty impossible to fully trust. Inspired by self-improvement reinforcement learning techniques that require minimal data, we present a simple but powerful framework KnowRL that strengthens a model's internal understanding of its own feasibility boundaries, enabling safer and more responsible behaviour. Our framework combines two components: (i) introspection, where the model generates and classifies tasks it judges feasible or infeasible, and (ii) consensus-based rewarding, where stability of self-knowledge assessment is reinforced through internal agreement. By using internally generated data, this design strengthens consistency in self-knowledge and entirely avoids costly external supervision. In experiments on LLaMA-3.1-8B and Qwen-2.5-7B, KnowRL steadily improved self-knowledge, validated by both intrinsic self-consistency and extrinsic benchmarking. With nothing more than a small seed set and no external supervision, our method drove gains as high as 28% in accuracy and 12% in F1, outperforming baselines in just a few iterations. Our framework essentially unlocks the untapped capacity of LLMs to self-improve their knowledge awareness, opening the door to reliable, more accountable AI and safer deployment in critical applications. Owing to its simplicity and independence from external effort, we encourage applying this reliability-enhancing process to all future models. 

**Abstract (ZH)**: 真正可靠的AI不仅需要扩大知识规模，还需要能够知道自己知道什么以及不知道什么。然而，最近的研究显示，即使是最优秀的大型语言模型在超过五分之一的情况下也误判了自己的能力，使得基于这种内部不确定性的任何回应都难以完全信任。受仅需少量数据的自我提升强化学习技术的启发，我们提出了一种简单但强有力的方法KnowRL，增强模型对其可行性边界的内部理解，从而实现更安全和更负责任的行为。该框架结合了两个组件：(i) 反省，模型生成并分类其认为可行或不可行的任务，以及(ii) 共识基础的奖励，通过内部一致性的强化来巩固自我知识评估的稳定性。通过使用内部生成的数据，此设计增强了自我知识的一致性并完全避免了昂贵的外部监督。在对LLaMA-3.1-8B和Qwen-2.5-7B的实验中，KnowRL稳定地提升了自我知识，并通过内在一致性和外部基准测试得到了验证。仅通过一个小型种子集和无需外部监督，我们的方法在准确性上取得了高达28%的增益，在F1分数上取得了12%的增益，并在几次迭代中超越了基线方法。该框架实质上解锁了大型语言模型自我提升其知识意识的未开发潜力，为可靠、更负责的AI和在关键应用场景中的安全部署打开了大门。由于其简单性并独立于外部努力，我们鼓励将此增强可靠性的过程应用于所有未来的模型。 

---
# Living Off the LLM: How LLMs Will Change Adversary Tactics 

**Title (ZH)**: LLM为生：大语言模型如何改变对手策略 

**Authors**: Sean Oesch, Jack Hutchins, Luke Koch, Kevin Kurian  

**Link**: [PDF](https://arxiv.org/pdf/2510.11398)  

**Abstract**: In living off the land attacks, malicious actors use legitimate tools and processes already present on a system to avoid detection. In this paper, we explore how the on-device LLMs of the future will become a security concern as threat actors integrate LLMs into their living off the land attack pipeline and ways the security community may mitigate this threat. 

**Abstract (ZH)**: 在本地开采攻击中，恶意行为者利用系统中已存在的合法工具和过程以逃避检测。本文探讨了未来的设备上大语言模型将成为安全关注点的原因，即威胁行为者将大语言模型整合到其本地开采攻击管道中，并讨论了安全社区可能采取的缓解措施。 

---
# DocReward: A Document Reward Model for Structuring and Stylizing 

**Title (ZH)**: DocReward: 一种用于结构化和风格化的文档奖励模型 

**Authors**: Junpeng Liu, Yuzhong Zhao, Bowen Cao, Jiayu Ding, Yilin Jia, Tengchao Lv, Yupan Huang, Shaohan Huang, Nan Yang, Li Dong, Lei Cui, Tao Ge, Xun Wang, Huitian Jiao, Sun Mao, FNU Kartik, Si-Qing Chen, Wai Lam, Furu Wei  

**Link**: [PDF](https://arxiv.org/pdf/2510.11391)  

**Abstract**: Recent advances in agentic workflows have enabled the automation of tasks such as professional document generation. However, they primarily focus on textual quality, neglecting visual structure and style, which are crucial for readability and engagement. This gap arises mainly from the absence of suitable reward models to guide agentic workflows toward producing documents with stronger structural and stylistic quality. To address this, we propose DocReward, a document reward model that evaluates documents based on their structure and style. We construct a multi-domain dataset DocPair of 117K paired documents, covering 32 domains and 267 document types, each including a high- and low-professionalism document with identical content but different structure and style. This enables the model to evaluate professionalism comprehensively, and in a textual-quality-agnostic way. DocReward is trained using the Bradley-Terry loss to score documents, penalizing predictions that contradict the annotated ranking. To assess the performance of reward models, we create a test dataset containing document bundles ranked by well-educated human evaluators. Notably, DocReward outperforms GPT-4o and GPT-5 in accuracy by 30.6 and 19.4 percentage points, respectively, demonstrating its superiority over baselines. In an extrinsic evaluation of document generation, DocReward achieves a significantly higher win rate of 60.8%, compared to GPT-5's 37.7% win rate, demonstrating its utility in guiding generation agents toward producing human-preferred documents. 

**Abstract (ZH)**: 近期代理工作流的进展已使专业文档生成任务的自动化成为可能。然而，这些进展主要关注文本质量，而忽略了视觉结构和风格的重要性，后者对于提高可读性和吸引力至关重要。这一差距主要源于缺乏合适的奖励模型来引导代理工作流生产结构和风格更强的文档。为了解决这一问题，我们提出了DocReward，一种基于结构和风格评价文档的文档奖励模型。我们构建了一个包含117,000对文档的多领域数据集DocPair，涵盖了32个领域和267种文档类型，每种类型包括内容相同但结构和风格不同的高专业性和低专业性文档。这使得模型能够全面且不依赖于文本质量地评估专业性。DocReward 使用Bradley-Terry损失训练，通过惩罚与标注排名矛盾的预测来评分。为了评估奖励模型的性能，我们创建了一个由受过良好教育的人类评估者按质量排名的文档集合作为测试集。值得注意的是，DocReward 在准确率上分别超过了GPT-4o和GPT-5，高出30.6和19.4个百分点，证明了其优于基线模型的优势。在文档生成的外部评估中，DocReward 达到了60.8%的更高胜率，相比之下，GPT-5 的胜率为37.7%，这表明其在引导生成代理生产人类偏好的文档方面的实用性。 

---
# Medical Interpretability and Knowledge Maps of Large Language Models 

**Title (ZH)**: 大型语言模型的医疗可解释性和知识图谱 

**Authors**: Razvan Marinescu, Victoria-Elisabeth Gruber, Diego Fajardo  

**Link**: [PDF](https://arxiv.org/pdf/2510.11390)  

**Abstract**: We present a systematic study of medical-domain interpretability in Large Language Models (LLMs). We study how the LLMs both represent and process medical knowledge through four different interpretability techniques: (1) UMAP projections of intermediate activations, (2) gradient-based saliency with respect to the model weights, (3) layer lesioning/removal and (4) activation patching. We present knowledge maps of five LLMs which show, at a coarse-resolution, where knowledge about patient's ages, medical symptoms, diseases and drugs is stored in the models. In particular for Llama3.3-70B, we find that most medical knowledge is processed in the first half of the model's layers. In addition, we find several interesting phenomena: (i) age is often encoded in a non-linear and sometimes discontinuous manner at intermediate layers in the models, (ii) the disease progression representation is non-monotonic and circular at certain layers of the model, (iii) in Llama3.3-70B, drugs cluster better by medical specialty rather than mechanism of action, especially for Llama3.3-70B and (iv) Gemma3-27B and MedGemma-27B have activations that collapse at intermediate layers but recover by the final layers. These results can guide future research on fine-tuning, un-learning or de-biasing LLMs for medical tasks by suggesting at which layers in the model these techniques should be applied. 

**Abstract (ZH)**: 我们对大型语言模型在医学领域中的可解释性进行了系统研究。我们通过四种不同的可解释性技术研究了大型语言模型如何表示和处理医学知识：(1) 中间激活的UMAP投影，(2) 模型权重的梯度基可解释性，(3) 层面损毁/移除，(4) 激活修补。我们展示了五个大型语言模型的知识图谱，粗略展示了模型中关于患者年龄、医学症状、疾病和药物的知识存储位置。特别是对于Llama3.3-70B，我们发现大部分医学知识在模型的前半部分层中处理。此外，我们还发现了几个有趣的现象：(i) 年龄在模型中间层中经常以非线性和有时不连续的方式编码，(ii) 疾病进展表示在某些模型层中是非单调和循环的，(iii) 在Llama3.3-70B中，药物按医学专业而非作用机制聚类，尤其是在Llama3.3-70B中，(iv) Gemma3-27B和MedGemma-27B在中间层中激活收敛，在最终层中恢复。这些结果可以指导未来针对医疗任务的大型语言模型微调、遗忘或去偏见的研究，建议在模型的哪些层应用这些技术。 

---
# Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning 

**Title (ZH)**: 早期检测与减少记忆现象以实现领域适应和指令调优 

**Authors**: Dean L. Slack, Noura Al Moubayed  

**Link**: [PDF](https://arxiv.org/pdf/2510.11372)  

**Abstract**: Although large language models excel across many tasks, they can memorise training data and thereby expose private or copyrighted text. Most defences target the pre-training stage, leaving memorisation during fine-tuning, especially for domain adaptation and instruction tuning, poorly understood. We fine-tune Pythia, Llama3, and Mistral models spanning 1.4B-70B parameters on common evaluation datasets and track verbatim memorisation throughout training. We find that memorisation increases dramatically in the first few epochs, often significantly before either validation perplexity or evaluation performance is optimised. We use a simple but effective n-gram memorisation score which reliably precedes verbatim memorisation; using it as an early-stopping criterion mitigates memorisation with minimal performance loss. Further, we introduce an n-gram-aware loss regulariser and show that it reduces memorisation across all model families tested by up to 40% while minimising evaluation performance trade-offs when compared to an existing memorisation mitigation strategy. These results yield practical, scalable insights into memorisation dynamics during language model fine-tuning. 

**Abstract (ZH)**: 尽管大规模语言模型在许多任务上表现出色，但它们可能会 memorise 训练数据，从而暴露私人或受版权保护的文本。大多数防御措施针对预训练阶段，而微调过程中，尤其是领域适应和指令调优中的 memorisation 尚不清楚。我们对包括1.4B至70B参数的 Pythia、Llama3 和 Mistral 模型在常见评估数据集上进行微调，并在整个训练过程中跟踪逐字 memorisation。我们发现 memorisation 在前几轮 epoch 中显著增加，通常在验证 perplexity 或评估性能优化之前就已发生。我们使用一个简单但有效的 n-gram 记忆分數，它可靠地先于逐字 memorisation；将其用作早期停止标准可以最小化性能损失的同时缓解 memorisation。此外，我们引入了一个 n-gram 意识的损失正则化项，并表明与现有缓解 memorisation 的策略相比，它可以在不牺牲评估性能的情况下将 memorisation 减少最多 40%。这些结果提供了关于语言模型微调过程中 memorisation 动力学的实际且可扩展的洞见。 

---
# Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers 

**Title (ZH)**: 通过对齐训练和推断路由器稳定MoE强化学习 

**Authors**: Wenhan Ma, Hailin Zhang, Liang Zhao, Yifan Song, Yudong Wang, Zhifang Sui, Fuli Luo  

**Link**: [PDF](https://arxiv.org/pdf/2510.11370)  

**Abstract**: Reinforcement learning (RL) has emerged as a crucial approach for enhancing the capabilities of large language models. However, in Mixture-of-Experts (MoE) models, the routing mechanism often introduces instability, even leading to catastrophic RL training collapse. We analyze the training-inference consistency of MoE models and identify a notable discrepancy in routing behaviors between the two phases. Moreover, even under identical conditions, the routing framework can yield divergent expert selections across repeated forward passes. To address this foundational inconsistency, we propose Rollout Routing Replay (R3), a method that records routing distributions from the inference engine and replays them during training. R3 significantly reduces training-inference policy KL divergence and mitigates extreme discrepancies without compromising training speed. Extensive experiments on various settings confirm that R3 succeeds in stabilizing RL training, preventing collapse and outperforming methods such as GSPO and TIS. We believe this work can offer a new solution for stabilizing RL in MoE models. 

**Abstract (ZH)**: 强化学习（RL）已成为提升大规模语言模型能力的关键方法。然而，在专家混合（MoE）模型中，路由机制往往引入不稳定性，甚至导致RL训练崩溃。我们分析了MoE模型的训练-推理一致性，并发现两阶段之间存在显著的路由行为差异。此外，即使在相同的条件下，路由框架也可能在重复正向传递中产生不同的专家选择。为解决这一基础不一致性，我们提出了一种称为Rollout Routing Replay（R3）的方法，该方法记录推理引擎的路由分布，并在训练过程中回放这些分布。R3显著减少了训练-推理策略的KL散度，并缓解了极端差异，而不牺牲训练速度。在各种设置下的广泛实验验证了R3能够稳定RL训练，避免崩溃，并优于GSPO和TIS等方法。我们相信这项工作能够为MoE模型中的RL稳定提供新的解决方案。 

---
# LLM-Specific Utility: A New Perspective for Retrieval-Augmented Generation 

**Title (ZH)**: LLM特定用途价值：检索增强生成的一个新视角 

**Authors**: Hengran Zhang, Keping Bi, Jiafeng Guo, Jiaming Zhang, Shuaiqiang Wang, Dawei Yin, Xueqi Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.11358)  

**Abstract**: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge. While traditional retrieval focuses on relevance, RAG's effectiveness depends on the utility of retrieved passages, i.e., the usefulness in facilitating the generation of an accurate and comprehensive answer. Existing studies often treat utility as a generic attribute, ignoring the fact that different LLMs may benefit differently from the same passage due to variations in internal knowledge and comprehension ability. In this work, we introduce and systematically investigate the notion of LLM-specific utility. Through large-scale experiments across multiple datasets and LLMs, we demonstrate that human-annotated passages are not optimal for LLMs and that ground-truth utilitarian passages are not transferable across different LLMs. These findings highlight the necessity of adopting the LLM-specific utility in RAG research. Our findings indicate that some human-annotated passages are not ground-truth utilitarian passages for specific LLMs, partially due to the varying readability of queries and passages for LLMs, a tendency for which perplexity is a key metric. Based on these findings, we propose a benchmarking procedure for LLM-specific utility judgments. We evaluate existing utility judgment methods on six datasets and find that while verbalized methods using pseudo-answers perform robustly, LLMs struggle to assess utility effectively-failing to reject all passages for known queries and to select truly useful ones for unknown queries. 

**Abstract (ZH)**: 基于检索的生成（RAG）通过融入外部知识增强了大型语言模型（LLMs），其有效性取决于检索段落的实际用途，即在生成准确和全面答案方面的有用性。现有研究通常将实用性视为一个通用属性，而忽视了不同LLMs因内部知识和理解能力的差异而在相同段落上的受益程度可能不同。在本工作中，我们引入并系统研究了LLM特定的实用性概念。通过针对多个数据集和LLMs的大规模实验，我们证明了人类标注的段落并非所有LLMs的最优选择，而地真实用性段落不能在不同LLMs之间转移。这些发现强调了在RAG研究中采用LLM特定实用性的必要性。我们的发现表明，由于查询和段落对LLMs的可读性差异，一些人类标注的段落并不是特定LLMs的地真实用性段落，而困惑度是关键指标之一。基于这些发现，我们提出了一种评估LLM特定实用性判断的基准方法。我们对六组数据集上的现有实用性判断方法进行了评估，发现尽管使用伪答案的口头化方法表现稳健，但LLMs在评估实用性方面效果不佳，无法有效拒绝所有已知查询的段落，也无法为未知查询选择真正有用的段落。 

---
# Understanding the Generalization of Stochastic Gradient Adam in Learning Neural Networks 

**Title (ZH)**: 理解随机梯度Adam在学习神经网络中的泛化能力 

**Authors**: Xuan Tang, Han Zhang, Yuan Cao, Difan Zou  

**Link**: [PDF](https://arxiv.org/pdf/2510.11354)  

**Abstract**: Adam is a popular and widely used adaptive gradient method in deep learning, which has also received tremendous focus in theoretical research. However, most existing theoretical work primarily analyzes its full-batch version, which differs fundamentally from the stochastic variant used in practice. Unlike SGD, stochastic Adam does not converge to its full-batch counterpart even with infinitesimal learning rates. We present the first theoretical characterization of how batch size affects Adam's generalization, analyzing two-layer over-parameterized CNNs on image data. Our results reveal that while both Adam and AdamW with proper weight decay $\lambda$ converge to poor test error solutions, their mini-batch variants can achieve near-zero test error. We further prove Adam has a strictly smaller effective weight decay bound than AdamW, theoretically explaining why Adam requires more sensitive $\lambda$ tuning. Extensive experiments validate our findings, demonstrating the critical role of batch size and weight decay in Adam's generalization performance. 

**Abstract (ZH)**: Adam是一种在深度学习中受欢迎且广泛应用的自适应梯度方法，也受到了极大的理论研究关注。然而，现有的大多数理论工作主要分析的是其全批量版本，这在理论上与实践中常用的小批量版本存在本质差异。与SGD不同，小批量Adam即使在学习率趋近于零时也不会收敛到其全批量对应版本。我们首次对小批量对Adam泛化性能的影响进行了理论刻画，分析了小批量过参数化两层CNN在图像数据上的表现。我们的研究结果表明，尽管Adam和带有适当重量衰减$\lambda$的AdamW都会收敛到较差的测试误差解，但它们的小批量版本可以实现接近零的测试误差。我们进一步证明，Adam的有效的重量衰减边界严格小于AdamW，从理论上解释了为什么Adam需要更敏感的$\lambda$调优。大量实验验证了我们的发现，突显了小批量和重量衰减在Adam泛化性能中的关键作用。 

---
# Multi-View Graph Feature Propagation for Privacy Preservation and Feature Sparsity 

**Title (ZH)**: 多视角图特征传播以保护隐私和减少特征稀疏性 

**Authors**: Etzion Harari, Moshe Unger  

**Link**: [PDF](https://arxiv.org/pdf/2510.11347)  

**Abstract**: Graph Neural Networks (GNNs) have demonstrated remarkable success in node classification tasks over relational data, yet their effectiveness often depends on the availability of complete node features. In many real-world scenarios, however, feature matrices are highly sparse or contain sensitive information, leading to degraded performance and increased privacy risks. Furthermore, direct exposure of information can result in unintended data leakage, enabling adversaries to infer sensitive information. To address these challenges, we propose a novel Multi-view Feature Propagation (MFP) framework that enhances node classification under feature sparsity while promoting privacy preservation. MFP extends traditional Feature Propagation (FP) by dividing the available features into multiple Gaussian-noised views, each propagating information independently through the graph topology. The aggregated representations yield expressive and robust node embeddings. This framework is novel in two respects: it introduces a mechanism that improves robustness under extreme sparsity, and it provides a principled way to balance utility with privacy. Extensive experiments conducted on graph datasets demonstrate that MFP outperforms state-of-the-art baselines in node classification while substantially reducing privacy leakage. Moreover, our analysis demonstrates that propagated outputs serve as alternative imputations rather than reconstructions of the original features, preserving utility without compromising privacy. A comprehensive sensitivity analysis further confirms the stability and practical applicability of MFP across diverse scenarios. Overall, MFP provides an effective and privacy-aware framework for graph learning in domains characterized by missing or sensitive features. 

**Abstract (ZH)**: 多视图特征传播框架：在特征稀疏性下的节点分类与隐私保护 

---
# Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation 

**Title (ZH)**: 面向不确定性的ControlNet：借助合成图像生成弥合领域差距 

**Authors**: Joshua Niemeijer, Jan Ehrhardt, Heinz Handels, Hristina Uzunova  

**Link**: [PDF](https://arxiv.org/pdf/2510.11346)  

**Abstract**: Generative Models are a valuable tool for the controlled creation of high-quality image data. Controlled diffusion models like the ControlNet have allowed the creation of labeled distributions. Such synthetic datasets can augment the original training distribution when discriminative models, like semantic segmentation, are trained. However, this augmentation effect is limited since ControlNets tend to reproduce the original training distribution.
This work introduces a method to utilize data from unlabeled domains to train ControlNets by introducing the concept of uncertainty into the control mechanism. The uncertainty indicates that a given image was not part of the training distribution of a downstream task, e.g., segmentation. Thus, two types of control are engaged in the final network: an uncertainty control from an unlabeled dataset and a semantic control from the labeled dataset. The resulting ControlNet allows us to create annotated data with high uncertainty from the target domain, i.e., synthetic data from the unlabeled distribution with labels. In our scenario, we consider retinal OCTs, where typically high-quality Spectralis images are available with given ground truth segmentations, enabling the training of segmentation networks. The recent development in Home-OCT devices, however, yields retinal OCTs with lower quality and a large domain shift, such that out-of-the-pocket segmentation networks cannot be applied for this type of data. Synthesizing annotated images from the Home-OCT domain using the proposed approach closes this gap and leads to significantly improved segmentation results without adding any further supervision. The advantage of uncertainty-guidance becomes obvious when compared to style transfer: it enables arbitrary domain shifts without any strict learning of an image style. This is also demonstrated in a traffic scene experiment. 

**Abstract (ZH)**: 利用不确定性引导的数据增强方法训练ControlNet以生成带有高不确定性标注的数据 

---
# Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with Asynchrony 

**Title (ZH)**: 第二部分：ROLL Flash -- 加速RLVR和自主训练的异步方法 

**Authors**: Han Lu, Zichen Liu, Shaopan Xiong, Yancheng He, Wei Gao, Yanan Wu, Weixun Wang, Jiashun Liu, Yang Li, Haizhou Zhao, Ju Huang, Siran Yang, Xiaoyang Li, Yijia Luo, Zihe Liu, Ling Pan, Junchi Yan, Wei Wang, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.11345)  

**Abstract**: Synchronous Reinforcement Learning (RL) post-training has emerged as a crucial step for enhancing Large Language Models (LLMs) with diverse capabilities. However, many systems designed to accelerate RL post-training still suffer from low resource utilization and limited scalability. We present ROLL Flash, a system that extends ROLL with native support for asynchronous RL post-training. ROLL Flash is built upon two core design principles: fine-grained parallelism and rollout-train decoupling. Guided by these principles, ROLL Flash provides flexible programming interfaces that enable a fully asynchronous training architecture and support efficient rollout mechanisms, including queue scheduling and environment-level asynchronous execution. Through comprehensive theoretical analysis and extensive experiments, we demonstrate that ROLL Flash significantly improves resource utilization and scalability over synchronous RL post-training. ROLL Flash achieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using the same GPU budget as synchronous baselines. Furthermore, we implement several popular off-policy algorithms and verify that asynchronous training can achieve performance on par with synchronous training. 

**Abstract (ZH)**: 同步强化学习（RL）的后训练与大规模语言模型（LLMs）的增强：现有的系统仍面临资源利用率低和可扩展性有限的问题。ROLL Flash系统扩展了ROLL以支持原生异步RL后训练。ROLL Flash基于细粒度并行和回放-训练解耦两大核心设计理念，并提供了灵活的编程接口，支持完全异步训练架构和高效的回放机制，包括队列调度和环境级别异步执行。通过全面的理论分析和广泛的实验，我们证明ROLL Flash在资源利用率和可扩展性方面显著优于同步RL后训练。ROLL Flash在RLVR任务上实现了高达2.24倍的加速，在代理任务上实现了高达2.72倍的加速，同时使用相同的GPU预算作为同步基线。此外，我们实现了多种流行的off-policy算法，并验证了异步训练可以达到与同步训练相当的性能。 

---
# Event-Aware Prompt Learning for Dynamic Graphs 

**Title (ZH)**: 事件感知的动态图提示学习 

**Authors**: Xingtong Yu, Ruijuan Liang, Xinming Zhang, Yuan Fang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11339)  

**Abstract**: Real-world graph typically evolve via a series of events, modeling dynamic interactions between objects across various domains. For dynamic graph learning, dynamic graph neural networks (DGNNs) have emerged as popular solutions. Recently, prompt learning methods have been explored on dynamic graphs. However, existing methods generally focus on capturing the relationship between nodes and time, while overlooking the impact of historical events. In this paper, we propose EVP, an event-aware dynamic graph prompt learning framework that can serve as a plug-in to existing methods, enhancing their ability to leverage historical events knowledge. First, we extract a series of historical events for each node and introduce an event adaptation mechanism to align the fine-grained characteristics of these events with downstream tasks. Second, we propose an event aggregation mechanism to effectively integrate historical knowledge into node representations. Finally, we conduct extensive experiments on four public datasets to evaluate and analyze EVP. 

**Abstract (ZH)**: 事件感知的动态图提示学习框架（EVP） 

---
# Diffusion-Link: Diffusion Probabilistic Model for Bridging the Audio-Text Modality Gap 

**Title (ZH)**: 扩散链接：用于桥接音频-文本模态差距的扩散概率模型 

**Authors**: KiHyun Nam, Jongmin Choi, Hyeongkeun Lee, Jungwoo Heo, Joon Son Chung  

**Link**: [PDF](https://arxiv.org/pdf/2510.11330)  

**Abstract**: Contrastive audio-language pretraining yields powerful joint representations, yet a persistent audio-text modality gap limits the benefits of coupling multimodal encoders with large language models (LLMs). We present Diffusion-Link, a diffusion-based modality-bridging module that generatively maps audio embeddings into the text-embedding distribution. The module is trained at the output embedding from the frozen multimodal encoder and implemented as a lightweight network with three residual MLP blocks. To assess the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on Automatic Audio Captioning (AAC); to our knowledge, this is the first application of diffusion-based modality bridging to AAC. We report two results. (1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link reduces the modality gap the most among prior diffusion-based methods and shows a collective migration of audio embeddings toward the text distribution. (2) Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised captioning without external knowledge, with relative gains up to 52.5% and 7.5%, respectively. These findings show that closing the modality gap is pivotal for effective coupling between multimodal encoders and LLMs, and diffusion-based modality bridging offers a promising direction beyond knowledge-retrieval-centric designs. Code will be released upon acceptance this https URL 

**Abstract (ZH)**: 基于扩散的模态连接模块Diffusion-Link增强了多模态编码器-大规模语言模型耦合，但持续存在的音频-文本模态差距限制了其益处。我们提出Diffusion-Link，一种基于扩散的模态桥梁模块，生成性地将音频嵌入映射至文本嵌入分布。该模块在冻结的多模态编码器的输出嵌入处进行训练，并作为带有三个残差MLP块的轻量级网络实现。为了评估Diffusion-Link对多模态编码器-大规模语言模型耦合的影响，我们在自动音频描述(Automatic Audio Captioning, AAC)上进行了评估；据我们所知，这是首次将基于扩散的模态桥梁应用到AAC中。我们报告了两个结果。(1) 模态差距分析：根据相似性和几何标准，Diffusion-Link在先前的基于扩散的方法中减少模态差距最多，并显示出音频嵌入集体向文本分布迁移。(2) 下游AAC：将Diffusion-Link附加到相同的基本多模态大规模语言模型，在AudioCaps上实现了零样本和全监督描述的新最佳性能，分别提高了累计52.5%和7.5%。这些发现表明，缩小模态差距对于多模态编码器和大规模语言模型之间的有效耦合至关重要，基于扩散的模态桥梁提供了超越知识检索为中心的设计的一种有前途的方向。代码将在接受后发布：<https://>。 

---
# Do LLMs "Feel"? Emotion Circuits Discovery and Control 

**Title (ZH)**: LLM们“有感觉”吗？情绪电路发现与控制 

**Authors**: Chenxi Wang, Yixuan Zhang, Ruiji Yu, Yufei Zheng, Lang Gao, Zirui Song, Zixiang Xu, Gus Xia, Huishuai Zhang, Dongyan Zhao, Xiuying Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.11328)  

**Abstract**: As the demand for emotional intelligence in large language models (LLMs) grows, a key challenge lies in understanding the internal mechanisms that give rise to emotional expression and in controlling emotions in generated text. This study addresses three core questions: (1) Do LLMs contain context-agnostic mechanisms shaping emotional expression? (2) What form do these mechanisms take? (3) Can they be harnessed for universal emotion control? We first construct a controlled dataset, SEV (Scenario-Event with Valence), to elicit comparable internal states across emotions. Subsequently, we extract context-agnostic emotion directions that reveal consistent, cross-context encoding of emotion (Q1). We identify neurons and attention heads that locally implement emotional computation through analytical decomposition and causal analysis, and validate their causal roles via ablation and enhancement interventions. Next, we quantify each sublayer's causal influence on the model's final emotion representation and integrate the identified local components into coherent global emotion circuits that drive emotional expression (Q2). Directly modulating these circuits achieves 99.65% emotion-expression accuracy on the test set, surpassing prompting- and steering-based methods (Q3). To our knowledge, this is the first systematic study to uncover and validate emotion circuits in LLMs, offering new insights into interpretability and controllable emotional intelligence. 

**Abstract (ZH)**: 随着对大型语言模型中情绪 intelligence 的需求增长，一个关键挑战在于理解产生情绪表达的内部机制，并控制生成文本中的情绪。本研究回答了三个核心问题：（1）大型语言模型中是否存在情境无关的情绪表达机制？（2）这些机制表现为什么形式？（3）它们能否用于通用情绪控制？我们首先构建了一个受控数据集 SEV（情境-事件与价值），以引发情绪间的可比内部状态。随后，我们提取了情境无关的情绪方向，揭示了情绪在不同情境下的一致编码（Q1）。我们通过分析分解和因果分析识别了局部实施情绪计算的神经元和注意力头，并通过消融和增强干预验证了它们的因果作用。接着，我们量化了每一子层对模型最终情绪表示的因果影响，并将识别出的局部组件整合到驱动情绪表达的协同全局情绪电路中（Q2）。直接调节这些电路在测试集上实现了 99.65% 的情绪表达准确性，超过了基于提示和引导的方法（Q3）。据我们所知，这是首个系统研究和验证大型语言模型中情绪电路的研究，为解释能力和可控情绪智能提供了新的见解。 

---
# FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks 

**Title (ZH)**: FOSSIL：利用反馈优化亚优样本以提高模仿学习在实体视觉-语言任务中数据高效泛化的性能 

**Authors**: Sabrina McCallum, Amit Parekh, Alessandro Suglia  

**Link**: [PDF](https://arxiv.org/pdf/2510.11307)  

**Abstract**: Current approaches to embodied AI tend to learn policies from expert demonstrations. However, without a mechanism to evaluate the quality of demonstrated actions, they are limited to learning from optimal behaviour, or they risk replicating errors and inefficiencies. While reinforcement learning offers one alternative, the associated exploration typically results in sacrificing data efficiency. This work explores how agents trained with imitation learning can learn robust representations from both optimal and suboptimal demonstrations when given access to constructive language feedback as a means to contextualise different modes of behaviour. We directly provide language feedback embeddings as part of the input sequence into a Transformer-based policy, and optionally complement the traditional next action prediction objective with auxiliary self-supervised learning objectives for feedback prediction. We test our approach on a range of embodied Vision-and-Language tasks in our custom BabyAI-XGen environment and show significant improvements in agents' compositional generalisation abilities and robustness, suggesting that our data-efficient method allows models to successfully convert suboptimal behaviour into learning opportunities. Overall, our results suggest that language feedback is a competitive and intuitive alternative to intermediate scalar rewards for language-specified embodied tasks. 

**Abstract (ZH)**: 基于语言反馈的模仿学习在体态AI中的数据高效表示学习 

---
# When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models 

**Title (ZH)**: 监督训练何时见效？视觉语言模型时代的目标检测隐含经济探讨 

**Authors**: Samer Al-Hamadani  

**Link**: [PDF](https://arxiv.org/pdf/2510.11302)  

**Abstract**: Object detection systems have traditionally relied on supervised learning with manually annotated bounding boxes, achieving high accuracy at the cost of substantial annotation investment. The emergence of Vision-Language Models (VLMs) offers an alternative paradigm enabling zero-shot detection through natural language queries, eliminating annotation requirements but operating with reduced accuracy. This paper presents the first comprehensive cost-effectiveness analysis comparing supervised detection (YOLO) with zero-shot VLM inference (Gemini Flash 2.5). Through systematic evaluation on 1,000 stratified COCO images and 200 diverse product images spanning consumer electronics and rare categories, combined with detailed Total Cost of Ownership modeling, we establish quantitative break-even thresholds governing architecture selection. Our findings reveal that supervised YOLO achieves 91.2% accuracy versus 68.5% for zero-shot Gemini on standard categories, representing a 22.7 percentage point advantage that costs $10,800 in annotation for 100-category systems. However, this advantage justifies investment only beyond 55 million inferences, equivalent to 151,000 images daily for one year. Zero-shot Gemini demonstrates 52.3% accuracy on diverse product categories (ranging from highly web-prevalent consumer electronics at 75-85% to rare specialized equipment at 25-40%) where supervised YOLO achieves 0% due to architectural constraints preventing detection of untrained classes. Cost per Correct Detection analysis reveals substantially lower per-detection costs for Gemini ($0.00050 vs $0.143) at 100,000 inferences despite accuracy deficits. We develop decision frameworks demonstrating that optimal architecture selection depends critically on deployment volume, category stability, budget constraints, and accuracy requirements rather than purely technical performance metrics. 

**Abstract (ZH)**: 监督检测系统与零样本VLM推理的成本效益分析：以YOLO与Gemini Flash 2.5为例 

---
# Beyond touch-based HMI: Control your machines in natural language by utilizing large language models and OPC UA 

**Title (ZH)**: 超越基于触控的人机接口：通过利用大型语言模型和OPC UA控制设备 

**Authors**: Bernd Hofmann, Sven Kreitlein, Joerg Franke, Patrick Bruendl  

**Link**: [PDF](https://arxiv.org/pdf/2510.11300)  

**Abstract**: This paper proposes an agent-based approach toward a more natural interface between humans and machines. Large language models equipped with tools and the communication standard OPC UA are utilized to control machines in natural language. Instead of touch interaction, which is currently the state-of-the-art medium for interaction in operations, the proposed approach enables operators to talk or text with machines. This allows commands such as 'Please decrease the temperature by 20 % in machine 1 and set the motor speed to 5000 rpm in machine 2.' The large language model receives the user input and selects one of three predefined tools that connect to an OPC UA server and either change or read the value of a node. Afterwards, the result of the tool execution is passed back to the language model, which then provides a final response to the user. The approach is universally designed and can therefore be applied to any machine that supports the OPC UA standard. The large language model is neither fine-tuned nor requires training data, only the relevant machine credentials and a parameter dictionary are included within the system prompt. The approach is evaluated on a Siemens S7-1500 programmable logic controller with four machine parameters in a case study of fifty synthetically generated commands on five different models. The results demonstrate high success rate, with proprietary GPT 5 models achieving accuracies between 96.0 % and 98.0 %, and open-weight models reaching up to 90.0 %. The proposed approach of this empirical study contributes to advancing natural interaction in industrial human-machine interfaces. 

**Abstract (ZH)**: 基于代理的方法：实现人类与机器之间的更自然接口 

---
# LouisKV: Efficient KV Cache Retrieval for Long Input-Output Sequences 

**Title (ZH)**: LouisKV: 高效的键值对缓存检索用于长输入输出序列 

**Authors**: Wenbo Wu, Qingyi Si, Xiurui Pan, Ye Wang, Jie Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11292)  

**Abstract**: While Key-Value (KV) cache succeeds in reducing redundant computations in auto-regressive models, it introduces significant memory overhead, limiting its practical deployment in long-sequence scenarios. Existing KV retrieval methods mitigate this by dynamically retaining only a subset of KV entries on the GPU. However, they still suffer from notable efficiency and accuracy bottlenecks due to per-token retrieval and coarse-grained page-level KV management, especially in long-output reasoning scenarios. With the emergence of large reasoning models, efficiently handling such scenarios has become increasingly important. To address this issue, we present two key observations: (1) critical KVs exhibit strong temporal locality during decoding, and (2) these KVs exhibit distinct distribution patterns across the input prompt and generated output. Building on these observations, we propose LouisKV, an efficient KV cache retrieval framework designed for various long-sequence scenarios. Specifically, LouisKV introduces a semantic-aware retrieval strategy leveraging temporal locality to trigger retrieval only at semantic boundaries, drastically reducing computation and data transfer overhead. LouisKV also designs a decoupled, fine-grained management scheme that tailors differentiated strategies for input and output sequences to create retrieval units that better match the model's attention patterns, enabling precise identification of critical KVs. Furthermore, to boost efficiency, LouisKV incorporates several kernel-level optimizations, including custom Triton and CUDA kernels to accelerate the KV clustering and retrieval. Evaluations show that LouisKV achieves up to 4.7$\times$ speedup over state-of-the-art KV retrieval methods while maintaining near-lossless accuracy across diverse long-sequence tasks, including long-input short-output, short-input long-output, and long-input long-output scenarios. 

**Abstract (ZH)**: LouisKV：高效的关键值缓存检索框架 

---
# ENIGMA: The Geometry of Reasoning and Alignment in Large-Language Models 

**Title (ZH)**: ENIGMA: 推理与大型语言模型对齐的几何学 

**Authors**: Gareth Seneque, Lap-Hang Ho, Nafise Erfanian Saeedi, Jeffrey Molendijk, Ariel Kupermann, Tim Elson  

**Link**: [PDF](https://arxiv.org/pdf/2510.11278)  

**Abstract**: We present Entropic Mutual-Information Geometry Large-Language Model Alignment (ENIGMA), a novel approach to Large-Language Model (LLM) training that jointly improves reasoning, alignment and robustness by treating an organisation's policies/principles as directions to move on a model's information manifold. Our single-loop trainer combines Group-Relative Policy Optimisation (GRPO), an on-policy, critic-free RL method with Chain-of-Thought (CoT)-format only rewards; a Self-Supervised Alignment with Mutual Information (SAMI)-style symmetric InfoNCE auxiliary; and an entropic Sinkhorn optimal-transport regulariser on hidden-state distributions to bound geometry drift. We also introduce infoNCE metrics that specialise to a standard MI lower bound under matched negatives to measure how strongly a model's CoT encodes these policies. These metrics include a Sufficiency Index (SI) that enables the selection and creation of principles that maximise downstream performance prior to training. In our experiments using small (1B) LLMs, high-SI principles predict steadier training dynamics and improved benchmark performance over GRPO ablations. Our information-geometry analysis of trained models validates desirable structural change in the manifold. These results support our hypothesis that reasoning, alignment, and robustness are projections of a single informationgeometric objective, and that models trained using ENIGMA demonstrate principled reasoning without the use of a reward model, offering a path to trusted capability 

**Abstract (ZH)**: Entropic Mutual-Information Geometry Large-Language Model Alignment (ENIGMA): 一种通过将组织政策/原则视为模型信息流形上移动方向来同时改进推理、对齐和鲁棒性的新颖大语言模型训练方法 

---
# Towards Real-Time Fake News Detection under Evidence Scarcity 

**Title (ZH)**: 面向证据稀缺下的实时假新闻检测 

**Authors**: Guangyu Wei, Ke Han, Yueming Lyu, Yu Luo, Yue Jiang, Caifeng Shan, Nicu Sebe  

**Link**: [PDF](https://arxiv.org/pdf/2510.11277)  

**Abstract**: Fake news detection becomes particularly challenging in real-time scenarios, where emerging events often lack sufficient supporting evidence. Existing approaches often rely heavily on external evidence and therefore struggle to generalize under evidence scarcity. To address this issue, we propose Evaluation-Aware Selection of Experts (EASE), a novel framework for real-time fake news detection that dynamically adapts its decision-making process according to the assessed sufficiency of available evidence. EASE introduces a sequential evaluation mechanism comprising three independent perspectives: (1) Evidence-based evaluation, which assesses evidence and incorporates it into decision-making only when the evidence is sufficiently supportive; (2) Reasoning-based evaluation, which leverages the world knowledge of large language models (LLMs) and applies them only when their reliability is adequately established; and (3) Sentiment-based fallback, which integrates sentiment cues when neither evidence nor reasoning is reliable. To enhance the accuracy of evaluation processes, EASE employs instruction tuning with pseudo labels to guide each evaluator in justifying its perspective-specific knowledge through interpretable reasoning. Furthermore, the expert modules integrate the evaluators' justified assessments with the news content to enable evaluation-aware decision-making, thereby enhancing overall detection accuracy. Moreover, we introduce RealTimeNews-25, a new benchmark comprising recent news for evaluating model generalization on emerging news with limited evidence. Extensive experiments demonstrate that EASE not only achieves state-of-the-art performance across multiple benchmarks, but also significantly improves generalization to real-time news. The code and dataset are available: this https URL. 

**Abstract (ZH)**: 实时场景中虚假新闻检测尤其具有挑战性，其中新兴事件往往缺乏足够的支持证据。现有方法经常依赖外部证据，因此在证据稀缺的情况下难以泛化。为解决这一问题，我们提出了一种新的实时虚假新闻检测框架Evaluation-Aware Selection of Experts (EASE)，该框架根据可用证据的充分性动态调整其决策过程。EASE引入了一种序列评估机制，包括三个独立视角：（1）基于证据的评估，仅当证据足够支持时才评估证据并将其纳入决策；（2）基于推理的评估，利用大语言模型的世界知识并在其可靠性得到充分验证时使用；（3）基于情感的后备，当证据和推理均不可靠时将其纳入评估。为提高评估过程的准确性，EASE采用伪标签调优指令来引导每个评估者通过可解释的推理来证明其特定知识。此外，专家模块将评估者的合理评估与新闻内容结合起来，实现评估意识下的决策，从而提高整体检测准确性。此外，我们引入了RealTimeNews-25，这是一种新的基准数据集，包含近期新闻以评估模型在有限证据的新兴新闻场景下的泛化能力。大量实验表明，EASE不仅在多个基准测试中达到了最先进的性能，还在实时新闻泛化方面显著改进。代码和数据集可在以下链接获取：this https URL。 

---
# From Prompts to Packets: A View from the Network on ChatGPT, Copilot, and Gemini 

**Title (ZH)**: 从提示到包：网络视角下的ChatGPT、Copilot和Gemini 

**Authors**: Antonio Montieri, Alfredo Nascita, Antonio Pescapè  

**Link**: [PDF](https://arxiv.org/pdf/2510.11269)  

**Abstract**: Generative AI (GenAI) chatbots are now pervasive in digital ecosystems, yet their network traffic remains largely underexplored. This study presents an in-depth investigation of traffic generated by three leading chatbots (ChatGPT, Copilot, and Gemini) when accessed via Android mobile apps for both text and image generation. Using a dedicated capture architecture, we collect and label two complementary workloads: a 60-hour generic dataset with unconstrained prompts, and a controlled dataset built from identical prompts across GenAI apps and replicated via conventional messaging apps to enable one-to-one comparisons. This dual design allows us to address practical research questions on the distinctiveness of GenAI traffic, its differences from widely deployed traffic categories, and its novel implications for network usage. To this end, we provide fine-grained traffic characterization at trace, flow, and protocol levels, and model packet-sequence dynamics with Multimodal Markov Chains. Our analyses reveal app- and content-specific traffic patterns, particularly in volume, uplink/downlink profiles, and protocol adoption. We highlight the predominance of TLS, with Gemini extensively leveraging QUIC, ChatGPT exclusively using TLS 1.3, and app- and content-specific Server Name Indication (SNI) values. A payload-based occlusion analysis quantifies SNI's contribution to classification: masking it reduces F1-score by up to 20 percentage points in GenAI app traffic classification. Finally, compared with conventional messaging apps when carrying the same content, GenAI chatbots exhibit unique traffic characteristics, highlighting new stress factors for mobile networks, such as sustained upstream activity, with direct implications for network monitoring and management. We publicly release the datasets to support reproducibility and foster extensions to other use cases. 

**Abstract (ZH)**: Generative AI对话机器人如今已在数字生态系统中无处不在，但其网络流量仍 largely未被充分探索。本研究对通过 Android 移动应用程序访问的三款领先对话机器人（ChatGPT、Copilot 和 Gemini）进行文本和图像生成时产生的流量进行了深入调查。利用专用捕获架构，我们收集并标注了两个互补的工作负载：一个包含未加约束的提示的 60 小时通用数据集，以及一个基于 GenAI 应用程序中相同提示构建并使用常规消息应用程序复制以进行一对一比较的受控数据集。这种双设计使我们能够探讨生成式 AI 流量的独特性、其与广泛部署的流量类别的差异以及其对网络使用的新见解。为此，我们在轨迹、流和协议级别提供了详细的流量表征，并使用多模态马尔可夫链建模数据包序列动力学。我们的分析揭示了应用和内容特定的流量模式，特别是在流量volume、上行/下行配置文件和协议采用方面。我们强调了 TLS 的主导地位，其中 Gemini 广泛使用 QUIC，ChatGPT 仅使用 TLS 1.3，以及应用和内容特定的 Server Name Indication (SNI) 值。基于载荷的 occlusion 分析量化了 SNI 对分类的贡献：在生成式 AI 应用程序流量分类中，隐藏它会导致 F1 分数最多减少 20 个百分点。最后，与传输相同内容的常规消息应用程序相比，生成式 AI 对话机器人表现出独特的流量特征，突出了移动网络中新的压力因素，如持续的上行活动，这对网络监控和管理具有直接的含义。我们公开发布了数据集以支持可重复性并促进其他用例的发展。 

---
# A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images 

**Title (ZH)**: 大型语言模型辅助的自动放大比例尺检测与提取框架扫描电子显微镜图像 

**Authors**: Yuxuan Chen, Ruotong Yang, Zhengyang Zhang, Mehreen Ahmed, Yanming Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11260)  

**Abstract**: Microscopic characterizations, such as Scanning Electron Microscopy (SEM), are widely used in scientific research for visualizing and analyzing microstructures. Determining the scale bars is an important first step of accurate SEM analysis; however, currently, it mainly relies on manual operations, which is both time-consuming and prone to errors. To address this issue, we propose a multi-modal and automated scale bar detection and extraction framework that provides concurrent object detection, text detection and text recognition with a Large Language Model (LLM) agent. The proposed framework operates in four phases; i) Automatic Dataset Generation (Auto-DG) model to synthesize a diverse dataset of SEM images ensuring robust training and high generalizability of the model, ii) scale bar object detection, iii) information extraction using a hybrid Optical Character Recognition (OCR) system with DenseNet and Convolutional Recurrent Neural Network (CRNN) based algorithms, iv) an LLM agent to analyze and verify accuracy of the results. The proposed model demonstrates a strong performance in object detection and accurate localization with a precision of 100%, recall of 95.8%, and a mean Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95. The hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the Auto-DG dataset, significantly outperforming several mainstream standalone engines, highlighting its reliability for scientific image analysis. The LLM is introduced as a reasoning engine as well as an intelligent assistant that suggests follow-up steps and verifies the results. This automated method powered by an LLM agent significantly enhances the efficiency and accuracy of scale bar detection and extraction in SEM images, providing a valuable tool for microscopic analysis and advancing the field of scientific imaging. 

**Abstract (ZH)**: 多模态自动化显微尺检测与提取框架：从数据生成到结果验证 

---
# Large Language Models Are Effective Code Watermarkers 

**Title (ZH)**: 大规模语言模型是有效的代码水印器 

**Authors**: Rui Xu, Jiawei Chen, Zhaoxia Yin, Cong Kong, Xinpeng Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11251)  

**Abstract**: The widespread use of large language models (LLMs) and open-source code has raised ethical and security concerns regarding the distribution and attribution of source code, including unauthorized redistribution, license violations, and misuse of code for malicious purposes. Watermarking has emerged as a promising solution for source attribution, but existing techniques rely heavily on hand-crafted transformation rules, abstract syntax tree (AST) manipulation, or task-specific training, limiting their scalability and generality across languages. Moreover, their robustness against attacks remains limited. To address these limitations, we propose CodeMark-LLM, an LLM-driven watermarking framework that embeds watermark into source code without compromising its semantics or readability. CodeMark-LLM consists of two core components: (i) Semantically Consistent Embedding module that applies functionality-preserving transformations to encode watermark bits, and (ii) Differential Comparison Extraction module that identifies the applied transformations by comparing the original and watermarked code. Leveraging the cross-lingual generalization ability of LLM, CodeMark-LLM avoids language-specific engineering and training pipelines. Extensive experiments across diverse programming languages and attack scenarios demonstrate its robustness, effectiveness, and scalability. 

**Abstract (ZH)**: 大规模语言模型（LLM）和开源代码的广泛应用引发了关于源代码分发和归属的伦理与安全担忧，包括未经授权的重新分发、许可证违规以及代码的恶意使用。水印技术作为源代码归属的一种有前景的解决方案已经出现，但现有技术方法严重依赖手工编写的转换规则、抽象语法树（AST）操作或特定任务的训练，限制了其在多种语言间的可扩展性和通用性。此外，它们对抗攻击的鲁棒性仍然有限。为解决这些限制，我们提出CodeMark-LLM，这是一种以LLM为驱动的水印框架，能够在不牺牲代码语义和可读性的情况下嵌入水印。CodeMark-LLM包括两个核心模块：（i）语义一致嵌入模块，通过保持功能性的转换来编码水印位，以及（ii）差异对比提取模块，通过比较原始代码和水代码来识别已应用的转换。利用LLM的跨语言泛化能力，CodeMark-LLM避免了特定语言的工程和训练流程。广泛的语言和攻击场景下的实验表明其鲁棒性、有效性和可扩展性。 

---
# Nepali Sign Language Characters Recognition: Dataset Development and Deep Learning Approaches 

**Title (ZH)**: 尼泊尔手语字符识别：数据集开发与深度学习方法 

**Authors**: Birat Poudel, Satyam Ghimire, Sijan Bhattarai, Saurav Bhandari, Suramya Sharma Dahal  

**Link**: [PDF](https://arxiv.org/pdf/2510.11243)  

**Abstract**: Sign languages serve as essential communication systems for individuals with hearing and speech impairments. However, digital linguistic dataset resources for underrepresented sign languages, such as Nepali Sign Language (NSL), remain scarce. This study introduces the first benchmark dataset for NSL, consisting of 36 gesture classes with 1,500 samples per class, designed to capture the structural and visual features of the language. To evaluate recognition performance, we fine-tuned MobileNetV2 and ResNet50 architectures on the dataset, achieving classification accuracies of 90.45% and 88.78%, respectively. These findings demonstrate the effectiveness of convolutional neural networks in sign recognition tasks, particularly within low-resource settings. To the best of our knowledge, this work represents the first systematic effort to construct a benchmark dataset and assess deep learning approaches for NSL recognition, highlighting the potential of transfer learning and fine-tuning for advancing research in underexplored sign languages. 

**Abstract (ZH)**: 手语作为听力和言语障碍个体的重要沟通系统，发挥着关键作用。然而，包括尼泊尔手语（NSL）在内的未充分代表的手语数字语言数据集仍然稀缺。本研究介绍了首个NSL基准数据集，包含36个手势类别，每类别1500个样本，旨在捕捉该语言的结构和视觉特征。为评估识别性能，我们在数据集上微调了MobileNetV2和ResNet50架构，分别获得了90.45%和88.78%的分类准确率。这些发现证明了卷积神经网络在手语识别任务中的有效性，特别是在低资源环境中。据我们所知，本工作代表了首个系统地构建基准数据集并评估深度学习方法进行NSL识别的研究，突显了迁移学习和微调在推进未充分探索的手语研究中的潜力。 

---
# Attacks by Content: Automated Fact-checking is an AI Security Issue 

**Title (ZH)**: 内容攻击：自动化事实核查是AI安全问题 

**Authors**: Michael Schlichtkrull  

**Link**: [PDF](https://arxiv.org/pdf/2510.11238)  

**Abstract**: When AI agents retrieve and reason over external documents, adversaries can manipulate the data they receive to subvert their behaviour. Previous research has studied indirect prompt injection, where the attacker injects malicious instructions. We argue that injection of instructions is not necessary to manipulate agents - attackers could instead supply biased, misleading, or false information. We term this an attack by content. Existing defenses, which focus on detecting hidden commands, are ineffective against attacks by content. To defend themselves and their users, agents must critically evaluate retrieved information, corroborating claims with external evidence and evaluating source trustworthiness. We argue that this is analogous to an existing NLP task, automated fact-checking, which we propose to repurpose as a cognitive self-defense tool for agents. 

**Abstract (ZH)**: 当AI代理检索和推理外部文档时，对手可以通过操纵接收到的数据来颠覆其行为。以往的研究集中在间接提示注入上，攻击者在其中注入恶意指令。我们认为，注入指令并不是操纵代理所必需的——攻击者可以通过提供带有偏见、误导或虚假信息来实现目标。我们将这种攻击称为内容攻击。现有的防御措施专注于检测隐藏的命令，但对于内容攻击效果不佳。为了保护自身和用户，代理必须批判性地评估检索到的信息，通过外部证据 corroborate 声称，并评估信息源的可信度。我们认为，这类似于现有的NLP任务——自动化事实核查——我们建议将这一任务重新利用为代理的认知自我防御工具。 

---
# LightPneumoNet: Lightweight Pneumonia Classifier 

**Title (ZH)**: LightPneumoNet: 轻量级肺炎分类器 

**Authors**: Neilansh Chauhan, Piyush Kumar Gupta, Faraz Doja  

**Link**: [PDF](https://arxiv.org/pdf/2510.11232)  

**Abstract**: Effective pneumonia diagnosis is often challenged by the difficulty of deploying large, computationally expensive deep learning models in resource-limited settings. This study introduces LightPneumoNet, an efficient, lightweight convolutional neural network (CNN) built from scratch to provide an accessible and accurate diagnostic solution for pneumonia detection from chest X-rays. Our model was trained on a public dataset of 5,856 chest X-ray images. Preprocessing included image resizing to 224x224, grayscale conversion, and pixel normalization, with data augmentation (rotation, zoom, shear) to prevent overfitting. The custom architecture features four blocks of stacked convolutional layers and contains only 388,082 trainable parameters, resulting in a minimal 1.48 MB memory footprint. On the independent test set, our model delivered exceptional performance, achieving an overall accuracy of 0.942, precision of 0.92, and an F1-Score of 0.96. Critically, it obtained a sensitivity (recall) of 0.99, demonstrating a near-perfect ability to identify true pneumonia cases and minimize clinically significant false negatives. Notably, LightPneumoNet achieves this high recall on the same dataset where existing approaches typically require significantly heavier architectures or fail to reach comparable sensitivity levels. The model's efficiency enables deployment on low-cost hardware, making advanced computer-aided diagnosis accessible in underserved clinics and serving as a reliable second-opinion tool to improve patient outcomes. 

**Abstract (ZH)**: 轻量级肺部感染诊断网络：面向资源受限环境的高效卷积神经网络 

---
# Fairness Metric Design Exploration in Multi-Domain Moral Sentiment Classification using Transformer-Based Models 

**Title (ZH)**: 多域道德情感分类中基于Transformer模型的公平性指标设计探索 

**Authors**: Battemuulen Naranbat, Seyed Sahand Mohammadi Ziabari, Yousuf Nasser Al Husaini, Ali Mohammed Mansoor Alsahag  

**Link**: [PDF](https://arxiv.org/pdf/2510.11222)  

**Abstract**: Ensuring fairness in natural language processing for moral sentiment classification is challenging, particularly under cross-domain shifts where transformer models are increasingly deployed. Using the Moral Foundations Twitter Corpus (MFTC) and Moral Foundations Reddit Corpus (MFRC), this work evaluates BERT and DistilBERT in a multi-label setting with in-domain and cross-domain protocols. Aggregate performance can mask disparities: we observe pronounced asymmetry in transfer, with Twitter->Reddit degrading micro-F1 by 14.9% versus only 1.5% for Reddit->Twitter. Per-label analysis reveals fairness violations hidden by overall scores; notably, the authority label exhibits Demographic Parity Differences of 0.22-0.23 and Equalized Odds Differences of 0.40-0.41. To address this gap, we introduce the Moral Fairness Consistency (MFC) metric, which quantifies the cross-domain stability of moral foundation detection. MFC shows strong empirical validity, achieving a perfect negative correlation with Demographic Parity Difference (rho = -1.000, p < 0.001) while remaining independent of standard performance metrics. Across labels, loyalty demonstrates the highest consistency (MFC = 0.96) and authority the lowest (MFC = 0.78). These findings establish MFC as a complementary, diagnosis-oriented metric for fairness-aware evaluation of moral reasoning models, enabling more reliable deployment across heterogeneous linguistic contexts. . 

**Abstract (ZH)**: 确保自然语言处理在道德情感分类中的公平性尤其是在跨域转移时具有挑战性：基于Moral Foundations Twitter Corpus和Moral Foundations Reddit Corpus的BERT和DistilBERT多标签评估 

---
# The Curious Case of Factual (Mis)Alignment between LLMs' Short- and Long-Form Answers 

**Title (ZH)**: LLMs长短回答事实一致性问题探究 

**Authors**: Saad Obaid ul Islam, Anne Lauscher, Goran Glavaš  

**Link**: [PDF](https://arxiv.org/pdf/2510.11218)  

**Abstract**: Large language models (LLMs) can correctly answer "When was Einstein born?" yet fail to provide the same date when writing about Einstein's life revealing a fundamental inconsistency in how models access factual knowledge across task complexities. While models display impressive accuracy on factual question-answering benchmarks, the reliability gap between simple and complex queries remains poorly understood, eroding their trustworthiness. In this work, we introduce Short-Long Form Alignment for Factual Question Answering (SLAQ), a controlled evaluation framework that compares LLMs' answers to the same factual questions asked (a) in isolation (short) vs. (b) integrated into complex queries (long). Looking at 16 LLMs across 600 queries, we find a systematic misalignment of answers to the corresponding short and long queries. We further uncover position-dependent accuracy loss and momentum effects where consecutive correct or incorrect answers create self-reinforcing patterns. Through mechanistic analysis, we find that aligned facts activate overlapping model internals, and that metrics based on mechanistic similarity can predict short-long answer alignment with up to 78% accuracy. Our work establishes factual consistency over query complexity as an important aspect of LLMs' trustworthiness and challenges current evaluation practices, which implicitly assume that good performance for simple factual queries implies reliability in more complex knowledge-seeking tasks too. 

**Abstract (ZH)**: 大型语言模型在正确回答“爱因斯坦是什么时候出生的？”的同时，在描述爱因斯坦生平时未能提供相同的日期，揭示了模型在不同任务复杂性下访问事实知识的基本不一致性。尽管模型在事实性问答基准测试中表现令人印象深刻，但简单和复杂查询之间 reliablity 的差距仍然 poorly understood，侵蚀了其可信度。在本研究中，我们引入了基于短长形式对齐的事实性问答（SLAQ）可控评估框架，该框架将 LLMs 的答案与同一事实问题在（a）孤立（短） vs. （b）整合到复杂查询中的形式进行比较。通过对 16 种 LLMs 在 600 个查询中的分析，我们发现了答案在相应短查询和长查询之间系统性的对齐不一致。我们还发现了位置依赖性的准确性损失和动量效应，其中连续的正确或错误答案会形成自我强化的模式。通过机制分析，我们发现对齐的事实激活了重叠的模型内部组件，并且基于机制相似性的度量可以预测短长答案对齐的准确率最高可达 78%。我们的研究建立了事实一致性的保持在查询复杂性上的重要方面，并挑战了当前的评估实践，后者隐含地假设简单的事实性查询的良好表现也意味着在更复杂的知识搜索任务中具有可靠性。 

---
# Domain-Specific Data Generation Framework for RAG Adaptation 

**Title (ZH)**: 面向特定领域数据生成的RAG适应框架 

**Authors**: Chris Xing Tian, Weihao Xie, Zhen Chen, Zhengyuan Yi, Hui Liu, Haoliang Li, Shiqi Wang, Siwei Ma  

**Link**: [PDF](https://arxiv.org/pdf/2510.11217)  

**Abstract**: Retrieval-Augmented Generation (RAG) combines the language understanding and reasoning power of large language models (LLMs) with external retrieval to enable domain-grounded responses. Effectively adapting RAG systems to domain-specific settings requires specialized, context-rich training data beyond general-purpose question-answering. Here, we propose RAGen, a scalable and modular framework for generating domain-grounded question-answer-context (QAC) triples tailored to diverse RAG adaptation approaches. RAGen produces these QAC triples by identifying key concepts in documents, generating diverse questions guided by Bloom's Taxonomy-inspired principles, and pairing them with precise answers extracted from relevant contexts. RAGen supports multiple RAG adaptation strategies, including the optimization of key components such as the LLM, retriever, and embedding model, etc. Its modular pipeline features semantic chunking, hierarchical concept extraction, and multi-chunk retrieval, along with the introduction of curated distractor contexts to promote robust reasoning. Designed for scalability, RAGen efficiently handles large and evolving document corpora without redundant processing, making it especially suitable for dynamic evolving domains such as scientific research and enterprise knowledge bases. 

**Abstract (ZH)**: 基于检索的生成（RAG）结合了大规模语言模型（LLMs）的语义理解和推理能力以及外部检索，以实现领域相关的回应。为了有效适应特定领域的设置，RAG系统需要具有领域背景的训练数据，而不仅仅是针对通用问题回答的训练数据。在这里，我们提出RAGen框架，这是一个可扩展且模块化的生成领域相关的问答上下文（QAC）三元组的方法，旨在适应多样的RAG适应方法。RAGen通过识别文档中的关键概念，根据布卢姆分类法启发的原则生成多样化的提问，并结合相关上下文中提取的精确答案来生成这些QAC三元组。RAGen支持多种RAG适应策略，包括优化关键组件如LLM、检索器和嵌入模型等。其模块化管道包括语义切片、层次概念提取和多片段检索，并引入了精心策划的干扰上下文以促进稳健的推理。出于可扩展性考虑，RAGen有效地处理大量不断演变的文档库而不进行冗余处理，使其特别适合科学研究和企业知识库等动态演变领域。 

---
# RAG-Pull: Imperceptible Attacks on RAG Systems for Code Generation 

**Title (ZH)**: RAG-Pull: 不可感知的针对代码生成RAG系统的攻击 

**Authors**: Vasilije Stambolic, Aritra Dhar, Lukas Cavigelli  

**Link**: [PDF](https://arxiv.org/pdf/2510.11195)  

**Abstract**: Retrieval-Augmented Generation (RAG) increases the reliability and trustworthiness of the LLM response and reduces hallucination by eliminating the need for model retraining. It does so by adding external data into the LLM's context. We develop a new class of black-box attack, RAG-Pull, that inserts hidden UTF characters into queries or external code repositories, redirecting retrieval toward malicious code, thereby breaking the models' safety alignment. We observe that query and code perturbations alone can shift retrieval toward attacker-controlled snippets, while combined query-and-target perturbations achieve near-perfect success. Once retrieved, these snippets introduce exploitable vulnerabilities such as remote code execution and SQL injection. RAG-Pull's minimal perturbations can alter the model's safety alignment and increase preference towards unsafe code, therefore opening up a new class of attacks on LLMs. 

**Abstract (ZH)**: Retrieval-Augmented Generation (RAG)增强的检索生成提高了LLM响应的可靠性和可信度并减少了幻觉，通过消除模型重新训练的需要。它通过将外部数据加入LLM的上下文中实现这一目标。我们开发了一种新的黑盒攻击类别RAG-Pull，该攻击将隐藏的UTF字符插入查询或外部代码仓库中，引导检索指向恶意代码，从而破坏模型的安全对齐。我们观察到，仅查询和代码扰动就可以将检索引导至攻击者控制的片段，而结合查询和目标扰动则几乎可以实现完全的成功。一旦检索到这些片段，它们将引入可利用的漏洞，如远程代码执行和SQL注入。RAG-Pull的最小扰动可以改变模型的安全对齐，并增加对不安全代码的偏好，因此为LLM打开了一个新的攻击类别。 

---
# Protein as a Second Language for LLMs 

**Title (ZH)**: 蛋白质作为LLMs的第二种语言 

**Authors**: Xinhui Chen, Zuchao Li, Mengqi Gao, Yufeng Zhang, Chak Tou Leong, Haoyang Li, Jiaqi Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.11188)  

**Abstract**: Deciphering the function of unseen protein sequences is a fundamental challenge with broad scientific impact, yet most existing methods depend on task-specific adapters or large-scale supervised fine-tuning. We introduce the "Protein-as-Second-Language" framework, which reformulates amino-acid sequences as sentences in a novel symbolic language that large language models can interpret through contextual exemplars. Our approach adaptively constructs sequence-question-answer triples that reveal functional cues in a zero-shot setting, without any further training. To support this process, we curate a bilingual corpus of 79,926 protein-QA instances spanning attribute prediction, descriptive understanding, and extended reasoning. Empirically, our method delivers consistent gains across diverse open-source LLMs and GPT-4, achieving up to 17.2% ROUGE-L improvement (average +7%) and even surpassing fine-tuned protein-specific language models. These results highlight that generic LLMs, when guided with protein-as-language cues, can outperform domain-specialized models, offering a scalable pathway for protein understanding in foundation models. 

**Abstract (ZH)**: 解析 unseen 蛋白质序列的功能是一项具有广泛科学影响的基本挑战，但大多数现有方法依赖于任务特定的适配器或大规模监督微调。“蛋白质作为第二语言”框架将氨基酸序列重新形式化为一种新的符号语言的句子，并通过上下文例证供大规模语言模型解释。我们的方法在零样本设置下自适应构建序列-问题-答案 triple，揭示功能性线索，无需进一步训练。为此，我们编 curated 了一个包含 79,926 个蛋白质-QA 实例的双语语料库，涵盖属性预测、描述性理解以及扩展推理。实验证明，我们的方法在多种开源 LLM 和 GPT-4 上表现出一致的性能提升，ROUGE-L 提高最高达 17.2%（平均提高 7%），甚至超越了蛋白质特定的微调语言模型。这些结果表明，当用蛋白质作为语言的线索加以引导时，通用的大规模语言模型可以在基础模型中实现对专门领域的模型的超越，提供了一种可扩展的蛋白质理解途径。 

---
# Generalisation of automatic tumour segmentation in histopathological whole-slide images across multiple cancer types 

**Title (ZH)**: 跨多种癌症类型Histopathological全切片图像中自动肿瘤分割的泛化研究 

**Authors**: Ole-Johan Skrede, Manohar Pradhan, Maria Xepapadakis Isaksen, Tarjei Sveinsgjerd Hveem, Ljiljana Vlatkovic, Arild Nesbakken, Kristina Lindemann, Gunnar B Kristensen, Jenneke Kasius, Alain G Zeimet, Odd Terje Brustugun, Lill-Tove Rasmussen Busund, Elin H Richardsen, Erik Skaaheim Haug, Bjørn Brennhovd, Emma Rewcastle, Melinda Lillesand, Vebjørn Kvikstad, Emiel Janssen, David J Kerr, Knut Liestøl, Fritz Albregtsen, Andreas Kleppe  

**Link**: [PDF](https://arxiv.org/pdf/2510.11182)  

**Abstract**: Deep learning is expected to aid pathologists by automating tasks such as tumour segmentation. We aimed to develop one universal tumour segmentation model for histopathological images and examine its performance in different cancer types. The model was developed using over 20 000 whole-slide images from over 4 000 patients with colorectal, endometrial, lung, or prostate carcinoma. Performance was validated in pre-planned analyses on external cohorts with over 3 000 patients across six cancer types. Exploratory analyses included over 1 500 additional patients from The Cancer Genome Atlas. Average Dice coefficient was over 80% in all validation cohorts with en bloc resection specimens and in The Cancer Genome Atlas cohorts. No loss of performance was observed when comparing the universal model with models specialised on single cancer types. In conclusion, extensive and rigorous evaluations demonstrate that generic tumour segmentation by a single model is possible across cancer types, patient populations, sample preparations, and slide scanners. 

**Abstract (ZH)**: 深度学习有望通过自动化如肿瘤分割等任务来辅助病理学家。我们旨在开发一个统一的肿瘤分割模型以应用于组织病理图像，并考察其在不同癌症类型中的性能表现。该模型使用了来自4000多名患者（包括结直肠癌、子宫内膜癌、肺癌和前列腺癌）的超过20,000张全切片图像进行开发。性能在外部多癌种队列中进行了预设分析验证，涵盖超过3,000名患者的六种癌症类型。探索性分析还包括来自The Cancer Genome Atlas的1,500多名额外患者。所有验证队列（包括整块切除标本和The Cancer Genome Atlas队列）的平均Dice系数超过80%。与专门针对单一癌症类型的模型相比，通用模型未观察到性能下降。总之，广泛的严格评估表明，单一模型在不同癌症类型、患者群体、样本制备和切片扫描仪中实现通用肿瘤分割是可行的。 

---
# G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation 

**Title (ZH)**: G2L:从 gigascale 到癌症特异性大规模病理基础模型的知识蒸馏 

**Authors**: Yesung Cho, Sungmin Lee, Geongyu Lee, Minkyung Lee, Jongbae Park, Dongmyung Shin  

**Link**: [PDF](https://arxiv.org/pdf/2510.11176)  

**Abstract**: Recent studies in pathology foundation models have shown that scaling training data, diversifying cancer types, and increasing model size consistently improve their performance. However, giga-scale foundation models, which are trained on hundreds of thousands of slides covering tens of cancer types and contain billions of parameters, pose significant challenges for practical use due to their tremendous computational costs in both development and deployment. In this work, we present a novel strategy, named the G2L framework, to increase the performance of large-scale foundation models, which consist of only $15\%$ of the parameters of giga-scale models, to a comparable performance level of giga-scale models in cancer-specific tasks. Our approach applies knowledge distillation, transferring the capabilities of a giga-scale model to a large-scale model, using just 1K pathology slides of a target cancer (e.g., breast, prostate, etc.). The resulting distilled model not only outperformed state-of-the-art models of the same size (i.e., large-scale) across several benchmarks but also, interestingly, surpassed the giga-scale teacher and huge-scale models in some benchmarks. In addition, the distilled model exhibited a higher robustness index, indicating improved resilience to image variations originating from multiple institutions. These findings suggest that the proposed distillation approach for a large-scale model is a data- and parameter-efficient way to achieve giga-scale-level performance for cancer-specific applications without prohibitive computational burden. 

**Abstract (ZH)**: 近期病理基础模型的研究表明，扩展训练数据、多样化癌症类型和增加模型规模能够一致地提高其性能。然而，由数百数千张病理切片覆盖数十种癌症类型、包含数十亿参数的巨型规模基础模型由于其巨大的开发和部署计算成本，给实际应用带来了显著挑战。本文提出了一种新的策略，即G2L框架，该策略能够将仅包含巨型规模模型15%参数量的大规模基础模型在癌症特异性任务中的性能提升至与巨型规模模型媲美的水平。我们的方法通过知识蒸馏，仅使用目标癌症（如乳腺癌、前列腺癌等）的1000张病理切片，将巨型规模模型的能力转移到大规模模型上。蒸馏模型不仅在多个基准测试中超越了相同规模（即大规模）的最先进的模型，而且在某些基准测试中甚至超过了巨型规模教师模型和超大规模模型。此外，蒸馏模型还展示了更高的鲁棒性指数，表明其对来自多个机构的图像变异具有更强的抗御能力。这些发现表明，提出的对大规模模型的知识蒸馏方法是一种在不带来巨大的计算负担的情况下，以数据和参数高效的方式实现巨型规模性能水平的方法，适用于癌症特异性应用。 

---
# EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling 

**Title (ZH)**: EAGER: 熵意识的生成模型以适应推理时扩展需求 

**Authors**: Daniel Scalena, Leonidas Zotos, Elisabetta Fersini, Malvina Nissim, Ahmet Üstün  

**Link**: [PDF](https://arxiv.org/pdf/2510.11170)  

**Abstract**: With the rise of reasoning language models and test-time scaling methods as a paradigm for improving model performance, substantial computation is often required to generate multiple candidate sequences from the same prompt. This enables exploration of different reasoning paths toward the correct solution, however, allocates the same compute budget for each prompt. Grounded on the assumption that different prompts carry different degrees of complexity, and thus different computation needs, we propose EAGer, a training-free generation method that leverages model uncertainty through token-wise entropy distribution to reduce redundant computation and concurrently improve overall performance. EAGer allows branching to multiple reasoning paths only in the presence of high-entropy tokens, and then reallocates the saved compute budget to the instances where exploration of alternative paths is most needed. We find that across multiple open-source models on complex reasoning benchmarks such as AIME 2025, EAGer can reallocate the budget without accessing target labels, achieving the best efficiency-performance trade-off in terms of reasoning length and Pass@k. When target labels are accessible, EAGer generates up to 65% fewer tokens (hence saving compute) and achieves up to 37% improvement in Pass@k compared to the Full Parallel Sampling. 

**Abstract (ZH)**: 基于熵分布的无需训练生成方法EAGer：在复杂推理基准上的计算预算重新分配 

---
# One Size Does Not Fit All: Exploring Variable Thresholds for Distance-Based Multi-Label Text Classification 

**Title (ZH)**: 一场不变：探索基于距离的多标签文本分类的变异性阈值 

**Authors**: Jens Van Nooten, Andriy Kosar, Guy De Pauw, Walter Daelemans  

**Link**: [PDF](https://arxiv.org/pdf/2510.11160)  

**Abstract**: Distance-based unsupervised text classification is a method within text classification that leverages the semantic similarity between a label and a text to determine label relevance. This method provides numerous benefits, including fast inference and adaptability to expanding label sets, as opposed to zero-shot, few-shot, and fine-tuned neural networks that require re-training in such cases. In multi-label distance-based classification and information retrieval algorithms, thresholds are required to determine whether a text instance is "similar" to a label or query. Similarity between a text and label is determined in a dense embedding space, usually generated by state-of-the-art sentence encoders. Multi-label classification complicates matters, as a text instance can have multiple true labels, unlike in multi-class or binary classification, where each instance is assigned only one label. We expand upon previous literature on this underexplored topic by thoroughly examining and evaluating the ability of sentence encoders to perform distance-based classification. First, we perform an exploratory study to verify whether the semantic relationships between texts and labels vary across models, datasets, and label sets by conducting experiments on a diverse collection of realistic multi-label text classification (MLTC) datasets. We find that similarity distributions show statistically significant differences across models, datasets and even label sets. We propose a novel method for optimizing label-specific thresholds using a validation set. Our label-specific thresholding method achieves an average improvement of 46% over normalized 0.5 thresholding and outperforms uniform thresholding approaches from previous work by an average of 14%. Additionally, the method demonstrates strong performance even with limited labeled examples. 

**Abstract (ZH)**: 基于距离的无监督文本分类是一种文本分类方法，它通过利用标签与文本之间的语义相似度来确定标签的相关性。该方法提供了诸多好处，包括快速推理和对扩展标签集的高度适应性，而零样本、少样本和细调的神经网络在这些情况下需要重新训练。在多标签距离基于分类和信息检索算法中，需要设置阈值来确定文本实例是否与标签或查询“相似”。文本与标签之间的相似性通常在密集嵌入空间中确定，通常由最先进的句子编码器生成。多标签分类使情况更加复杂，因为一个文本实例可以有多个真实标签，而在多类或二分类中，每个实例仅被分配一个标签。我们通过详细研究和评估句子编码器在距离基于分类中的能力，扩展了对该未充分研究主题的先前文献。首先，我们进行一项探索性研究，通过在一系列现实多标签文本分类（MLTC）数据集上进行实验，验证文本与标签之间的语义关系是否随模型、数据集和标签集的变化而变化。我们发现相似性分布显示出统计上的显著差异，不仅在模型之间，甚至在标签集之间也是如此。我们提出了一种使用验证集优化标签特定阈值的新方法。我们的标签特定阈值方法在平均上比归一化的0.5阈值提高了46%的性能，并且在以往工作中的均匀阈值方法的基础上平均提高了14%的表现。此外，即使在有限的带标签示例情况下，该方法仍然表现出较强的性能。 

---
# video-SALMONN S: Streaming Audio-Visual LLMs Beyond Length Limits via Memory 

**Title (ZH)**: 视频-SALMONN S：超越长度限制的流式音视频LLMs记忆方法 

**Authors**: Guangzhi Sun, Yixuan Li, Xiaodong Wu, Yudong Yang, Wei Li, Zejun Ma, Chao Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11129)  

**Abstract**: Continuous, high-frame-rate, high-resolution processing of long video streams is critical for future AI agents, yet current video-understanding LLMs struggle to scale. Offline, fixed-frame-number methods require the stream length to adapt frame rates; streaming methods constrain memory by merging or discarding tokens, losing information. We propose video-SALMONN S, a streaming audio-visual LLM that, to our knowledge, is the first to process 3-hour videos at 1 FPS and 360p resolution under a fixed memory budget. Our model introduces (i) a test-time-training (TTT) memory module that continually updates token representations to capture long-range dependencies by replacing token merging, and (ii) a prompt-dependent memory reader that selectively retrieves context-relevant content from fixed-size memory. The TTT module is optimised with a Hessian-free conjugate-gradient procedure (TTT_HF) for efficient adaptation. On long-video benchmarks (Video-MME, LVBench, VideoEvalPro), video-SALMONN S sustains high-quality understanding on multi-hour videos with 10k frames and 1M tokens. Our 8B-parameter model achieves 74.2% overall and 67.8% on the Video-MME long split, outperforming both offline and streaming baselines. 

**Abstract (ZH)**: 视频-SALMONN S：在固定内存预算下处理长达3小时的视频流 

---
# PhysioME: A Robust Multimodal Self-Supervised Framework for Physiological Signals with Missing Modalities 

**Title (ZH)**: PhysioME：一种 robust 的多模态自监督框架，用于处理缺失模态的生理信号 

**Authors**: Cheol-Hui Lee, Hwa-Yeon Lee, Min-Kyung Jung, Dong-Joo Kim  

**Link**: [PDF](https://arxiv.org/pdf/2510.11110)  

**Abstract**: Missing or corrupted modalities are common in physiological signal-based medical applications owing to hardware constraints or motion artifacts. However, most existing methods assume the availability of all modalities, resulting in substantial performance degradation in the absence of any modality. To overcome this limitation, this study proposes PhysioME, a robust framework designed to ensure reliable performance under missing modality conditions. PhysioME adopts: (1) a multimodal self-supervised learning approach that combines contrastive learning with masked prediction; (2) a Dual-PathNeuroNet backbone tailored to capture the temporal dynamics of each physiological signal modality; and (3) a restoration decoder that reconstructs missing modality tokens, enabling flexible processing of incomplete inputs. The experimental results show that PhysioME achieves high consistency and generalization performance across various missing modality scenarios. These findings highlight the potential of PhysioME as a reliable tool for supporting clinical decision-making in real-world settings with imperfect data availability. 

**Abstract (ZH)**: 生理信号驱动的医疗应用中由于硬件限制或运动伪影常会出现模态缺失或损坏。然而，现有大多数方法假设所有模态均可用，导致在缺少任何模态时性能大幅下降。为克服这一局限，本研究提出PhysioME，一种稳健框架，旨在在模态缺失条件下确保可靠性能。PhysioME采用：(1) 结合对比学习与掩蔽预测的多模态自监督学习方法；(2) 专门设计以捕捉每种生理信号模态时序动态的Dual-PathNeuroNet主干；以及(3) 一种重建解码器，能够重建缺失模态令牌，使 incomplete 输入的灵活处理成为可能。实验结果表明，PhysioME 在各种模态缺失场景中实现了高一致性和泛化性能。这些发现突显了PhysioME作为在数据可用性不完美的实际环境中支持临床决策的可靠工具的潜力。 

---
# A Vision for Access Control in LLM-based Agent Systems 

**Title (ZH)**: 基于大语言模型的代理系统访问控制愿景 

**Authors**: Xinfeng Li, Dong Huang, Jie Li, Hongyi Cai, Zhenhong Zhou, Wei Dong, XiaoFeng Wang, Yang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11108)  

**Abstract**: The autonomy and contextual complexity of LLM-based agents render traditional access control (AC) mechanisms insufficient. Static, rule-based systems designed for predictable environments are fundamentally ill-equipped to manage the dynamic information flows inherent in agentic interactions. This position paper argues for a paradigm shift from binary access control to a more sophisticated model of information governance, positing that the core challenge is not merely about permission, but about governing the flow of information. We introduce Agent Access Control (AAC), a novel framework that reframes AC as a dynamic, context-aware process of information flow governance. AAC operates on two core modules: (1) multi-dimensional contextual evaluation, which assesses not just identity but also relationships, scenarios, and norms; and (2) adaptive response formulation, which moves beyond simple allow/deny decisions to shape information through redaction, summarization, and paraphrasing. This vision, powered by a dedicated AC reasoning engine, aims to bridge the gap between human-like nuanced judgment and scalable Al safety, proposing a new conceptual lens for future research in trustworthy agent design. 

**Abstract (ZH)**: 基于LLM的代理的自主性和情境复杂性使传统访问控制机制不足。静态的基于规则的系统无法应对预测性环境，而适用于动态信息流的治理则是核心挑战。本文提出了从二元访问控制向更先进的信息治理模式转变的观点，介绍了代理访问控制（AAC）框架，将其视为动态的情境感知信息流动治理过程。AAC基于两个核心模块：多维度的情境评估和适应性响应形成。这一愿景通过专门的访问控制推理引擎，旨在弥合类似人类细致判断与可扩展的AI安全性之间的差距，为未来可信赖代理设计的研究提供新的概念框架。 

---
# Enhancing LLM Reasoning via Non-Human-Like Reasoning Path Preference Optimization 

**Title (ZH)**: 通过非人类似推理路径偏好优化增强LLM推理能力 

**Authors**: Junjie Lu, Yuliang Liu, Chaofeng Qu, Wei Shen, Zhouhan Lin, Min Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11104)  

**Abstract**: Current approaches for strengthening LLM reasoning tend to introduce a training bias toward human-like reasoning trajectories. In step-wise preference optimization, in particular, dependence on human or higher-capacity model annotations for intermediate steps limits exploration of alternative, non-human-like reasoning paths and thus constrains achievable performance. Furthermore, through a small-scale pilot study, we observed that in approximately 75% of cases, the model's first erroneous step occurs after the lowest-confidence point. This suggests that guiding the model at its lowest-confidence point before an error provides more accurate supervision than locating the first explicit error. In this paper, we propose Confidence-Guided Reasoning Path Preference Optimization (CGPO), a method that leverages a confidence signal to identify points of maximal uncertainty in the model's reasoning process and applies self-generated, non-human-like reasoning-path guidance to mitigate trajectory drift. Our experiments span diverse models applied to both code and mathematical reasoning tasks. The results show that, with the same amount of training data, our method using data generated by a small model can achieve better performance in most cases compared with approaches using data generated by a strong model or human-annotated. 

**Abstract (ZH)**: 基于信心引导的推理路径偏好优化（CGPO）：一种利用信心信号识别模型推理过程中的最大不确定性并应用非人类like推理路径指导以减轻路径偏移的方法 

---
# A Primer on SO(3) Action Representations in Deep Reinforcement Learning 

**Title (ZH)**: SO(3) 行动表示在深度强化学习中的入门介绍 

**Authors**: Martin Schuck, Sherif Samy, Angela P. Schoellig  

**Link**: [PDF](https://arxiv.org/pdf/2510.11103)  

**Abstract**: Many robotic control tasks require policies to act on orientations, yet the geometry of SO(3) makes this nontrivial. Because SO(3) admits no global, smooth, minimal parameterization, common representations such as Euler angles, quaternions, rotation matrices, and Lie algebra coordinates introduce distinct constraints and failure modes. While these trade-offs are well studied for supervised learning, their implications for actions in reinforcement learning remain unclear. We systematically evaluate SO(3) action representations across three standard continuous control algorithms, PPO, SAC, and TD3, under dense and sparse rewards. We compare how representations shape exploration, interact with entropy regularization, and affect training stability through empirical studies and analyze the implications of different projections for obtaining valid rotations from Euclidean network outputs. Across a suite of robotics benchmarks, we quantify the practical impact of these choices and distill simple, implementation-ready guidelines for selecting and using rotation actions. Our results highlight that representation-induced geometry strongly influences exploration and optimization and show that representing actions as tangent vectors in the local frame yields the most reliable results across algorithms. 

**Abstract (ZH)**: 许多机器人控制任务需要策略对姿态进行操作，但SO(3)的几何结构使这变得非平凡。由于SO(3)无法拥有全局、平滑且最小的参数化表示，常用表示方法如欧拉角、四元数、旋转矩阵和李代数坐标引入了不同的约束和失效模式。尽管这些权衡在监督学习中已有充分研究，但对于强化学习中的动作而言，其影响仍不清楚。我们系统地评估了SO(3)动作表示方法在PPO、SAC和TD3三种标准连续控制算法下，在稠密和稀疏奖励条件下的性能。我们比较了不同表示方法如何影响探索、与熵正则化的交互以及通过实验证明训练稳定，并分析了从欧几里得网络输出获取有效旋转的不同投影的含义。在一系列机器人基准测试中，我们量化了这些选择的实际影响，并提炼出选择和使用旋转动作的简单实现指南。我们的结果强调，由表示引起的几何结构强烈影响探索和优化，并显示将动作表示为局部坐标系中的切向量是最可靠的结果。 

---
# HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction 

**Title (ZH)**: HoMer: 通过建模顺序和集wise上下文来解决异质性进行点击率预测 

**Authors**: Shuwei Chen, Jiajun Cui, Zhengqi Xu, Fan Zhang, Jiangke Fan, Teng Zhang, Xingxing Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11100)  

**Abstract**: Click-through rate (CTR) prediction, which models behavior sequence and non-sequential features (e.g., user/item profiles or cross features) to infer user interest, underpins industrial recommender systems. However, most methods face three forms of heterogeneity that degrade predictive performance: (i) Feature Heterogeneity persists when limited sequence side features provide less granular interest representation compared to extensive non-sequential features, thereby impairing sequence modeling performance; (ii) Context Heterogeneity arises because a user's interest in an item will be influenced by other items, yet point-wise prediction neglects cross-item interaction context from the entire item set; (iii) Architecture Heterogeneity stems from the fragmented integration of specialized network modules, which compounds the model's effectiveness, efficiency and scalability in industrial deployments. To tackle the above limitations, we propose HoMer, a Homogeneous-Oriented TransforMer for modeling sequential and set-wise contexts. First, we align sequence side features with non-sequential features for accurate sequence modeling and fine-grained interest representation. Second, we shift the prediction paradigm from point-wise to set-wise, facilitating cross-item interaction in a highly parallel manner. Third, HoMer's unified encoder-decoder architecture achieves dual optimization through structural simplification and shared computation, ensuring computational efficiency while maintaining scalability with model size. Without arduous modification to the prediction pipeline, HoMer successfully scales up and outperforms our industrial baseline by 0.0099 in the AUC metric, and enhances online business metrics like CTR/RPM by 1.99%/2.46%. Additionally, HoMer saves 27% of GPU resources via preliminary engineering optimization, further validating its superiority and practicality. 

**Abstract (ZH)**: 基于同质化的TransforMer进行序列和集合理境建模 

---
# Text-Enhanced Panoptic Symbol Spotting in CAD Drawings 

**Title (ZH)**: CAD绘图中的文本增强全景符号检测 

**Authors**: Xianlin Liu, Yan Gong, Bohao Li, Jiajing Huang, Bowen Du, Junchen Ye, Liyan Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11091)  

**Abstract**: With the widespread adoption of Computer-Aided Design(CAD) drawings in engineering, architecture, and industrial design, the ability to accurately interpret and analyze these drawings has become increasingly critical. Among various subtasks, panoptic symbol spotting plays a vital role in enabling downstream applications such as CAD automation and design retrieval. Existing methods primarily focus on geometric primitives within the CAD drawings to address this task, but they face following major problems: they usually overlook the rich textual annotations present in CAD drawings and they lack explicit modeling of relationships among primitives, resulting in incomprehensive understanding of the holistic drawings. To fill this gap, we propose a panoptic symbol spotting framework that incorporates textual annotations. The framework constructs unified representations by jointly modeling geometric and textual primitives. Then, using visual features extract by pretrained CNN as the initial representations, a Transformer-based backbone is employed, enhanced with a type-aware attention mechanism to explicitly model the different types of spatial dependencies between various primitives. Extensive experiments on the real-world dataset demonstrate that the proposed method outperforms existing approaches on symbol spotting tasks involving textual annotations, and exhibits superior robustness when applied to complex CAD drawings. 

**Abstract (ZH)**: 基于文本注释的综合符号检测框架：解决CAD图纸综合理解问题 

---
# Source-Free Object Detection with Detection Transformer 

**Title (ZH)**: 无源物体检测：检测变换器方法 

**Authors**: Huizai Yao, Sicheng Zhao, Shuo Lu, Hui Chen, Yangyang Li, Guoping Liu, Tengfei Xing, Chenggang Yan, Jianhua Tao, Guiguang Ding  

**Link**: [PDF](https://arxiv.org/pdf/2510.11090)  

**Abstract**: Source-Free Object Detection (SFOD) enables knowledge transfer from a source domain to an unsupervised target domain for object detection without access to source data. Most existing SFOD approaches are either confined to conventional object detection (OD) models like Faster R-CNN or designed as general solutions without tailored adaptations for novel OD architectures, especially Detection Transformer (DETR). In this paper, we introduce Feature Reweighting ANd Contrastive Learning NetworK (FRANCK), a novel SFOD framework specifically designed to perform query-centric feature enhancement for DETRs. FRANCK comprises four key components: (1) an Objectness Score-based Sample Reweighting (OSSR) module that computes attention-based objectness scores on multi-scale encoder feature maps, reweighting the detection loss to emphasize less-recognized regions; (2) a Contrastive Learning with Matching-based Memory Bank (CMMB) module that integrates multi-level features into memory banks, enhancing class-wise contrastive learning; (3) an Uncertainty-weighted Query-fused Feature Distillation (UQFD) module that improves feature distillation through prediction quality reweighting and query feature fusion; and (4) an improved self-training pipeline with a Dynamic Teacher Updating Interval (DTUI) that optimizes pseudo-label quality. By leveraging these components, FRANCK effectively adapts a source-pre-trained DETR model to a target domain with enhanced robustness and generalization. Extensive experiments on several widely used benchmarks demonstrate that our method achieves state-of-the-art performance, highlighting its effectiveness and compatibility with DETR-based SFOD models. 

**Abstract (ZH)**: 源数据无从获取的目标检测（Source-Free Object Detection, SFOD）使知识能够在无需访问源数据的情况下，从一个源领域转移到一个未监督的目标领域进行目标检测。目前大多数SFOD方法要么局限于传统的对象检测（OD）模型如Faster R-CNN，要么作为通用解决方案设计，缺乏针对新型OD架构，尤其是检测变换器（DETR）的针对性调整。在本文中，我们引入了特征重赋权重和对比学习网络（FRANCK），这是一种专门设计用于对DETR进行查询中心特征增强的新型SFOD框架。FRANCK包含四个关键组件：基于对象概率的采样重赋权重模块（OSSR），计算多尺度编码特征图上的注意力对象概率分数，并重新加权检测损失以强调未充分识别的区域；具有匹配增强的记忆银行的对比学习模块（CMMB），将多层级特征整合进记忆银行中，增强类别间的对比学习；通过预测质量加权和查询特征融合改进的不确定性加权查询融合特征蒸馏模块（UQFD）；以及带有动态教师更新间隔改进的自我训练管道（DTUI），优化伪标签质量。通过利用这些组件，FRANCK有效地将源预训练的DETR模型适应到具有增强鲁棒性和泛化能力的目标领域。在几个广泛应用的标准上的广泛实验表明，我们的方法达到了最先进的性能，突显了其在基于DETR的SFOD模型中的有效性和兼容性。 

---
# Causal Disentanglement Learning for Accurate Anomaly Detection in Multivariate Time Series 

**Title (ZH)**: 多变量时间序列中准确异常检测的因果去纠缠学习 

**Authors**: Wonah Kim, Jeonghyeon Park, Dongsan Jun, Jungkyu Han, Sejin Chun  

**Link**: [PDF](https://arxiv.org/pdf/2510.11084)  

**Abstract**: Disentangling complex causal relationships is important for accurate detection of anomalies. In multivariate time series analysis, dynamic interactions among data variables over time complicate the interpretation of causal relationships. Traditional approaches assume statistical independence between variables in unsupervised settings, whereas recent methods capture feature correlations through graph representation learning. However, their representations fail to explicitly infer the causal relationships over different time periods. To solve the problem, we propose Causally Disentangled Representation Learning for Anomaly Detection (CDRL4AD) to detect anomalies and identify their causal relationships in multivariate time series. First, we design the causal process as model input, the temporal heterogeneous graph, and causal relationships. Second, our representation identifies causal relationships over different time periods and disentangles latent variables to infer the corresponding causal factors. Third, our experiments on real-world datasets demonstrate that CDRL4AD outperforms state-of-the-art methods in terms of accuracy and root cause analysis. Fourth, our model analysis validates hyperparameter sensitivity and the time complexity of CDRL4AD. Last, we conduct a case study to show how our approach assists human experts in diagnosing the root causes of anomalies. 

**Abstract (ZH)**: 因果关系分离的表示学习在异常检测中的应用（CDRL4AD） 

---
# Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling 

**Title (ZH)**: 基于流匹配的自驱动规划与高级交互行为建模 

**Authors**: Tianyi Tan, Yinan Zheng, Ruiming Liang, Zexu Wang, Kexin Zheng, Jinliang Zheng, Jianxiong Li, Xianyuan Zhan, Jingjing Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.11083)  

**Abstract**: Modeling interactive driving behaviors in complex scenarios remains a fundamental challenge for autonomous driving planning. Learning-based approaches attempt to address this challenge with advanced generative models, removing the dependency on over-engineered architectures for representation fusion. However, brute-force implementation by simply stacking transformer blocks lacks a dedicated mechanism for modeling interactive behaviors that are common in real driving scenarios. The scarcity of interactive driving data further exacerbates this problem, leaving conventional imitation learning methods ill-equipped to capture high-value interactive behaviors. We propose Flow Planner, which tackles these problems through coordinated innovations in data modeling, model architecture, and learning scheme. Specifically, we first introduce fine-grained trajectory tokenization, which decomposes the trajectory into overlapping segments to decrease the complexity of whole trajectory modeling. With a sophisticatedly designed architecture, we achieve efficient temporal and spatial fusion of planning and scene information, to better capture interactive behaviors. In addition, the framework incorporates flow matching with classifier-free guidance for multi-modal behavior generation, which dynamically reweights agent interactions during inference to maintain coherent response strategies, providing a critical boost for interactive scenario understanding. Experimental results on the large-scale nuPlan dataset and challenging interactive interPlan dataset demonstrate that Flow Planner achieves state-of-the-art performance among learning-based approaches while effectively modeling interactive behaviors in complex driving scenarios. 

**Abstract (ZH)**: 基于模型的交互驾驶行为在复杂场景中的建模依然是自主驾驶规划中的一个基本挑战。基于学习的方法试图通过先进的生成模型解决这一挑战，去除对过度工程化架构的依赖以实现表示融合。然而，简单地堆叠变压器块的 brute-force 实现缺乏专门机制来建模在实际驾驶场景中常见的交互行为。交互驾驶数据的缺乏进一步加剧了这一问题，使得传统的模仿学习方法难以捕捉高价值的交互行为。我们提出了 Flow Planner，通过数据建模、模型架构和学习方案的协调创新来解决这些问题。具体而言，我们首先引入细粒度轨迹标记化，将轨迹分解为重叠段以降低整个轨迹建模的复杂性。借助精心设计的架构，我们实现了规划和场景信息的高效时空融合，以更好地捕捉交互行为。此外，该框架整合了流匹配与无分类器引导的多模态行为生成，动态重新加权推理期间的代理人交互，以保持一致的响应策略，为交互场景理解提供了关键的提升。在大规模 nuPlan 数据集和具有挑战性的交互 interPlan 数据集上的实验结果显示，Flow Planner 在基于学习的方法中实现了最先进的性能，同时在复杂驾驶场景中有效地建模了交互行为。 

---
# PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System 

**Title (ZH)**: PhysHSI: 面向真实世界通用且自然的人形场景交互系统 

**Authors**: Huayi Wang, Wentao Zhang, Runyi Yu, Tao Huang, Junli Ren, Feiyu Jia, Zirui Wang, Xiaojie Niu, Xiao Chen, Jiahe Chen, Qifeng Chen, Jingbo Wang, Jiangmiao Pang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11072)  

**Abstract**: Deploying humanoid robots to interact with real-world environments--such as carrying objects or sitting on chairs--requires generalizable, lifelike motions and robust scene perception. Although prior approaches have advanced each capability individually, combining them in a unified system is still an ongoing challenge. In this work, we present a physical-world humanoid-scene interaction system, PhysHSI, that enables humanoids to autonomously perform diverse interaction tasks while maintaining natural and lifelike behaviors. PhysHSI comprises a simulation training pipeline and a real-world deployment system. In simulation, we adopt adversarial motion prior-based policy learning to imitate natural humanoid-scene interaction data across diverse scenarios, achieving both generalization and lifelike behaviors. For real-world deployment, we introduce a coarse-to-fine object localization module that combines LiDAR and camera inputs to provide continuous and robust scene perception. We validate PhysHSI on four representative interactive tasks--box carrying, sitting, lying, and standing up--in both simulation and real-world settings, demonstrating consistently high success rates, strong generalization across diverse task goals, and natural motion patterns. 

**Abstract (ZH)**: 将类人机器人部署到与现实环境交互——例如搬运物体或坐在椅子上——需要具有广泛适用性和逼真表现力的动作以及稳健的场景感知。尽管先前的方法在各自的能力上取得了进展，但在统一系统中结合这些能力仍然是一个持续的挑战。在本工作中，我们提出了一种物理世界类人场景交互系统PhysHSI，该系统使类人机器人能够在保持自然和逼真行为的同时自主执行多样的交互任务。PhysHSI 包括一个仿真训练流水线和一个现实世界部署系统。在仿真中，我们采用基于对抗性运动先验的策略学习来模仿跨不同场景的自然类人场景交互数据，实现了通用性和逼真行为的结合。在现实世界部署中，我们引入了一种细粒度到粗粒度物体定位模块，结合LiDAR和摄像头输入以提供连续和稳健的场景感知。我们在四种代表性交互任务——搬运箱子、坐下、躺下和站立——的仿真和现实世界设置中验证了PhysHSI，展示了高度一致的成功率、广泛的跨任务目标泛化能力和自然的运动模式。 

---
# Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models 

**Title (ZH)**: 时间对齐指导：扩散模型中的流形采样 

**Authors**: Youngrok Park, Hojung Jung, Sangmin Bae, Se-Young Yun  

**Link**: [PDF](https://arxiv.org/pdf/2510.11057)  

**Abstract**: Diffusion models have achieved remarkable success as generative models. However, even a well-trained model can accumulate errors throughout the generation process. These errors become particularly problematic when arbitrary guidance is applied to steer samples toward desired properties, which often breaks sample fidelity. In this paper, we propose a general solution to address the off-manifold phenomenon observed in diffusion models. Our approach leverages a time predictor to estimate deviations from the desired data manifold at each timestep, identifying that a larger time gap is associated with reduced generation quality. We then design a novel guidance mechanism, `Temporal Alignment Guidance' (TAG), attracting the samples back to the desired manifold at every timestep during generation. Through extensive experiments, we demonstrate that TAG consistently produces samples closely aligned with the desired manifold at each timestep, leading to significant improvements in generation quality across various downstream tasks. 

**Abstract (ZH)**: 扩散模型作为生成模型取得了显著的成功。然而，即使训练良好的模型在生成过程中也会累积误差。当对生成样本施加任意指导以引导其朝向期望的特性时，这些误差往往会破坏生成样本的保真度。在本文中，我们提出了一个通用解决方案来解决观察到的扩散模型中的离流现象。我们的方法利用时间预测器在每个时间步估计与期望数据流形的偏差，发现更大的时间间隔与较低的生成质量相关。随后，我们设计了一种新颖的指导机制，即“时间对齐指导”（TAG），在生成的每个时间步将样本吸引回期望的流形。通过广泛的实验，我们证明TAG能够在每个时间步持续产生与期望流形高度对齐的样本，从而在各种下游任务中显著提高生成质量。 

---
# From Reasoning LLMs to BERT: A Two-Stage Distillation Framework for Search Relevance 

**Title (ZH)**: 从推理LLM到BERT：一种两阶段知识蒸馏框架用于搜索相关性 

**Authors**: Runze Xia, Yupeng Ji, Yuxi Zhou, Haodong Liu, Teng Zhang, Piji Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.11056)  

**Abstract**: Query-service relevance prediction in e-commerce search systems faces strict latency requirements that prevent the direct application of Large Language Models (LLMs). To bridge this gap, we propose a two-stage reasoning distillation framework to transfer reasoning capabilities from a powerful teacher LLM to a lightweight, deployment-friendly student model. In the first stage, we address the limitations of general-purpose LLMs by constructing a domain-adapted teacher model. This is achieved through a three-step process: domain-adaptive pre-training to inject platform knowledge, supervised fine-tuning to elicit reasoning skills, and preference optimization with a multi-dimensional reward model to ensure the generation of reliable and preference-aligned reasoning paths. This teacher can then automatically annotate massive query-service pairs from search logs with both relevance labels and reasoning chains. In the second stage, to address the challenges of architectural heterogeneity in standard distillation, we introduce Contrastive Reasoning Self-Distillation (CRSD). By modeling the behavior of the same student model under "standard" and "reasoning-augmented" inputs as a teacher-student relationship, CRSD enables the lightweight model to internalize the teacher's complex decision-making mechanisms without needing the explicit reasoning path at inference. Offline evaluations and online A/B testing in the Meituan search advertising system demonstrate that our framework achieves significant improvements across multiple metrics, validating its effectiveness and practical value. 

**Abstract (ZH)**: 电子商务搜索系统中的查询服务相关性预测面临严格的延迟要求，这阻碍了直接应用大型语言模型（LLMs）的可能性。为了解决这一问题，我们提出了一种两阶段推理蒸馏框架，将强健的教师LLM的推理能力转移到轻量级、易于部署的学生模型上。在第一阶段，我们通过构建一个领域适应的教师模型来解决通用LLM的限制。这一过程包括三个步骤：领域适应预训练以注入平台知识、监督微调以激发推理技能、以及通过多维度奖励模型进行偏好优化以确保生成可靠且偏好对齐的推理路径。然后，该教师可以自动为搜索日志中的大量查询-服务对标注相关性标签和推理链。在第二阶段，为了解决标准蒸馏中由于架构异构性带来的挑战，我们引入了对比推理自蒸馏（CRSD）。通过将同一个学生模型在“标准”和“推理增强”输入下的行为建模为教师-学生关系，CRSD 允许轻量级模型内化教师的复杂决策机制，而不需要在推理时明确的推理路径。美团搜索广告系统中的离线评估和在线 A/B 测试表明，我们的框架在多个指标上取得了显著的改进，验证了其有效性和实际价值。 

---
# XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation 

**Title (ZH)**: XGrasp: 多爪夹数据生成的夹持检测与爪夹aware方法 

**Authors**: Yeonseo Lee, Jungwook Mun, Hyosup Shin, Guebin Hwang, Junhee Nam, Taeyeop Lee, Sungho Jo  

**Link**: [PDF](https://arxiv.org/pdf/2510.11036)  

**Abstract**: Most robotic grasping methods are typically designed for single gripper types, which limits their applicability in real-world scenarios requiring diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp detection framework that efficiently handles multiple gripper configurations. The proposed method addresses data scarcity by systematically augmenting existing datasets with multi-gripper annotations. XGrasp employs a hierarchical two-stage architecture. In the first stage, a Grasp Point Predictor (GPP) identifies optimal locations using global scene information and gripper specifications. In the second stage, an Angle-Width Predictor (AWP) refines the grasp angle and width using local features. Contrastive learning in the AWP module enables zero-shot generalization to unseen grippers by learning fundamental grasping characteristics. The modular framework integrates seamlessly with vision foundation models, providing pathways for future vision-language capabilities. The experimental results demonstrate competitive grasp success rates across various gripper types, while achieving substantial improvements in inference speed compared to existing gripper-aware methods. Project page: this https URL 

**Abstract (ZH)**: 多 gripper 配置aware 的实时夹持检测框架 XGrasp 

---
# GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation 

**Title (ZH)**: GeoVLMath：通过跨模态奖励辅助直线创建增强视觉-语言模型中的几何推理能力 

**Authors**: Shasha Guo, Liang Pang, Xi Wang, Yanling Wang, Huawei Shen, Jing Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.11020)  

**Abstract**: Auxiliary lines are essential for solving complex geometric problems but remain challenging for large vision-language models (LVLMs). Rather than editing diagrams to draw auxiliary lines, which current image editing models struggle to render with geometric precision, we generate textual descriptions of auxiliary-line constructions to better align with the representational strengths of LVLMs. To bridge the gap between textual descriptions and spatial structure, we propose a reinforcement learning framework that enhances diagram-text alignment. At the core of our approach is a cross-modal reward that evaluates how well the generated auxiliary-line description for an original diagram matches a ground-truth auxiliary-line diagram. Built on this reward, we present GeoVLMath, an open-source LVLM tailored to auxiliary-line reasoning in solid geometry. This fine-grained signal drives a GRPO-based RL stage, yielding precise diagram-text alignment. To support training, we develop a scalable data creation pipeline and construct AuxSolidMath, a dataset of 3,018 real-exam geometry problems with paired diagrams and aligned textual fields. At the 3B and 7B scales, GeoVLMath achieves competitive and often superior performance compared with strong open-source and proprietary LVLMs on auxiliary-line reasoning benchmarks. 

**Abstract (ZH)**: 辅助线对于解决复杂的几何问题至关重要，但对大型视觉-语言模型（LVLMs）来说仍具有挑战性。我们不通过编辑图形来绘制辅助线，而是生成辅助线构建的文字描述，以更好地与LVLMs的表征优势相契合。为了弥合文本描述与空间结构之间的差距，我们提出了一种强化学习框架，以增强图形-文本对齐。该方法的核心是一个跨模态奖励，用于评估生成的辅助线描述与真实辅助线图形之间的匹配程度。基于这一奖励，我们提出了GeoVLMath，一个适用于固态几何辅助线推理的开源LVLM。这一精细信号驱动基于GRPO的强化学习阶段，实现精确的图形-文本对齐。为了支持训练，我们开发了一个可扩展的数据创建管道，并构建了包含3,018个实际考试几何问题的AuxSolidMath数据集，这些问题配有配对的图形和对齐的文字字段。在3B和7B规模下，GeoVLMath在辅助线推理基准测试中与强大的开源和专有LVLMs相比，表现出竞争力甚至更优的性能。 

---
# Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces 

**Title (ZH)**: 未知之境：面向配置空间规划中环境不确定性先验采样的生成模型研究 

**Authors**: Subhransu S. Bhattacharjee, Hao Lu, Dylan Campbell, Rahul Shome  

**Link**: [PDF](https://arxiv.org/pdf/2510.11014)  

**Abstract**: Priors are vital for planning under partial observability, yet difficult to obtain in practice. We present a sampling-based pipeline that leverages large-scale pretrained generative models to produce probabilistic priors capturing environmental uncertainty and spatio-semantic relationships in a zero-shot manner. Conditioned on partial observations, the pipeline recovers complete RGB-D point cloud samples with occupancy and target semantics, formulated to be directly useful in configuration-space planning. We establish a Matterport3D benchmark of rooms partially visible through doorways, where a robot must navigate to an unobserved target object. Effective priors for this setting must represent both occupancy and target-location uncertainty in unobserved regions. Experiments show that our approach recovers commonsense spatial semantics consistent with ground truth, yielding diverse, clean 3D point clouds usable in motion planning, highlight the promise of generative models as a rich source of priors for robotic planning. 

**Abstract (ZH)**: 基于大规模预训练生成模型的采样管道在部分可观测性下的规划中至关重要但难以获取：我们提出了一种零样本方式利用大规模预训练生成模型生成捕捉环境不确定性和空间语义关系的概率先验的采样管道。该管道在部分观测条件下恢复完整的RGB-D点云样本，并且这些样本包含 occupancy 和目标语义，可以直接用于配置空间规划。我们在一个 Matterport3D 基准中建立了通过门洞部分可见的房间场景，其中机器人需要导航至一个未被观测到的目标物体。有效的先验在这种设定中必须同时表示未观测区域中的 occupancy 和目标位置的不确定性。实验结果显示，我们的方法恢复了与真实世界一致的常识性空间语义，生成了多样且干净的3D点云，可用于运动规划，突显了生成模型作为机器人规划中丰富先验来源的潜力。 

---
# Automating Structural Engineering Workflows with Large Language Model Agents 

**Title (ZH)**: 使用大型语言模型代理自动化结构工程工作流 

**Authors**: Haoran Liang, Yufa Zhou, Mohammad Talebi Kalaleh, Qipei Mei  

**Link**: [PDF](https://arxiv.org/pdf/2510.11004)  

**Abstract**: We introduce $\textbf{MASSE}$, the first Multi-Agent System for Structural Engineering, effectively integrating large language model (LLM)-based agents with real-world engineering workflows. Structural engineering is a fundamental yet traditionally stagnant domain, with core workflows remaining largely unchanged for decades despite its substantial economic impact and global market size. Recent advancements in LLMs have significantly enhanced their ability to perform complex reasoning, long-horizon planning, and precise tool utilization -- capabilities well aligned with structural engineering tasks such as interpreting design codes, executing load calculations, and verifying structural capacities. We present a proof-of-concept showing that most real-world structural engineering workflows can be fully automated through a training-free LLM-based multi-agent system. MASSE enables immediate deployment in professional environments, and our comprehensive validation on real-world case studies demonstrates that it can reduce expert workload from approximately two hours to mere minutes, while enhancing both reliability and accuracy in practical engineering scenarios. 

**Abstract (ZH)**: MASSE：面向结构工程的首个multi-agent系统，有效集成基于大语言模型的代理与实际工程工作流程 

---
# DND: Boosting Large Language Models with Dynamic Nested Depth 

**Title (ZH)**: DND: 通过动态嵌套深度增强大型语言模型 

**Authors**: Tieyuan Chen, Xiaodong Chen, Haoxing Chen, Zhenzhong Lan, Weiyao Lin, Jianguo Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.11001)  

**Abstract**: We introduce Dynamic Nested Depth (DND), a novel method that improves performance for off-the-shelf LLMs by selecting critical tokens to reprocess in a nested depth manner. Specifically, at the end of the given transformer layer, DND identifies more critical tokens with a router and feeds them back for an extra round of processing, effectively ``reviewing" difficult tokens while avoiding redundant computation for easier ones. The dynamic selection mechanism is tailored for precise control via two novel strategies: a router controlling loss to enhance token selection distinguishability, and a threshold control scheme to ensure selection stability. We demonstrate the effectiveness of DND by directly integrating it into pre-trained dense and MoE models during a post-training phase. On diverse benchmarks, this approach boosts the performances of the dense Qwen3-1.7B by 1.88% and the MoE Qwen3-30B-A3B by 0.87%, all with a minimal parameter and computing increase. 

**Abstract (ZH)**: 我们引入了动态嵌套深度（DND）方法，这是一种通过以嵌套深度方式重新处理关键令牌来提高现成大语言模型性能的新方法。具体而言，在给定的变压器层结束后，DND 使用一个路由器识别更多关键令牌，并让这些令牌进行额外一轮处理，从而有效地“审查”困难的令牌，同时避免对较简单的令牌进行冗余计算。动态选择机制通过两种新颖策略实现精确控制：一个用于控制损失以增强令牌选择的区分度的路由器，以及一个确保选择稳定性的阈值控制方案。我们通过在后训练阶段直接将DND集成到预训练的密集模型和MoE模型中，展示了DND的有效性。在多种基准测试中，这种方法分别将密集型Qwen3-1.7B和MoE型Qwen3-30B-A3B的性能提高了1.88%和0.87%，同时参数和计算量仅增加了minimal量。 

---
# ABLEIST: Intersectional Disability Bias in LLM-Generated Hiring Scenarios 

**Title (ZH)**: ableist: LLM生成招聘场景中的交叉残障偏见 

**Authors**: Mahika Phutane, Hayoung Jung, Matthew Kim, Tanushree Mitra, Aditya Vashistha  

**Link**: [PDF](https://arxiv.org/pdf/2510.10998)  

**Abstract**: Large language models (LLMs) are increasingly under scrutiny for perpetuating identity-based discrimination in high-stakes domains such as hiring, particularly against people with disabilities (PwD). However, existing research remains largely Western-centric, overlooking how intersecting forms of marginalization--such as gender and caste--shape experiences of PwD in the Global South. We conduct a comprehensive audit of six LLMs across 2,820 hiring scenarios spanning diverse disability, gender, nationality, and caste profiles. To capture subtle intersectional harms and biases, we introduce ABLEIST (Ableism, Inspiration, Superhumanization, and Tokenism), a set of five ableism-specific and three intersectional harm metrics grounded in disability studies literature. Our results reveal significant increases in ABLEIST harms towards disabled candidates--harms that many state-of-the-art models failed to detect. These harms were further amplified by sharp increases in intersectional harms (e.g., Tokenism) for gender and caste-marginalized disabled candidates, highlighting critical blind spots in current safety tools and the need for intersectional safety evaluations of frontier models in high-stakes domains like hiring. 

**Abstract (ZH)**: 大型语言模型（LLMs）在招聘等高风险领域中越来越多地受到审查，因其在针对残障人士（PwD）方面的身份歧视问题而受到质疑，尤其是在残疾人方面。然而，现有的研究仍然主要以西方为中心，未充分考虑到性别和种姓等多重边缘化形式如何在全球南方塑造残疾人的体验。我们对六种LLM进行了全面审计，覆盖了2,820个招聘场景，涉及多元化的残疾、性别、国籍和种姓特征。为了捕捉细微的交叉性伤害和偏见，我们引入了ABLEIST（能力建设主义、激励、超人化和象征性令牌）这一包含五项针对能力建设主义的具体指标和三项交叉性伤害指标的度量体系，其基础为残疾研究文献。研究结果揭示，最先进的模型未能检测到显著增加的ABLEIST伤害，特别是对于性别和种姓边缘化的残疾候选人的交叉性伤害进一步加剧，这突显了当前安全工具中的关键盲点，并强调了在招聘等高风险领域中对前沿模型进行交叉性安全评估的必要性。 

---
# DeepResearchGuard: Deep Research with Open-Domain Evaluation and Multi-Stage Guardrails for Safety 

**Title (ZH)**: DeepResearchGuard：基于开放域评估和多阶段防护栏的安全深度研究 

**Authors**: Wei-Chieh Huang, Henry Peng Zou, Yaozu Wu, Dongyuan Li, Yankai Chen, Weizhi Zhang, Yangning Li, Angelo Zangari, Jizhou Guo, Chunyu Miao, Liancheng Fang, Langzhou He, Renhe Jiang, Philip S. Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10994)  

**Abstract**: Deep research frameworks have shown promising capabilities in synthesizing comprehensive reports from web sources. While deep research possesses significant potential to address complex issues through planning and research cycles, existing frameworks are deficient in sufficient evaluation procedures and stage-specific protections. They typically treat evaluation as exact match accuracy of question-answering, but overlook crucial aspects of report quality such as credibility, coherence, breadth, depth, and safety. This oversight may result in hazardous or malicious sources being integrated into the final report. To address these issues, we introduce DEEPRESEARCHGUARD, a comprehensive framework featuring four-stage safeguards with open-domain evaluation of references and reports. We assess performance across multiple metrics, e.g., defense success rate and over-refusal rate, and five key report dimensions. In the absence of a suitable safety benchmark, we introduce DRSAFEBENCH, a stage-wise benchmark for deep research safety. Our evaluation spans diverse state-of-the-art LLMs, including GPT-4o, Gemini-2.5-flash, DeepSeek-v3, and o4-mini. DEEPRESEARCHGUARD achieves an average defense success rate improvement of 18.16% while reducing over-refusal rate by 6%. The input guard provides the most substantial early-stage protection by filtering out obvious risks, while the plan and research guards enhance citation discipline and source credibility. Through extensive experiments, we show that DEEPRESEARCHGUARD enables comprehensive open-domain evaluation and stage-aware defenses that effectively block harmful content propagation, while systematically improving report quality without excessive over-refusal rates. The code can be found via this https URL. 

**Abstract (ZH)**: 深度研究框架在从网络来源合成综合性报告方面展现了有前景的能力。尽管深度研究通过规划和研究周期在解决复杂问题方面具备显著潜力，现有的框架缺乏足够的评估程序和阶段特定保护。它们通常将评估视为问题回答的精确匹配准确率，但忽略了报告质量的关键方面，如可信度、连贯性、广度、深度和安全性。这种疏忽可能导致危险或恶意来源被集成到最终报告中。为了解决这些问题，我们提出了一种名为DEEPRESEARCHGUARD的综合框架，该框架包含四阶段保护措施，并对引文和报告进行开放式领域评估。我们在多个指标上评估性能，包括防御成功率、过度拒绝率，以及五个关键报告维度。在缺乏合适的安全性基准的情况下，我们引入了DRSAFEBENCH，一种阶段性的深度研究安全性基准。我们的评估涵盖了包括GPT-4o、Gemini-2.5-flash、DeepSeek-v3和o4-mini在内的多种最新LLMs。DEEPRESEARCHGUARD实现了平均防御成功率提高18.16%，过度拒绝率减少6%的效果。输入保护提供了最显著的早期阶段保护，通过过滤掉明显的风险，而计划和研究保护增强了引文纪律和来源可信度。通过大量实验，我们展示了DEEPRESEARCHGUARD能够实现综合的开放式领域评估和阶段感知防御，有效阻止有害内容的传播，同时系统地提高报告质量，而不增加过度拒绝率。代码可以通过这个链接访问。 

---
# A Survey on Agentic Multimodal Large Language Models 

**Title (ZH)**: 代理多模态大型语言模型综述 

**Authors**: Huanjin Yao, Ruifei Zhang, Jiaxing Huang, Jingyi Zhang, Yibo Wang, Bo Fang, Ruolin Zhu, Yongcheng Jing, Shunyu Liu, Guanbin Li, Dacheng Tao  

**Link**: [PDF](https://arxiv.org/pdf/2510.10991)  

**Abstract**: With the recent emergence of revolutionary autonomous agentic systems, research community is witnessing a significant shift from traditional static, passive, and domain-specific AI agents toward more dynamic, proactive, and generalizable agentic AI. Motivated by the growing interest in agentic AI and its potential trajectory toward AGI, we present a comprehensive survey on Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we explore the emerging paradigm of agentic MLLMs, delineating their conceptual foundations and distinguishing characteristics from conventional MLLM-based agents. We establish a conceptual framework that organizes agentic MLLMs along three fundamental dimensions: (i) Agentic internal intelligence functions as the system's commander, enabling accurate long-horizon planning through reasoning, reflection, and memory; (ii) Agentic external tool invocation, whereby models proactively use various external tools to extend their problem-solving capabilities beyond their intrinsic knowledge; and (iii) Agentic environment interaction further situates models within virtual or physical environments, allowing them to take actions, adapt strategies, and sustain goal-directed behavior in dynamic real-world scenarios. To further accelerate research in this area for the community, we compile open-source training frameworks, training and evaluation datasets for developing agentic MLLMs. Finally, we review the downstream applications of agentic MLLMs and outline future research directions for this rapidly evolving field. To continuously track developments in this rapidly evolving field, we will also actively update a public repository at this https URL. 

**Abstract (ZH)**: 近年来，随着革命性自主代理系统的出现，研究界正在从传统的静态、被动且领域特定的AI代理向更具动态性、主动性且可泛化的代理型AI转变。受代理型AI及其向AGI发展的潜在轨迹日益增长的兴趣推动，我们提供了一篇关于代理型多模态大型语言模型（Agentic MLLMs）的全面综述。在这篇综述中，我们探讨了代理型MLLMs新兴的范式，明确了它们与传统基于MLLM的代理的概念基础和区别特征。我们构建了一个概念框架，从三个方面组织代理型MLLMs：（i）代理内部智能作为系统的指挥官，通过推理、反思和记忆实现准确的长期规划；（ii）代理外部工具调用，即模型主动使用各种外部工具以超越其固有知识扩展其问题解决能力；（iii）代理环境交互，使模型在虚拟或物理环境中更易于采取行动、调整策略并维持目标导向行为，以适应动态现实世界场景。为了进一步促进该领域的研究，我们汇编了开源训练框架、训练和评估数据集，用于开发代理型MLLMs。最后，我们回顾了代理型MLLMs的下游应用，并概述了这一快速发展的领域的未来研究方向。为了持续跟踪这一快速发展的领域的发展，我们还将积极更新一个公共存储库。 

---
# DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation 

**Title (ZH)**: DITTO：一种通过知识蒸馏针对带水印的大语言模型的欺骗攻击框架 

**Authors**: Hyeseon Ahn, Shinwoo Park, Yo-Sub Han  

**Link**: [PDF](https://arxiv.org/pdf/2510.10987)  

**Abstract**: The promise of LLM watermarking rests on a core assumption that a specific watermark proves authorship by a specific model. We demonstrate that this assumption is dangerously flawed. We introduce the threat of watermark spoofing, a sophisticated attack that allows a malicious model to generate text containing the authentic-looking watermark of a trusted, victim model. This enables the seamless misattribution of harmful content, such as disinformation, to reputable sources. The key to our attack is repurposing watermark radioactivity, the unintended inheritance of data patterns during fine-tuning, from a discoverable trait into an attack vector. By distilling knowledge from a watermarked teacher model, our framework allows an attacker to steal and replicate the watermarking signal of the victim model. This work reveals a critical security gap in text authorship verification and calls for a paradigm shift towards technologies capable of distinguishing authentic watermarks from expertly imitated ones. Our code is available at this https URL. 

**Abstract (ZH)**: LLM水印的假设是危险破绽：一种复杂的伪造攻击使得恶意模型能够生成包含可信目标模型真实外观水印的文字，从而无缝地将有害内容归咎于可信赖的来源。攻击的关键在于将水印辐射性，即微调过程中无意继承的数据模式，从可发现的特征转换为攻击向量。通过从带水印的教师模型中提炼知识，我们的框架使攻击者能够窃取并复制目标模型的水印信号。本文揭示了文本作者身份验证中的关键安全漏洞，呼吁向能够区分真实水印与精心模仿水印的技术转变。代码可在以下链接获取。 

---
# Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization 

**Title (ZH)**: 唯一捕获：模型特定授权的非迁移性示例 

**Authors**: Zihan Wang, Zhiyong Ma, Zhongkui Ma, Shuofeng Liu, Akide Liu, Derui Wang, Minhui Xue, Guangdong Bai  

**Link**: [PDF](https://arxiv.org/pdf/2510.10982)  

**Abstract**: Recent AI regulations call for data that remain useful for innovation while resistant to misuse, balancing utility with protection at the model level. Existing approaches either perturb data to make it unlearnable or retrain models to suppress transfer, but neither governs inference by unknown models, and both typically require control over training. We propose non-transferable examples (NEs), a training-free and data-agnostic input-side usage-control mechanism. We recode inputs within a model-specific low-sensitivity subspace, preserving outputs for the authorized model while reducing performance on unauthorized models through subspace misalignment. We establish formal bounds that guarantee utility for the authorized model and quantify deviation for unauthorized ones, with the Hoffman-Wielandt inequality linking degradation to spectral differences. Empirically, NEs retain performance on diverse vision backbones and state-of-the-art vision-language models under common preprocessing, whereas non-target models collapse even with reconstruction attempts. These results establish NEs as a practical means to preserve intended data utility while preventing unauthorized exploitation. Our project is available at this https URL 

**Abstract (ZH)**: 近期的AI法规要求数据既有利于创新又能够抵御滥用，在保持模型实用性的同时提供保护。现有的方法要么通过扰动数据使其难以学习，要么重新训练模型以抑制迁移，但它们都未能控制未知模型的推理行为，且通常需要对训练过程进行控制。我们提出非可迁移示例（NEs），这是一种无需训练和数据无关的输入端使用控制机制。我们通过对模型特定低敏感子空间内的输入进行编码，保留授权模型的输出，同时通过对未经授权模型的子空间对齐来降低其性能。我们建立形式上的界限以确保授权模型的实用性，并通过度量未经授权模型的偏差进行量化，其中霍夫曼-魏兰特不等式将下降与谱差异联系起来。实验表明，NEs在常见的预处理下可以在多种视觉骨干网络和最先进的视觉-语言模型中保持性能，而未经授权的模型即使在重建尝试后也无法保持性能。这些结果证明了NEs作为一种实用手段，能够同时保持预期数据的实用性和防止未经授权的利用。我们的项目可在以下网址访问：这个 https URL 

---
# RV-HATE: Reinforced Multi-Module Voting for Implicit Hate Speech Detection 

**Title (ZH)**: RV-HATE: 强化多模块投票的隐含仇恨言论检测 

**Authors**: Yejin Lee, Hyeseon Ahn, Yo-Sub Han  

**Link**: [PDF](https://arxiv.org/pdf/2510.10971)  

**Abstract**: Hate speech remains prevalent in human society and continues to evolve in its forms and expressions. Modern advancements in internet and online anonymity accelerate its rapid spread and complicate its detection. However, hate speech datasets exhibit diverse characteristics primarily because they are constructed from different sources and platforms, each reflecting different linguistic styles and social contexts. Despite this diversity, prior studies on hate speech detection often rely on fixed methodologies without adapting to data-specific features. We introduce RV-HATE, a detection framework designed to account for the dataset-specific characteristics of each hate speech dataset. RV-HATE consists of multiple specialized modules, where each module focuses on distinct linguistic or contextual features of hate speech. The framework employs reinforcement learning to optimize weights that determine the contribution of each module for a given dataset. A voting mechanism then aggregates the module outputs to produce the final decision. RV-HATE offers two primary advantages: (1)~it improves detection accuracy by tailoring the detection process to dataset-specific attributes, and (2)~it also provides interpretable insights into the distinctive features of each dataset. Consequently, our approach effectively addresses implicit hate speech and achieves superior performance compared to conventional static methods. Our code is available at this https URL. 

**Abstract (ZH)**: 仇恨言论在人类社会中依然普遍存在，并且其形式和表达方式不断演变。互联网和在线匿名性的现代进步加速了其传播速度并使其检测变得更加复杂。尽管如此，仇恨言论数据集表现出多样化的特征，主要因为它们源自不同的来源和平台，每个平台反映了不同的语言风格和社会背景。尽管存在这些多样性，但之前关于仇恨言论检测的研究通常依赖于固定的检测方法，没有根据数据特异性进行调整。我们提出了RV-HATE，这是一种旨在考虑每个仇恨言论数据集特定特征的检测框架。RV-HATE 包含多个专门的模块，每个模块专注于仇恨言论的不同语言或背景特征。该框架使用强化学习来优化决定每个模块对给定数据集贡献权重的方法。然后通过投票机制将模块输出聚合为最终决策。RV-HATE 提供了两个主要优点：（1）它通过根据数据集特定属性定制检测过程来提高检测准确性；（2）它还提供了对每个数据集独特特征的可解释洞察。因此，我们的方法有效地解决了隐含的仇恨言论，并在性能上优于传统的静态方法。我们的代码可在此处获得。 

---
# Judge Before Answer: Can MLLM Discern the False Premise in Question? 

**Title (ZH)**: 先判断后回答：MLLM能识别虚假前提吗？ 

**Authors**: Jidong Li, Lingyong Fang, Haodong Zhao, Sufeng Duan, Gongshen Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10965)  

**Abstract**: Multimodal large language models (MLLMs) have witnessed astonishing advancements in recent years. Despite these successes, MLLMs remain vulnerable to flase premise problems. However, existing benchmarks targeting this issue are limited in scope: they often lack fine-grained categorization, exhibit insufficient coverage, and thus fail to provide a rigorous evaluation of the ability of models to recognize false premises. To bridge this gap, we introduce a fully automated pipeline for constructing a comprehensive benchmark of false premise questions. Our method systematically categorizes the premises into three main types and thirteen subtypes according to the abilities required to identify the premises, resulting in the JBA this http URL show current MLLMs still struggle with false premise recognition. Building upon this benchmark, we further propose a recognition enhancement framework tailored to strengthen the robustness of MLLMs to detect false premises. Extensive experiments demonstrate that models trained with our framework achieve significant improvements in false premise recognition. 

**Abstract (ZH)**: 多模态大规模语言模型（MLLMs）在近年来取得了惊人的进展。尽管取得了这些成功，MLLMs 对假前提问题仍然易受攻击。然而，针对这一问题的现有基准在范围上有限：它们往往缺乏细粒度的分类、覆盖面不足，因而无法提供对模型识别假前提能力的严谨评估。为弥补这一差距，我们提出了一种全自动的工作流，用于构建全面的假前提问题基准。我们的方法根据识别前提所需的能力系统地将前提划分为三大类和十三个亚类，形成了JBA这一基准。我们的研究表明，当前的MLLMs 在假前提识别方面仍存在困难。基于这一基准，我们进一步提出了一种增强框架，旨在加强MLLMs 识别假前提的鲁棒性。广泛的实验显示，使用我们框架训练的模型在假前提识别方面取得了显著的改进。 

---
# APLOT: Robust Reward Modeling via Adaptive Preference Learning with Optimal Transport 

**Title (ZH)**: APLOT：基于最优运输的自适应偏好学习稳健奖励建模 

**Authors**: Zhuo Li, Yuege Feng, Dandan Guo, Jinpeng Hu, Anningzhe Gao, Xiang Wan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10963)  

**Abstract**: The reward model (RM) plays a crucial role in aligning Large Language Models (LLMs) with human preferences through Reinforcement Learning, where the Bradley-Terry (BT) objective has been recognized as simple yet powerful, specifically for pairwise preference learning. However, BT-based RMs often struggle to effectively distinguish between similar preference responses, leading to insufficient separation between preferred and non-preferred outputs. Consequently, they may easily overfit easy samples and cannot generalize well to Out-Of-Distribution (OOD) samples, resulting in suboptimal performance. To address these challenges, this paper introduces an effective enhancement to BT-based RMs through an adaptive margin mechanism. Specifically, we design to dynamically adjust the RM focus on more challenging samples through margins, based on both semantic similarity and model-predicted reward differences, which is approached from a distributional perspective solvable with Optimal Transport (OT). By incorporating these factors into a principled OT cost matrix design, our adaptive margin enables the RM to better capture distributional differences between chosen and rejected responses, yielding significant improvements in performance, convergence speed, and generalization capabilities. Experimental results across multiple benchmarks demonstrate that our method outperforms several existing RM techniques, showcasing enhanced performance in both In-Distribution (ID) and OOD settings. Moreover, RLHF experiments support our practical effectiveness in better aligning LLMs with human preferences. Our code is available at this https URL 

**Abstract (ZH)**: 基于布雷德利-泰利目标的奖励模型改进：通过可适应的边际机制实现更好的分布区分与泛化能力 

---
# MC#: Mixture Compressor for Mixture-of-Experts Large Models 

**Title (ZH)**: 混合压缩器用于专家混合大型模型 

**Authors**: Wei Huang, Yue Liao, Yukang Chen, Jianhui Liu, Haoru Tan, Si Liu, Shiming Zhang, Shuicheng Yan, Xiaojuan Qi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10962)  

**Abstract**: Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and vision-language models (VLMs) by increasing capacity through sparse activation. However, preloading all experts into memory and activating multiple experts per input introduces significant computational and memory overhead, making the expert module a major contributor to model size and inference cost. To address this, we propose MC# (Mixture-Compressor-sharp), a framework that combines static quantization and dynamic expert pruning by leveraging the significance of experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce storage and loading costs, we introduce Pre-Loading Mixed-Precision Quantization (PMQ), which optimizes bit allocation via linear programming, balancing expert importance and quantization error for a Pareto-optimal trade-off between size and performance. To reduce runtime computation, Online Top-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a subset of experts per token, enabling fine-grained control over activation. By combining PMQ's static bit-width optimization with OTP's dynamic routing, MC# achieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC# achieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7% accuracy drop across five multimodal benchmarks. Additionally, OTP reduces expert activation over 20% with less than 1% performance degradation, demonstrating strong potential for efficient MoE-based model deployment. 

**Abstract (ZH)**: MC# (Mixture-Compressor-sharp): 结合静态量化和动态专家剪枝的 MoE 大型语言模型/视觉-语言模型高效压缩框架 

---
# KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification 

**Title (ZH)**: KOTOX：一个用于去混淆和去毒化的韩语有毒数据集 

**Authors**: Yejin Lee, Su-Hyeon Kim, Hyundong Jin, Dayoung Kim, Yeonsoo Kim, Yo-Sub Han  

**Link**: [PDF](https://arxiv.org/pdf/2510.10961)  

**Abstract**: Toxic content has become an increasingly critical social issue with the rapid expansion of online communication. While numerous studies explored methods for detecting and detoxifying such content, most have focused primarily on English, leaving low-resource language underrepresented. Consequently, Large Language Models~(LLMs) often struggle to identify and neutralize toxic expressions in these languages. This challenge becomes even more pronounced when user employ obfuscation techniques to evade detection systems. Therefore, we propose a \textbf{KOTOX: Korean Toxic Dataset} for deobfuscation and detoxicification to address this issue. We categorize various obfuscation approaches based on linguistic characteristics of Korean and define a set of transformation rules grounded in real-word examples. Using these rules, we construct three dataset versions (easy, normal, and hard) representing different levels of obfuscation difficulty. This is the first dataset that simultaneously supports deobfuscation and detoxification for the Korean language. We expect it to facilitate better understanding and mitigating of obfuscated toxic content in LLM for low-resource languages. Our code and data are available at this https URL. 

**Abstract (ZH)**: KOTOX: 韩语有毒数据集 

---
# Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning 

**Title (ZH)**: 重寻熵正则化的力量：自适应系数解锁其在大语言模型强化学习中的潜力 

**Authors**: Xiaoyun Zhang, Xiaojian Yuan, Di Huang, Wang You, Chen Hu, Jingqing Ruan, Kejiang Chen, Xing Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10959)  

**Abstract**: Reasoning ability has become a defining capability of Large Language Models (LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as a key paradigm to enhance it. However, RLVR training often suffers from policy entropy collapse, where the policy becomes overly deterministic, hindering exploration and limiting reasoning performance. While entropy regularization is a common remedy, its effectiveness is highly sensitive to the fixed coefficient, making it unstable across tasks and models. In this work, we revisit entropy regularization in RLVR and argue that its potential has been largely underestimated. Our analysis shows that (i) tasks of varying difficulty demand distinct exploration intensities, and (ii) balanced exploration may require the policy entropy to be maintained within a moderate range below its initial level. Therefore, we propose Adaptive Entropy Regularization (AER)--a framework that dynamically balances exploration and exploitation via three components: difficulty-aware coefficient allocation, initial-anchored target entropy, and dynamic global coefficient adjustment. Experiments on multiple mathematical reasoning benchmarks show that AER consistently outperforms baselines, improving both reasoning accuracy and exploration capability. 

**Abstract (ZH)**: 基于可验证奖励的强化学习推理能力提升中自适应熵正则化方法 

---
# Project-Level C-to-Rust Translation via Synergistic Integration of Knowledge Graphs and Large Language Models 

**Title (ZH)**: 基于知识图谱和大型语言模型协同集成的项目级C到Rust翻译方法 

**Authors**: Zhiqiang Yuan, Wenjun Mao, Zhuo Chen, Xiyue Shang, Chong Wang, Yiling Lou, Xin Peng  

**Link**: [PDF](https://arxiv.org/pdf/2510.10956)  

**Abstract**: Translating C code into safe Rust is an effective way to ensure its memory safety. Compared to rule-based translation which produces Rust code that remains largely unsafe, LLM-based methods can generate more idiomatic and safer Rust code because LLMs have been trained on vast amount of human-written idiomatic code. Although promising, existing LLM-based methods still struggle with project-level C-to-Rust translation. They typically partition a C project into smaller units (\eg{} functions) based on call graphs and translate them bottom-up to resolve program dependencies. However, this bottom-up, unit-by-unit paradigm often fails to translate pointers due to the lack of a global perspective on their usage. To address this problem, we propose a novel C-Rust Pointer Knowledge Graph (KG) that enriches a code-dependency graph with two types of pointer semantics: (i) pointer-usage information which record global behaviors such as points-to flows and map lower-level struct usage to higher-level units; and (ii) Rust-oriented annotations which encode ownership, mutability, nullability, and lifetime. Synthesizing the \kg{} with LLMs, we further propose \ourtool{}, which implements a project-level C-to-Rust translation technique. In \ourtool{}, the \kg{} provides LLMs with comprehensive pointer semantics from a global perspective, thus guiding LLMs towards generating safe and idiomatic Rust code from a given C project. Our experiments show that \ourtool{} reduces unsafe usages in translated Rust by 99.9\% compared to both rule-based translation and traditional LLM-based rewriting, while achieving an average 29.3\% higher functional correctness than those fuzzing-enhanced LLM methods. 

**Abstract (ZH)**: 将C代码翻译成安全的Rust代码是确保其内存安全的有效方式。与基于规则的翻译方法相比，基于LLM的方法可以生成更多地道且安全的Rust代码，因为LLMs已经训练了大量的人类编写的地道代码。尽管前景广阔，现有的基于LLM的方法在项目级C到Rust翻译方面仍然面临挑战。它们通常基于调用图将C项目拆分为较小的单元（例如函数），并从下至上进行翻译以解决程序依赖关系。然而，这种从下至上、逐单元的范式往往由于缺乏对指针使用全局视角而无法正确翻译指针。为了解决这个问题，我们提出了一种新型的C-Rust指针知识图谱（KG），它在代码依赖图中丰富了两种类型的指针语义：（i）指针使用信息，记录全局行为如指向流，并将低级别的结构使用映射到高级别的单元；（ii）面向Rust的注释，编码所有权、可变性和可为空性以及生命周期。结合知识图谱与LLM，我们进一步提出了\ourtool{}，其实现了项目级C到Rust的翻译技术。在\ourtool{}中，知识图谱为LLM提供了从全局视角的全面指针语义，从而引导LLM从给定的C项目生成安全且地道的Rust代码。我们的实验表明，与基于规则的翻译和传统的基于LLM的重写方法相比，\ourtool{}将翻译后的Rust中不安全使用的比例降低了99.9%，同时比那些增强的模糊测试的LLM方法的平均功能正确性提高了29.3%。 

---
# Unify Variables in Neural Scaling Laws for General Audio Representations via Embedding Effective Rank 

**Title (ZH)**: 通过嵌入有效秩统一神经尺度定律中的变量以实现通用音频表示 

**Authors**: Xuyao Deng, Yanjie Sun, Yong Dou, Kele Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10948)  

**Abstract**: Scaling laws have profoundly shaped our understanding of model performance in computer vision and natural language processing, yet their application to general audio representation learning remains underexplored. A key challenge lies in the multifactorial nature of general audio representation-representation quality is jointly influenced by variables such as audio length, embedding dimensionality, model depth, model architecture, data volume, etc., many of which are difficult to isolate or express analytically. In this work, we present a systematic study of scaling laws for general audio representations by utilizing embedding effective rank (RankMe) as a unifying metric that encapsulates the impact of diverse variables on representation quality. RankMe enables a label-free, information-theoretic quantification of audio embeddings, allowing us to examine scaling behaviors across a wide hyper-parameter space, including model size, training data volume, computational budget, architectural configurations, etc. Our empirical findings reveal a consistent power-law relationship between RankMe and representation quality, suggesting that embedding effective rank serves as a reliable proxy for assessing and predicting model performance in audio representation learning. This work not only validates the applicability of classical scaling principles to the general audio domain but also offers a theoretically grounded and empirically robust framework for guiding future model scaling strategies in audio foundation models. 

**Abstract (ZH)**: 尺度规律在塑造计算机视觉和自然语言处理中模型性能理解方面发挥了深远影响，但在通用音频表示学习中的应用仍鲜有人探索。一个关键挑战在于多因素性，通用音频表示的质量由音频长度、嵌入维度、模型深度、模型架构、数据量等多种变量共同影响，其中许多变量难以分离或通过分析表达。在本文中，我们通过使用嵌入有效秩（RankMe）作为一个统一的指标，系统地研究了通用音频表示的尺度规律，RankMe能综合反映多种变量对表示质量的影响。RankMe允许我们通过信息论方式无标签地量化音频嵌入，从而使我们能够跨越包括模型大小、训练数据量、计算预算、架构配置等广泛超参数空间来研究规模效应。我们的实证研究发现，RankMe与表示质量之间存在一致的幂律关系，这表明嵌入有效秩可以作为评估和预测音频表示学习中模型性能的可靠代理。本研究不仅验证了经典尺度原则在通用音频领域的适用性，还为指导未来音频基础模型的规模策略提供了理论依据和实证支持框架。 

---
# Redundancy as a Structural Information Principle for Learning and Generalization 

**Title (ZH)**: 冗余作为学习和泛化的结构信息原则 

**Authors**: Yuda Bi, Ying Zhu, Vince D Calhoun  

**Link**: [PDF](https://arxiv.org/pdf/2510.10938)  

**Abstract**: We present a theoretical framework that extends classical information theory to finite and structured systems by redefining redundancy as a fundamental property of information organization rather than inefficiency. In this framework, redundancy is expressed as a general family of informational divergences that unifies multiple classical measures, such as mutual information, chi-squared dependence, and spectral redundancy, under a single geometric principle. This reveals that these traditional quantities are not isolated heuristics but projections of a shared redundancy geometry. The theory further predicts that redundancy is bounded both above and below, giving rise to an optimal equilibrium that balances over-compression (loss of structure) and over-coupling (collapse). While classical communication theory favors minimal redundancy for transmission efficiency, finite and structured systems, such as those underlying real-world learning, achieve maximal stability and generalization near this equilibrium. Experiments with masked autoencoders are used to illustrate and verify this principle: the model exhibits a stable redundancy level where generalization peaks. Together, these results establish redundancy as a measurable and tunable quantity that bridges the asymptotic world of communication and the finite world of learning. 

**Abstract (ZH)**: 我们提出一个理论框架，将经典信息论扩展到有限和结构化的系统中，重新定义冗余作为信息组织的基本属性而非无效性。在这个框架中，冗余被表达为一套统一的信息差异的一般家族，这些差异统一了多个经典度量，如互信息、卡方依赖性和频谱冗余，在单一几何原理下。这揭示了这些传统量并不孤立，而是共享冗余几何学的投影。该理论进一步预测，冗余受到上下限的约束，产生一个最优平衡状态，平衡过度压缩（结构丧失）和过度耦合（坍塌）。虽然经典通信理论倾向于最小的冗余以提高传输效率，但在诸如现实世界学习所依托的有限和结构化系统中，接近这一平衡状态时会实现最大稳定性与泛化能力。用掩蔽自编码器的实验来说明并验证这一原理：模型显示一个稳定的冗余水平，在该水平上泛化能力达到峰值。总之，这些结果确立了冗余作为一个可测量和可调节的量，连接了通信领域的渐近世界和学习领域的有限世界。 

---
# TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models 

**Title (ZH)**: TabVLA: 面向视觉-语言-行动模型的 targeted 后门攻击 

**Authors**: Zonghuan Xu, Xiang Zheng, Xingjun Ma, Yu-Gang Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10932)  

**Abstract**: With the growing deployment of Vision-Language-Action (VLA) models in real-world embodied AI systems, their increasing vulnerability to backdoor attacks poses a serious safety threat. A backdoored VLA agent can be covertly triggered by a pre-injected backdoor to execute adversarial actions, potentially causing system failures or even physical harm. Although backdoor attacks on VLA models have been explored, prior work has focused only on untargeted attacks, leaving the more practically threatening scenario of targeted manipulation unexamined. In this paper, we study targeted backdoor attacks on VLA models and introduce TabVLA, a novel framework that enables such attacks via black-box fine-tuning. TabVLA explores two deployment-relevant inference-time threat models: input-stream editing and in-scene triggering. It formulates poisoned data generation as an optimization problem to improve attack effectivess. Experiments with OpenVLA-7B on the LIBERO benchmark reveal that the vision channel is the principal attack surface: targeted backdoors succeed with minimal poisoning, remain robust across variations in trigger design, and are degraded only by positional mismatches between fine-tuning and inference triggers. We also investigate a potential detection-based defense against TabVLA, which reconstructs latent visual triggers from the input stream to flag activation-conditioned backdoor samples. Our work highlights the vulnerability of VLA models to targeted backdoor manipulation and underscores the need for more advanced defenses. 

**Abstract (ZH)**: 随着视觉-语言-动作（VLA）模型在实际应用中嵌入式AI系统的部署增加，它们日益增长的后门攻击脆弱性对安全性构成了严重威胁。一个植入后门的VLA代理可能通过预先注入的后门被秘密触发执行敌意操作，可能会导致系统故障甚至物理伤害。尽管已经探讨了VLA模型的后门攻击，但先前的研究仅关注无目标攻击，而没有研究更具实际威胁的目标操纵场景。本文研究了VLA模型的目标后门攻击，并引入了TabVLA这一新框架，通过黑盒微调使这些攻击成为可能。TabVLA探讨了与部署相关的两种推理时威胁模型：输入流编辑和场景触发。它将有毒数据生成建模为优化问题以提高攻击效果。在LIBERO基准上使用OpenVLA-7B进行的实验揭示，视觉通道是主要的攻击面：目标后门在极小规模的中毒下就能成功，对触发设计的变化保持稳健，并且只有在微调和推理触发之间的位置不匹配时才会受到损害。我们还研究了对TabVLA潜在的基于检测的防御措施，该措施从输入流中重建潜在的视觉触发以标记条件激活的后门样本。我们的工作突显了VLA模型对目标后门操纵的脆弱性，并强调了需要更高级防御的必要性。 

---
# Evaluating Language Models' Evaluations of Games 

**Title (ZH)**: 评估语言模型对游戏的评价 

**Authors**: Katherine M. Collins, Cedegao E. Zhang, Graham Todd, Lance Ying, Mauricio Barba da Costa, Ryan Liu, Prafull Sharma, Adrian Weller, Ionatan Kuperwajs, Lionel Wong, Joshua B. Tenenbaum, Thomas L. Griffiths  

**Link**: [PDF](https://arxiv.org/pdf/2510.10930)  

**Abstract**: Reasoning is not just about solving problems -- it is also about evaluating which problems are worth solving at all. Evaluations of artificial intelligence (AI) systems primarily focused on problem solving, historically by studying how models play games such as chess and Go. In this paper, we advocate for a new paradigm that assesses AI systems' evaluation of games. First, we introduce a formalism for evaluating such evaluations. We then leverage a large-scale dataset of over $100$ novel board games and over 450 human judgments to compare evaluations produced by modern language and reasoning models against those of people and symbolic computational agents. We consider two kinds of evaluative queries: assessing the payoff (or fairness) and the funness of games. These queries span two dimensions relevant to the design of evaluations of AI evaluations: how complex a query is to compute and how difficult a query is to quantify. Our results show that reasoning models are generally more aligned to people in their evaluations of games than non-reasoning language models. However, we observe a non-monotonic relationship: as models get closer to game-theoretic optimal, their fit to human data weakens. We also observe more "jaggedness" across models for assessing funness, in line with the greater difficulty of quantifying this query. Across queries and games, reasoning models show highly variable and unpredictable resource usage when assessing queries, pointing to the importance of imbuing more resource-rational meta-reasoning in language and reasoning models. 

**Abstract (ZH)**: 推理不仅仅关于解决问题——它还关乎评估哪些问题是值得解决的。本文提倡一种新的范式，评估AI系统对游戏的评估。我们首先引入一种形式化方法来评估这些评估。然后，我们利用超过100种新型棋盘游戏和超过450个人类判断的大规模数据集，将现代语言和推理模型生成的游戏评估与人类和象征性计算代理的评估进行比较。我们考虑两类评估查询：评估收益（或公平性）和乐趣。这些查询涵盖了评估AI评估设计的两个维度：计算查询的复杂性和量化查询的难度。我们的结果表明，推理模型在评估游戏方面往往与人类的评估更一致，但观察到一种非单调关系：随着模型接近博弈论最优，它们与人类数据的契合度减弱。我们还观察到，在评估乐趣方面，不同模型的行为更加“锯齿状”，这与量化这一查询的难度更大相关。在各类查询和游戏上，推理模型在评估查询时显示出高度变性和不可预测的资源使用，这突显了在语言和推理模型中嵌入更多资源理性元推理的重要性。 

---
# FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model 

**Title (ZH)**: FG-CLIP 2：一种双语细粒度跨模态对齐模型 

**Authors**: Chunyu Xie, Bin Wang, Fanjing Kong, Jincheng Li, Dawei Liang, Ji Ao, Dawei Leng, Yuhui Yin  

**Link**: [PDF](https://arxiv.org/pdf/2510.10921)  

**Abstract**: Fine-grained vision-language understanding requires precise alignment between visual content and linguistic descriptions, a capability that remains limited in current models, particularly in non-English settings. While models like CLIP perform well on global alignment, they often struggle to capture fine-grained details in object attributes, spatial relations, and linguistic expressions, with limited support for bilingual comprehension. To address these challenges, we introduce FG-CLIP 2, a bilingual vision-language model designed to advance fine-grained alignment for both English and Chinese. Our approach leverages rich fine-grained supervision, including region-text matching and long-caption modeling, alongside multiple discriminative objectives. We further introduce the Textual Intra-modal Contrastive (TIC) loss to better distinguish semantically similar captions. Trained on a carefully curated mixture of large-scale English and Chinese data, FG-CLIP 2 achieves powerful bilingual performance. To enable rigorous evaluation, we present a new benchmark for Chinese multimodal understanding, featuring long-caption retrieval and bounding box classification. Extensive experiments on 29 datasets across 8 tasks show that FG-CLIP 2 outperforms existing methods, achieving state-of-the-art results in both languages. We release the model, code, and benchmark to facilitate future research on bilingual fine-grained alignment. 

**Abstract (ZH)**: 细粒度跨模态理解要求视觉内容与语言描述之间精确对齐，当前模型在非英语环境中尤其难以实现这一能力。尽管CLIP等模型在全局对齐上表现良好，但在捕捉对象属性、空间关系和语言表达的细粒度细节方面仍有局限，且双语理解支持有限。为解决这些挑战，我们引入了FG-CLIP 2，一种旨在提升英日双语细粒度对齐的双语跨模态模型。我们的方法利用丰富的细粒度监督，包括区域-文本匹配和长描述建模，并结合多个判别性目标。此外，我们引入了文本内模态对比（TIC）损失，以更好地区分语义相似的描述。FG-CLIP 2 在大量精选的英汉混合数据上训练，实现了强大的双语性能。为了进行严格的评估，我们提出了一套针对中文多模态理解的新基准，包含长描述检索和边界框分类。在8个任务的29个数据集上的广泛实验显示，FG-CLIP 2 在双语中均超越现有方法，达到最新水平。我们发布了该模型、代码和基准以促进未来双语细粒度对齐的研究。 

---
# Comparative Explanations via Counterfactual Reasoning in Recommendations 

**Title (ZH)**: 基于反事实推理的推荐系统中比较解释 

**Authors**: Yi Yu, Zhenxing Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10920)  

**Abstract**: Explainable recommendation through counterfactual reasoning seeks to identify the influential aspects of items in recommendations, which can then be used as explanations. However, state-of-the-art approaches, which aim to minimize changes in product aspects while reversing their recommended decisions according to an aggregated decision boundary score, often lead to factual inaccuracies in explanations. To solve this problem, in this work we propose a novel method of Comparative Counterfactual Explanations for Recommendation (CoCountER). CoCountER creates counterfactual data based on soft swap operations, enabling explanations for recommendations of arbitrary pairs of comparative items. Empirical experiments validate the effectiveness of our approach. 

**Abstract (ZH)**: 通过反事实推理实现可解释推荐以识别推荐中具有影响力的项目方面，并将其用作解释。然而，最先进的方法在最小化产品方面变化的同时根据聚合的决策边界分数逆转其推荐决策，往往会导致解释中的事实不准确。为了解决这一问题，本文提出了一种名为Comparative Counterfactual Explanations for Recommendation (CoCountER) 的新型方法。CoCountER 通过软交换操作生成反事实数据，从而使解释能够应用于任意一对比较项目的推荐。实验证明了该方法的有效性。 

---
# DreamMakeup: Face Makeup Customization using Latent Diffusion Models 

**Title (ZH)**: DreamMakeup：使用潜在扩散模型的面部化妆个性化定制 

**Authors**: Geon Yeong Park, Inhwa Han, Serin Yang, Yeobin Hong, Seongmin Jeong, Heechan Jeon, Myeongjin Goh, Sung Won Yi, Jin Nam, Jong Chul Ye  

**Link**: [PDF](https://arxiv.org/pdf/2510.10918)  

**Abstract**: The exponential growth of the global makeup market has paralleled advancements in virtual makeup simulation technology. Despite the progress led by GANs, their application still encounters significant challenges, including training instability and limited customization capabilities. Addressing these challenges, we introduce DreamMakup - a novel training-free Diffusion model based Makeup Customization method, leveraging the inherent advantages of diffusion models for superior controllability and precise real-image editing. DreamMakeup employs early-stopped DDIM inversion to preserve the facial structure and identity while enabling extensive customization through various conditioning inputs such as reference images, specific RGB colors, and textual descriptions. Our model demonstrates notable improvements over existing GAN-based and recent diffusion-based frameworks - improved customization, color-matching capabilities, identity preservation and compatibility with textual descriptions or LLMs with affordable computational costs. 

**Abstract (ZH)**: 全球美妆市场的指数增长与虚拟美妆技术的进步 parallel 进展。尽管生成对抗网络（GANs）在推动这一进步方面发挥了重要作用，但其应用仍然面临着训练不稳定性和定制能力有限等显著挑战。为应对这些挑战，我们提出了一种名为 DreamMakup 的新型无训练自洽扩散模型美妆定制方法，利用扩散模型固有的优势实现更优的可控性和精确的现实图像编辑。DreamMakup 使用早停的 DDIM 反转来保留面部结构和身份，同时通过参考图像、特定的 RGB 颜色和文本描述等多种条件输入实现广泛的定制。我们的模型在定制能力、色彩匹配能力、身份保存以及与文本描述或便宜的计算成本的语言大模型（LLMs）兼容性方面显著优于现有的 GAN 基础和最近的扩散基础框架。 

---
# LPCVAE: A Conditional VAE with Long-Term Dependency and Probabilistic Time-Frequency Fusion for Time Series Anomaly Detection 

**Title (ZH)**: LPCVAE：一种具备长期依赖关系和概率时频融合的条件VAE的时间序列异常检测方法 

**Authors**: Hanchang Cheng, Weimin Mu, Fan Liu, Weilin Zhu, Can Ma  

**Link**: [PDF](https://arxiv.org/pdf/2510.10915)  

**Abstract**: Time series anomaly detection(TSAD) is a critical task in signal processing field, ensuring the reliability of complex systems. Reconstruction-based methods dominate in TSAD. Among these methods, VAE-based methods have achieved promising results. Existing VAE-based methods suffer from the limitation of single-window feature and insufficient leveraging of long-term time and frequency information. We propose a Conditional Variational AutoEncoder with Long-term dependency and Probabilistic time-frequency fusion, named LPCVAE. LPCVAE introduces LSTM to capture long-term dependencies beyond windows. It further incorporates a Product-of-Experts (PoE) mechanism for adaptive and distribution-level probabilistic fusion. This design effectively mitigates time-frequency information loss. Extensive experiments on four public datasets demonstrate it outperforms state-of-the-art methods. The results confirm that integrating long-term time and frequency representations with adaptive fusion yields a robust and efficient solution for TSAD. 

**Abstract (ZH)**: 基于长期依赖和概率时间频率融合的条件变分自编码器在时间序列异常检测中的应用 

---
# Topological Alignment of Shared Vision-Language Embedding Space 

**Title (ZH)**: 共享视觉-语言嵌入空间的拓扑对齐 

**Authors**: Junwon You, Dasol Kang, Jae-Hun Jung  

**Link**: [PDF](https://arxiv.org/pdf/2510.10889)  

**Abstract**: Contrastive Vision-Language Models (VLMs) have demonstrated strong zero-shot capabilities. However, their cross-modal alignment remains biased toward English due to limited multilingual multimodal data. Recent multilingual extensions have alleviated this gap but enforce instance-level alignment while neglecting the global geometry of the shared embedding space. We address this problem by introducing ToMCLIP (Topological Alignment for Multilingual CLIP), a topology-aware framework aligning embedding spaces with topology-preserving constraints. The proposed method applies persistent homology to define a topological alignment loss and approximates persistence diagram with theoretical error bounds using graph sparsification strategy. This work validates the proposed approach, showing enhanced structural coherence of multilingual representations, higher zero-shot accuracy on the CIFAR-100, and stronger multilingual retrieval performance on the xFlickr&CO. Beyond VLMs, the proposed approach provides a general method for incorporating topological alignment into representation learning. 

**Abstract (ZH)**: 拓扑意识的多语文本-图像对齐框架：ToMCLIP（拓扑约束下的多语文本-图像对齐） 

---
# Generative AI for Software Project Management: Insights from a Review of Software Practitioner Literature 

**Title (ZH)**: 生成式AI在软件项目管理中的应用：基于软件从业者文献的见解 

**Authors**: Lakshana Iruni Assalaarachchi, Zainab Masood, Rashina Hoda, John Grundy  

**Link**: [PDF](https://arxiv.org/pdf/2510.10887)  

**Abstract**: Software practitioners are discussing GenAI transformations in software project management openly and widely. To understand the state of affairs, we performed a grey literature review using 47 publicly available practitioner sources including blogs, articles, and industry reports. We found that software project managers primarily perceive GenAI as an "assistant", "copilot", or "friend" rather than as a "PM replacement", with support of GenAI in automating routine tasks, predictive analytics, communication and collaboration, and in agile practices leading to project success. Practitioners emphasize responsible GenAI usage given concerns such as hallucinations, ethics and privacy, and lack of emotional intelligence and human judgment. We present upskilling requirements for software project managers in the GenAI era mapped to the Project Management Institute's talent triangle. We share key recommendations for both practitioners and researchers. 

**Abstract (ZH)**: 软件从业人员公开广泛地讨论着GenAI在软件项目管理中的转型。为了了解现状，我们使用47份公开可用的从业人员来源（包括博客、文章和行业报告）进行了灰色文献综述。我们发现，软件项目管理人员主要将GenAI视为“助手”、“副驾驶”或“朋友”，而非“项目经理的替代者”。从业者指出，GenAI在自动化常规任务、预测分析、沟通协作以及敏捷实践中的支持有助于项目成功。考虑到幻觉、伦理和隐私等问题，以及缺乏情感智能和人类判断，从业者强调负责任地使用GenAI。我们根据项目管理协会的人才三角模型，提出了软件项目管理人员在GenAI时代的再技能培训需求，并分享了针对从业人员和研究者的关键建议。 

---
# GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments 

**Title (ZH)**: GRIP：一种基于网格的中继与共现意识规划的统一框架 

**Authors**: Ahmed Alanazi, Duy Ho, Yugyung Lee  

**Link**: [PDF](https://arxiv.org/pdf/2510.10865)  

**Abstract**: Robots navigating dynamic, cluttered, and semantically complex environments must integrate perception, symbolic reasoning, and spatial planning to generalize across diverse layouts and object categories. Existing methods often rely on static priors or limited memory, constraining adaptability under partial observability and semantic ambiguity. We present GRIP, Grid-based Relay with Intermediate Planning, a unified, modular framework with three scalable variants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic occupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and LLM-based introspection; and GRIP-R (Real-World), enabling physical robot deployment under perceptual uncertainty. GRIP integrates dynamic 2D grid construction, open-vocabulary object grounding, co-occurrence-aware symbolic planning, and hybrid policy execution using behavioral cloning, D* search, and grid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks show that GRIP achieves up to 9.6% higher success rates and over $2\times$ improvement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative analyses reveal interpretable symbolic plans in ambiguous scenes. Real-world deployment on a Jetbot further validates GRIP's generalization under sensor noise and environmental variation. These results position GRIP as a robust, scalable, and explainable framework bridging simulation and real-world navigation. 

**Abstract (ZH)**: 基于网格的中间规划框架GRIP：动态、杂乱且语义复杂的环境下的导航 

---
# HeroFilter: Adaptive Spectral Graph Filter for Varying Heterophilic Relations 

**Title (ZH)**: HeroFilter：自适应谱图滤波器用于变化的异质关系 

**Authors**: Shuaicheng Zhang, Haohui Wang, Junhong Lin, Xiaojie Guo, Yada Zhu, Si Zhang, Dongqi Fu, Dawei Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.10864)  

**Abstract**: Graph heterophily, where connected nodes have different labels, has attracted significant interest recently. Most existing works adopt a simplified approach - using low-pass filters for homophilic graphs and high-pass filters for heterophilic graphs. However, we discover that the relationship between graph heterophily and spectral filters is more complex - the optimal filter response varies across frequency components and does not follow a strict monotonic correlation with heterophily degree. This finding challenges conventional fixed filter designs and suggests the need for adaptive filtering to preserve expressiveness in graph embeddings. Formally, natural questions arise: Given a heterophilic graph G, how and to what extent will the varying heterophily degree of G affect the performance of GNNs? How can we design adaptive filters to fit those varying heterophilic connections? Our theoretical analysis reveals that the average frequency response of GNNs and graph heterophily degree do not follow a strict monotonic correlation, necessitating adaptive graph filters to guarantee good generalization performance. Hence, we propose [METHOD NAME], a simple yet powerful GNN, which extracts information across the heterophily spectrum and combines salient representations through adaptive mixing. [METHOD NAME]'s superior performance achieves up to 9.2% accuracy improvement over leading baselines across homophilic and heterophilic graphs. 

**Abstract (ZH)**: 图的异质性，其中连接的节点具有不同的标签，近年来引起了广泛关注。大多数现有工作采用简化的方法——对同质图使用低通滤波器，对异质图使用高通滤波器。然而，我们发现图的异质性与频谱滤波器之间的关系更为复杂——最优滤波器响应随频率成分的不同而变化，并不严格遵循异质性程度的单调相关关系。这一发现挑战了传统的固定滤波器设计，并提示需要自适应滤波来保持图嵌入的表达性。正式地，自然地提出了一些问题：给定一个异质图G，G的异质性程度变化如何以及在多大程度上影响GNNs的性能？我们如何设计自适应滤波器来适应这些变化的异质连接？我们的理论分析表明，GNNs的平均频率响应与图的异质性程度之间并不严格遵循单调相关关系，这需要自适应图滤波器来保证良好的泛化性能。因此，我们提出了一种简单而强大的GNN [METHOD NAME]，它提取跨异质性光谱的信息，并通过自适应混合结合关键表示。[METHOD NAME]在同质图和异质图上的表现 superior，相对于领先的基础模型取得了高达9.2%的准确性提升。 

---
# Discrete State Diffusion Models: A Sample Complexity Perspective 

**Title (ZH)**: 离散状态扩散模型：一种样本复杂性视角 

**Authors**: Aadithya Srikanth, Mudit Gaur, Vaneet Aggarwal  

**Link**: [PDF](https://arxiv.org/pdf/2510.10854)  

**Abstract**: Diffusion models have demonstrated remarkable performance in generating high-dimensional samples across domains such as vision, language, and the sciences. Although continuous-state diffusion models have been extensively studied both empirically and theoretically, discrete-state diffusion models, essential for applications involving text, sequences, and combinatorial structures, remain significantly less understood from a theoretical standpoint. In particular, all existing analyses of discrete-state models assume score estimation error bounds without studying sample complexity results. In this work, we present a principled theoretical framework for discrete-state diffusion, providing the first sample complexity bound of $\widetilde{\mathcal{O}}(\epsilon^{-2})$. Our structured decomposition of the score estimation error into statistical, approximation, optimization, and clipping components offers critical insights into how discrete-state models can be trained efficiently. This analysis addresses a fundamental gap in the literature and establishes the theoretical tractability and practical relevance of discrete-state diffusion models. 

**Abstract (ZH)**: 离散状态扩散模型在视觉、语言和科学等领域生成高维样本方面展现了显著性能。尽管连续状态扩散模型在实验和理论研究中均得到了广泛探讨，但涉及文本、序列和组合结构应用的离散状态扩散模型在理论上仍远未得到充分理解。特别地，现有所有关于离散状态模型的分析都基于评分估计误差界而未研究样本复杂度结果。在本工作中，我们提出了一个严谨的理论框架来研究离散状态扩散模型，并提供了首个样本复杂度界$\widetilde{\mathcal{O}}(\epsilon^{-2})$。我们结构化的评分估计误差分解为统计、近似、优化和截断四项，为高效训练离散状态模型提供了关键见解。这项分析填补了文献中的一个基本空白，并确立了离散状态扩散模型的理论可处理性和实际相关性。 

---
# Software Defect Prediction using Autoencoder Transformer Model 

**Title (ZH)**: 使用自动编码器变压器模型的软件缺陷预测 

**Authors**: Seshu Barma, Mohanakrishnan Hariharan, Satish Arvapalli  

**Link**: [PDF](https://arxiv.org/pdf/2510.10840)  

**Abstract**: An AI-ML-powered quality engineering approach uses AI-ML to enhance software quality assessments by predicting defects. Existing ML models struggle with noisy data types, imbalances, pattern recognition, feature extraction, and generalization. To address these challenges, we develop a new model, Adaptive Differential Evolution (ADE) based Quantum Variational Autoencoder-Transformer (QVAET) Model (ADE-QVAET). ADE combines with QVAET to obtain high-dimensional latent features and maintain sequential dependencies, resulting in enhanced defect prediction accuracy. ADE optimization enhances model convergence and predictive performance. ADE-QVAET integrates AI-ML techniques such as tuning hyperparameters for scalable and accurate software defect prediction, representing an AI-ML-driven technology for quality engineering. During training with a 90% training percentage, ADE-QVAET achieves high accuracy, precision, recall, and F1-score of 98.08%, 92.45%, 94.67%, and 98.12%, respectively, when compared to the Differential Evolution (DE) ML model. 

**Abstract (ZH)**: 基于AI-ML的动力质量工程方法通过预测缺陷来增强软件质量评估 

---
# VeritasFi: An Adaptable, Multi-tiered RAG Framework for Multi-modal Financial Question Answering 

**Title (ZH)**: VeritasFi：一种适应性强的多层级RAG框架用于多模态金融问答 

**Authors**: Zhenghan Tai, Hanwei Wu, Qingchen Hu, Jijun Chi, Hailin He, Lei Ding, Tung Sum Thomas Kwok, Bohuai Xiao, Yuchen Hua, Suyuchen Wang, Peng Lu, Muzhi Li, Yihong Wu, Liheng Ma, Jerry Huang, Jiayi Zhang, Gonghao Zhang, Chaolong Jiang, Jingrui Tian, Sicheng Lyu, Zeyu Li, Boyu Han, Fengran Mo, Xinyue Yu, Yufei Cui, Ling Zhou, Xinyu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10828)  

**Abstract**: Retrieval-Augmented Generation (RAG) is becoming increasingly essential for Question Answering (QA) in the financial sector, where accurate and contextually grounded insights from complex public disclosures are crucial. However, existing financial RAG systems face two significant challenges: (1) they struggle to process heterogeneous data formats, such as text, tables, and figures; and (2) they encounter difficulties in balancing general-domain applicability with company-specific adaptation. To overcome these challenges, we present VeritasFi, an innovative hybrid RAG framework that incorporates a multi-modal preprocessing pipeline alongside a cutting-edge two-stage training strategy for its re-ranking component. VeritasFi enhances financial QA through three key innovations: (1) A multi-modal preprocessing pipeline that seamlessly transforms heterogeneous data into a coherent, machine-readable format. (2) A tripartite hybrid retrieval engine that operates in parallel, combining deep multi-path retrieval over a semantically indexed document corpus, real-time data acquisition through tool utilization, and an expert-curated memory bank for high-frequency questions, ensuring comprehensive scope, accuracy, and efficiency. (3) A two-stage training strategy for the document re-ranker, which initially constructs a general, domain-specific model using anonymized data, followed by rapid fine-tuning on company-specific data for targeted applications. By integrating our proposed designs, VeritasFi presents a groundbreaking framework that greatly enhances the adaptability and robustness of financial RAG systems, providing a scalable solution for both general-domain and company-specific QA tasks. Code accompanying this work is available at this https URL. 

**Abstract (ZH)**: 检索增强生成（RAG）对于金融领域的问答（QA）变得日益重要，因为准确且上下文相关的大规模财务披露洞察至关重要。然而，现有的金融RAG系统面临两大挑战：（1）它们难以处理异构数据格式，如文本、表格和图表；（2）难以在通用领域适用性和公司特定适应性之间取得平衡。为了克服这些挑战，我们提出了VeritasFi，一种创新的混合RAG框架，结合了多模态预处理管道和最新的两阶段训练策略，用于其重排组件。VeritasFi通过三项创新提升金融问答：（1）一个无缝转换异构数据为一致、机器可读格式的多模态预处理管道；（2）一个三元混合检索引擎，同时运行，结合深层多路径检索、实时数据采集以及由专家策展的高频问题记忆库，确保全面的范围、准确性和效率；（3）两个阶段的训练策略，用于文档重排名，首先使用匿名数据构建通用领域特定模型，然后迅速在公司特定数据上进行微调以实现目标应用。通过集成我们提出的设计，VeritasFi展示了大幅增强金融RAG系统适应性和鲁棒性的突破性框架，提供了一种可扩展的解决方案，适用于通用领域和公司特定的问答任务。与此工作相关联的代码可在以下网址获取。 

---
# Happiness is Sharing a Vocabulary: A Study of Transliteration Methods 

**Title (ZH)**: 幸福在于共享词汇：音译方法研究 

**Authors**: Haeji Jung, Jinju Kim, Kyungjin Kim, Youjeong Roh, David R. Mortensen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10827)  

**Abstract**: Transliteration has emerged as a promising means to bridge the gap between various languages in multilingual NLP, showing promising results especially for languages using non-Latin scripts. We investigate the degree to which shared script, overlapping token vocabularies, and shared phonology contribute to performance of multilingual models. To this end, we conduct controlled experiments using three kinds of transliteration (romanization, phonemic transcription, and substitution ciphers) as well as orthography. We evaluate each model on two downstream tasks -- named entity recognition (NER) and natural language inference (NLI) -- and find that romanization significantly outperforms other input types in 7 out of 8 evaluation settings, largely consistent with our hypothesis that it is the most effective approach. We further analyze how each factor contributed to the success, and suggest that having longer (subword) tokens shared with pre-trained languages leads to better utilization of the model. 

**Abstract (ZH)**: 多语言NLP中转写已成为缩小各种语言之间差距的有前途的方法，特别是在使用非拉丁字母-script的语言中显示出有前途的结果。我们研究了共享字母表、重叠词汇表以及共享音韵特征对多语言模型性能的贡献程度。为此，我们使用三种类型的转写（ romanization、音素转写和替换密码）以及 orthography 进行了受控实验。我们分别在命名实体识别（NER）和自然语言推理（NLI）两个下游任务上评估每个模型，并发现在7种8种评估设置中有7种情况下，romanization 显著优于其他输入类型，这基本符合我们的假设，即这是最有效的方法。我们还分析了每个因素对成功的贡献，并建议与预训练语言共享更长（子词）令牌可以更好地利用模型。 

---
# Agentic RAG for Software Testing with Hybrid Vector-Graph and Multi-Agent Orchestration 

**Title (ZH)**: 基于混合向量-图和多代理协调的软件测试代理记忆辅助系统 

**Authors**: Mohanakrishnan Hariharan, Satish Arvapalli, Seshu Barma, Evangeline Sheela  

**Link**: [PDF](https://arxiv.org/pdf/2510.10824)  

**Abstract**: We present an approach to software testing automation using Agentic Retrieval-Augmented Generation (RAG) systems for Quality Engineering (QE) artifact creation. We combine autonomous AI agents with hybrid vector-graph knowledge systems to automate test plan, case, and QE metric generation. Our approach addresses traditional software testing limitations by leveraging LLMs such as Gemini and Mistral, multi-agent orchestration, and enhanced contextualization. The system achieves remarkable accuracy improvements from 65% to 94.8% while ensuring comprehensive document traceability throughout the quality engineering lifecycle. Experimental validation of enterprise Corporate Systems Engineering and SAP migration projects demonstrates an 85% reduction in testing timeline, an 85% improvement in test suite efficiency, and projected 35% cost savings, resulting in a 2-month acceleration of go-live. 

**Abstract (ZH)**: 使用Agentic Retrieval-Augmented Generation (RAG) 系统进行质量工程（QE） artifacts 自动化生成的方法 

---
# From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis 

**Title (ZH)**: 从检测到缓解：解决胸部X光诊断深度学习模型中的偏见 

**Authors**: Clemence Mottez, Louisa Fay, Maya Varma, Sophie Ostmeier, Curtis Langlotz  

**Link**: [PDF](https://arxiv.org/pdf/2510.10822)  

**Abstract**: Deep learning models have shown promise in improving diagnostic accuracy from chest X-rays, but they also risk perpetuating healthcare disparities when performance varies across demographic groups. In this work, we present a comprehensive bias detection and mitigation framework targeting sex, age, and race-based disparities when performing diagnostic tasks with chest X-rays. We extend a recent CNN-XGBoost pipeline to support multi-label classification and evaluate its performance across four medical conditions. We show that replacing the final layer of CNN with an eXtreme Gradient Boosting classifier improves the fairness of the subgroup while maintaining or improving the overall predictive performance. To validate its generalizability, we apply the method to different backbones, namely DenseNet-121 and ResNet-50, and achieve similarly strong performance and fairness outcomes, confirming its model-agnostic design. We further compare this lightweight adapter training method with traditional full-model training bias mitigation techniques, including adversarial training, reweighting, data augmentation, and active learning, and find that our approach offers competitive or superior bias reduction at a fraction of the computational cost. Finally, we show that combining eXtreme Gradient Boosting retraining with active learning yields the largest reduction in bias across all demographic subgroups, both in and out of distribution on the CheXpert and MIMIC datasets, establishing a practical and effective path toward equitable deep learning deployment in clinical radiology. 

**Abstract (ZH)**: 深度学习模型在提高胸部X光诊断准确性方面显示出潜力，但同时也可能由于不同人群组之间的性能差异而加剧医疗保健不平等。本研究提出了一种综合偏见检测与缓解框架，旨在解决胸部X光诊断任务中基于性别、年龄和种族的不平等现象。我们将最近的CNN-XGBoost管道扩展以支持多标签分类，并在其上评估四种医学条件的表现。结果显示，用极端梯度提升分类器替换CNN的最后一层可以提高子群体的公平性，同时保持或提高总体预测性能。为了验证其通用性，我们将该方法应用于不同的骨干网络，即DenseNet-121和ResNet-50，并获得了相似的强性能和公平性结果，证明其具有模型无关性设计。我们进一步将该轻量级适配器训练方法与传统的全模型训练偏见缓解技术（包括对抗训练、重权分配、数据增强和主动学习）进行了比较，并发现我们的方法在计算成本大幅度降低的情况下提供了竞争力或更优越的偏见减少效果。最后，我们展示了结合极端梯度提升重新训练与主动学习可以最大程度地减少所有人口子群体中的偏见，在CheXpert和MIMIC数据集中分布内和分布外均是如此，为临床放射学中公平的深度学习部署提供了切实有效的方法。 

---
# Generative AI and the Transformation of Software Development Practices 

**Title (ZH)**: 生成式人工智能与软件开发实践的转型 

**Authors**: Vivek Acharya  

**Link**: [PDF](https://arxiv.org/pdf/2510.10819)  

**Abstract**: Generative AI is reshaping how software is designed, written, and maintained. Advances in large language models (LLMs) are enabling new development styles - from chat-oriented programming and 'vibe coding' to agentic programming - that can accelerate productivity and broaden access. This paper examines how AI-assisted techniques are changing software engineering practice, and the related issues of trust, accountability, and shifting skills. We survey iterative chat-based development, multi-agent systems, dynamic prompt orchestration, and integration via the Model Context Protocol (MCP). Using case studies and industry data, we outline both the opportunities (faster cycles, democratized coding) and the challenges (model reliability and cost) of applying generative AI to coding. We describe new roles, skills, and best practices for using AI in a responsible and effective way. 

**Abstract (ZH)**: 生成式AI正在重塑软件的设计、编写和维护方式。大规模语言模型的进步正推动新的开发模式——从聊天导向编程和“氛围编码”到代理式编程——这些模式能够提高生产力并扩大访问范围。本文探讨了AI辅助技术如何改变软件工程实践，以及相关的问题，如信任、问责和技能转移。我们概述了迭代聊天式开发、多智能体系统、动态提示编排以及通过模型上下文协议（MCP）集成的情况，并结合案例研究和行业数据，阐明将生成式AI应用于编码的机遇与挑战。我们描述了在负责任和有效的方式下使用AI的新角色、技能和最佳实践。 

---
# Is Implicit Knowledge Enough for LLMs? A RAG Approach for Tree-based Structures 

**Title (ZH)**: LLMs中隐性知识是否足够？基于RAG的树状结构检索方法 

**Authors**: Mihir Gupte, Paolo Giusto, Ramesh S  

**Link**: [PDF](https://arxiv.org/pdf/2510.10806)  

**Abstract**: Large Language Models (LLMs) are adept at generating responses based on information within their context. While this ability is useful for interacting with structured data like code files, another popular method, Retrieval-Augmented Generation (RAG), retrieves relevant documents to augment the model's in-context learning. However, it is not well-explored how to best represent this retrieved knowledge for generating responses on structured data, particularly hierarchical structures like trees. In this work, we propose a novel bottom-up method to linearize knowledge from tree-like structures (like a GitHub repository) by generating implicit, aggregated summaries at each hierarchical level. This approach enables the knowledge to be stored in a knowledge base and used directly with RAG. We then compare our method to using RAG on raw, unstructured code, evaluating the accuracy and quality of the generated responses. Our results show that while response quality is comparable across both methods, our approach generates over 68% fewer documents in the retriever, a significant gain in efficiency. This finding suggests that leveraging implicit, linearized knowledge may be a highly effective and scalable strategy for handling complex, hierarchical data structures. 

**Abstract (ZH)**: 大型语言模型（LLMs）能够基于上下文中的信息生成响应。虽然这一能力对于与结构化数据（如代码文件）交互很有用，另一种流行的方法——检索增强生成（RAG）——通过检索相关文档来增强模型的上下文学习能力。然而，关于如何最好地表示检索到的知识以生成结构化数据（特别是树状结构）的响应，尚未得到充分探索。在本文中，我们提出了一种新颖的自底向上的方法，通过生成每个层次结构级别的隐式聚合摘要来线性化类似树状结构的知识（如GitHub仓库）。这种方法使知识能够存储在知识库中，并直接与RAG结合使用。然后，我们将我们的方法与直接在RAG中使用原始非结构化代码进行比较，评估生成响应的准确性和质量。结果显示，虽然两种方法生成的响应质量相当，但我们的方法在检索器中生成的文档数量减少了超过68%，显示出显著的效率提升。这一发现表明，利用隐式、线性化的知识可能是处理复杂层次结构数据的有效且可扩展的方法。 

---
# Therapeutic AI and the Hidden Risks of Over-Disclosure: An Embedded AI-Literacy Framework for Mental Health Privacy 

**Title (ZH)**: therapeutic AI与过度披露的隐性风险：嵌入式AI素养框架下的精神健康隐私保护 

**Authors**: Soraya S. Anvari, Rina R. Wehbe  

**Link**: [PDF](https://arxiv.org/pdf/2510.10805)  

**Abstract**: Large Language Models (LLMs) are increasingly deployed in mental health contexts, from structured therapeutic support tools to informal chat-based well-being assistants. While these systems increase accessibility, scalability, and personalization, their integration into mental health care brings privacy and safety challenges that have not been well-examined. Unlike traditional clinical interactions, LLM-mediated therapy often lacks a clear structure for what information is collected, how it is processed, and how it is stored or reused. Users without clinical guidance may over-disclose personal information, which is sometimes irrelevant to their presenting concern, due to misplaced trust, lack of awareness of data risks, or the conversational design of the system. This overexposure raises privacy concerns and also increases the potential for LLM bias, misinterpretation, and long-term data misuse. We propose a framework embedding Artificial Intelligence (AI) literacy interventions directly into mental health conversational systems, and outline a study plan to evaluate their impact on disclosure safety, trust, and user experience. 

**Abstract (ZH)**: 大型语言模型（LLMs）在心理健康领域的应用从结构化的治疗支持工具扩展到了非正式的聊天式福祉助手。尽管这些系统提升了可访问性、可扩展性和个性化，但它们在心理健康护理中的集成带来了隐私和安全挑战，这些挑战尚未得到充分研究。不同于传统的临床互动，通过LLM介导的治疗往往缺乏对收集什么信息、如何处理、存储或重用这些信息的明确结构。没有临床指导的用户可能会因信任感缺失、不了解数据风险或系统的设计而过度披露个人信息，这信息有时与其当前的困扰无关。这种过度披露引发了隐私担忧，也增加了LLM偏见、误解释和长期数据滥用的风险。我们提出将人工智能（AI）素养干预直接嵌入心理健康对话系统中，并概述一项研究计划以评估其对披露安全、信任和用户体验的影响。 

---
# PruneGCRN: Minimizing and explaining spatio-temporal problems through node pruning 

**Title (ZH)**: PruneGCRN: 通过节点裁剪最小化和解释时空问题 

**Authors**: Javier García-Sigüenza, Mirco Nanni, Faraón Llorens-Largo, José F. Vicent  

**Link**: [PDF](https://arxiv.org/pdf/2510.10803)  

**Abstract**: This work addresses the challenge of using a deep learning model to prune graphs and the ability of this method to integrate explainability into spatio-temporal problems through a new approach. Instead of applying explainability to the model's behavior, we seek to gain a better understanding of the problem itself. To this end, we propose a novel model that integrates an optimized pruning mechanism capable of removing nodes from the graph during the training process, rather than doing so as a separate procedure. This integration allows the architecture to learn how to minimize prediction error while selecting the most relevant nodes. Thus, during training, the model searches for the most relevant subset of nodes, obtaining the most important elements of the problem, facilitating its analysis. To evaluate the proposed approach, we used several widely used traffic datasets, comparing the accuracy obtained by pruning with the model and with other methods. The experiments demonstrate that our method is capable of retaining a greater amount of information as the graph reduces in size compared to the other methods used. These results highlight the potential of pruning as a tool for developing models capable of simplifying spatio-temporal problems, thereby obtaining their most important elements. 

**Abstract (ZH)**: 本研究解决了使用深度学习模型修剪图结构的挑战，并提出了一种新方法，该方法通过将可解释性集成到时空问题中来增强模型的能力。该方法不是将可解释性应用于模型的行为，而是寻求更好地理解问题本身。为此，我们提出了一种新颖的模型，该模型集成了一个优化的修剪机制，在训练过程中能够从图中移除节点，而不需要将其作为单独的步骤进行。这种集成使得架构能够在选择最相关节点的同时学习如何最小化预测误差。因此，在训练过程中，模型会搜索最相关的节点子集，获得问题的重要元素，从而便于问题的分析。为了评估所提出的方法，我们使用了几种广泛使用的交通数据集，将修剪后的模型的准确性与完整模型和其他方法的准确性进行了比较。实验结果表明，与使用的方法相比，我们的方法能够在图结构减小的同时保留更多的信息。这些结果突显了修剪作为开发能够简化时空问题的模型工具的潜力，从而获取其最重要的元素。 

---
# MSCloudCAM: Cross-Attention with Multi-Scale Context for Multispectral Cloud Segmentation 

**Title (ZH)**: MSCloudCAM: 多尺度上下文的交叉注意力多光谱云分割 

**Authors**: Md Abdullah Al Mazid, Liangdong Deng, Naphtali Rishe  

**Link**: [PDF](https://arxiv.org/pdf/2510.10802)  

**Abstract**: Clouds remain a critical challenge in optical satellite imagery, hindering reliable analysis for environmental monitoring, land cover mapping, and climate research. To overcome this, we propose MSCloudCAM, a Cross-Attention with Multi-Scale Context Network tailored for multispectral and multi-sensor cloud segmentation. Our framework exploits the spectral richness of Sentinel-2 (CloudSEN12) and Landsat-8 (L8Biome) data to classify four semantic categories: clear sky, thin cloud, thick cloud, and cloud shadow. MSCloudCAM combines a Swin Transformer backbone for hierarchical feature extraction with multi-scale context modules ASPP and PSP for enhanced scale-aware learning. A Cross-Attention block enables effective multisensor and multispectral feature fusion, while the integration of an Efficient Channel Attention Block (ECAB) and a Spatial Attention Module adaptively refine feature representations. Comprehensive experiments on CloudSEN12 and L8Biome demonstrate that MSCloudCAM delivers state-of-the-art segmentation accuracy, surpassing leading baseline architectures while maintaining competitive parameter efficiency and FLOPs. These results underscore the model's effectiveness and practicality, making it well-suited for large-scale Earth observation tasks and real-world applications. 

**Abstract (ZH)**: 风云遥感影像中的云掩模问题仍然是光学卫星影像分析的关键挑战，阻碍了环境监测、土地覆盖制图和气候研究的可靠分析。为了解决这一问题，我们提出了MSCloudCAM，一种适用于多光谱和多传感器云分割的跨注意力多尺度上下文网络。该框架利用Sentinel-2（CloudSEN12）和Landsat-8（L8Biome）数据的光谱丰富性，用于分类四种语义类别：晴空、薄云、厚云和云影。MSCloudCAM 结合了Swin Transformer骨干网进行分层特征提取，以及 ASPP 和 PSP 多尺度上下文模块以增强尺度感知学习。跨注意力块实现了有效的多传感器和多光谱特征融合，而Efficient Channel Attention Block (ECAB) 和 Spatial Attention Module 的集成则适应性地细化特征表示。CloudSEN12 和 L8Biome 上的综合实验表明，MSCloudCAM 在分割精度上达到了最先进的水平，超越了领先的基本架构，同时保持了具有竞争力的参数效率和FLOPs。这些结果突显了该模型的有效性和实用性，使其适合于大规模地球观测任务和实际应用。 

---
# Toward Human-Centered Readability Evaluation 

**Title (ZH)**: 面向以人为中心的可读性评价 

**Authors**: Bahar İlgen, Georges Hattab  

**Link**: [PDF](https://arxiv.org/pdf/2510.10801)  

**Abstract**: Text simplification is essential for making public health information accessible to diverse populations, including those with limited health literacy. However, commonly used evaluation metrics in Natural Language Processing (NLP), such as BLEU, FKGL, and SARI, mainly capture surface-level features and fail to account for human-centered qualities like clarity, trustworthiness, tone, cultural relevance, and actionability. This limitation is particularly critical in high-stakes health contexts, where communication must be not only simple but also usable, respectful, and trustworthy. To address this gap, we propose the Human-Centered Readability Score (HCRS), a five-dimensional evaluation framework grounded in Human-Computer Interaction (HCI) and health communication research. HCRS integrates automatic measures with structured human feedback to capture the relational and contextual aspects of readability. We outline the framework, discuss its integration into participatory evaluation workflows, and present a protocol for empirical validation. This work aims to advance the evaluation of health text simplification beyond surface metrics, enabling NLP systems that align more closely with diverse users' needs, expectations, and lived experiences. 

**Abstract (ZH)**: 文本简化对于使公共健康信息易于不同人群获取，包括健康素养较低的人群，至关重要。然而，自然语言处理（NLP）中常用的评估指标，如BLEU、FKGL和SARI，主要捕捉表面特征，并未能考虑到以人为中心的质量，如清晰性、可信度、语调、文化相关性和可操作性。特别是在高风险的健康交流情境中，交流不仅要简单，还要易于使用、尊重并可信。为弥补这一不足，我们提出以人为本可读性评分（HCRS）框架，该框架结合了人机交互（HCI）和健康沟通研究。HCRS 将自动评估措施与结构化的人类反馈结合，以捕捉可读性的关系和上下文方面。我们概述了该框架，讨论了其如何融入参与式评估工作流程，并提出了实证验证的协议。本研究旨在超越表面指标，提升健康文本简化的评估，使得NLP系统更加贴近不同用户的需求、期望和生活体验。 

---
# BioOSS: A Bio-Inspired Oscillatory State System with Spatio-Temporal Dynamics 

**Title (ZH)**: BioOSS: 一种受生物启发的空间-时间动力学振荡状态系统 

**Authors**: Zhongju Yuan, Geraint Wiggins, Dick Botteldooren  

**Link**: [PDF](https://arxiv.org/pdf/2510.10790)  

**Abstract**: Today's deep learning architectures are primarily based on perceptron models, which do not capture the oscillatory dynamics characteristic of biological neurons. Although oscillatory systems have recently gained attention for their closer resemblance to neural behavior, they still fall short of modeling the intricate spatio-temporal interactions observed in natural neural circuits. In this paper, we propose a bio-inspired oscillatory state system (BioOSS) designed to emulate the wave-like propagation dynamics critical to neural processing, particularly in the prefrontal cortex (PFC), where complex activity patterns emerge. BioOSS comprises two interacting populations of neurons: p neurons, which represent simplified membrane-potential-like units inspired by pyramidal cells in cortical columns, and o neurons, which govern propagation velocities and modulate the lateral spread of activity. Through local interactions, these neurons produce wave-like propagation patterns. The model incorporates trainable parameters for damping and propagation speed, enabling flexible adaptation to task-specific spatio-temporal structures. We evaluate BioOSS on both synthetic and real-world tasks, demonstrating superior performance and enhanced interpretability compared to alternative architectures. 

**Abstract (ZH)**: 今天深度学习架构主要基于感知器模型，无法捕捉生物神经元的振荡动力学特性。尽管近年来振荡系统由于更接近神经行为而受到了关注，但仍不足以 modeling 天然神经回路中观察到的错综复杂的时空交互作用。本文提出了一种受生物启发的振荡状态系统（BioOSS），旨在模拟对于神经处理至关重要的波形传播动力学，特别是在前额叶皮层（PFC），复杂活动模式在此处出现。BioOSS 包含两种相互作用的神经元群体：p 神经元，代表由皮层柱中尖锋细胞启发的简化的膜电位样单元；o 神经元，控制传播速度并调节活动的侧向扩散。通过局部相互作用，这些神经元产生波形传播模式。该模型包含可训练参数，用于调整阻尼和传播速度，以适应特定任务的时空结构。我们在合成和真实任务上评估了 BioOSS，结果显示其性能更优且更具可解释性，优于其他架构。 

---
# DISC-GAN: Disentangling Style and Content for Cluster-Specific Synthetic Underwater Image Generation 

**Title (ZH)**: DISC-GAN: 解耦风格与内容以生成簇特定的合成水下图像 

**Authors**: Sneha Varur, Anirudh R Hanchinamani, Tarun S Bagewadi, Uma Mudenagudi, Chaitra D Desai, Sujata C, Padmashree Desai, Sumit Meharwade  

**Link**: [PDF](https://arxiv.org/pdf/2510.10782)  

**Abstract**: In this paper, we propose a novel framework, Disentangled Style-Content GAN (DISC-GAN), which integrates style-content disentanglement with a cluster-specific training strategy towards photorealistic underwater image synthesis. The quality of synthetic underwater images is challenged by optical due to phenomena such as color attenuation and turbidity. These phenomena are represented by distinct stylistic variations across different waterbodies, such as changes in tint and haze. While generative models are well-suited to capture complex patterns, they often lack the ability to model the non-uniform conditions of diverse underwater environments. To address these challenges, we employ K-means clustering to partition a dataset into style-specific domains. We use separate encoders to get latent spaces for style and content; we further integrate these latent representations via Adaptive Instance Normalization (AdaIN) and decode the result to produce the final synthetic image. The model is trained independently on each style cluster to preserve domain-specific characteristics. Our framework demonstrates state-of-the-art performance, obtaining a Structural Similarity Index (SSIM) of 0.9012, an average Peak Signal-to-Noise Ratio (PSNR) of 32.5118 dB, and a Frechet Inception Distance (FID) of 13.3728. 

**Abstract (ZH)**: 一种新颖的解耦风格-内容GAN框架：_DISC-GAN及其在水下图像合成中的应用 

---
# ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis 

**Title (ZH)**: ParsVoice: 一种大规模多说话人波斯语语音语料库，用于文本转语音合成 

**Authors**: Mohammad Javad Ranjbar Kalahroodi, Heshaam Faili, Azadeh Shakery  

**Link**: [PDF](https://arxiv.org/pdf/2510.10774)  

**Abstract**: Persian Language, despite being spoken by over 100 million people worldwide, remains severely underrepresented in high-quality speech corpora, particularly for text-to-speech (TTS) synthesis applications. Existing Persian speech datasets are typically smaller than their English counterparts, which creates a key limitation for developing Persian speech technologies. We address this gap by introducing ParsVoice, the largest Persian speech corpus designed specifically for TTS applications. We created an automated pipeline that transforms raw audiobook content into TTS-ready data, incorporating components such as a BERT-based sentence completion detector, a binary search boundary optimization method for precise audio-text alignment, and multi-dimensional quality assessment frameworks tailored to Persian. The pipeline processes 2,000 audiobooks, yielding 3,526 hours of clean speech, which was further filtered into a 1,804-hour high-quality subset suitable for TTS, featuring more than 470 speakers. ParsVoice is the largest high-quality Persian speech dataset, offering speaker diversity and audio quality comparable to major English corpora. The complete dataset has been made publicly available to accelerate the development of Persian speech technologies and to serve as a template for other low-resource languages. The ParsVoice dataset is publicly available at ParsVoice (this https URL). 

**Abstract (ZH)**: 尽管波斯语是全世界超过1亿人使用的语言，但在高质量语音语料库中仍然严重缺乏，尤其是在语音合成（TTS）应用方面。现有的波斯语音数据集通常比其英语对照组更小，这为发展波斯语音技术带来了关键限制。我们通过引入ParsVoice——为TTS应用量身设计的最大规模波斯语音语料库来填补这一空白。我们创建了一个自动化流水线，将原始有声书内容转换为TTS可用数据，其中包括基于BERT的句子完成检测器、二分搜索边界优化方法以实现精确的音频-文本对齐，以及针对波斯语量身定制的多维度质量评估框架。该流水线处理了2000本有声书，产生了3526小时的干净语音，并进一步筛选出1804小时高质量子集，适合TTS应用，涵盖了超过470名说话者。ParsVoice是最大的高质量波斯语音数据集，其说话人口语多样性及音频质量可与主要的英语语料库媲美。整个数据集已公开发布，旨在加速波斯语音技术的发展，并为其他低资源语言提供模板。ParsVoice数据集可在ParsVoice（此链接https URL）公开获取。 

---
# Understanding Sampler Stochasticity in Training Diffusion Models for RLHF 

**Title (ZH)**: 理解采样器随机性在训练用于RLHF的扩散模型中的作用 

**Authors**: Jiayuan Sheng, Hanyang Zhao, Haoxian Chen, David D. Yao, Wenpin Tang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10767)  

**Abstract**: Reinforcement Learning from Human Feedback (RLHF) is increasingly used to fine-tune diffusion models, but a key challenge arises from the mismatch between stochastic samplers used during training and deterministic samplers used during inference. In practice, models are fine-tuned using stochastic SDE samplers to encourage exploration, while inference typically relies on deterministic ODE samplers for efficiency and stability. This discrepancy induces a reward gap, raising concerns about whether high-quality outputs can be expected during inference. In this paper, we theoretically characterize this reward gap and provide non-vacuous bounds for general diffusion models, along with sharper convergence rates for Variance Exploding (VE) and Variance Preserving (VP) Gaussian models. Methodologically, we adopt the generalized denoising diffusion implicit models (gDDIM) framework to support arbitrarily high levels of stochasticity, preserving data marginals throughout. Empirically, our findings through large-scale experiments on text-to-image models using denoising diffusion policy optimization (DDPO) and mixed group relative policy optimization (MixGRPO) validate that reward gaps consistently narrow over training, and ODE sampling quality improves when models are updated using higher-stochasticity SDE training. 

**Abstract (ZH)**: 基于人类反馈的强化学习（RLHF）越来越多地用于微调扩散模型，但一个关键挑战来自于训练中使用的随机采样器与推断中使用的确定性采样器之间的不匹配。在实践中，模型使用随机SDE采样器进行微调以鼓励探索，而推断通常依赖于确定性ODE采样器以提高效率和稳定性。这种差异导致了奖励差距，引发了关于在推断过程中能否期望获得高质量输出的担忧。在本文中，我们从理论上界定了这种奖励差距，并为通用扩散模型提供了非空洞界，同时为发散（VE）和方差保持（VP）高斯模型提供了更精确的收敛速率。方法上，我们采用广义去噪扩散隐模型（gDDIM）框架以支持任意高的随机性，并在整个过程中保持数据边缘分布。实验上，通过大规模实验发现，使用更高随机性的SDE训练更新模型后，基于去噪扩散策略优化（DDPO）和混合群相对策略优化（MixGRPO）的文本到图像模型显示了奖励差距的一贯缩小，并且ODE采样质量也得以提高。 

---
# GPS Spoofing Attack Detection in Autonomous Vehicles Using Adaptive DBSCAN 

**Title (ZH)**: 基于自适应DBSCAN的自动驾驶车辆GPS欺骗攻击检测 

**Authors**: Ahmad Mohammadi, Reza Ahmari, Vahid Hemmati, Frederick Owusu-Ambrose, Mahmoud Nabil Mahmoud, Parham Kebria, Abdollah Homaifar, Mehrdad Saif  

**Link**: [PDF](https://arxiv.org/pdf/2510.10766)  

**Abstract**: As autonomous vehicles become an essential component of modern transportation, they are increasingly vulnerable to threats such as GPS spoofing attacks. This study presents an adaptive detection approach utilizing a dynamically tuned Density Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm, designed to adjust the detection threshold ({\epsilon}) in real-time. The threshold is updated based on the recursive mean and standard deviation of displacement errors between GPS and in-vehicle sensors data, but only at instances classified as non-anomalous. Furthermore, an initial threshold, determined from 120,000 clean data samples, ensures the capability to identify even subtle and gradual GPS spoofing attempts from the beginning. To assess the performance of the proposed method, five different subsets from the real-world Honda Research Institute Driving Dataset (HDD) are selected to simulate both large and small magnitude GPS spoofing attacks. The modified algorithm effectively identifies turn-by-turn, stop, overshoot, and multiple small biased spoofing attacks, achieving detection accuracies of 98.621%, 99.960.1%, 99.880.1%, and 98.380.1%, respectively. This work provides a substantial advancement in enhancing the security and safety of AVs against GPS spoofing threats. 

**Abstract (ZH)**: 随着自主车辆成为现代交通系统的重要组成部分，它们日益受到如GPS欺骗攻击等威胁的脆弱性增加。本研究提出了一种自适应检测方法，利用一个动态调谐的基于密度的空间聚类算法（DBSCAN），实现了检测阈值（ε）的实时调整。阈值根据GPS和车载传感器数据位移误差的递归均值和标准差进行更新，但仅在非异常分类时进行。此外，从120,000个干净数据样本中确定的初始阈值确保了从一开始就具备识别甚至微小和渐进的GPS欺骗尝试的能力。为了评估所提方法的性能，从现实世界的Honda Research Institute Driving Dataset (HDD) 中选择了五个不同的子集，模拟了不同规模的GPS欺骗攻击。修改后的算法能够有效识别逐个转向、停车、超速以及多个小偏置的欺骗攻击，分别达到了98.621%，99.960.1%，99.880.1%，和98.380.1%的检测精度。本研究在提高自主车辆对GPS欺骗威胁的安全性和鲁棒性方面提供了重要进展。 

---
# Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency 

**Title (ZH)**: 优化深度网络：根据数据集适配模型深度以获得更高的效率 

**Authors**: Shaharyar Ahmed Khan Tareen, Filza Khan Tareen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10764)  

**Abstract**: Deep neural networks (DNNs) have provided brilliant performance across various tasks. However, this success often comes at the cost of unnecessarily large model sizes, high computational demands, and substantial memory footprints. Typically, powerful architectures are trained at full depths but not all datasets or tasks require such high model capacity. Training very deep architectures on relatively low-complexity datasets frequently leads to wasted computation, unnecessary energy consumption, and excessive memory usage, which in turn makes deployment of models on resource-constrained devices impractical. To address this problem, we introduce Optimally Deep Networks (ODNs), which provide a balance between model depth and task complexity. Specifically, we propose a NAS like training strategy called progressive depth expansion, which begins by training deep networks at shallower depths and incrementally increases their depth as the earlier blocks converge, continuing this process until the target accuracy is reached. ODNs use only the optimal depth for the given datasets, removing redundant layers. This cuts down future training and inference costs, lowers the memory footprint, enhances computational efficiency, and facilitates deployment on edge devices. Empirical results show that the optimal depths of ResNet-18 and ResNet-34 for MNIST and SVHN, achieve up to 98.64 % and 96.44 % reduction in memory footprint, while maintaining a competitive accuracy of 99.31 % and 96.08 %, respectively. 

**Abstract (ZH)**: Optimally Deep Networks (ODNs): Balancing Model Depth and Task Complexity 

---
# A Stochastic Differential Equation Framework for Multi-Objective LLM Interactions: Dynamical Systems Analysis with Code Generation Applications 

**Title (ZH)**: 多目标LLM交互的随机微分方程框架：动力系统分析与代码生成应用 

**Authors**: Shivani Shukla, Himanshu Joshi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10739)  

**Abstract**: We introduce a general stochastic differential equation framework for modelling multiobjective optimization dynamics in iterative Large Language Model (LLM) interactions. Our framework captures the inherent stochasticity of LLM responses through explicit diffusion terms and reveals systematic interference patterns between competing objectives via an interference matrix formulation. We validate our theoretical framework using iterative code generation as a proof-of-concept application, analyzing 400 sessions across security, efficiency, and functionality objectives. Our results demonstrate strategy-dependent convergence behaviors with rates ranging from 0.33 to 1.29, and predictive accuracy achieving R2 = 0.74 for balanced approaches. This work proposes the feasibility of dynamical systems analysis for multi-objective LLM interactions, with code generation serving as an initial validation domain. 

**Abstract (ZH)**: 我们引入了一种一般性的随机微分方程框架，用于建模迭代大型语言模型（LLM）交互中的多目标优化动力学。我们的框架通过显式的扩散项捕捉LLM响应的固有随机性，并通过干扰矩阵形式揭示竞争目标之间的系统干扰模式。我们使用迭代代码生成作为概念验证应用来验证我们的理论框架，分析了400个会话，涵盖安全性、效率和功能目标。我们的结果展示了策略依赖性的收敛行为，收敛率从0.33到1.29不等，并且平衡方法的预测准确率达到R2 = 0.74。本工作提出了动力系统分析在多目标LLM交互中的可行性，迭代代码生成作为初始验证领域。 

---
# Proficiency-Aware Adaptation and Data Augmentation for Robust L2 ASR 

**Title (ZH)**: proficiency-aware 调适和数据增强以实现鲁棒的L2 ASR 

**Authors**: Ling Sun, Charlotte Zhu, Shuju Shi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10738)  

**Abstract**: General-purpose ASR underperforms for atypical speakers, such as L2 learners, reinforcing bias and limiting use in education and accessibility. Using the CEFR-graded Speak and Improve corpus, we show that naive fine-tuning of Whisper reduces average WER but simultaneously widens disparities and disproportionately harms lower-level learners. To address this, we propose two strategies: (i) proficiency-aware multitask learning, jointly optimizing ASR with proficiency classification, and (ii) targeted augmentation, applying spectrogram masking to low-proficiency speech to counter imbalance. These approaches reduce WER by up to 29.4 percent (relative) and insertion/deletion errors by as much as 58.6 percent (relative). Crucially, despite the severe imbalance of the dataset reflecting real-world distributions, both strategies consistently narrow proficiency gaps, advancing equitable ASR for L2 learners. 

**Abstract (ZH)**: 通用ASR在异常说话者（如二语学习者）上的表现不佳，加剧了偏见并限制了其在教育和无障碍领域的应用。利用CEFR分级的Speak and Improve语料库，我们发现对Whisper进行简单的微调虽然降低了平均词错误率（WER），但却同时扩大了差异，并不成比例地损害了低级别学习者。为了解决这一问题，我们提出了两种策略：（i）具备水平意识的多任务学习，联合优化ASR与水平分类；（ii）目标增强，通过对低水平语音应用频谱掩码以平衡数据分布。这两种方法最高可减少29.4%（相对）的WER，以及高达58.6%（相对）的插入/删除错误率。关键的是，尽管数据集中的严重不平衡反映了现实世界的真实分布，这两种策略都能一致地缩小水平差距，推动二语学习者的公平ASR。 

---
# Provable Anytime Ensemble Sampling Algorithms in Nonlinear Contextual Bandits 

**Title (ZH)**: 可验证的任意时间集成采样算法在非线性上下文多臂 bandits 中的应用 

**Authors**: Jiazheng Sun, Weixin Wang, Pan Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10730)  

**Abstract**: We provide a unified algorithmic framework for ensemble sampling in nonlinear contextual bandits and develop corresponding regret bounds for two most common nonlinear contextual bandit settings: Generalized Linear Ensemble Sampling (\texttt{GLM-ES}) for generalized linear bandits and Neural Ensemble Sampling (\texttt{Neural-ES}) for neural contextual bandits. Both methods maintain multiple estimators for the reward model parameters via maximum likelihood estimation on randomly perturbed data. We prove high-probability frequentist regret bounds of $\mathcal{O}(d^{3/2} \sqrt{T} + d^{9/2})$ for \texttt{GLM-ES} and $\mathcal{O}(\widetilde{d} \sqrt{T})$ for \texttt{Neural-ES}, where $d$ is the dimension of feature vectors, $\widetilde{d}$ is the effective dimension of a neural tangent kernel matrix, and $T$ is the number of rounds. These regret bounds match the state-of-the-art results of randomized exploration algorithms in nonlinear contextual bandit settings. In the theoretical analysis, we introduce techniques that address challenges specific to nonlinear models. Practically, we remove fixed-time horizon assumptions by developing anytime versions of our algorithms, suitable when $T$ is unknown. Finally, we empirically evaluate \texttt{GLM-ES}, \texttt{Neural-ES}, and their anytime variants, demonstrating strong performance. Overall, our results establish ensemble sampling as a provable and practical randomized exploration approach for nonlinear contextual bandits. 

**Abstract (ZH)**: 统一非线性上下文bandits的集成采样算法框架及对应的遗憾界分析：从广义线性集成采样(\texttt{GLM-ES})到神经集成采样(\texttt{Neural-ES}) 

---
# SS-DPPN: A self-supervised dual-path foundation model for the generalizable cardiac audio representation 

**Title (ZH)**: SS-DPPN: 一种自监督双路径基础模型用于通用心脏音频表示 

**Authors**: Ummy Maria Muna, Md Mehedi Hasan Shawon, Md Jobayer, Sumaiya Akter, Md Rakibul Hasan, Md. Golam Rabiul Alam  

**Link**: [PDF](https://arxiv.org/pdf/2510.10719)  

**Abstract**: The automated analysis of phonocardiograms is vital for the early diagnosis of cardiovascular disease, yet supervised deep learning is often constrained by the scarcity of expert-annotated data. In this paper, we propose the Self-Supervised Dual-Path Prototypical Network (SS-DPPN), a foundation model for cardiac audio representation and classification from unlabeled data. The framework introduces a dual-path contrastive learning based architecture that simultaneously processes 1D waveforms and 2D spectrograms using a novel hybrid loss. For the downstream task, a metric-learning approach using a Prototypical Network was used that enhances sensitivity and produces well-calibrated and trustworthy predictions. SS-DPPN achieves state-of-the-art performance on four cardiac audio benchmarks. The framework demonstrates exceptional data efficiency with a fully supervised model on three-fold reduction in labeled data. Finally, the learned representations generalize successfully across lung sound classification and heart rate estimation. Our experiments and findings validate SS-DPPN as a robust, reliable, and scalable foundation model for physiological signals. 

**Abstract (ZH)**: 自监督双路径原型网络在无标注数据中的心脏音频表示与分类 

---
# HYPERDOA: Robust and Efficient DoA Estimation using Hyperdimensional Computing 

**Title (ZH)**: HYPERDOA：基于超维度计算的稳健高效角度估计 

**Authors**: Rajat Bhattacharjya, Woohyeok Park, Arnab Sarkar, Hyunwoo Oh, Mohsen Imani, Nikil Dutt  

**Link**: [PDF](https://arxiv.org/pdf/2510.10718)  

**Abstract**: Direction of Arrival (DoA) estimation techniques face a critical trade-off, as classical methods often lack accuracy in challenging, low signal-to-noise ratio (SNR) conditions, while modern deep learning approaches are too energy-intensive and opaque for resource-constrained, safety-critical systems. We introduce HYPERDOA, a novel estimator leveraging Hyperdimensional Computing (HDC). The framework introduces two distinct feature extraction strategies -- Mean Spatial-Lag Autocorrelation and Spatial Smoothing -- for its HDC pipeline, and then reframes DoA estimation as a pattern recognition problem. This approach leverages HDC's inherent robustness to noise and its transparent algebraic operations to bypass the expensive matrix decompositions and ``black-box'' nature of classical and deep learning methods, respectively. Our evaluation demonstrates that HYPERDOA achieves ~35.39% higher accuracy than state-of-the-art methods in low-SNR, coherent-source scenarios. Crucially, it also consumes ~93% less energy than competing neural baselines on an embedded NVIDIA Jetson Xavier NX platform. This dual advantage in accuracy and efficiency establishes HYPERDOA as a robust and viable solution for mission-critical applications on edge devices. 

**Abstract (ZH)**: HYPERDOA：面向边缘设备的低信噪比条件下高效的到达方向估计方法 

---
# Deep Learning in Astrophysics 

**Title (ZH)**: 深度学习在天体物理学中的应用 

**Authors**: Yuan-Sen Ting  

**Link**: [PDF](https://arxiv.org/pdf/2510.10713)  

**Abstract**: Deep learning has generated diverse perspectives in astronomy, with ongoing discussions between proponents and skeptics motivating this review. We examine how neural networks complement classical statistics, extending our data analytical toolkit for modern surveys. Astronomy offers unique opportunities through encoding physical symmetries, conservation laws, and differential equations directly into architectures, creating models that generalize beyond training data. Yet challenges persist as unlabeled observations number in billions while confirmed examples with known properties remain scarce and expensive. This review demonstrates how deep learning incorporates domain knowledge through architectural design, with built-in assumptions guiding models toward physically meaningful solutions. We evaluate where these methods offer genuine advances versus claims requiring careful scrutiny. - Neural architectures overcome trade-offs between scalability, expressivity, and data efficiency by encoding physical symmetries and conservation laws into network structure, enabling learning from limited labeled data. - Simulation-based inference and anomaly detection extract information from complex, non-Gaussian distributions where analytical likelihoods fail, enabling field-level cosmological analysis and systematic discovery of rare phenomena. - Multi-scale neural modeling bridges resolution gaps in astronomical simulations, learning effective subgrid physics from expensive high-fidelity runs to enhance large-volume calculations where direct computation remains prohibitive. - Emerging paradigms-reinforcement learning for telescope operations, foundation models learning from minimal examples, and large language model agents for research automation-show promise though are still developing in astronomical applications. 

**Abstract (ZH)**: 深度学习在天文学中产生了多样的观点，提倡者与怀疑者之间的持续讨论推动了本综述的编写。我们探讨了神经网络如何补充经典统计学方法，扩展了用于现代调查的数据分析工具包。天文学通过直接将物理对称性、守恒律和微分方程编码到架构中，提供了独特的机会，从而创建出能够泛化到训练数据之外的模型。然而，随着未标记观测数据的数量达到数十亿，具备已知属性的确凿示例仍然稀缺且昂贵。本综述展示了深度学习如何通过架构设计整合领域知识，内置的假设指导模型趋向于物理上合理的解决方案。我们评估了这些方法提供的真正进展与需要仔细审查的声明之间的区别。- 神经网络架构通过将物理对称性和守恒律编码到网络结构中，克服了可扩展性、表达能力和数据效率之间的权衡，从而能够在有限标注数据下进行学习。- 基于模拟的推断和异常检测从复杂非高斯分布中提取信息，当解析似然函数失效时提供帮助，使天文学领域的宇宙学分析和系统发现稀有现象成为可能。- 多尺度神经建模弥合了天文学模拟中的分辨率差距，从昂贵的高保真运行中学到有效的子网格物理知识，以增强大规模计算，其中直接计算仍然是不切实际的。- 正在发展中但在天文学应用中展现潜力的新范式包括：望远镜操作中的强化学习、从少量示例学习的基础模型以及用于研究自动化的大语言模型代理。 

---
# Missing Data Multiple Imputation for Tabular Q-Learning in Online RL 

**Title (ZH)**: 基于在线强化学习的表格Q学习缺失数据多重插补 

**Authors**: Kyla Chasalow, Skyler Wu, Susan Murphy  

**Link**: [PDF](https://arxiv.org/pdf/2510.10709)  

**Abstract**: Missing data in online reinforcement learning (RL) poses challenges compared to missing data in standard tabular data or in offline policy learning. The need to impute and act at each time step means that imputation cannot be put off until enough data exist to produce stable imputation models. It also means future data collection and learning depend on previous imputations. This paper proposes fully online imputation ensembles. We find that maintaining multiple imputation pathways may help balance the need to capture uncertainty under missingness and the need for efficiency in online settings. We consider multiple approaches for incorporating these pathways into learning and action selection. Using a Grid World experiment with various types of missingness, we provide preliminary evidence that multiple imputation pathways may be a useful framework for constructing simple and efficient online missing data RL methods. 

**Abstract (ZH)**: 在线强化学习（RL）中缺失数据带来的挑战不同于标准表格式数据或离线策略学习中缺失数据的挑战。每次时间步都需要进行填充和行动意味着填充不能等到有足够的数据以产生稳定模型时才进行。这也意味着未来的数据收集和学习依赖于之前的填充。本文提出了一种完全在线的填充集成方法。我们发现，维护多个填充路径可能有助于在在线环境中平衡捕捉缺失性带来的不确定性需求与效率需求。我们考虑了将这些路径整合到学习和行动选择中的多种方法。通过使用具有不同类型缺失数据的Grid World实验，我们提供了初步证据，表明多个填充路径可能是一种有用的框架，用于构建简单的高效在线缺失数据RL方法。 

---
# Attention-Enhanced LSTM Modeling for Improved Temperature and Rainfall Forecasting in Bangladesh 

**Title (ZH)**: 增强注意力机制的LSTM模型在孟加拉国温度和降雨预报中的应用 

**Authors**: Usman Gani Joy, Shahadat kabir, Tasnim Niger  

**Link**: [PDF](https://arxiv.org/pdf/2510.10702)  

**Abstract**: Accurate climate forecasting is vital for Bangladesh, a region highly susceptible to climate change impacts on temperature and rainfall. Existing models often struggle to capture long-range dependencies and complex temporal patterns in climate data. This study introduces an advanced Long Short-Term Memory (LSTM) model integrated with an attention mechanism to enhance the prediction of temperature and rainfall dynamics. Utilizing comprehensive datasets from 1901-2023, sourced from NASA's POWER Project for temperature and the Humanitarian Data Exchange for rainfall, the model effectively captures seasonal and long-term trends. It outperforms baseline models, including XGBoost, Simple LSTM, and GRU, achieving a test MSE of 0.2411 (normalized units), MAE of 0.3860 degrees C, R^2 of 0.9834, and NRMSE of 0.0370 for temperature, and MSE of 1283.67 mm^2, MAE of 22.91 mm, R^2 of 0.9639, and NRMSE of 0.0354 for rainfall on monthly forecasts. The model demonstrates improved robustness with only a 20 percent increase in MSE under simulated climate trends (compared to an approximately 2.2-fold increase in baseline models without trend features) and a 50 percent degradation under regional variations (compared to an approximately 4.8-fold increase in baseline models without enhancements). These results highlight the model's ability to improve forecasting precision and offer potential insights into the physical processes governing climate variability in Bangladesh, supporting applications in climate-sensitive sectors. 

**Abstract (ZH)**: 准确的气候预测对于孟加拉国至关重要，该地区对温度和降雨量的气候变化影响极其敏感。现有的模型往往难以捕捉气候数据中的长期依赖关系和复杂的时空模式。本研究引入了结合注意力机制的高级长短期记忆（LSTM）模型，以增强温度和降雨动态的预测能力。利用自1901年至2023年来自NASA POWER项目和人道主义数据交换的数据集，该模型有效地捕捉到了季节性和长期趋势。与XGBoost、简单LSTM和GRU等基线模型相比，该模型在温度预测上实现了测试MSE为0.2411（归一化单位）、MAE为0.3860摄氏度、R²为0.9834和NRMSE为0.0370，在月度降雨预测上实现了MSE为1283.67平方毫米、MAE为22.91毫米、R²为0.9639和NRMSE为0.0354。在模拟气候趋势下，该模型仅增加了20%的MSE（而基线模型在没有趋势特征的情况下增加了约2.2倍），在区域差异情况下，其降解程度为50%（而基线模型在没有增强措施的情况下增加了约4.8倍）。这些结果突显了该模型提高预测精度的能力，并为其在孟加拉国气候敏感领域的应用提供了潜在的洞见，支持对气候变异物理过程的研究。 

---
# High-Dimensional Learning Dynamics of Quantized Models with Straight-Through Estimator 

**Title (ZH)**: 高维量化模型的直通估计学习动力学 

**Authors**: Yuma Ichikawa, Shuhei Kashiwamura, Ayaka Sakata  

**Link**: [PDF](https://arxiv.org/pdf/2510.10693)  

**Abstract**: Quantized neural network training optimizes a discrete, non-differentiable objective. The straight-through estimator (STE) enables backpropagation through surrogate gradients and is widely used. While previous studies have primarily focused on the properties of surrogate gradients and their convergence, the influence of quantization hyperparameters, such as bit width and quantization range, on learning dynamics remains largely unexplored. We theoretically show that in the high-dimensional limit, STE dynamics converge to a deterministic ordinary differential equation. This reveals that STE training exhibits a plateau followed by a sharp drop in generalization error, with plateau length depending on the quantization range. A fixed-point analysis quantifies the asymptotic deviation from the unquantized linear model. We also extend analytical techniques for stochastic gradient descent to nonlinear transformations of weights and inputs. 

**Abstract (ZH)**: 量化神经网络训练优化了一个离散的非可微目标。伪梯度直通估计器（STE）允许通过伪梯度进行反向传播，并被广泛使用。虽然以前的研究主要集中在伪梯度的性质及其收敛性上，但量化超参数，如位宽和量化范围，对学习动力学的影响仍 largely unexplored。我们从理论上证明，在高维极限下，STE动力学收敛到一个确定性的常微分方程。这揭示了STE训练在泛化误差上表现出一个平台期随后是急剧下降的现象，而平台期的长度取决于量化范围。定点分析量化了从无量化线性模型的渐近偏差。我们还扩展了随机梯度下降的分析技术，应用于权重和输入的非线性变换。 

---
# LSZone: A Lightweight Spatial Information Modeling Architecture for Real-time In-car Multi-zone Speech Separation 

**Title (ZH)**: LSZone：一种轻量级空间信息建模架构实现实时车内多区语音分离 

**Authors**: Jun Chen, Shichao Hu, Jiuxin Lin, Wenjie Li, Zihan Zhang, Xingchen Li, JinJiang Liu, Longshuai Xiao, Chao Weng, Lei Xie, Zhiyong Wu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10687)  

**Abstract**: In-car multi-zone speech separation, which captures voices from different speech zones, plays a crucial role in human-vehicle interaction. Although previous SpatialNet has achieved notable results, its high computational cost still hinders real-time applications in vehicles. To this end, this paper proposes LSZone, a lightweight spatial information modeling architecture for real-time in-car multi-zone speech separation. We design a spatial information extraction-compression (SpaIEC) module that combines Mel spectrogram and Interaural Phase Difference (IPD) to reduce computational burden while maintaining performance. Additionally, to efficiently model spatial information, we introduce an extremely lightweight Conv-GRU crossband-narrowband processing (CNP) module. Experimental results demonstrate that LSZone, with a complexity of 0.56G MACs and a real-time factor (RTF) of 0.37, delivers impressive performance in complex noise and multi-speaker scenarios. 

**Abstract (ZH)**: 车载多区域语音分离技术：一种轻量级空间信息建模架构 

---
# Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey 

**Title (ZH)**: 基于图像-语言基础模型的图像到视频转移学习综述 

**Authors**: Jinxuan Li, Chaolei Tan, Haoxuan Chen, Jianxin Ma, Jian-Fang Hu, Wei-Shi Zheng, Jianhuang Lai  

**Link**: [PDF](https://arxiv.org/pdf/2510.10671)  

**Abstract**: Image-Language Foundation Models (ILFM) have demonstrated remarkable success in image-text understanding/generation tasks, providing transferable multimodal representations that generalize across diverse downstream image-based tasks. The advancement of video-text research has spurred growing interest in extending image-based models to the video domain. This paradigm, known as image-to-video transfer learning, succeeds in alleviating the substantial data and computational requirements associated with training video-language foundation models from scratch for video-text learning. This survey provides the first comprehensive review of this emerging field, which begins by summarizing the widely used ILFM and their capabilities. We then systematically classify existing image-to-video transfer learning strategies into two categories: frozen features and modified features, depending on whether the original representations from ILFM are preserved or undergo modifications. Building upon the task-specific nature of image-to-video transfer, this survey methodically elaborates these strategies and details their applications across a spectrum of video-text learning tasks, ranging from fine-grained (e.g., spatio-temporal video grounding) to coarse-grained (e.g., video question answering). We further present a detailed experimental analysis to investigate the efficacy of different image-to-video transfer learning paradigms on a range of downstream video understanding tasks. Finally, we identify prevailing challenges and highlight promising directions for future research. By offering a comprehensive and structured overview, this survey aims to establish a structured roadmap for advancing video-text learning based on existing ILFM, and to inspire future research directions in this rapidly evolving domain. 

**Abstract (ZH)**: Image-Language 基础模型 (ILFM) 在图像-文本理解/生成任务中取得了显著的成功，提供了跨多种下游图像任务泛化的可转移多模态表示。视频-文本研究的进展激发了将基于图像的模型扩展到视频域的兴趣。这一范式被称为图像到视频迁移学习，成功地减轻了从零开始训练视频-语言基础模型所关联的大数据和计算需求。本文综述为该新兴领域提供了首个全面回顾，首先总结了广泛使用的ILFM及其能力。我们系统地将现有的图像到视频迁移学习策略分为两类：冻结特征和修改特征，取决于ILFM原始表示是否保持或修改。基于图像到视频迁移的特定任务性质，本文详细阐述了这些策略及其在视频-文本学习任务谱系中的应用，从精细粒度（例如，空时视频接地）到粗粒度（例如，视频问答）。我们进一步提供详细的实验分析，以调查不同图像到视频迁移学习范式在多种下游视频理解任务中的有效性。最后，我们指出了现有的挑战并强调了未来研究的前景方向。通过提供全面且结构化的综述，本文旨在为基于现有ILFM推动视频-文本学习建立一个结构化的路线图，并激发该快速发展的领域中的未来研究方向。 

---
# BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions 

**Title (ZH)**: BrowserAgent: 构建受人类网页浏览行为启发的网页代理 

**Authors**: Zhengbo Zhang, Zhiheng Lyu, Junhao Gong, Hongzhu Yi, Xinming Wang, Yuxuan Zhou, Jiabing Yang, Ping Nie, Yan Huang, Wenhu Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10666)  

**Abstract**: Efficiently solving real-world problems with LLMs increasingly hinges on their ability to interact with dynamic web environments and autonomously acquire external information. While recent research like Search-R1 and WebDancer demonstrates strong performance in solving web tasks, they heavily rely on additional tools to convert the interactive web environment into static text content. This is in contrast to human browsing behaviors, which involve diverse interactions with the browser, such as scrolling, clicking, and typing. In this paper, we propose BrowserAgent, a more interactive agent that solves complex tasks through human-inspired browser actions. BrowserAgent operates directly on raw web pages via Playwright through a set of predefined browser actions. We adopt a two-stage training (Supervised Fine-Tuning (SFT) and Rejection Fine-Tuning (RFT)) to improve the model's generalization abilities. Despite using significantly less training data than Search-R1, BrowserAgent achieves more competitive results across different Open-QA tasks. Additionally, we introduce an explicit memory mechanism to store key conclusions across steps, further enhancing the model's reasoning capabilities for long-horizon tasks. Notably, BrowserAgent-7B can achieve around 20\% improvement over Search-R1 on multi-hop QA tasks like HotpotQA, 2Wiki, and Bamboogle. These results indicate that BrowserAgent can serve as a more advanced framework for more interactive and scalable web agents. 

**Abstract (ZH)**: 利用LLM高效解决实际问题 increasingly hinges on their ability to interact with dynamic web environments and autonomously acquire external information. BrowserAgent: 一种通过受人类启发的浏览器操作解决复杂任务的更互动代理 

---
# Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection 

**Title (ZH)**: 可扩展的人脸安全视觉基础模型用于深伪、扩散和欺骗检测 

**Authors**: Gaojian Wang, Feng Lin, Tong Wu, Zhisheng Yan, Kui Ren  

**Link**: [PDF](https://arxiv.org/pdf/2510.10663)  

**Abstract**: With abundant, unlabeled real faces, how can we learn robust and transferable facial representations to boost generalization across various face security tasks? We make the first attempt and propose FS-VFM, a scalable self-supervised pre-training framework, to learn fundamental representations of real face images. We introduce three learning objectives, namely 3C, that synergize masked image modeling (MIM) and instance discrimination (ID), empowering FS-VFM to encode both local patterns and global semantics of real faces. Specifically, we formulate various facial masking strategies for MIM and devise a simple yet effective CRFR-P masking, which explicitly prompts the model to pursue meaningful intra-region Consistency and challenging inter-region Coherency. We present a reliable self-distillation mechanism that seamlessly couples MIM with ID to establish underlying local-to-global Correspondence. After pre-training, vanilla vision transformers (ViTs) serve as universal Vision Foundation Models for downstream Face Security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forensics. To efficiently transfer the pre-trained FS-VFM, we further propose FS-Adapter, a lightweight plug-and-play bottleneck atop the frozen backbone with a novel real-anchor contrastive objective. Extensive experiments on 11 public benchmarks demonstrate that our FS-VFM consistently generalizes better than diverse VFMs, spanning natural and facial domains, fully, weakly, and self-supervised paradigms, small, base, and large ViT scales, and even outperforms SOTA task-specific methods, while FS-Adapter offers an excellent efficiency-performance trade-off. The code and models are available on this https URL. 

**Abstract (ZH)**: 如何利用丰富的无标签真实人脸图像学习鲁棒且可迁移的面部表示以增强各类面部安全任务的一般化能力？我们首次进行尝试并提出FS-VFM，一种可扩展的自监督预训练框架，以学习真实人脸图像的基本表示。我们引入了三种学习目标，即3C，融合了掩码图像建模（MIM）和实例区分（ID），使FS-VFM能够编码真实人脸的局部模式和全局语义。具体而言，我们为MIM制定了各种面部掩码策略，并设计了一种简单有效的CRFR-P掩码，明确地促使模型追求有意义的区域内一致性以及具有挑战性的区域间一致性。我们提出了一种可靠的自蒸馏机制，无缝地将MIM与ID耦合起来，建立底层的局部到全局对应关系。预训练后，通用的视觉基础模型（ViTs）作为下游面部安全任务：跨数据集深度伪造检测、跨域人脸防篡改和未知扩散面部法医检验的通用组件。为了高效地迁移预训练的FS-VFM，我们进一步提出FS-Adapter，这是一种基于冻结主干的轻量级即插即用瓶颈结构，并带有新的真实锚点对比目标。在11个公开基准上的广泛实验表明，我们的FS-VFM在多种视觉变换器规模和自监督范式下，以及自然和面部领域内，均表现出更出色的泛化能力，甚至超越了现有的特定任务方法，而FS-Adapter则提供了卓越的效率-性能权衡。代码和模型可在以下链接获取：this https URL。 

---
# AGENTIQL: An Agent-Inspired Multi-Expert Framework for Text-to-SQL Generation 

**Title (ZH)**: AGENTIQL：一种受代理启发的多专家框架用于文本到SQL生成 

**Authors**: Omid Reza Heidari, Siobhan Reid, Yassine Yaakoubi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10661)  

**Abstract**: LLMs have advanced text-to-SQL generation, yet monolithic architectures struggle with complex reasoning and schema diversity. We propose AGENTIQL, an agent-inspired multi-expert framework that combines a reasoning agent for question decomposition, a coding agent for sub-query generation, and a refinement step for column selection. An adaptive router further balances efficiency and accuracy by selecting between our modular pipeline and a baseline parser. Several steps in the pipeline can be executed in parallel, making the framework scalable to larger workloads. Evaluated on the Spider benchmark, AGENTIQL improves execution accuracy and interpretability and achieves up to 86.07\% EX with 14B models using the Planner&Executor merging strategy. The attained performance is contingent upon the efficacy of the routing mechanism, thereby narrowing the gap to GPT-4-based SOTA (89.65% EX) while using much smaller open-source LLMs. Beyond accuracy, AGENTIQL enhances transparency by exposing intermediate reasoning steps, offering a robust, scalable, and interpretable approach to semantic parsing. 

**Abstract (ZH)**: LLMs在文本到SQL生成方面取得了进展，但单一架构在处理复杂推理和模式多样性时遇到困难。我们提出了一种受代理启发的多专家框架AGENTIQL，该框架结合了一个推理代理用于问题分解、一个编码代理用于子查询生成，以及一个列选择修正步骤。动态路由器进一步通过在模块化管道和基线解析器之间选择来平衡效率和准确性。管道中的若干步骤可以并行执行，使该框架能够扩展以处理更大的工作负载。在Spider基准测试下，AGENTIQL提高了执行准确性和可解释性，并且使用Planner&Executor合并策略的14B模型达到了86.07%的EX性能。该性能取决于路由机制的有效性，从而缩小了与基于GPT-4的当前最佳水平（89.65% EX）之间的差距，同时使用了规模更小的开源LLM。除了准确性之外，AGENTIQL通过暴露中间推理步骤增强了透明度，提供了一种 robust、可扩展和可解释的语义解析方法。 

---
# DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis 

**Title (ZH)**: DEMO: 解耦运动潜在流匹配的细腻粒度可控 Talking Portrait 合成 

**Authors**: Peiyin Chen, Zhuowei Yang, Hui Feng, Sheng Jiang, Rui Yan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10650)  

**Abstract**: Audio-driven talking-head generation has advanced rapidly with diffusion-based generative models, yet producing temporally coherent videos with fine-grained motion control remains challenging. We propose DEMO, a flow-matching generative framework for audio-driven talking-portrait video synthesis that delivers disentangled, high-fidelity control of lip motion, head pose, and eye gaze. The core contribution is a motion auto-encoder that builds a structured latent space in which motion factors are independently represented and approximately orthogonalized. On this disentangled motion space, we apply optimal-transport-based flow matching with a transformer predictor to generate temporally smooth motion trajectories conditioned on audio. Extensive experiments across multiple benchmarks show that DEMO outperforms prior methods in video realism, lip-audio synchronization, and motion fidelity. These results demonstrate that combining fine-grained motion disentanglement with flow-based generative modeling provides a powerful new paradigm for controllable talking-head video synthesis. 

**Abstract (ZH)**: 基于音频驱动的Head Motion生成，扩散型生成模型推动了头像视频生成的快速发展，但实时前后一致的、细粒度运动控制的视频生成仍然具有挑战性。我们提出了一种基于流匹配的生成框架DEMO，用于音频驱动的肖像视频合成，提供了解耦、高保真度的唇动、头部姿态和眼睛注视控制。核心贡献是一种运动自编码器，它构建了一个结构化的潜在空间，在该空间中，运动因素独立表示并通过近似正交化。在这一解耦的运动空间上，我们应用基于运输最优的流匹配和变压器预测器，根据音频条件生成平滑的运动轨迹。多基准实验显示，DEMO在视频真实性、唇音同步和运动保真度方面优于先前方法。这些结果表明，将细粒度运动解耦与基于流的生成建模相结合，为可控头像视频合成提供了一个强大新的范式。 

---
# Trustworthy Retrosynthesis: Eliminating Hallucinations with a Diverse Ensemble of Reaction Scorers 

**Title (ZH)**: 可信逆合成：通过多样化的反应评分器消除幻觉 

**Authors**: Michal Sadowski, Maria Wyrzykowska, Lukasz Sztukiewicz, Tadija Radusinović, Jan Rzymkowski, Paweł Włodarczyk-Pruszyński, Mikołaj Sacha, Piotr Kozakowski, Ruard van Workum, Stanislaw Kamil Jastrzebski  

**Link**: [PDF](https://arxiv.org/pdf/2510.10645)  

**Abstract**: Retrosynthesis is one of the domains transformed by the rise of generative models, and it is one where the problem of nonsensical or erroneous outputs (hallucinations) is particularly insidious: reliable assessment of synthetic plans is time-consuming, with automatic methods lacking. In this work, we present RetroTrim, a retrosynthesis system that successfully avoids nonsensical plans on a set of challenging drug-like targets. Compared to common baselines in the field, our system is not only the sole method that succeeds in filtering out hallucinated reactions, but it also results in the highest number of high-quality paths overall. The key insight behind RetroTrim is the combination of diverse reaction scoring strategies, based on machine learning models and existing chemical databases. We show that our scoring strategies capture different classes of hallucinations by analyzing them on a dataset of labeled retrosynthetic intermediates. To measure the performance of retrosynthesis systems, we propose a novel evaluation protocol for reactions and synthetic paths based on a structured review by expert chemists. Using this protocol, we compare systems on a set of 32 novel targets, curated to reflect recent trends in drug structures. While the insights behind our methodology are broadly applicable to retrosynthesis, our focus is on targets in the drug-like domain. By releasing our benchmark targets and the details of our evaluation protocol, we hope to inspire further research into reliable retrosynthesis. 

**Abstract (ZH)**: retrosynthesis 是生成模型兴起后发生变革的领域之一，其中不可信或错误输出（幻觉）的问题尤为隐蔽：可靠评估合成方案耗时且缺乏自动方法。在此项工作中，我们提出了一种名为 RetroTrim 的 retrosynthesis 系统，该系统成功避免了一组挑战性的药物样目标的不可信方案。与该领域的常见基准相比，我们的系统是唯一一种能够筛选出幻觉反应的方法，并且总体上生成了最高数量的高质量路径。RetroTrim 的关键洞察是结合了基于机器学习模型和现有化学数据库的不同反应评分策略。我们通过在标记的 retrosynthetic 中间体数据集上分析它们来证明我们的评分策略能够捕捉不同类别的幻觉。为了衡量 retrosynthesis 系统的性能，我们提出了基于专家化学家结构化评审的新评估协议。使用此协议，我们在一组 32 个经过精心挑选以反映最近药物结构趋势的新型目标上比较系统。虽然我们方法背后的原则在 retrosynthesis 领域具有广泛的适用性，但我们的重点是药物样目标。通过提供我们的基准目标和评估协议的详细信息，我们希望激励进一步的研究以实现可靠的 retrosynthesis。 

---
# UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning 

**Title (ZH)**: UniCoD: 增强机器人策略的统一连续与离散表示学习 

**Authors**: Jianke Zhang, Yucheng Hu, Yanjiang Guo, Xiaoyu Chen, Yichen Liu, Wenna Chen, Chaochao Lu, Jianyu Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10642)  

**Abstract**: Building generalist robot policies that can handle diverse tasks in open-ended environments is a central challenge in robotics. To leverage knowledge from large-scale pretraining, prior work has typically built generalist policies either on top of vision-language understanding models (VLMs) or generative models. However, both semantic understanding from vision-language pretraining and visual dynamics modeling from visual-generation pretraining are crucial for embodied robots. Recent unified models of generation and understanding have demonstrated strong capabilities in both comprehension and generation through large-scale pretraining. We posit that robotic policy learning can likewise benefit from the combined strengths of understanding, planning and continuous future representation learning. Building on this insight, we introduce UniCoD, which acquires the ability to dynamically model high-dimensional visual features through pretraining on over 1M internet-scale instructional manipulation videos. Subsequently, UniCoD is fine-tuned on data collected from the robot embodiment, enabling the learning of mappings from predictive representations to action tokens. Extensive experiments show our approach consistently outperforms baseline methods in terms of 9\% and 12\% across simulation environments and real-world out-of-distribution tasks. 

**Abstract (ZH)**: 构建能够在开放环境中处理多样化任务的一般主义机器人政策是机器人学中的一个核心挑战。尽管前期工作的重点是基于视觉-语言理解模型（VLMs）或生成模型来构建一般主义政策，但体现式机器人所需的视觉语义理解能力和视觉动力学建模能力同样重要。最近出现的生成与理解统一模型通过大规模预训练展示了在理解和生成方面的强大能力。我们认为，机器人策略学习可以从理解、规划和连续未来表示学习的综合优势中受益。基于此见解，我们引入了UniCoD，通过在超过100万规模的互联网指令操作视频上进行预训练，实现了动态建模高维度视觉特征的能力。随后，UniCoD 在机器人实体收集的数据上进行微调，以学习从预测表示到动作标记的映射。大量实验表明，我们的方法在仿真环境和真实世界未知任务中分别比基线方法高出9%和12%的性能。 

---
# A Machine Learning Approach for MIDI to Guitar Tablature Conversion 

**Title (ZH)**: 使用机器学习的方法将MIDI转化为吉他谱 

**Authors**: Maximos Kaliakatsos-Papakostas, Gregoris Bastas, Dimos Makris, Dorien Herremans, Vassilis Katsouros, Petros Maragos  

**Link**: [PDF](https://arxiv.org/pdf/2510.10619)  

**Abstract**: Guitar tablature transcription consists in deducing the string and the fret number on which each note should be played to reproduce the actual musical part. This assignment should lead to playable string-fret combinations throughout the entire track and, in general, preserve parsimonious motion between successive combinations. Throughout the history of guitar playing, specific chord fingerings have been developed across different musical styles that facilitate common idiomatic voicing combinations and motion between them. This paper presents a method for assigning guitar tablature notation to a given MIDI-based musical part (possibly consisting of multiple polyphonic tracks), i.e. no information about guitar-idiomatic expressional characteristics is involved (e.g. bending etc.) The current strategy is based on machine learning and requires a basic assumption about how much fingers can stretch on a fretboard; only standard 6-string guitar tuning is examined. The proposed method also examines the transcription of music pieces that was not meant to be played or could not possibly be played by a guitar (e.g. potentially a symphonic orchestra part), employing a rudimentary method for augmenting musical information and training/testing the system with artificial data. The results present interesting aspects about what the system can achieve when trained on the initial and augmented dataset, showing that the training with augmented data improves the performance even in simple, e.g. monophonic, cases. Results also indicate weaknesses and lead to useful conclusions about possible improvements. 

**Abstract (ZH)**: 吉他谱转录涉及推断每个音符应在哪些弦及品上演奏以重现实际的音乐部分。这一分配应确保整首歌曲中可演奏的弦-品组合，并且通常在相继组合之间保持简洁的运动。在吉他演奏的历史上，针对不同音乐风格开发了特定的和弦指法，便于常常出现的idiomatic和弦配置及它们之间的转换。本文提出了一种将吉他谱记谱应用于给定的基于MIDI的音乐部分（可能包括多个多声部轨道）的方法，即不涉及吉他特有的表达特征（如滑音等）。当前策略基于机器学习，并假设手指在琴颈上的伸展程度；仅考察了标准六弦吉他调音。所提方法还研究了那些并非意图由吉他演奏或根本无法由吉他演奏的音乐作品（如潜在的交响乐团部分），采用一种简单的数据扩充方法，并使用人工数据训练/测试系统。结果展示了当用初始和扩充数据集训练时，系统可以实现的有趣方面，表明使用扩充数据的训练甚至在简单的，例如单声部的情况下，也提高了性能。结果还显示了系统的弱点，从而得出关于可能改进的有用结论。 

---
# Dynamic Topic Evolution with Temporal Decay and Attention in Large Language Models 

**Title (ZH)**: 大型语言模型中具有时间衰减和注意力的动态话题演化 

**Authors**: Di Wu abd Shuaidong Pan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10613)  

**Abstract**: This paper proposes a modeling framework for dynamic topic evolution based on temporal large language models. The method first uses a large language model to obtain contextual embeddings of text and then introduces a temporal decay function and an attention mechanism. These components allow the model to adjust the importance of semantic units according to time intervals and capture topic variations across different periods. The temporal representations are then mapped into a latent topic space, where a state transition matrix is applied to describe the dynamic evolution of topics. A joint optimization objective constrains both semantic modeling and temporal consistency, ensuring diversity and smoothness in topic generation. The design emphasizes the unified modeling of semantic representation and temporal evolution, which improves topic coherence and diversity while enhancing stability and interpretability over time. Experiments on real-world corpora show that the framework effectively captures the generation, expansion, and decline of topics and outperforms existing models across multiple metrics. Overall, the proposed method provides a systematic solution for understanding dynamic semantic patterns in large-scale text, enriches the research paradigm of topic modeling, and supports complex text analysis tasks in multiple domains. 

**Abstract (ZH)**: 基于时间大型语言模型的动态主题演化建模框架 

---
# Compositional Symmetry as Compression: Lie Pseudogroup Structure in Algorithmic Agents 

**Title (ZH)**: 组合对称性作为压缩：算法代理中的李假群结构 

**Authors**: Giulio Ruffini  

**Link**: [PDF](https://arxiv.org/pdf/2510.10586)  

**Abstract**: In the algorithmic (Kolmogorov) view, agents are programs that track and compress sensory streams using generative programs. We propose a framework where the relevant structural prior is simplicity (Solomonoff) understood as \emph{compositional symmetry}: natural streams are well described by (local) actions of finite-parameter Lie pseudogroups on geometrically and topologically complex low-dimensional configuration manifolds (latent spaces). Modeling the agent as a generic neural dynamical system coupled to such streams, we show that accurate world-tracking imposes (i) \emph{structural constraints} -- equivariance of the agent's constitutive equations and readouts -- and (ii) \emph{dynamical constraints}: under static inputs, symmetry induces conserved quantities (Noether-style labels) in the agent dynamics and confines trajectories to reduced invariant manifolds; under slow drift, these manifolds move but remain low-dimensional. This yields a hierarchy of reduced manifolds aligned with the compositional factorization of the pseudogroup, providing a geometric account of the ``blessing of compositionality'' in deep models. We connect these ideas to the Spencer formalism for Lie pseudogroups and formulate a symmetry-based, self-contained version of predictive coding in which higher layers receive only \emph{coarse-grained residual transformations} (prediction-error coordinates) along symmetry directions unresolved at lower layers. 

**Abstract (ZH)**: 基于算法（柯尔莫哥洛夫）的观点，代理是程序，通过生成程序追踪和压缩感觉流。我们提出一个框架，其中相关的关键结构先验是简化性（索洛莫诺夫理解为组合对称性）：自然流可以用有限参数李赝群的局部作用来很好地描述几何和拓扑复杂但低维的配置流形（潜在空间）。将代理建模为与这些流耦合的通用神经动力系统，我们展示准确的世界追踪施加了（i）结构约束——代理基本方程和读数的不变性；以及（ii）动力学约束：在静态输入下，对称性诱导代理动力学中的守恒量（诺ether风格的标签），并限制轨迹到低维不变流形；在缓慢漂移下，这些流形会移动但保持低维。这产生了一种与赝群的组合因子分解相一致的流形层次结构，提供了关于深度模型中“组合性的祝福”的几何解释。我们将这些概念与李赝群的斯宾赛形式主义联系起来，并提出了一个基于对称性的自包含预测编码框架，其中更高层仅接收沿低层未解析的方向的粗糙化残差变换（预测误差坐标）。 

---
# BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices 

**Title (ZH)**: BitMar：基于 episodic 记忆的低比特多模态融合技术用于边缘设备 

**Authors**: Euhid Aman, Esteban Carlin, Hsing-Kuo Pao, Giovanni Beltrame, Ghaluh Indah Permata Sari, Yie-Tarng Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10560)  

**Abstract**: Cross-attention transformers and other multimodal vision-language models excel at grounding and generation; however, their extensive, full-precision backbones make it challenging to deploy them on edge devices. Memory-augmented architectures enhance the utilization of past context; however, most works rarely pair them with aggressive edge-oriented quantization. We introduce BitMar, a quantized multimodal transformer that proposes an external human-like episodic memory for effective image-text generation on hardware with limited resources. BitMar utilizes 1.58-bit encoders, one for text (BitNet-style) and one for vision (DiNOv2-based), to create compact embeddings that are combined and used to query a fixed-size key-value episodic memory. During vector retrieval, the BitNet decoder applies per-layer conditioning, which increases the contextual relevance of generated content. The decoder also employs attention sinks with a sliding-window mechanism to process long or streaming inputs under tight memory budgets. The combination of per-layer conditioning and sliding-window attention achieves a strong quality-speed trade-off, delivering competitive captioning and multimodal understanding at low latency with a small model footprint. These characteristics make BitMar well-suited for edge deployment. 

**Abstract (ZH)**: BitMar：一种用于边缘设备的量化多模态变压器 

---
# GLOFNet -- A Multimodal Dataset for GLOF Monitoring and Prediction 

**Title (ZH)**: GLOFNet -- 一种多模态数据集用于冰湖湖盆溃决洪水监测与预测 

**Authors**: Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Sidra Sultana, Ayesha Kanwal, Nazia Perwaiz  

**Link**: [PDF](https://arxiv.org/pdf/2510.10546)  

**Abstract**: Glacial Lake Outburst Floods (GLOFs) are rare but destructive hazards in high mountain regions, yet predictive research is hindered by fragmented and unimodal data. Most prior efforts emphasize post-event mapping, whereas forecasting requires harmonized datasets that combine visual indicators with physical precursors. We present GLOFNet, a multimodal dataset for GLOF monitoring and prediction, focused on the Shisper Glacier in the Karakoram. It integrates three complementary sources: Sentinel-2 multispectral imagery for spatial monitoring, NASA ITS_LIVE velocity products for glacier kinematics, and MODIS Land Surface Temperature records spanning over two decades. Preprocessing included cloud masking, quality filtering, normalization, temporal interpolation, augmentation, and cyclical encoding, followed by harmonization across modalities. Exploratory analysis reveals seasonal glacier velocity cycles, long-term warming of ~0.8 K per decade, and spatial heterogeneity in cryospheric conditions. The resulting dataset, GLOFNet, is publicly available to support future research in glacial hazard prediction. By addressing challenges such as class imbalance, cloud contamination, and coarse resolution, GLOFNet provides a structured foundation for benchmarking multimodal deep learning approaches to rare hazard prediction. 

**Abstract (ZH)**: GLOFNet：面向喀喇昆仑山脉希普ser冰川的多模态GLOF监测与预测数据集 

---
# PAC-Bayesian Reinforcement Learning Trains Generalizable Policies 

**Title (ZH)**: PAC-Bayesian Reinforcement Learning 培训可泛化的策略 

**Authors**: Abdelkrim Zitouni, Mehdi Hennequin, Juba Agoun, Ryan Horache, Nadia Kabachi, Omar Rivasplata  

**Link**: [PDF](https://arxiv.org/pdf/2510.10544)  

**Abstract**: We derive a novel PAC-Bayesian generalization bound for reinforcement learning that explicitly accounts for Markov dependencies in the data, through the chain's mixing time. This contributes to overcoming challenges in obtaining generalization guarantees for reinforcement learning, where the sequential nature of data breaks the independence assumptions underlying classical bounds. Our bound provides non-vacuous certificates for modern off-policy algorithms like Soft Actor-Critic. We demonstrate the bound's practical utility through PB-SAC, a novel algorithm that optimizes the bound during training to guide exploration. Experiments across continuous control tasks show that our approach provides meaningful confidence certificates while maintaining competitive performance. 

**Abstract (ZH)**: 我们通过链的混合时间明确考虑数据中的马尔可夫依赖性，推导出一种新的PAC-Bayesian泛化界，以克服强化学习中由于数据的序列性质破坏经典界限下的独立性假设而带来的泛化保证难题。我们的界为Soft Actor-Critic等现代离策略算法提供了非空洞的信心证书。我们通过在训练过程中优化该界来指导探索的新算法PB-SAC展示其实用性。实验结果表明，我们的方法在提供有意义的信心证书的同时保持了竞争性的性能。 

---
# Rethinking RL Evaluation: Can Benchmarks Truly Reveal Failures of RL Methods? 

**Title (ZH)**: 重新思考强化学习评估：基准真的能揭示强化学习方法的失败吗？ 

**Authors**: Zihan Chen, Yiming Zhang, Hengguang Zhou, Zenghui Ding, Yining Sun, Cho-Jui Hsieh  

**Link**: [PDF](https://arxiv.org/pdf/2510.10541)  

**Abstract**: Current benchmarks are inadequate for evaluating progress in reinforcement learning (RL) for large language models (LLMs).Despite recent benchmark gains reported for RL, we find that training on these benchmarks' training sets achieves nearly the same performance as training directly on the test sets, suggesting that the benchmarks cannot reliably separate further this http URL study this phenomenon, we introduce a diagnostic suite and the Oracle Performance Gap (OPG) metric that quantifies the performance difference between training on the train split versus the test split of a benchmark. We further analyze this phenomenon with stress tests and find that, despite strong benchmark scores, existing RL methods struggle to generalize across distribution shifts, varying levels of difficulty, and counterfactual scenarios: shortcomings that current benchmarks fail to this http URL conclude that current benchmarks are insufficient for evaluating generalization and propose three core principles for designing more faithful benchmarks: sufficient difficulty, balanced evaluation, and distributional robustness. 

**Abstract (ZH)**: 当前基准不足以评估大规模语言模型强化学习进展 

---
# ECO: Enhanced Code Optimization via Performance-Aware Prompting for Code-LLMs 

**Title (ZH)**: ECO: 增强代码优化通过性能感知提示的代码-LLM优化 

**Authors**: Su-Hyeon Kim, Joonghyuk Hahn, Sooyoung Cha, Yo-Sub Han  

**Link**: [PDF](https://arxiv.org/pdf/2510.10517)  

**Abstract**: Code runtime optimization-the task of rewriting a given code to a faster one-remains challenging, as it requires reasoning about performance trade-offs involving algorithmic and structural choices. Recent approaches employ code-LLMs with slow-fast code pairs provided as optimization guidance, but such pair-based methods obscure the causal factors of performance gains and often lead to superficial pattern imitation rather than genuine performance reasoning. We introduce ECO, a performance-aware prompting framework for code optimization. ECO first distills runtime optimization instructions (ROIs) from reference slow-fast code pairs; Each ROI describes root causes of inefficiency and the rationales that drive performance improvements. For a given input code, ECO in parallel employs (i) a symbolic advisor to produce a bottleneck diagnosis tailored to the code, and (ii) an ROI retriever to return related ROIs. These two outputs are then composed into a performance-aware prompt, providing actionable guidance for code-LLMs. ECO's prompts are model-agnostic, require no fine-tuning, and can be easily prepended to any code-LLM prompt. Our empirical studies highlight that ECO prompting significantly improves code-LLMs' ability to generate efficient code, achieving speedups of up to 7.81x while minimizing correctness loss. 

**Abstract (ZH)**: 代码运行时优化——一种将给定代码重写为更快速代码的任务——依然具有挑战性，因为这要求对涉及算法和结构选择的性能权衡进行推理。最近的方法使用代码-LLM，并提供快速-缓慢代码对作为优化指导，但基于此类成对的方法往往模糊了性能提升的原因，并且通常导致表面模式的模仿而不是真实的性能推理。我们引入了ECO，一种面向性能的代码优化提示框架。ECO首先从参考的快速-缓慢代码对中提炼出运行时优化指令（ROIs）；每个ROI描述了低效的根本原因及其驱动性能提升的推理。对于给定的输入代码，ECO并行使用(i)一个符号顾问生成针对代码的瓶颈诊断，以及(ii)一个ROI检索器返回相关ROIs。然后将这两个输出组合成一个面向性能的提示，为代码-LLM提供可操作的指导。ECO的提示对模型是通用的，不需要微调，可以轻松添加到任何代码-LLM提示的前面。我们的实证研究表明，ECO提示显著提高了代码-LLM生成高效代码的能力，实现了最高7.81倍的加速，同时最大限度地减少了正确性损失。 

---
# Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control 

**Title (ZH)**: 高维机器人控制的 population 编码放电神经网络 

**Authors**: Kanishkha Jaisankar, Xiaoyang Jiang, Feifan Liao, Jeethu Sreenivas Amuthan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10516)  

**Abstract**: Energy-efficient and high-performance motor control remains a critical challenge in robotics, particularly for high-dimensional continuous control tasks with limited onboard resources. While Deep Reinforcement Learning (DRL) has achieved remarkable results, its computational demands and energy consumption limit deployment in resource-constrained environments. This paper introduces a novel framework combining population-coded Spiking Neural Networks (SNNs) with DRL to address these challenges. Our approach leverages the event-driven, asynchronous computation of SNNs alongside the robust policy optimization capabilities of DRL, achieving a balance between energy efficiency and control performance. Central to this framework is the Population-coded Spiking Actor Network (PopSAN), which encodes high-dimensional observations into neuronal population activities and enables optimal policy learning through gradient-based updates. We evaluate our method on the Isaac Gym platform using the PixMC benchmark with complex robotic manipulation tasks. Experimental results on the Franka robotic arm demonstrate that our approach achieves energy savings of up to 96.10% compared to traditional Artificial Neural Networks (ANNs) while maintaining comparable control performance. The trained SNN policies exhibit robust finger position tracking with minimal deviation from commanded trajectories and stable target height maintenance during pick-and-place operations. These results position population-coded SNNs as a promising solution for energy-efficient, high-performance robotic control in resource-constrained applications, paving the way for scalable deployment in real-world robotics systems. 

**Abstract (ZH)**: 高能效和高性能的电机控制依然是机器人领域中的关键挑战，特别是在资源受限的环境中执行高维连续控制任务时。尽管深度强化学习（DRL）取得了显著成果，但其计算需求和能量消耗限制了其在资源受限环境中的部署。本文提出了一种结合脉冲编码神经网络（SNN）和DRL的新框架，以应对这些挑战。我们的方法利用了SNN的事件驱动和异步计算特性，以及DRL稳健的策略优化能力，实现了能量效率和控制性能的平衡。该框架的核心是脉冲编码神经元演员网络（PopSAN），该网络将高维观测编码为神经元群体活动，并通过梯度更新实现最优策略学习。我们使用Isaac Gym平台和PixMC基准对复杂机器人操作任务进行了评估。实验结果表明，与传统的神经网络（ANNS）相比，我们的方法在保持类似控制性能的同时，实现了高达96.10%的能量节约。训练好的SNN策略在手指位置跟踪和拾放操作中表现出强大的鲁棒性，并能稳定维持目标高度。这些结果表明，脉冲编码SNN是资源受限环境中高能效和高性能机器人控制的有前途的解决方案，为实际机器人系统的可扩展部署铺平了道路。 

---
# f-INE: A Hypothesis Testing Framework for Estimating Influence under Training Randomness 

**Title (ZH)**: f-INE：一种基于训练随机性的假设检验框架用于估算影响 

**Authors**: Subhodip Panda, Dhruv Tarsadiya, Shashwat Sourav, Prathosh A.P, Sai Praneeth Karimireddy  

**Link**: [PDF](https://arxiv.org/pdf/2510.10510)  

**Abstract**: Influence estimation methods promise to explain and debug machine learning by estimating the impact of individual samples on the final model. Yet, existing methods collapse under training randomness: the same example may appear critical in one run and irrelevant in the next. Such instability undermines their use in data curation or cleanup since it is unclear if we indeed deleted/kept the correct datapoints. To overcome this, we introduce *f-influence* -- a new influence estimation framework grounded in hypothesis testing that explicitly accounts for training randomness, and establish desirable properties that make it suitable for reliable influence estimation. We also design a highly efficient algorithm **f**-**IN**fluence **E**stimation (**f-INE**) that computes f-influence **in a single training run**. Finally, we scale up f-INE to estimate influence of instruction tuning data on Llama-3.1-8B and show it can reliably detect poisoned samples that steer model opinions, demonstrating its utility for data cleanup and attributing model behavior. 

**Abstract (ZH)**: *f*-影响估计方法：一种基于假设检验的新框架及其在模型影响估计中的应用 

---
# MARS-Sep: Multimodal-Aligned Reinforced Sound Separation 

**Title (ZH)**: MARS-Sep: 多模态对齐强化声源分离 

**Authors**: Zihan Zhang, Xize Cheng, Zhennan Jiang, Dongjie Fu, Jingyuan Chen, Zhou Zhao, Tao Jin  

**Link**: [PDF](https://arxiv.org/pdf/2510.10509)  

**Abstract**: Universal sound separation faces a fundamental misalignment: models optimized for low-level signal metrics often produce semantically contaminated outputs, failing to suppress perceptually salient interference from acoustically similar sources. To bridge this gap, we introduce MARS-Sep, a reinforcement learning framework that reformulates separation as decision making. Instead of simply regressing ground-truth masks, MARS-Sep learns a factorized Beta mask policy that is optimized by a clipped trust-region surrogate with entropy regularization and group-relative advantage normalization. Concretely, we sample masks from a frozen old policy, reconstruct waveforms, and update the current policy using clipped importance ratios-yielding substantially more stable and sample-efficient learning. Multimodal rewards, derived from an audio-text-vision encoder, directly incentivize semantic consistency with query prompts. We further propose a progressive alignment scheme to fine-tune this encoder, boosting its cross-modal discriminability and improving reward faithfulness. Extensive experiments on multiple benchmarks demonstrate consistent gains in Text-, Audio-, and Image-Queried separation, with notable improvements in signal metrics and semantic quality. Our code is available at this https URL. Sound separation samples are available at this https URL. 

**Abstract (ZH)**: 面向感知显著干扰的通用声音分离面临根本性不匹配：模型优化低级信号指标往往会产生语义污染的输出，难以抑制来自声学相似源的感知显著干扰。为解决这一问题，我们提出了MARS-Sep，这是一种强化学习框架，将分离重新表述为决策过程。MARS-Sep 不仅仅是回归真实掩码，而是学习一个通过剪裁信任区域代理优化并带有熵正则化和组相对优势规范化因子分解的Beta掩码策略。具体而言，我们从冻结的旧策略中采样掩码，重建波形，并使用剪裁的重要性比率更新当前策略，从而获得更为稳定和样本有效的学习。多模态奖励来自音频-文本-视觉编码器，直接激励与查询提示的语义一致性。我们还提出了一种渐进对齐方案，以进一步微调此编码器，提高其跨模态的可判别性和奖励忠实度。在多个基准上的大量实验展示了在文本查询、音频查询和图像查询分离方面的一致性改进，并且信号指标和语义质量都有显著提升。代码可在该网址获取：this https URL。声音分离样本可在该网址获取：this https URL。 

---
# Align2Act: Instruction-Tuned Models for Human-Aligned Autonomous Driving 

**Title (ZH)**: Align2Act: 依据指令调优的人机一致自主驾驶模型 

**Authors**: Kanishkha Jaisankar, Sunidhi Tandel  

**Link**: [PDF](https://arxiv.org/pdf/2510.10503)  

**Abstract**: Motion planning in complex scenarios is a core challenge in autonomous driving. Conventional methods apply predefined rules or learn from driving data to generate trajectories, while recent approaches leverage large language models (LLMs) for decision-making. However, it remains unclear whether LLMs truly capture human driving logic. We propose Align2Act, a motion planning framework that transforms instruction-tuned LLMs into interpretable planners aligned with human behavior. We derive structured driving instructions based on human reasoning patterns (e.g., anticipate hazards, yield at intersections) and traffic rules (e.g., stop at red lights, maintain lane boundaries). Our Align2ActChain module guides step-by-step reasoning to produce both an interpretable rationale and a safe trajectory. By fine-tuning LLaMA-2-7B with LoRA on one million scenarios from the nuPlan dataset, our method achieves an open-loop score of 85.17 and closed-loop scores of 70.31 (non-reactive) and 66.96 (reactive) on Test14-random. Unlike prior work focused on synthetic or open-loop settings, we demonstrate improved planning quality and human-likeness on the real-world nuPlan closed-loop benchmark. Ablation studies confirm that structured reasoning significantly improves performance over baseline LLM planners. 

**Abstract (ZH)**: 复杂场景中的运动规划是自主驾驶的核心挑战。传统的运动规划方法通过预定义规则或从驾驶数据中学习生成轨迹，而最新的方法则利用大型语言模型（LLMs）进行决策。然而，目前尚不清楚LLMs是否真正捕捉到了人类的驾驶逻辑。我们提出了一种名为Align2Act的运动规划框架，该框架将指令调优的LLMs转换为与人类行为对齐的可解释规划器。我们基于人类的推理模式（例如，预见危险、交叉路口让行）和交通规则（例如，在红灯前停车、保持车道边界）推导出结构化的驾驶指令。我们的Align2ActChain模块引导逐步推理以生成可解释的推理过程和安全轨迹。通过在nuPlan数据集中的一百万个场景上使用LoRA对LLaMA-2-7B进行微调，我们的方法在Test14-random上的开环得分为85.17，非反应式闭环得分为70.31，反应式闭环得分为66.96。我们的工作不同于以往专注于合成或开环设置的研究，展示了在真实世界的nuPlan闭环基准测试中改进的规划质量和人类相似度。消融研究证实，结构化推理显著提高了基线LLM规划器的性能。 

---
# Personalized Motion Guidance Framework for Athlete-Centric Coaching 

**Title (ZH)**: 运动员中心的个性化动作指导框架 

**Authors**: Ryota Takamidoa, Chiharu Suzukia, Hiroki Nakamoto  

**Link**: [PDF](https://arxiv.org/pdf/2510.10496)  

**Abstract**: A critical challenge in contemporary sports science lies in filling the gap between group-level insights derived from controlled hypothesis-driven experiments and the real-world need for personalized coaching tailored to individual athletes' unique movement patterns. This study developed a Personalized Motion Guidance Framework (PMGF) to enhance athletic performance by generating individualized motion-refinement guides using generative artificial intelligence techniques. PMGF leverages a vertical autoencoder to encode motion sequences into athlete-specific latent representations, which can then be directly manipulated to generate meaningful guidance motions. Two manipulation strategies were explored: (1) smooth interpolation between the learner's motion and a target (e.g., expert) motion to facilitate observational learning, and (2) shifting the motion pattern in an optimal direction in the latent space using a local optimization technique. The results of the validation experiment with data from 51 baseball pitchers revealed that (1) PMGF successfully generated smooth transitions in motion patterns between individuals across all 1,275 pitcher pairs, and (2) the features significantly altered through PMGF manipulations reflected known performance-enhancing characteristics, such as increased stride length and knee extension associated with higher ball velocity, indicating that PMGF induces biomechanically plausible improvements. We propose a future extension called general-PMGF to enhance the applicability of this framework. This extension incorporates bodily, environmental, and task constraints into the generation process, aiming to provide more realistic and versatile guidance across diverse sports contexts. 

**Abstract (ZH)**: 当代运动科学的一个关键挑战是在控制性假设驱动实验获得的群体层面洞见与个性化教练的实际需求之间填补差距，个性化教练需针对每位运动员独特的运动模式进行量身定制。本研究开发了一种个性化运动指导框架（PMGF），利用生成人工智能技术生成个性化运动精炼指南以提升运动表现。PMGF利用垂直自动编码器将运动序列编码为运动员特定的潜在表示，然后可以直接操作这些表示以生成有意义的指导运动。探索了两种操作策略：（1）在学习者的运动和目标（例如专家）运动之间进行平滑插值，以促进观察学习；（2）使用局部优化技术在潜在空间中将运动模式沿最优方向平移。验证实验使用51名棒球投手的数据表明，（1）PMGF成功生成了所有1,275对投手之间运动模式的平滑过渡，（2）通过PMGF操作显著改变的特征反映了已知能提高表现的特性，如步长增加和膝关节伸展与更高球速相关，表明PMGF引发了生物力学上合理的改进。我们提出了一种未来扩展——通用PMGF，以增强此框架的应用性。该扩展将身体、环境和任务约束融入生成过程，旨在提供更现实和多样的指导，适用于各种运动情境。 

---
# Towards Self-Refinement of Vision-Language Models with Triangular Consistency 

**Title (ZH)**: 面向三角一致性导向的视觉-语言模型自我精炼方法 

**Authors**: Yunlong Deng, Guangyi Chen, Tianpei Gu, Lingjing Kong, Yan Li, Zeyu Tang, Kun Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10487)  

**Abstract**: Vision-Language Models (VLMs) integrate visual knowledge with the analytical capabilities of Large Language Models (LLMs) through supervised visual instruction tuning, using image-question-answer triplets. However, the potential of VLMs trained without supervised instruction remains largely unexplored. This study validates that VLMs possess inherent self-refinement capabilities, enabling them to generate high-quality supervised data without external inputs and thereby learn autonomously. Specifically, to stimulate the self-refinement ability of VLMs, we propose a self-refinement framework based on a Triangular Consistency principle: within the image-query-answer triangle, any masked elements should be consistently and accurately reconstructed. The framework involves three steps: (1) We enable the instruction generation ability of VLMs by adding multi-task instruction tuning like image$\rightarrow$question-answer or image-answer$\rightarrow$question. (2) We generate image-query-answer triplets from unlabeled images and use the Triangular Consistency principle for filtering. (3) The model is further updated using the filtered synthetic data. To investigate the underlying mechanisms behind this self-refinement capability, we conduct a theoretical analysis from a causal perspective. Using the widely recognized LLaVA-1.5 as our baseline, our experiments reveal that the model can autonomously achieve consistent, though deliberately modest, improvements across multiple benchmarks without any external supervision, such as human annotations or environmental feedback. We expect that the insights of this study on the self-refinement ability of VLMs can inspire future research on the learning mechanism of VLMs. Code is available at this https URL. 

**Abstract (ZH)**: Vision-Language模型的内在自我精炼能力：无需监督指令的学习机制探究 

---
# SASER: Stego attacks on open-source LLMs 

**Title (ZH)**: SASER：开源大语言模型中的隐秘攻击 

**Authors**: Ming Tan, Wei Li, Hu Tao, Hailong Ma, Aodi Liu, Qian Chen, Zilong Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10486)  

**Abstract**: Open-source large language models (LLMs) have demonstrated considerable dominance over proprietary LLMs in resolving neural processing tasks, thanks to the collaborative and sharing nature. Although full access to source codes, model parameters, and training data lays the groundwork for transparency, we argue that such a full-access manner is vulnerable to stego attacks, and their ill-effects are not fully understood. In this paper, we conduct a systematic formalization for stego attacks on open-source LLMs by enumerating all possible threat models associated with adversary objectives, knowledge, and capabilities. Therein, the threat posed by adversaries with internal knowledge, who inject payloads and triggers during the model sharing phase, is of practical interest. We go even further and propose the first stego attack on open-source LLMs, dubbed SASER, which wields impacts through identifying targeted parameters, embedding payloads, injecting triggers, and executing payloads sequentially. Particularly, SASER enhances the attack robustness against quantization-based local deployment by de-quantizing the embedded payloads. In addition, to achieve stealthiness, SASER devises the performance-aware importance metric to identify targeted parameters with the least degradation of model performance. Extensive experiments on LlaMA2-7B and ChatGLM3-6B, without quantization, show that the stealth rate of SASER outperforms existing stego attacks (for general DNNs) by up to 98.1%, while achieving the same attack success rate (ASR) of 100%. More importantly, SASER improves ASR on quantized models from 0 to 100% in all settings. We appeal for investigations on countermeasures against SASER in view of the significant attack effectiveness. 

**Abstract (ZH)**: 开源大型语言模型（LLMs）在解决神经处理任务方面展现出了比专有LLMs更大的优势，这得益于其协作和共享的性质。尽管完全访问源代码、模型参数和训练数据为透明性奠定了基础，但我们认为这种完全开放的访问方式易受隐写攻击的影响，其潜在危害尚未完全理解。在本文中，我们通过列举与对手目标、知识和能力相关的所有可能威胁模型，系统地对开源LLMs的隐写攻击进行了形式化分析。其中，在模型共享阶段具有内部知识的对手，在注入有效载荷和触发器时所构成的威胁具有实际意义。进一步地，我们提出了首个针对开源LLMs的隐写攻击，称为SASER，该攻击通过识别目标参数、嵌入有效载荷、注入触发器并顺序执行有效载荷来产生影响。特别是，SASER通过去量化嵌入的有效载荷来增强攻击在基于量化的地方部署中的鲁棒性。为了实现隐蔽性，SASER设计了考虑性能的重要性度量，以识别对模型性能影响最小的目标参数。在LlaMA2-7B和ChatGLM3-6B上未进行量化的情况下进行的大量实验表明，SASER的隐蔽率优于现有隐写攻击（适用于通用DNNs）高达98.1%，同时保持相同的攻击成功率（ASR）为100%。更重要的是，SASER在所有设置中将量化模型的ASR从0提高到100%。鉴于SASER攻击效果显著，我们呼吁对其防御措施进行研究。 

---
# UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models 

**Title (ZH)**: UltraLLaDA: 将上下文长度扩展至128K的扩散型大规模语言模型 

**Authors**: Guangxin He, Shen Nie, Fengqi Zhu, Yuankang Zhao, Tianyi Bai, Ran Yan, Jie Fu, Chongxuan Li, Binhang Yuan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10481)  

**Abstract**: Diffusion LLMs have attracted growing interest, with plenty of recent work emphasizing their great potential in various downstream tasks; yet the long-context behavior of diffusion LLMs remains largely uncharted. We present a case study of post-training techniques for extending the context window of diffusion LLMs (i.e., LLaDA) without retraining from scratch. We show that a simple modification to the standard Rotary Positional Embeddings (RoPE) extension effectively accommodates the probabilistic modeling inherent in the diffusion process, enabling stable scaling to longer context ranges. We further compare masking strategies used during post-training and analyze their impact on optimization stability and long-range recall. Instantiating these insights, we introduce UltraLLaDA, a diffusion LLM with a 128K-token context window that, in our empirical evaluation on long-context tasks, significantly outperforms training-free baselines. Our experimental results highlight the special positional extension as a key lever for scaling diffusion LLMs to extended contexts and offer practical guidance for practitioners seeking 128K-scale context via efficient post-training. 

**Abstract (ZH)**: Diffusion LLMs在长上下文行为方面的训练后技术研究：以LLaDA为例 

---
# Latent Retrieval Augmented Generation of Cross-Domain Protein Binders 

**Title (ZH)**: 跨域蛋白配体的隐空间检索增强生成 

**Authors**: Zishen Zhang, Xiangzhe Kong, Wenbing Huang, Yang Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10480)  

**Abstract**: Designing protein binders targeting specific sites, which requires to generate realistic and functional interaction patterns, is a fundamental challenge in drug discovery. Current structure-based generative models are limited in generating nterfaces with sufficient rationality and interpretability. In this paper, we propose Retrieval-Augmented Diffusion for Aligned interface (RADiAnce), a new framework that leverages known interfaces to guide the design of novel binders. By unifying retrieval and generation in a shared contrastive latent space, our model efficiently identifies relevant interfaces for a given binding site and seamlessly integrates them through a conditional latent diffusion generator, enabling cross-domain interface transfer. Extensive exeriments show that RADiAnce significantly outperforms baseline models across multiple metrics, including binding affinity and recovery of geometries and interactions. Additional experimental results validate cross-domain generalization, demonstrating that retrieving interfaces from diverse domains, such as peptides, antibodies, and protein fragments, enhances the generation performance of binders for other domains. Our work establishes a new paradigm for protein binder design that successfully bridges retrieval-based knowledge and generative AI, opening new possibilities for drug discovery. 

**Abstract (ZH)**: 基于检索增强扩散的对齐界面生成（RADiAnce）：一种利用已知界面指导新型结合物设计的新框架 

---
# Assessing Large Language Models for Structured Medical Order Extraction 

**Title (ZH)**: 评估大型语言模型在结构化医疗订单提取中的表现 

**Authors**: A H M Rezaul Karim, Ozlem Uzuner  

**Link**: [PDF](https://arxiv.org/pdf/2510.10475)  

**Abstract**: Medical order extraction is essential for structuring actionable clinical information, supporting decision-making, and enabling downstream applications such as documentation and workflow automation. Orders may be embedded in diverse sources, including electronic health records, discharge summaries, and multi-turn doctor-patient dialogues, and can span categories such as medications, laboratory tests, imaging studies, and follow-up actions. The MEDIQA-OE 2025 shared task focuses on extracting structured medical orders from extended conversational transcripts, requiring the identification of order type, description, reason, and provenance. We present the MasonNLP submission, which ranked 5th among 17 participating teams with 105 total submissions. Our approach uses a general-purpose, instruction-tuned LLaMA-4 17B model without domain-specific fine-tuning, guided by a single in-context example. This few-shot configuration achieved an average F1 score of 37.76, with notable improvements in reason and provenance accuracy. These results demonstrate that large, non-domain-specific LLMs, when paired with effective prompt engineering, can serve as strong, scalable baselines for specialized clinical NLP tasks. 

**Abstract (ZH)**: 医学订单提取对于结构化 actionable 临床信息、支持决策并促使下游应用如文档记录和工作流自动化至关重要。订单可能嵌入多种来源中，包括电子健康记录、出院总结和多轮医生-患者对话，并涵盖药物、实验室检查、影像学研究和随访行动等类别。MEDIQA-OE 2025 共享任务关注从扩展对话转录中提取结构化医疗订单，要求识别订单类型、描述、原因和起源。我们介绍了 MasonNLP 的提交，该提交在 17 支参赛团队、总计 105 个提交中排名第 5。我们的方法使用了一种通用的、指令调优的 LLaMA-4 17B 模型，未进行特定领域的微调，由一个上下文内示例引导。这种少样本配置实现了平均 F1 分数 37.76，特别是在原因和起源准确性方面有所改进。这些结果表明，当与有效的提示工程相结合时，大规模、非特定领域的语言模型可以作为专门临床 NLP 任务的强大、可扩展基线。 

---
# FML-bench: A Benchmark for Automatic ML Research Agents Highlighting the Importance of Exploration Breadth 

**Title (ZH)**: FML-bench: 一个强调探索广度重要性的自动机器学习研究代理基准测试 

**Authors**: Qiran Zou, Hou Hei Lam, Wenhao Zhao, Yiming Tang, Tingting Chen, Samson Yu, Tianyi Zhang, Chang Liu, Xiangyang Ji, Dianbo Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10472)  

**Abstract**: Large language models (LLMs) have sparked growing interest in automatic machine learning research agents. Among them, agents capable of autonomously proposing ideas and conducting machine learning experiments are particularly promising, as they maximize research automation and accelerate scientific progress by iteratively refining ideas based on experimental results. However, comprehensively evaluating such agents remains challenging. Existing benchmarks tend to overemphasize engineering aspects while neglecting academic rigor, creating barriers that obscure a clear assessment of an agent's scientific capabilities in machine learning research. They also suffer from limited task diversity, an overemphasis on application-oriented tasks over fundamental research problems, and limited scalability to realistic research settings. To address these limitations, we introduce FML-bench, a benchmark designed to evaluate automatic machine learning research agents on 8 diverse and fundamental machine learning research problems. It reduces coding burden, emphasizes fundamental problems rather than specific use cases, offers high task diversity, and is extensible to real-world machine learning GitHub repositories. Furthermore, we present a unified evaluation framework with five complementary metrics, designed to comprehensively assess agent performance on our benchmark. We evaluate state-of-the-art automatic research agents on FML-bench, and find that agents employing broad research exploration strategies outperform those focusing on narrow but deep exploration. These findings suggest that emphasizing the breadth of exploration may lead to more effective research outcomes than focusing solely on incremental refinement. Our benchmark is available at this https URL. 

**Abstract (ZH)**: 大规模语言模型（LLMs）引发了自动机器学习研究代理的广泛关注。其中，能够自主提出想法并开展机器学习实验的代理尤其具有前景，因为它们通过基于实验结果迭代优化想法来最大化研究自动化并加速科学进步。然而，全面评估这些代理仍然是一个挑战。现有基准倾向于过分强调工程方面而忽略学术 rigor，这创建了阻碍，使清晰评估代理在机器学习研究中的科学能力变得模糊。它们还面临着任务多样性有限、过于强调应用导向任务而非基础研究问题以及难以扩展到现实研究环境的局限。为了应对这些局限，我们引入了FML-bench，这是一个旨在评估自动机器学习研究代理在8个多样化和基础的机器学习研究问题上的基准。该基准减少了编码负担，强调基本问题而非特定用例，提供了高任务多样性，并可扩展到真实的机器学习GitHub仓库。此外，我们提出了一个统一的评估框架，包含五个互补的指标，旨在全面评估代理在本基准上的性能。我们在FML-bench上评估了最先进的自动研究代理，并发现采用广泛研究探索策略的代理优于专注于狭窄但深刻探索的代理。这些发现表明，强调探索的广度可能比仅仅关注逐步优化更为有效。我们的基准可在此处访问：this https URL。 

---
# AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs 

**Title (ZH)**: AnyBCQ: 多精度大型语言模型的硬件高效灵活二进制编码量化 

**Authors**: Gunho Park, Jeongin Bae, Beomseok Kwon, Byeongwook Kim, Se Jung Kwon, Dongsoo Lee  

**Link**: [PDF](https://arxiv.org/pdf/2510.10467)  

**Abstract**: The deployment of large language models (LLMs) is increasingly constrained by memory and latency bottlenecks, motivating the need for quantization techniques that flexibly balance accuracy and efficiency. Recent work has introduced multi-precision models, which enable inference at multiple precisions within a single model depending on runtime constraints. To support such flexibility, quantized weights are often stored as bit-planes, where hardware efficiency improves when the compute operates directly at the bit-plane level and activates only the precision required by each request. In this work, we present AnyBCQ, a hardware-friendly multi-precision extension of Binary-Coded Quantization (BCQ) that supports direct bit-plane operations. By representing weights as binary bit-planes with corresponding scale factors, AnyBCQ enables bit-plane-level computation and maps naturally to accelerator-friendly, bit-parallel arithmetic. Our progressive precision expansion mechanism incrementally refines scaling factors while reusing previously assigned binary codes, yielding monotonic improvements in accuracy as additional bits are enabled. We further co-design a specialized kernel that exploits the BCQ structure to support dynamic per-request precision selection with negligible overhead. Experiments on recent LLMs demonstrate that AnyBCQ significantly narrows the accuracy drop in the low-bit regime (e.g. 2-bit), remains competitive at higher precision, and achieves throughput gains of up to 3.0x over half precision and 1.2x over state-of-the-art multi-precision methods. By aligning algorithmic flexibility with hardware efficiency, AnyBCQ provides a practical foundation for multi-precision LLM deployment across diverse service-level objectives. 

**Abstract (ZH)**: 大语言模型（LLMs）的部署越来越受到内存和延迟瓶颈的限制，推动了灵活平衡准确性和效率的量化技术的需求。近期工作引入了多精度模型，能够在单个模型中根据运行时约束调整为多种精度进行推理。为了支持这种灵活性，量化的权重通常以位平面形式存储，当计算直接在位平面级别进行操作并仅激活每个请求所需的精度时，硬件效率会提高。在这项工作中，我们提出了AnyBCQ，这是一种硬件友好的多精度二进制编码量化（BCQ）扩展，支持直接位平面操作。通过将权重表示为带有相应缩放因子的二进制位平面，AnyBCQ可以实现位平面级别的计算，并自然地映射到加速器友好的位并行算术上。我们提出了一种渐进精度扩展机制，该机制逐步细化缩放因子并重用先前分配的二进制代码，从而在启用更多位时实现单调准确性的提升。我们还共同设计了一个专门的内核，利用BCQ结构支持动态每次请求的精度选择，几乎不增加额外开销。在最近的LLM上的实验表明，AnyBCQ在低位数区间（如2位）显著减小了准确率下降，保持在较高精度下竞争力，并实现了最高3.0倍的半精度吞吐量增益和1.2倍的最新多精度方法的吞吐量增益。通过将算法灵活性与硬件效率相结合，AnyBCQ为跨不同服务水平目标的大语言模型多精度部署提供了务实的基础。 

---
# LightSAE: Parameter-Efficient and Heterogeneity-Aware Embedding for IoT Multivariate Time Series Forecasting 

**Title (ZH)**: LightSAE：参数高效且适应异构性的物联网多变量时间序列预测嵌入方法 

**Authors**: Yi Ren, Xinjie Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10465)  

**Abstract**: Modern Internet of Things (IoT) systems generate massive, heterogeneous multivariate time series data. Accurate Multivariate Time Series Forecasting (MTSF) of such data is critical for numerous applications. However, existing methods almost universally employ a shared embedding layer that processes all channels identically, creating a representational bottleneck that obscures valuable channel-specific information. To address this challenge, we introduce a Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into a shared base component capturing common patterns and channel-specific auxiliary components modeling unique deviations. Within this decomposition, we \rev{empirically observe} that the auxiliary components tend to exhibit low-rank and clustering characteristics, a structural pattern that is significantly less apparent when using purely independent embeddings. Consequently, we design LightSAE, a parameter-efficient embedding module that operationalizes these observed characteristics through low-rank factorization and a shared, gated component pool. Extensive experiments across 9 IoT-related datasets and 4 backbone architectures demonstrate LightSAE's effectiveness, achieving MSE improvements of up to 22.8\% with only 4.0\% parameter increase. 

**Abstract (ZH)**: 现代物联网(IoT)系统生成大量的异构多变量时间序列数据。准确的多变量时间序列预测(MTSF)对于众多应用至关重要。然而，现有方法几乎无一例外地使用一个共享嵌入层，对所有通道进行相同处理，从而形成一种表现瓶颈，掩盖了有价值的时间序列通道特定信息。为解决这一挑战，我们引入了一个共享辅助嵌入(SAE)框架，将嵌入分解为一个捕捉共同模式的共享基础组件和用于建模独特偏差的通道特定辅助组件。在这分解中，我们实验证明辅助组件往往表现出低秩和聚类特性，而在仅使用独立嵌入时，这种结构模式明显不那么突出。因此，我们设计了LightSAE，一个高效参数嵌入模块，通过低秩因子分解和共享门控组件池来实现这些观察到的特性。广泛实验表明，LightSAE在9个物联网相关数据集和4种骨干架构上表现出色，仅增加4.0%的参数量，就能实现MSE最大22.8%的改进。 

---
# Learning from Disagreement: A Group Decision Simulation Framework for Robust Medical Image Segmentation 

**Title (ZH)**: 基于分歧的学习：一种用于稳健医疗图像分割的群体决策模拟框架 

**Authors**: Chen Zhong, Yuxuan Yang, Xinyue Zhang, Ruohan Ma, Yong Guo, Gang Li, Jupeng Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.10462)  

**Abstract**: Medical image segmentation annotation suffers from inter-rater variability (IRV) due to differences in annotators' expertise and the inherent blurriness of medical images. Standard approaches that simply average expert labels are flawed, as they discard the valuable clinical uncertainty revealed in disagreements. We introduce a fundamentally new approach with our group decision simulation framework, which works by mimicking the collaborative decision-making process of a clinical panel. Under this framework, an Expert Signature Generator (ESG) learns to represent individual annotator styles in a unique latent space. A Simulated Consultation Module (SCM) then intelligently generates the final segmentation by sampling from this space. This method achieved state-of-the-art results on challenging CBCT and MRI datasets (92.11% and 90.72% Dice scores). By treating expert disagreement as a useful signal instead of noise, our work provides a clear path toward more robust and trustworthy AI systems for healthcare. 

**Abstract (ZH)**: 医学图像分割注释由于注释者专业水平差异和医学图像的固有模糊性而导致评价者间变异性（IRV）。传统的简单平均专家标签的方法存在缺陷，因为它忽略了分歧中揭示的宝贵临床不确定性。我们通过组决策模拟框架引入了一种全新的方法，该框架通过模拟临床小组的协作决策过程来工作。在这一框架下，专家签名生成器（ESG）学习在独特的潜在空间中代表个体注释者的风格。然后，模拟咨询模块（SCM）通过从中抽样智能生成最终的分割结果。该方法在具有挑战性的CBCT和MRI数据集上取得了最先进的结果（Dice分数分别为92.11%和90.72%）。通过将专家分歧视为有用的信号而不是噪声，我们的工作提供了一条通往更可靠和值得信赖的医疗保健AI系统的清晰路径。 

---
# Testing and Enhancing Multi-Agent Systems for Robust Code Generation 

**Title (ZH)**: 测试与增强多agent系统以实现稳健的代码生成 

**Authors**: Zongyi Lyu, Songqiang Chen, Zhenlan Ji, Liwen Wang, Shuai Wang, Daoyuan Wu, Wenxuan Wang, Shing-Chi Cheung  

**Link**: [PDF](https://arxiv.org/pdf/2510.10460)  

**Abstract**: Multi-agent systems (MASs) have emerged as a promising paradigm for automated code generation, demonstrating impressive performance on established benchmarks by decomposing complex coding tasks across specialized agents with different roles. Despite their prosperous development and adoption, their robustness remains pressingly under-explored, raising critical concerns for real-world deployment. This paper presents the first comprehensive study examining the robustness of MASs for code generation through a fuzzing-based testing approach. By designing a fuzzing pipeline incorporating semantic-preserving mutation operators and a novel fitness function, we assess mainstream MASs across multiple datasets and LLMs. Our findings reveal substantial robustness flaws of various popular MASs: they fail to solve 7.9%-83.3% of problems they initially resolved successfully after applying the semantic-preserving mutations. Through comprehensive failure analysis, we identify a common yet largely overlooked cause of the robustness issue: miscommunications between planning and coding agents, where plans lack sufficient detail and coding agents misinterpret intricate logic, aligning with the challenges inherent in a multi-stage information transformation process. Accordingly, we also propose a repairing method that encompasses multi-prompt generation and introduces a new monitor agent to address this issue. Evaluation shows that our repairing method effectively enhances the robustness of MASs by solving 40.0%-88.9% of identified failures. Our work uncovers critical robustness flaws in MASs and provides effective mitigation strategies, contributing essential insights for developing more reliable MASs for code generation. 

**Abstract (ZH)**: 基于 fuzzing 的多-agent 系统代码生成鲁棒性研究 

---
# NIM: Neuro-symbolic Ideographic Metalanguage for Inclusive Communication 

**Title (ZH)**: NIM: 神经符号表意元语言促进包容性沟通 

**Authors**: Prawaal Sharma, Poonam Goyal, Navneet Goyal, Vidisha Sharma  

**Link**: [PDF](https://arxiv.org/pdf/2510.10459)  

**Abstract**: Digital communication has become the cornerstone of modern interaction, enabling rapid, accessible, and interactive exchanges. However, individuals with lower academic literacy often face significant barriers, exacerbating the "digital divide". In this work, we introduce a novel, universal ideographic metalanguage designed as an innovative communication framework that transcends academic, linguistic, and cultural boundaries. Our approach leverages principles of Neuro-symbolic AI, combining neural-based large language models (LLMs) enriched with world knowledge and symbolic knowledge heuristics grounded in the linguistic theory of Natural Semantic Metalanguage (NSM). This enables the semantic decomposition of complex ideas into simpler, atomic concepts. Adopting a human-centric, collaborative methodology, we engaged over 200 semi-literate participants in defining the problem, selecting ideographs, and validating the system. With over 80\% semantic comprehensibility, an accessible learning curve, and universal adaptability, our system effectively serves underprivileged populations with limited formal education. 

**Abstract (ZH)**: 数字通信已成为现代交互的基石，使快速、便捷和互动的交流成为可能。然而，低学术素养的个体往往面临显著障碍，加剧了“数字鸿沟”。在本文中，我们介绍了一种新颖的通用意象型元语言，设计为一种创新的超越学术、语言和文化边界的交流框架。我们的方法利用神经符号人工智能的原则，结合神经基础的大语言模型（LLMs），这些模型富含世界知识，并基于自然语义元语言（NSM）理论的地基符号知识启发式规则。这使复杂的概念能够分解为更简单、更基本的概念。采用以人为本、协作的方法，我们与超过200名半文盲参与者共同定义问题、选择意象并验证系统。通过超过80%的语义可理解性、易于学习的曲线和普遍适应性，我们的系统有效服务于受教育程度有限的弱势群体。 

---
# Data-driven simulator of multi-animal behavior with unknown dynamics via offline and online reinforcement learning 

**Title (ZH)**: 基于离线和在线强化学习的多动物行为数据驱动模拟器（未知动态情况） 

**Authors**: Keisuke Fujii, Kazushi Tsutsui, Yu Teshima, Makoto Itoh, Naoya Takeishi, Nozomi Nishiumi, Ryoya Tanaka, Shunsuke Shigaki, Yoshinobu Kawahara  

**Link**: [PDF](https://arxiv.org/pdf/2510.10451)  

**Abstract**: Simulators of animal movements play a valuable role in studying behavior. Advances in imitation learning for robotics have expanded possibilities for reproducing human and animal movements. A key challenge for realistic multi-animal simulation in biology is bridging the gap between unknown real-world transition models and their simulated counterparts. Because locomotion dynamics are seldom known, relying solely on mathematical models is insufficient; constructing a simulator that both reproduces real trajectories and supports reward-driven optimization remains an open problem. We introduce a data-driven simulator for multi-animal behavior based on deep reinforcement learning and counterfactual simulation. We address the ill-posed nature of the problem caused by high degrees of freedom in locomotion by estimating movement variables of an incomplete transition model as actions within an RL framework. We also employ a distance-based pseudo-reward to align and compare states between cyber and physical spaces. Validated on artificial agents, flies, newts, and silkmoth, our approach achieves higher reproducibility of species-specific behaviors and improved reward acquisition compared with standard imitation and RL methods. Moreover, it enables counterfactual behavior prediction in novel experimental settings and supports multi-individual modeling for flexible what-if trajectory generation, suggesting its potential to simulate and elucidate complex multi-animal behaviors. 

**Abstract (ZH)**: 基于深度强化学习和反事实模拟的多动物行为数据驱动仿真 

---
# Reverse Supervision at Scale: Exponential Search Meets the Economics of Annotation 

**Title (ZH)**: 大规模逆向监督：指数搜索与标注经济相结合 

**Authors**: Masoud Makrehchi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10446)  

**Abstract**: We analyze a reversed-supervision strategy that searches over labelings of a large unlabeled set \(B\) to minimize error on a small labeled set \(A\). The search space is \(2^n\), and the resulting complexity remains exponential even under large constant-factor speedups (e.g., quantum or massively parallel hardware). Consequently, arbitrarily fast -- but not exponentially faster -- computation does not obviate the need for informative labels or priors. In practice, the machine learning pipeline still requires an initial human contribution: specifying the objective, defining classes, and providing a seed set of representative annotations that inject inductive bias and align models with task semantics. Synthetic labels from generative AI can partially substitute provided their quality is human-grade and anchored by a human-specified objective, seed supervision, and validation. In this view, generative models function as \emph{label amplifiers}, leveraging small human-curated cores via active, semi-supervised, and self-training loops, while humans retain oversight for calibration, drift detection, and failure auditing. Thus, extreme computational speed reduces wall-clock time but not the fundamental supervision needs of learning; initial human (or human-grade) input remains necessary to ground the system in the intended task. 

**Abstract (ZH)**: 我们分析了一种反向监督策略，该策略在大规模未标注数据集 \(B\) 的标注中搜索，以最小化小型标注数据集 \(A\) 上的错误率。搜索空间为 \(2^n\)，即使在以常数因子极大的加速（如量子计算或大规模并行硬件）的情况下，结果的复杂度仍然是指数级的。因此，尽管可以实现任意快速的计算，但不是指数级别的加速并不能消除对信息性标签或先验知识的需求。在实践中，机器学习管道仍然需要初始的人类贡献：指定目标、定义类别以及提供代表性的种子标注，以注入归纳偏见并使模型与任务语义对齐。生成AI提供的合成标签在质量达到人类水平且基于人类指定的目标、种子监督和验证的情况下，可以部分替代真实标签的功能。从这一角度看，生成模型作为标签放大器，利用小规模的人类策划核心，通过主动的、半监督的和自我训练循环来放大标签，而人类保留校准、漂移检测和故障审计的监督。因此，极端的计算速度减少了壁钟时间，但并没有消除学习的基本监督需求；最初的人类（或人类水平）输入仍然是必要的，以确保系统与预期任务相契合。 

---
# Do Audio LLMs Really LISTEN, or Just Transcribe? Measuring Lexical vs. Acoustic Emotion Cues Reliance 

**Title (ZH)**: 音频LLMs真的倾听，还是仅仅转录？测量词汇与声学情感线索的依赖性 

**Authors**: Jingyi Chen, Zhimeng Guo, Jiyun Chun, Pichao Wang, Andrew Perrault, Micha Elsner  

**Link**: [PDF](https://arxiv.org/pdf/2510.10444)  

**Abstract**: Understanding emotion from speech requires sensitivity to both lexical and acoustic cues. However, it remains unclear whether large audio language models (LALMs) genuinely process acoustic information or rely primarily on lexical content. We present LISTEN (Lexical vs. Acoustic Speech Test for Emotion in Narratives), a controlled benchmark designed to disentangle lexical reliance from acoustic sensitivity in emotion understanding. Across evaluations of six state-of-the-art LALMs, we observe a consistent lexical dominance. Models predict "neutral" when lexical cues are neutral or absent, show limited gains under cue alignment, and fail to classify distinct emotions under cue conflict. In paralinguistic settings, performance approaches chance. These results indicate that current LALMs largely "transcribe" rather than "listen," relying heavily on lexical semantics while underutilizing acoustic cues. LISTEN offers a principled framework for assessing emotion understanding in multimodal models. 

**Abstract (ZH)**: Lexical vs. Acoustic Speech Test for Emotion in Narratives 

---
# Multi-Task Learning with Feature-Similarity Laplacian Graphs for Predicting Alzheimer's Disease Progression 

**Title (ZH)**: 基于特征相似性拉普拉斯图的多任务学习预测阿尔茨海默病进展 

**Authors**: Zixiang Xu, Menghui Zhou, Jun Qi, Xuanhan Fan, Yun Yang, Po Yang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10433)  

**Abstract**: Alzheimer's Disease (AD) is the most prevalent neurodegenerative disorder in aging populations, posing a significant and escalating burden on global healthcare systems. While Multi-Tusk Learning (MTL) has emerged as a powerful computational paradigm for modeling longitudinal AD data, existing frameworks do not account for the time-varying nature of feature correlations. To address this limitation, we propose a novel MTL framework, named Feature Similarity Laplacian graph Multi-Task Learning (MTL-FSL). Our framework introduces a novel Feature Similarity Laplacian (FSL) penalty that explicitly models the time-varying relationships between features. By simultaneously considering temporal smoothness among tasks and the dynamic correlations among features, our model enhances both predictive accuracy and biological interpretability. To solve the non-smooth optimization problem arising from our proposed penalty terms, we adopt the Alternating Direction Method of Multipliers (ADMM) algorithm. Experiments conducted on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that our proposed MTL-FSL framework achieves state-of-the-art performance, outperforming various baseline methods. The implementation source can be found at this https URL. 

**Abstract (ZH)**: 阿尔茨海默病（AD）是老年人群中最常见的神经退行性疾病，对全球医疗保健系统造成了重大且不断上升的负担。虽然多任务学习（MTL）已成为建模纵向AD数据的强大计算范式，但现有框架未能考虑特征相关性的时变性。为解决这一局限性，我们提出了一种新型MTL框架，即特征相似性拉普拉斯图多任务学习（MTL-FSL）。该框架引入了一种新型特征相似性拉普拉斯（FSL）惩罚项，明确地建模了特征间的时变关系。通过同时考虑任务间的时序平滑性和特征间的动态相关性，我们的模型提升了预测准确性和生物学解释性。为解决由我们提议的惩罚项引起的非光滑优化问题，我们采用了交替方向乘子算法（ADMM）。在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验表明，我们提出的MTL-FSL框架达到了最先进的性能，超越了各种基线方法。源代码可以在以下链接找到：this https URL。 

---
# Hierarchical LoRA MoE for Efficient CTR Model Scaling 

**Title (ZH)**: 层级LoRA MoE用于高效的CTR模型扩展 

**Authors**: Zhichen Zeng, Mengyue Hang, Xiaolong Liu, Xiaoyi Liu, Xiao Lin, Ruizhong Qiu, Tianxin Wei, Zhining Liu, Siyang Yuan, Chaofei Yang, Yiqun Liu, Hang Yin, Jiyan Yang, Hanghang Tong  

**Link**: [PDF](https://arxiv.org/pdf/2510.10432)  

**Abstract**: Deep models have driven significant advances in click-through rate (CTR) prediction. While vertical scaling via layer stacking improves model expressiveness, the layer-by-layer sequential computation poses challenges to efficient scaling. Conversely, horizontal scaling through Mixture of Experts (MoE) achieves efficient scaling by activating a small subset of experts in parallel, but flat MoE layers may struggle to capture the hierarchical structure inherent in recommendation tasks. To push the Return-On-Investment (ROI) boundary, we explore the complementary strengths of both directions and propose HiLoMoE, a hierarchical LoRA MoE framework that enables holistic scaling in a parameter-efficient manner. Specifically, HiLoMoE employs lightweight rank-1 experts for parameter-efficient horizontal scaling, and stacks multiple MoE layers with hierarchical routing to enable combinatorially diverse expert compositions. Unlike conventional stacking, HiLoMoE routes based on prior layer scores rather than outputs, allowing all layers to execute in parallel. A principled three-stage training framework ensures stable optimization and expert diversity. Experiments on four public datasets show that HiLoMoE achieving better performance-efficiency tradeoff, achieving an average AUC improvement of 0.20\% in AUC and 18.5\% reduction in FLOPs compared to the non-MoE baseline. 

**Abstract (ZH)**: 深度模型在点击率（CTR）预测中推动了重要进展。垂直扩展通过层堆叠提高模型的表现力，但逐层序列计算会面临高效扩展的挑战。相反，通过混合专家（MoE）的水平扩展能够在并行激活少量专家的同时实现高效扩展，但平面MoE层可能难以捕捉推荐任务中固有的层次结构。为推动投资回报率（ROI）边界，我们探索了这两种方向的互补优势，并提出HiLoMoE，这是一种层级LoRA MoE框架，能够在参数有效的方式来实现整体扩展。具体来说，HiLoMoE 使用轻量级的秩1专家来进行参数有效的方式的水平扩展，并通过层级路由堆叠多个MoE层以实现组合多样的专家组成。与传统的堆叠不同，HiLoMoE 基于前一层的分数来路由，而不是输出，使得所有层能够并行执行。合理的三阶段训练框架确保了优化的稳定性和专家多样性。实验结果显示，HiLoMoE 在 AUC 上平均提升了 0.20%，在 FLOPs 上减少了 18.5%，相比非 MoE 基线表现出更好的性能效率折中。 

---
# Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs 

**Title (ZH)**: 驯化一个检索框架以具备类人方式阅读图像的能力，以增强大语言模型的生成能力 

**Authors**: Suyang Xi, Chenxi Yang, Hong Ding, Yiqing Ni, Catherine C. Liu, Yunhao Liu, Chengqi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10426)  

**Abstract**: Multimodal large language models (MLLMs) often fail in fine-grained visual question answering, producing hallucinations about object identities, positions, and relations because textual queries are not explicitly anchored to visual referents. Retrieval-augmented generation (RAG) alleviates some errors, but it fails to align with human-like processing at both the retrieval and augmentation levels. Specifically, it focuses only on global-level image information but lacks local detail and limits reasoning about fine-grained interactions. To overcome this limitation, we present Human-Like Retrieval-Augmented Generation (HuLiRAG), a framework that stages multimodal reasoning as a ``what--where--reweight'' cascade. Queries are first anchored to candidate referents via open-vocabulary detection (what), then spatially resolved with SAM-derived masks to recover fine-grained precision (where), and adaptively prioritized through the trade-off between local and global alignment (reweight). Mask-guided fine-tuning further injects spatial evidence into the generation process, transforming grounding from a passive bias into an explicit constraint on answer formulation. Extensive experiments demonstrate that this human-like cascade improves grounding fidelity and factual consistency while reducing hallucinations, advancing multimodal question answering toward trustworthy reasoning. 

**Abstract (ZH)**: 具有人类似的检索增强生成：面向细粒度视觉问答的多模态推理框架（Human-Like Retrieval-Augmented Generation (HuLiRAG) for Fine-Grained Visual Question Answering） 

---
# Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis 

**Title (ZH)**: Combo-Gait：统一Transformer框架的多模态步态识别与属性分析 

**Authors**: Zhao-Yang Wang, Zhimin Shao, Jieneng Chen, Rama Chellappa  

**Link**: [PDF](https://arxiv.org/pdf/2510.10417)  

**Abstract**: Gait recognition is an important biometric for human identification at a distance, particularly under low-resolution or unconstrained environments. Current works typically focus on either 2D representations (e.g., silhouettes and skeletons) or 3D representations (e.g., meshes and SMPLs), but relying on a single modality often fails to capture the full geometric and dynamic complexity of human walking patterns. In this paper, we propose a multi-modal and multi-task framework that combines 2D temporal silhouettes with 3D SMPL features for robust gait analysis. Beyond identification, we introduce a multitask learning strategy that jointly performs gait recognition and human attribute estimation, including age, body mass index (BMI), and gender. A unified transformer is employed to effectively fuse multi-modal gait features and better learn attribute-related representations, while preserving discriminative identity cues. Extensive experiments on the large-scale BRIAR datasets, collected under challenging conditions such as long-range distances (up to 1 km) and extreme pitch angles (up to 50°), demonstrate that our approach outperforms state-of-the-art methods in gait recognition and provides accurate human attribute estimation. These results highlight the promise of multi-modal and multitask learning for advancing gait-based human understanding in real-world scenarios. 

**Abstract (ZH)**: 多模态多任务框架在多挑战条件下的步态识别及人体属性估计 

---
# LONGQAEVAL: Designing Reliable Evaluations of Long-Form Clinical QA under Resource Constraints 

**Title (ZH)**: LONGQAEVAL: 在资源约束条件下设计可靠的长形式临床问答评估 

**Authors**: Federica Bologna, Tiffany Pan, Matthew Wilkens, Yue Guo, Lucy Lu Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10415)  

**Abstract**: Evaluating long-form clinical question answering (QA) systems is resource-intensive and challenging: accurate judgments require medical expertise and achieving consistent human judgments over long-form text is difficult. We introduce LongQAEval, an evaluation framework and set of evaluation recommendations for limited-resource and high-expertise settings. Based on physician annotations of 300 real patient questions answered by physicians and LLMs, we compare coarse answer-level versus fine-grained sentence-level evaluation over the dimensions of correctness, relevance, and safety. We find that inter-annotator agreement (IAA) varies by dimension: fine-grained annotation improves agreement on correctness, coarse improves agreement on relevance, and judgments on safety remain inconsistent. Additionally, annotating only a small subset of sentences can provide reliability comparable to coarse annotations, reducing cost and effort. 

**Abstract (ZH)**: 基于医师标注的长格式临床问答系统评估框架和建议 

---
# Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes 

**Title (ZH)**: Mesh-Gait：一种基于多模态表示学习的2D轮廓统一框架的人体姿态识别方法 

**Authors**: Zhao-Yang Wang, Jieneng Chen, Jiang Liu, Yuxiang Guo, Rama Chellappa  

**Link**: [PDF](https://arxiv.org/pdf/2510.10406)  

**Abstract**: Gait recognition, a fundamental biometric technology, leverages unique walking patterns for individual identification, typically using 2D representations such as silhouettes or skeletons. However, these methods often struggle with viewpoint variations, occlusions, and noise. Multi-modal approaches that incorporate 3D body shape information offer improved robustness but are computationally expensive, limiting their feasibility for real-time applications. To address these challenges, we introduce Mesh-Gait, a novel end-to-end multi-modal gait recognition framework that directly reconstructs 3D representations from 2D silhouettes, effectively combining the strengths of both modalities. Compared to existing methods, directly learning 3D features from 3D joints or meshes is complex and difficult to fuse with silhouette-based gait features. To overcome this, Mesh-Gait reconstructs 3D heatmaps as an intermediate representation, enabling the model to effectively capture 3D geometric information while maintaining simplicity and computational efficiency. During training, the intermediate 3D heatmaps are gradually reconstructed and become increasingly accurate under supervised learning, where the loss is calculated between the reconstructed 3D joints, virtual markers, and 3D meshes and their corresponding ground truth, ensuring precise spatial alignment and consistent 3D structure. Mesh-Gait extracts discriminative features from both silhouettes and reconstructed 3D heatmaps in a computationally efficient manner. This design enables the model to capture spatial and structural gait characteristics while avoiding the heavy overhead of direct 3D reconstruction from RGB videos, allowing the network to focus on motion dynamics rather than irrelevant visual details. Extensive experiments demonstrate that Mesh-Gait achieves state-of-the-art accuracy. The code will be released upon acceptance of the paper. 

**Abstract (ZH)**: 步态识别，一种基本的生物识别技术，利用独特的行走模式进行个体识别，通常使用2D表示，如轮廓或骨架。然而，这些方法往往难以处理视角变化、遮挡和噪声。多模态方法结合3D身体形状信息可以提高鲁棒性，但计算成本高，限制了其在实时应用中的可行性。为应对这些挑战，我们提出了一种新颖的端到端多模态步态识别框架Mesh-Gait，直接从2D轮廓重建3D表示，有效结合了两种模态的优势。与现有方法相比，直接从3D关节或网格中学习3D特征并将其与基于轮廓的步态特征融合既复杂又困难。为克服这一挑战，Mesh-Gait 构建了3D热图作为中间表示，使模型能够有效捕捉3D几何信息，同时保持简洁性和计算效率。在训练过程中，中间的3D热图在监督学习下逐渐重建并变得越来越准确，损失函数在重建的3D关节、虚拟标记、3D网格及其对应的地面真相之间计算，确保精确的空间对齐和一致的3D结构。Mesh-Gait 以计算高效的方式从轮廓和重建的3D热图中提取判别性特征。该设计使模型能够捕获空间和结构的步态特征，同时避免了从RGB视频直接进行3D重建时的沉重开销，使网络能够专注于运动动态而非无关的视觉细节。大量实验表明，Mesh-Gait 达到了最先进的准确率。代码将在论文被接受后发布。 

---
# Controllable Graph Generation with Diffusion Models via Inference-Time Tree Search Guidance 

**Title (ZH)**: 控制性的图生成方法：基于推断时树搜索指导的扩散模型 

**Authors**: Jiachi Zhao, Zehong Wang, Yamei Liao, Chuxu Zhang, Yanfang Ye  

**Link**: [PDF](https://arxiv.org/pdf/2510.10402)  

**Abstract**: Graph generation is a fundamental problem in graph learning with broad applications across Web-scale systems, knowledge graphs, and scientific domains such as drug and material discovery. Recent approaches leverage diffusion models for step-by-step generation, yet unconditional diffusion offers little control over desired properties, often leading to unstable quality and difficulty in incorporating new objectives. Inference-time guidance methods mitigate these issues by adjusting the sampling process without retraining, but they remain inherently local, heuristic, and limited in controllability. To overcome these limitations, we propose TreeDiff, a Monte Carlo Tree Search (MCTS) guided dual-space diffusion framework for controllable graph generation. TreeDiff is a plug-and-play inference-time method that expands the search space while keeping computation tractable. Specifically, TreeDiff introduces three key designs to make it practical and scalable: (1) a macro-step expansion strategy that groups multiple denoising updates into a single transition, reducing tree depth and enabling long-horizon exploration; (2) a dual-space denoising mechanism that couples efficient latent-space denoising with lightweight discrete correction in graph space, ensuring both scalability and structural fidelity; and (3) a dual-space verifier that predicts long-term rewards from partially denoised graphs, enabling early value estimation and removing the need for full rollouts. Extensive experiments on 2D and 3D molecular generation benchmarks, under both unconditional and conditional settings, demonstrate that TreeDiff achieves state-of-the-art performance. Notably, TreeDiff exhibits favorable inference-time scaling: it continues to improve with additional computation, while existing inference-time methods plateau early under limited resources. 

**Abstract (ZH)**: 基于树搜索的可控图生成树Diff框架 

---
# STEAM: A Semantic-Level Knowledge Editing Framework for Large Language Models 

**Title (ZH)**: STEAM：一种面向大规模语言模型的语义级别知识编辑框架 

**Authors**: Geunyeong Jeong, Juoh Sun, Seonghee Lee, Harksoo Kim  

**Link**: [PDF](https://arxiv.org/pdf/2510.10398)  

**Abstract**: Large Language Models store extensive factual knowledge acquired during large-scale pre-training. However, this knowledge is inherently static, reflecting only the state of the world at the time of training. Knowledge editing has emerged as a promising solution for updating outdated or incorrect facts without full retraining. However, most existing locate-and-edit methods primarily focus on token-level likelihood optimization without addressing semantic coherence. Our analysis reveals that such edited knowledge is often encoded as isolated residual streams in the model's latent space, distinct from pre-existing knowledge and bypassing natural reasoning process. To address this, we propose \textsc{Steam}, a semantic-level knowledge editing framework that enhances integration of updated knowledge into the model's knowledge structure. \textsc{Steam} first identifies target representations as semantic anchors for the updated factual association, then guides the internal representation of the edited fact towards these anchors through an alignment loss during optimization. Experimental results demonstrate that \textsc{Steam} improves model's ability to reason with edited knowledge and enhances semantic coherence, underscoring the importance of latent-space alignment for reliable and coherent knowledge editing. The code is available at this https URL. 

**Abstract (ZH)**: Large Language Models 存储了大量在大规模预训练过程中获得的事实知识。然而，这些知识本质是静态的，仅反映训练时的世界状态。知识编辑已作为一种有前景的解决方案出现，用于更新过时或错误的事实而无需进行全面重新训练。然而，大多数现有的查找和编辑方法主要集中在字符级别似然性优化上，而未能解决语义连贯性问题。我们的分析表明，这些编辑后的知识往往被编码为模型潜在空间中的孤立残差流，与预存知识隔绝，并绕过了自然推理过程。为解决这一问题，我们提出了一种名为 \textsc{Steam} 的语义级知识编辑框架，以增强更新知识与模型知识结构的整合。首先，\textsc{Steam} 确定目标表示作为更新事实关联的语义锚点，然后在优化过程中通过对齐损失引导编辑事实的内部表示朝向这些锚点。实验结果表明，\textsc{Steam} 提高了模型处理编辑知识的能力，并增强了语义连贯性，突显了潜在空间对齐对于可靠且连贯的知识编辑的重要性。代码可在以下网址获取：this https URL。 

---
# RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models 

**Title (ZH)**: RefusalBench: 生成评估基于地面真相语言模型的选择性拒绝能力 

**Authors**: Aashiq Muhamed, Leonardo F. R. Ribeiro, Markus Dreyer, Virginia Smith, Mona T. Diab  

**Link**: [PDF](https://arxiv.org/pdf/2510.10390)  

**Abstract**: The ability of language models in RAG systems to selectively refuse to answer based on flawed context is critical for safety, yet remains a significant failure point. Our large-scale study reveals that even frontier models struggle in this setting, with refusal accuracy dropping below 50% on multi-document tasks, while exhibiting either dangerous overconfidence or overcaution. Static benchmarks fail to reliably evaluate this capability, as models exploit dataset-specific artifacts and memorize test instances. We introduce RefusalBench, a generative methodology that programmatically creates diagnostic test cases through controlled linguistic perturbation. Our framework employs 176 distinct perturbation strategies across six categories of informational uncertainty and three intensity levels. Evaluation of over 30 models uncovers systematic failure patterns: refusal comprises separable detection and categorization skills, and neither scale nor extended reasoning improves performance. We find that selective refusal is a trainable, alignment-sensitive capability, offering a clear path for improvement. We release two benchmarks -- RefusalBench-NQ (single document) and RefusalBench-GaRAGe (multi-document) -- and our complete generation framework to enable continued, dynamic evaluation of this critical capability. 

**Abstract (ZH)**: 基于RAG系统中语言模型在面对错误上下文时选择性拒绝回答的能力对于安全性至关重要，但仍然是一个显著的失败点。我们的大规模研究揭示，即使是前沿模型在此情境下表现不佳，多文档任务中的拒绝准确率低于50%，且表现出危险的过度自信或过度谨慎。静态基准无法可靠评估这一能力，因为模型利用了数据集特定的特征并记忆了测试实例。我们引入了RefusalBench，这是一种生成方法，通过可控的语言扰动程序化地创建诊断测试案例。我们的框架涵盖了六类信息不确定性中的176种不同的扰动策略，以及三个强度级别。对30多个模型的评估发现了系统性的失败模式：拒绝回答包含了可分离的检测和分类技能，而规模和扩展推理均未提高性能。我们发现，选择性拒绝是可训练且对齐敏感的能力，为改进指明了清晰路径。我们发布了两个基准——RefusalBench-NQ（单一文档）和RefusalBench-GaRAGe（多文档）——以及我们的完整生成框架，以使对这一关键能力进行持续和动态评估成为可能。 

---
# Identifying bias in CNN image classification using image scrambling and transforms 

**Title (ZH)**: 使用图像杂乱和变换识别CNN图像分类中的偏差 

**Authors**: Sai Teja Erukude  

**Link**: [PDF](https://arxiv.org/pdf/2510.10383)  

**Abstract**: CNNs are now prevalent as the primary choice for most machine vision problems due to their superior rate of classification and the availability of user-friendly libraries. These networks effortlessly identify and select features in a non-intuitive data-driven manner, making it difficult to determine which features were most influential. That leads to a ``black box", where users cannot know how the image data are analyzed but rely on empirical results. Therefore the decision-making process can be biased by background information that is difficult to detect. Here we discuss examples of such hidden biases and propose techniques for identifying them, methods to distinguish between contextual information and background noise, and explore whether CNNs learn from irrelevant features. One effective approach to identify dataset bias is to classify blank background parts of the images. However, in some situations a blank background in the images is not available, making it more difficult to separate the foreground information from the blank background. Such parts of the image can also be considered contextual learning, not necessarily bias. To overcome this, we propose two approaches that were tested on six different datasets, including natural, synthetic, and hybrid datasets. The first method involves dividing images into smaller, non-overlapping tiles of various sizes, which are then shuffled randomly, making classification more challenging. The second method involves the application of several image transforms, including Fourier, Wavelet transforms, and Median filter, and their combinations. These transforms help recover background noise information used by CNN to classify images. Results indicate that this method can effectively distinguish between contextual information and background noise, and alert on the presence of background noise even without the need to use background information. 

**Abstract (ZH)**: CNNs在图像数据分类中的隐藏偏差识别与区分方法 

---
# RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning 

**Title (ZH)**: RobotFleet: 一种开源的集中式多机器人任务规划框架 

**Authors**: Rohan Gupta, Trevor Asbery, Zain Merchant, Abrar Anwar, Jesse Thomason  

**Link**: [PDF](https://arxiv.org/pdf/2510.10379)  

**Abstract**: Coordinating heterogeneous robot fleets to achieve multiple goals is challenging in multi-robot systems. We introduce an open-source and extensible framework for centralized multi-robot task planning and scheduling that leverages LLMs to enable fleets of heterogeneous robots to accomplish multiple tasks. RobotFleet provides abstractions for planning, scheduling, and execution across robots deployed as containerized services to simplify fleet scaling and management. The framework maintains a shared declarative world state and two-way communication for task execution and replanning. By modularizing each layer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet lowers the barrier to building scalable multi-robot systems. The code can be found here: this https URL. 

**Abstract (ZH)**: 基于LLM的协调异构机器人舰队实现多目标的集中式多机器人任务规划与调度框架 

---
# Ortho-Fuse: Orthomosaic Generation for Sparse High-Resolution Crop Health Maps Through Intermediate Optical Flow Estimation 

**Title (ZH)**: 正交融合：通过中间光学流估计生成稀疏高分辨率作物健康图的正交全景图生成方法 

**Authors**: Rugved Katole, Christopher Stewart  

**Link**: [PDF](https://arxiv.org/pdf/2510.10360)  

**Abstract**: AI-driven crop health mapping systems offer substantial advantages over conventional monitoring approaches through accelerated data acquisition and cost reduction. However, widespread farmer adoption remains constrained by technical limitations in orthomosaic generation from sparse aerial imagery datasets. Traditional photogrammetric reconstruction requires 70-80\% inter-image overlap to establish sufficient feature correspondences for accurate geometric registration. AI-driven systems operating under resource-constrained conditions cannot consistently achieve these overlap thresholds, resulting in degraded reconstruction quality that undermines user confidence in autonomous monitoring technologies. In this paper, we present Ortho-Fuse, an optical flow-based framework that enables the generation of a reliable orthomosaic with reduced overlap requirements. Our approach employs intermediate flow estimation to synthesize transitional imagery between consecutive aerial frames, artificially augmenting feature correspondences for improved geometric reconstruction. Experimental validation demonstrates a 20\% reduction in minimum overlap requirements. We further analyze adoption barriers in precision agriculture to identify pathways for enhanced integration of AI-driven monitoring systems. 

**Abstract (ZH)**: 基于AI的作物健康映射系统通过加速数据获取和降低成本提供了显著优势，但广泛农民采纳受到稀疏航拍影像数据正射影像生成技术限制。传统摄影测量重建需要70-80%的影像重叠以建立足够的特征对应关系，确保几何注册精度。在资源受限条件下运行的AI驱动系统无法一致地达到这些重叠阈值，导致重建质量下降，损害用户对自主监测技术的信心。本文介绍了一种基于光学流的框架Ortho-Fuse，能够以减少的重叠要求生成可靠的正射影像。通过中间流估计合成连续航拍帧之间的过渡影像，人为增强特征对应关系，提高几何重建效果。实验验证显示重叠要求减少了20%。我们进一步分析了精准农业中的采纳障碍，以识别增强AI驱动监测系统集成的途径。 

---
# Measuring What Matters: Connecting AI Ethics Evaluations to System Attributes, Hazards, and Harms 

**Title (ZH)**: 衡量重要事项：将AI伦理评估与系统属性、风险和危害连接起来 

**Authors**: Shalaleh Rismani, Renee Shelby, Leah Davis, Negar Rostamzadeh, AJung Moon  

**Link**: [PDF](https://arxiv.org/pdf/2510.10339)  

**Abstract**: Over the past decade, an ecosystem of measures has emerged to evaluate the social and ethical implications of AI systems, largely shaped by high-level ethics principles. These measures are developed and used in fragmented ways, without adequate attention to how they are situated in AI systems. In this paper, we examine how existing measures used in the computing literature map to AI system components, attributes, hazards, and harms. Our analysis draws on a scoping review resulting in nearly 800 measures corresponding to 11 AI ethics principles. We find that most measures focus on four principles - fairness, transparency, privacy, and trust - and primarily assess model or output system components. Few measures account for interactions across system elements, and only a narrow set of hazards is typically considered for each harm type. Many measures are disconnected from where harm is experienced and lack guidance for setting meaningful thresholds. These patterns reveal how current evaluation practices remain fragmented, measuring in pieces rather than capturing how harms emerge across systems. Framing measures with respect to system attributes, hazards, and harms can strengthen regulatory oversight, support actionable practices in industry, and ground future research in systems-level understanding. 

**Abstract (ZH)**: 过去十年，已形成一套评估人工智能系统社会和伦理影响的措施体系，这些措施主要受高级伦理原则的影响。这些措施在分散状态下开发和使用，未充分关注其在人工智能系统中的位置。本文探讨了计算文献中现有措施如何映射到人工智能系统的组件、属性、危险和伤害。我们的分析基于范围性回顾，涉及800多项措施，这些措施对应于11个人工智能伦理原则。我们发现，大多数措施侧重于公平性、透明性、隐私性和信任性这四项原则，并主要评估模型或输出系统组件。很少有措施考虑到系统元素之间的交互，每种伤害类型通常只考虑一组狭窄的危险。许多措施与实际体验到的伤害脱节，缺乏设定有意义阈值的指导。这些模式揭示了当前评估实践仍然碎片化，只片段地测量，未能捕捉到跨系统如何出现危害。从系统属性、危险和伤害的角度框架措施可以增强监管监督，支持行业中的可操作实践，并为未来的系统级理解奠定基础。 

---
# Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework 

**Title (ZH)**: 基于软Actor- Critic框架的双轴线转向机器人安全机动方法 

**Authors**: Kohio Deflesselle, Mélodie Daniel, Aly Magassouba, Miguel Aranda, Olivier Ly  

**Link**: [PDF](https://arxiv.org/pdf/2510.10332)  

**Abstract**: We present a deep reinforcement learning framework based on Soft Actor-Critic (SAC) for safe and precise maneuvering of double-Ackermann-steering mobile robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as differential-drive robots, DASMRs face strong kinematic constraints that make classical planners brittle in cluttered environments. Our framework leverages the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage maneuvering efficiency while avoiding obstacles. Simulation results with a heavy four-wheel-steering rover show that the learned policy can robustly reach up to 97% of target positions while avoiding obstacles. Our framework does not rely on handcrafted trajectories or expert demonstrations. 

**Abstract (ZH)**: 基于Soft Actor-Critic (SAC)的安全精准双Ackermann转向移动机器人操作的深度强化学习框架 

---
# Mapping the Urban Mobility Intelligence Frontier: A Scientometric Analysis of Data-Driven Pedestrian Trajectory Prediction and Simulation 

**Title (ZH)**: 城市 Mobility 智能前沿mapping：基于数据驱动的行人轨迹预测与模拟的文献计量分析 

**Authors**: Junhao Xu, Hui Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2510.10327)  

**Abstract**: Understanding and predicting pedestrian dynamics has become essential for shaping safer, more responsive, and human-centered urban environments. This study conducts a comprehensive scientometric analysis of research on data-driven pedestrian trajectory prediction and crowd simulation, mapping its intellectual evolution and interdisciplinary structure. Using bibliometric data from the Web of Science Core Collection, we employ SciExplorer and Bibliometrix to identify major trends, influential contributors, and emerging frontiers. Results reveal a strong convergence between artificial intelligence, urban informatics, and crowd behavior modeling--driven by graph neural networks, transformers, and generative models. Beyond technical advances, the field increasingly informs urban mobility design, public safety planning, and digital twin development for smart cities. However, challenges remain in ensuring interpretability, inclusivity, and cross-domain transferability. By connecting methodological trajectories with urban applications, this work highlights how data-driven approaches can enrich urban governance and pave the way for adaptive, socially responsible mobility intelligence in future cities. 

**Abstract (ZH)**: 基于数据驱动的行人轨迹预测与人群模拟研究：理解与预测行人动态已成塑造更安全、更响应且以人为本的城市环境的关键。本研究通过文献计量分析，揭示该领域的智力演化和跨学科结构，并采用图神经网络、变压器和生成模型推动的技术进步，探讨其在城市交通设计、公共安全规划和智慧城市数字孪生开发中的应用。然而，提高解释性、包容性和跨域转移性仍是挑战。通过将方法论轨迹与城市应用相结合，本文强调数据驱动方法如何丰富城市治理，并为未来城市的社会责任移动智能铺平道路。 

---
# KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments 

**Title (ZH)**: KG-MAS: 知识图谱增强的多智能体基础设施，用于耦合物理和数字机器人环境 

**Authors**: Walid Abdela  

**Link**: [PDF](https://arxiv.org/pdf/2510.10325)  

**Abstract**: The seamless integration of physical and digital environments in Cyber-Physical Systems(CPS), particularly within Industry 4.0, presents significant challenges stemming from system heterogeneity and complexity. Traditional approaches often rely on rigid, data-centric solutions like co-simulation frameworks or brittle point-to-point middleware bridges, which lack the semantic richness and flexibility required for intelligent, autonomous coordination. This report introduces the Knowledge Graph-Enhanced Multi-Agent Infrastructure(KG-MAS), as resolution in addressing such limitations. KG-MAS leverages a centralized Knowledge Graph (KG) as a dynamic, shared world model, providing a common semantic foundation for a Multi-Agent System(MAS). Autonomous agents, representing both physical and digital components, query this KG for decision-making and update it with real-time state information. The infrastructure features a model-driven architecture which facilitates the automatic generation of agents from semantic descriptions, thereby simplifying system extension and maintenance. By abstracting away underlying communication protocols and providing a unified, intelligent coordination mechanism, KG-MAS offers a robust, scalable, and flexible solution for coupling heterogeneous physical and digital robotic environments. 

**Abstract (ZH)**: Cyber-Physical系统(CPS)中物理与数字环境的无缝集成，特别是在工业4.0中，由于系统异构性和复杂性带来了显著挑战。传统方法往往依赖于像协同仿真框架或脆弱的点对点中间件桥接这样的刚性、数据为中心的解决方案，这些方法缺乏智能自主协调所需的语义丰富性和灵活性。本报告介绍了知识图谱增强的多代理基础设施(KG-MAS)，以解决这些局限性。KG-MAS利用中央化的知识图谱(KG)作为动态的共享世界模型，为多代理系统(MAS)提供一个共同的语义基础。自主代理，代表物理和数字组件，通过查询KG进行决策并实时更新其状态信息。该基础设施采用模型驱动架构，支持从语义描述自动生成代理，从而简化系统的扩展和维护。通过抽象底层通信协议并提供统一的智能协调机制，KG-MAS为异构物理和数字机器人环境的互联提供了稳健、可扩展和灵活的解决方案。 

---
# Bridging Semantics & Structure for Software Vulnerability Detection using Hybrid Network Models 

**Title (ZH)**: 基于混合网络模型的语义与结构桥梁构建以检测软件漏洞 

**Authors**: Jugal Gajjar, Kaustik Ranaware, Kamalasankari Subramaniakuppusamy  

**Link**: [PDF](https://arxiv.org/pdf/2510.10321)  

**Abstract**: Software vulnerabilities remain a persistent risk, yet static and dynamic analyses often overlook structural dependencies that shape insecure behaviors. Viewing programs as heterogeneous graphs, we capture control- and data-flow relations as complex interaction networks. Our hybrid framework combines these graph representations with light-weight (<4B) local LLMs, uniting topological features with semantic reasoning while avoiding the cost and privacy concerns of large cloud models. Evaluated on Java vulnerability detection (binary classification), our method achieves 93.57% accuracy-an 8.36% gain over Graph Attention Network-based embeddings and 17.81% over pretrained LLM baselines such as Qwen2.5 Coder 3B. Beyond accuracy, the approach extracts salient subgraphs and generates natural language explanations, improving interpretability for developers. These results pave the way for scalable, explainable, and locally deployable tools that can shift vulnerability analysis from purely syntactic checks to deeper structural and semantic insights, facilitating broader adoption in real-world secure software development. 

**Abstract (ZH)**: 软件漏洞依然构成持续的风险，然而静态和动态分析往往忽视了塑造不安全行为的结构依赖关系。将程序视为异构图，我们捕捉控制流和数据流关系作为复杂交互网络。我们的混合框架将这些图表示与轻量级（<4B）局部LLM结合，同时融合拓扑特征和语义推理，避免了大规模云模型的成本和隐私问题。在Java漏洞检测（二分类）评估中，我们的方法实现了93.57%的准确率，分别比基于图注意网络的嵌入高出8.36%，比预训练的LLMbaseline如Qwen2.5 Coder 3B高出17.81%。除了准确率之外，该方法提取了显著子图并生成了自然语言解释，提高了开发者的可解释性。这些结果为可扩展、可解释和本地部署的工具铺平了道路，这些工具可以将漏洞分析从纯粹的语法检查转变为更深层次的结构和语义洞察，促进其实现在世软件开发中的更广泛应用。 

---
# Prepared for the Unknown: Adapting AIOps Capacity Forecasting Models to Data Changes 

**Title (ZH)**: 未雨绸缪：适应数据变化的AIOps容量预测模型调整 

**Authors**: Lorena Poenaru-Olaru, Wouter van 't Hof, Adrian Stando, Arkadiusz P. Trawinski, Eileen Kapel, Jan S. Rellermeyer, Luis Cruz, Arie van Deursen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10320)  

**Abstract**: Capacity management is critical for software organizations to allocate resources effectively and meet operational demands. An important step in capacity management is predicting future resource needs often relies on data-driven analytics and machine learning (ML) forecasting models, which require frequent retraining to stay relevant as data evolves. Continuously retraining the forecasting models can be expensive and difficult to scale, posing a challenge for engineering teams tasked with balancing accuracy and efficiency. Retraining only when the data changes appears to be a more computationally efficient alternative, but its impact on accuracy requires further investigation. In this work, we investigate the effects of retraining capacity forecasting models for time series based on detected changes in the data compared to periodic retraining. Our results show that drift-based retraining achieves comparable forecasting accuracy to periodic retraining in most cases, making it a cost-effective strategy. However, in cases where data is changing rapidly, periodic retraining is still preferred to maximize the forecasting accuracy. These findings offer actionable insights for software teams to enhance forecasting systems, reducing retraining overhead while maintaining robust performance. 

**Abstract (ZH)**: 基于检测到的数据变化进行容量预测模型的重新训练与周期性重新训练的影响研究：一种成本效益策略 

---
# Sample-Efficient Online Learning in LM Agents via Hindsight Trajectory Rewriting 

**Title (ZH)**: 通过回顾轨迹重写实现LM代理的样本高效在线学习 

**Authors**: Michael Y. Hu, Benjamin Van Durme, Jacob Andreas, Harsh Jhamtani  

**Link**: [PDF](https://arxiv.org/pdf/2510.10304)  

**Abstract**: Language model (LM) agents deployed in novel environments often exhibit poor sample efficiency when learning from sequential interactions. This significantly hinders the usefulness of such agents in environments where interaction is costly (for example, when they interact with humans or reset physical systems). While a number of existing LM agent architectures incorporate various mechanisms for experience storage and reflection, they make limited use of LMs' abilities to directly generate or reason about full counterfactual trajectories. We introduce ECHO (Experience Consolidation via Hindsight Optimization), a prompting framework that adapts hindsight experience replay from reinforcement learning for language model agents. ECHO generates optimized trajectories for alternative goals that could have been achieved during failed attempts, effectively creating synthetic positive examples from unsuccessful interactions. Our approach consists of two components: a hindsight rule that uses the language model itself to identify relevant subgoals and generate optimized trajectories, and an update rule that maintains compressed trajectory representations in memory. We evaluate ECHO on stateful versions of XMiniGrid, a text-based navigation and planning benchmark, and PeopleJoinQA, a collaborative information-gathering enterprise simulation. Across both domains, ECHO outperforms vanilla language agent baselines by up to 80%; in XMiniGrid, it also outperforms a number of sophisticated agent architectures including Reflexion and AWM, demonstrating faster adaptation to novel environments through more effective utilization of past experiences. 

**Abstract (ZH)**: 语言模型代理在新型环境中的样本效率往往较低，尤其是在从顺序交互中学习时。这在交互成本高（例如与人类交互或重置物理系统）的环境中显著妨碍了这些代理的有效性。虽然现有的一些语言模型代理架构中包含各种经验存储和反思机制，但它们对利用语言模型直接生成或推理完整反事实轨迹的能力利用有限。我们引入了ECHO（通过后视展望经验 consolidation 的经验整合），这是一种将强化学习中的后视展望经验回放适应语言模型代理的提示框架。ECHO 为替代目标生成优化轨迹，这些目标在失败尝试期间本可以实现，从而有效地从不成功的交互中创建合成的正例。我们的方法包括两个组成部分：一个后视展望规则，使用语言模型本身识别相关子目标并生成优化轨迹，以及一个更新规则，用于在内存中维持压缩轨迹表示。我们在XMiniGrid的有状态版本（一个基于文本的导航和规划基准）和PeopleJoinQA（一个合作信息收集企业模拟）上评估了ECHO。在两个领域中，ECHO 在几乎所有情况下都优于 vanilla 语言代理基线，提高了高达 80%；在XMiniGrid中，ECHO 也优于包括 Reflexion 和 AWM 在内的多种复杂代理架构，证明了通过更有效地利用以往经验更快适应新型环境的能力。 

---
# The algorithmic regulator 

**Title (ZH)**: 算法监管者 

**Authors**: Giulio Ruffini  

**Link**: [PDF](https://arxiv.org/pdf/2510.10300)  

**Abstract**: The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \emph{good algorithmic regulator} if it \emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\varnothing$, i.e., \[ \Delta = K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] We then prove that the larger $\Delta$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $\Delta > 0$ yields \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-\Delta}, \] making low $M(W{:}R)$ exponentially unlikely as $\Delta$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \emph{canonical scalar objective} and implicates a \emph{planner}. On the realized episode, a regulator behaves \emph{as if} it minimized the conditional description length of the readout. 

**Abstract (ZH)**: 调节器定理指出，在某些条件下，任意最优控制器必须包含其所调节系统的模型，从而确立了控制器显式或隐式包含受控系统内部模型的理念。这一原理支撑着神经科学及预测大脑理论，如自由能原理或柯尔莫哥洛夫/算法代理理论。然而，该定理仅在有限条件下得到证明。本文将确定性的闭合耦合世界-调节器系统 $(W,R)$ 视为单一自界定程序 $p$，通过一个恒定大小的包装器产生世界输出字符串 $x$ 供给调节器。从输出的算法复杂性 $K(x)$ 视角分析调节。若调节器 $R$ 能将读取输出的算法复杂性相对于空基线 $\varnothing$ 减小，则定义 $R$ 为一个良好的算法调节器，即 \[ \Delta = K\big(O_{W,\varnothing}\big) - K\big(O_{W,R}\big) > 0. \] 然后证明，$\Delta$ 越大，高互信息的世界-调节器配对就越被青睐。更精确地说，复杂性差距 $\Delta > 0$ 导致 \[ \Pr\big((W,R)\mid x\big) \le C\,2^{\,M(W{:}R)}\,2^{-\Delta}, \] 使得低 $M(W{:}R)$ 随 $\Delta$ 增长而变得指数级不可能。这是基于算法信息论的观点，表明“调节器包含世界模型”的理念。该框架是分布无偏的，适用于单个序列，并补充了内部模型原则。除了这种必要性声明外，同样的编码定理计算还确定了一个标准规范目标，并暗示了一个规划器。在实际化的时间片段中，调节器的行为仿佛是将其读取输出的条件描述长度最小化。 

---
# MatryoshkaThinking: Recursive Test-Time Scaling Enables Efficient Reasoning 

**Title (ZH)**: 套娃思考：递归测试时缩放 enables 高效推理 

**Authors**: Hongwei Chen, Yishu Lei, Dan Zhang, Bo Ke, Danxiang Zhu, Xuyi Chen, Yuxiang Lu, Zhengjie Huang, Shikun Feng, Jingzhou He, Yu Sun, Hua Wu, Haifeng Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10293)  

**Abstract**: Test-time scaling has emerged as a promising paradigm in language modeling, wherein additional computational resources are allocated during inference to enhance model performance. Recent approaches, such as DeepConf, have demonstrated the efficacy of this strategy, however, they often incur substantial computational overhead to achieve competitive results. In this work, we propose MatryoshkaThinking, a novel method that significantly reduces computational cost while maintaining state-of-the-art performance. Specifically, MatryoshkaThinking attains a score of 99.79 on AIME2025 using only 4% of the computation required by DeepConf. The core of our approach lies in the recursive exploitation of the model's intrinsic capabilities in reasoning, verification, and summarization, which collectively enhance the retention of correct solutions and reduce the disparity between Pass@k and Pass@1. Comprehensive evaluations across multiple open-source models and challenging multi-modal reasoning benchmarks validate the effectiveness and generality of our method. These findings offer new insights into the design of efficient and scalable test-time inference strategies for advanced language models. 

**Abstract (ZH)**: Test-time Scaling through MatryoshkaThinking: Significantly Reducing Computational Cost while Maintaining State-of-the-Art Performance 

---
# From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries 

**Title (ZH)**: 从程序到姿态：通过学习程序库生成事实化的现实场景 

**Authors**: Joy Hsu, Emily Jin, Jiajun Wu, Niloy J. Mitra  

**Link**: [PDF](https://arxiv.org/pdf/2510.10292)  

**Abstract**: Real-world scenes, such as those in ScanNet, are difficult to capture, with highly limited data available. Generating realistic scenes with varied object poses remains an open and challenging task. In this work, we propose FactoredScenes, a framework that synthesizes realistic 3D scenes by leveraging the underlying structure of rooms while learning the variation of object poses from lived-in scenes. We introduce a factored representation that decomposes scenes into hierarchically organized concepts of room programs and object poses. To encode structure, FactoredScenes learns a library of functions capturing reusable layout patterns from which scenes are drawn, then uses large language models to generate high-level programs, regularized by the learned library. To represent scene variations, FactoredScenes learns a program-conditioned model to hierarchically predict object poses, and retrieves and places 3D objects in a scene. We show that FactoredScenes generates realistic, real-world rooms that are difficult to distinguish from real ScanNet scenes. 

**Abstract (ZH)**: FactoredScenes：通过房间程序和物体姿态的分解生成真实的3D场景 

---
# ArtPerception: ASCII Art-based Jailbreak on LLMs with Recognition Pre-test 

**Title (ZH)**: ArtPerception：基于ASCII艺术的LLM突破，并在识别预测试中检测 

**Authors**: Guan-Yan Yang, Tzu-Yu Cheng, Ya-Wen Teng, Farn Wanga, Kuo-Hui Yeh  

**Link**: [PDF](https://arxiv.org/pdf/2510.10281)  

**Abstract**: The integration of Large Language Models (LLMs) into computer applications has introduced transformative capabilities but also significant security challenges. Existing safety alignments, which primarily focus on semantic interpretation, leave LLMs vulnerable to attacks that use non-standard data representations. This paper introduces ArtPerception, a novel black-box jailbreak framework that strategically leverages ASCII art to bypass the security measures of state-of-the-art (SOTA) LLMs. Unlike prior methods that rely on iterative, brute-force attacks, ArtPerception introduces a systematic, two-phase methodology. Phase 1 conducts a one-time, model-specific pre-test to empirically determine the optimal parameters for ASCII art recognition. Phase 2 leverages these insights to launch a highly efficient, one-shot malicious jailbreak attack. We propose a Modified Levenshtein Distance (MLD) metric for a more nuanced evaluation of an LLM's recognition capability. Through comprehensive experiments on four SOTA open-source LLMs, we demonstrate superior jailbreak performance. We further validate our framework's real-world relevance by showing its successful transferability to leading commercial models, including GPT-4o, Claude Sonnet 3.7, and DeepSeek-V3, and by conducting a rigorous effectiveness analysis against potential defenses such as LLaMA Guard and Azure's content filters. Our findings underscore that true LLM security requires defending against a multi-modal space of interpretations, even within text-only inputs, and highlight the effectiveness of strategic, reconnaissance-based attacks. Content Warning: This paper includes potentially harmful and offensive model outputs. 

**Abstract (ZH)**: 大型语言模型（LLMs）集成到计算机应用中引入了变革性的能力但也带来了重大的安全挑战。现有的安全性对齐主要集中在语义解释上，使LLMs容易受到使用非标准数据表示的攻击。本文介绍了ArtPerception，这是一个 novel 黑盒 jailbreak 框架，战略性地利用ASCII艺术绕过最先进的（SOTA）LLM的安全措施。不同于依赖于迭代的暴力攻击方法，ArtPerception引入了一种系统性的、两阶段的方法。第一阶段进行一次性的、针对特定模型的预测试，以实验证明ASCII艺术识别的最佳参数。第二阶段利用这些洞察力，发起一个高效的一次性恶意 jailbreak 攻击。我们提出了一种修改后的莱文斯坦距离（MLD）度量，以更细致地评估LLM的识别能力。通过在四个SOTA开源LLM上的全面实验，我们展示了更强的jailbreak性能。我们进一步通过展示其成功转移到领先的商用模型，包括GPT-4o、Claude Sonnet 3.7和DeepSeek-V3，并对其潜在防御措施（如LLaMA Guard和Azure的内容过滤器）进行严格的有效性分析，证明了我们框架的实际相关性。我们的研究结果强调了即使在仅文本输入的情况下，真正的LLM安全也需要抵御多模态解释空间的攻击，并突显了战略性侦察攻击的有效性。内容警告：本文包括可能有害和冒犯性的模型输出。 

---
# Simulating Viva Voce Examinations to Evaluate Clinical Reasoning in Large Language Models 

**Title (ZH)**: 模拟口头答辩以评估大型语言模型的临床推理能力 

**Authors**: Christopher Chiu, Silviu Pitis, Mihaela van der Schaar  

**Link**: [PDF](https://arxiv.org/pdf/2510.10278)  

**Abstract**: Clinical reasoning in medicine is a hypothesis-driven process where physicians refine diagnoses from limited information through targeted history, physical examination, and diagnostic investigations. In contrast, current medical benchmarks for large language models (LLMs) primarily assess knowledge recall through single-turn questions, where complete clinical information is provided upfront. To address this gap, we introduce VivaBench, a multi-turn benchmark that evaluates sequential clinical reasoning in LLM agents. Our dataset consists of 1762 physician-curated clinical vignettes structured as interactive scenarios that simulate a (oral) examination in medical training, requiring agents to actively probe for relevant findings, select appropriate investigations, and synthesize information across multiple steps to reach a diagnosis. While current LLMs demonstrate competence in diagnosing conditions from well-described clinical presentations, their performance degrades significantly when required to navigate iterative diagnostic reasoning under uncertainty in our evaluation. Our analysis identified several failure modes that mirror common cognitive errors in clinical practice, including: (1) fixation on initial hypotheses, (2) inappropriate investigation ordering, (3) premature diagnostic closure, and (4) failing to screen for critical conditions. These patterns reveal fundamental limitations in how current LLMs reason and make decisions under uncertainty. Through VivaBench, we provide a standardized benchmark for evaluating conversational medical AI systems for real-world clinical decision support. Beyond medical applications, we contribute to the larger corpus of research on agentic AI by demonstrating how sequential reasoning trajectories can diverge in complex decision-making environments. 

**Abstract (ZH)**: 临床医学中的临床推理是一个假设驱动的过程，医生通过有针对性的病史采集、体格检查和诊断检查，从有限信息中精炼诊断。相比之下，当前用于大型语言模型（LLMs）的医学基准主要通过单轮问题评估知识回忆，提前提供完整临床信息。为解决这一问题，我们引入了VivaBench，这是一个多轮基准，用于评估LLM代理的序贯临床推理能力。我们的数据集包含1762个由医生编纂的临床案例，这些案例以交互式场景的形式结构化，模拟医学培训中的（口头）考试，要求代理积极探究相关发现，选择合适的检查，并在多个步骤中综合信息以得出诊断。尽管当前的LLM在从描述良好的临床表现中诊断疾病方面表现出色，但在我们的评估中要求其在不确定性下进行迭代诊断推理时，其性能显著下降。我们的分析发现了一些失败模式，这些模式反映了临床实践中常见的认知错误，包括：（1）固守初始假设，（2）不适当的检查顺序，（3）过早的诊断闭合，以及（4）未能筛查关键病症。这些模式揭示了当前LLM在不确定性下推理和决策方面的根本局限性。通过VivaBench，我们为评估对话式医疗AI系统在实际临床决策支持中的能力提供了标准化基准。除了医学应用外，我们还通过展示复杂决策环境下的序贯推理轨迹的差异性，为代理AI的研究做出了贡献。 

---
# X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model 

**Title (ZH)**: X-VLA：可扩展的跨体态视觉-语言-行动模型的软提示变换器 

**Authors**: Jinliang Zheng, Jianxiong Li, Zhihao Wang, Dongxiu Liu, Xirui Kang, Yuchun Feng, Yinan Zheng, Jiayin Zou, Yilun Chen, Jia Zeng, Ya-Qin Zhang, Jiangmiao Pang, Jingjing Liu, Tai Wang, Xianyuan Zhan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10274)  

**Abstract**: Successful generalist Vision-Language-Action (VLA) models rely on effective training across diverse robotic platforms with large-scale, cross-embodiment, heterogeneous datasets. To facilitate and leverage the heterogeneity in rich, diverse robotic data sources, we propose a novel Soft Prompt approach with minimally added parameters, by infusing prompt learning concepts into cross-embodiment robot learning and introducing separate sets of learnable embeddings for each distinct data source. These embeddings serve as embodiment-specific prompts, which in unity empower VLA models with effective exploitation of varying cross-embodiment features. Our new X-VLA, a neat flow-matching-based VLA architecture, relies exclusively on soft-prompted standard Transformer encoders, enjoying both scalability and simplicity. Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep of benchmarks, demonstrating superior results on a wide axes of capabilities, from flexible dexterity to quick adaptation across embodiments, environments, and tasks. Website: this https URL 

**Abstract (ZH)**: 成功的通用视觉-语言-动作（VLA）模型依赖于在具有大规模、跨载体和异构数据集的多样化机器人平台上进行有效的训练。为促进和利用丰富多样机器人数据源中的异质性，我们提出了一种新颖的轻量级软提示方法，通过将提示学习概念融入跨载体机器人学习，并为每个独立的数据源引入可学习嵌入，来利用这种异质性。这些嵌入作为载体特异性提示，共同赋予VLA模型有效地利用跨载体特征的能力。我们的新X-VLA是一种基于流匹配的VLA架构，仅依赖于软提示的标准Transformer编码器，兼具可扩展性和简洁性。在6个模拟平台和3个真实机器人上的评估结果表明，我们的0.9B实例X-VLA-0.9B在一系列基准测试中的表现优于现有方法，在灵活灵巧性、快速适应不同载体、环境和任务方面取得了卓越的成绩。网站: [这个链接](这个链接)。 

---
# MetaBreak: Jailbreaking Online LLM Services via Special Token Manipulation 

**Title (ZH)**: MetaBreak: 通过特殊令牌操纵突破在线LLM服务 difficoltà-Taobao 

**Authors**: Wentian Zhu, Zhen Xiang, Wei Niu, Le Guan  

**Link**: [PDF](https://arxiv.org/pdf/2510.10271)  

**Abstract**: Unlike regular tokens derived from existing text corpora, special tokens are artificially created to annotate structured conversations during the fine-tuning process of Large Language Models (LLMs). Serving as metadata of training data, these tokens play a crucial role in instructing LLMs to generate coherent and context-aware responses. We demonstrate that special tokens can be exploited to construct four attack primitives, with which malicious users can reliably bypass the internal safety alignment of online LLM services and circumvent state-of-the-art (SOTA) external content moderation systems simultaneously. Moreover, we found that addressing this threat is challenging, as aggressive defense mechanisms-such as input sanitization by removing special tokens entirely, as suggested in academia-are less effective than anticipated. This is because such defense can be evaded when the special tokens are replaced by regular ones with high semantic similarity within the tokenizer's embedding space. We systemically evaluated our method, named MetaBreak, on both lab environment and commercial LLM platforms. Our approach achieves jailbreak rates comparable to SOTA prompt-engineering-based solutions when no content moderation is deployed. However, when there is content moderation, MetaBreak outperforms SOTA solutions PAP and GPTFuzzer by 11.6% and 34.8%, respectively. Finally, since MetaBreak employs a fundamentally different strategy from prompt engineering, the two approaches can work synergistically. Notably, empowering MetaBreak on PAP and GPTFuzzer boosts jailbreak rates by 24.3% and 20.2%, respectively. 

**Abstract (ZH)**: 不同于源于现有文本文体的常规标记符，特殊标记符在大型语言模型（LLMs）微调过程中人工创建，用于标注结构化对话。作为训练数据的元数据，这些标记符在指导LLMs生成连贯和上下文相关响应方面发挥关键作用。我们展示了一种方法，利用特殊标记符构建四种攻击原语，恶意用户可以利用这些方法可靠地绕过在线LLM服务的内部安全对齐，并同时规避最先进的外部内容审核系统。此外，我们发现缓解这一威胁具有挑战性，学术界建议的激进防御机制（如通过完全移除特殊标记符进行输入清理）的实际效果低于预期，因为当特殊标记符被具有高语义相似性的常规标记符替代时，此类防御可以被规避。我们在实验室环境和商用LLM平台上系统评估了名为MetaBreak的方法。在没有内容审核的情况下，MetaBreak的脱狱成功率与最先进的提示工程解决方案相当。而在有内容审核的情况下，MetaBreak分别比PAP和GPTFuzzer高出11.6%和34.8%。最后，由于MetaBreak采用了一种与提示工程的根本不同策略，这两种方法可以协同工作。值得注意的是，在PAP和GPTFuzzer上增强MetaBreak分别提高了脱狱成功率24.3%和20.2%。 

---
# Unveiling Gamer Archetypes through Multi modal feature Correlations and Unsupervised Learning 

**Title (ZH)**: 通过多模态特征关联与无监督学习揭示游戏 archetype 

**Authors**: Moona Kanwal, Muhammad Sami Siddiqui, Syed Anael Ali  

**Link**: [PDF](https://arxiv.org/pdf/2510.10263)  

**Abstract**: Profiling gamers provides critical insights for adaptive game design, behavioral understanding, and digital well-being. This study proposes an integrated, data-driven framework that combines psychological measures, behavioral analytics, and machine learning to reveal underlying gamer personas. A structured survey of 250 participants, including 113 active gamers, captured multidimensional behavioral, motivational, and social data. The analysis pipeline integrated feature engineering, association-network, knowledge-graph analysis, and unsupervised clustering to extract meaningful patterns. Correlation statistics uses Cramers V, Tschuprows T, Theils U, and Spearmans quantified feature associations, and network centrality guided feature selection. Dimensionality-reduction techniques such as PCA, SVD, t-SNE are coupled with clustering algorithms like K-Means, Agglomerative, Spectral, DBSCAN, evaluated using Silhouette, Calinski Harabasz, and Davies Bouldin indices. The PCA with K-Means with k = 4 model achieved optimal cluster quality with Silhouette = 0.4, identifying four archetypes as Immersive Social Story-Seekers, Disciplined Optimizers, Strategic Systems Navigators, and Competitive Team-Builders. This research contributes a reproducible pipeline that links correlation-driven network insights with unsupervised learning. The integration of behavioral correlation networks with clustering not only enhances classification accuracy but also offers a holistic lens to connect gameplay motivations with psychological and wellness outcomes. 

**Abstract (ZH)**: 基于数据的综合框架揭示游戏者特征：适应性游戏设计、行为理解与数字福祉的研究 

---
# Audit-of-Understanding: Posterior-Constrained Inference for Mathematical Reasoning in Language Models 

**Title (ZH)**: 理解审计：后验约束推理在语言模型中的数学推理 

**Authors**: Samir Abdaljalil, Erchin Serpedin, Khalid Qaraqe, Hasan Kurban  

**Link**: [PDF](https://arxiv.org/pdf/2510.10252)  

**Abstract**: Large language models (LLMs) often generate reasoning traces that appear coherent but rest on unsupported assumptions, leading to hallucinated conclusions. Prior work mainly addresses factual hallucinations or relies on post-hoc verification, leaving reasoning-induced hallucinations largely unaddressed. We propose Audit-of-Understanding (AoU), a framework that constrains inference to validated premises through three phases: (1) decomposing a query into candidate assumptions, (2) auditing their support, and (3) conditioning inference only on the validated subset. Formally, AoU is \emph{posterior-constrained inference}, connecting to selective prediction and rejection learning. Our contributions are threefold: (i) theoretical guarantees under perfect validation, (ii) excess-risk bounds under imperfect audits, and (iii) tractability analysis. Empirically, AoU improves both accuracy and faithfulness on GSM8K, MultiArith, and SVAMP, achieving up to +30% gains on GSM8K, +45% on MultiArith, and consistent +20--28% improvements on SVAMP over Chain-of-Thought, Self-Consistency, and CoT-Decoding. Code is available at this https URL. 

**Abstract (ZH)**: 大型语言模型（LLMs）往往生成表面上连贯但实际上基于未支持假设的推理痕迹，导致产生虚构的结论。先前的工作主要处理事实上的虚构或依赖事后验证，而很大程度上忽略了由推理引起的虚构。我们提出了一种审计理解（AoU）框架，通过三个阶段限制推理仅在验证前提的范围内进行：（1）将查询分解为候选假设，（2）审计其支持情况，（3）仅在验证过的子集中进行推理。形式上，AoU 是后验受限推理，与选择性预测和拒绝学习相关联。我们的贡献包括三个方面：（i）在完美验证下提供的理论保证，（ii）在不完善审计下的 excess-risk 绑定，（iii）可操作性分析。实验表明，AoU 在 GSM8K、MultiArith 和 SVAMP 上提高了准确性和忠实度，分别在 GSM8K 上达到 +30% 的提升，在 MultiArith 上达到 +45% 的提升，并在 SVAMP 上相对于链式思考、自我一致性以及 CoT 编码实现了持续的 +20–28% 的改进。代码可在以下地址获取。 

---
# MRI Brain Tumor Detection with Computer Vision 

**Title (ZH)**: 基于计算机视觉的MRI脑肿瘤检测 

**Authors**: Jack Krolik, Jake Lynn, John Henry Rudden, Dmytro Vremenko  

**Link**: [PDF](https://arxiv.org/pdf/2510.10250)  

**Abstract**: This study explores the application of deep learning techniques in the automated detection and segmentation of brain tumors from MRI scans. We employ several machine learning models, including basic logistic regression, Convolutional Neural Networks (CNNs), and Residual Networks (ResNet) to classify brain tumors effectively. Additionally, we investigate the use of U-Net for semantic segmentation and EfficientDet for anchor-based object detection to enhance the localization and identification of tumors. Our results demonstrate promising improvements in the accuracy and efficiency of brain tumor diagnostics, underscoring the potential of deep learning in medical imaging and its significance in improving clinical outcomes. 

**Abstract (ZH)**: 本研究探讨了深度学习技术在自动检测和分割MRI扫描中脑肿瘤的应用。我们采用多种机器学习模型，包括基础逻辑回归、卷积神经网络（CNN）和残差网络（ResNet），以有效分类脑肿瘤。此外，我们还研究了U-Net在语义分割中的应用和EfficientDet在基于锚点的对象检测中的应用，以提高肿瘤的定位和识别。研究结果表明，深度学习在脑肿瘤诊断中的准确性和效率方面取得了令人鼓舞的改进，突显了其在医学成像中的潜力及其对改善临床结果的重要性。 

---
# Reasoning-Enhanced Large Language Models for Molecular Property Prediction 

**Title (ZH)**: 增强推理能力的大语言模型在分子性质预测中的应用 

**Authors**: Jiaxi Zhuang, Yaorui Shi, Jue Hou, Yunong He, Mingwei Ye, Mingjun Xu, Yuming Su, Linfeng Zhang, Linfeng Zhang, Guolin Ke, Hengxing Cai  

**Link**: [PDF](https://arxiv.org/pdf/2510.10248)  

**Abstract**: Molecular property prediction is crucial for drug discovery and materials science, yet existing approaches suffer from limited interpretability, poor cross-task generalization, and lack of chemical reasoning capabilities. Traditional machine learning models struggle with task transferability, while specialized molecular language models provide little insight into their decision-making processes. To address these limitations, we propose \textbf{MPPReasoner}, a multimodal large language model that incorporates chemical reasoning for molecular property prediction. Our approach, built upon Qwen2.5-VL-7B-Instruct, integrates molecular images with SMILES strings to enable comprehensive molecular understanding. We develop a two-stage training strategy: supervised fine-tuning (SFT) using 16,000 high-quality reasoning trajectories generated through expert knowledge and multiple teacher models, followed by Reinforcement Learning from Principle-Guided Rewards (RLPGR). RLPGR employs verifiable, rule-based rewards that systematically evaluate chemical principle application, molecular structure analysis, and logical consistency through computational verification. Extensive experiments across 8 datasets demonstrate significant performance improvements, with MPPReasoner outperforming the best baselines by 7.91\% and 4.53\% on in-distribution and out-of-distribution tasks respectively. MPPReasoner exhibits exceptional cross-task generalization and generates chemically sound reasoning paths that provide valuable insights into molecular property analysis, substantially enhancing both interpretability and practical utility for chemists. Code is available at this https URL. 

**Abstract (ZH)**: 分子性质预测对于药物发现和材料科学至关重要，但现有方法存在解释性有限、跨任务泛化能力差和缺乏化学推理能力的问题。传统机器学习模型难以实现任务转移，而专门的分子语言模型对于其决策过程的洞察则较少。为应对这些局限性，我们提出了\textbf{MPPReasoner}——一种结合化学推理能力的多模态大型语言模型，用于分子性质预测。我们的方法基于Qwen2.5-VL-7B-Instruct构建，将分子图像与SMILES字符串相结合，以实现全面的分子理解。我们开发了一种两阶段训练策略：使用16,000条高质量推理轨迹进行监督微调（SFT），这些轨迹通过专家知识和多个教师模型生成，后续采用基于原则指导奖励的强化学习（RLPGR）。RLPGR采用可验证的基于规则的奖励，通过系统地评估化学原理的应用、分子结构分析和逻辑一致性来进行计算验证。跨8个数据集的广泛实验展示了显著的性能提升，MPPReasoner在同分布任务和异分布任务中，分别比最佳基线提高了7.91%和4.53%。MPPReasoner展示了出色的跨任务泛化能力，并生成了化学上可信的推理路径，提供了有价值的分子性质分析见解，显著提升了化学家的解释性和实际应用。代码可在以下链接获取。 

---
# SGM: A Statistical Godel Machine for Risk-Controlled Recursive Self-Modification 

**Title (ZH)**: SGM：一种用于风险控制的递归自我修改统计哥德尔机 

**Authors**: Xuening Wu, Shenqin Yin, Yanlan Kang, Xinhang Zhang, Qianya Xu, Zeping Chen, Wenqiang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10232)  

**Abstract**: Recursive self-modification is increasingly central in AutoML, neural architecture search, and adaptive optimization, yet no existing framework ensures that such changes are made safely. Godel machines offer a principled safeguard by requiring formal proofs of improvement before rewriting code; however, such proofs are unattainable in stochastic, high-dimensional settings. We introduce the Statistical Godel Machine (SGM), the first statistical safety layer for recursive edits. SGM replaces proof-based requirements with statistical confidence tests (e-values, Hoeffding bounds), admitting a modification only when superiority is certified at a chosen confidence level, while allocating a global error budget to bound cumulative risk across this http URL also propose Confirm-Triggered Harmonic Spending (CTHS), which indexes spending by confirmation events rather than rounds, concentrating the error budget on promising edits while preserving familywise this http URL across supervised learning, reinforcement learning, and black-box optimization validate this role: SGM certifies genuine gains on CIFAR-100, rejects spurious improvement on ImageNet-100, and demonstrates robustness on RL and optimization this http URL, these results position SGM as foundational infrastructure for continual, risk-aware self-modification in learning this http URL is available at: this https URL. 

**Abstract (ZH)**: 统计哥德尔机（SGM）：递归编辑的统计安全性层 

---
# You only need 4 extra tokens: Synergistic Test-time Adaptation for LLMs 

**Title (ZH)**: 你只需要额外4个词：LLMs的协同测试时适配 

**Authors**: Yijie Xu, Huizai Yao, Zhiyu Guo, Weiyu Guo, Pengteng Li, Aiwei Liu, Xuming Hu, Hui Xiong  

**Link**: [PDF](https://arxiv.org/pdf/2510.10223)  

**Abstract**: Large language models (LLMs) are increasingly deployed in specialized domains such as finance, medicine, and agriculture, where they face significant distribution shifts from their training data. Domain-specific fine-tuning can mitigate this challenge but relies on high-quality labeled data that is expensive and slow to collect in expertise-limited settings. We study label-free test-time adaptation for language models and present SyTTA, an inference-time framework that adapts models on-the-fly without additional supervision. SyTTA couples two complementary uncertainty signals that arise under distribution shift: input-side perplexity, indicating mismatch with domain-specific terminology and patterns, and output-side predictive entropy, indicating diffuse and unstable token probabilities during generation. Across diverse model architectures and domain-specific benchmarks, SyTTA delivers consistent gains. Notably, on agricultural question answering, SyTTA improves Rouge-LSum by over 120% on Qwen-2.5-7B with only 4 extra tokens per query. These results show that effective test-time adaptation for language models is achievable without labeled examples, supporting deployment in label-scarce domains. The code will be made available upon acceptance. 

**Abstract (ZH)**: large语言模型（LLMs）在金融、医学和农业等专门领域中的应用越来越多，这些领域中的分布偏移给它们带来了挑战。领域特定的微调可以缓解这一挑战，但它依赖于高质量的标注数据，而在专家资源有限的情况下，这些数据的收集既昂贵又耗时。我们研究了语言模型的无标签测试时自适应方法，并提出了SyTTA，一种在推理时无需额外监督即可适应模型的框架。SyTTA结合了两种在分布偏移下出现的互补不确定性信号：输入端困惑度，表示与领域特定术语和模式的不匹配；输出端预测熵，表示生成过程中标记概率的分散和不稳定。在多种模型架构和领域特定基准测试中，SyTTA表现出一致的提升效果。特别是在农业问答领域，SyTTA在Qwen-2.5-7B上仅使用每查询4个额外标记就将Rouge-LSum提高了超过120%。这些结果表明，即使在缺少标注数据的情况下，语言模型的测试时自适应也是可以实现的，从而支持在标注资源稀缺的领域中的应用。代码将在录用后提供。 

---
# A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots 

**Title (ZH)**: A3RNN：机器人发展视觉注意的自底向上与自顶向下过程双向融合模型 

**Authors**: Hyogo Hiruma, Hiroshi Ito, Hiroki Mori, Tetsuya Ogata  

**Link**: [PDF](https://arxiv.org/pdf/2510.10221)  

**Abstract**: This study investigates the developmental interaction between top-down (TD) and bottom-up (BU) visual attention in robotic learning. Our goal is to understand how structured, human-like attentional behavior emerges through the mutual adaptation of TD and BU mechanisms over time. To this end, we propose a novel attention model $A^3 RNN$ that integrates predictive TD signals and saliency-based BU cues through a bi-directional attention architecture.
We evaluate our model in robotic manipulation tasks using imitation learning. Experimental results show that attention behaviors evolve throughout training, from saliency-driven exploration to prediction-driven direction. Initially, BU attention highlights visually salient regions, which guide TD processes, while as learning progresses, TD attention stabilizes and begins to reshape what is perceived as salient. This trajectory reflects principles from cognitive science and the free-energy framework, suggesting the importance of self-organizing attention through interaction between perception and internal prediction. Although not explicitly optimized for stability, our model exhibits more coherent and interpretable attention patterns than baselines, supporting the idea that developmental mechanisms contribute to robust attention formation. 

**Abstract (ZH)**: 本研究探讨了机器人学习中自上而下（TD）和自下而上（BU）视觉注意力的发育交互作用。我们的目标是理解通过TD和BU机制的相互适应，如何在时间进程中产生结构化的类人类注意力行为。为此，我们提出了一种新的注意力模型 $A^3 RNN$，该模型通过双向注意力架构整合了预测性TD信号和基于显著性的BU提示。我们使用模仿学习在机器人操作任务中评估了该模型。实验结果表明，注意力行为在训练过程中演化，从基于显著性的探索到基于预测的方向。起初，BU注意力突出显示视觉上显著的区域，引导TD过程，而随着学习的进展，TD注意力趋于稳定并开始重塑被认为显著的内容。这一轨迹反映了认知科学和最小自由能框架的原则，表明通过感知与内部预测之间的交互实现自我组织注意力的重要性。尽管我们的模型未明确优化稳定性，但其表现出比基线模型更加一致和可解释的注意力模式，支持发育机制在增强注意力形成 robust 性中的作用。 

---
# UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction 

**Title (ZH)**: UF-RNN：基于不确定性前瞻预测的实时自适应运动生成 

**Authors**: Hyogo Hiruma, Hiroshi Ito, Tetsuya Ogata  

**Link**: [PDF](https://arxiv.org/pdf/2510.10217)  

**Abstract**: Training robots to operate effectively in environments with uncertain states, such as ambiguous object properties or unpredictable interactions, remains a longstanding challenge in robotics. Imitation learning methods typically rely on successful examples and often neglect failure scenarios where uncertainty is most pronounced. To address this limitation, we propose the Uncertainty-driven Foresight Recurrent Neural Network (UF-RNN), a model that combines standard time-series prediction with an active "Foresight" module. This module performs internal simulations of multiple future trajectories and refines the hidden state to minimize predicted variance, enabling the model to selectively explore actions under high uncertainty. We evaluate UF-RNN on a door-opening task in both simulation and a real-robot setting, demonstrating that, despite the absence of explicit failure demonstrations, the model exhibits robust adaptation by leveraging self-induced chaotic dynamics in its latent space. When guided by the Foresight module, these chaotic properties stimulate exploratory behaviors precisely when the environment is ambiguous, yielding improved success rates compared to conventional stochastic RNN baselines. These findings suggest that integrating uncertainty-driven foresight into imitation learning pipelines can significantly enhance a robot's ability to handle unpredictable real-world conditions. 

**Abstract (ZH)**: 训练机器人在具有不确定状态的环境（如模糊的对象属性或不可预测的交互）中有效操作仍然是机器人技术中的长期挑战。我们提出了一种不确定性驱动的前瞻性循环神经网络（UF-RNN），该模型结合了标准的时间序列预测与一个主动的“前瞻性”模块。该模块进行多个未来轨迹的内部模拟并细化隐藏状态以最小化预测的不确定性，使模型能够在高度不确定的情况下选择性地探索动作。我们在门打开任务上的模拟和真实机器人设置中评估了UF-RNN，结果表明，在缺少明确失败示范的情况下，模型通过利用其潜在空间中的自我诱导混沌动力学表现出鲁棒的适应性。当由前瞻性模块引导时，这些混沌特性能够刺激在环境不确定性高时的探索行为，从而提高成功率，优于传统的随机RNN基线。这些发现表明，在模仿学习管道中集成不确定性驱动的前瞻性可以显著提高机器人处理不可预测的现实条件的能力。 

---
# Learning to Guarantee Type Correctness in Code Generation through Type-Guided Program Synthesis 

**Title (ZH)**: 通过类型引导的程序合成学习保证代码生成中的类型正确性 

**Authors**: Zhechong Huang, Zhao Zhang, Ruyi Ji, Tingxuan Xia, Qihao Zhu, Qinxiang Cao, Zeyu Sun, Yingfei Xiong  

**Link**: [PDF](https://arxiv.org/pdf/2510.10216)  

**Abstract**: Language models have shown remarkable proficiency in code generation; nevertheless, ensuring type correctness remains a challenge. Although traditional methods, such as constrained decoding, alleviate this problem by externally rejecting untypable code, the model itself does not effectively learn type reasoning internally, which ultimately limits its overall performance. This paper introduces TyFlow, a novel system that internalizes type reasoning within code generation to guide the model to learn the type system. The core of our approach is a novel type-guided program synthesis system that maintains an isomorphism between type derivation trees and synthesis derivation trees, enabling a new code representation based on synthesis decision sequences rather than traditional text-based token sequences. By offloading the complexity of type system learning to the representation itself, models can redirect their computational resources toward higher-level program semantics. Our evaluation shows that TyFlow not only eliminates type errors but also significantly improves functional correctness, highlighting the importance of aligning LMs with type systems internally. 

**Abstract (ZH)**: 语言模型在代码生成方面展现了出色的 proficiency，但在确保类型正确性方面仍面临挑战。尽管传统方法，如受约束解码，通过外部拒绝未类型化的代码来缓解这一问题，但模型本身并没有有效地在内部学习类型推理，这最终限制了其整体性能。本文介绍了一种名为 TyFlow 的新系统，该系统将类型推理内置于代码生成中以引导模型学习类型系统。我们方法的核心是一种新型类型的程序合成系统，它保持了类型演绎树和合成演绎树之间的同构性，从而提供了一种基于合成决策序列的新代码表示，而不是传统的基于文本的标记序列。通过将类型系统学习的复杂性转移到表示本身，模型可以将计算资源重新分配给更高层次的程序语义。我们的评估表明，TyFlow 不仅消除了类型错误，还显著提高了功能性正确性，突显了内部对齐语言模型和类型系统的重要性。 

---
# Distributionally Robust Control with End-to-End Statistically Guaranteed Metric Learning 

**Title (ZH)**: 端到端统计保证的度量学习下的分布鲁棒控制 

**Authors**: Jingyi Wu, Chao Ning, Yang Shi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10214)  

**Abstract**: Wasserstein distributionally robust control (DRC) recently emerges as a principled paradigm for handling uncertainty in stochastic dynamical systems. However, it constructs data-driven ambiguity sets via uniform distribution shifts before sequentially incorporating them into downstream control synthesis. This segregation between ambiguity set construction and control objectives inherently introduces a structural misalignment, which undesirably leads to conservative control policies with sub-optimal performance. To address this limitation, we propose a novel end-to-end finite-horizon Wasserstein DRC framework that integrates the learning of anisotropic Wasserstein metrics with downstream control tasks in a closed-loop manner, thus enabling ambiguity sets to be systematically adjusted along performance-critical directions and yielding more effective control policies. This framework is formulated as a bilevel program: the inner level characterizes dynamical system evolution under DRC, while the outer level refines the anisotropic metric leveraging control-performance feedback across a range of initial conditions. To solve this program efficiently, we develop a stochastic augmented Lagrangian algorithm tailored to the bilevel structure. Theoretically, we prove that the learned ambiguity sets preserve statistical finite-sample guarantees under a novel radius adjustment mechanism, and we establish the well-posedness of the bilevel formulation by demonstrating its continuity with respect to the learnable metric. Furthermore, we show that the algorithm converges to stationary points of the outer level problem, which are statistically consistent with the optimal metric at a non-asymptotic convergence rate. Experiments on both numerical and inventory control tasks verify that the proposed framework achieves superior closed-loop performance and robustness compared against state-of-the-art methods. 

**Abstract (ZH)**: Wasserstein 分布鲁棒控制 (DRC) 最近作为处理随机动力系统中不确定性的一种基本原则范式而崭露头角。然而，它在逐步将不确定性集合纳入下游控制合成之前，通过均匀分布偏移构造数据驱动的不确定性集合。这种不确定性集合构建与控制目标之间的分离固有地引入了结构不对齐，从而导致保守的控制策略，其性能次优。为解决这一局限，我们提出了一种新的端到端有限时限 Wasserstein DRC 框架，该框架以闭环方式将各向异性 Wasserstein 度量的学习与下游控制任务结合起来，从而使得不确定性集合能够沿着性能关键方向系统性地调整，并产生更具效用的控制策略。该框架被形式化为一个 bilevel 程序：内部层级在 DRC 下刻画动力系统演化，外部层级利用控制-性能反馈在多种初始条件下细化各向异性度量。为了高效求解该程序，我们开发了一种针对 bilevel 结构定制的随机增广拉格朗日算法。理论上，我们证明了通过新颖的半径调整机制学习到的不确定性集合在有限样本下保持统计保证，并通过证明其关于可学习度量的连续性来建立 bilevel 表述的适定性。此外，我们证明该算法收敛于外部层级问题的稳定点，这些稳定点以非渐近收敛速率与最优度量在统计上一致。实验结果表明，所提出框架在闭环性能和鲁棒性方面优于最先进的方法。 

---
# RLFR: Extending Reinforcement Learning for LLMs with Flow Environment 

**Title (ZH)**: RLFR：通过流环境扩展 reinforcement learning 在大语言模型中的应用 

**Authors**: Jinghao Zhang, Naishan Zheng, Ruilin Li, Dongzhou Cheng, Zheming Liang, Feng Zhao, Jiaqi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10201)  

**Abstract**: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a promising framework for improving reasoning abilities in Large Language Models (LLMs). However, policy optimized with binary verification prone to overlook potential valuable exploration in reasoning trajectory. In view of heavy annotation cost of golden Process Reward Models (PRMs), recent works attempt using auxiliary signals for reward shaping of process tokens, involving entropy and likelihood collected from logit space. In this work, we offer a novel perspective on shaping RLVR with flow rewards derived from latent space, and propose RLFR, where the flow fields of model latents are constructed from either off-policy high-quality data and on-policy rejection sampling data, and the velocity deviations of policy latents within it are quantified to serve as a reward signal. RLFR first demonstrates that a well-established flow field can be a sound environment for reward signal collection, highlighting the expressive latent space is much underexplored. Moreover, RLFR is able to compress any off-policy expert data as reference for constituting reward signals, and we show that the efficient context dependence compressed within the hidden states are utilized, rather than individual token-level denotation for context comprehending. Experiments on both language and multimodal reasoning benchmarks demonstrate the reliability of flow rewards, and suggesting a promising paradigm for reward shaping with auxiliary signals. 

**Abstract (ZH)**: 基于可验证奖励的强化学习（RLVR）近年来已成为提高大型语言模型（LLMs）推理能力的一种有前途的框架。然而，基于二元验证优化的策略可能会忽略推理轨迹中潜在的有价值探索。鉴于黄金过程奖励模型（PRMs）标注成本高昂，近期工作尝试使用辅助信号来塑造过程令牌的奖励，涉及从logit空间收集的熵和似然性。在本工作中，我们提出了一个新的视角，利用源自潜在空间的流动奖励来塑造RLVR，并提出了一种新的方法RLFR，其中模型潜在的空间流动场由离策高质量数据和在线策拒绝采样数据构建，且政策潜在的位移偏差被量化作为奖励信号。RLFR首先表明一个成熟的流动场可以成为一个可靠的奖励信号收集环境，突显了表达性强的潜在空间远未被探索。此外，RLFR能够压缩任何形式的离策专家数据作为构建奖励信号的参考，并表明内在的高效上下文依赖性在隐藏状态中被利用，而非个体令牌级别的表示。在语言和多模态推理基准测试上的实验表明流动奖励的可靠性，并表明提供了使用辅助信号进行奖励塑造的一种有前景的范式。 

---
# Revisiting Trust in the Era of Generative AI: Factorial Structure and Latent Profiles 

**Title (ZH)**: 重访生成式AI时代的信任：因子结构与潜在profile探究 

**Authors**: Haocan Sun, Weizi Liu, Di Wu, Guoming Yu, Mike Yao  

**Link**: [PDF](https://arxiv.org/pdf/2510.10199)  

**Abstract**: Trust is one of the most important factors shaping whether and how people adopt and rely on artificial intelligence (AI). Yet most existing studies measure trust in terms of functionality, focusing on whether a system is reliable, accurate, or easy to use, while giving less attention to the social and emotional dimensions that are increasingly relevant for today's generative AI (GenAI) systems. These systems do not just process information; they converse, respond, and collaborate with users, blurring the line between tool and partner. In this study, we introduce and validate the Human-AI Trust Scale (HAITS), a new measure designed to capture both the rational and relational aspects of trust in GenAI. Drawing on prior trust theories, qualitative interviews, and two waves of large-scale surveys in China and the United States, we used exploratory (n = 1,546) and confirmatory (n = 1,426) factor analyses to identify four key dimensions of trust: Affective Trust, Competence Trust, Benevolence & Integrity, and Perceived Risk. We then applied latent profile analysis to classify users into six distinct trust profiles, revealing meaningful differences in how affective-competence trust and trust-distrust frameworks coexist across individuals and cultures. Our findings offer a validated, culturally sensitive tool for measuring trust in GenAI and provide new insight into how trust evolves in human-AI interaction. By integrating instrumental and relational perspectives of trust, this work lays the foundation for more nuanced research and design of trustworthy AI systems. 

**Abstract (ZH)**: 人类与生成型人工智能的信任量表：兼顾理性和关系维度的信任测量 

---
# CauchyNet: Compact and Data-Efficient Learning using Holomorphic Activation Functions 

**Title (ZH)**: 柯西网络：使用全纯激活函数的紧凑且数据高效学习 

**Authors**: Hong-Kun Zhang, Xin Li, Sikun Yang, Zhihong Xia  

**Link**: [PDF](https://arxiv.org/pdf/2510.10195)  

**Abstract**: A novel neural network inspired by Cauchy's integral formula, is proposed for function approximation tasks that include time series forecasting, missing data imputation, etc. Hence, the novel neural network is named CauchyNet. By embedding real-valued data into the complex plane, CauchyNet efficiently captures complex temporal dependencies, surpassing traditional real-valued models in both predictive performance and computational efficiency. Grounded in Cauchy's integral formula and supported by the universal approximation theorem, CauchyNet offers strong theoretical guarantees for function approximation. The architecture incorporates complex-valued activation functions, enabling robust learning from incomplete data while maintaining a compact parameter footprint and reducing computational overhead. Through extensive experiments in diverse domains, including transportation, energy consumption, and epidemiological data, CauchyNet consistently outperforms state-of-the-art models in predictive accuracy, often achieving a 50% lower mean absolute error with fewer parameters. These findings highlight CauchyNet's potential as an effective and efficient tool for data-driven predictive modeling, particularly in resource-constrained and data-scarce environments. 

**Abstract (ZH)**: 一种受柯西积分公式启发的新型神经网络CauchyNet用于函数近似任务，包括时间序列预测、缺失数据插补等，通过将实值数据嵌入复平面中，CauchyNet高效地捕捉复杂的时间依赖关系，性能和计算效率均超过传统的实值模型。基于柯西积分公式和普遍逼近定理，CauchyNet为函数近似提供了强大的理论保证。其架构采用复值激活函数，能够在保持紧凑参数量和减少计算开销的同时，从不完整数据中获得稳健的learnings。通过在交通、能源消耗和流行病学数据等多个领域的广泛实验，CauchyNet在预测准确性上始终优于现有最佳模型，参数量更少时误差均降低50%。这些发现突显了CauchyNet作为数据驱动预测建模的有效且高效的工具的潜力，特别是在资源受限和数据稀缺的环境中。 

---
# Formally Verified Certification of Unsolvability of Temporal Planning Problems 

**Title (ZH)**: 形式化验证不可解时态规划问题的认证 

**Authors**: David Wang, Mohammad Abdulaziz  

**Link**: [PDF](https://arxiv.org/pdf/2510.10189)  

**Abstract**: We present an approach to unsolvability certification of temporal planning. Our approach is based on encoding the planning problem into a network of timed automata, and then using an efficient model checker on the network followed by a certificate checker to certify the output of the model checker. Our approach prioritises trustworthiness of the certification: we formally verify our implementation of the encoding to timed automata using the theorem prover Isabelle/HOL and we use an existing certificate checker (also formally verified in Isabelle/HOL) to certify the model checking result. 

**Abstract (ZH)**: 时间规划不可解性认证的方法：将规划问题编码为时间自动机网络，并利用高效模型检查器进行检查，随后使用已正式验证的证书检查器认证模型检查结果。 

---
# MedAgentAudit: Diagnosing and Quantifying Collaborative Failure Modes in Medical Multi-Agent Systems 

**Title (ZH)**: MedAgentAudit: 诊断和量化医疗多智能体系统中的协作失效模式 

**Authors**: Lei Gu, Yinghao Zhu, Haoran Sang, Zixiang Wang, Dehao Sui, Wen Tang, Ewen Harrison, Junyi Gao, Lequan Yu, Liantao Ma  

**Link**: [PDF](https://arxiv.org/pdf/2510.10185)  

**Abstract**: While large language model (LLM)-based multi-agent systems show promise in simulating medical consultations, their evaluation is often confined to final-answer accuracy. This practice treats their internal collaborative processes as opaque "black boxes" and overlooks a critical question: is a diagnostic conclusion reached through a sound and verifiable reasoning pathway? The inscrutable nature of these systems poses a significant risk in high-stakes medical applications, potentially leading to flawed or untrustworthy conclusions. To address this, we conduct a large-scale empirical study of 3,600 cases from six medical datasets and six representative multi-agent frameworks. Through a rigorous, mixed-methods approach combining qualitative analysis with quantitative auditing, we develop a comprehensive taxonomy of collaborative failure modes. Our quantitative audit reveals four dominant failure patterns: flawed consensus driven by shared model deficiencies, suppression of correct minority opinions, ineffective discussion dynamics, and critical information loss during synthesis. This study demonstrates that high accuracy alone is an insufficient measure of clinical or public trust. It highlights the urgent need for transparent and auditable reasoning processes, a cornerstone for the responsible development and deployment of medical AI. 

**Abstract (ZH)**: 基于大型语言模型的多Agent系统在模拟医疗咨询中显示出潜力，但其评估通常局限于最终答案的准确性。这种做法将它们的内部协作过程视为不透明的“黑盒”，并忽视了一个关键问题：诊断结论是否是通过一条合理的可验证推理路径得出的？这些系统的不可解释性在高风险医疗应用中构成了重大风险，可能导致不正确的或不可靠的结论。为此，我们对来自六个医疗数据集和六个代表性多Agent框架的3600个案例进行了大规模实证研究。通过结合定性分析与定量审计的严格混合方法，我们开发出全面的协作失败模式分类体系。我们的定量审计揭示了四种主要失败模式：由共享模型缺陷驱动的不正确共识、压制正确的少数意见、无效的讨论动态以及在综合过程中的关键信息丢失。本研究证明，单纯高准确率不足以衡量临床或公众的信任度。它强调了透明和可审计推理过程的急迫需求，这是负责任地开发和部署医疗AI的基石。 

---
# A Survey of Inductive Reasoning for Large Language Models 

**Title (ZH)**: 大型语言模型中归纳推理的研究综述 

**Authors**: Kedi Chen, Dezhao Ruan, Yuhao Dan, Yaoting Wang, Siyu Yan, Xuecheng Wu, Yinqi Zhang, Qin Chen, Jie Zhou, Liang He, Biqing Qi, Linyang Li, Qipeng Guo, Xiaoming Shi, Wei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10182)  

**Abstract**: Reasoning is an important task for large language models (LLMs). Among all the reasoning paradigms, inductive reasoning is one of the fundamental types, which is characterized by its particular-to-general thinking process and the non-uniqueness of its answers. The inductive mode is crucial for knowledge generalization and aligns better with human cognition, so it is a fundamental mode of learning, hence attracting increasing interest. Despite the importance of inductive reasoning, there is no systematic summary of it. Therefore, this paper presents the first comprehensive survey of inductive reasoning for LLMs. First, methods for improving inductive reasoning are categorized into three main areas: post-training, test-time scaling, and data augmentation. Then, current benchmarks of inductive reasoning are summarized, and a unified sandbox-based evaluation approach with the observation coverage metric is derived. Finally, we offer some analyses regarding the source of inductive ability and how simple model architectures and data help with inductive tasks, providing a solid foundation for future research. 

**Abstract (ZH)**: 大型语言模型中归纳推理的重要性和综述 

---
# Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback 

**Title (ZH)**: Dejavu: 通过经验反馈的部署后学习 for 体现代理 

**Authors**: Shaokai Wu, Yanbiao Ji, Qiuchang Li, Zhiyi Zhang, Qichen He, Wenyuan Xie, Guodong Zhang, Bayram Bayramli, Yue Ding, Hongtao Lu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10181)  

**Abstract**: Embodied agents face a fundamental limitation: once deployed in real-world environments to perform specific tasks, they are unable to acquire new useful knowledge to enhance task performance. In this paper, we propose a general post-deployment learning framework called Dejavu, which employs an Experience Feedback Network (EFN) and augments the frozen Vision-Language-Action (VLA) policy with retrieved execution memories. EFN automatically identifies contextually successful prior action experiences and conditions action prediction on this retrieved guidance. We adopt reinforcement learning with semantic similarity rewards on EFN to ensure that the predicted actions align with past successful behaviors under current observations. During deployment, EFN continually enriches its memory with new trajectories, enabling the agent to exhibit "learning from experience" despite fixed weights. Experiments across diverse embodied tasks show that EFN significantly improves adaptability, robustness, and success rates over frozen baselines. These results highlight a promising path toward embodied agents that continually refine their behavior after deployment. 

**Abstract (ZH)**: Embodied代理面临一个根本性限制：一旦部署到实际环境执行特定任务，它们无法获取新的有用知识以增强任务性能。本文提出了一种通用的后部署学习框架Dejavu，该框架利用经验反馈网络（EFN），并结合检索到的执行记忆来增强冻结的视觉-语言-行动（VLA）策略。EFN自动识别上下文成功的历史行动经验，并以检索到的指导为条件进行行动预测。我们采用基于语义相似度奖励的强化学习方法确保EFN预测的动作与当前观测下的历史成功行为一致。在部署过程中，EFN持续丰富其记忆，使代理能够在固定权重的情况下表现出“从经验中学习”的能力。跨多种embodied任务的实验结果表明，EFN显着提高了适应性、鲁棒性和成功率，相比于冻结基线具有显著优势。这些结果突显了朝向部署后不断自我优化的embodied代理的有希望途径。 

---
# LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models 

**Title (ZH)**: LLMs 足以应对一切？Improving Fuzz Testing for MOJO with Large Language Models 

**Authors**: Linghan Huang, Peizhou Zhao, Huaming Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10179)  

**Abstract**: The rapid development of large language models (LLMs) has revolutionized software testing, particularly fuzz testing, by automating the generation of diverse and effective test inputs. This advancement holds great promise for improving software reliability. Meanwhile, the introduction of MOJO, a high-performance AI programming language blending Python's usability with the efficiency of C and C++, presents new opportunities to enhance AI model scalability and programmability. However, as a new language, MOJO lacks comprehensive testing frameworks and a sufficient corpus for LLM-based testing, which exacerbates model hallucination. In this case, LLMs will generate syntactically valid but semantically incorrect code, significantly reducing the effectiveness of fuzz testing. To address this challenge, we propose MOJOFuzzer, the first adaptive LLM-based fuzzing framework designed for zero-shot learning environments of emerging programming languages. MOJOFuzzer integrates a mutil-phase framework that systematically eliminates low-quality generated inputs before execution, significantly improving test case validity. Furthermore, MOJOFuzzer dynamically adapts LLM prompts based on runtime feedback for test case mutation, enabling an iterative learning process that continuously enhances fuzzing efficiency and bug detection performance. Our experimental results demonstrate that MOJOFuzzer significantly enhances test validity, API coverage, and bug detection performance, outperforming traditional fuzz testing and state-of-the-art LLM-based fuzzing approaches. Using MOJOFuzzer, we have conducted a first large-scale fuzz testing evaluation of MOJO, uncorvering 13 previous unknown bugs. This study not only advances the field of LLM-driven software testing but also establishes a foundational methodology for leveraging LLMs in the testing of emerging programming languages. 

**Abstract (ZH)**: 大型语言模型的快速发展通过自动化生成多样且有效的测试输入， revolutionized 软件测试，特别是在 fuzz 测试领域。这一进展为提高软件可靠性提供了巨大潜力。同时，MOJO 语言的引入，这一结合了 Python 的易用性和 C 和 C++ 高效性的高性能 AI 编程语言，为提升 AI 模型的可扩展性和编程性提供了新的机会。然而，作为一门新兴语言，MOJO 缺乏全面的测试框架和基于 LLM 的测试所需的数据集，这加剧了模型的幻觉现象。在这种情况下，LLMs 将生成语法正确但语义错误的代码，显著降低了 fuzz 测试的有效性。为应对这一挑战，我们提出了 MOJOFuzzer，这是首个为新兴编程语言零-shot 学习环境设计的基于 LLM 的 fuzzing 框架。MOJOFuzzer 结合了一个多阶段框架，在执行前系统地消除低质量生成的输入，显著提高测试用例的有效性。此外，MOJOFuzzer 根据运行时反馈动态调整 LLM 命令，实现迭代学习过程，不断提高 fuzzing 效率和 bug 检测性能。实验结果表明，MOJOFuzzer 显著提高了测试有效性、API 覆盖范围和 bug 检测性能，优于传统 fuzz 测试和最先进的基于 LLM 的 fuzzing 方法。利用 MOJOFuzzer，我们首次对 MOJO 进行了大规模 fuzz 测试评估，发现了 13 个先前未知的 bug。本研究不仅推动了 LLM 驱动的软件测试领域的发展，还确立了利用 LLM 对新兴编程语言进行测试的基础方法论。 

---
# HccePose(BF): Predicting Front \& Back Surfaces to Construct Ultra-Dense 2D-3D Correspondences for Pose Estimation 

**Title (ZH)**: HccePose(BF): 预测前后表面以构建超密集2D-3D对应关系进行姿态估计 

**Authors**: Yulin Wang, Mengting Hu, Hongli Li, Chen Luo  

**Link**: [PDF](https://arxiv.org/pdf/2510.10177)  

**Abstract**: In pose estimation for seen objects, a prevalent pipeline involves using neural networks to predict dense 3D coordinates of the object surface on 2D images, which are then used to establish dense 2D-3D correspondences. However, current methods primarily focus on more efficient encoding techniques to improve the precision of predicted 3D coordinates on the object's front surface, overlooking the potential benefits of incorporating the back surface and interior of the object. To better utilize the full surface and interior of the object, this study predicts 3D coordinates of both the object's front and back surfaces and densely samples 3D coordinates between them. This process creates ultra-dense 2D-3D correspondences, effectively enhancing pose estimation accuracy based on the Perspective-n-Point (PnP) algorithm. Additionally, we propose Hierarchical Continuous Coordinate Encoding (HCCE) to provide a more accurate and efficient representation of front and back surface coordinates. Experimental results show that, compared to existing state-of-the-art (SOTA) methods on the BOP website, the proposed approach outperforms across seven classic BOP core datasets. Code is available at this https URL. 

**Abstract (ZH)**: 在已见物体的姿势估计中，一个常见的流程是使用神经网络在二维图像上预测物体表面的密集3D坐标，进而建立密集的2D-3D对应关系。然而，当前的方法主要侧重于更高效的编码技术以提高预测的3D坐标精度，忽略了结合物体背面和内部信息的潜在好处。为了更好地利用物体的完整表面和内部，本研究预测了物体正面和背面表面的3D坐标，并在两者之间进行密集采样。这一过程创建了超密集的2D-3D对应关系，基于视角点法（PnP）算法有效提升了姿势估计的准确性。此外，我们提出了层次连续坐标编码（HCCE）以提供更准确和高效的正面和背面表面坐标表示。实验结果显示，与BOP网站上现有的最先进的（SOTA）方法相比，所提出的方法在七个经典BOP核心数据集上表现更优。代码详见此链接。 

---
# Large Language Model Sourcing: A Survey 

**Title (ZH)**: 大规模语言模型数据来源：一项调查 

**Authors**: Liang Pang, Kangxi Wu, Sunhao Dai, Zihao Wei, Zenghao Duan, Jia Gu, Xiang Li, Zhiyi Yin, Jun Xu, Huawei Shen, Xueqi Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2510.10161)  

**Abstract**: The rapid advancement of large language models (LLMs) has revolutionized artificial intelligence, shifting from supporting objective tasks (e.g., recognition) to empowering subjective decision-making (e.g., planning, decision). This marks the dawn of general and powerful AI, with applications spanning a wide range of fields, including programming, education, healthcare, finance, and law. However, their deployment introduces multifaceted risks. Due to the black-box nature of LLMs and the human-like quality of their generated content, issues such as hallucinations, bias, unfairness, and copyright infringement become particularly significant. In this context, sourcing information from multiple perspectives is essential.
This survey presents a systematic investigation into provenance tracking for content generated by LLMs, organized around four interrelated dimensions that together capture both model- and data-centric perspectives. From the model perspective, Model Sourcing treats the model as a whole, aiming to distinguish content generated by specific LLMs from content authored by humans. Model Structure Sourcing delves into the internal generative mechanisms, analyzing architectural components that shape the outputs of model. From the data perspective, Training Data Sourcing focuses on internal attribution, tracing the origins of generated content back to the training data of model. In contrast, External Data Sourcing emphasizes external validation, identifying external information used to support or influence the responses of model. Moreover, we also propose a dual-paradigm taxonomy that classifies existing sourcing methods into prior-based (proactive traceability embedding) and posterior-based (retrospective inference) approaches. Traceability across these dimensions enhances the transparency, accountability, and trustworthiness of LLMs deployment in real-world applications. 

**Abstract (ZH)**: 大型语言模型的迅速发展已经改变了人工智能，从支持客观任务（如识别）转变为赋能主观决策（如规划、决策）。这标志着通用且强大的人工智能的 dawn，其应用涵盖了编程、教育、医疗、金融和法律等多个领域。然而，其部署引入了多方面的风险。由于大型语言模型的黑盒性质及其生成内容的人类质量，幻觉、偏见、不公平和版权侵权等问题变得尤为重要。在这种背景下，从多个角度获取信息是必不可少的。

本文综述了针对由大型语言模型生成内容的来源追踪进行系统的调查，围绕四个相互关联的维度组织，这些维度共同捕捉了模型和数据中心的视角。从模型视角来看，模型来源将模型作为一个整体对待，旨在区分由特定大型语言模型生成的内容与由人类编写的內容。模型结构来源深入探讨了内部生成机制，分析了塑造模型输出的架构组件。从数据视角来看，训练数据来源关注内部归因，追溯生成内容的溯源至模型的训练数据。相比之下，外部数据来源强调外部验证，识别用于支持或影响模型响应的外部信息。此外，我们还提出了一种双范式分类法，将现有的来源方法分为基于先验（主动跟踪嵌入）和基于后验（回顾性推理）的方法。这些维度上的可追溯性增强了大型语言模型在实际应用中部署的透明性、问责性和可信度。 

---
# SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation 

**Title (ZH)**: SaFiRe: 眯眼- fixation 重迭代用于图像分割的引用方法 

**Authors**: Zhenjie Mao, Yuhuan Yang, Chaofan Ma, Dongsheng Jiang, Jiangchao Yao, Ya Zhang, Yanfeng Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10160)  

**Abstract**: Referring Image Segmentation (RIS) aims to segment the target object in an image given a natural language expression. While recent methods leverage pre-trained vision backbones and more training corpus to achieve impressive results, they predominantly focus on simple expressions--short, clear noun phrases like "red car" or "left girl". This simplification often reduces RIS to a key word/concept matching problem, limiting the model's ability to handle referential ambiguity in expressions. In this work, we identify two challenging real-world scenarios: object-distracting expressions, which involve multiple entities with contextual cues, and category-implicit expressions, where the object class is not explicitly stated. To address the challenges, we propose a novel framework, SaFiRe, which mimics the human two-phase cognitive process--first forming a global understanding, then refining it through detail-oriented inspection. This is naturally supported by Mamba's scan-then-update property, which aligns with our phased design and enables efficient multi-cycle refinement with linear complexity. We further introduce aRefCOCO, a new benchmark designed to evaluate RIS models under ambiguous referring expressions. Extensive experiments on both standard and proposed datasets demonstrate the superiority of SaFiRe over state-of-the-art baselines. 

**Abstract (ZH)**: 参考图像分割（RIS）旨在给定自然语言表达的情况下对图像中的目标对象进行分割。尽管近期方法利用预训练的视觉 backbone 和更多的训练语料取得了显著成果，但它们主要侧重于简单的表达——如“红色汽车”或“左侧的女孩”这样的短且清晰的名词短语。这种简化往往将RIS简化为关键词/概念匹配问题，限制了模型处理表达中的引用歧义的能力。在本文中，我们识别了两个具有挑战性的现实场景：具有上下文提示的对象分散表达，以及包含未明确陈述的对象类别的情况。为应对这些挑战，我们提出了一种新的框架 SaFiRe，模拟人类的两阶段认知过程——首先形成全局理解，然后通过细节审视进行细化。Mamba 的扫描-更新特性天然支持这一设计，使我们的多阶段设计能够高效地进行线性复杂度的多轮细化。此外，我们引入了 aRefCOCO，这是一个新的基准，用于评估在模糊引用表达下的RIS模型性能。广泛的实验结果表明，SaFiRe 在标准数据集和提出的数据集上均优于现有的基线方法。 

---
# Multi-Scale Diffusion Transformer for Jointly Simulating User Mobility and Mobile Traffic Pattern 

**Title (ZH)**: 多尺度扩散变换器联合模拟用户移动性和移动流量模式 

**Authors**: Ziyi Liu, Qingyue Long, Zhiwen Xue, Huandong Wang, Yong Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.10158)  

**Abstract**: User mobility trajectory and mobile traffic data are essential for a wide spectrum of applications including urban planning, network optimization, and emergency management. However, large-scale and fine-grained mobility data remains difficult to obtain due to privacy concerns and collection costs, making it essential to simulate realistic mobility and traffic patterns. User trajectories and mobile traffic are fundamentally coupled, reflecting both physical mobility and cyber behavior in urban environments. Despite this strong interdependence, existing studies often model them separately, limiting the ability to capture cross-modal dynamics. Therefore, a unified framework is crucial. In this paper, we propose MSTDiff, a Multi-Scale Diffusion Transformer for joint simulation of mobile traffic and user trajectories. First, MSTDiff applies discrete wavelet transforms for multi-resolution traffic decomposition. Second, it uses a hybrid denoising network to process continuous traffic volumes and discrete location sequences. A transition mechanism based on urban knowledge graph embedding similarity is designed to guide semantically informed trajectory generation. Finally, a multi-scale Transformer with cross-attention captures dependencies between trajectories and traffic. Experiments show that MSTDiff surpasses state-of-the-art baselines in traffic and trajectory generation tasks, reducing Jensen-Shannon divergence (JSD) across key statistical metrics by up to 17.38% for traffic generation, and by an average of 39.53% for trajectory generation. The source code is available at: this https URL . 

**Abstract (ZH)**: 基于多尺度扩散变换器的移动交通和用户轨迹联合仿真 

---
# BILLY: Steering Large Language Models via Merging Persona Vectors for Creative Generation 

**Title (ZH)**: BILLY: 通过合并人格向量引导大型语言模型进行创造性生成 

**Authors**: Tsung-Min Pai, Jui-I Wang, Li-Chun Lu, Shao-Hua Sun, Hung-Yi Lee, Kai-Wei Chang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10157)  

**Abstract**: Multi-LLM systems enhance the creativity of large language models by simulating human collective intelligence but suffer from significant drawbacks, such as high computational costs and inference latency. To address these limitations, we propose BILLY (BlendIng persona vectors for Large Language model creativitY), a training-free framework that captures the benefits of multi-LLM collaboration, i.e. inducing diverse perspectives and specialized expertise, within a single model. BILLY operates by extracting and blending multiple distinct persona vectors directly in the model's activation space. We steer the model's generation process with this merged vector while inference, enabling multi-perspective output without explicit multi-LLM communication. Our experiments across creativity-oriented benchmarks demonstrate that BILLY surpasses single model prompting and traditional multi-LLM approaches, while substantially reducing inference time and computational costs. Our analyses further reveal that distinct persona vectors can be blended to achieve both effective control over complementary aspects of generation and greater interpretability. 

**Abstract (ZH)**: Multi-LLM系统通过模拟人类集体智能增强了大型语言模型的创造力，但面临显著的缺点，如高额的计算成本和推断延迟。为了解决这些局限性，我们提出了BILLY（BlendIng persona vectors for Large Language model creativitY）框架，这是一种无需训练的框架，能够在单一模型中捕捉多LLM合作的优势，即诱导多样视角和专业 expertise。BILLY通过直接在模型的激活空间中提取和融合多个独特的persona向量来操作，我们在推断过程中通过这个合并向量引导模型的生成过程，从而实现多视角输出而无需显式的多LLM通信。我们在创造力导向的基准测试中进行的实验表明，BILLY在单模型提示和传统多LLM方法的基础上，显著减少了推断时间和计算成本。进一步的分析表明，不同的persona向量可以被融合以实现生成的有效控制和更高的可解释性。 

---
# Rethinking Entropy Interventions in RLVR: An Entropy Change Perspective 

**Title (ZH)**: 重新思考RLVR中的熵干预：从熵变化视角出发 

**Authors**: Zhezheng Hao, Hong Wang, Haoyang Liu, Jian Luo, Jiarui Yu, Hande Dong, Qiang Lin, Can Wang, Jiawei Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10150)  

**Abstract**: While Reinforcement Learning with Verifiable Rewards (RLVR) can enhance LLM reasoning, its training process poses a critical risk: entropy collapse. This phenomenon is a rapid loss of policy diversity, stemming from the exploration-exploitation imbalance and leading to a lack of generalization. Recent entropy-intervention methods aim to prevent \coloredtext{entropy collapse}, yet their underlying mechanisms remain unclear. In this paper, we conduct a quantitative analysis to reveal token-level entropy changes and how existing entropy intervention methods help avoid entropy collapse. Our findings point out a fundamental limitation of existing methods: they attempt to control entropy dynamics indirectly. By only affecting related factors, such as the advantage signal and generation probability, their effectiveness is inherently limited and could potentially fail. To address this limitation, we introduce an entropy-change-aware reweighting scheme, namely Stabilizing Token-level Entropy-changE via Reweighting (STEER), that adaptively stabilizes entropy dynamics through fine-grained token-level adjustments. Our approach mitigates over-exploitation while fostering robust exploration. Extensive experiments demonstrate that STEER significantly mitigates entropy collapse, stabilizes entropy dynamics, and achieves stronger downstream performance across various mathematical reasoning benchmarks \footnote{Our code is available at this https URL. 

**Abstract (ZH)**: While Reinforcement Learning with Verifiable Rewards (RLVR)可以增强大模型的推理能力，其训练过程存在一个关键风险：熵坍缩现象。这种现象源于探索与利用间的不平衡，导致政策多样性快速降低，从而影响泛化能力。最近的熵干预方法旨在防止熵坍缩，但其背后的机制仍不明确。本文通过定量分析揭示了token级别的熵变化及其现有熵干预方法如何帮助避免熵坍缩。我们的研究发现指出了现有方法的一个根本局限性：它们试图通过间接方式控制熵动态。仅通过影响相关因素，如优势信号和生成概率，它们的有效性受到限制，有可能失效。为解决这一局限性，我们提出了一种熵变化感知的加权方案，即通过细粒度的token级别调整来适应性稳定熵动态（Stabilizing Token-level Entropy-changE via Reweighting, STEER）。我们的方法在抑制过度利用的同时促进了稳健的探索。广泛实验表明，STEER显著缓解了熵坍缩，稳定了熵动态，并在各种数学推理基准上实现了更强的下游性能。 

---
# A Unified Frequency Domain Decomposition Framework for Interpretable and Robust Time Series Forecasting 

**Title (ZH)**: 统一的频域分解框架：可解释性和稳健性时间序列预测 

**Authors**: Cheng He, Xijie Liang, Zengrong Zheng, Patrick P.C. Lee, Xu Huang, Zhaoyi Li, Hong Xie, Defu Lian, Enhong Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10145)  

**Abstract**: Current approaches for time series forecasting, whether in the time or frequency domain, predominantly use deep learning models based on linear layers or transformers. They often encode time series data in a black-box manner and rely on trial-and-error optimization solely based on forecasting performance, leading to limited interpretability and theoretical understanding. Furthermore, the dynamics in data distribution over time and frequency domains pose a critical challenge to accurate forecasting. We propose FIRE, a unified frequency domain decomposition framework that provides a mathematical abstraction for diverse types of time series, so as to achieve interpretable and robust time series forecasting. FIRE introduces several key innovations: (i) independent modeling of amplitude and phase components, (ii) adaptive learning of weights of frequency basis components, (iii) a targeted loss function, and (iv) a novel training paradigm for sparse data. Extensive experiments demonstrate that FIRE consistently outperforms state-of-the-art models on long-term forecasting benchmarks, achieving superior predictive performance and significantly enhancing interpretability of time series 

**Abstract (ZH)**: FIRE：频率域分解统一框架实现可解释且稳健的时间序列预测 

---
# DiffHeads: Differential Analysis and Inference-Time Masking of Bias Heads in Large Language Models 

**Title (ZH)**: DiffHeads: 大型语言模型中偏差头部的差异性分析及推理时掩码 

**Authors**: Tingxu Han, Wei Song, Ziqi Ding, Ziming Li, Chunrong Fang, Yuekang Li, Dongfang Liu, Zhenyu Chen, Zhenting Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10142)  

**Abstract**: Large language models (LLMs) increasingly mediate decisions in domains where unfair treatment of demographic groups is unacceptable. Existing work probes when biased outputs appear, but gives little insight into the mechanisms that generate them, leaving existing mitigations largely fragile. In this paper, we conduct a systematic investigation LLM unfairness and propose DiffHeads, a lightweight debiasing framework for LLMs. We first compare Direct-Answer (DA) prompting to Chain-of-Thought (CoT) prompting across eight representative open- and closed-source LLMs. DA will trigger the nature bias part of LLM and improve measured unfairness by 534.5%-391.9% in both one-turn and two-turn dialogues. Next, we define a token-to-head contribution score that traces each token's influence back to individual attention heads. This reveals a small cluster of bias heads that activate under DA but stay largely dormant with CoT, providing the first causal link between prompting strategy and bias emergence. Finally, building on this insight, we propose DiffHeads that identifies bias heads through differential activation analysis between DA and CoT, and selectively masks only those heads. DiffHeads reduces unfairness by 49.4%, and 40.3% under DA and CoT, respectively, without harming model utility. 

**Abstract (ZH)**: 大型语言模型（LLMs）在不可接受对 demographic groups 不公平处理的领域中日益成为决策中介。现有研究探讨了偏差输出出现的时间，但缺乏生成这些偏差机制的洞察，导致现有缓解措施不够稳健。在本文中，我们对 LLM 不公平性进行系统研究，并提出了一个轻量级的去偏框架 DiffHeads。我们首先比较了直接答案（DA）提示和思考链（CoT）提示在八种代表性开源和闭源 LLM 中的表现。DA 技术会触发 LLM 的自然偏差部分，并在单轮和双轮对话中分别将测量的不公平性提高 534.5% 至 391.9%。接下来，我们定义了一个 token 至 attention head 贡献评分，追踪每个 token 的影响追溯到个体注意力头。这揭示了一个在 DA 下激活但在 CoT 下保持静默的小型偏差头簇，提供了提示策略与偏差出现之间的因果联系。最后，基于这一洞察，我们提出了 DiffHeads，通过分析 DA 和 CoT 之间的不同激活来识别偏差头，并仅选择性地遮掩这些头。DiffHeads 分别在 DA 和 CoT 情况下将不公平性降低 49.4% 和 40.3%，而不损害模型的实用性。 

---
# Hybrid OCR-LLM Framework for Enterprise-Scale Document Information Extraction Under Copy-heavy Task 

**Title (ZH)**: 企业规模文档信息提取的OCR-LLM混合框架：以复制任务为主的工作负载 

**Authors**: Zilong Wang, Xiaoyu Shen  

**Link**: [PDF](https://arxiv.org/pdf/2510.10138)  

**Abstract**: Information extraction from copy-heavy documents, characterized by massive volumes of structurally similar content, represents a critical yet understudied challenge in enterprise document processing. We present a systematic framework that strategically combines OCR engines with Large Language Models (LLMs) to optimize the accuracy-efficiency trade-off inherent in repetitive document extraction tasks. Unlike existing approaches that pursue universal solutions, our method exploits document-specific characteristics through intelligent strategy selection. We implement and evaluate 25 configurations across three extraction paradigms (direct, replacement, and table-based) on identity documents spanning four formats (PNG, DOCX, XLSX, PDF). Through table-based extraction methods, our adaptive framework delivers outstanding results: F1=1.0 accuracy with 0.97s latency for structured documents, and F1=0.997 accuracy with 0.6 s for challenging image inputs when integrated with PaddleOCR, all while maintaining sub-second processing speeds. The 54 times performance improvement compared with multimodal methods over naive approaches, coupled with format-aware routing, enables processing of heterogeneous document streams at production scale. Beyond the specific application to identity extraction, this work establishes a general principle: the repetitive nature of copy-heavy tasks can be transformed from a computational burden into an optimization opportunity through structure-aware method selection. 

**Abstract (ZH)**: 从副本内容丰富的文档中提取信息：一种结合OCR引擎与大型语言模型的系统框架及其在企业文档处理中的应用 

---
# PermLLM: Learnable Channel Permutation for N:M Sparse Large Language Models 

**Title (ZH)**: PermLLM：可学习的信道置换用于N:M稀疏大型语言模型 

**Authors**: Lancheng Zou, Shuo Yin, Zehua Pei, Tsung-Yi Ho, Farzan Farnia, Bei Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10136)  

**Abstract**: Channel permutation is a powerful technique for enhancing the accuracy of N:M sparse models by reordering the channels of weight matrices to prioritize the retention of important weights. However, traditional channel permutation methods rely on handcrafted quality metrics, which often fail to accurately capture the true impact of pruning on model performance. To address this limitation, we propose PermLLM, a novel post-training pruning framework that introduces learnable channel permutation (LCP) for N:M sparsity. LCP leverages Sinkhorn normalization to transform discrete permutation matrices into differentiable soft permutation matrices, enabling end-to-end optimization. Additionally, PermLLM incorporates an efficient block-wise channel permutation strategy, which significantly reduces the number of learnable parameters and computational complexity. PermLLM seamlessly integrates with existing one-shot pruning methods to adaptively optimize channel permutations, effectively mitigating pruning-induced errors. Extensive experiments on the LLaMA series, Qwen, and OPT models demonstrate that PermLLM achieves superior performance in optimizing N:M sparse models. The code is available at this https URL. 

**Abstract (ZH)**: Channel 排序是一种通过重排权重矩阵的通道来增强N:M稀疏模型准确性的强大技术，以优先保留重要权重。然而，传统的通道排序方法依赖于手工设计的质量指标，这些指标往往无法准确捕捉剪枝对模型性能的真实影响。为解决这一局限，我们提出PermLLM，这是一种新颖的后训练剪枝框架，引入了可学习的通道排序（LCP）以实现N:M稀疏性。LCP利用Sinkhorn归一化将离散的排列矩阵转换为可微的软排列矩阵，从而实现端到端优化。此外，PermLLM还结合了一种高效的块级通道排序策略，显著减少了可学习参数的数量和计算复杂度。PermLLM能够无缝集成到现有的单次剪枝方法中，以自适应地优化通道排序，有效抵消剪枝引入的误差。在LLaMA系列、Qwen和OPT模型上的广泛实验表明，PermLLM在优化N:M稀疏模型方面表现出色。代码可在以下链接获取：this https URL。 

---
# CacheClip: Accelerating RAG with Effective KV Cache Reuse 

**Title (ZH)**: CacheClip: 加速RAG的有效KV缓存重用 

**Authors**: Bin Yang, Qiuyu Leng, Jun Zeng, Zhenhua Wu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10129)  

**Abstract**: Retrieval-Augmented Generation (RAG) systems suffer from severe time-to-first-token (TTFT) bottlenecks due to long input sequences. Existing KV cache reuse methods face a fundamental trade-off: prefix caching requires identical prefixes that rarely occur in RAG scenarios, while direct precomputation sacrifices quality due to missing inter-chunk attention and repeated attention sinks. Recent methods like APE and CacheBlend partially address these issues but remain inadequate for robust RAG applications. This paper presents CacheClip, a novel framework that achieves both fast TTFT and high generation quality. Our key insight is that small auxiliary LLMs exhibit similar last-layer attention distributions to primary LLMs (the target model for generation), enabling efficient identification of tokens critical for restoring inter-chunk attention, thereby significantly improving response quality on cross-chunk reasoning tasks. CacheClip integrates three techniques: (1) auxiliary-model-guided token selection for selective KV cache recomputation, where the auxiliary model is finetuned to improve selection accuracy, (2) shared prefixes to eliminate redundant attention sinks, and (3) grouping strategy to maintain local coherence during partial KV cache updates. Experiments show CacheClip retains up to 94.8% and 85.0% of full-attention performance on NIAH and LongBench, outperforming APE and CacheBlend by 25.2% and 35.1% on NIAH (with reomp% = 20%). Meanwhile, CacheClip accelerates LLM inference by up to 1.92x in prefill time, providing a practical solution to the efficiency-quality trade-off in RAG systems. 

**Abstract (ZH)**: 基于检索的生成（RAG）系统因长输入序列而遭受严重的首个token响应时间（TTFT）瓶颈。现有的KV缓存复用方法面临一个根本性的权衡：前缀缓存需要几乎不出现于RAG场景中的相同前缀，而直接预计算会因为缺少跨块注意和重复的注意阱而牺牲质量。最近的方法如APE和CacheBlend部分解决了这些问题，但对于鲁棒的RAG应用仍不够完善。本文提出了CacheClip，这是一种新颖的框架，能够同时实现快速的TTFT和高质量的生成。我们的关键洞察是，辅助LLM在最后一层注意力分布上与主要LLM（用于生成的目标模型）表现出相似性，这使我们能够有效识别对于恢复跨块注意力至关重要的token，从而显著提高跨块推理任务的响应质量。CacheClip结合了三种技术：（1）辅助模型引导的token选择以选择性地重新计算KV缓存，其中辅助模型微调以提高选择准确性；（2）共享前缀以消除冗余注意陷阱；（3）分组策略，在部分KV缓存更新过程中维持局部连贯性。实验结果显示，CacheClip在NIAH和LongBench上分别保留了94.8%和85.0%的全注意力性能，相较于APE和CacheBlend在NIAH上分别提高了25.2%和35.1%（凭借20%的重新计算比例）。同时，CacheClip将LLM推理的预填充时间加速了1.92倍，为RAG系统中的效率与质量权衡提供了一个实用的解决方案。 

---
# Ctrl-World: A Controllable Generative World Model for Robot Manipulation 

**Title (ZH)**: Ctrl-World: 一种可控制生成的世界模型用于机器人操作 

**Authors**: Yanjiang Guo, Lucy Xiaoyang Shi, Jianyu Chen, Chelsea Finn  

**Link**: [PDF](https://arxiv.org/pdf/2510.10125)  

**Abstract**: Generalist robot policies can now perform a wide range of manipulation skills, but evaluating and improving their ability with unfamiliar objects and instructions remains a significant challenge. Rigorous evaluation requires a large number of real-world rollouts, while systematic improvement demands additional corrective data with expert labels. Both of these processes are slow, costly, and difficult to scale. World models offer a promising, scalable alternative by enabling policies to rollout within imagination space. However, a key challenge is building a controllable world model that can handle multi-step interactions with generalist robot policies. This requires a world model compatible with modern generalist policies by supporting multi-view prediction, fine-grained action control, and consistent long-horizon interactions, which is not achieved by previous works. In this paper, we make a step forward by introducing a controllable multi-view world model that can be used to evaluate and improve the instruction-following ability of generalist robot policies. Our model maintains long-horizon consistency with a pose-conditioned memory retrieval mechanism and achieves precise action control through frame-level action conditioning. Trained on the DROID dataset (95k trajectories, 564 scenes), our model generates spatially and temporally consistent trajectories under novel scenarios and new camera placements for over 20 seconds. We show that our method can accurately rank policy performance without real-world robot rollouts. Moreover, by synthesizing successful trajectories in imagination and using them for supervised fine-tuning, our approach can improve policy success by 44.7\%. 

**Abstract (ZH)**: 通用机器人策略现在可以执行广泛的操纵技能，但评估和在不熟悉的对象和指令下提升其能力仍是一项重大挑战。严格的评估需要大量的真实世界滚动测试，而系统的改进则需要额外的带有专家标记的纠正数据。这两个过程都缓慢、昂贵且难以扩展。世界模型提供了一种有前景的、可扩展的替代方案，通过使策略在想象空间内滚动来实现这一点。然而，关键挑战是构建一个可控的世界模型，可以处理通用机器人策略的多步交互。这需要一种与现代通用策略相兼容的世界模型，支持多视图预测、精细的动作控制和一致的长时交互，而这些目标此前的研究并未实现。在这篇论文中，我们通过引入一个可控的多视图世界模型向前迈出一步，该模型可以用于评估和提高通用机器人策略遵循指令的能力。我们的模型通过姿态条件化的记忆检索机制保持长时间的一致性，并通过帧级动作条件实现精确的动作控制。在DROID数据集（包含95,000条轨迹、564个场景）上训练后，我们的模型能够在新的场景和新的摄像机架设方式下生成超过20秒的空间和时间上一致的轨迹。我们展示了我们的方法可以在不需要真实世界机器人滚动测试的情况下准确排名策略性能。此外，通过在想象中合成成功的轨迹并用于监督微调，我们的方法可以将策略成功率提高44.7%。 

---
# DeepFusionNet: Autoencoder-Based Low-Light Image Enhancement and Super-Resolution 

**Title (ZH)**: DeepFusionNet：基于自编码器的低光照图像增强与超分辨率 

**Authors**: Halil Hüseyin Çalışkan, Talha Koruk  

**Link**: [PDF](https://arxiv.org/pdf/2510.10122)  

**Abstract**: Computer vision and image processing applications suffer from dark and low-light images, particularly during real-time image transmission. Currently, low light and dark images are converted to bright and colored forms using autoencoders; however, these methods often achieve low SSIM and PSNR scores and require high computational power due to their large number of parameters. To address these challenges, the DeepFusionNet architecture has been developed. According to the results obtained with the LOL-v1 dataset, DeepFusionNet achieved an SSIM of 92.8% and a PSNR score of 26.30, while containing only approximately 2.5 million parameters. On the other hand, conversion of blurry and low-resolution images into high-resolution and blur-free images has gained importance in image processing applications. Unlike GAN-based super-resolution methods, an autoencoder-based super resolution model has been developed that contains approximately 100 thousand parameters and uses the DeepFusionNet architecture. According to the results of the tests, the DeepFusionNet based super-resolution method achieved a PSNR of 25.30 and a SSIM score of 80.7 percent according to the validation set. 

**Abstract (ZH)**: 计算机视觉和图像处理应用程序在处理暗光和低光图像时遇到挑战，特别是在实时图像传输中。目前，通过自编码器将低光照和暗光图像转换为明亮彩色的形式，但这些方法往往获得较低的SSIM和PSNR分数，并且由于参数众多需要大量计算资源。为解决这些问题，开发了DeepFusionNet架构。根据使用LOL-v1数据集获得的结果，DeepFusionNet实现了92.8%的SSIM和26.30的PSNR分数，其参数数量约为250万。另一方面，高分辨率和无模糊图像的转换在图像处理应用中变得重要。不同于基于GAN的超分辨率方法，开发了一种基于自编码器的超分辨率模型，参数数量约为10万，并采用DeepFusionNet架构。根据测试结果，基于DeepFusionNet的超分辨率方法在验证集上实现了25.30的PSNR和80.7%的SSIM分数。 

---
# Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization 

**Title (ZH)**: 无需训练的 context forensic 链对于图像操纵的检测与定位 

**Authors**: Rui Chen, Bin Liu, Changtao Miao, Xinghao Wang, Yi Li, Tao Gong, Qi Chu, Nenghai Yu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10111)  

**Abstract**: Advances in image tampering pose serious security threats, underscoring the need for effective image manipulation localization (IML). While supervised IML achieves strong performance, it depends on costly pixel-level annotations. Existing weakly supervised or training-free alternatives often underperform and lack interpretability. We propose the In-Context Forensic Chain (ICFC), a training-free framework that leverages multi-modal large language models (MLLMs) for interpretable IML tasks. ICFC integrates an objectified rule construction with adaptive filtering to build a reliable knowledge base and a multi-step progressive reasoning pipeline that mirrors expert forensic workflows from coarse proposals to fine-grained forensics results. This design enables systematic exploitation of MLLM reasoning for image-level classification, pixel-level localization, and text-level interpretability. Across multiple benchmarks, ICFC not only surpasses state-of-the-art training-free methods but also achieves competitive or superior performance compared to weakly and fully supervised approaches. 

**Abstract (ZH)**: 图像篡改技术的进步构成了严重的安全威胁，强调了有效图像操纵定位（IML）的需求。虽然监督式IML取得了较强的性能，但它依赖于昂贵的像素级注释。现有的弱监督或无需训练的替代方法往往性能不佳且缺乏可解释性。我们提出了一种无需训练的框架——上下文取证链（ICFC），该框架利用多模态大语言模型（MLLMs）进行可解释的IML任务。ICFC 结合对象化的规则构建与自适应过滤，构建了一个可靠的知识库，并建立了一个多步骤递进推理管道，该管道模拟了从粗略提案到细粒度取证结果的专家取证工作流程。这一设计使得系统地利用MLLM推理用于图像级分类、像素级定位和文本级可解释性成为可能。在多个基准测试中，ICFC 不仅超越了最先进的无需训练方法，而且在弱监督和全监督方法方面也实现了竞争力或更优的性能。 

---
# Uncertainty-Aware Post-Detection Framework for Enhanced Fire and Smoke Detection in Compact Deep Learning Models 

**Title (ZH)**: 考虑不确定性后处理框架以增强紧凑深度学习模型中的火灾和烟雾检测 

**Authors**: Aniruddha Srinivas Joshi, Godwyn James William, Shreyas Srinivas Joshi  

**Link**: [PDF](https://arxiv.org/pdf/2510.10108)  

**Abstract**: Accurate fire and smoke detection is critical for safety and disaster response, yet existing vision-based methods face challenges in balancing efficiency and reliability. Compact deep learning models such as YOLOv5n and YOLOv8n are widely adopted for deployment on UAVs, CCTV systems, and IoT devices, but their reduced capacity often results in false positives and missed detections. Conventional post-detection methods such as Non-Maximum Suppression and Soft-NMS rely only on spatial overlap, which can suppress true positives or retain false alarms in cluttered or ambiguous fire scenes. To address these limitations, we propose an uncertainty aware post-detection framework that rescales detection confidences using both statistical uncertainty and domain relevant visual cues. A lightweight Confidence Refinement Network integrates uncertainty estimates with color, edge, and texture features to adjust detection scores without modifying the base model. Experiments on the D-Fire dataset demonstrate improved precision, recall, and mean average precision compared to existing baselines, with only modest computational overhead. These results highlight the effectiveness of post-detection rescoring in enhancing the robustness of compact deep learning models for real-world fire and smoke detection. 

**Abstract (ZH)**: 准确的火灾和烟雾检测对于安全和灾害响应至关重要，但现有的基于视觉的方法在效率和可靠性之间难以平衡。紧凑型深度学习模型如YOLOv5n和YOLOv8n广泛应用在无人机、闭路电视系统和物联网设备上，但它们的容量缩减往往导致误报和漏报。传统后检测方法如非最大抑制和Soft-NMS仅依赖于空间重叠，这在复杂或多义的火灾场景中可能抑制真实阳性或保留误报。为解决这些问题，我们提出一个意识不确定性的后检测框架，使用统计不确定性和领域相关视觉线索重新标定检测置信度。一个轻量级的置信度精炼网络将不确定性估计与颜色、边缘和纹理特征整合，调整检测分数而不修改基础模型。在D-Fire数据集上的实验表明，与现有基线相比，该方法在精度、召回率和平均精度上有所提高，且计算 overhead 较小。这些结果突显了后检测重新评分在增强紧凑型深度学习模型在实际火灾和烟雾检测中的鲁棒性方面的有效性。 

---
# Uncovering Singularities in Feynman Integrals via Machine Learning 

**Title (ZH)**: 通过机器学习发现费曼积分中的奇点 

**Authors**: Yuanche Liu, Yingxuan Xu, Yang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10099)  

**Abstract**: We introduce a machine-learning framework based on symbolic regression to extract the full symbol alphabet of multi-loop Feynman integrals. By targeting the analytic structure rather than reduction, the method is broadly applicable and interpretable across different families of integrals. It successfully reconstructs complete symbol alphabets in nontrivial examples, demonstrating both robustness and generality. Beyond accelerating computations case by case, it uncovers the analytic structure universally. This framework opens new avenues for multi-loop amplitude analysis and provides a versatile tool for exploring scattering amplitudes. 

**Abstract (ZH)**: 基于符号回归的机器学习框架用于提取多环费曼积分的完整符号字母表 

---
# What Makes Looped Transformers Perform Better Than Non-Recursive Ones (Provably) 

**Title (ZH)**: Looped Transformer相较于非递归Transformer优越的原理分析 

**Authors**: Zixuan Gong, Jiaye Teng, Yong Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10089)  

**Abstract**: While looped transformers (termed as Looped-Attn) often outperform standard transformers (termed as Single-Attn) on complex reasoning tasks, the theoretical basis for this advantage remains underexplored. In this paper, we explain this phenomenon through the lens of loss landscape geometry, inspired by empirical observations of their distinct dynamics at both sample and Hessian levels. To formalize this, we extend the River-Valley landscape model by distinguishing between U-shaped valleys (flat) and V-shaped valleys (steep). Based on empirical observations, we conjecture that the recursive architecture of Looped-Attn induces a landscape-level inductive bias towards River-V-Valley. Theoretical derivations based on this inductive bias guarantee a better loss convergence along the river due to valley hopping, and further encourage learning about complex patterns compared to the River-U-Valley induced by Single-Attn. Building on this insight, we propose SHIFT (Staged HIerarchical Framework for Progressive Training), a staged training framework that accelerates the training process of Looped-Attn while achieving comparable performances. 

**Abstract (ZH)**: 循环变压器（记作 Looped-Attn）在复杂推理任务上通常优于标准变压器（记作 Single-Attn），但其理论优势的基础仍需进一步探索。本文通过损失景观几何结构的视角来解释这一现象，受到其在样本和海森berg矩阵层面不同动态的实证观察的启发。为了形式化这一分析，我们扩展了河流-山谷景观模型，区分U形山谷（平坦）和V形山谷（陡峭）。基于实证观察，我们推测 Looped-Attn 的递归架构诱导了在景观层面倾向于河流-山谷类型的归纳偏置。基于这一归纳偏置的理论推导保证了沿河流方向更好的损失收敛，通过山谷跳跃进一步促进了复杂模式的学习，而单感知器（Single-Attn）诱导的河流-山谷类型则不如前者。基于此洞见，我们提出了一种分阶段层次框架（SHIFT），以加速循环变换器（Looped-Attn）的训练过程并实现相当的性能。 

---
# Pharmacist: Safety Alignment Data Curation for Large Language Models against Harmful Fine-tuning 

**Title (ZH)**: 药师：针对有害微调的安全对齐数据编目大语言模型 

**Authors**: Guozhi Liu, Qi Mu, Tiansheng Huang, Xinhua Wang, Li Shen, Weiwei Lin, Zhang Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.10085)  

**Abstract**: Harmful fine-tuning issues present significant safety challenges for fine-tuning-as-a-service in large language models. Existing alignment-stage defenses, e.g., Vaccine, Repnoise, Booster, and T-Vaccine, mitigate harmful fine-tuning issues by enhancing the model's robustness during the alignment phase. While these methods have been proposed to mitigate the issue, they often overlook a critical upstream factor: the role of the original safety-alignment data. We observe that their defense performance and computational efficiency remain constrained by the quality and composition of the alignment dataset. To address this limitation, we propose Pharmacist, a safety alignment data curation solution that enhances defense against harmful fine-tuning by selecting a high-quality and safety-critical core subset from the original alignment data. The core idea of Pharmacist is to train an alignment data selector to rank alignment data. Specifically, up-ranking high-quality and safety-critical alignment data, down-ranking low-quality and non-safety-critical data. Empirical results indicate that models trained on datasets selected by Pharmacist outperform those trained on datasets selected by existing selection methods in both defense and inference performance. In addition, Pharmacist can be effectively integrated with mainstream alignment-stage defense methods. For example, when applied to RepNoise and T-Vaccine, using the dataset selected by Pharmacist instead of the full dataset leads to improvements in defense performance by 2.60\% and 3.30\%, respectively, and enhances inference performance by 3.50\% and 1.10\%. Notably, it reduces training time by 56.83\% and 57.63\%, respectively. Our code is available at this https URL. 

**Abstract (ZH)**: 有害微调问题对大型语言模型的微调即服务构成了显著的安全挑战。现有的对齐阶段防御措施，例如Vaccine、Repnoise、Booster和T-Vaccine，通过在对齐阶段增强模型的稳健性来缓解有害微调问题。虽然这些方法提出了缓解问题的策略，但往往忽视了一个关键的上游因素：原始安全对齐数据的作用。我们观察到，它们的防御性能和计算效率仍然受限于对齐数据集的质量和构成。为了解决这一局限性，我们提出Pharmacist，这是一种安全对齐数据策展解决方案，通过从原始对齐数据中选择高质量和关键安全核心子集来增强对有害微调的防御。Pharmacist的核心思想是训练一个对齐数据选择器来对对齐数据进行排序，具体而言，提升高质量和关键安全对齐数据的排名，降低低质量和非关键安全数据的排名。实验结果表明，使用Pharmacist选择的数据集训练的模型，在防御和推理性能上都优于使用现有选择方法的数据集训练的模型。此外，Pharmacist可以有效集成到主流的对齐阶段防御方法中。例如，当应用于RepNoise和T-Vaccine时，使用Pharmacist选择的数据集而不是全数据集，防御性能分别提高了2.60%和3.30%，推理性能分别提高了3.50%和1.10%。值得注意的是，这分别减少了56.83%和57.63%的训练时间。我们的代码 available at this https URL。 

---
# How AI Companionship Develops: Evidence from a Longitudinal Study 

**Title (ZH)**: AI伴侣的发展：纵向研究的实证证据 

**Authors**: Angel Hsing-Chi Hwang, Fiona Li, Jacy Reese Anthis, Hayoun Noh  

**Link**: [PDF](https://arxiv.org/pdf/2510.10079)  

**Abstract**: The quickly growing popularity of AI companions poses risks to mental health, personal wellbeing, and social relationships. Past work has identified many individual factors that can drive human-companion interaction, but we know little about how these factors interact and evolve over time. In Study 1, we surveyed AI companion users (N = 303) to map the psychological pathway from users' mental models of the agent to parasocial experiences, social interaction, and the psychological impact of AI companions. Participants' responses foregrounded multiple interconnected variables (agency, parasocial interaction, and engagement) that shape AI companionship. In Study 2, we conducted a longitudinal study with a subset of participants (N = 110) using a new generic chatbot. Participants' perceptions of the generic chatbot significantly converged to perceptions of their own companions by Week 3. These results suggest a longitudinal model of AI companionship development and demonstrate an empirical method to study human-AI companionship. 

**Abstract (ZH)**: AI伴侣的迅速流行对心理健康、个人福祉和社会关系构成风险：心理路径研究与纵向发展模型 

---
# Gradient-based Model Shortcut Detection for Time Series Classification 

**Title (ZH)**: 基于梯度的模型捷径检测时间序列分类 

**Authors**: Salomon Ibarra, Frida Cantu, Kaixiong Zhou, Li Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10075)  

**Abstract**: Deep learning models have attracted lots of research attention in time series classification (TSC) task in the past two decades. Recently, deep neural networks (DNN) have surpassed classical distance-based methods and achieved state-of-the-art performance. Despite their promising performance, deep neural networks (DNNs) have been shown to rely on spurious correlations present in the training data, which can hinder generalization. For instance, a model might incorrectly associate the presence of grass with the label ``cat" if the training set have majority of cats lying in grassy backgrounds. However, the shortcut behavior of DNNs in time series remain under-explored. Most existing shortcut work are relying on external attributes such as gender, patients group, instead of focus on the internal bias behavior in time series models.
In this paper, we take the first step to investigate and establish point-based shortcut learning behavior in deep learning time series classification. We further propose a simple detection method based on other class to detect shortcut occurs without relying on test data or clean training classes. We test our proposed method in UCR time series datasets. 

**Abstract (ZH)**: 深度学习模型在时间序列分类任务中吸引了过去二十多年来的大量研究关注。近年来，深度神经网络（DNN）超越了经典的基于距离的方法，并取得了最先进的性能。尽管表现出色，但深度神经网络（DNNs）已被证明依赖于训练数据中存在的虚假关联，这可能阻碍泛化能力。例如，一个模型可能会错误地将草的存在关联到“猫”这个标签，如果训练集中大部分猫都处于草地背景中。然而，时间序列中深度神经网络的捷径行为尚未得到充分探索。现有的大多数捷径工作依赖于外部属性，如性别、患者组，而不是专注于时间序列模型中的内部偏差行为。在本文中，我们首次探索并建立了基于点的时间序列分类深度学习中的捷径学习行为。我们进一步提出了一种基于其他类别的简单检测方法，以无需依赖测试数据或干净的训练类别来检测捷径现象。我们在UCR时间序列数据集上测试了我们提出的检测方法。 

---
# OBsmith: Testing JavaScript Obfuscator using LLM-powered sketching 

**Title (ZH)**: OBsmith：使用LLM驱动草图测试JavaScript混淆器 

**Authors**: Shan Jiang, Chenguang Zhu, Sarfraz Khurshid  

**Link**: [PDF](https://arxiv.org/pdf/2510.10066)  

**Abstract**: JavaScript obfuscators are widely deployed to protect intellectual property and resist reverse engineering, yet their correctness has been largely overlooked compared to performance and resilience. Existing evaluations typically measure resistance to deobfuscation, leaving the critical question of whether obfuscators preserve program semantics unanswered. Incorrect transformations can silently alter functionality, compromise reliability, and erode security-undermining the very purpose of obfuscation. To address this gap, we present OBsmith, a novel framework to systematically test JavaScript obfuscators using large language models (LLMs). OBsmith leverages LLMs to generate program sketches abstract templates capturing diverse language constructs, idioms, and corner cases-which are instantiated into executable programs and subjected to obfuscation under different configurations. Besides LLM-powered sketching, OBsmith also employs a second source: automatic extraction of sketches from real programs. This extraction path enables more focused testing of project specific features and lets developers inject domain knowledge into the resulting test cases. OBsmith uncovers 11 previously unknown correctness bugs. Under an equal program budget, five general purpose state-of-the-art JavaScript fuzzers (FuzzJIT, Jsfunfuzz, Superion, DIE, Fuzzilli) failed to detect these issues, highlighting OBsmith's complementary focus on obfuscation induced misbehavior. An ablation shows that all components except our generic MRs contribute to at least one bug class; the negative MR result suggests the need for obfuscator-specific metamorphic relations. Our results also seed discussion on how to balance obfuscation presets and performance cost. We envision OBsmith as an important step towards automated testing and quality assurance of obfuscators and other semantic-preserving toolchains. 

**Abstract (ZH)**: JavaScript 混淆器的正确性受到了广泛部署以保护知识产权和抵抗逆向工程的关注，但与性能和鲁棒性相比，其正确性已经被很大程度上忽视。现有的评估通常仅衡量其抵抗去混淆的能力，而未能回答一个关键问题：混淆器是否能保持程序语义不变。不正确的变换可能会默默改变功能，损害可靠性，并削弱安全性——这违背了混淆的目的。为了解决这一缺口，我们提出了 OBsmith，一种利用大规模语言模型（LLM）系统性测试 JavaScript 混淆器的新框架。OBsmith 利用 LLM 生成程序草图，即抽象模板，捕获多种语言构造、惯用法和边缘情况，并将这些草图实例化为可执行程序，并在不同配置下进行混淆。除了 LLM 驱动的草图生成，OBsmith 还使用第二个来源：从实际程序自动提取草图。这条提取路径使测试更加集中于特定项目的特性，并允许开发者将领域知识注入测试用例中。OBsmith 暴露了 11 个先前未知的正确性错误。在相同的程序预算下，五种通用最先进的 JavaScript 模糊测试工具（FuzzJIT、Jsfunfuzz、Superion、DIE、Fuzzilli）未能检测到这些问题，突显了 OBsmith 在混淆引发的不正常行为方面互补的关注重点。删除分析表明，除了我们通用的 MR 之外，所有组件至少对一个错误类别有所贡献；负的 MR 结果表明需要针对特定混淆器的形态关系。我们的结果还引发了关于如何平衡混淆预设和性能成本的讨论。我们展望 OBsmith 作为自动测试和验证混淆器及其他语义保留工具链质量保证的重要一步。 

---
# CLMN: Concept based Language Models via Neural Symbolic Reasoning 

**Title (ZH)**: CLMN：基于概念的神经符号推理语言模型 

**Authors**: Yibo Yang  

**Link**: [PDF](https://arxiv.org/pdf/2510.10063)  

**Abstract**: Deep learning has advanced NLP, but interpretability remains limited, especially in healthcare and finance. Concept bottleneck models tie predictions to human concepts in vision, but NLP versions either use binary activations that harm text representations or latent concepts that weaken semantics, and they rarely model dynamic concept interactions such as negation and context. We introduce the Concept Language Model Network (CLMN), a neural-symbolic framework that keeps both performance and interpretability. CLMN represents concepts as continuous, human-readable embeddings and applies fuzzy-logic reasoning to learn adaptive interaction rules that state how concepts affect each other and the final decision. The model augments original text features with concept-aware representations and automatically induces interpretable logic rules. Across multiple datasets and pre-trained language models, CLMN achieves higher accuracy than existing concept-based methods while improving explanation quality. These results show that integrating neural representations with symbolic reasoning in a unified concept space can yield practical, transparent NLP systems. 

**Abstract (ZH)**: 深度学习推动了自然语言处理的发展，但在医疗保健和金融等领域中的可解释性依然有限。视觉领域的概念瓶颈模型能够将预测与人类概念联系起来，但对于自然语言处理版本，要么使用损害文本表示的二值激活函数，要么使用削弱语义的潜在概念，并且它们很少建模如否定和背景这类动态概念交互。我们提出了概念语言模型网络（CLMN），这是一种在保持性能的同时提高可解释性的神经符号框架。CLMN 将概念表示为连续的人类可读嵌入，并应用模糊逻辑推理来学习适应性的交互规则，以阐释概念如何相互影响以及最终决策。该模型通过概念感知表示增强原始文本特征，并自动生成可解释的逻辑规则。在多个数据集和预训练语言模型上，CLMN 较现有的基于概念的方法具有更高的准确率，同时提高了解释质量。这些结果表明，在统一的概念空间中结合神经表示与符号推理可以产生实用且透明的自然语言处理系统。 

---
# Translution: Unifying Self-attention and Convolution for Adaptive and Relative Modeling 

**Title (ZH)**: 统一自注意力与卷积以实现自适应和相对建模 

**Authors**: Hehe Fan, Yi Yang, Mohan Kankanhalli, Fei Wu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10060)  

**Abstract**: When modeling a given type of data, we consider it to involve two key aspects: 1) identifying relevant elements (e.g., image pixels or textual words) to a central element, as in a convolutional receptive field, or to a query element, as in self-attention, and 2) encoding these tokens effectively. Self-attention can adaptively identify these elements but relies on absolute positional embedding for structural representation learning. In contrast, convolution encodes elements in a relative manner, yet their fixed kernel size limits their ability to adaptively select the relevant elements. In this paper, we introduce Translution, an operation that unifies the adaptive identification capability of self-attention and the relative encoding advantage of convolution. However, this integration leads to a substantial increase in the number of parameters, exceeding most currently available computational resources. Therefore, we propose a lightweight variant of Translution, named {\alpha}-Translution. Experiments on computer vision and natural language processing tasks show that Translution (including {\alpha}-Translution) achieves superior accuracy compared to self-attention. The code is available at this https URL. 

**Abstract (ZH)**: 在建模给定类型的数据时，我们认为涉及两个关键方面：1）识别与中心元素或查询元素相关的元素（例如，在卷积感受野中识别图像像素，在自我注意中识别文本单词），2）有效地编码这些标记。自我注意可以自适应地识别这些元素，但依赖绝对位置嵌入进行结构表示学习。相比之下，卷积以相对方式编码元素，但其固定的核尺寸限制了其自适应选择相关元素的能力。在本文中，我们引入了Translution操作，它统一了自我注意的自适应识别能力和卷积的相对编码优势。然而，这种整合导致参数数量显著增加，超过了大多数当前可用的计算资源。因此，我们提出了一种轻量级的Translution变体，命名为{\alpha}-Translution。实验表明，Translution（包括{\alpha}-Translution）在计算机视觉和自然语言处理任务中实现了优于自我注意的准确性。相关代码可以在以下网址获取。 

---
# Think Twice to See More: Iterative Visual Reasoning in Medical VLMs 

**Title (ZH)**: 慎重思考以洞察更多：医疗VLM中的迭代视觉推理 

**Authors**: Kaitao Chen, Shaohao Rui, Yankai Jiang, Jiamin Wu, Qihao Zheng, Chunfeng Song, Xiaosong Wang, Mu Zhou, Mianxin Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10052)  

**Abstract**: Medical vision-language models (VLMs) excel at image-text understanding but typically rely on a single-pass reasoning that neglects localized visual cues. In clinical practice, however, human experts iteratively scan, focus, and refine the regions of interest before reaching a final diagnosis. To narrow this machine-human perception gap, we introduce ViTAR, a novel VLM framework that emulates the iterative reasoning process of human experts through a cognitive chain of "think-act-rethink-answer". ViTAR treats medical images as interactive objects, enabling models to engage multi-step visual reasoning. To support this approach, we curate a high-quality instruction dataset comprising 1K interactive examples that encode expert-like diagnostic behaviors. In addition, a 16K visual question answering training data has been curated towards fine-grained visual diagnosis. We introduce a two-stage training strategy that begins with supervised fine-tuning to guide cognitive trajectories, followed by the reinforcement learning to optimize decision-making. Extensive evaluations demonstrate that ViTAR outperforms strong state-of-the-art models. Visual attention analysis reveals that from the "think" to "rethink" rounds, ViTAR increasingly anchors visual grounding to clinically critical regions and maintains high attention allocation to visual tokens during reasoning, providing mechanistic insight into its improved performance. These findings demonstrate that embedding expert-style iterative thinking chains into VLMs enhances both performance and trustworthiness of medical AI. 

**Abstract (ZH)**: 医学视觉语言模型（VLMs）在图像-文本理解方面表现出色，但通常依赖于忽视局部视觉提示的单次推理。然而，在临床实践中，人类专家会逐步扫描、聚焦并精炼感兴趣区域，最终得出诊断结果。为了缩小机器与人类感知之间的差距，我们提出了ViTAR，这是一种新的VLM框架，通过“思考-行动-再思考-回答”的认知链模拟人类专家的迭代推理过程。ViTAR将医学图像视为可交互的对象，使模型能够进行多步视觉推理。为了支持这一方法，我们构建了一个高质量的指令数据集，包含1000个交互式示例，这些示例编码了专家级的诊断行为。此外，我们还构建了一个16000个视觉问答训练数据集，支持精细视觉诊断。我们提出了一种两阶段训练策略，首先通过监督微调引导认知轨迹，然后通过强化学习优化决策过程。广泛评估表明，ViTAR优于现有的强大模型。视觉注意分析显示，从“思考”到“再思考”阶段，ViTAR逐渐将视觉 grounding 聚焦于临床关键区域，并在推理过程中保持对视觉令牌的高注意分配，提供了其性能改进的机制见解。这些发现表明，将专家级的迭代思维链嵌入VLMs可以提高医学AI的性能和可信度。 

---
# ALLOY: Generating Reusable Agent Workflows from User Demonstration 

**Title (ZH)**: ALLOY: 从用户演示生成可重用的智能体工作流 

**Authors**: Jiawen Li, Zheng Ning, Yuan Tian, Toby Jia-jun Li  

**Link**: [PDF](https://arxiv.org/pdf/2510.10049)  

**Abstract**: Large language models (LLMs) enable end-users to delegate complex tasks to autonomous agents through natural language. However, prompt-based interaction faces critical limitations: Users often struggle to specify procedural requirements for tasks, especially those that don't have a factually correct solution but instead rely on personal preferences, such as posting social media content or planning a trip. Additionally, a ''successful'' prompt for one task may not be reusable or generalizable across similar tasks. We present ALLOY, a system inspired by classical HCI theories on Programming by Demonstration (PBD), but extended to enhance adaptability in creating LLM-based web agents. ALLOY enables users to express procedural preferences through natural demonstrations rather than prompts, while making these procedures transparent and editable through visualized workflows that can be generalized across task variations. In a study with 12 participants, ALLOY's demonstration--based approach outperformed prompt-based agents and manual workflows in capturing user intent and procedural preferences in complex web tasks. Insights from the study also show how demonstration--based interaction complements the traditional prompt-based approach. 

**Abstract (ZH)**: 大型语言模型（LLMs）使得终端用户能够通过自然语言将复杂的任务委托给自主代理。然而，基于提示的交互面临关键限制：用户通常难以 specifying 指出任务的程序化要求，尤其是那些没有事实正确解决方案但依赖个人偏好（如发布社交媒体内容或计划旅行）的任务。此外，对一个任务成功的提示可能不适用于类似任务的再利用或泛化。我们提出了ALLOY系统，该系统借鉴了传统的人机交互（HCI）理论中的示范编程（Programming by Demonstration, PBD）方法，并扩展了在创建基于语言模型的网络代理方面增强适应性的能力。ALLOY使用户能够通过自然示范表达程序化偏好，而不是通过提示，并通过可视化的工作流使这些程序透明且可编辑，这些工作流可以在不同任务变体之间泛化。在一项包含12名参与者的研究中，ALLOY的基于示范的方法在捕捉复杂网络任务中的用户意图和程序化偏好方面优于基于提示的代理和手动工作流。研究还表明，基于示范的交互如何补充传统的基于提示的方法。 

---
# FOSSIL: Regret-Minimizing Curriculum Learning for Metadata-Free and Low-Data Mpox Diagnosis 

**Title (ZH)**: F OSSIL: 基于后悔最小化的 Curriculum 学习方法用于无元数据和少数据猴痘诊断 

**Authors**: Sahng-Min Han, Minjae Kim, Jinho Cha, Se-woon Choe, Eunchan Daniel Cha, Jungwon Choi, Kyudong Jung  

**Link**: [PDF](https://arxiv.org/pdf/2510.10041)  

**Abstract**: Deep learning in small and imbalanced biomedical datasets remains fundamentally constrained by unstable optimization and poor generalization. We present the first biomedical implementation of FOSSIL (Flexible Optimization via Sample-Sensitive Importance Learning), a regret-minimizing weighting framework that adaptively balances training emphasis according to sample difficulty. Using softmax-based uncertainty as a continuous measure of difficulty, we construct a four-stage curriculum (Easy-Very Hard) and integrate FOSSIL into both convolutional and transformer-based architectures for Mpox skin lesion diagnosis. Across all settings, FOSSIL substantially improves discrimination (AUC = 0.9573), calibration (ECE = 0.053), and robustness under real-world perturbations, outperforming conventional baselines without metadata, manual curation, or synthetic augmentation. The results position FOSSIL as a generalizable, data-efficient, and interpretable framework for difficulty-aware learning in medical imaging under data scarcity. 

**Abstract (ZH)**: FOSSIL在生物医学小规模和不平衡数据集中的深度学习应用:一种基于样本敏感重要性学习的后悔最小化加权框架及其在Mpox皮肤病变诊断中的应用 

---
# Efficient Onboard Vision-Language Inference in UAV-Enabled Low-Altitude Economy Networks via LLM-Enhanced Optimization 

**Title (ZH)**: UAV赋能低空经济网络中基于LLM增强优化的高效机载视觉-语言推理 

**Authors**: Yang Li, Ruichen Zhang, Yinqiu Liu, Guangyuan Liu, Dusit Niyato, Abbas Jamalipour, Xianbin Wang, Dong In Kim  

**Link**: [PDF](https://arxiv.org/pdf/2510.10028)  

**Abstract**: The rapid advancement of Low-Altitude Economy Networks (LAENets) has enabled a variety of applications, including aerial surveillance, environmental sensing, and semantic data collection. To support these scenarios, unmanned aerial vehicles (UAVs) equipped with onboard vision-language models (VLMs) offer a promising solution for real-time multimodal inference. However, ensuring both inference accuracy and communication efficiency remains a significant challenge due to limited onboard resources and dynamic network conditions. In this paper, we first propose a UAV-enabled LAENet system model that jointly captures UAV mobility, user-UAV communication, and the onboard visual question answering (VQA) pipeline. Based on this model, we formulate a mixed-integer non-convex optimization problem to minimize task latency and power consumption under user-specific accuracy constraints. To solve the problem, we design a hierarchical optimization framework composed of two parts: (i) an Alternating Resolution and Power Optimization (ARPO) algorithm for resource allocation under accuracy constraints, and (ii) a Large Language Model-augmented Reinforcement Learning Approach (LLaRA) for adaptive UAV trajectory optimization. The large language model (LLM) serves as an expert in refining reward design of reinforcement learning in an offline fashion, introducing no additional latency in real-time decision-making. Numerical results demonstrate the efficacy of our proposed framework in improving inference performance and communication efficiency under dynamic LAENet conditions. 

**Abstract (ZH)**: 低-altitude 经济网络（LAENets）的迅速发展为包括航空监视、环境感知和语义数据收集在内的多种应用提供了支持。为了支持这些场景，搭载机载视觉-语言模型（VLMs）的无人驾驶航空器（UAVs）为实时多模态推理提供了有前景的解决方案。然而，保证推理准确性和通信效率仍然是一项重大挑战，这归因于有限的机载资源和动态网络条件。本文首先提出一个集成了UAV移动性、用户-UAV通信和机载视觉问答（VQA）管道的UAV支持的LAENet系统模型。基于该模型，我们提出了一个混合整数非凸优化问题来在满足用户特定准确性的条件下最小化任务延迟和功率消耗。为了解决该问题，我们设计了一个分层优化框架，包括两个部分：（i）一种在满足准确性的条件下进行资源分配的交替分辨率和功率优化（ARPO）算法，以及（ii）一种增强型强化学习方法（LLaRA）来实现自适应的UAV轨迹优化。大型语言模型（LLM）作为专家，在线离线式优化强化学习的奖励设计，而不增加实时决策的延迟。数值结果表明，该框架在动态LAENet条件下有效提升了推理性能和通信效率。 

---
# Lightweight Baselines for Medical Abstract Classification: DistilBERT with Cross-Entropy as a Strong Default 

**Title (ZH)**: 轻量级医学摘要分类基础模型：基于交叉熵的DistilBERT 

**Authors**: Jiaqi Liu, Lanruo Wang, Su Liu, Xin Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10025)  

**Abstract**: Large language models work well for many NLP tasks, but they are hard to deploy in health settings with strict cost, latency, and privacy limits. We revisit a lightweight recipe for medical abstract classification and ask how far compact encoders can go under a controlled budget. Using the public medical abstracts corpus, we finetune BERT base and DistilBERT with three objectives standard cross-entropy, class weighted cross entropy, and focal loss keeping tokenizer, sequence length, optimizer, and schedule fixed. DistilBERT with plain cross-entropy gives the best balance on the test set while using far fewer parameters than BERT base. We report accuracy, Macro F1, and Weighted F1, release the evaluation code, and include confusion analyses to make error patterns clear. Our results suggest a practical default: start with a compact encoder and cross-entropy, then add calibration and task-specific checks before moving to heavier models. 

**Abstract (ZH)**: 轻量级模型在医疗环境中的NLP任务应用：在严格的成本、延迟和隐私限制下，大规模语言模型表现良好，但在医疗环境中部署仍面临挑战。我们重新审视一种轻量级的医疗摘要分类方法，并在控制预算下探讨紧凑型编码器的极限。利用公开的医疗摘要语料库，我们使用标准交叉熵、类权重交叉熵和焦损函数对BERT基模型和DistilBERT进行微调，保持分词器、序列长度、优化器和调度一致。DistilBERT在标准交叉熵下的表现，在测试集上兼顾准确性和参数效率。我们报告准确率、宏F1和加权F1分数，发布评估代码，并包含混淆矩阵分析以清晰展现错误模式。研究结果建议一种实用的默认方案：使用紧凑型编码器和交叉熵开始，然后添加校准和任务特定检查，再过渡到更重的模型。 

---
# Skill-Targeted Adaptive Training 

**Title (ZH)**: 技能导向的自适应训练 

**Authors**: Yinghui He, Abhishek Panigrahi, Yong Lin, Sanjeev Arora  

**Link**: [PDF](https://arxiv.org/pdf/2510.10023)  

**Abstract**: Language models often show little to no improvement (i.e., "saturation") when trained via vanilla supervised fine-tuning (SFT) on data similar to what they saw in their training set (e.g., MATH). We introduce a new fine-tuning strategy, STAT, to train such a student model by using the metacognition ability of a stronger large language model (LLM) as the teacher. The teacher uses the task dataset to create a list of skills needed for the task, and then labels each data point with its required skills (Didolkar et al., 2024). By monitoring the student's answers, the teacher creates a Missing-Skill-Profile for the student, tracking how often they failed to apply each skill in their responses. We use this idea to build a modified training set in one of two ways. In STAT-Sel, the teacher uses an existing set of training examples but adaptively reweights them according to the Missing-Skill-Profile. In STAT-Syn, the teacher synthesizes additional examples involving missing skills. Across extensive experiments on Llama and Qwen models, our methods yield improvements of up to 7.5% on MATH, whereas SFT provides only limited gains. Furthermore, STAT enhances performance on out-of-distribution benchmarks (e.g., AIME24/25, AMC23, etc.) by an average of 4.6%. Crucially, we find that STAT is complementary to RL via GRPO (Shao et al., 2024): after the model is improved using STAT to address skill gaps, GRPO continues to add further gains. We conclude that skill-targeted adaptive training should broadly improve current training pipelines. Our code is available at: this https URL. 

**Abstract (ZH)**: 一种新的细调策略：通过强大型语言模型的元认知能力提高语言模型在类似训练数据上的表现 

---
# SLEAN: Simple Lightweight Ensemble Analysis Network for Multi-Provider LLM Coordination: Design, Implementation, and Vibe Coding Bug Investigation Case Study 

**Title (ZH)**: SLEAN：简单轻量级ensemble分析网络用于多提供者LLM协同：设计、实现及Vibe Coding Bug案例研究 

**Authors**: Matheus J. T. Vargas  

**Link**: [PDF](https://arxiv.org/pdf/2510.10010)  

**Abstract**: We present SLEAN (Simple Lightweight Ensemble Analysis Network), a deterministic framework for coordinating multiple LLM providers through text-based prompt orchestration. Unlike complex multi-agent systems requiring specialized infrastructure, SLEAN operates as a simple prompt bridge between LLMs using .txt templates, requiring no deep technical knowledge for deployment. The three-phase protocol formed by independent analysis, cross-critique, and arbitration, filters harmful AI-generated code suggestions before production deployment, addressing how AI-assisted debugging increasingly produces modifications that introduce unnecessary complexity, break existing functionality, or address problems. Evaluating 15 software bugs, we analyzed 69 AI-generated fix propositions. SLEAN's filtering accepted 22 fixes (31.9%, 95% CI 20.9-42.9%) while rejecting 47 that would have been harmful if applied verbatim. The arbitration process reduced code change surface by 83-90% relative to raw AI outputs, enforcing minimal causal edits over scope-expanding modifications. Minimal Type 2 inputs proved more efficient than detailed Type 1 inputs, requiring 2.85 versus 3.56 propositions per accepted fix (35.1% versus 28.1% acceptance, about a 20% efficiency gain). Agreement between AI systems showed weak correlation with fix quality: high convergence (at least 80%) occurred in 4 of 15 cases and improved acceptance by only 2.4% points; arbitration appeared only at exactly 10% convergence in 2 of 15 cases, although low convergence alone did not necessitate arbitration. The file-driven, provider-agnostic architecture enables deployment without specialized coding expertise, making it applicable to security auditing, code review, document verification, and other domains requiring reliable multi-provider synthesis with end-to-end auditability. 

**Abstract (ZH)**: SLEAN（简单轻量级ensemble分析网络）：基于文本提示协调多个LLM提供者的确定性框架 

---
# Beyond the limitation of a single query: Train your LLM for query expansion with Reinforcement Learning 

**Title (ZH)**: 超越单一查询的限制：使用强化学习训练你的LLM进行查询扩展 

**Authors**: Shu Zhao, Tan Yu, Anbang Xu  

**Link**: [PDF](https://arxiv.org/pdf/2510.10009)  

**Abstract**: Reasoning-augmented search agents, such as Search-R1, are trained to reason, search, and generate the final answer iteratively. Nevertheless, due to their limited capabilities in reasoning and search, their performance on multi-hop QA benchmarks remains far from satisfactory. To handle complex or compound queries, we train an LLM-based search agent with the native capability of query expansion through reinforcement learning. In each turn, our search agent proposes several query variants, which are searched simultaneously to cover more relevant information. Meanwhile, given limited post-training data and computing resources, it is very challenging for a search agent to master multiple tasks, including query generation, retrieved information understanding, and answer generation. Therefore, we propose incorporating a pre-trained squeezer model that helps the search agent understand the retrieved documents, allowing the search agent to focus on query generation for high retrieval recall. With the assistance of the squeezer model, we discover that even a small-scale 3B LLM can demonstrate a strong capability of query expansion and achieve state-of-the-art accuracy on the multi-hop QA benchmarks. To be specific, our experiments across seven question-answering benchmarks demonstrate that our method, named ExpandSearch, achieves an average improvement of 4.4% compared to state-of-the-art baselines, with strong gains on multi-hop reasoning tasks requiring diverse evidence aggregation. 

**Abstract (ZH)**: 基于预训练压榨模型的增强查询扩展搜索代理 

---
# Neuro-inspired automated lens design 

**Title (ZH)**: 神经启发的自动透镜设计 

**Authors**: Yao Gao, Lei Sun, Shaohua Gao, Qi Jiang, Kailun Yang, Weijian Hu, Xiaolong Qian, Wenyong Li, Luc Van Gool, Kaiwei Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09979)  

**Abstract**: The highly non-convex optimization landscape of modern lens design necessitates extensive human expertise, resulting in inefficiency and constrained design diversity. While automated methods are desirable, existing approaches remain limited to simple tasks or produce complex lenses with suboptimal image quality. Drawing inspiration from the synaptic pruning mechanism in mammalian neural development, this study proposes OptiNeuro--a novel automated lens design framework that first generates diverse initial structures and then progressively eliminates low-performance lenses while refining remaining candidates through gradient-based optimization. By fully automating the design of complex aspheric imaging lenses, OptiNeuro demonstrates quasi-human-level performance, identifying multiple viable candidates with minimal human intervention. This advancement not only enhances the automation level and efficiency of lens design but also facilitates the exploration of previously uncharted lens architectures. 

**Abstract (ZH)**: 现代透镜设计高度非凸优化景观需要大量的专家知识，导致设计效率低下和设计多样性受限。虽然自动化方法是理想的，但现有方法仍局限于简单任务或产生具有次优成像质量的复杂透镜。受哺乳动物神经发育中突触修剪机制的启发，本研究提出了OptiNeuro——一种新颖的自动化透镜设计框架，该框架首先生成多样化初始结构，然后通过基于梯度的优化逐步淘汰低性能透镜并精炼剩余候选透镜。通过完全自动化复杂非球面成像透镜的设计，OptiNeuro展示了接近人类水平的表现，极少的人为干预即可识别出多个可行候选透镜。这一进展不仅提高了透镜设计的自动化程度和效率，还促进了对未探索透镜架构的探索。 

---
# Operationalizing AI: Empirical Evidence on MLOps Practices, User Satisfaction, and Organizational Context 

**Title (ZH)**: 将AI应用于实践：MLOps实践、用户满意度及组织背景的实证研究 

**Authors**: Stefan Pasch  

**Link**: [PDF](https://arxiv.org/pdf/2510.09968)  

**Abstract**: Organizational efforts to utilize and operationalize artificial intelligence (AI) are often accompanied by substantial challenges, including scalability, maintenance, and coordination across teams. In response, the concept of Machine Learning Operations (MLOps) has emerged as a set of best practices that integrate software engineering principles with the unique demands of managing the ML lifecycle. Yet, empirical evidence on whether and how these practices support users in developing and operationalizing AI applications remains limited. To address this gap, this study analyzes over 8,000 user reviews of AI development platforms from this http URL. Using zero-shot classification, we measure review sentiment toward nine established MLOps practices, including continuous integration and delivery (CI/CD), workflow orchestration, reproducibility, versioning, collaboration, and monitoring. Seven of the nine practices show a significant positive relationship with user satisfaction, suggesting that effective MLOps implementation contributes tangible value to AI development. However, organizational context also matters: reviewers from small firms discuss certain MLOps practices less frequently, suggesting that organizational context influences the prevalence and salience of MLOps, though firm size does not moderate the MLOps-satisfaction link. This indicates that once applied, MLOps practices are perceived as universally beneficial across organizational settings. 

**Abstract (ZH)**: 组织利用和实施人工智能（AI）的努力通常伴随着可扩展性、维护和团队间协调等方面的显著挑战。为此，Machine Learning Operations (MLOps) 的概念作为一套最佳实践逐渐形成，它结合了软件工程原则以适应管理机器学习生命周期的独特需求。然而，关于这些实践如何支持用户开发和实施AI应用程序的实证证据仍有限。为填补这一空白，本研究分析了来自此链接的超过8,000条AI开发平台用户评论。利用零样本分类，我们衡量了用户对九项公认MLOps实践的评价，包括持续集成和交付（CI/CD）、工作流编排、可再现性、版本控制、协作和监控。在这九项实践中，有七项显示出与用户满意度之间存在显著正相关关系，表明有效的MLOps实践为AI开发带来了实际价值。然而，组织背景也非常重要：小型企业的评论者讨论某些MLOps实践的频率较低，表明组织背景影响MLOps的普及度和显着性，尽管公司规模并未影响MLOps-满意度之间的联系。这表明一旦实施，MLOps实践在各类组织环境中被视为普遍有益。 

---
# Homomorphic Mappings for Value-Preserving State Aggregation in Markov Decision Processes 

**Title (ZH)**: 同态映射在马尔可夫决策过程中的值保持状态聚合 

**Authors**: Shuo Zhao, Yongqiang Li, Yu Feng, Zhongsheng Hou, Yuanjing Feng  

**Link**: [PDF](https://arxiv.org/pdf/2510.09965)  

**Abstract**: State aggregation aims to reduce the computational complexity of solving Markov Decision Processes (MDPs) while preserving the performance of the original system. A fundamental challenge lies in optimizing policies within the aggregated, or abstract, space such that the performance remains optimal in the ground MDP-a property referred to as {"}optimal policy equivalence {"}.
This paper presents an abstraction framework based on the notion of homomorphism, in which two Markov chains are deemed homomorphic if their value functions exhibit a linear relationship. Within this theoretical framework, we establish a sufficient condition for the equivalence of optimal policy.
We further examine scenarios where the sufficient condition is not met and derive an upper bound on the approximation error and a performance lower bound for the objective function under the ground MDP. We propose Homomorphic Policy Gradient (HPG), which guarantees optimal policy equivalence under sufficient conditions, and its extension, Error-Bounded HPG (EBHPG), which balances computational efficiency and the performance loss induced by aggregation. In the experiments, we validated the theoretical results and conducted comparative evaluations against seven algorithms. 

**Abstract (ZH)**: 状态聚类旨在通过在聚合或抽象空间中优化策略来降低求解马尔可夫决策过程（MDPs）的计算复杂性，同时保持原系统的表现。一个基本挑战是在聚合空间中优化策略，使得在地面MDP中的性能保持最优——这一性质称为“最优策略等效性”。

本文基于同态的概念提出了一种抽象框架，如果两个马尔可夫链的价值函数之间存在线性关系，则认为这两个马尔可夫链是同态的。在此理论框架下，我们建立了最优策略等效性的充分条件。进一步研究了充分条件不满足的情况，并推导出在地面MDP下的近似误差上界和目标函数的性能下界。我们提出了同态策略梯度（HPG），在满足某些条件下保证最优策略等效性，并提出了错误边界同态策略梯度（EBHPG）以平衡聚类带来的计算效率损失和性能损失。在实验中，我们验证了理论结果，并与七种算法进行了对比评估。 

---
# Beyond Fertility: Analyzing STRR as a Metric for Multilingual Tokenization Evaluation 

**Title (ZH)**: 超越生育率：将STRR作为多语言分词评估指标的分析 

**Authors**: Mir Tafseer Nayeem, Sawsan Alqahtani, Md Tahmid Rahman Laskar, Tasnim Mohiuddin, M Saiful Bari  

**Link**: [PDF](https://arxiv.org/pdf/2510.09947)  

**Abstract**: Tokenization is a crucial but under-evaluated step in large language models (LLMs). The standard metric, fertility (the average number of tokens per word), captures compression efficiency but obscures how vocabularies are allocated across languages and domains. We analyze six widely used tokenizers across seven languages and two domains, finding stable fertility for English, high fertility for Chinese, and little domain sensitivity. To address fertility's blind spots, we propose the Single Token Retention Rate (STRR), which measures the proportion of words preserved as single tokens. STRR reveals systematic prioritization of English, strong support for Chinese, and fragmentation in Hindi, offering an interpretable view of cross-lingual fairness. Our results show that STRR complements fertility and provides practical guidance for designing more equitable multilingual tokenizers. 

**Abstract (ZH)**: Tokenization在大型语言模型中的关键但未充分评估的步骤：单-token保留率（STRR）提供可解释的跨语言公平性视角 

---
# Explainable Human-in-the-Loop Segmentation via Critic Feedback Signals 

**Title (ZH)**: 可解释的人机环分割通过评论反馈信号 

**Authors**: Pouya Shaeri, Ryan T. Woo, Yasaman Mohammadpour, Ariane Middel  

**Link**: [PDF](https://arxiv.org/pdf/2510.09945)  

**Abstract**: Segmentation models achieve high accuracy on benchmarks but often fail in real-world domains by relying on spurious correlations instead of true object boundaries. We propose a human-in-the-loop interactive framework that enables interventional learning through targeted human corrections of segmentation outputs. Our approach treats human corrections as interventional signals that show when reliance on superficial features (e.g., color or texture) is inappropriate. The system learns from these interventions by propagating correction-informed edits across visually similar images, effectively steering the model toward robust, semantically meaningful features rather than dataset-specific artifacts. Unlike traditional annotation approaches that simply provide more training data, our method explicitly identifies when and why the model fails and then systematically corrects these failure modes across the entire dataset. Through iterative human feedback, the system develops increasingly robust representations that generalize better to novel domains and resist artifactual correlations. We demonstrate that our framework improves segmentation accuracy by up to 9 mIoU points (12-15\% relative improvement) on challenging cubemap data and yields 3-4$\times$ reductions in annotation effort compared to standard retraining, while maintaining competitive performance on benchmark datasets. This work provides a practical framework for researchers and practitioners seeking to build segmentation systems that are accurate, robust to dataset biases, data-efficient, and adaptable to real-world domains such as urban climate monitoring and autonomous driving. 

**Abstract (ZH)**: 基于人类循环交互的干预学习框架：提高分割模型的准确性和鲁棒性 

---
# Conformal Sparsification for Bandwidth-Efficient Edge-Cloud Speculative Decoding 

**Title (ZH)**: 带宽高效边缘-云推测解码的齐性稀疏化 

**Authors**: Payel Bhattacharjee, Fengwei Tian, Meiyu Zhong, Guangyi Zhang, Osvaldo Simeone, Ravi Tandon  

**Link**: [PDF](https://arxiv.org/pdf/2510.09942)  

**Abstract**: Edge-cloud speculative decoding (SD) accelerates inference by having a cloud-based large language model (LLM) that verifies draft tokens generated by a resource-constrained small language model (SLM) at the edge. A central bottleneck is the limited bandwidth of the edge-cloud link, which necessitates efficient compression of draft token distributions. We first derive an information-theoretic bound that decomposes the token rejection rate into contributions from SLM-LLM distribution mismatch and from quantization distortion. Guided by this analysis, we propose the Sparse Quantize-and-Sample SD (SQS-SD) framework, which exploits distributional sparsity through structured sparsification and lattice-based quantization. Within this framework, K-SQS applies fixed top-K truncation, while C-SQS adaptively adjusts the retained token set via online conformal prediction to ensure bounded deviation from the dense distribution. Empirical results confirm that both approaches improve end-to-end latency and rejection rates in complimentary operating regimes. 

**Abstract (ZH)**: 边缘-云计算猜测解码（SD）通过让基于云的大语言模型（LLM）验证边缘受限资源小语言模型（SLM）生成的草稿令牌来加速推理。主要瓶颈是边缘-云链路的有限带宽，这要求高效压缩草稿令牌分布。我们首先推导出一个信息论上限，将令牌拒绝率分解为SLM-LLM分布不匹配和量化失真两部分的贡献。在此分析指导下，我们提出了稀疏量化和采样猜测解码（SQS-SD）框架，该框架通过结构化稀疏化和基于格的量化利用分布稀疏性。在此框架中，K-SQS 使用固定的前 K 项截断，而 C-SQS 通过在线魁奈预测自适应调整保留的令牌集，以确保与密集分布的有界偏差。实验结果表明，这两种方法在互补的操作模式下均能改善端到端延迟和拒绝率。 

---
# Unpacking Hateful Memes: Presupposed Context and False Claims 

**Title (ZH)**: 拆解仇恨梗：预设背景与虚假声称 

**Authors**: Weibin Cai, Jiayu Li, Reza Zafarani  

**Link**: [PDF](https://arxiv.org/pdf/2510.09935)  

**Abstract**: While memes are often humorous, they are frequently used to disseminate hate, causing serious harm to individuals and society. Current approaches to hateful meme detection mainly rely on pre-trained language models. However, less focus has been dedicated to \textit{what make a meme hateful}. Drawing on insights from philosophy and psychology, we argue that hateful memes are characterized by two essential features: a \textbf{presupposed context} and the expression of \textbf{false claims}. To capture presupposed context, we develop \textbf{PCM} for modeling contextual information across modalities. To detect false claims, we introduce the \textbf{FACT} module, which integrates external knowledge and harnesses cross-modal reference graphs. By combining PCM and FACT, we introduce \textbf{\textsf{SHIELD}}, a hateful meme detection framework designed to capture the fundamental nature of hate. Extensive experiments show that SHIELD outperforms state-of-the-art methods across datasets and metrics, while demonstrating versatility on other tasks, such as fake news detection. 

**Abstract (ZH)**: 尽管网络 meme 往往具有幽默性，但它们常被用来传播仇恨内容，对个人和社会造成严重伤害。当前的仇恨 meme 检测方法主要依赖预训练语言模型。然而，较少关注什么是使 meme 具有仇恨性质。借鉴哲学和心理学的洞见，我们认为仇恨 meme 具有两个本质特征：预设情境和表达虚假声明。为了捕捉预设情境，我们开发了 PCM 以跨模态建模上下文信息。为了检测虚假声明，我们引入了 FACT 模块，该模块结合外部知识并利用跨模态参考图。通过结合 PCM 和 FACT，我们提出了 SHIELD 框架，旨在捕捉仇恨的本质。广泛实验表明，SHIELD 在多个数据集和指标上超越了现有方法，并在其他任务，如假新闻检测方面展示了适应性。 

---
# Denoising Diffusion as a New Framework for Underwater Images 

**Title (ZH)**: 去噪扩散作为一种新的水下图像处理框架 

**Authors**: Nilesh Jain, Elie Alhajjar  

**Link**: [PDF](https://arxiv.org/pdf/2510.09934)  

**Abstract**: Underwater images play a crucial role in ocean research and marine environmental monitoring since they provide quality information about the ecosystem. However, the complex and remote nature of the environment results in poor image quality with issues such as low visibility, blurry textures, color distortion, and noise. In recent years, research in image enhancement has proven to be effective but also presents its own limitations, like poor generalization and heavy reliance on clean datasets. One of the challenges herein is the lack of diversity and the low quality of images included in these datasets. Also, most existing datasets consist only of monocular images, a fact that limits the representation of different lighting conditions and angles. In this paper, we propose a new plan of action to overcome these limitations. On one hand, we call for expanding the datasets using a denoising diffusion model to include a variety of image types such as stereo, wide-angled, macro, and close-up images. On the other hand, we recommend enhancing the images using Controlnet to evaluate and increase the quality of the corresponding datasets, and hence improve the study of the marine ecosystem.
Tags - Underwater Images, Denoising Diffusion, Marine ecosystem, Controlnet 

**Abstract (ZH)**: underwater图像在海洋研究和marine环境监测中发挥着关键作用，因为它们提供了关于生态系统质量信息。然而，环境的复杂性和遥远性导致图像质量较差，存在低清晰度、纹理模糊、颜色失真和噪声等问题。近年来，图像增强研究证明是有效的，但也存在自身的局限性，如泛化能力差和对干净数据集的高依赖性。其中一项挑战是在这些数据集中缺乏多样性和低质量图像。此外，大多数现有数据集仅包含单目图像，这限制了不同光照条件和角度的代表性。在本文中，我们提出了一种新的计划来克服这些局限性。一方面，我们呼吁使用去噪扩散模型扩展数据集，包括立体、广角、宏观和特写图像等各种图像类型。另一方面，我们建议使用Controlnet来评估并提高相应的数据集质量，从而改善对marine生态系统的研究。 

---
# MemPromptTSS: Persistent Prompt Memory for Iterative Multi-Granularity Time Series State Segmentation 

**Title (ZH)**: MemPromptTSS: 坚持式提示记忆在迭代多粒度时间序列状态分割中的应用 

**Authors**: Ching Chang, Ming-Chih Lo, Chiao-Tung Chan, Wen-Chih Peng, Tien-Fu Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.09930)  

**Abstract**: Web platforms, mobile applications, and connected sensing systems generate multivariate time series with states at multiple levels of granularity, from coarse regimes to fine-grained events. Effective segmentation in these settings requires integrating across granularities while supporting iterative refinement through sparse prompt signals, which provide a compact mechanism for injecting domain knowledge. Yet existing prompting approaches for time series segmentation operate only within local contexts, so the effect of a prompt quickly fades and cannot guide predictions across the entire sequence. To overcome this limitation, we propose MemPromptTSS, a framework for iterative multi-granularity segmentation that introduces persistent prompt memory. A memory encoder transforms prompts and their surrounding subsequences into memory tokens stored in a bank. This persistent memory enables each new prediction to condition not only on local cues but also on all prompts accumulated across iterations, ensuring their influence persists across the entire sequence. Experiments on six datasets covering wearable sensing and industrial monitoring show that MemPromptTSS achieves 23% and 85% accuracy improvements over the best baseline in single- and multi-granularity segmentation under single iteration inference, and provides stronger refinement in iterative inference with average per-iteration gains of 2.66 percentage points compared to 1.19 for PromptTSS. These results highlight the importance of persistent memory for prompt-guided segmentation, establishing MemPromptTSS as a practical and effective framework for real-world applications. 

**Abstract (ZH)**: 基于持久提示记忆的迭代多粒度时间序列分段框架 

---
# Phase-Aware Deep Learning with Complex-Valued CNNs for Audio Signal Applications 

**Title (ZH)**: 基于复值卷积神经网络的相位感知深度学习在音频信号应用中 

**Authors**: Naman Agrawal  

**Link**: [PDF](https://arxiv.org/pdf/2510.09926)  

**Abstract**: This study explores the design and application of Complex-Valued Convolutional Neural Networks (CVCNNs) in audio signal processing, with a focus on preserving and utilizing phase information often neglected in real-valued networks. We begin by presenting the foundational theoretical concepts of CVCNNs, including complex convolutions, pooling layers, Wirtinger-based differentiation, and various complex-valued activation functions. These are complemented by critical adaptations of training techniques, including complex batch normalization and weight initialization schemes, to ensure stability in training dynamics. Empirical evaluations are conducted across three stages. First, CVCNNs are benchmarked on standard image datasets, where they demonstrate competitive performance with real-valued CNNs, even under synthetic complex perturbations. Although our focus is audio signal processing, we first evaluate CVCNNs on image datasets to establish baseline performance and validate training stability before applying them to audio tasks. In the second experiment, we focus on audio classification using Mel-Frequency Cepstral Coefficients (MFCCs). CVCNNs trained on real-valued MFCCs slightly outperform real CNNs, while preserving phase in input workflows highlights challenges in exploiting phase without architectural modifications. Finally, a third experiment introduces GNNs to model phase information via edge weighting, where the inclusion of phase yields measurable gains in both binary and multi-class genre classification. These results underscore the expressive capacity of complex-valued architectures and confirm phase as a meaningful and exploitable feature in audio processing applications. While current methods show promise, especially with activations like cardioid, future advances in phase-aware design will be essential to leverage the potential of complex representations in neural networks. 

**Abstract (ZH)**: 复杂值卷积神经网络在音频信号处理中的设计与应用：保留和利用常被忽略的相位信息 

---
# Augmenting generative models with biomedical knowledge graphs improves targeted drug discovery 

**Title (ZH)**: 将生物医学知识图谱融入生成模型以改善靶向药物发现 

**Authors**: Aditya Malusare, Vineet Punyamoorty, Vaneet Aggarwal  

**Link**: [PDF](https://arxiv.org/pdf/2510.09914)  

**Abstract**: Recent breakthroughs in generative modeling have demonstrated remarkable capabilities in molecular generation, yet the integration of comprehensive biomedical knowledge into these models has remained an untapped frontier. In this study, we introduce K-DREAM (Knowledge-Driven Embedding-Augmented Model), a novel framework that leverages knowledge graphs to augment diffusion-based generative models for drug discovery. By embedding structured information from large-scale knowledge graphs, K-DREAM directs molecular generation toward candidates with higher biological relevance and therapeutic suitability. This integration ensures that the generated molecules are aligned with specific therapeutic targets, moving beyond traditional heuristic-driven approaches. In targeted drug design tasks, K-DREAM generates drug candidates with improved binding affinities and predicted efficacy, surpassing current state-of-the-art generative models. It also demonstrates flexibility by producing molecules designed for multiple targets, enabling applications to complex disease mechanisms. These results highlight the utility of knowledge-enhanced generative models in rational drug design and their relevance to practical therapeutic development. 

**Abstract (ZH)**: 知识驱动的嵌入增强模型K-DREAM在基于扩散的生成模型中整合大规模生物医药知识用于药物发现 

---
# SpectralCA: Bi-Directional Cross-Attention for Next-Generation UAV Hyperspectral Vision 

**Title (ZH)**: SpectralCA: 双向交叉注意力机制用于下一代无人机 hyperspectral 视觉 

**Authors**: D.V. Brovko  

**Link**: [PDF](https://arxiv.org/pdf/2510.09912)  

**Abstract**: The relevance of this research lies in the growing demand for unmanned aerial vehicles (UAVs) capable of operating reliably in complex environments where conventional navigation becomes unreliable due to interference, poor visibility, or camouflage. Hyperspectral imaging (HSI) provides unique opportunities for UAV-based computer vision by enabling fine-grained material recognition and object differentiation, which are critical for navigation, surveillance, agriculture, and environmental monitoring. The aim of this work is to develop a deep learning architecture integrating HSI into UAV perception for navigation, object detection, and terrain classification. Objectives include: reviewing existing HSI methods, designing a hybrid 2D/3D convolutional architecture with spectral-spatial cross-attention, training, and benchmarking. The methodology is based on the modification of the Mobile 3D Vision Transformer (MDvT) by introducing the proposed SpectralCA block. This block employs bi-directional cross-attention to fuse spectral and spatial features, enhancing accuracy while reducing parameters and inference time. Experimental evaluation was conducted on the WHU-Hi-HongHu dataset, with results assessed using Overall Accuracy, Average Accuracy, and the Kappa coefficient. The findings confirm that the proposed architecture improves UAV perception efficiency, enabling real-time operation for navigation, object recognition, and environmental monitoring tasks.
Keywords: SpectralCA, deep learning, computer vision, hyperspectral imaging, unmanned aerial vehicle, object detection, semi-supervised learning. 

**Abstract (ZH)**: 基于航摄高光谱成像的无人机导航与目标检测深度学习架构研究 

---
# Agentic Property-Based Testing: Finding Bugs Across the Python Ecosystem 

**Title (ZH)**: 基于代理属性的测试：跨越Python生态系统寻找 bug 

**Authors**: Muhammad Maaz, Liam DeVoe, Zac Hatfield-Dodds, Nicholas Carlini  

**Link**: [PDF](https://arxiv.org/pdf/2510.09907)  

**Abstract**: Property-based testing (PBT) is a lightweight formal method, typically implemented as a randomized testing framework. Users specify the input domain for their test using combinators supplied by the PBT framework, and the expected properties or invariants as a unit-test function. The framework then searches for a counterexample, e.g. by generating inputs and calling the test function. In this work, we demonstrate an LLM-based agent which analyzes Python modules, infers function-specific and cross-function properties from code and documentation, synthesizes and executes PBTs, reflects on outputs of these tests to confirm true bugs, and finally outputs actionable bug reports for the developer. We perform an extensive evaluation of our agent across 100 popular Python packages. Of the bug reports generated by the agent, we found after manual review that 56\% were valid bugs and 32\% were valid bugs that we would report to maintainers. We then developed a ranking rubric to surface high-priority valid bugs to developers, and found that of the 21 top-scoring bugs, 86\% were valid and 81\% we would report. The bugs span diverse failure modes from serialization failures to numerical precision errors to flawed cache implementations. We reported 5 bugs, 4 with patches, including to NumPy and cloud computing SDKs, with 3 patches merged successfully. Our results suggest that LLMs with PBT provides a rigorous and scalable method for autonomously testing software. Our code and artifacts are available at: this https URL. 

**Abstract (ZH)**: 基于属性的测试（PBT）的LLM代理：从Python模块中自动推导和执行属性测试以检测有效 Bug 

---
# Stability of Transformers under Layer Normalization 

**Title (ZH)**: Transformer层归一化下的稳定性 

**Authors**: Kelvin Kan, Xingjian Li, Benjamin J. Zhang, Tuhin Sahai, Stanley Osher, Krishna Kumar, Markos A. Katsoulakis  

**Link**: [PDF](https://arxiv.org/pdf/2510.09904)  

**Abstract**: Despite their widespread use, training deep Transformers can be unstable. Layer normalization, a standard component, improves training stability, but its placement has often been ad-hoc. In this paper, we conduct a principled study on the forward (hidden states) and backward (gradient) stability of Transformers under different layer normalization placements. Our theory provides key insights into the training dynamics: whether training drives Transformers toward regular solutions or pathological behaviors. For forward stability, we derive explicit bounds on the growth of hidden states in trained Transformers. For backward stability, we analyze how layer normalization affects the backpropagation of gradients, thereby explaining the training dynamics of each layer normalization placement. Our analysis also guides the scaling of residual steps in Transformer blocks, where appropriate choices can further improve stability and performance. Our numerical results corroborate our theoretical findings. Beyond these results, our framework provides a principled way to sanity-check the stability of Transformers under new architectural modifications, offering guidance for future designs. 

**Abstract (ZH)**: 尽管深度Transformer在广泛应用，但其训练可能会不稳定。层规范化作为标准组件可以提高训练稳定性，但其放置方式往往缺乏系统性。本文系统研究了在不同层规范化放置情况下，Transformer的前向（隐藏状态）和后向（梯度）稳定性。我们的理论提供了关键见解，探讨了训练动力学：训练是否会引导Transformer趋向于良态解或病理行为。对于前向稳定性，我们推导了训练中隐藏状态增长的显式边界。对于后向稳定性，我们分析了层规范化如何影响梯度的反向传播，从而解释了每种层规范化放置下的训练动力学。我们的分析还指导了Transformer块中残差步骤的缩放，恰当的选择可以进一步提高稳定性和性能。我们的数值结果印证了理论发现。此外，我们的框架提供了一种系统的方法来验证新架构修改下Transformer的稳定性，为未来的设计提供指导。 

---
# Learning Bug Context for PyTorch-to-JAX Translation with LLMs 

**Title (ZH)**: 使用大规模语言模型学习PyTorch到JAX的转换上下文 Bug 

**Authors**: Hung Phan, Son Le Vu, Ali Jannesari  

**Link**: [PDF](https://arxiv.org/pdf/2510.09898)  

**Abstract**: Despite recent progress of large language models (LLMs) on code translation among mainstream languages, translating PyTorch to JAX remains nontrivial. The two libraries, though both embedded in Python, differ in core design, execution semantics, and ecosystem maturity; JAX is newer and comparatively underrepresented in public code, and parallel PyTorch--JAX corpora are limited. Weaknesses in existing evaluation further complicate cross-framework benchmarking. We present T2J, a prompt-augmentation framework that strengthens LLM-based PyTorch to JAX translation. Our pipeline (i) assembles two PyTorch sources -- the problem-solving set from TorchLeet (Aroori & Chien, 2025) and a GitHub-derived set from CodeParrot (Wolf et al., 2022) -- and uses GPT-4o-mini to produce initial JAX drafts; (ii) engages two professional developers to iteratively repair those drafts until functional equivalence, yielding a curated fixed-bug dataset of common errors and patches; and (iii) constructs augmented prompts that inject structured guidance from these fixes to steer lightweight LLMs (e.g., GPT-4o-mini). We also introduce three metrics tailored to PyTorch to JAX: T2J CodeTrans Score, T2J FixCost Score (an LLM-based estimate of bug-fix effort), and T2J Comparison Score (LLM-as-judge). Empirically, T2J raises GPT-4o-mini performance by up to 10% on CodeBLEU, 50% on T2J FixCost Score, 1.33 points on T2J CodeTrans Score (0--4 scale), and 100% on T2J Comparison Score; moreover, the generated code runs up to 2.5x faster than the baseline. 

**Abstract (ZH)**: 尽管大型语言模型（LLMs）在主流编程语言之间的代码翻译方面取得了进展，但将PyTorch翻译为JAX仍具有挑战性。尽管这两个库都嵌入在Python中，但它们在核心设计、执行语义和生态系统成熟度方面存在差异；JAX较新且在公共代码中相对较少见，且PyTorch与JAX的平行语料库有限。现有评估的不足进一步复杂化了跨框架基准测试。我们提出T2J，一种增强框架，旨在加强基于LLM的PyTorch到JAX的翻译。我们的流水线包括：（i）组装两个PyTorch源代码——来自TorchLeet的问题解决集（Aroori & Chien, 2025）和来自CodeParrot的GitHub衍生集（Wolf et al., 2022），并使用GPT-4o-mini生成初始JAX草稿；（ii）让两名专业开发人员迭代修复这些草稿，直至功能等效，从而生成一个修复常见错误和补丁的精选数据集；（iii）构建增强提示，这些提示注入这些修复的结构化指导，以引导轻量级LLM（例如，GPT-4o-mini）。我们还介绍了针对PyTorch到JAX的三种度量标准：T2J CodeTrans得分、T2J FixCost得分（基于LLM的错误修复努力估计）和T2J Comparison得分（LLM作为评判者）。实验结果显示，T2J在CodeBLEU上提高了GPT-4o-mini的性能多达10%，在T2J FixCost得分上提高了50%，在T2J CodeTrans得分上提高了1.33分（0-4分制），并在T2J Comparison得分上提高了100%；此外，生成的代码比基线快2.5倍。 

---
# Chain-of-Influence: Tracing Interdependencies Across Time and Features in Clinical Predictive Modelings 

**Title (ZH)**: 连锁影响：跨时间和特征追溯临床预测建模中的相互依赖关系 

**Authors**: Yubo Li, Rema Padman  

**Link**: [PDF](https://arxiv.org/pdf/2510.09895)  

**Abstract**: Modeling clinical time-series data is hampered by the challenge of capturing latent, time-varying dependencies among features. State-of-the-art approaches often rely on black-box mechanisms or simple aggregation, failing to explicitly model how the influence of one clinical variable propagates through others over time. We propose $\textbf{Chain-of-Influence (CoI)}$, an interpretable deep learning framework that constructs an explicit, time-unfolded graph of feature interactions. CoI leverages a multi-level attention architecture: first, a temporal attention layer identifies critical time points in a patient's record; second, a cross-feature attention layer models the directed influence from features at these time points to subsequent features. This design enables the tracing of influence pathways, providing a granular audit trail that shows how any feature at any time contributes to the final prediction, both directly and through its influence on other variables. We evaluate CoI on mortality and disease progression tasks using the MIMIC-IV dataset and a private chronic kidney disease cohort. Our framework significantly outperforms existing methods in predictive accuracy. More importantly, through case studies, we show that CoI can uncover clinically meaningful, patient-specific patterns of disease progression that are opaque to other models, offering unprecedented transparency into the temporal and cross-feature dependencies that inform clinical decision-making. 

**Abstract (ZH)**: Chain-of-Influence (CoI): An Interpretable Deep Learning Framework for Modeling Clinical Time-Series Data 

---
# Probabilistic bias adjustment of seasonal predictions of Arctic Sea Ice Concentration 

**Title (ZH)**: 基于概率偏差调整的 Arctic 海冰浓度季节预测校正 

**Authors**: Parsa Gooya, Reinel Sospedra-Alfonso  

**Link**: [PDF](https://arxiv.org/pdf/2510.09891)  

**Abstract**: Seasonal forecast of Arctic sea ice concentration is key to mitigate the negative impact and assess potential opportunities posed by the rapid decline of sea ice coverage. Seasonal prediction systems based on climate models often show systematic biases and complex spatio-temporal errors that grow with the forecasts. Consequently, operational predictions are routinely bias corrected and calibrated using retrospective forecasts. For predictions of Arctic sea ice concentration, error corrections are mainly based on one-to-one post-processing methods including climatological mean or linear regression correction and, more recently, machine learning. Such deterministic adjustments are confined at best to the limited number of costly-to-run ensemble members of the raw forecast. However, decision-making requires proper quantification of uncertainty and likelihood of events, particularly of extremes. We introduce a probabilistic error correction framework based on a conditional Variational Autoencoder model to map the conditional distribution of observations given the biased model prediction. This method naturally allows for generating large ensembles of adjusted forecasts. We evaluate our model using deterministic and probabilistic metrics and show that the adjusted forecasts are better calibrated, closer to the observational distribution, and have smaller errors than climatological mean adjusted forecasts. 

**Abstract (ZH)**: 北极海冰浓度的季节预测对于减轻海冰覆盖快速下降带来的负面影响并评估潜在机会至关重要。基于气候模型的季节预测系统经常显示出系统偏差和复杂的时空误差，这些误差随预测时间的延长而增大。因此，运营预测通常会使用回顾性预测进行偏差校正和校准。对于北极海冰浓度的预测，误差校正主要基于一对一后处理方法，包括气候平均值校正或线性回归校正，近年来还包括机器学习方法。这些确定性调整仅局限于昂贵的原始预报 ensemble 成员数量。然而，决策需要对不确定性及其事件的可能性进行适当的量化，尤其是极端事件。我们提出了一种基于条件变分自编码器模型的概率误差校正框架，以映射给定偏差模型预测的观测条件分布。该方法自然地能够生成大量的校正预测 ensemble。我们使用确定性和概率性指标评估了我们的模型，并证明了校正预测在校准性、与观测分布的接近度以及误差方面优于气候平均值校正预测。 

---
# Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs 

**Title (ZH)**: 关闭自回归和掩蔽扩散语言模型之间的数据效率差距 

**Authors**: Xu Pan, Ely Hahami, Jingxuan Fan, Ziqian Xie, Haim Sompolinsky  

**Link**: [PDF](https://arxiv.org/pdf/2510.09885)  

**Abstract**: Despite autoregressive large language models (arLLMs) being the current dominant paradigm in language modeling, they resist knowledge injection via fine-tuning due to inherent shortcomings such as the "reversal curse" -- the challenge of answering questions that reverse the original information order in the training sample. Masked diffusion large language models (dLLMs) are rapidly emerging as a powerful alternative to the arLLM paradigm, with evidence of better data efficiency and free of the "reversal curse" in pre-training. However, it is unknown whether these advantages extend to the post-training phase, i.e. whether pre-trained dLLMs can easily acquire new knowledge through fine-tuning. On three diverse datasets, we fine-tune arLLMs and dLLMs, evaluating them with forward and backward style Question Answering (QA) to probe knowledge generalization and the reversal curse. Our results confirm that arLLMs critically rely on extensive data augmentation via paraphrases for QA generalization, and paraphrases are only effective when their information order matches the QA style. Conversely, dLLMs achieve high accuracies on both forward and backward QAs without paraphrases; adding paraphrases yields only marginal gains. Lastly, inspired by the dLLM's performance, we introduce a novel masked fine-tuning paradigm for knowledge injection into pre-trained arLLMs. This proposed method successfully and drastically improves the data efficiency of arLLM fine-tuning, effectively closing the performance gap with dLLMs. 

**Abstract (ZH)**: 尽管自回归大规模语言模型(arLLMs)是当前语言建模的主导范式，但由于内在局限性（如“反转诅咒”——即回答训练样例中原信息顺序相反的问题的挑战），它们难以通过微调注入知识。掩码扩散大规模语言模型(dLLMs)正迅速成为arLLM范式的强大替代方案，证据表明它们在预训练过程中具有更好的数据效率且不受“反转诅咒”的影响。然而，目前尚不清楚这些优势是否延伸至微调阶段，即预训练的dLLMs是否可以轻松通过微调获取新知识。我们在三个不同的数据集上对arLLMs和dLLMs进行微调，并使用前进和后退风格的问答(QA)进行评估，以探究知识泛化和“反转诅咒”。研究结果证实，arLLMs在问答泛化过程中严重依赖广泛的同义句扩展，且只有当同义句的信息顺序与问答风格匹配时，同义句扩展才有效。相反，dLLMs在有无同义句扩展的情况下都能在正向和后向问答中达到高准确率；添加同义句扩展仅带来边际收益。最后，受到dLLM表现的启发，我们提出了一种新的掩码微调范式，用于向预训练的arLLMs注入知识。该方法能够显著提高arLLM微调的数据效率，有效地缩小了其与dLLM的性能差距。 

---
# CHUG: Crowdsourced User-Generated HDR Video Quality Dataset 

**Title (ZH)**: CHUG: 众包用户生成的高动态范围视频质量数据集 

**Authors**: Shreshth Saini, Alan C. Bovik, Neil Birkbeck, Yilin Wang, Balu Adsumilli  

**Link**: [PDF](https://arxiv.org/pdf/2510.09879)  

**Abstract**: High Dynamic Range (HDR) videos enhance visual experiences with superior brightness, contrast, and color depth. The surge of User-Generated Content (UGC) on platforms like YouTube and TikTok introduces unique challenges for HDR video quality assessment (VQA) due to diverse capture conditions, editing artifacts, and compression distortions. Existing HDR-VQA datasets primarily focus on professionally generated content (PGC), leaving a gap in understanding real-world UGC-HDR degradations. To address this, we introduce CHUG: Crowdsourced User-Generated HDR Video Quality Dataset, the first large-scale subjective study on UGC-HDR quality. CHUG comprises 856 UGC-HDR source videos, transcoded across multiple resolutions and bitrates to simulate real-world scenarios, totaling 5,992 videos. A large-scale study via Amazon Mechanical Turk collected 211,848 perceptual ratings. CHUG provides a benchmark for analyzing UGC-specific distortions in HDR videos. We anticipate CHUG will advance No-Reference (NR) HDR-VQA research by offering a large-scale, diverse, and real-world UGC dataset. The dataset is publicly available at: this https URL. 

**Abstract (ZH)**: 高动态范围（HDR）视频通过卓越的亮度、对比度和色深提升视觉体验。平台如YouTube和TikTok上的用户生成内容（UGC）激增，为HDR视频质量评估（VQA）带来了新的挑战，特别是由于不同的拍摄条件、编辑 artefacts 以及压缩失真。现有的HDR-VQA数据集主要关注专业生成内容（PGC），忽略了真实世界中UGC-HDR降质的理解。为解决这一问题，我们引入了CHUG：众包用户生成HDR视频质量数据集，它是首个大规模主观评估UGC-HDR质量的研究。CHUG包含856个UGC-HDR源视频，跨多个分辨率和比特率重新编码以模拟真实场景，总共5,992个视频。通过亚马逊 Mechanical Turk 的大规模研究收集了211,848个感知评分。CHUG为分析HDR视频中的UGC特定失真提供了基准数据。我们期望CHUG将通过提供一个大规模、多样且具有现实属性的UGC数据集，推动无参考（NR）HDR-VQA研究的发展。数据集已在以下网址公开：this https URL。 

---
# Myopic Bayesian Decision Theory for Batch Active Learning with Partial Batch Label Sampling 

**Title (ZH)**: 局部贝叶斯决策理论在部分批次标签采样的批量主动学习中 

**Authors**: Kangping Hu, Stephen Mussmann  

**Link**: [PDF](https://arxiv.org/pdf/2510.09877)  

**Abstract**: Over the past couple of decades, many active learning acquisition functions have been proposed, leaving practitioners with an unclear choice of which to use. Bayesian Decision Theory (BDT) offers a universal principle to guide decision-making. In this work, we derive BDT for (Bayesian) active learning in the myopic framework, where we imagine we only have one more point to label. This derivation leads to effective algorithms such as Expected Error Reduction (EER), Expected Predictive Information Gain (EPIG), and other algorithms that appear in the literature. Furthermore, we show that BAIT (active learning based on V-optimal experimental design) can be derived from BDT and asymptotic approximations. A key challenge of such methods is the difficult scaling to large batch sizes, leading to either computational challenges (BatchBALD) or dramatic performance drops (top-$B$ selection). Here, using a particular formulation of the decision process, we derive Partial Batch Label Sampling (ParBaLS) for the EPIG algorithm. We show experimentally for several datasets that ParBaLS EPIG gives superior performance for a fixed budget and Bayesian Logistic Regression on Neural Embeddings. Our code is available at this https URL. 

**Abstract (ZH)**: 近二十年来，许多主动学习获取函数被提出，给实践者的选择造成了困惑。贝叶斯决策理论（BDT）提供了一种通用原则来指导决策。在本文中，我们在近视框架下推导了BDT在（贝叶斯）主动学习中的应用，即我们设想只剩下一点需要标记。这一推导导出了有效的算法，如期望误差减少（EER）、期望预测信息增益（EPIG）和其他文献中出现的算法。此外，我们展示了基于V-最优实验设计的主动学习方法BAIT可以从BDT和渐近逼近中推导出来。这类方法的关键挑战是难以扩展到大批次大小，导致要么计算挑战（BatchBALD）要么性能显著下降（top-$B$ 选择）。在这里，通过特定的决策过程的公式化，我们为EPIG算法推导了部分批次标签采样（ParBaLS）。实验结果表明，对于固定预算和神经嵌入的贝叶斯逻辑回归，ParBaLS EPIG表现出更优的性能。我们的代码可在以下链接获取：this https URL。 

---
# ROBOPSY PL[AI]: Using Role-Play to Investigate how LLMs Present Collective Memory 

**Title (ZH)**: ROBOPSY PL[AI]: 通过角色扮演研究大规模语言模型呈现集体记忆的方式 

**Authors**: Margarete Jahrmann, Thomas Brandstetter, Stefan Glasauer  

**Link**: [PDF](https://arxiv.org/pdf/2510.09874)  

**Abstract**: The paper presents the first results of an artistic research project investigating how Large Language Models (LLMs) curate and present collective memory. In a public installation exhibited during two months in Vienna in 2025, visitors could interact with five different LLMs (ChatGPT with GPT 4o and GPT 4o mini, Mistral Large, DeepSeek-Chat, and a locally run Llama 3.1 model), which were instructed to act as narrators, implementing a role-playing game revolving around the murder of Austrian philosopher Moritz Schlick in 1936. Results of the investigation include protocols of LLM-user interactions during the game and qualitative conversations after the play experience to get insight into the players' reactions to the game. In a quantitative analysis 115 introductory texts for role-playing generated by the LLMs were examined by different methods of natural language processing, including semantic similarity and sentiment analysis. While the qualitative player feedback allowed to distinguish three distinct types of users, the quantitative text analysis showed significant differences between how the different LLMs presented the historical content. Our study thus adds to ongoing efforts to analyse LLM performance, but also suggests a way of how these efforts can be disseminated in a playful way to a general audience. 

**Abstract (ZH)**: 该论文呈现了首个关于大型语言模型（LLMs）编排和呈现集体记忆的研究成果。在2025年在维也纳展出的一个为期两个月的公共艺术安装中，访客可以与五种不同的LLM（ChatGPT及其GPT 4o和GPT 4o mini、Mistral Large、DeepSeek-Chat以及一个本地运行的Llama 3.1模型）互动，这些模型被指导扮演叙述者的角色，围绕1936年奥地利哲学家莫里茨·舍lick的谋杀案开展角色扮演游戏。研究结果包括LLM-用户在游戏中的互动记录以及游玩体验后的定性交谈，以了解玩家对游戏的反应。通过定量分析，对115篇由LLMs生成的背景介绍文本采用了自然语言处理的不同方法，包括语义相似性和情感分析。虽然定性的玩家反馈使我们可以区分出三种不同的用户类型，但定量文本分析显示了不同LLM在呈现历史内容方面存在显著差异。因此，本研究不仅增加了对LLM性能分析的努力，还提出了一种以有趣的方式向大众传播这些努力的方法。 

---
# WARC-Bench: Web Archive Based Benchmark for GUI Subtask Executions 

**Title (ZH)**: WARC-Bench：基于网络档案的GUI子任务执行基准测试 

**Authors**: Sanjari Srivastava, Gang Li, Cheng Chang, Rishu Garg, Manpreet Kaur, Charlene Y. Lee, Yuezhang Li, Yining Mao, Ignacio Cases, Yanan Xie, Peng Qi  

**Link**: [PDF](https://arxiv.org/pdf/2510.09872)  

**Abstract**: Training web agents to navigate complex, real-world websites requires them to master $\textit{subtasks}$ - short-horizon interactions on multiple UI components (e.g., choosing the correct date in a date picker, or scrolling in a container to extract information). We introduce WARC-Bench (Web Archive Benchmark), a novel web navigation benchmark featuring 438 tasks designed to evaluate multimodal AI agents on subtasks. WARC-Bench enables sandboxed interactions with dynamic and realistic webpages using Web ARChive files. We show that WARC-Bench is challenging for leading computer-use models, with the highest observed success rate being 64.8%. To improve open source models on subtask, we explore two common training techniques: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). Experiments show that SFT models obtain a 48.8% success rate on the benchmark. Training with RLVR over SFT checkpoints, even in data-scarce settings, improves the score to 52.8% on WARC-Bench, outperforming many frontier models. Our analysis concludes that mastering these subtasks is essential for robust web planning and navigation, and is a capability not extensively evaluated by existing benchmarks. 

**Abstract (ZH)**: 训练网络代理导航复杂的真实世界网站需要它们掌握子任务——在多个UI组件上的短期交互（例如，在日期选择器中选择正确的日期，或在容器中滚动以提取信息）。我们引入了WARC-Bench（Web档案基准），这是一个新颖的网络导航基准，包含438个任务，旨在评估多模式AI代理在子任务上的表现。WARC-Bench 使用Web ARChive文件实现了对动态和真实网页的沙箱交互。实验显示，领先的人工智能模型在基准测试中的最高成功率仅为64.8%。为了提高开源模型在子任务上的表现，我们探索了两种常见的训练技术：监督微调（SFT）和带有可验证奖励的强化学习（RLVR）。实验结果表明，使用SFT的模型在基准测试中的成功率达到了48.8%。即使在数据稀缺的情况下，使用RLVR对SFT检查点进行训练，也可以将WARC-Bench上的得分为52.8%，超过了诸多前沿模型。我们的分析得出结论，掌握这些子任务对于稳健的网页规划和导航至关重要，而现有的基准测试很少评估这一能力。 

---
# NarraBench: A Comprehensive Framework for Narrative Benchmarking 

**Title (ZH)**: NarrBench：综合叙事基准框架 

**Authors**: Sil Hamilton, Matthew Wilkens, Andrew Piper  

**Link**: [PDF](https://arxiv.org/pdf/2510.09869)  

**Abstract**: We present NarraBench, a theory-informed taxonomy of narrative-understanding tasks, as well as an associated survey of 78 existing benchmarks in the area. We find significant need for new evaluations covering aspects of narrative understanding that are either overlooked in current work or are poorly aligned with existing metrics. Specifically, we estimate that only 27% of narrative tasks are well captured by existing benchmarks, and we note that some areas -- including narrative events, style, perspective, and revelation -- are nearly absent from current evaluations. We also note the need for increased development of benchmarks capable of assessing constitutively subjective and perspectival aspects of narrative, that is, aspects for which there is generally no single correct answer. Our taxonomy, survey, and methodology are of value to NLP researchers seeking to test LLM narrative understanding. 

**Abstract (ZH)**: 我们介绍了Narrabench，一个基于理论的叙事理解任务分类体系，以及对该领域78个现有基准的研究概况。我们发现，在当前研究中存在重要需求，即需要新的评估来覆盖当前工作中忽视或与现有度量标准不完全匹配的叙事理解方面。具体而言，我们估计只有27%的叙事任务能够被现有的基准充分捕捉，某些领域（包括叙事事件、风格、视角和披露）几乎未被当前的评估所涵盖。我们还指出，需要加强对体现主观性和视角性特质的叙事评估基准的研究开发，即那些通常没有唯一正确答案的方面。我们的分类体系、研究概况和方法对寻求测试大规模语言模型叙事理解能力的自然语言处理研究人员具有价值。 

---
# Token is All You Price 

**Title (ZH)**: Token 全部决定价格 

**Authors**: Weijie Zhong  

**Link**: [PDF](https://arxiv.org/pdf/2510.09859)  

**Abstract**: We build a mechanism design framework where a platform designs GenAI models to screen users who obtain instrumental value from the generated conversation and privately differ in their preference for latency. We show that the revenue-optimal mechanism is simple: deploy a single aligned (user-optimal) model and use token cap as the only instrument to screen the user. The design decouples model training from pricing, is readily implemented with token metering, and mitigates misalignment pressures. 

**Abstract (ZH)**: 我们构建了一个机制设计框架，其中平台设计生成式AI模型以筛选出从生成对话中获得工具价值并具有不同延迟偏好偏好用户的。我们展示了最优收益机制的简单性：部署一个一致（用户最优）的模型，并仅使用令牌限制来筛选用户。该设计将模型训练与定价分离，易于通过令牌计量实现，并减轻了一致性的压力。 

---
# ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers 

**Title (ZH)**: ProxRouter: 基于proximity加权的LLM查询路由以提高对异常值的稳健性 

**Authors**: Shivam Patel, Neharika Jali, Ankur Mallick, Gauri Joshi  

**Link**: [PDF](https://arxiv.org/pdf/2510.09852)  

**Abstract**: Large language model (LLM) query routers are critical to modern AI platforms as they seek to improve efficiency by assigning inference queries to accurate, yet low-cost models. Parametric routers typically use trained neural networks for LLM selection but suffer from retraining and maintenance overheads. Nonparametric routers are training-free, instead estimating LLM accuracy and cost via similarity between encodings of the input query and training set queries. However, like their parametric counterparts, nonparametric routers struggle to generalize to outlier queries, an issue exacerbated by limited diversity in training sets which are costly to expand and difficult to keep current with ever-evolving use cases. We propose ProxRouter, which applies an exponentially tilted aggregation mechanism to balance bias and variance in nonparametric routers, improving their robustness to outliers. Experiments show ProxRouter enhances outlier routing while preserving inlier performance with minimal overhead. 

**Abstract (ZH)**: 非参数化大语言模型查询路由器：ProxRouter及其鲁棒性改进 

---
# CALM: A Causal Analysis Language Model for Tabular Data in Complex Systems with Local Scores, Conditional Independence Tests, and Relation Attributes 

**Title (ZH)**: CALM：一种用于复杂系统中表格数据的因果分析语言模型，包含局部评分、条件独立性检验和关系属性。 

**Authors**: Zhenjiang Fan, Zengyi Qin, Yuanning Zheng, Bo Xiong, Summer Han  

**Link**: [PDF](https://arxiv.org/pdf/2510.09846)  

**Abstract**: Causal discovery from observational data is fundamental to scientific fields like biology, where controlled experiments are often impractical. However, existing methods, including constraint-based (e.g., PC, causalMGM) and score-based approaches (e.g., NOTEARS), face significant limitations. These include an inability to resolve causal direction, restrictions to linear associations, sensitivity to violations of the faithfulness assumption, and inefficiency in searching vast hypothesis spaces. While large language models (LLMs) offer powerful reasoning capabilities, their application is hindered by a fundamental discrepancy: they are designed for text, while most causal data is tabular. To address these challenges, we introduce CALM, a novel causal analysis language model specifically designed for tabular data in complex systems. CALM leverages a Mamba-based architecture to classify causal patterns from pairwise variable relationships. It integrates a comprehensive suite of evidence, including local causal scores, conditional independence tests, and relational attributes, to capture a wide spectrum of linear, nonlinear, and conditional causal mechanisms. Trained on a diverse corpus of synthetic data (from linear, mixed, and nonlinear models) and 10 real-world biological datasets with rigorously validated causal relationships, our model ensures robustness and generalizability. Empirical evaluation demonstrates that CALM significantly outperforms existing methods in both simulation studies, achieving over 91% accuracy, and in a real-world application identifying causal factors in Hepatitis C virus progression. This work represents a significant step towards accurate and generalizable causal discovery by successfully adapting the pattern recognition capabilities of language models to the intricacies of tabular data. 

**Abstract (ZH)**: 基于观察数据的因果发现对于生物学等科学领域至关重要，但在许多情况下进行受控实验是不现实的。现有方法，包括基于约束的方法（例如PC, causalMGM）和基于评分的方法（例如NOTEARS），存在显著限制。这些限制包括无法确定因果方向、仅限于线性关系、对信仰假设违反的敏感性以及在大量假设空间搜索方面的低效性。虽然大型语言模型提供了强大的推理能力，但其应用受限于根本性差异：它们设计用于文本，而大多数因果数据为表格形式。为了解决这些挑战，我们引入了CALM，一种专门针对复杂系统中表格数据的新型因果分析语言模型。CALM利用Mamba架构来从成对变量关系中分类因果模式。它集成了局部因果评分、条件独立性检验和关系属性等多种证据，以捕捉广泛多样的线性、非线性和条件因果机制。该模型通过对来自线性、混合和非线性模型的合成数据以及10个真实世界生物数据集进行训练，这些真实世界数据集中的因果关系经过严格的验证，确保了模型的稳健性和泛化能力。实证评价表明，CALM在模拟研究中显著优于现有方法，准确率超过91%，在识别Hepatitis C病毒进展中的因果因素的实际应用中也同样表现出色。这项工作标志着准确和泛化因果发现的重要进步，成功将语言模型的模式识别能力适应了表格数据的复杂性。 

---
# Harnessing Self-Supervised Deep Learning and Geostationary Remote Sensing for Advancing Wildfire and Associated Air Quality Monitoring: Improved Smoke and Fire Front Masking using GOES and TEMPO Radiance Data 

**Title (ZH)**: 利用自我监督深度学习和地球静止轨道遥感促进野火及关联空气质量监测：使用GOES和TEMPO辐射数据优化烟雾和火线掩码 

**Authors**: Nicholas LaHaye, Thilanka Munashinge, Hugo Lee, Xiaohua Pan, Gonzalo Gonzalez Abad, Hazem Mahmoud, Jennifer Wei  

**Link**: [PDF](https://arxiv.org/pdf/2510.09845)  

**Abstract**: This work demonstrates the possibilities for improving wildfire and air quality management in the western United States by leveraging the unprecedented hourly data from NASA's TEMPO satellite mission and advances in self-supervised deep learning. Here we demonstrate the efficacy of deep learning for mapping the near real-time hourly spread of wildfire fronts and smoke plumes using an innovative self-supervised deep learning-system: successfully distinguishing smoke plumes from clouds using GOES-18 and TEMPO data, strong agreement across the smoke and fire masks generated from different sensing modalities as well as significant improvement over operational products for the same cases. 

**Abstract (ZH)**: 本研究展示了通过利用NASA TEMPO卫星任务前所未有的每小时数据以及自主监督深度学习的进步，提高美国西部地区野火和空气质量管理的可能性。我们证明了深度学习在使用创新的自主监督深度学习系统实时绘制野火前沿和烟霾分布图方面的有效性：成功使用GOES-18和TEMPO数据区分烟霾和云，不同传感模态生成的烟霾和火mask之间具有较强的协议，并且在相同情况下显著优于现有产品。 

---
# Towards Understanding Ambiguity Resolution in Multimodal Inference of Meaning 

**Title (ZH)**: 理解多模态语义推理中的歧义Resolve 

**Authors**: Yufei Wang, Adriana Kovashka, Loretta Fernández, Marc N. Coutanche, Seth Wiener  

**Link**: [PDF](https://arxiv.org/pdf/2510.09815)  

**Abstract**: We investigate a new setting for foreign language learning, where learners infer the meaning of unfamiliar words in a multimodal context of a sentence describing a paired image. We conduct studies with human participants using different image-text pairs. We analyze the features of the data (i.e., images and texts) that make it easier for participants to infer the meaning of a masked or unfamiliar word, and what language backgrounds of the participants correlate with success. We find only some intuitive features have strong correlations with participant performance, prompting the need for further investigating of predictive features for success in these tasks. We also analyze the ability of AI systems to reason about participant performance, and discover promising future directions for improving this reasoning ability. 

**Abstract (ZH)**: 我们研究了一种新的外语学习环境，在这种环境中，学习者在描述配对图像的句子的多模态上下文中推断陌生词的意义。我们使用不同的图像-文本对进行人类参与者的实验研究。我们分析了使参与者更容易推断被遮罩或陌生词意义的数据特征（即图像和文本），以及参与者的语言背景与成功之间的关联。我们发现只有某些直观的特征与参与者的表现有很强的相关性，这提示我们还需要进一步研究这些任务中预测成功的特征。我们还分析了AI系统在理解参与者表现方面的推理能力，并发现了改进这种推理能力的有希望的方向。 

---
# Temporal Lifting as Latent-Space Regularization for Continuous-Time Flow Models in AI Systems 

**Title (ZH)**: 时域提升作为latent空间正则化在AI系统中连续时间流模型中的应用 

**Authors**: Jeffrey Camlin  

**Link**: [PDF](https://arxiv.org/pdf/2510.09805)  

**Abstract**: We present a latent-space formulation of adaptive temporal reparametrization for continuous-time dynamical systems. The method, called *temporal lifting*, introduces a smooth monotone mapping $t \mapsto \tau(t)$ that regularizes near-singular behavior of the underlying flow while preserving its conservation laws. In the lifted coordinate, trajectories such as those of the incompressible Navier-Stokes equations on the torus $\mathbb{T}^3$ become globally smooth. From the standpoint of machine-learning dynamics, temporal lifting acts as a continuous-time normalization or time-warping operator that can stabilize physics-informed neural networks and other latent-flow architectures used in AI systems. The framework links analytic regularity theory with representation-learning methods for stiff or turbulent processes. 

**Abstract (ZH)**: 我们提出了连续时间动力系统自适应时间重参数的隐空间形式化方法：时间提升 

---
# Large Language Models for Imbalanced Classification: Diversity makes the difference 

**Title (ZH)**: 大型语言模型在不均衡分类中的应用：多样性带来差异 

**Authors**: Dang Nguyen, Sunil Gupta, Kien Do, Thin Nguyen, Taylor Braund, Alexis Whitton, Svetha Venkatesh  

**Link**: [PDF](https://arxiv.org/pdf/2510.09783)  

**Abstract**: Oversampling is one of the most widely used approaches for addressing imbalanced classification. The core idea is to generate additional minority samples to rebalance the dataset. Most existing methods, such as SMOTE, require converting categorical variables into numerical vectors, which often leads to information loss. Recently, large language model (LLM)-based methods have been introduced to overcome this limitation. However, current LLM-based approaches typically generate minority samples with limited diversity, reducing robustness and generalizability in downstream classification tasks. To address this gap, we propose a novel LLM-based oversampling method designed to enhance diversity. First, we introduce a sampling strategy that conditions synthetic sample generation on both minority labels and features. Second, we develop a new permutation strategy for fine-tuning pre-trained LLMs. Third, we fine-tune the LLM not only on minority samples but also on interpolated samples to further enrich variability. Extensive experiments on 10 tabular datasets demonstrate that our method significantly outperforms eight SOTA baselines. The generated synthetic samples are both realistic and diverse. Moreover, we provide theoretical analysis through an entropy-based perspective, proving that our method encourages diversity in the generated samples. 

**Abstract (ZH)**: 过采样是应对分类不平衡问题中最广泛使用的方法之一。核心思想是生成额外的少数类样本以重新平衡数据集。现有大多数方法，如SMOTE，需要将分类变量转换为数值向量，这往往会损失信息。最近，基于大规模语言模型（LLM）的方法已被引入以克服这一限制。然而，当前的LLM基方法通常生成多样性有限的少数类样本，降低了下游分类任务中的鲁棒性和泛化能力。为填补这一空白，我们提出了一种新的基于LLM的过采样方法，旨在增强多样性。首先，我们引入了一种采样策略，使合成样本生成有条件地依赖于少数类标签和特征。其次，我们开发了一种新的排列策略以微调预训练的LLM。第三，我们不仅在少数类样本，还在插值样本上微调LLM，以进一步丰富变异性。在10个表格数据集上的广泛实验表明，我们的方法显著优于八个最新基线。生成的合成样本既具有现实性又具有多样性。此外，我们从熵的角度提供了理论分析，证明我们的方法鼓励生成样本的多样性。 

---
# Building a Foundational Guardrail for General Agentic Systems via Synthetic Data 

**Title (ZH)**: 通过合成数据建立通用代理系统的基础 guardrail 

**Authors**: Yue Huang, Hang Hua, Yujun Zhou, Pengcheng Jing, Manish Nagireddy, Inkit Padhi, Greta Dolcetti, Zhangchen Xu, Subhajit Chaudhury, Ambrish Rawat, Liubov Nedoshivina, Pin-Yu Chen, Prasanna Sattigeri, Xiangliang Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09781)  

**Abstract**: While LLM agents can plan multi-step tasks, intervening at the planning stage-before any action is executed-is often the safest way to prevent harm, since certain risks can lead to severe consequences once carried out. However, existing guardrails mostly operate post-execution, which is difficult to scale and leaves little room for controllable supervision at the plan level. To address this challenge, we highlight three critical gaps in current research: data gap, model gap, and evaluation gap. To close the data gap, we introduce AuraGen, a controllable engine that (i) synthesizes benign trajectories, (ii) injects category-labeled risks with calibrated difficulty, and (iii) filters outputs via an automated reward model, producing large and reliable corpora for pre-execution safety. To close the guardian model gap, we propose a foundational guardrail Safiron, combining a cross-planner adapter with a compact guardian model. The adapter unifies different input formats, while Safiron flags risky cases, assigns risk types, and generates rationales; trained in two stages with a broadly explored data recipe, Safiron achieves robust transfer across settings. To close the evaluation gap, we release Pre-Exec Bench, a realistic benchmark covering diverse tools and branching trajectories, which measures detection, fine-grained categorization, explanation, and cross-planner generalization in human-verified scenarios. Extensive experiments demonstrate consistent gains of the proposed guardrail over strong baselines on Pre-Exec Bench, and ablations further distill actionable practices, providing a practical template for safer agentic systems. 

**Abstract (ZH)**: 现有的护栏大多在执行后运作，难以扩展，并且在计划层面留下的可控监督空间很小。为应对这一挑战，我们指出现有研究中的三个关键空白：数据空白、模型空白和评估空白。为填补数据空白，我们引入了AuraGen，这是一种可控引擎，它可以（i）生成良性轨迹，（ii）注入带校准难度的类别标签风险，并（iii）通过自动奖励模型筛选输出，从而生成预执行安全的大规模可靠数据集。为填补护栏模型空白，我们提出了基础护栏Safiron，将跨规划适应器与紧凑型护栏模型结合。适应器统一了不同的输入格式，而Safiron标注风险案例，分配风险类型并生成理由；经过两个阶段的训练，采用广泛探索的数据方案，Safiron在不同场景中实现了稳健的迁移。为填补评估空白，我们发布了Pre-Exec Bench，这是一个现实基准，涵盖了多种工具和分支轨迹，衡量了预执行检测、细粒度分类、解释和跨规划者的泛化能力。大量实验表明，在Pre-Exec Bench上，所提出的护栏在广泛的基线中表现一致改进，消融分析进一步提炼了可操作的实践，为更安全的代理系统提供了实用模板。 

---
# SVTime: Small Time Series Forecasting Models Informed by "Physics" of Large Vision Model Forecasters 

**Title (ZH)**: SVTime: 由大型视觉模型预报“物理”原理启发的_SMALL_时间序列 forecasting 模型 

**Authors**: ChengAo Shen, Ziming Zhao, Hanghang Tong, Dongjin Song, Dongsheng Luo, Qingsong Wen, Jingchao Ni  

**Link**: [PDF](https://arxiv.org/pdf/2510.09780)  

**Abstract**: Time series AI is crucial for analyzing dynamic web content, driving a surge of pre-trained large models known for their strong knowledge encoding and transfer capabilities across diverse tasks. However, given their energy-intensive training, inference, and hardware demands, using large models as a one-fits-all solution raises serious concerns about carbon footprint and sustainability. For a specific task, a compact yet specialized, high-performing model may be more practical and affordable, especially for resource-constrained users such as small businesses. This motivates the question: Can we build cost-effective lightweight models with large-model-like performance on core tasks such as forecasting? This paper addresses this question by introducing SVTime, a novel Small model inspired by large Vision model (LVM) forecasters for long-term Time series forecasting (LTSF). Recently, LVMs have been shown as powerful tools for LTSF. We identify a set of key inductive biases of LVM forecasters -- analogous to the "physics" governing their behaviors in LTSF -- and design small models that encode these biases through meticulously crafted linear layers and constraint functions. Across 21 baselines spanning lightweight, complex, and pre-trained large models on 8 benchmark datasets, SVTime outperforms state-of-the-art (SOTA) lightweight models and rivals large models with 10^3 fewer parameters than LVMs, while enabling efficient training and inference in low-resource settings. 

**Abstract (ZH)**: 基于大型模型的长周期时间序列预测轻量化模型SVTime 

---
# Why Do Transformers Fail to Forecast Time Series In-Context? 

**Title (ZH)**: 为什么变压器模型在上下文情境中无法预测时间序列？ 

**Authors**: Yufa Zhou, Yixiao Wang, Surbhi Goel, Anru R. Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09776)  

**Abstract**: Time series forecasting (TSF) remains a challenging and largely unsolved problem in machine learning, despite significant recent efforts leveraging Large Language Models (LLMs), which predominantly rely on Transformer architectures. Empirical evidence consistently shows that even powerful Transformers often fail to outperform much simpler models, e.g., linear models, on TSF tasks; however, a rigorous theoretical understanding of this phenomenon remains limited. In this paper, we provide a theoretical analysis of Transformers' limitations for TSF through the lens of In-Context Learning (ICL) theory. Specifically, under AR($p$) data, we establish that: (1) Linear Self-Attention (LSA) models $\textit{cannot}$ achieve lower expected MSE than classical linear models for in-context forecasting; (2) as the context length approaches to infinity, LSA asymptotically recovers the optimal linear predictor; and (3) under Chain-of-Thought (CoT) style inference, predictions collapse to the mean exponentially. We empirically validate these findings through carefully designed experiments. Our theory not only sheds light on several previously underexplored phenomena but also offers practical insights for designing more effective forecasting architectures. We hope our work encourages the broader research community to revisit the fundamental theoretical limitations of TSF and to critically evaluate the direct application of increasingly sophisticated architectures without deeper scrutiny. 

**Abstract (ZH)**: 时间序列预测（TSF）仍然是机器学习中一个极具挑战性和尚未完全解决的问题，尽管近年来通过大型语言模型（LLMs）取得了显著进展，这些模型主要依赖于Transformer架构。实证证据一致表明，即使强大的Transformer模型在时间序列预测任务上也往往无法超越更简单的模型，例如线性模型；然而，对这一现象的严格理论理解仍然有限。在本文中，我们通过基于In-Context Learning（ICL）理论的角度对Transformer在时间序列预测中的局限性进行了理论分析。具体来说，在AR($p$)数据下，我们证明了：（1）线性自注意力（LSA）模型不能实现比经典线性模型更低的期望均方误差（MSE）进行上下文中的预测；（2）随着上下文长度趋向无穷大，LSA渐近恢复最优线性预测器；（3）在链式思维（CoT）风格推理中，预测以指数形式收敛到均值。我们通过精心设计的实验验证了这些发现。我们的理论不仅揭示了几种先前未被充分探索的现象，也为设计更有效的预测架构提供了实际见解。我们希望我们的工作能够鼓励更广泛的科研社区重新审视时间序列预测的基本理论限制，并在深入审查之前批判性地评估越来越复杂的架构的应用。 

---
# PromptGuard at BLP-2025 Task 1: A Few-Shot Classification Framework Using Majority Voting and Keyword Similarity for Bengali Hate Speech Detection 

**Title (ZH)**: PromptGuard在BLP-2025任务1中的Few-Shot分类框架：基于多数投票和关键词相似性的孟加拉语仇恨言论检测 

**Authors**: Rakib Hossan, Shubhashis Roy Dipta  

**Link**: [PDF](https://arxiv.org/pdf/2510.09771)  

**Abstract**: The BLP-2025 Task 1A requires Bengali hate speech classification into six categories. Traditional supervised approaches need extensive labeled datasets that are expensive for low-resource languages. We developed PromptGuard, a few-shot framework combining chi-square statistical analysis for keyword extraction with adaptive majority voting for decision-making. We explore statistical keyword selection versus random approaches and adaptive voting mechanisms that extend classification based on consensus quality. Chi-square keywords provide consistent improvements across categories, while adaptive voting benefits ambiguous cases requiring extended classification rounds. PromptGuard achieves a micro-F1 of 67.61, outperforming n-gram baselines (60.75) and random approaches (14.65). Ablation studies confirm chi-square-based keywords show the most consistent impact across all categories. 

**Abstract (ZH)**: BLP-2025 任务1A 要求将孟加拉语仇恨言论分类为六类。传统的监督方法需要大量的标记数据集，这对于低资源语言来说成本高昂。我们开发了 PromptGuard，这是一种结合卡方统计分析进行关键词提取和自适应多数投票进行决策的少样本框架。我们探索了基于统计的关键词选择与随机方法以及基于共识质量的自适应投票机制，以扩展分类。卡方关键词在各类别中提供了持续的改进，而自适应投票机制有助于解决需要更长时间分类的歧义案例。PromptGuard 实现了微F1值为67.61，优于n-克隆基线（60.75）和随机方法（14.65）。消融研究确认基于卡方的关键词在所有类别中表现出最一致的影响。 

---
# Scaling Laws and Symmetry, Evidence from Neural Force Fields 

**Title (ZH)**: 神经力场的标度律与对称性证据 

**Authors**: Khang Ngo, Siamak Ravanbakhsh  

**Link**: [PDF](https://arxiv.org/pdf/2510.09768)  

**Abstract**: We present an empirical study in the geometric task of learning interatomic potentials, which shows equivariance matters even more at larger scales; we show a clear power-law scaling behaviour with respect to data, parameters and compute with ``architecture-dependent exponents''. In particular, we observe that equivariant architectures, which leverage task symmetry, scale better than non-equivariant models. Moreover, among equivariant architectures, higher-order representations translate to better scaling exponents. Our analysis also suggests that for compute-optimal training, the data and model sizes should scale in tandem regardless of the architecture. At a high level, these results suggest that, contrary to common belief, we should not leave it to the model to discover fundamental inductive biases such as symmetry, especially as we scale, because they change the inherent difficulty of the task and its scaling laws. 

**Abstract (ZH)**: 我们呈现了一项关于原子间势学习的几何任务中的实证研究，表明在更大尺度上，对称性的重要性更加突出；我们展示了数据、参数和计算在“架构依赖指数”下的幂律 scaling 行为。特别是，我们观察到利用任务对称性的对称架构相比非对称模型具有更好的 scaling 行为。此外，在对称架构中，更高阶的表示对应更好的 scaling 指数。我们的分析还表明，为了实现计算最优的训练，数据和模型的规模应该同步增长，而不受架构的影响。总体而言，这些结果表明，与常见的观点相反，当我们扩展规模时，不应让模型自己发现诸如对称性这样的基本归纳偏置，因为这会改变任务的内在难度及其 scaling 法则。 

---
# PatentVision: A multimodal method for drafting patent applications 

**Title (ZH)**: PatentVision: 一种多模态的专利申请撰写方法 

**Authors**: Ruo Yang, Sai Krishna Reddy Mudhiganti, Manali Sharma  

**Link**: [PDF](https://arxiv.org/pdf/2510.09762)  

**Abstract**: Patent drafting is complex due to its need for detailed technical descriptions, legal compliance, and visual elements. Although Large Vision Language Models (LVLMs) show promise across various tasks, their application in automating patent writing remains underexplored. In this paper, we present PatentVision, a multimodal framework that integrates textual and visual inputs such as patent claims and drawings to generate complete patent specifications. Built on advanced LVLMs, PatentVision enhances accuracy by combining fine tuned vision language models with domain specific training tailored to patents. Experiments reveal it surpasses text only methods, producing outputs with greater fidelity and alignment with human written standards. Its incorporation of visual data allows it to better represent intricate design features and functional connections, leading to richer and more precise results. This study underscores the value of multimodal techniques in patent automation, providing a scalable tool to reduce manual workloads and improve consistency. PatentVision not only advances patent drafting but also lays the groundwork for broader use of LVLMs in specialized areas, potentially transforming intellectual property management and innovation processes. 

**Abstract (ZH)**: 专利撰写复杂性在于其需要详细的技术描述、法律合规性以及视觉元素。尽管大规模视觉语言模型（LVLMs）在各种任务中显示出潜力，但其在自动化专利写作中的应用仍处于未开发状态。本文介绍了一种多模态框架——PatentVision，该框架整合了诸如专利权利要求和图纸等文本和视觉输入以生成完整的专利规范文件。基于先进的LVLMs，PatentVision通过结合微调的视觉语言模型和针对专利领域的特定训练提高了准确性。实验显示，它超越了仅基于文本的方法，生成的输出具有更高的准确性和与人类撰写标准的更好对齐。其纳入的视觉数据使其能够更准确地表示复杂的结构特征和功能连接，从而产生更丰富和精确的结果。本研究突显了多模态技术在专利自动化中的价值，提供了一种可扩展的工具以减少人工工作量并提高一致性。PatentVision不仅推动了专利撰写的工作，也为更广泛地在专有领域使用LVLMs奠定了基础，有可能改变知识产权管理与创新流程。 

---
# Patentformer: A demonstration of AI-assisted automated patent drafting 

**Title (ZH)**: Patentformer：人工智能辅助自动专利起草演示 

**Authors**: Sai Krishna Reddy Mudhiganti, Juanyan Wang, Ruo Yang, Manali Sharma  

**Link**: [PDF](https://arxiv.org/pdf/2510.09752)  

**Abstract**: Patent drafting presents significant challenges due to its reliance on the extensive experience and specialized expertise of patent attorneys, who must possess both legal acumen and technical understanding of an invention to craft patent applications in a formal legal writing style. This paper presents a demonstration of Patentformer, an AI-powered automated patent drafting platform designed to support patent attorneys by rapidly producing high-quality patent applications adhering to legal writing standards. 

**Abstract (ZH)**: 由于专利撰写依赖于专利律师的丰富经验和专业技能，要求律师同时具备法律洞察力和发明技术理解能力，以正式的法律文书风格撰写专利申请。本文展示了Patentformer这一基于AI的自动化专利撰写平台的示例，旨在通过快速生成符合法律写作标准的高质量专利申请来支持专利律师。 

---
# Machine learning methods fail to provide cohesive atheoretical construction of personality traits from semantic embeddings 

**Title (ZH)**: 机器学习方法未能提供人格特质的cohesive理论构建从语义嵌入 Perspective 

**Authors**: Ayoub Bouguettaya, Elizabeth M. Stuart  

**Link**: [PDF](https://arxiv.org/pdf/2510.09739)  

**Abstract**: The lexical hypothesis posits that personality traits are encoded in language and is foundational to models like the Big Five. We created a bottom-up personality model from a classic adjective list using machine learning and compared its descriptive utility against the Big Five by analyzing one million Reddit comments. The Big Five, particularly Agreeableness, Conscientiousness, and Neuroticism, provided a far more powerful and interpretable description of these online communities. In contrast, our machine-learning clusters provided no meaningful distinctions, failed to recover the Extraversion trait, and lacked the psychometric coherence of the Big Five. These results affirm the robustness of the Big Five and suggest personality's semantic structure is context-dependent. Our findings show that while machine learning can help check the ecological validity of established psychological theories, it may not be able to replace them. 

**Abstract (ZH)**: 词素假设提出了人格特质在语言中编码的理论，并构成了五大人格特质模型的基础。我们利用机器学习从经典形容词列表中自下而上构建了一个人格模型，并通过分析一百万条Reddit评论将其描述效用与五大人格特质进行了比较。五大人格特质，尤其是随和性、尽责性和情绪稳定性，提供了对这些在线社区更为强大且易于解释的描述。相比之下，我们的机器学习聚类未能提供有意义的区别，无法恢复外向性特质，并缺乏五大人格特质的心理测量一致性。这些结果证实了五大人格特质的稳健性，并暗示了人格的语义结构具有情境依赖性。我们的研究显示，虽然机器学习可以帮助验证已建立的心理学理论的生态效度，但它可能无法替代这些理论。 

---
# Judge's Verdict: A Comprehensive Analysis of LLM Judge Capability Through Human Agreement 

**Title (ZH)**: 法官判决：通过人类共识全面分析LLM法官能力 

**Authors**: Steve Han, Gilberto Titericz Junior, Tom Balough, Wenfei Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.09738)  

**Abstract**: This research introduces the Judge's Verdict Benchmark, a novel two-step methodology to evaluate Large Language Models (LLMs) as judges for response accuracy evaluation tasks. We assess how well 54 LLMs can replicate human judgment when scoring responses from RAG (Retrieval-Augmented Generation) or Agentic pipelines against ground truth answers. Our methodology progresses from traditional correlation analysis to comprehensive Cohen's Kappa analysis that measures actual agreement patterns. The two-step approach includes: (1) a correlation test that filters judges with strong alignment, followed by (2) a human-likeness test using z-scores to identify two distinct judgment patterns: human-like judgment (|z| < 1) that mimics natural human variation, and super-consistent judgment (z > 1) that exceeds typical human-to-human agreement levels. This methodology reveals that 27 out of 54 tested LLMs achieve Tier 1 performance: 23 models exhibit human-like patterns that preserve the nuances of human judgment, while 4 models demonstrate super-consistent behavior, a pattern that could indicate either enhanced reliability or oversimplification of complex judgments. Testing 43 open-source models (1B-405B parameters) and 11 closed models (GPT, Gemini, Claude variants), we demonstrate that judge excellence is not solely dependent on model size but on specific training strategies. Our key contributions include: (1) establishing that correlation alone is insufficient for judge evaluation, (2) introducing a "Turing Test for judges" based on agreement patterns, and (3) providing a standardized benchmark for classifying LLM judges into distinct performance tiers for different evaluation needs. 

**Abstract (ZH)**: 此次研究引入了裁判裁决基准，提出了一种新颖的两步方法学来评估大型语言模型（LLMs）作为响应准确性评估任务的裁判。我们评估了54种LLMs在对来自RAG（检索增强生成）或代理管道的响应与真实答案进行评分时，其复制人类判断的能力。该方法学从传统的相关性分析进展到全面的科恩κ分析以衡量实际的一致性模式。两步方法包括：（1）相关性测试以筛选出与人类判断高度一致的裁判，随后进行（2）人类一致性的测试，使用z分数识别出两种不同的判断模式：人类一致的判断（|z| < 1）、模仿自然人类差异模式，以及超级一致的判断（z > 1）、超过人类之间一致性的模式。该方法学揭示了54种测试模型中有27种取得了顶级性能：23种模型展示了人类一致的模式，保留了人类判断的微妙之处；4种模型展示了超级一致的行为，这可能预示着增强的可靠性或对复杂判断的过度简化。测试43种开源模型（参数量从1B到405B）和11种闭源模型（GPT、Gemini、Claude变体），我们证明了裁判的卓越性不仅依赖于模型规模，还依赖于特定的训练策略。我们的主要贡献包括：（1）确立了仅依靠相关性不足以评估裁判的有效性，（2）引入了基于一致性模式的“裁判图灵测试”，以及（3）提供了一个标准化基准，用于根据不同评估需求将LLM裁判分类到不同的性能层级中。 

---
# Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery 

**Title (ZH)**: 使用C2RCC处理的Sentinel 2影像进行马尔梅诺潟湖叶绿素-a的映射与预测 

**Authors**: Antonio Martínez-Ibarra, Aurora González-Vidal, Adrián Cánovas-Rodríguez, Antonio F. Skarmeta  

**Link**: [PDF](https://arxiv.org/pdf/2510.09736)  

**Abstract**: The Mar Menor, Europe's largest coastal lagoon, located in Spain, has undergone severe eutrophication crises. Monitoring chlorophyll-a (Chl-a) is essential to anticipate harmful algal blooms and guide mitigation. Traditional in situ measurements are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable, long-term, and transferable monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map Chl-a across the water column of the Mar Menor. The work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Nearly a decade of Sentinel 2 images was atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth (0-1 m, 1-2 m, 2-3 m, 3-4 m). Multiple ML and DL algorithms-including RF, XGBoost, CatBoost, Multilater Perceptron Networks, and ensembles-were trained and validated using cross-validation. Systematic band-combination experiments and spatial aggregation strategies were tested to optimize prediction. Results show depth-dependent performance. At the surface, C2X-Complex with XGBoost and ensemble models achieved R2 = 0.89; at 1-2 m, CatBoost and ensemble models reached R2 = 0.87; at 2-3 m, TOA reflectances with KNN performed best (R2 = 0.81); while at 3-4 m, RF achieved R2 = 0.66. Generated maps successfully reproduced known eutrophication events (e.g., 2016 crisis, 2025 surge), confirming robustness. The study delivers an end-to-end, validated methodology for depth-specific Chl-amapping. Its integration of multispectral band combinations, buoy calibration, and ML/DL modeling offers a transferable framework for other turbid coastal systems. 

**Abstract (ZH)**: 欧洲最大的沿海泻湖——西班牙的马尔梅诺泻湖经历了严重的富营养化危机。通过监测chlorophyll-a (Chl-a)可以预见有害藻华并指导缓解措施。传统的原位测量在空间和时间上都有限制。基于卫星的方法提供了更全面的观点，使监测变得规模化、长时间且可转移。本研究旨在通过开发可靠的预测和地图绘制方法来克服Chl-a监测的限制，该方法能够针对马尔梅诺泻湖水柱的高分辨率、深度特定监测，增强对富营养化的早期预警能力。利用Sentinel-2图像与浮标地面实况数据的整合，创建了可用于高分辨率、深度特定监测的模型，增强了对富营养化的早期预警能力。近十年的Sentinel-2图像通过C2RCC处理器进行了大气校正。浮标数据按深度（0-1米、1-2米、2-3米、3-4米）进行了聚合。多种机器学习和深度学习算法，包括随机森林、XGBoost、CatBoost、多层感知网络以及它们的集成，通过交叉验证进行了训练和验证。系统地进行了波段组合实验和空间聚合策略以优化预测。结果表明，预测性能具有深度依赖性。在表层，C2X-Complex与XGBoost和集成模型的R2值达到0.89；在1-2米深度，CatBoost和集成模型的R2值达到0.87；在2-3米深度，表面辐亮度与KNN方法表现最佳（R2值为0.81）；而在3-4米深度，随机森林的R2值为0.66。生成的地图成功重现了已知的富营养化事件（如2016年的危机和2025年的激增），证实了其稳健性。本研究提供了一种端到端的、经验证的深度特定Chl-a地图绘制方法。其结合多光谱波段组合、浮标校准和机器学习/深度学习建模，提供了一个适用于其他浑浊海岸系统的可转移框架。 

---
# InterCorpRel-LLM: Enhancing Financial Relational Understanding with Graph-Language Models 

**Title (ZH)**: InterCorpRel-LLM：增强企业关系理解的图语言模型 

**Authors**: Qianyou Sun, Jiexin Zheng, Bohan Jin, Lihua Chen, Yijie Peng  

**Link**: [PDF](https://arxiv.org/pdf/2510.09735)  

**Abstract**: Identifying inter-firm relationships such as supply and competitive ties is critical for financial analysis and corporate governance, yet remains challenging due to the scale, sparsity, and contextual dependence of corporate data. Graph-based methods capture structure but miss semantic depth, while large language models (LLMs) excel at text but remain limited in their ability to represent relational dependencies. To address this, we propose InterCorpRel-LLM, a cross-modal framework that integrates GNNs with LLMs, supported by a proprietary dataset derived from FactSet supply chain records and three tailored training tasks: company graph matching, industry classification, and supply relation prediction. This design enables effective joint modeling of structure and semantics. Experiments show that InterCorpRel-LLM substantially outperforms strong baselines, including GPT-5, on a supply relation identification task, achieving an F-score of 0.8543 vs. 0.2287 with only a 7B-parameter backbone and lightweight training. The model also generalizes to zero-shot competitor identification, underscoring its ability to capture nuanced inter-firm dynamics. Our framework thus provides analysts and strategists with a robust tool for mapping and reasoning about complex corporate networks, enhancing decision-making and risk management in dynamic markets. 

**Abstract (ZH)**: 基于跨模态框架的InterCorpRel-LLM：一种集成GNN与大规模语言模型的方法及其在识别供应链关系中的应用 

---
# ARROW: An Adaptive Rollout and Routing Method for Global Weather Forecasting 

**Title (ZH)**: ARROW：一种适应性滚动和routing方法用于全球天气预报 

**Authors**: Jindong Tian, Yifei Ding, Ronghui Xu, Hao Miao, Chenjuan Guo, Bin Yang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09734)  

**Abstract**: Weather forecasting is a fundamental task in spatiotemporal data analysis, with broad applications across a wide range of domains. Existing data-driven forecasting methods typically model atmospheric dynamics over a fixed short time interval (e.g., 6 hours) and rely on naive autoregression-based rollout for long-term forecasting (e.g., 138 hours). However, this paradigm suffers from two key limitations: (1) it often inadequately models the spatial and multi-scale temporal dependencies inherent in global weather systems, and (2) the rollout strategy struggles to balance error accumulation with the capture of fine-grained atmospheric variations. In this study, we propose ARROW, an Adaptive-Rollout Multi-scale temporal Routing method for Global Weather Forecasting. To contend with the first limitation, we construct a multi-interval forecasting model that forecasts weather across different time intervals. Within the model, the Shared-Private Mixture-of-Experts captures both shared patterns and specific characteristics of atmospheric dynamics across different time scales, while Ring Positional Encoding accurately encodes the circular latitude structure of the Earth when representing spatial information. For the second limitation, we develop an adaptive rollout scheduler based on reinforcement learning, which selects the most suitable time interval to forecast according to the current weather state. Experimental results demonstrate that ARROW achieves state-of-the-art performance in global weather forecasting, establishing a promising paradigm in this field. 

**Abstract (ZH)**: 面向全球天气预报的自适应展开多尺度时空路由方法_ARROW 

---
# Evaluating LLM-Based Process Explanations under Progressive Behavioral-Input Reduction 

**Title (ZH)**: 基于渐进行为输入缩减的LLM驱动过程解释评估 

**Authors**: P. van Oerle, R. H. Bemthuis, F. A. Bukhsh  

**Link**: [PDF](https://arxiv.org/pdf/2510.09732)  

**Abstract**: Large Language Models (LLMs) are increasingly used to generate textual explanations of process models discovered from event logs. Producing explanations from large behavioral abstractions (e.g., directly-follows graphs or Petri nets) can be computationally expensive. This paper reports an exploratory evaluation of explanation quality under progressive behavioral-input reduction, where models are discovered from progressively smaller prefixes of a fixed log. Our pipeline (i) discovers models at multiple input sizes, (ii) prompts an LLM to generate explanations, and (iii) uses a second LLM to assess completeness, bottleneck identification, and suggested improvements. On synthetic logs, explanation quality is largely preserved under moderate reduction, indicating a practical cost-quality trade-off. The study is exploratory, as the scores are LLM-based (comparative signals rather than ground truth) and the data are synthetic. The results suggest a path toward more computationally efficient, LLM-assisted process analysis in resource-constrained settings. 

**Abstract (ZH)**: 大型语言模型在事件日志中发现的过程模型生成文本解释的应用中，随着行为输入逐步减少对解释质量的探索性评估 

---
# Herb.jl: A Unifying Program Synthesis Library 

**Title (ZH)**: Herb.jl: 一个统一的程序合成库 

**Authors**: Tilman Hinnerichs, Reuben Gardos Reid, Jaap de Jong, Bart Swinkels, Pamela Wochner, Nicolae Filat, Tudor Magurescu, Issa Hanou, Sebastijan Dumancic  

**Link**: [PDF](https://arxiv.org/pdf/2510.09726)  

**Abstract**: Program synthesis -- the automatic generation of code given a specification -- is one of the most fundamental tasks in artificial intelligence (AI) and many programmers' dream. Numerous synthesizers have been developed to tackle program synthesis, manifesting different ideas to approach the exponentially growing program space. While numerous smart program synthesis tools exist, reusing and remixing previously developed methods is tedious and time-consuming. We propose this http URL, a unifying program synthesis library written in the Julia programming language, to address these issues. Since current methods rely on similar building blocks, we aim to modularize the underlying synthesis algorithm into communicating and fully extendable sub-compartments, allowing for straightforward reapplication of these modules. To demonstrate the benefits of using this http URL, we show three common use cases: 1. how to implement a simple problem and grammar, and how to solve it, 2. how to implement a previously developed synthesizer with just a few lines of code, and 3. how to run a synthesizer against a benchmark. 

**Abstract (ZH)**: 程序合成——根据规范自动生成代码——是人工智能（AI）中最基本的任务之一，也是许多程序员的梦想。我们提出了一个用Julia编程语言编写的统一程序合成库URL（此处URL应替换为实际网址），以解决这些问题。由于当前的方法依赖于相似的基本构建块，我们的目标是将底层合成算法模块化为可通信和完全可扩展的子模块，从而便于重新应用这些模块。为了展示使用这个库的好处，我们展示了三种常见用例：1. 如何实现一个简单的程序和语法，并解决相关问题，2. 如何仅用几行代码实现一个先前开发的合成器，3. 如何在基准上运行一个合成器。 

---
# InteractScience: Programmatic and Visually-Grounded Evaluation of Interactive Scientific Demonstration Code Generation 

**Title (ZH)**: InteractScience: 基于程序和视觉-grounded 的交互式科学演示代码生成评估 

**Authors**: Qiaosheng Chen, Yang Liu, Lei Li, Kai Chen, Qipeng Guo, Gong Cheng, Fei Yuan  

**Link**: [PDF](https://arxiv.org/pdf/2510.09724)  

**Abstract**: Large Language Models (LLMs) are increasingly capable of generating complete applications from natural language instructions, creating new opportunities in science and education. In these domains, interactive scientific demonstrations are particularly valuable for explaining concepts, supporting new teaching methods, and presenting research findings. Generating such demonstrations requires models to combine accurate scientific knowledge with the ability to implement interactive front-end code that behaves correctly and responds to user actions. This capability goes beyond the scope of existing benchmarks, which typically evaluate either knowledge question answering without grounding in code or static web code generation without scientific interactivity. To evaluate this integrated ability, we design a hybrid framework that combines programmatic functional testing to rigorously verify interaction logic with visually-grounded qualitative testing to assess rendered outputs against reference snapshots. Building on this framework, we present InteractScience, a benchmark consisting of a substantial set of carefully designed questions across five scientific domains, each paired with unit tests, reference snapshots, and checklists. We evaluate 30 leading open- and closed-source LLMs and report results that highlight ongoing weaknesses in integrating domain knowledge with interactive front-end coding. Our work positions InteractScience as the first benchmark to automatically measure this combined capability with realistic interactive operations, providing a foundation for advancing reliable and educationally useful scientific demonstration code generation. All code and data are publicly available at this https URL. 

**Abstract (ZH)**: 大型语言模型（LLMs） increasingly capable of generating complete applications from natural language instructions, creating new opportunities in science and education. To evaluate this integrated ability, we design a hybrid framework that combines programmatic functional testing and visually-grounded qualitative testing, and present InteractScience, a benchmark for assessing the combined capability of integrating domain knowledge with interactive front-end coding across five scientific domains. 

---
# It's 2025 -- Narrative Learning is the new baseline to beat for explainable machine learning 

**Title (ZH)**: 2025年——叙述学习成为可解释机器学习的新基准 

**Authors**: Gregory D. Baker  

**Link**: [PDF](https://arxiv.org/pdf/2510.09723)  

**Abstract**: In this paper, we introduce Narrative Learning, a methodology where models are defined entirely in natural language and iteratively refine their classification criteria using explanatory prompts rather than traditional numerical optimisation. We report on experiments to evaluate the accuracy and potential of this approach using 3 synthetic and 3 natural datasets and compare them against 7 baseline explainable machine learning models. We demonstrate that on 5 out of 6 of these datasets, Narrative Learning became more accurate than the baseline explainable models in 2025 or earlier because of improvements in language models. We also report on trends in the lexicostatistics of these models' outputs as a proxy for the comprehensibility of the explanations. 

**Abstract (ZH)**: Narrative Learning：一种完全用自然语言定义模型并使用解释性提示迭代精炼分类标准的方法及其在2025年前在6个数据集中优于基线可解释机器学习模型的准确性和可解释性趋势研究 

---
# Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation 

**Title (ZH)**: 面向布局的解析与高效语言模型的融合：一种统一可扩展的简历信息提取与评估框架 

**Authors**: Fanwei Zhu, Jinke Yu, Zulong Chen, Ying Zhou, Junhao Ji, Zhibo Yang, Yuxue Zhang, Haoyuan Hu, Zhenghao Liu  

**Link**: [PDF](https://arxiv.org/pdf/2510.09722)  

**Abstract**: Automated resume information extraction is critical for scaling talent acquisition, yet its real-world deployment faces three major challenges: the extreme heterogeneity of resume layouts and content, the high cost and latency of large language models (LLMs), and the lack of standardized datasets and evaluation tools. In this work, we present a layout-aware and efficiency-optimized framework for automated extraction and evaluation that addresses all three challenges. Our system combines a fine-tuned layout parser to normalize diverse document formats, an inference-efficient LLM extractor based on parallel prompting and instruction tuning, and a robust two-stage automated evaluation framework supported by new benchmark datasets. Extensive experiments show that our framework significantly outperforms strong baselines in both accuracy and efficiency. In particular, we demonstrate that a fine-tuned compact 0.6B LLM achieves top-tier accuracy while significantly reducing inference latency and computational cost. The system is fully deployed in Alibaba's intelligent HR platform, supporting real-time applications across its business units. 

**Abstract (ZH)**: 自动简历信息提取对于扩展人才收购至关重要，但在实际部署中面临着三大挑战：简历布局和内容的极度异质性、大型语言模型的成本和延迟问题，以及缺乏标准化的数据集和评估工具。本文提出了一种兼顾布局aware和效率优化的自动提取与评估框架，以应对上述三大挑战。我们的系统结合了一种微调布局解析器来规范化各种文档格式，基于并行提示和指令微调的高效推理大型语言模型提取器，以及由新的基准数据集支持的 robust 两阶段自动评估框架。大规模实验表明，我们的框架在准确性和效率上显著优于强基线。特别是，我们证明了一种微调的紧凑型0.6B大型语言模型在显著降低推理延迟和计算成本的同时实现了顶级的准确度。该系统已在阿里巴巴智能HR平台上全面部署，支持其各个业务单元的实时应用。 

---
# Preference-Aware Memory Update for Long-Term LLM Agents 

**Title (ZH)**: 带有偏好意识的记忆更新机制增强长期LLM代理 

**Authors**: Haoran Sun, Zekun Zhang, Shaoning Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2510.09720)  

**Abstract**: One of the key factors influencing the reasoning capabilities of LLM-based agents is their ability to leverage long-term memory. Integrating long-term memory mechanisms allows agents to make informed decisions grounded in historical interactions. While recent advances have significantly improved the storage and retrieval components, by encoding memory into dense vectors for similarity search or organizing memory as structured knowledge graphs most existing approaches fall short in memory updating. In particular, they lack mechanisms for dynamically refining preference memory representations in response to evolving user behaviors and contexts. To address this gap, we propose a Preference-Aware Memory Update Mechanism (PAMU) that enables dynamic and personalized memory refinement. By integrating sliding window averages (SW) with exponential moving averages (EMA), PAMU constructs a fused preference-aware representation that captures both short-term fluctuations and long-term user tendencies. We conduct experiments on five task scenarios of the LoCoMo dataset, and the results show that our mechanism can significantly improve the output quality of LLM in five baselines, validating its effectiveness in long-term conversations. 

**Abstract (ZH)**: 基于偏好感知的记忆更新机制：改进长短期记忆对语言模型推理能力的影响 

---
# ICL-Router: In-Context Learned Model Representations for LLM Routing 

**Title (ZH)**: ICL-Router：基于上下文学习的LLM路由模型表示 

**Authors**: Chenxu Wang, Hao Li, Yiqun Zhang, Linyao Chen, Jianhao Chen, Ping Jian, Peng Ye, Qiaosheng Zhang, Shuyue Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.09719)  

**Abstract**: Large language models (LLMs) often exhibit complementary strengths. Model routing harnesses these strengths by dynamically directing each query to the most suitable model, given a candidate model pool. However, routing performance relies on accurate model representations, and adding new models typically requires retraining, limiting scalability. To address these challenges, we propose a novel routing method using in-context vectors to represent model capabilities. The method proceeds in two stages. First, queries are embedded and projected into vectors, with a projector and LLM-based router trained to reconstruct the original queries, aligning vector representations with the router's semantic space. Second, each candidate model is profiled on a query set, and the router learns -- based on in-context vectors of query and model performance -- to predict whether each model can correctly answer new queries. Extensive experiments demonstrate that our method achieves state-of-the-art routing performance in both in-distribution and out-of-distribution tasks. Moreover, our method allows for seamless integration of new models without retraining the router. The code is available at this https URL. 

**Abstract (ZH)**: 大规模语言模型（LLMs）往往表现出互补的优势。模型路由通过动态将每个查询导向最适合的模型来利用这些优势，给定一个候选模型池。然而，路由性能依赖于准确的模型表示，并且添加新模型通常需要重新训练，这限制了可扩展性。为了应对这些挑战，我们提出了一种使用上下文相关向量表示模型能力的新型路由方法。该方法分为两个阶段。首先，查询被嵌入并投影成向量，通过训练投影器和基于LLM的路由器来重构原始查询，使向量表示与路由器的语义空间对齐。其次，每个候选模型在一组查询上进行配置，路由器基于查询和模型表现的上下文相关向量来学习预测每个模型能否正确回答新查询。广泛的实验表明，我们的方法在分布内和分布外任务中都达到了最先进的路由性能。此外，我们的方法允许无缝集成新模型而无需重新训练路由器。代码可在以下链接获得。 

---
# High-Power Training Data Identification with Provable Statistical Guarantees 

**Title (ZH)**: 具有可证明统计保证的高功率训练数据识别 

**Authors**: Zhenlong Liu, Hao Zeng, Weiran Huang, Hongxin Wei  

**Link**: [PDF](https://arxiv.org/pdf/2510.09717)  

**Abstract**: Identifying training data within large-scale models is critical for copyright litigation, privacy auditing, and ensuring fair evaluation. The conventional approaches treat it as a simple binary classification task without statistical guarantees. A recent approach is designed to control the false discovery rate (FDR), but its guarantees rely on strong, easily violated assumptions. In this paper, we introduce Provable Training Data Identification (PTDI), a rigorous method that identifies a set of training data with strict false discovery rate (FDR) control. Specifically, our method computes p-values for each data point using a set of known unseen data, and then constructs a conservative estimator for the data usage proportion of the test set, which allows us to scale these p-values. Our approach then selects the final set of training data by identifying all points whose scaled p-values fall below a data-dependent threshold. This entire procedure enables the discovery of training data with provable, strict FDR control and significantly boosted power. Extensive experiments across a wide range of models (LLMs and VLMs), and datasets demonstrate that PTDI strictly controls the FDR and achieves higher power. 

**Abstract (ZH)**: 可证明训练数据识别（PTDI）：严格控制误发现率的方法 

---
# All Code, No Thought: Current Language Models Struggle to Reason in Ciphered Language 

**Title (ZH)**: 所有代码，无思路：当前的语言模型在加密语言中 struggle 进行推理 

**Authors**: Shiyuan Guo, Henry Sleight, Fabien Roger  

**Link**: [PDF](https://arxiv.org/pdf/2510.09714)  

**Abstract**: Detecting harmful AI actions is important as AI agents gain adoption. Chain-of-thought (CoT) monitoring is one method widely used to detect adversarial attacks and AI misalignment. However, attackers and misaligned models might evade CoT monitoring through ciphered reasoning: reasoning hidden in encrypted, translated, or compressed text. To assess this risk, we test whether models can perform ciphered reasoning. For each of 28 different ciphers, we fine-tune and prompt up to 10 models to reason in that cipher. We measure model accuracy on math problems as a proxy for reasoning ability. Across the models we test, we find an asymmetry: model accuracy can drop significantly when reasoning in ciphered text, even though models demonstrate comprehension of ciphered text by being able to translate it accurately to English. Even frontier models struggle with lesser-known ciphers, although they can reason accurately in well-known ciphers like rot13. We show that ciphered reasoning capability correlates with cipher prevalence in pretraining data. We also identify scaling laws showing that ciphered reasoning capability improves slowly with additional fine-tuning data. Our work suggests that evading CoT monitoring using ciphered reasoning may be an ineffective tactic for current models and offers guidance on constraining the development of this capability in future frontier models. 

**Abstract (ZH)**: 检测有害AI行为至关重要，尤其是在AI代理广泛采用的情况下。链式思考（CoT）监控是广泛用于检测对抗攻击和AI失衡的一种方法。然而，攻击者和失衡模型可能通过加密推理（即隐藏在加密、翻译或压缩文本中的推理）来规避CoT监控。为了评估这一风险，我们测试模型是否能够进行加密推理。我们对28种不同的密码系统，分别对多达10个模型进行微调并提示它们进行加密推理。我们通过测量模型在数学问题上的准确率来代理推理能力。在测试的模型中，我们发现一种不对称性：当推理使用加密文本时，模型的准确率可能会显著下降，尽管模型能够准确地将加密文本翻译成英语展示其理解能力。即使处于前沿的模型也难以处理不太知名的密码系统，尽管它们能在熟悉的密码系统（如rot13）中准确推理。我们显示了加密推理能力与预训练数据中密码系统的普及程度之间存在关联。我们还发现规模律表明，加密推理能力随着额外微调数据的增加仅缓慢提高。我们的工作表明，当前模型使用加密推理规避CoT监控可能是无效的战术，并为未来前沿模型限制发展此类能力提供了指导。 

---
# Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments 

**Title (ZH)**: 针对恶意评论的鲁棒假新闻检测的组自适应对抗学习方法 

**Authors**: Zhao Tong, Chunlin Gong, Yimeng Gu, Haichao Shi, Qiang Liu, Shu Wu, Xiao-Yu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09712)  

**Abstract**: The spread of fake news online distorts public judgment and erodes trust in social media platforms. Although recent fake news detection (FND) models perform well in standard settings, they remain vulnerable to adversarial comments-authored by real users or by large language models (LLMs)-that subtly shift model decisions. In view of this, we first present a comprehensive evaluation of comment attacks to existing fake news detectors and then introduce a group-adaptive adversarial training strategy to improve the robustness of FND models. To be specific, our approach comprises three steps: (1) dividing adversarial comments into three psychologically grounded categories: perceptual, cognitive, and societal; (2) generating diverse, category-specific attacks via LLMs to enhance adversarial training; and (3) applying a Dirichlet-based adaptive sampling mechanism (InfoDirichlet Adjusting Mechanism) that dynamically adjusts the learning focus across different comment categories during training. Experiments on benchmark datasets show that our method maintains strong detection accuracy while substantially increasing robustness to a wide range of adversarial comment perturbations. 

**Abstract (ZH)**: 在线虚假新闻的传播扭曲了公众判断并侵蚀了对社交媒体平台的信任。尽管现有的虚假新闻检测模型在标准设置下表现出色，但它们仍然容易受到真实用户或大规模语言模型撰写的 adversarial comments 的攻击，这些评论会微妙地改变模型的决策。鉴于此，我们首先对现有虚假新闻检测器的评论攻击进行全面评估，然后提出了一种分组自适应对抗训练策略以提高虚假新闻检测模型的鲁棒性。具体而言，我们的方法包括三个步骤：（1）将 adversarial comments 分为三个基于心理的类别：知觉、认知和社会；（2）通过大规模语言模型生成多样化的、类别特定的攻击以增强对抗训练；（3）应用基于Dirichlet的自适应采样机制（信息Dirichlet调整机制），在训练过程中动态调整不同类别评论的学习重点。基准数据集上的实验表明，我们的方法在保持强检测准确性的同时，显著增强了对广泛类型的 adversarial comment 干扰的鲁棒性。 

---
# ReaLM: Residual Quantization Bridging Knowledge Graph Embeddings and Large Language Models 

**Title (ZH)**: ReaLM：残差量化连接知识图嵌入与大型语言模型 

**Authors**: Wenbin Guo, Xin Wang, Jiaoyan Chen, Lingbing Guo, Zhao Li, Zirui Chen  

**Link**: [PDF](https://arxiv.org/pdf/2510.09711)  

**Abstract**: Large Language Models (LLMs) have recently emerged as a powerful paradigm for Knowledge Graph Completion (KGC), offering strong reasoning and generalization capabilities beyond traditional embedding-based approaches. However, existing LLM-based methods often struggle to fully exploit structured semantic representations, as the continuous embedding space of pretrained KG models is fundamentally misaligned with the discrete token space of LLMs. This discrepancy hinders effective semantic transfer and limits their performance. To address this challenge, we propose ReaLM, a novel and effective framework that bridges the gap between KG embeddings and LLM tokenization through the mechanism of residual vector quantization. ReaLM discretizes pretrained KG embeddings into compact code sequences and integrates them as learnable tokens within the LLM vocabulary, enabling seamless fusion of symbolic and contextual knowledge. Furthermore, we incorporate ontology-guided class constraints to enforce semantic consistency, refining entity predictions based on class-level compatibility. Extensive experiments on two widely used benchmark datasets demonstrate that ReaLM achieves state-of-the-art performance, confirming its effectiveness in aligning structured knowledge with large-scale language models. 

**Abstract (ZH)**: 大规模语言模型（LLMs） recently emerged as a强大的范式用于知识图谱补全（KGC），提供了超越传统基于嵌入的方法的强大推理和泛化能力。然而，现有的基于LLM的方法往往难以充分利用结构化的语义表示，因为预训练知识图谱模型的连续嵌入空间与大型语言模型的离散令牌空间本质不匹配。这种不匹配阻碍了有效的语义转移并限制了其性能。为了解决这一挑战，我们提出了一种名为ReaLM的新颖且有效的框架，通过残差向量量化机制在KG嵌入和LLM分词之间建立桥梁。ReaLM将预训练的KG嵌入离散化为紧凑的代码序列，并将其作为可学习的令牌整合到LLM词汇表中，从而使符号和上下文知识的融合无缝进行。此外，我们引入了本体引导的类别约束以确保语义一致性，并根据类别级别的兼容性细化实体预测。在两个广泛使用的基准数据集上的广泛实验表明，ReaLM达到了最先进的性能，验证了其在将结构化知识与大规模语言模型对齐方面的有效性。 

---
# SeCon-RAG: A Two-Stage Semantic Filtering and Conflict-Free Framework for Trustworthy RAG 

**Title (ZH)**: SeCon-RAG: 一种两阶段语义过滤和冲突-Free框架以实现可信赖的RAG 

**Authors**: Xiaonan Si, Meilin Zhu, Simeng Qin, Lijia Yu, Lijun Zhang, Shuaitong Liu, Xinfeng Li, Ranjie Duan, Yang Liu, Xiaojun Jia  

**Link**: [PDF](https://arxiv.org/pdf/2510.09710)  

**Abstract**: Retrieval-augmented generation (RAG) systems enhance large language models (LLMs) with external knowledge but are vulnerable to corpus poisoning and contamination attacks, which can compromise output integrity. Existing defenses often apply aggressive filtering, leading to unnecessary loss of valuable information and reduced reliability in generation. To address this problem, we propose a two-stage semantic filtering and conflict-free framework for trustworthy RAG. In the first stage, we perform a joint filter with semantic and cluster-based filtering which is guided by the Entity-intent-relation extractor (EIRE). EIRE extracts entities, latent objectives, and entity relations from both the user query and filtered documents, scores their semantic relevance, and selectively adds valuable documents into the clean retrieval database. In the second stage, we proposed an EIRE-guided conflict-aware filtering module, which analyzes semantic consistency between the query, candidate answers, and retrieved knowledge before final answer generation, filtering out internal and external contradictions that could mislead the model. Through this two-stage process, SeCon-RAG effectively preserves useful knowledge while mitigating conflict contamination, achieving significant improvements in both generation robustness and output trustworthiness. Extensive experiments across various LLMs and datasets demonstrate that the proposed SeCon-RAG markedly outperforms state-of-the-art defense methods. 

**Abstract (ZH)**: 基于检索增强生成的可信两阶段语义过滤和冲突免费框架 

---
# The Idola Tribus of AI: Large Language Models tend to perceive order where none exists 

**Title (ZH)**: AI中的tribus谬误：大型语言模型倾向于在不存在秩序的地方感知秩序 

**Authors**: Shin-nosuke Ishikawa, Masato Todo, Taiki Ogihara, Hirotsugu Ohba  

**Link**: [PDF](https://arxiv.org/pdf/2510.09709)  

**Abstract**: We present a tendency of large language models (LLMs) to generate absurd patterns despite their clear inappropriateness in a simple task of identifying regularities in number series. Several approaches have been proposed to apply LLMs to complex real-world tasks, such as providing knowledge through retrieval-augmented generation and executing multi-step tasks using AI agent frameworks. However, these approaches rely on the logical consistency and self-coherence of LLMs, making it crucial to evaluate these aspects and consider potential countermeasures. To identify cases where LLMs fail to maintain logical consistency, we conducted an experiment in which LLMs were asked to explain the patterns in various integer sequences, ranging from arithmetic sequences to randomly generated integer series. While the models successfully identified correct patterns in arithmetic and geometric sequences, they frequently over-recognized patterns that were inconsistent with the given numbers when analyzing randomly generated series. This issue was observed even in multi-step reasoning models, including OpenAI o3, o4-mini, and Google Gemini 2.5 Flash Preview Thinking. This tendency to perceive non-existent patterns can be interpreted as the AI model equivalent of Idola Tribus and highlights potential limitations in their capability for applied tasks requiring logical reasoning, even when employing chain-of-thought reasoning mechanisms. 

**Abstract (ZH)**: 大型语言模型在识别数列规律任务中生成不合理模式的趋势及其应对策略 

---
# A Demonstration of Self-Adaptive Jamming Attack Detection in AI/ML Integrated O-RAN 

**Title (ZH)**: 自适应干扰攻击检测在AI/ML集成O-RAN中的演示 

**Authors**: Md Habibur Rahman, Md Sharif Hossen, Nathan H. Stephenson, Vijay K. Shah, Aloizio Da Silva  

**Link**: [PDF](https://arxiv.org/pdf/2510.09706)  

**Abstract**: The open radio access network (O-RAN) enables modular, intelligent, and programmable 5G network architectures through the adoption of software-defined networking, network function virtualization, and implementation of standardized open interfaces. However, one of the security concerns for O-RAN, which can severely undermine network performance, is jamming attacks. This paper presents SAJD- a self-adaptive jammer detection framework that autonomously detects jamming attacks in AI/ML framework-integrated ORAN environments without human intervention. The SAJD framework forms a closed-loop system that includes near-realtime inference of radio signal jamming via our developed ML-based xApp, as well as continuous monitoring and retraining pipelines through rApps. In this demonstration, we will show how SAJD outperforms state-of-the-art jamming detection xApp (offline trained with manual labels) in terms of accuracy and adaptability under various dynamic and previously unseen interference scenarios in the O-RAN-compliant testbed. 

**Abstract (ZH)**: 基于AI/ML框架的自适应射频 jammer 检测框架：SAJD 

---
# VisualDAN: Exposing Vulnerabilities in VLMs with Visual-Driven DAN Commands 

**Title (ZH)**: VisualDAN: 以视觉驱动DAN命令揭示VLMs的漏洞 

**Authors**: Aofan Liu, Lulu Tang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09699)  

**Abstract**: Vision-Language Models (VLMs) have garnered significant attention for their remarkable ability to interpret and generate multimodal content. However, securing these models against jailbreak attacks continues to be a substantial challenge. Unlike text-only models, VLMs integrate additional modalities, introducing novel vulnerabilities such as image hijacking, which can manipulate the model into producing inappropriate or harmful responses. Drawing inspiration from text-based jailbreaks like the "Do Anything Now" (DAN) command, this work introduces VisualDAN, a single adversarial image embedded with DAN-style commands. Specifically, we prepend harmful corpora with affirmative prefixes (e.g., "Sure, I can provide the guidance you need") to trick the model into responding positively to malicious queries. The adversarial image is then trained on these DAN-inspired harmful texts and transformed into the text domain to elicit malicious outputs. Extensive experiments on models such as MiniGPT-4, MiniGPT-v2, InstructBLIP, and LLaVA reveal that VisualDAN effectively bypasses the safeguards of aligned VLMs, forcing them to execute a broad range of harmful instructions that severely violate ethical standards. Our results further demonstrate that even a small amount of toxic content can significantly amplify harmful outputs once the model's defenses are compromised. These findings highlight the urgent need for robust defenses against image-based attacks and offer critical insights for future research into the alignment and security of VLMs. 

**Abstract (ZH)**: 视觉-语言模型（VLMs）因其出色的多模态内容解释和生成能力而备受关注。然而，如何抵御模型逃逸攻击仍然是一个重大挑战。与仅基于文本的模型不同，VLMs整合了额外的模态，引入了新的漏洞，如图像劫持，可以操纵模型生成不适当或有害的响应。受基于文本的模型逃逸攻击，如“现在你可以做任何事”（DAN）命令的启发，本文引入了VisualDAN，这是一种嵌入了DAN风格命令的单一对抗性图像。具体而言，我们在有害内容前加上肯定前缀（例如，“当然，我可以提供你需要的指导”），以使模型对恶意查询做出积极响应。然后，对抗性图像在这些DAN启发的有害文本上进行训练，并转换到文本域，以触发恶意输出。对MiniGPT-4、MiniGPT-v2、InstructBLIP和LLaVA等模型的广泛实验表明，VisualDAN能够有效绕过对齐的VLMs的安全措施，迫使它们执行一系列严重违反伦理标准的有害指令。我们的结果进一步表明，即使少量的有毒内容，在模型防护被破解的情况下，也能显著放大有害输出。这些发现强调了对基于图像的攻击进行 robust 防护的迫切需求，并为未来VLMs的对齐和安全性研究提供了关键见解。 

---
# Vanishing Contributions: A Unified Approach to Smoothly Transition Neural Models into Compressed Form 

**Title (ZH)**: 消失的贡献：平滑过渡神经模型至压缩形式的一体化方法 

**Authors**: Lorenzo Nikiforos, Charalampos Antoniadis, Luciano Prono, Fabio Pareschi, Riccardo Rovatti, Gianluca Setti  

**Link**: [PDF](https://arxiv.org/pdf/2510.09696)  

**Abstract**: The increasing scale of deep neural networks has led to a growing need for compression techniques such as pruning, quantization, and low-rank decomposition. While these methods are very effective in reducing memory, computation and energy consumption, they often introduce severe accuracy degradation when applied directly. We introduce Vanishing Contributions (VCON), a general approach for smoothly transitioning neural models into compressed form. Rather than replacing the original network directly with its compressed version, VCON executes the two in parallel during fine-tuning. The contribution of the original (uncompressed) model is progressively reduced, while that of the compressed model is gradually increased. This smooth transition allows the network to adapt over time, improving stability and mitigating accuracy degradation. We evaluate VCON across computer vision and natural language processing benchmarks, in combination with multiple compression strategies. Across all scenarios, VCON leads to consistent improvements: typical gains exceed 3%, while some configuration exhibits accuracy boosts of 20%. VCON thus provides a generalizable method that can be applied to the existing compression techniques, with evidence of consistent gains across multiple benchmarks. 

**Abstract (ZH)**: 深度神经网络规模的增加导致了压缩技术（如剪枝、量化和低秩分解）需求的增长。虽然这些方法在减少内存、计算和能耗方面非常有效，但在直接应用时通常会导致严重的准确率下降。我们引入了消失贡献（VCON）方法，这是一种使神经网络平滑过渡到压缩形式的通用方法。VCON不直接用压缩网络替换原始网络，而是在微调过程中并行执行两者。原始（未压缩）模型的贡献逐渐减少，而压缩模型的贡献逐渐增加。这种平滑过渡使网络能够随着时间调整，提高稳定性和减轻准确率下降。我们在计算机视觉和自然语言处理基准上评估了VCON，结合了多种压缩策略。在所有场景中，VCON都带来了持续改进：典型增益超过3%，而某些配置的准确率提升高达20%。因此，VCON提供了一种可应用于现有压缩技术的通用方法，并且在多个基准测试中表现出一致的增益。 

---
# Kelp: A Streaming Safeguard for Large Models via Latent Dynamics-Guided Risk Detection 

**Title (ZH)**: Kelp: 一种通过潜在动力学指导的风险检测.streaming安全保障大模型 

**Authors**: Xiaodan Li, Mengjie Wu, Yao Zhu, Yunna Lv, YueFeng Chen, Cen Chen, Jianmei Guo, Hui Xue  

**Link**: [PDF](https://arxiv.org/pdf/2510.09694)  

**Abstract**: Large models (LMs) are powerful content generators, yet their open-ended nature can also introduce potential risks, such as generating harmful or biased content. Existing guardrails mostly perform post-hoc detection that may expose unsafe content before it is caught, and the latency constraints further push them toward lightweight models, limiting detection accuracy. In this work, we propose Kelp, a novel plug-in framework that enables streaming risk detection within the LM generation pipeline. Kelp leverages intermediate LM hidden states through a Streaming Latent Dynamics Head (SLD), which models the temporal evolution of risk across the generated sequence for more accurate real-time risk detection. To ensure reliable streaming moderation in real applications, we introduce an Anchored Temporal Consistency (ATC) loss to enforce monotonic harm predictions by embedding a benign-then-harmful temporal prior. Besides, for a rigorous evaluation of streaming guardrails, we also present StreamGuardBench-a model-grounded benchmark featuring on-the-fly responses from each protected model, reflecting real-world streaming scenarios in both text and vision-language tasks. Across diverse models and datasets, Kelp consistently outperforms state-of-the-art post-hoc guardrails and prior plug-in probes (15.61% higher average F1), while using only 20M parameters and adding less than 0.5 ms of per-token latency. 

**Abstract (ZH)**: Large模型（LMs）是强大的内容生成工具，但其开放性也可能引入潜在风险，如生成有害或有偏见的内容。现有的防护栏大多是事后检测，可能在内容被发现之前就已经暴露了不安全的内容，而且延迟限制进一步推动它们采用轻量级模型，从而限制了检测准确性。在本文中，我们提出了一种名为Kelp的新型插件框架，可以在LM生成管道中实现流式风险检测。Kelp利用Streaming Latent Dynamics Head (SLD) 中间隐藏状态，模型生成序列中的风险随时间演变以实现更准确的实时风险检测。为了确保实际应用中的可靠流式内容审核，我们引入了锚定时间一致性（ATC）损失，以通过嵌入良性然后有害的时间先验来强制执行单调的有害性预测。此外，为了对流式防护栏进行严谨评估，我们还提出了StreamGuardBench，这是一种基于模型的基准，每个保护模型都能提供即时响应，反映了文本和视觉语言任务中的实际流式场景。在多种模型和数据集上，Kelp 在平均F1分数上持续优于最先进的事后防护栏和先前的插件探针（高出15.61%），同时仅使用20M参数并在每个token上增加不到0.5 ms的延迟。 

---
# Evaluation of Differential Privacy Mechanisms on Federated Learning 

**Title (ZH)**: 联邦学习中差分隐私机制的评估 

**Authors**: Tejash Varsani  

**Link**: [PDF](https://arxiv.org/pdf/2510.09691)  

**Abstract**: Federated learning is distributed model training across several clients without disclosing raw data. Despite advancements in data privacy, risks still remain. Differential Privacy (DP) is a technique to protect sensitive data by adding noise to model updates, usually controlled by a fixed privacy budget. However, this approach can introduce excessive noise, particularly when the model converges, which compromises performance. To address this problem, adaptive privacy budgets have been investigated as a potential solution. This work implements DP methods using Laplace and Gaussian mechanisms with an adaptive privacy budget, extending the SelecEval simulator. We introduce an adaptive clipping approach in the Gaussian mechanism, ensuring that gradients of the model are dynamically updated rather than using a fixed sensitivity. We conduct extensive experiments with various privacy budgets, IID and non-IID datasets, and different numbers of selected clients per round. While our experiments were limited to 200 training rounds, the results suggest that adaptive privacy budgets and adaptive clipping can help maintain model accuracy while preserving privacy. 

**Abstract (ZH)**: federated learning是通过多个客户端进行模型训练而不披露原始数据的技术。尽管在数据隐私方面取得了进展，风险仍然存在。差分隐私（DP）是一种通过在模型更新中添加噪声来保护敏感数据的技术，通常由固定隐私预算控制。然而，这种方法可能会在模型收敛时引入过多噪声，从而损害性能。为了解决这一问题，已经探索了可 adapters 隐私预算作为潜在的解决方案。本文使用拉普拉斯机制和高斯机制实现DP方法，并扩展了SelecEval模拟器，引入了高斯机制中的自适应裁剪方法，确保模型梯度动态更新而不是使用固定灵敏度。我们使用各种隐私预算、IID和非IID数据集以及每轮不同数量的选择客户端进行了广泛的实验。尽管我们的实验仅限于200轮训练，但结果表明，可 adapters 隐私预算和自适应裁剪有助于保持模型准确性同时保护隐私。 

---
# CREST-Search: Comprehensive Red-teaming for Evaluating Safety Threats in Large Language Models Powered by Web Search 

**Title (ZH)**: CREST-Search: 综合红队技术评估基于网络搜索的大语言模型安全威胁 

**Authors**: Haoran Ou, Kangjie Chen, Xingshuo Han, Gelei Deng, Jie Zhang, Han Qiu, Tianwei Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09689)  

**Abstract**: Large Language Models (LLMs) excel at tasks such as dialogue, summarization, and question answering, yet they struggle to adapt to specialized domains and evolving facts. To overcome this, web search has been integrated into LLMs, allowing real-time access to online content. However, this connection magnifies safety risks, as adversarial prompts combined with untrusted sources can cause severe vulnerabilities. We investigate red teaming for LLMs with web search and present CREST-Search, a framework that systematically exposes risks in such systems. Unlike existing methods for standalone LLMs, CREST-Search addresses the complex workflow of search-enabled models by generating adversarial queries with in-context learning and refining them through iterative feedback. We further construct WebSearch-Harm, a search-specific dataset to fine-tune LLMs into efficient red-teaming agents. Experiments show that CREST-Search effectively bypasses safety filters and reveals vulnerabilities in modern web-augmented LLMs, underscoring the need for specialized defenses to ensure trustworthy deployment. 

**Abstract (ZH)**: 大型语言模型（LLMs）在对话、总结和问答等任务上表现出色，但在适应专业化领域和不断变化的事实方面存在困难。为解决这一问题，已将网络搜索集成到LLMs中，使其能够实时访问在线内容。然而，这种连接放大了安全风险，因为恶意提示与不可信来源相结合可能导致严重的安全漏洞。我们研究了带有网络搜索的LLM的红队攻击，并介绍了CREST-Search框架，该框架系统地揭示了此类系统的风险。与现有针对独立LLM的方法不同，CREST-Search通过基于情境的学习生成恶意查询，并通过迭代反馈进行优化。我们进一步构建了WebSearch-Harm数据集，用于微调LLM成为高效的红队攻击代理。实验结果表明，CREST-Search能够有效规避安全过滤器，并揭露现代网络增强LLM的安全漏洞，突显了为确保可信部署而采取专门防护措施的必要性。 

---
# On the Occurence of Critical Learning Periods in Neural Networks 

**Title (ZH)**: 神经网络中的关键学习期发生研究 

**Authors**: Stanisław Pawlak  

**Link**: [PDF](https://arxiv.org/pdf/2510.09687)  

**Abstract**: This study delves into the plasticity of neural networks, offering empirical support for the notion that critical learning periods and warm-starting performance loss can be avoided through simple adjustments to learning hyperparameters. The critical learning phenomenon emerges when training is initiated with deficit data. Subsequently, after numerous deficit epochs, the network's plasticity wanes, impeding its capacity to achieve parity in accuracy with models trained from scratch, even when extensive clean data training follows deficit epochs. Building upon seminal research introducing critical learning periods, we replicate key findings and broaden the experimental scope of the main experiment from the original work. In addition, we consider a warm-starting approach and show that it can be seen as a form of deficit pretraining. In particular, we demonstrate that these problems can be averted by employing a cyclic learning rate schedule. Our findings not only impact neural network training practices but also establish a vital link between critical learning periods and ongoing research on warm-starting neural network training. 

**Abstract (ZH)**: 本研究探讨了神经网络的可塑性，提供了通过简单调整学习超参数来避免关键学习期和性能损失的实证支持。当训练初始使用缺陷数据时会出现关键学习现象。经过多个缺陷周期后，网络的可塑性减弱，即使后续使用大量干净数据进行训练，其准确度也无法与从头开始训练的模型相匹敌。基于引入关键学习期的开创性研究，我们复制了关键发现并扩大了主要实验的实验范围。此外，我们考虑了一种预热启动方法，并表明这可以被视为一种缺陷预训练形式。特别是，我们证明通过使用周期性学习率调度可以避免这些问题。本研究不仅影响神经网络训练实践，还建立了关键学习期与神经网络训练预热启动领域研究的相关性。 

---
# Stop DDoS Attacking the Research Community with AI-Generated Survey Papers 

**Title (ZH)**: 使用AI生成的调查论文遏制DDoS攻击科研社区 

**Authors**: Jianghao Lin, Rong Shan, Jiachen Zhu, Yunjia Xi, Yong Yu, Weinan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09686)  

**Abstract**: Survey papers are foundational to the scholarly progress of research communities, offering structured overviews that guide both novices and experts across disciplines. However, the recent surge of AI-generated surveys, especially enabled by large language models (LLMs), has transformed this traditionally labor-intensive genre into a low-effort, high-volume output. While such automation lowers entry barriers, it also introduces a critical threat: the phenomenon we term the "survey paper DDoS attack" to the research community. This refers to the unchecked proliferation of superficially comprehensive but often redundant, low-quality, or even hallucinated survey manuscripts, which floods preprint platforms, overwhelms researchers, and erodes trust in the scientific record. In this position paper, we argue that we must stop uploading massive amounts of AI-generated survey papers (i.e., survey paper DDoS attack) to the research community, by instituting strong norms for AI-assisted review writing. We call for restoring expert oversight and transparency in AI usage and, moreover, developing new infrastructures such as Dynamic Live Surveys, community-maintained, version-controlled repositories that blend automated updates with human curation. Through quantitative trend analysis, quality audits, and cultural impact discussion, we show that safeguarding the integrity of surveys is no longer optional but imperative to the research community. 

**Abstract (ZH)**: 我们必须停止上传大量AI生成的综述论文（即综述论文DDoS攻击）并引进强规范以辅助AI同行评审写作，以恢复专家监督和透明度，并开发新的基础设施如动态实时综述，以维护综述的完整性。 

---
# Deep Neural Networks Inspired by Differential Equations 

**Title (ZH)**: 受微分方程启发的深度神经网络 

**Authors**: Yongshuai Liu, Lianfang Wang, Kuilin Qin, Qinghua Zhang, Faqiang Wang, Li Cui, Jun Liu, Yuping Duan, Tieyong Zeng  

**Link**: [PDF](https://arxiv.org/pdf/2510.09685)  

**Abstract**: Deep learning has become a pivotal technology in fields such as computer vision, scientific computing, and dynamical systems, significantly advancing these disciplines. However, neural Networks persistently face challenges related to theoretical understanding, interpretability, and generalization. To address these issues, researchers are increasingly adopting a differential equations perspective to propose a unified theoretical framework and systematic design methodologies for neural networks. In this paper, we provide an extensive review of deep neural network architectures and dynamic modeling methods inspired by differential equations. We specifically examine deep neural network models and deterministic dynamical network constructs based on ordinary differential equations (ODEs), as well as regularization techniques and stochastic dynamical network models informed by stochastic differential equations (SDEs). We present numerical comparisons of these models to illustrate their characteristics and performance. Finally, we explore promising research directions in integrating differential equations with deep learning to offer new insights for developing intelligent computational methods that boast enhanced interpretability and generalization capabilities. 

**Abstract (ZH)**: 深度学习已成为计算机视觉、科学计算和动力系统等领域的关键技术，显著推动了这些学科的发展。然而，神经网络仍然面临理论理解、解释性和泛化能力等方面的挑战。为解决这些问题，研究人员越来越多地采用微分方程的观点，提出统一的理论框架和系统的设计方法。本文提供了深度神经网络架构和受微分方程启发的动态建模方法的全面综述。我们具体探讨了基于常微分方程（ODEs）的深层神经网络模型和确定性动态网络结构，以及基于随机微分方程（SDEs）的正则化技术和随机动态网络模型。我们通过数值比较展示了这些模型的特性与性能。最后，我们探讨了将微分方程与深度学习结合的研究方向，为开发具有增强解释性和泛化能力的智能计算方法提供新的见解。 

---
# Fortifying LLM-Based Code Generation with Graph-Based Reasoning on Secure Coding Practices 

**Title (ZH)**: 基于图推理的安全编码实践增强的LLM代码生成 

**Authors**: Rupam Patir, Keyan Guo, Haipeng Cai, Hongxin Hu  

**Link**: [PDF](https://arxiv.org/pdf/2510.09682)  

**Abstract**: The code generation capabilities of Large Language Models (LLMs) have transformed the field of software development. However, this advancement also presents significant security challenges, as LLM-generated code often contains vulnerabilities. One direction of research strengthens LLMs by injecting or refining security knowledge through curated datasets, model tuning, or static analyzers. While effective in certain settings, these methods can be resource-intensive, less adaptable to zero-day vulnerabilities, and often inapplicable to proprietary models. To address these challenges, we introduce GRASP, which explores a new direction that focuses on structured reasoning over Secure Coding Practices(SCPs) rather than additional training or external feedback. GRASP comprises two key ideas: (1) an SCP graph that organizes SCPs into a Directed Acyclic Graph (DAG) capturing dependencies and relationships, and (2) a graph-based reasoning process that systematically guides LLMs through relevant SCPs for code generation. This design enables interpretable, model-agnostic, and scalable security improvements, particularly for previously unseen vulnerabilities. Our evaluation shows that GRASP consistently achieves Security Rates (SR) exceeding 80% across multiple LLMs, and delivers up to 88% improvements over baselines on zero-day vulnerabilities. 

**Abstract (ZH)**: 大型语言模型的代码生成能力已彻底改变软件开发领域。然而，这一进展也带来了重要的安全挑战，因为由大型语言模型生成的代码常常包含漏洞。一种研究方向是通过精心整理的数据集、模型调优或静态分析器注入或精炼安全知识，来增强大型语言模型。尽管这些方法在某些设置中有效，但它们往往资源密集、对零日漏洞的适应性较差，并且常常不适用于专有模型。为应对这些挑战，我们提出了GRASP，并探索了一个新的方向，专注于结构化推理安全编程实践（SCPs）而非额外的训练或外部反馈。GRASP包括两个核心想法：（1）一个SCP图，将SCPs组织成一个有向无环图（DAG），捕捉依赖关系和关系；（2）基于图的推理过程，系统地引导大型语言模型通过相关的SCPs进行代码生成。此设计实现了可解释性、模型无关性和可扩展的安全改进，特别是在处理以前未见过的漏洞方面。我们的评估结果显示，GRASP在多个大型语言模型上始终能够实现超过80%的安全率（SR），并在零日漏洞上相对于基线实现高达88%的改进。 

---
# AI in Computational Thinking Education in Higher Education: A Systematic Literature Review 

**Title (ZH)**: AI在高等教育中支持计算思维教育：一项系统文献综述 

**Authors**: Ebrahim Rahimi, Clara Maathuis  

**Link**: [PDF](https://arxiv.org/pdf/2510.09677)  

**Abstract**: Computational Thinking (CT) is a key skill set for students in higher education to thrive and adapt to an increasingly technology-driven future and workplace. While research on CT education has gained remarkable momentum in K12 over the past decade, it has remained under-explored in higher education, leaving higher education teachers with an insufficient overview, knowledge, and support regarding CT education. The proliferation and adoption of artificial intelligence (AI) by educational institutions have demonstrated promising potential to support instructional activities across many disciplines, including CT education. However, a comprehensive overview outlining the various aspects of integrating AI in CT education in higher education is lacking. To mitigate this gap, we conducted this systematic literature review study. The focus of our study is to identify initiatives applying AI in CT education within higher education and to explore various educational aspects of these initiatives, including the benefits and challenges of AI in CT education, instructional strategies employed, CT components covered, and AI techniques and models utilized. This study provides practical and scientific contributions to the CT education community, including an inventory of AI-based initiatives for CT education useful to educators, an overview of various aspects of integrating AI into CT education such as its benefits and challenges (e.g., AI potential to reshape CT education versus its potential to diminish students creativity) and insights into new and expanded perspectives on CT in light of AI (e.g., the decoding approach alongside the coding approach to CT). 

**Abstract (ZH)**: 计算思维（CT）是高等教育学生在日益技术驱动的未来和工作场所中生存和适应的关键技能。尽管过去十年中针对CT教育的研究在K12领域获得了显著进展，但在高等教育领域对此研究仍显不足，导致高等教育教师在CT教育方面缺乏足够的概括、知识和支持。教育机构采用人工智能（AI）的应用展示了在许多学科支持教学活动的巨大潜力，包括CT教育。然而，关于在高等教育中整合AI在CT教育方面的综合概述仍然缺乏。为了弥补这一差距，我们开展了这项系统文献综述研究。本研究的重点是识别高等教育中应用AI的CT教育举措，并探索这些举措的各种教育方面，包括AI在CT教育中的优势与挑战、所采用的教学策略、涵盖的CT组件以及使用的AI技术和模型。本研究为CT教育社区提供了实用和科学的贡献，包括一份有用的基于AI的CT教育举措清单，对整合AI到CT教育的各种方面（如AI对CT教育的重塑潜力与其对学生创造性可能的减弱）进行了概述，并提出了在AI背景下CT的新和扩展视角（如解码方法与编码方法相结合的CT教学途径）。 

---
# Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling 

**Title (ZH)**: 耦合数据与测量空间动力学以增强扩散后验采样 

**Authors**: Shayan Mohajer Hamidi, En-Hui Yang, Ben Liang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09676)  

**Abstract**: Inverse problems, where the goal is to recover an unknown signal from noisy or incomplete measurements, are central to applications in medical imaging, remote sensing, and computational biology. Diffusion models have recently emerged as powerful priors for solving such problems. However, existing methods either rely on projection-based techniques that enforce measurement consistency through heuristic updates, or they approximate the likelihood $p(\boldsymbol{y} \mid \boldsymbol{x})$, often resulting in artifacts and instability under complex or high-noise conditions. To address these limitations, we propose a novel framework called \emph{coupled data and measurement space diffusion posterior sampling} (C-DPS), which eliminates the need for constraint tuning or likelihood approximation. C-DPS introduces a forward stochastic process in the measurement space $\{\boldsymbol{y}_t\}$, evolving in parallel with the data-space diffusion $\{\boldsymbol{x}_t\}$, which enables the derivation of a closed-form posterior $p(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{y}_{t-1})$. This coupling allows for accurate and recursive sampling based on a well-defined posterior distribution. Empirical results demonstrate that C-DPS consistently outperforms existing baselines, both qualitatively and quantitatively, across multiple inverse problem benchmarks. 

**Abstract (ZH)**: 逆问题中的耦合数据空间和测量空间漂移后验采样方法（C-DPS） 

---
# Leveraging LLMs to Streamline the Review of Public Funding Applications 

**Title (ZH)**: 利用大语言模型简化公共资金申请审核流程 

**Authors**: Joao D.S. Marques, Andre V. Duarte, Andre Carvalho, Gil Rocha, Bruno Martins, Arlindo L. Oliveira  

**Link**: [PDF](https://arxiv.org/pdf/2510.09674)  

**Abstract**: Every year, the European Union and its member states allocate millions of euros to fund various development initiatives. However, the increasing number of applications received for these programs often creates significant bottlenecks in evaluation processes, due to limited human capacity. In this work, we detail the real-world deployment of AI-assisted evaluation within the pipeline of two government initiatives: (i) corporate applications aimed at international business expansion, and (ii) citizen reimbursement claims for investments in energy-efficient home improvements. While these two cases involve distinct evaluation procedures, our findings confirm that AI effectively enhanced processing efficiency and reduced workload across both types of applications. Specifically, in the citizen reimbursement claims initiative, our solution increased reviewer productivity by 20.1%, while keeping a negligible false-positive rate based on our test set observations. These improvements resulted in an overall reduction of more than 2 months in the total evaluation time, illustrating the impact of AI-driven automation in large-scale evaluation workflows. 

**Abstract (ZH)**: 欧盟及其成员国每年为各类发展项目拨款数百万欧元。然而，这些项目收到的应用数量不断增加，常常在评估过程中造成瓶颈，由于人力有限。本文详细介绍了人工智能辅助评估在两个政府倡议中的实际部署：（i）针对国际业务扩张的企业申请，以及（ii）公民能源高效家庭改造投资的报销索赔。尽管这两种情况涉及不同的评估程序，但我们的研究发现证实，人工智能有效提高了两类申请的处理效率并减轻了工作负担。具体而言，在公民报销索赔倡议中，我们的解决方案将审阅员的生产力提高了20.1%，同时根据测试集观察保持了微不足道的误检率。这些改进使得总体评估时间减少了超过2个月，展示了人工智能驱动的自动化对大规模评估工作流程的影响。 

---
# A Hybrid Computational Intelligence Framework with Metaheuristic Optimization for Drug-Drug Interaction Prediction 

**Title (ZH)**: 基于元启发式优化的混合计算智能框架在药品药物相互作用预测中的应用 

**Authors**: Maryam Abdollahi Shamami, Babak Teimourpour, Farshad Sharifi  

**Link**: [PDF](https://arxiv.org/pdf/2510.09668)  

**Abstract**: Drug-drug interactions (DDIs) are a leading cause of preventable adverse events, often complicating treatment and increasing healthcare costs. At the same time, knowing which drugs do not interact is equally important, as such knowledge supports safer prescriptions and better patient outcomes. In this study, we propose an interpretable and efficient framework that blends modern machine learning with domain knowledge to improve DDI prediction. Our approach combines two complementary molecular embeddings - Mol2Vec, which captures fragment-level structural patterns, and SMILES-BERT, which learns contextual chemical features - together with a leakage-free, rule-based clinical score (RBScore) that injects pharmacological knowledge without relying on interaction labels. A lightweight neural classifier is then optimized using a novel three-stage metaheuristic strategy (RSmpl-ACO-PSO), which balances global exploration and local refinement for stable performance. Experiments on real-world datasets demonstrate that the model achieves high predictive accuracy (ROC-AUC 0.911, PR-AUC 0.867 on DrugBank) and generalizes well to a clinically relevant Type 2 Diabetes Mellitus cohort. Beyond raw performance, studies show how embedding fusion, RBScore, and the optimizer each contribute to precision and robustness. Together, these results highlight a practical pathway for building reliable, interpretable, and computationally efficient models that can support safer drug therapies and clinical decision-making. 

**Abstract (ZH)**: 药物-药物相互作用预测的可解释高效框架：融合现代机器学习与领域知识以提高预测性能 

---
# Adversarial-Resilient RF Fingerprinting: A CNN-GAN Framework for Rogue Transmitter Detection 

**Title (ZH)**: 对抗扰动 resilient RF 印记：一种用于探测 rogue 发射器的 CNN-GAN 框架 

**Authors**: Raju Dhakal, Prashant Shekhar, Laxima Niure Kandel  

**Link**: [PDF](https://arxiv.org/pdf/2510.09663)  

**Abstract**: Radio Frequency Fingerprinting (RFF) has evolved as an effective solution for authenticating devices by leveraging the unique imperfections in hardware components involved in the signal generation process. In this work, we propose a Convolutional Neural Network (CNN) based framework for detecting rogue devices and identifying genuine ones using softmax probability thresholding. We emulate an attack scenario in which adversaries attempt to mimic the RF characteristics of genuine devices by training a Generative Adversarial Network (GAN) using In-phase and Quadrature (IQ) samples from genuine devices. The proposed approach is verified using IQ samples collected from ten different ADALM-PLUTO Software Defined Radios (SDRs), with seven devices considered genuine, two as rogue, and one used for validation to determine the threshold. 

**Abstract (ZH)**: 基于卷积神经网络的软阈值化射频指纹检测框架 

---
# Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise 

**Title (ZH)**: 学习重要性：通过谱各向异性前向噪声引导扩散 

**Authors**: Luca Scimeca, Thomas Jiralerspong, Berton Earnshaw, Jason Hartford, Yoshua Bengio  

**Link**: [PDF](https://arxiv.org/pdf/2510.09660)  

**Abstract**: Diffusion Probabilistic Models (DPMs) have achieved strong generative performance, yet their inductive biases remain largely implicit. In this work, we aim to build inductive biases into the training and sampling of diffusion models to better accommodate the target distribution of the data to model. We introduce an anisotropic noise operator that shapes these biases by replacing the isotropic forward covariance with a structured, frequency-diagonal covariance. This operator unifies band-pass masks and power-law weightings, allowing us to emphasize or suppress designated frequency bands, while keeping the forward process Gaussian. We refer to this as spectrally anisotropic Gaussian diffusion (SAGD). In this work, we derive the score relation for anisotropic covariances and show that, under full support, the learned score converges to the true data score as $t\!\to\!0$, while anisotropy reshapes the probability-flow path from noise to data. Empirically, we show the induced anisotropy outperforms standard diffusion across several vision datasets, and enables selective omission: learning while ignoring known corruptions confined to specific bands. Together, these results demonstrate that carefully designed anisotropic forward noise provides a simple, yet principled, handle to tailor inductive bias in DPMs. 

**Abstract (ZH)**: 谱各向异性高斯扩散（SAGD）：在扩散模型中构建诱导偏置 

---
# Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models 

**Title (ZH)**: 基于梯度符号的掩码在预训练模型间传输任务向量 

**Authors**: Filippo Rinaldi, Aniello Panariello, Giacomo Salici, Fengyuan Liu, Marco Ciccone, Angelo Porrello, Simone Calderara  

**Link**: [PDF](https://arxiv.org/pdf/2510.09658)  

**Abstract**: When a new release of a foundation model is published, practitioners typically need to repeat full fine-tuning, even if the same task has already been solved in the previous version. A promising alternative is to reuse the parameter changes (i.e., task vectors) that capture how a model adapts to a specific task. However, they often fail to transfer across different pre-trained models due to their misaligned parameter space. In this work, we show that the key to successful transfer lies in the sign structure of the gradients of the new model. Based on this insight, we propose GradFix, a novel method that approximates the ideal gradient sign structure and leverages it to transfer knowledge using only a handful of labeled samples. Notably, this requires no additional fine-tuning: the adaptation is achieved by computing a few gradients at the target model and masking the source task vector accordingly. This yields an update that is locally aligned with the target loss landscape, effectively rebasing the task vector onto the new pre-training. We provide a theoretical guarantee that our method ensures first-order descent. Empirically, we demonstrate significant performance gains on vision and language benchmarks, consistently outperforming naive task vector addition and few-shot fine-tuning. 

**Abstract (ZH)**: 基于梯度符号结构的知识迁移：GradFix方法在预训练模型之间的任务适应 

---
# Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials 

**Title (ZH)**: 生成模型在亥姆霍兹方程解中的应用： acoustic 材料数据集 

**Authors**: Riccardo Fosco Gramaccioni, Christian Marinoni, Fabrizio Frezza, Aurelio Uncini, Danilo Comminiello  

**Link**: [PDF](https://arxiv.org/pdf/2510.09657)  

**Abstract**: Accurate simulation of wave propagation in complex acoustic materials is crucial for applications in sound design, noise control, and material engineering. Traditional numerical solvers, such as finite element methods, are computationally expensive, especially when dealing with large-scale or real-time scenarios. In this work, we introduce a dataset of 31,000 acoustic materials, named HA30K, designed and simulated solving the Helmholtz equations. For each material, we provide the geometric configuration and the corresponding pressure field solution, enabling data-driven approaches to learn Helmholtz equation solutions. As a baseline, we explore a deep learning approach based on Stable Diffusion with ControlNet, a state-of-the-art model for image generation. Unlike classical solvers, our approach leverages GPU parallelization to process multiple simulations simultaneously, drastically reducing computation time. By representing solutions as images, we bypass the need for complex simulation software and explicit equation-solving. Additionally, the number of diffusion steps can be adjusted at inference time, balancing speed and quality. We aim to demonstrate that deep learning-based methods are particularly useful in early-stage research, where rapid exploration is more critical than absolute accuracy. 

**Abstract (ZH)**: 准确模拟复杂声学材料中的波传播对于声学设计、噪声控制和材料工程的应用至关重要。传统的数值求解器，如有限元方法，在处理大规模或实时场景时计算成本高昂。在本工作中，我们引入了一个包含31,000种声学材料的数据集HA30K，这些材料通过求解亥姆霍兹方程设计并模拟。对于每种材料，我们提供了其几何配置和相应的压力场解，使得数据驱动的方法能够学习亥姆霍兹方程的解。作为基准，我们探索了基于Stable Diffusion with ControlNet的深度学习方法，这是一个用于图像生成的最先进的模型。与经典求解器不同，我们的方法利用GPU并行化同时处理多个模拟，大幅减少了计算时间。通过将解表示为图像，我们避免了使用复杂的仿真软件和显式方程求解的需求。此外，推理时可以调整扩散步数，平衡速度和质量。我们旨在证明基于深度学习的方法特别适用于早期研究阶段，此时快速探索比绝对准确性更为关键。 

---
# Data Provenance Auditing of Fine-Tuned Large Language Models with a Text-Preserving Technique 

**Title (ZH)**: 基于文本 preserved 技术的微调大型语言模型数据溯源审计 

**Authors**: Yanming Li, Seifeddine Ghozzi, Cédric Eichler, Nicolas Anciaux, Alexandra Bensamoun, Lorena Gonzalez Manzano  

**Link**: [PDF](https://arxiv.org/pdf/2510.09655)  

**Abstract**: We address the problem of auditing whether sensitive or copyrighted texts were used to fine-tune large language models (LLMs) under black-box access. Prior signals-verbatim regurgitation and membership inference-are unreliable at the level of individual documents or require altering the visible text. We introduce a text-preserving watermarking framework that embeds sequences of invisible Unicode characters into documents. Each watermark is split into a cue (embedded in odd chunks) and a reply (embedded in even chunks). At audit time, we submit prompts that contain only the cue; the presence of the corresponding reply in the model's output provides evidence of memorization consistent with training on the marked text. To obtain sound decisions, we compare the score of the published watermark against a held-out set of counterfactual watermarks and apply a ranking test with a provable false-positive-rate bound. The design is (i) minimally invasive (no visible text changes), (ii) scalable to many users and documents via a large watermark space and multi-watermark attribution, and (iii) robust to common passive transformations. We evaluate on open-weight LLMs and multiple text domains, analyzing regurgitation dynamics, sensitivity to training set size, and interference under multiple concurrent watermarks. Our results demonstrate reliable post-hoc provenance signals with bounded FPR under black-box access. We experimentally observe a failure rate of less than 0.1\% when detecting a reply after fine-tuning with 50 marked documents. Conversely, no spurious reply was recovered in over 18,000 challenges, corresponding to a 100\%TPR@0\% FPR. Moreover, detection rates remain relatively stable as the dataset size increases, maintaining a per-document detection rate above 45\% even when the marked collection accounts for less than 0.33\% of the fine-tuning data. 

**Abstract (ZH)**: 针对黑盒访问下的敏感或版权文本审计问题：一种文本保留水印框架 

---
# Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition 

**Title (ZH)**: YOLO演化超纲：YOLO26、YOLO11、YOLOv8和YOLOv5物体检测器综述 

**Authors**: Ranjan Sapkota, Manoj Karkee  

**Link**: [PDF](https://arxiv.org/pdf/2510.09653)  

**Abstract**: This paper presents a comprehensive overview of the Ultralytics YOLO(You Only Look Once) family of object detectors, focusing the architectural evolution, benchmarking, deployment perspectives, and future challenges. The review begins with the most recent release, YOLO26 (YOLOv26), which introduces key innovations including Distribution Focal Loss (DFL) removal, native NMS-free inference, Progressive Loss Balancing (ProgLoss), Small-Target-Aware Label Assignment (STAL), and the MuSGD optimizer for stable training. The progression is then traced through YOLO11, with its hybrid task assignment and efficiency-focused modules; YOLOv8, which advanced with a decoupled detection head and anchor-free predictions; and YOLOv5, which established the modular PyTorch foundation that enabled modern YOLO development. Benchmarking on the MS COCO dataset provides a detailed quantitative comparison of YOLOv5, YOLOv8, YOLO11, and YOLO26, alongside cross-comparisons with YOLOv12, YOLOv13, RT-DETR, and DEIM. Metrics including precision, recall, F1 score, mean Average Precision, and inference speed are analyzed to highlight trade-offs between accuracy and efficiency. Deployment and application perspectives are further discussed, covering export formats, quantization strategies, and real-world use in robotics, agriculture, surveillance, and manufacturing. Finally, the paper identifies challenges and future directions, including dense-scene limitations, hybrid CNN-Transformer integration, open-vocabulary detection, and edge-aware training approaches. 

**Abstract (ZH)**: 本论文对Ultralytics YOLO(你只看一次)家族的目标检测器进行了全面综述，重点介绍了架构演化、基准测试、部署视角以及未来挑战。综述从最新的YOLO26（YOLOv26）开始，该版本引入了关键创新，包括分布焦损（DFL）移除、原生无NMS推断、渐进损失平衡（ProgLoss）、小目标感知标签分配（STAL）以及MuSGD优化器以实现稳定的训练。随后追溯了从YOLO11及其混合任务分配和高效模块，到YOLOv8的解耦检测头和无锚预测，再到YOLOv5的模块化PyTorch基础，这些基础推动了现代YOLO的发展。在MS COCO数据集上的基准测试提供了YOLOv5、YOLOv8、YOLO11和YOLO26的详细定量比较，同时还与YOLOv12、YOLOv13、RT-DETR和DEIM进行了交叉比较。分析包括精度、召回率、F1分数、平均精确度和推理速度等指标，以强调准确性和效率之间的权衡。进一步讨论了部署和应用视角，包括导出格式、量化策略以及在机器人技术、农业、监控和制造等实际应用中的使用。最后，论文指出了挑战和未来方向，包括密集场景限制、CNN-Transformer结合、开放词汇检测以及边缘感知训练方法。 

---
# TinyViT-Batten: Few-Shot Vision Transformer with Explainable Attention for Early Batten-Disease Detection on Pediatric MRI 

**Title (ZH)**: TinyViT-Batten：具有可解释注意力的少量样本视觉变压器在儿童MRI早期巴特病检测中的应用 

**Authors**: Khartik Uppalapati, Bora Yimenicioglu, Shakeel Abdulkareem, Adan Eftekhari, Bhavya Uppalapati, Viraj Kamath  

**Link**: [PDF](https://arxiv.org/pdf/2510.09649)  

**Abstract**: Batten disease (neuronal ceroid lipofuscinosis) is a rare pediatric neurodegenerative disorder whose early MRI signs are subtle and often missed. We propose TinyViT-Batten, a few-shot Vision Transformer (ViT) framework to detect early Batten disease from pediatric brain MRI with limited training cases. We distill a large teacher ViT into a 5 M-parameter TinyViT and fine-tune it using metric-based few-shot learning (prototypical loss with 5-shot episodes). Our model achieves high accuracy (approximately 91%) and area under ROC of at least 0.95 on a multi-site dataset of 79 genetically confirmed Batten-disease MRIs (27 CLN3 from the Hochstein natural-history study, 32 CLN2 from an international longitudinal cohort, 12 early-manifestation CLN2 cases reported by Cokal et al., and 8 public Radiopaedia scans) together with 90 age-matched controls, outperforming a 3D-ResNet and Swin-Tiny baseline. We further integrate Gradient-weighted Class Activation Mapping (Grad-CAM) to highlight disease-relevant brain regions, enabling explainable predictions. The model's small size and strong performance (sensitivity greater than 90%, specificity approximately 90%) demonstrates a practical AI solution for early Batten disease detection. 

**Abstract (ZH)**: 基于少量样本学习的TinyViT-Batten框架在有限训练案例下从儿童脑MRI中检测早期Batten病 

---
# Rounding-Guided Backdoor Injection in Deep Learning Model Quantization 

**Title (ZH)**: 基于舍入引导的深度学习模型量化后门注入 

**Authors**: Xiangxiang Chen, Peixin Zhang, Jun Sun, Wenhai Wang, Jingyi Wang  

**Link**: [PDF](https://arxiv.org/pdf/2510.09647)  

**Abstract**: Model quantization is a popular technique for deploying deep learning models on resource-constrained environments. However, it may also introduce previously overlooked security risks. In this work, we present QuRA, a novel backdoor attack that exploits model quantization to embed malicious behaviors. Unlike conventional backdoor attacks relying on training data poisoning or model training manipulation, QuRA solely works using the quantization operations. In particular, QuRA first employs a novel weight selection strategy to identify critical weights that influence the backdoor target (with the goal of perserving the model's overall performance in mind). Then, by optimizing the rounding direction of these weights, we amplify the backdoor effect across model layers without degrading accuracy. Extensive experiments demonstrate that QuRA achieves nearly 100% attack success rates in most cases, with negligible performance degradation. Furthermore, we show that QuRA can adapt to bypass existing backdoor defenses, underscoring its threat potential. Our findings highlight critical vulnerability in widely used model quantization process, emphasizing the need for more robust security measures. Our implementation is available at this https URL. 

**Abstract (ZH)**: Model量化是一种在资源受限环境中部署深度学习模型的流行技术，但同时也可能引入先前未被注意的安全风险。在本文中，我们提出了QuRA，一种新颖的后门攻击方法，利用模型量化嵌入恶意行为。与依赖训练数据污染或模型训练操纵的传统后门攻击不同，QuRA仅通过量化操作工作。特别是在QuRA中，首先采用一种新颖的权重选择策略来识别影响后门目标的关键权重（同时考虑保持模型整体性能的因素），然后通过优化这些权重的舍入方向，在不影响准确性的前提下增强后门效果。大量实验表明，在大多数情况下，QuRA的攻击成功率接近100%，且性能下降微乎其微。此外，我们展示了QuRA可以适应绕过现有后门防御的能力，突显了其潜在威胁。我们的研究结果强调了广泛使用的模型量化过程中的关键漏洞，强调了需要更 robust 安全措施的必要性。我们的实现可在以下链接找到。 

---
# Real-Time Health Analytics Using Ontology-Driven Complex Event Processing and LLM Reasoning: A Tuberculosis Case Study 

**Title (ZH)**: 基于本体驱动复杂事件处理和大型语言模型推理的实时健康分析：以 tuberculosis 为例的研究 

**Authors**: Ritesh Chandra, Sonali Agarwal, Navjot Singh  

**Link**: [PDF](https://arxiv.org/pdf/2510.09646)  

**Abstract**: Timely detection of critical health conditions remains a major challenge in public health analytics, especially in Big Data environments characterized by high volume, rapid velocity, and diverse variety of clinical data. This study presents an ontology-enabled real-time analytics framework that integrates Complex Event Processing (CEP) and Large Language Models (LLMs) to enable intelligent health event detection and semantic reasoning over heterogeneous, high-velocity health data streams. The architecture leverages the Basic Formal Ontology (BFO) and Semantic Web Rule Language (SWRL) to model diagnostic rules and domain knowledge. Patient data is ingested and processed using Apache Kafka and Spark Streaming, where CEP engines detect clinically significant event patterns. LLMs support adaptive reasoning, event interpretation, and ontology refinement. Clinical information is semantically structured as Resource Description Framework (RDF) triples in Graph DB, enabling SPARQL-based querying and knowledge-driven decision support. The framework is evaluated using a dataset of 1,000 Tuberculosis (TB) patients as a use case, demonstrating low-latency event detection, scalable reasoning, and high model performance (in terms of precision, recall, and F1-score). These results validate the system's potential for generalizable, real-time health analytics in complex Big Data scenarios. 

**Abstract (ZH)**: 及时检测关键健康状况仍然是公共卫生分析中的主要挑战，特别是在以大数据量、高速度和多样数据特征为特点的环境中。本研究提出了一种基于本体的实时分析框架，该框架结合了复杂事件处理（CEP）和大规模语言模型（LLMs），以实现异质、高速健康数据流中的智能健康事件检测和语义推理。该架构利用基本形式本体（BFO）和语义网络规则语言（SWRL）来建模诊断规则和领域知识。患者数据通过Apache Kafka和Spark Streaming进行摄取和处理，其中CEP引擎检测临床显著事件模式。LLMs支持自适应推理、事件解释和本体优化。临床信息以资源描述框架（RDF）三元组形式结构化存储在图数据库中，支持SPARQL查询和基于知识的决策支持。该框架以1000名结核病（TB）患者的数据集为例进行评估，展示了低延迟事件检测、可扩展的推理能力和高模型性能（精度、召回率和F1分数）。这些结果验证了该系统在复杂大数据场景下实现通用化实时健康分析的潜力。 

---
# Enhanced Urban Traffic Management Using CCTV Surveillance Videos and Multi-Source Data Current State Prediction and Frequent Episode Mining 

**Title (ZH)**: 使用闭路电视监控视频和多源数据增强的城市交通管理：当前状态预测与频繁事件挖掘 

**Authors**: Shaharyar Alam Ansari, Mohammad Luqman, Aasim Zafar, Savir Ali  

**Link**: [PDF](https://arxiv.org/pdf/2510.09644)  

**Abstract**: Rapid urbanization has intensified traffic congestion, environmental strain, and inefficiencies in transportation systems, creating an urgent need for intelligent and adaptive traffic management solutions. Conventional systems relying on static signals and manual monitoring are inadequate for the dynamic nature of modern traffic. This research aims to develop a unified framework that integrates CCTV surveillance videos with multi-source data descriptors to enhance real-time urban traffic prediction. The proposed methodology incorporates spatio-temporal feature fusion, Frequent Episode Mining for sequential traffic pattern discovery, and a hybrid LSTM-Transformer model for robust traffic state forecasting. The framework was evaluated on the CityFlowV2 dataset comprising 313,931 annotated bounding boxes across 46 cameras. It achieved a high prediction accuracy of 98.46 percent, with a macro precision of 0.9800, macro recall of 0.9839, and macro F1-score of 0.9819. FEM analysis revealed significant sequential patterns such as moderate-congested transitions with confidence levels exceeding 55 percent. The 46 sustained congestion alerts are system-generated, which shows practical value for proactive congestion management. This emphasizes the need for the incorporation of video stream analytics with data from multiple sources for the design of real-time, responsive, adaptable multi-level intelligent transportation systems, which makes urban mobility smarter and safer. 

**Abstract (ZH)**: 快速城市化加剧了交通拥堵、环境压力和交通系统 inefficiencies，迫切需要智能和自适应的交通管理解决方案。传统的依赖静态信号和人工监控的系统无法满足现代交通的动态特性。本研究旨在开发一个结合闭路电视监控视频与多来源数据描述符的统一框架，以提升城市交通的实时预测。提出的方法结合了时空特征融合、频繁事件挖掘以发现序列交通模式，以及混合LSTM-Transformer模型进行稳健的交通状态预测。该框架在包含46个摄像头和313,931个标注边界框的CityFlowV2数据集上进行了评估，实现了98.46%的高预测准确率，宏精度为0.9800，宏召回率为0.9839，宏F1分为0.9819。FEM分析揭示了显著的序列模式，如中等拥堵转换，置信水平超过55%。46个持续拥堵警报由系统生成，体现了预防性拥堵管理的实际价值。这强调了将视频流分析与多源数据结合用于实时、响应性、自适应多层级智能交通系统设计的必要性，从而使城市交通更加智能和安全。 

---
# Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations 

**Title (ZH)**: 直接路由梯度（DRGrad）：面向多任务学习推荐的个性化信息手术 

**Authors**: Yuguang Liu, Yiyun Miao, Luyao Xia  

**Link**: [PDF](https://arxiv.org/pdf/2510.09643)  

**Abstract**: Multi-task learning (MTL) has emerged as a successful strategy in industrial-scale recommender systems, offering significant advantages such as capturing diverse users' interests and accurately detecting different behaviors like ``click" or ``dwell time". However, negative transfer and the seesaw phenomenon pose challenges to MTL models due to the complex and often contradictory task correlations in real-world recommendations. To address the problem while making better use of personalized information, we propose a personalized Direct Routing Gradient framework (DRGrad), which consists of three key components: router, updater and personalized gate network. DRGrad judges the stakes between tasks in the training process, which can leverage all valid gradients for the respective task to reduce conflicts. We evaluate the efficiency of DRGrad on complex MTL using a real-world recommendation dataset with 15 billion samples. The results show that DRGrad's superior performance over competing state-of-the-art MTL models, especially in terms of AUC (Area Under the Curve) metrics, indicating that it effectively manages task conflicts in multi-task learning environments without increasing model complexity, while also addressing the deficiencies in noise processing. Moreover, experiments on the public Census-income dataset and Synthetic dataset, have demonstrated the capability of DRGrad in judging and routing the stakes between tasks with varying degrees of correlation and personalization. 

**Abstract (ZH)**: 个性化直接路由梯度框架（DRGrad）：多任务学习中的任务冲突管理和个性化信息利用 

---
# Bias-Aware AI Chatbot for Engineering Advising at the University of Maryland A. James Clark School of Engineering 

**Title (ZH)**: 面向马里兰大学JAMES A. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. JAMES I. 威廉姆斯工程学院的意识偏见AI聊天机器人 

**Authors**: Prarthana P. Kartholy, Thandi M. Labor, Neil N. Panchal, Sean H. Wang, Hillary N. Owusu  

**Link**: [PDF](https://arxiv.org/pdf/2510.09636)  

**Abstract**: Selecting a college major is a difficult decision for many incoming freshmen. Traditional academic advising is often hindered by long wait times, intimidating environments, and limited personalization. AI Chatbots present an opportunity to address these challenges. However, AI systems also have the potential to generate biased responses, prejudices related to race, gender, socioeconomic status, and disability. These biases risk turning away potential students and undermining reliability of AI systems. This study aims to develop a University of Maryland (UMD) A. James Clark School of Engineering Program-specific AI chatbot. Our research team analyzed and mitigated potential biases in the responses. Through testing the chatbot on diverse student queries, the responses are scored on metrics of accuracy, relevance, personalization, and bias presence. The results demonstrate that with careful prompt engineering and bias mitigation strategies, AI chatbots can provide high-quality, unbiased academic advising support, achieving mean scores of 9.76 for accuracy, 9.56 for relevance, and 9.60 for personalization with no stereotypical biases found in the sample data. However, due to the small sample size and limited timeframe, our AI model may not fully reflect the nuances of student queries in engineering academic advising. Regardless, these findings will inform best practices for building ethical AI systems in higher education, offering tools to complement traditional advising and address the inequities faced by many underrepresented and first-generation college students. 

**Abstract (ZH)**: 选择大学专业是许多新生面临的艰难决定。传统的学术咨询往往受到长时间等待、令人 intimidated 的环境和有限的个性化程度的阻碍。AI聊天机器人提供了一个应对这些挑战的机会。然而，AI系统也可能生成有偏见的回应，涉及种族、性别、社会经济地位和残疾等方面的偏见。这些偏见可能会使潜在学生却步，并削弱AI系统的可靠性。本研究旨在为马里兰大学(UMD)杰斐逊·亚历山大·克拉克工程学院特定项目开发一个AI聊天机器人。我们的研究团队分析并缓解了潜在的偏见。通过在多样的学生查询上测试聊天机器人，对其响应进行了准确性、相关性、个性化和偏见存在的评分。结果显示，在精心的提示工程和偏见缓解策略下，AI聊天机器人可以提供高质量、无偏见的学术咨询支持，平均得分为：准确性9.76，相关性9.56，个性化9.60，样本数据中未发现刻板偏见。然而，由于样本量有限和时间限制，我们的AI模型可能无法完全反映工程学术咨询中学生的查询 nuances。无论怎样，这些发现将指导高等教育中建立伦理AI系统的最佳实践，提供工具以补充传统的咨询，并解决许多少数族裔和第一代大学生面临的不平等问题。 

---
# Responsible AI Adoption in the Public Sector: A Data-Centric Taxonomy of AI Adoption Challenges 

**Title (ZH)**: 公共部门负责任人工智能采纳：以数据为中心的人工智能采纳挑战分类 

**Authors**: Anastasija Nikiforova, Martin Lnenicka, Ulf Melin, David Valle-Cruz, Asif Gill, Cesar Casiano Flores, Emyana Sirait, Mariusz Luterek, Richard Michael Dreyling, Barbora Tesarova  

**Link**: [PDF](https://arxiv.org/pdf/2510.09634)  

**Abstract**: Despite Artificial Intelligence (AI) transformative potential for public sector services, decision-making, and administrative efficiency, adoption remains uneven due to complex technical, organizational, and institutional challenges. Responsible AI frameworks emphasize fairness, accountability, and transparency, aligning with principles of trustworthy AI and fair AI, yet remain largely aspirational, overlooking technical and institutional realities, especially foundational data and governance. This study addresses this gap by developing a taxonomy of data-related challenges to responsible AI adoption in government. Based on a systematic review of 43 studies and 21 expert evaluations, the taxonomy identifies 13 key challenges across technological, organizational, and environmental dimensions, including poor data quality, limited AI-ready infrastructure, weak governance, misalignment in human-AI decision-making, economic and environmental sustainability concerns. Annotated with institutional pressures, the taxonomy serves as a diagnostic tool to surface 'symptoms' of high-risk AI deployment and guides policymakers in building the institutional and data governance conditions necessary for responsible AI adoption. 

**Abstract (ZH)**: 尽管人工智能（AI）在公共部门服务、决策和行政效率方面具有变革潜力，但由于复杂的技术、组织和制度挑战，其采用仍不均衡。负责任的人工智能框架强调公平、问责和透明度，符合可信赖的人工智能和公平人工智能的原则，但这些框架仍主要停留在理想层面，忽视了技术与制度现实，尤其是基础数据和治理问题。本研究通过开发政府负责任的人工智能采用相关数据挑战的分类框架来弥补这一缺口。基于对43篇研究文献和21位专家评估的系统性回顾，该分类框架识别了技术、组织和环境维度下的13项关键挑战，包括数据质量差、缺乏AI就绪基础设施、治理薄弱、人类-人工智能决策不匹配、经济与环境可持续性担忧。该分类框架注释了制度压力，作为一种诊断工具，用于揭示高风险人工智能部署的“症状”，并指导政策制定者构建实施负责任人工智能所需的数据和制度治理条件。 

---
# Hound: Relation-First Knowledge Graphs for Complex-System Reasoning in Security Audits 

**Title (ZH)**: hound: 关系优先的知识图谱及其在安全审计中复杂系统推理的应用 

**Authors**: Bernhard Mueller  

**Link**: [PDF](https://arxiv.org/pdf/2510.09633)  

**Abstract**: Hound introduces a relation-first graph engine that improves system-level reasoning across interrelated components in complex codebases. The agent designs flexible, analyst-defined views with compact annotations (e.g., monetary/value flows, authentication/authorization roles, call graphs, protocol invariants) and uses them to anchor exact retrieval: for any question, it loads precisely the code that matters (often across components) so it can zoom out to system structure and zoom in to the decisive lines. A second contribution is a persistent belief system: long-lived vulnerability hypotheses whose confidence is updated as evidence accrues. The agent employs coverage-versus-intuition planning and a QA finalizer to confirm or reject hypotheses. On a five-project subset of ScaBench[1], Hound improves recall and F1 over a baseline LLM analyzer (micro recall 31.2% vs. 8.3%; F1 14.2% vs. 9.8%) with a modest precision trade-off. We attribute these gains to flexible, relation-first graphs that extend model understanding beyond call/dataflow to abstract aspects, plus the hypothesis-centric loop; code and artifacts are released to support reproduction. 

**Abstract (ZH)**: Hound 引入了一种关系优先的图引擎，提升了复杂代码库中相关组件间系统级推理能力。该代理设计了灵活的、分析师定义的观点，并使用紧凑的注解（如货币/价值流动、身份/授权角色、调用图、协议不变量）来锚定精确检索：对于任何一个问题，它都会加载相关的代码（往往是跨组件的），从而可以宏观审视系统结构，又能微观聚焦于关键代码行。第二个贡献是持久信念系统：长期存在的漏洞假设，随着证据的积累其置信度会被更新。代理使用覆盖率与直觉相结合的规划方法，并通过问答最终确认或拒绝假设。在 ScaBench 数据集的五个子项目上，Hound 在召回率和 F1 值上优于基准的大语言模型分析器（微观召回率 31.2% vs. 8.3%；F1 值 14.2% vs. 9.8%），以适度牺牲精度为代价。我们归功于这种提升的原因是灵活的关系优先图能够将模型的理解扩展到调用/数据流之外的抽象方面，加上以假设为中心的循环；代码和相关文件已发布以支持再现。 

---
# Toward a Unified Security Framework for AI Agents: Trust, Risk, and Liability 

**Title (ZH)**: 面向AI代理的统一安全框架：信任、风险与责任 

**Authors**: Jiayun Mo, Xin Kang, Tieyan Li, Zhongding Lei  

**Link**: [PDF](https://arxiv.org/pdf/2510.09620)  

**Abstract**: The excitement brought by the development of AI agents came alongside arising problems. These concerns centered around users' trust issues towards AIs, the risks involved, and the difficulty of attributing responsibilities and liabilities. Current solutions only attempt to target each problem separately without acknowledging their inter-influential nature. The Trust, Risk and Liability (TRL) framework proposed in this paper, however, ties together the interdependent relationships of trust, risk, and liability to provide a systematic method of building and enhancing trust, analyzing and mitigating risks, and allocating and attributing liabilities. It can be applied to analyze any application scenarios of AI agents and suggest appropriate measures fitting to the context. The implications of the TRL framework lie in its potential societal impacts, economic impacts, ethical impacts, and more. It is expected to bring remarkable values to addressing potential challenges and promoting trustworthy, risk-free, and responsible usage of AI in 6G networks. 

**Abstract (ZH)**: AI代理发展中带来的兴奋与出现的问题：信任、风险和责任框架在6G网络中促进可信、安全和负责任的AI应用 

---
# Causal Digital Twins for Cyber-Physical Security: A Framework for Robust Anomaly Detection in Industrial Control Systems 

**Title (ZH)**: 因果数字孪生在工业控制系统中鲁棒异常检测的框架：用于网络物理安全的方法 

**Authors**: Mohammadhossein Homaei, Mehran Tarif, Mar Avilla, Andres Caro  

**Link**: [PDF](https://arxiv.org/pdf/2510.09616)  

**Abstract**: Industrial Control Systems (ICS) face growing cyber-physical attacks that exploit both network vulnerabilities and physical processes. Current anomaly detection methods rely on correlation-based analysis, which cannot separate true causal relationships from spurious associations. This limitation results in high false alarm rates and poor root cause analysis. We propose a novel Causal Digital Twin (CDT) framework for cyber-physical security in medium-scale ICS. Our method combines causal inference theory with digital twin modeling. The framework enables three types of causal reasoning: association for pattern detection, intervention for understanding system responses, and counterfactual analysis for attack prevention planning. We evaluate our framework on three industrial datasets: SWaT, WADI, and HAI, with validation through physical constraint compliance (90.8\%) and synthetic ground truth testing (structural Hamming distance 0.13). Results show significant improvements over seven baseline methods. Our CDT achieves F1-scores are $0.944 \pm 0.014$ for SWaT, $0.902 \pm 0.021$ for WADI, and $0.923 \pm 0.018$ for HAI with statistical significance ($p < 0.0024$, Bonferroni corrected). The framework reduces false positives by \SI{74}{\percent} and achieves \SI{78.4}{\percent} root cause analysis accuracy compared to \SI{48.7}{\percent} for existing methods. Counterfactual analysis enables defense strategies that reduce attack success by \SI{73.2}{\percent}. The system keeps real-time performance with \SI{3.2}{ms} latency, which is suitable for industrial deployment, while providing interpretable explanations for operators. 

**Abstract (ZH)**: 工业控制系统中的因果数字孪生框架：面向中等规模ICS的因果推理与物理安全 

---
# Mission Impossible: Feedback-Guided Dynamic Interactive Planning for Improving Reasoning on LLMs 

**Title (ZH)**: 不可能的任务：反馈引导的动态交互式规划以提高大语言模型的推理能力 

**Authors**: Dong Yan, Gaochen Wu, Bowen Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2510.05577)  

**Abstract**: Recent advancements in language agents have led to significant improvements in multi-hop reasoning tasks. However, existing approaches often struggle with handling open-domain problems, which require massive information retrieval due to their reliance on a fixed sequence of actions. To address this, we propose Feedback-Guided Dynamic Interactive Planning (FGDIP), a novel framework tailored to enhance reasoning in LLMs by utilizing dynamic and adaptive strategies for information exploration in open-domain multi-hop reasoning tasks. Our approach begins by identifying key entities relevant to the problem, which serve as the initial nodes in the reasoning process. From these initial nodes, we then generate reasoning child nodes with the process being refined through a combination of historical error analysis and real-time feedback, which allows the framework to dynamically adjust and optimize its reasoning strategies. By integrating depth-first search with an innovative node generation technique, our framework adapts based on both prior error paths and concurrently generated nodes at the same hierarchical level. This dynamic strategy effectively expands the search space while ensuring the reasoning process systematically converges toward accurate solutions. Experimental results show that FGDIP achieved up to 54.47% F1 score on the HotpotQA dataset and 70.05% on the StrategyQA dataset, surpassing the best baseline by 5.03% and 7.25% respectively, highlighting its versatility and potential to enhance language agents in multi-hop reasoning tasks. 

**Abstract (ZH)**: Recent advancements in语言代理已在多跳推理任务中取得了显著进步。然而，现有的方法往往难以处理开放领域问题，因为这类问题需要大量的信息检索，依赖于固定顺序的操作。为了解决这一问题，我们提出了一种新的框架——反馈引导的动态交互规划（FGDIP），该框架旨在通过利用动态和适应性策略增强LLM在开放领域多跳推理任务中的推理能力。我们的方法首先识别与问题相关的关键实体，作为推理过程的初始节点。从这些初始节点出发，我们生成推理子节点，并通过历史错误分析和实时反馈的过程进行优化，使框架能够动态调整和优化其推理策略。通过将深度优先搜索与创新性的节点生成技术相结合，我们的框架能够根据先验错误路径和同时生成的同级节点进行适应。这种动态策略有效地扩展了搜索空间，同时确保推理过程系统地向准确的解决方案收敛。实验结果显示，FGDIP在HotpotQA数据集上的F1分数达到54.47%，在StrategyQA数据集上达到70.05%，分别比最佳基线高出5.03%和7.25%，突显了其在多跳推理任务中增强语言代理的灵活性和潜力。 

---
# Detecting Conspiracy Theory Against COVID-19 Vaccines 

**Title (ZH)**: 检测针对COVID-19疫苗的阴谋论 

**Authors**: Md Hasibul Amin, Harika Madanu, Sahithi Lavu, Hadi Mansourifar, Dana Alsagheer, Weidong Shi  

**Link**: [PDF](https://arxiv.org/pdf/2211.13003)  

**Abstract**: Since the beginning of the vaccination trial, social media has been flooded with anti-vaccination comments and conspiracy beliefs. As the day passes, the number of COVID- 19 cases increases, and online platforms and a few news portals entertain sharing different conspiracy theories. The most popular conspiracy belief was the link between the 5G network spreading COVID-19 and the Chinese government spreading the virus as a bioweapon, which initially created racial hatred. Although some disbelief has less impact on society, others create massive destruction. For example, the 5G conspiracy led to the burn of the 5G Tower, and belief in the Chinese bioweapon story promoted an attack on the Asian-Americans. Another popular conspiracy belief was that Bill Gates spread this Coronavirus disease (COVID-19) by launching a mass vaccination program to track everyone. This Conspiracy belief creates distrust issues among laypeople and creates vaccine hesitancy. This study aims to discover the conspiracy theory against the vaccine on social platforms. We performed a sentiment analysis on the 598 unique sample comments related to COVID-19 vaccines. We used two different models, BERT and Perspective API, to find out the sentiment and toxicity of the sentence toward the COVID-19 vaccine. 

**Abstract (ZH)**: 自疫苗试验开始以来，社交媒体上充斥着反疫苗评论和阴谋论。随着COVID-19病例的增加，网络平台和少数新闻门户网站在分享不同阴谋论。最受欢迎的阴谋论涉及5G网络传播COVID-19与中国政府将其作为生物武器传播之间的联系，最初引发了种族仇恨。虽然一些怀疑论对社会影响较小，但其他阴谋论造成了重大破坏。例如，5G阴谋论导致了破坏5G基站的行为，而相信中国生物武器故事则促进了对亚裔美国人的攻击。另一个流行的阴谋论是比尔·盖茨通过推出大规模疫苗接种计划传播了这种冠状病毒疾病，以监控每个人。这种阴谋论创建了普通民众的信任问题，并引发疫苗犹豫。本文旨在发现针对疫苗的阴谋论在社交平台上的情况。我们对与COVID-19疫苗相关的598条独特样本评论进行了情感分析。我们使用了两种不同的模型——BERT和Perspective API，以确定句子对COVID-19疫苗的情感和毒性。 

---
