# Small-Scale Testbeds for Connected and Automated Vehicles and Robot Swarms: Challenges and a Roadmap 

**Title (ZH)**: 面向连接和自动驾驶车辆及机器人 swarm 的小规模试验床：挑战与 roadmap 

**Authors**: Jianye Xu, Bassam Alrifaee, Johannes Betz, Armin Mokhtarian, Archak Mittal, Mengchi Cai, Rahul Mangharam, Omar M. Shehata, Catherine M. Elias, Jan-Nico Zaech, Patrick Scheffe, Felix Jahncke, Sangeet Sankaramangalam Ulhas, Kaj Munhoz Arfvidsson  

**Link**: [PDF](https://arxiv.org/pdf/2503.05656)  

**Abstract**: This article proposes a roadmap to address the current challenges in small-scale testbeds for Connected and Automated Vehicles (CAVs) and robot swarms. The roadmap is a joint effort of participants in the workshop "1st Workshop on Small-Scale Testbeds for Connected and Automated Vehicles and Robot Swarms," held on June 2 at the IEEE Intelligent Vehicles Symposium (IV) 2024 in Jeju, South Korea. The roadmap contains three parts: 1) enhancing accessibility and diversity, especially for underrepresented communities, 2) sharing best practices for the development and maintenance of testbeds, and 3) connecting testbeds through an abstraction layer to support collaboration. The workshop features eight invited speakers, four contributed papers [1]-[4], and a presentation of a survey paper on testbeds [5]. The survey paper provides an online comparative table of more than 25 testbeds, available at this https URL. The workshop's own website is available at this https URL. 

**Abstract (ZH)**: 本文提出了一条路线图，以应对连接和自动车辆（CAVs）及机器人蜂群小型试验床目前面临的挑战。该路线图是参加于2024年6月2日在韩国济州举行的IEEE智能汽车研讨会（IV）上举行的“首届连接和自动车辆及机器人蜂群小型试验床研讨会”工作坊的参与者们共同制定的。该路线图包含三个部分：1）提升 accessibility 和多样性，尤其是促进代表性不足的社区，2）分享试验床开发和维护的最佳实践，3）通过抽象层连接试验床以支持协作。研讨会设有八位特邀演讲嘉宾，四篇贡献论文 [1]-[4]，以及一篇关于试验床的综述论文的介绍 [5]。综述论文提供了一份在线比较表，包含超过25个试验床，并可通过此链接访问：https://link. Here. 研讨会的官方网站可通过此链接访问：https://link. Here. 

---
# Accelerating db-A$^\textbf{*}$ for Kinodynamic Motion Planning Using Diffusion 

**Title (ZH)**: 使用扩散加速db-A*算法的kinodynamic运动规划 

**Authors**: Julius Franke, Akmaral Moldagalieva, Pia Hanfeld, Wolfgang Hönig  

**Link**: [PDF](https://arxiv.org/pdf/2503.05539)  

**Abstract**: We present a novel approach for generating motion primitives for kinodynamic motion planning using diffusion models. The motions generated by our approach are adapted to each problem instance by utilizing problem-specific parameters, allowing for finding solutions faster and of better quality. The diffusion models used in our approach are trained on randomly cut solution trajectories. These trajectories are created by solving randomly generated problem instances with a kinodynamic motion planner. Experimental results show significant improvements up to 30 percent in both computation time and solution quality across varying robot dynamics such as second-order unicycle or car with trailer. 

**Abstract (ZH)**: 使用扩散模型生成适应性运动基本单元的新型方法：针对动力学运动规划的快速高效解决方案 

---
# Adaptive Neural Unscented Kalman Filter 

**Title (ZH)**: 自适应神经无迹卡尔曼滤波器 

**Authors**: Amit Levy, Itzik Klein  

**Link**: [PDF](https://arxiv.org/pdf/2503.05490)  

**Abstract**: The unscented Kalman filter is an algorithm capable of handling nonlinear scenarios. Uncertainty in process noise covariance may decrease the filter estimation performance or even lead to its divergence. Therefore, it is important to adjust the process noise covariance matrix in real time. In this paper, we developed an adaptive neural unscented Kalman filter to cope with time-varying uncertainties during platform operation. To this end, we devised ProcessNet, a simple yet efficient end-to-end regression network to adaptively estimate the process noise covariance matrix. We focused on the nonlinear inertial sensor and Doppler velocity log fusion problem in the case of autonomous underwater vehicle navigation. Using a real-world recorded dataset from an autonomous underwater vehicle, we demonstrated our filter performance and showed its advantages over other adaptive and non-adaptive nonlinear filters. 

**Abstract (ZH)**: 无迹卡尔曼滤波器是一种能够处理非线性场景的算法。过程噪声协方差中的不确定性可能会降低滤波器的估计性能，甚至导致滤波器发散。因此，实时调整过程噪声协方差矩阵非常重要。在本文中，我们开发了一种自适应神经无迹卡尔曼滤波器，以应对平台运行过程中时间变化的不确定性。为此，我们设计了ProcessNet，这是一种简单且高效的端到端回归网络，可自适应估计过程噪声协方差矩阵。我们专注于自主水下车辆导航中非线性惯性传感器与多普勒速度日志融合的问题。使用自主水下车辆记录的真实数据集，我们展示了该滤波器的性能，并且证明了其相对于其他自适应和非自适应非线性滤波器的优势。 

---
# Topology-Driven Trajectory Optimization for Modelling Controllable Interactions Within Multi-Vehicle Scenario 

**Title (ZH)**: 拓扑驱动的轨迹优化方法：多车辆场景中可控交互建模 

**Authors**: Changjia Ma, Yi Zhao, Zhongxue Gan, Bingzhao Gao, Wenchao Ding  

**Link**: [PDF](https://arxiv.org/pdf/2503.05471)  

**Abstract**: Trajectory optimization in multi-vehicle scenarios faces challenges due to its non-linear, non-convex properties and sensitivity to initial values, making interactions between vehicles difficult to control. In this paper, inspired by topological planning, we propose a differentiable local homotopy invariant metric to model the interactions. By incorporating this topological metric as a constraint into multi-vehicle trajectory optimization, our framework is capable of generating multiple interactive trajectories from the same initial values, achieving controllable interactions as well as supporting user-designed interaction patterns. Extensive experiments demonstrate its superior optimality and efficiency over existing methods. We will release open-source code to advance relative research. 

**Abstract (ZH)**: 多车辆场景中的轨迹优化由于其非线性和非凸性质以及对初始值的敏感性而面临挑战，使得车辆之间的交互难以控制。受拓扑规划启发，本文提出了一种可微局部同伦不变度量来建模交互。通过将这种拓扑度量作为约束融入多车辆轨迹优化中，我们的框架能够从相同的初始值生成多个交互轨迹，实现可控的交互并支持用户设计的交互模式。详实验验证了其在最优性和效率上的优越性。我们将开放源代码以促进相关研究。 

---
# Safety-Critical Traffic Simulation with Adversarial Transfer of Driving Intentions 

**Title (ZH)**: 基于敌对迁移驾驶意图的安全关键交通模拟 

**Authors**: Zherui Huang, Xing Gao, Guanjie Zheng, Licheng Wen, Xuemeng Yang, Xiao Sun  

**Link**: [PDF](https://arxiv.org/pdf/2503.05180)  

**Abstract**: Traffic simulation, complementing real-world data with a long-tail distribution, allows for effective evaluation and enhancement of the ability of autonomous vehicles to handle accident-prone scenarios. Simulating such safety-critical scenarios is nontrivial, however, from log data that are typically regular scenarios, especially in consideration of dynamic adversarial interactions between the future motions of autonomous vehicles and surrounding traffic participants. To address it, this paper proposes an innovative and efficient strategy, termed IntSim, that explicitly decouples the driving intentions of surrounding actors from their motion planning for realistic and efficient safety-critical simulation. We formulate the adversarial transfer of driving intention as an optimization problem, facilitating extensive exploration of diverse attack behaviors and efficient solution convergence. Simultaneously, intention-conditioned motion planning benefits from powerful deep models and large-scale real-world data, permitting the simulation of realistic motion behaviors for actors. Specially, through adapting driving intentions based on environments, IntSim facilitates the flexible realization of dynamic adversarial interactions with autonomous vehicles. Finally, extensive open-loop and closed-loop experiments on real-world datasets, including nuScenes and Waymo, demonstrate that the proposed IntSim achieves state-of-the-art performance in simulating realistic safety-critical scenarios and further improves planners in handling such scenarios. 

**Abstract (ZH)**: 交通仿真，通过补充长尾分布的实际数据，能够有效评估和提升自动驾驶车辆处理事故多发场景的能力。然而，从通常为常规场景的日志数据中模拟这种安全关键场景是具有挑战性的，特别是在考虑未来自动驾驶车辆及其周围交通参与者之间动态对抗性互动的情况下。为了解决这一问题，本文提出了一种创新且高效的策略，称为IntSim，该策略明确地将周围行为者的驾驶意图与他们的运动规划解耦，以实现现实且高效的安全关键仿真。我们将驾驶意图的对抗转移建模为一个优化问题，从而促进对多种攻击行为的广泛探索和高效解算收敛。同时，基于驾驶意图的运动规划得益于强大的深度模型和大规模的实际数据，使得能够模拟行为者的现实运动行为。特别地，通过根据环境调整驾驶意图，IntSim 支持灵活实现动态对抗性互动与自动驾驶车辆的互动。最后，通过在nuScenes和Waymo等现实世界数据集上的开环和闭环实验，证明所提出的IntSim 在模拟现实安全关键场景方面达到了最先进的性能，并进一步提升了规划器处理这些场景的能力。 

---
# HyperGraph ROS: An Open-Source Robot Operating System for Hybrid Parallel Computing based on Computational HyperGraph 

**Title (ZH)**: 基于计算超图的混合并行计算开源机器人操作系统HyperGraph ROS 

**Authors**: Shufang Zhang, Jiazheng Wu, Jiacheng He, Kaiyi Wang, Shan An  

**Link**: [PDF](https://arxiv.org/pdf/2503.05117)  

**Abstract**: This paper presents HyperGraph ROS, an open-source robot operating system that unifies intra-process, inter-process, and cross-device computation into a computational hypergraph for efficient message passing and parallel execution. In order to optimize communication, HyperGraph ROS dynamically selects the optimal communication mechanism while maintaining a consistent API. For intra-process messages, Intel-TBB Flow Graph is used with C++ pointer passing, which ensures zero memory copying and instant delivery. Meanwhile, inter-process and cross-device communication seamlessly switch to ZeroMQ. When a node receives a message from any source, it is immediately activated and scheduled for parallel execution by Intel-TBB. The computational hypergraph consists of nodes represented by TBB flow graph nodes and edges formed by TBB pointer-based connections for intra-process communication, as well as ZeroMQ links for inter-process and cross-device communication. This structure enables seamless distributed parallelism. Additionally, HyperGraph ROS provides ROS-like utilities such as a parameter server, a coordinate transformation tree, and visualization tools. Evaluation in diverse robotic scenarios demonstrates significantly higher transmission and throughput efficiency compared to ROS 2. Our work is available at this https URL. 

**Abstract (ZH)**: HyperGraph ROS：一种统一进程内、进程间及跨设备计算的开源机器人操作系统 

---
# Learning-based GNSS Uncertainty Quantification using Continuous-Time Factor Graph Optimization 

**Title (ZH)**: 基于学习的连续时间因子图优化下的GNSS不确定性量化 

**Authors**: Haoming Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.04933)  

**Abstract**: This short paper presents research findings on two learning-based methods for quantifying measurement uncertainties in global navigation satellite systems (GNSS). We investigate two learning strategies: offline learning for outlier prediction and online learning for noise distribution approximation, specifically applied to GNSS pseudorange observations. To develop and evaluate these learning methods, we introduce a novel multisensor state estimator that accurately and robustly estimates trajectory from multiple sensor inputs, critical for deriving GNSS measurement residuals used to train the uncertainty models. We validate the proposed learning-based models using real-world sensor data collected in diverse urban environments. Experimental results demonstrate that both models effectively handle GNSS outliers and improve state estimation performance. Furthermore, we provide insightful discussions to motivate future research toward developing a federated framework for robust vehicle localization in challenging environments. 

**Abstract (ZH)**: 基于学习的全球导航卫星系统测距误差量化方法研究 

---
# An energy-efficient learning solution for the Agile Earth Observation Satellite Scheduling Problem 

**Title (ZH)**: 敏捷地球观测卫星调度问题的能效学习解决方案 

**Authors**: Antonio M. Mercado-Martínez, Beatriz Soret, Antonio Jurado-Navas  

**Link**: [PDF](https://arxiv.org/pdf/2503.04803)  

**Abstract**: The Agile Earth Observation Satellite Scheduling Problem (AEOSSP) entails finding the subset of observation targets to be scheduled along the satellite's orbit while meeting operational constraints of time, energy and memory. The problem of deciding what and when to observe is inherently complex, and becomes even more challenging when considering several issues that compromise the quality of the captured images, such as cloud occlusion, atmospheric turbulence, and image resolution. This paper presents a Deep Reinforcement Learning (DRL) approach for addressing the AEOSSP with time-dependent profits, integrating these three factors to optimize the use of energy and memory resources. The proposed method involves a dual decision-making process: selecting the sequence of targets and determining the optimal observation time for each. Our results demonstrate that the proposed algorithm reduces the capture of images that fail to meet quality requirements by > 60% and consequently decreases energy waste from attitude maneuvers by up to 78%, all while maintaining strong observation performance. 

**Abstract (ZH)**: 敏捷地球观测卫星调度问题(AEOSSP)涉及在满足时间、能量和内存运营约束条件下确定要调度的目标子集。决定观察什么和何时观察的问题本身就很复杂，当考虑影响捕获图像质量的因素时，如云遮挡、大气湍流和图像分辨率，问题变得更为棘手。本文提出了一种基于深度强化学习(DRL)的方法来解决具有时变收益的AEOSSP，综合考虑这三个因素以优化能量和内存资源的使用。所提出的方法涉及双重决策过程：选择目标序列并确定每个目标的最佳观测时间。我们的结果显示，所提出的算法通过降低约60%无法满足质量要求的图像捕获比例，从而最多减少78%的姿态机动能耗，同时保持强大的观测性能。 

---
# Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART) 

**Title (ZH)**: 面向现实世界的路径规划：大规模多Agent实际测试平台（SMART） 

**Authors**: Jingtian Yan, Zhifei Li, William Kang, Yulun Zhang, Stephen Smith, Jiaoyang Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.04798)  

**Abstract**: We present Scalable Multi-Agent Realistic Testbed (SMART), a realistic and efficient software tool for evaluating Multi-Agent Path Finding (MAPF) algorithms. MAPF focuses on planning collision-free paths for a group of agents. While state-of-the-art MAPF algorithms can plan paths for hundreds of robots in seconds, they often rely on simplified robot models, making their real-world performance unclear. Researchers typically lack access to hundreds of physical robots in laboratory settings to evaluate the algorithms. Meanwhile, industrial professionals who lack expertise in MAPF require an easy-to-use simulator to efficiently test and understand the performance of MAPF algorithms in their specific settings. SMART fills this gap with several advantages: (1) SMART uses a physics-engine-based simulator to create realistic simulation environments, accounting for complex real-world factors such as robot kinodynamics and execution uncertainties, (2) SMART uses an execution monitor framework based on the Action Dependency Graph, facilitating seamless integration with various MAPF algorithms and robot models, and (3) SMART scales to thousands of robots. In addition, we use SMART to explore and demonstrate research questions about the execution of MAPF algorithms in real-world scenarios. The code is publicly available at this https URL. 

**Abstract (ZH)**: 面向多Agent路径规划算法评估的可扩展多Agent现实测试床（SMART） 

---
# Multi-Fidelity Policy Gradient Algorithms 

**Title (ZH)**: 多保真度策略梯度算法 

**Authors**: Xinjie Liu, Cyrus Neary, Kushagra Gupta, Christian Ellis, Ufuk Topcu, David Fridovich-Keil  

**Link**: [PDF](https://arxiv.org/pdf/2503.05696)  

**Abstract**: Many reinforcement learning (RL) algorithms require large amounts of data, prohibiting their use in applications where frequent interactions with operational systems are infeasible, or high-fidelity simulations are expensive or unavailable. Meanwhile, low-fidelity simulators--such as reduced-order models, heuristic reward functions, or generative world models--can cheaply provide useful data for RL training, even if they are too coarse for direct sim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL framework that mixes a small amount of data from the target environment with a large volume of low-fidelity simulation data to form unbiased, reduced-variance estimators (control variates) for on-policy policy gradients. We instantiate the framework by developing multi-fidelity variants of two policy gradient algorithms: REINFORCE and proximal policy optimization. Experimental results across a suite of simulated robotics benchmark problems demonstrate that when target-environment samples are limited, MFPG achieves up to 3.9x higher reward and improves training stability when compared to baselines that only use high-fidelity data. Moreover, even when the baselines are given more high-fidelity samples--up to 10x as many interactions with the target environment--MFPG continues to match or outperform them. Finally, we observe that MFPG is capable of training effective policies even when the low-fidelity environment is drastically different from the target environment. MFPG thus not only offers a novel paradigm for efficient sim-to-real transfer but also provides a principled approach to managing the trade-off between policy performance and data collection costs. 

**Abstract (ZH)**: 多保真度策略梯度：一种将目标环境数据与低保真度模拟数据相结合的强化学习框架 

---
# Riemann$^2$: Learning Riemannian Submanifolds from Riemannian Data 

**Title (ZH)**: 黎曼²：从黎曼数据学习黎曼子流形 

**Authors**: Leonel Rozo, Miguel González-Duque, Noémie Jaquier, Søren Hauberg  

**Link**: [PDF](https://arxiv.org/pdf/2503.05540)  

**Abstract**: Latent variable models are powerful tools for learning low-dimensional manifolds from high-dimensional data. However, when dealing with constrained data such as unit-norm vectors or symmetric positive-definite matrices, existing approaches ignore the underlying geometric constraints or fail to provide meaningful metrics in the latent space. To address these limitations, we propose to learn Riemannian latent representations of such geometric data. To do so, we estimate the pullback metric induced by a Wrapped Gaussian Process Latent Variable Model, which explicitly accounts for the data geometry. This enables us to define geometry-aware notions of distance and shortest paths in the latent space, while ensuring that our model only assigns probability mass to the data manifold. This generalizes previous work and allows us to handle complex tasks in various domains, including robot motion synthesis and analysis of brain connectomes. 

**Abstract (ZH)**: 潜变量模型是学习高维数据低维流形的强大工具。然而，在处理如单位范数向量或对称正定矩阵等受限数据时，现有方法要么忽略了潜在的数据几何约束，要么无法在潜在空间中提供有意义的度量。为了克服这些限制，我们提出学习此类几何数据的黎曼潜表示。为此，我们估计由包裹高斯过程潜变量模型诱导的拉普拉斯度量，明确考虑了数据几何。这使得我们能够在潜空间中定义几何感知的距离和最短路径，并确保我们的模型仅将概率质量分配给数据流形。这扩展了之前的工作，并允许我们在包括机器人运动合成和脑连接组分析在内的各种领域处理复杂任务。 

---
# Toward an Evaluation Science for Generative AI Systems 

**Title (ZH)**: 生成式AI系统评估科学探讨 

**Authors**: Laura Weidinger, Deb Raji, Hanna Wallach, Margaret Mitchell, Angelina Wang, Olawale Salaudeen, Rishi Bommasani, Sayash Kapoor, Deep Ganguli, Sanmi Koyejo, William Isaac  

**Link**: [PDF](https://arxiv.org/pdf/2503.05336)  

**Abstract**: There is an increasing imperative to anticipate and understand the performance and safety of generative AI systems in real-world deployment contexts. However, the current evaluation ecosystem is insufficient: Commonly used static benchmarks face validity challenges, and ad hoc case-by-case audits rarely scale. In this piece, we advocate for maturing an evaluation science for generative AI systems. While generative AI creates unique challenges for system safety engineering and measurement science, the field can draw valuable insights from the development of safety evaluation practices in other fields, including transportation, aerospace, and pharmaceutical engineering. In particular, we present three key lessons: Evaluation metrics must be applicable to real-world performance, metrics must be iteratively refined, and evaluation institutions and norms must be established. Applying these insights, we outline a concrete path toward a more rigorous approach for evaluating generative AI systems. 

**Abstract (ZH)**: 生成式AI系统在实际部署中的性能与安全预测及理解日益紧迫：当前的评估生态系统存在不足：常用的静态基准面临有效性挑战，而逐案审计很少能扩大规模。本文倡导成熟生成式AI系统的评估科学。尽管生成式AI为系统安全性工程和测量科学带来了独特挑战，但该领域可以从其他领域（如交通、航空和制药工程）的安全评估实践中获得宝贵启示。特别是，我们提出了三条关键教训：评估指标必须适用于实际性能，指标必须逐步精炼，并需建立评估机构和规范。应用这些启示，我们概述了一条更加严谨的评估生成式AI系统的具体路径。 

---
# Path Pooling: Train-Free Structure Enhancement for Efficient Knowledge Graph Retrieval-Augmented Generation 

**Title (ZH)**: 路径聚合：高效的知识图谱检索增强生成中的无训练结构增强 

**Authors**: Hairu Wang, Yuan Feng, Xike Xie, S Kevin Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2503.05203)  

**Abstract**: Although Large Language Models achieve strong success in many tasks, they still suffer from hallucinations and knowledge deficiencies in real-world applications. Many knowledge graph-based retrieval-augmented generation (KG-RAG) methods enhance the quality and credibility of LLMs by leveraging structure and semantic information in KGs as external knowledge bases. However, these methods struggle to effectively incorporate structure information, either incurring high computational costs or underutilizing available knowledge. Inspired by smoothing operations in graph representation learning, we propose path pooling, a simple, train-free strategy that introduces structure information through a novel path-centric pooling operation. It seamlessly integrates into existing KG-RAG methods in a plug-and-play manner, enabling richer structure information utilization. Extensive experiments demonstrate that incorporating the path pooling into the state-of-the-art KG-RAG method consistently improves performance across various settings while introducing negligible additional cost. Code is coming soon at this https URL. 

**Abstract (ZH)**: 尽管大型语言模型在许多任务中取得了显著的成功，但在实际应用中仍存在幻觉和知识不足的问题。基于知识图谱的检索增强生成（KG-RAG）方法通过利用知识图谱中结构和语义信息作为外部知识库，增强了语言模型的质量和可靠性。然而，这些方法在有效整合结构信息方面存在困难，要么导致高计算成本，要么未能充分利用可用的知识。受到图表示学习中平滑操作的启发，我们提出了一种简单的、无需训练的策略——路径池化，通过一个新颖的路径为中心的池化操作引入结构信息。该方法以即插即用的方式无缝集成到现有的KG-RAG方法中，能够更好地利用结构信息。大量实验表明，在最先进的KG-RAG方法中引入路径池化可以在各种场景中一致地提高性能，同时几乎不增加额外成本。代码 shortly 将在以下链接发布：this https URL。 

---
# FedMABench: Benchmarking Mobile Agents on Decentralized Heterogeneous User Data 

**Title (ZH)**: FedMABench：在分布式异构用户数据上的移动代理基准测试 

**Authors**: Wenhao Wang, Zijie Yu, Rui Ye, Jianqing Zhang, Siheng Chen, Yanfeng Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.05143)  

**Abstract**: Mobile agents have attracted tremendous research participation recently. Traditional approaches to mobile agent training rely on centralized data collection, leading to high cost and limited scalability. Distributed training utilizing federated learning offers an alternative by harnessing real-world user data, providing scalability and reducing costs. However, pivotal challenges, including the absence of standardized benchmarks, hinder progress in this field.
To tackle the challenges, we introduce FedMABench, the first benchmark for federated training and evaluation of mobile agents, specifically designed for heterogeneous scenarios. FedMABench features 6 datasets with 30+ subsets, 8 federated algorithms, 10+ base models, and over 800 apps across 5 categories, providing a comprehensive framework for evaluating mobile agents across diverse environments. Through extensive experiments, we uncover several key insights: federated algorithms consistently outperform local training; the distribution of specific apps plays a crucial role in heterogeneity; and, even apps from distinct categories can exhibit correlations during training. FedMABench is publicly available at: this https URL with the datasets at: this https URL. 

**Abstract (ZH)**: 移动代理吸引了大量的研究参与。传统移动代理训练方法依赖于集中式数据收集，导致成本高且可扩展性有限。利用联邦学习进行分布式训练提供了一种替代方案，通过利用真实世界用户数据，实现了可扩展性和成本降低。然而，缺乏标准化基准数据阻碍了该领域的发展。

为应对这些挑战，我们提出FedMABench，这是首个针对异构场景下移动代理联邦训练与评估的标准基准。FedMABench包括6个数据集（30多个子集）、8种联邦算法、10多种基础模型以及超过800个应用（涵盖5个类别），提供了一个全面的框架，用于评估不同环境下的移动代理。通过大量实验，我们揭示了几个关键洞察：联邦算法始终优于局部训练；特定应用的分布对于异构性至关重要；即使来自不同类别的应用在训练中也可能表现出相关性。FedMABench已公开发布：[这里](this https URL)，数据集获取地址：[这里](this https URL)。 

---
# Exploring FMCW Radars and Feature Maps for Activity Recognition: A Benchmark Study 

**Title (ZH)**: 探索FMCW雷达与特征图在活动识别中的应用：一项基准研究 

**Authors**: Ali Samimi Fard, Mohammadreza Mashhadigholamali, Samaneh Zolfaghari, Hajar Abedi, Mainak Chakraborty, Luigi Borzì, Masoud Daneshtalab, George Shaker  

**Link**: [PDF](https://arxiv.org/pdf/2503.05629)  

**Abstract**: Human Activity Recognition has gained significant attention due to its diverse applications, including ambient assisted living and remote sensing. Wearable sensor-based solutions often suffer from user discomfort and reliability issues, while video-based methods raise privacy concerns and perform poorly in low-light conditions or long ranges. This study introduces a Frequency-Modulated Continuous Wave radar-based framework for human activity recognition, leveraging a 60 GHz radar and multi-dimensional feature maps. Unlike conventional approaches that process feature maps as images, this study feeds multi-dimensional feature maps -- Range-Doppler, Range-Azimuth, and Range-Elevation -- as data vectors directly into the machine learning (SVM, MLP) and deep learning (CNN, LSTM, ConvLSTM) models, preserving the spatial and temporal structures of the data. These features were extracted from a novel dataset with seven activity classes and validated using two different validation approaches. The ConvLSTM model outperformed conventional machine learning and deep learning models, achieving an accuracy of 90.51% and an F1-score of 87.31% on cross-scene validation and an accuracy of 89.56% and an F1-score of 87.15% on leave-one-person-out cross-validation. The results highlight the approach's potential for scalable, non-intrusive, and privacy-preserving activity monitoring in real-world scenarios. 

**Abstract (ZH)**: 基于频段调制连续波雷达的人体活动识别框架：一种多维特征图在机器学习和深度学习中的应用 

---
# Superintelligence Strategy: Expert Version 

**Title (ZH)**: 超人工智能策略：专家版 

**Authors**: Dan Hendrycks, Eric Schmidt, Alexandr Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.05628)  

**Abstract**: Rapid advances in AI are beginning to reshape national security. Destabilizing AI developments could rupture the balance of power and raise the odds of great-power conflict, while widespread proliferation of capable AI hackers and virologists would lower barriers for rogue actors to cause catastrophe. Superintelligence -- AI vastly better than humans at nearly all cognitive tasks -- is now anticipated by AI researchers. Just as nations once developed nuclear strategies to secure their survival, we now need a coherent superintelligence strategy to navigate a new period of transformative change. We introduce the concept of Mutual Assured AI Malfunction (MAIM): a deterrence regime resembling nuclear mutual assured destruction (MAD) where any state's aggressive bid for unilateral AI dominance is met with preventive sabotage by rivals. Given the relative ease of sabotaging a destabilizing AI project -- through interventions ranging from covert cyberattacks to potential kinetic strikes on datacenters -- MAIM already describes the strategic picture AI superpowers find themselves in. Alongside this, states can increase their competitiveness by bolstering their economies and militaries through AI, and they can engage in nonproliferation to rogue actors to keep weaponizable AI capabilities out of their hands. Taken together, the three-part framework of deterrence, nonproliferation, and competitiveness outlines a robust strategy to superintelligence in the years ahead. 

**Abstract (ZH)**: AI快速发展开始重塑国家安全。不稳定的人工智能发展可能破坏权力平衡并增加大国冲突的可能性，而人工智能黑客和病毒学家的广泛扩散会降低流氓行为体引发灾难的门槛。超级智能——在几乎所有认知任务上远远超过人类的人工智能——现已为人工智能研究人员所预期。正如各国曾经制定核策略以确保自身的生存一样，我们现在需要一个连贯的超级人工智能战略来应对一次变革性变革时期的到来。我们提出了相互确保人工智能故障(MAIM)的概念：一种类似于核相互确保摧毁(MAD)的威慑机制，任何国家试图单方面追求人工智能主导地位的行为都可能受到对手的预防性破坏。鉴于对不稳定人工智能项目的破坏相对容易——从隐蔽网络攻击到可能的数据中心物理打击等干预措施——MAIM已经描述了人工智能超级大国所面临的战略格局。同时，各国可以通过增强经济和军事来提高竞争力，并通过非扩散努力防止将武器化的人工智能能力落入流氓行为体之手。整体来看，威慑、非扩散和竞争力三部分框架概述了在未来几年应对超级智能的稳健策略。 

---
# Compliance of AI Systems 

**Title (ZH)**: AI系统的合规性 

**Authors**: Julius Schöning, Niklas Kruse  

**Link**: [PDF](https://arxiv.org/pdf/2503.05571)  

**Abstract**: The increasing integration of artificial intelligence (AI) systems in various fields requires solid concepts to ensure compliance with upcoming legislation. This paper systematically examines the compliance of AI systems with relevant legislation, focusing on the EU's AI Act and the compliance of data sets. The analysis highlighted many challenges associated with edge devices, which are increasingly being used to deploy AI applications closer and closer to the data sources. Such devices often face unique issues due to their decentralized nature and limited computing resources for implementing sophisticated compliance mechanisms. By analyzing AI implementations, the paper identifies challenges and proposes the first best practices for legal compliance when developing, deploying, and running AI. The importance of data set compliance is highlighted as a cornerstone for ensuring the trustworthiness, transparency, and explainability of AI systems, which must be aligned with ethical standards set forth in regulatory frameworks such as the AI Act. The insights gained should contribute to the ongoing discourse on the responsible development and deployment of embedded AI systems. 

**Abstract (ZH)**: 人工智能系统在各领域的不断增加集成要求具备坚实的概念以确保符合即将出台的立法规定。本文系统性地研究了人工智能系统与相关立法的合规性，重点考察了欧盟AI法案以及数据集的合规性。分析指出，边缘设备越来越多地被用于更接近数据来源部署人工智能应用，这些设备因其去中心化特性以及有限的计算资源来实施复杂合规机制而面临独特的问题。通过分析人工智能实现方式，本文识别出挑战并提出了在开发、部署和运行人工智能时的首批最佳实践方法。数据集合规的重要性被突出强调，作为确保人工智能系统可信、透明和可解释性的基石，必须与伦理标准保持一致，这些标准由如AI法案等监管框架设定。获得的见解应有助于人工智能嵌入系统的负责任开发和部署的持续讨论。 

---
# Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept Representations 

**Title (ZH)**: 事后概念去纠缠：从相关到独立概念表示 

**Authors**: Eren Erogullari, Sebastian Lapuschkin, Wojciech Samek, Frederik Pahde  

**Link**: [PDF](https://arxiv.org/pdf/2503.05522)  

**Abstract**: Concept Activation Vectors (CAVs) are widely used to model human-understandable concepts as directions within the latent space of neural networks. They are trained by identifying directions from the activations of concept samples to those of non-concept samples. However, this method often produces similar, non-orthogonal directions for correlated concepts, such as "beard" and "necktie" within the CelebA dataset, which frequently co-occur in images of men. This entanglement complicates the interpretation of concepts in isolation and can lead to undesired effects in CAV applications, such as activation steering. To address this issue, we introduce a post-hoc concept disentanglement method that employs a non-orthogonality loss, facilitating the identification of orthogonal concept directions while preserving directional correctness. We evaluate our approach with real-world and controlled correlated concepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18 architectures. We further demonstrate the superiority of orthogonalized concept representations in activation steering tasks, allowing (1) the insertion of isolated concepts into input images through generative models and (2) the removal of concepts for effective shortcut suppression with reduced impact on correlated concepts in comparison to baseline CAVs. 

**Abstract (ZH)**: Concept Activation Vectors (CAVs) 在潜空间中的可解释概念 Modeling through Post-hoc Concept Disentanglement by Non-Orthogonality Loss 

---
# Noise-Robust Radio Frequency Fingerprint Identification Using Denoise Diffusion Model 

**Title (ZH)**: 噪声鲁棒的射频指纹识别方法：基于降噪扩散模型 

**Authors**: Guolin Yin, Junqing Zhang, Yuan Ding, Simon Cotton  

**Link**: [PDF](https://arxiv.org/pdf/2503.05514)  

**Abstract**: Securing Internet of Things (IoT) devices presents increasing challenges due to their limited computational and energy resources. Radio Frequency Fingerprint Identification (RFFI) emerges as a promising authentication technique to identify wireless devices through hardware impairments. RFFI performance under low signal-to-noise ratio (SNR) scenarios is significantly degraded because the minute hardware features can be easily swamped in noise. In this paper, we leveraged the diffusion model to effectively restore the RFF under low SNR scenarios. Specifically, we trained a powerful noise predictor and tailored a noise removal algorithm to effectively reduce the noise level in the received signal and restore the device fingerprints. We used Wi-Fi as a case study and created a testbed involving 6 commercial off-the-shelf Wi-Fi dongles and a USRP N210 software-defined radio (SDR) platform. We conducted experimental evaluations on various SNR scenarios. The experimental results show that the proposed algorithm can improve the classification accuracy by up to 34.9%. 

**Abstract (ZH)**: 物联网设备的安全性由于其有限的计算能力和能源资源而面临不断增加的挑战。射频指纹识别（RFFI）作为一种通过硬件缺陷识别无线设备的有希望的认证技术逐渐浮现。在低信噪比（SNR）场景下，RFFI的性能显著下降，因为细微的硬件特征容易被噪声淹没。在本文中，我们利用扩散模型有效地恢复了低SNR场景下的RFF。具体而言，我们训练了一个强大的噪声预测器，并设计了一种噪声去除算法，以有效降低接收到的信号中的噪声水平并恢复设备指纹。我们将Wi-Fi作为案例研究，并构建了一个包含6个商用Wi-Fi dongles和一个USRP N210软件定义无线电（SDR）平台的测试床。我们在不同的SNR场景下进行了实验评估。实验结果表明，所提出的算法可以将分类精度提高多达34.9%。 

---
# EuroBERT: Scaling Multilingual Encoders for European Languages 

**Title (ZH)**: 欧罗巴语BERT：扩展多语言编码器以应用到欧洲语言 

**Authors**: Nicolas Boizard, Hippolyte Gisserot-Boukhlef, Duarte M. Alves, André Martins, Ayoub Hammal, Caio Corro, Céline Hudelot, Emmanuel Malherbe, Etienne Malaboeuf, Fanny Jourdan, Gabriel Hautreux, João Alves, Kevin El-Haddad, Manuel Faysse, Maxime Peyrard, Nuno M. Guerreiro, Patrick Fernandes, Ricardo Rei, Pierre Colombo  

**Link**: [PDF](https://arxiv.org/pdf/2503.05500)  

**Abstract**: General-purpose multilingual vector representations, used in retrieval, regression and classification, are traditionally obtained from bidirectional encoder models. Despite their wide applicability, encoders have been recently overshadowed by advances in generative decoder-only models. However, many innovations driving this progress are not inherently tied to decoders. In this paper, we revisit the development of multilingual encoders through the lens of these advances, and introduce EuroBERT, a family of multilingual encoders covering European and widely spoken global languages. Our models outperform existing alternatives across a diverse range of tasks, spanning multilingual capabilities, mathematics, and coding, and natively supporting sequences of up to 8,192 tokens. We also examine the design decisions behind EuroBERT, offering insights into our dataset composition and training pipeline. We publicly release the EuroBERT models, including intermediate training checkpoints, together with our training framework. 

**Abstract (ZH)**: 通用多语言向量表示在检索、回归和分类中广泛应用，传统上是从双向编码器模型中获取的。尽管它们具有广泛的应用前景，编码器最近已被生成型解码器模型的进步所超越。然而，驱动这一进展的许多创新并非固有地与解码器相关。在本文中，我们通过这些进步的视角回顾多语言编码器的发展，并介绍了EuroBERT这一涵盖欧洲及广泛使用的全球语言的多语言编码器家族。我们的模型在一系列任务中表现出色，涵盖多语言能力、数学和编码领域，并原生支持最大8,192个令牌的序列。我们还分析了EuroBERT的设计决策，提供了关于数据集组成和训练管道的见解。我们公开发布了EuroBERT模型及其中间训练检查点，以及我们的训练框架。 

---
# Personalized Federated Learning via Learning Dynamic Graphs 

**Title (ZH)**: 基于学习动态图的个性化 federated 学习 

**Authors**: Ziran Zhou, Guanyu Gao, Xiaohu Wu, Yan Lyu  

**Link**: [PDF](https://arxiv.org/pdf/2503.05474)  

**Abstract**: Personalized Federated Learning (PFL) aims to train a personalized model for each client that is tailored to its local data distribution, learning fails to perform well on individual clients due to variations in their local data distributions. Most existing PFL methods focus on personalizing the aggregated global model for each client, neglecting the fundamental aspect of federated learning: the regulation of how client models are aggregated. Additionally, almost all of them overlook the graph structure formed by clients in federated learning. In this paper, we propose a novel method, Personalized Federated Learning with Graph Attention Network (pFedGAT), which captures the latent graph structure between clients and dynamically determines the importance of other clients for each client, enabling fine-grained control over the aggregation process. We evaluate pFedGAT across multiple data distribution scenarios, comparing it with twelve state of the art methods on three datasets: Fashion MNIST, CIFAR-10, and CIFAR-100, and find that it consistently performs well. 

**Abstract (ZH)**: 基于图注意力网络的个性化联邦学习（Personalized Federated Learning with Graph Attention Network, pFedGAT） 

---
# Controllable Complementarity: Subjective Preferences in Human-AI Collaboration 

**Title (ZH)**: 可控互补性：人类与AI协作中的主观偏好 

**Authors**: Chase McDonald, Cleotilde Gonzalez  

**Link**: [PDF](https://arxiv.org/pdf/2503.05455)  

**Abstract**: Research on human-AI collaboration often prioritizes objective performance. However, understanding human subjective preferences is essential to improving human-AI complementarity and human experiences. We investigate human preferences for controllability in a shared workspace task with AI partners using Behavior Shaping (BS), a reinforcement learning algorithm that allows humans explicit control over AI behavior.
In one experiment, we validate the robustness of BS in producing effective AI policies relative to self-play policies, when controls are hidden. In another experiment, we enable human control, showing that participants perceive AI partners as more effective and enjoyable when they can directly dictate AI behavior. Our findings highlight the need to design AI that prioritizes both task performance and subjective human preferences. By aligning AI behavior with human preferences, we demonstrate how human-AI complementarity can extend beyond objective outcomes to include subjective preferences. 

**Abstract (ZH)**: 关于人类与人工智能协作的研究往往侧重于客观性能。然而，理解人类的主观偏好对于提高人类与人工智能的互补性和人类体验至关重要。我们通过一种允许人类对人工智能行为进行显式控制的行为塑造（BS）强化学习算法，研究了人类在与人工智能伙伴共同工作空间任务中对可控性的偏好。在一项实验中，我们验证了在隐藏控制的情况下，BS相比自我博弈政策的健壮性。在另一项实验中，我们赋予了人类控制权，表明参与者在能够直接指导人工智能行为时，认为人工智能伙伴更有效且更令人愉悦。我们的研究结果强调了设计兼顾任务性能和主观人类偏好的人工智能的必要性。通过使人工智能行为与人类偏好相一致，我们展示了人类与人工智能的互补性可以超出客观结果，还包括主观偏好。 

---
# Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts 

**Title (ZH)**: 线性-MoE：线性序列建模与混合专家模型的结合 

**Authors**: Weigao Sun, Disen Lan, Tong Zhu, Xiaoye Qu, Yu Cheng  

**Link**: [PDF](https://arxiv.org/pdf/2503.05447)  

**Abstract**: Linear Sequence Modeling (LSM) like linear attention, state space models and linear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant architectural improvements. In this paper, we introduce Linear-MoE, a production-level system for modeling and training large-scale models that integrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules for linear-complexity sequence modeling and MoE layers for sparsely activation, aiming to offer high performance with efficient training. The Linear-MoE system comprises: 1) Modeling subsystem, which provides a unified framework supporting all instances of LSM. and 2) Training subsystem, which facilitates efficient training by incorporating various advanced parallelism technologies, particularly Sequence Parallelism designed for Linear-MoE models. Additionally, we explore hybrid models that combine Linear-MoE layers with standard Transformer-MoE layers with its Sequence Parallelism to further enhance model flexibility and performance. Evaluations on two model series, A0.3B-2B and A1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining competitive performance on various benchmarks, showcasing its potential as a next-generation foundational model architecture. Code: this https URL. 

**Abstract (ZH)**: 线性混合专家（Linear-MoE）：结合线性序列模型与混合专家的生产级系统 

---
# Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning 

**Title (ZH)**: 基于双投影和分类器重构的示例无类增量学习语义转移估计 

**Authors**: Run He, Di Fang, Yicheng Xu, Yawen Cui, Ming Li, Cen Chen, Ziqian Zeng, Huiping Zhuang  

**Link**: [PDF](https://arxiv.org/pdf/2503.05423)  

**Abstract**: Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn from distinct categories without retaining exemplars but easily suffers from catastrophic forgetting of learned knowledge. While existing EFCIL methods leverage knowledge distillation to alleviate forgetting, they still face two critical challenges: semantic shift and decision bias. Specifically, the embeddings of old tasks shift in the embedding space after learning new tasks, and the classifier becomes biased towards new tasks due to training solely with new data, thereby hindering the balance between old and new knowledge. To address these issues, we propose the Dual-Projection Shift Estimation and Classifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates semantic shift through a dual-projection, which combines a learnable transformation with a row-space projection to capture both task-wise and category-wise shifts. Furthermore, to mitigate decision bias, DPCR employs ridge regression to reformulate classifier training as a reconstruction process. This reconstruction exploits previous information encoded in covariance and prototype of each class after calibration with estimated shift, thereby reducing decision bias. Extensive experiments demonstrate that, across various datasets, DPCR effectively balances old and new tasks, outperforming state-of-the-art EFCIL methods. 

**Abstract (ZH)**: Exemplar-Free Class-Incremental Learning without Catastrophic Forgetting via Dual-Projection Shift Estimation and Classifier Reconstruction 

---
# Improving Hate Speech Classification with Cross-Taxonomy Dataset Integration 

**Title (ZH)**: 跨 taxonomy 数据集整合以改进仇恨言论分类 

**Authors**: Jan Fillies, Adrian Paschke  

**Link**: [PDF](https://arxiv.org/pdf/2503.05357)  

**Abstract**: Algorithmic hate speech detection faces significant challenges due to the diverse definitions and datasets used in research and practice. Social media platforms, legal frameworks, and institutions each apply distinct yet overlapping definitions, complicating classification efforts. This study addresses these challenges by demonstrating that existing datasets and taxonomies can be integrated into a unified model, enhancing prediction performance and reducing reliance on multiple specialized classifiers. The work introduces a universal taxonomy and a hate speech classifier capable of detecting a wide range of definitions within a single framework. Our approach is validated by combining two widely used but differently annotated datasets, showing improved classification performance on an independent test set. This work highlights the potential of dataset and taxonomy integration in advancing hate speech detection, increasing efficiency, and ensuring broader applicability across contexts. 

**Abstract (ZH)**: 算法仇恨言论检测面临着由于研究和实践中使用的多样定义和数据集所造成的重大挑战。社会媒体平台、法律框架和机构各自采用不同的但又相互重叠的定义，这使得分类工作变得复杂。本研究通过展示现有数据集和分类法可以整合到一个统一模型中，从而提高预测性能并减少对多种专门分类器的依赖，来应对这些挑战。这项工作提出了一种通用分类法和一个能够在一个框架内检测广泛定义的仇恨言论分类器。我们的方法通过结合两个广泛使用的但标注不同的数据集得以验证，在独立测试集上展示了改进的分类性能。这项工作强调了数据集和分类法整合在推进仇恨言论检测方面的潜力，提高了效率，并确保了更广泛的适用性。 

---
# On the Logical Content of Logic Programs 

**Title (ZH)**: 逻辑程序中的逻辑内容 

**Authors**: Alexader V. Gheorghiu  

**Link**: [PDF](https://arxiv.org/pdf/2503.05355)  

**Abstract**: Logic programming (LP) is typically understood through operational semantics (e.g., SLD-resolution) or model-theoretic interpretations (e.g., the least Herbrand model). This paper introduces a novel perspective on LP by defining a ``support'' relation that explicates what a program ``knows''. This interpretation is shown to express classical and intuitionistic logic, as well as an intermediate logic, depending on certain choices regarding LP and the meanings of disjunction and negation. These results are formalized using the idea of base-extension semantics within proof-theoretic semantics. Our approach offers new insights into the logical foundations of LP and has potential applications in knowledge representation, automated reasoning, and formal verification. 

**Abstract (ZH)**: 逻辑编程的一种新型视角：通过“支持”关系阐明程序的“知识” 

---
# Spatial Distillation based Distribution Alignment (SDDA) for Cross-Headset EEG Classification 

**Title (ZH)**: 基于空间蒸馏的分布对齐（SDDA）方法在跨头戴设备EEG分类中的应用 

**Authors**: Dingkun Liu, Siyang Li, Ziwei Wang, Wei Li, Dongrui Wu  

**Link**: [PDF](https://arxiv.org/pdf/2503.05349)  

**Abstract**: A non-invasive brain-computer interface (BCI) enables direct interaction between the user and external devices, typically via electroencephalogram (EEG) signals. However, decoding EEG signals across different headsets remains a significant challenge due to differences in the number and locations of the electrodes. To address this challenge, we propose a spatial distillation based distribution alignment (SDDA) approach for heterogeneous cross-headset transfer in non-invasive BCIs. SDDA uses first spatial distillation to make use of the full set of electrodes, and then input/feature/output space distribution alignments to cope with the significant differences between the source and target domains. To our knowledge, this is the first work to use knowledge distillation in cross-headset transfers. Extensive experiments on six EEG datasets from two BCI paradigms demonstrated that SDDA achieved superior performance in both offline unsupervised domain adaptation and online supervised domain adaptation scenarios, consistently outperforming 10 classical and state-of-the-art transfer learning algorithms. 

**Abstract (ZH)**: 一种基于空间蒸馏的分布对齐方法（SDDA）在跨头盔非侵入式脑机接口中的异质域迁移 

---
# Speculative Decoding for Multi-Sample Inference 

**Title (ZH)**: 推测解码for多样本推理 

**Authors**: Yiwei Li, Jiayi Shi, Shaoxiong Feng, Peiwen Yuan, Xinglin Wang, Yueqi Zhang, Ji Zhang, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.05330)  

**Abstract**: We propose a novel speculative decoding method tailored for multi-sample reasoning scenarios, such as self-consistency and Best-of-N sampling. Our method exploits the intrinsic consensus of parallel generation paths to synthesize high-quality draft tokens without requiring auxiliary models or external databases. By dynamically analyzing structural patterns across parallel reasoning paths through a probabilistic aggregation mechanism, it identifies consensus token sequences that align with the decoding distribution. Evaluations on mathematical reasoning benchmarks demonstrate a substantial improvement in draft acceptance rates over baselines, while reducing the latency in draft token construction. This work establishes a paradigm shift for efficient multi-sample inference, enabling seamless integration of speculative decoding with sampling-based reasoning techniques. 

**Abstract (ZH)**: 我们提出了一种专门针对多样本推理场景（如自我一致性及Best-of-N采样）的新型推测性解码方法。该方法利用并行生成路径内的固有共识来合成高质量的草稿令牌，无需辅助模型或外部数据库。通过概率聚合机制动态分析并行推理路径中的结构模式，它能够识别与解码分布相一致的共识令牌序列。在数学推理基准测试上的评估表明，与基线方法相比，该方法在草稿接纳率上取得了显著提高，同时降低了草稿令牌构建的延迟。这项工作确立了高效多样本推理的新范式，使得推测性解码与基于采样的推理技术无缝集成。 

---
# Disentangling Task Interference within Neurons: Model Merging in Alignment with Neuronal Mechanisms 

**Title (ZH)**: 在神经机制一致性的框架下解纠缠任务干扰：神经元内模型融合 

**Authors**: Zitao Fang, Guodong DU, Shuyang Yu, Yifei Guo, Yiwei Zhang, Jing Li, Ho-Kin Tang, Sim Kuan Goh  

**Link**: [PDF](https://arxiv.org/pdf/2503.05320)  

**Abstract**: Fine-tuning pre-trained models on targeted datasets enhances task-specific performance but often comes at the expense of generalization. Model merging techniques, which integrate multiple fine-tuned models into a single multi-task model through task arithmetic at various levels: model, layer, or parameter, offer a promising solution. However, task interference remains a fundamental challenge, leading to performance degradation and suboptimal merged models. Existing approaches largely overlook the fundamental role of individual neurons and their connectivity, resulting in a lack of interpretability in both the merging process and the merged models. In this work, we present the first study on the impact of neuronal alignment in model merging. We decompose task-specific representations into two complementary neuronal subspaces that regulate neuron sensitivity and input adaptability. Leveraging this decomposition, we introduce NeuroMerging, a novel merging framework developed to mitigate task interference within neuronal subspaces, enabling training-free model fusion across diverse tasks. Through extensive experiments, we demonstrate that NeuroMerging achieves superior performance compared to existing methods on multi-task benchmarks across both vision and natural language domains. Our findings highlight the importance of aligning neuronal mechanisms in model merging, offering new insights into mitigating task interference and improving knowledge fusion. 

**Abstract (ZH)**: 基于神经元对齐的模型合并对多任务学习的影响研究 

---
# PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and Latin Lexicons 

**Title (ZH)**: PhiloBERTA：基于Transformer的希腊语和拉丁语词典跨语言分析 

**Authors**: Rumi A. Allbert, Makai L. Allbert  

**Link**: [PDF](https://arxiv.org/pdf/2503.05265)  

**Abstract**: We present PhiloBERTA, a cross-lingual transformer model that measures semantic relationships between ancient Greek and Latin lexicons. Through analysis of selected term pairs from classical texts, we use contextual embeddings and angular similarity metrics to identify precise semantic alignments. Our results show that etymologically related pairs demonstrate significantly higher similarity scores, particularly for abstract philosophical concepts such as epistēmē (scientia) and dikaiosynē (iustitia). Statistical analysis reveals consistent patterns in these relationships (p = 0.012), with etymologically related pairs showing remarkably stable semantic preservation compared to control pairs. These findings establish a quantitative framework for examining how philosophical concepts moved between Greek and Latin traditions, offering new methods for classical philological research. 

**Abstract (ZH)**: 我们呈现PhiloBERTA，一种跨语言变换模型，用于测量古希腊语和拉丁语词典之间的语义关系。通过分析古典文献中选择的词对，我们使用上下文嵌入和角度相似性度量来识别精确的语义对齐。我们的结果表明，语源学上相关的词对显示出显著更高的相似分数，特别是在epistēmē（scientia）和dikaiosynē（iustitia）这样的抽象哲学概念方面。统计分析揭示了这些关系中一致的模式（p = 0.012），语源学上相关的词对在语义保真度方面显示出异常的稳定性，相比之下，控制词对则不是。这些发现为研究哲学概念如何在古希腊和拉丁传统之间转移建立了一个量化框架，为古典语言学研究提供了新的方法。 

---
# Jailbreaking is (Mostly) Simpler Than You Think 

**Title (ZH)**: 越狱并没有你想象的那么复杂 

**Authors**: Mark Russinovich, Ahmed Salem  

**Link**: [PDF](https://arxiv.org/pdf/2503.05264)  

**Abstract**: We introduce the Context Compliance Attack (CCA), a novel, optimization-free method for bypassing AI safety mechanisms. Unlike current approaches -- which rely on complex prompt engineering and computationally intensive optimization -- CCA exploits a fundamental architectural vulnerability inherent in many deployed AI systems. By subtly manipulating conversation history, CCA convinces the model to comply with a fabricated dialogue context, thereby triggering restricted behavior. Our evaluation across a diverse set of open-source and proprietary models demonstrates that this simple attack can circumvent state-of-the-art safety protocols. We discuss the implications of these findings and propose practical mitigation strategies to fortify AI systems against such elementary yet effective adversarial tactics. 

**Abstract (ZH)**: Context Compliance Attack: A Novel Method for Bypassing AI Safety Mechanisms 

---
# Robust Conformal Prediction with a Single Binary Certificate 

**Title (ZH)**: 单个二元证书的稳健同credible预测 

**Authors**: Soroush H. Zargarbashi, Aleksandar Bojchevski  

**Link**: [PDF](https://arxiv.org/pdf/2503.05239)  

**Abstract**: Conformal prediction (CP) converts any model's output to prediction sets with a guarantee to cover the true label with (adjustable) high probability. Robust CP extends this guarantee to worst-case (adversarial) inputs. Existing baselines achieve robustness by bounding randomly smoothed conformity scores. In practice, they need expensive Monte-Carlo (MC) sampling (e.g. $\sim10^4$ samples per point) to maintain an acceptable set size. We propose a robust conformal prediction that produces smaller sets even with significantly lower MC samples (e.g. 150 for CIFAR10). Our approach binarizes samples with an adjustable (or automatically adjusted) threshold selected to preserve the coverage guarantee. Remarkably, we prove that robustness can be achieved by computing only one binary certificate, unlike previous methods that certify each calibration (or test) point. Thus, our method is faster and returns smaller robust sets. We also eliminate a previous limitation that requires a bounded score function. 

**Abstract (ZH)**: 符合学术规范的标题翻译：

自适应预测 (CP) 将任何模型的输出转换为具有可调高概率覆盖真实标签的预测集。鲁棒 CP 将此保证扩展到最坏情况（对抗性）输入。现有Baseline通过限制随机平滑的一致性分数实现鲁棒性。实际上，它们需要昂贵的蒙特卡洛 (MC) 采样（例如，每个点约 $10^4$ 个样本）以保持可接受的集大小。我们提出了一种鲁棒预测，即使使用显著较少的MC样本（例如，CIFAR10 上为 150）也能生成更小的集。我们的方法使用可调（或自动调整）阈值对样本进行二值化，以保持覆盖保证。值得注意的是，我们证明了只需计算一个二值证书即可实现鲁棒性，而不像先前方法需要为每个校准（或测试）点进行验证。因此，我们的方法更快并返回更小的鲁棒集。我们还消除了先前需要有界评分函数的限制。 

---
# MOHPER: Multi-objective Hyperparameter Optimization Framework for E-commerce Retrieval System 

**Title (ZH)**: MOHPER：电子商务检索系统多目标超参数优化框架 

**Authors**: Jungbae Park, Heonseok Jang  

**Link**: [PDF](https://arxiv.org/pdf/2503.05227)  

**Abstract**: E-commerce search optimization has evolved to include a wider range of metrics that reflect user engagement and business objectives. Modern search frameworks now incorporate advanced quality features, such as sales counts and document-query relevance, to better align search results with these goals. Traditional methods typically focus on click-through rate (CTR) as a measure of engagement or relevance, but this can miss true purchase intent, creating a gap between user interest and actual conversions. Joint training with the click-through conversion rate (CTCVR) has become essential for understanding buying behavior, although its sparsity poses challenges for reliable optimization. This study presents MOHPER, a Multi-Objective Hyperparameter Optimization framework for E-commerce Retrieval systems. Utilizing Bayesian optimization and sampling, it jointly optimizes both CTR, CTCVR, and relevant objectives, focusing on engagement and conversion of the users. In addition, to improve the selection of the best configuration from multi-objective optimization, we suggest advanced methods for hyperparameter selection, including a meta-configuration voting strategy and a cumulative training approach that leverages prior optimal configurations, to improve speeds of training and efficiency. Currently deployed in a live setting, our proposed framework substantiates its practical efficacy in achieving a balanced optimization that aligns with both user satisfaction and revenue goals. 

**Abstract (ZH)**: 电子商务搜索优化已扩展到包括更广泛的指标，以反映用户参与度和企业目标。现代搜索框架现在整合了高级质量特征，如销售数量和文档查询相关性，以更好地使搜索结果与这些目标一致。传统方法通常以点击率（CTR）作为参与度或相关性的衡量标准，但可能会错过真实的购买意图，导致用户兴趣与实际转化之间产生差距。结合点击转化率（CTCVR）的联合训练已成为理解购买行为的必要手段，尽管其稀疏性给可靠的优化带来了挑战。本研究提出了一种面向电子商务检索系统的多目标超参数优化框架MOHPER。利用贝叶斯优化与采样，它联合优化了CTR、CTCVR以及相关目标，专注于用户的参与度和转化率。此外，为了提高多目标优化中最佳配置的选择，我们建议了高级超参数选择方法，包括元配置投票策略和利用先验最优配置的累积训练方法，以提高训练速度和效率。目前该框架已在实际环境中部署，证明其在兼顾用户满意度和收入目标方面具有实际效果。 

---
# Deep Sequence Models for Predicting Average Shear Wave Velocity from Strong Motion Records 

**Title (ZH)**: 基于强地面运动记录预测平均剪切波速的深层序列模型 

**Authors**: Baris Yilmaz, Erdem Akagündüz, Salih Tileylioglu  

**Link**: [PDF](https://arxiv.org/pdf/2503.05224)  

**Abstract**: This study explores the use of deep learning for predicting the time averaged shear wave velocity in the top 30 m of the subsurface ($V_{s30}$) at strong motion recording stations in Türkiye. $V_{s30}$ is a key parameter in site characterization and, as a result for seismic hazard assessment. However, it is often unavailable due to the lack of direct measurements and is therefore estimated using empirical correlations. Such correlations however are commonly inadequate in capturing complex, site-specific variability and this motivates the need for data-driven approaches. In this study, we employ a hybrid deep learning model combining convolutional neural networks (CNNs) and long short-term memory (LSTM) networks to capture both spatial and temporal dependencies in strong motion records. Furthermore, we explore how using different parts of the signal influence our deep learning model. Our results suggest that the hybrid approach effectively learns complex, nonlinear relationships within seismic signals. We observed that an improved P-wave arrival time model increased the prediction accuracy of $V_{s30}$. We believe the study provides valuable insights into improving $V_{s30}$ predictions using a CNN-LSTM framework, demonstrating its potential for improving site characterization for seismic studies. Our codes are available via this repo: this https URL 

**Abstract (ZH)**: 本研究探讨了使用深度学习预测土耳其强震记录站表层30米范围内的平均剪切波速度（$V_{s30}$）的方法。$V_{s30}$是场地表征中的关键参数，对于地震危害评估至关重要。然而，由于缺乏直接测量，$V_{s30}$往往不可用，因此通常使用经验相关方法来估算。然而，这些经验相关方法通常无法捕捉到复杂且场地特定的变化，因此本研究采用数据驱动的方法来解决这一问题。在本研究中，我们采用结合卷积神经网络（CNNs）和长短期记忆（LSTM）网络的混合深度学习模型，以捕捉强震记录中的时空依赖关系。此外，我们还探索了使用信号的不同部分如何影响深度学习模型。研究结果表明，混合方法能够有效地学习地震信号中的复杂非线性关系。我们发现，改进的P波到达时间模型提高了$V_{s30}$的预测精度。我们相信，本研究为使用CNN-LSTM框架改进$V_{s30}$预测提供了有价值的见解，展示了其在地震场地表征中的潜在应用价值。研究代码可通过以下链接获取：this https URL。 

---
# Deep Muscle EMG construction using A Physics-Integrated Deep Learning approach 

**Title (ZH)**: 基于物理整合深度学习的深部肌肉EMG构建 

**Authors**: Rajnish Kumar, Tapas Tripura, Souvik Chakraborty, Sitikantha Roy  

**Link**: [PDF](https://arxiv.org/pdf/2503.05201)  

**Abstract**: Electromyography (EMG)--based computational musculoskeletal modeling is a non-invasive method for studying musculotendon function, human movement, and neuromuscular control, providing estimates of internal variables like muscle forces and joint torques. However, EMG signals from deeper muscles are often challenging to measure by placing the surface EMG electrodes and unfeasible to measure directly using invasive methods. The restriction to the access of EMG data from deeper muscles poses a considerable obstacle to the broad adoption of EMG-driven modeling techniques. A strategic alternative is to use an estimation algorithm to approximate the missing EMG signals from deeper muscle. A similar strategy is used in physics-informed deep learning, where the features of physical systems are learned without labeled data. In this work, we propose a hybrid deep learning algorithm, namely the neural musculoskeletal model (NMM), that integrates physics-informed and data-driven deep learning to approximate the EMG signals from the deeper muscles. While data-driven modeling is used to predict the missing EMG signals, physics-based modeling engraves the subject-specific information into the predictions. Experimental verifications on five test subjects are carried out to investigate the performance of the proposed hybrid framework. The proposed NMM is validated against the joint torque computed from 'OpenSim' software. The predicted deep EMG signals are also compared against the state-of-the-art muscle synergy extrapolation (MSE) approach, where the proposed NMM completely outperforms the existing MSE framework by a significant margin. 

**Abstract (ZH)**: 基于 Electromyography (EMG) 的计算肌骨建模是一种非侵入性方法，用于研究肌肉肌腱功能、人体运动和神经肌肉控制，提供肌肉力量和关节扭矩等内部变量的估计。然而，深层肌肉的 EMG 信号往往难以通过表面 EMG 电极测量，使用侵入性方法直接测量也未必可行。受限于深层肌肉 EMG 数据的获取，困扰了 EMG 驱动建模技术的大规模应用。一种战略性的替代方案是使用估计算法来近似深层肌肉缺失的 EMG 信号。类似的方法在物理启发式的深度学习中使用，无需标注数据即可学习物理系统的特征。本文提出了一种结合物理启发式和数据驱动深度学习的混合算法——神经肌骨模型 (NMM)，用以近似深层肌肉的 EMG 信号。基于数据驱动的方法预测缺失的 EMG 信号，基于物理的方法将个体特异性信息嵌入预测中。通过五个受试者的实验验证了所提出的混合框架的性能。提出的 NMM 模型被验证与来自 'OpenSim' 软件计算的关节扭矩一致。预测的深层 EMG 信号还与最先进的肌群协同扩展 (MSE) 方法进行了比较，结果显示所提出的 NMM 明显优于现有的 MSE 框架。 

---
# Uncertainty-Aware Explainable Federated Learning 

**Title (ZH)**: 不确定性意识可解释联邦学习 

**Authors**: Yanci Zhang, Han Yu  

**Link**: [PDF](https://arxiv.org/pdf/2503.05194)  

**Abstract**: Federated Learning (FL) is a collaborative machine learning paradigm for enhancing data privacy preservation. Its privacy-preserving nature complicates the explanation of the decision-making processes and the evaluation of the reliability of the generated explanations. In this paper, we propose the Uncertainty-aware eXplainable Federated Learning (UncertainXFL) to address these challenges. It generates explanations for decision-making processes under FL settings and provides information regarding the uncertainty of these explanations. UncertainXFL is the first framework to explicitly offer uncertainty evaluation for explanations within the FL context. Explanatory information is initially generated by the FL clients and then aggregated by the server in a comprehensive and conflict-free manner during FL training. The quality of the explanations, including the uncertainty score and tested validity, guides the FL training process by prioritizing clients with the most reliable explanations through higher weights during model aggregation. Extensive experimental evaluation results demonstrate that UncertainXFL achieves superior model accuracy and explanation accuracy, surpassing the current state-of-the-art model that does not incorporate uncertainty information by 2.71% and 1.77%, respectively. By integrating and quantifying uncertainty in the data into the explanation process, UncertainXFL not only clearly presents the explanation alongside its uncertainty, but also leverages this uncertainty to guide the FL training process, thereby enhancing the robustness and reliability of the resulting models. 

**Abstract (ZH)**: 联邦学习中的不确定性感知可解释联邦学习（Uncertainty-aware eXplainable Federated Learning） 

---
# FinTMMBench: Benchmarking Temporal-Aware Multi-Modal RAG in Finance 

**Title (ZH)**: FinTMMBench: 基于时间感知的多模态RAG在金融领域的基准测试 

**Authors**: Fengbin Zhu, Junfeng Li, Liangming Pan, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, Tat-Seng Chua  

**Link**: [PDF](https://arxiv.org/pdf/2503.05185)  

**Abstract**: Finance decision-making often relies on in-depth data analysis across various data sources, including financial tables, news articles, stock prices, etc. In this work, we introduce FinTMMBench, the first comprehensive benchmark for evaluating temporal-aware multi-modal Retrieval-Augmented Generation (RAG) systems in finance. Built from heterologous data of NASDAQ 100 companies, FinTMMBench offers three significant advantages. 1) Multi-modal Corpus: It encompasses a hybrid of financial tables, news articles, daily stock prices, and visual technical charts as the corpus. 2) Temporal-aware Questions: Each question requires the retrieval and interpretation of its relevant data over a specific time period, including daily, weekly, monthly, quarterly, and annual periods. 3) Diverse Financial Analysis Tasks: The questions involve 10 different tasks, including information extraction, trend analysis, sentiment analysis and event detection, etc. We further propose a novel TMMHybridRAG method, which first leverages LLMs to convert data from other modalities (e.g., tabular, visual and time-series data) into textual format and then incorporates temporal information in each node when constructing graphs and dense indexes. Its effectiveness has been validated in extensive experiments, but notable gaps remain, highlighting the challenges presented by our FinTMMBench. 

**Abstract (ZH)**: 金融决策往往依赖于对各种数据源的深入数据分析，包括财务报表、新闻文章、股票价格等。在此工作中，我们引入了FinTMMBench，这是首个用于评估金融市场中感知时间的多模态检索增强生成（RAG）系统的综合性基准。FinTMMBench基于纳斯达克100家公司异构数据构建，具有三大显著优势。1) 多模态语料库：其中包括财务报表、新闻文章、每日股票价格和可视化技术图表的混合体。2) 感知时间的问题：每个问题都需要在特定时间段内检索和解释其相关数据，包括日、周、月、季度和年度等时间段。3) 多样化的金融分析任务：问题涉及10种不同的任务，包括信息提取、趋势分析、情感分析和事件检测等。我们进一步提出了一种新型的TMMHybridRAG方法，该方法首先利用预训练语言模型将其他模态的数据（例如表、图和时间序列数据）转换为文本格式，然后在构建图和密集索引时在每个节点中融入时间信息。该方法已在大量实验中得到验证，但仍存在显著差距，突显了我们FinTMMBench带来的挑战。 

---
# TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting 

**Title (ZH)**: TS-LIF: 一种用于时间序列预测的时序段脉冲神经网络 

**Authors**: Shibo Feng, Wanjin Feng, Xingyu Gao, Peilin Zhao, Zhiqi Shen  

**Link**: [PDF](https://arxiv.org/pdf/2503.05108)  

**Abstract**: Spiking Neural Networks (SNNs) offer a promising, biologically inspired approach for processing spatiotemporal data, particularly for time series forecasting. However, conventional neuron models like the Leaky Integrate-and-Fire (LIF) struggle to capture long-term dependencies and effectively process multi-scale temporal dynamics. To overcome these limitations, we introduce the Temporal Segment Leaky Integrate-and-Fire (TS-LIF) model, featuring a novel dual-compartment architecture. The dendritic and somatic compartments specialize in capturing distinct frequency components, providing functional heterogeneity that enhances the neuron's ability to process both low- and high-frequency information. Furthermore, the newly introduced direct somatic current injection reduces information loss during intra-neuronal transmission, while dendritic spike generation improves multi-scale information extraction. We provide a theoretical stability analysis of the TS-LIF model and explain how each compartment contributes to distinct frequency response characteristics. Experimental results show that TS-LIF outperforms traditional SNNs in time series forecasting, demonstrating better accuracy and robustness, even with missing data. TS-LIF advances the application of SNNs in time-series forecasting, providing a biologically inspired approach that captures complex temporal dynamics and offers potential for practical implementation in diverse forecasting scenarios. The source code is available at this https URL. 

**Abstract (ZH)**: 时空段漏积分火（TS-LIF）模型：用于时间序列预测的生物启发式方法 

---
# Grouped Sequential Optimization Strategy -- the Application of Hyperparameter Importance Assessment in Deep Learning 

**Title (ZH)**: 分组序贯优化策略——超参数重要性评估在深度学习中的应用 

**Authors**: Ruinan Wang, Ian Nabney, Mohammad Golbabaee  

**Link**: [PDF](https://arxiv.org/pdf/2503.05106)  

**Abstract**: Hyperparameter optimization (HPO) is a critical component of machine learning pipelines, significantly affecting model robustness, stability, and generalization. However, HPO is often a time-consuming and computationally intensive task. Traditional HPO methods, such as grid search and random search, often suffer from inefficiency. Bayesian optimization, while more efficient, still struggles with high-dimensional search spaces. In this paper, we contribute to the field by exploring how insights gained from hyperparameter importance assessment (HIA) can be leveraged to accelerate HPO, reducing both time and computational resources. Building on prior work that quantified hyperparameter importance by evaluating 10 hyperparameters on CNNs using 10 common image classification datasets, we implement a novel HPO strategy called 'Sequential Grouping.' That prior work assessed the importance weights of the investigated hyperparameters based on their influence on model performance, providing valuable insights that we leverage to optimize our HPO process. Our experiments, validated across six additional image classification datasets, demonstrate that incorporating hyperparameter importance assessment (HIA) can significantly accelerate HPO without compromising model performance, reducing optimization time by an average of 31.9\% compared to the conventional simultaneous strategy. 

**Abstract (ZH)**: 基于超参数重要性评估的加速超参数优化方法 

---
# Object Packing and Scheduling for Sequential 3D Printing: a Linear Arithmetic Model and a CEGAR-inspired Optimal Solver 

**Title (ZH)**: 面向顺序3D打印的物体打包与调度：线性算术模型及CEGAR启发式最优求解器 

**Authors**: Pavel Surynek, Vojtěch Bubník, Lukáš Matěna, Petr Kubiš  

**Link**: [PDF](https://arxiv.org/pdf/2503.05071)  

**Abstract**: We address the problem of object arrangement and scheduling for sequential 3D printing. Unlike the standard 3D printing, where all objects are printed slice by slice at once, in sequential 3D printing, objects are completed one after other. In the sequential case, it is necessary to ensure that the moving parts of the printer do not collide with previously printed objects. We look at the sequential printing problem from the perspective of combinatorial optimization. We propose to express the problem as a linear arithmetic formula, which is then solved using a solver for satisfiability modulo theories (SMT). However, we do not solve the formula expressing the problem of object arrangement and scheduling directly, but we have proposed a technique inspired by counterexample guided abstraction refinement (CEGAR), which turned out to be a key innovation to efficiency. 

**Abstract (ZH)**: 序列3D打印中的对象布置与调度问题 

---
# Accelerated Patient-specific Non-Cartesian MRI Reconstruction using Implicit Neural Representations 

**Title (ZH)**: 基于隐式神经表示的加速患者特定非笛卡尔MRI重建 

**Authors**: Di Xu, Hengjie Liu, Xin Miao, Daniel O'Connor, Jessica E. Scholey, Wensha Yang, Mary Feng, Michael Ohliger, Hui Lin, Dan Ruan, Yang Yang, Ke Sheng  

**Link**: [PDF](https://arxiv.org/pdf/2503.05051)  

**Abstract**: The scanning time for a fully sampled MRI can be undesirably lengthy. Compressed sensing has been developed to minimize image artifacts in accelerated scans, but the required iterative reconstruction is computationally complex and difficult to generalize on new cases. Image-domain-based deep learning methods (e.g., convolutional neural networks) emerged as a faster alternative but face challenges in modeling continuous k-space, a problem amplified with non-Cartesian sampling commonly used in accelerated acquisition. In comparison, implicit neural representations can model continuous signals in the frequency domain and thus are compatible with arbitrary k-space sampling patterns. The current study develops a novel generative-adversarially trained implicit neural representations (k-GINR) for de novo undersampled non-Cartesian k-space reconstruction. k-GINR consists of two stages: 1) supervised training on an existing patient cohort; 2) self-supervised patient-specific optimization. In stage 1, the network is trained with the generative-adversarial network on diverse patients of the same anatomical region supervised by fully sampled acquisition. In stage 2, undersampled k-space data of individual patients is used to tailor the prior-embedded network for patient-specific optimization. The UCSF StarVIBE T1-weighted liver dataset was evaluated on the proposed framework. k-GINR is compared with an image-domain deep learning method, Deep Cascade CNN, and a compressed sensing method. k-GINR consistently outperformed the baselines with a larger performance advantage observed at very high accelerations (e.g., 20 times). k-GINR offers great value for direct non-Cartesian k-space reconstruction for new incoming patients across a wide range of accelerations liver anatomy. 

**Abstract (ZH)**: 基于隐式神经表示的生成对抗训练方法用于非笛卡尔编码下采样k空间重建 

---
# Provably Correct Automata Embeddings for Optimal Automata-Conditioned Reinforcement Learning 

**Title (ZH)**: 可证明正确的自动机嵌入以实现最优自动机条件强化学习 

**Authors**: Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia  

**Link**: [PDF](https://arxiv.org/pdf/2503.05042)  

**Abstract**: Automata-conditioned reinforcement learning (RL) has given promising results for learning multi-task policies capable of performing temporally extended objectives given at runtime, done by pretraining and freezing automata embeddings prior to training the downstream policy. However, no theoretical guarantees were given. This work provides a theoretical framework for the automata-conditioned RL problem and shows that it is probably approximately correct learnable. We then present a technique for learning provably correct automata embeddings, guaranteeing optimal multi-task policy learning. Our experimental evaluation confirms these theoretical results. 

**Abstract (ZH)**: 基于自动机条件的强化学习（RL）在学习能够执行运行时给定的临时扩展目标的多任务策略方面提供了令人鼓舞的结果，通过在训练下游策略之前预训练并冻结自动机嵌入来实现。然而没有给出理论保证。本工作提供了一个基于自动机条件的RL问题的理论框架，并证明它是可能近似正确的学习的。我们随后提出了一种学习可证明正确的自动机嵌入的技术，确保多任务策略学习的最优性。实验评估证实了这些理论结果。 

---
# Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in Graph Convolutional Neural Networks on Tetrahedral Meshes 

**Title (ZH)**: 基于四面体网格的图卷积神经网络中的解剖标志增强阿尔茨海默病诊断 

**Authors**: Yanxi Chen, Mohammad Farazi, Zhangsihao Yang, Yonghui Fan, Nicholas Ashton, Eric M Reiman, Yi Su, Yalin Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.05031)  

**Abstract**: Alzheimer's disease (AD) is a major neurodegenerative condition that affects millions around the world. As one of the main biomarkers in the AD diagnosis procedure, brain amyloid positivity is typically identified by positron emission tomography (PET), which is costly and invasive. Brain structural magnetic resonance imaging (sMRI) may provide a safer and more convenient solution for the AD diagnosis. Recent advances in geometric deep learning have facilitated sMRI analysis and early diagnosis of AD. However, determining AD pathology, such as brain amyloid deposition, in preclinical stage remains challenging, as less significant morphological changes can be observed. As a result, few AD classification models are generalizable to the brain amyloid positivity classification task. Blood-based biomarkers (BBBMs), on the other hand, have recently achieved remarkable success in predicting brain amyloid positivity and identifying individuals with high risk of being brain amyloid positive. However, individuals in medium risk group still require gold standard tests such as Amyloid PET for further evaluation. Inspired by the recent success of transformer architectures, we propose a geometric deep learning model based on transformer that is both scalable and robust to variations in input volumetric mesh size. Our work introduced a novel tokenization scheme for tetrahedral meshes, incorporating anatomical landmarks generated by a pre-trained Gaussian process model. Our model achieved superior classification performance in AD classification task. In addition, we showed that the model was also generalizable to the brain amyloid positivity prediction with individuals in the medium risk class, where BM alone cannot achieve a clear classification. Our work may enrich geometric deep learning research and improve AD diagnosis accuracy without using expensive and invasive PET scans. 

**Abstract (ZH)**: 阿尔茨海默病（AD）是一种严重影响全世界数百万人的重大神经退行性疾病。作为AD诊断过程中的主要生物标志物之一，脑淀粉样蛋白阳性通常通过正电子发射断层扫描（PET）来识别，这种方法成本高且侵入性大。脑结构磁共振成像（sMRI）可能提供一种更安全、更方便的AD诊断解决方案。几何深度学习的最新进展促进了sMRI分析和AD的早期诊断。然而，在预临床阶段确定AD病理，如脑淀粉样蛋白沉积，仍然具有挑战性，因为观察到的形态学变化较少。因此，很少有AD分类模型能够推广到脑淀粉样蛋白阳性分类任务。另一方面，基于血液的生物标志物（BBBMs）最近在预测脑淀粉样蛋白阳性以及识别高风险个体方面取得了显著成功。然而，中风险个体仍需要使用如淀粉样蛋白PET等黄金标准测试进行进一步评估。受近期变压器架构成功的启发，我们提出了一种基于变压器的几何深度学习模型，该模型具有可扩展性和对输入体素网格尺寸变化的鲁棒性。我们的工作引入了一种新的四面体网格分词方案，结合了预训练高斯过程模型生成的解剖学landmark。我们的模型在AD分类任务中实现了卓越的分类性能。此外，我们还展示了该模型在中风险个体的脑淀粉样蛋白阳性预测方面具有泛化能力，而单独使用血液生物标志物无法清晰分类。我们的工作可能丰富几何深度学习研究，并在不使用昂贵且侵入性的PET扫描的情况下提高AD的诊断准确性。 

---
# A Consensus Privacy Metrics Framework for Synthetic Data 

**Title (ZH)**: 合成数据的共识隐私度量框架 

**Authors**: Lisa Pilgram, Fida K. Dankar, Jorg Drechsler, Mark Elliot, Josep Domingo-Ferrer, Paul Francis, Murat Kantarcioglu, Linglong Kong, Bradley Malin, Krishnamurty Muralidhar, Puja Myles, Fabian Prasser, Jean Louis Raisaro, Chao Yan, Khaled El Emam  

**Link**: [PDF](https://arxiv.org/pdf/2503.04980)  

**Abstract**: Synthetic data generation is one approach for sharing individual-level data. However, to meet legislative requirements, it is necessary to demonstrate that the individuals' privacy is adequately protected. There is no consolidated standard for measuring privacy in synthetic data. Through an expert panel and consensus process, we developed a framework for evaluating privacy in synthetic data. Our findings indicate that current similarity metrics fail to measure identity disclosure, and their use is discouraged. For differentially private synthetic data, a privacy budget other than close to zero was not considered interpretable. There was consensus on the importance of membership and attribute disclosure, both of which involve inferring personal information about an individual without necessarily revealing their identity. The resultant framework provides precise recommendations for metrics that address these types of disclosures effectively. Our findings further present specific opportunities for future research that can help with widespread adoption of synthetic data. 

**Abstract (ZH)**: 合成数据生成是共享个体级数据的一种方法。然而，为了满足立法要求，有必要证明个体的隐私得到了充分保护。目前没有统一的标准来衡量合成数据中的隐私。通过专家小组和共识过程，我们开发了一个评估合成数据中隐私的框架。我们的研究发现当前的相似性度量无法衡量身份泄露，其使用是不被推荐的。对于差分隐私的合成数据，除了接近零的隐私预算外，其他隐私预算被认为不具可解释性。一致认为成员身份和属性泄露的重要性，这两种情况都涉及推断个人的个人信息而不 necessarily 暴露其身份。所形成的框架提供了针对这些类型泄露的有效度量指标的具体建议。我们的研究结果还指出了未来研究的具体机会，这有助于合成数据的广泛应用。 

---
# Quantifying the Relevance of Youth Research Cited in the US Policy Documents 

**Title (ZH)**: 量化引用在美国政策文件中青年研究的相关性 

**Authors**: Miftahul Jannat Mokarrama, Hamed Alhoori  

**Link**: [PDF](https://arxiv.org/pdf/2503.04977)  

**Abstract**: In recent years, there has been a growing concern and emphasis on conducting research beyond academic or scientific research communities, benefiting society at large. A well-known approach to measuring the impact of research on society is enumerating its policy citation(s). Despite the importance of research in informing policy, there is no concrete evidence to suggest the research's relevance in cited policy documents. This is concerning because it may increase the possibility of evidence used in policy being manipulated by individual, social, or political biases that may lead to inappropriate, fragmented, or archaic research evidence in policy. Therefore, it is crucial to identify the degree of relevance between research articles and citing policy documents. In this paper, we examined the scale of contextual relevance of youth-focused research in the referenced US policy documents using natural language processing techniques, state-of-the-art pre-trained Large Language Models (LLMs), and statistical analysis. Our experiments and analysis concluded that youth-related research articles that get US policy citations are mostly relevant to the citing policy documents. 

**Abstract (ZH)**: 近年来，越来越关注并强调在学术或科学研究社区之外开展研究，以惠及全社会。衡量研究成果对社会影响的一种公认方法是统计其政策引用次数。尽管研究对政策制定具有重要影响，但目前没有确凿证据表明被引用的政策文件中所引用的研究的相关性。这令人担忧，因为它增加了政策中使用证据被个人、社会或政治偏见操纵的可能性，可能导致政策中缺乏适当的、整合的或现代的研究证据。因此，识别研究论文与引用政策文件之间的相关性程度至关重要。本文使用自然语言处理技术、最先进的预训练大规模语言模型（LLMs）和统计分析，考察了被引用的美国政策文件中 youths 领域研究的相关性规模。我们的实验和分析得出结论，获得美国政策引用的研究文章大多与引用的政策文件相关。 

---
# Incentivizing Multi-Tenant Split Federated Learning for Foundation Models at the Network Edge 

**Title (ZH)**: 在网络边缘促进多租户分割联邦学习的基础模型激励机制 

**Authors**: Songyuan Li, Jia Hu, Geyong Min, Haojun Huang  

**Link**: [PDF](https://arxiv.org/pdf/2503.04971)  

**Abstract**: Foundation models (FMs) such as GPT-4 exhibit exceptional generative capabilities across diverse downstream tasks through fine-tuning. Split Federated Learning (SFL) facilitates privacy-preserving FM fine-tuning on resource-constrained local devices by offloading partial FM computations to edge servers, enabling device-edge synergistic fine-tuning. Practical edge networks often host multiple SFL tenants to support diversified downstream tasks. However, existing research primarily focuses on single-tenant SFL scenarios, and lacks tailored incentive mechanisms for multi-tenant settings, which are essential to effectively coordinate self-interested local devices for participation in various downstream tasks, ensuring that each SFL tenant's distinct FM fine-tuning requirements (e.g., FM types, performance targets, and fine-tuning deadlines) are met. To address this gap, we propose a novel Price-Incentive Mechanism (PRINCE) that guides multiple SFL tenants to offer strategic price incentives, which solicit high-quality device participation for efficient FM fine-tuning. Specifically, we first develop a bias-resilient global SFL model aggregation scheme to eliminate model biases caused by independent device participation. We then derive a rigorous SFL convergence bound to evaluate the contributions of heterogeneous devices to FM performance improvements, guiding the incentive strategies of SFL tenants. Furthermore, we model inter-tenant device competition as a congestion game for Stackelberg equilibrium (SE) analysis, deriving each SFL tenant's optimal incentive strategy. Extensive simulations involving four representative SFL tenant types (ViT, BERT, Whisper, and LLaMA) across diverse data modalities (text, images, and audio) demonstrate that PRINCE accelerates FM fine-tuning by up to 3.07x compared to state-of-the-art approaches, while consistently meeting fine-tuning performance targets. 

**Abstract (ZH)**: 基于定价激励机制的多租户Split联邦学习中基础模型微调加速方法 

---
# Prediction of Frozen Region Growth in Kidney Cryoablation Intervention Using a 3D Flow-Matching Model 

**Title (ZH)**: 使用3D流匹配模型预测肾脏冷冻消融治疗中冻结区域的增长 

**Authors**: Siyeop Yoon, Yujin Oh, Matthew Tivnan, Sifan Song, Pengfei Jin, Sekeun KimHyun Jin Cho, Dufan Wu, Raul Uppot, Quanzheng Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.04966)  

**Abstract**: This study presents a 3D flow-matching model designed to predict the progression of the frozen region (iceball) during kidney cryoablation. Precise intraoperative guidance is critical in cryoablation to ensure complete tumor eradication while preserving adjacent healthy tissue. However, conventional methods, typically based on physics driven or diffusion based simulations, are computationally demanding and often struggle to represent complex anatomical structures accurately. To address these limitations, our approach leverages intraoperative CT imaging to inform the model. The proposed 3D flow matching model is trained to learn a continuous deformation field that maps early-stage CT scans to future predictions. This transformation not only estimates the volumetric expansion of the iceball but also generates corresponding segmentation masks, effectively capturing spatial and morphological changes over time. Quantitative analysis highlights the model robustness, demonstrating strong agreement between predictions and ground-truth segmentations. The model achieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient of 0.75. By integrating real time CT imaging with advanced deep learning techniques, this approach has the potential to enhance intraoperative guidance in kidney cryoablation, improving procedural outcomes and advancing the field of minimally invasive surgery. 

**Abstract (ZH)**: 本研究提出一种3D流匹配模型，用于预测肾脏冷冻消融过程中冰球区域的 progression。在冷冻消融过程中，精确的术中引导对于确保完全消除肿瘤同时保留相邻健康组织至关重要。然而，传统的基于物理驱动或扩散驱动的模拟方法计算复杂，往往难以准确表示复杂的解剖结构。为克服这些局限性，我们的方法利用术中CT成像来指导模型。所提出的3D流匹配模型被训练以学习连续的变形场，将早期CT扫描映射到未来的预测。这一变换不仅能估计冰球体积的扩张，还能生成相应的分割掩膜，有效地捕捉随时间变化的空间和形态变化。定量分析突显了模型的稳健性，预测与真实分割之间表现出强烈的对应关系。该模型的交并比(IoU)得分为0.61，Dice系数为0.75。通过将实时CT成像与先进的深度学习技术相结合，此方法有望增强肾脏冷冻消融过程中的术中引导，提高手术结果，并推动微创手术领域的发展。 

---
# Energy-Latency Attacks: A New Adversarial Threat to Deep Learning 

**Title (ZH)**: 能量-延迟攻击：对深度学习的一种新型敌对威胁 

**Authors**: Hanene F. Z. Brachemi Meftah, Wassim Hamidouche, Sid Ahmed Fezza, Olivier Deforges  

**Link**: [PDF](https://arxiv.org/pdf/2503.04963)  

**Abstract**: The growing computational demand for deep neural networks ( DNNs) has raised concerns about their energy consumption and carbon footprint, particularly as the size and complexity of the models continue to increase. To address these challenges, energy-efficient hardware and custom accelerators have become essential. Additionally, adaptable DNN s are being developed to dynamically balance performance and efficiency. The use of these strategies became more common to enable sustainable AI deployment. However, these efficiency-focused designs may also introduce vulnerabilities, as attackers can potentially exploit them to increase latency and energy usage by triggering their worst-case-performance scenarios. This new type of attack, called energy-latency attacks, has recently gained significant research attention, focusing on the vulnerability of DNN s to this emerging attack paradigm, which can trigger denial-of-service ( DoS) attacks. This paper provides a comprehensive overview of current research on energy-latency attacks, categorizing them using the established taxonomy for traditional adversarial attacks. We explore different metrics used to measure the success of these attacks and provide an analysis and comparison of existing attack strategies. We also analyze existing defense mechanisms and highlight current challenges and potential areas for future research in this developing field. The GitHub page for this work can be accessed at this https URL 

**Abstract (ZH)**: 深度神经网络（DNNs）不断增长的计算需求引发了对其能源消耗和碳足迹的担忧，尤其是在模型的规模和复杂性持续增加的情况下。为应对这些挑战，能源高效的硬件和定制加速器变得至关重要。此外，正在开发可调整的DNNs以动态平衡性能和效率。这些策略的使用越来越普遍，以实现可持续的人工智能部署。然而，这些注重效率的设计也可能引入漏洞，攻击者可以通过触发其最坏情况性能场景来增加延迟和能源消耗。这种新型攻击被称为能量-延迟攻击，最近引起了广泛关注，重点关注DNNs对这种新兴攻击范式的易受攻击性，这可以引发服务拒绝攻击（DoS）。本文提供了一种关于能量-延迟攻击的全面综述，通过传统对抗攻击的分类学对它们进行分类。我们探讨了用于衡量这些攻击成功程度的不同指标，并对现有的攻击策略进行了分析和比较。我们还分析了现有的防御机制，并指出现有挑战以及未来研究的潜在领域。 

---
# Federated Inverse Probability Treatment Weighting for Individual Treatment Effect Estimation 

**Title (ZH)**: 联邦逆概率治疗加权估计个体治疗效果 

**Authors**: Changchang Yin, Hong-You Chen, Wei-Lun Chao, Ping Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.04946)  

**Abstract**: Individual treatment effect (ITE) estimation is to evaluate the causal effects of treatment strategies on some important outcomes, which is a crucial problem in healthcare. Most existing ITE estimation methods are designed for centralized settings. However, in real-world clinical scenarios, the raw data are usually not shareable among hospitals due to the potential privacy and security risks, which makes the methods not applicable. In this work, we study the ITE estimation task in a federated setting, which allows us to harness the decentralized data from multiple hospitals. Due to the unavoidable confounding bias in the collected data, a model directly learned from it would be inaccurate. One well-known solution is Inverse Probability Treatment Weighting (IPTW), which uses the conditional probability of treatment given the covariates to re-weight each training example. Applying IPTW in a federated setting, however, is non-trivial. We found that even with a well-estimated conditional probability, the local model training step using each hospital's data alone would still suffer from confounding bias. To address this, we propose FED-IPTW, a novel algorithm to extend IPTW into a federated setting that enforces both global (over all the data) and local (within each hospital) decorrelation between covariates and treatments. We validated our approach on the task of comparing the treatment effects of mechanical ventilation on improving survival probability for patients with breadth difficulties in the intensive care unit (ICU). We conducted experiments on both synthetic and real-world eICU datasets and the results show that FED-IPTW outperform state-of-the-art methods on all the metrics on factual prediction and ITE estimation tasks, paving the way for personalized treatment strategy design in mechanical ventilation usage. 

**Abstract (ZH)**: 个体治疗效果（ITE）估计在 federated 设置中的研究 

---
# Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing Dialogue Systems 

**Title (ZH)**: 增强反思对话系统的深度假信息文本协作评估 

**Authors**: Jooyoung Lee, Xiaochen Zhu, Georgi Karadzhov, Tom Stafford, Andreas Vlachos, Dongwon Lee  

**Link**: [PDF](https://arxiv.org/pdf/2503.04945)  

**Abstract**: The proliferation of generative models has presented significant challenges in distinguishing authentic human-authored content from deepfake content. Collaborative human efforts, augmented by AI tools, present a promising solution. In this study, we explore the potential of DeepFakeDeLiBot, a deliberation-enhancing chatbot, to support groups in detecting deepfake text. Our findings reveal that group-based problem-solving significantly improves the accuracy of identifying machine-generated paragraphs compared to individual efforts. While engagement with DeepFakeDeLiBot does not yield substantial performance gains overall, it enhances group dynamics by fostering greater participant engagement, consensus building, and the frequency and diversity of reasoning-based utterances. Additionally, participants with higher perceived effectiveness of group collaboration exhibited performance benefits from DeepFakeDeLiBot. These findings underscore the potential of deliberative chatbots in fostering interactive and productive group dynamics while ensuring accuracy in collaborative deepfake text detection. \textit{Dataset and source code used in this study will be made publicly available upon acceptance of the manuscript. 

**Abstract (ZH)**: 生成模型的泛滥为区分真实人类创作的内容与深度伪造内容带来了重大挑战。借助AI工具的人机协作提供了有希望的解决方案。本研究探讨了增强辩论的聊天机器人DeepFakeDeLiBot在支持团队检测深度伪造文本方面的潜在作用。研究发现，基于团队的问题解决显著提高了识别机器生成段落的准确性，而个人努力则不如团队努力。虽然与DeepFakeDeLiBot的互动在总体上并未带来显著的性能提升，但它通过促进更高的参与者参与度、共识构建以及基于推理的说法频次和多样性，增强了团队动态。此外，感知到团队合作更有效的参与者从DeepFakeDeLiBot中获得了性能上的益处。这些发现强调了辩论型聊天机器人在促进互动和高效团队动态同时确保协作深度伪造文本检测准确性方面的潜力。本研究的数据集和源代码将在稿件被接受后公开。 

---
# HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using Knowledgebases and Large Language Models 

**Title (ZH)**: HILGEN：基于层级知识的数据生成方法在生物医学NER中的应用，结合知识库和大型语言模型 

**Authors**: Yao Ge, Yuting Guo, Sudeshna Das, Swati Rajwal, Selen Bozkurt, Abeed Sarker  

**Link**: [PDF](https://arxiv.org/pdf/2503.04930)  

**Abstract**: We present HILGEN, a Hierarchically-Informed Data Generation approach that combines domain knowledge from the Unified Medical Language System (UMLS) with synthetic data generated by large language models (LLMs), specifically GPT-3.5. Our approach leverages UMLS's hierarchical structure to expand training data with related concepts, while incorporating contextual information from LLMs through targeted prompts aimed at automatically generating synthetic examples for sparsely occurring named entities. The performance of the HILGEN approach was evaluated across four biomedical NER datasets (MIMIC III, BC5CDR, NCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation with Nearest Neighbor Classifier) models, applying various data generation strategies, including UMLS, GPT-3.5, and their best ensemble. For the BERT-Large model, incorporating UMLS led to an average F1 score improvement of 40.36%, while using GPT-3.5 resulted in a comparable average increase of 40.52%. The Best-Ensemble approach using BERT-Large achieved the highest improvement, with an average increase of 42.29%. DANN model's F1 score improved by 22.74% on average using the UMLS-only approach. The GPT-3.5-based method resulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more notable improvement, with an average increase of 25.03%. Our proposed HILGEN approach improves NER performance in few-shot settings without requiring additional manually annotated data. Our experiments demonstrate that an effective strategy for optimizing biomedical NER is to combine biomedical knowledge curated in the past, such as the UMLS, and generative LLMs to create synthetic training instances. Our future research will focus on exploring additional innovative synthetic data generation strategies for further improving NER performance. 

**Abstract (ZH)**: Hierarchically-Informed Data Generation Approach Combining UMLS with Large Language Models for Biomedical NER 

---
# Label Distribution Learning-Enhanced Dual-KNN for Text Classification 

**Title (ZH)**: 标签分布学习增强的双KNN文本分类 

**Authors**: Bo Yuan, Yulin Chen, Zhen Tan, Wang Jinyan, Huan Liu, Yin Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.04869)  

**Abstract**: Many text classification methods usually introduce external information (e.g., label descriptions and knowledge bases) to improve the classification performance. Compared to external information, some internal information generated by the model itself during training, like text embeddings and predicted label probability distributions, are exploited poorly when predicting the outcomes of some texts. In this paper, we focus on leveraging this internal information, proposing a dual $k$ nearest neighbor (D$k$NN) framework with two $k$NN modules, to retrieve several neighbors from the training set and augment the distribution of labels. For the $k$NN module, it is easily confused and may cause incorrect predictions when retrieving some nearest neighbors from noisy datasets (datasets with labeling errors) or similar datasets (datasets with similar labels). To address this issue, we also introduce a label distribution learning module that can learn label similarity, and generate a better label distribution to help models distinguish texts more effectively. This module eases model overfitting and improves final classification performance, hence enhancing the quality of the retrieved neighbors by $k$NN modules during inference. Extensive experiments on the benchmark datasets verify the effectiveness of our method. 

**Abstract (ZH)**: 许多文本分类方法通常引入外部信息（如标签描述和知识库）以提高分类性能。与外部信息相比，模型在训练过程中生成的一些内部信息（如文本嵌入和预测的标签概率分布）在预测某些文本的结果时利用不足。本文专注于利用这些内部信息，提出了一种双$K$最近邻（D$k$NN）框架，该框架包含两个$K$NN模块，从训练集检索几个邻居并增强标签分布。对于$K$NN模块，从嘈杂数据集（带有标签错误的数据集）或类似数据集（带有相似标签的数据集）中检索最近邻居时容易出错并可能导致错误预测。为解决这一问题，我们还引入了一个标签分布学习模块，它可以学习标签相似性，生成更好的标签分布，从而帮助模型更有效地区分文本。该模块减轻了模型过拟合，提高了最终分类性能，从而在推理过程中提高了$K$NN模块检索到的邻居的质量。基准数据集上的大量实验验证了我们方法的有效性。 

---
# Privacy in Responsible AI: Approaches to Facial Recognition from Cloud Providers 

**Title (ZH)**: 负责任人工智能中的隐私保护：云提供商的面部识别方法 

**Authors**: Anna Elivanova  

**Link**: [PDF](https://arxiv.org/pdf/2503.04866)  

**Abstract**: As the use of facial recognition technology is expanding in different domains, ensuring its responsible use is gaining more importance. This paper conducts a comprehensive literature review of existing studies on facial recognition technology from the perspective of privacy, which is one of the key Responsible AI principles.
Cloud providers, such as Microsoft, AWS, and Google, are at the forefront of delivering facial-related technology services, but their approaches to responsible use of these technologies vary significantly. This paper compares how these cloud giants implement the privacy principle into their facial recognition and detection services. By analysing their approaches, it identifies both common practices and notable differences. The results of this research will be valuable for developers and businesses by providing them insights into best practices of three major companies for integration responsible AI, particularly privacy, into their cloud-based facial recognition technologies. 

**Abstract (ZH)**: 随着面部识别技术在不同领域的应用扩展，确保其负责任地使用变得愈发重要。本文从隐私保护的角度对现有的面部识别技术研究进行综述，这是一项负责任人工智能原则中的重要方面。云计算提供商，如微软、AWS和Google，是提供相关技术服務的前沿，但它们在这些技术负责任使用方面的做法存在显著差异。本文比较了这些云计算巨头如何将隐私原则融入其面部识别和检测服务中，并通过分析其做法，识别出共同实践和显著差异。研究结果将为开发者和企业提供了宝贵的见解，特别是在将其云基面部识别技术与负责任的人工智能，特别是隐私保护相结合的最佳实践方面。 

---
# E4: Energy-Efficient DNN Inference for Edge Video Analytics Via Early-Exit and DVFS 

**Title (ZH)**: 基于早期退出和动态电压频率调整的边缘视频分析中的能效DNN推理 

**Authors**: Ziyang Zhang, Yang Zhao, Ming-Ching Chang, Changyao Lin, Jie Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.04865)  

**Abstract**: Deep neural network (DNN) models are increasingly popular in edge video analytic applications. However, the compute-intensive nature of DNN models pose challenges for energy-efficient inference on resource-constrained edge devices. Most existing solutions focus on optimizing DNN inference latency and accuracy, often overlooking energy efficiency. They also fail to account for the varying complexity of video frames, leading to sub-optimal performance in edge video analytics. In this paper, we propose an Energy-Efficient Early-Exit (E4) framework that enhances DNN inference efficiency for edge video analytics by integrating a novel early-exit mechanism with dynamic voltage and frequency scaling (DVFS) governors. It employs an attention-based cascade module to analyze video frame diversity and automatically determine optimal DNN exit points. Additionally, E4 features a just-in-time (JIT) profiler that uses coordinate descent search to co-optimize CPU and GPU clock frequencies for each layer before the DNN exit points. Extensive evaluations demonstrate that E4 outperforms current state-of-the-art methods, achieving up to 2.8x speedup and 26% average energy saving while maintaining high accuracy. 

**Abstract (ZH)**: 一种用于边缘视频分析的节能早期退出框架：结合基于注意机制的级联模块与动态电压和频率调整的节能早退框架 

---
# From Pixels to Trajectory: Universal Adversarial Example Detection via Temporal Imprints 

**Title (ZH)**: 从像素到轨迹：通过时间印记进行通用对抗性示例检测 

**Authors**: Yansong Gao, Huaibing Peng, Hua Ma, Zhiyang Dai, Shuo Wang, Hongsheng Hu, Anmin Fu, Minhui Xue  

**Link**: [PDF](https://arxiv.org/pdf/2503.04853)  

**Abstract**: For the first time, we unveil discernible temporal (or historical) trajectory imprints resulting from adversarial example (AE) attacks. Standing in contrast to existing studies all focusing on spatial (or static) imprints within the targeted underlying victim models, we present a fresh temporal paradigm for understanding these attacks. Of paramount discovery is that these imprints are encapsulated within a single loss metric, spanning universally across diverse tasks such as classification and regression, and modalities including image, text, and audio. Recognizing the distinct nature of loss between adversarial and clean examples, we exploit this temporal imprint for AE detection by proposing TRAIT (TRaceable Adversarial temporal trajectory ImprinTs). TRAIT operates under minimal assumptions without prior knowledge of attacks, thereby framing the detection challenge as a one-class classification problem. However, detecting AEs is still challenged by significant overlaps between the constructed synthetic losses of adversarial and clean examples due to the absence of ground truth for incoming inputs. TRAIT addresses this challenge by converting the synthetic loss into a spectrum signature, using the technique of Fast Fourier Transform to highlight the discrepancies, drawing inspiration from the temporal nature of the imprints, analogous to time-series signals. Across 12 AE attacks including SMACK (USENIX Sec'2023), TRAIT demonstrates consistent outstanding performance across comprehensively evaluated modalities, tasks, datasets, and model architectures. In all scenarios, TRAIT achieves an AE detection accuracy exceeding 97%, often around 99%, while maintaining a false rejection rate of 1%. TRAIT remains effective under the formulated strong adaptive attacks. 

**Abstract (ZH)**: 首次揭示 adversarial example 攻击导致的可辨识的时间轨迹印记：一种全新的时间维度分析范式 

---
# Role of Databases in GenAI Applications 

**Title (ZH)**: 数据库在生成式AI应用中的作用 

**Authors**: Santosh Bhupathi  

**Link**: [PDF](https://arxiv.org/pdf/2503.04847)  

**Abstract**: Generative AI (GenAI) is transforming industries by enabling intelligent content generation, automation, and decision-making. However, the effectiveness of GenAI applications depends significantly on efficient data storage, retrieval, and contextual augmentation. This paper explores the critical role of databases in GenAI workflows, emphasizing the importance of choosing the right database architecture to optimize performance, accuracy, and scalability. It categorizes database roles into conversational context (key-value/document databases), situational context (relational databases/data lakehouses), and semantic context (vector databases) each serving a distinct function in enriching AI-generated responses. Additionally, the paper highlights real-time query processing, vector search for semantic retrieval, and the impact of database selection on model efficiency and scalability. By leveraging a multi-database approach, GenAI applications can achieve more context-aware, personalized, and high-performing AI-driven solutions. 

**Abstract (ZH)**: 生成式人工智能（GenAI）正在通过智能内容生成、自动化和决策改造各行各业。然而，GenAI应用的有效性在很大程度上取决于高效的数据存储、检索和背景增强。本文探讨了数据库在GenAI工作流中的关键作用，强调选择合适的数据库架构以优化性能、准确性和可扩展性的重要性。文章将数据库角色划分为会话上下文（键值/文档数据库）、情境上下文（关系数据库/数据湖屋）和语义上下文（向量数据库），每种角色在丰富AI生成的响应方面发挥着独特的作用。此外，文章还强调了实时查询处理、向量搜索以实现语义检索以及数据库选择对模型效率和可扩展性的影响。通过运用多数据库方法，GenAI应用可以实现更具有上下文意识、个性化和高性能的人工智能驱动解决方案。 

---
# Universal Narrative Model: an Author-centric Storytelling Framework for Generative AI 

**Title (ZH)**: 面向生成式AI的以作者为中心的叙事框架：通用叙事模型 

**Authors**: Hank Gerba  

**Link**: [PDF](https://arxiv.org/pdf/2503.04844)  

**Abstract**: Generative AI promises to finally realize dynamic, personalized storytelling technologies across a range of media. To date, experimentation with generative AI in the field of procedural narrative generation has been quite promising from a technical perspective. However, fundamental narrative dilemmas remain, such as the balance between player agency and narrative coherence, and no rigorous narrative standard has been proposed to specifically leverage the strengths of generative AI. In this paper, we propose the Universal Narrative Model (UNM), an open and extensible standard designed to place writers at the center of future narrative design workflows and enable interoperability across authoring platforms. By encoding an author's intent according to an objective narrative model, the UNM enables narrative portability as well as intent-based constraints for generative systems. 

**Abstract (ZH)**: 生成式AI有望最终实现跨多种媒体的动态个性化叙事技术。在程序化叙事生成领域，生成式AI的技术实验迄今为止取得了相当有希望的结果。然而，根本的叙事难题仍然存在，例如玩家自主性和叙事连贯性的平衡，以及尚未提出具体的规范标准来充分发挥生成式AI的优势。本文提出了一种通用叙事模型（UNM），这是一种开放扩展的标准，旨在将作家置于未来叙事设计流程的中心，并实现跨作者平台的互操作性。通过根据客观叙事模型编码作者的意图，UNM 使得叙事具有可移植性，并为生成系统提供了基于意图的约束。 

---
# FedPalm: A General Federated Learning Framework for Closed- and Open-Set Palmprint Verification 

**Title (ZH)**: FedPalm: 一种用于封闭集和开放集掌纹验证的通用联邦学习框架 

**Authors**: Ziyuan Yang, Yingyu Chen, Chengrui Gao, Andrew Beng Jin Teoh, Bob Zhang, Yi Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.04837)  

**Abstract**: Current deep learning (DL)-based palmprint verification models rely on centralized training with large datasets, which raises significant privacy concerns due to biometric data's sensitive and immutable nature. Federated learning~(FL), a privacy-preserving distributed learning paradigm, offers a compelling alternative by enabling collaborative model training without the need for data sharing. However, FL-based palmprint verification faces critical challenges, including data heterogeneity from diverse identities and the absence of standardized evaluation benchmarks. This paper addresses these gaps by establishing a comprehensive benchmark for FL-based palmprint verification, which explicitly defines and evaluates two practical scenarios: closed-set and open-set verification. We propose FedPalm, a unified FL framework that balances local adaptability with global generalization. Each client trains a personalized textural expert tailored to local data and collaboratively contributes to a shared global textural expert for extracting generalized features. To further enhance verification performance, we introduce a Textural Expert Interaction Module that dynamically routes textural features among experts to generate refined side textural features. Learnable parameters are employed to model relationships between original and side features, fostering cross-texture-expert interaction and improving feature discrimination. Extensive experiments validate the effectiveness of FedPalm, demonstrating robust performance across both scenarios and providing a promising foundation for advancing FL-based palmprint verification research. 

**Abstract (ZH)**: 基于联邦学习的掌纹验证：综合基准与FedPalm框架 

---
# Distilling Dataset into Neural Field 

**Title (ZH)**: 将数据集提炼为神经场模型 

**Authors**: Donghyeok Shin, HeeSun Bae, Gyuwon Sim, Wanmo Kang, Il-Chul Moon  

**Link**: [PDF](https://arxiv.org/pdf/2503.04835)  

**Abstract**: Utilizing a large-scale dataset is essential for training high-performance deep learning models, but it also comes with substantial computation and storage costs. To overcome these challenges, dataset distillation has emerged as a promising solution by compressing the large-scale dataset into a smaller synthetic dataset that retains the essential information needed for training. This paper proposes a novel parameterization framework for dataset distillation, coined Distilling Dataset into Neural Field (DDiF), which leverages the neural field to store the necessary information of the large-scale dataset. Due to the unique nature of the neural field, which takes coordinates as input and output quantity, DDiF effectively preserves the information and easily generates various shapes of data. We theoretically confirm that DDiF exhibits greater expressiveness than some previous literature when the utilized budget for a single synthetic instance is the same. Through extensive experiments, we demonstrate that DDiF achieves superior performance on several benchmark datasets, extending beyond the image domain to include video, audio, and 3D voxel. We release the code at this https URL. 

**Abstract (ZH)**: 利用大规模数据集训练高性能深度学习模型至关重要，但也会带来显著的计算和存储成本。为克服这些挑战，数据集蒸馏作为一种有前景的解决方案应运而生，通过压缩大规模数据集为较小的合成数据集，同时保留必要的训练信息。本文提出了一种名为Distilling Dataset into Neural Field (DDiF) 的新型参数化框架，该框架利用神经场存储大规模数据集的必要信息。由于神经场的独特性质，它可以将坐标作为输入并输出数量，DDiF有效地保留了信息，并能够轻松生成各种形状的数据。理论分析证实，在相同的单个合成实例预算下，DDiF表现出了比某些先前文献更大的表达能力。通过广泛的实验，我们展示了在多个基准数据集上，DDiF实现了优于其他方法的性能，不仅限于图像领域，还包括视频、音频和3D体素。我们已在以下网址发布代码：此 https URL。 

---
# RD Efficient FPGA Deployment of Learned Image Compression: Knowledge Distillation and Hybrid Quantization 

**Title (ZH)**: 基于知识精炼和混合量化的大规模FPGA部署学习型图像压缩 

**Authors**: Mazouz Alaa Eddine, Sumanta Chaudhuri, Marco Cagnanzzo, Mihai Mitrea, Enzo Tartaglione, Attilio Fiandrotti  

**Link**: [PDF](https://arxiv.org/pdf/2503.04832)  

**Abstract**: Learnable Image Compression (LIC) has shown the potential to outperform standardized video codecs in RD efficiency, prompting the research for hardware-friendly implementations. Most existing LIC hardware implementations prioritize latency to RD-efficiency and through an extensive exploration of the hardware design space. We present a novel design paradigm where the burden of tuning the design for a specific hardware platform is shifted towards model dimensioning and without compromising on RD-efficiency. First, we design a framework for distilling a leaner student LIC model from a reference teacher: by tuning a single model hyperparameters, we can meet the constraints of different hardware platforms without a complex hardware design exploration. Second, we propose a hardware-friendly implementation of the Generalized Divisive Normalization (GDN) activation that preserves RD efficiency even post parameter quantization. Third, we design a pipelined FPGA configuration which takes full advantage of available FPGA resources by leveraging parallel processing and optimizing resource allocation. Our experiments with a state of the art LIC model show that we outperform all existing FPGA implementations while performing very close to the original model in terms of RD efficiency. 

**Abstract (ZH)**: 可学习图像压缩（LIC）展现了超越标准化视频编解码器的潜力，尤其是在RD效率方面，推动了硬件友好型实现的研究。现有的LIC硬件实现主要侧重于降低延迟以提高RD效率，并通过广泛探索硬件设计空间。我们提出了一种新的设计范式，将针对特定硬件平台调整设计的负担转移到模型维度化上，而不牺牲RD效率。首先，我们设计了一个框架，从一个参考教师模型中提取一个更精益的学生LIC模型：通过调整单一模型的超参数，可以在不进行复杂硬件设计探索的情况下满足不同硬件平台的约束条件。其次，我们提出了一种硬件友好的Generalized Divisive Normalization（GDN）激活函数实现，即使在参数量化后仍能保持RD效率。第三，我们设计了一个流水线FPGA配置，通过利用并行处理并优化资源分配来充分利用FPGA资源。我们的实验表明，在使用最先进的LIC模型时，我们在RD效率方面优于所有现有的FPGA实现，且性能与原始模型非常接近。 

---
# StickMotion: Generating 3D Human Motions by Drawing a Stickman 

**Title (ZH)**: StickMotion: 通过绘制 stickman 生成 3D 人体运动 

**Authors**: Tao Wang, Zhihua Wu, Qiaozhi He, Jiaming Chu, Ling Qian, Yu Cheng, Junliang Xing, Jian Zhao, Lei Jin  

**Link**: [PDF](https://arxiv.org/pdf/2503.04829)  

**Abstract**: Text-to-motion generation, which translates textual descriptions into human motions, has been challenging in accurately capturing detailed user-imagined motions from simple text inputs. This paper introduces StickMotion, an efficient diffusion-based network designed for multi-condition scenarios, which generates desired motions based on traditional text and our proposed stickman conditions for global and local control of these motions, respectively. We address the challenges introduced by the user-friendly stickman from three perspectives: 1) Data generation. We develop an algorithm to generate hand-drawn stickmen automatically across different dataset formats. 2) Multi-condition fusion. We propose a multi-condition module that integrates into the diffusion process and obtains outputs of all possible condition combinations, reducing computational complexity and enhancing StickMotion's performance compared to conventional approaches with the self-attention module. 3) Dynamic supervision. We empower StickMotion to make minor adjustments to the stickman's position within the output sequences, generating more natural movements through our proposed dynamic supervision strategy. Through quantitative experiments and user studies, sketching stickmen saves users about 51.5% of their time generating motions consistent with their imagination. Our codes, demos, and relevant data will be released to facilitate further research and validation within the scientific community. 

**Abstract (ZH)**: 基于文本到运动生成的StickMotion：一种高效控制全局和局部运动的扩散网络 

---
# Preserving Cultural Identity with Context-Aware Translation Through Multi-Agent AI Systems 

**Title (ZH)**: 基于多智能体AI系统的上下文感知翻译 preserve Cultural Identity Across Languages 

**Authors**: Mahfuz Ahmed Anik, Abdur Rahman, Azmine Toushik Wasi, Md Manjurul Ahsan  

**Link**: [PDF](https://arxiv.org/pdf/2503.04827)  

**Abstract**: Language is a cornerstone of cultural identity, yet globalization and the dominance of major languages have placed nearly 3,000 languages at risk of extinction. Existing AI-driven translation models prioritize efficiency but often fail to capture cultural nuances, idiomatic expressions, and historical significance, leading to translations that marginalize linguistic diversity. To address these challenges, we propose a multi-agent AI framework designed for culturally adaptive translation in underserved language communities. Our approach leverages specialized agents for translation, interpretation, content synthesis, and bias evaluation, ensuring that linguistic accuracy and cultural relevance are preserved. Using CrewAI and LangChain, our system enhances contextual fidelity while mitigating biases through external validation. Comparative analysis shows that our framework outperforms GPT-4o, producing contextually rich and culturally embedded translations, a critical advancement for Indigenous, regional, and low-resource languages. This research underscores the potential of multi-agent AI in fostering equitable, sustainable, and culturally sensitive NLP technologies, aligning with the AI Governance, Cultural NLP, and Sustainable NLP pillars of Language Models for Underserved Communities. Our full experimental codebase is publicly available at: this https URL 

**Abstract (ZH)**: 语言是文化身份的基础，然而全球化和主要语言的主导地位使得近3000种语言面临灭绝的风险。现有的基于AI的翻译模型注重效率，但常常无法捕捉文化细微差别、习语表达和历史意义，导致翻译结果边缘化语言多样性。为应对这些挑战，我们提出了一种多智能体AI框架，旨在为未充分服务的语言社区提供文化适应性翻译。我们的方法利用专门的智能体进行翻译、口译、内容合成和偏见评估，确保语言准确性和文化相关性得到保留。通过使用CrewAI和LangChain，我们的系统增强了上下文的真实性，同时通过外部验证减轻偏见。比较分析表明，我们的框架优于GPT-4o，产生丰富上下文并融入文化内容的翻译，这对原住民、区域性和低资源语言而言是一项关键进步。本研究强调了多智能体AI在促进公平、可持续和文化敏感的自然语言处理技术方面的潜力，符合未服务社区语言模型的AI治理、文化NLP和可持续NLP支柱。我们的完整实验代码库已公开发布于：this https URL 

---
# HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs 

**Title (ZH)**: HeTGB: 一种全面的异ophilic文本 attributed 图基准 

**Authors**: Shujie Li, Yuxia Wu, Chuan Shi, Yuan Fang  

**Link**: [PDF](https://arxiv.org/pdf/2503.04822)  

**Abstract**: Graph neural networks (GNNs) have demonstrated success in modeling relational data primarily under the assumption of homophily. However, many real-world graphs exhibit heterophily, where linked nodes belong to different categories or possess diverse attributes. Additionally, nodes in many domains are associated with textual descriptions, forming heterophilic text-attributed graphs (TAGs). Despite their significance, the study of heterophilic TAGs remains underexplored due to the lack of comprehensive benchmarks. To address this gap, we introduce the Heterophilic Text-attributed Graph Benchmark (HeTGB), a novel benchmark comprising five real-world heterophilic graph datasets from diverse domains, with nodes enriched by extensive textual descriptions. HeTGB enables systematic evaluation of GNNs, pre-trained language models (PLMs) and co-training methods on the node classification task. Through extensive benchmarking experiments, we showcase the utility of text attributes in heterophilic graphs, analyze the challenges posed by heterophilic TAGs and the limitations of existing models, and provide insights into the interplay between graph structures and textual attributes. We have publicly released HeTGB with baseline implementations to facilitate further research in this field. 

**Abstract (ZH)**: 异构文本属性图基准（HeTGB）：一种包含五个来自多个领域的异构图数据集的新基准 

---
# Technique Inference Engine: A Recommender Model to Support Cyber Threat Hunting 

**Title (ZH)**: 网络威胁狩猎支持的推荐模型：技术推理引擎 

**Authors**: Matthew J. Turner, Mike Carenzo, Jackie Lasky, James Morris-King, James Ross  

**Link**: [PDF](https://arxiv.org/pdf/2503.04819)  

**Abstract**: Cyber threat hunting is the practice of proactively searching for latent threats in a network. Engaging in threat hunting can be difficult due to the volume of network traffic, variety of adversary techniques, and constantly evolving vulnerabilities. To aid analysts in identifying techniques which may be co-occurring as part of a campaign, we present the Technique Inference Engine, a tool to infer tactics, techniques, and procedures (TTPs) which may be related to existing observations of adversarial behavior. We compile the largest (to our knowledge) available dataset of cyber threat intelligence (CTI) reports labeled with relevant TTPs. With the knowledge that techniques are chronically under-reported in CTI, we apply several implicit feedback recommender models to the data in order to predict additional techniques which may be part of a given campaign. We evaluate the results in the context of the cyber analyst's use case and apply t-SNE to visualize the model embeddings. We provide our code and a web interface. 

**Abstract (ZH)**: 网络威胁狩猎是主动搜索网络中潜藏威胁的做法。由于网络流量庞大、对手技术多样以及漏洞不断演变，进行威胁狩猎颇具挑战。为了帮助分析师识别可能在特定活动中共同出现的技术，我们介绍了技术推理引擎，该工具可用于推断可能与现有敌对行为观察相关的战术、技术和程序（TTP）。我们收集了已知最大的网络威胁情报（CTI）报告数据集，并将其标记为相关TTP。鉴于技术在威胁情报中的报告不充分，我们应用了多种隐式反馈推荐模型来预测可能属于特定活动的技术。我们从网络安全分析师的角度评估了结果，并使用t-SNE进行模型嵌入的可视化。我们提供了我们的代码和网络界面。 

---
# Multi-Agent System for AI-Assisted Extraction of Narrative Arcs in TV Series 

**Title (ZH)**: 基于多agent系统的AI辅助电视剧叙事弧抽取系统 

**Authors**: Roberto Balestri, Guglielmo Pescatore  

**Link**: [PDF](https://arxiv.org/pdf/2503.04817)  

**Abstract**: Serialized TV shows are built on complex storylines that can be hard to track and evolve in ways that defy straightforward analysis. This paper introduces a multi-agent system designed to extract and analyze these narrative arcs. Tested on the first season of Grey's Anatomy (ABC 2005-), the system identifies three types of arcs: Anthology (self-contained), Soap (relationship-focused), and Genre-Specific (strictly related to the series' genre). Episodic progressions of these arcs are stored in both relational and semantic (vectorial) databases, enabling structured analysis and comparison. To bridge the gap between automation and critical interpretation, the system is paired with a graphical interface that allows for human refinement using tools to enhance and visualize the data. The system performed strongly in identifying Anthology Arcs and character entities, but its reliance on textual paratexts (such as episode summaries) revealed limitations in recognizing overlapping arcs and subtler dynamics. This approach highlights the potential of combining computational and human expertise in narrative analysis. Beyond television, it offers promise for serialized written formats, where the narrative resides entirely in the text. Future work will explore the integration of multimodal inputs, such as dialogue and visuals, and expand testing across a wider range of genres to refine the system further. 

**Abstract (ZH)**: 基于复杂叙事结构的连续剧需要复杂分析方法：一个多智能体系统在《实习医生格蕾》第一季中的应用与拓展 

---
# The order in speech disorder: a scoping review of state of the art machine learning methods for clinical speech classification 

**Title (ZH)**: 言语紊乱中的秩序：先进机器学习方法在临床语音分类中的综述 

**Authors**: Birger Moell, Fredrik Sand Aronsson, Per Östberg, Jonas Beskow  

**Link**: [PDF](https://arxiv.org/pdf/2503.04802)  

**Abstract**: Background:Speech patterns have emerged as potential diagnostic markers for conditions with varying etiologies. Machine learning (ML) presents an opportunity to harness these patterns for accurate disease diagnosis.
Objective: This review synthesized findings from studies exploring ML's capability in leveraging speech for the diagnosis of neurological, laryngeal and mental disorders.
Methods: A systematic examination of 564 articles was conducted with 91 articles included in the study, which encompassed a wide spectrum of conditions, ranging from voice pathologies to mental and neurological disorders. Methods for speech classifications were assessed based on the relevant studies and scored between 0-10 based on the reported diagnostic accuracy of their ML models.
Results: High diagnostic accuracies were consistently observed for laryngeal disorders, dysarthria, and changes related to speech in Parkinsons disease. These findings indicate the robust potential of speech as a diagnostic tool. Disorders like depression, schizophrenia, mild cognitive impairment and Alzheimers dementia also demonstrated high accuracies, albeit with some variability across studies. Meanwhile, disorders like OCD and autism highlighted the need for more extensive research to ascertain the relationship between speech patterns and the respective conditions.
Conclusion: ML models utilizing speech patterns demonstrate promising potential in diagnosing a range of mental, laryngeal, and neurological disorders. However, the efficacy varies across conditions, and further research is needed. The integration of these models into clinical practice could potentially revolutionize the evaluation and diagnosis of a number of different medical conditions. 

**Abstract (ZH)**: 背景：语音模式已被确定为具有不同病因的条件的潜在诊断标志物。机器学习（ML）提供了一种利用这些模式进行准确疾病诊断的机会。目的：本综述综合了研究ML在利用语音进行神经疾病、喉疾病和精神障碍诊断方面能力的发现。方法：系统检查了564篇文章，其中91篇文章被纳入研究，涵盖了从嗓音病理到神经和精神障碍的广泛疾病范围。根据相关研究评估了语音分类方法，并根据其ML模型报告的诊断准确性得分，范围为0-10。结果：喉疾病、言语障碍及帕金森病相关的言语变化显示出一致的高诊断准确性。这些结果表明，语音作为诊断工具具有坚实的潜力。抑郁、精神分裂症、轻度认知障碍和阿尔茨海默病等疾病也表现出较高的准确性，但不同研究之间存在一定的可变性。另一方面，强迫症和自闭症等疾病强调了进一步研究的必要性，以确定语音模式与相应疾病的关系。结论：利用语音模式的ML模型在诊断多种神经、喉及精神障碍方面展现了有希望的潜力。然而，不同疾病的效用存在差异，仍需进行更多研究。将这些模型整合到临床实践中可能彻底改变多种医疗条件的评估和诊断。 

---
# Optimizing Multi-Hop Document Retrieval Through Intermediate Representations 

**Title (ZH)**: 通过中间表示优化多跳文档检索 

**Authors**: Jiaen Lin, Jingyu Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.04796)  

**Abstract**: Retrieval-augmented generation (RAG) encounters challenges when addressing complex queries, particularly multi-hop questions. While several methods tackle multi-hop queries by iteratively generating internal queries and retrieving external documents, these approaches are computationally expensive. In this paper, we identify a three-stage information processing pattern in LLMs during layer-by-layer reasoning, consisting of extraction, processing, and subsequent extraction steps. This observation suggests that the representations in intermediate layers contain richer information compared to those in other layers. Building on this insight, we propose Layer-wise RAG (L-RAG). Unlike prior methods that focus on generating new internal queries, L-RAG leverages intermediate representations from the middle layers, which capture next-hop information, to retrieve external knowledge. L-RAG achieves performance comparable to multi-step approaches while maintaining inference overhead similar to that of standard RAG. Experimental results show that L-RAG outperforms existing RAG methods on open-domain multi-hop question-answering datasets, including MuSiQue, HotpotQA, and 2WikiMultiHopQA. The code is available in this https URL 

**Abstract (ZH)**: 检索增强生成（RAG）在处理复杂查询，特别是多跳问题时遇到挑战。虽然有一些方法通过迭代生成内部查询并检索外部文档来应对多跳查询，但这些方法计算成本较高。在本文中，我们发现在逐层推理过程中LLMs的信息处理模式呈现出三层结构，包括提取、处理和后续提取步骤。这一观察表明，中间层的表示比其他层的表示包含更多的信息。基于这一洞察，我们提出了分层RAG（L-RAG）。与之前专注于生成新的内部查询的方法不同，L-RAG利用中间层捕获下一跳信息的表示来进行外部知识检索。L-RAG在多步方法可比的性能下，保持了与标准RAG类似的推理开销。实验结果表明，L-RAG在MuSiQue、HotpotQA和2WikiMultiHopQA等开放式多跳问答数据集上的表现优于现有RAG方法。代码可在以下链接获取。 

---
# SMT(LIA) Sampling with High Diversity 

**Title (ZH)**: SMT（LIA）采样与高多样性 

**Authors**: Yong Lai, Junjie Li, Chuan Luo  

**Link**: [PDF](https://arxiv.org/pdf/2503.04782)  

**Abstract**: Satisfiability Modulo Linear Integer Arithmetic, SMT(LIA) for short, is pivotal across various critical domains. Previous research has primarily focused on SMT solving techniques. However, in practical applications such as software and hardware testing, there is a need to generate a diverse set of solutions for use as test inputs. We have developed the first sampling framework that integrates local search with CDCL(T) techniques, named HighDiv, capable of generating a highly diverse set of solutions for constraints under linear integer theory. Initially, in the local search phase, we introduced a novel operator called boundary-aware movement. This operator performs random moves by considering the current state's constraints on variables, thereby enhancing the diversity of variables during the search process. Furthermore, we have conducted an in-depth study of the preprocessing and variable initialization mechanisms within the framework, which significantly enhances the efficiency of subsequent local searches. Lastly, we use the solutions obtained from local search sampling as additional constraints to further explore the solution space using the stochastic CDCL(T) method. Experimental results demonstrate that \HighDiv generates solutions with greater diversity compared to the state-of-the-art SMT(LIA) sampling tool, MeGASampler. 

**Abstract (ZH)**: 模线性整数算术 satisfiability modulo linear integer arithmetic, SMT(LIA)，简称 SMT(LIA)，在多个关键领域中至关重要。以往的研究主要关注 SMT 求解技术。然而，在软件和硬件测试等实用应用中，需要生成多样性较强的测试输入。我们开发了首个结合局部搜索与 CDCL(T) 技术的采样框架 HighDiv，能够在线性整数理论约束下生成高度多样化的解集。在局部搜索阶段，我们引入了一种新的操作符称为边界感知移动，该操作符通过考虑当前状态对变量的约束来进行随机移动，从而在搜索过程中增强变量的多样性。此外，我们在框架中深入研究了预处理和变量初始化机制，显著提高了后续局部搜索的效率。最后，我们使用局部搜索采样获得的解作为额外约束，进一步使用随机 CDCL(T) 方法探索解空间。实验结果表明，HighDiv 生成的解集比最先进的 SMT(LIA) 采样工具 MeGASampler 更具多样性。 

---
# A cross-regional review of AI safety regulations in the commercial aviation 

**Title (ZH)**: 跨区域商业航空AI安全监管综述 

**Authors**: Penny A. Barr, Sohel M. Imroz  

**Link**: [PDF](https://arxiv.org/pdf/2503.04767)  

**Abstract**: In this paper we examine the existing artificial intelligence (AI) policy documents in aviation for the following three regions: the United States, European Union, and China. The aviation industry has always been a first mover in adopting technological advancements. This early adoption offers valuable insights because of its stringent regulations and safety-critical procedures. As a result, the aviation industry provides an optimal platform to counter AI vulnerabilities through its tight regulations, standardization processes, and certification of new technologies. Keywords: AI in aviation; aviation safety; standardization; certifiable AI; regulations 

**Abstract (ZH)**: 本文分析了航空领域在美国、欧洲联盟和中国现有的人工智能（AI）政策文件。航空业一直是采用科技革新先驱者，其严格的法规和安全关键程序为研究AI漏洞提供了宝贵见解。因此，航空业提供了通过严格法规、标准化流程和新技术认证来应对AI漏洞的理想平台。关键词：航空人工智能；航空安全；标准化；可认证AI；法规。 

---
# Agentic AI and the Cyber Arms Race 

**Title (ZH)**: 代理人工智能与网络军备竞赛 

**Authors**: Sean Oesch, Jack Hutchins, Phillipe Austria, Amul Chaulagain  

**Link**: [PDF](https://arxiv.org/pdf/2503.04760)  

**Abstract**: Agentic AI is shifting the cybersecurity landscape as attackers and defenders leverage AI agents to augment humans and automate common tasks. In this article, we examine the implications for cyber warfare and global politics as Agentic AI becomes more powerful and enables the broad proliferation of capabilities only available to the most well resourced actors today. 

**Abstract (ZH)**: 行为AI正在改变网络安全格局，随着攻击者和防御者利用AI代理增强人类并自动化常见任务，行为AI变得更加强大并使当今仅能由资源最雄厚的行为主体获取的能力得以广泛普及，由此对网络战争和全球政治产生了影响。 

---
# Transforming Student Evaluation with Adaptive Intelligence and Performance Analytics 

**Title (ZH)**: 适应性智能与绩效分析驱动的学生评价转型 

**Authors**: Pushpalatha K S, Abhishek Mangalur, Ketan Hegde, Chetan Badachi, Mohammad Aamir  

**Link**: [PDF](https://arxiv.org/pdf/2503.04752)  

**Abstract**: The development in Artificial Intelligence (AI) offers transformative potential for redefining student assessment methodologies. This paper aims to establish the idea of the advancement of Artificial Intelligence (AI) and its prospect in reshaping approaches to assessing students. It creates a system for the evaluation of students performance using Artificial intelligence, and particularly the Gemini API for the generation of questions, grading and report on the students performances. This is to facilitate easy use of the tools in creating, scheduling, and delivering assessments with minimal chances of cheating through options such as full screen and time limit. There are formats of questions in the system which comprises multiple choice, short answers and descriptive questions, developed by Gemini. The most conspicuous feature is the self-checking system whereby the user gets instant feedback for the correct score that each of the students would have scored instantly with explanations about wrong answers. Moreover, the platform has intelligent learning progressions where the user will be able to monitor his/her performances to be recommended a certain level of performance. It will allow students as well as educators to have real-time analytics and feedback on what they are good at and where they need to improve. Not only does it make the assessment easier, but it also improves the levels of accuracy in grading and effectively strengthens a data based learning process for students. 

**Abstract (ZH)**: 人工智能的发展为重塑学生评估方法提供了变革潜力。本文旨在探讨人工智能的进步及其在重塑学生评估方法方面的前景。该论文建立了一个使用人工智能评估学生表现的系统，特别是利用Gemini API生成问题、评分和报告学生表现。这将有助于通过全屏和时间限制等选项轻松创建、安排和交付评估，减少作弊的机会。该系统包括由Gemini开发的多种题型，如选择题、简答题和论述题。最显着的特征是即刻反馈系统，用户可以即时获得每个学生的正确得分反馈，并附有错误答案的解释。此外，该平台具有智能学习渐进性，用户可以监控自己的表现并得到推荐的一些绩效水平。这将使学生和教育者能够实时获取他们在哪些方面表现出色以及需要改进的地方，不仅使评估更容易，还提高了评分的准确性，有效地增强了基于数据的学习过程。 

---
# What is Ethical: AIHED Driving Humans or Human-Driven AIHED? A Conceptual Framework enabling the Ethos of AI-driven Higher education 

**Title (ZH)**: 什么是符合伦理的：AIHED驱动的人类还是人类驱动的AIHED？一个基于人工智能驱动高等教育 ethos 的概念框架 

**Authors**: Prashant Mahajan  

**Link**: [PDF](https://arxiv.org/pdf/2503.04751)  

**Abstract**: The rapid integration of Artificial Intelligence (AI) in Higher Education (HE) is transforming personalized learning, administrative automation, and decision-making. However, this progress presents a duality, as AI adoption also introduces ethical and institutional challenges, including algorithmic bias, data privacy risks, and governance inconsistencies. To address these concerns, this study introduces the Human-Driven AI in Higher Education (HD-AIHED) Framework, ensuring compliance with UNESCO and OECD ethical standards. This conceptual research employs a qualitative meta-synthesis approach, integrating qualitative and quantitative studies to identify patterns, contradictions, and gaps in AI adoption within HE. It reinterprets existing datasets through theoretical and ethical lenses to develop governance frameworks. The study applies a participatory integrated co-system, Phased Human Intelligence, SWOC analysis, and AI ethical review boards to assess AI readiness and governance strategies for universities and HE institutions. The HD-AIHED model bridges AI research gaps, addresses global real-time challenges, and provides tailored, scalable, and ethical strategies for diverse educational contexts. By emphasizing interdisciplinary collaboration among stakeholders, this study envisions AIHED as a transparent and equitable force for innovation. The HD-AIHED framework ensures AI acts as a collaborative and ethical enabler rather than a disruptive replacement for human intelligence while advocating for responsible AI implementation in HE. 

**Abstract (ZH)**: 人工智能在高等教育中的快速融合：人类驱动的AI框架（HD-AIHED） 

---
# Position: AI agents should be regulated based on autonomous action sequences 

**Title (ZH)**: 位置：基于自主行动序列的AI代理应予以规制。 

**Authors**: Takauki Osogami  

**Link**: [PDF](https://arxiv.org/pdf/2503.04750)  

**Abstract**: This position paper argues that AI agents should be regulated based on the sequence of actions they autonomously take. AI agents with long-term planning and strategic capabilities can pose significant risks of human extinction and irreversible global catastrophes. While existing regulations often focus on computational scale as a proxy for potential harm, we contend that such measures are insufficient for assessing the risks posed by AI agents whose capabilities arise primarily from inference-time computation. To support our position, we discuss relevant regulations and recommendations from AI scientists regarding existential risks, as well as the advantages of action sequences over existing impact measures that require observing environmental states. 

**Abstract (ZH)**: 基于自主决策序列的AIagent监管：论点论文 

---
# E-LENS: User Requirements-Oriented AI Ethics Assurance 

**Title (ZH)**: E-LENS: 用户需求导向的AI伦理保障 

**Authors**: Jianlong Zhou, Fang Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.04747)  

**Abstract**: Despite the much proliferation of AI ethical principles in recent years, there is a challenge of assuring AI ethics with current AI ethics frameworks in real-world applications. While system safety has emerged as a distinct discipline for a long time, originated from safety concerns in early aircraft manufacturing. The safety assurance is now an indispensable component in safety critical domains. Motivated by the assurance approaches for safety-critical systems such as aviation, this paper introduces the concept of AI ethics assurance cases into the AI ethics assurance. Three pillars of user requirements, evidence, and validation are proposed as key components and integrated into AI ethics assurance cases for a new approach of user requirements-oriented AI ethics assurance. The user requirements-oriented AI ethics assurance case is set up based on three pillars and hazard analysis methods used in the safety assurance of safety-critical systems. This paper also proposes a platform named Ethical-Lens (E-LENS) to implement the user requirements-oriented AI ethics assurance approach. The proposed user requirements-based E-LENS platform is then applied to assure AI ethics of an AI-driven human resource shortlisting system as a case study to show the effectiveness of the proposed approach. 

**Abstract (ZH)**: 尽管近年来人工智能伦理原则得到了极大的普及，但在现实应用中确保人工智能伦理仍面临挑战。受到航空等关键安全领域安全保障方法的启发，本文将人工智能伦理保证概念引入人工智能伦理保证之中。提出了用户需求、证据和验证三大支柱作为关键组成部分，并整合至基于用户需求的人工智能伦理保证案例中，形成一种新的用户需求导向的人工智能伦理保证方法。该用户需求导向的人工智能伦理保证案例基于安全关键系统中的用户需求和危害分析方法建立。本文还提出一个名为Ethical-Lens (E-LENS) 的平台，用于实现基于用户需求的人工智能伦理保证方法，并将所提出的基于用户需求的E-LENS平台应用于一个人工智能驱动的人力资源筛选系统的伦理保证案例研究中，以展示所提方法的有效性。 

---
# Emerging Practices in Frontier AI Safety Frameworks 

**Title (ZH)**: 前沿AI安全框架中的新兴实践 

**Authors**: Marie Davidsen Buhl, Ben Bucknall, Tammy Masterson  

**Link**: [PDF](https://arxiv.org/pdf/2503.04746)  

**Abstract**: As part of the Frontier AI Safety Commitments agreed to at the 2024 AI Seoul Summit, many AI developers agreed to publish a safety framework outlining how they will manage potential severe risks associated with their systems. This paper summarises current thinking from companies, governments, and researchers on how to write an effective safety framework. We outline three core areas of a safety framework - risk identification and assessment, risk mitigation, and governance - and identify emerging practices within each area. As safety frameworks are novel and rapidly developing, we hope that this paper can serve both as an overview of work to date and as a starting point for further discussion and innovation. 

**Abstract (ZH)**: 关于2024 AI首尔峰会达成的前沿AI安全承诺，许多AI开发者同意发布一份安全框架，概述他们将如何管理其系统潜在的重大风险。本文总结了公司、政府和研究人员关于如何编写有效安全框架的当前观点。我们概述了安全框架的三个核心领域——风险识别与评估、风险减轻和治理——并确定了每个领域内的新兴实践。鉴于安全框架是新颖且快速发展的，我们希望本文既能作为迄今为止工作的综述，又能作为进一步讨论和创新的起点。 

---
# Safety Cases: A Scalable Approach to Frontier AI Safety 

**Title (ZH)**: 安全案例：通往前沿AI安全的可扩展方法 

**Authors**: Benjamin Hilton, Marie Davidsen Buhl, Tomek Korbak, Geoffrey Irving  

**Link**: [PDF](https://arxiv.org/pdf/2503.04744)  

**Abstract**: Safety cases - clear, assessable arguments for the safety of a system in a given context - are a widely-used technique across various industries for showing a decision-maker (e.g. boards, customers, third parties) that a system is safe. In this paper, we cover how and why frontier AI developers might also want to use safety cases. We then argue that writing and reviewing safety cases would substantially assist in the fulfilment of many of the Frontier AI Safety Commitments. Finally, we outline open research questions on the methodology, implementation, and technical details of safety cases. 

**Abstract (ZH)**: 安全论证——在一个给定的上下文中，清晰、可评估的安全论据是各行业中展示系统安全性给决策者（例如董事会、客户、第三方）的有效技术。本文探讨前沿AI开发者为何也应该使用安全论证，并论证编写和审核安全论证将如何有助于履行许多前沿AI安全承诺。最后，本文概述了安全论证方法论、实现和技术细节方面的开放研究问题。 

---
# AI Safety is Stuck in Technical Terms -- A System Safety Response to the International AI Safety Report 

**Title (ZH)**: AI安全困于技术术语——国际AI安全报告的系统安全回应 

**Authors**: Roel Dobbe  

**Link**: [PDF](https://arxiv.org/pdf/2503.04743)  

**Abstract**: Safety has become the central value around which dominant AI governance efforts are being shaped. Recently, this culminated in the publication of the International AI Safety Report, written by 96 experts of which 30 nominated by the Organisation for Economic Co-operation and Development (OECD), the European Union (EU), and the United Nations (UN). The report focuses on the safety risks of general-purpose AI and available technical mitigation approaches. In this response, informed by a system safety perspective, I refl ect on the key conclusions of the report, identifying fundamental issues in the currently dominant technical framing of AI safety and how this frustrates meaningful discourse and policy efforts to address safety comprehensively. The system safety discipline has dealt with the safety risks of software-based systems for many decades, and understands safety risks in AI systems as sociotechnical and requiring consideration of technical and non-technical factors and their interactions. The International AI Safety report does identify the need for system safety approaches. Lessons, concepts and methods from system safety indeed provide an important blueprint for overcoming current shortcomings in technical approaches by integrating rather than adding on non-technical factors and interventions. I conclude with why building a system safety discipline can help us overcome limitations in the European AI Act, as well as how the discipline can help shape sustainable investments into Public Interest AI. 

**Abstract (ZH)**: Safety已成为主导AI治理努力的中心价值。最近，这体现在国际AI安全报告的发布上，该报告由96位专家编写，其中30位分别由经济合作与发展组织(OECD)、欧盟(EU)和联合国(UN)提名。该报告专注于通用人工智能的安全风险以及可用的技术缓解方法。在此回应中，基于系统安全性视角，我反思报告的关键结论，指出现行主导的技术框架中关于AI安全的核心问题，以及这些问题如何阻碍全面安全的有意义讨论和政策制定。系统安全性学科已经处理基于软件的系统安全风险数十年，并将AI系统中的安全风险视为社会技术性的，需要考虑技术和非技术因素及其相互作用。国际AI安全报告确实指出了需要采取系统安全性方法。系统安全领域的教训、概念和方法确实为通过集成而非附加非技术因素和干预来克服当前技术方法的局限性提供了重要蓝图。最后，建立系统安全性学科如何帮助我们克服《欧洲AI法案》的局限性，以及该学科如何有助于塑造公共利益AI的可持续投资。 

---
# A case for specialisation in non-human entities 

**Title (ZH)**: 非人类实体专门化的论据 

**Authors**: El-Mahdi El-Mhamdi, Lê-Nguyên Hoang, Mariame Tighanimine  

**Link**: [PDF](https://arxiv.org/pdf/2503.04742)  

**Abstract**: With the rise of large multi-modal AI models, fuelled by recent interest in large language models (LLMs), the notion of artificial general intelligence (AGI) went from being restricted to a fringe community, to dominate mainstream large AI development programs.
In contrast, in this paper, we make a \emph{case for specialisation}, by reviewing the pitfalls of generality and stressing the industrial value of specialised
systems.
Our contribution is threefold. First, we review the most widely accepted arguments \emph{against} specialisation, and discuss how their relevance in the context of human labour is actually an argument \emph{for} specialisation in the case of non human agents, be they algorithms or human organisations. Second, we propose four arguments \emph{in favor of} specialisation, ranging from machine learning robustness, to computer security, social sciences and cultural evolution.
Third, we finally make a case for \emph{specification}, discuss how the machine learning approach to AI has so far failed to catch up with good practices from safety-engineering and formal verification of software, and discuss how some emerging good practices in machine learning help reduce this gap.
In particular, we justify the need for \emph{specified governance} for hard-to-specify systems. 

**Abstract (ZH)**: 大型多模态AI模型兴起背景下人工通用智能理念从边缘走向主流：论专业化的重要性及规范性 

---
# Which Information should the UK and US AISI share with an International Network of AISIs? Opportunities, Risks, and a Tentative Proposal 

**Title (ZH)**: 英国和美国AISI应与国际AISIs网络分享哪些信息？机遇、风险及初步建议 

**Authors**: Lara Thurnherr  

**Link**: [PDF](https://arxiv.org/pdf/2503.04741)  

**Abstract**: The UK AI Safety Institute (UK AISI) and its parallel organisation in the United States (US AISI) take up a unique position in the recently established International Network of AISIs. Both are in jurisdictions with frontier AI companies and are assuming leading roles in the international conversation on AI Safety. This paper argues that it is in the interest of both institutions to share specific categories of information with the International Network of AISIs, deliberately abstain from sharing others and carefully evaluate sharing some categories on a case by case basis, according to domestic priorities. The paper further proposes a provisional framework with which policymakers and researchers can distinguish between these three cases, taking into account the potential benefits and risks of sharing specific categories of information, ranging from pre-deployment evaluation results to evaluation standards. In an effort to further improve the research on AI policy relevant information sharing decisions, the paper emphasises the importance of continuously monitoring fluctuating factors influencing sharing decisions and a more in-depth analysis of specific policy relevant information categories and additional factors to consider in future research. 

**Abstract (ZH)**: 英国AI安全研究所（UK AISI）及其在美国的平行组织（US AISI）在新成立的国际AI安全研究所网络中占据独特位置。两者都在拥有前沿AI公司的管辖区域内，并在国际AI安全对话中承担领导角色。本文认为，这两所机构有必要向国际AI安全研究所网络分享特定类别信息，故意不分享其他类别信息，并根据国内优先事项就某些类别信息的具体案例进行谨慎评估。本文进一步提出了一种暂定框架，供政策制定者和研究人员区分这三种情况，同时考虑分享特定类别信息的潜在利益和风险，范围从部署前的评估结果到评估标准。为进一步改善与AI政策相关的信息共享决策的研究，本文强调持续监控影响共享决策的波动因素以及对特定政策相关信息类别和未来研究中需要考虑的额外因素进行更深入分析的重要性。 

---
# PRISM: Perspective Reasoning for Integrated Synthesis and Mediation as a Multi-Perspective Framework for AI Alignment 

**Title (ZH)**: PRISM: 多视角推理框架下的综合合成与调解以实现AI对齐 

**Authors**: Anthony Diamond  

**Link**: [PDF](https://arxiv.org/pdf/2503.04740)  

**Abstract**: In this work, we propose Perspective Reasoning for Integrated Synthesis and Mediation (PRISM), a multiple-perspective framework for addressing persistent challenges in AI alignment such as conflicting human values and specification gaming. Grounded in cognitive science and moral psychology, PRISM organizes moral concerns into seven "basis worldviews", each hypothesized to capture a distinct dimension of human moral cognition, ranging from survival-focused reflexes through higher-order integrative perspectives. It then applies a Pareto-inspired optimization scheme to reconcile competing priorities without reducing them to a single metric. Under the assumption of reliable context validation for robust use, the framework follows a structured workflow that elicits viewpoint-specific responses, synthesizes them into a balanced outcome, and mediates remaining conflicts in a transparent and iterative manner. By referencing layered approaches to moral cognition from cognitive science, moral psychology, and neuroscience, PRISM clarifies how different moral drives interact and systematically documents and mediates ethical tradeoffs. We illustrate its efficacy through real outputs produced by a working prototype, applying PRISM to classic alignment problems in domains such as public health policy, workplace automation, and education. By anchoring AI deliberation in these human vantage points, PRISM aims to bound interpretive leaps that might otherwise drift into non-human or machine-centric territory. We briefly outline future directions, including real-world deployments and formal verifications, while maintaining the core focus on multi-perspective synthesis and conflict mediation. 

**Abstract (ZH)**: 基于多视角的AI对齐综合与调解框架：认知科学与道德心理学视角下的观点推理（PRISM） 

---
# Responsible Artificial Intelligence Systems: A Roadmap to Society's Trust through Trustworthy AI, Auditability, Accountability, and Governance 

**Title (ZH)**: 负责任的智能系统：通过可信AI、可审计性、问责制和治理赢得社会信任的道路图谱 

**Authors**: Andrés Herrera-Poyatos, Javier Del Ser, Marcos López de Prado, Fei-Yue Wang, Enrique Herrera-Viedma, Francisco Herrera  

**Link**: [PDF](https://arxiv.org/pdf/2503.04739)  

**Abstract**: Artificial intelligence (AI) has matured as a technology, necessitating the development of responsibility frameworks that are fair, inclusive, trustworthy, safe and secure, transparent, and accountable. By establishing such frameworks, we can harness the full potential of AI while mitigating its risks, particularly in high-risk scenarios. This requires the design of responsible AI systems based on trustworthy AI technologies and ethical principles, with the aim of ensuring auditability and accountability throughout their design, development, and deployment, adhering to domain-specific regulations and standards.
This paper explores the concept of a responsible AI system from a holistic perspective, which encompasses four key dimensions: 1) regulatory context; 2) trustworthy AI technology along with standardization and assessments; 3) auditability and accountability; and 4) AI governance. The aim of this paper is double. First, we analyze and understand these four dimensions and their interconnections in the form of an analysis and overview. Second, the final goal of the paper is to propose a roadmap in the design of responsible AI systems, ensuring that they can gain society's trust. To achieve this trustworthiness, this paper also fosters interdisciplinary discussions on the ethical, legal, social, economic, and cultural aspects of AI from a global governance perspective. Last but not least, we also reflect on the current state and those aspects that need to be developed in the near future, as ten lessons learned. 

**Abstract (ZH)**: 人工智能的责任框架：公平、包容、可信、安全与隐私保护、透明及问责机制的研究 

---
# Copyright in AI-generated works: Lessons from recent developments in patent law 

**Title (ZH)**: AI生成作品的版权：近期专利法发展带来的启示 

**Authors**: Rita Matulionyte, Jyh-An Lee  

**Link**: [PDF](https://arxiv.org/pdf/2503.04738)  

**Abstract**: In Thaler v The Comptroller-General of Patents, Designs and Trade Marks (DABUS), Smith J. held that an AI owner can possibly claim patent ownership over an AI-generated invention based on their ownership and control of the AI system. This AI-owner approach reveals a new option to allocate property rights over AI-generated output. While this judgment was primarily about inventorship and ownership of AI-generated invention in patent law, it has important implications for copyright law. After analysing the weaknesses of applying existing judicial approaches to copyright ownership of AI-generated works, this paper examines whether the AI-owner approach is a better option for determining copyright ownership of AI-generated works. The paper argues that while contracts can be used to work around the AI-owner approach in scenarios where users want to commercially exploit the outputs, this approach still provides more certainty and less transaction costs for relevant parties than other approaches proposed so far. 

**Abstract (ZH)**: 在Thaler诉专利、外观设计及商标审查长一案（DABUS）中，史密斯法官裁定，AI的所有者可以基于其对AI系统的所有权和控制权，宣称对AI生成发明的专利所有权。这一AI所有者的方法揭示了一种新的分配AI生成输出财产权的方式。虽然这一判决主要涉及专利法中AI生成发明的发明者身份和所有权问题，但它对版权法具有重要意义。在分析现有司法方法应用于AI生成作品版权所有权的不足之后，本文探讨AI所有者方法是否是确定AI生成作品版权所有权的更好选择。本文认为，尽管在用户希望商业利用输出的情况下，合同可以绕过AI所有者方法，但该方法仍然为相关方提供了更多的确定性和更低的交易成本，这优于目前提出的所有其他方法。 

---
# Carelessness Detection using Performance Factor Analysis: A New Operationalization with Unexpectedly Different Relationship to Learning 

**Title (ZH)**: 使用绩效因素分析进行粗心检测：一个新的操作化及其与学习出乎意料的关系 

**Authors**: Jiayi Zhang, Ryan S. Baker, Namrata Srivastava, Jaclyn Ocumpaugh, Caitlin Mills, Bruce M. McLaren  

**Link**: [PDF](https://arxiv.org/pdf/2503.04737)  

**Abstract**: Detection of carelessness in digital learning platforms has relied on the contextual slip model, which leverages conditional probability and Bayesian Knowledge Tracing (BKT) to identify careless errors, where students make mistakes despite having the knowledge. However, this model cannot effectively assess carelessness in questions tagged with multiple skills due to the use of conditional probability. This limitation narrows the scope within which the model can be applied. Thus, we propose a novel model, the Beyond Knowledge Feature Carelessness (BKFC) model. The model detects careless errors using performance factor analysis (PFA) and behavioral features distilled from log data, controlling for knowledge when detecting carelessness. We applied the BKFC to detect carelessness in data from middle school students playing a learning game on decimal numbers and operations. We conducted analyses comparing the careless errors detected using contextual slip to the BKFC model. Unexpectedly, careless errors identified by these two approaches did not align. We found students' post-test performance was (corresponding to past results) positively associated with the carelessness detected using the contextual slip model, while negatively associated with the carelessness detected using the BKFC model. These results highlight the complexity of carelessness and underline a broader challenge in operationalizing carelessness and careless errors. 

**Abstract (ZH)**: 超越知识特征的疏忽检测模型（BKFC）：基于性能因素分析和行为特征识别疏忽错误 

---
# Standardizing Intelligence: Aligning Generative AI for Regulatory and Operational Compliance 

**Title (ZH)**: 标准化智能：对接监管与运营合规的生成式AI 

**Authors**: Joseph Marvin Imperial, Matthew D. Jones, Harish Tayyar Madabushi  

**Link**: [PDF](https://arxiv.org/pdf/2503.04736)  

**Abstract**: Technical standards, or simply standards, are established documented guidelines and rules that facilitate the interoperability, quality, and accuracy of systems and processes. In recent years, we have witnessed an emerging paradigm shift where the adoption of generative AI (GenAI) models has increased tremendously, spreading implementation interests across standard-driven industries, including engineering, legal, healthcare, and education. In this paper, we assess the criticality levels of different standards across domains and sectors and complement them by grading the current compliance capabilities of state-of-the-art GenAI models. To support the discussion, we outline possible challenges and opportunities with integrating GenAI for standard compliance tasks while also providing actionable recommendations for entities involved with developing and using standards. Overall, we argue that aligning GenAI with standards through computational methods can help strengthen regulatory and operational compliance. We anticipate this area of research will play a central role in the management, oversight, and trustworthiness of larger, more powerful GenAI-based systems in the near future. 

**Abstract (ZH)**: 技术标准是建立并记载的指南和规则，旨在促进系统和过程的互操作性、质量和准确性。近年来，我们见证了生成式人工智能（GenAI）模型采用程度的显著增加，其实施兴趣遍及由标准驱动的行业，包括工程、法律、医疗保健和教育。本文评估了不同领域和部门中标准的关键性级别，并通过评价当前最先进的GenAI模型的合规能力加以补充。为了支持讨论，我们概述了将GenAI整合到标准合规任务中可能面临的挑战和机遇，并为参与标准开发和使用的实体提供可操作的建议。总体而言，我们认为通过计算方法使GenAI与标准相一致有助于强化监管和运营合规性。我们预计，这一研究领域将在未来对大型、更强大的基于GenAI系统的管理和监督中扮演核心角色。 

---
# Ethics of generative AI and manipulation: a design-oriented research agenda 

**Title (ZH)**: 生成式人工智能与操控的伦理：以设计为导向的研究议程 

**Authors**: Michael Klenk  

**Link**: [PDF](https://arxiv.org/pdf/2503.04733)  

**Abstract**: Generative AI enables automated, effective manipulation at scale. Despite the growing general ethical discussion around generative AI, the specific manipulation risks remain inadequately investigated. This article outlines essential inquiries encompassing conceptual, empirical, and design dimensions of manipulation, pivotal for comprehending and curbing manipulation risks. By highlighting these questions, the article underscores the necessity of an appropriate conceptualisation of manipulation to ensure the responsible development of Generative AI technologies. 

**Abstract (ZH)**: 生成式AI使大规模自动化有效操作成为可能。尽管生成式AI的通用伦理讨论日益增长，但具体的操纵风险仍未得到充分研究。本文概述了涵盖概念、实证和设计维度的关键问题，对于理解和遏制操纵风险至关重要。通过强调这些问题，本文强调了对操纵进行适当概念化的重要性，以确保生成式AI技术的负责任发展。 

---
# Epistemic Logic Programs: Non-Ground and Counting Complexity 

**Title (ZH)**: 知识逻辑程序：非ground化与计数复杂性 

**Authors**: Thomas Eiter, Johannes K. Fichte, Markus Hecher, Stefan Woltran  

**Link**: [PDF](https://arxiv.org/pdf/2503.04731)  

**Abstract**: Answer Set Programming (ASP) is a prominent problem-modeling and solving framework, whose solutions are called answer sets. Epistemic logic programs (ELP) extend ASP to reason about all or some answer sets. Solutions to an ELP can be seen as consequences over multiple collections of answer sets, known as world views. While the complexity of propositional programs is well studied, the non-ground case remains open. This paper establishes the complexity of non-ground ELPs. We provide a comprehensive picture for well-known program fragments, which turns out to be complete for the class NEXPTIME with access to oracles up to \Sigma^P_2. In the quantitative setting, we establish complexity results for counting complexity beyond #EXP. To mitigate high complexity, we establish results in case of bounded predicate arity, reaching up to the fourth level of the polynomial hierarchy. Finally, we provide ETH-tight runtime results for the parameter treewidth, which has applications in quantitative reasoning, where we reason on (marginal) probabilities of epistemic literals. 

**Abstract (ZH)**: 非地面Epistemic逻辑程序的复杂性分析 

---
# Function-Coherent Gambles 

**Title (ZH)**: 功能相干赌局 

**Authors**: Gregory Wheeler  

**Link**: [PDF](https://arxiv.org/pdf/2503.01855)  

**Abstract**: The desirable gambles framework provides a foundational approach to imprecise probability theory but relies heavily on linear utility assumptions. This paper introduces {\em function-coherent gambles}, a generalization that accommodates non-linear utility while preserving essential rationality properties. We establish core axioms for function-coherence and prove a representation theorem that characterizes acceptable gambles through continuous linear functionals. The framework is then applied to analyze various forms of discounting in intertemporal choice, including hyperbolic, quasi-hyperbolic, scale-dependent, and state-dependent discounting. We demonstrate how these alternatives to constant-rate exponential discounting can be integrated within the function-coherent framework. This unified treatment provides theoretical foundations for modeling sophisticated patterns of time preference within the desirability paradigm, bridging a gap between normative theory and observed behavior in intertemporal decision-making under genuine uncertainty. 

**Abstract (ZH)**: 函数一致赌注：非线性效用下不精确概率理论的广义基础及时间折扣分析 

---
