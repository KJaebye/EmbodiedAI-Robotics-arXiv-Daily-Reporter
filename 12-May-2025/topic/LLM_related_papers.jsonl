{'arxiv_id': 'arXiv:2505.05787', 'title': 'Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives', 'authors': 'Chengyang He, Xu Liu, Gadiel Sznaier Camps, Guillaume Sartoretti, Mac Schwager', 'link': 'https://arxiv.org/abs/2505.05787', 'abstract': 'Diffusion policies have demonstrated remarkable dexterity and robustness in intricate, high-dimensional robot manipulation tasks, while training from a small number of demonstrations. However, the reason for this performance remains a mystery. In this paper, we offer a surprising hypothesis: diffusion policies essentially memorize an action lookup table -- and this is beneficial. We posit that, at runtime, diffusion policies find the closest training image to the test image in a latent space, and recall the associated training action sequence, offering reactivity without the need for action generalization. This is effective in the sparse data regime, where there is not enough data density for the model to learn action generalization. We support this claim with systematic empirical evidence. Even when conditioned on wildly out of distribution (OOD) images of cats and dogs, the Diffusion Policy still outputs an action sequence from the training data. With this insight, we propose a simple policy, the Action Lookup Table (ALT), as a lightweight alternative to the Diffusion Policy. Our ALT policy uses a contrastive image encoder as a hash function to index the closest corresponding training action sequence, explicitly performing the computation that the Diffusion Policy implicitly learns. We show empirically that for relatively small datasets, ALT matches the performance of a diffusion model, while requiring only 0.0034 of the inference time and 0.0085 of the memory footprint, allowing for much faster closed-loop inference with resource constrained robots. We also train our ALT policy to give an explicit OOD flag when the distance between the runtime image is too far in the latent space from the training images, giving a simple but effective runtime monitor. More information can be found at: this https URL.', 'abstract_zh': '扩散策略在少量示范下于复杂高维度机器人 manipulation 任务中展示了出色的灵巧性和鲁棒性，但其原因仍是个谜。本文提出一个惊人的假设：扩散策略实际上记忆了一个动作查找表——这是有益的。我们假设，在运行时，扩散策略在潜在空间中找到与测试图像最接近的训练图像，并召回相应的训练动作序列，从而实现快速反应而无需动作泛化。这一机制在数据稀疏的情况下尤为有效，模型在这些情况下无法学会动作泛化。我们通过系统性的实验证据支持这一观点。即使在使用猫和狗的野生离分布（OOD）图像进行条件约束时，扩散策略仍能输出训练数据中的动作序列。基于此洞见，我们提出一种简单的策略——动作查找表（ALT），作为一种轻量级的替代方案。我们的ALT策略使用对比图像编码器作为哈希函数，以索引最接近的对应训练动作序列，明确执行扩散策略隐含学习的计算。我们实验证明，对于相对较小的数据集，ALT在性能上与扩散模型相当，但仅需模型推理时间的0.0034和内存足迹的0.0085，从而在资源受限的机器人中实现更快的闭环推理。我们还训练ALT策略，在测试时图像与训练图像在潜在空间中的距离过远时给出明确的OOD标志，提供一个简单而有效的运行时监控。更多信息可访问：this https URL。', 'title_zh': '揭开扩散策略的神秘面纱：动作记忆与简单的查找表替代方案'}
{'arxiv_id': 'arXiv:2505.05665', 'title': 'Adaptive Stress Testing Black-Box LLM Planners', 'authors': 'Neeloy Chakraborty, John Pohovey, Melkior Ornik, Katherine Driggs-Campbell', 'link': 'https://arxiv.org/abs/2505.05665', 'abstract': 'Large language models (LLMs) have recently demonstrated success in generalizing across decision-making tasks including planning, control and prediction, but their tendency to hallucinate unsafe and undesired outputs poses risks. We argue that detecting such failures is necessary, especially in safety-critical scenarios. Existing black-box methods often detect hallucinations by identifying inconsistencies across multiple samples. Many of these approaches typically introduce prompt perturbations like randomizing detail order or generating adversarial inputs, with the intuition that a confident model should produce stable outputs. We first perform a manual case study showing that other forms of perturbations (e.g., adding noise, removing sensor details) cause LLMs to hallucinate in a driving environment. We then propose a novel method for efficiently searching the space of prompt perturbations using Adaptive Stress Testing (AST) with Monte-Carlo Tree Search (MCTS). Our AST formulation enables discovery of scenarios and prompts that cause language models to act with high uncertainty. By generating MCTS prompt perturbation trees across diverse scenarios, we show that offline analyses can be used at runtime to automatically generate prompts that influence model uncertainty, and to inform real-time trust assessments of an LLM.', 'abstract_zh': '大型语言模型（LLMs）在规划、控制和预测等决策任务上展现出泛化的成功，但它们产生不安全和不 desired 输出的趋势带来了风险。我们认为，在安全关键场景中检测此类失败是必要的。现有黑盒方法通常通过识别多份样本之间的不一致性来检测幻觉。许多这些方法通常引入提示扰动，例如随机化细节顺序或生成对抗性输入，其直觉是自信的模型应产生稳定输出。我们首先进行了一项手动案例研究，表明其他形式的扰动（例如，添加噪声、移除传感器细节）会使LLMs在驾驶环境中产生幻觉。然后，我们提出了一种使用自适应压力测试（AST）和蒙特卡洛树搜索（MCTS）高效搜索提示扰动空间的新方法。我们的AST公式化使我们能够发现导致语言模型高不确定性行为的场景和提示。通过跨多种场景生成MCTS提示扰动树，我们展示了脱机分析可以在运行时自动生成影响模型不确定性的提示，并为LLM提供实时信任评估信息。', 'title_zh': '自适应压力测试黑盒LLM规划器'}
{'arxiv_id': 'arXiv:2505.06096', 'title': 'Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs', 'authors': 'Sam Bush, Matthew DeLorenzo, Phat Tieu, Jeyavijayan Rajendran', 'link': 'https://arxiv.org/abs/2505.06096', 'abstract': 'Limitations in Large Language Model (LLM) capabilities for hardware design tasks, such as generating functional Verilog codes, have motivated various fine-tuning optimizations utilizing curated hardware datasets from open-source repositories. However, these datasets remain limited in size and contain minimal checks on licensing for reuse, resulting in potential copyright violations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to estimate the risk of Verilog-trained LLMs to generate copyright-protected codes. To minimize this risk, we present an open-source Verilog dataset, FreeSet, containing over 220k files, along with the automated dataset curation framework utilized to provide additional guarantees of fair-use Verilog data. We then execute an LLM fine-tuning framework consisting of continual pre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our results indicate that FreeV demonstrates the smallest risk of copyright-infringement among prior works, with only a 3% violation rate. Furthermore, experimental results demonstrate improvements in Verilog generation functionality over its baseline model, improving VerilogEval pass@10 rates by over 10%.', 'abstract_zh': '大型语言模型（LLM）在硬件设计任务中的能力限制，如生成功能性的Verilog代码，推动了利用开源仓库中的精心策划的硬件数据集的各种精细调整优化方法。然而，这些数据集仍然规模有限，并且在再利用时的许可证检查较少，导致潜在的版权侵权风险。因此，我们提出了一种评估基准来估计Verilog训练的LLM生成受版权保护代码的风险。为了最小化这种风险，我们提供了一个包含超过220k个文件的开源Verilog数据集FreeSet，以及用于提供有关公平使用Verilog数据的额外保障的自动数据策展框架。然后，我们执行了一个持续预训练的LLM精细调整框架，从而得到一个用于Verilog的精细调整的Llama模型FreeV。我们的结果表明，FreeV在先前工作中展示了最小的版权侵权风险，其中只有3%的违规率。此外，实验结果还显示，FreeV在Verilog生成功能方面优于其基线模型，VerilogEval pass@10得分提高了超过10%。', 'title_zh': '免费且公正的硬件：利用大语言模型实现版权侵权-free 的 Verilog 生成途径'}
{'arxiv_id': 'arXiv:2505.05758', 'title': 'APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning', 'authors': 'Azim Ospanov, Roozbeh Yousefzadeh', 'link': 'https://arxiv.org/abs/2505.05758', 'abstract': "Formal reasoning and automated theorem proving constitute a challenging subfield of machine learning, in which machines are tasked with proving mathematical theorems using formal languages like Lean. A formal verification system can check whether a formal proof is correct or not almost instantaneously, but generating a completely correct formal proof with large language models (LLMs) remains a formidable task. The usual approach in the literature is to prompt the LLM many times (up to several thousands) until one of the generated proofs passes the verification system. In this work, we present APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a modular, model-agnostic pipeline that combines the strengths of the Lean compiler with an LLM's reasoning abilities to achieve better proof-generation results at a low sampling budget. Apollo directs a fully automated process in which the LLM generates proofs for theorems, a set of agents analyze the proofs, fix the syntax errors, identify the mistakes in the proofs using Lean, isolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on each remaining goal with a low top-K budget. The repaired sub-proofs are recombined and reverified, iterating up to a user-controlled maximum number of attempts. On the miniF2F benchmark, we establish a new state-of-the-art accuracy of 75.0% among 7B-parameter models while keeping the sampling budget below one thousand. Moreover, Apollo raises the state-of-the-art accuracy for Goedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few hundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40% accuracy. Our results demonstrate that targeted, compiler-guided repair of LLM outputs yields dramatic gains in both efficiency and correctness, suggesting a general paradigm for scalable automated theorem proving.", 'abstract_zh': '自动推理与形式化定理证明是机器学习的一个具有挑战性的子领域，其中机器使用如Lean的形式语言来证明数学定理。形式验证系统几乎可以瞬时检查形式证明的正确性，但使用大语言模型（LLMs）生成完全正确的形式证明仍是一个艰巨的任务。文献中通常的方法是在验证系统中不断提示LLM（多达数千次），直到生成的证明之一通过验证系统。在本工作中，我们提出了APOLLO（自动推理验证通过LLM和Lean合作），一个模块化、模型无关的管道，结合了Lean编译器的力量和LLM的推理能力，在较低的采样预算下实现更好的证明生成结果。Apollo指导一个全自动过程，在该过程中，LLM生成定理的证明，一组代理分析证明、修正语法错误、使用Lean识别证明中的错误、隔离失败的子引理、利用自动求解器，并对剩余目标调用每个LLM，使用较低的Top-K预算。修复的子证明被重新组合和重新验证，迭代到用户控制的最大尝试次数。在miniF2F基准测试中，我们在7B参数模型中建立了一个新的最佳准确率75.0%，同时保持采样预算低于一千。此外，Apollo将Goedel-Prover-SFT的最佳准确率提高到65.6%，并将样本复杂度从25,600降低到几百。通用模型（o3-mini, o4-mini）的准确率从3-7%提高到超过40%。我们的结果表明，目标导向、编译器引导的LLM输出修复在效率和正确性方面产生了巨大的提升，这表明了一种可扩展自动定理证明的一般范式。', 'title_zh': 'APOLLO: 自动化大语言模型和精简协作以实现高级形式化推理'}
{'arxiv_id': 'arXiv:2505.05616', 'title': 'Leveraging Large Language Models for enzymatic reaction prediction and characterization', 'authors': 'Lorenzo Di Fruscia, Jana Marie Weber', 'link': 'https://arxiv.org/abs/2505.05616', 'abstract': 'Predicting enzymatic reactions is crucial for applications in biocatalysis, metabolic engineering, and drug discovery, yet it remains a complex and resource-intensive task. Large Language Models (LLMs) have recently demonstrated remarkable success in various scientific domains, e.g., through their ability to generalize knowledge, reason over complex structures, and leverage in-context learning strategies. In this study, we systematically evaluate the capability of LLMs, particularly the Llama-3.1 family (8B and 70B), across three core biochemical tasks: Enzyme Commission number prediction, forward synthesis, and retrosynthesis. We compare single-task and multitask learning strategies, employing parameter-efficient fine-tuning via LoRA adapters. Additionally, we assess performance across different data regimes to explore their adaptability in low-data settings. Our results demonstrate that fine-tuned LLMs capture biochemical knowledge, with multitask learning enhancing forward- and retrosynthesis predictions by leveraging shared enzymatic information. We also identify key limitations, for example challenges in hierarchical EC classification schemes, highlighting areas for further improvement in LLM-driven biochemical modeling.', 'abstract_zh': '预测酶促反应对于生物催化、代谢工程和药物发现的应用至关重要，但这项任务依然复杂且资源密集。大规模语言模型（LLMs）最近在各个科学领域展现了显著的成功，例如通过其泛化知识、处理复杂结构和利用上下文学习策略的能力。在这项研究中，我们系统地评估了LLMs，特别是Llama-3.1家族（8B和70B参数版本）在三大核心生化任务中的能力：酶委分类号预测、正向合成和逆向合成。我们比较了单任务和多任务学习策略，并通过LoRA适配器进行参数高效微调。此外，我们还评估了不同数据集对模型性能的影响，以探索其在数据稀缺环境中的适应性。研究结果表明，微调后的LLMs能够捕捉生化知识，多任务学习通过利用共享的酶促信息提高了正向合成和逆向合成的预测能力。我们还指出了关键的局限性，如在分层酶分类方案中的挑战，这突显了LLM驱动的生化建模进一步改进的必要性。', 'title_zh': '利用大规模语言模型进行酶促反应预测与表征'}
{'arxiv_id': 'arXiv:2505.05602', 'title': 'HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics', 'authors': 'Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec', 'link': 'https://arxiv.org/abs/2505.05602', 'abstract': 'As Large Language Models (LLMs) and other AI systems evolve, robustly estimating their capabilities from inherently stochastic outputs while systematically quantifying uncertainty in these estimates becomes increasingly important. Further, advanced AI evaluations often have a nested hierarchical structure, exhibit high levels of complexity, and come with high costs in testing the most advanced AI systems. To address these challenges, we introduce HiBayES, a generalizable Hierarchical Bayesian modeling framework for AI Evaluation Statistics. HiBayES supports robust inferences in classical question-answer benchmarks and advanced agentic evaluations, particularly in low-data scenarios (e.g., < 20 data points per evaluation). Built on Generalized Linear Models (GLMs), Bayesian data analysis, and formal model comparison, HiBayES provides principled uncertainty quantification and robust parameter estimation. This paper offers a comprehensive introduction to HiBayES, including illustrative examples, comparisons to conventional statistical methods, and practical guidance for implementing multilevel Bayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta version) for out-of-the-box implementation.', 'abstract_zh': '随着大型语言模型（LLMs）和其他AI系统的发展，从本质上具有随机性的输出中稳健估计其能力和系统地量化这些估计的不确定性变得越来越重要。此外，先进的AI评估往往具有嵌套的层级结构，表现出极高的复杂性，并且测试最先进AI系统需要高成本。为了解决这些问题，我们介绍了HiBayES，一种适用于AI评估统计的泛化层级贝叶斯建模框架。HiBayES 支持在经典问答基准测试和高级代理评估中进行稳健的推断，尤其是在低数据场景（例如，每个评估少于20个数据点）中。基于广义线性模型（GLMs）、贝叶斯数据分析和正式模型比较，HiBayES 提供了原则性的不确定性量化和稳健的参数估计。本文全面介绍了HiBayES，包括示例说明、与传统统计方法的比较以及实施多层次贝叶斯GLMs 的实用指导，并提供了HiBayES 软件包（Beta版本）以供直接使用。', 'title_zh': 'HiBayES：一种用于AI评估统计的分层贝叶斯建模框架'}
{'arxiv_id': 'arXiv:2505.06175', 'title': 'Turbo-ICL: In-Context Learning-Based Turbo Equalization', 'authors': 'Zihang Song, Matteo Zecchin, Bipin Rajendran, Osvaldo Simeone', 'link': 'https://arxiv.org/abs/2505.06175', 'abstract': 'This paper introduces a novel in-context learning (ICL) framework, inspired by large language models (LLMs), for soft-input soft-output channel equalization in coded multiple-input multiple-output (MIMO) systems. The proposed approach learns to infer posterior symbol distributions directly from a prompt of pilot signals and decoder feedback. A key innovation is the use of prompt augmentation to incorporate extrinsic information from the decoder output as additional context, enabling the ICL model to refine its symbol estimates iteratively across turbo decoding iterations. Two model variants, based on Transformer and state-space architectures, are developed and evaluated. Extensive simulations demonstrate that, when traditional linear assumptions break down, e.g., in the presence of low-resolution quantization, ICL equalizers consistently outperform conventional model-based baselines, even when the latter are provided with perfect channel state information. Results also highlight the advantage of Transformer-based models under limited training diversity, as well as the efficiency of state-space models in resource-constrained scenarios.', 'abstract_zh': '本文提出了一种受大规模语言模型启发的新型上下文学习（ICL）框架，用于编码的多输入多输出（MIMO）系统中的软输入-软输出信道均衡。所提出的方法直接从探针信号和解码器反馈中学习后验符号分布。一个关键创新是通过探针增强引入解码器输出的外部信息作为额外上下文，使ICL模型能够在Turbo解码迭代过程中迭代 refinement 其符号估计。基于Transformer和状态空间架构发展了两种模型变体，并进行了评估。广泛的仿真实验表明，当传统的线性假设不成立，例如在低分辨率量化存在的情况下，ICL均衡器始终优于传统的基于模型的基础方案，即使后者拥有完美的信道状态信息。结果还强调了在有限的训练多样性下基于Transformer模型的优势，以及基于状态空间模型在资源受限场景下的效率。', 'title_zh': 'Turbo-ICL：基于上下文学习的 Turbo 等化'}
{'arxiv_id': 'arXiv:2505.06150', 'title': 'A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets', 'authors': 'Ryan Lagasse, Aidan Kiernans, Avijit Ghosh, Shiri Dori-Hacohen', 'link': 'https://arxiv.org/abs/2505.06150', 'abstract': 'We introduce a scaling law for fine-tuning large language models (LLMs) under fixed compute budgets that explicitly accounts for data composition. Conventional approaches measure training data solely by total tokens, yet the number of examples and their average token length -- what we term \\emph{dataset volume} -- play a decisive role in model performance. Our formulation is tuned following established procedures. Experiments on the BRICC dataset \\cite{salavati2024reducing} and subsets of the MMLU dataset \\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple subsampling strategies, reveal that data composition significantly affects token efficiency. These results motivate refined scaling laws for practical LLM fine-tuning in resource-constrained settings.', 'abstract_zh': '我们介绍了一种在固定计算预算下调整大型语言模型（LLMs）的缩放定律，该定律明确考虑了数据组成。', 'title_zh': '固定计算预算下LLM细调中令牌效率的标度律'}
{'arxiv_id': 'arXiv:2505.06108', 'title': 'LLMs Outperform Experts on Challenging Biology Benchmarks', 'authors': 'Lennart Justen', 'link': 'https://arxiv.org/abs/2505.06108', 'abstract': 'This study systematically evaluates 27 frontier Large Language Models on eight diverse biology benchmarks spanning molecular biology, genetics, cloning, virology, and biosecurity. Models from major AI developers released between November 2022 and April 2025 were assessed through ten independent runs per benchmark. The findings reveal dramatic improvements in biological capabilities. Top model performance increased more than 4-fold on the challenging text-only subset of the Virology Capabilities Test over the study period, with the top model now performing twice as well as expert virologists. Several models now match or exceed expert-level performance on other challenging benchmarks, including LAB-Bench CloningScenarios and the biology subsets of GPQA and WMDP. Contrary to expectations, chain-of-thought did not substantially improve performance over zero-shot evaluation, while extended reasoning features in o3-mini and Claude 3.7 Sonnet typically improved performance as predicted by inference scaling. Benchmarks such as PubMedQA and the MMLU and WMDP biology subsets exhibited performance plateaus well below 100%, suggesting benchmark saturation and errors in the underlying benchmark data. The analysis highlights the need for more sophisticated evaluation methodologies as AI systems continue to advance.', 'abstract_zh': '本研究系统性评估了27个前沿大型语言模型在涵盖分子生物学、遗传学、克隆、病毒学和生物安全等八项多元生物学基准测试中的表现。从2022年11月到2025年4月期间发布的主流AI开发者的模型，每项基准测试进行了十次独立运行评估。研究结果揭示了生物能力方面的显著进步。顶级模型在病毒学能力测试的挑战性纯文本子集中的表现，在研究期间提升了4倍以上，顶级模型现在比专家病毒学家的绩效高出一倍。多项模型在其他挑战性基准测试中达到了或超过了专家级绩效，包括LAB-Bench克隆场景和GPQA及WMDP的生物学子集。与预期相反，推理链条并未在零样本评估中显著提升性能，而o3-mini和Claude 3.7 Sonnet中的扩展推理特征通常如预期的推断缩放所示，提升了性能。诸如PubMedQA和MMLU及WMDP的生物学子集等基准测试的表现 plateau 处于低于100%的水平，这表明基准测试饱和和基础数据中的错误。分析强调，随着AI系统继续进步，需要更加复杂的评估方法。', 'title_zh': 'LLMs在具有挑战性的生物学基准测试中 surpass 专家'}
{'arxiv_id': 'arXiv:2505.06085', 'title': "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities", 'authors': 'Hiari Pizzini Cavagna, Daniele Cesarini, Andrea Bartolini', 'link': 'https://arxiv.org/abs/2505.06085', 'abstract': "The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.", 'abstract_zh': '随着大型语言模型（LLMs）服务对生成人工智能日益增长的需求，已经推动了优化计算效率和能耗的专用硬件架构的发展。本文评估了Tenstorrent Grayskull e75 RISC-V加速器在降低数值精度下基本线性代数内核的性能，这是LLM计算中的基本操作。本文详细分析了Grayskull的执行模型、网格尺寸、矩阵维度、数据格式及其对计算效率的影响。此外，我们将Grayskull的性能与具有张量加速的最新架构进行了比较，包括Intel Sapphire Rapids处理器和两台NVIDIA GPU（V100和A100）。虽然NVIDIA GPU在原始性能上占据优势，但Grayskull在能耗和计算吞吐量之间的权衡表现出竞争力，BF16精度下的峰值性能达到1.55 TFLOPs/W。', 'title_zh': '评估Tenstorrent的RISC-V矩阵乘法加速能力'}
{'arxiv_id': 'arXiv:2505.05946', 'title': 'Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2', 'authors': 'Vytenis Šliogeris, Povilas Daniušis, Artūras Nakvosas', 'link': 'https://arxiv.org/abs/2505.05946', 'abstract': "This technical report describes an experiment on autoregressive pre-training of Gemma2 2 billion parameter large language model (LLM) with 10\\% on the Lithuanian language component of CulturaX from the point of view of continual learning. We apply elastic weight consolidation (EWC) to the full set of the model's parameters and investigate language understanding benchmarks, consisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande sets (both in English and Lithuanian versions), and perplexity benchmarks. We empirically demonstrate that EWC regularisation allows us not only to mitigate catastrophic forgetting effects but also that it is potentially beneficial for learning of the new task with LLMs.", 'abstract_zh': '本技术报告从持续学习的角度描述了使用CulturaX中的10%立陶宛语言组件对Gemma2 2亿参数大型语言模型（LLM）进行自回归预训练的实验。我们对模型的所有参数应用弹性权重聚合（EWC），并调查了由Arc、Belebele、Gsm8K、Hellaswag、MMLU、TruthfulQA和Winogrande数据集（包括英语和立陶宛语版本）组成的语言理解基准和困惑度基准。我们实验证明，EWC正则化不仅可以减轻灾难性遗忘效应，还可能对使用LLM学习新任务有益。', 'title_zh': 'Gemma2全参数连续预训练的弹性权重聚合'}
{'arxiv_id': 'arXiv:2505.05863', 'title': 'Evolutionary ecology of words', 'authors': 'Reiji Suzuki, Takaya Arita', 'link': 'https://arxiv.org/abs/2505.05863', 'abstract': 'We propose a model for the evolutionary ecology of words as one attempt to extend evolutionary game theory and agent-based models by utilizing the rich linguistic expressions of Large Language Models (LLMs). Our model enables the emergence and evolution of diverse and infinite options for interactions among agents. Within the population, each agent possesses a short word (or phrase) generated by an LLM and moves within a spatial environment. When agents become adjacent, the outcome of their interaction is determined by the LLM based on the relationship between their words, with the loser\'s word being replaced by the winner\'s. Word mutations, also based on LLM outputs, may occur. We conducted preliminary experiments assuming that ``strong animal species" would survive. The results showed that from an initial population consisting of well-known species, many species emerged both gradually and in a punctuated equilibrium manner. Each trial demonstrated the unique evolution of diverse populations, with one type of large species becoming dominant, such as terrestrial animals, marine life, or extinct species, which were ecologically specialized and adapted ones across diverse extreme habitats. We also conducted a long-term experiment with a large population, demonstrating the emergence and coexistence of diverse species.', 'abstract_zh': '我们提出了一种词汇演化生态学模型，旨在通过利用大型语言模型（LLMs）丰富的语言表达，扩展进化游戏理论和基于代理的模型。该模型能够促进代理之间多样且无限的互动方式的产生和演变。在该群体中，每个代理拥有由LLM生成的短词（或短语），并在空间环境中移动。当代理相邻时，其互动的结果由LLM根据它们之间词汇的关系来决定，输者词汇被胜者词汇取代。词汇突变也基于LLM的输出。我们在假设“强势动物物种”会生存的前提下进行了初步实验。结果显示，从最初由知名物种组成的人口开始，许多物种以渐进和间断平衡的方式逐渐出现。每次试验都展示了不同群体的独特演化，其中一类大型物种成为主导，如陆生动物、海洋生物或适应不同极端环境的生态特化和适应物种。我们还进行了长期大规模实验，展示了多种物种的出现与共存。', 'title_zh': '词的进化生态学'}
{'arxiv_id': 'arXiv:2505.05849', 'title': 'AgentXploit: End-to-End Redteaming of Black-Box AI Agents', 'authors': 'Zhun Wang, Vincent Siu, Zhe Ye, Tianneng Shi, Yuzhou Nie, Xuandong Zhao, Chenguang Wang, Wenbo Guo, Dawn Song', 'link': 'https://arxiv.org/abs/2505.05849', 'abstract': 'The strong planning and reasoning capabilities of Large Language Models (LLMs) have fostered the development of agent-based systems capable of leveraging external tools and interacting with increasingly complex environments. However, these powerful features also introduce a critical security risk: indirect prompt injection, a sophisticated attack vector that compromises the core of these agents, the LLM, by manipulating contextual information rather than direct user prompts. In this work, we propose a generic black-box fuzzing framework, AgentXploit, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents. Our approach starts by constructing a high-quality initial seed corpus, then employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS) to iteratively refine inputs, thereby maximizing the likelihood of uncovering agent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Moreover, AgentXploit exhibits strong transferability across unseen tasks and internal LLMs, as well as promising results against defenses. Beyond benchmark evaluations, we apply our attacks in real-world environments, successfully misleading agents to navigate to arbitrary URLs, including malicious sites.', 'abstract_zh': '大型语言模型（LLMs）强大的规划和推理能力促进了能够利用外部工具并与日益复杂的环境交互的基于代理的系统的发展。然而，这些强大的功能也引入了一个关键的安全风险：间接提示注入，这是一种高级攻击向量，通过操纵上下文信息而非直接用户提示来 compromize 这些代理的核心——LLM。本文提出了一种通用的灰盒模糊测试框架AgentXploit，旨在自动发现并利用多样化的LLM代理中的间接提示注入漏洞。我们的方法首先构建了一个高质量的初始种子库，然后使用基于蒙特卡洛树搜索（MCTS）的种子选择算法迭代优化输入，从而最大限度地提高发现代理弱点的可能性。我们在两个公开基准AgentDojo和VWA-adv上评估了AgentXploit，分别针对基于o3-mini和GPT-4o的代理，成功率分别为71%和70%，比基线攻击性能几乎翻了一番。此外，AgentXploit在未见过的任务和内部LLM上表现出强大的迁移性，并在针对防御措施方面取得了有希望的结果。除了基准测试评估，我们还在真实的环境中应用了我们的攻击，成功误导代理导航到任意URL，包括恶意网站。', 'title_zh': 'AgentXploit: 黑箱AI代理的整体红队评估'}
{'arxiv_id': 'arXiv:2505.05794', 'title': 'What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips', 'authors': 'Renjie Li, Wenjie Wei, Qi Xin, Xiaoli Liu, Sixuan Mao, Erik Ma, Zijian Chen, Malu Zhang, Haizhou Li, Zhaoyu Zhang', 'link': 'https://arxiv.org/abs/2505.05794', 'abstract': 'Large language models (LLMs) are rapidly pushing the limits of contemporary computing hardware. For example, training GPT-3 has been estimated to consume around 1300 MWh of electricity, and projections suggest future models may require city-scale (gigawatt) power budgets. These demands motivate exploration of computing paradigms beyond conventional von Neumann architectures. This review surveys emerging photonic hardware optimized for next-generation generative AI computing. We discuss integrated photonic neural network architectures (e.g., Mach-Zehnder interferometer meshes, lasers, wavelength-multiplexed microring resonators) that perform ultrafast matrix operations. We also examine promising alternative neuromorphic devices, including spiking neural network circuits and hybrid spintronic-photonic synapses, which combine memory and processing. The integration of two-dimensional materials (graphene, TMDCs) into silicon photonic platforms is reviewed for tunable modulators and on-chip synaptic elements. Transformer-based LLM architectures (self-attention and feed-forward layers) are analyzed in this context, identifying strategies and challenges for mapping dynamic matrix multiplications onto these novel hardware substrates. We then dissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and LLaMA, highlighting their architectural similarities and differences. We synthesize state-of-the-art components, algorithms, and integration methods, highlighting key advances and open issues in scaling such systems to mega-sized LLM models. We find that photonic computing systems could potentially surpass electronic processors by orders of magnitude in throughput and energy efficiency, but require breakthroughs in memory, especially for long-context windows and long token sequences, and in storage of ultra-large datasets.', 'abstract_zh': '大型语言模型（LLMs）正快速推动当代计算硬件的极限。例如，训练GPT-3耗电约1300 MWh，预计未来模型可能需要城市规模（吉瓦）级别的电力预算。这些需求促使我们探索超越传统冯·诺依曼架构的计算范式。本文综述了适用于下一代生成性AI计算的新兴光电硬件。我们讨论了集成的光电神经网络架构（如Mach-Zehnder干涉仪网格、激光器、波长复用微环谐振器），它们执行超高速矩阵操作。我们还考察了有前途的类脑替代器件，包括脉冲神经网络电路和结合了存储和处理功能的自旋电子-光电突触。我们审核了将二维材料（石墨烯、过渡金属二硫属化合物）集成到硅光电平台中的可调调制器和片上突触元件。在这一背景下分析了基于变换器的LLM架构（自我注意力层和前向传播层），确定了将动态矩阵乘法映射到这些新型硬件基板上的策略和挑战。然后剖析了主流LLM的机制，如ChatGPT、DeepSeek和LLaMA，突显了它们的架构异同。我们综合了最先进的组件、算法和集成方法，突显了扩展此类系统以支持巨型LLM模型的关键进展和开放问题。我们发现，光电计算系统在吞吐量和能效方面可能比电子处理器高出几个数量级，但需要在内存方面取得突破，特别是对于长上下文窗口和长令牌序列，并需要存储超大数据集。', 'title_zh': 'LLMs的下一步将是新一代基于光子芯片的AI计算硬件。'}
{'arxiv_id': 'arXiv:2505.05756', 'title': 'Evolutionary thoughts: integration of large language models and evolutionary algorithms', 'authors': 'Antonio Jimeno Yepes, Pieter Barnard', 'link': 'https://arxiv.org/abs/2505.05756', 'abstract': 'Large Language Models (LLMs) have unveiled remarkable capabilities in understanding and generating both natural language and code, but LLM reasoning is prone to hallucination and struggle with complex, novel scenarios, often getting stuck on partial or incorrect solutions. However, the inherent ability of Evolutionary Algorithms (EAs) to explore extensive and complex search spaces makes them particularly effective in scenarios where traditional optimization methodologies may falter. However, EAs explore a vast search space when applied to complex problems.\nTo address the computational bottleneck of evaluating large populations, particularly crucial for complex evolutionary tasks, we introduce a highly efficient evaluation framework. This implementation maintains compatibility with existing primitive definitions, ensuring the generation of valid individuals.\nUsing LLMs, we propose an enhanced evolutionary search strategy that enables a more focused exploration of expansive solution spaces. LLMs facilitate the generation of superior candidate solutions, as evidenced by empirical results demonstrating their efficacy in producing improved outcomes.', 'abstract_zh': '大型语言模型（LLMs）在理解和生成自然语言和代码方面展现了非凡的能力，但在处理复杂和新颖的情景时，其推理容易产生幻觉并常常陷入部分或不正确的解决方案。然而，进化算法（EAs）固有的能力使其能够在传统优化方法可能失效的情景中特别有效。但是，当应用于复杂问题时，EAs会探索一个广阔的搜索空间。为了应对评估大量个体的计算瓶颈，特别是在复杂的进化任务中尤为重要，我们提出了一种高效的家庭评估框架。该实现保持了与现有基本定义的兼容性，确保生成有效的个体。利用LLMs，我们提出了一种增强的进化搜索策略，能够更集中地探索广泛的解空间。实验结果证明了其生成改进结果的有效性。', 'title_zh': '演化思想：大型语言模型与演化算法的集成'}
{'arxiv_id': 'arXiv:2505.05704', 'title': 'Assessing Robustness to Spurious Correlations in Post-Training Language Models', 'authors': 'Julia Shuieh, Prasann Singhal, Apaar Shanker, John Heyer, George Pu, Samuel Denton', 'link': 'https://arxiv.org/abs/2505.05704', 'abstract': 'Supervised and preference-based fine-tuning techniques have become popular for aligning large language models (LLMs) with user intent and correctness criteria. However, real-world training data often exhibits spurious correlations -- arising from biases, dataset artifacts, or other "shortcut" features -- that can compromise a model\'s performance or generalization. In this paper, we systematically evaluate three post-training algorithms -- Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO (Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and spuriousness conditions. Our tasks span mathematical reasoning, constrained instruction-following, and document-grounded question answering. We vary the degree of spurious correlation (10% vs. 90%) and investigate two forms of artifacts: "Feature Ambiguity" and "Distributional Narrowness." Our results show that the models often but not always degrade under higher spuriousness. The preference-based methods (DPO/KTO) can demonstrate relative robustness in mathematical reasoning tasks. By contrast, SFT maintains stronger performance in complex, context-intensive tasks. These findings highlight that no single post-training strategy universally outperforms in all scenarios; the best choice depends on the type of target task and the nature of spurious correlations.', 'abstract_zh': '监督和偏好导向的微调技术已成为将大规模语言模型与用户意图和正确性标准对齐的流行方法。然而，实际的训练数据中往往存在虚假相关性——这些虚假相关性来源于偏差、数据集特征或其他“捷径”特征——这可能损害模型的性能或泛化能力。在本文中，我们系统性地评估了三种后训练算法——监督微调（SFT）、直接偏好优化（DPO）和KTO（凯汉曼-特维斯基优化）——在多种合成任务和虚假相关性条件下的表现。我们的任务涵盖了数学推理、受约束的指令遵循以及文档导向的问题回答。我们改变了虚假相关性的程度（10% vs. 90%）并探讨了两种形式的数据集特征：特征歧义性和分布狭窄性。结果显示，模型在较高的虚假相关性下表现通常但不总是较差。偏好导向的方法（DPO/KTO）在数学推理任务中展现出相对较高的鲁棒性。相比之下，监督微调（SFT）在复杂、上下文密集型任务中保持更强的表现。这些发现表明，并没有一种后训练策略在所有场景中都能普遍表现更优；最佳选择取决于目标任务的类型和虚假相关性的性质。', 'title_zh': '评估后训练语言模型对虚假相关性的鲁棒性'}
{'arxiv_id': 'arXiv:2505.05523', 'title': 'GenAI in Entrepreneurship: a systematic review of generative artificial intelligence in entrepreneurship research: current issues and future directions', 'authors': 'Anna Kusetogullari, Huseyin Kusetogullari, Martin Andersson, Tony Gorschek', 'link': 'https://arxiv.org/abs/2505.05523', 'abstract': 'Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are recognized to have significant effects on industry and business dynamics, not least because of their impact on the preconditions for entrepreneurship. There is still a lack of knowledge of GenAI as a theme in entrepreneurship research. This paper presents a systematic literature review aimed at identifying and analyzing the evolving landscape of research on the effects of GenAI on entrepreneurship. We analyze 83 peer-reviewed articles obtained from leading academic databases: Web of Science and Scopus. Using natural language processing and unsupervised machine learning techniques with TF-IDF vectorization, Principal Component Analysis (PCA), and hierarchical clustering, five major thematic clusters are identified: (1) Digital Transformation and Behavioral Models, (2) GenAI-Enhanced Education and Learning Systems, (3) Sustainable Innovation and Strategic AI Impact, (4) Business Models and Market Trends, and (5) Data-Driven Technological Trends in Entrepreneurship. Based on the review, we discuss future research directions, gaps in the current literature, as well as ethical concerns raised in the literature. We highlight the need for more macro-level research on GenAI and LLMs as external enablers for entrepreneurship and for research on effective regulatory frameworks that facilitate business experimentation, innovation, and further technology development.', 'abstract_zh': '生成式人工智能（GenAI）和大型语言模型（LLMs）对行业和商业动态产生了显著影响，尤其是在创业的先决条件方面。尽管如此，关于GenAI作为创业研究主题的现有知识仍然不足。本文提出了一项系统性文献综述，旨在识别和分析GenAI对创业影响的研究景观演变。我们分析了来自Web of Science和Scopus等领先学术数据库的83篇同行评审文章。通过使用自然语言处理和无监督机器学习技术，结合TF-IDF向量化、主成分分析（PCA）和层次聚类，我们识别出五大主题集群：（1）数字化转型与行为模型，（2）GenAI增强的教育和学习系统，（3）可持续创新和战略AI影响，（4）商业模式和市场趋势，（5）创业中的数据驱动技术趋势。基于综述，我们讨论了未来研究方向、当前文献中的知识空白以及文献中提出的伦理问题。我们强调了需要更多关于GenAI和LLMs作为外在促进因素的宏观层面研究，以及研究有助于业务试验、创新和技术发展的有效监管框架的必要性。', 'title_zh': 'GenAI在创业中的应用：生成式人工智能在创业研究中的系统回顾：现有问题与未来方向'}
{'arxiv_id': 'arXiv:2505.05501', 'title': 'Preliminary Explorations with GPT-4o(mni) Native Image Generation', 'authors': 'Pu Cao, Feng Zhou, Junyi Ji, Qingye Kong, Zhixiang Lv, Mingjian Zhang, Xuekun Zhao, Siqi Wu, Yinghui Lin, Qing Song, Lu Yang', 'link': 'https://arxiv.org/abs/2505.05501', 'abstract': "Recently, the visual generation ability by GPT-4o(mni) has been unlocked by OpenAI. It demonstrates a very remarkable generation capability with excellent multimodal condition understanding and varied task instructions. In this paper, we aim to explore the capabilities of GPT-4o across various tasks. Inspired by previous study, we constructed a task taxonomy along with a carefully curated set of test samples to conduct a comprehensive qualitative test. Benefiting from GPT-4o's powerful multimodal comprehension, its image-generation process demonstrates abilities surpassing those of traditional image-generation tasks. Thus, regarding the dimensions of model capabilities, we evaluate its performance across six task categories: traditional image generation tasks, discriminative tasks, knowledge-based generation, commonsense-based generation, spatially-aware image generation, and temporally-aware image generation. These tasks not only assess the quality and conditional alignment of the model's outputs but also probe deeper into GPT-4o's understanding of real-world concepts. Our results reveal that GPT-4o performs impressively well in general-purpose synthesis tasks, showing strong capabilities in text-to-image generation, visual stylization, and low-level image processing. However, significant limitations remain in its ability to perform precise spatial reasoning, instruction-grounded generation, and consistent temporal prediction. Furthermore, when faced with knowledge-intensive or domain-specific scenarios, such as scientific illustrations or mathematical plots, the model often exhibits hallucinations, factual errors, or structural inconsistencies. These findings suggest that while GPT-4o marks a substantial advancement in unified multimodal generation, there is still a long way to go before it can be reliably applied to professional or safety-critical domains.", 'abstract_zh': 'GPT-4o在各种任务中的生成能力探索：从传统图像生成到时空感知生成', 'title_zh': '最初探究：GPT-4o(mni)原生图像生成'}
{'arxiv_id': 'arXiv:2505.05494', 'title': 'An Automated LLM-based Pipeline for Asset-Level Database Creation to Assess Deforestation Impact', 'authors': 'Avanija Menon, Ovidiu Serban', 'link': 'https://arxiv.org/abs/2505.05494', 'abstract': 'The European Union Deforestation Regulation (EUDR) requires companies to prove their products do not contribute to deforestation, creating a critical demand for precise, asset-level environmental impact data. Current databases lack the necessary detail, relying heavily on broad financial metrics and manual data collection, which limits regulatory compliance and accurate environmental modeling. This study presents an automated, end-to-end data extraction pipeline that uses LLMs to create, clean, and validate structured databases, specifically targeting sectors with a high risk of deforestation. The pipeline introduces Instructional, Role-Based, Zero-Shot Chain-of-Thought (IRZ-CoT) prompting to enhance data extraction accuracy and a Retrieval-Augmented Validation (RAV) process that integrates real-time web searches for improved data reliability. Applied to SEC EDGAR filings in the Mining, Oil & Gas, and Utilities sectors, the pipeline demonstrates significant improvements over traditional zero-shot prompting approaches, particularly in extraction accuracy and validation coverage. This work advances NLP-driven automation for regulatory compliance, CSR (Corporate Social Responsibility), and ESG, with broad sectoral applicability.', 'abstract_zh': '欧洲联盟毁林法规（EUDR）要求企业证明其产品不会导致毁林，从而对精确的资产级别环境影响数据产生了关键性需求。当前数据库缺乏必要的细节，严重依赖于宽泛的财务指标和手动数据收集，这限制了监管合规性和准确的环境模型构建。本研究提出了一种自动化、端到端的数据提取管道，利用大语言模型（LLMs）创建、清洁和验证结构化数据库，特别针对毁林风险高的行业。该管道引入了指令、角色基于、零样本推理链（IRZ-CoT）提示以提高数据提取准确性，并结合了检索增强验证（RAV）流程，通过实时网络搜索提高数据可靠性。在矿业、石油与天然气及公用事业行业的SEC EDGAR申报文件中应用该管道，表现出显著优于传统零样本提示方法的改进，尤其是在提取准确性和验证覆盖面方面。这项工作推进了基于NLP的自动化在监管合规、企业社会责任（CSR）和ESG领域的应用，具有广泛的行业适用性。', 'title_zh': '基于LLM的自动资产级数据库创建流水线以评估森林砍伐影响'}
