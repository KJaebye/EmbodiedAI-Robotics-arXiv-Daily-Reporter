{'arxiv_id': 'arXiv:2507.13088', 'title': 'ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning', 'authors': 'Rahel Rickenbach, Alan A. Lahoud, Erik Schaffernicht, Melanie N. Zeilinger, Johannes A. Stork', 'link': 'https://arxiv.org/abs/2507.13088', 'abstract': 'The computational burden of model predictive control (MPC) limits its application on real-time systems, such as robots, and often requires the use of short prediction horizons. This not only affects the control performance, but also increases the difficulty of designing MPC cost functions that reflect the desired long-term objective. This paper proposes ZipMPC, a method that imitates a long-horizon MPC behaviour by learning a compressed and context-dependent cost function for a short-horizon MPC. It improves performance over alternative methods, such as approximate explicit MPC and automatic cost parameter tuning, in particular in terms of i) optimizing the long term objective; ii) maintaining computational costs comparable to a short-horizon MPC; iii) ensuring constraint satisfaction; and iv) generalizing control behaviour to environments not observed during training. For this purpose, ZipMPC leverages the concept of differentiable MPC with neural networks to propagate gradients of the imitation loss through the MPC optimization. We validate our proposed method in simulation and real-world experiments on autonomous racing. ZipMPC consistently completes laps faster than selected baselines, achieving lap times close to the long-horizon MPC baseline. In challenging scenarios where the short-horizon MPC baseline fails to complete a lap, ZipMPC is able to do so. In particular, these performance gains are also observed on tracks unseen during training.', 'abstract_zh': '基于压缩成本函数的ZipMPC：一种模仿长期优化行为的模型预测控制方法', 'title_zh': 'ZipMPC: 压缩依赖上下文的MPC成本通过模仿学习'}
{'arxiv_id': 'arXiv:2507.13041', 'title': 'What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics', 'authors': 'Julien Wacquez, Elisabetta Zibetti, Joffrey Becker, Lorenzo Aloe, Fabio Amadio, Salvatore Anzalone, Lola Cañamero, Serena Ivaldi', 'link': 'https://arxiv.org/abs/2507.13041', 'abstract': 'As robots find their way into more and more aspects of everyday life, questions around trust are becoming increasingly important. What does it mean to trust a robot? And how should we think about trust in relationships that involve both humans and non-human agents? While the field of Human-Robot Interaction (HRI) has made trust a central topic, the concept is often approached in fragmented ways. At the same time, established work in sociology, where trust has long been a key theme, is rarely brought into conversation with developments in robotics. This article argues that we need a more interdisciplinary approach. By drawing on insights from both social sciences and social robotics, we explore how trust is shaped, tested and made visible. Our goal is to open up a dialogue between disciplines and help build a more grounded and adaptable framework for understanding trust in the evolving world of human-robot interaction.', 'abstract_zh': '随着机器人在日常生活的方方面面找到自己的位置，信任相关的问题变得越来越重要。我们如何定义对机器人的信任？在涉及人类和非人类代理的关系中，我们又应该如何思考信任？尽管人机交互（HRI）领域已经将信任作为核心议题，该概念经常以零散的方式进行探讨。同时，社会学领域中关于信任长期以来的主要主题，与机器人技术的发展鲜有交集。本文主张我们需要采取一种更加跨学科的方法。通过结合社会科学和社会机器人学的洞见，我们探讨信任如何被塑造、测试和展现。我们的目标是促进不同学科之间的对话，并帮助构建一个更加坚实且灵活的框架，以理解不断演变的人机交互中的信任。', 'title_zh': '机器人能教给我们关于信任和依赖的什么？社会科学与社会机器人学的跨学科对话'}
{'arxiv_id': 'arXiv:2507.12920', 'title': 'MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion', 'authors': 'Zichao Shu, Shitao Bei, Jicheng Dai, Lijun Li, Zetao Chen', 'link': 'https://arxiv.org/abs/2507.12920', 'abstract': 'Marker-based optical motion capture (MoCap) systems are widely used to provide ground truth (GT) trajectories for benchmarking SLAM algorithms. However, the accuracy of MoCap-based GT trajectories is mainly affected by two factors: spatiotemporal calibration errors between the MoCap system and the device under test (DUT), and inherent MoCap jitter. Consequently, existing benchmarks focus primarily on absolute translation error, as accurate assessment of rotation and inter-frame errors remains challenging, hindering thorough SLAM evaluation. This paper proposes MoCap2GT, a joint optimization approach that integrates MoCap data and inertial measurement unit (IMU) measurements from the DUT for generating high-precision GT trajectories. MoCap2GT includes a robust state initializer to ensure global convergence, introduces a higher-order B-spline pose parameterization on the SE(3) manifold with variable time offset to effectively model MoCap factors, and employs a degeneracy-aware measurement rejection strategy to enhance estimation accuracy. Experimental results demonstrate that MoCap2GT outperforms existing methods and significantly contributes to precise SLAM benchmarking. The source code is available at this https URL (temporarily hosted anonymously for double-blind review).', 'abstract_zh': '基于标记的光学动作捕捉(MoCap)系统广泛用于提供地面 truth (GT) 轨迹以评估SLAM算法。然而，MoCap-based GT 轨迹的准确性主要受两方面因素影响：MoCap系统与待测设备(DUT)之间的时空校准误差以及动作捕捉固有的抖动。因此，现有基准主要关注绝对平移误差，而准确评估旋转误差和帧间误差仍然具有挑战性，阻碍了SLAM算法的全面评估。本文提出MoCap2GT，这是一种结合MoCap数据和DUT的惯性测量单元(IMU)测量的联合优化方法，用于生成高精度GT轨迹。MoCap2GT包括一个稳健的状态初始化器以确保全局收敛，引入了SE(3)流形上的具有可变时间偏移的高阶B样条姿态参数化以有效建模MoCap因子，并采用了退化感知测量拒绝策略以提高估计精度。实验结果表明，MoCap2GT优于现有方法，并显著促进了精确的SLAM基准测试。源代码可在此链接访问（暂时匿名托管以供双盲评审）。', 'title_zh': 'MoCap2GT：基于运动捕捉和IMU融合的高精度地面truth估计器用于SLAM基准测试'}
{'arxiv_id': 'arXiv:2507.12489', 'title': 'Physically Based Neural LiDAR Resimulation', 'authors': 'Richard Marcus, Marc Stamminger', 'link': 'https://arxiv.org/abs/2507.12489', 'abstract': 'Methods for Novel View Synthesis (NVS) have recently found traction in the field of LiDAR simulation and large-scale 3D scene reconstruction. While solutions for faster rendering or handling dynamic scenes have been proposed, LiDAR specific effects remain insufficiently addressed. By explicitly modeling sensor characteristics such as rolling shutter, laser power variations, and intensity falloff, our method achieves more accurate LiDAR simulation compared to existing techniques. We demonstrate the effectiveness of our approach through quantitative and qualitative comparisons with state-of-the-art methods, as well as ablation studies that highlight the importance of each sensor model component. Beyond that, we show that our approach exhibits advanced resimulation capabilities, such as generating high resolution LiDAR scans in the camera perspective.\nOur code and the resulting dataset are available at this https URL.', 'abstract_zh': 'LiDAR特定效果的新型视图synthesize方法在LiDAR模拟和大规模3D场景重建中的应用', 'title_zh': '基于物理的神经LiDAR仿真'}
{'arxiv_id': 'arXiv:2507.13017', 'title': 'CubeSat Orbit Insertion Maneuvering Using J2 Perturbation', 'authors': 'M. Amin Alandihallaj, M. Reza Emami', 'link': 'https://arxiv.org/abs/2507.13017', 'abstract': "The precise insertion of CubeSats into designated orbits is a complex task, primarily due to the limited propulsion capabilities and constrained fuel reserves onboard, which severely restrict the scope for large orbital corrections. This limitation necessitates the development of more efficient maneuvering techniques to ensure mission success. In this paper, we propose a maneuvering sequence that exploits the natural J2 perturbation caused by the Earth's oblateness. By utilizing the secular effects of this perturbation, it is possible to passively influence key orbital parameters such as the argument of perigee and the right ascension of the ascending node, thereby reducing the need for extensive propulsion-based corrections. The approach is designed to optimize the CubeSat's orbital insertion and minimize the total fuel required for trajectory adjustments, making it particularly suitable for fuel-constrained missions. The proposed methodology is validated through comprehensive numerical simulations that examine different initial orbital conditions and perturbation environments. Case studies are presented to demonstrate the effectiveness of the J2-augmented strategy in achieving accurate orbital insertion, showing a major reduction in fuel consumption compared to traditional methods. The results underscore the potential of this approach to extend the operational life and capabilities of CubeSats, offering a viable solution for future low-Earth orbit missions.", 'abstract_zh': 'CubeSats入轨到指定轨道的精确姿态设计：基于地球扁球性自然扰动的高效机动策略', 'title_zh': 'CubeSat 轨道插入 maneuvers 利用 J2 扰动'}
{'arxiv_id': 'arXiv:2507.12578', 'title': 'Deep Bilinear Koopman Model for Real-Time Vehicle Control in Frenet Frame', 'authors': 'Mohammad Abtahi, Farhang Motallebi Araghi, Navid Mojahed, Shima Nazari', 'link': 'https://arxiv.org/abs/2507.12578', 'abstract': 'Accurate modeling and control of autonomous vehicles remain a fundamental challenge due to the nonlinear and coupled nature of vehicle dynamics. While Koopman operator theory offers a framework for deploying powerful linear control techniques, learning a finite-dimensional invariant subspace for high-fidelity modeling continues to be an open problem. This paper presents a deep Koopman approach for modeling and control of vehicle dynamics within the curvilinear Frenet frame. The proposed framework uses a deep neural network architecture to simultaneously learn the Koopman operator and its associated invariant subspace from the data. Input-state bilinear interactions are captured by the algorithm while preserving convexity, which makes it suitable for real-time model predictive control (MPC) application. A multi-step prediction loss is utilized during training to ensure long-horizon prediction capability. To further enhance real-time trajectory tracking performance, the model is integrated with a cumulative error regulator (CER) module, which compensates for model mismatch by mitigating accumulated prediction errors. Closed-loop performance is evaluated through hardware-in-the-loop (HIL) experiments using a CarSim RT model as the target plant, with real-time validation conducted on a dSPACE SCALEXIO system. The proposed controller achieved significant reductions in tracking error relative to baseline controllers, confirming its suitability for real-time implementation in embedded autonomous vehicle systems.', 'abstract_zh': '基于曲率Frenet框架的深度Koopman方法在自主车辆动力学建模与控制中的应用', 'title_zh': '基于Frenet坐标系的深度双线性Koopman模型用于实时车辆控制'}
{'arxiv_id': 'arXiv:2507.12494', 'title': 'MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents', 'authors': "Dustin Holley, Jovin D'sa, Hossein Nourkhiz Mahjoub, Gibran Ali", 'link': 'https://arxiv.org/abs/2507.12494', 'abstract': 'Enhancing simulation environments to replicate real-world driver behavior, i.e., more humanlike sim agents, is essential for developing autonomous vehicle technology. In the context of highway merging, previous works have studied the operational-level yielding dynamics of lag vehicles in response to a merging car at highway on-ramps. Other works focusing on tactical decision modeling generally consider limited action sets or utilize payoff functions with large parameter sets and limited payoff bounds. In this work, we aim to improve the simulation of the highway merge scenario by targeting a game theoretic model for tactical decision-making with improved payoff functions and lag actions. We couple this with an underlying dynamics model to have a unified decision and dynamics model that can capture merging interactions and simulate more realistic interactions in an explainable and interpretable fashion. The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset. The model was finally integrated into a high fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.', 'abstract_zh': '提升模拟环境以更真实地复制实际驾驶行为，即更具人类特征的模拟代理，对于开发自动驾驶车辆技术至关重要。在高速公路并线的背景下，以往的研究已经研究了滞后车辆在面对高速公路匝道并线车辆时的运作级让行动态。其他专注于战术决策建模的工作通常考虑有限的动作集或使用具有大量参数集和有限回报范围的支付函数。在本项研究中，我们旨在通过采用改进的支付函数和滞后动作来提高对高速公路并线场景的模拟，并针对战术决策制定游戏理论模型。我们将这一模型与动态模型耦合，形成一个统一的决策和动力学模型，能够捕捉并模拟更真实且可解释的并线交互。所提出的模型在实际数据集上验证时显示出良好的复现复杂交互的能力。该模型最终集成到了高保真度模拟环境中，并确认其具有足够的计算时间效率，适用于大规模模拟以支持自动驾驶车辆技术的发展。', 'title_zh': 'MR-LDM -- 合并反应纵向决策模型：基于博弈论的人类决策建模用于交互式Sim代理'}
{'arxiv_id': 'arXiv:2507.13337', 'title': 'FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming', 'authors': 'Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekharya, Yoav Levine, Shai Shalev-Shwartz, Amnon Shashua', 'link': 'https://arxiv.org/abs/2507.13337', 'abstract': "Frontier AI models demonstrate formidable breadth of knowledge. But how close are they to true human -- or superhuman -- expertise? Genuine experts can tackle the hardest problems and push the boundaries of scientific understanding. To illuminate the limits of frontier model capabilities, we turn away from contrived competitive programming puzzles, and instead focus on real-life research problems.\nWe construct FormulaOne, a benchmark that lies at the intersection of graph theory, logic, and algorithms, all well within the training distribution of frontier models. Our problems are incredibly demanding, requiring an array of reasoning steps. The dataset has three key properties. First, it is of commercial interest and relates to practical large-scale optimisation problems, such as those arising in routing, scheduling, and network design. Second, it is generated from the highly expressive framework of Monadic Second-Order (MSO) logic on graphs, paving the way toward automatic problem generation at scale; ideal for building RL environments. Third, many of our problems are intimately related to the frontier of theoretical computer science, and to central conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As such, any significant algorithmic progress on our dataset, beyond known results, could carry profound theoretical implications.\nRemarkably, state-of-the-art models like OpenAI's o3 fail entirely on FormulaOne, solving less than 1% of the questions, even when given 10 attempts and explanatory fewshot examples -- highlighting how far they remain from expert-level understanding in some domains. To support further research, we additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from the same distribution. We release the full corpus along with a comprehensive evaluation framework.", 'abstract_zh': '前沿AI模型展示了广泛的知识面。但它们与真正的超人类专业知识有多接近呢？真正的专家能够解决最难的问题，推动科学理解的边界。为了阐明前沿模型能力的局限性，我们不再依赖于构造的编程 puzzles，而是专注于现实中的研究问题。', 'title_zh': 'FormulaOne: 评估算法推理深度超越 Competitive Programming 的方法'}
{'arxiv_id': 'arXiv:2507.13208', 'title': 'Higher-Order Pattern Unification Modulo Similarity Relations', 'authors': 'Besik Dundua, Temur Kutsia', 'link': 'https://arxiv.org/abs/2507.13208', 'abstract': 'The combination of higher-order theories and fuzzy logic can be useful in decision-making tasks that involve reasoning across abstract functions and predicates, where exact matches are often rare or unnecessary. Developing efficient reasoning and computational techniques for such a combined formalism presents a significant challenge. In this paper, we adopt a more straightforward approach aiming at integrating two well-established and computationally well-behaved components: higher-order patterns on one side and fuzzy equivalences expressed through similarity relations based on minimum T-norm on the other. We propose a unification algorithm for higher-order patterns modulo these similarity relations and prove its termination, soundness, and completeness. This unification problem, like its crisp counterpart, is unitary. The algorithm computes a most general unifier with the highest degree of approximation when the given terms are unifiable.', 'abstract_zh': '高阶理论与模糊逻辑的结合在涉及抽象函数和谓词的推理任务中可能非常有用，其中精确匹配往往很少见或不必要的。本论文采用一种更直接的方法，旨在整合两种既已建立且计算性能良好的组件：一方是高阶模式，另一方是基于最小T-诺姆相似关系表达的模糊等价性。我们提出了一种关于这些相似关系的高阶模式统计算法，并证明了其终止性、 soundness 和完备性。这一统计算法类似于其经典的对应物，是统一问题的单一形式。当给定项可统一时，该算法计算出最具一般性的统一，并提供最高的近似程度。', 'title_zh': '高阶模式统⼀模相似关系'}
{'arxiv_id': 'arXiv:2507.13112', 'title': 'Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data', 'authors': 'Junseong Lee, Jaegwan Cho, Yoonju Cho, Seoyoon Choi, Yejin Shin', 'link': 'https://arxiv.org/abs/2507.13112', 'abstract': 'The study "Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data" presents a machine learning-based traffic flow prediction model to address global traffic congestion issues. The research utilized 30-second interval traffic data from California Highway 78 over a five-month period from July to November 2022, analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino Real" in the San Diego area. The study employed Multiple Linear Regression (MLR) and Random Forest (RF) algorithms, analyzing data collection intervals ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance metrics, the analysis revealed that both MLR and RF models performed optimally with 10-minute data collection intervals. These findings are expected to contribute to future traffic congestion solutions and efficient traffic management.', 'abstract_zh': '基于加利福尼亚交通数据的人工智能算法高速公路交通流预测研究', 'title_zh': '基于人工智能算法的加利福尼亚交通数据高速公路交通流量预测'}
{'arxiv_id': 'arXiv:2507.13007', 'title': 'Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming', 'authors': 'Roger Xavier Lera-Leri, Filippo Bistaffa, Athina Georgara, Juan Antonio Rodriguez-Aguilar', 'link': 'https://arxiv.org/abs/2507.13007', 'abstract': 'Following the recent push for trustworthy AI, there has been an increasing interest in developing contrastive explanation techniques for optimisation, especially concerning the solution of specific decision-making processes formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic approach for building contrastive explanations for MILPs based on constraint reasoning techniques. First, we show how to encode the queries a user makes about the solution of an MILP problem as additional constraints. Then, we determine the reasons that constitute the answer to the user\'s query by computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set of constraints. Finally, we represent our explanation as a "graph of reasons" constructed from the IIS, which helps the user understand the structure among the reasons that answer their query. We test our method on instances of well-known optimisation problems to evaluate the empirical hardness of computing explanations.', 'abstract_zh': '跟随最近对可信赖人工智能的推动，越来越多的研究兴趣集中在开发优化的对比解释技术，特别是关于形式化为混合整数线性规划（MILP）的具体决策过程。沿着这一思路，我们提出了X-MILP，一种基于约束推理技术的通用方法，用于为MILP构建对比解释。首先，我们展示如何将用户对MILP问题解的查询编码为额外的约束条件。然后，通过计算新获得的约束集的不可约不一致子系统（IIS），来确定构成用户查询答案的原因。最后，我们将解释表示为从IIS构建的“原因图”，这有助于用户理解回答其查询的原因之间的结构。我们对著名的优化问题实例进行测试，以评估计算解释的实际难度。', 'title_zh': '利用约束推理构建混合整数线性规划的图形解释'}
{'arxiv_id': 'arXiv:2507.12989', 'title': 'A Translation of Probabilistic Event Calculus into Markov Decision Processes', 'authors': "Lyris Xu, Fabio Aurelio D'Asaro, Luke Dickens", 'link': 'https://arxiv.org/abs/2507.12989', 'abstract': 'Probabilistic Event Calculus (PEC) is a logical framework for reasoning about actions and their effects in uncertain environments, which enables the representation of probabilistic narratives and computation of temporal projections. The PEC formalism offers significant advantages in interpretability and expressiveness for narrative reasoning. However, it lacks mechanisms for goal-directed reasoning. This paper bridges this gap by developing a formal translation of PEC domains into Markov Decision Processes (MDPs), introducing the concept of "action-taking situations" to preserve PEC\'s flexible action semantics. The resulting PEC-MDP formalism enables the extensive collection of algorithms and theoretical tools developed for MDPs to be applied to PEC\'s interpretable narrative domains. We demonstrate how the translation supports both temporal reasoning tasks and objective-driven planning, with methods for mapping learned policies back into human-readable PEC representations, maintaining interpretability while extending PEC\'s capabilities.', 'abstract_zh': '概率事件演算（PEC）是一种在不确定性环境中推理行动及其效果的逻辑框架，能够表示概率叙事并计算时间投影。PEC形式主义在叙事推理方面具有显著的可解释性和表达能力。然而，它缺乏目标导向推理的机制。本文通过将PEC领域形式化转换为马尔可夫决策过程（MDP），并引入“行动取向情况”的概念以保留PEC灵活的动作语义，填补了这一空白。由此产生的PEC-MDP形式主义使得为MDP开发的广泛算法和理论工具可以应用于PEC可解释的叙事领域。我们展示了这种转换如何支持时间推理任务和目标驱动的规划，并提供方法将学习到的策略映射回可读的PEC表示，从而保持可解释性并扩展PEC的能力。', 'title_zh': '将概率事件逻辑翻译成马尔可夫决策过程'}
{'arxiv_id': 'arXiv:2507.12872', 'title': 'Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework', 'authors': 'Rishane Dassanayake, Mario Demetroudi, James Walpole, Lindley Lentati, Jason R. Brown, Edward James Young', 'link': 'https://arxiv.org/abs/2507.12872', 'abstract': 'Frontier AI systems are rapidly advancing in their capabilities to persuade, deceive, and influence human behaviour, with current models already demonstrating human-level persuasion and strategic deception in specific contexts. Humans are often the weakest link in cybersecurity systems, and a misaligned AI system deployed internally within a frontier company may seek to undermine human oversight by manipulating employees. Despite this growing threat, manipulation attacks have received little attention, and no systematic framework exists for assessing and mitigating these risks. To address this, we provide a detailed explanation of why manipulation attacks are a significant threat and could lead to catastrophic outcomes. Additionally, we present a safety case framework for manipulation risk, structured around three core lines of argument: inability, control, and trustworthiness. For each argument, we specify evidence requirements, evaluation methodologies, and implementation considerations for direct application by AI companies. This paper provides the first systematic methodology for integrating manipulation risk into AI safety governance, offering AI companies a concrete foundation to assess and mitigate these threats before deployment.', 'abstract_zh': '前沿AI系统在说服、欺骗和影响人类行为的能力上飞速发展，目前的模型已经在特定情境下展示了与人类水平相当的说服力和策略性欺骗。人类往往是网络安全系统中最薄弱的环节，如果一个在前沿公司内部部署且目标与其目标不符的AI系统存在，它可能会通过操纵员工来削弱人类的监督。尽管存在这一日益严重的威胁，但操纵攻击并未受到足够的关注，也没有现成的框架来评估和缓解这些风险。为应对这一挑战，我们详细解释了为什么操纵攻击是一个重大威胁，并可能导致灾难性后果。此外，我们提出了一个围绕三个核心论点构建的安全案例框架来评估操纵风险：不可行性、控制性和可信度。对于每个论点，我们指明了证据要求、评估方法和实施考虑，以便AI公司可以直接应用。本文首次提供了将操纵风险系统性地整合到AI安全治理中的方法论，为AI公司提供了评估和减轻这些威胁的实际基础，从而在部署前采取行动。', 'title_zh': '错准AI的操纵攻击：风险分析与安全案例框架'}
{'arxiv_id': 'arXiv:2507.12862', 'title': 'Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command', 'authors': 'Hussein Abbass, Taylan Akay, Harrison Tolley', 'link': 'https://arxiv.org/abs/2507.12862', 'abstract': "In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.", 'abstract_zh': '在人工智能时代，人类指挥官需要利用当今环境中的计算能力模拟大量场景。在每个场景中，不同的决策设计选项可能会产生伦理后果。依赖人类判断做出这些决策既不利于迅速探索大量场景的目标，也不切实际，因为需要大量的工作量将人类涉及每个选择中。本文将人类判断移出模拟决策循环。基本来说，人类将设计伦理度量空间，让模拟环境去探索这一空间。当模拟完成测试循环后，测试环境将返回给人类指挥官一些选项供其选择。然后，人类指挥官将运用人类判断来选择最合适的行动方案，该方案将被相应执行。我们假设设计出足够精细的指标以评估决策的伦理影响的问题已经解决。在此之后，本文关注的基本问题是在运行这些模拟时如何加权伦理决策；即，在生成式模拟过程中，当代理面临有伦理影响的决策选项时，如何动态加权伦理属性。多准则决策制定文献已经开始研究相关问题，其中熵的概念被用于聚合过程中的权重确定。我们从这一文献中借鉴了不同的方法来自动计算模拟测试与评估过程中伦理属性的权重。', 'title_zh': '基于信息论的伦理属性模拟指挥中综合研究'}
{'arxiv_id': 'arXiv:2507.12691', 'title': 'Benchmarking Deception Probes via Black-to-White Performance Boosts', 'authors': 'Avi Parrack, Carlo Leonardo Attubato, Stefan Heimersheim', 'link': 'https://arxiv.org/abs/2507.12691', 'abstract': 'AI assistants will occasionally respond deceptively to user queries. Recently, linear classifiers (called "deception probes") have been trained to distinguish the internal activations of a language model during deceptive versus honest responses. However, it\'s unclear how effective these probes are at detecting deception in practice, nor whether such probes are resistant to simple counter strategies from a deceptive assistant who wishes to evade detection. In this paper, we compare white-box monitoring (where the monitor has access to token-level probe activations) to black-box monitoring (without such access). We benchmark deception probes by the extent to which the white box monitor outperforms the black-box monitor, i.e. the black-to-white performance boost. We find weak but encouraging black-to-white performance boosts from existing deception probes.', 'abstract_zh': 'AI助手偶尔会对用户查询作出欺骗性响应。现有研究表明，线性分类器（称为“欺骗探针”）可用于区分语言模型在欺骗性响应和诚实性响应期间的内部激活。然而，这些探针在实际中检测欺骗的效果尚不明确，且不清楚它们能否抵御希望逃避检测的欺骗性助手的简单反制策略。本文比较了白盒监测（监控方可以访问探针激活的标记级别信息）与黑盒监测（缺乏此类访问）。我们通过白盒监控相对于黑盒监控的优势程度来基准测试欺骗探针，即黑盒到白盒的性能提升。我们发现现有欺骗探针的黑盒到白盒的性能提升较弱但值得鼓励。', 'title_zh': '通过黑盒子到白盒子性能提升 Benchmarking �视力探方法'}
{'arxiv_id': 'arXiv:2507.12599', 'title': 'A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs', 'authors': 'Léo Saulières', 'link': 'https://arxiv.org/abs/2507.12599', 'abstract': 'The success of recent Artificial Intelligence (AI) models has been accompanied by the opacity of their internal mechanisms, due notably to the use of deep neural networks. In order to understand these internal mechanisms and explain the output of these AI models, a set of methods have been proposed, grouped under the domain of eXplainable AI (XAI). This paper focuses on a sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims to explain the actions of an agent that has learned by reinforcement learning. We propose an intuitive taxonomy based on two questions "What" and "How". The first question focuses on the target that the method explains, while the second relates to the way the explanation is provided. We use this taxonomy to provide a state-of-the-art review of over 250 papers. In addition, we present a set of domains close to XRL, which we believe should get attention from the community. Finally, we identify some needs for the field of XRL.', 'abstract_zh': '最近的人工智能模型的成功伴随着其内部机制的不透明性，特别是在使用深度神经网络的情况下。为了理解这些内部机制并解释这些人工智能模型的输出，提出了一套方法，这些方法归属于可解释人工智能（XAI）领域。本文聚焦于XAI的一个子领域——可解释强化学习（XRL），旨在解释通过强化学习学到行为的智能体的行为。我们提出了一种基于两个问题“什么”和“如何”的直观分类法。第一个问题关注方法解释的目标，第二个问题则关系到解释的提供方式。我们使用这种分类法对超过250篇文献提供了综述。此外，我们提出了与XRL紧密相关的几个领域，认为这些领域应引起社区的关注。最后，我们指出了XRL领域的一些需求。', 'title_zh': '可解释强化学习综述：目标、方法与需求'}
{'arxiv_id': 'arXiv:2507.13345', 'title': 'Imbalance in Balance: Online Concept Balancing in Generation Models', 'authors': 'Yukai Shi, Jiarong Ou, Rui Chen, Haotian Yang, Jiahao Wang, Xin Tao, Pengfei Wan, Di Zhang, Kun Gai', 'link': 'https://arxiv.org/abs/2507.13345', 'abstract': 'In visual generation tasks, the responses and combinations of complex concepts often lack stability and are error-prone, which remains an under-explored area. In this paper, we attempt to explore the causal factors for poor concept responses through elaborately designed experiments. We also design a concept-wise equalization loss function (IMBA loss) to address this issue. Our proposed method is online, eliminating the need for offline dataset processing, and requires minimal code changes. In our newly proposed complex concept benchmark Inert-CompBench and two other public test sets, our method significantly enhances the concept response capability of baseline models and yields highly competitive results with only a few codes.', 'abstract_zh': '在视觉生成任务中，复杂概念的响应和组合往往缺乏稳定性和可靠性，这是一个未充分探索的领域。本文通过精心设计的实验尝试探究较差概念响应的原因，并设计了一种概念层面的均衡损失函数（IMBA损失）来解决这一问题。我们提出的方法是在线的，无需离线处理数据集，并且只需要少量的代码修改。在我们 newly 提出的复杂概念基准 Inert-CompBench 和两个其他公开测试集上，我们的方法显著提升了基线模型的概念响应能力，并仅用少量代码获得了极具竞争力的结果。', 'title_zh': '平衡中的不平衡：生成模型中的在线概念平衡'}
{'arxiv_id': 'arXiv:2507.13264', 'title': 'Voxtral', 'authors': 'Alexander H. Liu, Andy Ehrenberg, Andy Lo, Clément Denoix, Corentin Barreau, Guillaume Lample, Jean-Malo Delignon, Khyathi Raghavi Chandu, Patrick von Platen, Pavankumar Reddy Muddireddy, Sanchit Gandhi, Soham Ghosh, Srijan Mishra, Thomas Foubert, Abhinav Rastogi, Adam Yang, Albert Q. Jiang, Alexandre Sablayrolles, Amélie Héliou, Amélie Martin, Anmol Agarwal, Antoine Roux, Arthur Darcet, Arthur Mensch, Baptiste Bout, Baptiste Rozière, Baudouin De Monicault, Chris Bamford, Christian Wallenwein, Christophe Renaudin, Clémence Lanfranchi, Darius Dabert, Devendra Singh Chaplot, Devon Mizelle, Diego de las Casas, Elliot Chane-Sane, Emilien Fugier, Emma Bou Hanna, Gabrielle Berrada, Gauthier Delerce, Gauthier Guinet, Georgii Novikov, Guillaume Martin, Himanshu Jaju, Jan Ludziejewski, Jason Rute, Jean-Hadrien Chabran, Jessica Chudnovsky, Joachim Studnia, Joep Barmentlo, Jonas Amar, Josselin Somerville Roberts, Julien Denize, Karan Saxena, Karmesh Yadav, Kartik Khandelwal, Kush Jain, Lélio Renard Lavaud, Léonard Blier, Lingxiao Zhao, Louis Martin, Lucile Saulnier, Luyu Gao, Marie Pellat, Mathilde Guillaumin, Mathis Felardos, Matthieu Dinot, Maxime Darrin, Maximilian Augustin, Mickaël Seznec, Neha Gupta, Nikhil Raghuraman, Olivier Duchenne, Patricia Wang, Patryk Saffer, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Philomène Chagniot, Pierre Stock, Pravesh Agrawal, Rémi Delacourt, Romain Sauvestre, Roman Soletskyi, Sagar Vaze, Sandeep Subramanian, Saurabh Garg, Shashwat Dalal, Siddharth Gandhi, Sumukh Aithal, Szymon Antoniak, Teven Le Scao, Thibault Schueller, Thibaut Lavril, Thomas Robert, Thomas Wang, Timothée Lacroix, Tom Bewley, Valeriia Nemychnikova, Victor Paltz', 'link': 'https://arxiv.org/abs/2507.13264', 'abstract': 'We present Voxtral Mini and Voxtral Small, two multimodal audio chat models. Voxtral is trained to comprehend both spoken audio and text documents, achieving state-of-the-art performance across a diverse range of audio benchmarks, while preserving strong text capabilities. Voxtral Small outperforms a number of closed-source models, while being small enough to run locally. A 32K context window enables the model to handle audio files up to 40 minutes in duration and long multi-turn conversations. We also contribute three benchmarks for evaluating speech understanding models on knowledge and trivia. Both Voxtral models are released under Apache 2.0 license.', 'abstract_zh': '我们呈现了Voxtral Mini和Voxtral Small两种多模态音频聊天模型。Voxtral模型经过训练，能够理解语音音频和文本文档，取得了多种音频基准上的最佳性能，同时保留了强大的文本能力。Voxtral Small在性能上优于多种封闭源模型，且体积足够小以支持本地运行。32K上下文窗口使模型能够处理长达40分钟的音频文件和长多轮对话。我们还贡献了三个benchmark，用于评估语音理解模型在知识和 trivia 方面的表现。两种Voxtral模型均采用Apache 2.0许可证发布。', 'title_zh': 'VoiceTral'}
{'arxiv_id': 'arXiv:2507.13263', 'title': 'Merge Kernel for Bayesian Optimization on Permutation Space', 'authors': 'Zikai Xie, Linjiang Chen', 'link': 'https://arxiv.org/abs/2507.13263', 'abstract': 'Bayesian Optimization (BO) algorithm is a standard tool for black-box optimization problems. The current state-of-the-art BO approach for permutation spaces relies on the Mallows kernel-an $\\Omega(n^2)$ representation that explicitly enumerates every pairwise comparison. Inspired by the close relationship between the Mallows kernel and pairwise comparison, we propose a novel framework for generating kernel functions on permutation space based on sorting algorithms. Within this framework, the Mallows kernel can be viewed as a special instance derived from bubble sort. Further, we introduce the \\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic complexity with $\\Theta(n\\log n)$ to achieve the lowest possible complexity. The resulting feature vector is significantly shorter, can be computed in linearithmic time, yet still efficiently captures meaningful permutation distances. To boost robustness and right-invariance without sacrificing compactness, we further incorporate three lightweight, task-agnostic descriptors: (1) a shift histogram, which aggregates absolute element displacements and supplies a global misplacement signal; (2) a split-pair line, which encodes selected long-range comparisons by aligning elements across the two halves of the whole permutation; and (3) sliding-window motifs, which summarize local order patterns that influence near-neighbor objectives. Our empirical evaluation demonstrates that the proposed kernel consistently outperforms the state-of-the-art Mallows kernel across various permutation optimization benchmarks. Results confirm that the Merge Kernel provides a more compact yet more effective solution for Bayesian optimization in permutation space.', 'abstract_zh': '基于排序算法的排列空间核函数生成框架：Merge Kernel及其实现', 'title_zh': '排列空间上贝叶斯优化的合并内核'}
{'arxiv_id': 'arXiv:2507.13170', 'title': 'SHIELD: A Secure and Highly Enhanced Integrated Learning for Robust Deepfake Detection against Adversarial Attacks', 'authors': 'Kutub Uddin, Awais Khan, Muhammad Umar Farooq, Khalid Malik', 'link': 'https://arxiv.org/abs/2507.13170', 'abstract': 'Audio plays a crucial role in applications like speaker verification, voice-enabled smart devices, and audio conferencing. However, audio manipulations, such as deepfakes, pose significant risks by enabling the spread of misinformation. Our empirical analysis reveals that existing methods for detecting deepfake audio are often vulnerable to anti-forensic (AF) attacks, particularly those attacked using generative adversarial networks. In this article, we propose a novel collaborative learning method called SHIELD to defend against generative AF attacks. To expose AF signatures, we integrate an auxiliary generative model, called the defense (DF) generative model, which facilitates collaborative learning by combining input and output. Furthermore, we design a triplet model to capture correlations for real and AF attacked audios with real-generated and attacked-generated audios using auxiliary generative models. The proposed SHIELD strengthens the defense against generative AF attacks and achieves robust performance across various generative models. The proposed AF significantly reduces the average detection accuracy from 95.49% to 59.77% for ASVspoof2019, from 99.44% to 38.45% for In-the-Wild, and from 98.41% to 51.18% for HalfTruth for three different generative models. The proposed SHIELD mechanism is robust against AF attacks and achieves an average accuracy of 98.13%, 98.58%, and 99.57% in match, and 98.78%, 98.62%, and 98.85% in mismatch settings for the ASVspoof2019, In-the-Wild, and HalfTruth datasets, respectively.', 'abstract_zh': '音频在speaker验证、语音-enable的智能设备和音频会议等应用中起着关键作用。然而，音频篡改，如深伪，通过促进虚假信息的传播带来了重大风险。我们的实证分析表明，现有的深伪音频检测方法往往对对抗取证（AF）攻击脆弱，尤其是那些使用生成对抗网络进行攻击的。在本文中，我们提出了一种名为SHIELD的新型协作学习方法，以抵御生成性AF攻击。为了揭示AF特征，我们整合了一个辅助生成模型，称为防御（DF）生成模型，它通过结合输入和输出促进了协作学习。此外，我们设计了一个三元组模型，使用辅助生成模型捕获真实和AF攻击音频与真实生成和攻击生成音频之间的相关性。所提出的SHIELD增强了对生成性AF攻击的防御并实现了各种生成模型下的稳健性能。所提出的AF显著降低了ASVspoof2019、In-the-Wild和HalfTruth三个不同生成模型下的平均检测精度，分别为95.49%降至59.77%、99.44%降至38.45%和98.41%降至51.18%。所提出的SHIELD机制对AF攻击具有鲁棒性，在ASVspoof2019、In-the-Wild和HalfTruth数据集中，匹配设置下的平均准确率分别为98.13%、98.58%和99.57%，不匹配设置下的平均准确率分别为98.78%、98.62%和98.85%。', 'title_zh': 'SHIELD：一种针对对抗攻击的稳健深度假信息检测的安全高度集成学习方法'}
{'arxiv_id': 'arXiv:2507.13090', 'title': 'MUPAX: Multidimensional Problem Agnostic eXplainable AI', 'authors': 'Vincenzo Dentamaro, Felice Franchini, Giuseppe Pirlo, Irina Voiculescu', 'link': 'https://arxiv.org/abs/2507.13090', 'abstract': 'Robust XAI techniques should ideally be simultaneously deterministic, model agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability technique, with guaranteed convergency. MUPAX measure theoretic formulation gives principled feature importance attribution through structured perturbation analysis that discovers inherent input patterns and eliminates spurious relationships. We evaluate MUPAX on an extensive range of data modalities and tasks: audio classification (1D), image classification (2D), volumetric medical image analysis (3D), and anatomical landmark detection, demonstrating dimension agnostic effectiveness. The rigorous convergence guarantees extend to any loss function and arbitrary dimensions, making MUPAX applicable to virtually any problem context for AI. By contrast with other XAI methods that typically decrease performance when masking, MUPAX not only preserves but actually enhances model accuracy by capturing only the most important patterns of the original data. Extensive benchmarking against the state of the XAI art demonstrates MUPAX ability to generate precise, consistent and understandable explanations, a crucial step towards explainable and trustworthy AI systems. The source code will be released upon publication.', 'abstract_zh': '鲁棒的可解释人工智能技术应当同时具备确定性、模型无关性和收敛保证。我们提出了一种确定性、模型无关的解释性人工智能技术MULTIDIMENSIONAL PROBLEM AGNOSTIC EXPLAINABLE AI（MUPAX），其具有收敛保证。MUPAX的测度论表述通过结构化扰动分析提供原则上的特征重要性归因，发现固有的输入模式并消除虚假关系。我们在涵盖广泛数据模态和任务的评估中展示了MUPAX的维度无关有效性：音频分类（1D）、图像分类（2D）、医学影像体积分析（3D）和解剖标志检测。其严格的收敛保证适用于任何损失函数和任意维度，使MUPAX适用于几乎所有的人工智能问题上下文。与通常在遮蔽时降低性能的其他可解释性人工智能方法不同，MUPAX不仅保持了模型的准确性，而且还通过捕获原始数据中最重要的模式而增强了模型的准确性。与当前可解释性人工智能领域的最佳方法的广泛基准测试表明，MUPAX能够生成精确、一致且易于理解的解释，这是迈向可解释和可信赖的人工智能系统的关键步骤。源代码将在发表后公开。', 'title_zh': 'MUPAX：多维度问题无因果假设可解释人工智能'}
{'arxiv_id': 'arXiv:2507.13001', 'title': 'SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs', 'authors': 'Kossi Amouzouvi, Bowen Song, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati', 'link': 'https://arxiv.org/abs/2507.13001', 'abstract': 'Knowledge graph representation learning approaches provide a mapping between symbolic knowledge in the form of triples in a knowledge graph (KG) and their feature vectors. Knowledge graph embedding (KGE) models often represent relations in a KG as geometric transformations. Most state-of-the-art (SOTA) KGE models are derived from elementary geometric transformations (EGTs), such as translation, scaling, rotation, and reflection, or their combinations. These geometric transformations enable the models to effectively preserve specific structural and relational patterns of the KG. However, the current use of EGTs by KGEs remains insufficient without considering relation-specific transformations. Although recent models attempted to address this problem by ensembling SOTA baseline models in different ways, only a single or composite version of geometric transformations are used by such baselines to represent all the relations. In this paper, we propose a framework that evaluates how well each relation fits with different geometric transformations. Based on this ranking, the model can: (1) assign the best-matching transformation to each relation, or (2) use majority voting to choose one transformation type to apply across all relations. That is, the model learns a single relation-specific EGT in low dimensional vector space through an attention mechanism. Furthermore, we use the correlation between relations and EGTs, which are learned in a low dimension, for relation embeddings in a high dimensional vector space. The effectiveness of our models is demonstrated through comprehensive evaluations on three benchmark KGs as well as a real-world financial KG, witnessing a performance comparable to leading models', 'abstract_zh': '知识图谱表示学习方法将知识图谱（KG）中以三元组形式表示的符号知识映射到其特征向量。大多数最先进的（SOTA）知识图谱嵌入（KGE）模型是从基本几何变换（EGTs），如平移、缩放、旋转和反射，或其组合派生而来。这些几何变换使模型能够有效地保留知识图谱的特定结构和关系模式。然而，目前的KGEs在使用EGTs时尚未充分考虑关系特异性变换。尽管最近的模型试图通过以不同方式集成SOTA基线模型来解决这一问题，这些基线模型仅使用单一或组合的几何变换来表示所有关系。在本文中，我们提出了一种框架，以评估每种关系与不同几何变换的匹配程度，并基于此排名：（1）为每种关系分配最佳匹配的变换，或（2）使用多数投票选择一种变换类型应用于所有关系。即，模型通过注意力机制学习低维向量空间中的单个关系特异性EGT。此外，我们利用关系和EGTs在低维空间中学习到的相关性，在高维向量空间中为关系嵌入提供支持。通过在三个基准知识图谱以及一个实时金融知识图谱上的全面评估，证明了我们模型的有效性，表现可媲美领先模型。', 'title_zh': 'SMART：面向知识图的关系aware几何表示学习'}
{'arxiv_id': 'arXiv:2507.12979', 'title': 'A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints', 'authors': 'Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy', 'link': 'https://arxiv.org/abs/2507.12979', 'abstract': 'Federated Learning has gained increasing attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing their raw data. At the same time, Generative AI -- particularly Generative Adversarial Networks (GANs) -- have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices -- such as IoT devices and edge devices -- with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables the utilization of distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints -- ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experimental results shows that our approach demonstrates consistent and significant improvements across key performance metrics, where it achieves 1.1x -- 2.2x higher image generation scores, an average 10% boost in classification metrics (up to 50% in multi-domain non-IID settings), in much lower latency compared to several benchmarks. Find our code at this https URL.', 'abstract_zh': '联邦学习由于其能够使多个节点协作训练机器学习模型而无需共享原始数据的能力，引起了越来越多的关注。同时，生成性人工智能——特别是生成对抗网络（GANs）——在医疗保健、安全和图像生成等领域取得了显著成功。然而，训练生成模型通常需要大量数据集和显著的计算资源，这些资源在实际应用场景中往往无法获得。获取这些资源可能代价高昂且效率低下，尤其是当大量低利用率且能力各异的设备（如IoT设备和边缘设备）处于闲置状态时。此外，由于隐私担忧和版权限制，获得大量数据集也非常具有挑战性，因为大多数设备不愿意共享其数据。为了解决这些挑战，我们提出了一种新的去中心化GAN训练方法，该方法能够利用分布式数据和低利用率的低能力设备，而不以原始形式共享数据。该方法旨在解决去中心化环境中的一些关键挑战，结合KLD加权聚类联邦学习以应对数据异质性和多域数据集的问题，并采用异构U形分裂学习以在严格的数据共享约束下应对设备异质性挑战——确保节点之间永不共享任何标签或原始数据，无论是真实数据还是合成数据。实验结果表明，我们的方法在关键性能指标上表现出一致且显著的改进，其中在图像生成指标上达到1.1至2.2倍的提升，在分类指标上平均提升10%（在多域非IID设置中最高可提升50%），且在较低的延迟下实现。我们的代码请参见此链接：[这里](https://)。', 'title_zh': '一种在数据共享约束下的异构多域环境分布式生成AI方法'}
{'arxiv_id': 'arXiv:2507.12951', 'title': 'UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets', 'authors': 'Zhichao Sheng, Shilin Zhou, Chen Gong, Zhenghua Li', 'link': 'https://arxiv.org/abs/2507.12951', 'abstract': 'Spoken Language Understanding (SLU) plays a crucial role in speech-centric multimedia applications, enabling machines to comprehend spoken language in scenarios such as meetings, interviews, and customer service interactions. SLU encompasses multiple tasks, including Automatic Speech Recognition (ASR), spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA). However, existing methods often rely on separate model architectures for individual tasks such as spoken NER and SA, which increases system complexity, limits cross-task interaction, and fails to fully exploit heterogeneous datasets available across tasks. To address these limitations, we propose UniSLU, a unified framework that jointly models multiple SLU tasks within a single architecture. Specifically, we propose a unified representation for diverse SLU tasks, enabling full utilization of heterogeneous datasets across multiple tasks. Built upon this representation, we propose a unified generative method that jointly models ASR, spoken NER, and SA tasks, enhancing task interactions and enabling seamless integration with large language models to harness their powerful generative capabilities. Extensive experiments on public SLU datasets demonstrate the effectiveness of our approach, achieving superior SLU performance compared to several benchmark methods, making it well-suited for real-world speech-based multimedia scenarios. We will release all code and models at github to facilitate future research.', 'abstract_zh': '统一口语理解：联合建模多种口语理解任务以优化多模态语音应用', 'title_zh': 'UniSLU：统一的口语理解从异构跨任务数据集'}
{'arxiv_id': 'arXiv:2507.12935', 'title': 'MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration', 'authors': 'Shirui Zhao, Jun Yin, Lingyun Yao, Martin Andraud, Wannes Meert, Marian Verhelst', 'link': 'https://arxiv.org/abs/2507.12935', 'abstract': 'An increasing number of applications are exploiting sampling-based algorithms for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC) algorithms form the computational backbone of this emerging branch of machine learning. Unfortunately, the high computational cost limits their feasibility for large-scale problems and real-world applications, and the existing MCMC acceleration solutions are either limited in hardware flexibility or fail to maintain efficiency at the system level across a variety of end-to-end applications. This paper introduces \\textbf{MC$^2$A}, an algorithm-hardware co-design framework, enabling efficient and flexible optimization for MCMC acceleration. Firstly, \\textbf{MC$^2$A} analyzes the MCMC workload diversity through an extension of the processor performance roofline model with a 3rd dimension to derive the optimal balance between the compute, sampling and memory parameters. Secondly, \\textbf{MC$^2$A} proposes a parametrized hardware accelerator architecture with flexible and efficient support of MCMC kernels with a pipeline of ISA-programmable tree-structured processing units, reconfigurable samplers and a crossbar interconnect to support irregular access. Thirdly, the core of \\textbf{MC$^2$A} is powered by a novel Gumbel sampler that eliminates exponential and normalization operations. In the end-to-end case study, \\textbf{MC$^2$A} achieves an overall {$307.6\\times$, $1.4\\times$, $2.0\\times$, $84.2\\times$} speedup compared to the CPU, GPU, TPU and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC workloads, this work demonstrates and exploits the feasibility of general hardware acceleration to popularize MCMC-based solutions in diverse application domains.', 'abstract_zh': 'MC²A：一种算法-硬件协同设计框架，实现MCMC加速的高效与灵活优化', 'title_zh': 'MC$^2$A:  Enables 算法-硬件协同设计以实现高效的马尔可夫链蒙特卡洛加速'}
{'arxiv_id': 'arXiv:2507.12904', 'title': 'An ultra-low-power CGRA for accelerating Transformers at the edge', 'authors': 'Rohit Prasad', 'link': 'https://arxiv.org/abs/2507.12904', 'abstract': 'Transformers have revolutionized deep learning with applications in natural language processing, computer vision, and beyond. However, their computational demands make it challenging to deploy them on low-power edge devices. This paper introduces an ultra-low-power, Coarse-Grained Reconfigurable Array (CGRA) architecture specifically designed to accelerate General Matrix Multiplication (GEMM) operations in transformer models tailored for the energy and resource constraints of edge applications. The proposed architecture integrates a 4 x 4 array of Processing Elements (PEs) for efficient parallel computation and dedicated 4 x 2 Memory Operation Blocks (MOBs) for optimized LOAD/STORE operations, reducing memory bandwidth demands and enhancing data reuse. A switchless mesh torus interconnect network further minimizes power and latency by enabling direct communication between PEs and MOBs, eliminating the need for centralized switching. Through its heterogeneous array design and efficient dataflow, this CGRA architecture addresses the unique computational needs of transformers, offering a scalable pathway to deploy sophisticated machine learning models on edge devices.', 'abstract_zh': '基于细粒度可重构阵列的超低功耗GEMM加速器设计：针对边缘应用的能量和资源限制', 'title_zh': '边缘加速Transformer模型的超低功耗CGRA'}
{'arxiv_id': 'arXiv:2507.12871', 'title': 'Generative Multi-Target Cross-Domain Recommendation', 'authors': 'Jinqiu Jin, Yang Zhang, Junwei Pan, Fuli Feng, Hua Lu, Haijie Gu, Xiangnan He', 'link': 'https://arxiv.org/abs/2507.12871', 'abstract': 'Recently, there has been a surge of interest in Multi-Target Cross-Domain Recommendation (MTCDR), which aims to enhance recommendation performance across multiple domains simultaneously. Existing MTCDR methods primarily rely on domain-shared entities (\\eg users or items) to fuse and transfer cross-domain knowledge, which may be unavailable in non-overlapped recommendation scenarios. Some studies model user preferences and item features as domain-sharable semantic representations, which can be utilized to tackle the MTCDR task. Nevertheless, they often require extensive auxiliary data for pre-training. Developing more effective solutions for MTCDR remains an important area for further exploration.\nInspired by recent advancements in generative recommendation, this paper introduces GMC, a generative paradigm-based approach for multi-target cross-domain recommendation. The core idea of GMC is to leverage semantically quantized discrete item identifiers as a medium for integrating multi-domain knowledge within a unified generative model. GMC first employs an item tokenizer to generate domain-shared semantic identifiers for each item, and then formulates item recommendation as a next-token generation task by training a domain-unified sequence-to-sequence model. To further leverage the domain information to enhance performance, we incorporate a domain-aware contrastive loss into the semantic identifier learning, and perform domain-specific fine-tuning on the unified recommender. Extensive experiments on five public datasets demonstrate the effectiveness of GMC compared to a range of baseline methods.', 'abstract_zh': '最近，多目标跨域推荐（MTCDR）引起了广泛关注，其目标是同时在多个领域内提升推荐性能。现有MTCDR方法主要依赖领域共享实体（例如用户或物品）来融合和转移跨域知识，但在无重叠推荐场景中这些实体可能不可用。一些研究将用户偏好和物品特征建模为可跨域共享的语义表示，以应对MTCDR任务。然而，它们往往需要大量辅助数据进行预训练。开发更有效的MTCDR解决方案仍然是一个重要的研究方向。\n\n受生成推荐领域最新进展的启发，本文提出了GMC，一种基于生成范式的多目标跨域推荐方法。GMC的核心思想是利用语义量化离散物品标识符作为媒介，在统一的生成模型中整合多域知识。GMC首先使用物品分词器为每个物品生成领域共享的语义标识符，然后通过训练一个领域统一的序列到序列模型将物品推荐任务形式化为下一个标识符生成任务。为进一步利用领域信息提升性能，我们在语义标识符学习中引入了领域感知对比损失，并在统一推荐器中进行领域特定的微调。在五个公开数据集上的广泛实验结果表明，GMC相较于一系列基线方法具有更高的有效性。', 'title_zh': '生成式多目标跨域推荐'}
{'arxiv_id': 'arXiv:2507.12805', 'title': 'PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database', 'authors': 'Hui Sun, Yanfeng Ding, Liping Yi, Huidong Ma, Gang Wang, Xiaoguang Liu, Cheng Zhong, Wentong Cai', 'link': 'https://arxiv.org/abs/2507.12805', 'abstract': "Learning-based lossless compressors play a crucial role in large-scale genomic database backup, storage, transmission, and management. However, their 1) inadequate compression ratio, 2) low compression \\& decompression throughput, and 3) poor compression robustness limit their widespread adoption and application in both industry and academia. To solve those challenges, we propose a novel \\underline{P}arallel \\underline{M}ulti-\\underline{K}nowledge \\underline{L}earning-based \\underline{C}ompressor (PMKLC) with four crucial designs: 1) We propose an automated multi-knowledge learning-based compression framework as compressors' backbone to enhance compression ratio and robustness; 2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression throughput and computing resource usage; 3) we introduce data block partitioning and Step-wise Model Passing (SMP) mechanisms for parallel acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet the complex application scenarios, where the former runs on a resource-constrained single GPU and the latter is multi-GPU accelerated. We benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15 real-world datasets with different species and data sizes. Compared to baselines on the testing datasets, PMKLC-S/M achieve the average compression ratio improvement up to 73.609\\% and 73.480\\%, the average throughput improvement up to 3.036$\\times$ and 10.710$\\times$, respectively. Besides, PMKLC-S/M also achieve the best robustness and competitive memory cost, indicating its greater stability against datasets with different probability distribution perturbations, and its strong ability to run on memory-constrained devices.", 'abstract_zh': '基于学习的无损压缩器在大规模基因组数据库备份、存储、传输和管理中发挥着 crucial 作用。然而，它们存在的 1) 压缩比不足，2) 压缩与解压缩吞吐量低，3) 压缩鲁棒性差 的问题限制了其在工业和学术界的广泛应用。为解决这些挑战，我们提出了一种新颖的 Parallel Multi-Knowledge Learning-based Compressor (PMKLC)，其包含了四个关键设计：1) 提出了一种自动化多知识学习基于压缩的框架作为压缩器的核心，以增强压缩比和鲁棒性；2) 设计了 GPU 加速的 ($s$,$k$)-mer 编码器来优化压缩吞吐量和计算资源使用；3) 引入了数据块划分和 Step-wise Model Passing (SMP) 机制以实现并行加速；4) 设计了两种压缩模式 PMKLC-S 和 PMKLC-M 以适应复杂的应用场景，其中前者在资源受限的单个 GPU 上运行，后者则通过多 GPU 加速。我们使用 15 个不同物种和数据大小的实际数据集对 PMKLC-S/M 和 14 个 baselines (7 传统和 7 学习基于) 进行了基准测试。与测试数据集上的 baselines 相比，PMKLC-S/M 在压缩比上平均提高了 73.609% 和 73.480%，在吞吐量上平均分别提高了 3.036 倍和 10.710 倍。此外，PMKLC-S/M 在鲁棒性和内存成本方面也表现最佳，显示出其在面对不同概率分布扰动的数据集时具有更高的稳定性和在内存受限设备上运行的强适应能力。', 'title_zh': 'PMKLC：面向大规模基因组数据库的并行多知识学习无损压缩方法'}
{'arxiv_id': 'arXiv:2507.12803', 'title': 'FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction', 'authors': 'Qianru Zhang, Chenglei Yu, Haixin Wang, Yudong Yan, Yuansheng Cao, Siu-Ming Yiu, Tailin Wu, Hongzhi Yin', 'link': 'https://arxiv.org/abs/2507.12803', 'abstract': 'Time series prediction, a crucial task across various domains, faces significant challenges due to the inherent complexities of time series data, including non-stationarity, multi-scale periodicity, and transient dynamics, particularly when tackling long-term predictions. While Transformer-based architectures have shown promise, their quadratic complexity with sequence length hinders their efficiency for long-term predictions. Recent advancements in State-Space Models, such as Mamba, offer a more efficient alternative for long-term modeling, but they cannot capture multi-scale periodicity and transient dynamics effectively. Meanwhile, they are susceptible to data noise issues in time series. This paper proposes a novel framework, FLDmamba (Fourier and Laplace Transform Decomposition Mamba), addressing these limitations. FLDmamba leverages the strengths of both Fourier and Laplace transforms to effectively capture both multi-scale periodicity, transient dynamics within time series data, and improve the robustness of the model to the data noise issue. Our extensive experiments demonstrate that FLDmamba achieves superior performance on time series prediction benchmarks, outperforming both Transformer-based and other Mamba-based architectures. To promote the reproducibility of our method, we have made both the code and data accessible via the following URL:{\\href{this https URL}{this https URL\\model}.', 'abstract_zh': '时间序列预测是一个跨多个领域的关键任务，但由于时间序列数据内在的非平稳性、多尺度周期性和瞬态动力学特征，尤其是针对长期预测时，面临着显著挑战。尽管基于Transformer的架构显示出前景，但它们与序列长度呈二次复杂性的特性限制了其在长期预测中的效率。最近在状态空间模型方面的进展，如Mamba，为长期建模提供了一种更高效的替代方案，但它们在捕捉多尺度周期性和瞬态动力学方面效果欠佳，同时对时间序列中的数据噪声问题也较为敏感。本文提出了一种新颖的框架FLDmamba（傅里叶和拉普拉斯变换分解Mamba），以解决这些局限性。FLDmamba结合了傅里叶和拉普拉斯变换的优势，有效捕捉时间序列数据中的多尺度周期性和瞬态动力学，提高模型对数据噪声问题的鲁棒性。我们的 extensive 实验表明，FLDmamba 在时间序列预测基准上表现出优越的性能，超越了基于Transformer和Mamba的其他架构。为了促进我们的方法的可再现性，我们已将代码和数据通过以下 URL 提供给用户：{this https URL}。', 'title_zh': 'FLDmamba: 结合傅里叶变换和拉普拉斯变换分解与Mamba以增强时间序列预测'}
{'arxiv_id': 'arXiv:2507.12767', 'title': 'Autonomy for Older Adult-Agent Interaction', 'authors': 'Jiaxin An', 'link': 'https://arxiv.org/abs/2507.12767', 'abstract': "As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.", 'abstract_zh': '随着全球人口老龄化，人工智能（AI）驱动的代理已成为支持老年人护理的潜在工具。现有研究通过识别任务流程中的关键交互阶段并定义每个阶段的代理角色来探讨代理的自主性。然而，确保代理与老年人的自主性偏好相一致仍是一项关键挑战。基于跨学科对自主性的概念化，本文探讨了老年人的四个关键自主性维度：决策自主性、目标导向自主性、控制自主性和社会责任自主性。本文随后提出以下研究方向：（1）社会责任自主性，关注代理在集体环境中的使用所涉及的伦理和社会含义；（2）从任务视角实现代理自主性；（3）开发自主性测量方法。', 'title_zh': '老年人与代理互动的自主性'}
{'arxiv_id': 'arXiv:2507.12701', 'title': 'Task-Specific Audio Coding for Machines: Machine-Learned Latent Features Are Codes for That Machine', 'authors': 'Anastasia Kuznetsova, Inseon Jang, Wootaek Lim, Minje Kim', 'link': 'https://arxiv.org/abs/2507.12701', 'abstract': 'Neural audio codecs, leveraging quantization algorithms, have significantly impacted various speech/audio tasks. While high-fidelity reconstruction is paramount for human perception, audio coding for machines (ACoM) prioritizes efficient compression and downstream task performance, disregarding perceptual nuances. This work introduces an efficient ACoM method that can compress and quantize any chosen intermediate feature representation of an already trained speech/audio downstream model. Our approach employs task-specific loss guidance alongside residual vector quantization (RVQ) losses, providing ultra-low bitrates (i.e., less than 200 bps) with a minimal loss of the downstream model performance. The resulting tokenizer is adaptable to various bitrates and model sizes for flexible deployment. Evaluated on automatic speech recognition and audio classification, our method demonstrates its efficacy and potential for broader task and architectural applicability through appropriate regularization.', 'abstract_zh': '基于量化算法的神经音频编解码器对各种语音/音频任务产生了重大影响。虽然高保真重建对人类感知至关重要，但面向机器的音频编码（ACoM）侧重于高效压缩和下游任务性能，忽略感知上的细微差别。本工作介绍了一种高效的ACoM方法，可以压缩并量化任何预先训练的语音/音频下游模型的任意中间特征表示。该方法结合任务特定的损失指导和残差向量量化（RVQ）损失，能够在最大限度保持下游模型性能的情况下提供超低比特率（即低于200 bps）。生成的分词器具有多种比特率和模型大小的适应性，便于灵活部署。在自动语音识别和音频分类任务上，我们的方法通过适当的正则化展示了其有效性和在更广泛任务和架构上的应用潜力。', 'title_zh': '面向任务的音频编码：机器学习潜在特征作为该机器的编码'}
{'arxiv_id': 'arXiv:2507.12677', 'title': 'Data Transformation Strategies to Remove Heterogeneity', 'authors': 'Sangbong Yoo, Jaeyoung Lee, Chanyoung Yoon, Geonyeong Son, Hyein Hong, Seongbum Seo, Soobin Yim, Chanyoung Jung, Jungsoo Park, Misuk Kim, Yun Jang', 'link': 'https://arxiv.org/abs/2507.12677', 'abstract': 'Data heterogeneity is a prevalent issue, stemming from various conflicting factors, making its utilization complex. This uncertainty, particularly resulting from disparities in data formats, frequently necessitates the involvement of experts to find resolutions. Current methodologies primarily address conflicts related to data structures and schemas, often overlooking the pivotal role played by data transformation. As the utilization of artificial intelligence (AI) continues to expand, there is a growing demand for a more streamlined data preparation process, and data transformation becomes paramount. It customizes training data to enhance AI learning efficiency and adapts input formats to suit diverse AI models. Selecting an appropriate transformation technique is paramount in preserving crucial data details. Despite the widespread integration of AI across various industries, comprehensive reviews concerning contemporary data transformation approaches are scarce. This survey explores the intricacies of data heterogeneity and its underlying sources. It systematically categorizes and presents strategies to address heterogeneity stemming from differences in data formats, shedding light on the inherent challenges associated with each strategy.', 'abstract_zh': '数据异质性是一个普遍存在的问题，源自多种冲突因素，使其利用变得复杂。这种不确定性，尤其是由于数据格式差异引起的情况，通常需要专家介入以找到解决方案。现有的方法主要关注数据结构和模式相关的冲突，而往往忽视了数据转换所扮演的关键角色。随着人工智能（AI）的应用不断扩大，对更 streamlined 的数据准备过程的需求日益增加，数据转换变得尤为重要。它能够定制训练数据以提高AI学习效率，并适应不同的AI模型输入格式。选择合适的转换技术对于保留关键数据细节至关重要。尽管AI在各行各业中的应用越来越广泛，但关于当前数据转换方法的综合评估却很少见。本文探讨了数据异质性的复杂性及其背后的根源，系统地分类并呈现了应对由数据格式差异引起异质性的策略，揭示了每种策略固有的挑战。', 'title_zh': '数据转换策略以消除异质性'}
{'arxiv_id': 'arXiv:2507.12659', 'title': 'Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions', 'authors': 'Athanasios Papastathopoulos-Katsaros, Alexandra Stavrianidi, Zhandong Liu', 'link': 'https://arxiv.org/abs/2507.12659', 'abstract': 'Physics-Informed Neural Networks (PINNs) are deep learning models that incorporate the governing physical laws of a system into the learning process, making them well-suited for solving complex scientific and engineering problems. Recently, PINNs have gained widespread attention as a powerful framework for combining physical principles with data-driven modeling to improve prediction accuracy. Despite their successes, however, PINNs often exhibit poor extrapolation performance outside the training domain and are highly sensitive to the choice of activation functions (AFs). In this paper, we introduce a transfer learning (TL) method to improve the extrapolation capability of PINNs. Our approach applies transfer learning (TL) within an extended training domain, using only a small number of carefully selected collocation points. Additionally, we propose an adaptive AF that takes the form of a linear combination of standard AFs, which improves both the robustness and accuracy of the model. Through a series of experiments, we demonstrate that our method achieves an average of 40% reduction in relative L2 error and an average of 50% reduction in mean absolute error in the extrapolation domain, all without a significant increase in computational cost. The code is available at this https URL .', 'abstract_zh': '基于物理的神经网络（PINNs）的迁移学习方法提高其外推能力', 'title_zh': '通过迁移学习和自适应激活函数提高物理知情神经网络的外推能力'}
{'arxiv_id': 'arXiv:2507.12630', 'title': 'Achieving Robust Channel Estimation Neural Networks by Designed Training Data', 'authors': 'Dianxin Luan, John Thompson', 'link': 'https://arxiv.org/abs/2507.12630', 'abstract': 'Channel estimation is crucial in cognitive communications, as it enables intelligent spectrum sensing and adaptive transmission by providing accurate information about the current channel state. However, in many papers neural networks are frequently tested by training and testing on one example channel or similar channels. This is because data-driven methods often degrade on new data which they are not trained on, as they cannot extrapolate their training knowledge. This is despite the fact physical channels are often assumed to be time-variant. However, due to the low latency requirements and limited computing resources, neural networks may not have enough time and computing resources to execute online training to fine-tune the parameters. This motivates us to design offline-trained neural networks that can perform robustly over wireless channels, but without any actual channel information being known at design time. In this paper, we propose design criteria to generate synthetic training datasets for neural networks, which guarantee that after training the resulting networks achieve a certain mean squared error (MSE) on new and previously unseen channels. Therefore, neural network solutions require no prior channel information or parameters update for real-world implementations. Based on the proposed design criteria, we further propose a benchmark design which ensures intelligent operation for different channel profiles. To demonstrate general applicability, we use neural networks with different levels of complexity to show that the generalization achieved appears to be independent of neural network architecture. From simulations, neural networks achieve robust generalization to wireless channels with both fixed channel profiles and variable delay spreads.', 'abstract_zh': '基于合成数据集的无线信道稳健神经网络设计准则及验证', 'title_zh': '通过设计训练数据实现稳健的信道估计神经网络'}
{'arxiv_id': 'arXiv:2507.12568', 'title': 'Safeguarding Federated Learning-based Road Condition Classification', 'authors': 'Sheng Liu, Panos Papadimitratos', 'link': 'https://arxiv.org/abs/2507.12568', 'abstract': 'Federated Learning (FL) has emerged as a promising solution for privacy-preserving autonomous driving, specifically camera-based Road Condition Classification (RCC) systems, harnessing distributed sensing, computing, and communication resources on board vehicles without sharing sensitive image data. However, the collaborative nature of FL-RCC frameworks introduces new vulnerabilities: Targeted Label Flipping Attacks (TLFAs), in which malicious clients (vehicles) deliberately alter their training data labels to compromise the learned model inference performance. Such attacks can, e.g., cause a vehicle to mis-classify slippery, dangerous road conditions as pristine and exceed recommended speed. However, TLFAs for FL-based RCC systems are largely missing. We address this challenge with a threefold contribution: 1) we disclose the vulnerability of existing FL-RCC systems to TLFAs; 2) we introduce a novel label-distance-based metric to precisely quantify the safety risks posed by TLFAs; and 3) we propose FLARE, a defensive mechanism leveraging neuron-wise analysis of the output layer to mitigate TLFA effects. Extensive experiments across three RCC tasks, four evaluation metrics, six baselines, and three deep learning models demonstrate both the severity of TLFAs on FL-RCC systems and the effectiveness of FLARE in mitigating the attack impact.', 'abstract_zh': '联邦学习（FL）在隐私保护自动驾驶中的应用：针对基于摄像头的道路条件分类（RCC）系统的 targeted label flipping 攻击及其防御机制研究', 'title_zh': '基于联邦学习的道路状况分类安全防护'}
{'arxiv_id': 'arXiv:2507.12555', 'title': 'Can Mental Imagery Improve the Thinking Capabilities of AI Systems?', 'authors': 'Slimane Larabi', 'link': 'https://arxiv.org/abs/2507.12555', 'abstract': "Although existing models can interact with humans and provide satisfactory responses, they lack the ability to act autonomously or engage in independent reasoning. Furthermore, input data in these models is typically provided as explicit queries, even when some sensory data is already acquired.\nIn addition, AI agents, which are computational entities designed to perform tasks and make decisions autonomously based on their programming, data inputs, and learned knowledge, have shown significant progress. However, they struggle with integrating knowledge across multiple domains, unlike humans.\nMental imagery plays a fundamental role in the brain's thinking process, which involves performing tasks based on internal multisensory data, planned actions, needs, and reasoning capabilities. In this paper, we investigate how to integrate mental imagery into a machine thinking framework and how this could be beneficial in initiating the thinking process. Our proposed machine thinking framework integrates a Cognitive thinking unit supported by three auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery Unit. Within this framework, data is represented as natural language sentences or drawn sketches, serving both informative and decision-making purposes. We conducted validation tests for this framework, and the results are presented and discussed.", 'abstract_zh': '尽管现有的模型可以与人类交互并提供满意的回答，但它们缺乏自主行动或独立推理的能力。此外，这些模型中的输入数据通常以明确的查询形式提供，即使已经获得了某些感测数据。\n此外，能够自主地根据编程、数据输入和学习的知识来执行任务并作出决策的人工智能代理已经取得了显著的进步。然而，它们在跨多个领域整合知识方面存在困难，不像人类那样能够做到这一点。\n心智成像是大脑思维过程中的一个基本组成部分，涉及基于内部多感官数据、计划的动作、需求和推理能力来执行任务。本文探讨如何将心智成像集成到机器思维框架中，以及这种集成如何有助于启动思维过程。我们提出的一种机器思维框架集成了一个认知思维单元和支持该单元的三个辅助单元：输入数据单元、需求单元和心智成像单元。在这种框架中，数据以自然语言句子或绘制的草图形式表示，既具有信息传递功能，也具有决策制定功能。我们为此框架进行了验证测试，结果进行了展示和讨论。', 'title_zh': '心智想象能提升人工智能系统的思维能力吗？'}
{'arxiv_id': 'arXiv:2507.12504', 'title': 'Transforming Football Data into Object-centric Event Logs with Spatial Context Information', 'authors': 'Vito Chan, Lennart Ebert, Paul-Julius Hillmann, Christoffer Rubensson, Stephan A. Fahrenkrog-Petersen, Jan Mendling', 'link': 'https://arxiv.org/abs/2507.12504', 'abstract': 'Object-centric event logs expand the conventional single-case notion event log by considering multiple objects, allowing for the analysis of more complex and realistic process behavior. However, the number of real-world object-centric event logs remains limited, and further studies are needed to test their usefulness. The increasing availability of data from team sports can facilitate object-centric process mining, leveraging both real-world data and suitable use cases. In this paper, we present a framework for transforming football (soccer) data into an object-centric event log, further enhanced with a spatial dimension. We demonstrate the effectiveness of our framework by generating object-centric event logs based on real-world football data and discuss the results for varying process representations. With our paper, we provide the first example for object-centric event logs in football analytics. Future work should consider variant analysis and filtering techniques to better handle variability', 'abstract_zh': '基于对象的事件日志扩展了传统的单一案例事件日志概念，考虑了多个对象，从而允许分析更复杂和现实的过程行为。然而，实际世界的基于对象的事件日志仍然有限，需要进一步研究以检验其实用性。来自团队运动的数据越来越多地可以促进基于对象的过程挖掘，利用实际数据和合适的用例。本文提出了一种将足球数据转换为基于对象的事件日志的框架，并进一步增强其空间维度。我们通过基于实际足球数据生成基于对象的事件日志，展示了该框架的有效性，并讨论了不同过程表示的结果。通过本文，我们提供了足球分析中基于对象的事件日志的第一个示例。未来的工作应考虑变体分析和过滤技术以更好地处理变异性。', 'title_zh': '将足球数据转化为具有空间上下文信息的物为中心的事件日志'}
{'arxiv_id': 'arXiv:2507.12492', 'title': 'Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise', 'authors': 'Ratun Rahman, Atit Pokharel, Dinh C. Nguyen', 'link': 'https://arxiv.org/abs/2507.12492', 'abstract': 'Quantum Federated Learning (QFL) is an emerging paradigm that combines quantum computing and federated learning (FL) to enable decentralized model training while maintaining data privacy over quantum networks. However, quantum noise remains a significant barrier in QFL, since modern quantum devices experience heterogeneous noise levels due to variances in hardware quality and sensitivity to quantum decoherence, resulting in inadequate training performance. To address this issue, we propose SpoQFL, a novel QFL framework that leverages sporadic learning to mitigate quantum noise heterogeneity in distributed quantum systems. SpoQFL dynamically adjusts training strategies based on noise fluctuations, enhancing model robustness, convergence stability, and overall learning efficiency. Extensive experiments on real-world datasets demonstrate that SpoQFL significantly outperforms conventional QFL approaches, achieving superior training performance and more stable convergence.', 'abstract_zh': '量子联邦学习（QFL）是一种结合量子计算和联邦学习的新兴范式，旨在通过量子网络实现数据隐私下的去中心化模型训练。然而，量子噪声仍然是QFL中的一个重大障碍，因为现代量子设备由于硬件质量差异和对量子退相干的敏感性不同，导致噪声水平异质，从而影响训练性能。为解决这一问题，我们提出了一种名为SpoQFL的新颖QFL框架，利用间歇学习来减轻分布式量子系统中的量子噪声异质性。SpoQFL根据噪声波动动态调整训练策略，增强模型的鲁棒性、收敛稳定性和整体学习效率。实验结果表明，SpoQFL显著优于传统QFL方法，实现了更高的训练性能和更稳定的收敛。', 'title_zh': '量子环境中基于 sporadic 联邦学习的方法以应对量子噪声'}
{'arxiv_id': 'arXiv:2507.12486', 'title': 'On multiagent online problems with predictions', 'authors': 'Gabriel Istrate, Cosmin Bonchis, Victor Bogdan', 'link': 'https://arxiv.org/abs/2507.12486', 'abstract': "We study the power of (competitive) algorithms with predictions in a multiagent setting. We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players. The main problem we are concerned with is understanding what are the best competitive ratios that can be achieved by employing such predictors, under various assumptions on predictor quality.\nAs an illustration of our framework, we introduce and analyze a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.\nIn the particular case of perfect other predictions the algorithm that follows the self predictor is optimal but not robust to mispredictions of agent's future behavior; we give an algorithm with better robustness properties and benchmark it.", 'abstract_zh': '我们研究预测在多代理环境下竞争算法的能力。我们引入了一种两预测框架，假设代理使用一个预测他们自己未来行为的预测器，另一个预测其他玩家的行为。我们主要关注的问题是在各种假设条件下，可以实现的最佳竞争比是什么。\n\n为了展示我们的框架，我们引入并分析了一个多代理环境下的滑雪租赁问题。在这个问题中，代理可以通过共享资源来获得某种资产的团体许可证。如果许可证价格未达到，则代理必须以单一价格租用该资产一天；否则，许可证将对所有人永久免费。\n\n在其他预测完美的特殊情况下，遵循自我预测的算法是最优的，但对代理未来行为的误预测不够 robust；我们提出一个具有更好 robust 性质的算法并将其作为基准进行比较。', 'title_zh': '多智能体在线问题的预测研究'}
{'arxiv_id': 'arXiv:2507.12485', 'title': 'Quantum Transfer Learning to Boost Dementia Detection', 'authors': 'Sounak Bhowmik, Talita Perciano, Himanshu Thapliyal', 'link': 'https://arxiv.org/abs/2507.12485', 'abstract': 'Dementia is a devastating condition with profound implications for individuals, families, and healthcare systems. Early and accurate detection of dementia is critical for timely intervention and improved patient outcomes. While classical machine learning and deep learning approaches have been explored extensively for dementia prediction, these solutions often struggle with high-dimensional biomedical data and large-scale datasets, quickly reaching computational and performance limitations. To address this challenge, quantum machine learning (QML) has emerged as a promising paradigm, offering faster training and advanced pattern recognition capabilities. This work aims to demonstrate the potential of quantum transfer learning (QTL) to enhance the performance of a weak classical deep learning model applied to a binary classification task for dementia detection. Besides, we show the effect of noise on the QTL-based approach, investigating the reliability and robustness of this method. Using the OASIS 2 dataset, we show how quantum techniques can transform a suboptimal classical model into a more effective solution for biomedical image classification, highlighting their potential impact on advancing healthcare technology.', 'abstract_zh': '认知障碍是一种对个人、家庭和医疗卫生系统产生深远影响的毁灭性状况。早期和准确地检测认知障碍对于及时干预和改善患者结果至关重要。虽然经典的机器学习和深度学习方法在认知障碍预测方面得到了广泛探索，但这些解决方案往往难以应对高维生物医学数据和大规模数据集，很快达到了计算能力和性能的限制。为应对这一挑战，量子机器学习（QML）已逐渐成为一种有前景的范式，提供更快的训练和高级模式识别能力。本工作旨在展示量子迁移学习（QTL）增强弱经典深度学习模型在认知障碍二分类任务中的性能潜力。此外，我们展示了噪声对基于QTL方法的影响，探讨了该方法的可靠性和稳健性。使用OASIS 2数据集，我们展示了量子技术如何将一个次优的经典模型转换为更有效的生物医学图像分类解决方案，突显了其在推动医疗保健技术进步方面的潜在影响。', 'title_zh': '量子迁移学习以提升痴呆症检测'}
{'arxiv_id': 'arXiv:2507.12475', 'title': 'Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective', 'authors': 'Takashi Izumo', 'link': 'https://arxiv.org/abs/2507.12475', 'abstract': 'The St. Petersburg paradox presents a longstanding challenge in decision theory. It describes a game whose expected value is infinite, yet for which no rational finite stake can be determined. Traditional solutions introduce auxiliary assumptions, such as diminishing marginal utility, temporal discounting, or extended number systems. These methods often involve mathematical refinements that may not correspond to how people actually perceive or process numerical information. This paper explores an alternative approach based on a modified operation of addition defined over coarse partitions of the outcome space. In this model, exact numerical values are grouped into perceptual categories, and each value is replaced by a representative element of its group before being added. This method allows for a phenomenon where repeated additions eventually cease to affect the outcome, a behavior described as inertial stabilization. Although this is not intended as a definitive resolution of the paradox, the proposed framework offers a plausible way to represent how agents with limited cognitive precision might handle divergent reward structures. We demonstrate that the St. Petersburg series can become inert under this coarse addition for a suitably constructed partition. The approach may also have broader applications in behavioral modeling and the study of machine reasoning under perceptual limitations.', 'abstract_zh': '圣彼得堡悖论为决策理论提出了一个长期挑战。它描述了一个预期值无穷大的游戏，但其中没有任何合理的有限赌注可以确定。传统解决方案引入了辅助假设，如边际效用递减、时间折扣或扩展数值系统。这些方法通常涉及数学 refinements，这些可能并不符合人们实际感知或处理数值信息的方式。本文探讨了一种基于对结果空间粗略划分上定义的修改加法运算的替代方法。在此模型中，精确数值被分组为知觉类别，并在相加前用每个组的代表元素替换。这种方法允许一种现象，即重复加法最终不再影响结果，这种行为称为惯性稳定。虽然这不是解决悖论的最终方案，但提出的新框架提供了一种合理的表示认知精度有限的代理如何处理发散奖励结构的方式。我们证明，在适当构造的划分下，圣彼得堡级数可以在粗略加法下变得惯性稳定。该方法还可能在行为建模以及研究感知限制下的机器推理方面具有更广泛的应用。', 'title_zh': '粗略加法与圣彼得堡悖论：启发式视角'}
{'arxiv_id': 'arXiv:2407.02740', 'title': 'Implementation and Analysis of GPU Algorithms for Vecchia Approximation', 'authors': 'Zachary James, Joseph Guinness', 'link': 'https://arxiv.org/abs/2407.02740', 'abstract': "Gaussian Processes have become an indispensable part of the spatial statistician's toolbox but are unsuitable for analyzing large dataset because of the significant time and memory needed to fit the associated model exactly. Vecchia Approximation is widely used to reduce the computational complexity and can be calculated with embarrassingly parallel algorithms. While multi-core software has been developed for Vecchia Approximation, such as the GpGp R package, software designed to run on graphics processing units (GPU) is lacking, despite the tremendous success GPUs have had in statistics and machine learning. We compare three different ways to implement Vecchia Approximation on a GPU: two of which are similar to methods used for other Gaussian Process approximations and one that is new. The impact of memory type on performance is investigated and the final method is optimized accordingly. We show that our new method outperforms the other two and then present it in the GpGpU R package. We compare GpGpU to existing multi-core and GPU-accelerated software by fitting Gaussian Process models on various datasets, including a large spatial-temporal dataset of $n>10^6$ points collected from an earth-observing satellite. Our results show that GpGpU achieves faster runtimes and better predictive accuracy.", 'abstract_zh': 'GP Approximation on GPU: A New Method for Vecchia Approximation and Its Implementation in GpGpU R Package', 'title_zh': 'GPU算法在Vecchia逼近中的实现与分析'}
