{'arxiv_id': 'arXiv:2509.13279', 'title': 'HARMONIC: A Content-Centric Cognitive Robotic Architecture', 'authors': 'Sanjay Oruganti, Sergei Nirenburg, Marjorie McShane, Jesse English, Michael K. Roberts, Christian Arndt, Carlos Gonzalez, Mingyo Seo, Luis Sentis', 'link': 'https://arxiv.org/abs/2509.13279', 'abstract': 'This paper introduces HARMONIC, a cognitive-robotic architecture designed for robots in human-robotic teams. HARMONIC supports semantic perception interpretation, human-like decision-making, and intentional language communication. It addresses the issues of safety and quality of results; aims to solve problems of data scarcity, explainability, and safety; and promotes transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are demonstrated, each implemented in both a high-fidelity simulation environment and on physical robotic platforms.', 'abstract_zh': '本文介绍了HARMONIC，一种为人类-机器人团队设计的认知机器人架构。HARMONIC支持语义感知解释、类人的决策-making以及意图性的语言沟通。它解决了安全性和结果质量的问题，旨在解决数据稀缺性、可解释性和安全性问题，并促进透明度和信任。文中展示了基于HARMONIC的两个概念验证机器人系统，每个系统都在高保真模拟环境中以及物理机器人平台上实现。', 'title_zh': 'HARMONIC: 以内容为中心的认知机器人架构'}
{'arxiv_id': 'arXiv:2509.13249', 'title': 'Design and Control of a Perching Drone Inspired by the Prey-Capturing Mechanism of Venus Flytrap', 'authors': 'Ye Li, Daming Liu, Yanhe Zhu, Junming Zhang, Yongsheng Luo, Ziqi Wang, Chenyu Liu, Jie Zhao', 'link': 'https://arxiv.org/abs/2509.13249', 'abstract': 'The endurance and energy efficiency of drones remain critical challenges in their design and operation. To extend mission duration, numerous studies explored perching mechanisms that enable drones to conserve energy by temporarily suspending flight. This paper presents a new perching drone that utilizes an active flexible perching mechanism inspired by the rapid predation mechanism of the Venus flytrap, achieving perching in less than 100 ms. The proposed system is designed for high-speed adaptability to the perching targets. The overall drone design is outlined, followed by the development and validation of the biomimetic perching structure. To enhance the system stability, a cascade extended high-gain observer (EHGO) based control method is developed, which can estimate and compensate for the external disturbance in real time. The experimental results demonstrate the adaptability of the perching structure and the superiority of the cascaded EHGO in resisting wind and perching disturbances.', 'abstract_zh': '无人机的续航能力和能源效率仍是其设计和操作中的关键挑战。为了延长任务时间，众多研究探索了悬停机制，使无人机能够通过暂时停止飞行来节省能源。本文介绍了一种新式悬停无人机，采用受 Venus 猪笼草快速捕食机制启发的主动柔性悬停机制，能在不到100毫秒内实现悬停。所提出系统具有高速适应悬停目标的能力。概述了整体无人机设计，并开发和验证了仿生悬停结构。为了提高系统稳定性，开发了一种级联扩展高增益观测器（EHGO）控制方法，能够实时估计并补偿外部干扰。实验结果表明，悬停结构的适应性和级联EHGO在抵抗风干扰和悬停干扰方面的优越性。', 'title_zh': '受捕蝇草捕食机制启发的着陆无人机的设计与控制'}
{'arxiv_id': 'arXiv:2509.13239', 'title': 'Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum', 'authors': 'Tianxu An, Flavio De Vincenti, Yuntao Ma, Marco Hutter, Stelian Coros', 'link': 'https://arxiv.org/abs/2509.13239', 'abstract': 'We present a hierarchical RL pipeline for training one-armed legged robots to perform pick-and-place (P&P) tasks end-to-end -- from approaching the payload to releasing it at a target area -- in both single-robot and cooperative dual-robot settings. We introduce a novel dynamic reward curriculum that enables a single policy to efficiently learn long-horizon P&P operations by progressively guiding the agents through payload-centered sub-objectives. Compared to state-of-the-art approaches for long-horizon RL tasks, our method improves training efficiency by 55% and reduces execution time by 18.6% in simulation experiments. In the dual-robot case, we show that our policy enables each robot to attend to different components of its observation space at distinct task stages, promoting effective coordination via autonomous attention shifts. We validate our method through real-world experiments using ANYmal D platforms in both single- and dual-robot scenarios. To our knowledge, this is the first RL pipeline that tackles the full scope of collaborative P&P with two legged manipulators.', 'abstract_zh': '我们提出了一种分层强化学习管道，用于训练单臂腿式机器人从接近载荷到在目标区域释放载荷（P&P任务）的端到端学习——在单机器人和合作双机器人设置中均适用。我们引入了一种新颖的动力学奖励课程，使得单一策略能够通过逐步引导代理通过以载荷为中心的亚目标来高效地学习长时滞P&P操作。与最新的长时滞RL任务方法相比，在模拟实验中，我们的方法将训练效率提高了55%，并将执行时间减少了18.6%。在双机器人情况下，我们展示了我们的策略使每个机器人能够在不同的任务阶段关注其观察空间的不同部分，通过自主注意力转移实现有效的协调。我们通过在单机器人和双机器人场景中使用ANYmal D平台进行实际试验来验证我们的方法。据我们所知，这是第一个处理两腿操作器协作P&P全范围的RL管道。', 'title_zh': '动态奖励 Curriculum 的协作移位与拾放任务操作'}
{'arxiv_id': 'arXiv:2509.13200', 'title': 'StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening', 'authors': 'Moonyoung Lee, Dong Ki Kim, Jai Krishna Bandi, Max Smith, Aileen Liao, Ali-akbar Agha-mohammadi, Shayegan Omidshafiei', 'link': 'https://arxiv.org/abs/2509.13200', 'abstract': "Humanoid robots promise to operate in everyday human environments without requiring modifications to the surroundings. Among the many skills needed, opening doors is essential, as doors are the most common gateways in built spaces and often limit where a robot can go. Door opening, however, poses unique challenges as it is a long-horizon task under partial observability, such as reasoning about the door's unobservable latch state that dictates whether the robot should rotate the handle or push the door. This ambiguity makes standard behavior cloning prone to mode collapse, yielding blended or out-of-sequence actions. We introduce StageACT, a stage-conditioned imitation learning framework that augments low-level policies with task-stage inputs. This effective addition increases robustness to partial observability, leading to higher success rates and shorter completion times. On a humanoid operating in a real-world office environment, StageACT achieves a 55% success rate on previously unseen doors, more than doubling the best baseline. Moreover, our method supports intentional behavior guidance through stage prompting, enabling recovery behaviors. These results highlight stage conditioning as a lightweight yet powerful mechanism for long-horizon humanoid loco-manipulation.", 'abstract_zh': '人形机器人在无需对环境进行修改的情况下操作日常人类环境充满希望。人形机器人需要掌握许多技能，其中开门至关重要，因为门是建筑物内部最常见的入口，常常限制机器人的活动范围。然而，开门是一项独特的挑战，因为它在部分可观测性下是一个长期任务，例如需要推理门未观测到的锁状态，以决定机器人应旋转把手还是推门。这种不确定性使标准行为克隆容易陷入模式崩溃，产生混杂或顺序错误的动作。我们提出了StageACT，这是一种基于阶段条件的模仿学习框架，通过将任务阶段输入增强低级策略。这种方法的有效增加提高了对部分可观测性的鲁棒性，从而提高了成功率并缩短了完成时间。在一个在真实世界办公室环境中操作的人形机器人上，StageACT在未见过的门上的成功率达到了55%，超过了最佳基线方法一倍以上。此外，我们的方法支持通过阶段提示进行意向性行为引导，从而实现恢复行为。这些结果突显了阶段条件作为长期人形仿人移动中轻量且强大的机制的重要性。', 'title_zh': 'StageACT：基于阶段条件的鲁棒 humanoid 门开启模仿'}
{'arxiv_id': 'arXiv:2509.13177', 'title': 'ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation', 'authors': 'Salvatore Esposito, Matías Mattamala, Daniel Rebain, Francis Xiatian Zhang, Kevin Dhaliwal, Mohsen Khadem, Subramanian Ramamoorthy', 'link': 'https://arxiv.org/abs/2509.13177', 'abstract': 'Continuum robots are advancing bronchoscopy procedures by accessing complex lung airways and enabling targeted interventions. However, their development is limited by the lack of realistic training and test environments: Real data is difficult to collect due to ethical constraints and patient safety concerns, and developing autonomy algorithms requires realistic imaging and physical feedback. We present ROOM (Realistic Optical Observation in Medicine), a comprehensive simulation framework designed for generating photorealistic bronchoscopy training data. By leveraging patient CT scans, our pipeline renders multi-modal sensor data including RGB images with realistic noise and light specularities, metric depth maps, surface normals, optical flow and point clouds at medically relevant scales. We validate the data generated by ROOM in two canonical tasks for medical robotics -- multi-view pose estimation and monocular depth estimation, demonstrating diverse challenges that state-of-the-art methods must overcome to transfer to these medical settings. Furthermore, we show that the data produced by ROOM can be used to fine-tune existing depth estimation models to overcome these challenges, also enabling other downstream applications such as navigation. We expect that ROOM will enable large-scale data generation across diverse patient anatomies and procedural scenarios that are challenging to capture in clinical settings. Code and data: this https URL.', 'abstract_zh': '连续体机器人通过访问复杂的肺部气道并实现目标干预，正在推进支气管镜检查程序。然而，其发展受限于缺乏现实的训练和测试环境：由于伦理约束和患者安全问题，真实数据难以收集，同时开发自主算法需要现实的成像和物理反馈。我们提出了ROOM（医学中的现实光学观察），一个为生成逼真的支气管镜检查训练数据而设计的综合仿真框架。通过利用患者CT扫描，我们的管道渲染包括具有现实噪声和光泽的RGB图像、度量深度图、表面法线、光流和点云等多种模态的传感器数据，适用于医学相关规模。我们在医学机器人领域的两个经典任务——多视角姿态估计和单目深度估计中验证了ROOM生成的数据，展示了最先进的方法需要克服的多种挑战，以迁移到这些医学环境中。此外，我们展示ROOM生成的数据可以用于微调现有的深度估计模型以克服这些挑战，同时也使其他下游应用程序如导航成为可能。我们预计ROOM将使大规模数据生成成为可能，涵盖在临床环境中难以捕捉到的多种患者解剖结构和程序场景。代码和数据：this https URL。', 'title_zh': 'ROOM：一种基于物理的连续体机器人模拟器，用于生成逼真的医疗数据集'}
{'arxiv_id': 'arXiv:2509.13164', 'title': 'TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving', 'authors': 'Jiawei Wang, Haowei Sun, Xintao Yan, Shuo Feng, Jun Gao, Henry X. Liu', 'link': 'https://arxiv.org/abs/2509.13164', 'abstract': 'Safe and scalable deployment of end-to-end (E2E) autonomous driving requires extensive and diverse data, particularly safety-critical events. Existing data are mostly generated from simulators with a significant sim-to-real gap or collected from on-road testing that is costly and unsafe. This paper presents TeraSim-World, an automated pipeline that synthesizes realistic and geographically diverse safety-critical data for E2E autonomous driving at anywhere in the world. Starting from an arbitrary location, TeraSim-World retrieves real-world maps and traffic demand from geospatial data sources. Then, it simulates agent behaviors from naturalistic driving datasets, and orchestrates diverse adversities to create corner cases. Informed by street views of the same location, it achieves photorealistic, geographically grounded sensor rendering via the frontier video generation model Cosmos-Drive. By bridging agent and sensor simulations, TeraSim-World provides a scalable and critical~data synthesis framework for training and evaluation of E2E autonomous driving systems.', 'abstract_zh': '全球规模可信安全事件合成管道：TeraSim-World 用于端到端自主驾驶系统培训与评估', 'title_zh': 'TeraSim-World: 全球范围内的安全关键数据合成用于端到端自动驾驶'}
{'arxiv_id': 'arXiv:2509.13132', 'title': 'An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios', 'authors': 'Zhihao Zhang, Chengyang Peng, Minghao Zhu, Ekim Yurtsever, Keith A. Redmill', 'link': 'https://arxiv.org/abs/2509.13132', 'abstract': "Autonomous driving in dense, dynamic environments requires decision-making systems that can exploit both spatial structure and long-horizon temporal dependencies while remaining robust to uncertainty. This work presents a novel framework that integrates multi-channel bird's-eye-view occupancy grids with transformer-based sequence modeling for tactical driving in complex roundabout scenarios. To address the imbalance between frequent low-risk states and rare safety-critical decisions, we propose the Uncertainty-Weighted Decision Transformer (UWDT). UWDT employs a frozen teacher transformer to estimate per-token predictive entropy, which is then used as a weight in the student model's loss function. This mechanism amplifies learning from uncertain, high-impact states while maintaining stability across common low-risk transitions. Experiments in a roundabout simulator, across varying traffic densities, show that UWDT consistently outperforms other baselines in terms of reward, collision rate, and behavioral stability. The results demonstrate that uncertainty-aware, spatial-temporal transformers can deliver safer and more efficient decision-making for autonomous driving in complex traffic environments.", 'abstract_zh': '自主驾驶在密集动态环境中需要能够同时利用空间结构和长时间序列依赖性的决策系统，且要具备在不确定性下的鲁棒性。本文提出了一种将多通道鸟瞰视图占用格网与基于变压器的序列建模相结合的新型框架，用于处理复杂环形交叉口场景中的战术驾驶。为了解决低风险状态频繁出现与安全关键决策罕见之间的不平衡问题，我们提出了一种不确定性加权决策变压器（UWDT）。UWDT 使用冻结的教师变压器来估计每个标记的预测熵，并将其用作学生模型损失函数中的权重。该机制在放大不确定但高影响状态的学习效果的同时，保持了对常见低风险过渡的稳定性。在不同交通密度的环形交叉口模拟器中的实验表明，UWDT 在奖励、碰撞率和行为稳定性方面均优于其他基线方法。结果表明，感知不确定性的时间空间变压器可以为复杂交通环境中的自主驾驶提供更安全、更高效的决策。', 'title_zh': '面向稠密复杂驾驶场景的不确定性加权决策转换器'}
{'arxiv_id': 'arXiv:2509.13126', 'title': 'Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation', 'authors': 'Miquel Oller, An Dang, Nima Fazeli', 'link': 'https://arxiv.org/abs/2509.13126', 'abstract': "Tactile sensors have long been valued for their perceptual capabilities, offering rich insights into the otherwise hidden interface between the robot and grasped objects. Yet their inherent compliance -- a key driver of force-rich interactions -- remains underexplored. The central challenge is to capture the complex, nonlinear dynamics introduced by these passive-compliant elements. Here, we present a computationally efficient non-holonomic hydroelastic model that accurately models path-dependent contact force distributions and dynamic surface area variations. Our insight is to extend the object's state space, explicitly incorporating the distributed forces generated by the compliant sensor. Our differentiable formulation not only accounts for path-dependent behavior but also enables gradient-based trajectory optimization, seamlessly integrating with high-resolution tactile feedback. We demonstrate the effectiveness of our approach across a range of simulated and real-world experiments and highlight the importance of modeling the path dependence of sensor dynamics.", 'abstract_zh': '触觉传感器长期以来因其感知能力而备受重视，提供了对机器人与抓取物体之间隐藏界面的丰富见解。然而，其固有的顺应性——力丰富交互的关键驱动因素——仍然未被充分探索。核心挑战在于捕捉由这些被动顺应元件引入的复杂非线性动力学。在这里，我们提出了一种计算上高效的非完整水弹性模型，能够准确建模路径依赖的接触力分布和动态表面积变化。我们的见解在于扩展物体的状态空间，明确纳入由顺应传感器产生的分布力。可微分的建模不仅考虑了路径依赖行为，还允许基于梯度的轨迹优化，无缝结合高分辨率触觉反馈。我们在一系列模拟和实际实验中证明了该方法的有效性，并强调了建模传感器动力学路径依赖性的重要性。', 'title_zh': 'Hydrosoft: 非全轭水弹性模型及其在柔顺触觉操作中的应用'}
{'arxiv_id': 'arXiv:2509.13109', 'title': 'Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation', 'authors': 'Fabian Flürenbrock, Yanick Büchel, Johannes Köhler, Marianne Schmid Daners, Melanie N. Zeilinger', 'link': 'https://arxiv.org/abs/2509.13109', 'abstract': "This paper introduces a learning-based control framework for a soft robotic actuator system designed to modulate intracranial pressure (ICP) waveforms, which is essential for studying cerebrospinal fluid dynamics and pathological processes underlying neurological disorders. A two-layer framework is proposed to safely achieve a desired ICP waveform modulation. First, a model predictive controller (MPC) with a disturbance observer is used for offset-free tracking of the system's motor position reference trajectory under safety constraints. Second, to address the unknown nonlinear dependence of ICP on the motor position, we employ a Bayesian optimization (BO) algorithm used for online learning of a motor position reference trajectory that yields the desired ICP modulation. The framework is experimentally validated using a test bench with a brain phantom that replicates realistic ICP dynamics in vitro. Compared to a previously employed proportional-integral-derivative controller, the MPC reduces mean and maximum motor position reference tracking errors by 83 % and 73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor position reference trajectory that yields an ICP waveform with the desired mean and amplitude.", 'abstract_zh': '基于学习的软机器人执行器控制系统用于颅内压波形调控及其在研究脑脊液动力学和神经疾病病理过程中的应用：一种两层框架的安全实现', 'title_zh': '基于参考学习的模型预测控制在颅内压波形调节中的应用'}
{'arxiv_id': 'arXiv:2509.13095', 'title': 'Empowering Multi-Robot Cooperation via Sequential World Models', 'authors': 'Zijie Zhao, Honglei Guo, Shengqian Chen, Kaixuan Xu, Bo Jiang, Yuanheng Zhu, Dongbin Zhao', 'link': 'https://arxiv.org/abs/2509.13095', 'abstract': 'Model-based reinforcement learning (MBRL) has shown significant potential in robotics due to its high sample efficiency and planning capability. However, extending MBRL to multi-robot cooperation remains challenging due to the complexity of joint dynamics. To address this, we propose the Sequential World Model (SeqWM), a novel framework that integrates the sequential paradigm into model-based multi-agent reinforcement learning. SeqWM employs independent, sequentially structured agent-wise world models to decompose complex joint dynamics. Latent rollouts and decision-making are performed through sequential communication, where each agent generates its future trajectory and plans its actions based on the predictions of its predecessors. This design enables explicit intention sharing, enhancing cooperative performance, and reduces communication overhead to linear complexity. Results in challenging simulated environments (Bi-DexHands and Multi-Quad) show that SeqWM outperforms existing state-of-the-art model-free and model-based baselines in both overall performance and sample efficiency, while exhibiting advanced cooperative behaviors such as predictive adaptation and role division. Furthermore, SeqWM has been success fully deployed on physical quadruped robots, demonstrating its effectiveness in real-world multi-robot systems. Demos and code are available at: this https URL', 'abstract_zh': '基于模型的强化学习（MBRL）在机器人领域展现出了显著的潜力，得益于其高样本效率和规划能力。然而，将MBRL扩展到多机器人合作仍然存在挑战，因为联合动力学的复杂性较高。为了解决这一问题，我们提出了序贯世界模型（SeqWM），这是一种将序贯范式整合到基于模型的多智能体强化学习中的新型框架。SeqWM通过独立的、序贯结构化的智能体级世界模型分解复杂的联合动力学。通过序贯通信进行潜在轨迹采样和决策制定，每个智能体基于前一个智能体的预测生成其未来的轨迹并规划其动作。该设计使得显式的意图共享成为可能，增强了合作性能，并将通信开销降低到线性复杂度。在具有挑战性的模拟环境中（Bi-DexHands和Multi-Quad），SeqWM在整体性能和样本效率上均优于现有最先进的基于模型和无模型基线，同时展示了预测适应和角色分工等高级合作行为。此外，SeqWM已在物理四足机器人上成功部署，证明其在实际多机器人系统中的有效性。更多演示和代码请访问：this https URL。', 'title_zh': '通过序列世界模型赋能多机器人协同作业'}
{'arxiv_id': 'arXiv:2509.13077', 'title': 'A Design Co-Pilot for Task-Tailored Manipulators', 'authors': 'Jonathan Külz, Sehoon Ha, Matthias Althoff', 'link': 'https://arxiv.org/abs/2509.13077', 'abstract': "Although robotic manipulators are used in an ever-growing range of applications, robot manufacturers typically follow a ``one-fits-all'' philosophy, employing identical manipulators in various settings. This often leads to suboptimal performance, as general-purpose designs fail to exploit particularities of tasks. The development of custom, task-tailored robots is hindered by long, cost-intensive development cycles and the high cost of customized hardware. Recently, various computational design methods have been devised to overcome the bottleneck of human engineering. In addition, a surge of modular robots allows quick and economical adaptation to changing industrial settings. This work proposes an approach to automatically designing and optimizing robot morphologies tailored to a specific environment. To this end, we learn the inverse kinematics for a wide range of different manipulators. A fully differentiable framework realizes gradient-based fine-tuning of designed robots and inverse kinematics solutions. Our generative approach accelerates the generation of specialized designs from hours with optimization-based methods to seconds, serving as a design co-pilot that enables instant adaptation and effective human-AI collaboration. Numerical experiments show that our approach finds robots that can navigate cluttered environments, manipulators that perform well across a specified workspace, and can be adapted to different hardware constraints. Finally, we demonstrate the real-world applicability of our method by setting up a modular robot designed in simulation that successfully moves through an obstacle course.", 'abstract_zh': '尽管机器人 manipulator 被应用于日益广泛的场合，机器人制造商通常采用“一刀切”的理念，在不同场景中使用相同的 manipulator，这往往导致性能次优，因为通用设计无法充分利用特定任务的特点。定制化、任务适配的机器人开发受到长期且成本高昂的开发周期以及定制化硬件高成本的限制。最近，已开发出多种计算设计方法以克服人工工程的瓶颈。此外，模块化机器人的兴起使快速且经济地适应变化的工业环境成为可能。本研究提出了一种自动设计和优化特定环境适配机器人形态的方法。为此，我们学习了不同类型 manipulator 的逆运动学。基于完全可微的框架实现了基于梯度的所设计机器人和逆运动学解的微调。我们的生成方法能够将基于优化方法生成专门设计的时间从数小时缩短至数秒，从而发挥设计协作者的作用，实现即时适应和有效的人机合作。数值实验表明，我们的方法能够找到能够在杂乱环境中导航的机器人、在指定工作空间内表现良好的 manipulator，并能够适应不同的硬件约束。最后，我们通过在仿真中设计的模块化机器人成功穿越障碍赛道，展示了该方法的现实应用可行性。', 'title_zh': '任务定制化 manipulator 的设计副驾驶'}
{'arxiv_id': 'arXiv:2509.13074', 'title': 'Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five', 'authors': 'Simon Fritsch, Liam Achenbach, Riccardo Bianco, Nicola Irmiger, Gawain Marti, Samuel Visca, Chenyu Yang, Davide Liconti, Barnabas Gavin Cangan, Robert Jomar Malate, Ronan J. Hinchet, Robert K. Katzschmann', 'link': 'https://arxiv.org/abs/2509.13074', 'abstract': "This paper presents the SABD hand, a 16-degree-of-freedom (DoF) robotic hand that departs from purely anthropomorphic designs to achieve an expanded grasp envelope, enable manipulation poses beyond human capability, and reduce the required number of actuators. This is achieved by combining the adduction/abduction (Add/Abd) joint of digits four and five into a single joint with a large range of motion. The combined joint increases the workspace of the digits by 400\\% and reduces the required DoFs while retaining dexterity. Experimental results demonstrate that the combined Add/Abd joint enables the hand to grasp objects with a side distance of up to 200 mm. Reinforcement learning-based investigations show that the design enables grasping policies that are effective not only for handling larger objects but also for achieving enhanced grasp stability. In teleoperated trials, the hand successfully performed 86\\% of attempted grasps on suitable YCB objects, including challenging non-anthropomorphic configurations. These findings validate the design's ability to enhance grasp stability, flexibility, and dexterous manipulation without added complexity, making it well-suited for a wide range of applications.", 'abstract_zh': 'SABD手：一种16自由度的非拟人化机器人手及其扩展抓取能力与灵活操作能力的研究', 'title_zh': '超越拟人化：通过融合第四指和第五指的 abduction 增强抓取并消除一个自由度'}
{'arxiv_id': 'arXiv:2509.13069', 'title': 'Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol', 'authors': 'James C. Ward, Arthur Richards, Edmund R. Hunt', 'link': 'https://arxiv.org/abs/2509.13069', 'abstract': 'Persistent monitoring using robot teams is of interest in fields such as security, environmental monitoring, and disaster recovery. Performing such monitoring in a fully on-line decentralised fashion has significant potential advantages for robustness, adaptability, and scalability of monitoring solutions, including, in principle, the capacity to effectively adapt in real-time to a changing environment. We examine this through the lens of multi-robot patrol, in which teams of patrol robots must persistently minimise time between visits to points of interest, within environments where traversability of routes is highly dynamic. These dynamics must be observed by patrol agents and accounted for in a fully decentralised on-line manner. In this work, we present a new method of monitoring and adjusting for environment dynamics in a decentralised multi-robot patrol team. We demonstrate that our method significantly outperforms realistic baselines in highly dynamic scenarios, and also investigate dynamic scenarios in which explicitly accounting for environment dynamics may be unnecessary or impractical.', 'abstract_zh': '基于机器人团队的持续监测在安全、环境监测和灾后恢复等领域具有研究价值。通过多机器人巡逻的角度考察全离线去中心化监测的潜在优势，包括实时适应变化环境的能力。我们提出了一种新的方法，用于去中心化多机器人巡逻团队中监测和调整环境动态。我们证明了该方法在高度动态场景中显著优于现实基准，并探讨了在某些动态场景中无需或不实际考虑环境动态的情况。', 'title_zh': '分散控制的多机器人巡逻中动态环境的实际处理'}
{'arxiv_id': 'arXiv:2509.13024', 'title': 'DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception', 'authors': 'Haohan Min, Zhoujian Li, Yu Yang, Jinyu Chen, Shenghai Yuan', 'link': 'https://arxiv.org/abs/2509.13024', 'abstract': "Automatic docking has long been a significant challenge in the field of mobile robotics. Compared to other automatic docking methods, visual docking methods offer higher precision and lower deployment costs, making them an efficient and promising choice for this task. However, visual docking methods impose strict requirements on the robot's initial position at the start of the docking process. To overcome the limitations of current vision-based methods, we propose an innovative end-to-end visual docking method named DVDP(direct visual docking policy). This approach requires only a binocular RGB-D camera installed on the mobile robot to directly output the robot's docking path, achieving end-to-end automatic docking. Furthermore, we have collected a large-scale dataset of mobile robot visual automatic docking dataset through a combination of virtual and real environments using the Unity 3D platform and actual mobile robot setups. We developed a series of evaluation metrics to quantify the performance of the end-to-end visual docking method. Extensive experiments, including benchmarks against leading perception backbones adapted into our framework, demonstrate that our method achieves superior performance. Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy, with our model generating smooth, feasible docking trajectories that meet physical constraints and reach the target pose.", 'abstract_zh': '自动对接一直是移动机器人领域的一项重要挑战。与其它自动对接方法相比，视觉对接方法具有更高的精度和更低的部署成本，使其成为一个高效且有前景的选择。然而，视觉对接方法对机器人在对接过程开始时的初始位置有严格的要求。为克服当前基于视觉方法的局限性，我们提出了一种名为DVDP（直接视觉对接策略）的端到端视觉对接方法。该方法仅需在移动机器人上安装一个双目RGB-D相机，直接输出机器人的对接路径，实现端到端的自动对接。此外，我们通过Unity 3D平台结合虚拟和实际环境，以及实际移动机器人配置，收集了一个大规模的移动机器人视觉自动对接数据集。我们开发了一系列评估指标来量化端到端视觉对接方法的表现。广泛的实验，包括与我们的框架中适应的领先感知骨干网络的基准测试，证明了该方法具有优异的性能。最后，在SCOUT Mini上的实际部署验证了DVDP的有效性，我们的模型产生了平滑且可行的对接轨迹，满足物理约束并到达目标姿态。', 'title_zh': 'DVDP：基于RGB-D感知的移动机器人端到端视觉对接策略'}
{'arxiv_id': 'arXiv:2509.12982', 'title': 'Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins', 'authors': 'Erblin Isaku, Hassan Sartaj, Shaukat Ali, Beatriz Sanguino, Tongtong Wang, Guoyuan Li, Houxiang Zhang, Thomas Peyrucain', 'link': 'https://arxiv.org/abs/2509.12982', 'abstract': 'Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance -- up to 98\\% AUROC, 96\\% TNR@TPR95, and 95\\% F1-score -- while providing interpretable insights to support self-adaptation.', 'abstract_zh': '基于数字孪生的自适应机器人异常检测方法（ODiSAR）', 'title_zh': '基于AI驱动数字孪生的自适应机器人离分布检测'}
{'arxiv_id': 'arXiv:2509.12969', 'title': 'Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators', 'authors': 'Jae-Hyun Lee, Jonghoo Park, Kyu-Jin Cho', 'link': 'https://arxiv.org/abs/2509.12969', 'abstract': 'Anthropomorphic underactuated hands are widely employed for their versatility and structural simplicity. In such systems, compact sensing integration and proper interpretation aligned with underactuation are crucial for realizing practical grasp functionalities. This study proposes an anthropomorphic underactuated hand that achieves comprehensive situational awareness of hand-object interaction, utilizing tendon-based proprioception provided by series elastic actuators (SEAs). We developed a compact SEA with high accuracy and reliability that can be seamlessly integrated into sensorless fingers. By coupling proprioceptive sensing with potential energy-based modeling, the system estimates key grasp-related variables, including contact timing, joint angles, relative object stiffness, and finger configuration changes indicating external disturbances. These estimated variables enable grasp posture reconstruction, safe handling of deformable objects, and blind grasping with proprioceptive-only recognition of objects with varying geometry and stiffness. Finger-level experiments and hand-level demonstrations confirmed the effectiveness of the proposed approach. The results demonstrate that tendon-based proprioception serves as a compact and robust sensing modality for practical manipulation without reliance on vision or tactile feedback.', 'abstract_zh': '类人欠驱动手广泛应用于其灵活性和结构简单性。这类系统中，紧凑的传感整合和与欠驱动相匹配的适当解释对于实现实用的抓取功能至关重要。本研究提出了一种类人欠驱动手，利用系列弹性执行器（SEAs）提供的肌腱基本体感觉实现了对手物交互的全面情境awareness。我们开发了一种高精度和可靠性的紧凑型SEA，并可无缝集成到无传感器指尖中。通过结合本体感受感知与基于势能的建模，系统估计了包括接触时机、关节角度、相对物体刚度以及指示外部干扰的指尖配置变化等关键抓取相关变量。这些估计变量能够重建抓握手姿、安全处理可变形物体，并仅通过本体感觉识别几何和刚度各异的物体实现盲抓。指尖级实验和手级演示验证了所提方法的有效性。研究结果表明，肌腱基本体感觉是一种紧凑且鲁棒的传感模态，可在无需依赖视觉或触觉反馈的情况下实现实际操作。', 'title_zh': '基于肌腱的本体感觉在系列弹性执行器驱动的人类形态学欠驱动机器人手中'}
{'arxiv_id': 'arXiv:2509.12928', 'title': 'Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint', 'authors': 'Peiwen Yang, Mingquan Jiang, Xinyue Shen, Heping Zhang', 'link': 'https://arxiv.org/abs/2509.12928', 'abstract': "Laser vision sensors (LVS) are critical perception modules for industrial robots, facilitating real-time acquisition of workpiece geometric data in welding applications. However, the camera communication delay will lead to a temporal desynchronization between captured images and the robot motions. Additionally, hand-eye extrinsic parameters may vary during prolonged measurement. To address these issues, we introduce a measurement model of LVS considering the effect of the camera's time-offset and propose a teaching-free spatiotemporal calibration method utilizing line constraints. This method involves a robot equipped with an LVS repeatedly scanning straight-line fillet welds using S-shaped trajectories. Regardless of the robot's orientation changes, all measured welding positions are constrained to a straight-line, represented by Plucker coordinates. Moreover, a nonlinear optimization model based on straight-line constraints is established. Subsequently, the Levenberg-Marquardt algorithm (LMA) is employed to optimize parameters, including time-offset, hand-eye extrinsic parameters, and straight-line parameters. The feasibility and accuracy of the proposed approach are quantitatively validated through experiments on curved weld scanning. We open-sourced the code, dataset, and simulation report at this https URL.", 'abstract_zh': '激光视觉传感器（LVS）是工业机器人的重要感知模块，能够在焊接应用中实现焊接件几何数据的实时获取。然而，摄像头通信延迟会导致捕获图像与机器人运动之间的时间同步偏差。此外，手眼外部参数在长时间测量中可能会发生变化。为此，我们引入了一个考虑摄像头时间偏移影响的测量模型，并提出了一种基于直线约束的无示教空间时间校准方法。该方法中，配备LVS的机器人使用S形轨迹反复扫描直角焊缝。无论机器人方向如何变化，所有测量到的焊点位置都被限制在一条直线上，由普拉克鲁斯坐标表示。此外，基于直线约束建立了一个非线性优化模型。随后，采用Levenberg-Marquardt算法（LMA）优化时间偏移、手眼外部参数和直线参数。通过弯曲焊缝扫描实验定量验证了所提出方法的可行性和准确性。我们在以下网址开源了代码、数据集和仿真报告：这个 https URL。', 'title_zh': '基于直线约束的手眼系统激光视觉传感器时空标定'}
{'arxiv_id': 'arXiv:2509.12912', 'title': 'Spotting the Unfriendly Robot - Towards better Metrics for Interactions', 'authors': 'Raphael Wenzel, Malte Probst', 'link': 'https://arxiv.org/abs/2509.12912', 'abstract': 'Establishing standardized metrics for Social Robot Navigation (SRN) algorithms for assessing the quality and social compliance of robot behavior around humans is essential for SRN research. Currently, commonly used evaluation metrics lack the ability to quantify how cooperative an agent behaves in interaction with humans. Concretely, in a simple frontal approach scenario, no metric specifically captures if both agents cooperate or if one agent stays on collision course and the other agent is forced to evade. To address this limitation, we propose two new metrics, a conflict intensity metric and the responsibility metric. Together, these metrics are capable of evaluating the quality of human-robot interactions by showing how much a given algorithm has contributed to reducing a conflict and which agent actually took responsibility of the resolution. This work aims to contribute to the development of a comprehensive and standardized evaluation methodology for SRN, ultimately enhancing the safety, efficiency, and social acceptance of robots in human-centric environments.', 'abstract_zh': '建立标准化的评估指标以评估社交机器人导航（SRN）算法的人类交互质量和社交合规性是SRN研究中的essential。目前常用的评估指标无法量化代理在与人类交互中的合作程度。具体来说，在简单的正面接近场景中，没有指标能够具体捕捉到两个代理是否合作或是一个代理保持在冲撞路径上而另一个代理被迫避开的情况。为了应对这一局限性，我们提出了两个新的评估指标：冲突强度指标和责任指标。这两个指标能够通过展示给定算法在减少冲突中的贡献程度以及哪个代理实际承担了解决责任来评估人类-机器人交互的质量。本工作旨在为SRN开发一个全面和标准化的评估方法，最终增强机器人在以人类为中心环境中的安全性、效率和社会接受度。', 'title_zh': '识别不友好的机器人——朝着更完善的交互评估指标前进'}
{'arxiv_id': 'arXiv:2509.12890', 'title': 'Responsibility and Engagement - Evaluating Interactions in Social Robot Navigation', 'authors': 'Malte Probst, Raphael Wenzel, Monica Dasi', 'link': 'https://arxiv.org/abs/2509.12890', 'abstract': "In Social Robot Navigation (SRN), the availability of meaningful metrics is crucial for evaluating trajectories from human-robot interactions. In the SRN context, such interactions often relate to resolving conflicts between two or more agents. Correspondingly, the shares to which agents contribute to the resolution of such conflicts are important. This paper builds on recent work, which proposed a Responsibility metric capturing such shares. We extend this framework in two directions: First, we model the conflict buildup phase by introducing a time normalization. Second, we propose the related Engagement metric, which captures how the agents' actions intensify a conflict. In a comprehensive series of simulated scenarios with dyadic, group and crowd interactions, we show that the metrics carry meaningful information about the cooperative resolution of conflicts in interactions. They can be used to assess behavior quality and foresightedness. We extensively discuss applicability, design choices and limitations of the proposed metrics.", 'abstract_zh': '在社会机器人导航中的有意义指标对于评估人类-机器人交互的轨迹至关重要。在社会机器人导航的情景中，这些交互往往涉及解决两个或多个代理之间的冲突。相应地，代理对冲突解决所作贡献的比例非常重要。本文在此前工作的基础上，提出了一个责任度量来捕捉这些比例。我们在此框架上进行了两项扩展：首先，通过引入时间归一化来建模冲突积聚阶段；其次，提出了相关的参与度量，用于捕捉代理行为如何加剧冲突。在一系列包含二元、群体和人群交互的模拟场景中，我们展示了这些度量能够携带有关交互中合作解决冲突的重要信息，并可用于评估行为质量和洞察力。我们广泛讨论了所提出度量的适用性、设计选择及其局限性。', 'title_zh': '责任与参与：评估社会机器人导航中的互动'}
{'arxiv_id': 'arXiv:2509.12880', 'title': 'Towards Context-Aware Human-like Pointing Gestures with RL Motion Imitation', 'authors': 'Anna Deichler, Siyang Wang, Simon Alexanderson, Jonas Beskow', 'link': 'https://arxiv.org/abs/2509.12880', 'abstract': 'Pointing is a key mode of interaction with robots, yet most prior work has focused on recognition rather than generation. We present a motion capture dataset of human pointing gestures covering diverse styles, handedness, and spatial targets. Using reinforcement learning with motion imitation, we train policies that reproduce human-like pointing while maximizing precision. Results show our approach enables context-aware pointing behaviors in simulation, balancing task performance with natural dynamics.', 'abstract_zh': '基于运动捕捉的人类指指点 Gestures: 一种用于机器人交互的关键模式，现有研究主要集中在识别而非生成。我们呈现了一个涵盖多种风格、手型和空间目标的人类指指点运动捕捉数据集。通过结合运动模仿和强化学习，我们训练出能够产生类人类指指点行为并最大化精确性的策略。结果表明，该方法能够在仿真中实现上下文感知的指指点行为，平衡任务性能与自然动力学。', 'title_zh': '面向上下文感知的人类般指指点点手势的RL运动模仿研究成果'}
{'arxiv_id': 'arXiv:2509.12863', 'title': 'GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration', 'authors': 'Haozhan Ni, Jingsong Liang, Chenyu He, Yuhong Cao, Guillaume Sartoretti', 'link': 'https://arxiv.org/abs/2509.12863', 'abstract': "Autonomous robot exploration (ARE) is the process of a robot autonomously navigating and mapping an unknown environment. Recent Reinforcement Learning (RL)-based approaches typically formulate ARE as a sequential decision-making problem defined on a collision-free informative graph. However, these methods often demonstrate limited reasoning ability over graph-structured data. Moreover, due to the insufficient consideration of robot motion, the resulting RL policies are generally optimized to minimize travel distance, while neglecting time efficiency. To overcome these limitations, we propose GRATE, a Deep Reinforcement Learning (DRL)-based approach that leverages a Graph Transformer to effectively capture both local structure patterns and global contextual dependencies of the informative graph, thereby enhancing the model's reasoning capability across the entire environment. In addition, we deploy a Kalman filter to smooth the waypoint outputs, ensuring that the resulting path is kinodynamically feasible for the robot to follow. Experimental results demonstrate that our method exhibits better exploration efficiency (up to 21.5% in distance and 21.3% in time to complete exploration) than state-of-the-art conventional and learning-based baselines in various simulation benchmarks. We also validate our planner in real-world scenarios.", 'abstract_zh': '自主机器人探索（ARE）是机器人自主导航和绘制未知环境的过程。基于强化学习（RL）的最新方法通常将ARE表述为定义在无碰撞信息图上的序贯决策问题。然而，这些方法在处理基于图的数据时往往表现出有限的推理能力。此外，由于对机器人运动考虑不足，导致产生的RL策略通常优化为最小化行驶距离，而忽视了时间效率。为克服这些限制，我们提出了一种基于深度强化学习（DRL）的方法GRATE，该方法利用图变换器有效地捕捉信息图的局部结构模式和全局上下文依赖性，从而增强模型在整个环境中的推理能力。此外，我们部署卡尔曼滤波器来平滑航点输出，确保生成的路径对机器人来说是保形可动的。实验结果表明，与各类传统和基于学习的竞争 baseline 方法相比，我们的方法在各种仿真基准测试中表现出更好的探索效率（在距离方面可达21.5%，时间方面可达21.3%）。我们也验证了我们的规划器在实际场景中的应用。', 'title_zh': 'GRATE：基于图变换器的深度强化学习时间高效自主机器人探索方法'}
{'arxiv_id': 'arXiv:2509.12858', 'title': 'Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion', 'authors': 'Yidan Lu, Rurui Yang, Qiran Kou, Mengting Chen, Tao Fan, Peter Cui, Yinzhao Dong, Peng Lu', 'link': 'https://arxiv.org/abs/2509.12858', 'abstract': 'Reinforcement learning has produced remarkable advances in humanoid locomotion, yet a fundamental dilemma persists for real-world deployment: policies must choose between the robustness of reactive proprioceptive control or the proactivity of complex, fragile perception-driven systems. This paper resolves this dilemma by introducing a paradigm that imbues a purely proprioceptive policy with proactive capabilities, achieving the foresight of perception without its deployment-time costs. Our core contribution is a contrastive learning framework that compels the actor\'s latent state to encode privileged environmental information from simulation. Crucially, this ``distilled awareness" empowers an adaptive gait clock, allowing the policy to proactively adjust its rhythm based on an inferred understanding of the terrain. This synergy resolves the classic trade-off between rigid, clocked gaits and unstable clock-free policies. We validate our approach with zero-shot sim-to-real transfer to a full-sized humanoid, demonstrating highly robust locomotion over challenging terrains, including 30 cm high steps and 26.5° slopes, proving the effectiveness of our method. Website: this https URL.', 'abstract_zh': '强化学习在人形机器人运动控制方面取得了显著进展，但仍存在实际部署中的根本性难题：策略必须在反应性的本体感受控制的稳健性和基于复杂感知的系统预测性之间做出选择。本文通过引入一种框架，赋予纯粹本体感受策略以预测性能力，实现了感知的前瞻性而不增加部署时的成本。我们的核心贡献是一种对比学习框架，迫使演员的潜在状态编码来自仿真的特权环境信息。这一“提炼的意识”赋予了自适应步态时钟能力，使策略能够根据对地形的推断理解主动调整其节奏。这种协同作用解决了刚性、定时步态与不稳定、无定时策略的经典权衡。我们通过零样本仿真实验到现实世界的转移验证了该方法，在全尺寸人形机器人上实现了对挑战性地形的高稳健性运动，包括30 cm高的台阶和26.5°的斜坡，证明了该方法的有效性。网站：https://this.url', 'title_zh': '稳健的适应性人形行走从仿真到现实的知识转移的对比表示学习'}
{'arxiv_id': 'arXiv:2509.12851', 'title': "A Novel Skill Modeling Approach: Integrating Vergnaud's Scheme with Cognitive Architectures", 'authors': 'Antoine Lénat, Olivier Cheminat, Damien Chablat, Camilo Charron', 'link': 'https://arxiv.org/abs/2509.12851', 'abstract': "Human-machine interaction is increasingly important in industry, and this trend will only intensify with the rise of Industry 5.0. Human operators have skills that need to be adapted when using machines to achieve the best results. It is crucial to highlight the operator's skills and understand how they use and adapt them [18]. A rigorous description of these skills is necessary to compare performance with and without robot assistance. Predicate logic, used by Vergnaud within Piaget's scheme concept, offers a promising approach. However, this theory doesn't account for cognitive system constraints, such as the timing of actions, the limitation of cognitive resources, the parallelization of tasks, or the activation of automatic gestures contrary to optimal knowledge. Integrating these constraints is essential for representing agent skills understanding skill transfer between biological and mechanical structures. Cognitive architectures models [2] address these needs by describing cognitive structure and can be combined with the scheme for mutual benefit. Welding provides a relevant case study, as it highlights the challenges faced by operators, even highly skilled ones. Welding's complexity stems from the need for constant skill adaptation to variable parameters like part position and process. This adaptation is crucial, as weld quality, a key factor, is only assessed afterward via destructive testing. Thus, the welder is confronted with a complex perception-decision-action cycle, where the evaluation of the impact of his actions is delayed and where errors are definitive. This dynamic underscores the importance of understanding and modeling the skills of operators.", 'abstract_zh': '人机交互在工业中日益重要，随着Industry 5.0的发展这一趋势将进一步加剧。当使用机器时，操作员需要具备适应技能以实现最佳效果。阐明操作员技能并理解其使用和适应方式至关重要。对这些技能的严格描述对于在有无机器人辅助的情况下比较性能至关重要。Piaget方案概念中的Vergnaud所使用的谓词逻辑提供了一种有前景的方法。然而，这一理论没有考虑诸如动作的时间性、认知资源的限制、任务的并行化或与最优知识相反的自动手势等认知系统约束。将这些约束整合进技能的理解中对于代表智能体技能并理解生物结构与机械结构间技能转移是必要的。通过描述认知结构的认知架构模型能够满足这些需求并能与方案相结合以相互受益。焊接提供了相关的案例研究，它强调了即使是高度熟练的操作员也面临的挑战。焊接的复杂性源于对不断变化的参数（如部件位置和过程）持续技能适应的需求。这种适应至关重要，因为焊缝质量——关键因素——只能在事后通过破坏性测试评估。因此，焊工面对一个复杂的感知-决策-行动循环，其行动影响的评估被推迟且错误是不可逆的。这种动态突显了理解并建模操作员技能的重要性。', 'title_zh': '一种新型技能建模方法：结合维赣杜方案与认知架构'}
{'arxiv_id': 'arXiv:2509.12846', 'title': 'Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration', 'authors': 'Junlin Song, Antoine Richard, Miguel Olivares-Mendez', 'link': 'https://arxiv.org/abs/2509.12846', 'abstract': 'Visual-inertial fusion is crucial for a large amount of intelligent and autonomous applications, such as robot navigation and augmented reality. To bootstrap and achieve optimal state estimation, the spatial-temporal displacements between IMU and cameras must be calibrated in advance. Most existing calibration methods adopt continuous-time state representation, more specifically the B-spline. Despite these methods achieve precise spatial-temporal calibration, they suffer from high computational cost caused by continuous-time state representation. To this end, we propose a novel and extremely efficient calibration method that unleashes the power of discrete-time state representation. Moreover, the weakness of discrete-time state representation in temporal calibration is tackled in this paper. With the increasing production of drones, cellphones and other visual-inertial platforms, if one million devices need calibration around the world, saving one minute for the calibration of each device means saving 2083 work days in total. To benefit both the research and industry communities, our code will be open-source.', 'abstract_zh': '视觉-惯性融合在大量智能自主应用中至关重要，如机器人导航和增强现实。为了初始化并实现最优状态估计，必须提前校准imu和摄像头之间的时空位移。现有的大多数校准方法采用连续时间状态表示，具体为B样条表示。尽管这些方法能够实现精确的时空校准，但由于连续时间状态表示导致了较高的计算成本。为了解决这一问题，我们提出了一种新颖且极其高效的校准方法，利用离散时间状态表示的强大功能。此外，本文还解决了离散时间状态表示在时间校准中的不足。随着无人机、手机和其他视觉-惯性平台的生产增加，如果全球有一百万台设备需要校准，那么为每台设备节省一分钟校准时间就意味着总共可以节省2083个工作日。为了同时惠及研究和工业界，我们的代码将开源。', 'title_zh': '解锁离散时间状态表示的潜力：基于目标的IMU-相机时空超快校准'}
{'arxiv_id': 'arXiv:2509.12838', 'title': 'Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models', 'authors': 'Kento Murata, Shoichi Hasegawa, Tomochika Ishikawa, Yoshinobu Hagiwara, Akira Taniguchi, Lotfi El Hafi, Tadahiro Taniguchi', 'link': 'https://arxiv.org/abs/2509.12838', 'abstract': 'It is crucial to efficiently execute instructions such as "Find an apple and a banana" or "Get ready for a field trip," which require searching for multiple objects or understanding context-dependent commands. This study addresses the challenging problem of determining which robot should be assigned to which part of a task when each robot possesses different situational on-site knowledge-specifically, spatial concepts learned from the area designated to it by the user. We propose a task planning framework that leverages large language models (LLMs) and spatial concepts to decompose natural language instructions into subtasks and allocate them to multiple robots. We designed a novel few-shot prompting strategy that enables LLMs to infer required objects from ambiguous commands and decompose them into appropriate subtasks. In our experiments, the proposed method achieved 47/50 successful assignments, outperforming random (28/50) and commonsense-based assignment (26/50). Furthermore, we conducted qualitative evaluations using two actual mobile manipulators. The results demonstrated that our framework could handle instructions, including those involving ad hoc categories such as "Get ready for a field trip," by successfully performing task decomposition, assignment, sequential planning, and execution.', 'abstract_zh': '高效执行如“找到一个苹果和一根香蕉”或“准备野外 trip”等指令的研究，这些指令需要寻找多个对象或理解情境依赖的命令至关重要。本文解决了每个机器人拥有不同现场情境知识（特别是用户指定区域的空间概念）时，确定哪些机器人执行任务中哪些部分的难题。我们提出了一种利用大型语言模型（LLMs）和空间概念的任务规划框架，将自然语言指令分解为子任务并分配给多个机器人。我们设计了一种新颖的少样本提示策略，使LLMs能够从含糊的命令中推断出所需的对象并将其分解为适当的子任务。在我们的实验中，所提出的方法成功分配了47/50次任务，优于随机分配（28/50）和基于常识的分配（26/50）。此外，我们使用两台实际的移动操作机器人进行了定性评估。结果表明，我们的框架能够处理包括涉及临时类别（如“准备野外 trip”）的指令，通过成功地进行任务分解、任务分配、顺序规划和执行来应对这些指令。', 'title_zh': '基于分布式现场知识的大语言模型支持的多机器人多对象检索任务规划'}
{'arxiv_id': 'arXiv:2509.12813', 'title': 'Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks', 'authors': 'Bowen Ye, Junyue Huang, Yang Liu, Xiaozhen Qiao, Xiang Yin', 'link': 'https://arxiv.org/abs/2509.12813', 'abstract': 'We investigate the task and motion planning problem for Signal Temporal Logic (STL) specifications in robotics. Existing STL methods rely on pre-defined maps or mobility representations, which are ineffective in unstructured real-world environments. We propose the \\emph{Structured-MoE STL Planner} (\\textbf{S-MSP}), a differentiable framework that maps synchronized multi-view camera observations and an STL specification directly to a feasible trajectory. S-MSP integrates STL constraints within a unified pipeline, trained with a composite loss that combines trajectory reconstruction and STL robustness. A \\emph{structure-aware} Mixture-of-Experts (MoE) model enables horizon-aware specialization by projecting sub-tasks into temporally anchored embeddings. We evaluate S-MSP using a high-fidelity simulation of factory-logistics scenarios with temporally constrained tasks. Experiments show that S-MSP outperforms single-expert baselines in STL satisfaction and trajectory feasibility. A rule-based \\emph{safety filter} at inference improves physical executability without compromising logical correctness, showcasing the practicality of the approach.', 'abstract_zh': '我们探讨了机器人领域中基于信号时序逻辑(STL)规范的任务与运动规划问题。现有的STL方法依赖于预定义的地图或移动表示，在不结构化的现实环境中效果不佳。我们提出了一种可微框架\\emph{结构化-MoE STL规划器}(S-MSP)，它可以将同步的多视角摄像机观测和STL规范直接映射到一个可行的轨迹。S-MSP在统一管道中整合STL约束，并通过结合轨迹重建和STL鲁棒性的复合损失进行训练。一种\\emph{结构感知}的Mixture-of-Experts(MoE)模型通过将子任务投影到时间锚定的嵌入中实现了前瞻性的专业化。我们在具有时间约束任务的高保真工厂物流场景仿真中评估了S-MSP。实验结果显示，S-MSP在STL满足和轨迹可行性方面优于单专家基线方法。推理中的基于规则的安全过滤器可以提高物理可执行性而不牺牲逻辑正确性，展示了该方法的实际应用价值。', 'title_zh': '从知觉到规划：面向信号时态逻辑任务的端到端规划'}
{'arxiv_id': 'arXiv:2509.12776', 'title': 'Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing', 'authors': 'Renjie Wang, Shangke Lyu, Xin Lang, Wei Xiao, Donglin Wang', 'link': 'https://arxiv.org/abs/2509.12776', 'abstract': "Jumping constitutes an essential component of quadruped robots' locomotion capabilities, which includes dynamic take-off and adaptive landing. Existing quadrupedal jumping studies mainly focused on the stance and flight phase by assuming a flat landing ground, which is impractical in many real world cases. This work proposes a safe landing framework that achieves adaptive landing on rough terrains by combining Trajectory Optimization (TO) and Reinforcement Learning (RL) together. The RL agent learns to track the reference motion generated by TO in the environments with rough terrains. To enable the learning of compliant landing skills on challenging terrains, a reward relaxation strategy is synthesized to encourage exploration during landing recovery period. Extensive experiments validate the accurate tracking and safe landing skills benefiting from our proposed method in various scenarios.", 'abstract_zh': '四足机器人在崎岖地形上实现自适应安全着陆的轨迹优化与强化学习结合框架', 'title_zh': '基于地形自适应着陆的四足跳跃轨迹优化与强化学习集成方法'}
{'arxiv_id': 'arXiv:2509.12754', 'title': 'Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model', 'authors': 'Saki Hashimoto, Shoichi Hasegawa, Tomochika Ishikawa, Akira Taniguchi, Yoshinobu Hagiwara, Lotfi El Hafi, Tadahiro Taniguchi', 'link': 'https://arxiv.org/abs/2509.12754', 'abstract': "Robots operating in domestic and office environments must understand object ownership to correctly execute instructions such as ``Bring me my cup.'' However, ownership cannot be reliably inferred from visual features alone. To address this gap, we propose Active Ownership Learning (ActOwL), a framework that enables robots to actively generate and ask ownership-related questions to users. ActOwL employs a probabilistic generative model to select questions that maximize information gain, thereby acquiring ownership knowledge efficiently to improve learning efficiency. Additionally, by leveraging commonsense knowledge from Large Language Models (LLM), objects are pre-classified as either shared or owned, and only owned objects are targeted for questioning. Through experiments in a simulated home environment and a real-world laboratory setting, ActOwL achieved significantly higher ownership clustering accuracy with fewer questions than baseline methods. These findings demonstrate the effectiveness of combining active inference with LLM-guided commonsense reasoning, advancing the capability of robots to acquire ownership knowledge for practical and socially appropriate task execution.", 'abstract_zh': '在家庭和办公环境操作的机器人必须理解物体的所有权，以正确执行如“给我我的杯子”等指令。然而，所有权仅从视觉特征中无法可靠推断。为解决这一问题，我们提出了主动所有权学习（ActOwL）框架，该框架使机器人能够主动生成和向用户提问相关所有权问题。ActOwL 使用概率生成模型来选择能最大化信息获取的问题，从而高效地获取所有权知识，提高学习效率。此外，通过利用大型语言模型（LLM）的常识知识，物体被预先分类为共有或专属，仅对专属物体进行提问。通过在模拟家庭环境和实际实验室中的实验，ActOwL 在 fewer 问题下实现了显著更高的所有权聚类准确率。这些发现表明，结合主动推理与 LLM 引导的常识推理的有效性，提升了机器人获取所有权知识的能力，以执行实际且社会上适当的任务。', 'title_zh': '面向对象所有权理解的主动问题生成：大规模语言模型与概率生成模型相结合'}
{'arxiv_id': 'arXiv:2509.12747', 'title': 'NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts', 'authors': 'Botao He, Amir Hossein Shahidzadeh, Yu Chen, Jiayi Wu, Tianrui Guan, Guofei Chen, Howie Choset, Dinesh Manocha, Glen Chou, Cornelia Fermuller, Yiannis Aloimonos', 'link': 'https://arxiv.org/abs/2509.12747', 'abstract': 'This paper explores traversability estimation for robot navigation. A key bottleneck in traversability estimation lies in efficiently achieving reliable and robust predictions while accurately encoding both geometric and semantic information across diverse environments. We introduce Navigation via Mixture of Experts (NAVMOE), a hierarchical and modular approach for traversability estimation and local navigation. NAVMOE combines multiple specialized models for specific terrain types, each of which can be either a classical model-based or a learning-based approach that predicts traversability for specific terrain types. NAVMOE dynamically weights the contributions of different models based on the input environment through a gating network. Overall, our approach offers three advantages: First, NAVMOE enables traversability estimation to adaptively leverage specialized approaches for different terrains, which enhances generalization across diverse and unseen environments. Second, our approach significantly improves efficiency with negligible cost of solution quality by introducing a training-free lazy gating mechanism, which is designed to minimize the number of activated experts during inference. Third, our approach uses a two-stage training strategy that enables the training for the gating networks within the hybrid MoE method that contains nondifferentiable modules. Extensive experiments show that NAVMOE delivers a better efficiency and performance balance than any individual expert or full ensemble across different domains, improving cross- domain generalization and reducing average computational cost by 81.2% via lazy gating, with less than a 2% loss in path quality.', 'abstract_zh': '基于专家混合的机器人导航可通行性估计', 'title_zh': 'NavMoE: 结合模型和学习的专家混合模型在局部导航中的 traversability 估计'}
{'arxiv_id': 'arXiv:2509.12741', 'title': 'Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions', 'authors': 'Alexis Yihong Hao, Yufei Wang, Navin Sriram Ravie, Bharath Hegde, David Held, Zackory Erickson', 'link': 'https://arxiv.org/abs/2509.12741', 'abstract': "Robot-assisted dressing has the potential to significantly improve the lives of individuals with mobility impairments. To ensure an effective and comfortable dressing experience, the robot must be able to handle challenging deformable garments, apply appropriate forces, and adapt to limb movements throughout the dressing process. Prior work often makes simplifying assumptions -- such as static human limbs during dressing -- which limits real-world applicability. In this work, we develop a robot-assisted dressing system capable of handling partial observations with visual occlusions, as well as robustly adapting to arm motions during the dressing process. Given a policy trained in simulation with partial observations, we propose a method to fine-tune it in the real world using a small amount of data and multi-modal feedback from vision and force sensing, to further improve the policy's adaptability to arm motions and enhance safety. We evaluate our method in simulation with simplified articulated human meshes and in a real world human study with 12 participants across 264 dressing trials. Our policy successfully dresses two long-sleeve everyday garments onto the participants while being adaptive to various kinds of arm motions, and greatly outperforms prior baselines in terms of task completion and user feedback. Video are available at this https URL.", 'abstract_zh': '辅助机器人穿戴服装有潜力显著改善行动障碍个体的生活质量。为了确保有效的穿衣体验，机器人必须能够处理具有挑战性的可变形衣物、施加适当的力，并在穿衣过程中适应肢体运动。以往的工作往往做出简化假设——例如，在穿衣过程中静止的肢体——这限制了其在现实世界中的应用。在本工作中，我们开发了一种能够处理部分观测和视觉遮挡、并在穿衣过程中 robust 地适应手臂运动的辅助机器人穿戴系统。给定在部分观测环境下训练的策略，我们提出了一种方法，利用少量数据和来自视觉和力觉的多模态反馈，在真实世界中进一步 fine-tune 策略，以提高其对手臂运动的适应性并增强安全性。我们在简化的人体网格模拟中评估了该方法，并在包含 12 名参与者的 264 次穿衣试验的真实世界人体研究中进行了评估。我们的策略成功地将两件长袖日常衣物穿戴在参与者身上，能够适应各种类型的手臂运动，并在任务完成和用户体验方面显著优于之前的基线方法。视频见此链接: [提供链接的URL]。', 'title_zh': '基于力调节的视觉策略辅助机器人穿衣动作指导'}
{'arxiv_id': 'arXiv:2509.12740', 'title': 'Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0', 'authors': 'Eric Guiffo Kaigom', 'link': 'https://arxiv.org/abs/2509.12740', 'abstract': 'Robots are unrelentingly used to achieve operational efficiency in Industry 4.0 along with symbiotic and sustainable assistance for the work-force in Industry 5.0. As resilience, robustness, and well-being are required in anti-fragile manufacturing and human-centric societal tasks, an autonomous anticipation and adaption to thermal saturation and burns due to motors overheating become instrumental for human safety and robot availability. Robots are thereby expected to self-sustain their performance and deliver user experience, in addition to communicating their capability to other agents in advance to ensure fully automated thermally feasible tasks, and prolong their lifetime without human intervention. However, the traditional robot shutdown, when facing an imminent thermal saturation, inhibits productivity in factories and comfort in the society, while cooling strategies are hard to implement after the robot acquisition. In this work, smart digital twins endowed with generative AI, i.e., variational autoencoders, are leveraged to manage thermally anomalous and generate uncritical robot states. The notion of thermal difficulty is derived from the reconstruction error of variational autoencoders. A robot can use this score to predict, anticipate, and share the thermal feasibility of desired motion profiles to meet requirements from emerging applications in Industry 6.0 and Society 6.0.', 'abstract_zh': '工业4.0中机器人用于实现运营效率，而工业5.0中则提供共生和可持续的辅助。随着抗脆弱制造和以人为本的社会任务对韧性和福祉的要求，自主预测和应对由于电机过热引起的热饱和和烧伤变得对于人类安全和机器人可用性至关重要。机器人不仅应自我维持性能并提供用户 Experience，而且还要提前与其他代理通信以确保全自动热可行任务并延长其寿命，无需人工干预。然而，当面临即将出现的热饱和时，传统的机器人关机抑制了工厂的生产力和社会的舒适度，而冷却策略在机器人投入使用后难以实施。在此工作中，配备了生成性AI（变分自编码器）的智能数字孪生被用于管理热异常并生成非危急的机器人状态。热难度的概念源自于变分自编码器的重构误差。机器人可以使用此评分来预测、预见并分享所需运动轮廓的热可行性，以满足工业6.0和社会6.0新兴应用的需求。', 'title_zh': '具有变分自编码器的深生成和判别数字孪生在工业6.0和社会6.0中无监督预测物理机器人热条件监测'}
{'arxiv_id': 'arXiv:2509.12739', 'title': 'Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors', 'authors': 'Trung Kien La, Eric Guiffo Kaigom', 'link': 'https://arxiv.org/abs/2509.12739', 'abstract': 'In this work, deep neural networks made up of multiple hidden Long Short-Term Memory (LSTM) and Feedforward layers are trained to predict the thermal behavior of the joint motors of robot manipulators. A model-free and scalable approach is adopted. It accommodates complexity and uncertainty challenges stemming from the derivation, identification, and validation of a large number of parameters of an approximation model that is hardly available. To this end, sensed joint torques are collected and processed to foresee the thermal behavior of joint motors. Promising prediction results of the machine learning based capture of the temperature dynamics of joint motors of a redundant robot with seven joints are presented.', 'abstract_zh': '基于多隐层Long Short-Term Memory和前馈层的深层神经网络用于预测冗余机器人七关节电机的热行为', 'title_zh': '基于深度学习的无模型机器人关节电机热状态预测'}
{'arxiv_id': 'arXiv:2509.12723', 'title': 'NAMOUnc: Navigation Among Movable Obstacles with Decision Making on Uncertainty Interval', 'authors': 'Kai Zhang, Eric Lucet, Julien Alexandre Dit Sandretto, Shoubin Chen, David Filait', 'link': 'https://arxiv.org/abs/2509.12723', 'abstract': 'Navigation among movable obstacles (NAMO) is a critical task in robotics, often challenged by real-world uncertainties such as observation noise, model approximations, action failures, and partial observability. Existing solutions frequently assume ideal conditions, leading to suboptimal or risky decisions. This paper introduces NAMOUnc, a novel framework designed to address these uncertainties by integrating them into the decision-making process. We first estimate them and compare the corresponding time cost intervals for removing and bypassing obstacles, optimizing both the success rate and time efficiency, ensuring safer and more efficient navigation. We validate our method through extensive simulations and real-world experiments, demonstrating significant improvements over existing NAMO frameworks. More details can be found in our website: this https URL', 'abstract_zh': '移动障碍中导航（NAMOUnc）：一种考虑不确定性的新型框架', 'title_zh': '基于不确定性区间决策的移动障碍物导航'}
{'arxiv_id': 'arXiv:2509.12714', 'title': 'MoiréTac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moiré Pattern Amplification', 'authors': 'Kit-Wa Sou, Junhao Gong, Shoujie Li, Chuqiao Lyu, Ziwu Song, Shilong Mu, Wenbo Ding', 'link': 'https://arxiv.org/abs/2509.12714', 'abstract': 'Visuotactile sensors typically employ sparse marker arrays that limit spatial resolution and lack clear analytical force-to-image relationships. To solve this problem, we present \\textbf{MoiréTac}, a dual-mode sensor that generates dense interference patterns via overlapping micro-gratings within a transparent architecture. When two gratings overlap with misalignment, they create moiré patterns that amplify microscopic deformations. The design preserves optical clarity for vision tasks while producing continuous moiré fields for tactile sensing, enabling simultaneous 6-axis force/torque measurement, contact localization, and visual perception. We combine physics-based features (brightness, phase gradient, orientation, and period) from moiré patterns with deep spatial features. These are mapped to 6-axis force/torque measurements, enabling interpretable regression through end-to-end learning. Experimental results demonstrate three capabilities: force/torque measurement with R^2 > 0.98 across tested axes; sensitivity tuning through geometric parameters (threefold gain adjustment); and vision functionality for object classification despite moiré overlay. Finally, we integrate the sensor into a robotic arm for cap removal with coordinated force and torque control, validating its potential for dexterous manipulation.', 'abstract_zh': 'MoiréTac：一种基于莫尔纹的双模态传感器', 'title_zh': 'MoiréTac: 一种基于莫尔图案放大效应的双模式视触觉传感器多维感知方法'}
{'arxiv_id': 'arXiv:2509.12702', 'title': 'UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints', 'authors': 'Hongrui Zhao, Xunlan Zhou, Boris Ivanovic, Negar Mehr', 'link': 'https://arxiv.org/abs/2509.12702', 'abstract': 'Multi-robot mapping with neural implicit representations enables the compact reconstruction of complex environments. However, it demands robustness against communication challenges like packet loss and limited bandwidth. While prior works have introduced various mechanisms to mitigate communication disruptions, performance degradation still occurs under extremely low communication success rates. This paper presents UDON, a real-time multi-agent neural implicit mapping framework that introduces a novel uncertainty-weighted distributed optimization to achieve high-quality mapping under severe communication deterioration. The uncertainty weighting prioritizes more reliable portions of the map, while the distributed optimization isolates and penalizes mapping disagreement between individual pairs of communicating agents. We conduct extensive experiments on standard benchmark datasets and real-world robot hardware. We demonstrate that UDON significantly outperforms existing baselines, maintaining high-fidelity reconstructions and consistent scene representations even under extreme communication degradation (as low as 1% success rate).', 'abstract_zh': '神经隐式表示下的多机器人映射框架UDON：在严重通信降级下实现高质量映射', 'title_zh': 'UDON：在极端通信约束下的多机器人神经隐式地图构建的不确定性加权分布式优化方法'}
{'arxiv_id': 'arXiv:2509.12674', 'title': 'Safety filtering of robotic manipulation under environment uncertainty: a computational approach', 'authors': 'Anna Johansson, Daniel Lindmark, Viktor Wiberg, Martin Servin', 'link': 'https://arxiv.org/abs/2509.12674', 'abstract': 'Robotic manipulation in dynamic and unstructured environments requires safety mechanisms that exploit what is known and what is uncertain about the world. Existing safety filters often assume full observability, limiting their applicability in real-world tasks. We propose a physics-based safety filtering scheme that leverages high-fidelity simulation to assess control policies under uncertainty in world parameters. The method combines dense rollout with nominal parameters and parallelizable sparse re-evaluation at critical state-transitions, quantified through generalized factors of safety for stable grasping and actuator limits, and targeted uncertainty reduction through probing actions. We demonstrate the approach in a simulated bimanual manipulation task with uncertain object mass and friction, showing that unsafe trajectories can be identified and filtered efficiently. Our results highlight physics-based sparse safety evaluation as a scalable strategy for safe robotic manipulation under uncertainty.', 'abstract_zh': '基于物理的动态和未结构化环境中的机器人操作安全过滤方案', 'title_zh': '机器人操作在环境不确定性下的安全过滤：一种计算方法'}
{'arxiv_id': 'arXiv:2509.12620', 'title': 'PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion', 'authors': 'Yikai Chen, Zhi Zheng, Jin Wang, Bingye He, Xiangyu Xu, Jialu Zhang, Huan Yu, Guodong Lu', 'link': 'https://arxiv.org/abs/2509.12620', 'abstract': 'Achieving seamless integration of aerial flight, ground driving, and wall climbing within a single robotic platform remains a major challenge, as existing designs often rely on additional adhesion actuators that increase complexity, reduce efficiency, and compromise reliability. To address these limitations, we present PerchMobi^3, a quad-fan, negative-pressure, air-ground-wall robot that implements a propulsion-adhesion power-reuse mechanism. By repurposing four ducted fans to simultaneously provide aerial thrust and negative-pressure adhesion, and integrating them with four actively driven wheels, PerchMobi^3 eliminates dedicated pumps while maintaining a lightweight and compact design. To the best of our knowledge, this is the first quad-fan prototype to demonstrate functional power reuse for multi-modal locomotion. A modeling and control framework enables coordinated operation across ground, wall, and aerial domains with fan-assisted transitions. The feasibility of the design is validated through a comprehensive set of experiments covering ground driving, payload-assisted wall climbing, aerial flight, and cross-mode transitions, demonstrating robust adaptability across locomotion scenarios. These results highlight the potential of PerchMobi^3 as a novel design paradigm for multi-modal robotic mobility, paving the way for future extensions toward autonomous and application-oriented deployment.', 'abstract_zh': '实现单一机器人平台在空中飞行、地面行驶和墙体攀爬之间的无缝集成仍然是一个主要挑战，现有设计往往依赖额外的吸附执行器，增加了复杂性、降低了效率并损害了可靠性。为了解决这些限制，我们介绍了PerchMobi^3，这是一种四风扇、负压、空地墙机器人，实现了推进-吸附动力重用机制。通过将四个通道风扇重新用于同时提供空中推力和负压吸附，并与四个主动驱动轮集成，PerchMobi^3消除了专用泵的需求，同时保持了轻量化和紧凑的设计。据我们所知，这是首个展示多模态运动功能动力重用的四风扇原型。通过风扇辅助的协调操作框架，实现在地面、墙面和空中领域的协调运行。通过涵盖地面行驶、负载辅助墙体攀爬、空中飞行和多模式过渡的全面实验，验证了该设计的可行性，展示了其在运动场景中的稳健适应能力。这些结果突显了PerchMobi^3作为多模态机器人移动新型设计范式的潜在价值，为未来的自主和应用导向部署铺平了道路。', 'title_zh': 'PerchMobi³: 具有电源复用四扇机制的多模态机器人实现空地墙运动'}
{'arxiv_id': 'arXiv:2509.12618', 'title': 'ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation', 'authors': 'Zekai Zhang, Weiye Zhu, Hewei Pan, Xiangchen Wang, Rongtao Xu, Xing Sun, Feng Zheng', 'link': 'https://arxiv.org/abs/2509.12618', 'abstract': "The Vision-and-Language Navigation (VLN) task requires an agent to follow natural language instructions and navigate through complex environments. Existing MLLM-based VLN methods primarily rely on imitation learning (IL) and often use DAgger for post-training to mitigate covariate shift. While effective, these approaches incur substantial data collection and training costs. Reinforcement learning (RL) offers a promising alternative. However, prior VLN RL methods lack dynamic interaction with the environment and depend on expert trajectories for reward shaping, rather than engaging in open-ended active exploration. This restricts the agent's ability to discover diverse and plausible navigation routes. To address these limitations, we propose ActiveVLN, a VLN framework that explicitly enables active exploration through multi-turn RL. In the first stage, a small fraction of expert trajectories is used for IL to bootstrap the agent. In the second stage, the agent iteratively predicts and executes actions, automatically collects diverse trajectories, and optimizes multiple rollouts via the GRPO objective. To further improve RL efficiency, we introduce a dynamic early-stopping strategy to prune long-tail or likely failed trajectories, along with additional engineering optimizations. Experiments show that ActiveVLN achieves the largest performance gains over IL baselines compared to both DAgger-based and prior RL-based post-training methods, while reaching competitive performance with state-of-the-art approaches despite using a smaller model. Code and data will be released soon.", 'abstract_zh': '基于视线-语言导航（VLN）的任务要求智能体遵循自然语言指令并在复杂环境中导航。现有的基于多模态预训练语言模型的VLN方法主要依赖于模仿学习（IL），并且常常使用DAgger在后续训练中减轻协变量移位。虽然这些方法有效，但它们会带来大量数据收集和训练成本。强化学习（RL）提供了有前景的替代方案。然而，之前的VLN RL方法缺乏与环境的动态交互，并依赖于专家轨迹用于奖励塑造，而不是进行开放式的主动探索。这限制了智能体发现多样化和合理导航路径的能力。为了解决这些限制，我们提出了ActiveVLN，这是一种通过多回合RL明确促进主动探索的VLN框架。在第一阶段，使用少量的专家轨迹进行IL以引导智能体。在第二阶段，智能体迭代地预测和执行动作，自动收集多样化的轨迹，并通过GRPO目标优化多个滚动部署。为了进一步提高RL的效率，我们引入了动态提前停止策略来修剪长尾或很可能失败的轨迹，并且还进行了额外的工程优化。实验结果表明，与基于DAgger的和之前的基于RL的后续训练方法相比，ActiveVLN在IL基线下实现了最大的性能提升，尽管使用了较小的模型，其性能仍可与现有最先进的方法竞争。代码和数据将很快发布。', 'title_zh': 'ActiveVLN：通过多轮RL在视觉语言导航中实现主动探索'}
{'arxiv_id': 'arXiv:2509.12594', 'title': 'The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning', 'authors': 'Titong Jiang, Xuefeng Jiang, Yuan Ma, Xin Wen, Bailin Li, Kun Zhan, Peng Jia, Yahui Liu, Sheng Sun, Xianpeng Lang', 'link': 'https://arxiv.org/abs/2509.12594', 'abstract': 'We present LightVLA, a simple yet effective differentiable token pruning framework for vision-language-action (VLA) models. While VLA models have shown impressive capability in executing real-world robotic tasks, their deployment on resource-constrained platforms is often bottlenecked by the heavy attention-based computation over large sets of visual tokens. LightVLA addresses this challenge through adaptive, performance-driven pruning of visual tokens: It generates dynamic queries to evaluate visual token importance, and adopts Gumbel softmax to enable differentiable token selection. Through fine-tuning, LightVLA learns to preserve the most informative visual tokens while pruning tokens which do not contribute to task execution, thereby improving efficiency and performance simultaneously. Notably, LightVLA requires no heuristic magic numbers and introduces no additional trainable parameters, making it compatible with modern inference frameworks. Experimental results demonstrate that LightVLA outperforms different VLA models and existing token pruning methods across diverse tasks on the LIBERO benchmark, achieving higher success rates with substantially reduced computational overhead. Specifically, LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9% improvement in task success rate. Meanwhile, we also investigate the learnable query-based token pruning method LightVLA* with additional trainable parameters, which also achieves satisfactory performance. Our work reveals that as VLA pursues optimal performance, LightVLA spontaneously learns to prune tokens from a performance-driven perspective. To the best of our knowledge, LightVLA is the first work to apply adaptive visual token pruning to VLA tasks with the collateral goals of efficiency and performance, marking a significant step toward more efficient, powerful and practical real-time robotic systems.', 'abstract_zh': '轻量级VLA：一种简单的高效可微视觉令牌剪枝框架', 'title_zh': '你学得越好，修剪得越聪明：通过可微分 tokens 修剪 towards 效率更高的视觉-语言-行动模型'}
{'arxiv_id': 'arXiv:2509.12562', 'title': 'Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling', 'authors': 'Zhefei Gong, Shangke Lyu, Pengxiang Ding, Wei Xiao, Donglin Wang', 'link': 'https://arxiv.org/abs/2509.12562', 'abstract': 'Imitation learning (IL) enables efficient skill acquisition from demonstrations but often struggles with long-horizon tasks and high-precision control due to compounding errors. Residual policy learning offers a promising, model-agnostic solution by refining a base policy through closed-loop corrections. However, existing approaches primarily focus on local corrections to the base policy, lacking a global understanding of state evolution, which limits robustness and generalization to unseen scenarios. To address this, we propose incorporating global dynamics modeling to guide residual policy updates. Specifically, we leverage Koopman operator theory to impose linear time-invariant structure in a learned latent space, enabling reliable state transitions and improved extrapolation for long-horizon prediction and unseen environments. We introduce KORR (Koopman-guided Online Residual Refinement), a simple yet effective framework that conditions residual corrections on Koopman-predicted latent states, enabling globally informed and stable action refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture assembly tasks under various perturbations. Results demonstrate consistent gains in performance, robustness, and generalization over strong baselines. Our findings further highlight the potential of Koopman-based modeling to bridge modern learning methods with classical control theory.', 'abstract_zh': '基于科氏算子的全局动力学建模引导的残差策略在线精炼（KORR）', 'title_zh': '基于Koopman引导动力学建模的鲁棒在线残差精修'}
{'arxiv_id': 'arXiv:2509.12531', 'title': 'Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning', 'authors': 'Scott Jones, Liyou Zhou, Sebastian W. Pattinson', 'link': 'https://arxiv.org/abs/2509.12531', 'abstract': "In visuomotor policy learning, the control policy for the robotic agent is derived directly from visual inputs. The typical approach, where a policy and vision encoder are trained jointly from scratch, generalizes poorly to novel visual scene changes. Using pre-trained vision models (PVMs) to inform a policy network improves robustness in model-free reinforcement learning (MFRL). Recent developments in Model-based reinforcement learning (MBRL) suggest that MBRL is more sample-efficient than MFRL. However, counterintuitively, existing work has found PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness in MBRL, specifically on generalization under visual domain shifts. We show that, in scenarios with severe shifts, PVMs perform much better than a baseline model trained from scratch. We further investigate the effects of varying levels of fine-tuning of PVMs. Our results show that partial fine-tuning can maintain the highest average task performance under the most extreme distribution shifts. Our results demonstrate that PVMs are highly successful in promoting robustness in visual policy learning, providing compelling evidence for their wider adoption in model-based robotic learning applications.", 'abstract_zh': '基于模型的强化学习中预训练视觉模型在视觉域移变下的泛化效果研究', 'title_zh': '基于模型的强化学习中，预训练视觉表示在关键位置泛化'}
{'arxiv_id': 'arXiv:2509.12516', 'title': 'Zero to Autonomy in Real-Time: Online Adaptation of Dynamics in Unstructured Environments', 'authors': 'William Ward, Sarah Etter, Jesse Quattrociocchi, Christian Ellis, Adam J. Thorpe, Ufuk Topcu', 'link': 'https://arxiv.org/abs/2509.12516', 'abstract': 'Autonomous robots must go from zero prior knowledge to safe control within seconds to operate in unstructured environments. Abrupt terrain changes, such as a sudden transition to ice, create dynamics shifts that can destabilize planners unless the model adapts in real-time. We present a method for online adaptation that combines function encoders with recursive least squares, treating the function encoder coefficients as latent states updated from streaming odometry. This yields constant-time coefficient estimation without gradient-based inner-loop updates, enabling adaptation from only a few seconds of data. We evaluate our approach on a Van der Pol system to highlight algorithmic behavior, in a Unity simulator for high-fidelity off-road navigation, and on a Clearpath Jackal robot, including on a challenging terrain at a local ice rink. Across these settings, our method improves model accuracy and downstream planning, reducing collisions compared to static and meta-learning baselines.', 'abstract_zh': '自主机器人必须在几秒内从零先验知识过渡到安全控制，以在无结构环境中操作。突然的地形变化，如突然过渡到冰面，会导致动力学变化，除非模型能够实时适应，则可能使规划者失去稳定性。我们提出了一种在线适应方法，该方法结合了函数编码器和逐次最小二乘法，并将函数编码器系数视为从滑动里程计流数据中更新的潜在状态。这使得可以实现常数时间的系数估计，而无需基于梯度的内部循环更新，从而仅需少量数据即可实现适应。我们在范德ポール系统上评估了该方法以突出算法行为，在Unity模拟器中进行了高保真离线道路导航评估，并在Clearpath Jackal机器人上进行了评估，包括在本地溜冰场具有挑战性的地形上。在这些设置中，我们的方法提高了模型精度和下游规划，减少了与静态基准和元学习基准的碰撞。', 'title_zh': '从零到自主：不结构化环境中的实时动力学在线调整'}
{'arxiv_id': 'arXiv:2509.12507', 'title': 'Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents', 'authors': 'Anna Deichler, Siyang Wang, Simon Alexanderson, Jonas Beskow', 'link': 'https://arxiv.org/abs/2509.12507', 'abstract': 'One of the main goals of robotics and intelligent agent research is to enable natural communication with humans in physically situated settings. While recent work has focused on verbal modes such as language and speech, non-verbal communication is crucial for flexible interaction. We present a framework for generating pointing gestures in embodied agents by combining imitation and reinforcement learning. Using a small motion capture dataset, our method learns a motor control policy that produces physically valid, naturalistic gestures with high referential accuracy. We evaluate the approach against supervised learning and retrieval baselines in both objective metrics and a virtual reality referential game with human users. Results show that our system achieves higher naturalness and accuracy than state-of-the-art supervised models, highlighting the promise of imitation-RL for communicative gesture generation and its potential application to robots.', 'abstract_zh': '机器人与智能代理研究的一个主要目标是在物理环境下实现自然的人机沟通。虽然最近的工作集中在语言和语音等口头交流模式上，但非口头交流对于灵活交互至关重要。我们提出了一种通过结合模仿和强化学习生成身体代理指示手势的框架。使用少量的运动捕获数据集，我们的方法学习到了一种产生物理上有效、自然且具有高指代准确性的运动控制策略。我们在客观指标评估和基于虚拟现实的指代游戏中，将该方法与监督学习和检索基线进行对比。结果显示，与最先进的监督学习模型相比，我们的系统在自然度和准确性方面表现出更优，这表明模仿-强化学习在生成交际手势方面的潜力及其在机器人领域的应用前景。', 'title_zh': '学习生成情境化实体对话代理的指向手势'}
{'arxiv_id': 'arXiv:2509.12468', 'title': 'Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains', 'authors': 'Shipeng Liu, Meghana Sagare, Shubham Patil, Feifei Qian', 'link': 'https://arxiv.org/abs/2509.12468', 'abstract': 'Deformable substrates such as sand and mud present significant challenges for terrestrial robots due to complex robot-terrain interactions. Inspired by mudskippers, amphibious animals that naturally adjust their tail morphology and movement jointly to navigate such environments, we investigate how tail design and control can jointly enhance flipper-driven locomotion on granular media. Using a bio-inspired robot modeled after the mudskipper, we experimentally compared locomotion performance between idle and actively oscillating tail configurations. Tail oscillation increased robot speed by 67% and reduced body drag by 46%. Shear force measurements revealed that this improvement was enabled by tail oscillation fluidizing the substrate, thereby reducing resistance. Additionally, tail morphology strongly influenced the oscillation strategy: designs with larger horizontal surface areas leveraged the oscillation-reduced shear resistance more effectively by limiting insertion depth. Based on these findings, we present a design principle to inform tail action selection based on substrate strength and tail morphology. Our results offer new insights into tail design and control for improving robot locomotion on deformable substrates, with implications for agricultural robotics, search and rescue, and environmental exploration.', 'abstract_zh': '可变形基底如沙土给地面机器人带来复杂的机器人-地形相互作用挑战。受到能自然调节尾部形态和运动以在复杂环境中移动的跳,},\nuser\n重写一下，保持原意，禁止出现机器翻译的生硬痕迹。', 'title_zh': '受生物启发的尾部摆动使机器人能够快速爬行于可变形的颗粒地形上'}
{'arxiv_id': 'arXiv:2509.12458', 'title': 'Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles', 'authors': 'Àlmos Veres-Vitàlyos, Genis Castillo Gomez-Raya, Filip Lemic, Daniel Johannes Bugelnig, Bernhard Rinner, Sergi Abadal, Xavier Costa-Pérez', 'link': 'https://arxiv.org/abs/2509.12458', 'abstract': "Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for navigating indoor and hard-to-reach areas, yet their significant constraints in payload and autonomy have largely prevented their use for complex tasks like high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we introduce a novel system architecture that enables fully autonomous, high-fidelity 3D scanning of static objects using UAVs weighing under 100 grams. Our core innovation lies in a dual-reconstruction pipeline that creates a real-time feedback loop between data capture and flight control. A near-real-time (near-RT) process uses Structure from Motion (SfM) to generate an instantaneous pointcloud of the object. The system analyzes the model quality on the fly and dynamically adapts the UAV's trajectory to intelligently capture new images of poorly covered areas. This ensures comprehensive data acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR) approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB) location data to achieve superior accuracy. We implemented and validated this architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both single- and multi-UAV configurations, conclusively show that dynamic trajectory adaptation consistently improves reconstruction quality over static flight paths. This work demonstrates a scalable and autonomous solution that unlocks the potential of miniaturized UAVs for fine-grained 3D reconstruction in constrained environments, a capability previously limited to much larger platforms.", 'abstract_zh': '小型无人驾驶飞机（UAVs）在导航室内和难以到达区域方面展现出巨大的潜力，但由于其显著的载重和自主性限制，它们在执行高精度三维重建等复杂任务方面应用受限。为克服这一挑战，我们提出了一种新型系统架构，使用重量低于100克的无人驾驶飞机实现完全自主的高保真三维静态对象扫描。我们的核心创新在于一种双重建管道，它创建了数据采集与飞行控制之间的实时反馈循环。一个近实时（near-RT）过程使用结构从运动（SfM）生成对象的即时点云。系统在飞行过程中动态分析模型质量，并智能调整无人机的飞行轨迹以捕获未覆盖区域的新图像，从而确保全面的数据采集。对于最终的详细输出，一个非实时（non-RT）管道采用基于神经辐射场（NeRF）的神经三维重建（N3DR）方法，结合SfM提取的相机姿态和精确的超宽带（UWB）位置数据，以实现更高的准确性。我们利用Crazyflie 2.1无人机实现了并验证了这一架构。在单机和多机配置下的实验一致证明，动态轨迹调整可以提高重建质量。本研究展示了可扩展且自主的解决方案，解锁了微型化无人机在受限环境中的微米级三维重建潜力，这一能力此前仅限于更大的平台。', 'title_zh': '小型无人机辅助的神经网络三维对象重建'}
{'arxiv_id': 'arXiv:2509.12444', 'title': 'Computing forward statics from tendon-length in flexible-joint hyper-redundant manipulators', 'authors': 'Weiting Feng, Kyle L. Walker, Yunjie Yang, Francesco Giorgio-Serchi', 'link': 'https://arxiv.org/abs/2509.12444', 'abstract': 'Hyper-redundant tendon-driven manipulators of- fer greater flexibility and compliance over traditional manipu- lators. A common way of controlling such manipulators relies on adjusting tendon lengths, which is an accessible control parameter. This approach works well when the kinematic configuration is representative of the real operational con- ditions. However, when dealing with manipulators of larger size subject to gravity, it becomes necessary to solve a static force problem, using tendon force as the input and employing a mapping from the configuration space to retrieve tendon length. Alternatively, measurements of the manipulator posture can be used to iteratively adjust tendon lengths to achieve a desired posture. Hence, either tension measurement or state estimation of the manipulator are required, both of which are not always accurately available. Here, we propose a solution by reconciling cables tension and length as the input for the solution of the system forward statics. We develop a screw-based formulation for a tendon-driven, multi-segment, hyper-redundant manipulator with elastic joints and introduce a forward statics iterative solution method that equivalently makes use of either tendon length or tension as the input. This strategy is experimentally validated using a traditional tension input first, subsequently showing the efficacy of the method when exclusively tendon lengths are used. The results confirm the possibility to perform open-loop control in static conditions using a kinematic input only, thus bypassing some of the practical problems with tension measurement and state estimation of hyper-redundant systems.', 'abstract_zh': '超冗余缆驱动 manipulator 提供了比传统 manipulator 更大的灵活性和顺应性。控制这类 manipulator 的常见方法是调节缆绳长度，这是一种可访问的控制参数。当运动配置能代表实际操作条件时，这种方法效果很好。然而，处理受到重力影响的较大尺寸 manipulator 时，需要解决一个静态力问题，将缆绳力作为输入，并通过从配置空间映射来检索缆绳长度。此外，还可以通过迭代调整缆绳长度来利用 manipulator 的姿势测量来实现期望的姿势。因此，无论是张力测量还是 manipulator 的状态估计都是必要的，而这两者并不总是准确可用的。这里，我们提出一种解决方案，即通过将缆绳张力和长度作为解决系统静力学前向问题的输入来调和缆绳的张力和长度。我们为具有弹性关节的缆绳驱动多段超冗余 manipulator 开发了一种基于螺钉的公式，并提出了一种等效地将缆绳长度或张力作为输入的前向静力学迭代解决方案方法。该策略首先使用传统张力输入在实验中得到验证，并随后表明在仅使用缆绳长度时该方法的有效性。结果证实，在静态条件下仅使用运动输入即可实现开环控制的可能性，从而绕过了绷紧度测量和超冗余系统状态估计的一些实用问题。', 'title_zh': '从柔性关节超冗余 manipulator 的肌腱长度计算前向静态特性'}
{'arxiv_id': 'arXiv:2509.12398', 'title': 'MinJointTracker: Real-time inertial kinematic chain tracking with joint position estimation and minimal state size', 'authors': 'Michael Lorenz, Bertram Taetz, Gabriele Bleser-Taetz, Didier Stricker', 'link': 'https://arxiv.org/abs/2509.12398', 'abstract': 'Inertial motion capture is a promising approach for capturing motion outside the laboratory. However, as one major drawback, most of the current methods require different quantities to be calibrated or computed offline as part of the setup process, such as segment lengths, relative orientations between inertial measurement units (IMUs) and segment coordinate frames (IMU-to-segment calibrations) or the joint positions in the IMU frames. This renders the setup process inconvenient. This work contributes to real-time capable calibration-free inertial tracking of a kinematic chain, i.e. simultaneous recursive Bayesian estimation of global IMU angular kinematics and joint positions in the IMU frames, with a minimal state size. Experimental results on simulated IMU data from a three-link kinematic chain (manipulator study) as well as re-simulated IMU data from healthy humans walking (lower body study) show that the calibration-free and lightweight algorithm provides not only drift-free relative but also drift-free absolute orientation estimates with a global heading reference for only one IMU as well as robust and fast convergence of joint position estimates in the different movement scenarios.', 'abstract_zh': '无校准的惯性链实时动力学跟踪：基于最小状态的递归贝叶斯估计', 'title_zh': 'MinJointTracker：基于关节位置估计和最小状态尺寸的实时惯性运动链跟踪'}
{'arxiv_id': 'arXiv:2509.12390', 'title': 'Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems', 'authors': 'Evangelos Psomiadis, Panagiotis Tsiotras', 'link': 'https://arxiv.org/abs/2509.12390', 'abstract': 'This paper addresses the problem of collaborative formation control for multi-agent systems with limited resources. We consider a team of robots tasked with achieving a desired formation from arbitrary initial configurations. To reduce unnecessary control updates and conserve resources, we propose a distributed event-triggered formation controller that relies on inter-agent distance measurements. Control updates are triggered only when the measurement error exceeds a predefined threshold, ensuring system stability. The proposed controller is validated through extensive simulations and real-world experiments involving different formations, communication topologies, scalability tests, and variations in design parameters, while also being compared against periodic triggering strategies. Results demonstrate that the event-triggered approach significantly reduces control efforts while preserving formation performance.', 'abstract_zh': '本文解决了资源受限条件下多Agent系统协作 formations控制的问题。我们考虑了一组机器人从任意初始配置实现期望 formations的任务。为了减少不必要的控制更新并节约资源，我们提出了一种基于集群内距离测量的分布式事件触发 formations控制器。当测量误差超过预定义阈值时才进行控制更新，以确保系统稳定性。通过广泛的仿真实验和现实世界实验验证了所提出的控制器，实验涉及不同的 formations、通信拓扑、可扩展性测试以及设计参数的变化，并且将事件触发策略与周期性触发策略进行了比较。结果表明，事件触发方法可以显著减少控制努力，同时保持 formations性能。', 'title_zh': '分布式基于事件触发的距离导向多agent系统结构控制'}
{'arxiv_id': 'arXiv:2509.12379', 'title': 'Geometric Red-Teaming for Robotic Manipulation', 'authors': 'Divyam Goel, Yufei Wang, Tiancheng Wu, Guixiu Qiao, Pavel Piliptchak, David Held, Zackory Erickson', 'link': 'https://arxiv.org/abs/2509.12379', 'abstract': 'Standard evaluation protocols in robotic manipulation typically assess policy performance over curated, in-distribution test sets, offering limited insight into how systems fail under plausible variation. We introduce Geometric Red-Teaming (GRT), a red-teaming framework that probes robustness through object-centric geometric perturbations, automatically generating CrashShapes -- structurally valid, user-constrained mesh deformations that trigger catastrophic failures in pre-trained manipulation policies. The method integrates a Jacobian field-based deformation model with a gradient-free, simulator-in-the-loop optimization strategy. Across insertion, articulation, and grasping tasks, GRT consistently discovers deformations that collapse policy performance, revealing brittle failure modes missed by static benchmarks. By combining task-level policy rollouts with constraint-aware shape exploration, we aim to build a general purpose framework for structured, object-centric robustness evaluation in robotic manipulation. We additionally show that fine-tuning on individual CrashShapes, a process we refer to as blue-teaming, improves task success by up to 60 percentage points on those shapes, while preserving performance on the original object, demonstrating the utility of red-teamed geometries for targeted policy refinement. Finally, we validate both red-teaming and blue-teaming results with a real robotic arm, observing that simulated CrashShapes reduce task success from 90% to as low as 22.5%, and that blue-teaming recovers performance to up to 90% on the corresponding real-world geometry -- closely matching simulation outcomes. Videos and code can be found on our project website: this https URL .', 'abstract_zh': '几何红蓝组理论（GRT）：一种通过对象中心的几何扰动探查鲁棒性的框架', 'title_zh': '几何红队演练以提升机器人操作能力'}
{'arxiv_id': 'arXiv:2509.12367', 'title': 'An integrated process for design and control of lunar robotics using AI and simulation', 'authors': 'Daniel Lindmark, Jonas Andersson, Kenneth Bodin, Tora Bodin, Hugo Börjesson, Fredrik Nordfeldth, Martin Servin', 'link': 'https://arxiv.org/abs/2509.12367', 'abstract': 'We envision an integrated process for developing lunar construction equipment, where physical design and control are explored in parallel. In this paper, we describe a technical framework that supports this process. It relies on OpenPLX, a readable/writable declarative language that links CAD-models and autonomous systems to high-fidelity, real-time 3D simulations of contacting multibody dynamics, machine regolith interaction forces, and non-ideal sensors. To demonstrate its capabilities, we present two case studies, including an autonomous lunar rover that combines a vision-language model for navigation with a reinforcement learning-based control policy for locomotion.', 'abstract_zh': '我们设想了一种集成过程，用于开发月球建设设备，在这个过程中，物理设计和控制是并行探索的。在本文中，我们描述了一个支持这一过程的技术框架。该框架依赖于OpenPLX，这是一种可读可写的声明性语言，连接CAD模型和自主系统，实现高保真实时多体动力学、机器与月壤相互作用力以及非理想传感器的3D仿真。为了展示其能力，我们呈现了两个案例研究，包括一个结合了视觉语言模型导航和基于强化学习的运动控制策略的自主月球车。', 'title_zh': '基于AI和模拟的月球机器人设计与控制集成过程'}
{'arxiv_id': 'arXiv:2509.13288', 'title': 'Shapes of Cognition for Computational Cognitive Modeling', 'authors': 'Marjorie McShane, Sergei Nirenburg, Sanjay Oruganti, Jesse English', 'link': 'https://arxiv.org/abs/2509.13288', 'abstract': 'Shapes of cognition is a new conceptual paradigm for the computational cognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are remembered constellations of sensory, linguistic, conceptual, episodic, and procedural knowledge that allow agents to cut through the complexity of real life the same way as people do: by expecting things to be typical, recognizing patterns, acting by habit, reasoning by analogy, satisficing, and generally minimizing cognitive load to the degree situations permit. Atypical outcomes are treated using shapes-based recovery methods, such as learning on the fly, asking a human partner for help, or seeking an actionable, even if imperfect, situational understanding. Although shapes is an umbrella term, it is not vague: shapes-based modeling involves particular objectives, hypotheses, modeling strategies, knowledge bases, and actual models of wide-ranging phenomena, all implemented within a particular cognitive architecture. Such specificity is needed both to vet our hypotheses and to achieve our practical aims of building useful agent systems that are explainable, extensible, and worthy of our trust, even in critical domains. However, although the LEIA example of shapes-based modeling is specific, the principles can be applied more broadly, giving new life to knowledge-based and hybrid AI.', 'abstract_zh': '认知形态是一种新的概念范式，用于语言赋权智能代理（LEIA）的认知计算建模。认知形态是记忆中的感觉、语言、概念、情境和程序知识的星座，使代理能够像人们一样通过期望事物具有典型性、识别模式、习惯性行为、类比推理、满意化以及在情况允许的范围内尽量减少认知负荷来应对现实生活的复杂性。非典型的结果通过基于形态的恢复方法处理，如即时学习、向人类伙伴求助或寻求可行的甚至不完善的 situational 理解。虽然“形态”是一个伞形术语，但它并不模糊：基于形态的建模涉及特定的目标、假设、建模策略、知识库和广泛现象的实际模型，这些都在特定的认知架构内实现。这种具体性不仅有助于验证我们的假设，还有助于实现我们构建可解释、可扩展且值得信赖的有用代理系统的目标，尤其是在关键领域。然而，尽管基于形态的 LEIA 建模是特定的，但这些原则可以更广泛地应用，为基于知识和混合 AI 带来新的活力。', 'title_zh': '认知形态学：面向计算认知建模'}
{'arxiv_id': 'arXiv:2509.13257', 'title': 'Safety Critical Model Predictive Control Using Discrete-Time Control Density Functions', 'authors': 'Sriram S. K. S. Narayanan, Sajad Ahmadi, Javad Mohammadpour Velni, Umesh Vaidya', 'link': 'https://arxiv.org/abs/2509.13257', 'abstract': 'This paper presents MPC-CDF, a new approach integrating control density functions (CDFs) within a model predictive control (MPC) framework to ensure safety-critical control in nonlinear dynamical systems. By using the dual formulation of the navigation problem, we incorporate CDFs into the MPC framework, ensuring both convergence and safety in a discrete-time setting. These density functions are endowed with a physical interpretation, where the associated measure signifies the occupancy of system trajectories. Leveraging this occupancy-based perspective, we synthesize safety-critical controllers using the proposed MPC-CDF framework. We illustrate the safety properties of this framework using a unicycle model and compare it with a control barrier function-based method. The efficacy of this approach is demonstrated in the autonomous safe navigation of an underwater vehicle, which avoids complex and arbitrary obstacles while achieving the desired level of safety.', 'abstract_zh': 'MPC-CDF：一种将控制密度函数集成到模型预测控制框架中的新方法以确保非线性动力系统中的安全关键控制', 'title_zh': '使用离散时间控制密度函数的安全关键模型预测控制'}
{'arxiv_id': 'arXiv:2509.13089', 'title': 'A Synthetic Data Pipeline for Supporting Manufacturing SMEs in Visual Assembly Control', 'authors': 'Jonas Werheid, Shengjie He, Aymen Gannouni, Anas Abdelrazeq, Robert H. Schmitt', 'link': 'https://arxiv.org/abs/2509.13089', 'abstract': 'Quality control of assembly processes is essential in manufacturing to ensure not only the quality of individual components but also their proper integration into the final product. To assist in this matter, automated assembly control using computer vision methods has been widely implemented. However, the costs associated with image acquisition, annotation, and training of computer vision algorithms pose challenges for integration, especially for small- and medium-sized enterprises (SMEs), which often lack the resources for extensive training, data collection, and manual image annotation. Synthetic data offers the potential to reduce manual data collection and labeling. Nevertheless, its practical application in the context of assembly quality remains limited. In this work, we present a novel approach for easily integrable and data-efficient visual assembly control. Our approach leverages simulated scene generation based on computer-aided design (CAD) data and object detection algorithms. The results demonstrate a time-saving pipeline for generating image data in manufacturing environments, achieving a mean Average Precision (mAP@0.5:0.95) up to 99,5% for correctly identifying instances of synthetic planetary gear system components within our simulated training data, and up to 93% when transferred to real-world camera-captured testing data. This research highlights the effectiveness of synthetic data generation within an adaptable pipeline and underscores its potential to support SMEs in implementing resource-efficient visual assembly control solutions.', 'abstract_zh': '基于计算机辅助设计的模拟场景生成与物体检测算法的可整合高效视觉装配控制方法', 'title_zh': '支持制造中小企业在视觉装配控制中使用的合成数据管道'}
{'arxiv_id': 'arXiv:2509.12715', 'title': 'AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models', 'authors': 'Heng Zhang, Haichuan Hu, Yaomin Shen, Weihao Yu, Yilei Yuan, Haochen You, Guo Cheng, Zijian Zhang, Lubin Gan, Huihui Wei, Hao Zhang, Jin Huang', 'link': 'https://arxiv.org/abs/2509.12715', 'abstract': 'Large Vision-Language Models (LVLMs) have demonstrated impressive performance on multimodal tasks through scaled architectures and extensive training. However, existing Mixture of Experts (MoE) approaches face challenges due to the asymmetry between visual and linguistic processing. Visual information is spatially complete, while language requires maintaining sequential context. As a result, MoE models struggle to balance modality-specific features and cross-modal interactions. Through systematic analysis, we observe that language experts in deeper layers progressively lose contextual grounding and rely more on parametric knowledge rather than utilizing the provided visual and linguistic information. To address this, we propose AsyMoE, a novel architecture that models this asymmetry using three specialized expert groups. We design intra-modality experts for modality-specific processing, hyperbolic inter-modality experts for hierarchical cross-modal interactions, and evidence-priority language experts to suppress parametric biases and maintain contextual grounding. Extensive experiments demonstrate that AsyMoE achieves 26.58% and 15.45% accuracy improvements over vanilla MoE and modality-specific MoE respectively, with 25.45% fewer activated parameters than dense models.', 'abstract_zh': '大型多模态语言视觉模型（Large Vision-Language Models）通过扩展架构和大量的训练在多模态任务中表现出色。然而，现有的专家混合（Mixture of Experts, MoE）方法由于视觉处理和语言处理之间的不对称性而面临挑战。视觉信息是空间完备的，而语言需要保持序列上下文。因此，MoE模型难以平衡模态特异性特征和跨模态交互。通过系统分析，我们观察到更深layer的语言专家逐步失去上下文依托，更多依赖于参数性知识，而不是利用提供的视觉和语言信息。为此，我们提出了AsyMoE，这是一种新的架构，使用三个专门的专家组来建模这种不对称性。我们设计了跨模态专家进行模态特异性处理，超曲面跨模态专家进行分层的跨模态交互，以及证据优先级语言专家来抑制参数性偏见并保持上下文依托。 extensive实验表明，与vanilla MoE和模态特异性MoE相比，AsyMoE分别实现了26.58%和15.45%的准确率提升，且与稠密模型相比激活参数减少了25.45%。', 'title_zh': 'AsyMoE: 利用模态不对称性增强大型视觉语言模型专家专业化水平'}
{'arxiv_id': 'arXiv:2509.12250', 'title': 'OnlineHOI: Towards Online Human-Object Interaction Generation and Perception', 'authors': 'Yihong Ji, Yunze Liu, Yiyao Zhuo, Weijiang Yu, Fei Ma, Joshua Huang, Fei Yu', 'link': 'https://arxiv.org/abs/2509.12250', 'abstract': "The perception and generation of Human-Object Interaction (HOI) are crucial for fields such as robotics, AR/VR, and human behavior understanding. However, current approaches model this task in an offline setting, where information at each time step can be drawn from the entire interaction sequence. In contrast, in real-world scenarios, the information available at each time step comes only from the current moment and historical data, i.e., an online setting. We find that offline methods perform poorly in an online context. Based on this observation, we propose two new tasks: Online HOI Generation and Perception. To address this task, we introduce the OnlineHOI framework, a network architecture based on the Mamba framework that employs a memory mechanism. By leveraging Mamba's powerful modeling capabilities for streaming data and the Memory mechanism's efficient integration of historical information, we achieve state-of-the-art results on the Core4D and OAKINK2 online generation tasks, as well as the online HOI4D perception task.", 'abstract_zh': '基于内存机制的Online HOI生成与感知', 'title_zh': 'OnlineHOI: 向往在线人类对象交互生成与感知'}
{'arxiv_id': 'arXiv:2509.12207', 'title': 'UrgenGo: Urgency-Aware Transparent GPU Kernel Launching for Autonomous Driving', 'authors': 'Hanqi Zhu, Wuyang Zhang, Xinran Zhang, Ziyang Tao, Xinrui Lin, Yu Zhang, Jianmin Ji, Yanyong Zhang', 'link': 'https://arxiv.org/abs/2509.12207', 'abstract': 'The rapid advancements in autonomous driving have introduced increasingly complex, real-time GPU-bound tasks critical for reliable vehicle operation. However, the proprietary nature of these autonomous systems and closed-source GPU drivers hinder fine-grained control over GPU executions, often resulting in missed deadlines that compromise vehicle performance. To address this, we present UrgenGo, a non-intrusive, urgency-aware GPU scheduling system that operates without access to application source code. UrgenGo implicitly prioritizes GPU executions through transparent kernel launch manipulation, employing task-level stream binding, delayed kernel launching, and batched kernel launch synchronization. We conducted extensive real-world evaluations in collaboration with a self-driving startup, developing 11 GPU-bound task chains for a realistic autonomous navigation application and implementing our system on a self-driving bus. Our results show a significant 61% reduction in the overall deadline miss ratio, compared to the state-of-the-art GPU scheduler that requires source code modifications.', 'abstract_zh': '自主驾驶的快速进步引入了越来越多复杂且实时的GPU绑定任务，对于可靠的车辆操作至关重要。然而，这些自主系统的专有性质以及封闭源代码的GPU驱动程序阻碍了对GPU执行的细粒度控制，常常导致错过deadline，影响车辆性能。为解决这一问题，我们提出了UrgenGo，这是一个非侵入性、具有紧迫性感知的GPU调度系统，无需访问应用程序源代码。UrgenGo 通过透明的内核启动操作优先级排序，采用任务级流绑定、延迟内核启动和批量内核启动同步策略。我们与一家自动驾驶初创公司合作进行了广泛的实地评估，在真实的自动驾驶导航应用中开发了11条GPU绑定任务链，并在其自动驾驶巴士上实现了该系统。结果显示，与需要源代码修改的最先进的GPU调度器相比，整体错过deadline的比例显著降低了61%。', 'title_zh': 'UrgenGo: 基于 urgency 意识的透明 GPU 内核启动技术及其在自动驾驶中的应用'}
