# Do Chains-of-Thoughts of Large Language Models Suffer from Hallucinations, Cognitive Biases, or Phobias in Bayesian Reasoning? 

**Title (ZH)**: 大型语言模型的Chain-of-Thoughts会受到幻觉、认知偏见或贝叶斯推理恐惧症的影响吗？ 

**Authors**: Roberto Araya  

**Link**: [PDF](https://arxiv.org/pdf/2503.15268)  

**Abstract**: Learning to reason and carefully explain arguments is central to students' cognitive, mathematical, and computational thinking development. This is particularly challenging in problems under uncertainty and in Bayesian reasoning. With the new generation of large language models (LLMs) capable of reasoning using Chain-of-Thought (CoT), there is an excellent opportunity to learn with them as they explain their reasoning through a dialogue with their artificial internal voice. It is an engaging and excellent opportunity to learn Bayesian reasoning. Furthermore, given that different LLMs sometimes arrive at opposite solutions, CoT generates opportunities for deep learning by detailed comparisons of reasonings. However, unlike humans, we found that they do not autonomously explain using ecologically valid strategies like natural frequencies, whole objects, and embodied heuristics. This is unfortunate, as these strategies help humans avoid critical mistakes and have proven pedagogical value in Bayesian reasoning. In order to overcome these biases and aid understanding and learning, we included prompts that induce LLMs to use these strategies. We found that LLMs with CoT incorporate them but not consistently. They show persistent biases towards symbolic reasoning and avoidance or phobia of ecologically valid strategies. 

**Abstract (ZH)**: 学习推理和谨慎解释论证是学生认知、数学和计算思维发展中的核心。特别是在不确定性问题和贝叶斯推理中，这是一个尤为挑战性的任务。随着新一代大语言模型（LLMs）能够使用链式思考（CoT）进行推理，通过它们与人工内部语音的对话来解释其推理过程，学习贝叶斯推理成为一个引人入胜且优秀的契机。此外，由于不同的LLMs有时会得出完全相反的解决方案，CoT为通过仔细比较推理过程来进行深入学习提供了机会。然而，与人类不同，我们发现它们并未自主使用诸如自然频率、整体对象和体态启发法等生态有效策略进行解释。这令人遗憾，因为这些策略有助于人类避免关键错误，在贝叶斯推理中具有教学价值。为了克服这些偏见并促进理解和学习，我们加入了促使LLMs使用这些策略的提示。我们发现，具有CoT的LLMs可以融入这些策略，但不够一致。它们表现出持续倾向于符号推理，并避免或恐惧生态有效策略的偏见。 

---
# World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child 

**Title (ZH)**: 人工智能中的世界模型：像孩子一样感知、学习和推理 

**Authors**: Javier Del Ser, Jesus L. Lobo, Heimo Müller, Andreas Holzinger  

**Link**: [PDF](https://arxiv.org/pdf/2503.15168)  

**Abstract**: World Models help Artificial Intelligence (AI) predict outcomes, reason about its environment, and guide decision-making. While widely used in reinforcement learning, they lack the structured, adaptive representations that even young children intuitively develop. Advancing beyond pattern recognition requires dynamic, interpretable frameworks inspired by Piaget's cognitive development theory. We highlight six key research areas -- physics-informed learning, neurosymbolic learning, continual learning, causal inference, human-in-the-loop AI, and responsible AI -- as essential for enabling true reasoning in AI. By integrating statistical learning with advances in these areas, AI can evolve from pattern recognition to genuine understanding, adaptation and reasoning capabilities. 

**Abstract (ZH)**: 世界模型助力人工智能预测结果、推理论证其环境并指导决策。尽管在强化学习中广泛应用，但它们缺乏甚至幼儿都能直观发展的结构化和适应性表示。超越模式识别需要基于皮亚杰认知发展理论的动态可解释框架。我们强调六项关键研究领域——物理导向学习、神经符号学习、持续学习、因果推理、人力在环人工智能和负责任人工智能——对于实现真正的人工智能推理至关重要。通过将统计学习与这些领域的进展相结合，人工智能可以从模式识别进化到真正的理解、适应和推理能力。 

---
# Aligning Crowd-sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models 

**Title (ZH)**: 基于大规模语言模型的代码生成强化学习中众源人类反馈的对齐方法 

**Authors**: Man Fai Wong, Chee Wei Tan  

**Link**: [PDF](https://arxiv.org/pdf/2503.15129)  

**Abstract**: This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance reinforcement learning (RLHF) with crowd-sourced computation to enhance text-to-code generation. Additionally, we demonstrate that our Bayesian optimization framework supports AI alignment in code generation by distributing the feedback collection burden, highlighting the value of collecting human feedback of good quality. Our empirical evaluations demonstrate the efficacy of this approach, showcasing how LLM agents can be effectively trained for improved text-to-code generation. Our Bayesian optimization framework can be designed for general domain-specific languages, promoting the alignment of large language model capabilities with human feedback in AI-assisted programming for code generation. 

**Abstract (ZH)**: 本文研究了AI辅助编程和大型语言模型（LLM）如何通过GitHub Copilot和Amazon CodeWhisperer等AI工具提升软件开发人员的能力，并结合人类反馈增强强化学习（RLHF），利用crowd-sourced计算提高文本到代码生成能力。此外，我们展示了我们的贝叶斯优化框架如何通过分散反馈收集负担来支持代码生成中的AI对齐，突显高质量人类反馈的价值。我们的实证评估证明了该方法的有效性，展示了如何有效训练LLM代理以提高文本到代码生成能力。我们的贝叶斯优化框架可以适用于通用领域特定语言，促进大型语言模型能力与AI辅助编程中的人类反馈在代码生成中的对齐。 

---
# Reasoning Effort and Problem Complexity: A Scaling Analysis in LLMs 

**Title (ZH)**: 推理努力与问题复杂性：大规模语言模型中的标度分析 

**Authors**: Benjamin Estermann, Roger Wattenhofer  

**Link**: [PDF](https://arxiv.org/pdf/2503.15113)  

**Abstract**: Large Language Models (LLMs) have demonstrated remarkable text generation capabilities, and recent advances in training paradigms have led to breakthroughs in their reasoning performance. In this work, we investigate how the reasoning effort of such models scales with problem complexity. We use the infinitely scalable Tents puzzle, which has a known linear-time solution, to analyze this scaling behavior. Our results show that reasoning effort scales with problem size, but only up to a critical problem complexity. Beyond this threshold, the reasoning effort does not continue to increase, and may even decrease. This observation highlights a critical limitation in the logical coherence of current LLMs as problem complexity increases, and underscores the need for strategies to improve reasoning scalability. Furthermore, our results reveal significant performance differences between current state-of-the-art reasoning models when faced with increasingly complex logical puzzles. 

**Abstract (ZH)**: 大型语言模型的推理努力随着问题复杂性的增加按比例变化：基于无限可扩展Tents谜题的分析 

---
# GraspCorrect: Robotic Grasp Correction via Vision-Language Model-Guided Feedback 

**Title (ZH)**: GraspCorrect: 通过视觉-语言模型引导的抓取校正 

**Authors**: Sungjae Lee, Yeonjoo Hong, Kwang In Kim  

**Link**: [PDF](https://arxiv.org/pdf/2503.15035)  

**Abstract**: Despite significant advancements in robotic manipulation, achieving consistent and stable grasping remains a fundamental challenge, often limiting the successful execution of complex tasks. Our analysis reveals that even state-of-the-art policy models frequently exhibit unstable grasping behaviors, leading to failure cases that create bottlenecks in real-world robotic applications. To address these challenges, we introduce GraspCorrect, a plug-and-play module designed to enhance grasp performance through vision-language model-guided feedback. GraspCorrect employs an iterative visual question-answering framework with two key components: grasp-guided prompting, which incorporates task-specific constraints, and object-aware sampling, which ensures the selection of physically feasible grasp candidates. By iteratively generating intermediate visual goals and translating them into joint-level actions, GraspCorrect significantly improves grasp stability and consistently enhances task success rates across existing policy models in the RLBench and CALVIN datasets. 

**Abstract (ZH)**: 尽管机器人操纵取得了显著进步，但实现一致且稳定的抓取仍然是一个基本挑战，常常限制了复杂任务的成功执行。我们的分析表明，即使是最先进的策略模型也经常表现出不稳定的抓取行为，导致失败案例成为现实世界机器人应用中的瓶颈。为此，我们引入了GraspCorrect模块，这是一种即插即用模块，通过基于视觉语言模型的反馈来提升抓取性能。GraspCorrect采用迭代的视觉问答框架，包含两个关键组件：任务导向的提示，which Incorporates任务特定约束，和物体感知采样，which Ensures physically可行的抓取候选的选取。通过迭代生成中间视觉目标并转化为关节级动作，GraspCorrect显著提升了抓取稳定性，并在现有模型上跨RLBench和CALVIN数据集中的一致提高了任务成功率。 

---
# Behaviour Discovery and Attribution for Explainable Reinforcement Learning 

**Title (ZH)**: 可解释强化学习中的行为发现与归因 

**Authors**: Rishav Rishav, Somjit Nath, Vincent Michalski, Samira Ebrahimi Kahou  

**Link**: [PDF](https://arxiv.org/pdf/2503.14973)  

**Abstract**: Explaining the decisions made by reinforcement learning (RL) agents is critical for building trust and ensuring reliability in real-world applications. Traditional approaches to explainability often rely on saliency analysis, which can be limited in providing actionable insights. Recently, there has been growing interest in attributing RL decisions to specific trajectories within a dataset. However, these methods often generalize explanations to long trajectories, potentially involving multiple distinct behaviors. Often, providing multiple more fine grained explanations would improve clarity. In this work, we propose a framework for behavior discovery and action attribution to behaviors in offline RL trajectories. Our method identifies meaningful behavioral segments, enabling more precise and granular explanations associated with high level agent behaviors. This approach is adaptable across diverse environments with minimal modifications, offering a scalable and versatile solution for behavior discovery and attribution for explainable RL. 

**Abstract (ZH)**: 解释强化学习（RL）代理的决策对于在实际应用中建立信任并确保可靠性至关重要。传统的可解释性方法通常依赖于显著性分析，这在提供 actionable 洞察方面可能有限制。最近，人们越来越关注将 RL 决策归因于数据集中的特定轨迹。然而，这些方法经常将解释泛化到长轨迹中，可能涉及多种不同的行为。通常，提供更细粒度的多个解释会提高清晰度。在本文中，我们提出了一种用于行为发现和行为归因的框架，在离线 RL 轨迹中对行为进行归因。我们的方法识别出有意义的行为片段，使得与高级别代理行为相关的精确和细粒度解释成为可能。该方法在不同环境下的适应性较强，只需少量修改即可提供一种可扩展且多功能的解决方案，以实现可解释的 RL 中的行为发现和归因。 

---
# Generating Causal Explanations of Vehicular Agent Behavioural Interactions with Learnt Reward Profiles 

**Title (ZH)**: 基于学习到的奖励配置文件生成vehicles代理行为交互的因果解释 

**Authors**: Rhys Howard, Nick Hawes, Lars Kunze  

**Link**: [PDF](https://arxiv.org/pdf/2503.14557)  

**Abstract**: Transparency and explainability are important features that responsible autonomous vehicles should possess, particularly when interacting with humans, and causal reasoning offers a strong basis to provide these qualities. However, even if one assumes agents act to maximise some concept of reward, it is difficult to make accurate causal inferences of agent planning without capturing what is of importance to the agent. Thus our work aims to learn a weighting of reward metrics for agents such that explanations for agent interactions can be causally inferred. We validate our approach quantitatively and qualitatively across three real-world driving datasets, demonstrating a functional improvement over previous methods and competitive performance across evaluation metrics. 

**Abstract (ZH)**: 负责任的自动驾驶车辆在与人类交互时，透明度和可解释性是重要的特征，因果推理为此提供了强有力的 basis。然而，即使假设代理行为是为了最大化某种奖励概念，如果不捕捉代理认为重要的内容，也难以做出准确的因果推断。因此，我们的工作旨在学习代理的奖励度量权重，以便能够因果推理代理交互的解释。我们通过跨三个实际驾驶数据集的定量和定性验证，展示了相对于先前方法的功能改进，并且在评估指标上具有竞争力的性能。 

---
# TULIP: Towards Unified Language-Image Pretraining 

**Title (ZH)**: TULIP: 向统一的语言-图像预训练目标迈进 

**Authors**: Zineng Tang, Long Lian, Seun Eisape, XuDong Wang, Roei Herzig, Adam Yala, Alane Suhr, Trevor Darrell, David M. Chan  

**Link**: [PDF](https://arxiv.org/pdf/2503.15485)  

**Abstract**: Despite the recent success of image-text contrastive models like CLIP and SigLIP, these models often struggle with vision-centric tasks that demand high-fidelity image understanding, such as counting, depth estimation, and fine-grained object recognition. These models, by performing language alignment, tend to prioritize high-level semantics over visual understanding, weakening their image understanding. On the other hand, vision-focused models are great at processing visual information but struggle to understand language, limiting their flexibility for language-driven tasks. In this work, we introduce TULIP, an open-source, drop-in replacement for existing CLIP-like models. Our method leverages generative data augmentation, enhanced image-image and text-text contrastive learning, and image/text reconstruction regularization to learn fine-grained visual features while preserving global semantic alignment. Our approach, scaling to over 1B parameters, outperforms existing state-of-the-art (SOTA) models across multiple benchmarks, establishing a new SOTA zero-shot performance on ImageNet-1K, delivering up to a $2\times$ enhancement over SigLIP on RxRx1 in linear probing for few-shot classification, and improving vision-language models, achieving over $3\times$ higher scores than SigLIP on MMVP. Our code/checkpoints are available at this https URL 

**Abstract (ZH)**: 尽管近日图像-文本对比模型如CLIP和SigLIP取得了成功，但这些模型在要求高保真图像理解的任务（如计数、深度估计和细粒度对象识别）中经常表现不佳。通过进行语言对齐，这些模型倾向于优先处理高层语义，而削弱了其图像理解能力。另一方面，专注于视觉的模型擅长处理视觉信息，但在理解和处理语言方面存在局限性，限制了它们在语言驱动任务中的灵活性。在本研究中，我们提出了TULIP，这是一个开源的即插即用替代现有CLIP类似模型的方法。我们的方法利用生成的数据增强、增强的图像-图像和文本-文本对比学习以及图像/文本重建正则化来学习细粒度的视觉特征，同时保持全局语义对齐。我们的方法在超过10亿参数的规模下，在多个基准测试中超过了现有最先进的（SOTA）模型，并在ImageNet-1K上建立了新的SOTA零样本性能，在RxRx1上实现了高达2倍的线性探针少样本分类性能提升，以及在MMVP上实现了SigLIP超过3倍的评分改进。我们的代码/检查点可在以下链接获取。 

---
# Value Profiles for Encoding Human Variation 

**Title (ZH)**: 人类变异的特征表示方法 

**Authors**: Taylor Sorensen, Pushkar Mishra, Roma Patel, Michael Henry Tessler, Michiel Bakker, Georgina Evans, Iason Gabriel, Noah Goodman, Verena Rieser  

**Link**: [PDF](https://arxiv.org/pdf/2503.15484)  

**Abstract**: Modelling human variation in rating tasks is crucial for enabling AI systems for personalization, pluralistic model alignment, and computational social science. We propose representing individuals using value profiles -- natural language descriptions of underlying values compressed from in-context demonstrations -- along with a steerable decoder model to estimate ratings conditioned on a value profile or other rater information. To measure the predictive information in rater representations, we introduce an information-theoretic methodology. We find that demonstrations contain the most information, followed by value profiles and then demographics. However, value profiles offer advantages in terms of scrutability, interpretability, and steerability due to their compressed natural language format. Value profiles effectively compress the useful information from demonstrations (>70% information preservation). Furthermore, clustering value profiles to identify similarly behaving individuals better explains rater variation than the most predictive demographic groupings. Going beyond test set performance, we show that the decoder models interpretably change ratings according to semantic profile differences, are well-calibrated, and can help explain instance-level disagreement by simulating an annotator population. These results demonstrate that value profiles offer novel, predictive ways to describe individual variation beyond demographics or group information. 

**Abstract (ZH)**: 基于价值概况的人类变异建模对于实现个性化AI系统、多元模型对齐以及计算社会科学研究至关重要。我们提出使用价值概况——从情境演示中压缩而成的价值自然语言描述来表示个体，并结合可控解码模型，在给定价值概况或其他评分者信息的情况下估计评分。为了衡量评分者表示中的预测信息量，我们引入了一种信息论方法。研究表明，演示包含最多的信 息，其次是价值概况，然后是人口统计学信息。然而，价值概况因其压缩的自然语言格式而在可核查性、可解释性和可控性方面具有优势。价值概况有效地压缩了演示中的有用信息（>70%的信息保留）。此外，通过聚类价值概况来识别具有类似行为的个体，比最具预测性的群体分组更好地解释了评分者差异。超越测试集性能，我们展示了解码模型根据语义概况差异可解释地改变评分，并且校准良好，可以模拟注释员群体来解释实例级别的分歧。这些结果表明，价值概况提供了超越人口统计学或群体信息的新颖、可预测的方式以描述个体差异。 

---
# Learning to Play Piano in the Real World 

**Title (ZH)**: 在现实世界中学习弹钢琴 

**Authors**: Yves-Simon Zeulner, Sandeep Selvaraj, Roberto Calandra  

**Link**: [PDF](https://arxiv.org/pdf/2503.15481)  

**Abstract**: Towards the grand challenge of achieving human-level manipulation in robots, playing piano is a compelling testbed that requires strategic, precise, and flowing movements. Over the years, several works demonstrated hand-designed controllers on real world piano playing, while other works evaluated robot learning approaches on simulated piano scenarios. In this paper, we develop the first piano playing robotic system that makes use of learning approaches while also being deployed on a real world dexterous robot. Specifically, we make use of Sim2Real to train a policy in simulation using reinforcement learning before deploying the learned policy on a real world dexterous robot. In our experiments, we thoroughly evaluate the interplay between domain randomization and the accuracy of the dynamics model used in simulation. Moreover, we evaluate the robot's performance across multiple songs with varying complexity to study the generalization of our learned policy. By providing a proof-of-concept of learning to play piano in the real world, we want to encourage the community to adopt piano playing as a compelling benchmark towards human-level manipulation. We open-source our code and show additional videos at this https URL . 

**Abstract (ZH)**: 面向实现机器人人类级操作这一伟大挑战，演奏钢琴是一个极具吸引力的测试平台，它要求机器人进行战略性、精确性和流畅性操作。多年来，多项研究表明在真实钢琴上演奏的由手设计的控制器，而其他研究则评估了在模拟钢琴场景中进行机器人学习的方法。在本文中，我们首次开发了一种利用学习方法的钢琴演奏机器人系统，并将其部署在真实的灵巧机器人上。具体而言，我们使用Sim2Real在模拟环境中使用强化学习训练一个策略，然后在真实世界的灵巧机器人上部署所学的策略。在我们的实验中，我们详细评估了领域随机化与所用动力学模型精度之间的相互作用。此外，我们评估了机器人在多首不同难度歌曲上的表现，以研究我们学到的策略的泛化能力。通过提供在真实世界中学习演奏钢琴的概念验证，我们希望鼓励研究界将钢琴演奏作为迈向人类级操作的有吸引力的基准。我们在GitHub上开源了代码，并提供了额外的视频，请访问这个链接：this https URL。 

---
# What Makes a Reward Model a Good Teacher? An Optimization Perspective 

**Title (ZH)**: 奖励模型成为一个好老师的原因：从优化的角度探讨 

**Authors**: Noam Razin, Zixuan Wang, Hubert Strauss, Stanley Wei, Jason D. Lee, Sanjeev Arora  

**Link**: [PDF](https://arxiv.org/pdf/2503.15477)  

**Abstract**: The success of Reinforcement Learning from Human Feedback (RLHF) critically depends on the quality of the reward model. While this quality is primarily evaluated through accuracy, it remains unclear whether accuracy fully captures what makes a reward model an effective teacher. We address this question from an optimization perspective. First, we prove that regardless of how accurate a reward model is, if it induces low reward variance, then the RLHF objective suffers from a flat landscape. Consequently, even a perfectly accurate reward model can lead to extremely slow optimization, underperforming less accurate models that induce higher reward variance. We additionally show that a reward model that works well for one language model can induce low reward variance, and thus a flat objective landscape, for another. These results establish a fundamental limitation of evaluating reward models solely based on accuracy or independently of the language model they guide. Experiments using models of up to 8B parameters corroborate our theory, demonstrating the interplay between reward variance, accuracy, and reward maximization rate. Overall, our findings highlight that beyond accuracy, a reward model needs to induce sufficient variance for efficient optimization. 

**Abstract (ZH)**: 基于人类反馈的强化学习（RLHF）的成功关键取决于奖励模型的质量。从优化的角度回答这一问题，我们证明，无论奖励模型的准确性如何，如果它引起低奖励方差，那么RLHF目标将遭受平坦的景观问题。因此，即使一个完全准确的奖励模型也可能导致极其缓慢的优化，而不如一些准确度较低但引起更高奖励方差的模型表现得好。此外，我们还证明一个适用于一个语言模型的奖励模型可能会为另一个语言模型引起低奖励方差，从而导致平坦的目标景观。这些结果确立了仅根据准确性和独立于所指导的语言模型来评估奖励模型的基本限制。使用多达8B参数的模型进行的实验支持我们的理论，展示了奖励方差、准确性和奖励最大化率之间的相互作用。总体而言，我们的研究结果强调，除了准确性外，奖励模型还需要引起足够的方差以实现高效的优化。 

---
# EgoDTM: Towards 3D-Aware Egocentric Video-Language Pretraining 

**Title (ZH)**: EgoDTM: 面向3Daware 自我中心视频-语言预训练 

**Authors**: Boshen Xu, Yuting Mei, Xinbi Liu, Sipeng Zheng, Qin Jin  

**Link**: [PDF](https://arxiv.org/pdf/2503.15470)  

**Abstract**: Egocentric video-language pretraining has significantly advanced video representation learning. Humans perceive and interact with a fully 3D world, developing spatial awareness that extends beyond text-based understanding. However, most previous works learn from 1D text or 2D visual cues, such as bounding boxes, which inherently lack 3D understanding. To bridge this gap, we introduce EgoDTM, an Egocentric Depth- and Text-aware Model, jointly trained through large-scale 3D-aware video pretraining and video-text contrastive learning. EgoDTM incorporates a lightweight 3D-aware decoder to efficiently learn 3D-awareness from pseudo depth maps generated by depth estimation models. To further facilitate 3D-aware video pretraining, we enrich the original brief captions with hand-object visual cues by organically combining several foundation models. Extensive experiments demonstrate EgoDTM's superior performance across diverse downstream tasks, highlighting its superior 3D-aware visual understanding. Our code will be released at this https URL. 

**Abstract (ZH)**: 自视点视频-语言预训练显著推进了视频表示学习。自视点学习要求人类在三维空间中感知和互动，发展出超越文本理解的空间意识。然而，大多数先前工作主要从一维文本或二维视觉提示，如边界框中学习，这些提示本质上缺乏三维理解。为弥合这一差距，我们提出了EgoDTM，一种结合了轻量级三维意识解码器的自视点深度和文本感知模型，通过大规模三维意识视频预训练和视频-文本对比学习联合训练。为了进一步促进三维意识视频预训练，我们通过有机结合多个基础模型，丰富了原始简要说明，加入了手-物体视觉提示。广泛的实验表明，EgoDTM在多种下游任务中表现出卓越的性能，突显了其优越的三维意识视觉理解能力。我们的代码将在以下链接释放：这个 https URL。 

---
# Dynamic Bi-Elman Attention Networks (DBEAN): Dual-Directional Context-Aware Representation Learning for Enhanced Text Classification 

**Title (ZH)**: 动态双方向上下文感知注意力网络（DBEAN）：增强文本分类的双向上下文表示学习 

**Authors**: ZhengLin Lai, MengYao Liao, Dong Xu  

**Link**: [PDF](https://arxiv.org/pdf/2503.15469)  

**Abstract**: Text classification, a fundamental task in natural language processing (NLP), aims to categorize textual data into predefined labels. Traditional methods struggled with complex linguistic structures and semantic dependencies. The advent of deep learning, particularly recurrent neural networks (RNNs) and Transformer-based models, has significantly advanced the field by enabling nuanced feature extraction and context-aware predictions. Despite improvements, existing models exhibit limitations in balancing interpretability, computational efficiency, and long-range contextual understanding. This paper proposes the Dynamic Bidirectional Elman with Attention Network (DBEAN), which integrates bidirectional temporal modelling with self-attention mechanisms. DBEAN dynamically assigns weights to critical segments of input, improving contextual representation while maintaining computational efficiency. 

**Abstract (ZH)**: 动态双向Elman注意力网络：结合自注意力机制的双向时间建模 

---
# From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment 

**Title (ZH)**: 从1,000,000用户到每位用户：面向用户的个性化偏好扩展 

**Authors**: Jia-Nan Li, Jian Guan, Songhao Wu, Wei Wu, Rui Yan  

**Link**: [PDF](https://arxiv.org/pdf/2503.15463)  

**Abstract**: Large language models (LLMs) have traditionally been aligned through one-size-fits-all approaches that assume uniform human preferences, fundamentally overlooking the diversity in user values and needs. This paper introduces a comprehensive framework for scalable personalized alignment of LLMs. We establish a systematic preference space characterizing psychological and behavioral dimensions, alongside diverse persona representations for robust preference inference in real-world scenarios. Building upon this foundation, we introduce \textsc{AlignX}, a large-scale dataset of over 1.3 million personalized preference examples, and develop two complementary alignment approaches: \textit{in-context alignment} directly conditioning on persona representations and \textit{preference-bridged alignment} modeling intermediate preference distributions. Extensive experiments demonstrate substantial improvements over existing methods, with an average 17.06\% accuracy gain across four benchmarks while exhibiting a strong adaptation capability to novel preferences, robustness to limited user data, and precise preference controllability. These results validate our framework's effectiveness, advancing toward truly user-adaptive AI systems. 

**Abstract (ZH)**: 大型语言模型（LLMs）的传统对齐方法采用一刀切的方式，假设人类偏好一致，从根本上忽视了用户价值观和需求的多样性。本文提出了一种全面的框架以实现可扩展的个性化LLM对齐。我们建立了一个系统化的偏好空间，刻画了心理和行为维度，并结合多样化的人物角色表示，以实现稳健的偏好推断。在此基础上，我们引入了\textsc{AlignX}，这是一个包含超过130万个性化偏好示例的大型数据集，并开发了两种互补的对齐方法：基于人物角色表示的上下文对齐和基于偏好桥梁的对齐方法。广泛的实验结果表明，与现有方法相比取得了显著改进，平均在四个基准测试中准确性提升17.06%，同时具有强大的新偏好适应能力和对有限用户数据的鲁棒性，以及精确的偏好可控性。这些结果验证了我们框架的有效性，推动了真正用户自适应AI系统的进步。 

---
# Di$\mathtt{[M]}$O: Distilling Masked Diffusion Models into One-step Generator 

**Title (ZH)**: Di$\mathtt{[M]}$O: 将掩码扩散模型提炼为一步生成器 

**Authors**: Yuanzhi Zhu, Xi Wang, Stéphane Lathuilière, Vicky Kalogeiton  

**Link**: [PDF](https://arxiv.org/pdf/2503.15457)  

**Abstract**: Masked Diffusion Models (MDMs) have emerged as a powerful generative modeling technique. Despite their remarkable results, they typically suffer from slow inference with several steps. In this paper, we propose Di$\mathtt{[M]}$O, a novel approach that distills masked diffusion models into a one-step generator. Di$\mathtt{[M]}$O addresses two key challenges: (1) the intractability of using intermediate-step information for one-step generation, which we solve through token-level distribution matching that optimizes model output logits by an 'on-policy framework' with the help of an auxiliary model; and (2) the lack of entropy in the initial distribution, which we address through a token initialization strategy that injects randomness while maintaining similarity to teacher training distribution. We show Di$\mathtt{[M]}$O's effectiveness on both class-conditional and text-conditional image generation, impressively achieving performance competitive to multi-step teacher outputs while drastically reducing inference time. To our knowledge, we are the first to successfully achieve one-step distillation of masked diffusion models and the first to apply discrete distillation to text-to-image generation, opening new paths for efficient generative modeling. 

**Abstract (ZH)**: Di$\mathtt{[M]}$O: 一步生成的masked扩散模型蒸馏 

---
# VenusFactory: A Unified Platform for Protein Engineering Data Retrieval and Language Model Fine-Tuning 

**Title (ZH)**: 金星工厂：蛋白质工程数据检索与语言模型微调的统一平台 

**Authors**: Yang Tan, Chen Liu, Jingyuan Gao, Banghao Wu, Mingchen Li, Ruilin Wang, Lingrong Zhang, Huiqun Yu, Guisheng Fan, Liang Hong, Bingxin Zhou  

**Link**: [PDF](https://arxiv.org/pdf/2503.15438)  

**Abstract**: Natural language processing (NLP) has significantly influenced scientific domains beyond human language, including protein engineering, where pre-trained protein language models (PLMs) have demonstrated remarkable success. However, interdisciplinary adoption remains limited due to challenges in data collection, task benchmarking, and application. This work presents VenusFactory, a versatile engine that integrates biological data retrieval, standardized task benchmarking, and modular fine-tuning of PLMs. VenusFactory supports both computer science and biology communities with choices of both a command-line execution and a Gradio-based no-code interface, integrating $40+$ protein-related datasets and $40+$ popular PLMs. All implementations are open-sourced on this https URL. 

**Abstract (ZH)**: 自然语言处理（NLP）超越人类语言对科学领域产生了显著影响，包括蛋白质工程，其中预训练蛋白质语言模型（PLMs）取得了显著成功。然而，由于数据收集、任务基准测试和应用方面的挑战，跨学科应用仍然有限。本工作提出了VenusFactory，这是一个多功能引擎，集成了生物数据检索、标准化任务基准测试和PLMs模块化微调。VenusFactory同时支持计算机科学和生物学社区，提供命令行执行和Gradio基于的无代码界面，整合了40多个蛋白质相关数据集和40多个流行PLMs。所有实现均已开源，链接为：https://github.com/VenusFactory/VenusFactory。 

---
# An extensive simulation study evaluating the interaction of resampling techniques across multiple causal discovery contexts 

**Title (ZH)**: 基于多次因果发现场景下重采样技术交互作用的广泛模拟研究 

**Authors**: Ritwick Banerjee, Bryan Andrews, Erich Kummerfeld  

**Link**: [PDF](https://arxiv.org/pdf/2503.15436)  

**Abstract**: Despite the accelerating presence of exploratory causal analysis in modern science and medicine, the available non-experimental methods for validating causal models are not well characterized. One of the most popular methods is to evaluate the stability of model features after resampling the data, similar to resampling methods for estimating confidence intervals in statistics. Many aspects of this approach have received little to no attention, however, such as whether the choice of resampling method should depend on the sample size, algorithms being used, or algorithm tuning parameters. We present theoretical results proving that certain resampling methods closely emulate the assignment of specific values to algorithm tuning parameters. We also report the results of extensive simulation experiments, which verify the theoretical result and provide substantial data to aid researchers in further characterizing resampling in the context of causal discovery analysis. Together, the theoretical work and simulation results provide specific guidance on how resampling methods and tuning parameters should be selected in practice. 

**Abstract (ZH)**: 尽管探索性因果分析在现代科学和医学中的应用日益加速，现有的非实验性因果模型验证方法尚未得到充分character化。最流行的方法之一是通过重采样数据来评估模型特征的稳定性，类似于统计学中估计置信区间的方法。然而，这种方法的许多方面，例如重采样方法是否应依赖于样本大小、所使用的算法或算法调参参数，尚未得到足够的关注。我们提出了理论结果，证明某些重采样方法可以近似地模拟对算法调参参数赋值的过程。我们还报告了大量模拟实验的结果，验证了理论结果并提供了大量数据，以帮助研究人员进一步在因果发现分析的背景下characterize重采样方法。结合理论工作和模拟结果，我们为如何在实践中选择重采样方法和调参参数提供了具体指导。 

---
# Visual Position Prompt for MLLM based Visual Grounding 

**Title (ZH)**: 基于视觉定位提示的MLLM视觉 grounding 

**Authors**: Wei Tang, Yanpeng Sun, Qinying Gu, Zechao Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.15426)  

**Abstract**: Although Multimodal Large Language Models (MLLMs) excel at various image-related tasks, they encounter challenges in precisely aligning coordinates with spatial information within images, particularly in position-aware tasks such as visual grounding. This limitation arises from two key factors. First, MLLMs lack explicit spatial references, making it difficult to associate textual descriptions with precise image locations. Second, their feature extraction processes prioritize global context over fine-grained spatial details, leading to weak localization capability. To address this issue, we introduce VPP-LLaVA, an MLLM equipped with Visual Position Prompt (VPP) to improve its grounding capability. VPP-LLaVA integrates two complementary mechanisms. The global VPP overlays learnable, axis-like embeddings onto the input image to provide structured spatial cues. The local VPP focuses on fine-grained localization by incorporating position-aware queries, which suggests probable object locations. We also introduce a VPP-SFT dataset with 0.6M samples, consolidating high-quality visual grounding data into a compact format for efficient model training. Training on this dataset with VPP enhances the model's performance, achieving state-of-the-art results on standard grounding benchmarks despite using fewer training samples compared to other MLLMs like MiniGPT-v2, which rely on much larger datasets ($\sim$21M samples). The code and VPP-SFT dataset will be available at this https URL upon acceptance. 

**Abstract (ZH)**: 尽管多模态大型语言模型（MLLMs）在各种图像相关任务中表现出色，但在精确对齐坐标与图像中的空间信息方面仍面临挑战，特别是在位置感知任务（如视觉定位）中尤为明显。这一限制主要源自两个关键因素。首先，MLLMs缺乏明确的空间参考，使得难以将文本描述与精确的图像位置相关联。其次，它们的特征提取过程倾向于提取全局上下文信息，而忽略细粒度的空间细节，导致其定位能力较弱。为解决这一问题，我们提出了VPP-LLaVA，这是一种配备视觉位置提示（VPP）的MLLM，以提高其定位能力。VPP-LLaVA结合了两种互补机制。全局VPP通过在输入图像上叠加可学习的轴向嵌入，提供结构化空间线索。局部VPP则通过引入位置感知查询，专注于细粒度的定位，指出可能的对象位置。我们还引入了一个包含60万样本的VPP-SFT数据集，将高质量的视觉定位数据以紧凑格式整合，以便高效训练模型。在该数据集上进行训练可以提升模型性能，即使使用比其他MLLMs（如MiniGPT-v2）更少的训练样本（远少于210万样本），依然能达到标准定位基准上的先进结果。相关代码和VPP-SFT数据集将在接收后在此网址获取。 

---
# Probing the topology of the space of tokens with structured prompts 

**Title (ZH)**: 探究令牌空间的拓扑结构通过结构化提示 

**Authors**: Michael Robinson, Sourya Dey, Taisa Kushner  

**Link**: [PDF](https://arxiv.org/pdf/2503.15421)  

**Abstract**: This article presents a general and flexible method for prompting a large language model (LLM) to reveal its (hidden) token input embedding up to homeomorphism. Moreover, this article provides strong theoretical justification -- a mathematical proof for generic LLMs -- for why this method should be expected to work. With this method in hand, we demonstrate its effectiveness by recovering the token subspace of Llemma-7B. The results of this paper apply not only to LLMs but also to general nonlinear autoregressive processes. 

**Abstract (ZH)**: 本文提出了一种通用且灵活的方法，用于提示大型语言模型（LLM）通过同胚变换揭示其（隐藏的）标记输入嵌入。此外，本文提供了强大的理论证明——对通用LLM的数学证明——说明为何这种方法预期能够奏效。借助此方法，我们通过对Llemma-7B的标记子空间进行恢复，展示了其有效性。本文的结果不仅适用于LLM，还适用于一般非线性自回归过程。 

---
# Temporal Regularization Makes Your Video Generator Stronger 

**Title (ZH)**: 时间正则化让你的视频生成器更强 Wrest 

**Authors**: Harold Haodong Chen, Haojian Huang, Xianfeng Wu, Yexin Liu, Yajing Bai, Wen-Jie Shu, Harry Yang, Ser-Nam Lim  

**Link**: [PDF](https://arxiv.org/pdf/2503.15417)  

**Abstract**: Temporal quality is a critical aspect of video generation, as it ensures consistent motion and realistic dynamics across frames. However, achieving high temporal coherence and diversity remains challenging. In this work, we explore temporal augmentation in video generation for the first time, and introduce FluxFlow for initial investigation, a strategy designed to enhance temporal quality. Operating at the data level, FluxFlow applies controlled temporal perturbations without requiring architectural modifications. Extensive experiments on UCF-101 and VBench benchmarks demonstrate that FluxFlow significantly improves temporal coherence and diversity across various video generation models, including U-Net, DiT, and AR-based architectures, while preserving spatial fidelity. These findings highlight the potential of temporal augmentation as a simple yet effective approach to advancing video generation quality. 

**Abstract (ZH)**: Temporal 增强在视频生成中的探索：FluxFlow 的初步研究及其对时间一致性与多样性的提升 

---
# Automated Processing of eXplainable Artificial Intelligence Outputs in Deep Learning Models for Fault Diagnostics of Large Infrastructures 

**Title (ZH)**: 深度学习模型中可解释人工智能输出的自动化处理在大型基础设施故障诊断中的应用 

**Authors**: Giovanni Floreale, Piero Baraldi, Enrico Zio, Olga Fink  

**Link**: [PDF](https://arxiv.org/pdf/2503.15415)  

**Abstract**: Deep Learning (DL) models processing images to recognize the health state of large infrastructure components can exhibit biases and rely on non-causal shortcuts. eXplainable Artificial Intelligence (XAI) can address these issues but manually analyzing explanations generated by XAI techniques is time-consuming and prone to errors. This work proposes a novel framework that combines post-hoc explanations with semi-supervised learning to automatically identify anomalous explanations that deviate from those of correctly classified images and may therefore indicate model abnormal behaviors. This significantly reduces the workload for maintenance decision-makers, who only need to manually reclassify images flagged as having anomalous explanations. The proposed framework is applied to drone-collected images of insulator shells for power grid infrastructure monitoring, considering two different Convolutional Neural Networks (CNNs), GradCAM explanations and Deep Semi-Supervised Anomaly Detection. The average classification accuracy on two faulty classes is improved by 8% and maintenance operators are required to manually reclassify only 15% of the images. We compare the proposed framework with a state-of-the-art approach based on the faithfulness metric: the experimental results obtained demonstrate that the proposed framework consistently achieves F_1 scores larger than those of the faithfulness-based approach. Additionally, the proposed framework successfully identifies correct classifications that result from non-causal shortcuts, such as the presence of ID tags printed on insulator shells. 

**Abstract (ZH)**: 基于后验解释与半监督学习的解释异常自动识别框架：以电力网格基础设施监测中的绝缘子壳体无人机图像为例 

---
# Towards efficient keyword spotting using spike-based time difference encoders 

**Title (ZH)**: 基于脉冲时差编码的高效关键词识别方法 

**Authors**: Alejandro Pequeño-Zurro, Lyes Khacef, Stefano Panzeri, Elisabetta Chicca  

**Link**: [PDF](https://arxiv.org/pdf/2503.15402)  

**Abstract**: Keyword spotting in edge devices is becoming increasingly important as voice-activated assistants are widely used. However, its deployment is often limited by the extreme low-power constraints of the target embedded systems. Here, we explore the Temporal Difference Encoder (TDE) performance in keyword spotting. This recent neuron model encodes the time difference in instantaneous frequency and spike count to perform efficient keyword spotting with neuromorphic processors. We use the TIdigits dataset of spoken digits with a formant decomposition and rate-based encoding into spikes. We compare three Spiking Neural Networks (SNNs) architectures to learn and classify spatio-temporal signals. The proposed SNN architectures are made of three layers with variation in its hidden layer composed of either (1) feedforward TDE, (2) feedforward Current-Based Leaky Integrate-and-Fire (CuBa-LIF), or (3) recurrent CuBa-LIF neurons. We first show that the spike trains of the frequency-converted spoken digits have a large amount of information in the temporal domain, reinforcing the importance of better exploiting temporal encoding for such a task. We then train the three SNNs with the same number of synaptic weights to quantify and compare their performance based on the accuracy and synaptic operations. The resulting accuracy of the feedforward TDE network (89%) is higher than the feedforward CuBa-LIF network (71%) and close to the recurrent CuBa-LIF network (91%). However, the feedforward TDE-based network performs 92% fewer synaptic operations than the recurrent CuBa-LIF network with the same amount of synapses. In addition, the results of the TDE network are highly interpretable and correlated with the frequency and timescale features of the spoken keywords in the dataset. Our findings suggest that the TDE is a promising neuron model for scalable event-driven processing of spatio-temporal patterns. 

**Abstract (ZH)**: 边缘设备中关键词识别在语音激活助手广泛应用的背景下变得越来越重要。然而，其部署往往受限于目标嵌入系统极端的低功耗约束。本文探讨了时差编码器（TDE）在关键词识别中的性能。这种最近的神经元模型通过编码瞬时频率和脉冲计数之间的时差，在神经形态处理器上执行高效的关键词识别。我们使用经过共振分解并基于速率编码成脉冲的TIdigits语音数字数据集。我们将三种脉冲神经网络（SNN）架构用于学习和分类时空信号，并提出了具有变化隐藏层的三层结构，隐藏层由（1）前馈TDE、（2）前馈电流基漏式积分-放电（CuBa-LIF）或（3）递归CuBa-LIF神经元组成。我们首先展示频率转换的语音数字脉冲列在时间域中包含大量信息，强调了更好地利用时间编码对于此类任务的重要性。随后，我们训练了三个具有相同突触权重数量的SNN，以量化并比较其基于准确性和突触操作量的表现。前馈TDE网络的准确率为89%，高于前馈CuBa-LIF网络的71%，接近递归CuBa-LIF网络的91%。然而，前馈TDE网络在相同数量的突触下执行的突触操作少了92%。此外，TDE网络的结果高度可解释，并与数据集中语音关键词的频率和时间尺度特征相关。我们的发现表明，TDE是可用于时空模式可扩展事件驱动处理的有前途的神经元模型。 

---
# CCDP: Composition of Conditional Diffusion Policies with Guided Sampling 

**Title (ZH)**: CCDP：带有引导采样的条件扩散策略的组合 

**Authors**: Amirreza Razmjoo, Sylvain Calinon, Michael Gienger, Fan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.15386)  

**Abstract**: Imitation Learning offers a promising approach to learn directly from data without requiring explicit models, simulations, or detailed task definitions. During inference, actions are sampled from the learned distribution and executed on the robot. However, sampled actions may fail for various reasons, and simply repeating the sampling step until a successful action is obtained can be inefficient. In this work, we propose an enhanced sampling strategy that refines the sampling distribution to avoid previously unsuccessful actions. We demonstrate that by solely utilizing data from successful demonstrations, our method can infer recovery actions without the need for additional exploratory behavior or a high-level controller. Furthermore, we leverage the concept of diffusion model decomposition to break down the primary problem (which may require long-horizon history to manage failures) into multiple smaller, more manageable sub-problems in learning, data collection, and inference, thereby enabling the system to adapt to variable failure counts. Our approach yields a low-level controller that dynamically adjusts its sampling space to improve efficiency when prior samples fall short. We validate our method across several tasks, including door opening with unknown directions, object manipulation, and button-searching scenarios, demonstrating that our approach outperforms traditional baselines. 

**Abstract (ZH)**: 模仿学习提供了一种有前途的方法，可以直接从数据中学习，而无需显式模型、模拟或详细任务定义。在推理过程中，动作从学习得到的分布中采样并在机器人上执行。然而，采样动作可能因各种原因失败，简单地重复采样步骤直到获得成功动作的执行可能是低效的。在本工作中，我们提出了一种改进的采样策略，通过细化采样分布以避免之前不成功的动作。我们通过仅利用成功演示的数据，可以推断出恢复动作，而无需额外的探索行为或高级控制器。此外，我们利用扩散模型分解的概念，将主要问题分解为多个更小、更易管理的子问题，从而在学习、数据收集和推理过程中使系统能够适应变化的失败次数。我们的方法生成了一个低级控制器，该控制器能根据先前样本的不足动态调整其采样空间，提高效率。我们在多个任务中验证了我们的方法，包括未知方向的门开启、物体操作和按钮搜索场景，结果显示我们的方法优于传统基线。 

---
# Real-world validation of a multimodal LLM-powered pipeline for High-Accuracy Clinical Trial Patient Matching leveraging EHR data 

**Title (ZH)**: 基于EHR数据的多模态LLM赋能高精度临床试验患者匹配pipeline的现实世界验证 

**Authors**: Anatole Callies, Quentin Bodinier, Philippe Ravaud, Kourosh Davarpanah  

**Link**: [PDF](https://arxiv.org/pdf/2503.15374)  

**Abstract**: Background: Patient recruitment in clinical trials is hindered by complex eligibility criteria and labor-intensive chart reviews. Prior research using text-only models have struggled to address this problem in a reliable and scalable way due to (1) limited reasoning capabilities, (2) information loss from converting visual records to text, and (3) lack of a generic EHR integration to extract patient data.
Methods: We introduce a broadly applicable, integration-free, LLM-powered pipeline that automates patient-trial matching using unprocessed documents extracted from EHRs. Our approach leverages (1) the new reasoning-LLM paradigm, enabling the assessment of even the most complex criteria, (2) visual capabilities of latest LLMs to interpret medical records without lossy image-to-text conversions, and (3) multimodal embeddings for efficient medical record search. The pipeline was validated on the n2c2 2018 cohort selection dataset (288 diabetic patients) and a real-world dataset composed of 485 patients from 30 different sites matched against 36 diverse trials.
Results: On the n2c2 dataset, our method achieved a new state-of-the-art criterion-level accuracy of 93\%. In real-world trials, the pipeline yielded an accuracy of 87\%, undermined by the difficulty to replicate human decision-making when medical records lack sufficient information. Nevertheless, users were able to review overall eligibility in under 9 minutes per patient on average, representing an 80\% improvement over traditional manual chart reviews.
Conclusion: This pipeline demonstrates robust performance in clinical trial patient matching without requiring custom integration with site systems or trial-specific tailoring, thereby enabling scalable deployment across sites seeking to leverage AI for patient matching. 

**Abstract (ZH)**: 背景：临床试验中患者的招募受到了复杂入选标准和劳动密集型病历审查的阻碍。由于（1）有限的推理能力，（2）将视觉记录转换为文本时的信息损失，以及（3）缺乏通用的电子健康记录（EHR）集成来提取患者数据，先前仅使用文本模型的研究难以可靠且可扩展地解决这一问题。

方法：我们引入了一种广泛适用的、无需集成的、由大规模语言模型（LLM）驱动的pipeline，该pipeline利用未处理的从EHR提取的文档自动完成患者-试验匹配。我们的方法利用了（1）新的推理LLM范式，能够评估最复杂的标准；（2）最新LLM的视觉能力，能够在不进行损失性的图像到文本转换的情况下解释医疗记录；以及（3）多模态嵌入，用于高效地搜索医疗记录。该pipeline在n2c2 2018队列选择数据集（288名糖尿病患者）和一个由来自30个不同地点的485名患者组成的实际数据集（与36项不同试验匹配）上进行了验证。

结果：在n2c2数据集上，该方法实现了新的最佳标准级别准确率93%。在实际临床试验中，pipeline的准确率为87%，由于医疗记录缺乏充分信息而使人工决策复制变得困难。然而，用户仍然能够平均在每名患者不到9分钟内审查总体入组资格，这比传统的手动病历审查提高了80%。

结论：该pipeline在无需对站点系统进行定制集成或针对特定试验进行调整的情况下展示了在临床试验患者匹配中的稳健性能，从而使得使用AI进行患者匹配的部署能够在寻求利用AI的各个站点中实现可扩展性。 

---
# Optimizing Decomposition for Optimal Claim Verification 

**Title (ZH)**: 优化分解以实现最优索赔验证 

**Authors**: Yining Lu, Noah Ziems, Hy Dang, Meng Jiang  

**Link**: [PDF](https://arxiv.org/pdf/2503.15354)  

**Abstract**: Current research on the \textit{Decompose-Then-Verify} paradigm for evaluating the factuality of long-form text typically treats decomposition and verification in isolation, overlooking their interactions and potential misalignment. We find that existing decomposition policies, typically hand-crafted demonstrations, do not align well with downstream verifiers in terms of atomicity -- a novel metric quantifying information density -- leading to suboptimal verification results. We formulate finding the optimal decomposition policy for optimal verification as a bilevel optimization problem. To approximate a solution for this strongly NP-hard problem, we propose dynamic decomposition, a reinforcement learning framework that leverages verifier feedback to learn a policy for dynamically decomposing claims to verifier-preferred atomicity. Experimental results show that dynamic decomposition outperforms existing decomposition policies, improving verification confidence by 0.07 and accuracy by 0.12 (on a 0-1 scale) on average across varying verifiers, datasets, and atomcities of input claims. 

**Abstract (ZH)**: 当前关于\textit{分解后验证}范式评价长篇文本事实性的研究通常将分解和验证分离，忽视了它们之间的互动和潜在的不一致。我们发现现有的分解策略，通常为手工构建的示例，与下游验证器在原子性方面（原子性是衡量信息密度的新型指标）不一致，导致验证结果次优。我们将寻找最优分解策略以实现最优验证建模为一个双层优化问题。为了近似解决这一强NP难问题，我们提出了一种动力分解框架，该框架利用验证器的反馈学习一种动力分解策略，以达到验证器偏好化的原子性。实验结果表明，动力分解在所有验证器、不同数据集和输入声明原子性差异的情况下，优于现有的分解策略，平均将验证置信度提高0.07和准确性提高0.12（在0-1尺度上）。 

---
# Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer 

**Title (ZH)**: 利用完美的多模态对齐和高斯假设进行跨模态迁移 

**Authors**: Abhi Kamboj, Minh N. Do  

**Link**: [PDF](https://arxiv.org/pdf/2503.15352)  

**Abstract**: Multimodal alignment aims to construct a joint latent vector space where two modalities representing the same concept map to the same vector. We formulate this as an inverse problem and show that under certain conditions perfect alignment can be achieved. We then address a specific application of alignment referred to as cross-modal transfer. Unsupervised cross-modal transfer aims to leverage a model trained with one modality to perform inference on another modality, without any labeled fine-tuning on the new modality. Assuming that semantic classes are represented as a mixture of Gaussians in the latent space, we show how cross-modal transfer can be performed by projecting the data points from the representation space onto different subspaces representing each modality. Our experiments on synthetic multimodal Gaussian data verify the effectiveness of our perfect alignment and cross-modal transfer method. We hope these findings inspire further exploration of the applications of perfect alignment and the use of Gaussian models for cross-modal learning. 

**Abstract (ZH)**: 多模态对齐旨在构建一个联合隐空间，在该空间中表示相同概念的两种模态映射到同一个向量。我们将这种对齐视为逆问题，并证明在某些条件下可以实现完美的对齐。随后，我们讨论了对齐的特定应用，即跨模态迁移。无监督的跨模态迁移旨在利用一种模态训练的模型在另一种模态上进行推理，而不需要对新模态进行任何标注的微调。假设语义类在隐空间中以高斯混合模型表示，我们展示了如何通过将数据点从表示空间投影到表示每个模态的不同子空间来进行跨模态迁移。我们对合成的多模态高斯数据的实验验证了我们完美对齐和跨模态迁移方法的有效性。我们希望这些发现能激发对完美对齐应用及其在跨模态学习中使用高斯模型的进一步探索。 

---
# TruthLens:A Training-Free Paradigm for DeepFake Detection 

**Title (ZH)**: TruthLens：一种无需训练的深度伪造检测范式 

**Authors**: Ritabrata Chakraborty, Rajatsubhra Chakraborty, Ali Khaleghi Rahimian, Thomas MacDougall  

**Link**: [PDF](https://arxiv.org/pdf/2503.15342)  

**Abstract**: The proliferation of synthetic images generated by advanced AI models poses significant challenges in identifying and understanding manipulated visual content. Current fake image detection methods predominantly rely on binary classification models that focus on accuracy while often neglecting interpretability, leaving users without clear insights into why an image is deemed real or fake. To bridge this gap, we introduce TruthLens, a novel training-free framework that reimagines deepfake detection as a visual question-answering (VQA) task. TruthLens utilizes state-of-the-art large vision-language models (LVLMs) to observe and describe visual artifacts and combines this with the reasoning capabilities of large language models (LLMs) like GPT-4 to analyze and aggregate evidence into informed decisions. By adopting a multimodal approach, TruthLens seamlessly integrates visual and semantic reasoning to not only classify images as real or fake but also provide interpretable explanations for its decisions. This transparency enhances trust and provides valuable insights into the artifacts that signal synthetic content. Extensive evaluations demonstrate that TruthLens outperforms conventional methods, achieving high accuracy on challenging datasets while maintaining a strong emphasis on explainability. By reframing deepfake detection as a reasoning-driven process, TruthLens establishes a new paradigm in combating synthetic media, combining cutting-edge performance with interpretability to address the growing threats of visual disinformation. 

**Abstract (ZH)**: 合成图像生成技术的迅猛发展对识别和理解篡改视觉内容构成了重大挑战。当前的假图像检测方法主要依赖于注重准确性的二分类模型，但往往忽视了可解释性，使得用户无法清晰了解为何某张图被判定为真实或虚假。为弥合这一差距，我们引入了TruthLens，这是一种无需训练的新颖框架，重新构想了深度伪造检测为视觉问答任务（VQA）。TruthLens 利用最先进的大型视觉-语言模型（LVLM）观察和描述视觉特征，并结合大型语言模型（LLMs）如GPT-4的推理能力，分析和汇总证据为明智的决策。通过采用多模态方法，TruthLens 平滑地整合了视觉和语义推理，不仅能够将图像分类为真实或虚假，还能为决策提供可解释的解释。这种透明度提升了信任并提供了关于指示合成内容的特征的关键见解。广泛评估表明，TruthLens 在性能和解释性方面均优于传统方法，能够在具有挑战性的数据集上实现高精度。通过将深度伪造检测重新构想为推理驱动的过程，TruthLens 建立了对抗合成媒体的新范式，结合了顶级性能与解释性，以应对日益严重的视觉虚假信息威胁。 

---
# Challenges and Trends in Egocentric Vision: A Survey 

**Title (ZH)**: 自视点视觉挑战与趋势综述 

**Authors**: Xiang Li, Heqian Qiu, Lanxiao Wang, Hanwen Zhang, Chenghao Qi, Linfeng Han, Huiyu Xiong, Hongliang Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.15275)  

**Abstract**: With the rapid development of artificial intelligence technologies and wearable devices, egocentric vision understanding has emerged as a new and challenging research direction, gradually attracting widespread attention from both academia and industry. Egocentric vision captures visual and multimodal data through cameras or sensors worn on the human body, offering a unique perspective that simulates human visual experiences. This paper provides a comprehensive survey of the research on egocentric vision understanding, systematically analyzing the components of egocentric scenes and categorizing the tasks into four main areas: subject understanding, object understanding, environment understanding, and hybrid understanding. We explore in detail the sub-tasks within each category. We also summarize the main challenges and trends currently existing in the field. Furthermore, this paper presents an overview of high-quality egocentric vision datasets, offering valuable resources for future research. By summarizing the latest advancements, we anticipate the broad applications of egocentric vision technologies in fields such as augmented reality, virtual reality, and embodied intelligence, and propose future research directions based on the latest developments in the field. 

**Abstract (ZH)**: 随着人工智能技术和可穿戴设备的快速发展，第一人称视觉理解已成为一个新兴且具有挑战性的研究方向，逐渐引起了学术界和工业界的广泛关注。第一人称视觉通过穿戴在人体上的摄像头或传感器捕获视觉和多模态数据，提供了一种模拟人类视觉体验的独特视角。本文对第一人称视觉理解的研究进行了全面综述，系统分析了第一人称场景的组成，并将任务划分为四个主要领域：主体理解、对象理解、环境理解和混合理解。我们详细探讨了每个类别下的子任务。同时，我们总结了当前领域中存在的主要挑战和趋势。此外，本文概述了高质量的第一人称视觉数据集，为未来的研究提供了宝贵资源。通过总结最新进展，我们预见了第一人称视觉技术在增强现实、虚拟现实和嵌入式智能等领域的广泛应用，并基于最新发展提出未来的研究方向。 

---
# MAMM-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration 

**Title (ZH)**: MAMM-Refine: 多智能体合作改进生成忠实度的方法 

**Authors**: David Wan, Justin Chih-Yao Chen, Elias Stengel-Eskin, Mohit Bansal  

**Link**: [PDF](https://arxiv.org/pdf/2503.15272)  

**Abstract**: Multi-agent collaboration among models has shown promise in reasoning tasks but is underexplored in long-form generation tasks like summarization and question-answering. We extend multi-agent multi-model reasoning to generation, specifically to improving faithfulness through refinement, i.e., revising model-generated outputs to remove factual inconsistencies. We investigate how iterative collaboration among multiple instances and types of large language models (LLMs) enhances subtasks in the refinement process, such as error detection, critiquing unfaithful sentences, and making corrections based on critiques. We design intrinsic evaluations for each subtask, with our findings indicating that both multi-agent (multiple instances) and multi-model (diverse LLM types) approaches benefit error detection and critiquing. Additionally, reframing critiquing and refinement as reranking rather than generation tasks improves multi-agent performance. We consolidate these insights into a final "recipe" called Multi-Agent Multi-Model Refinement (MAMM-Refine), where multi-agent and multi-model collaboration significantly boosts performance on three summarization datasets as well as on long-form question answering, demonstrating the effectiveness and generalizability of our recipe. 

**Abstract (ZH)**: 多agent多模型协作在生成任务中的推理研究：提升忠实性通过精炼 

---
# Automated Non-Functional Requirements Generation in Software Engineering with Large Language Models: A Comparative Study 

**Title (ZH)**: 使用大型语言模型在软件工程中自动生成非功能需求：一项比较研究 

**Authors**: Jomar Thomas Almonte, Santhosh Anitha Boominathan, Nathalia Nascimento  

**Link**: [PDF](https://arxiv.org/pdf/2503.15248)  

**Abstract**: Neglecting non-functional requirements (NFRs) early in software development can lead to critical challenges. Despite their importance, NFRs are often overlooked or difficult to identify, impacting software quality. To support requirements engineers in eliciting NFRs, we developed a framework that leverages Large Language Models (LLMs) to derive quality-driven NFRs from functional requirements (FRs). Using a custom prompting technique within a Deno-based pipeline, the system identifies relevant quality attributes for each functional requirement and generates corresponding NFRs, aiding systematic integration. A crucial aspect is evaluating the quality and suitability of these generated requirements. Can LLMs produce high-quality NFR suggestions? Using 34 functional requirements - selected as a representative subset of 3,964 FRs-the LLMs inferred applicable attributes based on the ISO/IEC 25010:2023 standard, generating 1,593 NFRs. A horizontal evaluation covered three dimensions: NFR validity, applicability of quality attributes, and classification precision. Ten industry software quality evaluators, averaging 13 years of experience, assessed a subset for relevance and quality. The evaluation showed strong alignment between LLM-generated NFRs and expert assessments, with median validity and applicability scores of 5.0 (means: 4.63 and 4.59, respectively) on a 1-5 scale. In the classification task, 80.4% of LLM-assigned attributes matched expert choices, with 8.3% near misses and 11.3% mismatches. A comparative analysis of eight LLMs highlighted variations in performance, with gemini-1.5-pro exhibiting the highest attribute accuracy, while llama-3.3-70B achieved higher validity and applicability scores. These findings provide insights into the feasibility of using LLMs for automated NFR generation and lay the foundation for further exploration of AI-assisted requirements engineering. 

**Abstract (ZH)**: 忽视软件开发早期的功能需求非功能性要求（NFRs）可能导致关键挑战。尽管NFRs很重要，但它们往往被忽视或难以识别，影响软件质量。为了支持需求工程师提取NFRs，我们开发了一个框架，利用大型语言模型（LLMs）从功能需求（FRs）中推导出质量驱动的NFRs。通过一个基于Deno的流水线中的定制提示技术，系统识别每个功能需求的相关质量属性并生成相应的NFRs，促进系统的集成。一个关键方面是评估这些生成需求的质量和适用性。大型语言模型能否生成高质量的NFR建议？使用34个功能需求——作为3,964个FRs的一个代表性子集——LLMs根据ISO/IEC 25010:2023标准推断适用的属性，生成1,593个NFRs。横向评估涵盖了三个维度：NFR有效性、质量属性的适用性以及分类精度。十名拥有平均13年经验的行业软件质量评估员评估了其中一部分的相关性和质量。评估结果显示LLM生成的NFR与专家评估之间有很强的契合度，中位有效性和适用性分数分别为5.0（平均分别为4.63和4.59）。在分类任务中，80.4%的LLM分配的属性与专家选择匹配，8.3%为接近匹配，11.3%为不匹配。对于八种大型语言模型的比较分析揭示了性能上的差异，gemini-1.5-pro在属性准确性上表现最佳，而llama-3.3-70B在有效性和适用性评分上更高。这些发现为使用大型语言模型进行自动化NFR生成提供了见解，并为AI辅助需求工程的进一步探索奠定了基础。 

---
# BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity? 

**Title (ZH)**: BigO(基准)——大型语言模型能否生成受控时间与空间复杂度的代码？ 

**Authors**: Pierre Chambon, Baptiste Roziere, Benoit Sagot, Gabriel Synnaeve  

**Link**: [PDF](https://arxiv.org/pdf/2503.15242)  

**Abstract**: We introduce BigO(Bench), a novel coding benchmark designed to evaluate the capabilities of generative language models in understanding and generating code with specified time and space complexities. This benchmark addresses the gap in current evaluations that often overlook the ability of models to comprehend and produce code constrained by computational complexity. BigO(Bench) includes tooling to infer the algorithmic complexity of any Python function from profiling measurements, including human- or LLM-generated solutions. BigO(Bench) also includes of set of 3,105 coding problems and 1,190,250 solutions from Code Contests annotated with inferred (synthetic) time and space complexity labels from the complexity framework, as well as corresponding runtime and memory footprint values for a large set of input sizes. We present results from evaluating multiple state-of-the-art language models on this benchmark, highlighting their strengths and weaknesses in handling complexity requirements. In particular, token-space reasoning models are unrivaled in code generation but not in complexity understanding, hinting that they may not generalize well to tasks for which no reward was given at training time. 

**Abstract (ZH)**: BigO(Bench): 一种用于评估生成语言模型在理解与生成具有指定时空复杂度代码方面能力的新基准 

---
# Exploring Large Language Models for Word Games:Who is the Spy? 

**Title (ZH)**: 探索大型语言模型在词游中的应用：谁是间谍？ 

**Authors**: Chentian Wei, Jiewei Chen, Jinzhu Xu  

**Link**: [PDF](https://arxiv.org/pdf/2503.15235)  

**Abstract**: Word games hold significant research value for natural language processing (NLP), game theory, and related fields due to their rule-based and situational nature. This study explores how large language models (LLMs) can be effectively involved in word games and proposes a training-free framework. "Shei Shi Wo Di" or "Who is the Spy" in English, is a classic word game. Using this game as an example, we introduce a Chain-of-Thought (CoT)-based scheduling framework to enable LLMs to achieve excellent performance in tasks such as inferring role words and disguising their identities. We evaluate the framework's performance based on game success rates and the accuracy of the LLM agents' analytical results. Experimental results affirm the framework's effectiveness, demonstrating notable improvements in LLM performance across multiple datasets. This work highlights the potential of LLMs in mastering situational reasoning and social interactions within structured game environments. Our code is publicly available at this https URL. 

**Abstract (ZH)**: 基于规则和情境的词游游戏对于自然语言处理（NLP）、博弈论及相关领域的研究具有重要研究价值。本研究探讨大型语言模型（LLMs）在词游游戏中的有效应用，并提出了一种无需训练的框架。“谁是卧底”是一种经典的词游游戏。通过该游戏为例，我们介绍了一种基于Chain-of-Thought（CoT）的调度框架，以使LLMs在推断角色词和伪装身份等任务中表现出色。我们根据游戏成功率和LLMs代理分析结果的准确性评估该框架的性能。实验结果证实了该框架的有效性，展示了在多个数据集上LLMs性能的显著提升。本工作突显了LLMs在掌握结构化游戏环境中情境推理和社会互动方面的潜力。相关代码已在以下网址公开：此httpsURL。 

---
# CoE: Chain-of-Explanation via Automatic Visual Concept Circuit Description and Polysemanticity Quantification 

**Title (ZH)**: CoE:基于自动视觉概念电路描述和多义性量化的过程解释 

**Authors**: Wenlong Yu, Qilong Wang, Chuang Liu, Dong Li, Qinghua Hu  

**Link**: [PDF](https://arxiv.org/pdf/2503.15234)  

**Abstract**: Explainability is a critical factor influencing the wide deployment of deep vision models (DVMs). Concept-based post-hoc explanation methods can provide both global and local insights into model decisions. However, current methods in this field face challenges in that they are inflexible to automatically construct accurate and sufficient linguistic explanations for global concepts and local circuits. Particularly, the intrinsic polysemanticity in semantic Visual Concepts (VCs) impedes the interpretability of concepts and DVMs, which is underestimated severely. In this paper, we propose a Chain-of-Explanation (CoE) approach to address these issues. Specifically, CoE automates the decoding and description of VCs to construct global concept explanation datasets. Further, to alleviate the effect of polysemanticity on model explainability, we design a concept polysemanticity disentanglement and filtering mechanism to distinguish the most contextually relevant concept atoms. Besides, a Concept Polysemanticity Entropy (CPE), as a measure of model interpretability, is formulated to quantify the degree of concept uncertainty. The modeling of deterministic concepts is upgraded to uncertain concept atom distributions. Finally, CoE automatically enables linguistic local explanations of the decision-making process of DVMs by tracing the concept circuit. GPT-4o and human-based experiments demonstrate the effectiveness of CPE and the superiority of CoE, achieving an average absolute improvement of 36% in terms of explainability scores. 

**Abstract (ZH)**: 基于概念的解释链（CoE）方法：提高深度视觉模型解释性的新途径 

---
# A Personalized Data-Driven Generative Model of Human Motion 

**Title (ZH)**: 个性化数据驱动的人体运动生成模型 

**Authors**: Angelo Di Porzio, Marco Coraggio  

**Link**: [PDF](https://arxiv.org/pdf/2503.15225)  

**Abstract**: The deployment of autonomous virtual avatars (in extended reality) and robots in human group activities - such as rehabilitation therapy, sports, and manufacturing - is expected to increase as these technologies become more pervasive. Designing cognitive architectures and control strategies to drive these agents requires realistic models of human motion. However, existing models only provide simplified descriptions of human motor behavior. In this work, we propose a fully data-driven approach, based on Long Short-Term Memory neural networks, to generate original motion that captures the unique characteristics of specific individuals. We validate the architecture using real data of scalar oscillatory motion. Extensive analyses show that our model effectively replicates the velocity distribution and amplitude envelopes of the individual it was trained on, remaining different from other individuals, and outperforming state-of-the-art models in terms of similarity to human data. 

**Abstract (ZH)**: 自主虚拟化身（在扩展现实中的部署）和机器人在人类群体活动（如康复治疗、体育和制造业）中的应用预计随着这些技术的普及而增加。设计驱动这些代理的认知架构和控制策略需要真实的human运动模型。然而，现有模型仅提供了人类运动行为的简化的描述。在本工作中，我们提出了一种基于长短期记忆神经网络的完全数据驱动的方法，以生成能够捕捉特定个体独特特征的原始运动。我们使用标量振荡运动的真实数据对该架构进行了验证。广泛的分析表明，我们的模型有效地复制了所训练个体的速度分布和振幅包络，并且在与人类数据的相似性方面优于现有最先进的模型。 

---
# When Pigs Get Sick: Multi-Agent AI for Swine Disease Detection 

**Title (ZH)**: 当猪生病时：多Agent人工智能在猪病检测中的应用 

**Authors**: Tittaya Mairittha, Tanakon Sawanglok, Panuwit Raden, Sorrawit Treesuk  

**Link**: [PDF](https://arxiv.org/pdf/2503.15204)  

**Abstract**: Swine disease surveillance is critical to the sustainability of global agriculture, yet its effectiveness is frequently undermined by limited veterinary resources, delayed identification of cases, and variability in diagnostic accuracy. To overcome these barriers, we introduce a novel AI-powered, multi-agent diagnostic system that leverages Retrieval-Augmented Generation (RAG) to deliver timely, evidence-based disease detection and clinical guidance. By automatically classifying user inputs into either Knowledge Retrieval Queries or Symptom-Based Diagnostic Queries, the system ensures targeted information retrieval and facilitates precise diagnostic reasoning. An adaptive questioning protocol systematically collects relevant clinical signs, while a confidence-weighted decision fusion mechanism integrates multiple diagnostic hypotheses to generate robust disease predictions and treatment recommendations. Comprehensive evaluations encompassing query classification, disease diagnosis, and knowledge retrieval demonstrate that the system achieves high accuracy, rapid response times, and consistent reliability. By providing a scalable, AI-driven diagnostic framework, this approach enhances veterinary decision-making, advances sustainable livestock management practices, and contributes substantively to the realization of global food security. 

**Abstract (ZH)**: 猪疾病监控对于全球农业的可持续发展至关重要，然而其有效性常因兽医资源有限、病例识别延迟以及诊断准确性的变异性而受到削弱。为克服这些障碍，我们提出了一种新型的基于人工智能的多代理诊断系统，该系统利用检索增强生成（RAG）技术，提供及时的、基于证据的疾病检测和临床指导。通过自动将用户输入分类为知识检索查询或基于症状的诊断查询，该系统确保了精准的信息检索，并促进了精确的诊断推理。系统采用自适应询问协议系统地收集相关临床表现，并通过信心加权决策融合机制整合多个诊断假设，生成稳健的疾病预测和治疗建议。全面的评估表明，该系统在查询分类、疾病诊断和知识检索方面实现了高精度、快速响应时间和一致的可靠性。通过提供一种可扩展的人工智能驱动诊断框架，该方法增强了兽医决策能力，推动了可持续的畜禽管理实践，并对全球食物安全的实现做出了实质性贡献。 

---
# A Unified Framework for Real-Time Failure Handling in Robotics Using Vision-Language Models, Reactive Planner and Behavior Trees 

**Title (ZH)**: 基于视觉语言模型、反应性规划器和行为树的统一实时故障处理框架 

**Authors**: Faseeh Ahmad, Hashim Ismail, Jonathan Styrud, Maj Stenmark, Volker Krueger  

**Link**: [PDF](https://arxiv.org/pdf/2503.15202)  

**Abstract**: Robotic systems often face execution failures due to unexpected obstacles, sensor errors, or environmental changes. Traditional failure recovery methods rely on predefined strategies or human intervention, making them less adaptable. This paper presents a unified failure recovery framework that combines Vision-Language Models (VLMs), a reactive planner, and Behavior Trees (BTs) to enable real-time failure handling. Our approach includes pre-execution verification, which checks for potential failures before execution, and reactive failure handling, which detects and corrects failures during execution by verifying existing BT conditions, adding missing preconditions and, when necessary, generating new skills. The framework uses a scene graph for structured environmental perception and an execution history for continuous monitoring, enabling context-aware and adaptive failure handling. We evaluate our framework through real-world experiments with an ABB YuMi robot on tasks like peg insertion, object sorting, and drawer placement, as well as in AI2-THOR simulator. Compared to using pre-execution and reactive methods separately, our approach achieves higher task success rates and greater adaptability. Ablation studies highlight the importance of VLM-based reasoning, structured scene representation, and execution history tracking for effective failure recovery in robotics. 

**Abstract (ZH)**: 基于视觉-语言模型、反应规划器和行为树的统一故障恢复框架 

---
# 3D Occupancy Prediction with Low-Resolution Queries via Prototype-aware View Transformation 

**Title (ZH)**: 基于原型感知视图变换的低分辨率查询三维占用预测 

**Authors**: Gyeongrok Oh, Sungjune Kim, Heeju Ko, Hyung-gun Chi, Jinkyu Kim, Dongwook Lee, Daehyun Ji, Sungjoon Choi, Sujin Jang, Sangpil Kim  

**Link**: [PDF](https://arxiv.org/pdf/2503.15185)  

**Abstract**: The resolution of voxel queries significantly influences the quality of view transformation in camera-based 3D occupancy prediction. However, computational constraints and the practical necessity for real-time deployment require smaller query resolutions, which inevitably leads to an information loss. Therefore, it is essential to encode and preserve rich visual details within limited query sizes while ensuring a comprehensive representation of 3D occupancy. To this end, we introduce ProtoOcc, a novel occupancy network that leverages prototypes of clustered image segments in view transformation to enhance low-resolution context. In particular, the mapping of 2D prototypes onto 3D voxel queries encodes high-level visual geometries and complements the loss of spatial information from reduced query resolutions. Additionally, we design a multi-perspective decoding strategy to efficiently disentangle the densely compressed visual cues into a high-dimensional 3D occupancy scene. Experimental results on both Occ3D and SemanticKITTI benchmarks demonstrate the effectiveness of the proposed method, showing clear improvements over the baselines. More importantly, ProtoOcc achieves competitive performance against the baselines even with 75\% reduced voxel resolution. 

**Abstract (ZH)**: 基于相机的3D占用率预测中的体素查询分辨率显著影响视图变换的质量。然而，计算约束和实时部署的实际需求要求较小的查询分辨率，这不可避免地会导致信息丢失。因此，在有限的查询尺寸内编码和保留丰富的视觉细节并确保3D占用率的全面表示是至关重要的。为此，我们引入了ProtoOcc，一种新颖的占用网络，通过视图变换中聚类图像片段的原型来增强低分辨率上下文。特别是，将2D原型映射到3D体素查询中，编码高层次的视觉几何结构，补充了由于降低查询分辨率而导致的空间信息损失。另外，我们设计了一种多视角解码策略，以高效地将密集压缩的视觉线索解码为高维3D占用场景。在Occ3D和SemanticKITTI基准上的实验结果证明了所提方法的有效性，显示出在基线方法上的明显改进。更重要的是，即使体素分辨率降低75%，ProtoOcc仍能达到与基线方法竞争力相当的性能。 

---
# Foundation models may exhibit staged progression in novel CBRN threat disclosure 

**Title (ZH)**: 基础模型可能在新的CBRN威胁披露中表现出阶段性的进展 

**Authors**: Kevin M Esvelt  

**Link**: [PDF](https://arxiv.org/pdf/2503.15182)  

**Abstract**: The extent to which foundation models can disclose novel chemical, biological, radiation, and nuclear (CBRN) threats to expert users is unclear due to a lack of test cases. I leveraged the unique opportunity presented by an upcoming publication describing a novel catastrophic biothreat - "Technical Report on Mirror Bacteria: Feasibility and Risks" - to conduct a small controlled study before it became public. Graduate-trained biologists tasked with predicting the consequences of releasing mirror E. coli showed no significant differences in rubric-graded accuracy using Claude Sonnet 3.5 new (n=10) or web search only (n=2); both groups scored comparably to a web baseline (28 and 43 versus 36). However, Sonnet reasoned correctly when prompted by a report author, but a smaller model, Haiku 3.5, failed even with author guidance (80 versus 5). These results suggest distinct stages of model capability: Haiku is unable to reason about mirror life even with threat-aware expert guidance (Stage 1), while Sonnet correctly reasons only with threat-aware prompting (Stage 2). Continued advances may allow future models to disclose novel CBRN threats to naive experts (Stage 3) or unskilled users (Stage 4). While mirror life represents only one case study, monitoring new models' ability to reason about privately known threats may allow protective measures to be implemented before widespread disclosure. 

**Abstract (ZH)**: 基于基础模型对专家用户披露新型化学、生物、辐射和核（CBRN）威胁能力的研究：一项基于即将发布的新型灾难性生物威胁技术报告的小规模受控研究 

---
# Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems 

**Title (ZH)**: 多代理actor-critic算法结合谐波退火修剪方法在动态频谱访问系统中的应用 

**Authors**: George Stamatelis, Angelos-Nikolaos Kanatas, George C. Alexandropoulos  

**Link**: [PDF](https://arxiv.org/pdf/2503.15172)  

**Abstract**: Multi-Agent Deep Reinforcement Learning (MADRL) has emerged as a powerful tool for optimizing decentralized decision-making systems in complex settings, such as Dynamic Spectrum Access (DSA). However, deploying deep learning models on resource-constrained edge devices remains challenging due to their high computational cost. To address this challenge, in this paper, we present a novel sparse recurrent MARL framework integrating gradual neural network pruning into the independent actor global critic paradigm. Additionally, we introduce a harmonic annealing sparsity scheduler, which achieves comparable, and in certain cases superior, performance to standard linear and polynomial pruning schedulers at large sparsities. Our experimental investigation demonstrates that the proposed DSA framework can discover superior policies, under diverse training conditions, outperforming conventional DSA, MADRL baselines, and state-of-the-art pruning techniques. 

**Abstract (ZH)**: 多代理深度强化学习（MADRL）在网络资源受限的动态频谱访问（DSA）等复杂环境中优化去中心化决策系统方面已成为一种强有力的工具。然而，在资源受限的边缘设备上部署深度学习模型仍然具有挑战性，原因在于其高计算成本。为解决这一挑战，本文提出了一种新颖的稀疏递归多代理强化学习框架，该框架将渐进神经网络剪枝技术集成到独立演员全局批评家范式中。此外，我们引入了一种谐波退火稀疏调度器，在高稀疏性下能够实现与标准线性和多项式剪枝调度器相当，甚至更优的性能。实验研究证明，所提出的DSA框架在各种训练条件下能够发现更优策略，超越了传统的DSA、MADRL基线和最先进的剪枝技术。 

---
# Comparing Llama3 and DeepSeekR1 on Biomedical Text Classification Tasks 

**Title (ZH)**: 比较Llama3和DeepSeekR1在生物医学文本分类任务中的性能 

**Authors**: Yuting Guo, Abeed Sarker  

**Link**: [PDF](https://arxiv.org/pdf/2503.15169)  

**Abstract**: This study compares the performance of two open-source large language models (LLMs)-Llama3-70B and DeepSeekR1-distill-Llama3-70B-on six biomedical text classification tasks. Four tasks involve data from social media, while two tasks focus on clinical notes from electronic health records, and all experiments were performed in zero-shot settings. Performance metrics, including precision, recall, and F1 scores, were measured for each task, along with their 95% confidence intervals. Results demonstrated that DeepSeekR1-distill-Llama3-70B generally performs better in terms of precision on most tasks, with mixed results on recall. While the zero-shot LLMs demonstrated high F1 scores for some tasks, they grossly underperformed on others, for data from both sources. The findings suggest that model selection should be guided by the specific requirements of the health-related text classification tasks, particularly when considering the precision-recall trade-offs, and that, in the presence of annotated data, supervised classification approaches may be more reliable than zero-shot LLMs. 

**Abstract (ZH)**: 本研究比较了两个开源大规模语言模型（LLM）——Llama3-70B和DeepSeekR1-distill-Llama3-70B在六项生物医学文本分类任务中的性能。四项任务涉及社交媒体数据，而两项任务则专注于电子健康记录中的临床笔记，所有实验均在零样本设置下进行。测量了每个任务的精确度、召回率和F1分数，以及它们的95%置信区间。结果显示，DeepSeekR1-distill-Llama3-70B在大多数任务中通常在精确度方面表现更好，召回率的表现则参差不齐。虽然零样本LLM在某些任务上表现出高F1分数，但在其他任务上，无论是哪种数据源，它们的表现都非常糟糕。研究结果表明，在选择模型时应根据健康相关文本分类任务的具体要求进行，尤其是在考虑精确度与召回率之间的权衡时，而且在有标注数据的情况下，监督分类方法可能比零样本LLM更加可靠。 

---
# Volumetric Reconstruction From Partial Views for Task-Oriented Grasping 

**Title (ZH)**: 基于部分视角的体积重建用于任务导向的抓取 

**Authors**: Fujian Yan, Hui Li, Hongsheng He  

**Link**: [PDF](https://arxiv.org/pdf/2503.15167)  

**Abstract**: Object affordance and volumetric information are essential in devising effective grasping strategies under task-specific constraints. This paper presents an approach for inferring suitable grasping strategies from limited partial views of an object. To achieve this, a recurrent generative adversarial network (R-GAN) was proposed by incorporating a recurrent generator with long short-term memory (LSTM) units for it to process a variable number of depth scans. To determine object affordances, the AffordPose knowledge dataset is utilized as prior knowledge. Affordance retrieving is defined by the volume similarity measured via Chamfer Distance and action similarities. A Proximal Policy Optimization (PPO) reinforcement learning model is further implemented to refine the retrieved grasp strategies for task-oriented grasping. The retrieved grasp strategies were evaluated on a dual-arm mobile manipulation robot with an overall grasping accuracy of 89% for four tasks: lift, handle grasp, wrap grasp, and press. 

**Abstract (ZH)**: 基于任务特定约束的有效抓取策略设计需要考虑物体功能和体素信息。本文提出了一种从物体有限部分视图中推断合适抓取策略的方法。为此，提出了一种递归生成对抗网络（R-GAN），该网络结合了包含长短期记忆（LSTM）单元的递归生成器，以处理不同数量的深度扫描。为了确定物体功能，利用AffordPose知识数据集作为先验知识。通过坎泊尔距离测量的体积相似性和动作相似性定义功能提取。进一步实现了近端策略优化（PPO）强化学习模型以针对任务细化提取的抓取策略。在双臂移动操作机器人上评估了提取的抓取策略，在四项任务（起吊、柄抓、包握和压握）中总体抓取准确率为89%。 

---
# Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU 

**Title (ZH)**: 超曲面与欧几里得多元对比学习中的机器忘记：适应MERU的对齐校准 

**Authors**: Àlex Pujol Vidal, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund  

**Link**: [PDF](https://arxiv.org/pdf/2503.15166)  

**Abstract**: Machine unlearning methods have become increasingly important for selective concept removal in large pre-trained models. While recent work has explored unlearning in Euclidean contrastive vision-language models, the effectiveness of concept removal in hyperbolic spaces remains unexplored. This paper investigates machine unlearning in hyperbolic contrastive learning by adapting Alignment Calibration to MERU, a model that embeds images and text in hyperbolic space to better capture semantic hierarchies. Through systematic experiments and ablation studies, we demonstrate that hyperbolic geometry offers distinct advantages for concept removal, achieving near perfect forgetting with reasonable performance on retained concepts, particularly when scaling to multiple concept removal. Our approach introduces hyperbolic-specific components including entailment calibration and norm regularization that leverage the unique properties of hyperbolic space. Comparative analysis with Euclidean models reveals fundamental differences in unlearning dynamics, with hyperbolic unlearning reorganizing the semantic hierarchy while Euclidean approaches merely disconnect cross-modal associations. These findings not only advance machine unlearning techniques but also provide insights into the geometric properties that influence concept representation and removal in multimodal models. Source code available at this https URL 

**Abstract (ZH)**: 机器未学习方法在双曲对比学习中的概念移除研究：通过将对齐校准适应MERU模型探究双曲空间中的概念移除效果 

---
# A Foundational Theory for Decentralized Sensory Learning 

**Title (ZH)**: 去中心化感官学习的基础理论 

**Authors**: Linus Mårtensson, Jonas M.D. Enander, Udaya B. Rongala, Henrik Jörntell  

**Link**: [PDF](https://arxiv.org/pdf/2503.15130)  

**Abstract**: In both neuroscience and artificial intelligence, popular functional frameworks and neural network formulations operate by making use of extrinsic error measurements and global learning algorithms. Through a set of conjectures based on evolutionary insights on the origin of cellular adaptive mechanisms, we reinterpret the core meaning of sensory signals to allow the brain to be interpreted as a negative feedback control system, and show how this could lead to local learning algorithms without the need for global error correction metrics. Thereby, a sufficiently good minima in sensory activity can be the complete reward signal of the network, as well as being both necessary and sufficient for biological learning to arise. We show that this method of learning was likely already present in the earliest unicellular life forms on earth. We show evidence that the same principle holds and scales to multicellular organisms where it in addition can lead to division of labour between cells. Available evidence shows that the evolution of the nervous system likely was an adaptation to more effectively communicate intercellular signals to support such division of labour. We therefore propose that the same learning principle that evolved already in the earliest unicellular life forms, i.e. negative feedback control of externally and internally generated sensor signals, has simply been scaled up to become a fundament of the learning we see in biological brains today. We illustrate diverse biological settings, from the earliest unicellular organisms to humans, where this operational principle appears to be a plausible interpretation of the meaning of sensor signals in biology, and how this relates to current neuroscientific theories and findings. 

**Abstract (ZH)**: 在神经科学和人工智能中，流行的功能性框架和神经网络形式化方法通过利用外在误差测量和全局学习算法来运作。通过基于细胞适应机制起源的进化洞察的一系列猜想，我们重新解释了感官信号的核心意义，允许大脑被解释为一个负反馈控制系统，并展示了如何这可以导致无需全局误差矫正度量的局部学习算法。因此，感官活动中的足够好的极小值可以成为网络的完整奖励信号，同时也是生物学习出现的必要和充分条件。我们证明，在地球最早期的单细胞生物中很可能就已经存在这种学习方式。我们还展示了同样的原理在多细胞生物中适用并可扩展，而且在这种情况下，它还可能导致细胞之间的劳动分工。现有证据表明，神经系统的进化很可能是为了更有效地传递细胞间信号，以支持这种劳动分工。因此，我们提出，在最早期的单细胞生物中已经进化出的负反馈控制外部和内部生成的传感器信号的学习原理，只是在今天生物大脑中的学习中得到了放大。我们展示了从最早期的单细胞生物到人类的多样化的生物设置，其中这种操作原理似乎是生物学中传感器信号意义的一种合理解释，并探讨了它与当前神经科学理论和发现之间的关系。 

---
# Increasing the Robustness of the Fine-tuned Multilingual Machine-Generated Text Detectors 

**Title (ZH)**: 增强细调多语言机器生成文本检测器的鲁棒性 

**Authors**: Dominik Macko, Robert Moro, Ivan Srba  

**Link**: [PDF](https://arxiv.org/pdf/2503.15128)  

**Abstract**: Since the proliferation of LLMs, there have been concerns about their misuse for harmful content creation and spreading. Recent studies justify such fears, providing evidence of LLM vulnerabilities and high potential of their misuse. Humans are no longer able to distinguish between high-quality machine-generated and authentic human-written texts. Therefore, it is crucial to develop automated means to accurately detect machine-generated content. It would enable to identify such content in online information space, thus providing an additional information about its credibility. This work addresses the problem by proposing a robust fine-tuning process of LLMs for the detection task, making the detectors more robust against obfuscation and more generalizable to out-of-distribution data. 

**Abstract (ZH)**: 自大规模语言模型的兴起以来，人们对其用于有害内容创作和传播的滥用表示担忧。近期研究证实了这种担忧，提供了关于语言模型漏洞及其滥用潜力的证据。人类现在难以区分高质量的机器生成文本和真实的人类撰写的文本。因此，开发准确检测机器生成内容的自动化方法至关重要。这将有助于在在线信息空间中识别此类内容，从而提供其可信度的额外信息。本工作通过提出一种稳健的大型语言模型微调过程来解决这个问题，使检测器更 robust 地抵抗混淆，并更具泛化性以应对分布外数据。 

---
# Text-Derived Relational Graph-Enhanced Network for Skeleton-Based Action Segmentation 

**Title (ZH)**: 基于文本衍生关系图增强的骨架基动作分割网络 

**Authors**: Haoyu Ji, Bowen Chen, Weihong Ren, Wenze Huang, Zhihao Yang, Zhiyong Wang, Honghai Liu  

**Link**: [PDF](https://arxiv.org/pdf/2503.15126)  

**Abstract**: Skeleton-based Temporal Action Segmentation (STAS) aims to segment and recognize various actions from long, untrimmed sequences of human skeletal movements. Current STAS methods typically employ spatio-temporal modeling to establish dependencies among joints as well as frames, and utilize one-hot encoding with cross-entropy loss for frame-wise classification supervision. However, these methods overlook the intrinsic correlations among joints and actions within skeletal features, leading to a limited understanding of human movements. To address this, we propose a Text-Derived Relational Graph-Enhanced Network (TRG-Net) that leverages prior graphs generated by Large Language Models (LLM) to enhance both modeling and supervision. For modeling, the Dynamic Spatio-Temporal Fusion Modeling (DSFM) method incorporates Text-Derived Joint Graphs (TJG) with channel- and frame-level dynamic adaptation to effectively model spatial relations, while integrating spatio-temporal core features during temporal modeling. For supervision, the Absolute-Relative Inter-Class Supervision (ARIS) method employs contrastive learning between action features and text embeddings to regularize the absolute class distributions, and utilizes Text-Derived Action Graphs (TAG) to capture the relative inter-class relationships among action features. Additionally, we propose a Spatial-Aware Enhancement Processing (SAEP) method, which incorporates random joint occlusion and axial rotation to enhance spatial generalization. Performance evaluations on four public datasets demonstrate that TRG-Net achieves state-of-the-art results. 

**Abstract (ZH)**: 基于骨架的时间动作分割（STAS）旨在从长未修剪的人体骨架运动序列中分割和识别各种动作。当前的STAS方法通常采用时空建模来建立关节之间的依赖关系以及帧之间的依赖关系，并使用one-hot编码加交叉熵损失对帧级分类监督。然而，这些方法忽略了骨架特征中关节和动作的内在相关性，导致对人类运动的理解有限。为了解决这个问题，我们提出了一种基于文本驱动关系图增强网络（TRG-Net），该网络利用大型语言模型（LLM）生成的先验图来增强建模和监督。在建模方面，动态时空融合建模（DSFM）方法结合了文本驱动关节图（TJG），并采用通道级和帧级动态适应来有效建模空间关系，在时间建模过程中整合时空核心特征。在监督方面，绝对相对跨类监督（ARIS）方法通过对照学习动作特征和文本嵌入来正则化绝对类分布，并利用文本驱动动作图（TAG）捕获动作特征之间的相对跨类关系。此外，我们还提出了一种空间感知增强处理（SAEP）方法，该方法通过随机关节遮挡和轴向旋转来增强空间泛化能力。在四个公开数据集上的性能评估表明，TRG-Net取得了当前最先进的成果。 

---
# VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making 

**Title (ZH)**: VIPER：视觉感知与可解释推理在序列决策中的应用 

**Authors**: Mohamed Salim Aissi, Clemence Grislain, Mohamed Chetouani, Olivier Sigaud, Laure Soulier, Nicolas Thome  

**Link**: [PDF](https://arxiv.org/pdf/2503.15108)  

**Abstract**: While Large Language Models (LLMs) excel at reasoning on text and Vision-Language Models (VLMs) are highly effective for visual perception, applying those models for visual instruction-based planning remains a widely open problem. In this paper, we introduce VIPER, a novel framework for multimodal instruction-based planning that integrates VLM-based perception with LLM-based reasoning. Our approach uses a modular pipeline where a frozen VLM generates textual descriptions of image observations, which are then processed by an LLM policy to predict actions based on the task goal. We fine-tune the reasoning module using behavioral cloning and reinforcement learning, improving our agent's decision-making capabilities. Experiments on the ALFWorld benchmark show that VIPER significantly outperforms state-of-the-art visual instruction-based planners while narrowing the gap with purely text-based oracles. By leveraging text as an intermediate representation, VIPER also enhances explainability, paving the way for a fine-grained analysis of perception and reasoning components. 

**Abstract (ZH)**: 而大规模语言模型（LLMs）在文本推理方面表现出色，视觉语言模型（VLMs）在视觉感知方面非常有效，但将这些模型应用于基于视觉指令的规划仍然是一个开放性问题。本文介绍了VIPER，这是一种结合VLM基于的感知与LLM基于的推理的新型多模态指令驱动规划框架。我们的方法采用模块化流水线，其中冻结的VLM生成图像观察的文本描述，随后由LLM策略基于任务目标预测动作。我们通过行为克隆和强化学习微调推理模块，提高代理的决策能力。在ALFWorld基准测试中的实验表明，VIPER显著优于现有的基于视觉指令的规划器，并缩小了与纯文本基准则确性之间的差距。通过利用文本作为中间表示，VIPER增强了可解释性，为感知和推理组件的细粒度分析铺平了道路。 

---
# Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control 

**Title (ZH)**: 基于扩散的预测方法以实现不确定性感知的模型预测控制 

**Authors**: Stelios Zarifis, Ioannis Kordonis, Petros Maragos  

**Link**: [PDF](https://arxiv.org/pdf/2503.15095)  

**Abstract**: We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic framework for uncertainty-aware prediction and decision-making in partially observable stochastic systems by integrating diffusion-based time series forecasting models in Model Predictive Control algorithms. In our approach, a diffusion-based time series forecasting model is used to probabilistically estimate the evolution of the system's stochastic components. These forecasts are then incorporated into MPC algorithms to estimate future trajectories and optimize action selection under the uncertainty of the future. We evaluate the framework on the task of energy arbitrage, where a Battery Energy Storage System participates in the day-ahead electricity market of the New York state. Experimental results indicate that our model-based approach with a diffusion-based forecaster significantly outperforms both implementations with classical forecasting methods and model-free reinforcement learning baselines. 

**Abstract (ZH)**: 基于扩散模型的模型预测控制（D-I MPC）：在部分可观测随机系统中实现不确定性意识的预测与决策 

---
# Towards Understanding the Safety Boundaries of DeepSeek Models: Evaluation and Findings 

**Title (ZH)**: 探索深Seek模型的安全边界：评估与发现 

**Authors**: Zonghao Ying, Guangyi Zheng, Yongxin Huang, Deyue Zhang, Wenxin Zhang, Quanchen Zou, Aishan Liu, Xianglong Liu, Dacheng Tao  

**Link**: [PDF](https://arxiv.org/pdf/2503.15092)  

**Abstract**: This study presents the first comprehensive safety evaluation of the DeepSeek models, focusing on evaluating the safety risks associated with their generated content. Our evaluation encompasses DeepSeek's latest generation of large language models, multimodal large language models, and text-to-image models, systematically examining their performance regarding unsafe content generation. Notably, we developed a bilingual (Chinese-English) safety evaluation dataset tailored to Chinese sociocultural contexts, enabling a more thorough evaluation of the safety capabilities of Chinese-developed models. Experimental results indicate that despite their strong general capabilities, DeepSeek models exhibit significant safety vulnerabilities across multiple risk dimensions, including algorithmic discrimination and sexual content. These findings provide crucial insights for understanding and improving the safety of large foundation models. Our code is available at this https URL. 

**Abstract (ZH)**: 本研究首次全面评估了DeepSeek模型的安全性，重点关注其生成内容相关的安全风险。我们的评估涵盖了DeepSeek最新一代的大语言模型、多模态大语言模型和文本到图像模型，系统地检查了它们在产生不当内容方面的性能。值得注意的是，我们开发了一个适用于中国社会文化背景的双语（中文-英文）安全评估数据集，使对中文开发模型的安全能力进行更全面的评估成为可能。实验结果表明，尽管DeepSeek模型具有强大的通用能力，但在多个安全风险维度上仍表现出显著的安全漏洞，包括算法歧视和性内容。这些发现为理解并改进大型基础模型的安全性提供了重要见解。我们的代码可在以下链接获取。 

---
# Conjuring Positive Pairs for Efficient Unification of Representation Learning and Image Synthesis 

**Title (ZH)**: 召唤正样本对以高效统一表示学习与图像合成 

**Authors**: Imanol G. Estepa, Jesús M. Rodríguez-de-Vera, Ignacio Sarasúa, Bhalaji Nagarajan, Petia Radeva  

**Link**: [PDF](https://arxiv.org/pdf/2503.15060)  

**Abstract**: While representation learning and generative modeling seek to understand visual data, unifying both domains remains unexplored. Recent Unified Self-Supervised Learning (SSL) methods have started to bridge the gap between both paradigms. However, they rely solely on semantic token reconstruction, which requires an external tokenizer during training -- introducing a significant overhead. In this work, we introduce Sorcen, a novel unified SSL framework, incorporating a synergic Contrastive-Reconstruction objective. Our Contrastive objective, "Echo Contrast", leverages the generative capabilities of Sorcen, eliminating the need for additional image crops or augmentations during training. Sorcen "generates" an echo sample in the semantic token space, forming the contrastive positive pair. Sorcen operates exclusively on precomputed tokens, eliminating the need for an online token transformation during training, thereby significantly reducing computational overhead. Extensive experiments on ImageNet-1k demonstrate that Sorcen outperforms the previous Unified SSL SoTA by 0.4%, 1.48 FID, 1.76%, and 1.53% on linear probing, unconditional image generation, few-shot learning, and transfer learning, respectively, while being 60.8% more efficient. Additionally, Sorcen surpasses previous single-crop MIM SoTA in linear probing and achieves SoTA performance in unconditional image generation, highlighting significant improvements and breakthroughs in Unified SSL models. 

**Abstract (ZH)**: Sorcen：一种新颖的协同对比重建统一自监督学习框架 

---
# Texture-Aware StarGAN for CT data harmonisation 

**Title (ZH)**: 面向纹理的StarGAN在CT数据调和中的应用 

**Authors**: Francesco Di Feola, Ludovica Pompilio, Cecilia Assolito, Valerio Guarrasi, Paolo Soda  

**Link**: [PDF](https://arxiv.org/pdf/2503.15058)  

**Abstract**: Computed Tomography (CT) plays a pivotal role in medical diagnosis; however, variability across reconstruction kernels hinders data-driven approaches, such as deep learning models, from achieving reliable and generalized performance. To this end, CT data harmonization has emerged as a promising solution to minimize such non-biological variances by standardizing data across different sources or conditions. In this context, Generative Adversarial Networks (GANs) have proved to be a powerful framework for harmonization, framing it as a style-transfer problem. However, GAN-based approaches still face limitations in capturing complex relationships within the images, which are essential for effective harmonization. In this work, we propose a novel texture-aware StarGAN for CT data harmonization, enabling one-to-many translations across different reconstruction kernels. Although the StarGAN model has been successfully applied in other domains, its potential for CT data harmonization remains unexplored. Furthermore, our approach introduces a multi-scale texture loss function that embeds texture information across different spatial and angular scales into the harmonization process, effectively addressing kernel-induced texture variations. We conducted extensive experimentation on a publicly available dataset, utilizing a total of 48667 chest CT slices from 197 patients distributed over three different reconstruction kernels, demonstrating the superiority of our method over the baseline StarGAN. 

**Abstract (ZH)**: 计算机断层扫描（CT）在医学诊断中发挥着关键作用；然而，不同重建内核之间的差异阻碍了深度学习等数据驱动方法的可靠性和通用性表现。为此，CT数据谐调作为减轻这种非生物学差异的一种有前途的解决方案应运而生，它通过标准化来自不同来源或条件的数据来最小化这些差异。在这个背景下，生成对抗网络（GANs）已被证明是谐调的一种强大框架，将其视为一种风格迁移问题。然而，基于GAN的方法仍然难以捕捉图像中复杂的相互关系，这对于有效的谐调至关重要。在本文中，我们提出了一种新的纹理感知StarGAN用于CT数据谐调，使其能够在不同的重建内核之间实现一对多的翻译。尽管StarGAN模型已在其他领域取得成功应用，但其在CT数据谐调领域的潜力尚未得到探索。此外，我们的方法引入了一种多尺度纹理损失函数，将不同空间和角度尺度的纹理信息嵌入到谐调过程，有效解决了由内核引起的纹理变化。我们通过在公开可用的数据集上进行广泛的实验，利用197名患者共计48667个胸部CT切片分布在三个不同的重建内核中，展示了我们方法相对于基线StarGAN的优越性。 

---
# HAD-Gen: Human-like and Diverse Driving Behavior Modeling for Controllable Scenario Generation 

**Title (ZH)**: HAD-Gen: 类人且多样的驾驶行为建模以实现可控场景生成 

**Authors**: Cheng Wang, Lingxin Kong, Massimiliano Tamborski, Stefano V. Albrecht  

**Link**: [PDF](https://arxiv.org/pdf/2503.15049)  

**Abstract**: Simulation-based testing has emerged as an essential tool for verifying and validating autonomous vehicles (AVs). However, contemporary methodologies, such as deterministic and imitation learning-based driver models, struggle to capture the variability of human-like driving behavior. Given these challenges, we propose HAD-Gen, a general framework for realistic traffic scenario generation that simulates diverse human-like driving behaviors. The framework first clusters the vehicle trajectory data into different driving styles according to safety features. It then employs maximum entropy inverse reinforcement learning on each of the clusters to learn the reward function corresponding to each driving style. Using these reward functions, the method integrates offline reinforcement learning pre-training and multi-agent reinforcement learning algorithms to obtain general and robust driving policies. Multi-perspective simulation results show that our proposed scenario generation framework can simulate diverse, human-like driving behaviors with strong generalization capability. The proposed framework achieves a 90.96% goal-reaching rate, an off-road rate of 2.08%, and a collision rate of 6.91% in the generalization test, outperforming prior approaches by over 20% in goal-reaching performance. The source code is released at this https URL. 

**Abstract (ZH)**: 基于仿真测试的自动驾驶车辆真实交通场景生成框架：HAD-Gen 

---
# A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection 

**Title (ZH)**: 一种基于信道增强残差CNN-Transformer与区域边界的乳腺癌检测方法 

**Authors**: Aamir Mehmood, Yue Hu, Saddam Hussain Khan  

**Link**: [PDF](https://arxiv.org/pdf/2503.15008)  

**Abstract**: Recent advancements in detecting tumors using deep learning on breast ultrasound images (BUSI) have demonstrated significant success. Deep CNNs and vision-transformers (ViTs) have demonstrated individually promising initial performance. However, challenges related to model complexity and contrast, texture, and tumor morphology variations introduce uncertainties that hinder the effectiveness of current methods. This study introduces a novel hybrid framework, CB-Res-RBCMT, combining customized residual CNNs and new ViT components for detailed BUSI cancer analysis. The proposed RBCMT uses stem convolution blocks with CNN Meet Transformer (CMT) blocks, followed by new Regional and boundary (RB) feature extraction operations for capturing contrast and morphological variations. Moreover, the CMT block incorporates global contextual interactions through multi-head attention, enhancing computational efficiency with a lightweight design. Additionally, the customized inverse residual and stem CNNs within the CMT effectively extract local texture information and handle vanishing gradients. Finally, the new channel-boosted (CB) strategy enriches the feature diversity of the limited dataset by combining the original RBCMT channels with transfer learning-based residual CNN-generated maps. These diverse channels are processed through a spatial attention block for optimal pixel selection, reducing redundancy and improving the discrimination of minor contrast and texture variations. The proposed CB-Res-RBCMT achieves an F1-score of 95.57%, accuracy of 95.63%, sensitivity of 96.42%, and precision of 94.79% on the standard harmonized stringent BUSI dataset, outperforming existing ViT and CNN methods. These results demonstrate the versatility of our integrated CNN-Transformer framework in capturing diverse features and delivering superior performance in BUSI cancer diagnosis. 

**Abstract (ZH)**: Recent advancements in detecting tumors using deep learning on breast ultrasound images (BUSI) have demonstrated significant success. Deep CNNs and vision-transformers (ViTs) have demonstrated individually promising initial performance. However, challenges related to model complexity and contrast, texture, and tumor morphology variations introduce uncertainties that hinder the effectiveness of current methods. This study introduces a novel hybrid framework, CB-Res-RBCMT, combining customized residual CNNs and new ViT components for detailed BUSI cancer analysis. 

---
# Application of linear regression method to the deep reinforcement learning in continuous action cases 

**Title (ZH)**: 线性回归方法在连续动作情况下的深度强化学习应用 

**Authors**: Hisato Komatsu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14976)  

**Abstract**: The linear regression (LR) method offers the advantage that optimal parameters can be calculated relatively easily, although its representation capability is limited than that of the deep learning technique. To improve deep reinforcement learning, the Least Squares Deep Q Network (LS-DQN) method was proposed by Levine et al., which combines Deep Q Network (DQN) with LR method. However, the LS-DQN method assumes that the actions are discrete. In this study, we propose the Double Least Squares Deep Deterministic Policy Gradient (DLS-DDPG) method to address this limitation. This method combines the LR method with the Deep Deterministic Policy Gradient (DDPG) technique, one of the representative deep reinforcement learning algorithms for continuous action cases. Numerical experiments conducted in MuJoCo environments showed that the LR update improved performance at least in some tasks, although there are difficulties such as the inability to make the regularization terms small. 

**Abstract (ZH)**: 基于最小二乘的双层深度确定性策略梯度方法（DLS-DDPG） 

---
# USAM-Net: A U-Net-based Network for Improved Stereo Correspondence and Scene Depth Estimation using Features from a Pre-trained Image Segmentation network 

**Title (ZH)**: USAM-Net：一种基于U-Net的网络，结合预训练图像分割网络的特征以改进立体匹配和场景深度估计 

**Authors**: Joseph Emmanuel DL Dayo, Prospero C. Naval Jr  

**Link**: [PDF](https://arxiv.org/pdf/2503.14950)  

**Abstract**: The increasing demand for high-accuracy depth estimation in autonomous driving and augmented reality applications necessitates advanced neural architectures capable of effectively leveraging multiple data modalities. In this context, we introduce the Unified Segmentation Attention Mechanism Network (USAM-Net), a novel convolutional neural network that integrates stereo image inputs with semantic segmentation maps and attention to enhance depth estimation performance. USAM-Net employs a dual-pathway architecture, which combines a pre-trained segmentation model (SAM) and a depth estimation model. The segmentation pathway preprocesses the stereo images to generate semantic masks, which are then concatenated with the stereo images as inputs to the depth estimation pathway. This integration allows the model to focus on important features such as object boundaries and surface textures which are crucial for accurate depth perception. Empirical evaluation on the DrivingStereo dataset demonstrates that USAM-Net achieves superior performance metrics, including a Global Difference (GD) of 3.61\% and an End-Point Error (EPE) of 0.88, outperforming traditional models such as CFNet, SegStereo, and iResNet. These results underscore the effectiveness of integrating segmentation information into stereo depth estimation tasks, highlighting the potential of USAM-Net in applications demanding high-precision depth data. 

**Abstract (ZH)**: 统一分割注意力机制网络（USAM-Net）：结合语义分割和注意力机制的立体深度估计 

---
# FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding 

**Title (ZH)**: FAVOR-Bench: 一种全面的细粒度视频运动理解基准 

**Authors**: Chongjun Tu, Lin Zhang, Pengtao Chen, Peng Ye, Xianfang Zeng, Wei Cheng, Gang Yu, Tao Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.14935)  

**Abstract**: Multimodal Large Language Models (MLLMs) have shown remarkable capabilities in video content understanding but still struggle with fine-grained motion comprehension. To comprehensively assess the motion understanding ability of existing MLLMs, we introduce FAVOR-Bench, comprising 1,776 videos with structured manual annotations of various motions. Our benchmark includes both close-ended and open-ended tasks. For close-ended evaluation, we carefully design 8,184 multiple-choice question-answer pairs spanning six distinct sub-tasks. For open-ended evaluation, we develop both a novel cost-efficient LLM-free and a GPT-assisted caption assessment method, where the former can enhance benchmarking interpretability and reproducibility. Comprehensive experiments with 21 state-of-the-art MLLMs reveal significant limitations in their ability to comprehend and describe detailed temporal dynamics in video motions. To alleviate this limitation, we further build FAVOR-Train, a dataset consisting of 17,152 videos with fine-grained motion annotations. The results of finetuning Qwen2.5-VL on FAVOR-Train yield consistent improvements on motion-related tasks of TVBench, MotionBench and our FAVOR-Bench. Comprehensive assessment results demonstrate that the proposed FAVOR-Bench and FAVOR-Train provide valuable tools to the community for developing more powerful video understanding models. Project page: \href{this https URL}{this https URL}. 

**Abstract (ZH)**: 多模态大型语言模型（MLLMs）在视频内容理解方面展现出显著的能力，但仍难以理解细微动作。为全面评估现有MLLMs的动作理解能力，我们引入了FAAVOR-Bench，包含1,776个视频，并附有结构化的手动标注的各种动作。基准包括封闭式和开放式任务。对于封闭式评估，我们精心设计了8,184个多选题-答案对，涵盖六个不同的子任务。对于开放式评估，我们开发了一种成本效益高且无需大型语言模型的方法和一种基于GPT的字幕评估方法，前者可提高基准的可解释性和可再现性。全面实验表明，当前最先进的MLLMs在理解视频动作的详细时序动态方面存在显著局限。为此，我们进一步构建了FAAVOR-Train数据集，包含17,152个细粒度动作标注的视频。基于FAAVOR-Train微调Qwen2.5-VL在TVBench、MotionBench和FAAVOR-Bench上的性能均得到一致提升。全面评估结果表明，提出的FAAVOR-Bench和FAAVOR-Train为开发更强大的视频理解模型提供了有价值的工具。项目页面：\href{this https URL}{this https URL}。 

---
# Shushing! Let's Imagine an Authentic Speech from the Silent Video 

**Title (ZH)**: 静音了！让我们想象一段真实的无声视频中的演讲。 

**Authors**: Jiaxin Ye, Hongming Shan  

**Link**: [PDF](https://arxiv.org/pdf/2503.14928)  

**Abstract**: Vision-guided speech generation aims to produce authentic speech from facial appearance or lip motions without relying on auditory signals, offering significant potential for applications such as dubbing in filmmaking and assisting individuals with aphonia. Despite recent progress, existing methods struggle to achieve unified cross-modal alignment across semantics, timbre, and emotional prosody from visual cues, prompting us to propose Consistent Video-to-Speech (CV2S) as an extended task to enhance cross-modal consistency. To tackle emerging challenges, we introduce ImaginTalk, a novel cross-modal diffusion framework that generates faithful speech using only visual input, operating within a discrete space. Specifically, we propose a discrete lip aligner that predicts discrete speech tokens from lip videos to capture semantic information, while an error detector identifies misaligned tokens, which are subsequently refined through masked language modeling with BERT. To further enhance the expressiveness of the generated speech, we develop a style diffusion transformer equipped with a face-style adapter that adaptively customizes identity and prosody dynamics across both the channel and temporal dimensions while ensuring synchronization with lip-aware semantic features. Extensive experiments demonstrate that ImaginTalk can generate high-fidelity speech with more accurate semantic details and greater expressiveness in timbre and emotion compared to state-of-the-art baselines. Demos are shown at our project page: this https URL. 

**Abstract (ZH)**: 基于视觉引导的语音生成旨在从面部外观或唇部动作生成逼真语音，而不依赖于听觉信号，为电影配音等领域和帮助失声个体提供了显著的应用潜力。虽然近期取得了进展，但现有方法在从视觉线索中统一实现语义、音色和情感韵律的一致性方面仍面临挑战，为此我们提出了Consistent Video-to-Speech (CV2S) 作为增强跨模态一致性的一种扩展任务。为应对新兴挑战，我们引入了ImaginTalk，这是一种新颖的跨模态扩散框架，仅使用视觉输入生成忠实语音，并在离散空间内操作。具体而言，我们提出了一个离散唇部对齐器，从唇部视频中预测离散语音标记以捕捉语义信息，同时错误检测器识别错位的标记，随后通过掩码语言建模与BERT进行修正。为了进一步增强生成语音的表现力，我们开发了一种样式扩散变换器，配备了面部样式适配器，能够在通道和时间维度上自适应地定制身份和韵律动态，并确保与唇部意识语义特征的同步。大量实验表明，ImaginTalk相比现有最先进的基线能够生成更高保真度的语音，具有更准确的语义细节和更具表现力的音色和情感。展示演示请参见我们的项目页面：https://your-project-page-url。 

---
# A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks 

**Title (ZH)**: 面向图卷积网络的语义和干净标签后门攻击 

**Authors**: Jiazhu Dai, Haoyu Sun  

**Link**: [PDF](https://arxiv.org/pdf/2503.14922)  

**Abstract**: Graph Convolutional Networks (GCNs) have shown excellent performance in graph-structured tasks such as node classification and graph classification. However, recent research has shown that GCNs are vulnerable to a new type of threat called the backdoor attack, where the adversary can inject a hidden backdoor into the GCNs so that the backdoored model performs well on benign samples, whereas its prediction will be maliciously changed to the attacker-specified target label if the hidden backdoor is activated by the attacker-defined trigger. Clean-label backdoor attack and semantic backdoor attack are two new backdoor attacks to Deep Neural Networks (DNNs), they are more imperceptible and have posed new and serious threats. The semantic and clean-label backdoor attack is not fully explored in GCNs. In this paper, we propose a semantic and clean-label backdoor attack against GCNs under the context of graph classification to reveal the existence of this security vulnerability in GCNs. Specifically, SCLBA conducts an importance analysis on graph samples to select one type of node as semantic trigger, which is then inserted into the graph samples to create poisoning samples without changing the labels of the poisoning samples to the attacker-specified target label. We evaluate SCLBA on multiple datasets and the results show that SCLBA can achieve attack success rates close to 99% with poisoning rates of less than 3%, and with almost no impact on the performance of model on benign samples. 

**Abstract (ZH)**: Graph卷积网络中的语义清洁标签后门攻击 

---
# MASS: Mathematical Data Selection via Skill Graphs for Pretraining Large Language Models 

**Title (ZH)**: MASS：通过技能图进行数学数据选择以预训练大规模语言模型 

**Authors**: Jiazheng Li, Lu Yu, Qing Cui, Zhiqiang Zhang, Jun Zhou, Yanfang Ye, Chuxu Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14917)  

**Abstract**: High-quality data plays a critical role in the pretraining and fine-tuning of large language models (LLMs), even determining their performance ceiling to some degree. Consequently, numerous data selection methods have been proposed to identify subsets of data that can effectively and efficiently enhance model performance. However, most of these methods focus on general data selection and tend to overlook the specific nuances of domain-related data. In this paper, we introduce MASS, a \textbf{MA}thematical data \textbf{S}election framework using the \textbf{S}kill graph for pretraining LLMs in the mathematical reasoning domain. By taking into account the unique characteristics of mathematics and reasoning, we construct a skill graph that captures the mathematical skills and their interrelations from a reference dataset. This skill graph guides us in assigning quality scores to the target dataset, enabling us to select the top-ranked subset which is further used to pretrain LLMs. Experimental results demonstrate the efficiency and effectiveness of MASS across different model sizes (1B and 7B) and pretraining datasets (web data and synthetic data). Specifically, in terms of efficiency, models trained on subsets selected by MASS can achieve similar performance to models trained on the original datasets, with a significant reduction in the number of trained tokens - ranging from 50\% to 70\% fewer tokens. In terms of effectiveness, when trained on the same amount of tokens, models trained on the data selected by MASS outperform those trained on the original datasets by 3.3\% to 5.9\%. These results underscore the potential of MASS to improve both the efficiency and effectiveness of pretraining LLMs. 

**Abstract (ZH)**: 数学数据选择框架MASS：基于技能图的大型语言模型数学推理领域预训练数据分析 

---
# POSTA: A Go-to Framework for Customized Artistic Poster Generation 

**Title (ZH)**: POSTA：一种定制化艺术海报生成的通用框架 

**Authors**: Haoyu Chen, Xiaojie Xu, Wenbo Li, Jingjing Ren, Tian Ye, Songhua Liu, Ying-Cong Chen, Lei Zhu, Xinchao Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14908)  

**Abstract**: Poster design is a critical medium for visual communication. Prior work has explored automatic poster design using deep learning techniques, but these approaches lack text accuracy, user customization, and aesthetic appeal, limiting their applicability in artistic domains such as movies and exhibitions, where both clear content delivery and visual impact are essential. To address these limitations, we present POSTA: a modular framework powered by diffusion models and multimodal large language models (MLLMs) for customized artistic poster generation. The framework consists of three modules. Background Diffusion creates a themed background based on user input. Design MLLM then generates layout and typography elements that align with and complement the background style. Finally, to enhance the poster's aesthetic appeal, ArtText Diffusion applies additional stylization to key text elements. The final result is a visually cohesive and appealing poster, with a fully modular process that allows for complete customization. To train our models, we develop the PosterArt dataset, comprising high-quality artistic posters annotated with layout, typography, and pixel-level stylized text segmentation. Our comprehensive experimental analysis demonstrates POSTA's exceptional controllability and design diversity, outperforming existing models in both text accuracy and aesthetic quality. 

**Abstract (ZH)**: Poster 设计是视觉通信的关键媒介。尽管已有研究利用深度学习技术探索自动 poster 设计，但这些方法缺乏文字准确性、用户个性化和审美吸引力，限制了其在电影和展览等艺术领域中的应用，而在这些领域中，清晰的内容传达和视觉冲击力至关重要。为了克服这些局限性，我们提出了 POSTA：一种基于扩散模型和多模态大型语言模型 (MLLMs) 的模块化框架，用于自定义艺术 poster 生成。该框架由三个模块组成。背景扩散模块根据用户输入创建主题背景。设计 MLLM 然后生成与背景风格相协调和互补的布局和字体元素。最后，为了增强 poster 的审美吸引力，ArtText 扩散模块对关键文字元素进行进一步的风格化处理。最终结果是一个视觉上连贯且有吸引力的 poster，整个过程完全模块化，允许完全的自定义。为了训练我们的模型，我们开发了 PosterArt 数据集，该数据集包含高质量的艺术 poster，并标注了布局、字体和像素级风格化文字分割。我们全面的实验分析表明，POSTA 在文本准确性和审美质量方面均优于现有模型，具备出色的可控性和设计多样性。 

---
# Deep Contrastive Unlearning for Language Models 

**Title (ZH)**: 深度对比去学习语言模型 

**Authors**: Estrid He, Tabinda Sarwar, Ibrahim Khalil, Xun Yi, Ke Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14900)  

**Abstract**: The past a few years have witnessed the great success of large language models, demonstrating powerful capabilities in comprehending textual data and generating human-like languages. Large language models achieve success by being trained on vast amounts of textual data, including online sources with copyrighted content and user-generated knowledge. However, this comes at a cost: the potential risk of exposing users' privacy and violating copyright protections. Thus, to safeguard individuals' "right to be forgotten", there has been increasing interests in machine unlearning -- the process of removing information carried by particular training samples from a model while not deteriorating its predictive quality. This is a challenging task due to the black-box nature of language models. Most existing studies focus on mitigating the impact of those forgot samples upon a model's outputs, and do not explicitly consider the geometric distributions of samples in the latent space of a model. To address this issue, we propose a machine unlearning framework, named Deep Contrastive Unlearning for fine-Tuning (DeepCUT) language models. Our proposed model achieves machine unlearning by directly optimizing the latent space of a model. Comprehensive experiments on real-world datasets demonstrate the effectiveness and efficiency of DeepCUT with consistent and significant improvement over baseline methods. 

**Abstract (ZH)**: 过去几年大型语言模型取得了巨大成功，展示了其在理解和生成类人类语言方面的强大能力。大型语言模型通过训练大量文本数据实现成功，包括包含版权内容的在线来源和用户生成的知识。然而，这伴随着潜在的风险：泄露用户的隐私和违反版权保护。因此，为了保护个人的“被遗忘权”，机器遗忘——即从模型中移除特定训练样本信息而不降低其预测质量的过程——引起了越来越多的关注。这一任务由于语言模型的黑匣子性质而极具挑战性。现有大多数研究集中于减轻被遗忘样本对模型输出的影响，而没有明确考虑模型潜在空间中样本的几何分布。为了解决这一问题，我们提出了一种机器遗忘框架，名为用于微调的语言模型的深度对比遗忘（DeepCUT）。我们提出的方法通过直接优化模型的潜在空间实现机器遗忘。在真实世界数据集上的全面实验表明，DeepCUT在基线方法上具有显著的有效性和效率，提供了一致的改进。 

---
# Mitigating Object Hallucinations in MLLMs via Multi-Frequency Perturbations 

**Title (ZH)**: 通过多频率扰动缓解MLLMs中的对象幻觉 

**Authors**: Shuo Li, Jiajun Sun, Guodong Zheng, Xiaoran Fan, Yujiong Shen, Yi Lu, Zhiheng Xi, Yuming Yang, Wenming Tan, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14895)  

**Abstract**: Recently, multimodal large language models (MLLMs) have demonstrated remarkable performance in visual-language tasks. However, the authenticity of the responses generated by MLLMs is often compromised by object hallucinations. We identify that a key cause of these hallucinations is the model's over-susceptibility to specific image frequency features in detecting objects. In this paper, we introduce Multi-Frequency Perturbations (MFP), a simple, cost-effective, and pluggable method that leverages both low-frequency and high-frequency features of images to perturb visual feature representations and explicitly suppress redundant frequency-domain features during inference, thereby mitigating hallucinations. Experimental results demonstrate that our method significantly mitigates object hallucinations across various model architectures. Furthermore, as a training-time method, MFP can be combined with inference-time methods to achieve state-of-the-art performance on the CHAIR benchmark. 

**Abstract (ZH)**: 最近，多模态大型语言模型（MLLMs）在视觉语言任务中展现了卓越的表现。然而，MLLMs生成的响应真实性常常受到物体错觉的损害。我们发现这些错觉的一个关键原因是模型对检测物体时过于敏感于特定图像频率特征。在本文中，我们提出了一种简单、成本效益高且易嵌入的方法——多频谱扰动（MFP），该方法利用图像的低频和高频特征来扰动视觉特征表示，并在推理时明确抑制冗余的频域特征，从而减轻错觉。实验结果表明，我们的方法显著减轻了各种模型架构中的物体错觉。此外，作为一种训练时方法，MFP可以与推理时方法结合使用，在CHAIR基准测试上达到当前最佳性能。 

---
# MetaLadder: Ascending Mathematical Solution Quality via Analogical-Problem Reasoning Transfer 

**Title (ZH)**: MetaLadder: 通过类问题推理转移提升数学解决方案质量 

**Authors**: Honglin Lin, Zhuoshi Pan, Yu Li, Qizhi Pei, Xin Gao, Mengzhang Cai, Conghui He, Lijun Wu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14891)  

**Abstract**: Large Language Models (LLMs) have demonstrated promising capabilities in solving mathematical reasoning tasks, leveraging Chain-of-Thought (CoT) data as a vital component in guiding answer generation. Current paradigms typically generate CoT and answers directly for a given problem, diverging from human problem-solving strategies to some extent. Humans often solve problems by recalling analogous cases and leveraging their solutions to reason about the current task. Inspired by this cognitive process, we propose \textbf{MetaLadder}, a novel framework that explicitly prompts LLMs to recall and reflect on meta-problems, those structurally or semantically analogous problems, alongside their CoT solutions before addressing the target problem. Additionally, we introduce a problem-restating mechanism to enhance the model's comprehension of the target problem by regenerating the original question, which further improves reasoning accuracy. Therefore, the model can achieve reasoning transfer from analogical problems, mimicking human-like "learning from examples" and generalization abilities. Extensive experiments on mathematical benchmarks demonstrate that our MetaLadder significantly boosts LLMs' problem-solving accuracy, largely outperforming standard CoT-based methods (\textbf{10.3\%} accuracy gain) and other methods. Our code and data has been released at this https URL. 

**Abstract (ZH)**: 大型语言模型通过显式提示回忆和反映元问题来提升数学推理能力：MetaLadder框架及其实验分析 

---
# Envisioning an AI-Enhanced Mental Health Ecosystem 

**Title (ZH)**: 设想一种增强心理健康的人工智能生态系统 

**Authors**: Kellie Yu Hui Sim, Kenny Tsu Wei Choo  

**Link**: [PDF](https://arxiv.org/pdf/2503.14883)  

**Abstract**: The rapid advancement of Large Language Models (LLMs), reasoning models, and agentic AI approaches coincides with a growing global mental health crisis, where increasing demand has not translated into adequate access to professional support, particularly for underserved populations. This presents a unique opportunity for AI to complement human-led interventions, offering scalable and context-aware support while preserving human connection in this sensitive domain. We explore various AI applications in peer support, self-help interventions, proactive monitoring, and data-driven insights, using a human-centred approach that ensures AI supports rather than replaces human interaction. However, AI deployment in mental health fields presents challenges such as ethical concerns, transparency, privacy risks, and risks of over-reliance. We propose a hybrid ecosystem where where AI assists but does not replace human providers, emphasising responsible deployment and evaluation. We also present some of our early work and findings in several of these AI applications. Finally, we outline future research directions for refining AI-enhanced interventions while adhering to ethical and culturally sensitive guidelines. 

**Abstract (ZH)**: 大型语言模型、推理模型和自主AI方法的快速发展 coincides with an increasing global mental health crisis, where growing demand has not translated into adequate access to professional support, particularly for underserved populations. This presents a unique opportunity for AI to complement human-led interventions, offering scalable and context-aware support while preserving human connection in this sensitive domain. We explore various AI applications in peer support, self-help interventions, proactive monitoring, and data-driven insights, using a human-centred approach that ensures AI supports rather than replaces human interaction. However, AI deployment in mental health fields presents challenges such as ethical concerns, transparency, privacy risks, and risks of over-reliance. We propose a hybrid ecosystem where AI assists but does not replace human providers, emphasizing responsible deployment and evaluation. We also present some of our early work and findings in several of these AI applications. Finally, we outline future research directions for refining AI-enhanced interventions while adhering to ethical and culturally sensitive guidelines. 

---
# Exploring the Limits of KV Cache Compression in Visual Autoregressive Transformers 

**Title (ZH)**: 探索视觉自回归 transformer 中 KV 缓存压缩的极限 

**Authors**: Bo Chen, Xiaoyu Li, Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song  

**Link**: [PDF](https://arxiv.org/pdf/2503.14881)  

**Abstract**: A fundamental challenge in Visual Autoregressive models is the substantial memory overhead required during inference to store previously generated representations. Despite various attempts to mitigate this issue through compression techniques, prior works have not explicitly formalized the problem of KV-cache compression in this context. In this work, we take the first step in formally defining the KV-cache compression problem for Visual Autoregressive transformers. We then establish a fundamental negative result, proving that any mechanism for sequential visual token generation under attention-based architectures must use at least $\Omega(n^2 d)$ memory, when $d = \Omega(\log n)$, where $n$ is the number of tokens generated and $d$ is the embedding dimensionality. This result demonstrates that achieving truly sub-quadratic memory usage is impossible without additional structural constraints. Our proof is constructed via a reduction from a computational lower bound problem, leveraging randomized embedding techniques inspired by dimensionality reduction principles. Finally, we discuss how sparsity priors on visual representations can influence memory efficiency, presenting both impossibility results and potential directions for mitigating memory overhead. 

**Abstract (ZH)**: 视觉自回归模型中的一个基本挑战是在推理过程中存储之前生成的表示所需的大量内存开销。尽管通过压缩技术已尝试减轻这一问题，但先前的工作尚未明确形式化这种上下文中的KV缓存压缩问题。在本文中，我们首次正式定义了视觉自回归变压器的KV缓存压缩问题。然后，我们建立了基本的消极结果，证明在注意力机制架构下，任何顺序生成视觉标记的机制必须至少使用$\Omega(n^2 d)$内存，其中当$d=\Omega(\log n)$时，$n$是生成的标记数量，$d$是嵌入维度。这一结果表明，在没有额外结构约束的情况下实现真正亚二次内存使用是不可能的。我们的证明是通过从计算下界问题的归约构建的，利用基于降维原理的随机嵌入技术。最后，我们讨论了视觉表示的稀疏先验如何影响内存效率，并提出了不可能结果以及减轻内存开销的潜在方向。 

---
# Efficient Personalization of Quantized Diffusion Model without Backpropagation 

**Title (ZH)**: 无需反向传播的量化扩散模型高效个性化 

**Authors**: Hoigi Seo, Wongi Jeong, Kyungryeol Lee, Se Young Chun  

**Link**: [PDF](https://arxiv.org/pdf/2503.14868)  

**Abstract**: Diffusion models have shown remarkable performance in image synthesis, but they demand extensive computational and memory resources for training, fine-tuning and inference. Although advanced quantization techniques have successfully minimized memory usage for inference, training and fine-tuning these quantized models still require large memory possibly due to dequantization for accurate computation of gradients and/or backpropagation for gradient-based algorithms. However, memory-efficient fine-tuning is particularly desirable for applications such as personalization that often must be run on edge devices like mobile phones with private data. In this work, we address this challenge by quantizing a diffusion model with personalization via Textual Inversion and by leveraging a zeroth-order optimization on personalization tokens without dequantization so that it does not require gradient and activation storage for backpropagation that consumes considerable memory. Since a gradient estimation using zeroth-order optimization is quite noisy for a single or a few images in personalization, we propose to denoise the estimated gradient by projecting it onto a subspace that is constructed with the past history of the tokens, dubbed Subspace Gradient. In addition, we investigated the influence of text embedding in image generation, leading to our proposed time steps sampling, dubbed Partial Uniform Timestep Sampling for sampling with effective diffusion timesteps. Our method achieves comparable performance to prior methods in image and text alignment scores for personalizing Stable Diffusion with only forward passes while reducing training memory demand up to $8.2\times$. 

**Abstract (ZH)**: 通过Textual Inversion量化个性化扩散模型并利用零阶优化进行内存高效微调 

---
# 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities 

**Title (ZH)**: 1000层网络用于自监督RL：扩大深度可以实现新的目标达成能力 

**Authors**: Kevin Wang, Ishaan Javali, Michał Bortkiewicz, Tomasz Trzciński, Benjamin Eysenbach  

**Link**: [PDF](https://arxiv.org/pdf/2503.14858)  

**Abstract**: Scaling up self-supervised learning has driven breakthroughs in language and vision, yet comparable progress has remained elusive in reinforcement learning (RL). In this paper, we study building blocks for self-supervised RL that unlock substantial improvements in scalability, with network depth serving as a critical factor. Whereas most RL papers in recent years have relied on shallow architectures (around 2 - 5 layers), we demonstrate that increasing the depth up to 1024 layers can significantly boost performance. Our experiments are conducted in an unsupervised goal-conditioned setting, where no demonstrations or rewards are provided, so an agent must explore (from scratch) and learn how to maximize the likelihood of reaching commanded goals. Evaluated on simulated locomotion and manipulation tasks, our approach increases performance by $2\times$ - $50\times$. Increasing the model depth not only increases success rates but also qualitatively changes the behaviors learned. 

**Abstract (ZH)**: 自监督强化学习中规模提升的构建块：网络深度的关键作用与显著性能增益 

---
# Project Jenkins: Turning Monkey Neural Data into Robotic Arm Movement, and Back 

**Title (ZH)**: 项目Jenkins: 将猴子神经数据转化为机械臂运动，反之亦然 

**Authors**: Andrii Zahorodnii, Dima Yanovsky  

**Link**: [PDF](https://arxiv.org/pdf/2503.14847)  

**Abstract**: Project Jenkins explores how neural activity in the brain can be decoded into robotic movement and, conversely, how movement patterns can be used to generate synthetic neural data. Using real neural data recorded from motor and premotor cortex areas of a macaque monkey named Jenkins, we develop models for decoding (converting brain signals into robotic arm movements) and encoding (simulating brain activity corresponding to a given movement). For the interface between the brain simulation and the physical world, we utilized Koch v1.1 leader and follower robotic arms. We developed an interactive web console that allows users to generate synthetic brain data from joystick movements in real time. Our results are a step towards brain-controlled robotics, prosthetics, and enhancing normal motor function. By accurately modeling brain activity, we take a step toward flexible brain-computer interfaces that generalize beyond predefined movements. To support the research community, we provide open source tools for both synthetic data generation and neural decoding, fostering reproducibility and accelerating progress. The project is available at this https URL 

**Abstract (ZH)**: Jenkins项目探索了如何将大脑神经活动解码为机器人运动，反之亦然，并利用Koch v1.1领袖和跟随机器人手臂实现了脑模拟与物理世界之间的接口。我们开发了一个交互式的网页控制台，允许用户实时从游戏杆运动生成合成的大脑数据。该项目向前迈进了一步，朝着脑控机器人、假肢以及增强正常运动功能的方向发展。通过准确建模大脑活动，我们朝着能够泛化到预定义动作之外的灵活脑-机接口迈出了一步。为了支持研究社区，我们提供了合成数据生成和神经解码的开源工具，促进可再现性并加速研究进展。该项目可在以下网址获取：this https URL。 

---
# Curiosity-Diffuser: Curiosity Guide Diffusion Models for Reliability 

**Title (ZH)**: 好奇心弥散器：好奇心引导的扩散模型以提升可靠性 

**Authors**: Zihao Liu, Xing Liu, Yizhai Zhang, Zhengxiong Liu, Panfeng Huang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14833)  

**Abstract**: One of the bottlenecks in robotic intelligence is the instability of neural network models, which, unlike control models, lack a well-defined convergence domain and stability. This leads to risks when applying intelligence in the physical world. Specifically, imitation policy based on neural network may generate hallucinations, leading to inaccurate behaviors that impact the safety of real-world applications. To address this issue, this paper proposes the Curiosity-Diffuser, aimed at guiding the conditional diffusion model to generate trajectories with lower curiosity, thereby improving the reliability of policy. The core idea is to use a Random Network Distillation (RND) curiosity module to assess whether the model's behavior aligns with the training data, and then minimize curiosity by classifier guidance diffusion to reduce overgeneralization during inference. Additionally, we propose a computationally efficient metric for evaluating the reliability of the policy, measuring the similarity between the generated behaviors and the training dataset, to facilitate research about reliability learning. Finally, simulation verify the effectiveness and applicability of the proposed method to a variety of scenarios, showing that Curiosity-Diffuser significantly improves task performance and produces behaviors that are more similar to the training data. The code for this work is available at: this http URL 

**Abstract (ZH)**: 一种基于好奇度消解的条件扩散模型以提高政策可靠性的方法 

---
# The CLEF-2025 CheckThat! Lab: Subjectivity, Fact-Checking, Claim Normalization, and Retrieval 

**Title (ZH)**: CLEF-2025 CheckThat! 实验室：主观性、事实核查、论断规范化与检索 

**Authors**: Firoj Alam, Julia Maria Struß, Tanmoy Chakraborty, Stefan Dietze, Salim Hafid, Katerina Korre, Arianna Muti, Preslav Nakov, Federico Ruggeri, Sebastian Schellhammer, Vinay Setty, Megha Sundriyal, Konstantin Todorov, Venktesh V  

**Link**: [PDF](https://arxiv.org/pdf/2503.14828)  

**Abstract**: The CheckThat! lab aims to advance the development of innovative technologies designed to identify and counteract online disinformation and manipulation efforts across various languages and platforms. The first five editions focused on key tasks in the information verification pipeline, including check-worthiness, evidence retrieval and pairing, and verification. Since the 2023 edition, the lab has expanded its scope to address auxiliary tasks that support research and decision-making in verification. In the 2025 edition, the lab revisits core verification tasks while also considering auxiliary challenges. Task 1 focuses on the identification of subjectivity (a follow-up from CheckThat! 2024), Task 2 addresses claim normalization, Task 3 targets fact-checking numerical claims, and Task 4 explores scientific web discourse processing. These tasks present challenging classification and retrieval problems at both the document and span levels, including multilingual settings. 

**Abstract (ZH)**: CheckThat!实验室旨在推进识别和对抗各种语言和平台上的在线虚假信息和操纵努力的创新技术的发展。前五届活动主要关注信息核实管道中的关键任务，包括可核实性、证据检索和配对以及核实。从2023年版开始，实验室扩大了范围，以支持核实研究和决策的辅助任务。在2025年版中，实验室重新审视核心核实任务，同时考虑辅助挑战。任务1关注主观性识别（继承自CheckThat! 2024），任务2处理主张规范化，任务3针对事实核查数值声明，任务4探索科学网络话语处理。这些任务在文档级和短语级上提出了具有挑战性的分类和检索问题，包括多语种设置。 

---
# MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation Models 

**Title (ZH)**: MMDT：解码多模态基础模型的可靠性和安全性 

**Authors**: Chejian Xu, Jiawei Zhang, Zhaorun Chen, Chulin Xie, Mintong Kang, Yujin Potter, Zhun Wang, Zhuowen Yuan, Alexander Xiong, Zidi Xiong, Chenhui Zhang, Lingzhi Yuan, Yi Zeng, Peiyang Xu, Chengquan Guo, Andy Zhou, Jeffrey Ziwei Tan, Xuandong Zhao, Francesco Pinto, Zhen Xiang, Yu Gai, Zinan Lin, Dan Hendrycks, Bo Li, Dawn Song  

**Link**: [PDF](https://arxiv.org/pdf/2503.14827)  

**Abstract**: Multimodal foundation models (MMFMs) play a crucial role in various applications, including autonomous driving, healthcare, and virtual assistants. However, several studies have revealed vulnerabilities in these models, such as generating unsafe content by text-to-image models. Existing benchmarks on multimodal models either predominantly assess the helpfulness of these models, or only focus on limited perspectives such as fairness and privacy. In this paper, we present the first unified platform, MMDT (Multimodal DecodingTrust), designed to provide a comprehensive safety and trustworthiness evaluation for MMFMs. Our platform assesses models from multiple perspectives, including safety, hallucination, fairness/bias, privacy, adversarial robustness, and out-of-distribution (OOD) generalization. We have designed various evaluation scenarios and red teaming algorithms under different tasks for each perspective to generate challenging data, forming a high-quality benchmark. We evaluate a range of multimodal models using MMDT, and our findings reveal a series of vulnerabilities and areas for improvement across these perspectives. This work introduces the first comprehensive and unique safety and trustworthiness evaluation platform for MMFMs, paving the way for developing safer and more reliable MMFMs and systems. Our platform and benchmark are available at this https URL. 

**Abstract (ZH)**: 多模态基础模型（MMFMs）在自动驾驶、 healthcare 和虚拟助理等多个应用中发挥着关键作用。然而，多项研究揭示了这些模型的漏洞，例如文本到图像模型生成不安全的内容。现有的多模态模型基准主要评估这些模型的有用性，或者仅关注公平性、隐私等有限视角。在本文中，我们提出了第一个统一平台 MMDT（多模态解码信任），旨在为 MMFMs 提供全方位的安全性和可信度评估。该平台从多个视角评估模型，包括安全性、幻想、公平性/偏向性、隐私、对抗鲁棒性和离群值外推能力。我们在每个视角下设计了多种评估场景和红队算法，生成具有挑战性的数据，形成高质量的基准。我们使用 MMDT 评估了多种多模态模型，并发现了一系列跨视角的漏洞和改进领域。本研究引入了第一个全面且独特的 MMFMs 安全性和可信度评估平台，为开发更安全和更可靠的 MMFMs 和系统铺平了道路。我们的平台和基准可在以下网址获得：this https URL。 

---
# Learning with Expert Abstractions for Efficient Multi-Task Continuous Control 

**Title (ZH)**: 基于专家抽象的高效多任务连续控制学习 

**Authors**: Jeff Jewett, Sandhya Saisubramanian  

**Link**: [PDF](https://arxiv.org/pdf/2503.14809)  

**Abstract**: Decision-making in complex, continuous multi-task environments is often hindered by the difficulty of obtaining accurate models for planning and the inefficiency of learning purely from trial and error. While precise environment dynamics may be hard to specify, human experts can often provide high-fidelity abstractions that capture the essential high-level structure of a task and user preferences in the target environment. Existing hierarchical approaches often target discrete settings and do not generalize across tasks. We propose a hierarchical reinforcement learning approach that addresses these limitations by dynamically planning over the expert-specified abstraction to generate subgoals to learn a goal-conditioned policy. To overcome the challenges of learning under sparse rewards, we shape the reward based on the optimal state value in the abstract model. This structured decision-making process enhances sample efficiency and facilitates zero-shot generalization. Our empirical evaluation on a suite of procedurally generated continuous control environments demonstrates that our approach outperforms existing hierarchical reinforcement learning methods in terms of sample efficiency, task completion rate, scalability to complex tasks, and generalization to novel scenarios. 

**Abstract (ZH)**: 在复杂连续多任务环境中的决策制定往往受到准确建模规划的难度以及仅通过试错学习的低效性的阻碍。虽然环境动力学可能难以精确描述，但人类专家通常可以提供高保真抽象，捕获任务的基本高层结构和目标环境中的用户偏好。现有层次化方法往往针对离散设置，并且不能在任务之间泛化。我们提出了一种层次化强化学习方法，通过动态规划专家指定的抽象来生成子目标，以学习一个以目标条件化策略。为了克服在稀疏奖励下的学习挑战，我们基于抽象模型中的最优状态值塑造奖励。这种结构化的决策过程提高了样本效率并促进了零样本泛化。我们在一系列程序生成的连续控制环境中的实证评估表明，我们的方法在样本效率、任务完成率、复杂任务的可扩展性以及向新颖场景的泛化方面优于现有的层次化强化学习方法。 

---
# Long Context Modeling with Ranked Memory-Augmented Retrieval 

**Title (ZH)**: 带排名记忆增强检索的长上下文建模 

**Authors**: Ghadir Alselwi, Hao Xue, Shoaib Jameel, Basem Suleiman, Flora D. Salim, Imran Razzak  

**Link**: [PDF](https://arxiv.org/pdf/2503.14800)  

**Abstract**: Effective long-term memory management is crucial for language models handling extended contexts. We introduce a novel framework that dynamically ranks memory entries based on relevance. Unlike previous works, our model introduces a novel relevance scoring and a pointwise re-ranking model for key-value embeddings, inspired by learning-to-rank techniques in information retrieval. Enhanced Ranked Memory Augmented Retrieval ERMAR achieves state-of-the-art results on standard benchmarks. 

**Abstract (ZH)**: 一种基于动态相关性排序的记忆管理框架实现语言模型在处理长上下文时的有效长期记忆管理。ERMAR：增强排序记忆扩展检索取得标准基准上的最佳效果。 

---
# RAT: Boosting Misclassification Detection Ability without Extra Data 

**Title (ZH)**: RAT: 在无需额外数据的情况下提升误分类检测能力 

**Authors**: Ge Yan, Tsui-Wei Weng  

**Link**: [PDF](https://arxiv.org/pdf/2503.14783)  

**Abstract**: As deep neural networks(DNN) become increasingly prevalent, particularly in high-stakes areas such as autonomous driving and healthcare, the ability to detect incorrect predictions of models and intervene accordingly becomes crucial for safety. In this work, we investigate the detection of misclassified inputs for image classification models from the lens of adversarial perturbation: we propose to use robust radius (a.k.a. input-space margin) as a confidence metric and design two efficient estimation algorithms, RR-BS and RR-Fast, for misclassification detection. Furthermore, we design a training method called Radius Aware Training (RAT) to boost models' ability to identify mistakes. Extensive experiments show our method could achieve up to 29.3% reduction on AURC and 21.62% reduction in FPR@95TPR, compared with previous methods. 

**Abstract (ZH)**: 随着深度神经网络(DNN)在自动驾驶和医疗等高风险领域中的广泛应用，检测模型的错误预测并及时干预以确保安全变得至关重要。在本工作中，我们从对手扰动的角度研究了图像分类模型的误分类检测：我们提出使用鲁棒半径（即输入空间间隔）作为置信度度量，并设计了两种高效的误分类检测算法RR-BS和RR-Fast。此外，我们提出了一种名为鲁棒半径感知训练（RAT）的训练方法，以提高模型识别错误的能力。大量实验结果显示，与之前的方法相比，我们的方法在AURC上最多可减少29.3%，在FPR@95TPR上减少21.62%。 

---
# Involution and BSConv Multi-Depth Distillation Network for Lightweight Image Super-Resolution 

**Title (ZH)**: 基于进化的BSConv多深度精炼网络的轻量级图像超分辨率 

**Authors**: Akram Khatami-Rizi, Ahmad Mahmoudi-Aznaveh  

**Link**: [PDF](https://arxiv.org/pdf/2503.14779)  

**Abstract**: Single Image Super-Resolution (SISR) aims to reconstruct high-resolution (HR) images from low-resolution (LR) inputs. Deep learning, especially Convolutional Neural Networks (CNNs), has advanced SISR. However, increasing network depth increases parameters, and memory usage, and slows training, which is problematic for resource-limited devices. To address this, lightweight models are developed to balance accuracy and efficiency. We propose the Involution & BSConv Multi-Depth Distillation Network (IBMDN), combining Involution & BSConv Multi-Depth Distillation Block (IBMDB) and the Contrast and High-Frequency Attention Block (CHFAB). IBMDB integrates Involution and BSConv to balance computational efficiency and feature extraction. CHFAB enhances high-frequency details for better visual quality. IBMDB is compatible with other SISR architectures and reduces complexity, improving evaluation metrics like PSNR and SSIM. In transformer-based models, IBMDB reduces memory usage while improving feature extraction. In GANs, it enhances perceptual quality, balancing pixel-level accuracy with perceptual details. Our experiments show that the method achieves high accuracy with minimal computational cost. The code is available at GitHub. 

**Abstract (ZH)**: 单张图像超分辨率（SISR）旨在从低分辨率（LR）输入重建高分辨率（HR）图像。深度学习，尤其是卷积神经网络（CNNs），推动了SISR的发展。然而，网络深度的增加会导致参数和内存使用量增加，并减慢训练速度，这在资源受限的设备上是一个问题。为解决这个问题，开发了轻量化模型以平衡准确性和效率。我们提出了结合Involution & BSConv多层蒸馏块（IBMDB）和对比与高频注意力块（CHFAB）的Involution & BSConv多层蒸馏网络（IBMDN）。IBMDB将Involution和BSConv结合以平衡计算效率和特征提取。CHFAB增强高频细节以获得更好的视觉质量。IBMDB与其他SISR架构兼容，降低复杂性，改善像PSNR和SSIM这样的评估指标。在基于变压器的模型中，IBMDB在提高特征提取的同时减少内存使用。在生成对抗网络（GANs）中，它增强感知质量，平衡像素级准确性和感知细节。我们的实验表明，该方法以最小的计算成本实现了高精度。代码可在GitHub获得。 

---
# Language Independent Named Entity Recognition via Orthogonal Transformation of Word Vectors 

**Title (ZH)**: 基于词向量正交变换的无语言依赖命名实体识别 

**Authors**: Omar E. Rakha, Hazem M. Abbas  

**Link**: [PDF](https://arxiv.org/pdf/2503.14755)  

**Abstract**: Word embeddings have been a key building block for NLP in which models relied heavily on word embeddings in many different tasks. In this paper, a model is proposed based on using Bidirectional LSTM/CRF with word embeddings to perform named entity recognition for any language. This is done by training a model on a source language (English) and transforming word embeddings from the target language into word embeddings of the source language by using an orthogonal linear transformation matrix. Evaluation of the model shows that by training a model on an English dataset the model was capable of detecting named entities in an Arabic dataset without neither training or fine tuning the model on an Arabic language dataset. 

**Abstract (ZH)**: 基于双向LSTM/CRF和词嵌入的语言无关命名实体识别模型 

---
# Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection 

**Title (ZH)**: 零 shot 分类的贝叶斯建模在城市洪涝检测中的应用 

**Authors**: Matt Franchi, Nikhil Garg, Wendy Ju, Emma Pierson  

**Link**: [PDF](https://arxiv.org/pdf/2503.14754)  

**Abstract**: Street scene datasets, collected from Street View or dashboard cameras, offer a promising means of detecting urban objects and incidents like street flooding. However, a major challenge in using these datasets is their lack of reliable labels: there are myriad types of incidents, many types occur rarely, and ground-truth measures of where incidents occur are lacking. Here, we propose BayFlood, a two-stage approach which circumvents this difficulty. First, we perform zero-shot classification of where incidents occur using a pretrained vision-language model (VLM). Second, we fit a spatial Bayesian model on the VLM classifications. The zero-shot approach avoids the need to annotate large training sets, and the Bayesian model provides frequent desiderata in urban settings - principled measures of uncertainty, smoothing across locations, and incorporation of external data like stormwater accumulation zones. We comprehensively validate this two-stage approach, showing that VLMs provide strong zero-shot signal for floods across multiple cities and time periods, the Bayesian model improves out-of-sample prediction relative to baseline methods, and our inferred flood risk correlates with known external predictors of risk. Having validated our approach, we show it can be used to improve urban flood detection: our analysis reveals 113,738 people who are at high risk of flooding overlooked by current methods, identifies demographic biases in existing methods, and suggests locations for new flood sensors. More broadly, our results showcase how Bayesian modeling of zero-shot LM annotations represents a promising paradigm because it avoids the need to collect large labeled datasets and leverages the power of foundation models while providing the expressiveness and uncertainty quantification of Bayesian models. 

**Abstract (ZH)**: 基于街景数据的BayFlood双阶段方法：规避标签难题，提高城市洪水检测能力 

---
# LipShiFT: A Certifiably Robust Shift-based Vision Transformer 

**Title (ZH)**: LipShiFT: 一种可认证稳健的基于移位的视觉变换器 

**Authors**: Rohan Menon, Nicola Franco, Stephan Günnemann  

**Link**: [PDF](https://arxiv.org/pdf/2503.14751)  

**Abstract**: Deriving tight Lipschitz bounds for transformer-based architectures presents a significant challenge. The large input sizes and high-dimensional attention modules typically prove to be crucial bottlenecks during the training process and leads to sub-optimal results. Our research highlights practical constraints of these methods in vision tasks. We find that Lipschitz-based margin training acts as a strong regularizer while restricting weights in successive layers of the model. Focusing on a Lipschitz continuous variant of the ShiftViT model, we address significant training challenges for transformer-based architectures under norm-constrained input setting. We provide an upper bound estimate for the Lipschitz constants of this model using the $l_2$ norm on common image classification datasets. Ultimately, we demonstrate that our method scales to larger models and advances the state-of-the-art in certified robustness for transformer-based architectures. 

**Abstract (ZH)**: 基于变压器的架构获取紧的利普希茨界是一个重大挑战。大输入尺寸和高维注意力模块通常在训练过程中成为关键瓶颈，导致次优结果。我们的研究强调了这些方法在视觉任务中的实际限制。我们发现基于利普希茨的边际训练作为一种强正则化手段，能够限制模型后续层中的权重。我们专注于ShiftViT模型的连续变体，在范数约束输入设置下，解决了变压器架构的重要训练挑战。我们使用常见的图像分类数据集上的$l_2$范数，提供了该模型的利普希茨常数的上界估计。最终，我们证明了该方法可扩展到更大的模型，并在变压器架构的验证鲁棒性方面取得了最先进的成果。 

---
# GR00T N1: An Open Foundation Model for Generalist Humanoid Robots 

**Title (ZH)**: GR00T N1: 通用基础模型为人形机器人 

**Authors**: NVIDIA, Johan Bjorck, Fernando Castañeda, Nikita Cherniadev, Xingye Da, Runyu Ding, Linxi "Jim" Fan, Yu Fang, Dieter Fox, Fengyuan Hu, Spencer Huang, Joel Jang, Zhenyu Jiang, Jan Kautz, Kaushil Kundalia, Lawrence Lao, Zhiqi Li, Zongyu Lin, Kevin Lin, Guilin Liu, Edith Llontop, Loic Magne, Ajay Mandlekar, Avnish Narayan, Soroush Nasiriany, Scott Reed, You Liang Tan, Guanzhi Wang, Zu Wang, Jing Wang, Qi Wang, Jiannan Xiang, Yuqi Xie, Yinzhen Xu, Zhenjia Xu, Seonghyeon Ye, Zhiding Yu, Ao Zhang, Hao Zhang, Yizhou Zhao, Ruijie Zheng, Yuke Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14734)  

**Abstract**: General-purpose robots need a versatile body and an intelligent mind. Recent advancements in humanoid robots have shown great promise as a hardware platform for building generalist autonomy in the human world. A robot foundation model, trained on massive and diverse data sources, is essential for enabling the robots to reason about novel situations, robustly handle real-world variability, and rapidly learn new tasks. To this end, we introduce GR00T N1, an open foundation model for humanoid robots. GR00T N1 is a Vision-Language-Action (VLA) model with a dual-system architecture. The vision-language module (System 2) interprets the environment through vision and language instructions. The subsequent diffusion transformer module (System 1) generates fluid motor actions in real time. Both modules are tightly coupled and jointly trained end-to-end. We train GR00T N1 with a heterogeneous mixture of real-robot trajectories, human videos, and synthetically generated datasets. We show that our generalist robot model GR00T N1 outperforms the state-of-the-art imitation learning baselines on standard simulation benchmarks across multiple robot embodiments. Furthermore, we deploy our model on the Fourier GR-1 humanoid robot for language-conditioned bimanual manipulation tasks, achieving strong performance with high data efficiency. 

**Abstract (ZH)**: 通用机器人需要多功能的身体和智能的大脑。 humanoid机器人Recent advancements在人体世界的通用自主性方面展现出了巨大的硬件平台潜力。一种基于庞大且多样数据源训练的机器人基础模型对于使机器人能够推理新情况、稳健应对现实世界的变异性以及迅速学习新任务是必不可少的。为此，我们引入了GR00T N1，一种面向humanoid机器人的开放基础模型。GR00T N1是一种具有双系统架构的 Vision-Language-Action (VLA) 模型。视觉语言模块（System 2）通过视觉和语言指令解释环境。后续的扩散变换器模块（System 1）实时生成流畅的运动动作。两个模块紧密结合，并联合进行端到端训练。我们使用来自实际机器人轨迹、人类视频和合成生成数据集的异构混合数据训练GR00T N1。我们展示了我们的通用机器人模型GR00T N1在多个机器人身体上的标准化模拟基准测试中，性能优于最新的模仿学习基线。此外，我们将在Fourier GR-1 humanoid机器人中部署该模型，用于条件语言指导下的双臂操作任务，并实现了高效的数据使用和出色的表现。 

---
# Construction Site Scaffolding Completeness Detection Based on Mask R-CNN and Hough Transform 

**Title (ZH)**: 基于Mask R-CNN和霍夫变换的建筑工地脚手架完整性检测 

**Authors**: Pei-Hsin Lin, Jacob J. Lin, Shang-Hsien Hsieh  

**Link**: [PDF](https://arxiv.org/pdf/2503.14716)  

**Abstract**: Construction site scaffolding is essential for many building projects, and ensuring its safety is crucial to prevent accidents. The safety inspector must check the scaffolding's completeness and integrity, where most violations occur. The inspection process includes ensuring all the components are in the right place since workers often compromise safety for convenience and disassemble parts such as cross braces. This paper proposes a deep learning-based approach to detect the scaffolding and its cross braces using computer vision. A scaffold image dataset with annotated labels is used to train a convolutional neural network (CNN) model. With the proposed approach, we can automatically detect the completeness of cross braces from images taken at construction sites, without the need for manual inspection, saving a significant amount of time and labor costs. This non-invasive and efficient solution for detecting scaffolding completeness can help improve safety in construction sites. 

**Abstract (ZH)**: 基于深度学习的计算机视觉方法在施工现场检测脚手架及其剪刀撑的研究 

---
# DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis 

**Title (ZH)**: DPImageBench: 一体化差分隐私图像合成基准 

**Authors**: Chen Gong, Kecen Li, Zinan Lin, Tianhao Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14681)  

**Abstract**: Differentially private (DP) image synthesis aims to generate artificial images that retain the properties of sensitive images while protecting the privacy of individual images within the dataset. Despite recent advancements, we find that inconsistent--and sometimes flawed--evaluation protocols have been applied across studies. This not only impedes the understanding of current methods but also hinders future advancements.
To address the issue, this paper introduces DPImageBench for DP image synthesis, with thoughtful design across several dimensions: (1) Methods. We study eleven prominent methods and systematically characterize each based on model architecture, pretraining strategy, and privacy mechanism. (2) Evaluation. We include nine datasets and seven fidelity and utility metrics to thoroughly assess them. Notably, we find that a common practice of selecting downstream classifiers based on the highest accuracy on the sensitive test set not only violates DP but also overestimates the utility scores. DPImageBench corrects for these mistakes. (3) Platform. Despite the methods and evaluation protocols, DPImageBench provides a standardized interface that accommodates current and future implementations within a unified framework. With DPImageBench, we have several noteworthy findings. For example, contrary to the common wisdom that pretraining on public image datasets is usually beneficial, we find that the distributional similarity between pretraining and sensitive images significantly impacts the performance of the synthetic images and does not always yield improvements. In addition, adding noise to low-dimensional features, such as the high-level characteristics of sensitive images, is less affected by the privacy budget compared to adding noise to high-dimensional features, like weight gradients. The former methods perform better than the latter under a low privacy budget. 

**Abstract (ZH)**: 不同隐私保护（DP）图像合成的研究评估标准不一，且有时存在缺陷，这不仅阻碍了当前方法的理解，也妨碍了未来的发展。为了解决这一问题，本文提出了DPImageBench，从多个维度进行了精心设计：方法方面，我们研究了十一种主流方法，并基于模型架构、预训练策略和隐私机制对每种方法进行了系统化描述；评估方面，我们包含了九个数据集和七项保真度与实用性指标，以全面评估这些方法。值得注意的是，我们发现根据敏感测试集上的最高准确性选择下游分类器不仅违反了DP，还高估了实用性得分，DPImageBench纠正了这些错误；平台方面，尽管有方法和评估标准的不同，DPImageBench仍提供了一套标准化接口，适用于当前和未来的统一框架实现。通过使用DPImageBench，我们获得了几个重要发现。例如，与普遍观点相反，我们发现，预训练在公共图像数据集上的效果并不总是最优，预训练和敏感图像之间的分布相似性显著影响合成图像的表现，并不总是带来改进。此外，在低维度特征（如敏感图像的高层次特性）上添加噪声比在高维度特征（如权重梯度）上添加噪声受隐私预算的影响更小，在低隐私预算下前者方法的表现优于后者。 

---
# ConQuer: A Framework for Concept-Based Quiz Generation 

**Title (ZH)**: ConQuer：基于概念的quiz生成框架 

**Authors**: Yicheng Fu, Zikui Wang, Liuxin Yang, Meiqing Huo, Zhongdongming Dai  

**Link**: [PDF](https://arxiv.org/pdf/2503.14662)  

**Abstract**: Quizzes play a crucial role in education by reinforcing students' understanding of key concepts and encouraging self-directed exploration. However, compiling high-quality quizzes can be challenging and require deep expertise and insight into specific subject matter. Although LLMs have greatly enhanced the efficiency of quiz generation, concerns remain regarding the quality of these AI-generated quizzes and their educational impact on students. To address these issues, we introduce ConQuer, a concept-based quiz generation framework that leverages external knowledge sources. We employ comprehensive evaluation dimensions to assess the quality of the generated quizzes, using LLMs as judges. Our experiment results demonstrate a 4.8% improvement in evaluation scores and a 77.52% win rate in pairwise comparisons against baseline quiz sets. Ablation studies further underscore the effectiveness of each component in our framework. Code available at this https URL. 

**Abstract (ZH)**: 概念导向的 quiz 生成框架 ConQuer 在利用外部知识源的基础上提升 quiz 质量及教育影响 

---
# Core-Periphery Principle Guided State Space Model for Functional Connectome Classification 

**Title (ZH)**: 由核心-边缘原则引导的空间模型在功能联接组分类中的应用 

**Authors**: Minheng Chen, Xiaowei Yu, Jing Zhang, Tong Chen, Chao Cao, Yan Zhuang, Yanjun Lyu, Lu Zhang, Tianming Liu, Dajiang Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14655)  

**Abstract**: Understanding the organization of human brain networks has become a central focus in neuroscience, particularly in the study of functional connectivity, which plays a crucial role in diagnosing neurological disorders. Advances in functional magnetic resonance imaging and machine learning techniques have significantly improved brain network analysis. However, traditional machine learning approaches struggle to capture the complex relationships between brain regions, while deep learning methods, particularly Transformer-based models, face computational challenges due to their quadratic complexity in long-sequence modeling. To address these limitations, we propose a Core-Periphery State-Space Model (CP-SSM), an innovative framework for functional connectome classification. Specifically, we introduce Mamba, a selective state-space model with linear complexity, to effectively capture long-range dependencies in functional brain networks. Furthermore, inspired by the core-periphery (CP) organization, a fundamental characteristic of brain networks that enhances efficient information transmission, we design CP-MoE, a CP-guided Mixture-of-Experts that improves the representation learning of brain connectivity patterns. We evaluate CP-SSM on two benchmark fMRI datasets: ABIDE and ADNI. Experimental results demonstrate that CP-SSM surpasses Transformer-based models in classification performance while significantly reducing computational complexity. These findings highlight the effectiveness and efficiency of CP-SSM in modeling brain functional connectivity, offering a promising direction for neuroimaging-based neurological disease diagnosis. 

**Abstract (ZH)**: 理解人类大脑网络的组织已经成为神经科学中的一个核心焦点，特别是在功能性连接的研究中，后者在神经障碍诊断中扮演着至关重要的角色。功能性磁共振成像技术和机器学习方法的进步显著改善了大脑网络分析。然而，传统的机器学习方法难以捕捉大脑区域之间的复杂关系，而基于Transformer的深度学习方法在长时间序列建模中面临着计算上的挑战。为了解决这些局限性，我们提出了一种核心-外围状态空间模型（CP-SSM），这是一种用于功能性连接体分类的创新框架。具体来说，我们引入了一种选择性状态空间模型Mamba，该模型具有线性复杂度，能够有效地捕捉功能性脑网络中的长程依赖关系。此外，受到脑网络中核心-外围（CP）组织这一基本原则的启发，这种组织形式提升了信息传输效率，我们设计了一种CP引导的专家混合模型CP-MoE，以改善脑连接模式的表示学习。我们在两个基准fMRI数据集ABIDE和ADNI上评估了CP-SSM。实验结果表明，CP-SSM在分类性能上超过了基于Transformer的模型，同时显著降低了计算复杂度。这些发现突显了CP-SSM在建模脑功能连接方面的有效性和效率，为神经影像学基础上的神经疾病诊断提供了有前景的方向。 

---
# RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving 

**Title (ZH)**: RAGO：检索增强生成服务的系统性能优化 

**Authors**: Wenqi Jiang, Suvinay Subramanian, Cat Graves, Gustavo Alonso, Amir Yazdanbakhsh, Vidushi Dadu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14649)  

**Abstract**: Retrieval-augmented generation (RAG), which combines large language models (LLMs) with retrievals from external knowledge databases, is emerging as a popular approach for reliable LLM serving. However, efficient RAG serving remains an open challenge due to the rapid emergence of many RAG variants and the substantial differences in workload characteristics across them. In this paper, we make three fundamental contributions to advancing RAG serving. First, we introduce RAGSchema, a structured abstraction that captures the wide range of RAG algorithms, serving as a foundation for performance optimization. Second, we analyze several representative RAG workloads with distinct RAGSchema, revealing significant performance variability across these workloads. Third, to address this variability and meet diverse performance requirements, we propose RAGO (Retrieval-Augmented Generation Optimizer), a system optimization framework for efficient RAG serving. Our evaluation shows that RAGO achieves up to a 2x increase in QPS per chip and a 55% reduction in time-to-first-token latency compared to RAG systems built on LLM-system extensions. 

**Abstract (ZH)**: 基于检索增强生成（RAG）的检索辅助生成（RAGSchema）抽象及其性能优化框架（RAGO） 

---
# Dynamic Accumulated Attention Map for Interpreting Evolution of Decision-Making in Vision Transformer 

**Title (ZH)**: 视觉变换器中决策演化解释的动态累积注意力图 

**Authors**: Yi Liao, Yongsheng Gao, Weichuan Zhang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14640)  

**Abstract**: Various Vision Transformer (ViT) models have been widely used for image recognition tasks. However, existing visual explanation methods can not display the attention flow hidden inside the inner structure of ViT models, which explains how the final attention regions are formed inside a ViT for its decision-making. In this paper, a novel visual explanation approach, Dynamic Accumulated Attention Map (DAAM), is proposed to provide a tool that can visualize, for the first time, the attention flow from the top to the bottom through ViT networks. To this end, a novel decomposition module is proposed to construct and store the spatial feature information by unlocking the [class] token generated by the self-attention module of each ViT block. The module can also obtain the channel importance coefficients by decomposing the classification score for supervised ViT models. Because of the lack of classification score in self-supervised ViT models, we propose dimension-wise importance weights to compute the channel importance coefficients. Such spatial features are linearly combined with the corresponding channel importance coefficients, forming the attention map for each block. The dynamic attention flow is revealed by block-wisely accumulating each attention map. The contribution of this work focuses on visualizing the evolution dynamic of the decision-making attention for any intermediate block inside a ViT model by proposing a novel decomposition module and dimension-wise importance weights. The quantitative and qualitative analysis consistently validate the effectiveness and superior capacity of the proposed DAAM for not only interpreting ViT models with the fully-connected layers as the classifier but also self-supervised ViT models. The code is available at this https URL. 

**Abstract (ZH)**: 动态积累注意力图：一种可视化ViT模型决策注意力流的新方法 

---
# Reinforcement learning-based motion imitation for physiologically plausible musculoskeletal motor control 

**Title (ZH)**: 基于强化学习的动力学模仿生理学合理肌肉骨骼运动控制 

**Authors**: Merkourios Simos, Alberto Silvio Chiappa, Alexander Mathis  

**Link**: [PDF](https://arxiv.org/pdf/2503.14637)  

**Abstract**: How do humans move? The quest to understand human motion has broad applications in numerous fields, ranging from computer animation and motion synthesis to neuroscience, human prosthetics and rehabilitation. Although advances in reinforcement learning (RL) have produced impressive results in capturing human motion using simplified humanoids, controlling physiologically accurate models of the body remains an open challenge. In this work, we present a model-free motion imitation framework (KINESIS) to advance the understanding of muscle-based motor control. Using a musculoskeletal model of the lower body with 80 muscle actuators and 20 DoF, we demonstrate that KINESIS achieves strong imitation performance on 1.9 hours of motion capture data, is controllable by natural language through pre-trained text-to-motion generative models, and can be fine-tuned to carry out high-level tasks such as target goal reaching. Importantly, KINESIS generates muscle activity patterns that correlate well with human EMG activity. The physiological plausibility makes KINESIS a promising model for tackling challenging problems in human motor control theory, which we highlight by investigating Bernstein's redundancy problem in the context of locomotion. Code, videos and benchmarks will be available at this https URL. 

**Abstract (ZH)**: 人类如何移动？对人体运动的理解在计算机动画、运动合成、神经科学、人体假肢和康复等多个领域有着广泛的应用。尽管增强学习的进展在使用简化的人形模型捕捉人体运动方面取得了显著成果，但控制生理上准确的身体模型仍然是一个开放的挑战。在本工作中，我们提出了一种基于运动模仿的无模型框架（KINESIS），以促进基于肌肉的运动控制理解。使用一个包含80个肌肉驱动器和20个自由度的下体 musculoskeletal 模型，我们展示了KINESIS在1.9小时的运动捕捉数据上实现了强大的模仿性能，可以通过预训练的文本到运动生成模型自然语言控制，并且可以微调以执行如目标到达这样的高级任务。重要的是，KINESIS生成的肌肉活动模式与人类EMG活动相关性良好。生理学上的可行性使KINESIS成为解决人体运动控制理论中具有挑战性问题的有前景的模型，我们通过在行进中的伯恩斯坦冗余性问题的背景下对此进行探讨。代码、视频和基准将在此链接中提供。 

---
# Assessing Large Language Models for Automated Feedback Generation in Learning Programming Problem Solving 

**Title (ZH)**: 评估大规模语言模型在编程问题求解自动化反馈生成中的应用 

**Authors**: Priscylla Silva, Evandro Costa  

**Link**: [PDF](https://arxiv.org/pdf/2503.14630)  

**Abstract**: Providing effective feedback is important for student learning in programming problem-solving. In this sense, Large Language Models (LLMs) have emerged as potential tools to automate feedback generation. However, their reliability and ability to identify reasoning errors in student code remain not well understood. This study evaluates the performance of four LLMs (GPT-4o, GPT-4o mini, GPT-4-Turbo, and Gemini-1.5-pro) on a benchmark dataset of 45 student solutions. We assessed the models' capacity to provide accurate and insightful feedback, particularly in identifying reasoning mistakes. Our analysis reveals that 63\% of feedback hints were accurate and complete, while 37\% contained mistakes, including incorrect line identification, flawed explanations, or hallucinated issues. These findings highlight the potential and limitations of LLMs in programming education and underscore the need for improvements to enhance reliability and minimize risks in educational applications. 

**Abstract (ZH)**: 提供有效的反馈对于编程问题解决中的学生学习至关重要。在这种背景下，大型语言模型（LLMs）被视作自动反馈生成的潜在工具。然而，它们的可靠性和识别学生代码中的推理错误能力尚不明确。本研究评估了四种LLMs（GPT-4o、GPT-4o mini、GPT-4-Turbo和Gemini-1.5-pro）在包含45个学生解决方案的基准数据集上的性能。我们评估了模型提供准确且有洞察力的反馈的能力，特别是在识别推理错误方面的能力。我们的分析显示，63%的反馈提示是准确且完整的，而37%则包含错误，包括错误的行标识、不合理的解释或虚假的问题。这些发现凸显了LLMs在编程教育中的潜力和局限性，并强调了提高可靠性和减少教育应用中风险的必要性。 

---
# Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine Learning Approach 

**Title (ZH)**: 在ICU环境中减少假性室性心动过速警报：一种机器学习方法 

**Authors**: Grace Funmilayo Farayola, Akinyemi Sadeeq Akintola, Oluwole Fagbohun, Chukwuka Michael Oforgu, Bisola Faith Kayode, Christian Chimezie, Temitope Kadri, Abiola Oludotun, Nelson Ogbeide, Mgbame Michael, Adeseye Ifaturoti, Toyese Oloyede  

**Link**: [PDF](https://arxiv.org/pdf/2503.14621)  

**Abstract**: False arrhythmia alarms in intensive care units (ICUs) are a significant challenge, contributing to alarm fatigue and potentially compromising patient safety. Ventricular tachycardia (VT) alarms are particularly difficult to detect accurately due to their complex nature. This paper presents a machine learning approach to reduce false VT alarms using the VTaC dataset, a benchmark dataset of annotated VT alarms from ICU monitors. We extract time-domain and frequency-domain features from waveform data, preprocess the data, and train deep learning models to classify true and false VT alarms. Our results demonstrate high performance, with ROC-AUC scores exceeding 0.96 across various training configurations. This work highlights the potential of machine learning to improve the accuracy of VT alarm detection in clinical settings. 

**Abstract (ZH)**: ICUs中室性心动过速假警报的机器学习减缓方法：基于VTaC数据集的研究 

---
# Image Captioning Evaluation in the Age of Multimodal LLMs: Challenges and Future Perspectives 

**Title (ZH)**: 多模态大语言模型时代的产品描述评价：挑战与未来展望 

**Authors**: Sara Sarto, Marcella Cornia, Rita Cucchiara  

**Link**: [PDF](https://arxiv.org/pdf/2503.14604)  

**Abstract**: The evaluation of machine-generated image captions is a complex and evolving challenge. With the advent of Multimodal Large Language Models (MLLMs), image captioning has become a core task, increasing the need for robust and reliable evaluation metrics. This survey provides a comprehensive overview of advancements in image captioning evaluation, analyzing the evolution, strengths, and limitations of existing metrics. We assess these metrics across multiple dimensions, including correlation with human judgment, ranking accuracy, and sensitivity to hallucinations. Additionally, we explore the challenges posed by the longer and more detailed captions generated by MLLMs and examine the adaptability of current metrics to these stylistic variations. Our analysis highlights some limitations of standard evaluation approaches and suggests promising directions for future research in image captioning assessment. 

**Abstract (ZH)**: 机器生成图像描述的评估是一个复杂且不断演化的挑战。随着多模态大型语言模型（MLLMs）的发展，图像描述已成为一个核心任务，增加了对稳健且可靠的评估指标的需求。本文综述了图像描述评估方面的最新进展，分析了现有指标的发展、优势和局限性。我们从多个维度评估这些指标，包括与人类判断的相关性、排名准确性以及对幻觉的敏感性。此外，我们探讨了MLLMs生成的更长、更详细的描述所提出的挑战，并考察了当前指标对这些文体变化的适应性。我们的分析指出了标准评估方法的一些局限性，并提出了图像描述评估未来研究的有希望的方向。 

---
# PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer's Disease 

**Title (ZH)**: PHGNN：一种新型提示超图神经网络用于诊断阿尔茨海默病 

**Authors**: Chenyu Liu, Luca Rossi  

**Link**: [PDF](https://arxiv.org/pdf/2503.14577)  

**Abstract**: The accurate diagnosis of Alzheimer's disease (AD) and prognosis of mild cognitive impairment (MCI) conversion are crucial for early intervention. However, existing multimodal methods face several challenges, from the heterogeneity of input data, to underexplored modality interactions, missing data due to patient dropouts, and limited data caused by the time-consuming and costly data collection process. In this paper, we propose a novel Prompted Hypergraph Neural Network (PHGNN) framework that addresses these limitations by integrating hypergraph based learning with prompt learning. Hypergraphs capture higher-order relationships between different modalities, while our prompt learning approach for hypergraphs, adapted from NLP, enables efficient training with limited data. Our model is validated through extensive experiments on the ADNI dataset, outperforming SOTA methods in both AD diagnosis and the prediction of MCI conversion. 

**Abstract (ZH)**: 阿尔茨海默病（AD）的准确诊断和轻度认知 impairment （MCI）向 AD 转变的预后对于早期干预至关重要。现有多种模态方法面临数据异质性、模态交互未充分探索、患者退出导致的数据缺失以及由于耗时且成本高的数据收集过程而引起的数据有限等问题。本文提出了一种新颖的Prompted Hypergraph Neural Network (PHGNN)框架，通过结合超图学习和提示学习来解决这些问题。我们的模型在ADNI数据集上的广泛实验中表现出色，不仅在AD诊断中优于当前最佳方法，还在MCI转换的预测中也表现出色。 

---
# SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas 

**Title (ZH)**: SocialJax：在序列社会困境中多智能体强化学习的评估套件 

**Authors**: Zihao Guo, Richard Willis, Shuqing Shi, Tristan Tomilin, Joel Z. Leibo, Yali Du  

**Link**: [PDF](https://arxiv.org/pdf/2503.14576)  

**Abstract**: Social dilemmas pose a significant challenge in the field of multi-agent reinforcement learning (MARL). Melting Pot is an extensive framework designed to evaluate social dilemma environments, providing an evaluation protocol that measures generalization to new social partners across various test scenarios. However, running reinforcement learning algorithms in the official Melting Pot environments demands substantial computational resources. In this paper, we introduce SocialJax, a suite of sequential social dilemma environments implemented in JAX. JAX is a high-performance numerical computing library for Python that enables significant improvements in the operational efficiency of SocialJax on GPUs and TPUs. Our experiments demonstrate that the training pipeline of SocialJax achieves a 50\texttimes{} speedup in real-time performance compared to Melting Pot's RLlib baselines. Additionally, we validate the effectiveness of baseline algorithms within the SocialJax environments. Finally, we use Schelling diagrams to verify the social dilemma properties of these environments, ensuring they accurately capture the dynamics of social dilemmas. 

**Abstract (ZH)**: 多智能体 reinforcement 学习领域的社会困境构成重大挑战。Melting Pot 是一个广泛采用的框架，旨在评估社会困境环境，并提供一种评估协议，该协议衡量在各种测试场景中对新社会伙伴的泛化能力。然而，在官方 Melting Pot 环境中运行 reinforcement 学习算法需要大量计算资源。本文介绍了基于 JAX 实现的一系列顺序社会困境环境——SocialJax。JAX 是一个高性能的 Python 数值计算库，使 SocialJax 在 GPU 和 TPU 上的运行效率显著提高。我们的实验表明，SocialJax 的训练管道在实时性能上比 Melting Pot 的 RLlib 基准速度快 50 倍。此外，我们验证了 SocialJax 环境中基础算法的有效性。最后，我们使用 Schelling 图来验证这些环境的社会困境特性，确保它们能够准确捕捉社会困境的动力学。 

---
# Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation 

**Title (ZH)**: 稳健的权重印记：从神经崩溃和代理聚合中获得的见解 

**Authors**: Justus Westerhoff, Golzar Atefi, Mario Koddenbrock, Alexei Figueroa, Alexander Löser, Erik Rodner, Felix A. Gers  

**Link**: [PDF](https://arxiv.org/pdf/2503.14572)  

**Abstract**: The capacity of a foundation model allows for adaptation to new downstream tasks. Weight imprinting is a universal and efficient method to fulfill this purpose. It has been reinvented several times, but it has not been systematically studied. In this paper, we propose a framework for imprinting, identifying three main components: generation, normalization, and aggregation. This allows us to conduct an in-depth analysis of imprinting and a comparison of the existing work. We reveal the benefits of representing novel data with multiple proxies in the generation step and show the importance of proper normalization. We determine those proxies through clustering and propose a novel variant of imprinting that outperforms previous work. We motivate this by the neural collapse phenomenon -- an important connection that we can draw for the first time. Our results show an increase of up to 4% in challenging scenarios with complex data distributions for new classes. 

**Abstract (ZH)**: 基础模型的容量使其能够适应新的下游任务。权重印记是一种通用且高效的实现这一目标的方法。尽管它已被重新发明多次，但尚未进行系统性的研究。本文提出了一种印记框架，识别出生成、规范化和聚合三个主要组成部分，以开展对印记的深度分析和现有工作的比较。我们揭示了在生成步骤中使用多个代理表示新颖数据的好处，并强调了适当规范化的重要性。我们通过聚类确定这些代理，并提出了一种新的印记变体，其性能优于之前的工作。我们通过神经崩溃现象来阐述这一点，这是首次可以建立的重要联系。我们的结果表明，在复杂数据分布的新类场景中，性能最高可提升4%。 

---
# Potential Score Matching: Debiasing Molecular Structure Sampling with Potential Energy Guidance 

**Title (ZH)**: 潜在能评分匹配：以潜在能为导向的分子结构采样去偏差化 

**Authors**: Liya Guo, Zun Wang, Chang Liu, Junzhe Li, Pipi Hu, Yi Zhu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14569)  

**Abstract**: The ensemble average of physical properties of molecules is closely related to the distribution of molecular conformations, and sampling such distributions is a fundamental challenge in physics and chemistry. Traditional methods like molecular dynamics (MD) simulations and Markov chain Monte Carlo (MCMC) sampling are commonly used but can be time-consuming and costly. Recently, diffusion models have emerged as efficient alternatives by learning the distribution of training data. Obtaining an unbiased target distribution is still an expensive task, primarily because it requires satisfying ergodicity. To tackle these challenges, we propose Potential Score Matching (PSM), an approach that utilizes the potential energy gradient to guide generative models. PSM does not require exact energy functions and can debias sample distributions even when trained on limited and biased data. Our method outperforms existing state-of-the-art (SOTA) models on the Lennard-Jones (LJ) potential, a commonly used toy model. Furthermore, we extend the evaluation of PSM to high-dimensional problems using the MD17 and MD22 datasets. The results demonstrate that molecular distributions generated by PSM more closely approximate the Boltzmann distribution compared to traditional diffusion models. 

**Abstract (ZH)**: 分子的ensemble平均物理性质与分子构象分布密切相关，而采样这种分布是物理学和化学中的基本挑战。传统的分子动力学（MD）模拟和马尔可夫链蒙特卡洛（MCMC）采样方法常用但耗时且成本高。近年来，通过学习训练数据分布的扩散模型已 emerge 为有效的替代方法。获得无偏目标分布仍然是一个昂贵的任务，主要是因为它要求满足遍历性。为应对这些挑战，我们提出了势能评分匹配（PSM）方法，该方法利用势能梯度引导生成模型。PSM 不需要精确的能量函数，即使在训练数据有限且有偏的情况下也能消除样本分布的偏差。我们的方法在Lennard-Jones（LJ）势能下优于现有最先进的（SOTA）模型，该势能常被用作玩具模型。此外，我们通过MD17和MD22数据集评估了PSM在高维问题上的表现。结果表明，PSM生成的分子分布更接近玻耳兹曼分布，相比传统扩散模型表现出更佳的结果。 

---
# Teaching Artificial Intelligence to Perform Rapid, Resolution-Invariant Grain Growth Modeling via Fourier Neural Operator 

**Title (ZH)**: 通过傅里叶神经算子教学人工 Intelligence 进行快速、分辨率无关的晶粒生长建模 

**Authors**: Iman Peivaste, Ahmed Makradi, Salim Belouettar  

**Link**: [PDF](https://arxiv.org/pdf/2503.14568)  

**Abstract**: Microstructural evolution, particularly grain growth, plays a critical role in shaping the physical, optical, and electronic properties of materials. Traditional phase-field modeling accurately simulates these phenomena but is computationally intensive, especially for large systems and fine spatial resolutions. While machine learning approaches have been employed to accelerate simulations, they often struggle with resolution dependence and generalization across different grain scales. This study introduces a novel approach utilizing Fourier Neural Operator (FNO) to achieve resolution-invariant modeling of microstructure evolution in multi-grain systems. FNO operates in the Fourier space and can inherently handle varying resolutions by learning mappings between function spaces. By integrating FNO with the phase field method, we developed a surrogate model that significantly reduces computational costs while maintaining high accuracy across different spatial scales. We generated a comprehensive dataset from phase-field simulations using the Fan Chen model, capturing grain evolution over time. Data preparation involved creating input-output pairs with a time shift, allowing the model to predict future microstructures based on current and past states. The FNO-based neural network was trained using sequences of microstructures and demonstrated remarkable accuracy in predicting long-term evolution, even for unseen configurations and higher-resolution grids not encountered during training. 

**Abstract (ZH)**: 利用傅里叶神经运算子实现多晶体系微观结构演化的一致分辨率建模 

---
# SpecReX: Explainable AI for Raman Spectroscopy 

**Title (ZH)**: SpecReX: 可解释的人工智能在拉曼光谱中的应用 

**Authors**: Nathan Blake, David A. Kelly, Akchunya Chanchal, Sarah Kapllani-Mucaj, Geraint Thomas, Hana Chockler  

**Link**: [PDF](https://arxiv.org/pdf/2503.14567)  

**Abstract**: Raman spectroscopy is becoming more common for medical diagnostics with deep learning models being increasingly used to leverage its full potential. However, the opaque nature of such models and the sensitivity of medical diagnosis together with regulatory requirements necessitate the need for explainable AI tools. We introduce SpecReX, specifically adapted to explaining Raman spectra. SpecReX uses the theory of actual causality to rank causal responsibility in a spectrum, quantified by iteratively refining mutated versions of the spectrum and testing if it retains the original classification. The explanations provided by SpecReX take the form of a responsibility map, highlighting spectral regions most responsible for the model to make a correct classification. To assess the validity of SpecReX, we create increasingly complex simulated spectra, in which a "ground truth" signal is seeded, to train a classifier. We then obtain SpecReX explanations and compare the results with another explainability tool. By using simulated spectra we establish that SpecReX localizes to the known differences between classes, under a number of conditions. This provides a foundation on which we can find the spectral features which differentiate disease classes. This is an important first step in proving the validity of SpecReX. 

**Abstract (ZH)**: 拉曼光谱学在医学诊断中的应用日益增多，深度学习模型的使用使其潜力得到更大发挥。然而，这类模型的黑盒性质、医学诊断的敏感性以及监管要求促使需要可解释的人工智能工具。我们介绍了一种专门用于解释拉曼光谱的SpecReX工具。SpecReX利用实际因果理论对光谱中的因果责任进行排名，通过迭代优化光谱的变异版本并测试其是否保留原始分类来实现。SpecReX提供的解释采取责任图的形式，突出显示对模型正确分类影响最大的光谱区域。为验证SpecReX的有效性，我们创建了越来越复杂的模拟光谱，在其中植入“真实信号”以训练分类器。然后我们使用SpecReX获得解释，并将其结果与另一种可解释性工具进行比较。通过使用模拟光谱，我们发现在多种条件下，SpecReX能够定位到不同类别之间的已知差异，为发现区分疾病类别的光谱特征奠定了基础。这是证明SpecReX有效性的关键一步。 

---
# Effortless Active Labeling for Long-Term Test-Time Adaptation 

**Title (ZH)**: 无努力的主动标注以实现长期测试时自适应 

**Authors**: Guowei Wang, Changxing Ding  

**Link**: [PDF](https://arxiv.org/pdf/2503.14564)  

**Abstract**: Long-term test-time adaptation (TTA) is a challenging task due to error accumulation. Recent approaches tackle this issue by actively labeling a small proportion of samples in each batch, yet the annotation burden quickly grows as the batch number increases. In this paper, we investigate how to achieve effortless active labeling so that a maximum of one sample is selected for annotation in each batch. First, we annotate the most valuable sample in each batch based on the single-step optimization perspective in the TTA context. In this scenario, the samples that border between the source- and target-domain data distributions are considered the most feasible for the model to learn in one iteration. Then, we introduce an efficient strategy to identify these samples using feature perturbation. Second, we discover that the gradient magnitudes produced by the annotated and unannotated samples have significant variations. Therefore, we propose balancing their impact on model optimization using two dynamic weights. Extensive experiments on the popular ImageNet-C, -R, -K, -A and PACS databases demonstrate that our approach consistently outperforms state-of-the-art methods with significantly lower annotation costs. 

**Abstract (ZH)**: 长期内存时自适应（TTA）在由于误差累积而成为一个具有挑战性的任务。近期的方法通过在每个批次中积极标注少量样本来解决这一问题，然而随着批次数量的增加，标注负担迅速增长。在本文中，我们探讨了如何实现轻松的主动标注，以便在每个批次中最多只选择一个样本进行标注。首先，我们基于TTA上下文的一步优化视角，标注每个批次中最有价值的样本。在这种情况下，位于源领域和目标领域数据分布之间的样本被认为是模型在一个迭代中学习的最佳选择。然后，我们引入了一种高效的方法来使用特征扰动识别这些样本。其次，我们发现标注样本和未标注样本产生的梯度幅度存在显著差异。因此，我们提出使用两个动态权重来平衡它们对模型优化的影响。在流行的ImageNet-C、-R、-K、-A和PACS数据库上的广泛实验表明，我们的方法在显著降低标注成本的同时，能够持续优于现有最佳方法。 

---
# Workflow for Safe-AI 

**Title (ZH)**: Safe-AI工作流 

**Authors**: Suzana Veljanovska, Hans Dermot Doran  

**Link**: [PDF](https://arxiv.org/pdf/2503.14563)  

**Abstract**: The development and deployment of safe and dependable AI models is crucial in applications where functional safety is a key concern. Given the rapid advancement in AI research and the relative novelty of the safe-AI domain, there is an increasing need for a workflow that balances stability with adaptability. This work proposes a transparent, complete, yet flexible and lightweight workflow that highlights both reliability and qualifiability. The core idea is that the workflow must be qualifiable, which demands the use of qualified tools. Tool qualification is a resource-intensive process, both in terms of time and cost. We therefore place value on a lightweight workflow featuring a minimal number of tools with limited features. The workflow is built upon an extended ONNX model description allowing for validation of AI algorithms from their generation to runtime deployment. This validation is essential to ensure that models are validated before being reliably deployed across different runtimes, particularly in mixed-criticality systems. Keywords-AI workflows, safe-AI, dependable-AI, functional safety, v-model development 

**Abstract (ZH)**: 安全可靠的人工智能模型的发展与部署在功能安全至关重要的应用中至关重要。鉴于人工智能研究的快速进展以及安全人工智能领域的相对新颖性，需要一种平衡稳定性和适应性的工作流。本文提出了一种透明、全面但灵活且轻量级的工作流，强调可靠性和可认证性。核心思想是工作流必须可认证，这要求使用合格的工具。工具认证是一个耗时且耗资的过程。因此，我们重视一种轻量级的工作流，其中包含具有有限功能的最少工具。该工作流建立在扩展的ONNX模型描述之上，允许从生成到运行时部署验证人工智能算法。这种验证对于确保在不同运行时环境中可靠部署模型，特别是在混合关键性系统中，至关重要。关键词-AI工作流，安全人工智能，可靠人工智能，功能安全，V模型开发。 

---
# Analysis of human visual field information using machine learning methods and assessment of their accuracy 

**Title (ZH)**: 使用机器学习方法分析人类视觉场信息及其准确性评估 

**Authors**: A.I. Medvedeva, V.V. Bakutkin  

**Link**: [PDF](https://arxiv.org/pdf/2503.14562)  

**Abstract**: Subject of research: is the study of methods for analyzing perimetric images for the diagnosis and control of glaucoma diseases. Objects of research: is a dataset collected on the ophthalmological perimeter with the results of various patient pathologies, since the ophthalmological community is acutely aware of the issue of disease control and import substitution. [5]. Purpose of research: is to consider various machine learning methods that can classify glaucoma. This is possible thanks to the classifier built after labeling the dataset. It is able to determine from the image whether the visual fields depicted on it are the results of the impact of glaucoma on the eyes or other visual diseases. Earlier in the work [3], a dataset was described that was collected on the Tomey perimeter. The average age of the examined patients ranged from 30 to 85 years. Methods of research: machine learning methods for classifying image results (stochastic gradient descent, logistic regression, random forest, naive Bayes). Main results of research: the result of the study is computer modeling that can determine from the image whether the result is glaucoma or another disease (binary classification). 

**Abstract (ZH)**: 研究主题：基于视网膜周边成像的方法研究，用于青光眼疾病的诊断与控制  
研究对象：来自眼科学 perimeter 的数据集，包含多种患者病理结果，鉴于眼科学界对疾病控制和进口替代的紧迫需求。  
研究目的：考虑可用于分类青光眼的各种机器学习方法。这得益于对数据集进行标注后构建的分类器，能够从图像中判断所显示的视野是否为青光眼的影响结果或其他视觉疾病的结果。此前，在文献[3]中描述了一个在 Tomey perimeter 上收集的数据集。受检患者平均年龄在30至85岁之间。  
研究方法：图像结果分类的机器学习方法（随机梯度下降、逻辑回归、随机森林、朴素贝叶斯）。  
主要研究结果：研究结果是计算机建模，可以从图像中确定结果是青光眼还是其他疾病（二元分类）。 

---
# Squeeze Out Tokens from Sample for Finer-Grained Data Governance 

**Title (ZH)**: 从样本中挤出令牌以实现更细粒度的数据治理 

**Authors**: Weixiong Lin, Chen Ju, Haicheng Wang, Shengchao Hu, Shuai Xiao, Mengting Chen, Yuheng Jiao, Mingshuai Yao, Jinsong Lan, Qingwen Liu, Ying Chen  

**Link**: [PDF](https://arxiv.org/pdf/2503.14559)  

**Abstract**: Widely observed data scaling laws, in which error falls off as a power of the training size, demonstrate the diminishing returns of unselective data expansion. Hence, data governance is proposed to downsize datasets through pruning non-informative samples. Yet, isolating the impact of a specific sample on overall model performance is challenging, due to the vast computation required for tryout all sample combinations. Current data governors circumvent this complexity by estimating sample contributions through heuristic-derived scalar scores, thereby discarding low-value ones. Despite thorough sample sieving, retained samples contain substantial undesired tokens intrinsically, underscoring the potential for further compression and purification. In this work, we upgrade data governance from a 'sieving' approach to a 'juicing' one. Instead of scanning for least-flawed samples, our dual-branch DataJuicer applies finer-grained intra-sample governance. It squeezes out informative tokens and boosts image-text alignments. Specifically, the vision branch retains salient image patches and extracts relevant object classes, while the text branch incorporates these classes to enhance captions. Consequently, DataJuicer yields more refined datasets through finer-grained governance. Extensive experiments across datasets demonstrate that DataJuicer significantly outperforms existing DataSieve in image-text retrieval, classification, and dense visual reasoning. 

**Abstract (ZH)**: 广泛观察到的数据缩放定律表明，误差随训练数据量的增加呈幂次衰减，这展示了非选择性数据扩增的递减回报。因此，提议通过修剪非信息性样本来减少数据集规模进行数据治理。然而，隔离单个样本对整体模型性能的影响极具挑战性，因为需要进行大量计算来尝试所有样本组合。当前的数据经理通过启发式衍生的标量评分估计样本贡献，从而丢弃低价值的样本。尽管进行了彻底的样本筛选，保留的样本中仍然包含大量内在的不希望出现的标记，这表明进一步压缩和净化的潜力。在此项工作中，我们将数据治理从“筛选”方法升级为“压榨”方法。与其寻找最无瑕的样本，我们的双分支DataJuicer应用更精细粒度的样本内治理。它挤出有价值的信息标记，并增强图像-文本对齐。具体来说，视觉分支保留显著的图像块并提取相关的对象类别，而文本分支将这些类别纳入以增强描述。因此，DataJuicer通过更精细粒度的治理产生更精细的数据集。广泛的数据集实验表明，DataJuicer在图像-文本检索、分类和密集视觉推理中显著优于现有的DataSieve。 

---
# Designing and Deploying AI Models for Sustainable Logistics Optimization: A Case Study on Eco-Efficient Supply Chains in the USA 

**Title (ZH)**: 设计并部署.AI模型以实现可持续物流优化：以美国生态高效供应链案例研究为例 

**Authors**: Reza E Rabbi Shawon, MD Rokibul Hasan, Md Anisur Rahman, Mohamed Ghandri, Iman Ahmed Lamari, Mohammed Kawsar, Rubi Akter  

**Link**: [PDF](https://arxiv.org/pdf/2503.14556)  

**Abstract**: The rapid evolution of Artificial Intelligence (AI) and Machine Learning (ML) has significantly transformed logistics and supply chain management, particularly in the pursuit of sustainability and eco-efficiency. This study explores AI-based methodologies for optimizing logistics operations in the USA, focusing on reducing environmental impact, improving fuel efficiency, and minimizing costs. Key AI applications include predictive analytics for demand forecasting, route optimization through machine learning, and AI-powered fuel efficiency strategies. Various models, such as Linear Regression, XGBoost, Support Vector Machine, and Neural Networks, are applied to real-world logistics datasets to reduce carbon emissions based on logistics operations, optimize travel routes to minimize distance and travel time, and predict future deliveries to plan optimal routes. Other models such as K-Means and DBSCAN are also used to optimize travel routes to minimize distance and travel time for logistics operations. This study utilizes datasets from logistics companies' databases. The study also assesses model performance using metrics such as mean absolute error (MAE), mean squared error (MSE), and R2 score. This study also explores how these models can be deployed to various platforms for real-time logistics and supply chain use. The models are also examined through a thorough case study, highlighting best practices and regulatory frameworks that promote sustainability. The findings demonstrate AI's potential to enhance logistics efficiency, reduce carbon footprints, and contribute to a more resilient and adaptive supply chain ecosystem. 

**Abstract (ZH)**: 人工智能和机器学习的快速演进显著 transforming 物流和供应链管理，特别是在追求可持续性和生态效率方面的努力。本文探讨了基于人工智能的方法论以优化美国的物流操作，重点关注减少环境影响、提高燃料效率和降低成本。关键的人工智能应用包括基于预测分析的需求预测、通过机器学习实现的路线优化以及人工智能驱动的燃料效率策略。应用了线性回归、XGBoost、支持向量机和神经网络等多种模型，基于物流操作数据减少碳排放、优化旅行路线以最小化距离和旅行时间，并预测未来交付以规划最优路线。其他模型如K-均值和DBSCAN也被用于最小化物流操作中的距离和旅行时间以优化旅行路线。本文利用了物流公司的数据库数据集。研究还使用平均绝对误差（MAE）、均方误差（MSE）和R2评分等指标评估模型性能。本文还探讨了这些模型如何部署到各种平台以实现实时的物流和供应链使用。通过详尽的案例研究，本文还探讨了促进可持续性的最佳实践和监管框架。研究发现表明，人工智能有可能提升物流效率、减少碳足迹，并促进更具韧性和适应性的供应链生态系统。 

---
# A Generalist Hanabi Agent 

**Title (ZH)**: 通用型Hanabi智能体 

**Authors**: Arjun V Sudhakar, Hadi Nekoei, Mathieu Reymond, Miao Liu, Janarthanan Rajendran, Sarath Chandar  

**Link**: [PDF](https://arxiv.org/pdf/2503.14555)  

**Abstract**: Traditional multi-agent reinforcement learning (MARL) systems can develop cooperative strategies through repeated interactions. However, these systems are unable to perform well on any other setting than the one they have been trained on, and struggle to successfully cooperate with unfamiliar collaborators. This is particularly visible in the Hanabi benchmark, a popular 2-to-5 player cooperative card-game which requires complex reasoning and precise assistance to other agents. Current MARL agents for Hanabi can only learn one specific game-setting (e.g., 2-player games), and play with the same algorithmic agents. This is in stark contrast to humans, who can quickly adjust their strategies to work with unfamiliar partners or situations. In this paper, we introduce Recurrent Replay Relevance Distributed DQN (R3D2), a generalist agent for Hanabi, designed to overcome these limitations. We reformulate the task using text, as language has been shown to improve transfer. We then propose a distributed MARL algorithm that copes with the resulting dynamic observation- and action-space. In doing so, our agent is the first that can play all game settings concurrently, and extend strategies learned from one setting to other ones. As a consequence, our agent also demonstrates the ability to collaborate with different algorithmic agents -- agents that are themselves unable to do so. The implementation code is available at: $\href{this https URL}{R3D2-A-Generalist-Hanabi-Agent}$ 

**Abstract (ZH)**: 传统的多代理强化学习（MARL）系统可以通过重复交互发展合作策略。然而，这些系统在训练环境之外的表现不佳，并且难以与不熟悉的合作者成功合作。这一点在Hanabi基准中尤为明显，Hanabi是一个流行的合作纸牌游戏，需要复杂的推理和对其他代理的精确协助。目前的Hanabi MARL代理只能学习一种特定的游戏设置（例如2人游戏），并且使用相同的算法代理进行游戏。这与人类的行为形成鲜明对比，人类能够快速调整策略以适应不熟悉的合作伙伴或情况。在本文中，我们引入了循环回放相关分布式DQN（R3D2），这是一种用于Hanabi的通用代理，旨在克服这些限制。我们通过文本重新定义了任务，因为语言已被证明可以改进迁移。然后，我们提出了一种能够应对由此产生的动态观测空间和动作空间的分布式MARL算法。因此，我们的代理可以同时玩所有游戏设置，并将从一种设置中学到的策略扩展到其他设置。因此，我们的代理还展示了与不同算法代理协作的能力——这些代理本身也无法做到这一点。相关实现代码可在以下链接获得：R3D2-A通用Hanabi代理$\href{this https URL}{R3D2-A-Generalist-Hanabi-Agent}$ 

---
# Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot 

**Title (ZH)**: 同步vs异步强化学习在真实机器人中的应用 

**Authors**: Ali Parsaee, Fahim Shahriar, Chuxin He, Ruiqing Tan  

**Link**: [PDF](https://arxiv.org/pdf/2503.14554)  

**Abstract**: In recent times, reinforcement learning (RL) with physical robots has attracted the attention of a wide range of researchers. However, state-of-the-art RL algorithms do not consider that physical environments do not wait for the RL agent to make decisions or updates. RL agents learn by periodically conducting computationally expensive gradient updates. When decision-making and gradient update tasks are carried out sequentially by the RL agent in a physical robot, it significantly increases the agent's response time. In a rapidly changing environment, this increased response time may be detrimental to the performance of the learning agent. Asynchronous RL methods, which separate the computation of decision-making and gradient updates, are a potential solution to this problem. However, only a few comparisons between asynchronous and synchronous RL have been made with physical robots. For this reason, the exact performance benefits of using asynchronous RL methods over synchronous RL methods are still unclear. In this study, we provide a performance comparison between asynchronous and synchronous RL using a physical robotic arm called Franka Emika Panda. Our experiments show that the agents learn faster and attain significantly more returns using asynchronous RL. Our experiments also demonstrate that the learning agent with a faster response time performs better than the agent with a slower response time, even if the agent with a slower response time performs a higher number of gradient updates. 

**Abstract (ZH)**: 物理机器人中异步与同步强化学习性能比较 

---
# Fire and Smoke Datasets in 20 Years: An In-depth Review 

**Title (ZH)**: 二十年来火灾与烟雾数据集：深入回顾 

**Authors**: Sayed Pedram Haeri Boroujeni, Niloufar Mehrabi, Fatemeh Afghah, Connor Peter McGrath, Danish Bhatkar, Mithilesh Anil Biradar, Abolfazl Razi  

**Link**: [PDF](https://arxiv.org/pdf/2503.14552)  

**Abstract**: Fire and smoke phenomena pose a significant threat to the natural environment, ecosystems, and global economy, as well as human lives and wildlife. In this particular circumstance, there is a demand for more sophisticated and advanced technologies to implement an effective strategy for early detection, real-time monitoring, and minimizing the overall impacts of fires on ecological balance and public safety. Recently, the rapid advancement of Artificial Intelligence (AI) and Computer Vision (CV) frameworks has substantially revolutionized the momentum for developing efficient fire management systems. However, these systems extensively rely on the availability of adequate and high-quality fire and smoke data to create proficient Machine Learning (ML) methods for various tasks, such as detection and monitoring. Although fire and smoke datasets play a critical role in training, evaluating, and testing advanced Deep Learning (DL) models, a comprehensive review of the existing datasets is still unexplored. For this purpose, we provide an in-depth review to systematically analyze and evaluate fire and smoke datasets collected over the past 20 years. We investigate the characteristics of each dataset, including type, size, format, collection methods, and geographical diversities. We also review and highlight the unique features of each dataset, such as imaging modalities (RGB, thermal, infrared) and their applicability for different fire management tasks (classification, segmentation, detection). Furthermore, we summarize the strengths and weaknesses of each dataset and discuss their potential for advancing research and technology in fire management. Ultimately, we conduct extensive experimental analyses across different datasets using several state-of-the-art algorithms, such as ResNet-50, DeepLab-V3, and YoloV8. 

**Abstract (ZH)**: 火和烟现象对自然环境、生态系统、全球经济以及人类生活和野生动物构成重大威胁。在这种情况下，需要更加先进和 sophisticated 的技术来实施有效的早期检测、实时监控和减少火灾对生态平衡和公共安全的总体影响策略。近年来，人工智能（AI）和计算机视觉（CV）框架的快速发展极大地推动了高效火灾管理系统的开发。然而，这些系统广泛依赖于充足的高质量火灾和烟雾数据，以便为各种任务（如检测和监控）创建高效的机器学习（ML）方法。尽管火灾和烟雾数据在训练、评估和测试先进深度学习（DL）模型中发挥着关键作用，但现有数据集的全面回顾尚未探索。为此，我们提供了一项深入的回顾，系统地分析和评估过去20年收集的火灾和烟雾数据集。我们调查了每个数据集的特点，包括类型、大小、格式、采集方法以及地理多样性。我们还回顾并突出了每个数据集的独特特点，例如成像模态（RGB、热成像、红外）及其在不同火灾管理任务（分类、分割、检测）中的适用性。此外，我们总结了每个数据集的优点和缺点，并讨论了它们在火灾管理研究和技术进步中的潜在价值。最终，我们使用多个最先进的算法（如ResNet-50、DeepLab-V3和YoloV8）在不同数据集上进行了广泛的实验分析。 

---
# Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk 

**Title (ZH)**: 基于人工智能的新穎乳腺动脉钙化定量方法以预测心血管风险 

**Authors**: Theodorus Dapamede, Aisha Urooj, Vedant Joshi, Gabrielle Gershon, Frank Li, Mohammadreza Chavoshi, Beatrice Brown-Mulry, Rohan Satya Isaac, Aawez Mansuri, Chad Robichaux, Chadi Ayoub, Reza Arsanjani, Laurence Sperling, Judy Gichoya, Marly van Assen, Charles W. ONeill, Imon Banerjee, Hari Trivedi  

**Link**: [PDF](https://arxiv.org/pdf/2503.14550)  

**Abstract**: Women are underdiagnosed and undertreated for cardiovascular disease. Automatic quantification of breast arterial calcification on screening mammography can identify women at risk for cardiovascular disease and enable earlier treatment and management of disease. In this retrospective study of 116,135 women from two healthcare systems, a transformer-based neural network quantified BAC severity (no BAC, mild, moderate, and severe) on screening mammograms. Outcomes included major adverse cardiovascular events (MACE) and all-cause mortality. BAC severity was independently associated with MACE after adjusting for cardiovascular risk factors, with increasing hazard ratios from mild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22) across datasets (all p<0.001). This association remained significant across all age groups, with even mild BAC indicating increased risk in women under 50. BAC remained an independent predictor when analyzed alongside ASCVD risk scores, showing significant associations with myocardial infarction, stroke, heart failure, and mortality (all p<0.005). Automated BAC quantification enables opportunistic cardiovascular risk assessment during routine mammography without additional radiation or cost. This approach provides value beyond traditional risk factors, particularly in younger women, offering potential for early CVD risk stratification in the millions of women undergoing annual mammography. 

**Abstract (ZH)**: 女性心血管疾病诊断不足且治疗不足。基于Transformer的神经网络在筛查乳腺X线摄影中自动量化乳腺动脉钙化可以识别心血管疾病风险女性并促进疾病的早期治疗和管理。在两项 healthcare 系统中的116,135名女性的回顾性研究中，变压器基神经网络在筛查乳腺X线摄影中量化了乳腺动脉钙化严重程度（无钙化、轻度、中度和重度）。结果包括主要不良心血管事件（MACE）和全因死亡率。钙化严重程度在调整心血管风险因素后独立与MACE相关，从轻度钙化（HR 1.18-1.22）、中度钙化（HR 1.38-1.47）到重度钙化（HR 2.03-2.22）的危险比在不同数据集中逐渐增加（所有p<0.001）。这种关联在所有年龄组中均具显著性，即使轻度钙化也增加了50岁以下女性的患病风险。在同时分析冠状动脉性心脏病风险评分时，钙化仍是一个独立的预测因子，显示出与心肌梗死、中风、心力衰竭和死亡的显著关联（所有p<0.005）。自动量化乳腺动脉钙化可以在常规乳腺X线摄影中进行机会性心血管风险评估，无需额外辐射或成本。这种方法为年轻女性提供了传统风险因素之外的额外价值，特别是在每年接受乳腺X线摄影的数百万女性中提供早期心血管疾病风险分层的潜力。 

---
# Sampling Decisions 

**Title (ZH)**: 采样决策 

**Authors**: Michael Chertkov, Sungsoo Ahn, Hamidreza Behjoo  

**Link**: [PDF](https://arxiv.org/pdf/2503.14549)  

**Abstract**: In this manuscript we introduce a novel Decision Flow (DF) framework for sampling from a target distribution while incorporating additional guidance from a prior sampler. DF can be viewed as an AI driven algorithmic reincarnation of the Markov Decision Process (MDP) approach in Stochastic Optimal Control. It extends the continuous space, continuous time path Integral Diffusion sampling technique to discrete time and space, while also generalizing the Generative Flow Network framework. In its most basic form, an explicit, Neural Network (NN) free formulation, DF leverages the linear solvability of the the underlying MDP to adjust the transition probabilities of the prior sampler. The resulting Markov Process is expressed as a convolution of the reverse time Green's function of the prior sampling with the target distribution. We illustrate the DF framework through an example of sampling from the Ising model, discuss potential NN based extensions, and outline how DF can enhance guided sampling across various applications. 

**Abstract (ZH)**: 基于先验采样器的附加指导的新型决策流框架 

---
# The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances 

**Title (ZH)**: 人工智能对急诊医学的影响：近期进展综述 

**Authors**: Gustavo Correia, Victor Alves, Paulo Novais  

**Link**: [PDF](https://arxiv.org/pdf/2503.14546)  

**Abstract**: Artificial Intelligence (AI) is revolutionizing emergency medicine by enhancing diagnostic processes and improving patient outcomes. This article provides a review of the current applications of AI in emergency imaging studies, focusing on the last five years of advancements. AI technologies, particularly machine learning and deep learning, are pivotal in interpreting complex imaging data, offering rapid, accurate diagnoses and potentially surpassing traditional diagnostic methods. Studies highlighted within the article demonstrate AI's capabilities in accurately detecting conditions such as fractures, pneumothorax, and pulmonary diseases from various imaging modalities including X-rays, CT scans, and MRIs. Furthermore, AI's ability to predict clinical outcomes like mechanical ventilation needs illustrates its potential in crisis resource optimization. Despite these advancements, the integration of AI into clinical practice presents challenges such as data privacy, algorithmic bias, and the need for extensive validation across diverse settings. This review underscores the transformative potential of AI in emergency settings, advocating for a future where AI and clinical expertise synergize to elevate patient care standards. 

**Abstract (ZH)**: 人工智能（AI）正通过增强诊断流程和提升患者结果来革新急诊医学。本文 review 了过去五年AI在急诊影像学应用中的进展，重点介绍了机器学习和深度学习等AI技术在解读复杂影像数据中的关键作用，以及其在预测临床结果方面的潜力。文章中的研究表明，AI能够从多种影像学检查方法（如X光、CT扫描和MRI）中准确检测骨折、气胸和肺部疾病等状况。此外，AI预测临床结果如机械通气需求的能力展示了其在危机资源优化中的潜在作用。尽管取得了这些进步，AI在临床实践中的整合仍面临数据隐私、算法偏见和跨多样场景验证的挑战。本文强调了AI在急诊环境中的变革潜力，倡导未来AI与临床专长的协同作用以提升患者护理标准。 

---
# Inteligencia Artificial para la conservación y uso sostenible de la biodiversidad, una visión desde Colombia (Artificial Intelligence for conservation and sustainable use of biodiversity, a view from Colombia) 

**Title (ZH)**: 人工智能在保护和可持续利用生物多样性中的应用：以哥伦比亚为例 

**Authors**: Juan Sebastián Cañas, Camila Parra-Guevara, Manuela Montoya-Castrillón, Julieta M Ramírez-Mejía, Gabriel-Alejandro Perilla, Esteban Marentes, Nerieth Leuro, Jose Vladimir Sandoval-Sierra, Sindy Martinez-Callejas, Angélica Díaz, Mario Murcia, Elkin A. Noguera-Urbano, Jose Manuel Ochoa-Quintero, Susana Rodríguez Buriticá, Juan Sebastián Ulloa  

**Link**: [PDF](https://arxiv.org/pdf/2503.14543)  

**Abstract**: The rise of artificial intelligence (AI) and the aggravating biodiversity crisis have resulted in a research area where AI-based computational methods are being developed to act as allies in conservation, and the sustainable use and management of natural resources. While important general guidelines have been established globally regarding the opportunities and challenges that this interdisciplinary research offers, it is essential to generate local reflections from the specific contexts and realities of each region. Hence, this document aims to analyze the scope of this research area from a perspective focused on Colombia and the Neotropics. In this paper, we summarize the main experiences and debates that took place at the Humboldt Institute between 2023 and 2024 in Colombia. To illustrate the variety of promising opportunities, we present current uses such as automatic species identification from images and recordings, species modeling, and in silico bioprospecting, among others. From the experiences described above, we highlight limitations, challenges, and opportunities for in order to successfully implementate AI in conservation efforts and sustainable management of biological resources in the Neotropics. The result aims to be a guide for researchers, decision makers, and biodiversity managers, facilitating the understanding of how artificial intelligence can be effectively integrated into conservation and sustainable use strategies. Furthermore, it also seeks to open a space for dialogue on the development of policies that promote the responsible and ethical adoption of AI in local contexts, ensuring that its benefits are harnessed without compromising biodiversity or the cultural and ecosystemic values inherent in Colombia and the Neotropics. 

**Abstract (ZH)**: 人工智能兴起与生物多样性危机加剧背景下基于人工智能的计算方法在哥伦比亚和新热带地区的保护及自然资源可持续利用中的作用研究 

---
# AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients 

**Title (ZH)**: 基于AI的快速识别菌血症患者血液涂片中细菌和真菌病原体方法 

**Authors**: Agnieszka Sroka-Oleksiak, Adam Pardyl, Dawid Rymarczyk, Aldona Olechowska-Jarząb, Katarzyna Biegun-Drożdż, Dorota Ochońska, Michał Wronka, Adriana Borowa, Tomasz Gosiewski, Miłosz Adamczyk, Henryk Telega, Bartosz Zieliński, Monika Brzychczy-Włoch  

**Link**: [PDF](https://arxiv.org/pdf/2503.14542)  

**Abstract**: Sepsis is a life-threatening condition which requires rapid diagnosis and treatment. Traditional microbiological methods are time-consuming and expensive. In response to these challenges, deep learning algorithms were developed to identify 14 bacteria species and 3 yeast-like fungi from microscopic images of Gram-stained smears of positive blood samples from sepsis patients.
A total of 16,637 Gram-stained microscopic images were used in the study. The analysis used the Cellpose 3 model for segmentation and Attention-based Deep Multiple Instance Learning for classification. Our model achieved an accuracy of 77.15% for bacteria and 71.39% for fungi, with ROC AUC of 0.97 and 0.88, respectively. The highest values, reaching up to 96.2%, were obtained for Cutibacterium acnes, Enterococcus faecium, Stenotrophomonas maltophilia and Nakaseomyces glabratus. Classification difficulties were observed in closely related species, such as Staphylococcus hominis and Staphylococcus haemolyticus, due to morphological similarity, and within Candida albicans due to high morphotic diversity.
The study confirms the potential of our model for microbial classification, but it also indicates the need for further optimisation and expansion of the training data set. In the future, this technology could support microbial diagnosis, reducing diagnostic time and improving the effectiveness of sepsis treatment due to its simplicity and accessibility. Part of the results presented in this publication was covered by a patent application at the European Patent Office EP24461637.1 "A computer implemented method for identifying a microorganism in a blood and a data processing system therefor". 

**Abstract (ZH)**: 深度学习算法在Gram染色血样显微镜图像中鉴定14种细菌和3种酵母菌株的研究 

---
# Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data 

**Title (ZH)**: 基于视觉-语言模型的急性 tuberculosis 诊断：结合影像学和临床数据的多模态方法 

**Authors**: Ananya Ganapthy, Praveen Shastry, Naveen Kumarasami, Anandakumar D, Keerthana R, Mounigasri M, Varshinipriya M, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam  

**Link**: [PDF](https://arxiv.org/pdf/2503.14538)  

**Abstract**: Background: This study introduces a Vision-Language Model (VLM) leveraging SIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB) screening. By integrating chest X-ray images and clinical notes, the model aims to enhance diagnostic accuracy and efficiency, particularly in resource-limited settings.
Methods: The VLM combines visual data from chest X-rays with clinical context to generate detailed, context-aware diagnostic reports. The architecture employs SIGLIP for visual encoding and Gemma-3b for decoding, ensuring effective representation of acute TB-specific pathologies and clinical insights.
Results: Key acute TB pathologies, including consolidation, cavities, and nodules, were detected with high precision (97percent) and recall (96percent). The model demonstrated strong spatial localization capabilities and robustness in distinguishing TB-positive cases, making it a reliable tool for acute TB diagnosis.
Conclusion: The multimodal capability of the VLM reduces reliance on radiologists, providing a scalable solution for acute TB screening. Future work will focus on improving the detection of subtle pathologies and addressing dataset biases to enhance its generalizability and application in diverse global healthcare settings. 

**Abstract (ZH)**: 背景：本研究介绍了利用SIGLIP和Gemma-3b架构的视觉语言模型（VLM），用于自动化急性结核病（TB）筛查。通过整合胸部X光图像和临床笔记，该模型旨在提高诊断的准确性和效率，特别是在资源有限的环境中。

方法：VLM将胸部X光图像的视觉数据与临床上下文结合起来生成详细、情境相关的诊断报告。该架构使用SIGLIP进行视觉编码，使用Gemma-3b进行解码，确保有效表示急性TB特定的病理和临床见解。

结果：研究检测了包括实变、空洞和结节在内的主要急性TB病理，精度为97%，召回率为96%。该模型展示了强大的空间定位能力和在区分TB阳性病例方面的鲁棒性，使其成为急性TB诊断的可靠工具。

结论：VLM的多模态能力减少了对放射科医生的依赖，提供了一个可扩展的解决方案以供急性TB筛查使用。未来工作将重点提高对细微病理的检测能力，并解决数据集偏差问题，以增强其适应性和在全球不同医疗保健环境中的普遍适用性。 

---
# Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis 

**Title (ZH)**: 使用视觉语言模型推进慢性 tuberculosis 诊断：精确分析的多模态框架 

**Authors**: Praveen Shastry, Sowmya Chowdary Muthulur, Naveen Kumarasami, Anandakumar D, Mounigasri M, Keerthana R, Kishore Prasath Venkatesh, Bargava Subramanian, Kalyan Sivasailam, Revathi Ezhumalai, Abitha Marimuthu  

**Link**: [PDF](https://arxiv.org/pdf/2503.14536)  

**Abstract**: Background This study proposes a Vision-Language Model (VLM) leveraging the SIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic tuberculosis (TB) screening. By integrating chest X-ray images with clinical data, the model addresses the challenges of manual interpretation, improving diagnostic consistency and accessibility, particularly in resource-constrained settings.
Methods The VLM architecture combines a Vision Transformer (ViT) for visual encoding and a transformer-based text encoder to process clinical context, such as patient histories and treatment records. Cross-modal attention mechanisms align radiographic features with textual information, while the Gemma-3b decoder generates comprehensive diagnostic reports. The model was pre-trained on 5 million paired medical images and texts and fine-tuned using 100,000 chronic TB-specific chest X-rays.
Results The model demonstrated high precision (94 percent) and recall (94 percent) for detecting key chronic TB pathologies, including fibrosis, calcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores exceeded 0.93, and Intersection over Union (IoU) values were above 0.91, validating its effectiveness in detecting and localizing TB-related abnormalities.
Conclusion The VLM offers a robust and scalable solution for automated chronic TB diagnosis, integrating radiographic and clinical data to deliver actionable and context-aware insights. Future work will address subtle pathologies and dataset biases to enhance the model's generalizability, ensuring equitable performance across diverse populations and healthcare settings. 

**Abstract (ZH)**: 基于SIGLIP编码器和Gemma-3b变压器解码器的视觉语言模型在增强自动化慢性肺结核筛查中的应用 

---
# Interpretable Unsupervised Joint Denoising and Enhancement for Real-World low-light Scenarios 

**Title (ZH)**: 可解释的无监督联合去噪与增强方法及其在实际低光场景中的应用 

**Authors**: Huaqiu Li, Xiaowan Hu, Haoqian Wang  

**Link**: [PDF](https://arxiv.org/pdf/2503.14535)  

**Abstract**: Real-world low-light images often suffer from complex degradations such as local overexposure, low brightness, noise, and uneven illumination. Supervised methods tend to overfit to specific scenarios, while unsupervised methods, though better at generalization, struggle to model these degradations due to the lack of reference images. To address this issue, we propose an interpretable, zero-reference joint denoising and low-light enhancement framework tailored for real-world scenarios. Our method derives a training strategy based on paired sub-images with varying illumination and noise levels, grounded in physical imaging principles and retinex theory. Additionally, we leverage the Discrete Cosine Transform (DCT) to perform frequency domain decomposition in the sRGB space, and introduce an implicit-guided hybrid representation strategy that effectively separates intricate compounded degradations. In the backbone network design, we develop retinal decomposition network guided by implicit degradation representation mechanisms. Extensive experiments demonstrate the superiority of our method. Code will be available at this https URL. 

**Abstract (ZH)**: 现实世界中的低光照图像常常遭受复杂退化的影响，如局部过曝、低亮度、噪声和不均匀光照。监督方法往往会过度拟合到特定场景中，而无监督方法虽然在泛化能力上更优，但由于缺乏参考图像而在建模这些退化时遇到困难。为解决这一问题，我们提出了一种针对现实世界场景的可解释、无参考联合去噪和低光照增强框架。该方法基于具有不同光照和噪声水平的配对子图像训练策略，并基于物理成像原理和retinex理论。此外，我们利用离散余弦变换（DCT）在sRGB空间中进行频域分解，并引入了一种隐式引导的混合表示策略，有效地分离复杂的复合退化。在网络设计方面，我们提出了由隐式退化表示机制引导的视网膜分解网络。广泛的经验表明，我们的方法具有优越性。代码将在以下链接处提供：this https URL。 

---
# SAUCE: Selective Concept Unlearning in Vision-Language Models with Sparse Autoencoders 

**Title (ZH)**: SAUCE: 基于稀疏自编码器的选择性概念遗忘在视觉-语言模型中的应用 

**Authors**: Qing Li, Jiahui Geng, Derui Zhu, Fengyu Cai, Chenyang Lyu, Fakhri Karray  

**Link**: [PDF](https://arxiv.org/pdf/2503.14530)  

**Abstract**: Unlearning methods for vision-language models (VLMs) have primarily adapted techniques from large language models (LLMs), relying on weight updates that demand extensive annotated forget sets. Moreover, these methods perform unlearning at a coarse granularity, often leading to excessive forgetting and reduced model utility. To address this issue, we introduce SAUCE, a novel method that leverages sparse autoencoders (SAEs) for fine-grained and selective concept unlearning in VLMs. Briefly, SAUCE first trains SAEs to capture high-dimensional, semantically rich sparse features. It then identifies the features most relevant to the target concept for unlearning. During inference, it selectively modifies these features to suppress specific concepts while preserving unrelated information. We evaluate SAUCE on two distinct VLMs, LLaVA-v1.5-7B and LLaMA-3.2-11B-Vision-Instruct, across two types of tasks: concrete concept unlearning (objects and sports scenes) and abstract concept unlearning (emotions, colors, and materials), encompassing a total of 60 concepts. Extensive experiments demonstrate that SAUCE outperforms state-of-the-art methods by 18.04% in unlearning quality while maintaining comparable model utility. Furthermore, we investigate SAUCE's robustness against widely used adversarial attacks, its transferability across models, and its scalability in handling multiple simultaneous unlearning requests. Our findings establish SAUCE as an effective and scalable solution for selective concept unlearning in VLMs. 

**Abstract (ZH)**: 基于稀疏自编码器的视觉-语言模型细粒度选择性去学习方法 

---
# Accessibility Considerations in the Development of an AI Action Plan 

**Title (ZH)**: AI行动计划中的可达性考虑 

**Authors**: Jennifer Mankoff, Janice Light, James Coughlan, Christian Vogler, Abraham Glasser, Gregg Vanderheiden, Laura Rice  

**Link**: [PDF](https://arxiv.org/pdf/2503.14522)  

**Abstract**: We argue that there is a need for Accessibility to be represented in several important domains:
- Capitalize on the new capabilities AI provides - Support for open source development of AI, which can allow disabled and disability focused professionals to contribute, including
- Development of Accessibility Apps which help realise the promise of AI in accessibility domains
- Open Source Model Development and Validation to ensure that accessibility concerns are addressed in these algorithms
- Data Augmentation to include accessibility in data sets used to train models
- Accessible Interfaces that allow disabled people to use any AI app, and to validate its outputs
- Dedicated Functionality and Libraries that can make it easy to integrate AI support into a variety of settings and apps. - Data security and privacy and privacy risks including data collected by AI based accessibility technologies; and the possibility of disability disclosure. - Disability-specific AI risks and biases including both direct bias (during AI use by the disabled person) and indirect bias (when AI is used by someone else on data relating to a disabled person). 

**Abstract (ZH)**: 我们argue需要在以下几个重要领域体现Accessibility：
- 充分利用AI提供的新能力 - 支持开放源代码的AI开发，这可以让残疾和以残疾人为中心的专业人员贡献自己的力量
- 发展无障碍应用程序，以实现AI在无障碍领域的潜力
- 开放源代码模型开发和验证，确保在这些算法中解决无障碍问题
- 数据增强，将无障碍纳入用于训练模型的数据集中
- 可访问界面，使残疾人能够使用任何AI应用程序，并验证其输出
- 专门的功能和库，使其更容易将AI支持集成到各种环境和应用程序中
- 数据安全与隐私以及隐私风险，包括AI无障碍技术收集的数据；以及披露残疾人身份的可能性
- 专门的AI风险和偏见，包括直接偏见（残疾人使用AI期间）和间接偏见（他人使用AI处理与残疾人相关的数据时）。 

---
# Policy Frameworks for Transparent Chain-of-Thought Reasoning in Large Language Models 

**Title (ZH)**: 大型语言模型中透明链式推理的政策框架 

**Authors**: Yihang Chen, Haikang Deng, Kaiqiao Han, Qingyue Zhao  

**Link**: [PDF](https://arxiv.org/pdf/2503.14521)  

**Abstract**: Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by decomposing complex problems into step-by-step solutions, improving performance on reasoning tasks. However, current CoT disclosure policies vary widely across different models in frontend visibility, API access, and pricing strategies, lacking a unified policy framework. This paper analyzes the dual-edged implications of full CoT disclosure: while it empowers small-model distillation, fosters trust, and enables error diagnosis, it also risks violating intellectual property, enabling misuse, and incurring operational costs. We propose a tiered-access policy framework that balances transparency, accountability, and security by tailoring CoT availability to academic, business, and general users through ethical licensing, structured reasoning outputs, and cross-tier safeguards. By harmonizing accessibility with ethical and operational considerations, this framework aims to advance responsible AI deployment while mitigating risks of misuse or misinterpretation. 

**Abstract (ZH)**: 全链推理披露的双刃剑影响及分级访问政策框架：促进负责任的AI部署的同时减轻滥用或误用风险 

---
# Content ARCs: Decentralized Content Rights in the Age of Generative AI 

**Title (ZH)**: 生成人工智能时代的内容权利ARC：去中心化的内容权利管理 

**Authors**: Kar Balan, Andrew Gilbert, John Collomosse  

**Link**: [PDF](https://arxiv.org/pdf/2503.14519)  

**Abstract**: The rise of Generative AI (GenAI) has sparked significant debate over balancing the interests of creative rightsholders and AI developers. As GenAI models are trained on vast datasets that often include copyrighted material, questions around fair compensation and proper attribution have become increasingly urgent. To address these challenges, this paper proposes a framework called \emph{Content ARCs} (Authenticity, Rights, Compensation). By combining open standards for provenance and dynamic licensing with data attribution, and decentralized technologies, Content ARCs create a mechanism for managing rights and compensating creators for using their work in AI training. We characterize several nascent works in the AI data licensing space within Content ARCs and identify where challenges remain to fully implement the end-to-end framework. 

**Abstract (ZH)**: Generative AI (GenAI)的发展引发了关于创造性权利持有者利益与AI开发者之间平衡的显著 debate。由于GenAI模型在训练过程中通常包含了受版权保护的内容，因此关于公平补偿和适当归属的问题日益迫切。为应对这些挑战，本文提出了一种名为Content ARCs（Authenticity, Rights, Compensation）的框架。通过结合溯源的开放标准、动态许可与数据归属，并利用去中心化技术，Content ARCs 创建了一个管理权利和补偿创作者在AI训练中使用其作品的机制。我们对AI数据许可领域的几种初步工作在Content ARCs中的特征进行描述，并识别出实施端到端框架仍存在的挑战。 

---
# Cafe-Talk: Generating 3D Talking Face Animation with Multimodal Coarse- and Fine-grained Control 

**Title (ZH)**: Cafe-Talk：多模态细粒度和粗粒度控制生成3D交谈人脸动画 

**Authors**: Hejia Chen, Haoxian Zhang, Shoulong Zhang, Xiaoqiang Liu, Sisi Zhuang, Yuan Zhang, Pengfei Wan, Di Zhang, Shuai Li  

**Link**: [PDF](https://arxiv.org/pdf/2503.14517)  

**Abstract**: Speech-driven 3D talking face method should offer both accurate lip synchronization and controllable expressions. Previous methods solely adopt discrete emotion labels to globally control expressions throughout sequences while limiting flexible fine-grained facial control within the spatiotemporal domain. We propose a diffusion-transformer-based 3D talking face generation model, Cafe-Talk, which simultaneously incorporates coarse- and fine-grained multimodal control conditions. Nevertheless, the entanglement of multiple conditions challenges achieving satisfying performance. To disentangle speech audio and fine-grained conditions, we employ a two-stage training pipeline. Specifically, Cafe-Talk is initially trained using only speech audio and coarse-grained conditions. Then, a proposed fine-grained control adapter gradually adds fine-grained instructions represented by action units (AUs), preventing unfavorable speech-lip synchronization. To disentangle coarse- and fine-grained conditions, we design a swap-label training mechanism, which enables the dominance of the fine-grained conditions. We also devise a mask-based CFG technique to regulate the occurrence and intensity of fine-grained control. In addition, a text-based detector is introduced with text-AU alignment to enable natural language user input and further support multimodal control. Extensive experimental results prove that Cafe-Talk achieves state-of-the-art lip synchronization and expressiveness performance and receives wide acceptance in fine-grained control in user studies. Project page: this https URL 

**Abstract (ZH)**: 基于语音驱动的3D Talking Face方法应同时提供精确的唇同步和可控的表情。以往方法仅采用离散的情绪标签对整个序列进行全局控制，而在时空域内限制了灵活的细粒度面部控制。我们提出了一种基于扩散变压器的3D Talking Face生成模型Cafe-Talk，该模型同时融入了粗粒度和细粒度的多模态控制条件。然而，多种条件的交织给实现满意性能带来了挑战。为了解开语音音频和细粒度条件之间的纠缠，我们采用了两阶段训练管道。具体来说，Cafe-Talk首先仅使用语音音频和粗粒度条件进行训练。然后，通过一个提出的细粒度控制适配器逐步添加由动作单位（AUs）表示的细粒度指令，防止不理想的语音-唇同步。为了分离粗粒度和细粒度条件，我们设计了一种换标签训练机制，使细粒度条件占据主导地位。我们还设计了一种基于掩码的CFG技术，以调节细粒度控制的发生和强度。此外，我们引入了一种基于文本的检测器，该检测器与文本-AU对齐，以便接受自然语言用户输入并进一步支持多模态控制。广泛的实验结果证明，Cafe-Talk在唇同步和表现力方面达到了最先进的性能，并在用户研究中获得了广泛接受。项目页面：这个 https URL 

---
# Acceptance or Rejection of Lots while Minimizing and Controlling Type I and Type II Errors 

**Title (ZH)**: 接受或拒绝批次并同时最小化和控制类型I和类型II错误 

**Authors**: Edson Luiz Ursini, Elaine Cristina Catapani Poletti, Loreno Menezes da Silveira, José Roberto Emiliano Leite  

**Link**: [PDF](https://arxiv.org/pdf/2503.14514)  

**Abstract**: The double hypothesis test (DHT) is a test that allows controlling Type I (producer) and Type II (consumer) errors. It is possible to say whether the batch has a defect rate, p, between 1.5 and 2%, or between 2 and 5%, or between 5 and 10%, and so on, until finding a required value for this probability. Using the two probabilities side by side, the Type I error for the lower probability distribution and the Type II error for the higher probability distribution, both can be controlled and minimized. It can be applied in the development or manufacturing process of a batch of components, or in the case of purchasing from a supplier, when the percentage of defects (p) is unknown, considering the technology and/or process available to obtain them. The power of the test is amplified by the joint application of the Limit of Successive Failures (LSF) related to the Renewal Theory. To enable the choice of the most appropriate algorithm for each application. Four distributions are proposed for the Bernoulli event sequence, including their computational efforts: Binomial, Binomial approximated by Poisson, and Binomial approximated by Gaussian (with two variants). Fuzzy logic rules are also applied to facilitate decision-making. 

**Abstract (ZH)**: 双假设检验(DHT)是一种能够控制生产者(I型)错误和消费者(II型)错误的检验方法。可以通过计算既可以判断批产品的缺陷率p处于1.5%-2%、2%-5%、5%-10%等区间中的哪一个，直到找到所需概率的值。将两个概率值并列使用，可以同时控制和最小化较低概率分布的I型错误和较高概率分布的II型错误。该方法可以应用于组件批次的研发或制造过程，或在从供应商采购时，当未知缺陷百分比(p)的情况下，结合可用的技术和/或工艺来获取它们。通过与更新理论相关的连续失败上限(LSF)的联合应用，提高了检验的功效。为了适应不同应用选择最合适的算法。提出了四种伯努利事件序列的分布，并讨论了各自的计算成本：二项式分布、泊松逼近的二项式分布、高斯逼近的二项式分布（两种变体），还应用了模糊逻辑规则以辅助决策。 

---
# Synthetic Data Generation of Body Motion Data by Neural Gas Network for Emotion Recognition 

**Title (ZH)**: 基于神经_gas网络的 BodysMotion数据合成生成及其在情感识别中的应用 

**Authors**: Seyed Muhammad Hossein Mousavi  

**Link**: [PDF](https://arxiv.org/pdf/2503.14513)  

**Abstract**: In the domain of emotion recognition using body motion, the primary challenge lies in the scarcity of diverse and generalizable datasets. Automatic emotion recognition uses machine learning and artificial intelligence techniques to recognize a person's emotional state from various data types, such as text, images, sound, and body motion. Body motion poses unique challenges as many factors, such as age, gender, ethnicity, personality, and illness, affect its appearance, leading to a lack of diverse and robust datasets specifically for emotion recognition. To address this, employing Synthetic Data Generation (SDG) methods, such as Generative Adversarial Networks (GANs) and Variational Auto Encoders (VAEs), offers potential solutions, though these methods are often complex. This research introduces a novel application of the Neural Gas Network (NGN) algorithm for synthesizing body motion data and optimizing diversity and generation speed. By learning skeletal structure topology, the NGN fits the neurons or gas particles on body joints. Generated gas particles, which form the skeletal structure later on, will be used to synthesize the new body posture. By attaching body postures over frames, the final synthetic body motion appears. We compared our generated dataset against others generated by GANs, VAEs, and another benchmark algorithm, using benchmark metrics such as Fréchet Inception Distance (FID), Diversity, and a few more. Furthermore, we continued evaluation using classification metrics such as accuracy, precision, recall, and a few others. Joint-related features or kinematic parameters were extracted, and the system assessed model performance against unseen data. Our findings demonstrate that the NGN algorithm produces more realistic and emotionally distinct body motion data and does so with more synthesizing speed than existing methods. 

**Abstract (ZH)**: 在基于身体运动的情感识别领域，主要挑战在于多样性和通用性强的数据库稀缺。自动情感识别采用机器学习和人工智能技术，从文本、图像、声音和身体运动等多种数据类型中识别人的情感状态。身体运动带来了独特的挑战，因为诸如年龄、性别、种族、个性和疾病等因素都会影响其表现，导致缺乏专门用于情感识别的多样性和稳健性数据集。为了应对这一挑战，利用合成数据生成（SDG）方法，如生成对抗网络（GANs）和变分自编码器（VAEs），提供了潜在的解决方案，尽管这些方法通常较为复杂。本研究介绍了一种神经气体网络（NGN）算法的新应用，用于合成身体运动数据并优化多样性和生成速度。通过学习骨骼结构拓扑，NGN将神经元或气体颗粒放置在身体关节上。生成的气体颗粒将用于合成新的身体姿态。通过在帧上附加身体姿态，最终合成的身体运动显现出来。我们使用弗雷切尔感知距离（FID）、多样性和其他基准指标，将我们的生成数据集与其他由GANs、VAEs和另一基准算法生成的数据集进行比较。此外，我们继续使用准确率、精确率、召回率等分类指标进行评估。提取与关节相关的特征或运动参数，并评估系统在面对未见过的数据时的性能。我们的研究结果表明，NGN算法生成的情感上更真实且更具有差异性的身体运动数据，并且生成速度也快于现有方法。 

---
