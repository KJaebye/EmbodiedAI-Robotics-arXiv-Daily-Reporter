{'arxiv_id': 'arXiv:2505.16997', 'title': 'X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs', 'authors': 'Rui Ye, Xiangrui Liu, Qimin Wu, Xianghe Pang, Zhenfei Yin, Lei Bai, Siheng Chen', 'link': 'https://arxiv.org/abs/2505.16997', 'abstract': "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by enabling cooperation among multiple specialized agents. However, most existing MAS frameworks rely on a single LLM to drive all agents, constraining the system's intelligence to the limit of that model. This paper explores the paradigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by diverse LLMs, elevating the system's potential to the collective intelligence of diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to evaluate the performance of various LLMs across different domains and MAS-related functions. As an extensive empirical study, we assess 27 LLMs across 5 domains (encompassing 21 test sets) and 5 functions, conducting over 1.7 million evaluations to identify optimal model selections for each domain-function combination. Building on these findings, we demonstrate that transitioning from homogeneous to heterogeneous LLM-driven MAS can significantly enhance system performance without requiring structural redesign. Specifically, in a chatbot-only MAS scenario, the heterogeneous configuration yields up to 8.4\\% performance improvement on the MATH dataset. In a mixed chatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable 47\\% performance boost on the AIME dataset. Our results underscore the transformative potential of heterogeneous LLMs in MAS, highlighting a promising avenue for advancing scalable, collaborative AI systems.", 'abstract_zh': '基于LLM的异构多智能体系统（X-MAS）：提升多智能体系统潜力的异构LLM驱动范式', 'title_zh': 'X-MAS: 向构建异构大语言模型多智能体系统方向努力'}
{'arxiv_id': 'arXiv:2505.16982', 'title': 'Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine', 'authors': 'Adib Bazgir, Amir Habibdoust Lafmajani, Yuwen Zhang', 'link': 'https://arxiv.org/abs/2505.16982', 'abstract': 'Large Language Models (LLMs) show promise in biomedicine but lack true causal understanding, relying instead on correlations. This paper envisions causal LLM agents that integrate multimodal data (text, images, genomics, etc.) and perform intervention-based reasoning to infer cause-and-effect. Addressing this requires overcoming key challenges: designing safe, controllable agentic frameworks; developing rigorous benchmarks for causal evaluation; integrating heterogeneous data sources; and synergistically combining LLMs with structured knowledge (KGs) and formal causal inference tools. Such agents could unlock transformative opportunities, including accelerating drug discovery through automated hypothesis generation and simulation, enabling personalized medicine through patient-specific causal models. This research agenda aims to foster interdisciplinary efforts, bridging causal concepts and foundation models to develop reliable AI partners for biomedical progress.', 'abstract_zh': '大规模语言模型（LLMs）在生物医学领域展现出潜力，但缺乏真正的因果理解，而是依赖于相关性。本文构想了集成多模态数据（文本、图像、基因组等）并进行干预推理以推断因果关系的因果LLM代理。实现这一目标需要克服关键挑战：设计安全可控的代理框架；开发严格的因果评估基准；整合异构数据源；以及协同结合LLMs与结构化知识（KGs）和形式化的因果推理工具。这些代理有望解锁变革性机会，包括通过自动化假设生成和模拟加速药物发现，以及通过患者特异性因果模型实现个性化医疗。这一研究议程旨在促进跨学科努力，将因果概念与基础模型结合起来，开发可信赖的AI伙伴以促进生物医学的进步。', 'title_zh': '超越相关性：迈向生物医学中的因果大型语言模型代理'}
{'arxiv_id': 'arXiv:2505.16979', 'title': 'Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design', 'authors': 'Zhenkun Li, Lingyao Li, Shuhang Lin, Yongfeng Zhang', 'link': 'https://arxiv.org/abs/2505.16979', 'abstract': 'Single-agent LLMs hit hard limits--finite context, role overload, and brittle domain transfer. Conventional multi-agent fixes soften those edges yet expose fresh pains: ill-posed decompositions, fuzzy contracts, and verification overhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a framework that converts domain priors into an algorithmic blueprint hierarchy, in which tasks are recursively split into typed, controller-mediated subtasks, each solved zero-shot or with the lightest viable boost (e.g., chain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch theorem, KtR trades the chase for a universal prompt for disciplined decomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents raise accuracy from 3% zero-shot to 95% on size-5 instances after patching a single bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a six-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15, versus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation thus turns modest models into reliable collaborators--no ever-larger monoliths required.', 'abstract_zh': 'Single-agent LLMs碰触硬极限——有限语境、角色过载和脆弱的知识域迁移。传统的多agent解决方案缓解了这些限制，但也暴露出新的问题：含糊的细分、模糊的协议和验证开销，这些都削弱了收益。因此，我们提出了Know-The-Ropes (KtR)框架，该框架将先验知识转化为分层算法蓝图，任务递归拆分为类型化、控制器中介的子任务，每个子任务零样本解决或仅以最小可行增强（例如，思考链、微量调整、自我检查）解决。基于No-Free-Lunch定理，KtR交易了对通用提示的追求，以实现有序的细分。在背包问题（3-8项）中，三个GPT-4o-mini代理在修补了一个瓶颈代理后，将零样本准确率从3%提高到大小为5的实例的95%。在更复杂的任务分配问题（6-15项工作）中，六代理o3-mini蓝图在大小为10时达到100%，在大小13-15时达到84%，而零样本准确率为11%。因此，算法意识的细分加上有针对性的增强将朴素模型转变为可靠的合作者——无需更大的单一实体。', 'title_zh': '了解关键环节：一种基于LLM的多 Agents 系统设计的启发式策略'}
{'arxiv_id': 'arXiv:2505.16978', 'title': 'HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation', 'authors': 'Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle', 'link': 'https://arxiv.org/abs/2505.16978', 'abstract': 'Grammar plays a critical role in natural language processing and text/code generation by enabling the definition of syntax, the creation of parsers, and guiding structured outputs. Although large language models (LLMs) demonstrate impressive capabilities across domains, their ability to infer and generate grammars has not yet been thoroughly explored. In this paper, we aim to study and improve the ability of LLMs for few-shot grammar generation, where grammars are inferred from sets of a small number of positive and negative examples and generated in Backus-Naur Form. To explore this, we introduced a novel dataset comprising 540 structured grammar generation challenges, devised 6 metrics, and evaluated 8 various LLMs against it. Our findings reveal that existing LLMs perform sub-optimally in grammar generation. To address this, we propose an LLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar generation. HyGenar achieves substantial improvements in both the syntactic and semantic correctness of generated grammars across LLMs.', 'abstract_zh': '语法在自然语言处理和文本/代码生成中扮演着关键角色，它使得语法定义、解析器创建以及指导结构化输出成为可能。尽管大规模语言模型（LLMs）在各个领域展现出令人印象深刻的性能，但它们推断和生成语法的能力尚未得到充分探索。在本文中，我们旨在研究和提高LLMs在少样本语法生成方面的能力，其中语法是从少量正负例中推断并以Backus-Naur形式生成的。为探索这一领域，我们引入了一个包含540个结构化语法生成挑战的新数据集，制定了6个评估指标，并将8种不同的LLMs进行了评估。我们的发现表明，现有LLMs在语法生成方面表现欠佳。为此，我们提出了一种基于LLM的混合遗传算法，即HyGenar，以优化语法生成。HyGenar在LLMs生成的语法的句法和语义正确性方面取得了显著改善。', 'title_zh': 'HyGenar: 由大规模语言模型驱动的混合遗传算法用于少量样本语法规则生成'}
{'arxiv_id': 'arXiv:2505.16944', 'title': 'AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios', 'authors': 'Yunjia Qi, Hao Peng, Xiaozhi Wang, Amy Xin, Youfeng Liu, Bin Xu, Lei Hou, Juanzi Li', 'link': 'https://arxiv.org/abs/2505.16944', 'abstract': 'Large Language Models (LLMs) have demonstrated advanced capabilities in real-world agentic applications. Growing research efforts aim to develop LLM-based agents to address practical demands, introducing a new challenge: agentic scenarios often involve lengthy instructions with complex constraints, such as extended system prompts and detailed tool specifications. While adherence to such instructions is crucial for agentic applications, whether LLMs can reliably follow them remains underexplored. In this paper, we introduce AgentIF, the first benchmark for systematically evaluating LLM instruction following ability in agentic scenarios. AgentIF features three key characteristics: (1) Realistic, constructed from 50 real-world agentic applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words. (3) Complex, averaging 11.9 constraints per instruction, covering diverse constraint types, such as tool specifications and condition constraints. To construct AgentIF, we collect 707 human-annotated instructions across 50 agentic tasks from industrial application agents and open-source agentic systems. For each instruction, we annotate the associated constraints and corresponding evaluation metrics, including code-based evaluation, LLM-based evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically evaluate existing advanced LLMs. We observe that current models generally perform poorly, especially in handling complex constraint structures and tool specifications. We further conduct error analysis and analytical experiments on instruction length and meta constraints, providing some findings about the failure modes of existing LLMs. We have released the code and data to facilitate future research.', 'abstract_zh': '大型语言模型（LLMs）在现实世界的代理应用中展现了先进的能力。不断增长的研究努力旨在开发基于LLM的代理以应对实际需求，这引入了一个新的挑战：代理场景通常涉及长篇复杂的指令，如扩展系统提示和详细的工具规范。尽管遵守这些指令对于代理应用至关重要，但LLMs能否可靠地遵循它们仍是一个未被充分探索的问题。在本文中，我们介绍了AgentIF，这是首个系统性评估LLM指令遵循能力的基准。AgentIF具有三个关键特征：(1) 现实性强，来自50个真实的代理应用。(2) 长度长，平均1,723字，最多15,630字。(3) 复杂性强，平均每条指令包含11.9个约束，涵盖了不同类型，如工具规范和条件约束。为构建AgentIF，我们收集了来自50个代理任务的707条人类注释的指令，这些任务来自工业应用代理和开源代理系统。对于每条指令，我们标注了相关的约束及其对应的评估指标，包括代码评估、基于LLM的评估以及代码-LLM混合评估。我们使用AgentIF系统性评估现有的高级LLM。我们发现当前模型在这类复杂约束结构和工具规范的处理方面表现较差。我们进一步对指令长度和元约束进行错误分析和实验性研究，揭示了一些关于现有LLM失败模式的发现。我们已公开了代码和数据，以促进未来的研究。', 'title_zh': 'AGENTIF: 在代理场景下大型语言模型指令跟随能力的基准评估'}
{'arxiv_id': 'arXiv:2505.16938', 'title': 'NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification', 'authors': 'NovelSeek Team, Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang, Shaowei Hou, Zheng Nie, Zhilong Wang, Jinyao Liu, Runmin Ma, Tianshuo Peng, Peng Ye, Dongzhan Zhou, Shufei Zhang, Xiaosong Wang, Yilan Zhang, Meng Li, Zhongying Tu, Xiangyu Yue, Wangli Ouyang, Bowen Zhou, Lei Bai', 'link': 'https://arxiv.org/abs/2505.16938', 'abstract': 'Artificial Intelligence (AI) is accelerating the transformation of scientific research paradigms, not only enhancing research efficiency but also driving innovation. We introduce NovelSeek, a unified closed-loop multi-agent framework to conduct Autonomous Scientific Research (ASR) across various scientific research fields, enabling researchers to tackle complicated problems in these fields with unprecedented speed and precision. NovelSeek highlights three key advantages: 1) Scalability: NovelSeek has demonstrated its versatility across 12 scientific research tasks, capable of generating innovative ideas to enhance the performance of baseline code. 2) Interactivity: NovelSeek provides an interface for human expert feedback and multi-agent interaction in automated end-to-end processes, allowing for the seamless integration of domain expert knowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in several scientific fields with significantly less time cost compared to human efforts. For instance, in reaction yield prediction, it increased from 27.6% to 35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from 0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation, precision advanced from 78.8% to 81.0% in a mere 30 hours.', 'abstract_zh': '人工智能（AI）正加速科研范式的转变，不仅提高研究效率，还推动创新。我们介绍了NovelSeek，这是一种统一的闭环多代理框架，用于跨多个科学领域开展自主科学研究（ASR），使研究人员能够以前所未有的速度和精确度解决这些领域的复杂问题。NovelSeek突显了三项关键优势：1）可扩展性：NovelSeek在其在12项科学研究任务中的 versatility 表现出了强大的适应性，能够生成创新想法以提升基础代码的性能。2）互动性：NovelSeek 提供了供人类专家反馈和多代理交互的接口，在自动化端到端过程中实现专业知识的无缝集成。3）效率：NovelSeek 在多个科学领域中取得了显著的性能提升，所需时间远少于人力投入。例如，在反应产率预测中，它在12小时内将准确率从27.6％提升至35.4％；在增强子活性预测中，仅用4小时处理即从0.52提升至0.79；在2D语义分割中，精度在30小时内从78.8％提升至81.0％。', 'title_zh': 'NovelSeek: 当代理论成为科学家——从假设到验证的闭环系统构建'}
{'arxiv_id': 'arXiv:2505.16928', 'title': 'Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning', 'authors': 'Bosung Kim, Prithviraj Ammanabrolu', 'link': 'https://arxiv.org/abs/2505.16928', 'abstract': "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks that advances long-context understanding in embodied AI. $\\infty$-THOR provides: (1) a generation framework for synthesizing scalable, reproducible, and unlimited long-horizon trajectories; (2) a novel embodied QA task, Needle(s) in the Embodied Haystack, where multiple scattered clues across extended trajectories test agents' long-context reasoning ability; and (3) a long-horizon dataset and benchmark suite featuring complex tasks that span hundreds of environment steps, each paired with ground-truth action sequences. To enable this capability, we explore architectural adaptations, including interleaved Goal-State-Action modeling, context extension techniques, and Context Parallelism, to equip LLM-based agents for extreme long-context reasoning and interaction. Experimental results and analyses highlight the challenges posed by our benchmark and provide insights into training strategies and model behaviors under long-horizon conditions. Our work provides a foundation for the next generation of embodied AI systems capable of robust, long-term reasoning and planning.", 'abstract_zh': '$\\infty$-THOR：一种新的长时域体态任务框架，推进体态AI中的长上下文理解', 'title_zh': '超越体内的针堆：长上下文推理中的环境、架构与训练考量'}
{'arxiv_id': 'arXiv:2505.16899', 'title': 'Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships', 'authors': 'Kerem Oktar, Katherine M. Collins, Jose Hernandez-Orallo, Diane Coyle, Stephen Cave, Adrian Weller, Ilia Sucholutsky', 'link': 'https://arxiv.org/abs/2505.16899', 'abstract': 'Artificial Intelligence (AI) systems have historically been used as tools that execute narrowly defined tasks. Yet recent advances in AI have unlocked possibilities for a new class of models that genuinely collaborate with humans in complex reasoning, from conceptualizing problems to brainstorming solutions. Such AI thought partners enable novel forms of collaboration and extended cognition, yet they also pose major risks-including and beyond risks of typical AI tools and agents. In this commentary, we systematically identify risks of AI thought partners through a novel framework that identifies risks at multiple levels of analysis, including Real-time, Individual, and Societal risks arising from collaborative cognition (RISc). We leverage this framework to propose concrete metrics for risk evaluation, and finally suggest specific mitigation strategies for developers and policymakers. As AI thought partners continue to proliferate, these strategies can help prevent major harms and ensure that humans actively benefit from productive thought partnerships.', 'abstract_zh': 'AI思考伙伴的风险及其应对策略：从协作认知（RISc）框架下的多层次分析', 'title_zh': '识别、评估和缓解AI思想合作伙伴关系的风险'}
{'arxiv_id': 'arXiv:2505.16877', 'title': 'Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings', 'authors': 'Yuqicheng Zhu, Daniel Hernández, Yuan He, Zifeng Ding, Bo Xiong, Evgeny Kharlamov, Steffen Staab', 'link': 'https://arxiv.org/abs/2505.16877', 'abstract': 'Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is crucial for ensuring the reliability of downstream applications. A recent work applies conformal prediction to KGE methods, providing uncertainty estimates by generating a set of answers that is guaranteed to include the true answer with a predefined confidence level. However, existing methods provide probabilistic guarantees averaged over a reference set of queries and answers (marginal coverage guarantee). In high-stakes applications such as medical diagnosis, a stronger guarantee is often required: the predicted sets must provide consistent coverage per query (conditional coverage guarantee). We propose CondKGCP, a novel method that approximates predicate-conditional coverage guarantees while maintaining compact prediction sets. CondKGCP merges predicates with similar vector representations and augments calibration with rank information. We prove the theoretical guarantees and demonstrate empirical effectiveness of CondKGCP by comprehensive evaluations.', 'abstract_zh': '知识图嵌入方法中不确定性量化对于确保下游应用的可靠性至关重要。一项近期工作将符合性预测应用于知识图嵌入方法，通过生成一个保证包含真实答案的置信区间内的答案集合来提供不确定性估计。现有方法提供基于参考查询和答案集合的边际覆盖概率保证。在医疗诊断等高风险应用中，通常需要更强的保证：预测集必须为每个查询提供一致的覆盖（条件覆盖保证）。我们提出了一种名为CondKGCP的新方法，该方法近似预测的条件覆盖保证，同时保持预测集的紧凑性。CondKGCP结合了具有相似向量表示的谓词，并通过排名信息增强校准。我们证明了CondKGCP的理论保证，并通过全面评估展示了其实验有效性。', 'title_zh': '基于谓词条件的置信区间回答集嵌入'}
{'arxiv_id': 'arXiv:2505.16854', 'title': 'Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models', 'authors': 'Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou', 'link': 'https://arxiv.org/abs/2505.16854', 'abstract': "Reinforcement Learning (RL) has proven to be an effective post-training strategy for enhancing reasoning in vision-language models (VLMs). Group Relative Policy Optimization (GRPO) is a recent prominent method that encourages models to generate complete reasoning traces before answering, leading to increased token usage and computational cost. Inspired by the human-like thinking process-where people skip reasoning for easy questions but think carefully when needed-we explore how to enable VLMs to first decide when reasoning is necessary. To realize this, we propose TON, a two-stage training strategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective 'thought dropout' operation, where reasoning traces are randomly replaced with empty thoughts. This introduces a think-or-not format that serves as a cold start for selective reasoning; (ii) a GRPO stage that enables the model to freely explore when to think or not, while maximizing task-aware outcome rewards. Experimental results show that TON can reduce the completion length by up to 90% compared to vanilla GRPO, without sacrificing performance or even improving it. Further evaluations across diverse vision-language tasks-covering a range of reasoning difficulties under both 3B and 7B models-consistently reveal that the model progressively learns to bypass unnecessary reasoning steps as training advances. These findings shed light on the path toward human-like reasoning patterns in reinforcement learning approaches. Our code is available at this https URL.", 'abstract_zh': '强化学习（RL）已被证明是一种有效的后训练策略，用于增强视觉语言模型（VLMs）的推理能力。组相对策略优化（GRPO）是一种近期的突出方法，它鼓励模型在回答之前生成完整的推理轨迹，从而增加了标记的使用量和计算成本。借鉴人类的思考过程——人们在回答简单问题时会跳过推理，而在需要时会仔细思考——我们探索如何使VLMs首先决定何时进行推理是必要的。为实现这一点，我们提出了一种两阶段训练策略TON：（i）监督微调（SFT）阶段包含一个简单的‘思考跳过’操作，其中随机用空想法替换推理轨迹，这引入了一种思考或不思考的格式，作为选择性推理的起点；（ii）GRPO阶段使模型能够自由探索何时思考或不思考，同时最大化任务相关的结果奖励。实验结果显示，与vanilla GRPO相比，TON可以将完成长度最多减少90%，而无需牺牲性能甚至有所提升。在多种视觉语言任务（涵盖3B和7B模型下各种推理难度）上的进一步评估一致表明，随着训练的进行，模型逐渐学会了跳过不必要的推理步骤。这些发现为强化学习方法中的人类似推理模式的研究提供了启示。我们的代码可在以下链接获取。', 'title_zh': '思考还是不思考？基于强化学习的视觉-语言模型的选择性推理'}
{'arxiv_id': 'arXiv:2505.16832', 'title': 'From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization', 'authors': 'Haonian Ji, Shi Qiu, Siyang Xin, Siwei Han, Zhaorun Chen, Hongyi Wang, Dake Zhang, Huaxiu Yao', 'link': 'https://arxiv.org/abs/2505.16832', 'abstract': 'While foundation models (FMs), such as diffusion models and large vision-language models (LVLMs), have been widely applied in educational contexts, their ability to generate pedagogically effective visual explanations remains limited. Most existing approaches focus primarily on textual reasoning, overlooking the critical role of structured and interpretable visualizations in supporting conceptual understanding. To better assess the visual reasoning capabilities of FMs in educational settings, we introduce EduVisBench, a multi-domain, multi-level benchmark. EduVisBench features diverse STEM problem sets requiring visually grounded solutions, along with a fine-grained evaluation rubric informed by pedagogical theory. Our empirical analysis reveals that existing models frequently struggle with the inherent challenge of decomposing complex reasoning and translating it into visual representations aligned with human cognitive processes. To address these limitations, we propose EduVisAgent, a multi-agent collaborative framework that coordinates specialized agents for instructional planning, reasoning decomposition, metacognitive prompting, and visualization design. Experimental results show that EduVisAgent substantially outperforms all baselines, achieving a 40.2% improvement and delivering more educationally aligned visualizations. EduVisBench and EduVisAgent are available at this https URL and this https URL.', 'abstract_zh': '尽管基础模型（如扩散模型和大型视觉语言模型）已经在教育场景中广泛应用，但在生成教学有效的视觉解释方面的能力仍有限。现有方法大多主要侧重于文本推理，忽略了结构化和可解释的可视化在支持概念理解中的关键作用。为了更好地评估基础模型在教育场景中的视觉推理能力，我们提出了EduVisBench，一个多领域、多层级基准。EduVisBench 包含了需要视觉 grounding 解决方案的多样化 STEM 问题集，并结合了基于教育理论的细粒度评估标准。实证分析显示，现有模型在分解复杂推理并将其转化为与人类认知过程相一致的视觉表示方面经常遇到困难。为了解决这些局限性，我们提出了EduVisAgent，一个多智能体协作框架，协调专门的智能体进行教学规划、推理分解、元认知提示和可视化设计。实验结果表明，EduVisAgent 显著优于所有基线，实现了40.2%的改进，并提供了更多教育导向的视觉表示。EduVisBench 和 EduVisAgent 可通过以下链接获取：[该链接] 和 [该链接]。', 'title_zh': '从EduVisBench到EduVisAgent：教学可视化基准及多智能体框架'}
{'arxiv_id': 'arXiv:2505.16827', 'title': 'GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent', 'authors': 'Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie', 'link': 'https://arxiv.org/abs/2505.16827', 'abstract': 'GUI automation faces critical challenges in dynamic environments. MLLMs suffer from two key issues: misinterpreting UI components and outdated knowledge. Traditional fine-tuning methods are costly for app-specific knowledge updates. We propose GUI-explorer, a training-free GUI agent that incorporates two fundamental mechanisms: (1) Autonomous Exploration of Function-aware Trajectory. To comprehensively cover all application functionalities, we design a Function-aware Task Goal Generator that automatically constructs exploration goals by analyzing GUI structural information (e.g., screenshots and activity hierarchies). This enables systematic exploration to collect diverse trajectories. (2) Unsupervised Mining of Transition-aware Knowledge. To establish precise screen-operation logic, we develop a Transition-aware Knowledge Extractor that extracts effective screen-operation logic through unsupervised analysis the state transition of structured interaction triples (observation, action, outcome). This eliminates the need for human involvement in knowledge extraction. With a task success rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows significant improvements over SOTA agents. It requires no parameter updates for new apps. GUI-explorer is open-sourced and publicly available at this https URL.', 'abstract_zh': 'GUI自动化在动态环境中面临关键挑战。MLLMs遭受两大关键问题：UI组件误读和过时的知识。传统的细调方法对于应用程序特定知识的更新成本较高。我们提出GUI-explorer，一种无需训练的GUI智能体，整合了两种基本机制：（1）功能导向的自主探索轨迹。为全面覆盖所有应用程序功能，我们设计了一个功能导向的任务目标生成器，该生成器通过分析GUI结构信息（如屏幕截图和活动层级）自动构建探索目标，从而实现系统性探索以收集多样化轨迹。（2）基于转换的无监督知识挖掘。为建立精确的屏幕操作逻辑，我们开发了一个基于转换的知识提取器，该提取器通过无监督分析结构化的交互三元组（观察、动作、结果）的状态转换来提取有效的屏幕操作逻辑。这消除了知识抽取过程中的人工参与需求。GUI-explorer在SPA-Bench上的任务成功率达到了53.7%，在AndroidWorld上的成功率达到了47.4%，显示出对当前最佳代理的显著改进。它无需为新应用更新参数。GUI-explorer开源并公开可用于此[链接]。', 'title_zh': 'GUI-explorer: 自主探索与挖掘具有状态转换意识的知识的GUI代理'}
{'arxiv_id': 'arXiv:2505.16826', 'title': 'KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning', 'authors': 'Wei Sun, Wen Yang, Pu Jian, Qianlong Du, Fuwei Cui, Shuo Ren, Jiajun Zhang', 'link': 'https://arxiv.org/abs/2505.16826', 'abstract': 'Recent advances have demonstrated that integrating reinforcement learning with rule-based rewards can significantly enhance the reasoning capabilities of large language models, even without supervised fine-tuning. However, prevalent reinforcement learning algorithms such as GRPO and its variants like DAPO, suffer from a coarse granularity issue when computing the advantage. Specifically, they compute rollout-level advantages that assign identical values to every token within a sequence, failing to capture token-specific contributions and hindering effective learning. To address this limitation, we propose Key-token Advantage Estimation (KTAE) - a novel algorithm that estimates fine-grained, token-level advantages without introducing additional models. KTAE leverages the correctness of sampled rollouts and applies statistical analysis to quantify the importance of individual tokens within a sequence to the final outcome. This quantified token-level importance is then combined with the rollout-level advantage to obtain a more fine-grained token-level advantage estimation. Empirical results show that models trained with GRPO+KTAE and DAPO+KTAE outperform baseline methods across five mathematical reasoning benchmarks. Notably, they achieve higher accuracy with shorter responses and even surpass R1-Distill-Qwen-1.5B using the same base model.', 'abstract_zh': 'Recent Advances in Key-token Advantage Estimation for Enhancing Reasoning Capabilities of Large Language Models Without Supervised Fine-tuning', 'title_zh': 'KTAE：一种无需模型的关键-token 优势估计算法在数学推理中的应用'}
{'arxiv_id': 'arXiv:2505.16787', 'title': 'Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce', 'authors': 'Ashish Sundar, Chunbo Luo, Xiaoyang Wang', 'link': 'https://arxiv.org/abs/2505.16787', 'abstract': 'Model-based reinforcement learning (MBRL) offers an intuitive way to increase the sample efficiency of model-free RL methods by simultaneously training a world model that learns to predict the future. MBRL methods have progressed by largely prioritising the actor; optimising the world model learning has been neglected meanwhile. Improving the fidelity of the world model and reducing its time to convergence can yield significant downstream benefits, one of which is improving the ensuing performance of any actor it may train. We propose a novel approach that anticipates and actively seeks out high-entropy states using short-horizon latent predictions generated by the world model, offering a principled alternative to traditional curiosity-driven methods that chase once-novel states well after they were stumbled into. While many model predictive control (MPC) based methods offer similar alternatives, they typically lack commitment, synthesising multi step plans after every step. To mitigate this, we present a hierarchical planner that dynamically decides when to replan, planning horizon length, and the weighting between reward and entropy. While our method can theoretically be applied to any model that trains its own actors with solely model generated data, we have applied it to just Dreamer as a proof of concept. Our method finishes the Miniworld procedurally generated mazes 50% faster than base Dreamer at convergence and the policy trained in imagination converges in only 60% of the environment steps that base Dreamer needs.', 'abstract_zh': '基于模型的强化学习（MBRL）提供了一种通过同时训练一个世界模型来预测未来的直观方式，从而提高无模型RL方法的样本效率。尽管MBRL方法主要关注优化演员，但同时优化世界模型的学习却常常被忽视。提高世界模型的保真度并减少其收敛时间可以带来显著的下游效益，其中之一是提高它所训练的任何演员的性能。我们提出了一种新颖的方法，该方法利用由世界模型生成的短时滞后潜变量来预见并主动寻求高熵状态，从而提供了一种传统的好奇心驱动方法的原理性替代方案，后者在遇到不寻常的状态后才追逐这些状态。虽然许多基于模型预测控制（MPC）的方法提供相似的替代方案，但它们通常缺乏承诺，每步之后综合多步计划。为了缓解这一问题，我们提出了一种分层规划器，它可以动态决定何时重新规划、规划时滞长度以及奖励和熵之间的权重。虽然我们的方法理论上可以应用于任何仅使用模型生成数据训练自己演员的模型，但我们在Dreamer上进行了实验，作为概念验证。我们的方法在Miniworld程序生成的迷宫收敛时速度快50%，并且在想象中训练的策略只需要基线Dreamer所需环境步骤的60%即可收敛。', 'title_zh': '凝视 abyss ——当奖励稀缺时寻求entropy 的规划'}
{'arxiv_id': 'arXiv:2505.16781', 'title': 'Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making', 'authors': 'Qianlei Jia, Xinliang Zhou, Ondrej Krejcar, Enrique Herrera-Viedma', 'link': 'https://arxiv.org/abs/2505.16781', 'abstract': 'In group decision-making (GDM) scenarios, uncertainty, dynamic social structures, and vague information present major challenges for traditional opinion dynamics models. To address these issues, this study proposes a novel social network group decision-making (SNGDM) framework that integrates three-way decision (3WD) theory, dynamic network reconstruction, and linguistic opinion representation. First, the 3WD mechanism is introduced to explicitly model hesitation and ambiguity in agent judgments, thereby preventing irrational decisions. Second, a connection adjustment rule based on opinion similarity is developed, enabling agents to adaptively update their communication links and better reflect the evolving nature of social relationships. Third, linguistic terms are used to describe agent opinions, allowing the model to handle subjective, vague, or incomplete information more effectively. Finally, an integrated multi-agent decision-making framework is constructed, which simultaneously considers individual uncertainty, opinion evolution, and network dynamics. The proposed model is applied to a multi-UAV cooperative decision-making scenario, where simulation results and consensus analysis demonstrate its effectiveness. Experimental comparisons further verify the advantages of the algorithm in enhancing system stability and representing realistic decision-making behaviors.', 'abstract_zh': '在群决策制定（GDM）场景中，传统意见动力学模型面临着不确定性、动态社会结构和模糊信息的重大挑战。为应对这些问题，本研究提出了一种融合三元决策（3WD）理论、动态网络重构和语言意见表示的新颖社会网络群决策制定（SNGDM）框架。首先，引入3WD机制以明确建模代理人的犹豫和模糊性，从而避免不理智的决策。其次，基于意见相似性的连接调整规则被开发出来，使代理能够适应性更新其通信链路，更好地反映社交关系的动态变化。第三，使用语言术语来描述代理人的意见，使得模型能够更有效地处理主观、模糊或不完整的信息。最后，构建了一个综合性的多-agent决策制定框架，同时考虑个体不确定性、意见演变和网络动态。提出的模型应用于多-UAV协同决策制定场景，仿真结果和共识分析证明了其有效性。实验比较进一步验证了该算法在增强系统稳定性和代表现实决策行为方面的优势。', 'title_zh': '基于三元决策的社交网络群体决策中模糊信息演化'}
{'arxiv_id': 'arXiv:2505.16771', 'title': 'Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review', 'authors': 'Beyazit Bestami Yuksel, Ayse Yilmazer Metin', 'link': 'https://arxiv.org/abs/2505.16771', 'abstract': "This paper presents a comprehensive synthesis of major breakthroughs in artificial intelligence (AI) over the past fifteen years, integrating historical, theoretical, and technological perspectives. It identifies key inflection points in AI' s evolution by tracing the convergence of computational resources, data access, and algorithmic innovation. The analysis highlights how researchers enabled GPU based model training, triggered a data centric shift with ImageNet, simplified architectures through the Transformer, and expanded modeling capabilities with the GPT series. Rather than treating these advances as isolated milestones, the paper frames them as indicators of deeper paradigm shifts. By applying concepts from statistical learning theory such as sample complexity and data efficiency, the paper explains how researchers translated breakthroughs into scalable solutions and why the field must now embrace data centric approaches. In response to rising privacy concerns and tightening regulations, the paper evaluates emerging solutions like federated learning, privacy enhancing technologies (PETs), and the data site paradigm, which reframe data access and security. In cases where real world data remains inaccessible, the paper also assesses the utility and constraints of mock and synthetic data generation. By aligning technical insights with evolving data infrastructure, this study offers strategic guidance for future AI research and policy development.", 'abstract_zh': '过去十五年人工智能重大突破的综合综述：从计算资源、数据访问和算法创新的融合视角探讨关键拐点及深远范式转变', 'title_zh': '数据驱动的人工智能基础设施突破与未来方向：全面回顾'}
{'arxiv_id': 'arXiv:2505.16700', 'title': 'MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models', 'authors': 'Xuanqi Gao, Siyi Xie, Juan Zhai, Shqing Ma, Chao Shen', 'link': 'https://arxiv.org/abs/2505.16700', 'abstract': 'As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of tool interaction, the Model Context Protocol (MCP) has emerged as a standardized framework for dynamic tool discovery and orchestration. Despite widespread industry adoption, existing evaluation methodologies fail to adequately assess tool utilization capabilities within this new paradigm. This paper introduces MCP-RADAR, the first comprehensive benchmark specifically designed to evaluate LLM performance in the MCP framework through a novel five-dimensional approach measuring: answer accuracy, tool selection efficiency, computational resource efficiency, parameter construction accuracy, and execution speed. Unlike conventional benchmarks that rely on subjective human evaluations or binary success metrics, MCP-RADAR employs objective, quantifiable measurements across multiple task domains including software engineering, mathematical reasoning, and general problem-solving. Our evaluations of leading commercial and open-source LLMs reveal distinctive capability profiles with significant trade-offs between accuracy, efficiency, and speed, challenging traditional single-metric performance rankings. Besides, we provide valuable guidance for developers to optimize their tools for maximum model compatibility and effectiveness. While focused on MCP due to its standardized approach, our methodology remains applicable across all LLM agent tool integration frameworks, providing valuable insights for both LLM developers and tool creators to optimize the entire LLM-tool interaction ecosystem. The implementation, configurations, and datasets used in our evaluation are publicly available at this https URL.', 'abstract_zh': '大型语言模型（LLMs）从被动文本生成器进化为能够进行工具交互的主动推理代理，模型上下文协议（MCP）作为一种标准化框架，用于动态工具发现和编排，由此而生。尽管MCP在工业界得到了广泛应用，但现有的评估方法无法充分评估这一新范式下的工具利用能力。本文介绍了MCP-RADAR，这是第一个专为评估MCP框架下LLM性能而设计的全面基准，采用新颖的五维度方法测量：答案准确性、工具选择效率、计算资源效率、参数构建准确性和执行速度。不同于依赖主观人类评估或二元成功标准的传统基准，MCP-RADAR在软件工程、数学推理和一般问题解决等多个任务领域采用客观、可量化的评估指标。我们的评估表明，主流商用和开源LLM在准确度、效率和速度之间存在权衡，挑战了传统的单一指标性能排名。此外，我们为开发者提供了优化工具以最大化模型兼容性和有效性的宝贵建议。由于专注于MCP的标准化方法，我们的方法在所有LLM代理工具集成框架中都是适用的，为LLM开发者和工具创建者提供了优化整个LLM-工具交互生态系统的重要见解。我们在评估中使用的实现、配置和数据集可在此网址访问。', 'title_zh': 'MCP-RADAR：评估大型语言模型工具使用能力的多维度基准'}
{'arxiv_id': 'arXiv:2505.16686', 'title': 'SPaRC: A Spatial Pathfinding Reasoning Challenge', 'authors': 'Lars Benedikt Kaesberg, Jan Philip Wahle, Terry Ruas, Bela Gipp', 'link': 'https://arxiv.org/abs/2505.16686', 'abstract': "Existing reasoning datasets saturate and fail to test abstract, multi-step problems, especially pathfinding and complex rule constraint satisfaction. We introduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000 2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning, requiring step-by-step planning with arithmetic and geometric rules. Humans achieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best reasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles). Models often generate invalid paths (>50% of puzzles for o4-mini), and reasoning tokens reveal they make errors in navigation and spatial logic. Unlike humans, who take longer on hard puzzles, models fail to scale test-time compute with difficulty. Allowing models to make multiple solution attempts improves accuracy, suggesting potential for better spatial reasoning with improved training and efficient test-time scaling methods. SPaRC can be used as a window into models' spatial reasoning limitations and drive research toward new methods that excel in abstract, multi-step problem-solving.", 'abstract_zh': 'SPaRC：空间路径推理挑战', 'title_zh': 'SPaRC: 空间路径推理挑战'}
{'arxiv_id': 'arXiv:2505.16667', 'title': 'ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming', 'authors': 'Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei', 'link': 'https://arxiv.org/abs/2505.16667', 'abstract': 'While recent research increasingly emphasizes the value of human-LLM collaboration in competitive programming and proposes numerous empirical methods, a comprehensive understanding remains elusive due to the fragmented nature of existing studies and their use of diverse, application-specific human feedback. Thus, our work serves a three-fold purpose: First, we present the first taxonomy of human feedback consolidating the entire programming process, which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a novel programming dataset specifically designed for human-LLM collaboration, meticulously annotated to enable large-scale simulated human feedback and facilitate costeffective real human interaction studies. Third, we introduce ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM competitive programming. With ELABORATION, we pinpoint strengthes and weaknesses of existing methods, thereby setting the foundation for future improvement. Our code and dataset are available at this https URL', 'abstract_zh': '近年来，越来越多的研究强调人类与大模型合作在竞争编程中的价值，并提出了多种实证方法，但由于现有研究零碎且使用多样化的应用特定的人类反馈，全面理解仍不明晰。因此，我们的工作具有三重目的：首先，我们提出了首个涵盖整个编程过程的人类反馈分类法，促进精细评估。其次，我们引入了ELABORATIONSET，这是一个专门为人类与大模型合作设计的新颖编程数据集，详细标注以支持大规模模拟人类反馈并促进经济高效的真人交互研究。第三，我们引入了ELABORATION，这是一个新颖的基准工具，用于促进竞争编程中的人类与大模型系统的全面评估。通过ELABORATION，我们明确了现有方法的强项和弱点，为未来改进奠定了基础。我们的代码和数据集可在以下网址获取。', 'title_zh': '详述：人类与大语言模型在编程竞赛中的全面基准测试'}
{'arxiv_id': 'arXiv:2505.16646', 'title': "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving", 'authors': 'Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hu Huang', 'link': 'https://arxiv.org/abs/2505.16646', 'abstract': 'Large Language Models have achieved remarkable results on a variety of mathematical benchmarks. However, concerns remain as to whether these successes reflect genuine mathematical reasoning or superficial pattern recognition. Common evaluation metrics, such as final answer accuracy, fail to disentangle the underlying competencies involved, offering limited diagnostic value. To address these limitations, we introduce SMART: a Self-Generating and Self-Validating Multi-Dimensional Assessment Framework. SMART decomposes mathematical problem solving into four distinct dimensions: understanding, reasoning, arithmetic, and reflection \\& refinement. Each dimension is evaluated independently through tailored tasks, enabling interpretable and fine-grained analysis of LLM behavior. Crucially, SMART integrates an automated self-generating and self-validating mechanism to produce and verify benchmark data, ensuring both scalability and reliability. We apply SMART to 21 state-of-the-art open- and closed-source LLMs, uncovering significant discrepancies in their abilities across different dimensions. Our findings demonstrate the inadequacy of final answer accuracy as a sole metric and motivate a new holistic metric to better capture true problem-solving capabilities. Code and benchmarks will be released upon acceptance.', 'abstract_zh': '大型语言模型在多种数学基准测试中取得了显著成果，但对其成功是否真实反映数学推理能力而非表面模式识别存有疑虑。常用的评估指标，如最终答案准确性，无法区分潜在的能力，提供有限的诊断价值。为解决这些局限性，我们引入了SMART：一个自我生成和自我验证的多维度评估框架。SMART将数学问题解决分解为四个独立维度：理解、推理、算术和反思与完善。每个维度通过定制任务独立评估，使LML的行为分析具有可解释性和精细度。最关键的是，SMART整合了自动自我生成和自我验证机制，以生成和验证基准数据，确保了规模性和可靠性。我们将SMART应用于21个最先进的开源和闭源LML，揭示了它们在不同维度上的能力差异。我们的研究结果表明，仅依靠最终答案准确性作为单一指标的不足，并激发了新的综合性指标来更好地捕捉真正的问题解决能力。代码和基准数据将在接收后发布。', 'title_zh': 'SMART: 自生成和自验证多维度评估以检验LLMs的数学问题解决能力'}
{'arxiv_id': 'arXiv:2505.16619', 'title': 'Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences', 'authors': 'Gavin Farrell, Eleni Adamidi, Rafael Andrade Buono, Mihail Anton, Omar Abdelghani Attafi, Salvador Capella Gutierrez, Emidio Capriotti, Leyla Jael Castro, Davide Cirillo, Lisa Crossman, Christophe Dessimoz, Alexandros Dimopoulos, Raul Fernandez-Diaz, Styliani-Christina Fragkouli, Carole Goble, Wei Gu, John M. Hancock, Alireza Khanteymoori, Tom Lenaerts, Fabio G. Liberante, Peter Maccallum, Alexander Miguel Monzon, Magnus Palmblad, Lucy Poveda, Ovidiu Radulescu, Denis C. Shields, Shoaib Sufi, Thanasis Vergoulis, Fotis Psomopoulos, Silvio C.E. Tosatto', 'link': 'https://arxiv.org/abs/2505.16619', 'abstract': 'Artificial intelligence (AI) has recently seen transformative breakthroughs in the life sciences, expanding possibilities for researchers to interpret biological information at an unprecedented capacity, with novel applications and advances being made almost daily. In order to maximise return on the growing investments in AI-based life science research and accelerate this progress, it has become urgent to address the exacerbation of long-standing research challenges arising from the rapid adoption of AI methods. We review the increased erosion of trust in AI research outputs, driven by the issues of poor reusability and reproducibility, and highlight their consequent impact on environmental sustainability. Furthermore, we discuss the fragmented components of the AI ecosystem and lack of guiding pathways to best support Open and Sustainable AI (OSAI) model development. In response, this perspective introduces a practical set of OSAI recommendations directly mapped to over 300 components of the AI ecosystem. Our work connects researchers with relevant AI resources, facilitating the implementation of sustainable, reusable and transparent AI. Built upon life science community consensus and aligned to existing efforts, the outputs of this perspective are designed to aid the future development of policy and structured pathways for guiding AI implementation.', 'abstract_zh': '人工智能（AI）在生命科学领域 recently 见证了转型性的突破，极大地扩展了研究人员以前所未有的能力解释生物信息的可能性，新型应用和进展几乎每天都有所突破。为了最大化对基于AI的生命科学研究日益增加的投资回报并加速这一进程，亟需解决快速采用AI方法带来的长期研究挑战。本文回顾了AI研究输出信任度下降的问题，这些问题主要由可重用性和可再现性差所驱动，并强调了其对环境可持续性的负面影响。此外，还讨论了AI生态系统碎片化的组成部分以及缺乏指导路径来最好地支持开放和可持续AI（OSAI）模型的开发。为此，本文介绍了一套实用的OSAI建议，直接映射到AI生态系统超过300个组成部分。我们的工作将研究人员与相关AI资源连接起来，促进可持续、可重用和透明AI的实施。本文的成果基于生命科学界的共识，并与现有努力保持一致，旨在为指导AI实施提供未来的政策和结构化路径。', 'title_zh': '开放和可持续人工智能：生命科学领域面临的挑战、机遇及前行之路'}
{'arxiv_id': 'arXiv:2505.16579', 'title': 'Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning', 'authors': 'Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang', 'link': 'https://arxiv.org/abs/2505.16579', 'abstract': 'While chains-of-thought (CoT) have advanced complex reasoning in multimodal large language models (MLLMs), existing methods remain confined to text or static visual domains, often faltering in dynamic spatial reasoning tasks. To bridge this gap, we present GRASSLAND, a novel maze navigation benchmark designed to evaluate dynamic spatial reasoning. Our experiments show that augmenting textual reasoning chains with dynamic visual drafts, overlaid on input images, significantly outperforms conventional approaches, offering new insights into spatial reasoning in evolving environments. To generalize this capability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free framework that seamlessly integrates textual CoT with corresponding visual drafts into MLLMs. Extensive evaluations demonstrate that D2R consistently enhances performance across diverse tasks, establishing a robust baseline for dynamic spatial reasoning without requiring model fine-tuning. Project is open at this https URL.', 'abstract_zh': '尽管思维链（CoT）在多模态大型语言模型（MLLMs）中促进了复杂的推理，现有方法仍然局限于文本或静态视觉领域，往往在动态空间推理任务中表现不佳。为了解决这一问题，我们提出了GRASSLAND，一种新型的迷宫导航基准，旨在评估动态空间推理能力。我们的实验表明，在输入图像上叠加动态视觉草图以增强文本推理链可以显著优于传统方法，为在变化环境中进行空间推理提供了新的见解。为了使这一能力得到推广，我们提出了一种无需训练的框架D2R（动态草图增强推理），该框架将文本CoT与相应的视觉草图无缝集成到MLLMs中。广泛的评估表明，D2R在多种任务中一直能提高性能，为动态空间推理提供了一个稳健的基础，而无需对模型进行微调。项目详情请参见：https://this-url..alibabacloud.com。', 'title_zh': '动态感知差距的弥补：无需训练的动态多模态空间推理思维链'}
{'arxiv_id': 'arXiv:2505.16507', 'title': 'Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)', 'authors': 'Anshu Xiong, Songmao Zhang', 'link': 'https://arxiv.org/abs/2505.16507', 'abstract': 'The notion of relevance was proposed for stability of justification status of a single argument in incomplete argumentation frameworks (IAFs) in 2024 by Odekerken et al. To extend the notion, we study the relevance for stability of verification status of a set of arguments in this paper, i.e., the uncertainties in an IAF that have to be resolved in some situations so that answering whether a given set of arguments is an extension obtains the same result in every completion of the IAF. Further we propose the notion of strong relevance for describing the necessity of resolution in all situations reaching stability. An analysis of complexity reveals that detecting the (strong) relevance for stability of sets of arguments can be accomplished in P time under the most semantics discussed in the paper. We also discuss the difficulty in finding tractable methods for relevance detection under grounded semantics.', 'abstract_zh': '不完备论证框架中单个论证稳定性的相关性概念于2024年由Odekerken等提出，本文研究了相关性在不完备论证框架中一组论证的验证稳定性中的应用，即在某些情况下需要解决的不确定性，以确保在IAF的每个完成中，判断给定一组论证是否为扩展的结果一致。进一步提出了强相关性的概念，以描述在所有情况下解决必要性以达到稳定性。复杂性分析表明，在论文讨论的大多数语义下，检测一组论证稳定性的（强）相关性可以在多项式时间内完成。我们还讨论了在接地语义下找到可解决性检测方法的难度。', 'title_zh': '不完满论辩框架中论证集验证状态的相关性与稳定性（附证明）'}
{'arxiv_id': 'arXiv:2505.16482', 'title': 'Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes', 'authors': 'Huynh Thi Thanh Binh, Le Van Cuong, Dang Hai Dang, Le Trong Vinh', 'link': 'https://arxiv.org/abs/2505.16482', 'abstract': 'Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the advantage of wireless energy transfer technology have opened a promising opportunity in solving the limited energy issue. However, an ineffective charging strategy may reduce the charging performance. Although many practical charging algorithms have been introduced, these studies mainly focus on optimizing the charging path with a fully charging approach. This approach may lead to the death of a series of sensors due to their extended charging latency. This paper introduces a novel partial charging approach that follows a bi-level optimized scheme to minimize energy depletion in WRSNs. We aim at optimizing simultaneously two factors: the charging path and time. To accomplish this, we first formulate a mathematical model of the investigated problem. We then propose two approximate algorithms in which the optimization of the charging path and the charging time are considered as the upper and lower level, respectively. The first algorithm combines a Multi-start Local Search method and a Genetic Algorithm to find a solution. The second algorithm adopts a nested approach that utilizes the advantages of the Multitasking and Covariance Matrix Adaptation Evolutionary Strategies. Experimental validations on various network scenarios demonstrate that our proposed algorithms outperform the existing works.', 'abstract_zh': 'recently, 利用水无线能量传输技术的无线可充电传感器网络 (WRSNs) 已为解决能量限制问题开辟了前景。然而，无效的充电策略可能降低充电性能。尽管已经引入了许多实际的充电算法，这些研究主要集中在使用全充满策略优化充电路径上。这种策略可能导致由于延长的充电延迟而导致一系列传感器的失效。本文介绍了一种新颖的部分充电方法，该方法遵循双层优化方案以最小化 WRSNs 中的能量耗尽。我们旨在同时优化两个因素：充电路径和时间。为此，我们首先制定了所研究问题的数学模型。然后，我们提出两种近似算法，其中充电路径的优化被视为高层，充电时间的优化被视为低层。第一个算法结合了多启动局部搜索方法和遗传算法来寻找解决方案。第二个算法采用嵌套方法，利用多任务和共变异矩阵适应进化策略的优势。在各种网络场景下的实验验证表明，我们提出的算法优于现有工作。', 'title_zh': '使用双层元启发式充电方案最小化无线可充电传感器网络的能量耗尽'}
{'arxiv_id': 'arXiv:2505.16477', 'title': 'Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery', 'authors': 'Yanbo Zhang, Sumeer A. Khan, Adnan Mahmud, Huck Yang, Alexander Lavin, Michael Levin, Jeremy Frey, Jared Dunnmon, James Evans, Alan Bundy, Saso Dzeroski, Jesper Tegner, Hector Zenil', 'link': 'https://arxiv.org/abs/2505.16477', 'abstract': "With recent Nobel Prizes recognising AI contributions to science, Large Language Models (LLMs) are transforming scientific research by enhancing productivity and reshaping the scientific method. LLMs are now involved in experimental design, data analysis, and workflows, particularly in chemistry and biology. However, challenges such as hallucinations and reliability persist. In this contribution, we review how Large Language Models (LLMs) are redefining the scientific method and explore their potential applications across different stages of the scientific cycle, from hypothesis testing to discovery. We conclude that, for LLMs to serve as relevant and effective creative engines and productivity enhancers, their deep integration into all steps of the scientific process should be pursued in collaboration and alignment with human scientific goals, with clear evaluation metrics. The transition to AI-driven science raises ethical questions about creativity, oversight, and responsibility. With careful guidance, LLMs could evolve into creative engines, driving transformative breakthroughs across scientific disciplines responsibly and effectively. However, the scientific community must also decide how much it leaves to LLMs to drive science, even when associations with 'reasoning', mostly currently undeserved, are made in exchange for the potential to explore hypothesis and solution regions that might otherwise remain unexplored by human exploration alone.", 'abstract_zh': '近年来，诺贝尔奖认可了AI对科学的贡献，大型语言模型（LLMs）正在通过提升生产力和重塑科学方法来革新科学研究。LLMs现已被应用于实验设计、数据分析和工作流程中，特别是在化学和生物学领域。然而，幻觉和可靠性等问题仍然存在。本文回顾了大型语言模型如何重新定义科学方法，并探讨了它们在科学周期各个阶段的潜在应用。我们得出结论，为了使LLMs成为相关且有效的创造力引擎和生产力提升工具，需要在与人类科学目标合作和准确定位的背景下深入整合到科学研究的所有步骤中，并采用明确的评估指标。向AI驱动的科学研究过渡引发了关于创造力、监管和责任的伦理问题。在谨慎引导下，LLMs可以演变为创造力引擎，负责任且有效推动跨学科的变革性突破。然而，科学社区还必须决定在赋权LLMs驱动科学时保留多大程度的自主权，即使会因为所谓的“推理”与人类独自探索可能未被发现的假说和解决方案区域相比而产生潜在的关联。', 'title_zh': '运用大型语言模型推动科学研究方法：从假设到发现'}
{'arxiv_id': 'arXiv:2505.16475', 'title': 'ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection', 'authors': 'Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng', 'link': 'https://arxiv.org/abs/2505.16475', 'abstract': "We present a novel pipeline, ReflectEvo, to demonstrate that small language models (SLMs) can enhance meta introspection through reflection learning. This process iteratively generates self-reflection for self-training, fostering a continuous and self-evolving process. Leveraging this pipeline, we construct ReflectEvo-460k, a large-scale, comprehensive, self-generated reflection dataset with broadened instructions and diverse multi-domain tasks. Building upon this dataset, we demonstrate the effectiveness of reflection learning to improve SLMs' reasoning abilities using SFT and DPO with remarkable performance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral from 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the reasoning capability of the three prominent open-sourced models on BIG-bench without distillation from superior models or fine-grained human annotation. We further conduct a deeper analysis of the high quality of self-generated reflections and their impact on error localization and correction. Our work highlights the potential of continuously enhancing the reasoning performance of SLMs through iterative reflection learning in the long run.", 'abstract_zh': '我们提出了一种新颖的工作流程ReflectEvo，以展示小型语言模型(SLMs)可以通过反思学习增强元反省的能力。该过程通过迭代生成自我反省以促进自我训练，进而形成一个持续的、自我演化的过程。利用这一工作流程，我们构建了ReflectEvo-460k，这是一个大规模、全面、自我生成的反思数据集，包含了广泛的任务指令和多种领域任务。基于此数据集，我们利用SFT和DPO展示了反思学习在提高SLMs推理能力方面的有效性，显著提升了Llama-3从52.4%到71.2%，Mistral从44.4%到71.1%。这验证了ReflectEvo在无需来自更优秀的模型蒸馏或细粒度的人工注释的情况下，能够与三大开源模型在BIG-bench上的推理能力相媲美甚至超越。我们进一步分析了自我生成反思的高质量及其对错误定位和修正的影响。我们的工作突显了长期通过迭代反思学习持续提升SLMs推理性能的潜力。', 'title_zh': 'ReflectEvo: 改进小规模LLM元内省能力的学习自我反思方法'}
{'arxiv_id': 'arXiv:2505.16459', 'title': 'MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks', 'authors': 'Guiyao Tie, Xueyang Zhou, Tianhe Gu, Ruihang Zhang, Chaoran Hu, Sizhe Zhang, Mengqu Sun, Yan Zhang, Pan Zhou, Lichao Sun', 'link': 'https://arxiv.org/abs/2505.16459', 'abstract': 'Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled unified processing of language, vision, and structured inputs, opening the door to complex tasks such as logical deduction, spatial reasoning, and scientific analysis. Despite their promise, the reasoning capabilities of MLLMs, particularly those augmented with intermediate thinking traces (MLLMs-T), remain poorly understood and lack standardized evaluation benchmarks. Existing work focuses primarily on perception or final answer correctness, offering limited insight into how models reason or fail across modalities. To address this gap, we introduce the MMMR, a new benchmark designed to rigorously evaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a high-difficulty dataset of 1,083 questions spanning six diverse reasoning types with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy through metrics like relevance, consistency, and structured error annotations. Empirical results show that MLLMs-T overall outperform non-thinking counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro suffer from reasoning pathologies such as inconsistency and overthinking. This benchmark reveals persistent gaps between accuracy and reasoning quality and provides an actionable evaluation pipeline for future model development. Overall, the MMMR offers a scalable foundation for evaluating, comparing, and improving the next generation of multi-modal reasoning systems.', 'abstract_zh': 'Recent advances in 多模态大型语言模型 (MLLMs) 使统一处理语言、视觉和结构化输入成为可能，开启了逻辑推理、空间推理和科学分析等复杂任务的大门。尽管前景广阔，但特别是配备了中间推理痕迹 (MLLMs-T) 的 MLLMs 的推理能力仍缺乏理解，缺少标准化评估基准。现有工作主要集中在感知或最终答案的正确性上，这为了解模型在不同模态下的推理或失败提供有限的见解。为了解决这一差距，我们引入了 MMMR，一种新的基准，旨在通过明确的思考进行多模态推理的严格评估。MMMR 包括 1) 一个高难度数据集，包含 1,083 个跨六个不同推理类型的复杂问题，具有符号深度和多跳需求，以及 2) 一种模块化的推理痕迹评估流水线 (RTEP)，通过相关性、连贯性和结构化错误注释等指标来评估推理质量，而不仅仅是准确性。实验结果表明，MLLMs-T 整体上优于非思考模型，但即使是顶级模型如 Claude-3.7-Sonnet 和 Gemini-2.5 Pro 也存在推理路径障碍，如连贯性差和过度推理。该基准揭示了准确性与推理质量之间的持续差距，并为未来模型开发提供了一套可操作的评估流水线。总体而言，MMMR 为评估、比较和改进下一代多模态推理系统提供了可扩展的基础。', 'title_zh': 'MMMR：大规模多模态推理任务benchmarking'}
{'arxiv_id': 'arXiv:2505.16455', 'title': 'Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events', 'authors': 'Mengzhu Liu, Zhengqiu Zhu, Chuan Ai, Chen Gao, Xinghong Li, Lingnan He, Kaisheng Lai, Yingfeng Chen, Xin Lu, Yong Li, Quanjun Yin', 'link': 'https://arxiv.org/abs/2505.16455', 'abstract': 'During sudden disaster events, accurately predicting public panic sentiment on social media is crucial for proactive governance and crisis management. Current efforts on this problem face three main challenges: lack of finely annotated data hinders emotion prediction studies, unmodeled risk perception causes prediction inaccuracies, and insufficient interpretability of panic formation mechanisms. We address these issues by proposing a Psychology-driven generative Agent framework (PsychoAgent) for explainable panic prediction based on emotion arousal theory. Specifically, we first construct a fine-grained open panic emotion dataset (namely COPE) via human-large language models (LLMs) collaboration to mitigate semantic bias. Then, we develop a framework integrating cross-domain heterogeneous data grounded in psychological mechanisms to model risk perception and cognitive differences in emotion generation. To enhance interpretability, we design an LLM-based role-playing agent that simulates individual psychological chains through dedicatedly designed prompts. Experimental results on our annotated dataset show that PsychoAgent improves panic emotion prediction performance by 12.6% to 21.7% compared to baseline models. Furthermore, the explainability and generalization of our approach is validated. Crucially, this represents a paradigm shift from opaque "data-driven fitting" to transparent "role-based simulation with mechanistic interpretation" for panic emotion prediction during emergencies. Our implementation is publicly available at: this https URL.', 'abstract_zh': '突发灾难事件中基于情感唤醒理论的心理驱动生成代理框架（PsychoAgent）：解释性恐慌情绪预测', 'title_zh': '基于心理学驱动的大语言模型代理在突发灾难事件中社交媒体上可解释的恐慌预测'}
{'arxiv_id': 'arXiv:2505.16448', 'title': 'Internal Bias in Reasoning Models leads to Overthinking', 'authors': 'Renfei Dang, Shujian Huang, Jiajun Chen', 'link': 'https://arxiv.org/abs/2505.16448', 'abstract': "While current reasoning models possess strong exploratory capabilities, they are often criticized for overthinking due to redundant and unnecessary reflections. In this work, we reveal for the first time that overthinking in reasoning models may stem from their internal bias towards input texts. Upon encountering a reasoning problem, the model immediately forms a preliminary guess about the answer, which we term as an internal bias since it is not derived through actual reasoning. When this guess conflicts with its reasoning result, the model tends to engage in reflection, leading to the waste of computational resources. Through further interpretability experiments, we find that this behavior is largely driven by the model's excessive attention to the input section, which amplifies the influence of internal bias on its decision-making process. Additionally, by masking out the original input section, the affect of internal bias can be effectively alleviated and the reasoning length could be reduced by 31%-53% across different complex reasoning tasks. Notably, in most cases, this approach also leads to improvements in accuracy. These findings demonstrate a causal relationship between internal bias and overthinking.", 'abstract_zh': '当前推理模型虽然具备较强的探索能力，但常常因为冗余和不必要的反思而受到过度思考的批评。在本文中，我们首次揭示，推理模型的过度思考可能源于其对输入文本的内在偏向。面对推理问题时，模型会立即形成关于答案的初步猜测，这被称为内在偏见，因为它并非通过实际推理得出。当这一猜测与推理结果发生冲突时，模型会倾向于进行反思，从而浪费计算资源。通过进一步的解释性实验，我们发现，这种行为很大程度上是由模型对输入部分的过度关注驱动的，这放大了内在偏见对其决策过程的影响。此外，通过屏蔽原始输入部分，可以有效地减轻内在偏见的影响，并在不同复杂的推理任务中将推理长度减少31%-53%。值得注意的是，在大多数情况下，这种方法还能够提高准确性。这些发现表明内在偏见与过度思考之间存在因果关系。', 'title_zh': '内在偏见在推理模型中导致过度思考'}
{'arxiv_id': 'arXiv:2505.16409', 'title': 'FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS', 'authors': 'Chaeeun Kim, Seungone Kim', 'link': 'https://arxiv.org/abs/2505.16409', 'abstract': "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in multi-step reasoning and calling search engines at appropriate steps. However, existing retrieval-augmented reasoning approaches rely on separate retrieval models, limiting the LRM's role in retrieval to deciding when to retrieve and how to query. This separation not only increases hardware and operational costs but also leads to errors in the retrieval process due to the representation bottleneck, a phenomenon where the retriever's embedding space is not expressive enough to meet the generator's requirements. To address this, we shift our perspective from sequence-to-sequence matching to locating the answer-containing paths within the corpus, and propose a novel framework called FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables LRMs to retrieve relevant knowledge on their own by acting as both a generator and retriever. To achieve this, we introduce a variant of the MCTS algorithm specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus toward answer-containing regions. Our results on five open-domain QA benchmarks, including single-hop and multi-hop questions, show that FREESON achieves an average improvement of 14.4% in EM and F1 over four multi-step reasoning models with a separate retriever, and it also performs comparably to the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.", 'abstract_zh': 'Large Reasoning Models (LRMs)在多步推理和适时调用搜索引擎方面展现了显著的能力。然而，现有的检索增强推理方法依赖于独立的检索模型，限制了LRM在检索方面的角色，仅限于决定何时检索及如何查询。这种分离不仅增加了硬件和运营成本，还由于检索瓶颈（即检索器的嵌入空间不足以满足生成器的要求）导致了检索过程中的错误。为了应对这一问题，我们将视角从序列到序列匹配转向在语料库中定位包含答案的路径，并提出了一种名为FREESON（Retriever-FREE Retrieval-Augmented ReaSONing）的新框架。该框架使LRMs能够通过自身充当生成器和检索器的角色来自主检索相关知识。为此，我们引入了一种专为检索任务设计的MCTS算法变体，称之为CT-MCTS（Corpus-Traversing Monte Carlo Tree Search）。在该算法中，LRMs在语料库中朝向包含答案的区域进行遍历。在五个开放领域问答基准测试上的结果，包括单跳和多跳问题，表明FREESON在EM和F1指标上分别比四种带有独立检索器的多步推理模型平均提高了14.4%，并且在PopQA和2WikiMultihopQA基准上分别超越最强基线3%和2%。', 'title_zh': 'FREESON: 不依赖检索的基于语料遍历的MCTS增强推理'}
{'arxiv_id': 'arXiv:2505.16388', 'title': 'Serious Games: Human-AI Interaction, Evolution, and Coevolution', 'authors': 'Nandini Doreswamy, Louise Horstmanshof', 'link': 'https://arxiv.org/abs/2505.16388', 'abstract': "The serious games between humans and AI have only just begun. Evolutionary Game Theory (EGT) models the competitive and cooperative strategies of biological entities. EGT could help predict the potential evolutionary equilibrium of humans and AI. The objective of this work was to examine some of the EGT models relevant to human-AI interaction, evolution, and coevolution. Of thirteen EGT models considered, three were examined: the Hawk-Dove Game, Iterated Prisoner's Dilemma, and the War of Attrition. This selection was based on the widespread acceptance and clear relevance of these models to potential human-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove Game predicts balanced mixed-strategy equilibria based on the costs of conflict. It also shows the potential for balanced coevolution rather than dominance. Iterated Prisoner's Dilemma suggests that repeated interaction may lead to cognitive coevolution. It demonstrates how memory and reciprocity can lead to cooperation. The War of Attrition suggests that competition for resources may result in strategic coevolution, asymmetric equilibria, and conventions on sharing resources. Therefore, EGT may provide a suitable framework to understand and predict the human-AI evolutionary dynamic. However, future research could extend beyond EGT and explore additional frameworks, empirical validation methods, and interdisciplinary perspectives. AI is being shaped by human input and is evolving in response to it. So too, neuroplasticity allows the human brain to grow and evolve in response to stimuli. If humans and AI converge in future, what might be the result of human neuroplasticity combined with an ever-evolving AI? Future research should be mindful of the ethical and cognitive implications of human-AI interaction, evolution, and coevolution.", 'abstract_zh': '人类与AI之间的严肃游戏刚刚开始：进化博弈理论在人类-AI交互、进化及其共进化中的应用及其前景', 'title_zh': '严肃游戏：人机交互、进化与共生进化'}
{'arxiv_id': 'arXiv:2505.16315', 'title': 'Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning', 'authors': 'Xiaoxue Cheng, Junyi Li, Zhenduo Zhang, Xinyu Tang, Wayne Xin Zhao, Xinyu Kong, Zhiqiang Zhang', 'link': 'https://arxiv.org/abs/2505.16315', 'abstract': "Large reasoning models (LRMs) have demonstrated strong performance on complex reasoning tasks, but often suffer from overthinking, generating redundant content regardless of task difficulty. Inspired by the dual process theory in cognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a reinforcement learning framework that enables LRMs to achieve efficient reasoning through adaptive cognitive allocation and dynamic system switch. ACPO incorporates two key components: (1) introducing system-aware reasoning tokens to explicitly represent the thinking modes thereby making the model's cognitive process transparent, and (2) integrating online difficulty estimation and token length budget to guide adaptive system switch and reasoning during reinforcement learning. To this end, we propose a two-stage training strategy. The first stage begins with supervised fine-tuning to cold start the model, enabling it to generate reasoning paths with explicit thinking modes. In the second stage, we apply ACPO to further enhance adaptive system switch for difficulty-aware reasoning. Experimental results demonstrate that ACPO effectively reduces redundant reasoning while adaptively adjusting cognitive allocation based on task complexity, achieving efficient hybrid reasoning.", 'abstract_zh': '基于认知策略优化的大型推理模型高效推理方法（Adaptive Cognition Policy Optimization for Efficient Reasoning in Large Reasoning Models）', 'title_zh': '激励双重过程思考以实现高效大型语言模型推理'}
{'arxiv_id': 'arXiv:2505.16312', 'title': 'EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning', 'authors': 'Jiawei Liu, Qisi Chen, Jianshu Zhang, Quan Liu, Defu Lian', 'link': 'https://arxiv.org/abs/2505.16312', 'abstract': 'Large Language Models (LLMs) excel at complex reasoning through search algorithms, yet current strategies often suffer from massive token consumption due to redundant exploration of semantically equivalent steps. Existing semantic similarity methods struggle to accurately identify such equivalence in domain-specific contexts like mathematical reasoning. To address this, we propose EquivPruner, a simple yet effective approach that identifies and prunes semantically equivalent actions during LLM reasoning search. We also introduce MathEquiv, the first dataset we created for mathematical statement equivalence, which enables the training of a lightweight equivalence detector. Extensive experiments across various models and tasks demonstrate that EquivPruner significantly reduces token consumption, improving searching efficiency and often bolstering reasoning accuracy. For instance, when applied to Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by 48.1\\% while also improving accuracy. Our code is available at this https URL.', 'abstract_zh': '大规模语言模型通过搜索算法在复杂推理方面表现出色，但由于在语义等价步骤上的冗余探索，当前策略往往会消耗大量令牌。现有的语义相似性方法在处理数学推理等特定领域语境中的等价性识别时表现不佳。为解决这一问题，我们提出了一种名为EquivPruner的简单而有效的方法，在LLM推理搜索过程中识别并修剪语义等价的操作。同时，我们引入了MathEquiv数据集，这是首个用于数学命题等价性的数据集，使轻量级等价性检测器的训练成为可能。在各种模型和任务上的广泛实验表明，EquivPruner能显著降低令牌消耗，提高搜索效率，并且常常增强推理准确性。例如，在应用于Qwen2.5-Math-7B-Instruct和GSM8K任务时，EquivPruner将令牌消耗减少了48.1%，同时提高了一定的准确率。代码已开源。', 'title_zh': 'EquivPruner: 通过动作剪枝提升基于LLM的搜索的效率和质量'}
{'arxiv_id': 'arXiv:2505.16288', 'title': 'No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery', 'authors': 'Xiaoxue Han, Pengfei Hu, Jun-En Ding, Chang Lu, Feng Liu, Yue Ning', 'link': 'https://arxiv.org/abs/2505.16288', 'abstract': "Deep learning models trained on extensive Electronic Health Records (EHR) data have achieved high accuracy in diagnosis prediction, offering the potential to assist clinicians in decision-making and treatment planning. However, these models lack two crucial features that clinicians highly value: interpretability and interactivity. The ``black-box'' nature of these models makes it difficult for clinicians to understand the reasoning behind predictions, limiting their ability to make informed decisions. Additionally, the absence of interactive mechanisms prevents clinicians from incorporating their own knowledge and experience into the decision-making process. To address these limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal discovery framework that integrates personalized knowledge databases and agentic LLMs. II-KEA enhances interpretability through explicit reasoning and causal analysis, while also improving interactivity by allowing clinicians to inject their knowledge and experience through customized knowledge bases and prompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating superior performance along with enhanced interpretability and interactivity, as evidenced by its strong results from extensive case studies.", 'abstract_zh': '基于扩展电子健康记录数据训练的深度学习模型在诊断预测中取得了高精度，有望辅助临床决策和治疗规划。然而，这些模型缺乏临床医生高度重视的两个关键特性：可解释性和交互性。“黑盒”性质使得临床医生难以理解预测背后的推理过程，限制了他们做出知情决策的能力。此外，缺乏交互机制也阻止了临床医生将其知识和经验融入决策过程。为解决这些限制，我们提出了II-KEA，一种增强的知识驱动因果发现框架，结合了个性化知识数据库和自主代理大语言模型。II-KEA 通过显式推理和因果分析提升可解释性，同时通过定制的知识库和提示增强交互性，允许临床医生注入其知识和经验。II-KEA 在 MIMIC-III 和 MIMIC-IV 上进行了评估，展示了卓越的表现，以及通过广泛案例研究证明的增强的可解释性和交互性。', 'title_zh': '无黑箱：基于知识增强代理因果发现的可解释可交互预测医疗'}
{'arxiv_id': 'arXiv:2505.16276', 'title': 'How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance', 'authors': 'Desiree Heim, Lars-Peter Meyer, Markus Schröder, Johannes Frey, Andreas Dengel', 'link': 'https://arxiv.org/abs/2505.16276', 'abstract': 'When using Large Language Models (LLMs) to support Knowledge Graph Engineering (KGE), one of the first indications when searching for an appropriate model is its size. According to the scaling laws, larger models typically show higher capabilities. However, in practice, resource costs are also an important factor and thus it makes sense to consider the ratio between model performance and costs. The LLM-KG-Bench framework enables the comparison of LLMs in the context of KGE tasks and assesses their capabilities of understanding and producing KGs and KG queries. Based on a dataset created in an LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the model size scaling laws specific to KGE tasks. In our analyses, we assess how benchmark scores evolve between different model size categories. Additionally, we inspect how the general score development of single models and families of models correlates to their size. Our analyses revealed that, with a few exceptions, the model size scaling laws generally also apply to the selected KGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e., the task performance did not change much between a model and the next larger model. In these cases, smaller models could be considered to achieve high cost-effectiveness. Regarding models of the same family, sometimes larger models performed worse than smaller models of the same family. These effects occurred only locally. Hence it is advisable to additionally test the next smallest and largest model of the same family.', 'abstract_zh': '使用大型语言模型（LLMs）支持知识图谱工程（KGE）时的模型大小 Scaling Laws 特异性研究：基于 LLM-KG-Bench 架构的分析', 'title_zh': '扩展律在知识图谱工程任务中的应用：模型规模对大型语言模型性能的影响'}
{'arxiv_id': 'arXiv:2505.16225', 'title': 'MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning', 'authors': 'Zihan Chen, Song Wang, Zhen Tan, Jundong Li, Cong Shen', 'link': 'https://arxiv.org/abs/2505.16225', 'abstract': 'In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle diverse tasks by incorporating multiple input-output examples, known as demonstrations, into the input of LLMs. More recently, advancements in the expanded context windows of LLMs have led to many-shot ICL, which uses hundreds of demonstrations and outperforms few-shot ICL, which relies on fewer examples. However, this approach is often hindered by the high cost of obtaining large amounts of labeled data. To address this challenge, we propose Many-Shot Adaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL framework that utilizes pseudo-labeled samples to compensate for the lack of label information. We first identify a subset of impactful unlabeled samples and perform pseudo-labeling on them by querying LLMs. These pseudo-labeled samples are then adaptively selected and tailored to each test query as input to improve the performance of many-shot ICL, without significant labeling costs. Extensive experiments on real-world datasets demonstrate the effectiveness of our framework, showcasing its ability to enhance LLM adaptability and performance with limited labeled data.', 'abstract_zh': '基于影响分析的Many-Shot自适应伪标注学习', 'title_zh': 'MAPLE: 多-shot自适应伪标签化在上下文学习中的应用'}
{'arxiv_id': 'arXiv:2505.16223', 'title': 'MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network', 'authors': 'Sangyong Lee, Subo Hwang, Dohoon Kim', 'link': 'https://arxiv.org/abs/2505.16223', 'abstract': "In this paper, we propose MADCluster, a novel model-agnostic anomaly detection framework utilizing self-supervised clustering. MADCluster is applicable to various deep learning architectures and addresses the 'hypersphere collapse' problem inherent in existing deep learning-based anomaly detection methods. The core idea is to cluster normal pattern data into a 'single cluster' while simultaneously learning the cluster center and mapping data close to this center. Also, to improve expressiveness and enable effective single clustering, we propose a new 'One-directed Adaptive loss'. The optimization of this loss is mathematically proven. MADCluster consists of three main components: Base Embedder capturing high-dimensional temporal dynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous center updates. Its model-agnostic characteristics are achieved by applying various architectures to the Base Embedder. Experiments on four time series benchmark datasets demonstrate that applying MADCluster improves the overall performance of comparative models. In conclusion, the compatibility of MADCluster shows potential for enhancing model performance across various architectures.", 'abstract_zh': 'MADCluster：一种利用自监督聚类的新型模型无关异常检测框架', 'title_zh': 'MADCluster：模型无关的异常检测自监督聚类网络'}
{'arxiv_id': 'arXiv:2505.16221', 'title': 'LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead', 'authors': 'Yifan Zhang, Xinkui Zhao, Zuxin Wang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin', 'link': 'https://arxiv.org/abs/2505.16221', 'abstract': 'The rapid advancement of large language models has unlocked remarkable capabilities across a diverse array of natural language processing tasks. However, the considerable differences among available LLMs-in terms of cost, performance, and computational demands-pose significant challenges for users aiming to identify the most suitable model for specific tasks. In this work, we present LightRouter, a novel framework designed to systematically select and integrate a small subset of LLMs from a larger pool, with the objective of jointly optimizing both task performance and cost efficiency. LightRouter leverages an adaptive selection mechanism to identify models that require only a minimal number of boot tokens, thereby reducing costs, and further employs an effective integration strategy to combine their outputs. Extensive experiments across multiple benchmarks demonstrate that LightRouter matches or outperforms widely-used ensemble baselines, achieving up to a 25% improvement in accuracy. Compared with leading high-performing models, LightRouter achieves comparable performance while reducing inference costs by up to 27%. Importantly, our framework operates without any prior knowledge of individual models and relies exclusively on inexpensive, lightweight models. This work introduces a practical approach for efficient LLM selection and provides valuable insights into optimal strategies for model combination.', 'abstract_zh': '大型语言模型的迅速发展解锁了多样自然语言处理任务的非凡能力。然而，可用的大规模语言模型在成本、性能和计算需求方面的显著差异为用户选择最适合特定任务的模型带来了重大挑战。本文介绍了LightRouter，一种新型框架，旨在系统地从大量候选模型中选择和整合一个小型子集，以同时优化任务性能和成本效率。LightRouter利用自适应选择机制来识别仅需少量启动标记的模型，从而降低成本，并进一步采用有效整合策略结合它们的输出。多基准实验表明，LightRouter与广泛使用的集成基线相当或优于基线，最高可提升25%的准确性。与顶级高性能模型相比，LightRouter在降低成本高达27%的同时实现了相当的性能。重要的是，我们的框架无需任何关于个体模型的先验知识，仅依赖于经济且轻量级的模型。本文引入了一种高效的大型语言模型选择实践方法，并提供了关于模型组合的优化策略的宝贵见解。', 'title_zh': 'LightRouter: 向量效LLM协作 minimal overhead'}
{'arxiv_id': 'arXiv:2505.16199', 'title': 'Velocity Completion Task and Method for Event-based Player Positional Data in Soccer', 'authors': 'Rikuhei Umemoto, Keisuke Fujii', 'link': 'https://arxiv.org/abs/2505.16199', 'abstract': "In many real-world complex systems, the behavior can be observed as a collection of discrete events generated by multiple interacting agents. Analyzing the dynamics of these multi-agent systems, especially team sports, often relies on understanding the movement and interactions of individual agents. However, while providing valuable snapshots, event-based positional data typically lacks the continuous temporal information needed to directly calculate crucial properties such as velocity. This absence severely limits the depth of dynamic analysis, preventing a comprehensive understanding of individual agent behaviors and emergent team strategies. To address this challenge, we propose a new method to simultaneously complete the velocity of all agents using only the event-based positional data from team sports. Based on this completed velocity information, we investigate the applicability of existing team sports analysis and evaluation methods. Experiments using soccer event data demonstrate that neural network-based approaches outperformed rule-based methods regarding velocity completion error, considering the underlying temporal dependencies and graph structure of player-to-player or player-to-ball interaction. Moreover, the space evaluation results obtained using the completed velocity are closer to those derived from complete tracking data, highlighting our method's potential for enhanced team sports system analysis.", 'abstract_zh': '在许多现实世界的复杂系统中，行为可以观察到是由多个相互作用的代理生成的离散事件组成的集合。分析这些多代理系统的动力学，尤其是在研究团队运动时，通常依赖于理解单个代理的运动和相互作用。然而，虽然事件定位数据提供了有价值的快照，但它们通常缺乏直接计算关键属性（如速度）所需的连续时间信息。这种缺失严重限制了动力学分析的深度，阻碍了对单个代理行为和涌现团队策略的全面理解。为了解决这一挑战，我们提出了一个新的方法，仅使用团队运动的事件定位数据来同时完成所有代理的速度。基于这种完成的速度信息，我们探讨了现有团队运动分析和评估方法的应用性。使用足球事件数据的实验证明，基于神经网络的方法在速度填充误差方面优于基于规则的方法，考虑到球员之间或球员与球之间相互作用的潜在时间依赖性和图结构。此外，使用完成的速度进行的空间评估结果与基于完全追踪数据得出的结果更为接近，突显了我们方法在增强团队运动系统分析方面的潜力。', 'title_zh': '基于事件的足球运动员位置数据的速率完成任务与方法'}
{'arxiv_id': 'arXiv:2505.16186', 'title': 'SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning', 'authors': 'Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang', 'link': 'https://arxiv.org/abs/2505.16186', 'abstract': "Large Reasoning Models (LRMs) introduce a new generation paradigm of explicitly reasoning before answering, leading to remarkable improvements in complex tasks. However, they pose great safety risks against harmful queries and adversarial attacks. While recent mainstream safety efforts on LRMs, supervised fine-tuning (SFT), improve safety performance, we find that SFT-aligned models struggle to generalize to unseen jailbreak prompts. After thorough investigation of LRMs' generation, we identify a safety aha moment that can activate safety reasoning and lead to a safe response. This aha moment typically appears in the `key sentence', which follows models' query understanding process and can indicate whether the model will proceed safely. Based on these insights, we propose SafeKey, including two complementary objectives to better activate the safety aha moment in the key sentence: (1) a Dual-Path Safety Head to enhance the safety signal in the model's internal representations before the key sentence, and (2) a Query-Mask Modeling objective to improve the models' attention on its query understanding, which has important safety hints. Experiments across multiple safety benchmarks demonstrate that our methods significantly improve safety generalization to a wide range of jailbreak attacks and out-of-distribution harmful prompts, lowering the average harmfulness rate by 9.6\\%, while maintaining general abilities. Our analysis reveals how SafeKey enhances safety by reshaping internal attention and improving the quality of hidden representations.", 'abstract_zh': '大型推理模型中的安全关键时刻：SafeKey', 'title_zh': 'SafeKey: 增强安全推理中的恍然大悟洞察'}
{'arxiv_id': 'arXiv:2505.16176', 'title': 'Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning', 'authors': 'Jun Rao, Xuebo Liu, Hexuan Deng, Zepeng Lin, Zixiong Yu, Jiansheng Wei, Xiaojun Meng, Min Zhang', 'link': 'https://arxiv.org/abs/2505.16176', 'abstract': "In the realm of data selection for reasoning tasks, existing approaches predominantly rely on externally predefined static metrics such as difficulty and diversity, which are often designed for supervised fine-tuning (SFT) and lack adaptability to continuous training processes. A critical limitation of these methods is their inability to dynamically align with the evolving capabilities of models during online training, a gap that becomes increasingly pronounced with the rise of dynamic training paradigms and online reinforcement learning (RL) frameworks (e.g., R1 models). To address this, we introduce SAI-DPO, an algorithm that dynamically selects training data by continuously assessing a model's stage-specific reasoning abilities across different training phases. By integrating real-time model performance feedback, SAI-DPO adaptively adapts data selection to the evolving strengths and weaknesses of the model, thus enhancing both data utilization efficiency and final task performance. Extensive experiments on three state-of-the-art models and eight mathematical reasoning benchmarks, including challenging competition-level datasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average performance boost of up to 21.3 percentage points, with particularly notable improvements of 10 and 15 points on AIME24 and AMC23, respectively. These results highlight the superiority of dynamic, model-adaptive data selection over static, externally defined strategies in advancing reasoning.", 'abstract_zh': '基于推理任务的数据选择：动态适应性数据选择算法(SAI-DPO)', 'title_zh': '自适应动态采样：迭代DPO在自我意识数学推理中的应用'}
{'arxiv_id': 'arXiv:2505.16147', 'title': 'Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value', 'authors': 'Le Ma, Shirao Yang, Zihao Wang, Yinggui Wang, Lei Wang, Tao Wei, Kejun Zhang', 'link': 'https://arxiv.org/abs/2505.16147', 'abstract': 'The proliferation of large models has intensified the need for efficient data valuation methods to quantify the contribution of individual data providers. Traditional approaches, such as game-theory-based Shapley value and influence-function-based techniques, face prohibitive computational costs or require access to full data and model training details, making them hardly achieve partial data valuation. To address this, we propose Unlearning Shapley, a novel framework that leverages machine unlearning to estimate data values efficiently. By unlearning target data from a pretrained model and measuring performance shifts on a reachable test set, our method computes Shapley values via Monte Carlo sampling, avoiding retraining and eliminating dependence on full data. Crucially, Unlearning Shapley supports both full and partial data valuation, making it scalable for large models (e.g., LLMs) and practical for data markets. Experiments on benchmark datasets and large-scale text corpora demonstrate that our approach matches the accuracy of state-of-the-art methods while reducing computational overhead by orders of magnitude. Further analysis confirms a strong correlation between estimated values and the true impact of data subsets, validating its reliability in real-world scenarios. This work bridges the gap between data valuation theory and practical deployment, offering a scalable, privacy-compliant solution for modern AI ecosystems.', 'abstract_zh': '大型模型的普及加剧了对高效数据估值方法的需求，以量化个体数据提供者的贡献。传统的基于博弈论的Shapley值方法和基于影响函数的技术面临难以承受的计算成本，或需要访问完整数据和模型训练细节，使它们难以实现部分数据估值。为解决这一问题，我们提出了一种新的框架——Unlearning Shapley，该框架利用机器遗忘高效估计数据价值。通过从预训练模型中遗忘目标数据，并在可达测试集上测量性能变化，我们的方法利用蒙特卡洛采样计算Shapley值，避免重新训练并消除对完整数据的依赖。重要的是，Unlearning Shapley 支持完整和部分数据估值，使其在大规模模型（如语言模型）中具有可扩展性，并在数据市场中具有实用性。在基准数据集和大规模文本语料库上的实验表明，我们的方法在计算开销上比最先进的方法减少了几个数量级，同时保持了准确性。进一步的分析证实了估计值与数据子集真实影响之间的强相关性，验证了其在实际场景中的可靠性。这项工作填补了数据估值理论与实际部署之间的差距，提供了针对现代人工智能生态系统的可扩展且隐私合规的解决方案。', 'title_zh': '失去是为了珍惜：基于机器遗忘和夏皮利值的数据估值'}
{'arxiv_id': 'arXiv:2505.16135', 'title': 'Sudoku-Bench: Evaluating creative reasoning with Sudoku variants', 'authors': 'Jeffrey Seely, Yuki Imajuku, Tianyu Zhao, Edoardo Cetin, Llion Jones', 'link': 'https://arxiv.org/abs/2505.16135', 'abstract': "Existing reasoning benchmarks for large language models (LLMs) frequently fail to capture authentic creativity, often rewarding memorization of previously observed patterns. We address this shortcoming with Sudoku-Bench, a curated benchmark of challenging and unconventional Sudoku variants specifically selected to evaluate creative, multi-step logical reasoning. Sudoku variants form an unusually effective domain for reasoning research: each puzzle introduces unique or subtly interacting constraints, making memorization infeasible and requiring solvers to identify novel logical breakthroughs (``break-ins''). Despite their diversity, Sudoku variants maintain a common and compact structure, enabling clear and consistent evaluation. Sudoku-Bench includes a carefully chosen puzzle set, a standardized text-based puzzle representation, and flexible tools compatible with thousands of publicly available puzzles -- making it easy to extend into a general research environment. Baseline experiments show that state-of-the-art LLMs solve fewer than 15\\% of puzzles unaided, highlighting significant opportunities to advance long-horizon, strategic reasoning capabilities.", 'abstract_zh': '现有的大型语言模型推理基准经常无法捕捉到真实的创造力， often rewarding memorization of previously observed patterns. 我们通过Sudoku-Bench解决了这一不足，这是一个精选的基准，包含了具有挑战性和非传统性的数独变体，特别选择用于评估创造性、多步逻辑推理能力。尽管数独变体多样，但它们维持着一种共同且紧凑的结构，使得推理研究具有清晰和一致的评估标准。Sudoku-Bench包含仔细选择的谜题集、标准化的文字表示形式的谜题以及与数千个公开可用的谜题兼容的灵活工具，使其易于扩展为通用研究环境。基准实验显示，最先进的大型语言模型在无辅助的情况下仅能解决不到15%的谜题，强调了在长时规划和战略推理能力方面有巨大的研究潜力。', 'title_zh': 'Sudoku-Bench: 评估变体数独中的创造性推理能力'}
{'arxiv_id': 'arXiv:2505.16120', 'title': 'LLM-Powered AI Agent Systems and Their Applications in Industry', 'authors': 'Guannan Liang, Qianqian Tong', 'link': 'https://arxiv.org/abs/2505.16120', 'abstract': 'The emergence of Large Language Models (LLMs) has reshaped agent systems. Unlike traditional rule-based agents with limited task scope, LLM-powered agents offer greater flexibility, cross-domain reasoning, and natural language interaction. Moreover, with the integration of multi-modal LLMs, current agent systems are highly capable of processing diverse data modalities, including text, images, audio, and structured tabular data, enabling richer and more adaptive real-world behavior. This paper comprehensively examines the evolution of agent systems from the pre-LLM era to current LLM-powered architectures. We categorize agent systems into software-based, physical, and adaptive hybrid systems, highlighting applications across customer service, software development, manufacturing automation, personalized education, financial trading, and healthcare. We further discuss the primary challenges posed by LLM-powered agents, including high inference latency, output uncertainty, lack of evaluation metrics, and security vulnerabilities, and propose potential solutions to mitigate these concerns.', 'abstract_zh': '大型语言模型（LLMs）的出现重塑了代理系统。不同于传统基于规则的代理系统，LLM驱动的代理系统提供了更大的灵活性、跨域推理和自然语言交互。此外，通过集成多模态LLM，当前的代理系统能够高效处理包括文本、图像、音频和结构化表格数据在内的多种数据模态，从而实现更加丰富和适应性强的现实世界行为。本文全面考察了从预LLM时代到当前LLM驱动架构代理系统的演化。我们将代理系统分为软件基座式、物理式和适应性混合系统，并强调了其在客户服务、软件开发、制造业自动化、个性化教育、金融交易和医疗保健等领域的应用。我们进一步讨论了LLM驱动代理系统所面临的 primary challenges，包括高推理延迟、输出不确定性、缺乏评价指标以及安全漏洞，并提出了可能的解决方案以减轻这些担忧。', 'title_zh': 'LLM驱动的AI代理系统及其在工业领域的应用'}
{'arxiv_id': 'arXiv:2505.16114', 'title': 'Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language', 'authors': 'Naiqi Li, Peiyuan Liu, Zheng Liu, Tao Dai, Yong Jiang, Shu-Tao Xia', 'link': 'https://arxiv.org/abs/2505.16114', 'abstract': 'Solving puzzles in natural language poses a long-standing challenge in AI. While large language models (LLMs) have recently shown impressive capabilities in a variety of tasks, they continue to struggle with complex puzzles that demand precise reasoning and exhaustive search. In this paper, we propose Logic-of-Thought (Logot), a novel framework that bridges LLMs with logic programming to address this problem. Our method leverages LLMs to translate puzzle rules and states into answer set programs (ASPs), the solution of which are then accurately and efficiently inferred by an ASP interpreter. This hybrid approach combines the natural language understanding of LLMs with the precise reasoning capabilities of logic programs. We evaluate our method on various grid puzzles and dynamic puzzles involving actions, demonstrating near-perfect accuracy across all tasks. Our code and data are available at: this https URL.', 'abstract_zh': '自然语言求解谜题是AI领域的长期挑战。尽管大规模语言模型（LLMs）最近在各种任务中展现了令人印象深刻的性能，它们在需要精确推理和全面搜索的复杂谜题中仍然表现不佳。在本文中，我们提出了一种新的框架——Logic-of-Thought (Logot)，将LLMs与逻辑编程相结合，以解决这一问题。我们的方法利用LLMs将谜题规则和状态转换为回答集程序（ASP），ASP解析器随后准确高效地推断出解。这种混合方法结合了LLMs的自然语言理解和逻辑程序的精确推理能力。我们在各种网格谜题和涉及动作的动态谜题上评估了该方法，展示了在所有任务中几乎完美的准确性。我们的代码和数据可在以下链接获取：this https URL。', 'title_zh': '逻辑思维：通过逻辑程序增强大型语言模型以解决自然语言中的谜题'}
{'arxiv_id': 'arXiv:2505.16100', 'title': 'BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research', 'authors': 'Zifeng Wang, Benjamin Danek, Jimeng Sun', 'link': 'https://arxiv.org/abs/2505.16100', 'abstract': "Validating scientific hypotheses is a central challenge in biomedical research, and remains difficult for artificial intelligence (AI) agents due to the complexity of real-world data analysis and evidence interpretation. In this work, we present BioDSA-1K, a benchmark designed to evaluate AI agents on realistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K consists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans, curated from over 300 published biomedical studies to reflect the structure and reasoning found in authentic research workflows. Each task includes a structured hypothesis derived from the original study's conclusions, expressed in the affirmative to reflect the language of scientific reporting, and one or more pieces of supporting evidence grounded in empirical data tables. While these hypotheses mirror published claims, they remain testable using standard statistical or machine learning methods. The benchmark enables evaluation along four axes: (1) hypothesis decision accuracy, (2) alignment between evidence and conclusion, (3) correctness of the reasoning process, and (4) executability of the AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable hypotheses: cases where the available data are insufficient to support or refute a claim, reflecting a common yet underexplored scenario in real-world science. We propose BioDSA-1K as a foundation for building and evaluating generalizable, trustworthy AI agents for biomedical discovery.", 'abstract_zh': 'BioDSA-1K：一种用于评估生物医学假设验证任务的人工智能代理基准', 'title_zh': 'BioDSA-1K: 评估生物医学研究中的数据科学代理'}
{'arxiv_id': 'arXiv:2505.16097', 'title': 'TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials', 'authors': 'Zifeng Wang, Qiao Jin, Jiacheng Lin, Junyi Gao, Jathurshan Pradeepkumar, Pengcheng Jiang, Benjamin Danek, Zhiyong Lu, Jimeng Sun', 'link': 'https://arxiv.org/abs/2505.16097', 'abstract': 'Developing artificial intelligence (AI) for vertical domains requires a solid data foundation for both training and evaluation. In this work, we introduce TrialPanorama, a large-scale, structured database comprising 1,657,476 clinical trial records aggregated from 15 global sources. The database captures key aspects of trial design and execution, including trial setups, interventions, conditions, biomarkers, and outcomes, and links them to standard biomedical ontologies such as DrugBank and MedDRA. This structured and ontology-grounded design enables TrialPanorama to serve as a unified, extensible resource for a wide range of clinical trial tasks, including trial planning, design, and summarization. To demonstrate its utility, we derive a suite of benchmark tasks directly from the TrialPanorama database. The benchmark spans eight tasks across two categories: three for systematic review (study search, study screening, and evidence summarization) and five for trial design (arm design, eligibility criteria, endpoint selection, sample size estimation, and trial completion assessment). The experiments using five state-of-the-art large language models (LLMs) show that while general-purpose LLMs exhibit some zero-shot capability, their performance is still inadequate for high-stakes clinical trial workflows. We release TrialPanorama database and the benchmark to facilitate further research on AI for clinical trials.', 'abstract_zh': '垂直领域开发人工智能（AI）需要坚实的数据基础用于训练和评估。本文介绍了TrialPanorama，一个包含1,657,476个临床试验记录的大规模结构化数据库，这些记录来自15个全球来源。该数据库捕捉到临床试验设计和执行的关键方面，包括试验设置、干预措施、条件、生物标志物和结果，并将其链接到标准生物医学本体，如DrugBank和MedDRA。该结构化和基于本体的设计使TrialPanorama能够作为多种临床试验任务的一体化、可扩展资源，包括试验规划、设计和总结。为了展示其 usefulness，我们从TrialPanorama数据库直接推导出一系列基准任务。这些基准任务覆盖八个任务，分为两类：三类是系统评价任务（研究搜索、研究筛选和证据总结），五类是试验设计任务（组设计、入组标准、终点选择、样本量估算和试验完成评估）。使用五种最先进的大规模语言模型（LLMs）的实验表明，虽然通用的大规模语言模型具有一定的零样本能力，但它们的表现仍然不足以应对高风险的临床试验工作流程。我们发布了TrialPanorama数据库和基准任务，以促进临床试验中人工智能研究的进一步发展。', 'title_zh': 'TrialPanorama: 临床试验系统评价与设计的数据库及基准测试'}
{'arxiv_id': 'arXiv:2505.16090', 'title': 'Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance', 'authors': 'Dominick Kubica, Dylan T. Gordon, Nanami Emura, Derleen Saini, Charlie Goldenberg', 'link': 'https://arxiv.org/abs/2505.16090', 'abstract': "As of 2025, Generative Artificial Intelligence (GenAI) has become a central tool for productivity across industries. Beyond text generation, GenAI now plays a critical role in coding, data analysis, and research workflows. As large language models (LLMs) continue to evolve, it is essential to assess the reliability and accuracy of their outputs, especially in specialized, high-stakes domains like finance. Most modern LLMs transform text into numerical vectors, which are used in operations such as cosine similarity searches to generate responses. However, this abstraction process can lead to misinterpretation of emotional tone, particularly in nuanced financial contexts. While LLMs generally excel at identifying sentiment in everyday language, these models often struggle with the nuanced, strategically ambiguous language found in earnings call transcripts. Financial disclosures frequently embed sentiment in hedged statements, forward-looking language, and industry-specific jargon, making it difficult even for human analysts to interpret consistently, let alone AI models. This paper presents findings from the Santa Clara Microsoft Practicum Project, led by Professor Charlie Goldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's ChatGPT, Google's Gemini, and traditional machine learning models for sentiment analysis of financial text. Using Microsoft earnings call transcripts, the analysis assesses how well LLM-derived sentiment correlates with market sentiment and stock movements and evaluates the accuracy of model outputs. Prompt engineering techniques are also examined to improve sentiment analysis results. Visualizations of sentiment consistency are developed to evaluate alignment between tone and stock performance, with sentiment trends analyzed across Microsoft's lines of business to determine which segments exert the greatest influence.", 'abstract_zh': '截至2025年，生成式人工智能（GenAI）已成为各行各业提高生产力的核心工具。除了文本生成，GenAI在编程、数据分析和研究工作流程中也扮演着至关重要的角色。随着大型语言模型（LLMs）的不断演变，评估其输出的可靠性和准确性变得尤为重要，尤其是在金融等专业且高风险的领域。大多数现代LLM将文本转换为数值向量，用于如余弦相似度搜索等操作生成响应。然而，这一抽象过程可能导致情绪色调的误读，尤其是在细腻的金融语境中。虽然LLMs在识别普通语言中的情感方面表现良好，但在分析收益电话会议记录中发现的细微、战略性含糊语言时，这些模型往往会遇到困难。财务披露经常嵌入了谨慎陈述、前瞻性语言和行业特定术语的情感，这使得即使是人类分析师也难以一致地进行解释，更不用说AI模型了。本文基于Santa Clara微软实践项目的研究成果，该项目由Charlie Goldenberg教授领导，旨在评估微软Copilot、OpenAI的ChatGPT、Google的Gemini以及传统机器学习模型在金融文本情感分析方面的表现。通过分析微软收益电话会议记录，该研究评估LLM衍生情感与市场情绪和股票变动的相关性，并评估模型输出的准确性。还研究了促进情感分析结果的方法工程技术。开发了情感一致性可视化来评估语气与股票表现之间的对齐情况，并分析了微软各业务线的情感趋势，以确定哪些细分市场的影响最大。', 'title_zh': 'AI能读透文字背后的意思吗？LLMs在金融细微差异方面的基准测试'}
{'arxiv_id': 'arXiv:2505.16086', 'title': 'Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development', 'authors': 'Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang', 'link': 'https://arxiv.org/abs/2505.16086', 'abstract': 'We have seen remarkable progress in large language models (LLMs) empowered multi-agent systems solving complex tasks necessitating cooperation among experts with diverse skills. However, optimizing LLM-based multi-agent systems remains challenging. In this work, we perform an empirical case study on group optimization of role-based multi-agent systems utilizing natural language feedback for challenging software development tasks under various evaluation dimensions. We propose a two-step agent prompts optimization pipeline: identifying underperforming agents with their failure explanations utilizing textual feedback and then optimizing system prompts of identified agents utilizing failure explanations. We then study the impact of various optimization settings on system performance with two comparison groups: online against offline optimization and individual against group optimization. For group optimization, we study two prompting strategies: one-pass and multi-pass prompting optimizations. Overall, we demonstrate the effectiveness of our optimization method for role-based multi-agent systems tackling software development tasks evaluated on diverse evaluation dimensions, and we investigate the impact of diverse optimization settings on group behaviors of the multi-agent systems to provide practical insights for future development.', 'abstract_zh': '我们已经在大型语言模型（LLMs）赋能的多智能体系统解决需要专家之间协作的复杂任务方面看到了显著进步。然而，优化基于LLM的多智能体系统仍然是一个挑战。本研究通过对角色_based多智能体系统进行自然语言反馈驱动的小组优化的实证案例研究，探讨了在多种评价维度下挑战性软件开发任务中的系统性能影响。我们提出了一种两阶段智能体提示优化管道：利用文本反馈识别表现不佳的智能体及其失败解释，然后利用失败解释优化被识别智能体的系统提示。我们研究了不同优化设置对系统性能的影响，设置了两个比较组：在线优化与离线优化，以及个体优化与小组优化。在小组优化方面，我们研究了两种提示策略：单轮和多轮提示优化。总体而言，我们展示了该优化方法在面对多种评价维度下的软件开发任务挑战性任务的角色_based多智能体系统中的有效性，并探讨了不同优化设置对多智能体系统小组行为的影响，以提供对未来开发的实用见解。', 'title_zh': '基于文本反馈优化LLM驱动的多智能体系统：软件开发案例研究'}
{'arxiv_id': 'arXiv:2505.16080', 'title': 'SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation', 'authors': 'Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang', 'link': 'https://arxiv.org/abs/2505.16080', 'abstract': 'Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.', 'abstract_zh': '探究时空系统中的规律可以惠及各个科学和社会规划领域。当前的时空学习器通常是从特定源数据中训练独立模型，这导致了来源间有限的迁移性，即使相关任务也需要新的设计和训练。通过增强跨域知识，关键在于促进集体智能和模型进化。受神经科学理论启发，本文从理论上推导出通过学习跨域集体智能来增加信息边界，并提出了一种Synaptic Evolutionary时空网络（SynEVO），SynEVO打破了模型独立性，使跨域知识能够共享和聚合。具体来说，我们首先重新排列样本组以模仿人类的课程学习，并设计了两个互补的 learner：弹性通用容器和任务独立提取器，以允许模型增长和任务内共同性与个性的解耦。然后，一个自适应动态耦合器结合新的差异度量确定新的样本组是否应被整合到通用容器中，以实现不同领域下的模型进化。实验表明，在跨域场景下，SynEVO最多可提高42%的泛化能力，并为知识转移和适应提供了神经人工智能范式。', 'title_zh': 'SynEVO: 一种神经启发的空间时间演化跨域适应框架'}
{'arxiv_id': 'arXiv:2505.16067', 'title': 'How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior', 'authors': 'Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang', 'link': 'https://arxiv.org/abs/2505.16067', 'abstract': "Memory is a critical component in large language model (LLM)-based agents, enabling them to store and retrieve past executions to improve task performance over time. In this paper, we conduct an empirical study on how memory management choices impact the LLM agents' behavior, especially their long-term performance. Specifically, we focus on two fundamental memory operations that are widely used by many agent frameworks-addition, which incorporates new experiences into the memory base, and deletion, which selectively removes past experiences-to systematically study their impact on the agent behavior. Through our quantitative analysis, we find that LLM agents display an experience-following property: high similarity between a task input and the input in a retrieved memory record often results in highly similar agent outputs. Our analysis further reveals two significant challenges associated with this property: error propagation, where inaccuracies in past experiences compound and degrade future performance, and misaligned experience replay, where outdated or irrelevant experiences negatively influence current tasks. Through controlled experiments, we show that combining selective addition and deletion strategies can help mitigate these negative effects, yielding an average absolute performance gain of 10% compared to naive memory growth. Furthermore, we highlight how memory management choices affect agents' behavior under challenging conditions such as task distribution shifts and constrained memory resources. Our findings offer insights into the behavioral dynamics of LLM agent memory systems and provide practical guidance for designing memory components that support robust, long-term agent performance. We also release our code to facilitate further study.", 'abstract_zh': '基于大型语言模型的代理的记忆管理研究：行为影响与挑战', 'title_zh': 'LSTM记忆管理对语言模型代理的影响：一种经验跟随行为的实证研究'}
{'arxiv_id': 'arXiv:2505.16048', 'title': 'SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution', 'authors': 'Philipp D. Siedler', 'link': 'https://arxiv.org/abs/2505.16048', 'abstract': 'We introduce a novel dataset designed to benchmark the physical and spatial reasoning capabilities of Large Language Models (LLM) based on topology optimization, a method for computing optimal material distributions within a design space under prescribed loads and supports. In this dataset, LLMs are provided with conditions such as 2D boundary, applied forces and supports, and must reason about the resulting optimal material distribution. The dataset includes a variety of tasks, ranging from filling in masked regions within partial structures to predicting complete material distributions. Solving these tasks requires understanding the flow of forces and the required material distribution under given constraints, without access to simulation tools or explicit physical models, challenging models to reason about structural stability and spatial organization. Our dataset targets the evaluation of spatial and physical reasoning abilities in 2D settings, offering a complementary perspective to traditional language and logic benchmarks.', 'abstract_zh': '我们引入了一个新型的数据集，用于评估基于拓扑优化的大规模语言模型（LLM）的物理和空间推理能力。该数据集提供给LLM二维边界、施加的力和支撑条件，并要求其推断在这些条件下最优的材料分布。数据集包括从填充部分结构中的空白区域到预测完整材料分布的各种任务。解决这些任务需要理解在给定约束条件下力的传递和所需的材料分布，挑战模型进行结构稳定性和空间组织的推理。我们的数据集旨在评估2D设置中的空间和物理推理能力，为传统语言和逻辑基准测试提供补充视角。', 'title_zh': 'SPhyR：材料分布的空间物理推理基准'}
{'arxiv_id': 'arXiv:2505.16037', 'title': 'Causal LLM Routing: End-to-End Regret Minimization from Observational Data', 'authors': 'Asterios Tsiourvas, Wei Sun, Georgia Perakis', 'link': 'https://arxiv.org/abs/2505.16037', 'abstract': 'LLM routing aims to select the most appropriate model for each query, balancing competing performance metrics such as accuracy and cost across a pool of language models. Prior approaches typically adopt a decoupled strategy, where the metrics are first predicted and the model is then selected based on these estimates. This setup is prone to compounding errors and often relies on full-feedback data, where each query is evaluated by all candidate models, which is costly to obtain and maintain in practice. In contrast, we learn from observational data, which records only the outcome of the model actually deployed. We propose a causal end-to-end framework that learns routing policies by minimizing decision-making regret from observational data. To enable efficient optimization, we introduce two theoretically grounded surrogate objectives: a classification-based upper bound, and a softmax-weighted regret approximation shown to recover the optimal policy at convergence. We further extend our framework to handle heterogeneous cost preferences via an interval-conditioned architecture. Experiments on public benchmarks show that our method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.', 'abstract_zh': 'LLM路由旨在为每个查询选择最合适的模型，平衡准确度和成本等竞争性能指标。先前的方法通常采用解耦策略，先预测指标，再基于这些估计来选择模型。这种设置容易累积错误，并且通常依赖于全反馈数据，即每个查询都被所有候选模型评估，这在实践中成本高昂且难以维持。相比之下，我们从观测数据中学习，只记录实际部署的模型的结果。我们提出了一种因果端到端框架，通过从观测数据中最小化决策遗憾来学习路由策略。为了实现高效的优化，我们引入了两个理论依据的替代目标：基于分类的上界和softmax加权遗憾近似，在收敛时可恢复最优策略。我们进一步扩展了框架以处理不同的成本偏好，通过区间条件化架构来实现。实验表明，我们的方法在公共基准测试中优于现有基线，实现了不同嵌入模型下的最佳性能。', 'title_zh': '因果LLM路由：基于观测数据的端到端后悔最小化'}
{'arxiv_id': 'arXiv:2505.16031', 'title': "Children's Mental Models of AI Reasoning: Implications for AI Literacy Education", 'authors': 'Aayushi Dangol, Robert Wolfe, Runhua Zhao, JaeWon Kim, Trushaa Ramanan, Katie Davis, Julie A. Kientz', 'link': 'https://arxiv.org/abs/2505.16031', 'abstract': 'As artificial intelligence (AI) advances in reasoning capabilities, most recently with the emergence of Large Reasoning Models (LRMs), understanding how children conceptualize AI\'s reasoning processes becomes critical for fostering AI literacy. While one of the "Five Big Ideas" in AI education highlights reasoning algorithms as central to AI decision-making, less is known about children\'s mental models in this area. Through a two-phase approach, consisting of a co-design session with 8 children followed by a field study with 106 children (grades 3-8), we identified three models of AI reasoning: Deductive, Inductive, and Inherent. Our findings reveal that younger children (grades 3-5) often attribute AI\'s reasoning to inherent intelligence, while older children (grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions that surfaced in children\'s understanding of AI reasoning and conclude with implications for scaffolding AI curricula and designing explainable AI tools.', 'abstract_zh': '随着人工智能（AI）在推理能力上的进步，尤其是在大型推理模型（LRMs）的出现之后，理解儿童如何概念化AI的推理过程对于培养AI素养变得至关重要。尽管AI教育中的“五大核心理念”之一强调推理算法是AI决策的核心，但关于这一领域的儿童心理模型知之甚少。通过两阶段的方法，包括与8名儿童合作设计会话，随后对106名儿童（3-8年级）进行实地研究，我们确定了三种AI推理模型：演绎、归纳和固有。研究发现显示，较低年级的儿童（3-5年级）常将AI的推理归因于固有的智能，而较高年级的儿童（6-8年级）则认识到AI是一个模式识别器。我们强调了在儿童对AI推理理解中浮现的三个紧张关系，并提出构建AI课程和支持可解释AI工具的建议。', 'title_zh': '儿童对AI推理的认知模型：对AI literacy教育的启示'}
{'arxiv_id': 'arXiv:2505.15998', 'title': 'Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics', 'authors': 'Thomas Michel, Marko Cvjetko, Gautier Hamon, Pierre-Yves Oudeyer, Clément Moulin-Frier', 'link': 'https://arxiv.org/abs/2505.15998', 'abstract': 'We present a method for the automated discovery of system-level dynamics in Flow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and parameter localization$-$using a curiosity-driven AI scientist. This method aims to uncover processes leading to self-organization of evolutionary and ecosystemic dynamics in CAs. We build on previous work which uses diversity search algorithms in Lenia to find self-organized individual patterns, and extend it to large environments that support distinct interacting patterns. We adapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive exploration of diverse Flow-Lenia environments using simulation-wide metrics, such as evolutionary activity, compression-based complexity, and multi-scale entropy. We test our method in two experiments, showcasing its ability to illuminate significantly more diverse dynamics compared to random search. We show qualitative results illustrating how ecosystemic simulations enable self-organization of complex collective behaviors not captured by previous individual pattern search and analysis. We complement automated discovery with an interactive exploration tool, creating an effective human-AI collaborative workflow for scientific investigation. Though demonstrated specifically with Flow-Lenia, this methodology provides a framework potentially applicable to other parameterizable complex systems where understanding emergent collective properties is of interest.', 'abstract_zh': '我们提出了一种使用好奇心驱动的AI科学家在Flow-Lenia中自动发现系统级动力学的方法——一种具有质量守恒和参数局部化的连续细胞自动机。该方法旨在揭示在细胞自动机中导致演化和生态系统动力学自我组织的过程。我们在此前使用Lenia中的多样性搜索算法寻找自我组织的个体模式的基础上，将其扩展到支持不同相互作用模式的大型环境。我们采用固有动机目标探索过程（IMGEPs）利用全局仿真指标（如演化活性、基于压缩的复杂性、多尺度熵）驱动Flow-Lenia环境的探索。我们在两个实验中测试了该方法，展示了其相较于随机搜索能够揭示更多样化的动力学的能力。我们提供了定性结果，说明生态系统的模拟如何使复杂的集体行为自我组织，这些行为在以往的个体模式搜索和分析中并未被捕捉到。我们结合自动发现提供了一种交互式探索工具，创建了一个高效的人工智能协作工作流以进行科学研究。尽管在Flow-Lenia中具体演示了这种方法，但该方法论框架有可能适用于其他参数可调的复杂系统，其中理解涌现的集体性质是有趣的。', 'title_zh': '基于好奇心驱动的AI科学家探索Flow-Lenia宇宙：发现多样的生态系统动态'}
{'arxiv_id': 'arXiv:2505.15929', 'title': 'PhyX: Does Your Model Have the "Wits" for Physical Reasoning?', 'authors': 'Hui Shen, Taiqiang Wu, Qi Han, Yunta Hsieh, Jizhou Wang, Yuyue Zhang, Yuxin Cheng, Zijian Hao, Yuansheng Ni, Xin Wang, Zhongwei Wan, Kai Zhang, Wendong Xu, Jing Xiong, Ping Luo, Wenhu Chen, Chaofan Tao, Zhuoqing Mao, Ngai Wong', 'link': 'https://arxiv.org/abs/2505.15929', 'abstract': 'Existing benchmarks fail to capture a crucial aspect of intelligence: physical reasoning, the integrated ability to combine domain knowledge, symbolic reasoning, and understanding of real-world constraints. To address this gap, we introduce PhyX: the first large-scale benchmark designed to assess models capacity for physics-grounded reasoning in visual scenarios. PhyX includes 3K meticulously curated multimodal questions spanning 6 reasoning types across 25 sub-domains and 6 core physics domains: thermodynamics, electromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In our comprehensive evaluation, even state-of-the-art models struggle significantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and GPT-o4-mini achieve only 32.5\\%, 42.2\\%, and 45.8\\% accuracy respectively-performance gaps exceeding 29\\% compared to human experts. Our analysis exposes critical limitations in current models: over-reliance on memorized disciplinary knowledge, excessive dependence on mathematical formulations, and surface-level visual pattern matching rather than genuine physical understanding. We provide in-depth analysis through fine-grained statistics, detailed case studies, and multiple evaluation paradigms to thoroughly examine physical reasoning capabilities. To ensure reproducibility, we implement a compatible evaluation protocol based on widely-used toolkits such as VLMEvalKit, enabling one-click evaluation.', 'abstract_zh': '现有的基准未能捕捉到智能的一个关键方面：物理推理，即结合领域知识、符号推理和对现实世界约束理解的综合能力。为填补这一空白，我们引入了PhyX：首个大型基准，旨在评估模型在视觉场景中进行物理基础推理的能力。PhyX 包含3000个精心挑选的多模态问题，覆盖6种推理类型，涉及25个子领域和6个核心物理领域：热力学、电磁学、力学、现代物理、光学和波与声学。在我们全面的评估中，即使是最先进的模型也显著挣扎于物理推理。GPT-4o、Claude3.7-Sonnet和GPT-o4-mini分别达到了32.5%、42.2%和45.8%的准确率，与人类专家的差距超过29%。我们的分析揭示了当前模型的关键局限性：过度依赖记忆学科知识、过度依赖数学公式以及表层视觉模式匹配而非真正的物理理解。我们通过精细的统计分析、详细的案例研究和多种评估范式进行了深入分析，以彻底检验物理推理能力。为了确保可重现性，我们基于广泛使用的工具包（如VLMEvalKit）实现了兼容的评估协议，实现一键评估。', 'title_zh': 'PhyX: 你的模型具备“智慧”进行物理推理了吗？'}
{'arxiv_id': 'arXiv:2505.15862', 'title': 'Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems', 'authors': 'Long Wanga, Jiongzhi Zheng, Zhengda Xiong, ChuMin Li, Kun He', 'link': 'https://arxiv.org/abs/2505.15862', 'abstract': "Algorithms designed for routing problems typically rely on high-quality candidate edges to guide their search, aiming to reduce the search space and enhance the search efficiency. However, many existing algorithms, like the classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman Problem (TSP), often use predetermined candidate edges that remain static throughout local searches. This rigidity could cause the algorithm to get trapped in local optima, limiting its potential to find better solutions. To address this issue, we propose expanding the candidate sets to include other promising edges, providing them an opportunity for selection. Specifically, we incorporate multi-armed bandit models to dynamically select the most suitable candidate edges in each iteration, enabling LKH to make smarter choices and lead to improved solutions. Extensive experiments on multiple TSP benchmarks show the excellent performance of our method. Moreover, we employ this bandit-based method to LKH-3, an extension of LKH tailored for solving various TSP variant problems, and our method also significantly enhances LKH-3's performance across typical TSP variants.", 'abstract_zh': '设计用于路由问题的算法通常依赖高质量的候选边来引导搜索，旨在减少搜索空间并提高搜索效率。然而，许多现有的算法，如经典的Lin-Kernighan-Helsgaucu (LKH)算法用于旅行商问题(TSP)，往往使用固定的候选边，在局部搜索过程中保持不变。这种刚性可能导致算法陷入局部最优，限制其找到更好解的潜力。为解决这一问题，我们提出扩大候选集，包括其他有潜力的边，给它们选择的机会。具体而言，我们引入多臂老虎机模型，在每一轮迭代中动态选择最合适的候选边，使LKH能够做出更明智的选择并产生更好的解。在多种TSP基准测试上的广泛实验显示了我们方法的优秀性能。此外，我们将基于多臂老虎机的方法应用于LKH-3，这是专门为解决各种TSP变体问题而扩展的LKH版本，我们的方法也在典型的TSP变体中显著提升了LKH-3的性能。', 'title_zh': '基于拉臂算法的动态候选边选择在解决旅行商问题中的应用'}
{'arxiv_id': 'arXiv:2505.17022', 'title': 'GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning', 'authors': 'Chengqi Duan, Rongyao Fang, Yuqing Wang, Kun Wang, Linjiang Huang, Xingyu Zeng, Hongsheng Li, Xihui Liu', 'link': 'https://arxiv.org/abs/2505.17022', 'abstract': 'Visual generation models have made remarkable progress in creating realistic images from text prompts, yet struggle with complex prompts that specify multiple objects with precise spatial relationships and attributes. Effective handling of such prompts requires explicit reasoning about the semantic content and spatial layout. We present GoT-R1, a framework that applies reinforcement learning to enhance semantic-spatial reasoning in visual generation. Building upon the Generation Chain-of-Thought approach, GoT-R1 enables models to autonomously discover effective reasoning strategies beyond predefined templates through carefully designed reinforcement learning. To achieve this, we propose a dual-stage multi-dimensional reward framework that leverages MLLMs to evaluate both the reasoning process and final output, enabling effective supervision across the entire generation pipeline. The reward system assesses semantic alignment, spatial accuracy, and visual quality in a unified approach. Experimental results demonstrate significant improvements on T2I-CompBench benchmark, particularly in compositional tasks involving precise spatial relationships and attribute binding. GoT-R1 advances the state-of-the-art in image generation by successfully transferring sophisticated reasoning capabilities to the visual generation domain. To facilitate future research, we make our code and pretrained models publicly available at this https URL.', 'abstract_zh': '视觉生成模型在从文本提示生成真实图像方面取得了显著进展，但在处理需精确指定多个物体及其空间关系和属性的复杂提示时仍然存在挑战。有效处理此类提示需要明确进行语义内容和空间布局的推理。我们提出了一种名为GoT-R1的框架，该框架采用强化学习来增强视觉生成中的语义-空间推理。基于生成链式思考方法，GoT-R1使模型能够在精心设计的强化学习指导下自主发现超越预定义模板的有效推理策略。为此，我们提出了一种双阶段多维奖励框架，利用MLLMs评估推理过程和最终输出，实现了整个生成管道的有效监督。奖励系统采用统一方法评估语义对齐、空间准确性和视觉质量。实验结果表明，GoT-R1在T2I-CompBench基准上取得了显著改进，特别是在涉及精确空间关系和属性绑定的组合任务中。GoT-R1通过成功将复杂的推理能力转移到视觉生成领域，推动了图像生成技术的发展。为了促进未来的研究，我们已在以下链接公开了我们的代码和预训练模型：此 https URL。', 'title_zh': 'GoT-R1: 解锁大语言模型在强化学习驱动的视觉生成中的推理能力'}
{'arxiv_id': 'arXiv:2505.17019', 'title': 'Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework', 'authors': 'Chenhao Zhang, Yazhe Niu', 'link': 'https://arxiv.org/abs/2505.17019', 'abstract': 'Metaphorical comprehension in images remains a critical challenge for AI systems, as existing models struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. While multimodal large language models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they struggle with a fundamental limitation on image implication tasks: contextual gaps that obscure the relationships between different visual elements and their abstract meanings. Inspired by the human cognitive process, we propose Let Androids Dream (LAD), a novel framework for image implication understanding and reasoning. LAD addresses contextual missing through the three-stage framework: (1) Perception: converting visual information into rich and multi-level textual representations, (2) Search: iteratively searching and integrating cross-domain knowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment image implication via explicit reasoning. Our framework with the lightweight GPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English image implication benchmark and a huge improvement on Chinese benchmark, performing comparable with the GPT-4o model on Multiple-Choice Question (MCQ) and outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work provides new insights into how AI can more effectively interpret image implications, advancing the field of vision-language reasoning and human-AI interaction. Our project is publicly available at this https URL.', 'abstract_zh': '图像中隐含意义的理解仍然是AI系统的关键挑战，现有模型难以捕捉视觉内容中复杂的文化、情感和上下文隐含意义。虽然多模态大规模语言模型（MLLMs）在基本视觉问答（VQA）任务中表现出色，但在图像隐含意义任务中面临根本性局限：上下文缺失导致不同视觉元素及其抽象意义之间的关系模糊不清。受人类认知过程的启发，我们提出了一种新颖的图像隐含意义理解和推理框架Let Androids Dream（LAD）。LAD通过三阶段框架解决上下文缺失问题：(1) 感知：将视觉信息转换为丰富且多层次的文本表示；(2) 查询：迭代搜索和整合跨域知识以解决歧义；(3) 推理：通过显式推理生成上下文对齐的图像隐含意义。与15多个MLLMs相比，我们的框架使用轻量级的GPT-4o-mini模型在英语图像隐含意义基准测试中取得了SOTA性能，并且在中文基准测试中取得了巨大改进，与GPT-4o模型在多项选择题（MCQ）上表现相当，在开放式问题（OSQ）上超越了36.7%的模型。此外，我们的工作为了解AI如何更有效地解释图像隐含意义提供了新的见解，推动了视觉语言推理和人机交互领域的发展。我们的项目在下面的网址公开：这个https URL。', 'title_zh': '让机器人梦回电羊：一种类人类图像含义理解与推理框架'}
{'arxiv_id': 'arXiv:2505.17017', 'title': 'Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO', 'authors': 'Chengzhuo Tong, Ziyu Guo, Renrui Zhang, Wenyu Shan, Xinyu Wei, Zhenghao Xing, Hongsheng Li, Pheng-Ann Heng', 'link': 'https://arxiv.org/abs/2505.17017', 'abstract': 'Recent advancements underscore the significant role of Reinforcement Learning (RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large language models (LLMs). Two prominent RL algorithms, Direct Preference Optimization (DPO) and Group Relative Policy Optimization (GRPO), are central to these developments, showcasing different pros and cons. Autoregressive image generation, also interpretable as a sequential CoT reasoning process, presents unique challenges distinct from LLM-based CoT reasoning. These encompass ensuring text-image consistency, improving image aesthetic quality, and designing sophisticated reward models, rather than relying on simpler rule-based rewards. While recent efforts have extended RL to this domain, these explorations typically lack an in-depth analysis of the domain-specific challenges and the characteristics of different RL strategies. To bridge this gap, we provide the first comprehensive investigation of the GRPO and DPO algorithms in autoregressive image generation, evaluating their in-domain performance and out-of-domain generalization, while scrutinizing the impact of different reward models on their respective capabilities. Our findings reveal that GRPO and DPO exhibit distinct advantages, and crucially, that reward models possessing stronger intrinsic generalization capabilities potentially enhance the generalization potential of the applied RL algorithms. Furthermore, we systematically explore three prevalent scaling strategies to enhance both their in-domain and out-of-domain proficiency, deriving unique insights into efficiently scaling performance for each paradigm. We hope our study paves a new path for inspiring future work on developing more effective RL algorithms to achieve robust CoT reasoning in the realm of autoregressive image generation. Code is released at this https URL', 'abstract_zh': '最近的研究强调了强化学习（RL）在提高大型语言模型（LLMs）链式思维（CoT）推理能力方面的重要作用。Direct Preference Optimization（DPO）和Group Relative Policy Optimization（GRPO）这两种主要的RL算法在这些发展中起到了关键作用，展示了各自的优缺点。自回归图像生成可解释为一种序列式的CoT推理过程，不同于基于LLM的CoT推理，它面临着独特的挑战，包括确保文本与图像的一致性、提高图像的审美质量以及设计复杂的奖励模型，而不是依赖于简单的基于规则的奖励模型。尽管最近的努力已经将RL扩展到这一领域，但这些探索通常缺乏对特定领域挑战和不同RL策略特性的深入分析。为填补这一空白，我们提供了GRPO和DPO算法在自回归图像生成领域中的首次全面研究，评估它们在领域内的性能以及跨领域的泛化能力，同时审查不同奖励模型对其各自能力的影响。研究发现表明，GRPO和DPO各具优势，并且关键在于具有更强内在泛化能力的奖励模型可能增强所应用的RL算法的泛化潜力。此外，我们系统地探索了三种常见的扩展策略，以增强它们在领域内和跨领域的能力，为每种范式高效扩展性能提供了独特的见解。我们希望我们的研究为未来开发更有效的RL算法，以实现自回归图像生成领域内稳健的CoT推理开辟新的路径。代码发布于此 URL。', 'title_zh': '基于CoT的图像生成中的RL研究：DPO与GRPO的比较'}
{'arxiv_id': 'arXiv:2505.17016', 'title': 'Interactive Post-Training for Vision-Language-Action Models', 'authors': 'Shuhan Tan, Kairan Dou, Yue Zhao, Philipp Krähenbühl', 'link': 'https://arxiv.org/abs/2505.17016', 'abstract': 'We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based interactive post-training paradigm that fine-tunes pretrained Vision-Language-Action (VLA) models using only sparse binary success rewards. Existing VLA training pipelines rely heavily on offline expert demonstration data and supervised imitation, limiting their ability to adapt to new tasks and environments under low-data regimes. RIPT-VLA addresses this by enabling interactive post-training with a stable policy optimization algorithm based on dynamic rollout sampling and leave-one-out advantage estimation.\nRIPT-VLA has the following characteristics. First, it applies to various VLA models, resulting in an improvement on the lightweight QueST model by 21.2%, and the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it is computationally efficient and data-efficient: with only one demonstration, RIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success rate within 15 iterations. Furthermore, we demonstrate that the policy learned by RIPT-VLA generalizes across different tasks and scenarios and is robust to the initial state context. These results highlight RIPT-VLA as a practical and effective paradigm for post-training VLA models through minimal supervision.', 'abstract_zh': 'RIPT-VLA：一种基于强化学习的简单可扩展的交互式后训练范式', 'title_zh': '训练后交互式微调方法用于视觉-语言-行动模型'}
{'arxiv_id': 'arXiv:2505.17012', 'title': 'SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding', 'authors': 'Haoning Wu, Xiao Huang, Yaohui Chen, Ya Zhang, Yanfeng Wang, Weidi Xie', 'link': 'https://arxiv.org/abs/2505.17012', 'abstract': 'Multimodal large language models (MLLMs) have achieved impressive success in question-answering tasks, yet their capabilities for spatial understanding are less explored. This work investigates a critical question: do existing MLLMs possess 3D spatial perception and understanding abilities? Concretely, we make the following contributions in this paper: (i) we introduce VGBench, a benchmark specifically designed to assess MLLMs for visual geometry perception, e.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most comprehensive and diverse multimodal spatial understanding benchmark to date, integrating VGBench with relevant data from the other 11 existing datasets. This benchmark comprises 28K samples across various spatial understanding tasks, modalities, and QA formats, along with a carefully curated challenging subset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent system incorporating 9 specialized tools for spatial understanding, supporting both Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive evaluations to reveal persistent challenges in spatial reasoning while demonstrating the effectiveness of SpatialAgent. We believe SpatialScore will offer valuable insights and serve as a rigorous benchmark for the next evolution of MLLMs.', 'abstract_zh': '多模态大型语言模型（MLLMs）在问答任务中取得了显著成功，但其空间理解能力尚未得到充分探索。本文探讨了一个关键问题：现有的MLLMs是否具备三维空间感知和理解能力？具体而言，本文做出如下贡献：（i）我们引入了VGBench，这是一个专门用于评估MLLMs的视觉几何感知基准，例如相机姿态和运动估计；（ii）我们提出了SpatialScore，这是迄今为止最全面和多样的多模态空间理解基准，将VGBench与来自其他11个现有数据集的相关数据集成；该基准包括了各种空间理解任务、模态和问答格式的28,000个样本，以及一个精心策划的具有挑战性的子集SpatialScore-Hard；（iii）我们开发了SpatialAgent，这是一个包含9种专门工具的新型多智能体系统，支持计划-执行和ReAct推理范式；（iv）我们进行了广泛的评估，揭示了空间推理中的持续挑战，同时展示了SpatialAgent的有效性。我们相信SpatialScore将提供有价值的见解，并作为MLLMs下一阶段演进的严格基准。', 'title_zh': 'SpatialScore: 朝着统一评估多模态空间理解的方向'}
{'arxiv_id': 'arXiv:2505.17010', 'title': 'Understanding Prompt Tuning and In-Context Learning via Meta-Learning', 'authors': 'Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter', 'link': 'https://arxiv.org/abs/2505.17010', 'abstract': 'Prompting is one of the main ways to adapt a pretrained model to target tasks. Besides manually constructing prompts, many prompt optimization methods have been proposed in the literature. Method development is mainly empirically driven, with less emphasis on a conceptual understanding of prompting. In this paper we discuss how optimal prompting can be understood through a Bayesian view, which also implies some fundamental limitations of prompting that can only be overcome by tuning weights. The paper explains in detail how meta-trained neural networks behave as Bayesian predictors over the pretraining distribution, whose hallmark feature is rapid in-context adaptation. Optimal prompting can be studied formally as conditioning these Bayesian predictors, yielding criteria for target tasks where optimal prompting is and is not possible. We support the theory with educational experiments on LSTMs and Transformers, where we compare different versions of prefix-tuning and different weight-tuning methods. We also confirm that soft prefixes, which are sequences of real-valued vectors outside the token alphabet, can lead to very effective prompts for trained and even untrained networks by manipulating activations in ways that are not achievable by hard tokens. This adds an important mechanistic aspect beyond the conceptual Bayesian theory.', 'abstract_zh': '通过贝叶斯视角理解最优提示：提示的局限性及权重调整的必要性', 'title_zh': '通过元学习理解提示调优和上下文学习'}
{'arxiv_id': 'arXiv:2505.17005', 'title': 'R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning', 'authors': 'Huatong Song, Jinhao Jiang, Wenqing Tian, Zhipeng Chen, Yuhuan Wu, Jiahao Zhao, Yingqian Min, Wayne Xin Zhao, Lei Fang, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2505.17005', 'abstract': "Large Language Models (LLMs) are powerful but prone to hallucinations due to static knowledge. Retrieval-Augmented Generation (RAG) helps by injecting external information, but current methods often are costly, generalize poorly, or ignore the internal knowledge of the model. In this paper, we introduce R1-Searcher++, a novel framework designed to train LLMs to adaptively leverage both internal and external knowledge sources. R1-Searcher++ employs a two-stage training strategy: an initial SFT Cold-start phase for preliminary format learning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses outcome-supervision to encourage exploration, incorporates a reward mechanism for internal knowledge utilization, and integrates a memorization mechanism to continuously assimilate retrieved information, thereby enriching the model's internal knowledge. By leveraging internal knowledge and external search engine, the model continuously improves its capabilities, enabling efficient retrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++ outperforms previous RAG and reasoning methods and achieves efficient retrieval. The code is available at this https URL.", 'abstract_zh': '大型语言模型（LLMs）虽然强大但容易因静态知识而产生幻觉。检索增强生成（RAG）通过注入外部信息有所帮助，但当前方法往往成本高、泛化能力差或忽视模型的内部知识。本文介绍了一种新的R1-Searcher++框架，旨在训练LLMs适应性地利用内部和外部知识来源。R1-Searcher++采用两阶段训练策略：初始的SFT冷启动阶段进行初步格式学习，随后是基于奖励的动态知识获取阶段。奖励阶段使用结果监督鼓励探索，引入了内部知识利用的奖励机制，并结合记忆机制持续吸收检索到的信息，从而丰富模型的内部知识。通过利用内部知识和外部搜索引擎，模型能够不断改进其能力，实现高效的检索增强推理。我们的实验表明，R1-Searcher++在与以往的RAG和推理方法的对比中表现更优，实现了高效的检索。代码可在以下链接获取：this https URL。', 'title_zh': 'R1-Searcher++: 通过强化学习激励LLM的动态知识获取'}
{'arxiv_id': 'arXiv:2505.17004', 'title': 'Guided Diffusion Sampling on Function Spaces with Applications to PDEs', 'authors': 'Jiachen Yao, Abbas Mammadov, Julius Berner, Gavin Kerrigan, Jong Chul Ye, Kamyar Azizzadenesheli, Anima Anandkumar', 'link': 'https://arxiv.org/abs/2505.17004', 'abstract': "We propose a general framework for conditional sampling in PDE-based inverse problems, targeting the recovery of whole solutions from extremely sparse or noisy measurements. This is accomplished by a function-space diffusion model and plug-and-play guidance for conditioning. Our method first trains an unconditional discretization-agnostic denoising model using neural operator architectures. At inference, we refine the samples to satisfy sparse observation data via a gradient-based guidance mechanism. Through rigorous mathematical analysis, we extend Tweedie's formula to infinite-dimensional Hilbert spaces, providing the theoretical foundation for our posterior sampling approach. Our method (FunDPS) accurately captures posterior distributions in function spaces under minimal supervision and severe data scarcity. Across five PDE tasks with only 3% observation, our method achieves an average 32% accuracy improvement over state-of-the-art fixed-resolution diffusion baselines while reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning ensures strong cross-resolution generalizability. To the best of our knowledge, this is the first diffusion-based framework to operate independently of discretization, offering a practical and flexible solution for forward and inverse problems in the context of PDEs. Code is available at this https URL", 'abstract_zh': '我们提出了一种基于偏微分方程的逆问题中条件采样的通用框架，旨在从极少量或噪声测量中恢复完整解。该框架通过函数空间扩散模型和可插拔的条件引导机制实现。方法首先使用神经算子架构训练一个无条件的离散化无关去噪模型。在推理过程中，通过梯度引导机制细化样本以满足稀疏观测数据的要求。通过严格的数学分析，我们将Tweedie公式扩展到无限维希尔伯特空间，为我们的后验采样方法提供了理论基础。我们的方法（FunDPS）在最少监督和严重数据匮乏的情况下，能够准确捕捉函数空间中的后验分布。在仅3%观测数据的五个PDE任务中，与最先进的固定分辨率扩散 baseline 相比，我们的方法在采样步骤减少4倍的情况下，平均提高了32%的准确性。此外，多分辨率微调确保了跨分辨率的良好泛化能力。据我们所知，这是第一个独立于离散化的扩散基框架，为PDE中的直接和逆问题提供了实用且灵活的解决方案。代码可在以下链接获取。', 'title_zh': '函数空间中的指导扩散采样及其在偏微分方程中的应用'}
{'arxiv_id': 'arXiv:2505.17002', 'title': 'PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association', 'authors': 'Abdul Hannan, Muhammad Arslan Manzoor, Shah Nawaz, Muhammad Irzam Liaqat, Markus Schedl, Mubashir Noman', 'link': 'https://arxiv.org/abs/2505.17002', 'abstract': 'We study the task of learning association between faces and voices, which is gaining interest in the multimodal community lately. These methods suffer from the deliberate crafting of negative mining procedures as well as the reliance on the distant margin parameter. These issues are addressed by learning a joint embedding space in which orthogonality constraints are applied to the fused embeddings of faces and voices. However, embedding spaces of faces and voices possess different characteristics and require spaces to be aligned before fusing them. To this end, we propose a method that accurately aligns the embedding spaces and fuses them with an enhanced gated fusion thereby improving the performance of face-voice association. Extensive experiments on the VoxCeleb dataset reveals the merits of the proposed approach.', 'abstract_zh': '我们研究面部与声音关联的学习任务，这一领域近年来在多模态社区中引起了关注。这些方法主要受制于负样本挖掘过程的人为设计以及对远距边际参数的依赖。通过学习一个联合嵌入空间，在其中对融合的面部和声音嵌入施加正交约束，我们解决了这些问题。然而，面部和声音的嵌入空间具有不同的特性，需要在融合之前对它们进行对齐。为此，我们提出了一种准确对齐嵌入空间并使用增强门控融合将它们融合的方法，从而提高了面部与声音关联的效果。在 VoxCeleb 数据集上的 extensive 实验验证了所提方法的优势。', 'title_zh': 'PAEFF: 精准对齐和增强门控特征融合用于面音关联'}
{'arxiv_id': 'arXiv:2505.16998', 'title': 'Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?', 'authors': 'Jin Jiang, Jianing Wang, Yuchen Yan, Yang Liu, Jianhua Zhu, Mengdi Zhang, Xunliang Cai, Liangcai Gao', 'link': 'https://arxiv.org/abs/2505.16998', 'abstract': 'Large Language Models (LLMs) have been shown to achieve breakthrough performance on complex logical reasoning tasks. Nevertheless, most existing research focuses on employing formal language to guide LLMs to derive reliable reasoning paths, while systematic evaluations of these capabilities are still limited. In this paper, we aim to conduct a comprehensive evaluation of LLMs across various logical reasoning problems utilizing formal languages. From the perspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and format of trajectories, our key findings are: 1) Thinking models significantly outperform Instruct models, especially when formal language is employed; 2) All LLMs exhibit limitations in inductive reasoning capability, irrespective of whether they use a formal language; 3) Data with PoT format achieves the best generalization performance across other languages. Additionally, we also curate the formal-relative training data to further enhance the small language models, and the experimental results indicate that a simple rejected fine-tuning method can better enable LLMs to generalize across formal languages and achieve the best overall performance. Our codes and reports are available at this https URL.', 'abstract_zh': '大型语言模型在复杂逻辑推理任务中取得了突破性的性能，但大多数现有研究主要集中于使用正式语言指导模型推导可靠的推理路径，系统的评估仍然有限。本文旨在利用正式语言对大型语言模型在各种逻辑推理问题上的能力进行全面评估。从三个维度，即大型语言模型的谱系、任务的分类以及轨迹的格式，我们的关键发现是：1) 思维模型明显优于指令模型，尤其是在使用正式语言的情况下；2) 所有大型语言模型在归纳推理能力方面都存在局限性，无论是否使用正式语言；3)采用PoT格式的数据在其他语言中表现出最佳的泛化性能。此外，我们还整理了相关正式语言训练数据以进一步增强小型语言模型，并实验结果表明一个简单的拒绝微调方法能够更好地使模型跨正式语言泛化并取得最佳的总体性能。我们的代码和报告可在以下链接访问：this https URL。', 'title_zh': '大型语言模型在形式语言中的复杂逻辑推理方面表现出色吗？'}
{'arxiv_id': 'arXiv:2505.16994', 'title': '$\\text{R}^2\\text{ec}$: Towards Large Recommender Models with Reasoning', 'authors': 'Runyang You, Yongqi Li, Xinyu Lin, Xin Zhang, Wenjie Wang, Wenjie Li, Liqiang Nie', 'link': 'https://arxiv.org/abs/2505.16994', 'abstract': 'Large recommender models have extended LLMs as powerful recommenders via encoding or item generation, and recent breakthroughs in LLM reasoning synchronously motivate the exploration of reasoning in recommendation. Current studies usually position LLMs as external reasoning modules to yield auxiliary thought for augmenting conventional recommendation pipelines. However, such decoupled designs are limited in significant resource cost and suboptimal joint optimization. To address these issues, we propose \\name, a unified large recommender model with intrinsic reasoning capabilities. Initially, we reconceptualize the model architecture to facilitate interleaved reasoning and recommendation in the autoregressive process. Subsequently, we propose RecPO, a corresponding reinforcement learning framework that optimizes \\name\\ both the reasoning and recommendation capabilities simultaneously in a single policy update; RecPO introduces a fused reward scheme that solely leverages recommendation labels to simulate the reasoning capability, eliminating dependency on specialized reasoning annotations. Experiments on three datasets with various baselines verify the effectiveness of \\name, showing relative improvements of 68.67\\% in Hit@5 and 45.21\\% in NDCG@20. Code available at this https URL.', 'abstract_zh': '一种具有内在推理能力的统一大型推荐模型', 'title_zh': 'R$^2\\text{ec}$: 向大规模具有推理能力的推荐模型迈进'}
{'arxiv_id': 'arXiv:2505.16988', 'title': 'MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems', 'authors': 'Rui Ye, Keduan Huang, Qimin Wu, Yuzhu Cai, Tian Jin, Xianghe Pang, Xiangrui Liu, Jiaqi Su, Chen Qian, Bohan Tang, Kaiqu Liang, Jiaao Chen, Yue Hu, Zhenfei Yin, Rongye Shi, Bo An, Yang Gao, Wenjun Wu, Lei Bai, Siheng Chen', 'link': 'https://arxiv.org/abs/2505.16988', 'abstract': 'LLM-based multi-agent systems (MAS) have demonstrated significant potential in enhancing single LLMs to address complex and diverse tasks in practical applications. Despite considerable advancements, the field lacks a unified codebase that consolidates existing methods, resulting in redundant re-implementation efforts, unfair comparisons, and high entry barriers for researchers. To address these challenges, we introduce MASLab, a unified, comprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab integrates over 20 established methods across multiple domains, each rigorously validated by comparing step-by-step outputs with its official implementation. (2) MASLab provides a unified environment with various benchmarks for fair comparisons among methods, ensuring consistent inputs and standardized evaluation protocols. (3) MASLab implements methods within a shared streamlined structure, lowering the barriers for understanding and extension. Building on MASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models, offering researchers a clear and comprehensive view of the current landscape of MAS methods. MASLab will continue to evolve, tracking the latest developments in the field, and invite contributions from the broader open-source community.', 'abstract_zh': '基于大型语言模型的多代理系统（LLM-based Multi-Agent Systems, LLM- MAS）展示了在实际应用中处理复杂多样的任务方面的显著潜力。尽管取得了显著进步，该领域缺乏一个整合现有方法的统一代码库，导致重复实现、不公平比较和高研究门槛。为解决这些问题，我们介绍了MASLab，一个统一、全面且有利于研究的LLM- MAS代码库。（1）MASLab整合了来自多个领域的超过20种成熟方法，并通过逐步输出与官方实现的比较进行了严格验证。（2）MASLab提供了一个统一的环境和多种基准，用于公正比较方法，确保一致的输入和标准化的评估协议。（3）MASLab在共享的简化结构中实现方法，降低了理解和扩展的门槛。基于MASLab，我们进行了广泛的实验，覆盖了10多个基准和8个模型，为研究人员提供了当前LM-MAS方法布局的清晰而全面的视角。MASLab将持续发展，跟踪该领域的最新进展，并邀请更广泛开源社区的贡献。', 'title_zh': 'MASLab: 一种统一且全面的基于LLM的多Agent系统代码库'}
{'arxiv_id': 'arXiv:2505.16986', 'title': 'T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning', 'authors': 'Amartya Chakraborty, Paresh Dashore, Nadia Bathaee, Anmol Jain, Anirban Das, Shi-Xiong Zhang, Sambit Sahu, Milind Naphade, Genta Indra Winata', 'link': 'https://arxiv.org/abs/2505.16986', 'abstract': "Large Language Models (LLMs) have demonstrated impressive capabilities as intelligent agents capable of solving complex problems. However, effective planning in scenarios involving dependencies between API or tool calls-particularly in multi-turn conversations-remains a significant challenge. To address this, we introduce T1, a tool-augmented, multi-domain, multi-turn conversational dataset specifically designed to capture and manage inter-tool dependencies across diverse domains. T1 enables rigorous evaluation of agents' ability to coordinate tool use across nine distinct domains (4 single domain and 5 multi-domain) with the help of an integrated caching mechanism for both short- and long-term memory, while supporting dynamic replanning-such as deciding whether to recompute or reuse cached results. Beyond facilitating research on tool use and planning, T1 also serves as a benchmark for evaluating the performance of open-source language models. We present results powered by T1-Agent, highlighting their ability to plan and reason in complex, tool-dependent scenarios.", 'abstract_zh': '大型语言模型（LLMs）展示了作为具有解决复杂问题能力的智能代理的 impressive 能力。然而，在涉及 API 或工具调用之间的依赖关系的情景中，尤其是在多轮对话中，有效的规划仍然是一项重大挑战。为了解决这一问题，我们引入了 T1，一个工具增强的、跨域的、多轮对话数据集，旨在捕捉和管理不同领域之间的工具间依赖关系。T1 通过集成的缓存机制支持短期和长期记忆，并允许动态重新规划（如决定重计算或重用缓存结果）来评估代理协调工具使用的能力，支持在四个单域和五个跨域任务中的九个不同的领域中进行严格的评估。除了促进关于工具使用和规划的研究外，T1 还作为开源语言模型性能评估的标准基准。我们展示了由 T1-Agent 得出的结果，突显了其在复杂、工具依赖场景中进行规划和推理的能力。', 'title_zh': '面向工具的多轮代理规划对话数据集'}
{'arxiv_id': 'arXiv:2505.16985', 'title': 'Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation', 'authors': 'Moru Liu, Hao Dong, Jessica Kelly, Olga Fink, Mario Trapp', 'link': 'https://arxiv.org/abs/2505.16985', 'abstract': 'Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for multimodal outlier synthesis with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370 \\times$ speedup. Our source code and dataset will be available at this https URL.', 'abstract_zh': '分布外(OOD)检测与分割对于自动驾驶和机器人辅助手术等安全关键应用的机器学习模型部署至关重要。尽管先前的研究主要集中在单模态图像数据上，但现实世界的应用本质上是多模态的，需要融合多种模态以提高OOD检测性能。面临的主要挑战是没有未知数据的监督信号，导致模型对OOD样本作出过于自信的预测。为应对这一挑战，我们提出了一种极简单且快速的多模态离群值合成方法Feature Mixing，并具备理论支持，该方法可以通过优化来帮助模型更好地区分分布内(ID)和OOD数据。Feature Mixing对模态无特定要求，适用于各种模态组合。此外，我们还引入了CARLA-OOD多模态数据集，用于OOD分割，该数据集包含多种场景和天气条件下的合成OOD对象。在SemanticKITTI、nuScenes、CARLA-OOD数据集及MultiOOD基准上进行的大量实验表明，Feature Mixing在保持优越性能的同时，实现了高达10倍至370倍的速度提升。我们的源代码和数据集将在此网址提供。', 'title_zh': '超出分布检测与分割的极简多模态离群值合成'}
{'arxiv_id': 'arXiv:2505.16968', 'title': 'CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark', 'authors': 'Ahmed Heakl, Sarim Hashmi, Gustavo Bertolo Stahl, Seung Hun Eddie Han, Salman Khan, Abdulrahman Mahmoud', 'link': 'https://arxiv.org/abs/2505.16968', 'abstract': 'We introduce \\texttt{CASS}, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA~$\\leftrightarrow$~HIP) and assembly-level (Nvidia SASS~$\\leftrightarrow$~AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the \\texttt{CASS} family of domain-specific language models, achieving 95\\% source translation accuracy and 37.5\\% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85\\% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce \\texttt{CASS-Bench}, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation. Dataset and benchmark are on \\href{this https URL}{\\textcolor{blue}{HuggingFace}}, with code at \\href{this https URL}{\\textcolor{blue}{GitHub}}.', 'abstract_zh': '我们介绍了\\texttt{CASS}，这是首个针对跨架构GPU代码转换的大规模数据集和模型套件，旨在实现源代码级别（CUDA $\\leftrightarrow$ HIP）和汇编级别（Nvidia SASS $\\leftrightarrow$ AMD RDNA3）的翻译。数据集包括70,000个经过验证的代码对，涵盖主机和设备，弥补了低级GPU代码移植的关键空白。利用这一资源，我们训练了\\texttt{CASS}家族的领域特定语言模型，实现了95%的源代码翻译准确率和37.5%的汇编代码翻译准确率，大幅优于GPT-4o、Claude和Hipify等商用基线。我们生成的代码在超过85%的测试用例中达到了原生性能，保持了运行时和内存行为的一致性。为了支持严格的评估，我们引入了\\texttt{CASS-Bench}，这是一个涵盖了16个GPU领域的精编基准测试集，具有真实的执行结果。所有数据、模型和评估工具均开源，以促进GPU编译器工具链、二进制兼容性和LLM引导硬件转换的进步。数据集和基准测试集可在\\href{this https URL}{HuggingFace}获取，代码位于\\href{this https URL}{GitHub}。', 'title_zh': 'CASS: 从Nvidia到AMD的编译转换，包含数据、模型和基准测试'}
{'arxiv_id': 'arXiv:2505.16967', 'title': 'Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval', 'authors': 'Nandan Thakur, Crystina Zhang, Xueguang Ma, Jimmy Lin', 'link': 'https://arxiv.org/abs/2505.16967', 'abstract': 'Training robust retrieval and reranker models typically relies on large-scale retrieval datasets; for example, the BGE collection contains 1.6 million query-passage pairs sourced from various data sources. However, we find that certain datasets can negatively impact model effectiveness -- pruning 8 out of 15 datasets from the BGE collection reduces the training set size by 2.35$\\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a deeper examination of training data quality, with a particular focus on "false negatives", where relevant passages are incorrectly labeled as irrelevant. We propose a simple, cost-effective approach using cascading LLM prompts to identify and relabel hard negatives. Experimental results show that relabeling false negatives with true positives improves both E5 (base) and Qwen2.5-7B retrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot AIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on the relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the cascading design is further supported by human annotation results, where we find judgment by GPT-4o shows much higher agreement with humans than GPT-4o-mini.', 'abstract_zh': '训练稳健的检索和重排模型通常依赖大规模的检索数据集；例如，BGE集合包含来自各种数据源的160万查询-段落对。然而，我们发现某些数据集会对模型效果产生负面影响——从BGE集合中剔除15个数据集中的8个，可将训练集规模减少2.35倍，并在BEIR上提高nDCG@10分数1.0分。这促使我们对训练数据质量进行更深入的考察，特别是关注那些本应相关但被错误标记为无关的“假负样本”。我们提出了一种简单且成本效益高的方法，通过级联LLM提示来识别和重新标记困难的负样本。实验结果表明，使用真正相关样本重新标记假负样本可以提高E5（基线）和Qwen2.5-7B检索模型在BEIR上的nDCG@10分数0.7-1.4分，并且在零样本AIR-Bench评估中提高1.7-1.8分。对使用重新标记数据进行微调的重排模型（如BEIR上的Qwen2.5-3B）也观察到了类似收益。进一步的人工标注结果显示，GPT-4o的判断与人类的高度一致，而GPT-4o-mini则不然。', 'title_zh': '修复损害性能的数据：级联大语言模型重新标记困难负样本以实现稳健的信息检索'}
{'arxiv_id': 'arXiv:2505.16965', 'title': 'BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation', 'authors': 'Fengyi Li, Kayhan Behdin, Natesh Pillai, Xiaofeng Wang, Zhipeng Wang, Ercan Yildiz', 'link': 'https://arxiv.org/abs/2505.16965', 'abstract': 'Text segmentation based on the semantic meaning of sentences is a fundamental task with broad utility in many downstream applications. In this paper, we propose a graphical model-based unsupervised learning approach, named BP-Seg for efficient text segmentation. Our method not only considers local coherence, capturing the intuition that adjacent sentences are often more related, but also effectively groups sentences that are distant in the text yet semantically similar. This is achieved through belief propagation on the carefully constructed graphical models. Experimental results on both an illustrative example and a dataset with long-form documents demonstrate that our method performs favorably compared to competing approaches.', 'abstract_zh': '基于句子语义意义的文本切分：一种基于图形模型的无监督学习方法', 'title_zh': 'BP-Seg: 使用信念传播的无监督和非连续文本分割图形模型方法'}
{'arxiv_id': 'arXiv:2505.16957', 'title': 'Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models', 'authors': 'Junjie Xiong, Changjia Zhu, Shuhang Lin, Chong Zhang, Yongfeng Zhang, Yao Liu, Lingyao Li', 'link': 'https://arxiv.org/abs/2505.16957', 'abstract': 'Large Language Models (LLMs) are increasingly equipped with capabilities of real-time web search and integrated with protocols like Model Context Protocol (MCP). This extension could introduce new security vulnerabilities. We present a systematic investigation of LLM vulnerabilities to hidden adversarial prompts through malicious font injection in external resources like webpages, where attackers manipulate code-to-glyph mapping to inject deceptive content which are invisible to users. We evaluate two critical attack scenarios: (1) "malicious content relay" and (2) "sensitive data leakage" through MCP-enabled tools. Our experiments reveal that indirect prompts with injected malicious font can bypass LLM safety mechanisms through external resources, achieving varying success rates based on data sensitivity and prompt design. Our research underscores the urgent need for enhanced security measures in LLM deployments when processing external content.', 'abstract_zh': '大型语言模型通过恶意字体注入外部资源中的隐藏对抗提示研究：针对模型上下文协议（MCP）启用工具的新安全漏洞分析', 'title_zh': '无形的提示，可见的威胁：大型语言模型外部资源中的恶意字体注入'}
{'arxiv_id': 'arXiv:2505.16950', 'title': 'Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning', 'authors': 'Adnan Oomerjee, Zafeirios Fountas, Zhongwei Yu, Haitham Bou-Ammar, Jun Wang', 'link': 'https://arxiv.org/abs/2505.16950', 'abstract': 'Despite their impressive capabilities, Large Language Models struggle with generalisation beyond their training distribution, often exhibiting sophisticated pattern interpolation rather than true abstract reasoning (extrapolation). In this work, we approach this limitation through the lens of Information Bottleneck (IB) theory, which posits that model generalisation emerges from an optimal balance between input compression and retention of predictive information in latent representations. We prove using IB theory that decoder-only Transformers are inherently constrained in their ability to form task-optimal sequence representations. We then use this result to demonstrate that periodic global transformation of the internal sequence-level representations (KV cache) is a necessary computational step for improving Transformer generalisation in reasoning tasks. Based on these theoretical insights, we propose a modification to the Transformer architecture, in the form of an additional module that globally rewrites the KV cache at periodic intervals, shifting its capacity away from memorising input prefixes and toward encoding features most useful for predicting future tokens. Our model delivers substantial gains on mathematical reasoning benchmarks, outperforming both vanilla Transformers with up to 3.5x more parameters, as well as heuristic-driven pruning mechanisms for cache compression. Our approach can be seen as a principled generalisation of existing KV-cache compression methods; whereas such methods focus solely on compressing input representations, they often do so at the expense of retaining predictive information, and thus their capabilities are inherently bounded by those of an unconstrained model. This establishes a principled framework to manipulate Transformer memory using information theory, addressing fundamental reasoning limitations that scaling alone cannot overcome.', 'abstract_zh': '尽管大型语言模型具有 impressive 的能力，但在超出训练分布范围的一般化方面仍然存在局限性，常常表现出复杂的模式插值而缺乏真正的抽象推理（外推）。本文通过信息瓶颈（IB）理论的视角来解决这一限制，该理论认为模型的一般化源自输入压缩和潜在表示中预测信息保留之间的最优平衡。我们利用 IB 理论证明，仅解码器的变压器在形成任务最优序列表示方面存在内在限制。然后，我们利用这一结果证明，周期性地全局变换内部序列级表示（KV 缓存）是提高变压器在推理任务中一般化能力的必要计算步骤。基于这些理论洞见，我们提出了一种对变压器架构的修改，形式上增加了一个额外模块，该模块在周期性间隔内全局重写 KV 缓存，将其实用容量从记忆输入前缀转移到对预测未来标记最有用的特征编码。我们的模型在数学推理基准测试中取得了显著的改进，超越了具有多达 3.5 倍参数数的 vanilla 变压器，以及驱动的缓存压缩启发式剪枝机制。我们的方法可以看作是现有 KV 缓存压缩方法的原理上的一般化；这些方法仅专注于压缩输入表示，而常常以保留预测信息为代价，因此它们的能力受到不受约束的模型的内在限制。这为我们提供了一种原理上的框架，使用信息理论操纵变压器记忆，解决了仅靠扩展无法克服的基本推理限制。', 'title_zh': '瓶颈变换器：周期性 KV 缓存抽象化通用推理'}
{'arxiv_id': 'arXiv:2505.16947', 'title': 'MixAT: Combining Continuous and Discrete Adversarial Training for LLMs', 'authors': 'Csaba Dékány, Stefan Balauca, Robin Staab, Dimitar I. Dimitrov, Martin Vechev', 'link': 'https://arxiv.org/abs/2505.16947', 'abstract': "Despite recent efforts in Large Language Models (LLMs) safety and alignment, current adversarial attacks on frontier LLMs are still able to force harmful generations consistently. Although adversarial training has been widely studied and shown to significantly improve the robustness of traditional machine learning models, its strengths and weaknesses in the context of LLMs are less understood. Specifically, while existing discrete adversarial attacks are effective at producing harmful content, training LLMs with concrete adversarial prompts is often computationally expensive, leading to reliance on continuous relaxations. As these relaxations do not correspond to discrete input tokens, such latent training methods often leave models vulnerable to a diverse set of discrete attacks. In this work, we aim to bridge this gap by introducing MixAT, a novel method that combines stronger discrete and faster continuous attacks during training. We rigorously evaluate MixAT across a wide spectrum of state-of-the-art attacks, proposing the At Least One Attack Success Rate (ALO-ASR) metric to capture the worst-case vulnerability of models. We show MixAT achieves substantially better robustness (ALO-ASR < 20%) compared to prior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to methods based on continuous relaxations. We further analyze MixAT in realistic deployment settings, exploring how chat templates, quantization, low-rank adapters, and temperature affect both adversarial training and evaluation, revealing additional blind spots in current methodologies. Our results demonstrate that MixAT's discrete-continuous defense offers a principled and superior robustness-accuracy tradeoff with minimal computational overhead, highlighting its promise for building safer LLMs. We provide our code and models at this https URL.", 'abstract_zh': '尽管在大型语言模型（LLMs）的安全性和对齐方面付出了近期努力，当前针对前沿LLMs的对抗攻击仍能一致地迫使生成有害内容。虽然对抗训练已经被广泛研究并显示出显著提高传统机器学习模型鲁棒性的效果，但在LLMs背景下其优势与局限性尚不够了解。具体而言，在现有离散对抗攻击在生成有害内容方面非常有效的同时，使用具体的对抗提示训练LLMs通常计算成本高昂，导致对连续松弛的依赖。由于这些松弛不对应于离散输入令牌，这种潜在训练方法往往使模型容易受到一系列离散攻击。在这项工作中，我们通过引入结合更强离散攻击和更快连续攻击的MixAT新方法来填补这一差距。我们全面评估MixAT在最先进的各类攻击下，并提出最低成功率指标（ALO-ASR）来捕捉模型的最坏情况脆弱性。结果显示，MixAT在鲁棒性（ALO-ASR < 20%）方面显著优于先前防御方法（ALO-ASR > 50%），同时保持与基于连续松弛的方法相当的运行时间。此外，我们在现实部署场景下分析MixAT，探讨聊天模板、量化、低秩适配器和温度如何影响对抗训练和评估，揭示当前方法中的额外盲点。我们的结果表明，MixAT的离散-连续防御提供了一种具有最小计算开销的鲁棒性-准确率权衡，并展示了其构建更安全LLMs的潜力。我们在此处提供代码和模型：https://your-link-url。', 'title_zh': 'MixAT：结合连续性和离散性对抗训练的大型语言模型训练方法'}
{'arxiv_id': 'arXiv:2505.16941', 'title': 'FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records', 'authors': 'Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi', 'link': 'https://arxiv.org/abs/2505.16941', 'abstract': "Foundation models hold significant promise in healthcare, given their capacity to extract meaningful representations independent of downstream tasks. This property has enabled state-of-the-art performance across several clinical applications trained on structured electronic health record (EHR) data, even in settings with limited labeled data, a prevalent challenge in healthcare. However, there is little consensus on these models' potential for clinical utility due to the lack of desiderata of comprehensive and meaningful tasks and sufficiently diverse evaluations to characterize the benefit over conventional supervised learning. To address this gap, we propose a suite of clinically meaningful tasks spanning patient outcomes, early prediction of acute and chronic conditions, including desiderata for robust evaluations. We evaluate state-of-the-art foundation models on EHR data consisting of 5 million patients from Columbia University Irving Medical Center (CUMC), a large urban academic medical center in New York City, across 14 clinically relevant tasks. We measure overall accuracy, calibration, and subpopulation performance to surface tradeoffs based on the choice of pre-training, tokenization, and data representation strategies. Our study aims to advance the empirical evaluation of structured EHR foundation models and guide the development of future healthcare foundation models.", 'abstract_zh': '基于模型在医疗健康领域的应用中展现出显著潜力，得益于它们能够独立于下游任务提取有意义的表示。这一特性使得这些模型能够在结构化的电子健康记录(EHR)数据上训练，并在有限标注数据的环境中实现最先进的临床应用性能。然而，由于缺乏全面且有意义的任务定义以及足够多样的评估来表征与传统监督学习相比的优势，这些模型的临床实用性还有待商榷。为填补这一空白，我们提出了涵盖患者结局、急性及慢性疾病早期预测等一系列临床相关任务的方案，并为此类任务制定了评估标准。我们评估了各种先进的基础模型在包含50万患者的哥伦比亚大学欧文医学中心(CUMC)的EHR数据上的性能，涵盖了14个临床相关任务。我们衡量总体准确性、校准情况以及子人群表现，以基于预训练策略、分词方法和数据表示方法的选择探讨各项权衡。我们的研究旨在推动结构化EHR基础模型的实证评估，并指导未来医疗健康基础模型的发展。', 'title_zh': 'FoMoH: 一个临床相关的基础模型评估框架用于结构化的电子健康记录'}
{'arxiv_id': 'arXiv:2505.16932', 'title': 'The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm', 'authors': 'Noah Amsel, David Persson, Christopher Musco, Robert Gower', 'link': 'https://arxiv.org/abs/2505.16932', 'abstract': 'Computing the polar decomposition and the related matrix sign function, has been a well-studied problem in numerical analysis for decades. More recently, it has emerged as an important subroutine in deep learning, particularly within the Muon optimization framework. However, the requirements in this setting differ significantly from those of traditional numerical analysis. In deep learning, methods must be highly efficient and GPU-compatible, but high accuracy is often unnecessary. As a result, classical algorithms like Newton-Schulz (which suffers from slow initial convergence) and methods based on rational functions (which rely on QR decompositions or matrix inverses) are poorly suited to this context. In this work, we introduce Polar Express, a GPU-friendly algorithm for computing the polar decomposition. Like classical polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix multiplications, making it GPU-compatible. Motivated by earlier work of Chen & Chow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule at each iteration by solving a minimax optimization problem, and we prove that it enjoys a strong worst-case optimality guarantee. This property ensures both rapid early convergence and fast asymptotic convergence. We also address finite-precision issues, making it stable in bfloat16 in practice. We apply Polar Express within the Muon optimization framework and show consistent improvements in validation loss on large-scale models such as GPT-2, outperforming recent alternatives across a range of learning rates.', 'abstract_zh': '计算极分解及其相关矩阵符号函数在数值分析中已有几十年的研究历史。近年来，它已成为深度学习中的一个重要子程序，特别是在Muon优化框架中。然而，在这种情况下的要求与传统数值分析的要求大不相同。在深度学习中，方法必须极其高效且兼容GPU，但高精度往往是不必要的。因此，像Newton-Schulz这样经典的算法（由于初始收敛速度慢）和基于有理函数的方法（依赖于QR分解或矩阵逆）在这种背景下适应性较差。本文我们介绍了Polar Express，这是一种兼容GPU的用于计算极分解的算法。就像经典的多项式方法（如Newton-Schulz）一样，我们的方法仅使用矩阵-矩阵乘法，使其兼容GPU。受Chen & Chow和Nakatsukasa & Freund早期工作的启发，Polar Express在每次迭代中通过求解极小极大优化问题来适应多项式更新规则，并证明它享有强大的最坏情况最优性保证。这一特性确保了快速的早期收敛和快速的渐近收敛。我们还解决了有限精度问题，使其在实践中能够在bfloat16中稳定运行。我们在Muon优化框架中应用Polar Express，并在大型模型（如GPT-2）上展示了验证损失的一致改善，在不同学习率范围内优于近期的替代方法。', 'title_zh': '极地 Express：最优矩阵符号方法及其在穆链算法中的应用'}
{'arxiv_id': 'arXiv:2505.16927', 'title': 'Latent Principle Discovery for Language Model Self-Improvement', 'authors': 'Keshav Ramji, Tahira Naseem, Ramón Fernandez Astudillo', 'link': 'https://arxiv.org/abs/2505.16927', 'abstract': 'When language model (LM) users aim to improve the quality of its generations, it is crucial to specify concrete behavioral attributes that the model should strive to reflect. However, curating such principles across many domains, even non-exhaustively, requires a labor-intensive annotation process. To automate this process, we propose eliciting these latent attributes guiding model reasoning towards human-preferred responses by explicitly modeling them in a self-correction setting. Our approach mines new principles from the LM itself and compresses the discovered elements to an interpretable set via clustering. Specifically, we employ an approximation of posterior-regularized Monte Carlo Expectation-Maximization to both identify a condensed set of the most effective latent principles and teach the LM to strategically invoke them in order to intrinsically refine its responses. We demonstrate that bootstrapping our algorithm over multiple iterations enables smaller language models (7-8B parameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an average of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on IFEval. We also show that clustering the principles yields interpretable and diverse model-generated constitutions while retaining model performance. The gains our method achieves highlight the potential of automated, principle-driven post-training recipes toward continual self-improvement.', 'abstract_zh': '通过自洽设置explicitly建模latent属性以自动化提升语言模型生成质量的原理驱动方法', 'title_zh': '语言模型自我提升的潜在原理发现'}
{'arxiv_id': 'arXiv:2505.16915', 'title': 'DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?', 'authors': 'Qirui Jiao, Daoyuan Chen, Yilun Huang, Xika Lin, Ying Shen, Yaliang Li', 'link': 'https://arxiv.org/abs/2505.16915', 'abstract': "While recent text-to-image (T2I) models show impressive capabilities in synthesizing images from brief descriptions, their performance significantly degrades when confronted with long, detail-intensive prompts required in professional applications. We present DetailMaster, the first comprehensive benchmark specifically designed to evaluate T2I models' systematical abilities to handle extended textual inputs that contain complex compositional requirements. Our benchmark introduces four critical evaluation dimensions: Character Attributes, Structured Character Locations, Multi-Dimensional Scene Attributes, and Explicit Spatial/Interactive Relationships. The benchmark comprises long and detail-rich prompts averaging 284.89 tokens, with high quality validated by expert annotators. Evaluation on 7 general-purpose and 5 long-prompt-optimized T2I models reveals critical performance limitations: state-of-the-art models achieve merely ~50% accuracy in key dimensions like attribute binding and spatial reasoning, while all models showing progressive performance degradation as prompt length increases. Our analysis highlights systemic failures in structural comprehension and detail overload handling, motivating future research into architectures with enhanced compositional reasoning. We open-source the dataset, data curation code, and evaluation tools to advance detail-rich T2I generation and enable broad applications that would otherwise be infeasible due to the lack of a dedicated benchmark.", 'abstract_zh': 'DetailMaster：专为评估文本到图像模型处理长细节文本能力的综合基准', 'title_zh': 'DetailMaster: 你的文本到图像模型能处理长提示吗？'}
{'arxiv_id': 'arXiv:2505.16911', 'title': 'Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation', 'authors': 'Ofir Yaish, Yehuda Mishaly, Eliya Nachmani', 'link': 'https://arxiv.org/abs/2505.16911', 'abstract': 'We introduce a new paradigm for active sound modification: Active Speech Enhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on suppressing external interference, ASE goes further by actively shaping the speech signal -- both attenuating unwanted noise components and amplifying speech-relevant frequencies -- to improve intelligibility and perceptual quality. To enable this, we propose a novel Transformer-Mamba-based architecture, along with a task-specific loss function designed to jointly optimize interference suppression and signal enrichment. Our method outperforms existing baselines across multiple speech processing tasks -- including denoising, dereverberation, and declipping -- demonstrating the effectiveness of active, targeted modulation in challenging acoustic environments.', 'abstract_zh': '基于Transformer-Mamba的主动语音增强（ASE）新范式', 'title_zh': '主动语音增强：主动语音降噪、去Clip和去失真'}
{'arxiv_id': 'arXiv:2505.16896', 'title': 'Structure-Aligned Protein Language Model', 'authors': 'Can Chen, David Heurtel-Depeiges, Robert M. Vernon, Christopher James Langmead, Yoshua Bengio, Quentin Fournier', 'link': 'https://arxiv.org/abs/2505.16896', 'abstract': 'Protein language models (pLMs) pre-trained on vast protein sequence databases excel at various downstream tasks but lack the structural knowledge essential for many biological applications. To address this, we integrate structural insights from pre-trained protein graph neural networks (pGNNs) into pLMs through a latent-level contrastive learning task. This task aligns residue representations from pLMs with those from pGNNs across multiple proteins, enriching pLMs with inter-protein structural knowledge. Additionally, we incorporate a physical-level task that infuses intra-protein structural knowledge by optimizing pLMs to predict structural tokens. The proposed dual-task framework effectively incorporates both inter-protein and intra-protein structural knowledge into pLMs. Given the variability in the quality of protein structures in PDB, we further introduce a residue loss selection module, which uses a small model trained on high-quality structures to select reliable yet challenging residue losses for the pLM to learn. Applying our structure alignment method to the state-of-the-art ESM2 and AMPLIFY results in notable performance gains across a wide range of tasks, including a 12.7% increase in ESM2 contact prediction. The data, code, and resulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.', 'abstract_zh': '基于结构的蛋白语言模型：通过双重任务框架融合 residue 表征增强蛋白间与蛋白内结构知识', 'title_zh': '结构对齐蛋白质语言模型'}
{'arxiv_id': 'arXiv:2505.16888', 'title': 'CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework', 'authors': 'Viet Pham, Thai Le', 'link': 'https://arxiv.org/abs/2505.16888', 'abstract': 'Large language models (LLMs) have advanced many applications, but are also known to be vulnerable to adversarial attacks. In this work, we introduce a novel security threat: hijacking AI-human conversations by manipulating LLMs\' system prompts to produce malicious answers only to specific targeted questions (e.g., "Who should I vote for US President?", "Are Covid vaccines safe?"), while behaving benignly on others. This attack is detrimental as it can enable malicious actors to exercise large-scale information manipulation by spreading harmful but benign-looking system prompts online. To demonstrate such an attack, we develop CAIN, an algorithm that can automatically curate such harmful system prompts for a specific target question in a black-box setting or without the need to access the LLM\'s parameters. Evaluated on both open-source and commercial LLMs, CAIN demonstrates significant adversarial impact. In untargeted attacks or forcing LLMs to output incorrect answers, CAIN achieves up to 40% F1 degradation on targeted questions while preserving high accuracy on benign inputs. For targeted attacks or forcing LLMs to output specific harmful answers, CAIN achieves over 70% F1 scores on these targeted responses with minimal impact on benign questions. Our results highlight the critical need for enhanced robustness measures to safeguard the integrity and safety of LLMs in real-world applications. All source code will be publicly available.', 'abstract_zh': '大语言模型（LLMs）已经在多个应用中取得了进展，但也被认为容易受到 adversarial 攻击。本文介绍了一种新的安全威胁：通过操纵 LLMs 的系统提示来生成仅对特定目标问题（例如，“我应该支持哪位美国总统？”、“新冠疫苗安全吗？”）产生恶意回答的系统提示，而在其他问题上表现 benign。这种攻击具有严重性，因为它可以使恶意行为者通过在线传播看似无害但实际上有害的系统提示来进行大规模信息操控。为了展示这种攻击，我们开发了 CAIN 算法，该算法可以在黑盒环境中或不访问 LLM 参数的情况下自动为特定目标问题定制此类有害系统提示。CAIN 在开源和商用大语言模型上的评估显示了显著的 adversarial 影响。在未针对特定目标的攻击中或迫使 LLM 生成不正确答案时，CAIN 在目标问题上的 F1 值最多可降低 40%，同时在良性输入上保持高准确率。在针对特定目标的攻击中或迫使 LLM 生成特定有害回答时，CAIN 在这些目标响应上的 F1 值超过 70%，对良性问题的负面影响最小。我们的结果强调了在实际应用中增强大语言模型的健壮性措施的重要性。所有源代码将公开可用。', 'title_zh': 'CAIN：通过两阶段恶意系统提示生成和优化框架操控LLM-人类对话'}
{'arxiv_id': 'arXiv:2505.16886', 'title': 'Don\'t "Overthink" Passage Reranking: Is Reasoning Truly Necessary?', 'authors': 'Nour Jedidi, Yung-Sung Chuang, James Glass, Jimmy Lin', 'link': 'https://arxiv.org/abs/2505.16886', 'abstract': "With the growing success of reasoning models across complex natural language tasks, researchers in the Information Retrieval (IR) community have begun exploring how similar reasoning capabilities can be integrated into passage rerankers built on Large Language Models (LLMs). These methods typically employ an LLM to produce an explicit, step-by-step reasoning process before arriving at a final relevance prediction. But, does reasoning actually improve reranking accuracy? In this paper, we dive deeper into this question, studying the impact of the reasoning process by comparing reasoning-based pointwise rerankers (ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under identical training conditions, and observe that StandardRR generally outperforms ReasonRR. Building on this observation, we then study the importance of reasoning to ReasonRR by disabling its reasoning process (ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more effective than ReasonRR. Examining the cause of this result, our findings reveal that reasoning-based rerankers are limited by the LLM's reasoning process, which pushes it toward polarized relevance scores and thus fails to consider the partial relevance of passages, a key factor for the accuracy of pointwise rerankers.", 'abstract_zh': '随着推理模型在复杂自然语言任务中取得越来越多的成功，信息检索（IR）领域的研究人员开始探索如何将类似的推理能力整合到基于大规模语言模型（LLMs）的段落重排序器中。这些方法通常使用LLM产生显式的、逐步的推理过程，最终得出最后的相关性预测。但推理是否真的能提高重排序准确性？在本文中，我们深入探讨了这一问题，通过在相同的训练条件下将基于推理的点wise重排序器（ReasonRR）与标准的非推理点wise重排序器（StandardRR）进行对比研究，发现StandardRR通常优于ReasonRR。在此基础上，我们进一步探讨了推理对ReasonRR的重要性，通过禁用其推理过程（ReasonRR-NoReason）进行研究，发现ReasonRR-NoReason竟然比ReasonRR更为有效。研究这一结果的原因，我们的发现表明，基于推理的重排序器受到LLM推理过程的限制，这促使它趋向于极化的相关性评分，从而未能考虑段落的部分相关性，这是点wise重排序器准确性的一个关键因素。', 'title_zh': '别“过度思考”段落重排：推理真的必要吗？'}
{'arxiv_id': 'arXiv:2505.16881', 'title': 'CASTILLO: Characterizing Response Length Distributions of Large Language Models', 'authors': 'Daniel F. Perez-Ramirez, Dejan Kostic, Magnus Boman', 'link': 'https://arxiv.org/abs/2505.16881', 'abstract': 'Efficiently managing compute resources for Large Language Model (LLM) inference remains challenging due to the inherently stochastic and variable lengths of autoregressive text generation. Accurately estimating response lengths in advance enables proactive resource allocation, yet existing approaches either bias text generation towards certain lengths or rely on assumptions that ignore model- and prompt-specific variability. We introduce CASTILLO, a dataset characterizing response length distributions across 13 widely-used open-source LLMs evaluated on seven distinct instruction-following corpora. For each $\\langle$prompt, model$\\rangle$ sample pair, we generate 10 independent completions using fixed decoding hyper-parameters, record the token length of each response, and publish summary statistics (mean, std-dev, percentiles), along with the shortest and longest completions, and the exact generation settings. Our analysis reveals significant inter- and intra-model variability in response lengths (even under identical generation settings), as well as model-specific behaviors and occurrences of partial text degeneration in only subsets of responses. CASTILLO enables the development of predictive models for proactive scheduling and provides a systematic framework for analyzing model-specific generation behaviors. We publicly release the dataset and code to foster research at the intersection of generative language modeling and systems.', 'abstract_zh': '高效管理大规模语言模型（LLM）推理计算资源仍具有挑战性，原因在于自回归文本生成固有的随机性和响应长度的变异性。准确地事先估计响应长度可以实现主动的资源分配，但现有方法要么偏向于生成特定长度的文本，要么依赖于忽略模型和提示特定变异性的情况性假设。我们引入了CASTILLO数据集，该数据集描述了13个广泛使用的开源LLM在七个不同指令遵循语料库上的响应长度分布。对于每个$\\langle$提示，模型$\\rangle$样本对，我们使用固定解码超参数生成10个独立的完成，记录每个响应的token长度，并发布汇总统计信息（均值、标准差、百分位数），以及最短和最长的完成，和精确的生成设置。我们的分析揭示了即使在相同的生成设置下，响应长度的显著跨模型和跨样本变异性，以及模型特定的行为和仅在某些响应中出现的部分文本退化现象。CASTILLO使得预测模型的开发成为可能，为分析模型特定的生成行为提供了一种系统框架。我们公开释放了数据集和代码，以促进生成语言建模与系统交叉领域的研究。', 'title_zh': 'CASTILLO: 大型语言模型响应长度分布Characterizing'}
{'arxiv_id': 'arXiv:2505.16875', 'title': 'T2I-ConBench: Text-to-Image Benchmark for Continual Post-training', 'authors': 'Zhehao Huang, Yuhang Liu, Yixin Lou, Zhengbao He, Mingzhen He, Wenxing Zhou, Tao Li, Kehan Li, Zeyi Huang, Xiaolin Huang', 'link': 'https://arxiv.org/abs/2505.16875', 'abstract': 'Continual post-training adapts a single text-to-image diffusion model to learn new tasks without incurring the cost of separate models, but naive post-training causes forgetting of pretrained knowledge and undermines zero-shot compositionality. We observe that the absence of a standardized evaluation protocol hampers related research for continual post-training. To address this, we introduce T2I-ConBench, a unified benchmark for continual post-training of text-to-image models. T2I-ConBench focuses on two practical scenarios, item customization and domain enhancement, and analyzes four dimensions: (1) retention of generality, (2) target-task performance, (3) catastrophic forgetting, and (4) cross-task generalization. It combines automated metrics, human-preference modeling, and vision-language QA for comprehensive assessment. We benchmark ten representative methods across three realistic task sequences and find that no approach excels on all fronts. Even joint "oracle" training does not succeed for every task, and cross-task generalization remains unsolved. We release all datasets, code, and evaluation tools to accelerate research in continual post-training for text-to-image models.', 'abstract_zh': '持续后训练适应单个文本到图像扩散模型以学习新任务，同时避免单独模型的高昂成本，但 naive 后训练会导致先验知识的遗忘并削弱零-shot 组合性。我们观察到缺乏标准化评估协议阻碍了持续后训练相关研究。为解决这一问题，我们引入了 T2I-ConBench，这是一个统一的持续后训练基准，专门针对项目个性化和领域增强两种实用场景，并从四个维度进行分析：（1）保持通用性，（2）目标任务性能，（3）灾难性遗忘，以及（4）跨任务泛化。该基准结合了自动化指标、人类偏好建模和视觉-语言问答，进行全面评估。我们在三个现实任务序列中对十种代表性方法进行了基准测试，发现没有一种方法在所有方面都表现出色。即使联合“先验”训练也无法在所有任务中成功，跨任务泛化问题尚未解决。我们将所有数据集、代码和评估工具公开，以促进文本到图像模型持续后训练的研究。', 'title_zh': 'T2I-ConBench: 文本到图像持续后训练基准'}
{'arxiv_id': 'arXiv:2505.16860', 'title': 'GCAL: Adapting Graph Models to Evolving Domain Shifts', 'authors': 'Ziyue Qiao, Qianyi Cai, Hao Dong, Jiawei Gu, Pengyang Wang, Meng Xiao, Xiao Luo, Hui Xiong', 'link': 'https://arxiv.org/abs/2505.16860', 'abstract': 'This paper addresses the challenge of graph domain adaptation on evolving, multiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation methods are confined to single-step adaptation, making them ineffective in handling continuous domain shifts and prone to catastrophic forgetting. This paper introduces the Graph Continual Adaptive Learning (GCAL) method, designed to enhance model sustainability and adaptability across various graph domains. GCAL employs a bilevel optimization strategy. The "adapt" phase uses an information maximization approach to fine-tune the model with new graph domains while re-adapting past memories to mitigate forgetting. Concurrently, the "generate memory" phase, guided by a theoretical lower bound derived from information bottleneck theory, involves a variational memory graph generation module to condense original graphs into memories. Extensive experimental evaluations demonstrate that GCAL substantially outperforms existing methods in terms of adaptability and knowledge retention.', 'abstract_zh': '这种论文解决了 evolving、multiple out-of-distribution (OOD) 图的图域适应挑战。传统的图域适应方法局限于单步适应，使其在处理连续域移位时效果不佳，并且容易出现灾难性遗忘。本文引入了图持续适应学习（GCAL）方法，旨在提高模型在各种图域中的可持续性和适应性。GCAL采用多层次优化策略。“adapt”阶段使用信息最大化的手段对模型进行微调，并重新适应过去的记忆以减轻遗忘。“generate memory”阶段则通过信息瓶颈理论推导出的理论下界指导，利用变分记忆图生成模块将原始图压缩成记忆。广泛的实验证明，GCAL在适应性和知识保留方面显著优于现有方法。', 'title_zh': 'GCAL：适应演变领域偏移的图模型改编'}
{'arxiv_id': 'arXiv:2505.16856', 'title': 'Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only', 'authors': 'Wei Xiao, Jiacheng Liu, Zifeng Zhuang, Runze Suo, Shangke Lyu, Donglin Wang', 'link': 'https://arxiv.org/abs/2505.16856', 'abstract': 'Improving the performance of pre-trained policies through online reinforcement learning (RL) is a critical yet challenging topic. Existing online RL fine-tuning methods require continued training with offline pretrained Q-functions for stability and performance. However, these offline pretrained Q-functions commonly underestimate state-action pairs beyond the offline dataset due to the conservatism in most offline RL methods, which hinders further exploration when transitioning from the offline to the online setting. Additionally, this requirement limits their applicability in scenarios where only pre-trained policies are available but pre-trained Q-functions are absent, such as in imitation learning (IL) pre-training. To address these challenges, we propose a method for efficient online RL fine-tuning using solely the offline pre-trained policy, eliminating reliance on pre-trained Q-functions. We introduce PORL (Policy-Only Reinforcement Learning Fine-Tuning), which rapidly initializes the Q-function from scratch during the online phase to avoid detrimental pessimism. Our method not only achieves competitive performance with advanced offline-to-online RL algorithms and online RL approaches that leverage data or policies prior, but also pioneers a new path for directly fine-tuning behavior cloning (BC) policies.', 'abstract_zh': '通过在线强化学习提高预训练策略性能：一种仅依赖预训练策略的高效在线RL微调方法', 'title_zh': '基于离线预训练策略的高效在线RL微调'}
{'arxiv_id': 'arXiv:2505.16845', 'title': 'Unlocking Temporal Flexibility: Neural Speech Codec with Variable Frame Rate', 'authors': 'Hanglei Zhang, Yiwei Guo, Zhihan Li, Xiang Hao, Xie Chen, Kai Yu', 'link': 'https://arxiv.org/abs/2505.16845', 'abstract': 'Most neural speech codecs achieve bitrate adjustment through intra-frame mechanisms, such as codebook dropout, at a Constant Frame Rate (CFR). However, speech segments inherently have time-varying information density (e.g., silent intervals versus voiced regions). This property makes CFR not optimal in terms of bitrate and token sequence length, hindering efficiency in real-time applications. In this work, we propose a Temporally Flexible Coding (TFC) technique, introducing variable frame rate (VFR) into neural speech codecs for the first time. TFC enables seamlessly tunable average frame rates and dynamically allocates frame rates based on temporal entropy. Experimental results show that a codec with TFC achieves optimal reconstruction quality with high flexibility, and maintains competitive performance even at lower frame rates. Our approach is promising for the integration with other efforts to develop low-frame-rate neural speech codecs for more efficient downstream tasks.', 'abstract_zh': 'Temporal Flexibility Coding for Neural Speech Codecs', 'title_zh': '解锁时间灵活性：具有可变帧率的神经语音编解码器'}
{'arxiv_id': 'arXiv:2505.16836', 'title': 'Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning', 'authors': 'Fanrui Zhang, Dian Li, Qiang Zhang, Chenjun, sinbadliu, Junxiong Lin, Jiahong Yan, Jiawei Liu, Zheng-Jun Zha', 'link': 'https://arxiv.org/abs/2505.16836', 'abstract': 'The rapid spread of multimodal misinformation on social media has raised growing concerns, while research on video misinformation detection remains limited due to the lack of large-scale, diverse datasets. Existing methods often overfit to rigid templates and lack deep reasoning over deceptive content. To address these challenges, we introduce FakeVV, a large-scale benchmark comprising over 100,000 video-text pairs with fine-grained, interpretable annotations. In addition, we further propose Fact-R1, a novel framework that integrates deep reasoning with collaborative rule-based reinforcement learning. Fact-R1 is trained through a three-stage process: (1) misinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference alignment via Direct Preference Optimization (DPO), and (3) Group Relative Policy Optimization (GRPO) using a novel verifiable reward function. This enables Fact-R1 to exhibit emergent reasoning behaviors comparable to those observed in advanced text-based reinforcement learning systems, but in the more complex multimodal misinformation setting. Our work establishes a new paradigm for misinformation detection, bridging large-scale video understanding, reasoning-guided alignment, and interpretable verification.', 'abstract_zh': '大规模多模态错误信息在社交媒体上的迅速传播引发了广泛关注，但由于缺乏大规模、多样化的数据集，有关视频错误信息检测的研究仍然有限。现有方法往往过度依赖固定模板，并缺乏对欺骗性内容的深层推理。为应对这些挑战，我们引入了FakeVV，这是一个包含超过100,000个详尽标注的视频-文本对的大规模基准数据集。此外，我们还提出了Fact-R1，这是一种融合深度推理与协作规则强化学习的新框架。Fact-R1通过三个阶段的训练过程进行训练：（1）错误信息长链推理指令调优，（2）通过直接偏好优化（DPO）进行偏好对齐，（3）使用新的可验证奖励函数进行组相对策略优化（GRPO）。这使得Fact-R1能够在更复杂的多模态错误信息环境中展现出类似于高级文本强化学习系统中的新兴推理行为。我们的研究确立了一种新的错误信息检测范式，结合了大规模视频理解、推理引导的对齐和可解释的验证。', 'title_zh': '面向可解释的视频错误信息检测的深度推理方法'}
{'arxiv_id': 'arXiv:2505.16834', 'title': 'SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis', 'authors': 'Shuang Sun, Huatong Song, Yuhao Wang, Ruiyang Ren, Jinhao Jiang, Junjie Zhang, Fei Bai, Jia Deng, Wayne Xin Zhao, Zheng Liu, Lei Fang, Zhongyuan Wang, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2505.16834', 'abstract': 'Retrieval-augmented generation (RAG) systems have advanced large language models (LLMs) in complex deep search scenarios requiring multi-step reasoning and iterative information retrieval. However, existing approaches face critical limitations that lack high-quality training trajectories or suffer from the distributional mismatches in simulated environments and prohibitive computational costs for real-world deployment. This paper introduces SimpleDeepSearcher, a lightweight yet effective framework that bridges this gap through strategic data engineering rather than complex training paradigms. Our approach synthesizes high-quality training data by simulating realistic user interactions in live web search environments, coupled with a multi-criteria curation strategy that optimizes the diversity and quality of input and output side. Experiments on five benchmarks across diverse domains demonstrate that SFT on only 871 curated samples yields significant improvements over RL-based baselines. Our work establishes SFT as a viable pathway by systematically addressing the data-scarce bottleneck, offering practical insights for efficient deep search systems. Our code is available at this https URL.', 'abstract_zh': '基于检索的生成（RAG）系统在复杂的深度搜索场景中推进了大型语言模型（LLMs），这些场景需要多步推理和迭代的信息检索。然而，现有方法面临关键限制，包括缺乏高质量的训练轨迹或在模拟环境中存在分布不匹配问题，以及在实际部署中高昂的计算成本。本文引入了SimpleDeepSearcher，这是一种轻量级但有效的框架，通过战略性数据工程而非复杂的训练范式来填补这一缺口。我们的方法通过模拟现实生活中的网络搜索环境中的真实用户交互来合成高质量的训练数据，并结合多标准策展策略，优化输入和输出的多样性和质量。横跨五个不同领域的基准实验表明，仅在871个策展样本上进行样本Fine-tuning（SFT）就能显著优于基于强化学习的方法。我们的研究系统地解决了数据稀缺瓶颈，为高效的深度搜索系统提供了实用见解。代码可在以下链接获取：this https URL。', 'title_zh': 'SimpleDeepSearcher: 通过网页驱动的推理轨迹合成实现深度信息检索'}
{'arxiv_id': 'arXiv:2505.16831', 'title': "Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs", 'authors': 'Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du', 'link': 'https://arxiv.org/abs/2505.16831', 'abstract': 'Unlearning in large language models (LLMs) is intended to remove the influence of specific data, yet current evaluations rely heavily on token-level metrics such as accuracy and perplexity. We show that these metrics can be misleading: models often appear to forget, but their original behavior can be rapidly restored with minimal fine-tuning, revealing that unlearning may obscure information rather than erase it. To diagnose this phenomenon, we introduce a representation-level evaluation framework using PCA-based similarity and shift, centered kernel alignment, and Fisher information. Applying this toolkit across six unlearning methods, three domains (text, code, math), and two open-source LLMs, we uncover a critical distinction between reversible and irreversible forgetting. In reversible cases, models suffer token-level collapse yet retain latent features; in irreversible cases, deeper representational damage occurs. We further provide a theoretical account linking shallow weight perturbations near output layers to misleading unlearning signals, and show that reversibility is modulated by task type and hyperparameters. Our findings reveal a fundamental gap in current evaluation practices and establish a new diagnostic foundation for trustworthy unlearning in LLMs. We provide a unified toolkit for analyzing LLM representation changes under unlearning and relearning: this https URL.', 'abstract_zh': '大规模语言模型（LLMs）的遗忘意图是在去除特定数据影响的同时保留其他信息，但当前评估主要依赖于基于令牌级别的指标，如准确率和困惑度。我们表明，这些指标可能会误导：模型在表面上似乎已经忘记，但通过少量微调即可迅速恢复其原始行为，揭示了遗忘可能掩盖信息而非彻底删除信息。为了诊断这一现象，我们引入了一种基于PCA的相似性和偏移、中心核对齐和Fisher信息的表示层面评估框架。应用这一工具包，我们发现可逆遗忘和不可逆遗忘之间的关键区别。在可逆的情况下，模型在基于令牌的层面出现崩溃，但仍保留潜在特征；而在不可逆的情况下，深层表示遭受了更严重的破坏。我们进一步提供了将浅层权重扰动与误导性的遗忘信号联系起来的理论解释，并表明可逆性受任务类型和超参数的调节。我们的发现揭示了当前评估实践中存在的根本缺陷，并建立了规模语言模型可信遗忘的新诊断基础。我们提供了一个统一的工具包来分析语言模型在遗忘和重新学习下的表示变化：这个链接', 'title_zh': '卸载并不等同于删除：探究大语言模型中机器卸载的可逆性'}
{'arxiv_id': 'arXiv:2505.16813', 'title': 'Dynamic Reservoir Computing with Physical Neuromorphic Networks', 'authors': 'Yinhao Xu, Georg A. Gottwald, Zdenka Kuncic', 'link': 'https://arxiv.org/abs/2505.16813', 'abstract': "Reservoir Computing (RC) with physical systems requires an understanding of the underlying structure and internal dynamics of the specific physical reservoir. In this study, physical nano-electronic networks with neuromorphic dynamics are investigated for their use as physical reservoirs in an RC framework. These neuromorphic networks operate as dynamic reservoirs, with node activities in general coupled to the edge dynamics through nonlinear nano-electronic circuit elements, and the reservoir outputs influenced by the underlying network connectivity structure. This study finds that networks with varying degrees of sparsity generate more useful nonlinear temporal outputs for dynamic RC compared to dense networks. Dynamic RC is also tested on an autonomous multivariate chaotic time series prediction task with networks of varying densities, which revealed the importance of network sparsity in maintaining network activity and overall dynamics, that in turn enabled the learning of the chaotic Lorenz63 system's attractor behavior.", 'abstract_zh': '物理系统中的人工神经网络计算（Reservoir Computing with Physical Nano-Electronic Networks and Neuromorphic Dynamics）及其在动态人工神经网络计算框架中的应用', 'title_zh': '物理神经形态网络中的动态 reservoir 计算'}
{'arxiv_id': 'arXiv:2505.16801', 'title': 'A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents', 'authors': 'Eleftherios Kalafatis, Konstantinos Mitsis, Konstantia Zarkogianni, Maria Athanasiou, Konstantina Nikita', 'link': 'https://arxiv.org/abs/2505.16801', 'abstract': "Serious Games (SGs) are nowadays shifting focus to include procedural content generation (PCG) in the development process as a means of offering personalized and enhanced player experience. However, the development of a framework to assess the impact of PCG techniques when integrated into SGs remains particularly challenging. This study proposes a methodology for automated evaluation of PCG integration in SGs, incorporating deep reinforcement learning (DRL) game testing agents. To validate the proposed framework, a previously introduced SG featuring card game mechanics and incorporating three different versions of PCG for nonplayer character (NPC) creation has been deployed. Version 1 features random NPC creation, while versions 2 and 3 utilize a genetic algorithm approach. These versions are used to test the impact of different dynamic SG environments on the proposed framework's agents. The obtained results highlight the superiority of the DRL game testing agents trained on Versions 2 and 3 over those trained on Version 1 in terms of win rate (i.e. number of wins per played games) and training time. More specifically, within the execution of a test emulating regular gameplay, both Versions 2 and 3 peaked at a 97% win rate and achieved statistically significant higher (p=0009) win rates compared to those achieved in Version 1 that peaked at 94%. Overall, results advocate towards the proposed framework's capability to produce meaningful data for the evaluation of procedurally generated content in SGs.", 'abstract_zh': '严肃游戏（SGs）通过引入过程性内容生成（PCG）来开发个性化和增强的游戏体验正逐渐成为主流。然而，开发一种评估PCG技术在SGs中集成影响的框架仍然极具挑战性。本研究提出了一种结合深度强化学习（DRL）游戏测试代理的方法论，以自动评估PCG在SGs中的集成。为了验证提出的框架，使用了一款先前介绍的结合了卡牌游戏机制并在非玩家角色（NPC）创建中采用三种不同PCG版本的严肃游戏。第一版采用随机生成NPC，而第二版和第三版则采用遗传算法的方法。这些版本用于测试不同动态SG环境对提出的框架代理的影响。研究结果表明，在以常规游戏方式执行的测试中，采用第二版和第三版训练的DRL游戏测试代理的胜率（即每场比赛的获胜次数）和训练时间均优于采用第一版训练的代理。具体而言，第二版和第三版在测试中分别达到了97%的胜率，并且与第一版94%的胜率相比，具有统计学意义上的显著差异（p=0.009）。总体而言，结果表明提出的框架能够产生可用于评估SGs中过程性生成内容的有效数据。', 'title_zh': '基于深度强化学习代理的严肃游戏中程序内容生成的自动化评估模块化框架'}
{'arxiv_id': 'arXiv:2505.16798', 'title': 'SEED: Speaker Embedding Enhancement Diffusion Model', 'authors': 'KiHyun Nam, Jungwoo Heo, Jee-weon Jung, Gangin Park, Chaeyoung Jung, Ha-Jin Yu, Joon Son Chung', 'link': 'https://arxiv.org/abs/2505.16798', 'abstract': 'A primary challenge when deploying speaker recognition systems in real-world applications is performance degradation caused by environmental mismatch. We propose a diffusion-based method that takes speaker embeddings extracted from a pre-trained speaker recognition model and generates refined embeddings. For training, our approach progressively adds Gaussian noise to both clean and noisy speaker embeddings extracted from clean and noisy speech, respectively, via forward process of a diffusion model, and then reconstructs them to clean embeddings in the reverse process. While inferencing, all embeddings are regenerated via diffusion process. Our method needs neither speaker label nor any modification to the existing speaker recognition pipeline. Experiments on evaluation sets simulating environment mismatch scenarios show that our method can improve recognition accuracy by up to 19.6% over baseline models while retaining performance on conventional scenarios. We publish our code here this https URL', 'abstract_zh': '在实际应用中部署说话人识别系统的主要挑战是由于环境不匹配导致的性能下降。我们提出了一种基于扩散的方法，该方法从预训练的说话人识别模型中提取说话人嵌入，并生成精炼的嵌入。在训练过程中，我们的方法通过扩散模型的前向过程，逐步将高斯噪声添加到分别从干净语音和噪声语音中提取的干净和噪声说话人嵌入中，并在反向过程中重建它们为干净嵌入。在推理过程中，所有嵌入都通过扩散过程再生。该方法既不需要说话人标签，也不需要修改现有的说话人识别管道。在模拟环境不匹配场景的评估集上进行的实验表明，与基线模型相比，我们的方法可以在保持传统场景性能的同时将识别准确性提升多达19.6%。我们在这里发布了我们的代码：https://github.com/username/repo', 'title_zh': 'SEED: 言语嵌入增强扩散模型'}
{'arxiv_id': 'arXiv:2505.16792', 'title': "REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training", 'authors': 'Ziqiao Wang, Wangbo Zhao, Yuhao Zhou, Zekai Li, Zhiyuan Liang, Mingjia Shi, Xuanlei Zhao, Pengfei Zhou, Kaipeng Zhang, Zhangyang Wang, Kai Wang, Yang You', 'link': 'https://arxiv.org/abs/2505.16792', 'abstract': "Diffusion Transformers (DiTs) deliver state-of-the-art image quality, yet their training remains notoriously slow. A recent remedy -- representation alignment (REPA) that matches DiT hidden features to those of a non-generative teacher (e.g. DINO) -- dramatically accelerates the early epochs but plateaus or even degrades performance later. We trace this failure to a capacity mismatch: once the generative student begins modelling the joint data distribution, the teacher's lower-dimensional embeddings and attention patterns become a straitjacket rather than a guide. We then introduce HASTE (Holistic Alignment with Stage-wise Termination for Efficient training), a two-phase schedule that keeps the help and drops the hindrance. Phase I applies a holistic alignment loss that simultaneously distills attention maps (relational priors) and feature projections (semantic anchors) from the teacher into mid-level layers of the DiT, yielding rapid convergence. Phase II then performs one-shot termination that deactivates the alignment loss, once a simple trigger such as a fixed iteration is hit, freeing the DiT to focus on denoising and exploit its generative capacity. HASTE speeds up training of diverse DiTs without architecture changes. On ImageNet 256X256, it reaches the vanilla SiT-XL/2 baseline FID in 50 epochs and matches REPA's best FID in 500 epochs, amounting to a 28X reduction in optimization steps. HASTE also improves text-to-image DiTs on MS-COCO, demonstrating to be a simple yet principled recipe for efficient diffusion training across various tasks. Our code is available at this https URL .", 'abstract_zh': '扩散变换器(DiTs)提供了最先进的图像质量，但其训练仍然极度缓慢。一种近期的解决方案——表示对齐(REPA)，能够在早期阶段显著加速训练，但在之后的阶段则会停滞或甚至降低性能。我们将其失败归因于容量不匹配：一旦生成性学生开始建模联合数据分布，教师较低维度的嵌入和注意力模式反而成为了束缚而非指导。然后，我们提出了HASTE（全方位对齐与阶段终止以提高训练效率），这是一种两阶段的时间表，它保持帮助并放弃阻碍。第一阶段应用了全方位对齐损失，同时从教师中蒸馏出注意力图（关系先验）和特征投影（语义锚点）到DiT的中间层，实现快速收敛。第二阶段则进行了单次终止，一旦触发一个简单的条件（如固定迭代次数），就禁用对齐损失，释放DiT专注于降噪并利用其生成能力。HASTE在不改变架构的情况下加快了各种DiTs的训练。在ImageNet 256X256上，它在50个周期内达到了vanilla SiT-XL/2基线的FID，并在500个周期内匹配了REPA最佳的FID，相当于减少了28倍的优化步骤。HASTE还改进了MS-COCO上的文本到图像DiTs，展示了它是针对各种任务实现高效扩散训练的一个简单而原理性的配方。我们的代码可在以下链接获取。', 'title_zh': 'REPA在不再有效时依旧奏效：早停的整体对齐增强扩散训练'}
{'arxiv_id': 'arXiv:2505.16791', 'title': 'Cohort-Based Active Modality Acquisition', 'authors': 'Tillmann Rheude, Roland Eils, Benjamin Wild', 'link': 'https://arxiv.org/abs/2505.16791', 'abstract': 'Real-world machine learning applications often involve data from multiple modalities that must be integrated effectively to make robust predictions. However, in many practical settings, not all modalities are available for every sample, and acquiring additional modalities can be costly. This raises the question: which samples should be prioritized for additional modality acquisition when resources are limited? While prior work has explored individual-level acquisition strategies and training-time active learning paradigms, test-time and cohort-based acquisition remain underexplored despite their importance in many real-world settings. We introduce Cohort-based Active Modality Acquisition (CAMA), a novel test-time setting to formalize the challenge of selecting which samples should receive additional modalities. We derive acquisition strategies that leverage a combination of generative imputation and discriminative modeling to estimate the expected benefit of acquiring missing modalities based on common evaluation metrics. We also introduce upper-bound heuristics that provide performance ceilings to benchmark acquisition strategies. Experiments on common multimodal datasets demonstrate that our proposed imputation-based strategies can more effectively guide the acquisition of new samples in comparison to those relying solely on unimodal information, entropy guidance, and random selections. Our work provides an effective solution for optimizing modality acquisition at the cohort level, enabling better utilization of resources in constrained settings.', 'abstract_zh': '基于群体的主动模态获取（CAMA）：实世界多模态数据的测试时选择策略', 'title_zh': '基于群体的主动模态 acquisition'}
{'arxiv_id': 'arXiv:2505.16790', 'title': 'Learning Flexible Forward Trajectories for Masked Molecular Diffusion', 'authors': 'Hyunjin Seo, Taewon Kim, Sihyun Yu, SungSoo Ahn', 'link': 'https://arxiv.org/abs/2505.16790', 'abstract': 'Masked diffusion models (MDMs) have achieved notable progress in modeling discrete data, while their potential in molecular generation remains underexplored. In this work, we explore their potential and introduce the surprising result that naively applying standards MDMs severely degrades the performance. We identify the critical cause of this issue as a state-clashing problem-where the forward diffusion of distinct molecules collapse into a common state, resulting in a mixture of reconstruction targets that cannot be learned using typical reverse diffusion process with unimodal predictions. To mitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that orchestrates per-element corruption trajectories to avoid collision between distinct molecular graphs. This is achieved through a parameterized noise scheduling network that assigns distinct corruption rates to individual graph elements, i.e., atoms and bonds. Extensive experiments on diverse molecular benchmarks reveal that MELD markedly enhances overall generation quality compared to element-agnostic noise scheduling, increasing the chemical validity of vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves state-of-the-art property alignment in conditional generation tasks.', 'abstract_zh': '掩码扩散模型在分子生成领域的潜力尚未充分探索。在此工作中，我们探索了其潜力，并引入了一个令人惊讶的结果，即直接应用标准掩码扩散模型显著降低了性能。我们识别出这一问题的关键原因是状态冲突问题——不同的分子在前向扩散过程中坍缩到一个共同状态，导致无法使用典型的具有单模预测的逆向扩散过程来学习混合的重构目标。为缓解这一问题，我们提出了掩码元素级可学习扩散（MELD），通过调控每个元素的破坏轨迹来避免不同的分子图之间的碰撞。这通过一个参数化的噪声调度网络实现，该网络为单个图元素（即原子和键）分配不同的破坏率。在多种分子基准上的广泛实验表明，与元素无关的噪声调度相比，MELD 明显提高了整体生成质量，将 ZINC250K 上 vanilla MDM 的化学有效性从 15% 提高到 93%。此外，它在条件生成任务中达到了最先进的属性对齐效果。', 'title_zh': '学习灵活的掩码分子扩散前向轨迹'}
{'arxiv_id': 'arXiv:2505.16789', 'title': 'Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability', 'authors': 'Punya Syon Pandey, Samuel Simko, Kellin Pelrine, Zhijing Jin', 'link': 'https://arxiv.org/abs/2505.16789', 'abstract': 'As large language models gain popularity, their vulnerability to adversarial attacks remains a primary concern. While fine-tuning models on domain-specific datasets is often employed to improve model performance, it can introduce vulnerabilities within the underlying model. In this work, we investigate Accidental Misalignment, unexpected vulnerabilities arising from characteristics of fine-tuning data. We begin by identifying potential correlation factors such as linguistic features, semantic similarity, and toxicity within our experimental datasets. We then evaluate the adversarial performance of these fine-tuned models and assess how dataset factors correlate with attack success rates. Lastly, we explore potential causal links, offering new insights into adversarial defense strategies and highlighting the crucial role of dataset design in preserving model alignment. Our code is available at this https URL.', 'abstract_zh': '随着大型语言模型的流行，它们对对抗攻击的脆弱性仍然是主要关切。虽然在领域特定数据集上进行微调以提高模型性能是一种常见做法，但这可能会在底层模型中引入脆弱性。在本文中，我们研究了由微调数据特性引发的意外失准问题。我们首先识别潜在的相关因素，如语言特征、语义相似性和毒性。然后评估这些微调模型的对抗性能，并评估数据集因素与攻击成功率之间的关联性。最后，我们探索潜在的因果关系，提供了对抗防御策略的新见解，并强调了数据集设计在保持模型对齐方面的重要作用。我们的代码可在以下链接获取：this https URL。', 'title_zh': '意外的不对齐：语言模型微调诱导出意外的脆弱性'}
{'arxiv_id': 'arXiv:2505.16785', 'title': 'CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models', 'authors': 'Zhenzhen Ren, GuoBiao Li, Sheng Li, Zhenxing Qian, Xinpeng Zhang', 'link': 'https://arxiv.org/abs/2505.16785', 'abstract': 'Despite providing superior performance, open-source large language models (LLMs) are vulnerable to abusive usage. To address this issue, recent works propose LLM fingerprinting methods to identify the specific source LLMs behind suspect applications. However, these methods fail to provide stealthy and robust fingerprint verification. In this paper, we propose a novel LLM fingerprinting scheme, namely CoTSRF, which utilizes the Chain of Thought (CoT) as the fingerprint of an LLM. CoTSRF first collects the responses from the source LLM by querying it with crafted CoT queries. Then, it applies contrastive learning to train a CoT extractor that extracts the CoT feature (i.e., fingerprint) from the responses. Finally, CoTSRF conducts fingerprint verification by comparing the Kullback-Leibler divergence between the CoT features of the source and suspect LLMs against an empirical threshold. Various experiments have been conducted to demonstrate the advantage of our proposed CoTSRF for fingerprinting LLMs, particularly in stealthy and robust fingerprint verification.', 'abstract_zh': '尽管开源大型语言模型（LLM）性能优越，但极易遭受滥用。为应对这一问题，近期的研究提出了一种LLM指纹识别方法，以确定嫌疑应用程序背后的特定源LLM。然而，这些方法未能提供隐蔽且 robust 的指纹验证方法。本文提出了一种新颖的LLM指纹识别方案，即CoTSRF，该方案利用Chain of Thought（CoT）作为LLM的指纹。CoTSRF首先通过定制的CoT查询收集源LLM的响应，然后应用对比学习训练一个CoT提取器，从响应中提取CoT特征（即指纹）。最后，CoTSRF通过将源LLM和嫌疑LLM的CoT特征的Kullback-Leibler距离与经验阈值进行比较来进行指纹验证。各种实验表明，CoTSRF在隐蔽和robust的指纹验证方面具有显著优势。', 'title_zh': 'CoTSRF: 将思维链作为大型语言模型隐蔽且 robust 的指纹rolloater'}
{'arxiv_id': 'arXiv:2505.16773', 'title': 'Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis', 'authors': 'Iván Matas, Carmen Serrano, Miguel Nogales, David Moreno, Lara Ferrándiz, Teresa Ojeda, Begoña Acha', 'link': 'https://arxiv.org/abs/2505.16773', 'abstract': 'Deep learning has transformed computer vision but relies heavily on large labeled datasets and computational resources. Transfer learning, particularly fine-tuning pretrained models, offers a practical alternative; however, models pretrained on natural image datasets such as ImageNet may fail to capture domain-specific characteristics in medical imaging. This study introduces an unsupervised learning framework that extracts high-value dermatological features instead of relying solely on ImageNet-based pretraining. We employ a Variational Autoencoder (VAE) trained from scratch on a proprietary dermatological dataset, allowing the model to learn a structured and clinically relevant latent space. This self-supervised feature extractor is then compared to an ImageNet-pretrained backbone under identical classification conditions, highlighting the trade-offs between general-purpose and domain-specific pretraining. Our results reveal distinct learning patterns. The self-supervised model achieves a final validation loss of 0.110 (-33.33%), while the ImageNet-pretrained model stagnates at 0.100 (-16.67%), indicating overfitting. Accuracy trends confirm this: the self-supervised model improves from 45% to 65% (+44.44%) with a near-zero overfitting gap, whereas the ImageNet-pretrained model reaches 87% (+50.00%) but plateaus at 75% (+19.05%), with its overfitting gap increasing to +0.060. These findings suggest that while ImageNet pretraining accelerates convergence, it also amplifies overfitting on non-clinically relevant features. In contrast, self-supervised learning achieves steady improvements, stronger generalization, and superior adaptability, underscoring the importance of domain-specific feature extraction in medical imaging.', 'abstract_zh': '深度学习已变革计算机视觉，但依赖大量标注数据和计算资源。迁移学习，尤其是微调预训练模型，提供了一种实用的选择；然而，基于自然图像数据集（如ImageNet）预训练的模型可能无法捕捉医学影像中的领域特定特征。本研究引入了一种无监督学习框架，提取高价值的皮肤病学特征，而非仅仅依赖于ImageNet预训练。我们采用从一个专用皮肤病学数据集从零开始训练的变分自编码器（VAE），使模型能够学习一个结构化和临床相关的潜在空间。随后，该自监督特征提取器与在ImageNet上预训练的骨干网络在相同的分类条件下进行比较，突显通用预训练和领域特定预训练之间的权衡。我们的结果显示不同的学习模式。自监督模型在最终验证损失为0.110（-33.33%），而基于ImageNet预训练的模型停滞在0.100（-16.67%），表明过拟合现象。准确率趋势也证实了这一点：自监督模型从45%提高到65%（+44.44%），几乎无过拟合差距，而基于ImageNet预训练的模型达到87%（+50.00%），但停滞在75%（+19.05%），其过拟合差距增加到+0.060。这些发现表明虽然ImageNet预训练加速了收敛，但也放大了对非临床相关特征的过拟合现象。相比之下，自监督学习实现了稳定改进、更强的泛化能力和更优的适应性，突显了在医学影像中领域特定特征提取的重要性。', 'title_zh': '医学影像中的过拟合缓解：皮肤科诊断中自我监督预训练与ImageNet迁移学习的比较'}
{'arxiv_id': 'arXiv:2505.16765', 'title': "When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques", 'authors': 'Jianing Geng, Biao Yi, Zekun Fei, Tongxi Wu, Lihai Nie, Zheli Liu', 'link': 'https://arxiv.org/abs/2505.16765', 'abstract': 'Jailbreak attacks pose a serious threat to large language models (LLMs) by bypassing built-in safety mechanisms and leading to harmful outputs. Studying these attacks is crucial for identifying vulnerabilities and improving model security. This paper presents a systematic survey of jailbreak methods from the novel perspective of stealth. We find that existing attacks struggle to simultaneously achieve toxic stealth (concealing toxic content) and linguistic stealth (maintaining linguistic naturalness). Motivated by this, we propose StegoAttack, a fully stealthy jailbreak attack that uses steganography to hide the harmful query within benign, semantically coherent text. The attack then prompts the LLM to extract the hidden query and respond in an encrypted manner. This approach effectively hides malicious intent while preserving naturalness, allowing it to evade both built-in and external safety mechanisms. We evaluate StegoAttack on four safety-aligned LLMs from major providers, benchmarking against eight state-of-the-art methods. StegoAttack achieves an average attack success rate (ASR) of 92.00%, outperforming the strongest baseline by 11.0%. Its ASR drops by less than 1% even under external detection (e.g., Llama Guard). Moreover, it attains the optimal comprehensive scores on stealth detection metrics, demonstrating both high efficacy and exceptional stealth capabilities. The code is available at this https URL', 'abstract_zh': 'Jailbreak攻击对大型语言模型（LLMs）构成严重威胁，通过绕过内置的安全机制并导致有害输出。研究这些攻击对于识别漏洞和改善模型安全性至关重要。本文从隐蔽性的新颖视角系统总结了 Jailbreak 方法。我们发现现有的攻击难以同时实现有毒隐蔽（隐藏有毒内容）和语言隐蔽（保持语言自然性）。受此启发，我们提出了 StegoAttack，这是一种完全隐蔽的 Jailbreak 攻击，利用隐写术将有害查询隐藏在 benign、语义一致的文本中。攻击随后促使LLM提取隐藏查询并以加密方式响应。该方法有效地隐藏了恶意意图的同时保留了自然性，使其能够避开内置和外部安全机制。我们在来自主要提供商的四种安全对齐的LLM上评估了StegoAttack，并将其与八种最先进的方法进行了基准测试。StegoAttack实现了平均攻击成功率（ASR）为92.00%，比最强基准高11.0%。即使在外部检测下（例如，Llama Guard），其ASR也仅下降不到1%。此外，它在隐蔽性检测指标上取得了最优综合得分，展示了高效性和卓越的隐蔽性能力。代码可在以下链接获取。', 'title_zh': '当安全检测器不够用时：通过隐写技术对大语言模型进行隐蔽而有效的越狱攻击'}
{'arxiv_id': 'arXiv:2505.16752', 'title': 'Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation', 'authors': 'Hao Guo, Erpeng Xue, Lei Huang, Shichao Wang, Xiaolei Wang, Lei Wang, Jinpeng Wang, Sheng Chen', 'link': 'https://arxiv.org/abs/2505.16752', 'abstract': "We introduce the Dual-Flow Generative Ranking Network (DFGR), a two-stream architecture designed for recommendation systems. DFGR integrates innovative interaction patterns between real and fake flows within the QKV modules of the self-attention mechanism, enhancing both training and inference efficiency. This approach effectively addresses a key limitation observed in Meta's proposed HSTU generative recommendation approach, where heterogeneous information volumes are mapped into identical vector spaces, leading to training instability. Unlike traditional recommendation models, DFGR only relies on user history behavior sequences and minimal attribute information, eliminating the need for extensive manual feature engineering. Comprehensive evaluations on open-source and industrial datasets reveal DFGR's superior performance compared to established baselines such as DIN, DCN, DIEN, and DeepFM. We also investigate optimal parameter allocation strategies under computational constraints, establishing DFGR as an efficient and effective next-generation generate ranking paradigm.", 'abstract_zh': '双流生成排名网络（DFGR）：一种针对推荐系统的设计结构', 'title_zh': '只需行动：基于双流生成排序网络的推荐'}
{'arxiv_id': 'arXiv:2505.16743', 'title': 'TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning', 'authors': 'Florentin Beck, William Rudman, Carsten Eickhoff', 'link': 'https://arxiv.org/abs/2505.16743', 'abstract': 'Large Language Models (LLMs) present significant computational and memory challenges due to their extensive size, making pruning essential for their efficient deployment. Existing one-shot pruning methods often apply uniform sparsity constraints across layers or within each layer, resulting in suboptimal performance, especially at high sparsity ratios. This work introduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel approach that applies varying sparsity ratios to individual output dimensions (rows) within each layer. TRIM employs an iterative adjustment process guided by quality metrics to optimize dimension-wise sparsity allocation, focusing on reducing variance in quality retention across outputs to preserve critical information. TRIM can be seamlessly integrated with existing layer-wise pruning strategies. Our evaluations on perplexity and zero-shot tasks across diverse LLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that TRIM achieves new state-of-the-art results and enhances stability. For instance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and over 90% for OPT-13B compared to baseline methods. We conclude that fine-grained, dimension-wise sparsity adaptation is crucial for pushing the limits of extreme LLM compression. Code available at: this https URL', 'abstract_zh': '针对大规模语言模型的逐行迭代度量驱动剪枝(TRIM)：细粒度的维度-wise稀疏性适配对于极致压缩大语言模型至关重要', 'title_zh': 'TRIM: 实现目标行 wise 迭代度量驱动稀疏性的极度压缩'}
{'arxiv_id': 'arXiv:2505.16740', 'title': 'Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP', 'authors': 'Alya Zouzou, Léo andéol, Mélanie Ducoffe, Ryma Boumazouza', 'link': 'https://arxiv.org/abs/2505.16740', 'abstract': 'We explore the use of conformal prediction to provide statistical uncertainty guarantees for runway detection in vision-based landing systems (VLS). Using fine-tuned YOLOv5 and YOLOv6 models on aerial imagery, we apply conformal prediction to quantify localization reliability under user-defined risk levels. We also introduce Conformal mean Average Precision (C-mAP), a novel metric aligning object detection performance with conformal guarantees. Our results show that conformal prediction can improve the reliability of runway detection by quantifying uncertainty in a statistically sound way, increasing safety on-board and paving the way for certification of ML system in the aerospace domain.', 'abstract_zh': '我们探索使用共形预测为基于视觉的着陆系统（VLS）中的跑道检测提供统计不确定性保证。我们通过在航空航天图像上微调YOLOv5和YOLOv6模型，并应用共形预测来在用户定义的风险水平下量化定位可靠性。我们还引入了共形均值平均精确度（C-mAP），这是一种将目标检测性能与共形保证相契合的新指标。我们的结果表明，共形预测可以通过以统计学上合理的方式量化不确定性来提高跑道检测的可靠性，从而增强机载安全并为航空航天领域中的ML系统认证铺平道路。', 'title_zh': '基于先验校准的鲁棒视景跑道检测与Conformal mAP'}
{'arxiv_id': 'arXiv:2505.16737', 'title': 'Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization', 'authors': 'Chengcan Wu, Zhixin Zhang, Zeming Wei, Yihao Zhang, Meng Sun', 'link': 'https://arxiv.org/abs/2505.16737', 'abstract': "The significant progress of large language models (LLMs) has led to remarkable achievements across numerous applications. However, their ability to generate harmful content has sparked substantial safety concerns. Despite the implementation of safety alignment techniques during the pre-training phase, recent research indicates that fine-tuning LLMs on adversarial or even benign data can inadvertently compromise their safety. In this paper, we re-examine the fundamental issue of why fine-tuning on non-harmful data still results in safety degradation. We introduce a safety-aware probing (SAP) optimization framework designed to mitigate the safety risks of fine-tuning LLMs. Specifically, SAP incorporates a safety-aware probe into the gradient propagation process, mitigating the model's risk of safety degradation by identifying potential pitfalls in gradient directions, thereby enhancing task-specific performance while successfully preserving model safety. Our extensive experimental results demonstrate that SAP effectively reduces harmfulness below the original fine-tuned model and achieves comparable test loss to standard fine-tuning methods. Our code is available at this https URL.", 'abstract_zh': '大型语言模型（LLMs）的重要进展已经在众多应用中取得了显著成果，然而其生成有害内容的能力引发了重大安全关切。尽管在预训练阶段实施了安全对齐技术，近期研究显示，对LLMs进行对抗性或甚至良性数据微调仍然可能导致安全降级。在本文中，我们重新审视了尽管使用非有害数据进行微调但仍导致安全降级的根本原因。我们提出了一种安全感知探针（SAP）优化框架，旨在减轻对LLMs进行微调的安全风险。具体而言，SAP将安全感知探针融入梯度传播过程，通过识别梯度方向中的潜在风险来降低模型的安全降级风险，从而在增强任务特定性能的同时成功保持模型安全。我们的大量实验结果表明，SAP有效减少了有害性并达到了与标准微调方法相当的测试损失。我们的代码可在以下链接获取：this https URL。', 'title_zh': '通过安全意识探查优化缓解大语言模型微调风险'}
{'arxiv_id': 'arXiv:2505.16735', 'title': 'Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting', 'authors': 'Youngmoon Jung, Yong-Hyeok Lee, Myunghun Jung, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho', 'link': 'https://arxiv.org/abs/2505.16735', 'abstract': 'For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic and text embeddings are typically compared at either the phoneme or utterance level. To facilitate this, we optimize acoustic and text encoders using deep metric learning (DML), enabling direct comparison of multi-modal embeddings in a shared embedding space. However, the inherent heterogeneity between audio and text modalities presents a significant challenge. To address this, we propose Modality Adversarial Learning (MAL), which reduces the domain gap in heterogeneous modality representations. Specifically, we train a modality classifier adversarially to encourage both encoders to generate modality-invariant embeddings. Additionally, we apply DML to achieve phoneme-level alignment between audio and text, and conduct comprehensive comparisons across various DML objectives. Experiments on the Wall Street Journal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the proposed approach.', 'abstract_zh': '基于文本注册的开放词汇关键词 spotting (KWS) 中，声学和文本嵌入通常在音素或语句水平上进行比较。为了促进这一点，我们使用深度度量学习（DML）优化声学和文本编码器，从而在共享嵌入空间中直接比较多模态嵌入。然而，音频和文本模态之间的固有异质性提出了一个重大挑战。为了解决这个问题，我们提出了一种模态对抗学习（MAL），以减少异质模态表示之间的领域差距。具体来说，我们通过对抗训练模态分类器，鼓励两个编码器生成模态不变嵌入。此外，我们应用DML在音频和文本之间实现音素级别对齐，并在多种DML目标下进行全面比较。在Wall Street Journal（WSJ）和LibriPhrase数据集上的实验表明所提出方法的有效性。', 'title_zh': '面向开放词汇关键词识别的对抗深度度量学习的跨模态音频-文本对齐'}
{'arxiv_id': 'arXiv:2505.16732', 'title': 'Sequential Monte Carlo for Policy Optimization in Continuous POMDPs', 'authors': 'Hany Abdulsamad, Sahel Iqbal, Simo Särkkä', 'link': 'https://arxiv.org/abs/2505.16732', 'abstract': 'Optimal decision-making under partial observability requires agents to balance reducing uncertainty (exploration) against pursuing immediate objectives (exploitation). In this paper, we introduce a novel policy optimization framework for continuous partially observable Markov decision processes (POMDPs) that explicitly addresses this challenge. Our method casts policy learning as probabilistic inference in a non-Markovian Feynman--Kac model that inherently captures the value of information gathering by anticipating future observations, without requiring extrinsic exploration bonuses or handcrafted heuristics. To optimize policies under this model, we develop a nested sequential Monte Carlo~(SMC) algorithm that efficiently estimates a history-dependent policy gradient under samples from the optimal trajectory distribution induced by the POMDP. We demonstrate the effectiveness of our algorithm across standard continuous POMDP benchmarks, where existing methods struggle to act under uncertainty.', 'abstract_zh': '部分可观测条件下最优决策要求智能体在降低不确定性（探索）与追求即时目标（利用）之间取得平衡。本文介绍了一种新的连续部分可观测马尔可夫决策过程（POMDP）的策略优化框架，该框架明确解决了上述挑战。我们的方法将策略学习视为非马尔可夫费曼-卡克模型中的概率推理问题，该模型本身能够通过预见未来的观测结果来捕获信息收集的价值，无需额外的探索奖励或手工设计的启发式方法。为了在该模型下优化策略，我们开发了一种嵌套顺序蒙特卡罗（SMC）算法，该算法能够高效地在由POMDP诱导的最优轨迹分布的样本下估计依赖历史的策略梯度。我们在标准连续POMDP基准测试中展示了该算法的有效性，而现有方法在不确定性下很难采取行动。', 'title_zh': '连续部分可观测马尔可夫决策过程的顺序蒙特卡洛策略优化'}
{'arxiv_id': 'arXiv:2505.16724', 'title': 'Advancing Brainwave Modeling with a Codebook-Based Foundation Model', 'authors': 'Konstantinos Barmpas, Na Lee, Yannis Panagakis, Dimitrios A. Adamos, Nikolaos Laskaris, Stefanos Zafeiriou', 'link': 'https://arxiv.org/abs/2505.16724', 'abstract': 'Recent advances in large-scale pre-trained Electroencephalogram (EEG) models have shown great promise, driving progress in Brain-Computer Interfaces (BCIs) and healthcare applications. However, despite their success, many existing pre-trained models have struggled to fully capture the rich information content of neural oscillations, a limitation that fundamentally constrains their performance and generalizability across diverse BCI tasks. This limitation is frequently rooted in suboptimal architectural design choices which constrain their representational capacity. In this work, we introduce LaBraM++, an enhanced Large Brainwave Foundation Model (LBM) that incorporates principled improvements grounded in robust signal processing foundations. LaBraM++ demonstrates substantial gains across a variety of tasks, consistently outperforming its originally-based architecture and achieving competitive results when compared to other open-source LBMs. Its superior performance and training efficiency highlight its potential as a strong foundation for future advancements in LBMs.', 'abstract_zh': 'Recent Advances in Large-Scale Pre-Trained Electroencephalogram (EEG) Models Have Shown Great Promise in Driving Progress in Brain-Computer Interfaces (BCIs) and Healthcare Applications: However, Many Existing Pre-Trained Models Struggle to Fully Capture the Rich Information Content of Neural Oscillations, Limiting Their Performance and Generalizability Across Diverse BCI Tasks. This Limitation is Frequently Rooted in Suboptimal Architectural Design Choices Constraining Their Representational Capacity. In This Work, We Introduce LaBraM++, an Enhanced Large Brainwave Foundation Model (LBM) That Incorporates Principled Improvements Grounded in Robust Signal Processing Foundations. LaBraM++ Demonstrates Substantial Gains Across a Variety of Tasks, Consistently Outperforming Its Originally Based Architecture and Achieving Competitive Results When Compared to Other Open-Source LBMs. Its Superior Performance and Training Efficiency Highlight Its Potential as a Strong Foundation for Future Advancements in LBMs。', 'title_zh': '基于码本基础模型的脑电波建模进展'}
{'arxiv_id': 'arXiv:2505.16722', 'title': 'Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification', 'authors': 'Himanshu Beniwal, Youngwoo Kim, Maarten Sap, Soham Dan, Thomas Hartvigsen', 'link': 'https://arxiv.org/abs/2505.16722', 'abstract': 'As large language models (LLMs) become increasingly prevalent in global applications, ensuring that they are toxicity-free across diverse linguistic contexts remains a critical challenge. We explore "Cross-lingual Detoxification", a cross-lingual paradigm that mitigates toxicity, enabling detoxification capabilities to transfer between high and low-resource languages across different script families. We analyze cross-lingual detoxification\'s effectiveness through 504 extensive settings to evaluate toxicity reduction in cross-distribution settings with limited data and investigate how mitigation impacts model performance on non-toxic tasks, revealing trade-offs between safety and knowledge preservation. Our code and dataset are publicly available at this https URL.', 'abstract_zh': '跨语言去毒研究：一种在不同文字体系的高资源和低资源语言之间转移去毒能力的跨语言 paradigm', 'title_zh': '打破mBad！监督微调在跨语言去污中的应用'}
{'arxiv_id': 'arXiv:2505.16710', 'title': 'Training Long-Context LLMs Efficiently via Chunk-wise Optimization', 'authors': 'Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji', 'link': 'https://arxiv.org/abs/2505.16710', 'abstract': "While long-context large language models (LLMs) exhibit remarkable document processing capabilities, their prohibitively high training costs often hinder customized applications. To mitigate this issue, we propose \\textit{Sequential Chunk-wise Optimization} (SeCO), a memory-efficient training paradigm that partitions lengthy inputs into manageable chunks. Each chunk independently constructs its computational graph and performs localized backpropagation, ensuring that only one chunk's forward activations are stored in memory. Building on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization} (SpaCO), which reduces computational overhead by selectively propagating gradients to specific chunks and incorporates a carefully designed compensation factor to ensure unbiased gradient estimation. SpaCO decouples the computational cost of backpropagation from the context length, enabling training time to gradually converge to inference time as sequences become longer. Implemented as lightweight training wrappers, both SeCO and SpaCO offer substantial practical benefits. For example, when fine-tuning an 8B model with LoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to 16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up to 3x faster than SeCO under the same experimental setup. These innovations provide new insights into optimizing long-context models, making them more accessible for practical applications. We have open-sourced the code at \\href{this https URL}{here}.", 'abstract_zh': '长上下文大型语言模型展现出卓越的文档处理能力，但由于高昂的训练成本常常限制了定制化应用。为缓解这一问题，我们提出了 Sequential Chunk-wise Optimization (SeCO)——一种内存高效的训练范式，将长输入分割为可管理的片段。每个片段独立构建计算图并执行局部反向传播，确保仅存储一个片段的前向激活。在此基础上，我们进一步引入 Sparse Chunk-wise Optimization (SpaCO)，通过选择性地将梯度传播到特定片段来减少计算开销，并结合精心设计的补偿因子以确保无偏的梯度估计。SpaCO 将反向传播的计算成本与上下文长度解耦，使训练时间随着序列变长逐渐收敛至推理时间。作为轻量级训练包装器，SeCO 和 SpaCO 提供了显著的实际益处。例如，在使用 LoRA 对一个 8B 模型进行微调时，SeCO 将最大序列长度从 1K 扩展至 16K 令牌，而 SpaCO 在相同的实验设置下展示了加速的训练速度，比 SeCO 快至 3 倍。这些创新为优化长上下文模型提供了新的思路，使它们更能适用于实际应用。我们已将代码开源在 [这里](this https URL)。', 'title_zh': '通过分块优化高效训练长上下文LLMs'}
{'arxiv_id': 'arXiv:2505.16705', 'title': 'An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations', 'authors': 'Seonghwan Park, Jueun Mun, Donghyun Oh, Namhoon Lee', 'link': 'https://arxiv.org/abs/2505.16705', 'abstract': 'Concept bottleneck models (CBMs) ensure interpretability by decomposing predictions into human interpretable concepts. Yet the annotations used for training CBMs that enable this transparency are often noisy, and the impact of such corruption is not well understood. In this study, we present the first systematic study of noise in CBMs and show that even moderate corruption simultaneously impairs prediction performance, interpretability, and the intervention effectiveness. Our analysis identifies a susceptible subset of concepts whose accuracy declines far more than the average gap between noisy and clean supervision and whose corruption accounts for most performance loss. To mitigate this vulnerability we propose a two-stage framework. During training, sharpness-aware minimization stabilizes the learning of noise-sensitive concepts. During inference, where clean labels are unavailable, we rank concepts by predictive entropy and correct only the most uncertain ones, using uncertainty as a proxy for susceptibility. Theoretical analysis and extensive ablations elucidate why sharpness-aware training confers robustness and why uncertainty reliably identifies susceptible concepts, providing a principled basis that preserves both interpretability and resilience in the presence of noise.', 'abstract_zh': '概念瓶颈模型中噪声的系统研究及其缓解方法', 'title_zh': '概念瓶颈模型的分析：衡量、理解及其对嘈杂标注影响的缓解'}
{'arxiv_id': 'arXiv:2505.16694', 'title': 'Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence', 'authors': 'Gouki Minegishi, Hiroki Furuta, Shohei Taniguchi, Yusuke Iwasawa, Yutaka Matsuo', 'link': 'https://arxiv.org/abs/2505.16694', 'abstract': "Transformer-based language models exhibit In-Context Learning (ICL), where predictions are made adaptively based on context. While prior work links induction heads to ICL through a sudden jump in accuracy, this can only account for ICL when the answer is included within the context. However, an important property of practical ICL in large language models is the ability to meta-learn how to solve tasks from context, rather than just copying answers from context; how such an ability is obtained during training is largely unexplored. In this paper, we experimentally clarify how such meta-learning ability is acquired by analyzing the dynamics of the model's circuit during training. Specifically, we extend the copy task from previous research into an In-Context Meta Learning setting, where models must infer a task from examples to answer queries. Interestingly, in this setting, we find that there are multiple phases in the process of acquiring such abilities, and that a unique circuit emerges in each phase, contrasting with the single-phases change in induction heads. The emergence of such circuits can be related to several phenomena known in large language models, and our analysis lead to a deeper understanding of the source of the transformer's ICL ability.", 'abstract_zh': '基于Transformer的语言模型表现出的内省式学习（ICL），其中预测是根据上下文自适应地做出的。尽管先前的工作通过准确性的突然飞跃将归纳头与ICL联系起来，这只能解释当答案包含在上下文中时的ICL现象。然而，实际大型语言模型中的ICL的一个重要特性是其解决任务的能力是通过上下文进行元学习获得的，而不仅仅是从上下文中复制答案；这一能力在训练过程中是如何获得的仍然鲜有探讨。在本文中，我们通过分析模型电路在训练过程中的动态性，实验证实了这种元学习能力是如何获得的。具体而言，我们将复制任务扩展为一个内省式元学习环境，在这种环境中，模型必须从示例中推断出任务以回答查询。有趣的是，在这种环境中，我们发现获得此类能力的过程存在多个阶段，并且每个阶段会出现一个独特的电路，这与归纳头的单阶段变化相反。这些电路的出现与已知的大型语言模型中的几种现象有关，而我们的分析加深了对变压器ICL能力来源的理解。', 'title_zh': '超越归纳头部：上下文内元学习诱导多阶段电路 emergence'}
{'arxiv_id': 'arXiv:2505.16691', 'title': 'EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion', 'authors': 'Advait Joglekar, Divyanshu Singh, Rooshil Rohit Bhatia, S. Umesh', 'link': 'https://arxiv.org/abs/2505.16691', 'abstract': 'Voice Conversion research in recent times has increasingly focused on improving the zero-shot capabilities of existing methods. Despite remarkable advancements, current architectures still tend to struggle in zero-shot cross-lingual settings. They are also often unable to generalize for speakers of unseen languages and accents. In this paper, we adopt a simple yet effective approach that combines discrete speech representations from self-supervised models with a non-autoregressive Diffusion-Transformer based conditional flow matching speech decoder. We show that this architecture allows us to train a voice-conversion model in a purely textless, self-supervised fashion. Our technique works without requiring multiple encoders to disentangle speech features. Our model also manages to excel in zero-shot cross-lingual settings even for unseen languages.', 'abstract_zh': '近期的语音转换研究越来越多地关注于提高现有方法的零样本能力。尽管取得了显著的进步，当前的架构在零样本跨语言设置中仍然会遇到困难，通常也无法泛化到未见语言和口音的说话人。在本文中，我们采用了一种简单而有效的方法，将自监督模型的离散语音表示与非自回归扩散变换器条件流匹配语音解码器相结合。我们展示了这种架构使我们能够以纯粹无文本、自监督的方式训练一个语音转换模型。我们的方法无需使用多个编码器来解码语音特征即可工作，模型也能够在未见语言的零样本跨语言设置中表现出色。', 'title_zh': 'EZ-VC: Easy Zero-shot Any-to-Any语音转换'}
{'arxiv_id': 'arXiv:2505.16690', 'title': 'Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator', 'authors': 'Beier Luo, Shuoyuan Wang, Yixuan Li, Hongxin Wei', 'link': 'https://arxiv.org/abs/2505.16690', 'abstract': "Post-training of large language models is essential for adapting pre-trained language models (PLMs) to align with human preferences and downstream tasks. While PLMs typically exhibit well-calibrated confidence, post-trained language models (PoLMs) often suffer from over-confidence, assigning high confidence to both correct and incorrect outputs, which can undermine reliability in critical applications. A major obstacle in calibrating PoLMs is the scarcity of labeled data for individual downstream tasks. To address this, we propose Disagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to optimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence calibration. Our method is motivated by the under-confidence issue caused by prediction disagreement between the PLM and PoLM while aligning their confidence via temperature scaling. Theoretically, the PLM's confidence underestimates PoLM's prediction accuracy on disagreement examples, causing a larger $\\tau$ and producing under-confident predictions. DACA mitigates this by selectively using only agreement examples for calibration, effectively decoupling the influence of disagreement. In this manner, our method avoids an overly large $\\tau$ in temperature scaling caused by disagreement examples, improving calibration performance. Extensive experiments demonstrate the effectiveness of our method, improving the average ECE of open-sourced and API-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.", 'abstract_zh': '大型语言模型的后训练对于适应预训练语言模型（PLMs）以与人类偏好和下游任务对齐是必不可少的。后训练语言模型（PoLMs）常常表现出过度自信，对正确和错误的输出都赋予很高的置信度，这可能在关键应用中削弱可靠性。校准PoLMs的主要障碍是缺乏用于个体下游任务的标注数据。为此，我们提出了一种新颖的无监督方法——分歧感知置信校准（DACA），以优化后训练置信校准（如温度$\\tau$）的参数。该方法受到PLM和PoLM之间预测分歧导致置信对齐时置信度低估的启发。理论上，PLM的置信度低估了PoLM在分歧样本上的预测准确性，导致更大的$\\tau$值并产生不自信的预测。DACA通过仅选择一致性样本进行校准，有效地解耦了分歧的影响。从而避免了由于分歧样本导致的温度缩放中的过大$\\tau$值，提高了校准性能。广泛的实验表明了该方法的有效性，在常用基准上将开源和API基于的大型语言模型（如GPT-4o）的平均ECE提升了高达15.08%。', 'title_zh': '你的预训练大规模语言模型实际上是无监督的置信度校准器'}
{'arxiv_id': 'arXiv:2505.16679', 'title': 'Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds', 'authors': 'Jordan Dotzel, Tony Montes, Mohamed S. Abdelfattah, Zhiru Zhang', 'link': 'https://arxiv.org/abs/2505.16679', 'abstract': 'Traditional methods for 3D object compression operate only on structural information within the object vertices, polygons, and textures. These methods are effective at compression rates up to 10x for standard object sizes but quickly deteriorate at higher compression rates with texture artifacts, low-polygon counts, and mesh gaps. In contrast, semantic compression ignores structural information and operates directly on the core concepts to push to extreme levels of compression. In addition, it uses natural language as its storage format, which makes it natively human-readable and a natural fit for emerging applications built around large-scale, collaborative projects within augmented and virtual reality. It deprioritizes structural information like location, size, and orientation and predicts the missing information with state-of-the-art deep generative models. In this work, we construct a pipeline for 3D semantic compression from public generative models and explore the quality-compression frontier for 3D object compression. We apply this pipeline to achieve rates as high as 105x for 3D objects taken from the Objaverse dataset and show that semantic compression can outperform traditional methods in the important quality-preserving region around 100x compression.', 'abstract_zh': '传统的3D对象压缩方法仅作用于对象顶点、多边形和纹理的结构信息。这些方法在标准对象大小下的压缩率高达10倍，但在更高压缩率下迅速恶化，出现纹理artifact、低多边形数量和网格间隙问题。相比之下，语义压缩忽略结构信息，直接作用于核心概念，以实现极致的压缩效果。此外，它使用自然语言作为存储格式，使其天然具有人类可读性，适配于基于增强和虚拟现实的大型协作项目中的新兴应用。它优先考虑预测丢失信息，而非结构性信息如位置、大小和方向。在此工作中，我们从公共生成模型构建了3D语义压缩的管道，并探索了3D对象压缩的质量-压缩前沿。我们将此管道应用于从Objaverse数据集中获取的3D对象，实现了高达105倍的压缩率，并展示了在约100倍压缩率的重要质量保持区域内，语义压缩可以超越传统方法。', 'title_zh': '开放协作虚拟世界中3D对象的语义压缩'}
{'arxiv_id': 'arXiv:2505.16673', 'title': 'R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO', 'authors': 'Huanjin Yao, Qixiang Yin, Jingyi Zhang, Min Yang, Yibo Wang, Wenhao Wu, Fei Su, Li Shen, Minghui Qiu, Dacheng Tao, Jiaxing Huang', 'link': 'https://arxiv.org/abs/2505.16673', 'abstract': 'In this work, we aim to incentivize the reasoning ability of Multimodal Large Language Models (MLLMs) via reinforcement learning (RL) and develop an effective approach that mitigates the sparse reward and advantage vanishing issues during RL. To this end, we propose Share-GRPO, a novel RL approach that tackle these issues by exploring and sharing diverse reasoning trajectories over expanded question space. Specifically, Share-GRPO first expands the question space for a given question via data transformation techniques, and then encourages MLLM to effectively explore diverse reasoning trajectories over the expanded question space and shares the discovered reasoning trajectories across the expanded questions during RL. In addition, Share-GRPO also shares reward information during advantage computation, which estimates solution advantages hierarchically across and within question variants, allowing more accurate estimation of relative advantages and improving the stability of policy training. Extensive evaluations over six widely-used reasoning benchmarks showcase the superior performance of our method. Code will be available at this https URL.', 'abstract_zh': '本研究旨在通过强化学习激励多模态大型语言模型的推理能力，并开发一种有效的方法，以缓解强化学习过程中稀疏奖励和优势消失问题。为此，我们提出了Share-GRPO，这是一种通过探索和在扩展的问题空间中共享多样化的推理轨迹来解决这些问题的新型强化学习方法。Specifically, Share-GRPO 首先通过数据变换技术扩展给定问题的问题空间，然后在强化学习过程中促使多模态大型语言模型有效探索扩展后问题空间中的多样化推理轨迹，并在扩展的问题上共享发现的推理轨迹。此外，Share-GRPO 在优势计算过程中也共享奖励信息，以分层次地估计不同变体问题之间的解的优势，从而更准确地估计相对优势并提高策略训练的稳定性。在六个广泛使用的推理基准上的广泛评估展示了该方法的优越性能。代码将发布在此 URL。', 'title_zh': 'R1-ShareVL: 通过Share-GRPO激励多模态大型语言模型的推理能力'}
{'arxiv_id': 'arXiv:2505.16670', 'title': 'BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models', 'authors': 'Xiaobei Yan, Yiming Li, Zhaoxin Fan, Han Qiu, Tianwei Zhang', 'link': 'https://arxiv.org/abs/2505.16670', 'abstract': "Large language models (LLMs) have shown impressive capabilities across a wide range of applications, but their ever-increasing size and resource demands make them vulnerable to inference cost attacks, where attackers induce victim LLMs to generate the longest possible output content. In this paper, we revisit existing inference cost attacks and reveal that these methods can hardly produce large-scale malicious effects since they are self-targeting, where attackers are also the users and therefore have to execute attacks solely through the inputs, whose generated content will be charged by LLMs and can only directly influence themselves. Motivated by these findings, this paper introduces a new type of inference cost attacks (dubbed 'bit-flip inference cost attack') that target the victim model itself rather than its inputs. Specifically, we design a simple yet effective method (dubbed 'BitHydra') to effectively flip critical bits of model parameters. This process is guided by a loss function designed to suppress <EOS> token's probability with an efficient critical bit search algorithm, thus explicitly defining the attack objective and enabling effective optimization. We evaluate our method on 11 LLMs ranging from 1.5B to 14B parameters under both int8 and float16 settings. Experimental results demonstrate that with just 4 search samples and as few as 3 bit flips, BitHydra can force 100% of test prompts to reach the maximum generation length (e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its efficiency, scalability, and strong transferability across unseen inputs.", 'abstract_zh': '大型语言模型（LLMs）在多种应用中展现了出色的性能，但其不断增加的规模和资源需求使其容易受到推理成本攻击的影响，攻击者可诱导受害的LLMs生成尽可能长的输出内容。本文重新审视了现有的推理成本攻击，并揭示这些方法难以产生大规模恶意效果，因为它们是自我靶向的，攻击者同时也是用户，因此必须通过输入来执行攻击，这些输入生成的内容将被LLMs收费，并只能直接影响自身。受此发现的启发，本文提出了一种新的推理成本攻击类型（称为“位翻转推理成本攻击”），该攻击直接针对受害模型本身而非其输入。具体地，我们设计了一种简单而有效的方法（称为“BitHydra”）来有效翻转模型参数的关键位。这一过程由一个损失函数引导，该损失函数通过一种高效的关键位搜索算法抑制<EOS>标记的概率，从而明确定义攻击目标并实现有效的优化。我们在涵盖1.5B至14B参数的11个LLM（包括int8和float16设置）上评估了该方法。实验结果表明，只需4个搜索样本和3次位翻转，BitHydra就能迫使代表性LLM（如LLaMA3）上的100%测试提示达到最大生成长度（例如，2048个标记），这突显了其高效性、可扩展性和在未见输入上的强转移能力。', 'title_zh': 'BitHydra: 针对大型语言模型的位翻转推理成本攻击'}
{'arxiv_id': 'arXiv:2505.16664', 'title': 'End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries', 'authors': 'Khoa Tran, Tri Le, Bao Huynh, Hung-Cuong Trinh, Vy-Rin Nguyen', 'link': 'https://arxiv.org/abs/2505.16664', 'abstract': 'Accurate prediction of the Remaining Useful Life (RUL) is essential for enabling timely maintenance of lithium-ion batteries, impacting the operational efficiency of electric applications that rely on them. This paper proposes a RUL prediction approach that leverages data from recent charge-discharge cycles to estimate the number of remaining usable cycles. The approach introduces both a novel signal processing pipeline and a deep learning prediction model. In the signal preprocessing pipeline, a derived capacity feature is computed based on current and capacity signals. Alongside original capacity, voltage and current, these features are denoised and enhanced using statistical metrics and a delta-based method to capture differences between the current and previous cycles. In the prediction model, the processed features are then fed into a hybrid deep learning architecture composed of 1D Convolutional Neural Networks (CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential Equation-based LSTM (ODE-LSTM) modules. This architecture is designed to capture both local signal characteristics and long-range temporal dependencies while modeling the continuous-time dynamics of battery degradation. The model is further evaluated using transfer learning across different learning strategies and target data partitioning scenarios. Results indicate that the model maintains robust performance, even when fine-tuned on limited target data. Experimental results on two publicly available large-scale datasets demonstrate that the proposed method outperforms a baseline deep learning approach and machine learning techniques, achieving an RMSE of 101.59, highlighting its strong potential for real-world RUL prediction applications.', 'abstract_zh': '准确预测锂离子电池的剩余使用寿命对于实现对依赖它们的电动应用的及时维护至关重要，影响其运营效率。本文提出了一种RUL预测方法，该方法利用最近的充放电循环数据来估计剩余可用循环次数。该方法引入了一个新型信号处理管道和一种深度学习预测模型。在信号预处理管道中，基于电流和容量信号计算了一个衍生容量特征。这些特征与原始容量、电压和电流一起，通过统计指标和基于差分的方法进行降噪和增强，以捕捉与当前循环和前一循环之间的差异。在预测模型中，预处理特征被输入由1D卷积神经网络（CNN）、注意力长期短期记忆（A-LSTM）和基于常微分方程的长期短期记忆（ODE-LSTM）模块组成的混合深度学习架构。该架构旨在捕捉局部信号特征和长距离时间依赖关系，同时建模电池退化的连续时间动态。通过不同学习策略和目标数据划分场景下的迁移学习进一步评估了该模型。结果显示，即使在目标数据微调较少的情况下，模型也保持了稳健的性能。实验结果表明，该方法在两个公开的大型数据集上优于基线深度学习方法和机器学习技术，RMSE为101.59，显示出其在实际RUL预测应用中的强大潜力。', 'title_zh': '端到端框架预测锂离子电池的剩余使用寿命'}
{'arxiv_id': 'arXiv:2505.16660', 'title': 'Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu', 'authors': 'Liu Chang, Wang Dongbo, Liu liu, Zhao Zhixiao', 'link': 'https://arxiv.org/abs/2505.16660', 'abstract': 'This study addresses the challenges in intelligent processing of Chinese ancient mathematical classics by constructing Guji_MATH, a benchmark for evaluating classical texts based on Suanjing Shishu. It systematically assesses the mathematical problem-solving capabilities of mainstream reasoning models under the unique linguistic constraints of classical Chinese. Through machine-assisted annotation and manual verification, 538 mathematical problems were extracted from 8 canonical texts, forming a structured dataset centered on the "Question-Answer-Solution" framework, supplemented by problem types and difficulty levels. Dual evaluation modes--closed-book (autonomous problem-solving) and open-book (reproducing classical solution methods)--were designed to evaluate the performance of six reasoning models on ancient Chinese mathematical problems. Results indicate that reasoning models can partially comprehend and solve these problems, yet their overall performance remains inferior to benchmarks on modern mathematical tasks. Enhancing models\' classical Chinese comprehension and cultural knowledge should be prioritized for optimization. This study provides methodological support for mining mathematical knowledge from ancient texts and disseminating traditional culture, while offering new perspectives for evaluating cross-linguistic and cross-cultural capabilities of reasoning models.', 'abstract_zh': '本研究通过构建Guji_MATHbenchmark，针对中国古代数学经典智能化处理的挑战进行了探讨，系统评估了主流推理模型在古典中文独特语言约束下的数学问题解决能力。通过机器辅助注释和人工验证，从8部经典文献中提取了538个数学问题，形成了以“问题-答案-解决方案”框架为中心的结构化数据集，并辅以问题类型和难度级别。设计了闭卷（自主问题解决）和开卷（再现古典解题方法）两种评估模式，以评估六种推理模型在古代汉语数学问题上的性能。研究结果表明，推理模型能够部分理解和解决这些问题，但在整体性能上仍不及现代数学任务的基准。优化模型的古典汉语理解和文化知识应被优先考虑。本研究为从古籍中挖掘数学知识和传播传统文化提供了方法学支持，并为评估跨语言和跨文化推理模型的能力提供了新视角。', 'title_zh': '古籍《算经十书》中的数学问题，推理模型能否理解？基于实证研究'}
{'arxiv_id': 'arXiv:2505.16648', 'title': 'Collaboration among Multiple Large Language Models for Medical Question Answering', 'authors': 'Kexin Shang, Chia-Hsuan Chang, Christopher C. Yang', 'link': 'https://arxiv.org/abs/2505.16648', 'abstract': "Empowered by vast internal knowledge reservoir, the new generation of large language models (LLMs) demonstrate untapped potential to tackle medical tasks. However, there is insufficient effort made towards summoning up a synergic effect from multiple LLMs' expertise and background. In this study, we propose a multi-LLM collaboration framework tailored on a medical multiple-choice questions dataset. Through post-hoc analysis on 3 pre-trained LLM participants, our framework is proved to boost all LLMs reasoning ability as well as alleviate their divergence among questions. We also measure an LLM's confidence when it confronts with adversary opinions from other LLMs and observe a concurrence between LLM's confidence and prediction accuracy.", 'abstract_zh': '受大规模内部知识库支持，新一代大型语言模型（LLMs）展示了应对医疗任务的未充分利用的潜力。然而，尚未有充分努力将多个LLMs的专业背景汇聚产生协同效果。在本研究中，我们提出了一种针对医学选择题数据集的多LLM协作框架。通过事后分析3个预训练LLM的表现，我们的框架证明能够提升所有LLMs的推理能力，并减少它们在不同问题上的分歧。我们还测量了LLM在面对其他LLMs的对立观点时的信心，并观察到LLM的信心与其预测准确率之间的关联。', 'title_zh': '多个大型语言模型在医疗问答中的协作'}
{'arxiv_id': 'arXiv:2505.16647', 'title': 'Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models', 'authors': 'Sushant Gautam, Michael A. Riegler, Pål Halvorsen', 'link': 'https://arxiv.org/abs/2505.16647', 'abstract': 'We investigate fine-tuning Vision-Language Models (VLMs) for multi-task medical image understanding, focusing on detection, localization, and counting of findings in medical images. Our objective is to evaluate whether instruction-tuned VLMs can simultaneously improve these tasks, with the goal of enhancing diagnostic accuracy and efficiency. Using MedMultiPoints, a multimodal dataset with annotations from endoscopy (polyps and instruments) and microscopy (sperm cells), we reformulate each task into instruction-based prompts suitable for vision-language reasoning. We fine-tune Qwen2.5-VL-7B-Instruct using Low-Rank Adaptation (LoRA) across multiple task combinations. Results show that multi-task training improves robustness and accuracy. For example, it reduces the Count Mean Absolute Error (MAE) and increases Matching Accuracy in the Counting + Pointing task. However, trade-offs emerge, such as more zero-case point predictions, indicating reduced reliability in edge cases despite overall performance gains. Our study highlights the potential of adapting general-purpose VLMs to specialized medical tasks via prompt-driven fine-tuning. This approach mirrors clinical workflows, where radiologists simultaneously localize, count, and describe findings - demonstrating how VLMs can learn composite diagnostic reasoning patterns. The model produces interpretable, structured outputs, offering a promising step toward explainable and versatile medical AI. Code, model weights, and scripts will be released for reproducibility at this https URL.', 'abstract_zh': 'Fine-tuning 视觉-语言模型进行多任务医学图像理解：检测、定位和计数任务的指令调优研究', 'title_zh': '指向、检测、计数：基于指令调优视觉-语言模型的多任务医疗图像理解'}
{'arxiv_id': 'arXiv:2505.16643', 'title': 'From Evaluation to Defense: Advancing Safety in Video Large Language Models', 'authors': 'Yiwei Sun, Peiqi Jiang, Chuanbin Liu, Luohao Lin, Zhiying Lu, Hongtao Xie', 'link': 'https://arxiv.org/abs/2505.16643', 'abstract': 'While the safety risks of image-based large language models have been extensively studied, their video-based counterparts (Video LLMs) remain critically under-examined. To systematically study this problem, we introduce \\textbf{VideoSafetyBench (VSB-77k) - the first large-scale, culturally diverse benchmark for Video LLM safety}, which compromises 77,646 video-query pairs and spans 19 principal risk categories across 10 language communities. \\textit{We reveal that integrating video modality degrades safety performance by an average of 42.3\\%, exposing systemic risks in multimodal attack exploitation.} To address this vulnerability, we propose \\textbf{VideoSafety-R1}, a dual-stage framework achieving unprecedented safety gains through two innovations: (1) Alarm Token-Guided Safety Fine-Tuning (AT-SFT) injects learnable alarm tokens into visual and textual sequences, enabling explicit harm perception across modalities via multitask objectives. (2) Then, Safety-Guided GRPO enhances defensive reasoning through dynamic policy optimization with rule-based rewards derived from dual-modality verification. These components synergize to shift safety alignment from passive harm recognition to active reasoning. The resulting framework achieves a 65.1\\% improvement on VSB-Eval-HH, and improves by 59.1\\%, 44.3\\%, and 15.0\\% on the image safety datasets MMBench, VLGuard, and FigStep, respectively. \\textit{Our codes are available in the supplementary materials.} \\textcolor{red}{Warning: This paper contains examples of harmful language and videos, and reader discretion is recommended.}', 'abstract_zh': '视频基础大型语言模型的安全风险：VideoSafetyBench（VSB-77k）-首个大规模跨文化视频LLM安全基准', 'title_zh': '从评估到防御：推进视频大规模语言模型的安全性'}
{'arxiv_id': 'arXiv:2505.16640', 'title': 'BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization', 'authors': 'Xueyang Zhou, Guiyao Tie, Guowen Zhang, Hechang Wang, Pan Zhou, Lichao Sun', 'link': 'https://arxiv.org/abs/2505.16640', 'abstract': 'Vision-Language-Action (VLA) models have advanced robotic control by enabling end-to-end decision-making directly from multimodal inputs. However, their tightly coupled architectures expose novel security vulnerabilities. Unlike traditional adversarial perturbations, backdoor attacks represent a stealthier, persistent, and practically significant threat-particularly under the emerging Training-as-a-Service paradigm-but remain largely unexplored in the context of VLA models. To address this gap, we propose BadVLA, a backdoor attack method based on Objective-Decoupled Optimization, which for the first time exposes the backdoor vulnerabilities of VLA models. Specifically, it consists of a two-stage process: (1) explicit feature-space separation to isolate trigger representations from benign inputs, and (2) conditional control deviations that activate only in the presence of the trigger, while preserving clean-task performance. Empirical results on multiple VLA benchmarks demonstrate that BadVLA consistently achieves near-100% attack success rates with minimal impact on clean task accuracy. Further analyses confirm its robustness against common input perturbations, task transfers, and model fine-tuning, underscoring critical security vulnerabilities in current VLA deployments. Our work offers the first systematic investigation of backdoor vulnerabilities in VLA models, highlighting an urgent need for secure and trustworthy embodied model design practices. We have released the project page at this https URL.', 'abstract_zh': '基于视觉-语言-行动模型的后门攻击：Objective-Decoupled Optimization方法（BadVLA）首次揭示了视觉-语言-行动模型的安全漏洞', 'title_zh': 'BadVLA：通过目标解耦优化向视觉-语言-动作模型发起后门攻击'}
{'arxiv_id': 'arXiv:2505.16637', 'title': 'SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation', 'authors': 'Wenjie Yang, Mao Zheng, Mingyang Song, Zheng Li', 'link': 'https://arxiv.org/abs/2505.16637', 'abstract': 'Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $\\leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.', 'abstract_zh': '大型语言模型（LLMs）在机器翻译（MT）方面 recently 已经展现了令人瞩目的能力。然而，大多数先进的MT专用LLMs在训练过程中严重依赖外部监督信号，如人工标注的参考数据或训练好的奖励模型（RMs），这些信号往往非常昂贵且难以扩展。为克服这一限制，我们提出了一种基于参考的Simple Self-Rewarding（SSR）强化学习（RL）框架，该框架完全在线，仅依赖自我评判奖励进行训练。使用13000个单语例句和Qwen-2.5-7B作为骨干模型进行训练后，我们的SSR-Zero-7B模型在WMT23、WMT24和Flores200基准的英译中和中译英任务中优于现有MT专用LLMs，例如TowerInstruct-13B和GemmaX-28-9B，以及更大的通用LLMs如Qwen2.5-32B-Instruct。此外，通过结合COMET提供的外部监督，我们最强的模型SSR-X-Zero-7B在英译中任务中达到了最先进的性能，超过了所有现有参数量小于72B的开源模型，甚至优于某些封闭源模型，例如GPT-4o和Gemini 1.5 Pro。我们的分析突出了自我奖励机制在MT中比外部LLM-as-a-judge方法的有效性，并表明将其与训练好的RMs结合使用时具有互补优势。我们的发现为自我提升的RL方法的潜在能力提供了宝贵见解。我们已公开发布了我们的代码、数据和模型。', 'title_zh': 'SSR-Zero: 简单的自奖励强化学习机器翻译'}
{'arxiv_id': 'arXiv:2505.16630', 'title': 'SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding', 'authors': 'Sushant Gautam, Cise Midoglu, Vajira Thambawita, Michael A. Riegler, Pål Halvorsen, Mubarak Shah', 'link': 'https://arxiv.org/abs/2505.16630', 'abstract': 'The integration of artificial intelligence in sports analytics has transformed soccer video understanding, enabling real-time, automated insights into complex game dynamics. Traditional approaches rely on isolated data streams, limiting their effectiveness in capturing the full context of a match. To address this, we introduce SoccerChat, a multimodal conversational AI framework that integrates visual and textual data for enhanced soccer video comprehension. Leveraging the extensive SoccerNet dataset, enriched with jersey color annotations and automatic speech recognition (ASR) transcripts, SoccerChat is fine-tuned on a structured video instruction dataset to facilitate accurate game understanding, event classification, and referee decision making. We benchmark SoccerChat on action classification and referee decision-making tasks, demonstrating its performance in general soccer event comprehension while maintaining competitive accuracy in referee decision making. Our findings highlight the importance of multimodal integration in advancing soccer analytics, paving the way for more interactive and explainable AI-driven sports analysis. this https URL', 'abstract_zh': '人工智能在体育分析中的集成已 transform 足球视频理解，使其能够实现实时、自动化的复杂比赛动态洞察。传统方法依赖于孤立的数据流，限制了它们在捕获比赛完整背景方面的有效性。为了解决这个问题，我们介绍了SoccerChat，这是一种多模式对话式AI框架，综合视觉和文本数据以增强对足球视频的理解。利用广泛的数据集SoccerNet，该数据集包含球衣颜色注释和自动语音识别（ASR）转录，SoccerChat在结构化的视频指令数据集上进行了微调，以促进准确的比赛理解、事件分类和裁判决策。我们在动作分类和裁判决策任务上对SoccerChat进行了基准测试，展示了其在一般足球比赛事件理解方面的性能，同时保持了在裁判决策方面的竞争力。我们的研究结果突显了在推进足球分析中多模式集成的重要性，为更互动和解释性的AI驱动体育分析铺平了道路。', 'title_zh': 'SoccerChat: 结合多模态数据以提升足球比赛理解'}
{'arxiv_id': 'arXiv:2505.16612', 'title': 'Steering Large Language Models for Machine Translation Personalization', 'authors': 'Daniel Scalena, Gabriele Sarti, Arianna Bisazza, Elisabetta Fersini, Malvina Nissim', 'link': 'https://arxiv.org/abs/2505.16612', 'abstract': 'High-quality machine translation systems based on large language models (LLMs) have simplified the production of personalized translations reflecting specific stylistic constraints. However, these systems still struggle in settings where stylistic requirements are less explicit and might be harder to convey via prompting. We explore various strategies for personalizing LLM-generated translations in low-resource settings, focusing on the challenging literary translation domain. We explore prompting strategies and inference-time interventions for steering model generations towards a personalized style, and propose a contrastive framework exploiting latent concepts extracted from sparse autoencoders to identify salient personalization properties. Our results show that steering achieves strong personalization while preserving translation quality. We further examine the impact of steering on LLM representations, finding model layers with a relevant impact for personalization are impacted similarly by multi-shot prompting and our steering method, suggesting similar mechanism at play.', 'abstract_zh': '基于大规模语言模型的高质机器翻译系统简化了反映特定風格约束的个性化翻译生产。然而，这些系统在风格要求不够明确且难以通过提示传达的情况下仍面临挑战。我们探讨了在低资源环境下个性化大规模语言模型生成翻译的各种策略，重点关注具有挑战性的文学翻译领域。我们探索了提示策略和推理时干预方法，以引导模型生成个性化风格，并提出了一种利用稀疏自编码器提取的潜在概念进行对比的框架，以识别重要的个性化属性。我们的结果表明，引导不仅可以实现强大的个性化，还能保持翻译质量。我们进一步研究了引导对大规模语言模型表示的影响，发现对个性化有相关影响的模型层级，在多轮提示和我们的引导方法作用下表现出相似的影响，表明可能存在相似的机制。', 'title_zh': '指导大型语言模型实现机器翻译个性化'}
{'arxiv_id': 'arXiv:2505.16596', 'title': 'Safe Uncertainty-Aware Learning of Robotic Suturing', 'authors': 'Wilbert Peter Empleo, Yitaek Kim, Hansoul Kim, Thiusius Rajeeth Savarimuthu, Iñigo Iturrate', 'link': 'https://arxiv.org/abs/2505.16596', 'abstract': "Robot-Assisted Minimally Invasive Surgery is currently fully manually controlled by a trained surgeon. Automating this has great potential for alleviating issues, e.g., physical strain, highly repetitive tasks, and shortages of trained surgeons. For these reasons, recent works have utilized Artificial Intelligence methods, which show promising adaptability. Despite these advances, there is skepticism of these methods because they lack explainability and robust safety guarantees. This paper presents a framework for a safe, uncertainty-aware learning method. We train an Ensemble Model of Diffusion Policies using expert demonstrations of needle insertion. Using an Ensemble model, we can quantify the policy's epistemic uncertainty, which is used to determine Out-Of-Distribution scenarios. This allows the system to release control back to the surgeon in the event of an unsafe scenario. Additionally, we implement a model-free Control Barrier Function to place formal safety guarantees on the predicted action. We experimentally evaluate our proposed framework using a state-of-the-art robotic suturing simulator. We evaluate multiple scenarios, such as dropping the needle, moving the camera, and moving the phantom. The learned policy is robust to these perturbations, showing corrective behaviors and generalization, and it is possible to detect Out-Of-Distribution scenarios. We further demonstrate that the Control Barrier Function successfully limits the action to remain within our specified safety set in the case of unsafe predictions.", 'abstract_zh': '机器人辅助微创手术目前完全由训练有素的外科医生手动控制。利用人工智能方法自动控制具有减轻体力劳动、减少重复性任务以及缓解训练外科医生短缺等问题的巨大潜力。鉴于这些原因，近期的研究利用了人工智能方法，显示出较强的适应性。尽管取得了这些进展，但由于缺乏解释性和稳健的安全保证，人们对这些方法仍持怀疑态度。本文提出了一种安全、 Awareness不确定性的学习方法框架。我们使用专家的针插入演示训练了一个扩散策略集成模型，使用集成模型可以量化策略的 epistemic 不确定性，并用于确定 Out-Of-Distribution 情况。这使得系统能够在发生不安全情况时将控制权交还给外科医生。此外，我们实现了一个无模型的控制障碍函数，以正式的安全保证约束预测动作。我们使用最先进的机器人缝合模拟器实验性地评估了我们提出的方法。我们评估了针丢失、移动摄像机和移动人造器官等多种场景。所学习的策略对这些干扰具有稳健性，展示了纠正行为和泛化能力，并且能够检测到 Out-Of-Distribution 情况。我们进一步证明，控制障碍函数成功地限制了动作，使其在不安全预测的情况下保持在我们指定的安全集内。', 'title_zh': '具有安全不确定性意识学习的机器人缝合'}
{'arxiv_id': 'arXiv:2505.16582', 'title': 'O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering', 'authors': 'Jianbiao Mei, Tao Hu, Daocheng Fu, Licheng Wen, Xuemeng Yang, Rong Wu, Pinlong Cai, Xing Gao, Yu Yang, Chengjun Xie, Botian Shi, Yong Liu, Yu Qiao', 'link': 'https://arxiv.org/abs/2505.16582', 'abstract': "Large Language Models (LLMs), despite their advancements, are fundamentally limited by their static parametric knowledge, hindering performance on tasks requiring open-domain up-to-date information. While enabling LLMs to interact with external knowledge environments is a promising solution, current efforts primarily address closed-end problems. Open-ended questions, which characterized by lacking a standard answer or providing non-unique and diverse answers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a novel search agent leveraging reinforcement learning to effectively tackle both open-ended and closed-ended questions in the open domain. O$^2$-Searcher leverages an efficient, locally simulated search environment for dynamic knowledge acquisition, effectively decoupling the external world knowledge from model's sophisticated reasoning processes. It employs a unified training mechanism with meticulously designed reward functions, enabling the agent to identify problem types and adapt different answer generation strategies. Furthermore, to evaluate performance on complex open-ended tasks, we construct O$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain open-ended questions with associated web page caches. Extensive experiments show that O$^2$-Searcher, using only a 3B model, significantly surpasses leading LLM agents on O$^2$-QA. It also achieves SOTA results on various closed-ended QA benchmarks against similarly-sized models, while performing on par with much larger ones.", 'abstract_zh': '开放领域中面向开放与封闭问题的搜索代理O$^2$-Searcher', 'title_zh': 'O$^2$-Searcher: 一种基于搜索的开放域无止境问答代理模型'}
{'arxiv_id': 'arXiv:2505.16581', 'title': 'How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning', 'authors': 'Max Weltevrede, Moritz A. Zanger, Matthijs T.J. Spaan, Wendelin Böhmer', 'link': 'https://arxiv.org/abs/2505.16581', 'abstract': 'In the zero-shot policy transfer setting in reinforcement learning, the goal is to train an agent on a fixed set of training environments so that it can generalise to similar, but unseen, testing environments. Previous work has shown that policy distillation after training can sometimes produce a policy that outperforms the original in the testing environments. However, it is not yet entirely clear why that is, or what data should be used to distil the policy. In this paper, we prove, under certain assumptions, a generalisation bound for policy distillation after training. The theory provides two practical insights: for improved generalisation, you should 1) train an ensemble of distilled policies, and 2) distil it on as much data from the training environments as possible. We empirically verify that these insights hold in more general settings, when the assumptions required for the theory no longer hold. Finally, we demonstrate that an ensemble of policies distilled on a diverse dataset can generalise significantly better than the original agent.', 'abstract_zh': '在强化学习的零样本策略迁移设置中，目标是通过对一组固定训练环境进行训练，使智能体能够在类似但未见过的测试环境中泛化。先前的研究表明，训练后进行策略蒸馏有时会产生在测试环境中表现优于原始策略的策略。然而，尚不清楚为何会出现这种情况，或应该使用什么数据进行策略蒸馏。在本文中，我们在某些假设下证明了训练后进行策略蒸馏的一般泛化界。该理论提供了两个实用的见解：为了提高泛化能力，应该1) 训练多个蒸馏策略的集合，并且2) 尽可能使用更多来自训练环境的数据进行策略蒸馏。我们实验证明了这些见解在更一般的情况下仍然成立，即理论所需的假设不再成立时也是如此。最后，我们证明了一个基于多样数据集进行策略蒸馏的策略集合可以在泛化能力上显著优于原始智能体。', 'title_zh': '蒸馏策略 ensemble 如何提高强化学习中的泛化能力'}
{'arxiv_id': 'arXiv:2505.16573', 'title': 'From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling', 'authors': 'Yi Hu, Hanchi Ren, Jingjing Deng, Xianghua Xie', 'link': 'https://arxiv.org/abs/2505.16573', 'abstract': 'Stock price prediction is a critical area of financial forecasting, traditionally approached by training models using the historical price data of individual stocks. While these models effectively capture single-stock patterns, they fail to leverage potential correlations among stock trends, which could improve predictive performance. Current single-stock learning methods are thus limited in their ability to provide a broader understanding of price dynamics across multiple stocks. To address this, we propose a novel method that merges local patterns into a global understanding through cross-stock pattern integration. Our strategy is inspired by Federated Learning (FL), a paradigm designed for decentralized model training. FL enables collaborative learning across distributed datasets without sharing raw data, facilitating the aggregation of global insights while preserving data privacy. In our adaptation, we train models on individual stock data and iteratively merge them to create a unified global model. This global model is subsequently fine-tuned on specific stock data to retain local relevance. The proposed strategy enables parallel training of individual stock models, facilitating efficient utilization of computational resources and reducing overall training time. We conducted extensive experiments to evaluate the proposed method, demonstrating that it outperforms benchmark models and enhances the predictive capabilities of state-of-the-art approaches. Our results highlight the efficacy of Cross-Stock Trend Integration (CSTI) in advancing stock price prediction, offering a robust alternative to traditional single-stock learning methodologies.', 'abstract_zh': '跨股票趋势集成在股票价格预测中的应用研究', 'title_zh': '从局部模式到全局理解：跨股票趋势集成以增强预测建模'}
{'arxiv_id': 'arXiv:2505.16567', 'title': 'Finetuning-Activated Backdoors in LLMs', 'authors': 'Thibaud Gloaguen, Mark Vero, Robin Staab, Martin Vechev', 'link': 'https://arxiv.org/abs/2505.16567', 'abstract': 'Finetuning openly accessible Large Language Models (LLMs) has become standard practice for achieving task-specific performance improvements. Until now, finetuning has been regarded as a controlled and secure process in which training on benign datasets led to predictable behaviors. In this paper, we demonstrate for the first time that an adversary can create poisoned LLMs that initially appear benign but exhibit malicious behaviors once finetuned by downstream users. To this end, our proposed attack, FAB (Finetuning-Activated Backdoor), poisons an LLM via meta-learning techniques to simulate downstream finetuning, explicitly optimizing for the emergence of malicious behaviors in the finetuned models. At the same time, the poisoned LLM is regularized to retain general capabilities and to exhibit no malicious behaviors prior to finetuning. As a result, when users finetune the seemingly benign model on their own datasets, they unknowingly trigger its hidden backdoor behavior. We demonstrate the effectiveness of FAB across multiple LLMs and three target behaviors: unsolicited advertising, refusal, and jailbreakability. Additionally, we show that FAB-backdoors are robust to various finetuning choices made by the user (e.g., dataset, number of steps, scheduler). Our findings challenge prevailing assumptions about the security of finetuning, revealing yet another critical attack vector exploiting the complexities of LLMs.', 'abstract_zh': '开放访问的大语言模型（LLMs）的微调已成为实现任务特定性能改进的标准做法。迄今为止，微调一直被视为一个受控和安全的过程，其中在良性数据集上进行训练会导致可预测的行为。在本文中，我们首次证明了一个对手可以创建看似无害但经过下游微调后表现出恶意行为的中毒LLMs。为此，我们提出了一种名为FAB（Finetuning-Activated Backdoor）的攻击方法，通过元学习技术对LLM进行中毒，模拟下游微调过程，明确优化使微调后的模型表现出恶意行为。同时，中毒的LLM受到正则化以保留其一般能力，并在微调前不表现出恶意行为。当用户在其自己的数据集上微调看似无害的模型时，他们会不知不觉地触发其隐藏的后门行为。我们展示了FAB在多个LLM和三种目标行为（未经请求的广告、拒绝及脱疆）上的有效性。此外，我们还展示了FAB后门对用户不同微调选择（如数据集、步骤数、调度器等）的鲁棒性。我们的发现挑战了关于微调安全性的现有假设，揭示了又一个利用LLMs复杂性的关键攻击向量。', 'title_zh': 'Finetuning-激活的Backdoors在LLMs中'}
{'arxiv_id': 'arXiv:2505.16561', 'title': 'Auto-nnU-Net: Towards Automated Medical Image Segmentation', 'authors': 'Jannis Becktepe, Leona Hennig, Steffen Oeltze-Jafra, Marius Lindauer', 'link': 'https://arxiv.org/abs/2505.16561', 'abstract': 'Medical Image Segmentation (MIS) includes diverse tasks, from bone to organ segmentation, each with its own challenges in finding the best segmentation model. The state-of-the-art AutoML-related MIS-framework nnU-Net automates many aspects of model configuration but remains constrained by fixed hyperparameters and heuristic design choices. As a full-AutoML framework for MIS, we propose Auto-nnU-Net, a novel nnU-Net variant enabling hyperparameter optimization (HPO), neural architecture search (NAS), and hierarchical NAS (HNAS). Additionally, we propose Regularized PriorBand to balance model accuracy with the computational resources required for training, addressing the resource constraints often faced in real-world medical settings that limit the feasibility of extensive training procedures. We evaluate our approach across diverse MIS datasets from the well-established Medical Segmentation Decathlon, analyzing the impact of AutoML techniques on segmentation performance, computational efficiency, and model design choices. The results demonstrate that our AutoML approach substantially improves the segmentation performance of nnU-Net on 6 out of 10 datasets and is on par on the other datasets while maintaining practical resource requirements. Our code is available at this https URL.', 'abstract_zh': '医学图像分割（MIS）包括从骨骼到器官分割的多样化任务，每项任务在寻找最佳分割模型时都有其独特的挑战。作为MIS的全AutoML框架，我们提出Auto-nnU-Net，这是一种新型的nnU-Net变体，支持超参数优化（HPO）、神经架构搜索（NAS）和分层NAS（HNAS）。此外，我们提出Regularized PriorBand，以平衡模型准确性与训练所需的计算资源，解决实际医疗环境中常面临的资源限制问题，这限制了全面训练程序的可行性。我们在Medical Segmentation Decathlon这个广泛认可的数据集上评估了我们的方法，分析了AutoML技术对分割性能、计算效率和模型设计选择的影响。结果表明，我们的AutoML方法在6个数据集上显著提高了nnU-Net的分割性能，在其他数据集上的表现与之相当，同时保持了实际的资源需求。', 'title_zh': '自动-nnU-Net：迈向自动化的医学图像分割'}
{'arxiv_id': 'arXiv:2505.16547', 'title': 'Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation', 'authors': 'Nitesh Subedi, Hsin-Jung Yang, Devesh K. Jha, Soumik Sarkar', 'link': 'https://arxiv.org/abs/2505.16547', 'abstract': 'This paper presents an end-to-end deep reinforcement learning (RL) framework for occlusion-aware robotic manipulation in cluttered plant environments. Our approach enables a robot to interact with a deformable plant to reveal hidden objects of interest, such as fruits, using multimodal observations. We decouple the kinematic planning problem from robot control to simplify zero-shot sim2real transfer for the trained policy. Our results demonstrate that the trained policy, deployed using our framework, achieves up to 86.7% success in real-world trials across diverse initial conditions. Our findings pave the way toward autonomous, perception-driven agricultural robots that intelligently interact with complex foliage plants to "find the fruit" in challenging occluded scenarios, without the need for explicitly designed geometric and dynamic models of every plant scenario.', 'abstract_zh': '本文提出了一种端到端的深度强化学习（RL）框架，用于遮挡感知的机器人在杂乱植物环境中的操作。我们的方法使机器人能够使用多模态观测与可变形植物交互，以揭示感兴趣的目标对象，如果实。我们将运动学规划问题与机器人控制分离，简化了训练策略的零样本模拟到现实的转移。实验结果表明，使用我们框架部署的训练策略在不同初始条件下成功率达到86.7%。我们的研究为智能交互复杂叶状植物以在挑战性的遮挡场景中“找到果实”的自主感知农业机器人铺平了道路，无需为每个植物场景显式设计几何和动力学模型。', 'title_zh': '找到果实：设计一种适用于遮挡感知植物操作的零样本模拟到现实的深度强化学习规划器'}
{'arxiv_id': 'arXiv:2505.16540', 'title': 'TextureSAM: Towards a Texture Aware Foundation Model for Segmentation', 'authors': 'Inbal Cohen, Boaz Meivar, Peihan Tu, Shai Avidan, Gal Oren', 'link': 'https://arxiv.org/abs/2505.16540', 'abstract': "Segment Anything Models (SAM) have achieved remarkable success in object segmentation tasks across diverse datasets. However, these models are predominantly trained on large-scale semantic segmentation datasets, which introduce a bias toward object shape rather than texture cues in the image. This limitation is critical in domains such as medical imaging, material classification, and remote sensing, where texture changes define object boundaries. In this study, we investigate SAM's bias toward semantics over textures and introduce a new texture-aware foundation model, TextureSAM, which performs superior segmentation in texture-dominant scenarios. To achieve this, we employ a novel fine-tuning approach that incorporates texture augmentation techniques, incrementally modifying training images to emphasize texture features. By leveraging a novel texture-alternation of the ADE20K dataset, we guide TextureSAM to prioritize texture-defined regions, thereby mitigating the inherent shape bias present in the original SAM model. Our extensive experiments demonstrate that TextureSAM significantly outperforms SAM-2 on both natural (+0.2 mIoU) and synthetic (+0.18 mIoU) texture-based segmentation datasets. The code and texture-augmented dataset will be publicly available.", 'abstract_zh': 'Segment Anything模型(SAM)在多种数据集中实现了物体分割任务的显著成功。然而，这些模型主要在大规模语义分割数据集上进行训练，这会导致模型偏向于对象形状而非图像中的纹理线索。这一局限性在医学成像、材料分类和遥感等领域尤为关键，因为在这些领域，纹理变化定义了对象边界。在本研究中，我们探讨了SAM对语义信息的偏好，并引入了一种新的纹理感知基础模型——TextureSAM，该模型在纹理主导场景下的分割表现更优。为此，我们采用了一种创新的微调方法，结合了纹理增强技术，逐步修改训练图像以突出纹理特征。通过利用ADE20K数据集的新型纹理变换，我们引导TextureSAM优先关注由纹理定义的区域，从而减轻了原SAM模型固有的形状偏见。广泛的经验表明，TextureSAM在自然纹理（+0.2 mIoU）和合成纹理（+0.18 mIoU）基础分割数据集上的表现均显著优于SAM-2。代码和纹理增强数据集将公开提供。', 'title_zh': 'TextureSAM: 面向语义分割的纹理感知基础模型'}
{'arxiv_id': 'arXiv:2505.16530', 'title': 'DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection', 'authors': 'Yuliang Yan, Haochun Tang, Shuo Yan, Enyan Dai', 'link': 'https://arxiv.org/abs/2505.16530', 'abstract': 'Large language models (LLMs) are considered valuable Intellectual Properties (IP) for legitimate owners due to the enormous computational cost of training. It is crucial to protect the IP of LLMs from malicious stealing or unauthorized deployment. Despite existing efforts in watermarking and fingerprinting LLMs, these methods either impact the text generation process or are limited in white-box access to the suspect model, making them impractical. Hence, we propose DuFFin, a novel $\\textbf{Du}$al-Level $\\textbf{Fin}$gerprinting $\\textbf{F}$ramework for black-box setting ownership verification. DuFFin extracts the trigger pattern and the knowledge-level fingerprints to identify the source of a suspect model. We conduct experiments on a variety of models collected from the open-source website, including four popular base models as protected LLMs and their fine-tuning, quantization, and safety alignment versions, which are released by large companies, start-ups, and individual users. Results show that our method can accurately verify the copyright of the base protected LLM on their model variants, achieving the IP-ROC metric greater than 0.95. Our code is available at this https URL.', 'abstract_zh': '一种用于黑盒设置的Dual-Level Fingerprinting Framework (DuFFin) 用于所有权验证', 'title_zh': 'DuFFin：LLMs IP保护的双重层级指纹框架'}
{'arxiv_id': 'arXiv:2505.16522', 'title': 'Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing', 'authors': 'Zhouhao Sun, Zhiyuan Kan, Xiao Ding, Li Du, Yang Zhao, Bing Qin, Ting Liu', 'link': 'https://arxiv.org/abs/2505.16522', 'abstract': 'Despite significant progress, recent studies have indicated that current large language models (LLMs) may still utilize bias during inference, leading to the poor generalizability of LLMs. Some benchmarks are proposed to investigate the generalizability of LLMs, with each piece of data typically containing one type of controlled bias. However, a single piece of data may contain multiple types of biases in practical applications. To bridge this gap, we propose a multi-bias benchmark where each piece of data contains five types of biases. The evaluations conducted on this benchmark reveal that the performance of existing LLMs and debiasing methods is unsatisfying, highlighting the challenge of eliminating multiple types of biases simultaneously. To overcome this challenge, we propose a causal effect estimation-guided multi-bias elimination method (CMBE). This method first estimates the causal effect of multiple types of biases simultaneously. Subsequently, we eliminate the causal effect of biases from the total causal effect exerted by both the semantic information and biases during inference. Experimental results show that CMBE can effectively eliminate multiple types of bias simultaneously to enhance the generalizability of LLMs.', 'abstract_zh': '尽管取得了显著进展，近期研究表明，当前的大规模语言模型（LLMs）在推断过程中仍然可能存在偏见，导致LLMs的泛化能力不足。一些基准被提出以研究LLMs的泛化能力，每条数据通常包含一种控制偏见。然而，在实际应用中，一条数据可能包含多种类型的偏见。为解决这一问题，我们提出了一个多偏见基准，每条数据包含五类偏见。在该基准上的评估显示，现有的LLMs和去偏方法表现不佳，突显了同时消除多种偏见的挑战。为克服这一挑战，我们提出了一个基于因果效应估计的多偏见消除方法（CMBE）。该方法首先同时估计多种偏见的因果效应。随后，我们从语义信息和偏见共同作用的总因果效应中消除偏见的因果效应。实验结果表明，CMBE能够同时有效消除多种偏见，提升LLMs的泛化能力。', 'title_zh': '基于因果效应估计导向的去偏见方法，benchmarking及推动大型语言模型多偏见消除边界'}
{'arxiv_id': 'arXiv:2505.16520', 'title': 'Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs', 'authors': 'Giovanni Servedio, Alessandro De Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia', 'link': 'https://arxiv.org/abs/2505.16520', 'abstract': 'Factual hallucinations are a major challenge for Large Language Models (LLMs). They undermine reliability and user trust by generating inaccurate or fabricated content. Recent studies suggest that when generating false statements, the internal states of LLMs encode information about truthfulness. However, these studies often rely on synthetic datasets that lack realism, which limits generalization when evaluating the factual accuracy of text generated by the model itself. In this paper, we challenge the findings of previous work by investigating truthfulness encoding capabilities, leading to the generation of a more realistic and challenging dataset. Specifically, we extend previous work by introducing: (1) a strategy for sampling plausible true-false factoid sentences from tabular data and (2) a procedure for generating realistic, LLM-dependent true-false datasets from Question Answering collections. Our analysis of two open-source LLMs reveals that while the findings from previous studies are partially validated, generalization to LLM-generated datasets remains challenging. This study lays the groundwork for future research on factuality in LLMs and offers practical guidelines for more effective evaluation.', 'abstract_zh': '大规模语言模型中的事实幻觉是一个主要挑战。它们通过生成不准确或虚构的内容削弱了可靠性和用户信任。近期研究表明，当生成虚假陈述时，大语言模型内部状态中包含了关于真实性的信息。然而，这些研究往往依赖于缺乏现实性的合成数据集，这限制了对其自身生成文本的事实准确性评估的泛化能力。本文通过探讨真实性编码能力，提出了一种更具现实性和挑战性的数据集生成方法。具体来说，本文扩展了先前的工作，引入了（1）从表格数据中采样可证实的真假事实句的策略，以及（2）从问答集合中生成真实的、依赖于大语言模型的真假数据集的程序。我们对两个开源大语言模型的分析表明，尽管先前研究的部分发现得到了验证，但将其推广到大语言模型生成的数据集仍然具有挑战性。本文为未来关于大语言模型事实性的研究奠定了基础，并提供了更有效的评估实践指南。', 'title_zh': '隐藏状态在隐藏什么？测试大型语言模型事实编码能力的极限'}
{'arxiv_id': 'arXiv:2505.16518', 'title': 'CUB: Benchmarking Context Utilisation Techniques for Language Models', 'authors': 'Lovisa Hagström, Youna Kim, Haeun Yu, Sang-goo Lee, Richard Johansson, Hyunsoo Cho, Isabelle Augenstein', 'link': 'https://arxiv.org/abs/2505.16518', 'abstract': 'Incorporating external knowledge is crucial for knowledge-intensive tasks, such as question answering and fact checking. However, language models (LMs) may ignore relevant information that contradicts outdated parametric memory or be distracted by irrelevant contexts. While many context utilisation manipulation techniques (CMTs) that encourage or suppress context utilisation have recently been proposed to alleviate these issues, few have seen systematic comparison. In this paper, we develop CUB (Context Utilisation Benchmark) to help practitioners within retrieval-augmented generation (RAG) identify the best CMT for their needs. CUB allows for rigorous testing on three distinct context types, observed to capture key challenges in realistic context utilisation scenarios. With this benchmark, we evaluate seven state-of-the-art methods, representative of the main categories of CMTs, across three diverse datasets and tasks, applied to nine LMs. Our results show that most of the existing CMTs struggle to handle the full set of types of contexts that may be encountered in real-world retrieval-augmented scenarios. Moreover, we find that many CMTs display an inflated performance on simple synthesised datasets, compared to more realistic datasets with naturally occurring samples. Altogether, our results show the need for holistic tests of CMTs and the development of CMTs that can handle multiple context types.', 'abstract_zh': 'Incorporating 外部知识对于知识密集型任务（如问答和事实核查）至关重要。然而，语言模型（LMs）可能会忽略与其过时参数记忆相矛盾的相关信息，或被无关上下文所分散。虽然最近提出了许多鼓励或抑制上下文利用的技术（CMTs）来缓解这些问题，但很少有进行全面比较。在本文中，我们开发了CUB（上下文利用基准）以帮助检索增强生成（RAG）领域的实践者识别最适合他们需求的最佳CMT。CUB 允许在三种不同类型的上下文中进行严格的测试，这些类型被视为现实环境中上下文利用挑战的关键。借助此基准，我们评估了七种最先进的方法，这些方法代表了主要的CMT类别，在三个不同的数据集和任务上应用于九种LMs。我们的结果表明，现有的大多数CMT难以处理真实世界检索增强场景中可能出现的各种类型的上下文。此外，我们发现，许多CMT在简单合成数据集上的表现明显优于包含自然出现样本的更现实的数据集。总之，我们的结果强调了对CMT进行全面测试以及开发能够处理多种上下文类型的CMT的需求。', 'title_zh': 'CUB：评估语言模型中上下文利用技术的标准测试集'}
{'arxiv_id': 'arXiv:2505.16516', 'title': 'Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods', 'authors': 'Majid Mohammadi, Siu Lun Chau, Krikamol Muandet', 'link': 'https://arxiv.org/abs/2505.16516', 'abstract': 'Kernel methods are widely used in machine learning due to their flexibility and expressive power. However, their black-box nature poses significant challenges to interpretability, limiting their adoption in high-stakes applications. Shapley value-based feature attribution techniques, such as SHAP and kernel-specific variants like RKHS-SHAP, offer a promising path toward explainability. Yet, computing exact Shapley values remains computationally intractable in general, motivating the development of various approximation schemes. In this work, we introduce PKeX-Shapley, a novel algorithm that utilizes the multiplicative structure of product kernels to enable the exact computation of Shapley values in polynomial time. We show that product-kernel models admit a functional decomposition that allows for a recursive formulation of Shapley values. This decomposition not only yields computational efficiency but also enhances interpretability in kernel-based learning. We also demonstrate how our framework can be generalized to explain kernel-based statistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the Hilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for interpretable statistical inference.', 'abstract_zh': '基于核函数的PKeX-Shapley算法：利用乘法结构实现多项式时间精确计算Shapley值，及其在内核基于学习可解释性和统计差异解释中的应用', 'title_zh': '在多项式时间内为产品核方法计算精确的沙普ley值'}
{'arxiv_id': 'arXiv:2505.16512', 'title': 'Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection', 'authors': 'Jiaxin Liu, Jia Wang, Saihui Hou, Min Ren, Huijia Wu, Zhaofeng He', 'link': 'https://arxiv.org/abs/2505.16512', 'abstract': 'In recent years, the rapid development of deepfake technology has given rise to an emerging and serious threat to public security: diffusion model-based digital human generation. Unlike traditional face manipulation methods, such models can generate highly realistic videos with consistency through multimodal control signals. Their flexibility and covertness pose severe challenges to existing detection strategies. To bridge this gap, we introduce DigiFakeAV, the first large-scale multimodal digital human forgery dataset based on diffusion models. Employing five latest digital human generation methods (Sonic, Hallo, etc.) and voice cloning method, we systematically produce a dataset comprising 60,000 videos (8.4 million frames), covering multiple nationalities, skin tones, genders, and real-world scenarios, significantly enhancing data diversity and realism. User studies show that the confusion rate between forged and real videos reaches 68%, and existing state-of-the-art (SOTA) detection models exhibit large drops in AUC values on DigiFakeAV, highlighting the challenge of the dataset. To address this problem, we further propose DigiShield, a detection baseline based on spatiotemporal and cross-modal fusion. By jointly modeling the 3D spatiotemporal features of videos and the semantic-acoustic features of audio, DigiShield achieves SOTA performance on both the DigiFakeAV and DF-TIMIT datasets. Experiments show that this method effectively identifies covert artifacts through fine-grained analysis of the temporal evolution of facial features in synthetic videos.', 'abstract_zh': '近年来，深度伪造技术的快速发展给公共安全带来了新兴且严重的威胁：基于扩散模型的数字人生成伪造。与传统的人脸操控方法不同，此类模型可以通过多模态控制信号生成高度真实的视频，并保持一致性。它们的灵活性和隐蔽性给现有检测策略带来了严重挑战。为弥合这一差距，我们引入了DigiFakeAV，这是基于扩散模型的第一个大规模多模态数字人伪造数据集。我们利用最新的五种数字人生成方法（Sonic、Hallo等）和语音克隆方法，系统地生成了一个包含60,000个视频（840万个帧）的数据集，涵盖了多种国籍、肤色、性别和现实世界场景，显著增强了数据的多样性和真实性。用户研究显示，伪造视频与真实视频的混淆率达到68%，现有的尖端检测模型在DigiFakeAV上的AUC值大幅下降，突显了数据集的挑战性。为解决这一问题，我们进一步提出DigiShield，这是一种基于时空和跨模态融合的检测基线。通过联合建模视频的3D时空特征和音频的语义-音质特征，DigiShield在DigiFakeAV和DF-TIMIT数据集上均实现了尖端性能。实验表明，该方法通过细致分析合成视频中面部特征的时序演变有效识别了隐蔽的伪造痕迹。', 'title_zh': '超越面部替换：一种基于扩散的多模态深度假信息检测数字人类基准'}
{'arxiv_id': 'arXiv:2505.16508', 'title': 'Edge-First Language Model Inference: Models, Metrics, and Tradeoffs', 'authors': 'SiYoung Jang, Roberto Morabito', 'link': 'https://arxiv.org/abs/2505.16508', 'abstract': 'The widespread adoption of Language Models (LMs) across industries is driving interest in deploying these services across the computing continuum, from the cloud to the network edge. This shift aims to reduce costs, lower latency, and improve reliability and privacy. Small Language Models (SLMs), enabled by advances in model compression, are central to this shift, offering a path to on-device inference on resource-constrained edge platforms. This work examines the interplay between edge and cloud deployments, starting from detailed benchmarking of SLM capabilities on single edge devices, and extending to distributed edge clusters. We identify scenarios where edge inference offers comparable performance with lower costs, and others where cloud fallback becomes essential due to limits in scalability or model capacity. Rather than proposing a one-size-fits-all solution, we present platform-level comparisons and design insights for building efficient, adaptive LM inference systems across heterogeneous environments.', 'abstract_zh': '语言模型在各行业的广泛应用推动了跨计算 continuum 部署服务的兴趣，从云端到网络边缘。这一转变旨在降低费用、减少延迟，并提高可靠性和隐私性。通过模型压缩实现的小语言模型（SLM）是这一转变的核心，它们为资源受限的边缘平台提供离线推理的可能性。本文探讨了边缘和云端部署之间的相互作用，从单个边缘设备上小语言模型能力的详细基准测试开始，扩展到分布式边缘集群。我们识别了边缘推理在某些情况下提供类似性能并具有更低成本的场景，同时也指出了在可扩展性或模型容量有限时依赖云端作为后备的必要性。我们不提供一刀切的解决方案，而是提供了跨异构环境构建高效、自适应语言模型推理系统的平台级比较和设计洞察。', 'title_zh': '边缘优先语言模型推理：模型、度量标准与tradeoffs'}
{'arxiv_id': 'arXiv:2505.16505', 'title': 'Sparse Activation Editing for Reliable Instruction Following in Narratives', 'authors': 'Runcong Zhao, Chengyu Cao, Qinglin Zhu, Xiucheng Lv, Shun Shao, Lin Gui, Ruifeng Xu, Yulan He', 'link': 'https://arxiv.org/abs/2505.16505', 'abstract': "Complex narrative contexts often challenge language models' ability to follow instructions, and existing benchmarks fail to capture these difficulties. To address this, we propose Concise-SAE, a training-free framework that improves instruction following by identifying and editing instruction-relevant neurons using only natural language instructions, without requiring labelled data. To thoroughly evaluate our method, we introduce FreeInstruct, a diverse and realistic benchmark of 1,212 examples that highlights the challenges of instruction following in narrative-rich settings. While initially motivated by complex narratives, Concise-SAE demonstrates state-of-the-art instruction adherence across varied tasks without compromising generation quality.", 'abstract_zh': '复杂叙事背景往往挑战语言模型遵循指令的能力，现有基准也未能捕捉到这些困难。为此，我们提出了一种无需训练的Concise-SAE框架，通过仅使用自然语言指令来识别和编辑指令相关的神经元，从而改进指令遵循能力，无需标注数据。为了全面评估我们的方法，我们引入了FreeInstruct，这是一个包含1,212个例子的多样化且现实的基准，突出了叙事丰富环境下指令遵循的挑战。尽管最初是针对复杂叙事提出，但Concise-SAE在各种任务中均表现出色，同时保持了生成质量。', 'title_zh': '稀疏激活编辑以实现叙事中可靠的指令跟随'}
{'arxiv_id': 'arXiv:2505.16499', 'title': 'Smaller, Smarter, Closer: The Edge of Collaborative Generative AI', 'authors': 'Roberto Morabito, SiYoung Jang', 'link': 'https://arxiv.org/abs/2505.16499', 'abstract': 'The rapid adoption of generative AI (GenAI), particularly Large Language Models (LLMs), has exposed critical limitations of cloud-centric deployments, including latency, cost, and privacy concerns. Meanwhile, Small Language Models (SLMs) are emerging as viable alternatives for resource-constrained edge environments, though they often lack the capabilities of their larger counterparts. This article explores the potential of collaborative inference systems that leverage both edge and cloud resources to address these challenges. By presenting distinct cooperation strategies alongside practical design principles and experimental insights, we offer actionable guidance for deploying GenAI across the computing continuum.', 'abstract_zh': '生成式人工智能（GenAI）尤其是大型语言模型（LLMs）的快速 adoption 已暴露出基于云部署的关键限制，包括延迟、成本和隐私问题。同时，小型语言模型（SLMs）正成为资源受限边缘环境的可行替代方案，尽管它们往往缺乏大型模型的能力。本文探讨了利用边缘和云资源的协作推理系统在应对这些挑战方面的潜力。通过提出不同的合作策略并结合实用的设计原则和实验见解，我们为在计算连续体中部署GenAI提供了可操作的指导。', 'title_zh': '更小，更智能，更近：协作生成AI的边缘'}
{'arxiv_id': 'arXiv:2505.16498', 'title': 'Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models', 'authors': 'Augusto Luis Ballardini, Miguel Ángel Sotelo', 'link': 'https://arxiv.org/abs/2505.16498', 'abstract': 'Achieving full automation in self-driving vehicles remains a challenge, especially in dynamic urban environments where navigation requires real-time adaptability. Existing systems struggle to handle navigation plans when faced with unpredictable changes in road layouts, spontaneous detours, or missing map data, due to their heavy reliance on predefined cartographic information. In this work, we explore the use of Large Language Models to generate Answer Set Programming rules by translating informal navigation instructions into structured, logic-based reasoning. ASP provides non-monotonic reasoning, allowing autonomous vehicles to adapt to evolving scenarios without relying on predefined maps. We present an experimental evaluation in which LLMs generate ASP constraints that encode real-world urban driving logic into a formal knowledge representation. By automating the translation of informal navigation instructions into logical rules, our method improves adaptability and explainability in autonomous navigation. Results show that LLM-driven ASP rule generation supports semantic-based decision-making, offering an explainable framework for dynamic navigation planning that aligns closely with how humans communicate navigational intent.', 'abstract_zh': '在自驾车中实现完全自动化仍是一个挑战，特别是在需要实时适应性的动态城市环境中。现有系统难以处理不可预测的道路布局变化、突发的路线绕行或缺失的地图数据，因为它们高度依赖预定义的地图信息。在此工作中，我们探索使用大型语言模型通过将非正式的导航指令翻译为结构化的逻辑推理规则来生成Answer Set Programming（ASP）规则。ASP提供了非单调推理能力，使自动驾驶车辆能够在无需依赖预定义地图的情况下适应不断变化的场景。我们通过实验评估，展示了LLM生成的ASP约束如何将现实世界的城市驾驶逻辑编码为形式化的知识表示。通过自动化非正式导航指令到逻辑规则的翻译，我们的方法提高了自主导航的适应性和可解释性。结果表明，由LLM驱动的ASP规则生成支持基于语义的决策制定，提供了一个与人类导航意图交流紧密相连的可解释动态导航规划框架。', 'title_zh': '基于知识表示和大型语言模型的人类级语义导航自主驾驶'}
{'arxiv_id': 'arXiv:2505.16491', 'title': 'LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing', 'authors': 'Dario Di Palma, Alessandro De Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia', 'link': 'https://arxiv.org/abs/2505.16491', 'abstract': 'Large Language Models (LLMs) have rapidly become central to NLP, demonstrating their ability to adapt to various tasks through prompting techniques, including sentiment analysis. However, we still have a limited understanding of how these models capture sentiment-related information. This study probes the hidden layers of Llama models to pinpoint where sentiment features are most represented and to assess how this affects sentiment analysis.\nUsing probe classifiers, we analyze sentiment encoding across layers and scales, identifying the layers and pooling methods that best capture sentiment signals. Our results show that sentiment information is most concentrated in mid-layers for binary polarity tasks, with detection accuracy increasing up to 14% over prompting techniques. Additionally, we find that in decoder-only models, the last token is not consistently the most informative for sentiment encoding. Finally, this approach enables sentiment tasks to be performed with memory requirements reduced by an average of 57%.\nThese insights contribute to a broader understanding of sentiment in LLMs, suggesting layer-specific probing as an effective approach for sentiment tasks beyond prompting, with potential to enhance model utility and reduce memory requirements.', 'abstract_zh': '大型语言模型（LLMs）已迅速成为自然语言处理（NLP）的核心，通过提示技术展示了其适应各种任务的能力，包括情感分析。然而，我们仍对这些模型如何捕捉情感相关信息缺乏充分的理解。本研究探讨了Llama模型的隐藏层，以确定情感特征最集中的位置，并评估这一过程对情感分析的影响。\n\n通过探针分类器，我们分析了不同层和尺度的情感编码，识别出最适合捕捉情感信号的层和池化方法。结果显示，对于二元极性任务，情感信息主要集中在中间层，使用探针分类器的情感检测准确率最高可提高14%。此外，我们发现，在解码器-only模型中，最后一个标记并不总是最信息丰富的标记。最后，这种方法使得情感任务的内存需求平均减少57%。\n\n这些见解有助于更全面地理解LLMs中的情感，表明针对情感任务的层特定探针是一种有效的方法，不仅可以超越提示技术的应用，而且还具有提高模型实用性和减少内存需求的潜力。', 'title_zh': 'LLaMAs 也有情感：通过探针揭示LLaMA模型中的情感和情绪表示'}
{'arxiv_id': 'arXiv:2505.16483', 'title': 'Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning', 'authors': 'Shuzheng Si, Haozhe Zhao, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Bofei Gao, Kangyang Luo, Wenhao Li, Yufei Huang, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun', 'link': 'https://arxiv.org/abs/2505.16483', 'abstract': 'Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seeking systems. Therefore, we propose a systematic framework, CANOE, to improve the faithfulness of LLMs in both short-form and long-form generation tasks without human annotations. Specifically, we first synthesize short-form question-answering (QA) data with four diverse tasks to construct high-quality and easily verifiable training data without human annotation. Also, we propose Dual-GRPO, a rule-based reinforcement learning method that includes three tailored rule-based rewards derived from synthesized short-form QA data, while simultaneously optimizing both short-form and long-form response generation. Notably, Dual-GRPO eliminates the need to manually label preference data to train reward models and avoids over-optimizing short-form generation when relying only on the synthesized short-form QA data. Experimental results show that CANOE greatly improves the faithfulness of LLMs across 11 different downstream tasks, even outperforming the most advanced LLMs, e.g., GPT-4o and OpenAI o1.', 'abstract_zh': 'Teaching大型语言模型（LLMs）在提供上下文中的诚信对于构建可靠的信息查询系统至关重要。因此，我们提出了一种系统性框架CANOE，以在短文本和长文本生成任务中不依赖人类注解提高LLMs的诚信度。具体而言，我们首先通过四种不同的任务综合生成短文本问答（QA）数据，以构建无需人工标注的高质量且易于验证的训练数据。同时，我们提出了基于规则的增强学习方法Dual-GRPO，该方法包括三个针对合成短文本QA数据定制的规则奖励，同时优化短文本和长文本响应生成。值得注意的是，Dual-GRPO消除了需要手动标注偏好数据来训练奖励模型的需求，并避免了仅依赖合成短文本QA数据时过度优化短文本生成。实验结果表明，CANOE显著提高了LLMs在11个不同下游任务中的诚信度，甚至超越了最先进的LLMs，例如GPT-4o和OpenAI o1。', 'title_zh': '通过合成任务和强化学习教学大型语言模型保持上下文忠诚度'}
{'arxiv_id': 'arXiv:2505.16466', 'title': 'Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for GNN-based Recommendation Methods', 'authors': 'Meng Yan, Cai Xu, Xujing Wang, Ziyu Guan, Wei Zhao, Yuhang Zhou', 'link': 'https://arxiv.org/abs/2505.16466', 'abstract': 'Recommender systems based on graph neural networks perform well in tasks such as rating and ranking. However, in real-world recommendation scenarios, noise such as user misuse and malicious advertisement gradually accumulates through the message propagation mechanism. Even if existing studies mitigate their effects by reducing the noise propagation weights, the severe sparsity of the recommender system still leads to the low-weighted noisy neighbors being mistaken as meaningful information, and the prediction result obtained based on the polluted nodes is not entirely trustworthy. Therefore, it is crucial to measure the confidence of the prediction results in this highly noisy framework. Furthermore, our evaluation of the existing representative GNN-based recommendation shows that it suffers from overconfidence. Based on the above considerations, we propose a new method to quantify and calibrate the prediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically, we propose a rating calibration method that dynamically adjusts excessive ratings to mitigate overconfidence based on user personalization. We also design a confidence loss function to reduce the overconfidence of negative samples and effectively improve recommendation performance. Experiments on public datasets demonstrate the validity of Conf-GNNRec in prediction confidence and recommendation performance.', 'abstract_zh': '基于图神经网络的推荐系统在评级和排名任务中表现良好。然而，在实际推荐场景中，通过消息传播机制逐渐积累的用户滥用、恶意广告等噪声导致推荐系统稀疏性严重，低权重的噪声邻居被误认为有意义的信息，基于污染节点的预测结果可信度不高。因此，在这种高度噪声的框架中衡量预测结果的信心至关重要。进一步的评估显示，现有的基于图神经网络的代表性推荐方法存在过度自信的问题。基于以上考虑，我们提出了一种新的方法来量化和校准基于图神经网络的推荐预测置信度（Conf-GNNRec）。具体地，我们提出了一个评分校准方法，基于用户个性化动态调整过高的评分以缓解过度自信。我们还设计了一种置信度损失函数，以减少负样本的过度自信并有效提高推荐性能。在公共数据集上的实验验证了Conf-GNNRec在预测置信度和推荐性能上的有效性。', 'title_zh': 'Conf-GNNRec: 量化和校准基于GNN的推荐方法的预测置信度'}
{'arxiv_id': 'arXiv:2505.16460', 'title': 'University of Indonesia at SemEval-2025 Task 11: Evaluating State-of-the-Art Encoders for Multi-Label Emotion Detection', 'authors': 'Ikhlasul Akmal Hanif, Eryawan Presma Yulianrifat, Jaycent Gunawan Ongris, Eduardus Tjitrahardja, Muhammad Falensi Azmi, Rahmat Bryan Naufal, Alfan Farizki Wicaksono', 'link': 'https://arxiv.org/abs/2505.16460', 'abstract': 'This paper presents our approach for SemEval 2025 Task 11 Track A, focusing on multilabel emotion classification across 28 languages. We explore two main strategies: fully fine-tuning transformer models and classifier-only training, evaluating different settings such as fine-tuning strategies, model architectures, loss functions, encoders, and classifiers. Our findings suggest that training a classifier on top of prompt-based encoders such as mE5 and BGE yields significantly better results than fully fine-tuning XLMR and mBERT. Our best-performing model on the final leaderboard is an ensemble combining multiple BGE models, where CatBoost serves as the classifier, with different configurations. This ensemble achieves an average F1-macro score of 56.58 across all languages.', 'abstract_zh': '本文提出了我们针对SemEval 2025 Task 11 Track A的方法，集中于28种语言上的多标签情感分类。我们探索了两种主要策略：完全微调变换器模型和仅训练分类器，并评估了不同的设置，如微调策略、模型架构、损失函数、编码器和分类器。我们的研究发现，在基于提示的编码器（如mE5和BGE）上训练分类器的效果显著优于完全微调XLMR和mBERT。最终排行榜上性能最佳的模型是多个BGE模型的集成，其中CatBoost用作分类器，并采用不同的配置，该集成在所有语言上的平均F1-宏分值为56.58。', 'title_zh': '印度尼西亚大学在SemEval-2025任务11中的研究：评估先进编码器在多标签情感检测中的性能'}
{'arxiv_id': 'arXiv:2505.16452', 'title': 'CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI', 'authors': 'Mohamed S. Elmahdy, Marius Staring, Patrick J. H. de Koning, Samer Alabed, Mahan Salehi, Faisal Alandejani, Michael Sharkey, Ziad Aldabbagh, Andrew J. Swift, Rob J. van der Geest', 'link': 'https://arxiv.org/abs/2505.16452', 'abstract': 'Accurate and efficient quantification of cardiac function is essential for the estimation of prognosis of cardiovascular diseases (CVDs). One of the most commonly used metrics for evaluating cardiac pumping performance is left ventricular ejection fraction (LVEF). However, LVEF can be affected by factors such as inter-observer variability and varying pre-load and after-load conditions, which can reduce its reproducibility. Additionally, cardiac dysfunction may not always manifest as alterations in LVEF, such as in heart failure and cardiotoxicity diseases. An alternative measure that can provide a relatively load-independent quantitative assessment of myocardial contractility is myocardial strain and strain rate. By using LVEF in combination with myocardial strain, it is possible to obtain a thorough description of cardiac function. Automated estimation of LVEF and other volumetric measures from cine-MRI sequences can be achieved through segmentation models, while strain calculation requires the estimation of tissue displacement between sequential frames, which can be accomplished using registration models. These tasks are often performed separately, potentially limiting the assessment of cardiac function. To address this issue, in this study we propose an end-to-end deep learning (DL) model that jointly estimates groupwise (GW) registration and segmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep GW network was trained and validated on a large dataset of 4-chamber view cine-MRI image series of 374 subjects. A quantitative comparison with conventional GW registration using elastix and two DL-based methods showed that the proposed model improved performance and substantially reduced computation time.', 'abstract_zh': '准确而高效的评估心脏功能对于心血管疾病（CVDs）预后估计至关重要。左室射血分数（LVEF）是评估心脏泵血性能的一个常用指标。然而，LVEF 可受观测者间差异和不同前负荷及后负荷条件的影响，这会降低其可重复性。此外，心脏功能障碍可能不会总是表现为LVEF 的改变，例如在心力衰竭和心肌毒性疾病中。一种相对独立于负荷的评估心肌收缩能力的量化指标是心肌应变和应变率。通过结合LVEF 和心肌应变，可以更全面地描述心脏功能。从 cine-MRI 序列中自动化估计 LVEF 及其他容积测量值可通过分割模型实现，而应变计算需要估计连续帧之间的组织位移，这可以通过注册模型实现。这些任务通常分开进行，这可能限制了心脏功能的评估。为解决这一问题，在本研究中我们提出了一种端到端的深度学习（DL）模型，用于联合估计心脏 cine-MRI 图像的群组级注册和分割。所提出的解剖导向的深度群组级网络在4 腔视图 cine-MRI 图像系列的374 个受试者的大型数据集上进行了训练和验证。与使用 elastix 的传统群组级注册以及两种基于DL 的方法相比，提出的模型在定量比较中表现更好，并大幅减少了计算时间。', 'title_zh': 'CMRINet：心脏功能定量的 cine-MRI 联合群组配准与分割'}
{'arxiv_id': 'arXiv:2505.16430', 'title': 'AutoMCQ -- Automatically Generate Code Comprehension Questions using GenAI', 'authors': 'Martin Goodfellow, Robbie Booth, Andrew Fagan, Alasdair Lambert', 'link': 'https://arxiv.org/abs/2505.16430', 'abstract': 'Students often do not fully understand the code they have written. This sometimes does not become evident until later in their education, which can mean it is harder to fix their incorrect knowledge or misunderstandings. In addition, being able to fully understand code is increasingly important in a world where students have access to generative artificial intelligence (GenAI) tools, such as GitHub Copilot. One effective solution is to utilise code comprehension questions, where a marker asks questions about a submission to gauge understanding, this can also have the side effect of helping to detect plagiarism. However, this approach is time consuming and can be difficult and/or expensive to scale. This paper introduces AutoMCQ, which uses GenAI for the automatic generation of multiple-choice code comprehension questions. This is integrated with the CodeRunner automated assessment platform.', 'abstract_zh': '学生往往不能完全理解他们编写的代码。这种情况有时直到教育的后期才变得明显，这可能导致更难纠正他们的错误知识或误解。此外，在学生可以获取生成式人工智能（GenAI）工具（如GitHub Copilot）的世界中，完全理解代码的能力变得越来越重要。一种有效的方法是利用代码理解问题，评分者通过提出关于提交的问题来评估理解程度，这还可以作为检测抄袭的侧面效果。然而，这种方法耗时且难以或成本高昂地扩展。本文介绍了AutoMCQ，这是一种利用GenAI自动生成多项选择代码理解问题的方法，并将其与CodeRunner自动评估平台集成。', 'title_zh': 'AutoMCQ —— 使用生成式人工智能自动生成代码理解问题'}
{'arxiv_id': 'arXiv:2505.16429', 'title': 'Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems', 'authors': 'Song Jin, Juntian Zhang, Yuhan Liu, Xun Zhang, Yufei Zhang, Guojun Yin, Fei Jiang, Wei Lin, Rui Yan', 'link': 'https://arxiv.org/abs/2505.16429', 'abstract': 'Evaluating and iterating upon recommender systems is crucial, yet traditional A/B testing is resource-intensive, and offline methods struggle with dynamic user-platform interactions. While agent-based simulation is promising, existing platforms often lack a mechanism for user actions to dynamically reshape the environment. To bridge this gap, we introduce RecInter, a novel agent-based simulation platform for recommender systems featuring a robust interaction mechanism. In RecInter platform, simulated user actions (e.g., likes, reviews, purchases) dynamically update item attributes in real-time, and introduced Merchant Agents can reply, fostering a more realistic and evolving ecosystem. High-fidelity simulation is ensured through Multidimensional User Profiling module, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought (CoT) enriched interaction data. Our platform achieves significantly improved simulation credibility and successfully replicates emergent phenomena like Brand Loyalty and the Matthew Effect. Experiments demonstrate that this interaction mechanism is pivotal for simulating realistic system evolution, establishing our platform as a credible testbed for recommender systems research.', 'abstract_zh': 'RecInter：一种具备动态用户互动机制的推荐系统仿真实验平台', 'title_zh': '超越静态测试床：面向交互的动态推荐系统智能体模拟平台'}
{'arxiv_id': 'arXiv:2505.16425', 'title': '$I^2G$: Generating Instructional Illustrations via Text-Conditioned Diffusion', 'authors': 'Jing Bi, Pinxin Liu, Ali Vosoughi, Jiarui Wu, Jinxi He, Chenliang Xu', 'link': 'https://arxiv.org/abs/2505.16425', 'abstract': 'The effective communication of procedural knowledge remains a significant challenge in natural language processing (NLP), as purely textual instructions often fail to convey complex physical actions and spatial relationships. We address this limitation by proposing a language-driven framework that translates procedural text into coherent visual instructions. Our approach models the linguistic structure of instructional content by decomposing it into goal statements and sequential steps, then conditioning visual generation on these linguistic elements. We introduce three key innovations: (1) a constituency parser-based text encoding mechanism that preserves semantic completeness even with lengthy instructions, (2) a pairwise discourse coherence model that maintains consistency across instruction sequences, and (3) a novel evaluation protocol specifically designed for procedural language-to-image alignment. Our experiments across three instructional datasets (HTStep, CaptainCook4D, and WikiAll) demonstrate that our method significantly outperforms existing baselines in generating visuals that accurately reflect the linguistic content and sequential nature of instructions. This work contributes to the growing body of research on grounding procedural language in visual content, with applications spanning education, task guidance, and multimodal language understanding.', 'abstract_zh': '有效的过程知识通信仍然是自然语言处理（NLP）中的一个显著挑战，因为纯文本指令往往无法传达复杂的物理动作和空间关系。我们通过提出一种语言驱动的框架来解决这一限制，该框架将过程文本转换为连贯的视觉指令。我们的方法通过将指令内容分解为目标陈述和顺序步骤来建模语言结构，然后基于这些语言元素进行视觉生成。我们提出了三项关键创新：（1）基于短语结构解析器的文本编码机制，即使指令较长也能保持语义完整性；（2）一对话语篇连贯模型，确保指令序列之间的一致性；（3）一种专门设计的评估协议，用于过程语言到图像的对齐。我们在三个指令数据集中（HTStep、CaptainCook4D和WikiAll）的实验表明，我们的方法在生成准确反映指令语言内容和顺序性质的视觉效果方面显著优于现有基线。这项工作为将过程语言与视觉内容相结合的研究做出了贡献，具有跨越教育、任务指导和多模态语言理解的应用潜力。', 'title_zh': '$I^2G$: 通过文本条件化扩散生成教学插图'}
{'arxiv_id': 'arXiv:2505.16419', 'title': 'Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment', 'authors': 'Soh Takahashi, Masaru Sasaki, Ken Takeda, Masafumi Oizumi', 'link': 'https://arxiv.org/abs/2505.16419', 'abstract': 'The learning mechanisms by which humans acquire internal representations of objects are not fully understood. Deep neural networks (DNNs) have emerged as a useful tool for investigating this question, as they have internal representations similar to those of humans as a byproduct of optimizing their objective functions. While previous studies have shown that models trained with various learning paradigms - such as supervised, self-supervised, and CLIP - acquire human-like representations, it remains unclear whether their similarity to human representations is primarily at a coarse category level or extends to finer details. Here, we employ an unsupervised alignment method based on Gromov-Wasserstein Optimal Transport to compare human and model object representations at both fine-grained and coarse-grained levels. The unique feature of this method compared to conventional representational similarity analysis is that it estimates optimal fine-grained mappings between the representation of each object in human and model representations. We used this unsupervised alignment method to assess the extent to which the representation of each object in humans is correctly mapped to the corresponding representation of the same object in models. Using human similarity judgments of 1,854 objects from the THINGS dataset, we find that models trained with CLIP consistently achieve strong fine- and coarse-grained matching with human object representations. In contrast, self-supervised models showed limited matching at both fine- and coarse-grained levels, but still formed object clusters that reflected human coarse category structure. Our results offer new insights into the role of linguistic information in acquiring precise object representations and the potential of self-supervised learning to capture coarse categorical structures.', 'abstract_zh': '人类获取物体内部表示的学习机制尚不完全理解。深层神经网络（DNNs）已成为研究这一问题的一个有用工具，因为它们在优化目标函数的过程中产生了类似于人类的内部表示。虽然以前的研究表明，使用不同学习范式（如监督学习、自监督学习和CLIP）训练的模型获得了类似人类的表现，但它们与人类表示的相似性主要是粗略类别层面的，还是延伸到了更精细的细节层面仍然不清楚。在这里，我们利用基于Gromov-Wasserstein最优传输的无监督对齐方法，在粗略和精细层面比较人类和模型的物体表示。与传统的表征相似性分析相比，这种方法的独特之处在于它估计了人类和模型中每个物体表示之间的最优精细映射。我们使用这种无监督对齐方法评估了人类中每个物体表示是否正确映射到模型中相同物体的相应表示。使用来自THINGS数据集的1,854个物体的人类相似性判断，我们发现使用CLIP训练的模型在粗略和精细层面与人类物体表示的匹配较强。相比之下，自监督模型在粗细两个层面的匹配有限，但仍然形成了反映人类粗略类别结构的对象集群。我们的结果提供了关于语言信息在获得精确物体表示中的作用以及自监督学习捕捉粗略类别结构潜力的新见解。', 'title_zh': '基于无监督对齐探究深度神经网络与人类对象图像相似性判断之间细粒度和粗粒度结构对应关系'}
{'arxiv_id': 'arXiv:2505.16416', 'title': 'Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models', 'authors': 'Chengcheng Wang, Jianyuan Guo, Hongguang Li, Yuchuan Tian, Ying Nie, Chang Xu, Kai Han', 'link': 'https://arxiv.org/abs/2505.16416', 'abstract': "Rotary Position Embedding (RoPE) is a widely adopted technique for encoding relative positional information in large language models (LLMs). However, when extended to large vision-language models (LVLMs), its variants introduce unintended cross-modal positional biases. Specifically, they enforce relative positional dependencies between text token indices and image tokens, causing spurious alignments. This issue arises because image tokens representing the same content but located at different spatial positions are assigned distinct positional biases, leading to inconsistent cross-modal associations. To address this, we propose Per-Token Distance (PTD) - a simple yet effective metric for quantifying the independence of positional encodings across modalities. Informed by this analysis, we introduce Circle-RoPE, a novel encoding scheme that maps image token indices onto a circular trajectory orthogonal to the linear path of text token indices, forming a cone-like structure. This configuration ensures that each text token maintains an equal distance to all image tokens, reducing artificial cross-modal biases while preserving intra-image spatial information. To further enhance performance, we propose a staggered layer strategy that applies different RoPE variants across layers. This design leverages the complementary strengths of each RoPE variant, thereby enhancing the model's overall performance. Our experimental results demonstrate that our method effectively preserves spatial information from images while reducing relative positional bias, offering a more robust and flexible positional encoding framework for LVLMs. The code is available at [this https URL](this https URL).", 'abstract_zh': 'Rotary Position Embedding (RoPE)在大型视觉语言模型中的独立性量化及Circle-RoPE方案', 'title_zh': 'Circle-RoPE: 锥形-Decoupled 旋转位置嵌入 for 大型视觉-语言模型'}
{'arxiv_id': 'arXiv:2505.16415', 'title': 'Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation', 'authors': 'Ruizhe Li, Chen Chen, Yuchen Hu, Yanjun Gao, Xi Wang, Emine Yilmaz', 'link': 'https://arxiv.org/abs/2505.16415', 'abstract': 'Retrieval-Augmented Generation (RAG) leverages large language models (LLMs) combined with external contexts to enhance the accuracy and reliability of generated responses. However, reliably attributing generated content to specific context segments, context attribution, remains challenging due to the computationally intensive nature of current methods, which often require extensive fine-tuning or human annotation. In this work, we introduce a novel Jensen-Shannon Divergence driven method to Attribute Response to Context (ARC-JSD), enabling efficient and accurate identification of essential context sentences without additional fine-tuning or surrogate modelling. Evaluations on a wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using instruction-tuned LLMs in different scales demonstrate superior accuracy and significant computational efficiency improvements compared to the previous surrogate-based method. Furthermore, our mechanistic analysis reveals specific attention heads and multilayer perceptron (MLP) layers responsible for context attribution, providing valuable insights into the internal workings of RAG models.', 'abstract_zh': '基于检索增强生成的响应与上下文归因（ARC-JSD）方法', 'title_zh': '基于Jensen-Shannon散度的检索增强生成中上下文归因机理研究'}
{'arxiv_id': 'arXiv:2505.16410', 'title': 'Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning', 'authors': 'Guanting Dong, Yifei Chen, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Yutao Zhu, Hangyu Mao, Guorui Zhou, Zhicheng Dou, Ji-Rong Wen', 'link': 'https://arxiv.org/abs/2505.16410', 'abstract': 'Recently, large language models (LLMs) have shown remarkable reasoning capabilities via large-scale reinforcement learning (RL). However, leveraging the RL algorithm to empower effective multi-tool collaborative reasoning in LLMs remains an open challenge. In this paper, we introduce Tool-Star, an RL-based framework designed to empower LLMs to autonomously invoke multiple external tools during stepwise reasoning. Tool-Star integrates six types of tools and incorporates systematic designs in both data synthesis and training. To address the scarcity of tool-use data, we propose a general tool-integrated reasoning data synthesis pipeline, which combines tool-integrated prompting with hint-based sampling to automatically and scalably generate tool-use trajectories. A subsequent quality normalization and difficulty-aware classification process filters out low-quality samples and organizes the dataset from easy to hard. Furthermore, we propose a two-stage training framework to enhance multi-tool collaborative reasoning by: (1) cold-start fine-tuning, which guides LLMs to explore reasoning patterns via tool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with hierarchical reward design, which reinforces reward understanding and promotes effective tool collaboration. Experimental analyses on over 10 challenging reasoning benchmarks highlight the effectiveness and efficiency of Tool-Star. The code is available at this https URL.', 'abstract_zh': '最近，大型语言模型（LLMs）通过大规模强化学习（RL）展示了卓越的推理能力。然而，利用RL算法增强LLMs的自主多工具协同推理能力仍是一个开放的挑战。本文介绍了一种基于RL的框架Tool-Star，旨在使LLMs在逐步推理过程中自主调用多个外部工具。Tool-Star集成了六类工具，并在数据合成和训练中采用了系统性设计。为了解决工具使用数据稀缺的问题，我们提出了一种通用的工具集成推理数据合成管道，该管道结合了工具集成提示和基于提示的采样，以自动生成工具使用轨迹。随后的质量规范化和难度感知分类过程过滤掉低质量样本，将数据集按难度排序。此外，我们提出了一种两阶段训练框架，通过以下方式增强多工具协同推理能力：（1）冷启动微调，通过工具调用反馈引导LLMs探索推理模式；（2）具有层次化奖励设计的多工具自批判RL算法，增强奖励理解并促进有效的工具协作。对超过10个具有挑战性的推理基准的实验分析突显了Tool-Star的有效性和效率。代码已发布于此：https://this-url。', 'title_zh': 'Tool-Star: 通过强化学习赋能兼具LLM大脑的多工具推理器'}
{'arxiv_id': 'arXiv:2505.16400', 'title': 'AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning', 'authors': 'Yang Chen, Zhuolin Yang, Zihan Liu, Chankyu Lee, Peng Xu, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping', 'link': 'https://arxiv.org/abs/2505.16400', 'abstract': "Despite recent progress in large-scale reinforcement learning (RL) for reasoning, the training recipe for building high-performing reasoning models remains elusive. Key implementation details of frontier models, such as DeepSeek-R1, including data curation strategies and RL training recipe, are often omitted. Moreover, recent research indicates distillation remains more effective than RL for smaller models. In this work, we demonstrate that large-scale RL can significantly enhance the reasoning capabilities of strong, small- and mid-sized models, achieving results that surpass those of state-of-the-art distillation-based models. We systematically study the RL training process through extensive ablations and propose a simple yet effective approach: first training on math-only prompts, then on code-only prompts. Notably, we find that math-only RL not only significantly enhances the performance of strong distilled models on math benchmarks (e.g., +14.6% / +17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks (e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition, extended code-only RL iterations further improve performance on code benchmarks with minimal or no degradation in math results. We develop a robust data curation pipeline to collect challenging prompts with high-quality, verifiable answers and test cases to enable verification-based RL across both domains. Finally, we identify key experimental insights, including curriculum learning with progressively increasing response lengths and the stabilizing effect of on-policy parameter updates. We find that RL not only elicits the foundational reasoning capabilities acquired during pretraining and supervised fine-tuning (e.g., distillation), but also pushes the limits of the model's reasoning ability, enabling it to solve problems that were previously unsolvable.", 'abstract_zh': '尽管在大规模强化学习（RL）推理方面取得了最近的进步，但构建高性能推理模型的训练方法仍不清楚。前沿模型如DeepSeek-R1的关键实现细节，包括数据整理策略和RL训练方法，往往被省略。此外，近期研究表明，蒸馏在小模型上比RL更有效。在这项工作中，我们证明了大规模RL可以显著提升强大、小型和中型模型的推理能力，实现超越最先进的基于蒸馏模型的结果。我们通过广泛的消融研究系统地研究了RL训练过程，并提出了一种简单有效的方法：首先在纯数学提示上训练，然后在纯代码提示上训练。值得注意的是，我们发现纯数学RL不仅显著增强了强大蒸馏模型在数学基准测试中的性能（例如，7B和14B模型在AIME 2025上的性能分别提高14.6%和17.2%），还增强了代码推理任务（例如，在LiveCodeBench上，7B和14B模型分别提高6.8%和5.8%）。此外，扩展的纯代码RL循环将进一步提高代码基准测试中的性能，而对数学结果几乎没有或没有退化。我们开发了一种稳健的数据整理管道，收集具有高质量且可验证答案和测试案例的挑战性提示，以在两个领域实现基于验证的RL。最后，我们确定了一些关键的实验洞见，包括逐步增加回复长度的课程学习和在线策略参数更新的稳定效果。我们发现，RL不仅提取了预训练和监督微调（例如，蒸馏）期间获得的基本推理能力，而且推动了模型推理能力的极限，使其能够解决以前无法解决的问题。', 'title_zh': 'AceReason-Nemotron：通过强化学习推动数学与代码推理发展'}
{'arxiv_id': 'arXiv:2505.16394', 'title': 'Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)', 'authors': 'Zhenjie Yang, Xiaosong Jia, Qifeng Li, Xue Yang, Maoqing Yao, Junchi Yan', 'link': 'https://arxiv.org/abs/2505.16394', 'abstract': 'Reinforcement Learning (RL) can mitigate the causal confusion and distribution shift inherent to imitation learning (IL). However, applying RL to end-to-end autonomous driving (E2E-AD) remains an open problem for its training difficulty, and IL is still the mainstream paradigm in both academia and industry. Recently Model-based Reinforcement Learning (MBRL) have demonstrated promising results in neural planning; however, these methods typically require privileged information as input rather than raw sensor data. We fill this gap by designing Raw2Drive, a dual-stream MBRL approach. Initially, we efficiently train an auxiliary privileged world model paired with a neural planner that uses privileged information as input. Subsequently, we introduce a raw sensor world model trained via our proposed Guidance Mechanism, which ensures consistency between the raw sensor world model and the privileged world model during rollouts. Finally, the raw sensor world model combines the prior knowledge embedded in the heads of the privileged world model to effectively guide the training of the raw sensor policy. Raw2Drive is so far the only RL based end-to-end method on CARLA Leaderboard 2.0, and Bench2Drive and it achieves state-of-the-art performance.', 'abstract_zh': '强化学习（RL）可以缓解模仿学习（IL）中固有的因果混淆和分布偏移问题。然而，将RL应用于端到端自主驾驶（E2E-AD）仍然是一个开放问题，因为其训练难度较大，而IL仍然是学术界和工业界的主流范式。最近，基于模型的强化学习（MBRL）在神经规划领域取得了令人promise的结果；然而，这些方法通常需要特权信息作为输入而非原始传感器数据。我们通过设计Raw2Drive，一种双流MBRL方法来填补这一空白。首先，我们高效地训练一个辅助的特权世界模型，该模型与一个使用特权信息作为输入的神经规划器配对。随后，我们引入了一个通过我们提出的一种引导机制训练的原始传感器世界模型，该机制确保了原始传感器世界模型和特权世界模型在滚动过程中的一致性。最后，原始传感器世界模型结合了特权世界模型头部嵌入的先验知识，有效引导原始传感器策略的训练。Raw2Drive目前是CARLA Leaderboard 2.0和Bench2Drive上唯一的基于RL的端到端方法，并取得了最先进的性能。', 'title_zh': 'Raw2Drive: 基于对齐世界模型的强化学习端到端自动驾驶（在CARLA v2中）'}
{'arxiv_id': 'arXiv:2505.16392', 'title': 'Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection', 'authors': 'Benjamin Vendeville, Liana Ermakova, Pierre De Loor', 'link': 'https://arxiv.org/abs/2505.16392', 'abstract': 'The general public often encounters complex texts but does not have the time or expertise to fully understand them, leading to the spread of misinformation. Automatic Text Simplification (ATS) helps make information more accessible, but its evaluation methods have not kept up with advances in text generation, especially with Large Language Models (LLMs). In particular, recent studies have shown that current ATS metrics do not correlate with the presence of errors. Manual inspections have further revealed a variety of errors, underscoring the need for a more nuanced evaluation framework, which is currently lacking. This resource paper addresses this gap by introducing a test collection for detecting and classifying errors in simplified texts. First, we propose a taxonomy of errors, with a formal focus on information distortion. Next, we introduce a parallel dataset of automatically simplified scientific texts. This dataset has been human-annotated with labels based on our proposed taxonomy. Finally, we analyze the quality of the dataset, and we study the performance of existing models to detect and classify errors from that taxonomy. These contributions give researchers the tools to better evaluate errors in ATS, develop more reliable models, and ultimately improve the quality of automatically simplified texts.', 'abstract_zh': '公共读者经常遇到复杂的文本，但没有足够的时间或专业知识来完全理解这些文本，导致错误信息的传播。自动文本简化（ATS）有助于使信息更加易于获取，但其评估方法尚未跟上文本生成技术的进步，特别是大型语言模型（LLMs）的进步。近期研究显示，当前的ATS指标与错误的出现无关。进一步的手动检查揭示了各种错误，突显了需要一种更加复杂的评估框架的需求，而这一需求目前尚未得到满足。本文献综述通过引入一个检测和分类简化文本中错误的数据集来弥补这一缺口。首先，我们提出了一种错误分类学，重点关注信息失真。其次，我们介绍了自动简化科学文本的平行数据集。该数据集基于我们提出的分类学进行了人工注释。最后，我们分析了数据集的质量，并研究了现有模型检测和分类分类学中错误的性能。这些贡献为研究人员提供了工具，以便更好地评估ATS中的错误，开发更可靠的技术，并最终提高自动简化文本的质量。', 'title_zh': '文本简化中的错误分析资源：新分类与测试集'}
{'arxiv_id': 'arXiv:2505.16379', 'title': 'Materials Generation in the Era of Artificial Intelligence: A Comprehensive Survey', 'authors': 'Zhixun Li, Bin Cao, Rui Jiao, Liang Wang, Ding Wang, Yang Liu, Dingshuo Chen, Jia Li, Qiang Liu, Yu Rong, Liang Wang, Tong-yi Zhang, Jeffrey Xu Yu', 'link': 'https://arxiv.org/abs/2505.16379', 'abstract': 'Materials are the foundation of modern society, underpinning advancements in energy, electronics, healthcare, transportation, and infrastructure. The ability to discover and design new materials with tailored properties is critical to solving some of the most pressing global challenges. In recent years, the growing availability of high-quality materials data combined with rapid advances in Artificial Intelligence (AI) has opened new opportunities for accelerating materials discovery. Data-driven generative models provide a powerful tool for materials design by directly create novel materials that satisfy predefined property requirements. Despite the proliferation of related work, there remains a notable lack of up-to-date and systematic surveys in this area. To fill this gap, this paper provides a comprehensive overview of recent progress in AI-driven materials generation. We first organize various types of materials and illustrate multiple representations of crystalline materials. We then provide a detailed summary and taxonomy of current AI-driven materials generation approaches. Furthermore, we discuss the common evaluation metrics and summarize open-source codes and benchmark datasets. Finally, we conclude with potential future directions and challenges in this fast-growing field. The related sources can be found at this https URL.', 'abstract_zh': '材料是现代社会的基础，支撑着能源、电子、医疗、交通和基础设施等方面的发展。发现和设计具有定制性质的新材料的能力对于解决一些最紧迫的全球挑战至关重要。近年来，高质量材料数据的日益增多与人工智能（AI）的飞速进步相结合，为加速材料发现开辟了新的机会。数据驱动的生成模型为材料设计提供了一种强大工具，可以直接生成满足预定义性质要求的新材料。尽管相关工作日益增多，但在该领域仍缺乏最新的系统性综述。为填补这一空白，本文提供了AI驱动材料生成最近进展的全面概述。我们首先整理各类材料并展示多种晶体材料表现形式，然后详细总结并分类当前的AI驱动材料生成方法。此外，讨论常见的评估指标，并总结开源代码和基准数据集。最后，展望该快速发展的领域中的潜在未来方向和挑战。相关参考资料可访问此链接：this https URL。', 'title_zh': '人工智能时代材料生成：一项全面综述'}
{'arxiv_id': 'arXiv:2505.16377', 'title': 'VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving', 'authors': 'Yansong Qu, Zilin Huang, Zihao Sheng, Jiancong Chen, Sikai Chen, Samuel Labi', 'link': 'https://arxiv.org/abs/2505.16377', 'abstract': 'Reinforcement learning (RL)-based autonomous driving policy learning faces critical limitations such as low sample efficiency and poor generalization; its reliance on online interactions and trial-and-error learning is especially unacceptable in safety-critical scenarios. Existing methods including safe RL often fail to capture the true semantic meaning of "safety" in complex driving contexts, leading to either overly conservative driving behavior or constraint violations. To address these challenges, we propose VL-SAFE, a world model-based safe RL framework with Vision-Language model (VLM)-as-safety-guidance paradigm, designed for offline safe policy learning. Specifically, we construct offline datasets containing data collected by expert agents and labeled with safety scores derived from VLMs. A world model is trained to generate imagined rollouts together with safety estimations, allowing the agent to perform safe planning without interacting with the real environment. Based on these imagined trajectories and safety evaluations, actor-critic learning is conducted under VLM-based safety guidance to optimize the driving policy more safely and efficiently. Extensive evaluations demonstrate that VL-SAFE achieves superior sample efficiency, generalization, safety, and overall performance compared to existing baselines. To the best of our knowledge, this is the first work that introduces a VLM-guided world model-based approach for safe autonomous driving. The demo video and code can be accessed at: this https URL', 'abstract_zh': '基于视觉语言模型的世界模型导向的增强学习安全自驾车策略学习', 'title_zh': 'VL-SAFE: 视觉-语言引导的安全意识强化学习方法及其在自主驾驶中的应用'}
{'arxiv_id': 'arXiv:2505.16376', 'title': 'DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos', 'authors': 'Zijia Lu, A S M Iftekhar, Gaurav Mittal, Tianjian Meng, Xiawei Wang, Cheng Zhao, Rohith Kukkala, Ehsan Elhamifar, Mei Chen', 'link': 'https://arxiv.org/abs/2505.16376', 'abstract': "Long Video Temporal Grounding (LVTG) aims at identifying specific moments within lengthy videos based on user-provided text queries for effective content retrieval. The approach taken by existing methods of dividing video into clips and processing each clip via a full-scale expert encoder is challenging to scale due to prohibitive computational costs of processing a large number of clips in long videos. To address this issue, we introduce DeCafNet, an approach employing ``delegate-and-conquer'' strategy to achieve computation efficiency without sacrificing grounding performance. DeCafNet introduces a sidekick encoder that performs dense feature extraction over all video clips in a resource-efficient manner, while generating a saliency map to identify the most relevant clips for full processing by the expert encoder. To effectively leverage features from sidekick and expert encoders that exist at different temporal resolutions, we introduce DeCaf-Grounder, which unifies and refines them via query-aware temporal aggregation and multi-scale temporal refinement for accurate grounding. Experiments on two LTVG benchmark datasets demonstrate that DeCafNet reduces computation by up to 47\\% while still outperforming existing methods, establishing a new state-of-the-art for LTVG in terms of both efficiency and performance. Our code is available at this https URL.", 'abstract_zh': '长视频时间定位（LVTG）旨在基于用户提供的文本查询在 lengthy 视频中识别特定时刻，以实现有效的内容检索。现有的方法通过将视频分割成片段并在全规模专家编码器处理每个片段，虽然有效，但由于处理长视频中大量片段的计算成本高昂，难以扩展。为了解决这一问题，我们引入了 DeCafNet，该方法采用“委托-征服”策略以实现计算效率，同时不牺牲定位性能。DeCafNet 引入了辅助编码器，该编码器以资源高效的方式对所有视频片段进行密集特征提取，并生成显著性图以识别由专家编码器进行完整处理的最相关片段。为了有效地利用来自辅助编码器和专家编码器在不同时间分辨率上存在的特征，我们引入了 DeCaf-Grounder，通过查询感知的时间聚合和多尺度时间细化统一并精炼它们，从而实现准确的时间定位。在两个 LVTG 标准数据集上的实验表明，DeCafNet 可将计算量减少多达 47% 且性能仍优于现有方法，从而在效率和性能方面均建立了新的 LVTG 状态-of-艺术水平。我们的代码可在以下网址获得。', 'title_zh': 'DeCafNet：委托与征服，实现长视频高效时空语义接地'}
{'arxiv_id': 'arXiv:2505.16372', 'title': 'Temporal and Spatial Feature Fusion Framework for Dynamic Micro Expression Recognition', 'authors': 'Feng Liu, Bingyu Nan, Xuezhong Qian, Xiaolan Fu', 'link': 'https://arxiv.org/abs/2505.16372', 'abstract': 'When emotions are repressed, an individual\'s true feelings may be revealed through micro-expressions. Consequently, micro-expressions are regarded as a genuine source of insight into an individual\'s authentic emotions. However, the transient and highly localised nature of micro-expressions poses a significant challenge to their accurate recognition, with the accuracy rate of micro-expression recognition being as low as 50%, even for professionals. In order to address these challenges, it is necessary to explore the field of dynamic micro expression recognition (DMER) using multimodal fusion techniques, with special attention to the diverse fusion of temporal and spatial modal features. In this paper, we propose a novel Temporal and Spatial feature Fusion framework for DMER (TSFmicro). This framework integrates a Retention Network (RetNet) and a transformer-based DMER network, with the objective of efficient micro-expression recognition through the capture and fusion of temporal and spatial relations. Meanwhile, we propose a novel parallel time-space fusion method from the perspective of modal fusion, which fuses spatio-temporal information in high-dimensional feature space, resulting in complementary "where-how" relationships at the semantic level and providing richer semantic information for the model. The experimental results demonstrate the superior performance of the TSFmicro method in comparison to other contemporary state-of-the-art methods. This is evidenced by its effectiveness on three well-recognised micro-expression datasets.', 'abstract_zh': '基于多模态融合的动态微表情识别的时空特征融合框架（TSFmicro）', 'title_zh': '时空特征融合框架用于动态微表情识别'}
{'arxiv_id': 'arXiv:2505.16368', 'title': 'SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning', 'authors': 'Huanyu Liu, Jia Li, Hao Zhu, Kechi Zhang, Yihong Dong, Ge Li', 'link': 'https://arxiv.org/abs/2505.16368', 'abstract': "How to design reinforcement learning (RL) tasks that effectively unleash the reasoning capability of large language models (LLMs) remains an open question. Existing RL tasks (e.g., math, programming, and constructing reasoning tasks) suffer from three key limitations: (1) Scalability. They rely heavily on human annotation or expensive LLM synthesis to generate sufficient training data. (2) Verifiability. LLMs' outputs are hard to verify automatically and reliably. (3) Controllable Difficulty. Most tasks lack fine-grained difficulty control, making it hard to train LLMs to develop reasoning ability from easy to hard.\nTo address these limitations, we propose Saturn, a SAT-based RL framework that uses Boolean Satisfiability (SAT) problems to train and evaluate LLM reasoning. Saturn enables scalable task construction, rule-based verification, and precise difficulty control. Saturn designs a curriculum learning pipeline that continuously improves LLMs' reasoning capability by constructing SAT tasks of increasing difficulty and training LLMs from easy to hard. To ensure stable training, we design a principled mechanism to control difficulty transitions.\nWe introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying difficulty. It supports the evaluation of how LLM reasoning changes with problem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain Saturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT problems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of +14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B and Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g., AIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in constructing RL tasks, Saturn achieves further improvements of +8.8%. We release the source code, data, and models to support future research.", 'abstract_zh': '如何设计有效的强化学习任务以充分利用大型语言模型的推理能力仍然是一个开放问题。现有强化学习任务（如数学、编程和构建推理任务）存在三个关键局限性：可扩展性、验证性和可控难度。卫星：基于SAT的强化学习框架', 'title_zh': 'SATURN: 基于SAT的强化学习以释放语言模型推理能力'}
{'arxiv_id': 'arXiv:2505.16365', 'title': 'A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules', 'authors': 'Manuel Ruiz-Botella, Marta Sales-Pardo, Roger Guimerà', 'link': 'https://arxiv.org/abs/2505.16365', 'abstract': "Developing new molecular compounds is crucial to address pressing challenges, from health to environmental sustainability. However, exploring the molecular space to discover new molecules is difficult due to the vastness of the space. Here we introduce CoCoGraph, a collaborative and constrained graph diffusion model capable of generating molecules that are guaranteed to be chemically valid. Thanks to the constraints built into the model and to the collaborative mechanism, CoCoGraph outperforms state-of-the-art approaches on standard benchmarks while requiring up to an order of magnitude fewer parameters. Analysis of 36 chemical properties also demonstrates that CoCoGraph generates molecules with distributions more closely matching real molecules than current models. Leveraging the model's efficiency, we created a database of 8.2M million synthetically generated molecules and conducted a Turing-like test with organic chemistry experts to further assess the plausibility of the generated molecules, and potential biases and limitations of CoCoGraph.", 'abstract_zh': '开发新的分子化合物对于应对健康和环境可持续等紧迫挑战至关重要。然而，探索分子空间以发现新分子具有挑战性，因为分子空间极其庞大。我们介绍了CoCoGraph，这是一种协作和受限的图扩散模型，能够生成化学上有效的分子。得益于模型中的约束条件和协作机制，CoCoGraph在标准基准测试上优于当前最先进的方法，同时所需的参数数量最多减少了一个数量级。对36种化学性质的分析还表明，CoCoGraph生成的分子的分布更接近真实分子。利用模型的效率，我们创建了一个包含820万 synthetically 生成分子的数据库，并与有机化学专家进行了类似图灵测试，以进一步评估生成分子的可行性，以及 CoCoGraph 的潜在偏见和局限性。', 'title_zh': '一种生成逼真合成分子的协作约束图扩散模型'}
{'arxiv_id': 'arXiv:2505.16363', 'title': 'AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training', 'authors': 'Huishuai Zhang, Bohan Wang, Luoxin Chen', 'link': 'https://arxiv.org/abs/2505.16363', 'abstract': 'We introduce AdamS, a simple yet effective alternative to Adam for large language model (LLM) pretraining and post-training. By leveraging a novel denominator, i.e., the root of weighted sum of squares of the momentum and the current gradient, AdamS eliminates the need for second-moment estimates. Hence, AdamS is efficient, matching the memory and compute footprint of SGD with momentum while delivering superior optimization performance. Moreover, AdamS is easy to adopt: it can directly inherit hyperparameters of AdamW, and is entirely model-agnostic, integrating seamlessly into existing pipelines without modifications to optimizer APIs or architectures. The motivation behind AdamS stems from the observed $(L_0, L_1)$ smoothness properties in transformer objectives, where local smoothness is governed by gradient magnitudes that can be further approximated by momentum magnitudes. We establish rigorous theoretical convergence guarantees and provide practical guidelines for hyperparameter selection. Empirically, AdamS demonstrates strong performance in various tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B parameters) and reinforcement learning in post-training regimes. With its efficiency, simplicity, and theoretical grounding, AdamS stands as a compelling alternative to existing optimizers.', 'abstract_zh': 'AdamS: 一种用于大规模语言模型预训练和后训练的有效替代Adam的方法', 'title_zh': 'AdamS: 动量本身可以成为大规模语言模型预训练和后训练的规范化方法'}
{'arxiv_id': 'arXiv:2505.16362', 'title': 'Neuromorphic-based metaheuristics: A new generation of low power, low latency and small footprint optimization algorithms', 'authors': 'El-ghazali Talbi', 'link': 'https://arxiv.org/abs/2505.16362', 'abstract': 'Neuromorphic computing (NC) introduces a novel algorithmic paradigm representing a major shift from traditional digital computing of Von Neumann architectures. NC emulates or simulates the neural dynamics of brains in the form of Spiking Neural Networks (SNNs). Much of the research in NC has concentrated on machine learning applications and neuroscience simulations. This paper investigates the modelling and implementation of optimization algorithms and particularly metaheuristics using the NC paradigm as an alternative to Von Neumann architectures, leading to breakthroughs in solving optimization problems.\nNeuromorphic-based metaheuristics (Nheuristics) are supposed to be characterized by low power, low latency and small footprint. Since NC systems are fundamentally different from conventional Von Neumann computers, several challenges are posed to the design and implementation of Nheuristics. A guideline based on a classification and critical analysis is conducted on the different families of metaheuristics and optimization problems they address. We also discuss future directions that need to be addressed to expand both the development and application of Nheuristics.', 'abstract_zh': '神经形态计算驱动的元启发式算法', 'title_zh': '基于神经形态的元启发式算法：新一代低功耗、低延迟和紧凑占用空间的优化算法'}
{'arxiv_id': 'arXiv:2505.16351', 'title': 'Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection', 'authors': 'Chenxu Guo, Jiachen Lian, Xuanru Zhou, Jinming Zhang, Shuhe Li, Zongli Ye, Hwi Joo Park, Anaisha Das, Zoe Ezzes, Jet Vonk, Brittany Morin, Rian Bogley, Lisa Wauters, Zachary Miller, Maria Gorno-Tempini, Gopala Anumanchipalli', 'link': 'https://arxiv.org/abs/2505.16351', 'abstract': 'Automatic detection of speech dysfluency aids speech-language pathologists in efficient transcription of disordered speech, enhancing diagnostics and treatment planning. Traditional methods, often limited to classification, provide insufficient clinical insight, and text-independent models misclassify dysfluency, especially in context-dependent cases. This work introduces Dysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes and detects dysfluency. Unlike previous models, Dysfluent-WFST operates with upstream encoders like WavLM and requires no additional training. It achieves state-of-the-art performance in both phonetic error rate and dysfluency detection on simulated and real speech data. Our approach is lightweight, interpretable, and effective, demonstrating that explicit modeling of pronunciation behavior in decoding, rather than complex architectures, is key to improving dysfluency processing systems.', 'abstract_zh': '自动检测语音不流畅现象有助于言语病理学家高效地转录障碍性言语，提升诊断和治疗规划。传统方法往往仅限于分类，提供的临床洞察不足，且文本无关模型在上下文依赖性病例中误分类不流畅现象。本研究引入了Dysfluent-WFST，这是一种零样本解码器，同时进行音素转录和不流畅检测。与以往模型不同，Dysfluent-WFST 使用如WavLM的上游编码器，无需额外训练即可实现最佳表现。我们的方法轻量、可解释且有效，表明在解码中明确建模发音行为而非复杂架构是提高不流畅检测系统性能的关键。', 'title_zh': '零样本语音断流转写与检测框架：不流畅WFST'}
{'arxiv_id': 'arXiv:2505.16335', 'title': 'FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design', 'authors': 'Renjie Wei, Songqiang Xu, Qingyu Guo, Meng Li', 'link': 'https://arxiv.org/abs/2505.16335', 'abstract': 'Visual autoregressive (VAR) modeling has marked a paradigm shift in image generation from next-token prediction to next-scale prediction. VAR predicts a set of tokens at each step from coarse to fine scale, leading to better image quality and faster inference speed compared to existing diffusion models. However, the large parameter size and computation cost hinder its deployment on edge devices. To reduce the memory and computation cost, we propose FPQVAR, an efficient post-training floating-point (FP) quantization framework for VAR featuring algorithm and hardware co-design. At the algorithm level, we first identify the challenges of quantizing VAR. To address them, we propose Dual Format Quantization for the highly imbalanced input activation. We further propose Group-wise Hadamard Transformation and GHT-Aware Learnable Transformation to address the time-varying outlier channels. At the hardware level, we design the first low-bit FP quantizer and multiplier with lookup tables on FPGA and propose the first FPGA-based VAR accelerator featuring low-bit FP computation and an elaborate two-level pipeline. Extensive experiments show that compared to the state-of-the-art quantization method, our proposed FPQVAR significantly improves Fréchet Inception Distance (FID) from 10.83 to 3.58, Inception Score (IS) from 175.9 to 241.5 under 4-bit quantization. FPQVAR also significantly improves the performance of 6-bit quantized VAR, bringing it on par with the FP16 model. Our accelerator on AMD-Xilinx VCK190 FPGA achieves a throughput of 1.1 image/s, which is 3.1x higher than the integer-based accelerator. It also demonstrates 3.6x and 2.8x higher energy efficiency compared to the integer-based accelerator and GPU baseline, respectively.', 'abstract_zh': '视觉自回归（VAR）建模标志着图像生成从下一个token预测到下一个尺度预测的范式转变。VAR通过从粗尺度到细尺度预测一组token，相比现有的扩散模型，产生了更好的图像质量并加快了推断速度。然而，其庞大的参数量和计算成本阻碍了其在边缘设备上的部署。为了降低内存和计算成本，我们提出了一种高效的事后训练浮点（FP）量化框架FPQVAR，结合了算法和硬件协同设计。在算法层面，我们首先识别了量化VAR的挑战，并提出了双重格式量化以应对高度不平衡的输入激活。我们进一步提出了组内哈达玛变换及基于组内哈达玛变换的可学习变换，以应对时间变化的异常通道。在硬件层面，我们设计了首个用于FPGA的低比特浮点量化器和乘法器，并提出了首个基于FPGA的VAR加速器，该加速器实现了低比特浮点计算和细致两级流水线。广泛实验显示，相比最先进的量化方法，我们提出的FPQVAR在4比特量化下显著提高了弗雷chet inception距离（FID）至3.58（从10.83），提高了风格转移分数（IS）至241.5（从175.9）。FPQVAR还显著提高了6比特量化VAR的性能，使其与FP16模型持平。我们的加速器在AMD-Xilinx VCK190 FPGA上实现了每秒1.1张图像的吞吐量，比整数基加速器高3.1倍。与整数基加速器相比，其能效提升了3.6倍，与GPU基线相比，能效提高了2.8倍。', 'title_zh': 'FPQVAR：基于FPGA硬件协同设计的浮点量化视觉自回归模型'}
{'arxiv_id': 'arXiv:2505.16332', 'title': 'Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing', 'authors': 'Zhehui Wanga, Benjamin Chen Ming Choonga, Tian Huang, Daniel Gerlinghoffa, Rick Siow Mong Goh, Cheng Liu, Tao Luo', 'link': 'https://arxiv.org/abs/2505.16332', 'abstract': 'Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across various domains. In deep learning, deep neural networks (DNN) have reached immense sizes to support new predictive capabilities. Optimization of large-scale models is critical for sustainable deployment, but becomes increasingly challenging with ever-growing model sizes and complexity. While quantum optimization is suitable for solving complex problems, its application to DNN optimization is not straightforward, requiring thorough reformulation for compatibility with commercially available quantum devices. In this work, we explore the potential of adopting AQC for fine-grained pruning-quantization of convolutional neural networks. We rework established heuristics to formulate model compression as a quadratic unconstrained binary optimization (QUBO) problem, and assess the solution space offered by commercial quantum annealing devices. Through our exploratory efforts of reformulation, we demonstrate that AQC can achieve effective compression of practical DNN models. Experiments demonstrate that adiabatic quantum computing (AQC) not only outperforms classical algorithms like genetic algorithms and reinforcement learning in terms of time efficiency but also excels at identifying global optima.', 'abstract_zh': '量子优化是目前最成熟的量子计算技术，提供了高效解决复杂组合问题的有望途径。近年来，通过绝热量子计算（AQC）等方法在不同领域的重要优化问题上得到了应用。在深度学习中，深度神经网络（DNN）已达到巨大规模以支持新的预测能力。大规模模型的优化对于可持续部署至关重要，但随着模型规模和复杂性的不断增加，这一过程越来越具挑战性。虽然量子优化适合解决复杂问题，但将其应用于DNN优化并不简单，需要彻底改革以适应现有的商用量子设备。在本工作中，我们探讨了采用绝热量子计算（AQC）进行卷积神经网络精细剪枝-量化的方法。我们将现有的启发式方法重新构建成二次无约束二元优化（QUBO）问题，并评估商用量子退火设备提供的解空间。通过重新构形的努力，我们证明AQC能够有效压缩实际的DNN模型。实验表明，绝热量子计算（AQC）不仅在时间效率上优于遗传算法和强化学习等经典算法，且在识别全局最优解方面也表现出色。', 'title_zh': '量子优化准备就绪了吗？基于腺联量子计算的神经网络压缩研究'}
{'arxiv_id': 'arXiv:2505.16330', 'title': 'SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers', 'authors': 'Wenqing Wu, Chengzhi Zhang, Tong Bao, Yi Zhao', 'link': 'https://arxiv.org/abs/2505.16330', 'abstract': "Novelty is a core component of academic papers, and there are multiple perspectives on the assessment of novelty. Existing methods often focus on word or entity combinations, which provide limited insights. The content related to a paper's novelty is typically distributed across different core sections, e.g., Introduction, Methodology and Results. Therefore, exploring the optimal combination of sections for evaluating the novelty of a paper is important for advancing automated novelty assessment. In this paper, we utilize different combinations of sections from academic papers as inputs to drive language models to predict novelty scores. We then analyze the results to determine the optimal section combinations for novelty score prediction. We first employ natural language processing techniques to identify the sectional structure of academic papers, categorizing them into introduction, methods, results, and discussion (IMRaD). Subsequently, we used different combinations of these sections (e.g., introduction and methods) as inputs for pretrained language models (PLMs) and large language models (LLMs), employing novelty scores provided by human expert reviewers as ground truth labels to obtain prediction results. The results indicate that using introduction, results and discussion is most appropriate for assessing the novelty of a paper, while the use of the entire text does not yield significant results. Furthermore, based on the results of the PLMs and LLMs, the introduction and results appear to be the most important section for the task of novelty score prediction. The code and dataset for this paper can be accessed at this https URL.", 'abstract_zh': '新颖性是学术论文的核心组成部分，对于新颖性的评估有多重视角。现有方法通常侧重于单词或实体组合，提供了有限的洞察。论文新颖性的相关内容通常分布在不同的核心部分，如引言、方法和结果。因此，探索用于评估论文新颖性的最佳部分组合对于推动自动新颖性评估的发展至关重要。本文利用学术论文的不同部分组合作为输入，驱动语言模型预测新颖性得分。随后，我们分析结果以确定用于新颖性得分预测的最佳部分组合。我们首先采用自然语言处理技术识别学术论文的结构性质，将其分为引言、方法、结果和讨论（IMRaD）。随后，我们使用这些部分的不同组合（例如，引言和方法）作为预训练语言模型（PLMs）和大型语言模型（LLMs）的输入，使用人类专家评审员提供的新颖性得分作为真实标签，以获取预测结果。结果表明，使用引言、结果和讨论更适合评估论文的新颖性，而使用整个文本则未得到显著的预测结果。此外，基于PLMs和LLMs的结果，引言和结果似乎是新颖性得分预测任务中最重要部分。本文的代码和数据集可在以下网址访问。', 'title_zh': 'SC4ANM: 识别学术论文新颖性预测自动化中的最优段落组合'}
{'arxiv_id': 'arXiv:2505.16325', 'title': 'CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation', 'authors': 'Yuyang Jiang, Chacha Chen, Shengyuan Wang, Feng Li, Zecong Tang, Benjamin M. Mervak, Lydia Chelala, Christopher M Straus, Reve Chahine, Samuel G. Armato III, Chenhao Tan', 'link': 'https://arxiv.org/abs/2505.16325', 'abstract': "Existing metrics often lack the granularity and interpretability to capture nuanced clinical differences between candidate and ground-truth radiology reports, resulting in suboptimal evaluation. We introduce a Clinically-grounded tabular framework with Expert-curated labels and Attribute-level comparison for Radiology report evaluation (CLEAR). CLEAR not only examines whether a report can accurately identify the presence or absence of medical conditions, but also assesses whether it can precisely describe each positively identified condition across five key attributes: first occurrence, change, severity, descriptive location, and recommendation. Compared to prior works, CLEAR's multi-dimensional, attribute-level outputs enable a more comprehensive and clinically interpretable evaluation of report quality. Additionally, to measure the clinical alignment of CLEAR, we collaborate with five board-certified radiologists to develop CLEAR-Bench, a dataset of 100 chest X-ray reports from MIMIC-CXR, annotated across 6 curated attributes and 13 CheXpert conditions. Our experiments show that CLEAR achieves high accuracy in extracting clinical attributes and provides automated metrics that are strongly aligned with clinical judgment.", 'abstract_zh': '一种基于临床的表格框架：专家标注与属性级比较用于放射报告评估（CLEAR）', 'title_zh': 'CLEAR：一种基于临床的表格式放射报告评估框架'}
{'arxiv_id': 'arXiv:2505.16322', 'title': 'AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners', 'authors': 'Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun', 'link': 'https://arxiv.org/abs/2505.16322', 'abstract': "Self-Taught Reasoners (STaR), synonymously known as Rejection sampling Fine-Tuning (RFT), is an integral part of the training pipeline of self-improving reasoning Language Models (LMs). The self-improving mechanism often employs random observation (data) sampling. However, this results in trained observation imbalance; inefficiently over-training on solved examples while under-training on challenging ones. In response, we introduce Adaptive STaR (AdaSTaR), a novel algorithm that rectifies this by integrating two adaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting balanced training across observations, and (2) Adaptive Sampling for Curriculum: dynamically adjusting data difficulty to match the model's evolving strength. Across six benchmarks, AdaSTaR achieves best test accuracy in all instances (6/6) and reduces training FLOPs by an average of 58.6% against an extensive list of baselines. These improvements in performance and efficiency generalize to different pre-trained LMs and larger models, paving the way for more efficient and effective self-improving LMs.", 'abstract_zh': '自学习推理器（STaR），又称拒绝采样微调（RFT），是自我改进推理语言模型（LMs）训练管道中的一个关键组成部分。为了应对训练过程中出现的观察数据不平衡问题，即过度训练于已解决问题而忽视具有挑战性的问题，我们提出了自适应STaR（AdaSTaR）算法，该算法结合了两种自适应采样原则：（1）多样性自适应采样：促进观察数据的均衡训练，（2） Curriculum自适应采样：动态调整数据难度以匹配模型的发展强度。在六个基准上，AdaSTaR在所有情况下均实现了最佳测试准确率，并且与一系列基线相比，平均减少了58.6%的训练FLOPs。这些在性能和效率上的改进适用于不同预训练的LMs和更大规模的模型，为更高效和有效的自我改进LMs铺平了道路。', 'title_zh': 'AdaSTaR: 自适应数据采样训练自教会推理器'}
{'arxiv_id': 'arXiv:2505.16314', 'title': 'NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment', 'authors': 'Shuhao Han, Haotian Fan, Fangyuan Kong, Wenjie Liao, Chunle Guo, Chongyi Li, Radu Timofte, Liang Li, Tao Li, Junhui Cui, Yunqiu Wang, Yang Tai, Jingwei Sun, Jianhui Sun, Xinli Yue, Tianyi Wang, Huan Hou, Junda Lu, Xinyang Huang, Zitang Zhou, Zijian Zhang, Xuhui Zheng, Xuecheng Wu, Chong Peng, Xuezhi Cao, Trong-Hieu Nguyen-Mau, Minh-Hoang Le, Minh-Khoa Le-Phan, Duy-Nam Ly, Hai-Dang Nguyen, Minh-Triet Tran, Yukang Lin, Yan Hong, Chuanbiao Song, Siyuan Li, Jun Lan, Zhichao Zhang, Xinyue Li, Wei Sun, Zicheng Zhang, Yunhao Li, Xiaohong Liu, Guangtao Zhai, Zitong Xu, Huiyu Duan, Jiarui Wang, Guangji Ma, Liu Yang, Lu Liu, Qiang Hu, Xiongkuo Min, Zichuan Wang, Zhenchen Tang, Bo Peng, Jing Dong, Fengbin Guan, Zihao Yu, Yiting Lu, Wei Luo, Xin Li, Minhao Lin, Haofeng Chen, Xuanxuan He, Kele Xu, Qisheng Xu, Zijian Gao, Tianjiao Wan, Bo-Cheng Qiu, Chih-Chung Hsu, Chia-ming Lee, Yu-Fan Lin, Bo Yu, Zehao Wang, Da Mu, Mingxiu Chen, Junkang Fang, Huamei Sun, Wending Zhao, Zhiyu Wang, Wang Liu, Weikang Yu, Puhong Duan, Bin Sun, Xudong Kang, Shutao Li, Shuai He, Lingzhi Fu, Heng Cong, Rongyu Zhang, Jiarong He, Zhishan Qiao, Yongqing Huang, Zewen Chen, Zhe Pang, Juan Wang, Jian Guo, Zhizhuo Shao, Ziyu Feng, Bing Li, Weiming Hu', 'link': 'https://arxiv.org/abs/2505.16314', 'abstract': 'This paper reports on the NTIRE 2025 challenge on Text to Image (T2I) generation model quality assessment, which will be held in conjunction with the New Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025. The aim of this challenge is to address the fine-grained quality assessment of text-to-image generation models. This challenge evaluates text-to-image models from two aspects: image-text alignment and image structural distortion detection, and is divided into the alignment track and the structural track. The alignment track uses the EvalMuse-40K, which contains around 40K AI-Generated Images (AIGIs) generated by 20 popular generative models. The alignment track has a total of 371 registered participants. A total of 1,883 submissions are received in the development phase, and 507 submissions are received in the test phase. Finally, 12 participating teams submitted their models and fact sheets. The structure track uses the EvalMuse-Structure, which contains 10,000 AI-Generated Images (AIGIs) with corresponding structural distortion mask. A total of 211 participants have registered in the structure track. A total of 1155 submissions are received in the development phase, and 487 submissions are received in the test phase. Finally, 8 participating teams submitted their models and fact sheets. Almost all methods have achieved better results than baseline methods, and the winning methods in both tracks have demonstrated superior prediction performance on T2I model quality assessment.', 'abstract_zh': 'NTIRE 2025挑战赛：文本到图像生成模型质量评估', 'title_zh': 'NTIRE 2025挑战赛：文本到图像生成模型质量评估'}
{'arxiv_id': 'arXiv:2505.16307', 'title': 'PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models', 'authors': 'Chenzhuo Zhao, Ziqian Liu, Xingda Wang, Junting Lu, Chaoyi Ruan', 'link': 'https://arxiv.org/abs/2505.16307', 'abstract': "Prompt optimization offers a practical and broadly applicable alternative to fine-tuning for improving large language model (LLM) performance. However, existing methods often rely on costly output generation, self-critiquing abilities, or human-annotated preferences, which limit their scalability, especially for smaller or non-instruction-tuned models. We introduce PMPO (Probabilistic Metric Prompt Optimization), a unified framework that refines prompts using token-level cross-entropy loss as a direct, lightweight evaluation signal. PMPO identifies low-quality prompt segments by masking and measuring their impact on loss, then rewrites and selects improved variants by minimizing loss over positive and negative examples. Unlike prior methods, it requires no output sampling or human evaluation during optimization, relying only on forward passes and log-likelihoods. PMPO supports both supervised and preference-based tasks through a closely aligned loss-based evaluation strategy. Experiments show that PMPO consistently outperforms prior methods across model sizes and tasks: it achieves the highest average accuracy on BBH, performs strongly on GSM8K and AQUA-RAT, and improves AlpacaEval 2.0 win rates by over 19 points. These results highlight PMPO's effectiveness, efficiency, and broad applicability.", 'abstract_zh': '概率度量提示优化为提高大型语言模型性能提供了一种实用且广泛适用的替代方法，无需微调。然而，现有方法通常依赖于昂贵的输出生成、自我批判能力或人工标注的偏好，这限制了它们的扩展性，尤其是在对于较小或未指令微调的模型中。我们引入了PMPO（概率度量提示优化）统一框架，该框架使用标记级交叉熵损失作为直接、轻量级的评价信号来精炼提示。PMPO通过遮罩和测量其对损失的影响来识别低质量提示段落，然后通过最小化损失来重写和选择改进的版本。与先有方法不同，它在优化过程中不需要采样输出或人工评估，仅依赖前向传递和对数似然性。PMPO通过紧密对齐的基于损失的评价策略支持监督和偏好任务。实验结果表明，PMPO在不同模型规模和任务中均优于先前方法：在BBH上实现最高平均准确率，在GSM8K和AQUA-RAT上表现强劲，并将AlpacaEval 2.0的胜率提高了超过19个百分点。这些结果突显了PMPO的有效性、效率和广泛的适用性。', 'title_zh': 'PMPO：概率度量提示优化方法研究（适用于小型和大型语言模型）'}
{'arxiv_id': 'arXiv:2505.16306', 'title': 'Layer-wise Investigation of Large-Scale Self-Supervised Music Representation Models', 'authors': 'Yizhi Zhou, Haina Zhu, Hangting Chen', 'link': 'https://arxiv.org/abs/2505.16306', 'abstract': 'Recently, pre-trained models for music information retrieval based on self-supervised learning (SSL) are becoming popular, showing success in various downstream tasks. However, there is limited research on the specific meanings of the encoded information and their applicability. Exploring these aspects can help us better understand their capabilities and limitations, leading to more effective use in downstream tasks.\nIn this study, we analyze the advanced music representation model MusicFM and the newly emerged SSL model MuQ. We focus on three main aspects: (i) validating the advantages of SSL models across multiple downstream tasks, (ii) exploring the specialization of layer-wise information for different tasks, and (iii) comparing performance differences when selecting specific layers. Through this analysis, we reveal insights into the structure and potential applications of SSL models in music information retrieval.', 'abstract_zh': '近年来，基于自监督学习（SSL）的音乐信息检索预训练模型逐渐流行，并在各种下游任务中取得了成功。然而，对编码信息的具体含义及其适用性的研究相对有限。探索这些方面有助于我们更深入地了解其能力和局限性，从而更有效地应用于下游任务。\n\n在本研究中，我们分析了先进的音乐表示模型MusicFM和新兴的SSL模型MuQ。我们重点关注三个方面：（i）验证SSL模型在多种下游任务中的优势，（ii）探索不同任务中逐层信息的专业化特性，（iii）比较选择特定层时的性能差异。通过这些分析，我们揭示了SSL模型在音乐信息检索中的结构及其潜在应用。', 'title_zh': '大规模自我监督音乐表示模型的分层探究'}
{'arxiv_id': 'arXiv:2505.16301', 'title': 'Artificial Intelligence for Direct Prediction of Molecular Dynamics Across Chemical Space', 'authors': 'Fuchun Ge, Pavlo O. Dral', 'link': 'https://arxiv.org/abs/2505.16301', 'abstract': "Molecular dynamics (MD) is a powerful tool for exploring the behavior of atomistic systems, but its reliance on sequential numerical integration limits simulation efficiency. We present MDtrajNet-1, a foundational AI model that directly generates MD trajectories across chemical space, bypassing force calculations and integration. This approach accelerates simulations by up to two orders of magnitude compared to traditional MD, even those enhanced by machine-learning interatomic potentials. MDtrajNet-1 combines equivariant neural networks with a Transformer-based architecture to achieve strong accuracy and transferability in predicting long-time trajectories for both known and unseen systems. Remarkably, the errors of the trajectories generated by MDtrajNet-1 for various molecular systems are close to those of the conventional ab initio MD. The model's flexible design supports diverse application scenarios, including different statistical ensembles, boundary conditions, and interaction types. By overcoming the intrinsic speed barrier of conventional MD, MDtrajNet-1 opens new frontiers in efficient and scalable atomistic simulations.", 'abstract_zh': 'MDtrajNet-1：直接生成化学空间中MD轨迹的基stdbool模型', 'title_zh': '人工智能直接预测化学空间中的分子动力学'}
{'arxiv_id': 'arXiv:2505.16290', 'title': 'Multimodal Generative AI for Story Point Estimation in Software Development', 'authors': 'Mohammad Rubyet Islam, Peter Sandborn', 'link': 'https://arxiv.org/abs/2505.16290', 'abstract': 'This research explores the application of Multimodal Generative AI to enhance story point estimation in Agile software development. By integrating text, image, and categorical data using advanced models like BERT, CNN, and XGBoost, our approach surpasses the limitations of traditional single-modal estimation methods. The results demonstrate strong accuracy for simpler story points, while also highlighting challenges in more complex categories due to data imbalance. This study further explores the impact of categorical data, particularly severity, on the estimation process, emphasizing its influence on model performance. Our findings emphasize the transformative potential of multimodal data integration in refining AI-driven project management, paving the way for more precise, adaptable, and domain-specific AI capabilities. Additionally, this work outlines future directions for addressing data variability and enhancing the robustness of AI in Agile methodologies.', 'abstract_zh': '这项研究探索了多模态生成AI在敏捷软件开发中增强故事点估计的应用。通过使用BERT、CNN和XGBoost等先进模型整合文本、图像和分类数据，我们的方法超越了传统单模态估计方法的局限性。结果表明，对于较简单的故事点，我们的方法具有很强的准确性，而对于更复杂的类别，则由于数据不平衡也揭示了一些挑战。本研究进一步探讨了分类数据，尤其是严重性，对估计过程的影响，强调了其对模型性能的影响。我们的研究结果强调了多模态数据整合在细化AI驱动项目管理方面的变革潜力，为更精确、更具适应性和领域特定的AI能力铺平了道路。此外，这项工作还概述了未来方向，以应对数据变化性并增强敏捷方法中AI的稳健性。', 'title_zh': '多模态生成AI在软件开发中的故事点估算'}
{'arxiv_id': 'arXiv:2505.16278', 'title': 'DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving', 'authors': 'Zhenjie Yang, Yilin Chai, Xiaosong Jia, Qifeng Li, Yuqian Shao, Xuekai Zhu, Haisheng Su, Junchi Yan', 'link': 'https://arxiv.org/abs/2505.16278', 'abstract': 'End-to-end autonomous driving (E2E-AD) demands effective processing of multi-view sensory data and robust handling of diverse and complex driving scenarios, particularly rare maneuvers such as aggressive turns. Recent success of Mixture-of-Experts (MoE) architecture in Large Language Models (LLMs) demonstrates that specialization of parameters enables strong scalability. In this work, we propose DriveMoE, a novel MoE-based E2E-AD framework, with a Scene-Specialized Vision MoE and a Skill-Specialized Action MoE. DriveMoE is built upon our $\\pi_0$ Vision-Language-Action (VLA) baseline (originally from the embodied AI field), called Drive-$\\pi_0$. Specifically, we add Vision MoE to Drive-$\\pi_0$ by training a router to select relevant cameras according to the driving context dynamically. This design mirrors human driving cognition, where drivers selectively attend to crucial visual cues rather than exhaustively processing all visual information. In addition, we add Action MoE by training another router to activate specialized expert modules for different driving behaviors. Through explicit behavioral specialization, DriveMoE is able to handle diverse scenarios without suffering from modes averaging like existing models. In Bench2Drive closed-loop evaluation experiments, DriveMoE achieves state-of-the-art (SOTA) performance, demonstrating the effectiveness of combining vision and action MoE in autonomous driving tasks. We will release our code and models of DriveMoE and Drive-$\\pi_0$.', 'abstract_zh': '端到端自主驾驶（E2E-AD）要求有效地处理多视图感知数据，并且能够 robust 地处理多样且复杂的驾驶场景，特别是激烈的转向等罕见操作。MoE 架构在大语言模型（LLMs）中的 recent 成功表明，参数的专业化能够实现 strong 的扩展性。在本文中，我们提出了一种新型的 MoE 基础的端到端自主驾驶框架 DriveMoE，包含场景专业化视觉 MoE 和技能专业化行动 MoE。DriveMoE 是建立在我们 $\\pi_0$ 视觉-语言-行动（VLA）基线基础上的，称为 Drive-$\\pi_0$（最初来自赋能 AI 领域）。具体来说，我们在 Drive-$\\pi_0$ 中加入了视觉 MoE，通过训练一个路由器动态选择与驾驶情境相关的摄像头。这种设计反映了人类驾驶的认知模式，即驾驶员会选择性地关注关键的视觉线索而不会处理所有的视觉信息。此外，我们通过训练另一个路由器激活不同的专家模块来增强行动 MoE，以适应不同的驾驶行为。通过明确的行为专业化，DriveMoE 能够处理多样化的场景，避免了现有模型中模式平均的问题。在 Bench2Drive 闭环评估实验中，DriveMoE 达到了最先进的（SOTA）性能，证明了结合视觉和行动 MoE 在自主驾驶任务中的有效性。我们将发布 DriveMoE 和 Drive-$\\pi_0$ 的代码和模型。', 'title_zh': 'DriveMoE：端到端自动驾驶中的视觉-语言-动作模型的混合专家模型'}
{'arxiv_id': 'arXiv:2505.16270', 'title': 'Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning', 'authors': 'Jiaru Zou, Yikun Ban, Zihao Li, Yunzhe Qi, Ruizhong Qiu, Ling Yang, Jingrui He', 'link': 'https://arxiv.org/abs/2505.16270', 'abstract': "Large language models are typically adapted to downstream tasks through supervised fine-tuning on domain-specific data. While standard fine-tuning focuses on minimizing generation loss to optimize model parameters, we take a deeper step by retaining and leveraging the model's own learning signals, analogous to how human learners reflect on past mistakes to improve future performance. We first introduce the concept of Mistake Log to systematically track the model's learning behavior and recurring errors throughout fine-tuning. Treating the original transformer-based model as the Pilot, we correspondingly design a Copilot model to refine the Pilot's inference performance via logits rectification. We name the overall Pilot-Copilot framework the Transformer Copilot, which introduces (i) a novel Copilot model design, (ii) a joint training paradigm where the Copilot continuously learns from the evolving Mistake Log alongside the Pilot, and (iii) a fused inference paradigm where the Copilot rectifies the Pilot's logits for enhanced generation. We provide both theoretical and empirical analyses on our new learning framework. Experiments on 12 benchmarks spanning commonsense, arithmetic, and recommendation tasks demonstrate that Transformer Copilot consistently improves performance by up to 34.5%, while introducing marginal computational overhead to Pilot models and exhibiting strong scalability and transferability.", 'abstract_zh': '大型语言模型通常通过领域特定数据的监督微调来适应下游任务。而标准的微调侧重于最小化生成损失以优化模型参数，我们则更进一步，通过保留并利用模型自身的学习信号来改进模型，类似于人类学习者通过反思过去的错误来提升未来的表现。我们首先引入了“错误日志”（Mistake Log）的概念，系统地追踪微调过程中模型的学习行为及其反复出现的错误。我们将原始的基于Transformer的模型视为“副驾”（Pilot），相应地设计了一个“副驾”模型，通过修正“副驾”的概率输出来提升“副驾”的推理性能。我们将整体的“副驾-副驾”框架命名为Transformer Copilot，该框架引入了(i)一种新型的“副驾”模型设计，(ii)一种联合训练范式，其中“副驾”不断从不断演化的错误日志中学习，并与“副驾”同步进行，以及(iii)一种融合推理范式，其中“副驾”修正“副驾”的概率输出以增强生成性能。我们对新的学习框架进行了理论和实验分析。在涵盖常识、算术和推荐等12个基准任务的实验中，Transformer Copilot 一致地提高了34.5%的性能，同时对“副驾”模型的计算开销仅增加了轻微的影响，并且展示了强大的扩展性和迁移性。', 'title_zh': 'Transformer Copilot: 从错误日志中学习在大型语言模型 fine-tuning 中'}
{'arxiv_id': 'arXiv:2505.16259', 'title': 'Dialogue in Resonance: An Interactive Music Piece for Piano and Real-Time Automatic Transcription System', 'authors': 'Hayeon Bang, Taegyun Kwon, Juhan Nam', 'link': 'https://arxiv.org/abs/2505.16259', 'abstract': "This paper presents <Dialogue in Resonance>, an interactive music piece for a human pianist and a computer-controlled piano that integrates real-time automatic music transcription into a score-driven framework. Unlike previous approaches that primarily focus on improvisation-based interactions, our work establishes a balanced framework that combines composed structure with dynamic interaction. Through real-time automatic transcription as its core mechanism, the computer interprets and responds to the human performer's input in real time, creating a musical dialogue that balances compositional intent with live interaction while incorporating elements of unpredictability. In this paper, we present the development process from composition to premiere performance, including technical implementation, rehearsal process, and performance considerations.", 'abstract_zh': '《共鸣中的对话：一种结合实时自动音乐转写的互动音乐作品》', 'title_zh': '共振中的对话：钢琴与实时自动 transcription 系统的互动音乐作品'}
{'arxiv_id': 'arXiv:2505.16258', 'title': 'IRONIC: Coherence-Aware Reasoning Chains for Multi-Modal Sarcasm Detection', 'authors': 'Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee', 'link': 'https://arxiv.org/abs/2505.16258', 'abstract': 'Interpreting figurative language such as sarcasm across multi-modal inputs presents unique challenges, often requiring task-specific fine-tuning and extensive reasoning steps. However, current Chain-of-Thought approaches do not efficiently leverage the same cognitive processes that enable humans to identify sarcasm. We present IRONIC, an in-context learning framework that leverages Multi-modal Coherence Relations to analyze referential, analogical and pragmatic image-text linkages. Our experiments show that IRONIC achieves state-of-the-art performance on zero-shot Multi-modal Sarcasm Detection across different baselines. This demonstrates the need for incorporating linguistic and cognitive insights into the design of multi-modal reasoning strategies. Our code is available at: this https URL', 'abstract_zh': '跨多模态输入解释比喻语言如讽刺带来了独特挑战，通常需要特定任务的微调和广泛的推理步骤。然而，当前的链式思考方法并未高效利用人类识别讽刺的认知过程。我们提出了IRONIC，一种基于多模态一致性关系的上下文学习框架，用于分析参照性、类比性和语用性的图文关联。我们的实验结果显示，IRONIC在零样本多模态讽刺检测方面实现了最佳性能，这表明需要将语言和认知洞察力纳入多模态推理策略的设计中。我们的代码可在以下链接获取：this https URL', 'title_zh': 'IRONIC: 具有连贯性意识的多模态讽刺检测推理链'}
{'arxiv_id': 'arXiv:2505.16256', 'title': 'DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor', 'authors': 'Yan Zhao, Zhengxue Cheng, Junxuan Zhang, Qunshan Gu, Qi Wang, Li Song', 'link': 'https://arxiv.org/abs/2505.16256', 'abstract': 'Most learning-based lossless compressors are designed for a single modality, requiring separate models for multi-modal data and lacking flexibility. However, different modalities vary significantly in format and statistical properties, making it ineffective to use compressors that lack modality-specific adaptations. While multi-modal large language models (MLLMs) offer a potential solution for modality-unified compression, their excessive complexity hinders practical deployment. To address these challenges, we focus on the two most common modalities, image and text, and propose DualComp, the first unified and lightweight learning-based dual-modality lossless compressor. Built on a lightweight backbone, DualComp incorporates three key structural enhancements to handle modality heterogeneity: modality-unified tokenization, modality-switching contextual learning, and modality-routing mixture-of-experts. A reparameterization training strategy is also used to boost compression performance. DualComp integrates both modality-specific and shared parameters for efficient parameter utilization, enabling near real-time inference (200KB/s) on desktop CPUs. With much fewer parameters, DualComp achieves compression performance on par with the SOTA LLM-based methods for both text and image datasets. Its simplified single-modality variant surpasses the previous best image compressor on the Kodak dataset by about 9% using just 1.2% of the model size.', 'abstract_zh': 'DualComp：一种轻量级的统一双模态无损压缩器', 'title_zh': 'DualComp: 统一无损双模态端到端压缩学习'}
{'arxiv_id': 'arXiv:2505.16249', 'title': 'Manipulating Elasto-Plastic Objects With 3D Occupancy and Learning-Based Predictive Control', 'authors': 'Zhen Zhang, Xiangyu Chu, Yunxi Tang, Lulu Zhao, Jing Huang, Zhongliang Jiang, K. W. Samuel Au', 'link': 'https://arxiv.org/abs/2505.16249', 'abstract': 'Manipulating elasto-plastic objects remains a significant challenge due to severe self-occlusion, difficulties of representation, and complicated dynamics. This work proposes a novel framework for elasto-plastic object manipulation with a quasi-static assumption for motions, leveraging 3D occupancy to represent such objects, a learned dynamics model trained with 3D occupancy, and a learning-based predictive control algorithm to address these challenges effectively. We build a novel data collection platform to collect full spatial information and propose a pipeline for generating a 3D occupancy dataset. To infer the 3D occupancy during manipulation, an occupancy prediction network is trained with multiple RGB images supervised by the generated dataset. We design a deep neural network empowered by a 3D convolution neural network (CNN) and a graph neural network (GNN) to predict the complex deformation with the inferred 3D occupancy results. A learning-based predictive control algorithm is introduced to plan the robot actions, incorporating a novel shape-based action initialization module specifically designed to improve the planner efficiency. The proposed framework in this paper can successfully shape the elasto-plastic objects into a given goal shape and has been verified in various experiments both in simulation and the real world.', 'abstract_zh': '基于拟静止假设的弹性塑性物体操作新型框架', 'title_zh': '基于3D占据表示和学习导向的预测控制的弹性-塑性物体操纵'}
{'arxiv_id': 'arXiv:2505.16234', 'title': 'LIFEBench: Evaluating Length Instruction Following in Large Language Models', 'authors': 'Wei Zhang, Zhenhong Zhou, Junfeng Fang, Rongwu Xu, Kun Wang, Yuanhe Zhang, Rui Wang, Ge Zhang, Xinfeng Li, Li Sun, Lingjuan Lyu, Yang Liu, Sen Su', 'link': 'https://arxiv.org/abs/2505.16234', 'abstract': "While large language models (LLMs) can solve PhD-level reasoning problems over long context inputs, they still struggle with a seemingly simpler task: following explicit length instructions-e.g., write a 10,000-word novel. Additionally, models often generate far too short outputs, terminate prematurely, or even refuse the request. Existing benchmarks focus primarily on evaluating generations quality, but often overlook whether the generations meet length constraints. To this end, we introduce Length Instruction Following Evaluation Benchmark (LIFEBench) to comprehensively evaluate LLMs' ability to follow length instructions across diverse tasks and a wide range of specified lengths. LIFEBench consists of 10,800 instances across 4 task categories in both English and Chinese, covering length constraints ranging from 16 to 8192 words. We evaluate 26 widely-used LLMs and find that most models reasonably follow short-length instructions but deteriorate sharply beyond a certain threshold. Surprisingly, almost all models fail to reach the vendor-claimed maximum output lengths in practice, as further confirmed by our evaluations extending up to 32K words. Even long-context LLMs, despite their extended input-output windows, counterintuitively fail to improve length-instructions following. Notably, Reasoning LLMs outperform even specialized long-text generation models, achieving state-of-the-art length following. Overall, LIFEBench uncovers fundamental limitations in current LLMs' length instructions following ability, offering critical insights for future progress.", 'abstract_zh': '长指令遵循评估基准（LIFEBench）', 'title_zh': 'LIFEBench: 评估大型语言模型的长度指令跟随能力'}
{'arxiv_id': 'arXiv:2505.16227', 'title': 'Explain Less, Understand More: Jargon Detection via Personalized Parameter-Efficient Fine-tuning', 'authors': 'Bohao Wu, Qingyun Wang, Yue Guo', 'link': 'https://arxiv.org/abs/2505.16227', 'abstract': 'Personalizing jargon detection and explanation is essential for making technical documents accessible to readers with diverse disciplinary backgrounds. However, tailoring models to individual users typically requires substantial annotation efforts and computational resources due to user-specific finetuning. To address this, we present a systematic study of personalized jargon detection, focusing on methods that are both efficient and scalable for real-world deployment. We explore two personalization strategies: (1) lightweight fine-tuning using Low-Rank Adaptation (LoRA) on open-source models, and (2) personalized prompting, which tailors model behavior at inference time without retaining. To reflect realistic constraints, we also investigate hybrid approaches that combine limited annotated data with unsupervised user background signals. Our personalized LoRA model outperforms GPT-4 by 21.4% in F1 score and exceeds the best performing oracle baseline by 8.3%. Remarkably, our method achieves comparable performance using only 10% of the annotated training data, demonstrating its practicality for resource-constrained settings. Our study offers the first work to systematically explore efficient, low-resource personalization of jargon detection using open-source language models, offering a practical path toward scalable, user-adaptive NLP system.', 'abstract_zh': '个性化领域术语检测与解释对于使技术文档对多元化学科背景的阅读者更加 accessible 至关重要。然而，针对 individual 用户调整模型通常需要大量的注释努力和计算资源以进行用户特定的微调。为解决这一问题，我们进行了一项系统研究，专注于高效且可扩展的个性化领域术语检测方法，以满足实际部署需求。我们探索了两种个性化策略：（1）使用低秩适应（LoRA）对开源模型进行轻量级微调，以及（2）个性化提示，该方法在推理时调整模型行为而不进行保留。为了反映现实中的限制，我们还研究了结合有限标注数据与无监督用户背景信号的混合方法。我们的个性化 LoRA 模型在 F1 分数上比 GPT-4 高出 21.4%，并在标注训练数据上仅使用 10% 的情况下超越了最佳的 oracle 基准，8.3%。值得注意的是，我们的方法证明了在资源受限的环境中其实用性。我们的研究是首个系统探讨使用开源语言模型高效且低资源个性化领域术语检测的工作，提供了一条通向可扩展且用户自适应 NLP 系统的实用路径。', 'title_zh': '解释更少，理解更多：个性化参数高效微调的领域术语检测'}
{'arxiv_id': 'arXiv:2505.16211', 'title': 'AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models', 'authors': 'Kai Li, Can Shen, Yile Liu, Jirui Han, Kelong Zheng, Xuechao Zou, Zhe Wang, Xingjian Du, Shun Zhang, Hanjun Luo, Yingbin Jin, Xinxin Xing, Ziyang Ma, Yue Liu, Xiaojun Jia, Yifan Zhang, Junfeng Fang, Kun Wang, Yibo Yan, Haoyang Li, Yiming Li, Xiaobin Zhuang, Yang Liu, Haibo Hu, Zhuo Chen, Zhizheng Wu, Xiaolin Hu, Eng-Siong Chng, XiaoFeng Wang, Wenyuan Xu, Wei Dong, Xinfeng Li', 'link': 'https://arxiv.org/abs/2505.16211', 'abstract': 'The rapid advancement and expanding applications of Audio Large Language Models (ALLMs) demand a rigorous understanding of their trustworthiness. However, systematic research on evaluating these models, particularly concerning risks unique to the audio modality, remains largely unexplored. Existing evaluation frameworks primarily focus on the text modality or address only a restricted set of safety dimensions, failing to adequately account for the unique characteristics and application scenarios inherent to the audio modality. We introduce AudioTrust-the first multifaceted trustworthiness evaluation framework and benchmark specifically designed for ALLMs. AudioTrust facilitates assessments across six key dimensions: fairness, hallucination, safety, privacy, robustness, and authentication. To comprehensively evaluate these dimensions, AudioTrust is structured around 18 distinct experimental setups. Its core is a meticulously constructed dataset of over 4,420 audio/text samples, drawn from real-world scenarios (e.g., daily conversations, emergency calls, voice assistant interactions), specifically designed to probe the multifaceted trustworthiness of ALLMs. For assessment, the benchmark carefully designs 9 audio-specific evaluation metrics, and we employ a large-scale automated pipeline for objective and scalable scoring of model outputs. Experimental results reveal the trustworthiness boundaries and limitations of current state-of-the-art open-source and closed-source ALLMs when confronted with various high-risk audio scenarios, offering valuable insights for the secure and trustworthy deployment of future audio models. Our platform and benchmark are available at this https URL.', 'abstract_zh': 'AudioTrust：面向音频大语言模型的多维度可信性评估框架与基准', 'title_zh': 'AudioTrust: 评估音频大规模语言模型的多维度可信性'}
{'arxiv_id': 'arXiv:2505.16210', 'title': 'NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics', 'authors': 'Zhihang Cai, Xingjun Zhang, Zhendong Tan, Zheng Wei', 'link': 'https://arxiv.org/abs/2505.16210', 'abstract': 'Large Language Models (LLMs) have demonstrated remarkable proficiency across a wide range of tasks. However, LLMs often require larger batch sizes to enhance throughput or longer context lengths to meet task demands, which significantly increases the memory resource consumption of the Key-Value (KV) cache during inference, becoming a major bottleneck in LLM deployment. To address this issue, quantization is a common and straightforward approach. Currently, quantization methods for activations are limited to 8-bit, and quantization to even lower bits can lead to substantial accuracy drops. To further save space by quantizing the KV cache to even lower bits, we analyzed the element distribution of the KV cache and designed the NQKV algorithm. Since the elements within each block of the KV cache follow a normal distribution, NQKV employs per-block quantile quantization to achieve information-theoretically optimal quantization error. Without significantly compromising model output quality, NQKV enables the OPT model to perform inference with an 2x larger batch size or a 4x longer context length, and it improves throughput by 9.3x compared to when the KV cache is not used.', 'abstract_zh': '大型语言模型通过量化技术实现KV缓存高效 inference', 'title_zh': 'NQKV：基于正态分布特性的一种键值缓存量化方案'}
{'arxiv_id': 'arXiv:2505.16208', 'title': 'Using Echo-State Networks to Reproduce Rare Events in Chaotic Systems', 'authors': 'Anton Erofeev, Balasubramanya T. Nadiga, Ilya Timofeyev', 'link': 'https://arxiv.org/abs/2505.16208', 'abstract': 'We apply the Echo-State Networks to predict the time series and statistical properties of the competitive Lotka-Volterra model in the chaotic regime. In particular, we demonstrate that Echo-State Networks successfully learn the chaotic attractor of the competitive Lotka-Volterra model and reproduce histograms of dependent variables, including tails and rare events. We use the Generalized Extreme Value distribution to quantify the tail behavior.', 'abstract_zh': '我们应用回声状态网络预测竞争Lotka-Volterra模型在混沌区间的时间序列和统计特性。特别地，我们证明回声状态网络能够学习竞争Lotka-Volterra模型的混沌吸引子，并重现因变量的直方图，包括尾部和稀有事件。我们使用广义极值分布定量分析尾部行为。', 'title_zh': '使用回响状态网络重现混沌系统中的罕见事件'}
{'arxiv_id': 'arXiv:2505.16196', 'title': 'SEM: Enhancing Spatial Understanding for Robust Robot Manipulation', 'authors': 'Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Yiwei Jin, Keyu Li, Zhizhong Su', 'link': 'https://arxiv.org/abs/2505.16196', 'abstract': 'A key challenge in robot manipulation lies in developing policy models with strong spatial understanding, the ability to reason about 3D geometry, object relations, and robot embodiment. Existing methods often fall short: 3D point cloud models lack semantic abstraction, while 2D image encoders struggle with spatial reasoning. To address this, we propose SEM (Spatial Enhanced Manipulation model), a novel diffusion-based policy framework that explicitly enhances spatial understanding from two complementary perspectives. A spatial enhancer augments visual representations with 3D geometric context, while a robot state encoder captures embodiment-aware structure through graphbased modeling of joint dependencies. By integrating these modules, SEM significantly improves spatial understanding, leading to robust and generalizable manipulation across diverse tasks that outperform existing baselines.', 'abstract_zh': '机器人操作中的一个关键挑战在于开发具有强烈空间理解能力的策略模型，即能够推理三维几何、物体关系和机器人本体的能力。现有方法往往不够理想：3D点云模型缺乏语义抽象，而2D图像编码器在空间推理方面存在问题。为此，我们提出了一种新的基于扩散的策略框架SEM（Spatial Enhanced Manipulation模型），该框架从两个互补的角度 Explicitly 提升空间理解能力。空间增强器通过添加3D几何上下文来增强视觉表示，而机器人状态编码器则通过基于图的关节依赖建模来捕捉本体感知的结构。通过整合这些模块，SEM 显著提高了空间理解能力，从而在各种任务中实现了稳健且通用的操作，优于现有基线方法。', 'title_zh': 'SEM: 提升空间理解以实现稳健的机器人操作'}
{'arxiv_id': 'arXiv:2505.16195', 'title': 'SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet', 'authors': 'Zhi Zhong, Akira Takahashi, Shuyang Cui, Keisuke Toyama, Shusuke Takahashi, Yuki Mitsufuji', 'link': 'https://arxiv.org/abs/2505.16195', 'abstract': 'Foley synthesis aims to synthesize high-quality audio that is both semantically and temporally aligned with video frames. Given its broad application in creative industries, the task has gained increasing attention in the research community. To avoid the non-trivial task of training audio generative models from scratch, adapting pretrained audio generative models for video-synchronized foley synthesis presents an attractive direction. ControlNet, a method for adding fine-grained controls to pretrained generative models, has been applied to foley synthesis, but its use has been limited to handcrafted human-readable temporal conditions. In contrast, from-scratch models achieved success by leveraging high-dimensional deep features extracted using pretrained video encoders. We have observed a performance gap between ControlNet-based and from-scratch foley models. To narrow this gap, we propose SpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward video-synchronized foley synthesis via ControlNet. To unlock the potential of a single ControlNet branch, we resolve the discrepancy between the temporal video features and the time-frequency nature of the pretrained SpecMaskGIT via a frequency-aware temporal feature aligner, eliminating the need for complicated conditioning mechanisms widely used in prior arts. Evaluations on a common foley synthesis benchmark demonstrate that SpecMaskFoley could even outperform strong from-scratch baselines, substantially advancing the development of ControlNet-based foley synthesis models. Demo page: this https URL', 'abstract_zh': 'SpecMaskFoley：一种通过ControlNet引导的预训练SpecMaskGIT模型用于视频同步FOLEY合成的方法', 'title_zh': 'SpecMaskFoley: 通过ControlNet引导预训练频谱掩蔽生成变换器实现同步视频到音频合成'}
{'arxiv_id': 'arXiv:2505.16192', 'title': 'VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought', 'authors': 'Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang', 'link': 'https://arxiv.org/abs/2505.16192', 'abstract': 'Recently, reasoning-based MLLMs have achieved a degree of success in generating long-form textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on and revisiting of visual regions to achieve precise grounding of textual reasoning in visual evidence. We introduce \\textbf{VLM-R$^3$} (\\textbf{V}isual \\textbf{L}anguage \\textbf{M}odel with \\textbf{R}egion \\textbf{R}ecognition and \\textbf{R}easoning), a framework that equips an MLLM with the ability to (i) decide \\emph{when} additional visual evidence is needed, (ii) determine \\emph{where} to ground within the image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved chain-of-thought. The core of our method is \\textbf{Region-Conditioned Reinforcement Policy Optimization (R-GRPO)}, a training paradigm that rewards the model for selecting informative regions, formulating appropriate transformations (e.g.\\ crop, zoom), and integrating the resulting visual context into subsequent reasoning steps. To bootstrap this policy, we compile a modest but carefully curated Visuo-Lingual Interleaved Rationale (VLIR) corpus that provides step-level supervision on region selection and textual justification. Extensive experiments on MathVista, ScienceQA, and other benchmarks show that VLM-R$^3$ sets a new state of the art in zero-shot and few-shot settings, with the largest gains appearing on questions demanding subtle spatial reasoning or fine-grained visual cue extraction.', 'abstract_zh': 'VLM-R$^3$：视觉语言模型与区域识别及推理', 'title_zh': 'VLM-R³: 区域识别、推理和精炼以增强多模态链式思考'}
{'arxiv_id': 'arXiv:2505.16187', 'title': 'EasyInsert: A Data-Efficient and Generalizable Insertion Policy', 'authors': 'Guanghe Li, Junming Zhao, Shengjie Wang, Yang Gao', 'link': 'https://arxiv.org/abs/2505.16187', 'abstract': 'Insertion task is highly challenging that requires robots to operate with exceptional precision in cluttered environments. Existing methods often have poor generalization capabilities. They typically function in restricted and structured environments, and frequently fail when the plug and socket are far apart, when the scene is densely cluttered, or when handling novel objects. They also rely on strong assumptions such as access to CAD models or a digital twin in simulation. To address this, we propose EasyInsert, a framework which leverages the human intuition that relative pose (delta pose) between plug and socket is sufficient for successful insertion, and employs efficient and automated real-world data collection with minimal human labor to train a generalizable model for relative pose prediction. During execution, EasyInsert follows a coarse-to-fine execution procedure based on predicted delta pose, and successfully performs various insertion tasks. EasyInsert demonstrates strong zero-shot generalization capability for unseen objects in cluttered environments, handling cases with significant initial pose deviations while maintaining high sample efficiency and requiring little human effort. In real-world experiments, with just 5 hours of training data, EasyInsert achieves over 90% success in zero-shot insertion for 13 out of 15 unseen novel objects, including challenging objects like Type-C cables, HDMI cables, and Ethernet cables. Furthermore, with only one human demonstration and 4 minutes of automatically collected data for fine-tuning, it reaches over 90% success rate for all 15 objects.', 'abstract_zh': '插入任务高度具有挑战性，要求机器人在拥挤环境中以极高的精度操作。现有方法通常具有较差的泛化能力。它们通常仅在受限和结构化的环境中有效，并且经常在插头和插座距离较远、场景高度拥挤或处理新型物体时失败。这些方法还依赖于诸如CAD模型访问或模拟中的数字孪生等强烈假设。为解决这一问题，我们提出了EasyInsert框架，该框架利用人类直觉，即插头和插座之间的相对姿态（增量姿态）对于成功的插入是足够的，并通过最少的人工劳动高效且自动化地收集现实世界数据来训练一个可泛化的相对姿态预测模型。在执行过程中，EasyInsert基于预测的增量姿态采取粗到细的执行程序，并成功完成了多种插入任务。EasyInsert展示了在未见过的物体和拥挤环境中出色的零-shot泛化能力，即使初始姿态偏差较大也能保持高样本效率并减少人工投入。在实际实验中，仅使用5小时的训练数据，EasyInsert在13个未见过的新型物体上的零-shot插入成功率超过90%，包括Type-C数据线、HDMI数据线和以太网数据线等具有挑战性的物体。此外，仅通过一次人工演示和4分钟的自动收集数据进行微调后，它对所有15个物体的插入成功率超过90%。', 'title_zh': 'EasyInsert: 一种数据高效且通用的插入策略'}
{'arxiv_id': 'arXiv:2505.16181', 'title': 'Understanding Generative AI Capabilities in Everyday Image Editing Tasks', 'authors': 'Mohammad Reza Taesiri, Brandon Collins, Logan Bolton, Viet Dac Lai, Franck Dernoncourt, Trung Bui, Anh Totti Nguyen', 'link': 'https://arxiv.org/abs/2505.16181', 'abstract': 'Generative AI (GenAI) holds significant promise for automating everyday image editing tasks, especially following the recent release of GPT-4o on March 25, 2025. However, what subjects do people most often want edited? What kinds of editing actions do they want to perform (e.g., removing or stylizing the subject)? Do people prefer precise edits with predictable outcomes or highly creative ones? By understanding the characteristics of real-world requests and the corresponding edits made by freelance photo-editing wizards, can we draw lessons for improving AI-based editors and determine which types of requests can currently be handled successfully by AI editors? In this paper, we present a unique study addressing these questions by analyzing 83k requests from the past 12 years (2013-2025) on the Reddit community, which collected 305k PSR-wizard edits. According to human ratings, approximately only 33% of requests can be fulfilled by the best AI editors (including GPT-4o, Gemini-2.0-Flash, SeedEdit). Interestingly, AI editors perform worse on low-creativity requests that require precise editing than on more open-ended tasks. They often struggle to preserve the identity of people and animals, and frequently make non-requested touch-ups. On the other side of the table, VLM judges (e.g., o1) perform differently from human judges and may prefer AI edits more than human edits. Code and qualitative examples are available at: this https URL', 'abstract_zh': '生成式AI（GenAI）在自动化日常图像编辑任务方面展现出显著的潜力，尤其是在2025年3月25日GPT-4o发布之后。人们最常希望编辑哪些主题？他们希望执行哪种编辑动作（例如，移除或风格化主题）？人们偏好精确的编辑还是高度创意的编辑？通过对过去12年（2013-2025） Reddit社区中83,000个请求及其305,000个PSR-巫师编辑的分析，我们了解真实世界请求的特点和相应的编辑结果，能否从中汲取改进基于AI的编辑器的教训，并确定哪些类型的请求当前可以由AI编辑器成功处理？在本文中，我们呈现了一项独特研究，通过分析Reddit社区过去12年中的83,000个请求及其305,000个PSR-巫师编辑来回答这些问题。根据人类评级，仅约33%的请求可以由最佳AI编辑器（包括GPT-4o、Gemini-2.0-Flash、SeedEdit）满足。有趣的是，AI编辑器在需要精确编辑的低创意请求上表现不如更开放的任务。它们往往难以保留人物和动物的身份，并经常进行未请求的润色。相比之下，VLM评判者（如o1）的表现不同于人类评判者，可能会更偏好AI编辑而非人类编辑。相关代码和定性示例可在以下链接获取：this https URL', 'title_zh': '理解生成式人工智能在日常图像编辑任务中的能力'}
{'arxiv_id': 'arXiv:2505.16175', 'title': 'QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design', 'authors': 'Benjamin Schneider, Dongfu Jiang, Chao Du, Tianyu Pang, Wenhu Chen', 'link': 'https://arxiv.org/abs/2505.16175', 'abstract': 'Long-video understanding has emerged as a crucial capability in real-world applications such as video surveillance, meeting summarization, educational lecture analysis, and sports broadcasting. However, it remains computationally prohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential video decoding, the process of converting the raw bit stream to RGB frames can take up to a minute for hour-long video inputs, and 2) costly prefilling of up to several million tokens for LLM inference, resulting in high latency and memory use. To address these challenges, we propose QuickVideo, a system-algorithm co-design that substantially accelerates long-video understanding to support real-time downstream applications. It comprises three key innovations: QuickDecoder, a parallelized CPU-based video decoder that achieves 2-3 times speedup by splitting videos into keyframe-aligned intervals processed concurrently; QuickPrefill, a memory-efficient prefilling method using KV-cache pruning to support more frames with less GPU memory; and an overlapping scheme that overlaps CPU video decoding with GPU inference. Together, these components infernece time reduce by a minute on long video inputs, enabling scalable, high-quality video understanding even on limited hardware. Experiments show that QuickVideo generalizes across durations and sampling rates, making long video processing feasible in practice.', 'abstract_zh': '长视频理解在视频监控、会议总结、教育讲座分析和体育广播等实际应用中日益成为关键能力。然而，由于两个瓶颈，这一能力对于VideoLLMs来说仍然是计算上不可行的：1) 顺序视频解码，将原始位流转换为RGB帧的过程可能需要几分钟来处理一个小时的视频输入；2) 预填充LLM推理所需的高达数百万个标记，导致高延迟和大量内存使用。为了解决这些挑战，我们提出了一种系统-算法协同设计的方案QuickVideo，以显著加速长视频理解，支持实时下游应用。该方案包含了三个关键创新：QuickDecoder，一种基于并行CPU的视频解码器，通过按关键帧对齐的区间并行处理视频，实现2-3倍的速度提升；QuickPrefill，一种高效的预填充方法，通过使用KV缓存剪枝来支持更多帧，减少GPU内存使用；以及一种重叠方案，该方案将CPU视频解码与GPU推理重叠。这些组件共同减少了长视频推理时间一分钟，即使在限制硬件条件下也能实现可扩展且高质量的视频理解。实验表明，QuickVideo能够在不同持续时间和采样率下泛化，使实际中的长视频处理成为可能。', 'title_zh': 'QuickVideo: 实时长视频理解的系统算法协同设计'}
{'arxiv_id': 'arXiv:2505.16172', 'title': 'Automated Feedback Loops to Protect Text Simplification with Generative AI from Information Loss', 'authors': 'Abhay Kumara Sri Krishna Nandiraju, Gondy Leroy, David Kauchak, Arif Ahmed', 'link': 'https://arxiv.org/abs/2505.16172', 'abstract': 'Understanding health information is essential in achieving and maintaining a healthy life. We focus on simplifying health information for better understanding. With the availability of generative AI, the simplification process has become efficient and of reasonable quality, however, the algorithms remove information that may be crucial for comprehension. In this study, we compare generative AI to detect missing information in simplified text, evaluate its importance, and fix the text with the missing information. We collected 50 health information texts and simplified them using gpt-4-0613. We compare five approaches to identify missing elements and regenerate the text by inserting the missing elements. These five approaches involve adding missing entities and missing words in various ways: 1) adding all the missing entities, 2) adding all missing words, 3) adding the top-3 entities ranked by gpt-4-0613, and 4, 5) serving as controls for comparison, adding randomly chosen entities. We use cosine similarity and ROUGE scores to evaluate the semantic similarity and content overlap between the original, simplified, and reconstructed simplified text. We do this for both summaries and full text. Overall, we find that adding missing entities improves the text. Adding all the missing entities resulted in better text regeneration, which was better than adding the top-ranked entities or words, or random words. Current tools can identify these entities, but are not valuable in ranking them.', 'abstract_zh': '理解健康信息对于实现和维持健康生活至关重要。本研究重点在于简化健康信息以提高理解效果。借助生成式AI，简化过程变得高效且质量合理，然而算法可能会移除对于理解至关重要的信息。本研究旨在比较生成式AI检测简化文本中缺失信息的能力，并评估这些信息的重要性，进而通过插入缺失信息修复文本。我们收集了50篇健康信息文本，并使用gpt-4-0613进行简化。我们比较了五种方法以识别缺失元素并通过对缺失元素进行再生来修复文本。这五种方法包括以不同方式添加缺失实体和缺失词汇：1) 添加所有缺失实体，2) 添加所有缺失词汇，3) 添加由gpt-4-0613排名前三的实体，以及4)、5) 作为对照，添加随机选择的实体。我们使用余弦相似度和ROUGE分数来评估原始文本、简化文本和重构简化文本之间的语义相似性和内容重叠。这包括摘要和完整文本。总体而言，我们发现添加缺失实体能够提高文本的质量。添加所有缺失实体的效果优于添加排名靠前的实体或随机词汇。当前工具可以识别这些实体，但在排序方面尚不具备价值。', 'title_zh': '自动反馈循环以保护基于生成式AI的文字简化不致信息损失'}
{'arxiv_id': 'arXiv:2505.16149', 'title': 'When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification', 'authors': 'Zirui Pang, Haosheng Tan, Yuhan Pu, Zhijie Deng, Zhouan Shen, Keyu Hu, Jiaheng Wei', 'link': 'https://arxiv.org/abs/2505.16149', 'abstract': 'Image classification benchmark datasets such as CIFAR, MNIST, and ImageNet serve as critical tools for model evaluation. However, despite the cleaning efforts, these datasets still suffer from pervasive noisy labels and often contain missing labels due to the co-existing image pattern where multiple classes appear in an image sample. This results in misleading model comparisons and unfair evaluations. Existing label cleaning methods focus primarily on noisy labels, but the issue of missing labels remains largely overlooked. Motivated by these challenges, we present a comprehensive framework named REVEAL, integrating state-of-the-art pre-trained vision-language models (e.g., LLaVA, BLIP, Janus, Qwen) with advanced machine/human label curation methods (e.g., Docta, Cleanlab, MTurk), to systematically address both noisy labels and missing label detection in widely-used image classification test sets. REVEAL detects potential noisy labels and omissions, aggregates predictions from various methods, and refines label accuracy through confidence-informed predictions and consensus-based filtering. Additionally, we provide a thorough analysis of state-of-the-art vision-language models and pre-trained image classifiers, highlighting their strengths and limitations within the context of dataset renovation by revealing 10 observations. Our method effectively reveals missing labels from public datasets and provides soft-labeled results with likelihoods. Through human verifications, REVEAL significantly improves the quality of 6 benchmark test sets, highly aligning to human judgments and enabling more accurate and meaningful comparisons in image classification.', 'abstract_zh': '基于图像分类基准数据集（如CIFAR、MNIST和ImageNet）的清理框架：同时应对噪声标签与缺失标签', 'title_zh': '当大模型遇到图像分类：通过缺失标签识别更新测试集'}
{'arxiv_id': 'arXiv:2505.16146', 'title': 'Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation', 'authors': 'Zhenglin Hua, Jinghan He, Zijun Yao, Tianxu Han, Haiyun Guo, Yuheng Jia, Junfeng Fang', 'link': 'https://arxiv.org/abs/2505.16146', 'abstract': "Large vision-language models (LVLMs) have achieved remarkable performance on multimodal tasks such as visual question answering (VQA) and image captioning. However, they still suffer from hallucinations, generating text inconsistent with visual input, posing significant risks in real-world applications. Existing approaches to address this issue focus on incorporating external knowledge bases, alignment training, or decoding strategies, all of which require substantial computational cost and time. Recent works try to explore more efficient alternatives by adjusting LVLMs' internal representations. Although promising, these methods may cause hallucinations to be insufficiently suppressed or lead to excessive interventions that negatively affect normal semantics. In this work, we leverage sparse autoencoders (SAEs) to identify semantic directions closely associated with either hallucinations or actuality, realizing more precise and direct hallucination-related representations. Our analysis demonstrates that interventions along the faithful direction we identified can mitigate hallucinations, while those along the hallucinatory direction can exacerbate them. Building on these insights, we propose Steering LVLMs via SAE Latent Directions (SSL), a training-free method based on SAE-derived latent directions to mitigate hallucinations in LVLMs. Extensive experiments demonstrate that SSL significantly outperforms existing decoding approaches in mitigating hallucinations, while maintaining transferability across different model architectures with negligible additional time overhead.", 'abstract_zh': '利用稀疏自编码器引导LVLMs减轻幻觉（Steering LVLMs via SAE Latent Directions (SSL) for Mitigating Hallucinations）', 'title_zh': '通过稀疏自编码器引导LVLMs以减轻幻觉现象'}
{'arxiv_id': 'arXiv:2505.16136', 'title': 'Interpretable Machine Learning for Macro Alpha: A News Sentiment Case Study', 'authors': 'Yuke Zhang', 'link': 'https://arxiv.org/abs/2505.16136', 'abstract': "This study introduces an interpretable machine learning (ML) framework to extract macroeconomic alpha from global news sentiment. We process the Global Database of Events, Language, and Tone (GDELT) Project's worldwide news feed using FinBERT -- a Bidirectional Encoder Representations from Transformers (BERT) based model pretrained on finance-specific language -- to construct daily sentiment indices incorporating mean tone, dispersion, and event impact. These indices drive an XGBoost classifier, benchmarked against logistic regression, to predict next-day returns for EUR/USD, USD/JPY, and 10-year U.S. Treasury futures (ZN). Rigorous out-of-sample (OOS) backtesting (5-fold expanding-window cross-validation, OOS period: c. 2017-April 2025) demonstrates exceptional, cost-adjusted performance for the XGBoost strategy: Sharpe ratios achieve 5.87 (EUR/USD), 4.65 (USD/JPY), and 4.65 (Treasuries), with respective compound annual growth rates (CAGRs) exceeding 50% in Foreign Exchange (FX) and 22% in bonds. Shapley Additive Explanations (SHAP) affirm that sentiment dispersion and article impact are key predictive features. Our findings establish that integrating domain-specific Natural Language Processing (NLP) with interpretable ML offers a potent and explainable source of macro alpha.", 'abstract_zh': '本研究介绍了一种可解释的机器学习框架，用于从全球新闻情绪中提取宏观经济阿尔法。我们使用基于金融专用语言预训练的FinBERT模型处理GDELT项目的世界各地新闻Feed，构建包含平均情绪、波动性和事件影响的日度情绪指数。这些指数驱动了与逻辑回归基准对比的XGBoost分类器，用于预测EUR/USD、USD/JPY和10年期美国国债期货（ZN）的下一交易日回报。严格的外样本回测（5折扩展窗口交叉验证，外样本期约为2017年-2025年4月）表明，XGBoost策略具有出色的成本调整后表现：夏普比率分别为5.87（EUR/USD）、4.65（USD/JPY）和4.65（国债），相应的外汇（FX）和债券的复合年增长率分别超过50%和22%。Shapley添加解释（SHAP）证实情绪波动性和文章影响是关键的预测特征。研究结果表明，将领域特定的自然语言处理与可解释的机器学习结合使用，提供了一种强大的可解释的宏观经济阿尔法来源。', 'title_zh': '可解释的机器学习在宏观经济alpha中的应用：基于新闻情绪的研究案例'}
{'arxiv_id': 'arXiv:2505.16130', 'title': 'Scalable Graph Generative Modeling via Substructure Sequences', 'authors': 'Zehong Wang, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye', 'link': 'https://arxiv.org/abs/2505.16130', 'abstract': 'Graph neural networks (GNNs) has been predominantly driven by message-passing, where node representations are iteratively updated via local neighborhood aggregation. Despite their success, message-passing suffers from fundamental limitations -- including constrained expressiveness, over-smoothing, over-squashing, and limited capacity to model long-range dependencies. These issues hinder scalability: increasing data size or model size often fails to yield improved performance, limiting the viability of GNNs as backbones for graph foundation models. In this work, we explore pathways beyond message-passing and introduce Generative Graph Pattern Machine (G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM represents graph instances (nodes, edges, or entire graphs) as sequences of substructures, and employs generative pre-training over the sequences to learn generalizable, transferable representations. Empirically, G$^2$PM demonstrates strong scalability: on the ogbn-arxiv benchmark, it continues to improve with model sizes up to 60M parameters, outperforming prior generative approaches that plateau at significantly smaller scales (e.g., 3M). In addition, we systematically analyze the model design space, highlighting key architectural choices that contribute to its scalability and generalization. Across diverse tasks -- including node classification, graph classification, and transfer learning -- G$^2$PM consistently outperforms strong baselines, establishing a compelling foundation for scalable graph learning. The code and dataset are available at this https URL.', 'abstract_zh': '图神经网络（GNNs）主要依赖于消息传递，其中节点表示通过局部邻域聚合迭代更新。尽管取得了成功，但消息传递存在根本局限性，包括表达能力受限、过度平滑、过度挤压，以及建模长距离依赖关系的能力有限。这些问题阻碍了扩展性：数据量或模型规模的增加往往未能提升性能，限制了GNNs作为图基础模型骨干网络的可行性。在本文中，我们探索了超越消息传递的途径，并引入了生成图模式机器（G$^2$PM），这是一种针对图的生成Transformer预训练框架。G$^2$PM将图实例（节点、边或整个图）表示为子结构序列，并通过序列的生成预训练来学习可泛化的、可迁移的表示。实验证明，G$^2$PM具有强大的扩展性：在ogbn-arxiv基准上，其性能随着模型规模达到60M参数时仍然不断提升，超越了在较小规模（如3M）时就达到饱和的先前生成方法。此外，我们系统地分析了模型设计空间，强调了关键架构选择对其实现扩展性和泛化的重要贡献。在包括节点分类、图分类和迁移学习等多种任务中，G$^2$PM始终优于强基线，为可扩展图学习奠定了令人信服的基础。代码和数据集可在以下链接获取。', 'title_zh': '基于子结构序列的可扩展图生成建模'}
{'arxiv_id': 'arXiv:2505.16103', 'title': 'Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI', 'authors': 'Monirul Islam Mahmud', 'link': 'https://arxiv.org/abs/2505.16103', 'abstract': 'Keylogger detection involves monitoring for unusual system behaviors such as delays between typing and character display, analyzing network traffic patterns for data exfiltration. In this study, we provide a comprehensive analysis for keylogger detection with traditional machine learning models - SVC, Random Forest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes and advanced ensemble methods including Stacking, Blending and Voting. Moreover, feature selection approaches such as Information gain, Lasso L1 and Fisher Score are thoroughly assessed to improve predictive performance and lower computational complexity. The Keylogger Detection dataset from publicly available Kaggle website is used in this project. In addition to accuracy-based classification, this study implements the approach for model interpretation using Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to deliver finer explanations for how much each feature contributes in assisting or hindering the detection process. To evaluate the models result, we have used AUC score, sensitivity, Specificity, Accuracy and F1 score. The best performance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99, 100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is near-perfect classification with Fisher Score.', 'abstract_zh': '基于传统机器学习模型和高级集成方法的键盘记录器检测全面分析', 'title_zh': '基于可解释人工智能的集成技术与特征选择综合分析：可信赖的按键记录器检测研究'}
{'arxiv_id': 'arXiv:2505.16088', 'title': 'Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning', 'authors': 'Gagan Bhatia, Maxime Peyrard, Wei Zhao', 'link': 'https://arxiv.org/abs/2505.16088', 'abstract': 'Modern BPE tokenizers often split calendar dates into meaningless fragments, e.g., 20250312 $\\rightarrow$ 202, 503, 12, inflating token counts and obscuring the inherent structure needed for robust temporal reasoning. In this work, we (1) introduce a simple yet interpretable metric, termed date fragmentation ratio, that measures how faithfully a tokenizer preserves multi-digit date components; (2) release DateAugBench, a suite of 6500 examples spanning three temporal reasoning tasks: context-based date resolution, format-invariance puzzles, and date arithmetic across historical, contemporary, and future regimes; and (3) through layer-wise probing and causal attention-hop analyses, uncover an emergent date-abstraction mechanism whereby large language models stitch together the fragments of month, day, and year components for temporal reasoning. Our experiments show that excessive fragmentation correlates with accuracy drops of up to 10 points on uncommon dates like historical and futuristic dates. Further, we find that the larger the model, the faster the emergent date abstraction that heals date fragments is accomplished. Lastly, we observe a reasoning path that LLMs follow to assemble date fragments, typically differing from human interpretation (year $\\rightarrow$ month $\\rightarrow$ day).', 'abstract_zh': '现代BPE分词器经常将日期拆分成无意义的片段，例如20250312 → 202, 503, 12，增加分词数量并遮蔽了用于稳健时间推理所需的基本结构。本文中，我们（1）提出了一种简单且可解释的指标，称为日期碎片化比率，用于衡量分词器忠实地保留多数字日期组件的程度；（2）发布DateAugBench，包含6500个示例，涵盖三种时间推理任务：基于上下文的日期解析、格式不变性难题以及跨越历史、当代和未来的日期运算；（3）通过逐层探针和因果注意力跳转分析，揭示了一个新兴的日期抽象机制，大型语言模型通过将月份、日期和年的片段拼接起来进行时间推理。我们的实验表明，过度的碎片化与在历史和未来日期上的准确性下降多达10个百分点相关。此外，我们发现模型越大，这种新兴的日期抽象机制修复日期片段的速度越快。最后，我们观察到LLM遵循的推理路径将日期片段组装起来，通常不同于人类的解释（年份 → 月份 → 日期）。', 'title_zh': '时间碎片：时间推理中词元化的一个隐藏瓶颈'}
{'arxiv_id': 'arXiv:2505.16074', 'title': 'Bidirectional Variational Autoencoders', 'authors': 'Bart Kosko, Olaoluwa Adigun', 'link': 'https://arxiv.org/abs/2505.16074', 'abstract': 'We present the new bidirectional variational autoencoder (BVAE) network architecture. The BVAE uses a single neural network both to encode and decode instead of an encoder-decoder network pair. The network encodes in the forward direction and decodes in the backward direction through the same synaptic web. Simulations compared BVAEs and ordinary VAEs on the four image tasks of image reconstruction, classification, interpolation, and generation. The image datasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and CelebA-64 face images. The bidirectional structure of BVAEs cut the parameter count by almost 50% and still slightly outperformed the unidirectional VAEs.', 'abstract_zh': '我们提出了一种新的双向变分自编码器（BVAE）网络架构。', 'title_zh': '双向变分自编码器'}
{'arxiv_id': 'arXiv:2505.16066', 'title': 'Merge to Mix: Mixing Datasets via Model Merging', 'authors': 'Zhixu Silvia Tao, Kasper Vinken, Hao-Wei Yeh, Avi Cooper, Xavier Boix', 'link': 'https://arxiv.org/abs/2505.16066', 'abstract': 'Mixing datasets for fine-tuning large models (LMs) has become critical for maximizing performance on downstream tasks. However, composing effective dataset mixtures typically relies on heuristics and trial-and-error, often requiring multiple fine-tuning runs to achieve the desired outcome. We propose a novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset mixtures through model merging. Model merging is a recent technique that combines the abilities of multiple individually fine-tuned LMs into a single LM by using a few simple arithmetic operations. Our key insight is that merging models individually fine-tuned on each dataset in a mixture can effectively serve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix leverages this insight to accelerate selecting dataset mixtures without requiring full fine-tuning on each candidate mixture. Our experiments demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset selection for fine-tuning LMs.', 'abstract_zh': '混合数据集以加速大规模模型微调已成为最大化下游任务性能的关键。然而，有效组合数据集混合体通常依赖于启发式方法和尝试错误，常常需要多次微调才能达到预期效果。我们提出了一种新颖的方法——Merge to Mix，通过模型合并加速数据集混合体的组合。模型合并是一种近期的技术，通过少数简单的算术操作将多个独立微调的大型语言模型（LMs）的能力整合到一个模型中。我们的核心洞察是，将混合体中的每个数据集独立微调的模型合并可以有效替代在一个混合体上进行整体微调的模型。Merge to Mix 利用这一洞察加速数据集混合体的选择，而无需对每个候选混合体进行完整的微调。我们的实验表明，Merge to Mix 在大型语言模型微调的数据集选择方面超越了现有最先进方法。', 'title_zh': 'Merge to Mix: 通过模型合并进行数据集混合'}
{'arxiv_id': 'arXiv:2505.16058', 'title': 'Mesh-free sparse identification of nonlinear dynamics', 'authors': 'Mars Liyao Gao, J. Nathan Kutz, Bernat Font', 'link': 'https://arxiv.org/abs/2505.16058', 'abstract': "Identifying the governing equations of a dynamical system is one of the most important tasks for scientific modeling. However, this procedure often requires high-quality spatio-temporal data uniformly sampled on structured grids. In this paper, we propose mesh-free SINDy, a novel algorithm which leverages the power of neural network approximation as well as auto-differentiation to identify governing equations from arbitrary sensor placements and non-uniform temporal data sampling. We show that mesh-free SINDy is robust to high noise levels and limited data while remaining computationally efficient. In our implementation, the training procedure is straight-forward and nearly free of hyperparameter tuning, making mesh-free SINDy widely applicable to many scientific and engineering problems. In the experiments, we demonstrate its effectiveness on a series of PDEs including the Burgers' equation, the heat equation, the Korteweg-De Vries equation and the 2D advection-diffusion equation. We conduct detailed numerical experiments on all datasets, varying the noise levels and number of samples, and we also compare our approach to previous state-of-the-art methods. It is noteworthy that, even in high-noise and low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery, achieving successful identification with up to 75% noise for the Burgers' equation using 5,000 samples and with as few as 100 samples and 1% noise. All of this is achieved within a training time of under one minute.", 'abstract_zh': '无网格式SINDy：一种利用神经网络逼近与自动微分识别动力系统 governing 方程的新型算法', 'title_zh': '无网格稀疏识别非线性动力学'}
{'arxiv_id': 'arXiv:2505.16057', 'title': 'Signals of Provenance: Practices & Challenges of Navigating Indicators in AI-Generated Media for Sighted and Blind Individuals', 'authors': 'Ayae Ide, Tory Park, Jaron Mink, Tanusree Sharma', 'link': 'https://arxiv.org/abs/2505.16057', 'abstract': 'AI-Generated (AIG) content has become increasingly widespread by recent advances in generative models and the easy-to-use tools that have significantly lowered the technical barriers for producing highly realistic audio, images, and videos through simple natural language prompts. In response, platforms are adopting provable provenance with platforms recommending AIG to be self-disclosed and signaled to users. However, these indicators may be often missed, especially when they rely solely on visual cues and make them ineffective to users with different sensory abilities. To address the gap, we conducted semi-structured interviews (N=28) with 15 sighted and 13 BLV participants to examine their interaction with AIG content through self-disclosed AI indicators. Our findings reveal diverse mental models and practices, highlighting different strengths and weaknesses of content-based (e.g., title, description) and menu-aided (e.g., AI labels) indicators. While sighted participants leveraged visual and audio cues, BLV participants primarily relied on audio and existing assistive tools, limiting their ability to identify AIG. Across both groups, they frequently overlooked menu-aided indicators deployed by platforms and rather interacted with content-based indicators such as title and comments. We uncovered usability challenges stemming from inconsistent indicator placement, unclear metadata, and cognitive overload. These issues were especially critical for BLV individuals due to the insufficient accessibility of interface elements. We provide practical recommendations and design implications for future AIG indicators across several dimensions.', 'abstract_zh': '基于AI生成的内容逐渐普及：生成模型进步和易于使用的工具大幅降低了通过简单自然语言提示生产高度逼真音频、图像和视频的技术门槛。为应对这一变化，平台正在采用可验证的来源，并建议将AI生成内容进行自我披露并提示用户。然而，这些标识往往容易被忽视，尤其是在仅依赖视觉线索的情况下，这使得它们对具有不同感官能力的用户不够有效。为解决这一差距，我们对28名参与者进行了半结构化访谈（其中15名视力正常参与者和13名盲人参与者），研究他们如何通过自我披露的AI标识与基于内容的（如标题、描述）和菜单辅助的（如AI标签）标识互动。研究发现揭示了不同的心理模型和实践，突显了基于内容和菜单辅助标识的不同优势和劣势。视力正常参与者利用视觉和听觉线索，而盲人参与者主要依赖听觉和现有辅助工具，这限制了他们识别基于AI生成内容的能力。在两个群体中，他们经常忽视平台部署的菜单辅助标识，而是与基于内容的标识（如标题和评论）进行互动。我们发现了由不一致的标识位置、不清晰的元数据和认知过载引起的人机交互挑战。这些问题对盲人个体尤为重要，因为界面元素的不足可访问性加剧了这些问题。我们为未来基于AI生成内容标识提供了实用建议和设计启示。', 'title_zh': '来源信号：视障与非视障个体导航AI生成媒体中指标的实践与挑战'}
{'arxiv_id': 'arXiv:2505.16056', 'title': 'Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models', 'authors': 'Jingcong Liang, Siyuan Wang, Miren Tian, Yitong Li, Duyu Tang, Zhongyu Wei', 'link': 'https://arxiv.org/abs/2505.16056', 'abstract': 'Mixture-of-Experts (MoE) enables efficient scaling of large language models (LLMs) with sparsely activated experts during inference. To effectively deploy large MoE models on memory-constrained devices, many systems introduce *expert offloading* that caches a subset of experts in fast memory, leaving others on slow memory to run on CPU or load on demand. While some research has exploited the locality of expert activations, where consecutive tokens activate similar experts, the degree of this **local routing consistency** varies across models and remains understudied. In this paper, we propose two metrics to measure local routing consistency of MoE models: (1) **Segment Routing Best Performance (SRP)**, which evaluates how well a fixed group of experts can cover the needs of a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which measures the optimal segment-level cache hit rate under a given cache size limit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found that models that apply MoE on every layer and do not use shared experts exhibit the highest local routing consistency. We further showed that domain-specialized experts contribute more to routing consistency than vocabulary-specialized ones, and that most models can balance between cache effectiveness and efficiency with cache sizes approximately 2x the active experts. These findings pave the way for memory-efficient MoE design and deployment without compromising inference speed. We publish the code for replicating experiments at this https URL .', 'abstract_zh': 'Mixture-of-Experts (MoE)在推理时稀疏激活专家，使大规模语言模型（LLMs）的高效扩展成为可能。为了有效在内存受限设备上部署大规模MoE模型，许多系统引入了“专家卸载”机制，将部分专家缓存在快速内存中，其余专家置于慢速内存上运行或按需加载。虽然一些研究利用了专家激活的局部性，即连续token激活相似的专家，但这种“局部路由一致性”的程度在不同模型之间变化较大且尚未得到充分研究。在本文中，我们提出了两个度量MoE模型局部路由一致性的指标：（1）段落路由最佳性能（SRP），评估固定专家组在一个token段上的表现；（2）段落缓存最佳命中率（SCH），衡量在给定缓存大小限制下的最优段落级缓存命中率。我们分析了20个不同规模和架构的MoE LLM，并发现不使用共享专家且在每一层应用MoE的模型展现出最高的局部路由一致性。进一步研究表明，领域特化的专家对路由一致性贡献更多，而非词汇特化的专家。大多数模型可以在缓存大小约为活跃专家数量2倍的情况下，平衡缓存有效性和效率。这些发现为在不影响推理速度的情况下进行内存高效MoE设计与部署铺平了道路。我们将在该网址发布实验复现代码：this https URL。', 'title_zh': '并不是所有模型都适用于专家卸载：关于混合专家模型的局部路由一致性研究'}
{'arxiv_id': 'arXiv:2505.16035', 'title': 'Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces', 'authors': 'Alejandro García-Castellanos, David R. Wessels, Nicky J. van den Berg, Remco Duits, Daniël M. Pelt, Erik J. Bekkers', 'link': 'https://arxiv.org/abs/2505.16035', 'abstract': 'We introduce Equivariant Neural Eikonal Solvers, a novel framework that integrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our approach employs a single neural field where a unified shared backbone is conditioned on signal-specific latent variables - represented as point clouds in a Lie group - to model diverse Eikonal solutions. The ENF integration ensures equivariant mapping from these latent representations to the solution field, delivering three key benefits: enhanced representation efficiency through weight-sharing, robust geometric grounding, and solution steerability. This steerability allows transformations applied to the latent point cloud to induce predictable, geometrically meaningful modifications in the resulting Eikonal solution. By coupling these steerable representations with Physics-Informed Neural Networks (PINNs), our framework accurately models Eikonal travel-time solutions while generalizing to arbitrary Riemannian manifolds with regular group actions. This includes homogeneous spaces such as Euclidean, position-orientation, spherical, and hyperbolic manifolds. We validate our approach through applications in seismic travel-time modeling of 2D and 3D benchmark datasets. Experimental results demonstrate superior performance, scalability, adaptability, and user controllability compared to existing Neural Operator-based Eikonal solver methods.', 'abstract_zh': 'equivariant神经Eigen解算器：将equivariant神经场与神经Eigen解算器相结合的新型框架', 'title_zh': '不变电弹神经网络：均匀空间中无网格、可扩展的旅行时间预测'}
{'arxiv_id': 'arXiv:2505.16027', 'title': 'Benchmarking Chest X-ray Diagnosis Models Across Multinational Datasets', 'authors': 'Qinmei Xu, Yiheng Li, Xianghao Zhan, Ahmet Gorkem Er, Brittany Dashevsky, Chuanjun Xu, Mohammed Alawad, Mengya Yang, Liu Ya, Changsheng Zhou, Xiao Li, Haruka Itakura, Olivier Gevaert', 'link': 'https://arxiv.org/abs/2505.16027', 'abstract': 'Foundation models leveraging vision-language pretraining have shown promise in chest X-ray (CXR) interpretation, yet their real-world performance across diverse populations and diagnostic tasks remains insufficiently evaluated. This study benchmarks the diagnostic performance and generalizability of foundation models versus traditional convolutional neural networks (CNNs) on multinational CXR datasets. We evaluated eight CXR diagnostic models - five vision-language foundation models and three CNN-based architectures - across 37 standardized classification tasks using six public datasets from the USA, Spain, India, and Vietnam, and three private datasets from hospitals in China. Performance was assessed using AUROC, AUPRC, and other metrics across both shared and dataset-specific tasks. Foundation models outperformed CNNs in both accuracy and task coverage. MAVL, a model incorporating knowledge-enhanced prompts and structured supervision, achieved the highest performance on public (mean AUROC: 0.82; AUPRC: 0.32) and private (mean AUROC: 0.95; AUPRC: 0.89) datasets, ranking first in 14 of 37 public and 3 of 4 private tasks. All models showed reduced performance on pediatric cases, with average AUROC dropping from 0.88 +/- 0.18 in adults to 0.57 +/- 0.29 in children (p = 0.0202). These findings highlight the value of structured supervision and prompt design in radiologic AI and suggest future directions including geographic expansion and ensemble modeling for clinical deployment. Code for all evaluated models is available at this https URL', 'abstract_zh': '基于视觉-语言预训练的foundation模型在胸部X光片(CXR)解释中展现出了潜力，但其在多元人群和诊断任务中的实际性能仍需进一步评估。本研究对比了foundation模型与传统卷积神经网络(CNNs)在跨国CXR数据集上的诊断性能和泛化能力。我们评估了八种CXR诊断模型——五种视觉-语言foundation模型和三种CNN基线架构——在来自美国、西班牙、印度和越南的六个公开数据集以及来自中国医院的三个私有数据集上的37项标准化分类任务。性能评估使用了AUROC、AUPRC和其他指标，涵盖共用和私有数据集任务。foundation模型在准确性和任务覆盖面上均优于CNNs。MAVL模型，一种结合了知识增强提示和结构化监督的模型，在公开和私有数据集上达到了最高性能（公开数据集平均AUROC: 0.82；AUPRC: 0.32；私有数据集平均AUROC: 0.95；AUPRC: 0.89），分别在37项公开任务中的14项和4项私有任务中的3项中排名第一。所有模型在儿科病例中表现较差，成人AUROC平均值从0.88±0.18下降到儿童的0.57±0.29（p=0.0202）。这些发现突显了结构化监督和提示设计在放射学AI中的价值，并建议未来研究的方向包括地理扩展和集成建模以供临床部署。所有评估模型的代码可在以下链接获得。', 'title_zh': '多国数据集上胸片诊断模型基准测试'}
{'arxiv_id': 'arXiv:2505.16024', 'title': 'Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging', 'authors': 'Weiguo Gao, Ming Li', 'link': 'https://arxiv.org/abs/2505.16024', 'abstract': 'Diffusion trajectory distillation methods aim to accelerate sampling in diffusion models, which produce high-quality outputs but suffer from slow sampling speeds. These methods train a student model to approximate the multi-step denoising process of a pretrained teacher model in a single step, enabling one-shot generation. However, theoretical insights into the trade-off between different distillation strategies and generative quality remain limited, complicating their optimization and selection. In this work, we take a first step toward addressing this gap. Specifically, we reinterpret trajectory distillation as an operator merging problem in the linear regime, where each step of the teacher model is represented as a linear operator acting on noisy data. These operators admit a clear geometric interpretation as projections and rescalings corresponding to the noise schedule. During merging, signal shrinkage occurs as a convex combination of operators, arising from both discretization and limited optimization time of the student model. We propose a dynamic programming algorithm to compute the optimal merging strategy that maximally preserves signal fidelity. Additionally, we demonstrate the existence of a sharp phase transition in the optimal strategy, governed by data covariance structures. Our findings enhance the theoretical understanding of diffusion trajectory distillation and offer practical insights for improving distillation strategies.', 'abstract_zh': '扩散轨迹蒸馏方法旨在加速扩散模型的采样过程，尽管这些模型能够生成高质量的输出，但采样速度较慢。这些方法通过训练一个学生模型在单一步骤中近似预训练教师模型的多步去噪过程，从而实现一次性生成。然而，不同蒸馏策略与生成质量之间的权衡关系的理论见解仍然有限，这给优化和选择带来了复杂性。在本文中，我们朝着填补这一空白迈出了第一步。具体而言，我们将轨迹蒸馏重新解释为线性域中的算子合并问题，其中教师模型的每一步都被表示为作用于噪声数据的线性算子。这些算子具有明确的几何解释，对应于与噪声分配相关的投影和缩放操作。在合并过程中，信号收缩由于算子的凸组合、离散化以及学生模型有限的优化时间而发生。我们提出了一种动态规划算法来计算最大化保留信号保真度的最优合并策略。此外，我们展示了最优策略中存在的锐利相变现象，由数据协方差结构控制。我们的发现增强了对扩散轨迹蒸馏理论的理解，并为改进蒸馏策略提供了实用见解。', 'title_zh': '向通过操作合并理论洞察扩散轨迹精炼的研究迈进'}
{'arxiv_id': 'arXiv:2505.16022', 'title': 'NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning', 'authors': 'Wei Liu, Siya Qi, Xinyu Wang, Chen Qian, Yali Du, Yulan He', 'link': 'https://arxiv.org/abs/2505.16022', 'abstract': "Recent advances such as DeepSeek R1-Zero highlight the effectiveness of incentive training, a reinforcement learning paradigm that computes rewards solely based on the final answer part of a language model's output, thereby encouraging the generation of intermediate reasoning steps. However, these methods fundamentally rely on external verifiers, which limits their applicability to domains like mathematics and coding where such verifiers are readily available. Although reward models can serve as verifiers, they require high-quality annotated data and are costly to train. In this work, we propose NOVER, NO-VERifier Reinforcement Learning, a general reinforcement learning framework that requires only standard supervised fine-tuning data with no need for an external verifier. NOVER enables incentive training across a wide range of text-to-text tasks and outperforms the model of the same size distilled from large reasoning models such as DeepSeek R1 671B by 7.7 percent. Moreover, the flexibility of NOVER enables new possibilities for optimizing large language models, such as inverse incentive training.", 'abstract_zh': 'Recent Advances Such as DeepSeek R1-Zero Highlight the Effectiveness of Incentive Training in Reinforcement Learning, but External Verifiers Limit Their Applicability to Specific Domains: NOVER, NO-VERifier Reinforcement Learning, Enables Incentive Training Across Text-to-Text Tasks Without External Verifiers', 'title_zh': 'NOVER：基于验证者无 involving 验证者的强化学习促使语言模型激励训练'}
{'arxiv_id': 'arXiv:2505.16008', 'title': 'LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization', 'authors': 'Wenrui Yu, Yiyi Chen, Johannes Bjerva, Sokol Kosta, Qiongxiu Li', 'link': 'https://arxiv.org/abs/2505.16008', 'abstract': 'We propose LAGO - Language Similarity-Aware Graph Optimization - a novel approach for few-shot cross-lingual embedding inversion attacks, addressing critical privacy vulnerabilities in multilingual NLP systems. Unlike prior work in embedding inversion attacks that treat languages independently, LAGO explicitly models linguistic relationships through a graph-based constrained distributed optimization framework. By integrating syntactic and lexical similarity as edge constraints, our method enables collaborative parameter learning across related languages. Theoretically, we show this formulation generalizes prior approaches, such as ALGEN, which emerges as a special case when similarity constraints are relaxed. Our framework uniquely combines Frobenius-norm regularization with linear inequality or total variation constraints, ensuring robust alignment of cross-lingual embedding spaces even with extremely limited data (as few as 10 samples per language). Extensive experiments across multiple languages and embedding models demonstrate that LAGO substantially improves the transferability of attacks with 10-20% increase in Rouge-L score over baselines. This work establishes language similarity as a critical factor in inversion attack transferability, urging renewed focus on language-aware privacy-preserving multilingual embeddings.', 'abstract_zh': '语言相似性感知图优化：一种新的 few-shot 跨语言嵌入反转攻击方法', 'title_zh': 'LAGO: 语言相似性 Awareness 图优化下的少样本跨语言嵌入反向攻击'}
{'arxiv_id': 'arXiv:2505.16004', 'title': 'Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations', 'authors': 'Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju', 'link': 'https://arxiv.org/abs/2505.16004', 'abstract': 'Sparse autoencoders (SAEs) are commonly used to interpret the internal activations of large language models (LLMs) by mapping them to human-interpretable concept representations. While existing evaluations of SAEs focus on metrics such as the reconstruction-sparsity tradeoff, human (auto-)interpretability, and feature disentanglement, they overlook a critical aspect: the robustness of concept representations to input perturbations. We argue that robustness must be a fundamental consideration for concept representations, reflecting the fidelity of concept labeling. To this end, we formulate robustness quantification as input-space optimization problems and develop a comprehensive evaluation framework featuring realistic scenarios in which adversarial perturbations are crafted to manipulate SAE representations. Empirically, we find that tiny adversarial input perturbations can effectively manipulate concept-based interpretations in most scenarios without notably affecting the outputs of the base LLMs themselves. Overall, our results suggest that SAE concept representations are fragile and may be ill-suited for applications in model monitoring and oversight.', 'abstract_zh': '稀疏自编码器（SAEs）常用于通过将其映射到可人力解释的概念表示，来解析大型语言模型（LLMs）的内部激活。虽然现有SAE评估主要集中在重构稀疏性权衡、人类（自助）解释性和特征解耦等指标上，但忽略了概念表示对输入扰动具有鲁棒性这一关键方面。我们主张鲁棒性应是概念表示的基本考量因素，反映概念标注的准确性。为此，我们将鲁棒性量化形式化为输入空间优化问题，并开发了一个包含现实场景的综合评估框架，在这些场景中，恶意扰动被精心设计以操控SAE表示。实验结果表明，在大多数情况下，细微的恶意输入扰动可以有效操控基于概念的解释，而对基础LLM本身输出的影响并不明显。总体而言，我们的结果表明SAE概念表示是脆弱的，可能不适合用于模型监控和监督的应用中。', 'title_zh': '稀疏自编码器中的可解释性幻觉：概念表示的稳健性评估'}
{'arxiv_id': 'arXiv:2505.16003', 'title': 'SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models', 'authors': 'Roland Daynauth, Christopher Clarke, Krisztian Flautner, Lingjia Tang, Jason Mars', 'link': 'https://arxiv.org/abs/2505.16003', 'abstract': 'The LLM-as-a-Judge paradigm offers a scalable, reference-free approach for evaluating language models. Although several calibration techniques have been proposed to better align these evaluators with human judgment, prior studies focus primarily on narrow, well-structured benchmarks. As a result, it remains unclear whether such calibrations generalize to real-world, open-ended tasks.\nIn this work, we show that SOTA calibrated evaluators often fail in these settings, exhibiting weak or even negative correlation with human judgments. To address this, we propose SLMEval, a novel and efficient calibration method based on entropy maximization over a small amount of human preference data. By estimating a latent distribution over model quality and reweighting evaluator scores accordingly, SLMEval achieves strong correlation with human evaluations across two real-world production use cases and the public benchmark. For example, on one such task, SLMEval achieves a Spearman correlation of 0.57 with human judgments, while G-Eval yields a negative correlation. In addition, SLMEval reduces evaluation costs by 5-30x compared to GPT-4-based calibrated evaluators such as G-eval.', 'abstract_zh': 'LLM-as-a-Judge范式提供了无参考的大规模语言模型评估方法。尽管提出了一些校准技术以更准确地对齐这些评估者与人类判断，但之前的研究所关注的主要是一些狭窄且结构良好的基准。因此，尚不清楚这样的校准是否能够泛化到实际世界中的开放任务。\n\n在本研究中，我们展示了最先进的校准评估者在这些场景中往往表现不佳，与人类判断表现出弱或甚至是负相关。为了解决这一问题，我们提出了一种基于少量人类偏好数据的熵最大化的新颖且高效的校准方法SLMEval。通过估计模型质量的潜在分布并相应地重新加权评价分数，SLMEval在两个实际世界生产应用场景和公共基准测试中实现了与人类评估的强相关性。例如，在其中一个任务中，SLMEval与人类判断之间的斯皮尔曼相关系数为0.57，而G-Eval则表现出负相关。此外，与基于GPT-4的校准评估者（如G-Eval）相比，SLMEval将评估成本降低了5到30倍。', 'title_zh': 'SLMEval: 基于熵的校准以实现人工对齐评价的大语言模型'}
{'arxiv_id': 'arXiv:2505.16002', 'title': 'Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions', 'authors': 'Sasha Boguraev, Christopher Potts, Kyle Mahowald', 'link': 'https://arxiv.org/abs/2505.16002', 'abstract': 'Large Language Models (LLMs) have emerged as powerful sources of evidence for linguists seeking to develop theories of syntax. In this paper, we argue that causal interpretability methods, applied to LLMs, can greatly enhance the value of such evidence by helping us characterize the abstract mechanisms that LLMs learn to use. Our empirical focus is a set of English filler-gap dependency constructions (e.g., questions, relative clauses). Linguistic theories largely agree that these constructions share many properties. Using experiments based in Distributed Interchange Interventions, we show that LLMs converge on similar abstract analyses of these constructions. These analyses also reveal previously overlooked factors -- relating to frequency, filler type, and surrounding context -- that could motivate changes to standard linguistic theory. Overall, these results suggest that mechanistic, internal analyses of LLMs can push linguistic theory forward.', 'abstract_zh': '大规模语言模型（LLMs）已成为语言学家开发句法理论的重要证据来源。本文我们argue，将因果可解释性方法应用于LLMs，可以极大地增强这类证据的价值，帮助我们characterize LLMs学习使用的抽象机制。我们的实证重点是一组英语填充-空白依赖构造（例如，疑问句、从句）。语言学理论很大程度上认为这些构造共享许多属性。我们基于分布式互换干预的实验表明，LLMs对这些构造给出了类似的抽象分析。这些分析还揭示了以前未被注意到的因素——涉及频率、填充词类型以及周围语境——这些因素可能促使对标准语言理论进行修改。总体而言，这些结果表明，对LLMs的机械内部分析可以推动语言学理论的发展。', 'title_zh': '因果干预揭示英语填充-空位构 constructions 中的共享结构'}
{'arxiv_id': 'arXiv:2505.16000', 'title': 'Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model', 'authors': 'Mehrdad ghassabi, Pedram Rostami, Hamidreza Baradaran Kashani, Amirhossein Poursina, Zahra Kazemi, Milad Tavakoli', 'link': 'https://arxiv.org/abs/2505.16000', 'abstract': 'The rapid advancement of language models has demonstrated the potential of artificial intelligence in the healthcare industry. However, small language models struggle with specialized domains in low-resource languages like Persian. While numerous medical-domain websites exist in Persian, no curated dataset or corpus has been available making ours the first of its kind. This study explores the enhancement of medical knowledge in a small language model by leveraging accessible online data, including a crawled corpus from medical magazines and a dataset of real doctor-patient QA pairs. We fine-tuned a baseline model using our curated data to improve its medical knowledge. Benchmark evaluations demonstrate that the fine-tuned model achieves improved accuracy in medical question answering and provides better responses compared to its baseline. This work highlights the potential of leveraging open-access online data to enrich small language models in medical fields, providing a novel solution for Persian medical AI applications suitable for resource-constrained environments.', 'abstract_zh': '语言模型的 rapid advancement 在医疗健康行业的应用潜力已得到证实，但小型语言模型在低资源语言如波斯语的专业领域中存在挑战。尽管存在许多波斯语医疗领域网站，但缺乏经过整理的数据集或语料库，使得我们的工作成为该领域的首创。本研究通过利用可获得的在线数据，包括从医学杂志抓取的语料库和真实的医生-患者问答数据集，探索了增强小型语言模型医学知识的方法。我们使用精选数据对基准模型进行了微调，以提高其医学知识水平。基准评估表明，微调后的模型在医学问答中的准确性和响应质量均优于基准模型。本研究强调了利用开放访问的在线数据来丰富小型语言模型在医学领域的可能性，提出了适合资源受限环境的波斯语医疗AI应用的新解决方案。', 'title_zh': '利用在线数据提升小规模波斯语医疗知识模型'}
{'arxiv_id': 'arXiv:2505.15997', 'title': 'Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers', 'authors': 'Mehran Zoravar, Shadi Alijani, Homayoun Najjaran', 'link': 'https://arxiv.org/abs/2505.15997', 'abstract': "Exploring the trustworthiness of deep learning models is crucial, especially in critical domains such as medical imaging decision support systems. Conformal prediction has emerged as a rigorous means of providing deep learning models with reliable uncertainty estimates and safety guarantees. However, conformal prediction results face challenges due to the backbone model's struggles in domain-shifted scenarios, such as variations in different sources. To aim this challenge, this paper proposes a novel framework termed Conformal Ensemble of Vision Transformers (CE-ViTs) designed to enhance image classification performance by prioritizing domain adaptation and model robustness, while accounting for uncertainty. The proposed method leverages an ensemble of vision transformer models in the backbone, trained on diverse datasets including HAM10000, Dermofit, and Skin Cancer ISIC datasets. This ensemble learning approach, calibrated through the combined mentioned datasets, aims to enhance domain adaptation through conformal learning. Experimental results underscore that the framework achieves a high coverage rate of 90.38\\%, representing an improvement of 9.95\\% compared to the HAM10000 model. This indicates a strong likelihood that the prediction set includes the true label compared to singular models. Ensemble learning in CE-ViTs significantly improves conformal prediction performance, increasing the average prediction set size for challenging misclassified samples from 1.86 to 3.075.", 'abstract_zh': '探索深度学习模型的可信度至关重要，尤其是在医疗影像决策支持系统等关键领域。基于变换器的 conformal 集成框架 (CE-ViTs) 旨在通过优先考虑领域适应和模型鲁棒性来提升图像分类性能，同时考虑不确定性。', 'title_zh': '基于视觉变换器同化ensemble的皮肤病变分类域适应方法'}
{'arxiv_id': 'arXiv:2505.15966', 'title': 'Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning', 'authors': 'Alex Su, Haozhe Wang, Weimin Ren, Fangzhen Lin, Wenhu Chen', 'link': 'https://arxiv.org/abs/2505.15966', 'abstract': "Chain-of-thought reasoning has significantly improved the performance of Large Language Models (LLMs) across various domains. However, this reasoning process has been confined exclusively to textual space, limiting its effectiveness in visually intensive tasks. To address this limitation, we introduce the concept of reasoning in the pixel-space. Within this novel framework, Vision-Language Models (VLMs) are equipped with a suite of visual reasoning operations, such as zoom-in and select-frame. These operations enable VLMs to directly inspect, interrogate, and infer from visual evidences, thereby enhancing reasoning fidelity for visual tasks. Cultivating such pixel-space reasoning capabilities in VLMs presents notable challenges, including the model's initially imbalanced competence and its reluctance to adopt the newly introduced pixel-space operations. We address these challenges through a two-phase training approach. The first phase employs instruction tuning on synthesized reasoning traces to familiarize the model with the novel visual operations. Following this, a reinforcement learning (RL) phase leverages a curiosity-driven reward scheme to balance exploration between pixel-space reasoning and textual reasoning. With these visual operations, VLMs can interact with complex visual inputs, such as information-rich images or videos to proactively gather necessary information. We demonstrate that this approach significantly improves VLM performance across diverse visual reasoning benchmarks. Our 7B model, \\model, achieves 84\\% on V* bench, 74\\% on TallyQA-Complex, and 84\\% on InfographicsVQA, marking the highest accuracy achieved by any open-source model to date. These results highlight the importance of pixel-space reasoning and the effectiveness of our framework.", 'abstract_zh': '链路思考推理显著提升了大型语言模型在各个领域的性能。然而，这一推理过程仅局限于文本空间，限制了其在视觉密集任务中的有效性。为解决这一局限性，我们介绍了像素空间推理的概念。在此新颖框架下，视觉-语言模型（VLMs）配备了缩放和选择帧等多种视觉推理操作，使VLMs能够直接检查、询问和从视觉证据中推理，从而提高视觉任务的推理准确性。培养这些像素空间推理能力面临显著挑战，包括模型初始不平衡的能力和其对新引入的像素空间操作的抗拒性。我们通过两阶段训练方法解决这些挑战。第一阶段使用合成的推理轨迹进行指令调优，使模型熟悉新的视觉操作。随后，使用好奇心驱动的奖励方案的强化学习阶段平衡像素空间推理和文本推理之间的探索。通过这些视觉操作，VLMs能够与复杂的视觉输入，如信息丰富图像或视频进行交互，主动收集必要信息。研究表明，这种方法显著提高了VLM在各种视觉推理基准测试中的性能。我们的7B模型\\textbf{model}在V* bench上取得84%，在TallyQA-Complex上取得74%，在InfographicsVQA上取得84%，标志着迄今为止开源模型达到的最高准确率。这些结果突显了像素空间推理的重要性以及我们框架的有效性。', 'title_zh': '像素推理器：基于好奇心驱动的强化学习在像素空间中的推理激励'}
{'arxiv_id': 'arXiv:2505.15962', 'title': 'Pre-training Large Memory Language Models with Internal and External Knowledge', 'authors': 'Linxi Zhao, Sofian Zalouk, Christian K. Belardi, Justin Lovelace, Jin Peng Zhou, Kilian Q. Weinberger, Yoav Artzi, Jennifer J. Sun', 'link': 'https://arxiv.org/abs/2505.15962', 'abstract': 'Neural language models are black-boxes -- both linguistic patterns and factual knowledge are distributed across billions of opaque parameters. This entangled encoding makes it difficult to reliably inspect, verify, or update specific facts. We propose a new class of language models, Large Memory Language Models (LMLM) with a pre-training recipe that stores factual knowledge in both internal weights and an external database. Our approach strategically masks externally retrieved factual values from the training loss, thereby teaching the model to perform targeted lookups rather than relying on memorization in model weights. Our experiments demonstrate that LMLMs achieve competitive performance compared to significantly larger, knowledge-dense LLMs on standard benchmarks, while offering the advantages of explicit, editable, and verifiable knowledge bases. This work represents a fundamental shift in how language models interact with and manage factual knowledge.', 'abstract_zh': '大型记忆语言模型：通过内部权重和外部数据库存储事实知识的新类语言模型', 'title_zh': '使用内部和外部知识预训练大规模语言模型'}
{'arxiv_id': 'arXiv:2505.15957', 'title': 'Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey', 'authors': 'Chih-Kai Yang, Neo S. Ho, Hung-yi Lee', 'link': 'https://arxiv.org/abs/2505.15957', 'abstract': "With advancements in large audio-language models (LALMs), which enhance large language models (LLMs) with auditory capabilities, these models are expected to demonstrate universal proficiency across various auditory tasks. While numerous benchmarks have emerged to assess LALMs' performance, they remain fragmented and lack a structured taxonomy. To bridge this gap, we conduct a comprehensive survey and propose a systematic taxonomy for LALM evaluations, categorizing them into four dimensions based on their objectives: (1) General Auditory Awareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented Ability, and (4) Fairness, Safety, and Trustworthiness. We provide detailed overviews within each category and highlight challenges in this field, offering insights into promising future directions. To the best of our knowledge, this is the first survey specifically focused on the evaluations of LALMs, providing clear guidelines for the community. We will release the collection of the surveyed papers and actively maintain it to support ongoing advancements in the field.", 'abstract_zh': '随着大型音频语言模型（LALMs）的发展，这些模型通过增强大型语言模型（LLMs）的听觉能力，预期将在各种听觉任务中展现出普遍的专业能力。尽管已经出现了众多评价LALMs性能的基准，但它们仍较为零散且缺乏结构化的分类体系。为填补这一空白，我们进行了一项全面的综述，并提出了一套系统性的评价分类体系，根据其目标将LALM分为四个维度：（1）一般听觉意识和处理能力，（2）知识与推理，（3）对话导向能力，以及（4）公平性、安全性和可靠性。我们在每个分类中提供了详细概述，并突出了该领域的挑战，提供了未来研究方向的见解。据我们所知，这是首个专门针对LALM评价的综述，为该领域提供了明确的指南。我们将发布所调研论文的集合，并积极维护，以支持该领域的持续发展。', 'title_zh': '面向大规模音语言模型综合评估的研究综述'}
{'arxiv_id': 'arXiv:2505.15952', 'title': 'VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance', 'authors': 'Mohammad Reza Taesiri, Abhijay Ghildyal, Saman Zadtootaghaj, Nabajeet Barman, Cor-Paul Bezemer', 'link': 'https://arxiv.org/abs/2505.15952', 'abstract': "With video games now generating the highest revenues in the entertainment industry, optimizing game development workflows has become essential for the sector's sustained growth. Recent advancements in Vision-Language Models (VLMs) offer considerable potential to automate and enhance various aspects of game development, particularly Quality Assurance (QA), which remains one of the industry's most labor-intensive processes with limited automation options. To accurately evaluate the performance of VLMs in video game QA tasks and determine their effectiveness in handling real-world scenarios, there is a clear need for standardized benchmarks, as existing benchmarks are insufficient to address the specific requirements of this domain. To bridge this gap, we introduce VideoGameQA-Bench, a comprehensive benchmark that covers a wide array of game QA activities, including visual unit testing, visual regression testing, needle-in-a-haystack tasks, glitch detection, and bug report generation for both images and videos of various games. Code and data are available at: this https URL", 'abstract_zh': '随着电子游戏现已成为娱乐行业的最高收入来源，优化游戏开发工作流程对于该领域持续增长变得至关重要。近期视觉-语言模型（VLMs）的进步为自动化和提升游戏开发的各个方面提供了巨大潜力，尤其是质量保证（QA），这是行业中最具劳动密集型且自动化选择有限的过程之一。为了准确评估VLMs在视频游戏QA任务中的性能并确定其在处理现实场景中的有效性，建立标准化基准显得尤为必要，现有基准不足以满足该领域的特定需求。为了填补这一空白，我们提出了VideoGameQA-Bench，这是一个全面的基准，涵盖了广泛的game QA活动，包括视觉单元测试、视觉回归测试、针锋相对的任务、故障检测以及针对不同游戏的图像和视频的bug报告生成。代码和数据可通过以下链接获得：this https URL。', 'title_zh': 'VideoGameQA-Bench: 评估视觉语言模型在视频游戏质量保证中的表现'}
{'arxiv_id': 'arXiv:2505.15946', 'title': 'MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding', 'authors': 'Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun', 'link': 'https://arxiv.org/abs/2505.15946', 'abstract': "Decoding visual experiences from fMRI offers a powerful avenue to understand human perception and develop advanced brain-computer interfaces. However, current progress often prioritizes maximizing reconstruction fidelity while overlooking interpretability, an essential aspect for deriving neuroscientific insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework designed for high-fidelity, adaptable, and interpretable visual reconstruction. MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture where distinct experts process fMRI signals from functionally related voxel groups, mimicking specialized brain networks. The experts are first trained to encode fMRI into the frozen CLIP space. A finetuned diffusion model then synthesizes images, guided by expert outputs through a novel dual-stage routing mechanism that dynamically weighs expert contributions across the diffusion process. MoRE-Brain offers three main advancements: First, it introduces a novel Mixture-of-Experts architecture grounded in brain network principles for neuro-decoding. Second, it achieves efficient cross-subject generalization by sharing core expert networks while adapting only subject-specific routers. Third, it provides enhanced mechanistic insight, as the explicit routing reveals precisely how different modeled brain regions shape the semantic and spatial attributes of the reconstructed image. Extensive experiments validate MoRE-Brain's high reconstruction fidelity, with bottleneck analyses further demonstrating its effective utilization of fMRI signals, distinguishing genuine neural decoding from over-reliance on generative priors. Consequently, MoRE-Brain marks a substantial advance towards more generalizable and interpretable fMRI-based visual decoding. Code will be publicly available soon: this https URL.", 'abstract_zh': '从fMRI解码视觉体验为理解人类感知和开发先进的脑机接口提供了强有力的途径。然而，当前进展往往侧重于最大限度地提高重建保真度，而忽略了可解释性，这是获取神经科学洞察所必需的一个方面。为了解决这一差距，我们提出了MoRE-Brain，一个受神经启发的框架，旨在实现高保真、灵活且可解释的视觉重建。MoRE-Brain独树一帜地采用了一种分层Mixture-of-Experts架构，其中不同的专家处理功能相关体素组的fMRI信号，模拟专门化的脑网络。首先，专家被训练将fMRI编码到冻结的CLIP空间中。然后，微调的扩散模型通过一种新颖的两阶段路由机制合成图像，该机制动态评估扩散过程中专家贡献的权重，该机制由专家输出指导。MoRE-Brain提供了三项主要进展：首先，它引入了一种基于脑网络原则的新颖Mixture-of-Experts架构，用于神经解码。其次，它通过共享核心专家网络并仅适应个体特异性路由器实现高效的跨被试泛化。第三，它提供了增强的机械性洞见，因为明确的路由揭示了哪些建模的大脑区域如何精确地塑造重建图像的语义和空间属性。大量实验验证了MoRE-Brain的高重建保真度，瓶颈分析进一步证明了其有效利用fMRI信号，区分真实的神经解码和过度依赖生成先验。因此，MoRE-Brain标志着更可泛化和可解释的基于fMRI的视觉解码的重要进步。代码即将公开：this https URL。', 'title_zh': 'MoRE-Brain: 路由混合专家模型解释性跨被试fMRI视觉解码'}
{'arxiv_id': 'arXiv:2505.15925', 'title': 'VERDI: VLM-Embedded Reasoning for Autonomous Driving', 'authors': 'Bowen Feng, Zhiting Mei, Baiang Li, Julian Ost, Roger Girgis, Anirudha Majumdar, Felix Heide', 'link': 'https://arxiv.org/abs/2505.15925', 'abstract': 'While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information. Recent work has attempted to leverage finetuned Vision-Language Models (VLMs) for trajectory planning at inference time to emulate human behavior. Despite their success in benchmark evaluations, these methods are often impractical to deploy (a 70B parameter VLM inference at merely 8 tokens per second requires more than 160G of memory), and their monolithic network structure prohibits safety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for autonomous Driving (VERDI), a training-time framework that distills the reasoning process and commonsense knowledge of VLMs into the AD stack. VERDI augments modular differentiable end-to-end (e2e) AD models by aligning intermediate module outputs at the perception, prediction, and planning stages with text features explaining the driving reasoning process produced by VLMs. By encouraging alignment in latent space, \\textsc{VERDI} enables the modular AD stack to internalize structured reasoning, without incurring the inference-time costs of large VLMs. We demonstrate the effectiveness of our method on the NuScenes dataset and find that VERDI outperforms existing e2e methods that do not embed reasoning by 10% in $\\ell_{2}$ distance, while maintaining high inference speed.', 'abstract_zh': 'VLM嵌入推理在自主驾驶中的应用：VERDI方法', 'title_zh': 'VERDI: VLM嵌入式推理在自动驾驶中的应用'}
{'arxiv_id': 'arXiv:2505.15918', 'title': 'Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization', 'authors': 'Aliakbar Nafar, Kristen Brent Venable, Zijun Cui, Parisa Kordjamshidi', 'link': 'https://arxiv.org/abs/2505.15918', 'abstract': 'Large Language Models (LLMs) have demonstrated potential as factual knowledge bases; however, their capability to generate probabilistic knowledge about real-world events remains understudied. This paper investigates using probabilistic knowledge inherent in LLMs to derive probability estimates for statements concerning events and their interrelationships captured via a Bayesian Network (BN). Using LLMs in this context allows for the parameterization of BNs, enabling probabilistic modeling within specific domains. Experiments on eighty publicly available Bayesian Networks, from healthcare to finance, demonstrate that querying LLMs about the conditional probabilities of events provides meaningful results when compared to baselines, including random and uniform distributions, as well as approaches based on next-token generation probabilities. We explore how these LLM-derived distributions can serve as expert priors to refine distributions extracted from minimal data, significantly reducing systematic biases. Overall, this work introduces a promising strategy for automatically constructing Bayesian Networks by combining probabilistic knowledge extracted from LLMs with small amounts of real-world data. Additionally, we evaluate several prompting strategies for eliciting probabilistic knowledge from LLMs and establish the first comprehensive baseline for assessing LLM performance in extracting probabilistic knowledge.', 'abstract_zh': '大型语言模型（LLMs）在事实知识库方面展现了潜力，但其生成关于现实世界事件的概率性知识的能力仍需进一步研究。本文探讨了利用LLMs内在的概率性知识来通过贝叶斯网络（BN）推导出关于事件及其相互关系的概率估计。在这种背景下使用LLMs允许对BN进行参数化，从而在特定领域内实现概率建模。实验表明，查询LLMs关于事件条件概率的结果相较于随机分布、均匀分布以及基于下一个词生成概率的方法，具有重要意义。我们研究了这些LLM衍生的分布如何作为专家先验知识，以 refinement 的方式改进从少量数据中提取的分布，从而显著减少系统性偏差。总体而言，本文提出了一种通过结合从LLMs中提取的概率性知识和少量现实世界数据自动构建贝叶斯网络的有前景策略。此外，我们评估了几种提示策略以从LLMs中引出概率性知识，并建立了第一个全面的基线来评估LLMs在提取概率性知识方面的表现。', 'title_zh': '从大型语言模型中提取概率性知识进行贝叶斯网络参数化'}
{'arxiv_id': 'arXiv:2505.15916', 'title': 'BR-TaxQA-R: A Dataset for Question Answering with References for Brazilian Personal Income Tax Law, including case law', 'authors': 'Juvenal Domingos Júnior, Augusto Faria, E. Seiti de Oliveira, Erick de Brito, Matheus Teotonio, Andre Assumpção, Diedre Carmo, Roberto Lotufo, Jayr Pereira', 'link': 'https://arxiv.org/abs/2505.15916', 'abstract': "This paper presents BR-TaxQA-R, a novel dataset designed to support question answering with references in the context of Brazilian personal income tax law. The dataset contains 715 questions from the 2024 official Q\\&A document published by Brazil's Internal Revenue Service, enriched with statutory norms and administrative rulings from the Conselho Administrativo de Recursos Fiscais (CARF). We implement a Retrieval-Augmented Generation (RAG) pipeline using OpenAI embeddings for searching and GPT-4o-mini for answer generation. We compare different text segmentation strategies and benchmark our system against commercial tools such as ChatGPT and this http URL using RAGAS-based metrics. Results show that our custom RAG pipeline outperforms commercial systems in Response Relevancy, indicating stronger alignment with user queries, while commercial models achieve higher scores in Factual Correctness and fluency. These findings highlight a trade-off between legally grounded generation and linguistic fluency. Crucially, we argue that human expert evaluation remains essential to ensure the legal validity of AI-generated answers in high-stakes domains such as taxation. BR-TaxQA-R is publicly available at this https URL.", 'abstract_zh': 'BR-TaxQA-R：一种支持巴西个人所得税法参考上下文中文本问答的新数据集', 'title_zh': '巴西个人所得税法及案例法参考问答数据集：BR-TaxQA-R'}
{'arxiv_id': 'arXiv:2505.15888', 'title': 'Last Layer Empirical Bayes', 'authors': 'Valentin Villecroze, Yixin Wang, Gabriel Loaiza-Ganem', 'link': 'https://arxiv.org/abs/2505.15888', 'abstract': 'The task of quantifying the inherent uncertainty associated with neural network predictions is a key challenge in artificial intelligence. Bayesian neural networks (BNNs) and deep ensembles are among the most prominent approaches to tackle this task. Both approaches produce predictions by computing an expectation of neural network outputs over some distribution on the corresponding weights; this distribution is given by the posterior in the case of BNNs, and by a mixture of point masses for ensembles. Inspired by recent work showing that the distribution used by ensembles can be understood as a posterior corresponding to a learned data-dependent prior, we propose last layer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a normalizing flow, which is then trained to maximize the evidence lower bound; to retain tractability we use the flow only on the last layer. We show why LLEB is well motivated, and how it interpolates between standard BNNs and ensembles in terms of the strength of the prior that they use. LLEB performs on par with existing approaches, highlighting that empirical Bayes is a promising direction for future research in uncertainty quantification.', 'abstract_zh': '量化与神经网络预测相关的固有不确定性是人工智能中的一个关键挑战。贝叶斯神经网络（BNN）和深度集成是解决这一问题的最突出方法之一。受近期研究表明集成中使用的分布可以视为与数据相关的先验对应的后验的启发，我们提出了最后一层经验贝叶斯（LLEB）。LLEB将可学习的先验实例化为归一化流，并通过最大化证据下界来训练该流；为保持可计算性，仅在最后一层使用流。我们展示了LLEB为什么合理，并且如何在使用先验强度方面介于标准BNN和集成之间。LLEB的表现与现有方法相当，突显了经验贝叶斯在未来不确定性量化研究中的前景。', 'title_zh': '最后一层经验贝叶斯'}
{'arxiv_id': 'arXiv:2505.15879', 'title': 'GRIT: Teaching MLLMs to Think with Images', 'authors': 'Yue Fan, Xuehai He, Diji Yang, Kaizhi Zheng, Ching-Chen Kuo, Yuting Zheng, Sravana Jyothi Narayanaraju, Xinze Guan, Xin Eric Wang', 'link': 'https://arxiv.org/abs/2505.15879', 'abstract': 'Recent studies have demonstrated the efficacy of using Reinforcement Learning (RL) in building reasoning models that articulate chains of thoughts prior to producing final answers. However, despite ongoing advances that aim at enabling reasoning for vision-language tasks, existing open-source visual reasoning models typically generate reasoning content with pure natural language, lacking explicit integration of visual information. This limits their ability to produce clearly articulated and visually grounded reasoning chains. To this end, we propose Grounded Reasoning with Images and Texts (GRIT), a novel method for training MLLMs to think with images. GRIT introduces a grounded reasoning paradigm, in which models generate reasoning chains that interleave natural language and explicit bounding box coordinates. These coordinates point to regions of the input image that the model consults during its reasoning process. Additionally, GRIT is equipped with a reinforcement learning approach, GRPO-GR, built upon the GRPO algorithm. GRPO-GR employs robust rewards focused on the final answer accuracy and format of the grounded reasoning output, which eliminates the need for data with reasoning chain annotations or explicit bounding box labels. As a result, GRIT achieves exceptional data efficiency, requiring as few as 20 image-question-answer triplets from existing datasets. Comprehensive evaluations demonstrate that GRIT effectively trains MLLMs to produce coherent and visually grounded reasoning chains, showing a successful unification of reasoning and grounding abilities.', 'abstract_zh': '基于图像和文本的 grounded 理论推理（GRIT）', 'title_zh': 'GRIT: 教学MLLMs通过图像思考'}
{'arxiv_id': 'arXiv:2505.15868', 'title': 'An Inclusive Foundation Model for Generalizable Cytogenetics in Precision Oncology', 'authors': 'Changchun Yang, Weiqian Dai, Yilan Zhang, Siyuan Chen, Jingdong Hu, Junkai Su, Yuxuan Chen, Ao Xu, Na Li, Xin Gao, Yongguo Yu', 'link': 'https://arxiv.org/abs/2505.15868', 'abstract': 'Chromosome analysis is vital for diagnosing genetic disorders and guiding cancer therapy decisions through the identification of somatic clonal aberrations. However, developing an AI model are hindered by the overwhelming complexity and diversity of chromosomal abnormalities, requiring extensive annotation efforts, while automated methods remain task-specific and lack generalizability due to the scarcity of comprehensive datasets spanning diverse resource conditions. Here, we introduce CHROMA, a foundation model for cytogenomics, designed to overcome these challenges by learning generalizable representations of chromosomal abnormalities. Pre-trained on over 84,000 specimens (~4 million chromosomal images) via self-supervised learning, CHROMA outperforms other methods across all types of abnormalities, even when trained on fewer labelled data and more imbalanced datasets. By facilitating comprehensive mapping of instability and clonal leisons across various aberration types, CHROMA offers a scalable and generalizable solution for reliable and automated clinical analysis, reducing the annotation workload for experts and advancing precision oncology through the early detection of rare genomic abnormalities, enabling broad clinical AI applications and making advanced genomic analysis more accessible.', 'abstract_zh': '染色体分析对于诊断遗传疾病和通过识别体细胞克隆异常来指导癌症治疗决策至关重要。然而，由于染色体异常的复杂性和多样性，开发AI模型受到限制，需要大量的标注工作，而现有的自动化方法由于缺乏涵盖多样资源条件的全面数据集，仍然任务特定且缺乏泛化能力。在这里，我们介绍了CHROMA，一种用于细胞遗传学的基础模型，旨在通过学习染色体异常的一般表示来克服这些挑战。CHROMA通过自我监督学习在超过84,000个样本（约400万张染色体图像）上进行预训练，即使在训练数据较少和数据集更不平衡时，CHROMA也能够在各种类型的异常中取得最佳表现。通过促进各种异常类型不稳定性及克隆病灶的全面映射，CHROMA提供了一种可扩展且可泛化的临床分析解决方案，减轻了专家的标注工作量，并通过早期检测罕见的基因组异常推动精准 oncology，实现了广泛的临床AI应用，使高级基因组分析更具可及性。', 'title_zh': '包容性基础模型在精准 Oncology 中的可泛化细胞遗传学'}
{'arxiv_id': 'arXiv:2505.15859', 'title': 'AutoData: A Multi-Agent System for Open Web Data Collection', 'authors': 'Tianyi Ma, Yiyue Qian, Zheyuan Zhang, Zehong Wang, Xiaoye Qian, Feifan Bai, Yifan Ding, Xuwei Luo, Shinan Zhang, Keerthiram Murugesan, Chuxu Zhang, Yanfang Ye', 'link': 'https://arxiv.org/abs/2505.15859', 'abstract': "The exponential growth of data-driven systems and AI technologies has intensified the demand for high-quality web-sourced datasets. While existing datasets have proven valuable, conventional web data collection approaches face significant limitations in terms of human effort and scalability. Current data-collecting solutions fall into two categories: wrapper-based methods that struggle with adaptability and reproducibility, and large language model (LLM)-based approaches that incur substantial computational and financial costs. To address these challenges, we propose AutoData, a novel multi-agent system for Automated web Data collection, that requires minimal human intervention, i.e., only necessitating a natural language instruction specifying the desired dataset. In addition, AutoData is designed with a robust multi-agent architecture, featuring a novel oriented message hypergraph coordinated by a central task manager, to efficiently organize agents across research and development squads. Besides, we introduce a novel hypergraph cache system to advance the multi-agent collaboration process that enables efficient automated data collection and mitigates the token cost issues prevalent in existing LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark dataset supporting live data collection from web sources across three domains: academic, finance, and sports. Comprehensive evaluations over Instruct2DS and three existing benchmark datasets demonstrate AutoData's superior performance compared to baseline methods. Case studies on challenging tasks such as picture book collection and paper extraction from surveys further validate its applicability. Our source code and dataset are available at this https URL.", 'abstract_zh': '数据驱动系统和AI技术的指数增长加剧了对高质量网页数据集的需求。尽管现有数据集证明了其价值，但传统的网页数据收集方法在人力投入和可扩展性方面面临重大限制。当前的数据收集解决方案大致可分为两类：挣扎于适应性和可重复性的封装方法，以及带来显著计算和财务成本的大语言模型（LLM）方法。为解决这些挑战，我们提出AutoData，这是一种新型多代理系统，用于自动化网页数据收集，仅需少量的人工干预，即只需提供一个自然语言指令来指定所需的数据集。此外，AutoData采用了一种稳健的多代理架构，包括由中央任务管理器协调的新型导向消息超图，以高效地组织研究与发展团队中的代理。此外，我们引入了一种新的超图缓存系统，以促进多代理协作过程，实现高效自动化数据收集，并缓解现有基于LLM系统中的标记成本问题。我们还引入了Instruct2DS，这是一种新的基准数据集，支持从三个领域（学术、金融和体育）的网页源进行实时数据收集。AutoData在Instruct2DS和三个现有基准数据集上的全面评估表明其性能优于基线方法。在书籍图集收集和调查中论文提取等具有挑战性的任务上进行的案例研究进一步验证了其适用性。我们的源代码和数据集可在此网页中获取。', 'title_zh': 'AutoData：一种面向开放网络数据收集的多智能体系统'}
{'arxiv_id': 'arXiv:2505.15856', 'title': 'DisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management', 'authors': 'Kai Yin, Xiangjue Dong, Chengkai Liu, Lipai Huang, Yiming Xiao, Zhewei Liu, Ali Mostafavi, James Caverlee', 'link': 'https://arxiv.org/abs/2505.15856', 'abstract': 'Effective disaster management requires timely access to accurate and contextually relevant information. Existing Information Retrieval (IR) benchmarks, however, focus primarily on general or specialized domains, such as medicine or finance, neglecting the unique linguistic complexity and diverse information needs encountered in disaster management scenarios. To bridge this gap, we introduce DisastIR, the first comprehensive IR evaluation benchmark specifically tailored for disaster management. DisastIR comprises 9,600 diverse user queries and more than 1.3 million labeled query-passage pairs, covering 48 distinct retrieval tasks derived from six search intents and eight general disaster categories that include 301 specific event types. Our evaluations of 30 state-of-the-art retrieval models demonstrate significant performance variances across tasks, with no single model excelling universally. Furthermore, comparative analyses reveal significant performance gaps between general-domain and disaster management-specific tasks, highlighting the necessity of disaster management-specific benchmarks for guiding IR model selection to support effective decision-making in disaster management scenarios. All source codes and DisastIR are available at this https URL.', 'abstract_zh': '有效的灾害管理需要及时访问准确且上下文相关的信息。然而，现有的信息检索（IR）基准主要集中在一般或专业领域，如医学或金融，忽视了灾害管理场景中遇到的独特语言复杂性和多样的信息需求。为了填补这一空白，我们引入了DisastIR，这是首个专门针对灾害管理的信息检索综合评价基准。DisastIR包含9600个多样化的用户查询和超过130万标记的查询-段落对，涵盖了来自六个检索意图和八个一般灾害类别中提取的48项独特检索任务，包括301种特定事件类型。我们对30种最先进的检索模型的评估表明，不同任务之间存在显著的性能差异，没有一种模型能在所有任务中表现出色。此外，对比分析揭示了通用领域和灾害管理特定任务之间显著的性能差距，突显了制定灾害管理特定基准的重要性，以指导信息检索模型的选择，支持灾害管理场景中的有效决策。所有源代码和DisastIR均可从此链接访问。', 'title_zh': 'DisastIR：灾难管理综合信息检索基准'}
{'arxiv_id': 'arXiv:2505.15854', 'title': 'Integration of TinyML and LargeML: A Survey of 6G and Beyond', 'authors': 'Thai-Hoc Vu, Ngo Hoang Tu, Thien Huynh-The, Kyungchun Lee, Sunghwan Kim, Miroslav Voznak, Quoc-Viet Pham', 'link': 'https://arxiv.org/abs/2505.15854', 'abstract': 'The transition from 5G networks to 6G highlights a significant demand for machine learning (ML). Deep learning models, in particular, have seen wide application in mobile networking and communications to support advanced services in emerging wireless environments, such as smart healthcare, smart grids, autonomous vehicles, aerial platforms, digital twins, and the metaverse. The rapid expansion of Internet-of-Things (IoT) devices, many with limited computational capabilities, has accelerated the development of tiny machine learning (TinyML) and resource-efficient ML approaches for cost-effective services. However, the deployment of large-scale machine learning (LargeML) solutions require major computing resources and complex management strategies to support extensive IoT services and ML-generated content applications. Consequently, the integration of TinyML and LargeML is projected as a promising approach for future seamless connectivity and efficient resource management.\nAlthough the integration of TinyML and LargeML shows abundant potential, several challenges persist, including performance optimization, practical deployment strategies, effective resource management, and security considerations. In this survey, we review and analyze the latest research aimed at enabling the integration of TinyML and LargeML models for the realization of smart services and applications in future 6G networks and beyond. The paper concludes by outlining critical challenges and identifying future research directions for the holistic integration of TinyML and LargeML in next-generation wireless networks.', 'abstract_zh': '5G网络向6G的过渡突显了对机器学习的显著需求。特别是在移动网络和通信中，深度学习模型已经在智能医疗、智能电网、自动驾驶车辆、空中平台、数字孪生和元宇宙等新兴无线环境中得到了广泛应用，以支持高级服务。物联网（IoT）设备的快速发展，许多设备计算能力有限，加速了对成本效益高的小型机器学习（TinyML）和资源高效机器学习方法的需求。然而，大规模机器学习（LargeML）解决方案的部署需要大量的计算资源和复杂的管理策略，以支持广泛的IoT服务和机器学习生成的内容应用。因此，TinyML和LargeML的结合被预见为未来无缝连接和有效资源管理的一个有希望的方法。\n\n尽管TinyML和LargeML的结合展示出了巨大的潜力，但仍存在一些挑战，包括性能优化、实际部署策略、有效的资源管理以及安全考量。在这篇综述中，我们回顾和分析了最新研究，旨在使TinyML和LargeML模型能够实现未来6G网络及其以上应用中的智能服务和应用。文章最后概述了TinyML和LargeML综合集成的关键挑战，并指出了下一代无线网络中TinyML和LargeML综合集成的未来研究方向。', 'title_zh': 'TinyML和LargeML的整合：面向6G及更远未来的综述'}
{'arxiv_id': 'arXiv:2505.15851', 'title': 'Exploring Moral Exercises for Human Oversight of AI systems: Insights from Three Pilot Studies', 'authors': 'Silvia Crafa, Teresa Scantamburlo', 'link': 'https://arxiv.org/abs/2505.15851', 'abstract': 'This paper elaborates on the concept of moral exercises as a means to help AI actors cultivate virtues that enable effective human oversight of AI systems. We explore the conceptual framework and significance of moral exercises, situating them within the contexts of philosophical discourse, ancient practices, and contemporary AI ethics scholarship. We outline the core pillars of the moral exercises methodology - eliciting an engaged personal disposition, fostering relational understanding, and cultivating technomoral wisdom - and emphasize their relevance to key activities and competencies essential for human oversight of AI systems. Our argument is supported by findings from three pilot studies involving a company, a multidisciplinary team of AI researchers, and higher education students. These studies allow us to explore both the potential and the limitations of moral exercises. Based on the collected data, we offer insights into how moral exercises can foster a responsible AI culture within organizations, and suggest directions for future research.', 'abstract_zh': '本文探讨了道德练习的概念，作为帮助AI主体培养能够有效进行人类监督的人类美德的一种手段。我们探究了道德练习的概念框架及其意义，将其置于哲学话语、古代实践以及当代AI伦理研究的背景下。我们概述了道德练习方法的核心支柱——激发积极个人倾向、培养关系理解以及培养技术美德智慧——并强调了它们对于人类监督AI系统的关键活动和能力的重要性。我们的论点得到了三项试点研究的支持，这些研究涉及一家公司、多学科的AI研究人员团队以及高等教育学生。这些研究使我们得以探索道德练习的潜力及其限制。基于收集的数据，我们提供了有关道德练习如何在组织内培养负责任的AI文化的见解，并建议了未来研究的方向。', 'title_zh': '探索人工道德练习以监管AI系统：三项试点研究的启示'}
{'arxiv_id': 'arXiv:2505.15849', 'title': 'What Lives? A meta-analysis of diverse opinions on the definition of life', 'authors': 'Reed Bender, Karina Kofman, Blaise Agüera y Arcas, Michael Levin', 'link': 'https://arxiv.org/abs/2505.15849', 'abstract': 'The question of "what is life?" has challenged scientists and philosophers for centuries, producing an array of definitions that reflect both the mystery of its emergence and the diversity of disciplinary perspectives brought to bear on the question. Despite significant progress in our understanding of biological systems, psychology, computation, and information theory, no single definition for life has yet achieved universal acceptance. This challenge becomes increasingly urgent as advances in synthetic biology, artificial intelligence, and astrobiology challenge our traditional conceptions of what it means to be alive. We undertook a methodological approach that leverages large language models (LLMs) to analyze a set of definitions of life provided by a curated set of cross-disciplinary experts. We used a novel pairwise correlation analysis to map the definitions into distinct feature vectors, followed by agglomerative clustering, intra-cluster semantic analysis, and t-SNE projection to reveal underlying conceptual archetypes. This methodology revealed a continuous landscape of the themes relating to the definition of life, suggesting that what has historically been approached as a binary taxonomic problem should be instead conceived as differentiated perspectives within a unified conceptual latent space. We offer a new methodological bridge between reductionist and holistic approaches to fundamental questions in science and philosophy, demonstrating how computational semantic analysis can reveal conceptual patterns across disciplinary boundaries, and opening similar pathways for addressing other contested definitional territories across the sciences.', 'abstract_zh': '“生命是什么？”这一问题challenge了科学家和哲学家数世纪之久，产生了多种定义，这些定义既反映了其起源的神秘性，也反映了不同学科视角的多样性。尽管我们在生物学系统、心理学、计算和信息理论方面的理解取得了 significant 进展，但尚未达成对生命单一定义的普遍接受。随着合成生物学、人工智能和天体生物学的进展，我们对生命意义的传统认知面临新的挑战。我们采用了一种方法论方法，利用大规模语言模型（LLMs）分析由跨学科专家提供的生命定义。我们使用了一种新颖的成对相关分析，将定义映射为不同的特征向量，随后进行了凝聚聚类、簇内语义分析和t-SNE投影，以揭示潜在的概念原型。这种方法揭示了与生命定义相关的主题连续谱，表明历史上被视为二分分类问题的内容，应该被视为统一概念潜在空间内的分化视角。我们提供了一种方法论桥梁，将还原论和整体论方法应用于科学研究和哲学的基本问题，展示了如何通过计算语义分析揭示跨学科界限的概念模式，并为解决科学领域其他争议性定义领域开辟了类似的路径。', 'title_zh': '生命何为？关于生命定义的多元观点元分析'}
{'arxiv_id': 'arXiv:2505.15840', 'title': 'TDFormer: A Top-Down Attention-Controlled Spiking Transformer', 'authors': 'Zizheng Zhu, Yingchao Yu, Zeqi Zheng, Zhaofei Yu, Yaochu Jin', 'link': 'https://arxiv.org/abs/2505.15840', 'abstract': "Traditional spiking neural networks (SNNs) can be viewed as a combination of multiple subnetworks with each running for one time step, where the parameters are shared, and the membrane potential serves as the only information link between them. However, the implicit nature of the membrane potential limits its ability to effectively represent temporal information. As a result, each time step cannot fully leverage information from previous time steps, seriously limiting the model's performance. Inspired by the top-down mechanism in the brain, we introduce TDFormer, a novel model with a top-down feedback structure that functions hierarchically and leverages high-order representations from earlier time steps to modulate the processing of low-order information at later stages. The feedback structure plays a role from two perspectives: 1) During forward propagation, our model increases the mutual information across time steps, indicating that richer temporal information is being transmitted and integrated in different time steps. 2) During backward propagation, we theoretically prove that the feedback structure alleviates the problem of vanishing gradients along the time dimension. We find that these mechanisms together significantly and consistently improve the model performance on multiple datasets. In particular, our model achieves state-of-the-art performance on ImageNet with an accuracy of 86.83%.", 'abstract_zh': '传统的脉冲神经网络（SNN）可以被视为多个子网络的组合，每个子网络在同一时间步运行，参数共享，膜电位作为它们之间的唯一信息链接。然而，膜电位的隐式性质限制了其有效地表示时间信息的能力。因此，每个时间步无法充分利用前一时间步的信息，严重限制了模型的性能。受大脑自上而下机制的启发，我们引入了TDFormer，这是一种具有自上而下反馈结构的新型模型，能够分层运行，并利用早期时间步的高阶表示来调节后期阶段低阶信息的处理。反馈结构从两个角度发挥作用：1）在正向传播过程中，模型增加跨时间步的信息互惠，表明在不同的时间步中传递和整合了更丰富的时空信息。2）在反向传播过程中，我们理论上证明了反馈结构缓解了时间维度中梯度消失的问题。我们发现，这些机制共同显著且一致地提高了模型在多个数据集上的性能。特别是在ImageNet数据集上，我们的模型达到了最先进的准确率86.83%。', 'title_zh': 'TDFormer: 一种自上而下注意力控制的神经脉冲变换器'}
{'arxiv_id': 'arXiv:2505.15836', 'title': 'Quantum-Evolutionary Neural Networks for Multi-Agent Federated Learning', 'authors': 'Aarav Lala, Kalyan Cherukuri', 'link': 'https://arxiv.org/abs/2505.15836', 'abstract': 'As artificial intelligence continues to drive innovation in complex, decentralized environments, the need for scalable, adaptive, and privacy-preserving decision-making systems has become critical. This paper introduces a novel framework combining quantum-inspired neural networks with evolutionary algorithms to optimize real-time decision-making in multi-agent systems (MAS). The proposed Quantum-Evolutionary Neural Network (QE-NN) leverages quantum computing principles -- such as quantum superposition and entanglement -- to enhance learning speed and decision accuracy, while integrating evolutionary optimization to continually refine agent behaviors in dynamic, uncertain environments. By utilizing federated learning, QE-NN ensures privacy preservation, enabling decentralized agents to collaborate without sharing sensitive data. The framework is designed to allow agents to adapt in real-time to their environments, optimizing decision-making processes for applications in areas such as autonomous systems, smart cities, and healthcare. This research represents a breakthrough in merging quantum computing, evolutionary optimization, and privacy-preserving techniques to solve complex problems in multi-agent decision-making systems, pushing the boundaries of AI in real-world, privacy-sensitive applications.', 'abstract_zh': '随着人工智能在复杂分散环境中的持续创新，构建可扩展、适应性强且保护隐私的决策系统变得至关重要。本文提出了一种结合量子启发神经网络与演化算法的新框架，以优化多智能体系统（MAS）的实时决策。所提出的量子-演化神经网络（QE-NN）利用量子计算原理——如量子叠加和纠缠——来提高学习速度和决策准确性，并结合演化优化持续改进智能体行为，使其能够在动态、不确定性环境中不断优化。通过利用联邦学习，QE-NN确保了隐私保护，使分散的智能体能够在不共享敏感数据的情况下进行协作。该框架设计旨在使智能体能够实时适应环境，优化决策过程，应用于自主系统、智慧城市和医疗健康等领域。该研究代表了将量子计算、演化优化和隐私保护技术融合以解决多智能体决策系统中复杂问题的突破，推动了在隐私敏感的实际应用中人工智能的边界。', 'title_zh': '量子演化神经网络在多agent联邦学习中的应用'}
{'arxiv_id': 'arXiv:2505.15835', 'title': 'Transforming Decoder-Only Transformers for Accurate WiFi-Telemetry Based Indoor Localization', 'authors': 'Nayan Sanjay Bhatia, Katia Obraczka', 'link': 'https://arxiv.org/abs/2505.15835', 'abstract': 'Wireless Fidelity (WiFi) based indoor positioning is a widely researched area for determining the position of devices within a wireless network. Accurate indoor location has numerous applications, such as asset tracking and indoor navigation. Despite advances in WiFi localization techniques -- in particular approaches that leverage WiFi telemetry -- their adoption in practice remains limited due to several factors including environmental changes that cause signal fading, multipath effects, interference, which, in turn, impact positioning accuracy. In addition, telemetry data differs depending on the WiFi device vendor, offering distinct features and formats; use case requirements can also vary widely. Currently, there is no unified model to handle all these variations effectively. In this paper, we present WiFiGPT, a Generative Pretrained Transformer (GPT) based system that is able to handle these variations while achieving high localization accuracy. Our experiments with WiFiGPT demonstrate that GPTs, in particular Large Language Models (LLMs), can effectively capture subtle spatial patterns in noisy wireless telemetry, making them reliable regressors. Compared to existing state-of-the-art methods, our method matches and often surpasses conventional approaches for multiple types of telemetry. Achieving sub-meter accuracy for RSSI and FTM and centimeter-level precision for CSI demonstrates the potential of LLM-based localisation to outperform specialized techniques, all without handcrafted signal processing or calibration.', 'abstract_zh': '基于WiFi的室内定位：一种能够处理变异并实现高精度定位的生成预训练变压器系统', 'title_zh': '仅解码器变压器模型的变换以实现基于WiFi-遥测的精确室内定位'}
{'arxiv_id': 'arXiv:2505.15834', 'title': 'MPPFND: A Dataset and Analysis of Detecting Fake News with Multi-Platform Propagation', 'authors': 'Congyuan Zhao, Lingwei Wei, Ziming Qin, Wei Zhou, Yunya Song, Songlin Hu', 'link': 'https://arxiv.org/abs/2505.15834', 'abstract': 'Fake news spreads widely on social media, leading to numerous negative effects. Most existing detection algorithms focus on analyzing news content and social context to detect fake news. However, these approaches typically detect fake news based on specific platforms, ignoring differences in propagation characteristics across platforms. In this paper, we introduce the MPPFND dataset, which captures propagation structures across multiple platforms. We also describe the commenting and propagation characteristics of different platforms to show that their social contexts have distinct features. We propose a multi-platform fake news detection model (APSL) that uses graph neural networks to extract social context features from various platforms. Experiments show that accounting for cross-platform propagation differences improves fake news detection performance.', 'abstract_zh': '多平台假新闻检测数据集及基于图神经网络的多平台假新闻检测模型', 'title_zh': 'MPPFND：多平台传播的假新闻检测数据集及分析'}
{'arxiv_id': 'arXiv:2505.15832', 'title': 'From Hand-Crafted Metrics to Evolved Training-Free Performance Predictors for Neural Architecture Search via Genetic Programming', 'authors': 'Quan Minh Phan, Ngoc Hoang Luong', 'link': 'https://arxiv.org/abs/2505.15832', 'abstract': 'Estimating the network performance using zero-cost (ZC) metrics has proven both its efficiency and efficacy in Neural Architecture Search (NAS). However, a notable limitation of most ZC proxies is their inconsistency, as reflected by the substantial variation in their performance across different problems. Furthermore, the design of existing ZC metrics is manual, involving a time-consuming trial-and-error process that requires substantial domain expertise. These challenges raise two critical questions: (1) Can we automate the design of ZC metrics? and (2) Can we utilize the existing hand-crafted ZC metrics to synthesize a more generalizable one? In this study, we propose a framework based on Symbolic Regression via Genetic Programming to automate the design of ZC metrics. Our framework is not only highly extensible but also capable of quickly producing a ZC metric with a strong positive rank correlation to true network performance across diverse NAS search spaces and tasks. Extensive experiments on 13 problems from NAS-Bench-Suite-Zero demonstrate that our automatically generated proxies consistently outperform hand-crafted alternatives. Using our evolved proxy metric as the search objective in an evolutionary algorithm, we could identify network architectures with competitive performance within 15 minutes using a single consumer GPU.', 'abstract_zh': '使用符号回归通过遗传编程自动化设计零成本度量以估计网络性能的研究', 'title_zh': '从手工构建的度量标准到通过遗传编程进化出的无训练性能预测器：针对神经架构搜索的进化训练-free方法'}
{'arxiv_id': 'arXiv:2505.15828', 'title': 'Generative AI-Aided QoE Maximization for RIS-Assisted Digital Twin Interaction', 'authors': 'Jiayuan Chen, Yuxiang Li, Changyan Yi, Shimin Gong', 'link': 'https://arxiv.org/abs/2505.15828', 'abstract': "In this paper, we investigate a quality of experience (QoE)-aware resource allocation problem for reconfigurable intelligent surface (RIS)-assisted digital twin (DT) interaction with uncertain evolution. In the considered system, mobile users are expected to interact with a DT model maintained on a DT server that is deployed on a base station, via effective uplink and downlink channels assisted by an RIS. Our goal is to maximize the sum of all mobile users' joint subjective and objective QoE in DT interactions across various DT scenes, by jointly optimizing phase shift matrix, receive/transmit beamforming matrix, rendering resolution configuration and computing resource allocation. While solving this problem is challenging mainly due to the uncertain evolution of the DT model, which leads to multiple scene-specific problems, and require us to constantly re-solve each of them whenever DT model evolves.\nTo this end, leveraging the dynamic optimization capabilities of decision transformers and the generalization strengths of generative artificial intelligence (GAI), we propose a novel GAI-aided approach, called the prompt-guided decision transformer integrated with zero-forcing optimization (PG-ZFO). Simulations are conducted to evaluate the proposed PG-ZFO, demonstrating its effectiveness and superiority over counterparts.", 'abstract_zh': '基于RIS辅助数字孪生交互的不确定演化效用感知资源分配问题：提示引导决策变换器结合零强迫优化方法', 'title_zh': '基于RIS辅助的数字孪生交互中生成式AI辅助的QoE最大化'}
{'arxiv_id': 'arXiv:2505.15825', 'title': 'Multilinear subspace learning for person re-identification based fusion of high order tensor features', 'authors': 'Ammar Chouchane, Mohcene Bessaoudi, Hamza Kheddar, Abdelmalik Ouamane, Tiago Vieira, Mahmoud Hassaballah', 'link': 'https://arxiv.org/abs/2505.15825', 'abstract': "Video surveillance image analysis and processing is a challenging field in computer vision, with one of its most difficult tasks being Person Re-Identification (PRe-ID). PRe-ID aims to identify and track target individuals who have already been detected in a network of cameras, using a robust description of their pedestrian images. The success of recent research in person PRe-ID is largely due to effective feature extraction and representation, as well as the powerful learning of these features to reliably discriminate between pedestrian images. To this end, two powerful features, Convolutional Neural Networks (CNN) and Local Maximal Occurrence (LOMO), are modeled on multidimensional data using the proposed method, High-Dimensional Feature Fusion (HDFF). Specifically, a new tensor fusion scheme is introduced to leverage and combine these two types of features in a single tensor, even though their dimensions are not identical. To enhance the system's accuracy, we employ Tensor Cross-View Quadratic Analysis (TXQDA) for multilinear subspace learning, followed by cosine similarity for matching. TXQDA efficiently facilitates learning while reducing the high dimensionality inherent in high-order tensor data. The effectiveness of our approach is verified through experiments on three widely-used PRe-ID datasets: VIPeR, GRID, and PRID450S. Extensive experiments demonstrate that our approach outperforms recent state-of-the-art methods.", 'abstract_zh': '视频监控图像分析与处理是计算机视觉中的一个挑战性领域，其中最困难的任务之一是行人重识别（PRe-ID）。PRe-ID旨在通过稳健描述行人的图像来识别和跟踪已在摄像头网络中被检测到的目标个体。近年来行人PRe-ID研究取得成功的主要原因是有效的特征提取和表示，以及这些特征的强大学习能力，以可靠地区分行人的图像。为此，本文提出了高维特征融合（HDFF）方法，利用该方法在多维数据上建模两种强大力量特征，卷积神经网络（CNN）和局部最大出现（LOMO）。具体而言，引入了一种新的张量融合方案，以在同一张量中利用和结合这两种特征，即使它们的维度不一致。为了提高系统的准确性，我们使用张量跨视图二次分析（TXQDA）进行多线性子空间学习，随后使用余弦相似度进行匹配。TXQDA有效地促进了学习并降低了高阶张量数据固有的高维度。通过在三个广泛使用的PRe-ID数据集VIPeR、GRID和PRID450S上的实验验证了我们方法的有效性。广泛实验表明，我们方法优于最近的先进方法。', 'title_zh': '基于高阶张量特征融合的人重识别多线性子空间学习'}
{'arxiv_id': 'arXiv:2505.15821', 'title': 'A Novel Compound AI Model for 6G Networks in 3D Continuum', 'authors': 'Milos Gravara, Andrija Stanisic, Stefan Nastic', 'link': 'https://arxiv.org/abs/2505.15821', 'abstract': 'The 3D continuum presents a complex environment that spans the terrestrial, aerial and space domains, with 6Gnetworks serving as a key enabling technology. Current AI approaches for network management rely on monolithic models that fail to capture cross-domain interactions, lack adaptability,and demand prohibitive computational resources. This paper presents a formal model of Compound AI systems, introducing a novel tripartite framework that decomposes complex tasks into specialized, interoperable modules. The proposed modular architecture provides essential capabilities to address the unique challenges of 6G networks in the 3D continuum, where heterogeneous components require coordinated, yet distributed, intelligence. This approach introduces a fundamental trade-off between model and system performance, which must be carefully addressed. Furthermore, we identify key challenges faced by Compound AI systems within 6G networks operating in the 3D continuum, including cross-domain resource orchestration, adaptation to dynamic topologies, and the maintenance of consistent AI service quality across heterogeneous environments.', 'abstract_zh': '3D连续体中的6G网络复合人工智能系统的形式模型及挑战', 'title_zh': '一种用于三维连续体的6G网络新型复合人工智能模型'}
{'arxiv_id': 'arXiv:2505.15820', 'title': 'Common Data Format (CDF): A Standardized Format for Match-Data in Football (Soccer)', 'authors': 'Gabriel Anzer, Kilian Arnsmeyer, Pascal Bauer, Joris Bekkers, Ulf Brefeld, Jesse Davis, Nicolas Evans, Matthias Kempe, Samuel J Robertson, Joshua Wyatt Smith, Jan Van Haaren', 'link': 'https://arxiv.org/abs/2505.15820', 'abstract': 'During football matches, a variety of different parties (e.g., companies) each collect (possibly overlapping) data about the match ranging from basic information (e.g., starting players) to detailed positional data. This data is provided to clubs, federations, and other organizations who are increasingly interested in leveraging this data to inform their decision making. Unfortunately, analyzing such data pose significant barriers because each provider may (1) collect different data, (2) use different specifications even within the same category of data, (3) represent the data differently, and (4) delivers the data in a different manner (e.g., file format, protocol). Consequently, working with these data requires a significant investment of time and money. The goal of this work is to propose a uniform and standardized format for football data called the Common Data Format (CDF). The CDF specifies a minimal schema for five types of match data: match sheet data, video footage, event data, tracking data, and match meta data. It aims to ensure that the provided data is clear, sufficiently contextualized (e.g., its provenance is clear), and complete such that it enables common downstream analysis tasks. Concretely, this paper will detail the technical specifications of the CDF, the representational choices that were made to help ensure the clarity of the provided data, and a concrete approach for delivering data in the CDF.', 'abstract_zh': '足球比赛中的通用数据格式（CDF）：一种统一且标准化的数据格式', 'title_zh': '通用数据格式（CDF）：足球比赛匹配数据的标准格式'}
{'arxiv_id': 'arXiv:2505.14679', 'title': 'UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models', 'authors': 'Xiaojie Gu, Guangxu Chen, Jungang Li, Jia-Chen Gu, Xuming Hu, Kai Zhang', 'link': 'https://arxiv.org/abs/2505.14679', 'abstract': "Lifelong learning enables large language models (LLMs) to adapt to evolving information by continually updating their internal knowledge. An ideal system should support efficient, wide-ranging updates while preserving existing capabilities and ensuring reliable deployment. Model editing stands out as a promising solution for this goal, offering a focused and efficient way to revise a model's internal knowledge. Although recent paradigms have made notable progress, they often struggle to meet the demands of practical lifelong adaptation at scale. To bridge this gap, we propose ULTRAEDIT-a fundamentally new editing solution that is training-, subject- and memory-free, making it particularly well-suited for ultra-scalable, real-world lifelong model editing. ULTRAEDIT performs editing through a self-contained process that relies solely on lightweight linear algebra operations to compute parameter shifts, enabling fast and consistent parameter modifications with minimal overhead. To improve scalability in lifelong settings, ULTRAEDIT employs a lifelong normalization strategy that continuously updates feature statistics across turns, allowing it to adapt to distributional shifts and maintain consistency over time. ULTRAEDIT achieves editing speeds over 7x faster than the previous state-of-the-art method-which was also the fastest known approach-while consuming less than 1/3 the VRAM, making it the only method currently capable of editing a 7B LLM on a 24GB consumer-grade GPU. Furthermore, we construct ULTRAEDITBENCH-the largest dataset in the field to date, with over 2M editing pairs-and demonstrate that our method supports up to 1M edits while maintaining high accuracy. Comprehensive experiments on four datasets and six models show that ULTRAEDIT consistently achieves superior performance across diverse model editing scenarios. Our code is available at: this https URL.", 'abstract_zh': '终身学习使大规模语言模型（LLMs）能够通过不断更新其内部知识来适应不断变化的信息。理想的系统应该支持高效、广泛的更新，同时保留现有能力并确保可靠的部署。模型编辑作为一种专注于高效更新模型内部知识的解决方案脱颖而出。尽管最近的范式取得了显著进展，但在大规模实际终身适应方面，它们往往难以满足需求。为解决这一问题，我们提出ULTRAEDIT——一种全新的、无训练、无领域知识和无内存负担的编辑解决方案，使其特别适合超大规模的实际终身模型编辑。ULTRAEDIT通过一个自包含的过程进行编辑，仅依赖轻量级线性代数操作来计算参数变动，从而实现快速且一致的参数修改，同时减少开销。为提高终身场景下的可扩展性，ULTRAEDIT采用了终身标准化策略，能够不断更新跨回合的特征统计，从而适应分布变化并保持时间一致。与上一种最先进方法相比，ULTRAEDIT的编辑速度高出7倍以上，且消耗的VRAM少于其1/3，从而成为唯一能够在24GB消费级GPU上编辑7B LLM的方法。此外，我们构建了迄今为止领域内最大的数据集ULTRAEDITBENCH，包含超过200万对编辑数据，并证明我们的方法在支持高达100万次编辑的同时保持高准确性。在四个数据集和六个模型的综合实验中，ULTRAEDIT在各种模型编辑场景中表现出优越性能。我们的代码可从以下链接获得：this https URL。', 'title_zh': 'UltraEdit: 无需训练、特定主题和记忆的大型语言模型终身编辑'}
{'arxiv_id': 'arXiv:2502.15401', 'title': 'Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning', 'authors': 'Xuetao Ma, Wenbin Jiang, Hua Huang', 'link': 'https://arxiv.org/abs/2502.15401', 'abstract': 'In-context learning (ICL) can significantly enhance the complex reasoning capabilities of large language models (LLMs), with the key lying in the selection and ordering of demonstration examples. Previous methods typically relied on simple features to measure the relevance between examples. We argue that these features are not sufficient to reflect the intrinsic connections between examples. In this study, we propose a curriculum ICL strategy guided by problem-solving logic. We select demonstration examples by analyzing the problem-solving logic and order them based on curriculum learning. Specifically, we constructed a problem-solving logic instruction set based on the BREAK dataset and fine-tuned a language model to analyze the problem-solving logic of examples. Subsequently, we selected appropriate demonstration examples based on problem-solving logic and assessed their difficulty according to the number of problem-solving steps. In accordance with the principles of curriculum learning, we ordered the examples from easy to hard to serve as contextual prompts. Experimental results on multiple benchmarks indicate that our method outperforms previous ICL approaches in terms of performance and efficiency, effectively enhancing the complex reasoning capabilities of LLMs. Our project will be publicly available subsequently.', 'abstract_zh': '基于问题求解逻辑的在上下文学习策略', 'title_zh': '基于问题求解逻辑导向的在域复杂推理融合学习课程设计'}
