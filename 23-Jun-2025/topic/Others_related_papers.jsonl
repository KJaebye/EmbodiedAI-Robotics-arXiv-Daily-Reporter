{'arxiv_id': 'arXiv:2506.16892', 'title': 'Orbital Collision: An Indigenously Developed Web-based Space Situational Awareness Platform', 'authors': 'Partha Chowdhury, Harsha M, Ayush Gupta, Sanat K Biswas', 'link': 'https://arxiv.org/abs/2506.16892', 'abstract': "This work presents an indigenous web based platform Orbital Collision (OrCo), created by the Space Systems Laboratory at IIIT Delhi, to enhance Space Situational Awareness (SSA) by predicting collision probabilities of space objects using Two Line Elements (TLE) data. The work highlights the growing challenges of congestion in the Earth's orbital environment, mainly due to space debris and defunct satellites, which increase collision risks. It employs several methods for propagating orbital uncertainty and calculating the collision probability. The performance of the platform is evaluated through accuracy assessments and efficiency metrics, in order to improve the tracking of space objects and ensure the safety of the satellite in congested space.", 'abstract_zh': '本研究介绍由印度信息技术学院DELHI空间系统实验室创建的本民族Web基于平台Orbital Collision (OrCo)，通过使用Two Line Elements (TLE)数据预测空间物体的碰撞概率以增强太空态势感知（SSA）。该研究强调了地球轨道环境日益严重的拥堵问题，主要由于空间碎片和失效卫星增加了碰撞风险。平台采用了多种方法传播轨道不确定性并计算碰撞概率。通过准确性和效率指标评估平台性能，以提高对空间物体的跟踪并确保拥挤太空中卫星的安全。', 'title_zh': '轨道碰撞：一款本土开发的基于Web的空间态势感知平台'}
{'arxiv_id': 'arXiv:2506.16537', 'title': 'Agile, Autonomous Spacecraft Constellations with Disruption Tolerant Networking to Monitor Precipitation and Urban Floods', 'authors': 'Sreeja Roy-Singh, Alan P. Li, Vinay Ravindra, Roderick Lammers, Marc Sanchez Net', 'link': 'https://arxiv.org/abs/2506.16537', 'abstract': 'Fully re-orientable small spacecraft are now supported by commercial technologies, allowing them to point their instruments in any direction and capture images, with short notice. When combined with improved onboard processing, and implemented on a constellation of inter-communicable satellites, this intelligent agility can significantly increase responsiveness to transient or evolving phenomena. We demonstrate a ground-based and onboard algorithmic framework that combines orbital mechanics, attitude control, inter-satellite communication, intelligent prediction and planning to schedule the time-varying, re-orientation of agile, small satellites in a constellation. Planner intelligence is improved by updating the predictive value of future space-time observations based on shared observations of evolving episodic precipitation and urban flood forecasts. Reliable inter-satellite communication within a fast, dynamic constellation topology is modeled in the physical, access control and network layer. We apply the framework on a representative 24-satellite constellation observing 5 global regions. Results show appropriately low latency in information exchange (average within 1/3rd available time for implicit consensus), enabling the onboard scheduler to observe ~7% more flood magnitude than a ground-based implementation. Both onboard and offline versions performed ~98% better than constellations without agility.', 'abstract_zh': '完全可重新定向的小型航天器现在由商业技术支持，允许它们在任何方向指向仪器并快速捕获图像。通过结合改进的机载处理，并在通信卫星星座中实施，这种智能敏捷性可以显著提高对瞬态或演变现象的响应性。我们展示了结合轨道力学、姿态控制、卫星间通信、智能预测和规划的地面和机载算法框架，以协调星座中敏捷小型卫星的时间变化重新定向。通过基于共享的演化 episodic 降水和城市洪水预报更新未来时空观测的预测值来提高规划的智能性。在物理层、访问控制层和网络层中建模了快速动态星座拓扑内的可靠卫星间通信。我们在一个代表性的24颗卫星星座上应用了该框架，该星座观察5个全球区域。结果显示适当较低的延迟（平均在隐式共识可用时间的三分之一以内）使得机载调度器能够检测到比地面实现多约7%的洪水规模。无论是机载版本还是离线版本都比没有敏捷性的星座高出约98%。', 'title_zh': '具有中断 tolerant 网络的敏捷自主卫星星座及其在监测降水和城市洪涝中的应用'}
{'arxiv_id': 'arXiv:2506.16535', 'title': 'eCAV: An Edge-Assisted Evaluation Platform for Connected Autonomous Vehicles', 'authors': 'Tyler Landle, Jordan Rapp, Dean Blank, Chandramouli Amarnath, Abhijit Chatterjee, Alex Daglis, Umakishore Ramachandran', 'link': 'https://arxiv.org/abs/2506.16535', 'abstract': 'As autonomous vehicles edge closer to widespread adoption, enhancing road safety through collision avoidance and minimization of collateral damage becomes imperative. Vehicle-to-everything (V2X) technologies, which include vehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), and vehicle-to-cloud (V2C), are being proposed as mechanisms to achieve this safety improvement.\nSimulation-based testing is crucial for early-stage evaluation of Connected Autonomous Vehicle (CAV) control systems, offering a safer and more cost-effective alternative to real-world tests. However, simulating large 3D environments with many complex single- and multi-vehicle sensors and controllers is computationally intensive. There is currently no evaluation framework that can effectively evaluate realistic scenarios involving large numbers of autonomous vehicles.\nWe propose eCAV -- an efficient, modular, and scalable evaluation platform to facilitate both functional validation of algorithmic approaches to increasing road safety, as well as performance prediction of algorithms of various V2X technologies, including a futuristic Vehicle-to-Edge control plane and correspondingly designed control algorithms. eCAV can model up to 256 vehicles running individual control algorithms without perception enabled, which is $8\\times$ more vehicles than what is possible with state-of-the-art alternatives. %faster than state-of-the-art alternatives that can simulate $8\\times$ fewer vehicles. With perception enabled, eCAV simulates up to 64 vehicles with a step time under 800ms, which is $4\\times$ more and $1.5\\times$ faster than the state-of-the-art OpenCDA framework.', 'abstract_zh': '随着自动驾驶车辆向广泛应用接近，通过碰撞避免和减少副损伤来增强道路安全变得至关重要。车辆到万物（V2X）技术，包括车辆到车辆（V2V）、车辆到基础设施（V2I）和车辆到云（V2C），被提出作为实现这一安全提升的机制。\n\n基于仿真的测试对于联网自动驾驶车辆（CAV）控制系统的早期评估至关重要， Offering a更安全和更具成本效益的替代方案，智能替代真实的道路测试。然而，模拟包含许多复杂单、多车辆传感器和控制器的大型三维环境计算量巨大。目前尚不存在有效的评估框架来评估大量自动驾驶车辆的现实场景。\n\n我们提出eCAV——一种高效的、模块化的和可扩展的评估平台，以促进对增加道路安全的算法方法的功能验证，以及各种V2X技术的算法性能预测，包括未来的车辆到边缘控制平面及其相应设计的控制算法。eCAV在未启用感知的情况下可模拟最多256辆车单独运行控制算法，比最先进的替代方案多8倍的车辆。当启用感知时，eCAV可模拟最多64辆车，每步时间低于800毫秒，比最先进的OpenCDA框架多4倍、快1.5倍。', 'title_zh': '基于边缘辅助的Connected Autonomous Vehicles评估平台:eCAV'}
{'arxiv_id': 'arXiv:2506.16050', 'title': 'Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments', 'authors': 'Jiawen Yu, Jieji Ren, Yang Chang, Qiaojun Yu, Xuan Tong, Boyang Wang, Yan Song, You Li, Xinji Mai, Wenqiang Zhang', 'link': 'https://arxiv.org/abs/2506.16050', 'abstract': 'Anomaly detection and localization in automated industrial manufacturing can significantly enhance production efficiency and product quality. Existing methods are capable of detecting surface defects in pre-defined or controlled imaging environments. However, accurately detecting workpiece defects in complex and unstructured industrial environments with varying views, poses and illumination remains challenging. We propose a novel anomaly detection and localization method specifically designed to handle inputs with perturbative patterns. Our approach introduces a new framework based on a collaborative distillation heterogeneous teacher network (HetNet), an adaptive local-global feature fusion module, and a local multivariate Gaussian noise generation module. HetNet can learn to model the complex feature distribution of normal patterns using limited information about local disruptive changes. We conducted extensive experiments on mainstream benchmarks. HetNet demonstrates superior performance with approximately 10% improvement across all evaluation metrics on MSC-AD under industrial conditions, while achieving state-of-the-art results on other datasets, validating its resilience to environmental fluctuations and its capability to enhance the reliability of industrial anomaly detection systems across diverse scenarios. Tests in real-world environments further confirm that HetNet can be effectively integrated into production lines to achieve robust and real-time anomaly detection. Codes, images and videos are published on the project website at: this https URL', 'abstract_zh': '自动化工业制造中的异常检测和定位可以显著提高生产效率和产品质量。现有的方法能够在预定义或受控的成像环境中检测表面缺陷。然而，在复杂且非结构化的工业环境中，面对不同视角、姿态和照明条件导致的缺陷检测仍然具有挑战性。我们提出了一种新型的异常检测和定位方法，专门用于处理具有扰动模式的输入。我们的方法引入了一种基于协作式蒸馏异构教师网络（HetNet）的新框架、自适应局部-全局特征融合模块以及局部多元高斯噪声生成模块。HetNet能够利用有限的局部扰动变化信息学习建模正常模式的复杂特征分布。我们在主流基准上进行了广泛的实验。在工业条件下，HetNet在MSC-AD上的所有评估指标上表现出约10%的性能提升，而在其他数据集上则达到了最先进的结果，验证了其对环境波动的抗性和在各种场景下增强工业异常检测系统的可靠性。在真实环境中的测试进一步证实HetNet可以有效集成到生产线上，实现稳健且实时的异常检测。相关代码、图像和视频已在项目网站上发布：this https URL。', 'title_zh': '基于噪声融合的精炼学习方法在复杂工业环境中的异常检测'}
{'arxiv_id': 'arXiv:2506.15983', 'title': 'A Low-Cost Portable Lidar-based Mobile Mapping System on an Android Smartphone', 'authors': 'Jianzhu Huai, Yuxin Shao, Yujia Zhang, Alper Yilmaz', 'link': 'https://arxiv.org/abs/2506.15983', 'abstract': "The rapid advancement of the metaverse, digital twins, and robotics underscores the demand for low-cost, portable mapping systems for reality capture. Current mobile solutions, such as the Leica BLK2Go and lidar-equipped smartphones, either come at a high cost or are limited in range and accuracy. Leveraging the proliferation and technological evolution of mobile devices alongside recent advancements in lidar technology, we introduce a novel, low-cost, portable mobile mapping system. Our system integrates a lidar unit, an Android smartphone, and an RTK-GNSS stick. Running on the Android platform, it features lidar-inertial odometry built with the NDK, and logs data from the lidar, wide-angle camera, IMU, and GNSS. With a total bill of materials (BOM) cost under 2,000 USD and a weight of about 1 kilogram, the system achieves a good balance between affordability and portability. We detail the system design, multisensor calibration, synchronization, and evaluate its performance for tracking and mapping. To further contribute to the community, the system's design and software are made open source at: this https URL", 'abstract_zh': '虚拟现实、数字孪生和机器人技术的快速发展突显了对低成本、便携式现实捕捉测绘系统的 Demand。当前的移动解决方案，如 Leica BLK2Go 和配备激光雷达的智能手机，要么成本高昂，要么在范围和精度上有限制。借助移动设备的普及和技术演变以及近年来激光雷达技术的进步，我们引入了一种新型低成本便携式移动测绘系统。该系统集成了激光雷达单元、Android智能手机和RTK-GNSS天线杆。基于Android平台，该系统使用NDK构建了激光雷达-惯性 odometry，并记录来自激光雷达、广角相机、IMU和GNSS的数据。该系统的材料成本低于2000美元，重量约为1千克，实现了成本效益和便携性的良好平衡。我们详细介绍了系统设计、多传感器标定、同步及其在追踪和测绘中的性能评估。为进一步贡献社区，该系统的硬件设计和软件已在以下链接开源：this https URL。', 'title_zh': '一种基于Android智能手机的低成本便携式LiDAR移动 Mapping 系统'}
{'arxiv_id': 'arXiv:2506.15890', 'title': 'Challenges and Research Directions from the Operational Use of a Machine Learning Damage Assessment System via Small Uncrewed Aerial Systems at Hurricanes Debby and Helene', 'authors': 'Thomas Manzini, Priyankari Perali, Robin R. Murphy, David Merrick', 'link': 'https://arxiv.org/abs/2506.15890', 'abstract': 'This paper details four principal challenges encountered with machine learning (ML) damage assessment using small uncrewed aerial systems (sUAS) at Hurricanes Debby and Helene that prevented, degraded, or delayed the delivery of data products during operations and suggests three research directions for future real-world deployments. The presence of these challenges is not surprising given that a review of the literature considering both datasets and proposed ML models suggests this is the first sUAS-based ML system for disaster damage assessment actually deployed as a part of real-world operations. The sUAS-based ML system was applied by the State of Florida to Hurricanes Helene (2 orthomosaics, 3.0 gigapixels collected over 2 sorties by a Wintra WingtraOne sUAS) and Debby (1 orthomosaic, 0.59 gigapixels collected via 1 sortie by a Wintra WingtraOne sUAS) in Florida. The same model was applied to crewed aerial imagery of inland flood damage resulting from post-tropical remnants of Hurricane Debby in Pennsylvania (436 orthophotos, 136.5 gigapixels), providing further insights into the advantages and limitations of sUAS for disaster response. The four challenges (variationin spatial resolution of input imagery, spatial misalignment between imagery and geospatial data, wireless connectivity, and data product format) lead to three recommendations that specify research needed to improve ML model capabilities to accommodate the wide variation of potential spatial resolutions used in practice, handle spatial misalignment, and minimize the dependency on wireless connectivity. These recommendations are expected to improve the effective operational use of sUAS and sUAS-based ML damage assessment systems for disaster response.', 'abstract_zh': '本文详细分析了在飓风黛比和海伦期间使用小型无人 aerial 系统（sUAS）进行机器学习（ML）损伤评估时遇到的四个主要挑战，这些挑战妨碍、降低了或延迟了数据产品的交付，并提出了三个未来实际部署中的研究方向。鉴于文献审查表明，这是首个在实际灾害响应操作中部署的基于sUAS的ML系统，这些挑战的存在并不令人惊讶。基于sUAS的ML系统分别应用于佛罗里达州的飓风海伦（2张正射影像，采集数据量3.0吉像素，通过两次飞行任务由Wintra WingtraOne sUAS完成）和黛比（1张正射影像，0.59吉像素，通过一次飞行任务由Wintra WingtraOne sUAS采集），以及宾夕法尼亚州由后热带残余的黛比引起的内陆洪水灾害的有照侦察（436张正射影像，136.5吉像素）。这进一步揭示了sUAS在灾害响应中的优势与局限性。四个挑战（输入影像的空间分辨率变异、影像与地理空间数据的空间错位、无线连接以及数据产品格式）导致三个建议，这些建议详细规定了需进行的研究以改进ML模型的能力，以适应实际操作中使用的广泛空间分辨率变异、处理空间错位，并减少对无线连接的依赖。这些建议有望提高sUAS及其基于sUAS的ML损伤评估系统在灾害响应中的有效操作使用。', 'title_zh': '小型无人航空系统在飓风德贝和海伦中运用的机器学习损伤评估系统的操作使用挑战及研究方向'}
{'arxiv_id': 'arXiv:2506.17213', 'title': 'Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation', 'authors': 'Xiuyu Yang, Shuhan Tan, Philipp Krähenbühl', 'link': 'https://arxiv.org/abs/2506.17213', 'abstract': 'An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system experiences during deployment. Prior models and benchmarks focus on closed-loop motion simulation for initial agents in a scene. This is problematic for long-term simulation. Agents enter and exit the scene as the ego vehicle enters new regions. We propose InfGen, a unified next-token prediction model that performs interleaved closed-loop motion simulation and scene generation. InfGen automatically switches between closed-loop motion simulation and scene generation mode. It enables stable long-term rollout simulation. InfGen performs at the state-of-the-art in short-term (9s) traffic simulation, and significantly outperforms all other methods in long-term (30s) simulation. The code and model of InfGen will be released at this https URL', 'abstract_zh': '一个理想的交通模拟器能够重现自动驾驶系统在部署过程中经历的现实长期点对点行程。以往的模型和基准主要关注场景中初始代理的闭环运动模拟。这不利于长期模拟。随着 ego 车辆进入新的区域，代理会进入和退出场景。我们提出了一种统一的下一标记预测模型 InfGen，该模型执行交错的闭环运动模拟和场景生成。InfGen 自动在闭环运动模拟模式和场景生成模式之间切换，从而实现稳定长期滚动模拟。InfGen 在短期（9秒）交通模拟中达到最先进的性能，并在长期（30秒）模拟中显著优于所有其他方法。InfGen 的代码和模型将在此处发布：https://xxxxxx。', 'title_zh': '交错自回归运动与场景生成的长期交通仿真'}
{'arxiv_id': 'arXiv:2506.16753', 'title': 'Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation', 'authors': 'Kosuke Nakanishi, Akihiro Kubo, Yuji Yasui, Shin Ishii', 'link': 'https://arxiv.org/abs/2506.16753', 'abstract': "Recently, robust reinforcement learning (RL) methods designed to handle adversarial input observations have received significant attention, motivated by RL's inherent vulnerabilities. While existing approaches have demonstrated reasonable success, addressing worst-case scenarios over long time horizons requires both minimizing the agent's cumulative rewards for adversaries and training agents to counteract them through alternating learning. However, this process introduces mutual dependencies between the agent and the adversary, making interactions with the environment inefficient and hindering the development of off-policy methods. In this work, we propose a novel off-policy method that eliminates the need for additional environmental interactions by reformulating adversarial learning as a soft-constrained optimization problem. Our approach is theoretically supported by the symmetric property of policy evaluation between the agent and the adversary. The implementation is available at this https URL.", 'abstract_zh': '最近，针对对抗输入观测的鲁棒强化学习方法受到了广泛关注，这类方法旨在处理RL固有的脆弱性。虽然现有方法已经显示出合理的成效，但在长时间范围内应对最坏情况场景需要同时最小化智能体累积的奖励给对手带来的影响，并通过交替学习训练智能体对抗对手。然而，这一过程引入了智能体与对手之间的相互依赖，使得与环境的交互变得低效，阻碍了离策方法的发展。本文提出了一种新的离策方法，通过将对抗学习重新表述为软约束优化问题来消除额外环境交互的需求。我们的方法基于智能体和对手之间策略评估的对称性质具有理论支持。该实现可在以下链接访问：this https URL。', 'title_zh': '针对对抗观测稳健性的离策训练actor-critic方法：通过对称策略评估的虚拟替代训练'}
{'arxiv_id': 'arXiv:2506.17130', 'title': 'Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI', 'authors': 'Botao Zhu, Xianbin Wang, Lei Zhang, Xuemin, Shen', 'link': 'https://arxiv.org/abs/2506.17130', 'abstract': 'In collaborative systems with complex tasks relying on distributed resources, trust evaluation of potential collaborators has emerged as an effective mechanism for task completion. However, due to the network dynamics and varying information gathering latencies, it is extremely challenging to observe and collect all trust attributes of a collaborating device concurrently for a comprehensive trust assessment. In this paper, a novel progressive trust evaluation framework, namely chain-of-trust, is proposed to make better use of misaligned device attribute data. This framework, designed for effective task completion, divides the trust evaluation process into multiple chained stages based on task decomposition. At each stage, based on the task completion process, the framework only gathers the latest device attribute data relevant to that stage, leading to reduced trust evaluation complexity and overhead. By leveraging advanced in-context learning, few-shot learning, and reasoning capabilities, generative AI is then employed to analyze and interpret the collected data to produce correct evaluation results quickly. Only devices deemed trustworthy at this stage proceed to the next round of trust evaluation. The framework ultimately determines devices that remain trustworthy across all stages. Experimental results demonstrate that the proposed framework achieves high accuracy in trust evaluation.', 'abstract_zh': '在依赖分布式资源的复杂任务协作系统中，潜在协作方的信任评估已成为有效完成任务的有效机制。然而，由于网络动态性和信息收集延迟的变化，很难同时观察和收集协作设备的所有信任属性以进行全面的信任评估。本文提出了一种新颖的逐级信任评估框架——链式信任框架，以更好地利用不一致的设备属性数据。该框架针对有效完成任务而设计，基于任务分解将信任评估过程划分为多个链式阶段。在每个阶段，基于任务完成过程，该框架仅收集当前阶段相关的最新设备属性数据，从而降低信任评估的复杂性和开销。通过利用高级上下文学习、少样本学习和推理能力，然后使用生成式AI来分析和解释收集的数据，迅速生成正确的评估结果。仅在当前阶段被认为可信的设备才进入下一阶段的信任评估。该框架最终确定在整个阶段都保持可信的设备。实验结果表明，所提出的框架在信任评估中实现了高准确性。', 'title_zh': '可信链：由生成式AI赋能的逐步信任评估框架'}
{'arxiv_id': 'arXiv:2506.17114', 'title': 'Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models', 'authors': 'Dadi Guo, Jiayu Liu, Zhiyuan Fan, Zhitao He, Haoran Li, Yumeng Wang, Yi R., Fung', 'link': 'https://arxiv.org/abs/2506.17114', 'abstract': "Large reasoning models (e.g., R1, o3) have demonstrated remarkable mathematical problem-solving abilities. However, the high reported accuracy of these advanced models on popular datasets, reliance on purely numerical evaluation and potential benchmark leakage, often masks their true reasoning shortcomings. To address this, we propose leveraging the inherent rigor and methodological complexity of mathematical proofs as a diagnostic tool to expose these hidden failures. Specifically, we introduce the RFMDataset (Reveal Failure Modes), a collection of 200 diverse mathematical proof problems, and thoroughly evaluate advanced models' performance on it. Our in-depth analysis of their failures uncovers 10 fine-grained error types, which shows fundamental limitations in current large reasoning models: 1) large reasoning models grapple profoundly with mathematical proofs, with some generating entirely correct proofs for less than 20% of problems and failing even on basic ones; 2) models exhibit a diverse spectrum of reasoning failures, prominently demonstrating the lack of guarantees for the correctness and rigor of single-step reasoning; and 3) models show hallucination and incompleteness during the reasoning process. Our findings reveal that models' self-reflection is insufficient to resolve the current logical dilemmas, necessitating formalized and fine-grained logical training.", 'abstract_zh': '大型推理模型（如R1、o3）在数学问题求解能力上表现出色，但这些先进模型在流行数据集上的高报道准确度、纯粹的数值评估依赖以及潜在的基准泄露问题，往往掩盖了它们真实的推理缺陷。为解决这一问题，我们提出利用数学证明固有的严谨性和方法学复杂性作为诊断工具，以揭示隐藏的失败模式。具体而言，我们引入了RFMDataset（Reveal Failure Modes），包含200个多样化的数学证明问题，并全面评估先进模型在该数据集上的表现。通过对它们失败的深入分析，我们发现了10种细微错误类型，揭示了当前大型推理模型的基本限制：1）大型推理模型在数学证明问题上面临深刻挑战，部分模型在不到20%的问题上生成完全正确的证明，并且在简单问题上也屡屡失败；2）模型在推理过程中的失败表现多样，明显缺乏单步推理正确性和严谨性的保证；3）模型在推理过程中表现出幻觉和不完整性。我们的研究结果表明，模型的自我反思不足以解决当前的逻辑困境，需要进行形式化和细致的逻辑训练。', 'title_zh': '数学证明作为试金石：揭示高级大型推理模型的失效模式'}
{'arxiv_id': 'arXiv:2506.17085', 'title': 'Dispositions and Roles of Generically Dependent Entities', 'authors': 'Fabian Neuhaus', 'link': 'https://arxiv.org/abs/2506.17085', 'abstract': 'BFO 2020 does not support functions, dispositions, and roles of generically dependent continuants (like software or datasets). In this paper, we argue that this is a severe limitation, which prevents, for example, the adequate representation of the functions of computer models or the various roles of datasets during the execution of these models. We discuss the aspects of BFO 2020 that prevent the representation of realizable entities of generically dependent continuants. Two approaches to address the issue are presented: (a) the use of defined classes and (b) a proposal of changes that allow BFO to support functions, dispositions, and roles of generically dependent continuants.', 'abstract_zh': 'BFO 2020 不支持通用依赖延续体（如软件或数据集）的功能、性质和角色。本文认为这是一项严重限制，例如无法充分代表计算机模型的功能或模型运行期间数据集的各种角色。我们讨论了 BFO 2020 阻碍通用依赖延续体实现实体表示的方面。提出了两种解决方案：（a）使用定义类，（b）提出更改以使 BFO 支持通用依赖延续体的功能、性质和角色。', 'title_zh': '泛依赖实体的性质与角色'}
{'arxiv_id': 'arXiv:2506.17018', 'title': 'A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models', 'authors': 'Davide Frizzo, Francesco Borsatti, Gian Antonio Susto', 'link': 'https://arxiv.org/abs/2506.17018', 'abstract': 'Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively enhancing efficiency through accurate equipment Remaining Useful Life (RUL) prediction, thus optimizing maintenance scheduling and reducing unexpected failures and premature interventions. This paper introduces a novel RUL estimation approach leveraging State Space Models (SSM) for efficient long-term sequence modeling. To handle model uncertainty, Simoultaneous Quantile Regression (SQR) is integrated into the SSM, enabling multiple quantile estimations. The proposed method is benchmarked against traditional sequence modelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset. Results demonstrate superior accuracy and computational efficiency of SSM models, underscoring their potential for high-stakes industrial applications.', 'abstract_zh': 'Predictive 维护在工业4.0和5.0中至关重要，通过准确的设备剩余使用寿命（RUL）预测主动提升效率，从而优化维护调度并减少意外故障和过早干预。本文引入了一种利用状态空间模型（SSM）进行高效长序列建模的新RUL估计方法。为了处理模型不确定性，将同时分位数回归（SQR）集成到SSM中，使其能够进行多分位数估计。所提出的方法使用C-MAPSS数据集与传统的序列建模技术（LSTM、Transformer、Informer）进行基准测试。结果展示了SSM模型在准确性和计算效率方面的优越性，突显了其在高风险工业应用中的潜在价值。', 'title_zh': '基于状态空间模型的分位数回归剩余使用寿命估算方法'}
{'arxiv_id': 'arXiv:2506.16924', 'title': 'Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines', 'authors': 'Tomoya Kashimata, Yohei Hamakawa, Masaya Yamasaki, Kosuke Tatsumura', 'link': 'https://arxiv.org/abs/2506.16924', 'abstract': 'Many real-time systems require the optimization of discrete variables. Black-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms perform optimization by repeatedly taking actions and observing the corresponding instant rewards without any prior knowledge. Recently, a BBO method using an Ising machine has been proposed to find the best action that is represented by a combination of discrete values and maximizes the instant reward in static environments. In contrast, dynamic environments, where real-time systems operate, necessitate MAB algorithms that maximize the average reward over multiple trials. However, due to the enormous number of actions resulting from the combinatorial nature of discrete optimization, conventional MAB algorithms cannot effectively optimize dynamic, discrete environments. Here, we show a heuristic MAB method for dynamic, discrete environments by extending the BBO method, in which an Ising machine effectively explores the actions while considering interactions between variables and changes in dynamic environments. We demonstrate the dynamic adaptability of the proposed method in a wireless communication system with moving users.', 'abstract_zh': '使用伊辛机的黑盒优化方法在动态离散环境中优化即时奖励：一种扩展多臂bandit算法的方法', 'title_zh': '使用嵌入式伊辛机的实时黑盒优化方法及其在动态离散环境中的应用'}
{'arxiv_id': 'arXiv:2506.16731', 'title': 'Incentivizing High-quality Participation From Federated Learning Agents', 'authors': 'Jinlong Pang, Jiaheng Wei, Yifan Hua, Chen Qian, Yang Liu', 'link': 'https://arxiv.org/abs/2506.16731', 'abstract': "Federated learning (FL) provides a promising paradigm for facilitating collaboration between multiple clients that jointly learn a global model without directly sharing their local data. However, existing research suffers from two caveats: 1) From the perspective of agents, voluntary and unselfish participation is often assumed. But self-interested agents may opt out of the system or provide low-quality contributions without proper incentives; 2) From the mechanism designer's perspective, the aggregated models can be unsatisfactory as the existing game-theoretical federated learning approach for data collection ignores the potential heterogeneous effort caused by contributed data. To alleviate above challenges, we propose an incentive-aware framework for agent participation that considers data heterogeneity to accelerate the convergence process. Specifically, we first introduce the notion of Wasserstein distance to explicitly illustrate the heterogeneous effort and reformulate the existing upper bound of convergence. To induce truthful reporting from agents, we analyze and measure the generalization error gap of any two agents by leveraging the peer prediction mechanism to develop score functions. We further present a two-stage Stackelberg game model that formalizes the process and examines the existence of equilibrium. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed mechanism.", 'abstract_zh': 'federated学习（FL）提供了一种促进多个客户端协作学习全局模型而无需直接共享本地数据的有前途的范式。然而，现有研究存在两个问题：1) 从代理的角度来看，自愿和无私的参与通常被视为理所当然。但自私的代理可能会退出系统或在没有适当激励的情况下提供低质量的贡献；2) 从机制设计者角度来看，现有的基于博弈论的数据收集联邦学习方法忽略了贡献数据导致的潜在异质性努力，从而使聚合模型不尽如人意。为了缓解上述挑战，我们提出了一种关注激励的代理参与框架，该框架考虑数据异质性以加速收敛过程。具体而言，我们首先引入Wasserstein距离来明确表示异质性努力并重新表述现有收敛的上界。为诱导代理进行真实报告，我们利用同伴预测机制分析和度量任意两个代理的泛化误差差异，以开发评分函数。我们进一步提出了一种两阶段斯塔克尔贝格博弈模型，该模型形式化了过程并检查了均衡的存在性。在真实世界数据集上的 extensive 实验表明我们提出机制的有效性。', 'title_zh': '激励联邦学习代理参与高质量合作'}
{'arxiv_id': 'arXiv:2506.16696', 'title': 'Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics', 'authors': 'Kenjiro Ide, Taiga Someya, Kohei Kawaguchi, Keisuke Fujii', 'link': 'https://arxiv.org/abs/2506.16696', 'abstract': "Understanding football tactics is crucial for managers and analysts. Previous research has proposed models based on spatial and kinematic equations, but these are computationally expensive. Also, Reinforcement learning approaches use player positions and velocities but lack interpretability and require large datasets. Rule-based models align with expert knowledge but have not fully considered all players' states. This study explores whether low-dimensional, rule-based models using spatiotemporal data can effectively capture football tactics. Our approach defines interpretable state variables for both the ball-holder and potential pass receivers, based on criteria that explore options like passing. Through discussions with a manager, we identified key variables representing the game state. We then used StatsBomb event data and SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost model to predict pass success. The analysis revealed that the distance between the player and the ball, as well as the player's space score, were key factors in determining successful passes. Our interpretable low-dimensional modeling facilitates tactical analysis through the use of intuitive variables and provides practical value as a tool to support decision-making in football.", 'abstract_zh': '理解足球战术对于教练和分析师至关重要。尽管以往研究提出了基于空间和运动方程的模型，但这些模型计算成本较高。强化学习方法通过球员位置和速度进行操作，但缺乏可解释性且需要大量数据集。基于规则的模型符合专家知识，但未全面考虑所有球员的状态。本研究探讨低维、基于规则的方法是否可以通过时空数据有效地捕捉足球战术。我们的方法基于传递选项等标准定义了可解释的状态变量，不仅包括持球者还涉及潜在传球接收者。通过与一名教练的讨论，我们确定了代表比赛状态的关键变量。我们使用2023-24赛季西甲联赛的StatsBomb事件数据和SkillCorner跟踪数据训练了一个XGBoost模型来预测传球成功率。分析结果显示，球员与球之间的距离以及球员的空间得分是决定成功传球的关键因素。我们的可解释低维建模通过使用直观变量促进战术分析，并作为一种支持足球决策的实用工具提供了实际价值。', 'title_zh': '足球战术中基于时空代理状态的可解释低维建模决策方法'}
{'arxiv_id': 'arXiv:2506.16617', 'title': 'The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring', 'authors': 'Soobin Chae, Suhwan Lee, Hanna Hauptmann, Hajo A. Reijers, Xixi Lu', 'link': 'https://arxiv.org/abs/2506.16617', 'abstract': "Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.", 'abstract_zh': '解释性人工智能在过程监控中的解释样式和感知AI准确度对决策的影响研究', 'title_zh': '解释风格和感知准确性在预测过程监控中决策制定的作用'}
{'arxiv_id': 'arXiv:2506.16596', 'title': 'A Community-driven vision for a new Knowledge Resource for AI', 'authors': 'Vinay K Chaudhri, Chaitan Baru, Brandon Bennett, Mehul Bhatt, Darion Cassel, Anthony G Cohn, Rina Dechter, Esra Erdem, Dave Ferrucci, Ken Forbus, Gregory Gelfond, Michael Genesereth, Andrew S. Gordon, Benjamin Grosof, Gopal Gupta, Jim Hendler, Sharat Israni, Tyler R. Josephson, Patrick Kyllonen, Yuliya Lierler, Vladimir Lifschitz, Clifton McFate, Hande K. McGinty, Leora Morgenstern, Alessandro Oltramari, Praveen Paritosh, Dan Roth, Blake Shepard, Cogan Shimzu, Denny Vrandečić, Mark Whiting, Michael Witbrock', 'link': 'https://arxiv.org/abs/2506.16596', 'abstract': 'The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.', 'abstract_zh': '持久的目标：构建一个综合性的多用途知识资源——类似于1984年的Cyc项目——在AI领域仍然存在。尽管有WordNet、ConceptNet、Wolfram|Alpha及其他商业知识图谱的成功，可验证的、通用的广泛应用的知识来源仍然是AI基础设施中的关键不足。大型语言模型由于知识空白而受到影响；机器人规划缺乏必要的世界知识；而事实错误信息的检测则高度依赖人类专家。当前最需要什么样的知识资源？现代技术如何塑造其发展和评估？最近的AAAI研讨会汇集了超过50名研究人员探讨这些问题。本文综合了我们的研究成果，并阐述了一个由社区驱动的新知识基础设施愿景。除了利用知识表示和推理的当代进展，一个有希望的想法是构建一个开放的工程框架，以有效地在实际应用中利用知识模块。这样的框架应该包括贡献者采纳的一套约定和社交结构。', 'title_zh': '社区驱动的关于新AI知识资源的愿景'}
{'arxiv_id': 'arXiv:2506.16429', 'title': 'Agentic Personalisation of Cross-Channel Marketing Experiences', 'authors': 'Sami Abboud, Eleanor Hanna, Olivier Jeunen, Vineesha Raheja, Schaun Wheeler', 'link': 'https://arxiv.org/abs/2506.16429', 'abstract': 'Consumer applications provide ample opportunities to surface and communicate various forms of content to users. From promotional campaigns for new features or subscriptions, to evergreen nudges for engagement, or personalised recommendations; across e-mails, push notifications, and in-app surfaces. The conventional approach to orchestration for communication relies heavily on labour-intensive manual marketer work, and inhibits effective personalisation of content, timing, frequency, and copy-writing. We formulate this task under a sequential decision-making framework, where we aim to optimise a modular decision-making policy that maximises incremental engagement for any funnel event. Our approach leverages a Difference-in-Differences design for Individual Treatment Effect estimation, and Thompson sampling to balance the explore-exploit trade-off. We present results from a multi-service application, where our methodology has resulted in significant increases to a variety of goal events across several product features, and is currently deployed across 150 million users.', 'abstract_zh': '消费者应用提供了展示和传达各种类型内容给用户的充足机会。从新功能或订阅的推广活动，到持续的参与提示，或是个性化推荐；这些都通过电子邮件、推送通知以及应用内界面实现。传统的 communication 调度方法依赖于劳动密集型的手动营销工作，限制了内容的个性化、时机、频次和文案优化。我们将这一任务构建成一个序列决策框架，目标是优化模块化决策策略，以最大化漏斗事件的增量参与度。我们的方法利用 Difference-in-Differences 设计估计个体治疗效应，并采用 Thompson 抽样平衡探索与利用的 trade-off。我们展示了一个多服务应用的结果，其中我们的方法在多个产品功能中显著提高了各种目标事件，并已部署给超过 1.5 亿用户。', 'title_zh': '渠道营销体验的主动个性化'}
{'arxiv_id': 'arXiv:2506.16294', 'title': 'Approximation Fixpoint Theory with Refined Approximation Spaces', 'authors': 'Linde Vanbesien, Bart Bogaerts, Marc Denecker', 'link': 'https://arxiv.org/abs/2506.16294', 'abstract': 'Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.', 'abstract_zh': 'Approximation Fixpoint Theory拓展至处理比区间更精细的近似', 'title_zh': '精细近似空间的近似定点理论'}
{'arxiv_id': 'arXiv:2506.16144', 'title': 'Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction', 'authors': 'Ana Kostovska, Carola Doerr, Sašo Džeroski, Panče Panov, Tome Eftimov', 'link': 'https://arxiv.org/abs/2506.16144', 'abstract': 'Automated algorithm performance prediction in numerical blackbox optimization often relies on problem characterizations, such as exploratory landscape analysis features. These features are typically used as inputs to machine learning models and are represented in a tabular format. However, such approaches often overlook algorithm configurations, a key factor influencing performance. The relationships between algorithm operators, parameters, problem characteristics, and performance outcomes form a complex structure best represented as a graph. This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.', 'abstract_zh': '基于数值黑盒优化的自动算法性能预测往往依赖于问题表征，如探索性景观分析特征。这些特征通常作为机器学习模型的输入，并以表格格式表示。然而，这些方法往往忽略了算法配置这一关键因素，而算法配置对性能有着重要影响。算法操作符、参数、问题特征与性能结果之间的关系形成一个复杂结构，最好用图来表示。本文探讨了使用异构图数据结构和图神经网络预测优化算法性能的方法，通过捕捉问题、算法配置和性能结果之间的复杂依赖关系。我们专注于两个模块化框架modCMA-ES和modDE，分别分解了两种广泛使用的无导数优化算法：共变异矩阵演化策略（CMA-ES）和差分演化（DE）。我们在六种运行时预算和两种问题维度下，对24个BBOB问题的324个modCMA-ES变体和576个modDE变体进行了评估。与传统的基于表格的方法相比，本研究在均方误差方面实现了高达36.6%的改进，突显了几何学习在黑盒优化中的潜力。', 'title_zh': '黑盒优化中的几何学习：基于GNN的算法性能预测框架'}
{'arxiv_id': 'arXiv:2506.16087', 'title': 'Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies', 'authors': 'Tom Jeleniewski, Hamied Nabizada, Jonathan Reif, Felix Gehlhoff, Alexander Fay', 'link': 'https://arxiv.org/abs/2506.16087', 'abstract': 'The formalization of process knowledge using ontologies enables consistent modeling of parameter interdependencies in manufacturing. These interdependencies are typically represented as mathematical expressions that define relations between process parameters, supporting tasks such as calculation, validation, and simulation. To support cross-context application and knowledge reuse, such expressions are often defined in a generic form and applied across multiple process contexts. This highlights the necessity of a consistent and semantically coherent model to ensure the correctness of data retrieval and interpretation. Consequently, dedicated mechanisms are required to address key challenges such as selecting context-relevant data, ensuring unit compatibility between variables and data elements, and verifying the completeness of input data required for evaluating mathematical expressions. This paper presents a set of verification mechanisms for a previously developed ontology-based process model that integrates standardized process semantics, data element definitions, and formal mathematical constructs. The approach includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a unit consistency check based on expected-unit annotations and semantic classification, and (iii) a data completeness check to validate the evaluability of interdependencies. The applicability of the approach is demonstrated with a use case from Resin Transfer Molding (RTM), supporting the development of machine-interpretable and verifiable engineering models.', 'abstract_zh': '使用本体形式化过程知识以实现制造中参数交互依赖性的一致建模。这些交互依赖性通常以数学表达式的形式表示，定义过程参数之间的关系，支持计算、验证和仿真等任务。为了支持跨上下文应用和知识重用，这些表达式通常以通用形式定义并在多个过程上下文中应用。这突显出需要一致且语义上连贯的模型以确保数据检索和解释的正确性。因此，需要专门的机制来解决关键挑战，如选择上下文相关数据、确保变量和数据元素之间的单位兼容性以及验证用于评估数学表达式所需的输入数据完整性。本文提出了一组验证机制，用于一个新的本体基于过程模型，该模型整合了标准化的过程语义、数据元素定义和形式化数学构造。该方法包括基于SPARQL的过滤以检索过程相关数据、基于预期单位注释和语义分类的单位一致性检查以及数据完整性检查以验证依赖性的可评估性。该方法的应用通过树脂传递模塑（RTM）使用案例得到验证，支持机器可解析和可验证的工程模型的开发。', 'title_zh': '基于参数依赖性的本体驱动过程模型中的一致性验证'}
{'arxiv_id': 'arXiv:2506.16042', 'title': 'OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents', 'authors': 'Reyna Abhyankar, Qi Qi, Yiying Zhang', 'link': 'https://arxiv.org/abs/2506.16042', 'abstract': 'Generative AI is being leveraged to solve a variety of computer-use tasks involving desktop applications. State-of-the-art systems have focused solely on improving accuracy on leading benchmarks. However, these systems are practically unusable due to extremely high end-to-end latency (e.g., tens of minutes) for tasks that typically take humans just a few minutes to complete. To understand the cause behind this and to guide future developments of computer agents, we conduct the first study on the temporal performance of computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We find that large model calls for planning and reflection account for the majority of the overall latency, and as an agent uses more steps to complete a task, each successive step can take 3x longer than steps at the beginning of a task. We then construct OSWorld-Human, a manually annotated version of the original OSWorld dataset that contains a human-determined trajectory for each task. We evaluate 16 agents on their efficiency using OSWorld-Human and found that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than necessary.', 'abstract_zh': '生成式AI正被用于解决涉及桌面应用程序的各种计算机使用任务。尽管最先进的系统专注于在领先基准上的准确性改进，但由于执行任务的端到端延迟极高（例如，数十分钟），这些系统在实际操作中几乎无法使用，而人类通常只需几分钟即可完成这些任务。为了理解背后的原因并指导计算机代理的未来发展，我们在OSWorld上进行了首个计算机使用代理的时序性能研究，OSWorld是计算机使用AI领域的旗舰基准。我们发现，大规模模型在规划和反思上的调用占据了整体延迟的主要部分，随着代理完成任务的步骤增加，每个后续步骤可能比任务初始步骤耗时长3倍。然后，我们构建了OSWorld-Human，这是原始OSWorld数据集的手工注释版本，包含每个任务的人类确定轨迹。我们使用OSWorld-Human评估了16个代理的效率，并发现即使在OSWorld上得分最高的代理也需要比必要步骤多1.4-2.7倍的步骤。', 'title_zh': 'OSWorld-Human: 评估计算机使用代理的效率'}
{'arxiv_id': 'arXiv:2506.16016', 'title': 'Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations', 'authors': 'William Sharpless, Dylan Hirsch, Sander Tonkens, Nikhil Shinde, Sylvia Herbert', 'link': 'https://arxiv.org/abs/2506.16016', 'abstract': 'Hard constraints in reinforcement learning (RL), whether imposed via the reward function or the model architecture, often degrade policy performance. Lagrangian methods offer a way to blend objectives with constraints, but often require intricate reward engineering and parameter tuning. In this work, we extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to propose two novel value functions for dual-objective satisfaction. Namely, we address: (1) the Reach-Always-Avoid problem - of achieving distinct reward and penalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds of two distinct rewards. In contrast with temporal logic approaches, which typically involve representing an automaton, we derive explicit, tractable Bellman forms in this context by decomposing our problem into reach, avoid, and reach-avoid problems, as to leverage these aforementioned recent advances. From a mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are complementary and fundamentally different from standard sum-of-rewards problems and temporal logic problems, providing a new perspective on constrained decision-making. We leverage our analysis to propose a variation of Proximal Policy Optimization (DO-HJ-PPO), which solves these problems. Across a range of tasks for safe-arrival and multi-target achievement, we demonstrate that DO-HJ-PPO produces qualitatively distinct behaviors from previous approaches and out-competes a number of baselines in various metrics.', 'abstract_zh': '强化学习中的硬约束及其解决方法：从Hamilton-Jacobi方程到DO-HJ-PPO', 'title_zh': '具有新颖哈密顿-雅可比-贝尔曼形式的双目标强化学习'}
{'arxiv_id': 'arXiv:2506.16015', 'title': 'Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning', 'authors': 'Craig S. Wright', 'link': 'https://arxiv.org/abs/2506.16015', 'abstract': 'The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.', 'abstract_zh': '科学文献的指数增长已经超越了人类专家和当前人工智能系统的知识处理能力。本文介绍了一种正式结构化的架构——带权重权威的贝叶斯 epistemology (BEWA)，该架构将信念形式化为在结构化科学主张上的动态、概率一致函数。每项主张都被置位上下文、作者归属，并通过复制评分、引用权重和时间衰减的系统进行评估。信念更新通过证据条件下的贝叶斯推断、矛盾处理以及 epistemic 衰减机制来实现。该架构支持基于图的主张传播、作者可信度建模、加密锚定以及零知识审计验证。通过将科学推理形式化为可计算验证的 epistemic 网络，BEWA 推进了促进真实效用、理性信念汇聚以及在动态科学领域具有审计抗性的完备性的机器推理系统的基础。', 'title_zh': '加权权威下的贝叶斯认识论：一种促进真理自主科学研究的正式架构'}
{'arxiv_id': 'arXiv:2506.15774', 'title': 'Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints', 'authors': 'J. Schwardt, J. C. Budich', 'link': 'https://arxiv.org/abs/2506.15774', 'abstract': 'We introduce and benchmark a stochastic local search heuristic for the NP-complete satisfiability problem 3-SAT that drastically outperforms existing solvers in the notoriously difficult realm of critically hard instances. Our construction is based on the crucial observation that well established previous approaches such as WalkSAT are prone to get stuck in local minima that are distinguished from true solutions by a larger number of oversatisfied combinatorial constraints. To address this issue, the proposed algorithm, coined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their unfavorable abundance so as to render them critical. We analyze and benchmark our algorithm on a randomly generated sample of hard but satisfiable 3-SAT instances with varying problem sizes up to N=15000. Quite remarkably, we find that DOCSAT outperforms both WalkSAT and other well known algorithms including the complete solver Kissat, even when comparing its ability to solve the hardest quintile of the sample to the average performance of its competitors. The essence of DOCSAT may be seen as a way of harnessing statistical structure beyond the primary cost function of a combinatorial problem to avoid or escape local minima traps in stochastic local search, which opens avenues for generalization to other optimization problems.', 'abstract_zh': '我们介绍并评估了一种用于NP完全可满足性问题3-SAT的随机局部搜索启发式算法，该算法在最难的实例中显著超越了现有的求解器。我们提出的算法DOCSAT通过减少过度满足的约束条件（DOC）来摆脱局部极小值陷阱，从而提高了性能。我们在随机生成的、具有不同规模的hard但可满足的3-SAT实例上分析和评估了DOCSAT算法，发现DOCSAT不仅在处理最难的实例方面表现出色，甚至在解决最难的五分之一实例的能力上也超过了包括完整求解器Kissat在内的其他知名算法。DOCSAT的核心思想在于利用组合问题主要成本函数之外的统计结构来避免或脱离局部极小值陷阱，这为进一步将该方法推广到其他优化问题开辟了途径。', 'title_zh': '通过减少过满意约束来提升随机3-SAT求解器的性能'}
{'arxiv_id': 'arXiv:2506.15758', 'title': 'Linear-Time Primitives for Algorithm Development in Graphical Causal Inference', 'authors': 'Marcel Wienöbst, Sebastian Weichwald, Leonard Henckel', 'link': 'https://arxiv.org/abs/2506.15758', 'abstract': "We introduce CIfly, a framework for efficient algorithmic primitives in graphical causal inference that isolates reachability as a reusable core operation. It builds on the insight that many causal reasoning tasks can be reduced to reachability in purpose-built state-space graphs that can be constructed on the fly during traversal. We formalize a rule table schema for specifying such algorithms and prove they run in linear time. We establish CIfly as a more efficient alternative to the common primitives moralization and latent projection, which we show are computationally equivalent to Boolean matrix multiplication. Our open-source Rust implementation parses rule table text files and runs the specified CIfly algorithms providing high-performance execution accessible from Python and R. We demonstrate CIfly's utility by re-implementing a range of established causal inference tasks within the framework and by developing new algorithms for instrumental variables. These contributions position CIfly as a flexible and scalable backbone for graphical causal inference, guiding algorithm development and enabling easy and efficient deployment.", 'abstract_zh': '我们介绍了CIfly框架，这是一种用于图形因果推理的高效算法基础构件框架，将可达性隔离为可重用的核心操作。该框架基于一个见解，即许多因果推理任务可以被归约为主为特定目的而构建的状态空间图中的可达性问题，这些图可以在遍历过程中即席构建。我们为指定此类算法定义了一个规则表模式，并证明它们可以在线性时间内运行。我们确立CIfly作为比常用的道德化和潜在投影等基本构件更高效的替代方案，我们证明这些基本构件在计算上等价于布尔矩阵乘法。我们的开源Rust实现解析规则表文本文件，并运行指定的CIfly算法，提供从Python和R访问的高性能执行。通过在框架内重新实现一系列已建立的因果推理任务，并开发新的工具变量算法，我们展示了CIfly的实用性。这些贡献将CIfly定位为图形因果推理的灵活且可扩展的基础架构，指导算法开发，并使部署更加容易和高效。', 'title_zh': '图形因果推断中线性时间原语的算法开发'}
{'arxiv_id': 'arXiv:2506.17204', 'title': 'Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning', 'authors': 'Guozheng Ma, Lu Li, Zilin Wang, Li Shen, Pierre-Luc Bacon, Dacheng Tao', 'link': 'https://arxiv.org/abs/2506.17204', 'abstract': 'Effectively scaling up deep reinforcement learning models has proven notoriously difficult due to network pathologies during training, motivating various targeted interventions such as periodic reset and architectural advances such as layer normalization. Instead of pursuing more complex modifications, we show that introducing static network sparsity alone can unlock further scaling potential beyond their dense counterparts with state-of-the-art architectures. This is achieved through simple one-shot random pruning, where a predetermined percentage of network weights are randomly removed once before training. Our analysis reveals that, in contrast to naively scaling up dense DRL networks, such sparse networks achieve both higher parameter efficiency for network expressivity and stronger resistance to optimization challenges like plasticity loss and gradient interference. We further extend our evaluation to visual and streaming RL scenarios, demonstrating the consistent benefits of network sparsity.', 'abstract_zh': '仅通过引入静态网络稀疏性即可超越密集模型解锁先进架构下的进一步扩展潜力：通过一次性随机剪枝实现网络表达性和优化挑战抵抗力的提升', 'title_zh': '网络稀疏性解锁了深度强化学习的扩展潜力'}
{'arxiv_id': 'arXiv:2506.17169', 'title': 'Continual Learning with Columnar Spiking Neural Networks', 'authors': 'Denis Larionov, Nikolay Bazenkov, Mikhail Kiselev', 'link': 'https://arxiv.org/abs/2506.17169', 'abstract': 'This study investigates columnar-organized spiking neural networks (SNNs) for continual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered Network), we show that microcolumns adapt most efficiently to new tasks when they lack shared structure with prior learning. We demonstrate how CoLaNET hyperparameters govern the trade-off between retaining old knowledge (stability) and acquiring new information (plasticity). Our optimal configuration learns ten sequential MNIST tasks effectively, maintaining 92% accuracy on each. It shows low forgetting, with only 4% performance degradation on the first task after training on nine subsequent tasks.', 'abstract_zh': '本研究考察了柱状组织的脉冲神经网络（SNN）在连续学习和灾难性遗忘方面的应用。通过使用CoLaNET（柱状分层网络），我们展示了当微柱状结构与先前学习缺乏共性时，它们能够最有效地适应新任务。我们展示了CoLaNET超参数如何控制保持旧知识（稳定性和获取新信息（可塑性）之间的权衡。最优配置能够有效地学习十个连续的MNIST任务，在每个任务上保持92%的准确率，同时显示出低遗忘率，在接受九个后续任务训练后，第一任务的性能仅下降4%。', 'title_zh': '基于列式脉冲神经网络的持续学习'}
{'arxiv_id': 'arXiv:2506.17155', 'title': 'Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity', 'authors': 'Samin Yeasar Arnob, Scott Fujimoto, Doina Precup', 'link': 'https://arxiv.org/abs/2506.17155', 'abstract': 'In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce "Sparse-Reg": a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.', 'abstract_zh': '在本论文中，我们探讨了小数据集在离线强化学习（RL）中的应用。虽然许多常见的离线RL基准使用包含超过一百万个数据点的大型数据集，但许多离线RL应用依赖于更小的数据集。我们展示了离线RL算法在小数据集上容易过拟合，导致性能不佳。为了解决这一挑战，我们提出了“Sparse-Reg”：一种基于稀疏性的正则化技术，用于减轻离线强化学习中的过拟合问题，使其在有限数据环境中有效学习，并在连续控制任务中优于现有最佳基线。', 'title_zh': 'Sparse-Reg: 在离线强化学习中利用稀疏性提高样本复杂性'}
{'arxiv_id': 'arXiv:2506.17140', 'title': 'MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification', 'authors': 'David Jacob Drexlin, Jonas Dippel, Julius Hense, Niklas Prenißl, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller', 'link': 'https://arxiv.org/abs/2506.17140', 'abstract': 'Deep learning models have made significant advances in histological prediction tasks in recent years. However, for adaptation in clinical practice, their lack of robustness to varying conditions such as staining, scanner, hospital, and demographics is still a limiting factor: if trained on overrepresented subpopulations, models regularly struggle with less frequent patterns, leading to shortcut learning and biased predictions. Large-scale foundation models have not fully eliminated this issue. Therefore, we propose a novel approach explicitly modeling such metadata into a Metadata-guided generative Diffusion model framework (MeDi). MeDi allows for a targeted augmentation of underrepresented subpopulations with synthetic data, which balances limited training data and mitigates biases in downstream models. We experimentally show that MeDi generates high-quality histopathology images for unseen subpopulations in TCGA, boosts the overall fidelity of the generated images, and enables improvements in performance for downstream classifiers on datasets with subpopulation shifts. Our work is a proof-of-concept towards better mitigating data biases with generative models.', 'abstract_zh': '深度学习模型在最近几年显著推进了组织学预测任务，但在临床实践中，它们对不同染色、扫描仪、医院和人口统计等因素变化的鲁棒性不足仍然是一个限制因素：如果训练数据主要来自过度代表的亚人群，模型往往会难以处理较少见的模式，导致捷径学习和有偏预测。大规模的基础模型尚未完全解决这一问题。因此，我们提出了一种显式将元数据建模到元数据指导生成扩散模型框架（MeDi）中的新方法。MeDi 允许有针对性地使用合成数据扩充欠代表的亚人群，从而平衡有限的训练数据并减轻下游模型中的偏差。实验结果显示，MeDi 能够为 TCGA 中未见过的亚人群生成高质量的病理图像，提升生成图像的整体保真度，并在亚人群转移的数据集上改进下游分类器的性能。我们的工作是一个使用生成模型更好地减轻数据偏差的可行性研究。', 'title_zh': 'MeDi: 元数据引导的扩散模型用于减轻肿瘤分类中的偏差'}
{'arxiv_id': 'arXiv:2506.17139', 'title': 'Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models', 'authors': 'Michael Plainer, Hao Wu, Leon Klein, Stephan Günnemann, Frank Noé', 'link': 'https://arxiv.org/abs/2506.17139', 'abstract': "Diffusion models have recently gained significant attention due to their effectiveness in various scientific domains, including biochemistry. When trained on equilibrium molecular distributions, diffusion models provide both: a generative procedure to sample equilibrium conformations and associated forces derived from the model's scores. However, using the forces for coarse-grained molecular dynamics simulations uncovers inconsistencies in the samples generated via classical diffusion inference and simulation, despite both originating from the same model. Particularly at the small diffusion timesteps required for simulations, diffusion models fail to satisfy the Fokker-Planck equation, which governs how the score should evolve over time. We interpret this deviation as an indication of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term enforcing consistency. We demonstrate the effectiveness of our approach on toy systems, alanine dipeptide, and introduce a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and demonstrates enhanced consistency and efficient sampling.", 'abstract_zh': '扩散模型由于在各种科学领域中的有效性，特别是在生物化学领域，最近引起了广泛关注。当这些模型在平衡分子分布上进行训练时，它们能够提供生成 equilibrium 贝叶斯构象和从模型得分中推导出的力的生成程序。然而，在使用这些力进行粗粒化分子动力学模拟时，尽管这些样本和经典扩散推断与模拟都源自同一模型，仍然发现了不一致之处。特别地，在模拟所需的较小扩散时间步长下，扩散模型未能满足由 Fokker-Planck 方程所控制的得分随时间的演变方式。我们将这一偏差视为观察到不一致性的指示，并提出一种基于 Fokker-Planck 方程的正则化项的能量扩散模型以确保一致性。我们通过玩具系统、丙氨酸二肽的实例以及引入一种最先进的可转移的二肽玻尔兹曼模拟器，展示了该方法的有效性，并证实了其增强的一致性和高效的采样能力。', 'title_zh': '一致采样与模拟：基于能量的扩散模型分子动力学'}
{'arxiv_id': 'arXiv:2506.17133', 'title': 'Robust Training with Data Augmentation for Medical Imaging Classification', 'authors': 'Josué Martínez-Martínez, Olivia Brown, Mostafa Karami, Sheida Nabavi', 'link': 'https://arxiv.org/abs/2506.17133', 'abstract': 'Deep neural networks are increasingly being used to detect and diagnose medical conditions using medical imaging. Despite their utility, these models are highly vulnerable to adversarial attacks and distribution shifts, which can affect diagnostic reliability and undermine trust among healthcare professionals. In this study, we propose a robust training algorithm with data augmentation (RTDA) to mitigate these vulnerabilities in medical image classification. We benchmark classifier robustness against adversarial perturbations and natural variations of RTDA and six competing baseline techniques, including adversarial training and data augmentation approaches in isolation and combination, using experimental data sets with three different imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that RTDA achieves superior robustness against adversarial attacks and improved generalization performance in the presence of distribution shift in each image classification task while maintaining high clean accuracy.', 'abstract_zh': '深度神经网络在医疗影像中检测和诊断医疗条件的应用日益增多。尽管这些模型非常有用，但它们对对抗攻击和分布偏移的高度脆弱性会影响诊断可靠性并削弱医务人员的信任。在本研究中，我们提出了一种结合数据增强的鲁棒训练算法（RTDA）以减轻医学图像分类中的这些脆弱性。我们使用包含三种不同成像技术（乳腺X射线、X光片和超声波）的实验数据集，将RTDA与六种竞争基准技术（包括单独和组合的对抗训练和数据增强方法）的分类器鲁棒性进行了基准测试。结果显示，RTDA在每项图像分类任务中均能实现对抗攻击下的优越鲁棒性和分布偏移情况下的改进泛化性能，同时保持较高的准确率。', 'title_zh': '基于数据增强的医学影像分类稳健训练'}
{'arxiv_id': 'arXiv:2506.17128', 'title': 'Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model', 'authors': 'Botao Zhu, Xianbin Wang', 'link': 'https://arxiv.org/abs/2506.17128', 'abstract': "Trust is emerging as an effective tool to ensure the successful completion of collaborative tasks within collaborative systems. However, rapidly and continuously evaluating the trustworthiness of collaborators during task execution is a significant challenge due to distributed devices, complex operational environments, and dynamically changing resources. To tackle this challenge, this paper proposes a Siamese-enabled rapid and continuous trust evaluation framework (SRCTE) to facilitate effective task collaboration. First, the communication and computing resource attributes of the collaborator in a trusted state, along with historical collaboration data, are collected and represented using an attributed control flow graph (ACFG) that captures trust-related semantic information and serves as a reference for comparison with data collected during task execution. At each time slot of task execution, the collaborator's communication and computing resource attributes, as well as task completion effectiveness, are collected in real time and represented with an ACFG to convey their trust-related semantic information. A Siamese model, consisting of two shared-parameter Structure2vec networks, is then employed to learn the deep semantics of each pair of ACFGs and generate their embeddings. Finally, the similarity between the embeddings of each pair of ACFGs is calculated to determine the collaborator's trust value at each time slot. A real system is built using two Dell EMC 5200 servers and a Google Pixel 8 to test the effectiveness of the proposed SRCTE framework. Experimental results demonstrate that SRCTE converges rapidly with only a small amount of data and achieves a high anomaly trust detection rate compared to the baseline algorithm.", 'abstract_zh': '基于双路网络的快速连续信任评估框架(SRCTE)以促进有效协作任务的完成', 'title_zh': '通过双胞胎模型实现的有效任务协作的快速连续信任评估'}
{'arxiv_id': 'arXiv:2506.17093', 'title': 'Identifiability of Deep Polynomial Neural Networks', 'authors': 'Konstantin Usevich, Clara Dérand, Ricardo Borsoi, Marianne Clausel', 'link': 'https://arxiv.org/abs/2506.17093', 'abstract': "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability -- a key property for ensuring interpretability -- remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. This yields both generic conditions determined by the architecture, and effective conditions that depend on the network's parameters. We also settle an open conjecture on the expected dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach its maximum.", 'abstract_zh': '多项式神经网络（PNNs）具有丰富的代数和几何结构。然而，它们的可识别性——这一确保可解释性的重要性质——至今尚未得到充分理解。在本文中，我们对深层PNNs的可识别性进行了全面分析，包括包含和不包含 bias 项的架构。我们的结果揭示了激活阶数和层宽之间实现可识别性的一种复杂的相互作用。作为特殊情况，我们展示了在轻微条件下，具有非递增层宽的架构是通用可识别的，而编码-解码网络在解码器宽度不快速增长时是可识别的。我们的证明是构造性的，并集中在深层PNNs与低秩张量分解之间的联系以及Kruskal型唯一性定理上。这既提供了由架构决定的通用条件，也提供了依赖于网络参数的有效条件。我们还解决了PNN神经簇体的预期维数的一个公开猜想，并提供了达到最大值所需的激活阶数的新界。', 'title_zh': '深度多项式神经网络的可 identifiability'}
{'arxiv_id': 'arXiv:2506.17065', 'title': 'Flow-Based Non-stationary Temporal Regime Causal Structure Learning', 'authors': 'Abdellah Rahmani, Pascal Frossard', 'link': 'https://arxiv.org/abs/2506.17065', 'abstract': "Understanding causal relationships in multivariate time series is crucial in many scenarios, such as those dealing with financial or neurological data. Many such time series exhibit multiple regimes, i.e., consecutive temporal segments with a priori unknown boundaries, with each regime having its own causal structure. Inferring causal dependencies and regime shifts is critical for analyzing the underlying processes. However, causal structure learning in this setting is challenging due to (1) non stationarity, i.e., each regime can have its own causal graph and mixing function, and (2) complex noise distributions, which may be non Gaussian or heteroscedastic. Existing causal discovery approaches cannot address these challenges, since generally assume stationarity or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified framework for causal discovery that handles non stationary processes along with non Gaussian and heteroscedastic noises. FANTOM simultaneously infers the number of regimes and their corresponding indices and learns each regime's Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm that maximizes the evidence lower bound of the data log likelihood. On the theoretical side, we prove, under mild assumptions, that temporal heteroscedastic causal models, introduced in FANTOM's formulation, are identifiable in both stationary and non stationary settings. In addition, extensive experiments on synthetic and real data show that FANTOM outperforms existing methods.", 'abstract_zh': '理解多变量时间序列中的因果关系在许多场景中至关重要，例如金融或神经数据领域。这类时间序列常常包含多个制度，即具有先前未知边界的连续时间段，每个制度具有自己的因果结构。推断因果依赖性和制度转换对于分析潜在过程至关重要。然而，在这种场景下的因果结构学习具有挑战性，原因在于（1）非平稳性，即每个制度可以有自己的因果图和混合函数，以及（2）复杂的噪声分布，可能会是非正态分布或异方差的。现有的因果发现方法无法解决这些挑战，因为它们通常假定平稳性或具有恒定方差的高斯噪声。因此，我们引入了FANTOM，这是一种统一的框架，可以处理非平稳过程以及非正态和异方差的噪声。FANTOM同时推断制度的数量及其相应的索引，并学习每个制度的有向无环图。它使用最大化数据对数似然证据下界的贝叶斯期望最大化算法。在理论上，我们证明，在温和假设下，FANTOM公式中引入的时间异方差因果模型在平稳和非平稳设置中是可辨识的。此外，对合成数据和真实数据的广泛实验表明，FANTOM优于现有方法。', 'title_zh': '基于流的方法非平稳时间动态度量因果结构学习'}
{'arxiv_id': 'arXiv:2506.17041', 'title': 'MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection', 'authors': 'Joshua Schraven, Alexander Windmann, Oliver Niggemann', 'link': 'https://arxiv.org/abs/2506.17041', 'abstract': "Benchmark datasets for network intrusion detection commonly rely on synthetically generated traffic, which fails to reflect the statistical variability and temporal drift encountered in operational environments. This paper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1 dataset, designed to enable realistic and reproducible evaluation of anomaly detection methods. A reproducible preprocessing pipeline is presented that transforms raw packet captures into flow representations conforming to the CICFlowMeter format, while preserving MAWILab's original anomaly labels. The resulting datasets comprise temporally distinct samples from January 2011, 2016, and 2021, drawn from trans-Pacific backbone traffic.\nTo establish reference baselines, traditional machine learning methods, including Decision Trees, Random Forests, XGBoost, and Logistic Regression, are compared to a deep learning model based on a CNN-BiLSTM architecture. Empirical results demonstrate that tree-based classifiers perform well on temporally static data but experience significant performance degradation over time. In contrast, the CNN-BiLSTM model maintains better performance, thus showing improved generalization. These findings underscore the limitations of synthetic benchmarks and static models, and motivate the adoption of realistic datasets with explicit temporal structure. All datasets, pipeline code, and model implementations are made publicly available to foster transparency and reproducibility.", 'abstract_zh': '基于MAWILAB v1.1数据集的MAWIFlow流基准：一种用于异常检测方法的现实和可重复评估的数据集', 'title_zh': 'MAWIFlow基准：基于流的网络入侵检测的现实评价'}
{'arxiv_id': 'arXiv:2506.17039', 'title': 'LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation', 'authors': 'Elizabeth Fons, Alejandro Sztrajman, Yousef El-Laham, Luciana Ferrer, Svitlana Vyetrenko, Manuela Veloso', 'link': 'https://arxiv.org/abs/2506.17039', 'abstract': 'Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data. We integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. Experiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.', 'abstract_zh': '缺失或不规则采样时间序列是机器学习中的一个持久挑战。许多方法依赖于傅里叶频域，依赖于快速傅里叶变换（FFT），该变换假设均匀采样，因此需要先行内插，这可能会扭曲频谱。为解决这一局限，我们引入了一个可微的Lomb--Scargle层，使得不规则采样数据的功率谱计算更加可靠。我们将这一层整合到一种新型基于得分的扩散模型（LSCD）中，用于整个信号频谱条件下的时间序列插补。在合成和真实世界基准上的实验表明，我们的方法比单纯的时域基线更准确地恢复了缺失数据，同时生成一致的频率估计。尤为重要的是，我们的方法可以轻松地集成到学习框架中，从而在涉及不完整或不规则数据的机器学习方法中更广泛地采用频谱指导。', 'title_zh': 'LSCD: Lomb-Scargle条件下的扩散时间序列插补'}
{'arxiv_id': 'arXiv:2506.17019', 'title': 'Instituto de Telecomunicações at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning', 'authors': 'Giuseppe Attanasio, Sonal Sannigrahi, Ben Peters, André F. T. Martins', 'link': 'https://arxiv.org/abs/2506.17019', 'abstract': 'This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on Instruction Following Speech Processing. We submit results for the Short Track, i.e., speech recognition, translation, and spoken question answering. Our model is a unified speech-to-text model that integrates a pre-trained continuous speech encoder and text decoder through a first phase of modality alignment and a second phase of instruction fine-tuning. Crucially, we focus on using small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY data along with synthetic data generation to supplement existing resources.', 'abstract_zh': '本文介绍了我们提交给2025年IWSLT共享任务的IT-IST参赛作品，该任务聚焦于指令跟随语音处理。我们提交了短赛道的结果，即语音识别、翻译和语音问答。我们的模型是一种统一的从语音到文本的模型，通过两个阶段——模态对齐和指令微调——将预训练的连续语音编码器和文本解码器进行整合。 crucial的是，我们专注于使用小规模的语言模型骨干网（<2B）并在高质CC-BY数据的基础上结合合成数据生成以补充现有资源。', 'title_zh': 'Instituto de Telecomunicações 在 IWSLT 2025：优化小型语音和语言模型实现语音转文本学习'}
{'arxiv_id': 'arXiv:2506.16971', 'title': 'Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)', 'authors': 'Oliver Schön, Sofie Haesaert, Sadegh Soudjani', 'link': 'https://arxiv.org/abs/2506.16971', 'abstract': 'The requirement for identifying accurate system representations has not only been a challenge to fulfill, but it has compromised the scalability of formal methods, as the resulting models are often too complex for effective decision making with formal correctness and performance guarantees. Focusing on probabilistic simulation relations and surrogate models of stochastic systems, we propose an approach that significantly enhances the scalability and practical applicability of such simulation relations by eliminating the need to compute error bounds directly. As a result, we provide an abstraction-based technique that scales effectively to higher dimensions while addressing complex nonlinear agent-environment interactions with infinite-horizon temporal logic guarantees amidst uncertainty. Our approach trades scalability for conservatism favorably, as demonstrated on a complex high-dimensional vehicle intersection case study.', 'abstract_zh': '识别准确系统表示的要求不仅是一项挑战，还削弱了形式方法的扩展性，因为生成的模型往往过于复杂，无法确保有效的决策制定并保证性能。针对随机系统的概率仿真关系和代理模型，我们提出了一种方法，通过消除直接计算误差界的需求，显著增强了此类仿真关系的扩展性和实用性。由此，我们提供了一种基于抽象的技术，可以在高维空间中有效扩展，并在不确定性下利用无限_horizon 时间逻辑保证处理复杂的非线性代理-环境交互。我们的方法在可扩展性和保守性之间进行了有利的权衡，如在复杂高维车辆交叉口案例研究中所示。', 'title_zh': '基于合同的概率代理模型的不确定性系统形式控制（扩展版）'}
{'arxiv_id': 'arXiv:2506.16929', 'title': 'A deep learning and machine learning approach to predict neonatal death in the context of São Paulo', 'authors': 'Mohon Raihan, Plabon Kumar Saha, Rajan Das Gupta, A Z M Tahmidul Kabir, Afia Anjum Tamanna, Md. Harun-Ur-Rashid, Adnan Bin Abdus Salam, Md Tanvir Anjum, A Z M Ahteshamul Kabir', 'link': 'https://arxiv.org/abs/2506.16929', 'abstract': 'Neonatal death is still a concerning reality for underdeveloped and even some developed countries. Worldwide data indicate that 26.693 babies out of 1,000 births die, according to Macro Trades. To reduce this number, early prediction of endangered babies is crucial. Such prediction enables the opportunity to take ample care of the child and mother so that early child death can be avoided. In this context, machine learning was used to determine whether a newborn baby is at risk. To train the predictive model, historical data of 1.4 million newborns was used. Machine learning and deep learning techniques such as logical regression, K-nearest neighbor, random forest classifier, extreme gradient boosting (XGBoost), convolutional neural network, and long short-term memory (LSTM) were implemented using the dataset to identify the most accurate model for predicting neonatal mortality. Among the machine learning algorithms, XGBoost and random forest classifier achieved the best accuracy with 94%, while among the deep learning models, LSTM delivered the highest accuracy with 99%. Therefore, using LSTM appears to be the most suitable approach to predict whether precautionary measures for a child are necessary.', 'abstract_zh': '新生儿死亡仍然是发展中国家乃至部分发达国家值得关注的现实问题。根据Macro Trades的数据，全球范围内每1000名新生儿中就有26.693名婴儿死亡。为了减少这一数字，提前预测处于危险中的婴儿至关重要。这样的预测可以为婴儿和母亲提供充足的照料机会，从而避免早产儿死亡。在此背景下，机器学习被用于判断新生儿是否处于风险中。为了训练预测模型，使用了140万名新生儿的历史数据。通过逻辑回归、K最近邻、随机森林分类器、极端梯度提升（XGBoost）、卷积神经网络和长短期记忆（LSTM）等机器学习和深度学习技术实施了实验，以识别出最准确的预测新生儿死亡率的模型。在机器学习算法中，XGBoost和随机森林分类器的准确率最高，达到94%，而在深度学习模型中，LSTM的准确率最高，达到99%。因此，使用LSTM似乎是预测是否需要采取预防措施的最佳方法。', 'title_zh': '基于 São Paulo 情境下深度学习和机器学习预测新生儿死亡的方法'}
{'arxiv_id': 'arXiv:2506.16925', 'title': 'Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence', 'authors': 'Jack Griffiths, Steven A. Wrathmall, Simon A. Gardiner', 'link': 'https://arxiv.org/abs/2506.16925', 'abstract': "Precise determination of thermodynamic parameters in ultracold Bose gases remains challenging due to the destructive nature of conventional measurement techniques and inherent experimental uncertainties. We demonstrate an artificial intelligence approach for rapid, non-destructive estimation of the chemical potential and temperature from single-shot, in situ imaged density profiles of finite-temperature Bose gases. Our convolutional neural network is trained exclusively on quasi-2D `pancake' condensates in harmonic trap configurations. It achieves parameter extraction within fractions of a second. The model also demonstrates zero-shot generalisation across both trap geometry and thermalisation dynamics, successfully estimating thermodynamic parameters for toroidally trapped condensates with errors of only a few nanokelvin despite no prior exposure to such geometries during training, and maintaining predictive accuracy during dynamic thermalisation processes after a relatively brief evolution without explicit training on non-equilibrium states. These results suggest that supervised learning can overcome traditional limitations in ultracold atom thermometry, with extension to broader geometric configurations, temperature ranges, and additional parameters potentially enabling comprehensive real-time analysis of quantum gas experiments. Such capabilities could significantly streamline experimental workflows whilst improving measurement precision across a range of quantum fluid systems.", 'abstract_zh': '利用人工神经网络实现有限温度玻色气体化学势和温度的快速无损估计：超越传统超冷原子 thermometry 的限制', 'title_zh': '使用人工智能进行模拟玻色-爱因斯坦凝聚态的一次成像温度测量'}
{'arxiv_id': 'arXiv:2506.16884', 'title': 'The Importance of Being Lazy: Scaling Limits of Continual Learning', 'authors': 'Jacopo Graldi, Alessandro Breccia, Giulia Lanzillotta, Thomas Hofmann, Lorenzo Noci', 'link': 'https://arxiv.org/abs/2506.16884', 'abstract': 'Despite recent efforts, neural networks still struggle to learn in non-stationary environments, and our understanding of catastrophic forgetting (CF) is far from complete. In this work, we perform a systematic study on the impact of model scale and the degree of feature learning in continual learning. We reconcile existing contradictory observations on scale in the literature, by differentiating between lazy and rich training regimes through a variable parameterization of the architecture. We show that increasing model width is only beneficial when it reduces the amount of feature learning, yielding more laziness. Using the framework of dynamical mean field theory, we then study the infinite width dynamics of the model in the feature learning regime and characterize CF, extending prior theoretical results limited to the lazy regime. We study the intricate relationship between feature learning, task non-stationarity, and forgetting, finding that high feature learning is only beneficial with highly similar tasks. We identify a transition modulated by task similarity where the model exits an effectively lazy regime with low forgetting to enter a rich regime with significant forgetting. Finally, our findings reveal that neural networks achieve optimal performance at a critical level of feature learning, which depends on task non-stationarity and transfers across model scales. This work provides a unified perspective on the role of scale and feature learning in continual learning.', 'abstract_zh': '尽管最近做出了努力，神经网络在非平稳环境中仍然难以学习，我们对灾难性遗忘（CF）的理解也远未完善。在本文中，我们系统研究了模型规模和持续学习中特征学习程度的影响。通过架构的可变参数化区分懒惰和丰富的训练制度，我们 reconciled 文献中存在的矛盾观察结果。我们利用框架理论研究特征学习状态下模型的无限宽度动态，并表征 CF，扩大了仅限懒惰状态下成立的先前理论结果。我们研究了特征学习、任务非平稳性和遗忘之间的复杂关系，发现只有在任务高度相似时，高特征学习才是有益的。我们确定了一种由任务相似性调节的过渡，在这种过渡中，模型从一个低遗忘的有效懒惰状态下退出，进入一个显著遗忘的丰富状态下。最后，我们的发现表明，神经网络在特征学习的临界水平上实现最佳性能，这取决于任务非平稳性和模型规模之间的转移。本文为模型规模和特征学习在持续学习中的作用提供了统一视角。', 'title_zh': '懒有所值：连续学习的缩放极限'}
{'arxiv_id': 'arXiv:2506.16844', 'title': 'Bandwidth Selectors on Semiparametric Bayesian Networks', 'authors': 'Victor Alejandre, Concha Bielza, Pedro Larrañaga', 'link': 'https://arxiv.org/abs/2506.16844', 'abstract': 'Semiparametric Bayesian networks (SPBNs) integrate parametric and non-parametric probabilistic models, offering flexibility in learning complex data distributions from samples. In particular, kernel density estimators (KDEs) are employed for the non-parametric component. Under the assumption of data normality, the normal rule is used to learn the bandwidth matrix for the KDEs in SPBNs. This matrix is the key hyperparameter that controls the trade-off between bias and variance. However, real-world data often deviates from normality, potentially leading to suboptimal density estimation and reduced predictive performance. This paper first establishes the theoretical framework for the application of state-of-the-art bandwidth selectors and subsequently evaluates their impact on SPBN performance. We explore the approaches of cross-validation and plug-in selectors, assessing their effectiveness in enhancing the learning capability and applicability of SPBNs. To support this investigation, we have extended the open-source package PyBNesian for SPBNs with the additional bandwidth selection techniques and conducted extensive experimental analyses. Our results demonstrate that the proposed bandwidth selectors leverage increasing information more effectively than the normal rule, which, despite its robustness, stagnates with more data. In particular, unbiased cross-validation generally outperforms the normal rule, highlighting its advantage in high sample size scenarios.', 'abstract_zh': '半参数贝叶斯网络的带宽选择：理论框架与实证分析', 'title_zh': '半参数贝叶斯网络中的带宽选择器'}
{'arxiv_id': 'arXiv:2506.16791', 'title': 'TabArena: A Living Benchmark for Machine Learning on Tabular Data', 'authors': 'Nick Erickson, Lennart Purucker, Andrej Tschalzev, David Holzmüller, Prateek Mutalik Desai, and David Salinas, Frank Hutter', 'link': 'https://arxiv.org/abs/2506.16791', 'abstract': 'With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at this https URL.', 'abstract_zh': '随深度学习和基础模型在表格数据中的 popularity 增长，对标准化和可靠的基准测试的需求比以往任何时候都更高。然而，当前的基准测试是静态的，即使发现缺陷、模型版本更新或新模型发布，其设计也不会被更新。为解决这一问题，我们引入了 TabArena，这是第一个持续维护的动态表格基准测试系统。为启动 TabArena，我们手动筛选了具有代表性的数据集和实现良好的模型集合，进行大规模基准测试研究以初始化公共排行榜，并组建了一支经验丰富的维护团队。我们的结果显示了验证方法和超参数配置的集成对充分发挥基准模型性能的影响。尽管在实际的表格数据集上增强梯度提升树仍然表现强劲，但在较大的时间预算下，集成的深度学习方法已经迎头赶上。同时，基础模型在小数据集上表现出色。最后，我们展示了模型间集成推动了表格机器学习的最先进水平，并探讨了单个模型的贡献。我们以公共排行榜、可重复的代码和维护协议启动 TabArena，网址为 this https URL。', 'title_zh': 'TabArena: 一个针对表格数据机器学习的活基准测试'}
{'arxiv_id': 'arXiv:2506.16782', 'title': 'What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity', 'authors': 'Youjin Kong', 'link': 'https://arxiv.org/abs/2506.16782', 'abstract': 'Fairness in machine learning (ML) has become a rapidly growing area of research. But why, in the first place, is unfairness in ML morally wrong? And why should we care about improving fairness? Most fair-ML research implicitly appeals to distributive equality: the idea that desirable goods and benefits, such as opportunities (e.g., Barocas et al., 2023), should be equally distributed across society. Unfair ML models, then, are seen as wrong because they unequally distribute such benefits. This paper argues that this exclusive focus on distributive equality offers an incomplete and potentially misleading ethical foundation. Grounding ML fairness in egalitarianism -- the view that equality is a fundamental moral and social ideal -- requires challenging structural inequality: systematic, institutional, and durable arrangements that privilege some groups while disadvantaging others. Structural inequality manifests through ML systems in two primary forms: allocative harms (e.g., economic loss) and representational harms (e.g., stereotypes, erasure). While distributive equality helps address allocative harms, it fails to explain why representational harms are wrong -- why it is wrong for ML systems to reinforce social hierarchies that stratify people into superior and inferior groups -- and why ML systems should aim to foster a society where people relate as equals (i.e., relational equality). To address these limitations, the paper proposes a multifaceted egalitarian framework for ML fairness that integrates both distributive and relational equality. Drawing on critical social and political philosophy, this framework offers a more comprehensive ethical foundation for tackling the full spectrum of harms perpetuated by ML systems. The paper also outlines practical pathways for implementing the framework across the ML pipeline.', 'abstract_zh': '机器学习中的公平性：超越分配平等的多维度平等框架', 'title_zh': '机器学习公平性中的平等意义：超越机会平等'}
{'arxiv_id': 'arXiv:2506.16776', 'title': 'PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model', 'authors': 'Beomseok Ko, Hyeryung Jang', 'link': 'https://arxiv.org/abs/2506.16776', 'abstract': "Diffusion models excel in image generation but are computational and resource-intensive due to their reliance on iterative Markov chain processes, leading to error accumulation and limiting the effectiveness of naive compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid compression framework combining Progressive Quantization (PQ) and Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs a two-stage quantization with adaptive bit-width transitions guided by a momentum-based mechanism, reducing excessive weight perturbations in low-precision. CAD leverages full-precision calibration datasets during distillation, enabling the student to match full-precision performance even with a quantized teacher. As a result, PQCAD-DM achieves a balance between computational efficiency and generative quality, halving inference time while maintaining competitive performance. Extensive experiments validate PQCAD-DM's superior generative capabilities and efficiency across diverse datasets, outperforming fixed-bit quantization methods.", 'abstract_zh': 'PQCAD-DM：一种Combining 分级量化和校准辅助精炼的新型混合压缩框架', 'title_zh': 'PQCAD-DM: 进步量化和校准辅助蒸馏以实现极其高效的扩散模型'}
{'arxiv_id': 'arXiv:2506.16754', 'title': 'Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding', 'authors': 'Jongmin Park, Seunghoon Han, Won-Yong Shin, Sungsu Lim', 'link': 'https://arxiv.org/abs/2506.16754', 'abstract': 'The hyperbolic space, characterized by a constant negative curvature and exponentially expanding space, aligns well with the structural properties of heterogeneous graphs. However, although heterogeneous graphs inherently possess diverse power-law structures, most hyperbolic heterogeneous graph embedding models rely on a single hyperbolic space. This approach may fail to effectively capture the diverse power-law structures within heterogeneous graphs. To address this limitation, we propose a Metapath-based Hyperbolic Contrastive Learning framework (MHCL), which uses multiple hyperbolic spaces to capture diverse complex structures within heterogeneous graphs. Specifically, by learning each hyperbolic space to describe the distribution of complex structures corresponding to each metapath, it is possible to capture semantic information effectively. Since metapath embeddings represent distinct semantic information, preserving their discriminability is important when aggregating them to obtain node representations. Therefore, we use a contrastive learning approach to optimize MHCL and improve the discriminability of metapath embeddings. In particular, our contrastive learning method minimizes the distance between embeddings of the same metapath and maximizes the distance between those of different metapaths in hyperbolic space, thereby improving the separability of metapath embeddings with distinct semantic information. We conduct comprehensive experiments to evaluate the effectiveness of MHCL. The experimental results demonstrate that MHCL outperforms state-of-the-art baselines in various graph machine learning tasks, effectively capturing the complex structures of heterogeneous graphs.', 'abstract_zh': '基于元路径的双曲对比学习框架（MHCL）：捕捉异构图中的多样复杂结构', 'title_zh': '基于元路径的双曲对比学习异质图嵌入'}
{'arxiv_id': 'arXiv:2506.16741', 'title': 'RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching', 'authors': 'Hyun Joon Park, Jeongmin Liu, Jin Sob Kim, Jeong Yeol Yang, Sung Won Han, Eunwoo Song', 'link': 'https://arxiv.org/abs/2506.16741', 'abstract': 'We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in flow matching (FM) training. Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed. To address this challenge, RapFlow-TTS enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps. Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis. Experimental results show that RapFlow-TTS achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.', 'abstract_zh': 'RapFlow-TTS：一种基于流匹配的快速高保真TTS声学模型', 'title_zh': 'RapFlow-TTS：快速高保真文本到语音转换及改进的一致性流匹配'}
{'arxiv_id': 'arXiv:2506.16738', 'title': 'LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization', 'authors': 'Daejin Jo, Jeeyoung Yun, Byungseok Roh, Sungwoong Kim', 'link': 'https://arxiv.org/abs/2506.16738', 'abstract': 'With the rapid progress of speech language models (SLMs), discrete speech tokens have emerged as a core interface between speech and text, enabling unified modeling across modalities. Recent speech tokenization approaches aim to isolate semantic information from low-level acoustics to better align with language models. In particular, previous methods use SSL teachers such as HuBERT to extract semantic representations, which are then distilled into a semantic quantizer to suppress acoustic redundancy as well as capture content-related latent structures. However, they still produce speech token sequences significantly longer than their textual counterparts, creating challenges for efficient speech-language modeling. Reducing the frame rate is a natural solution, but standard techniques, such as rigid average pooling across frames, can distort or dilute the semantic structure required for effective LM alignment. To address this, we propose LM-SPT, a speech tokenization method that introduces a novel semantic distillation. Instead of directly matching teacher and student features via pooling, we reconstruct speech solely from semantic tokens and minimize the discrepancy between the encoded representations of the original and reconstructed waveforms, obtained from a frozen automatic speech recognition (ASR) encoder. This indirect yet data-driven supervision enables the tokenizer to learn discrete units that are more semantically aligned with language models. LM-SPT further incorporates architectural improvements to the encoder and decoder for speech tokenization, and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz. Experimental results show that LM-SPT achieves superior reconstruction fidelity compared to baselines, and that SLMs trained with LM-SPT tokens achieve competitive performances on speech-to-text and consistently outperform baselines on text-to-speech tasks.', 'abstract_zh': '借助语音语言模型的迅猛发展，离散语音令牌已成为语音与文本之间的核心接口，实现了跨模态的统一建模。最近的语音分词方法旨在从低级 acoustic 信息中隔离语义信息，以更好地与语言模型对齐。特别是，以往的方法使用如 HuBERT 的 SSL 老师来提取语义表示，这些表示随后被精简成语义量器，以抑制 acoustic 冗余并捕捉内容相关的潜在结构。然而，它们仍然生成显著长于其文本对应物的语音令牌序列，这为高效的语音-语言建模带来了挑战。降低帧率是一种自然的解决方案，但标准技术，如在帧之间进行刚性平均池化，可能会歪曲或稀释有效的语言模型对齐所需的语义结构。为解决这一问题，我们提出了 LM-SPT，一种引入新颖语义精简的语音分词方法。我们不是通过池化直接匹配老师和学生特征，而是仅从语义令牌重构语音，并最小化原始波形和重构波形的编码表示之间的差异，这些波形来自冻结的自动语音识别（ASR）编码器。这种间接但基于数据的监督使分词器能够学习更符合语言模型的离散单元。LM-SPT 还对编码器和解码器的架构进行了改进，支持多种帧率，包括 25Hz、12.5Hz 和 6.25Hz。实验结果显示，LM-SPT 在重建保真度方面优于基线，并且使用 LM-SPT 令牌训练的语音语言模型在语音转文本任务上表现出竞争性性能，在文本转语音任务上也始终优于基线。', 'title_zh': 'LM-SPT: LM对齐的语义蒸馏用于语音分词'}
{'arxiv_id': 'arXiv:2506.16732', 'title': 'On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis', 'authors': 'Fanchen Bu, Kijung Shin', 'link': 'https://arxiv.org/abs/2506.16732', 'abstract': 'In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.', 'abstract_zh': '无监督组合优化中的训练与测试对齐：包括可微分的去随机化版本以改善训练-测试对齐', 'title_zh': '关于无监督组合优化中训练-测试不对齐的现象、 empirical 探索与分析'}
{'arxiv_id': 'arXiv:2506.16723', 'title': 'TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data', 'authors': 'Yuping Yan, Yizhi Wang, Yuanshuai Li, Yaochu Jin', 'link': 'https://arxiv.org/abs/2506.16723', 'abstract': 'Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.', 'abstract_zh': '基于三重洗牌和贡献感知的串行联邦学习框架TriCon-SF：低通信开销下处理跨孤岛联邦学习数据异质性的高效范式', 'title_zh': 'TriCon-SF: 一种考虑贡献的异构 healthcare 数据三重洗牌串联联邦学习框架'}
{'arxiv_id': 'arXiv:2506.16718', 'title': 'Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation', 'authors': 'Chenxu Wang, Yonggang Jin, Cheng Hu, Youpeng Zhao, Zipeng Dai, Jian Zhao, Shiyu Huang, Liuyu Xiang, Junge Zhang, Zhaofeng He', 'link': 'https://arxiv.org/abs/2506.16718', 'abstract': "Adapting a single agent to a new multi-agent system brings challenges, necessitating adjustments across various tasks, environments, and interactions with unknown teammates and opponents. Addressing this challenge is highly complex, and researchers have proposed two simplified scenarios, Multi-agent reinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on these foundations, we propose a more comprehensive setting, Agent Collaborative-Competitive Adaptation (ACCA), which evaluates an agent to generalize across diverse scenarios, tasks, and interactions with both unfamiliar opponents and teammates. In ACCA, agents adjust to task and environmental changes, collaborate with unseen teammates, and compete against unknown opponents. We introduce a new modeling approach, Multi-Retrieval and Dynamic Generation (MRDG), that effectively models both teammates and opponents using their behavioral trajectories. This method incorporates a positional encoder for varying team sizes and a hypernetwork module to boost agents' learning and adaptive capabilities. Additionally, a viewpoint alignment module harmonizes the observational perspectives of retrieved teammates and opponents with the learning agent. Extensive tests in benchmark scenarios like SMAC, Overcooked-AI, and Melting Pot show that MRDG significantly improves robust collaboration and competition with unseen teammates and opponents, surpassing established baselines. Our code is available at: this https URL", 'abstract_zh': '将单一代理适应新的多代理系统带来了挑战，需要在各种任务、环境以及与未知队友和对手的互动中进行调整。解决这一挑战非常复杂，研究人员提出了两种简化的场景：零样本学习的多代理强化学习和即兴团队合作。在这些基础上，我们提出一种更为全面的设置——代理协作-竞争适应（ACCA），该设置评估代理在多样场景、任务和与未知队友及对手互动中的通用性。在ACCA中，代理适应任务和环境变化，与未见过的队友合作，并与未知对手竞争。我们引入了一种新的建模方法——多检索和动态生成（MRDG），该方法有效利用了行为轨迹来建模队友和对手。该方法包含一个位置编码器以适应不同规模的团队，并包含一个超网络模块以增强代理的学习和适应能力。此外，视点对齐模块使检索到的队友和对手的观察视角与学习代理协调一致。在基准场景SMAC、Overcooked-AI和Melting Pot中的广泛测试表明，MRDG显著提高了与未见过队友和对手的稳健合作和竞争能力，超过了已有的基准。我们的代码可在以下链接获取：this https URL。', 'title_zh': '具有多检索和动态生成的可迁移代理建模以适应代理协作与竞争适应'}
{'arxiv_id': 'arXiv:2506.16688', 'title': 'Fast and Stable Diffusion Planning through Variational Adaptive Weighting', 'authors': 'Zhiying Qiu, Tao Lin', 'link': 'https://arxiv.org/abs/2506.16688', 'abstract': 'Diffusion models have recently shown promise in offline RL. However, these methods often suffer from high training costs and slow convergence, particularly when using transformer-based denoising backbones. While several optimization strategies have been proposed -- such as modified noise schedules, auxiliary prediction targets, and adaptive loss weighting -- challenges remain in achieving stable and efficient training. In particular, existing loss weighting functions typically rely on neural network approximators, which can be ineffective in early training phases due to limited generalization capacity of MLPs when exposed to sparse feedback in the early training stages. In this work, we derive a variationally optimal uncertainty-aware weighting function and introduce a closed-form polynomial approximation method for its online estimation under the flow-based generative modeling framework. We integrate our method into a diffusion planning pipeline and evaluate it on standard offline RL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our method achieves competitive performance with up to 10 times fewer training steps, highlighting its practical effectiveness.', 'abstract_zh': '基于流的生成建模框架下变分最优不确定性感知权重函数及其在线闭式多项式逼近方法在离线RL中的应用', 'title_zh': '快速且稳定的扩散规划通过变分自适应加权'}
{'arxiv_id': 'arXiv:2506.16679', 'title': 'How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions', 'authors': 'Manuel Brack, Sudeep Katakol, Felix Friedrich, Patrick Schramowski, Hareesh Ravi, Kristian Kersting, Ajinkya Kale', 'link': 'https://arxiv.org/abs/2506.16679', 'abstract': "Training data is at the core of any successful text-to-image models. The quality and descriptiveness of image text are crucial to a model's performance. Given the noisiness and inconsistency in web-scraped datasets, recent works shifted towards synthetic training captions. While this setup is generally believed to produce more capable models, current literature does not provide any insights into its design choices. This study closes this gap by systematically investigating how different synthetic captioning strategies impact the downstream performance of text-to-image models. Our experiments demonstrate that dense, high-quality captions enhance text alignment but may introduce trade-offs in output aesthetics and diversity. Conversely, captions of randomized lengths yield balanced improvements across aesthetics and alignment without compromising sample diversity. We also demonstrate that varying caption distributions introduce significant shifts in the output bias of a trained model. Our findings underscore the importance of caption design in achieving optimal model performance and provide practical insights for more effective training data strategies in text-to-image generation.", 'abstract_zh': '训练数据是任何成功文本到图像模型的核心。图像文本的质量和描述性对于模型性能至关重要。鉴于网络抓取数据集中的噪声和不一致性，近期的研究转向了合成训练Caption。虽然这种设置通常被认为能够产生更强大的模型，但当前文献并未提供其设计选择的相关见解。本研究通过系统性地探究不同合成Caption策略对下游文本到图像模型性能的影响，填补了这一空白。我们的实验表明，密集且高质量的Caption能够增强文本对齐，但可能会导致输出美学性和多样性之间的权衡。相反，随机长度的Caption能够在美学性和对齐之间提供均衡的改进，而不会牺牲样本多样性。此外，我们还证明了改变Caption分布会对训练模型的输出偏差产生显著影响。我们的研究结果强调了Caption设计在实现最优模型性能中的重要性，并为文本到图像生成中更有效的训练数据策略提供了实用见解。', 'title_zh': '如何训练你的文本-to-图像模型：关于合成训练描述词设计选择的评估'}
{'arxiv_id': 'arXiv:2506.16654', 'title': 'Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures', 'authors': 'Vijay Prakash Dwivedi, Charilaos Kanatsoulis, Shenyang Huang, Jure Leskovec', 'link': 'https://arxiv.org/abs/2506.16654', 'abstract': "Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.", 'abstract_zh': '图机器学习在分子、社会网络、推荐系统和交通等领域处理任意图结构数据的能力上取得了显著提升，并且可以通过关系深度学习（RDL）将多表关系数据库构建为“关系实体图”，从而实现端到端的表示学习而无需传统特征工程。与任意图结构数据相比，关系实体图具有以下关键特性：（i）其结构由不同表中的实体之间的一对多关系定义，（ii）结构连接性由定义数据库的关系模式决定，（iii）图连接性在时间和异构性方面具有性质。在本文中，我们首先通过介绍关系数据库表示为关系实体图来全面回顾关系深度学习（RDL），然后回顾用于开发和评估基于图神经网络（GNN）的RDL模型的公共基准数据集，讨论包括大规模多表集成在内的关键挑战以及建模时间动态和异构数据的复杂性，并概述适用于关系实体图的基础神经网络方法和近期架构进步。最后，我们探索了统一这些不同建模挑战的机会，强调RDL如何将图机器学习中的多个子领域统一起来，朝着设计能够转型处理关系数据的基础模型方向发展。', 'title_zh': '关系深度学习：挑战、基础与下一代架构'}
{'arxiv_id': 'arXiv:2506.16640', 'title': 'Long-Context Generalization with Sparse Attention', 'authors': 'Pavlo Vasylenko, Marcos Treviso, André F. T. Martins', 'link': 'https://arxiv.org/abs/2506.16640', 'abstract': 'Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $\\alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $\\alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $\\alpha$-entmax baselines on long-context generalization.', 'abstract_zh': '基于Transformer的稀疏注意力机制通过α-entmax实现精准焦点学习与表示改进', 'title_zh': '长上下文泛化与稀疏注意力'}
{'arxiv_id': 'arXiv:2506.16636', 'title': 'Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation', 'authors': 'Rex Shen, Lu Tian', 'link': 'https://arxiv.org/abs/2506.16636', 'abstract': 'Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/\\sqrt{n}$ rate when approximating the true data distribution.\nTo overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles.\nOur procedure satisfies local $(\\epsilon, \\delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.', 'abstract_zh': '合成数据生成已成为实现可扩展性和隐私保护统计分析的关键。虽然基于生成模型的标准方法，如规范化流，已被广泛应用，但在高维设置中它们往往收敛速度较慢，往往慢于传统的约 $1/\\sqrt{n}$ 率，用于近似真实的数据分布。\n\n为了克服这些限制，我们提出了一种使用掩码自回归流（MAF）注入潜在噪声的方法。我们的方法不是直接从训练好的模型中采样，而是对潜在空间中的每个数据点进行扰动，并将其映射回数据域。这种构造在观察数据和合成数据之间保持了一对一的关系，使得合成输出能够密切反映潜在的真实分布，特别是在传统采样方法难以应对的高维挑战性环境中。\n\n我们的过程满足局部 $(\\epsilon, \\delta)$-差分隐私，并引入单个扰动参数来控制隐私-效用权衡。虽然基于单一合成数据集的估计量可能收敛得较慢，但我们从理论上和实验上都证明，在元分析框架中聚合 $K$ 个研究可以恢复经典的效率，并生成一致可靠的推断结果。我们展示了通过合理校准扰动参数，潜在噪声注入能够实现与原始数据强大的统计对齐，并对成员推断攻击具有鲁棒性。这些结果使我们的方法成为在分散和隐私敏感领域，如生物医学研究中合成数据共享的强有力替代方法。', 'title_zh': '潜在噪声注入以生成私密且统计对齐的合成数据'}
{'arxiv_id': 'arXiv:2506.16622', 'title': 'Modeling Public Perceptions of Science in Media', 'authors': 'Jiaxin Pei, Dustin Wright, Isabelle Augenstin, David Jurgens', 'link': 'https://arxiv.org/abs/2506.16622', 'abstract': "Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.", 'abstract_zh': '有效与公众开展科学交流对于培养公众对科学社区的信任和理解至关重要。然而，随着信息量的不断增加，科学传播者难以预见到受众如何感知和互动科学新闻。在本文中，我们引入了一种计算框架，该框架涵盖了十二个维度来建模公众的感知，如新闻价值、重要性和意外性。利用该框架，我们创建了一个包含10,489个注释的大规模科学新闻感知数据集，参与者来自多样化的美国和英国人口，提供了关于公众对科学信息的反应的有价值的见解。我们进一步开发了NLP模型，该模型在预测公众感知得分方面表现出色。依托数据集和模型，我们从两个视角探讨了公众对科学的感知：（1）感知作为结果：哪些因素会影响公众对科学信息的感知？（2）感知作为预测因子：我们能否利用估计的感知来预测公众对科学的兴趣和互动？研究发现，个人的科学新闻消费频率是感知的主要驱动因素，而人口统计学因素的影响较小。更重要的是，通过大规模分析和精心设计的Reddit自然实验，我们证明了估计的公众对科学信息的感知与最终的互动模式之间存在直接联系。获得更高感知得分的帖子收到了显著更多的评论和点赞，这种模式在不同科学信息和相同科学内容中均得到体现，但表达方式不同。总体而言，这项研究强调了在科学传播中进行精细感知建模的重要性，为预测公众对科学内容的兴趣和参与提供了新的途径。', 'title_zh': '媒体中公众对科学的认知 modeling'}
{'arxiv_id': 'arXiv:2506.16608', 'title': 'Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces', 'authors': 'Jiamin He, A. Rupam Mahmood, Martha White', 'link': 'https://arxiv.org/abs/2506.16608', 'abstract': 'We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces.', 'abstract_zh': '我们介绍了一种新颖的强化学习（RL）框架，将分布参数视为动作，并重新定义了代理与环境之间的边界。这种重新参数化使得新的动作空间连续，而无论原始动作类型（离散、连续、混合等）如何。在这一新的参数化下，我们开发了一种广义的确定性策略梯度估计器，分布参数策略梯度（DPPG），其方差低于原始动作空间中的梯度。尽管在分布参数上学习批评家提出了新的挑战，我们提出了一种插值批评家学习（ICL）的简单而有效的策略来增强学习，其灵感来源于拉姆达 bandit 设置。在连续控制的强基线 TD3 的基础上，我们提出了一种实用的基于 DPPG 的 actor-critic 算法，分布参数 actor-critic（DPAC）。实验证明，DPAC 在 OpenAI Gym 和 DeepMind Control Suite 的 MuJoCo 连续控制任务中表现优于 TD3，并且在具有离散化动作空间的相同环境中展示了竞争力。', 'title_zh': '分布参数演员-评论家：扩展行动空间中的智能体-环境边界'}
{'arxiv_id': 'arXiv:2506.16590', 'title': 'Energy-Based Transfer for Reinforcement Learning', 'authors': 'Zeyun Deng, Jasorsi Ghosh, Fiona Xie, Yuzhe Lu, Katia Sycara, Joseph Campbell', 'link': 'https://arxiv.org/abs/2506.16590', 'abstract': "Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.", 'abstract_zh': '强化学习算法往往 Sample Efficiency 较差，这使得它们在多任务或持续学习环境中应用起来颇具挑战。通过将先前训练的教师策略的知识转移到新但相关的任务中以指导探索，可以提高效率。然而，如果新任务与教师的训练任务相差足够大，转移的指导可能会变得次优，并倾向于引导探索低奖励行为。我们提出了一种基于能量的迁移学习方法，利用离群检测选择性地发布指导，使教师仅在其实训练分布内的状态下干预。理论上，我们证明了能量分数反映了教师的状态访问密度，并通过单任务和多任务设置的实验展示了样本效率和性能的提升。', 'title_zh': '基于能量的迁移强化学习'}
{'arxiv_id': 'arXiv:2506.16586', 'title': 'AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions', 'authors': 'Ihor Pysmennyi, Roman Kyslyi, Kyrylo Kleshch', 'link': 'https://arxiv.org/abs/2506.16586', 'abstract': 'Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the Quality Assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. We performed comprehensive analysis of implications on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, "black box" nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI\'s transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies.', 'abstract_zh': '现代分布式软件应用的质量保证过程中的AI工具整合及其挑战和前景研究', 'title_zh': 'AI驱动的工具在现代软件质量保证中的作用：优势、挑战及未来方向'}
{'arxiv_id': 'arXiv:2506.16553', 'title': 'One Sample is Enough to Make Conformal Prediction Robust', 'authors': 'Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar Bojchevski', 'link': 'https://arxiv.org/abs/2506.16553', 'abstract': 'Given any model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends this to inputs with worst-case noise. A well-established approach is to use randomized smoothing for RCP since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, current smoothing-based RCP requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a forward pass on a single randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. around 100) passes per input. Our key insight is to certify the conformal prediction procedure itself rather than individual scores. Our approach is agnostic to the setup (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.', 'abstract_zh': '给定任何模型，可信预测（CP）返回保证包含真实标签的预测集，且概率可以调整。鲁棒可信预测（RCP）将这一保证扩展到具有最坏情况噪声的输入。一种已确立的方法是使用随机平滑进行RCP，因为它适用于任何黑盒模型，并且能提供比确定性方法更小的预测集。然而，当前基于平滑的方法需要对每个输入进行多次模型前向传递，这在计算上是昂贵的。我们展示了即使对单个随机扰动输入进行一次前向传递，可信预测也能获得一些鲁棒性。使用任何二元证书，我们提出了一次样本鲁棒可信预测（RCP1）。我们的方法与使用多个（例如约100个）输入的当前最佳方法相比，返回具有更小平均集大小的鲁棒预测集。我们的关键见解是认证可信预测过程本身而非单个分数。我们的方法对设置（分类和回归）是无偏的。我们进一步将该方法扩展到基于平滑的鲁棒可信风险控制。', 'title_zh': '一个样本足以使一致预测 robust'}
{'arxiv_id': 'arXiv:2506.16506', 'title': 'Subspace-Boosted Model Merging', 'authors': 'Ronald Skorobogat, Karsten Roth, Mariana-Iuliana Georgescu, Zeynep Akata', 'link': 'https://arxiv.org/abs/2506.16506', 'abstract': 'Model merging enables the combination of multiple specialized expert models into a single model capable of performing multiple tasks. However, the benefits of merging an increasing amount of specialized experts generally lead to diminishing returns and reduced overall performance gains. In this work, we offer an explanation and analysis from a task arithmetic perspective; revealing that as the merging process (across numerous existing merging methods) continues for more and more experts, the associated task vector space experiences rank collapse. To mitigate this issue, we introduce Subspace Boosting, which operates on the singular value decomposed task vector space and maintains task vector ranks. Subspace Boosting raises merging efficacy for up to 20 expert models by large margins of more than 10% when evaluated on vision benchmarks. Moreover, we propose employing Higher-Order Generalized Singular Value Decomposition to further quantify task similarity, offering a new interpretable perspective on model merging.', 'abstract_zh': '模型合并使得多个专业专家模型能够整合成一个能够执行多项任务的单一模型。然而，合并越来越多的专业专家通常会导致收益递减和整体性能改进的减少。在本研究中，我们从任务算术的角度提供了解释和分析；揭示出随着合并过程（跨越多种现有合并方法）的进行，涉及的任务向量空间经历秩崩溃。为解决这一问题，我们引入了子空间增强方法，该方法在奇异值分解的任务向量空间上操作，并保持任务向量的秩。子空间增强在视觉基准测试中将最多20个专家模型的合并效率大幅提升超过10%。此外，我们提出了使用高阶广义奇异值分解进一歩量化任务相似性，提供一种可解释的模型合并新视角。', 'title_zh': '子空间增强模型融合'}
{'arxiv_id': 'arXiv:2506.16476', 'title': 'Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection', 'authors': 'Saad Almohaimeed, Saleh Almohaimeed, Damla Turgut, Ladislau Bölöni', 'link': 'https://arxiv.org/abs/2506.16476', 'abstract': "Implicit hate speech has recently emerged as a critical challenge for social media platforms. While much of the research has traditionally focused on harmful speech in general, the need for generalizable techniques to detect veiled and subtle forms of hate has become increasingly pressing. Based on lexicon analysis, we hypothesize that implicit hate speech is already present in publicly available harmful speech datasets but may not have been explicitly recognized or labeled by annotators. Additionally, crowdsourced datasets are prone to mislabeling due to the complexity of the task and often influenced by annotators' subjective interpretations. In this paper, we propose an approach to address the detection of implicit hate speech and enhance generalizability across diverse datasets by leveraging existing harmful speech datasets. Our method comprises three key components: influential sample identification, reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental results demonstrate the effectiveness of our approach in improving implicit hate detection, achieving a +12.9-point F1 score improvement compared to the baseline.", 'abstract_zh': '隐含仇恨言论近年来已成为社交媒体平台面临的关键挑战。虽然大多数研究传统上集中在一般有害言论上，但检测隐蔽和微妙的仇恨言论的通用技术需求日益紧迫。基于词典分析，我们假设隐含仇恨言论已经存在于公开可用的有害言论数据集中，但可能未被标注者明确识别或标注。此外，基于众包的数据集容易因任务复杂性和标注者主观解释的影响而出现误标。在本文中，我们提出了一种方法，通过利用现有有害言论数据集来解决隐含仇恨言论的检测问题并提高跨不同数据集的一般化能力。该方法包括三个关键组件：有影响力样本的识别、重新标注和使用Llama-3 70B和GPT-4o的数据增强。实验结果表明，与基线相比，我们的方法在提高隐含仇恨言论检测效果方面取得了12.9点的F1分数提升。', 'title_zh': '通用型泛化有害言论数据集以促进隐性仇恨言论检测'}
{'arxiv_id': 'arXiv:2506.16471', 'title': 'Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities', 'authors': 'Tara Akhound-Sadegh, Jungyoon Lee, Avishek Joey Bose, Valentin De Bortoli, Arnaud Doucet, Michael M. Bronstein, Dominique Beaini, Siamak Ravanbakhsh, Kirill Neklyudov, Alexander Tong', 'link': 'https://arxiv.org/abs/2506.16471', 'abstract': 'Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: this https URL', 'abstract_zh': '从目标非标准化概率密度高效采样的核心挑战仍然存在于无数高影响科学应用中。一种有前景的方法是设计借鉴生成扩散模型中先进技术理念（如概率路径设计）的递归采样器。然而，现有的所有基于扩散的采样器仍然无法从简单的分子系统规模的分布中抽样。在本文中，我们提出了递归推理时退火(PITA)框架，这是一种结合了两种互补的插值技术的新颖框架：I.) 贝尔茨曼分布退火和II.) 扩散平滑。PITA 通过逐步提高训练温度来训练一系列从高到低温度的扩散模型，并利用工程化获得的退火目标密度样本的便捷访问。在后续步骤中，PITA 通过结合费曼-卡克偏微分方程与序列蒙特卡洛技术进行推理时退火，使训练好的扩散模型能够在较低温度下生成训练样本，用于下一个扩散模型。实验上，PITA 首次实现了在直角坐标系中对N体粒子系统、阿尔法二肽和三肽的平衡采样，并显著减少了能量函数评估次数。代码请参见：this https URL', 'title_zh': '扩散模型采样 tobز曼密度的渐进采样时退火方法'}
{'arxiv_id': 'arXiv:2506.16456', 'title': 'Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation', 'authors': 'Jun Qi, Chen-Yu Liu, Sabato Marco Siniscalchi, Chao-Han Huck Yang, Min-Hsiu Hsieh', 'link': 'https://arxiv.org/abs/2506.16456', 'abstract': 'Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient fine-tuning of large-scale neural models. However, standard LoRA independently optimizes low-rank matrices, which inherently limits its expressivity and generalization capabilities. While classical tensor-train (TT) decomposition can be separately employed on individual LoRA matrices, this work demonstrates that the classical TT-based approach neither significantly improves parameter efficiency nor achieves substantial performance gains. This paper proposes TensorGuide, a novel tensor-train-guided adaptation framework to overcome these limitations. TensorGuide generates two correlated low-rank LoRA matrices through a unified TT structure driven by controlled Gaussian noise. The resulting joint TT representation inherently provides structured, low-rank adaptations, significantly enhancing expressivity, generalization, and parameter efficiency without increasing the number of trainable parameters. Theoretically, we justify these improvements through neural tangent kernel analyses, demonstrating superior optimization dynamics and enhanced generalization. Extensive experiments on quantum dot classification and GPT-2 fine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently outperforms standard LoRA and TT-LoRA, achieving improved accuracy and scalability with fewer parameters.', 'abstract_zh': 'TensorGuide：一种新的张量引导适应框架', 'title_zh': '联合张量-训练参量化方法以实现高效的低秩适应'}
{'arxiv_id': 'arXiv:2506.16448', 'title': 'Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach', 'authors': 'Tri Duc Ly, Gia H. Ngo', 'link': 'https://arxiv.org/abs/2506.16448', 'abstract': 'EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.', 'abstract_zh': '基于EEG的情感识别：利用多尺度卷积神经网络的一种新方法', 'title_zh': '面向消费者的基于EEG的情绪识别系统：一种多尺度卷积神经网络方法'}
{'arxiv_id': 'arXiv:2506.16443', 'title': 'Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks', 'authors': 'Jonas R. Naujoks, Aleksander Krasowski, Moritz Weckbecker, Galip Ümit Yolcu, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek, René P. Klausen', 'link': 'https://arxiv.org/abs/2506.16443', 'abstract': "Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.", 'abstract_zh': '物理启发的神经网络（PINNs）为解决偏微分方程（PDEs）提供了一种强大的方法，这类方程在定量科学中无处不在。在各个科学领域中的正向问题和逆向问题中，PINNs 近年来已成为科学机器学习领域的一项宝贵工具。其训练的关键方面在于，可以方便地获得来自 PDE 输入域的空间-时间点数据。解释性人工智能（XAI）领域的影响函数近似每个训练点对模型的影响，增强了可解释性。在本工作中，我们探讨了基于影响函数的采样方法在训练数据中的应用。研究结果表明，基于数据归属的方法进行的目标重采样有可能提高物理启发的神经网络的预测准确性，展示了 XAI 方法在 PINN 训练中的实际应用。', 'title_zh': '利用影响函数在物理知情神经网络中重新采样数据'}
{'arxiv_id': 'arXiv:2506.16343', 'title': 'Analyzing the Influence of Knowledge Graph Information on Relation Extraction', 'authors': 'Cedric Möller, Ricardo Usbeck', 'link': 'https://arxiv.org/abs/2506.16343', 'abstract': 'We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.', 'abstract_zh': '我们探讨了在不同数据集中将知识图谱信息整合到关系抽取模型中对性能的影响。我们的假设是知识图谱中实体的位置为关系抽取任务提供了重要的见解。我们使用多个数据集进行实验，每个数据集在关系数量、训练示例数量和底层知识图谱方面有所不同。实验结果表明，整合知识图谱信息显著提升了模型性能，特别是在处理每种关系的训练示例不平衡时效果尤为明显。我们通过结合传统的关系抽取方法和图意识神经贝尔曼-福德网络来评估基于知识图谱特征的贡献。这些特征在有监督和零样本设置下均表现出一致的性能提升。', 'title_zh': '分析知识图谱信息对关系提取的影响'}
{'arxiv_id': 'arXiv:2506.16330', 'title': 'Reliable Few-shot Learning under Dual Noises', 'authors': 'Ji Zhang, Jingkuan Song, Lianli Gao, Nicu Sebe, Heng Tao Shen', 'link': 'https://arxiv.org/abs/2506.16330', 'abstract': "Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target this http URL, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.", 'abstract_zh': 'Recent Advances in Model Pre-Training Giving Rise to Task Adaptation-Based Few-Shot Learning (FSL): DEnoised Task Adaptation (DETA++) for Reliable Few-Shot Learning', 'title_zh': '双噪音条件下可靠的少样本学习'}
{'arxiv_id': 'arXiv:2506.16313', 'title': 'Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks', 'authors': 'Sajan Muhammad, Salem Lahlou', 'link': 'https://arxiv.org/abs/2506.16313', 'abstract': 'Efficiently identifying the right trajectories for training remains an open problem in GFlowNets. To address this, it is essential to prioritize exploration in regions of the state space where the reward distribution has not been sufficiently learned. This calls for uncertainty-driven exploration, in other words, the agent should be aware of what it does not know. This attribute can be measured by joint predictions, which are particularly important for combinatorial and sequential decision problems. In this research, we integrate epistemic neural networks (ENN) with the conventional architecture of GFlowNets to enable more efficient joint predictions and better uncertainty quantification, thereby improving exploration and the identification of optimal trajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the baseline method in GFlownets and evaluated in grid environments and structured sequence generation in various settings, demonstrating both its efficacy and efficiency.', 'abstract_zh': '高效识别用于训练的正确轨迹仍然是GFlowNets中的一个开放问题。为此，需要在奖励分布尚未充分学习的空间区域中优先进行探索。这就需要基于不确定性驱动的探索，换句话说，代理应该知道自己不知道的东西。这一属性可以通过联合预测来度量，对于组合性和序列性决策问题尤其重要。在本研究中，我们将epistemic神经网络（ENN）与GFlowNets的常规架构相结合，以实现更有效的联合预测并更好地量化不确定性，从而改善探索和最优轨迹的识别。我们提出的算法ENN-GFN-Enhanced与GFlowNets的基线方法进行比较，并在不同设置的网格环境和结构化序列生成中进行评估，证明了其有效性和效率。', 'title_zh': '通过增强 episodic 神经网络提高 GFlownets 的探索能力'}
{'arxiv_id': 'arXiv:2506.16288', 'title': 'Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective', 'authors': 'Leo Gagnon, Eric Elmoznino, Sarthak Mittal, Tom Marty, Tejas Kasetty, Dhanya Sridhar, Guillaume Lajoie', 'link': 'https://arxiv.org/abs/2506.16288', 'abstract': 'The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.', 'abstract_zh': '自回归基础模型的快速适应能力通常归因于其预训练数据的多样性。从贝叶斯观点来看，这种设置中的预测误差最小化需要整合所有与观察结果一致的合理潜在假设。虽然这种行为原则上是可取的，但在实际中往往过于雄心勃勃：在高不确定性下，合理的潜在替代方案数量使贝叶斯最优预测计算上不可行。认知科学长期认识到这一限制，建议在这种情况下，启发式或信息寻求策略比详尽推理更可取。将这一洞察应用于下一个令牌预测，我们推测低不确定性与高不确定性预测在计算需求上存在差异，使不确定性忽略的下一个令牌预测成为不利的归纳偏见。为验证这一假设，我们引入了MetaHMM，这是一个具有丰富组合结构的合成序列元学习基准及可行的贝叶斯 oracle。我们显示，不同规模的Transformer确实难以处理高不确定性预测。受认知理论的启发，我们提出了一种将预训练模型转化为马尔可夫蒙特卡洛预测者的办法，以分离任务推理与令牌预测。初步结果表明，在不确定的上下文中，通过改进的容量分配和测试时可扩展的推理，可以获得显著收益，但仍存在挑战。', 'title_zh': '下一词预测应具备歧义敏感性：一种元学习视角'}
{'arxiv_id': 'arXiv:2506.16281', 'title': 'Artificial Intelligence for Atmospheric Sciences: A Research Roadmap', 'authors': 'Martha Arbayani Zaidan, Naser Hossein Motlagh, Petteri Nurmi, Tareq Hussein, Markku Kulmala, Tuukka Petäjä, Sasu Tarkoma', 'link': 'https://arxiv.org/abs/2506.16281', 'abstract': 'Atmospheric sciences are crucial for understanding environmental phenomena ranging from air quality to extreme weather events, and climate change. Recent breakthroughs in sensing, communication, computing, and Artificial Intelligence (AI) have significantly advanced atmospheric sciences, enabling the generation of vast amounts of data through long-term Earth observations and providing powerful tools for analyzing atmospheric phenomena and predicting natural disasters. This paper contributes a critical interdisciplinary overview that bridges the fields of atmospheric science and computer science, highlighting the transformative potential of AI in atmospheric research. We identify key challenges associated with integrating AI into atmospheric research, including issues related to big data and infrastructure, and provide a detailed research roadmap that addresses both current and emerging challenges.', 'abstract_zh': '大气科学对于理解从空气质量到极端天气事件以及气候变化的环境现象至关重要。最近在感知、通信、计算和人工智能（AI）领域的突破性进展极大地推动了大气科学的发展，通过长期的地球观测生成了大量的数据，并提供强大的工具来分析大气现象和预测自然灾害。本文提供了一个跨学科的关键性综述，将大气科学与计算机科学领域连接起来，突显了AI在大气研究中的变革潜力。我们识别了将AI整合到大气研究中所面临的若干关键挑战，包括与大数据和基础设施相关的问题，并提供了详细的研究路线图，以解决当前和新兴的挑战。', 'title_zh': '人工智能在大气科学中的应用：研究路线图'}
{'arxiv_id': 'arXiv:2506.16243', 'title': 'Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping', 'authors': 'Abdulvahap Mutlu, Şengül Doğan, Türker Tuncer', 'link': 'https://arxiv.org/abs/2506.16243', 'abstract': 'Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.', 'abstract_zh': '肌萎缩侧索硬化症（ALS）是一种罕见的神经退行性疾病，ALS患者高质量EEG数据稀缺。这种数据稀缺性与ALS记录与健康控制记录之间严重的类别不平衡相结合，为训练可靠的机器学习分类器带来了挑战。本文通过使用条件沃森生成对抗网络（CWGAN）生成ALS患者的合成EEG信号来解决这些问题。我们使用一个私有的EEG数据集（ALS vs. 非ALS）训练CWGAN，以学习ALS EEG信号的分布并产生逼真的合成样本。我们预处理并标准化EEG记录，训练了一个CWGAN模型以生成合成ALS信号。CWGAN架构和训练流程被详细说明，关键超参数选择以实现稳定训练。生成信号的定性评估显示，它们 closely 模仿真实的ALS EEG模式。CWGAN训练收敛，生成器和判别器损失曲线趋于稳定，表明成功学习。生成的合成EEG信号看起来很真实，并且有可能作为训练分类器的增強数据使用，有助于缓解类别不平衡并提高ALS检测准确性。我们讨论了该方法如何促进数据共享并增强诊断模型。', 'title_zh': '基于条件WGAN与权重裁剪的ALS-EEG合成数据增强在ALS诊断中的应用'}
{'arxiv_id': 'arXiv:2506.16189', 'title': 'CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization', 'authors': 'Putri A. van der Linden, Alexander Timans, Erik J. Bekkers', 'link': 'https://arxiv.org/abs/2506.16189', 'abstract': 'We study the problem of conformal prediction (CP) under geometric data shifts, where data samples are susceptible to transformations such as rotations or flips. While CP endows prediction models with post-hoc uncertainty quantification and formal coverage guarantees, their practicality breaks under distribution shifts that deteriorate model performance. To address this issue, we propose integrating geometric information--such as geometric pose--into the conformal procedure to reinstate its guarantees and ensure robustness under geometric shifts. In particular, we explore recent advancements on pose canonicalization as a suitable information extractor for this purpose. Evaluating the combined approach across discrete and continuous shifts and against equivariant and augmentation-based baselines, we find that integrating geometric information with CP yields a principled way to address geometric shifts while maintaining broad applicability to black-box predictors.', 'abstract_zh': '几何数据变换下保准预测问题的研究：几何信息的集成以应对几何变换', 'title_zh': 'CP$^2$: 利用几何进行规范预测的典范化方法'}
{'arxiv_id': 'arXiv:2506.16168', 'title': 'On using AI for EEG-based BCI applications: problems, current challenges and future trends', 'authors': "Thomas Barbera, Jacopo Burger, Alessandro D'Amelio, Simone Zini, Simone Bianco, Raffaella Lanzarotti, Paolo Napoletano, Giuseppe Boccignone, Jose Luis Contreras-Vidal", 'link': 'https://arxiv.org/abs/2506.16168', 'abstract': 'Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines "see" and "understand" language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT).\nHowever, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability.\nHere, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today\'s technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.', 'abstract_zh': '想象一下利用心智的力量进行沟通、创造，甚至与周围的这个世界互动。近期人工智能（AI）在机器如何“看”和“理解”语言方面的突破，正推动着从头皮脑电图（EEG）解码脑信号的激动人心的进展。初步看来，这为设计用于现实生活的革命性脑机接口（BCI）打开了大门，超越了传统应用领域，设想脑到语音（Brain-to-Speech）、脑到图像（Brain-to-Image）和甚至脑到物联网（BCIoT）。\n\n然而，这一旅程不像计算机视觉（CV）和自然语言处理（NLP）那样简单。将AI应用于基于EEG的BCI，尤其是构建强大的基础模型，面临着独特而复杂的挑战，这些挑战可能会影响它们的可靠性。\n\n在此，我们展开了一次引导性的探索，这一领域是动态且快速发展的。我们的目标不是简单地勾勒出现有努力和结果的地图，而是提供一种原理性的导航，以探索这一热门和前沿的研究景观。我们从因果视角出发考虑基本框架和随之而来的挑战，随后讨论有可能克服当前技术、方法和伦理限制的有希望的研究方向。我们的目标是为创造能够在日常环境中茁壮成长的真正实用且有效的基于EEG的BCI解决方案绘制一条清晰的路线图。', 'title_zh': '基于EEG的BCI应用中使用AI的问题、当前挑战及未来趋势'}
{'arxiv_id': 'arXiv:2506.16127', 'title': 'Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching', 'authors': 'Shoutrik Das, Nishant Singh, Arjun Gangwar, S Umesh', 'link': 'https://arxiv.org/abs/2506.16127', 'abstract': 'Dysarthria is a neurological disorder that significantly impairs speech intelligibility, often rendering affected individuals unable to communicate effectively. This necessitates the development of robust dysarthric-to-regular speech conversion techniques. In this work, we investigate the utility and limitations of self-supervised learning (SSL) features and their quantized representations as an alternative to mel-spectrograms for speech generation. Additionally, we explore methods to mitigate speaker variability by generating clean speech in a single-speaker voice using features extracted from WavLM. To this end, we propose a fully non-autoregressive approach that leverages Conditional Flow Matching (CFM) with Diffusion Transformers to learn a direct mapping from dysarthric to clean speech. Our findings highlight the effectiveness of discrete acoustic units in improving intelligibility while achieving faster convergence compared to traditional mel-spectrogram-based approaches.', 'abstract_zh': '构音障碍是一种神经性疾病，显著影响言语清晰度，常导致患者无法有效沟通。这 necessitates the development of robust dysarthric-to-regular speech conversion techniques. 在此工作中，我们探讨了自监督学习（SSL）特征及其量化表示作为mel- spectrograms替代品用于语音生成的应用和限制。此外，我们探索了通过使用从WavLM提取的特征生成单说话人口头清晰的语音以减轻说话人变异性的方法。为此，我们提出了一种完全非自回归方法，利用条件流匹配（CFM）与扩散变换器来学习从构音障碍到口头清晰语音的直接映射。我们的研究发现显示，离散声学单元在提高清晰度方面非常有效，并且收敛速度比传统的基于mel- spectrograms的方法更快。', 'title_zh': '使用条件流匹配改进失语性 speech 的可懂度'}
{'arxiv_id': 'arXiv:2506.16096', 'title': 'A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders', 'authors': 'Qianqian Liao, Wuque Cai, Hongze Sun, Dongze Liu, Duo Chen, Dezhong Yao, Daqing Guo', 'link': 'https://arxiv.org/abs/2506.16096', 'abstract': 'Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.', 'abstract_zh': '基于脑图谱的双阶段脑至人群图学习框架', 'title_zh': '一种脑-人群图学习框架用于诊断脑部疾病'}
{'arxiv_id': 'arXiv:2506.16056', 'title': 'CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations', 'authors': 'Puchun Liu, C. L. Philip Chen, Yubin He, Tong Zhang', 'link': 'https://arxiv.org/abs/2506.16056', 'abstract': 'The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.', 'abstract_zh': 'EEG表示学习的通用预训练框架中的跨视图信息提取与整合挑战及解决方案：CRIA方法', 'title_zh': 'CRIA：一种跨视角交互和实例适配的通用EEG表示预训练框架'}
{'arxiv_id': 'arXiv:2506.16014', 'title': 'VRAIL: Vectorized Reward-based Attribution for Interpretable Learning', 'authors': 'Jina Kim, Youjin Jang, Jeongjin Han', 'link': 'https://arxiv.org/abs/2506.16014', 'abstract': 'We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.', 'abstract_zh': '基于价值向量化奖励归因的可解释学习双层框架：VRAIL', 'title_zh': 'VRAIL：向量奖励归因的可解释学习'}
{'arxiv_id': 'arXiv:2506.16006', 'title': 'DIGMAPPER: A Modular System for Automated Geologic Map Digitization', 'authors': 'Weiwei Duan, Michael P. Gerlek, Steven N. Minton, Craig A. Knoblock, Fandel Lin, Theresa Chen, Leeje Jang, Sofia Kirsanova, Zekun Li, Yijun Lin, Yao-Yi Chiang', 'link': 'https://arxiv.org/abs/2506.16006', 'abstract': 'Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.', 'abstract_zh': '历史地质图包含丰富的空间信息，如岩层单位、断层、褶皱和层面，这些信息对于评估对可再生能源、电动汽车和国家安全至关重要的矿产资源至关重要。然而，地图数字化仍然是一个劳动密集型和耗时的过程。我们提出了一种模块化、可扩展的系统DIGMAPPER，该系统与美国地质调查局（USGS）合作开发，旨在自动数字化地质图。DIGMAPPER具备完整的Docker化、工作流协调架构，集成了最先进的深度学习模型进行地图布局分析、特征提取和地理参照。为了克服有限的训练数据和复杂的视觉内容等挑战，我们的系统采用了创新技巧，包括上下文学习、合成数据生成和基于 transformer 的模型。在超过100张标注的地图上进行的评估显示出在多边形、线性和点特征提取方面的高精度，并且具有可靠的地理参照性能。在美国地质调查局部署后，DIGMAPPER显著加速了分析准备好空间数据集的创建，支持全国范围内的关键矿产评估和更广泛的地质科学应用。', 'title_zh': 'DIGMAPPER：一种自动化地质图数字化的模块化系统'}
{'arxiv_id': 'arXiv:2506.16001', 'title': 'AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction', 'authors': 'Qianru Zhang, Honggang Wen, Ming Li, Dong Huang, Siu-Ming Yiu, Christian S. Jensen, Pietro Liò', 'link': 'https://arxiv.org/abs/2506.16001', 'abstract': 'Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at this https URL.', 'abstract_zh': '时间序列预测需要能够在同时实现三个竞争性目标的架构：（1）严格的时序因果性以获得可靠的预测，（2）次二次复杂性以实现实用的可扩展性，（3）多尺度模式识别以实现精确的长时程预测。我们引入了AutoHFormer，这是一种通过三项关键创新解决这些挑战的自回归变压器：1）多层次时序建模：我们的架构将预测分解为并行处理的段级块，随后进行段内的顺序细化。这种双尺度方法保持了时序一致性的同时，提高了计算效率。2）动态窗口注意力：注意力机制采用可学习的因果窗口，并具有指数衰减，从而减少复杂性同时保留精确的时序关系。该设计避免了标准变压器的反因果违反和RNN混合模型的顺序瓶颈。3）自适应时序编码：采用了一种新的一位编码系统来捕捉多尺度的时间模式。它结合了固定振荡模式来捕捉短期变化，并且具有可学习的衰减速率来捕捉长期趋势。全面的实验证明，与PatchTST在PEMS08数据集上的相比，AutoHFormer在大多数情况下保持一致的准确性的同时，训练速度提高了10.76倍，内存减少了6.06倍。这些突破性进展为高效和精确的时间序列建模设定了新的基准。我们的方法及其在多层次自回归机制中的所有基线的实现可在以下网址获取：这个 https URL。', 'title_zh': 'AutoHFormer: 效率较高的层次自回归Transformer在时间序列预测中的应用'}
{'arxiv_id': 'arXiv:2506.15978', 'title': 'A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension', 'authors': 'Toan Nguyen Hai, Ha Nguyen Viet, Truong Quan Xuan, Duc Do Minh', 'link': 'https://arxiv.org/abs/2506.15978', 'abstract': 'Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15\\% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace', 'abstract_zh': 'Vietnamese语资源欠缺，尤其是在文本分割和机器阅读理解等关键自然语言处理任务方面，拥有超过1.02亿母语使用者的越南语排名世界第20位。为解决这一问题，我们提出了VSMRC：越南语文本分割与多项选择阅读理解数据集。该数据集源自越南维基百科，包含15,942份用于文本分割的文档和16,347个人工质量保障生成的多项选择题-答案对，确保资源可靠且多样。实验结果显示，mBERT在两项任务上均优于单一语言模型，分别在机器阅读理解测试集上达到88.01%的准确率和在文本分割测试集上达到63.15%的F1分数。我们的分析表明，多语言模型在越南语的NLP任务中表现优异，这可能对其他资源匮乏的语言也有潜力应用。VSMRC可在HuggingFace获取。', 'title_zh': '越南语语料库用于文本分段和多项选择阅读理解'}
{'arxiv_id': 'arXiv:2506.15923', 'title': 'PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning', 'authors': 'Liangyan Li, Yangyi Liu, Yimo Ning, Stefano Rini, Jun Chen', 'link': 'https://arxiv.org/abs/2506.15923', 'abstract': 'Federated Learning (FL) has emerged as a powerful paradigm for leveraging diverse datasets from multiple sources while preserving data privacy by avoiding centralized storage. However, many existing approaches fail to account for the intricate gradient correlations between remote clients, a limitation that becomes especially problematic in data heterogeneity scenarios. In this work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity (PNCS) to improve client selection for model aggregation. By capturing higher-order gradient moments, PNCS addresses non-IID data challenges, enhancing convergence speed and accuracy. Additionally, we introduce a simple algorithm ensuring diverse client selection through a selection history queue. Experiments with a VGG16 model across varied data partitions demonstrate consistent improvements over state-of-the-art methods.', 'abstract_zh': '联邦学习（FL）作为一种利用多个数据源的多样化数据集同时保护数据隐私的有力范式，通过避免集中存储数据而崭露头角。然而，许多现有方法未能考虑远处客户端之间复杂的梯度相关性，这一局限在数据异质性场景中表现得尤为突出。在本工作中，我们提出了一种利用Power-Norm余弦相似度（PNCS）的新颖FL框架，以改进模型聚合时的客户端选择。通过捕获高阶梯度矩，PNCS解决了非IID数据的挑战，提高了收敛速度和准确性。此外，我们还引入了一个简单的算法，通过选择历史队列确保客户端选择的多样性。实验结果表明，在多种数据分割下，该方法在VGG16模型上的一致性改进超过了现有最佳方法。', 'title_zh': 'PNCS：Power-Norm余弦相似度在联邦学习中多样客户端选择中的应用'}
{'arxiv_id': 'arXiv:2506.15896', 'title': 'KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction', 'authors': 'Yu Zhang, Gaoshan Bi, Simon Jeffery, Max Davis, Yang Li, Qing Xue, Po Yang', 'link': 'https://arxiv.org/abs/2506.15896', 'abstract': 'Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.', 'abstract_zh': '基于知识引导的图神经网络框架在精确诊断农田温室气体排放中的应用', 'title_zh': '基于知识引导的GNN基础模型：肥料导向的土壤温室气体 Flux 预测'}
{'arxiv_id': 'arXiv:2506.15862', 'title': 'MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense, and Human Retrievers', 'authors': 'Jushaan Singh Kalra, Xinran Zhao, To Eun Kim, Fengyu Cai, Fernando Diaz, Tongshuang Wu', 'link': 'https://arxiv.org/abs/2506.15862', 'abstract': 'Retrieval-augmented Generation (RAG) is powerful, but its effectiveness hinges on which retrievers we use and how. Different retrievers offer distinct, often complementary signals: BM25 captures lexical matches; dense retrievers, semantic similarity. Yet in practice, we typically fix a single retriever based on heuristics, which fails to generalize across diverse information needs. Can we dynamically select and integrate multiple retrievers for each individual query, without the need for manual selection? In our work, we validate this intuition with quantitative analysis and introduce mixture of retrievers: a zero-shot, weighted combination of heterogeneous retrievers. Extensive experiments show that such mixtures are effective and efficient: Despite totaling just 0.8B parameters, this mixture outperforms every individual retriever and even larger 7B models by +10.8% and +3.9% on average, respectively. Further analysis also shows that this mixture framework can help incorporate specialized non-oracle human information sources as retrievers to achieve good collaboration, with a 58.9% relative performance improvement over simulated humans alone.', 'abstract_zh': '检索增强生成（RAG）很强大，但其效果依赖于使用的检索器及其应用方式。不同的检索器提供独特的、往往互补的信号：BM25捕获词汇匹配；密集检索器捕获语义相似性。然而，在实践中，我们通常基于启发式方法固定一个单一的检索器，这无法针对多样化的信息需求进行泛化。我们能否为每个单独的查询动态选择和整合多个检索器，而无需手动选择？在我们的工作中，我们通过定量分析验证了这一直觉，并引入了检索器混合：一种零样本、加权组合的异构检索器。广泛的实验显示，这种混合是有效且高效的：尽管总参数量仅为0.8B，但这种混合在个体检索器基础上分别取得了+10.8%和+3.9%的平均性能提升。进一步的分析还显示，这种混合框架可以有助于引入专门的非或acular人类信息源作为检索器进行协作，相较于单独的模拟人类，其相对性能提升了58.9%。', 'title_zh': 'MoR: 使用稀疏、稠密和人工检索器混合处理多样查询'}
{'arxiv_id': 'arXiv:2506.15850', 'title': 'Uncertainty Estimation by Human Perception versus Neural Models', 'authors': 'Pedro Mendes, Paolo Romano, David Garlan', 'link': 'https://arxiv.org/abs/2506.15850', 'abstract': 'Modern neural networks (NNs) often achieve high predictive accuracy but remain poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.', 'abstract_zh': '现代神经网络的预测准确率往往很高，但往往缺乏校准，即使错误时也会产生过于自信的预测。这种校准不足给那些需要可靠不确定性估计的应用带来了严重挑战。在本工作中，我们探讨了人类感知的不确定性与神经网络估计的不确定性之间的差异。使用三个标注有人类分歧和众包自信度的视觉基准，我们评估了模型预测不确定性与人类感知不确定性之间的相关性。结果显示，当前方法仅弱弱地与人类直觉对齐，相关性在不同任务和不确定性度量下差异显著。值得注意的是，我们发现将人类衍生的软标签纳入训练过程可以在不牺牲准确性的前提下改善校准。这些发现揭示了模型和人类不确定性之间持续存在的差距，并强调了利用人类洞察来指导开发更可信赖的AI系统潜力的重要性。', 'title_zh': '人类感知与神经模型的不确定性估计比较'}
{'arxiv_id': 'arXiv:2506.15841', 'title': 'MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents', 'authors': 'Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, Paul Pu Liang', 'link': 'https://arxiv.org/abs/2506.15841', 'abstract': 'Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.', 'abstract_zh': '现代语言代理必须在长期多轮交互中运行，期间它们检索外部信息、适应观察结果并回答相互依赖的问题。然而，大多数LLM系统依赖于全上下文提示，无论相关性如何都附加上所有过去轮次，这导致内存无界增长、增加计算成本并降低在分布外输入长度上的推理性能。我们引入了MEM1，这是一种端到端的强化学习框架，使代理能够在长期多轮任务中保持恒定内存运行。在每一轮中，MEM1更新一个紧凑的共享内部状态，该状态同时支持记忆巩固和推理。该状态将先前的记忆与环境的新观察结果整合在一起，同时策略性地丢弃无关或重复的信息。为了在更现实和组合的环境中支持训练，我们提出了一种简单而有效且可扩展的方法来构建多轮环境，通过组合现有数据集构建任意复杂程度的任务序列。在三个领域（包括内部检索问答、开放领域网络问答和多轮网络购物）的实验表明，与Qwen2.5-14B-Instruct相比，MEM1-7B在16目标多跳问答任务中的性能提高了3.5倍，同时内存使用量减少了3.7倍，并且能够超越训练范围进行泛化。我们的结果展示了基于推理的记忆巩固作为一种可扩展的替代方案的潜力，该方案用于训练长期交互代理，在效率和性能方面都进行了优化。', 'title_zh': 'MEM1: 学习协同记忆与推理以实现高效的长期智能体'}
{'arxiv_id': 'arXiv:2506.15803', 'title': 'Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma', 'authors': 'Bohan Yang, Gang Liu, Rirao Dao, Yujia Qian, Ke Shi, Anke Tang, Yong Luo, Jingnan Liu', 'link': 'https://arxiv.org/abs/2506.15803', 'abstract': "Objective. Proton arc therapy (PAT) is an emerging and promising modality in radiotherapy, offering several advantages over conventional intensitymodulated proton therapy (IMPT). However, identifying the optimal energy layer (EL) sequence remains computationally intensive due to the large number of possible energy layer transitions. This study proposes an unsupervised deep learning framework for fast and effective EL pre-selection, aiming to minimize energy layer switch time while preserving high plan quality. Approach. We introduce a novel data representation method, spot-count representation, which encodes the number of proton spots intersecting the target and organs at risk (OARs) in a matrix structured by sorted gantry angles and energy layers. This representation is the input of a UNet-based architecture, SPArcdl, which is trained to optimize a tri-objective function: maximizing target coverage, minimizing OAR exposure, and reducing energy switching time. The model is evaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked against plans generated by SPArcparticle swarm. Main results. SPArcdl produces EL pre-selection that significantly improves both plan quality and delivery efficiency. Compared to SPArc particle swarm, it enhances the conformity index by 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens the energy switching time by 38.4% (p < 0.01), and lowers the mean dose to brainstem by 0.21 (p < 0.01). The results unintentionally reveal employing unchanged ELS is more time-wise efficient than descended ELS. SPArcdl's inference time is within 1 second. Significance. SPArcdl is a fast and effective tool for generating high-quality PAT plans by strategically pre-selecting energy layers to reduce delivery time while maintaining excellent dosimetric performance.", 'abstract_zh': '目标. 质子弧疗法(PAT)是一种新兴且有前景的放疗技术，相较于常规调强质子疗法(IMPT)具有多项优势。然而，确定最优能量层(EL)序列仍因可能的能量层转换数量庞大而计算密集。本研究提出了一种无监督深度学习框架，用于快速有效地进行EL预选，旨在最小化能量层切换时间的同时保持高计划质量。方法. 我们引入了一种新的数据表示方法——点计数表示法，该方法编码了穿过靶区和危险器官(OARs)的质子点的数量，并以排序的扫描角度和能量层结构化矩阵形式表示。该表示法作为基于UNet架构的SPArcdl模型的输入，该模型被训练以优化一个三目标函数：最大化靶区覆盖、最小化OAR暴露和减少能量切换时间。该模型在54例鼻咽癌病例上进行了评估，并与SPArc粒子群优化生成的计划进行了基准测试。主要结果. SPArcdl产生的EL预选显著提高了计划质量和递送效率。与SPArc粒子群优化相比，它提高了一致性指数0.16(p < 0.01)、减少了均匀性指数0.71(p < 0.01)、缩短了能量切换时间38.4%(p < 0.01)、降低了脑干的平均剂量0.21 Gy(p < 0.01)。结果无意间揭示了使用不变的能量层比下降的能量层更为时间高效。SPArcdl的推理时间在1秒之内。意义. SPArcdl是一种快速有效的工具，通过战略性地预选能量层来生成高质量的PAT计划，从而减少递送时间并保持卓越的剂量学表现。', 'title_zh': '无监督深度学习模型用于鼻咽癌递送高效质子弧治疗计划的快速能量层预选'}
{'arxiv_id': 'arXiv:2506.15793', 'title': 'Linearithmic Clean-up for Vector-Symbolic Key-Value Memory with Kroneker Rotation Products', 'authors': 'Ruipeng Liu, Qinru Qiu, Simon Khan, Garrett E. Katz', 'link': 'https://arxiv.org/abs/2506.15793', 'abstract': "A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is the ``clean-up'' step, which decodes the noisy vectors retrieved from the architecture. Clean-up typically compares noisy vectors against a ``codebook'' of prototype vectors, incurring computational complexity that is quadratic or similar. We present a new codebook representation that supports efficient clean-up, based on Kroneker products of rotation-like matrices. The resulting clean-up time complexity is linearithmic, i.e. $\\mathcal{O}(N\\,\\text{log}\\,N)$, where $N$ is the vector dimension and also the number of vectors in the codebook. Clean-up space complexity is $\\mathcal{O}(N)$. Furthermore, the codebook is not stored explicitly in computer memory: It can be represented in $\\mathcal{O}(\\text{log}\\,N)$ space, and individual vectors in the codebook can be materialized in $\\mathcal{O}(N)$ time and space. At the same time, asymptotic memory capacity remains comparable to standard approaches. Computer experiments confirm these results, demonstrating several orders of magnitude more scalability than baseline VSA techniques.", 'abstract_zh': '当前向量-符号架构中的一个计算瓶颈是在从架构中检索到的嘈杂向量进行“清洁”步骤，这涉及到将这些嘈杂向量与原型向量的“代码本”进行比较，从而产生二次或类似的计算复杂度。我们提出了一种新的代码本表示方法，它基于旋转矩阵的克罗内克积，支持高效的清洁步骤。清洁步骤的时间复杂度为对数线性，即$\\mathcal{O}(N \\,\\text{log}\\, N)$，其中$N$是向量维数，也是代码本中向量的数量。清洁步骤的空间复杂度为$\\mathcal{O}(N)$。此外，该代码本并未显式存储在计算机内存中：它可以使用$\\mathcal{O}(\\text{log}\\,N)$的空间表示，并且可以在$\\mathcal{O}(N)$的时间和空间内实现代码本中的个别向量。与此同时，渐近内存容量与标准方法相当。计算机实验验证了这些结果，显示出比基线向量-符号架构技术高出几个数量级的可扩展性。', 'title_zh': '基于克罗内克旋转积的线性对数级清理算法用于向量符号键值记忆系统'}
{'arxiv_id': 'arXiv:2506.15791', 'title': 'TRUST: Transparent, Robust and Ultra-Sparse Trees', 'authors': 'Albert Dorador', 'link': 'https://arxiv.org/abs/2506.15791', 'abstract': "Piecewise-constant regression trees remain popular for their interpretability, yet often lag behind black-box models like Random Forest in predictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and Ultra-Sparse Trees), a novel regression tree model that combines the accuracy of Random Forests with the interpretability of shallow decision trees and sparse linear models. TRUST further enhances transparency by leveraging Large Language Models to generate tailored, user-friendly explanations. Extensive validation on synthetic and real-world benchmark datasets demonstrates that TRUST consistently outperforms other interpretable models -- including CART, Lasso, and Node Harvest -- in predictive accuracy, while matching the accuracy of Random Forest and offering substantial gains in both accuracy and interpretability over M5', a well-established model that is conceptually related.", 'abstract_zh': '透明、稳健且极度稀疏的树模型TRUST：结合随机森林的预测准确性和浅决策树及稀疏线性模型的可解释性', 'title_zh': 'TRUST: 透明、鲁棒且超稀疏树结构'}
{'arxiv_id': 'arXiv:2506.15786', 'title': 'Graphics4Science: Computer Graphics for Scientific Impacts', 'authors': 'Peter Yichen Chen, Minghao Guo, Hanspeter Pfister, Ming Lin, William Freeman, Qixing Huang, Han-Wei Shen, Wojciech Matusik', 'link': 'https://arxiv.org/abs/2506.15786', 'abstract': 'Computer graphics, often associated with films, games, and visual effects, has long been a powerful tool for addressing scientific challenges--from its origins in 3D visualization for medical imaging to its role in modern computational modeling and simulation. This course explores the deep and evolving relationship between computer graphics and science, highlighting past achievements, ongoing contributions, and open questions that remain. We show how core methods, such as geometric reasoning and physical modeling, provide inductive biases that help address challenges in both fields, especially in data-scarce settings. To that end, we aim to reframe graphics as a modeling language for science by bridging vocabulary gaps between the two communities. Designed for both newcomers and experts, Graphics4Science invites the graphics community to engage with science, tackle high-impact problems where graphics expertise can make a difference, and contribute to the future of scientific discovery. Additional details are available on the course website: this https URL', 'abstract_zh': '计算机图形学，常与电影、游戏和视觉效果相关，长期以来一直是应对科学挑战的强大工具——从医学成像领域的3D可视化起源，到现代计算建模和模拟中的角色。本课程探讨了计算机图形学与科学之间深厚且不断发展的关系，突显了过去的成就、现有的贡献以及仍然存在的开放问题。我们展示了核心方法，如几何推理和物理建模，如何提供归纳偏置，帮助解决两个领域的挑战，尤其是在数据稀缺的情况下。为此，我们旨在通过弥合两个社区之间的词汇差异，将图形学重新构想为一种科学建模语言。面向新手和专家，Graphics4Science 邀请图形学社区参与科学领域，解决那些图形学专长可以产生重大影响的问题，并为科学发现的未来作出贡献。更多细节请参见课程网站：this https URL', 'title_zh': 'Graphics4Science: 计算机图形学的科学影响'}
{'arxiv_id': 'arXiv:2506.15756', 'title': 'RecBayes: Recurrent Bayesian Ad Hoc Teamwork in Large Partially Observable Domains', 'authors': 'João G. Ribeiro, Yaniv Oren, Alberto Sardinha, Matthijs Spaan, Francisco S. Melo', 'link': 'https://arxiv.org/abs/2506.15756', 'abstract': "This paper proposes RecBayes, a novel approach for ad hoc teamwork under partial observability, a setting where agents are deployed on-the-fly to environments where pre-existing teams operate, that never requires, at any stage, access to the states of the environment or the actions of its teammates. We show that by relying on a recurrent Bayesian classifier trained using past experiences, an ad hoc agent is effectively able to identify known teams and tasks being performed from observations alone. Unlike recent approaches such as PO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some stage fully observable states of the environment, actions of teammates, or both, or approaches such as ATPO (Ribeiro et al., 2023) that require the environments to be small enough to be tabularly modelled (Ribeiro et al., 2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes is both able to handle arbitrarily large spaces while never relying on either states and teammates' actions. Our results in benchmark domains from the multi-agent systems literature, adapted for partial observability and scaled up to 1M states and 2^125 observations, show that RecBayes is effective at identifying known teams and tasks being performed from partial observations alone, and as a result, is able to assist the teams in solving the tasks effectively.", 'abstract_zh': 'RecBayes：在部分可观测性环境下的一种新型即兴团队工作方法', 'title_zh': 'RecBayes: 递归贝叶斯即兴团队协作在大型部分可观测域中'}
{'arxiv_id': 'arXiv:2506.15737', 'title': 'A Study of Hybrid and Evolutionary Metaheuristics for Single Hidden Layer Feedforward Neural Network Architecture', 'authors': 'Gautam Siddharth Kashyap, Md Tabrez Nafis, Samar Wazir', 'link': 'https://arxiv.org/abs/2506.15737', 'abstract': 'Training Artificial Neural Networks (ANNs) with Stochastic Gradient Descent (SGD) frequently encounters difficulties, including substantial computing expense and the risk of converging to local optima, attributable to its dependence on partial weight gradients. Therefore, this work investigates Particle Swarm Optimization (PSO) and Genetic Algorithms (GAs) - two population-based Metaheuristic Optimizers (MHOs) - as alternatives to SGD to mitigate these constraints. A hybrid PSO-SGD strategy is developed to improve local search efficiency. The findings indicate that the hybrid PSO-SGD technique decreases the median training MSE by 90 to 95 percent relative to conventional GA and PSO across various network sizes (e.g., from around 0.02 to approximately 0.001 in the Sphere function). RMHC attains substantial enhancements, reducing MSE by roughly 85 to 90 percent compared to GA. Simultaneously, RS consistently exhibits errors exceeding 0.3, signifying subpar performance. These findings underscore that hybrid and evolutionary procedures significantly improve training efficiency and accuracy compared to conventional optimization methods and imply that the Building Block Hypothesis (BBH) may still be valid, indicating that advantageous weight structures are retained during evolutionary search.', 'abstract_zh': '使用粒子群优化（PSO）和遗传算法（GAs）替代随机梯度下降（SGD）以缓解人工神经网络（ANNs）的训练难题：基于混合PSO-SGD策略的改进局部搜索效率', 'title_zh': '单隐层前向神经网络架构的混合与进化元启发式研究'}
{'arxiv_id': 'arXiv:2506.15725', 'title': 'Graph Diffusion that can Insert and Delete', 'authors': 'Matteo Ninniri, Marco Podda, Davide Bacciu', 'link': 'https://arxiv.org/abs/2506.15725', 'abstract': 'Generative models of graphs based on discrete Denoising Diffusion Probabilistic Models (DDPMs) offer a principled approach to molecular generation by systematically removing structural noise through iterative atom and bond adjustments. However, existing formulations are fundamentally limited by their inability to adapt the graph size (that is, the number of atoms) during the diffusion process, severely restricting their effectiveness in conditional generation scenarios such as property-driven molecular design, where the targeted property often correlates with the molecular size. In this paper, we reformulate the noising and denoising processes to support monotonic insertion and deletion of nodes. The resulting model, which we call GrIDDD, dynamically grows or shrinks the chemical graph during generation. GrIDDD matches or exceeds the performance of existing graph diffusion models on molecular property targeting despite being trained on a more difficult problem. Furthermore, when applied to molecular optimization, GrIDDD exhibits competitive performance compared to specialized optimization models. This work paves the way for size-adaptive molecular generation with graph diffusion.', 'abstract_zh': '基于离散去噪扩散概率模型（DDPMs）的图生成模型通过迭代的原子和化学键调整系统地去除结构噪声，提供了一种分子生成的原理性方法。然而，现有的模型在扩散过程中固有限制了其对分子大小的适应性，严重限制了其在如性质驱动的分子设计等条件生成场景中的有效性，这些场景中目标性质往往与分子大小相关。本文重新定义了去噪和扰噪过程，支持节点的单调插入和删除，提出了一种称为GrIDDD的模型，该模型在生成过程中动态地增长或缩小化学图。尽管是针对一个更困难的问题进行训练，GrIDDD在分子性质目标方面的性能与现有的图扩散模型相当或超越。此外，在分子优化中，GrIDDD也表现出与专门优化模型相竞争的性能。这项工作为进一步实现图扩散下的自适应分子生成奠定了基础。', 'title_zh': '具有插入和删除功能的图扩散'}
{'arxiv_id': 'arXiv:2506.15722', 'title': 'UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation', 'authors': 'Wangzhi Zhan, Jianpeng Chen, Dongqi Fu, Dawei Zhou', 'link': 'https://arxiv.org/abs/2506.15722', 'abstract': 'Metamaterials are artificial materials that are designed to meet unseen properties in nature, such as ultra-stiffness and negative materials indices. In mechanical metamaterial design, three key modalities are typically involved, i.e., 3D topology, density condition, and mechanical property. Real-world complex application scenarios place the demanding requirements on machine learning models to consider all three modalities together. However, a comprehensive literature review indicates that most existing works only consider two modalities, e.g., predicting mechanical properties given the 3D topology or generating 3D topology given the required properties. Therefore, there is still a significant gap for the state-of-the-art machine learning models capturing the whole. Hence, we propose a unified model named UNIMATE, which consists of a modality alignment module and a synergetic diffusion generation module. Experiments indicate that UNIMATE outperforms the other baseline models in topology generation task, property prediction task, and condition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We opensource our proposed UNIMATE model and corresponding results at this https URL.', 'abstract_zh': '人工材料是设计用于实现自然界中未见属性的人工材料，如超刚度和负材料指数。在机械人工材料设计中，通常涉及三种关键模态，即三维拓扑结构、密度条件和机械性能。现实世界复杂的应用场景对机器学习模型提出了同时综合考虑这三个模态的要求。然而，文献综述表明，大多数现有工作仅考虑了两个模态，例如给定三维拓扑结构预测机械性能或给定所需属性生成三维拓扑结构。因此，最先进的机器学习模型仍然在综合捕捉这三个模态方面存在显著差距。因此，我们提出了一种名为UNIMATE的统一模型，该模型包括一种模态对齐模块和一种协同扩散生成模块。实验表明，在拓扑结构生成任务、性能预测任务和条件确认任务中，UNIMATE分别比其他基线模型高出80.2%、5.1%和50.2%。我们开源了所提出的UNIMATE模型及其相应结果。', 'title_zh': 'UniMate：统一的机械元材料生成、性质预测和条件验证模型'}
{'arxiv_id': 'arXiv:2506.15716', 'title': "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies", 'authors': 'Angelos Assos, Carmel Baharav, Bailey Flanigan, Ariel Procaccia', 'link': 'https://arxiv.org/abs/2506.15716', 'abstract': "An increasingly influential form of deliberative democracy centers on citizens' assemblies, where randomly selected people discuss policy questions. The legitimacy of these panels hinges on their representation of the broader population, but panelists often drop out, leading to an unbalanced composition. Although participant attrition is mitigated in practice by alternates, their selection is not taken into account by existing methods. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. We establish theoretical guarantees for our approach, including worst-case bounds on sample complexity (with implications for computational efficiency) and on loss when panelists' probabilities of dropping out are mis-estimated. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.", 'abstract_zh': '一种日益有影响力的 deliberative democracy 形式侧重于公民 assembly，其中随机选定的人员讨论政策问题。这些小组的合法性取决于其对更广泛人口的代表性，但参与者常会退出，导致小组组成失衡。尽管在实践中通过备选人员可以减轻参与者流失的问题，但现有的方法并未将备选人员的选择考虑在内。为解决这一缺口，我们提出了一种备选人员选择的优化框架。我们的算法方法利用了学习理论的工具，利用历史数据估计退出概率，并选择备选人员以最小化预期的代表性失真。我们为这种方法建立了理论保证，包括最坏情况下的样本复杂性界（对计算效率的影响）以及参与者退出概率估计有误时的损失界。使用真实数据的实证评估表明，与现状相比，我们的方法在需要更少备选人员的情况下显著提高了代表性。', 'title_zh': '交替登场！公民大会的最佳替代者选择'}
{'arxiv_id': 'arXiv:2506.15715', 'title': 'NeuronSeek: On Stability and Expressivity of Task-driven Neurons', 'authors': 'Hanyu Pei, Jing-Xiao Liao, Qibin Zhao, Ting Gao, Shijun Zhang, Xiaoge Zhang, Feng-Lei Fan', 'link': 'https://arxiv.org/abs/2506.15715', 'abstract': "Drawing inspiration from our human brain that designs different neurons for different tasks, recent advances in deep learning have explored modifying a network's neurons to develop so-called task-driven neurons. Prototyping task-driven neurons (referred to as NeuronSeek) employs symbolic regression (SR) to discover the optimal neuron formulation and construct a network from these optimized neurons. Along this direction, this work replaces symbolic regression with tensor decomposition (TD) to discover optimal neuronal formulations, offering enhanced stability and faster convergence. Furthermore, we establish theoretical guarantees that modifying the aggregation functions with common activation functions can empower a network with a fixed number of parameters to approximate any continuous function with an arbitrarily small error, providing a rigorous mathematical foundation for the NeuronSeek framework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD framework not only achieves superior stability, but also is competitive relative to the state-of-the-art models across diverse benchmarks. The code is available at this https URL.", 'abstract_zh': '从人类大脑设计不同神经元用于不同任务中汲取灵感， recent advances in deep learning探索了修改网络神经元以开发所谓的任务驱动神经元。Prototype任务驱动神经元（即NeuronSeek）使用符号回归（SR）来发现最优神经元公式并构建由这些优化神经元组成的网络。在此方向上，本文用张量分解（TD）替换符号回归以发现最优神经元公式，提供增强的稳定性和更快的收敛性。此外，我们建立了理论保证，修改常用的激活函数可以使具有固定参数数量的网络逼近任意连续函数，随任意小的误差，为NeuronSeek框架提供了坚实的数学基础。广泛的实证评估表明，我们的NeuronSeek-TD框架不仅实现了卓越的稳定性，还在多种基准上与最先进的模型竞争。代码可在以下链接获取。', 'title_zh': 'NeuronSeek：任务驱动神经元的稳定性和表征能力探究'}
{'arxiv_id': 'arXiv:2506.15711', 'title': 'Shadow defense against gradient inversion attack in federated learning', 'authors': 'Le Jiang, Liyan Ma, Guang Yang', 'link': 'https://arxiv.org/abs/2506.15711', 'abstract': 'Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1\\% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5\\% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.', 'abstract_zh': '联邦学习（FL）作为一种保护隐私的分布式训练范式，允许多个客户端协作训练全局模型而无需共享本地数据。这在像医疗健康这样敏感的领域尤为重要，因为保护患者数据至关重要。然而，隐私泄露仍然是一个关键挑战，因为模型更新的通信可能会被潜在对手利用。梯度反向攻击（GIAs）允许对手逼近用于训练的梯度并重建训练图像，从而窃取患者隐私。现有的防御机制掩盖了梯度，但缺乏对哪些梯度或哪种图像信息最容易受到此类攻击的理解。这种不分青红皂白的校准扰动要么过度保护隐私导致模型准确性下降，要么保护不足无法保护敏感信息。因此，我们提出了一种框架，通过利用具有可解释性的阴影模型来识别敏感区域，以实现更具针对性和样本特异性的噪声注入。特别地，我们的防御策略在ChestXRay数据集中与无防御情况相比，PSNR上的差异为3.73，SSIM上的差异为0.2；在EyePACS数据集中，PSNR上的差异为2.78，SSIM上的差异为0.166。此外，它还可以最小化对模型性能的负面影响，与最先进的方法相比，F1分数的降低不到1%。我们在多种类型医疗图像上进行的广泛实验验证了所提出框架的泛化能力。对于FedAvg的稳定防御改进，稳定感知相异性（LPIPS）和SSIM均超过1.5%。该框架还对各种GIAs类型提供了普遍防御，尤其对图像中的敏感区域特别有效。', 'title_zh': '联邦学习中抵御梯度反转攻击的阴影防御'}
{'arxiv_id': 'arXiv:2506.15709', 'title': 'Studying and Improving Graph Neural Network-based Motif Estimation', 'authors': 'Pedro C. Vieira, Miguel E. P. Silva, Pedro Manuel Pinto Ribeiro', 'link': 'https://arxiv.org/abs/2506.15709', 'abstract': 'Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.', 'abstract_zh': '基于图神经网络的网络模体显著性分布估计：超越子图频率估计的模体温床构建', 'title_zh': '基于图神经网络的图模式估计研究与改进'}
{'arxiv_id': 'arXiv:2506.15708', 'title': 'Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification', 'authors': 'Falih Gozi Febrinanto, Adonia Simango, Chengpei Xu, Jingjing Zhou, Jiangang Ma, Sonika Tyagi, Feng Xia', 'link': 'https://arxiv.org/abs/2506.15708', 'abstract': 'Graph neural networks (GNNs) have been developed to model the relationship between regions of interest (ROIs) in brains and have shown significant improvement in detecting brain diseases. However, most of these frameworks do not consider the intrinsic relationship of causality factor between brain ROIs, which is arguably more essential to observe cause and effect interaction between signals rather than typical correlation values. We propose a novel framework called CGB (Causal Graphs for Brains) for brain disease classification/detection, which models refined brain networks based on the causal discovery method, transfer entropy, and geometric curvature strategy. CGB unveils causal relationships between ROIs that bring vital information to enhance brain disease classification performance. Furthermore, CGB also performs a graph rewiring through a geometric curvature strategy to refine the generated causal graph to become more expressive and reduce potential information bottlenecks when GNNs model it. Our extensive experiments show that CGB outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.', 'abstract_zh': '基于因果图的脑疾病分类/检测框架（CGB）', 'title_zh': '基于曲率的精细化因果图形结构学习在脑疾病分类中的应用'}
{'arxiv_id': 'arXiv:2506.15705', 'title': 'Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models', 'authors': 'Jittarin Jetwiriyanon, Teo Susnjak, Surangika Ranathunga', 'link': 'https://arxiv.org/abs/2506.15705', 'abstract': 'This study investigates zero-shot forecasting capabilities of Time Series Foundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to forecasting economic indicators under univariate conditions, bypassing the need for train bespoke econometric models using and extensive training datasets. Our experiments were conducted on a case study dataset, without additional customisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos, TimeGPT and Moirai) under data-scarce conditions and structural breaks. Our results demonstrate that appropriately engineered TSFMs can internalise rich economic dynamics, accommodate regime shifts, and deliver well-behaved uncertainty estimates out of the box, while matching state-of-the-art multivariate models on this domain. Our findings suggest that, without any fine-tuning, TSFMs can match or exceed classical models during stable economic conditions. However, they are vulnerable to degradation in performances during periods of rapid shocks. The findings offer guidance to practitioners on when zero-shot deployments are viable for macroeconomic monitoring and strategic planning.', 'abstract_zh': '本研究探讨时间序列基础模型（TSFM）在宏观经济学指标零样本预测能力。我们对单一变量条件下经济指标进行了预测，绕过了使用广泛训练数据集构建定制经济计量模型的需要。我们使用案例研究数据集进行了实验，未进行额外的定制化。我们在数据稀缺和结构性断点条件下严格回测了三种最先进的TSFM（Chronos、TimeGPT和Moirai）。结果显示，适当工程化的TSFM能够内化丰富的经济动态，适应制度变化，并提供即用型的良好行为不确定性估计，同时在该领域与最先进的多元模型表现相当。我们的研究发现，在经济稳定时期，TSFM可以匹配或超越经典模型。然而，在快速冲击时期，它们的表现容易受到影响。这些发现为实务操作者提供了指导，说明了在宏观经济学监控和战略规划中零样本部署的有效性。', 'title_zh': '基于时间序列基础模型的零样本经济预测泛化边界研究'}
{'arxiv_id': 'arXiv:2506.15703', 'title': 'Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance', 'authors': 'Guoqing Chao, Zhenghao Zhang, Lei Meng, Jie Wen, Dianhui Chu', 'link': 'https://arxiv.org/abs/2506.15703', 'abstract': 'Federated multi-view clustering has been proposed to mine the valuable information within multi-view data distributed across different devices and has achieved impressive results while preserving the privacy. Despite great progress, most federated multi-view clustering methods only used global pseudo-labels to guide the downstream clustering process and failed to exploit the global information when extracting features. In addition, missing data problem in federated multi-view clustering task is less explored. To address these problems, we propose a novel Federated Incomplete Multi-view Clustering method with globally Fused Graph guidance (FIMCFG). Specifically, we designed a dual-head graph convolutional encoder at each client to extract two kinds of underlying features containing global and view-specific information. Subsequently, under the guidance of the fused graph, the two underlying features are fused into high-level features, based on which clustering is conducted under the supervision of pseudo-labeling. Finally, the high-level features are uploaded to the server to refine the graph fusion and pseudo-labeling computation. Extensive experimental results demonstrate the effectiveness and superiority of FIMCFG. Our code is publicly available at this https URL.', 'abstract_zh': '联邦多视图不完备聚类方法及其全局图引导（FIMCFG）', 'title_zh': '全局融合图引导的联邦不完备多视图聚类'}
{'arxiv_id': 'arXiv:2506.15691', 'title': 'What Do Latent Action Models Actually Learn?', 'authors': 'Chuheng Zhang, Tim Pearce, Pushi Zhang, Kaixin Wang, Xiaoyu Chen, Wei Shen, Li Zhao, Jiang Bian', 'link': 'https://arxiv.org/abs/2506.15691', 'abstract': 'Latent action models (LAMs) aim to learn action-relevant changes from unlabeled videos by compressing changes between frames as latents. However, differences between video frames can be caused by controllable changes as well as exogenous noise, leading to an important concern -- do latents capture the changes caused by actions or irrelevant noise? This paper studies this issue analytically, presenting a linear model that encapsulates the essence of LAM learning, while being this http URL provides several insights, including connections between LAM and principal component analysis (PCA), desiderata of the data-generating policy, and justification of strategies to encourage learning controllable changes using data augmentation, data cleaning, and auxiliary action-prediction. We also provide illustrative results based on numerical simulation, shedding light on the specific structure of observations, actions, and noise in data that influence LAM learning.', 'abstract_zh': '潜动作模型（LAMs）旨在通过压缩帧间变化来学习未标注视频中的动作相关变化，但视频帧之间的差异可能由可控变化和外部噪声引起，这引发了一个重要问题：潜变量是否捕获了由动作引起的变化还是无关的噪声？本文从理论上研究了这一问题，建立了一个线性模型来体现LAM学习的本质，同时探讨了LAM与主成分分析（PCA）的联系、数据生成策略的期望、以及通过数据增强、数据清洗和辅助动作预测来促进学习可控变化的合理性。我们也提供了基于数值模拟的示例结果，揭示了影响LAM学习的观察、动作和噪声的具体结构。', 'title_zh': '潜行动作模型究竟学到了什么？'}
{'arxiv_id': 'arXiv:2506.15688', 'title': 'Cellular Traffic Prediction via Deep State Space Models with Attention Mechanism', 'authors': 'Hui Ma, Kai Yang, Man-On Pun', 'link': 'https://arxiv.org/abs/2506.15688', 'abstract': 'Cellular traffic prediction is of great importance for operators to manage network resources and make decisions. Traffic is highly dynamic and influenced by many exogenous factors, which would lead to the degradation of traffic prediction accuracy. This paper proposes an end-to-end framework with two variants to explicitly characterize the spatiotemporal patterns of cellular traffic among neighboring cells. It uses convolutional neural networks with an attention mechanism to capture the spatial dynamics and Kalman filter for temporal modelling. Besides, we can fully exploit the auxiliary information such as social activities to improve prediction performance. We conduct extensive experiments on three real-world datasets. The results show that our proposed models outperform the state-of-the-art machine learning techniques in terms of prediction accuracy.', 'abstract_zh': '基于端到端框架的邻区细胞流量时空模式预测研究', 'title_zh': '基于注意力机制的深度状态空间模型在细胞流量预测中的应用'}
{'arxiv_id': 'arXiv:2506.15686', 'title': 'Learning from M-Tuple Dominant Positive and Unlabeled Data', 'authors': 'Jiahe Qin, Junpeng Li, Changchun Hua, Yana Yang', 'link': 'https://arxiv.org/abs/2506.15686', 'abstract': 'Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework \\emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.', 'abstract_zh': 'MDPU：基于分布统一的风险估计的标记比例学习泛化框架', 'title_zh': '学习来自M-元主导正样本和未标注数据'}
{'arxiv_id': 'arXiv:2506.15685', 'title': 'Ignition Phase : Standard Training for Fast Adversarial Robustness', 'authors': 'Wang Yu-Hang, Liu ying, Fang liang, Wang Xuelin, Junkang Guo, Shiwei Li, Lei Gao, Jian Liu, Wenfei Yin', 'link': 'https://arxiv.org/abs/2506.15685', 'abstract': 'Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25\\%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.', 'abstract_zh': '对抗训练（AT）是基础性的防御手段，但许多变体主要关注于更强攻击的生成而忽略了基础特征表示。我们引入了对抗演化训练（AET），这是一种简单而强大的框架，在传统的AT中战略地前接一个经验风险最小化（ERM）阶段。我们假设这一初始的ERM阶段培养出更有利的特征流形，从而使 robustness 的获得更加高效和有效。实验表明，AET 能更快地实现可比或更优的 robustness，提高干净准确性，并降低8-25%的训练成本。其有效性在多种数据集、架构以及增强现有AT方法时均得到验证。我们的发现强调了通过标准训练进行特征预处理对于开发更高效、原则性的 robust 防御的重要性。相关代码附在补充材料中。', 'title_zh': '点火阶段：标准训练以快速提升 adversarial 抵抗性'}
{'arxiv_id': 'arXiv:2506.15655', 'title': 'cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree', 'authors': 'Yilin Zhang, Xinran Zhao, Zora Zhiruo Wang, Chenyang Yang, Jiayi Wei, Tongshuang Wu', 'link': 'https://arxiv.org/abs/2506.15655', 'abstract': 'Retrieval-Augmented Generation (RAG) has become essential for large-scale code generation, grounding predictions in external code corpora to improve actuality. However, a critical yet underexplored aspect of RAG pipelines is chunking -- the process of dividing documents into retrievable units. Existing line-based chunking heuristics often break semantic structures, splitting functions or merging unrelated code, which can degrade generation quality. We propose chunking via Abstract Syntax Trees (\\ourwork), a structure-aware method that recursively breaks large AST nodes into smaller chunks and merges sibling nodes while respecting size limits. This approach generates self-contained, semantically coherent units across programming languages and tasks, improving performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3 points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation. Our work highlights the importance of structure-aware chunking for scaling retrieval-enhanced code intelligence.', 'abstract_zh': '基于抽象语法树的分块方法（RAG中的结构感知分块）已成为大规模代码生成的关键，能够基于外部代码语料库提高预测的实际性。然而，RAG管道中的一个关键但未充分探索的方面是分块——文档分割成可检索单元的过程。现有的基于行的分块启发式方法往往破坏了语义结构，分割函数或将不相关的代码合并，从而降低了生成质量。我们提出了一种基于抽象语法树的分块方法（\\ourwork），这是一种结构感知方法，递归地将大型AST节点分割成较小的块，并合并兄弟节点同时遵守大小限制。这种方法在编程语言和任务中生成自我包含且语义连贯的单元，提高了各种代码生成任务的性能，例如在RepoEval检索上的Recall@5提升了4.3个点，在SWE-bench生成上的Pass@1提升了2.67个点。我们的工作强调了为了扩展增强检索的代码智能，结构感知分块的重要性。', 'title_zh': 'cAST：通过抽象语法树的结构分块增强代码检索增强生成'}
